Title: PromCon Online 2020 - TSDB WTF, Ian Billett, Improbable
Publication date: 2020-07-23
Playlist: PromCon Online 2020
Description: 
	The TSDB is the beating heart of any instance of Prometheus; it is the storage engine that lets users efficiently store and query billions of data points. However, getting the best out of the TSDB is non-trivial and easy to get wrong.

If we can develop an understanding of how it works under the hood, we can precisely reason about what it is well suited for, and more importantly, what it is not well suited for.

In this beginner-focused talk Ian will introduce the TSDB, examine its main components, and explain how each piece fits together. We will walk through the lifecycle of a sample, from storage to compaction and retrieval. In this journey we will cover: blocks, chunks, wals, series churn, cardinality, inverted indexes andâ€¦ gorillas?
Captions: 
	00:00:01,770 --> 00:00:04,940
[Music]

00:00:15,599 --> 00:00:19,760
next up

00:00:16,560 --> 00:00:20,960
we have iron billet talking about all

00:00:19,760 --> 00:00:24,080
the intricacies

00:00:20,960 --> 00:00:26,960
of of the tsdb and also as

00:00:24,080 --> 00:00:28,880
as a nameless cloud provider is not on

00:00:26,960 --> 00:00:30,480
fire anymore he's even able to join us

00:00:28,880 --> 00:00:32,399
afterwards for the q a

00:00:30,480 --> 00:00:34,160
so another round of virtual applause

00:00:32,399 --> 00:00:36,559
please

00:00:34,160 --> 00:00:38,719
welcome to this virtual prom con north

00:00:36,559 --> 00:00:41,040
america 2020 talk

00:00:38,719 --> 00:00:43,360
my name is ian billet i'm a software

00:00:41,040 --> 00:00:45,360
engineer at improbable where we

00:00:43,360 --> 00:00:46,399
build and run infrastructure for online

00:00:45,360 --> 00:00:51,520
games

00:00:46,399 --> 00:00:53,520
and the title of this talk is tsdbwtf

00:00:51,520 --> 00:00:55,840
this is a statement that i found myself

00:00:53,520 --> 00:00:57,280
saying when i was trying to wrap my head

00:00:55,840 --> 00:01:00,480
around what the tsdb

00:00:57,280 --> 00:01:03,199
is what it does and how it works

00:01:00,480 --> 00:01:05,600
but i am pleased to tell you that the

00:01:03,199 --> 00:01:08,720
number of wtfs per minute

00:01:05,600 --> 00:01:09,280
is decreasing over time which is a

00:01:08,720 --> 00:01:11,600
perfectly

00:01:09,280 --> 00:01:12,799
scientific measurement of understanding

00:01:11,600 --> 00:01:15,840
this talk is about

00:01:12,799 --> 00:01:18,159
sharing with you the intuition

00:01:15,840 --> 00:01:19,600
mental models and coping strategies that

00:01:18,159 --> 00:01:23,360
have been helpful to me

00:01:19,600 --> 00:01:25,119
in understanding the tsdb this talk is

00:01:23,360 --> 00:01:26,400
aimed at the less experienced members of

00:01:25,119 --> 00:01:28,880
this community

00:01:26,400 --> 00:01:30,880
it's about getting a firm grasp of the

00:01:28,880 --> 00:01:32,880
fundamental concepts that will serve you

00:01:30,880 --> 00:01:36,159
well when working with prometheus

00:01:32,880 --> 00:01:39,280
and also the wider ecosystem projects

00:01:36,159 --> 00:01:41,680
like thanos and cortex

00:01:39,280 --> 00:01:43,040
this is very much a i wish i'd been told

00:01:41,680 --> 00:01:45,439
this kind of talk

00:01:43,040 --> 00:01:46,240
i'm very much a visual learner so

00:01:45,439 --> 00:01:49,439
diagrams

00:01:46,240 --> 00:01:51,280
animations will all feature very heavily

00:01:49,439 --> 00:01:52,560
and coincidentally this is actually

00:01:51,280 --> 00:01:53,600
quite a good time to give this talk

00:01:52,560 --> 00:01:57,280
because there have been some

00:01:53,600 --> 00:01:57,840
changes to the tsdb in the 2.19 release

00:01:57,280 --> 00:02:01,520
that we'll

00:01:57,840 --> 00:02:03,040
mention so we're going to introduce the

00:02:01,520 --> 00:02:05,680
core concepts of the tsdb

00:02:03,040 --> 00:02:06,399
by stepping through the right path the

00:02:05,680 --> 00:02:09,599
right path

00:02:06,399 --> 00:02:12,000
is the sequence of steps that happen for

00:02:09,599 --> 00:02:12,800
a given piece of data to be ingested and

00:02:12,000 --> 00:02:15,920
stored

00:02:12,800 --> 00:02:16,560
in the tsdb we will pause and discuss

00:02:15,920 --> 00:02:18,080
concepts

00:02:16,560 --> 00:02:20,080
kind of in more detail where it makes

00:02:18,080 --> 00:02:21,760
sense to and

00:02:20,080 --> 00:02:23,599
finally we're going to round this talk

00:02:21,760 --> 00:02:26,560
off with a recap

00:02:23,599 --> 00:02:28,879
like cheat sheet to solidify the things

00:02:26,560 --> 00:02:32,160
that we have talked about

00:02:28,879 --> 00:02:33,440
so without further ado let's dive

00:02:32,160 --> 00:02:36,640
straight in

00:02:33,440 --> 00:02:39,840
firstly the basics tsdb

00:02:36,640 --> 00:02:43,200
stands for time series database

00:02:39,840 --> 00:02:45,440
what is a time series a time series is a

00:02:43,200 --> 00:02:48,000
stream of timestamp value pairs

00:02:45,440 --> 00:02:49,360
that is uniquely identified by an

00:02:48,000 --> 00:02:52,400
identifier

00:02:49,360 --> 00:02:52,800
in prometheus the identifier is a label

00:02:52,400 --> 00:02:55,840
set

00:02:52,800 --> 00:02:57,760
that looks like this a label set is just

00:02:55,840 --> 00:02:59,920
a collection of key value pairs that

00:02:57,760 --> 00:03:00,959
tell you useful metadata about the time

00:02:59,920 --> 00:03:03,040
series

00:03:00,959 --> 00:03:04,800
and when i'm feeling particularly lazy i

00:03:03,040 --> 00:03:05,280
kind of think of this just like a json

00:03:04,800 --> 00:03:08,319
blob

00:03:05,280 --> 00:03:10,720
it's kind of close enough

00:03:08,319 --> 00:03:12,080
so the first thing i think of when

00:03:10,720 --> 00:03:14,959
thinking about the right path

00:03:12,080 --> 00:03:15,920
is how does prometheus get the time

00:03:14,959 --> 00:03:18,239
series data

00:03:15,920 --> 00:03:20,239
let's demonstrate this so we have our

00:03:18,239 --> 00:03:23,680
prometheus server

00:03:20,239 --> 00:03:26,159
and we have our target target is the

00:03:23,680 --> 00:03:27,920
terminology used to refer to a thing

00:03:26,159 --> 00:03:30,480
that we receive data from

00:03:27,920 --> 00:03:31,519
technically it is like an ip and port

00:03:30,480 --> 00:03:33,840
combination

00:03:31,519 --> 00:03:35,680
it is deliberately an abstract phrase as

00:03:33,840 --> 00:03:37,120
we could easily be scraping different

00:03:35,680 --> 00:03:39,840
ports on the same vm

00:03:37,120 --> 00:03:40,720
or pods or whatever you might ask how

00:03:39,840 --> 00:03:42,239
does prometheus

00:03:40,720 --> 00:03:44,560
know about the targets it should be

00:03:42,239 --> 00:03:46,799
scraping that is the topic of service

00:03:44,560 --> 00:03:48,239
discovery and it is vastly out of scope

00:03:46,799 --> 00:03:49,760
for this talk but

00:03:48,239 --> 00:03:52,239
there are lots of great resources out

00:03:49,760 --> 00:03:54,239
there so prometheus is a

00:03:52,239 --> 00:03:55,760
pull-based system that means that it

00:03:54,239 --> 00:03:58,720
requests the data

00:03:55,760 --> 00:03:59,200
from the target usually this is exposed

00:03:58,720 --> 00:04:03,040
by

00:03:59,200 --> 00:04:05,120
via the slash metrics http endpoint

00:04:03,040 --> 00:04:06,319
the target then responds with the

00:04:05,120 --> 00:04:08,959
metrics page

00:04:06,319 --> 00:04:09,920
this is a text response in the metric

00:04:08,959 --> 00:04:12,959
exposition

00:04:09,920 --> 00:04:14,720
format you can look that up in reality

00:04:12,959 --> 00:04:17,199
there are loads of metrics on this

00:04:14,720 --> 00:04:18,160
metrics page this is just a tiny tiny

00:04:17,199 --> 00:04:21,519
fraction

00:04:18,160 --> 00:04:24,320
for example prometheus's own metrics

00:04:21,519 --> 00:04:25,360
page exports about 340 metrics by

00:04:24,320 --> 00:04:27,919
default

00:04:25,360 --> 00:04:30,720
internally to prometheus each target is

00:04:27,919 --> 00:04:32,960
managed by a scrape loop object

00:04:30,720 --> 00:04:33,919
that pulls this data in at regular

00:04:32,960 --> 00:04:37,360
intervals

00:04:33,919 --> 00:04:39,280
the default for which is 15 seconds

00:04:37,360 --> 00:04:40,720
the metrics page that the scrape loop

00:04:39,280 --> 00:04:43,600
obtained from the target

00:04:40,720 --> 00:04:45,680
is then run through the text parser this

00:04:43,600 --> 00:04:48,160
converts the raw bytes of the metrics

00:04:45,680 --> 00:04:48,800
page response into native objects that

00:04:48,160 --> 00:04:52,479
contain

00:04:48,800 --> 00:04:54,320
the time series identifier the label set

00:04:52,479 --> 00:04:56,479
and the time stamp that the scrape

00:04:54,320 --> 00:04:57,040
happened and the value of the time

00:04:56,479 --> 00:04:59,759
series

00:04:57,040 --> 00:05:00,800
at that point in time these are called

00:04:59,759 --> 00:05:03,520
samples

00:05:00,800 --> 00:05:04,320
each of which is one value in a time

00:05:03,520 --> 00:05:07,199
series

00:05:04,320 --> 00:05:08,080
now at this point in our story of the

00:05:07,199 --> 00:05:10,560
right path

00:05:08,080 --> 00:05:12,160
we have a regular stream of samples

00:05:10,560 --> 00:05:14,320
coming in from all the targets that our

00:05:12,160 --> 00:05:16,880
prometheus instance is scraping

00:05:14,320 --> 00:05:18,160
the next natural question to ask is how

00:05:16,880 --> 00:05:20,479
should we go about

00:05:18,160 --> 00:05:21,600
storing these samples we can start to

00:05:20,479 --> 00:05:24,560
answer this question

00:05:21,600 --> 00:05:26,479
when we think about the pattern of data

00:05:24,560 --> 00:05:28,479
ingestion and the types of queries that

00:05:26,479 --> 00:05:30,639
people will ask of the data

00:05:28,479 --> 00:05:32,240
let's give an example of what we mean we

00:05:30,639 --> 00:05:34,560
have our time series

00:05:32,240 --> 00:05:36,880
here on the y-axis and time on the

00:05:34,560 --> 00:05:37,680
x-axis and as time progresses we ingest

00:05:36,880 --> 00:05:40,800
data

00:05:37,680 --> 00:05:42,320
like so sometimes scrapes are missing

00:05:40,800 --> 00:05:44,240
sometimes the targets are not scraped

00:05:42,320 --> 00:05:45,840
perfectly at each interval this is

00:05:44,240 --> 00:05:49,199
normal unexpected

00:05:45,840 --> 00:05:51,680
but what we do see is a vertical pattern

00:05:49,199 --> 00:05:53,759
of rights this basically means that we

00:05:51,680 --> 00:05:54,639
ingest samples from our targets all at

00:05:53,759 --> 00:05:56,960
once

00:05:54,639 --> 00:05:58,960
however the general pattern of a user

00:05:56,960 --> 00:06:00,000
requesting data from the system will be

00:05:58,960 --> 00:06:02,720
horizontal

00:06:00,000 --> 00:06:04,720
in nature which means that they will

00:06:02,720 --> 00:06:06,639
likely request data for a subset of

00:06:04,720 --> 00:06:10,319
metrics over a period of time

00:06:06,639 --> 00:06:12,479
these are called horizontal reads

00:06:10,319 --> 00:06:15,360
satisfying these two constraints is the

00:06:12,479 --> 00:06:17,759
core problem that the tsdb has to solve

00:06:15,360 --> 00:06:20,080
data is ingested in vertical slices but

00:06:17,759 --> 00:06:20,720
it needs to be stored in such a way that

00:06:20,080 --> 00:06:24,720
supports

00:06:20,720 --> 00:06:27,039
the horizontal reads done by users so

00:06:24,720 --> 00:06:30,240
how does prometheus tackle this problem

00:06:27,039 --> 00:06:34,400
well in part it solves it by introducing

00:06:30,240 --> 00:06:37,520
the concept of chunks what is a chunk

00:06:34,400 --> 00:06:40,960
a chunk is a per time series sequential

00:06:37,520 --> 00:06:43,039
series of samples

00:06:40,960 --> 00:06:44,639
let's step through kind of how they work

00:06:43,039 --> 00:06:45,759
so we have our incoming stream of

00:06:44,639 --> 00:06:47,840
samples

00:06:45,759 --> 00:06:49,759
coming from our target scrape loops

00:06:47,840 --> 00:06:50,319
these samples are written into the head

00:06:49,759 --> 00:06:51,919
chunk

00:06:50,319 --> 00:06:53,680
which is the chunk that is currently

00:06:51,919 --> 00:06:56,000
open for a pens

00:06:53,680 --> 00:06:58,560
the samples then fill up in the chunk

00:06:56,000 --> 00:06:58,560
like so

00:07:00,720 --> 00:07:07,360
when the chunk contains 120 samples

00:07:04,080 --> 00:07:10,479
it is classified as being full well why

00:07:07,360 --> 00:07:12,240
120 samples per chunk well

00:07:10,479 --> 00:07:14,000
when the samples are appended to the

00:07:12,240 --> 00:07:16,880
chunk they are encoded

00:07:14,000 --> 00:07:17,360
and 120 samples is the sweet spot for

00:07:16,880 --> 00:07:20,240
the

00:07:17,360 --> 00:07:21,199
standard encoding mechanism the next

00:07:20,240 --> 00:07:24,000
question you may ask

00:07:21,199 --> 00:07:25,120
is how are the samples encoded into the

00:07:24,000 --> 00:07:26,720
chunks

00:07:25,120 --> 00:07:28,639
this is a very interesting topic that i

00:07:26,720 --> 00:07:30,560
will not go into any detail on and i

00:07:28,639 --> 00:07:32,240
encourage you to watch these videos that

00:07:30,560 --> 00:07:35,280
go into a lot of detail

00:07:32,240 --> 00:07:36,000
the tldr is that the encoding mechanism

00:07:35,280 --> 00:07:39,039
is called

00:07:36,000 --> 00:07:41,520
xor encoding this harnesses

00:07:39,039 --> 00:07:44,000
the regularity of scraping timestamps

00:07:41,520 --> 00:07:44,639
and linearly increasing values to

00:07:44,000 --> 00:07:48,400
compress

00:07:44,639 --> 00:07:49,440
each sample from 16 bytes down to 1.3

00:07:48,400 --> 00:07:52,639
bytes on average

00:07:49,440 --> 00:07:53,280
it is very impressive when our head

00:07:52,639 --> 00:07:56,080
chunk is

00:07:53,280 --> 00:07:58,000
full the chunk is closed to right and a

00:07:56,080 --> 00:08:03,280
new head chunk is created

00:07:58,000 --> 00:08:03,280
to accept the incoming stream of samples

00:08:04,080 --> 00:08:11,520
so prometheus version 2.19 introduced

00:08:07,520 --> 00:08:14,240
the memory mapping of chunks

00:08:11,520 --> 00:08:17,280
in the chunks underscore head directory

00:08:14,240 --> 00:08:19,360
in the tsdb data directory

00:08:17,280 --> 00:08:21,199
we won't go into detail but suffice to

00:08:19,360 --> 00:08:22,160
say that this is an optimization to

00:08:21,199 --> 00:08:24,879
reduce

00:08:22,160 --> 00:08:26,080
the memory overhead of holding chunks in

00:08:24,879 --> 00:08:28,319
memory

00:08:26,080 --> 00:08:30,160
at this point we are happily ingesting

00:08:28,319 --> 00:08:31,159
samples from our scrape loops and we are

00:08:30,160 --> 00:08:34,719
creating

00:08:31,159 --> 00:08:35,680
120 sample chunks everything seems to be

00:08:34,719 --> 00:08:37,599
going smoothly

00:08:35,680 --> 00:08:39,279
one problem is that we are holding all

00:08:37,599 --> 00:08:42,080
of these samples in memory

00:08:39,279 --> 00:08:43,919
if the process crashes we stand to lose

00:08:42,080 --> 00:08:45,200
the data that we have ingested from our

00:08:43,919 --> 00:08:46,959
targets

00:08:45,200 --> 00:08:49,040
and prometheus protects us against its

00:08:46,959 --> 00:08:53,200
eventuality with something called

00:08:49,040 --> 00:08:56,560
the wow what is the wow

00:08:53,200 --> 00:08:59,120
the right ahead log is an on-disk log of

00:08:56,560 --> 00:09:00,720
every record that has been ingested by

00:08:59,120 --> 00:09:04,080
prometheus

00:09:00,720 --> 00:09:06,000
a record here is either a sample a new

00:09:04,080 --> 00:09:06,720
series that prometheus has seen or a

00:09:06,000 --> 00:09:10,240
tombstone

00:09:06,720 --> 00:09:10,800
i'll explain these later on the idea of

00:09:10,240 --> 00:09:13,279
a wow

00:09:10,800 --> 00:09:14,560
is that every single incoming record to

00:09:13,279 --> 00:09:17,839
this tsdb

00:09:14,560 --> 00:09:20,000
is written to disk before being appended

00:09:17,839 --> 00:09:21,920
to the relevant chunk

00:09:20,000 --> 00:09:23,920
this protects prometheus against data

00:09:21,920 --> 00:09:26,959
loss by providing a mechanism

00:09:23,920 --> 00:09:29,120
for replaying the data into memory that

00:09:26,959 --> 00:09:32,240
was lost when the process crashed

00:09:29,120 --> 00:09:35,279
and it's fairly common in database

00:09:32,240 --> 00:09:37,040
let's see this in action so we have an

00:09:35,279 --> 00:09:40,720
instance of prometheus that starts up

00:09:37,040 --> 00:09:40,720
and begins ingesting samples

00:09:42,880 --> 00:09:48,080
at some point the process crashes wiping

00:09:45,839 --> 00:09:50,320
all of the chunks from memory

00:09:48,080 --> 00:09:52,000
when the process is restarted the first

00:09:50,320 --> 00:09:52,640
thing that happens is the data in the

00:09:52,000 --> 00:09:55,040
wow

00:09:52,640 --> 00:09:56,800
is replayed back into memory to get us

00:09:55,040 --> 00:09:58,800
back to where we were

00:09:56,800 --> 00:10:00,160
by default the while retains the last

00:09:58,800 --> 00:10:03,440
two hours worth of data

00:10:00,160 --> 00:10:06,000
we will explain two hours very shortly

00:10:03,440 --> 00:10:07,279
in the tsdb data directory the wow looks

00:10:06,000 --> 00:10:10,320
like this

00:10:07,279 --> 00:10:13,519
and you may ask what are these files

00:10:10,320 --> 00:10:16,240
these are wow segment files so

00:10:13,519 --> 00:10:19,360
the totality of the wild data is split

00:10:16,240 --> 00:10:23,040
between these 128 megabyte

00:10:19,360 --> 00:10:26,560
files what is the wow checkpoint

00:10:23,040 --> 00:10:27,200
this is an optimization made to speed up

00:10:26,560 --> 00:10:29,680
the wow

00:10:27,200 --> 00:10:30,839
replay process and the while checkpoint

00:10:29,680 --> 00:10:34,240
contains

00:10:30,839 --> 00:10:36,079
compacted wow segment files

00:10:34,240 --> 00:10:38,079
heavy load servers can have really

00:10:36,079 --> 00:10:40,320
really big walls that can take

00:10:38,079 --> 00:10:42,240
hours to reload when the tsdb is

00:10:40,320 --> 00:10:46,640
reopened

00:10:42,240 --> 00:10:48,800
so lots of optimizations have been made

00:10:46,640 --> 00:10:50,880
so at this point we have a stream of

00:10:48,800 --> 00:10:52,079
samples ingested by our target scrape

00:10:50,880 --> 00:10:55,120
loops

00:10:52,079 --> 00:10:57,519
the samples have been encoded into per

00:10:55,120 --> 00:10:58,240
time series chunks in memory and

00:10:57,519 --> 00:11:00,320
prometheus

00:10:58,240 --> 00:11:02,640
is protected against data loss by the

00:11:00,320 --> 00:11:06,079
wow the next thing we want to do

00:11:02,640 --> 00:11:07,920
is write our in-memory chunks to disk

00:11:06,079 --> 00:11:10,240
to explain this we must introduce the

00:11:07,920 --> 00:11:13,360
concept of a block

00:11:10,240 --> 00:11:15,440
what is a block

00:11:13,360 --> 00:11:18,160
a block is like a mini database it

00:11:15,440 --> 00:11:19,920
contains your chunk data

00:11:18,160 --> 00:11:21,680
and all of the other things you need to

00:11:19,920 --> 00:11:23,519
query that data

00:11:21,680 --> 00:11:24,880
and there are two key processes that

00:11:23,519 --> 00:11:27,440
govern the life cycle

00:11:24,880 --> 00:11:29,200
of a block these are compaction and

00:11:27,440 --> 00:11:32,240
truncation

00:11:29,200 --> 00:11:32,959
let's now see how blocks work similar to

00:11:32,240 --> 00:11:35,120
chunks

00:11:32,959 --> 00:11:36,880
the head block is the in-memory data

00:11:35,120 --> 00:11:39,279
structure that represents the block that

00:11:36,880 --> 00:11:41,600
is currently being filled up with data

00:11:39,279 --> 00:11:43,600
it has some extra bits of information

00:11:41,600 --> 00:11:46,480
that we'll talk about in just a second

00:11:43,600 --> 00:11:48,000
as samples are being ingested and chunks

00:11:46,480 --> 00:11:50,320
are being created

00:11:48,000 --> 00:11:52,320
those chunks fill up in the head block

00:11:50,320 --> 00:11:54,320
like so

00:11:52,320 --> 00:11:55,440
when the head block contains two hours

00:11:54,320 --> 00:11:57,760
worth of data

00:11:55,440 --> 00:11:59,600
it then becomes compactable which

00:11:57,760 --> 00:12:02,160
basically means that it is ready to be

00:11:59,600 --> 00:12:04,240
written to disk

00:12:02,160 --> 00:12:05,680
two hours is the default block value

00:12:04,240 --> 00:12:08,000
which can be configured

00:12:05,680 --> 00:12:10,079
and this is why the while retains two

00:12:08,000 --> 00:12:12,720
hours worth of data

00:12:10,079 --> 00:12:14,399
compaction is a process that takes any

00:12:12,720 --> 00:12:16,959
number of blocks as input

00:12:14,399 --> 00:12:17,680
and compacts these into a new block

00:12:16,959 --> 00:12:20,000
containing

00:12:17,680 --> 00:12:21,040
all of the information of the input

00:12:20,000 --> 00:12:22,880
blocks

00:12:21,040 --> 00:12:24,880
here we are talking about it in the

00:12:22,880 --> 00:12:27,680
context of compacting the head block

00:12:24,880 --> 00:12:29,279
but it also applies to compacting

00:12:27,680 --> 00:12:31,200
multiple on-disk blocks

00:12:29,279 --> 00:12:32,560
into bigger blocks covering a longer

00:12:31,200 --> 00:12:35,120
time range

00:12:32,560 --> 00:12:36,959
so when the next compaction cycle occurs

00:12:35,120 --> 00:12:39,360
which is triggered at least every minute

00:12:36,959 --> 00:12:41,519
the head block is written to disk like

00:12:39,360 --> 00:12:43,120
so

00:12:41,519 --> 00:12:45,519
once the head block has been compacted

00:12:43,120 --> 00:12:46,320
to disk it goes through the truncation

00:12:45,519 --> 00:12:48,639
process

00:12:46,320 --> 00:12:50,720
which basically means flushing all of

00:12:48,639 --> 00:12:52,800
its in-memory data structures

00:12:50,720 --> 00:12:56,560
ready to start being recreated by the

00:12:52,800 --> 00:12:56,560
stream of incoming samples

00:12:56,720 --> 00:13:04,000
so what do the blocks look like on disk

00:13:00,240 --> 00:13:04,000
the block format looks like this

00:13:04,240 --> 00:13:10,240
the name is some kind of encoding of the

00:13:07,440 --> 00:13:12,480
timestamp of when the block was created

00:13:10,240 --> 00:13:13,920
you can see the chunk files here be

00:13:12,480 --> 00:13:16,399
careful

00:13:13,920 --> 00:13:18,720
seeing two chunk files does not mean

00:13:16,399 --> 00:13:21,200
that there are two chunks in the block

00:13:18,720 --> 00:13:23,519
these are in fact chunk segment files

00:13:21,200 --> 00:13:24,880
where many many chunks are embedded in a

00:13:23,519 --> 00:13:27,519
special format

00:13:24,880 --> 00:13:29,519
and these files roll over at 512

00:13:27,519 --> 00:13:32,720
megabytes which is the default chunk

00:13:29,519 --> 00:13:35,200
segment file size you will also ask what

00:13:32,720 --> 00:13:37,040
are tombstones

00:13:35,200 --> 00:13:38,639
tombstones represent the way that

00:13:37,040 --> 00:13:41,360
prometheus deletes data

00:13:38,639 --> 00:13:42,000
if you call the delete api endpoint and

00:13:41,360 --> 00:13:44,079
say

00:13:42,000 --> 00:13:45,600
i want to delete time series x between

00:13:44,079 --> 00:13:47,760
these two time stamps

00:13:45,600 --> 00:13:48,720
the data is not actually deleted there

00:13:47,760 --> 00:13:51,839
and then

00:13:48,720 --> 00:13:52,959
rather a tombstone entry is created that

00:13:51,839 --> 00:13:55,839
basically says

00:13:52,959 --> 00:13:58,240
that the data of time series x between

00:13:55,839 --> 00:14:01,360
this time range is due to be deleted

00:13:58,240 --> 00:14:05,040
when the block that contains

00:14:01,360 --> 00:14:09,440
that piece of data is next compacted

00:14:05,040 --> 00:14:12,240
the compaction process will not include

00:14:09,440 --> 00:14:13,199
the time series data range referenced by

00:14:12,240 --> 00:14:17,600
the tombstones

00:14:13,199 --> 00:14:19,040
when the next block of data is created

00:14:17,600 --> 00:14:20,880
so the final thing i wanted to talk

00:14:19,040 --> 00:14:22,480
about in a little bit of detail is the

00:14:20,880 --> 00:14:25,839
index

00:14:22,480 --> 00:14:28,639
so how does the block index work

00:14:25,839 --> 00:14:30,480
each block contains an index this is the

00:14:28,639 --> 00:14:32,720
thing that you use when you're trying to

00:14:30,480 --> 00:14:35,440
figure out where the chunks of data are

00:14:32,720 --> 00:14:37,199
for time series that you care about for

00:14:35,440 --> 00:14:38,079
on disk blocks this is contained in the

00:14:37,199 --> 00:14:39,920
index file

00:14:38,079 --> 00:14:42,160
but the head block keeps these data

00:14:39,920 --> 00:14:44,720
structures in memory

00:14:42,160 --> 00:14:45,199
so prometheus uses an inverted index to

00:14:44,720 --> 00:14:47,839
achieve

00:14:45,199 --> 00:14:50,720
chunk data when queried and the key data

00:14:47,839 --> 00:14:54,079
structure here is the postings table

00:14:50,720 --> 00:14:58,240
so a normal index would map a reference

00:14:54,079 --> 00:14:59,040
to the data but an inverted index maps

00:14:58,240 --> 00:15:01,680
data to

00:14:59,040 --> 00:15:02,560
references and this is very common in

00:15:01,680 --> 00:15:05,440
document-like

00:15:02,560 --> 00:15:08,079
databases seeing this in action will

00:15:05,440 --> 00:15:10,800
help it make more sense

00:15:08,079 --> 00:15:12,560
let's take for example a promql query

00:15:10,800 --> 00:15:15,680
promql is the language

00:15:12,560 --> 00:15:17,360
used to query data in prometheus uh

00:15:15,680 --> 00:15:19,440
last prom con i gave a talk called

00:15:17,360 --> 00:15:21,920
promql for mere mortals so

00:15:19,440 --> 00:15:23,839
shameless plug to go check that out when

00:15:21,920 --> 00:15:26,079
we create prometheus we say hey

00:15:23,839 --> 00:15:28,480
please return to me all of the series in

00:15:26,079 --> 00:15:30,320
the dsdb that match my query

00:15:28,480 --> 00:15:31,600
and the query we're looking at here

00:15:30,320 --> 00:15:34,800
consists of two

00:15:31,600 --> 00:15:35,519
labels and we are saying please return

00:15:34,800 --> 00:15:37,839
to me

00:15:35,519 --> 00:15:39,519
all of the time series that contain

00:15:37,839 --> 00:15:42,560
these two labels

00:15:39,519 --> 00:15:45,600
so what the postings table does

00:15:42,560 --> 00:15:48,560
is maintain a mapping of labels

00:15:45,600 --> 00:15:49,199
to time series references that contain

00:15:48,560 --> 00:15:52,480
this

00:15:49,199 --> 00:15:52,959
label now we know which time series have

00:15:52,480 --> 00:15:55,360
each

00:15:52,959 --> 00:15:56,240
label set how do we know which time

00:15:55,360 --> 00:15:58,399
series have

00:15:56,240 --> 00:16:00,320
both of these labels set and that is as

00:15:58,399 --> 00:16:03,839
simple as taking the intersection

00:16:00,320 --> 00:16:06,000
of these references simple

00:16:03,839 --> 00:16:07,279
we then use these time series references

00:16:06,000 --> 00:16:10,560
to fetch the chunks

00:16:07,279 --> 00:16:13,680
to satisfy our original query

00:16:10,560 --> 00:16:16,320
if you dig a bit deeper into the index

00:16:13,680 --> 00:16:18,959
documentation you will find references

00:16:16,320 --> 00:16:20,959
to things like the postings offset table

00:16:18,959 --> 00:16:24,480
and the symbol table

00:16:20,959 --> 00:16:26,959
these are data structures that are used

00:16:24,480 --> 00:16:28,079
to minimize the amount of data that we

00:16:26,959 --> 00:16:30,880
store on disk

00:16:28,079 --> 00:16:33,279
but they don't change the rough flow

00:16:30,880 --> 00:16:35,199
that we've just explained

00:16:33,279 --> 00:16:36,639
this concludes all of the concepts that

00:16:35,199 --> 00:16:38,720
i want to talk about today so let's

00:16:36,639 --> 00:16:39,839
quickly recap the key things that we

00:16:38,720 --> 00:16:43,279
have discovered

00:16:39,839 --> 00:16:46,079
when stepping through the right path

00:16:43,279 --> 00:16:47,360
a sample is the raw data point that we

00:16:46,079 --> 00:16:50,720
get from the target

00:16:47,360 --> 00:16:51,040
scrape loops they are one entry in a

00:16:50,720 --> 00:16:53,440
time

00:16:51,040 --> 00:16:56,480
series and comprise a label set a

00:16:53,440 --> 00:16:59,600
timestamp and a value

00:16:56,480 --> 00:17:01,199
a chunk is an encoded sequential series

00:16:59,600 --> 00:17:02,959
of samples

00:17:01,199 --> 00:17:04,640
the head chunk is the chunk that is

00:17:02,959 --> 00:17:08,079
currently being filled up with

00:17:04,640 --> 00:17:10,880
samples the wow is a two

00:17:08,079 --> 00:17:11,600
hour persistent on-disk record of

00:17:10,880 --> 00:17:14,799
samples

00:17:11,600 --> 00:17:17,120
series and tombstones prometheus uses

00:17:14,799 --> 00:17:18,720
the wow to protect itself against data

00:17:17,120 --> 00:17:21,280
loss in the case that the process

00:17:18,720 --> 00:17:23,439
crashes

00:17:21,280 --> 00:17:25,839
a block is like a mini database that

00:17:23,439 --> 00:17:28,400
contains the chunks of samples

00:17:25,839 --> 00:17:29,679
and the data structures needed to query

00:17:28,400 --> 00:17:31,919
that data

00:17:29,679 --> 00:17:32,720
a block life cycles are managed by the

00:17:31,919 --> 00:17:35,919
compaction

00:17:32,720 --> 00:17:39,120
and truncation steps

00:17:35,919 --> 00:17:41,120
finally an index is a per block object

00:17:39,120 --> 00:17:43,760
that tells us which chunks contain the

00:17:41,120 --> 00:17:46,400
data we care about

00:17:43,760 --> 00:17:47,200
that's all folks thank you very much for

00:17:46,400 --> 00:17:50,880
watching

00:17:47,200 --> 00:17:53,120
i hope that your tsdbwtfs per minute

00:17:50,880 --> 00:17:54,960
now decrease over time and i hope that

00:17:53,120 --> 00:17:57,919
you now have a more intuitive

00:17:54,960 --> 00:17:58,640
understanding for what the tsdb is what

00:17:57,919 --> 00:18:01,200
it does

00:17:58,640 --> 00:18:02,240
and how it works do reach out if you

00:18:01,200 --> 00:18:04,160
have any feedback

00:18:02,240 --> 00:18:05,360
and i hope to see you all at the next

00:18:04,160 --> 00:18:14,559
prom con

00:18:05,360 --> 00:18:17,840
see ya

00:18:14,559 --> 00:18:21,039
can you hear me yes hi

00:18:17,840 --> 00:18:24,160
how you doing richie hi i'm you

00:18:21,039 --> 00:18:26,480
yeah good glad that that's over nothing

00:18:24,160 --> 00:18:28,640
on fire anymore

00:18:26,480 --> 00:18:30,240
i meant the talk because it's so now i

00:18:28,640 --> 00:18:32,000
still get the same nerves like

00:18:30,240 --> 00:18:33,360
like watching a talkback when i do get

00:18:32,000 --> 00:18:36,640
it doing a talk live but

00:18:33,360 --> 00:18:38,720
hey ho yes i find it's a lot more

00:18:36,640 --> 00:18:42,000
horrible to talk into a computer instead

00:18:38,720 --> 00:18:45,600
of having an audience to work with so

00:18:42,000 --> 00:18:46,320
cool uh yeah sorry i think julian was

00:18:45,600 --> 00:18:51,039
doing q a

00:18:46,320 --> 00:18:54,160
i uh sorry i'll just mute myself again

00:18:51,039 --> 00:18:56,160
ah how do i do this

00:18:54,160 --> 00:18:58,240
while reading it out i saw a question

00:18:56,160 --> 00:19:01,280
earlier uh but that was already

00:18:58,240 --> 00:19:01,600
deleted i think or maybe it wasn't i

00:19:01,280 --> 00:19:04,080
think

00:19:01,600 --> 00:19:05,120
uh yeah so there were some questions

00:19:04,080 --> 00:19:06,559
some really good questions from

00:19:05,120 --> 00:19:08,320
darshaname i think that's

00:19:06,559 --> 00:19:09,600
pronounced uh in the chat that i

00:19:08,320 --> 00:19:11,200
answered kind of

00:19:09,600 --> 00:19:12,960
midway through but i guess it's worth uh

00:19:11,200 --> 00:19:14,559
just repeating for for people

00:19:12,960 --> 00:19:16,240
that may be listening on the recording

00:19:14,559 --> 00:19:19,039
so the first question was

00:19:16,240 --> 00:19:19,840
um does the chunk store samples from all

00:19:19,039 --> 00:19:22,640
targets

00:19:19,840 --> 00:19:24,240
or are there chunks per target if the

00:19:22,640 --> 00:19:25,760
former don't we lose some x or

00:19:24,240 --> 00:19:28,320
compressibility

00:19:25,760 --> 00:19:29,280
uh so the answer there is that uh chunks

00:19:28,320 --> 00:19:32,160
are per

00:19:29,280 --> 00:19:33,440
time series so one target presents its

00:19:32,160 --> 00:19:34,960
metrics page to you

00:19:33,440 --> 00:19:37,120
in the metrics page are lots of

00:19:34,960 --> 00:19:39,679
individual time series and it's those

00:19:37,120 --> 00:19:40,960
individual time series per target that

00:19:39,679 --> 00:19:42,960
are stored per chunk

00:19:40,960 --> 00:19:45,440
so you do get this kind of uh amazing

00:19:42,960 --> 00:19:48,240
level of compressibility that um

00:19:45,440 --> 00:19:48,880
fabian and bjorn um and others kind of

00:19:48,240 --> 00:19:51,600
implemented

00:19:48,880 --> 00:19:52,720
over the over the time uh then there was

00:19:51,600 --> 00:19:56,000
a follow-up question

00:19:52,720 --> 00:19:58,640
to uh which was um are wells

00:19:56,000 --> 00:19:59,360
fsync on every right if yes isn't that

00:19:58,640 --> 00:20:02,080
slow

00:19:59,360 --> 00:20:03,520
if not how do we not lose data in the

00:20:02,080 --> 00:20:04,960
event of a crash so

00:20:03,520 --> 00:20:06,559
i wasn't actually quite sure the answer

00:20:04,960 --> 00:20:10,000
to this question but um

00:20:06,559 --> 00:20:10,720
brian has uh very kindly um uh chipped

00:20:10,000 --> 00:20:13,840
in

00:20:10,720 --> 00:20:14,320
and it's not synced uh so i'll just read

00:20:13,840 --> 00:20:16,559
out his

00:20:14,320 --> 00:20:18,480
uh answer verbatim like many other

00:20:16,559 --> 00:20:19,360
databases it's not f synced that will be

00:20:18,480 --> 00:20:20,799
far too slow

00:20:19,360 --> 00:20:22,480
the thinking is that if you lose some

00:20:20,799 --> 00:20:24,000
data it's the same as if the prometheus

00:20:22,480 --> 00:20:25,360
had died a few seconds before

00:20:24,000 --> 00:20:27,039
so not like a massive problem

00:20:25,360 --> 00:20:29,039
semantically for the

00:20:27,039 --> 00:20:31,520
in in the case that prometheus crashes

00:20:29,039 --> 00:20:34,559
and you lose a bunch of data

00:20:31,520 --> 00:20:37,280
um there was another question uh in the

00:20:34,559 --> 00:20:39,600
zoom chat from uh

00:20:37,280 --> 00:20:41,039
actually i believe um one correction on

00:20:39,600 --> 00:20:44,080
that is we actually do

00:20:41,039 --> 00:20:47,440
f sync the wall every 10 seconds

00:20:44,080 --> 00:20:48,640
oh there you go excellent thank you ben

00:20:47,440 --> 00:20:51,440
very much

00:20:48,640 --> 00:20:52,000
um so there's another uh there's another

00:20:51,440 --> 00:20:56,000
question

00:20:52,000 --> 00:20:58,400
from arthur silva sends in the zoom chat

00:20:56,000 --> 00:20:59,840
which says uh from what i remember

00:20:58,400 --> 00:21:01,600
prometheus v1

00:20:59,840 --> 00:21:03,919
used to create a new file at the file

00:21:01,600 --> 00:21:05,280
system for each time series ingested

00:21:03,919 --> 00:21:07,120
this will cause a problem of opening too

00:21:05,280 --> 00:21:08,159
many files when working with a large

00:21:07,120 --> 00:21:10,159
amount of metrics

00:21:08,159 --> 00:21:11,600
this problem was solved in previous v2

00:21:10,159 --> 00:21:14,159
how does the wow

00:21:11,600 --> 00:21:15,280
write samples to the file system without

00:21:14,159 --> 00:21:16,880
causing this problem again

00:21:15,280 --> 00:21:18,720
that's a really good question uh so

00:21:16,880 --> 00:21:19,600
after that you're touching on a topic

00:21:18,720 --> 00:21:20,880
which i

00:21:19,600 --> 00:21:22,400
if i were to do this talk again i would

00:21:20,880 --> 00:21:23,440
definitely mention and that is a serious

00:21:22,400 --> 00:21:25,760
churn so

00:21:23,440 --> 00:21:28,080
when you have a highly dynamic compute

00:21:25,760 --> 00:21:29,360
environment like a kubernetes cluster

00:21:28,080 --> 00:21:32,400
where

00:21:29,360 --> 00:21:34,080
um you get a new set of time series

00:21:32,400 --> 00:21:35,760
every time you roll out every time your

00:21:34,080 --> 00:21:37,520
pods are recreated you get a unique

00:21:35,760 --> 00:21:38,720
uh you get unique sets of time series

00:21:37,520 --> 00:21:39,840
because the pods have different names

00:21:38,720 --> 00:21:41,600
etc etc

00:21:39,840 --> 00:21:42,880
this means that although you may have

00:21:41,600 --> 00:21:45,360
say one million

00:21:42,880 --> 00:21:46,880
active targets that you're scraping from

00:21:45,360 --> 00:21:50,080
your entire

00:21:46,880 --> 00:21:50,799
the tsdb actually represents ten times

00:21:50,080 --> 00:21:53,760
that

00:21:50,799 --> 00:21:53,760
they've been ten rolls

00:21:55,919 --> 00:21:59,840
so so that is the

00:22:05,280 --> 00:22:13,520
i okay i see julian moving so

00:22:09,280 --> 00:22:16,960
it's i know just cut out

00:22:13,520 --> 00:22:16,960
oh sorry it's probably my end

00:22:18,480 --> 00:22:21,440
so yes

00:22:22,240 --> 00:22:24,559
yep

00:22:25,280 --> 00:22:29,200
okay cool we'll try this um yeah so

00:22:27,919 --> 00:22:32,480
that's kind of

00:22:29,200 --> 00:22:35,760
kind of the top concept of

00:22:32,480 --> 00:22:37,280
um and uh yeah and and that kind of co

00:22:35,760 --> 00:22:39,280
in like some of the larger media servers

00:22:37,280 --> 00:22:41,679
that caused prometheus to

00:22:39,280 --> 00:22:42,640
run out of inodes on the underlying

00:22:41,679 --> 00:22:46,240
machine

00:22:42,640 --> 00:22:48,960
uh so the way that uh prometheus

00:22:46,240 --> 00:22:50,640
deals with this in the v2 of the tsdb i

00:22:48,960 --> 00:22:52,400
believe although i would happily

00:22:50,640 --> 00:22:53,760
defer to uh more experienced known as a

00:22:52,400 --> 00:22:57,200
community here um

00:22:53,760 --> 00:22:59,760
is that it compacts it writes the

00:22:57,200 --> 00:23:01,200
chunks in these chunk segment files so

00:22:59,760 --> 00:23:03,200
when you look at your tsd

00:23:01,200 --> 00:23:04,640
directory you look in a chunk directory

00:23:03,200 --> 00:23:06,400
you see a chunks

00:23:04,640 --> 00:23:07,840
subdirectory there are kind of

00:23:06,400 --> 00:23:08,400
sequentially numbered chunks that i

00:23:07,840 --> 00:23:12,400
believe

00:23:08,400 --> 00:23:14,960
roll over at about 12 megabytes

00:23:12,400 --> 00:23:16,799
and so all of these series are kind of

00:23:14,960 --> 00:23:18,880
compacted into these kind of highly

00:23:16,799 --> 00:23:21,039
optimized on disk formats so

00:23:18,880 --> 00:23:21,919
that's that's how they solve it that the

00:23:21,039 --> 00:23:25,280
know problem in

00:23:21,919 --> 00:23:28,799
meteors too um

00:23:25,280 --> 00:23:31,280
okay uh uh answer question if i want to

00:23:28,799 --> 00:23:33,039
continue decreasing my tsd vwds per

00:23:31,280 --> 00:23:36,559
minute further where do i start

00:23:33,039 --> 00:23:40,080
in the code that is a

00:23:36,559 --> 00:23:41,200
funny but troll question um

00:23:40,080 --> 00:23:42,720
i think that actually touches on quite

00:23:41,200 --> 00:23:44,080
an interesting uh point that i'll just

00:23:42,720 --> 00:23:45,679
make here is that um

00:23:44,080 --> 00:23:48,320
kind of for someone coming to this the

00:23:45,679 --> 00:23:50,320
um the code is you know

00:23:48,320 --> 00:23:51,600
it like the code is the the

00:23:50,320 --> 00:23:53,440
implementation but

00:23:51,600 --> 00:23:54,720
for new people it can be quite difficult

00:23:53,440 --> 00:23:57,120
and it was quite difficult

00:23:54,720 --> 00:23:58,640
to openly kind of getting my head around

00:23:57,120 --> 00:24:00,240
what's going on what's happening what

00:23:58,640 --> 00:24:02,159
does this mean what does that mean but

00:24:00,240 --> 00:24:03,919
and there's like there's an open there's

00:24:02,159 --> 00:24:04,559
an open ticket in the prometheus backlog

00:24:03,919 --> 00:24:07,679
to kind of

00:24:04,559 --> 00:24:08,960
talk about uh like uh different sets of

00:24:07,679 --> 00:24:09,760
documentation or something that we can

00:24:08,960 --> 00:24:11,760
do to do this so

00:24:09,760 --> 00:24:13,840
i'm gonna raise a pr there and we can

00:24:11,760 --> 00:24:17,200
kind of start discussion from there

00:24:13,840 --> 00:24:19,520
um okay next

00:24:17,200 --> 00:24:20,960
question we have that's open any ideas

00:24:19,520 --> 00:24:24,080
for tsdb

00:24:20,960 --> 00:24:26,799
dash next for prometheus v3 do we

00:24:24,080 --> 00:24:28,400
already have uh a number of issues with

00:24:26,799 --> 00:24:29,039
the current format do we need major

00:24:28,400 --> 00:24:32,159
updates

00:24:29,039 --> 00:24:34,880
for it from alexi uh

00:24:32,159 --> 00:24:36,880
shiroki um that's a very very good

00:24:34,880 --> 00:24:37,440
question and that is a question that i

00:24:36,880 --> 00:24:40,640
am not

00:24:37,440 --> 00:24:44,000
uh best placed uh to answer

00:24:40,640 --> 00:24:47,120
i believe uh ganesh is doing a talk

00:24:44,000 --> 00:24:48,480
i believe tomorrow called uh tsd be a

00:24:47,120 --> 00:24:50,000
year in review and

00:24:48,480 --> 00:24:52,080
ganesh is kind of one of the main

00:24:50,000 --> 00:24:54,720
developers of the tse at the moment so

00:24:52,080 --> 00:24:56,320
i would highly encourage you all to tune

00:24:54,720 --> 00:24:59,360
into that and direct those kind of

00:24:56,320 --> 00:25:02,960
questions to ganesh

00:24:59,360 --> 00:25:06,000
all right we have

00:25:02,960 --> 00:25:06,000
no open questions

00:25:06,640 --> 00:25:11,360
i still have one question hi uh if i

00:25:10,080 --> 00:25:15,120
still have 30 seconds

00:25:11,360 --> 00:25:17,120
yes the latest treasure produce enabled

00:25:15,120 --> 00:25:17,600
the wall compression by default does it

00:25:17,120 --> 00:25:20,159
mean that

00:25:17,600 --> 00:25:20,720
also some part in memory is also

00:25:20,159 --> 00:25:24,159
compressed

00:25:20,720 --> 00:25:24,159
in only the one in the disk

00:25:24,720 --> 00:25:30,960
the question there was that the tsdb uh

00:25:28,960 --> 00:25:34,000
uh compression has been enabled by

00:25:30,960 --> 00:25:34,640
default is that just on disk i believe

00:25:34,000 --> 00:25:37,679
that

00:25:34,640 --> 00:25:40,880
is just one disk although i mean

00:25:37,679 --> 00:25:43,919
i would i would happily be corrected by

00:25:40,880 --> 00:25:45,520
uh by brian or ben or richie

00:25:43,919 --> 00:25:47,039
yeah you're correct the while

00:25:45,520 --> 00:25:47,520
compression only affects the while on

00:25:47,039 --> 00:25:50,320
disk

00:25:47,520 --> 00:25:52,559
the cost is a tiny amount of cpu that

00:25:50,320 --> 00:25:56,000
normally doesn't matter

00:25:52,559 --> 00:25:56,960
thank you i think that's probably it for

00:25:56,000 --> 00:25:58,960
all questions

00:25:56,960 --> 00:26:00,080
um yeah thank you all for listening i

00:25:58,960 --> 00:26:04,000
hope that was helpful

00:26:00,080 --> 00:26:11,840
and yeah see you all when i see you

00:26:04,000 --> 00:26:11,840
hopefully the next one

00:26:14,160 --> 00:26:19,360
[Music]

00:26:17,279 --> 00:26:19,360

YouTube URL: https://www.youtube.com/watch?v=zTH7DKAWqHc


