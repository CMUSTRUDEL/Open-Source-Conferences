Title: PromCon EU 2019: Expectations on Remote Data
Publication date: 2019-12-29
Playlist: PromCon EU 2019
Description: 
	Speaker: Alfred Landrum

Prometheus's remote storage API allows PromQL evaluation to work with stores other than TSDB, and with data that may not have originated via native Prometheus scraping. PromQL has expectations about the data served by the API, which must be met in order to give a "compatible" user experience with native Prometheus. I'll present my teams experience marrying an existing distributed time series database, originally designed around storing downsampled statsd-style metrics, with a PromQL evaluation engine. I'll cover topics including: downsampling, counter aggregation, series staleness, and others.

Slides: https://promcon.io/2019-munich/slides/expectations-on-remote-data.pdf
Captions: 
	00:00:00,650 --> 00:00:08,910
[Music]

00:00:09,670 --> 00:00:15,250
hi all right I know it's been a long day

00:00:13,600 --> 00:00:16,750
the presentations have been great I also

00:00:15,250 --> 00:00:18,820
am suffering a little bit from jet lag

00:00:16,750 --> 00:00:20,590
so I'm trying to get myself up a bit

00:00:18,820 --> 00:00:23,170
here to make sure that I'm gonna do

00:00:20,590 --> 00:00:24,369
justice to the material so I'm an

00:00:23,170 --> 00:00:26,290
engineer at sisty egg

00:00:24,369 --> 00:00:28,810
if you haven't heard of us we make a

00:00:26,290 --> 00:00:30,849
security and monitoring platform and our

00:00:28,810 --> 00:00:33,100
tagline is that our goal is to help

00:00:30,849 --> 00:00:37,180
users confidently run cloud native

00:00:33,100 --> 00:00:38,470
workloads so recently myself and it's a

00:00:37,180 --> 00:00:41,350
few engineers that are here have been

00:00:38,470 --> 00:00:43,750
working to add support for prom ql into

00:00:41,350 --> 00:00:45,309
our existing monitoring platform and I

00:00:43,750 --> 00:00:47,170
wanted to share a little bit about what

00:00:45,309 --> 00:00:49,539
we've learned about prompt well and the

00:00:47,170 --> 00:00:52,059
Prometheus data model and supporting the

00:00:49,539 --> 00:00:53,350
Prometheus remote read API so I need to

00:00:52,059 --> 00:01:07,090
give you a little bit of information

00:00:53,350 --> 00:01:08,560
about the system there we go so so

00:01:07,090 --> 00:01:11,110
assistance monitoring platform looks

00:01:08,560 --> 00:01:13,030
like this we have a software agent that

00:01:11,110 --> 00:01:15,250
runs on a host and a gathers date about

00:01:13,030 --> 00:01:17,380
this system and about the processes and

00:01:15,250 --> 00:01:19,630
containers that run on the system and

00:01:17,380 --> 00:01:21,880
then include system level info like CPU

00:01:19,630 --> 00:01:24,189
usage and memory usage but we also

00:01:21,880 --> 00:01:25,570
collect metrics from any applications

00:01:24,189 --> 00:01:29,560
that are running there and that includes

00:01:25,570 --> 00:01:31,570
JMX stat Z and of course Prometheus well

00:01:29,560 --> 00:01:33,820
the agent gathers this data and then

00:01:31,570 --> 00:01:35,799
pushes it up to our back in and we

00:01:33,820 --> 00:01:37,360
gather data roughly every 10 seconds we

00:01:35,799 --> 00:01:40,420
typically push it up to the back and

00:01:37,360 --> 00:01:42,250
immediately after we gather it so in our

00:01:40,420 --> 00:01:44,049
back end it's stored there both in the

00:01:42,250 --> 00:01:46,149
original form that we collected but we

00:01:44,049 --> 00:01:49,780
also down sample the data to make large

00:01:46,149 --> 00:01:52,149
queries more efficient so in our back in

00:01:49,780 --> 00:01:53,979
then users can view in slice that data

00:01:52,149 --> 00:01:56,049
in lots of different ways per cluster

00:01:53,979 --> 00:01:57,670
per deployment we do things like

00:01:56,049 --> 00:02:00,219
supporting our backs so if you're a user

00:01:57,670 --> 00:02:01,420
you have a very specific interest slice

00:02:00,219 --> 00:02:03,549
of the infrastructure that you could

00:02:01,420 --> 00:02:04,659
look at it any kind of time so we have a

00:02:03,549 --> 00:02:06,430
lot of features and we have like

00:02:04,659 --> 00:02:08,860
customers that like what we do however

00:02:06,430 --> 00:02:11,230
what we can't do today is that we can't

00:02:08,860 --> 00:02:14,050
perform arbitrary math operations on the

00:02:11,230 --> 00:02:16,780
data so hence that's why we wanted to

00:02:14,050 --> 00:02:19,599
add prompt well support and specifically

00:02:16,780 --> 00:02:22,599
we wanted to support the Prometheus HTTP

00:02:19,599 --> 00:02:23,170
API so that in our own UI inside the

00:02:22,599 --> 00:02:25,840
Cystic you

00:02:23,170 --> 00:02:27,220
we can make calls to that API but also

00:02:25,840 --> 00:02:30,010
our customers can use other

00:02:27,220 --> 00:02:32,110
visualization tools like Ravana and that

00:02:30,010 --> 00:02:34,270
API will connect to a prompt ul engine

00:02:32,110 --> 00:02:37,450
that uses the prom cue evaluation code

00:02:34,270 --> 00:02:39,550
from Prometheus the prom cue evaluation

00:02:37,450 --> 00:02:42,010
engine that we have named the prom cue

00:02:39,550 --> 00:02:45,550
later will talk with our data store via

00:02:42,010 --> 00:02:47,500
the remote read API so let's look at

00:02:45,550 --> 00:02:51,580
some examples of what prompt to L asks

00:02:47,500 --> 00:02:54,010
from the storage later we go so here's

00:02:51,580 --> 00:02:56,980
an example this is a range query from t0

00:02:54,010 --> 00:03:00,730
to t1 over a 10 second step and it asks

00:02:56,980 --> 00:03:03,459
for instances 7 that have been up so

00:03:00,730 --> 00:03:05,380
what the storage layer sees and prompt

00:03:03,459 --> 00:03:06,730
well parses and sends a request on it's

00:03:05,380 --> 00:03:08,530
something that looks like this there's a

00:03:06,730 --> 00:03:11,260
set of label matches where the name is

00:03:08,530 --> 00:03:13,380
up the end equals prod and then there's

00:03:11,260 --> 00:03:16,090
a request time and if you look closely

00:03:13,380 --> 00:03:19,540
you will see that very interesting ly

00:03:16,090 --> 00:03:21,519
the start time is not t0 its t0 minus 5

00:03:19,540 --> 00:03:23,739
minutes so the first question I'm going

00:03:21,519 --> 00:03:25,930
to talk about the topic I'll talk about

00:03:23,739 --> 00:03:27,250
is where what is it asked for this extra

00:03:25,930 --> 00:03:28,959
5 minutes and what does it mean for

00:03:27,250 --> 00:03:30,070
people like us that are trying to make

00:03:28,959 --> 00:03:33,310
prompt you all work with something

00:03:30,070 --> 00:03:35,350
dissing data a second example here it's

00:03:33,310 --> 00:03:36,820
again another range query and this time

00:03:35,350 --> 00:03:39,190
it's running a rate over a specific

00:03:36,820 --> 00:03:41,079
metric and if you look at what the

00:03:39,190 --> 00:03:43,180
storage layer sees out of that request

00:03:41,079 --> 00:03:45,310
you see the name matching this time you

00:03:43,180 --> 00:03:47,530
see the start and end times t0 and t1

00:03:45,310 --> 00:03:49,630
that actually match up but then you also

00:03:47,530 --> 00:03:52,630
see this other interesting section

00:03:49,630 --> 00:03:54,670
called read hence so the second and

00:03:52,630 --> 00:03:56,860
third topics I'll talk about are what's

00:03:54,670 --> 00:03:59,230
a func hit right why is that information

00:03:56,860 --> 00:04:01,180
being passed along and then what does

00:03:59,230 --> 00:04:02,920
rate me like why is that passed long and

00:04:01,180 --> 00:04:04,840
what's the implication for this orange

00:04:02,920 --> 00:04:08,470
layer to respond okay so let's talk

00:04:04,840 --> 00:04:11,950
first about the five minutes as you know

00:04:08,470 --> 00:04:14,140
the Prometheus scrapes scrapes target's

00:04:11,950 --> 00:04:15,970
obtain samples and stores results as

00:04:14,140 --> 00:04:18,850
sets of time-series identified by

00:04:15,970 --> 00:04:22,300
different labels and so this is the

00:04:18,850 --> 00:04:23,919
Prometheus storage storage model now for

00:04:22,300 --> 00:04:25,930
each job samples should be roughly a

00:04:23,919 --> 00:04:27,760
scrape interval apart but that varies

00:04:25,930 --> 00:04:29,650
depending on the response time of the

00:04:27,760 --> 00:04:31,539
target the system load network

00:04:29,650 --> 00:04:33,910
conditions and so forth and even if

00:04:31,539 --> 00:04:35,410
targets have the same scraping interval

00:04:33,910 --> 00:04:37,090
they'll have different starting points

00:04:35,410 --> 00:04:39,040
so there are lots of reasons

00:04:37,090 --> 00:04:40,630
the time series in your store have

00:04:39,040 --> 00:04:43,600
samples that don't line up with each

00:04:40,630 --> 00:04:46,000
other so this has an impact to how

00:04:43,600 --> 00:04:47,470
prompt well evaluates data appears so

00:04:46,000 --> 00:04:51,250
let's talk through the two data queries

00:04:47,470 --> 00:04:53,500
that you can do in prams well and there

00:04:51,250 --> 00:04:56,170
is the instant query which says given

00:04:53,500 --> 00:04:58,930
some prompt expression evaluated at one

00:04:56,170 --> 00:05:00,850
point in time and there's a range query

00:04:58,930 --> 00:05:03,250
which takes a start you're gonna step it

00:05:00,850 --> 00:05:05,680
in and it evaluates the expression you

00:05:03,250 --> 00:05:07,780
give it at each step along the way and a

00:05:05,680 --> 00:05:10,620
range query logically just works like

00:05:07,780 --> 00:05:13,060
it's a sequence of instant queries in

00:05:10,620 --> 00:05:14,740
either case you know consider what

00:05:13,060 --> 00:05:16,720
happens if you try to evaluate a prompt

00:05:14,740 --> 00:05:18,880
you'll expression that references a time

00:05:16,720 --> 00:05:22,330
series and there's no sample at the

00:05:18,880 --> 00:05:23,950
evaluation time so what happens well it

00:05:22,330 --> 00:05:25,750
depends on how you reference the series

00:05:23,950 --> 00:05:29,110
there are again two ways that this could

00:05:25,750 --> 00:05:30,940
happen one is by the range vector

00:05:29,110 --> 00:05:33,700
selector and that's the syntax you'll

00:05:30,940 --> 00:05:36,160
recognize with brackets it's prompt well

00:05:33,700 --> 00:05:38,980
we'll look at the duration that you

00:05:36,160 --> 00:05:40,630
specify and then use the sample starting

00:05:38,980 --> 00:05:43,330
from that duration before in the

00:05:40,630 --> 00:05:45,370
evaluation time and then it takes those

00:05:43,330 --> 00:05:47,110
those samples is input and feeds it into

00:05:45,370 --> 00:05:50,740
some whatever function you're specifying

00:05:47,110 --> 00:05:52,450
this range vector selector - and then

00:05:50,740 --> 00:05:55,210
there's the instant vector selector and

00:05:52,450 --> 00:05:57,580
as the name suggests it's looking for a

00:05:55,210 --> 00:05:59,980
value at a particular instant okay but

00:05:57,580 --> 00:06:03,100
chances are there won't be one just

00:05:59,980 --> 00:06:06,630
because of how your samples line up so

00:06:03,100 --> 00:06:09,550
then what is prompt well do in this case

00:06:06,630 --> 00:06:11,860
well what it does is it looks for the

00:06:09,550 --> 00:06:14,500
most recent value found at or before

00:06:11,860 --> 00:06:16,630
that evaluation time right so in this

00:06:14,500 --> 00:06:18,520
case they'll go back in time find the

00:06:16,630 --> 00:06:20,650
sample that was closest to your

00:06:18,520 --> 00:06:23,380
evaluation moment take its value and

00:06:20,650 --> 00:06:27,280
then act as if that value occurred at

00:06:23,380 --> 00:06:30,280
the evaluation isn't like I said instant

00:06:27,280 --> 00:06:31,510
queries are just rain and senator range

00:06:30,280 --> 00:06:33,730
queries are just instant queries

00:06:31,510 --> 00:06:36,250
repeated over time so the same logic

00:06:33,730 --> 00:06:38,170
applies at each step right so if you do

00:06:36,250 --> 00:06:39,730
some range preferencing lots of series

00:06:38,170 --> 00:06:43,390
we'll just go and find the most recent

00:06:39,730 --> 00:06:44,980
value and push it forward and the

00:06:43,390 --> 00:06:47,800
benefit of this is that it lets prompt

00:06:44,980 --> 00:06:49,569
well work with aligned values between

00:06:47,800 --> 00:06:51,129
samples so you can

00:06:49,569 --> 00:06:52,779
you set for your calculations or for

00:06:51,129 --> 00:06:55,960
comparisons as you interact with the

00:06:52,779 --> 00:06:58,689
different series that are there so maybe

00:06:55,960 --> 00:07:00,550
you're wondering well how far back does

00:06:58,689 --> 00:07:02,770
it look I mean they're phrased

00:07:00,550 --> 00:07:04,830
differently you know how long do you see

00:07:02,770 --> 00:07:07,749
the value of the last sample

00:07:04,830 --> 00:07:09,459
well it's controlled in again two

00:07:07,749 --> 00:07:12,610
different ways this seems to be a

00:07:09,459 --> 00:07:14,619
repeating pattern for prompt you all so

00:07:12,610 --> 00:07:16,270
the first way is via something called a

00:07:14,619 --> 00:07:18,669
configuration setting in your Prometheus

00:07:16,270 --> 00:07:20,259
server called look-back Delta can I just

00:07:18,669 --> 00:07:21,399
get a show of hands who here knows about

00:07:20,259 --> 00:07:23,979
this like who's here is actually

00:07:21,399 --> 00:07:25,270
configure this ok great I'm glad I'm

00:07:23,979 --> 00:07:30,399
glad it's not everyone that I'm like oh

00:07:25,270 --> 00:07:33,430
this is so fascinating so ok so the

00:07:30,399 --> 00:07:35,559
default value this is five minutes and

00:07:33,430 --> 00:07:37,569
this is where that five that extra

00:07:35,559 --> 00:07:40,599
five-minute request came from here in

00:07:37,569 --> 00:07:42,909
the storage layer request so and again

00:07:40,599 --> 00:07:44,800
same logic for range queries so what

00:07:42,909 --> 00:07:47,740
this means is that if you do a range

00:07:44,800 --> 00:07:49,179
query and the alignment logic says that

00:07:47,740 --> 00:07:51,999
it's gonna use to look back Delta

00:07:49,179 --> 00:07:54,669
process to find to find a value you can

00:07:51,999 --> 00:07:56,469
see this odd-looking repeat of the value

00:07:54,669 --> 00:07:59,830
across a straight line for five minutes

00:07:56,469 --> 00:08:01,839
and consider what this means for alerts

00:07:59,830 --> 00:08:03,459
right so if you had an alert that was

00:08:01,839 --> 00:08:05,439
supposed to fire if there was no value

00:08:03,459 --> 00:08:07,119
for a series you know something like

00:08:05,439 --> 00:08:08,949
alert me if there are no application

00:08:07,119 --> 00:08:10,629
instances you would be waiting five

00:08:08,949 --> 00:08:12,129
minutes before that was actually noticed

00:08:10,629 --> 00:08:13,629
right because your evaluation would just

00:08:12,129 --> 00:08:16,749
keep saying but yes it looks like it's

00:08:13,629 --> 00:08:18,369
it's up okay so chances are you have not

00:08:16,749 --> 00:08:20,079
noticed this five minute delay right in

00:08:18,369 --> 00:08:22,659
your alert processing so what else is

00:08:20,079 --> 00:08:24,309
going on well the second way the prompt

00:08:22,659 --> 00:08:26,409
co-manages sprayed samples is with

00:08:24,309 --> 00:08:28,899
something called as stale markers who

00:08:26,409 --> 00:08:32,259
hears heard about stale markers all

00:08:28,899 --> 00:08:33,909
right about a third I think in terms of

00:08:32,259 --> 00:08:36,699
people they're looking at so during

00:08:33,909 --> 00:08:38,349
scraping if a series isn't seen after

00:08:36,699 --> 00:08:40,479
some scrape interval then the scraping

00:08:38,349 --> 00:08:42,519
logic adds a special sample called a

00:08:40,479 --> 00:08:45,339
stale marker it's encoded with a special

00:08:42,519 --> 00:08:47,290
floating-point value of stale man and if

00:08:45,339 --> 00:08:49,380
prompt ghost sees this value it won't

00:08:47,290 --> 00:08:52,420
try to create those extra values after

00:08:49,380 --> 00:08:54,459
after the sale marker occurs so it's not

00:08:52,420 --> 00:08:56,529
like a permanent tombstone that you

00:08:54,459 --> 00:08:58,209
might think about works like a sandra

00:08:56,529 --> 00:09:00,069
right it can appear multiple times

00:08:58,209 --> 00:09:02,470
throughout the time series just based on

00:09:00,069 --> 00:09:04,090
if the target the instance

00:09:02,470 --> 00:09:08,290
created series comes up goes down comes

00:09:04,090 --> 00:09:10,990
up goes so this marker is never seen

00:09:08,290 --> 00:09:13,360
directly by users of prompt well and

00:09:10,990 --> 00:09:15,340
prompt well ignores this marker for

00:09:13,360 --> 00:09:17,110
anything except this very specific usage

00:09:15,340 --> 00:09:20,590
of finding out what value use of the

00:09:17,110 --> 00:09:22,300
evaluation time so what does this mean

00:09:20,590 --> 00:09:23,680
for us are you for assisting or for

00:09:22,300 --> 00:09:25,660
people that are embedding prompt well in

00:09:23,680 --> 00:09:27,610
front of other data well it matters for

00:09:25,660 --> 00:09:29,080
us because we have data that did not

00:09:27,610 --> 00:09:31,570
originally come in via Prometheus

00:09:29,080 --> 00:09:33,820
phrasing so we need to ensure that there

00:09:31,570 --> 00:09:35,860
were the read responses we give back to

00:09:33,820 --> 00:09:37,420
prompt well have the sale markers we're

00:09:35,860 --> 00:09:39,880
needed to make sure that users see the

00:09:37,420 --> 00:09:41,440
same type of graphs and the same type of

00:09:39,880 --> 00:09:43,840
alerts that they would see with with

00:09:41,440 --> 00:09:45,490
Prometheus so since we're adding this

00:09:43,840 --> 00:09:47,830
functionality you to our existing

00:09:45,490 --> 00:09:49,390
systems ones that already have data we

00:09:47,830 --> 00:09:51,640
have to do a mix of actions here where

00:09:49,390 --> 00:09:53,950
for some metrics will add sale markers

00:09:51,640 --> 00:09:56,260
that we as we gather them from sources

00:09:53,950 --> 00:09:58,210
like Prometheus metrics but for other

00:09:56,260 --> 00:09:59,800
metrics like those that already exist in

00:09:58,210 --> 00:10:02,640
a customer's data store will have to

00:09:59,800 --> 00:10:05,290
dynamically add them in that query time

00:10:02,640 --> 00:10:07,300
okay so coming back to our questions so

00:10:05,290 --> 00:10:09,130
now we know why the prompt will ask that

00:10:07,300 --> 00:10:10,810
extra five minutes of time before the

00:10:09,130 --> 00:10:13,420
search so let's go on to the second

00:10:10,810 --> 00:10:15,610
question here why does prompt well send

00:10:13,420 --> 00:10:18,370
this ask for our send a hint here called

00:10:15,610 --> 00:10:20,710
funk well the answer has to do with down

00:10:18,370 --> 00:10:22,810
sandwich so again show of hands who here

00:10:20,710 --> 00:10:24,370
uses a down sampling system presumably

00:10:22,810 --> 00:10:26,920
probably Santos in this room but maybe

00:10:24,370 --> 00:10:30,550
sis dig here so okay not a lot of folks

00:10:26,920 --> 00:10:32,320
here well think of it this way right so

00:10:30,550 --> 00:10:34,330
let's say you scrape the series once

00:10:32,320 --> 00:10:36,040
every minute which i think makes sense

00:10:34,330 --> 00:10:37,980
scraping intervals i think are typically

00:10:36,040 --> 00:10:40,780
in the order of a minute or maybe less

00:10:37,980 --> 00:10:43,200
if you want to graph that data over a

00:10:40,780 --> 00:10:47,560
month right for each sample that's about

00:10:43,200 --> 00:10:49,630
45,000 samples that's likely more pixels

00:10:47,560 --> 00:10:52,480
than you actually have on your display

00:10:49,630 --> 00:10:54,460
right so why pay the resource cost in

00:10:52,480 --> 00:10:56,980
terms of the CPU to evaluate expression

00:10:54,460 --> 00:10:58,540
and the i/o to load all that data when

00:10:56,980 --> 00:11:02,200
most of them won't make a difference to

00:10:58,540 --> 00:11:05,410
what you actually see so what you can do

00:11:02,200 --> 00:11:07,870
is instead instead of using the data

00:11:05,410 --> 00:11:09,790
directly you can store an aggregation of

00:11:07,870 --> 00:11:12,190
those scrape samples so you break up

00:11:09,790 --> 00:11:14,710
your samples into windows a time like

00:11:12,190 --> 00:11:16,330
five minutes or hour or whatever value

00:11:14,710 --> 00:11:18,310
you want and you store some

00:11:16,330 --> 00:11:19,780
representative value of all the data

00:11:18,310 --> 00:11:21,940
that occurred within that window and

00:11:19,780 --> 00:11:24,130
then you use this aggregated data

00:11:21,940 --> 00:11:25,810
instead of the raw to give you answers

00:11:24,130 --> 00:11:27,940
that are close enough for many use cases

00:11:25,810 --> 00:11:30,460
and I can serve resources at the same

00:11:27,940 --> 00:11:32,530
time so if you do this what

00:11:30,460 --> 00:11:35,050
representation should you store right

00:11:32,530 --> 00:11:37,300
within that window I mean you can

00:11:35,050 --> 00:11:39,010
obviously go calculate an average which

00:11:37,300 --> 00:11:40,720
might work for many cases but as we

00:11:39,010 --> 00:11:42,100
heard kind of Max is very important

00:11:40,720 --> 00:11:44,440
especially if you're looking for a peak

00:11:42,100 --> 00:11:47,260
usage so maybe you'd also want to store

00:11:44,440 --> 00:11:49,270
the maximum value instead and you can

00:11:47,260 --> 00:11:50,830
come up with lots of other use cases

00:11:49,270 --> 00:11:52,930
where you really want more than one

00:11:50,830 --> 00:11:54,790
representation because you want data to

00:11:52,930 --> 00:11:58,810
specialize for a particular type of

00:11:54,790 --> 00:12:00,520
query so there's no constraint to only

00:11:58,810 --> 00:12:01,780
store a single one of these aggregations

00:12:00,520 --> 00:12:03,580
right because we're not doing this to

00:12:01,780 --> 00:12:05,860
save on storage costs we're doing to

00:12:03,580 --> 00:12:09,280
reduce the cost of these large wide

00:12:05,860 --> 00:12:11,200
queries so now if you store multiple of

00:12:09,280 --> 00:12:13,960
these aggregations how do you know which

00:12:11,200 --> 00:12:16,210
one to use well that's what the hint is

00:12:13,960 --> 00:12:18,910
for right the hint when prompt well

00:12:16,210 --> 00:12:20,230
makes a request to to this for a

00:12:18,910 --> 00:12:22,150
particular series of the storage layer

00:12:20,230 --> 00:12:23,890
it looks at the function or the

00:12:22,150 --> 00:12:25,780
aggregation that surrounds that

00:12:23,890 --> 00:12:27,160
reference and then it sings that along

00:12:25,780 --> 00:12:29,740
as a head it's actually called the

00:12:27,160 --> 00:12:31,750
surrounding function it and then down

00:12:29,740 --> 00:12:33,820
sampling systems like Thanos or Cystic

00:12:31,750 --> 00:12:35,980
can use this hint to select which

00:12:33,820 --> 00:12:38,260
aggregation to use to satisfy the

00:12:35,980 --> 00:12:40,870
request so if the surrounding function

00:12:38,260 --> 00:12:43,330
was max over time we use the max

00:12:40,870 --> 00:12:45,700
aggregation for example so hopefully

00:12:43,330 --> 00:12:48,250
that makes sense so then to the last

00:12:45,700 --> 00:12:50,260
question well what about this rate hint

00:12:48,250 --> 00:12:53,650
so what kind of aggregation would you

00:12:50,260 --> 00:12:55,390
use to satisfy a rate hint okay to

00:12:53,650 --> 00:12:57,130
answer that we need to understand

00:12:55,390 --> 00:13:00,760
counters and we need to understand the

00:12:57,130 --> 00:13:02,940
rate function a counter is pretty simple

00:13:00,760 --> 00:13:06,430
it tracks the occurrence of an event

00:13:02,940 --> 00:13:08,650
weight it starts at 0 and increases from

00:13:06,430 --> 00:13:10,660
there or until something happens and

00:13:08,650 --> 00:13:17,590
then it resets and then it starts over

00:13:10,660 --> 00:13:19,780
again at 0 soon so here's an example

00:13:17,590 --> 00:13:21,690
counter series from premedia for

00:13:19,780 --> 00:13:24,040
previously each of these values is

00:13:21,690 --> 00:13:26,050
represents the number of events since

00:13:24,040 --> 00:13:28,810
that moment from the start of the time

00:13:26,050 --> 00:13:30,100
series or from the latest reset any

00:13:28,810 --> 00:13:32,440
decreasing value

00:13:30,100 --> 00:13:33,910
here is interpreted as a reset since we

00:13:32,440 --> 00:13:36,610
may not actually sample the counter

00:13:33,910 --> 00:13:38,470
right with the zero occurs and resets

00:13:36,610 --> 00:13:41,019
happen as I said because application

00:13:38,470 --> 00:13:42,339
instances may come up go down to come up

00:13:41,019 --> 00:13:43,899
crash go down and come back up

00:13:42,339 --> 00:13:45,970
right so you just see these resets over

00:13:43,899 --> 00:13:48,699
time

00:13:45,970 --> 00:13:51,850
the rate function in prompt well looks

00:13:48,699 --> 00:13:53,980
is it's the most common usage we talk

00:13:51,850 --> 00:13:55,810
about four four counters and rate

00:13:53,980 --> 00:13:58,089
divides the change in the number of

00:13:55,810 --> 00:14:00,940
events by the change in time over some

00:13:58,089 --> 00:14:02,470
interval so what you really need since

00:14:00,940 --> 00:14:04,029
getting the difference in time is pretty

00:14:02,470 --> 00:14:05,589
straightforward the tricky bit is

00:14:04,029 --> 00:14:07,720
finding the difference in the number of

00:14:05,589 --> 00:14:10,209
events so how does rate do this to

00:14:07,720 --> 00:14:11,649
calculate the difference in events well

00:14:10,209 --> 00:14:13,180
if you look at a section where there's

00:14:11,649 --> 00:14:15,790
no resets it's pretty straight forward

00:14:13,180 --> 00:14:17,620
you can sum up all the deltas between

00:14:15,790 --> 00:14:19,329
the samples so you just look at the

00:14:17,620 --> 00:14:21,639
difference between one the first and a

00:14:19,329 --> 00:14:24,850
second add that to your sum and then you

00:14:21,639 --> 00:14:26,410
keep doing this all the way along to get

00:14:24,850 --> 00:14:30,040
the difference between the last value

00:14:26,410 --> 00:14:32,410
and the first if you have a reset there

00:14:30,040 --> 00:14:34,240
you add the post reset value and that's

00:14:32,410 --> 00:14:36,069
because that reset again represents some

00:14:34,240 --> 00:14:38,910
number events since a zero that occurred

00:14:36,069 --> 00:14:41,430
in this case they didn't necessarily see

00:14:38,910 --> 00:14:43,569
so you add up all those values and

00:14:41,430 --> 00:14:45,009
effectively I like to think about this

00:14:43,569 --> 00:14:47,019
you just transform in this series by

00:14:45,009 --> 00:14:48,670
sliding up everything after each reset

00:14:47,019 --> 00:14:50,889
and if you look at kind of these high

00:14:48,670 --> 00:14:52,089
level values again if you want to get

00:14:50,889 --> 00:14:54,430
the difference in events you can just

00:14:52,089 --> 00:14:56,880
subtract the first value from the last

00:14:54,430 --> 00:14:59,500
value and that tells you the difference

00:14:56,880 --> 00:15:02,230
so what kind of aggregation would you

00:14:59,500 --> 00:15:04,209
need for rate so immediately you can

00:15:02,230 --> 00:15:05,470
know that average won't work

00:15:04,209 --> 00:15:07,240
average won't work because you'd

00:15:05,470 --> 00:15:09,040
probably lose some resets just depending

00:15:07,240 --> 00:15:10,300
on the data that actually occurred so

00:15:09,040 --> 00:15:13,120
let's walk through a simple example of

00:15:10,300 --> 00:15:16,329
just comparing two windows so how many

00:15:13,120 --> 00:15:18,220
events occurred between t1 and t2 well

00:15:16,329 --> 00:15:19,959
first thing we can think about here is

00:15:18,220 --> 00:15:21,130
that what we really want really asking

00:15:19,959 --> 00:15:23,740
is the difference in events between the

00:15:21,130 --> 00:15:26,649
last value in t1 and the last value in

00:15:23,740 --> 00:15:29,430
t2 right the the events before the last

00:15:26,649 --> 00:15:32,589
one and t1 don't make a difference just

00:15:29,430 --> 00:15:34,810
get rid of those and with the value set

00:15:32,589 --> 00:15:36,639
your left then you can now calculate the

00:15:34,810 --> 00:15:39,699
difference in events just accounting for

00:15:36,639 --> 00:15:41,949
resets and you do the same process that

00:15:39,699 --> 00:15:43,900
I mentioned before slide them all up and

00:15:41,949 --> 00:15:45,010
then sum up the values that you

00:15:43,900 --> 00:15:47,710
have them there to actually get that

00:15:45,010 --> 00:15:48,940
last that last value and again if you'll

00:15:47,710 --> 00:15:50,590
notice what's happening here it's a

00:15:48,940 --> 00:15:52,900
little hard to I think see your peers

00:15:50,590 --> 00:15:56,200
it's your summing up all the values that

00:15:52,900 --> 00:15:58,300
occurred within the t two window and if

00:15:56,200 --> 00:16:00,820
you store that sum that's what you

00:15:58,300 --> 00:16:05,080
actually mean to effectively perform the

00:16:00,820 --> 00:16:07,570
rate calculation so in this case we just

00:16:05,080 --> 00:16:09,610
needed the last raw value of the window

00:16:07,570 --> 00:16:11,860
before and the sum of the events in the

00:16:09,610 --> 00:16:13,870
window we're looking at now and with

00:16:11,860 --> 00:16:15,310
just this you can now subtract those two

00:16:13,870 --> 00:16:18,100
and you've got the difference in number

00:16:15,310 --> 00:16:19,780
of s which is exactly what rate needs so

00:16:18,100 --> 00:16:23,170
the point here is look at the last raw

00:16:19,780 --> 00:16:24,820
value look to some of the events but

00:16:23,170 --> 00:16:26,980
that's not all you need so let's walk

00:16:24,820 --> 00:16:29,800
through one more example so let's do

00:16:26,980 --> 00:16:31,420
this case where you go from t3 to t4 we

00:16:29,800 --> 00:16:32,980
can do the same thing right only the

00:16:31,420 --> 00:16:34,810
last value material really makes a

00:16:32,980 --> 00:16:37,660
difference we can sum up everything that

00:16:34,810 --> 00:16:39,550
occurred in t4 and now you would think

00:16:37,660 --> 00:16:41,740
well can you just subtract the

00:16:39,550 --> 00:16:44,260
difference from the last value the last

00:16:41,740 --> 00:16:47,680
some you calculate in t4 to the last one

00:16:44,260 --> 00:16:49,480
and t3 and the answer is you cannot you

00:16:47,680 --> 00:16:51,730
cannot because there was a reset that

00:16:49,480 --> 00:16:53,740
occurred between t3 and t4 right and so

00:16:51,730 --> 00:16:55,120
what that means is that just the events

00:16:53,740 --> 00:16:57,910
and t4 actually make a difference

00:16:55,120 --> 00:17:01,810
so to summarize here what we said is

00:16:57,910 --> 00:17:02,860
like we need is you need the sum you can

00:17:01,810 --> 00:17:04,690
go through all of your all of your

00:17:02,860 --> 00:17:07,089
samples and you need the sum of the

00:17:04,690 --> 00:17:09,010
events in the window the first raw value

00:17:07,089 --> 00:17:10,630
and the last raw value and you need

00:17:09,010 --> 00:17:12,310
those raw values because you need to be

00:17:10,630 --> 00:17:16,030
able to recognize one counter resets

00:17:12,310 --> 00:17:17,560
occur and that gives you the information

00:17:16,030 --> 00:17:19,120
you need to calculate the difference in

00:17:17,560 --> 00:17:21,220
events between windows which is great

00:17:19,120 --> 00:17:22,839
but that's not exactly what prompt you

00:17:21,220 --> 00:17:25,240
will ask for it actually asks for a

00:17:22,839 --> 00:17:26,950
series of values over time so we need to

00:17:25,240 --> 00:17:29,440
turn this into a into a response so we

00:17:26,950 --> 00:17:32,050
can get back to prompt well and the way

00:17:29,440 --> 00:17:34,000
this works at least a notice is that it

00:17:32,050 --> 00:17:36,760
looks at the data that was stored off of

00:17:34,000 --> 00:17:38,440
that aggregation and it constructs by

00:17:36,760 --> 00:17:41,770
adding up these differences over time

00:17:38,440 --> 00:17:43,900
this really nice monotonically

00:17:41,770 --> 00:17:46,120
increasing value that goes up in time

00:17:43,900 --> 00:17:47,710
with no resets and this is exactly what

00:17:46,120 --> 00:17:49,330
prompt well watts right you could handle

00:17:47,710 --> 00:17:51,250
the resets if it needed to but it's now

00:17:49,330 --> 00:17:52,510
giving it exactly the values it needs so

00:17:51,250 --> 00:17:56,080
the prompt well can look at the

00:17:52,510 --> 00:17:57,639
difference between those two so that's

00:17:56,080 --> 00:17:59,619
so that was last question ret

00:17:57,639 --> 00:18:01,179
rate with downsampled data you need

00:17:59,619 --> 00:18:03,219
something like a specialized counter

00:18:01,179 --> 00:18:04,570
aggregation in order to make sure that

00:18:03,219 --> 00:18:06,099
you're giving the correct and accurate

00:18:04,570 --> 00:18:09,009
answers back when you look at down

00:18:06,099 --> 00:18:10,779
sample data and then how this matters to

00:18:09,009 --> 00:18:12,190
us is that well we need to make sure we

00:18:10,779 --> 00:18:13,869
support that specialized counter

00:18:12,190 --> 00:18:15,700
aggregation and of course we'll do this

00:18:13,869 --> 00:18:17,919
for Prometheus metrics but very

00:18:15,700 --> 00:18:19,539
interestingly again since we have data

00:18:17,919 --> 00:18:21,429
that did not come out of Prometheus we

00:18:19,539 --> 00:18:23,289
can now use similar techniques for other

00:18:21,429 --> 00:18:25,419
non Prometheus data in our system and

00:18:23,289 --> 00:18:27,309
that means that users can use rate even

00:18:25,419 --> 00:18:28,809
with non Prometheus data because we know

00:18:27,309 --> 00:18:30,339
exactly how to represent it to crops

00:18:28,809 --> 00:18:34,119
well to make sure that it gets accurate

00:18:30,339 --> 00:18:35,709
answers so that's it I hope that like

00:18:34,119 --> 00:18:37,179
that little like pouring into like

00:18:35,709 --> 00:18:39,789
Cromwell and the Prometheus data models

00:18:37,179 --> 00:18:41,320
been interesting I'll be happy to take

00:18:39,789 --> 00:18:49,899
any questions about what we've been

00:18:41,320 --> 00:18:58,899
working on Thanks are you who wants to

00:18:49,899 --> 00:19:05,379
box what was the bug with you discovered

00:18:58,899 --> 00:19:07,299
in Tanner's this the boundary line reset

00:19:05,379 --> 00:19:08,950
right so that it was just a matter of

00:19:07,299 --> 00:19:12,070
like we need to store you need to store

00:19:08,950 --> 00:19:13,779
the first raw value - thank you and

00:19:12,070 --> 00:19:18,339
thanks to Alexander my colleague who

00:19:13,779 --> 00:19:20,349
spotted this problem I just want yeah

00:19:18,339 --> 00:19:26,229
Thomas was storing the last value but

00:19:20,349 --> 00:19:28,179
not the first retire - have there been

00:19:26,229 --> 00:19:32,349
any prom cool expressions that were hard

00:19:28,179 --> 00:19:34,389
for you to prom kool-aid or that you

00:19:32,349 --> 00:19:37,059
think it might be hard to translate did

00:19:34,389 --> 00:19:38,649
to translate it for what we think not

00:19:37,059 --> 00:19:39,909
yet the counter is definitely like the

00:19:38,649 --> 00:19:41,679
one that just what are some more spot

00:19:39,909 --> 00:19:43,419
the most often thinking I mean an

00:19:41,679 --> 00:19:45,039
advantage of what we're doing we really

00:19:43,419 --> 00:19:48,070
are taking the exact prompt well code

00:19:45,039 --> 00:19:50,859
right using just creating a service out

00:19:48,070 --> 00:19:52,719
of that it supports a storage

00:19:50,859 --> 00:19:54,249
abstraction that's there the abstraction

00:19:52,719 --> 00:19:55,929
layers within Prometheus are really nice

00:19:54,249 --> 00:19:58,209
so it's actually pretty easy to work

00:19:55,929 --> 00:20:00,029
with and do this cool any other

00:19:58,209 --> 00:20:03,530
questions

00:20:00,029 --> 00:20:06,970
okay well I guess thank you very much

00:20:03,530 --> 00:20:16,690
[Applause]

00:20:06,970 --> 00:20:16,690

YouTube URL: https://www.youtube.com/watch?v=_asWX7RL2mg


