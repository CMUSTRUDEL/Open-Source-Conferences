Title: Mozilla's DeepSpeech and Common Voice projects
Publication date: 2018-02-23
Playlist: Mozilla at FOSDEM 2018
Description: 
	Open and offline-capable voice recognition for everyone

Presented by Tilman Kamp. 

First presented at FOSDEM, Feb 3, 2018. 
(https://fosdem.org/2018/schedule/event/mozilla_deepspeech_common_voice_projects/)

These talks have been recorded at FOSDEM (https://fosdem.org/) This work is licensed under the Creative Commons Attribution 2.0 Belgium Licence. To view a copy of this licence, visit:
https://creativecommons.org/licenses/by/2.0/be/deed.en
Captions: 
	00:00:05,030 --> 00:00:10,260
presentation was originally planned for

00:00:07,920 --> 00:00:12,720
one hour I had to compress stuff and do

00:00:10,260 --> 00:00:14,790
some tricks and these tricks work at

00:00:12,720 --> 00:00:17,369
best when you actually prepare also for

00:00:14,790 --> 00:00:20,189
yourself by properly opening that the

00:00:17,369 --> 00:00:21,930
link that I put there on the screen to

00:00:20,189 --> 00:00:23,970
actually be able to follow that because

00:00:21,930 --> 00:00:26,789
at the beginning the light was not bad

00:00:23,970 --> 00:00:28,830
idea on so looking at that screen was

00:00:26,789 --> 00:00:31,199
not that perfect experience so however

00:00:28,830 --> 00:00:34,410
let's start so like there's a lot of

00:00:31,199 --> 00:00:37,230
talk about deep speech recently and I

00:00:34,410 --> 00:00:39,270
just want to present here more like a

00:00:37,230 --> 00:00:41,930
users and developers perspective not

00:00:39,270 --> 00:00:44,969
that much machine learners and

00:00:41,930 --> 00:00:46,670
scientists perspective more like what

00:00:44,969 --> 00:00:50,550
the outcome of that is and what

00:00:46,670 --> 00:00:54,120
contributors can do to help us so to

00:00:50,550 --> 00:00:57,300
start here first this simple question

00:00:54,120 --> 00:01:00,329
like what are we actually doing so what

00:00:57,300 --> 00:01:02,579
we do is that we develop a

00:01:00,329 --> 00:01:04,770
speech-to-text system that means like

00:01:02,579 --> 00:01:06,780
this is this little component while

00:01:04,770 --> 00:01:08,970
little is probably a bad part for that

00:01:06,780 --> 00:01:11,940
it's actually quite a powerful component

00:01:08,970 --> 00:01:14,850
that enables voice assistance like for

00:01:11,940 --> 00:01:18,450
example Cortana 0 and allocate Alexa

00:01:14,850 --> 00:01:21,899
echo and so forth and this is that piece

00:01:18,450 --> 00:01:24,720
that translates audio bra do data into

00:01:21,899 --> 00:01:26,940
text so these assistants need more

00:01:24,720 --> 00:01:29,640
components than that for example like a

00:01:26,940 --> 00:01:31,709
voice activity detection and the reverse

00:01:29,640 --> 00:01:34,649
operation like creating a voice from

00:01:31,709 --> 00:01:37,590
text but at the moment we concentrate on

00:01:34,649 --> 00:01:41,250
this actual hard part of translating

00:01:37,590 --> 00:01:43,920
speech into text and this is based

00:01:41,250 --> 00:01:45,929
actually on tensorflow and those of you

00:01:43,920 --> 00:01:49,920
who know this is actually Pais based

00:01:45,929 --> 00:01:52,979
framework developed by Google and we

00:01:49,920 --> 00:01:56,550
built deep speech actually following a

00:01:52,979 --> 00:02:00,060
paper from Baidu that that's actually

00:01:56,550 --> 00:02:02,729
quite famous and we just realize what's

00:02:00,060 --> 00:02:06,900
in that paper intensive flow to make it

00:02:02,729 --> 00:02:11,320
accessible for everybody so

00:02:06,900 --> 00:02:14,010
why are we doing this that's actually so

00:02:11,320 --> 00:02:16,750
like I want to answer this as refold so

00:02:14,010 --> 00:02:20,800
because it's it's a nice thing to do

00:02:16,750 --> 00:02:23,770
like that so first thing is we actually

00:02:20,800 --> 00:02:26,680
want to have a state of the art solution

00:02:23,770 --> 00:02:29,020
that's not proprietary so state of the

00:02:26,680 --> 00:02:31,210
admins like there's this classical

00:02:29,020 --> 00:02:33,190
approaches that are based on hidden

00:02:31,210 --> 00:02:35,470
Markov models and so forth and there are

00:02:33,190 --> 00:02:37,510
very manually driven like programmed

00:02:35,470 --> 00:02:39,460
literally from end to end like every

00:02:37,510 --> 00:02:42,730
piece of that solutions is programmed by

00:02:39,460 --> 00:02:44,320
people and what we wanted to do is like

00:02:42,730 --> 00:02:48,160
to have this state-of-the-art solutions

00:02:44,320 --> 00:02:50,290
like Google and and others do and have

00:02:48,160 --> 00:02:52,510
this actually available for the broader

00:02:50,290 --> 00:02:57,160
public and not just for proprietary

00:02:52,510 --> 00:02:59,800
players and we know that this is

00:02:57,160 --> 00:03:02,530
typically proprietary solutions we tend

00:02:59,800 --> 00:03:05,710
to get evil at some point so and

00:03:02,530 --> 00:03:09,100
therefore we try to get a better

00:03:05,710 --> 00:03:10,630
solution here so the second reason is

00:03:09,100 --> 00:03:12,580
that we actually want to have offline

00:03:10,630 --> 00:03:14,890
support so as you probably know like

00:03:12,580 --> 00:03:16,840
most assistants nowadays actually are

00:03:14,890 --> 00:03:19,810
based on this schema of having some

00:03:16,840 --> 00:03:23,040
audio data recorded locally send over

00:03:19,810 --> 00:03:26,950
the network translated on some server

00:03:23,040 --> 00:03:30,010
sent back and this comes with many

00:03:26,950 --> 00:03:32,290
drawbacks and most importantly this

00:03:30,010 --> 00:03:34,510
would our approach of offline support

00:03:32,290 --> 00:03:37,480
would solve this privacy issue that this

00:03:34,510 --> 00:03:39,610
has actually inherently and secondly

00:03:37,480 --> 00:03:42,850
this will also lead to lower latency

00:03:39,610 --> 00:03:45,190
like and if you have if you feel if you

00:03:42,850 --> 00:03:48,220
really like experience the the solutions

00:03:45,190 --> 00:03:51,910
nowadays even small improvements in

00:03:48,220 --> 00:03:53,560
latency actually are really recognizable

00:03:51,910 --> 00:03:57,250
you actually get different and better

00:03:53,560 --> 00:03:59,950
feeling of the solution like and the

00:03:57,250 --> 00:04:02,140
third reason is that an end-to-end

00:03:59,950 --> 00:04:04,480
machine learning approach namely not

00:04:02,140 --> 00:04:07,570
coding everything from A to Z but

00:04:04,480 --> 00:04:10,450
actually having machine learning filling

00:04:07,570 --> 00:04:14,799
the gap from input/output more or less

00:04:10,450 --> 00:04:16,870
automatically is that our scaling you

00:04:14,799 --> 00:04:18,959
mean actually that means actually

00:04:16,870 --> 00:04:21,880
if you have data from let me say like an

00:04:18,959 --> 00:04:24,130
unknown language X and you have enough

00:04:21,880 --> 00:04:27,040
data of it you would not have to start

00:04:24,130 --> 00:04:29,530
coding actually based on a linguistic

00:04:27,040 --> 00:04:31,840
pattern a new solution but you would

00:04:29,530 --> 00:04:34,350
instead just train the system to learn

00:04:31,840 --> 00:04:37,419
this language by itself more or less and

00:04:34,350 --> 00:04:39,460
the second thing is also that you have a

00:04:37,419 --> 00:04:42,100
better degree of quality and that means

00:04:39,460 --> 00:04:45,510
like these end-to-end machine learning

00:04:42,100 --> 00:04:47,860
solutions are better at actually

00:04:45,510 --> 00:04:49,600
accessing that details in the

00:04:47,860 --> 00:04:53,320
abstraction levels that you typically

00:04:49,600 --> 00:04:55,600
have in that systems in a way that is

00:04:53,320 --> 00:04:57,160
actually more powerful for the outcome

00:04:55,600 --> 00:04:59,979
that is actually leading to greater

00:04:57,160 --> 00:05:07,120
quality so it's it's actually also in

00:04:59,979 --> 00:05:08,560
quality scaling better so I actually as

00:05:07,120 --> 00:05:10,810
I said already like want to give a bit

00:05:08,560 --> 00:05:13,360
like a users perspective and first thing

00:05:10,810 --> 00:05:15,580
I want to say like we released means

00:05:13,360 --> 00:05:17,770
like it was a bit like a silent release

00:05:15,580 --> 00:05:19,210
but in the end we released and this was

00:05:17,770 --> 00:05:22,660
actually a couple weeks ago like was

00:05:19,210 --> 00:05:25,000
last year and this week actually had

00:05:22,660 --> 00:05:27,669
already a secondary release like um and

00:05:25,000 --> 00:05:31,870
I actually wanted to show you what's in

00:05:27,669 --> 00:05:33,789
the package so first thing is how you

00:05:31,870 --> 00:05:35,349
prepare the environment like we have

00:05:33,789 --> 00:05:37,599
software packages that you can just

00:05:35,349 --> 00:05:40,660
install but for them to work you need

00:05:37,599 --> 00:05:42,490
the data namely the models the brain you

00:05:40,660 --> 00:05:43,840
could say like that we train you have to

00:05:42,490 --> 00:05:45,490
download it and you have to get it

00:05:43,840 --> 00:05:48,010
somewhere and this is what I actually

00:05:45,490 --> 00:05:49,720
now want to show you it's a bit like

00:05:48,010 --> 00:05:52,419
accelerator I'm not able to type that

00:05:49,720 --> 00:05:55,150
fast I have to admit and so first you

00:05:52,419 --> 00:05:57,099
actually get the models downloaded it's

00:05:55,150 --> 00:06:00,789
actually a huge package that we provide

00:05:57,099 --> 00:06:04,030
on github then you actually download

00:06:00,789 --> 00:06:07,240
also some audio data and you can see

00:06:04,030 --> 00:06:09,550
here like the audio data is actually

00:06:07,240 --> 00:06:13,810
provided for you for demo purposes for

00:06:09,550 --> 00:06:16,419
testing simple tests and I would now

00:06:13,810 --> 00:06:20,130
like to try to play one of these samples

00:06:16,419 --> 00:06:20,130
that are you throughout this demo now

00:06:20,240 --> 00:06:26,479
this is that eight four five five XYZ

00:06:23,690 --> 00:06:31,030
simple and I will go with the microphone

00:06:26,479 --> 00:06:34,039
near to my notebook Wow

00:06:31,030 --> 00:06:36,050
so it's actually somebody telling us so

00:06:34,039 --> 00:06:40,729
saying like your power is sufficient I

00:06:36,050 --> 00:06:43,009
said so like I do not want to lose too

00:06:40,729 --> 00:06:44,449
many words on that but the thing is now

00:06:43,009 --> 00:06:46,460
I want to show you like how this

00:06:44,449 --> 00:06:52,699
actually works in pison to understand

00:06:46,460 --> 00:06:54,440
this sentence so like you first create a

00:06:52,699 --> 00:06:55,849
virtual environment as this we like from

00:06:54,440 --> 00:06:59,660
scratch like you create in virtual

00:06:55,849 --> 00:07:02,590
environment you source it then you

00:06:59,660 --> 00:07:06,830
actually do pip install off deep speech

00:07:02,590 --> 00:07:08,479
and comes batteries included namely it

00:07:06,830 --> 00:07:10,940
has a command-line tool as you can see

00:07:08,479 --> 00:07:12,949
here this use it parameters and now

00:07:10,940 --> 00:07:14,780
actually we just pass in the model that

00:07:12,949 --> 00:07:17,930
we downloaded the wav file that I just

00:07:14,780 --> 00:07:20,539
played and the alphabet and you can see

00:07:17,930 --> 00:07:23,139
here how it was translated actually into

00:07:20,539 --> 00:07:25,909
that sentence that I just showed you and

00:07:23,139 --> 00:07:28,820
the same happens here in the second pass

00:07:25,909 --> 00:07:31,430
with a GPU power solution as you can see

00:07:28,820 --> 00:07:33,139
like the GPU one is actually faster and

00:07:31,430 --> 00:07:35,780
this is what we currently also

00:07:33,139 --> 00:07:39,500
concentrate on to get the solution fast

00:07:35,780 --> 00:07:41,719
and regards to real time like you have a

00:07:39,500 --> 00:07:43,880
certain computing overhead that this

00:07:41,719 --> 00:07:46,400
model actually implies and at the moment

00:07:43,880 --> 00:07:51,099
if you go with the CPU there we are

00:07:46,400 --> 00:07:54,800
almost around real time on normal PC

00:07:51,099 --> 00:07:56,599
with the GPU you will get more so like

00:07:54,800 --> 00:07:59,180
you can see that from the interpretation

00:07:56,599 --> 00:08:04,580
times that you that you can see here in

00:07:59,180 --> 00:08:07,250
the lock so it's a simplified

00:08:04,580 --> 00:08:08,930
representation of this code it's

00:08:07,250 --> 00:08:11,509
actually we like simple you have an

00:08:08,930 --> 00:08:13,400
import you do then model you create a

00:08:11,509 --> 00:08:15,530
model then you enable the decoder was a

00:08:13,400 --> 00:08:17,330
language model and you pass in pretty

00:08:15,530 --> 00:08:20,449
much that what I passed into this

00:08:17,330 --> 00:08:23,190
command-line utility and then in the end

00:08:20,449 --> 00:08:26,379
you print the transcript

00:08:23,190 --> 00:08:31,360
so there's also a no chance version of

00:08:26,379 --> 00:08:33,550
this it's very very similar um you

00:08:31,360 --> 00:08:37,089
actually also can just use NPM install

00:08:33,550 --> 00:08:39,580
deep speed well the typical kind of like

00:08:37,089 --> 00:08:41,589
NPM workflow here it warns you here now

00:08:39,580 --> 00:08:44,709
on uh not an initialized an

00:08:41,589 --> 00:08:47,230
uninitialized project and then you can

00:08:44,709 --> 00:08:48,940
actually here use the client that comes

00:08:47,230 --> 00:08:50,740
also ship whether it was a model again

00:08:48,940 --> 00:08:52,180
with the audio again and busy alphabet

00:08:50,740 --> 00:08:56,649
again and you actually get the

00:08:52,180 --> 00:09:00,970
translation the same with the version on

00:08:56,649 --> 00:09:04,589
GPU basis you just replace in the former

00:09:00,970 --> 00:09:08,200
statement you will see in a second

00:09:04,589 --> 00:09:11,140
you'll replace keep speech with deep

00:09:08,200 --> 00:09:17,020
deep deep speech - GPU and you get

00:09:11,140 --> 00:09:19,600
actually the faster result this is a bit

00:09:17,020 --> 00:09:21,700
like same similar code is completely

00:09:19,600 --> 00:09:25,570
asynchronous like Noda stupidly doing

00:09:21,700 --> 00:09:28,060
things by the way our community also

00:09:25,570 --> 00:09:30,520
provided already rust and go bindings so

00:09:28,060 --> 00:09:34,899
you can just also work with rust and go

00:09:30,520 --> 00:09:38,140
on that somewhere to the performance in

00:09:34,899 --> 00:09:39,640
regards to quality and this is kind of

00:09:38,140 --> 00:09:41,740
like a measurement that's called vert

00:09:39,640 --> 00:09:44,500
error rate whatever it means like how

00:09:41,740 --> 00:09:49,510
many hours you have on how many correct

00:09:44,500 --> 00:09:52,110
words and there is typically a done

00:09:49,510 --> 00:09:54,370
measurement is a some table in the net

00:09:52,110 --> 00:09:56,500
that compares the different solutions

00:09:54,370 --> 00:09:59,050
against each other however part of this

00:09:56,500 --> 00:10:00,700
tables also some from some deeps from

00:09:59,050 --> 00:10:02,649
the leap speech paper from by do they

00:10:00,700 --> 00:10:04,829
measure to the human performance so like

00:10:02,649 --> 00:10:09,700
they actually let I think like they let

00:10:04,829 --> 00:10:11,470
humans do the test and to have some cuts

00:10:09,700 --> 00:10:13,089
some baseline to compare with and the

00:10:11,470 --> 00:10:14,680
system that we currently have in the

00:10:13,089 --> 00:10:17,500
model that we actually provide for

00:10:14,680 --> 00:10:18,990
download is already actually performing

00:10:17,500 --> 00:10:22,089
better than humans

00:10:18,990 --> 00:10:24,360
just to get some some comparable will be

00:10:22,089 --> 00:10:24,360
here

00:10:26,260 --> 00:10:31,900
so now two more kind of like development

00:10:29,220 --> 00:10:33,610
centric view on on to all of that not

00:10:31,900 --> 00:10:36,220
embedding stuff but really like using

00:10:33,610 --> 00:10:39,190
that stuff and extending it mainly

00:10:36,220 --> 00:10:42,070
training models and development so like

00:10:39,190 --> 00:10:44,290
when you want to train a model you have

00:10:42,070 --> 00:10:47,590
to have also done some preparation work

00:10:44,290 --> 00:10:49,660
I show that here this is primarily

00:10:47,590 --> 00:10:52,690
actually about you have to by the way

00:10:49,660 --> 00:10:55,090
this is one of them most often questions

00:10:52,690 --> 00:10:56,980
and our forums it's both like why isn't

00:10:55,090 --> 00:10:59,080
the download working it's because git

00:10:56,980 --> 00:11:03,400
LFS is not instance so you have to

00:10:59,080 --> 00:11:05,200
install git LFS first and so like when

00:11:03,400 --> 00:11:07,450
you actually am clone our project

00:11:05,200 --> 00:11:10,090
there's three steps that you have to do

00:11:07,450 --> 00:11:11,830
afterwards the first step is actually to

00:11:10,090 --> 00:11:13,570
install the requirements the Python

00:11:11,830 --> 00:11:20,160
requirements there's a requirements txt

00:11:13,570 --> 00:11:20,160
file and so like you can see that here

00:11:20,640 --> 00:11:26,940
so we activate the environment that we

00:11:23,080 --> 00:11:31,720
just created we install the requirements

00:11:26,940 --> 00:11:33,580
and then after the requires come

00:11:31,720 --> 00:11:35,740
installed I install manually this is

00:11:33,580 --> 00:11:37,480
actually an additional step you have to

00:11:35,740 --> 00:11:40,000
do when you have a GPU on your machine

00:11:37,480 --> 00:11:43,060
you can additionally to the deep speech

00:11:40,000 --> 00:11:45,520
package actually on salt also the these

00:11:43,060 --> 00:11:50,020
requirements for a GPU solar that tends

00:11:45,520 --> 00:11:51,730
a flow GPU support we have a tool for

00:11:50,020 --> 00:11:54,280
that that is actually integrating for

00:11:51,730 --> 00:11:56,560
all sorts of platforms the binaries that

00:11:54,280 --> 00:11:57,970
are required for that like this tool

00:11:56,560 --> 00:12:00,100
that you can see here is actually

00:11:57,970 --> 00:12:04,330
automatically downloading that in

00:12:00,100 --> 00:12:05,860
regards to your local machine so yeah

00:12:04,330 --> 00:12:07,600
and you have a tremendous amount of

00:12:05,860 --> 00:12:11,830
parameters you can see you're just the

00:12:07,600 --> 00:12:14,110
tail of the whole parameter bulk that

00:12:11,830 --> 00:12:17,080
deep speech docked I has as a command

00:12:14,110 --> 00:12:20,560
and we actually because this is so

00:12:17,080 --> 00:12:22,540
complicated we want to later do an

00:12:20,560 --> 00:12:24,580
example that we like goes end-to-end

00:12:22,540 --> 00:12:26,530
through the whole process of using it so

00:12:24,580 --> 00:12:29,200
first we need to get some data and the

00:12:26,530 --> 00:12:32,980
data we actually gather together onto a

00:12:29,200 --> 00:12:36,819
page that we use voiced or mozilla.org

00:12:32,980 --> 00:12:39,459
slash data and we not only provide our

00:12:36,819 --> 00:12:42,249
common voice data which is a corpus that

00:12:39,459 --> 00:12:44,499
we actually provide but we link also to

00:12:42,249 --> 00:12:46,749
other data sources so it's really like a

00:12:44,499 --> 00:12:50,139
one-stop shop here for actually getting

00:12:46,749 --> 00:12:52,389
actual data I have to say this is only

00:12:50,139 --> 00:12:54,489
for the English language at the moment

00:12:52,389 --> 00:12:57,759
like this is English language corpora

00:12:54,489 --> 00:13:03,609
that are used for training that kind of

00:12:57,759 --> 00:13:06,009
deep speech models so if you want to

00:13:03,609 --> 00:13:08,529
contribute your own voice you can do

00:13:06,009 --> 00:13:11,139
that there is a mask for that you can

00:13:08,529 --> 00:13:12,789
actually just tip tap this button and

00:13:11,139 --> 00:13:14,139
then it will actually start a recording

00:13:12,789 --> 00:13:16,449
process and then you can contribute

00:13:14,139 --> 00:13:17,889
actually you was by reading at a

00:13:16,449 --> 00:13:20,289
sentence that's presented to you and

00:13:17,889 --> 00:13:26,470
this is the way how we built up our own

00:13:20,289 --> 00:13:28,419
common voice corpus it's free to be used

00:13:26,470 --> 00:13:30,369
by everybody in innocence premiere

00:13:28,419 --> 00:13:33,039
important to say like it's not just like

00:13:30,369 --> 00:13:36,879
let me get this data then it's really

00:13:33,039 --> 00:13:38,859
like completely open data and and here

00:13:36,879 --> 00:13:41,259
you can see also like it's not just

00:13:38,859 --> 00:13:43,749
recording stuff but also like verifying

00:13:41,259 --> 00:13:45,489
things like if something got recorded it

00:13:43,749 --> 00:13:47,529
needs also to be verified by independent

00:13:45,489 --> 00:13:49,539
people and there's some statistics

00:13:47,529 --> 00:13:52,179
process running in background that says

00:13:49,539 --> 00:13:54,609
like if you have more positive votes and

00:13:52,179 --> 00:13:56,169
negative votes or no negative votes at

00:13:54,609 --> 00:14:01,479
all then it's actually already validated

00:13:56,169 --> 00:14:03,249
as as a valid file and and somebody had

00:14:01,479 --> 00:14:05,679
not been just like accidentally hitting

00:14:03,249 --> 00:14:09,129
a record and recorded his cat in the

00:14:05,679 --> 00:14:11,229
background and whatsoever so this is how

00:14:09,129 --> 00:14:12,939
that works so you can install easily

00:14:11,229 --> 00:14:14,529
this common voice corpus we have

00:14:12,939 --> 00:14:16,539
batteries included in deep speech

00:14:14,529 --> 00:14:20,139
because we provide actually an own

00:14:16,539 --> 00:14:23,199
importer tool for that this is again

00:14:20,139 --> 00:14:26,009
like sourcing our environment and then

00:14:23,199 --> 00:14:28,479
we actually go into the bin import CV

00:14:26,009 --> 00:14:29,979
and this is really like just downloading

00:14:28,479 --> 00:14:32,350
everything this actually what you saw

00:14:29,979 --> 00:14:35,019
here is super super accelerated like it

00:14:32,350 --> 00:14:37,730
takes really a long time to do like and

00:14:35,019 --> 00:14:42,240
therefore I had to fake all of this

00:14:37,730 --> 00:14:45,060
so you can see here actually I'm in the

00:14:42,240 --> 00:14:47,670
last command that we have all sorts of

00:14:45,060 --> 00:14:50,610
CSV files people look into those CSV

00:14:47,670 --> 00:14:52,410
files later but take a take a look at

00:14:50,610 --> 00:14:55,800
the different names that we have here we

00:14:52,410 --> 00:14:59,910
have typically three different in this

00:14:55,800 --> 00:15:04,140
case suffixes and one suffix is def and

00:14:59,910 --> 00:15:07,710
train and and def train and test and I

00:15:04,140 --> 00:15:09,750
will come later to that so now I will

00:15:07,710 --> 00:15:14,010
give you a micro tutorial actually end

00:15:09,750 --> 00:15:17,610
to end how to use all of this first a

00:15:14,010 --> 00:15:19,740
bit of terminology so loss is actually a

00:15:17,610 --> 00:15:23,550
name from from the from the machine

00:15:19,740 --> 00:15:25,770
learning and this is like indicating leg

00:15:23,550 --> 00:15:28,380
as a number how different the actual

00:15:25,770 --> 00:15:30,060
outcome is from the from the expected

00:15:28,380 --> 00:15:32,550
outcome so like if you have a

00:15:30,060 --> 00:15:35,160
translation of some audio into text and

00:15:32,550 --> 00:15:37,020
you compare the text or outcome that you

00:15:35,160 --> 00:15:39,480
expect with the textual outcome that it

00:15:37,020 --> 00:15:41,100
computed you will get a number and that

00:15:39,480 --> 00:15:43,770
number is actually important for the

00:15:41,100 --> 00:15:48,839
system to actually do back propagation

00:15:43,770 --> 00:15:52,279
in the process of learning sets in the

00:15:48,839 --> 00:15:54,630
data corpus as we already saw the data

00:15:52,279 --> 00:15:57,660
that in the train set is used for

00:15:54,630 --> 00:16:00,180
training the Deaf set is in every

00:15:57,660 --> 00:16:02,070
application of the training data used

00:16:00,180 --> 00:16:04,170
for validating that we are still

00:16:02,070 --> 00:16:07,320
learning and not overfitting we will

00:16:04,170 --> 00:16:09,300
come to that later and the test set is

00:16:07,320 --> 00:16:11,190
in the end an unbiased set that is

00:16:09,300 --> 00:16:13,529
executed after the learning is

00:16:11,190 --> 00:16:15,060
completely done you actually do a final

00:16:13,529 --> 00:16:17,100
test and this is typically used for

00:16:15,060 --> 00:16:19,529
comparing across the industry the

00:16:17,100 --> 00:16:21,959
different systems because all of those

00:16:19,529 --> 00:16:25,200
tests are actually fixed by the ones who

00:16:21,959 --> 00:16:27,029
create the corpus not by the by the

00:16:25,200 --> 00:16:29,520
machine learners that actually use it

00:16:27,029 --> 00:16:31,890
but by that that people that actually

00:16:29,520 --> 00:16:35,330
provide the corpus so that across the

00:16:31,890 --> 00:16:38,430
industry you can then compare solutions

00:16:35,330 --> 00:16:41,310
an apart is actually when you trained of

00:16:38,430 --> 00:16:43,050
the whole training set one time but

00:16:41,310 --> 00:16:44,910
actually typically in training what you

00:16:43,050 --> 00:16:48,260
do is you could you apply it several

00:16:44,910 --> 00:16:50,910
times over and over and over again

00:16:48,260 --> 00:16:53,010
so and this is actually what we will do

00:16:50,910 --> 00:16:55,020
now in a second this is we will try to

00:16:53,010 --> 00:16:56,370
overfit that means like this is just the

00:16:55,020 --> 00:16:58,860
hello Baltimore and machine learning

00:16:56,370 --> 00:17:02,040
it's not actual training overfitting

00:16:58,860 --> 00:17:04,410
means like you learn your training set

00:17:02,040 --> 00:17:06,420
it means like it will only understand

00:17:04,410 --> 00:17:08,160
your training set it will not learn a

00:17:06,420 --> 00:17:09,810
general understanding of the language

00:17:08,160 --> 00:17:12,540
and this is because I have just one

00:17:09,810 --> 00:17:13,589
sample I will I will show you that

00:17:12,540 --> 00:17:17,010
sample in a second

00:17:13,589 --> 00:17:20,459
and so in the end when the validation

00:17:17,010 --> 00:17:22,860
said the orange one starts to to the

00:17:20,459 --> 00:17:24,600
loss starts to increase again not a

00:17:22,860 --> 00:17:27,120
decrease in the beginning of the train

00:17:24,600 --> 00:17:28,920
it starts to increase again you actually

00:17:27,120 --> 00:17:33,390
failed already but we do that on purpose

00:17:28,920 --> 00:17:34,950
to just show that training works so what

00:17:33,390 --> 00:17:36,960
I will show you now is actually not

00:17:34,950 --> 00:17:41,940
realistic in regards to creating a real

00:17:36,960 --> 00:17:43,470
model it's just a fake um so like and by

00:17:41,940 --> 00:17:44,850
the way we have two different models so

00:17:43,470 --> 00:17:46,470
like we have an acoustic and the

00:17:44,850 --> 00:17:49,110
language model the acoustic one is that

00:17:46,470 --> 00:17:52,470
one that we train now this is actually

00:17:49,110 --> 00:17:54,720
mapping sounds to letters it's very

00:17:52,470 --> 00:17:56,670
simplified but that's bonus what it does

00:17:54,720 --> 00:17:58,650
and the latter one the the language

00:17:56,670 --> 00:18:00,840
model is more less is it pro you

00:17:58,650 --> 00:18:03,330
remember typing support on mobile phones

00:18:00,840 --> 00:18:04,890
like it understands on a stochastic

00:18:03,330 --> 00:18:09,350
point of view it understands language

00:18:04,890 --> 00:18:12,090
and and can correct kind of like

00:18:09,350 --> 00:18:14,630
literally translated audio into

00:18:12,090 --> 00:18:17,100
characters into actual written words I

00:18:14,630 --> 00:18:20,460
just understands language on an auto

00:18:17,100 --> 00:18:23,430
graphic point of view and this is the

00:18:20,460 --> 00:18:26,010
terminology that we need so first we

00:18:23,430 --> 00:18:28,380
actually start to to try to actually I

00:18:26,010 --> 00:18:31,350
can trend I can really like now it just

00:18:28,380 --> 00:18:34,020
read it it's I recorded myself saying to

00:18:31,350 --> 00:18:36,140
bukhov Yakov soon twice we create from

00:18:34,020 --> 00:18:39,240
hidden text this is a stupid German

00:18:36,140 --> 00:18:41,460
sentence that is a pan ramp Engram is

00:18:39,240 --> 00:18:43,770
every letter of the German language is

00:18:41,460 --> 00:18:47,160
one at least one time in this sentence

00:18:43,770 --> 00:18:50,480
it's like the twig fox jumps over and so

00:18:47,160 --> 00:18:50,480
forth just for German

00:18:50,940 --> 00:18:59,759
now we create a corpus from that simple

00:18:53,929 --> 00:19:01,859
oops this and this is really simple it's

00:18:59,759 --> 00:19:05,249
in the end just like we have the simple

00:19:01,859 --> 00:19:07,830
we make a corpus directory in that

00:19:05,249 --> 00:19:11,940
directory of a file directory remove the

00:19:07,830 --> 00:19:14,369
WAV file there then we actually create

00:19:11,940 --> 00:19:17,460
one of these in this case a train one

00:19:14,369 --> 00:19:19,590
CSV file the CSV file consists of three

00:19:17,460 --> 00:19:22,229
columns a file name this is actually an

00:19:19,590 --> 00:19:24,570
absolute file name namely it needs needs

00:19:22,229 --> 00:19:26,759
to be rooted then the wav file size of

00:19:24,570 --> 00:19:28,559
the transcript and enter we like the

00:19:26,759 --> 00:19:31,789
absolute class now of this jack-up WAV

00:19:28,559 --> 00:19:34,679
file the file size of that that are just

00:19:31,789 --> 00:19:36,599
remembered and write down this stupid

00:19:34,679 --> 00:19:39,090
sentence lower case because it's not

00:19:36,599 --> 00:19:42,450
required to be different encasing

00:19:39,090 --> 00:19:44,669
because you don't hear Kaazing it's just

00:19:42,450 --> 00:19:51,029
like the system will translate

00:19:44,669 --> 00:19:52,440
case-insensitive from there on we now

00:19:51,029 --> 00:19:54,809
create a language model this is a bit

00:19:52,440 --> 00:19:57,109
more tricky for that I actually used

00:19:54,809 --> 00:20:00,359
wooden barrack

00:19:57,109 --> 00:20:03,899
book they'll just download it and that I

00:20:00,359 --> 00:20:06,389
actually used with a tool called kennel

00:20:03,899 --> 00:20:08,220
I'm this is that tool that is used for

00:20:06,389 --> 00:20:09,899
language models typically and you can

00:20:08,220 --> 00:20:11,460
see here like how this is used to just

00:20:09,899 --> 00:20:12,899
passed in their text in a sense and you

00:20:11,460 --> 00:20:14,970
get this kind of language model

00:20:12,899 --> 00:20:16,649
automatically there so there's no

00:20:14,970 --> 00:20:19,499
training in the sense like it's more

00:20:16,649 --> 00:20:22,289
like a conversion and you can see here I

00:20:19,499 --> 00:20:23,909
am now doing a German alphabet I removed

00:20:22,289 --> 00:20:27,809
this apostrophe that is not used in

00:20:23,909 --> 00:20:29,849
German I add instead the umlaut an asset

00:20:27,809 --> 00:20:32,759
and that's pretty much it then

00:20:29,849 --> 00:20:34,830
downloading the arm the book wouldn't

00:20:32,759 --> 00:20:37,109
back book you can see here like it's

00:20:34,830 --> 00:20:40,229
simplified it's lower case all sentences

00:20:37,109 --> 00:20:42,929
are actually on separate lines and then

00:20:40,229 --> 00:20:45,840
actually we create using Ken LM this

00:20:42,929 --> 00:20:47,820
model you there's a need to convert the

00:20:45,840 --> 00:20:51,749
also to a binary representation that is

00:20:47,820 --> 00:20:53,879
cheaper that is cheaper in n space and

00:20:51,749 --> 00:20:55,830
then last not least we create a

00:20:53,879 --> 00:20:58,109
so-called tree file that is used by our

00:20:55,830 --> 00:21:00,119
piece of software that's not the

00:20:58,109 --> 00:21:01,300
language model but the the acoustic

00:21:00,119 --> 00:21:05,620
model from

00:21:01,300 --> 00:21:08,710
for connecting to the language model now

00:21:05,620 --> 00:21:11,590
let's do the almost last step all

00:21:08,710 --> 00:21:14,170
together it's always a good thing to

00:21:11,590 --> 00:21:16,090
write the so-called God run script or

00:21:14,170 --> 00:21:17,890
run is actually get ignored in the root

00:21:16,090 --> 00:21:20,560
of our deep speech project so you can

00:21:17,890 --> 00:21:22,330
just put in your own run and that is

00:21:20,560 --> 00:21:24,760
actually parameter rising deep speech to

00:21:22,330 --> 00:21:28,660
your needs so you put in in this case

00:21:24,760 --> 00:21:30,490
this simplified one sample corpus that

00:21:28,660 --> 00:21:33,490
are just created three times for

00:21:30,490 --> 00:21:35,470
development test and validation just

00:21:33,490 --> 00:21:37,330
allow that like before for for not

00:21:35,470 --> 00:21:41,380
development for training test and

00:21:37,330 --> 00:21:43,810
validation and they're they're linked to

00:21:41,380 --> 00:21:45,760
the alphabet file that we created to

00:21:43,810 --> 00:21:47,850
this language model the tree and the

00:21:45,760 --> 00:21:52,060
binary paths that we just traded I

00:21:47,850 --> 00:21:54,220
actually measured or figured out the

00:21:52,060 --> 00:21:55,690
hyperparameters learning rate and

00:21:54,220 --> 00:21:57,580
dropout right this is in machine and

00:21:55,690 --> 00:21:59,470
called hyper Camrys I had to try out

00:21:57,580 --> 00:22:02,590
like what the best values are for my

00:21:59,470 --> 00:22:05,500
purpose for the demo here and the rest

00:22:02,590 --> 00:22:07,410
is more like clutter except for the last

00:22:05,500 --> 00:22:09,970
one this is actually then here

00:22:07,410 --> 00:22:11,830
specifying this directory German models

00:22:09,970 --> 00:22:13,540
actually acts as an export directive

00:22:11,830 --> 00:22:15,340
once it actually got trained it will

00:22:13,540 --> 00:22:17,500
store the model there and we will have

00:22:15,340 --> 00:22:22,990
actually a similar directory to the

00:22:17,500 --> 00:22:26,920
English one that we provide so this is

00:22:22,990 --> 00:22:29,640
whoops this is like a real-time view now

00:22:26,920 --> 00:22:32,440
of the training process this is not

00:22:29,640 --> 00:22:35,980
accelerated this is also me typing slow

00:22:32,440 --> 00:22:38,020
by the way so you will see like he first

00:22:35,980 --> 00:22:40,480
complains about are no validation step

00:22:38,020 --> 00:22:42,160
needs to be bigger than 0 for early

00:22:40,480 --> 00:22:43,930
stopping to work this is just like me

00:22:42,160 --> 00:22:46,150
doing overfitting stuff without caring

00:22:43,930 --> 00:22:48,640
on invalidation at all

00:22:46,150 --> 00:22:50,650
but you can see here he is starting

00:22:48,640 --> 00:22:53,320
optimization and the first thing that he

00:22:50,650 --> 00:22:57,040
learns is something yah-yah-yah and I

00:22:53,320 --> 00:23:00,010
learn something and then he's shortening

00:22:57,040 --> 00:23:02,260
it in to just one letter and goes on

00:23:00,010 --> 00:23:05,260
like that and you can see here if you

00:23:02,260 --> 00:23:08,169
look at the loss if you spot the loss

00:23:05,260 --> 00:23:10,419
it's going down over the steps

00:23:08,169 --> 00:23:12,730
but I just this is boring to look at

00:23:10,419 --> 00:23:16,840
that because this will take a while so I

00:23:12,730 --> 00:23:20,580
actually prepared 20 time accelerated

00:23:16,840 --> 00:23:23,679
version of this and this looks like this

00:23:20,580 --> 00:23:27,279
and now look how the sentence on the

00:23:23,679 --> 00:23:31,139
bottom converts over time as the network

00:23:27,279 --> 00:23:34,989
understands what that means

00:23:31,139 --> 00:23:37,389
except for this Rudin which is by the

00:23:34,989 --> 00:23:40,149
way I can I consume this Rudin is a

00:23:37,389 --> 00:23:42,309
German word and DN is a German word and

00:23:40,149 --> 00:23:44,379
problem is DN is matching better here

00:23:42,309 --> 00:23:46,480
and therefore he actually wants all the

00:23:44,379 --> 00:23:49,659
time once to match T and but he will get

00:23:46,480 --> 00:23:52,210
it at some point he will get it and then

00:23:49,659 --> 00:23:54,429
he will not list this entries anymore

00:23:52,210 --> 00:23:56,679
because he is only listing stuff that's

00:23:54,429 --> 00:23:59,470
failing here already he matched it so it

00:23:56,679 --> 00:24:01,899
means like you can see we trained an an

00:23:59,470 --> 00:24:04,210
over fitting fashion perfectly this one

00:24:01,899 --> 00:24:06,759
sentence this model is understanding

00:24:04,210 --> 00:24:09,549
only in just this one sentence and not a

00:24:06,759 --> 00:24:11,409
general general German representation

00:24:09,549 --> 00:24:15,369
and you can see here now in the German

00:24:11,409 --> 00:24:18,730
models folder it's actually also if you

00:24:15,369 --> 00:24:20,889
see that output graph PB we already have

00:24:18,730 --> 00:24:24,249
the kind of like similar directory that

00:24:20,889 --> 00:24:28,720
we ship for English by our release of

00:24:24,249 --> 00:24:30,190
deep speech next steps for you actually

00:24:28,720 --> 00:24:33,100
if you want to go for doing something

00:24:30,190 --> 00:24:36,249
something more serious on that is to get

00:24:33,100 --> 00:24:38,529
more transcribed voice data get more and

00:24:36,249 --> 00:24:39,820
contemporary language model texts the

00:24:38,529 --> 00:24:41,889
texts from Gutenberg are not

00:24:39,820 --> 00:24:43,539
contemporary German so like it's not

00:24:41,889 --> 00:24:45,279
matching certain things it's really not

00:24:43,539 --> 00:24:46,929
not working for modern Germany you can

00:24:45,279 --> 00:24:48,879
say nein similar for of any other

00:24:46,929 --> 00:24:53,109
language but you do not have really like

00:24:48,879 --> 00:24:54,519
contemporary texts you have to tune the

00:24:53,109 --> 00:24:57,220
hyper permease and for a wheeeeel

00:24:54,519 --> 00:25:00,580
scenario not for this overfitting stupid

00:24:57,220 --> 00:25:02,980
stuff that I demoed here and you have to

00:25:00,580 --> 00:25:06,100
get hardware because machine learning is

00:25:02,980 --> 00:25:10,149
computing intensive as hell we use two

00:25:06,100 --> 00:25:12,220
machines with eight Titan X Pascal cards

00:25:10,149 --> 00:25:15,480
in it for two weeks to train the model

00:25:12,220 --> 00:25:15,480
for English that we should

00:25:15,800 --> 00:25:22,550
and spread the word so last not least

00:25:18,830 --> 00:25:26,840
our roadmap for 2018 is to train for

00:25:22,550 --> 00:25:29,030
another language not named yet to have

00:25:26,840 --> 00:25:30,860
streaming support this is like that the

00:25:29,030 --> 00:25:34,040
computing starts already when the first

00:25:30,860 --> 00:25:35,780
samples come in not just when the when

00:25:34,040 --> 00:25:37,850
the recording is done and then you pass

00:25:35,780 --> 00:25:41,480
it into the machinery so you lose some

00:25:37,850 --> 00:25:44,330
time I'm optimizing for noisy

00:25:41,480 --> 00:25:47,480
backgrounds this is really like having

00:25:44,330 --> 00:25:50,210
samples augmented with Street noise

00:25:47,480 --> 00:25:51,920
Restaurant noise stuff like that

00:25:50,210 --> 00:25:54,560
actually barking dogs in the background

00:25:51,920 --> 00:25:56,290
kitchen backgrounds and so forth so to

00:25:54,560 --> 00:25:58,850
actually make a capable of understanding

00:25:56,290 --> 00:26:01,400
language also under that conditions and

00:25:58,850 --> 00:26:03,620
in the end we are currently working also

00:26:01,400 --> 00:26:07,460
on text-to-speech so we want to actually

00:26:03,620 --> 00:26:10,640
also have a text-to-speech component so

00:26:07,460 --> 00:26:14,360
like you can talk to us be on IRC we

00:26:10,640 --> 00:26:18,530
have the machine learning loop and that

00:26:14,360 --> 00:26:20,440
is actually our discourse so please feel

00:26:18,530 --> 00:26:23,650
free to contact us that's it

00:26:20,440 --> 00:26:23,650
[Applause]

00:26:28,420 --> 00:26:33,109
[Music]

00:26:29,910 --> 00:26:33,109

YouTube URL: https://www.youtube.com/watch?v=NtZipf0BxKg


