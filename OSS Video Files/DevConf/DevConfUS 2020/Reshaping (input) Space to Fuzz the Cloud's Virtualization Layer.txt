Title: Reshaping (input) Space to Fuzz the Cloud's Virtualization Layer
Publication date: 2020-10-06
Playlist: DevConfUS 2020
Description: 
	Speaker: Alexander Bulekov

The market for public cloud platforms is valued in the hundreds of billions of dollars. Hypervisors form the backbone of the cloud and are, therefore, security-critical applications which are attractive targets for attackers. Fuzzing is a widely-adopted technique for automated software testing based on randomly-provided inputs. As testament to their success, fuzzers have found thousands of bugs in the Linux kernel.  Unfortunately, it is difficult to apply simple fuzzing techniques to the virtualization-layer, as hypervisors expose a massive input space which includes the entirety of the VM's memory. In this talk, I will present my research on making cloud virtual devices amenable to fuzzing. I will explain how we implemented fuzzing for the popular open-source QEMU hypervisor, where it has already led to dozens of bugs reports.
Captions: 
	00:00:00,080 --> 00:00:03,600
uh hi everyone my name is alexander

00:00:02,320 --> 00:00:06,240
borjejeko i'm a

00:00:03,600 --> 00:00:07,200
phd student at boston university and i'm

00:00:06,240 --> 00:00:09,599
an intern at

00:00:07,200 --> 00:00:10,639
red hat research i'm excited to talk to

00:00:09,599 --> 00:00:13,200
you today about

00:00:10,639 --> 00:00:13,679
um some of the work that i've been doing

00:00:13,200 --> 00:00:17,440
on

00:00:13,679 --> 00:00:20,800
fuzzy and virtual devices in hypervisors

00:00:17,440 --> 00:00:21,279
so i think we've probably all seen a

00:00:20,800 --> 00:00:23,840
picture

00:00:21,279 --> 00:00:24,640
similar to this you know explaining what

00:00:23,840 --> 00:00:27,920
the cloud is

00:00:24,640 --> 00:00:28,560
what what the hypervisor's job is but to

00:00:27,920 --> 00:00:31,760
sort of

00:00:28,560 --> 00:00:33,760
uh give a brief reminder the job of

00:00:31,760 --> 00:00:34,880
hypervisors is this piece of software

00:00:33,760 --> 00:00:37,440
that's running on

00:00:34,880 --> 00:00:39,520
a system and it's trying to partition

00:00:37,440 --> 00:00:42,320
the resources of that system

00:00:39,520 --> 00:00:43,680
among various different tenants and

00:00:42,320 --> 00:00:45,280
these tenants there

00:00:43,680 --> 00:00:46,879
they they care about running

00:00:45,280 --> 00:00:50,160
applications um

00:00:46,879 --> 00:00:52,079
and the hypervisor uh is providing

00:00:50,160 --> 00:00:54,239
resources to these applications and also

00:00:52,079 --> 00:00:56,800
providing isolation between

00:00:54,239 --> 00:00:58,160
these applications um and traditionally

00:00:56,800 --> 00:01:00,399
the way this is done is you know

00:00:58,160 --> 00:01:01,199
there's a fully virtualized operating

00:01:00,399 --> 00:01:04,400
system

00:01:01,199 --> 00:01:07,439
allocated for each tenant so

00:01:04,400 --> 00:01:10,400
the uh os that's running on the servers

00:01:07,439 --> 00:01:12,479
is virtualizing multiple um additional

00:01:10,400 --> 00:01:15,840
os's for each tenant

00:01:12,479 --> 00:01:19,040
and i briefly mentioned isolation

00:01:15,840 --> 00:01:20,320
um and what i mean there is you know one

00:01:19,040 --> 00:01:22,320
of these tenants might

00:01:20,320 --> 00:01:24,159
have might have been compromised or

00:01:22,320 --> 00:01:26,640
maybe they are malicious from

00:01:24,159 --> 00:01:27,280
from the start um and the job of the

00:01:26,640 --> 00:01:29,439
hyper

00:01:27,280 --> 00:01:31,360
hypervisor and the cloud provider is to

00:01:29,439 --> 00:01:33,920
prevent this malicious tenant from

00:01:31,360 --> 00:01:34,640
negatively affecting the other workloads

00:01:33,920 --> 00:01:38,079
of

00:01:34,640 --> 00:01:40,479
of the other tenants and from um and

00:01:38,079 --> 00:01:42,079
and further from you know compromising

00:01:40,479 --> 00:01:42,880
the actual underlying server so this

00:01:42,079 --> 00:01:45,280
would be

00:01:42,880 --> 00:01:47,119
the bad scenario where um this

00:01:45,280 --> 00:01:47,520
compromised guest is able to break out

00:01:47,119 --> 00:01:50,159
of

00:01:47,520 --> 00:01:51,520
uh the isolation guarantees of the

00:01:50,159 --> 00:01:54,560
hypervisor

00:01:51,520 --> 00:01:56,799
and um and run code at the privileged

00:01:54,560 --> 00:02:00,240
level of the hypervisor

00:01:56,799 --> 00:02:01,600
um and to sort of understand how

00:02:00,240 --> 00:02:04,560
something like this might happen

00:02:01,600 --> 00:02:05,759
well let's uh let's rewind and let's

00:02:04,560 --> 00:02:08,160
remember so the

00:02:05,759 --> 00:02:09,599
the the hypervisor is running on a

00:02:08,160 --> 00:02:12,000
server that's running on

00:02:09,599 --> 00:02:14,480
real hardware but these guest operating

00:02:12,000 --> 00:02:17,360
systems they were also designed to run

00:02:14,480 --> 00:02:18,800
on hardware or or something that looks

00:02:17,360 --> 00:02:21,520
like hardware at least

00:02:18,800 --> 00:02:22,319
so all of them expect to have this sort

00:02:21,520 --> 00:02:24,160
of view

00:02:22,319 --> 00:02:26,560
that they are they are the ones in fact

00:02:24,160 --> 00:02:29,280
that are interacting with the hardware

00:02:26,560 --> 00:02:30,160
and any time uh application running on a

00:02:29,280 --> 00:02:33,120
guest

00:02:30,160 --> 00:02:35,040
wants to uh communicate with the outside

00:02:33,120 --> 00:02:38,160
world or communicate with the hypervisor

00:02:35,040 --> 00:02:40,560
it has to do this through this uh device

00:02:38,160 --> 00:02:41,440
uh this device layer so the hypervisor

00:02:40,560 --> 00:02:43,840
provides

00:02:41,440 --> 00:02:45,040
these virtualized devices that govern

00:02:43,840 --> 00:02:48,720
the access

00:02:45,040 --> 00:02:50,959
uh and the resources that the uh uh

00:02:48,720 --> 00:02:53,040
that all each of the guest vms share

00:02:50,959 --> 00:02:55,040
with the outside world

00:02:53,040 --> 00:02:56,400
and um since this is the critical

00:02:55,040 --> 00:02:58,319
interface

00:02:56,400 --> 00:02:59,519
uh this virtual device interface this is

00:02:58,319 --> 00:03:02,879
the one that we're interested in

00:02:59,519 --> 00:03:06,560
protecting these virtual devices

00:03:02,879 --> 00:03:08,959
but the problem is that um when you're

00:03:06,560 --> 00:03:10,560
building a virtual device uh sometimes

00:03:08,959 --> 00:03:12,319
you're lucky enough and you have a spec

00:03:10,560 --> 00:03:14,560
for a real device that you're basing

00:03:12,319 --> 00:03:16,800
your virtu your code off

00:03:14,560 --> 00:03:19,599
and you know you just read a couple

00:03:16,800 --> 00:03:21,519
hundred or a couple thousand pages of

00:03:19,599 --> 00:03:24,879
of spec and then you sit down and you

00:03:21,519 --> 00:03:28,640
write a uh bug-free virtual device right

00:03:24,879 --> 00:03:31,360
um or uh or sometimes you can write your

00:03:28,640 --> 00:03:33,360
even your own spec for a power virtual

00:03:31,360 --> 00:03:36,640
device which

00:03:33,360 --> 00:03:37,599
is interesting but um in the worst case

00:03:36,640 --> 00:03:42,000
you actually

00:03:37,599 --> 00:03:44,239
don't don't have a spec that you can

00:03:42,000 --> 00:03:46,319
that you can design a device based on

00:03:44,239 --> 00:03:47,920
you either have to reverse engineer the

00:03:46,319 --> 00:03:48,799
actual device or you have to reverse

00:03:47,920 --> 00:03:52,159
engineer

00:03:48,799 --> 00:03:53,040
a driver for that device and go from a

00:03:52,159 --> 00:03:56,239
driver to

00:03:53,040 --> 00:03:56,879
a virtual device driver um and as you

00:03:56,239 --> 00:03:59,519
can

00:03:56,879 --> 00:04:00,879
probably guess you know the each each

00:03:59,519 --> 00:04:01,519
time you want a virtualized device that

00:04:00,879 --> 00:04:04,159
can be

00:04:01,519 --> 00:04:05,760
weeks or months of work and they're

00:04:04,159 --> 00:04:08,720
often implemented in

00:04:05,760 --> 00:04:10,000
fast but unsafe languages such as c and

00:04:08,720 --> 00:04:11,599
in general this is just a very

00:04:10,000 --> 00:04:13,120
error-prone process so

00:04:11,599 --> 00:04:15,360
it's a little scary that you know this

00:04:13,120 --> 00:04:17,600
is this is the code that's covering

00:04:15,360 --> 00:04:18,799
governing the um the isolation

00:04:17,600 --> 00:04:21,840
guarantees

00:04:18,799 --> 00:04:23,440
uh that that you know we expect from the

00:04:21,840 --> 00:04:26,800
cloud

00:04:23,440 --> 00:04:29,120
and unfortunately bugs in in these uh

00:04:26,800 --> 00:04:30,960
virtual devices aren't just a

00:04:29,120 --> 00:04:33,919
theoretical problem

00:04:30,960 --> 00:04:34,479
um in fact there's bugs found all the

00:04:33,919 --> 00:04:37,680
time

00:04:34,479 --> 00:04:39,680
in hypervisors and uh

00:04:37,680 --> 00:04:40,960
the common thread between most of these

00:04:39,680 --> 00:04:42,880
bugs is

00:04:40,960 --> 00:04:44,400
that they they they live in the virtual

00:04:42,880 --> 00:04:47,680
device code which is the

00:04:44,400 --> 00:04:49,040
huge uh percentage of the um code of a

00:04:47,680 --> 00:04:52,320
typical hypervisor

00:04:49,040 --> 00:04:54,080
probably the the most um well-known

00:04:52,320 --> 00:04:55,440
bug of this type it was the venom

00:04:54,080 --> 00:04:56,800
vulnerability which was discovered in

00:04:55,440 --> 00:04:59,040
00:04:56,800 --> 00:05:00,800
and this one is actually quite a simple

00:04:59,040 --> 00:05:02,240
you know buffer overflow type

00:05:00,800 --> 00:05:04,240
vulnerability that you learn about in

00:05:02,240 --> 00:05:07,919
any class that in any class where you

00:05:04,240 --> 00:05:10,000
learned the c language um and

00:05:07,919 --> 00:05:11,360
what's worse it was it was in a floppy

00:05:10,000 --> 00:05:13,680
disk controller which

00:05:11,360 --> 00:05:14,880
basically exists uh is connected to a

00:05:13,680 --> 00:05:16,479
bunch of virtual machines and

00:05:14,880 --> 00:05:19,759
hypervisors such as zen

00:05:16,479 --> 00:05:20,720
virtualbox and qmu for legacy reasons

00:05:19,759 --> 00:05:24,160
right because

00:05:20,720 --> 00:05:26,240
uh pcs originally had a floppy disk uh

00:05:24,160 --> 00:05:29,520
controllers

00:05:26,240 --> 00:05:31,919
um so if if if these were the types

00:05:29,520 --> 00:05:34,000
this bike's bug sort of made people wake

00:05:31,919 --> 00:05:36,240
up to the fact that you know

00:05:34,000 --> 00:05:37,840
the security of these virtual devices

00:05:36,240 --> 00:05:39,199
really needs to be taken a lot more

00:05:37,840 --> 00:05:42,320
seriously

00:05:39,199 --> 00:05:44,560
um and so looking at what a lot of the

00:05:42,320 --> 00:05:45,520
the other the rest of the industry has

00:05:44,560 --> 00:05:48,479
been doing

00:05:45,520 --> 00:05:50,160
um well fuzz testing has gained a lot of

00:05:48,479 --> 00:05:51,039
traction uh so when you do normal

00:05:50,160 --> 00:05:53,199
testing

00:05:51,039 --> 00:05:54,080
you you write some manual tests and you

00:05:53,199 --> 00:05:57,120
make sure that

00:05:54,080 --> 00:05:58,960
whatever the result of your test uh

00:05:57,120 --> 00:06:00,960
running over an application is it's it's

00:05:58,960 --> 00:06:04,000
what you'd expect right

00:06:00,960 --> 00:06:06,479
um fuzz testing uh from a

00:06:04,000 --> 00:06:07,280
bird's eye view is basically the same

00:06:06,479 --> 00:06:09,520
exact

00:06:07,280 --> 00:06:11,360
uh concept but instead of you writing a

00:06:09,520 --> 00:06:13,600
manual test you let the computer

00:06:11,360 --> 00:06:15,520
use a random number generator to provide

00:06:13,600 --> 00:06:16,960
some randomized data to your application

00:06:15,520 --> 00:06:19,440
and you make sure that you know in

00:06:16,960 --> 00:06:21,680
general your application sort of behaves

00:06:19,440 --> 00:06:22,479
properly and doesn't just completely

00:06:21,680 --> 00:06:26,560
crash

00:06:22,479 --> 00:06:27,680
um so that's basically that's basically

00:06:26,560 --> 00:06:29,199
fuzzing you know you provide

00:06:27,680 --> 00:06:31,120
randomized inputs to your application

00:06:29,199 --> 00:06:33,680
you make sure that you know your

00:06:31,120 --> 00:06:34,639
your application doesn't crash

00:06:33,680 --> 00:06:36,800
spectacularly

00:06:34,639 --> 00:06:38,160
yeah usually you can get more advanced

00:06:36,800 --> 00:06:41,039
with that um but that's

00:06:38,160 --> 00:06:42,400
that's in general um what fuzzing is uh

00:06:41,039 --> 00:06:45,120
used for

00:06:42,400 --> 00:06:46,479
and in fact there's a lot of fuzzing

00:06:45,120 --> 00:06:48,400
work that's that's gone on and

00:06:46,479 --> 00:06:49,919
it's been combined with for example

00:06:48,400 --> 00:06:51,919
coverage information where

00:06:49,919 --> 00:06:54,880
you can track the coverage that each of

00:06:51,919 --> 00:06:57,919
your fuzzer generated inputs achieves

00:06:54,880 --> 00:06:59,520
um over your application and based on

00:06:57,919 --> 00:07:00,080
that you can sort of judge whether that

00:06:59,520 --> 00:07:02,160
input

00:07:00,080 --> 00:07:03,360
produce some interesting behavior or

00:07:02,160 --> 00:07:04,800
whether it was just something that

00:07:03,360 --> 00:07:06,479
didn't completely didn't make any sense

00:07:04,800 --> 00:07:07,599
in the context of the program and if it

00:07:06,479 --> 00:07:09,919
was interesting

00:07:07,599 --> 00:07:12,080
you store it for later and you use that

00:07:09,919 --> 00:07:16,000
saved input as the basis for

00:07:12,080 --> 00:07:18,319
further mutations um

00:07:16,000 --> 00:07:20,720
and and you can also build your program

00:07:18,319 --> 00:07:23,199
with sanitizers to find entirely

00:07:20,720 --> 00:07:24,960
uh different classes of bugs that are

00:07:23,199 --> 00:07:28,560
typically hidden

00:07:24,960 --> 00:07:30,960
so simple enough right um this fuzz

00:07:28,560 --> 00:07:33,120
testing has completely you know

00:07:30,960 --> 00:07:34,080
has has proven to be very powerful it's

00:07:33,120 --> 00:07:35,919
used in

00:07:34,080 --> 00:07:38,080
a lot of domains ranging from like image

00:07:35,919 --> 00:07:39,919
parsing libraries to even the kernel

00:07:38,080 --> 00:07:41,120
so we just need to find you know where

00:07:39,919 --> 00:07:42,639
the virtual devices are

00:07:41,120 --> 00:07:45,199
and provide them with these buzzer

00:07:42,639 --> 00:07:47,440
inputs right

00:07:45,199 --> 00:07:49,120
well that's a little bit easier said

00:07:47,440 --> 00:07:49,840
than done so if we look at the input

00:07:49,120 --> 00:07:53,120
space

00:07:49,840 --> 00:07:53,680
for a device so how the cpu interacts

00:07:53,120 --> 00:07:57,520
with

00:07:53,680 --> 00:07:58,080
typical devices first we have on x86

00:07:57,520 --> 00:08:01,599
machines

00:07:58,080 --> 00:08:04,160
a address space of 64k addresses

00:08:01,599 --> 00:08:06,560
each of which can be mapped to a

00:08:04,160 --> 00:08:07,680
particular device and when the cpu wants

00:08:06,560 --> 00:08:10,960
to interact

00:08:07,680 --> 00:08:13,120
with these port devices over port io

00:08:10,960 --> 00:08:15,199
it uses a special instructions such as

00:08:13,120 --> 00:08:17,440
in or out

00:08:15,199 --> 00:08:19,759
to read or write a value to this device

00:08:17,440 --> 00:08:22,240
and when that instruction is executed

00:08:19,759 --> 00:08:23,759
the device receives the request it does

00:08:22,240 --> 00:08:24,560
whatever it needs to and then the cpu

00:08:23,759 --> 00:08:27,440
continues

00:08:24,560 --> 00:08:28,080
its execution and then in a very similar

00:08:27,440 --> 00:08:29,919
vein

00:08:28,080 --> 00:08:31,759
you know we're all used to programming

00:08:29,919 --> 00:08:33,760
with memory and using memory

00:08:31,759 --> 00:08:34,880
well parts of memory can actually be

00:08:33,760 --> 00:08:38,080
mapped to

00:08:34,880 --> 00:08:40,640
uh devices as well with memory mapped io

00:08:38,080 --> 00:08:41,360
and in these cases instead of when you

00:08:40,640 --> 00:08:44,080
read or write

00:08:41,360 --> 00:08:44,399
from those addresses um instead of them

00:08:44,080 --> 00:08:47,200
uh

00:08:44,399 --> 00:08:47,600
those requests hitting ram um they end

00:08:47,200 --> 00:08:50,640
up

00:08:47,600 --> 00:08:52,720
uh also getting routed to the vert to

00:08:50,640 --> 00:08:54,560
the devices and then the device again

00:08:52,720 --> 00:08:57,360
does whatever it needs to

00:08:54,560 --> 00:08:59,360
to um to handle that request and then

00:08:57,360 --> 00:09:01,600
the cpu continues execution

00:08:59,360 --> 00:09:02,640
and right off the bat there's um some

00:09:01,600 --> 00:09:06,160
complications here

00:09:02,640 --> 00:09:08,720
so for one

00:09:06,160 --> 00:09:09,600
a lot of these memory maps and port io

00:09:08,720 --> 00:09:12,240
regions

00:09:09,600 --> 00:09:14,320
aren't actually mapped uh as soon as you

00:09:12,240 --> 00:09:16,720
boot the machine you actually have to

00:09:14,320 --> 00:09:17,839
go through for example pci configuration

00:09:16,720 --> 00:09:20,720
to enable

00:09:17,839 --> 00:09:22,000
further memory regions so when you

00:09:20,720 --> 00:09:24,560
before you actually start

00:09:22,000 --> 00:09:25,519
running any code on the cpu you you have

00:09:24,560 --> 00:09:28,880
no idea

00:09:25,519 --> 00:09:30,800
when and where um a lot of these uh

00:09:28,880 --> 00:09:32,160
memory maps and port io regions are

00:09:30,800 --> 00:09:33,600
going to be so

00:09:32,160 --> 00:09:35,440
it's not something that's set in stone

00:09:33,600 --> 00:09:37,760
and they can they can

00:09:35,440 --> 00:09:40,480
shift around based on your interactions

00:09:37,760 --> 00:09:42,399
with the devices

00:09:40,480 --> 00:09:45,040
and then what it what makes this even

00:09:42,399 --> 00:09:47,760
worse is that there's actually a third

00:09:45,040 --> 00:09:48,480
mode of i o that's very commonly used

00:09:47,760 --> 00:09:51,040
and that's

00:09:48,480 --> 00:09:52,480
dma or direct memory access so the

00:09:51,040 --> 00:09:54,240
problem with poor io and memory mapped

00:09:52,480 --> 00:09:55,680
io is that for each you know binder set

00:09:54,240 --> 00:09:58,959
of bytes that you want to

00:09:55,680 --> 00:10:00,480
communicate to the device you have to uh

00:09:58,959 --> 00:10:02,640
you know the cpu has to run an

00:10:00,480 --> 00:10:04,240
instruction wait for uh

00:10:02,640 --> 00:10:07,040
wait for that request to go through and

00:10:04,240 --> 00:10:09,680
then you know uh run another instruction

00:10:07,040 --> 00:10:11,600
and and so forth so this is this really

00:10:09,680 --> 00:10:14,880
wastes a lot of the cpu's time and it's

00:10:11,600 --> 00:10:16,959
it's quite a slow um

00:10:14,880 --> 00:10:18,160
for high bandwidth applications such as

00:10:16,959 --> 00:10:20,640
you know network cards

00:10:18,160 --> 00:10:22,480
so for these uh cases we have direct

00:10:20,640 --> 00:10:24,720
memory access where

00:10:22,480 --> 00:10:25,839
instead of writing actual data to the

00:10:24,720 --> 00:10:27,680
devices

00:10:25,839 --> 00:10:29,200
uh all the cpu has to do is it writes

00:10:27,680 --> 00:10:31,519
the address and

00:10:29,200 --> 00:10:33,519
the length of or it just writes the

00:10:31,519 --> 00:10:36,079
address of some data to

00:10:33,519 --> 00:10:38,079
a virtual device or to a device over

00:10:36,079 --> 00:10:39,920
port ior memory map dio

00:10:38,079 --> 00:10:42,160
and then the device will asynchronously

00:10:39,920 --> 00:10:44,959
go ahead and read

00:10:42,160 --> 00:10:45,680
read the data from that data from memory

00:10:44,959 --> 00:10:47,200
um

00:10:45,680 --> 00:10:49,120
and then once it's done handling that

00:10:47,200 --> 00:10:52,079
for example it can uh

00:10:49,120 --> 00:10:53,279
like raise an interrupt or uh or uh

00:10:52,079 --> 00:10:55,519
something like that

00:10:53,279 --> 00:10:57,360
to communicate to the cpu that it's done

00:10:55,519 --> 00:10:58,079
processing that input so the cpu is free

00:10:57,360 --> 00:10:59,760
to

00:10:58,079 --> 00:11:01,680
run whatever code it needs to in the

00:10:59,760 --> 00:11:05,040
meantime and this is great for

00:11:01,680 --> 00:11:08,480
high bandwidth applications um such as

00:11:05,040 --> 00:11:10,160
network disk you know video um

00:11:08,480 --> 00:11:12,000
but this is also a nightmare for a

00:11:10,160 --> 00:11:15,360
fuzzer because it means that our

00:11:12,000 --> 00:11:18,240
input space encompasses all of memory

00:11:15,360 --> 00:11:19,120
all of memory basically and uh because

00:11:18,240 --> 00:11:21,040
of the

00:11:19,120 --> 00:11:23,600
pci mappings that i mentioned our input

00:11:21,040 --> 00:11:26,000
space also encompasses all port io

00:11:23,600 --> 00:11:26,880
so if we want to fuzz a virtual device

00:11:26,000 --> 00:11:30,160
we have to consider

00:11:26,880 --> 00:11:33,120
this entire input space um

00:11:30,160 --> 00:11:33,440
which is absolutely intractable for uh

00:11:33,120 --> 00:11:36,800
in

00:11:33,440 --> 00:11:38,560
an off-the-shelf the shelf of fuzzer

00:11:36,800 --> 00:11:40,160
considering that you know combine this

00:11:38,560 --> 00:11:42,000
can be gigabytes or even

00:11:40,160 --> 00:11:43,200
exabytes if you're talking about 64-bit

00:11:42,000 --> 00:11:46,880
machine

00:11:43,200 --> 00:11:48,000
of input space so this this is the main

00:11:46,880 --> 00:11:50,560
problem with buzzing

00:11:48,000 --> 00:11:51,120
um virtual devices on hypervisors is

00:11:50,560 --> 00:11:54,880
this

00:11:51,120 --> 00:11:56,560
huge input space and to sort of

00:11:54,880 --> 00:11:58,959
emphasize this point i want to briefly

00:11:56,560 --> 00:12:03,120
walk you through an actual bug that

00:11:58,959 --> 00:12:05,279
our uh fuzzer discovered um

00:12:03,120 --> 00:12:06,959
not sure why that tab is down there but

00:12:05,279 --> 00:12:10,720
um

00:12:06,959 --> 00:12:14,160
uh instead of actually trying to explain

00:12:10,720 --> 00:12:15,600
what it does i just copied an email that

00:12:14,160 --> 00:12:20,240
one of the developers that was fixing

00:12:15,600 --> 00:12:20,240
this bug in in this e1000 network card

00:12:20,880 --> 00:12:23,920
responded with to the original bug

00:12:22,800 --> 00:12:25,360
report so they say the bug

00:12:23,920 --> 00:12:27,760
is interesting which is probably you

00:12:25,360 --> 00:12:31,120
know as much praise as you can expect

00:12:27,760 --> 00:12:34,240
um when you're reporting a bug uh

00:12:31,120 --> 00:12:35,120
and uh and then on the left i have the

00:12:34,240 --> 00:12:37,200
actual

00:12:35,120 --> 00:12:38,959
port io and memory mapped io and memory

00:12:37,200 --> 00:12:41,040
instruction

00:12:38,959 --> 00:12:43,040
operations that lead up to the bug so

00:12:41,040 --> 00:12:45,680
first as i mentioned there's this

00:12:43,040 --> 00:12:47,279
pci controller that can map additional

00:12:45,680 --> 00:12:48,560
memory mapped io regions and that's

00:12:47,279 --> 00:12:51,440
basically what these

00:12:48,560 --> 00:12:53,519
instructions do and they lead to this

00:12:51,440 --> 00:12:56,720
memory mapped io region down here being

00:12:53,519 --> 00:12:57,120
created for the e1000 device and then

00:12:56,720 --> 00:12:58,560
once

00:12:57,120 --> 00:13:00,480
that's done we can start interacting

00:12:58,560 --> 00:13:03,360
with that memory mapped io region and

00:13:00,480 --> 00:13:06,639
and in this case we basically set up a

00:13:03,360 --> 00:13:08,160
packet transmission request um

00:13:06,639 --> 00:13:09,760
and you might notice that there's these

00:13:08,160 --> 00:13:11,360
purple regions that appeared well these

00:13:09,760 --> 00:13:15,279
are the dma

00:13:11,360 --> 00:13:18,399
uh these are two dma buffers that to

00:13:15,279 --> 00:13:20,639
actually reproduce this uh this bug

00:13:18,399 --> 00:13:21,920
um so these these could as well be

00:13:20,639 --> 00:13:23,200
anywhere in memory they could have been

00:13:21,920 --> 00:13:24,959
all the way over here it's just

00:13:23,200 --> 00:13:27,279
that the address that happened to be

00:13:24,959 --> 00:13:30,160
written up here in this instruction

00:13:27,279 --> 00:13:31,600
um provided this this particular

00:13:30,160 --> 00:13:35,360
location

00:13:31,600 --> 00:13:37,120
um so uh i actually drew this picture

00:13:35,360 --> 00:13:38,959
slightly and accurately because the bug

00:13:37,120 --> 00:13:41,519
entails the fact that uh is involves the

00:13:38,959 --> 00:13:44,959
fact that this region over here

00:13:41,519 --> 00:13:47,120
actually overlaps the devices the e1000

00:13:44,959 --> 00:13:49,920
devices memory mapped io region so

00:13:47,120 --> 00:13:51,760
when the e1000 tries to write to this

00:13:49,920 --> 00:13:52,639
dma buffer it actually ends up writing

00:13:51,760 --> 00:13:54,880
to its own

00:13:52,639 --> 00:13:55,920
memory mapped io region triggering a

00:13:54,880 --> 00:13:58,320
reentrancy bug

00:13:55,920 --> 00:13:59,680
and basically it ends up freeing some

00:13:58,320 --> 00:14:02,160
resources that

00:13:59,680 --> 00:14:04,639
uh that that we're still in use causing

00:14:02,160 --> 00:14:08,240
a uh use after free bug

00:14:04,639 --> 00:14:11,680
um so i guess the takeaway here is that

00:14:08,240 --> 00:14:14,839
we needed to rely on all three um

00:14:11,680 --> 00:14:16,160
modes of io in order to reproduce this

00:14:14,839 --> 00:14:17,920
bug

00:14:16,160 --> 00:14:19,760
in order to generate this bug and also

00:14:17,920 --> 00:14:20,560
if you just look at like these addresses

00:14:19,760 --> 00:14:22,959
here

00:14:20,560 --> 00:14:24,560
um there's the it just emphasizes that

00:14:22,959 --> 00:14:26,639
the input space is enormous the

00:14:24,560 --> 00:14:29,760
the actual addresses we write to are

00:14:26,639 --> 00:14:33,279
only a tiny tiny fraction of

00:14:29,760 --> 00:14:34,880
all of the possible addresses and

00:14:33,279 --> 00:14:36,639
the fuzzer generated from this from

00:14:34,880 --> 00:14:38,560
scratch uh

00:14:36,639 --> 00:14:40,000
and so this is sort of what the crashing

00:14:38,560 --> 00:14:41,760
trace looks like as i said this is a

00:14:40,000 --> 00:14:43,040
reentrancy bug so down right here we

00:14:41,760 --> 00:14:46,399
have this segment of

00:14:43,040 --> 00:14:46,959
e1000 e code and then and then there was

00:14:46,399 --> 00:14:48,959
this

00:14:46,959 --> 00:14:50,399
dma access that i mentioned and that

00:14:48,959 --> 00:14:53,279
leads to another nested

00:14:50,399 --> 00:14:55,120
mmio access leading to a use after free

00:14:53,279 --> 00:14:57,279
button

00:14:55,120 --> 00:14:58,560
so if you want to tackle this enormous

00:14:57,279 --> 00:15:02,639
input space

00:14:58,560 --> 00:15:04,480
how do we do this we are um we

00:15:02,639 --> 00:15:06,320
let well first let's look at the port io

00:15:04,480 --> 00:15:08,560
and mmio part of the equations

00:15:06,320 --> 00:15:09,440
how do hypervisors even implement port

00:15:08,560 --> 00:15:12,160
io and

00:15:09,440 --> 00:15:13,040
memory mapped io well when a guest when

00:15:12,160 --> 00:15:15,440
the guest cpu

00:15:13,040 --> 00:15:16,880
or the guest tries to access normal

00:15:15,440 --> 00:15:18,880
locations and ram

00:15:16,880 --> 00:15:21,279
um that goes through fine right there's

00:15:18,880 --> 00:15:24,560
no the hypervisor doesn't take over to

00:15:21,279 --> 00:15:26,880
service those requests generally um

00:15:24,560 --> 00:15:28,399
but with one what we could want to do

00:15:26,880 --> 00:15:29,680
with memory mapped ios instead of

00:15:28,399 --> 00:15:31,519
letting the device

00:15:29,680 --> 00:15:32,800
just read or write from that location in

00:15:31,519 --> 00:15:35,199
ram or

00:15:32,800 --> 00:15:36,240
memory or even worse like the underlying

00:15:35,199 --> 00:15:39,279
privileged device

00:15:36,240 --> 00:15:42,079
we want to intercept that request and

00:15:39,279 --> 00:15:43,199
handle it in the virtual device code so

00:15:42,079 --> 00:15:45,279
what the hypervisor

00:15:43,199 --> 00:15:46,639
can do is for example unmap the pages

00:15:45,279 --> 00:15:50,000
that correspond to the

00:15:46,639 --> 00:15:52,560
mmio range and so when when you do that

00:15:50,000 --> 00:15:54,160
um when when you access a address in

00:15:52,560 --> 00:15:57,120
mmio from the guest

00:15:54,160 --> 00:15:58,480
you uh you trap into the hypervisor's

00:15:57,120 --> 00:16:00,560
code

00:15:58,480 --> 00:16:01,519
and then the hypervisor can inspect you

00:16:00,560 --> 00:16:05,519
know what address

00:16:01,519 --> 00:16:08,880
led to the trap and um inspect

00:16:05,519 --> 00:16:10,639
the the access um and

00:16:08,880 --> 00:16:12,399
identify you know what what virtual

00:16:10,639 --> 00:16:14,399
device code it needs to run in order to

00:16:12,399 --> 00:16:16,880
service their request

00:16:14,399 --> 00:16:18,079
and uh the key thing here is that the

00:16:16,880 --> 00:16:21,360
hypervisor needs to be

00:16:18,079 --> 00:16:23,279
needs to keep this mapping of guest uh

00:16:21,360 --> 00:16:25,279
to guest physical from guest physical

00:16:23,279 --> 00:16:28,399
addresses to virtual device

00:16:25,279 --> 00:16:30,800
uh handlers right um and it does this in

00:16:28,399 --> 00:16:33,440
in something like a table

00:16:30,800 --> 00:16:35,360
and the the hypervisor needs this to to

00:16:33,440 --> 00:16:38,480
perform any mmo functionality

00:16:35,360 --> 00:16:41,120
or or poor i o functionality um so

00:16:38,480 --> 00:16:42,560
what we can do is as the puzzlers we can

00:16:41,120 --> 00:16:45,199
just keep track of this table

00:16:42,560 --> 00:16:46,000
and if we if we keep track of this table

00:16:45,199 --> 00:16:49,360
we always have an

00:16:46,000 --> 00:16:50,000
accurate representation of um the port i

00:16:49,360 --> 00:16:53,199
o and the memory

00:16:50,000 --> 00:16:56,480
mapped io regions um on on the

00:16:53,199 --> 00:16:58,160
guest that was partly on memory mapped

00:16:56,480 --> 00:16:59,199
io the more complicated one i think the

00:16:58,160 --> 00:17:02,000
more interesting

00:16:59,199 --> 00:17:03,839
one is uh direct memory access right so

00:17:02,000 --> 00:17:05,199
there's no table of direct memory access

00:17:03,839 --> 00:17:08,400
regions because they could

00:17:05,199 --> 00:17:11,600
be anywhere in memory

00:17:08,400 --> 00:17:12,400
but remember so how the how dma works is

00:17:11,600 --> 00:17:16,480
usually

00:17:12,400 --> 00:17:19,600
the cpu writes uh some

00:17:16,480 --> 00:17:21,439
some uh address of a dma region

00:17:19,600 --> 00:17:23,120
overpower io memory map data and then

00:17:21,439 --> 00:17:24,400
eventually the device decides okay i

00:17:23,120 --> 00:17:28,880
need to fetch this device

00:17:24,400 --> 00:17:32,880
this this buffer over uh over dma

00:17:28,880 --> 00:17:34,720
and when it does that um it uh

00:17:32,880 --> 00:17:36,160
it can't just dereference a pointer pass

00:17:34,720 --> 00:17:38,320
from the guest right because

00:17:36,160 --> 00:17:39,360
the the address space of the hypervisor

00:17:38,320 --> 00:17:41,120
is completely

00:17:39,360 --> 00:17:42,640
different from you know what the what

00:17:41,120 --> 00:17:45,679
the guest view of

00:17:42,640 --> 00:17:46,080
of the address space is so it needs to

00:17:45,679 --> 00:17:48,080
somehow

00:17:46,080 --> 00:17:49,440
convert the address that it gets from

00:17:48,080 --> 00:17:53,280
the guest into

00:17:49,440 --> 00:17:55,840
an ad into an address or access into a

00:17:53,280 --> 00:17:57,200
buffer that i can actually reach from

00:17:55,840 --> 00:17:59,919
the context of

00:17:57,200 --> 00:18:02,000
the hypervisor and to do this

00:17:59,919 --> 00:18:03,039
hypervisors generally implement a memory

00:18:02,000 --> 00:18:06,000
access api so

00:18:03,039 --> 00:18:06,799
qmu implements a set of functions that

00:18:06,000 --> 00:18:08,480
are

00:18:06,799 --> 00:18:10,000
convenient to use for virtual device

00:18:08,480 --> 00:18:13,360
developers to

00:18:10,000 --> 00:18:16,640
just read or write some data to a from a

00:18:13,360 --> 00:18:18,640
dma location in guest memory and

00:18:16,640 --> 00:18:20,320
of course you probably know what's

00:18:18,640 --> 00:18:23,440
coming already

00:18:20,320 --> 00:18:26,559
yes the fuzzer can hook these

00:18:23,440 --> 00:18:29,120
memory accesses this memory access api

00:18:26,559 --> 00:18:29,679
and in fact what it can do is uh

00:18:29,120 --> 00:18:32,720
interrupt

00:18:29,679 --> 00:18:34,240
execution uh or intercept the execution

00:18:32,720 --> 00:18:36,880
of the memory access api

00:18:34,240 --> 00:18:37,440
and make sure that there's some fuzz

00:18:36,880 --> 00:18:40,559
fuzzed

00:18:37,440 --> 00:18:44,640
data um at the location that the

00:18:40,559 --> 00:18:46,480
api is about to access before it um

00:18:44,640 --> 00:18:48,080
returns execution to the memory access

00:18:46,480 --> 00:18:50,480
api so

00:18:48,080 --> 00:18:51,120
when a device accesses some data over

00:18:50,480 --> 00:18:53,280
dma

00:18:51,120 --> 00:18:55,039
the fuzzer takes over execution quickly

00:18:53,280 --> 00:18:57,679
fills in that region

00:18:55,039 --> 00:18:58,480
with randomized data and then gives

00:18:57,679 --> 00:19:00,960
access back

00:18:58,480 --> 00:19:02,640
or gives execution control back to the

00:19:00,960 --> 00:19:03,520
memory access api so it can read that

00:19:02,640 --> 00:19:08,240
data

00:19:03,520 --> 00:19:11,440
and um and as if it was always there

00:19:08,240 --> 00:19:12,960
so to to bring this all together we we

00:19:11,440 --> 00:19:15,760
hook into these two

00:19:12,960 --> 00:19:17,280
um uh hyper essential hypervisory

00:19:15,760 --> 00:19:20,080
constructs so we have this

00:19:17,280 --> 00:19:21,120
table of port ion mmio regions and the

00:19:20,080 --> 00:19:23,760
dma access

00:19:21,120 --> 00:19:25,919
api and then we have a interpreter

00:19:23,760 --> 00:19:26,720
basically for all of our fuzzed inputs

00:19:25,919 --> 00:19:30,160
where we

00:19:26,720 --> 00:19:32,880
where we interpret uh fuzzer input

00:19:30,160 --> 00:19:34,799
fuzzer generated random data into port i

00:19:32,880 --> 00:19:37,600
o and memory mapped io instructions

00:19:34,799 --> 00:19:38,400
and then when a device eventually tries

00:19:37,600 --> 00:19:41,919
to perform

00:19:38,400 --> 00:19:45,120
a mm-io a dma access

00:19:41,919 --> 00:19:46,240
we uh use some of the fuzzer-provided

00:19:45,120 --> 00:19:49,520
data to

00:19:46,240 --> 00:19:52,559
uh fill uh that dma region in

00:19:49,520 --> 00:19:55,120
just in time uh

00:19:52,559 --> 00:19:56,559
and eventually uh we will find some

00:19:55,120 --> 00:19:59,120
crashes because

00:19:56,559 --> 00:19:59,919
uh this this way we we can guarantee

00:19:59,120 --> 00:20:02,720
that

00:19:59,919 --> 00:20:03,120
each uh byte inside the fuzzer provided

00:20:02,720 --> 00:20:06,240
input

00:20:03,120 --> 00:20:07,760
is gonna directly uh impact a virtual

00:20:06,240 --> 00:20:10,640
device in some way we're not

00:20:07,760 --> 00:20:12,080
we're not at risk of wasting uh fuzzer

00:20:10,640 --> 00:20:13,600
provided data on you know

00:20:12,080 --> 00:20:15,919
writing to ram that's not going to be

00:20:13,600 --> 00:20:18,080
used for anything or writing to

00:20:15,919 --> 00:20:20,480
a port io address that isn't mapped to

00:20:18,080 --> 00:20:23,200
any virtual device

00:20:20,480 --> 00:20:24,080
so finally one thing that we want to do

00:20:23,200 --> 00:20:26,240
is you know we

00:20:24,080 --> 00:20:27,600
hypervisors don't normally have this

00:20:26,240 --> 00:20:30,159
like just in time

00:20:27,600 --> 00:20:31,840
dma functionality that we use so what we

00:20:30,159 --> 00:20:34,880
can do is we can actually

00:20:31,840 --> 00:20:35,760
collect a when we find a crash with our

00:20:34,880 --> 00:20:38,960
fuzzer

00:20:35,760 --> 00:20:41,760
we can reorder the uh

00:20:38,960 --> 00:20:42,559
order the commands so that the uh any

00:20:41,760 --> 00:20:45,200
dma

00:20:42,559 --> 00:20:46,320
uh just-in-time commands will directly

00:20:45,200 --> 00:20:50,159
proceed

00:20:46,320 --> 00:20:53,520
the uh pre the prior um

00:20:50,159 --> 00:20:55,840
port a or mmio request so that way

00:20:53,520 --> 00:20:56,559
um when you rearrange it this way by the

00:20:55,840 --> 00:20:58,880
time

00:20:56,559 --> 00:20:59,679
the request that triggers the dma access

00:20:58,880 --> 00:21:02,720
executes

00:20:59,679 --> 00:21:05,840
it's as if the dma data had already been

00:21:02,720 --> 00:21:08,880
there the whole time so

00:21:05,840 --> 00:21:11,280
um we implemented this for a qmu

00:21:08,880 --> 00:21:12,720
and as we were doing this we kept track

00:21:11,280 --> 00:21:14,320
of you know the coverage that we achieve

00:21:12,720 --> 00:21:16,960
over various devices

00:21:14,320 --> 00:21:18,000
and we could zoom in on individual lines

00:21:16,960 --> 00:21:20,080
and to see you know

00:21:18,000 --> 00:21:21,520
how to how to improve our fuzzer and

00:21:20,080 --> 00:21:23,039
this was eventually the technique that

00:21:21,520 --> 00:21:24,799
we came to

00:21:23,039 --> 00:21:26,480
and because of the way that our fuzzer

00:21:24,799 --> 00:21:28,960
functions um it's

00:21:26,480 --> 00:21:30,720
very easy for the developer to reproduce

00:21:28,960 --> 00:21:31,200
a crash and that was a big focus as we

00:21:30,720 --> 00:21:34,159
were

00:21:31,200 --> 00:21:35,039
designing this so when i when we do find

00:21:34,159 --> 00:21:36,880
a crash

00:21:35,039 --> 00:21:38,080
we can actually send it to the developer

00:21:36,880 --> 00:21:40,799
by email

00:21:38,080 --> 00:21:42,720
and they can just copy and paste it into

00:21:40,799 --> 00:21:44,320
their existing build of qmu

00:21:42,720 --> 00:21:46,720
to reproduce the crash immediately and

00:21:44,320 --> 00:21:49,840
they can see exactly which

00:21:46,720 --> 00:21:53,840
uh port io mmi and

00:21:49,840 --> 00:21:53,840
dma requests led up to the crash

00:21:54,000 --> 00:22:00,159
um so we've

00:21:57,360 --> 00:22:01,520
already found reported and fixed bugs in

00:22:00,159 --> 00:22:04,799
a wide range of

00:22:01,520 --> 00:22:08,400
uh network devices graphics devices uh

00:22:04,799 --> 00:22:12,400
audio devices and um

00:22:08,400 --> 00:22:14,960
there we've reported over 60 60 bugs um

00:22:12,400 --> 00:22:17,440
there we there's i think six tvs

00:22:14,960 --> 00:22:20,960
associated with bugs that we've reported

00:22:17,440 --> 00:22:22,480
uh up to date um and

00:22:20,960 --> 00:22:25,840
most of our work is actually already

00:22:22,480 --> 00:22:28,240
upstream within qmu

00:22:25,840 --> 00:22:29,120
and because qmu is such a popular

00:22:28,240 --> 00:22:31,919
hypervisor

00:22:29,120 --> 00:22:34,640
um our work directly benefits a lot of

00:22:31,919 --> 00:22:36,880
projects that depend on qmu

00:22:34,640 --> 00:22:38,240
and because qmu is open source we can

00:22:36,880 --> 00:22:39,600
also take advantage of programs such as

00:22:38,240 --> 00:22:42,320
oss fuzz so

00:22:39,600 --> 00:22:43,280
as i'm giving this talk right now our

00:22:42,320 --> 00:22:45,760
the qmu

00:22:43,280 --> 00:22:46,720
code is being fuzzed in real time on the

00:22:45,760 --> 00:22:49,760
cloud somewhere

00:22:46,720 --> 00:22:51,840
and bugs are being found um

00:22:49,760 --> 00:22:53,360
and as as soon as new code gets

00:22:51,840 --> 00:22:55,760
committed to qmu

00:22:53,360 --> 00:22:58,559
we we fuzzed that code as well to catch

00:22:55,760 --> 00:23:01,360
bugs as soon as possible

00:22:58,559 --> 00:23:02,320
uh that was my talk i'd like to give a

00:23:01,360 --> 00:23:05,760
huge thank you to

00:23:02,320 --> 00:23:06,320
everybody um who reviewed my code and

00:23:05,760 --> 00:23:08,880
helped me

00:23:06,320 --> 00:23:10,480
come up with uh various techniques for

00:23:08,880 --> 00:23:12,720
fuzzing virtual devices

00:23:10,480 --> 00:23:13,760
i'd never be able to do this without my

00:23:12,720 --> 00:23:16,080
mentors and

00:23:13,760 --> 00:23:17,039
the rest of the qmu community i think

00:23:16,080 --> 00:23:19,919
that um

00:23:17,039 --> 00:23:21,039
the takeaways from this work can also be

00:23:19,919 --> 00:23:24,080
applied to

00:23:21,039 --> 00:23:27,200
a lot of kernel fuzzing and even

00:23:24,080 --> 00:23:28,320
stuff like browser fuzzing efforts um

00:23:27,200 --> 00:23:30,159
if you thought this was interesting

00:23:28,320 --> 00:23:31,280
you'd like to talk more here are my

00:23:30,159 --> 00:23:37,840
contact details

00:23:31,280 --> 00:23:37,840
below and uh that'll uh end my talk

00:23:40,880 --> 00:23:47,679
thank you for the amazing talk alex

00:23:44,240 --> 00:23:48,880
folks feel free to um put your questions

00:23:47,679 --> 00:23:50,799
down in chat

00:23:48,880 --> 00:23:53,360
or you can also carry on the

00:23:50,799 --> 00:23:57,840
conversation in the breakout room

00:23:53,360 --> 00:23:57,840
the link to which i just posted in chat

00:24:00,320 --> 00:24:04,559
okay i guess i'll go to the breakout

00:24:02,400 --> 00:24:08,159
room then andrea thank you

00:24:04,559 --> 00:24:08,159

YouTube URL: https://www.youtube.com/watch?v=LspS3K3oxAE


