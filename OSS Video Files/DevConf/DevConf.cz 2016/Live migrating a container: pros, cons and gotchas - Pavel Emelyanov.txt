Title: Live migrating a container: pros, cons and gotchas - Pavel Emelyanov
Publication date: 2016-02-11
Playlist: DevConf.cz 2016
Description: 
	In this talk I will show why you might want to live migrate a container,
why you might want to avoid doing this and what can be done instead. 

Presentation: http://bit.ly/1QbZkOL
I will also demonstrate why live migrating a container is more complex than live migrating a virtual machines, what can be done with this complexity and what we currently do with it in CRIU and P.Haul projects.
Captions: 
	00:00:00,000 --> 00:00:02,030
I

00:02:19,530 --> 00:02:32,640
oh oh ok let's start and let's welcome

00:02:24,849 --> 00:02:37,330
that's our next speaker panel yeah well

00:02:32,640 --> 00:02:40,720
I work for the chosen which other is a

00:02:37,330 --> 00:02:43,150
new name of my current employer we used

00:02:40,720 --> 00:02:48,760
to be called parallels you probably know

00:02:43,150 --> 00:02:52,750
as we did and still do the open easy

00:02:48,760 --> 00:02:55,599
project one of the feature of which is a

00:02:52,750 --> 00:02:59,769
continuous live migration and this is

00:02:55,599 --> 00:03:02,920
what I'm going to talk about today so

00:02:59,769 --> 00:03:07,120
the dog will be about why someone might

00:03:02,920 --> 00:03:09,940
want to live my great the container why

00:03:07,120 --> 00:03:12,549
someone want to avoid doing this because

00:03:09,940 --> 00:03:17,739
light migrate in a container is a tricky

00:03:12,549 --> 00:03:22,690
task and how tricky it is and why it's

00:03:17,739 --> 00:03:24,489
really tricky most of you probably know

00:03:22,690 --> 00:03:26,230
that light migration of for example

00:03:24,489 --> 00:03:29,799
virtual machines doesn't seem to be that

00:03:26,230 --> 00:03:33,370
complex so during my talk I will refer

00:03:29,799 --> 00:03:37,480
to a virtual machine sometimes just for

00:03:33,370 --> 00:03:41,349
comparison to see the complexity of

00:03:37,480 --> 00:03:43,450
containers live migration so live

00:03:41,349 --> 00:03:45,190
migration is quite simple it's pretty

00:03:43,450 --> 00:03:47,470
much like teleportation you take an

00:03:45,190 --> 00:03:50,799
object in our case it's a container you

00:03:47,470 --> 00:03:54,069
get it state send it to the place you

00:03:50,799 --> 00:03:59,260
want it to have live migrated to and

00:03:54,069 --> 00:04:03,489
then restore the object back that in a

00:03:59,260 --> 00:04:08,530
few words it's pretty simple people use

00:04:03,489 --> 00:04:10,329
it for several reasons examples are for

00:04:08,530 --> 00:04:13,630
example for load balancing if you have a

00:04:10,329 --> 00:04:16,329
cluster of nodes which run jobs and you

00:04:13,630 --> 00:04:19,120
cannot restore a job easily and one of

00:04:16,329 --> 00:04:22,120
the node becomes overloaded with with

00:04:19,120 --> 00:04:25,630
tasks you can take some of them and move

00:04:22,120 --> 00:04:30,430
to another hardware nodes to buy

00:04:25,630 --> 00:04:32,860
a lot between them another usage

00:04:30,430 --> 00:04:36,460
scenario for life migration is to update

00:04:32,860 --> 00:04:40,090
the colonel it works pretty simple you

00:04:36,460 --> 00:04:42,460
make a hardware not free from critical

00:04:40,090 --> 00:04:44,920
workloads from containers or from

00:04:42,460 --> 00:04:46,710
virtual machines by moving them to

00:04:44,920 --> 00:04:50,410
another nodes of course you need a

00:04:46,710 --> 00:04:52,090
cluster to do that then you booty not

00:04:50,410 --> 00:04:55,300
into a new kernel and then you can

00:04:52,090 --> 00:04:59,410
either rely on your balancer to balance

00:04:55,300 --> 00:05:03,280
the workload back or move the load back

00:04:59,410 --> 00:05:08,820
manually this case can actually be done

00:05:03,280 --> 00:05:12,820
without real live migration you can

00:05:08,820 --> 00:05:15,430
there is a technology using the saving

00:05:12,820 --> 00:05:17,950
state in restoring state that can

00:05:15,430 --> 00:05:20,260
replace the colonel on the running not

00:05:17,950 --> 00:05:25,540
without actually live migrating but

00:05:20,260 --> 00:05:27,250
still updating the colonel uses the very

00:05:25,540 --> 00:05:30,400
core technology that save states and

00:05:27,250 --> 00:05:32,920
restored states of containers the third

00:05:30,400 --> 00:05:36,220
example is to upgrade or replace

00:05:32,920 --> 00:05:38,230
hardware it's the same as with updating

00:05:36,220 --> 00:05:39,940
the colonel but in this case you cannot

00:05:38,230 --> 00:05:42,460
avoid doing real life migration because

00:05:39,940 --> 00:05:45,100
you have to power down the node and in

00:05:42,460 --> 00:05:47,290
the end it just looks great when you

00:05:45,100 --> 00:05:49,330
know that there are two servers and you

00:05:47,290 --> 00:05:51,070
so container on one of them and you

00:05:49,330 --> 00:05:56,440
press the button and then you see it on

00:05:51,070 --> 00:05:59,920
another it looks cool the technology is

00:05:56,440 --> 00:06:02,710
nice but sometimes people would like to

00:05:59,920 --> 00:06:04,870
avoid live migration because it's really

00:06:02,710 --> 00:06:09,040
complex and just like in case of

00:06:04,870 --> 00:06:13,720
teleportation sound weird or unwanted

00:06:09,040 --> 00:06:15,670
results can be achieved and if you want

00:06:13,720 --> 00:06:19,450
a word live migration there are options

00:06:15,670 --> 00:06:22,150
how to do that for example you can try

00:06:19,450 --> 00:06:24,760
to balance not a load on your cluster

00:06:22,150 --> 00:06:28,480
but the cause of that load for example

00:06:24,760 --> 00:06:29,950
if you have web servers that generate

00:06:28,480 --> 00:06:31,600
load is response in the traffic that

00:06:29,950 --> 00:06:33,640
they receive you can try to balance a

00:06:31,600 --> 00:06:36,190
traffic itself like redirecting coming

00:06:33,640 --> 00:06:38,080
requests on different nodes and hope

00:06:36,190 --> 00:06:41,620
that

00:06:38,080 --> 00:06:45,460
different requests will cause like equal

00:06:41,620 --> 00:06:46,960
workload on the servers another way to

00:06:45,460 --> 00:06:50,110
add live migration is to use

00:06:46,960 --> 00:06:53,020
microservices circuit architecture this

00:06:50,110 --> 00:06:55,960
is when your application is written so

00:06:53,020 --> 00:07:00,340
that it can be shut down at any time and

00:06:55,960 --> 00:07:02,590
started probably anywhere else with this

00:07:00,340 --> 00:07:06,009
architecture you can load balance

00:07:02,590 --> 00:07:08,139
without live migration just by keeping

00:07:06,009 --> 00:07:13,810
the necessary amount of your application

00:07:08,139 --> 00:07:17,680
on the list loaded hardware nodes get

00:07:13,810 --> 00:07:20,979
another way not to live migration it's

00:07:17,680 --> 00:07:24,810
the last two cases are about updating

00:07:20,979 --> 00:07:27,400
the hardware or the colonel on the nodes

00:07:24,810 --> 00:07:30,009
first way is how we call it a crash

00:07:27,400 --> 00:07:32,379
driven update we see some people doing

00:07:30,009 --> 00:07:35,110
this they continue running all the

00:07:32,379 --> 00:07:36,789
colonel until it crashed hang and once

00:07:35,110 --> 00:07:39,490
it does so they have to reboot them out

00:07:36,789 --> 00:07:41,349
anyway so they just rebooted into a new

00:07:39,490 --> 00:07:47,409
kernel which should be pre-installed of

00:07:41,349 --> 00:07:52,259
course on them it works people use it it

00:07:47,409 --> 00:07:56,889
might not be very nice wet still and the

00:07:52,259 --> 00:07:59,159
a nicer option of doing updates without

00:07:56,889 --> 00:08:03,000
life immigration is to do plan downtime

00:07:59,159 --> 00:08:06,009
like you can send an email to people

00:08:03,000 --> 00:08:09,610
running workloads on your notes and say

00:08:06,009 --> 00:08:12,819
that guy's within by the end of this

00:08:09,610 --> 00:08:15,520
week we will power down notes

00:08:12,819 --> 00:08:18,310
sequentially so get prepared maybe move

00:08:15,520 --> 00:08:25,659
your clothes manually or just live for

00:08:18,310 --> 00:08:31,270
several minutes without them so let's

00:08:25,659 --> 00:08:33,729
now see into the live migration into

00:08:31,270 --> 00:08:41,349
details to find out what why it's really

00:08:33,729 --> 00:08:43,479
complex so live migration Eva taking it

00:08:41,349 --> 00:08:46,000
simple as I told it consists of list of

00:08:43,479 --> 00:08:47,829
three steps steps you get a state of a

00:08:46,000 --> 00:08:49,880
container then copy to another node and

00:08:47,829 --> 00:08:52,610
restore back

00:08:49,880 --> 00:08:54,290
one important thing that worth

00:08:52,610 --> 00:08:55,550
mentioning is that before getting to the

00:08:54,290 --> 00:08:58,400
state of a container the container

00:08:55,550 --> 00:09:03,200
should be frozen because we should get

00:08:58,400 --> 00:09:05,300
the state which is correct from the

00:09:03,200 --> 00:09:08,540
container point of view we cannot take

00:09:05,300 --> 00:09:11,810
States of individual processes while

00:09:08,540 --> 00:09:15,260
letting them run as we do it because in

00:09:11,810 --> 00:09:18,290
this case this stage we get might be not

00:09:15,260 --> 00:09:20,990
consistent with each other of course

00:09:18,290 --> 00:09:23,480
there is a theoretical possibilities

00:09:20,990 --> 00:09:25,730
that we take processes and containers

00:09:23,480 --> 00:09:27,890
are processes and life my great

00:09:25,730 --> 00:09:31,190
individual processes from one node to

00:09:27,890 --> 00:09:33,050
another one by one but that's quite a

00:09:31,190 --> 00:09:35,300
complex technology in this case what we

00:09:33,050 --> 00:09:38,930
effectively get is a container that is

00:09:35,300 --> 00:09:41,800
scattered between two nodes and there is

00:09:38,930 --> 00:09:44,930
no alive implementation of that so to

00:09:41,800 --> 00:09:48,530
get the correct state we freeze the

00:09:44,930 --> 00:09:50,660
whole container then we read it copy to

00:09:48,530 --> 00:09:53,120
another node and restore it back then

00:09:50,660 --> 00:09:57,110
unfreeze and clean up on the on the

00:09:53,120 --> 00:09:59,270
source side the critical parameter of

00:09:57,110 --> 00:10:01,520
this process is called the frozen time

00:09:59,270 --> 00:10:04,940
it's the time between the container gets

00:10:01,520 --> 00:10:06,370
frozen and the moment we unfreeze the

00:10:04,940 --> 00:10:08,630
container because this is what people

00:10:06,370 --> 00:10:11,300
care the most when a live mcgrady

00:10:08,630 --> 00:10:14,720
container if you work with it why the

00:10:11,300 --> 00:10:17,570
network typically people work with

00:10:14,720 --> 00:10:19,040
containers why the network when the

00:10:17,570 --> 00:10:22,610
container has been life migrated to you

00:10:19,040 --> 00:10:24,650
will notice it as a small slowdown of

00:10:22,610 --> 00:10:27,500
your operations like the network will

00:10:24,650 --> 00:10:29,600
seem to get stuck for several seconds or

00:10:27,500 --> 00:10:32,540
that the time the container is in

00:10:29,600 --> 00:10:34,690
migrated for so the smaller the frozen

00:10:32,540 --> 00:10:40,670
time is the better live migration is and

00:10:34,690 --> 00:10:42,710
to reduce the Freestyle there are

00:10:40,670 --> 00:10:45,770
several options first of all we can try

00:10:42,710 --> 00:10:50,230
to make getting the state and restoring

00:10:45,770 --> 00:10:52,550
from state faster but the truth is

00:10:50,230 --> 00:10:55,190
getting the state in restoring the state

00:10:52,550 --> 00:10:56,810
are two operations that I extremely hard

00:10:55,190 --> 00:10:59,510
to optimize because they consist of

00:10:56,810 --> 00:11:02,120
fix-it steps which should be performed

00:10:59,510 --> 00:11:03,379
like container has several processes

00:11:02,120 --> 00:11:05,299
each of them has to

00:11:03,379 --> 00:11:08,299
analyzed for each of them this stage

00:11:05,299 --> 00:11:10,660
should be red and there is not there is

00:11:08,299 --> 00:11:15,259
no much room for optimization they're

00:11:10,660 --> 00:11:17,599
the biggest amount of the biggest

00:11:15,259 --> 00:11:20,389
portion in this frozen time is actually

00:11:17,599 --> 00:11:23,769
the time that takes what the state get

00:11:20,389 --> 00:11:29,899
transferred from one node to another and

00:11:23,769 --> 00:11:32,989
for most of the cases we've seen so far

00:11:29,899 --> 00:11:36,049
more than ninety percent of the state

00:11:32,989 --> 00:11:38,509
contents is it is the contents of the

00:11:36,049 --> 00:11:40,549
memory that process use it's not

00:11:38,509 --> 00:11:43,429
information about how much process we

00:11:40,549 --> 00:11:46,669
have what are the open files information

00:11:43,429 --> 00:11:49,009
about connections all these stuff is

00:11:46,669 --> 00:11:51,159
like less than ten percent it gets

00:11:49,009 --> 00:11:54,739
transferred within fractions of seconds

00:11:51,159 --> 00:11:59,269
ninety percent is whatever data sits in

00:11:54,739 --> 00:12:01,369
the process memory so if we can move the

00:11:59,269 --> 00:12:03,919
memory transfer out of the frozen time

00:12:01,369 --> 00:12:07,339
we can shrink it significantly without

00:12:03,919 --> 00:12:12,470
even trying to optimize the save state

00:12:07,339 --> 00:12:15,439
and restore state stages and likely we

00:12:12,470 --> 00:12:17,449
can do two tricks with the process

00:12:15,439 --> 00:12:22,069
memory first of all we can effectively

00:12:17,449 --> 00:12:24,470
track which memory pages are changing

00:12:22,069 --> 00:12:26,959
over the time we can request the kernel

00:12:24,470 --> 00:12:31,100
for that information and the second

00:12:26,959 --> 00:12:34,100
thing is that we at least in theory but

00:12:31,100 --> 00:12:37,220
I'll get back to this later now they so

00:12:34,100 --> 00:12:40,399
in practice we can restore process

00:12:37,220 --> 00:12:44,389
actually without any memory and restore

00:12:40,399 --> 00:12:46,959
the memory on demand while the process

00:12:44,389 --> 00:12:50,959
starts to request particular areas of it

00:12:46,959 --> 00:12:54,949
so to move the memory transfer out of

00:12:50,959 --> 00:12:57,979
the frozen time there are two ways the

00:12:54,949 --> 00:13:01,839
first is called memory precoding is

00:12:57,979 --> 00:13:03,919
pretty simple we turn the memory tracker

00:13:01,839 --> 00:13:05,859
memory changes check your own in the

00:13:03,919 --> 00:13:08,359
kernel and then start popping the

00:13:05,859 --> 00:13:12,289
containers memory to the destination

00:13:08,359 --> 00:13:14,940
node without freezing the processes this

00:13:12,289 --> 00:13:16,530
step is called iteration

00:13:14,940 --> 00:13:20,490
once we've copied all the memory we can

00:13:16,530 --> 00:13:22,140
either do what we did before that is

00:13:20,490 --> 00:13:23,640
freezer container get estate but this

00:13:22,140 --> 00:13:26,040
time without a memory because we has

00:13:23,640 --> 00:13:28,320
transferred it copy it restore and the

00:13:26,040 --> 00:13:30,600
container is migrated all we can say

00:13:28,320 --> 00:13:33,240
that the amount of memory that has

00:13:30,600 --> 00:13:35,820
changed while we've been coping it is

00:13:33,240 --> 00:13:38,130
still too big we would like to try one

00:13:35,820 --> 00:13:40,350
more iteration so we reset a change

00:13:38,130 --> 00:13:44,490
tracker copy what has changed from the

00:13:40,350 --> 00:13:49,320
previous time and do it again in this

00:13:44,490 --> 00:13:52,080
time in this case this live migration

00:13:49,320 --> 00:13:54,660
would be safe so once it finished you

00:13:52,080 --> 00:13:56,250
can be sure that your container is alive

00:13:54,660 --> 00:13:58,050
and it's fully present on the

00:13:56,250 --> 00:14:02,520
destination note you can just power down

00:13:58,050 --> 00:14:05,430
the source and the container will still

00:14:02,520 --> 00:14:08,220
be alive it has no ties to the source

00:14:05,430 --> 00:14:11,340
node that's that's a good side of the

00:14:08,220 --> 00:14:14,880
pre copy what's bad about pre coping

00:14:11,340 --> 00:14:16,830
memories that it's unpredictable there

00:14:14,880 --> 00:14:18,540
is no reliable way to predict how much

00:14:16,830 --> 00:14:21,870
time you would spend on iterations

00:14:18,540 --> 00:14:24,420
because you have no at least before you

00:14:21,870 --> 00:14:26,640
started doing this any hints about how

00:14:24,420 --> 00:14:28,950
actively processes are using memory and

00:14:26,640 --> 00:14:32,400
how much of the memory would change

00:14:28,950 --> 00:14:35,940
while you copied and this thing also

00:14:32,400 --> 00:14:39,510
gives us the second disadvantage of pre

00:14:35,940 --> 00:14:41,640
coping the memory these iterations do

00:14:39,510 --> 00:14:43,830
not guarantee that your freeze time will

00:14:41,640 --> 00:14:45,600
always be small enough if protests are

00:14:43,830 --> 00:14:48,870
changing the memory actively and you

00:14:45,600 --> 00:14:51,330
copied the next iteration you might see

00:14:48,870 --> 00:14:53,730
that you still need to copy a lot of

00:14:51,330 --> 00:14:56,700
memory and it's still should take like

00:14:53,730 --> 00:14:59,130
tens of seconds or minutes or things

00:14:56,700 --> 00:15:00,990
like that of course you have a choice to

00:14:59,130 --> 00:15:02,970
say that okay I do not like my latest

00:15:00,990 --> 00:15:04,770
container because it would take long the

00:15:02,970 --> 00:15:09,870
live migration won't build won't be

00:15:04,770 --> 00:15:14,550
alive but still with this method there

00:15:09,870 --> 00:15:18,510
is nothing that can be done the second

00:15:14,550 --> 00:15:21,000
way to copy the memory without freezing

00:15:18,510 --> 00:15:23,970
the process called the post copia memory

00:15:21,000 --> 00:15:26,730
migration it works the opposite way you

00:15:23,970 --> 00:15:27,790
freeze the container get it state but

00:15:26,730 --> 00:15:29,290
skip all the memory

00:15:27,790 --> 00:15:31,840
Mountains every single page you just do

00:15:29,290 --> 00:15:34,360
not including the into the state you

00:15:31,840 --> 00:15:35,800
safe co-op it is a told it's pretty

00:15:34,360 --> 00:15:38,230
small it will get copied within

00:15:35,800 --> 00:15:40,750
fractions of seconds then you restore

00:15:38,230 --> 00:15:46,200
container but say that all the memory

00:15:40,750 --> 00:15:48,850
that container uses seeds in in the swap

00:15:46,200 --> 00:15:52,810
this is what processes would see in

00:15:48,850 --> 00:15:55,990
reality you would have to set up a

00:15:52,810 --> 00:15:59,050
subsystem I will get back to it a little

00:15:55,990 --> 00:16:01,060
bit later that will read the memory over

00:15:59,050 --> 00:16:03,070
the network while the processes are

00:16:01,060 --> 00:16:06,570
running can put the pages with the

00:16:03,070 --> 00:16:06,570
memory contents into the proper places

00:16:07,230 --> 00:16:14,710
with this you can well estimate the time

00:16:11,680 --> 00:16:16,300
that live migration would take you can

00:16:14,710 --> 00:16:19,060
estimate the amount of data you would

00:16:16,300 --> 00:16:20,680
transfer in the first step the the size

00:16:19,060 --> 00:16:23,020
of the state without the memory it can

00:16:20,680 --> 00:16:25,300
be well estimated and you know you know

00:16:23,020 --> 00:16:27,070
the total memory the total size of the

00:16:25,300 --> 00:16:30,730
memory that containers use and you will

00:16:27,070 --> 00:16:33,250
only transfer it once so Nanak the speed

00:16:30,730 --> 00:16:34,810
of the network and this size you can say

00:16:33,250 --> 00:16:36,930
that okay my life migration will

00:16:34,810 --> 00:16:40,270
complete within maybe five minutes

00:16:36,930 --> 00:16:41,950
within which a couple of seconds the

00:16:40,270 --> 00:16:49,090
container would be frozen and living on

00:16:41,950 --> 00:16:51,670
the source node but that's the only good

00:16:49,090 --> 00:16:53,200
thing about memory post cobia the

00:16:51,670 --> 00:16:58,000
problem with it is that it's really

00:16:53,200 --> 00:16:59,980
unsafe so once you have a live magritte

00:16:58,000 --> 00:17:02,470
ETO container and it has started working

00:16:59,980 --> 00:17:05,650
on the destination node you still cannot

00:17:02,470 --> 00:17:08,260
shut down the source node if you power

00:17:05,650 --> 00:17:11,320
it down or if it crashed the container

00:17:08,260 --> 00:17:12,790
can day as well because some parts of

00:17:11,320 --> 00:17:15,730
its memory may still be on the source

00:17:12,790 --> 00:17:17,620
note you may have not yet committed and

00:17:15,730 --> 00:17:19,210
the second bad thing about memory post

00:17:17,620 --> 00:17:22,000
copying is that it actually slows

00:17:19,210 --> 00:17:23,770
applications down significantly when you

00:17:22,000 --> 00:17:27,190
start an application without a single

00:17:23,770 --> 00:17:29,440
page in ram it will start accessing it

00:17:27,190 --> 00:17:32,440
immediately it will wait for the memory

00:17:29,440 --> 00:17:34,840
transfer will wait for the colonel to

00:17:32,440 --> 00:17:36,400
find this page and put it into a protest

00:17:34,840 --> 00:17:38,840
address space and this will happen with

00:17:36,400 --> 00:17:41,510
every single page for the first

00:17:38,840 --> 00:17:44,840
seconds maybe minute applications will

00:17:41,510 --> 00:17:47,059
work slowly like if you put all the

00:17:44,840 --> 00:17:52,130
memory into real swap and ask them to

00:17:47,059 --> 00:17:55,520
continue raining so with these two

00:17:52,130 --> 00:17:59,240
things a really live migration which

00:17:55,520 --> 00:18:01,669
keeps the frozen time really small which

00:17:59,240 --> 00:18:05,210
is almost an no deficit unnoticeable by

00:18:01,669 --> 00:18:07,220
the human it's slightly more complex

00:18:05,210 --> 00:18:10,309
than just read state copy and restore

00:18:07,220 --> 00:18:13,130
state it includes several optional

00:18:10,309 --> 00:18:15,799
iterations of recording it includes

00:18:13,130 --> 00:18:20,330
freezing and saving the state then we

00:18:15,799 --> 00:18:26,649
copy restoring unfreeze and optionally

00:18:20,330 --> 00:18:26,649
we post copy the memory to the container

00:18:26,980 --> 00:18:35,600
so to get an idea why this is that

00:18:31,850 --> 00:18:37,159
complex for containers let's see the

00:18:35,600 --> 00:18:39,590
things we have to deal with when we talk

00:18:37,159 --> 00:18:41,600
about containers so when we live my

00:18:39,590 --> 00:18:46,159
bread a container we take effectively a

00:18:41,600 --> 00:18:49,750
tree of processes with all the colonel

00:18:46,159 --> 00:18:55,340
objects that these processes use files

00:18:49,750 --> 00:18:57,559
sockets sessions protest groups all the

00:18:55,340 --> 00:18:59,899
memory and when it comes to processes as

00:18:57,559 --> 00:19:01,610
compared to virtual machines memory

00:18:59,899 --> 00:19:05,149
layout is much more complex for

00:19:01,610 --> 00:19:09,070
containers all the Linux specific stuff

00:19:05,149 --> 00:19:13,970
like I notifies signal file descriptors

00:19:09,070 --> 00:19:15,350
all of this then when life Anchorage in

00:19:13,970 --> 00:19:18,169
a container we should take containers

00:19:15,350 --> 00:19:21,049
environment which consists of namespaces

00:19:18,169 --> 00:19:26,630
at sea groups and of course the memory

00:19:21,049 --> 00:19:29,059
contents itself so first complexity

00:19:26,630 --> 00:19:33,590
comes when we try to pre-compute the

00:19:29,059 --> 00:19:36,710
memory the problem is that there is no

00:19:33,590 --> 00:19:38,929
such thing as container memory there is

00:19:36,710 --> 00:19:41,659
no a place in the kernel where you can

00:19:38,929 --> 00:19:44,169
go and ask for it to give you all the

00:19:41,659 --> 00:19:48,140
pages that I used by this container

00:19:44,169 --> 00:19:51,320
instead you should first collect the

00:19:48,140 --> 00:19:52,220
processes that sit inside container this

00:19:51,320 --> 00:19:54,140
is relatively

00:19:52,220 --> 00:19:57,500
but then you have to individually

00:19:54,140 --> 00:20:02,090
analyze every single process to find out

00:19:57,500 --> 00:20:05,210
which memory the process use and since

00:20:02,090 --> 00:20:07,370
we're talking about Linux containers in

00:20:05,210 --> 00:20:09,740
Linux they are effectively four types of

00:20:07,370 --> 00:20:12,409
memory that processes can use this can

00:20:09,740 --> 00:20:14,299
be anonymous private memory animals

00:20:12,409 --> 00:20:17,059
shared memory file private and file

00:20:14,299 --> 00:20:22,600
shared memory all this stuff should be

00:20:17,059 --> 00:20:25,549
first collected into into a system that

00:20:22,600 --> 00:20:27,620
reads the state of the process all the

00:20:25,549 --> 00:20:29,659
sharing of the pages and of the map it

00:20:27,620 --> 00:20:32,539
should be resolved and only after that

00:20:29,659 --> 00:20:34,159
we have an idea of what memories in use

00:20:32,539 --> 00:20:39,010
by the containers and we can start

00:20:34,159 --> 00:20:42,289
actually copy need to the destination up

00:20:39,010 --> 00:20:45,250
then goes the second state second step

00:20:42,289 --> 00:20:48,049
when we save the state of the containers

00:20:45,250 --> 00:20:52,850
again unlike virtual machines when the

00:20:48,049 --> 00:20:55,340
state should be read from a tree of

00:20:52,850 --> 00:20:57,860
objects of known amount in the fix it

00:20:55,340 --> 00:21:02,360
sighs it's mostly virtual hardware and

00:20:57,860 --> 00:21:05,630
perverted stuff container even even an

00:21:02,360 --> 00:21:08,120
average container it forms a graph of

00:21:05,630 --> 00:21:11,780
objects which consists of thousands of

00:21:08,120 --> 00:21:14,210
nodes and these graph is oriented every

00:21:11,780 --> 00:21:17,870
single knot has different attributes you

00:21:14,210 --> 00:21:19,669
have to deal with and there is no again

00:21:17,870 --> 00:21:23,179
in the kernel a single place where you

00:21:19,669 --> 00:21:26,690
can call and say okay save me the state

00:21:23,179 --> 00:21:32,030
of this set of process for example

00:21:26,690 --> 00:21:35,270
actually we've tried to go this way some

00:21:32,030 --> 00:21:36,980
time ago with we've sent a page set to

00:21:35,270 --> 00:21:39,409
the Linux kernel community aiding the

00:21:36,980 --> 00:21:41,330
subsystem that saved the state of the

00:21:39,409 --> 00:21:44,030
processes and restore the state of the

00:21:41,330 --> 00:21:48,409
process but the colonel guys decided

00:21:44,030 --> 00:21:52,250
that this big button that does this

00:21:48,409 --> 00:21:54,980
magic tis is a bad design nobody wanted

00:21:52,250 --> 00:21:57,320
to have this in the colonel so instead

00:21:54,980 --> 00:21:59,840
of doing all this stuff are in the

00:21:57,320 --> 00:22:03,230
kernel space we decided to do it in the

00:21:59,840 --> 00:22:04,909
user space so we wrote we started the

00:22:03,230 --> 00:22:08,509
project called crew

00:22:04,909 --> 00:22:10,340
it's a system-level tool that does all

00:22:08,509 --> 00:22:13,039
that magic I'm right now talking about

00:22:10,340 --> 00:22:14,899
it take a tree of process and analyzes

00:22:13,039 --> 00:22:19,639
which processes are there which objects

00:22:14,899 --> 00:22:22,369
they use all this stuff about memory and

00:22:19,639 --> 00:22:27,019
saves this information in the set of

00:22:22,369 --> 00:22:30,649
files on disk and to achieve this goal

00:22:27,019 --> 00:22:35,840
creo uses quite a lot of colonel AP is

00:22:30,649 --> 00:22:38,950
it reads opens and reads quite a lot of

00:22:35,840 --> 00:22:41,419
prague files it uses several netlink

00:22:38,950 --> 00:22:45,619
protocols to get information for example

00:22:41,419 --> 00:22:48,679
about active connections it actively

00:22:45,619 --> 00:22:52,489
uses debugging interface ptrace system

00:22:48,679 --> 00:22:55,159
call and the thing is that all these api

00:22:52,489 --> 00:22:57,409
is a quite diverse there is no single or

00:22:55,159 --> 00:23:00,499
unified api for different types of

00:22:57,409 --> 00:23:03,590
objects in the kernel to get information

00:23:00,499 --> 00:23:05,749
about a state every single every new

00:23:03,590 --> 00:23:10,340
object that appears and that we have to

00:23:05,749 --> 00:23:14,409
support in creo they typically all have

00:23:10,340 --> 00:23:14,409
their own API to get information from

00:23:16,840 --> 00:23:22,580
this is pretty much the same for the

00:23:19,580 --> 00:23:24,649
restore restore and light unlike virtual

00:23:22,580 --> 00:23:28,159
machines when you create a fixed amount

00:23:24,649 --> 00:23:31,429
of objects and just copy their state

00:23:28,159 --> 00:23:34,009
inside with single instructions we have

00:23:31,429 --> 00:23:37,249
to recreate this graph of thousands of

00:23:34,009 --> 00:23:39,590
objects and yet again there is no as I

00:23:37,249 --> 00:23:42,379
told single the entry point into the

00:23:39,590 --> 00:23:44,269
kernel work we can heat some information

00:23:42,379 --> 00:23:47,649
and say ok please start all this stuff

00:23:44,269 --> 00:23:50,119
from the very beginning instead creo

00:23:47,649 --> 00:23:53,119
recreates all the staff literally by

00:23:50,119 --> 00:23:57,879
hands it Forks processes it opens files

00:23:53,119 --> 00:24:00,559
it calls all the system calls that can

00:23:57,879 --> 00:24:04,659
get a tree of prod get a tree of

00:24:00,559 --> 00:24:08,629
processes into the stage we need and

00:24:04,659 --> 00:24:11,229
there is a world word same emphasized on

00:24:08,629 --> 00:24:13,190
the slide this means that some

00:24:11,229 --> 00:24:16,639
configurations that we can see on a

00:24:13,190 --> 00:24:17,490
linux boxes that process get into they

00:24:16,639 --> 00:24:19,500
do not have

00:24:17,490 --> 00:24:22,440
direct ways to get into this for example

00:24:19,500 --> 00:24:26,460
the simplest example is the east protest

00:24:22,440 --> 00:24:28,590
sessions session there is no a system

00:24:26,460 --> 00:24:33,300
called take arbitrary process and put it

00:24:28,590 --> 00:24:35,070
into an arbitrary section a session the

00:24:33,300 --> 00:24:37,410
session protest lives in can be either

00:24:35,070 --> 00:24:39,720
inherited from the parent or created its

00:24:37,410 --> 00:24:41,429
own session from the very beginning so

00:24:39,720 --> 00:24:43,679
in case we see some tricky combination

00:24:41,429 --> 00:24:46,710
that protest live lives in the session

00:24:43,679 --> 00:24:50,880
without the session leader in which is a

00:24:46,710 --> 00:24:52,920
child of some third process we can

00:24:50,880 --> 00:24:55,230
adjust for this process and create a

00:24:52,920 --> 00:24:56,970
session and move it into it with example

00:24:55,230 --> 00:24:58,860
three goals we have to create fake

00:24:56,970 --> 00:25:00,920
processes that keep sessions opened

00:24:58,860 --> 00:25:04,020
while they're being populated than do

00:25:00,920 --> 00:25:08,280
tricks with repairing things repenting

00:25:04,020 --> 00:25:10,620
process on the tree and so on and this

00:25:08,280 --> 00:25:14,610
stays true for quite a lot of Colonel

00:25:10,620 --> 00:25:17,970
api's all the API is for regulating

00:25:14,610 --> 00:25:19,950
staff is also very diverse and crew has

00:25:17,970 --> 00:25:24,750
to do with this complexity to recreate

00:25:19,950 --> 00:25:30,870
that stuff and the last interesting step

00:25:24,750 --> 00:25:33,020
is memory post coping this thing is

00:25:30,870 --> 00:25:35,670
already implemented by andrea arcangeli

00:25:33,020 --> 00:25:37,559
the thing is called user fault of genes

00:25:35,670 --> 00:25:40,380
some of you might have probably seen

00:25:37,559 --> 00:25:44,520
this in the colonel I'm Dre I did this

00:25:40,380 --> 00:25:48,450
to make a post copy memory migration for

00:25:44,520 --> 00:25:51,300
kvm so he implemented user folder gear

00:25:48,450 --> 00:25:53,040
so that well user fault of G in simple

00:25:51,300 --> 00:25:55,380
words is a file descriptor using which

00:25:53,040 --> 00:25:59,429
you can catch page falls from the kernel

00:25:55,380 --> 00:26:00,720
and put pages back into it to handle the

00:25:59,429 --> 00:26:04,710
page faults instead of letting the

00:26:00,720 --> 00:26:06,450
colonel find the page somewhere the user

00:26:04,710 --> 00:26:09,720
fault of d current implementation

00:26:06,450 --> 00:26:12,120
implies that a process doing page fault

00:26:09,720 --> 00:26:14,700
in its address space and the process

00:26:12,120 --> 00:26:16,650
reading reading event from the file

00:26:14,700 --> 00:26:18,780
descriptor is the same process maybe

00:26:16,650 --> 00:26:21,450
different threads but still the same

00:26:18,780 --> 00:26:25,470
process which share the virtual memory

00:26:21,450 --> 00:26:28,470
between each other for containers this

00:26:25,470 --> 00:26:30,759
is not the case we cannot make the

00:26:28,470 --> 00:26:33,029
processes that we have restored

00:26:30,759 --> 00:26:35,139
though this user for do you think and

00:26:33,029 --> 00:26:38,889
repopulate their own address space

00:26:35,139 --> 00:26:40,479
instead the process that accesses the

00:26:38,889 --> 00:26:43,419
memory is one process and the process

00:26:40,479 --> 00:26:46,570
that owns the user fault of G and puts

00:26:43,419 --> 00:26:49,329
memory into it is another process and

00:26:46,570 --> 00:26:52,209
current implementation of user fault ivd

00:26:49,329 --> 00:26:56,259
doesn't allow for that for example if

00:26:52,209 --> 00:27:00,249
the process which is being monitored

00:26:56,259 --> 00:27:02,379
calls fork or remap serious or does some

00:27:00,249 --> 00:27:04,149
tricky stuff with Emma devices the

00:27:02,379 --> 00:27:07,679
protest at listens on the user fault of

00:27:04,149 --> 00:27:10,089
G may get confused there is no

00:27:07,679 --> 00:27:13,359
notifications about this stuff coming

00:27:10,089 --> 00:27:15,719
into user for EE this is what was called

00:27:13,359 --> 00:27:18,399
non cooperative mode of user fault DVD

00:27:15,719 --> 00:27:20,859
and it's currently working progress

00:27:18,399 --> 00:27:24,089
hopefully someday it will hit the main

00:27:20,859 --> 00:27:29,559
line and we'll have a post copy for

00:27:24,089 --> 00:27:32,799
containers live migration and other than

00:27:29,559 --> 00:27:34,449
this before like migrating container we

00:27:32,799 --> 00:27:36,069
have to do one thing which is pretty

00:27:34,449 --> 00:27:37,659
similar virtual machines we have to

00:27:36,069 --> 00:27:42,599
check that CPUs are compatible between

00:27:37,659 --> 00:27:46,449
source and destination node this is

00:27:42,599 --> 00:27:47,919
slightly more complex than the same for

00:27:46,449 --> 00:27:51,129
virtual machines because for virtual

00:27:47,919 --> 00:27:53,409
machines the masks that are reported by

00:27:51,129 --> 00:27:56,759
cpuid can be emulated inside the guests

00:27:53,409 --> 00:27:59,019
so you can make some assumptions about

00:27:56,759 --> 00:28:02,169
source and destination CPU

00:27:59,019 --> 00:28:04,389
incompatibility for containers they see

00:28:02,169 --> 00:28:06,219
all the CPU features that are on the

00:28:04,389 --> 00:28:09,309
hardware so it should be done more

00:28:06,219 --> 00:28:11,109
carefully and the second thing that is

00:28:09,309 --> 00:28:12,999
container specifically that we have to

00:28:11,109 --> 00:28:15,849
check that kernels on source node and

00:28:12,999 --> 00:28:17,019
destination order compatible and here

00:28:15,849 --> 00:28:20,079
i'm not talking about binary

00:28:17,019 --> 00:28:21,669
compatibility because Colonel community

00:28:20,079 --> 00:28:24,369
is known for keeping the binary

00:28:21,669 --> 00:28:28,539
compatibility for for ages like you can

00:28:24,369 --> 00:28:31,569
be pretty sure that the binary pie that

00:28:28,539 --> 00:28:35,440
is in for that something kernels is the

00:28:31,569 --> 00:28:37,119
same as for two dot even for this is

00:28:35,440 --> 00:28:39,640
mostly about the features feature

00:28:37,119 --> 00:28:42,880
presence like if you have certain

00:28:39,640 --> 00:28:44,500
a netfilter model module floated on the

00:28:42,880 --> 00:28:47,080
source not the same should be present on

00:28:44,500 --> 00:28:49,660
the destination one for virtual machines

00:28:47,080 --> 00:28:54,670
this is not an option so this is

00:28:49,660 --> 00:28:58,600
container specific thing all this stuff

00:28:54,670 --> 00:29:02,410
I have just described is already

00:28:58,600 --> 00:29:04,090
implemented inside to project first

00:29:02,410 --> 00:29:06,880
first I have already mentioned it's

00:29:04,090 --> 00:29:08,320
called crew crew is an acronym it's a

00:29:06,880 --> 00:29:12,040
checkpoint and restore in user space

00:29:08,320 --> 00:29:14,680
it's a tool written in C which does all

00:29:12,040 --> 00:29:16,570
the time critical staff eat save state

00:29:14,680 --> 00:29:19,360
and restores state dealing with all this

00:29:16,570 --> 00:29:23,500
complexity I have just described and it

00:29:19,360 --> 00:29:27,790
also provides an API to set up an actual

00:29:23,500 --> 00:29:30,280
Iran memory pre and post post is still

00:29:27,790 --> 00:29:33,940
not in the mainstream but still memory

00:29:30,280 --> 00:29:35,950
pre and post copy stuff but that's only

00:29:33,940 --> 00:29:39,580
saving the state and restoring the state

00:29:35,950 --> 00:29:42,400
to properly synchronize all this staff

00:29:39,580 --> 00:29:45,580
to handle iterations for pre coping and

00:29:42,400 --> 00:29:49,440
setting up connections between source

00:29:45,580 --> 00:29:53,800
node and destination one we have a

00:29:49,440 --> 00:29:55,660
sister project called people right now

00:29:53,800 --> 00:29:57,850
basically it's just a Python script that

00:29:55,660 --> 00:29:59,470
performs all the necessary projects

00:29:57,850 --> 00:30:03,640
before live migration and then calls

00:29:59,470 --> 00:30:05,950
creo to start copying the memory saving

00:30:03,640 --> 00:30:08,680
the state copies over the wire restores

00:30:05,950 --> 00:30:12,250
and probably sit ups memory post copy

00:30:08,680 --> 00:30:15,310
again using creo and one feature that we

00:30:12,250 --> 00:30:17,380
have also put into the pee hole is a is

00:30:15,310 --> 00:30:18,970
hanging the file system if you have

00:30:17,380 --> 00:30:20,770
shared file system between source and

00:30:18,970 --> 00:30:23,110
destination that that simple you do not

00:30:20,770 --> 00:30:24,700
have to do any special about this but if

00:30:23,110 --> 00:30:26,260
the file system is not sure tiff file

00:30:24,700 --> 00:30:28,960
system should also be copied between

00:30:26,260 --> 00:30:32,640
nodes it will make life regression

00:30:28,960 --> 00:30:35,710
longer but yet again there are ways to

00:30:32,640 --> 00:30:38,200
make the two not to make this while the

00:30:35,710 --> 00:30:42,760
protesters are frozen that's still read

00:30:38,200 --> 00:30:46,570
using the free Stein both processes are

00:30:42,760 --> 00:30:49,410
open source the main entry point is

00:30:46,570 --> 00:30:53,200
crude at work website

00:30:49,410 --> 00:30:55,180
it's a wiki there is a category called

00:30:53,200 --> 00:30:57,880
people where we collect all their life

00:30:55,180 --> 00:31:00,400
immigration related stuff if you want to

00:30:57,880 --> 00:31:03,670
participate join our mailing list it's

00:31:00,400 --> 00:31:05,740
clear it up in wizard at work we put

00:31:03,670 --> 00:31:09,580
news on the Google Places page in them

00:31:05,740 --> 00:31:14,590
Twitter and the source code seats on the

00:31:09,580 --> 00:31:21,160
github this is all I have if there are

00:31:14,590 --> 00:31:33,070
any questions we have presents for the

00:31:21,160 --> 00:31:35,770
best question asker cook crew is a

00:31:33,070 --> 00:31:37,530
Firebird it's it's a bird from Russian

00:31:35,770 --> 00:31:39,790
fairy tales and the pee hole is a

00:31:37,530 --> 00:31:42,240
hunchback horses yet another Russian

00:31:39,790 --> 00:31:42,240
fairy tale

00:31:53,570 --> 00:32:02,030
okay the question was how Google life a

00:31:55,880 --> 00:32:03,830
great shared library state when we get

00:32:02,030 --> 00:32:06,020
the state of a protest we do not

00:32:03,830 --> 00:32:08,090
actually care whether well libraries

00:32:06,020 --> 00:32:10,220
present as a virtual memory region

00:32:08,090 --> 00:32:11,990
inside the process and when we read the

00:32:10,220 --> 00:32:13,520
virtual memory regions inside the

00:32:11,990 --> 00:32:15,410
protest we do not really care whether

00:32:13,520 --> 00:32:20,420
it's just a file or a library or

00:32:15,410 --> 00:32:23,120
whatever whatever else we just see Ed

00:32:20,420 --> 00:32:25,430
flex this reflects this mapping was

00:32:23,120 --> 00:32:28,940
created with either it was shared to

00:32:25,430 --> 00:32:31,250
private if it's shared then we just get

00:32:28,940 --> 00:32:34,670
information about starting and ending

00:32:31,250 --> 00:32:37,250
point in the file that was mapped if its

00:32:34,670 --> 00:32:39,890
private then we go to the colonel and

00:32:37,250 --> 00:32:42,320
ask for which pages has been copyrighted

00:32:39,890 --> 00:32:45,110
from this file and take them into the

00:32:42,320 --> 00:32:47,570
image and that's it and there is no

00:32:45,110 --> 00:32:49,940
difference in getting the state for a

00:32:47,570 --> 00:32:52,510
library or just a file mapped by an

00:32:49,940 --> 00:32:52,510
application

00:33:18,980 --> 00:33:27,110
okay so the question is about capability

00:33:21,650 --> 00:33:31,760
about security context right the answer

00:33:27,110 --> 00:33:33,910
is right now the whole thing only works

00:33:31,760 --> 00:33:36,860
if you run for you is super user is root

00:33:33,910 --> 00:33:39,679
in this case it can create everything

00:33:36,860 --> 00:33:43,580
and then trim down its capabilities to

00:33:39,679 --> 00:33:45,830
whatever state is appropriate if someone

00:33:43,580 --> 00:33:48,260
wants to run for you from a regular user

00:33:45,830 --> 00:33:52,730
and we have such requests from openmpi

00:33:48,260 --> 00:33:55,669
guys they run their stuff as just some

00:33:52,730 --> 00:33:59,210
user on on the host then we have paged

00:33:55,669 --> 00:34:01,280
crew to do saving the state part because

00:33:59,210 --> 00:34:02,660
saving the state could be done

00:34:01,280 --> 00:34:04,400
regardless of the security restrictions

00:34:02,660 --> 00:34:08,629
by the kernel but saying if the state

00:34:04,400 --> 00:34:11,570
can be done restoring the state is quite

00:34:08,629 --> 00:34:14,300
tricking it's not yet implemented and

00:34:11,570 --> 00:34:16,340
not not because of the capabilities but

00:34:14,300 --> 00:34:19,310
because we need to recreate the

00:34:16,340 --> 00:34:22,520
processes with the exact same peds they

00:34:19,310 --> 00:34:24,590
had before for unprivileged user this is

00:34:22,520 --> 00:34:27,770
only possible if you spawn a username

00:34:24,590 --> 00:34:30,679
space in the PID namespace but in this

00:34:27,770 --> 00:34:32,419
case what you have restored might not be

00:34:30,679 --> 00:34:34,940
completely equal to what you have done

00:34:32,419 --> 00:34:37,250
previously so this thing is yet to be

00:34:34,940 --> 00:34:38,780
resolved right now result restore only

00:34:37,250 --> 00:34:41,020
works for the root user which can do

00:34:38,780 --> 00:34:41,020
anything

00:34:45,330 --> 00:35:07,180
yeah yeah what's it what's impact on the

00:35:05,920 --> 00:35:17,320
performance of the container life a

00:35:07,180 --> 00:35:18,760
great huh it's not a performance

00:35:17,320 --> 00:35:40,270
degradation it's a freeze time when the

00:35:18,760 --> 00:35:44,380
container doesn't respond like yeah when

00:35:40,270 --> 00:35:50,200
using the post-hoc memory it really

00:35:44,380 --> 00:35:53,920
depends on the application right what

00:35:50,200 --> 00:35:56,050
we've seen before at least in the open

00:35:53,920 --> 00:35:57,900
is that users they they mostly suffered

00:35:56,050 --> 00:36:01,300
from the free Stein but not from the

00:35:57,900 --> 00:36:04,420
delay they got after restoring because

00:36:01,300 --> 00:36:07,630
this postcode migration there are two

00:36:04,420 --> 00:36:09,580
tricks that can like reduce this impact

00:36:07,630 --> 00:36:11,320
we can check which page with the

00:36:09,580 --> 00:36:16,650
container would require first by

00:36:11,320 --> 00:36:18,760
checking its IP address IP register and

00:36:16,650 --> 00:36:21,340
some more registers and just fetching

00:36:18,760 --> 00:36:23,140
the pages this couple of pages it won't

00:36:21,340 --> 00:36:25,030
take time but the process the process

00:36:23,140 --> 00:36:31,260
will get him immediately so this

00:36:25,030 --> 00:36:31,260
slowdown is really not a big yeah

00:36:36,680 --> 00:36:45,750
we are talking about TCP probably all

00:36:39,360 --> 00:36:48,180
right or any connection okay so net link

00:36:45,750 --> 00:36:50,370
is relatively simple because it's a

00:36:48,180 --> 00:36:51,900
connection between the process end and

00:36:50,370 --> 00:36:54,480
the colonel we just recreate the circuit

00:36:51,900 --> 00:36:57,380
back if we see that there is some data

00:36:54,480 --> 00:36:59,730
in this circuit we for now we do not

00:36:57,380 --> 00:37:02,610
refuse dumping that container because

00:36:59,730 --> 00:37:03,990
it's quite unusual situation rods is

00:37:02,610 --> 00:37:05,640
typically reach all the data from the

00:37:03,990 --> 00:37:08,010
link sockets immediately so we can

00:37:05,640 --> 00:37:11,190
unfreeze it wait for a second and try to

00:37:08,010 --> 00:37:13,830
do it again circuit will be empty unique

00:37:11,190 --> 00:37:16,650
circuits are not yet complex too because

00:37:13,830 --> 00:37:20,040
they all connect processes within one

00:37:16,650 --> 00:37:22,350
container so we can just read them using

00:37:20,040 --> 00:37:25,020
the unix dag module in the colonel

00:37:22,350 --> 00:37:29,730
that's a model that SS 2 uses to fetch

00:37:25,020 --> 00:37:32,150
the information and we can actually read

00:37:29,730 --> 00:37:35,070
the data from the socket without

00:37:32,150 --> 00:37:38,070
removing it from there there is a msg

00:37:35,070 --> 00:37:39,930
peak flag in the reco energy system call

00:37:38,070 --> 00:37:43,470
which just copies the data and leaves it

00:37:39,930 --> 00:37:45,360
there and at restore time we do the same

00:37:43,470 --> 00:37:48,660
recreate the circuit and write data back

00:37:45,360 --> 00:37:51,180
on it the most interesting case is to be

00:37:48,660 --> 00:37:54,030
TCP connections for TCP connections we

00:37:51,180 --> 00:37:59,900
have patched the colonel you can google

00:37:54,030 --> 00:38:02,430
for TCP day tcp repair socket option

00:37:59,900 --> 00:38:04,020
it's a socket option with which we can

00:38:02,430 --> 00:38:06,450
freeze the circuit and get all the

00:38:04,020 --> 00:38:10,560
critical tcp information light sequence

00:38:06,450 --> 00:38:12,300
numbers timestamps scaling factors all

00:38:10,560 --> 00:38:14,790
the parameters that sit on the circuit

00:38:12,300 --> 00:38:16,860
and then we can create a socket put it

00:38:14,790 --> 00:38:19,050
into repair mode again and force it to

00:38:16,860 --> 00:38:20,400
have the sequences timestamp and all the

00:38:19,050 --> 00:38:25,010
stuff that comes from the user space

00:38:20,400 --> 00:38:25,010
this makes TCP sockets language

00:38:28,680 --> 00:38:37,030
but I want to stay back up data yes this

00:38:34,570 --> 00:38:40,060
is how seamless kernel update is working

00:38:37,030 --> 00:38:42,640
you can say reboot and restore but in

00:38:40,060 --> 00:38:45,220
this case the first time will be quite

00:38:42,640 --> 00:38:46,390
big not because of the colonel slow boot

00:38:45,220 --> 00:38:48,430
but because you'll have to read

00:38:46,390 --> 00:38:50,410
everything from disk we have a

00:38:48,430 --> 00:38:53,200
proof-of-concept technology that keeps

00:38:50,410 --> 00:38:55,090
container in RAM while rebooting the

00:38:53,200 --> 00:38:59,520
kernel with k exact so it doesn't

00:38:55,090 --> 00:38:59,520
disappear we can do it many times faster

00:39:22,230 --> 00:39:29,590
yes there is one thing currently we see

00:39:26,260 --> 00:39:33,780
that quite a big portion of getting the

00:39:29,590 --> 00:39:36,970
state is spent on accessing prog files

00:39:33,780 --> 00:39:39,670
open increasing and surprisingly closing

00:39:36,970 --> 00:39:42,160
them closing takes like thirty percent

00:39:39,670 --> 00:39:46,480
of this time strange thing but it takes

00:39:42,160 --> 00:39:49,300
so we have again proof-of-concept

00:39:46,480 --> 00:39:51,730
patches that implement net link protocol

00:39:49,300 --> 00:39:54,400
that can get this information in binary

00:39:51,730 --> 00:39:57,250
format and not in protest by process but

00:39:54,400 --> 00:40:00,750
in a batch manner it saves lots of time

00:39:57,250 --> 00:40:00,750
but it's still noted in upstream

00:40:07,210 --> 00:40:18,920
with what docker the the answer is we

00:40:15,110 --> 00:40:21,170
have created well we took took part in

00:40:18,920 --> 00:40:24,140
creating namespaces into groups inside

00:40:21,170 --> 00:40:26,210
colonel on top of which later dr.

00:40:24,140 --> 00:40:28,940
introduced the docker files and this

00:40:26,210 --> 00:40:31,580
layering management system but the we

00:40:28,940 --> 00:40:43,070
and them add two different companies and

00:40:31,580 --> 00:40:44,510
developers in the existing versions of

00:40:43,070 --> 00:40:47,840
virtual that we still don't do it

00:40:44,510 --> 00:40:50,480
unfortunately but in next virtual which

00:40:47,840 --> 00:40:58,150
will be which was at eight something

00:40:50,480 --> 00:40:58,150
like that with the Peoria okay thanks

00:41:11,390 --> 00:41:16,309
the zombie reassure picketers date

00:44:12,070 --> 00:44:18,920
that's worse thank you everyone for

00:44:16,460 --> 00:44:20,930
attending the presentations we really

00:44:18,920 --> 00:44:23,060
appreciate your feedback please free

00:44:20,930 --> 00:44:27,859
feel free to provide it on our official

00:44:23,060 --> 00:44:31,339
website you can also tweet about the

00:44:27,859 --> 00:44:34,010
event or create a blog post there is

00:44:31,339 --> 00:44:35,900
actually competition for the best blog

00:44:34,010 --> 00:44:40,490
post so you can get some prizes for that

00:44:35,900 --> 00:44:44,050
thank you very much the donation in the

00:44:40,490 --> 00:44:44,050
book is not box it's not bad

00:45:02,080 --> 00:45:04,950
to the first

00:45:25,180 --> 00:45:36,340
sophie has a job to provide good nominal

00:45:29,780 --> 00:45:36,340
doctor what is this place

00:45:37,250 --> 00:45:40,270
so much so much

00:45:41,980 --> 00:45:51,920
fifty-fifty fixable meaning everyone is

00:45:50,240 --> 00:45:56,089
very experienced because they know

00:45:51,920 --> 00:46:02,270
exactly when you are with all presenters

00:45:56,089 --> 00:46:04,250
because just come to drink but this

00:46:02,270 --> 00:46:07,809
aggravation also we got through

00:46:04,250 --> 00:46:07,809
presented presentations well yes

00:46:15,250 --> 00:46:18,830
this is surprised like the guy is not

00:46:17,300 --> 00:46:24,410
from reston over here you're a furry

00:46:18,830 --> 00:46:26,860
head they shouldn't be but in reality

00:46:24,410 --> 00:46:26,860
you know

00:46:55,930 --> 00:47:04,570
open-source corporation doesn't appear

00:46:59,350 --> 00:47:04,570
yeah that's what's got a few them

00:47:22,740 --> 00:47:30,720
finally your subscribers what's the

00:47:26,710 --> 00:47:30,720
lowest rate

00:47:31,559 --> 00:47:40,880

YouTube URL: https://www.youtube.com/watch?v=M1FKW945bQA


