Title: ML pipelines with Kubeflow, Argo and Open Data Hub
Publication date: 2019-10-02
Playlist: DevConfUS 2019
Description: 
	Speakers: Juana Nakfour and Peter MacKinnon

Data scientists and machine learning (ML) engineers rely heavily on creating workflows to train, verify, and deploy ML models. Argo is a cloud-native workflow management tool that enables the creation of sophisticated native Kubernetes ML workflows. Kubeflow is an ML toolkit that incorporates best-of-breed ML projects (for example, TensorFlow) as well as providing important infrastructure such as hyperparameter tuning. The Open Data Hub (ODH) is a scalable data lake platform that provides tools such as distributed Spark and Ceph data store. In this presentation we will explore workflow features available using Argo running as a component of Kubeflow and integrated with ODH. Presentation will include a live demonstration of ML workflows using Kubeflow, Spark and Ceph.
Captions: 
	00:00:03,270 --> 00:00:06,870
so today as you can see from your

00:00:05,670 --> 00:00:09,360
schedule we're here to talk about

00:00:06,870 --> 00:00:11,580
machine learning pipelines hopefully by

00:00:09,360 --> 00:00:15,720
now everybody recognizes that mini

00:00:11,580 --> 00:00:17,970
acronym of ml and we're gonna put it in

00:00:15,720 --> 00:00:20,159
the context of a couple of open source

00:00:17,970 --> 00:00:21,390
projects and you in the previous session

00:00:20,159 --> 00:00:23,429
just heard about one of them we're gonna

00:00:21,390 --> 00:00:27,900
revisit that we're also going to talk a

00:00:23,429 --> 00:00:29,819
little bit about coop flow yeah so we'll

00:00:27,900 --> 00:00:32,660
do sort of a brief introduction to

00:00:29,819 --> 00:00:34,890
machine learning pipelines as we sort of

00:00:32,660 --> 00:00:36,690
idealize them or understand them today

00:00:34,890 --> 00:00:37,980
and we'll talk about some of the

00:00:36,690 --> 00:00:41,129
attributes and features of those

00:00:37,980 --> 00:00:42,649
pipelines we'll do serve a survey of

00:00:41,129 --> 00:00:44,609
some of the more popular open source

00:00:42,649 --> 00:00:48,089
pipeline projects and that's gonna

00:00:44,609 --> 00:00:51,329
include air flow Tecton agro and kupo

00:00:48,089 --> 00:00:53,399
pipelines and then Joanna's gonna get

00:00:51,329 --> 00:00:55,379
into a bit more detail about two of

00:00:53,399 --> 00:00:58,559
these these projects have sort of

00:00:55,379 --> 00:01:01,949
different ages for us and we have more

00:00:58,559 --> 00:01:04,860
experience with things like cargo Argo

00:01:01,949 --> 00:01:06,960
and coop flow pipelines and so that's

00:01:04,860 --> 00:01:09,360
what we're gonna focus on and joanna is

00:01:06,960 --> 00:01:11,790
gonna lead us through a demo of that

00:01:09,360 --> 00:01:14,520
that is based on a very practical

00:01:11,790 --> 00:01:17,490
machine learning application which is

00:01:14,520 --> 00:01:19,050
fraud detection and then then we'll at

00:01:17,490 --> 00:01:22,020
the end talk about some of the future

00:01:19,050 --> 00:01:25,110
direction and wrap up so as you can sort

00:01:22,020 --> 00:01:27,120
of expect from a pipeline there's this

00:01:25,110 --> 00:01:29,880
notion of sort of an organized set of

00:01:27,120 --> 00:01:31,650
stages and there's interdependencies

00:01:29,880 --> 00:01:33,480
between those stages and that's very

00:01:31,650 --> 00:01:35,850
important in the context of machine

00:01:33,480 --> 00:01:37,590
learning these days because it turns out

00:01:35,850 --> 00:01:39,600
you know there's sort of this classic

00:01:37,590 --> 00:01:42,150
notion of data science with a notebook

00:01:39,600 --> 00:01:45,120
like an eye Python your book of Jupiter

00:01:42,150 --> 00:01:47,120
notebook but actually machine learning

00:01:45,120 --> 00:01:50,100
in production is much more complicated

00:01:47,120 --> 00:01:53,430
there's various stages involved to get

00:01:50,100 --> 00:01:56,010
from that first point of ingesting some

00:01:53,430 --> 00:01:58,080
data and actually producing a model from

00:01:56,010 --> 00:02:00,830
it training that model and deploying

00:01:58,080 --> 00:02:02,940
that into production and this is where

00:02:00,830 --> 00:02:06,230
the importance of machine learning

00:02:02,940 --> 00:02:09,629
pipelines comes into place into play and

00:02:06,230 --> 00:02:12,630
having tools to do that so sort of in a

00:02:09,629 --> 00:02:14,820
generalized example here we have sort of

00:02:12,630 --> 00:02:15,710
an ingest layer that is doing a reader

00:02:14,820 --> 00:02:17,930
and transform a

00:02:15,710 --> 00:02:21,620
I'm data from various sources maybe s3

00:02:17,930 --> 00:02:24,440
and perhaps that data is coming in it's

00:02:21,620 --> 00:02:26,030
sort of tagged as sort of experimental

00:02:24,440 --> 00:02:27,740
or development data or maybe it's

00:02:26,030 --> 00:02:30,620
actually for inference and it's coming

00:02:27,740 --> 00:02:33,260
in from some production sort of input or

00:02:30,620 --> 00:02:35,810
perhaps from some other location and

00:02:33,260 --> 00:02:38,720
then we sort of want to distribute that

00:02:35,810 --> 00:02:43,460
throughout a pipeline where we can

00:02:38,720 --> 00:02:46,130
basically do various different types of

00:02:43,460 --> 00:02:47,960
model development techniques so in this

00:02:46,130 --> 00:02:50,480
case maybe it's PI torch maybe we're

00:02:47,960 --> 00:02:53,630
doing a convolutional neural network

00:02:50,480 --> 00:02:56,360
with tensorflow random forest model and

00:02:53,630 --> 00:02:57,950
then from that in our pipeline we're

00:02:56,360 --> 00:03:00,350
coming down and we're doing that

00:02:57,950 --> 00:03:02,600
evaluation of how we did in terms of

00:03:00,350 --> 00:03:05,210
doing the training of that and then

00:03:02,600 --> 00:03:07,730
there are some techniques that are

00:03:05,210 --> 00:03:10,580
applied at this point to find basically

00:03:07,730 --> 00:03:12,440
the best model for the input and then

00:03:10,580 --> 00:03:14,540
finally once we derive that model we

00:03:12,440 --> 00:03:17,170
want to push it out into production and

00:03:14,540 --> 00:03:21,170
do some monitoring and things like that

00:03:17,170 --> 00:03:23,900
so this can be executed in many cases in

00:03:21,170 --> 00:03:25,880
parallel and some of the companies that

00:03:23,900 --> 00:03:30,050
are very advanced in machine learning

00:03:25,880 --> 00:03:32,600
think of an uber or lyft or some of the

00:03:30,050 --> 00:03:34,280
other companies out there Google they

00:03:32,600 --> 00:03:36,170
actually do this in production they have

00:03:34,280 --> 00:03:39,400
sophisticated machine learning pipelines

00:03:36,170 --> 00:03:41,350
for doing exactly this type of work

00:03:39,400 --> 00:03:44,870
slide please

00:03:41,350 --> 00:03:46,520
so but taking a step back we can look at

00:03:44,870 --> 00:03:49,130
sort of the attributes and features of

00:03:46,520 --> 00:03:53,720
machine learning pipelines and in terms

00:03:49,130 --> 00:03:56,570
of computer science a lot of us are very

00:03:53,720 --> 00:03:59,930
familiar with DAGs or distributed

00:03:56,570 --> 00:04:02,090
acyclic graphs so you'll see when

00:03:59,930 --> 00:04:03,770
throughout this discussion of machine

00:04:02,090 --> 00:04:06,980
learning pipelines we'll touch on this

00:04:03,770 --> 00:04:08,540
topic of of DAGs but in general my

00:04:06,980 --> 00:04:11,870
machine learning pipeline should be

00:04:08,540 --> 00:04:13,520
automated and we'll see that openshift

00:04:11,870 --> 00:04:16,040
and cooper Nettie's is an excellent

00:04:13,520 --> 00:04:18,920
platform for helping us with the

00:04:16,040 --> 00:04:21,200
enablement of that automation also it

00:04:18,920 --> 00:04:23,240
should be repeatable there should be a

00:04:21,200 --> 00:04:25,550
capability of doing some article

00:04:23,240 --> 00:04:28,910
artifact passing in terms of input and

00:04:25,550 --> 00:04:31,970
output between different targets with

00:04:28,910 --> 00:04:34,220
in our pipeline the notion of triggers

00:04:31,970 --> 00:04:38,300
so something happens say in a github

00:04:34,220 --> 00:04:40,220
repo that should kick off a stage in a

00:04:38,300 --> 00:04:42,620
pipeline or the very beginning of a

00:04:40,220 --> 00:04:45,740
pipeline and then there's the notion of

00:04:42,620 --> 00:04:49,970
integration for multiple clusters so

00:04:45,740 --> 00:04:52,370
perhaps we have defined a pipeline that

00:04:49,970 --> 00:04:54,890
exists for the steps for dag there's

00:04:52,370 --> 00:04:56,780
sort of features or attributes that

00:04:54,890 --> 00:04:58,490
we're looking for so the notion of

00:04:56,780 --> 00:05:01,220
targets which are really the notes in

00:04:58,490 --> 00:05:04,550
the deck in the graph the ability to do

00:05:01,220 --> 00:05:10,010
parallel processing conditionals are

00:05:04,550 --> 00:05:12,020
important so if we have a or a node here

00:05:10,010 --> 00:05:13,760
perhaps there's some condition in here

00:05:12,020 --> 00:05:16,490
that immediately triggers that can get

00:05:13,760 --> 00:05:18,890
us down to e but other conditions

00:05:16,490 --> 00:05:21,550
perhaps go to B and C or directly to D

00:05:18,890 --> 00:05:23,900
that's where conditionals come through

00:05:21,550 --> 00:05:26,420
the notion of loops were not talking

00:05:23,900 --> 00:05:28,190
about loops within a dag the notion of a

00:05:26,420 --> 00:05:31,370
loop in this case is within the target

00:05:28,190 --> 00:05:34,910
itself the ability to iterate over a

00:05:31,370 --> 00:05:37,250
list or a sequence of inputs and then

00:05:34,910 --> 00:05:41,210
for each these targets the ability to

00:05:37,250 --> 00:05:44,210
pause and resume also timeouts so that

00:05:41,210 --> 00:05:45,710
in some case if we have a pipeline and

00:05:44,210 --> 00:05:48,140
there's a stage that's taking too long

00:05:45,710 --> 00:05:49,340
we want to kill that off basically

00:05:48,140 --> 00:05:52,280
something's gone wrong

00:05:49,340 --> 00:05:56,180
and perhaps kick it back and it follows

00:05:52,280 --> 00:05:59,090
another path down through the day and

00:05:56,180 --> 00:06:02,210
then the notion of retries so all these

00:05:59,090 --> 00:06:04,690
are the ideal capabilities that we want

00:06:02,210 --> 00:06:07,850
to see in a machine learning pipeline

00:06:04,690 --> 00:06:10,340
slide so it turns out there's actually

00:06:07,850 --> 00:06:14,450
quite a few open-source tools today that

00:06:10,340 --> 00:06:17,180
help us in this respect and we're gonna

00:06:14,450 --> 00:06:21,500
focus on a couple of these not all these

00:06:17,180 --> 00:06:25,730
in detail but are Goku flow pipelines

00:06:21,500 --> 00:06:29,210
Apache air flow pachyderm Tecton Jenkins

00:06:25,730 --> 00:06:32,030
axe these are all different open source

00:06:29,210 --> 00:06:34,010
toolkits that give us varying degrees of

00:06:32,030 --> 00:06:37,100
those capabilities that you saw

00:06:34,010 --> 00:06:39,080
previously and we'll see that some of

00:06:37,100 --> 00:06:42,050
them are better suited to open

00:06:39,080 --> 00:06:43,509
shifting kubernetes than others next

00:06:42,050 --> 00:06:47,419
slide please

00:06:43,509 --> 00:06:49,310
so it's important to touch on airflow

00:06:47,419 --> 00:06:52,430
because it was one of the early open

00:06:49,310 --> 00:06:55,310
source workflow orchestrators or dag

00:06:52,430 --> 00:06:58,819
orchestrators but it is not kubernetes

00:06:55,310 --> 00:07:01,939
native it's a Python SDK and it can

00:06:58,819 --> 00:07:04,159
basically make use of various different

00:07:01,939 --> 00:07:06,919
types of schedulers like desk or

00:07:04,159 --> 00:07:09,319
kubernetes or made Tso's but it's not a

00:07:06,919 --> 00:07:12,469
dependent on kubernetes it's not in a

00:07:09,319 --> 00:07:13,969
inherently built around kubernetes so

00:07:12,469 --> 00:07:16,009
that's an Apache project it's been

00:07:13,969 --> 00:07:19,340
around for a while it's very popular out

00:07:16,009 --> 00:07:22,430
there it was originally started Airbnb

00:07:19,340 --> 00:07:24,560
and then contributed to Apache it has

00:07:22,430 --> 00:07:26,719
the concept of operators which is not to

00:07:24,560 --> 00:07:29,270
be confused with kubernetes operators

00:07:26,719 --> 00:07:32,690
which you'll probably hear throughout

00:07:29,270 --> 00:07:35,050
the weekend in various talks so they

00:07:32,690 --> 00:07:37,370
have different types of operators for

00:07:35,050 --> 00:07:39,949
representing those single independent

00:07:37,370 --> 00:07:42,020
tasks in a workflow so those are

00:07:39,949 --> 00:07:44,560
predefined in the SDK so there's a

00:07:42,020 --> 00:07:48,080
Python operator for executing some

00:07:44,560 --> 00:07:51,020
segments of Python code or bash or

00:07:48,080 --> 00:07:58,159
integration with G speed Google cloud

00:07:51,020 --> 00:08:04,339
platform next slide I'm surprising you

00:07:58,159 --> 00:08:07,849
because Jon and I were upstairs and we

00:08:04,339 --> 00:08:10,669
were sitting there we should put

00:08:07,849 --> 00:08:12,680
something in there so so this is a

00:08:10,669 --> 00:08:15,050
little snippet this is incomplete but it

00:08:12,680 --> 00:08:17,089
gives you an idea of what the SDK for

00:08:15,050 --> 00:08:18,919
airflow looks like you see the

00:08:17,089 --> 00:08:22,250
abstractions there that we just talked

00:08:18,919 --> 00:08:25,900
about the notion of a dag as a native

00:08:22,250 --> 00:08:31,129
type in the Python SDK Python operator

00:08:25,900 --> 00:08:34,190
those types of concepts so that's it for

00:08:31,129 --> 00:08:36,079
airflow again we're just doing a summary

00:08:34,190 --> 00:08:37,269
of some of these projects next slide

00:08:36,079 --> 00:08:40,940
please

00:08:37,269 --> 00:08:42,890
sorry not quite the end but what airflow

00:08:40,940 --> 00:08:46,630
does have is a fairly sophisticated UI

00:08:42,890 --> 00:08:49,400
which is nice it's fairly well developed

00:08:46,630 --> 00:08:51,470
so it gives you a service sense

00:08:49,400 --> 00:08:54,230
this is one of many different types of

00:08:51,470 --> 00:08:57,710
visualizations that you can get from

00:08:54,230 --> 00:08:59,120
your dag and this one we kind of threw

00:08:57,710 --> 00:09:02,750
it up because it gives you a classic

00:08:59,120 --> 00:09:05,450
sort of conceptual visualization of what

00:09:02,750 --> 00:09:07,339
the dag is doing and we'll see that the

00:09:05,450 --> 00:09:09,339
other tools that we're going to demo

00:09:07,339 --> 00:09:14,890
later on also give you nice

00:09:09,339 --> 00:09:14,890
representations of these DAGs next slide

00:09:14,950 --> 00:09:21,170
Tecton is a very new project it came out

00:09:17,750 --> 00:09:26,000
of Google specifically the Tecton CD

00:09:21,170 --> 00:09:27,410
project and Vincent Baths who is here I

00:09:26,000 --> 00:09:28,940
don't know if he's in the room but he's

00:09:27,410 --> 00:09:32,240
here at the conference somewhere as I

00:09:28,940 --> 00:09:35,839
think is one of the people from the CTO

00:09:32,240 --> 00:09:40,370
office who is very much involved in this

00:09:35,839 --> 00:09:44,589
new project and the idea is to develop a

00:09:40,370 --> 00:09:48,230
new kubernetes native CIC D pipeline

00:09:44,589 --> 00:09:51,140
specifically you know designed for for

00:09:48,230 --> 00:09:53,600
kubernetes and right now it's entirely

00:09:51,140 --> 00:09:55,459
based in github there's a couple of sub

00:09:53,600 --> 00:09:59,510
projects that go along with it there's a

00:09:55,459 --> 00:10:02,959
UI for it as well CLI and it has sub

00:09:59,510 --> 00:10:04,700
project for venting and so with

00:10:02,959 --> 00:10:06,860
kubernetes the Nokia chef we're all

00:10:04,700 --> 00:10:10,390
familiar you know we're always dealing

00:10:06,860 --> 00:10:12,709
with api's and in those api's there's

00:10:10,390 --> 00:10:15,140
representations of those resource

00:10:12,709 --> 00:10:18,950
objects from the API they've done the

00:10:15,140 --> 00:10:21,290
same thing in Tecton so in their API

00:10:18,950 --> 00:10:23,810
there are kubernetes definitions for

00:10:21,290 --> 00:10:27,320
things like a tasks tasks run pipeline

00:10:23,810 --> 00:10:31,070
resource pipeline pipeline run so tasks

00:10:27,320 --> 00:10:34,430
are really sort of the the atomic almost

00:10:31,070 --> 00:10:37,430
atomic thing that executes your workflow

00:10:34,430 --> 00:10:41,270
so those are run as pods defined by a

00:10:37,430 --> 00:10:44,540
task run resource object within a task

00:10:41,270 --> 00:10:47,089
each container now in a pod as you know

00:10:44,540 --> 00:10:50,470
you can have multiple containers so the

00:10:47,089 --> 00:10:53,810
steps within a pod are represented by

00:10:50,470 --> 00:10:56,660
containers then there's a pipeline

00:10:53,810 --> 00:10:59,890
resource which represents possible

00:10:56,660 --> 00:11:02,060
inputs and outputs for a given task so

00:10:59,890 --> 00:11:03,410
it could be a git Ref

00:11:02,060 --> 00:11:07,490
maybe a pull request

00:11:03,410 --> 00:11:11,379
that appears on a get repo a change to

00:11:07,490 --> 00:11:14,420
an image from an image registry

00:11:11,379 --> 00:11:16,370
interaction or output to another cluster

00:11:14,420 --> 00:11:19,730
we talked about that or earlier the

00:11:16,370 --> 00:11:21,860
ability to interact with multiple

00:11:19,730 --> 00:11:23,540
clusters and currently of course it's a

00:11:21,860 --> 00:11:25,790
Google project they always lead with

00:11:23,540 --> 00:11:27,920
their preferred infrastructure so

00:11:25,790 --> 00:11:30,829
there's a storage output and currently

00:11:27,920 --> 00:11:32,899
that is Google Cloud storage but this is

00:11:30,829 --> 00:11:36,500
the project that Red Hat has a fair

00:11:32,899 --> 00:11:38,269
amount of interest in and we're gonna

00:11:36,500 --> 00:11:40,189
talk about coop flow in a second but

00:11:38,269 --> 00:11:43,540
they're also taking a certain amount of

00:11:40,189 --> 00:11:46,610
interest in this project as well so

00:11:43,540 --> 00:11:49,040
again a bunch of resource objects are

00:11:46,610 --> 00:11:50,600
the highest level resource object is the

00:11:49,040 --> 00:11:53,000
pipeline itself and that's your

00:11:50,600 --> 00:11:55,759
definition of this ordered sequence of

00:11:53,000 --> 00:11:58,100
tasks and so you have your inputs and

00:11:55,759 --> 00:12:00,110
outputs going from task to task these

00:11:58,100 --> 00:12:02,420
are defined as the pipeline resource and

00:12:00,110 --> 00:12:05,019
that defines your flow through the

00:12:02,420 --> 00:12:07,550
pipeline and then a pipeline run

00:12:05,019 --> 00:12:10,880
represents an object that is the

00:12:07,550 --> 00:12:14,230
execution of a specific instance of that

00:12:10,880 --> 00:12:16,579
pipeline next slide please

00:12:14,230 --> 00:12:21,290
so if you were here for the previous

00:12:16,579 --> 00:12:22,670
talk we talked about open data hub the

00:12:21,290 --> 00:12:25,759
important part of these machine

00:12:22,670 --> 00:12:29,800
pipelines is that they need to sort of

00:12:25,759 --> 00:12:33,019
to be useful they're part of some larger

00:12:29,800 --> 00:12:36,019
ecosystem and in this case the ecosystem

00:12:33,019 --> 00:12:38,420
that is of interest here is Red Hat's

00:12:36,019 --> 00:12:41,329
own open data hub now that's an open

00:12:38,420 --> 00:12:44,480
source project that provides various

00:12:41,329 --> 00:12:46,850
capabilities it's a meta project for the

00:12:44,480 --> 00:12:49,939
hybrid cloud it is designed specifically

00:12:46,850 --> 00:12:52,699
to run very well on kubernetes and most

00:12:49,939 --> 00:12:54,949
specifically on open shift itself it has

00:12:52,699 --> 00:12:57,259
notebooks it has integration with SPARC

00:12:54,949 --> 00:13:00,379
operator for generating or spinning up

00:12:57,259 --> 00:13:07,220
SPARC clusters notebooks tensorflow

00:13:00,379 --> 00:13:11,709
notebooks scikit-learn and this type of

00:13:07,220 --> 00:13:14,360
meta project is what's needed to sort of

00:13:11,709 --> 00:13:15,570
connect together some of this pipeline

00:13:14,360 --> 00:13:17,070
in terms of

00:13:15,570 --> 00:13:19,500
different components so there's

00:13:17,070 --> 00:13:21,660
different responsibilities that are tied

00:13:19,500 --> 00:13:24,840
to different personas in the overall

00:13:21,660 --> 00:13:27,750
machine learning pipeline so with spark

00:13:24,840 --> 00:13:31,710
you can do ETL into say a tensor flow

00:13:27,750 --> 00:13:34,800
notebook for example and then you can do

00:13:31,710 --> 00:13:37,050
serving of a model that once it's been

00:13:34,800 --> 00:13:40,020
developed in the notebook and then you

00:13:37,050 --> 00:13:43,410
can do some monitoring or hyper

00:13:40,020 --> 00:13:45,330
parameter tuning of that model so this

00:13:43,410 --> 00:13:48,090
is the direction that open data hub is

00:13:45,330 --> 00:13:49,680
going and one of the key sort of

00:13:48,090 --> 00:13:51,990
components we've identified for

00:13:49,680 --> 00:13:54,420
integration into open data hub is a

00:13:51,990 --> 00:13:57,300
workflow manager and currently the

00:13:54,420 --> 00:14:00,390
target is are go and Joanna's gonna

00:13:57,300 --> 00:14:05,370
target talk about Argo in a bit next

00:14:00,390 --> 00:14:07,920
slide so a graphical representation of

00:14:05,370 --> 00:14:10,950
open data hub I've sort of called out

00:14:07,920 --> 00:14:12,960
Argo workflows inside this layer here

00:14:10,950 --> 00:14:14,190
that we associate with monitoring and

00:14:12,960 --> 00:14:16,470
orchestration

00:14:14,190 --> 00:14:18,360
it's important to understand and the

00:14:16,470 --> 00:14:20,640
open data hub that's available today we

00:14:18,360 --> 00:14:24,540
have an open data hub operator you don't

00:14:20,640 --> 00:14:27,540
get all these things currently this is

00:14:24,540 --> 00:14:29,910
sort of a reference architecture for a

00:14:27,540 --> 00:14:33,020
set of components that are designed to

00:14:29,910 --> 00:14:37,140
be integrated into machine learning

00:14:33,020 --> 00:14:39,300
pipeline so components like model

00:14:37,140 --> 00:14:41,640
lifecycle we integrate with Selden we

00:14:39,300 --> 00:14:45,120
have the AI library developed by percent

00:14:41,640 --> 00:14:48,480
there we have Jupiter hub for spawning

00:14:45,120 --> 00:14:52,590
notebooks super set and a course spark

00:14:48,480 --> 00:14:54,330
for doing big data processing internally

00:14:52,590 --> 00:14:58,250
we use some other components

00:14:54,330 --> 00:15:01,470
elasticsearch Kafka is a caching layer

00:14:58,250 --> 00:15:04,050
hive and then so it's all unified

00:15:01,470 --> 00:15:07,260
basically by Red Hat openshift and

00:15:04,050 --> 00:15:10,680
kubernetes which is what openshift is

00:15:07,260 --> 00:15:12,980
basically and we integrate with set for

00:15:10,680 --> 00:15:15,270
storage so it's a fairly comprehensive

00:15:12,980 --> 00:15:17,010
reference architecture for machine

00:15:15,270 --> 00:15:20,220
learning and again an important

00:15:17,010 --> 00:15:25,080
component of it will be yaga workflows

00:15:20,220 --> 00:15:28,970
which we are targeting to August end of

00:15:25,080 --> 00:15:28,970
August is that change

00:15:29,360 --> 00:15:35,450
are you the one on the hook next slide

00:15:34,170 --> 00:15:37,920
please

00:15:35,450 --> 00:15:40,740
so that's open data hub that's a meta

00:15:37,920 --> 00:15:42,900
project really driven by Red Hat

00:15:40,740 --> 00:15:44,960
there's also a project out there called

00:15:42,900 --> 00:15:47,760
coop flow you might have heard of it

00:15:44,960 --> 00:15:51,120
it's an upstream project that was

00:15:47,760 --> 00:15:53,570
initiated by the folks at Google who

00:15:51,120 --> 00:15:57,060
spent a lot of time doing development of

00:15:53,570 --> 00:15:59,790
machine learning pipelines and

00:15:57,060 --> 00:16:01,440
recommendation engines for YouTube and

00:15:59,790 --> 00:16:04,650
they took some of those back best

00:16:01,440 --> 00:16:08,220
practices and understanding from that

00:16:04,650 --> 00:16:10,650
environment and once open source said so

00:16:08,220 --> 00:16:12,450
that's what goop flow is so that's the

00:16:10,650 --> 00:16:16,170
project I've been involved with for

00:16:12,450 --> 00:16:18,450
about over a year now and it's grown

00:16:16,170 --> 00:16:20,520
quite a bit and the idea is that it's

00:16:18,450 --> 00:16:23,640
totally dedicated to making machine

00:16:20,520 --> 00:16:26,130
learning workflows and pipelines simple

00:16:23,640 --> 00:16:29,250
portable and scalable only on kubernetes

00:16:26,130 --> 00:16:32,070
it's not exclusive to pure kubernetes it

00:16:29,250 --> 00:16:35,580
runs fine on openshift it just requires

00:16:32,070 --> 00:16:38,130
a few tweaks here and there but it's a

00:16:35,580 --> 00:16:40,740
very powerful project again a meta

00:16:38,130 --> 00:16:42,830
project so the idea with coop flow is

00:16:40,740 --> 00:16:46,080
not to recreate all these different

00:16:42,830 --> 00:16:48,930
types of things like Python notebooks

00:16:46,080 --> 00:16:50,970
and Jupiter and all that stuff but

00:16:48,930 --> 00:16:53,940
basically to provide an integrated

00:16:50,970 --> 00:16:55,620
platform kind of like open data hub for

00:16:53,940 --> 00:16:58,140
these different components to fill out

00:16:55,620 --> 00:17:00,060
the machine learning pipeline so the

00:16:58,140 --> 00:17:01,860
core components is a notebook controller

00:17:00,060 --> 00:17:04,260
so you can spin up Jupiter notebooks

00:17:01,860 --> 00:17:07,860
tensorflow training controller you could

00:17:04,260 --> 00:17:10,620
do distributed job training pencil flow

00:17:07,860 --> 00:17:12,510
serving and Seldon there's a sub project

00:17:10,620 --> 00:17:16,910
called captive for hyper parameter

00:17:12,510 --> 00:17:19,800
tuning and then finally a fairly large

00:17:16,910 --> 00:17:22,140
significant sub project that came on

00:17:19,800 --> 00:17:24,000
late into the coop flow project it's

00:17:22,140 --> 00:17:26,340
called coop flow pipelines it actually

00:17:24,000 --> 00:17:30,720
came out of the tensorflow extended tf-x

00:17:26,340 --> 00:17:32,670
group there at Google and they have gone

00:17:30,720 --> 00:17:37,200
about building up a machine learning

00:17:32,670 --> 00:17:38,370
pipeline DSL an SDK that basically sits

00:17:37,200 --> 00:17:41,970
on top of our go

00:17:38,370 --> 00:17:44,400
so they've provided some useful

00:17:41,970 --> 00:17:47,400
learning abstractions on our go which is

00:17:44,400 --> 00:17:49,140
not necessarily designed with machine

00:17:47,400 --> 00:17:51,000
learning in mind it is designed for

00:17:49,140 --> 00:17:55,409
kubernetes but it's more generic than

00:17:51,000 --> 00:17:58,830
that over to you John I think that's it

00:17:55,409 --> 00:18:00,270
for me yes thank you all right so I'm

00:17:58,830 --> 00:18:01,620
just gonna ask a couple questions just

00:18:00,270 --> 00:18:07,020
have a feel of the audience how many

00:18:01,620 --> 00:18:09,600
people here are using our good today I'm

00:18:07,020 --> 00:18:12,120
no not your person I already know what

00:18:09,600 --> 00:18:15,780
you're doing no so how many people

00:18:12,120 --> 00:18:17,669
actually maybe are looking into moving

00:18:15,780 --> 00:18:23,700
from notebooks to workflows for

00:18:17,669 --> 00:18:27,059
production yeah in the back

00:18:23,700 --> 00:18:30,059
alright so I guess my audience is a

00:18:27,059 --> 00:18:32,580
clean slate so that's good because this

00:18:30,059 --> 00:18:33,840
presentation is very basic we want you

00:18:32,580 --> 00:18:38,190
to leave this presentation with some

00:18:33,840 --> 00:18:40,350
idea of which tool to use and maybe a

00:18:38,190 --> 00:18:42,990
little hello world of how to use it so

00:18:40,350 --> 00:18:45,330
what is Argo Argo is an open source

00:18:42,990 --> 00:18:47,250
container native workflow it's one of

00:18:45,330 --> 00:18:50,970
the original I would say contaminate

00:18:47,250 --> 00:18:53,669
avoid workflow tools out there it was

00:18:50,970 --> 00:18:56,190
originally made for CICE workflows but

00:18:53,669 --> 00:18:57,990
then it got picked up by the data

00:18:56,190 --> 00:19:00,150
science community to do production

00:18:57,990 --> 00:19:03,000
workflows why is it containing it why is

00:19:00,150 --> 00:19:05,130
it kubernetes native or container native

00:19:03,000 --> 00:19:07,650
it's because the steps in the workflow

00:19:05,130 --> 00:19:10,169
are containers your run containers and

00:19:07,650 --> 00:19:12,990
then they use something called the

00:19:10,169 --> 00:19:16,380
custom resource to add basically API to

00:19:12,990 --> 00:19:20,760
kubernetes does anybody here know what

00:19:16,380 --> 00:19:24,120
custom resources are on kubernetes ok so

00:19:20,760 --> 00:19:26,309
basically what it is is he tell

00:19:24,120 --> 00:19:28,020
kubernetes I want to provide this AV API

00:19:26,309 --> 00:19:29,309
for the cluster and then this smart your

00:19:28,020 --> 00:19:32,669
this containers gonna take care of that

00:19:29,309 --> 00:19:34,710
API and this is what argo did the custom

00:19:32,669 --> 00:19:36,480
research is called workflow so if you

00:19:34,710 --> 00:19:38,460
want our workflow you just create the

00:19:36,480 --> 00:19:41,880
custom resource and then arguable argo I

00:19:38,460 --> 00:19:45,210
will handle it for you so the workflow

00:19:41,880 --> 00:19:48,030
that Argo provides can be a step-by-step

00:19:45,210 --> 00:19:50,130
parallel steps or dependent steps or it

00:19:48,030 --> 00:19:51,210
could be a dad which are tasks and

00:19:50,130 --> 00:19:53,960
you'll see that in a little bit

00:19:51,210 --> 00:19:56,149
you can pass parameter

00:19:53,960 --> 00:19:59,750
between containers you can define

00:19:56,149 --> 00:20:02,630
artifacts you can do loops you can do

00:19:59,750 --> 00:20:06,440
conditionals you have to write your

00:20:02,630 --> 00:20:10,279
workflow in Yemen I don't know how many

00:20:06,440 --> 00:20:12,679
people are comfortable diamo oh okay

00:20:10,279 --> 00:20:14,600
I say I'm comfortable every time I took

00:20:12,679 --> 00:20:16,669
yeah I look at ya I'm like Oh what is

00:20:14,600 --> 00:20:20,210
this I can't really talk what's under

00:20:16,669 --> 00:20:21,950
what and then there is a UI portal the

00:20:20,210 --> 00:20:24,440
UI portal is very basic it's read-only

00:20:21,950 --> 00:20:25,700
and it's just for you to see the

00:20:24,440 --> 00:20:28,909
workflow and you'll see that in a little

00:20:25,700 --> 00:20:31,220
bit all right so move on on to coop slow

00:20:28,909 --> 00:20:33,740
pipelines which Pete talked a little bit

00:20:31,220 --> 00:20:36,350
about so what coops wall did is they

00:20:33,740 --> 00:20:39,049
took Argo and they built stuff around it

00:20:36,350 --> 00:20:42,020
the first thing they did is provide an

00:20:39,049 --> 00:20:44,840
SDK where you can write your workflow in

00:20:42,020 --> 00:20:46,669
Python they are scientists are more

00:20:44,840 --> 00:20:48,169
comfortable with Python I don't think

00:20:46,669 --> 00:20:49,340
they would run away from Python they

00:20:48,169 --> 00:20:52,100
probably hate writing llamó

00:20:49,340 --> 00:20:54,470
and then what they did also is they kind

00:20:52,100 --> 00:20:56,570
of gave the data scientists more tools

00:20:54,470 --> 00:20:58,700
to do experiments with parameters so

00:20:56,570 --> 00:21:00,200
it's repeatable so you know when you ran

00:20:58,700 --> 00:21:02,240
your workflow you know what parameters

00:21:00,200 --> 00:21:03,919
used when you did it and you can repeat

00:21:02,240 --> 00:21:09,470
it or change the parameters and run it

00:21:03,919 --> 00:21:11,210
in a different way like I said you they

00:21:09,470 --> 00:21:13,880
have Python SDK and you'll see right now

00:21:11,210 --> 00:21:16,960
to be able to compile your Python code

00:21:13,880 --> 00:21:19,250
which in turn translates to a llamó

00:21:16,960 --> 00:21:20,750
workflow that's run by our dough which

00:21:19,250 --> 00:21:23,690
we'll see in a little bit all right so

00:21:20,750 --> 00:21:26,840
now we're gonna look at some code the

00:21:23,690 --> 00:21:28,549
first one is a hello world and I'm gonna

00:21:26,840 --> 00:21:29,870
show you a hello world in our go I'm

00:21:28,549 --> 00:21:32,480
gonna have a world in the coop slow

00:21:29,870 --> 00:21:34,070
pipeline using Python I find it really

00:21:32,480 --> 00:21:36,740
hard these days to find the hello world

00:21:34,070 --> 00:21:40,399
how many people here find it hard when

00:21:36,740 --> 00:21:40,820
looking at open source projects so here

00:21:40,399 --> 00:21:44,090
we go

00:21:40,820 --> 00:21:47,350
this is the hello world for Yemen it's

00:21:44,090 --> 00:21:50,029
pretty straightforward you can see here

00:21:47,350 --> 00:21:51,950
yep you can see here that this is your

00:21:50,029 --> 00:21:54,230
resource the customer is called workflow

00:21:51,950 --> 00:21:57,110
and you're basically just entering the

00:21:54,230 --> 00:21:58,970
parameters of the customer resource this

00:21:57,110 --> 00:22:00,500
is just running basically not even a

00:21:58,970 --> 00:22:02,870
step it's just front running a container

00:22:00,500 --> 00:22:05,330
called way I'll say all it does is just

00:22:02,870 --> 00:22:05,960
print out a picture of a whale that says

00:22:05,330 --> 00:22:08,929
something

00:22:05,960 --> 00:22:11,480
and here's saying hello world and then

00:22:08,929 --> 00:22:16,340
if we go to coop slow this would look

00:22:11,480 --> 00:22:18,919
like this in Python sure this looks more

00:22:16,340 --> 00:22:22,730
well organized we have functions we have

00:22:18,919 --> 00:22:24,409
variables so this is the same thing it's

00:22:22,730 --> 00:22:26,179
running only one container which is

00:22:24,409 --> 00:22:28,610
called will say and it says hello world

00:22:26,179 --> 00:22:31,309
and then when you run this through coop

00:22:28,610 --> 00:22:34,779
flow it's gonna translate to this big

00:22:31,309 --> 00:22:37,279
yamo file and you can see here that

00:22:34,779 --> 00:22:39,200
coops were just added parameters and

00:22:37,279 --> 00:22:41,899
that's the way you run different

00:22:39,200 --> 00:22:43,669
experiments and runs and then it added

00:22:41,899 --> 00:22:45,409
at the bottom here some artifacts and

00:22:43,669 --> 00:22:47,029
they are the metadata for your more

00:22:45,409 --> 00:22:48,590
information about the work for that you

00:22:47,029 --> 00:22:50,330
rack but it's basically the same thing

00:22:48,590 --> 00:22:54,590
it's a container with some argument and

00:22:50,330 --> 00:22:58,279
some image all right next how do we run

00:22:54,590 --> 00:23:00,379
those in our go all you need to do is

00:22:58,279 --> 00:23:03,950
install our go on your kubernetes or

00:23:00,379 --> 00:23:07,070
open shift and then to submit or to run

00:23:03,950 --> 00:23:09,440
a workflow you can either do OC o cube

00:23:07,070 --> 00:23:11,749
CTL create - f and your Yama file or

00:23:09,440 --> 00:23:13,519
Argo they also have a little executable

00:23:11,749 --> 00:23:14,809
you can install on your computer which

00:23:13,519 --> 00:23:17,389
will give you a little bit more visual

00:23:14,809 --> 00:23:18,980
and you'll see that in a little bit and

00:23:17,389 --> 00:23:20,779
then you run your workflow and after you

00:23:18,980 --> 00:23:22,669
run your workflow you can go to the UI

00:23:20,779 --> 00:23:24,830
and then just take a look at what your

00:23:22,669 --> 00:23:27,289
workflow did we'll see that in a little

00:23:24,830 --> 00:23:29,929
bit in coop slow things change a little

00:23:27,289 --> 00:23:32,659
bit for running Python you have to set

00:23:29,929 --> 00:23:34,610
up a virtual Python environment and

00:23:32,659 --> 00:23:37,970
install the coupe's will pipeline SDK

00:23:34,610 --> 00:23:41,119
and compile your Python code into this

00:23:37,970 --> 00:23:43,850
tar.gz file then you go to the UI you

00:23:41,119 --> 00:23:45,799
upload you're tired of GC which in turn

00:23:43,850 --> 00:23:48,710
translates your Yama file that's run by

00:23:45,799 --> 00:23:50,869
our dough so this is kind of like just

00:23:48,710 --> 00:23:52,549
giving you an idea of the difference

00:23:50,869 --> 00:23:54,080
between the two I say if you're just

00:23:52,549 --> 00:23:56,450
starting out you're comfortable yam will

00:23:54,080 --> 00:23:59,269
go with Argo it's only two pods that run

00:23:56,450 --> 00:24:00,710
on a kubernetes or open shift you

00:23:59,269 --> 00:24:02,480
already have come flow or you really

00:24:00,710 --> 00:24:04,700
want the end to end and you're willing

00:24:02,480 --> 00:24:11,110
to give it time to invest more time in

00:24:04,700 --> 00:24:13,519
it go ahead and do Python all right so

00:24:11,110 --> 00:24:14,929
we're gonna run these hello world in the

00:24:13,519 --> 00:24:17,750
demo in a little bit but I just wanted

00:24:14,929 --> 00:24:20,480
to put context for kind of more calm

00:24:17,750 --> 00:24:23,030
located work flow which is based on our

00:24:20,480 --> 00:24:25,370
use case a fraud detection use case so

00:24:23,030 --> 00:24:26,630
we built this use case based on data

00:24:25,370 --> 00:24:30,650
that we downloaded from cargo

00:24:26,630 --> 00:24:34,420
it was around 2000 credit card

00:24:30,650 --> 00:24:38,300
transaction rows of some hidden features

00:24:34,420 --> 00:24:40,310
in the data time and amount including

00:24:38,300 --> 00:24:41,750
the data the full-blown demo is on

00:24:40,310 --> 00:24:44,150
youtube if you're interested to see it

00:24:41,750 --> 00:24:47,300
and we got this data and what we did is

00:24:44,150 --> 00:24:50,390
we created a notebook and we analyzed

00:24:47,300 --> 00:24:51,680
data in the notebook we created a model

00:24:50,390 --> 00:24:54,920
called the random forest where a

00:24:51,680 --> 00:24:57,710
classifier model we used spark to kind

00:24:54,920 --> 00:24:59,750
of grab the data from stuff and then we

00:24:57,710 --> 00:25:01,850
served it user seldom after we served it

00:24:59,750 --> 00:25:04,550
we also grabbed metrics from the model

00:25:01,850 --> 00:25:07,220
and we use Prometheus to grab the

00:25:04,550 --> 00:25:08,840
metrics and show it on graph on all this

00:25:07,220 --> 00:25:10,910
is nice and handy in everything but it's

00:25:08,840 --> 00:25:12,380
not really repeatable we have you know

00:25:10,910 --> 00:25:14,960
we have the Jupiter notebook what if the

00:25:12,380 --> 00:25:17,840
data changes or we want to change the

00:25:14,960 --> 00:25:19,820
model so we're moving into creating this

00:25:17,840 --> 00:25:21,530
workflow and this is the workflow you'll

00:25:19,820 --> 00:25:22,700
see next it's kind of a shell of a

00:25:21,530 --> 00:25:23,240
workflow that we want to do we're not

00:25:22,700 --> 00:25:25,520
there yet

00:25:23,240 --> 00:25:27,740
maybe next year and the next step comp

00:25:25,520 --> 00:25:32,630
would have it completed but this is what

00:25:27,740 --> 00:25:34,280
it looks like so we're reading data from

00:25:32,630 --> 00:25:36,650
different sources and that's just

00:25:34,280 --> 00:25:39,710
showing you how to do parallel steps or

00:25:36,650 --> 00:25:42,290
parallel tasks in a workflow and then

00:25:39,710 --> 00:25:45,020
after this is done we have transforming

00:25:42,290 --> 00:25:47,090
the data task which is another task that

00:25:45,020 --> 00:25:49,040
depends on those two to be done it won't

00:25:47,090 --> 00:25:51,860
run until the two are run already

00:25:49,040 --> 00:25:53,540
and then in transform data this is going

00:25:51,860 --> 00:25:54,980
to decide after we done the data

00:25:53,540 --> 00:25:57,170
transformation it's going to decide

00:25:54,980 --> 00:25:58,880
based on a condition whether it's gonna

00:25:57,170 --> 00:26:00,350
do a hyper parameter tuning or not and

00:25:58,880 --> 00:26:04,250
you'll see that in the demo in a little

00:26:00,350 --> 00:26:06,530
bit after both these are done then we

00:26:04,250 --> 00:26:08,240
train the model after we train the model

00:26:06,530 --> 00:26:10,130
we want to validate the model and we're

00:26:08,240 --> 00:26:11,540
giving here an example of how you run

00:26:10,130 --> 00:26:13,640
the same container with different

00:26:11,540 --> 00:26:16,520
parameters we're gonna run we're gonna

00:26:13,640 --> 00:26:18,410
validate the model with parameter a I'm

00:26:16,520 --> 00:26:21,380
gonna validate it would probably be and

00:26:18,410 --> 00:26:23,480
after we're done we publish the model

00:26:21,380 --> 00:26:25,280
but that's not the end of work for her

00:26:23,480 --> 00:26:26,990
hey actually that's where all the work

00:26:25,280 --> 00:26:28,269
begins we don't have that either ready

00:26:26,990 --> 00:26:30,159
for next year but

00:26:28,269 --> 00:26:32,709
do you publish the model you don't just

00:26:30,159 --> 00:26:34,539
sit there and you just look at it you

00:26:32,709 --> 00:26:36,129
really have to keep watching it you have

00:26:34,539 --> 00:26:38,289
to keep watching the data coming in you

00:26:36,129 --> 00:26:41,219
have to monitoring etc but for this demo

00:26:38,289 --> 00:26:45,969
we're just stuck in there any questions

00:26:41,219 --> 00:26:48,429
good alright so for the demo we're gonna

00:26:45,969 --> 00:26:50,469
run the hello world in both Argo and

00:26:48,429 --> 00:26:52,330
coops well then we're gonna look at the

00:26:50,469 --> 00:26:54,219
fraud detection workflow Yama file and

00:26:52,330 --> 00:26:55,599
we're gonna run it in Argo and we're

00:26:54,219 --> 00:26:56,940
gonna upload it to coop Sloan run it

00:26:55,599 --> 00:27:00,839
again

00:26:56,940 --> 00:27:00,839
alright so let's hop off

00:27:05,850 --> 00:27:09,200
of course I got logged out

00:27:11,520 --> 00:27:14,750
I'm gonna just

00:27:16,140 --> 00:27:19,560
one second

00:27:23,390 --> 00:27:27,190
so I'm just trying to get the password

00:27:40,910 --> 00:27:46,280
all right so this is our cluster and we

00:27:43,980 --> 00:27:46,280
are

00:27:55,299 --> 00:28:03,799
so we are in let's first hop onto our go

00:28:01,130 --> 00:28:06,260
project so when you install our go it

00:28:03,799 --> 00:28:07,670
has two pods running the agro UI takes

00:28:06,260 --> 00:28:10,070
care of the UI which you'll see in a

00:28:07,670 --> 00:28:12,260
little bit and work flow controller that

00:28:10,070 --> 00:28:16,580
takes care of every time you create a

00:28:12,260 --> 00:28:25,010
resource it handles it and let's take a

00:28:16,580 --> 00:28:26,120
look really quick here at coop flow I'm

00:28:25,010 --> 00:28:33,850
just gonna see if I should make it

00:28:26,120 --> 00:28:33,850
bigger my back row see this yes no no no

00:28:36,460 --> 00:28:45,830
alright so basically what you see here

00:28:41,020 --> 00:28:47,750
is a lot of pods you also see the same

00:28:45,830 --> 00:28:50,240
ones this is our new UI and then at the

00:28:47,750 --> 00:28:52,220
end we have the world workflow but you

00:28:50,240 --> 00:28:53,630
but there's a lot of pods running so if

00:28:52,220 --> 00:28:54,679
you want to install coop flow it's a lot

00:28:53,630 --> 00:28:56,360
of dedication and make sure they're

00:28:54,679 --> 00:28:58,100
running and everything but it's an

00:28:56,360 --> 00:29:00,320
end-to-end so it has a lot of tools for

00:28:58,100 --> 00:29:02,210
you to use so that's the other workflow

00:29:00,320 --> 00:29:08,890
container alright so let's hop up and

00:29:02,210 --> 00:29:08,890
look at the hello world yep

00:29:16,480 --> 00:29:22,330
really small I can't make it I can't

00:29:18,550 --> 00:29:23,710
make it big all right so basically it's

00:29:22,330 --> 00:29:28,960
the same thing I shows you it's just one

00:29:23,710 --> 00:29:30,460
container that runs and then all that

00:29:28,960 --> 00:29:31,720
container says is hello world so we're

00:29:30,460 --> 00:29:35,070
gonna hop off and we're gonna run that

00:29:31,720 --> 00:29:35,070
container we run that workflow

00:29:38,870 --> 00:29:53,029
so this one I can make bigger nicer and

00:29:43,700 --> 00:29:56,090
we can look at it here all right it's

00:29:53,029 --> 00:29:59,779
not better a little bit still looking at

00:29:56,090 --> 00:30:02,230
code so this is how it looks and we're

00:29:59,779 --> 00:30:02,230
gonna run it

00:30:15,510 --> 00:30:22,280
all right kicked me out here too

00:30:19,280 --> 00:30:22,280
sorry

00:31:17,360 --> 00:31:24,430
all right sorry again got kicked out of

00:31:21,800 --> 00:31:24,430
the cluster

00:31:36,350 --> 00:31:42,380
all right so we are in the cluster

00:31:39,860 --> 00:31:48,830
project and you're gonna run the

00:31:42,380 --> 00:31:52,330
workflow so we're going to go back to

00:31:48,830 --> 00:31:52,330
the UI to the argue UI

00:31:57,530 --> 00:32:01,340
and you're gonna see a hello world and

00:31:59,840 --> 00:32:03,680
then you can click on it it will tell

00:32:01,340 --> 00:32:05,630
you one pod was running and some

00:32:03,680 --> 00:32:08,510
parameters about the pod and if you look

00:32:05,630 --> 00:32:10,100
at the logs they'll show you what vlogs

00:32:08,510 --> 00:32:12,740
it spit out which is basically hello

00:32:10,100 --> 00:32:15,500
world with the whale so we're gonna do

00:32:12,740 --> 00:32:22,610
another thing is we are gonna run this

00:32:15,500 --> 00:32:24,890
and coop swap and the way we do it in

00:32:22,610 --> 00:32:27,260
coop flow there's a bit different so

00:32:24,890 --> 00:32:29,990
you'll see here this is my Python

00:32:27,260 --> 00:32:36,980
environment that's running and I am

00:32:29,990 --> 00:32:40,750
going to compile my hello world volume

00:32:36,980 --> 00:32:40,750
WI so this is the command we run

00:32:44,430 --> 00:32:49,110
and it's gonna produce this file hello

00:32:46,710 --> 00:32:52,500
world volume tired of GZ I'm gonna hop

00:32:49,110 --> 00:32:55,140
back to coop flow this time and this is

00:32:52,500 --> 00:32:57,180
how the coop slew I looks like the way

00:32:55,140 --> 00:33:03,410
we upload pop lines is this we click

00:32:57,180 --> 00:33:08,760
upload choose the file choose this one

00:33:03,410 --> 00:33:11,610
and we upload it we click on it and if

00:33:08,760 --> 00:33:12,900
you look at the source it looks

00:33:11,610 --> 00:33:14,460
different right we have all these

00:33:12,900 --> 00:33:18,330
artifacts that are attached to it the

00:33:14,460 --> 00:33:27,960
parameters and to run it you create a

00:33:18,330 --> 00:33:29,460
run you can say world run and you can

00:33:27,960 --> 00:33:31,680
add more things this is just simple we

00:33:29,460 --> 00:33:37,010
didn't really add anything now we hit

00:33:31,680 --> 00:33:37,010
start and we can watch it

00:33:46,990 --> 00:33:51,360
casitas running one container

00:33:55,890 --> 00:34:03,600
all right so if you look at the logs it

00:33:59,490 --> 00:34:05,570
did run it and there's an error and that

00:34:03,600 --> 00:34:07,890
error is not a surprise

00:34:05,570 --> 00:34:09,720
we already know that scenario there's an

00:34:07,890 --> 00:34:11,070
issue with running and this issue if

00:34:09,720 --> 00:34:13,530
anybody's interested to know what it is

00:34:11,070 --> 00:34:14,359
but it's basically what it is it's

00:34:13,530 --> 00:34:16,649
OpenShift

00:34:14,359 --> 00:34:19,409
4.1 that we're using does not use docker

00:34:16,649 --> 00:34:21,510
and and the coop slow pipeline is still

00:34:19,409 --> 00:34:23,850
relying on docker for moving parameters

00:34:21,510 --> 00:34:26,520
back and forth but it's an open issue

00:34:23,850 --> 00:34:28,560
that we're still working on all right so

00:34:26,520 --> 00:34:30,840
let's move on here to the last workflow

00:34:28,560 --> 00:34:34,230
we have which is a bit more complicated

00:34:30,840 --> 00:34:37,050
and I am gonna open it from the turtle

00:34:34,230 --> 00:34:39,030
so it looks a little better so this is

00:34:37,050 --> 00:34:45,060
the fraud detection detection workflow

00:34:39,030 --> 00:34:48,720
that we talked about earlier what a

00:34:45,060 --> 00:34:51,300
better back row yeah okay good all right

00:34:48,720 --> 00:34:53,369
so again all these containers that we

00:34:51,300 --> 00:34:55,440
have our just shell containers right now

00:34:53,369 --> 00:34:58,109
we're just building the work zone so we

00:34:55,440 --> 00:34:59,910
have a container called echo this is an

00:34:58,109 --> 00:35:03,890
example for you to know to see how we

00:34:59,910 --> 00:35:06,960
can pass keys and access to an s3

00:35:03,890 --> 00:35:09,450
storage to the container right so we

00:35:06,960 --> 00:35:15,630
have a secret here inside the namespace

00:35:09,450 --> 00:35:18,060
that secret stores these two credentials

00:35:15,630 --> 00:35:18,980
which is access key and key ID and we

00:35:18,060 --> 00:35:22,530
pick them up

00:35:18,980 --> 00:35:24,510
including the s3 endpoint for the bucket

00:35:22,530 --> 00:35:26,869
where we are our object store and we

00:35:24,510 --> 00:35:28,980
just pass them to the container another

00:35:26,869 --> 00:35:31,920
template that we're using is well say

00:35:28,980 --> 00:35:35,010
which I showed in the hello world and

00:35:31,920 --> 00:35:36,450
all it does just draw a whale that says

00:35:35,010 --> 00:35:39,690
something the next one is an interesting

00:35:36,450 --> 00:35:43,320
one it's a container what it does is

00:35:39,690 --> 00:35:45,660
mount a volume and writes in a file in

00:35:43,320 --> 00:35:49,590
that volume whether to run the next step

00:35:45,660 --> 00:35:51,390
or not and here you'll see echo false

00:35:49,590 --> 00:35:53,700
meaning don't run the next step and

00:35:51,390 --> 00:35:56,930
that's the conditional loop example that

00:35:53,700 --> 00:35:59,510
we're gonna go through all right

00:35:56,930 --> 00:36:00,740
let's look at the diet so the first two

00:35:59,510 --> 00:36:02,960
tasks that we showed they run in

00:36:00,740 --> 00:36:05,810
parallel and they're just grabbing data

00:36:02,960 --> 00:36:08,480
so they use echo because echo has the

00:36:05,810 --> 00:36:12,170
credentials for these three buckets and

00:36:08,480 --> 00:36:15,170
then we transform the data and once

00:36:12,170 --> 00:36:17,180
we're transforming the data what we do

00:36:15,170 --> 00:36:18,560
is we decide whether we want to do a

00:36:17,180 --> 00:36:21,260
hyper tuning or not because a hyper

00:36:18,560 --> 00:36:23,360
tuning task is relying on this if this

00:36:21,260 --> 00:36:24,800
is false it won't run if it's true it

00:36:23,360 --> 00:36:26,420
will run and we'll show you this in a

00:36:24,800 --> 00:36:32,180
little bit I'll toggle between them and

00:36:26,420 --> 00:36:34,220
you'll see on the last one just a

00:36:32,180 --> 00:36:38,840
training model and then validate model

00:36:34,220 --> 00:36:41,300
and then the Train model that's another

00:36:38,840 --> 00:36:44,450
example of a for loop it's one container

00:36:41,300 --> 00:36:46,730
that's running twice each time with a

00:36:44,450 --> 00:36:47,930
different parameter that's passed in

00:36:46,730 --> 00:36:51,110
hello world goodbye world

00:36:47,930 --> 00:36:52,580
very intuitive all right and then at the

00:36:51,110 --> 00:36:55,480
end we publish the model so let's run it

00:36:52,580 --> 00:36:55,480
let's run this in our go

00:37:04,690 --> 00:37:10,450
all right and that's hot bucket the UI

00:37:06,950 --> 00:37:10,450
cuz it looks more impressive there

00:37:17,330 --> 00:37:23,000
so transform data right now was false

00:37:19,810 --> 00:37:27,380
meaning hyper parameter tuning is not

00:37:23,000 --> 00:37:29,810
gonna run so read AWS and stuff ran in

00:37:27,380 --> 00:37:32,060
parallel once they're done transform

00:37:29,810 --> 00:37:33,260
data is dependent on them and then it

00:37:32,060 --> 00:37:34,970
ran when they're both done hyper

00:37:33,260 --> 00:37:38,780
parameter is greyed out because it says

00:37:34,970 --> 00:37:41,720
here it's false and then next we train

00:37:38,780 --> 00:37:44,360
the model validate the model which runs

00:37:41,720 --> 00:37:47,590
twice different variables hello world

00:37:44,360 --> 00:37:47,590
goodbye world

00:37:50,620 --> 00:37:54,790
and then we publish the line

00:38:00,590 --> 00:38:05,090
all right so this is one iteration we're

00:38:03,140 --> 00:38:08,170
gonna do it again with false just to see

00:38:05,090 --> 00:38:08,170
it not running just for fun

00:38:25,340 --> 00:38:28,340
okay

00:38:37,030 --> 00:38:40,500
any questions while this is running

00:38:45,120 --> 00:38:48,580
right now it's just a shell but the

00:38:47,590 --> 00:38:50,610
model that we have with linear

00:38:48,580 --> 00:38:50,610
regression

00:38:59,780 --> 00:39:02,320
yeah

00:39:10,390 --> 00:39:14,290
no there's more so you can run

00:39:12,370 --> 00:39:17,740
experiments attach parameters

00:39:14,290 --> 00:39:19,630
experiments so the experiment is

00:39:17,740 --> 00:39:22,180
multiple runs with multiple parameters

00:39:19,630 --> 00:39:23,740
and you can its it keeps the history of

00:39:22,180 --> 00:39:26,380
what you ran and which parameters used

00:39:23,740 --> 00:39:31,090
so you can keep track of it Coop's law

00:39:26,380 --> 00:39:33,670
does there's I think there's more

00:39:31,090 --> 00:39:36,100
complexity in coop flow pipelines right

00:39:33,670 --> 00:39:39,340
in terms of because you can put together

00:39:36,100 --> 00:39:41,410
as a zip file there's probably different

00:39:39,340 --> 00:39:44,020
types of components that could be or

00:39:41,410 --> 00:39:45,640
artifacts within the zip file right no

00:39:44,020 --> 00:39:47,290
they all have to translate to our goal

00:39:45,640 --> 00:39:55,960
so if I go doesn't support it you can't

00:39:47,290 --> 00:39:58,990
do it yeah so so whatever artifacts are

00:39:55,960 --> 00:40:00,580
the supports populates up to Google

00:39:58,990 --> 00:40:02,350
alright so what we're gonna do right now

00:40:00,580 --> 00:40:03,880
so it rants you saw this because we told

00:40:02,350 --> 00:40:06,130
it to run so what we do right now is

00:40:03,880 --> 00:40:08,080
just again for fun

00:40:06,130 --> 00:40:13,270
we're gonna go to coop flow and we're

00:40:08,080 --> 00:40:17,290
gonna run the same pipeline so we do

00:40:13,270 --> 00:40:18,970
pipelines upload a pipeline choose a

00:40:17,290 --> 00:40:23,710
file and this time we're gonna choose

00:40:18,970 --> 00:40:26,590
the fraud detection one and as you can

00:40:23,710 --> 00:40:29,860
see here I can do a mall with Cooper all

00:40:26,590 --> 00:40:32,470
too but I won't get the parameter and

00:40:29,860 --> 00:40:36,430
the metrics is associated with it the

00:40:32,470 --> 00:40:38,380
coop flow does go in here so right now

00:40:36,430 --> 00:40:39,970
it's just showing you the name of the

00:40:38,380 --> 00:40:42,840
container is just not showing you the

00:40:39,970 --> 00:40:48,490
name of the steps and I say create run

00:40:42,840 --> 00:40:51,370
let's just so here you see the run

00:40:48,490 --> 00:40:52,930
parameters this is where you can

00:40:51,370 --> 00:40:55,660
actually specify parameters and change

00:40:52,930 --> 00:40:57,960
them depending on what you want to test

00:40:55,660 --> 00:41:00,960
them or you when I'm doing your run

00:40:57,960 --> 00:41:00,960
start

00:41:26,950 --> 00:41:30,220
the same thing you can have you can see

00:41:29,050 --> 00:41:31,990
someone this is basically the same

00:41:30,220 --> 00:41:34,330
information that you see on Argo logs

00:41:31,990 --> 00:41:36,780
and put out of artefact this is just

00:41:34,330 --> 00:41:36,780
printing

00:41:50,490 --> 00:41:53,670
any questions while this is running are

00:41:52,440 --> 00:41:55,440
we good this is the last thing we're

00:41:53,670 --> 00:41:57,740
gonna demo today you just have one more

00:41:55,440 --> 00:41:57,740
slide

00:42:16,160 --> 00:42:21,050
so can anyone notice the difference

00:42:18,410 --> 00:42:27,920
between in coupe slow between running

00:42:21,050 --> 00:42:31,520
this workflow in the hello world there

00:42:27,920 --> 00:42:35,300
are no errors that's because we use the

00:42:31,520 --> 00:42:36,650
Amal and none of the extra parameters

00:42:35,300 --> 00:42:38,660
that are added by coupe flow where there

00:42:36,650 --> 00:42:39,260
are there so that's why it ran without

00:42:38,660 --> 00:42:41,720
errors

00:42:39,260 --> 00:42:50,180
alright so let's move on to the last

00:42:41,720 --> 00:42:52,190
slide that we have all right so what are

00:42:50,180 --> 00:42:53,930
the future challenges or thing things to

00:42:52,190 --> 00:42:57,640
think about with regards to workflow I

00:42:53,930 --> 00:43:00,920
think automation from perspective of

00:42:57,640 --> 00:43:02,930
moving from a notebook to a workflow how

00:43:00,920 --> 00:43:06,980
do you I think there's some ideas out

00:43:02,930 --> 00:43:09,860
there I just don't think it's well

00:43:06,980 --> 00:43:11,030
thought of or well developed but a lot

00:43:09,860 --> 00:43:13,970
of data scientists start with a notebook

00:43:11,030 --> 00:43:15,440
and how do we translate that or

00:43:13,970 --> 00:43:18,080
transform that into a productive

00:43:15,440 --> 00:43:20,900
production or clone triggers there are

00:43:18,080 --> 00:43:23,450
some triggers I just don't think there

00:43:20,900 --> 00:43:25,520
is enough of them there's a couple of

00:43:23,450 --> 00:43:28,520
them there but it needs to be more

00:43:25,520 --> 00:43:30,710
elaborate to run workflows things like

00:43:28,520 --> 00:43:34,250
triggers could be based on incoming data

00:43:30,710 --> 00:43:36,590
or model performance monitor monitoring

00:43:34,250 --> 00:43:38,750
you have your workflow running I think

00:43:36,590 --> 00:43:40,520
better tools for monitoring how the

00:43:38,750 --> 00:43:44,870
workflows running how its performing

00:43:40,520 --> 00:43:46,790
what to do based on some events within

00:43:44,870 --> 00:43:48,200
the workflow and the last one I think

00:43:46,790 --> 00:43:51,230
it's exciting and it's I think it's

00:43:48,200 --> 00:43:54,350
coming to a multi cluster we do have

00:43:51,230 --> 00:43:57,200
today multi cluster storage but compute

00:43:54,350 --> 00:43:59,210
running a workflow across multiple

00:43:57,200 --> 00:44:01,820
clusters and deciding where you want to

00:43:59,210 --> 00:44:04,820
compute certain steps in the workflow

00:44:01,820 --> 00:44:07,010
it's interesting yep all right so

00:44:04,820 --> 00:44:08,660
there's we've talked about a bunch of

00:44:07,010 --> 00:44:10,780
projects and they have varying degrees

00:44:08,660 --> 00:44:12,920
of maturity in terms of these

00:44:10,780 --> 00:44:15,470
capabilities for example in coop flow

00:44:12,920 --> 00:44:18,320
there's a faring sub project which is

00:44:15,470 --> 00:44:20,270
designed to basically from a notebook do

00:44:18,320 --> 00:44:23,590
the training and then push that out as

00:44:20,270 --> 00:44:27,260
an artifact into a pipeline as an image

00:44:23,590 --> 00:44:28,900
so there is work done there we talked

00:44:27,260 --> 00:44:31,170
about tacked on

00:44:28,900 --> 00:44:34,089
it's fair amount of triggers there but

00:44:31,170 --> 00:44:36,670
all the projects are not entirely equal

00:44:34,089 --> 00:44:38,710
in that that sense and again Tecton does

00:44:36,670 --> 00:44:40,780
have support for targeting multiple

00:44:38,710 --> 00:44:43,540
clusters so you can provide credentials

00:44:40,780 --> 00:44:45,760
for basically going from a task and

00:44:43,540 --> 00:44:48,599
logging in to a cluster and basically

00:44:45,760 --> 00:44:51,160
sending that output to the cluster so

00:44:48,599 --> 00:44:55,119
it's a very interesting space

00:44:51,160 --> 00:44:59,109
I think we've typically set our cap on

00:44:55,119 --> 00:45:00,940
Argo basically for open data of coop

00:44:59,109 --> 00:45:05,710
slow pipelines does have a lot of

00:45:00,940 --> 00:45:07,990
momentum so it's a space that we're kind

00:45:05,710 --> 00:45:10,980
of watching very closely and trying to

00:45:07,990 --> 00:45:13,660
it's difficult to pick a winner but

00:45:10,980 --> 00:45:15,849
where the winners will emerge is the

00:45:13,660 --> 00:45:18,160
degree that they're well integrated with

00:45:15,849 --> 00:45:19,839
other components I would say yeah and

00:45:18,160 --> 00:45:22,210
performance and you saw me when I was

00:45:19,839 --> 00:45:23,770
running the coop flow was kind of slow

00:45:22,210 --> 00:45:27,070
and I had nothing there were just shell

00:45:23,770 --> 00:45:31,810
containers yeah yeah maybe it's do is

00:45:27,070 --> 00:45:36,400
use but is there other questions is

00:45:31,810 --> 00:45:39,530
there non c OE coalition no go ahead

00:45:36,400 --> 00:45:39,530
[Music]

00:45:57,600 --> 00:46:05,790
right now the question is possibly

00:46:01,340 --> 00:46:08,070
providing abstraction for coop flow

00:46:05,790 --> 00:46:12,150
pipelines I think on another platform

00:46:08,070 --> 00:46:13,590
like Tecton yeah and that is sort of

00:46:12,150 --> 00:46:15,630
being discussed in the coop flow

00:46:13,590 --> 00:46:18,180
community unfortunately right now there

00:46:15,630 --> 00:46:21,600
are some agro abstractions that leak

00:46:18,180 --> 00:46:23,820
through and it so there's there's work

00:46:21,600 --> 00:46:27,390
to be done to basically encapsulate that

00:46:23,820 --> 00:46:29,850
stuff also in coop flow they're looking

00:46:27,390 --> 00:46:32,610
at currently in coop flow we have an end

00:46:29,850 --> 00:46:34,470
end sort of testing pipeline currently

00:46:32,610 --> 00:46:36,660
that's totally reliant on our go there's

00:46:34,470 --> 00:46:40,590
an open issue if anybody wants to get

00:46:36,660 --> 00:46:42,630
involved in coop for basically also

00:46:40,590 --> 00:46:55,500
putting in Tecton as a possible

00:46:42,630 --> 00:46:57,870
replacement for for our go ml flow the

00:46:55,500 --> 00:47:01,110
question is how does experiment tracking

00:46:57,870 --> 00:47:03,180
and coop flow pipelines compared to ml

00:47:01,110 --> 00:47:05,790
flow which has been sort of developed by

00:47:03,180 --> 00:47:08,420
data bricks someone raised their hand

00:47:05,790 --> 00:47:08,420
with an answer

00:47:15,240 --> 00:47:21,450
ml flow is right now the gate very

00:47:17,730 --> 00:47:23,040
sophisticated in terms of UI and and the

00:47:21,450 --> 00:47:26,130
various capabilities from a user

00:47:23,040 --> 00:47:32,640
experience at this point all hand off to

00:47:26,130 --> 00:47:38,090
Zak maybe he needs this can you stand up

00:47:32,640 --> 00:47:38,090
Zak and use your other voice yeah

00:48:14,769 --> 00:48:18,619
that that's a good point when is your

00:48:17,000 --> 00:48:21,140
talk is that tomorrow

00:48:18,619 --> 00:48:23,299
oh right after this perfect but but I

00:48:21,140 --> 00:48:25,009
feel like I think part of this is it's

00:48:23,299 --> 00:48:28,160
the whole workflow it you are setting

00:48:25,009 --> 00:48:30,920
parameters versus maybe one model or one

00:48:28,160 --> 00:48:32,960
within demo for this is an end-to-end

00:48:30,920 --> 00:48:34,490
workflow from the beginning of getting

00:48:32,960 --> 00:48:37,579
all the data all the way to publishing

00:48:34,490 --> 00:48:40,630
which is not covered by a month so I

00:48:37,579 --> 00:48:40,630
would think of it as an end-to-end

00:48:43,240 --> 00:48:49,369
currently in coop flow there's no

00:48:46,210 --> 00:48:51,950
there's no sort of inherent integration

00:48:49,369 --> 00:48:53,829
between cats head and couplet pipelines

00:48:51,950 --> 00:48:56,900
there's a lot of discussion about how

00:48:53,829 --> 00:49:00,529
that might look like cat tip currently

00:48:56,900 --> 00:49:02,180
uses model DB for experiment parameter

00:49:00,529 --> 00:49:04,970
tracking and as part of the hyper

00:49:02,180 --> 00:49:06,319
parameter tuning so it's an area where

00:49:04,970 --> 00:49:07,880
they're trying to figure out okay how

00:49:06,319 --> 00:49:12,099
these two things sort of fit together

00:49:07,880 --> 00:49:14,119
currently they're fairly separate so

00:49:12,099 --> 00:49:19,009
down the road hopefully they'll be

00:49:14,119 --> 00:49:22,910
better integration for that yep okay

00:49:19,009 --> 00:49:23,480
anything else good all right thank you

00:49:22,910 --> 00:49:26,049
everybody

00:49:23,480 --> 00:49:26,049

YouTube URL: https://www.youtube.com/watch?v=NZOky2Gm0iA


