Title: Everything you Wanted to Know about Apache Kafka but You Were too Afraid to Ask!
Publication date: 2019-10-02
Playlist: DevConfUS 2019
Description: 
	Speaker: Ricardo Ferreira

Streaming platforms have emerged as a popular, new trend, but what exactly is a streaming platform? Part messaging system, part Hadoop made fast, part fast ETL and scalable data integration, with Apache Kafka at the core, streaming platforms offer an entirely new perspective on managing the flow of data. This talk will explain what a streaming platform such as Apache Kafka is and some of the use cases and design patterns around its use. Moreover, this talk will also present and answer a set of random -- but recurring -- questions from the community about Apache Kafka.
Captions: 
	00:00:17,340 --> 00:00:21,839
alright let's get started guys uh good

00:00:19,779 --> 00:00:24,519
morning

00:00:21,839 --> 00:00:26,740
hope you were enjoying the comforts so

00:00:24,519 --> 00:00:28,960
far how many how many sessions we have

00:00:26,740 --> 00:00:32,920
before when you first started like today

00:00:28,960 --> 00:00:35,890
- 3 - oh cool that's so your brains are

00:00:32,920 --> 00:00:37,270
probably on the peak of understanding

00:00:35,890 --> 00:00:39,910
everything that's going to be true

00:00:37,270 --> 00:00:43,420
that's good alright that's good so this

00:00:39,910 --> 00:00:45,070
session which has this very lengthy and

00:00:43,420 --> 00:00:47,680
weird title

00:00:45,070 --> 00:00:49,630
it's literally aims to teach you about

00:00:47,680 --> 00:00:52,090
everything about that you would like to

00:00:49,630 --> 00:00:53,680
know about Kafka but in a different way

00:00:52,090 --> 00:00:55,360
that you might think right the whole

00:00:53,680 --> 00:00:58,210
purpose of this presentation is to

00:00:55,360 --> 00:01:01,210
address two main topics the first one

00:00:58,210 --> 00:01:02,980
what is Kafka I think that's the most

00:01:01,210 --> 00:01:05,470
interesting one for people that are

00:01:02,980 --> 00:01:07,390
beginning with the Pacha Kafka and would

00:01:05,470 --> 00:01:09,700
like to understand more what to do with

00:01:07,390 --> 00:01:12,070
it and what to expect on it the second

00:01:09,700 --> 00:01:14,289
one is even more important right the

00:01:12,070 --> 00:01:17,590
second session of this presentation is

00:01:14,289 --> 00:01:22,390
to kind of address a couple questions

00:01:17,590 --> 00:01:24,399
that we've been seeing and Stack

00:01:22,390 --> 00:01:26,409
Overflow and those are kind of a

00:01:24,399 --> 00:01:27,969
recording questions that developers from

00:01:26,409 --> 00:01:29,859
the community keep asking about Kafka

00:01:27,969 --> 00:01:31,749
and I'm gonna try to address some of

00:01:29,859 --> 00:01:32,859
those questions right here so I think

00:01:31,749 --> 00:01:35,020
it's gonna be interesting for people

00:01:32,859 --> 00:01:36,789
that are starting with Kafka and people

00:01:35,020 --> 00:01:39,260
that are actually working with Kafka for

00:01:36,789 --> 00:01:41,450
many many years all right

00:01:39,260 --> 00:01:43,850
and this is my twitter handle right here

00:01:41,450 --> 00:01:46,370
and i work for this company here called

00:01:43,850 --> 00:01:50,060
confluent how many of you have where in

00:01:46,370 --> 00:01:52,160
my presentation yesterday from 50% of

00:01:50,060 --> 00:01:53,750
you so I think it's worth if you want to

00:01:52,160 --> 00:01:56,720
explain what confluent is right

00:01:53,750 --> 00:01:58,580
confluent is this company that has been

00:01:56,720 --> 00:02:01,970
founded by original creators of apache

00:01:58,580 --> 00:02:03,890
calculus so basically the three true

00:02:01,970 --> 00:02:05,600
gentlemen's and one lady that were kind

00:02:03,890 --> 00:02:07,340
of a created a technology on linkedin

00:02:05,600 --> 00:02:10,310
they left the company they founded this

00:02:07,340 --> 00:02:11,780
company inc company and that's the

00:02:10,310 --> 00:02:14,180
company that's pragmatically speaking

00:02:11,780 --> 00:02:16,310
behind conquered though technically

00:02:14,180 --> 00:02:18,800
Kafka belongs to Apache and there's a

00:02:16,310 --> 00:02:21,290
huge community of developers working on

00:02:18,800 --> 00:02:22,610
it but 80% of the commits from the

00:02:21,290 --> 00:02:25,310
Koshka fear comes from Coughlin so

00:02:22,610 --> 00:02:27,260
that's that's the deal visions are we

00:02:25,310 --> 00:02:31,040
the company that's what we do

00:02:27,260 --> 00:02:34,340
pragmatically right so as I told you

00:02:31,040 --> 00:02:36,650
before right the main purpose of this

00:02:34,340 --> 00:02:38,330
presentation is kind of to address this

00:02:36,650 --> 00:02:42,470
right here how many of you have heard

00:02:38,330 --> 00:02:44,000
about that Kafka is a cue like I mean

00:02:42,470 --> 00:02:45,470
don't be shy like a pretty pretty much

00:02:44,000 --> 00:02:46,820
everybody kind of would think that cafes

00:02:45,470 --> 00:02:49,250
are killed so that's embedded the whole

00:02:46,820 --> 00:02:53,030
problem what we are trying to address

00:02:49,250 --> 00:02:55,160
here in this presentation is to dismiss

00:02:53,030 --> 00:02:57,830
by this right because this is not true

00:02:55,160 --> 00:02:59,060
all right which is kind of an

00:02:57,830 --> 00:03:01,400
interesting because if you think about

00:02:59,060 --> 00:03:03,410
it 99% of the people in the whole world

00:03:01,400 --> 00:03:05,810
think that Kafka is a cue but it is not

00:03:03,410 --> 00:03:07,010
believe it or not so we're going to try

00:03:05,810 --> 00:03:13,040
to address here in this presentation

00:03:07,010 --> 00:03:14,720
right and hi my name is Ricardo I work

00:03:13,040 --> 00:03:16,370
as a developer advocate for its

00:03:14,720 --> 00:03:19,160
confluence as I may explain it before

00:03:16,370 --> 00:03:22,430
this is my blog and if you want

00:03:19,160 --> 00:03:25,610
something about Kafka or confluent this

00:03:22,430 --> 00:03:27,800
is my email the main purpose of my job

00:03:25,610 --> 00:03:29,840
besides going to conferences and doing

00:03:27,800 --> 00:03:31,489
evangelism and that's why we call

00:03:29,840 --> 00:03:34,459
ourself developer advocates is because

00:03:31,489 --> 00:03:36,680
we literally advocate for you so if you

00:03:34,459 --> 00:03:40,040
have any problems with the Kafka

00:03:36,680 --> 00:03:42,410
documentation any PR that you have file

00:03:40,040 --> 00:03:44,450
on the Kafka project that's taking too

00:03:42,410 --> 00:03:47,250
long for developers to pick up and kind

00:03:44,450 --> 00:03:49,560
of discuss or apply or even reject

00:03:47,250 --> 00:03:51,870
talk to me and I am literally your

00:03:49,560 --> 00:03:54,450
advocate on behalf of confluence

00:03:51,870 --> 00:03:57,900
engineering that's what I do for a

00:03:54,450 --> 00:04:00,570
living right so use me right in a

00:03:57,900 --> 00:04:03,870
correct sense of the work all right

00:04:00,570 --> 00:04:06,420
use me as in your favor okay

00:04:03,870 --> 00:04:08,160
all right let's get started I think the

00:04:06,420 --> 00:04:10,080
first question I would like to pose here

00:04:08,160 --> 00:04:12,240
is how many of you have heard about the

00:04:10,080 --> 00:04:15,990
Stern called distributed string

00:04:12,240 --> 00:04:16,380
platforms before good that is good to

00:04:15,990 --> 00:04:19,440
know

00:04:16,380 --> 00:04:21,090
50% of the rule but still good I have

00:04:19,440 --> 00:04:23,280
done this presentation kind of a six

00:04:21,090 --> 00:04:24,900
times now and believe it or not this is

00:04:23,280 --> 00:04:27,570
the average of people raising their

00:04:24,900 --> 00:04:29,880
hands 50% of the role like how many of

00:04:27,570 --> 00:04:31,890
them have heard about the superstring

00:04:29,880 --> 00:04:34,980
platform and the reason for this is

00:04:31,890 --> 00:04:36,300
because it's a brand new concept so for

00:04:34,980 --> 00:04:38,700
those of you that never have heard of

00:04:36,300 --> 00:04:39,720
before you are more than excuse it

00:04:38,700 --> 00:04:41,850
that's fine

00:04:39,720 --> 00:04:44,430
all right I'm going to explain what this

00:04:41,850 --> 00:04:46,950
is here but the interesting thing is

00:04:44,430 --> 00:04:49,470
that most people go to the kafka website

00:04:46,950 --> 00:04:51,510
they go straight to the download session

00:04:49,470 --> 00:04:52,919
to start using it perhaps they go to the

00:04:51,510 --> 00:04:55,200
documentation from the still a little

00:04:52,919 --> 00:04:58,380
bit more but they often forgot about

00:04:55,200 --> 00:05:02,700
this term right here they never read it

00:04:58,380 --> 00:05:04,410
never like we kind of a asked a lot of

00:05:02,700 --> 00:05:05,970
people about you know the cupcakes did

00:05:04,410 --> 00:05:09,330
you disturb the string platform and they

00:05:05,970 --> 00:05:12,450
asked it really like nobody knows this

00:05:09,330 --> 00:05:14,220
and before I actually went forward the

00:05:12,450 --> 00:05:15,960
answer is right in front of you about

00:05:14,220 --> 00:05:19,650
what a disturbed streaming platform is

00:05:15,960 --> 00:05:21,030
right here I'm not gonna even say it

00:05:19,650 --> 00:05:23,600
what do you think it's Triplets of a

00:05:21,030 --> 00:05:27,810
platform is only looking to this

00:05:23,600 --> 00:05:29,730
screenshot of Apache Kafka what it is

00:05:27,810 --> 00:05:31,440
don't tell me that's the platform that

00:05:29,730 --> 00:05:35,370
is distributed and then streaming come

00:05:31,440 --> 00:05:38,670
on because you're literally reading it's

00:05:35,370 --> 00:05:42,000
more intuitive than this it is a

00:05:38,670 --> 00:05:46,440
platform that allows you to yes do pub

00:05:42,000 --> 00:05:49,110
subscribe but also to process records

00:05:46,440 --> 00:05:52,050
and events as well as is a platform that

00:05:49,110 --> 00:05:54,990
offers storage and persistence

00:05:52,050 --> 00:05:57,330
capabilities that's it

00:05:54,990 --> 00:05:59,100
remaining three main pillars that's what

00:05:57,330 --> 00:06:00,990
it's just a personal platform is all

00:05:59,100 --> 00:06:03,169
right if you if you're one of those

00:06:00,990 --> 00:06:06,150
people like me that created simple

00:06:03,169 --> 00:06:08,250
direct maps in their heads like key

00:06:06,150 --> 00:06:11,669
value maps for understanding things

00:06:08,250 --> 00:06:14,130
Patrick Kafka is this right or this is a

00:06:11,669 --> 00:06:16,830
posh Kafka create the relationship as

00:06:14,130 --> 00:06:21,480
you wanting okay let's dig a little

00:06:16,830 --> 00:06:23,040
deeper in this and before they get a

00:06:21,480 --> 00:06:24,630
little bit but we have to kind of a come

00:06:23,040 --> 00:06:26,780
back in time how many of you have

00:06:24,630 --> 00:06:29,790
watched the vendors endgame by the way

00:06:26,780 --> 00:06:31,620
so this is a huge spoiler for those of

00:06:29,790 --> 00:06:33,450
you that haven't watched it before so

00:06:31,620 --> 00:06:35,070
but I think we are in the period of

00:06:33,450 --> 00:06:36,840
revealing spoiler at this point because

00:06:35,070 --> 00:06:39,180
the the movie has been launched a wide

00:06:36,840 --> 00:06:41,190
two months ago three months ago I don't

00:06:39,180 --> 00:06:43,620
know so this is a spoiler all right

00:06:41,190 --> 00:06:46,290
don't be hard I'll be don't mad about

00:06:43,620 --> 00:06:49,050
this showing this right here because the

00:06:46,290 --> 00:06:51,150
whole the whole solution of the movie is

00:06:49,050 --> 00:06:53,460
there they're going back in time right

00:06:51,150 --> 00:06:54,690
to retrieve the finish stones and to

00:06:53,460 --> 00:06:56,729
defeat Anna than all of that

00:06:54,690 --> 00:07:00,660
oops I just told the spoiler come on

00:06:56,729 --> 00:07:03,450
sorry all right let's go so if we go

00:07:00,660 --> 00:07:05,700
back 30 years ago 25 years ago work how

00:07:03,450 --> 00:07:10,060
many years ago you want it you're gonna

00:07:05,700 --> 00:07:13,090
see that databases were this huge

00:07:10,060 --> 00:07:15,010
very powerful systems that solves all

00:07:13,090 --> 00:07:16,930
the problems in the word right that's a

00:07:15,010 --> 00:07:19,480
feel a little bit of alimentation but

00:07:16,930 --> 00:07:21,190
the point here is that if you go about

00:07:19,480 --> 00:07:23,260
30 years ago most of the systems were

00:07:21,190 --> 00:07:26,260
built on top of databases and there have

00:07:23,260 --> 00:07:28,090
basically two layers right the database

00:07:26,260 --> 00:07:30,100
itself where most of the business logic

00:07:28,090 --> 00:07:32,290
where you didn't in the form or start

00:07:30,100 --> 00:07:34,690
procedures or triggers or something like

00:07:32,290 --> 00:07:37,120
this right and you have the application

00:07:34,690 --> 00:07:38,950
which basically actually as a producer

00:07:37,120 --> 00:07:40,389
and consumer of the database read and

00:07:38,950 --> 00:07:42,790
write from the database and data

00:07:40,389 --> 00:07:46,530
business this entity that remember

00:07:42,790 --> 00:07:48,430
things right where you could reliably

00:07:46,530 --> 00:07:50,950
understand that all your information

00:07:48,430 --> 00:07:54,100
would be safe there that's fair to

00:07:50,950 --> 00:07:57,340
understand right 30 years ago okay but

00:07:54,100 --> 00:07:58,690
these days data bins are too good right

00:07:57,340 --> 00:08:00,479
I don't don't get me wrong I'm not

00:07:58,690 --> 00:08:04,540
saying that database sucks these days

00:08:00,479 --> 00:08:07,210
databases still have their places but

00:08:04,540 --> 00:08:09,910
very specific places and my databases

00:08:07,210 --> 00:08:12,760
until I'm talking about SQL databases

00:08:09,910 --> 00:08:15,100
and no SQL database any type of database

00:08:12,760 --> 00:08:18,190
the point I'm trying to make here is

00:08:15,100 --> 00:08:21,400
that we're living in the end era that

00:08:18,190 --> 00:08:22,900
not every problem in computing it's so

00:08:21,400 --> 00:08:25,180
bad by simply putting your data in the

00:08:22,900 --> 00:08:28,000
database fair enough

00:08:25,180 --> 00:08:29,500
right ok how many of you that develop

00:08:28,000 --> 00:08:32,080
micro services on top of disrepair

00:08:29,500 --> 00:08:32,770
architectures or kubernetes would agree

00:08:32,080 --> 00:08:35,650
with that

00:08:32,770 --> 00:08:37,390
right because databases are not the

00:08:35,650 --> 00:08:38,950
super bullet for every problem in

00:08:37,390 --> 00:08:41,800
computer that's the whole point right

00:08:38,950 --> 00:08:45,010
again you're still have their use cases

00:08:41,800 --> 00:08:47,750
they're still good ok

00:08:45,010 --> 00:08:49,820
all right some of the problems that

00:08:47,750 --> 00:08:53,540
database kind of brings to us the first

00:08:49,820 --> 00:08:55,279
problem is that it's limited and makes a

00:08:53,540 --> 00:08:58,399
lot of mess right

00:08:55,279 --> 00:09:00,560
why is it limited because of the problem

00:08:58,399 --> 00:09:03,950
of volume all right if you go back 30

00:09:00,560 --> 00:09:06,529
years ago you could first see an entire

00:09:03,950 --> 00:09:09,709
earpiece system that would be comprised

00:09:06,529 --> 00:09:12,410
by roughly I don't know 30 or 45 tables

00:09:09,709 --> 00:09:14,300
make some tables or bills and that's not

00:09:12,410 --> 00:09:16,670
you could be an entire year this system

00:09:14,300 --> 00:09:19,250
all on top of a database and you would

00:09:16,670 --> 00:09:21,440
be great to go but because it didn't

00:09:19,250 --> 00:09:23,350
happen internet back then all right

00:09:21,440 --> 00:09:27,110
by the time we start thinking in

00:09:23,350 --> 00:09:29,120
scalability right databases start to

00:09:27,110 --> 00:09:33,170
show their limited a true limitation

00:09:29,120 --> 00:09:35,950
like are any of you our DBA are working

00:09:33,170 --> 00:09:39,380
with a DBA you know what VBA is right so

00:09:35,950 --> 00:09:42,350
imagine that you go for a DBA right I'm

00:09:39,380 --> 00:09:44,360
very good and very like very

00:09:42,350 --> 00:09:45,890
professional DBA anywhere said hey I'm

00:09:44,360 --> 00:09:47,839
gonna developer and I'm starting to

00:09:45,890 --> 00:09:50,209
think about creating this application

00:09:47,839 --> 00:09:52,640
where I would like to store five

00:09:50,209 --> 00:09:53,870
terabytes of data and this application

00:09:52,640 --> 00:09:56,450
is going to consume this five terabytes

00:09:53,870 --> 00:10:00,250
can use a business what's gonna man the

00:09:56,450 --> 00:10:02,420
answer of the day but the DBA hell no

00:10:00,250 --> 00:10:05,240
that's the answer that's gonna keep it

00:10:02,420 --> 00:10:07,279
to you because databases cannot handle

00:10:05,240 --> 00:10:08,899
that volume they're bees are very good

00:10:07,279 --> 00:10:11,180
because they're a transactional system

00:10:08,899 --> 00:10:13,760
but if you start dealing with multiple

00:10:11,180 --> 00:10:15,160
amounts of data in a single database you

00:10:13,760 --> 00:10:19,490
have to start doing things like

00:10:15,160 --> 00:10:21,680
partitioning replication or division by

00:10:19,490 --> 00:10:23,300
silos because the database itself cannot

00:10:21,680 --> 00:10:24,500
keep handling volumes and volumes and

00:10:23,300 --> 00:10:26,690
problems I'm David forever

00:10:24,500 --> 00:10:28,520
all right it's we've gotta slow down the

00:10:26,690 --> 00:10:30,230
database it's not gonna work it's

00:10:28,520 --> 00:10:31,910
proving right it's not me that is

00:10:30,230 --> 00:10:35,149
telling it right this is the industry

00:10:31,910 --> 00:10:38,360
kind of approve this right so what

00:10:35,149 --> 00:10:40,730
happens is that you end up having to do

00:10:38,360 --> 00:10:42,500
some kind of a trickeries and all that

00:10:40,730 --> 00:10:44,839
you overcome this limitation for example

00:10:42,500 --> 00:10:46,380
how many of you have thought about this

00:10:44,839 --> 00:10:49,710
why do we have data

00:10:46,380 --> 00:10:52,260
houses have you thought about this the

00:10:49,710 --> 00:10:54,300
very own reasons why someone came up

00:10:52,260 --> 00:10:56,730
with this idea about let's come up with

00:10:54,300 --> 00:10:59,400
this database that's only focus on

00:10:56,730 --> 00:11:01,320
analytics and not only is the databases

00:10:59,400 --> 00:11:05,010
that are used for the transactional

00:11:01,320 --> 00:11:12,620
systems why okay someone asked me this

00:11:05,010 --> 00:11:16,020
answer me this why they cannot handle

00:11:12,620 --> 00:11:18,510
analytics as well as through sections at

00:11:16,020 --> 00:11:21,870
the same time it will slow down the

00:11:18,510 --> 00:11:24,570
database right that's why we came up

00:11:21,870 --> 00:11:27,210
with this idea about you use an ETL or

00:11:24,570 --> 00:11:29,310
batch ETL is extract you from load right

00:11:27,210 --> 00:11:32,160
so we have this data warehouse where

00:11:29,310 --> 00:11:33,540
periodically usually at midnight we're

00:11:32,160 --> 00:11:35,460
gonna have this small program that's

00:11:33,540 --> 00:11:37,590
gonna strap data from the transactional

00:11:35,460 --> 00:11:40,620
bring to the data warehouse and then

00:11:37,590 --> 00:11:42,930
we're gonna insert all the company's

00:11:40,620 --> 00:11:45,270
questions through the data warehouse so

00:11:42,930 --> 00:11:47,490
the dental house is conceptually a

00:11:45,270 --> 00:11:49,440
replication of the transactional but

00:11:47,490 --> 00:11:51,270
with a different data modeling a

00:11:49,440 --> 00:11:56,690
metadata modeling that's more focused

00:11:51,270 --> 00:12:00,990
and answering questions rather than

00:11:56,690 --> 00:12:04,410
allowing transactions and throughput ok

00:12:00,990 --> 00:12:09,120
turn up transactional their house that's

00:12:04,410 --> 00:12:11,070
why they exist and as for those of you

00:12:09,120 --> 00:12:13,980
that I kind of I have created some ETL

00:12:11,070 --> 00:12:18,240
programs before you know that running

00:12:13,980 --> 00:12:20,100
ETL programs kind of hurts the

00:12:18,240 --> 00:12:22,980
transactional databases hurts because

00:12:20,100 --> 00:12:25,200
you might end up with lots problems you

00:12:22,980 --> 00:12:28,230
mind up with databases that sometimes

00:12:25,200 --> 00:12:30,690
it's more focuses on processing the ETL

00:12:28,230 --> 00:12:31,920
then actually handling the transactional

00:12:30,690 --> 00:12:33,660
records that is coming from the

00:12:31,920 --> 00:12:37,230
transaction systems and that's why

00:12:33,660 --> 00:12:39,300
people choose to run this ETL or batch

00:12:37,230 --> 00:12:42,190
programs at midnight because it's

00:12:39,300 --> 00:12:43,990
outside of business hours right that's

00:12:42,190 --> 00:12:46,949
are you getting the feeling that we are

00:12:43,990 --> 00:12:49,269
coming up with a lot of workarounds

00:12:46,949 --> 00:12:50,980
because one fundamental problem that

00:12:49,269 --> 00:12:53,069
their basis cannot keep handling

00:12:50,980 --> 00:12:58,329
throughput can you get this feeling

00:12:53,069 --> 00:13:00,550
right so I told you that it is a

00:12:58,329 --> 00:13:02,439
database are limited and creates a lot

00:13:00,550 --> 00:13:04,120
of mess the math problem it's kind of a

00:13:02,439 --> 00:13:06,670
consequences of the limitation because

00:13:04,120 --> 00:13:09,430
by the time we start creating this

00:13:06,670 --> 00:13:11,949
multiple databases one for data

00:13:09,430 --> 00:13:14,500
warehouse one for the transaction system

00:13:11,949 --> 00:13:17,350
one because I have a partner that can is

00:13:14,500 --> 00:13:19,029
going to read the data from the the

00:13:17,350 --> 00:13:20,500
transaction system but just like the

00:13:19,029 --> 00:13:22,600
Dare warehouse it cannot kind of a

00:13:20,500 --> 00:13:24,100
compete the throughput with two systems

00:13:22,600 --> 00:13:26,290
so I'm gonna create a third database

00:13:24,100 --> 00:13:27,579
then I'm going to keep replicating just

00:13:26,290 --> 00:13:30,339
for the partner to read the data

00:13:27,579 --> 00:13:32,199
something like this and because the

00:13:30,339 --> 00:13:34,120
company got acquired by another company

00:13:32,199 --> 00:13:36,910
all the database is kind of a merge

00:13:34,120 --> 00:13:39,069
together so in five years of existence

00:13:36,910 --> 00:13:42,430
of one single company you might end up

00:13:39,069 --> 00:13:44,589
with a picture just like this a bunch of

00:13:42,430 --> 00:13:47,790
databases that are keep replicating

00:13:44,589 --> 00:13:50,319
across the entire organization sometimes

00:13:47,790 --> 00:13:52,300
beyond the organization because as I

00:13:50,319 --> 00:13:53,709
said the example of the partners some

00:13:52,300 --> 00:13:57,189
other organization might be interested

00:13:53,709 --> 00:13:59,680
on the data right so database architects

00:13:57,189 --> 00:14:02,259
creates a lot of mess I mean again this

00:13:59,680 --> 00:14:03,160
is not me telling you this is the

00:14:02,259 --> 00:14:05,439
industry

00:14:03,160 --> 00:14:07,720
all right that's why every time I show

00:14:05,439 --> 00:14:09,670
this feature sometimes some people kind

00:14:07,720 --> 00:14:11,920
of start crying like when they say yeah

00:14:09,670 --> 00:14:15,330
man this is my life this is why do you

00:14:11,920 --> 00:14:20,970
everything go day right

00:14:15,330 --> 00:14:23,250
in maintaining write this ETL programs

00:14:20,970 --> 00:14:25,110
it's kind of a fair heart as well all

00:14:23,250 --> 00:14:27,330
right for example you just write you

00:14:25,110 --> 00:14:29,250
just wrote an ETL program to extract

00:14:27,330 --> 00:14:31,610
data from the transaction and load it up

00:14:29,250 --> 00:14:34,500
into a data warehouse system you just

00:14:31,610 --> 00:14:36,540
finish your job you took one week doing

00:14:34,500 --> 00:14:39,690
this you've probably then never slept

00:14:36,540 --> 00:14:41,400
doing this and then someone comes to us

00:14:39,690 --> 00:14:44,190
again you know that column that I've

00:14:41,400 --> 00:14:46,710
used to call order ID yeah I rename it

00:14:44,190 --> 00:14:47,130
to order identifier because it sounds

00:14:46,710 --> 00:14:48,780
cooler

00:14:47,130 --> 00:14:52,530
so what's gonna happen with your ETL

00:14:48,780 --> 00:14:54,480
program it's gonna break right it's

00:14:52,530 --> 00:14:56,580
gonna break you did ETL program is going

00:14:54,480 --> 00:14:58,740
to break because and things like this

00:14:56,580 --> 00:15:00,300
data schema change its keep happening

00:14:58,740 --> 00:15:04,110
all the time so it's kind of hard to

00:15:00,300 --> 00:15:06,720
keep up it forces the company or the

00:15:04,110 --> 00:15:09,300
organization to have a pretty much a

00:15:06,720 --> 00:15:11,790
dedicated team always going for this and

00:15:09,300 --> 00:15:14,520
this is very costly this is what we call

00:15:11,790 --> 00:15:17,430
the collateral cost of having databases

00:15:14,520 --> 00:15:21,390
because those teams those human Labor's

00:15:17,430 --> 00:15:23,460
developers they're very costly last year

00:15:21,390 --> 00:15:25,290
painted by hugs or kisses and pretty

00:15:23,460 --> 00:15:28,740
much I think I don't know right they're

00:15:25,290 --> 00:15:31,410
not so we came up with some workarounds

00:15:28,740 --> 00:15:34,170
across the years to kind of a minimize

00:15:31,410 --> 00:15:36,500
all this mess and limitations that we've

00:15:34,170 --> 00:15:39,660
seen with database the front by the way

00:15:36,500 --> 00:15:43,230
how many of you kind of watch our

00:15:39,660 --> 00:15:46,860
ragnarok yeah so that's what I figured

00:15:43,230 --> 00:15:49,890
because this slide right here it's only

00:15:46,860 --> 00:15:52,620
gonna make sense or even be funny if you

00:15:49,890 --> 00:15:54,240
have watched that movie so but I think

00:15:52,620 --> 00:15:56,670
what I'm trying to say here is that

00:15:54,240 --> 00:15:59,820
another day another Doug is the

00:15:56,670 --> 00:16:02,700
explosion of whole new database have

00:15:59,820 --> 00:16:04,860
came up in the last two years like I

00:16:02,700 --> 00:16:06,990
think there's three type of phenomenon

00:16:04,860 --> 00:16:08,710
in IT industry people creating

00:16:06,990 --> 00:16:10,930
programming languages every day

00:16:08,710 --> 00:16:13,330
people creating JavaScript frameworks

00:16:10,930 --> 00:16:15,640
everyday and people creating databases

00:16:13,330 --> 00:16:18,010
everyday like so that's why

00:16:15,640 --> 00:16:19,779
another day another duck alright so you

00:16:18,010 --> 00:16:21,310
don't need to actually watch for a

00:16:19,779 --> 00:16:25,390
regular rock but I would recommend

00:16:21,310 --> 00:16:27,670
because it's a very funny movie so let's

00:16:25,390 --> 00:16:28,959
see some of the databases that we kind

00:16:27,670 --> 00:16:31,029
of a found through the years the first

00:16:28,959 --> 00:16:33,790
one I think is the most popular one it's

00:16:31,029 --> 00:16:37,270
radoo right I do how many of you have

00:16:33,790 --> 00:16:39,940
heard about it big data very cool I

00:16:37,270 --> 00:16:43,330
think big data is probably one of the

00:16:39,940 --> 00:16:45,820
best kind of LinkedIn skills that people

00:16:43,330 --> 00:16:47,800
and last 10 years put in their profile

00:16:45,820 --> 00:16:49,630
like I know big data because I need a

00:16:47,800 --> 00:16:51,580
real award in Hadoop so something like

00:16:49,630 --> 00:16:53,980
this right it's kind of a cool we're

00:16:51,580 --> 00:16:55,950
working with the big data so Hadoop me

00:16:53,980 --> 00:16:58,450
is a very is a very spectacular

00:16:55,950 --> 00:17:00,370
technology and I have a huge respect for

00:16:58,450 --> 00:17:02,770
Hadoop I have work at with Hadoop before

00:17:00,370 --> 00:17:06,819
I kind of a make me to live in and the

00:17:02,770 --> 00:17:09,640
past using Hadoop but I do solves one

00:17:06,819 --> 00:17:12,939
problem in particular which is the

00:17:09,640 --> 00:17:14,079
problem of volume all right remember the

00:17:12,939 --> 00:17:16,449
example I told you before about

00:17:14,079 --> 00:17:18,220
databases only cannot keeping up with

00:17:16,449 --> 00:17:20,679
like five terabytes of data

00:17:18,220 --> 00:17:22,600
Hadoop does right because they would

00:17:20,679 --> 00:17:25,059
design it to handle large amount of

00:17:22,600 --> 00:17:28,420
large amounts of volume right but still

00:17:25,059 --> 00:17:31,000
Hadoop is continues to be just like

00:17:28,420 --> 00:17:34,990
databases a technology where you start

00:17:31,000 --> 00:17:37,960
data there is persisted in a file system

00:17:34,990 --> 00:17:40,710
called HDFS right and you still have to

00:17:37,960 --> 00:17:43,929
come up with programs or applications

00:17:40,710 --> 00:17:48,160
that's going to read the data out of

00:17:43,929 --> 00:17:52,330
Hadoop bring into memory and start

00:17:48,160 --> 00:17:54,400
processing right the DB the philosophy

00:17:52,330 --> 00:17:57,070
of how do you do computing with Hadoop

00:17:54,400 --> 00:18:01,630
it didn't change so and that sense is

00:17:57,070 --> 00:18:04,000
just like databases right again always

00:18:01,630 --> 00:18:06,460
solving the problem of scalability you

00:18:04,000 --> 00:18:07,070
can't hand a large amount of olive which

00:18:06,460 --> 00:18:10,970
I do

00:18:07,070 --> 00:18:13,220
so for this sake right so how do we

00:18:10,970 --> 00:18:15,710
overcome this problem of having to

00:18:13,220 --> 00:18:17,090
process the data later right because

00:18:15,710 --> 00:18:19,970
that's the whole problematic like they

00:18:17,090 --> 00:18:23,150
store it I acquired the data I started

00:18:19,970 --> 00:18:26,720
and someone else have to process later

00:18:23,150 --> 00:18:31,430
so we came up when when I say we is the

00:18:26,720 --> 00:18:33,950
industry okay we as a community we came

00:18:31,430 --> 00:18:37,430
up with different type of as I call it

00:18:33,950 --> 00:18:41,030
it specialized databases that are

00:18:37,430 --> 00:18:43,870
strictly focused on minimizing as much

00:18:41,030 --> 00:18:47,420
as possible the amount of processing or

00:18:43,870 --> 00:18:49,820
post-processing that you have to do we

00:18:47,420 --> 00:18:51,920
fir a raw data that you have stored in

00:18:49,820 --> 00:18:54,050
the database I'll give you one perfect

00:18:51,920 --> 00:18:59,840
example how many of you know this

00:18:54,050 --> 00:19:01,520
database called the rat is coffee being

00:18:59,840 --> 00:19:04,190
mint Dave's though those examples that I

00:19:01,520 --> 00:19:08,270
gave here those are no sequel databases

00:19:04,190 --> 00:19:10,580
right the example I like to give is

00:19:08,270 --> 00:19:11,690
graph oriented databases for example

00:19:10,580 --> 00:19:15,020
when you were designing an application

00:19:11,690 --> 00:19:17,570
that will behave as a social network the

00:19:15,020 --> 00:19:20,750
social network itself it's being

00:19:17,570 --> 00:19:23,090
modeling as a graph right like a three

00:19:20,750 --> 00:19:24,980
that have live face and each one of this

00:19:23,090 --> 00:19:27,500
leaf it has more leaf is and you can

00:19:24,980 --> 00:19:29,090
have a very concept of a graph in this

00:19:27,500 --> 00:19:32,480
this is one single record the whole

00:19:29,090 --> 00:19:34,340
graph right some of those databases were

00:19:32,480 --> 00:19:36,680
designed so you can start the entire

00:19:34,340 --> 00:19:38,600
graph in the database so when the

00:19:36,680 --> 00:19:42,080
application is going to pull the graph

00:19:38,600 --> 00:19:43,640
out to start reading it or using it as

00:19:42,080 --> 00:19:46,700
you as you call it you don't have to

00:19:43,640 --> 00:19:48,860
process the whole graph again right so

00:19:46,700 --> 00:19:51,590
that's the whole point of using no

00:19:48,860 --> 00:19:52,400
sequel database because you start very

00:19:51,590 --> 00:19:55,280
efficiently

00:19:52,400 --> 00:19:57,560
just like Hadoop it's very good as well

00:19:55,280 --> 00:19:59,720
to handle large amounts of volumes all

00:19:57,560 --> 00:20:01,370
right and when you were going to

00:19:59,720 --> 00:20:04,340
retrieve it you don't need to reprocess

00:20:01,370 --> 00:20:05,800
the whole data because conceptually some

00:20:04,340 --> 00:20:10,190
of those know sequel database already

00:20:05,800 --> 00:20:12,019
process the data during storage

00:20:10,190 --> 00:20:14,090
right that's the whole point that's how

00:20:12,019 --> 00:20:15,440
that's the beauty of no sequel database

00:20:14,090 --> 00:20:18,289
because when you we retrieve it

00:20:15,440 --> 00:20:19,250
here's the key give me the value it's

00:20:18,289 --> 00:20:21,350
very fast

00:20:19,250 --> 00:20:24,259
right and you don't have to reprocess

00:20:21,350 --> 00:20:28,070
just to overcome the information that

00:20:24,259 --> 00:20:28,490
that value comprises make sense all

00:20:28,070 --> 00:20:31,879
right

00:20:28,490 --> 00:20:35,000
but as I said another day another Doug

00:20:31,879 --> 00:20:36,889
we came up with this workaround of

00:20:35,000 --> 00:20:39,620
having different type of databases an

00:20:36,889 --> 00:20:41,720
entire organization and that we again

00:20:39,620 --> 00:20:44,960
kind of a go back to the same problem

00:20:41,720 --> 00:20:46,490
right here right how many of you have

00:20:44,960 --> 00:20:49,370
working companies that you might have

00:20:46,490 --> 00:20:52,789
Oracles Sybase db2 posts queries my

00:20:49,370 --> 00:20:54,590
sequel CouchDB Cassandra MongoDB a lots

00:20:52,789 --> 00:20:57,110
of databases spread all over the

00:20:54,590 --> 00:20:59,450
organization that you are responsible to

00:20:57,110 --> 00:21:02,240
make it happen the data flow in one

00:20:59,450 --> 00:21:05,000
place around right cuz this is your

00:21:02,240 --> 00:21:09,460
problem so again I'm gonna pose the

00:21:05,000 --> 00:21:13,549
question can you see it that we are not

00:21:09,460 --> 00:21:14,659
effectively solving the problem we're

00:21:13,549 --> 00:21:18,320
continuously

00:21:14,659 --> 00:21:20,539
coming up with excuses and excuses and

00:21:18,320 --> 00:21:21,649
excuses and workarounds and workarounds

00:21:20,539 --> 00:21:24,019
and workarounds and we're not

00:21:21,649 --> 00:21:28,399
effectively serving the problem okay

00:21:24,019 --> 00:21:30,830
make sense all right so let's talk about

00:21:28,399 --> 00:21:32,470
oh and before actually forgot always

00:21:30,830 --> 00:21:34,730
forgot about this piece I have to

00:21:32,470 --> 00:21:36,260
practice a little more how does this

00:21:34,730 --> 00:21:38,539
presentation

00:21:36,260 --> 00:21:41,389
messaging technologies have you heard

00:21:38,539 --> 00:21:42,620
about this like remember the question

00:21:41,389 --> 00:21:44,090
that I originally posed in the beginning

00:21:42,620 --> 00:21:47,570
the presentation Kafka is not a cute

00:21:44,090 --> 00:21:49,279
right so cute our example of messaging

00:21:47,570 --> 00:21:52,250
technologies right messaging

00:21:49,279 --> 00:21:54,169
technologies are really cool right I've

00:21:52,250 --> 00:21:57,200
worked with some of this technology

00:21:54,169 --> 00:21:59,539
right here JMS for sure sonic activemq a

00:21:57,200 --> 00:22:02,299
little bit of amazon ask us sometimes

00:21:59,539 --> 00:22:05,480
and that they're very good for a single

00:22:02,299 --> 00:22:09,799
purpose which is moving data from point

00:22:05,480 --> 00:22:11,659
A to point B some people some developers

00:22:09,799 --> 00:22:14,169
also use messaging technology to do this

00:22:11,659 --> 00:22:16,820
to come up with some sort of buffering

00:22:14,169 --> 00:22:18,529
strategies for your applications for

00:22:16,820 --> 00:22:22,070
example I have a backhand micro service

00:22:18,529 --> 00:22:25,580
that cannot handle 10 concurrent process

00:22:22,070 --> 00:22:27,799
per second so what I do instead of my I

00:22:25,580 --> 00:22:29,179
don't know my API gateway delivering the

00:22:27,799 --> 00:22:31,070
message as they happen through the

00:22:29,179 --> 00:22:33,710
back-end service I put a messaging

00:22:31,070 --> 00:22:36,559
technology in between them so the

00:22:33,710 --> 00:22:38,960
messaging radar will throttle the

00:22:36,559 --> 00:22:40,460
processing so I kind of load a little

00:22:38,960 --> 00:22:43,120
bit of my back-end that's one of the

00:22:40,460 --> 00:22:45,110
many use cases that you can serve with

00:22:43,120 --> 00:22:47,000
messaging all right

00:22:45,110 --> 00:22:49,190
so messaging technologies are really

00:22:47,000 --> 00:22:52,250
good all right but in the end of the day

00:22:49,190 --> 00:22:54,830
they're just pipes what I mean about

00:22:52,250 --> 00:22:57,470
they're just pipes they're just a way as

00:22:54,830 --> 00:23:00,549
I've mentioned before to move data some

00:22:57,470 --> 00:23:03,710
point A to point B they are dumb

00:23:00,549 --> 00:23:05,360
why dumb because they cannot they don't

00:23:03,710 --> 00:23:07,820
know what's happening right they're

00:23:05,360 --> 00:23:09,740
basically a carrier right you're

00:23:07,820 --> 00:23:12,620
basically allowing the movement of the

00:23:09,740 --> 00:23:17,500
data but you cannot process them process

00:23:12,620 --> 00:23:21,720
the data s the data is being move it

00:23:17,500 --> 00:23:26,190
alright make sense okay

00:23:21,720 --> 00:23:28,889
so let's go back in time one more time

00:23:26,190 --> 00:23:32,639
but this time not 30 years ago now we

00:23:28,889 --> 00:23:34,889
are going back in time we aren't to tell

00:23:32,639 --> 00:23:36,360
the 19 that's a weird question to ask

00:23:34,889 --> 00:23:40,019
like it's just like I don't know what

00:23:36,360 --> 00:23:44,490
I'm doing here of course we are in 2019

00:23:40,019 --> 00:23:48,600
but let's go back in time like 11 years

00:23:44,490 --> 00:23:50,460
ago right to the end to the peak of this

00:23:48,600 --> 00:23:52,559
company right here called LinkedIn how

00:23:50,460 --> 00:23:58,350
many of you know this company all right

00:23:52,559 --> 00:24:00,120
cool so with then they just like every

00:23:58,350 --> 00:24:02,039
other company or every organization they

00:24:00,120 --> 00:24:03,570
have all the problems that I have

00:24:02,039 --> 00:24:05,399
discussed before they have this

00:24:03,570 --> 00:24:07,259
explosion of data bases inside the

00:24:05,399 --> 00:24:09,299
company they were having lots of

00:24:07,259 --> 00:24:11,159
problems maintaining ETL programs to

00:24:09,299 --> 00:24:13,019
replicated data they were consuming a

00:24:11,159 --> 00:24:15,120
lot of messaging technologies to keep

00:24:13,019 --> 00:24:18,409
moving data from point A to B all these

00:24:15,120 --> 00:24:23,730
problems linked they were suffering but

00:24:18,409 --> 00:24:25,470
linking choose to say and and they come

00:24:23,730 --> 00:24:29,220
up with this idea there's an internal

00:24:25,470 --> 00:24:32,690
project right - okay the title of this

00:24:29,220 --> 00:24:35,279
project is let's solve the problem of

00:24:32,690 --> 00:24:37,200
minimizing considerably the amount of

00:24:35,279 --> 00:24:39,750
databases that we hire inside a company

00:24:37,200 --> 00:24:41,580
because that's cost minimize

00:24:39,750 --> 00:24:43,049
considerably the amount of messaging

00:24:41,580 --> 00:24:45,840
technology that we have inside a copy

00:24:43,049 --> 00:24:48,539
because again this is cost minimize

00:24:45,840 --> 00:24:50,129
considerably the amount of ETL programs

00:24:48,539 --> 00:24:53,070
that we have to keep maintaining all the

00:24:50,129 --> 00:24:55,049
time because again this is cost right

00:24:53,070 --> 00:24:57,990
remember back at 11 years ago sleek and

00:24:55,049 --> 00:25:00,720
it was startup right so cost is a very

00:24:57,990 --> 00:25:04,139
huge problem for them right and more

00:25:00,720 --> 00:25:06,299
probably minimize the complexity of our

00:25:04,139 --> 00:25:09,149
architecture ease so instead of having

00:25:06,299 --> 00:25:10,860
these and remember the mass the diagram

00:25:09,149 --> 00:25:13,350
that I've showed before let's minimize

00:25:10,860 --> 00:25:16,049
the problem I don't want a mess I have

00:25:13,350 --> 00:25:18,299
my life to be funny and beautiful and I

00:25:16,049 --> 00:25:20,549
have to laugh I don't want to cry when I

00:25:18,299 --> 00:25:24,840
go to work right that's what the link

00:25:20,549 --> 00:25:26,999
name was kind of doing so that's why we

00:25:24,840 --> 00:25:28,799
is kind of at the backyard of the SEC

00:25:26,999 --> 00:25:32,820
knowledge that you know today as a pasha

00:25:28,799 --> 00:25:35,850
Kafka right to gentleman's Jake reps and

00:25:32,820 --> 00:25:38,039
Jim Hall and one lady near her I've all

00:25:35,850 --> 00:25:40,019
forget heard last name near her dark in

00:25:38,039 --> 00:25:41,610
a dark a day or dark a day I probably

00:25:40,019 --> 00:25:43,740
mispronounced in her last name

00:25:41,610 --> 00:25:48,480
sorry she used to be my boss actually

00:25:43,740 --> 00:25:51,059
that's a sin they work it about I think

00:25:48,480 --> 00:25:54,539
it was nine months to create the first

00:25:51,059 --> 00:25:56,730
draft of the technology back then wasn't

00:25:54,539 --> 00:26:00,419
called Pasha Kafka back then but it was

00:25:56,730 --> 00:26:02,340
this draft of this architecture II then

00:26:00,419 --> 00:26:04,619
allow all of this all right

00:26:02,340 --> 00:26:06,840
and the project internally was so

00:26:04,619 --> 00:26:08,639
successful because they literally solve

00:26:06,840 --> 00:26:10,710
all this problem that I kind of elected

00:26:08,639 --> 00:26:12,990
to before that they decided to okay

00:26:10,710 --> 00:26:15,690
let's bring this to the community let's

00:26:12,990 --> 00:26:18,240
transform this into Apache Incubator

00:26:15,690 --> 00:26:21,840
project and guess what

00:26:18,240 --> 00:26:23,429
one year later this technology this

00:26:21,840 --> 00:26:27,809
project came out for an Apache Incubator

00:26:23,429 --> 00:26:29,940
to a Pasha GA Pasha Kafka was probably

00:26:27,809 --> 00:26:33,690
one of the first of many successful

00:26:29,940 --> 00:26:36,360
projects and Apache because Apache have

00:26:33,690 --> 00:26:38,850
a very strict set of policies to

00:26:36,360 --> 00:26:41,399
transform an incubator project into a GA

00:26:38,850 --> 00:26:42,899
right they're very picky about this they

00:26:41,399 --> 00:26:45,330
kind of expect that the technologies

00:26:42,899 --> 00:26:47,249
being used throughout the community

00:26:45,330 --> 00:26:49,710
around the world for very long years

00:26:47,249 --> 00:26:53,220
before they decided to promote as GA a

00:26:49,710 --> 00:26:55,049
posh carpet took one year that's why

00:26:53,220 --> 00:26:57,149
it's so so fast and successful right

00:26:55,049 --> 00:26:59,879
forget about scalability aspects of a

00:26:57,149 --> 00:27:02,309
posh carpet brush Kafka as a code itself

00:26:59,879 --> 00:27:04,529
was very successful for the eyes of the

00:27:02,309 --> 00:27:07,120
Apache Software Foundation right which

00:27:04,529 --> 00:27:10,990
is pretty cool we should think about it

00:27:07,120 --> 00:27:13,210
and if you ask me what a possum Kopke is

00:27:10,990 --> 00:27:15,880
i told you before it is a super stringy

00:27:13,210 --> 00:27:17,950
platform but what that really means is

00:27:15,880 --> 00:27:20,380
if you think about what is the

00:27:17,950 --> 00:27:23,770
advantages of messaging technologies

00:27:20,380 --> 00:27:26,080
which is fast flow rate latency and the

00:27:23,770 --> 00:27:28,120
advantages of ETL and databases

00:27:26,080 --> 00:27:30,040
architecture which is highly scalable

00:27:28,120 --> 00:27:33,570
highly durable highly persistent and

00:27:30,040 --> 00:27:37,960
highly ordering if you mix them together

00:27:33,570 --> 00:27:42,270
that is what distributing platform are

00:27:37,960 --> 00:27:49,840
and therefore that is what Apache Kafka

00:27:42,270 --> 00:27:52,390
really is okay it's a platform if it's

00:27:49,840 --> 00:27:56,650
not clear yet it's a platform that

00:27:52,390 --> 00:28:01,030
allows you to process data as they

00:27:56,650 --> 00:28:03,370
happen at scale terabytes of data is not

00:28:01,030 --> 00:28:07,510
an intimidation for a posh Kafka right

00:28:03,370 --> 00:28:10,330
and more importantly it can act just

00:28:07,510 --> 00:28:11,950
like a messaging technology right but

00:28:10,330 --> 00:28:13,510
without the limitation of messaging

00:28:11,950 --> 00:28:17,110
technology I'm going to discuss this

00:28:13,510 --> 00:28:20,200
later on right and still efficiently and

00:28:17,110 --> 00:28:22,300
durably and consistently doing all the

00:28:20,200 --> 00:28:25,060
things that a typical database could do

00:28:22,300 --> 00:28:26,580
like transactions and seed properties

00:28:25,060 --> 00:28:30,520
like you know atomicity consistency

00:28:26,580 --> 00:28:32,980
isolation and durability acid properties

00:28:30,520 --> 00:28:35,860
of a database can do all this we're

00:28:32,980 --> 00:28:37,870
gonna discuss this before okay so that

00:28:35,860 --> 00:28:39,790
was a batch of Kafka really is so if

00:28:37,870 --> 00:28:42,280
there is one thing that I would like you

00:28:39,790 --> 00:28:44,590
to bring back when you leave this

00:28:42,280 --> 00:28:50,590
presentation is what Apache Kafka it's

00:28:44,590 --> 00:28:53,320
not what a post Kafka is not

00:28:50,590 --> 00:28:55,779
it's not a queue is a distribution

00:28:53,320 --> 00:28:58,029
platform more powerful than a simple

00:28:55,779 --> 00:29:02,049
queue it's not good as a key for the

00:28:58,029 --> 00:29:04,059
God's sake that's what's the whole

00:29:02,049 --> 00:29:06,279
problem that's what we are at Compline

00:29:04,059 --> 00:29:08,830
we are as a company kind of a behind

00:29:06,279 --> 00:29:10,539
Basha Kafka we're trying to educate

00:29:08,830 --> 00:29:12,490
people around the world about this

00:29:10,539 --> 00:29:15,879
concept because actually there was our

00:29:12,490 --> 00:29:18,429
mistake because back then you're not

00:29:15,879 --> 00:29:22,179
sure if it's our mistake along but we

00:29:18,429 --> 00:29:25,570
take the tool nuts because that's kind

00:29:22,179 --> 00:29:27,519
of a shows responsibility we presented

00:29:25,570 --> 00:29:30,610
the technology as a messaging technology

00:29:27,519 --> 00:29:33,220
10 years ago so it's kind of a natural

00:29:30,610 --> 00:29:35,230
for people to compare magic Africa to

00:29:33,220 --> 00:29:38,590
alter messaging technology such as

00:29:35,230 --> 00:29:42,450
wrapped mq action to IBM and Q or

00:29:38,590 --> 00:29:45,429
something like this so but we are slowly

00:29:42,450 --> 00:29:50,679
remembered for people that is not just

00:29:45,429 --> 00:29:52,090
of that ok all right so back to the

00:29:50,679 --> 00:29:56,169
question what is it descriptive serene

00:29:52,090 --> 00:29:57,639
platform it's all boils down alright I

00:29:56,169 --> 00:29:59,559
just explained what a disturb the

00:29:57,639 --> 00:30:04,240
soudanese platform is but it all boils

00:29:59,559 --> 00:30:06,580
down to making you understand that a

00:30:04,240 --> 00:30:10,269
distributor serving platform just like a

00:30:06,580 --> 00:30:13,149
database can be seen as yourson single

00:30:10,269 --> 00:30:17,529
source of truth all right you know what

00:30:13,149 --> 00:30:19,779
that means like you know that phrase

00:30:17,529 --> 00:30:22,179
that we used to use for databases that

00:30:19,779 --> 00:30:24,369
we treat the database as your source of

00:30:22,179 --> 00:30:26,440
truths like all the applications right

00:30:24,369 --> 00:30:29,649
into the database so all their

00:30:26,440 --> 00:30:32,049
applications can confidently believe

00:30:29,649 --> 00:30:36,220
that the data that is coming from that

00:30:32,049 --> 00:30:39,610
database is reliable it's consistent

00:30:36,220 --> 00:30:42,249
it's durable I can trust my Processing's

00:30:39,610 --> 00:30:45,740
and my decisions doesn't on that data

00:30:42,249 --> 00:30:48,230
because the database is believable I

00:30:45,740 --> 00:30:50,210
so you can do the same thing with posh

00:30:48,230 --> 00:30:51,770
Kafka and all started with this guy

00:30:50,210 --> 00:30:54,850
right here do you know how many of you

00:30:51,770 --> 00:30:56,659
know what this guy are but this guy is

00:30:54,850 --> 00:30:59,990
that heroin

00:30:56,659 --> 00:31:03,679
do you know I've heard about a very

00:30:59,990 --> 00:31:05,929
small company called a SS and maybe

00:31:03,679 --> 00:31:07,220
measurer have you heard about this cloud

00:31:05,929 --> 00:31:09,919
provide this very small

00:31:07,220 --> 00:31:11,840
I heard from Microsoft this is the guy

00:31:09,919 --> 00:31:14,510
that basically architected the whole

00:31:11,840 --> 00:31:18,260
high scalability behind ADA bless and

00:31:14,510 --> 00:31:21,860
Azure he's probably best known for this

00:31:18,260 --> 00:31:24,500
accomplishment so in other words he's a

00:31:21,860 --> 00:31:28,010
very good guy like he's he's very smart

00:31:24,500 --> 00:31:29,510
and he wrote this paper right basically

00:31:28,010 --> 00:31:32,419
the name of the paper immutability

00:31:29,510 --> 00:31:37,730
changed everything right he's very good

00:31:32,419 --> 00:31:40,850
at discipline systems design right and

00:31:37,730 --> 00:31:44,390
solving justice system problems with

00:31:40,850 --> 00:31:46,370
very smart and simple solutions and he

00:31:44,390 --> 00:31:48,380
basically kind of came up with the

00:31:46,370 --> 00:31:52,640
strategy of thinking and data in terms

00:31:48,380 --> 00:31:54,649
of logs right and this is how a posture

00:31:52,640 --> 00:31:57,289
Kafka structures the data as a log

00:31:54,649 --> 00:31:59,029
that's how they map a skeptic in front

00:31:57,289 --> 00:32:01,399
so there's this author called Franz

00:31:59,029 --> 00:32:04,429
Kafka which basically is known because

00:32:01,399 --> 00:32:06,830
he writes small stories or journals but

00:32:04,429 --> 00:32:09,169
has a college so this mean stars its

00:32:06,830 --> 00:32:11,299
forms as a sequence one after the other

00:32:09,169 --> 00:32:13,010
if you read the third Journal it has a

00:32:11,299 --> 00:32:15,950
link with the previous journal because

00:32:13,010 --> 00:32:17,570
the store is always continuously to be

00:32:15,950 --> 00:32:19,909
delivered that's how can we trace the

00:32:17,570 --> 00:32:23,679
log that's how the name Kafka came from

00:32:19,909 --> 00:32:25,760
for this outer French captain right and

00:32:23,679 --> 00:32:28,850
when we start thinking now about this

00:32:25,760 --> 00:32:31,399
concept of Kafka logs right we are going

00:32:28,850 --> 00:32:34,970
to realize that Kafka as a technology

00:32:31,399 --> 00:32:36,080
has three main pillars it's basically

00:32:34,970 --> 00:32:40,090
the three main pillars that I've

00:32:36,080 --> 00:32:40,090
discussed before remember subscribe

00:32:40,149 --> 00:32:45,830
storage and persistency as well as the

00:32:43,610 --> 00:32:48,710
ability to process data right that's the

00:32:45,830 --> 00:32:49,660
main the foundation of what Kafka does

00:32:48,710 --> 00:32:52,450
so like

00:32:49,660 --> 00:32:55,150
quickly discuss each one of them right

00:32:52,450 --> 00:32:56,530
and then I'm gonna do a very cool them a

00:32:55,150 --> 00:32:59,080
probably you're gonna enjoy it

00:32:56,530 --> 00:33:01,900
there's gonna showcase the power of

00:32:59,080 --> 00:33:04,180
Kafka alright and how you design systems

00:33:01,900 --> 00:33:06,640
around Kafka so because everything that

00:33:04,180 --> 00:33:08,860
I've told you right now although I think

00:33:06,640 --> 00:33:11,590
it's interesting it's kind of a it looks

00:33:08,860 --> 00:33:14,710
like a little abstract in your mind at

00:33:11,590 --> 00:33:16,690
this point right now I know this because

00:33:14,710 --> 00:33:18,130
that's the feedback I get kind of a

00:33:16,690 --> 00:33:20,230
receive for everybody that believes this

00:33:18,130 --> 00:33:22,960
presentation so don't mind if it's too

00:33:20,230 --> 00:33:25,540
abstract right but let's discuss this

00:33:22,960 --> 00:33:29,320
first and then we can do the demo first

00:33:25,540 --> 00:33:32,080
of all is messaging doing done right

00:33:29,320 --> 00:33:39,040
right what did I'm what I kind of meant

00:33:32,080 --> 00:33:41,410
when I say this homework for you not for

00:33:39,040 --> 00:33:43,000
now of course when you leave this

00:33:41,410 --> 00:33:44,770
presentation and if you're still

00:33:43,000 --> 00:33:47,700
interested in learning more about Kafka

00:33:44,770 --> 00:33:47,700
go

00:33:51,290 --> 00:33:57,390
okay when you were after the

00:33:55,590 --> 00:34:02,220
presentation you go through the Kafka

00:33:57,390 --> 00:34:05,250
site Kafka the Apache org I think you go

00:34:02,220 --> 00:34:08,669
to the documentation session right and

00:34:05,250 --> 00:34:11,600
do a ctrl F like it to search and search

00:34:08,669 --> 00:34:14,629
for this words descent is called don't

00:34:11,600 --> 00:34:19,470
fear the file system

00:34:14,629 --> 00:34:21,629
very cool right and basically what he

00:34:19,470 --> 00:34:23,310
the author says and basically by the way

00:34:21,629 --> 00:34:25,230
the author is Jake reps the guy that

00:34:23,310 --> 00:34:26,119
actually one of the guys that created a

00:34:25,230 --> 00:34:28,260
posh Kafka

00:34:26,119 --> 00:34:30,990
Paul's is a very interesting question

00:34:28,260 --> 00:34:34,770
about how you should see file systems

00:34:30,990 --> 00:34:37,919
right like for example what ran ran

00:34:34,770 --> 00:34:42,119
memory ran means the the Ekron ran what

00:34:37,919 --> 00:34:44,820
what that means random access memory so

00:34:42,119 --> 00:34:47,869
the first word random if you are dealing

00:34:44,820 --> 00:34:51,080
with a storage that you have to randomly

00:34:47,869 --> 00:34:53,580
retrieve data right to start processing

00:34:51,080 --> 00:34:57,109
memory or read is going to be very

00:34:53,580 --> 00:35:00,330
efficiency because you are randomly

00:34:57,109 --> 00:35:00,780
searching for data on that storage all

00:35:00,330 --> 00:35:04,260
right

00:35:00,780 --> 00:35:06,570
however if you try to do the same thing

00:35:04,260 --> 00:35:10,500
with a disk it's going to be terribly

00:35:06,570 --> 00:35:13,920
slow why because this little thing here

00:35:10,500 --> 00:35:16,140
called needle or sectors of the disk of

00:35:13,920 --> 00:35:19,550
the hard disk we're not designed for

00:35:16,140 --> 00:35:22,109
doing things randomly right make sense

00:35:19,550 --> 00:35:23,940
searching things in a disk requires you

00:35:22,109 --> 00:35:27,510
to move the needle very very very fast

00:35:23,940 --> 00:35:30,810
and so even if you have the best start

00:35:27,510 --> 00:35:32,760
disk and homeworld the number of rpms or

00:35:30,810 --> 00:35:35,280
rotations per minutes is going to be

00:35:32,760 --> 00:35:37,620
infinite slower and smaller than wrap

00:35:35,280 --> 00:35:40,890
right

00:35:37,620 --> 00:35:43,860
without me explaining back to you how do

00:35:40,890 --> 00:35:47,010
you think we should search for things

00:35:43,860 --> 00:35:48,210
this in this type of architecture just

00:35:47,010 --> 00:35:50,280
look at the picture I'm not gonna get

00:35:48,210 --> 00:35:57,540
even explain it's very explainable by

00:35:50,280 --> 00:36:00,150
itself coming in I like it it's right

00:35:57,540 --> 00:36:03,540
technically speaking but I'm looking for

00:36:00,150 --> 00:36:06,360
another word actually think about the

00:36:03,540 --> 00:36:09,210
format of the disk which is a circle and

00:36:06,360 --> 00:36:13,080
think about this this movement of the

00:36:09,210 --> 00:36:15,420
needle that has to do like think about

00:36:13,080 --> 00:36:20,220
clockwise what is doing this clockwise

00:36:15,420 --> 00:36:20,970
what is this for you sequencing my

00:36:20,220 --> 00:36:23,670
friend

00:36:20,970 --> 00:36:29,100
it's searching for things or processes

00:36:23,670 --> 00:36:30,660
and a sequence e of alright so back to

00:36:29,100 --> 00:36:32,400
the documentation part I've explained it

00:36:30,660 --> 00:36:35,000
before don't fear the file system he

00:36:32,400 --> 00:36:37,740
came up with this idea about what if

00:36:35,000 --> 00:36:39,510
instead of using those algorithms and

00:36:37,740 --> 00:36:41,580
data structures that we typically kind

00:36:39,510 --> 00:36:44,490
of a model in database which is between

00:36:41,580 --> 00:36:47,130
that allows easily retrievable data when

00:36:44,490 --> 00:36:50,640
you were randomly trying to search for

00:36:47,130 --> 00:36:53,610
data what if we use data structures that

00:36:50,640 --> 00:36:56,220
structures the data as a log remember

00:36:53,610 --> 00:36:58,980
the law concept right one after the

00:36:56,220 --> 00:37:01,020
other right where each position of the

00:36:58,980 --> 00:37:03,240
data has an offset that I uniquely

00:37:01,020 --> 00:37:05,220
identifies the position of the log and

00:37:03,240 --> 00:37:06,990
when you were about to search data

00:37:05,220 --> 00:37:09,270
remember that this table here is a log

00:37:06,990 --> 00:37:11,130
right that's why I keep moving in front

00:37:09,270 --> 00:37:12,750
of you and when you were about to search

00:37:11,130 --> 00:37:17,180
data the only thing I have to do is move

00:37:12,750 --> 00:37:20,569
the offset old or backward

00:37:17,180 --> 00:37:23,270
right no struggle a that I only need if

00:37:20,569 --> 00:37:24,500
I know the offset number the exact

00:37:23,270 --> 00:37:26,930
position of the data

00:37:24,500 --> 00:37:28,099
I moved the offset forward or back how

00:37:26,930 --> 00:37:32,900
fast do you think there's gonna be here

00:37:28,099 --> 00:37:35,420
maybe for hard disks and he proves right

00:37:32,900 --> 00:37:38,420
there's an article actually he refers to

00:37:35,420 --> 00:37:41,900
an ACM Journal article he proves that

00:37:38,420 --> 00:37:45,109
believe it or not this is faster than

00:37:41,900 --> 00:37:48,319
ran faster

00:37:45,109 --> 00:37:50,630
imagine this so it's all about how you

00:37:48,319 --> 00:37:53,000
structure the data the algorithm and

00:37:50,630 --> 00:37:55,880
dinner structures as well as which type

00:37:53,000 --> 00:37:58,280
of stars to use it right so what is the

00:37:55,880 --> 00:38:01,730
advantages of this strategy first of all

00:37:58,280 --> 00:38:04,609
it's much better I mean huh what is he

00:38:01,730 --> 00:38:10,670
like if we buy a machinist days

00:38:04,609 --> 00:38:14,540
I think typical regular Bell machine let

00:38:10,670 --> 00:38:17,200
you gonna buy for your data center we'd

00:38:14,540 --> 00:38:20,630
have one 128 gigabytes of memory

00:38:17,200 --> 00:38:23,559
something like this or 256 gigabytes of

00:38:20,630 --> 00:38:27,319
memory tops why let's

00:38:23,559 --> 00:38:28,819
512 gigabytes of data right that's the

00:38:27,319 --> 00:38:31,339
hand memory available for your cheese

00:38:28,819 --> 00:38:35,359
right it's still limited it's too small

00:38:31,339 --> 00:38:38,540
for these days specifically how much how

00:38:35,359 --> 00:38:41,839
much ha your laptops has as a hard disk

00:38:38,540 --> 00:38:44,299
how much stars you have in our bytes 1

00:38:41,839 --> 00:38:47,240
terabyte soup terabytes imagine a server

00:38:44,299 --> 00:38:49,309
having 5 terabytes 10 terabytes 100

00:38:47,240 --> 00:38:51,680
terabytes like petabytes

00:38:49,309 --> 00:38:54,290
right of disks because you can cluster

00:38:51,680 --> 00:38:55,210
disks to come up with 1 petabyte of data

00:38:54,290 --> 00:38:59,359
right

00:38:55,210 --> 00:39:02,630
imagine you using those disks to start

00:38:59,359 --> 00:39:04,460
data and process data on those discs as

00:39:02,630 --> 00:39:07,730
the way I told it before sequency and

00:39:04,460 --> 00:39:10,280
using moving the offsets that's the

00:39:07,730 --> 00:39:12,110
magic of a Pasha cava guys

00:39:10,280 --> 00:39:13,340
why Kafka's so much scalable than the

00:39:12,110 --> 00:39:16,880
other brokers our messaging technology

00:39:13,340 --> 00:39:18,560
because of this it uses the disk for

00:39:16,880 --> 00:39:20,150
this and you know something else that

00:39:18,560 --> 00:39:22,550
Kafka does that's pretty cool

00:39:20,150 --> 00:39:24,560
actually there are two more things one

00:39:22,550 --> 00:39:26,450
of them have you heard about this term

00:39:24,560 --> 00:39:29,810
of operating systems modern operating

00:39:26,450 --> 00:39:33,590
system call OS page cache Linux uses

00:39:29,810 --> 00:39:36,410
UNIX system uses which is region of your

00:39:33,590 --> 00:39:38,990
available memory that uses for cache

00:39:36,410 --> 00:39:43,340
data that is been stored in a file

00:39:38,990 --> 00:39:46,610
system right uses this heavily right

00:39:43,340 --> 00:39:49,460
typical Kafka broker has only two three

00:39:46,610 --> 00:39:52,580
gigabytes of memory for the heap memory

00:39:49,460 --> 00:39:54,680
which is a JVM right so it's two three

00:39:52,580 --> 00:39:56,870
three bytes of memory for JVM it's more

00:39:54,680 --> 00:39:59,240
than enough for the broker the actual

00:39:56,870 --> 00:40:03,740
data is not loaded into the heap memory

00:39:59,240 --> 00:40:05,390
it's loaded into OS page cache so that

00:40:03,740 --> 00:40:07,100
means if you compare Kafka to our

00:40:05,390 --> 00:40:09,350
ActiveMQ for example which is purely

00:40:07,100 --> 00:40:11,390
reading in Java it runs in the JVM

00:40:09,350 --> 00:40:14,780
actual cube is gonna load up all the

00:40:11,390 --> 00:40:16,670
data into the JVM which is I can load

00:40:14,780 --> 00:40:19,070
all the data I want into JVM without

00:40:16,670 --> 00:40:21,670
having garbage collection problems no

00:40:19,070 --> 00:40:24,140
you cannot sixteen gigabytes of memory

00:40:21,670 --> 00:40:27,020
data in a memory for in the fridge Aegon

00:40:24,140 --> 00:40:31,730
is already too much for them all right

00:40:27,020 --> 00:40:33,110
not for copter the second very design is

00:40:31,730 --> 00:40:34,790
actually the third because the first one

00:40:33,110 --> 00:40:37,100
using the disk the third design decision

00:40:34,790 --> 00:40:39,470
that Kafka does which is very cool there

00:40:37,100 --> 00:40:40,280
is an API from the Linux and UNIX file

00:40:39,470 --> 00:40:44,600
system called

00:40:40,280 --> 00:40:46,970
sent file have you heard about it it's

00:40:44,600 --> 00:40:50,870
very uncommon but basically what the

00:40:46,970 --> 00:40:53,870
send file API function does is Ireland

00:40:50,870 --> 00:40:56,890
let me create an analogy have you heard

00:40:53,870 --> 00:40:56,890
about InfiniBand

00:40:57,000 --> 00:41:02,970
cinnamon is kind of a competitor of

00:40:59,220 --> 00:41:06,930
Ethernet type of networks whereas

00:41:02,970 --> 00:41:08,580
Ethernet has a throughput of 10 or maybe

00:41:06,930 --> 00:41:11,849
10 gigabytes per second

00:41:08,580 --> 00:41:12,740
InfiniBand can have like 80 gigabytes

00:41:11,849 --> 00:41:14,640
per second

00:41:12,740 --> 00:41:16,080
there are something pretty bad

00:41:14,640 --> 00:41:18,300
architecture that actually go beyond

00:41:16,080 --> 00:41:20,730
that it's like 120 gigabytes per second

00:41:18,300 --> 00:41:23,970
in a network level so the free report is

00:41:20,730 --> 00:41:27,720
even smaller even higher right so what

00:41:23,970 --> 00:41:30,240
this end file API does is imagine that

00:41:27,720 --> 00:41:32,940
your application that runs on top of the

00:41:30,240 --> 00:41:35,490
operating system is trying to send data

00:41:32,940 --> 00:41:37,349
out to another application running and

00:41:35,490 --> 00:41:39,359
another machine right in a typical

00:41:37,349 --> 00:41:41,460
Ethernet architect what's gonna happen

00:41:39,359 --> 00:41:44,099
you're gonna have the seven layers of

00:41:41,460 --> 00:41:46,920
the network topology and have buffer

00:41:44,099 --> 00:41:48,599
copies between them right copy to this

00:41:46,920 --> 00:41:50,369
layer copy this layer copy this layer

00:41:48,599 --> 00:41:53,310
until the final layer which is the

00:41:50,369 --> 00:41:55,590
network heart that's going to transmit

00:41:53,310 --> 00:41:58,050
the bits to the other network card in

00:41:55,590 --> 00:42:00,150
other words right you know what to send

00:41:58,050 --> 00:42:01,980
fire function does here's your

00:42:00,150 --> 00:42:05,730
application right straight in the

00:42:01,980 --> 00:42:09,150
network card straight without buffer

00:42:05,730 --> 00:42:11,280
copies so it doesn't burn CPU cycles for

00:42:09,150 --> 00:42:11,849
transmitting data so let's go back a

00:42:11,280 --> 00:42:14,820
little bit

00:42:11,849 --> 00:42:17,940
the data's original OS page cache so

00:42:14,820 --> 00:42:19,770
there's no y ou at all I can't transmit

00:42:17,940 --> 00:42:21,480
that data it's right for the RAS page

00:42:19,770 --> 00:42:26,339
cache straight to the network card

00:42:21,480 --> 00:42:27,780
without any i/o that's why calf gets so

00:42:26,339 --> 00:42:30,270
much scalable than the automat some

00:42:27,780 --> 00:42:33,089
technologies can you understand why

00:42:30,270 --> 00:42:36,020
right now can you have a clear picture

00:42:33,089 --> 00:42:39,500
about why kafka so scalable so

00:42:36,020 --> 00:42:41,960
let's do something very funny and I'm

00:42:39,500 --> 00:42:46,070
gonna actually ask your help pick up

00:42:41,960 --> 00:42:54,200
your phones and scan this barcode right

00:42:46,070 --> 00:42:57,710
here and when you do it I'm not gonna

00:42:54,200 --> 00:42:59,690
even explain what the what the

00:42:57,710 --> 00:43:02,119
application that's going to pop up in

00:42:59,690 --> 00:43:06,290
your browser is going to do I'm pretty

00:43:02,119 --> 00:43:08,840
sure right that you are in your 16 years

00:43:06,290 --> 00:43:11,570
old 25 years old or maybe four years old

00:43:08,840 --> 00:43:18,380
even six years old here we're gonna know

00:43:11,570 --> 00:43:21,110
what you have to do alright and keep

00:43:18,380 --> 00:43:28,280
playing you can start playing if you

00:43:21,110 --> 00:43:31,520
want it if you are already there let me

00:43:28,280 --> 00:43:35,960
know when I can skip this and open

00:43:31,520 --> 00:43:39,980
another window okay so if you're there

00:43:35,960 --> 00:43:44,080
already start playing like I said I

00:43:39,980 --> 00:43:44,080
don't have to explain what this means

00:43:44,650 --> 00:43:53,859
very old pac-man game the only thing

00:43:50,410 --> 00:43:57,590
differently that you have to understand

00:43:53,859 --> 00:43:59,780
is that this pac-man game that you are

00:43:57,590 --> 00:44:02,170
playing right now I assume you are

00:43:59,780 --> 00:44:02,170
playing

00:44:09,680 --> 00:44:16,880
it's sending continuously the name of

00:44:14,029 --> 00:44:21,140
the little ball that pac-man eats when

00:44:16,880 --> 00:44:23,960
he started moving in it what pellets

00:44:21,140 --> 00:44:26,359
every time he eats a pellets it keep

00:44:23,960 --> 00:44:28,400
increasing your score right so that's

00:44:26,359 --> 00:44:30,200
emitting events to appacha graphically

00:44:28,400 --> 00:44:33,230
so that's running on the cloud right and

00:44:30,200 --> 00:44:37,130
I'm consuming right here right as well

00:44:33,230 --> 00:44:38,750
as your names as well as your level that

00:44:37,130 --> 00:44:43,400
you were currently are and how many

00:44:38,750 --> 00:44:47,839
lives you have right here right so this

00:44:43,400 --> 00:44:50,000
is what we call the raw topic so imagine

00:44:47,839 --> 00:44:52,220
those databases I'm sorry if you're

00:44:50,000 --> 00:44:54,079
those applications for the transactional

00:44:52,220 --> 00:44:56,859
layer in the database architecture that

00:44:54,079 --> 00:45:01,369
keeps red writing data into the

00:44:56,859 --> 00:45:02,930
transactional right database right so

00:45:01,369 --> 00:45:04,940
this is what you're doing right now you

00:45:02,930 --> 00:45:08,329
are writing data into the database and

00:45:04,940 --> 00:45:11,270
then remember the data warehouse now why

00:45:08,329 --> 00:45:13,069
we have their house to do analytics so

00:45:11,270 --> 00:45:14,960
instead of copying the data to the data

00:45:13,069 --> 00:45:19,000
house we're going to do the analytics

00:45:14,960 --> 00:45:20,960
right here on top of the transactional

00:45:19,000 --> 00:45:25,309
there's no need to replicate that

00:45:20,960 --> 00:45:27,770
anymore people right because after can

00:45:25,309 --> 00:45:30,859
handle it all right that's the whole

00:45:27,770 --> 00:45:35,089
point so you are you're using the data

00:45:30,859 --> 00:45:38,089
so what I'm gonna do right now we model

00:45:35,089 --> 00:45:40,819
in Kafka everything is you know this

00:45:38,089 --> 00:45:42,589
concept of tables that we have and

00:45:40,819 --> 00:45:44,390
databases usually we should have the

00:45:42,589 --> 00:45:48,049
cost above tables here in Kafka as well

00:45:44,390 --> 00:45:51,230
right but before I think any tables you

00:45:48,049 --> 00:45:55,190
have to think in its streams right

00:45:51,230 --> 00:45:58,200
streams are tables that keeps receiving

00:45:55,190 --> 00:46:00,390
records continuously it never stopped

00:45:58,200 --> 00:46:02,490
right so if we look right now how many

00:46:00,390 --> 00:46:08,220
streams we have we shouldn't have no

00:46:02,490 --> 00:46:11,460
streams and no tables right all we have

00:46:08,220 --> 00:46:15,089
right now is the wrong kafka topics that

00:46:11,460 --> 00:46:17,550
are receiving data okay so what I'm

00:46:15,089 --> 00:46:19,560
gonna do now is actually like we call

00:46:17,550 --> 00:46:22,770
this pipeline we're gonna design a

00:46:19,560 --> 00:46:25,410
pipeline with a number of instructions

00:46:22,770 --> 00:46:27,990
that's going to model our analytics for

00:46:25,410 --> 00:46:29,820
example the first stop is actually bring

00:46:27,990 --> 00:46:32,430
up the concept of the topic into a

00:46:29,820 --> 00:46:34,619
stream right so that's what this command

00:46:32,430 --> 00:46:37,140
is doing I'm creating a string called

00:46:34,619 --> 00:46:40,440
user game which is build been built on

00:46:37,140 --> 00:46:42,960
top of the Kafka topic right and then

00:46:40,440 --> 00:46:44,790
I'm creating another stream called user

00:46:42,960 --> 00:46:47,339
losses every time you game over

00:46:44,790 --> 00:46:49,589
and pac-man is going to set an event

00:46:47,339 --> 00:46:56,480
with this user losses that's like game

00:46:49,589 --> 00:46:56,480
over kind of a signal three minutes

00:46:56,630 --> 00:47:04,530
really okay so one minute then all right

00:47:02,070 --> 00:47:09,900
so what I'm gonna do is just run this

00:47:04,530 --> 00:47:11,940
real quick I can show you outside and if

00:47:09,900 --> 00:47:13,859
you're playing pacman keep playing

00:47:11,940 --> 00:47:16,310
because I have you have to generate the

00:47:13,859 --> 00:47:16,310
events

00:47:22,880 --> 00:47:38,810
okay so now it just sticks statistics

00:47:33,400 --> 00:47:40,850
yep so you see here that you have the

00:47:38,810 --> 00:47:42,890
highest score the highest labview

00:47:40,850 --> 00:47:47,150
achieved in the number of losses per

00:47:42,890 --> 00:47:48,110
user this is a table let's imagine a

00:47:47,150 --> 00:47:50,720
table right

00:47:48,110 --> 00:47:52,880
but I do aggregations to come up with a

00:47:50,720 --> 00:47:54,710
table but all of this are being

00:47:52,880 --> 00:47:56,720
continuously updated because the streams

00:47:54,710 --> 00:47:59,120
are keep coming in so this is being

00:47:56,720 --> 00:48:02,150
recomputed in real time as they happen

00:47:59,120 --> 00:48:05,290
all right it's pretty cool right guys

00:48:02,150 --> 00:48:07,880
sorry it has to start speaking I am NOT

00:48:05,290 --> 00:48:09,590
thank you for coming and I will be

00:48:07,880 --> 00:48:13,480
outside if you want to see this how this

00:48:09,590 --> 00:48:13,480

YouTube URL: https://www.youtube.com/watch?v=--q3yeqyVJg


