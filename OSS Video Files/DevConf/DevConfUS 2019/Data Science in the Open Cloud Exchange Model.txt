Title: Data Science in the Open Cloud Exchange Model
Publication date: 2019-10-02
Playlist: DevConfUS 2019
Description: 
	Speakers: Steven Huels and Vasek PavliÂ­n

Have a great idea for a data science experiment but don't have the hardware to run it? The MOC and Red Hat have partnered to deploy the Open Data Hub into the MOC giving you access to hardware and support required for leading edge experiments.

The MOC IaaS platform combined with OpenShift and current data science development tools provides you with an alternative to using public clouds to execute your experiments.

Watch this talk to learn about:
- What the Massachusetts Open Cloud and Open Cloud Exchange is
- Current projects running in the MOC
- Running your project in the MOC
Captions: 
	00:00:03,410 --> 00:00:11,940
all right welcome everybody

00:00:06,960 --> 00:00:13,799
no problem very so I'm Stephen Jules I'm

00:00:11,940 --> 00:00:16,170
responsible for the AI Center of

00:00:13,799 --> 00:00:17,520
Excellence at Red Hat and presenting

00:00:16,170 --> 00:00:19,470
with me today would be Michael dates

00:00:17,520 --> 00:00:22,770
Minh from the Massachusetts open cloud

00:00:19,470 --> 00:00:24,780
and lamed in the Smith also from the AIC

00:00:22,770 --> 00:00:29,700
OE and we're gonna be talking about data

00:00:24,780 --> 00:00:31,260
science in the open cloud so kind of

00:00:29,700 --> 00:00:35,340
kick things off all right

00:00:31,260 --> 00:00:37,140
the proprietary public AWS GC has your

00:00:35,340 --> 00:00:38,730
all these things we've all come to know

00:00:37,140 --> 00:00:40,350
and love right they come with a lot of

00:00:38,730 --> 00:00:42,420
benefits right there's a lot of

00:00:40,350 --> 00:00:43,980
elasticity there they're highly

00:00:42,420 --> 00:00:45,300
integrated there's a lot of security

00:00:43,980 --> 00:00:47,550
they have built in you don't to deal

00:00:45,300 --> 00:00:49,320
with it yourself there's some great ways

00:00:47,550 --> 00:00:51,480
to change the monetization of how you

00:00:49,320 --> 00:00:53,640
recognize and spend money on those

00:00:51,480 --> 00:00:56,790
things which helps a lot of companies in

00:00:53,640 --> 00:00:58,290
budget allocations there's a lot of

00:00:56,790 --> 00:01:00,510
service abstraction so you can plug

00:00:58,290 --> 00:01:02,579
things in wherever you want there's a

00:01:00,510 --> 00:01:04,290
lot of operational excellence built into

00:01:02,579 --> 00:01:06,780
those systems right they make it easy

00:01:04,290 --> 00:01:09,149
for you and a lot of its built on open

00:01:06,780 --> 00:01:11,189
source but along with all that goodness

00:01:09,149 --> 00:01:14,009
there's also negatives that come along

00:01:11,189 --> 00:01:15,359
with it first off there's a lot of

00:01:14,009 --> 00:01:16,770
vertical lock-in right if you're

00:01:15,359 --> 00:01:18,840
embedding into a lot of those embedded

00:01:16,770 --> 00:01:19,979
services in those environments we're

00:01:18,840 --> 00:01:21,569
really really tough to break your

00:01:19,979 --> 00:01:23,069
application away from those if you want

00:01:21,569 --> 00:01:24,889
to try to switch environments or go to

00:01:23,069 --> 00:01:27,689
something that you've developed in-house

00:01:24,889 --> 00:01:30,240
there's a dated gravity issue so is

00:01:27,689 --> 00:01:31,649
everyone know what data gravity is no so

00:01:30,240 --> 00:01:33,209
whenever you're gonna be doing a lot of

00:01:31,649 --> 00:01:33,840
datum analysis that requires a lot of

00:01:33,209 --> 00:01:35,969
data

00:01:33,840 --> 00:01:37,679
right terabytes petabytes of data that

00:01:35,969 --> 00:01:39,719
need to be loaded once you've loaded

00:01:37,679 --> 00:01:41,460
that in data into a particular cloud

00:01:39,719 --> 00:01:43,920
environment chances are you're not

00:01:41,460 --> 00:01:46,020
pulling that data back out and to run

00:01:43,920 --> 00:01:47,460
something locally or in another

00:01:46,020 --> 00:01:49,590
environment right they've got you locked

00:01:47,460 --> 00:01:51,149
in because the cost it would take in

00:01:49,590 --> 00:01:53,219
time it would take to move that back out

00:01:51,149 --> 00:01:55,409
it's not worth the investment so you're

00:01:53,219 --> 00:01:57,539
gonna stay there in fact there was a

00:01:55,409 --> 00:01:59,880
saying they still say it in the public

00:01:57,539 --> 00:02:01,380
cloud environment that give us your data

00:01:59,880 --> 00:02:02,850
and we'll take all your business right

00:02:01,380 --> 00:02:04,319
because once they have your data they

00:02:02,850 --> 00:02:07,170
know you're gonna build everything else

00:02:04,319 --> 00:02:09,090
all around it and then out from an open

00:02:07,170 --> 00:02:10,890
source besides perspective their users

00:02:09,090 --> 00:02:12,660
of open source but a lot of those

00:02:10,890 --> 00:02:14,400
providers are not giving back to and

00:02:12,660 --> 00:02:15,780
source right it's a one-way street so

00:02:14,400 --> 00:02:17,040
that doesn't help all of us who are open

00:02:15,780 --> 00:02:19,440
sort of that the kids aren't trying to

00:02:17,040 --> 00:02:20,910
take advantage of those things you're

00:02:19,440 --> 00:02:24,120
also at the dependency of their

00:02:20,910 --> 00:02:25,620
lifecycles they're gonna you know best

00:02:24,120 --> 00:02:27,180
so they will roll out new services on a

00:02:25,620 --> 00:02:28,560
regular basis but they also have the

00:02:27,180 --> 00:02:30,269
ability just to kill services

00:02:28,560 --> 00:02:32,400
willy-nilly right so if you decided to

00:02:30,269 --> 00:02:33,569
use that of that particular service it

00:02:32,400 --> 00:02:35,400
might disappear in a month or two

00:02:33,569 --> 00:02:37,560
there's no guarantee that there's any

00:02:35,400 --> 00:02:39,299
consistency there and then there's a lot

00:02:37,560 --> 00:02:41,970
of black box services if you're taking

00:02:39,299 --> 00:02:43,230
advantage of the various you know pre

00:02:41,970 --> 00:02:44,700
deployed things out there you don't know

00:02:43,230 --> 00:02:46,650
what's going on behind the scenes and if

00:02:44,700 --> 00:02:48,600
you're accountable at all for any type

00:02:46,650 --> 00:02:49,560
of audit or traceability in the process

00:02:48,600 --> 00:02:51,299
that you're doing you don't have

00:02:49,560 --> 00:02:53,579
visibility into what's happening behind

00:02:51,299 --> 00:02:55,739
the scenes so in essence the public

00:02:53,579 --> 00:02:57,959
cloud has basically reinvented the

00:02:55,739 --> 00:03:00,150
mainframe and that we have black box

00:02:57,959 --> 00:03:03,769
services controlled by and controlled

00:03:00,150 --> 00:03:03,769
ecosystem on at least hardware

00:03:04,160 --> 00:03:08,580
so Steven you convinced us we're not

00:03:06,720 --> 00:03:10,470
gonna be with anything and public cloud

00:03:08,580 --> 00:03:13,440
anymore so we're gonna do everything in

00:03:10,470 --> 00:03:14,160
private fantastic that's not always easy

00:03:13,440 --> 00:03:16,230
either

00:03:14,160 --> 00:03:18,060
there's a lot of operational complexity

00:03:16,230 --> 00:03:19,980
with running things in a private cloud

00:03:18,060 --> 00:03:21,870
environment and not all firms and

00:03:19,980 --> 00:03:24,660
companies are large enough to be able to

00:03:21,870 --> 00:03:27,660
have the in-house expertise to run and

00:03:24,660 --> 00:03:29,040
manage those types of environments a lot

00:03:27,660 --> 00:03:29,910
of the private cloud components

00:03:29,040 --> 00:03:31,740
especially a lot of the open source

00:03:29,910 --> 00:03:34,920
components don't necessarily give the

00:03:31,740 --> 00:03:36,450
best user experience so if you have from

00:03:34,920 --> 00:03:38,100
an IT perspective it might be great you

00:03:36,450 --> 00:03:40,440
can stand things up you give people the

00:03:38,100 --> 00:03:42,240
capability but as far as having them go

00:03:40,440 --> 00:03:43,830
in and have a nice interface with which

00:03:42,240 --> 00:03:45,810
to select components from a catalog

00:03:43,830 --> 00:03:47,640
deploy those components configure

00:03:45,810 --> 00:03:49,260
integration points a lot of that's gonna

00:03:47,640 --> 00:03:50,370
be done behind the scenes and if you

00:03:49,260 --> 00:03:52,440
have developers that aren't familiar

00:03:50,370 --> 00:03:54,150
with what it takes to do that type of

00:03:52,440 --> 00:03:56,970
configuration it can be a real barrier

00:03:54,150 --> 00:03:58,650
success there's also a lack of diversity

00:03:56,970 --> 00:04:00,870
right if you're gonna host your own

00:03:58,650 --> 00:04:02,640
private cloud you're probably not gonna

00:04:00,870 --> 00:04:04,140
have the breadth of things that Amazon's

00:04:02,640 --> 00:04:06,630
gonna offer right you're gonna have

00:04:04,140 --> 00:04:08,190
whatever select amount of components

00:04:06,630 --> 00:04:09,900
that you guys can support that your

00:04:08,190 --> 00:04:11,430
developers need so you're not gonna have

00:04:09,900 --> 00:04:13,290
it maintenance take advantage all the

00:04:11,430 --> 00:04:15,060
latest and greatest that's out there and

00:04:13,290 --> 00:04:17,880
then it's costly to support overtime

00:04:15,060 --> 00:04:19,320
that that first iteration we get it up

00:04:17,880 --> 00:04:21,390
and running we're all excited we get

00:04:19,320 --> 00:04:23,730
stuff out there and then the next

00:04:21,390 --> 00:04:25,980
upgrade comes out and you have thousand

00:04:23,730 --> 00:04:27,600
services running on your system I mean

00:04:25,980 --> 00:04:29,160
they're all doing something

00:04:27,600 --> 00:04:30,570
interdependently and if you have an

00:04:29,160 --> 00:04:32,790
outage you know your business can't run

00:04:30,570 --> 00:04:34,290
so how do we manage that upgrade you're

00:04:32,790 --> 00:04:36,360
gonna buy a second environment so

00:04:34,290 --> 00:04:39,259
there's costs and operation operational

00:04:36,360 --> 00:04:41,910
considerations to take into account

00:04:39,259 --> 00:04:43,800
okay so public cloud Steve you got me

00:04:41,910 --> 00:04:45,900
convinced I'm not going there private

00:04:43,800 --> 00:04:48,900
cloud I'm nervous I'm not rich enough to

00:04:45,900 --> 00:04:50,130
handle this there's all these OpenStack

00:04:48,900 --> 00:04:51,690
clouds that are out there right these

00:04:50,130 --> 00:04:54,630
are generally available when you take

00:04:51,690 --> 00:04:57,990
advantage of those from a distribution

00:04:54,630 --> 00:05:00,240
perspective the OpenStack footprint far

00:04:57,990 --> 00:05:02,639
exceeds any of the regional footprints

00:05:00,240 --> 00:05:05,250
of any one of the public cloud providers

00:05:02,639 --> 00:05:06,690
they have instances everywhere that's

00:05:05,250 --> 00:05:09,210
fantastic

00:05:06,690 --> 00:05:11,190
the downside none of them are large

00:05:09,210 --> 00:05:12,690
enough individually to track the

00:05:11,190 --> 00:05:13,949
diversity of services that you'll find

00:05:12,690 --> 00:05:15,360
in a lot of the public clouds there's

00:05:13,949 --> 00:05:17,250
sort of niche components that are

00:05:15,360 --> 00:05:20,520
managed for specific targeted audiences

00:05:17,250 --> 00:05:22,740
and specific purposes the divergent

00:05:20,520 --> 00:05:24,630
services between these systems and the

00:05:22,740 --> 00:05:26,460
different base images it's not really

00:05:24,630 --> 00:05:28,560
easy to move things from environment to

00:05:26,460 --> 00:05:31,139
environment or get things to to work

00:05:28,560 --> 00:05:33,539
together and then at the end of the day

00:05:31,139 --> 00:05:36,900
not a single one of these providers has

00:05:33,539 --> 00:05:38,370
a mandate to actually solve this problem

00:05:36,900 --> 00:05:40,199
right they were stood up to solve

00:05:38,370 --> 00:05:41,699
individual problems so they're not

00:05:40,199 --> 00:05:45,840
really intended to work together to

00:05:41,699 --> 00:05:47,580
handle this at scale so what if there

00:05:45,840 --> 00:05:53,719
was a different model we can go after

00:05:47,580 --> 00:05:56,389
right the open cloud exchange model

00:05:53,719 --> 00:05:58,789
so what is an open cloud exchange so

00:05:56,389 --> 00:06:01,009
it's an alternative filed model where

00:05:58,789 --> 00:06:02,299
there are many stakeholders and rather

00:06:01,009 --> 00:06:04,369
than just be there being a single

00:06:02,299 --> 00:06:06,379
provider you have lots and lots of

00:06:04,369 --> 00:06:08,809
different types of vendors hardware

00:06:06,379 --> 00:06:10,909
vendors software vendors open source

00:06:08,809 --> 00:06:12,469
communities all implementing

00:06:10,909 --> 00:06:14,959
implementing and operating cloud

00:06:12,469 --> 00:06:16,819
together and in doing so basically

00:06:14,959 --> 00:06:19,039
create this multi-sided market place

00:06:16,819 --> 00:06:20,479
right there different hardware profiles

00:06:19,039 --> 00:06:22,459
that you can select from there different

00:06:20,479 --> 00:06:23,919
software components made available are

00:06:22,459 --> 00:06:26,719
different services being made available

00:06:23,919 --> 00:06:29,509
and users can freely choose from that

00:06:26,719 --> 00:06:30,919
set of components and infrastructure and

00:06:29,509 --> 00:06:32,809
the compute resources to basically

00:06:30,919 --> 00:06:36,409
provide the services they need for their

00:06:32,809 --> 00:06:38,779
users so what's a common use case for

00:06:36,409 --> 00:06:40,789
something like this right probably the

00:06:38,779 --> 00:06:42,979
most common is being able to respond to

00:06:40,789 --> 00:06:46,459
seasonal or peak demands for hardware

00:06:42,979 --> 00:06:48,229
usage so I am a contributor into an open

00:06:46,459 --> 00:06:50,479
cloud exchange I will have bought

00:06:48,229 --> 00:06:51,889
credits in and contributed hardware into

00:06:50,479 --> 00:06:54,199
the environment to handle maybe my

00:06:51,889 --> 00:06:56,059
normal workloads and then I might

00:06:54,199 --> 00:06:57,860
contribute a little bit extra right so

00:06:56,059 --> 00:06:59,719
I'm not using that I'm treating that and

00:06:57,860 --> 00:07:01,639
back to the public cloud component of it

00:06:59,719 --> 00:07:03,889
so other users can take advantage of my

00:07:01,639 --> 00:07:06,110
hardware when I'm not using it and in

00:07:03,889 --> 00:07:07,610
return I'm gonna be earning credits for

00:07:06,110 --> 00:07:09,050
the time I'm not using my hardware but

00:07:07,610 --> 00:07:12,110
I'm making it available to the other

00:07:09,050 --> 00:07:14,239
users of the open cloud exchange so that

00:07:12,110 --> 00:07:16,129
then when I hit my peak usage right

00:07:14,239 --> 00:07:18,979
maybe I'm seasonal maybe I'm retail i

00:07:16,129 --> 00:07:20,929
middlemen to over consume what it is

00:07:18,979 --> 00:07:22,819
that I've actually provided and take

00:07:20,929 --> 00:07:26,089
advantage of those credits and get

00:07:22,819 --> 00:07:27,709
access to that extra infrastructure but

00:07:26,089 --> 00:07:29,479
when I don't need it I'm not paying for

00:07:27,709 --> 00:07:31,069
all that added infrastructure I don't

00:07:29,479 --> 00:07:32,629
have idle time sitting there I'm not

00:07:31,069 --> 00:07:34,150
responsible for all of the maintenance

00:07:32,629 --> 00:07:37,210
and upkeep and I don't

00:07:34,150 --> 00:07:39,010
I pay for the support contracts another

00:07:37,210 --> 00:07:41,199
common example is where we want access

00:07:39,010 --> 00:07:43,570
to current technology without private

00:07:41,199 --> 00:07:45,280
operations because you have hardware and

00:07:43,570 --> 00:07:47,380
software vendors contributing into this

00:07:45,280 --> 00:07:49,720
environment they will use it as a

00:07:47,380 --> 00:07:51,040
proving ground to get early feedback on

00:07:49,720 --> 00:07:52,960
the latest and greatest hardware

00:07:51,040 --> 00:07:55,660
accelerators and software components

00:07:52,960 --> 00:07:57,130
that they're releasing in doing so the

00:07:55,660 --> 00:07:58,930
community benefits because they get

00:07:57,130 --> 00:08:01,060
access to software they they might not

00:07:58,930 --> 00:08:02,710
otherwise have had access to being

00:08:01,060 --> 00:08:05,199
maintained by the developers who are

00:08:02,710 --> 00:08:07,120
actually building that software and the

00:08:05,199 --> 00:08:08,949
developers are getting regular feedback

00:08:07,120 --> 00:08:11,080
based on the users of that environment

00:08:08,949 --> 00:08:15,460
and they can then continuously update it

00:08:11,080 --> 00:08:17,110
right so it closes it accelerates the

00:08:15,460 --> 00:08:20,110
overall feedback loop and development

00:08:17,110 --> 00:08:22,150
lifecycle for those components you also

00:08:20,110 --> 00:08:24,160
get a rich and constantly evolving set

00:08:22,150 --> 00:08:25,419
of services right there gonna be some

00:08:24,160 --> 00:08:27,010
long-term players who are always going

00:08:25,419 --> 00:08:28,150
to remain in the environment but then

00:08:27,010 --> 00:08:29,830
there are others who may plug into

00:08:28,150 --> 00:08:31,600
various points in time and make things

00:08:29,830 --> 00:08:33,760
available so there's gonna be this

00:08:31,600 --> 00:08:35,950
ever-evolving availability of services

00:08:33,760 --> 00:08:37,330
within the environment and then because

00:08:35,950 --> 00:08:39,940
you're distributing this out across

00:08:37,330 --> 00:08:41,469
multiple providers and those operational

00:08:39,940 --> 00:08:43,900
components are being distributed between

00:08:41,469 --> 00:08:45,670
hardware vendors software vendors the

00:08:43,900 --> 00:08:46,900
overall cost to maintain it you're not

00:08:45,670 --> 00:08:48,640
bearing the burden as a single

00:08:46,900 --> 00:08:51,029
organization right those costs are being

00:08:48,640 --> 00:08:51,029
distributed

00:08:51,110 --> 00:08:55,100
so the end of the day it's probably not

00:08:53,180 --> 00:08:57,350
all that crazy right so the current

00:08:55,100 --> 00:08:58,640
clouds are extremely expensive they're

00:08:57,350 --> 00:09:00,710
gonna take all your stuff and make it

00:08:58,640 --> 00:09:01,820
really hard for you to leave a lot of

00:09:00,710 --> 00:09:03,290
the industry out there can't actually

00:09:01,820 --> 00:09:05,780
even use clouds due to regulatory

00:09:03,290 --> 00:09:07,670
requirements there's lots of great

00:09:05,780 --> 00:09:10,250
options and open-source software that

00:09:07,670 --> 00:09:12,110
can provide you the same capabilities a

00:09:10,250 --> 00:09:14,210
lot of these black box services but in

00:09:12,110 --> 00:09:15,410
an open source manner and there's lots

00:09:14,210 --> 00:09:17,000
of niche markets that need to be

00:09:15,410 --> 00:09:18,680
serviced it can't be serviced due to

00:09:17,000 --> 00:09:21,140
price point availability things like

00:09:18,680 --> 00:09:23,660
that for these other clouds your void

00:09:21,140 --> 00:09:26,480
vendor locked in and you don't have to

00:09:23,660 --> 00:09:28,310
do this at the a scale of an AWS for

00:09:26,480 --> 00:09:31,010
this to be a good idea right there's a

00:09:28,310 --> 00:09:32,870
point at which scale does not matter and

00:09:31,010 --> 00:09:35,300
so Michael is gonna come up now and talk

00:09:32,870 --> 00:09:39,140
to you about implementation of this

00:09:35,300 --> 00:09:40,610
exact model so accommodate they say that

00:09:39,140 --> 00:09:42,430
there are certain comedians it's never

00:09:40,610 --> 00:09:50,840
going to follow I've just funded

00:09:42,430 --> 00:09:52,730
education there's a little bit about the

00:09:50,840 --> 00:09:55,370
mass open cloud before I go much further

00:09:52,730 --> 00:09:57,890
than this it's five partner universities

00:09:55,370 --> 00:09:59,330
those five partner universities if you

00:09:57,890 --> 00:10:02,480
take the entire student body of the

00:09:59,330 --> 00:10:06,050
staff and the faculty it's roughly the

00:10:02,480 --> 00:10:10,730
size of the population of Iceland so

00:10:06,050 --> 00:10:12,500
it's actually a pretty good size and

00:10:10,730 --> 00:10:15,570
then we've got a bunch of other partners

00:10:12,500 --> 00:10:17,920
the Air Force has been involved

00:10:15,570 --> 00:10:21,160
some of these are fairly familiar to you

00:10:17,920 --> 00:10:22,450
guys I think in telmanovo NetApp all of

00:10:21,160 --> 00:10:28,060
these folks have at various times

00:10:22,450 --> 00:10:30,310
contributed to making the MOC real red

00:10:28,060 --> 00:10:33,370
that's been an amazing partner as well

00:10:30,310 --> 00:10:34,720
here's a couple more all of these people

00:10:33,370 --> 00:10:36,640
are interested in it for the very

00:10:34,720 --> 00:10:39,580
reasons that Stephen just talked about

00:10:36,640 --> 00:10:41,350
which is we don't really want there to

00:10:39,580 --> 00:10:43,450
just be three or four incumbent cloud

00:10:41,350 --> 00:10:46,029
partner cloud cloud providers out there

00:10:43,450 --> 00:10:48,490
we want there to be diversity we want

00:10:46,029 --> 00:10:51,339
there to be a bizarre not just to the

00:10:48,490 --> 00:10:55,089
cathedral I say that looking out at the

00:10:51,339 --> 00:10:57,490
pipe organ in there so what's the mask

00:10:55,089 --> 00:10:59,529
open cloud it's housed at the Mascarene

00:10:57,490 --> 00:11:01,660
high-performance computing Center which

00:10:59,529 --> 00:11:03,670
is in Holyoke Massachusetts or the

00:11:01,660 --> 00:11:08,529
electricity and the land are inexpensive

00:11:03,670 --> 00:11:10,660
there's huge chunks of well big cables

00:11:08,529 --> 00:11:13,570
full of dark fiber running up the Mass

00:11:10,660 --> 00:11:15,070
Pike out to Holyoke so there's a very

00:11:13,570 --> 00:11:17,710
high speed connection into the Boston

00:11:15,070 --> 00:11:22,630
area into the New York area basically up

00:11:17,710 --> 00:11:28,810
and down the coast we have a combination

00:11:22,630 --> 00:11:32,260
of a OpenStack environment which is we

00:11:28,810 --> 00:11:33,730
call Kaizen but of those 2,500 cores a

00:11:32,260 --> 00:11:37,330
thousand eighty eight of them are

00:11:33,730 --> 00:11:41,290
elastic which means that if you need to

00:11:37,330 --> 00:11:43,029
for example share resources with a high

00:11:41,290 --> 00:11:43,930
performance computing group because they

00:11:43,029 --> 00:11:45,880
have a peak to me

00:11:43,930 --> 00:11:48,340
at a different time than our general

00:11:45,880 --> 00:11:50,770
cloud users do we can do that and in

00:11:48,340 --> 00:11:52,660
fact we do do that it's also used for

00:11:50,770 --> 00:11:55,030
for research

00:11:52,660 --> 00:11:56,640
we're running OpenStack we're running

00:11:55,030 --> 00:12:00,010
openshift

00:11:56,640 --> 00:12:02,230
here's some of the projects that are

00:12:00,010 --> 00:12:03,970
being run on there the open data hub is

00:12:02,230 --> 00:12:07,420
one of them open Jeff does another

00:12:03,970 --> 00:12:09,780
OpenStack ESI is the elastic secure

00:12:07,420 --> 00:12:13,210
infrastructure Keystone and Seth

00:12:09,780 --> 00:12:14,650
those are important because one of the

00:12:13,210 --> 00:12:17,740
things that happens when you start

00:12:14,650 --> 00:12:19,420
actually putting large data centers that

00:12:17,740 --> 00:12:21,460
are that people can do real meaningful

00:12:19,420 --> 00:12:22,780
research on and actually look at the

00:12:21,460 --> 00:12:25,030
underlying data that's made available

00:12:22,780 --> 00:12:26,740
did you start getting benefits that you

00:12:25,030 --> 00:12:29,560
wouldn't otherwise get so for example

00:12:26,740 --> 00:12:32,290
the s I grew out of a project that we

00:12:29,560 --> 00:12:35,130
had called Hill and BMI it's moving

00:12:32,290 --> 00:12:37,540
upstream into ironic and ansible so that

00:12:35,130 --> 00:12:39,700
everybody who's using the Linux

00:12:37,540 --> 00:12:41,530
operating system in the future and the

00:12:39,700 --> 00:12:43,930
OpenStack components of it are going to

00:12:41,530 --> 00:12:45,700
be able to do the same kind of bursting

00:12:43,930 --> 00:12:47,260
that we're talking about so the way that

00:12:45,700 --> 00:12:49,390
we've been trying to get this concept of

00:12:47,260 --> 00:12:52,630
the open cloud exchange out there is by

00:12:49,390 --> 00:12:55,030
both standing it up and running it in

00:12:52,630 --> 00:12:56,770
our own data center but trying to move

00:12:55,030 --> 00:13:00,250
the components of it upstream so that

00:12:56,770 --> 00:13:01,720
they come back down to everybody there's

00:13:00,250 --> 00:13:03,460
some upcoming projects that are going on

00:13:01,720 --> 00:13:06,100
they're kind of cool

00:13:03,460 --> 00:13:09,400
the new zealand storage exchange is a 20

00:13:06,100 --> 00:13:11,110
petabyte online Lake expected to grow to

00:13:09,400 --> 00:13:12,070
over a hundred petabyte that's also

00:13:11,110 --> 00:13:14,260
housed to the best green

00:13:12,070 --> 00:13:17,680
high-performance computing center so

00:13:14,260 --> 00:13:20,320
what happens if you have your data in

00:13:17,680 --> 00:13:22,270
the same computing center as your

00:13:20,320 --> 00:13:23,670
compute these you don't have to pay to

00:13:22,270 --> 00:13:26,430
move the data around

00:13:23,670 --> 00:13:29,160
but the thing about that exchange that's

00:13:26,430 --> 00:13:33,860
kind of cool is if you have your data in

00:13:29,160 --> 00:13:38,910
a data center in Holyoke for example and

00:13:33,860 --> 00:13:40,710
your researcher in Toronto and you're

00:13:38,910 --> 00:13:43,050
using the dataverse project which is a

00:13:40,710 --> 00:13:46,140
project that is started out of Harvard

00:13:43,050 --> 00:13:48,800
but it's got a bunch of smaller versions

00:13:46,140 --> 00:13:51,750
of it around Harvard's is the largest

00:13:48,800 --> 00:13:57,560
looking straited than you should stand

00:13:51,750 --> 00:14:00,570
up and wave then you could for example

00:13:57,560 --> 00:14:02,280
kickoff of us yes project from Toronto

00:14:00,570 --> 00:14:06,090
that would run on the data center in

00:14:02,280 --> 00:14:07,530
Mount Holyoke against the data from for

00:14:06,090 --> 00:14:11,970
example of Boston Children's Hospital

00:14:07,530 --> 00:14:14,700
and just pull back the data you care

00:14:11,970 --> 00:14:17,240
about that's the kind of flexibility

00:14:14,700 --> 00:14:19,730
that we're starting to experiment with

00:14:17,240 --> 00:14:23,310
so there's the connection to nesting

00:14:19,730 --> 00:14:24,840
these are things I can talk about we're

00:14:23,310 --> 00:14:26,730
working on a reference platform for the

00:14:24,840 --> 00:14:28,530
Boston Children's Hospital where they're

00:14:26,730 --> 00:14:31,050
going to basically stand up HIPAA

00:14:28,530 --> 00:14:33,000
compliant Enclave using the same

00:14:31,050 --> 00:14:36,720
reference architectures as we're using

00:14:33,000 --> 00:14:38,000
for the master bed cloud if you look on

00:14:36,720 --> 00:14:39,750
the right side you see the four hundred

00:14:38,000 --> 00:14:42,180
physical power and iron core is

00:14:39,750 --> 00:14:46,410
basically IBM did a whole bunch of power

00:14:42,180 --> 00:14:48,360
9 systems to us each of them has all but

00:14:46,410 --> 00:14:53,940
one of them so nine of them have a half

00:14:48,360 --> 00:14:56,700
a terabyte of RAM and the tenth one has

00:14:53,940 --> 00:14:58,260
a terabyte each of them have four GPUs

00:14:56,700 --> 00:15:01,229
that are - that are connected at high

00:14:58,260 --> 00:15:03,459
speed through Envy link

00:15:01,229 --> 00:15:06,429
that's becoming available the data

00:15:03,459 --> 00:15:10,569
researchers within the the master open

00:15:06,429 --> 00:15:12,689
cloud so that again they can work on the

00:15:10,569 --> 00:15:20,709
data that's sitting in the in the in the

00:15:12,689 --> 00:15:23,259
Nessie MIT is getting I think 40 of them

00:15:20,709 --> 00:15:26,109
or 50 of them they're gonna be using

00:15:23,259 --> 00:15:28,539
again this the plan is for chunk of

00:15:26,109 --> 00:15:30,369
those machines to be using our reference

00:15:28,539 --> 00:15:33,039
architecture that architecture for

00:15:30,369 --> 00:15:34,689
OpenShift on the power nines with the

00:15:33,039 --> 00:15:36,939
plan of federating them over time

00:15:34,689 --> 00:15:39,519
so that if the guys at MIT need a little

00:15:36,939 --> 00:15:41,259
bit more power they can borrow it if we

00:15:39,519 --> 00:15:43,029
need a little bit more power we can

00:15:41,259 --> 00:15:48,839
borrow it it probably works out better

00:15:43,029 --> 00:15:51,850
for us than them whatever is available

00:15:48,839 --> 00:15:55,059
to researchers students at any of the

00:15:51,850 --> 00:15:56,559
five partner universities as long as

00:15:55,059 --> 00:15:59,229
it's being used for things that are open

00:15:56,559 --> 00:16:03,039
source or small startups in other words

00:15:59,229 --> 00:16:06,869
non corporate at the moment but

00:16:03,039 --> 00:16:06,869
corporate working on open source is fine

00:16:07,739 --> 00:16:13,720
and you can sign up using a university

00:16:10,569 --> 00:16:15,249
account you can sign up using a Google

00:16:13,720 --> 00:16:20,079
logon which if you're a red hat means

00:16:15,249 --> 00:16:21,939
Red Hat and then you'll probably get a

00:16:20,079 --> 00:16:24,729
note from me if you're using it from Red

00:16:21,939 --> 00:16:29,039
Hat or non University saying what are

00:16:24,729 --> 00:16:29,039
you doing and then we'll turn on for you

00:16:29,650 --> 00:16:35,220
the way you get that is onboarding

00:16:31,240 --> 00:16:38,380
dumbass open another cloud slash sign up

00:16:35,220 --> 00:16:41,190
we're currently decommissioning our old

00:16:38,380 --> 00:16:43,570
Kaizen so I talked about 2500 cores

00:16:41,190 --> 00:16:46,300
we're gonna be increasing that over the

00:16:43,570 --> 00:16:48,310
next four weeks as we decommission the

00:16:46,300 --> 00:16:55,600
old cloud and move the hardware over to

00:16:48,310 --> 00:17:11,500
the new cloud we're trying to turn that

00:16:55,600 --> 00:17:18,329
model into the real thing essentially a

00:17:11,500 --> 00:17:24,790
community to the best practices for

00:17:18,329 --> 00:17:27,699
deploying different AI email tools on

00:17:24,790 --> 00:17:30,160
how I deploy so we're actively working

00:17:27,699 --> 00:17:32,980
to get that running in the mass open

00:17:30,160 --> 00:17:37,870
cloud I think we recently did an upgrade

00:17:32,980 --> 00:17:42,940
so what we want to do is make it easy

00:17:37,870 --> 00:17:49,990
for you to run your different machine

00:17:42,940 --> 00:17:55,059
learning projects so I'm going to dim

00:17:49,990 --> 00:17:56,200
all the different parts of it that we

00:17:55,059 --> 00:17:58,030
want to make it as configurable as

00:17:56,200 --> 00:18:01,570
possible so whatever your preferred

00:17:58,030 --> 00:18:03,429
method for managing your data analyzing

00:18:01,570 --> 00:18:04,960
your data and running models on your

00:18:03,429 --> 00:18:07,990
data we want to make that

00:18:04,960 --> 00:18:10,000
so it's currently running in the MSM OC

00:18:07,990 --> 00:18:11,560
or will be but it's also available for

00:18:10,000 --> 00:18:13,330
public consumption so if you have your

00:18:11,560 --> 00:18:16,450
own cluster or you just want to play

00:18:13,330 --> 00:18:20,370
around with it or pull it into kind of

00:18:16,450 --> 00:18:20,370
any environment that you're running in

00:18:21,900 --> 00:18:26,080
we plan out some of the key things that

00:18:24,250 --> 00:18:29,440
are running on the open data home so

00:18:26,080 --> 00:18:33,220
we're using object object storage to

00:18:29,440 --> 00:18:37,000
store the data internally we're actually

00:18:33,220 --> 00:18:41,050
using a elastic search in kafka streams

00:18:37,000 --> 00:18:44,470
Cubana to explore that data analyze it

00:18:41,050 --> 00:18:47,230
and then on the data science in we have

00:18:44,470 --> 00:18:49,750
super golem or Jupiter notebooks to

00:18:47,230 --> 00:18:52,200
actually interact with that data and so

00:18:49,750 --> 00:18:58,030
we want to make it easier for all the

00:18:52,200 --> 00:18:59,800
users of the data to make it as simple

00:18:58,030 --> 00:19:01,630
as possible so if you're DevOps it's

00:18:59,800 --> 00:19:04,120
really easy to deploy I will demo that

00:19:01,630 --> 00:19:06,250
if you're in a data engineer you can

00:19:04,120 --> 00:19:07,690
easily get access to that data if you're

00:19:06,250 --> 00:19:09,700
a data scientist and don't care about

00:19:07,690 --> 00:19:13,360
any of that stuff it's really easy to

00:19:09,700 --> 00:19:16,150
just deploy the tool and start just

00:19:13,360 --> 00:19:17,410
starting on your no phone so these are

00:19:16,150 --> 00:19:19,840
some of the components so right now the

00:19:17,410 --> 00:19:23,140
data hub we have a Jupiter we have

00:19:19,840 --> 00:19:24,790
support for set object storage Seldon is

00:19:23,140 --> 00:19:27,960
available to be deployed by the open

00:19:24,790 --> 00:19:30,880
data refiner Prometheus for monitoring

00:19:27,960 --> 00:19:33,400
spark operator for deploying on demand

00:19:30,880 --> 00:19:37,620
smart clusters we're actually working to

00:19:33,400 --> 00:19:37,620
integrate simul flow Shu

00:19:39,140 --> 00:19:42,199
[Music]

00:20:04,419 --> 00:20:10,099
and what that means is we make it easy

00:20:08,059 --> 00:20:11,450
to deploy other operators that will

00:20:10,099 --> 00:20:14,749
actually employ the tools that you're

00:20:11,450 --> 00:20:16,519
comfortable with so we don't want to

00:20:14,749 --> 00:20:18,379
control the entirety of the stack we

00:20:16,519 --> 00:20:20,330
leave it completely up to open to you to

00:20:18,379 --> 00:20:21,919
what you want to deploy and we say it's

00:20:20,330 --> 00:20:23,149
close to the upstream as possible so

00:20:21,919 --> 00:20:25,460
that we're not running a highly

00:20:23,149 --> 00:20:28,149
customized version so you can mix and

00:20:25,460 --> 00:20:30,799
match different tools as you see fit if

00:20:28,149 --> 00:20:33,080
if you have a custom smart cluster that

00:20:30,799 --> 00:20:34,970
you want to use you can disable the

00:20:33,080 --> 00:20:37,159
spark deployment that we provide as open

00:20:34,970 --> 00:20:38,629
with open data if you have your own

00:20:37,159 --> 00:20:43,220
Jupiter server but you want the

00:20:38,629 --> 00:20:45,109
monitoring and message passing from the

00:20:43,220 --> 00:20:46,970
cockpit we can make that available is

00:20:45,109 --> 00:20:54,590
completely up to you on how you want to

00:20:46,970 --> 00:20:55,879
use it so I will point out data

00:20:54,590 --> 00:20:58,909
scientists would actually be interested

00:20:55,879 --> 00:21:02,720
in using the data hub in the process so

00:20:58,909 --> 00:21:04,519
we have demo projects so this is a banal

00:21:02,720 --> 00:21:08,289
project so the only thing that's in this

00:21:04,519 --> 00:21:10,639
project are the trims each operator for

00:21:08,289 --> 00:21:14,049
for Kafka and the open data

00:21:10,639 --> 00:21:14,049
operator there's nothing else running

00:21:14,850 --> 00:21:20,260
so this is a regular user so the user

00:21:18,010 --> 00:21:22,510
I'm logged in is just project that man

00:21:20,260 --> 00:21:24,490
this is Knox Esther admin in order to

00:21:22,510 --> 00:21:26,320
deploy the operator you would have to be

00:21:24,490 --> 00:21:30,370
cluster admin but that's one time per

00:21:26,320 --> 00:21:32,230
project at this point this would be kind

00:21:30,370 --> 00:21:33,910
of a DevOps would enable this operator

00:21:32,230 --> 00:21:36,040
running in the namespace or they would

00:21:33,910 --> 00:21:39,250
actually go through the next few steps

00:21:36,040 --> 00:21:42,520
to actually deploy so we're going to do

00:21:39,250 --> 00:21:44,440
the super way that's by the catalog and

00:21:42,520 --> 00:21:46,950
since we've already deployed operate it

00:21:44,440 --> 00:21:51,580
into this namespace we can go to

00:21:46,950 --> 00:21:54,400
operators you'll get some quick

00:21:51,580 --> 00:22:03,910
information about what the Open Data

00:21:54,400 --> 00:22:09,000
operator this is also available in order

00:22:03,910 --> 00:22:11,440
to you can click on create and hopefully

00:22:09,000 --> 00:22:13,600
this is just a simple you know file this

00:22:11,440 --> 00:22:15,730
defines what we want to deploy as far as

00:22:13,600 --> 00:22:19,210
open data so at this point this would

00:22:15,730 --> 00:22:21,250
probably be the responsibility of DevOps

00:22:19,210 --> 00:22:22,750
if you're adventurous and is data

00:22:21,250 --> 00:22:24,850
scientist and you want to configure this

00:22:22,750 --> 00:22:27,010
to your need this simple yeah mo file

00:22:24,850 --> 00:22:29,620
wants to operators deploy will allow you

00:22:27,010 --> 00:22:33,600
to customize it to your needs

00:22:29,620 --> 00:22:33,600
the the false we have set up our

00:22:33,929 --> 00:22:38,470
out-of-the-box you could run a simpler

00:22:35,920 --> 00:22:41,220
notebook normally I think the default

00:22:38,470 --> 00:22:44,050
notebook memory is two or four gigabytes

00:22:41,220 --> 00:22:46,000
which should allow you to play around

00:22:44,050 --> 00:22:48,580
with kind of small data sets to get a

00:22:46,000 --> 00:22:50,080
feel for what you do in the data so if

00:22:48,580 --> 00:22:52,400
we want to configure any of this stuff

00:22:50,080 --> 00:22:57,200
so we have Jupiter

00:22:52,400 --> 00:23:02,480
here you'll see we have the spark

00:22:57,200 --> 00:23:04,400
operating point here monitoring which is

00:23:02,480 --> 00:23:06,620
for me cassandra fauna and in Kafka

00:23:04,400 --> 00:23:10,070
enabled we disabled the deployment of

00:23:06,620 --> 00:23:12,260
Selden AI library to be correct but if

00:23:10,070 --> 00:23:14,530
we want to deploy those also we can just

00:23:12,260 --> 00:23:17,630
change this folium to the false or true

00:23:14,530 --> 00:23:19,940
if we wanted to say one anything we can

00:23:17,630 --> 00:23:22,750
set early age deploy to false so it's

00:23:19,940 --> 00:23:26,120
highly customizable disabling any

00:23:22,750 --> 00:23:27,770
components will not affect other

00:23:26,120 --> 00:23:30,410
components so we make it completely

00:23:27,770 --> 00:23:32,270
modular so that you can pick and choose

00:23:30,410 --> 00:23:34,460
what you want and have different types

00:23:32,270 --> 00:23:40,840
of open data running in your environment

00:23:34,460 --> 00:23:40,840
so just go ahead and create

00:23:46,640 --> 00:23:52,010
so what's gonna happen is we've

00:23:48,679 --> 00:23:54,200
specified the type of data hub open data

00:23:52,010 --> 00:23:56,240
that we want to deploy so the operator

00:23:54,200 --> 00:23:58,250
is going to see that and start to deploy

00:23:56,240 --> 00:24:01,250
it based on the different configurations

00:23:58,250 --> 00:24:03,650
that we selected so in a few seconds you

00:24:01,250 --> 00:24:07,610
should start to see some things

00:24:03,650 --> 00:24:10,130
deploying there we go so first we have

00:24:07,610 --> 00:24:13,690
Jupiter hub and the database that's

00:24:10,130 --> 00:24:13,690
connected you for help that are the coin

00:24:16,930 --> 00:24:21,940
pretty soon as you see the spark

00:24:18,970 --> 00:24:23,620
operator and Prometheus and Griffin

00:24:21,940 --> 00:24:28,360
so I'll just go ahead and show you the

00:24:23,620 --> 00:24:29,650
pods so this way this data scientist

00:24:28,360 --> 00:24:30,250
doesn't care about it this is more

00:24:29,650 --> 00:24:33,700
DevOps

00:24:30,250 --> 00:24:36,310
they want to make sure that the positive

00:24:33,700 --> 00:24:37,990
point correctly we set up for me Thea

00:24:36,310 --> 00:24:39,790
super vana so that you have you can

00:24:37,990 --> 00:24:47,320
actually view the metrics for those pods

00:24:39,790 --> 00:24:49,800
capture that is prior but the user has

00:24:47,320 --> 00:24:53,320
complete access to it so we created the

00:24:49,800 --> 00:24:56,470
s3 credentials time access to object

00:24:53,320 --> 00:25:00,430
storage but we are not directly tied

00:24:56,470 --> 00:25:02,320
into object source locally if you have

00:25:00,430 --> 00:25:04,600
an external set cluster you can connect

00:25:02,320 --> 00:25:11,680
to that if you have data stored on AWS

00:25:04,600 --> 00:25:14,250
you can connect to that so other things

00:25:11,680 --> 00:25:16,870
are spinning up primarily Prometheus

00:25:14,250 --> 00:25:18,910
let's switch over to the data science to

00:25:16,870 --> 00:25:21,220
you so as a data scientist you don't

00:25:18,910 --> 00:25:23,620
care about this you just want to pull up

00:25:21,220 --> 00:25:27,430
your environment to access your data so

00:25:23,620 --> 00:25:29,770
the all you concerned about is how do

00:25:27,430 --> 00:25:37,090
you get to Jupiter on so what would

00:25:29,770 --> 00:25:41,610
normally happen is the dev ops and they

00:25:37,090 --> 00:25:46,960
just send you an email to say here's the

00:25:41,610 --> 00:25:50,490
taxes Jupiter so based on your open

00:25:46,960 --> 00:25:50,490
shift credentials you'll just log you

00:25:53,789 --> 00:26:05,019
allow access to read your information

00:25:59,340 --> 00:26:07,149
and we have to allow you our group of

00:26:05,019 --> 00:26:10,059
users to kind of select the type of

00:26:07,149 --> 00:26:13,059
notebook gimmicks they want the size of

00:26:10,059 --> 00:26:14,919
their notebook if your cluster was GPU

00:26:13,059 --> 00:26:19,179
enabled you can actually change the

00:26:14,919 --> 00:26:21,159
number of GPUs you want access to and

00:26:19,179 --> 00:26:24,059
any necessary environment variables that

00:26:21,159 --> 00:26:27,279
you want to make available to your pod

00:26:24,059 --> 00:26:30,070
so the key environment variables here

00:26:27,279 --> 00:26:37,649
are your s3 credentials for accessing

00:26:30,070 --> 00:26:37,649
this object storage for this workshop

00:26:41,399 --> 00:26:48,039
maybe if you want to add any additional

00:26:43,960 --> 00:26:51,539
variables so you can do that here so

00:26:48,039 --> 00:26:56,320
we're just going to spawn this cluster

00:26:51,539 --> 00:26:59,759
and part of this custom cheaper Dom

00:26:56,320 --> 00:27:04,389
deployment for open data is we also

00:26:59,759 --> 00:27:06,489
spawn a user spark cluster so if you

00:27:04,389 --> 00:27:08,259
have multiple users running Jupiter

00:27:06,489 --> 00:27:11,080
notebooks in the space they'll each get

00:27:08,259 --> 00:27:12,820
their own spark cluster if your

00:27:11,080 --> 00:27:16,769
environment will set up where you also

00:27:12,820 --> 00:27:19,749
have kind of a heavy-duty cluster that

00:27:16,769 --> 00:27:22,539
people would want access to they can

00:27:19,749 --> 00:27:24,580
also access that we don't tie you

00:27:22,539 --> 00:27:26,710
directly into that cluster meaning

00:27:24,580 --> 00:27:28,359
there's no hard requirement that you use

00:27:26,710 --> 00:27:30,429
it if you want to substitute your own

00:27:28,359 --> 00:27:32,379
spark cluster you can do that the same

00:27:30,429 --> 00:27:35,340
goes for Prometheus uber fauna you can

00:27:32,379 --> 00:27:40,400
disable that and monitor it on

00:27:35,340 --> 00:27:48,780
cluster why Prometheus and seven so

00:27:40,400 --> 00:27:51,060
that's the parts just you get an idea

00:27:48,780 --> 00:27:53,060
and this is more of interest to the

00:27:51,060 --> 00:27:57,270
DevOps so you can see that there is a

00:27:53,060 --> 00:28:06,200
user spark cluster here one master and

00:27:57,270 --> 00:28:06,200
two workers and the users here

00:28:14,110 --> 00:28:17,529
so that's gonna happen we're still

00:28:16,149 --> 00:28:20,500
waiting for the Supergirl of notebook

00:28:17,529 --> 00:28:23,169
pod to come up so once it comes out

00:28:20,500 --> 00:28:24,580
where we've already pre-loaded some data

00:28:23,169 --> 00:28:27,370
in there that we're gonna use for the

00:28:24,580 --> 00:28:30,250
workshop so I'm just going to go through

00:28:27,370 --> 00:28:33,880
a quick workshop or notebook that will

00:28:30,250 --> 00:28:37,200
demonstrate how you would actually

00:28:33,880 --> 00:28:40,179
access that information that since

00:28:37,200 --> 00:28:44,110
object storage how you can run some

00:28:40,179 --> 00:28:46,600
operations on it and then how you would

00:28:44,110 --> 00:28:52,620
also at the same time pull information

00:28:46,600 --> 00:28:52,620
from a public Amazon s3

00:29:10,460 --> 00:29:14,980
so standard interface

00:29:34,810 --> 00:29:42,860
so this is this notebook we did this in

00:29:38,330 --> 00:29:47,420
a workshop on one Wednesday demonstrate

00:29:42,860 --> 00:29:49,220
different parts of the notebook so some

00:29:47,420 --> 00:29:51,440
key things I'll point out is we're just

00:29:49,220 --> 00:29:55,220
using the standard photo three library

00:29:51,440 --> 00:29:57,950
for accessing the SP server so we're

00:29:55,220 --> 00:30:02,920
using this to connect to it our custom

00:29:57,950 --> 00:30:04,880
spark cluster sorry cluster and then

00:30:02,920 --> 00:30:07,250
demonstrate how you would actually

00:30:04,880 --> 00:30:09,670
create buckets and put that into those

00:30:07,250 --> 00:30:09,670
buckets

00:30:19,679 --> 00:30:26,169
that's right we are going to connect to

00:30:22,720 --> 00:30:28,239
our user specific spark cluster and run

00:30:26,169 --> 00:30:30,279
some operations on it so this whole

00:30:28,239 --> 00:30:32,259
workflow is the only thing a data

00:30:30,279 --> 00:30:34,299
scientist needs to be concerned with as

00:30:32,259 --> 00:30:36,850
the DevOps would deploy open data home

00:30:34,299 --> 00:30:39,309
and mints in some type of notification

00:30:36,850 --> 00:30:42,629
to say hey this environments up and

00:30:39,309 --> 00:30:45,429
running here is the URL to Jupiter hub

00:30:42,629 --> 00:30:56,649
here is your username and password

00:30:45,429 --> 00:31:01,239
have fun so I won't go in detail for

00:30:56,649 --> 00:31:03,399
every cell since I kind of what we're

00:31:01,239 --> 00:31:05,710
doing is we're actually setting up so

00:31:03,399 --> 00:31:08,139
notifying to do that we have an

00:31:05,710 --> 00:31:12,700
additional s3 endpoints that we want to

00:31:08,139 --> 00:31:19,359
access data from so the Vita's 10 points

00:31:12,700 --> 00:31:21,789
is actually a public s 3 bucket and the

00:31:19,359 --> 00:31:24,129
other point is stuff so we're getting

00:31:21,789 --> 00:31:26,590
data from the public festive and storing

00:31:24,129 --> 00:31:29,460
it in our internal open data hub

00:31:26,590 --> 00:31:29,460
s3

00:31:38,409 --> 00:31:44,269
so he queried the spark clusters see how

00:31:41,869 --> 00:31:48,039
many workers are available and now we're

00:31:44,269 --> 00:31:48,039
just running actions on that day

00:32:03,150 --> 00:32:10,470
so in the past I think this is running

00:32:06,340 --> 00:32:13,179
on for one in 311 we're actually using

00:32:10,470 --> 00:32:16,890
nano the prior to that we were using

00:32:13,179 --> 00:32:19,720
video so the the underlying server

00:32:16,890 --> 00:32:21,460
object storage server does not matter we

00:32:19,720 --> 00:32:22,840
just care about the endpoints so as long

00:32:21,460 --> 00:32:27,040
as you have a credentials for it and

00:32:22,840 --> 00:32:27,429
it'll accesses so all of that abstracted

00:32:27,040 --> 00:32:29,110
away

00:32:27,429 --> 00:32:31,540
we're not tying you into a specific

00:32:29,110 --> 00:32:35,320
technology all the Red Hat products are

00:32:31,540 --> 00:32:38,530
the best so you can use whatever you

00:32:35,320 --> 00:32:44,530
want if I think in another workshop

00:32:38,530 --> 00:32:46,480
somebody had asked the question there's

00:32:44,530 --> 00:32:48,070
nothing tying you to the spark cluster

00:32:46,480 --> 00:32:50,200
that we provide you can completely

00:32:48,070 --> 00:32:53,919
disable that the only thing that you're

00:32:50,200 --> 00:32:56,160
concerned about is the URL to that spark

00:32:53,919 --> 00:32:58,600
cluster so here we're actually

00:32:56,160 --> 00:33:00,040
connecting to the user specifically but

00:32:58,600 --> 00:33:01,330
if there was an external one that you

00:33:00,040 --> 00:33:03,570
wanted to send data to you could do that

00:33:01,330 --> 00:33:03,570
here

00:33:06,590 --> 00:33:10,220
like this might have

00:33:11,030 --> 00:33:14,480
where is my nephew

00:33:15,470 --> 00:33:18,789
so soon

00:33:19,090 --> 00:33:24,080
okay so

00:33:21,830 --> 00:33:26,659
Jim rub is just a server to manage

00:33:24,080 --> 00:33:31,669
multiple users what you'll see here is

00:33:26,659 --> 00:33:35,590
we have the file specific to this user

00:33:31,669 --> 00:33:38,720
this is backed by a persistent bond so

00:33:35,590 --> 00:33:40,159
all the files will be stored I think it

00:33:38,720 --> 00:33:41,720
depends on the server whatever their

00:33:40,159 --> 00:33:48,049
volumes are bad five typically

00:33:41,720 --> 00:33:54,289
internally we use so you do have access

00:33:48,049 --> 00:33:55,700
to those outside of Jupiter hub so let

00:33:54,289 --> 00:33:57,320
me just show you what it looks like so

00:33:55,700 --> 00:34:00,289
right now we're logged in as user one

00:33:57,320 --> 00:34:07,539
just imagine I'm open up another web

00:34:00,289 --> 00:34:07,539
browser and I want to login as user 25

00:34:11,819 --> 00:34:18,190
so they get the same screen they can

00:34:14,560 --> 00:34:25,079
change options as they see fit and then

00:34:18,190 --> 00:34:27,310
we would just hit a smaller Sodra have

00:34:25,079 --> 00:34:30,190
multiple users use the same jus for

00:34:27,310 --> 00:34:33,280
server it's primarily responsibility is

00:34:30,190 --> 00:34:34,540
to take that information spawn a

00:34:33,280 --> 00:34:37,060
notebook according to your

00:34:34,540 --> 00:34:39,550
configurations or Delta pod according to

00:34:37,060 --> 00:34:42,720
your specifications and then allow you

00:34:39,550 --> 00:34:45,399
to do whatever you want with it and

00:34:42,720 --> 00:34:48,129
you'll see we have two notebooks one for

00:34:45,399 --> 00:34:49,869
user 1 and 1 producer 25 so internally

00:34:48,129 --> 00:34:54,280
we have one Jupiter app server then we

00:34:49,869 --> 00:34:56,339
have 100 plus users actually using their

00:34:54,280 --> 00:34:56,339
own

00:35:20,290 --> 00:35:25,310
[Music]

00:35:22,210 --> 00:35:27,020
all right so I'm gonna bring this home

00:35:25,310 --> 00:35:28,490
now for you to tie all these connect all

00:35:27,020 --> 00:35:30,619
these dots together right so we saw the

00:35:28,490 --> 00:35:32,960
different personas so hopefully it's

00:35:30,619 --> 00:35:35,450
obvious why we think that the open cloud

00:35:32,960 --> 00:35:37,790
exchange model is a very attractive

00:35:35,450 --> 00:35:39,980
model to run the open data hub from a

00:35:37,790 --> 00:35:41,810
software person bender perspective we

00:35:39,980 --> 00:35:43,070
are like we give access to users and

00:35:41,810 --> 00:35:45,230
they can give us feedback on the various

00:35:43,070 --> 00:35:46,970
components we have we also have the

00:35:45,230 --> 00:35:49,220
operations components so we get feedback

00:35:46,970 --> 00:35:51,200
from the MOC folks on what it takes to

00:35:49,220 --> 00:35:53,390
operate these types of clusters of scale

00:35:51,200 --> 00:35:55,070
and we're running across a number of

00:35:53,390 --> 00:35:56,930
different hardware architectures so

00:35:55,070 --> 00:35:59,030
we're getting that feedback on a lot

00:35:56,930 --> 00:36:00,530
more infrastructure components than we

00:35:59,030 --> 00:36:03,400
would otherwise for our internal

00:36:00,530 --> 00:36:06,890
environments and from a user perspective

00:36:03,400 --> 00:36:08,810
the researchers students communities are

00:36:06,890 --> 00:36:10,490
getting access to infrastructure and

00:36:08,810 --> 00:36:12,590
capabilities that they otherwise might

00:36:10,490 --> 00:36:15,890
not have access to rightly expensive

00:36:12,590 --> 00:36:18,400
things like GPUs FPGAs all of that type

00:36:15,890 --> 00:36:21,020
of information or environment and

00:36:18,400 --> 00:36:22,250
large-scale storage right so they don't

00:36:21,020 --> 00:36:23,720
have to worry about spending all that

00:36:22,250 --> 00:36:25,609
stuff up they're not bothered with the

00:36:23,720 --> 00:36:27,410
infrastructure so again it's bringing

00:36:25,609 --> 00:36:29,780
together all those core concepts for the

00:36:27,410 --> 00:36:32,210
open cloud exchange and realizing the

00:36:29,780 --> 00:36:33,859
benefits of it and so last year at this

00:36:32,210 --> 00:36:36,080
particular conference we announced our

00:36:33,859 --> 00:36:40,250
ta program and out of that EA program we

00:36:36,080 --> 00:36:41,660
had a couple research institutions we'll

00:36:40,250 --> 00:36:43,430
call them I guess and private

00:36:41,660 --> 00:36:45,710
researchers that ran through the this

00:36:43,430 --> 00:36:48,350
exact environment gave us feedback that

00:36:45,710 --> 00:36:50,180
has not resulted in what landing gave

00:36:48,350 --> 00:36:52,310
you so from that perspective we did

00:36:50,180 --> 00:36:54,230
learn some lessons around the capacity

00:36:52,310 --> 00:36:55,970
planning for data science we definitely

00:36:54,230 --> 00:36:57,619
needed to plan that a lot more

00:36:55,970 --> 00:36:59,720
diligently upfront when we're onboarding

00:36:57,619 --> 00:37:02,660
users which is that's been accounted for

00:36:59,720 --> 00:37:04,609
in the new intake process the stability

00:37:02,660 --> 00:37:06,680
of the platform and services we need to

00:37:04,609 --> 00:37:08,240
do some large-scale validation of the

00:37:06,680 --> 00:37:09,680
before we then roll those out to

00:37:08,240 --> 00:37:09,890
individual users records they're going

00:37:09,680 --> 00:37:11,720
to

00:37:09,890 --> 00:37:14,240
things at a scale maybe we haven't done

00:37:11,720 --> 00:37:16,220
with our small-scale just integration

00:37:14,240 --> 00:37:19,310
testing we want to make sure our

00:37:16,220 --> 00:37:20,900
priorities are lined up right so from a

00:37:19,310 --> 00:37:22,250
what red-hats trying to get out of it

00:37:20,900 --> 00:37:23,420
what the MOC is trying to get out of it

00:37:22,250 --> 00:37:24,920
and what the research is trying to get

00:37:23,420 --> 00:37:27,140
out of it is want to make sure everyone

00:37:24,920 --> 00:37:29,150
gets a win and then that keep that

00:37:27,140 --> 00:37:29,780
communication flowing so what are we

00:37:29,150 --> 00:37:31,700
doing next

00:37:29,780 --> 00:37:33,740
Landon talks obviously all the stuff is

00:37:31,700 --> 00:37:36,170
running in git lab we're doing more

00:37:33,740 --> 00:37:38,330
around operationalizing model serving

00:37:36,170 --> 00:37:40,520
and creating public endpoints so the

00:37:38,330 --> 00:37:41,900
data science early adopters we had

00:37:40,520 --> 00:37:44,210
before were able to build their models

00:37:41,900 --> 00:37:45,770
do their research and generate their

00:37:44,210 --> 00:37:47,360
output papers and now we're gonna give

00:37:45,770 --> 00:37:48,800
them the ability to do is with a push of

00:37:47,360 --> 00:37:51,230
a button or a couple lines of code

00:37:48,800 --> 00:37:53,030
actually publish an endpoint and host

00:37:51,230 --> 00:37:54,500
them for inference so they can send data

00:37:53,030 --> 00:37:57,800
into it live if they want to have an

00:37:54,500 --> 00:38:00,080
external application calling into the

00:37:57,800 --> 00:38:02,000
components they have built and then we

00:38:00,080 --> 00:38:04,520
also want to initiate the open cloud

00:38:02,000 --> 00:38:06,290
marketplace so this is where we'll have

00:38:04,520 --> 00:38:08,180
a number of components listed open data

00:38:06,290 --> 00:38:09,710
hub being one of them and users can come

00:38:08,180 --> 00:38:13,550
into the MOC and select which components

00:38:09,710 --> 00:38:15,440
they want to be able to play with so you

00:38:13,550 --> 00:38:16,790
can try it yourself right we're standing

00:38:15,440 --> 00:38:18,290
this is out there on the MOC if you're

00:38:16,790 --> 00:38:20,750
interested in using it we are looking

00:38:18,290 --> 00:38:22,700
for a second round of use cases to run

00:38:20,750 --> 00:38:24,590
through the new environment build on

00:38:22,700 --> 00:38:25,850
what we've had and continue this sort of

00:38:24,590 --> 00:38:28,430
a turret iterative development

00:38:25,850 --> 00:38:29,540
environment so if you have any interest

00:38:28,430 --> 00:38:30,860
if you're interested in the open data

00:38:29,540 --> 00:38:33,200
hub go ahead and join the community

00:38:30,860 --> 00:38:34,700
right that's what it's out there for if

00:38:33,200 --> 00:38:36,920
you want to be an early adopter contact

00:38:34,700 --> 00:38:38,410
myself contact Michael contact Landon

00:38:36,920 --> 00:38:40,210
anyone

00:38:38,410 --> 00:38:46,020
a CEO a team when we can get you

00:38:40,210 --> 00:38:46,020

YouTube URL: https://www.youtube.com/watch?v=KWDUkm1ZeKY


