Title: Flock 2018 - Building Fedora CoreOS
Publication date: 2018-09-03
Playlist: Flock 2018
Description: 
	Thursday, August 9, 2018 
2:30pm - 3:20pm
@Hamburg 1+2

Talk: Building Fedora CoreOS
Presenters: Dusty Mabe, Benjamin Gilbert

Description: Fedora CoreOS is a future Fedora edition drawing from the best of Fedora Atomic Host and CoreOS Container Linux. We'll look at the structure and key design choices of those two operating systems, what's worked and what hasn't, and where we think Fedora CoreOS should go as a result. We'll conclude with an update on the state of Fedora CoreOS development.
Captions: 
	00:00:01,310 --> 00:00:07,620
all right yeah let's try that again

00:00:04,890 --> 00:00:10,019
I'm Benjamin Gilbert formerly on the

00:00:07,620 --> 00:00:13,019
container Linux team at core OS now on

00:00:10,019 --> 00:00:15,859
the core OS team at Red Hat working on

00:00:13,019 --> 00:00:19,890
container Linux and on Fedora core OS

00:00:15,859 --> 00:00:21,330
and I am dusty mabe previously I've been

00:00:19,890 --> 00:00:23,699
involved in the atomic working group

00:00:21,330 --> 00:00:26,670
within fedora and now involved in the

00:00:23,699 --> 00:00:28,010
Fedora core OS working group so that's

00:00:26,670 --> 00:00:33,170
what I do

00:00:28,010 --> 00:00:37,170
cool so we're gonna do a few things here

00:00:33,170 --> 00:00:39,180
Wow interesting

00:00:37,170 --> 00:00:41,489
we're gonna do a few things I'm gonna

00:00:39,180 --> 00:00:44,219
talk for a while about container Linux I

00:00:41,489 --> 00:00:47,039
assume that folks in this room aren't

00:00:44,219 --> 00:00:50,100
necessarily that familiar with it and

00:00:47,039 --> 00:00:52,770
then afterward dusty is going to talk

00:00:50,100 --> 00:00:54,449
about project atomic and at the end

00:00:52,770 --> 00:00:56,070
we're going to close with how both of

00:00:54,449 --> 00:00:59,960
those projects have been formed where we

00:00:56,070 --> 00:01:04,080
think we're going from Fedora core OS so

00:00:59,960 --> 00:01:07,200
where did container Linux come from this

00:01:04,080 --> 00:01:11,760
is a linux OS project that we started in

00:01:07,200 --> 00:01:16,740
2013 at the then fledgling startup core

00:01:11,760 --> 00:01:20,670
OS it's based on chromium OS which is

00:01:16,740 --> 00:01:22,890
the Google Chrome OS upstream open

00:01:20,670 --> 00:01:25,189
source project we inherited a lot of its

00:01:22,890 --> 00:01:31,380
design choices including the fact that

00:01:25,189 --> 00:01:34,770
it uses gen 2 packages Gen 2 tooling to

00:01:31,380 --> 00:01:37,189
build software since 2013 we've had a

00:01:34,770 --> 00:01:40,009
whole bunch of releases

00:01:37,189 --> 00:01:42,409
and the thing we're building is a

00:01:40,009 --> 00:01:45,700
minimal container focused server

00:01:42,409 --> 00:01:45,700
operating system for production use

00:01:45,939 --> 00:01:50,719
targeting primarily clustered

00:01:47,719 --> 00:01:53,240
deployments though also operate

00:01:50,719 --> 00:01:54,469
standalone and we think a lot in terms

00:01:53,240 --> 00:01:56,020
of a mutable infrastructure and I'll

00:01:54,469 --> 00:01:58,310
talk about that more in a minute

00:01:56,020 --> 00:02:00,829
automatic updates are a big part of the

00:01:58,310 --> 00:02:06,969
story the idea is that you should be

00:02:00,829 --> 00:02:06,969
able to install a container Linux node

00:02:08,470 --> 00:02:15,410
install a container Linux node and not

00:02:13,579 --> 00:02:16,700
think about it afterward the node should

00:02:15,410 --> 00:02:19,819
just update itself and you shouldn't

00:02:16,700 --> 00:02:21,470
have to worry we try to have broad

00:02:19,819 --> 00:02:24,049
platform support so that whatever cloud

00:02:21,470 --> 00:02:26,170
you want to run on or whatever bare

00:02:24,049 --> 00:02:28,790
metal system or whatever you can do so

00:02:26,170 --> 00:02:30,739
and of course stability and security our

00:02:28,790 --> 00:02:33,819
primary concern so that seems to have

00:02:30,739 --> 00:02:33,819
helped but could you

00:02:40,860 --> 00:02:44,160
okay so going into some of those a

00:02:42,690 --> 00:02:45,920
little bit more detail production

00:02:44,160 --> 00:02:48,930
operating system was that mean exactly

00:02:45,920 --> 00:02:50,070
we do not ship anything that you don't

00:02:48,930 --> 00:02:52,170
need for running containers in

00:02:50,070 --> 00:02:55,950
production for the most part no

00:02:52,170 --> 00:02:58,620
development tools except to get not a

00:02:55,950 --> 00:03:00,540
lot of debugging tools and really just

00:02:58,620 --> 00:03:04,170
enough to get your Hardware going and

00:03:00,540 --> 00:03:05,280
then and then rent containers immutable

00:03:04,170 --> 00:03:09,060
infrastructure I mentioned a moment

00:03:05,280 --> 00:03:10,740
before the idea here is that you have

00:03:09,060 --> 00:03:12,120
the base OS image and then any

00:03:10,740 --> 00:03:13,920
customizations you want to make the

00:03:12,120 --> 00:03:16,590
configuration or or what-have-you

00:03:13,920 --> 00:03:18,900
are encoded in a single provisioning

00:03:16,590 --> 00:03:22,500
configuration that you pass through user

00:03:18,900 --> 00:03:24,120
data for example in the cloud we don't

00:03:22,500 --> 00:03:26,360
prevent you from SSA Qing in and

00:03:24,120 --> 00:03:31,410
arbitrarily modifying the node afterward

00:03:26,360 --> 00:03:32,790
but really you shouldn't configuration

00:03:31,410 --> 00:03:34,860
management this is a bit tongue-in-cheek

00:03:32,790 --> 00:03:36,870
is not something we really encourage

00:03:34,860 --> 00:03:39,840
you're free to do it

00:03:36,870 --> 00:03:42,390
you can ansible can run with some effort

00:03:39,840 --> 00:03:43,800
but really the idea is that if you want

00:03:42,390 --> 00:03:47,940
to make changes you should probably be

00:03:43,800 --> 00:03:49,710
reprovision the note and then automatic

00:03:47,940 --> 00:03:51,000
updates as I said users shouldn't have

00:03:49,710 --> 00:03:52,980
to think about them this has

00:03:51,000 --> 00:03:57,780
consequences for us we cannot break

00:03:52,980 --> 00:04:01,020
compatibility ever if there are old boot

00:03:57,780 --> 00:04:02,640
loaders that we no longer ship which is

00:04:01,020 --> 00:04:05,520
true if they're old versions of cloud

00:04:02,640 --> 00:04:09,810
agents that are still on nodes we have

00:04:05,520 --> 00:04:10,890
to work if a daemon is updated it still

00:04:09,810 --> 00:04:12,180
needs to be able to read deal version to

00:04:10,890 --> 00:04:15,420
config file or we have to go through

00:04:12,180 --> 00:04:16,830
some conversion process and if we really

00:04:15,420 --> 00:04:17,609
do need to deprecated a service and

00:04:16,830 --> 00:04:19,109
remove it from the operating system

00:04:17,609 --> 00:04:21,120
there has to be a long deprecation

00:04:19,109 --> 00:04:24,390
window which long for us means probably

00:04:21,120 --> 00:04:29,040
upwards of a year and then of course no

00:04:24,390 --> 00:04:30,660
regressions that's hard to do if we

00:04:29,040 --> 00:04:32,190
regress too much users will disable

00:04:30,660 --> 00:04:33,690
automatic updates and they will no

00:04:32,190 --> 00:04:35,700
longer be getting security patches and

00:04:33,690 --> 00:04:38,120
they'll be running some OS version from

00:04:35,700 --> 00:04:38,120
two years ago

00:04:38,630 --> 00:04:41,990
here's a list of the platform's you

00:04:39,800 --> 00:04:44,960
support pretty much all the major at

00:04:41,990 --> 00:04:48,470
least US and European focus cloud

00:04:44,960 --> 00:04:50,090
providers life pixie is an important key

00:04:48,470 --> 00:04:52,040
use case for us we actually have quite a

00:04:50,090 --> 00:04:55,850
few quite a large percentage of our user

00:04:52,040 --> 00:04:58,190
base is booting container linux from

00:04:55,850 --> 00:05:04,610
pixie into ram and the entire sort of

00:04:58,190 --> 00:05:06,170
the OS itself is running on ram ok so a

00:05:04,610 --> 00:05:09,470
big part of the story is install an

00:05:06,170 --> 00:05:10,190
update how does that work I'm sorry but

00:05:09,470 --> 00:05:13,040
I'm going to present you with a

00:05:10,190 --> 00:05:14,480
partition table and the reason is that

00:05:13,040 --> 00:05:15,560
this is pretty important for

00:05:14,480 --> 00:05:18,650
understanding how the operating system

00:05:15,560 --> 00:05:22,270
fits together so at the end there is the

00:05:18,650 --> 00:05:29,990
root filesystem that is for user data

00:05:22,270 --> 00:05:32,270
should we try to make the root partition

00:05:29,990 --> 00:05:33,710
is for user data and it's for

00:05:32,270 --> 00:05:36,800
configuration data you can put whatever

00:05:33,710 --> 00:05:38,180
you want in Etsy and that's fine the

00:05:36,800 --> 00:05:41,240
rest of the partitions are owned by the

00:05:38,180 --> 00:05:43,190
operating system and users are not

00:05:41,240 --> 00:05:45,340
encouraged to mess with them so boot of

00:05:43,190 --> 00:05:49,280
courses for kernels and then we have two

00:05:45,340 --> 00:05:50,930
identical partitions for user because

00:05:49,280 --> 00:05:53,840
all of the operating system code is

00:05:50,930 --> 00:05:56,900
shipped in user as a immutable

00:05:53,840 --> 00:05:59,000
filesystem image so there's an

00:05:56,900 --> 00:06:00,350
active/passive partition and we update

00:05:59,000 --> 00:06:04,280
one while running from the other and

00:06:00,350 --> 00:06:06,200
then reboot the OEM partition is four

00:06:04,280 --> 00:06:07,430
it's a weird name for historical reasons

00:06:06,200 --> 00:06:09,590
it's for platform specific

00:06:07,430 --> 00:06:12,770
customizations like on GCE

00:06:09,590 --> 00:06:16,760
or or packet or whatever and I'll talk

00:06:12,770 --> 00:06:18,500
about that a little bit more later how

00:06:16,760 --> 00:06:21,169
do we install this thing there are no

00:06:18,500 --> 00:06:25,340
installers in the cloud you launch an

00:06:21,169 --> 00:06:27,080
ami or an image of some sort and of

00:06:25,340 --> 00:06:29,120
course for pixie there's no installer so

00:06:27,080 --> 00:06:31,010
that leaves bare metal installed to disk

00:06:29,120 --> 00:06:32,870
and we didn't want to write an installer

00:06:31,010 --> 00:06:34,730
just for that use case where you're

00:06:32,870 --> 00:06:36,380
doing your customization in a way

00:06:34,730 --> 00:06:38,330
different from the other platform

00:06:36,380 --> 00:06:40,520
so the installer is just a shell script

00:06:38,330 --> 00:06:43,310
that really just downloads an image and

00:06:40,520 --> 00:06:45,610
DS at DD's onto the disk that works

00:06:43,310 --> 00:06:49,400
pretty well it doesn't work perfectly

00:06:45,610 --> 00:06:52,220
for K sector drives are a problem but

00:06:49,400 --> 00:06:53,810
for the most part it works you get a

00:06:52,220 --> 00:06:56,870
monolithic image same as on other

00:06:53,810 --> 00:06:59,450
platforms once you have that monolithic

00:06:56,870 --> 00:07:02,810
image booted you need to customize it

00:06:59,450 --> 00:07:07,160
provision it in some way we've had a

00:07:02,810 --> 00:07:09,620
couple attempts at this canonical cloud

00:07:07,160 --> 00:07:11,470
in it is the obvious thing to try it's

00:07:09,620 --> 00:07:14,540
written in Python we don't ship Python

00:07:11,470 --> 00:07:19,190
we wrote our own it's more or less cloud

00:07:14,540 --> 00:07:21,730
net kind of less it turned out to be a

00:07:19,190 --> 00:07:24,830
problem it runs as a regular process

00:07:21,730 --> 00:07:26,690
halfway through boot and at that point

00:07:24,830 --> 00:07:29,390
it runs around and writes our config

00:07:26,690 --> 00:07:32,500
files and enables and disables services

00:07:29,390 --> 00:07:34,520
and starts services and when it fails

00:07:32,500 --> 00:07:38,360
you're left with a half configured

00:07:34,520 --> 00:07:40,190
system even when it succeeds you end up

00:07:38,360 --> 00:07:43,310
with complications around service

00:07:40,190 --> 00:07:44,900
ordering and that kind of thing also it

00:07:43,310 --> 00:07:47,090
runs on every boot which means that

00:07:44,900 --> 00:07:48,650
users try to modify the config behind

00:07:47,090 --> 00:07:49,910
its back and then reboot to have it pick

00:07:48,650 --> 00:07:52,190
up changes and it was really never

00:07:49,910 --> 00:07:56,600
designed for that so to correct those

00:07:52,190 --> 00:07:58,910
problems we built ignition ignition is a

00:07:56,600 --> 00:08:02,330
provisioning system that runs in unit

00:07:58,910 --> 00:08:04,640
RAM FS once on first boot and because

00:08:02,330 --> 00:08:07,570
it's running that early it can do things

00:08:04,640 --> 00:08:10,970
with impunity that cloud and it couldn't

00:08:07,570 --> 00:08:13,460
so it can of course drop files it can

00:08:10,970 --> 00:08:15,560
create system D units enable and disable

00:08:13,460 --> 00:08:16,910
services and that's fine because the

00:08:15,560 --> 00:08:19,440
boot hasn't really started yet

00:08:16,910 --> 00:08:21,840
create users and groups

00:08:19,440 --> 00:08:23,460
but because it's running in part before

00:08:21,840 --> 00:08:24,870
the root filesystem is even mounted it

00:08:23,460 --> 00:08:25,530
can do things like reformat the root

00:08:24,870 --> 00:08:27,390
filesystem

00:08:25,530 --> 00:08:29,730
if you want to be exif s or butter s

00:08:27,390 --> 00:08:31,950
instead of x4 you can do that with

00:08:29,730 --> 00:08:33,930
ignition and then finally if

00:08:31,950 --> 00:08:35,520
provisioning fails you're done we just

00:08:33,930 --> 00:08:37,770
drop you to an emergency shell and we

00:08:35,520 --> 00:08:39,479
don't boot the system at all which means

00:08:37,770 --> 00:08:46,020
that if the system comes up you know

00:08:39,479 --> 00:08:48,150
that it's provision properly okay atomic

00:08:46,020 --> 00:08:50,700
updates how do we update I mentioned the

00:08:48,150 --> 00:08:52,260
active and passive system before we ship

00:08:50,700 --> 00:08:55,500
you an X for file system image and a

00:08:52,260 --> 00:08:58,260
kernel and it gets written down to the

00:08:55,500 --> 00:09:02,160
disk that's easy to explain it seems

00:08:58,260 --> 00:09:04,410
pretty nice it has limitations updates

00:09:02,160 --> 00:09:08,190
overwrite the previous version we had a

00:09:04,410 --> 00:09:10,020
case recently where we had a bad version

00:09:08,190 --> 00:09:11,760
and we were trying to update out of it

00:09:10,020 --> 00:09:12,990
but that was kind of scary we weren't

00:09:11,760 --> 00:09:14,970
sure whether we were going to be able to

00:09:12,990 --> 00:09:17,460
update out of it in that case but trying

00:09:14,970 --> 00:09:19,620
to do so was going to overwrite the last

00:09:17,460 --> 00:09:23,310
known good previous version and there

00:09:19,620 --> 00:09:26,940
was just no way that with a B model once

00:09:23,310 --> 00:09:31,710
we boot into the new system 45 seconds

00:09:26,940 --> 00:09:33,390
later it commits and at that point the

00:09:31,710 --> 00:09:35,700
updater can now fetch a subsequent

00:09:33,390 --> 00:09:37,170
update and download that so there's this

00:09:35,700 --> 00:09:42,000
very narrow window where rollback is

00:09:37,170 --> 00:09:43,770
even possible and we have essentially

00:09:42,000 --> 00:09:46,320
one update image per architecture

00:09:43,770 --> 00:09:49,550
because the platform customizations are

00:09:46,320 --> 00:09:49,550
only embedded in the install image

00:09:50,630 --> 00:09:55,459
an important piece of how we do updates

00:09:52,610 --> 00:09:59,959
is staged rollouts we do not just push

00:09:55,459 --> 00:10:02,509
an update to the mirrors and and let

00:09:59,959 --> 00:10:03,649
everyone download it at once if a client

00:10:02,509 --> 00:10:05,269
wants to receive an update it has to

00:10:03,649 --> 00:10:08,209
call into a server to get permission and

00:10:05,269 --> 00:10:10,790
we ramped up over time the number of

00:10:08,209 --> 00:10:12,440
nodes we're allowing to update nominally

00:10:10,790 --> 00:10:14,990
this allows us to watch dess reports

00:10:12,440 --> 00:10:18,199
coming back from nodes but in practice

00:10:14,990 --> 00:10:20,000
the major use of it is that if a user

00:10:18,199 --> 00:10:22,220
reports a bug in the new version we can

00:10:20,000 --> 00:10:27,110
stop the rollout before it hits all

00:10:22,220 --> 00:10:28,490
nodes in the process of talking to the

00:10:27,110 --> 00:10:30,769
update server the client sends the

00:10:28,490 --> 00:10:32,680
metrics cloud platform OS version

00:10:30,769 --> 00:10:34,850
original OS version that kind of thing

00:10:32,680 --> 00:10:36,470
but because that's coupled to the update

00:10:34,850 --> 00:10:38,060
system if user disables updates for

00:10:36,470 --> 00:10:40,519
whatever reasons we no longer get those

00:10:38,060 --> 00:10:41,990
metrics and we have no idea the node

00:10:40,519 --> 00:10:47,300
becomes dark matter we have no idea that

00:10:41,990 --> 00:10:49,310
it's out there these are some of the

00:10:47,300 --> 00:10:51,589
components that that are involved

00:10:49,310 --> 00:10:52,670
protocol client server they all have

00:10:51,589 --> 00:10:54,500
problems

00:10:52,670 --> 00:10:57,040
that was not code that we wanted to

00:10:54,500 --> 00:10:57,040
carry forward

00:10:57,890 --> 00:11:02,339
clusterings

00:10:59,730 --> 00:11:04,529
so once a note is updated it needs to

00:11:02,339 --> 00:11:07,169
reboot into the new Chrome the new user

00:11:04,529 --> 00:11:09,540
partition and the original assumption

00:11:07,169 --> 00:11:11,879
was that the OS would be installed in

00:11:09,540 --> 00:11:14,850
clusters and the cluster has to handle

00:11:11,879 --> 00:11:17,939
node failures and so it's okay to just

00:11:14,850 --> 00:11:19,290
reboot a node we can't reboot all the

00:11:17,939 --> 00:11:21,660
nodes at once of course or the cluster

00:11:19,290 --> 00:11:24,419
would go down so we have a coordination

00:11:21,660 --> 00:11:26,730
mechanism called locksmiths which takes

00:11:24,419 --> 00:11:28,619
a lock and head CD to ensure that only

00:11:26,730 --> 00:11:32,249
one node in the cluster can reboot in a

00:11:28,619 --> 00:11:35,489
given time but the cluster doesn't know

00:11:32,249 --> 00:11:37,980
about any of this if you have a

00:11:35,489 --> 00:11:40,980
kubernetes system with container or

00:11:37,980 --> 00:11:43,470
linux underneath than by just using this

00:11:40,980 --> 00:11:46,679
mechanism the nodes don't drain before

00:11:43,470 --> 00:11:50,129
reboot so some some connections that

00:11:46,679 --> 00:11:51,600
you're serving will just drop conversely

00:11:50,129 --> 00:11:53,040
the cluster doesn't control the OS

00:11:51,600 --> 00:11:54,299
version running on each of the nodes the

00:11:53,040 --> 00:11:58,259
nodes are all updating at their own pace

00:11:54,299 --> 00:12:01,079
and that's not ideal either so what we

00:11:58,259 --> 00:12:03,809
needed to do for tecktonik and and for

00:12:01,079 --> 00:12:07,649
kubernetes was build a higher-level

00:12:03,809 --> 00:12:09,569
coordination mechanism and we did that

00:12:07,649 --> 00:12:11,519
but it doesn't get any help from the

00:12:09,569 --> 00:12:14,789
operating system it's it's reaching in

00:12:11,519 --> 00:12:16,199
and twiddling some of the same

00:12:14,789 --> 00:12:17,699
mechanisms without going through

00:12:16,199 --> 00:12:21,169
locksmith or any of the tooling it

00:12:17,699 --> 00:12:21,169
shipped on the OS so that's not ideal

00:12:22,019 --> 00:12:27,940
automate automate ik updates also have

00:12:25,120 --> 00:12:30,459
exclusions the om partition that I

00:12:27,940 --> 00:12:33,459
mentioned earlier which contains a lot

00:12:30,459 --> 00:12:36,310
of the platform-specific code the cloud

00:12:33,459 --> 00:12:39,220
agents cannot be updated for weird

00:12:36,310 --> 00:12:42,399
historical reasons the bootloader can't

00:12:39,220 --> 00:12:44,260
be updated either for the reason that if

00:12:42,399 --> 00:12:46,980
you break the bootloader you brick the

00:12:44,260 --> 00:12:49,690
machine and so it just didn't seem safe

00:12:46,980 --> 00:12:51,610
and then one day we had a bug where

00:12:49,690 --> 00:12:54,970
there was memory corruption inside grub

00:12:51,610 --> 00:12:57,610
and depending on the exact like block

00:12:54,970 --> 00:13:02,410
level layout of the boot partition grub

00:12:57,610 --> 00:13:05,260
would start boot looping we have a shell

00:13:02,410 --> 00:13:07,540
script core rest post densed it runs

00:13:05,260 --> 00:13:10,959
after the image is laid down and it

00:13:07,540 --> 00:13:14,829
contains all the hacks so what we had to

00:13:10,959 --> 00:13:17,320
do to fix this was detect the broken

00:13:14,829 --> 00:13:20,339
versions of grub and use printf and DD

00:13:17,320 --> 00:13:20,339
to binary patch them

00:13:22,660 --> 00:13:26,320
just briefly automatic roll back seems

00:13:24,670 --> 00:13:29,740
like a useful thing to do if the node

00:13:26,320 --> 00:13:31,720
fails to come back after a reboot boot

00:13:29,740 --> 00:13:33,970
back into the old version that kind of

00:13:31,720 --> 00:13:35,770
works there's no reason it we couldn't

00:13:33,970 --> 00:13:40,180
have gotten this completely working but

00:13:35,770 --> 00:13:43,540
we didn't put the time into it so if the

00:13:40,180 --> 00:13:45,190
new OS personally in effing boot we will

00:13:43,540 --> 00:13:47,320
automatically reboot back into the old

00:13:45,190 --> 00:13:49,660
system because you get further into the

00:13:47,320 --> 00:13:50,860
boot things get fuzzier if if the

00:13:49,660 --> 00:13:53,940
network doesn't come up because you have

00:13:50,860 --> 00:13:58,180
a bad Network driver there's a problem

00:13:53,940 --> 00:13:59,890
we don't detect it if there's a service

00:13:58,180 --> 00:14:01,300
that you particularly care about like

00:13:59,890 --> 00:14:02,680
dr. D if it doesn't start

00:14:01,300 --> 00:14:04,750
we don't detect it you end up with a

00:14:02,680 --> 00:14:07,360
broken machine even if we do

00:14:04,750 --> 00:14:08,590
automatically roll you back the update

00:14:07,360 --> 00:14:10,300
client doesn't know and it'll just apply

00:14:08,590 --> 00:14:13,540
now your boot looping except with a 300

00:14:10,300 --> 00:14:15,340
megabyte download and in between and

00:14:13,540 --> 00:14:17,680
finally we don't have user specific

00:14:15,340 --> 00:14:22,660
health checks for things like special

00:14:17,680 --> 00:14:24,760
services of the user cares about very

00:14:22,660 --> 00:14:27,550
briefly update channels there are

00:14:24,760 --> 00:14:29,020
several most the time you'll want to run

00:14:27,550 --> 00:14:31,510
container links on the stable Channel

00:14:29,020 --> 00:14:34,360
but there exist faster-moving beta and

00:14:31,510 --> 00:14:36,460
alpha releases for reasons I'll get to

00:14:34,360 --> 00:14:38,260
in a moment we try to keep those also

00:14:36,460 --> 00:14:40,360
usable and we encourage users to run a

00:14:38,260 --> 00:14:42,660
few percent of their their nodes on each

00:14:40,360 --> 00:14:42,660
of them

00:14:43,450 --> 00:14:50,470
here's the reason we don't do any manual

00:14:46,570 --> 00:14:51,940
routine testing we have CI and the CI

00:14:50,470 --> 00:14:53,860
tests are fine as far as they go but

00:14:51,940 --> 00:14:55,660
we're shipping millions of lines of

00:14:53,860 --> 00:14:57,310
colonel and system d and docker and

00:14:55,660 --> 00:14:59,500
there are things that CI isn't going to

00:14:57,310 --> 00:15:03,180
catch this is why you want to run alpha

00:14:59,500 --> 00:15:05,520
and beta so the idea is by the time

00:15:03,180 --> 00:15:08,440
codes promote to the stable channel

00:15:05,520 --> 00:15:10,690
users who have a few percent of their

00:15:08,440 --> 00:15:11,980
nodes on on the earlier channels should

00:15:10,690 --> 00:15:13,720
have caught problems that are specific

00:15:11,980 --> 00:15:19,390
to their environments and be able to

00:15:13,720 --> 00:15:22,710
report them to us briefly a few odds and

00:15:19,390 --> 00:15:22,710
ends about the container linux runtime

00:15:22,890 --> 00:15:28,540
we support amd64

00:15:25,330 --> 00:15:29,980
at at arm 64 later we never quite got

00:15:28,540 --> 00:15:32,110
there we actually just recently removed

00:15:29,980 --> 00:15:34,030
it within the last month or so

00:15:32,110 --> 00:15:36,820
it should be surprised to no one who's

00:15:34,030 --> 00:15:38,200
ever even looked at this that bolting on

00:15:36,820 --> 00:15:43,030
a second architecture after the fact

00:15:38,200 --> 00:15:45,220
it's a bad idea we push pretty hard on

00:15:43,030 --> 00:15:50,830
the idea that you should run software in

00:15:45,220 --> 00:15:52,120
containers on CL you can copy binaries

00:15:50,830 --> 00:15:54,610
to the host system from them there's

00:15:52,120 --> 00:15:55,780
nothing preventing you from doing so but

00:15:54,610 --> 00:15:58,180
we really don't think you should

00:15:55,780 --> 00:16:00,790
there's no package manager there are no

00:15:58,180 --> 00:16:06,150
conveniences for this run solver in

00:16:00,790 --> 00:16:10,150
containers okay well it turns out that

00:16:06,150 --> 00:16:14,380
that's right okay well it turns out that

00:16:10,150 --> 00:16:16,030
there are some things like daemons

00:16:14,380 --> 00:16:17,650
associated to particular storage cards

00:16:16,030 --> 00:16:19,600
or whatever that you might want to run

00:16:17,650 --> 00:16:21,430
in the host and of course people are

00:16:19,600 --> 00:16:25,030
interested in out of tree kernel modules

00:16:21,430 --> 00:16:26,380
which they need for various reasons we

00:16:25,030 --> 00:16:29,800
don't have a great answer for that right

00:16:26,380 --> 00:16:31,540
now people ask on IRC about our tree

00:16:29,800 --> 00:16:34,230
kernel modules and my coworker David

00:16:31,540 --> 00:16:34,230
sends the majestÃ©

00:16:35,399 --> 00:16:40,209
docker turned out to be a problem

00:16:37,480 --> 00:16:41,139
initially the model was that we were

00:16:40,209 --> 00:16:42,759
going to ship the latest version of

00:16:41,139 --> 00:16:45,490
docker and everyone's going to be happy

00:16:42,759 --> 00:16:47,470
and for folks using docker a docker

00:16:45,490 --> 00:16:49,990
engine standalone or using docker swarm

00:16:47,470 --> 00:16:52,800
or whatever that was fine the problem is

00:16:49,990 --> 00:16:55,870
the kubernetes does not is not qualified

00:16:52,800 --> 00:17:00,129
against any version of dr. which is

00:16:55,870 --> 00:17:02,829
still under support and so we had a

00:17:00,129 --> 00:17:04,809
choice to make and if we went either

00:17:02,829 --> 00:17:07,360
direction in terms of picking a version

00:17:04,809 --> 00:17:09,520
someone was going to be unhappy so the

00:17:07,360 --> 00:17:12,459
net result is we had to provide a way in

00:17:09,520 --> 00:17:13,689
this OS that's just supposed to work and

00:17:12,459 --> 00:17:15,459
you don't have to think about it we had

00:17:13,689 --> 00:17:18,610
to provide a way to let you choose a

00:17:15,459 --> 00:17:22,569
version of docker the result was torques

00:17:18,610 --> 00:17:23,980
which was just enough package manager to

00:17:22,569 --> 00:17:27,039
get the job done it doesn't do

00:17:23,980 --> 00:17:32,020
dependencies it installs essentially

00:17:27,039 --> 00:17:34,659
every boot into a temp of s it works

00:17:32,020 --> 00:17:39,130
well enough but no one was really happy

00:17:34,659 --> 00:17:40,870
with that compromise I think we try to

00:17:39,130 --> 00:17:42,460
keep interpreters out of the operating

00:17:40,870 --> 00:17:44,890
system this will become important later

00:17:42,460 --> 00:17:46,270
when we talk about Fedora core OS we

00:17:44,890 --> 00:17:47,169
have bash and awk we don't have Python

00:17:46,270 --> 00:17:50,320
we don't have Perl

00:17:47,169 --> 00:17:52,690
it keeps the image small it keeps the

00:17:50,320 --> 00:17:54,100
attack surface small you probably

00:17:52,690 --> 00:17:58,059
shouldn't be running a lot of fancy code

00:17:54,100 --> 00:18:02,130
in the host anyway however then we have

00:17:58,059 --> 00:18:02,130
to do things like re-implement cloud net

00:18:02,900 --> 00:18:09,860
and finally platform agent we have them

00:18:07,250 --> 00:18:12,050
in the OEM partition they can't be

00:18:09,860 --> 00:18:14,030
updated sometimes we have to ship Python

00:18:12,050 --> 00:18:17,660
in the OEM partition that can't be

00:18:14,030 --> 00:18:21,560
updated and the code that we're running

00:18:17,660 --> 00:18:24,860
there is of perhaps uneven quality and

00:18:21,560 --> 00:18:27,440
perhaps uneven usefulness so that's been

00:18:24,860 --> 00:18:28,520
an ongoing issue for us all right at

00:18:27,440 --> 00:18:40,190
this point dusty is going to talk about

00:18:28,520 --> 00:18:41,810
atomic host cool we'll see if I managed

00:18:40,190 --> 00:18:44,090
to stay away from the speaker

00:18:41,810 --> 00:18:45,860
interference okay so I'm here to talk a

00:18:44,090 --> 00:18:47,690
little bit about some of the atomic host

00:18:45,860 --> 00:18:50,510
design goals the structure what went

00:18:47,690 --> 00:18:53,030
well what didn't so let's dig right in

00:18:50,510 --> 00:18:54,860
so first of all I want to take a detour

00:18:53,030 --> 00:18:57,380
from design goals and talk a little bit

00:18:54,860 --> 00:18:59,630
about the update model so basically

00:18:57,380 --> 00:19:01,430
there's three steps with atomic Coast

00:18:59,630 --> 00:19:04,220
you download the update in the

00:19:01,430 --> 00:19:06,170
background you stage a new deployment

00:19:04,220 --> 00:19:08,150
for the next reboot and then you boot

00:19:06,170 --> 00:19:11,870
into the upgraded deployment so one two

00:19:08,150 --> 00:19:13,310
three pretty easy right so I'll talk

00:19:11,870 --> 00:19:14,990
about the design goals and we'll keep

00:19:13,310 --> 00:19:17,360
that update model in mind the whole time

00:19:14,990 --> 00:19:19,790
so essentially what we wanted to do with

00:19:17,360 --> 00:19:22,220
atomic host was create reliable fault

00:19:19,790 --> 00:19:24,740
tolerant updates we didn't want people

00:19:22,220 --> 00:19:27,470
to be scared of updates we wanted to

00:19:24,740 --> 00:19:29,150
create offline updates and I'll get into

00:19:27,470 --> 00:19:33,620
what that is here in just a minute and

00:19:29,150 --> 00:19:37,370
we wanted to focus on security but how

00:19:33,620 --> 00:19:40,010
do we do this so a way that we can do

00:19:37,370 --> 00:19:42,110
this is basically shrink the base of the

00:19:40,010 --> 00:19:44,360
operating system if you ship less you

00:19:42,110 --> 00:19:47,300
are responsible for less and you're less

00:19:44,360 --> 00:19:50,000
likely to have security issues with the

00:19:47,300 --> 00:19:51,350
software they deliver you know if we're

00:19:50,000 --> 00:19:53,240
shrinking the base how do we still

00:19:51,350 --> 00:19:54,680
deliver something that is useful to the

00:19:53,240 --> 00:19:56,990
users and the admins who are

00:19:54,680 --> 00:20:00,680
administering these systems at the time

00:19:56,990 --> 00:20:02,150
atomic host was created in 2014

00:20:00,680 --> 00:20:03,410
you know container technology was

00:20:02,150 --> 00:20:07,310
starting to come on so the answer

00:20:03,410 --> 00:20:09,890
leverage containers and then you know we

00:20:07,310 --> 00:20:11,630
needed to essentially develop an image

00:20:09,890 --> 00:20:13,260
based update system that was different

00:20:11,630 --> 00:20:17,520
than the model that we had been

00:20:13,260 --> 00:20:19,230
using in the past with yo more DNF so we

00:20:17,520 --> 00:20:21,450
need to revisit our design goals first

00:20:19,230 --> 00:20:23,460
we had a reliable updates offline

00:20:21,450 --> 00:20:25,500
updates and security but now with that

00:20:23,460 --> 00:20:28,320
last slide in consideration of the first

00:20:25,500 --> 00:20:29,760
three we add good container hosts so

00:20:28,320 --> 00:20:34,200
that is something that we want to do as

00:20:29,760 --> 00:20:36,180
well okay so the reliable updates if you

00:20:34,200 --> 00:20:38,700
consider the update model I mentioned

00:20:36,180 --> 00:20:41,700
earlier one download updates two-stage

00:20:38,700 --> 00:20:43,740
new deployment three reboot in this

00:20:41,700 --> 00:20:45,420
model there are two deployments so you

00:20:43,740 --> 00:20:47,250
essentially have your pre upgraded

00:20:45,420 --> 00:20:50,310
deployment and your upgraded deployment

00:20:47,250 --> 00:20:52,500
this means that if your new upgrade

00:20:50,310 --> 00:20:54,840
doesn't work for any reason you can

00:20:52,500 --> 00:20:56,520
easily roll back to the old one if it

00:20:54,840 --> 00:20:58,440
makes it all the way to user space and

00:20:56,520 --> 00:21:00,450
it doesn't work you can run our pmos

00:20:58,440 --> 00:21:02,820
tree roll back and do a reboot and

00:21:00,450 --> 00:21:05,820
you'll be back into the old one if for

00:21:02,820 --> 00:21:08,130
some reason it doesn't make it the user

00:21:05,820 --> 00:21:11,490
space say there was a kernel or in an it

00:21:08,130 --> 00:21:15,000
Rd issue or something just early on you

00:21:11,490 --> 00:21:17,790
can actually boot into the pre upgrade

00:21:15,000 --> 00:21:20,490
deployment and choose to keep that one

00:21:17,790 --> 00:21:22,050
forever as well so you know a little bit

00:21:20,490 --> 00:21:25,140
of fault tolerance here for people who

00:21:22,050 --> 00:21:26,610
are risk averse and you know want to be

00:21:25,140 --> 00:21:29,010
able to go back if something goes wrong

00:21:26,610 --> 00:21:32,190
this encourages people to not

00:21:29,010 --> 00:21:33,900
necessarily fear upgrades as much the

00:21:32,190 --> 00:21:34,620
offline updates which I said I'll verify

00:21:33,900 --> 00:21:36,570
earlier

00:21:34,620 --> 00:21:38,190
again we download updates in the

00:21:36,570 --> 00:21:41,760
background we staged a new deployment

00:21:38,190 --> 00:21:43,830
and then we reboot so this means that no

00:21:41,760 --> 00:21:48,150
software ever runs in a half upgraded

00:21:43,830 --> 00:21:52,440
state you know getting back to the first

00:21:48,150 --> 00:21:56,370
design goal reliable updates if you if

00:21:52,440 --> 00:21:58,350
you download and essentially perform an

00:21:56,370 --> 00:22:01,230
update like on a young or DNF system

00:21:58,350 --> 00:22:02,850
what you end up with is you know if you

00:22:01,230 --> 00:22:06,530
happen to have a failure in between

00:22:02,850 --> 00:22:09,240
somewhere maybe DNF has a sack trace or

00:22:06,530 --> 00:22:11,910
RPM as a sack trace or somehow you get

00:22:09,240 --> 00:22:14,940
in a half upgrade state you lose power

00:22:11,910 --> 00:22:17,070
or anything like that your system might

00:22:14,940 --> 00:22:19,950
be in a state that you can't recover out

00:22:17,070 --> 00:22:21,549
of and in this case for all flying

00:22:19,950 --> 00:22:24,970
updates

00:22:21,549 --> 00:22:26,350
you know software that is currently

00:22:24,970 --> 00:22:29,799
running on the system say you didn't

00:22:26,350 --> 00:22:32,799
stop services or whatnot can still be

00:22:29,799 --> 00:22:34,450
running old software after the update

00:22:32,799 --> 00:22:36,820
has completed so if you don't do a

00:22:34,450 --> 00:22:38,769
reboot after you run a DNF upgrade you

00:22:36,820 --> 00:22:40,720
then check your packages to see what

00:22:38,769 --> 00:22:42,340
software's vulnerable well guess what

00:22:40,720 --> 00:22:44,619
it's all updated but there might be some

00:22:42,340 --> 00:22:46,809
stuff in memory that's not so this model

00:22:44,619 --> 00:22:49,419
allows us to have fully offline updates

00:22:46,809 --> 00:22:52,269
you can actually leave your hosts online

00:22:49,419 --> 00:22:54,009
serving content you know performing

00:22:52,269 --> 00:22:55,929
their service fund the update the only

00:22:54,009 --> 00:22:58,509
time they go down is obviously when you

00:22:55,929 --> 00:23:01,179
reboot the third design goal was

00:22:58,509 --> 00:23:04,779
security so basically smaller base west

00:23:01,179 --> 00:23:07,600
risk there the image base update system

00:23:04,779 --> 00:23:09,759
also allows for users to verify what

00:23:07,600 --> 00:23:12,909
they have on their system matches what

00:23:09,759 --> 00:23:15,519
was built on the server so like you can

00:23:12,909 --> 00:23:19,269
basically cryptic cryptographically

00:23:15,519 --> 00:23:20,980
verify and it's also signed we also

00:23:19,269 --> 00:23:22,210
mount file systems read-only so if

00:23:20,980 --> 00:23:23,619
somebody does get on your system

00:23:22,210 --> 00:23:26,799
hopefully they're not able to actually

00:23:23,619 --> 00:23:29,320
modify the content of Nerys and then

00:23:26,799 --> 00:23:31,149
leveraging selinux you know means that

00:23:29,320 --> 00:23:32,980
if they do happen to get on the system

00:23:31,149 --> 00:23:35,950
hopefully they are confined and not able

00:23:32,980 --> 00:23:37,929
to touch things and then the last one

00:23:35,950 --> 00:23:39,850
good container hosts so we basically

00:23:37,929 --> 00:23:40,929
provide container runtimes for users to

00:23:39,850 --> 00:23:42,309
use so that they can run their

00:23:40,929 --> 00:23:46,210
applications because if you can't run

00:23:42,309 --> 00:23:47,679
your applications pretty much useless so

00:23:46,210 --> 00:23:50,169
we provide container runtimes and

00:23:47,679 --> 00:23:53,109
basically manage hosts updates ourselves

00:23:50,169 --> 00:23:56,440
so you are essentially trusting another

00:23:53,109 --> 00:23:58,179
team to do your updates for you or at

00:23:56,440 --> 00:24:01,389
least delivery you something that is

00:23:58,179 --> 00:24:03,999
reliable from an updates perspective and

00:24:01,389 --> 00:24:06,879
then you manage the applications that

00:24:03,999 --> 00:24:09,190
are on the system and the separation of

00:24:06,879 --> 00:24:11,590
concerns here basically atomic host team

00:24:09,190 --> 00:24:14,799
manages the hosts updates and the admins

00:24:11,590 --> 00:24:17,859
manage the application updates kind of

00:24:14,799 --> 00:24:18,609
helps the reliability okay the structure

00:24:17,859 --> 00:24:20,289
of atomic Coast

00:24:18,609 --> 00:24:23,710
I mentioned the image based update

00:24:20,289 --> 00:24:26,619
system so basically we created our pmos

00:24:23,710 --> 00:24:28,629
tree we it actually existed before

00:24:26,619 --> 00:24:31,210
atomic host but this was a quite a good

00:24:28,629 --> 00:24:32,120
use of it and our chemistry is really

00:24:31,210 --> 00:24:35,450
good at

00:24:32,120 --> 00:24:37,610
tracking it's a hybrid approach is not a

00:24:35,450 --> 00:24:39,440
disk image based system so it doesn't

00:24:37,610 --> 00:24:41,900
work at the block device level it works

00:24:39,440 --> 00:24:44,150
right above the filesystem level and

00:24:41,900 --> 00:24:46,640
it's smart content tracking it knows

00:24:44,150 --> 00:24:49,100
about rpms it knows about boot loaders

00:24:46,640 --> 00:24:51,110
it's able to manage all of that for you

00:24:49,100 --> 00:24:53,150
so when it does an update it basically

00:24:51,110 --> 00:24:55,430
gets the new content it'll update the

00:24:53,150 --> 00:24:57,830
boot loader and then once you reboot

00:24:55,430 --> 00:25:00,380
your into your OS the nice thing about

00:24:57,830 --> 00:25:03,560
this content tracking system is it is

00:25:00,380 --> 00:25:05,360
like git for your operating system five

00:25:03,560 --> 00:25:07,460
years ago if somebody would have told me

00:25:05,360 --> 00:25:09,140
it's like it for your operating system I

00:25:07,460 --> 00:25:10,610
would have been like yes that's exactly

00:25:09,140 --> 00:25:13,310
what I want

00:25:10,610 --> 00:25:16,130
I loved the conceptual model OS 3 repo

00:25:13,310 --> 00:25:19,940
or as OS tree server-side repo is like a

00:25:16,130 --> 00:25:22,250
get repo it is a remote to your client

00:25:19,940 --> 00:25:24,950
it has branches that you can follow it

00:25:22,250 --> 00:25:27,050
has checkout it has rebasing so that's

00:25:24,950 --> 00:25:28,790
really nice and the other thing is it

00:25:27,050 --> 00:25:30,650
shares common contents between different

00:25:28,790 --> 00:25:33,230
deployments so for example if there's a

00:25:30,650 --> 00:25:35,240
new update and only one hour PM changed

00:25:33,230 --> 00:25:37,130
and only 10 files change in the RPM

00:25:35,240 --> 00:25:39,650
you're only downloading those 10 files

00:25:37,130 --> 00:25:41,270
when you do an update and similarly on

00:25:39,650 --> 00:25:44,210
the local system you're only storing

00:25:41,270 --> 00:25:46,210
those 10 files in addition to what you

00:25:44,210 --> 00:25:48,470
already had on the system so that's nice

00:25:46,210 --> 00:25:52,400
the disk layout structure that we have

00:25:48,470 --> 00:25:54,680
is pretty generic basically you know it

00:25:52,400 --> 00:25:57,950
gives the user or the admin a lot of

00:25:54,680 --> 00:26:00,140
flexibility oh yeah you can have

00:25:57,950 --> 00:26:02,150
partition base we can have LVM base we

00:26:00,140 --> 00:26:05,210
can have butter FS based systems I think

00:26:02,150 --> 00:26:07,490
that works I haven't tried it lately and

00:26:05,210 --> 00:26:08,900
this is configured during install so

00:26:07,490 --> 00:26:10,400
like if you were to run a bare-metal

00:26:08,900 --> 00:26:12,560
install you could configure this

00:26:10,400 --> 00:26:15,410
obviously if you download a pre-baked

00:26:12,560 --> 00:26:17,840
image you will get a partition setup

00:26:15,410 --> 00:26:20,510
that is predefined for you in our mount

00:26:17,840 --> 00:26:23,660
points user is read-only VARs read/write

00:26:20,510 --> 00:26:25,250
there's some other ones for example top

00:26:23,660 --> 00:26:27,530
level directories like slash home and

00:26:25,250 --> 00:26:29,210
slash mail or redirected to var home and

00:26:27,530 --> 00:26:32,120
var mount and sim links are in place

00:26:29,210 --> 00:26:34,370
there and the state in slash Etsy is

00:26:32,120 --> 00:26:36,440
tracked and restored on rollback this

00:26:34,370 --> 00:26:38,930
basically makes rollbacks more reliable

00:26:36,440 --> 00:26:40,740
because updated configuration files for

00:26:38,930 --> 00:26:42,750
new software might not have worked

00:26:40,740 --> 00:26:47,100
the old software that existed on the

00:26:42,750 --> 00:26:48,779
system bootstrapping basically you heard

00:26:47,100 --> 00:26:52,770
Benjamin talk earlier about how they're

00:26:48,779 --> 00:26:54,750
using a shell script two installs we for

00:26:52,770 --> 00:26:57,390
bare metal use and install our ISO which

00:26:54,750 --> 00:26:58,890
has anaconda in it which is similar to

00:26:57,390 --> 00:27:01,500
what you might experience with the

00:26:58,890 --> 00:27:04,169
Fedora CentOS based system today and for

00:27:01,500 --> 00:27:06,059
cloud we use canonical cloud init which

00:27:04,169 --> 00:27:07,649
is baked into the OS tree so you provide

00:27:06,059 --> 00:27:09,450
your user data for that and it spins out

00:27:07,649 --> 00:27:11,010
the system obviously there are problems

00:27:09,450 --> 00:27:12,539
without that Benjamin mentioned earlier

00:27:11,010 --> 00:27:15,690
because it runs during boot rather than

00:27:12,539 --> 00:27:19,590
kind of before the system has switched

00:27:15,690 --> 00:27:21,960
into the new root host accessibility so

00:27:19,590 --> 00:27:24,360
you heard Benjamin talk about torx our

00:27:21,960 --> 00:27:28,110
answer to that was twofold

00:27:24,360 --> 00:27:29,840
one was package layering so basically

00:27:28,110 --> 00:27:33,000
what you can do is take an RPM and

00:27:29,840 --> 00:27:35,130
mutate be a mutable post but in a

00:27:33,000 --> 00:27:37,049
controlled way so you can add that rpm

00:27:35,130 --> 00:27:38,730
as a layer on top of what you already

00:27:37,049 --> 00:27:42,090
have what was delivered to you by the

00:27:38,730 --> 00:27:43,860
atomic host team so that's one option

00:27:42,090 --> 00:27:46,169
the other option is running system

00:27:43,860 --> 00:27:48,750
containers be atomic CLI what is the

00:27:46,169 --> 00:27:50,429
system container it's basically like a

00:27:48,750 --> 00:27:52,380
no CI image just how you would have

00:27:50,429 --> 00:27:55,350
built one using docker build or pod man

00:27:52,380 --> 00:27:57,450
build but atomic CLI helps you grab that

00:27:55,350 --> 00:28:00,960
set up a system to unit so it'll run on

00:27:57,450 --> 00:28:03,299
every boot and then also you know it has

00:28:00,960 --> 00:28:06,179
hooks for making them super privileged

00:28:03,299 --> 00:28:08,100
so that you know it can do the low-level

00:28:06,179 --> 00:28:10,260
things it needs to do to the host is

00:28:08,100 --> 00:28:12,870
this a good idea I don't know probably

00:28:10,260 --> 00:28:15,510
not it's to undefined what all those

00:28:12,870 --> 00:28:18,299
things can do unfortunately and it makes

00:28:15,510 --> 00:28:20,760
it harder to update reliably so what

00:28:18,299 --> 00:28:22,649
worked well I think using the Fedora

00:28:20,760 --> 00:28:25,289
slash rpm ecosystem has worked really

00:28:22,649 --> 00:28:28,830
well for the atomic host project because

00:28:25,289 --> 00:28:30,510
essentially we get to reuse all the hard

00:28:28,830 --> 00:28:32,610
work that's done in fedora and also

00:28:30,510 --> 00:28:34,770
contribute back so if they're bug in the

00:28:32,610 --> 00:28:37,200
kernel and atomic host it's the same bug

00:28:34,770 --> 00:28:39,360
that's in the kernel in Fedora so if we

00:28:37,200 --> 00:28:41,250
find a bug we we get it fixed it helps

00:28:39,360 --> 00:28:43,590
everybody if somebody else find them

00:28:41,250 --> 00:28:46,380
finds a bug and put our work station or

00:28:43,590 --> 00:28:48,570
whatnot and gets it fixed it helps us so

00:28:46,380 --> 00:28:50,130
that's really nice package layering has

00:28:48,570 --> 00:28:52,769
worked really nice obviously container

00:28:50,130 --> 00:28:56,249
izing low-level system tools is hard

00:28:52,769 --> 00:28:58,980
and this that helps us get around these

00:28:56,249 --> 00:29:01,049
issues because you know somebody has to

00:28:58,980 --> 00:29:02,879
really want to containerize a low-level

00:29:01,049 --> 00:29:05,220
system application in order to do it

00:29:02,879 --> 00:29:08,129
right and we haven't hit a lot of cases

00:29:05,220 --> 00:29:10,499
where people are jumping in the water

00:29:08,129 --> 00:29:12,990
and ready to do that and the get for

00:29:10,499 --> 00:29:14,940
your OS conceptual model is really nice

00:29:12,990 --> 00:29:17,850
for new people who want to understand

00:29:14,940 --> 00:29:20,159
what OS tree does and what RPM OS tree

00:29:17,850 --> 00:29:21,840
does so the other thing that's really

00:29:20,159 --> 00:29:24,240
good is representing system state in a

00:29:21,840 --> 00:29:26,369
clear way so this is an example of

00:29:24,240 --> 00:29:28,379
running our pmos tree status on a system

00:29:26,369 --> 00:29:33,990
and you can clearly see there's a

00:29:28,379 --> 00:29:36,149
version here that people can use to talk

00:29:33,990 --> 00:29:37,980
to other people talk to us when they

00:29:36,149 --> 00:29:39,929
report bugs and say hey I'm having this

00:29:37,980 --> 00:29:43,200
bug is anybody else seeing this I'm on

00:29:39,929 --> 00:29:46,379
version XYZ and I tell them no I'm on

00:29:43,200 --> 00:29:48,600
version ABC and I'm not seeing it can

00:29:46,379 --> 00:29:50,519
you try ABC or I'll either rebase my

00:29:48,600 --> 00:29:52,769
system to XYZ and see if I see the

00:29:50,519 --> 00:29:54,690
problem so that's really powerful the

00:29:52,769 --> 00:29:56,940
other thing is that really it represents

00:29:54,690 --> 00:29:59,369
any mutations to the system so layered

00:29:56,940 --> 00:30:01,440
packages I've listed out there I've got

00:29:59,369 --> 00:30:03,629
a few layered packages on that system so

00:30:01,440 --> 00:30:05,909
it clearly lists here's what it is what

00:30:03,629 --> 00:30:08,429
a user's done to this system maybe you

00:30:05,909 --> 00:30:11,039
can replicate the state so what didn't

00:30:08,429 --> 00:30:13,139
work well I sent this email to atomic

00:30:11,039 --> 00:30:15,179
devel I forget I think it was like eight

00:30:13,139 --> 00:30:16,740
months ago or so there were four big

00:30:15,179 --> 00:30:19,769
issues that were kind of plaguing our

00:30:16,740 --> 00:30:22,919
our eco some I mean people would just

00:30:19,769 --> 00:30:25,740
hit these periodically and one of them

00:30:22,919 --> 00:30:28,710
is lost content and Etsy problem so I

00:30:25,740 --> 00:30:31,619
mentioned earlier Etsy's tracked the way

00:30:28,710 --> 00:30:35,039
it works is a user will run our pmos

00:30:31,619 --> 00:30:37,919
tree upgrade and then as part of that a

00:30:35,039 --> 00:30:40,049
new deployment is created and a new Etsy

00:30:37,919 --> 00:30:42,179
is made as part of that it basically

00:30:40,049 --> 00:30:45,570
takes the current Etsy on the system and

00:30:42,179 --> 00:30:47,909
the Etsy from the new commits and merges

00:30:45,570 --> 00:30:50,340
them together and creates a new Etsy for

00:30:47,909 --> 00:30:52,080
the new deployment the problem is if you

00:30:50,340 --> 00:30:54,360
run our pmos tree upgrade and then wait

00:30:52,080 --> 00:30:55,919
three days to reboot if you made any

00:30:54,360 --> 00:30:57,960
changes to Etsy on the running system

00:30:55,919 --> 00:31:00,029
before you reboot those will be lost

00:30:57,960 --> 00:31:01,409
because the Etsy merge was done you know

00:31:00,029 --> 00:31:03,929
at the time you've ran our pmos tree

00:31:01,409 --> 00:31:05,080
upgrade that's now fixed we started

00:31:03,929 --> 00:31:07,749
doing the Etsy

00:31:05,080 --> 00:31:11,139
urghhh right as you do the reboot rather

00:31:07,749 --> 00:31:12,940
than before so that's been fixed

00:31:11,139 --> 00:31:16,059
another problem can't package later some

00:31:12,940 --> 00:31:19,480
rpms if rpms right to directories that

00:31:16,059 --> 00:31:21,909
are read right on the system so for

00:31:19,480 --> 00:31:24,940
example user local is read right because

00:31:21,909 --> 00:31:26,409
you know people put stuff there /opt is

00:31:24,940 --> 00:31:29,289
read right because people put stuff

00:31:26,409 --> 00:31:31,899
there are pmos tree does not allow

00:31:29,289 --> 00:31:34,360
somebody to an install an RPM that puts

00:31:31,899 --> 00:31:38,049
contents there because we don't want to

00:31:34,360 --> 00:31:39,340
control directories that read right we

00:31:38,049 --> 00:31:41,379
want to control ones that read only

00:31:39,340 --> 00:31:43,350
essentially and then third-party kernel

00:31:41,379 --> 00:31:47,019
modules mention Benjamin mentioned this

00:31:43,350 --> 00:31:48,639
DKMS ake a mods don't work this has been

00:31:47,019 --> 00:31:50,830
a problem for a while we haven't really

00:31:48,639 --> 00:31:52,629
got a good solution to it his gist

00:31:50,830 --> 00:31:55,899
answers probably about as good as we got

00:31:52,629 --> 00:31:57,820
to we did have a user that actually

00:31:55,899 --> 00:32:01,809
created like a subsystem for doing this

00:31:57,820 --> 00:32:06,220
for wire guard but that's about as far

00:32:01,809 --> 00:32:08,679
as we've gotten the bad the update

00:32:06,220 --> 00:32:11,080
philosophy obviously our update

00:32:08,679 --> 00:32:14,169
philosophy from gaming was more of a you

00:32:11,080 --> 00:32:16,119
update it on your time frame type of

00:32:14,169 --> 00:32:17,950
scenario rather than the automated

00:32:16,119 --> 00:32:19,869
update policy that Benjamin mentioned I

00:32:17,950 --> 00:32:21,539
think it would have been better to go

00:32:19,869 --> 00:32:23,980
the other way because obviously people

00:32:21,539 --> 00:32:28,090
aren't as proactive about their updates

00:32:23,980 --> 00:32:30,279
so this essentially makes you know

00:32:28,090 --> 00:32:32,169
upgrades less reliable because if you're

00:32:30,279 --> 00:32:35,950
upgrading from something a year old on

00:32:32,169 --> 00:32:38,409
that's a lot it's a lot more likely to

00:32:35,950 --> 00:32:41,169
have issues than if you're upgrading to

00:32:38,409 --> 00:32:44,230
from n minus 1 to n which is probably

00:32:41,169 --> 00:32:45,789
something that we tested and package

00:32:44,230 --> 00:32:48,429
layering also makes upgrades less

00:32:45,789 --> 00:32:51,159
reliable because you know we can test

00:32:48,429 --> 00:32:53,289
the base upgrade to another base upgrade

00:32:51,159 --> 00:32:55,239
and we can even test base upgrades with

00:32:53,289 --> 00:32:58,090
layered packages but we probably didn't

00:32:55,239 --> 00:33:01,359
test your set of layered packages with

00:32:58,090 --> 00:33:03,369
our upgrades so it's just a combination

00:33:01,359 --> 00:33:05,019
you know we have a big matrix there if

00:33:03,369 --> 00:33:08,049
we start adding a lot of layered

00:33:05,019 --> 00:33:10,149
packages and I'll hand it back over to

00:33:08,049 --> 00:33:12,539
Benjamin for Fedora core OS do you want

00:33:10,149 --> 00:33:12,539
this or

00:33:16,160 --> 00:33:20,700
all right so first of all what are we

00:33:18,360 --> 00:33:21,810
trying to build I mentioned before that

00:33:20,700 --> 00:33:24,200
we're essentially trying to take the

00:33:21,810 --> 00:33:26,970
best of container Linux an atomic host

00:33:24,200 --> 00:33:31,140
this is the language we have now I won't

00:33:26,970 --> 00:33:32,820
read it out it looks a lot like the

00:33:31,140 --> 00:33:34,740
container Linux usage model as it exists

00:33:32,820 --> 00:33:39,360
now it's for running containers in

00:33:34,740 --> 00:33:44,160
production minimal system monolithic

00:33:39,360 --> 00:33:45,960
image we have some use cases defined I

00:33:44,160 --> 00:33:47,400
haven't there's there's some stuff down

00:33:45,960 --> 00:33:50,100
below that I haven't included on the

00:33:47,400 --> 00:33:52,760
slide but essentially the primary use

00:33:50,100 --> 00:33:55,860
cases are either a single server

00:33:52,760 --> 00:33:58,920
essentially node for running docker or

00:33:55,860 --> 00:34:02,730
pod man or whatever or a clustered node

00:33:58,920 --> 00:34:05,130
for Cooper nazar or okay date and then

00:34:02,730 --> 00:34:09,570
secondarily cluster nodes for running

00:34:05,130 --> 00:34:11,310
other container orchestrators okay so

00:34:09,570 --> 00:34:15,330
platforms we're targeting the same

00:34:11,310 --> 00:34:18,810
Cloudant c and so on that container

00:34:15,330 --> 00:34:20,130
Linux targets install process we're

00:34:18,810 --> 00:34:22,380
currently thinking will be something

00:34:20,130 --> 00:34:25,050
like chorus install probably not the

00:34:22,380 --> 00:34:27,930
same shell script but essentially

00:34:25,050 --> 00:34:30,450
download a monolithic image and write to

00:34:27,930 --> 00:34:33,900
disk provisioning will be about by

00:34:30,450 --> 00:34:36,330
ignition the partition layout is still

00:34:33,900 --> 00:34:37,950
up in the air a little bit the

00:34:36,330 --> 00:34:39,990
straightforward thing to do would be a

00:34:37,950 --> 00:34:43,590
single partition for both user data and

00:34:39,990 --> 00:34:47,340
operating system code but it seems like

00:34:43,590 --> 00:34:49,440
it'd be nice to separate those out first

00:34:47,340 --> 00:34:51,810
so that you could format the user data

00:34:49,440 --> 00:34:53,520
partition using ignition on first boot

00:34:51,810 --> 00:34:55,770
and also just to keep a little bit more

00:34:53,520 --> 00:34:58,770
isolation in terms of disk space users

00:34:55,770 --> 00:35:00,240
and so on automatic updates we are

00:34:58,770 --> 00:35:03,380
throwing away all over the container

00:35:00,240 --> 00:35:06,660
Linux update code server protocol client

00:35:03,380 --> 00:35:09,720
on the client side there will be rpm OS

00:35:06,660 --> 00:35:12,240
tree installing primarily rpms from

00:35:09,720 --> 00:35:13,890
fedora we will have rate limited

00:35:12,240 --> 00:35:16,680
rollouts the same way we do on container

00:35:13,890 --> 00:35:20,010
Linux that code does not exist yet

00:35:16,680 --> 00:35:24,089
there is some work going into network

00:35:20,010 --> 00:35:26,490
wire protocol for that and will have to

00:35:24,089 --> 00:35:28,200
write new server code because we're

00:35:26,490 --> 00:35:31,789
supplying automatic updates the same

00:35:28,200 --> 00:35:34,109
model applies we cannot break users any

00:35:31,789 --> 00:35:36,569
backward competitive breaks in the OS

00:35:34,109 --> 00:35:39,450
will need to be announced with a

00:35:36,569 --> 00:35:40,799
deprecation window far in advance and

00:35:39,450 --> 00:35:43,680
we're going to work on the automatic

00:35:40,799 --> 00:35:47,400
rollback story as well that there will

00:35:43,680 --> 00:35:49,230
be user provide health checks and

00:35:47,400 --> 00:35:54,809
hopefully more comprehensive automatic

00:35:49,230 --> 00:35:57,089
reboot eight streams this will probably

00:35:54,809 --> 00:35:59,130
not be the container linux alpha beta

00:35:57,089 --> 00:36:01,500
stable model we want to do something a

00:35:59,130 --> 00:36:03,990
little bit like that so there will be a

00:36:01,500 --> 00:36:08,170
stable stream and there will be at least

00:36:03,990 --> 00:36:09,559
one pre stable stream details still TBD

00:36:08,170 --> 00:36:11,730
[Music]

00:36:09,559 --> 00:36:13,140
there's the reason that's important is

00:36:11,730 --> 00:36:16,049
that the testing model will be similar

00:36:13,140 --> 00:36:19,289
as well there will be CI but it'll also

00:36:16,049 --> 00:36:21,059
be important that users run some nodes

00:36:19,289 --> 00:36:26,130
on the pre stable stream in order to

00:36:21,059 --> 00:36:28,559
catch any regressions metrics turned out

00:36:26,130 --> 00:36:30,390
to be important the metrics that we have

00:36:28,559 --> 00:36:30,960
on container linux are better than

00:36:30,390 --> 00:36:33,750
nothing

00:36:30,960 --> 00:36:35,520
they have gaps there's additional pieces

00:36:33,750 --> 00:36:37,140
of data that we would like and without

00:36:35,520 --> 00:36:39,119
those it's been really difficult to

00:36:37,140 --> 00:36:41,789
figure out how to spend our time it is

00:36:39,119 --> 00:36:44,670
some corner case actually worth spending

00:36:41,789 --> 00:36:48,359
a bunch of development effort on are we

00:36:44,670 --> 00:36:52,109
prioritizing the correct platforms so

00:36:48,359 --> 00:36:54,299
having some sort of metric gathering is

00:36:52,109 --> 00:36:56,190
useful there will of course be privacy

00:36:54,299 --> 00:36:58,020
knobs so that you can turn that off if

00:36:56,190 --> 00:37:01,500
you really don't want to give us that

00:36:58,020 --> 00:37:02,910
information but hopefully we'll be able

00:37:01,500 --> 00:37:04,859
to do this in a way that's not tied to

00:37:02,910 --> 00:37:06,510
the update model so that we can get

00:37:04,859 --> 00:37:09,630
metrics independently of whether you're

00:37:06,510 --> 00:37:12,450
obtaining updates container

00:37:09,630 --> 00:37:12,900
infrastructure the docker problem is not

00:37:12,450 --> 00:37:15,690
going away

00:37:12,900 --> 00:37:18,390
there's still a need to be able to run

00:37:15,690 --> 00:37:21,359
usually the docker or the one that

00:37:18,390 --> 00:37:24,329
kubernetes requires we will be shipping

00:37:21,359 --> 00:37:26,470
pod in and at the moment it looks as

00:37:24,329 --> 00:37:29,349
though we will not be shipping

00:37:26,470 --> 00:37:31,569
rocket is not the direction that the

00:37:29,349 --> 00:37:35,730
container ecosystem has gone and we

00:37:31,569 --> 00:37:35,730
think it's a good time to start

00:37:36,670 --> 00:37:42,400
in addition farther up the stack we're

00:37:40,150 --> 00:37:49,119
currently looking at shipping Goulet and

00:37:42,400 --> 00:37:50,140
cryo in the OS image so that's one less

00:37:49,119 --> 00:37:52,059
thing that you have to provide

00:37:50,140 --> 00:37:53,650
separately but the problem is that both

00:37:52,059 --> 00:37:54,759
those piece of software care about the

00:37:53,650 --> 00:37:58,539
version of kubernetes running in your

00:37:54,759 --> 00:38:00,250
cluster and so in that case we're going

00:37:58,539 --> 00:38:01,900
to have the same sort of issue is with

00:38:00,250 --> 00:38:04,930
docker we need to figure out a way to

00:38:01,900 --> 00:38:08,799
give you the version of those components

00:38:04,930 --> 00:38:11,230
that you need in a given time how to do

00:38:08,799 --> 00:38:12,910
that is still an open question but

00:38:11,230 --> 00:38:14,170
probably it'll have something to do with

00:38:12,910 --> 00:38:16,380
with package overlays because that

00:38:14,170 --> 00:38:19,680
mechanism exists and it works well

00:38:16,380 --> 00:38:21,940
they're also useful for debugging so

00:38:19,680 --> 00:38:23,650
container linux is a little bit weak in

00:38:21,940 --> 00:38:26,769
this area if you need debugging tools

00:38:23,650 --> 00:38:28,420
that aren't on the machine you have to

00:38:26,769 --> 00:38:31,180
bring them in there a couple of

00:38:28,420 --> 00:38:33,519
different ways to do that so we want

00:38:31,180 --> 00:38:35,410
package overlays around but we're

00:38:33,519 --> 00:38:36,970
probably going to try discouraging them

00:38:35,410 --> 00:38:39,640
being used any more widely than

00:38:36,970 --> 00:38:42,839
necessary the exact new ones there has

00:38:39,640 --> 00:38:45,849
yet to be worked out but as dusty said

00:38:42,839 --> 00:38:48,599
overuse of package overlays complicates

00:38:45,849 --> 00:38:48,599
the update story

00:38:48,920 --> 00:38:54,440
a couple quick things armed 64 support I

00:38:52,340 --> 00:38:57,650
mentioned before bullet on much later is

00:38:54,440 --> 00:39:00,980
a bad idea we will try to ship it right

00:38:57,650 --> 00:39:02,780
off the bat we may need to cut it for

00:39:00,980 --> 00:39:06,410
the initial release if and becomes a

00:39:02,780 --> 00:39:08,180
factor contrariwise Python we will try

00:39:06,410 --> 00:39:13,520
not to but we may need to include it if

00:39:08,180 --> 00:39:15,290
time becomes a factor cloud agents the

00:39:13,520 --> 00:39:17,140
OEM partition has to go we're not doing

00:39:15,290 --> 00:39:20,180
that again

00:39:17,140 --> 00:39:23,360
so for starters we're going to ship all

00:39:20,180 --> 00:39:26,450
of the cloud agents inside the the base

00:39:23,360 --> 00:39:27,620
image effectively and then conditionally

00:39:26,450 --> 00:39:36,490
enable them based on what cloud you're

00:39:27,620 --> 00:39:36,490
running on burnt

00:39:41,920 --> 00:39:47,260
the install images will be slightly

00:39:44,320 --> 00:39:50,380
different because each image needs to

00:39:47,260 --> 00:39:52,270
know what cloud it's running on but

00:39:50,380 --> 00:39:53,920
probably that'll just be a few bytes and

00:39:52,270 --> 00:39:57,580
and otherwise the images will be

00:39:53,920 --> 00:39:59,830
identical in the long run the idea is

00:39:57,580 --> 00:40:02,140
not to ship all of the agents inside the

00:39:59,830 --> 00:40:04,150
OS but rather to not ship the agents

00:40:02,140 --> 00:40:05,980
where we can get away with that in some

00:40:04,150 --> 00:40:07,450
cases there's just a little bit of

00:40:05,980 --> 00:40:10,300
callback code or whatever it needs to be

00:40:07,450 --> 00:40:12,100
implemented to tell the cloud that the

00:40:10,300 --> 00:40:15,210
note is healthy when we can implement

00:40:12,100 --> 00:40:15,210
out ourselves and not

00:40:22,070 --> 00:40:29,940
so there are a couple other things that

00:40:24,930 --> 00:40:32,160
that a couple other things that are

00:40:29,940 --> 00:40:34,650
still up in the air that we know will

00:40:32,160 --> 00:40:36,030
need more thought I mentioned the

00:40:34,650 --> 00:40:38,670
cluster coordination issue before we

00:40:36,030 --> 00:40:40,200
were container Linux with locksmith

00:40:38,670 --> 00:40:44,130
wants to just reboot nodes out from

00:40:40,200 --> 00:40:45,420
under the cluster that's not okay and it

00:40:44,130 --> 00:40:50,600
would be nice to have some sort of

00:40:45,420 --> 00:40:53,240
unified model where code on the OS node

00:40:50,600 --> 00:40:56,100
interfaces with the cluster in order to

00:40:53,240 --> 00:40:58,140
in coordinate and then of course there

00:40:56,100 --> 00:41:00,810
are party kurtal modules that's still up

00:40:58,140 --> 00:41:03,240
in the air as well all right I think we

00:41:00,810 --> 00:41:05,660
have just a few minutes left if people

00:41:03,240 --> 00:41:05,660
have questions

00:41:09,420 --> 00:41:12,579
[Applause]

00:41:24,880 --> 00:41:27,979
[Music]

00:41:40,390 --> 00:41:45,590
yeah so the comment is you know some

00:41:44,120 --> 00:41:48,710
problems that we have where people want

00:41:45,590 --> 00:41:51,200
to use either atomic host or the future

00:41:48,710 --> 00:41:53,270
Fedora core OS for things that aren't

00:41:51,200 --> 00:41:55,730
necessarily primary use cases that we're

00:41:53,270 --> 00:41:57,500
targeting it would be nice if we made it

00:41:55,730 --> 00:42:01,070
really easy for people to create their

00:41:57,500 --> 00:42:02,420
own atomic hose for core OS system so

00:42:01,070 --> 00:42:04,550
that they could deliver their own and

00:42:02,420 --> 00:42:07,100
have a little more control over it a

00:42:04,550 --> 00:42:08,990
goal is you know that people are able to

00:42:07,100 --> 00:42:11,060
use the build tools and create their own

00:42:08,990 --> 00:42:12,500
systems that they can update so that

00:42:11,060 --> 00:42:15,830
would that would be yeah really nice

00:42:12,500 --> 00:42:17,810
also the infrastructure for updates will

00:42:15,830 --> 00:42:22,210
offline updates or third-party update

00:42:17,810 --> 00:42:22,210
servers so that side of the org as well

00:42:51,860 --> 00:42:57,860
so I'll do the first part so comment

00:42:55,160 --> 00:43:00,440
from Susa basically they're doing

00:42:57,860 --> 00:43:02,720
something similar in the Kubik project

00:43:00,440 --> 00:43:06,500
and they do recommend having a separate

00:43:02,720 --> 00:43:08,270
bar from root as part of that and then

00:43:06,500 --> 00:43:10,150
the question was have we looked at the

00:43:08,270 --> 00:43:11,510
kubernetes reboot daemon for for

00:43:10,150 --> 00:43:13,310
coordination

00:43:11,510 --> 00:43:14,840
I tend personally to work further down

00:43:13,310 --> 00:43:17,150
the stack and there have been a variety

00:43:14,840 --> 00:43:20,300
of reboot coordination things in the

00:43:17,150 --> 00:43:22,990
cabeza context that have been attempted

00:43:20,300 --> 00:43:26,440
I have not looked at that particular

00:43:22,990 --> 00:43:26,440
piece of software

00:43:37,420 --> 00:43:41,800
right so the comment was that that

00:43:39,520 --> 00:43:47,020
several of them require running in

00:43:41,800 --> 00:43:48,640
Cooper days cluster I think from the OS

00:43:47,020 --> 00:43:52,390
perspective the interesting piece is

00:43:48,640 --> 00:43:54,010
finding a way to provide some hook or

00:43:52,390 --> 00:43:56,850
library or something on the host that

00:43:54,010 --> 00:43:56,850
those things can interact with

00:44:01,840 --> 00:44:05,350
how do you do static IP network

00:44:03,400 --> 00:44:08,620
configuration without an installer it's

00:44:05,350 --> 00:44:11,350
relevant for bare metal and unbearable

00:44:08,620 --> 00:44:12,760
hopefully you think about this what to

00:44:11,350 --> 00:44:20,040
say you control the DHCP server but

00:44:12,760 --> 00:44:22,510
that's not the answer you wanted you can

00:44:20,040 --> 00:44:25,240
when you're installing the system either

00:44:22,510 --> 00:44:28,660
from pixie or from an ISO image or

00:44:25,240 --> 00:44:31,600
whatever you can modify the kernel

00:44:28,660 --> 00:44:33,850
command line and the grub config and on

00:44:31,600 --> 00:44:37,480
container Linux at least we support IP

00:44:33,850 --> 00:44:42,160
equals where you can pass stuff in for

00:44:37,480 --> 00:44:46,450
for the unit Rama fests for the real

00:44:42,160 --> 00:44:51,670
root filesystem ignition can write down

00:44:46,450 --> 00:44:53,590
a network D config so depends on exactly

00:44:51,670 --> 00:44:55,840
which piece you need to get working but

00:44:53,590 --> 00:44:59,010
there's a couple ways to do it

00:44:55,840 --> 00:44:59,010
[Music]

00:45:11,920 --> 00:45:16,930
the question was do we have in contract

00:45:14,230 --> 00:45:18,310
with container customers or folks like

00:45:16,930 --> 00:45:22,330
that that they need to run alpha and

00:45:18,310 --> 00:45:23,800
beta the the need to run alpha and beta

00:45:22,330 --> 00:45:25,930
has been sort of an ongoing issue

00:45:23,800 --> 00:45:28,480
because it's something we talked about

00:45:25,930 --> 00:45:31,960
in talks and things but we don't

00:45:28,480 --> 00:45:33,790
actually document it very well and so we

00:45:31,960 --> 00:45:36,010
have users showing up reporting stable

00:45:33,790 --> 00:45:36,850
regressions and that's the first time

00:45:36,010 --> 00:45:39,850
that they learned they probably

00:45:36,850 --> 00:45:47,470
should've been writing on beta the

00:45:39,850 --> 00:45:50,100
messaging there has been uneven any

00:45:47,470 --> 00:45:50,100
other questions

00:45:55,260 --> 00:46:01,150
so the question is what happens if

00:45:58,150 --> 00:46:03,850
there's a merge conflict in / Etsy

00:46:01,150 --> 00:46:05,950
directory that's probably a better

00:46:03,850 --> 00:46:07,869
question for Colin Walters or Jonathan

00:46:05,950 --> 00:46:10,570
Lebon because they know the technology

00:46:07,869 --> 00:46:15,220
better than I do but I have not hit that

00:46:10,570 --> 00:46:18,609
problem I think what they basically do

00:46:15,220 --> 00:46:21,210
today and it probably could be smarter

00:46:18,609 --> 00:46:24,760
but I think what they do today is if

00:46:21,210 --> 00:46:26,890
there is a file in the current Etsy

00:46:24,760 --> 00:46:30,940
that's on the system that has been

00:46:26,890 --> 00:46:33,670
modified then that overrides essentially

00:46:30,940 --> 00:46:37,630
what comes in in the new deployment or

00:46:33,670 --> 00:46:40,420
as part of the new update so if it's

00:46:37,630 --> 00:46:43,450
been modified it stays if it's the same

00:46:40,420 --> 00:46:45,460
like basically if it hasn't changed over

00:46:43,450 --> 00:46:48,580
that if you as the user has not touched

00:46:45,460 --> 00:46:51,760
it it will pull in the one from the new

00:46:48,580 --> 00:46:53,950
deployment and and use the new one so I

00:46:51,760 --> 00:46:56,380
think that's what happens in rpms today

00:46:53,950 --> 00:46:58,660
but the RPMs will basically drop down a

00:46:56,380 --> 00:47:01,780
dot rpm new file so you can essentially

00:46:58,660 --> 00:47:03,369
inspect the old one and the new one and

00:47:01,780 --> 00:47:08,130
I think that's what it does and in

00:47:03,369 --> 00:47:08,130
atomic Coast Josh

00:47:22,390 --> 00:47:26,859
the question was why are we in fedora

00:47:25,150 --> 00:47:28,089
coral s switching to it automatic

00:47:26,859 --> 00:47:31,200
updates which is the container Linux

00:47:28,089 --> 00:47:35,710
model rather than the atomic host people

00:47:31,200 --> 00:47:38,680
and the answer I guess comes down to we

00:47:35,710 --> 00:47:42,099
hope you want updates bug fixes security

00:47:38,680 --> 00:47:43,540
fixes the nodes should be essentially an

00:47:42,099 --> 00:47:44,770
appliance that you don't have to think

00:47:43,540 --> 00:47:46,030
about because you're thinking about the

00:47:44,770 --> 00:47:49,599
things running in containers on top of

00:47:46,030 --> 00:47:51,700
it and so if it becomes another thing to

00:47:49,599 --> 00:47:57,099
manage then then we're not achieving our

00:47:51,700 --> 00:48:00,400
goal right and to second that basically

00:47:57,099 --> 00:48:02,619
the idea here is that and and I know I'm

00:48:00,400 --> 00:48:04,450
gonna get dinged for using this analogy

00:48:02,619 --> 00:48:07,059
but I feel like people know it really

00:48:04,450 --> 00:48:10,780
well pets vs. cattle right we

00:48:07,059 --> 00:48:13,000
essentially want to support more the you

00:48:10,780 --> 00:48:16,180
know the spin up a node throw it away

00:48:13,000 --> 00:48:19,030
model rather than the spin up a node let

00:48:16,180 --> 00:48:22,270
me customize it you know exactly how I

00:48:19,030 --> 00:48:27,900
want it let me do create a snowflake and

00:48:22,270 --> 00:48:30,010
in the cattle model essentially

00:48:27,900 --> 00:48:32,950
automatic updates should be something

00:48:30,010 --> 00:48:35,319
that's welcomed because if for example

00:48:32,950 --> 00:48:36,940
something doesn't go right you can throw

00:48:35,319 --> 00:48:40,599
that wet note away and bring it back up

00:48:36,940 --> 00:48:42,339
I also feel like it has reached it's

00:48:40,599 --> 00:48:44,380
definitely resonated with a larger user

00:48:42,339 --> 00:48:46,900
base because there are more people using

00:48:44,380 --> 00:48:49,089
core OS container Linux than either

00:48:46,900 --> 00:48:52,869
relative echoes or Fedora atomic host

00:48:49,089 --> 00:48:55,809
today so obviously that spoke to someone

00:48:52,869 --> 00:48:59,040
and we we listen to that so I think it's

00:48:55,809 --> 00:48:59,040
the right way to go in the future

00:49:05,790 --> 00:49:09,089
take that again

00:49:21,820 --> 00:49:25,420
[Music]

00:49:22,900 --> 00:49:27,850
the question is how do we plan on

00:49:25,420 --> 00:49:32,170
dealing with rpm dependencies in Fedora

00:49:27,850 --> 00:49:35,950
core OS o how do we trim it down to make

00:49:32,170 --> 00:49:40,330
a smaller guy show us so pretty much

00:49:35,950 --> 00:49:42,670
right now we need to see what tools

00:49:40,330 --> 00:49:46,360
would be removed from the hosts

00:49:42,670 --> 00:49:48,850
if we remove Python and which of those

00:49:46,360 --> 00:49:52,690
tools are ones that we absolutely can't

00:49:48,850 --> 00:49:55,600
do without and then either try to work

00:49:52,690 --> 00:49:57,130
with those teams to somehow remove the

00:49:55,600 --> 00:49:58,470
Python dependency because some of the

00:49:57,130 --> 00:50:01,270
things that we've looked at are

00:49:58,470 --> 00:50:03,369
essentially packages that have one

00:50:01,270 --> 00:50:06,160
Python script in them that could

00:50:03,369 --> 00:50:07,810
probably be rewritten and then some of

00:50:06,160 --> 00:50:10,630
them are packages that are completely

00:50:07,810 --> 00:50:13,330
Python right so we'll just have to deal

00:50:10,630 --> 00:50:15,280
with those one one by one and see if we

00:50:13,330 --> 00:50:23,260
can if we can do this or not

00:50:15,280 --> 00:50:24,490
right so right yeah I guess a way to do

00:50:23,260 --> 00:50:26,380
that is either convince people to

00:50:24,490 --> 00:50:29,020
rewrite it or try to get them to put it

00:50:26,380 --> 00:50:32,260
in a sub package right the other option

00:50:29,020 --> 00:50:35,010
is when we create the OS tree we can

00:50:32,260 --> 00:50:39,970
theoretically remove particular things

00:50:35,010 --> 00:50:42,700
you know from the OS tree before we do

00:50:39,970 --> 00:50:45,180
the commit so that's an option too it's

00:50:42,700 --> 00:50:47,130
not as clean

00:50:45,180 --> 00:50:49,170
real quick let me try again on your

00:50:47,130 --> 00:50:52,470
static IP question if you're running

00:50:49,170 --> 00:50:53,970
chorus install from whatever medium it

00:50:52,470 --> 00:50:56,790
can the objective ignition config and

00:50:53,970 --> 00:51:00,510
the ignition config can have Network D

00:50:56,790 --> 00:51:04,470
on it in it real quick

00:51:00,510 --> 00:51:06,780
are we done at 320 or yes okay thing we

00:51:04,470 --> 00:51:08,220
might be out of time but thanks for

00:51:06,780 --> 00:51:10,280
thanks everybody for coming I appreciate

00:51:08,220 --> 00:51:13,859
it

00:51:10,280 --> 00:51:13,859

YouTube URL: https://www.youtube.com/watch?v=DjnMnFwamGo


