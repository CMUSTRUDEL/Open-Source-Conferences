Title: Towards a Lightweight Software Architecture for PX4 Computer Vision — PX4 Developer Summit Virtual
Publication date: 2020-07-19
Playlist: PX4 Developer Summit 2020 | Virtual
Description: 
	Title: Towards a Lightweight Software Architecture for PX4 Computer Vision

Summary: We present a powerful, yet lightweight, software architecture designed to run on an embedded companion computer alongside a PX4 flight controller. This architecture provides multi-modal computer vision functionality to PX4 such as Visual Obstacle Avoidance (VOA), an open-source Visual Inertial Odometry (VINS Fusion), Fiducial Marker Relocalization, and Object Tracking. We demonstrate the functionality of this architecture on a ModalAI PX4 development platform and present our roadmap for future development.


The PX4 Developer Summit is the annual flagship conference hosted by Dronecode for the drone development community. https://bit.ly/2YXe4Rd

PX4 Developer Summit Virtual 2020
Captions: 
	00:00:16,420 --> 00:00:22,340
hey everyone I'm back so next up we got

00:00:20,300 --> 00:00:25,580
towards the lightweight software

00:00:22,340 --> 00:00:27,920
architecture for px for computer vision

00:00:25,580 --> 00:00:30,170
it's a session by James strossen Jamis

00:00:27,920 --> 00:00:33,700
is a senior roboticist at Waddell a guy

00:00:30,170 --> 00:00:36,500
and he's calling in from San Diego today

00:00:33,700 --> 00:00:39,829
James received his PhD in robotics from

00:00:36,500 --> 00:00:42,289
UCSD where he also thought classes on 3d

00:00:39,829 --> 00:00:44,569
printing mechanical design feedback

00:00:42,289 --> 00:00:47,659
control and embedded systems Wow

00:00:44,569 --> 00:00:49,460
before me joining model AI James created

00:00:47,659 --> 00:00:51,679
the robotic clip and it'll meep

00:00:49,460 --> 00:00:53,449
development platforms as well as the

00:00:51,679 --> 00:00:56,179
leap controlled robot open-source

00:00:53,449 --> 00:00:59,359
software package for the Beagle borg

00:00:56,179 --> 00:01:01,190
foundation morally I James enjoys

00:00:59,359 --> 00:01:03,109
designing lightweight control and

00:01:01,190 --> 00:01:05,720
navigation algorithms for robots to run

00:01:03,109 --> 00:01:09,430
on embedded platforms all right guys

00:01:05,720 --> 00:01:09,430
let's give it up for James

00:01:11,690 --> 00:01:24,680
you can me now okay technical

00:01:13,400 --> 00:01:27,470
difficulties as to be expected okay some

00:01:24,680 --> 00:01:28,820
of the fundamental computer vision tasks

00:01:27,470 --> 00:01:31,610
that you're going to want to start

00:01:28,820 --> 00:01:34,640
experimenting with and plugging into the

00:01:31,610 --> 00:01:36,830
px4 ecosystem is going to be crucially

00:01:34,640 --> 00:01:39,590
visual inertial a dollar trip so that

00:01:36,830 --> 00:01:43,100
you can do very precise position

00:01:39,590 --> 00:01:47,600
feedback control as well as navigation

00:01:43,100 --> 00:01:50,060
in indoor environments the fiducial

00:01:47,600 --> 00:01:52,160
market real localization is the next

00:01:50,060 --> 00:01:55,040
step that's going to try and compensate

00:01:52,160 --> 00:01:57,380
for some of the shortcomings of a visual

00:01:55,040 --> 00:01:59,240
inertial odometry system which is

00:01:57,380 --> 00:02:01,100
knowing where you are relative to the

00:01:59,240 --> 00:02:06,170
world around you as opposed to just

00:02:01,100 --> 00:02:09,350
where you are when the battery system

00:02:06,170 --> 00:02:12,770
started up and then finally you may want

00:02:09,350 --> 00:02:14,470
to use one of px fours newest and nicest

00:02:12,770 --> 00:02:16,730
features which is collision prevention

00:02:14,470 --> 00:02:19,220
this is something that can easily be

00:02:16,730 --> 00:02:21,470
done with a stereo camera pair along

00:02:19,220 --> 00:02:23,630
with a host of other sensors but for

00:02:21,470 --> 00:02:25,340
this presentation we want to focus on

00:02:23,630 --> 00:02:27,620
computer vision and so I'm going to talk

00:02:25,340 --> 00:02:33,260
about how to use a stereo cameras for

00:02:27,620 --> 00:02:36,680
this now a big part of connecting higher

00:02:33,260 --> 00:02:39,830
level data such as odometry into px4 is

00:02:36,680 --> 00:02:41,900
just plumbing it's getting data from the

00:02:39,830 --> 00:02:45,440
right sensors to the right algorithms

00:02:41,900 --> 00:02:47,630
and then finally into px4 itself now

00:02:45,440 --> 00:02:49,850
there's a lot of examples online that

00:02:47,630 --> 00:02:53,390
you can find around based on Ross and

00:02:49,850 --> 00:02:55,910
math link parameter these are great

00:02:53,390 --> 00:02:58,280
methods to get you started because there

00:02:55,910 --> 00:03:01,760
are examples available however if you're

00:02:58,280 --> 00:03:04,760
comfortable with it just reading and

00:03:01,760 --> 00:03:06,980
writing UDP and you are packets that's

00:03:04,760 --> 00:03:09,380
something you can easily do yourself if

00:03:06,980 --> 00:03:12,440
you're comfortable with it the more

00:03:09,380 --> 00:03:14,840
complicated step is keeping track of all

00:03:12,440 --> 00:03:16,850
of the frames of reference that the data

00:03:14,840 --> 00:03:21,680
comes in and the frame of reference that

00:03:16,850 --> 00:03:25,069
px4 it expects data to be in so Ross and

00:03:21,680 --> 00:03:27,049
tf2 are very good tools for a

00:03:25,069 --> 00:03:29,090
in track of different frames of

00:03:27,049 --> 00:03:31,760
reference and moving data around between

00:03:29,090 --> 00:03:33,950
them or if you're comfortable I can show

00:03:31,760 --> 00:03:36,109
you how to do some of that math by hands

00:03:33,950 --> 00:03:39,019
so that you can more easily optimize it

00:03:36,109 --> 00:03:41,510
or fine-tune for your platform and then

00:03:39,019 --> 00:03:43,129
finally my colleagues going to talk

00:03:41,510 --> 00:03:45,650
about some of our experiences with an

00:03:43,129 --> 00:03:52,010
open source the i/o algorithm thinnest

00:03:45,650 --> 00:03:53,840
fusion so the fundamental basis for a

00:03:52,010 --> 00:03:57,409
lot of what I'm going to talk about all

00:03:53,840 --> 00:03:59,120
depends on visual and neural odometry so

00:03:57,409 --> 00:04:02,329
here you can see a drone flying with no

00:03:59,120 --> 00:04:05,060
magnetometer and no GPS this is purely

00:04:02,329 --> 00:04:07,430
based on visual inertial odometry and as

00:04:05,060 --> 00:04:10,400
you can see this allows for extremely

00:04:07,430 --> 00:04:13,250
good position control as well as the

00:04:10,400 --> 00:04:15,620
disturbance rejection as I push the

00:04:13,250 --> 00:04:19,250
drone around it's very stable and very

00:04:15,620 --> 00:04:21,940
easy to fly especially in very tight

00:04:19,250 --> 00:04:26,509
indoor environments with a lot of

00:04:21,940 --> 00:04:29,360
backwash off of walls and furniture so

00:04:26,509 --> 00:04:33,710
to get this to work you're going to be

00:04:29,360 --> 00:04:37,970
taking data out of your vio algorithm of

00:04:33,710 --> 00:04:40,250
choices dozens and dozens of Rosse

00:04:37,970 --> 00:04:42,560
options online that you can start

00:04:40,250 --> 00:04:46,099
playing with but whenever you choose

00:04:42,560 --> 00:04:49,070
that data has to be passed through to

00:04:46,099 --> 00:04:53,870
the px4 autopilot in the form of the

00:04:49,070 --> 00:04:56,389
manic packets and whether you use tf2 or

00:04:53,870 --> 00:04:58,460
other ross tools or math link router and

00:04:56,389 --> 00:05:02,710
you still have to make sure every step

00:04:58,460 --> 00:05:05,479
of the way that the data is correctly

00:05:02,710 --> 00:05:08,780
rotated and translated into the frame

00:05:05,479 --> 00:05:10,759
the px4 expects you have to choose the

00:05:08,780 --> 00:05:13,219
appropriate and a blank packet for what

00:05:10,759 --> 00:05:14,840
you're trying to do and you have to make

00:05:13,219 --> 00:05:17,419
sure that the data is time stamped

00:05:14,840 --> 00:05:19,820
correctly if you're using mayor ross

00:05:17,419 --> 00:05:21,830
then mayor ross is going to handle a lot

00:05:19,820 --> 00:05:23,419
of the time syncing for you otherwise

00:05:21,830 --> 00:05:25,280
you're going to have to make sure to do

00:05:23,419 --> 00:05:29,320
the time syncing between your onboard

00:05:25,280 --> 00:05:32,000
computer and the px4 autopilot yourself

00:05:29,320 --> 00:05:34,340
now your first option for mailing

00:05:32,000 --> 00:05:36,830
packets that you can send into px4 is

00:05:34,340 --> 00:05:39,350
the vision position estimate this is the

00:05:36,830 --> 00:05:41,900
first one that you'll see in the px4

00:05:39,350 --> 00:05:43,940
a dormitory documentation page and it's

00:05:41,900 --> 00:05:47,000
extremely simple you're just sending in

00:05:43,940 --> 00:05:51,800
the drones position relative to the

00:05:47,000 --> 00:05:53,630
local frame in x y&z in meters this is

00:05:51,800 --> 00:05:56,660
going to be like the knit coordinate

00:05:53,630 --> 00:05:58,490
frame northeast and down or since this

00:05:56,660 --> 00:06:00,830
isn't necessarily lined up with north

00:05:58,490 --> 00:06:03,500
it's more appropriate to call the local

00:06:00,830 --> 00:06:05,990
frame aligned with forward right and

00:06:03,500 --> 00:06:08,510
down as the odometry system is when it

00:06:05,990 --> 00:06:12,200
boots up you can also send in the wrong

00:06:08,510 --> 00:06:13,820
pitch and your angles of the padrone now

00:06:12,200 --> 00:06:17,210
if you want to be a little bit more

00:06:13,820 --> 00:06:20,750
fancy you can give the EKF to common

00:06:17,210 --> 00:06:23,360
filter inside px for more information to

00:06:20,750 --> 00:06:27,440
work with and therefore give you much

00:06:23,360 --> 00:06:29,930
better precision control and accuracy by

00:06:27,440 --> 00:06:34,730
also sending in the first derivatives of

00:06:29,930 --> 00:06:37,520
the first packets the velocities in x

00:06:34,730 --> 00:06:40,520
y&z as well as the roll speed pitch

00:06:37,520 --> 00:06:42,080
speed and your speeds now something very

00:06:40,520 --> 00:06:44,990
critical to know when you're sending

00:06:42,080 --> 00:06:48,050
this data in is that the frame of

00:06:44,990 --> 00:06:50,990
reference for the first derivatives are

00:06:48,050 --> 00:06:54,590
going to be in body frame not in local

00:06:50,990 --> 00:06:57,470
frame so while we say that the x y&z

00:06:54,590 --> 00:07:00,080
position of the drone is the position of

00:06:57,470 --> 00:07:02,600
the body in local frame relative to

00:07:00,080 --> 00:07:05,750
where it started up the velocity is

00:07:02,600 --> 00:07:08,120
actually going to be the velocity of the

00:07:05,750 --> 00:07:09,800
body of the drone relative to where the

00:07:08,120 --> 00:07:13,150
drone is pointing them so a positive

00:07:09,800 --> 00:07:16,100
velocity in X is always going to be

00:07:13,150 --> 00:07:18,350
forward along the direction of the

00:07:16,100 --> 00:07:22,130
drones know so wherever the German is

00:07:18,350 --> 00:07:28,070
pointing not the velocity along the

00:07:22,130 --> 00:07:31,160
local X access you can be very explicit

00:07:28,070 --> 00:07:33,320
with the frame IDs so here I've used the

00:07:31,160 --> 00:07:36,140
example of the child frame I D being

00:07:33,320 --> 00:07:37,670
body frame and the primary frame itíd

00:07:36,140 --> 00:07:41,360
being local frame and this is most

00:07:37,670 --> 00:07:43,700
likely what we're going to use now once

00:07:41,360 --> 00:07:46,550
that data is going into px wall I think

00:07:43,700 --> 00:07:50,450
you'll find the experience is very good

00:07:46,550 --> 00:07:51,009
as long as you understand this plot and

00:07:50,450 --> 00:07:53,589
understand

00:07:51,009 --> 00:07:57,699
exactly what it means to be sending data

00:07:53,589 --> 00:07:59,949
in body frame and local frame so each of

00:07:57,699 --> 00:08:02,080
the green boxes here is a frame of

00:07:59,949 --> 00:08:06,279
reference it's defining a coordinate

00:08:02,080 --> 00:08:09,369
system so for example the body this

00:08:06,279 --> 00:08:12,099
coordinate system is aligned with Ford

00:08:09,369 --> 00:08:14,889
out the nose of the drone right and then

00:08:12,099 --> 00:08:18,699
down this is also centered around the

00:08:14,889 --> 00:08:23,740
center of mass there is an option in the

00:08:18,699 --> 00:08:26,349
EKF two parameters of px4 to define the

00:08:23,740 --> 00:08:29,949
center of your visual odometry data as

00:08:26,349 --> 00:08:33,099
offset from the center of mass however

00:08:29,949 --> 00:08:34,599
if you understand all of these frames of

00:08:33,099 --> 00:08:37,630
reference and you're going to be doing

00:08:34,599 --> 00:08:40,269
rotations and translations in your vio

00:08:37,630 --> 00:08:42,819
algorithm anyway I think it's definitely

00:08:40,269 --> 00:08:45,519
worth going the extra step and making

00:08:42,819 --> 00:08:47,019
sure that the data is going in correctly

00:08:45,519 --> 00:08:50,880
in the first place then you don't have

00:08:47,019 --> 00:08:53,949
to worry about tweaking px4 parameters

00:08:50,880 --> 00:08:55,720
now each of the blue boxes is going to

00:08:53,949 --> 00:08:58,319
be a transform so that's going to

00:08:55,720 --> 00:09:01,600
consist of a rotation and a translation

00:08:58,319 --> 00:09:04,899
translation is a simple one by three

00:09:01,600 --> 00:09:07,720
vector x y&z whereas the rotation can be

00:09:04,899 --> 00:09:11,350
represented as either auto naeun roll

00:09:07,720 --> 00:09:13,180
pitch yaw or rotation matrix for

00:09:11,350 --> 00:09:15,639
simplicity of the math I highly

00:09:13,180 --> 00:09:18,579
recommend just using rotation matrices

00:09:15,639 --> 00:09:20,500
however tf2 if you elect to go that

00:09:18,579 --> 00:09:23,050
route will handle all of that in the

00:09:20,500 --> 00:09:24,790
background for you so the data that

00:09:23,050 --> 00:09:27,430
you're really going to get out of the

00:09:24,790 --> 00:09:29,440
vio algorithm is not this body with

00:09:27,430 --> 00:09:32,380
respect to local transform it's actually

00:09:29,440 --> 00:09:36,279
going to be I am u with respect to the

00:09:32,380 --> 00:09:38,319
vio frame so the vast majority of the

00:09:36,279 --> 00:09:41,920
i/o algorithms are going to represent

00:09:38,319 --> 00:09:44,920
the position of the IMU relative to

00:09:41,920 --> 00:09:47,380
wherever the IMU was when it booted up

00:09:44,920 --> 00:09:49,540
now the Ainu you use for visual inertial

00:09:47,380 --> 00:09:52,029
odometry is not necessarily young to be

00:09:49,540 --> 00:09:54,940
aligned up with the aeronautics

00:09:52,029 --> 00:09:57,399
coordinate frame forward right and down

00:09:54,940 --> 00:09:59,980
nor is it necessarily going to be

00:09:57,399 --> 00:10:02,589
aligned with gravity and so I highly

00:09:59,980 --> 00:10:04,230
recommend doing the next step of having

00:10:02,589 --> 00:10:07,440
another rotation

00:10:04,230 --> 00:10:11,510
to go from the iOS frame of reference to

00:10:07,440 --> 00:10:13,350
a gravity aligned equivalent so this

00:10:11,510 --> 00:10:15,450
rotation between vio

00:10:13,350 --> 00:10:18,140
and vio gravity aligns will have no

00:10:15,450 --> 00:10:20,820
translation it will simply have a

00:10:18,140 --> 00:10:23,610
rotation to correct for the angle of the

00:10:20,820 --> 00:10:26,940
gravity vector inside of the eye nose

00:10:23,610 --> 00:10:29,460
frame you will then also have to rotate

00:10:26,940 --> 00:10:33,420
to local frame which is most likely

00:10:29,460 --> 00:10:35,970
going to be the opposite of IMU with

00:10:33,420 --> 00:10:38,220
respect to body so you'll have to undo

00:10:35,970 --> 00:10:40,680
this twice you'll have to go from IMU to

00:10:38,220 --> 00:10:42,990
body and then the I owe it to local and

00:10:40,680 --> 00:10:47,190
then this is an optional step to go

00:10:42,990 --> 00:10:48,750
between vio and vio gravity aligned now

00:10:47,190 --> 00:10:50,070
once all of those are in place you can

00:10:48,750 --> 00:10:52,560
start doing something a bit more

00:10:50,070 --> 00:10:55,380
advanced so here we have the drone has

00:10:52,560 --> 00:10:58,740
started with the vio frame purposefully

00:10:55,380 --> 00:11:02,100
offset and crooked from its landing pad

00:10:58,740 --> 00:11:03,720
and I have a small Rev Mavros base node

00:11:02,100 --> 00:11:05,550
running which has just taught the drone

00:11:03,720 --> 00:11:09,330
to go forward and back a couple of

00:11:05,550 --> 00:11:12,270
meters along the line of wherever it

00:11:09,330 --> 00:11:15,150
exits the x axis theta this which in

00:11:12,270 --> 00:11:17,700
this case is off crooked now as it

00:11:15,150 --> 00:11:20,790
reappears landing pad the camera

00:11:17,700 --> 00:11:24,300
suddenly sees the landing target and has

00:11:20,790 --> 00:11:26,780
now made a correction to that offset so

00:11:24,300 --> 00:11:30,330
the drone was flying in local frame

00:11:26,780 --> 00:11:33,360
before which was offset due to the

00:11:30,330 --> 00:11:35,460
crooked vio frame but then as soon as it

00:11:33,360 --> 00:11:38,880
saw the landing pad it's made a

00:11:35,460 --> 00:11:43,620
correction from local frame to what I

00:11:38,880 --> 00:11:45,480
like to call fixed frame so local frame

00:11:43,620 --> 00:11:47,970
is going to be aligned with revenue line

00:11:45,480 --> 00:11:52,110
yours when VI Leo initialized and it's

00:11:47,970 --> 00:11:55,290
going to be your job to calculate the

00:11:52,110 --> 00:11:57,660
translation and rotation between the

00:11:55,290 --> 00:12:00,240
local frame and fixed frame which is

00:11:57,660 --> 00:12:02,940
defined by fiducial markers or some

00:12:00,240 --> 00:12:05,580
similar localization system you could

00:12:02,940 --> 00:12:08,070
even use a GPS or a magnetometer to do

00:12:05,580 --> 00:12:11,910
this but April tanks are a very

00:12:08,070 --> 00:12:16,470
available open source method for doing

00:12:11,910 --> 00:12:17,279
this now much like we had a chain of

00:12:16,470 --> 00:12:19,709
transform

00:12:17,279 --> 00:12:22,170
and rotations to calculate out the body

00:12:19,709 --> 00:12:25,040
with respect to local frame this is just

00:12:22,170 --> 00:12:27,420
a case of calculating this by

00:12:25,040 --> 00:12:29,850
multiplying the rotation matrix and

00:12:27,420 --> 00:12:32,970
transforming each of these steps they do

00:12:29,850 --> 00:12:34,889
multiply add multiply add multiply add

00:12:32,970 --> 00:12:42,930
multiply add and then finally you get

00:12:34,889 --> 00:12:45,059
back to this link now the final or

00:12:42,930 --> 00:12:46,470
fundamental computer vision techniques

00:12:45,059 --> 00:12:50,279
that you're going to want to play with

00:12:46,470 --> 00:12:52,920
is px fours collision prevention feature

00:12:50,279 --> 00:12:55,350
now here we're using a stereo camera

00:12:52,920 --> 00:12:57,389
pair looking forward at the wall and as

00:12:55,350 --> 00:12:59,819
you can see it doesn't matter how hard I

00:12:57,389 --> 00:13:01,980
push the stick forward the drone is not

00:12:59,819 --> 00:13:04,439
going to crash into the wall I can

00:13:01,980 --> 00:13:06,269
freely move back as I try to go forward

00:13:04,439 --> 00:13:09,209
into the wall again it's going to

00:13:06,269 --> 00:13:11,999
prevent me now this is the collision

00:13:09,209 --> 00:13:14,430
prevention itself and the processing of

00:13:11,999 --> 00:13:17,040
my radio control inputs is completely

00:13:14,430 --> 00:13:20,420
being done in px for right now all I'm

00:13:17,040 --> 00:13:23,699
doing on the on-board computer side is

00:13:20,420 --> 00:13:29,149
transforms and rotations of the stereo

00:13:23,699 --> 00:13:31,500
data into the format that px4 expects so

00:13:29,149 --> 00:13:36,120
this is the data structure that you're

00:13:31,500 --> 00:13:38,790
going to want to keep in or send into px

00:13:36,120 --> 00:13:41,850
4 and the data structure is very much

00:13:38,790 --> 00:13:44,579
going to look like a spinning light at

00:13:41,850 --> 00:13:47,220
our sensor so it's called the obstacle

00:13:44,579 --> 00:13:51,120
distance and it's math link message ID

00:13:47,220 --> 00:13:53,879
330 and it's a very flexible math Lake

00:13:51,120 --> 00:13:57,269
packet lets you send it up to 72

00:13:53,879 --> 00:13:59,220
different distances spanning around on

00:13:57,269 --> 00:14:02,339
the drone now you don't have to populate

00:13:59,220 --> 00:14:03,959
all of them for example here the stereo

00:14:02,339 --> 00:14:08,129
can repair that I showed in the last

00:14:03,959 --> 00:14:11,819
video is has a field of view of 65

00:14:08,129 --> 00:14:16,350
degrees and so if we split the 360

00:14:11,819 --> 00:14:19,019
degree field of view up into the 5

00:14:16,350 --> 00:14:22,769
degree increments then we're only going

00:14:19,019 --> 00:14:24,870
to use the center 13 of those it's

00:14:22,769 --> 00:14:27,990
helpful to know that these distances and

00:14:24,870 --> 00:14:28,880
the the array that contains them start

00:14:27,990 --> 00:14:32,990
pointing for

00:14:28,880 --> 00:14:36,050
and then spins all the way around to the

00:14:32,990 --> 00:14:38,060
right so here we have a distance index

00:14:36,050 --> 00:14:40,520
zero is pointing straight forward and

00:14:38,060 --> 00:14:43,250
then it's five degree increments all the

00:14:40,520 --> 00:14:45,740
way around if you want higher resolution

00:14:43,250 --> 00:14:47,780
you can decrease the increment value to

00:14:45,740 --> 00:14:49,580
something less than five degrees and

00:14:47,780 --> 00:14:52,010
then you can have that's a higher

00:14:49,580 --> 00:14:56,090
resolution in this forward-facing area

00:14:52,010 --> 00:14:57,740
or you can just leave it as 5 degree

00:14:56,090 --> 00:15:01,730
increments and then you'll see all the

00:14:57,740 --> 00:15:04,280
way around now to get there you're going

00:15:01,730 --> 00:15:06,320
to have to take the point cloud that you

00:15:04,280 --> 00:15:09,230
get out of your stereo camera and do

00:15:06,320 --> 00:15:11,330
more transforms and rotations primarily

00:15:09,230 --> 00:15:14,900
you're going to have to take stereo

00:15:11,330 --> 00:15:17,030
camera field of view which is Z out of

00:15:14,900 --> 00:15:20,330
the lens X to the right and white down

00:15:17,030 --> 00:15:24,470
generally rotated that into body frame

00:15:20,330 --> 00:15:27,350
and then ideally put that also into a

00:15:24,470 --> 00:15:29,030
leveled out version of the body frame so

00:15:27,350 --> 00:15:32,150
in the same way that we had a rotation

00:15:29,030 --> 00:15:34,310
between the vio frame and the gravity of

00:15:32,150 --> 00:15:37,160
lining vio frame we're going to do the

00:15:34,310 --> 00:15:39,170
same here going from body frame to a

00:15:37,160 --> 00:15:42,260
level demat version of the body frame

00:15:39,170 --> 00:15:44,090
now a very easy way to do this a very

00:15:42,260 --> 00:15:47,540
computationally efficient way to do this

00:15:44,090 --> 00:15:50,360
is to take a vector which is pointing

00:15:47,540 --> 00:15:53,630
down along gravity so positive one in

00:15:50,360 --> 00:15:56,570
the Z direction straight down rotate it

00:15:53,630 --> 00:15:58,520
by our rotation matrix defining body to

00:15:56,570 --> 00:16:02,180
local which is what we already set into

00:15:58,520 --> 00:16:04,820
px form if we take the cross product of

00:16:02,180 --> 00:16:09,110
those two then what we're going to get

00:16:04,820 --> 00:16:11,390
out is one by three vector the cross

00:16:09,110 --> 00:16:14,030
product which is going to define the XS

00:16:11,390 --> 00:16:16,100
that the body has to rotate about to go

00:16:14,030 --> 00:16:20,390
from where it is nailed to being level

00:16:16,100 --> 00:16:24,020
and then the two normal of that vector

00:16:20,390 --> 00:16:27,560
can be arcsine to get the angle now we

00:16:24,020 --> 00:16:29,840
have a rotation in excess angle format

00:16:27,560 --> 00:16:32,480
which can very easily be rotated but

00:16:29,840 --> 00:16:35,120
transformed it into a rotation matrix

00:16:32,480 --> 00:16:37,130
attorney enroll picture however you like

00:16:35,120 --> 00:16:38,810
to represent your rotations this is a

00:16:37,130 --> 00:16:42,920
very computationally efficient way to do

00:16:38,810 --> 00:16:46,970
this and it also works well for the

00:16:42,920 --> 00:16:52,250
for the vio gravity online frame now I'd

00:16:46,970 --> 00:16:54,350
like to see just what you get once all

00:16:52,250 --> 00:16:56,990
of these are in place so this is an open

00:16:54,350 --> 00:16:59,180
source now for a space note that we have

00:16:56,990 --> 00:17:02,060
available on our website that sends in a

00:16:59,180 --> 00:17:04,220
smooth trajectory into px4

00:17:02,060 --> 00:17:06,260
that defines a new Lee's lemma state

00:17:04,220 --> 00:17:08,839
also known as a figure Eight's

00:17:06,260 --> 00:17:12,820
pattern and so this is sending in 2px

00:17:08,839 --> 00:17:16,130
for a position velocity and acceleration

00:17:12,820 --> 00:17:19,250
at 30 frames per second and what you get

00:17:16,130 --> 00:17:20,860
is a perfectly smooth trajectory now I'd

00:17:19,250 --> 00:17:23,120
like to hand it off to my colleague

00:17:20,860 --> 00:17:26,150
Hendrik and Ghani who's going to talk a

00:17:23,120 --> 00:17:28,130
little bit about the open source of

00:17:26,150 --> 00:17:32,960
insertion project and our experiences

00:17:28,130 --> 00:17:37,070
getting it to work with px4 thank you

00:17:32,960 --> 00:17:38,930
James and hello everyone so in the

00:17:37,070 --> 00:17:43,240
interest of time I'll just jump right

00:17:38,930 --> 00:17:48,890
into it so I will be talking about our

00:17:43,240 --> 00:17:51,320
effort into working on a open source we

00:17:48,890 --> 00:17:53,480
are algorithm convinced fusion and so we

00:17:51,320 --> 00:17:55,160
wanted to share our experience about the

00:17:53,480 --> 00:17:56,330
approach that we took the changes that

00:17:55,160 --> 00:17:58,190
we had to make to get real-time

00:17:56,330 --> 00:18:03,170
performance and the kind of problems

00:17:58,190 --> 00:18:05,720
that we ran into so to begin with what

00:18:03,170 --> 00:18:09,530
we did was we tried Vince fusion on a

00:18:05,720 --> 00:18:10,100
regular desktop PC but using our own raw

00:18:09,530 --> 00:18:13,700
specs

00:18:10,100 --> 00:18:16,100
so our ross bags were collected on the

00:18:13,700 --> 00:18:20,210
system on which we eventually wanted to

00:18:16,100 --> 00:18:21,560
run Vince vision live with px4 and the

00:18:20,210 --> 00:18:26,060
raw specs that we collected were both

00:18:21,560 --> 00:18:28,460
handheld as well as in flight so the

00:18:26,060 --> 00:18:31,850
reason we took this approach was because

00:18:28,460 --> 00:18:34,730
it helps resolve a lot of fundamental

00:18:31,850 --> 00:18:36,380
issues like the extrinsic calibration

00:18:34,730 --> 00:18:39,530
which wherein you have to give the I am

00:18:36,380 --> 00:18:42,020
into camera relationship the intrinsic

00:18:39,530 --> 00:18:44,090
camera calibration feature tracking as

00:18:42,020 --> 00:18:45,620
to how many features you want or good

00:18:44,090 --> 00:18:48,080
enough for what should the distance be

00:18:45,620 --> 00:18:50,450
if it will and anything that will help

00:18:48,080 --> 00:18:52,280
you get good feature tracking another

00:18:50,450 --> 00:18:54,770
important thing that we can tweak during

00:18:52,280 --> 00:18:55,230
this process is the IMU noise parameters

00:18:54,770 --> 00:18:58,290
which is

00:18:55,230 --> 00:19:01,080
the axle and the gyro noise deviation

00:18:58,290 --> 00:19:03,809
and the bias and while we are working on

00:19:01,080 --> 00:19:05,309
these issues we also realize that there

00:19:03,809 --> 00:19:07,590
were certain assumptions that were made

00:19:05,309 --> 00:19:10,530
like the vocal and being of a particular

00:19:07,590 --> 00:19:13,140
value and the way in which the IME only

00:19:10,530 --> 00:19:16,290
both generation was being done so even

00:19:13,140 --> 00:19:19,950
though we were working on a PC with our

00:19:16,290 --> 00:19:23,190
Ross bags we were able to I I not all

00:19:19,950 --> 00:19:26,220
the issues in order to get it working

00:19:23,190 --> 00:19:29,520
stimuli on a pc with our drawers packs

00:19:26,220 --> 00:19:32,010
so once we had this consistently working

00:19:29,520 --> 00:19:34,890
then we made the space to moving from

00:19:32,010 --> 00:19:37,790
the pc to the actual drone on which we

00:19:34,890 --> 00:19:41,340
wanted to fly a vince fusion with px4

00:19:37,790 --> 00:19:43,380
and then once we move there first step

00:19:41,340 --> 00:19:45,000
was to make sure that the ross bags that

00:19:43,380 --> 00:19:48,870
were consistently and the pc works

00:19:45,000 --> 00:19:51,750
really well on the on-board computer as

00:19:48,870 --> 00:19:54,480
well and then we moved from using the

00:19:51,750 --> 00:19:56,790
ross batch to using light camera and i

00:19:54,480 --> 00:19:58,140
mediator and since the pc is going to be

00:19:56,790 --> 00:20:00,750
much more powerful than your onboard

00:19:58,140 --> 00:20:02,280
computer we had to deal with the

00:20:00,750 --> 00:20:04,470
real-time performance and what we

00:20:02,280 --> 00:20:06,990
noticed was then if we are not

00:20:04,470 --> 00:20:09,360
performing enough then the functionality

00:20:06,990 --> 00:20:12,090
also starts breaking down so we had to

00:20:09,360 --> 00:20:14,070
resolve a lot of performance issues so

00:20:12,090 --> 00:20:16,440
that the functionality stayed intact and

00:20:14,070 --> 00:20:19,020
some of the things that we did was to

00:20:16,440 --> 00:20:21,540
use GPU for feature tracking instead of

00:20:19,020 --> 00:20:23,549
the CPU some optimizations related to C

00:20:21,540 --> 00:20:26,130
resolver specifically in Vince fusion

00:20:23,549 --> 00:20:28,080
and then instead of consuming let's say

00:20:26,130 --> 00:20:30,299
features in every camera frame we said

00:20:28,080 --> 00:20:32,520
let's try and consume features from

00:20:30,299 --> 00:20:34,679
every other camera frame and another

00:20:32,520 --> 00:20:37,500
thing was related to that we have just

00:20:34,679 --> 00:20:39,630
recently discord is issues related to

00:20:37,500 --> 00:20:40,919
thread threading mechanisms so we need

00:20:39,630 --> 00:20:44,600
to have very efficient threading

00:20:40,919 --> 00:20:46,650
mechanisms to gain real-time performance

00:20:44,600 --> 00:20:48,540
so these were some of the performance

00:20:46,650 --> 00:20:51,450
issues that we resolved or to get a good

00:20:48,540 --> 00:20:56,010
functionality as well now the final step

00:20:51,450 --> 00:20:58,049
was to try Vince fusion with px4 and the

00:20:56,010 --> 00:20:59,700
first step was to send the wins fusion

00:20:58,049 --> 00:21:02,429
data to px core and the pain which we

00:20:59,700 --> 00:21:05,950
did that was using what James mentioned

00:21:02,429 --> 00:21:07,809
earlier using the

00:21:05,950 --> 00:21:09,880
what's the vision px4 that we have so he

00:21:07,809 --> 00:21:14,559
sent up insufficient data using that

00:21:09,880 --> 00:21:17,289
mechanism and there were a few problems

00:21:14,559 --> 00:21:20,620
that we ran into when we did that was

00:21:17,289 --> 00:21:23,409
sending incorrect parameter for the VF

00:21:20,620 --> 00:21:26,710
data specifically like James mentioned

00:21:23,409 --> 00:21:29,110
earlier it was xpx were expecting the

00:21:26,710 --> 00:21:30,549
VAR data to be in a certain frame of

00:21:29,110 --> 00:21:32,470
reference but we're not sending it in

00:21:30,549 --> 00:21:36,429
that frame of reference so that's what I

00:21:32,470 --> 00:21:40,120
mean that here and then as far as Bose

00:21:36,429 --> 00:21:42,340
is concerned it's sending the timestamp

00:21:40,120 --> 00:21:44,950
mechanisms wherein if you lack the post

00:21:42,340 --> 00:21:47,169
by a lot as compared to the current

00:21:44,950 --> 00:21:49,179
times and the vio packets were getting

00:21:47,169 --> 00:21:51,580
wrong now so this is just a quick video

00:21:49,179 --> 00:21:56,820
of where we stand this is using the

00:21:51,580 --> 00:21:59,980
infusion in in hold mode is what we are

00:21:56,820 --> 00:22:02,830
doing here and one of the things that we

00:21:59,980 --> 00:22:04,720
are expending with right now is to

00:22:02,830 --> 00:22:07,929
update the post using I new data only

00:22:04,720 --> 00:22:09,519
using a good camera pose as a basement

00:22:07,929 --> 00:22:14,490
but something that we have just been

00:22:09,519 --> 00:22:19,149
trying out recently thank you very much

00:22:14,490 --> 00:22:23,620
thank you so let's see what questions we

00:22:19,149 --> 00:22:25,570
have come up already good we have lots

00:22:23,620 --> 00:22:30,789
of questions then we stop back to my

00:22:25,570 --> 00:22:33,820
video see you can see me there we go

00:22:30,789 --> 00:22:36,340
all right so questions what hardware do

00:22:33,820 --> 00:22:41,470
you use to run your vio setup ie

00:22:36,340 --> 00:22:45,090
computer cameras I use so we develop and

00:22:41,470 --> 00:22:48,580
distribute a fully open source

00:22:45,090 --> 00:22:51,700
development platform called voxel which

00:22:48,580 --> 00:22:52,960
is based on this dragon processor and so

00:22:51,700 --> 00:22:55,090
that's what we use for all of our

00:22:52,960 --> 00:22:57,419
development we have a wide angle fisheye

00:22:55,090 --> 00:23:00,880
lenses which plugs straight into the

00:22:57,419 --> 00:23:03,940
camera is P of the Qualcomm Snapdragon

00:23:00,880 --> 00:23:08,429
chips and so we can get very high

00:23:03,940 --> 00:23:12,220
performance vio out of this setup can

00:23:08,429 --> 00:23:15,820
vio work outdoors with GPS fusion as

00:23:12,220 --> 00:23:17,230
well yes the i/o can work outdoors you

00:23:15,820 --> 00:23:20,740
may want to configure

00:23:17,230 --> 00:23:24,190
a little bit differently just basic

00:23:20,740 --> 00:23:28,090
parameters at the vio algorithm GPS

00:23:24,190 --> 00:23:31,510
fusion with vio is actually fairly

00:23:28,090 --> 00:23:33,120
recent development in px4 itself and I

00:23:31,510 --> 00:23:35,799
think we're going to see a lot of

00:23:33,120 --> 00:23:38,350
tweaking and performance improvements of

00:23:35,799 --> 00:23:43,450
that in the coming months in the coming

00:23:38,350 --> 00:23:46,960
releases of px4 derivative doesn't work

00:23:43,450 --> 00:23:50,710
for discontinuity and corners how to

00:23:46,960 --> 00:23:52,960
deal with that so I assume you're

00:23:50,710 --> 00:23:59,169
talking about sending in the derivative

00:23:52,960 --> 00:24:00,790
of the velocity going inside derivative

00:23:59,169 --> 00:24:04,540
of position that you're sending in to

00:24:00,790 --> 00:24:08,640
ps4 for the odometry now our px4 expects

00:24:04,540 --> 00:24:10,990
a continuous input so you should have no

00:24:08,640 --> 00:24:15,370
discontinuities into the input going

00:24:10,990 --> 00:24:17,770
into px4 if you need to handle any jumps

00:24:15,370 --> 00:24:20,380
such as when you see an April tag you

00:24:17,770 --> 00:24:23,230
need to make sure that the data px4 is

00:24:20,380 --> 00:24:26,500
getting is completely smooth and any

00:24:23,230 --> 00:24:29,890
adjustments you do to those offsets

00:24:26,500 --> 00:24:32,440
are taking care of before use in the set

00:24:29,890 --> 00:24:35,290
point into the x4 so be equitable always

00:24:32,440 --> 00:24:38,799
needs to be flying relative to local

00:24:35,290 --> 00:24:41,080
frame if you have position set points in

00:24:38,799 --> 00:24:43,870
a fixed frame you need to translate

00:24:41,080 --> 00:24:47,020
those set points into local frame first

00:24:43,870 --> 00:24:49,090
to avoid those discontinuity since px-41

00:24:47,020 --> 00:24:53,230
handle them and of course we can't have

00:24:49,090 --> 00:24:55,450
the first derivative of a job have

00:24:53,230 --> 00:24:57,610
recent boss versions dealt adequately

00:24:55,450 --> 00:25:00,340
with their software time stepping issues

00:24:57,610 --> 00:25:02,440
previous versions did not provide hard

00:25:00,340 --> 00:25:04,960
real-time guarantees on time stamps

00:25:02,440 --> 00:25:08,890
causing serious issues with sensitive to

00:25:04,960 --> 00:25:13,600
envision processing if you're going to

00:25:08,890 --> 00:25:16,419
be consuming camera and IMU data through

00:25:13,600 --> 00:25:19,120
Ross I think you'll definitely want to

00:25:16,419 --> 00:25:21,250
be very sure that the Rost nodes that

00:25:19,120 --> 00:25:25,570
you're using to publish the camera and I

00:25:21,250 --> 00:25:27,340
new data handles the time stems properly

00:25:25,570 --> 00:25:29,679
so that's the wonderful thing about the

00:25:27,340 --> 00:25:30,440
open source community is we release the

00:25:29,679 --> 00:25:33,440
Ross moment

00:25:30,440 --> 00:25:35,090
we all create and it is the rostov's

00:25:33,440 --> 00:25:36,830
themselves which generate those time

00:25:35,090 --> 00:25:39,379
stamps so it's really up to whoever's

00:25:36,830 --> 00:25:42,169
programming the node to do the time

00:25:39,379 --> 00:25:44,720
stamp correctly that's not up to Ross

00:25:42,169 --> 00:25:47,029
Ross just sends around the timestamp

00:25:44,720 --> 00:25:49,909
that it's given in the packet

00:25:47,029 --> 00:25:51,710
so whatever driver you have reading that

00:25:49,909 --> 00:25:56,659
IMU is gonna have to do the time

00:25:51,710 --> 00:26:00,080
stamping okay a question XYZ position

00:25:56,659 --> 00:26:03,200
with respect to home position home

00:26:00,080 --> 00:26:06,610
position should be fixed then yeah this

00:26:03,200 --> 00:26:12,889
relates similarly to a previous question

00:26:06,610 --> 00:26:16,100
where home position is wherever the Biao

00:26:12,889 --> 00:26:18,440
you started up and so anything that you

00:26:16,100 --> 00:26:20,299
want to move anywhere you want to go

00:26:18,440 --> 00:26:22,549
relative to that you're going to have to

00:26:20,299 --> 00:26:25,570
do a transform and a rotation to the set

00:26:22,549 --> 00:26:28,250
point so that you can't move that around

00:26:25,570 --> 00:26:31,279
the last question we have to use vio

00:26:28,250 --> 00:26:33,710
with GPS so the drone can enter indoors

00:26:31,279 --> 00:26:35,750
doing an auto mission isn't that the

00:26:33,710 --> 00:26:39,889
feature that everybody wants so I think

00:26:35,750 --> 00:26:41,419
starting with px4 1.11 the i/o and gps

00:26:39,889 --> 00:26:44,509
play a little bit more nicely together

00:26:41,419 --> 00:26:47,059
but that's not something that I've done

00:26:44,509 --> 00:26:48,649
lots of flight testing with myself but I

00:26:47,059 --> 00:26:52,690
think we're going to see a lot of

00:26:48,649 --> 00:26:55,700
development in px4 with regard to this

00:26:52,690 --> 00:26:57,549
so I think that's all of my time and

00:26:55,700 --> 00:27:01,970
that was the last question

00:26:57,549 --> 00:27:05,799
so thank you all for dialing in I hope

00:27:01,970 --> 00:27:05,799
you found this informative thank you

00:27:06,460 --> 00:27:08,990
James

00:27:07,759 --> 00:27:10,730
thank you a lot for your time and

00:27:08,990 --> 00:27:12,620
contributions to open source it was a

00:27:10,730 --> 00:27:16,179
really cool presentation and I'll talk

00:27:12,620 --> 00:27:22,009
to you soon community Wow welcome

00:27:16,179 --> 00:27:25,000
I see like everyone here let's see I get

00:27:22,009 --> 00:27:29,539
people from Portugal from Mexico yeah

00:27:25,000 --> 00:27:33,470
USA UK is louvenia Finland Brazil Turkey

00:27:29,539 --> 00:27:37,159
Colombia India Korea Romania Myanmar

00:27:33,470 --> 00:27:38,960
Indonesia Calais Switzerland Wow thank

00:27:37,159 --> 00:27:39,900
you guys this is awesome thank you for

00:27:38,960 --> 00:27:42,600
joining today

00:27:39,900 --> 00:27:46,200
we have a full day of sessions today so

00:27:42,600 --> 00:27:49,350
I'm sure you're gonna be busy next up we

00:27:46,200 --> 00:27:50,910
have open source workflow for advanced

00:27:49,350 --> 00:27:53,820
vehicle dynamics

00:27:50,910 --> 00:27:56,700
it's like magma canteen Jesse Hoskins by

00:27:53,820 --> 00:27:58,680
GE Aviation while I know the speakers

00:27:56,700 --> 00:28:00,360
please stand by don't forget to look for

00:27:58,680 --> 00:28:01,920
the pre-recorded sessions they're our

00:28:00,360 --> 00:28:03,690
YouTube channel please go and search for

00:28:01,920 --> 00:28:06,720
those there's some that are premiering

00:28:03,690 --> 00:28:08,880
right now as I speak pay attention to

00:28:06,720 --> 00:28:12,560
that and please follow us on social

00:28:08,880 --> 00:28:16,560
media don't forget to post using the

00:28:12,560 --> 00:28:19,100
hashtag px4 dev summit alright so be

00:28:16,560 --> 00:28:19,100

YouTube URL: https://www.youtube.com/watch?v=P0YM2zK0qRc


