Title: Embedded machine learning in practice â€” PX4 Developer Summit Virtual 2020
Publication date: 2020-07-19
Playlist: PX4 Developer Summit 2020 | Virtual
Description: 
	Title: Embedded machine learning in practice 

Summary: TinyML is a global community of software engineers and data scientists working together to bring more intelligence to sensors on embedded devices. This movement has enabled a wide range of applications on the tiniest of devices, from predictive maintenance to object detection to sound recognition. In systems where decision-making needs to happen in real-time, it is important that the processing can be done as close as possible to the data source - enhancing security and cutting down on network energy consumption, latency, and bandwidth usage.

During this talk, you will learn why you should consider doing ML even on the most constrained computing devices available to you and how to get started in practice.

The PX4 Developer Summit 2020 is the annual flagship conference hosted by Dronecode for the drone development community. https://bit.ly/2YXe4Rd
Captions: 
	00:00:00,380 --> 00:00:07,859
today we're back thank you now we have a

00:00:05,790 --> 00:00:10,050
central Grandin he's the IOT ecosystem

00:00:07,859 --> 00:00:12,210
manager for arm and he's coming from

00:00:10,050 --> 00:00:15,230
Cambridge UK he's gonna be talking to us

00:00:12,210 --> 00:00:20,240
about tiny ml and doing machine learning

00:00:15,230 --> 00:00:25,789
let's see how does that relate to drones

00:00:20,240 --> 00:00:30,390
wait let me show you I can't see myself

00:00:25,789 --> 00:00:30,810
at my own yes you're on oh hey hi I'm

00:00:30,390 --> 00:00:34,770
good

00:00:30,810 --> 00:00:36,300
the my clothes thank you thank you so

00:00:34,770 --> 00:00:45,660
I'm gonna share my screen just give me

00:00:36,300 --> 00:00:49,050
one second okay cool so thank you for

00:00:45,660 --> 00:00:51,360
having me Ramon and I'm really happy to

00:00:49,050 --> 00:00:55,140
be here today and be able to share with

00:00:51,360 --> 00:00:57,809
you my passion around machine learning

00:00:55,140 --> 00:00:59,280
on embedded devices so I as a Ramon said

00:00:57,809 --> 00:01:03,420
I'm a developer advocate an ecosystem

00:00:59,280 --> 00:01:12,930
manager and I work for arm and let's see

00:01:03,420 --> 00:01:15,630
if this works slide okay yeah and why am

00:01:12,930 --> 00:01:17,970
I here well the interesting thing is

00:01:15,630 --> 00:01:20,460
that because of my job I'm exposed to a

00:01:17,970 --> 00:01:21,890
lot of really interesting people and a

00:01:20,460 --> 00:01:24,630
lot of interesting trends that I see

00:01:21,890 --> 00:01:27,030
across the industry and with this comes

00:01:24,630 --> 00:01:29,189
a lot of use cases that people in

00:01:27,030 --> 00:01:31,530
industry and industry leaders are

00:01:29,189 --> 00:01:33,750
actually trying to make a reality and

00:01:31,530 --> 00:01:35,100
the other the other point is that I'm

00:01:33,750 --> 00:01:37,979
passionate about machine learning

00:01:35,100 --> 00:01:40,619
especially on embedded devices and the

00:01:37,979 --> 00:01:42,810
capabilities that this unlocks and I

00:01:40,619 --> 00:01:44,700
want to share also with you

00:01:42,810 --> 00:01:46,770
what I've learned in Latin last couple

00:01:44,700 --> 00:01:49,140
of years around machine learning on

00:01:46,770 --> 00:01:53,490
embedded devices and this new world of

00:01:49,140 --> 00:01:56,130
possibilities that's opening up so I

00:01:53,490 --> 00:01:58,140
guess I'm coming from an IOT space right

00:01:56,130 --> 00:02:01,530
so why am I here and why am I talking to

00:01:58,140 --> 00:02:04,200
you about machine learning on on drones

00:02:01,530 --> 00:02:06,799
in some ways and I think I think really

00:02:04,200 --> 00:02:08,910
when we look at the challenges in drones

00:02:06,799 --> 00:02:10,709
they're very similar to some of the

00:02:08,910 --> 00:02:13,319
challenges that we see in other spaces

00:02:10,709 --> 00:02:15,480
like IOT for example robotics

00:02:13,319 --> 00:02:18,389
and these are that we are in a situation

00:02:15,480 --> 00:02:19,799
where real time is a really important

00:02:18,389 --> 00:02:23,010
thing and we have to make sure that and

00:02:19,799 --> 00:02:26,790
you know we are taking making decisions

00:02:23,010 --> 00:02:30,870
on on time in real time and the other

00:02:26,790 --> 00:02:34,260
thing is that and the the devices that

00:02:30,870 --> 00:02:37,469
we're operating with we're using are in

00:02:34,260 --> 00:02:39,810
are situated in a very energy

00:02:37,469 --> 00:02:42,060
constrained environment you usually are

00:02:39,810 --> 00:02:44,370
running off batteries obviously you want

00:02:42,060 --> 00:02:47,639
to try and fly as as much as you can and

00:02:44,370 --> 00:02:49,799
and this enables you you know you have

00:02:47,639 --> 00:02:52,709
to like make sure that you are

00:02:49,799 --> 00:02:55,980
considering that when you're looking at

00:02:52,709 --> 00:02:57,599
your what's running on your device the

00:02:55,980 --> 00:03:00,060
other thing is that you are in a

00:02:57,599 --> 00:03:03,359
constrained memory system and like in a

00:03:00,060 --> 00:03:05,250
lot of IOT devices and lasts you've got

00:03:03,359 --> 00:03:06,870
actually a lot of data coming from a lot

00:03:05,250 --> 00:03:10,019
of different senses and you want to make

00:03:06,870 --> 00:03:12,629
sense of this data so I really see in

00:03:10,019 --> 00:03:14,790
the same way as in the IOT world I see a

00:03:12,629 --> 00:03:18,000
massive opportunity here and that is

00:03:14,790 --> 00:03:19,349
really embedded machine learning or how

00:03:18,000 --> 00:03:22,290
some people like to call it

00:03:19,349 --> 00:03:24,900
tiny ml and and what is it actually what

00:03:22,290 --> 00:03:26,489
do we mean by embedded machine learning

00:03:24,900 --> 00:03:29,430
or endpoint AI

00:03:26,489 --> 00:03:34,259
or tiny ml it's actually machine

00:03:29,430 --> 00:03:36,989
learning that can run on devices with an

00:03:34,259 --> 00:03:39,780
energy cost bill or below a few milli

00:03:36,989 --> 00:03:42,239
watts or around a few milli watts what's

00:03:39,780 --> 00:03:43,439
interesting is that you know you most of

00:03:42,239 --> 00:03:44,639
you are probably familiar with machine

00:03:43,439 --> 00:03:46,709
learning so I'm not gonna focus too much

00:03:44,639 --> 00:03:48,509
on what machine learning is but one

00:03:46,709 --> 00:03:50,069
thing I do want to mention is that you

00:03:48,509 --> 00:03:53,099
know this this can be mind-blowing

00:03:50,069 --> 00:03:55,290
mind-blowing to some of you you can see

00:03:53,099 --> 00:03:58,319
my blowing because actually we used to

00:03:55,290 --> 00:04:02,549
think of machine learning running on on

00:03:58,319 --> 00:04:03,870
big GPUs or big servers but actually you

00:04:02,549 --> 00:04:06,150
know there are two steps in machine

00:04:03,870 --> 00:04:07,709
learning one is the training and for

00:04:06,150 --> 00:04:09,329
that you actually need a lot of data a

00:04:07,709 --> 00:04:11,639
lot of compute but then there is also

00:04:09,329 --> 00:04:15,750
the the other side the inference side

00:04:11,639 --> 00:04:18,150
that is basically what making sense of

00:04:15,750 --> 00:04:20,849
the data around you and actually taking

00:04:18,150 --> 00:04:23,430
actions on them and that actually can

00:04:20,849 --> 00:04:26,620
run very effectively on smaller devices

00:04:23,430 --> 00:04:29,030
as we'll see today

00:04:26,620 --> 00:04:30,500
so what are some of the benefits of

00:04:29,030 --> 00:04:33,349
actually thinking about machine learning

00:04:30,500 --> 00:04:35,990
on embedded devices I like to think that

00:04:33,349 --> 00:04:38,659
there is actually three main ones one is

00:04:35,990 --> 00:04:41,270
security and privacy and why is that a

00:04:38,659 --> 00:04:42,860
benefit well because think about the

00:04:41,270 --> 00:04:45,470
fact that every time every time you

00:04:42,860 --> 00:04:48,080
shift data and you send it somewhere off

00:04:45,470 --> 00:04:50,900
chip or somewhere else potentially on a

00:04:48,080 --> 00:04:53,000
cloud or on a ground station in a drone

00:04:50,900 --> 00:04:55,639
situation and what you're doing is

00:04:53,000 --> 00:04:57,440
actually sharing that data with someone

00:04:55,639 --> 00:04:59,330
else or some other some other entity

00:04:57,440 --> 00:05:01,310
where if you if you're able to do the

00:04:59,330 --> 00:05:02,750
processing on the device you're not

00:05:01,310 --> 00:05:04,340
sharing that data with anyone you're

00:05:02,750 --> 00:05:07,699
keeping it privately on the device and

00:05:04,340 --> 00:05:09,800
the other really efficient thing that I

00:05:07,699 --> 00:05:11,840
like to think about when I think about

00:05:09,800 --> 00:05:15,770
machine learning on embedded devices is

00:05:11,840 --> 00:05:18,889
actually powering cost moving and

00:05:15,770 --> 00:05:20,840
fetching data is very expensive and if

00:05:18,889 --> 00:05:26,060
you're sending data outside of your

00:05:20,840 --> 00:05:28,099
device that cost increasingly increases

00:05:26,060 --> 00:05:30,229
massively sorry and and and therefore

00:05:28,099 --> 00:05:31,940
the closer you do the processing to the

00:05:30,229 --> 00:05:34,219
data itself to where the data is

00:05:31,940 --> 00:05:36,800
captured they they're more efficient and

00:05:34,219 --> 00:05:38,150
cost effective it is the last point is

00:05:36,800 --> 00:05:40,039
actually reliability I've mentioned

00:05:38,150 --> 00:05:41,779
before obviously in a real-time

00:05:40,039 --> 00:05:44,409
situation you want to make sure that

00:05:41,779 --> 00:05:47,479
you're and what you're doing is actually

00:05:44,409 --> 00:05:50,719
happening it's actually happening right

00:05:47,479 --> 00:05:55,639
away and and actually you don't want to

00:05:50,719 --> 00:05:59,509
make you don't want to be you don't want

00:05:55,639 --> 00:06:00,889
to be making decisions delayed from from

00:05:59,509 --> 00:06:03,560
what you're doing so for example if

00:06:00,889 --> 00:06:05,330
you're trying to do object detection to

00:06:03,560 --> 00:06:07,419
object avoidance you want to make sure

00:06:05,330 --> 00:06:10,009
that you avoid your object in time

00:06:07,419 --> 00:06:12,289
before you hit the object so you have to

00:06:10,009 --> 00:06:14,509
make decisions right away and you know

00:06:12,289 --> 00:06:16,819
there's better me and and actually being

00:06:14,509 --> 00:06:19,219
able to do this taking these decisions

00:06:16,819 --> 00:06:20,690
closer to the data itself to the sensor

00:06:19,219 --> 00:06:23,330
itself being able to do machine learning

00:06:20,690 --> 00:06:27,259
on the sensor itself potentially can

00:06:23,330 --> 00:06:29,919
enable you to do it even quicker now

00:06:27,259 --> 00:06:31,729
there are a lot of use cases

00:06:29,919 --> 00:06:34,520
everybody talks about machine learning

00:06:31,729 --> 00:06:37,969
and it's interesting that actually there

00:06:34,520 --> 00:06:39,830
is a big range of use cases from

00:06:37,969 --> 00:06:42,980
starting from you know GP

00:06:39,830 --> 00:06:45,860
use that are really important when it

00:06:42,980 --> 00:06:49,070
comes to really complex and real-time

00:06:45,860 --> 00:06:52,670
and object recognition or person

00:06:49,070 --> 00:06:55,940
identification and Cortex's are the more

00:06:52,670 --> 00:06:57,470
linux enabled devices arm devices those

00:06:55,940 --> 00:06:59,870
are able to do a lot of machine learning

00:06:57,470 --> 00:07:01,880
like for example raspberry pies are able

00:06:59,870 --> 00:07:04,490
to do computer vision type applications

00:07:01,880 --> 00:07:06,710
and run very efficiently and but then if

00:07:04,490 --> 00:07:09,440
we move down the left of this graph we

00:07:06,710 --> 00:07:11,210
can have this table here we could see

00:07:09,440 --> 00:07:13,810
how actually there is a lot of use cases

00:07:11,210 --> 00:07:17,510
that could be covered there could be

00:07:13,810 --> 00:07:20,360
effectively run on on cortex-m or

00:07:17,510 --> 00:07:22,400
microcontrollers so things like

00:07:20,360 --> 00:07:26,270
vibration detection sensor fusion

00:07:22,400 --> 00:07:28,430
keyboard detection and other things like

00:07:26,270 --> 00:07:30,530
for example person detection so

00:07:28,430 --> 00:07:33,290
individually detecting whether a person

00:07:30,530 --> 00:07:34,790
is in there is in the video or not could

00:07:33,290 --> 00:07:36,920
be something that's that could run

00:07:34,790 --> 00:07:39,380
efficiently on a really small device

00:07:36,920 --> 00:07:41,600
constrained device and the other

00:07:39,380 --> 00:07:43,490
interesting thing is that actually this

00:07:41,600 --> 00:07:47,450
trend is here to stay because actually

00:07:43,490 --> 00:07:49,460
we see that you know we together we're

00:07:47,450 --> 00:07:50,900
coming up with all these different

00:07:49,460 --> 00:07:52,730
devices and there is more and more

00:07:50,900 --> 00:07:53,030
cortex-m devices being shipped every

00:07:52,730 --> 00:07:56,390
year

00:07:53,030 --> 00:07:58,190
so there is even more chances for or all

00:07:56,390 --> 00:08:00,020
these devices to get into places where

00:07:58,190 --> 00:08:04,580
they could be utilized more effectively

00:08:00,020 --> 00:08:07,400
and more efficiently so I wanted to

00:08:04,580 --> 00:08:10,340
touch on when does it make sense to

00:08:07,400 --> 00:08:13,520
actually do machine learning on endpoint

00:08:10,340 --> 00:08:14,690
devices and I believe that it makes

00:08:13,520 --> 00:08:18,140
sense to do machine learning to think

00:08:14,690 --> 00:08:20,480
about machine learning on constrained

00:08:18,140 --> 00:08:23,090
devices when when you have data that's

00:08:20,480 --> 00:08:25,250
messy so when you're not really sure how

00:08:23,090 --> 00:08:27,920
to solve your problem when you you know

00:08:25,250 --> 00:08:30,140
when you probably would struggle to come

00:08:27,920 --> 00:08:32,900
up with an algorithm and you're trying

00:08:30,140 --> 00:08:35,360
to find a solution that's not very very

00:08:32,900 --> 00:08:37,280
well understood yet so in that case you

00:08:35,360 --> 00:08:40,310
could try and see whether machine

00:08:37,280 --> 00:08:42,400
learning model could be able to make

00:08:40,310 --> 00:08:45,320
sense of your data and actually give you

00:08:42,400 --> 00:08:46,970
results that you want or make sense of

00:08:45,320 --> 00:08:51,410
the data and actually help you to take

00:08:46,970 --> 00:08:53,370
action so there are different use cases

00:08:51,410 --> 00:08:55,200
as we said before I think you know

00:08:53,370 --> 00:08:58,170
it's useful to think about three

00:08:55,200 --> 00:09:00,900
different use cases categories and those

00:08:58,170 --> 00:09:03,990
are really vibration in motion so any

00:09:00,900 --> 00:09:06,240
kind of signal outside of voice and

00:09:03,990 --> 00:09:10,410
vision and then there is yet recognition

00:09:06,240 --> 00:09:12,000
of voice or sound and images and videos

00:09:10,410 --> 00:09:14,220
really and those are like three

00:09:12,000 --> 00:09:16,710
different classes of the problem that

00:09:14,220 --> 00:09:20,190
and the machine learning kit so could

00:09:16,710 --> 00:09:22,080
solve on embedded devices okay so now

00:09:20,190 --> 00:09:24,630
we're moving in towards actually the

00:09:22,080 --> 00:09:26,790
more practical side of the presentation

00:09:24,630 --> 00:09:30,750
and in a few moments I'll actually show

00:09:26,790 --> 00:09:32,100
you a live demo of this happening and so

00:09:30,750 --> 00:09:33,960
I'm really excited about that so let's

00:09:32,100 --> 00:09:37,440
get into the beefier parts of the

00:09:33,960 --> 00:09:40,400
presentation first of all I wanted to

00:09:37,440 --> 00:09:42,810
mention that actually this is a massive

00:09:40,400 --> 00:09:45,330
ecosystem effort it's not just one

00:09:42,810 --> 00:09:48,420
player that's enabling this technology

00:09:45,330 --> 00:09:50,580
to actually to actually work and to

00:09:48,420 --> 00:09:52,320
actually be efficient and effective

00:09:50,580 --> 00:09:54,900
it's actually an ecosystem of partners

00:09:52,320 --> 00:09:56,730
and you can see here really there is a

00:09:54,900 --> 00:09:59,010
lot of partners are focused on the

00:09:56,730 --> 00:10:01,890
software side so our girden software

00:09:59,010 --> 00:10:04,500
tools and Arthur are toast partners and

00:10:01,890 --> 00:10:06,690
all and all other software partners and

00:10:04,500 --> 00:10:08,130
then there is a silicon partners those

00:10:06,690 --> 00:10:11,040
are actually building the hardware

00:10:08,130 --> 00:10:12,600
itself and and it's interesting how all

00:10:11,040 --> 00:10:14,790
these players are actually coming

00:10:12,600 --> 00:10:16,010
together to make tiny amount of

00:10:14,790 --> 00:10:18,870
possibility

00:10:16,010 --> 00:10:20,520
what does it actually look like what

00:10:18,870 --> 00:10:23,970
does the flow look like for a developer

00:10:20,520 --> 00:10:25,290
well if you're familiar with machine

00:10:23,970 --> 00:10:26,910
learning you know that there is a lot of

00:10:25,290 --> 00:10:29,610
different angular and frameworks out

00:10:26,910 --> 00:10:31,020
there one of one of them is tensor flow

00:10:29,610 --> 00:10:34,440
for example so if you think about a

00:10:31,020 --> 00:10:36,480
tensor flow generated model and train

00:10:34,440 --> 00:10:40,320
model you can then think of taking that

00:10:36,480 --> 00:10:43,650
model and optimizing it for for running

00:10:40,320 --> 00:10:46,770
on on on an embedded stack and what you

00:10:43,650 --> 00:10:49,740
use in this is actually a tensor flow

00:10:46,770 --> 00:10:52,230
and a Google version of tensor flow

00:10:49,740 --> 00:10:55,500
called tensor flow light micro so for

00:10:52,230 --> 00:10:58,560
microcontrollers and by utilizing this

00:10:55,500 --> 00:11:01,860
on top of of an embedded stack you can

00:10:58,560 --> 00:11:02,880
then use your favorite tool like Arduino

00:11:01,860 --> 00:11:05,690
or Kyle Microvision

00:11:02,880 --> 00:11:07,290
or embed studio to actually generate an

00:11:05,690 --> 00:11:09,740
binary code

00:11:07,290 --> 00:11:12,149
that can be used on your device itself

00:11:09,740 --> 00:11:14,370
so I wanted to take you through some of

00:11:12,149 --> 00:11:15,690
the steps that are important to keep in

00:11:14,370 --> 00:11:18,269
mind when you're doing machine learning

00:11:15,690 --> 00:11:20,399
on these constraint devices first of all

00:11:18,269 --> 00:11:22,050
I think it's important to realize that

00:11:20,399 --> 00:11:24,269
actually you need to pick your device

00:11:22,050 --> 00:11:26,600
first you need to be able to understand

00:11:24,269 --> 00:11:29,160
that actually you know in comparison to

00:11:26,600 --> 00:11:31,860
classical machine learning actually here

00:11:29,160 --> 00:11:33,690
you are on a constrained device so you

00:11:31,860 --> 00:11:36,300
really have to know your devices and

00:11:33,690 --> 00:11:38,730
more capabilities it has the next bit is

00:11:36,300 --> 00:11:41,100
actually you need to be aware that and

00:11:38,730 --> 00:11:43,380
you need to pick a model that's compact

00:11:41,100 --> 00:11:46,079
enough that could run on this device and

00:11:43,380 --> 00:11:47,399
the last point here is that and you

00:11:46,079 --> 00:11:51,269
wanna make sure that the model has less

00:11:47,399 --> 00:11:53,519
operations now there is a stage that's

00:11:51,269 --> 00:11:55,980
called optimization stage and this

00:11:53,519 --> 00:11:59,519
really it boils down to making sure that

00:11:55,980 --> 00:12:01,829
the model that you've created can run on

00:11:59,519 --> 00:12:04,170
your device and to do this you have to

00:12:01,829 --> 00:12:06,569
shrink the model somehow and there is

00:12:04,170 --> 00:12:09,029
different of the optimization techniques

00:12:06,569 --> 00:12:12,329
one of which is for example quantization

00:12:09,029 --> 00:12:17,850
so through reducing the size of the

00:12:12,329 --> 00:12:21,360
weights and quanta and and weights and

00:12:17,850 --> 00:12:24,000
then the other bits of the model to run

00:12:21,360 --> 00:12:25,889
on to your device and you can you can

00:12:24,000 --> 00:12:29,040
reduce the size that it occupies it and

00:12:25,889 --> 00:12:30,420
one more more efficiently effectively so

00:12:29,040 --> 00:12:32,730
you're doing you're doing operations and

00:12:30,420 --> 00:12:36,899
more quicker because now you're doing it

00:12:32,730 --> 00:12:38,760
on smaller parts of data so this is

00:12:36,899 --> 00:12:41,339
really important what's interesting here

00:12:38,760 --> 00:12:44,730
is that actually you can do this without

00:12:41,339 --> 00:12:47,010
losing any accuracy the last thing I

00:12:44,730 --> 00:12:49,139
wanted to show you here is that actually

00:12:47,010 --> 00:12:52,319
and as I mentioned before it tends to

00:12:49,139 --> 00:12:54,689
throw light Micro is a tool from Google

00:12:52,319 --> 00:12:57,360
it's an inference engine from Google the

00:12:54,689 --> 00:13:00,959
arm is partnering with to actually

00:12:57,360 --> 00:13:03,149
optimize the efficiency of the of the of

00:13:00,959 --> 00:13:04,709
the inference engine itself on arm

00:13:03,149 --> 00:13:07,040
hardware so we're partnering with Google

00:13:04,709 --> 00:13:11,579
to make sure that actually tends to flow

00:13:07,040 --> 00:13:13,620
runs efficiently on arm and this is what

00:13:11,579 --> 00:13:15,750
you utilize to actually do the last bit

00:13:13,620 --> 00:13:17,310
of the porting to your device so you

00:13:15,750 --> 00:13:20,449
generate the C code that then you can

00:13:17,310 --> 00:13:20,449
run on your device and

00:13:20,640 --> 00:13:25,350
really interesting is that already in in

00:13:23,190 --> 00:13:27,540
less than a year there's been a lot of

00:13:25,350 --> 00:13:30,030
different hardware platforms that are

00:13:27,540 --> 00:13:32,330
supporting tends to flow and thence of a

00:13:30,030 --> 00:13:35,820
like micro and our running if

00:13:32,330 --> 00:13:37,530
effectively these these models on their

00:13:35,820 --> 00:13:40,410
hardware so you can see here a bunch of

00:13:37,530 --> 00:13:41,370
different examples and one of them I'll

00:13:40,410 --> 00:13:44,090
show you today

00:13:41,370 --> 00:13:46,320
in action is actually a do we know and

00:13:44,090 --> 00:13:49,020
yeah do we know board that you can see

00:13:46,320 --> 00:13:53,910
here very interesting little little

00:13:49,020 --> 00:13:55,800
board and so now I wanted to get to the

00:13:53,910 --> 00:13:57,600
actual action and I wanted to show you

00:13:55,800 --> 00:13:59,730
that they there is a lot of things that

00:13:57,600 --> 00:14:02,700
you can do today and actually here I've

00:13:59,730 --> 00:14:05,790
got a list of tutorials and resources

00:14:02,700 --> 00:14:11,300
that you can look at they're all also

00:14:05,790 --> 00:14:13,950
listed in the developer the arm comm IOT

00:14:11,300 --> 00:14:15,750
website you can you can find in there

00:14:13,950 --> 00:14:17,340
but I'll be sharing this slide so you

00:14:15,750 --> 00:14:21,600
can take a look at these afterwards as

00:14:17,340 --> 00:14:25,220
well and now I wanted to run the demo so

00:14:21,600 --> 00:14:29,310
I think I need some help from from from

00:14:25,220 --> 00:14:33,360
Ramon on being able to run this so I'm

00:14:29,310 --> 00:14:40,890
gonna unshare my screen and I'm gonna

00:14:33,360 --> 00:14:50,520
share another screen just give me one

00:14:40,890 --> 00:14:53,600
second okay so we're getting ready

00:14:50,520 --> 00:14:57,270
so what I'll show you today is really a

00:14:53,600 --> 00:15:01,080
simple way to get started on machine

00:14:57,270 --> 00:15:06,900
learning with your microcontroller in a

00:15:01,080 --> 00:15:13,830
few easy steps so let's see here

00:15:06,900 --> 00:15:16,500
I'm sharing okay so one of the one of

00:15:13,830 --> 00:15:18,750
the guides that and they yeah do we know

00:15:16,500 --> 00:15:20,610
team has put together and a lot of work

00:15:18,750 --> 00:15:23,700
has gone into this guide from there even

00:15:20,610 --> 00:15:26,070
do we know team so props to them for for

00:15:23,700 --> 00:15:29,160
doing this they put together is really

00:15:26,070 --> 00:15:32,130
really easy to use guide that you can

00:15:29,160 --> 00:15:34,050
use to train your model and to run it on

00:15:32,130 --> 00:15:36,300
your device so um

00:15:34,050 --> 00:15:38,880
wanted to show you basically something

00:15:36,300 --> 00:15:41,880
that people now working in ml are quite

00:15:38,880 --> 00:15:44,519
familiar with is zoomit jupiter notebook

00:15:41,880 --> 00:15:47,580
this is a tool that allows you to train

00:15:44,519 --> 00:15:49,589
your model and and and optimize it on

00:15:47,580 --> 00:15:53,040
the cloud directly without having to

00:15:49,589 --> 00:15:57,779
build build it on your local hardware so

00:15:53,040 --> 00:15:59,730
the Google has created the call app that

00:15:57,779 --> 00:16:01,410
we know is actually using in this in

00:15:59,730 --> 00:16:05,010
this example so you can see here and

00:16:01,410 --> 00:16:07,380
this is actually you should be able to

00:16:05,010 --> 00:16:09,839
see yeah the different steps so there is

00:16:07,380 --> 00:16:13,079
a setup step there is I've already run

00:16:09,839 --> 00:16:15,480
all this for and just before this this

00:16:13,079 --> 00:16:16,980
presentation I didn't want to run it

00:16:15,480 --> 00:16:19,019
right now just just because I'm

00:16:16,980 --> 00:16:20,910
conscious of time but it's it's really a

00:16:19,019 --> 00:16:23,790
few simple steps so you can see here

00:16:20,910 --> 00:16:26,790
what you do is basically you you get

00:16:23,790 --> 00:16:28,620
your your data through your Arduino

00:16:26,790 --> 00:16:31,800
device you upload it here on the left

00:16:28,620 --> 00:16:35,279
and then you're able to train a model so

00:16:31,800 --> 00:16:38,370
you prepare the data set first and then

00:16:35,279 --> 00:16:42,149
you randomize it and and split it into

00:16:38,370 --> 00:16:44,730
different sets of data so you have

00:16:42,149 --> 00:16:46,440
typically your training set that in this

00:16:44,730 --> 00:16:48,570
case is sixty percent of your initial

00:16:46,440 --> 00:16:50,220
data twenty percent of Violation twenty

00:16:48,570 --> 00:16:52,110
percent of testing that you will use

00:16:50,220 --> 00:16:54,120
later to do actually the testing then

00:16:52,110 --> 00:16:55,320
you train the model this doesn't take

00:16:54,120 --> 00:16:59,100
too long because it's actually running

00:16:55,320 --> 00:17:00,990
on on the GPU and on a big beefy GPU and

00:16:59,100 --> 00:17:03,029
then what you could do here is actually

00:17:00,990 --> 00:17:05,579
the luteal team has done a really good

00:17:03,029 --> 00:17:07,439
job by showing you some of the really

00:17:05,579 --> 00:17:10,260
interesting some really interesting data

00:17:07,439 --> 00:17:12,120
on on on the loss function for example I

00:17:10,260 --> 00:17:14,069
can give you an idea of how well do your

00:17:12,120 --> 00:17:16,260
model is performing so you can see here

00:17:14,069 --> 00:17:23,429
the the plot of the loss function or in

00:17:16,260 --> 00:17:25,559
my case and finally you can run the test

00:17:23,429 --> 00:17:28,830
so to see how it's performing in my case

00:17:25,559 --> 00:17:33,780
for example I trained two different two

00:17:28,830 --> 00:17:36,210
different types of of motions turbulence

00:17:33,780 --> 00:17:38,370
a knockdown motion I'm trying to

00:17:36,210 --> 00:17:40,980
simulate for example use case in which

00:17:38,370 --> 00:17:44,429
I'm trying to understand whether my my

00:17:40,980 --> 00:17:46,740
flying device is actually in in

00:17:44,429 --> 00:17:48,120
turbulence or is perceiving turbulence

00:17:46,740 --> 00:17:50,550
or is that oh it's actually

00:17:48,120 --> 00:17:52,890
going up and down and you can see how

00:17:50,550 --> 00:17:56,700
the performance of this this model is

00:17:52,890 --> 00:17:59,610
actually really really good and and then

00:17:56,700 --> 00:18:01,260
here you can convert the last ages

00:17:59,610 --> 00:18:04,710
converting the Train model to tensorflow

00:18:01,260 --> 00:18:07,410
light and at the end you're able to

00:18:04,710 --> 00:18:11,310
generate a code that can run on our

00:18:07,410 --> 00:18:15,570
Duino itself so I'm gonna now share the

00:18:11,310 --> 00:18:19,400
actual so this is the yeah do we know

00:18:15,570 --> 00:18:22,530
code that's running on my device and

00:18:19,400 --> 00:18:26,610
Ramon can confirm that I can that you

00:18:22,530 --> 00:18:28,560
can people can see my camera okay cool

00:18:26,610 --> 00:18:31,050
so so you should be able to see here do

00:18:28,560 --> 00:18:33,780
we know device and you're seeing now on

00:18:31,050 --> 00:18:36,570
the on the camera also your on the

00:18:33,780 --> 00:18:41,040
screen that you know by moving this now

00:18:36,570 --> 00:18:43,790
I will be able to to understand the

00:18:41,040 --> 00:18:47,550
motion right so let's see if this works

00:18:43,790 --> 00:18:50,190
demo gods please be with me so let's see

00:18:47,550 --> 00:18:54,870
okay so if I move up and down that's up

00:18:50,190 --> 00:19:01,920
and down up and down let's see if it

00:18:54,870 --> 00:19:04,440
detects turbulence up and down again and

00:19:01,920 --> 00:19:08,340
you can see how they the accuracy of

00:19:04,440 --> 00:19:10,200
this is actually quite impressive for

00:19:08,340 --> 00:19:14,270
being a model that runs on a cortex m4

00:19:10,200 --> 00:19:16,260
and in a really really efficient way and

00:19:14,270 --> 00:19:17,640
you can see actually the speed of

00:19:16,260 --> 00:19:18,660
recognition I mean it's it's actually

00:19:17,640 --> 00:19:20,850
really fast the only thing that's

00:19:18,660 --> 00:19:23,550
slowing it down is that you're there is

00:19:20,850 --> 00:19:25,740
a window of of data collection that's

00:19:23,550 --> 00:19:29,460
happening but you can see how actually

00:19:25,740 --> 00:19:32,910
it's really it's really good at

00:19:29,460 --> 00:19:35,610
recognizing whether this is turbulence

00:19:32,910 --> 00:19:37,970
or up and down and actually you can

00:19:35,610 --> 00:19:41,070
train the same so you could use the same

00:19:37,970 --> 00:19:43,500
model here to actually add more classes

00:19:41,070 --> 00:19:45,470
so you could potentially train multiple

00:19:43,500 --> 00:19:48,380
classes to understand multiple types of

00:19:45,470 --> 00:19:50,550
operations of of your device and

00:19:48,380 --> 00:19:52,260
obviously it's taking data from the

00:19:50,550 --> 00:19:54,000
accelerometer and making sense of that

00:19:52,260 --> 00:19:55,650
data and again data from an

00:19:54,000 --> 00:19:57,810
accelerometer is usually very messy and

00:19:55,650 --> 00:20:00,120
what it's what's interesting is actually

00:19:57,810 --> 00:20:01,470
this is able to make sense of it without

00:20:00,120 --> 00:20:04,259
actually much work I mean

00:20:01,470 --> 00:20:07,019
here is below a few minutes to be able

00:20:04,259 --> 00:20:09,080
to do this and get this with with this

00:20:07,019 --> 00:20:11,460
accuracy so I'm really impressed by

00:20:09,080 --> 00:20:13,379
their do we know they work do we not

00:20:11,460 --> 00:20:15,059
done and all this again is running

00:20:13,379 --> 00:20:18,090
affect effectively is running on

00:20:15,059 --> 00:20:21,620
tensorflow light micro and it's running

00:20:18,090 --> 00:20:26,490
in the end optimized on arm hardware

00:20:21,620 --> 00:20:32,850
okay so with that I go back to the

00:20:26,490 --> 00:20:34,200
slides here and so in summary I I really

00:20:32,850 --> 00:20:36,659
think that machine learning on

00:20:34,200 --> 00:20:39,120
constrained devices tiny Mel is actually

00:20:36,659 --> 00:20:42,330
happening now so it'd be interesting

00:20:39,120 --> 00:20:45,840
really to understand all the use cases

00:20:42,330 --> 00:20:49,350
that could be unlocked in in the world

00:20:45,840 --> 00:20:50,519
of drones I'd be really curious to to

00:20:49,350 --> 00:20:52,590
understand you know the different things

00:20:50,519 --> 00:20:55,019
that the different places where you

00:20:52,590 --> 00:20:57,509
think you could utilize this type of

00:20:55,019 --> 00:20:59,909
machine learning and and really reach

00:20:57,509 --> 00:21:01,769
out and let's collaborate I'm excited by

00:20:59,909 --> 00:21:04,740
but what's possible and I'm really

00:21:01,769 --> 00:21:06,090
excited to hear from you guys what what

00:21:04,740 --> 00:21:08,789
you guys have in mind and what kind of

00:21:06,090 --> 00:21:11,820
stuff you think could be done with this

00:21:08,789 --> 00:21:15,240
type of technology and last but not

00:21:11,820 --> 00:21:17,129
least there is the link here if you want

00:21:15,240 --> 00:21:18,419
to learn more about the different

00:21:17,129 --> 00:21:20,759
partners of what they're doing there is

00:21:18,419 --> 00:21:24,299
we're running some vector AI tech talks

00:21:20,759 --> 00:21:28,039
and that you can follow by clicking on

00:21:24,299 --> 00:21:30,960
the link okay that's all so I I think

00:21:28,039 --> 00:21:32,460
thank you yeah we can go to questions

00:21:30,960 --> 00:21:35,250
that was really good

00:21:32,460 --> 00:21:36,899
I have a few questions do you mind stop

00:21:35,250 --> 00:21:43,019
sharing your screen and now is Gerald's

00:21:36,899 --> 00:21:46,220
questions guillotines sure awesome so

00:21:43,019 --> 00:21:48,509
I'm gonna just drop the questions here

00:21:46,220 --> 00:21:51,289
thanks to the volunteers that put them

00:21:48,509 --> 00:21:53,549
together and they put like a beanie to

00:21:51,289 --> 00:21:56,009
really help us with those questions by

00:21:53,549 --> 00:21:57,720
David really added since the morning

00:21:56,009 --> 00:21:59,820
this hand roll so we have a few

00:21:57,720 --> 00:22:02,399
questions here feel free to pick the

00:21:59,820 --> 00:22:04,049
ones that you - that you like the most

00:22:02,399 --> 00:22:06,529
I don't think we have time for more than

00:22:04,049 --> 00:22:06,529
two or three

00:22:10,410 --> 00:22:15,360
yeah I'm just looking at the question so

00:22:13,200 --> 00:22:16,800
okay so there is a I'll just pick the

00:22:15,360 --> 00:22:18,120
first two to start with so the first one

00:22:16,800 --> 00:22:19,650
is what is the difference between

00:22:18,120 --> 00:22:22,050
embedded machine learning and running

00:22:19,650 --> 00:22:24,030
running the machine learning in an SOC

00:22:22,050 --> 00:22:26,070
so okay we're talking about the same

00:22:24,030 --> 00:22:28,050
thing it depends how big your SOC is how

00:22:26,070 --> 00:22:31,230
capable your SOC is so if you're

00:22:28,050 --> 00:22:33,360
thinking about Linux enabled SOC like a

00:22:31,230 --> 00:22:35,970
Raspberry Pi for example that has a

00:22:33,360 --> 00:22:39,480
Linux enable as to see you're usually

00:22:35,970 --> 00:22:41,130
running more beefier models what we're

00:22:39,480 --> 00:22:44,190
talking about here is the ability to run

00:22:41,130 --> 00:22:45,870
these models down to a few milli watts

00:22:44,190 --> 00:22:49,050
of power so the ability to run these

00:22:45,870 --> 00:22:51,059
models in very constrained devices and

00:22:49,050 --> 00:22:53,880
the ability to do it effectively and

00:22:51,059 --> 00:22:56,000
efficiently and so that's I guess that's

00:22:53,880 --> 00:22:59,190
the difference is you know SOC is are

00:22:56,000 --> 00:23:01,679
there is a wide range of SOC based on

00:22:59,190 --> 00:23:03,840
arm as I showed a graph at the beginning

00:23:01,679 --> 00:23:08,160
there are SOC is the amount different

00:23:03,840 --> 00:23:10,559
types of of CPUs and what what I think

00:23:08,160 --> 00:23:12,750
is really exciting is the ability to run

00:23:10,559 --> 00:23:15,390
machine learning on they're really tiny

00:23:12,750 --> 00:23:18,960
and so C's or there's really tiny CPUs

00:23:15,390 --> 00:23:21,240
the cortex M and C CPUs so the ones that

00:23:18,960 --> 00:23:23,010
I guess to put into context of drones

00:23:21,240 --> 00:23:24,990
the ones that usually are on the flight

00:23:23,010 --> 00:23:27,390
controller itself so they the SOC and

00:23:24,990 --> 00:23:29,160
the flight controller or SOC is that

00:23:27,390 --> 00:23:32,940
that could be attached to the sensor

00:23:29,160 --> 00:23:34,710
itself now I go for this second question

00:23:32,940 --> 00:23:38,010
as well can you train on small devices

00:23:34,710 --> 00:23:40,020
so in there is some partners that are

00:23:38,010 --> 00:23:42,950
looking at that and are starting to do

00:23:40,020 --> 00:23:46,080
some of the training on the devices and

00:23:42,950 --> 00:23:47,820
right now it's it's probably best if you

00:23:46,080 --> 00:23:50,640
don't do the training on the device but

00:23:47,820 --> 00:23:52,830
you do the training of the you know

00:23:50,640 --> 00:23:56,250
prior to the device and what you could

00:23:52,830 --> 00:23:58,320
do is is feed back some of your data to

00:23:56,250 --> 00:24:00,929
potentially an external source so you

00:23:58,320 --> 00:24:02,730
could refine the model and potentially

00:24:00,929 --> 00:24:05,670
redeploy a better model in the future

00:24:02,730 --> 00:24:07,980
that's that's a the easiest workflow

00:24:05,670 --> 00:24:09,960
today but things are moving very fast

00:24:07,980 --> 00:24:11,580
and I you know I can see how the

00:24:09,960 --> 00:24:15,690
training could start happening on on

00:24:11,580 --> 00:24:19,030
device as well do I have time for

00:24:15,690 --> 00:24:25,380
another one okay

00:24:19,030 --> 00:24:25,380
and so I'm just reading the questions

00:24:31,230 --> 00:24:35,770
okay so no yeah

00:24:33,880 --> 00:24:37,810
what's the wire through ml models we can

00:24:35,770 --> 00:24:40,030
use and embedded systems are their only

00:24:37,810 --> 00:24:43,690
computer vision models or are there more

00:24:40,030 --> 00:24:46,690
ml models we can use for example SVM for

00:24:43,690 --> 00:24:49,570
sensor fusion so the reality as I

00:24:46,690 --> 00:24:51,870
mentioned before is that it really

00:24:49,570 --> 00:24:54,370
depends on it

00:24:51,870 --> 00:24:56,200
understanding the size of the model and

00:24:54,370 --> 00:25:00,370
and you know there are some models are

00:24:56,200 --> 00:25:01,810
and quite there have a lot of operations

00:25:00,370 --> 00:25:04,150
and those are probably not the best

00:25:01,810 --> 00:25:06,400
models to run on really tiny devices but

00:25:04,150 --> 00:25:07,930
there are a lot of different models are

00:25:06,400 --> 00:25:10,060
being ported to the embedded devices

00:25:07,930 --> 00:25:12,520
right now I shared some of the links to

00:25:10,060 --> 00:25:14,110
some some links to some guides where you

00:25:12,520 --> 00:25:15,970
can see a bunch of different models so

00:25:14,110 --> 00:25:17,320
some die running like the one that I

00:25:15,970 --> 00:25:19,000
used today

00:25:17,320 --> 00:25:21,610
they're running fully connected models

00:25:19,000 --> 00:25:24,430
for vibration for example use cases or

00:25:21,610 --> 00:25:25,920
in general sensors like accelerometer x'

00:25:24,430 --> 00:25:29,320
and stuff like that and then there is

00:25:25,920 --> 00:25:31,900
cnn's and are being utilized a lot in

00:25:29,320 --> 00:25:33,250
computer vision another model so there

00:25:31,900 --> 00:25:35,530
is there is a lot of research around

00:25:33,250 --> 00:25:40,360
trying to port different types of models

00:25:35,530 --> 00:25:41,890
to embedded embedded devices and then

00:25:40,360 --> 00:25:44,530
I'll just go with the last one can I run

00:25:41,890 --> 00:25:49,330
tensorflow light on a name and a sorry

00:25:44,530 --> 00:25:52,000
NXP I'm x8 and me me and so tensor for

00:25:49,330 --> 00:25:56,410
light could be run on multiple platforms

00:25:52,000 --> 00:25:58,480
if you go to the tensor flow light micro

00:25:56,410 --> 00:26:01,600
website there is a list of supported

00:25:58,480 --> 00:26:03,910
devices and and there is you know

00:26:01,600 --> 00:26:06,730
obviously there are ways of porting that

00:26:03,910 --> 00:26:08,410
to different platforms so if you know if

00:26:06,730 --> 00:26:10,330
it's not ported to the device that

00:26:08,410 --> 00:26:12,970
you're using today you can you can do

00:26:10,330 --> 00:26:15,640
that and don't forget that they I'm x8

00:26:12,970 --> 00:26:18,160
for example has got most people CPUs so

00:26:15,640 --> 00:26:20,740
some of them will run Linux and will run

00:26:18,160 --> 00:26:22,180
containers and will run you know will

00:26:20,740 --> 00:26:24,130
give you the ability to run machine

00:26:22,180 --> 00:26:25,990
learning in a different way and then

00:26:24,130 --> 00:26:28,840
there are also court exams on there so

00:26:25,990 --> 00:26:32,340
you could run and potentially tiny ml on

00:26:28,840 --> 00:26:32,340
on those court exams

00:26:33,229 --> 00:26:39,739
Thank You Alessandra thank you there's a

00:26:36,440 --> 00:26:42,109
pleasure all right

00:26:39,739 --> 00:26:43,759
hey guys welcome back to the peaks for

00:26:42,109 --> 00:26:45,169
developers summit your host here at

00:26:43,759 --> 00:26:46,309
Ramon watch it

00:26:45,169 --> 00:26:49,609
thanks folks for your help with the

00:26:46,309 --> 00:26:51,349
questions team effort right Thank You

00:26:49,609 --> 00:26:53,359
lissandra again super cool demo please

00:26:51,349 --> 00:26:55,700
check the link on slack with all of us

00:26:53,359 --> 00:26:57,710
there's a lot of more questions for

00:26:55,700 --> 00:27:02,979
Alessandra so maybe you want to join us

00:26:57,710 --> 00:27:02,979

YouTube URL: https://www.youtube.com/watch?v=94myqaMrxmI


