Title: Keynote 3: System Performance Analysis Methodologies - Brendan Gregg
Publication date: 2019-10-16
Playlist: EuroBSDcon 2017, France
Description: 
	Keynote 3: System Performance Analysis Methodologies - Brendan Gregg
Captions: 
	00:00:05,060 --> 00:00:11,460
imagine it's July in 1969 and the Apollo

00:00:09,059 --> 00:00:15,240
11 lunar module is descending to make

00:00:11,460 --> 00:00:18,720
the historic first landing 5 minutes

00:00:15,240 --> 00:00:22,500
into the descent at 6,000 feet there is

00:00:18,720 --> 00:00:25,590
a problem a 1202 program alarm some of

00:00:22,500 --> 00:00:27,630
you may know the details of this but the

00:00:25,590 --> 00:00:31,320
1202 program alarm is actually a

00:00:27,630 --> 00:00:33,600
performance issue if this performance

00:00:31,320 --> 00:00:37,410
issue is not diagnosed quickly Neil

00:00:33,600 --> 00:00:39,390
Armstrong must abort the descent as he

00:00:37,410 --> 00:00:40,910
later said he wasn't there to practice

00:00:39,390 --> 00:00:43,200
aborts

00:00:40,910 --> 00:00:45,450
fortunately one engineer had seen her

00:00:43,200 --> 00:00:49,260
perform and was able to give the

00:00:45,450 --> 00:00:52,160
go-ahead for the landing imagine the

00:00:49,260 --> 00:00:55,250
Apollo lunar module guidance computer is

00:00:52,160 --> 00:00:58,800
the system that you are performance

00:00:55,250 --> 00:00:59,940
analyzing how do you begin to understand

00:00:58,800 --> 00:01:02,219
performance on that system

00:00:59,940 --> 00:01:04,650
what methodologies or process would you

00:01:02,219 --> 00:01:08,939
go through to get to the bottom of that

00:01:04,650 --> 00:01:14,280
alarm what I like to start with for any

00:01:08,939 --> 00:01:16,140
system is a functional diagram and

00:01:14,280 --> 00:01:17,909
here's a functional diagram that's from

00:01:16,140 --> 00:01:20,610
the Apollo era

00:01:17,909 --> 00:01:23,070
I've actually annotated a little bit

00:01:20,610 --> 00:01:26,759
because was missing a few parts of the

00:01:23,070 --> 00:01:30,479
computer so it was missing the erasable

00:01:26,759 --> 00:01:35,310
memory which was 2048 words of core

00:01:30,479 --> 00:01:41,820
memory the 36 Killah words of core rote

00:01:35,310 --> 00:01:44,040
memory and there's also the VAX sets for

00:01:41,820 --> 00:01:47,909
vector accumulator and the cost set area

00:01:44,040 --> 00:01:50,009
for registers for swapping out tasks it

00:01:47,909 --> 00:01:52,619
was a really interesting and pioneering

00:01:50,009 --> 00:01:56,850
computer so the lunar module guidance

00:01:52,619 --> 00:01:58,320
computer was a time sharing system I'd

00:01:56,850 --> 00:01:59,610
like to start with functional diagrams

00:01:58,320 --> 00:02:03,420
because then I can work through the

00:01:59,610 --> 00:02:05,159
blocks and figure out what makes sense

00:02:03,420 --> 00:02:07,409
and in some ways that's the first method

00:02:05,159 --> 00:02:09,090
methodology I can tell you and from my

00:02:07,409 --> 00:02:10,950
time as a performance consultant this

00:02:09,090 --> 00:02:12,959
always worked well to tell the customer

00:02:10,950 --> 00:02:15,390
draw up the functional diagram for your

00:02:12,959 --> 00:02:16,890
environment and you'll be surprised or

00:02:15,390 --> 00:02:18,900
maybe not surprised how many times no

00:02:16,890 --> 00:02:20,730
one had done that and when they draw the

00:02:18,900 --> 00:02:24,150
functional diagrams and problems are

00:02:20,730 --> 00:02:26,700
evident also useful for getting into

00:02:24,150 --> 00:02:30,090
more detail so return to this example

00:02:26,700 --> 00:02:34,019
we'll see how we can analyze that

00:02:30,090 --> 00:02:39,390
computer as well as any system I work at

00:02:34,019 --> 00:02:43,890
Netflix and yes this is regions where

00:02:39,390 --> 00:02:49,140
Netflix is available taken pretty good

00:02:43,890 --> 00:02:52,590
so far we have Linux Ubuntu on the cloud

00:02:49,140 --> 00:02:54,540
and we have FreeBSD on our CDN the

00:02:52,590 --> 00:02:56,790
easiest way to describe this is when you

00:02:54,540 --> 00:02:59,400
first log in to Netflix and you

00:02:56,790 --> 00:03:02,099
authenticate and browse you're on the

00:02:59,400 --> 00:03:04,230
Linux cloud they say don't AWS and when

00:03:02,099 --> 00:03:07,200
you hit play you're now coming from the

00:03:04,230 --> 00:03:09,599
FreeBSD CDN and Sam finder reports the

00:03:07,200 --> 00:03:12,810
show that we're over 33% of the internet

00:03:09,599 --> 00:03:18,349
traffic in the u.s. at night so very

00:03:12,810 --> 00:03:20,280
popular now as bed graph the methodology

00:03:18,349 --> 00:03:22,800
performance methodologies have done this

00:03:20,280 --> 00:03:26,400
for a long time and system performance

00:03:22,800 --> 00:03:29,580
up to the 90s was for close source

00:03:26,400 --> 00:03:31,019
universes and applications and it's

00:03:29,580 --> 00:03:33,599
where the vendor would give you manuals

00:03:31,019 --> 00:03:35,159
a long time ago I did max VMs

00:03:33,599 --> 00:03:37,440
administration so this is 12 feet of

00:03:35,159 --> 00:03:39,900
manuals and you would read the manuals

00:03:37,440 --> 00:03:42,019
and you'd assume that the vendor had

00:03:39,900 --> 00:03:44,549
come up with the best metrics possible

00:03:42,019 --> 00:03:48,900
and it was our job to interpret the

00:03:44,549 --> 00:03:50,610
metrics the the vendor has provided now

00:03:48,900 --> 00:03:52,439
some problems is the vendor may not

00:03:50,610 --> 00:03:53,970
provide the best metrics quite often

00:03:52,439 --> 00:03:56,610
customers are running workloads that

00:03:53,970 --> 00:03:58,590
they haven't really tested themselves

00:03:56,610 --> 00:04:01,860
and they haven't really thought about in

00:03:58,590 --> 00:04:06,569
detail there are blind spots and so we

00:04:01,860 --> 00:04:08,250
had to infer rather than measure I used

00:04:06,569 --> 00:04:12,180
to do performance in this era when I

00:04:08,250 --> 00:04:13,769
first started and you could be quite

00:04:12,180 --> 00:04:17,370
successful if you could read the tea

00:04:13,769 --> 00:04:19,949
leaves from the output of vmstat and MP

00:04:17,370 --> 00:04:21,269
pS and various tools and figure out what

00:04:19,949 --> 00:04:24,720
the colonel was doing even though the

00:04:21,269 --> 00:04:27,030
tools never said that today it's really

00:04:24,720 --> 00:04:28,770
different it's really exciting

00:04:27,030 --> 00:04:35,580
almost everything we expect is

00:04:28,770 --> 00:04:39,090
open-source now and we can now do custom

00:04:35,580 --> 00:04:40,800
metrics so if it's open-source I can

00:04:39,090 --> 00:04:42,360
take the source code and write in some

00:04:40,800 --> 00:04:44,490
metrics or instrumentation I need some

00:04:42,360 --> 00:04:46,440
advanced logging some printf statements

00:04:44,490 --> 00:04:48,840
and then I can run a custom kernel or a

00:04:46,440 --> 00:04:51,270
custom application but we also live in

00:04:48,840 --> 00:04:53,070
the era of dynamic tracing so any

00:04:51,270 --> 00:04:57,960
software at all like an instrument and

00:04:53,070 --> 00:04:59,550
then get metrics out it's now more

00:04:57,960 --> 00:05:02,400
useful than ever to think about

00:04:59,550 --> 00:05:03,960
methodologies so what do what do we do

00:05:02,400 --> 00:05:08,070
with these awesome powers how do we

00:05:03,960 --> 00:05:09,620
explore a system and understand it one

00:05:08,070 --> 00:05:11,850
of the problems of dynamic tracing is

00:05:09,620 --> 00:05:13,199
since you can instrument all software if

00:05:11,850 --> 00:05:14,789
you think about how many functions are

00:05:13,199 --> 00:05:16,770
in a body of software it's tens of

00:05:14,789 --> 00:05:18,330
thousands and you can see that arguments

00:05:16,770 --> 00:05:21,030
and you can look at latency you can do

00:05:18,330 --> 00:05:23,030
histograms you could really drown in

00:05:21,030 --> 00:05:25,740
metrics there's a lot of metrics

00:05:23,030 --> 00:05:27,360
methodologies help you help guide you

00:05:25,740 --> 00:05:29,039
through those metrics so that you can

00:05:27,360 --> 00:05:33,030
put your fingers on the ones that are

00:05:29,039 --> 00:05:34,979
most important I was heavily involved

00:05:33,030 --> 00:05:36,720
with the launch of dtrace and there was

00:05:34,979 --> 00:05:38,490
a big problem we saw addy trace when

00:05:36,720 --> 00:05:39,870
that was launched it was a great

00:05:38,490 --> 00:05:43,500
superpower but what do we do with that

00:05:39,870 --> 00:05:45,240
super villain so it's a different type

00:05:43,500 --> 00:05:46,289
of thinking now instead of assuming the

00:05:45,240 --> 00:05:49,530
vendor is going to give you the best

00:05:46,289 --> 00:05:53,310
metrics now we think of the questions we

00:05:49,530 --> 00:05:55,229
want asked and it's opposite to being

00:05:53,310 --> 00:05:57,539
provided the answers to start with and

00:05:55,229 --> 00:05:58,889
then trying to figure it out now it's

00:05:57,539 --> 00:06:03,229
about the questions what do you really

00:05:58,889 --> 00:06:03,229
want answered from the systems

00:06:04,290 --> 00:06:09,560
some 80 methodologies to start with so

00:06:06,660 --> 00:06:12,390
you can understand methodologies and the

00:06:09,560 --> 00:06:15,270
first would be what I call the

00:06:12,390 --> 00:06:17,400
streetlight ante method and this comes

00:06:15,270 --> 00:06:20,130
from a parable about a drunk who's

00:06:17,400 --> 00:06:23,010
looking for his keys under a streetlight

00:06:20,130 --> 00:06:25,950
and a police officer finds the drunk and

00:06:23,010 --> 00:06:27,480
asks why what are you doing and he says

00:06:25,950 --> 00:06:31,080
I've lost my keys I'm looking for them

00:06:27,480 --> 00:06:32,550
and the police officer asks why you look

00:06:31,080 --> 00:06:34,710
did you lose them under the streetlight

00:06:32,550 --> 00:06:37,800
and the drunk says no but that's where

00:06:34,710 --> 00:06:39,690
the light is best and I see this quite

00:06:37,800 --> 00:06:42,360
often in performance analysis people

00:06:39,690 --> 00:06:43,980
will run talk because they always run

00:06:42,360 --> 00:06:45,930
top and that's familiar

00:06:43,980 --> 00:06:46,920
instead of using more advanced tools or

00:06:45,930 --> 00:06:49,080
tool that's appropriate for that

00:06:46,920 --> 00:06:50,070
subsystem they'll run what they find on

00:06:49,080 --> 00:06:54,380
the internet they'll run things at

00:06:50,070 --> 00:06:57,110
random sometimes works but it can really

00:06:54,380 --> 00:07:00,780
waste time you can go around in circles

00:06:57,110 --> 00:07:04,620
you can miss things because there are

00:07:00,780 --> 00:07:06,180
blind spots there that was an

00:07:04,620 --> 00:07:08,490
observational methodology this is an

00:07:06,180 --> 00:07:10,290
experimental methodology the truck mania

00:07:08,490 --> 00:07:11,460
method and this is where you tune things

00:07:10,290 --> 00:07:13,530
at random until the problem goes away

00:07:11,460 --> 00:07:14,880
just to give these methodologies and

00:07:13,530 --> 00:07:15,540
names so that you can recognize it in

00:07:14,880 --> 00:07:20,400
the workplace

00:07:15,540 --> 00:07:21,870
I once came to work and the application

00:07:20,400 --> 00:07:23,490
was working on have been the

00:07:21,870 --> 00:07:25,950
configuration had been changed quite a

00:07:23,490 --> 00:07:27,720
lot and I was told Brendan we had to

00:07:25,950 --> 00:07:28,770
change the comfy was performing badly in

00:07:27,720 --> 00:07:30,990
the middle of the night we didn't wake

00:07:28,770 --> 00:07:33,360
you up by the way we used the drunk man

00:07:30,990 --> 00:07:35,220
ante method and that was actually useful

00:07:33,360 --> 00:07:37,080
because immediately and I understood why

00:07:35,220 --> 00:07:39,510
they picked the crazy metrics the two

00:07:37,080 --> 00:07:41,820
nobles they picked they just guessed

00:07:39,510 --> 00:07:46,410
and so they've a current debug

00:07:41,820 --> 00:07:48,150
themselves myself and understand another

00:07:46,410 --> 00:07:49,470
18 methodology I'd like to mention I'd

00:07:48,150 --> 00:07:52,860
call the blame someone else eighty

00:07:49,470 --> 00:07:54,510
method so you find something that is not

00:07:52,860 --> 00:07:57,270
responsible for you and then you

00:07:54,510 --> 00:08:00,450
hypothesize the problem must be that

00:07:57,270 --> 00:08:02,520
component go talk to that tape and so

00:08:00,450 --> 00:08:04,290
I've seen this many times where people

00:08:02,520 --> 00:08:07,500
with the networkers blinked it must be

00:08:04,290 --> 00:08:08,670
the network must be retransmits or

00:08:07,500 --> 00:08:12,090
there's something wrong with the

00:08:08,670 --> 00:08:14,610
microwave link of this makes bgp issue

00:08:12,090 --> 00:08:17,460
there talk to them they talk to the DNS

00:08:14,610 --> 00:08:22,199
maybe's deenis that's an anti

00:08:17,460 --> 00:08:24,360
methodology another one I like it's a

00:08:22,199 --> 00:08:26,520
traffic light angie method and that's

00:08:24,360 --> 00:08:28,439
where people traffic lights are easy to

00:08:26,520 --> 00:08:30,270
interpret red is bad and green is good

00:08:28,439 --> 00:08:32,310
and some people like to create these

00:08:30,270 --> 00:08:36,169
dashboards where they put colors on

00:08:32,310 --> 00:08:39,599
everything now colors are good for

00:08:36,169 --> 00:08:41,820
objective metrics so errors so something

00:08:39,599 --> 00:08:44,250
is actually broken a disk has got a

00:08:41,820 --> 00:08:45,089
failure you can color it red if it

00:08:44,250 --> 00:08:47,820
doesn't have a failure

00:08:45,089 --> 00:08:51,630
perhaps green but for performance

00:08:47,820 --> 00:08:55,380
analysis these are often subjective

00:08:51,630 --> 00:08:57,480
metrics so I on some latency and what

00:08:55,380 --> 00:09:02,880
latency might be good for one person

00:08:57,480 --> 00:09:04,140
who's running a chat server online may

00:09:02,880 --> 00:09:07,230
be different for someone who's running a

00:09:04,140 --> 00:09:09,000
high frequency trading application and I

00:09:07,230 --> 00:09:10,890
upset how do you even say what I am says

00:09:09,000 --> 00:09:13,740
good or bad is a thousand i obscured

00:09:10,890 --> 00:09:15,480
this no bad really depends on your point

00:09:13,740 --> 00:09:16,649
of view so I don't like any

00:09:15,480 --> 00:09:20,070
methodologies where they try and put

00:09:16,649 --> 00:09:22,230
colors on subjective metrics it's okay

00:09:20,070 --> 00:09:24,800
for objective metrics where something is

00:09:22,230 --> 00:09:28,890
broken and something is not broken

00:09:24,800 --> 00:09:35,130
so that's a few anti methodologies now

00:09:28,890 --> 00:09:36,600
for methodologies I've been collecting

00:09:35,130 --> 00:09:39,450
them

00:09:36,600 --> 00:09:42,210
I published a lot of them for the first

00:09:39,450 --> 00:09:46,290
time in my last book systems performance

00:09:42,210 --> 00:09:48,420
and I hope that people didn't find this

00:09:46,290 --> 00:09:50,250
too crazy because no one had really

00:09:48,420 --> 00:09:52,260
thoroughly explore explored

00:09:50,250 --> 00:09:54,630
methodologies like this before there had

00:09:52,260 --> 00:09:58,290
been some so method I was was published

00:09:54,630 --> 00:10:00,360
for article analysis and there's some

00:09:58,290 --> 00:10:02,640
methodologies in Rodge drains out of

00:10:00,360 --> 00:10:04,710
compute performance analysis but I

00:10:02,640 --> 00:10:09,120
really study lots and lots of them I I

00:10:04,710 --> 00:10:15,090
think it's extremely useful and I'll

00:10:09,120 --> 00:10:16,980
pick a few to go through here so for

00:10:15,090 --> 00:10:19,140
systems engineers these are ways to

00:10:16,980 --> 00:10:21,600
analyze an unfamiliar system or

00:10:19,140 --> 00:10:24,360
application and if you are the developer

00:10:21,600 --> 00:10:27,750
you can have your dashboard support the

00:10:24,360 --> 00:10:29,610
methodologies so these are my toolbox

00:10:27,750 --> 00:10:32,010
these methodologies they also work

00:10:29,610 --> 00:10:34,440
across any operating system and so I've

00:10:32,010 --> 00:10:36,060
given this a talk where of covered

00:10:34,440 --> 00:10:38,340
methodologies before but for different

00:10:36,060 --> 00:10:41,730
operating systems and I was able to put

00:10:38,340 --> 00:10:43,890
them to BSD for this talk without too

00:10:41,730 --> 00:10:46,620
much difficulty and the hard part is

00:10:43,890 --> 00:10:52,950
knowing what to do and that's that

00:10:46,620 --> 00:10:54,480
writing up with the methodology is the

00:10:52,950 --> 00:10:58,970
first one is the problem statement

00:10:54,480 --> 00:11:01,200
method and I learn about this from a

00:10:58,970 --> 00:11:02,670
support team engineering support team

00:11:01,200 --> 00:11:05,040
this is the first thing that they would

00:11:02,670 --> 00:11:06,150
ask a customer over the phone what makes

00:11:05,040 --> 00:11:08,100
you think there is a performance problem

00:11:06,150 --> 00:11:11,160
has the system ever performed well and

00:11:08,100 --> 00:11:13,050
so on and they're able to diagnose

00:11:11,160 --> 00:11:15,510
performance issues without even logging

00:11:13,050 --> 00:11:18,570
into the system and it's always worth

00:11:15,510 --> 00:11:22,500
asking when I was a system administrator

00:11:18,570 --> 00:11:24,630
once I had a database administration

00:11:22,500 --> 00:11:26,250
team tell me Brendan this database is

00:11:24,630 --> 00:11:29,010
performing badly you must log in and

00:11:26,250 --> 00:11:30,480
debug it and fix it immediately I was

00:11:29,010 --> 00:11:32,880
like wow alright let me have a look and

00:11:30,480 --> 00:11:35,250
so I run the instat and I look at the

00:11:32,880 --> 00:11:37,440
summary since boot and I say it's always

00:11:35,250 --> 00:11:39,810
been on fire since it since it said is

00:11:37,440 --> 00:11:41,250
building many many days ago it's like

00:11:39,810 --> 00:11:42,630
well that's strange because now they're

00:11:41,250 --> 00:11:43,950
telling me and now I look at I

00:11:42,630 --> 00:11:46,500
understand I look at the some recent

00:11:43,950 --> 00:11:48,900
boot and everywhere I look I don't see

00:11:46,500 --> 00:11:50,200
any changes to the system so I'm trying

00:11:48,900 --> 00:11:52,900
to get my head around why

00:11:50,200 --> 00:11:54,220
why would it be bad now when the disks

00:11:52,900 --> 00:11:57,100
have always been this busy and the

00:11:54,220 --> 00:11:59,260
seekers have always been this busy and

00:11:57,100 --> 00:12:02,650
so I finally remembered maybe I should

00:11:59,260 --> 00:12:04,840
ask has this system ever performed well

00:12:02,650 --> 00:12:05,830
and the answer was no it's always being

00:12:04,840 --> 00:12:08,500
like that it's been like that for the

00:12:05,830 --> 00:12:10,690
weeks we only thought about asking you

00:12:08,500 --> 00:12:12,460
but if that's the way they asked me was

00:12:10,690 --> 00:12:14,620
as though something had changed like

00:12:12,460 --> 00:12:17,020
something broke and I must dive in and

00:12:14,620 --> 00:12:17,710
debug it so after that I always

00:12:17,020 --> 00:12:19,780
remembered

00:12:17,710 --> 00:12:23,500
has it ever performed well has always

00:12:19,780 --> 00:12:25,180
been like this can the problem be

00:12:23,500 --> 00:12:27,550
described in terms of latency it's

00:12:25,180 --> 00:12:29,530
pretty useful and people often will say

00:12:27,550 --> 00:12:31,660
my CPU utilization is high that's a

00:12:29,530 --> 00:12:33,700
problem is it a problem it might be good

00:12:31,660 --> 00:12:36,820
you're getting a return of investment so

00:12:33,700 --> 00:12:40,300
coming up with a more metric that makes

00:12:36,820 --> 00:12:42,820
sense to reflect customer pain does the

00:12:40,300 --> 00:12:45,580
problem affect other people or apps they

00:12:42,820 --> 00:12:46,090
say well latency for this application is

00:12:45,580 --> 00:12:48,040
bad

00:12:46,090 --> 00:12:50,140
it's like lengthy for every application

00:12:48,040 --> 00:12:53,830
I run is bad because the Wi-Fi is is

00:12:50,140 --> 00:12:55,570
down further for their office and also

00:12:53,830 --> 00:12:59,460
checking what is the environment so

00:12:55,570 --> 00:13:01,900
basic stuff but always worth doing a

00:12:59,460 --> 00:13:03,880
functional diagram method may mention

00:13:01,900 --> 00:13:05,530
this at the start and that's where you

00:13:03,880 --> 00:13:07,570
want a functional diagram you trace the

00:13:05,530 --> 00:13:08,950
components in the data path and then for

00:13:07,570 --> 00:13:10,990
each component you check performance

00:13:08,950 --> 00:13:12,640
however that works I've got a nice

00:13:10,990 --> 00:13:15,250
picture here if they're up a network

00:13:12,640 --> 00:13:18,940
from 1969 you can imagine if you're told

00:13:15,250 --> 00:13:22,240
the internet is slow back in 1969 you

00:13:18,940 --> 00:13:23,710
could break it up into only a handful of

00:13:22,240 --> 00:13:25,900
pieces and then go through them one by

00:13:23,710 --> 00:13:28,090
one and actually brute cause the slow

00:13:25,900 --> 00:13:29,290
part but that's what the functional

00:13:28,090 --> 00:13:30,640
diagram method is about it's about

00:13:29,290 --> 00:13:38,740
breaking a big problem into smaller

00:13:30,640 --> 00:13:41,650
parts workload analysis so this is also

00:13:38,740 --> 00:13:43,270
known as top-down analysis this is where

00:13:41,650 --> 00:13:46,050
I begin with the workload that's applied

00:13:43,270 --> 00:13:48,100
to the system and then I drill down

00:13:46,050 --> 00:13:49,360
what's happening at the application

00:13:48,100 --> 00:13:51,220
level what's happening at the library

00:13:49,360 --> 00:13:53,110
level what's happening for system calls

00:13:51,220 --> 00:13:57,880
and the Carnales going down to hardware

00:13:53,110 --> 00:13:59,470
and trying to see if there is a some

00:13:57,880 --> 00:14:02,260
requests that are performing badly the

00:13:59,470 --> 00:14:03,790
application level then break it down to

00:14:02,260 --> 00:14:05,350
what library calls I have

00:14:03,790 --> 00:14:06,940
what system calls are happening is the

00:14:05,350 --> 00:14:08,590
latency in the system calls or is these

00:14:06,940 --> 00:14:10,690
library calls was just in the

00:14:08,590 --> 00:14:12,280
application code if it's in the system

00:14:10,690 --> 00:14:14,710
calls then what is the system call and

00:14:12,280 --> 00:14:17,440
we're doing some reads to a file system

00:14:14,710 --> 00:14:19,620
and then break that apart and so

00:14:17,440 --> 00:14:23,710
drilling down from top to the bottom

00:14:19,620 --> 00:14:25,180
it's useful because when you do this

00:14:23,710 --> 00:14:27,070
methodology you're beginning with the

00:14:25,180 --> 00:14:30,370
application context so you may begin

00:14:27,070 --> 00:14:32,530
with this is the request that makes

00:14:30,370 --> 00:14:35,760
customers unhappy it has high latency

00:14:32,530 --> 00:14:39,310
and then as you drill down you can then

00:14:35,760 --> 00:14:44,020
provide system metrics in the context of

00:14:39,310 --> 00:14:45,550
that application request can't be

00:14:44,020 --> 00:14:48,090
difficult to deep from application to

00:14:45,550 --> 00:14:48,090
resource there

00:14:48,210 --> 00:14:52,450
well the characterization which is

00:14:51,100 --> 00:14:54,610
actually at the top of that the workload

00:14:52,450 --> 00:14:56,110
applied is its own methodology which

00:14:54,610 --> 00:14:58,990
I've used to solve many many problems

00:14:56,110 --> 00:15:02,020
and this is where you need to not think

00:14:58,990 --> 00:15:03,730
about the resulting performance and you

00:15:02,020 --> 00:15:06,490
need to think about just what's the

00:15:03,730 --> 00:15:08,970
workload applied I used to look after

00:15:06,490 --> 00:15:11,790
storage appliance and many many times

00:15:08,970 --> 00:15:16,300
customers would would bench market by

00:15:11,790 --> 00:15:21,130
driving a crazy micro benchmark workload

00:15:16,300 --> 00:15:23,260
and saturate the system and just by

00:15:21,130 --> 00:15:24,670
characterizing the workload applied I

00:15:23,260 --> 00:15:26,620
didn't really need to look at the system

00:15:24,670 --> 00:15:28,210
just by looking at the millions of AI

00:15:26,620 --> 00:15:29,650
ups they are trying to drive out of

00:15:28,210 --> 00:15:32,050
something that was underpowered that

00:15:29,650 --> 00:15:34,270
wasn't supposed to do that much so like

00:15:32,050 --> 00:15:35,710
half a j-pod of tests instead of they

00:15:34,270 --> 00:15:38,500
are our full gear it's like you've

00:15:35,710 --> 00:15:40,810
picked the wrong system so always

00:15:38,500 --> 00:15:42,430
worthwhile to check just the workload

00:15:40,810 --> 00:15:44,410
that's applied to the system before you

00:15:42,430 --> 00:15:45,940
get into the resulting performance

00:15:44,410 --> 00:15:47,620
because the workload that's applied may

00:15:45,940 --> 00:15:49,810
be crazy if you've got a web server

00:15:47,620 --> 00:15:51,670
that's misbehaving while we look at the

00:15:49,810 --> 00:15:54,340
latency how you under a DDoS attack

00:15:51,670 --> 00:15:55,840
so that's workload characterization like

00:15:54,340 --> 00:15:58,120
since you know you're under a DDoS

00:15:55,840 --> 00:15:59,620
attack then you solve the Telos attack

00:15:58,120 --> 00:16:01,600
you don't need to no need to start

00:15:59,620 --> 00:16:04,500
tuning Apache intervals to make the DDoS

00:16:01,600 --> 00:16:04,500
attack go faster

00:16:06,770 --> 00:16:12,630
now for workload characterization to

00:16:10,290 --> 00:16:16,170
drill into this a little bit more for

00:16:12,630 --> 00:16:18,240
CPUs I can break it up into four

00:16:16,170 --> 00:16:21,600
components which understood here who

00:16:18,240 --> 00:16:24,180
which is who is using the CPUs why is

00:16:21,600 --> 00:16:26,220
the code paths in context what is would

00:16:24,180 --> 00:16:28,140
be CPU cycles and instructions what's it

00:16:26,220 --> 00:16:31,890
actually doing on the CPU and how is

00:16:28,140 --> 00:16:34,440
that changing over time and we can

00:16:31,890 --> 00:16:37,770
answer them fairly well so who is using

00:16:34,440 --> 00:16:38,880
CPU stop or similar metrics how is it

00:16:37,770 --> 00:16:42,810
changing over time there's lots of

00:16:38,880 --> 00:16:47,250
products that plot that why we can do CP

00:16:42,810 --> 00:16:50,250
flame grass CP profiling and then what

00:16:47,250 --> 00:16:52,740
are the CPU are doing we can use pmc

00:16:50,250 --> 00:16:54,480
stand on BST would you seek out flame

00:16:52,740 --> 00:16:55,830
graphs dimension moment and really

00:16:54,480 --> 00:16:59,700
understand that the low-level what the

00:16:55,830 --> 00:17:03,290
CPS are doing and you can do this who

00:16:59,700 --> 00:17:05,339
why how will what for any component I

00:17:03,290 --> 00:17:06,660
want to mention this one because if you

00:17:05,339 --> 00:17:10,380
look at most companies and monitoring

00:17:06,660 --> 00:17:12,630
products they don't do those they will

00:17:10,380 --> 00:17:14,880
do who's using the CPUs they can

00:17:12,630 --> 00:17:16,290
basically get top output and of course

00:17:14,880 --> 00:17:20,040
they'll plot things over time you'll get

00:17:16,290 --> 00:17:21,510
line graphs but fewer monitoring

00:17:20,040 --> 00:17:23,429
products will actually profile the code

00:17:21,510 --> 00:17:26,699
even though that's hugely useful to get

00:17:23,429 --> 00:17:29,460
a CP profile and barely anyone touches

00:17:26,699 --> 00:17:31,500
PMC's even a PMC's are becoming more and

00:17:29,460 --> 00:17:33,120
more useful because systems are getting

00:17:31,500 --> 00:17:34,590
faster and faster and bottled the

00:17:33,120 --> 00:17:37,320
bottleneck is moving to the memory

00:17:34,590 --> 00:17:39,630
subsystem and so memory stalls are big

00:17:37,320 --> 00:17:42,450
issue you need to have performance

00:17:39,630 --> 00:17:44,960
monitoring counters to understand it so

00:17:42,450 --> 00:17:44,960
we can do better

00:17:45,550 --> 00:17:51,770
resource analysis is another methodology

00:17:48,080 --> 00:17:54,860
this is where the analysis starts at the

00:17:51,770 --> 00:17:56,470
resources and what's its way up and you

00:17:54,860 --> 00:17:58,670
may be familiar of this this is how

00:17:56,470 --> 00:18:02,690
systems performance has traditionally

00:17:58,670 --> 00:18:04,640
been taught by old books on systems

00:18:02,690 --> 00:18:06,620
performance where there'll be a chapter

00:18:04,640 --> 00:18:08,990
on disks and a chapter on CPUs and a

00:18:06,620 --> 00:18:10,190
chapter on networking because they're

00:18:08,990 --> 00:18:13,790
starting with the hardware components

00:18:10,190 --> 00:18:14,960
and then trying to figure it and then

00:18:13,790 --> 00:18:16,190
trying to identify if there's a

00:18:14,960 --> 00:18:18,310
performance problem there and then

00:18:16,190 --> 00:18:20,600
working its way back to a profession

00:18:18,310 --> 00:18:22,430
it's okay it's another methodology

00:18:20,600 --> 00:18:24,050
I mean I'll use all the methodologies

00:18:22,430 --> 00:18:26,930
that there's no just one methodology

00:18:24,050 --> 00:18:29,720
I'll use on I'll pick everything it's

00:18:26,930 --> 00:18:32,870
one of the problems is false positives

00:18:29,720 --> 00:18:34,220
for this method quite often you can look

00:18:32,870 --> 00:18:37,490
at the disks and say the disks are on

00:18:34,220 --> 00:18:38,540
fire performance is really bad and as

00:18:37,490 --> 00:18:40,970
you work your way up the stack you

00:18:38,540 --> 00:18:42,890
realize that's right back flushing or

00:18:40,970 --> 00:18:44,450
it's read ahead the application has not

00:18:42,890 --> 00:18:45,890
actually blocked on the disk the

00:18:44,450 --> 00:18:47,720
filesystem is doing it asynchronously

00:18:45,890 --> 00:18:53,690
but they're just looking at the disk

00:18:47,720 --> 00:18:55,340
itself can be mislead they use method

00:18:53,690 --> 00:18:58,640
which is short for utilization

00:18:55,340 --> 00:19:00,860
saturation and errors and I came up with

00:18:58,640 --> 00:19:03,110
with this a long time ago it's proven

00:19:00,860 --> 00:19:07,610
very useful and that is where I will

00:19:03,110 --> 00:19:11,450
draw a functional diagram and then for

00:19:07,610 --> 00:19:13,730
each block and bus an interconnect on

00:19:11,450 --> 00:19:15,890
the functional diagram I just want those

00:19:13,730 --> 00:19:18,230
three metrics utilization saturation and

00:19:15,890 --> 00:19:20,000
errors this was great because there are

00:19:18,230 --> 00:19:22,520
lots of metrics if you look at a system

00:19:20,000 --> 00:19:25,130
there are hundreds of thousands of nests

00:19:22,520 --> 00:19:26,360
that money says or wherever you we can

00:19:25,130 --> 00:19:30,560
get the metrics that are there are way

00:19:26,360 --> 00:19:34,130
too many but this whittles it down just

00:19:30,560 --> 00:19:38,870
to maybe a few dozen once you iterate

00:19:34,130 --> 00:19:42,110
over the devices and also opposes

00:19:38,870 --> 00:19:43,760
questions for the system to answer so

00:19:42,110 --> 00:19:46,940
instead of starting with metrics and

00:19:43,760 --> 00:19:49,640
saying how how would these answer on the

00:19:46,940 --> 00:19:52,830
system yeah what what since these

00:19:49,640 --> 00:19:57,149
metrics may I start with my questions

00:19:52,830 --> 00:19:59,789
see DRAM utilization not in terms of

00:19:57,149 --> 00:20:01,649
volume but in terms of say sets of stall

00:19:59,789 --> 00:20:03,779
cycles or cycles where I'm actually

00:20:01,649 --> 00:20:04,950
talking to main memory well that's

00:20:03,779 --> 00:20:07,710
actually a difficult question now I

00:20:04,950 --> 00:20:10,200
hadn't eaten PMC's and you can see how

00:20:07,710 --> 00:20:11,460
this methodology will drive you to

00:20:10,200 --> 00:20:13,830
asking questions you may not normally

00:20:11,460 --> 00:20:18,899
ask because the sister tools don't make

00:20:13,830 --> 00:20:21,840
it easy which we can change I came up

00:20:18,899 --> 00:20:24,000
with a rosetta stone of for the use

00:20:21,840 --> 00:20:26,610
method it's on my homepage it's very

00:20:24,000 --> 00:20:28,919
very long there's only a fraction of it

00:20:26,610 --> 00:20:32,639
where I go through Linux FreeBSD Mac OS

00:20:28,919 --> 00:20:35,549
X for you CPU error is saturation

00:20:32,639 --> 00:20:39,029
utilization those three metrics are

00:20:35,549 --> 00:20:43,250
actually really useful for a just a

00:20:39,029 --> 00:20:46,590
high-level understanding of performance

00:20:43,250 --> 00:20:47,730
saturation or in fact the order in fact

00:20:46,590 --> 00:20:49,590
the order have printed them here is

00:20:47,730 --> 00:20:51,510
order I'll check them errors if

00:20:49,590 --> 00:20:54,510
something's broken its broken that's

00:20:51,510 --> 00:20:57,240
easy to interpret saturation is the next

00:20:54,510 --> 00:21:00,870
most useful metric to interpret so CP

00:20:57,240 --> 00:21:03,000
saturation means I have more threads to

00:21:00,870 --> 00:21:04,559
run than I have CPU so I have many

00:21:03,000 --> 00:21:07,080
threads in the runnable state they're

00:21:04,559 --> 00:21:09,539
waiting on the turn on CPUs that's bad

00:21:07,080 --> 00:21:10,679
there's a forms engineer if I fix it in

00:21:09,539 --> 00:21:11,639
a number of different ways I can improve

00:21:10,679 --> 00:21:14,610
performance

00:21:11,639 --> 00:21:18,269
so saturation after heiresses next most

00:21:14,610 --> 00:21:20,580
important utilization is lost so CPUs a

00:21:18,269 --> 00:21:23,639
50% utilized or eight percent utilized

00:21:20,580 --> 00:21:25,500
may not matter too much utilization is

00:21:23,639 --> 00:21:27,779
interesting in the longer term for

00:21:25,500 --> 00:21:30,389
capacity planning because you know once

00:21:27,779 --> 00:21:32,010
you get closer to 100% you're likely to

00:21:30,389 --> 00:21:33,860
have cueing and once you hit hundred

00:21:32,010 --> 00:21:36,480
percent you're likely to have saturation

00:21:33,860 --> 00:21:37,639
but I thought there is then saturation

00:21:36,480 --> 00:21:39,870
than utilization

00:21:37,639 --> 00:21:41,960
there's my FreeBSD one again I had a

00:21:39,870 --> 00:21:45,080
truncate this for the slide spring long

00:21:41,960 --> 00:21:47,899
but I can apply that to anything so I

00:21:45,080 --> 00:21:49,889
probably need to update this tool I

00:21:47,899 --> 00:21:52,049
applied it to UNIX seventh edition

00:21:49,889 --> 00:21:57,080
because that was fun and I figured I had

00:21:52,049 --> 00:21:59,909
to do all the different things

00:21:57,080 --> 00:22:03,450
I'm also apply applied it to the Apollo

00:21:59,909 --> 00:22:04,799
lunar module guidance computer so if you

00:22:03,450 --> 00:22:06,509
went through this so you're a

00:22:04,799 --> 00:22:09,109
performance engineer it's 1969

00:22:06,509 --> 00:22:11,429
you want to understand performance of it

00:22:09,109 --> 00:22:13,199
some boxes in the middle include the

00:22:11,429 --> 00:22:16,349
corset area the back sets a reasonable

00:22:13,199 --> 00:22:19,859
memory fixed memory the corset area was

00:22:16,349 --> 00:22:22,949
important that's where the threads that

00:22:19,859 --> 00:22:24,869
aren't on CPU their information will go

00:22:22,949 --> 00:22:29,669
and live in the closet area it would be

00:22:24,869 --> 00:22:34,019
able to hold several of these tasks

00:22:29,669 --> 00:22:35,699
concurrent tasks so if you started

00:22:34,019 --> 00:22:37,549
looking for metrics of the console area

00:22:35,699 --> 00:22:39,509
you're looking for say utilization

00:22:37,549 --> 00:22:42,839
utilization would be how many of those

00:22:39,509 --> 00:22:45,089
several slots are in use saturation

00:22:42,839 --> 00:22:47,519
would be if I filled up all seven slots

00:22:45,089 --> 00:22:51,479
it means I see if you can't handle any

00:22:47,519 --> 00:22:54,119
more concurrent tasks an error would

00:22:51,479 --> 00:22:56,669
mean if I try to launch a new task and

00:22:54,119 --> 00:22:59,339
it's like I'm full I can't run it so

00:22:56,669 --> 00:23:01,799
turns out the 1202 is the saturation era

00:22:59,339 --> 00:23:03,929
when the corset area is full the

00:23:01,799 --> 00:23:05,249
computer throws or 1202 alarm and that's

00:23:03,929 --> 00:23:07,829
what Neil Armstrong had during the

00:23:05,249 --> 00:23:10,579
descent its interest interest in sea

00:23:07,829 --> 00:23:14,099
waves because the rendezvous radar was

00:23:10,579 --> 00:23:17,699
turned on and misaligned and unlike in

00:23:14,099 --> 00:23:19,619
simulation it was adding an extra CPU

00:23:17,699 --> 00:23:21,239
load to the system they were expecting

00:23:19,619 --> 00:23:23,699
to have some Headroom during the descent

00:23:21,239 --> 00:23:26,759
but because the rendezvous radar kept

00:23:23,699 --> 00:23:30,269
interrupting the CPU to do calculations

00:23:26,759 --> 00:23:32,219
that they didn't strictly need the CPU

00:23:30,269 --> 00:23:34,409
went to a hundred percent or the closet

00:23:32,219 --> 00:23:37,639
area went 100 percent they got the 1202

00:23:34,409 --> 00:23:40,769
alarm the rendezvous rate I was tracking

00:23:37,639 --> 00:23:42,659
the command module so that if an abort

00:23:40,769 --> 00:23:45,749
happened they could plot the trajectory

00:23:42,659 --> 00:23:49,739
to return and so they could turn it off

00:23:45,749 --> 00:23:52,349
and still land back sentence the

00:23:49,739 --> 00:23:53,729
effector accumulator sets also find on

00:23:52,349 --> 00:23:58,529
the descent that was a 1201 alarm

00:23:53,729 --> 00:24:00,209
because they filled up as well but use

00:23:58,529 --> 00:24:02,099
method and you can actually go through

00:24:00,209 --> 00:24:04,739
hardware systems as well and figure it

00:24:02,099 --> 00:24:05,459
out what would it make what it makes

00:24:04,739 --> 00:24:07,379
could I do

00:24:05,459 --> 00:24:09,539
utilization saturation and errors for

00:24:07,379 --> 00:24:12,989
the rendezvous radar and for the descent

00:24:09,539 --> 00:24:15,119
engine so in some cases yes in some

00:24:12,989 --> 00:24:16,649
cases the metric may not make sense but

00:24:15,119 --> 00:24:19,690
it's useful exercise to go through

00:24:16,649 --> 00:24:25,340
because it will reveal metrics

00:24:19,690 --> 00:24:27,500
you can also do this for software so for

00:24:25,340 --> 00:24:30,160
example mutex locks utilization for a

00:24:27,500 --> 00:24:32,780
mutex lock would be lock hold time

00:24:30,160 --> 00:24:36,140
saturation would be lucky contention and

00:24:32,780 --> 00:24:38,059
errors are any errors of throws I could

00:24:36,140 --> 00:24:43,700
do for an entire application or a micro

00:24:38,059 --> 00:24:45,320
service on the cloud as well and if you

00:24:43,700 --> 00:24:47,510
use the method feels a little like

00:24:45,320 --> 00:24:49,640
queueing theory than Trump doing Theory

00:24:47,510 --> 00:24:52,309
studies utilization and certain queue

00:24:49,640 --> 00:24:58,250
length and saturation as well with the

00:24:52,309 --> 00:24:59,870
addition of errors in this case Tom

00:24:58,250 --> 00:25:02,210
Wilkie came up with the read method I

00:24:59,870 --> 00:25:05,179
think he was inspired by the use method

00:25:02,210 --> 00:25:08,300
so this is for a higher level for a web

00:25:05,179 --> 00:25:10,910
service looking at three metrics request

00:25:08,300 --> 00:25:13,760
break error rate and duration and going

00:25:10,910 --> 00:25:16,580
through components from a modern

00:25:13,760 --> 00:25:20,240
application environment it's a similar

00:25:16,580 --> 00:25:22,520
useful exercise so here's my functional

00:25:20,240 --> 00:25:24,140
diagram these are the three metrics that

00:25:22,520 --> 00:25:25,640
are most important now I step through

00:25:24,140 --> 00:25:28,610
each component see how I can measure

00:25:25,640 --> 00:25:30,050
them and the result of that may be for

00:25:28,610 --> 00:25:31,670
the use method and read method is you

00:25:30,050 --> 00:25:33,110
come up with a dashboard so that

00:25:31,670 --> 00:25:38,270
everyone can go to the dashboard and

00:25:33,110 --> 00:25:41,900
elicits those important metrics thread

00:25:38,270 --> 00:25:44,840
state analysis this is a different

00:25:41,900 --> 00:25:48,380
methodology this is where enough drawing

00:25:44,840 --> 00:25:50,090
a this is a generic thread state system

00:25:48,380 --> 00:25:54,800
I think I borrowed a lot of this from

00:25:50,090 --> 00:25:57,320
the bark UNIX book you can see when I am

00:25:54,800 --> 00:25:58,730
when a thread is on CPU so that's

00:25:57,320 --> 00:26:00,890
colored red so I'm switching between

00:25:58,730 --> 00:26:03,080
user mode and kernel mode and when I go

00:26:00,890 --> 00:26:06,140
after sepia there's lots of modes so I

00:26:03,080 --> 00:26:09,890
can be in the runnable state I can be

00:26:06,140 --> 00:26:12,800
swapping I can be waiting on resources

00:26:09,890 --> 00:26:16,309
and so on the thread state analysis

00:26:12,800 --> 00:26:19,090
method is about identifying application

00:26:16,309 --> 00:26:23,210
threads to see which of these states

00:26:19,090 --> 00:26:25,870
those threads are in because each of

00:26:23,210 --> 00:26:28,130
these states leads to actionable items

00:26:25,870 --> 00:26:31,280
so if you find out that you're you

00:26:28,130 --> 00:26:32,000
spending most of the time in the block

00:26:31,280 --> 00:26:34,340
state

00:26:32,000 --> 00:26:36,380
well you've got a lock problem so let's

00:26:34,340 --> 00:26:38,330
fix the let's look at the locks and lock

00:26:36,380 --> 00:26:40,790
contention and maybe you've got too many

00:26:38,330 --> 00:26:43,370
threads in a thread pool or whatever

00:26:40,790 --> 00:26:45,560
they whatever the issue is if I find

00:26:43,370 --> 00:26:49,070
most the time I'm in this what being

00:26:45,560 --> 00:26:52,370
state then I've run out of memory and

00:26:49,070 --> 00:26:54,020
I'm being kicked out if I find I'm

00:26:52,370 --> 00:26:57,740
spending most of the time in the

00:26:54,020 --> 00:27:01,730
runnable state but I'm not uncie PU that

00:26:57,740 --> 00:27:03,260
means of exhausted CPU this was useful

00:27:01,730 --> 00:27:04,430
because it works for any application

00:27:03,260 --> 00:27:05,690
these are not specific to the

00:27:04,430 --> 00:27:07,850
application they're specific to the

00:27:05,690 --> 00:27:09,730
operating system so it's another one of

00:27:07,850 --> 00:27:14,360
these methodologies that you can apply

00:27:09,730 --> 00:27:15,620
generally which is great and you see

00:27:14,360 --> 00:27:17,300
thread states everywhere you look so

00:27:15,620 --> 00:27:20,120
like I know SX there's thread States in

00:27:17,300 --> 00:27:21,290
instruments and it plots it over time so

00:27:20,120 --> 00:27:24,580
you can see whether you're waiting

00:27:21,290 --> 00:27:26,300
suspended running on a run cue and so on

00:27:24,580 --> 00:27:28,700
thread states have been around for a

00:27:26,300 --> 00:27:31,600
long time so one of the oldest ones I

00:27:28,700 --> 00:27:35,390
found was from wristers and you could

00:27:31,600 --> 00:27:36,770
also on Tenex you could control T and it

00:27:35,390 --> 00:27:38,660
would print out the current task and

00:27:36,770 --> 00:27:41,570
tell you that the current job state

00:27:38,660 --> 00:27:43,910
you're getting the kernel tracked or the

00:27:41,570 --> 00:27:46,100
executive program is often called back

00:27:43,910 --> 00:27:50,720
then tracked these states for the

00:27:46,100 --> 00:27:52,040
running processes or tasks I also came

00:27:50,720 --> 00:27:54,830
up with really good methodology for

00:27:52,040 --> 00:27:57,260
Solaris doing thread state analysis and

00:27:54,830 --> 00:28:01,880
I can't really use that anymore but I've

00:27:57,260 --> 00:28:03,350
been getting it to work on BSD so I did

00:28:01,880 --> 00:28:05,810
this in the last two days what about

00:28:03,350 --> 00:28:10,120
thread States on BSD surely there is a

00:28:05,810 --> 00:28:13,310
way to come up with similar States

00:28:10,120 --> 00:28:15,560
it's dtrace has a lot of events or

00:28:13,310 --> 00:28:17,690
probes in the scheduler and so based on

00:28:15,560 --> 00:28:20,450
dtrace probes we can see when we go on

00:28:17,690 --> 00:28:22,670
sleepy enough cpu we can see when we're

00:28:20,450 --> 00:28:26,750
in the runnable state so we're waiting

00:28:22,670 --> 00:28:29,480
in turn on CPU and then we can also pull

00:28:26,750 --> 00:28:35,540
out information from the thread struct

00:28:29,480 --> 00:28:39,260
so we've got the TD state has some basic

00:28:35,540 --> 00:28:41,540
thread States but there's also TDI so

00:28:39,260 --> 00:28:44,060
that tells us if we're sleeping

00:28:41,540 --> 00:28:45,620
suspended swapped waiting on a lock I

00:28:44,060 --> 00:28:47,600
wait

00:28:45,620 --> 00:28:51,230
when we could get ink those out as well

00:28:47,600 --> 00:28:53,900
and so I can try and demo it because I

00:28:51,230 --> 00:28:55,580
only got this to work like an hour ago

00:28:53,900 --> 00:29:06,350
but I wanted to do this as a proof of

00:28:55,580 --> 00:29:10,910
concept but just did it quickly it's not

00:29:06,350 --> 00:29:13,010
so nice it fits on an 80 by 24 screen so

00:29:10,910 --> 00:29:15,410
it's not more than 80 characters wide so

00:29:13,010 --> 00:29:19,430
I've printed out the command name

00:29:15,410 --> 00:29:21,860
process ID and then I've got States CPU

00:29:19,430 --> 00:29:22,790
if you're on CPU run queue if you're

00:29:21,860 --> 00:29:26,330
waiting your turn

00:29:22,790 --> 00:29:36,760
sleep suspend swap walk I wait and yield

00:29:26,330 --> 00:29:39,290
and if I do a work load so there's a few

00:29:36,760 --> 00:29:41,570
and I can like put it in the back read

00:29:39,290 --> 00:29:46,340
like suspend it you know so that's I've

00:29:41,570 --> 00:29:50,150
got some suspend time so there we go so

00:29:46,340 --> 00:29:52,900
now I've got my check silence and Earth

00:29:50,150 --> 00:29:55,490
the bottom and I can see one of them has

00:29:52,900 --> 00:29:56,720
2.4 seconds in the suspend state these

00:29:55,490 --> 00:29:58,430
are I just printed them out in

00:29:56,720 --> 00:29:59,990
milliseconds and you can see the other

00:29:58,430 --> 00:30:04,150
ones are competing for the CPU so

00:29:59,990 --> 00:30:04,150
there's the they're still running right

00:30:11,160 --> 00:30:20,850
so there's my cpu and run queue I can

00:30:18,180 --> 00:30:22,350
probably add some more states and flags

00:30:20,850 --> 00:30:27,060
to this because there's also flags from

00:30:22,350 --> 00:30:29,790
the struct thread so what's useful about

00:30:27,060 --> 00:30:32,280
that is it is this this works for any

00:30:29,790 --> 00:30:36,750
application at all and it gives you a

00:30:32,280 --> 00:30:40,530
direction to begin performance tuning so

00:30:36,750 --> 00:30:43,280
if I am just on CPU I should use a CPU

00:30:40,530 --> 00:30:45,510
profiler to find out what kind of if I'm

00:30:43,280 --> 00:30:48,090
spending most of my time on on the run

00:30:45,510 --> 00:30:50,750
queue that means I've exhausted CPU and

00:30:48,090 --> 00:30:54,200
I should look at buying most CPUs

00:30:50,750 --> 00:30:56,190
killing tasks that are consuming CPU and

00:30:54,200 --> 00:30:58,110
in so on you go through each of the

00:30:56,190 --> 00:31:07,170
columns and they will direct further

00:30:58,110 --> 00:31:09,570
actions so maybe I'll leave that running

00:31:07,170 --> 00:31:11,900
let's see if I can catch something else

00:31:09,570 --> 00:31:11,900
happening

00:31:15,670 --> 00:31:23,180
so there's an output so that's the

00:31:21,680 --> 00:31:25,640
thread state analysis and I said if you

00:31:23,180 --> 00:31:28,850
were in the CPU state you would use

00:31:25,640 --> 00:31:31,850
profilers so uncie p analysis which i've

00:31:28,850 --> 00:31:33,860
split out something you can do to start

00:31:31,850 --> 00:31:36,020
with this what stay do in user eternal

00:31:33,860 --> 00:31:39,920
state and that's pretty easy to find you

00:31:36,020 --> 00:31:44,240
can check your cpu balance if you know

00:31:39,920 --> 00:31:45,680
your own CPU are you hot on one CP only

00:31:44,240 --> 00:31:48,680
because you don't have enough threads

00:31:45,680 --> 00:31:51,230
will you pins to a CPU profile software

00:31:48,680 --> 00:31:53,030
see if you can graphs are great and if

00:31:51,230 --> 00:31:55,190
you get down to the low level than SPM

00:31:53,030 --> 00:31:59,660
seasons and cycles per instruction plain

00:31:55,190 --> 00:32:02,030
ground plane graph analysis so we're on

00:31:59,660 --> 00:32:05,330
cpu let's do a flame graph hands up if

00:32:02,030 --> 00:32:07,070
you've used flame graphs it have like

00:32:05,330 --> 00:32:07,900
half the room a bit more than half the

00:32:07,070 --> 00:32:11,120
room great

00:32:07,900 --> 00:32:14,060
so flame graphs simply a visualization

00:32:11,120 --> 00:32:17,390
of sample stack traces i can also be

00:32:14,060 --> 00:32:22,490
traced stack traces and it's really an

00:32:17,390 --> 00:32:24,140
adjacent adjacency plot and it works

00:32:22,490 --> 00:32:27,920
really well it works really well because

00:32:24,140 --> 00:32:31,190
the how these work is the x-axis is the

00:32:27,920 --> 00:32:33,230
passage of time no sorry the x-axis is

00:32:31,190 --> 00:32:36,530
the alphabet not the passage of time and

00:32:33,230 --> 00:32:38,960
the y-axis is the stack depth and you

00:32:36,530 --> 00:32:41,420
look at the largest towers first and so

00:32:38,960 --> 00:32:44,240
if i said half the room haven't haven't

00:32:41,420 --> 00:32:47,260
used them yet they go to one of my

00:32:44,240 --> 00:32:47,260
standard flame graphs

00:32:56,800 --> 00:33:04,930
so I can zoom in but the so this is

00:33:01,240 --> 00:33:08,050
Bosch running and if I was interested in

00:33:04,930 --> 00:33:10,120
where my CPU cycles are spent you just

00:33:08,050 --> 00:33:12,730
look for the biggest rectangles and the

00:33:10,120 --> 00:33:14,980
biggest rectangles says bashas in main

00:33:12,730 --> 00:33:16,870
reader loop execute command I can mean

00:33:14,980 --> 00:33:18,310
execute commands and once I mean execute

00:33:16,870 --> 00:33:21,310
commands are then run this and this and

00:33:18,310 --> 00:33:22,570
this you can split it up quickly so you

00:33:21,310 --> 00:33:23,530
just look for the biggest rectangles

00:33:22,570 --> 00:33:25,900
that's where you spend most of your time

00:33:23,530 --> 00:33:27,670
stacktrace goes up don't worry about the

00:33:25,900 --> 00:33:29,170
X ordering because I sort things

00:33:27,670 --> 00:33:31,330
alphabetically so I can merge all the

00:33:29,170 --> 00:33:32,770
frames really quickly and then you can

00:33:31,330 --> 00:33:35,230
zoom in we use them in Netflix all the

00:33:32,770 --> 00:33:37,540
time on both links and previously so

00:33:35,230 --> 00:33:40,510
that we can understand where CPU cycles

00:33:37,540 --> 00:33:44,350
are and of course if things are really

00:33:40,510 --> 00:33:47,170
thin I don't have enough room to draw

00:33:44,350 --> 00:33:49,000
the names right and that's not a bad

00:33:47,170 --> 00:33:50,320
thing because if they're really thin it

00:33:49,000 --> 00:33:52,360
means they didn't contribute much to the

00:33:50,320 --> 00:33:55,210
profile so they're not that interesting

00:33:52,360 --> 00:33:57,400
so just by virtue of being only able to

00:33:55,210 --> 00:33:59,530
label boxes that are big enough to label

00:33:57,400 --> 00:34:01,960
that helps as part of the visualization

00:33:59,530 --> 00:34:05,220
as it is elite your eyes into the areas

00:34:01,960 --> 00:34:05,220
that you should you should care about

00:34:08,550 --> 00:34:13,590
so this discovers issues by their CPU

00:34:11,140 --> 00:34:17,140
usage and narrows the target to study

00:34:13,590 --> 00:34:18,580
I've got the commands to do it using D

00:34:17,140 --> 00:34:21,940
trace on FreeBSD you can also create

00:34:18,580 --> 00:34:26,740
flame graphs using pmc stat and other

00:34:21,940 --> 00:34:30,790
profilers as well and I've got those

00:34:26,740 --> 00:34:33,850
steps for DTrace online I've also been

00:34:30,790 --> 00:34:37,419
doing things with mixed-mode flame

00:34:33,850 --> 00:34:41,530
graphs and so at Netflix for Java

00:34:37,419 --> 00:34:44,530
analysis I do this a lot that's where we

00:34:41,530 --> 00:34:46,600
can see when we go into the cut actually

00:34:44,530 --> 00:34:49,630
color the Comal a different color I can

00:34:46,600 --> 00:34:54,460
see my java code in green C++ in yellow

00:34:49,630 --> 00:34:57,280
and use a space in red and I have not

00:34:54,460 --> 00:34:58,890
tried this on BSD yet but it should work

00:34:57,280 --> 00:35:01,420
if you do the preserve frame cleaner

00:34:58,890 --> 00:35:02,980
which is an option I worked with Oracle

00:35:01,420 --> 00:35:05,770
to get added just so that we could do

00:35:02,980 --> 00:35:07,420
flame graphs and so that means system

00:35:05,770 --> 00:35:08,900
profilers can then walk stack pack

00:35:07,420 --> 00:35:11,869
traces

00:35:08,900 --> 00:35:14,630
then I use Java perf map agent which

00:35:11,869 --> 00:35:16,760
will do an on demand symbol done so if

00:35:14,630 --> 00:35:18,309
you've run into problems with profiling

00:35:16,760 --> 00:35:20,510
jittered runtimes

00:35:18,309 --> 00:35:21,770
there are solutions it just depends on

00:35:20,510 --> 00:35:27,109
the runtime so that's how i'm currently

00:35:21,770 --> 00:35:30,740
doing java i mentioned a CPI flame graph

00:35:27,109 --> 00:35:33,170
so here's an example from bsd CPI cycles

00:35:30,740 --> 00:35:38,200
per instruction this is in this example

00:35:33,170 --> 00:35:38,200
is using pmc stat so that I can see

00:35:38,799 --> 00:35:44,869
instructions and stalls and then I've

00:35:41,720 --> 00:35:48,289
colored the output in a way that the

00:35:44,869 --> 00:35:51,549
width on the x-axis shows how often

00:35:48,289 --> 00:35:58,099
you're on CPU so that is relative to

00:35:51,549 --> 00:36:00,890
cycles and the color is relative to what

00:35:58,099 --> 00:36:03,319
those cycles were with were they more

00:36:00,890 --> 00:36:06,440
instruction retires or were they more

00:36:03,319 --> 00:36:08,569
stall cycles because if they're more

00:36:06,440 --> 00:36:10,549
stall cycles then you need to do memory

00:36:08,569 --> 00:36:13,609
tune so how can I do zero copy

00:36:10,549 --> 00:36:16,760
what's my Numa settings can I just do

00:36:13,609 --> 00:36:19,460
less memory i/o to improve performance

00:36:16,760 --> 00:36:21,980
or switch to a system that has a better

00:36:19,460 --> 00:36:24,109
memory subsystem if it's more red than

00:36:21,980 --> 00:36:25,849
its cycle down towards its instruction

00:36:24,109 --> 00:36:28,819
bound and then it's a different

00:36:25,849 --> 00:36:31,130
actionable items and so look at reducing

00:36:28,819 --> 00:36:33,529
code using different order algorithms

00:36:31,130 --> 00:36:36,200
and so on we've automated these are

00:36:33,529 --> 00:36:38,029
Netflix or The OC a team uses the CPI

00:36:36,200 --> 00:36:45,170
flame graphs for doing performance

00:36:38,029 --> 00:36:47,480
analysis after CPU analysis so on CPU

00:36:45,170 --> 00:36:52,880
analysis is great but what about off CPU

00:36:47,480 --> 00:36:54,230
when we block and we can do that using

00:36:52,880 --> 00:36:56,089
enough CP flame graph when we can

00:36:54,230 --> 00:37:00,470
instrument when we block and when what

00:36:56,089 --> 00:37:02,750
the state of the thread is so I did one

00:37:00,470 --> 00:37:06,970
for FreeBSD this is an off CPU time

00:37:02,750 --> 00:37:06,970
flame graph but let me just browse it

00:37:13,910 --> 00:37:18,410
this time the x-axis has not said the

00:37:16,670 --> 00:37:20,750
sample population it's time because

00:37:18,410 --> 00:37:24,590
instead of taking periodic samples i'm

00:37:20,750 --> 00:37:27,470
instrumenting tracing the wider it is

00:37:24,590 --> 00:37:29,900
the more we're in that path of cpu the

00:37:27,470 --> 00:37:31,640
y-axis is still the stack depth I've got

00:37:29,900 --> 00:37:34,340
the use of stack trace and in the kernel

00:37:31,640 --> 00:37:36,920
stack trace and the use of stack traces

00:37:34,340 --> 00:37:38,810
are all hex because that symbol was

00:37:36,920 --> 00:37:41,030
tripped so I don't have this thing but

00:37:38,810 --> 00:37:43,510
we can fix that but you can see the

00:37:41,030 --> 00:37:46,610
kernel stack traces this is BSD tar

00:37:43,510 --> 00:37:50,210
tearing some files most of the time

00:37:46,610 --> 00:37:52,970
we're here in do file read probably not

00:37:50,210 --> 00:37:55,700
surprising sometimes we get in to be

00:37:52,970 --> 00:37:57,170
read in flags would be read sometimes we

00:37:55,700 --> 00:38:00,020
get into cluster read which I believe is

00:37:57,170 --> 00:38:03,350
doing read ahead for some reason our

00:38:00,020 --> 00:38:04,610
beastie tag gets into this twice so if

00:38:03,350 --> 00:38:06,920
it hears the same stuff we've got cost

00:38:04,610 --> 00:38:08,120
of read and be read in but there's other

00:38:06,920 --> 00:38:10,730
bits in here as well so here's a

00:38:08,120 --> 00:38:12,680
redirect ring so I can see we spent 55

00:38:10,730 --> 00:38:19,310
milliseconds off CPU and read directory

00:38:12,680 --> 00:38:21,320
and there's also this stuff see for some

00:38:19,310 --> 00:38:23,810
reason tar was doing sakes and we spent

00:38:21,320 --> 00:38:25,820
30 milliseconds in C but I can quickly

00:38:23,810 --> 00:38:28,910
identify where the bulk of the off CPU

00:38:25,820 --> 00:38:31,250
time was so for that profile is 1,000

00:38:28,910 --> 00:38:33,230
milliseconds was doing file reads if

00:38:31,250 --> 00:38:35,570
this was off CPU for another reason so I

00:38:33,230 --> 00:38:37,880
was blocked on locks show up in the

00:38:35,570 --> 00:38:41,270
stack trace so I've CV frame graphs are

00:38:37,880 --> 00:38:43,040
a very powerful tool for tackling all

00:38:41,270 --> 00:38:46,790
the times that you block and you go off

00:38:43,040 --> 00:38:49,790
CPU here's how I did it with D trace I'm

00:38:46,790 --> 00:38:52,610
you saying off CPU and I record a

00:38:49,790 --> 00:38:55,940
timestamp when we go back on CPU then to

00:38:52,610 --> 00:38:59,180
the Delta record stack traces and I'll

00:38:55,940 --> 00:39:02,860
share these slides online and then I

00:38:59,180 --> 00:39:05,510
feed it into flame graph and color blue

00:39:02,860 --> 00:39:07,250
one thing I might want to do is so here

00:39:05,510 --> 00:39:10,400
I'm just filtered for the tar commands

00:39:07,250 --> 00:39:13,400
actually PSD time one thing I might you

00:39:10,400 --> 00:39:15,110
might consider doing is it's interesting

00:39:13,400 --> 00:39:17,540
to get an insight into this is if you

00:39:15,110 --> 00:39:20,270
actually run this on a production system

00:39:17,540 --> 00:39:22,370
sometimes you'll get some crazy code

00:39:20,270 --> 00:39:23,089
paths where you go off CPU and you look

00:39:22,370 --> 00:39:24,049
at you think

00:39:23,089 --> 00:39:25,999
doesn't make any sense but they're

00:39:24,049 --> 00:39:29,390
really thin and narrow we seem to be

00:39:25,999 --> 00:39:32,269
just like randomly jumping off CPU when

00:39:29,390 --> 00:39:33,710
when there's no explanation for it no

00:39:32,269 --> 00:39:34,789
explanation in the user curve but if you

00:39:33,710 --> 00:39:38,359
look at the kernel code you'll see

00:39:34,789 --> 00:39:39,920
you're getting preempted and so you've

00:39:38,359 --> 00:39:42,410
just got CPU saturation these are

00:39:39,920 --> 00:39:44,119
involuntary contact switches a way to

00:39:42,410 --> 00:39:47,269
filter them out is to look at the thread

00:39:44,119 --> 00:39:48,829
state and so I can make sure that the

00:39:47,269 --> 00:39:53,210
thread state is less than equal to one

00:39:48,829 --> 00:39:56,180
which is in the TD state and that should

00:39:53,210 --> 00:39:57,710
just look at the that should exclude the

00:39:56,180 --> 00:39:59,239
involuntary context switches so you

00:39:57,710 --> 00:40:04,089
might get a little bit more sensible of

00:39:59,239 --> 00:40:08,150
CP phone graph so there have decorated

00:40:04,089 --> 00:40:15,469
some of the paths that one file read

00:40:08,150 --> 00:40:17,239
read ahead that one now this one I'm

00:40:15,469 --> 00:40:21,170
just running turn on piping it to dev

00:40:17,239 --> 00:40:23,420
now this one I'm running tar and I'm

00:40:21,170 --> 00:40:25,849
piping it into gzip and it looks

00:40:23,420 --> 00:40:28,960
completely different because now we're

00:40:25,849 --> 00:40:33,130
spending most of our time in pipe right

00:40:28,960 --> 00:40:35,269
because tower is waiting for gzip to

00:40:33,130 --> 00:40:38,059
finish its stuff and then write it back

00:40:35,269 --> 00:40:40,369
to disk if you were a performance

00:40:38,059 --> 00:40:41,630
analyst that's kind of interesting okay

00:40:40,369 --> 00:40:43,489
so I'm spending a lot of my time blocked

00:40:41,630 --> 00:40:44,869
in pipe right but if you tried to make

00:40:43,489 --> 00:40:47,479
the system faster there's no explanation

00:40:44,869 --> 00:40:48,769
here it's like I'm waiting on a pipe but

00:40:47,479 --> 00:40:53,450
I don't know what happened on the other

00:40:48,769 --> 00:40:55,789
side so what was it doing that took so

00:40:53,450 --> 00:40:59,390
long especially since that dominates so

00:40:55,789 --> 00:41:01,819
a solution to this is to do wake up time

00:40:59,390 --> 00:41:05,089
profiling where I instrument the wake up

00:41:01,819 --> 00:41:06,289
events and the way I've drawn it here is

00:41:05,089 --> 00:41:09,349
the flame graph well it's really more

00:41:06,289 --> 00:41:13,460
instrument it's just one stack gzip has

00:41:09,349 --> 00:41:17,619
woken up be as DITA and it's because

00:41:13,460 --> 00:41:17,619
gzip was reading from the pine

00:41:18,860 --> 00:41:28,580
that's what we expect there's my wake-up

00:41:22,010 --> 00:41:33,200
profiling D tree script now we can go

00:41:28,580 --> 00:41:35,690
one step further except to do that in

00:41:33,200 --> 00:41:37,550
Colonel I've had to use EBP F and so

00:41:35,690 --> 00:41:39,260
this this example is from Linux and

00:41:37,550 --> 00:41:42,260
that's where in the kernel I can merge

00:41:39,260 --> 00:41:45,590
the wakest stack with the blocked stack

00:41:42,260 --> 00:41:47,600
and so you can see tah this is table

00:41:45,590 --> 00:41:51,770
blocking and then here is the wakest

00:41:47,600 --> 00:41:53,300
stack that woke us up it so it would be

00:41:51,770 --> 00:41:55,280
good to get this working on BST as well

00:41:53,300 --> 00:41:58,330
but it's a it's a this is a more

00:41:55,280 --> 00:42:01,340
powerful tool for doing our CPU analysis

00:41:58,330 --> 00:42:03,020
because I would say that if you do I've

00:42:01,340 --> 00:42:05,360
done a lots and lots of CP or FanGraphs

00:42:03,020 --> 00:42:07,460
I think you'll find probably 70 to 80

00:42:05,360 --> 00:42:09,320
percent of the stack traces are not that

00:42:07,460 --> 00:42:11,330
interesting you're blocked on the mutex

00:42:09,320 --> 00:42:13,400
you're blocked on a conditional variable

00:42:11,330 --> 00:42:14,930
you need to know who woke you up and

00:42:13,400 --> 00:42:17,870
there's that trace to make sense of it

00:42:14,930 --> 00:42:22,090
so being able to merge the weaker with

00:42:17,870 --> 00:42:24,980
the blocked stack is pretty important

00:42:22,090 --> 00:42:29,270
just to mention it as it's interesting

00:42:24,980 --> 00:42:36,590
BPF PPF is Berkeley packet filter and so

00:42:29,270 --> 00:42:38,150
I believe this came from BSD and BPF

00:42:36,590 --> 00:42:39,710
previously is probably not that

00:42:38,150 --> 00:42:41,660
interesting at technology I mean it's

00:42:39,710 --> 00:42:47,030
kind of interesting if it helps it helps

00:42:41,660 --> 00:42:49,210
network filtering performance but what

00:42:47,030 --> 00:42:51,620
made it interesting was that recently

00:42:49,210 --> 00:42:53,570
some engineers realized that it was a

00:42:51,620 --> 00:42:56,000
internal virtual machine in kernel

00:42:53,570 --> 00:42:57,380
sandbox virtual machine so if it could

00:42:56,000 --> 00:42:59,120
be extended it could be used to do all

00:42:57,380 --> 00:43:01,820
sorts of things like software-defined

00:42:59,120 --> 00:43:06,050
networking or instrumentation like

00:43:01,820 --> 00:43:08,300
dtrace and so that's what IPPF is and EP

00:43:06,050 --> 00:43:10,760
PF programs look like this so that we've

00:43:08,300 --> 00:43:14,380
got more actions we can do more

00:43:10,760 --> 00:43:18,680
registers eb PF programs have maps

00:43:14,380 --> 00:43:21,350
hashes associative race they can handle

00:43:18,680 --> 00:43:23,150
stack traces and they can do actions and

00:43:21,350 --> 00:43:25,810
so i'm starting to do a lot of work on

00:43:23,150 --> 00:43:28,960
that for monix

00:43:25,810 --> 00:43:30,640
the front end is really difficult in

00:43:28,960 --> 00:43:33,790
fact I've written a lot of programs a

00:43:30,640 --> 00:43:36,070
lot of programming languages and EPP F

00:43:33,790 --> 00:43:38,140
assembly Rory BPF assembly is the first

00:43:36,070 --> 00:43:39,250
language that's defeated me I have not

00:43:38,140 --> 00:43:42,490
been able to write a program that

00:43:39,250 --> 00:43:44,740
compiles and it's because it's it's its

00:43:42,490 --> 00:43:46,990
own special assembly that has been made

00:43:44,740 --> 00:43:48,910
up for EBP F so I can't really go to

00:43:46,990 --> 00:43:51,760
stack overflow and see who else has run

00:43:48,910 --> 00:43:52,450
into this because there's nothing so

00:43:51,760 --> 00:43:53,890
it's hard

00:43:52,450 --> 00:43:59,440
fortunately we are put in front ends on

00:43:53,890 --> 00:44:01,180
it the friends could get better at least

00:43:59,440 --> 00:44:04,840
this program fits on the slide this is

00:44:01,180 --> 00:44:06,100
BCC George mentioned BCC earlier at

00:44:04,840 --> 00:44:07,720
least that program fits on the slide but

00:44:06,100 --> 00:44:10,030
if you browse them they're quite long so

00:44:07,720 --> 00:44:13,540
they're not quite high level like D

00:44:10,030 --> 00:44:16,000
traces yet I have been asked a few times

00:44:13,540 --> 00:44:18,790
if EBP F can solves some interesting

00:44:16,000 --> 00:44:24,840
things like the merging of stacks can a

00:44:18,790 --> 00:44:24,840
BPF be ported to be state and why not

00:44:26,360 --> 00:44:31,030
someone's got to do it though so you

00:44:28,040 --> 00:44:33,140
have to put your hand up to do the work

00:44:31,030 --> 00:44:36,590
latency choleric colorations

00:44:33,140 --> 00:44:41,570
correlations another methodology is

00:44:36,590 --> 00:44:43,340
where say you're doing a drill-down

00:44:41,570 --> 00:44:46,460
analysis from top to bottom and you know

00:44:43,340 --> 00:44:49,670
you have some lengthy outliers to

00:44:46,460 --> 00:44:53,060
understand where they originate from so

00:44:49,670 --> 00:44:55,460
range itself it's really useful to do a

00:44:53,060 --> 00:44:57,320
histogram so you can under five you have

00:44:55,460 --> 00:45:01,580
multimodal latency or if you have

00:44:57,320 --> 00:45:04,730
outliers even better is to use latency

00:45:01,580 --> 00:45:07,370
heat maps which I came up with a long

00:45:04,730 --> 00:45:09,740
time ago originally originally

00:45:07,370 --> 00:45:12,620
instrumented using DTrace so that we

00:45:09,740 --> 00:45:14,060
could get the rich data out and so this

00:45:12,620 --> 00:45:16,490
is an example where you can see it's a

00:45:14,060 --> 00:45:18,500
multi-modal distribution the y-axis is

00:45:16,490 --> 00:45:19,220
the latency and the x-axis is the

00:45:18,500 --> 00:45:21,530
passage of time

00:45:19,220 --> 00:45:23,270
it's a multi-modal distribution the

00:45:21,530 --> 00:45:26,090
color depth is how many I have fell into

00:45:23,270 --> 00:45:28,250
that latency and time range but this

00:45:26,090 --> 00:45:29,540
distribution changes over time and that

00:45:28,250 --> 00:45:33,920
could be very interesting to a

00:45:29,540 --> 00:45:35,870
performance analyst but for later

00:45:33,920 --> 00:45:38,390
correlations I'll go further and this is

00:45:35,870 --> 00:45:41,090
something that I also originally did it

00:45:38,390 --> 00:45:45,460
somewhere we could measure length C from

00:45:41,090 --> 00:45:47,900
different levels like NFS disk

00:45:45,460 --> 00:45:50,120
application and then look at the heat

00:45:47,900 --> 00:45:53,300
maps at each level and if we see a

00:45:50,120 --> 00:45:55,460
problem instrumented at one level does

00:45:53,300 --> 00:45:57,110
that appear at the next level down in

00:45:55,460 --> 00:45:59,120
the next level down so if there's a

00:45:57,110 --> 00:46:00,560
cloud of bad lights this is a bad storm

00:45:59,120 --> 00:46:02,210
cloud like this is hurting the

00:46:00,560 --> 00:46:04,220
application does it come from the file

00:46:02,210 --> 00:46:05,810
system does it come from the disks and

00:46:04,220 --> 00:46:10,100
if you say it's in the file system but

00:46:05,810 --> 00:46:11,900
not the disks then you might look more

00:46:10,100 --> 00:46:13,130
closely at the file system is there some

00:46:11,900 --> 00:46:15,650
problem with the file system like lock

00:46:13,130 --> 00:46:16,880
contention or memory allocation where

00:46:15,650 --> 00:46:18,920
it's waiting on it or something like

00:46:16,880 --> 00:46:21,260
that because I didn't see that latency

00:46:18,920 --> 00:46:23,480
cloud coming from disks so latency

00:46:21,260 --> 00:46:25,250
correlations as a method is to look at

00:46:23,480 --> 00:46:27,620
latency at different levels of the stack

00:46:25,250 --> 00:46:31,370
and then compare them visually to see

00:46:27,620 --> 00:46:33,590
where latency originates another

00:46:31,370 --> 00:46:35,540
methodology maybe I could put down this

00:46:33,590 --> 00:46:38,420
first very simple one is checklists

00:46:35,540 --> 00:46:39,589
checklists work I mean I don't like them

00:46:38,420 --> 00:46:41,450
a lot because they

00:46:39,589 --> 00:46:44,719
can miss things they only as good as the

00:46:41,450 --> 00:46:46,160
checklist but they are useful in that it

00:46:44,719 --> 00:46:46,789
can be something you can share with a

00:46:46,160 --> 00:46:48,769
lot of people

00:46:46,789 --> 00:46:51,559
he's a BST performs analysis checklist

00:46:48,769 --> 00:46:54,019
in 60 seconds so the first 10 commands

00:46:51,559 --> 00:46:59,900
all run on a PSD system because I want

00:46:54,019 --> 00:47:01,279
to understand performance we used lots

00:46:59,900 --> 00:47:04,279
of dashboards at Netflix for the cloud

00:47:01,279 --> 00:47:07,279
and in a way dashboards are checklists

00:47:04,279 --> 00:47:09,200
as well it's just an example dashboard

00:47:07,279 --> 00:47:14,089
that we use for performance engineering

00:47:09,200 --> 00:47:15,739
and so checklists aren't just a list of

00:47:14,089 --> 00:47:19,869
commands you can also make a dashboard

00:47:15,739 --> 00:47:22,609
that serves as a checklist another

00:47:19,869 --> 00:47:26,059
favorite methodology of mine is static

00:47:22,609 --> 00:47:28,670
performance tuning and this is first

00:47:26,059 --> 00:47:31,849
come up first created by Richard Elling

00:47:28,670 --> 00:47:36,789
a long time ago and the idea of static

00:47:31,849 --> 00:47:39,910
performance tuning is you look at the

00:47:36,789 --> 00:47:43,430
static state of the system without load

00:47:39,910 --> 00:47:45,589
imagine if someone said this system is

00:47:43,430 --> 00:47:47,359
performing really badly and then they

00:47:45,589 --> 00:47:50,180
turn off the application and use a

00:47:47,359 --> 00:47:52,940
performance engineer login and you run

00:47:50,180 --> 00:47:55,489
top or you run up time whatever and

00:47:52,940 --> 00:47:57,609
loads gone the systems now idle can you

00:47:55,489 --> 00:48:00,349
do anything at all on an idle system

00:47:57,609 --> 00:48:02,839
what you do once you can check for lots

00:48:00,349 --> 00:48:05,660
of problems even though that the

00:48:02,839 --> 00:48:08,059
workload is not present it is just a a

00:48:05,660 --> 00:48:09,979
static or idle system and so you can

00:48:08,059 --> 00:48:10,999
check whether we were the disks fault

00:48:09,979 --> 00:48:13,099
because that can cause performance

00:48:10,999 --> 00:48:15,019
issues when you're approaching and

00:48:13,099 --> 00:48:16,910
you're getting full in if in faster you

00:48:15,019 --> 00:48:19,279
have vessel CFS and they're trying to

00:48:16,910 --> 00:48:21,589
find places to put blocks and what

00:48:19,279 --> 00:48:24,559
services are turned on what applications

00:48:21,589 --> 00:48:26,420
how they configured what's what's memory

00:48:24,559 --> 00:48:28,880
allocations look like helping in the

00:48:26,420 --> 00:48:32,839
caches what's my rap table look like is

00:48:28,880 --> 00:48:34,279
that crazy have I swapped to disk is

00:48:32,839 --> 00:48:36,469
there a whole heap that's being swapped

00:48:34,279 --> 00:48:40,759
out one of my ZFS settings with my giome

00:48:36,469 --> 00:48:43,160
settings and so on and so on some static

00:48:40,759 --> 00:48:46,309
performance tuning all of the and also D

00:48:43,160 --> 00:48:47,340
message and everything you see in kld

00:48:46,309 --> 00:48:49,470
stand

00:48:47,340 --> 00:48:53,360
leaves all the static configuration of

00:48:49,470 --> 00:48:53,360
the system can be thoroughly checked

00:48:55,880 --> 00:49:02,190
another performance analysis methodology

00:48:59,430 --> 00:49:05,430
called the tools based method this is

00:49:02,190 --> 00:49:06,870
where you just try all the talks this is

00:49:05,430 --> 00:49:11,040
not the best because you may miss things

00:49:06,870 --> 00:49:13,020
but it is very simple to do and Martin

00:49:11,040 --> 00:49:14,310
gave a talk yesterday about doing

00:49:13,020 --> 00:49:17,760
performance analysis black box

00:49:14,310 --> 00:49:19,560
performance analysis where he said and I

00:49:17,760 --> 00:49:20,940
am looking at all the metrics and just

00:49:19,560 --> 00:49:22,500
taking the metrics that the system has

00:49:20,940 --> 00:49:24,750
and I'm working my way through them to

00:49:22,500 --> 00:49:27,180
solve the problem similar tools based

00:49:24,750 --> 00:49:28,740
method where this is what this is what

00:49:27,180 --> 00:49:30,120
the system makes it easy to dig out

00:49:28,740 --> 00:49:32,370
let's just quickly go through that and

00:49:30,120 --> 00:49:36,440
see if the problem sticks out and so

00:49:32,370 --> 00:49:38,880
there's my diagram for FreeBSD tools I

00:49:36,440 --> 00:49:40,680
can also write separate diagrams for

00:49:38,880 --> 00:49:45,510
these details because they supplement

00:49:40,680 --> 00:49:50,960
the existing tools so I'm saying to add

00:49:45,510 --> 00:49:53,550
more of these 2d trace freebsd so my i

00:49:50,960 --> 00:49:55,890
need to publish actually the one I just

00:49:53,550 --> 00:49:57,480
did T States for this talk I need to

00:49:55,890 --> 00:49:59,190
stick on this diagram because that does

00:49:57,480 --> 00:50:00,600
my thread state analysis and it needs to

00:49:59,190 --> 00:50:05,640
go into the scheduler area so it's

00:50:00,600 --> 00:50:07,490
already out of date some other

00:50:05,640 --> 00:50:10,170
methodologies are well I mention

00:50:07,490 --> 00:50:13,650
scientific method I was taught the

00:50:10,170 --> 00:50:15,780
scientific method at school okay so

00:50:13,650 --> 00:50:17,880
maybe Porter people it's taught a lot in

00:50:15,780 --> 00:50:19,650
it depends on the country right so some

00:50:17,880 --> 00:50:22,200
people have been it's been drummed into

00:50:19,650 --> 00:50:24,090
them they know note off by harden it so

00:50:22,200 --> 00:50:26,190
I'm having it's useful way of posing the

00:50:24,090 --> 00:50:28,640
hypothesis and going through it and

00:50:26,190 --> 00:50:32,280
analyzing it there's the five why's

00:50:28,640 --> 00:50:34,590
methodology where you poke you ask why

00:50:32,280 --> 00:50:36,990
and then based on the answer you ask why

00:50:34,590 --> 00:50:39,360
again five times to see if you can get

00:50:36,990 --> 00:50:40,550
to the bottom of something process of

00:50:39,360 --> 00:50:45,350
elimination

00:50:40,550 --> 00:50:49,170
commonly used so being able to find

00:50:45,350 --> 00:50:51,540
tests that will eliminate what's on the

00:50:49,170 --> 00:50:54,260
operating table so the what you're

00:50:51,540 --> 00:50:56,490
analyzing becomes smaller and smaller

00:50:54,260 --> 00:50:59,670
you can also come up with a tree for

00:50:56,490 --> 00:51:01,170
that and do differential diagnosis endo

00:50:59,670 --> 00:51:02,760
has an interesting methodology

00:51:01,170 --> 00:51:07,440
anyone who's top-down methodology on

00:51:02,760 --> 00:51:09,569
PMC's nobody interesting it's just a PMC

00:51:07,440 --> 00:51:11,130
in their own universe of stuff that are

00:51:09,569 --> 00:51:13,980
becoming more important that's how you

00:51:11,130 --> 00:51:15,960
you're trying to understand cycles and

00:51:13,980 --> 00:51:17,670
stall cycles and what the caches are

00:51:15,960 --> 00:51:19,500
doing and intel has come up with this

00:51:17,670 --> 00:51:20,910
interesting methodology and have coded

00:51:19,500 --> 00:51:23,069
intervie tune as well but there's also

00:51:20,910 --> 00:51:25,500
open-source tools that do it where

00:51:23,069 --> 00:51:27,390
they're breaking up cycles into parts

00:51:25,500 --> 00:51:29,730
and then so on and so on to understand

00:51:27,390 --> 00:51:31,470
what's efficiently and then method I was

00:51:29,730 --> 00:51:37,650
was once been around for wealth for

00:51:31,470 --> 00:51:39,450
looking at white state and Oracle I'll

00:51:37,650 --> 00:51:42,630
leave you with some things you can do

00:51:39,450 --> 00:51:47,700
and that is to know what's possible on

00:51:42,630 --> 00:51:49,349
modern systems so dynamic tracing means

00:51:47,700 --> 00:51:51,420
we can efficiently instrument any

00:51:49,349 --> 00:51:53,549
software and it allows us to play these

00:51:51,420 --> 00:51:57,329
methodology games and come up with new

00:51:53,549 --> 00:51:59,819
methodologies that in the past for all

00:51:57,329 --> 00:52:02,130
the systems would have been an academic

00:51:59,819 --> 00:52:04,230
exercise like great you want to measure

00:52:02,130 --> 00:52:06,000
and thread stains we can't because the

00:52:04,230 --> 00:52:07,440
kernel doesn't do that but now I can

00:52:06,000 --> 00:52:09,210
have that idea I can sit down with a

00:52:07,440 --> 00:52:11,309
dtrace program and write estrogen which

00:52:09,210 --> 00:52:13,079
I did earlier and so it's it's a great

00:52:11,309 --> 00:52:15,020
time to be investigating performance

00:52:13,079 --> 00:52:17,220
analysis methodologies because we have

00:52:15,020 --> 00:52:18,780
things are open source and we have

00:52:17,220 --> 00:52:21,690
dynamic tracing tools and we can try

00:52:18,780 --> 00:52:23,460
them out and see what works CP

00:52:21,690 --> 00:52:25,260
facilities are becoming more and more

00:52:23,460 --> 00:52:28,470
important so performance monitoring

00:52:25,260 --> 00:52:30,299
counters who's used PMC's who's the PMC

00:52:28,470 --> 00:52:34,290
nerds all right lots of people

00:52:30,299 --> 00:52:36,720
it's a PMC stat and in BSD more and more

00:52:34,290 --> 00:52:39,829
important performance issues are moving

00:52:36,720 --> 00:52:41,760
down there to low-level CPU CPU problems

00:52:39,829 --> 00:52:44,700
you get some things out of there miss

00:52:41,760 --> 00:52:46,260
ours as well visualizations are

00:52:44,700 --> 00:52:49,280
important as well plane graphs lengthen

00:52:46,260 --> 00:52:53,910
heat maps and they should be commonplace

00:52:49,280 --> 00:52:57,450
ask questions first so what do you want

00:52:53,910 --> 00:53:00,809
the system to answer and then we will

00:52:57,450 --> 00:53:03,540
find an answer to it instead of just

00:53:00,809 --> 00:53:06,910
treat just using what the system gives

00:53:03,540 --> 00:53:08,650
you and also

00:53:06,910 --> 00:53:11,440
maybe you're going to write the dtrace

00:53:08,650 --> 00:53:13,390
tools and use the pmc as yourself but a

00:53:11,440 --> 00:53:16,150
lot of people pay vendors to write

00:53:13,390 --> 00:53:18,759
monitoring software ask them to do it

00:53:16,150 --> 00:53:21,430
and so there should be a pmc dashboard

00:53:18,759 --> 00:53:24,069
in whatever nifty monitoring software

00:53:21,430 --> 00:53:26,319
you're actually paying for so you press

00:53:24,069 --> 00:53:28,569
a button and it does intel's top-down

00:53:26,319 --> 00:53:31,119
analysis of PMC's and gives you the

00:53:28,569 --> 00:53:33,430
answer or does threat state analysis and

00:53:31,119 --> 00:53:36,029
gives you the answer and so we don't all

00:53:33,430 --> 00:53:39,789
have to do the hard heavy lifting for

00:53:36,029 --> 00:53:41,440
some of these detailed methodologies so

00:53:39,789 --> 00:53:43,900
once someone does someone at your

00:53:41,440 --> 00:53:45,730
company does maybe it's someone on

00:53:43,900 --> 00:53:47,140
someone who looks after performance or

00:53:45,730 --> 00:53:48,640
the operating system and they can write

00:53:47,140 --> 00:53:50,289
the tools and dashboards and share them

00:53:48,640 --> 00:53:54,910
or maybe it's a third party company

00:53:50,289 --> 00:53:57,069
that's selling that is a dutchman be

00:53:54,910 --> 00:53:59,500
aware that dynamic tracing is very

00:53:57,069 --> 00:54:01,720
efficient and we should it's a different

00:53:59,500 --> 00:54:05,200
mindset I still run into people who are

00:54:01,720 --> 00:54:07,240
thinking of who think only the lines of

00:54:05,200 --> 00:54:08,799
TCP dump it's like well let's dump all

00:54:07,240 --> 00:54:11,109
the packets and then post process and we

00:54:08,799 --> 00:54:11,799
can we can identify everything like we

00:54:11,109 --> 00:54:15,130
transmit

00:54:11,799 --> 00:54:18,220
well with dynamic Tracy I can just trace

00:54:15,130 --> 00:54:20,799
whatever the transmit function is and I

00:54:18,220 --> 00:54:22,450
don't have to touch every packet or

00:54:20,799 --> 00:54:24,220
whatever the activities there's probably

00:54:22,450 --> 00:54:25,809
kernel function that deals with it so

00:54:24,220 --> 00:54:28,480
you can end up with much more efficient

00:54:25,809 --> 00:54:30,579
instrumentation I really don't touch

00:54:28,480 --> 00:54:32,619
every packet is of these our last resort

00:54:30,579 --> 00:54:35,049
can you imagine doing that when we're

00:54:32,619 --> 00:54:36,759
over 33% of the US Internet traffic at

00:54:35,049 --> 00:54:38,529
night and then you have vendors coming

00:54:36,759 --> 00:54:40,210
to Netflix and say hey buy a product

00:54:38,529 --> 00:54:42,400
it's just gonna instrument every package

00:54:40,210 --> 00:54:44,230
it's like do you not know Netflix we are

00:54:42,400 --> 00:54:46,180
we are a third of the internet traffic

00:54:44,230 --> 00:54:49,359
we can't do that you can't add overhead

00:54:46,180 --> 00:54:52,869
to every packet so yeah I've had this

00:54:49,359 --> 00:54:54,009
conversation a lot so eventually they'll

00:54:52,869 --> 00:54:55,630
figure it out cuz they'll realize we're

00:54:54,009 --> 00:54:58,059
not buying their products because we

00:54:55,630 --> 00:54:59,440
can't turn them on you can solve a lot

00:54:58,059 --> 00:55:05,019
of these things without touching every

00:54:59,440 --> 00:55:06,940
paddock and of course of dynamic tracing

00:55:05,019 --> 00:55:09,670
you can really go to town he's an old

00:55:06,940 --> 00:55:14,319
diagram of mine from Solaris with a lot

00:55:09,670 --> 00:55:16,990
of the DTrace tools I wrote these these

00:55:14,319 --> 00:55:19,480
fortunately have survived so they've

00:55:16,990 --> 00:55:21,310
been ported and they work on BSD

00:55:19,480 --> 00:55:23,590
haven't completely died and so there is

00:55:21,310 --> 00:55:28,210
a under the open D trace project there

00:55:23,590 --> 00:55:30,250
is the eateries talking tools and maybe

00:55:28,210 --> 00:55:33,280
that interests you to help out and see

00:55:30,250 --> 00:55:36,550
which ones still need to be ported but I

00:55:33,280 --> 00:55:38,440
just put this slide is an example of we

00:55:36,550 --> 00:55:41,650
have a lot of instrumentation available

00:55:38,440 --> 00:55:46,119
to us nowadays and forth monitoring

00:55:41,650 --> 00:55:49,540
counters so this PMC's his PM secrets on

00:55:46,119 --> 00:55:50,800
bsd for Intel Sandy Bridge so you can

00:55:49,540 --> 00:55:53,740
see it's a functional diagram so I

00:55:50,800 --> 00:55:55,240
already like it drew this one and so I

00:55:53,740 --> 00:55:57,820
can go through the functional diagram

00:55:55,240 --> 00:55:59,140
and I can figure out how to instrument

00:55:57,820 --> 00:56:01,450
them actually I drew the functional

00:55:59,140 --> 00:56:02,619
diagram then I looked at PMC stat and

00:56:01,450 --> 00:56:04,390
then I looked at all the groups and then

00:56:02,619 --> 00:56:10,350
I decorated it and now I have something

00:56:04,390 --> 00:56:13,300
useful for attacking PMC zombie st and

00:56:10,350 --> 00:56:15,670
visualizations is the last thing I want

00:56:13,300 --> 00:56:17,350
you to have a takeaway so we need to do

00:56:15,670 --> 00:56:19,540
better with visualizations in monitoring

00:56:17,350 --> 00:56:22,720
products later heat maps should be a

00:56:19,540 --> 00:56:27,520
common staple line graphs very useful as

00:56:22,720 --> 00:56:28,869
well so it's the crystal ball age of

00:56:27,520 --> 00:56:31,470
performance observed building whatever

00:56:28,869 --> 00:56:33,400
questions you want to be answered and

00:56:31,470 --> 00:56:35,200
methodologies like so much summarized

00:56:33,400 --> 00:56:39,369
here or a great way to pose those

00:56:35,200 --> 00:56:41,680
questions and I'll post these slides

00:56:39,369 --> 00:56:45,690
online I've got all the references and

00:56:41,680 --> 00:56:57,090
resources and thank you very much

00:56:45,690 --> 00:56:57,090
[Applause]

00:57:00,049 --> 00:57:04,890
do we have any questions you have a few

00:57:03,990 --> 00:57:08,029
minutes for questions

00:57:04,890 --> 00:57:08,029
Joe awesome

00:57:16,819 --> 00:57:20,000
no one

00:57:35,190 --> 00:57:45,940
thanks for the talk so I just wanted to

00:57:39,970 --> 00:57:49,630
ask so you mentioned that BPF could be

00:57:45,940 --> 00:57:51,640
put it to the BST so do you see that as

00:57:49,630 --> 00:57:53,920
a replacement for the DJ's or as a

00:57:51,640 --> 00:57:58,660
complementary feature or functionality

00:57:53,920 --> 00:58:00,310
which could provide more coverage so the

00:57:58,660 --> 00:58:04,090
question is about if you have the mic

00:58:00,310 --> 00:58:05,590
anyway so about if we were to put eb PF

00:58:04,090 --> 00:58:08,710
games obviously well put it this way

00:58:05,590 --> 00:58:09,940
basting already has BPF so you already

00:58:08,710 --> 00:58:12,580
have it so it's not like we're

00:58:09,940 --> 00:58:13,870
introducing something totally new and so

00:58:12,580 --> 00:58:16,630
it's a matter of enhancing what's

00:58:13,870 --> 00:58:19,960
already there and it would be something

00:58:16,630 --> 00:58:23,230
that I could say either dtrace or

00:58:19,960 --> 00:58:24,880
another front end front end would use to

00:58:23,230 --> 00:58:27,760
do the advanced instrumentation like

00:58:24,880 --> 00:58:29,590
merging stacks in current context so EBP

00:58:27,760 --> 00:58:32,050
F itself is just the engine that runs a

00:58:29,590 --> 00:58:36,070
program when an event fires you still

00:58:32,050 --> 00:58:37,960
need the instrumentation part that does

00:58:36,070 --> 00:58:40,600
the dynamic or static tracing and then

00:58:37,960 --> 00:58:42,640
calls EBP F and you still need a

00:58:40,600 --> 00:58:45,220
front-end part which is a high-level

00:58:42,640 --> 00:58:46,540
language for you to write things in so

00:58:45,220 --> 00:58:52,360
there's lots of different things we can

00:58:46,540 --> 00:58:54,130
do but if to start with if BST was

00:58:52,360 --> 00:58:56,350
enhanced with the EBP F instructions

00:58:54,130 --> 00:58:58,870
then maybe one of the smallest steps

00:58:56,350 --> 00:59:01,750
would be for dtrace to be able to use it

00:58:58,870 --> 00:59:03,160
as needed and I've already talked to

00:59:01,750 --> 00:59:06,460
some people who are interested in doing

00:59:03,160 --> 00:59:08,700
this development including for enhancing

00:59:06,460 --> 00:59:11,830
BST firewalling

00:59:08,700 --> 00:59:14,800
speakers with BPF you can have basically

00:59:11,830 --> 00:59:17,590
an unlimited map in kernel memory that

00:59:14,800 --> 00:59:19,240
the kernel program can access and use

00:59:17,590 --> 00:59:21,370
the level can access and so user level

00:59:19,240 --> 00:59:23,770
can populate and update things and so

00:59:21,370 --> 00:59:25,750
you can have a a potentially a much

00:59:23,770 --> 00:59:28,300
faster firewall for complicated rule

00:59:25,750 --> 00:59:30,850
sets and CloudFlare and Facebook are

00:59:28,300 --> 00:59:34,540
already using EPP f4 like DDoS attack

00:59:30,850 --> 00:59:37,150
mitigation and so EB gift looks like EPF

00:59:34,540 --> 00:59:39,520
may show up in beasties and enhancement

00:59:37,150 --> 00:59:41,410
to existing vpf and then it's used for

00:59:39,520 --> 00:59:45,890
DDoS mitigation and security and no one

00:59:41,410 --> 00:59:47,300
uses of observability right I would

00:59:45,890 --> 00:59:49,940
at some point someone's gonna put the

00:59:47,300 --> 00:59:52,280
that it's just the extensions over to

00:59:49,940 --> 00:59:54,020
BSD and we'll see what see what happens

00:59:52,280 --> 00:59:55,580
for them from there should be at least

00:59:54,020 --> 01:00:01,940
they'll be using it for Software Defined

00:59:55,580 --> 01:00:05,320
Networking I'm sure George Devol nail

01:00:01,940 --> 01:00:08,990
can you talk more about future plans and

01:00:05,320 --> 01:00:10,250
maybe George and I can George and I can

01:00:08,990 --> 01:00:15,320
talk about it we can figure something

01:00:10,250 --> 01:00:22,970
out okay no more questions so we had a

01:00:15,320 --> 01:00:25,280
question down the front that thread

01:00:22,970 --> 01:00:28,940
state analysis Julie wrote when can I

01:00:25,280 --> 01:00:32,740
use it I will publish it it's new I may

01:00:28,940 --> 01:00:35,330
have missed something up but I'll I will

01:00:32,740 --> 01:00:36,860
stick a link in the slide deck and then

01:00:35,330 --> 01:00:38,300
put the slide deck on SlideShare so you

01:00:36,860 --> 01:00:40,580
will if you get a slide on there

01:00:38,300 --> 01:00:42,640
such Bren Greg you'll find the links and

01:00:40,580 --> 01:00:46,010
I actually have a github repository of

01:00:42,640 --> 01:00:48,530
just BSD a previous duty-free store

01:00:46,010 --> 01:00:51,350
sociable in there and tell me if I've

01:00:48,530 --> 01:00:54,190
messed something up so I think it makes

01:00:51,350 --> 01:00:54,190
sense I think it makes sense

01:00:55,060 --> 01:00:59,989
thank you how much

01:00:57,590 --> 01:00:59,989

YouTube URL: https://www.youtube.com/watch?v=ZNkFDHLQnrA


