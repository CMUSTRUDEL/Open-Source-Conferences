Title: OpenStack and OpenContrail for FreeBSD platform - Michał Dubiel
Publication date: 2019-10-14
Playlist: EuroBSDcon 2014, Bulgaria
Description: 
	Abstract:

OpenStack and OpenContrail network virtualization solution form a complete suite able to successfully handle orchestration of resources and services of a contemporary cloud installations. These projects, however, have been only available for Linux hosted platforms by now. This talk is about a work underway that brings them into the FreeBSD world.It explains in greater details an architecture of an OpenStack system and shows how support for the FreeBSD bhyve hypervisor was brought up using the libvirt library. Details of the OpenContrail network virtualization solution is also provided, with special emphasis on the lower level system entities like a vRouter kernel module, which required most of the work while developing the FreeBSD version.

Speaker biography:

Michal Dubiel, M.Sc. Eng., born 17th of September 1983 in KrakÛw, Poland. He graduated in 2009 from the faculty of Electrical Engineering, Automatics, Computer Science and Electronics of AGH University of Science and Technology in KrakÛw. Throughout his career he worked for ACK Cyfronet AGH on hardware-accelerated data mining systems and later for Motorola Electronics on DSP software for LTE base stations. Currently he is working for Semihalf on various software projects ranging from low level kernel development to Software Defined Networking systems. He is mainly interested in the computer science, especially the operating systems, programming languages, networks, and digital signal processing.
Captions: 
	00:00:00,000 --> 00:00:10,280
I would like to talk about it also we

00:00:07,859 --> 00:00:14,670
were interested only in the networking

00:00:10,280 --> 00:00:17,400
utilization things related to opaque

00:00:14,670 --> 00:00:20,100
contrast so it also involves the open

00:00:17,400 --> 00:00:24,359
stack because our use case was about

00:00:20,100 --> 00:00:27,599
data center orchestration and network

00:00:24,359 --> 00:00:31,610
virtualization these need data centers

00:00:27,599 --> 00:00:34,550
so I'd like to talk about this today

00:00:31,610 --> 00:00:38,309
what's the plan I would like to talk

00:00:34,550 --> 00:00:41,760
introduce a bit an open stack what is it

00:00:38,309 --> 00:00:47,309
why it has been invented what problems

00:00:41,760 --> 00:00:49,710
it it solves just take two just talk a

00:00:47,309 --> 00:00:52,980
bit about this and then focus more on on

00:00:49,710 --> 00:00:56,309
open contrary which was the most work we

00:00:52,980 --> 00:00:59,640
were doing actually and talk about why

00:00:56,309 --> 00:01:02,579
why it was also invented why what kind

00:00:59,640 --> 00:01:06,150
of problems it solves and how it does

00:01:02,579 --> 00:01:09,869
itself try to describe a bit the

00:01:06,150 --> 00:01:12,390
software architecture of all this and at

00:01:09,869 --> 00:01:15,119
the at the end of the presentation I'd

00:01:12,390 --> 00:01:17,340
like to present the status and what are

00:01:15,119 --> 00:01:20,729
the next steps that has to be done why

00:01:17,340 --> 00:01:23,100
I'm talking about open contrail today in

00:01:20,729 --> 00:01:26,790
this presentation is because one of the

00:01:23,100 --> 00:01:29,820
tasks I was involved was supporting open

00:01:26,790 --> 00:01:34,170
contract to FreeBSD because you may know

00:01:29,820 --> 00:01:36,329
this systems probably better OpenStack

00:01:34,170 --> 00:01:38,820
than open contrail but they were they

00:01:36,329 --> 00:01:41,100
had been available only on a Linux

00:01:38,820 --> 00:01:45,869
platform and we wanted to change it and

00:01:41,100 --> 00:01:48,060
and actually we did it so when it comes

00:01:45,869 --> 00:01:51,740
to the data center we have something

00:01:48,060 --> 00:01:55,290
like picture here we have many

00:01:51,740 --> 00:01:57,509
hypervisor which are physical servers

00:01:55,290 --> 00:02:00,570
physical machines and we host many

00:01:57,509 --> 00:02:03,030
virtual machines that can pound some

00:02:00,570 --> 00:02:05,450
user applications when your cloud

00:02:03,030 --> 00:02:08,759
provider you want to you will have

00:02:05,450 --> 00:02:11,910
plenty of users each user may have

00:02:08,759 --> 00:02:14,670
plenty of feature machines because they

00:02:11,910 --> 00:02:17,090
his application may involve having

00:02:14,670 --> 00:02:20,040
separate database on different machine

00:02:17,090 --> 00:02:22,530
some load balancing on different and

00:02:20,040 --> 00:02:25,380
this kind of things so you'll end up

00:02:22,530 --> 00:02:27,360
having many virtual machines that will

00:02:25,380 --> 00:02:31,200
be transparent to your user

00:02:27,360 --> 00:02:35,300
he will just like to use them as a as

00:02:31,200 --> 00:02:37,560
just a regular server and when you are

00:02:35,300 --> 00:02:40,220
managing this kind of data center you

00:02:37,560 --> 00:02:44,520
have to make a decision on which

00:02:40,220 --> 00:02:48,450
Hardware you want to run with v vm it is

00:02:44,520 --> 00:02:51,900
important because because given server

00:02:48,450 --> 00:02:54,720
may have not enough resources to house

00:02:51,900 --> 00:02:57,510
here and other VMs and managing this

00:02:54,720 --> 00:03:01,760
kind of stuff and setting up networking

00:02:57,510 --> 00:03:06,900
between those VMs may be challenging and

00:03:01,760 --> 00:03:10,530
and something that will manage this has

00:03:06,900 --> 00:03:13,440
to be introduced and we can see that it

00:03:10,530 --> 00:03:15,510
is quite similar to what we see when we

00:03:13,440 --> 00:03:19,230
have one machine we have also resources

00:03:15,510 --> 00:03:21,540
we have CPU cores we have memory we have

00:03:19,230 --> 00:03:24,030
storage we have networking and the

00:03:21,540 --> 00:03:28,200
operating system is doing manual

00:03:24,030 --> 00:03:30,360
management of this on our behalf so so

00:03:28,200 --> 00:03:33,530
this is exactly the same situation but

00:03:30,360 --> 00:03:37,080
we have many machines and what was

00:03:33,530 --> 00:03:39,420
created is an OpenStack and OpenStack

00:03:37,080 --> 00:03:42,150
calls themselves that they are the cloud

00:03:39,420 --> 00:03:44,280
operating system and I think they they

00:03:42,150 --> 00:03:47,880
are pretty right because this is

00:03:44,280 --> 00:03:50,300
actually what what it does they divided

00:03:47,880 --> 00:03:54,360
it in two into three major

00:03:50,300 --> 00:03:58,350
functionalities they compute the the

00:03:54,360 --> 00:04:01,140
networking and the storage I'll focus on

00:03:58,350 --> 00:04:03,660
those two first about compute and about

00:04:01,140 --> 00:04:07,530
networking about compute because we have

00:04:03,660 --> 00:04:10,710
to have ability to spawn a VM on a given

00:04:07,530 --> 00:04:13,140
machine so it is necessary and

00:04:10,710 --> 00:04:15,390
networking because we were most

00:04:13,140 --> 00:04:19,280
interested in this as open control is a

00:04:15,390 --> 00:04:24,770
solution is external solution to handle

00:04:19,280 --> 00:04:24,770
complex scenarios and very large systems

00:04:24,870 --> 00:04:33,540
when you have to have some kind of

00:04:29,120 --> 00:04:37,200
flexibility in terms of configuring and

00:04:33,540 --> 00:04:41,820
managing networking so let's start with

00:04:37,200 --> 00:04:47,640
the with the OpenStack it's actually

00:04:41,820 --> 00:04:50,490
what I said previously that they aims to

00:04:47,640 --> 00:04:53,760
manage those three things and the things

00:04:50,490 --> 00:04:57,510
about compute and storage has been had

00:04:53,760 --> 00:04:59,310
been already very well supported by

00:04:57,510 --> 00:05:03,660
OpenStack but when it comes to

00:04:59,310 --> 00:05:07,190
networking the I don't know the stack

00:05:03,660 --> 00:05:09,870
solution implemented in OpenStack is not

00:05:07,190 --> 00:05:12,660
good if you have a large number of

00:05:09,870 --> 00:05:14,490
systems it doesn't scale just so in

00:05:12,660 --> 00:05:17,040
terms of networking you have to have

00:05:14,490 --> 00:05:20,400
something extra some external solution

00:05:17,040 --> 00:05:23,250
that we all will allow you to maintain

00:05:20,400 --> 00:05:27,150
your data center and expansion of your

00:05:23,250 --> 00:05:31,350
data center but for the simple scenarios

00:05:27,150 --> 00:05:35,010
it works very well so we ported also the

00:05:31,350 --> 00:05:37,440
networking inherently lamented in in the

00:05:35,010 --> 00:05:39,630
OpenStack to FreeBSD and also reported

00:05:37,440 --> 00:05:43,770
the open contrail which I was for more

00:05:39,630 --> 00:05:46,890
sophisticated networks European stack is

00:05:43,770 --> 00:05:49,230
composed of many many components that

00:05:46,890 --> 00:05:53,010
the most important one for the compute

00:05:49,230 --> 00:05:57,840
is Nova it implements the wall which is

00:05:53,010 --> 00:06:00,510
necessary to schedule a VM on a given on

00:05:57,840 --> 00:06:04,050
a given Hardware and then talk to the

00:06:00,510 --> 00:06:06,780
hypervisor and and just spawn this VM it

00:06:04,050 --> 00:06:10,410
also provides these networking managing

00:06:06,780 --> 00:06:13,350
facilities but these are in the case of

00:06:10,410 --> 00:06:16,340
this simple networking scenarios now

00:06:13,350 --> 00:06:18,450
Tron is a component which provides

00:06:16,340 --> 00:06:21,720
networking service that may be

00:06:18,450 --> 00:06:24,060
implemented by the external systems such

00:06:21,720 --> 00:06:26,640
as open control via the plugins

00:06:24,060 --> 00:06:28,980
mechanism and there is also others like

00:06:26,640 --> 00:06:30,900
glass which holds the images because if

00:06:28,980 --> 00:06:33,750
you want one to spawn a VM you have to

00:06:30,900 --> 00:06:35,669
you have to fetch the image from

00:06:33,750 --> 00:06:36,500
somewhere so there is plenty of other

00:06:35,669 --> 00:06:41,180
components

00:06:36,500 --> 00:06:43,520
but our interest and we were we

00:06:41,180 --> 00:06:48,230
were focused on on this compute note

00:06:43,520 --> 00:06:50,660
components because of they are the one

00:06:48,230 --> 00:06:53,570
that are dependent on the underlying

00:06:50,660 --> 00:06:55,250
platform because the rest actually every

00:06:53,570 --> 00:06:57,830
component in OpenStack is written in

00:06:55,250 --> 00:06:59,930
Python and they're just using standard

00:06:57,830 --> 00:07:02,900
to standard libraries so if you have

00:06:59,930 --> 00:07:04,580
this library you can just run it on any

00:07:02,900 --> 00:07:06,410
platform you want but there are

00:07:04,580 --> 00:07:08,030
exception when you want to talk directly

00:07:06,410 --> 00:07:10,580
to the operating system like for

00:07:08,030 --> 00:07:13,220
instance the hypervisor and since we

00:07:10,580 --> 00:07:16,130
have beehive in freebsd now we can use

00:07:13,220 --> 00:07:20,240
freebsd as as the underlying platform

00:07:16,130 --> 00:07:24,230
for the OpenStack so now try to focus on

00:07:20,240 --> 00:07:28,660
this compute now and say a few words

00:07:24,230 --> 00:07:35,330
about that calc it not works

00:07:28,660 --> 00:07:38,180
it requires maybe it's like we have a

00:07:35,330 --> 00:07:39,830
hypervisor like behaving we have to be

00:07:38,180 --> 00:07:42,710
able to control it

00:07:39,830 --> 00:07:45,260
the simplest way is to use some

00:07:42,710 --> 00:07:48,350
abstraction line like liber8 which is

00:07:45,260 --> 00:07:50,480
fortunately available on the freebsd we

00:07:48,350 --> 00:07:53,300
did some development around it but but

00:07:50,480 --> 00:07:56,270
the initial initial part of live it for

00:07:53,300 --> 00:07:59,570
free bsd and support for the beehive had

00:07:56,270 --> 00:08:03,250
already been done so so it saves us a

00:07:59,570 --> 00:08:05,750
lot of work and this deep vert is

00:08:03,250 --> 00:08:08,890
controlled by the anova compute process

00:08:05,750 --> 00:08:15,320
which is a Python like Python daemon

00:08:08,890 --> 00:08:19,340
which which just uses the buildings of

00:08:15,320 --> 00:08:21,590
the library to spawn VMs and it also

00:08:19,340 --> 00:08:23,630
talks to another process which is not

00:08:21,590 --> 00:08:26,180
one network which is responsible for

00:08:23,630 --> 00:08:29,060
setting up networking in this case it

00:08:26,180 --> 00:08:32,110
creates bridges it creates VLAN tags

00:08:29,060 --> 00:08:36,260
associates some addresses to the

00:08:32,110 --> 00:08:40,460
interfaces I create stop devices and etc

00:08:36,260 --> 00:08:43,640
etc and and those three components are

00:08:40,460 --> 00:08:47,210
necessary and those marked by violet

00:08:43,640 --> 00:08:49,960
color here we're necessary to

00:08:47,210 --> 00:08:52,250
there are missed I mean not miss but

00:08:49,960 --> 00:08:54,380
they were not working on a few big

00:08:52,250 --> 00:09:00,080
platform so all these three components

00:08:54,380 --> 00:09:03,650
has to be custom has to be rewritten but

00:09:00,080 --> 00:09:06,050
the main intent in terms of OpenStack

00:09:03,650 --> 00:09:09,410
openness the is this never compute

00:09:06,050 --> 00:09:11,930
another network which we put most of our

00:09:09,410 --> 00:09:14,810
efforts of course it was also a Lib food

00:09:11,930 --> 00:09:18,110
but the lip view it hasn't didn't

00:09:14,810 --> 00:09:20,150
require as much work as those those to

00:09:18,110 --> 00:09:23,830
some other compute is responsible as I

00:09:20,150 --> 00:09:27,080
said previously just to spawn and

00:09:23,830 --> 00:09:30,050
destroy some VM that Nava network is

00:09:27,080 --> 00:09:32,930
responsible for setting up the

00:09:30,050 --> 00:09:36,350
networking so how it actually works

00:09:32,930 --> 00:09:40,430
let's try to analyze some example when

00:09:36,350 --> 00:09:43,840
our schedule decides that this given VM

00:09:40,430 --> 00:09:46,790
should be spawn on this given platform

00:09:43,840 --> 00:09:49,310
they never compute on this server

00:09:46,790 --> 00:09:52,940
fetches de image from the glance service

00:09:49,310 --> 00:09:56,570
and builds an XML description of the

00:09:52,940 --> 00:10:00,440
domain that is to be spawned this XML

00:09:56,570 --> 00:10:03,320
it's literally defined thing that you

00:10:00,440 --> 00:10:06,440
have to create if you want serious to

00:10:03,320 --> 00:10:07,940
spawn the VM in the meantime Nava

00:10:06,440 --> 00:10:10,790
Network configures the bridges

00:10:07,940 --> 00:10:14,350
configures all which is necessary for

00:10:10,790 --> 00:10:17,540
the networking and once the libvirt

00:10:14,350 --> 00:10:20,750
spawns the vm it puts the top that

00:10:17,540 --> 00:10:23,480
corresponds to the interfaces from

00:10:20,750 --> 00:10:26,360
inside the guest VM on the proper

00:10:23,480 --> 00:10:30,440
bridges because each bridge means each

00:10:26,360 --> 00:10:33,770
virtual network in this in this case so

00:10:30,440 --> 00:10:38,390
so this is very simple simple scenario

00:10:33,770 --> 00:10:42,140
that allows you to have to have some

00:10:38,390 --> 00:10:44,840
flexibility upon spawning your VMs on

00:10:42,140 --> 00:10:48,530
different hosts and have some simple

00:10:44,840 --> 00:10:52,610
networking between them just to

00:10:48,530 --> 00:10:55,400
summarize what we up to now what we did

00:10:52,610 --> 00:10:57,080
in terms of development it was like I

00:10:55,400 --> 00:10:59,540
said before libvirt

00:10:57,080 --> 00:11:00,440
it is work of ramen burger Itsuki I hope

00:10:59,540 --> 00:11:05,060
I pronounced it

00:11:00,440 --> 00:11:09,080
correctly he made initial part of the

00:11:05,060 --> 00:11:12,350
beehive support for the for the lip

00:11:09,080 --> 00:11:15,140
field and also made some some hugs

00:11:12,350 --> 00:11:17,240
around the qmo which is also actually

00:11:15,140 --> 00:11:20,270
necessary by the Nova compete to do some

00:11:17,240 --> 00:11:24,020
stuff like converting from one to

00:11:20,270 --> 00:11:28,370
another image formats we did some

00:11:24,020 --> 00:11:33,290
adjustments in the Nova compute just to

00:11:28,370 --> 00:11:35,450
allow it to so use the be high fiber

00:11:33,290 --> 00:11:39,110
visor because the code which is

00:11:35,450 --> 00:11:42,410
responsible for generating the XML have

00:11:39,110 --> 00:11:45,350
to has to take into account that we are

00:11:42,410 --> 00:11:49,580
now using different different hypervisor

00:11:45,350 --> 00:11:52,880
and there were some things that were

00:11:49,580 --> 00:11:54,620
linux specific like mining some things

00:11:52,880 --> 00:11:57,260
inside scissor vests which we do not

00:11:54,620 --> 00:11:59,930
have in freebsd so so this was

00:11:57,260 --> 00:12:04,070
adjustments done to the another computer

00:11:59,930 --> 00:12:04,970
and when it comes to Nova network it

00:12:04,070 --> 00:12:09,290
actually works

00:12:04,970 --> 00:12:13,550
by executing common line tools on a

00:12:09,290 --> 00:12:17,720
given platform so in the linux case it

00:12:13,550 --> 00:12:20,270
was just bridge control and IP tools and

00:12:17,720 --> 00:12:25,270
we do not have this in freebsd so we

00:12:20,270 --> 00:12:29,300
have to write our driver which we'll use

00:12:25,270 --> 00:12:31,970
if config for doing this stuff also

00:12:29,300 --> 00:12:36,190
there is a big difference in executing

00:12:31,970 --> 00:12:39,170
gene mask which is serving DHCP and DNS

00:12:36,190 --> 00:12:42,110
services for the VMS in this in this

00:12:39,170 --> 00:12:44,960
case so we also have to make some

00:12:42,110 --> 00:12:47,300
modifications to this code and the last

00:12:44,960 --> 00:12:50,650
but not least is a dev stack deaf stack

00:12:47,300 --> 00:12:55,130
is a script a huge script that is

00:12:50,650 --> 00:12:59,089
supposed to install configure and run

00:12:55,130 --> 00:13:02,150
the entire open star cluster if you if

00:12:59,089 --> 00:13:04,880
you run the OpenStack trust area

00:13:02,150 --> 00:13:08,120
entirely on one host it would consist of

00:13:04,880 --> 00:13:10,050
more than 20 processes each of them has

00:13:08,120 --> 00:13:12,810
to be properly

00:13:10,050 --> 00:13:16,800
installed configured and executed so

00:13:12,810 --> 00:13:19,190
this is what devstack does and of course

00:13:16,800 --> 00:13:21,600
there are no support for FreeBSD and

00:13:19,190 --> 00:13:23,339
unfortunately it's a bit paintwork with

00:13:21,600 --> 00:13:25,110
their stack because there is a lot of

00:13:23,339 --> 00:13:27,180
ifs there are a lot of differences

00:13:25,110 --> 00:13:29,580
between even flavors of Linux

00:13:27,180 --> 00:13:31,950
distributions like if you have federal

00:13:29,580 --> 00:13:34,050
Centaurus or Ubuntu there are different

00:13:31,950 --> 00:13:36,330
packages may be named differently and

00:13:34,050 --> 00:13:39,209
you have to cope with this we have

00:13:36,330 --> 00:13:41,610
totally different things in freebsd so

00:13:39,209 --> 00:13:45,330
it is unfortunately still diverging we

00:13:41,610 --> 00:13:48,360
haven't we haven't yet majid upstream so

00:13:45,330 --> 00:13:49,950
they're staggered routes so it all the

00:13:48,360 --> 00:13:51,959
time is diverging because they are some

00:13:49,950 --> 00:13:54,360
changing some things and it broke sorry

00:13:51,959 --> 00:13:56,820
so it's a bit of pain but we have to

00:13:54,360 --> 00:14:00,450
have something that is able to easily

00:13:56,820 --> 00:14:03,500
set up a cluster just for example for

00:14:00,450 --> 00:14:05,970
the development purposes so that was

00:14:03,500 --> 00:14:10,440
that was what we did in terms of

00:14:05,970 --> 00:14:13,980
OpenStack we created this part of Nova

00:14:10,440 --> 00:14:16,260
compute another network but our goal was

00:14:13,980 --> 00:14:22,800
to have more sophisticated ways of

00:14:16,260 --> 00:14:26,520
networking so we now went to the open

00:14:22,800 --> 00:14:29,760
contrail which is actually serving this

00:14:26,520 --> 00:14:32,880
networking part of the OpenStack and

00:14:29,760 --> 00:14:36,120
let's have a closer look about what we

00:14:32,880 --> 00:14:39,300
have in the typical Iraq in the data

00:14:36,120 --> 00:14:41,579
center we have a switch which connects

00:14:39,300 --> 00:14:44,399
those physical machines and inside of

00:14:41,579 --> 00:14:49,529
this physical machines we have there is

00:14:44,399 --> 00:14:52,230
VM so we see that even if we have only

00:14:49,529 --> 00:14:55,470
one physical endpoints networking points

00:14:52,230 --> 00:14:58,529
we may have several virtual logical end

00:14:55,470 --> 00:15:00,870
points associated because we have

00:14:58,529 --> 00:15:03,240
several machines running on this house

00:15:00,870 --> 00:15:05,490
and this is only one rack in reality

00:15:03,240 --> 00:15:08,970
will you will have much more racks much

00:15:05,490 --> 00:15:11,670
more servers and you have to provide net

00:15:08,970 --> 00:15:13,350
network connectivity between them and if

00:15:11,670 --> 00:15:15,570
it comes to the physical network

00:15:13,350 --> 00:15:18,709
connectivity this is an example of

00:15:15,570 --> 00:15:22,529
top-of-rack architecture you use a

00:15:18,709 --> 00:15:27,980
typical cross network detector to

00:15:22,529 --> 00:15:31,650
connect each of the of the physical host

00:15:27,980 --> 00:15:34,740
to each other so it looks like you we

00:15:31,650 --> 00:15:39,180
have now the problem of the physical

00:15:34,740 --> 00:15:42,060
connectivity is done but the the ritual

00:15:39,180 --> 00:15:44,550
endpoints may migrate from one host to

00:15:42,060 --> 00:15:47,550
another host may be in one rack the

00:15:44,550 --> 00:15:51,660
later in other Iraq so the packets for

00:15:47,550 --> 00:15:56,630
this ritual endpoints has to cross over

00:15:51,660 --> 00:16:00,570
this physical the physical networks and

00:15:56,630 --> 00:16:03,300
it may not be as easy as it seems

00:16:00,570 --> 00:16:04,410
because it may involve in the typical

00:16:03,300 --> 00:16:07,320
scenario it may involve

00:16:04,410 --> 00:16:10,140
necessity of reconfiguration of the

00:16:07,320 --> 00:16:12,959
switch and so on so what we can observe

00:16:10,140 --> 00:16:17,370
is that the very important observation

00:16:12,959 --> 00:16:18,990
is that the in contemporary data center

00:16:17,370 --> 00:16:21,149
installations the majority of the

00:16:18,990 --> 00:16:26,070
endpoints are virtual so we need to take

00:16:21,149 --> 00:16:28,260
special care of this and we have to we

00:16:26,070 --> 00:16:29,850
have to have an isolation between them

00:16:28,260 --> 00:16:32,750
because you may have several users

00:16:29,850 --> 00:16:35,990
either may have want

00:16:32,750 --> 00:16:39,319
have isolation between its front-end or

00:16:35,990 --> 00:16:42,230
back-end system in these applications

00:16:39,319 --> 00:16:46,660
whatever so we have to provide all this

00:16:42,230 --> 00:16:46,660
and we don't want to change the physical

00:16:47,439 --> 00:16:54,769
network when this it is doing because we

00:16:51,259 --> 00:16:57,740
want to build a data center and then let

00:16:54,769 --> 00:17:05,179
users decide what they want to do with

00:16:57,740 --> 00:17:08,959
this so we know we don't like to have to

00:17:05,179 --> 00:17:12,860
be forced to do some hardware changes to

00:17:08,959 --> 00:17:14,270
that and there are some solutions as

00:17:12,860 --> 00:17:16,400
many solutions I would like to present

00:17:14,270 --> 00:17:18,620
two of them one is the bridges and

00:17:16,400 --> 00:17:21,709
villains which is what actually does

00:17:18,620 --> 00:17:24,319
OpenStack by default that what I was

00:17:21,709 --> 00:17:28,789
talking about previously and the other

00:17:24,319 --> 00:17:33,429
is the overlay networking which is what

00:17:28,789 --> 00:17:37,220
opaque on trail is doing I'll try to

00:17:33,429 --> 00:17:41,030
compare them and now in a minute we all

00:17:37,220 --> 00:17:44,750
see why the latter is much better

00:17:41,030 --> 00:17:47,809
solution let's stick with villains when

00:17:44,750 --> 00:17:51,230
we have a villains we just put VMs on

00:17:47,809 --> 00:17:53,570
the house and and you defy the network

00:17:51,230 --> 00:17:56,690
virtual networks by VLAN tags and

00:17:53,570 --> 00:18:03,230
bridges we have a limit here so if we

00:17:56,690 --> 00:18:05,539
want to have more than 4096 we hit a

00:18:03,230 --> 00:18:08,600
problem we can of course overcome is

00:18:05,539 --> 00:18:11,299
using a shorter path region but but it

00:18:08,600 --> 00:18:14,270
is not very flexible difficult to manage

00:18:11,299 --> 00:18:16,309
and and what's important the physical

00:18:14,270 --> 00:18:19,909
switches those there may be a lot of

00:18:16,309 --> 00:18:21,890
them they may be very expensive has to

00:18:19,909 --> 00:18:24,919
keep a state of the virtual networks

00:18:21,890 --> 00:18:29,480
industry in the system why is that let's

00:18:24,919 --> 00:18:31,640
take a simple example we have a three

00:18:29,480 --> 00:18:34,730
servers here server one two and three

00:18:31,640 --> 00:18:37,640
and have VMs on each and I distinguish

00:18:34,730 --> 00:18:40,880
the different virtual networks by color

00:18:37,640 --> 00:18:43,220
so we have here red and blue virtual

00:18:40,880 --> 00:18:46,300
network and let's assume you want to

00:18:43,220 --> 00:18:49,840
send packet from VN one the

00:18:46,300 --> 00:18:52,720
in top left corner to the vm9 so blue

00:18:49,840 --> 00:18:55,650
Network which is at the bottom so what

00:18:52,720 --> 00:18:59,559
we'll see on a wire is that we'll see

00:18:55,650 --> 00:19:03,760
Ethernet MAC address VLAN tag and IP of

00:18:59,559 --> 00:19:07,540
the VM 9 and this packet will hit the

00:19:03,760 --> 00:19:11,050
switch and this switch has to know on

00:19:07,540 --> 00:19:14,170
which port this VM is now connected

00:19:11,050 --> 00:19:15,760
because the switch by our protocol knows

00:19:14,170 --> 00:19:19,030
where the physical house are connected

00:19:15,760 --> 00:19:21,640
but if we put on the wire the IP address

00:19:19,030 --> 00:19:25,330
of the virtual network it also has to

00:19:21,640 --> 00:19:28,380
somehow know that it has to prove this

00:19:25,330 --> 00:19:32,050
packet to the port 3 the problem is when

00:19:28,380 --> 00:19:36,250
the vm9 migrates from several 3 to

00:19:32,050 --> 00:19:39,610
server 2 then the switch has to now no

00:19:36,250 --> 00:19:43,540
longer forward packets to the V and 9 to

00:19:39,610 --> 00:19:46,510
the server 3 but port 3 but it has to

00:19:43,540 --> 00:19:50,350
followed it to the port 2 so somehow it

00:19:46,510 --> 00:19:52,750
has to get know that this happened that

00:19:50,350 --> 00:19:54,490
this migration has happened of course we

00:19:52,750 --> 00:19:57,730
know the emigration happens because we

00:19:54,490 --> 00:20:01,929
had the OpenStack orchestration system

00:19:57,730 --> 00:20:04,059
and he decides where the VM is now

00:20:01,929 --> 00:20:08,350
located so the information is but it has

00:20:04,059 --> 00:20:10,230
to be somehow propagated to the to these

00:20:08,350 --> 00:20:12,640
physical switches all switches that

00:20:10,230 --> 00:20:15,400
takes part in the root of the packet

00:20:12,640 --> 00:20:19,950
there are solutions for this for

00:20:15,400 --> 00:20:23,110
instance standard open flow tries to

00:20:19,950 --> 00:20:26,440
standardize the way how this controllers

00:20:23,110 --> 00:20:29,050
can talk to the switches and then do it

00:20:26,440 --> 00:20:33,010
automatically when when the VM migrates

00:20:29,050 --> 00:20:35,440
it can configure the switch but it it is

00:20:33,010 --> 00:20:39,190
some solution but there is a better

00:20:35,440 --> 00:20:41,710
solution which open control provides and

00:20:39,190 --> 00:20:44,740
it is based on the over line networking

00:20:41,710 --> 00:20:48,610
it is by no means new technology it has

00:20:44,740 --> 00:20:51,820
been known by the industry for years but

00:20:48,610 --> 00:20:54,669
its utilization in data center is

00:20:51,820 --> 00:20:56,280
relatively new and what it does it

00:20:54,669 --> 00:20:58,590
separates

00:20:56,280 --> 00:21:04,110
the physical and the logical or virtual

00:20:58,590 --> 00:21:06,930
networks from each other their physical

00:21:04,110 --> 00:21:09,390
underlying network is called by in the

00:21:06,930 --> 00:21:11,580
open country nomenclature IP fabric and

00:21:09,390 --> 00:21:14,460
it contains no tenant state you have

00:21:11,580 --> 00:21:19,050
most information about virtual networks

00:21:14,460 --> 00:21:22,050
about anything in the physical physical

00:21:19,050 --> 00:21:24,930
network every state information except

00:21:22,050 --> 00:21:29,190
gateways but maybe about this a bit

00:21:24,930 --> 00:21:31,880
later on all the state information is

00:21:29,190 --> 00:21:34,800
contained in the virtual overlay

00:21:31,880 --> 00:21:37,530
networking and topic on try users sample

00:21:34,800 --> 00:21:39,870
is over Greve AVX LAN and main pillars

00:21:37,530 --> 00:21:41,790
over you the people types of of

00:21:39,870 --> 00:21:44,100
tunneling because this over line

00:21:41,790 --> 00:21:47,850
networks are created as two nodes

00:21:44,100 --> 00:21:50,370
between between the VMS so let's go back

00:21:47,850 --> 00:21:52,380
to the same example but now let's see

00:21:50,370 --> 00:21:56,670
what happens when we have an overlay

00:21:52,380 --> 00:22:00,150
Network so EVM tries to reach vm v 1

00:21:56,670 --> 00:22:04,280
tries to reach vm 9 the view router the

00:22:00,150 --> 00:22:08,220
the software in this in this server 1

00:22:04,280 --> 00:22:11,700
hypervisor it encapsulate the packets

00:22:08,220 --> 00:22:15,690
for the VN 9 with the header of the

00:22:11,700 --> 00:22:17,730
physical server 3 because as I

00:22:15,690 --> 00:22:19,620
previously mentioned that this

00:22:17,730 --> 00:22:22,590
information is available the controller

00:22:19,620 --> 00:22:24,870
we don't have to we we know this because

00:22:22,590 --> 00:22:27,330
we have components of the entire system

00:22:24,870 --> 00:22:30,060
in the hypervisor in the software so we

00:22:27,330 --> 00:22:32,790
know that that this VM is now running on

00:22:30,060 --> 00:22:36,200
the server 3 so we encapsulate our

00:22:32,790 --> 00:22:41,040
packets V and 9 with the header of the

00:22:36,200 --> 00:22:43,920
SV server and put it to the network this

00:22:41,040 --> 00:22:47,730
is just alternate and IP

00:22:43,920 --> 00:22:50,580
network so the switch when once the

00:22:47,730 --> 00:22:54,090
physical server was connected to the

00:22:50,580 --> 00:22:57,720
network switch then using ARP where are

00:22:54,090 --> 00:23:00,210
which servers so it doesn't have so it

00:22:57,720 --> 00:23:05,790
knows where to put pockets on which part

00:23:00,210 --> 00:23:09,330
and when the when the VN migrates from

00:23:05,790 --> 00:23:14,820
one several three to several two we

00:23:09,330 --> 00:23:17,549
still have the same VN we don't have any

00:23:14,820 --> 00:23:19,799
longer the same packet like it was in

00:23:17,549 --> 00:23:23,070
the previous example with VLAN because

00:23:19,799 --> 00:23:26,010
now we we know that this this VM is on a

00:23:23,070 --> 00:23:28,380
server too so we put s to a telnet

00:23:26,010 --> 00:23:32,700
header physically encapsulated with a

00:23:28,380 --> 00:23:35,669
certain eternal in IP headers and this

00:23:32,700 --> 00:23:39,049
is just sent to the physical switch

00:23:35,669 --> 00:23:42,000
physical switch knows various physical

00:23:39,049 --> 00:23:46,049
physical house so it for us it's two

00:23:42,000 --> 00:23:48,900
parts so and the packet reaches the

00:23:46,049 --> 00:23:53,010
server which is now currently which is

00:23:48,900 --> 00:23:59,270
currently hosting vn9 there are clear

00:23:53,010 --> 00:24:02,760
advantages of this of this solution

00:23:59,270 --> 00:24:05,280
because the knowledge about network is

00:24:02,760 --> 00:24:06,840
only in the software so you have the

00:24:05,280 --> 00:24:08,370
knowledge about which one networks the

00:24:06,840 --> 00:24:11,120
state of the virtual network is in the

00:24:08,370 --> 00:24:14,790
controller or in the compute nodes

00:24:11,120 --> 00:24:17,580
components and what is really nice is

00:24:14,790 --> 00:24:20,250
that any switch will work for the IP

00:24:17,580 --> 00:24:22,860
fabric you don't have to have any means

00:24:20,250 --> 00:24:26,520
of configuration this switch any switch

00:24:22,860 --> 00:24:30,900
really work only speed matters actually

00:24:26,520 --> 00:24:33,200
if it is faster it is better and if it

00:24:30,900 --> 00:24:38,040
doesn't have to have any sophisticated

00:24:33,200 --> 00:24:41,520
configuration possibilities then it may

00:24:38,040 --> 00:24:46,620
be of lower price than the former one

00:24:41,520 --> 00:24:49,650
and in case of this in case of opaque

00:24:46,620 --> 00:24:52,470
control this whole process is based on

00:24:49,650 --> 00:24:55,510
the standard protocols which makes it

00:24:52,470 --> 00:24:58,270
very easy to interoperate with

00:24:55,510 --> 00:25:02,130
the equipment in the data center so

00:24:58,270 --> 00:25:05,320
let's see how the open control is built

00:25:02,130 --> 00:25:09,090
here's a an architectural overview of

00:25:05,320 --> 00:25:13,330
the entire upper control system from the

00:25:09,090 --> 00:25:15,640
highest altitude it is actually composed

00:25:13,330 --> 00:25:19,330
of two things one things are the for

00:25:15,640 --> 00:25:21,880
waiting for waiting plane which is a V

00:25:19,330 --> 00:25:23,830
rotor and it is available on every

00:25:21,880 --> 00:25:27,760
compute node because compute nodes are

00:25:23,830 --> 00:25:30,820
the machines that actually are used to

00:25:27,760 --> 00:25:34,450
spawn the VMs but they have to have some

00:25:30,820 --> 00:25:37,510
components and the the the view the

00:25:34,450 --> 00:25:40,930
router forwarding plane is put on every

00:25:37,510 --> 00:25:43,920
hypervisor on every on every server that

00:25:40,930 --> 00:25:48,250
is hosting any VMs and the second

00:25:43,920 --> 00:25:53,010
component is is a controller which of

00:25:48,250 --> 00:25:53,010
course is built from different different

00:25:53,160 --> 00:26:00,580
components altered about them in a

00:25:56,260 --> 00:26:04,680
second but but we may distinguish those

00:26:00,580 --> 00:26:06,970
two things this controller itself is

00:26:04,680 --> 00:26:09,190
centralized but it is logically

00:26:06,970 --> 00:26:12,310
centralized and physically is

00:26:09,190 --> 00:26:14,230
distributed it allows for scalability

00:26:12,310 --> 00:26:16,600
because every component of the

00:26:14,230 --> 00:26:19,420
controller works in an active active

00:26:16,600 --> 00:26:21,250
manner so so if you are lacking of

00:26:19,420 --> 00:26:23,080
resources or something like this you

00:26:21,250 --> 00:26:25,770
just spawn an array VM because

00:26:23,080 --> 00:26:28,750
components of this control may be also

00:26:25,770 --> 00:26:31,240
in the VM or may be in the physical

00:26:28,750 --> 00:26:34,290
server so we may add another hardware

00:26:31,240 --> 00:26:39,280
and everything everything just scale out

00:26:34,290 --> 00:26:43,900
very easy so let's walk through a bit

00:26:39,280 --> 00:26:46,540
through those components at the very top

00:26:43,900 --> 00:26:51,010
we have a configuration node and the

00:26:46,540 --> 00:26:55,770
main the main the task for the

00:26:51,010 --> 00:26:58,870
configuration node is provide the API

00:26:55,770 --> 00:27:01,510
for the user or for the orchestrator in

00:26:58,870 --> 00:27:04,270
in this case when you use OpenStack use

00:27:01,510 --> 00:27:07,450
Neutron and plug-in which will talk to

00:27:04,270 --> 00:27:08,440
the configuration out and it will be

00:27:07,450 --> 00:27:13,330
talking

00:27:08,440 --> 00:27:17,200
using very high-level description so you

00:27:13,330 --> 00:27:20,320
just won this VM VM 1 and V and 2 ones

00:27:17,200 --> 00:27:22,210
in the virtual networks network a you

00:27:20,320 --> 00:27:24,610
want to a low virtual network a

00:27:22,210 --> 00:27:29,170
connectivity to virtual network be for

00:27:24,610 --> 00:27:31,810
instance yellow virtual machine 3 to be

00:27:29,170 --> 00:27:33,730
not through outside world or something

00:27:31,810 --> 00:27:37,630
like this you use very high level

00:27:33,730 --> 00:27:40,420
description primitives to describe the

00:27:37,630 --> 00:27:43,600
state of the system and this state of

00:27:40,420 --> 00:27:45,760
the system is held in the database it's

00:27:43,600 --> 00:27:50,260
Cassandra in the case of open contrail

00:27:45,760 --> 00:27:52,900
it is also it was choose because it is

00:27:50,260 --> 00:27:57,010
easily scalable so if you are looking

00:27:52,900 --> 00:28:00,130
from if you are lucky you can of laser

00:27:57,010 --> 00:28:02,560
or the performance then you may put some

00:28:00,130 --> 00:28:06,520
load balance if you do shutting of the

00:28:02,560 --> 00:28:10,150
database without any problems so this is

00:28:06,520 --> 00:28:13,360
Cassandra in case of open contrail the

00:28:10,150 --> 00:28:16,930
rest api server is of course serving the

00:28:13,360 --> 00:28:20,320
api so so it is receiving the request

00:28:16,930 --> 00:28:21,760
from the orchestrator and the very

00:28:20,320 --> 00:28:25,300
important thing is the schema

00:28:21,760 --> 00:28:28,140
transformer it is actually some kind of

00:28:25,300 --> 00:28:31,630
compile it compiles from this high level

00:28:28,140 --> 00:28:34,920
description of the networking an entire

00:28:31,630 --> 00:28:38,140
system state so more lower level

00:28:34,920 --> 00:28:42,490
primitives like routing it stands like

00:28:38,140 --> 00:28:47,050
next hope etc etc because this schema

00:28:42,490 --> 00:28:49,690
transformer makes it transformation from

00:28:47,050 --> 00:28:52,150
the description what we want to achieve

00:28:49,690 --> 00:28:55,390
to the description how we want to

00:28:52,150 --> 00:28:59,200
achieve on in this given

00:28:55,390 --> 00:29:02,110
system cluster we we made and applicant

00:28:59,200 --> 00:29:06,970
reduces if map to broadcast this

00:29:02,110 --> 00:29:10,360
information to the control notes so if

00:29:06,970 --> 00:29:12,880
something is changing user changes

00:29:10,360 --> 00:29:15,490
configuration if map server will

00:29:12,880 --> 00:29:19,710
broadcast it to the control control

00:29:15,490 --> 00:29:24,730
nodes and control nodes responsible for

00:29:19,710 --> 00:29:29,230
for setting up actual providing base

00:29:24,730 --> 00:29:33,730
information and communicating those into

00:29:29,230 --> 00:29:37,600
the compute nodes it uses XMPP for this

00:29:33,730 --> 00:29:39,580
purpose and it also gets some

00:29:37,600 --> 00:29:44,410
information from the compute nodes like

00:29:39,580 --> 00:29:49,710
if they if he decides to proxy some some

00:29:44,410 --> 00:29:52,390
protocols like let's say our DNS or DHCP

00:29:49,710 --> 00:29:56,680
besides the communication with the

00:29:52,390 --> 00:29:58,750
compute nodes there is also each control

00:29:56,680 --> 00:30:01,390
node communicates with other control

00:29:58,750 --> 00:30:04,990
nodes using BGP protocol and it can

00:30:01,390 --> 00:30:07,960
communicate with regular hardware

00:30:04,990 --> 00:30:10,510
equipment so any switch that understands

00:30:07,960 --> 00:30:13,300
net cover and that kind of or BGP also

00:30:10,510 --> 00:30:15,220
can can communicate with control nodes

00:30:13,300 --> 00:30:18,420
so they can exchange their routing

00:30:15,220 --> 00:30:21,190
informations and cooperate very smoothly

00:30:18,420 --> 00:30:27,280
of course there is a lot of control

00:30:21,190 --> 00:30:29,140
nodes at least two I mean one compute

00:30:27,280 --> 00:30:33,280
nodes connected to at least two four

00:30:29,140 --> 00:30:36,130
residence reasons and they all of those

00:30:33,280 --> 00:30:39,790
control nodes are active so if one goes

00:30:36,130 --> 00:30:43,390
down the other automatically take cares

00:30:39,790 --> 00:30:47,440
of the job that the first one did so so

00:30:43,390 --> 00:30:51,910
we are very fault tolerant with this but

00:30:47,440 --> 00:30:54,250
now we come to the most important note

00:30:51,910 --> 00:30:59,770
which is the compute node and which

00:30:54,250 --> 00:31:03,400
actually requires some work when we try

00:30:59,770 --> 00:31:06,790
to use it on the freebsd platform it is

00:31:03,400 --> 00:31:09,250
this is similar picture I presented when

00:31:06,790 --> 00:31:11,350
I was talking about the open

00:31:09,250 --> 00:31:13,720
compute knowledge it's almost the same

00:31:11,350 --> 00:31:16,240
we have never compute we have libvirt

00:31:13,720 --> 00:31:19,720
and we have beehive and v-n so this is

00:31:16,240 --> 00:31:21,640
this hasn't changed but now we have some

00:31:19,720 --> 00:31:25,420
new components we have another wave

00:31:21,640 --> 00:31:28,030
driver which is which is supposed to

00:31:25,420 --> 00:31:30,160
communicate the state of the VMS which

00:31:28,030 --> 00:31:32,770
is known by de novo compute from the

00:31:30,160 --> 00:31:35,140
OpenStack controller to the contrail

00:31:32,770 --> 00:31:40,810
again because you want to know which

00:31:35,140 --> 00:31:44,170
part should should be or which tab

00:31:40,810 --> 00:31:46,780
device is associated with which VM he

00:31:44,170 --> 00:31:49,870
has to know this in order to connect

00:31:46,780 --> 00:31:51,700
correct VN to the correct virtual

00:31:49,870 --> 00:31:57,100
network and there is a control agent

00:31:51,700 --> 00:32:00,670
which is user space process and it is

00:31:57,100 --> 00:32:04,590
actually sort of part distributed part

00:32:00,670 --> 00:32:09,850
of the control nodes it actually handles

00:32:04,590 --> 00:32:12,010
the proxies of arp and dhcp because this

00:32:09,850 --> 00:32:14,290
kind of protocols are not broadcasted

00:32:12,010 --> 00:32:16,750
over not centered over the IP fabric

00:32:14,290 --> 00:32:22,770
network but are handled inside the

00:32:16,750 --> 00:32:25,960
compute nodes just here and the main

00:32:22,770 --> 00:32:29,170
main task of the country agent is to

00:32:25,960 --> 00:32:32,710
communicate with the viewer which is a

00:32:29,170 --> 00:32:34,660
kernel module and the curvy router

00:32:32,710 --> 00:32:37,330
doesn't have any information any

00:32:34,660 --> 00:32:40,630
intelligence inside it just has a

00:32:37,330 --> 00:32:43,330
forwarding tables flow tables and this

00:32:40,630 --> 00:32:45,370
kind of stuff and it just puts packet

00:32:43,330 --> 00:32:48,370
from one port to another puzzle from one

00:32:45,370 --> 00:32:50,650
VN to another VN does encapsulation and

00:32:48,370 --> 00:32:55,330
this kind of stuff it is controlled by

00:32:50,650 --> 00:32:57,970
the agent and and they communicate with

00:32:55,330 --> 00:33:02,230
java using netbeans i think is a linux

00:32:57,970 --> 00:33:03,790
thing not available in freebsd but

00:33:02,230 --> 00:33:09,040
fortunately the communication between

00:33:03,790 --> 00:33:11,980
agent and the v router was only using

00:33:09,040 --> 00:33:14,260
nothing but wasn't is not using any

00:33:11,980 --> 00:33:17,230
sophisticated features of the netting

00:33:14,260 --> 00:33:19,900
drawers the headers and the transmission

00:33:17,230 --> 00:33:21,299
control so so we are using just the same

00:33:19,900 --> 00:33:24,139
headers and using this

00:33:21,299 --> 00:33:26,909
Quinn's numbers to acknowledge that this

00:33:24,139 --> 00:33:30,029
part of the communication has been

00:33:26,909 --> 00:33:32,610
received by the V router or body by the

00:33:30,029 --> 00:33:38,629
agent and there is something like death

00:33:32,610 --> 00:33:41,549
flow which is just just a memory sharing

00:33:38,629 --> 00:33:43,950
region between the agent and view router

00:33:41,549 --> 00:33:46,950
and it is used for the flow tables

00:33:43,950 --> 00:33:49,710
because from tables are hash tables and

00:33:46,950 --> 00:33:52,110
and both agent and filter once it has a

00:33:49,710 --> 00:33:57,320
quick access to them to quickly find

00:33:52,110 --> 00:34:01,200
which flow should go where so so it is

00:33:57,320 --> 00:34:04,649
those hash tables are shared by the

00:34:01,200 --> 00:34:08,879
agent and by the filter via their flow

00:34:04,649 --> 00:34:11,460
and there is a picot a device which is

00:34:08,879 --> 00:34:15,000
just a taut device and induced when the

00:34:11,460 --> 00:34:18,480
new flow is discovered so if he wants to

00:34:15,000 --> 00:34:21,540
send a packet of a new flow so the first

00:34:18,480 --> 00:34:25,319
packet of each flow is sent to agent and

00:34:21,540 --> 00:34:28,530
then agent said if there is no a proper

00:34:25,319 --> 00:34:32,069
flow already set up in the V router then

00:34:28,530 --> 00:34:36,720
it sends out to send it up to the agent

00:34:32,069 --> 00:34:39,149
and I agent agent sets up correct flows

00:34:36,720 --> 00:34:44,339
and communicates about new flow to the

00:34:39,149 --> 00:34:48,119
controller and etc etc so this is this

00:34:44,339 --> 00:34:52,679
is those elements again here marked in

00:34:48,119 --> 00:34:56,549
the violet color this all has to be or

00:34:52,679 --> 00:35:01,140
written ported or modify it in order to

00:34:56,549 --> 00:35:03,000
make them work in the FreeBSD case what

00:35:01,140 --> 00:35:07,109
we actually support in the FreeBSD is

00:35:03,000 --> 00:35:10,559
only one mode of operation and is the

00:35:07,109 --> 00:35:15,450
tuning via amperes over GRE and I would

00:35:10,559 --> 00:35:17,609
like to show very similar example of

00:35:15,450 --> 00:35:22,500
Weald we have been talking what we

00:35:17,609 --> 00:35:24,720
talked before during when I talk about

00:35:22,500 --> 00:35:27,690
told about the overline networks and

00:35:24,720 --> 00:35:30,900
this is very similar example but it is

00:35:27,690 --> 00:35:32,850
much more concrete because we have all

00:35:30,900 --> 00:35:34,470
these nodes I

00:35:32,850 --> 00:35:36,000
already spoken so we have the

00:35:34,470 --> 00:35:39,030
configuration that control now then

00:35:36,000 --> 00:35:42,900
compute nodes here and how the works

00:35:39,030 --> 00:35:47,670
when we have a VM and VM is bound on the

00:35:42,900 --> 00:35:51,770
server one here on the left then it's

00:35:47,670 --> 00:35:57,590
informs that informs the controller that

00:35:51,770 --> 00:36:01,170
the VM with IP address 10111 should be

00:35:57,590 --> 00:36:04,890
it just sets up the next hope for this

00:36:01,170 --> 00:36:06,810
VN and with the physical address of the

00:36:04,890 --> 00:36:09,660
server that way the controller knows

00:36:06,810 --> 00:36:14,250
that once somebody would like to reach

00:36:09,660 --> 00:36:17,120
this VM of address 10111 it has to send

00:36:14,250 --> 00:36:20,060
packets packets should be sent

00:36:17,120 --> 00:36:25,680
capsulated in the seventy tenth and one

00:36:20,060 --> 00:36:31,320
address and MPLS label number 39 should

00:36:25,680 --> 00:36:33,450
be should be put in the MPLS header the

00:36:31,320 --> 00:36:35,700
same is for the server too but different

00:36:33,450 --> 00:36:40,530
of course different IP addresses

00:36:35,700 --> 00:36:43,680
different levels and then if VM one from

00:36:40,530 --> 00:36:47,310
several one wants to reach VM on the

00:36:43,680 --> 00:36:50,550
server - it looks in his forwarding

00:36:47,310 --> 00:36:55,350
table and he sees that next hope for 10

00:36:50,550 --> 00:36:57,960
1 1 is one five one tenth and one so he

00:36:55,350 --> 00:37:02,700
knows e test encapsulated in the jury

00:36:57,960 --> 00:37:05,160
and impeller stack number 17 and that's

00:37:02,700 --> 00:37:09,080
what we see on the network actually and

00:37:05,160 --> 00:37:13,020
when this packet arrives to the server

00:37:09,080 --> 00:37:15,840
it is d capsulated by the v router this

00:37:13,020 --> 00:37:19,100
Empire is the label identifies the

00:37:15,840 --> 00:37:23,370
virtual network where the VN is

00:37:19,100 --> 00:37:27,060
connected to this is quite a nice thing

00:37:23,370 --> 00:37:29,250
because those labels are local through

00:37:27,060 --> 00:37:31,590
the compute nodes and to the virtual

00:37:29,250 --> 00:37:34,710
networks on this concrete nodes so even

00:37:31,590 --> 00:37:38,610
though there is limit of MPLS notes

00:37:34,710 --> 00:37:40,590
numbers we probably doesn't reach it

00:37:38,610 --> 00:37:42,160
because it is welcome it's not global

00:37:40,590 --> 00:37:48,849
like it was in the

00:37:42,160 --> 00:37:52,960
one case that we have fought 4096 tax

00:37:48,849 --> 00:37:56,859
and we were using they were just used

00:37:52,960 --> 00:38:01,119
globally and those are things that are

00:37:56,859 --> 00:38:04,839
that matter is only locally so so we may

00:38:01,119 --> 00:38:07,780
never reach end of this actually so so

00:38:04,839 --> 00:38:10,630
this also helps with the scalability of

00:38:07,780 --> 00:38:17,470
the system there is also yet another

00:38:10,630 --> 00:38:19,450
note which is which is part of the open

00:38:17,470 --> 00:38:24,000
contrary solution and it is analytics

00:38:19,450 --> 00:38:26,710
note it doesn't take presence in the

00:38:24,000 --> 00:38:30,309
actual transmission of the packets or

00:38:26,710 --> 00:38:34,089
deciding where how it works but it is

00:38:30,309 --> 00:38:36,970
very useful in terms of analytics in

00:38:34,089 --> 00:38:41,319
terms of debugging because each each

00:38:36,970 --> 00:38:43,420
event that occurs in the open country

00:38:41,319 --> 00:38:46,270
system is reported to the analytics now

00:38:43,420 --> 00:38:49,559
they have here some rules in jiying

00:38:46,270 --> 00:38:55,750
which is just very simple MapReduce

00:38:49,559 --> 00:38:59,170
MapReduce pattern that can get any

00:38:55,750 --> 00:39:01,380
information you they they have special

00:38:59,170 --> 00:39:04,720
query language for this and you can just

00:39:01,380 --> 00:39:07,569
extract the information about how many

00:39:04,720 --> 00:39:10,779
packets were transmitted at given time

00:39:07,569 --> 00:39:12,819
in the given virtual network or how many

00:39:10,779 --> 00:39:17,529
reach this given virtual machine how

00:39:12,819 --> 00:39:19,990
many of them were encapsulated with what

00:39:17,529 --> 00:39:22,930
kind of stuff everything what you want

00:39:19,990 --> 00:39:26,079
to do want to know is available via this

00:39:22,930 --> 00:39:29,440
analytics node so it is very very nice

00:39:26,079 --> 00:39:32,559
thing but this analytics node controller

00:39:29,440 --> 00:39:36,430
and compute nodes are as it was in the

00:39:32,559 --> 00:39:41,950
OpenStack case just on user space

00:39:36,430 --> 00:39:44,049
application is not necessarily dependent

00:39:41,950 --> 00:39:46,750
on the underlying platform so from our

00:39:44,049 --> 00:39:49,690
point of view the compute node was was

00:39:46,750 --> 00:39:53,410
the most important one and most

00:39:49,690 --> 00:39:54,970
interesting for us and for the freebsd

00:39:53,410 --> 00:39:58,599
developments we

00:39:54,970 --> 00:40:03,220
just created a new module of Europe

00:39:58,599 --> 00:40:07,569
there are some there are some common

00:40:03,220 --> 00:40:10,240
parts in this like GP car which is which

00:40:07,569 --> 00:40:12,579
takes curve of the encapsulation

00:40:10,240 --> 00:40:15,450
decapsulation is this kind of stuff and

00:40:12,579 --> 00:40:18,910
everything else went to the FreeBSD

00:40:15,450 --> 00:40:21,460
subdirectory when it comes to agent

00:40:18,910 --> 00:40:23,950
development there were some differences

00:40:21,460 --> 00:40:26,560
between IRC TRL's tap device

00:40:23,950 --> 00:40:28,960
manipulations in freebsd and linux so we

00:40:26,560 --> 00:40:31,390
have to do this we have to change the

00:40:28,960 --> 00:40:33,609
short memory the Deaf plow device they

00:40:31,390 --> 00:40:36,640
use on the Linux we just use a regular

00:40:33,609 --> 00:40:40,000
file and mapped between the view router

00:40:36,640 --> 00:40:43,290
and the agent and we have to create a

00:40:40,000 --> 00:40:46,210
listener listener is a module that

00:40:43,290 --> 00:40:48,730
learns about changes of the network

00:40:46,210 --> 00:40:50,560
stays in the host they use nothing for

00:40:48,730 --> 00:40:52,630
this but we don't have nothing so we use

00:40:50,560 --> 00:40:55,329
p.m. root for this and we have to

00:40:52,630 --> 00:40:58,480
implement this from scratch and in order

00:40:55,329 --> 00:41:01,630
to make it sense we have to made a lot

00:40:58,480 --> 00:41:05,619
of refactoring to abstract that the

00:41:01,630 --> 00:41:08,589
differences between names of the fields

00:41:05,619 --> 00:41:09,579
in in structures of network headers or

00:41:08,589 --> 00:41:12,280
something like this there are

00:41:09,579 --> 00:41:14,770
differences between Linux and FreeBSD n

00:41:12,280 --> 00:41:19,270
we have to take care about vision and

00:41:14,770 --> 00:41:23,369
abstract out most of this stuff and what

00:41:19,270 --> 00:41:26,680
has left to be done still we need some

00:41:23,369 --> 00:41:31,480
improvements because current support in

00:41:26,680 --> 00:41:33,819
lipfird is not very not very complete we

00:41:31,480 --> 00:41:36,150
only can spawn a freebsd machines at the

00:41:33,819 --> 00:41:39,910
moment actually we need some OpenStack

00:41:36,150 --> 00:41:43,030
improvements but we are here depending

00:41:39,910 --> 00:41:45,339
on what liberates actually does so so at

00:41:43,030 --> 00:41:49,990
first place we have to put some effort

00:41:45,339 --> 00:41:50,950
in leap years we do not support firewall

00:41:49,990 --> 00:41:55,960
in

00:41:50,950 --> 00:42:00,160
nova because current implementation has

00:41:55,960 --> 00:42:04,329
only 4 IP tables we have PFI PA v and IP

00:42:00,160 --> 00:42:07,210
filter but we haven't done it yet and we

00:42:04,329 --> 00:42:10,800
still if you want to use it you still

00:42:07,210 --> 00:42:13,240
have to use our for gov Nova we need to

00:42:10,800 --> 00:42:16,390
complete all the stuff because OpenStack

00:42:13,240 --> 00:42:17,950
doesn't want to integrate if the support

00:42:16,390 --> 00:42:19,599
is not complete they don't want to

00:42:17,950 --> 00:42:22,900
integrate it into their official

00:42:19,599 --> 00:42:25,570
repositories we also doesn't support

00:42:22,900 --> 00:42:27,910
employees over UDP and VX lands which

00:42:25,570 --> 00:42:30,160
are supported on the Linux platform so

00:42:27,910 --> 00:42:33,400
this is also this also has to be done

00:42:30,160 --> 00:42:35,650
and a lot of work has to be put in the

00:42:33,400 --> 00:42:38,470
automatic provisioning so to devstack

00:42:35,650 --> 00:42:40,900
and Contra install scripts because they

00:42:38,470 --> 00:42:44,680
on the freebsd are still suffering from

00:42:40,900 --> 00:42:47,829
for many from many issues and that's

00:42:44,680 --> 00:42:49,660
actually all I or I have prepared if

00:42:47,829 --> 00:42:53,609
somebody have any questions I'll be

00:42:49,660 --> 00:42:53,609
happy to answer yep

00:42:57,660 --> 00:43:04,680
ah thank you for your talk

00:43:01,380 --> 00:43:06,150
do you have any ETA in mind when you

00:43:04,680 --> 00:43:08,069
think you're going to get this

00:43:06,150 --> 00:43:10,289
production ready and integrated with the

00:43:08,069 --> 00:43:13,799
open side what do you mean by ETA

00:43:10,289 --> 00:43:17,130
estimated time of arrival okay so the

00:43:13,799 --> 00:43:20,490
open contrail is already emerged in

00:43:17,130 --> 00:43:24,119
official repositories so it is you have

00:43:20,490 --> 00:43:26,099
to have Forks of OpenStack components

00:43:24,119 --> 00:43:29,190
because they have not yet been

00:43:26,099 --> 00:43:33,089
integrated but the this is all available

00:43:29,190 --> 00:43:36,779
on the github so you can just take it

00:43:33,089 --> 00:43:40,519
and try it by yourself but unfortunately

00:43:36,779 --> 00:43:42,900
it may not be as easy without some

00:43:40,519 --> 00:43:45,960
fiddling with some things especially

00:43:42,900 --> 00:43:49,380
when it comes to these provisioning

00:43:45,960 --> 00:43:52,319
scripts and devstack but the rest is is

00:43:49,380 --> 00:43:54,569
there an you can you can use it so I

00:43:52,319 --> 00:43:55,920
don't know how many free cycles will be

00:43:54,569 --> 00:43:59,099
had because we are now focusing on

00:43:55,920 --> 00:44:01,230
different development in the open

00:43:59,099 --> 00:44:05,029
contrary not this one related to the

00:44:01,230 --> 00:44:08,940
FreeBSD port it was just one task but

00:44:05,029 --> 00:44:11,700
but we will try to to complete and

00:44:08,940 --> 00:44:13,559
somehow get this stuff matched to

00:44:11,700 --> 00:44:18,359
upstream and have it supported

00:44:13,559 --> 00:44:21,930
everywhere so you know there's already

00:44:18,359 --> 00:44:23,099
work being done to get VX LAN on freebsd

00:44:21,930 --> 00:44:25,980
so there's someone actually currently

00:44:23,099 --> 00:44:26,849
working on that No okay so I'll connect

00:44:25,980 --> 00:44:28,950
you with them later and the other

00:44:26,849 --> 00:44:31,470
question I had is in the earlier network

00:44:28,950 --> 00:44:33,480
example where you said that you so you

00:44:31,470 --> 00:44:35,250
create all these MPLS tunnels or GRE

00:44:33,480 --> 00:44:38,299
tunnels or whatever you're doing which

00:44:35,250 --> 00:44:40,920
is incredibly wasteful of bandwidth so

00:44:38,299 --> 00:44:44,789
why don't you simply use a gratuitous

00:44:40,920 --> 00:44:46,769
ARP to update the switch sorry we would

00:44:44,789 --> 00:44:48,599
you because if you move a virtual

00:44:46,769 --> 00:44:49,859
machine yeah you know you've moved a

00:44:48,599 --> 00:44:51,779
virtual machine and you've taken an

00:44:49,859 --> 00:44:54,029
action on your own part so you could

00:44:51,779 --> 00:44:55,680
actually poison your old ARP entry to

00:44:54,029 --> 00:44:57,750
the switch by doing a gratuitous ARP you

00:44:55,680 --> 00:45:01,559
could tell the switch instead of

00:44:57,750 --> 00:45:03,360
creating a million tunnels I don't I

00:45:01,559 --> 00:45:18,540
don't

00:45:03,360 --> 00:45:21,290
people start doing this because it's

00:45:18,540 --> 00:45:21,290
very hard to change

00:45:23,960 --> 00:45:29,390
if you four kids and start changing it

00:45:26,820 --> 00:45:29,390
probably too

00:45:40,070 --> 00:45:46,870
okay so thank you very much

00:45:42,910 --> 00:45:46,870

YouTube URL: https://www.youtube.com/watch?v=T4laPGU0ruA


