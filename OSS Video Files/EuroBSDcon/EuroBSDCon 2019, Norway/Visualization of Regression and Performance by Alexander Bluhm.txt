Title: Visualization of Regression and Performance by Alexander Bluhm
Publication date: 2019-10-21
Playlist: EuroBSDCon 2019, Norway
Description: 
	Visualization of Regression and Performance

Know when something went wrong

When you try a new software version, something may be wrong or slow. After updating OpenBSD you might see that something does not work as it used to be. To simplify debugging it is helpful to determine the point in time when the change was introduced and search for the relevant commit.

Making statements about performance is more difficult than for functional regressions. The requirements for measurements may change, new test programs are needed, test hardware is only available for a limited time. So it is not sufficient to store historic data on a daily basis. You want to change granularity or look back into the past.

For that purpose I have created a system that can create a performance history of the OpenBSD kernel. The kernel is compiled from certain CVS checkouts. That may sound easier than it is as the OpenBSD kernel is not self contained. It belongs to a base system, there may be incompatibilities with userland. The performance also depends on the compiler version that changes over an OpenBSD development cycle. My framework addresses this in an automated way.

An overview of all tests results is here: http://bluhm.genua.de/perform/results/perform.html

This is a follow up to my talk at BSDCan 2019. I will add new findings and conclusions which were detected during the last months.

More Info:
https://2019.eurobsdcon.org/talk-speakers/#performance
Captions: 
	00:00:03,580 --> 00:00:07,960
are we going to start good afternoon

00:00:06,760 --> 00:00:10,059
everyone

00:00:07,960 --> 00:00:13,300
the Europeans the confrontation is

00:00:10,059 --> 00:00:17,019
thrilled to have mr. Alexander bloom

00:00:13,300 --> 00:00:19,449
today talking about performance

00:00:17,019 --> 00:00:20,499
measurement on OpenBSD so performance

00:00:19,449 --> 00:00:23,259
and OpenBSD

00:00:20,499 --> 00:00:24,999
you know can mix in the same sentence

00:00:23,259 --> 00:00:25,570
which is good thank you very much for

00:00:24,999 --> 00:00:28,150
being here

00:00:25,570 --> 00:00:30,869
Alexander and leave it leave it up to

00:00:28,150 --> 00:00:30,869
you Thanks

00:00:33,300 --> 00:00:41,559
thank you so I'll start with motivation

00:00:37,629 --> 00:00:44,920
I work for a company quinoa and we build

00:00:41,559 --> 00:00:47,440
firewalls based on open BSD and we want

00:00:44,920 --> 00:00:49,570
to know how fast they are especially we

00:00:47,440 --> 00:00:51,129
have several requirements we have

00:00:49,570 --> 00:00:52,449
customers who are asking for numbers we

00:00:51,129 --> 00:00:54,399
have Hardware guys who have to choose

00:00:52,449 --> 00:00:56,890
the next hardware we have developers who

00:00:54,399 --> 00:00:58,359
want to see regressions and we have

00:00:56,890 --> 00:01:01,329
marketing who wants to publish numbers

00:00:58,359 --> 00:01:04,690
so we started to to build

00:01:01,329 --> 00:01:07,150
high-performance firewall testbed and

00:01:04,690 --> 00:01:09,910
which can reproduce some some graphs and

00:01:07,150 --> 00:01:12,700
I think what you can see here is that

00:01:09,910 --> 00:01:14,410
you can't see much problem is it's not

00:01:12,700 --> 00:01:16,660
written there what is measured it's

00:01:14,410 --> 00:01:21,610
going up and down you don't have reason

00:01:16,660 --> 00:01:24,370
why that happens so I was feeling that

00:01:21,610 --> 00:01:26,410
we need something better before we were

00:01:24,370 --> 00:01:28,330
just wondering we upgraded open BSD

00:01:26,410 --> 00:01:30,930
version then we got some other jumpin

00:01:28,330 --> 00:01:33,640
numbers here and I want you to make more

00:01:30,930 --> 00:01:35,560
detailed analysis

00:01:33,640 --> 00:01:38,260
what's going on with open BSD

00:01:35,560 --> 00:01:40,300
performance so the reason why this graph

00:01:38,260 --> 00:01:42,910
looked that bad is because we have a

00:01:40,300 --> 00:01:44,080
very complex setup it's four there were

00:01:42,910 --> 00:01:45,700
a lot of requirements too many

00:01:44,080 --> 00:01:49,690
requirements so we have multi users

00:01:45,700 --> 00:01:51,280
using those targets in parallel we have

00:01:49,690 --> 00:01:53,830
some some machines that generate

00:01:51,280 --> 00:01:55,330
generate traffic those are here so we

00:01:53,830 --> 00:01:57,940
have some machine scanner writing

00:01:55,330 --> 00:02:02,230
traffic it's quite old so those only

00:01:57,940 --> 00:02:04,350
capable woops sorry got the wrong press

00:02:02,230 --> 00:02:07,000
the wrong button sorry sorry sorry yeah

00:02:04,350 --> 00:02:09,519
okay so we have some machines they are

00:02:07,000 --> 00:02:11,440
quite quite old because it's they

00:02:09,519 --> 00:02:13,750
produce one gigabit of traffic we

00:02:11,440 --> 00:02:16,650
accumulate that to ten gigabit send them

00:02:13,750 --> 00:02:21,140
through a target collected here again

00:02:16,650 --> 00:02:25,019
do it several drain machines and see how

00:02:21,140 --> 00:02:27,290
and measure the throughput and by doing

00:02:25,019 --> 00:02:29,610
this in the switch we have a lot of

00:02:27,290 --> 00:02:31,560
disturbances there and and you don't get

00:02:29,610 --> 00:02:34,799
reliable results you have other people

00:02:31,560 --> 00:02:37,739
using this and that is the reason for

00:02:34,799 --> 00:02:41,040
the for the numbers jumping up and down

00:02:37,739 --> 00:02:42,959
so what I want to have is it designed

00:02:41,040 --> 00:02:47,310
like this because I have to reduce

00:02:42,959 --> 00:02:48,810
complexity to get reliable numbers so

00:02:47,310 --> 00:02:51,840
the other thing I have done before is

00:02:48,810 --> 00:02:55,859
doing regression tests so and there I

00:02:51,840 --> 00:02:59,489
was focusing on - - visualizing what

00:02:55,859 --> 00:03:02,129
happens so we run those tests every day

00:02:59,489 --> 00:03:05,760
so that's a day of testing I run them on

00:03:02,129 --> 00:03:07,290
several architectures and you have a lot

00:03:05,760 --> 00:03:10,409
of links and this is this is published

00:03:07,290 --> 00:03:11,670
on web and my webpage is public and you

00:03:10,409 --> 00:03:13,859
have a lot of links so if you click on

00:03:11,670 --> 00:03:15,959
this fail you see the test output and

00:03:13,859 --> 00:03:18,120
can figure out what's going on if you

00:03:15,959 --> 00:03:21,090
click on here you see the the DMS of the

00:03:18,120 --> 00:03:23,579
snapshot that is installed and here you

00:03:21,090 --> 00:03:25,349
can get every result on that day you can

00:03:23,579 --> 00:03:27,599
figure out which version was installed

00:03:25,349 --> 00:03:29,579
when was it measured the first line is

00:03:27,599 --> 00:03:31,709
the is the date whether the measurement

00:03:29,579 --> 00:03:34,290
was running and when you click on here

00:03:31,709 --> 00:03:36,540
you get to the OpenBSD CVS web

00:03:34,290 --> 00:03:38,910
repository and see what has been changed

00:03:36,540 --> 00:03:41,010
in this regression test what was it

00:03:38,910 --> 00:03:44,239
somewhere what was it related to the

00:03:41,010 --> 00:03:47,280
change in the test and when you sort it

00:03:44,239 --> 00:03:50,099
so now we look at only the results for

00:03:47,280 --> 00:03:53,010
i386 so it's much clearer impression

00:03:50,099 --> 00:03:56,220
what you have so it's it's sorted by the

00:03:53,010 --> 00:03:57,870
failing test to the top and so you see

00:03:56,220 --> 00:04:00,480
the things you should care about and

00:03:57,870 --> 00:04:03,449
it's sorted in history so you can figure

00:04:00,480 --> 00:04:05,569
out oh here between the 13th and the

00:04:03,449 --> 00:04:07,829
15th something happened in this test

00:04:05,569 --> 00:04:10,319
continued breaking so you know where you

00:04:07,829 --> 00:04:13,079
have to search so you we have history

00:04:10,319 --> 00:04:14,790
and we have severity and for regression

00:04:13,079 --> 00:04:16,859
testing that's quite easy and quite

00:04:14,790 --> 00:04:20,940
common and I wanted to have the same

00:04:16,859 --> 00:04:24,510
thing for performance testing so what I

00:04:20,940 --> 00:04:26,909
had what did i do there so here my goal

00:04:24,510 --> 00:04:28,979
so for the for the system I built based

00:04:26,909 --> 00:04:30,780
on the two things I've presented before

00:04:28,979 --> 00:04:33,780
I want to see the history

00:04:30,780 --> 00:04:37,620
I want to have reproducible numbers so

00:04:33,780 --> 00:04:39,330
so that you can rely on them you want to

00:04:37,620 --> 00:04:40,890
have to click on something and see what

00:04:39,330 --> 00:04:42,870
are the date details what has been

00:04:40,890 --> 00:04:46,470
tested when has been tested what are the

00:04:42,870 --> 00:04:48,360
the the lock outputs you want to see it

00:04:46,470 --> 00:04:49,950
you want you have drill down so here we

00:04:48,360 --> 00:04:51,930
have a lot of commits in the tree and

00:04:49,950 --> 00:04:54,360
you know don't know which one is really

00:04:51,930 --> 00:04:55,890
the the relevant one for the change in

00:04:54,360 --> 00:04:58,020
the performance so you want to say okay

00:04:55,890 --> 00:05:00,270
was it here or was it there and drill

00:04:58,020 --> 00:05:03,660
down to this thing and you want to do

00:05:00,270 --> 00:05:05,490
some automatic testing those regression

00:05:03,660 --> 00:05:07,410
tests are run every night so you can

00:05:05,490 --> 00:05:10,290
come up wake up in the morning and see

00:05:07,410 --> 00:05:11,760
okay what what did break this day and I

00:05:10,290 --> 00:05:14,760
want something similar for the

00:05:11,760 --> 00:05:17,010
performance test and there I created a

00:05:14,760 --> 00:05:22,320
cron job that collects the data of the

00:05:17,010 --> 00:05:25,500
last week every week so the the the

00:05:22,320 --> 00:05:28,530
principle idea of the design is that you

00:05:25,500 --> 00:05:30,780
start and install an open BSD release we

00:05:28,530 --> 00:05:33,230
release every half a year and that's the

00:05:30,780 --> 00:05:35,930
the base where where we start from and

00:05:33,230 --> 00:05:39,270
then I say okay let's whoops wrong

00:05:35,930 --> 00:05:42,480
button again here so here we check out

00:05:39,270 --> 00:05:44,600
at a certain date we have a CVS system

00:05:42,480 --> 00:05:47,250
and you can say check out this date

00:05:44,600 --> 00:05:49,590
basically I want to measure the

00:05:47,250 --> 00:05:51,240
performance of the kernel I could do a

00:05:49,590 --> 00:05:53,940
full build of the whole system but that

00:05:51,240 --> 00:05:56,010
takes hours one and a half hour for

00:05:53,940 --> 00:05:59,520
example but compiling the kernel only

00:05:56,010 --> 00:06:01,380
takes two minutes so I just wanted to

00:05:59,520 --> 00:06:04,979
test the kernel I compile the kernel

00:06:01,380 --> 00:06:07,380
I run the tests then I advance by the

00:06:04,979 --> 00:06:09,900
step the step is configurable to to

00:06:07,380 --> 00:06:12,360
allow this drill down feature check out

00:06:09,900 --> 00:06:15,479
the next date compile the kernel run the

00:06:12,360 --> 00:06:16,919
test until the whole series is done then

00:06:15,479 --> 00:06:22,919
I collect the results and draw those

00:06:16,919 --> 00:06:26,880
nice graphs so the first thing you get

00:06:22,919 --> 00:06:29,000
is a web page we can say okay

00:06:26,880 --> 00:06:33,810
somebody did a measurement at this date

00:06:29,000 --> 00:06:36,630
he installed version six four and then

00:06:33,810 --> 00:06:39,750
he checked out from this state to this

00:06:36,630 --> 00:06:42,539
state and the step was one day so every

00:06:39,750 --> 00:06:44,460
day is measured so that's one of those

00:06:42,539 --> 00:06:47,669
columns one column is

00:06:44,460 --> 00:06:49,550
one test run and it's running in one day

00:06:47,669 --> 00:06:52,050
steps between this date and that date

00:06:49,550 --> 00:06:53,880
when currently a test is running you can

00:06:52,050 --> 00:06:55,919
click here and you see okay this machine

00:06:53,880 --> 00:06:57,630
is doing there and it's it's going there

00:06:55,919 --> 00:07:01,289
and if the kernel panics in between you

00:06:57,630 --> 00:07:03,750
can see everything there here we have

00:07:01,289 --> 00:07:06,539
some some details shown and here we have

00:07:03,750 --> 00:07:09,870
exactly the tests that we run so here I

00:07:06,539 --> 00:07:11,849
run a TCP bench with some parameters so

00:07:09,870 --> 00:07:13,680
you know what what's running when you go

00:07:11,849 --> 00:07:15,840
drill down when you click on some some

00:07:13,680 --> 00:07:19,590
things here you get even the the hole

00:07:15,840 --> 00:07:22,110
lock output of the command so now we

00:07:19,590 --> 00:07:24,720
could be click on here and get one of

00:07:22,110 --> 00:07:30,389
those columns so what happens in one

00:07:24,720 --> 00:07:32,190
test in one test we we have here to

00:07:30,389 --> 00:07:33,930
check out that we check out here here

00:07:32,190 --> 00:07:39,570
here we I said before that are one-day

00:07:33,930 --> 00:07:41,370
steps and no it's a weak step he is

00:07:39,570 --> 00:07:46,289
written one week so that's a week and a

00:07:41,370 --> 00:07:48,150
week and week and we run those tests so

00:07:46,289 --> 00:07:50,550
to figure out whether the numbers are

00:07:48,150 --> 00:07:52,590
reliable or not I have to run them

00:07:50,550 --> 00:07:55,409
multiple times so he in this case I run

00:07:52,590 --> 00:08:01,680
them five times and here you see the the

00:07:55,409 --> 00:08:03,900
maximum throughput so what what I do

00:08:01,680 --> 00:08:06,060
here so here you see the average numbers

00:08:03,900 --> 00:08:10,949
of the five measurements you have in

00:08:06,060 --> 00:08:13,139
this for this measurement and here again

00:08:10,949 --> 00:08:15,449
you see some some blocks and can figure

00:08:13,139 --> 00:08:18,000
out what happens here you see the number

00:08:15,449 --> 00:08:20,280
of kernel commits between this

00:08:18,000 --> 00:08:23,639
measurement and this measurement so you

00:08:20,280 --> 00:08:25,919
can even click on the CVS lock that you

00:08:23,639 --> 00:08:27,479
see all the commits collected so you can

00:08:25,919 --> 00:08:32,250
say ok what happened between here and

00:08:27,479 --> 00:08:32,849
here and also I have to to do some build

00:08:32,250 --> 00:08:36,829
quarks

00:08:32,849 --> 00:08:40,079
I'll explain later what that means so

00:08:36,829 --> 00:08:43,770
here we have the average number of all

00:08:40,079 --> 00:08:46,160
the tests and as I said before they are

00:08:43,770 --> 00:08:49,529
jumping up and down and I made them read

00:08:46,160 --> 00:08:51,720
when those numbers are not consistent so

00:08:49,529 --> 00:08:54,959
if they change lock between in each test

00:08:51,720 --> 00:08:57,209
round I am mark it here and what I've

00:08:54,959 --> 00:08:58,060
also find is that I have very unstable

00:08:57,209 --> 00:09:01,500
results

00:08:58,060 --> 00:09:06,640
in this column everything is it's bad

00:09:01,500 --> 00:09:09,100
for some reason so I can click on the on

00:09:06,640 --> 00:09:12,130
the next and so I click the one back

00:09:09,100 --> 00:09:13,810
when I click here it goes to next one

00:09:12,130 --> 00:09:16,540
and I see everything that happens in

00:09:13,810 --> 00:09:20,890
those five measurements one two three

00:09:16,540 --> 00:09:23,500
four five and what is he here that we

00:09:20,890 --> 00:09:26,620
have an outlier so this measurement for

00:09:23,500 --> 00:09:29,890
some reason went pretty wrong so here we

00:09:26,620 --> 00:09:34,120
have 3.9 gigabit for seconds for at 0

00:09:29,890 --> 00:09:36,400
3.8 and here we have only 1.6 actually I

00:09:34,120 --> 00:09:40,540
don't know what happened here you see it

00:09:36,400 --> 00:09:45,340
in the next graph as a as a picture here

00:09:40,540 --> 00:09:47,500
something really went bad so we we see

00:09:45,340 --> 00:09:49,840
that this is an outlier and mark it red

00:09:47,500 --> 00:09:51,400
and it's shown as red in the in the

00:09:49,840 --> 00:09:52,230
upper graph so it's see okay here we

00:09:51,400 --> 00:09:55,360
have a problem

00:09:52,230 --> 00:10:01,660
so one thing in this graph is indeed

00:09:55,360 --> 00:10:04,210
every single result yes so here then

00:10:01,660 --> 00:10:06,580
from the most numbers I generate new

00:10:04,210 --> 00:10:07,450
flawed graphs like this that's the thing

00:10:06,580 --> 00:10:11,370
you have seen before

00:10:07,450 --> 00:10:15,550
we are running a whole recently release

00:10:11,370 --> 00:10:18,580
that's 6 2 2 6 3 and we do it per week

00:10:15,550 --> 00:10:20,950
and we run five measurements each and

00:10:18,580 --> 00:10:25,060
the outlier you just saw in in the in

00:10:20,950 --> 00:10:28,930
the table is this one so on some

00:10:25,060 --> 00:10:31,300
measurements we have only 1.6 gigabit so

00:10:28,930 --> 00:10:32,860
what I see it only happens on the two

00:10:31,300 --> 00:10:37,260
socket machine we have here this machine

00:10:32,860 --> 00:10:39,670
has two sockets with four cores each and

00:10:37,260 --> 00:10:42,940
with this hardware configuration it's

00:10:39,670 --> 00:10:46,210
it's very unlike it these outliers they

00:10:42,940 --> 00:10:48,100
have not figured out why they happen you

00:10:46,210 --> 00:10:51,670
know there's also one thing that I want

00:10:48,100 --> 00:10:55,240
to show you here we have a an outlier

00:10:51,670 --> 00:10:59,110
that is faster so all measurements and

00:10:55,240 --> 00:11:01,300
this day were faster and what I will

00:10:59,110 --> 00:11:04,950
develop later is how we can try to

00:11:01,300 --> 00:11:04,950
figure out what this is

00:11:05,010 --> 00:11:10,870
okay now let's explain those quirks

00:11:07,780 --> 00:11:12,409
you see those vertical lines here with

00:11:10,870 --> 00:11:15,449
those letters on top of it

00:11:12,409 --> 00:11:17,309
the thing is that the OpenBSD kernel is

00:11:15,449 --> 00:11:22,499
not self-contained

00:11:17,309 --> 00:11:24,479
you cannot compile it just on a random

00:11:22,499 --> 00:11:27,569
system you have to compile the OpenBSD

00:11:24,479 --> 00:11:30,199
kernel with with the source with a base

00:11:27,569 --> 00:11:34,799
system that matches to the two it's

00:11:30,199 --> 00:11:37,439
checkout date so when we change

00:11:34,799 --> 00:11:40,349
compilers then we have to adapt the

00:11:37,439 --> 00:11:44,429
kernel sources to make it compile again

00:11:40,349 --> 00:11:44,909
and so we have to make sure that we can

00:11:44,429 --> 00:11:46,829
build it

00:11:44,909 --> 00:11:50,279
and on the other hand when I want to

00:11:46,829 --> 00:11:51,899
speak about open BSD come performance if

00:11:50,279 --> 00:11:53,789
I have a change in the tool chain for

00:11:51,899 --> 00:11:56,039
example if you change the compiler then

00:11:53,789 --> 00:12:01,109
I also want to see the effects of that

00:11:56,039 --> 00:12:02,849
and in this case I recompile parts of

00:12:01,109 --> 00:12:04,229
the build system I don't don't do it all

00:12:02,849 --> 00:12:06,449
the time because it would be much too

00:12:04,229 --> 00:12:08,069
slow but here I can say okay we got a

00:12:06,449 --> 00:12:10,619
new compiler I have to compile it and

00:12:08,069 --> 00:12:13,139
then I raw draw some vertical line in

00:12:10,619 --> 00:12:15,499
here there are also some other places we

00:12:13,139 --> 00:12:20,429
have to do that when the system gets

00:12:15,499 --> 00:12:22,079
incompatible so here in compatible

00:12:20,429 --> 00:12:24,899
between kernel and user land if that's

00:12:22,079 --> 00:12:27,569
if the system interface changes and

00:12:24,899 --> 00:12:31,289
here's all the things I figured out

00:12:27,569 --> 00:12:35,879
manually what to do to compile and open

00:12:31,289 --> 00:12:37,799
B is the kernel just before 6 3 when you

00:12:35,879 --> 00:12:39,779
have installed 6 2 then you have to

00:12:37,799 --> 00:12:41,999
adapt the both the bill chain and the

00:12:39,779 --> 00:12:44,089
user land in that way so the first thing

00:12:41,999 --> 00:12:46,619
I figured out I have to do is to fix CVS

00:12:44,089 --> 00:12:48,599
because I cannot check out the compiler

00:12:46,619 --> 00:12:50,849
because there was a barking in CVS and

00:12:48,599 --> 00:12:52,649
they picked some wrong files so the

00:12:50,849 --> 00:12:56,189
first thing I patch my spilled system to

00:12:52,649 --> 00:12:59,069
fix CVS and then I can next step is we

00:12:56,189 --> 00:13:01,529
had a compiler update to 5.0 and we can

00:12:59,069 --> 00:13:06,839
fetch the right compiler I recompile the

00:13:01,529 --> 00:13:09,569
compiler here then there is PF + PF CTL

00:13:06,839 --> 00:13:11,879
that's PFC tlz userland program and they

00:13:09,569 --> 00:13:15,720
have a common header file that's PFR and

00:13:11,879 --> 00:13:18,989
sometimes in PFR the system interface

00:13:15,720 --> 00:13:21,029
changes and then the old PF CTL cannot

00:13:18,989 --> 00:13:22,109
load the rules into the kernel and then

00:13:21,029 --> 00:13:23,970
we have no rules and then the

00:13:22,109 --> 00:13:25,440
performance changes so what I did is

00:13:23,970 --> 00:13:28,740
just tell him ok

00:13:25,440 --> 00:13:31,230
recompile PFC TL here's somebody next

00:13:28,740 --> 00:13:33,180
one the e somebody made a mistake when

00:13:31,230 --> 00:13:34,890
he committed the colonel he forgot the

00:13:33,180 --> 00:13:35,400
file and the colonel didn't compile

00:13:34,890 --> 00:13:37,800
anymore

00:13:35,400 --> 00:13:40,380
normally such things are fixed within

00:13:37,800 --> 00:13:42,660
hours in the OpenBSD tree but when I do

00:13:40,380 --> 00:13:44,190
the CVS check out exactly at the moment

00:13:42,660 --> 00:13:46,800
where it was broken the colonel doesn't

00:13:44,190 --> 00:13:52,590
compile then adjust to apply patch and

00:13:46,800 --> 00:13:54,540
fix it so here again the PFC TL header

00:13:52,590 --> 00:14:00,120
files changed so I have to recompile the

00:13:54,540 --> 00:14:02,790
userland here same from CTL then si Lang

00:14:00,120 --> 00:14:08,610
was updated again PFC TL was changed and

00:14:02,790 --> 00:14:10,590
then we are at OpenBSD 6-3 so the graph

00:14:08,610 --> 00:14:12,300
from before changed a little bit by by

00:14:10,590 --> 00:14:14,310
these quirks we do the colonel check out

00:14:12,300 --> 00:14:16,740
wery compile the kernel we run the tests

00:14:14,310 --> 00:14:19,410
we want to advance and now we check is

00:14:16,740 --> 00:14:22,530
there some incompatibility change in

00:14:19,410 --> 00:14:25,050
userland I have a list of this and

00:14:22,530 --> 00:14:26,880
between the last state and the next

00:14:25,050 --> 00:14:28,620
state if there's a change we check out

00:14:26,880 --> 00:14:31,350
the user line to build our tool chain

00:14:28,620 --> 00:14:32,910
and go to check out the colonel and then

00:14:31,350 --> 00:14:34,950
we can either go the short way to be

00:14:32,910 --> 00:14:41,040
fast or the long way when it's necessary

00:14:34,950 --> 00:14:44,340
so that's my hardware setup that I

00:14:41,040 --> 00:14:47,550
actually have so I have two machines one

00:14:44,340 --> 00:14:49,980
is a tool socket machine we have this

00:14:47,550 --> 00:14:54,270
unreliable results then we set up the

00:14:49,980 --> 00:14:56,940
same setup and just removed one of the

00:14:54,270 --> 00:14:58,620
one of the CPUs and this machine is much

00:14:56,940 --> 00:15:02,220
more suitable for performance testing

00:14:58,620 --> 00:15:04,650
you have less jumping around and what

00:15:02,220 --> 00:15:07,200
I'm my food future plans is to have some

00:15:04,650 --> 00:15:08,940
Linux machine here to get some

00:15:07,200 --> 00:15:11,180
performance here but I have not

00:15:08,940 --> 00:15:14,790
implemented that yet it's just the plan

00:15:11,180 --> 00:15:17,820
but the machine is already there so how

00:15:14,790 --> 00:15:20,400
is the hardware controlled to do things

00:15:17,820 --> 00:15:23,370
so I have a master machine that's this

00:15:20,400 --> 00:15:26,130
one here all the scripts are started and

00:15:23,370 --> 00:15:28,650
run so and here is also running a web

00:15:26,130 --> 00:15:31,010
server where publish my results I have a

00:15:28,650 --> 00:15:35,250
console server all those machines the

00:15:31,010 --> 00:15:38,410
both target machines are attached to a

00:15:35,250 --> 00:15:41,350
serial console and I have some

00:15:38,410 --> 00:15:43,720
reboots install scripts and automatic

00:15:41,350 --> 00:15:46,810
reboot I use the auto installer from

00:15:43,720 --> 00:15:50,320
OpenBSD to to install those machines

00:15:46,810 --> 00:15:53,950
with a release software so you say okay

00:15:50,320 --> 00:15:58,200
install this v6 3 and then the the

00:15:53,950 --> 00:16:01,270
master locks in into these machines and

00:15:58,200 --> 00:16:04,120
compile the kernel compile the kernel

00:16:01,270 --> 00:16:06,550
runs the test it strikes the results and

00:16:04,120 --> 00:16:11,230
compiled checks out compiles and runs

00:16:06,550 --> 00:16:12,970
and then here we generate new

00:16:11,230 --> 00:16:24,640
measurements and we rebuild all the

00:16:12,970 --> 00:16:29,530
machines that over the time ok whatever

00:16:24,640 --> 00:16:31,690
found out so that's the graph from

00:16:29,530 --> 00:16:34,750
before and now we switched from weeks to

00:16:31,690 --> 00:16:36,100
days before I had one outlier here on

00:16:34,750 --> 00:16:40,060
the top I have called you to remember

00:16:36,100 --> 00:16:44,860
now I have two of them because I am here

00:16:40,060 --> 00:16:46,900
here is days they step in between and

00:16:44,860 --> 00:16:48,460
now I can find which are the commits

00:16:46,900 --> 00:16:51,700
here and which I have commits here and

00:16:48,460 --> 00:16:55,000
what happened there and here it was the

00:16:51,700 --> 00:16:56,860
case that dlg committed some TX

00:16:55,000 --> 00:16:58,620
mitigations that means that when you

00:16:56,860 --> 00:17:01,000
have network packets that should go out

00:16:58,620 --> 00:17:03,100
you don't throw every packet to the

00:17:01,000 --> 00:17:04,780
network card and say do something do

00:17:03,100 --> 00:17:06,939
something do something but you collect

00:17:04,780 --> 00:17:09,280
them and then just throw a bunch of

00:17:06,939 --> 00:17:12,730
packets to the network cards and that

00:17:09,280 --> 00:17:13,420
makes it faster that was here two days

00:17:12,730 --> 00:17:15,459
afterwards

00:17:13,420 --> 00:17:17,890
Claudio another OpenBSD developer

00:17:15,459 --> 00:17:21,790
complaint in ic B that is suspend on

00:17:17,890 --> 00:17:24,939
laptop failed and the laptop crashed and

00:17:21,790 --> 00:17:26,770
then it was packed out again so we

00:17:24,939 --> 00:17:34,000
dropped performance again but Claudius

00:17:26,770 --> 00:17:37,390
left over stable again so back to those

00:17:34,000 --> 00:17:39,160
outliers these here I wanted to figure

00:17:37,390 --> 00:17:41,050
out why it's jumping so much we have

00:17:39,160 --> 00:17:42,820
those outliers and also here we have

00:17:41,050 --> 00:17:47,050
several measurements and and they are

00:17:42,820 --> 00:17:49,030
not one dot so we have several things

00:17:47,050 --> 00:17:51,820
that runs on TCP bench that runs on

00:17:49,030 --> 00:17:55,440
iperf but also the I pervs on the same

00:17:51,820 --> 00:17:57,700
the same setup is moving so I thought is

00:17:55,440 --> 00:18:01,570
there some difference what I can do I

00:17:57,700 --> 00:18:04,690
told you already that I run five tests

00:18:01,570 --> 00:18:07,900
in a row can also run ten tests in a row

00:18:04,690 --> 00:18:10,120
it's just a new parameter and what I can

00:18:07,900 --> 00:18:11,650
do is run the test multiple times I

00:18:10,120 --> 00:18:14,040
compile the kernel around the tests and

00:18:11,650 --> 00:18:17,920
then it can either just run them again I

00:18:14,040 --> 00:18:18,340
can reboot the machine and run them

00:18:17,920 --> 00:18:20,920
again

00:18:18,340 --> 00:18:25,750
or I can relink the kernel in open BSD

00:18:20,920 --> 00:18:28,840
we relink the kernel at every reboot to

00:18:25,750 --> 00:18:31,840
to make a random kernel image to make it

00:18:28,840 --> 00:18:34,450
harder to to do attacks on the OpenBSD

00:18:31,840 --> 00:18:37,600
kernel it's an end address space

00:18:34,450 --> 00:18:39,460
randomization and it's done

00:18:37,600 --> 00:18:41,980
automatically at every reboot in open

00:18:39,460 --> 00:18:44,980
BSD and before starting that I just

00:18:41,980 --> 00:18:46,780
disabled it because when I reboot and it

00:18:44,980 --> 00:18:49,420
starts real inking it affects my

00:18:46,780 --> 00:18:51,190
measurements so what I did first was

00:18:49,420 --> 00:18:53,320
this here just run it again without real

00:18:51,190 --> 00:18:55,720
inking anything then I started okay

00:18:53,320 --> 00:18:57,550
let's reboot it see if something changes

00:18:55,720 --> 00:18:59,890
and then said okay let's turn on real

00:18:57,550 --> 00:19:04,000
inking the kernel again and see what

00:18:59,890 --> 00:19:06,280
happens then so in that what are the the

00:19:04,000 --> 00:19:10,150
findings with those options what you can

00:19:06,280 --> 00:19:13,990
do in this image in this kind slide I

00:19:10,150 --> 00:19:15,670
keep the machine running and I took one

00:19:13,990 --> 00:19:17,560
day so that's the the first of all

00:19:15,670 --> 00:19:23,820
orders and that's the second of August

00:19:17,560 --> 00:19:29,490
and split it in six parts so we have

00:19:23,820 --> 00:19:33,630
four hours between each of those and

00:19:29,490 --> 00:19:39,130
what I've inserted here are the commits

00:19:33,630 --> 00:19:41,230
so this one is dlg committed sudo driver

00:19:39,130 --> 00:19:43,300
that isn't used yet it's something like

00:19:41,230 --> 00:19:44,620
trunk and I don't use it and it's just

00:19:43,300 --> 00:19:48,940
there it's just compiled in the kernel

00:19:44,620 --> 00:19:51,730
here I visa committed something for the

00:19:48,940 --> 00:19:54,190
octane platform but I'm using amd64 so

00:19:51,730 --> 00:19:56,500
it's not relevant and here I fixed some

00:19:54,190 --> 00:19:59,110
unveil back in the file system it's also

00:19:56,500 --> 00:20:00,850
not relevant and now we look at the

00:19:59,110 --> 00:20:02,800
numbers here we have three gigabit and

00:20:00,850 --> 00:20:04,600
here we have 3.5 gigabytes and now we

00:20:02,800 --> 00:20:05,190
are here and here from drive on the

00:20:04,600 --> 00:20:08,760
kernel that we

00:20:05,190 --> 00:20:12,750
Jews he will commit to the platform we

00:20:08,760 --> 00:20:15,480
don't we don't have here nothing

00:20:12,750 --> 00:20:16,550
happened no commit no commit back fix

00:20:15,480 --> 00:20:20,720
somewhere else

00:20:16,550 --> 00:20:23,880
no commit so why is it going up and down

00:20:20,720 --> 00:20:27,090
so what I tried next i rebooted between

00:20:23,880 --> 00:20:30,360
each of those dots so here we have those

00:20:27,090 --> 00:20:32,760
measurements that are happening with the

00:20:30,360 --> 00:20:34,620
same kernel and I rebooted between each

00:20:32,760 --> 00:20:36,120
of those dots here I have to reboot

00:20:34,620 --> 00:20:39,690
anyway because I recompile the kernel

00:20:36,120 --> 00:20:41,520
but now every boot here and since we see

00:20:39,690 --> 00:20:46,350
it's still jumping oh it's jumping down

00:20:41,520 --> 00:20:48,630
and it's basically the same code so what

00:20:46,350 --> 00:20:50,910
a now did is I relink the kernel what I

00:20:48,630 --> 00:20:53,130
when I recompile it from here to here

00:20:50,910 --> 00:20:55,260
for to relink it anyway but if I can

00:20:53,130 --> 00:20:58,470
also do is real inking it here and and

00:20:55,260 --> 00:21:00,060
shuffling around the object files for

00:20:58,470 --> 00:21:01,400
security measurement and then it looks

00:21:00,060 --> 00:21:04,530
like this

00:21:01,400 --> 00:21:07,620
so by real inking but just moving the

00:21:04,530 --> 00:21:10,170
objects up and down the performance

00:21:07,620 --> 00:21:12,960
changes and now you see that those

00:21:10,170 --> 00:21:15,600
commits are completely irrelevant it's

00:21:12,960 --> 00:21:19,530
just a layout of the files that changes

00:21:15,600 --> 00:21:25,680
that and we are between here here's 3.1

00:21:19,530 --> 00:21:30,870
gigabit and here is 3.45 so it's it's

00:21:25,680 --> 00:21:33,830
pretty much so I I want to explain again

00:21:30,870 --> 00:21:37,800
how it works so what what the security

00:21:33,830 --> 00:21:41,040
mechanism of open BSD is doing so when

00:21:37,800 --> 00:21:43,140
when when the boot loader loads the

00:21:41,040 --> 00:21:46,380
kernel it looks like oops got the wrong

00:21:43,140 --> 00:21:49,050
button here okay when the boot loader

00:21:46,380 --> 00:21:51,660
loads the kernel it looks like that so

00:21:49,050 --> 00:21:54,600
we have here's the boot loader here's a

00:21:51,660 --> 00:21:56,760
low coronel loco zero that's the the

00:21:54,600 --> 00:21:58,950
part of the kernel that's setting up

00:21:56,760 --> 00:22:00,690
page tables in a very basic way and the

00:21:58,950 --> 00:22:02,610
bootloader has to know where to jump to

00:22:00,690 --> 00:22:05,400
it and it's the start function so this

00:22:02,610 --> 00:22:08,370
one is a fixed address and by real

00:22:05,400 --> 00:22:11,340
inking the kernel before booting it we

00:22:08,370 --> 00:22:14,040
add a random gap so that those object

00:22:11,340 --> 00:22:15,750
files are jumping up and down and we

00:22:14,040 --> 00:22:18,030
have a linker option that shuffles them

00:22:15,750 --> 00:22:19,050
randomly so when a attacker wants to

00:22:18,030 --> 00:22:21,750
know Oh where's

00:22:19,050 --> 00:22:24,660
address in object for it's completely

00:22:21,750 --> 00:22:26,429
different at their every boot and the

00:22:24,660 --> 00:22:28,740
loco jumps to the main function which is

00:22:26,429 --> 00:22:32,250
in this object file and after starting

00:22:28,740 --> 00:22:33,780
this this part is unlinked from the

00:22:32,250 --> 00:22:35,760
outer space the thing is that that here

00:22:33,780 --> 00:22:37,860
you have the pointers to there so if the

00:22:35,760 --> 00:22:39,990
Edit attacker can read that he can

00:22:37,860 --> 00:22:41,490
figure out where this object is but not

00:22:39,990 --> 00:22:43,410
an open B is d because this here is

00:22:41,490 --> 00:22:45,780
unlinked and you can't see it anymore in

00:22:43,410 --> 00:22:49,230
the address space so nice thing for

00:22:45,780 --> 00:22:54,059
security but bad for reproducible

00:22:49,230 --> 00:22:57,210
performance so what I did now I sort

00:22:54,059 --> 00:23:02,420
those object files and I set the gap to

00:22:57,210 --> 00:23:06,080
zero and now everything's good see here

00:23:02,420 --> 00:23:11,490
so but what's that so here we have a

00:23:06,080 --> 00:23:13,590
file a commit that's not used but an

00:23:11,490 --> 00:23:16,620
additional object file in the kernel and

00:23:13,590 --> 00:23:19,440
of course that moves all of the other

00:23:16,620 --> 00:23:21,600
object files that are above it so they

00:23:19,440 --> 00:23:28,140
are sorted alphabetically so everything

00:23:21,600 --> 00:23:31,770
after T is moved this this means we

00:23:28,140 --> 00:23:35,940
still have some moving moving effects of

00:23:31,770 --> 00:23:39,179
performance and as I made a test I just

00:23:35,940 --> 00:23:41,460
add a random gap so I sort them

00:23:39,179 --> 00:23:44,790
alphabetically but it just move the gap

00:23:41,460 --> 00:23:48,600
so move the kernel up and down and it

00:23:44,790 --> 00:23:51,870
starts jumping again so what I can do

00:23:48,600 --> 00:23:54,360
now so my think was okay it has to be

00:23:51,870 --> 00:23:59,160
something with alignment alignment so so

00:23:54,360 --> 00:24:05,179
cache lines page alignment what was my

00:23:59,160 --> 00:24:08,610
guess and what I do now is I align those

00:24:05,179 --> 00:24:11,010
each object file at the page boundary

00:24:08,610 --> 00:24:13,800
that means the colonel gets twice as big

00:24:11,010 --> 00:24:18,390
but for the test it's it's irrelevant

00:24:13,800 --> 00:24:21,600
and what I get is very precise values

00:24:18,390 --> 00:24:23,730
here but still this one jumping and the

00:24:21,600 --> 00:24:26,880
things that that this one it's quite a

00:24:23,730 --> 00:24:30,120
lot and the other objects above it start

00:24:26,880 --> 00:24:33,180
jumping by whole pages and that's still

00:24:30,120 --> 00:24:34,950
relevant for performance so my previous

00:24:33,180 --> 00:24:36,780
theory that it has to be something with

00:24:34,950 --> 00:24:39,390
page alignment or calendar sign

00:24:36,780 --> 00:24:41,970
alignment is wrong and I don't know why

00:24:39,390 --> 00:24:45,210
it drums if you execute the object file

00:24:41,970 --> 00:24:46,770
at an higher address even it has the

00:24:45,210 --> 00:24:52,100
same alignment page wise

00:24:46,770 --> 00:24:56,550
it changes performance I did some

00:24:52,100 --> 00:25:01,290
measurement here so I took an M to get

00:24:56,550 --> 00:25:04,830
all the the symbols and addresses that's

00:25:01,290 --> 00:25:07,350
and I sorted and I dipped them and sent

00:25:04,830 --> 00:25:10,800
them to drift art and here with the

00:25:07,350 --> 00:25:15,660
unveil change that is very local when I

00:25:10,800 --> 00:25:18,240
use when I just sorted the the it

00:25:15,660 --> 00:25:20,880
effects much more code above it until it

00:25:18,240 --> 00:25:24,780
gets some with this alignment it it

00:25:20,880 --> 00:25:26,430
fades out after a while and then the the

00:25:24,780 --> 00:25:29,070
address is in the kernel are the same as

00:25:26,430 --> 00:25:31,050
before but if I use the alignment kernel

00:25:29,070 --> 00:25:33,660
it gets much better then all the changes

00:25:31,050 --> 00:25:36,600
are only in the symbol of the source

00:25:33,660 --> 00:25:38,850
file all the changes in addresses of

00:25:36,600 --> 00:25:42,510
symbols are within the source file of

00:25:38,850 --> 00:25:45,510
this unveil source file it's somewhere

00:25:42,510 --> 00:25:49,110
in the file system so here it works

00:25:45,510 --> 00:25:51,570
perfectly changes are locally but here

00:25:49,110 --> 00:25:53,580
with the other with a new driver edit it

00:25:51,570 --> 00:25:56,070
doesn't help so everything above it it

00:25:53,580 --> 00:26:06,600
gets new symbols and it's completely

00:25:56,070 --> 00:26:13,230
somewhere else sorry so what did we do

00:26:06,600 --> 00:26:15,690
now we have six four I run it for 15

00:26:13,230 --> 00:26:17,840
days let me see the next slide

00:26:15,690 --> 00:26:19,170
ah now I know what I want to explain

00:26:17,840 --> 00:26:21,990
okay

00:26:19,170 --> 00:26:23,400
so it took the two CPU socket machine

00:26:21,990 --> 00:26:27,750
that was dead which are outliers and

00:26:23,400 --> 00:26:30,240
here you see we have this line that's

00:26:27,750 --> 00:26:32,100
where most of the results are and

00:26:30,240 --> 00:26:36,540
there's a shadow line where only one

00:26:32,100 --> 00:26:38,670
result is in between sometimes so I

00:26:36,540 --> 00:26:40,770
checked the the slides where you have

00:26:38,670 --> 00:26:42,780
all the the the page where you have all

00:26:40,770 --> 00:26:45,360
the results and you see that's the first

00:26:42,780 --> 00:26:46,950
try it's extra next next next and it's

00:26:45,360 --> 00:26:50,220
always the second cycle

00:26:46,950 --> 00:26:50,909
so when you keep it right keep the

00:26:50,220 --> 00:26:52,710
machine running

00:26:50,909 --> 00:26:53,879
I don't reboot here around the test run

00:26:52,710 --> 00:26:57,059
the test from the test run it tries to

00:26:53,879 --> 00:26:58,649
run a test then the second cycle has

00:26:57,059 --> 00:27:01,350
different results and they are much

00:26:58,649 --> 00:27:04,799
slower they know they are 10% or 20%

00:27:01,350 --> 00:27:08,009
slower and I don't know why so what

00:27:04,799 --> 00:27:13,590
happens there is that by recompiling the

00:27:08,009 --> 00:27:15,779
kernel here the the times on the cpu how

00:27:13,590 --> 00:27:18,600
much it was used is changed and then the

00:27:15,779 --> 00:27:20,549
scheduler decides to run the threads on

00:27:18,600 --> 00:27:22,379
other processes that might be on the

00:27:20,549 --> 00:27:25,049
other socket and that effects

00:27:22,379 --> 00:27:28,019
performance that was relatively clear to

00:27:25,049 --> 00:27:31,980
figure out but then if you re compile

00:27:28,019 --> 00:27:34,499
the kernel again and go to the next

00:27:31,980 --> 00:27:37,799
column then the performance gets higher

00:27:34,499 --> 00:27:39,419
again and that happens reliable on the

00:27:37,799 --> 00:27:43,019
to socket machine but not on the one

00:27:39,419 --> 00:27:47,190
socket machine and it's so this is going

00:27:43,019 --> 00:27:50,340
up again I can't explain so now at what

00:27:47,190 --> 00:27:53,730
I did now is moving to the one socket

00:27:50,340 --> 00:27:58,499
machines because the other one is just

00:27:53,730 --> 00:28:00,029
crap and I did the so that the colors

00:27:58,499 --> 00:28:03,029
change I give the each measure range

00:28:00,029 --> 00:28:07,919
each measurement has a color in this new

00:28:03,029 --> 00:28:09,690
clock graph and so we depending on it

00:28:07,919 --> 00:28:12,090
whether it has the parameters for the

00:28:09,690 --> 00:28:15,330
for for CPU or for the eight CPU

00:28:12,090 --> 00:28:17,639
machines it changes so that's why it's

00:28:15,330 --> 00:28:20,960
green and red here and here we see again

00:28:17,639 --> 00:28:24,570
this TX mitigation that was this 2-day

00:28:20,960 --> 00:28:27,629
performance fix what I also do is is

00:28:24,570 --> 00:28:28,409
compiling the kernel and measure how

00:28:27,629 --> 00:28:32,820
long it takes

00:28:28,409 --> 00:28:35,879
and here we upgraded to see lang 5.0 and

00:28:32,820 --> 00:28:38,580
got this little bit faster here we

00:28:35,879 --> 00:28:41,580
upgraded 4.10 and also get slightly

00:28:38,580 --> 00:28:45,869
faster and here we added some meltdown

00:28:41,580 --> 00:28:48,450
fixes so it made it slower we don't see

00:28:45,869 --> 00:28:50,700
this on the TCP graph it's only in the

00:28:48,450 --> 00:28:53,369
kernel compile time where it affects it

00:28:50,700 --> 00:28:55,919
by the way this is the system time where

00:28:53,369 --> 00:28:57,929
the where we spend in the kernel that's

00:28:55,919 --> 00:29:00,630
the real time that's where is where we

00:28:57,929 --> 00:29:02,850
are actually in the compiler to

00:29:00,630 --> 00:29:05,179
real stuff and that's the combined time

00:29:02,850 --> 00:29:07,830
how long it takes to compile the kernel

00:29:05,179 --> 00:29:09,630
what has we mentioned it's it's not a

00:29:07,830 --> 00:29:11,789
clear measurement because we run on the

00:29:09,630 --> 00:29:14,039
kernel we compile the kernel so we had

00:29:11,789 --> 00:29:16,289
depend on the source files we compile

00:29:14,039 --> 00:29:18,659
and we could depend on the compiler it's

00:29:16,289 --> 00:29:20,970
not made to figure out what's going on

00:29:18,659 --> 00:29:22,830
but it's made more for the fact that a

00:29:20,970 --> 00:29:24,929
lot of developers says oh my machine got

00:29:22,830 --> 00:29:26,580
slower when they compile their kernel

00:29:24,929 --> 00:29:31,760
what happened and I just want to take

00:29:26,580 --> 00:29:33,990
track how the the build time takes and

00:29:31,760 --> 00:29:35,700
there's one other thing when you have

00:29:33,990 --> 00:29:38,820
those perform those network performance

00:29:35,700 --> 00:29:40,380
the fast numbers are higher but here's

00:29:38,820 --> 00:29:45,539
the time to compile the kernel the good

00:29:40,380 --> 00:29:48,149
numbers are slower so it's going up so

00:29:45,539 --> 00:29:52,850
now we have participate for formants

00:29:48,149 --> 00:29:55,769
from 63 to 64 there we had multiple

00:29:52,850 --> 00:30:00,000
things first of all here we committed

00:29:55,769 --> 00:30:03,539
red pool line that's spectra mitigation

00:30:00,000 --> 00:30:05,970
where we make function calls more

00:30:03,539 --> 00:30:08,600
expensive because we trick the branch

00:30:05,970 --> 00:30:12,539
branch predictor that it doesn't find

00:30:08,600 --> 00:30:15,600
that it doesn't remember where we jump

00:30:12,539 --> 00:30:17,940
to so spectra attacks get more difficult

00:30:15,600 --> 00:30:19,799
but jumping on function pointers also

00:30:17,940 --> 00:30:23,039
and the network's tag does that a lot so

00:30:19,799 --> 00:30:25,350
here we lose performance then we have

00:30:23,039 --> 00:30:27,720
added witness witness is a tool that we

00:30:25,350 --> 00:30:30,899
copied from FreeBSD that helps you to

00:30:27,720 --> 00:30:32,940
find mismanagement of locks and and

00:30:30,899 --> 00:30:34,260
deadlock prevention and it's more or

00:30:32,940 --> 00:30:37,169
less a debugging tool and we were

00:30:34,260 --> 00:30:41,340
running it for for a while in our kernel

00:30:37,169 --> 00:30:42,720
just to see other reports and can be

00:30:41,340 --> 00:30:44,309
fixed it so it was never planned for

00:30:42,720 --> 00:30:49,529
release we know that it would be slower

00:30:44,309 --> 00:30:51,870
and here we enabled it here we got

00:30:49,529 --> 00:30:56,850
another security feature that's read

00:30:51,870 --> 00:31:01,860
guard read guard makes it harder to

00:30:56,850 --> 00:31:04,230
exploit return-oriented programming ROPS

00:31:01,860 --> 00:31:06,149
because those rough slides that you have

00:31:04,230 --> 00:31:08,730
at the function stops before the return

00:31:06,149 --> 00:31:10,770
we may have an additional check before

00:31:08,730 --> 00:31:13,620
the return instruction to figure out if

00:31:10,770 --> 00:31:14,220
the stack was mangled and some attackers

00:31:13,620 --> 00:31:15,600
doing evil

00:31:14,220 --> 00:31:18,780
stuff so we have more drums more

00:31:15,600 --> 00:31:22,110
compares and it gets slower that's here

00:31:18,780 --> 00:31:25,289
and here we disabled witness again so it

00:31:22,110 --> 00:31:27,270
was a debugging test for just one two

00:31:25,289 --> 00:31:28,679
months or one and a half months we

00:31:27,270 --> 00:31:31,140
enabled it again and now we got

00:31:28,679 --> 00:31:33,630
performance but it was much less than

00:31:31,140 --> 00:31:35,880
before and here it's more or less

00:31:33,630 --> 00:31:39,990
constant and you still see we have a

00:31:35,880 --> 00:31:43,650
broad range of performance because I

00:31:39,990 --> 00:31:47,280
didn't get the numbers they will get so

00:31:43,650 --> 00:31:51,539
when we look at the at the compile time

00:31:47,280 --> 00:31:53,340
here we updated si Lang to 6-0 and since

00:31:51,539 --> 00:31:58,710
then updating the compiler made it

00:31:53,340 --> 00:32:02,610
slower then we added a new DRM that's

00:31:58,710 --> 00:32:04,860
the the graphics driver and it added new

00:32:02,610 --> 00:32:06,390
files so compiling the colonel gets

00:32:04,860 --> 00:32:09,179
lower because we have more source file

00:32:06,390 --> 00:32:11,549
so that's expected here we see again

00:32:09,179 --> 00:32:13,049
what we had before we had you see

00:32:11,549 --> 00:32:14,460
especially see it at the system time

00:32:13,049 --> 00:32:16,710
because system calls get more expensive

00:32:14,460 --> 00:32:19,980
here we have witness that's a kernel

00:32:16,710 --> 00:32:22,830
feature we have Red Guard that's Colonel

00:32:19,980 --> 00:32:24,630
Red Guard so system time goes up and we

00:32:22,830 --> 00:32:29,159
have witness turning off that's also

00:32:24,630 --> 00:32:31,049
colonel so it happens here and here the

00:32:29,159 --> 00:32:33,510
system time got up but here it got down

00:32:31,049 --> 00:32:37,080
so and when I started doing this project

00:32:33,510 --> 00:32:38,669
I was around here and then I saw all

00:32:37,080 --> 00:32:41,280
what what happened here the system time

00:32:38,669 --> 00:32:44,250
got down and it was a part in the kernel

00:32:41,280 --> 00:32:45,900
we we changed the way we we measured the

00:32:44,250 --> 00:32:48,330
time and we forgot some sometimes

00:32:45,900 --> 00:32:50,789
especially the spinning times about

00:32:48,330 --> 00:32:53,010
mutexes was forgotten to add to the

00:32:50,789 --> 00:32:55,430
system time so this time is just a

00:32:53,010 --> 00:32:59,720
measurement error and here fix the back

00:32:55,430 --> 00:33:05,039
[Laughter]

00:32:59,720 --> 00:33:07,620
so now we go from 64 to 65 so nothing

00:33:05,039 --> 00:33:11,700
really important changed here except

00:33:07,620 --> 00:33:15,480
here we have added safe arc safe arcs is

00:33:11,700 --> 00:33:17,640
a feature that we copy the register when

00:33:15,480 --> 00:33:19,530
we call a function we copy the the

00:33:17,640 --> 00:33:21,750
content of the registers to the stack

00:33:19,530 --> 00:33:24,600
because when the kernel crashes you get

00:33:21,750 --> 00:33:27,030
a trace back trace and then you see all

00:33:24,600 --> 00:33:27,990
the arguments that were given to the

00:33:27,030 --> 00:33:30,510
function

00:33:27,990 --> 00:33:34,440
which makes which makes it much much

00:33:30,510 --> 00:33:36,090
easier to debug but it costs time by by

00:33:34,440 --> 00:33:38,250
copying it from the registers to the

00:33:36,090 --> 00:33:40,350
stack and you can actually see it so I

00:33:38,250 --> 00:33:46,230
made some drill down and it's exactly

00:33:40,350 --> 00:33:50,730
this line so the now the name same for

00:33:46,230 --> 00:33:52,620
for Colonel compiling here we changed

00:33:50,730 --> 00:33:55,170
the the linker before we had the new

00:33:52,620 --> 00:33:57,660
linker now we have the C Lang linker or

00:33:55,170 --> 00:33:59,640
the the LLVM linker and what you see

00:33:57,660 --> 00:34:02,040
here that's the link time and it was

00:33:59,640 --> 00:34:03,990
pretty constant here and now LD is

00:34:02,040 --> 00:34:06,630
multi-threaded and that's the reason why

00:34:03,990 --> 00:34:09,510
the link time is not stable anymore it's

00:34:06,630 --> 00:34:12,149
going going depending on how the

00:34:09,510 --> 00:34:17,669
threading works it's much faster or less

00:34:12,149 --> 00:34:22,100
fast so here we change to si Lang 7-0 as

00:34:17,669 --> 00:34:27,300
usual compile time goes up then we

00:34:22,100 --> 00:34:30,990
changed to we create a library out of

00:34:27,300 --> 00:34:33,000
the the compiler and it's like okay we

00:34:30,990 --> 00:34:35,970
create now the compiler uses library and

00:34:33,000 --> 00:34:38,520
they talk to it with it with Patrick

00:34:35,970 --> 00:34:41,220
yesterday and said oh it the compiler

00:34:38,520 --> 00:34:43,050
doesn't use it so this this change is

00:34:41,220 --> 00:34:45,750
irrelevant but you still see it here in

00:34:43,050 --> 00:34:48,179
the in the build time going up the

00:34:45,750 --> 00:34:50,520
reason is that it's it's a quirk so I

00:34:48,179 --> 00:34:52,710
compile recompile here the compiler

00:34:50,520 --> 00:34:54,540
because I saw okay we had this this

00:34:52,710 --> 00:34:56,790
change but here in between there's also

00:34:54,540 --> 00:34:58,560
some changes to the compiler so one of

00:34:56,790 --> 00:35:00,600
those changes between the full compiler

00:34:58,560 --> 00:35:04,260
build here and the full compiler built

00:35:00,600 --> 00:35:08,280
here resulted in this little being a

00:35:04,260 --> 00:35:11,790
little bit slower so what we did here is

00:35:08,280 --> 00:35:14,460
we recompile the compiler again because

00:35:11,790 --> 00:35:16,680
we had a stack protector in there and

00:35:14,460 --> 00:35:18,300
the red card and OpenBSD decided then

00:35:16,680 --> 00:35:21,150
when you have red card that's the

00:35:18,300 --> 00:35:27,540
stricter thing then you disable the the

00:35:21,150 --> 00:35:29,550
general stack protector okay so compile

00:35:27,540 --> 00:35:31,500
time got a little bit up but again I

00:35:29,550 --> 00:35:33,630
compiled the real whole compiler could

00:35:31,500 --> 00:35:35,790
be something hidden in here and the

00:35:33,630 --> 00:35:37,890
system time got a little bit down so the

00:35:35,790 --> 00:35:40,290
kernel it's only kernel stack protector

00:35:37,890 --> 00:35:41,580
that's removed so the system time is a

00:35:40,290 --> 00:35:46,140
little bit down

00:35:41,580 --> 00:35:53,070
so it works better so that's the newest

00:35:46,140 --> 00:35:55,920
release so that's six five two now so we

00:35:53,070 --> 00:35:57,990
told dlg about the problem that the

00:35:55,920 --> 00:36:00,480
performance no not the problem the thing

00:35:57,990 --> 00:36:02,070
that his TX mitigation made it faster he

00:36:00,480 --> 00:36:04,110
said okay now I try to make the

00:36:02,070 --> 00:36:07,110
difficult braking Claudia's laptop and

00:36:04,110 --> 00:36:11,580
that was committed here so performance

00:36:07,110 --> 00:36:15,030
got up then I couldn't figure out what

00:36:11,580 --> 00:36:17,010
this is the problem is it so another

00:36:15,030 --> 00:36:20,400
thing a change to alignment now before I

00:36:17,010 --> 00:36:22,530
had those randomized kernels now I have

00:36:20,400 --> 00:36:25,110
the aligned kernels I couldn't do that

00:36:22,530 --> 00:36:30,030
before because I need the the new linker

00:36:25,110 --> 00:36:32,550
the the LD the the si Lang LD linker and

00:36:30,030 --> 00:36:34,890
we hadn't that before so I can do it now

00:36:32,550 --> 00:36:37,260
and you see that the the the broadness

00:36:34,890 --> 00:36:40,320
of the lines went down because the the

00:36:37,260 --> 00:36:44,040
the numbers are more exact but every

00:36:40,320 --> 00:36:47,220
time when we have a change that affects

00:36:44,040 --> 00:36:49,800
the layout of the kernel although we

00:36:47,220 --> 00:36:52,020
align it like adding a driver then we

00:36:49,800 --> 00:36:54,240
have something like this or we have

00:36:52,020 --> 00:36:56,070
something like this you see it goes down

00:36:54,240 --> 00:36:57,900
and then up and I couldn't figure out

00:36:56,070 --> 00:37:00,090
what it is and here also it goes down

00:36:57,900 --> 00:37:02,160
down down if it's if it's one going up

00:37:00,090 --> 00:37:03,990
and down then it's quite easy to say

00:37:02,160 --> 00:37:06,030
okay then what's dead but if it's going

00:37:03,990 --> 00:37:10,650
down slowly it's it's really hard to say

00:37:06,030 --> 00:37:15,930
what it is so working on we figured out

00:37:10,650 --> 00:37:17,670
that the kernel does not did not use the

00:37:15,930 --> 00:37:19,080
checksum offloading feature of the

00:37:17,670 --> 00:37:21,360
driver because of what you just said

00:37:19,080 --> 00:37:23,820
disabled in the driver we enabled it it

00:37:21,360 --> 00:37:26,160
was the i-x driver and then performance

00:37:23,820 --> 00:37:28,890
went up I haven't figured out what this

00:37:26,160 --> 00:37:31,740
is this and this because it I finished

00:37:28,890 --> 00:37:35,760
this measurement last week and didn't do

00:37:31,740 --> 00:37:37,890
the drill down yet so to figure out

00:37:35,760 --> 00:37:39,870
those things that happen

00:37:37,890 --> 00:37:42,300
it showed you the click before you can

00:37:39,870 --> 00:37:45,450
click on the on the the column and then

00:37:42,300 --> 00:37:50,730
you find the CVS lock I take everything

00:37:45,450 --> 00:37:53,040
from CVS and put it in a nice HTML page

00:37:50,730 --> 00:37:54,930
so you can just scroll through it and

00:37:53,040 --> 00:37:55,440
here you can click that's a link into

00:37:54,930 --> 00:37:57,420
the

00:37:55,440 --> 00:37:58,829
CVS web of open bees DS or you can

00:37:57,420 --> 00:38:03,930
figure out what was between here and

00:37:58,829 --> 00:38:06,660
there so now I have something about UDP

00:38:03,930 --> 00:38:07,549
that's the slides I could skip if I'm

00:38:06,660 --> 00:38:11,490
too slow

00:38:07,549 --> 00:38:15,809
so we have five minutes or well okay we

00:38:11,490 --> 00:38:20,460
do it so I started doing UDP for

00:38:15,809 --> 00:38:22,950
performance tests basically I do it from

00:38:20,460 --> 00:38:26,670
65 I did it with iperf before and it was

00:38:22,950 --> 00:38:28,049
just a constant line not very

00:38:26,670 --> 00:38:31,440
interesting and if we wanted to figure

00:38:28,049 --> 00:38:32,880
out why and so before all the releases

00:38:31,440 --> 00:38:34,559
before it was ahead only this this

00:38:32,880 --> 00:38:38,519
measurement that's the iperf measurement

00:38:34,559 --> 00:38:40,619
and I saw it and then here we we added

00:38:38,519 --> 00:38:43,109
MBS mitigation that's a machine that has

00:38:40,619 --> 00:38:45,119
an old CPU without new firmware so I'm

00:38:43,109 --> 00:38:46,890
the s in mitigation from Intel without

00:38:45,119 --> 00:38:51,509
Intel firmware drops the performance

00:38:46,890 --> 00:38:54,119
that's expected and then I think 10 is

00:38:51,509 --> 00:38:56,309
committed a time counter change that

00:38:54,119 --> 00:38:58,980
means that we changed the way how we

00:38:56,309 --> 00:39:01,140
measure time in the kernel and they are

00:38:58,980 --> 00:39:06,480
dropped and it has more or less nothing

00:39:01,140 --> 00:39:09,089
to do with UDP and here we changed time

00:39:06,480 --> 00:39:10,559
counter the the time counting again in

00:39:09,089 --> 00:39:13,170
the kernel that's pure off this change

00:39:10,559 --> 00:39:15,839
and went up again here we have to check

00:39:13,170 --> 00:39:19,920
some fix that's also expected that it

00:39:15,839 --> 00:39:21,839
gets faster and so what I wanted to know

00:39:19,920 --> 00:39:24,779
what what how does this time counting

00:39:21,839 --> 00:39:26,819
effect our our graphs and I did those

00:39:24,779 --> 00:39:28,980
iperf tests with different time counters

00:39:26,819 --> 00:39:30,539
so that's T is see that's the CPU

00:39:28,980 --> 00:39:33,480
hardware time counter that's the fastest

00:39:30,539 --> 00:39:38,150
then here's some other a CPI counters

00:39:33,480 --> 00:39:41,369
get slower and some i some some very old

00:39:38,150 --> 00:39:43,109
intel counter so we have very poor

00:39:41,369 --> 00:39:45,150
performance but it has nothing to do

00:39:43,109 --> 00:39:48,180
with UDP so i checked what does either

00:39:45,150 --> 00:39:50,849
of to when it does UDP forever UDP size

00:39:48,180 --> 00:39:53,130
a packet is sending it was one right for

00:39:50,849 --> 00:39:55,799
the tepees then it has to time of get

00:39:53,130 --> 00:39:58,259
off they - it's a one select system call

00:39:55,799 --> 00:40:00,509
and another to get time of days system

00:39:58,259 --> 00:40:02,369
called so basically what I prefer - you

00:40:00,509 --> 00:40:04,920
is measuring is the the speed of your

00:40:02,369 --> 00:40:07,200
get time of day a system call and the

00:40:04,920 --> 00:40:08,680
Linux guys don't measure don't get it

00:40:07,200 --> 00:40:10,740
because they have mapped

00:40:08,680 --> 00:40:14,500
memory and it's very fast but for them

00:40:10,740 --> 00:40:16,630
okay now I went back and said okay let's

00:40:14,500 --> 00:40:19,450
write the tool myself and I wrote it a

00:40:16,630 --> 00:40:20,829
tool that it doesn't do get after time

00:40:19,450 --> 00:40:24,670
with David while it's measuring it's

00:40:20,829 --> 00:40:26,470
only doing some alarm timer to to get

00:40:24,670 --> 00:40:27,760
informed when a measurement is over so

00:40:26,470 --> 00:40:29,740
it's all done in the signal handler

00:40:27,760 --> 00:40:31,599
without system calls and then they get

00:40:29,740 --> 00:40:33,849
this line for large packets and

00:40:31,599 --> 00:40:35,500
deadlines with small packets they are

00:40:33,849 --> 00:40:38,010
more or less the same except that you

00:40:35,500 --> 00:40:40,770
can't see the changes in the small

00:40:38,010 --> 00:40:43,720
packets for this because of the scaling

00:40:40,770 --> 00:40:47,290
so here we have two TX mitigation and

00:40:43,720 --> 00:40:52,630
for UDP it gets slower because packets

00:40:47,290 --> 00:40:56,200
are delayed and that means that you have

00:40:52,630 --> 00:40:59,050
bursts and the bursts especially is bad

00:40:56,200 --> 00:41:01,740
when you try to measure TCP a UDP but if

00:40:59,050 --> 00:41:04,359
for TCP it gets fast for UDP get slower

00:41:01,740 --> 00:41:06,880
here is half the MDS yeah of course that

00:41:04,359 --> 00:41:09,250
also effects the the right and send and

00:41:06,880 --> 00:41:11,500
receive system call don't know what that

00:41:09,250 --> 00:41:15,700
is going up and down here we have the

00:41:11,500 --> 00:41:17,980
tech checksum checksum fix performance

00:41:15,700 --> 00:41:23,980
goes up perfect and those time counters

00:41:17,980 --> 00:41:25,049
don't affect our performance anymore so

00:41:23,980 --> 00:41:28,000
what's the conclusion

00:41:25,049 --> 00:41:29,619
so measuring sucks it's really

00:41:28,000 --> 00:41:30,900
complicated and you see things you don't

00:41:29,619 --> 00:41:33,790
understand

00:41:30,900 --> 00:41:35,890
Multi sockets boards suck

00:41:33,790 --> 00:41:41,440
you see effects that you understand even

00:41:35,890 --> 00:41:43,660
less reproducing your numbers is hard so

00:41:41,440 --> 00:41:45,220
it's not an easy job to get the same

00:41:43,660 --> 00:41:50,349
number when you do the same measurement

00:41:45,220 --> 00:41:53,200
twice don't trust your numbers look look

00:41:50,349 --> 00:41:56,079
at those this iperf tool it it set me

00:41:53,200 --> 00:41:57,730
for four for two or three releases your

00:41:56,079 --> 00:41:59,530
numbers are perfectly constant at one

00:41:57,730 --> 00:42:03,339
gigabit and I never know how does it

00:41:59,530 --> 00:42:06,040
measure one gigabit and keep it simple

00:42:03,339 --> 00:42:07,720
and stupid your more complexity you add

00:42:06,040 --> 00:42:09,520
I have no switch in there it's just a

00:42:07,720 --> 00:42:12,099
line between a cable between two

00:42:09,520 --> 00:42:13,839
machines and it's just two machines with

00:42:12,099 --> 00:42:15,099
the same software and sending packets

00:42:13,839 --> 00:42:19,660
from one machine to the other one

00:42:15,099 --> 00:42:19,990
through a single cable so what can be

00:42:19,660 --> 00:42:21,609
done

00:42:19,990 --> 00:42:23,499
additionally

00:42:21,609 --> 00:42:25,390
I've not done forwarding it's just

00:42:23,499 --> 00:42:27,390
measuring the stack sending from one

00:42:25,390 --> 00:42:29,920
machine and receiving on the other one I

00:42:27,390 --> 00:42:31,749
could add some some Linux clients so

00:42:29,920 --> 00:42:33,190
ever after Hardware standing there but I

00:42:31,749 --> 00:42:35,440
have to figure out how to to do a

00:42:33,190 --> 00:42:38,279
sensible measurement so I have a

00:42:35,440 --> 00:42:42,369
constant source or drain of packets I

00:42:38,279 --> 00:42:44,049
can't could test patches the framework

00:42:42,369 --> 00:42:46,119
doesn't provide that I only cook mesh

00:42:44,049 --> 00:42:48,660
measure committed things and if somebody

00:42:46,119 --> 00:42:52,509
sends a patch I won't want to test that

00:42:48,660 --> 00:42:53,950
somehow automatically I can measure

00:42:52,509 --> 00:42:56,079
historic releases how was the

00:42:53,950 --> 00:42:58,930
performance at open BSD four zero for

00:42:56,079 --> 00:43:00,400
example and file system performance I

00:42:58,930 --> 00:43:02,109
have a test there but it doesn't work

00:43:00,400 --> 00:43:03,700
very well because the controller I have

00:43:02,109 --> 00:43:07,779
sucks with the hardware and some

00:43:03,700 --> 00:43:09,880
problems so I have to say thank you for

00:43:07,779 --> 00:43:12,180
a young clamp or who is administrating

00:43:09,880 --> 00:43:15,430
all the machines and keeps them running

00:43:12,180 --> 00:43:17,200
so move it spool he's always not sitting

00:43:15,430 --> 00:43:21,849
in my talk he went to another talk he

00:43:17,200 --> 00:43:24,519
did I say thank thank you anyway so he

00:43:21,849 --> 00:43:26,999
did all those new plot visualization and

00:43:24,519 --> 00:43:30,210
also helped keeping the machine running

00:43:26,999 --> 00:43:35,950
my employer is quinoa they pay for the

00:43:30,210 --> 00:43:38,619
Rackspace and work time so I have put

00:43:35,950 --> 00:43:42,249
everything on line here those links you

00:43:38,619 --> 00:43:45,369
can get those results those those slides

00:43:42,249 --> 00:43:46,059
and here's all the test data in in a

00:43:45,369 --> 00:43:50,380
text file

00:43:46,059 --> 00:43:53,829
suitable for new plot I've put all my

00:43:50,380 --> 00:43:56,769
performance and regression testing in a

00:43:53,829 --> 00:44:00,880
github project it's here he is the the

00:43:56,769 --> 00:44:02,489
code from from Yan Clem ko to setup to

00:44:00,880 --> 00:44:05,049
make those auto installs in the auto

00:44:02,489 --> 00:44:08,200
configuration of machines and this here

00:44:05,049 --> 00:44:12,269
is my talk on github and that's how it

00:44:08,200 --> 00:44:12,269
looks like thank you

00:44:13,000 --> 00:44:18,650
[Music]

00:44:15,609 --> 00:44:27,349
we have time for a couple of fast

00:44:18,650 --> 00:44:30,770
questions go there to question about the

00:44:27,349 --> 00:44:33,380
tools if I did do you use I perv and not

00:44:30,770 --> 00:44:38,690
TCP burn switches and bays and supports

00:44:33,380 --> 00:44:40,790
UDP as well so I do TCP bench for TCP so

00:44:38,690 --> 00:44:43,250
I have those differently colored numbers

00:44:40,790 --> 00:44:44,770
those are the Reds and the and the the

00:44:43,250 --> 00:44:47,720
yellow ones and the green ones there's

00:44:44,770 --> 00:44:51,520
iperf and tcp intermixed and they give

00:44:47,720 --> 00:44:54,830
the same results for TCP for TCP bench

00:44:51,520 --> 00:44:57,290
- you I have the problem that I cannot

00:44:54,830 --> 00:44:59,869
measure how much how many packets I

00:44:57,290 --> 00:45:01,490
received an automatic way so if I have

00:44:59,869 --> 00:45:03,440
two tools running and the one says me

00:45:01,490 --> 00:45:04,700
okay I'm sending this much and the other

00:45:03,440 --> 00:45:06,859
one prints

00:45:04,700 --> 00:45:09,830
now I've received zero then I get some

00:45:06,859 --> 00:45:12,560
packets and then 0 again so I decided to

00:45:09,830 --> 00:45:14,900
write in my own tool that's called UDP

00:45:12,560 --> 00:45:18,520
bench that is setting up yet the

00:45:14,900 --> 00:45:20,720
receiving side via an SSH connection and

00:45:18,520 --> 00:45:22,400
sending the packets here receiving it

00:45:20,720 --> 00:45:26,210
there collecting both results and

00:45:22,400 --> 00:45:29,599
publishing both ok so TCP bench for UDP

00:45:26,210 --> 00:45:32,750
is not very suitable ok for automatic

00:45:29,599 --> 00:45:38,180
testing and the other question is I once

00:45:32,750 --> 00:45:41,869
did performance testing where I used 1

00:45:38,180 --> 00:45:44,030
the test device under test right at the

00:45:41,869 --> 00:45:48,859
optimistic box and then a second machine

00:45:44,030 --> 00:45:53,650
where I used add there's an bootable net

00:45:48,859 --> 00:45:56,859
map image does FreeBSD net map sing and

00:45:53,650 --> 00:46:00,470
you can just put it on USB booted and

00:45:56,859 --> 00:46:02,900
then it it works in a way that it

00:46:00,470 --> 00:46:05,810
basically poops puts packets directly on

00:46:02,900 --> 00:46:08,510
the network interface ring and then I

00:46:05,810 --> 00:46:10,190
had a dual port card so I one card was

00:46:08,510 --> 00:46:12,650
set up to send and it can also measure

00:46:10,190 --> 00:46:15,140
the packet it receives so the pezzi

00:46:12,650 --> 00:46:17,630
ocula allows you to use the dual port IX

00:46:15,140 --> 00:46:20,210
in a server puts this net map image

00:46:17,630 --> 00:46:23,000
it's FreeBSD but it's just for testing

00:46:20,210 --> 00:46:25,460
yeah it's okay and and then you can

00:46:23,000 --> 00:46:26,600
dubia generate wires P traffic and

00:46:25,460 --> 00:46:28,280
measure the reach

00:46:26,600 --> 00:46:30,050
and the optimistic box in the middle

00:46:28,280 --> 00:46:32,300
just has to forward this because I

00:46:30,050 --> 00:46:35,300
always have the problem that the tools

00:46:32,300 --> 00:46:37,490
to generate that much UDP traffic are

00:46:35,300 --> 00:46:40,820
not really fast enough to send or

00:46:37,490 --> 00:46:44,750
receive it for reword a situation you

00:46:40,820 --> 00:46:48,320
get wire speed from the out what you

00:46:44,750 --> 00:46:50,660
describe is the correct setup for doing

00:46:48,320 --> 00:46:53,720
forwarding tests yet what I wanted to

00:46:50,660 --> 00:47:00,530
test it's the TCP stack so I have to

00:46:53,720 --> 00:47:03,110
have a real TCP connection and I just

00:47:00,530 --> 00:47:05,180
wanted to see how does sending and

00:47:03,110 --> 00:47:07,130
receiving from the same machine work for

00:47:05,180 --> 00:47:09,200
example for UDP I think the problem is

00:47:07,130 --> 00:47:11,000
that the system call we have can only

00:47:09,200 --> 00:47:14,210
send one packet per system call that's

00:47:11,000 --> 00:47:16,820
why this UDP numbers are so slow yeah so

00:47:14,210 --> 00:47:19,640
it depends what you want to measure I

00:47:16,820 --> 00:47:21,500
would say for forwarding a setup like

00:47:19,640 --> 00:47:22,880
you described could be better it can be

00:47:21,500 --> 00:47:26,780
done that's the reason why there is this

00:47:22,880 --> 00:47:28,970
Linux box in in in this picture but I

00:47:26,780 --> 00:47:30,650
haven't set it up yeah but for measuring

00:47:28,970 --> 00:47:33,500
the stack you have to go through your

00:47:30,650 --> 00:47:36,290
stack anyway and if you go it on both

00:47:33,500 --> 00:47:38,030
sides which OpenBSD it's just a problem

00:47:36,290 --> 00:47:40,640
that you can't see if it's a sending a

00:47:38,030 --> 00:47:43,610
receiving side causing the problems okay

00:47:40,640 --> 00:47:47,390
thank you but of course there's a lot of

00:47:43,610 --> 00:47:49,280
room to for improvement and it's it's I

00:47:47,390 --> 00:47:51,950
can do a historical things I can say

00:47:49,280 --> 00:47:54,560
okay run from 6 to 2 to 6 3 again with

00:47:51,950 --> 00:47:56,870
its new test it's also an advantage I

00:47:54,560 --> 00:47:59,390
can think of a test in the afterwards

00:47:56,870 --> 00:48:02,470
and say ok now let's put the test to the

00:47:59,390 --> 00:48:02,470
past and see what happened there

00:48:03,040 --> 00:48:07,690
Thank You Alexander thank you very much

00:48:10,410 --> 00:48:12,470
you

00:48:19,420 --> 00:48:21,480

YouTube URL: https://www.youtube.com/watch?v=as5gCNgWjmY


