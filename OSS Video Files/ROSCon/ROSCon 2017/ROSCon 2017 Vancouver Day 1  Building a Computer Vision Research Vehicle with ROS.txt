Title: ROSCon 2017 Vancouver Day 1  Building a Computer Vision Research Vehicle with ROS
Publication date: 2021-03-28
Playlist: ROSCon 2017
Description: 
	Unaltered video by Open Robotics from http://roscon.ros.org/2017 under the Attribution-NonCommercial-NoDerivs 3.0 Unported (CC BY-NC-ND 3.0) License
Captions: 
	00:00:01,100 --> 00:00:06,870
thank you very much for the introduction

00:00:03,449 --> 00:00:08,790
and welcome to our presentation with a

00:00:06,870 --> 00:00:12,660
name building a computer vision research

00:00:08,790 --> 00:00:14,639
vehicle with Ross this is the agenda I

00:00:12,660 --> 00:00:16,980
will start with the introduction and a

00:00:14,639 --> 00:00:19,050
short history section followed by the

00:00:16,980 --> 00:00:21,020
main parts trigging I had a

00:00:19,050 --> 00:00:24,029
heterogeneous center set up and/or

00:00:21,020 --> 00:00:26,369
calibration solution for cameras later I

00:00:24,029 --> 00:00:28,170
will cover enhancement that we did for

00:00:26,369 --> 00:00:30,359
example at the respec player and

00:00:28,170 --> 00:00:32,430
recorder and the top will close with

00:00:30,359 --> 00:00:35,040
some words about data handling and hope

00:00:32,430 --> 00:00:39,180
personal lessons learned while working

00:00:35,040 --> 00:00:41,340
with Ross a few words about ourselves as

00:00:39,180 --> 00:00:44,070
you may know Daimler is a corporate

00:00:41,340 --> 00:00:46,350
parent of missus bands and the work that

00:00:44,070 --> 00:00:48,989
I am presenting today is not done by me

00:00:46,350 --> 00:00:50,969
alone but with my colleagues we all

00:00:48,989 --> 00:00:53,600
started in the corporate research in

00:00:50,969 --> 00:00:56,940
team pattern recognition and cameras as

00:00:53,600 --> 00:00:59,520
PhDs and or each search topics are

00:00:56,940 --> 00:01:01,260
pedestrian intention recognition driver

00:00:59,520 --> 00:01:03,539
observation and traffic light

00:01:01,260 --> 00:01:05,339
recognition that means we are all

00:01:03,539 --> 00:01:07,710
working with camera images mainly and

00:01:05,339 --> 00:01:10,200
have a second strong focus on machine

00:01:07,710 --> 00:01:13,530
learning where for we in need good data

00:01:10,200 --> 00:01:15,299
sets for research we choose Ross and to

00:01:13,530 --> 00:01:17,189
show you how we build our computer

00:01:15,299 --> 00:01:19,740
vision orientated research vehicles and

00:01:17,189 --> 00:01:21,990
here today I'd like to add some words

00:01:19,740 --> 00:01:25,259
about my personal backgrounds regarding

00:01:21,990 --> 00:01:26,430
Ross because I started Ross using at the

00:01:25,259 --> 00:01:28,619
university of hannover

00:01:26,430 --> 00:01:30,900
where the mechatronics labs that this

00:01:28,619 --> 00:01:32,610
was an early adopter of the cuca you

00:01:30,900 --> 00:01:35,490
bought that you can see here on the

00:01:32,610 --> 00:01:37,380
right the orange thing the ubot

00:01:35,490 --> 00:01:39,540
originally came with ross sea turtle

00:01:37,380 --> 00:01:42,240
pre-installed and was when i started

00:01:39,540 --> 00:01:45,060
working with the u-boat in 2011 it was

00:01:42,240 --> 00:01:46,619
just migrated to Ross Diamondback we

00:01:45,060 --> 00:01:49,560
also found the team for the then

00:01:46,619 --> 00:01:51,119
upcoming Robocop leaked at work and when

00:01:49,560 --> 00:01:55,079
I started working on traffic light

00:01:51,119 --> 00:01:56,880
detection at Daimler in 2013 most of my

00:01:55,079 --> 00:01:59,729
colleagues were either not using a

00:01:56,880 --> 00:02:02,520
framework or the established one used in

00:01:59,729 --> 00:02:04,860
automotive context I also started with

00:02:02,520 --> 00:02:07,350
plain open CV until I wanted to exchange

00:02:04,860 --> 00:02:09,810
my image loader with life images from a

00:02:07,350 --> 00:02:12,330
camera and therefore used a framework as

00:02:09,810 --> 00:02:13,380
well while doing so and wrapping my

00:02:12,330 --> 00:02:16,740
classes by

00:02:13,380 --> 00:02:18,870
rain rock filters I started to miss the

00:02:16,740 --> 00:02:21,570
introspection capabilities of Ross and

00:02:18,870 --> 00:02:25,500
also especially the documentation from

00:02:21,570 --> 00:02:31,650
the worst out wiki we are almost free at

00:02:25,500 --> 00:02:33,960
Daimler pas Daimler phd's I'm sorry we

00:02:31,650 --> 00:02:36,510
are almost free in which tools we use at

00:02:33,960 --> 00:02:38,220
Daimler so I switched back to Ross which

00:02:36,510 --> 00:02:40,530
was not pre-installed on a corporate

00:02:38,220 --> 00:02:43,380
workstations and that resulted in a lot

00:02:40,530 --> 00:02:44,850
of tries build across from source but in

00:02:43,380 --> 00:02:47,700
the end I think it was worth the pain

00:02:44,850 --> 00:02:51,630
and about a year later my New York PhD

00:02:47,700 --> 00:02:54,810
colleagues also joined the restrain our

00:02:51,630 --> 00:02:56,760
research has mainly autonomous driving

00:02:54,810 --> 00:02:58,500
in mind so I thought in the quick little

00:02:56,760 --> 00:03:00,210
history about the Emilie's pass on

00:02:58,500 --> 00:03:02,430
autonomous driving would be interesting

00:03:00,210 --> 00:03:04,770
the Daimler Corporate Research is

00:03:02,430 --> 00:03:07,770
participating in public research project

00:03:04,770 --> 00:03:10,110
since 30 years and as far as I know

00:03:07,770 --> 00:03:13,290
autonomous driving at Daimler started

00:03:10,110 --> 00:03:17,610
with research vehicle coil to Vita it's

00:03:13,290 --> 00:03:20,340
a one in the in the left and it has was

00:03:17,610 --> 00:03:24,450
also called the video bus it has analog

00:03:20,340 --> 00:03:26,700
cameras into 8086 processes of that time

00:03:24,450 --> 00:03:28,230
and an extra generator installed that

00:03:26,700 --> 00:03:30,990
was producing the electrical energy

00:03:28,230 --> 00:03:32,940
needed the bus was equipped with the

00:03:30,990 --> 00:03:35,670
vision system for automated driving

00:03:32,940 --> 00:03:37,710
developed by the German military that

00:03:35,670 --> 00:03:41,030
had the leading solution that days in

00:03:37,710 --> 00:03:43,709
the early 1990s the Prometheus project

00:03:41,030 --> 00:03:45,300
for the promises project to Mercy

00:03:43,709 --> 00:03:47,459
disbands s classes were equipped with

00:03:45,300 --> 00:03:50,160
this kind of vision system and what

00:03:47,459 --> 00:03:52,770
remarkable is the thing that these cars

00:03:50,160 --> 00:03:55,020
were used to show things like adaptive

00:03:52,770 --> 00:03:58,800
cruise control automated lane keeping at

00:03:55,020 --> 00:03:59,900
up to 130 km/h outer metal lane change

00:03:58,800 --> 00:04:02,070
as well

00:03:59,900 --> 00:04:04,050
Prometheus was followed by a project

00:04:02,070 --> 00:04:06,390
called promote chauffeur which was about

00:04:04,050 --> 00:04:09,930
electronic duel coupling of highways of

00:04:06,390 --> 00:04:13,290
trucks on highways in more recent days

00:04:09,930 --> 00:04:18,000
we showed an autonomous drive called the

00:04:13,290 --> 00:04:22,710
beta route in 2013 on public roads in

00:04:18,000 --> 00:04:26,100
Germany with the car called s 500

00:04:22,710 --> 00:04:27,000
intelligent drive and a yearly year

00:04:26,100 --> 00:04:30,660
later we

00:04:27,000 --> 00:04:33,120
also showed this drive in the USA and we

00:04:30,660 --> 00:04:38,520
also brought it to the truck world and

00:04:33,120 --> 00:04:41,850
bass world okay as mentioned or talked

00:04:38,520 --> 00:04:44,070
covers about research vehicles and here

00:04:41,850 --> 00:04:46,050
they are or team has currently three

00:04:44,070 --> 00:04:49,470
mercedes-benz s-class vehicles and

00:04:46,050 --> 00:04:51,360
another vehicle is a 2016 Mercedes Benz

00:04:49,470 --> 00:04:53,910
b-class electric drive used for another

00:04:51,360 --> 00:04:55,740
research project and the two in the top

00:04:53,910 --> 00:04:58,830
I used for traffic light research and

00:04:55,740 --> 00:05:00,660
have relatively simple setup using the

00:04:58,830 --> 00:05:03,450
vehicle sensor or data obtained from

00:05:00,660 --> 00:05:06,960
canvases as well as prototype prototype

00:05:03,450 --> 00:05:09,000
li stereo cameras and the other two have

00:05:06,960 --> 00:05:11,520
more complex setups including lighters

00:05:09,000 --> 00:05:14,610
high-end odometry sensors or infrared

00:05:11,520 --> 00:05:17,100
cameras the one in the left bottom left

00:05:14,610 --> 00:05:22,320
for example has seven cameras as well as

00:05:17,100 --> 00:05:24,000
relighted systems installed so cars

00:05:22,320 --> 00:05:26,340
already come equipped with a lot of

00:05:24,000 --> 00:05:29,700
sensors and these send the readings are

00:05:26,340 --> 00:05:32,160
transferred using canvases canvases has

00:05:29,700 --> 00:05:34,380
masses descriptions with Rory from car

00:05:32,160 --> 00:05:38,550
to car so to get the readings from the

00:05:34,380 --> 00:05:41,190
bus you need a specific decoder on the

00:05:38,550 --> 00:05:44,430
other side this can message description

00:05:41,190 --> 00:05:46,470
is at least available for us s OEMs so

00:05:44,430 --> 00:05:48,690
we implemented a Ross message generator

00:05:46,470 --> 00:05:51,630
that can create dot message files from

00:05:48,690 --> 00:05:53,850
such a can message description and the

00:05:51,630 --> 00:05:55,830
normal Ross generate message magic is

00:05:53,850 --> 00:05:59,520
used to create the message for each Ross

00:05:55,830 --> 00:06:01,440
client library as CPP or Python the

00:05:59,520 --> 00:06:03,450
message description is also used for our

00:06:01,440 --> 00:06:06,000
decoder note that reads the canvas

00:06:03,450 --> 00:06:09,180
messages decodes them and publish them

00:06:06,000 --> 00:06:14,150
as strongly typed messages as we are

00:06:09,180 --> 00:06:17,010
know it or expected from rostov x

00:06:14,150 --> 00:06:19,530
alright second thing is the prototypical

00:06:17,010 --> 00:06:22,320
hardware that we added to the car like

00:06:19,530 --> 00:06:24,810
cameras and lighters whenever you want

00:06:22,320 --> 00:06:26,660
to use data from multiple senders in low

00:06:24,810 --> 00:06:29,640
levels and diffusion you need two things

00:06:26,660 --> 00:06:31,979
time stamps and frame IDs and with

00:06:29,640 --> 00:06:35,160
fremitus I mean a sender to send or

00:06:31,979 --> 00:06:37,020
transformation regarding time we ideally

00:06:35,160 --> 00:06:39,390
want to capture the surrounding at the

00:06:37,020 --> 00:06:40,470
exact same moment in time and this

00:06:39,390 --> 00:06:42,930
across all

00:06:40,470 --> 00:06:45,030
foreign sensors at best and in this

00:06:42,930 --> 00:06:46,470
context we may have a hit regional

00:06:45,030 --> 00:06:48,840
center set up consisting of different

00:06:46,470 --> 00:06:52,140
height hardware drivers and not rappers

00:06:48,840 --> 00:06:54,750
different captura cycle rates and inside

00:06:52,140 --> 00:06:56,490
the current car we have the canvases as

00:06:54,750 --> 00:06:59,100
well which transfer our sensor readings

00:06:56,490 --> 00:07:00,450
that are not time-stamped so the

00:06:59,100 --> 00:07:03,540
question is how to handle these

00:07:00,450 --> 00:07:06,300
constraints the kind of normal solution

00:07:03,540 --> 00:07:08,580
is setting up Sanders at defined cycle

00:07:06,300 --> 00:07:13,350
rates and use for example software

00:07:08,580 --> 00:07:15,870
triggering the image on the left or this

00:07:13,350 --> 00:07:18,540
on the left of the slide is shown how it

00:07:15,870 --> 00:07:21,360
could be like we have four cameras here

00:07:18,540 --> 00:07:23,100
that are transferring data to the PC and

00:07:21,360 --> 00:07:25,650
the canvas reader which is also

00:07:23,100 --> 00:07:27,840
transferring data the problem is that we

00:07:25,650 --> 00:07:29,970
have normally no insight on the camera

00:07:27,840 --> 00:07:32,370
drivers so we do not know internal

00:07:29,970 --> 00:07:34,350
latencies and using software rigging in

00:07:32,370 --> 00:07:38,100
the end the images will most likely not

00:07:34,350 --> 00:07:40,140
be captured in the very same moment most

00:07:38,100 --> 00:07:42,150
industry grade cameras include a head

00:07:40,140 --> 00:07:45,000
root hardware triggering capability that

00:07:42,150 --> 00:07:49,640
could also be used so when using a

00:07:45,000 --> 00:07:54,150
trigger bus as shown in black color here

00:07:49,640 --> 00:07:55,979
for example controlled by a

00:07:54,150 --> 00:07:59,160
microcontroller that is generating the

00:07:55,979 --> 00:08:03,390
trigger or also a main camera that is

00:07:59,160 --> 00:08:06,090
used as master we can make sure that all

00:08:03,390 --> 00:08:08,490
captures are done in the exact time

00:08:06,090 --> 00:08:12,060
moment but we still don't know when it

00:08:08,490 --> 00:08:13,800
is so when ever sends us to not know

00:08:12,060 --> 00:08:16,050
about reference time we have a problem

00:08:13,800 --> 00:08:19,680
with time stamping we can use the normal

00:08:16,050 --> 00:08:21,479
Ross time now on data arrival but for

00:08:19,680 --> 00:08:23,910
several different nodes this will result

00:08:21,479 --> 00:08:26,250
in different time stamps as they are all

00:08:23,910 --> 00:08:29,190
different processes using Ross time now

00:08:26,250 --> 00:08:31,760
so using a time synchronizer across rust

00:08:29,190 --> 00:08:34,140
topics afterwards will be difficult

00:08:31,760 --> 00:08:36,360
another thing is that rust time now is

00:08:34,140 --> 00:08:37,890
always not correct as it refers to the

00:08:36,360 --> 00:08:40,110
data arrival time and not the data

00:08:37,890 --> 00:08:42,450
acquisition time so in the end we want

00:08:40,110 --> 00:08:46,560
to know the moment of triggering in the

00:08:42,450 --> 00:08:48,810
reference time in our case we migrated

00:08:46,560 --> 00:08:53,580
or Arduino triggering microcontroller to

00:08:48,810 --> 00:08:55,320
an stm32f4 based microcontroller and

00:08:53,580 --> 00:08:59,730
this kind of microcontroller Bosch

00:08:55,320 --> 00:09:02,820
showed on roschin 2015 Rus

00:08:59,730 --> 00:09:04,710
implementation and this project used the

00:09:02,820 --> 00:09:06,660
lightweight internet protocol stack in

00:09:04,710 --> 00:09:08,490
conjunction with the self written XML

00:09:06,660 --> 00:09:11,700
RPC server and the Ross UDP

00:09:08,490 --> 00:09:13,800
implementation to directly publish and

00:09:11,700 --> 00:09:16,770
subscribe ross messages without the need

00:09:13,800 --> 00:09:20,130
of a host pc we adopted this solution

00:09:16,770 --> 00:09:22,130
and added the precise time protocol to

00:09:20,130 --> 00:09:24,450
the project which enables us to publish

00:09:22,130 --> 00:09:28,140
stamped trigger messages that use

00:09:24,450 --> 00:09:30,960
reference time as well so next slide

00:09:28,140 --> 00:09:33,090
here you can see the Edit internet

00:09:30,960 --> 00:09:35,250
connection in red from the host pc to

00:09:33,090 --> 00:09:37,650
the microcontroller that is used by the

00:09:35,250 --> 00:09:40,890
PTP time synchronization as well as the

00:09:37,650 --> 00:09:42,390
Rossi IP implementation in this case the

00:09:40,890 --> 00:09:43,890
host PC is the clock master

00:09:42,390 --> 00:09:46,260
synchronizing the time to the

00:09:43,890 --> 00:09:49,860
microcontroller the microcontroller is

00:09:46,260 --> 00:09:52,020
the trigger master and uses the time to

00:09:49,860 --> 00:09:54,450
send out rus messengers with a header

00:09:52,020 --> 00:09:58,860
that includes the time stamps when the

00:09:54,450 --> 00:10:01,080
when the triggering acute and this

00:09:58,860 --> 00:10:03,360
message is received by the camera nodes

00:10:01,080 --> 00:10:05,760
or January set by general nodes which

00:10:03,360 --> 00:10:09,780
then can use these times them for the

00:10:05,760 --> 00:10:11,670
data when they arrive well we still have

00:10:09,780 --> 00:10:15,510
the unstamped canvas but we can do

00:10:11,670 --> 00:10:17,730
anything there but we can go one step

00:10:15,510 --> 00:10:20,280
further and add valid on led us to the

00:10:17,730 --> 00:10:24,210
scene the valid on itself has a solution

00:10:20,280 --> 00:10:26,970
for time stamping using a GPS sensor and

00:10:24,210 --> 00:10:30,360
the PPS pulse per second trigger system

00:10:26,970 --> 00:10:32,760
in conjunction with Mir spring and in

00:10:30,360 --> 00:10:34,740
all setup we can use the GPS time as a

00:10:32,760 --> 00:10:37,260
reference time the microcontroller then

00:10:34,740 --> 00:10:40,020
becomes the PTP master and transfers the

00:10:37,260 --> 00:10:43,350
time to the host which all will be GPS

00:10:40,020 --> 00:10:46,950
time and in the end we have all sensors

00:10:43,350 --> 00:10:51,000
living in the exact time same time

00:10:46,950 --> 00:10:53,160
reference all right

00:10:51,000 --> 00:10:54,870
initially I said the second big thing

00:10:53,160 --> 00:10:57,540
for us is sensor to sensor

00:10:54,870 --> 00:11:00,660
transformation so the reason behind this

00:10:57,540 --> 00:11:02,910
is sensor orientation even small errors

00:11:00,660 --> 00:11:05,730
here can result in huge position errors

00:11:02,910 --> 00:11:07,590
when we measure distant objects so good

00:11:05,730 --> 00:11:11,710
calibration is

00:11:07,590 --> 00:11:14,380
four cameras starting points is the

00:11:11,710 --> 00:11:16,270
camera Kelly reto dot pi note which

00:11:14,380 --> 00:11:19,210
internally uses OpenCV camera

00:11:16,270 --> 00:11:20,770
calibration and it has an informative UI

00:11:19,210 --> 00:11:23,190
that teaches you where to do your

00:11:20,770 --> 00:11:26,320
chicken dance and where data is needed

00:11:23,190 --> 00:11:28,180
but it also picks images from the

00:11:26,320 --> 00:11:30,700
running video which can result in motion

00:11:28,180 --> 00:11:32,620
blur for example it also does not allow

00:11:30,700 --> 00:11:34,900
you to modify the collected checkerboard

00:11:32,620 --> 00:11:36,700
poses so you have to restart from the

00:11:34,900 --> 00:11:38,380
beginning if you press calibrate and

00:11:36,700 --> 00:11:42,670
decide that calibration is not good

00:11:38,380 --> 00:11:44,860
enough and it does not generate a sensor

00:11:42,670 --> 00:11:49,200
to car transformation at all so our

00:11:44,860 --> 00:11:53,380
solution or requirements are first from

00:11:49,200 --> 00:11:56,020
from the calibration is we wanted to be

00:11:53,380 --> 00:11:57,580
able to do calibrations alone we wanted

00:11:56,020 --> 00:11:59,680
to have an on-demand checkerboard

00:11:57,580 --> 00:12:01,870
detection we wanted to have an life

00:11:59,680 --> 00:12:04,120
detection inspection and we wanted to be

00:12:01,870 --> 00:12:06,910
able to remove poses or to add specific

00:12:04,120 --> 00:12:10,510
poses and we came up with this solution

00:12:06,910 --> 00:12:13,050
a Windows 10 tablet that we installed

00:12:10,510 --> 00:12:14,770
Ubuntu on which is a way more

00:12:13,050 --> 00:12:18,730
complicated than it sounds

00:12:14,770 --> 00:12:20,920
and the checker board directly glued on

00:12:18,730 --> 00:12:23,500
the backside we implemented a

00:12:20,920 --> 00:12:25,210
calibrations client-server system where

00:12:23,500 --> 00:12:28,210
we get a live image using the Wi-Fi

00:12:25,210 --> 00:12:29,920
tablet as a tablet Wi-Fi connection the

00:12:28,210 --> 00:12:31,780
operator can trigger checkerboard

00:12:29,920 --> 00:12:34,090
detections when pressing a button on the

00:12:31,780 --> 00:12:38,020
touchscreen and the result is then sent

00:12:34,090 --> 00:12:41,770
to result slots where they're where they

00:12:38,020 --> 00:12:43,750
can be inspected if we need a bigger

00:12:41,770 --> 00:12:46,060
trigger a bigger checker board for

00:12:43,750 --> 00:12:48,280
example it's also possible to use a

00:12:46,060 --> 00:12:49,690
really big one and to place a tablet on

00:12:48,280 --> 00:12:51,790
the backside it's just important that

00:12:49,690 --> 00:12:53,650
you would be able to press the trigger

00:12:51,790 --> 00:12:58,540
button because then you can do it on

00:12:53,650 --> 00:13:01,090
your own from the Ross graph behind this

00:12:58,540 --> 00:13:03,880
looking like this we have the camera

00:13:01,090 --> 00:13:06,040
publishing images we already also have a

00:13:03,880 --> 00:13:08,350
total station that can measure the 3d

00:13:06,040 --> 00:13:10,960
distance from our checker board to the

00:13:08,350 --> 00:13:12,580
car frame and/or calibration solution

00:13:10,960 --> 00:13:15,190
consisting of a calibration server

00:13:12,580 --> 00:13:17,740
running inside the car and the GUI

00:13:15,190 --> 00:13:20,500
running on the tablet the server

00:13:17,740 --> 00:13:20,980
subscribes the images or the image or

00:13:20,500 --> 00:13:24,040
images

00:13:20,980 --> 00:13:27,190
in case of a stereo system as well as a

00:13:24,040 --> 00:13:28,839
distance data an TF to allow life-image

00:13:27,190 --> 00:13:30,639
streaming to the tablet the server

00:13:28,839 --> 00:13:32,980
scales the image a little bit down and

00:13:30,639 --> 00:13:34,600
also publishes only with 8-bit depth

00:13:32,980 --> 00:13:37,300
while everything else is running with

00:13:34,600 --> 00:13:38,949
16-bit pixel depth and in case of a

00:13:37,300 --> 00:13:40,740
stereo camera both images are

00:13:38,949 --> 00:13:43,389
transferred side by side as one image

00:13:40,740 --> 00:13:45,430
the server also includes a number of

00:13:43,389 --> 00:13:47,470
services the on-demand checkerboard

00:13:45,430 --> 00:13:49,389
detection trigger the calibration

00:13:47,470 --> 00:13:51,730
trigger as well as services for deletion

00:13:49,389 --> 00:13:54,550
and detection and lord save

00:13:51,730 --> 00:13:57,040
functionalities this way we can do the

00:13:54,550 --> 00:13:59,139
calibration the conventional way but in

00:13:57,040 --> 00:14:00,970
more detail as we can call calibrate

00:13:59,139 --> 00:14:05,160
multiple times and each time get

00:14:00,970 --> 00:14:05,160
projection arrows for all single images

00:14:09,120 --> 00:14:15,910
okay three very quick slides regarding

00:14:12,699 --> 00:14:18,699
rostral enhancements in general a first

00:14:15,910 --> 00:14:21,040
example is time shift recording when we

00:14:18,699 --> 00:14:22,690
started to record traffic lights in

00:14:21,040 --> 00:14:25,180
urban environment we wanted to capture

00:14:22,690 --> 00:14:27,100
the traffic light approaching and in

00:14:25,180 --> 00:14:29,589
case of a halt in front of a red traffic

00:14:27,100 --> 00:14:30,990
light we want to skip the red face where

00:14:29,589 --> 00:14:33,790
the whole scene is more or less static

00:14:30,990 --> 00:14:36,100
but we wanted to capture the moment the

00:14:33,790 --> 00:14:38,680
traffic light switches its color state

00:14:36,100 --> 00:14:39,310
so we need to pause recording when the

00:14:38,680 --> 00:14:41,920
car stops

00:14:39,310 --> 00:14:44,709
but we need to resume before we see the

00:14:41,920 --> 00:14:46,870
change in the state our solution was to

00:14:44,709 --> 00:14:48,790
modify the back recorder that it

00:14:46,870 --> 00:14:51,959
continuously records into a ram buffer

00:14:48,790 --> 00:14:55,180
and exposes a recording trigger topic

00:14:51,959 --> 00:14:57,819
the operator can then request a start

00:14:55,180 --> 00:15:00,100
recording - sometime in the background

00:14:57,819 --> 00:15:02,410
and in the past sorry and as long as

00:15:00,100 --> 00:15:04,779
this path data is still available inside

00:15:02,410 --> 00:15:07,480
the potentially very big Ram buffer you

00:15:04,779 --> 00:15:09,839
can dump also scenes from the past to

00:15:07,480 --> 00:15:09,839
your disk

00:15:10,290 --> 00:15:15,699
we are working with recorded images a

00:15:12,880 --> 00:15:17,769
lot and therefore use respects and when

00:15:15,699 --> 00:15:18,910
recording datasets you sometimes make

00:15:17,769 --> 00:15:20,949
not everything correct

00:15:18,910 --> 00:15:23,170
you may either publish a wrong image

00:15:20,949 --> 00:15:25,300
encoding or you may decide to rename

00:15:23,170 --> 00:15:27,040
your frame IDs or you may want to add

00:15:25,300 --> 00:15:29,829
offline computer sensor data like

00:15:27,040 --> 00:15:31,839
disparity images later or you finish a

00:15:29,829 --> 00:15:32,680
labeling process and want to include the

00:15:31,839 --> 00:15:35,649
ground truth data

00:15:32,680 --> 00:15:38,559
at your back this are all real examples

00:15:35,649 --> 00:15:41,199
and we especially like in this case the

00:15:38,559 --> 00:15:44,410
respect Python module which which works

00:15:41,199 --> 00:15:49,660
just great for modifying and rewriting

00:15:44,410 --> 00:15:51,759
backs other powerful tools and packages

00:15:49,660 --> 00:15:54,399
are for example the not--let's package

00:15:51,759 --> 00:15:57,189
so we normally write only notelets and

00:15:54,399 --> 00:15:59,980
small note wrappers that we are able to

00:15:57,189 --> 00:16:03,670
use to make use of zero copy while also

00:15:59,980 --> 00:16:05,709
during creation of experimental software

00:16:03,670 --> 00:16:09,069
we can use them as notes and not the

00:16:05,709 --> 00:16:10,300
whole graph cursor graph trash and for

00:16:09,069 --> 00:16:13,660
example my whole traffic light

00:16:10,300 --> 00:16:15,759
recognition pipeline is is realized as

00:16:13,660 --> 00:16:17,980
several note LEDs and we always try to

00:16:15,759 --> 00:16:20,379
use raw standard messages or message

00:16:17,980 --> 00:16:21,610
packages that already exist and this way

00:16:20,379 --> 00:16:24,339
get a high grade of stretch

00:16:21,610 --> 00:16:26,439
exchangeability I'm personally also a

00:16:24,339 --> 00:16:29,499
big fan of the imagery of geometry

00:16:26,439 --> 00:16:32,529
package and use the 3d to 2d and 2d to

00:16:29,499 --> 00:16:34,959
3d projection it's quite a lot also we

00:16:32,529 --> 00:16:37,329
are big fans of TF as a central for our

00:16:34,959 --> 00:16:39,279
transformations and over the time we

00:16:37,329 --> 00:16:41,470
also set up detailed launch files in a

00:16:39,279 --> 00:16:43,389
special like that you can nest launch

00:16:41,470 --> 00:16:45,129
files inside other launch files and can

00:16:43,389 --> 00:16:47,980
use arguments in this context as well

00:16:45,129 --> 00:16:49,629
also the whole Diagnostics idea is great

00:16:47,980 --> 00:16:53,410
especially when you are working with the

00:16:49,629 --> 00:16:53,920
set up with thousands of nodes so to

00:16:53,410 --> 00:16:56,350
wrap it all up

00:16:53,920 --> 00:16:58,839
we think that Ross already includes the

00:16:56,350 --> 00:17:00,759
concepts concepts to realize complexity

00:16:58,839 --> 00:17:02,860
genius and the setups we like the

00:17:00,759 --> 00:17:05,740
capabilities of Ross for handling high

00:17:02,860 --> 00:17:08,409
data rates and cycle rates and if you

00:17:05,740 --> 00:17:11,339
need succeed well exceeds what rots

00:17:08,409 --> 00:17:13,689
comes with them just extend it and

00:17:11,339 --> 00:17:17,549
that's it thank you very much for your

00:17:13,689 --> 00:17:17,549
attention and I'm ready for questions

00:17:21,500 --> 00:17:25,350
all right we'll take questions from the

00:17:23,580 --> 00:17:28,890
audience this one here for your

00:17:25,350 --> 00:17:32,400
extrinsic calibration your node diagram

00:17:28,890 --> 00:17:34,860
showed a node called total s T so using

00:17:32,400 --> 00:17:37,200
a total station to track and develop the

00:17:34,860 --> 00:17:39,990
extrinsic calibration from that that's

00:17:37,200 --> 00:17:42,180
right I simplified this slide a little

00:17:39,990 --> 00:17:44,730
bit but we are using a total station and

00:17:42,180 --> 00:17:47,490
we do an initially measurement of the

00:17:44,730 --> 00:17:50,040
car frame so we measure the four wheels

00:17:47,490 --> 00:17:54,920
and then we get the car frame and then

00:17:50,040 --> 00:17:54,920
is the same run we calibrate all sensors

00:17:58,100 --> 00:18:04,470
so I just had a question regarding all

00:18:01,110 --> 00:18:05,970
your can Ross packages so one of the

00:18:04,470 --> 00:18:07,950
hardest things that I've that I

00:18:05,970 --> 00:18:09,480
encountered when just building any

00:18:07,950 --> 00:18:12,360
autonomous thing on my own using the

00:18:09,480 --> 00:18:14,340
canvas was the lack of availability of

00:18:12,360 --> 00:18:16,680
resources to do such a thing

00:18:14,340 --> 00:18:17,720
so do you guys have any plans ever to

00:18:16,680 --> 00:18:21,360
open source

00:18:17,720 --> 00:18:24,480
well actually the whole can bust

00:18:21,360 --> 00:18:26,850
messages is a big big big secret for the

00:18:24,480 --> 00:18:30,590
OEMs and we don't have any plans to

00:18:26,850 --> 00:18:33,570
release it you can anyway get the small

00:18:30,590 --> 00:18:36,990
subset like for example with the ODB

00:18:33,570 --> 00:18:39,750
standard open in Diagnostics bus I think

00:18:36,990 --> 00:18:41,640
exactly where you can get basic data but

00:18:39,750 --> 00:18:45,180
I don't think you will be able without

00:18:41,640 --> 00:18:52,110
signing an NDA with any big om2 to get

00:18:45,180 --> 00:18:55,110
anything else next one she's good time

00:18:52,110 --> 00:18:58,830
for one any plans to open source any

00:18:55,110 --> 00:19:01,080
other parts of that stack I would like

00:18:58,830 --> 00:19:02,700
to I would like to the problem is that

00:19:01,080 --> 00:19:04,950
we are not allowed to pass it

00:19:02,700 --> 00:19:07,170
participated with open source projects

00:19:04,950 --> 00:19:13,410
so the only thing giving something back

00:19:07,170 --> 00:19:14,550
is two presentations like this one all

00:19:13,410 --> 00:19:17,400
right we'll just take this one as well

00:19:14,550 --> 00:19:20,100
that was a quick one you mentioned that

00:19:17,400 --> 00:19:22,200
the image calibration does not do since

00:19:20,100 --> 00:19:23,610
at a car calibration but you didn't

00:19:22,200 --> 00:19:26,100
describe how you do that in your talk

00:19:23,610 --> 00:19:27,420
and what's the main part of your

00:19:26,100 --> 00:19:29,250
question and this is attack our

00:19:27,420 --> 00:19:29,720
calibration yes but not just calibrating

00:19:29,250 --> 00:19:31,639
cameras

00:19:29,720 --> 00:19:35,269
calibrating senses and depositions on

00:19:31,639 --> 00:19:40,580
the car sorry I not get it

00:19:35,269 --> 00:19:42,529
acoustically calibration so you want to

00:19:40,580 --> 00:19:45,919
have more details or what's the question

00:19:42,529 --> 00:19:48,139
yeah okay we have for example four

00:19:45,919 --> 00:19:49,850
cameras we have a checkerboard we have a

00:19:48,139 --> 00:19:51,980
reflector on the checkerboard that can

00:19:49,850 --> 00:19:54,529
be measured from the total station we

00:19:51,980 --> 00:19:56,570
initially calibrated the car so we know

00:19:54,529 --> 00:19:58,429
the transformation from the total

00:19:56,570 --> 00:20:00,500
station to the car reference system and

00:19:58,429 --> 00:20:03,139
we can measure the checkerboard so we

00:20:00,500 --> 00:20:04,370
have the 3d distance information and we

00:20:03,139 --> 00:20:06,950
can find the checkerboard

00:20:04,370 --> 00:20:08,690
inside the image using the checkerboard

00:20:06,950 --> 00:20:12,679
texture and so we can solve the problem

00:20:08,690 --> 00:20:15,519
okay thank you fantastic let's think

00:20:12,679 --> 00:20:15,519
andreas once more

00:20:15,760 --> 00:20:22,269

YouTube URL: https://www.youtube.com/watch?v=w42CRUHQeXo


