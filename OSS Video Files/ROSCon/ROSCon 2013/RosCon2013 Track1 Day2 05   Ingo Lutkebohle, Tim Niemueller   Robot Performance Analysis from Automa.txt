Title: RosCon2013 Track1 Day2 05   Ingo Lutkebohle, Tim Niemueller   Robot Performance Analysis from Automa
Publication date: 2014-09-02
Playlist: ROSCon 2013
Description: 
	Unaltered video by Open Robotics from http://roscon.ros.org/2013 under the Attribution-NonCommercial-NoDerivs 3.0 Unported (CC BY-NC-ND 3.0) License https://creativecommons.org/licenses/by-nc-nd/3.0/
Captions: 
	00:00:00,000 --> 00:00:05,490
so how come hello and we are going to

00:00:03,360 --> 00:00:07,140
talk about robot from silences and my

00:00:05,490 --> 00:00:08,880
part will be about the automatically

00:00:07,140 --> 00:00:12,809
recorded data that's the only reason why

00:00:08,880 --> 00:00:15,000
this is bold here so the overview of the

00:00:12,809 --> 00:00:17,369
first half is given motivation then

00:00:15,000 --> 00:00:19,770
describe why MongoDB is a good generic

00:00:17,369 --> 00:00:22,410
robot database and then mention two

00:00:19,770 --> 00:00:25,289
applications where we have used that so

00:00:22,410 --> 00:00:26,699
the long term goal that Ingo and I both

00:00:25,289 --> 00:00:29,580
agree on and that's why we working

00:00:26,699 --> 00:00:31,679
together mostly is we want to develop

00:00:29,580 --> 00:00:34,410
tools for generic performance analysis

00:00:31,679 --> 00:00:36,210
of the robot so currently the analysis

00:00:34,410 --> 00:00:37,680
is typically domain-specific so there

00:00:36,210 --> 00:00:39,390
are no widely used generic tools when

00:00:37,680 --> 00:00:42,030
you do it on a particular platform in a

00:00:39,390 --> 00:00:43,800
particular domain and another thing is

00:00:42,030 --> 00:00:46,140
that data types do not have any

00:00:43,800 --> 00:00:48,539
semantics at the moment it's just a type

00:00:46,140 --> 00:00:49,829
and so it's a number but not a distance

00:00:48,539 --> 00:00:52,649
value and that's something I think we'll

00:00:49,829 --> 00:00:54,480
talk about and then the little thing the

00:00:52,649 --> 00:00:56,789
next thing is that there's little

00:00:54,480 --> 00:00:58,109
cross-platform comparison so if you do

00:00:56,789 --> 00:01:00,180
your experiments on a pier to it's very

00:00:58,109 --> 00:01:02,640
hard to compare them to experiment done

00:01:00,180 --> 00:01:04,860
on any other platform or another task so

00:01:02,640 --> 00:01:06,360
this is the goal to develop the concepts

00:01:04,860 --> 00:01:09,990
and tools for these favorite white

00:01:06,360 --> 00:01:12,420
analysis the first part is so you have

00:01:09,990 --> 00:01:14,430
all seen similar pictures so that's just

00:01:12,420 --> 00:01:17,130
a point cloud taken somewhere in a lap

00:01:14,430 --> 00:01:19,049
of ours extract the table scene and then

00:01:17,130 --> 00:01:20,310
get the objects on the table that's

00:01:19,049 --> 00:01:22,259
something everybody is basically doing

00:01:20,310 --> 00:01:24,119
then there's another laser pointer here

00:01:22,259 --> 00:01:26,189
that's a verb and then you can also use

00:01:24,119 --> 00:01:29,909
that for example to find a little bottle

00:01:26,189 --> 00:01:31,500
on the on the table there and then

00:01:29,909 --> 00:01:33,000
there's another laser scanning that you

00:01:31,500 --> 00:01:35,189
use for collision avoidance but what all

00:01:33,000 --> 00:01:37,409
this data has in common that we acquired

00:01:35,189 --> 00:01:39,060
we use it for some time to make

00:01:37,409 --> 00:01:41,400
decisions on the actual current behavior

00:01:39,060 --> 00:01:44,640
but after what we just grab it and throw

00:01:41,400 --> 00:01:46,590
it away and that's actually waste of

00:01:44,640 --> 00:01:49,470
resources what we argue is there would

00:01:46,590 --> 00:01:51,540
be much better if we store most or some

00:01:49,470 --> 00:01:56,159
medley solve this data to a database so

00:01:51,540 --> 00:01:57,960
that we can use it later on so we have

00:01:56,159 --> 00:01:59,880
come up with some criteria and this is

00:01:57,960 --> 00:02:01,829
just an excerpt for a formal arrows

00:01:59,880 --> 00:02:04,439
paper so what we want to do is to be

00:02:01,829 --> 00:02:06,420
able to store any and all data and we

00:02:04,439 --> 00:02:09,360
want to do that in real time and the

00:02:06,420 --> 00:02:10,830
reason is we do not want to run into the

00:02:09,360 --> 00:02:12,239
situation that after what you say oh I

00:02:10,830 --> 00:02:13,510
should have locked this particular piece

00:02:12,239 --> 00:02:17,290
of data but now I cannot

00:02:13,510 --> 00:02:18,549
is what was going on and a criterion is

00:02:17,290 --> 00:02:20,680
that we want to have powerful an

00:02:18,549 --> 00:02:22,090
expressive retrieval features so that we

00:02:20,680 --> 00:02:24,010
can actually do something with the data

00:02:22,090 --> 00:02:25,840
after what's not just have it sitting on

00:02:24,010 --> 00:02:27,430
the hard drive and we want to integrate

00:02:25,840 --> 00:02:28,930
it with took the robot middleware here

00:02:27,430 --> 00:02:30,010
and pay particular it's Ross but we also

00:02:28,930 --> 00:02:32,500
have an integration with our own

00:02:30,010 --> 00:02:34,750
framework and we want to have minimal

00:02:32,500 --> 00:02:36,519
configuration that the student does not

00:02:34,750 --> 00:02:38,230
wanna walk up to you and say I know it

00:02:36,519 --> 00:02:40,810
was to pain the air so I didn't run your

00:02:38,230 --> 00:02:42,760
logging and better we cannot analyze so

00:02:40,810 --> 00:02:44,620
we determined that longer DB is a

00:02:42,760 --> 00:02:45,940
suitable candidate for doing this so

00:02:44,620 --> 00:02:48,640
it's a document-oriented schema-less

00:02:45,940 --> 00:02:50,500
database and i will tell you what this

00:02:48,640 --> 00:02:54,430
means in a minute and this was joined

00:02:50,500 --> 00:02:58,440
work with syd sreenivasa from CMU so

00:02:54,430 --> 00:03:01,000
document-oriented means that unlike

00:02:58,440 --> 00:03:04,120
sql-based databases we have group key

00:03:01,000 --> 00:03:06,159
value pairs in our database so on the

00:03:04,120 --> 00:03:08,620
right side here you see an example

00:03:06,159 --> 00:03:11,680
document and then you see and read the

00:03:08,620 --> 00:03:13,540
keys and then afterwards the data that's

00:03:11,680 --> 00:03:16,840
stored in these keys and all of this is

00:03:13,540 --> 00:03:18,430
embraced Jason like in these curly

00:03:16,840 --> 00:03:21,040
brackets that means that this is one

00:03:18,430 --> 00:03:22,660
document so it's ki minus so there's no

00:03:21,040 --> 00:03:24,489
declaration or enforcement of a

00:03:22,660 --> 00:03:26,949
particular structure by the database

00:03:24,489 --> 00:03:28,959
that sounds like chaos and havoc but

00:03:26,949 --> 00:03:30,099
it's not actually it's very useful in

00:03:28,959 --> 00:03:31,299
particular when coming to robot

00:03:30,099 --> 00:03:34,870
applications that i will show in a

00:03:31,299 --> 00:03:36,790
second but also the remedy parts of this

00:03:34,870 --> 00:03:38,709
confusion is that we have collections if

00:03:36,790 --> 00:03:41,560
you come form a relational database

00:03:38,709 --> 00:03:43,389
world it's kind of a table but not a

00:03:41,560 --> 00:03:45,220
real table what it means is that

00:03:43,389 --> 00:03:50,190
typically in one collection you saw or

00:03:45,220 --> 00:03:53,290
store similarly structured documents so

00:03:50,190 --> 00:03:55,569
in terms of Ross to meet some of the

00:03:53,290 --> 00:03:57,819
criteria and with the topic based

00:03:55,569 --> 00:03:59,500
peer-to-peer messaging and the ability

00:03:57,819 --> 00:04:01,090
to list all of the existing topics you

00:03:59,500 --> 00:04:02,500
can easily exploit these middle and

00:04:01,090 --> 00:04:05,109
features to knock any and all data

00:04:02,500 --> 00:04:07,629
without configuration so basically we

00:04:05,109 --> 00:04:09,729
only configure what we do not want to

00:04:07,629 --> 00:04:12,010
lock for example images in jpeg and raw

00:04:09,729 --> 00:04:14,530
we are usually only interested in one so

00:04:12,010 --> 00:04:18,070
this is what we use to get the minimal

00:04:14,530 --> 00:04:20,560
in particularly minimal criterion up and

00:04:18,070 --> 00:04:22,840
running so here's side by side on the

00:04:20,560 --> 00:04:24,070
left hand side you see the database

00:04:22,840 --> 00:04:27,130
document under earth

00:04:24,070 --> 00:04:28,690
a output of Ross topic echo of the

00:04:27,130 --> 00:04:30,400
transfer public on the right hand side

00:04:28,690 --> 00:04:31,690
you see them on would be documented and

00:04:30,400 --> 00:04:34,210
what you immediately see it is that

00:04:31,690 --> 00:04:35,590
there's almost no one-to-one relation

00:04:34,210 --> 00:04:37,360
between the two so that makes it

00:04:35,590 --> 00:04:41,200
particularly easy if we use that

00:04:37,360 --> 00:04:43,150
framework to transform incoming data any

00:04:41,200 --> 00:04:45,310
incoming to our data into MongoDB

00:04:43,150 --> 00:04:47,200
documents and what it also means is that

00:04:45,310 --> 00:04:49,030
we sustain development knowledge about

00:04:47,200 --> 00:04:51,130
the data structures that they use during

00:04:49,030 --> 00:04:54,750
the online system on and can now use it

00:04:51,130 --> 00:04:58,480
after the fact on the database so

00:04:54,750 --> 00:05:00,970
fairies are built in longwood eb using

00:04:58,480 --> 00:05:05,170
javascript base query language on the

00:05:00,970 --> 00:05:06,940
right hand side you see two queries the

00:05:05,170 --> 00:05:08,650
upper one is there's a collector spoon

00:05:06,940 --> 00:05:10,540
called behavior in which we store

00:05:08,650 --> 00:05:13,450
information about executed behavior and

00:05:10,540 --> 00:05:15,490
this particular query gives us the

00:05:13,450 --> 00:05:17,650
document that describes the execution of

00:05:15,490 --> 00:05:19,780
grabbing a bottle the last time when it

00:05:17,650 --> 00:05:22,900
failed so that easily allows us to get

00:05:19,780 --> 00:05:25,840
the time frame for example of the failed

00:05:22,900 --> 00:05:28,240
execution and later on like in this one

00:05:25,840 --> 00:05:29,710
we can use the start and end time that

00:05:28,240 --> 00:05:32,380
we have to turn in the first query to

00:05:29,710 --> 00:05:34,030
get all the data thats related to that

00:05:32,380 --> 00:05:37,930
time period where we were executing the

00:05:34,030 --> 00:05:39,760
behavior so you select based on document

00:05:37,930 --> 00:05:42,460
fields you can carry into sub documents

00:05:39,760 --> 00:05:44,860
as you see here and it also supports

00:05:42,460 --> 00:05:46,120
nicely the MapReduce paradigm and there

00:05:44,860 --> 00:05:48,190
won't be an example on this one but

00:05:46,120 --> 00:05:50,950
there's one in the paper so if you're

00:05:48,190 --> 00:05:54,420
interested it's there so we have been

00:05:50,950 --> 00:05:58,150
doing some experiments on the pier tool

00:05:54,420 --> 00:05:59,680
and herb and virtuous well known herb is

00:05:58,150 --> 00:06:02,980
this guy on the right it's the robot and

00:05:59,680 --> 00:06:05,230
seeing you and we also did synthetic

00:06:02,980 --> 00:06:07,000
recording benchmarks where we just took

00:06:05,230 --> 00:06:08,860
the transform topic because it's

00:06:07,000 --> 00:06:10,540
basically the one which transmits most

00:06:08,860 --> 00:06:12,820
of the messages and just send it a

00:06:10,540 --> 00:06:16,180
hundred Hertz which is already quite low

00:06:12,820 --> 00:06:18,550
and we have two kinds of loggers one is

00:06:16,180 --> 00:06:21,850
a C++ based blogger and one is Python

00:06:18,550 --> 00:06:23,620
and the Python logger is able to

00:06:21,850 --> 00:06:26,320
generically take any kind of message

00:06:23,620 --> 00:06:29,260
parse it and put it in your document the

00:06:26,320 --> 00:06:32,169
back side is that the Pisan decoding of

00:06:29,260 --> 00:06:32,840
ross messages is awfully slow it's not

00:06:32,169 --> 00:06:34,669
about

00:06:32,840 --> 00:06:37,310
hyphen or about Ross but it's about the

00:06:34,669 --> 00:06:39,500
crossing from the sea and Python world

00:06:37,310 --> 00:06:42,440
in the decoding process so we have the

00:06:39,500 --> 00:06:44,389
same problem in rossville for example so

00:06:42,440 --> 00:06:45,889
that's why we want to have C++ based

00:06:44,389 --> 00:06:47,870
orders but then comes another problem

00:06:45,889 --> 00:06:51,139
with ross's that it does not support any

00:06:47,870 --> 00:06:53,240
kind of message reflection in the c++

00:06:51,139 --> 00:06:56,620
program so we cannot build a generic

00:06:53,240 --> 00:07:00,290
logger in C++ so what we did is we

00:06:56,620 --> 00:07:02,060
identified the most transmitted messages

00:07:00,290 --> 00:07:04,660
in our system either the ones which are

00:07:02,060 --> 00:07:07,460
sent most frequent or the ones which are

00:07:04,660 --> 00:07:08,720
largest in size and brought specifics if

00:07:07,460 --> 00:07:11,240
that's nice luggage which are a

00:07:08,720 --> 00:07:12,860
magnitude of auto magnitude faster than

00:07:11,240 --> 00:07:19,040
the Python blogger for these specific

00:07:12,860 --> 00:07:21,020
traffic topics so at the moment and we

00:07:19,040 --> 00:07:25,070
discussed this before so that it's kind

00:07:21,020 --> 00:07:27,380
of an attack in the in rows back is that

00:07:25,070 --> 00:07:30,229
Ross black is even slower than the

00:07:27,380 --> 00:07:32,090
MongoDB logging that's because Ross back

00:07:30,229 --> 00:07:33,889
currently stores stores with each

00:07:32,090 --> 00:07:35,240
message it gets and needs a store into

00:07:33,889 --> 00:07:37,880
the file also the full message

00:07:35,240 --> 00:07:39,770
description into the file and that's why

00:07:37,880 --> 00:07:41,419
what would it be logging which doesn't

00:07:39,770 --> 00:07:45,530
do that it's more efficient and even

00:07:41,419 --> 00:07:47,840
faster at the moment so the echo main

00:07:45,530 --> 00:07:49,310
message from this is the starting robert

00:07:47,840 --> 00:07:51,800
runtime data to our database is

00:07:49,310 --> 00:07:52,970
efficient and suitable and it enables

00:07:51,800 --> 00:07:54,200
interesting your applications i will

00:07:52,970 --> 00:07:58,220
show you a little bit about the

00:07:54,200 --> 00:07:59,720
applications and coming out but mongodb

00:07:58,220 --> 00:08:01,490
locking or logging in general to a

00:07:59,720 --> 00:08:04,580
database of the data that you're always

00:08:01,490 --> 00:08:06,410
producing it is not as expensive as most

00:08:04,580 --> 00:08:08,750
people are thinking and you should

00:08:06,410 --> 00:08:10,820
really try it out so there are two

00:08:08,750 --> 00:08:12,770
applications the one the first one is

00:08:10,820 --> 00:08:15,110
joint work with nikola updos also

00:08:12,770 --> 00:08:19,010
sitting here somewhere and guys had lab

00:08:15,110 --> 00:08:21,740
or neighbor and both uncle grant from

00:08:19,010 --> 00:08:23,720
Freiburg University so the task was to

00:08:21,740 --> 00:08:25,940
identify cups on the table so the

00:08:23,720 --> 00:08:28,669
classic tabletop scene is just a mock-up

00:08:25,940 --> 00:08:32,000
scenario to get the basic things going

00:08:28,669 --> 00:08:34,610
so um here you see the scenario as its

00:08:32,000 --> 00:08:37,520
set up and here you see the map and the

00:08:34,610 --> 00:08:39,349
blue spots is our observation points if

00:08:37,520 --> 00:08:42,650
the robot will visit one after another

00:08:39,349 --> 00:08:45,220
and during the full operation of the

00:08:42,650 --> 00:08:47,500
robot it's recording all

00:08:45,220 --> 00:08:51,550
data image data and transform so the

00:08:47,500 --> 00:08:53,350
database and the reason why we do this

00:08:51,550 --> 00:08:55,269
is that ultimately we want the robot to

00:08:53,350 --> 00:08:57,670
be able to figure out by itself where to

00:08:55,269 --> 00:09:00,579
go and from where to look and why we do

00:08:57,670 --> 00:09:02,709
this is to fill delusions and shadows in

00:09:00,579 --> 00:09:05,319
our perception from multiple

00:09:02,709 --> 00:09:08,170
perspectives because otherwise we can

00:09:05,319 --> 00:09:10,180
never analyze the full scene so and then

00:09:08,170 --> 00:09:12,009
afterwards after we have gathered all

00:09:10,180 --> 00:09:14,470
the data in a database we go back to the

00:09:12,009 --> 00:09:16,269
specific time stems extract the data

00:09:14,470 --> 00:09:17,709
from the database realign the point

00:09:16,269 --> 00:09:20,500
clouds and run the perception pipeline

00:09:17,709 --> 00:09:23,379
on the full merge point outs so this is

00:09:20,500 --> 00:09:26,050
an example of reconstruction emerging

00:09:23,379 --> 00:09:29,949
point loads from a database online ad

00:09:26,050 --> 00:09:31,899
runtime for perception so that's the

00:09:29,949 --> 00:09:34,300
first thing that's when you just get the

00:09:31,899 --> 00:09:37,000
point loads from the database they look

00:09:34,300 --> 00:09:39,129
like junk but once you did do a first

00:09:37,000 --> 00:09:41,079
initial alignment based on the mcl

00:09:39,129 --> 00:09:43,870
localization that the robot have you

00:09:41,079 --> 00:09:45,250
already get a somewhat good estimate and

00:09:43,870 --> 00:09:48,670
then we do with some additional

00:09:45,250 --> 00:09:51,309
alignment steps so first we bias our

00:09:48,670 --> 00:09:52,980
perception and filter out the data that

00:09:51,309 --> 00:09:55,899
we're not interested in down sample it

00:09:52,980 --> 00:09:57,879
then do ICP it for the first alignment

00:09:55,899 --> 00:10:01,000
which mostly aligns it by the table

00:09:57,879 --> 00:10:02,529
planes then remove the table plane to

00:10:01,000 --> 00:10:04,329
buy it more by the objects that are

00:10:02,529 --> 00:10:06,189
interested in and then we get the full

00:10:04,329 --> 00:10:08,230
merged point loud and that's a top view

00:10:06,189 --> 00:10:10,600
of that and here you can also see why we

00:10:08,230 --> 00:10:13,990
need to do this so you see these shadows

00:10:10,600 --> 00:10:15,759
here these you cannot fill unless you

00:10:13,990 --> 00:10:18,819
look from multiple perspectives on the

00:10:15,759 --> 00:10:27,189
data so there's a little video and I

00:10:18,819 --> 00:10:29,410
will quickly skim through this so this

00:10:27,189 --> 00:10:31,569
is a robot on the left hand side you see

00:10:29,410 --> 00:10:34,240
the arvest you on the upper right hand

00:10:31,569 --> 00:10:36,430
side you see an objective observer the

00:10:34,240 --> 00:10:38,649
camera on the outside and then here you

00:10:36,430 --> 00:10:41,290
see every now and then updated the image

00:10:38,649 --> 00:10:42,879
from the robot so and now it took the

00:10:41,290 --> 00:10:44,589
first part i ran the perception above

00:10:42,879 --> 00:10:46,029
you already see is that it mislabeled

00:10:44,589 --> 00:10:48,970
some of the objects so we're looking at

00:10:46,029 --> 00:10:50,290
mid size cups so the big cylindrical

00:10:48,970 --> 00:10:51,910
thing here should actually not be

00:10:50,290 --> 00:10:54,220
detected and the boxes should also be

00:10:51,910 --> 00:10:56,559
protective so let me click forward a

00:10:54,220 --> 00:10:57,450
little bit through it so it will now go

00:10:56,559 --> 00:11:02,529
around

00:10:57,450 --> 00:11:04,090
and that doesn't work okay it's going

00:11:02,529 --> 00:11:06,640
around the table taking data from

00:11:04,090 --> 00:11:08,470
different perspectives marching as it

00:11:06,640 --> 00:11:11,860
goes that's just for visualization and

00:11:08,470 --> 00:11:13,660
ultimately in the end it has acquired

00:11:11,860 --> 00:11:15,700
all the data it needs and it's able to

00:11:13,660 --> 00:11:17,230
correctly label all of the objects which

00:11:15,700 --> 00:11:20,170
are in the scene which it wasn't able

00:11:17,230 --> 00:11:22,089
until before the last scan that it took

00:11:20,170 --> 00:11:26,279
and it wouldn't be able to it would just

00:11:22,089 --> 00:11:28,930
think that our skin as well so there's

00:11:26,279 --> 00:11:31,060
nothing a little more yeah so here you

00:11:28,930 --> 00:11:33,910
can see that the objects are not

00:11:31,060 --> 00:11:36,100
correctly classified so this was the

00:11:33,910 --> 00:11:37,990
first example for online usage and

00:11:36,100 --> 00:11:39,490
here's another example where we apply

00:11:37,990 --> 00:11:41,620
the database for post-mortem for

00:11:39,490 --> 00:11:43,390
analysis on the recorded data and that's

00:11:41,620 --> 00:11:45,040
an example how we can use the data

00:11:43,390 --> 00:11:47,380
offline that was with the student online

00:11:45,040 --> 00:11:50,200
by Stan king and profits again like a

00:11:47,380 --> 00:11:52,120
maior University so what we want to do

00:11:50,200 --> 00:11:54,010
is the robot is grass from the cup and

00:11:52,120 --> 00:11:56,020
it misses the cut by a few centimeters

00:11:54,010 --> 00:11:58,240
and why is it doing that and we want to

00:11:56,020 --> 00:12:01,780
analyze that so again we record all the

00:11:58,240 --> 00:12:03,610
data all the time and on thought we

00:12:01,780 --> 00:12:05,950
interrupt the system and now we go and

00:12:03,610 --> 00:12:07,839
look at the data and what we do is we

00:12:05,950 --> 00:12:09,730
restore the data in the simulation

00:12:07,839 --> 00:12:13,360
environment so that's gazebo now and

00:12:09,730 --> 00:12:14,920
then see the scene in the simulator from

00:12:13,360 --> 00:12:17,110
the perspective of the robot so we get

00:12:14,920 --> 00:12:20,170
the actual perception data off the robot

00:12:17,110 --> 00:12:22,300
that it had at that time so it's also a

00:12:20,170 --> 00:12:24,520
little video so the shakey's on the

00:12:22,300 --> 00:12:26,830
right hand side you see they the

00:12:24,520 --> 00:12:28,630
objective camera on the outside little

00:12:26,830 --> 00:12:31,690
delayed and the left hand side you see

00:12:28,630 --> 00:12:33,820
the reconstruction of this data in the

00:12:31,690 --> 00:12:35,800
simulation and you already see the table

00:12:33,820 --> 00:12:38,230
shaking sometimes doesn't detect the

00:12:35,800 --> 00:12:39,490
table at all there are only two objects

00:12:38,230 --> 00:12:41,290
at the moment now there are three and

00:12:39,490 --> 00:12:43,060
eventually what turned up here we have

00:12:41,290 --> 00:12:45,760
some tool support to guide you through

00:12:43,060 --> 00:12:48,430
the search of all your data and that led

00:12:45,760 --> 00:12:49,810
to discover that one mound of a camera

00:12:48,430 --> 00:12:51,370
had shifted slightly and then you

00:12:49,810 --> 00:12:52,959
couldn't detect it anymore properly so

00:12:51,370 --> 00:12:54,850
it was just a static transform problem

00:12:52,959 --> 00:12:56,650
not the first thing you would look into

00:12:54,850 --> 00:12:58,600
when you look for that error by so you

00:12:56,650 --> 00:13:02,529
probably go and try to tune your

00:12:58,600 --> 00:13:05,140
perception first okay I think that

00:13:02,529 --> 00:13:09,180
concludes my part of the top and now I

00:13:05,140 --> 00:13:09,180
hand over training

00:13:15,540 --> 00:13:24,339
check it has a usual okay thanks so okay

00:13:21,930 --> 00:13:25,839
so we'll check questions afterwards I

00:13:24,339 --> 00:13:29,350
guess seeing that the team has already

00:13:25,839 --> 00:13:33,700
left all right so in a sense that was

00:13:29,350 --> 00:13:35,140
the easy part and it's a very nice easy

00:13:33,700 --> 00:13:36,880
part you can get lots of nice

00:13:35,140 --> 00:13:38,950
applications by logging data that like

00:13:36,880 --> 00:13:41,399
that but what I will be talking about

00:13:38,950 --> 00:13:46,810
now is the multi source data acquisition

00:13:41,399 --> 00:13:49,510
part and first of all why do we would we

00:13:46,810 --> 00:13:52,480
need this and what we're looking at here

00:13:49,510 --> 00:13:55,060
is what we want to enable you to do as

00:13:52,480 --> 00:13:56,860
if you look at like things such as we're

00:13:55,060 --> 00:13:59,290
about fuel trials for example I have

00:13:56,860 --> 00:14:01,300
this image here this is a map and

00:13:59,290 --> 00:14:03,550
there's multiple robots driving around

00:14:01,300 --> 00:14:05,740
on a map to communicate and you want to

00:14:03,550 --> 00:14:08,050
analyze that window afterwards or you

00:14:05,740 --> 00:14:10,420
have human robot tests or you have

00:14:08,050 --> 00:14:13,420
continues lab tests in all of these

00:14:10,420 --> 00:14:15,850
situations you don't need just the data

00:14:13,420 --> 00:14:19,510
that the robot has available internally

00:14:15,850 --> 00:14:23,890
but you need also external environment

00:14:19,510 --> 00:14:26,170
data may be recording of the user may be

00:14:23,890 --> 00:14:29,970
white wine sensors on the environment

00:14:26,170 --> 00:14:32,740
the terrains things such as that and

00:14:29,970 --> 00:14:34,420
what we are particularly looking at at

00:14:32,740 --> 00:14:35,920
first of course with this sort of data

00:14:34,420 --> 00:14:38,949
you could do lots of things but we're

00:14:35,920 --> 00:14:42,880
looking at it versus some sort of robot

00:14:38,949 --> 00:14:44,680
profiler and I use this term profiling

00:14:42,880 --> 00:14:47,980
because it's like a performance profiler

00:14:44,680 --> 00:14:50,470
it doesn't necessarily tell you why your

00:14:47,980 --> 00:14:52,720
code is has a certain speed but it tells

00:14:50,470 --> 00:14:55,540
you what you look more closely and this

00:14:52,720 --> 00:14:58,570
is what we also want to do for things

00:14:55,540 --> 00:15:00,459
such as these large data sets where are

00:14:58,570 --> 00:15:02,949
the problem situated how severe our

00:15:00,459 --> 00:15:04,510
problems and also how does the internal

00:15:02,949 --> 00:15:07,870
view of the robot correspond to the

00:15:04,510 --> 00:15:11,110
external one as we saw earlier and so to

00:15:07,870 --> 00:15:13,089
give you sort of sneak preview of what

00:15:11,110 --> 00:15:15,040
we are headed with this what kind of

00:15:13,089 --> 00:15:17,589
inspection we want you to do able to do

00:15:15,040 --> 00:15:19,540
is a look at this tool here what you

00:15:17,589 --> 00:15:20,960
have for us you have multiple camera

00:15:19,540 --> 00:15:23,510
views this is the camera

00:15:20,960 --> 00:15:25,490
if the robot is another camera on the

00:15:23,510 --> 00:15:28,250
robot here we have an outside camera

00:15:25,490 --> 00:15:31,610
looking down and down below here we have

00:15:28,250 --> 00:15:33,710
various tiers recording various data

00:15:31,610 --> 00:15:36,770
sources of the robot and their current

00:15:33,710 --> 00:15:40,900
values we also have some audio data here

00:15:36,770 --> 00:15:43,670
and this sort of generic high-level view

00:15:40,900 --> 00:15:45,560
it's hard to get his current tools and I

00:15:43,670 --> 00:15:49,550
would like to explain a little bit more

00:15:45,560 --> 00:15:53,330
about how you can get it so for this

00:15:49,550 --> 00:15:54,770
sort of view of your robots performance

00:15:53,330 --> 00:15:57,440
what you need is first of all you need

00:15:54,770 --> 00:15:59,810
to capture various data sources and then

00:15:57,440 --> 00:16:02,900
you need to associate that data so that

00:15:59,810 --> 00:16:05,810
you know which which of it belongs

00:16:02,900 --> 00:16:08,150
together and that the easiest method for

00:16:05,810 --> 00:16:09,980
that is temporal overlap so if you have

00:16:08,150 --> 00:16:11,780
a camera view and you know it is a

00:16:09,980 --> 00:16:13,460
certain time and you have to data from

00:16:11,780 --> 00:16:15,260
your overt and it's a certain time than

00:16:13,460 --> 00:16:17,420
it matches there are other more

00:16:15,260 --> 00:16:19,520
complicated methods for association

00:16:17,420 --> 00:16:21,380
whether that's not to focus then

00:16:19,520 --> 00:16:24,200
particularly if you're looking at

00:16:21,380 --> 00:16:26,360
recording data for days or weeks you

00:16:24,200 --> 00:16:28,430
need to verify completeness so that

00:16:26,360 --> 00:16:31,550
you're sure yet to get you don't have

00:16:28,430 --> 00:16:33,650
any holes and then the first step is

00:16:31,550 --> 00:16:36,770
usually visualization of your data and

00:16:33,650 --> 00:16:40,010
that can already take some preparation

00:16:36,770 --> 00:16:43,670
and conversion and you also also usually

00:16:40,010 --> 00:16:46,100
need annotations to provide ground truth

00:16:43,670 --> 00:16:48,200
for example of what actually happened as

00:16:46,100 --> 00:16:50,810
opposed to what the robot thought it had

00:16:48,200 --> 00:16:53,630
happened and then at the end you would

00:16:50,810 --> 00:16:57,560
like maybe to compute some metrics using

00:16:53,630 --> 00:16:59,960
a database or so and what we are using

00:16:57,560 --> 00:17:02,870
for this purpose and what's quite

00:16:59,960 --> 00:17:04,910
interesting tool is called Elan it's

00:17:02,870 --> 00:17:08,150
usually developed by the gods originally

00:17:04,910 --> 00:17:10,190
developed by linguists and you might

00:17:08,150 --> 00:17:13,339
wonder we have all these nice

00:17:10,190 --> 00:17:14,690
visualization tools and we're already so

00:17:13,339 --> 00:17:17,390
what's the point of having another one

00:17:14,690 --> 00:17:20,540
this one is not for just display it's

00:17:17,390 --> 00:17:24,080
for editing so it's for annotation of

00:17:20,540 --> 00:17:25,940
the data and has very nice annotation

00:17:24,080 --> 00:17:26,530
and also time syncing tools are

00:17:25,940 --> 00:17:28,990
available

00:17:26,530 --> 00:17:30,610
on that of course you could use other

00:17:28,990 --> 00:17:32,590
tools most of what I will be talking

00:17:30,610 --> 00:17:35,440
about is applicable to other tools but

00:17:32,590 --> 00:17:37,990
this is one that we use and one of the

00:17:35,440 --> 00:17:41,850
advantages is has a very nice open data

00:17:37,990 --> 00:17:45,670
format that you can easily generate into

00:17:41,850 --> 00:17:47,260
ok and you might also ask yourselves why

00:17:45,670 --> 00:17:50,410
don't we just use Ross back for

00:17:47,260 --> 00:17:53,380
recording well apart from the fact that

00:17:50,410 --> 00:17:56,470
Ross back cannot record external data

00:17:53,380 --> 00:17:59,470
sources it's really only intended for

00:17:56,470 --> 00:18:02,080
message data so if you really want to

00:17:59,470 --> 00:18:06,730
record audio video data it's it's not

00:18:02,080 --> 00:18:08,590
the most efficient storage format and so

00:18:06,730 --> 00:18:10,420
and usually also if you have something

00:18:08,590 --> 00:18:11,950
in the back and you want to analyze it

00:18:10,420 --> 00:18:13,480
you have to convert take it out again

00:18:11,950 --> 00:18:16,680
and then convert it into some other

00:18:13,480 --> 00:18:19,030
analysis from it so why don't why not

00:18:16,680 --> 00:18:22,690
record it directly to something that is

00:18:19,030 --> 00:18:25,660
easier to analyze of course what I'm

00:18:22,690 --> 00:18:27,850
will be so Ross back is still the tool

00:18:25,660 --> 00:18:29,800
to use for message logging I'm just

00:18:27,850 --> 00:18:32,530
saying that there are also other tools

00:18:29,800 --> 00:18:35,980
and so to support this sort of an a

00:18:32,530 --> 00:18:39,100
logging what we wrote is called metal

00:18:35,980 --> 00:18:40,690
logo robot metal logo rml it's in

00:18:39,100 --> 00:18:43,870
Brittany pizen it's a data capture

00:18:40,690 --> 00:18:46,870
framework and it just calls lots of

00:18:43,870 --> 00:18:50,200
different capture tools that's simple

00:18:46,870 --> 00:18:51,940
but it makes your life easier and one of

00:18:50,200 --> 00:18:55,210
the thing is it stores the data in the

00:18:51,940 --> 00:18:56,830
native format so for a middle back

00:18:55,210 --> 00:18:59,340
capture from Ross the native form it

00:18:56,830 --> 00:19:02,920
might be Ross back or it might be Tim's

00:18:59,340 --> 00:19:04,990
MongoDB logging tool for screen capture

00:19:02,920 --> 00:19:06,730
if you like want to record tell

00:19:04,990 --> 00:19:10,180
operation or something you would record

00:19:06,730 --> 00:19:13,240
a video file and it has various camera

00:19:10,180 --> 00:19:15,960
supports actually in there so for

00:19:13,240 --> 00:19:18,210
example you can use network cameras and

00:19:15,960 --> 00:19:21,130
one other thing it does for you is

00:19:18,210 --> 00:19:23,560
manager sessions so if you have an

00:19:21,130 --> 00:19:25,420
experiment usually usually for example

00:19:23,560 --> 00:19:27,760
have one test chopped subject that would

00:19:25,420 --> 00:19:30,190
be one session you want to distinguish

00:19:27,760 --> 00:19:32,110
test subjects from each other and within

00:19:30,190 --> 00:19:34,180
one test subject you might have

00:19:32,110 --> 00:19:36,400
different runs maybe the first one

00:19:34,180 --> 00:19:38,020
didn't work you try another one you want

00:19:36,400 --> 00:19:41,530
to separate those out

00:19:38,020 --> 00:19:43,570
and what we often saw before using a

00:19:41,530 --> 00:19:45,760
framework like this was that to set the

00:19:43,570 --> 00:19:48,370
second run with over right data from the

00:19:45,760 --> 00:19:50,860
first run so r ml manager set for you

00:19:48,370 --> 00:19:56,440
and then it also asked conversion to its

00:19:50,860 --> 00:19:59,470
various other things and one one thing

00:19:56,440 --> 00:20:01,450
if you use like a tool I caramel or your

00:19:59,470 --> 00:20:03,340
other homegrown capture tool I don't

00:20:01,450 --> 00:20:06,460
know one of the things is really

00:20:03,340 --> 00:20:08,230
important is setting up your sources if

00:20:06,460 --> 00:20:10,630
you want to associate your resources

00:20:08,230 --> 00:20:13,000
afterwards you need consistent

00:20:10,630 --> 00:20:16,360
timestamps if you want to do temporarily

00:20:13,000 --> 00:20:20,620
based Association but that's not usually

00:20:16,360 --> 00:20:22,240
a given you know all like pcs if you

00:20:20,620 --> 00:20:24,070
don't synchronize them they all have

00:20:22,240 --> 00:20:25,930
their different clocks and what we're

00:20:24,070 --> 00:20:29,140
really aiming for here is millisecond

00:20:25,930 --> 00:20:31,690
accuracy it's not it's not a second is

00:20:29,140 --> 00:20:33,520
not enough in a second a lot of things

00:20:31,690 --> 00:20:37,000
happen in a second so we really need

00:20:33,520 --> 00:20:39,640
more accuracy than that and i just want

00:20:37,000 --> 00:20:40,960
to point out to some tools you can use

00:20:39,640 --> 00:20:42,910
for that for example network time

00:20:40,960 --> 00:20:45,130
protocol it's probably known to many

00:20:42,910 --> 00:20:47,290
here but its lesser known is that

00:20:45,130 --> 00:20:50,250
there's also a very end of that called a

00:20:47,290 --> 00:20:52,690
simple network time protocol and it's

00:20:50,250 --> 00:20:56,320
usable on embedded devices for example

00:20:52,690 --> 00:20:57,970
if they are network connected and then

00:20:56,320 --> 00:21:02,140
you have things such as non

00:20:57,970 --> 00:21:04,360
network-connected cameras there we found

00:21:02,140 --> 00:21:06,400
a simple expedient of taking a picture

00:21:04,360 --> 00:21:08,590
of a sub-millisecond clock and then you

00:21:06,400 --> 00:21:11,020
have the offset we can associate it

00:21:08,590 --> 00:21:13,540
afterwards if you have network cameras

00:21:11,020 --> 00:21:16,300
network cameras usually use real-time

00:21:13,540 --> 00:21:19,900
transport protocol which also has NT

00:21:16,300 --> 00:21:21,880
piece x times imp embedded but not all

00:21:19,900 --> 00:21:25,230
of the recording tools capture that time

00:21:21,880 --> 00:21:27,550
Sam so you need to use one that does and

00:21:25,230 --> 00:21:32,080
maybe one thing if you have such a

00:21:27,550 --> 00:21:34,810
things such as a waypoint sensor many of

00:21:32,080 --> 00:21:36,820
these do some internal logging but don't

00:21:34,810 --> 00:21:39,580
include timestamps so if you were at

00:21:36,820 --> 00:21:43,300
suffer for that include time stands so

00:21:39,580 --> 00:21:45,790
that's just preparation and one other

00:21:43,300 --> 00:21:48,820
thing to note on time stamps is that

00:21:45,790 --> 00:21:50,110
it's not the time when it is in your

00:21:48,820 --> 00:21:53,140
application that

00:21:50,110 --> 00:21:54,910
and I just put up here a little

00:21:53,140 --> 00:21:57,910
calculation for you if you look at the

00:21:54,910 --> 00:21:59,980
camera so something happens in the real

00:21:57,910 --> 00:22:02,950
world and then the camera takes an image

00:21:59,980 --> 00:22:05,290
and so the same thing of the image can

00:22:02,950 --> 00:22:07,929
already take up to 10 milliseconds

00:22:05,290 --> 00:22:10,120
depending on exposure time then there's

00:22:07,929 --> 00:22:13,720
usually some processing and then the

00:22:10,120 --> 00:22:17,770
sense data is transmitted to the PC that

00:22:13,720 --> 00:22:22,090
all ready for a 640 by 480 image in y UV

00:22:17,770 --> 00:22:24,549
420 that takes 15 milliseconds and then

00:22:22,090 --> 00:22:28,720
application isn't processing so what

00:22:24,549 --> 00:22:31,630
what you get when you have the image in

00:22:28,720 --> 00:22:37,360
your application it's already between 20

00:22:31,630 --> 00:22:39,880
and 40 milliseconds later than the than

00:22:37,360 --> 00:22:42,640
when it happened and if you take larger

00:22:39,880 --> 00:22:45,490
image it is it's like 5 megapixel images

00:22:42,640 --> 00:22:47,230
then transport takes longer of course if

00:22:45,490 --> 00:22:49,000
you have a different bus system then the

00:22:47,230 --> 00:22:51,790
transport may be faster but you know the

00:22:49,000 --> 00:22:54,100
point to take away here is that you

00:22:51,790 --> 00:22:56,860
really need to get at the time stem from

00:22:54,100 --> 00:22:59,049
the sensory source many cameras support

00:22:56,860 --> 00:23:00,549
this they can embed a timestamp of when

00:22:59,049 --> 00:23:02,860
the same thing actually happened but you

00:23:00,549 --> 00:23:07,090
can try to compute it this is just you

00:23:02,860 --> 00:23:09,580
know for Association and if if you end

00:23:07,090 --> 00:23:12,150
up with data which is not temporarily

00:23:09,580 --> 00:23:14,620
synchronized there's a few few

00:23:12,150 --> 00:23:16,720
heuristics that you can do in our they

00:23:14,620 --> 00:23:19,720
all boil down to finding a common event

00:23:16,720 --> 00:23:23,770
in an event that is observed across

00:23:19,720 --> 00:23:26,830
sensors and for example if in camera

00:23:23,770 --> 00:23:30,130
images usually use a clapper or you can

00:23:26,830 --> 00:23:32,140
also use a flash and if you have audio

00:23:30,130 --> 00:23:33,700
data you can also do correlation if you

00:23:32,140 --> 00:23:35,320
have all the data for multiple cameras

00:23:33,700 --> 00:23:38,200
you can correlate the audio streams

00:23:35,320 --> 00:23:39,730
that's a very accurate method and so

00:23:38,200 --> 00:23:42,160
what I want to point out here is try to

00:23:39,730 --> 00:23:44,559
record such data which you might not

00:23:42,160 --> 00:23:46,809
actually need for your analysis but

00:23:44,559 --> 00:23:50,380
which helps you to actually associate it

00:23:46,809 --> 00:23:52,480
later so an 11 point thing I want to

00:23:50,380 --> 00:23:55,059
point out shortly here is that for

00:23:52,480 --> 00:23:57,940
recording of audio video data network

00:23:55,059 --> 00:24:01,059
cameras are quite useful into the output

00:23:57,940 --> 00:24:03,200
compressed data stream which is not as

00:24:01,059 --> 00:24:05,029
good as a vision camera but it's

00:24:03,200 --> 00:24:07,220
it's fellow cpu-intensive to do

00:24:05,029 --> 00:24:09,350
compression and so it's quite useful to

00:24:07,220 --> 00:24:11,299
have another one of these cameras just

00:24:09,350 --> 00:24:13,070
you know observing the scene outputting

00:24:11,299 --> 00:24:17,600
a readily compressed stream that you can

00:24:13,070 --> 00:24:20,450
work quite fully and we as a short black

00:24:17,600 --> 00:24:25,039
we found basler systems makes very high

00:24:20,450 --> 00:24:26,960
quality network cameras so this is all

00:24:25,039 --> 00:24:30,559
about you know getting data what do we

00:24:26,960 --> 00:24:32,779
do with it when we have it and if you

00:24:30,559 --> 00:24:34,700
look at the typical data data analysis

00:24:32,779 --> 00:24:37,159
process first you capture it then you

00:24:34,700 --> 00:24:39,440
have to do some preparation extract the

00:24:37,159 --> 00:24:43,669
data you want an end run some metrics so

00:24:39,440 --> 00:24:48,919
easy right well this preparation step

00:24:43,669 --> 00:24:50,539
can be a so you need first of all

00:24:48,919 --> 00:24:52,940
you need to convert your data into

00:24:50,539 --> 00:24:54,919
common formats you don't wouldn't

00:24:52,940 --> 00:24:57,200
believe how many different timestamp

00:24:54,919 --> 00:25:00,139
formats are out there and for many other

00:24:57,200 --> 00:25:04,970
data types it's similar then you need

00:25:00,139 --> 00:25:07,070
well define ranges and this may be your

00:25:04,970 --> 00:25:08,990
sense of my may already provide this but

00:25:07,070 --> 00:25:11,870
you need to know what it is maybe

00:25:08,990 --> 00:25:14,179
cleaning remove you know have recorded

00:25:11,870 --> 00:25:16,100
human robot experiment and the camera as

00:25:14,179 --> 00:25:18,830
you switch it on and then ten minutes

00:25:16,100 --> 00:25:20,840
later the person comes so you don't want

00:25:18,830 --> 00:25:24,559
to use these ten minutes clean it out

00:25:20,840 --> 00:25:25,909
and then again completeness checking so

00:25:24,559 --> 00:25:28,700
if you do this in a multi-source

00:25:25,909 --> 00:25:31,039
environment what we often see is that

00:25:28,700 --> 00:25:33,460
people run you know this for every

00:25:31,039 --> 00:25:36,950
source they have they do this pipeline

00:25:33,460 --> 00:25:39,529
that is very inefficient and it usually

00:25:36,950 --> 00:25:42,380
results in not all of the sources that

00:25:39,529 --> 00:25:44,659
you would have available being used so

00:25:42,380 --> 00:25:48,110
you don't want to do that what we

00:25:44,659 --> 00:25:51,019
suggest instead is that you know at

00:25:48,110 --> 00:25:53,750
least for the high level analysis you do

00:25:51,019 --> 00:25:55,669
a model-based approach where you do your

00:25:53,750 --> 00:25:58,340
data capture and your various formats

00:25:55,669 --> 00:26:02,240
and then you do some sort of structuring

00:25:58,340 --> 00:26:05,919
process which extracts just part of the

00:26:02,240 --> 00:26:08,990
map data which is common across across

00:26:05,919 --> 00:26:11,450
many messages and so for all of the

00:26:08,990 --> 00:26:14,779
messages and data types that support

00:26:11,450 --> 00:26:15,620
this model you can then have one common

00:26:14,779 --> 00:26:19,940
pipeline

00:26:15,620 --> 00:26:21,470
towards which is much easier to do so to

00:26:19,940 --> 00:26:24,530
give you a few examples of what that

00:26:21,470 --> 00:26:26,990
could look like one is the occurrence

00:26:24,530 --> 00:26:29,360
model it's about the simplest model that

00:26:26,990 --> 00:26:32,690
you can use it just includes okay I have

00:26:29,360 --> 00:26:34,750
one what type is my message what is ID

00:26:32,690 --> 00:26:36,890
to distinguish between different

00:26:34,750 --> 00:26:39,170
messages of the same time and when is

00:26:36,890 --> 00:26:41,660
the time stamp and what this is useful

00:26:39,170 --> 00:26:46,190
for us completeness checking for example

00:26:41,660 --> 00:26:50,720
I displayed here in elon the histogram

00:26:46,190 --> 00:26:53,030
of message counts over all types so it's

00:26:50,720 --> 00:26:54,770
not like Eric's plot or erics back which

00:26:53,030 --> 00:26:58,010
you know just display one type it's

00:26:54,770 --> 00:27:00,679
about all and so you see here you have

00:26:58,010 --> 00:27:03,620
this sort of heartbeat of message counts

00:27:00,679 --> 00:27:06,650
and if you see a gap in this heartbeat

00:27:03,620 --> 00:27:08,990
then you know Oh message capture failed

00:27:06,650 --> 00:27:12,410
for that period of time so it's a very

00:27:08,990 --> 00:27:15,080
quick and easy way to check that may be

00:27:12,410 --> 00:27:18,830
a little bit more useful as a component

00:27:15,080 --> 00:27:21,350
activity model so you want to know which

00:27:18,830 --> 00:27:24,350
component was actually active during

00:27:21,350 --> 00:27:28,130
which time and what was the result and

00:27:24,350 --> 00:27:31,460
for that for example you can use Ross

00:27:28,130 --> 00:27:35,360
actions they provide this information

00:27:31,460 --> 00:27:36,740
out of the box when if you convert this

00:27:35,360 --> 00:27:39,050
for example it looks like this you have

00:27:36,740 --> 00:27:41,570
a diac type of the action then you have

00:27:39,050 --> 00:27:44,270
is its ID and in a start time stamina

00:27:41,570 --> 00:27:47,470
type 7 end result and you can do that

00:27:44,270 --> 00:27:49,760
for all actions in the system in a

00:27:47,470 --> 00:27:53,059
single way and there's actually already

00:27:49,760 --> 00:27:55,580
an analysis script in RM l which just

00:27:53,059 --> 00:27:57,800
says and if you have the sort of

00:27:55,580 --> 00:27:59,480
extraction what you get is a display

00:27:57,800 --> 00:28:02,690
like this one where you have your

00:27:59,480 --> 00:28:05,960
various actions listed as tears here in

00:28:02,690 --> 00:28:09,800
the display and for each of them you

00:28:05,960 --> 00:28:12,200
have the beginning and the end and the

00:28:09,800 --> 00:28:14,929
message ID and for action lip the

00:28:12,200 --> 00:28:19,760
message the goal ID usually signifies

00:28:14,929 --> 00:28:23,120
who initiated the action so if you look

00:28:19,760 --> 00:28:24,800
at this this is all quite nice so far we

00:28:23,120 --> 00:28:27,440
already know what's going on what failed

00:28:24,800 --> 00:28:28,280
what succeeded what we don't really know

00:28:27,440 --> 00:28:32,120
what the what

00:28:28,280 --> 00:28:34,460
action does and for that at the moment

00:28:32,120 --> 00:28:35,960
you have to look at the video that's why

00:28:34,460 --> 00:28:37,490
it's so important to have all the

00:28:35,960 --> 00:28:42,650
various data sources in one application

00:28:37,490 --> 00:28:44,540
and but theoretically ideally what we

00:28:42,650 --> 00:28:47,740
would like is get more information out

00:28:44,540 --> 00:28:50,540
of the messages again in a generic way

00:28:47,740 --> 00:28:52,850
and of course what's also missing here

00:28:50,540 --> 00:28:55,940
is anything that does not use actions so

00:28:52,850 --> 00:28:59,330
how do we get that sort of data and what

00:28:55,940 --> 00:29:02,750
we did here is we extended the rust

00:28:59,330 --> 00:29:06,650
message definition format with type

00:29:02,750 --> 00:29:09,830
information so this this is just an

00:29:06,650 --> 00:29:12,830
example this is of course this is

00:29:09,830 --> 00:29:15,710
totally our own experiment this is not

00:29:12,830 --> 00:29:17,930
standard this might become standard if

00:29:15,710 --> 00:29:20,420
there's interest but it's it's just you

00:29:17,930 --> 00:29:21,890
know we needed this and that's why I

00:29:20,420 --> 00:29:24,290
wanted to mention it here and it might

00:29:21,890 --> 00:29:26,570
spark a discussion and so for example we

00:29:24,290 --> 00:29:29,360
could do say something like this the

00:29:26,570 --> 00:29:32,360
message field length is in meters or x

00:29:29,360 --> 00:29:35,750
is a pixel-by-pixel court in it our

00:29:32,360 --> 00:29:38,120
power is in watts or maybe what is also

00:29:35,750 --> 00:29:40,490
interesting there's this string it's

00:29:38,120 --> 00:29:43,490
called a label and has words in it for

00:29:40,490 --> 00:29:46,160
example so if we have this additional

00:29:43,490 --> 00:29:48,260
information on your types then what we

00:29:46,160 --> 00:29:49,880
can do is we do this generic analysis we

00:29:48,260 --> 00:29:52,430
don't actually need to know what your

00:29:49,880 --> 00:29:55,730
type is about we can extract anything

00:29:52,430 --> 00:29:58,280
that is a word for example and if you do

00:29:55,730 --> 00:30:01,190
that again this is a picture from the

00:29:58,280 --> 00:30:04,430
beginning and I hope you can actually a

00:30:01,190 --> 00:30:07,070
York in rhesus I hope so if you look

00:30:04,430 --> 00:30:09,920
here for example this is a retina object

00:30:07,070 --> 00:30:12,140
recognizer output and here you see the

00:30:09,920 --> 00:30:15,590
word it's unknown as an unknown picture

00:30:12,140 --> 00:30:17,900
or this is for example its robot what is

00:30:15,590 --> 00:30:20,390
the robot speaking and it's in German ok

00:30:17,900 --> 00:30:22,760
but here it is you see the output of the

00:30:20,390 --> 00:30:25,130
robot yeah what what the robot is

00:30:22,760 --> 00:30:28,160
speaking you see this directly and so of

00:30:25,130 --> 00:30:31,910
course you could do this for your

00:30:28,160 --> 00:30:34,760
specific data type easily right but it

00:30:31,910 --> 00:30:37,100
would only work for your for your type

00:30:34,760 --> 00:30:39,560
so we don't have a generic tool and if

00:30:37,100 --> 00:30:41,520
you use the sort of annotation then we

00:30:39,560 --> 00:30:43,230
can do this for any

00:30:41,520 --> 00:30:45,270
such type that's out there an assistant

00:30:43,230 --> 00:30:48,990
even for message types we didn't know

00:30:45,270 --> 00:30:52,230
about at all before so that would be our

00:30:48,990 --> 00:30:54,720
suggestion at disqus and with that i'm

00:30:52,230 --> 00:30:55,950
already done here so which is good i

00:30:54,720 --> 00:31:00,020
think we have some time for questions

00:30:55,950 --> 00:31:04,410
but let me just shortly conclude and

00:31:00,020 --> 00:31:06,570
included this is including Tim's talk so

00:31:04,410 --> 00:31:09,120
what I would like to what we find is

00:31:06,570 --> 00:31:12,510
that this sort of system profiling needs

00:31:09,120 --> 00:31:15,300
a compact high-level view and it's

00:31:12,510 --> 00:31:18,750
important to store data from multiple

00:31:15,300 --> 00:31:21,630
sources easily and to give you

00:31:18,750 --> 00:31:23,160
additional insights and the only point

00:31:21,630 --> 00:31:26,820
you have to look out for it's a time

00:31:23,160 --> 00:31:29,550
stamp and i also want to i think that

00:31:26,820 --> 00:31:32,580
this model based extraction is very

00:31:29,550 --> 00:31:35,490
useful for generic inspection tasks so

00:31:32,580 --> 00:31:37,980
this does not replace the the types of

00:31:35,490 --> 00:31:40,380
feature and performance analysis that we

00:31:37,980 --> 00:31:42,150
have been doing before but it gives you

00:31:40,380 --> 00:31:45,540
information where to apply it and which

00:31:42,150 --> 00:31:48,900
one to use and finally refer them back

00:31:45,540 --> 00:31:52,350
to tim's talk we found that storing this

00:31:48,900 --> 00:31:54,120
runtime data that in a database is quite

00:31:52,350 --> 00:31:56,190
efficient and enables you to have

00:31:54,120 --> 00:31:58,950
interesting new applications because

00:31:56,190 --> 00:32:00,480
it's much easier to access it and for

00:31:58,950 --> 00:32:02,880
example we saw this online news for the

00:32:00,480 --> 00:32:04,460
multi-perspective perception d offline

00:32:02,880 --> 00:32:08,490
use for postmortem scene reconstruction

00:32:04,460 --> 00:32:09,750
and so on and with that we're done with

00:32:08,490 --> 00:32:12,020
the talking and hopefully you have some

00:32:09,750 --> 00:32:12,020

YouTube URL: https://www.youtube.com/watch?v=KqSBlYq_sF8


