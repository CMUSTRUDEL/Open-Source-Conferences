Title: ROSCon 2018 Madrid Cloud based Mapping and Localization in Dynamic Warehouse Environments
Publication date: 2021-03-28
Playlist: ROSCon 2018
Description: 
	Unaltered video by Open Robotics from http://roscon.ros.org/2018 under the Attribution-NonCommercial-NoDerivs 3.0 Unported (CC BY-NC-ND 3.0) License https://creativecommons.org/licenses/by-nc-nd/3.0/
Captions: 
	00:00:01,820 --> 00:00:05,759
thank you

00:00:03,179 --> 00:00:07,770
so my name is mover and fan magazine oh

00:00:05,759 --> 00:00:09,870
and we're presenting today joint work

00:00:07,770 --> 00:00:13,139
with Google on how we can use different

00:00:09,870 --> 00:00:14,639
robots for mapping an environment for

00:00:13,139 --> 00:00:15,870
integrating the information from these

00:00:14,639 --> 00:00:17,130
robots coming in order to have a

00:00:15,870 --> 00:00:19,740
consistent view of how the word is

00:00:17,130 --> 00:00:20,369
actually looking like so why do we want

00:00:19,740 --> 00:00:24,560
to do that

00:00:20,369 --> 00:00:27,090
so with magazine oh we are building

00:00:24,560 --> 00:00:32,189
mobile clicking place robots that should

00:00:27,090 --> 00:00:34,250
be shown in this video here you're gonna

00:00:32,189 --> 00:00:36,570
see the video on our booth as well so

00:00:34,250 --> 00:00:37,800
the important thing is we have mobile

00:00:36,570 --> 00:00:39,450
robots they navigate through the

00:00:37,800 --> 00:00:42,360
warehouses autonomously they can pick

00:00:39,450 --> 00:00:44,149
items they can store items and basically

00:00:42,360 --> 00:00:46,230
do the same job that humans are doing

00:00:44,149 --> 00:00:47,850
while they're driving around they're

00:00:46,230 --> 00:00:49,350
also interacting with humans who are

00:00:47,850 --> 00:00:51,360
operating in the same warehouse or the

00:00:49,350 --> 00:00:53,460
humans also pick items put items change

00:00:51,360 --> 00:00:55,920
the environment by this and addition to

00:00:53,460 --> 00:00:57,660
safety requirements the robots also have

00:00:55,920 --> 00:01:01,109
to cope with all the uncertainty that

00:00:57,660 --> 00:01:03,480
the humans introduce and what's very

00:01:01,109 --> 00:01:04,710
important of course we're going to sell

00:01:03,480 --> 00:01:07,950
these robots to customers they are

00:01:04,710 --> 00:01:09,869
already in live operation so for the

00:01:07,950 --> 00:01:11,670
robots to pay for the customers they

00:01:09,869 --> 00:01:12,930
have to be on the one hand fast and on

00:01:11,670 --> 00:01:15,240
the other hand they have to be reliable

00:01:12,930 --> 00:01:18,570
and in this talk we're talking about how

00:01:15,240 --> 00:01:19,920
we can help the robots to become both by

00:01:18,570 --> 00:01:22,470
having better information of the

00:01:19,920 --> 00:01:24,119
environment so the video didn't really

00:01:22,470 --> 00:01:26,549
play but let's have a look at these

00:01:24,119 --> 00:01:29,159
animations so this is like a top-down

00:01:26,549 --> 00:01:31,770
view of the warehouse so you see in some

00:01:29,159 --> 00:01:34,680
rows of shelves you see some humans

00:01:31,770 --> 00:01:35,640
these long elongated squares like carts

00:01:34,680 --> 00:01:37,020
that you can imagine they're like

00:01:35,640 --> 00:01:39,810
shelves on wheels that they are pulling

00:01:37,020 --> 00:01:41,600
around so start putting the items in and

00:01:39,810 --> 00:01:44,159
in between you have some robots that are

00:01:41,600 --> 00:01:46,079
driving that are also picking and of

00:01:44,159 --> 00:01:48,030
course you have lots of objects that are

00:01:46,079 --> 00:01:49,770
lying there in our cases is often like

00:01:48,030 --> 00:01:52,799
shoe boxes or other kinds of things and

00:01:49,770 --> 00:01:54,270
in the morning the shelves are normally

00:01:52,799 --> 00:01:56,579
pretty full over the course of the day

00:01:54,270 --> 00:01:58,079
the humans and the robots pick items

00:01:56,579 --> 00:02:01,110
everything that you ordered online all

00:01:58,079 --> 00:02:03,329
these shoes and they continue picking

00:02:01,110 --> 00:02:05,159
and in the afternoon the warehouse

00:02:03,329 --> 00:02:06,570
actually looks pretty different and it

00:02:05,159 --> 00:02:07,490
looks different at the high level at the

00:02:06,570 --> 00:02:08,989
semantic level of

00:02:07,490 --> 00:02:11,569
which objects are located yeah but also

00:02:08,989 --> 00:02:13,400
the low level of if you look at the data

00:02:11,569 --> 00:02:15,319
map at this at the height of the laser

00:02:13,400 --> 00:02:17,300
scan then you just see different things

00:02:15,319 --> 00:02:21,580
and the the outline of the environment

00:02:17,300 --> 00:02:24,069
has just changed a lot and if we want to

00:02:21,580 --> 00:02:26,870
remember we want to be fast and reliable

00:02:24,069 --> 00:02:28,430
we need to ensure that the robots know

00:02:26,870 --> 00:02:30,650
where they are so they need good

00:02:28,430 --> 00:02:32,330
localization in this area but they also

00:02:30,650 --> 00:02:34,849
need to know where the objects are so

00:02:32,330 --> 00:02:37,220
imagine the robot wants to pick the item

00:02:34,849 --> 00:02:38,599
that is there this red box the warehouse

00:02:37,220 --> 00:02:39,950
management system only tells us is

00:02:38,599 --> 00:02:42,170
somewhere in this area here so it's

00:02:39,950 --> 00:02:43,160
somewhere on this on the shelf but in

00:02:42,170 --> 00:02:44,810
order to really pick it and already

00:02:43,160 --> 00:02:47,540
drive to the right location and order

00:02:44,810 --> 00:02:49,549
not to have to search the robot better

00:02:47,540 --> 00:02:52,310
knows where exactly it is so that it can

00:02:49,549 --> 00:02:53,750
plan its path and the problem is of

00:02:52,310 --> 00:02:55,580
course the more humans are there the

00:02:53,750 --> 00:02:57,950
more robots are there this faster the

00:02:55,580 --> 00:02:59,420
environment changes and in order to have

00:02:57,950 --> 00:03:01,459
good data that it could believe about

00:02:59,420 --> 00:03:04,130
the environment we need to have frequent

00:03:01,459 --> 00:03:06,200
updates and we increase the sampling

00:03:04,130 --> 00:03:07,730
rate by integrating data from different

00:03:06,200 --> 00:03:11,930
robots feed them into a common belief

00:03:07,730 --> 00:03:14,570
state and by that one I have very good

00:03:11,930 --> 00:03:16,579
information and that's also where we

00:03:14,570 --> 00:03:18,609
collaborated with Google on seeing how

00:03:16,579 --> 00:03:21,500
we can actually leverage this data and

00:03:18,609 --> 00:03:25,430
how it could use extend cartographer

00:03:21,500 --> 00:03:33,620
localization and mapping system in order

00:03:25,430 --> 00:03:36,170
to help with that hi so I guess it's

00:03:33,620 --> 00:03:38,739
become quite clear that we need dynamic

00:03:36,170 --> 00:03:42,500
mapping we need cloud based mapping and

00:03:38,739 --> 00:03:43,970
we at Google we developed the open

00:03:42,500 --> 00:03:46,910
source software cartographer

00:03:43,970 --> 00:03:48,410
photographer is a software for

00:03:46,910 --> 00:03:52,069
simultaneous localization and mapping

00:03:48,410 --> 00:03:56,450
slam and it offers 2d and 3d algorithms

00:03:52,069 --> 00:04:00,889
so you can use 2d and 3d laser scanner

00:03:56,450 --> 00:04:05,019
sliders and it's it's around on github

00:04:00,889 --> 00:04:05,019
as an open-source package we recently

00:04:05,799 --> 00:04:11,989
released the Ross package version 1.0

00:04:09,410 --> 00:04:14,799
and it's it's not only been used by

00:04:11,989 --> 00:04:16,870
mobile robot companies but also by

00:04:14,799 --> 00:04:19,750
researchers and

00:04:16,870 --> 00:04:23,430
internally with Street View so what is

00:04:19,750 --> 00:04:26,169
catwalk about and how does it help with

00:04:23,430 --> 00:04:28,900
cloud based mapping so I will briefly

00:04:26,169 --> 00:04:32,710
explain the algorithm and then we will

00:04:28,900 --> 00:04:36,060
later see how magazine or uses it in

00:04:32,710 --> 00:04:39,190
practice so starting from the lower row

00:04:36,060 --> 00:04:40,870
we have lidar sensors laser scanners we

00:04:39,190 --> 00:04:43,690
have inertial measurement units we have

00:04:40,870 --> 00:04:46,990
wheel encoders and these sensor data

00:04:43,690 --> 00:04:49,060
feeds into the slam algorithm and

00:04:46,990 --> 00:04:53,050
cartographer we do scan to sapna

00:04:49,060 --> 00:04:56,650
matching so what is this exactly mean

00:04:53,050 --> 00:04:59,590
so the spam algorithm receives a lidar

00:04:56,650 --> 00:05:01,389
scan the preimage looks like like a

00:04:59,590 --> 00:05:04,120
small point cloud that shows the

00:05:01,389 --> 00:05:09,630
reflections of the laser rays and we

00:05:04,120 --> 00:05:12,130
match this scan against a short time

00:05:09,630 --> 00:05:14,500
accumulation probability grid which we

00:05:12,130 --> 00:05:17,530
call a sub map so the suburb is a

00:05:14,500 --> 00:05:19,690
probability grid of occupancies and we

00:05:17,530 --> 00:05:21,729
match it against the sub map and this

00:05:19,690 --> 00:05:24,760
gives us the estimated post place game

00:05:21,729 --> 00:05:27,130
matching and we insert this scan at this

00:05:24,760 --> 00:05:30,520
place into the sub map so we do

00:05:27,130 --> 00:05:32,740
localization and mapping of course this

00:05:30,520 --> 00:05:40,510
is LAN without good closure loop closure

00:05:32,740 --> 00:05:43,120
is important because so far every scan

00:05:40,510 --> 00:05:46,389
insertion will have a tiny arrow and

00:05:43,120 --> 00:05:49,120
this drift accumulates over time so we

00:05:46,389 --> 00:05:53,770
need to cancel out this drift how we do

00:05:49,120 --> 00:05:57,400
we do this we feed the limited time sub

00:05:53,770 --> 00:05:59,380
maps into a post graph which we can then

00:05:57,400 --> 00:06:04,360
optimize and find additional loop

00:05:59,380 --> 00:06:06,880
closure so before when you before loop

00:06:04,360 --> 00:06:11,979
closure when you map a large area like

00:06:06,880 --> 00:06:14,229
on the left side this sensor working

00:06:11,979 --> 00:06:17,110
around a very large museum working in

00:06:14,229 --> 00:06:20,740
large circle and this oval room and the

00:06:17,110 --> 00:06:22,539
museum you can see double because it was

00:06:20,740 --> 00:06:25,719
recorded in the beginning and in the end

00:06:22,539 --> 00:06:26,590
so it's really double recording and the

00:06:25,719 --> 00:06:28,660
loop closure

00:06:26,590 --> 00:06:31,270
we run scan matching

00:06:28,660 --> 00:06:34,870
from the current scan to old suck maps

00:06:31,270 --> 00:06:37,420
and here we can find a match and that

00:06:34,870 --> 00:06:40,090
match enters into the pose graph as a

00:06:37,420 --> 00:06:42,900
constraint and then the post graph

00:06:40,090 --> 00:06:45,220
optimizer can move pieces together and

00:06:42,900 --> 00:06:48,310
optimize the post graph so this is

00:06:45,220 --> 00:06:50,830
really important to provide a good

00:06:48,310 --> 00:06:53,500
quality map so this is one important

00:06:50,830 --> 00:06:55,750
piece of their algorithm the second

00:06:53,500 --> 00:06:58,120
important thing of course is how do we

00:06:55,750 --> 00:07:01,810
do localization we do really do global

00:06:58,120 --> 00:07:04,210
localization so when we talk of a map

00:07:01,810 --> 00:07:07,030
and cartographer it's not a bitmap but

00:07:04,210 --> 00:07:09,550
it's really like a frozen post graph

00:07:07,030 --> 00:07:12,220
with all the information attached so

00:07:09,550 --> 00:07:15,910
when the when a robot moves around needs

00:07:12,220 --> 00:07:17,770
to localize it what it does it matches

00:07:15,910 --> 00:07:20,669
the currents it tries to match the

00:07:17,770 --> 00:07:23,530
current laser scan against the existing

00:07:20,669 --> 00:07:26,050
post graph against the SAP maps in the

00:07:23,530 --> 00:07:28,630
existing post graph and when it finds a

00:07:26,050 --> 00:07:31,030
scan match to the existing map that's

00:07:28,630 --> 00:07:33,910
really you have a post graph of the

00:07:31,030 --> 00:07:36,550
current motion and the map is the the

00:07:33,910 --> 00:07:39,130
frozen post graph and then you you

00:07:36,550 --> 00:07:42,880
combine you have a connection between

00:07:39,130 --> 00:07:45,280
these graphs and that helps you that the

00:07:42,880 --> 00:07:48,160
current pose is really localized in the

00:07:45,280 --> 00:07:50,350
coordinate frame of the of the frozen

00:07:48,160 --> 00:07:52,120
map so that's its global coordinates

00:07:50,350 --> 00:07:53,680
then so this is the localization

00:07:52,120 --> 00:07:56,790
procedure of cartography

00:07:53,680 --> 00:07:59,800
what else do we need of course for

00:07:56,790 --> 00:08:02,380
cloud-based mapping in these two dynamic

00:07:59,800 --> 00:08:07,270
environments we need to have

00:08:02,380 --> 00:08:10,540
collaborative mapping so the robots

00:08:07,270 --> 00:08:13,090
usually they run a slam in a finit

00:08:10,540 --> 00:08:16,630
history configuration so that means that

00:08:13,090 --> 00:08:19,419
keep only is a sub maps and over a

00:08:16,630 --> 00:08:22,720
certain time scale and of course they

00:08:19,419 --> 00:08:24,910
provide very low latency hoes so they

00:08:22,720 --> 00:08:28,690
can that can be used for robot control

00:08:24,910 --> 00:08:30,460
and they do global localization which in

00:08:28,690 --> 00:08:32,260
our case is really loop closure to a

00:08:30,460 --> 00:08:36,729
frozen map so that's what each robot

00:08:32,260 --> 00:08:38,600
does and then each robots up streams

00:08:36,729 --> 00:08:40,640
data to the cloud or

00:08:38,600 --> 00:08:43,100
to a central cloud web mapping instance

00:08:40,640 --> 00:08:45,560
it can also be on an ad server it

00:08:43,100 --> 00:08:48,050
upstreams the SAP Maps to the post graph

00:08:45,560 --> 00:08:50,480
optimisation that runs in the central

00:08:48,050 --> 00:08:53,210
instance and the post graph optimizer

00:08:50,480 --> 00:08:54,680
can even find loop closures across the

00:08:53,210 --> 00:08:56,690
different trajectories of the robot so

00:08:54,680 --> 00:08:59,540
it really comes out with an optimized

00:08:56,690 --> 00:09:03,320
map of the entire area the only thing

00:08:59,540 --> 00:09:06,980
the only missing piece though is that

00:09:03,320 --> 00:09:08,960
you're only reporting data but the map

00:09:06,980 --> 00:09:11,270
grows and grows and the post graph has

00:09:08,960 --> 00:09:14,510
more and more layers so we also need

00:09:11,270 --> 00:09:17,440
means to erase all data and that's the

00:09:14,510 --> 00:09:21,110
lifelong trimmer that's life on wrapping

00:09:17,440 --> 00:09:23,720
so we we came up with a very very simple

00:09:21,110 --> 00:09:26,720
approach to lifelong mapping so far it's

00:09:23,720 --> 00:09:29,000
the easiest such approach you can

00:09:26,720 --> 00:09:31,970
imagine it's just we have the subnets in

00:09:29,000 --> 00:09:36,320
the post graph and we look how old they

00:09:31,970 --> 00:09:40,460
are and which area they cover and if a

00:09:36,320 --> 00:09:45,310
SAP map is old enough and has only a

00:09:40,460 --> 00:09:48,320
small unique area that gets lost if I

00:09:45,310 --> 00:09:50,060
erase that SAP map we just remove it

00:09:48,320 --> 00:09:52,100
from the postcard so that's what we call

00:09:50,060 --> 00:09:53,360
the lifelong trimmer that's very easy

00:09:52,100 --> 00:09:55,640
solution for this problem

00:09:53,360 --> 00:09:57,530
yeah essentially these are all the

00:09:55,640 --> 00:10:00,800
building blocks of the cartographer

00:09:57,530 --> 00:10:08,150
algorithm that I'm necessary for this

00:10:00,800 --> 00:10:12,980
task and now we can present how this is

00:10:08,150 --> 00:10:14,990
plugged together in practice yeah

00:10:12,980 --> 00:10:19,640
my name is Michael I'm working at

00:10:14,990 --> 00:10:21,790
Magazine Oh on slam and yeah I'm going

00:10:19,640 --> 00:10:24,110
to come back to the initial problem that

00:10:21,790 --> 00:10:26,900
Morris was explaining which is the

00:10:24,110 --> 00:10:29,210
dynamic reference in which our robots

00:10:26,900 --> 00:10:31,550
are operating picking objects and have

00:10:29,210 --> 00:10:35,720
to cope with all the changes that are

00:10:31,550 --> 00:10:37,790
happening in the environment so first

00:10:35,720 --> 00:10:40,550
I'm going to start with the conventional

00:10:37,790 --> 00:10:43,070
approach that probably most people are

00:10:40,550 --> 00:10:45,720
more or less familiar who are working

00:10:43,070 --> 00:10:48,029
with localization

00:10:45,720 --> 00:10:54,149
so we used photographer since about a

00:10:48,029 --> 00:10:58,110
year and so far our approach was yeah

00:10:54,149 --> 00:11:02,279
not to have a cloud-based instance for

00:10:58,110 --> 00:11:04,769
mapping but to have the mappings

00:11:02,279 --> 00:11:07,620
separated from the real time operation

00:11:04,769 --> 00:11:09,569
of the robots so what does this mean we

00:11:07,620 --> 00:11:12,420
have robots that are running the

00:11:09,569 --> 00:11:14,519
real-time localization with a finite

00:11:12,420 --> 00:11:18,149
history so you can really imagine this

00:11:14,519 --> 00:11:20,399
like yeah sliding window of sub maps so

00:11:18,149 --> 00:11:21,420
you don't keep all data on the robots of

00:11:20,399 --> 00:11:26,339
course because you have limited

00:11:21,420 --> 00:11:29,449
resources and rather you do the mapping

00:11:26,339 --> 00:11:32,879
as a separate process so every time we

00:11:29,449 --> 00:11:34,680
that environment changes this can be on

00:11:32,879 --> 00:11:36,810
a weekly basis or a monthly basis

00:11:34,680 --> 00:11:39,509
depending on the environment we have to

00:11:36,810 --> 00:11:41,850
remap and load this static map hundred

00:11:39,509 --> 00:11:47,490
robots which they then use to find loop

00:11:41,850 --> 00:11:51,149
closure constraints so here's a gift of

00:11:47,490 --> 00:11:54,449
this process you can see a robot single

00:11:51,149 --> 00:11:57,949
robot going on a dedicated mapping path

00:11:54,449 --> 00:12:00,420
through an warehouse environment and

00:11:57,949 --> 00:12:03,269
yeah capturing the current state of the

00:12:00,420 --> 00:12:05,550
environment so we invested quite some

00:12:03,269 --> 00:12:07,920
time in this conventional approach to

00:12:05,550 --> 00:12:11,639
make it robust and increase the quality

00:12:07,920 --> 00:12:15,089
of the maps we also have automatic

00:12:11,639 --> 00:12:18,449
Waypoint generator for the warehouse to

00:12:15,089 --> 00:12:20,160
remap so the whole process is not manual

00:12:18,449 --> 00:12:24,329
but you can send a robot on this path

00:12:20,160 --> 00:12:29,279
and that's what we have been doing last

00:12:24,329 --> 00:12:32,100
month basically so it works fine from a

00:12:29,279 --> 00:12:36,120
mapping point of view but there are some

00:12:32,100 --> 00:12:37,949
problems with it so as you can see the

00:12:36,120 --> 00:12:40,829
robot is driving basically through an

00:12:37,949 --> 00:12:42,329
empty warehouse which is problematic if

00:12:40,829 --> 00:12:44,670
we think about that we want to have

00:12:42,329 --> 00:12:47,550
multiple robots working in whereas

00:12:44,670 --> 00:12:49,840
environment and those robots shouldn't

00:12:47,550 --> 00:12:52,130
be blocked by mappings

00:12:49,840 --> 00:12:54,260
first of all we need a mapping robot

00:12:52,130 --> 00:12:55,850
that is going on this path but we also

00:12:54,260 --> 00:12:57,920
need to remove all the other robots so

00:12:55,850 --> 00:13:02,210
the mapping doesn't take forever and the

00:12:57,920 --> 00:13:04,040
mapping robot is not blocked so the

00:13:02,210 --> 00:13:06,860
whole idea of this cloud-based mapping

00:13:04,040 --> 00:13:10,490
project was why do we need to send a

00:13:06,860 --> 00:13:14,990
robot on this complicated path if we

00:13:10,490 --> 00:13:18,170
have this by all the time which is

00:13:14,990 --> 00:13:20,330
basically all robots operating in

00:13:18,170 --> 00:13:22,820
different areas of the warehouse seeing

00:13:20,330 --> 00:13:25,250
the current state and I'm using this

00:13:22,820 --> 00:13:30,980
state that robots see to assemble an

00:13:25,250 --> 00:13:33,080
updated map so how does the component

00:13:30,980 --> 00:13:34,640
from component point of view how does

00:13:33,080 --> 00:13:36,050
the migration look like from this

00:13:34,640 --> 00:13:39,350
conventional approach a cloud-based

00:13:36,050 --> 00:13:41,330
approach so under robot we didn't want

00:13:39,350 --> 00:13:43,040
to change much so because we have

00:13:41,330 --> 00:13:46,550
limited resources we still want to use

00:13:43,040 --> 00:13:49,190
the same basic approach for localization

00:13:46,550 --> 00:13:51,410
we have frozen static map and try to

00:13:49,190 --> 00:13:54,110
localize living in more or less

00:13:51,410 --> 00:13:56,030
real-time and also we didn't want to

00:13:54,110 --> 00:14:00,020
change any api's for the rest of the

00:13:56,030 --> 00:14:02,720
robot what's now new is an uplink on

00:14:00,020 --> 00:14:06,860
every robot that is communicating wire

00:14:02,720 --> 00:14:10,580
at a tree up C framework with cloud

00:14:06,860 --> 00:14:12,980
instance which is optimized for mapping

00:14:10,580 --> 00:14:15,940
so that it's basically a separation of

00:14:12,980 --> 00:14:18,440
concerns the robots do their tasks they

00:14:15,940 --> 00:14:21,320
manipulate objects to only real-time

00:14:18,440 --> 00:14:24,050
localization but we do the mapping on a

00:14:21,320 --> 00:14:28,730
more powerful cloud instance that we can

00:14:24,050 --> 00:14:31,010
also scale to our environments so the

00:14:28,730 --> 00:14:33,920
robots are sending their observations

00:14:31,010 --> 00:14:39,140
which of sub maps and sensor data to the

00:14:33,920 --> 00:14:42,140
cloud instance and we regularly update

00:14:39,140 --> 00:14:44,060
the map on the robots by down streaming

00:14:42,140 --> 00:14:50,240
it from this cloud instance to the robot

00:14:44,060 --> 00:14:51,830
and yeah because we have yeah can

00:14:50,240 --> 00:14:55,430
basically scale theoretically to

00:14:51,830 --> 00:14:57,470
unlimited compute power in the cloud we

00:14:55,430 --> 00:15:00,060
can scale this multiple robots operating

00:14:57,470 --> 00:15:09,240
in big warehouses

00:15:00,060 --> 00:15:11,130
so yeah we piloted this approach first

00:15:09,240 --> 00:15:14,040
of all we started in our lab so this

00:15:11,130 --> 00:15:16,710
what you can see here is our mini

00:15:14,040 --> 00:15:21,390
warehouse at magazine oh it's basically

00:15:16,710 --> 00:15:23,910
a small warehouse we have the same type

00:15:21,390 --> 00:15:25,590
of boxes same type of shelves of course

00:15:23,910 --> 00:15:28,080
a small environment but we can use it

00:15:25,590 --> 00:15:31,050
for testing and here to illustrate our

00:15:28,080 --> 00:15:32,910
approach so what you can see is

00:15:31,050 --> 00:15:36,270
basically we have an obstacle that is

00:15:32,910 --> 00:15:38,040
this big cart filled with boxes and we

00:15:36,270 --> 00:15:40,170
intentionally placed it there to

00:15:38,040 --> 00:15:42,270
illustrate yeah the bigger picture that

00:15:40,170 --> 00:15:45,950
we want to achieve in the next month was

00:15:42,270 --> 00:15:50,610
this whole project so the idea is that

00:15:45,950 --> 00:15:56,250
the robot that you just saw on drives by

00:15:50,610 --> 00:16:00,270
this obstacle and by driving by it can

00:15:56,250 --> 00:16:05,220
capture this obstacle with its yeah with

00:16:00,270 --> 00:16:09,000
its local slam approach so you can see

00:16:05,220 --> 00:16:11,520
the obstacle appeared in the right

00:16:09,000 --> 00:16:16,590
location which is here on the left in

00:16:11,520 --> 00:16:20,460
the video and in the future we want to

00:16:16,590 --> 00:16:22,830
use this yeah updated belief state you

00:16:20,460 --> 00:16:25,500
can say of the environment to shared

00:16:22,830 --> 00:16:30,240
with the other robots also in real-time

00:16:25,500 --> 00:16:31,320
so imagine another robot that is also

00:16:30,240 --> 00:16:33,780
driving through the thing the same

00:16:31,320 --> 00:16:36,540
warehouse that wants to get to a

00:16:33,780 --> 00:16:38,220
position near the obstacle and it's now

00:16:36,540 --> 00:16:40,200
getting the information from the other

00:16:38,220 --> 00:16:43,410
robot that has mapped the obstacle and

00:16:40,200 --> 00:16:46,470
is now able to replan according to the

00:16:43,410 --> 00:16:49,940
updated map so initially the shortest

00:16:46,470 --> 00:16:53,340
path was where the obstacle was located

00:16:49,940 --> 00:16:55,140
but since we now have updated the

00:16:53,340 --> 00:16:59,370
environment representation we can use

00:16:55,140 --> 00:17:01,320
this to replan and go another path which

00:16:59,370 --> 00:17:04,770
is actually longer but in this case more

00:17:01,320 --> 00:17:07,400
optimal yeah so this is visualized here

00:17:04,770 --> 00:17:07,400
in this video

00:17:07,449 --> 00:17:13,370
yes the other robot is basically going

00:17:10,310 --> 00:17:15,560
the other path so what you see here is

00:17:13,370 --> 00:17:21,020
of course a toy environment this is not

00:17:15,560 --> 00:17:23,240
real Wales but we are illustrating what

00:17:21,020 --> 00:17:27,290
we want to achieve with it here so

00:17:23,240 --> 00:17:29,480
that's why we're showing it um we did

00:17:27,290 --> 00:17:32,000
not only test in our own lab but we also

00:17:29,480 --> 00:17:33,500
deployed it to a real warehouse so the

00:17:32,000 --> 00:17:37,280
same warehouse that I showed you before

00:17:33,500 --> 00:17:40,640
in the mapping video we used for pilot

00:17:37,280 --> 00:17:42,620
tests of the cloud cutter offer and we

00:17:40,640 --> 00:17:44,420
use three robots and the cloud instance

00:17:42,620 --> 00:17:48,920
and what you see here in this animation

00:17:44,420 --> 00:17:50,660
is a comparison of the stage of the map

00:17:48,920 --> 00:17:54,140
that the robots used for real-time

00:17:50,660 --> 00:17:58,690
localization versus the state of the map

00:17:54,140 --> 00:18:01,070
server at the end of the day so there

00:17:58,690 --> 00:18:03,650
that the blobs that you're seeing in the

00:18:01,070 --> 00:18:05,270
2d 2d maps are mostly boxes that are

00:18:03,650 --> 00:18:08,840
located in shelves and that have been

00:18:05,270 --> 00:18:10,940
moved and with the cloud-based mapping

00:18:08,840 --> 00:18:13,330
approach we were able to capture all

00:18:10,940 --> 00:18:16,430
these movements all this dynamic

00:18:13,330 --> 00:18:19,760
environment changes from robots

00:18:16,430 --> 00:18:21,800
operating in yeah in a normal setting

00:18:19,760 --> 00:18:28,040
just doing their tasks and picking

00:18:21,800 --> 00:18:31,400
objects and yeah also we were able to

00:18:28,040 --> 00:18:33,800
tune it that the quality was of the map

00:18:31,400 --> 00:18:36,860
itself is staying the same so you don't

00:18:33,800 --> 00:18:43,160
see any larger geometric distortions

00:18:36,860 --> 00:18:45,920
from this life based mapping so yeah

00:18:43,160 --> 00:18:49,520
that was our presentation on cloud based

00:18:45,920 --> 00:18:52,460
mapping if you have any questions feel

00:18:49,520 --> 00:18:54,230
free to ask us an important thing to

00:18:52,460 --> 00:18:57,200
note here is maybe also that we're not

00:18:54,230 --> 00:18:59,690
developing this in the secret so you can

00:18:57,200 --> 00:19:04,370
find the source code of the components

00:18:59,690 --> 00:19:09,610
on github and yeah feel free to come by

00:19:04,370 --> 00:19:09,610
a boost of magazine or Google and we're

00:19:10,200 --> 00:19:15,459
[Applause]

00:19:16,460 --> 00:19:23,400
thank you very much looks like we got a

00:19:18,929 --> 00:19:24,870
question yes my question is I've also

00:19:23,400 --> 00:19:27,659
experimented with Katara for a little

00:19:24,870 --> 00:19:31,980
bit and I was wondering if you were able

00:19:27,659 --> 00:19:33,809
to get it to map accurately across

00:19:31,980 --> 00:19:37,260
different masks but only using wheel

00:19:33,809 --> 00:19:45,260
encoder and to the lighter without an

00:19:37,260 --> 00:19:47,909
IMU we use wheel encoders I'm you and

00:19:45,260 --> 00:19:52,309
data because that's yeah all we can use

00:19:47,909 --> 00:19:56,279
and one not wet you scarlet in this case

00:19:52,309 --> 00:19:59,640
we but we were also able to use it

00:19:56,279 --> 00:20:02,850
without an eye on you so I don't know

00:19:59,640 --> 00:20:06,149
what if you had any problems with tuning

00:20:02,850 --> 00:20:10,020
without I'm you maybe you can elaborate

00:20:06,149 --> 00:20:12,090
here yeah I mean that was the so we were

00:20:10,020 --> 00:20:14,010
able to do this so okay but there are

00:20:12,090 --> 00:20:17,070
many parameters you can trim you can use

00:20:14,010 --> 00:20:20,760
also a front-end that is based on the

00:20:17,070 --> 00:20:22,260
loop closure so the real-time correlated

00:20:20,760 --> 00:20:23,789
scan Metro yeah

00:20:22,260 --> 00:20:25,740
which is actually recommended if you

00:20:23,789 --> 00:20:30,899
don't have reliable input from an eye on

00:20:25,740 --> 00:20:32,130
us so I can try that okay thank you

00:20:30,899 --> 00:20:33,570
looks like we got a lot of interesting

00:20:32,130 --> 00:20:36,240
questions I've got time for one more

00:20:33,570 --> 00:20:38,909
because I got to get you moving on to

00:20:36,240 --> 00:20:40,830
the next things so first of all very

00:20:38,909 --> 00:20:41,970
cool stuff it's kind of a lot of things

00:20:40,830 --> 00:20:44,100
that we've been thinking about as well

00:20:41,970 --> 00:20:46,440
so my question is how do you deal with

00:20:44,100 --> 00:20:47,520
stale information so for example let's

00:20:46,440 --> 00:20:48,360
say you have a robot that goes down a

00:20:47,520 --> 00:20:50,100
really long aisle

00:20:48,360 --> 00:20:51,690
she's a forklift kind of parked there

00:20:50,100 --> 00:20:53,730
puts it in the map gives that to all the

00:20:51,690 --> 00:20:55,440
robots and now no robot is gonna plan

00:20:53,730 --> 00:20:57,029
down that path but eventually that

00:20:55,440 --> 00:21:01,740
thing's gonna go away so do you have any

00:20:57,029 --> 00:21:04,409
kind of decay so I mean the idea would

00:21:01,740 --> 00:21:07,440
if we have some semantic information

00:21:04,409 --> 00:21:10,520
from other sources like for example of

00:21:07,440 --> 00:21:13,520
warehouse management system so

00:21:10,520 --> 00:21:16,150
we have some information that we get

00:21:13,520 --> 00:21:18,680
from the custom for example where

00:21:16,150 --> 00:21:20,810
objects are located roughly in the

00:21:18,680 --> 00:21:23,960
warehouse is whether they have been

00:21:20,810 --> 00:21:25,490
manipulated or not of course in case of

00:21:23,960 --> 00:21:28,840
a forklift you have to make sure that

00:21:25,490 --> 00:21:32,230
this also gets streamed to your

00:21:28,840 --> 00:21:36,440
environment representation but I think

00:21:32,230 --> 00:21:41,510
if you have some semantic annotation

00:21:36,440 --> 00:21:46,490
that this object is a a volatile object

00:21:41,510 --> 00:21:48,950
that is moving you can then mark this

00:21:46,490 --> 00:21:54,950
area as an area with a high probability

00:21:48,950 --> 00:21:56,480
of being dynamic and also I know what

00:21:54,950 --> 00:21:58,250
you mean when you have when you have

00:21:56,480 --> 00:22:01,190
objects also Auto robots

00:21:58,250 --> 00:22:06,970
standing in hallways you which

00:22:01,190 --> 00:22:09,080
eventually map them to so I would then

00:22:06,970 --> 00:22:11,750
incorporate all the information we can

00:22:09,080 --> 00:22:15,260
gather from multi robot coordination and

00:22:11,750 --> 00:22:18,320
warehouse management system to define a

00:22:15,260 --> 00:22:21,650
prior that this is probably being

00:22:18,320 --> 00:22:25,120
resolved after some time yeah cool thank

00:22:21,650 --> 00:22:25,120
you thank you very much

00:22:25,310 --> 00:22:30,440

YouTube URL: https://www.youtube.com/watch?v=c3bl3EE3xzU


