Title: Introducing ROS RealSense 3D empowered Robotics Innovation ROSCon 2015 Hamburg Day 2 Amit Moran
Publication date: 2015-12-08
Playlist: ROSCon 2015
Description: 
	Unaltered video by Open Robotics from http://roscon.ros.org/2015 under the Attribution-NonCommercial-NoDerivs 3.0 Unported (CC BY-NC-ND 3.0) License https://creativecommons.org/licenses/by-nc-nd/3.0/
Captions: 
	00:00:00,000 --> 00:00:05,250
alright so sorry about that so I'm from

00:00:04,020 --> 00:00:07,589
the advanced technologies team in

00:00:05,250 --> 00:00:10,170
perceptual computing department at Intel

00:00:07,589 --> 00:00:12,780
and I'm going to talk about intel

00:00:10,170 --> 00:00:16,710
realsense and our robotics innovation

00:00:12,780 --> 00:00:18,359
program so I'm going to give a short

00:00:16,710 --> 00:00:21,000
introduction about what is intel

00:00:18,359 --> 00:00:23,850
realsense actually I guess not everyone

00:00:21,000 --> 00:00:25,680
knows what it is and then going to talk

00:00:23,850 --> 00:00:28,320
about our innovation program robotics

00:00:25,680 --> 00:00:30,779
innovation program what it is what is

00:00:28,320 --> 00:00:33,090
our goal and how are planning to achieve

00:00:30,779 --> 00:00:35,760
it going by summer in hopefully some

00:00:33,090 --> 00:00:38,700
questions so Wintel real sense

00:00:35,760 --> 00:00:41,070
technology what it is so wear it until

00:00:38,700 --> 00:00:44,579
probably have best sensor up there

00:00:41,070 --> 00:00:46,890
you're right possessor out there no I

00:00:44,579 --> 00:00:48,750
guess most people here using the posters

00:00:46,890 --> 00:00:52,770
for in the laptops in their researchers

00:00:48,750 --> 00:00:55,079
and we wanted to create this kind of new

00:00:52,770 --> 00:00:57,210
interaction this immersive into it even

00:00:55,079 --> 00:01:00,270
natural interaction with our computing

00:00:57,210 --> 00:01:03,420
devices via desktop laptops tablets and

00:01:00,270 --> 00:01:05,369
called smartphone large shaft and in

00:01:03,420 --> 00:01:08,360
order to do that we wanted to add senses

00:01:05,369 --> 00:01:11,640
to this brain that we are developing and

00:01:08,360 --> 00:01:14,640
so we need to be able to perceive the

00:01:11,640 --> 00:01:19,560
environment of the computing device so

00:01:14,640 --> 00:01:22,020
we created developed to depth sensors

00:01:19,560 --> 00:01:25,740
should I have them over here so they are

00:01:22,020 --> 00:01:28,229
extremely small and light and they have

00:01:25,740 --> 00:01:30,750
just a USB connection usb3 connection

00:01:28,229 --> 00:01:32,750
and one of them is a short range and

00:01:30,750 --> 00:01:35,430
it's a and inside but they were

00:01:32,750 --> 00:01:38,700
developed to be able to integrate into

00:01:35,430 --> 00:01:41,220
our ultrabooks in the tablets smart

00:01:38,700 --> 00:01:45,930
phone etc so they were small low power

00:01:41,220 --> 00:01:49,170
low cost and this is what our aim so we

00:01:45,930 --> 00:01:51,509
have those two and sensors one is the

00:01:49,170 --> 00:01:54,680
short range sensor for short-range

00:01:51,509 --> 00:01:58,159
interaction in front of the computer

00:01:54,680 --> 00:02:01,950
gesture recognition finger tracking

00:01:58,159 --> 00:02:04,770
facial recognition all kind of stuff

00:02:01,950 --> 00:02:06,570
like that and second sensor a long-range

00:02:04,770 --> 00:02:08,190
sensor is for what long-range

00:02:06,570 --> 00:02:10,979
interaction goes up to three and a half

00:02:08,190 --> 00:02:13,530
meters indoor and it is for scanning and

00:02:10,979 --> 00:02:17,100
the environment understanding and etc

00:02:13,530 --> 00:02:19,560
so I'll show you some before that

00:02:17,100 --> 00:02:22,740
actually and we said we want to create

00:02:19,560 --> 00:02:25,800
this in immersive interactions so we

00:02:22,740 --> 00:02:29,160
also provide an SDK and sdk comes with a

00:02:25,800 --> 00:02:30,989
set of capabilities is everything I said

00:02:29,160 --> 00:02:33,650
before just recognition and the facial

00:02:30,989 --> 00:02:35,880
recognition and stuff like that so

00:02:33,650 --> 00:02:37,770
application developers will be able to

00:02:35,880 --> 00:02:40,319
develop their application and to focus

00:02:37,770 --> 00:02:43,500
on their application not developing

00:02:40,319 --> 00:02:46,050
computer vision models and what I'm

00:02:43,500 --> 00:02:49,100
going to show now is kind of a video of

00:02:46,050 --> 00:02:58,260
kind of applications we are imagining

00:02:49,100 --> 00:03:01,550
inside into our world isn't one or two

00:02:58,260 --> 00:03:04,800
dimensional it's three-dimensional and

00:03:01,550 --> 00:03:06,870
with the integration of true 3d capable

00:03:04,800 --> 00:03:10,680
cameras across a range of Intel

00:03:06,870 --> 00:03:13,980
computing platforms so is your computing

00:03:10,680 --> 00:03:17,959
experience giving you the power to

00:03:13,980 --> 00:03:17,959
capture and share your world

00:03:20,910 --> 00:03:24,360
extend your reach

00:03:28,069 --> 00:03:39,950
express yourself in new ways create

00:03:32,719 --> 00:03:44,560
something dramatic how do I slices

00:03:39,950 --> 00:03:44,560
pepper learn something entirely new

00:03:44,799 --> 00:03:54,340
Sanders me connects how about this and

00:03:51,620 --> 00:03:54,340
collaborate

00:04:03,690 --> 00:04:09,760
full 3d computing is here today

00:04:06,930 --> 00:04:13,360
connecting you with what matters most in

00:04:09,760 --> 00:04:16,150
ways you will never imagined all you

00:04:13,360 --> 00:04:19,120
have to do that's all for now there's

00:04:16,150 --> 00:04:25,270
more to come this is just the beginning

00:04:19,120 --> 00:04:29,260
is look inside so this is just the

00:04:25,270 --> 00:04:30,520
beginning I am so obviously and what why

00:04:29,260 --> 00:04:33,480
is this a beginning why we're thinking

00:04:30,520 --> 00:04:35,680
what we saw here is just the beginning

00:04:33,480 --> 00:04:37,720
is because we started with this user

00:04:35,680 --> 00:04:39,400
facing technologies that we can actually

00:04:37,720 --> 00:04:41,800
interact with a computer and gesture

00:04:39,400 --> 00:04:44,920
recognition etc and he's already very

00:04:41,800 --> 00:04:47,320
exciting and we moved to this world

00:04:44,920 --> 00:04:51,310
facing interaction scanning and etc

00:04:47,320 --> 00:04:54,040
Tucson there in the video and which is

00:04:51,310 --> 00:04:56,170
kind of the next phase for that and

00:04:54,040 --> 00:04:59,890
we're looking at multi user interactions

00:04:56,170 --> 00:05:02,350
between users using our devices but the

00:04:59,890 --> 00:05:04,540
actual future is what kind if we are

00:05:02,350 --> 00:05:07,330
calling dynamic social interaction

00:05:04,540 --> 00:05:08,740
devices shouldn't be in our way should

00:05:07,330 --> 00:05:11,290
be able to interact with people with the

00:05:08,740 --> 00:05:14,980
environment and kind of the ubiquitous

00:05:11,290 --> 00:05:16,960
computing concept moving from human

00:05:14,980 --> 00:05:20,020
computer interaction to human world

00:05:16,960 --> 00:05:22,930
interaction and this is why wearables

00:05:20,020 --> 00:05:25,410
IOT and robots obviously are kind of the

00:05:22,930 --> 00:05:29,110
ultimate platform to use our technology

00:05:25,410 --> 00:05:33,250
and this is why we created this robotic

00:05:29,110 --> 00:05:36,190
innovation program in our team and we

00:05:33,250 --> 00:05:38,340
are trying to develop and we want to

00:05:36,190 --> 00:05:41,500
create this rapid cycles of innovation

00:05:38,340 --> 00:05:43,150
in the robotic world and we try to kind

00:05:41,500 --> 00:05:48,070
of developed nudging to encourage that

00:05:43,150 --> 00:05:51,430
and we are not robotics expert and what

00:05:48,070 --> 00:05:54,880
we want to do is to enable you everyone

00:05:51,430 --> 00:05:57,340
here to create innovation and you create

00:05:54,880 --> 00:06:01,380
the next big thing in robotics thanks to

00:05:57,340 --> 00:06:04,630
our realsense camera and technology and

00:06:01,380 --> 00:06:07,270
so we kind of did the research of it and

00:06:04,630 --> 00:06:08,920
looked around and we can find out that

00:06:07,270 --> 00:06:11,800
Ross is probably the best button for

00:06:08,920 --> 00:06:14,700
that there is a lot of fair ecosystem

00:06:11,800 --> 00:06:17,460
the developer researchers and

00:06:14,700 --> 00:06:19,170
and now is this abstraction layer and it

00:06:17,460 --> 00:06:23,040
is extremely important because we can

00:06:19,170 --> 00:06:26,460
already tapping existing capabilities

00:06:23,040 --> 00:06:28,010
and applications and when we thought

00:06:26,460 --> 00:06:32,340
that this is going to be really nice

00:06:28,010 --> 00:06:36,840
using our technology so we started a

00:06:32,340 --> 00:06:39,180
year ago in April 15 we started a pilot

00:06:36,840 --> 00:06:40,740
program with some selected universities

00:06:39,180 --> 00:06:42,810
and we gathered feedback and

00:06:40,740 --> 00:06:48,150
requirements really try to understand

00:06:42,810 --> 00:06:50,070
what you guys need and then and then the

00:06:48,150 --> 00:06:52,560
request started to come along but a lot

00:06:50,070 --> 00:06:55,310
of tractions from PG students from

00:06:52,560 --> 00:06:57,960
research facilities from companies and

00:06:55,310 --> 00:07:01,010
people wanted our sensors our software

00:06:57,960 --> 00:07:06,210
and after some internal discussions we

00:07:01,010 --> 00:07:08,550
decided to make our offering available

00:07:06,210 --> 00:07:11,460
for the old growth community following

00:07:08,550 --> 00:07:13,710
our CEO announcement and last August in

00:07:11,460 --> 00:07:16,410
the IDF the Intel development forum and

00:07:13,710 --> 00:07:18,240
it is already available it is an

00:07:16,410 --> 00:07:22,380
experimental code we're still developing

00:07:18,240 --> 00:07:25,500
it and we are going to add more features

00:07:22,380 --> 00:07:27,570
and to fix what we need but it's already

00:07:25,500 --> 00:07:31,440
available you can already go on download

00:07:27,570 --> 00:07:34,380
it and use it in your development and so

00:07:31,440 --> 00:07:37,290
what we're actually providing so

00:07:34,380 --> 00:07:40,440
obviously some of the camera access or

00:07:37,290 --> 00:07:43,020
the RGB data the depth data fi our point

00:07:40,440 --> 00:07:44,850
cloud and we're planning to provide some

00:07:43,020 --> 00:07:47,880
basic computer vision models like a

00:07:44,850 --> 00:07:50,700
plane analyzes blood protections and

00:07:47,880 --> 00:07:53,460
some advanced models if you are more

00:07:50,700 --> 00:07:55,110
interested in creating this human robot

00:07:53,460 --> 00:07:57,420
interaction so personal detection

00:07:55,110 --> 00:08:00,690
skeleton adjust your object recognition

00:07:57,420 --> 00:08:04,410
and you can all decide what you want to

00:08:00,690 --> 00:08:05,550
use out of this package and so the coins

00:08:04,410 --> 00:08:07,680
that I'm going to show you some of the

00:08:05,550 --> 00:08:10,710
stuff we're developing it it's under

00:08:07,680 --> 00:08:12,690
development but I thought it would be

00:08:10,710 --> 00:08:14,250
interesting to share with you so what we

00:08:12,690 --> 00:08:16,230
have just a set that we have kind of a

00:08:14,250 --> 00:08:19,440
turtlebot and we have a real little

00:08:16,230 --> 00:08:21,330
sensor over there this mountain and one

00:08:19,440 --> 00:08:23,820
of the tools we are developing it what

00:08:21,330 --> 00:08:26,340
we call a depth enhancement it's

00:08:23,820 --> 00:08:26,740
basically set of filters that we can run

00:08:26,340 --> 00:08:29,560
on

00:08:26,740 --> 00:08:32,979
f data and we can see live how the depth

00:08:29,560 --> 00:08:35,620
data image changes how the point cloud

00:08:32,979 --> 00:08:37,300
changes and what's nice about that you

00:08:35,620 --> 00:08:41,469
can also develop your own filters and

00:08:37,300 --> 00:08:43,539
add it to this tool and basically see

00:08:41,469 --> 00:08:48,850
how what is the best configuration for

00:08:43,539 --> 00:08:50,620
your development another thing is well

00:08:48,850 --> 00:08:52,060
as I said Ross has this abstraction

00:08:50,620 --> 00:08:54,839
layer and we can use existing

00:08:52,060 --> 00:08:57,040
technologies and existing and

00:08:54,839 --> 00:08:59,709
capabilities people here developed or

00:08:57,040 --> 00:09:03,040
our open source so here you can see I

00:08:59,709 --> 00:09:06,839
always sensor monitor the same robot and

00:09:03,040 --> 00:09:10,870
using optimum app to 3d scan our lab and

00:09:06,839 --> 00:09:13,990
we're also 3d mapping it using the gene

00:09:10,870 --> 00:09:16,690
mapping so this is something which is

00:09:13,990 --> 00:09:18,520
you can just plug in and some other

00:09:16,690 --> 00:09:20,380
patient remapping and you have it out of

00:09:18,520 --> 00:09:22,330
the box so it's something very nice it

00:09:20,380 --> 00:09:26,320
is what we wanted to use is why we

00:09:22,330 --> 00:09:29,980
wanted to use Ross and so after we have

00:09:26,320 --> 00:09:31,420
a map we can also obviously and move

00:09:29,980 --> 00:09:34,089
around we're using the autonomous

00:09:31,420 --> 00:09:39,310
navigation of frost and with our sensors

00:09:34,089 --> 00:09:41,079
over later it is the number to boss

00:09:39,310 --> 00:09:43,360
today's with our laptop and do the

00:09:41,079 --> 00:09:45,839
Wobble and the matters to navigate there

00:09:43,360 --> 00:09:48,670
and we are basing leaving a 2d

00:09:45,839 --> 00:09:51,480
navigation goal and our little robot is

00:09:48,670 --> 00:09:53,770
is going and thanks for a 3d sensor and

00:09:51,480 --> 00:09:56,500
what I was an obstacle around here in

00:09:53,770 --> 00:09:59,079
our cubicle area so it recalculate your

00:09:56,500 --> 00:10:01,390
route and in managed to pass even though

00:09:59,079 --> 00:10:04,329
there is quite interesting path we

00:10:01,390 --> 00:10:05,829
decided to go through and it doesn't

00:10:04,329 --> 00:10:08,050
manage depth well because I well using

00:10:05,829 --> 00:10:09,970
the bumper sensors there and eventually

00:10:08,050 --> 00:10:11,770
actually it doesn't register Bell so

00:10:09,970 --> 00:10:16,390
this is quite nice and it is kind of a

00:10:11,770 --> 00:10:19,870
narrow place to go through and again we

00:10:16,390 --> 00:10:23,140
just adopted our sensor to Ross and we

00:10:19,870 --> 00:10:26,680
get all kind of cool capabilities out of

00:10:23,140 --> 00:10:30,600
the box we will now set a navigation

00:10:26,680 --> 00:10:33,449
goal today all right I'm

00:10:30,600 --> 00:10:35,310
next is a person tracking its we are

00:10:33,449 --> 00:10:38,550
it's under development it's very early

00:10:35,310 --> 00:10:41,310
but it's some stuff with you will see in

00:10:38,550 --> 00:10:43,829
the future here we are trying to tag the

00:10:41,310 --> 00:10:46,740
his gestures not actually the person the

00:10:43,829 --> 00:10:48,810
gestures the user of pointing where the

00:10:46,740 --> 00:10:53,579
robot should go to so it is just kind of

00:10:48,810 --> 00:10:55,170
some and research we're doing in I lab

00:10:53,579 --> 00:10:56,459
how it is the best way to do it but

00:10:55,170 --> 00:11:00,449
these kind of things you'll be able to

00:10:56,459 --> 00:11:06,630
see and in our models in our packet in

00:11:00,449 --> 00:11:09,269
the future another another thing which

00:11:06,630 --> 00:11:11,370
is a think very interesting for most of

00:11:09,269 --> 00:11:13,980
the people here is that our sensor the

00:11:11,370 --> 00:11:17,040
log rate sensor works also outside has

00:11:13,980 --> 00:11:20,089
some noise but it works for inside and

00:11:17,040 --> 00:11:23,339
outside and you get some good obstacle

00:11:20,089 --> 00:11:26,100
identification and this is in full

00:11:23,339 --> 00:11:30,180
sunlight mode you can see it's very hot

00:11:26,100 --> 00:11:31,740
this day and then clicking I mean we

00:11:30,180 --> 00:11:33,990
have some partners or say that they get

00:11:31,740 --> 00:11:37,170
up to 10 meters of information outside

00:11:33,990 --> 00:11:38,970
so this is a trick it's quite useful

00:11:37,170 --> 00:11:45,500
because it works also inside and outside

00:11:38,970 --> 00:11:47,870
I last I wanted to show some work of

00:11:45,500 --> 00:11:51,899
university is actually hearing me in a

00:11:47,870 --> 00:11:56,009
here in Germany and the top one is using

00:11:51,899 --> 00:11:58,110
our short-range camera and the button

00:11:56,009 --> 00:12:06,740
one is using language camera most of

00:11:58,110 --> 00:12:06,740
them are using that's great alright

00:12:10,320 --> 00:12:23,620
corrections alright so both of them are

00:12:20,740 --> 00:12:25,390
doing kind of scanning the at the bottom

00:12:23,620 --> 00:12:28,120
one from technical university of mill

00:12:25,390 --> 00:12:32,250
hand is doing 3d scanning of their lab

00:12:28,120 --> 00:12:32,250
and they're using an open-source

00:12:34,290 --> 00:12:41,020
algorithm the top one is a 3d scanning

00:12:37,510 --> 00:12:43,839
some objects and so this is very

00:12:41,020 --> 00:12:45,760
exciting because again it was possible

00:12:43,839 --> 00:12:47,920
to be done just because it was available

00:12:45,760 --> 00:12:50,589
on the Ross and people can take it and

00:12:47,920 --> 00:12:52,750
do stuff with it which is the top one is

00:12:50,589 --> 00:12:58,240
Patrick is here somewhere and it is even

00:12:52,750 --> 00:12:59,709
3d 3d printed himself so I guess to give

00:12:58,240 --> 00:13:04,180
him to give it to his mom or something

00:12:59,709 --> 00:13:05,770
to know it's really really exciting to

00:13:04,180 --> 00:13:10,050
see already some people taking the

00:13:05,770 --> 00:13:12,399
technique the sensory taking there yeah

00:13:10,050 --> 00:13:16,750
taking the technology and creating

00:13:12,399 --> 00:13:19,180
something or some out of that so just a

00:13:16,750 --> 00:13:20,770
summary for what we saw with a huge pool

00:13:19,180 --> 00:13:22,270
do is we'll need also we talked you toys

00:13:20,770 --> 00:13:23,860
RF and there is a real need in the

00:13:22,270 --> 00:13:25,990
robotics community for those kind of

00:13:23,860 --> 00:13:27,850
sensors and we think there is a really

00:13:25,990 --> 00:13:30,760
competitive advantage because of the

00:13:27,850 --> 00:13:34,140
size of the low cost of the low weight

00:13:30,760 --> 00:13:36,700
and etc and then we're hoping that

00:13:34,140 --> 00:13:39,640
actually you guys can take this kind of

00:13:36,700 --> 00:13:41,050
things and create your innovation tell

00:13:39,640 --> 00:13:43,329
us what you need because you're still

00:13:41,050 --> 00:13:47,170
understanding and we still want to make

00:13:43,329 --> 00:13:50,010
something that is good for you so this

00:13:47,170 --> 00:13:50,010
is why it's just the beginning

00:13:51,500 --> 00:13:56,340
ok the question was a low-cost can I

00:13:54,120 --> 00:14:01,380
give an indication so yes it is

00:13:56,340 --> 00:14:03,300
available for pre-order and in the short

00:14:01,380 --> 00:14:05,580
range is available to order already it's

00:14:03,300 --> 00:14:07,410
a developer platform I think it's a

00:14:05,580 --> 00:14:09,780
hundred dollars right a hundred dollars

00:14:07,410 --> 00:14:12,960
and the same is for the long-range

00:14:09,780 --> 00:14:21,260
sensor at the asset developer and as a

00:14:12,960 --> 00:14:21,260
developer kit the model is $65 alright

00:14:26,240 --> 00:14:39,860
how many cameras sensors the real sense

00:14:28,680 --> 00:14:39,860
support in parallel it support sorry I

00:14:42,170 --> 00:14:49,680
so and so how many camera it's afford

00:14:47,610 --> 00:14:52,050
support so we have two cameras actually

00:14:49,680 --> 00:14:54,810
alright so as I said those 20 cameras

00:14:52,050 --> 00:14:57,390
are the real sense cameras and you can

00:14:54,810 --> 00:15:00,840
connect a long-range camera you can

00:14:57,390 --> 00:15:02,790
connect many of those we try the I think

00:15:00,840 --> 00:15:04,860
one of our partners try to connect think

00:15:02,790 --> 00:15:06,540
10 de cuisine parallel into work quite

00:15:04,860 --> 00:15:08,340
good there is no interference sense

00:15:06,540 --> 00:15:10,710
because of the technology so you can

00:15:08,340 --> 00:15:15,690
even like connect like look at the same

00:15:10,710 --> 00:15:17,160
thing and so yeah so we can connect

00:15:15,690 --> 00:15:20,030
several of them 10 of them and those

00:15:17,160 --> 00:15:20,030

YouTube URL: https://www.youtube.com/watch?v=EFNU1Nkqa_M


