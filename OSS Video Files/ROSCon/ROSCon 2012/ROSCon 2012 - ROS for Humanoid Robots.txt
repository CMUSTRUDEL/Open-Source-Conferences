Title: ROSCon 2012 - ROS for Humanoid Robots
Publication date: 2014-08-31
Playlist: ROSCon 2012
Description: 
	Armin Hornung
ROS for Humanoid Robots

Slides: http://www.informatik.uni-freiburg.de/~hornunga/pub/hornung12roscon.pdf
Captions: 
	00:00:00,560 --> 00:00:06,810
so next up is Armand Horton who's going

00:00:04,140 --> 00:00:08,429
to tell us about using Ross on humanoid

00:00:06,810 --> 00:00:11,880
robots I think specifically the elder

00:00:08,429 --> 00:00:15,990
brown now amongst others amongst others

00:00:11,880 --> 00:00:18,320
all right all right thank you Brian so

00:00:15,990 --> 00:00:21,210
I'm arming horny university of freiburg

00:00:18,320 --> 00:00:23,970
and aaron working in the humid robots

00:00:21,210 --> 00:00:26,550
lab and kind of topic i'm working and

00:00:23,970 --> 00:00:28,260
interested in is a humanoid robot

00:00:26,550 --> 00:00:35,550
navigation in complex indoor

00:00:28,260 --> 00:00:37,800
environments so first of all it's not

00:00:35,550 --> 00:00:40,200
all of you have a background in humid

00:00:37,800 --> 00:00:41,610
robotics let motivate why do you want to

00:00:40,200 --> 00:00:45,149
work with you my robots where do you

00:00:41,610 --> 00:00:48,090
want to sort of apply them thing is well

00:00:45,149 --> 00:00:49,530
the pr2 robot is great you can just put

00:00:48,090 --> 00:00:51,449
it in any environment it will work there

00:00:49,530 --> 00:00:53,039
eventually we want to put these personal

00:00:51,449 --> 00:00:55,890
robots in the home we want them for our

00:00:53,039 --> 00:00:58,079
elder care or home assistance and daddy

00:00:55,890 --> 00:01:00,750
I just said these robots then we'll

00:00:58,079 --> 00:01:04,530
actually be able to navigate and and

00:01:00,750 --> 00:01:07,590
work in all environments which which

00:01:04,530 --> 00:01:10,500
Williamson naturally are able to work

00:01:07,590 --> 00:01:11,970
and live in so national choice is to

00:01:10,500 --> 00:01:14,280
build these robots which are designed

00:01:11,970 --> 00:01:16,470
like a human so then they find a way and

00:01:14,280 --> 00:01:18,930
they can cope with these environments

00:01:16,470 --> 00:01:20,670
made for humans and if you look at the

00:01:18,930 --> 00:01:23,520
top right grin challenge this year then

00:01:20,670 --> 00:01:26,310
rhetoric but we've probably seen the

00:01:23,520 --> 00:01:29,159
picture then the idea here is that we

00:01:26,310 --> 00:01:31,380
have a disaster zone which is a human

00:01:29,159 --> 00:01:33,390
workplace we have stairs here we have

00:01:31,380 --> 00:01:35,220
lots of clutter where the robots has to

00:01:33,390 --> 00:01:38,100
step into we have on the I even terrain

00:01:35,220 --> 00:01:39,299
so we really see the trend that this is

00:01:38,100 --> 00:01:41,939
the kind of environment that you want to

00:01:39,299 --> 00:01:43,890
apply robot which is kind of shaped like

00:01:41,939 --> 00:01:46,259
a human it can operate human equipment

00:01:43,890 --> 00:01:48,479
your machinery like valves to close sort

00:01:46,259 --> 00:01:51,630
of power tool to breaking walls we'll

00:01:48,479 --> 00:01:53,970
see if that actually happens but you see

00:01:51,630 --> 00:01:55,829
that I mean the choices we don't want to

00:01:53,970 --> 00:01:57,930
send humans there but we want robots

00:01:55,829 --> 00:02:01,590
which can operate things just as such as

00:01:57,930 --> 00:02:04,520
we humans can do but there are a couple

00:02:01,590 --> 00:02:07,140
of challenges with human robots robots

00:02:04,520 --> 00:02:08,580
first of all most is we have many

00:02:07,140 --> 00:02:10,500
degrees of freedom to control if you

00:02:08,580 --> 00:02:13,319
look at the now down there just like a

00:02:10,500 --> 00:02:15,689
very small and relatively simple email

00:02:13,319 --> 00:02:17,700
say it has already 25 degrees of freedom

00:02:15,689 --> 00:02:19,230
feel asleep more complex robots like

00:02:17,700 --> 00:02:21,030
asking would have 30 40 or even 50

00:02:19,230 --> 00:02:23,159
degrees of freedom to control and then

00:02:21,030 --> 00:02:26,489
we have a free 43 a free-floating base

00:02:23,159 --> 00:02:30,030
so while the robot walks its base is

00:02:26,489 --> 00:02:31,670
shaking and back and forth so this X

00:02:30,030 --> 00:02:33,959
almost like a UAV you could say

00:02:31,670 --> 00:02:35,430
environment while it's walking we have

00:02:33,959 --> 00:02:37,109
they're quite lightweight sensors

00:02:35,430 --> 00:02:38,849
attached to the robot because everything

00:02:37,109 --> 00:02:40,319
we pack on the robot robot has to carry

00:02:38,849 --> 00:02:41,879
some need to stronger motors in the legs

00:02:40,319 --> 00:02:43,680
to support the weight which again

00:02:41,879 --> 00:02:45,959
requires stronger battery increase the

00:02:43,680 --> 00:02:47,909
weight again so this is kind of trouble

00:02:45,959 --> 00:02:50,129
we have noisy standards we have like my

00:02:47,909 --> 00:02:51,510
sensors which don't gives us the high

00:02:50,129 --> 00:02:53,099
quality data that we want like on a

00:02:51,510 --> 00:02:55,199
wheeled platform I compared to where we

00:02:53,099 --> 00:02:57,989
can just put in two big service to do

00:02:55,199 --> 00:02:59,040
all the processing for us the end of

00:02:57,989 --> 00:03:01,980
thing is since we have the stepping

00:02:59,040 --> 00:03:03,569
motions with quite some drift here the

00:03:01,980 --> 00:03:05,129
robot tries to walk on a straight line

00:03:03,569 --> 00:03:06,689
you see that it really tripped seriously

00:03:05,129 --> 00:03:09,810
to the right already on this short

00:03:06,689 --> 00:03:11,909
distance because every every step you

00:03:09,810 --> 00:03:13,109
make there's a contact with the feet and

00:03:11,909 --> 00:03:15,180
if the contact isn't perfect or the

00:03:13,109 --> 00:03:18,109
robot isn't calibrated perfect then this

00:03:15,180 --> 00:03:21,419
creates quite some emotion noise here

00:03:18,109 --> 00:03:23,250
these are the challenges so let's start

00:03:21,419 --> 00:03:25,109
with some review of suitable Ross

00:03:23,250 --> 00:03:27,479
packages generally geared towards

00:03:25,109 --> 00:03:31,379
humanoid robots we see them now on the

00:03:27,479 --> 00:03:33,419
right people at last working already on

00:03:31,379 --> 00:03:35,939
getting the Romeo which is next bigger

00:03:33,419 --> 00:03:39,239
humanoid from a LeBron into Ross here's

00:03:35,939 --> 00:03:40,530
the HRP too so the first thing is since

00:03:39,239 --> 00:03:41,639
we have all these degrees of freedom we

00:03:40,530 --> 00:03:43,620
have all these sensors attached to the

00:03:41,639 --> 00:03:48,030
robot it's really important to get your

00:03:43,620 --> 00:03:49,409
DF and TF right at the beginning so we

00:03:48,030 --> 00:03:51,120
want coordinate transforms to all the

00:03:49,409 --> 00:03:52,769
joints you want or difference forms to

00:03:51,120 --> 00:03:54,479
all the sensors eventually you want to

00:03:52,769 --> 00:03:56,909
know like what's the camera looking at

00:03:54,479 --> 00:03:59,280
and where is it located to respect to

00:03:56,909 --> 00:04:01,829
the for example the right foot so we eat

00:03:59,280 --> 00:04:03,269
TF in there and there we have some ways

00:04:01,829 --> 00:04:06,750
to standardize dis dis transforms

00:04:03,269 --> 00:04:09,449
there's our EP 105 for mobile basis we

00:04:06,750 --> 00:04:11,189
have localization running there's map

00:04:09,449 --> 00:04:13,109
transformed organization gives us

00:04:11,189 --> 00:04:15,629
transform of the autumn frame in the map

00:04:13,109 --> 00:04:17,099
and which finally leads to the base link

00:04:15,629 --> 00:04:20,880
and the base link for this humid robot

00:04:17,099 --> 00:04:22,529
is something like in the torso here the

00:04:20,880 --> 00:04:26,669
HRP is I think it's down here because it

00:04:22,529 --> 00:04:29,650
has this articulated hip joint same here

00:04:26,669 --> 00:04:30,940
but then we have a couple of more joints

00:04:29,650 --> 00:04:33,669
which are specific to this humanoid

00:04:30,940 --> 00:04:36,700
robots and just recently we kind of got

00:04:33,669 --> 00:04:38,500
this are a PE 120 which tells you how

00:04:36,700 --> 00:04:41,380
these joints are named because you can

00:04:38,500 --> 00:04:43,600
just rename joints in TF I just like

00:04:41,380 --> 00:04:46,120
like topics so it's good to have a

00:04:43,600 --> 00:04:48,700
common naming scheme for the joints and

00:04:46,120 --> 00:04:52,000
what they mean so there is a the base

00:04:48,700 --> 00:04:53,970
footprint on a mobile base this is

00:04:52,000 --> 00:04:56,919
rigidly attached to the base link

00:04:53,970 --> 00:04:58,240
project it onto the floor but these

00:04:56,919 --> 00:04:59,800
humid robots are walking you've seen the

00:04:58,240 --> 00:05:02,260
swaying motion so what you want is kind

00:04:59,800 --> 00:05:03,910
of a stable projection to the ground so

00:05:02,260 --> 00:05:05,470
we can use 2d path planning and we don't

00:05:03,910 --> 00:05:07,330
want this to move back and forth so this

00:05:05,470 --> 00:05:09,250
is like the base footprint gives you a

00:05:07,330 --> 00:05:11,080
stable reference frame projected on the

00:05:09,250 --> 00:05:14,979
ground between the feet what seater than

00:05:11,080 --> 00:05:17,620
the demo towards the end torso is that

00:05:14,979 --> 00:05:21,160
comes the upper body with now it's it's

00:05:17,620 --> 00:05:22,780
the same link as the base link otherwise

00:05:21,160 --> 00:05:24,700
it's the reference frame for the upper

00:05:22,780 --> 00:05:26,860
body so all your manipulation change

00:05:24,700 --> 00:05:28,450
start there then we have the case which

00:05:26,860 --> 00:05:31,090
tells us which direction robot is

00:05:28,450 --> 00:05:32,860
looking so this is like a camera frame

00:05:31,090 --> 00:05:34,660
but it gives you like the more the back

00:05:32,860 --> 00:05:37,090
the appearance word robot is looking for

00:05:34,660 --> 00:05:38,530
example for human-robot interaction the

00:05:37,090 --> 00:05:40,600
end effectors of the arms to left and

00:05:38,530 --> 00:05:42,340
right gripper and finally the soles

00:05:40,600 --> 00:05:45,490
which are important for walking pattern

00:05:42,340 --> 00:05:48,430
generation and for footstep planning so

00:05:45,490 --> 00:05:50,350
with this already and and we all get our

00:05:48,430 --> 00:05:51,940
you might robots throw you are the F in

00:05:50,350 --> 00:05:53,440
there I put in arvest you can already

00:05:51,940 --> 00:05:58,000
get some really nice visualization of

00:05:53,440 --> 00:06:00,700
what's going on so let's look at some

00:05:58,000 --> 00:06:02,500
other tools which are kind of available

00:06:00,700 --> 00:06:05,139
in Ross and the first thing is we want

00:06:02,500 --> 00:06:06,280
to manipulate the environment so there

00:06:05,139 --> 00:06:08,229
comes the under if occasionally we've

00:06:06,280 --> 00:06:10,660
already heard about it Omni vacation

00:06:08,229 --> 00:06:12,190
wizard and this already works really

00:06:10,660 --> 00:06:17,130
really well as long as you have a single

00:06:12,190 --> 00:06:17,130
chain so we see on the top here

00:06:19,090 --> 00:06:24,470
yeah so this is a like navigation you

00:06:22,790 --> 00:06:25,970
could call it so this is the army

00:06:24,470 --> 00:06:28,840
vacation wizard apply to the leg chain

00:06:25,970 --> 00:06:31,370
of the now we can have ik control there

00:06:28,840 --> 00:06:34,130
and we could do the same with the arms

00:06:31,370 --> 00:06:36,080
but usually we don't want to control

00:06:34,130 --> 00:06:38,450
single chains because you see this is a

00:06:36,080 --> 00:06:41,060
quite limited to work space this robot

00:06:38,450 --> 00:06:42,500
so we want to bend forward you want to

00:06:41,060 --> 00:06:44,480
do more interesting things you can all

00:06:42,500 --> 00:06:46,520
see that once we start articulating this

00:06:44,480 --> 00:06:48,620
leg robot will eventually fall over it

00:06:46,520 --> 00:06:50,030
doesn't stabilize because it cannot

00:06:48,620 --> 00:06:51,890
stand like this under on the left leg so

00:06:50,030 --> 00:06:53,360
there are additional constraints we need

00:06:51,890 --> 00:06:56,570
to move into and we need to eventually

00:06:53,360 --> 00:06:59,690
go to beyond single chain planning and

00:06:56,570 --> 00:07:02,900
that's already heard you on this morning

00:06:59,690 --> 00:07:04,850
will be in the next evil evolution of

00:07:02,900 --> 00:07:06,230
the Omni vacation stack will closely

00:07:04,850 --> 00:07:09,550
working on that on getting the whole

00:07:06,230 --> 00:07:11,690
body motion planning with move it and

00:07:09,550 --> 00:07:15,170
actually what you see down there is

00:07:11,690 --> 00:07:16,610
already in move it so we start with the

00:07:15,170 --> 00:07:17,810
omni regression then we're now at the

00:07:16,610 --> 00:07:23,900
stage waves the same functionality and

00:07:17,810 --> 00:07:26,120
move it plus stability constraints so

00:07:23,900 --> 00:07:27,830
let's get to sensing and perception this

00:07:26,120 --> 00:07:30,080
is basically working of the box right if

00:07:27,830 --> 00:07:32,540
we have to write TF transforms to our

00:07:30,080 --> 00:07:35,600
sensors we have all kinds of sensors

00:07:32,540 --> 00:07:38,510
integrated roles like the Ouya here

00:07:35,600 --> 00:07:40,670
we're doing 3d laser scans then running

00:07:38,510 --> 00:07:43,100
a plane segmentation to detect stairs in

00:07:40,670 --> 00:07:46,910
the 3d laser scans which we then can

00:07:43,100 --> 00:07:48,230
advance to to climb these stairs still

00:07:46,910 --> 00:07:51,350
just looking at look at look up the

00:07:48,230 --> 00:07:53,450
publication there but otherwise this is

00:07:51,350 --> 00:07:56,210
really working here people at last are

00:07:53,450 --> 00:07:58,550
using stereo vision their stereo cameras

00:07:56,210 --> 00:08:00,680
running on the HRP and just recently we

00:07:58,550 --> 00:08:02,870
got these nice asus RGB d cameras which

00:08:00,680 --> 00:08:07,580
we put on them now and so we get a nice

00:08:02,870 --> 00:08:09,710
colored point clouds out so what you

00:08:07,580 --> 00:08:11,480
going to do with that you can build in

00:08:09,710 --> 00:08:13,400
the 3d environment map and eventually

00:08:11,480 --> 00:08:15,410
want to navigate in this environment so

00:08:13,400 --> 00:08:16,700
then we have the problem how can we

00:08:15,410 --> 00:08:18,620
localize in the environment and we've

00:08:16,700 --> 00:08:22,160
seen the shaking movements of the robot

00:08:18,620 --> 00:08:23,330
while it's walking this we seen that the

00:08:22,160 --> 00:08:27,020
center is swaying back and forth but

00:08:23,330 --> 00:08:29,360
it's also rolling and this environment

00:08:27,020 --> 00:08:30,740
is not inherently 2d right there are

00:08:29,360 --> 00:08:31,910
stairs to multiple levels

00:08:30,740 --> 00:08:35,200
all kinds of clutter can be

00:08:31,910 --> 00:08:38,899
environmentally want is a 3d

00:08:35,200 --> 00:08:41,630
localization what we hear do is realize

00:08:38,899 --> 00:08:43,130
the 60 tour suppose we have XYZ roll

00:08:41,630 --> 00:08:44,870
pitch in your angles of the robot which

00:08:43,130 --> 00:08:48,080
way we estimate while it's walking in

00:08:44,870 --> 00:08:51,290
the environment so the 3d environment

00:08:48,080 --> 00:08:52,640
model we have a volumetric model in

00:08:51,290 --> 00:08:54,470
October where we perform the

00:08:52,640 --> 00:08:56,149
localization in and if they are we

00:08:54,470 --> 00:08:58,310
running Monte Carlo cool is Asian based

00:08:56,149 --> 00:09:00,440
on the laser sensor it's located here in

00:08:58,310 --> 00:09:02,839
the head mu data which gives us an

00:09:00,440 --> 00:09:04,040
estimate about the road and the

00:09:02,839 --> 00:09:07,100
proprioception which gives us an

00:09:04,040 --> 00:09:08,420
estimate of how high the robots torso is

00:09:07,100 --> 00:09:11,029
above the ground and we also get some

00:09:08,420 --> 00:09:13,339
ultimate reset of the proprioception so

00:09:11,029 --> 00:09:15,380
and all this is available in the

00:09:13,339 --> 00:09:17,360
ultimate weapon stack also the ray

00:09:15,380 --> 00:09:18,709
casting methods so we can from

00:09:17,360 --> 00:09:21,470
vocalization with your own sensors and

00:09:18,709 --> 00:09:22,790
if there's interested in getting this

00:09:21,470 --> 00:09:25,459
code out I think we can also publish

00:09:22,790 --> 00:09:27,260
this code so can run it for a humanoid

00:09:25,459 --> 00:09:29,390
even though it's kind of geared towards

00:09:27,260 --> 00:09:32,649
this now so if there's interest just let

00:09:29,390 --> 00:09:36,230
me know we'll see a quick movie about it

00:09:32,649 --> 00:09:38,860
so this is this kind of scale town toy

00:09:36,230 --> 00:09:41,450
environment for our now see the stairs

00:09:38,860 --> 00:09:43,040
this is the 3d environment model a lock

00:09:41,450 --> 00:09:44,209
to map I'll perform a global

00:09:43,040 --> 00:09:46,250
organization you see all the particles

00:09:44,209 --> 00:09:47,420
all over the place we integrate the

00:09:46,250 --> 00:09:49,190
first laser measurement and we have a

00:09:47,420 --> 00:09:51,560
couple of posts hypothesis here here

00:09:49,190 --> 00:09:53,209
also on the on the stairs while it's

00:09:51,560 --> 00:09:55,040
walking and continues to integrate more

00:09:53,209 --> 00:09:57,050
sensor data becomes more and more

00:09:55,040 --> 00:09:59,360
certain about its global localization

00:09:57,050 --> 00:10:07,370
and finally we have a really accurate

00:09:59,360 --> 00:10:09,920
localized 60 torso pose and this gives

00:10:07,370 --> 00:10:12,350
us some real nice results we get an

00:10:09,920 --> 00:10:14,149
error out of two or three centimeters

00:10:12,350 --> 00:10:16,760
but if you think of climbing stairs then

00:10:14,149 --> 00:10:19,399
this is not really enough so kind of

00:10:16,760 --> 00:10:23,360
went on and improved that and to do so

00:10:19,399 --> 00:10:26,959
we combined the mouse camera image with

00:10:23,360 --> 00:10:29,600
the laser localization in a one global

00:10:26,959 --> 00:10:30,740
particle filter so now the robot

00:10:29,600 --> 00:10:32,570
localizers with the laser and it

00:10:30,740 --> 00:10:34,399
improves this localization with this

00:10:32,570 --> 00:10:35,990
short range sensing where it compares

00:10:34,399 --> 00:10:38,750
edges in the camera images to with a

00:10:35,990 --> 00:10:42,279
known stare model you can we see three

00:10:38,750 --> 00:10:42,279
environment model and the localized post

00:10:46,869 --> 00:10:51,709
you see also that the field of view of

00:10:50,600 --> 00:10:53,089
the camera is quite narrow so it's

00:10:51,709 --> 00:10:56,029
looking left center and right on each

00:10:53,089 --> 00:10:58,160
step to localize and with this we can

00:10:56,029 --> 00:11:01,549
really accurately find the start of the

00:10:58,160 --> 00:11:04,239
staircase and start climbing it this is

00:11:01,549 --> 00:11:10,160
sped up a little bit you might notice

00:11:04,239 --> 00:11:12,559
it's not the fastest robot but yeah so

00:11:10,160 --> 00:11:15,019
it never actually misses a step here and

00:11:12,559 --> 00:11:16,999
you this the stair climbing behavior

00:11:15,019 --> 00:11:18,769
itself is actually open loop so in a

00:11:16,999 --> 00:11:20,209
small error of only one centimeter will

00:11:18,769 --> 00:11:22,009
already lead to a fall because robot

00:11:20,209 --> 00:11:23,959
will either bumper to the handrail or

00:11:22,009 --> 00:11:27,859
mr. step fall backwards or run into the

00:11:23,959 --> 00:11:30,649
front step interesting part is of course

00:11:27,859 --> 00:11:33,199
the spiral spiral part here which is a

00:11:30,649 --> 00:11:35,649
bit more complicated but performs just

00:11:33,199 --> 00:11:35,649
as well

00:11:46,490 --> 00:11:51,040
right so this is running in real time

00:11:48,170 --> 00:11:54,890
again so let's looking straight ahead

00:11:51,040 --> 00:11:58,100
this is the observation of likelihood to

00:11:54,890 --> 00:11:59,540
the edge model this is more peaked here

00:11:58,100 --> 00:12:02,600
and then it's integrating this with the

00:11:59,540 --> 00:12:03,890
laser into one final improved proposal

00:12:02,600 --> 00:12:06,279
distribution which it then uses for

00:12:03,890 --> 00:12:10,360
localization see that it's really moving

00:12:06,279 --> 00:12:10,360
accurate up to the stair edge

00:12:20,950 --> 00:12:28,810
go for it yeah so I think the whole

00:12:27,190 --> 00:12:35,440
sequence takes almost 10 minutes if you

00:12:28,810 --> 00:12:37,510
in real time all right so then we

00:12:35,440 --> 00:12:38,650
continued and like once the robot is up

00:12:37,510 --> 00:12:39,700
there what's supposed to do it maybe

00:12:38,650 --> 00:12:41,950
it's carrying some stuff you need to

00:12:39,700 --> 00:12:44,110
clean up and for getting down then we

00:12:41,950 --> 00:12:45,370
constructed this ramp which is a whole

00:12:44,110 --> 00:12:47,920
different problem but again we used a

00:12:45,370 --> 00:12:49,900
similar approach using edge detection in

00:12:47,920 --> 00:12:51,760
the camera image so it finds the

00:12:49,900 --> 00:12:54,280
beginning of the day after the ramp and

00:12:51,760 --> 00:12:55,600
you'll notice that this robot doesn't

00:12:54,280 --> 00:12:57,820
have any laser so this uses only the

00:12:55,600 --> 00:13:01,420
camera and the IMU to climb down the

00:12:57,820 --> 00:13:03,070
stair so it's slowly advancing to the

00:13:01,420 --> 00:13:05,320
stair edge attitude sorry between the

00:13:03,070 --> 00:13:06,970
RAM patch where it's expecting it then

00:13:05,320 --> 00:13:10,060
using the division data to confirm it's

00:13:06,970 --> 00:13:11,470
on the right position I think now it

00:13:10,060 --> 00:13:18,580
should be happy with all organizations

00:13:11,470 --> 00:13:20,170
good enough so now order to step forward

00:13:18,580 --> 00:13:21,430
it really you see the problem with

00:13:20,170 --> 00:13:23,290
humanoids you need to balance your

00:13:21,430 --> 00:13:24,520
center of mass and you have this feat to

00:13:23,290 --> 00:13:26,130
balance these are quite big further now

00:13:24,520 --> 00:13:28,900
but still it's challenging problem

00:13:26,130 --> 00:13:34,360
because now your support polygon is

00:13:28,900 --> 00:13:37,330
getting tilted by the ramp and made it

00:13:34,360 --> 00:13:38,670
again these are visualization artists

00:13:37,330 --> 00:13:40,480
you see the projected center of mass

00:13:38,670 --> 00:13:43,000
creates to compute from the robots

00:13:40,480 --> 00:13:44,680
current configuration and you don't see

00:13:43,000 --> 00:13:47,580
the polygons the actual but it is like

00:13:44,680 --> 00:13:52,030
the convex hull of the supporting foot

00:13:47,580 --> 00:13:53,590
and every couple of steps it then uses

00:13:52,030 --> 00:13:55,690
the IMU data in order to get its

00:13:53,590 --> 00:13:57,010
orientation right because doesn't any

00:13:55,690 --> 00:13:58,930
other other sensing it needs to use the

00:13:57,010 --> 00:14:01,480
IMU just to get the orientation right

00:13:58,930 --> 00:14:04,330
and this is this is like vision and I'm

00:14:01,480 --> 00:14:06,310
your data this is like fully sufficient

00:14:04,330 --> 00:14:09,790
to climb down this ramp which is like

00:14:06,310 --> 00:14:12,840
two meters long correct for all the

00:14:09,790 --> 00:14:12,840
motion lift as we ended

00:14:18,470 --> 00:14:25,100
small correction steps okay that's not

00:14:22,250 --> 00:14:26,660
much more happening so so now we've seen

00:14:25,100 --> 00:14:28,550
a navigation for humanoid robot so we've

00:14:26,660 --> 00:14:31,460
seen the localization part of navigation

00:14:28,550 --> 00:14:33,290
so next thing is what we actually want

00:14:31,460 --> 00:14:34,850
to do we don't want to perform 2d path

00:14:33,290 --> 00:14:36,680
planning well we can do that in open

00:14:34,850 --> 00:14:38,270
spaces but you must have this unique

00:14:36,680 --> 00:14:39,530
capability that in actually step over

00:14:38,270 --> 00:14:41,210
obstacles I don't have to walk around

00:14:39,530 --> 00:14:43,010
them but if they are planar obstacles

00:14:41,210 --> 00:14:44,960
are small enough they can step over them

00:14:43,010 --> 00:14:47,360
and we want to exploit this in a

00:14:44,960 --> 00:14:48,560
footstep planning and what we do there

00:14:47,360 --> 00:14:51,050
is we have a discrete set of footsteps

00:14:48,560 --> 00:14:53,000
transitions see on the top right this is

00:14:51,050 --> 00:14:54,320
this the stand spot stands foot and

00:14:53,000 --> 00:14:55,700
these are the set of foot sir

00:14:54,320 --> 00:14:58,700
transitions for a bigger role but it's

00:14:55,700 --> 00:15:00,380
not now this is like an HR p robot and

00:14:58,700 --> 00:15:03,260
with these foots of transitions we can

00:15:00,380 --> 00:15:05,600
perform a heuristic search such as a

00:15:03,260 --> 00:15:08,840
Star Wolf issues affixed on here is

00:15:05,600 --> 00:15:11,870
we've extended this so we can use s ppl

00:15:08,840 --> 00:15:14,240
and Ross now which is also used on the

00:15:11,870 --> 00:15:16,580
pr2 for navigation with motion

00:15:14,240 --> 00:15:19,700
primitives so here we've like this two

00:15:16,580 --> 00:15:21,290
discrete stepping motions then with s

00:15:19,700 --> 00:15:23,180
ppl we have nice property that we can

00:15:21,290 --> 00:15:24,980
use the any time repairing a star

00:15:23,180 --> 00:15:28,430
algorithm or efficiently planning with

00:15:24,980 --> 00:15:33,560
any time d star and what this looks like

00:15:28,430 --> 00:15:35,000
you see on the bottom right so here then

00:15:33,560 --> 00:15:36,440
now is navigating these are the plan

00:15:35,000 --> 00:15:38,060
footsteps are pretty dense because it's

00:15:36,440 --> 00:15:40,120
my own small step in range and now you

00:15:38,060 --> 00:15:42,710
see a small change in the environment

00:15:40,120 --> 00:15:45,610
and it immediately replants around this

00:15:42,710 --> 00:15:48,350
this is the any time g-star algorithm

00:15:45,610 --> 00:15:50,720
you skip forward once you have the

00:15:48,350 --> 00:15:52,460
footstep locations either you have a min

00:15:50,720 --> 00:15:54,500
then how do you going to walk on them

00:15:52,460 --> 00:15:55,910
that's the question so for this you need

00:15:54,500 --> 00:15:57,890
to generate I'm walking motion we've

00:15:55,910 --> 00:16:01,370
seen the do we have this high number of

00:15:57,890 --> 00:16:02,900
degrees of freedom so one thing is you

00:16:01,370 --> 00:16:04,340
can have an out-of-the-box walking

00:16:02,900 --> 00:16:06,110
controller for them now we have put some

00:16:04,340 --> 00:16:08,000
control or omnidirectional velocity

00:16:06,110 --> 00:16:09,230
control with footstep controller we can

00:16:08,000 --> 00:16:11,600
actually directly walk on these

00:16:09,230 --> 00:16:14,330
locations and for other robots the

00:16:11,600 --> 00:16:15,920
people at last Thomas will are they

00:16:14,330 --> 00:16:17,510
develop the humid walk stack which is

00:16:15,920 --> 00:16:20,060
already available so given foots up

00:16:17,510 --> 00:16:23,780
locations you can plan the actual joint

00:16:20,060 --> 00:16:26,540
trajectory so let's quickly skip to the

00:16:23,780 --> 00:16:29,050
overview of the now in Ross and how it's

00:16:26,540 --> 00:16:31,330
making use of all of this

00:16:29,050 --> 00:16:34,060
so the basic API is in the now driver

00:16:31,330 --> 00:16:38,110
package what this does is it wraps the

00:16:34,060 --> 00:16:40,930
other brands now he API in Python so you

00:16:38,110 --> 00:16:42,670
can put this on the robot or off aboard

00:16:40,930 --> 00:16:44,080
the robot you can runs on your laptop

00:16:42,670 --> 00:16:46,870
and it connects to the robot with a

00:16:44,080 --> 00:16:50,290
standard API and forwards all the

00:16:46,870 --> 00:16:51,850
important stuff in raw spy you're the f

00:16:50,290 --> 00:16:53,829
and he'll operation is in our common and

00:16:51,850 --> 00:16:54,940
we have odometry and projected base

00:16:53,829 --> 00:16:57,070
footprint since this needs to be

00:16:54,940 --> 00:16:59,140
computed so it's a stable projection on

00:16:57,070 --> 00:17:03,100
the ground this is an extra note running

00:16:59,140 --> 00:17:05,020
in our remote so quick overview this

00:17:03,100 --> 00:17:06,850
stuff needs to run on the robot or off

00:17:05,020 --> 00:17:09,250
the robot and this usually runs off the

00:17:06,850 --> 00:17:10,740
robot here we see the sensors which give

00:17:09,250 --> 00:17:14,199
us an estimate of the joint positions

00:17:10,740 --> 00:17:16,209
and also the new angles odometry all

00:17:14,199 --> 00:17:18,429
this gets into the robot State publisher

00:17:16,209 --> 00:17:21,760
and remove odometry which creates the

00:17:18,429 --> 00:17:24,130
odometry extra drama tree from this but

00:17:21,760 --> 00:17:26,020
we got one control in our controller now

00:17:24,130 --> 00:17:27,640
Walker which is accepting the the

00:17:26,020 --> 00:17:29,650
footstep and the walking commands and we

00:17:27,640 --> 00:17:32,679
can control this with a simple game bit

00:17:29,650 --> 00:17:34,510
o show you in a minute finally for

00:17:32,679 --> 00:17:36,400
diagnostic debugging there's a

00:17:34,510 --> 00:17:38,050
diagnostic updater and the dashboard so

00:17:36,400 --> 00:17:39,809
we can get an overview of the health of

00:17:38,050 --> 00:17:42,520
the system you get battery we have the

00:17:39,809 --> 00:17:44,230
joint state and also the kind of the

00:17:42,520 --> 00:17:47,110
temperature of the service which tend to

00:17:44,230 --> 00:17:50,400
run hot after a while so let's quickly

00:17:47,110 --> 00:17:50,400
soup to a live demo

00:17:55,160 --> 00:18:00,900
so first thing I'm going to do is start

00:17:58,950 --> 00:18:04,890
simulated now on my machine here I

00:18:00,900 --> 00:18:16,340
didn't bring any sorry then I'm going to

00:18:04,890 --> 00:18:16,340
start the notes the driver notes for now

00:18:24,790 --> 00:18:33,790
so we don't see anything here yet all

00:18:32,770 --> 00:18:37,480
right this is the stuff that's running

00:18:33,790 --> 00:18:39,640
right now we got the 33 notes for them

00:18:37,480 --> 00:18:42,120
now and then we're connecting this with

00:18:39,640 --> 00:18:42,120
the remote

00:18:47,720 --> 00:18:53,840
alright and this gives us a connection

00:18:50,809 --> 00:18:56,090
of the sensor nodes and the controller

00:18:53,840 --> 00:18:57,950
for joint attract reactions we got the

00:18:56,090 --> 00:19:03,380
Walker here which didn't receive

00:18:57,950 --> 00:19:13,580
anything yet so now we can look at the

00:19:03,380 --> 00:19:19,039
TF visualization quite dense and the

00:19:13,580 --> 00:19:20,740
robot model alright this is a simple

00:19:19,039 --> 00:19:22,669
visualization of the now we have an

00:19:20,740 --> 00:19:28,220
extended one which is using the

00:19:22,669 --> 00:19:42,650
propriety measures from algebra on check

00:19:28,220 --> 00:19:46,370
so we get a nice utilization alright so

00:19:42,650 --> 00:19:50,059
here's our now or in Ross what I can do

00:19:46,370 --> 00:19:52,630
now is I can tell up it with a with the

00:19:50,059 --> 00:19:52,630
gamepad

00:20:18,970 --> 00:20:25,390
alright so it started so here i have a

00:20:23,740 --> 00:20:27,010
meter external control i can let it walk

00:20:25,390 --> 00:20:30,970
straight i can go let it walk sideways

00:20:27,010 --> 00:20:33,460
and perform rotations this is always a

00:20:30,970 --> 00:20:38,250
standard ross gamepad driver rustic

00:20:33,460 --> 00:20:42,520
driver and i can also perform like

00:20:38,250 --> 00:20:46,600
single body poses and do a head tracking

00:20:42,520 --> 00:20:50,559
with that and think we're running out of

00:20:46,600 --> 00:20:52,360
time so i may give you show you some

00:20:50,559 --> 00:20:54,850
more stuff afterwards at the maybe

00:20:52,360 --> 00:20:58,530
letting talks or at the reception later

00:20:54,850 --> 00:20:58,530
if you're interested in running them now

00:21:05,090 --> 00:21:07,780
ok

00:21:08,440 --> 00:21:19,759
so just real quick I can show you how

00:21:11,210 --> 00:21:22,489
can use puts the planner which uses

00:21:19,759 --> 00:21:24,259
arvest as a as a GUI so now the foot sub

00:21:22,489 --> 00:21:28,159
panel is running background i have this

00:21:24,259 --> 00:21:29,570
2d map with planar obstacles i can give

00:21:28,159 --> 00:21:31,519
a 2d poses to met which tells the

00:21:29,570 --> 00:21:34,759
footstep enter the starting post give

00:21:31,519 --> 00:21:41,869
the two teen ethical example here now

00:21:34,759 --> 00:21:44,509
it's planning and we get a footstep

00:21:41,869 --> 00:21:47,559
trajectory for this robot which is

00:21:44,509 --> 00:21:47,559
stepping over the obstacles

00:21:52,549 --> 00:21:59,820
ok

00:21:55,049 --> 00:22:01,499
so let me wrap up here above I could

00:21:59,820 --> 00:22:04,440
give you a small review of suitable Ross

00:22:01,499 --> 00:22:07,200
packages which are for working for you

00:22:04,440 --> 00:22:10,409
melt robots we've seen that the

00:22:07,200 --> 00:22:11,970
manipulation and kin kinematics nodes

00:22:10,409 --> 00:22:13,559
and packages in rows are mostly working

00:22:11,970 --> 00:22:16,320
already as long as you're playing for

00:22:13,559 --> 00:22:17,549
single chains we're sure that this will

00:22:16,320 --> 00:22:19,679
improve in the future so we can have

00:22:17,549 --> 00:22:21,769
whole body control seen examples of

00:22:19,679 --> 00:22:24,899
localization and path planning here and

00:22:21,769 --> 00:22:26,489
this is like the first tiny tiny steps

00:22:24,899 --> 00:22:28,739
towards the navigation stack for

00:22:26,489 --> 00:22:30,239
humanoid robots and finally we've seen

00:22:28,739 --> 00:22:31,950
over your frost for the now humored if

00:22:30,239 --> 00:22:37,279
you have no more questions I mean we can

00:22:31,950 --> 00:22:37,279
discuss later so that's it thank you

00:22:40,920 --> 00:22:42,980

YouTube URL: https://www.youtube.com/watch?v=MrONDuzKa7Q


