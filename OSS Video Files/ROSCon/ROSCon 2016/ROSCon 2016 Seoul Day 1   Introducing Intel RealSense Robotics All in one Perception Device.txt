Title: ROSCon 2016 Seoul Day 1   Introducing Intel RealSense Robotics All in one Perception Device
Publication date: 2016-10-20
Playlist: ROSCon 2016
Description: 
	Unaltered video by Open Robotics from http://roscon.ros.org/2016 under the Attribution-NonCommercial-NoDerivs 3.0 Unported (CC BY-NC-ND 3.0) License https://creativecommons.org/licenses/by-nc-nd/3.0/
Captions: 
	00:00:00,060 --> 00:00:03,360
I'll speak closer hey everybody it's

00:00:02,040 --> 00:00:05,700
great to be here this afternoon and also

00:00:03,360 --> 00:00:07,500
my name is Matt Curfman and I'm a

00:00:05,700 --> 00:00:09,450
robotic software architect also in the

00:00:07,500 --> 00:00:12,210
perceptional computing

00:00:09,450 --> 00:00:14,849
last year many of you who attended Ross

00:00:12,210 --> 00:00:18,000
Con in Germany may have seen a MIT's

00:00:14,849 --> 00:00:20,250
presentation where he proposed working

00:00:18,000 --> 00:00:22,230
with the intel realsense technology and

00:00:20,250 --> 00:00:24,900
how that could be applied in robotics

00:00:22,230 --> 00:00:26,310
and in particularly Ross and that was

00:00:24,900 --> 00:00:28,199
very interesting talk where he walked

00:00:26,310 --> 00:00:30,929
through and abling the until realsense

00:00:28,199 --> 00:00:33,059
camera with a binary Ross rapper and a

00:00:30,929 --> 00:00:34,770
binary driver well we've been really

00:00:33,059 --> 00:00:36,090
busy and we're real excited to talk to

00:00:34,770 --> 00:00:37,290
you about some of the additional things

00:00:36,090 --> 00:00:39,300
that we've done over the course of the

00:00:37,290 --> 00:00:41,579
last year and are showing in our booth

00:00:39,300 --> 00:00:44,789
and I wanted to really quickly review

00:00:41,579 --> 00:00:46,739
some of those things one of the things

00:00:44,789 --> 00:00:49,770
we've introduced is many more cameras

00:00:46,739 --> 00:00:52,020
now supported in the Ross ecosystem we

00:00:49,770 --> 00:00:54,539
enabled support for Ross with our intel

00:00:52,020 --> 00:00:55,829
realsense sr 300 camera which uses

00:00:54,539 --> 00:00:56,940
structured light to give you that

00:00:55,829 --> 00:00:58,890
capability of doing background

00:00:56,940 --> 00:01:01,020
segmentation and facial tracking for

00:00:58,890 --> 00:01:03,420
some relaxed applications we're also

00:01:01,020 --> 00:01:06,390
very excited and introduced in August

00:01:03,420 --> 00:01:09,420
our new intel realsense cameras gr 300

00:01:06,390 --> 00:01:13,770
this cameras tuned specifically for

00:01:09,420 --> 00:01:15,840
robots and adds that wide-angle lens for

00:01:13,770 --> 00:01:18,180
slam and navigation it also integrates

00:01:15,840 --> 00:01:20,960
an IMU in there and we have some

00:01:18,180 --> 00:01:23,460
demonstrations of that running our lab

00:01:20,960 --> 00:01:26,159
over the course of the last year in

00:01:23,460 --> 00:01:28,170
addition to our always popular into Luke

00:01:26,159 --> 00:01:29,850
platform we've introduced a couple new

00:01:28,170 --> 00:01:31,560
robotics platforms that we think are

00:01:29,850 --> 00:01:33,990
very interesting for the folks in this

00:01:31,560 --> 00:01:36,780
audience we've introduced the intel

00:01:33,990 --> 00:01:39,299
realsense robotics developer's kit this

00:01:36,780 --> 00:01:41,850
kit contains both the intel realsense

00:01:39,299 --> 00:01:43,829
r200 camera that admit talked about last

00:01:41,850 --> 00:01:46,020
year along with everything else you

00:01:43,829 --> 00:01:47,930
would need in a box to add computer

00:01:46,020 --> 00:01:50,220
vision capabilities to your camera

00:01:47,930 --> 00:01:52,530
including an atom based single board

00:01:50,220 --> 00:01:54,229
computer with a lot of the familiar iOS

00:01:52,530 --> 00:01:56,670
you would expect in the robotics world

00:01:54,229 --> 00:01:58,740
the intel realsense camera i said and

00:01:56,670 --> 00:02:00,750
also some running ubuntu it's a rican

00:01:58,740 --> 00:02:03,149
boot a full desktop on that and we also

00:02:00,750 --> 00:02:04,979
put all the power supplies and cables

00:02:03,149 --> 00:02:06,719
everything you need to build sort of an

00:02:04,979 --> 00:02:09,509
advanced robotics capability first

00:02:06,719 --> 00:02:11,489
computer vision in august we are also

00:02:09,509 --> 00:02:12,770
really excited to introduce now our new

00:02:11,489 --> 00:02:15,170
intel jewels of

00:02:12,770 --> 00:02:17,720
Birkett build upon the capabilities of

00:02:15,170 --> 00:02:20,030
the revised development kit we've worked

00:02:17,720 --> 00:02:22,550
to integrate a lot of the high speed iOS

00:02:20,030 --> 00:02:24,830
in a very convenient module which allows

00:02:22,550 --> 00:02:26,330
you to go from prototyping with the

00:02:24,830 --> 00:02:28,760
carry port and the developer kit that we

00:02:26,330 --> 00:02:30,590
provide to going to mass production with

00:02:28,760 --> 00:02:33,050
a production vise that you would bring

00:02:30,590 --> 00:02:34,880
to market of yourself there jewel module

00:02:33,050 --> 00:02:36,590
also includes all of the capabilities

00:02:34,880 --> 00:02:39,560
communication stacks for y-type

00:02:36,590 --> 00:02:43,370
Bluetooth we support a variety of os's

00:02:39,560 --> 00:02:45,410
including Ubuntu and out of the box the

00:02:43,370 --> 00:02:48,770
jewel module also supports intel

00:02:45,410 --> 00:02:50,120
realsense technology in addition over

00:02:48,770 --> 00:02:52,820
the course of the last year we've really

00:02:50,120 --> 00:02:55,780
worked hard to serve fully embrace and

00:02:52,820 --> 00:02:58,640
be a little bit easier work with by a

00:02:55,780 --> 00:03:01,160
embracing open-source so we've worked

00:02:58,640 --> 00:03:03,260
very hard to take the work that Amit

00:03:01,160 --> 00:03:04,850
showed last year I'm gonna provide that

00:03:03,260 --> 00:03:08,000
as now open source drivers

00:03:04,850 --> 00:03:10,700
and open source camera nodes for Ross

00:03:08,000 --> 00:03:13,070
and so there's no encumbrance with you

00:03:10,700 --> 00:03:15,260
to use realsense technology on your own

00:03:13,070 --> 00:03:17,030
operating system if you have more

00:03:15,260 --> 00:03:18,560
questions or informations about the work

00:03:17,030 --> 00:03:20,300
that we've been doing in open source I

00:03:18,560 --> 00:03:22,190
would invite you to go to our realsense

00:03:20,300 --> 00:03:23,930
site there at we keyed up rasta org

00:03:22,190 --> 00:03:25,790
where we're proposing that we will keep

00:03:23,930 --> 00:03:28,220
sort of all the links to the relevant

00:03:25,790 --> 00:03:31,940
software pieces for to use realsense

00:03:28,220 --> 00:03:34,010
technology and robotics in addition over

00:03:31,940 --> 00:03:35,420
the course of the last year we want to

00:03:34,010 --> 00:03:37,730
make sure that we could demonstrate how

00:03:35,420 --> 00:03:40,459
realsense works with the turtlebot and

00:03:37,730 --> 00:03:42,320
so so my colleagues Matt and Mark you're

00:03:40,459 --> 00:03:44,300
sitting over here from the Intel open

00:03:42,320 --> 00:03:47,570
source technology group have worked to

00:03:44,300 --> 00:03:49,130
release all the you RDF models and make

00:03:47,570 --> 00:03:51,110
serve the realsense camera of first

00:03:49,130 --> 00:03:53,270
classes and in the turtle bot stack

00:03:51,110 --> 00:03:55,490
we're real happy that these are now been

00:03:53,270 --> 00:03:58,280
merged and integrated into the turtle

00:03:55,490 --> 00:04:00,590
lot mainline and all the software

00:03:58,280 --> 00:04:02,709
turtlebot apps the real sense driver

00:04:00,590 --> 00:04:05,060
software and the realsense camera nodes

00:04:02,709 --> 00:04:06,920
we're real happy are now building in the

00:04:05,060 --> 00:04:08,300
Ross of build form so you don't even

00:04:06,920 --> 00:04:10,370
have to go and pull the source you can

00:04:08,300 --> 00:04:12,800
just install support for those like you

00:04:10,370 --> 00:04:16,580
would any other camera making that

00:04:12,800 --> 00:04:18,530
really easy then finally it's been our

00:04:16,580 --> 00:04:20,150
pleasure to work with many of our

00:04:18,530 --> 00:04:21,950
customers and deploying realsense

00:04:20,150 --> 00:04:24,940
technology into products of and these

00:04:21,950 --> 00:04:26,540
were a few many of the capabilities that

00:04:24,940 --> 00:04:28,250
already demonstrated

00:04:26,540 --> 00:04:30,770
these products here and we're showcasing

00:04:28,250 --> 00:04:33,020
in our booth particular we have a

00:04:30,770 --> 00:04:34,760
cognitive computing demonstration which

00:04:33,020 --> 00:04:36,910
shows a turtle bot base which sort of

00:04:34,760 --> 00:04:39,530
fuses the ability to use speech and

00:04:36,910 --> 00:04:41,360
gestures together and build some of the

00:04:39,530 --> 00:04:44,450
capabilities that many of our partners

00:04:41,360 --> 00:04:46,760
have built and finally we have a raffle

00:04:44,450 --> 00:04:48,350
at our booth if we have a interested in

00:04:46,760 --> 00:04:50,360
entering that we invite you to come and

00:04:48,350 --> 00:04:52,250
leave your business card and we'll

00:04:50,360 --> 00:04:54,980
having a raffle this afternoon and when

00:04:52,250 --> 00:04:58,190
tomorrow we would provide a robot

00:04:54,980 --> 00:04:59,780
developing kit is the prize for that and

00:04:58,190 --> 00:05:02,030
then finally we're really excited to

00:04:59,780 --> 00:05:03,950
talk about until Euclid and so now I'd

00:05:02,030 --> 00:05:13,310
like to turn it over to my colleague I'm

00:05:03,950 --> 00:05:18,020
in thank you Matt each other um yeah

00:05:13,310 --> 00:05:20,240
until Euclid so in the last two years or

00:05:18,020 --> 00:05:23,060
so we were working with startups and

00:05:20,240 --> 00:05:28,580
companies and academia getting feedback

00:05:23,060 --> 00:05:30,260
on real sense in robotics and we we got

00:05:28,580 --> 00:05:32,000
great feedback on that and we put people

00:05:30,260 --> 00:05:36,080
of this depth perception at the size and

00:05:32,000 --> 00:05:38,420
everything and one thing we saw that if

00:05:36,080 --> 00:05:41,300
something is required is to have like an

00:05:38,420 --> 00:05:43,400
easy setup and ramp up with the

00:05:41,300 --> 00:05:45,560
technology to start prototyping and

00:05:43,400 --> 00:05:48,140
developing new capabilities and new

00:05:45,560 --> 00:05:51,830
experiences and this is why we came up

00:05:48,140 --> 00:05:56,720
with Euclid the idea of Euclid is to

00:05:51,830 --> 00:05:59,540
have a robotics vision solution which is

00:05:56,720 --> 00:06:02,990
complete working by the standards and

00:05:59,540 --> 00:06:05,270
easy to use what I mean by that so

00:06:02,990 --> 00:06:07,580
complete everything you need to start

00:06:05,270 --> 00:06:11,420
working with our technology if it is the

00:06:07,580 --> 00:06:13,910
Intel quad core SOC our CR 300 would not

00:06:11,420 --> 00:06:15,130
describe before that includes depth data

00:06:13,910 --> 00:06:17,870
and motion

00:06:15,130 --> 00:06:20,240
internal storage communication like

00:06:17,870 --> 00:06:22,490
Wi-Fi Bluetooth and USB even a

00:06:20,240 --> 00:06:26,360
detachable battery so you can work

00:06:22,490 --> 00:06:28,190
autonomously by itself and together with

00:06:26,360 --> 00:06:31,550
that we're going to provide some 3d

00:06:28,190 --> 00:06:35,150
printable parts and 3d printable robots

00:06:31,550 --> 00:06:38,249
for you to start working if you need so

00:06:35,150 --> 00:06:41,879
complete solution to start prototyping

00:06:38,249 --> 00:06:44,459
your robots second is about working by

00:06:41,879 --> 00:06:47,189
the community standard it's important

00:06:44,459 --> 00:06:49,379
for us that you and other people want to

00:06:47,189 --> 00:06:50,939
use our technology from day one we'll

00:06:49,379 --> 00:06:55,199
know how to use it and we want to use it

00:06:50,939 --> 00:06:57,989
it's why Euclid is planned to run Ubuntu

00:06:55,199 --> 00:07:01,139
1604 with Ross kinetic and have a good

00:06:57,989 --> 00:07:04,879
integration with Arduino technology I

00:07:01,139 --> 00:07:10,079
will speak about that a couple of slides

00:07:04,879 --> 00:07:11,699
and first thing is about easy to use we

00:07:10,079 --> 00:07:13,169
really wanted to have this experience

00:07:11,699 --> 00:07:15,539
like you have with your phone when you

00:07:13,169 --> 00:07:17,849
buy it and turn it on and it just works

00:07:15,539 --> 00:07:20,429
you have everything there and so this is

00:07:17,849 --> 00:07:24,049
why we have the turbo battery and s you

00:07:20,429 --> 00:07:26,639
going to turn Euclid on will have a

00:07:24,049 --> 00:07:30,389
hotspot you can connect to it wirelessly

00:07:26,639 --> 00:07:32,399
from your phone or from your laptop and

00:07:30,389 --> 00:07:34,879
there is this web interface what

00:07:32,399 --> 00:07:38,759
cross-platform web interfaces you can

00:07:34,879 --> 00:07:40,859
monitor the device control device CD

00:07:38,759 --> 00:07:45,419
streaming data from the camera from the

00:07:40,859 --> 00:07:47,489
capabilities and so very easy to use and

00:07:45,419 --> 00:07:50,759
zero installation because device will

00:07:47,489 --> 00:07:54,809
run by default ross master on that so

00:07:50,759 --> 00:07:56,999
you can connect your ross device to this

00:07:54,809 --> 00:07:59,099
Ross master in start using the

00:07:56,999 --> 00:08:01,289
capability register to the messages

00:07:59,099 --> 00:08:02,939
using the services etc obviously

00:08:01,289 --> 00:08:05,129
afterward you can configure it to use

00:08:02,939 --> 00:08:07,289
other Ross masters and etc but the first

00:08:05,129 --> 00:08:12,239
use the first time should be very simple

00:08:07,289 --> 00:08:14,969
to start using the technology and here

00:08:12,239 --> 00:08:17,309
it's it's a video we made showing some

00:08:14,969 --> 00:08:18,629
of sample capabilities all right not

00:08:17,309 --> 00:08:20,159
everything is going to be on the device

00:08:18,629 --> 00:08:22,829
itself but call kind of things that we

00:08:20,159 --> 00:08:25,139
can run and on Euclid and explaining

00:08:22,829 --> 00:08:29,819
what is the experience more or less can

00:08:25,139 --> 00:08:32,459
be with it so this is me with my phone

00:08:29,819 --> 00:08:35,669
streaming the data it directly from the

00:08:32,459 --> 00:08:38,370
device the the color and the depth data

00:08:35,669 --> 00:08:41,250
so as you get the device you can start

00:08:38,370 --> 00:08:43,559
seeing what the camera actually sees in

00:08:41,250 --> 00:08:47,009
real time when you phone or any kind of

00:08:43,559 --> 00:08:48,649
other device and I think is sick stuff

00:08:47,009 --> 00:08:50,990
we said we have motion

00:08:48,649 --> 00:08:53,600
so here is much for marketing he's also

00:08:50,990 --> 00:08:57,949
here in the conference and he's moving

00:08:53,600 --> 00:09:00,649
around the device and from another boot

00:08:57,949 --> 00:09:02,149
to laptop running our keys we're just

00:09:00,649 --> 00:09:04,369
doing the visualization so all the data

00:09:02,149 --> 00:09:06,860
is being is being calculated on the

00:09:04,369 --> 00:09:09,800
device itself in the visualization is

00:09:06,860 --> 00:09:12,829
being used on another device running our

00:09:09,800 --> 00:09:16,100
pins and once we have that we can do 3d

00:09:12,829 --> 00:09:18,050
scanning we saw before there is all kind

00:09:16,100 --> 00:09:20,689
of algorithms that we can use their open

00:09:18,050 --> 00:09:22,429
source for example this one is our tab

00:09:20,689 --> 00:09:27,290
map if you know which is running there

00:09:22,429 --> 00:09:36,410
and we can see 3d scanning of our small

00:09:27,290 --> 00:09:38,990
lab here another example eventually yeah

00:09:36,410 --> 00:09:42,319
so it's another thing we can have is six

00:09:38,990 --> 00:09:44,059
degrees of freedom very small and simple

00:09:42,319 --> 00:09:45,829
robot so this is this is one of our

00:09:44,059 --> 00:09:49,009
robots it's over here in the booth as

00:09:45,829 --> 00:09:51,379
well and just Arduino with two DC motors

00:09:49,009 --> 00:09:54,529
that's it but we can get full Doubletree

00:09:51,379 --> 00:09:57,319
data from the camera and from the device

00:09:54,529 --> 00:10:01,459
understanding where the where the device

00:09:57,319 --> 00:10:05,600
is in space where the robot is in space

00:10:01,459 --> 00:10:07,459
and that is obviously very useful you

00:10:05,600 --> 00:10:09,620
can do for example 3d scan on my

00:10:07,459 --> 00:10:12,800
building this case it's even simply

00:10:09,620 --> 00:10:17,420
robot very small one and it does 3d

00:10:12,800 --> 00:10:20,660
scanning and mapping of our lab another

00:10:17,420 --> 00:10:25,899
part of it so you can do these kind of

00:10:20,660 --> 00:10:28,610
things with very simple locomotion layer

00:10:25,899 --> 00:10:30,249
just connect this kind of device to it

00:10:28,610 --> 00:10:32,420
it works

00:10:30,249 --> 00:10:34,399
another thing is obviously person

00:10:32,420 --> 00:10:37,970
following in the text person it can

00:10:34,399 --> 00:10:39,439
follow him around so turtlebot all kind

00:10:37,970 --> 00:10:42,079
of four devices it's obviously running

00:10:39,439 --> 00:10:45,679
for us so you can use all kind of all

00:10:42,079 --> 00:10:48,079
kind of robots the last sample here is

00:10:45,679 --> 00:10:51,709
just obstacle avoidance so very simple

00:10:48,079 --> 00:10:54,019
wandering mode in our cubicle area so

00:10:51,709 --> 00:10:55,790
the idea is that you can run all kind of

00:10:54,019 --> 00:10:58,870
sample application running your own code

00:10:55,790 --> 00:11:03,220
many different codes on it and very fast

00:10:58,870 --> 00:11:03,220
prototype what you want

00:11:08,200 --> 00:11:15,250
so ma'am I'll go bit into details I'll

00:11:13,000 --> 00:11:16,750
go a bit details of what what we have so

00:11:15,250 --> 00:11:21,100
this is the high level software

00:11:16,750 --> 00:11:22,600
components we have in Euclid it's not an

00:11:21,100 --> 00:11:26,350
architecture per se but just explaining

00:11:22,600 --> 00:11:30,010
more or less what we have and the base

00:11:26,350 --> 00:11:34,630
has Ubuntu we'll have a boom - 1604 and

00:11:30,010 --> 00:11:37,390
Ross kinetic as our basics together with

00:11:34,630 --> 00:11:40,089
that we'll have our cross platform API

00:11:37,390 --> 00:11:41,470
was platform driver and liberal sense

00:11:40,089 --> 00:11:47,320
which is existing already to date not

00:11:41,470 --> 00:11:49,270
Matt described and with potentially the

00:11:47,320 --> 00:11:52,300
real sense Linux SDK who might come at

00:11:49,270 --> 00:11:55,630
some point the real sense Ross wrappers

00:11:52,300 --> 00:11:59,140
so you can use everything in in Rus and

00:11:55,630 --> 00:12:00,400
sample code and specifically for Euclid

00:11:59,140 --> 00:12:02,410
so this is true for also for other

00:12:00,400 --> 00:12:05,650
models and other platforms that you can

00:12:02,410 --> 00:12:07,870
use with with real sense specifically

00:12:05,650 --> 00:12:09,970
for Euclid you will have the automation

00:12:07,870 --> 00:12:11,560
nodes in the automation layer to have

00:12:09,970 --> 00:12:14,080
everything running out of the box and

00:12:11,560 --> 00:12:16,600
the command control web interface and we

00:12:14,080 --> 00:12:18,820
used a lot Russ for that we use many

00:12:16,600 --> 00:12:21,730
features in Ross to help us do that and

00:12:18,820 --> 00:12:25,300
I'm going to talk about some of them

00:12:21,730 --> 00:12:28,450
right now and so on one of them is the

00:12:25,300 --> 00:12:30,420
command and control web interface we

00:12:28,450 --> 00:12:33,520
wanted to have a cross-platform web

00:12:30,420 --> 00:12:35,980
interface to control the device and we

00:12:33,520 --> 00:12:37,660
were very happy to discover the truss

00:12:35,980 --> 00:12:40,180
have a JavaScript interface we didn't

00:12:37,660 --> 00:12:41,800
know that when we started work and and

00:12:40,180 --> 00:12:45,100
even a video web server so we're using

00:12:41,800 --> 00:12:47,260
all of that to stream our our data or

00:12:45,100 --> 00:12:50,140
streaming data to control the device

00:12:47,260 --> 00:12:53,950
we're even showing the log system in

00:12:50,140 --> 00:12:57,310
this web interface it allows very fast

00:12:53,950 --> 00:12:59,279
to see what the Vice can do and this

00:12:57,310 --> 00:13:04,810
basically helped us to reduce the time

00:12:59,279 --> 00:13:06,670
it took us to program that and it

00:13:04,810 --> 00:13:08,320
basically works we have this Euclid

00:13:06,670 --> 00:13:10,720
automation nodes they have some topics

00:13:08,320 --> 00:13:12,459
they have some services and we have a

00:13:10,720 --> 00:13:14,200
JavaScript client that basically uses

00:13:12,459 --> 00:13:15,880
those

00:13:14,200 --> 00:13:17,440
this architecture allows us to have

00:13:15,880 --> 00:13:19,029
other clients like the Ross serial

00:13:17,440 --> 00:13:24,010
client and I will explain about that

00:13:19,029 --> 00:13:26,170
when we go to Audrina part next the web

00:13:24,010 --> 00:13:29,139
interface we created this concept of

00:13:26,170 --> 00:13:31,420
scenarios scenarios is basically kind of

00:13:29,139 --> 00:13:32,860
an application onyx or experience for

00:13:31,420 --> 00:13:35,019
example you want to do a turtle bot

00:13:32,860 --> 00:13:37,180
personal folder and you will need to run

00:13:35,019 --> 00:13:39,790
several notes together like the camera

00:13:37,180 --> 00:13:42,100
know the person tracking node and the

00:13:39,790 --> 00:13:44,290
total boat driver and so you basically

00:13:42,100 --> 00:13:46,269
can choose all of them and run them

00:13:44,290 --> 00:13:48,040
together in one scenario you can also

00:13:46,269 --> 00:13:50,829
configure each of them using the dynamic

00:13:48,040 --> 00:13:52,870
reconfiguration and which is available

00:13:50,829 --> 00:13:54,639
in the website so we can the same

00:13:52,870 --> 00:13:57,820
website you can go and configure each

00:13:54,639 --> 00:13:59,380
and every and node tweak them and

00:13:57,820 --> 00:14:01,120
eventually when you get to something you

00:13:59,380 --> 00:14:03,610
would like you can actually save those

00:14:01,120 --> 00:14:07,269
configuration it's a scenario this is

00:14:03,610 --> 00:14:08,529
all the configuration is saved and the

00:14:07,269 --> 00:14:10,480
next time we're going to launch the

00:14:08,529 --> 00:14:11,709
scenario it will load all those

00:14:10,480 --> 00:14:13,290
configurations so you can create

00:14:11,709 --> 00:14:16,690
different scenarios different

00:14:13,290 --> 00:14:19,120
experiences and then load them as you

00:14:16,690 --> 00:14:22,089
want you can even define one of the

00:14:19,120 --> 00:14:23,589
scenarios as a default one so you can as

00:14:22,089 --> 00:14:26,140
the device turn on if too much

00:14:23,589 --> 00:14:28,240
automatically loads all the nodes and

00:14:26,140 --> 00:14:30,820
they don't need to connect to the web

00:14:28,240 --> 00:14:32,829
interface and everything to load this

00:14:30,820 --> 00:14:35,649
scenario so you can do some fast

00:14:32,829 --> 00:14:38,110
prototyping understand what you want how

00:14:35,649 --> 00:14:41,980
you want to do it and I think it's cool

00:14:38,110 --> 00:14:43,180
um I think one of the things here is

00:14:41,980 --> 00:14:45,029
about trade we know we really want it

00:14:43,180 --> 00:14:48,250
again to have a Twinner compatibility

00:14:45,029 --> 00:14:53,500
let's check in the time do you know

00:14:48,250 --> 00:14:55,209
compatibility to have makers people that

00:14:53,500 --> 00:14:58,300
are using Arduino to do all kind of

00:14:55,209 --> 00:15:01,360
other stuff and again we were extremely

00:14:58,300 --> 00:15:02,740
happy to discover that Ross have an

00:15:01,360 --> 00:15:06,970
interface for that Ross serial and

00:15:02,740 --> 00:15:10,240
westeros Arduino and yeah basically it

00:15:06,970 --> 00:15:12,339
allows you to use Arlena code to get

00:15:10,240 --> 00:15:15,760
messages and services basically

00:15:12,339 --> 00:15:17,680
everything form Arduino and we added in

00:15:15,760 --> 00:15:19,569
the web interface just the web that you

00:15:17,680 --> 00:15:21,670
can just a page that you can generate

00:15:19,569 --> 00:15:23,560
the library and download to your device

00:15:21,670 --> 00:15:26,800
so you can ASSU connecting from your

00:15:23,560 --> 00:15:28,170
windows device for example to Euclid you

00:15:26,800 --> 00:15:30,660
can go to this way

00:15:28,170 --> 00:15:33,540
generate the library download and open

00:15:30,660 --> 00:15:36,680
your arduino ID and see all kind of

00:15:33,540 --> 00:15:40,880
sample sketches in in order you know and

00:15:36,680 --> 00:15:40,880
and basically program your arduino

00:15:40,910 --> 00:15:45,330
if you remember I talked about the

00:15:42,990 --> 00:15:48,540
Euclid automation nodes and they have

00:15:45,330 --> 00:15:50,340
services and topics all these can be

00:15:48,540 --> 00:15:52,740
consumed by their I adored we know so

00:15:50,340 --> 00:15:55,830
you can get even monitoring data like

00:15:52,740 --> 00:15:58,440
about the battery of cutely fond Arduino

00:15:55,830 --> 00:16:00,180
or you can even start and stop scenarios

00:15:58,440 --> 00:16:02,400
and stuff like that so you can even

00:16:00,180 --> 00:16:06,450
create you can create your experience in

00:16:02,400 --> 00:16:08,070
on your laptop create your scenario and

00:16:06,450 --> 00:16:10,830
then after that you can program your ad

00:16:08,070 --> 00:16:13,140
we know to whatever whenever an event

00:16:10,830 --> 00:16:14,880
happens start specific scenarios so when

00:16:13,140 --> 00:16:17,700
the lights go on you have a sensor for

00:16:14,880 --> 00:16:19,320
that you send service to start the

00:16:17,700 --> 00:16:20,430
specific scenario and the scenario will

00:16:19,320 --> 00:16:23,940
start and you can do for example

00:16:20,430 --> 00:16:28,290
pressure recognition and so this allows

00:16:23,940 --> 00:16:29,490
also for non robotics developers per se

00:16:28,290 --> 00:16:34,520
to do all kind of interesting

00:16:29,490 --> 00:16:36,450
experiences and it straight away

00:16:34,520 --> 00:16:39,690
so the last thing here is about

00:16:36,450 --> 00:16:41,370
extendibility I mean this solution is is

00:16:39,690 --> 00:16:44,070
open it's actually in a bundle machine

00:16:41,370 --> 00:16:46,110
it has an HDMI connection in a USB you

00:16:44,070 --> 00:16:48,270
connected to a terminal or for remote

00:16:46,110 --> 00:16:50,640
desktop and you can expand and you can

00:16:48,270 --> 00:16:53,790
create your own algorithms you can use

00:16:50,640 --> 00:16:57,450
open source ones you can even add

00:16:53,790 --> 00:17:00,000
everything to the web interface so the

00:16:57,450 --> 00:17:02,460
idea is that can it can kind of help

00:17:00,000 --> 00:17:03,660
people from day one from the Wade from

00:17:02,460 --> 00:17:06,180
the day that they opened the device

00:17:03,660 --> 00:17:08,850
until they want to create new

00:17:06,180 --> 00:17:11,130
experiences and new solutions and

00:17:08,850 --> 00:17:15,449
everything the web interface and user

00:17:11,130 --> 00:17:17,250
scenarios and yeah and basically use

00:17:15,449 --> 00:17:21,150
that as a prototyping as a development

00:17:17,250 --> 00:17:24,089
tool and to create their robots and it's

00:17:21,150 --> 00:17:26,550
going to be available around the q1 2017

00:17:24,089 --> 00:17:29,610
you don't have the price yet I know some

00:17:26,550 --> 00:17:31,140
less for that and but it's coming you

00:17:29,610 --> 00:17:34,070
can get information on the web just

00:17:31,140 --> 00:17:37,620
search for Intel Blue Zones Euclid and

00:17:34,070 --> 00:17:39,150
and you get more information and you

00:17:37,620 --> 00:17:40,920
come to our booth you can see the demo

00:17:39,150 --> 00:17:41,650
you can see the demos that my described

00:17:40,920 --> 00:17:45,040
before

00:17:41,650 --> 00:17:47,200
about our DK about dual cameras and our

00:17:45,040 --> 00:17:49,600
DK is available now so you can already

00:17:47,200 --> 00:17:51,060
start if you're excited about using this

00:17:49,600 --> 00:17:55,630
technology you can or you start using

00:17:51,060 --> 00:17:59,820
real such technology today and then stay

00:17:55,630 --> 00:17:59,820
tuned for more stuff thank you very much

00:18:07,770 --> 00:18:33,220
there any questions so for this step up

00:18:10,330 --> 00:18:38,020
to Mike hi I'm Patricia so first one is

00:18:33,220 --> 00:18:41,050
I know that this camera is the 3d touch

00:18:38,020 --> 00:18:45,220
camera so it requires the 3d point cloud

00:18:41,050 --> 00:18:47,530
so you might need the extensive

00:18:45,220 --> 00:18:50,500
computing so was there any lagging issue

00:18:47,530 --> 00:18:57,310
and the second question is is there any

00:18:50,500 --> 00:19:00,310
pre-order for this camera resolution

00:18:57,310 --> 00:19:02,020
this is the question for Sony's like was

00:19:00,310 --> 00:19:04,120
there any lagging issue for the new

00:19:02,020 --> 00:19:06,190
motor since this one requires the

00:19:04,120 --> 00:19:11,230
extensive computing for the Deaf's

00:19:06,190 --> 00:19:13,090
camera so the computing capabilities one

00:19:11,230 --> 00:19:15,670
thing to know about the intel realsense

00:19:13,090 --> 00:19:18,400
cameras is that each camera is includes

00:19:15,670 --> 00:19:20,530
a special ASIC where all of the depth

00:19:18,400 --> 00:19:22,420
calculations are performed on camera so

00:19:20,530 --> 00:19:24,820
this removes the need to perform that

00:19:22,420 --> 00:19:29,770
calculation on the host PC and in terms

00:19:24,820 --> 00:19:32,020
of the intel r 200 and into CR 300 come

00:19:29,770 --> 00:19:36,370
with a two megapixel color sensor and a

00:19:32,020 --> 00:19:38,110
VGA depth sensor the second question is

00:19:36,370 --> 00:19:41,200
you stand on a pre-order for this

00:19:38,110 --> 00:19:45,070
so the until are 200 camera is available

00:19:41,200 --> 00:19:46,720
today at click Intel calm as is the

00:19:45,070 --> 00:19:48,600
Intel provides development kit which is

00:19:46,720 --> 00:19:51,130
also shipping and available today

00:19:48,600 --> 00:19:53,080
although they are robotics in focus and

00:19:51,130 --> 00:19:54,520
then selling out occasionally so there's

00:19:53,080 --> 00:19:55,010
a button that you can click on that to

00:19:54,520 --> 00:19:59,690
be notif

00:19:55,010 --> 00:20:01,790
that's back in the in stock the zero 300

00:19:59,690 --> 00:20:05,330
camera we intend to announce pricing and

00:20:01,790 --> 00:20:07,010
the release dates in q4 the Intel dual

00:20:05,330 --> 00:20:08,960
module was announced in August and that

00:20:07,010 --> 00:20:15,230
is also available for sale today at

00:20:08,960 --> 00:20:17,809
newegg.com thank you Euclid I think we

00:20:15,230 --> 00:20:21,010
mentioned is pricing in shipping

00:20:17,809 --> 00:20:25,820
information will be available in q1 2017

00:20:21,010 --> 00:20:30,130
can I answer one question until you call

00:20:25,820 --> 00:20:36,200
it has a Wi-Fi and videos of a feature

00:20:30,130 --> 00:20:39,290
so does you clip and as Euclid can live

00:20:36,200 --> 00:20:43,130
a stream and live stream the video and

00:20:39,290 --> 00:20:48,140
real-time the utility had that kind of

00:20:43,130 --> 00:20:50,929
feature yeah so the short question is

00:20:48,140 --> 00:20:54,200
yes it can you can live and you can see

00:20:50,929 --> 00:20:57,380
it in our booth using Ross messages

00:20:54,200 --> 00:21:00,679
basically we're using Ross to stream the

00:20:57,380 --> 00:21:03,919
data you can write something else if you

00:21:00,679 --> 00:21:08,559
want to can I use this private stream

00:21:03,919 --> 00:21:11,570
data in Wi-Fi with that and cable with

00:21:08,559 --> 00:21:14,600
Holy See yes you can

00:21:11,570 --> 00:21:17,270
okay it depends if you want to use it I

00:21:14,600 --> 00:21:19,790
mean eventually depends a bandwidth how

00:21:17,270 --> 00:21:22,549
much data I want to send but just adjust

00:21:19,790 --> 00:21:24,049
the data just the the depth data for

00:21:22,549 --> 00:21:29,570
example in the RGB can be sent in

00:21:24,049 --> 00:21:32,870
problem thank you sure yeah I'm just

00:21:29,570 --> 00:21:36,200
curious about the kind of licensing and

00:21:32,870 --> 00:21:39,740
openness of the six degree of freedom

00:21:36,200 --> 00:21:42,350
tracking kind of AP eyes and algorithms

00:21:39,740 --> 00:21:45,799
are using there how available those be

00:21:42,350 --> 00:21:54,250
or don't have the answer at the moment

00:21:45,799 --> 00:21:54,250

YouTube URL: https://www.youtube.com/watch?v=fpXyJXXyr0w


