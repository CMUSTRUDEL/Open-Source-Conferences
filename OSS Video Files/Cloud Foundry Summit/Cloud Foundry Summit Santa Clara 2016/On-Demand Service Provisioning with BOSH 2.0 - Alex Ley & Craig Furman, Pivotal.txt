Title: On-Demand Service Provisioning with BOSH 2.0 - Alex Ley & Craig Furman, Pivotal
Publication date: 2016-05-29
Playlist: Cloud Foundry Summit Santa Clara 2016
Description: 
	Alex & Craig have been busy building what they are calling “On-Demand Services”, leveraging new features arriving in BOSH 2.0. For the first time, app developers will have the ability to deploy dedicated resources by simply running `cf create-service`. For example, app developers could create a dedicated RabbitMQ cluster or a customised Redis instance for their application. 

You will be taken behind the scenes, showing how an app developer’s CF CLI request will trigger a service broker to create a new BOSH deployment which results in freshly created virtual machines. 

Finally, they will discuss and demonstrate what challenges on-demand services bring to operating the Cloud Foundry platform and exciting new user experiences that we could start to offer. 

Craig Furman
Software Engineer, Pivotal
Craig Furman is a software engineer at Pivotal in London. He currently builds data services for Cloud Foundry and has contributed to Cloud Foundry services brokers for Redis, Cassandra and Neo4J. He primarily writes code in Go, Java, Ruby and the occasional shell script.

Alex Ley
Product Manager, Pivotal
Alex Ley works on the Cloud Foundry platform at Pivotal as a Product Manager. He is primarily focused on bringing data services to the Pivotal Cloud Foundry platform such as Redis, RabbitMQ and Cassandra. Alex has a passion for Cloud Foundry and the way we build software. Previously Alex has given talks at "muCon - The Microservices Conference 2015", "Continuous Lifecycle Conference 2016" , "London PaaS Meetup 2015", "Pivotal Open Lunch & Learn 2016".
Captions: 
	00:00:00,030 --> 00:00:03,840
okay let's get started so thanks for

00:00:02,760 --> 00:00:05,339
joining us today

00:00:03,840 --> 00:00:07,170
so we're here to talk to you about

00:00:05,339 --> 00:00:10,800
on-demand service provisioning with

00:00:07,170 --> 00:00:11,960
bosch 2.0 so I'm Alex Lai I work for

00:00:10,800 --> 00:00:14,639
pivotal in London

00:00:11,960 --> 00:00:16,619
I'm Greg I work for pivotal in London on

00:00:14,639 --> 00:00:18,750
the cloud for Andrew services yeah so

00:00:16,619 --> 00:00:20,400
we've spent the last few months building

00:00:18,750 --> 00:00:22,080
cloud foundry service brokers the

00:00:20,400 --> 00:00:24,570
provision you know infrastructure

00:00:22,080 --> 00:00:25,680
resources on demand and so we're going

00:00:24,570 --> 00:00:28,109
to tell you about some new features that

00:00:25,680 --> 00:00:29,880
we've used in Bosch that enable us to do

00:00:28,109 --> 00:00:31,650
this and also the features in cloud

00:00:29,880 --> 00:00:34,020
foundry they kind of tie this all

00:00:31,650 --> 00:00:36,030
together so this in a talk about the

00:00:34,020 --> 00:00:38,399
Bosch internals I think there's good

00:00:36,030 --> 00:00:39,930
talk about that earlier today but we're

00:00:38,399 --> 00:00:41,550
going to be talking out it's like people

00:00:39,930 --> 00:00:43,739
who develop services for cloud foundry

00:00:41,550 --> 00:00:45,570
but this is going to be interesting for

00:00:43,739 --> 00:00:47,129
the application developers who want to

00:00:45,570 --> 00:00:51,570
know a bit more of what happens when you

00:00:47,129 --> 00:00:53,219
run CF create service so I'm sure this

00:00:51,570 --> 00:00:54,600
email will look familiar to any app

00:00:53,219 --> 00:00:57,120
developers in the audience especially

00:00:54,600 --> 00:00:59,820
those that work at typical large

00:00:57,120 --> 00:01:02,100
enterprises so this is an example of an

00:00:59,820 --> 00:01:05,250
app developer asking for a Redis service

00:01:02,100 --> 00:01:06,960
to be provisioned for them by ops they

00:01:05,250 --> 00:01:08,640
probably can't walk over to the desk

00:01:06,960 --> 00:01:09,780
where the ops team sits the ops team

00:01:08,640 --> 00:01:11,369
might be in a completely different

00:01:09,780 --> 00:01:15,540
office they've got to specify exactly

00:01:11,369 --> 00:01:17,250
what they want in that first email and

00:01:15,540 --> 00:01:19,530
often you'll get an email that looks

00:01:17,250 --> 00:01:21,890
like this coming back in asking for your

00:01:19,530 --> 00:01:24,090
like cost center or business approvers

00:01:21,890 --> 00:01:25,680
yeah like we don't want to worry about

00:01:24,090 --> 00:01:27,570
this no one wants to worry about that

00:01:25,680 --> 00:01:29,369
and so we want you know databases in

00:01:27,570 --> 00:01:31,079
like three to five minutes we don't want

00:01:29,369 --> 00:01:32,130
it in three to five days and if you get

00:01:31,079 --> 00:01:34,350
something wrong you have to go through

00:01:32,130 --> 00:01:37,290
the cycle over and over again it's

00:01:34,350 --> 00:01:38,909
really painful so then along comes Cloud

00:01:37,290 --> 00:01:44,220
Foundry and improves everyone's lives

00:01:38,909 --> 00:01:45,570
immeasurably right so so who's run this

00:01:44,220 --> 00:01:48,360
command before who's run CF create

00:01:45,570 --> 00:01:50,640
service okay that's most people as good

00:01:48,360 --> 00:01:52,799
so I'll go every quickly just to break

00:01:50,640 --> 00:01:54,540
it down the first argument to create

00:01:52,799 --> 00:01:57,060
service Redis cloud for Andrew looks up

00:01:54,540 --> 00:01:58,710
the external service broker URL for the

00:01:57,060 --> 00:02:00,810
Redis service offering forwards the

00:01:58,710 --> 00:02:02,549
request to it the last parameter is just

00:02:00,810 --> 00:02:04,409
a name that you make up so that you can

00:02:02,549 --> 00:02:05,700
reference the service later it's the

00:02:04,409 --> 00:02:08,610
middle one which is interesting to this

00:02:05,700 --> 00:02:10,170
example shared VM so implicit in this

00:02:08,610 --> 00:02:12,750
plan name is that we're going to be

00:02:10,170 --> 00:02:16,920
doing an example of a multi-tenant

00:02:12,750 --> 00:02:18,600
service plan so Redis is single user not

00:02:16,920 --> 00:02:19,710
natively multi-tenant to achieve

00:02:18,600 --> 00:02:21,930
multi-tenancy we're going to have to

00:02:19,710 --> 00:02:28,110
start up Redis processes on the same

00:02:21,930 --> 00:02:30,540
virtual machine yes so clarity really

00:02:28,110 --> 00:02:32,850
helps us with our applications but still

00:02:30,540 --> 00:02:34,260
behind the scenes anything kind of to do

00:02:32,850 --> 00:02:36,209
with managing services it doesn't help

00:02:34,260 --> 00:02:39,540
you and this is quite a hard problem to

00:02:36,209 --> 00:02:40,800
solve and so you know especially when

00:02:39,540 --> 00:02:43,680
you've got stateful services and you

00:02:40,800 --> 00:02:44,370
start to manage disks and persistence so

00:02:43,680 --> 00:02:46,560
we're going to walk through a scenario

00:02:44,370 --> 00:02:49,950
where we want to do this for a

00:02:46,560 --> 00:02:51,630
multi-tenant Redis service so first you

00:02:49,950 --> 00:02:54,230
need somewhere to run your service so

00:02:51,630 --> 00:02:56,280
you go and get a VM from let's say AWS

00:02:54,230 --> 00:02:58,140
you've got a copy over the Redis

00:02:56,280 --> 00:02:59,790
software you've got to set down some

00:02:58,140 --> 00:03:01,770
convict on the VM including things such

00:02:59,790 --> 00:03:03,510
as port you've got to start the Redis

00:03:01,770 --> 00:03:05,790
process and then importantly you've got

00:03:03,510 --> 00:03:07,050
to monitor it so that it stays up you're

00:03:05,790 --> 00:03:08,820
going to need a persistent disk if you

00:03:07,050 --> 00:03:13,080
want to use Redis is persistent modes to

00:03:08,820 --> 00:03:15,870
store state but wait someone else wants

00:03:13,080 --> 00:03:19,049
another Redis on the same multi-tenant

00:03:15,870 --> 00:03:20,580
service so yeah we need to start off

00:03:19,049 --> 00:03:21,989
another Redis process on a different

00:03:20,580 --> 00:03:24,060
port with different configuration

00:03:21,989 --> 00:03:27,170
possibly and then we also need a place

00:03:24,060 --> 00:03:29,430
to store that on the disk and then

00:03:27,170 --> 00:03:30,420
actually if you want to spin up another

00:03:29,430 --> 00:03:32,310
one you probably need some kind of

00:03:30,420 --> 00:03:34,380
orchestration on that VM to handle bring

00:03:32,310 --> 00:03:36,480
it up Redis processes taking them down

00:03:34,380 --> 00:03:38,760
you know what happens when someone wants

00:03:36,480 --> 00:03:40,980
to delete their service instance you

00:03:38,760 --> 00:03:42,840
have to handle that in this agent we

00:03:40,980 --> 00:03:44,250
still need monitoring if you have too

00:03:42,840 --> 00:03:46,110
many registers and you have this noisy

00:03:44,250 --> 00:03:49,650
neighbor problem where Redis one is

00:03:46,110 --> 00:03:54,090
taking all vs. twos memory how do you

00:03:49,650 --> 00:03:55,470
handle this so to solve some of these

00:03:54,090 --> 00:03:57,930
problems we should just give everybody

00:03:55,470 --> 00:04:00,090
their own Redis this is referred to as a

00:03:57,930 --> 00:04:01,860
single tenant service plan where each

00:04:00,090 --> 00:04:07,049
Redis instance process runs on its own

00:04:01,860 --> 00:04:08,910
dedicated VM you still need the virtual

00:04:07,049 --> 00:04:10,980
machine you still need to run and of

00:04:08,910 --> 00:04:12,630
course monitor the Redis process and you

00:04:10,980 --> 00:04:14,310
still need the persistent disk the

00:04:12,630 --> 00:04:15,989
configuration gets a little simpler you

00:04:14,310 --> 00:04:18,450
no longer have to do stuff like make the

00:04:15,989 --> 00:04:20,519
port or the location on persistent disk

00:04:18,450 --> 00:04:21,690
to store data anything other than static

00:04:20,519 --> 00:04:23,400
you're on you're gonna have one Redis on

00:04:21,690 --> 00:04:24,700
this machine you lose the noisy neighbor

00:04:23,400 --> 00:04:26,650
problem too

00:04:24,700 --> 00:04:30,160
now you've got to automate provisioning

00:04:26,650 --> 00:04:33,040
these single tenant virtual machines so

00:04:30,160 --> 00:04:34,510
how do we do this we use Bosch so I'm

00:04:33,040 --> 00:04:36,250
sure it seems like most of people in the

00:04:34,510 --> 00:04:38,890
room know this but it's preferred way in

00:04:36,250 --> 00:04:40,750
cloud foundry for managing deployments

00:04:38,890 --> 00:04:43,240
it manages the full lifecycle of

00:04:40,750 --> 00:04:44,890
software rights concerns with packaging

00:04:43,240 --> 00:04:47,530
your software deploying software running

00:04:44,890 --> 00:04:49,180
software and upgrading software it

00:04:47,530 --> 00:04:52,630
supports multi cloud so you've got

00:04:49,180 --> 00:04:55,390
vSphere AWS as your OpenStack cloud

00:04:52,630 --> 00:04:57,160
stack google google compute pretty much

00:04:55,390 --> 00:04:59,020
all of the main infrastructure providers

00:04:57,160 --> 00:05:02,190
so really this means that you can focus

00:04:59,020 --> 00:05:05,230
on your code and not the infrastructure

00:05:02,190 --> 00:05:10,960
you know because we do love Bashan Cloud

00:05:05,230 --> 00:05:12,310
Foundry so so this slide shows one

00:05:10,960 --> 00:05:15,400
pattern you could use to develop a

00:05:12,310 --> 00:05:16,960
single tenant Redis using Bosh we're

00:05:15,400 --> 00:05:20,320
gonna have four virtual machines

00:05:16,960 --> 00:05:22,090
three Redis VMs and one service broker

00:05:20,320 --> 00:05:23,860
when the broker receives a create

00:05:22,090 --> 00:05:25,720
service request it's gonna very simply

00:05:23,860 --> 00:05:27,430
allocate one of the pre provisioned

00:05:25,720 --> 00:05:29,860
Redis virtual machines from the pool and

00:05:27,430 --> 00:05:31,600
market is taken deep provisioning is a

00:05:29,860 --> 00:05:32,740
bit more complicated when someone gives

00:05:31,600 --> 00:05:33,910
up their instance you're going to want

00:05:32,740 --> 00:05:34,390
to recycle it because you're not gonna

00:05:33,910 --> 00:05:36,040
get anymore

00:05:34,390 --> 00:05:38,380
so you've got to scrub the stay off the

00:05:36,040 --> 00:05:40,150
persistent disk rotate the password

00:05:38,380 --> 00:05:42,580
probably bounce the process as well

00:05:40,150 --> 00:05:44,860
you'll probably need an agent kono kata

00:05:42,580 --> 00:05:47,350
Don the VM to do all of this um the

00:05:44,860 --> 00:05:49,450
upshot of using an approach like this is

00:05:47,350 --> 00:05:51,220
your operational story is a lot simpler

00:05:49,450 --> 00:05:52,660
the entire service offering and every

00:05:51,220 --> 00:05:56,260
instance are described by one bosch

00:05:52,660 --> 00:05:58,000
deployment but the big problem of course

00:05:56,260 --> 00:06:01,510
what happens when someone tries to

00:05:58,000 --> 00:06:04,330
create more than three instances oh it

00:06:01,510 --> 00:06:05,650
looks like instant creation will fail co

00:06:04,330 --> 00:06:07,240
the service broker would have noticed

00:06:05,650 --> 00:06:09,040
that the he only has three to give out

00:06:07,240 --> 00:06:11,740
and when you ask for the fourth there's

00:06:09,040 --> 00:06:13,060
none left so we're right back to here we

00:06:11,740 --> 00:06:15,250
have to send another email to the Cloud

00:06:13,060 --> 00:06:16,270
Foundry ops team and say can we increase

00:06:15,250 --> 00:06:18,850
the number of registers we have

00:06:16,270 --> 00:06:22,810
available on the platform and so why

00:06:18,850 --> 00:06:26,290
should developers be doing this so how

00:06:22,810 --> 00:06:28,450
about we deploy resources on demand so

00:06:26,290 --> 00:06:30,910
we use boss to do this and what would

00:06:28,450 --> 00:06:36,180
this look like effectively I mean CF

00:06:30,910 --> 00:06:38,020
crates service is a boss deploy and so

00:06:36,180 --> 00:06:38,620
let's take a look at what this is going

00:06:38,020 --> 00:06:41,780
to look like

00:06:38,620 --> 00:06:43,310
so a Bosch deployment is described by a

00:06:41,780 --> 00:06:45,710
Bosch manifest every deployment has

00:06:43,310 --> 00:06:47,990
exactly one manifest so the first job of

00:06:45,710 --> 00:06:49,580
a service broker that wants to deploy

00:06:47,990 --> 00:06:51,620
things on demand using Bosch when it

00:06:49,580 --> 00:06:54,080
receives a create service request is to

00:06:51,620 --> 00:06:55,310
generate a Bosch manifest then it

00:06:54,080 --> 00:06:57,980
creates the deployment by just sending

00:06:55,310 --> 00:06:59,390
that manifest to Bosch we then we don't

00:06:57,980 --> 00:07:01,010
care like we love Bosch we love what it

00:06:59,390 --> 00:07:02,390
does but we love that we don't have to

00:07:01,010 --> 00:07:03,830
think about it Bosch will just converge

00:07:02,390 --> 00:07:05,720
the state of the world into what's

00:07:03,830 --> 00:07:07,310
describes in your manifest there are a

00:07:05,720 --> 00:07:08,360
few problems with generating bosch

00:07:07,310 --> 00:07:11,810
manifests with code though that we're

00:07:08,360 --> 00:07:14,330
going to go through now so in a bush

00:07:11,810 --> 00:07:16,610
wonder a manifest some of the Aya's

00:07:14,330 --> 00:07:19,400
abstractions leaked into the manifest

00:07:16,610 --> 00:07:22,730
and it results in a as specific

00:07:19,400 --> 00:07:25,160
manifests and also you have a lot of

00:07:22,730 --> 00:07:26,990
stateful IP bookkeeping so the service

00:07:25,160 --> 00:07:28,370
broker has to handle giving out IP

00:07:26,990 --> 00:07:31,370
addresses and putting those in

00:07:28,370 --> 00:07:33,590
particular manifests and it also has to

00:07:31,370 --> 00:07:35,900
worry about running it over multiple

00:07:33,590 --> 00:07:38,750
availability zones so you in Bosch Wando

00:07:35,900 --> 00:07:41,030
manifest your handcrafting you have a

00:07:38,750 --> 00:07:43,190
diversity zillion structure and so this

00:07:41,030 --> 00:07:44,510
is lots of work and you know results in

00:07:43,190 --> 00:07:47,690
quite complex service broker

00:07:44,510 --> 00:07:50,210
architectures so this is a snippet from

00:07:47,690 --> 00:07:51,380
a Bosch one style manifest another kind

00:07:50,210 --> 00:07:54,230
of show of hands how many people have

00:07:51,380 --> 00:07:55,760
written Bosch manifests ok that's almost

00:07:54,230 --> 00:07:58,190
everyone again that's good

00:07:55,760 --> 00:08:00,080
so this is just a snippet it's not the

00:07:58,190 --> 00:08:01,700
whole thing obviously we're gonna

00:08:00,080 --> 00:08:03,710
highlight some of the issues but

00:08:01,700 --> 00:08:05,480
generating these first of all look at

00:08:03,710 --> 00:08:07,430
that static IPS blog you've got to keep

00:08:05,480 --> 00:08:08,960
a stateful representation of what you

00:08:07,430 --> 00:08:11,060
haven't haven't already assigned it

00:08:08,960 --> 00:08:12,050
forces the service developer to perform

00:08:11,060 --> 00:08:16,910
part of the role of a network

00:08:12,050 --> 00:08:18,410
administrator another snippet from the

00:08:16,910 --> 00:08:20,600
same manifest this is the concrete

00:08:18,410 --> 00:08:22,430
network definition specific to the CPI

00:08:20,600 --> 00:08:24,320
we're on looking at the cloud properties

00:08:22,430 --> 00:08:28,250
block at the bottom you can see that

00:08:24,320 --> 00:08:29,660
it's AWS now it's not a not a huge deal

00:08:28,250 --> 00:08:31,580
but you're gonna need a code path per

00:08:29,660 --> 00:08:34,400
CPR you want to support someone brings

00:08:31,580 --> 00:08:35,570
our new CPI and you have five service

00:08:34,400 --> 00:08:37,940
brokers let's say that are all doing

00:08:35,570 --> 00:08:40,450
this you've got a push and update to all

00:08:37,940 --> 00:08:43,040
five brokers it can become a pain

00:08:40,450 --> 00:08:44,990
similarly you've got cloud specific stem

00:08:43,040 --> 00:08:48,460
cell definition stem cell names even and

00:08:44,990 --> 00:08:48,460
virtual machine definitions

00:08:49,490 --> 00:08:54,980
so what comes along Bush to doe write

00:08:52,610 --> 00:08:56,780
songs of our problems it makes our lives

00:08:54,980 --> 00:08:58,610
a lot easier service developers and also

00:08:56,780 --> 00:09:01,900
anyone that will be running Bosch

00:08:58,610 --> 00:09:05,660
releases you know it's great and so

00:09:01,900 --> 00:09:07,070
really it's not a a to delay release as

00:09:05,660 --> 00:09:08,780
you might had earlier it's like a set of

00:09:07,070 --> 00:09:11,200
incremental features that have been put

00:09:08,780 --> 00:09:14,090
into Bosch over the last six months and

00:09:11,200 --> 00:09:17,810
then aiming to keep some backwards

00:09:14,090 --> 00:09:19,820
compatibility so let's go through some

00:09:17,810 --> 00:09:20,750
of the new features in in Bosch do some

00:09:19,820 --> 00:09:21,770
of them are a lot older than others

00:09:20,750 --> 00:09:24,170
because like Alex said they've been

00:09:21,770 --> 00:09:26,150
trickling in over a long time so static

00:09:24,170 --> 00:09:28,280
IPS have been optional for some time now

00:09:26,150 --> 00:09:32,240
if you omit them Bosch will dynamically

00:09:28,280 --> 00:09:33,590
assign an IP per job from whatever range

00:09:32,240 --> 00:09:35,900
you've configured from the networks and

00:09:33,590 --> 00:09:38,150
no more bookkeeping there was a kind of

00:09:35,900 --> 00:09:39,830
old trick people did for one job to

00:09:38,150 --> 00:09:41,690
discover another let's say you've got an

00:09:39,830 --> 00:09:43,790
errand that registers a service broker

00:09:41,690 --> 00:09:46,280
with Cloud Foundry and needs to know the

00:09:43,790 --> 00:09:48,140
service brokers IP address you you would

00:09:46,280 --> 00:09:50,900
in the past give the service broker a

00:09:48,140 --> 00:09:52,730
static IP and copy the IP into the

00:09:50,900 --> 00:09:55,460
properties block of the errand that

00:09:52,730 --> 00:09:57,920
needs it well we now got this feature

00:09:55,460 --> 00:09:59,450
job links that allows one job to

00:09:57,920 --> 00:10:02,210
discover facts about another such as the

00:09:59,450 --> 00:10:04,670
IP at a templating time so you never

00:10:02,210 --> 00:10:05,720
need to use static opiez in any

00:10:04,670 --> 00:10:08,270
circumstance that I can think of

00:10:05,720 --> 00:10:10,610
certainly CPI specific resource

00:10:08,270 --> 00:10:12,140
definitions to those subnets and BM

00:10:10,610 --> 00:10:14,960
types we saw earlier in the snippets

00:10:12,140 --> 00:10:17,480
these have all been moved up to a global

00:10:14,960 --> 00:10:18,980
cloud configuration manifests now only

00:10:17,480 --> 00:10:20,570
reference resources by their abstract

00:10:18,980 --> 00:10:22,580
name these names are then concrete

00:10:20,570 --> 00:10:23,840
defined in the cloud config the power of

00:10:22,580 --> 00:10:25,580
this is that manifests are now

00:10:23,840 --> 00:10:28,360
completely portable across different

00:10:25,580 --> 00:10:31,520
clouds no more code changes when someone

00:10:28,360 --> 00:10:33,160
wants to support a new new CPI in their

00:10:31,520 --> 00:10:35,420
broker it's all just done for you

00:10:33,160 --> 00:10:37,400
similarly like Alec Alex already said

00:10:35,420 --> 00:10:38,930
there's now first-class AZ support you

00:10:37,400 --> 00:10:40,340
don't need to do the trick anymore where

00:10:38,930 --> 00:10:43,490
you stripe the jobs across a ZZZ

00:10:40,340 --> 00:10:44,420
manually you define which a ZZZ you'd

00:10:43,490 --> 00:10:48,110
like to stripe across in your manifest

00:10:44,420 --> 00:10:50,450
and boss handles everything for you so

00:10:48,110 --> 00:10:54,130
this is an entire Bosh to manifest it's

00:10:50,450 --> 00:10:56,390
short enough to fit on one slide and

00:10:54,130 --> 00:10:58,910
down the bottom you can see an example

00:10:56,390 --> 00:11:00,290
of resources being referenced but not

00:10:58,910 --> 00:11:02,870
defined in the same manifest this

00:11:00,290 --> 00:11:03,420
manifest is portable to any Bosch

00:11:02,870 --> 00:11:06,570
director

00:11:03,420 --> 00:11:10,470
on any CPI much easier to generate

00:11:06,570 --> 00:11:13,140
encode for us lazy developers yes so

00:11:10,470 --> 00:11:15,240
this is all documented on the Bosch IO

00:11:13,140 --> 00:11:17,130
website so these are some of the main

00:11:15,240 --> 00:11:19,200
like features and so you can go to these

00:11:17,130 --> 00:11:21,390
links to check it out we're point upload

00:11:19,200 --> 00:11:22,980
the slides afterwards so you can get

00:11:21,390 --> 00:11:25,200
these links but it's quite easy to find

00:11:22,980 --> 00:11:28,260
on the site so what we're going to do

00:11:25,200 --> 00:11:31,110
now is you know went away taking these

00:11:28,260 --> 00:11:32,550
concepts and built like a example how

00:11:31,110 --> 00:11:34,470
you build a service broker so we're

00:11:32,550 --> 00:11:36,900
going to take a look at like the CFC Li

00:11:34,470 --> 00:11:40,380
life cycle and look at how that

00:11:36,900 --> 00:11:42,810
orchestrates Bosch tasks and I as we

00:11:40,380 --> 00:11:46,340
know resources so bear with me a sec

00:11:42,810 --> 00:11:46,340
well I try and get it out of this into a

00:11:48,140 --> 00:11:51,360
video yeah we're probably gonna have to

00:11:50,220 --> 00:12:02,790
flick through every slide again when

00:11:51,360 --> 00:12:05,180
this is done great okay yeah just play

00:12:02,790 --> 00:12:05,180
this here

00:12:06,960 --> 00:12:11,510
okay so what we're going to be doing

00:12:09,149 --> 00:12:14,010
here is using Redis as an example again

00:12:11,510 --> 00:12:14,880
and the first thing we want to do is see

00:12:14,010 --> 00:12:17,640
what's available to us in the

00:12:14,880 --> 00:12:18,779
marketplace I'm just gonna stop there

00:12:17,640 --> 00:12:27,680
since see if I make a little bit bigger

00:12:18,779 --> 00:12:27,680
so great

00:12:29,050 --> 00:12:33,670
okay so we can see that we've got an

00:12:31,149 --> 00:12:36,760
on-demand Redis broker and we've got a

00:12:33,670 --> 00:12:38,230
dedicated Redis plan available and so

00:12:36,760 --> 00:12:40,540
what we're going to do is create a

00:12:38,230 --> 00:12:43,300
service and this will use the Cloud

00:12:40,540 --> 00:12:44,920
Foundry async provisioning feature and

00:12:43,300 --> 00:12:46,360
so what cloud controller does is sends a

00:12:44,920 --> 00:12:48,160
request to the service broker the

00:12:46,360 --> 00:12:49,570
service broker accepts it and then the

00:12:48,160 --> 00:12:52,240
cloud controller will keep polling the

00:12:49,570 --> 00:12:54,040
service broker saying is it done yet so

00:12:52,240 --> 00:12:55,990
you can see what's happened here is that

00:12:54,040 --> 00:12:59,230
the service broker has created a Bosch

00:12:55,990 --> 00:13:01,660
task this is a new boss deployment for

00:12:59,230 --> 00:13:03,850
Redis so this is Yano provision a VM you

00:13:01,660 --> 00:13:07,329
can see here the Bosch is talking to the

00:13:03,850 --> 00:13:10,089
IRS to provision this VM and so what

00:13:07,329 --> 00:13:13,000
this results in in AWS is a new VM

00:13:10,089 --> 00:13:16,170
coming up you as expected with Bosch and

00:13:13,000 --> 00:13:19,570
so here you can see that we've got a t2

00:13:16,170 --> 00:13:21,190
was at t2 Micro yes there's a really

00:13:19,570 --> 00:13:24,130
small Reddy's instance suitable for like

00:13:21,190 --> 00:13:26,110
a development use case so now a Bosch

00:13:24,130 --> 00:13:28,029
will lay down the Redis software like we

00:13:26,110 --> 00:13:29,230
described earlier and it's gonna monitor

00:13:28,029 --> 00:13:32,410
make sure that all those processes are

00:13:29,230 --> 00:13:34,690
healthy and so once it's done that or

00:13:32,410 --> 00:13:36,730
we'll come back to you know report

00:13:34,690 --> 00:13:38,140
success and in the meantime the Cloud

00:13:36,730 --> 00:13:40,149
Controller is still polling the service

00:13:38,140 --> 00:13:42,700
broker saying you know it's my service

00:13:40,149 --> 00:13:45,149
instance ready yet and so here you can

00:13:42,700 --> 00:13:47,829
see that it's still in progress and

00:13:45,149 --> 00:13:50,589
within a minute we should have it have

00:13:47,829 --> 00:13:52,390
it created successfully and so you can

00:13:50,589 --> 00:13:54,399
see that we've easily gone from cf great

00:13:52,390 --> 00:13:56,589
service talking to the service broker

00:13:54,399 --> 00:13:58,570
and then resulted in a new radius

00:13:56,589 --> 00:14:00,579
deployment so let's have a look at how

00:13:58,570 --> 00:14:02,320
we could reconfigure this so you've got

00:14:00,579 --> 00:14:04,570
your own dedicated Redis you know that

00:14:02,320 --> 00:14:06,550
was really easy but you might want to

00:14:04,570 --> 00:14:08,800
fine-tune some of the configuration so

00:14:06,550 --> 00:14:10,810
we're going to push an example app this

00:14:08,800 --> 00:14:12,730
example app allows us to read and write

00:14:10,810 --> 00:14:15,520
from Redis also check out the rightest

00:14:12,730 --> 00:14:16,930
configuration so you can see here that

00:14:15,520 --> 00:14:20,140
we're just pushing it and binding it to

00:14:16,930 --> 00:14:22,000
the service and so once we have the

00:14:20,140 --> 00:14:23,470
application up and running we're just

00:14:22,000 --> 00:14:25,089
going to make sure that Redis is healthy

00:14:23,470 --> 00:14:31,390
and we're just going to try and write

00:14:25,089 --> 00:14:33,279
some data to Redis so you can see next

00:14:31,390 --> 00:14:35,529
so the video might be on the point but

00:14:33,279 --> 00:14:38,529
we've effectively got the application

00:14:35,529 --> 00:14:41,680
running and bound and now we are going

00:14:38,529 --> 00:14:42,850
to issue a command to Redis to write

00:14:41,680 --> 00:14:45,160
some data which was a success

00:14:42,850 --> 00:14:46,539
so next we want to try and change your

00:14:45,160 --> 00:14:49,689
configuration so we're gonna we've

00:14:46,539 --> 00:14:51,249
chosen the max clients Redis which you

00:14:49,689 --> 00:14:54,519
can see in a sec by default this is set

00:14:51,249 --> 00:14:56,739
to 100 and so we want to limit how many

00:14:54,519 --> 00:14:58,239
people can connect to our Redis and by

00:14:56,739 --> 00:15:00,999
default we're gonna set the max clients

00:14:58,239 --> 00:15:02,350
to 10 so this is something that as a

00:15:00,999 --> 00:15:04,809
developer you might want to put

00:15:02,350 --> 00:15:06,999
constraints on in your service so what

00:15:04,809 --> 00:15:10,089
we're gonna do is do this update service

00:15:06,999 --> 00:15:11,709
and pass in an arbitrary pram again you

00:15:10,089 --> 00:15:13,139
can see a common pattern here right with

00:15:11,709 --> 00:15:15,699
the service brokers received a request

00:15:13,139 --> 00:15:18,189
generated a new manifest send it to Bosh

00:15:15,699 --> 00:15:20,769
and then Bosh has community started the

00:15:18,189 --> 00:15:22,689
deployment and it is going to update the

00:15:20,769 --> 00:15:25,089
deployment lay down in the new

00:15:22,689 --> 00:15:26,859
configuration and so let's see run the

00:15:25,089 --> 00:15:29,649
max clients command again and see if

00:15:26,859 --> 00:15:31,449
that's changed and so yet boss has done

00:15:29,649 --> 00:15:34,389
the deployment and we've changed the max

00:15:31,449 --> 00:15:36,189
clients to 10 so this is giving the CLI

00:15:34,389 --> 00:15:39,009
user a lot more power around how they

00:15:36,189 --> 00:15:41,019
manage their service so finally we're

00:15:39,009 --> 00:15:43,389
going to look at switching Redis over on

00:15:41,019 --> 00:15:45,009
to a high memory VM so a use case for

00:15:43,389 --> 00:15:47,769
this is like your apps running out of

00:15:45,009 --> 00:15:50,049
memory in Redis and you want a new a new

00:15:47,769 --> 00:15:52,089
bigger Redis right it's quite common so

00:15:50,049 --> 00:15:53,649
you do this through a plan migration so

00:15:52,089 --> 00:15:57,789
we're changing over to a high memory

00:15:53,649 --> 00:16:00,309
plan and I think you might be shocked to

00:15:57,789 --> 00:16:02,979
this but we're gonna use Bosh again to

00:16:00,309 --> 00:16:06,069
upgrade the deployment and what this

00:16:02,979 --> 00:16:09,039
does behind the scenes as is detaches

00:16:06,069 --> 00:16:10,659
the disk from the old Redis VM and it

00:16:09,039 --> 00:16:12,100
will bring up a new high memory VM here

00:16:10,659 --> 00:16:14,679
you can see we're going for like an r3

00:16:12,100 --> 00:16:17,709
large and then you know Bosch is going

00:16:14,679 --> 00:16:23,259
to reattach the disk and it'll mean that

00:16:17,709 --> 00:16:25,239
we have pretty easily switched over the

00:16:23,259 --> 00:16:27,220
VM type all using the power Bosch and

00:16:25,239 --> 00:16:29,139
the service broker effectively just

00:16:27,220 --> 00:16:31,720
becomes a manifest generator and

00:16:29,139 --> 00:16:34,179
instructs Bosch so that's kind of the

00:16:31,720 --> 00:16:35,979
end of the demo but you can see this is

00:16:34,179 --> 00:16:38,049
quite a powerful experience for CLI

00:16:35,979 --> 00:16:40,589
users now so let me try and get back

00:16:38,049 --> 00:16:40,589
into the slides

00:16:44,740 --> 00:16:47,980
[Applause]

00:16:49,859 --> 00:16:54,159
so that demo was made entirely using

00:16:52,839 --> 00:16:55,419
shell scripts that look like they're

00:16:54,159 --> 00:16:58,659
creating watch deployments but really

00:16:55,419 --> 00:17:01,779
they no no no I'm kidding it was it was

00:16:58,659 --> 00:17:03,399
recreated using entirely features that

00:17:01,779 --> 00:17:05,079
are available in open source Cloud

00:17:03,399 --> 00:17:11,429
Foundry an open source Bosh so you could

00:17:05,079 --> 00:17:11,429
make something like this today yep

00:17:12,089 --> 00:17:24,909
so this Santa comes back on track great

00:17:22,319 --> 00:17:27,220
so this is fantastic for app developers

00:17:24,909 --> 00:17:28,960
this gives up developers more control

00:17:27,220 --> 00:17:30,249
over provisioning and managing their

00:17:28,960 --> 00:17:32,619
stateful services than ever before

00:17:30,249 --> 00:17:34,690
crucially it even gives them the ability

00:17:32,619 --> 00:17:36,700
to provision and manage hires resources

00:17:34,690 --> 00:17:38,740
which quite possibly they won't have

00:17:36,700 --> 00:17:42,970
done before this can move organizations

00:17:38,740 --> 00:17:44,139
to a more DevOps oriented culture so you

00:17:42,970 --> 00:17:47,259
can see that we can offer these cool

00:17:44,139 --> 00:17:49,119
experiences around managing of services

00:17:47,259 --> 00:17:52,450
from the CLI so today you would probably

00:17:49,119 --> 00:17:54,159
use like arbitrary parameter configure

00:17:52,450 --> 00:17:57,460
this so we're gonna help look at example

00:17:54,159 --> 00:17:59,019
here where we're scaling a cluster right

00:17:57,460 --> 00:18:01,090
so you might want to have a Cassandra

00:17:59,019 --> 00:18:02,649
service and all of a sudden you want to

00:18:01,090 --> 00:18:04,809
scale the number of seed nodes in your

00:18:02,649 --> 00:18:06,039
cluster so you could pass an arbitrary

00:18:04,809 --> 00:18:07,809
pram that would get through to the

00:18:06,039 --> 00:18:09,970
service broker and here we're saying we

00:18:07,809 --> 00:18:11,559
want five seed nodes so the service

00:18:09,970 --> 00:18:13,480
broker would then receive this it would

00:18:11,559 --> 00:18:16,600
generate a new manifest just increasing

00:18:13,480 --> 00:18:17,740
the instance count and deploy this so

00:18:16,600 --> 00:18:20,470
this is pretty awesome because now the

00:18:17,740 --> 00:18:22,539
CLI user the app developer is in control

00:18:20,470 --> 00:18:25,960
of you know scaling their cluster

00:18:22,539 --> 00:18:27,519
dynamically as they see fit it's

00:18:25,960 --> 00:18:30,159
currently we do this often through plans

00:18:27,519 --> 00:18:33,850
so you change your plan you know which

00:18:30,159 --> 00:18:35,950
isn't great and you know we currently

00:18:33,850 --> 00:18:38,200
have no control for app developers often

00:18:35,950 --> 00:18:39,940
when your service gets upgraded right so

00:18:38,200 --> 00:18:42,399
if you're changing major versions of

00:18:39,940 --> 00:18:44,919
your service you know your bump you

00:18:42,399 --> 00:18:46,330
might be changing your Redis version and

00:18:44,919 --> 00:18:48,220
it might have braking changes so at the

00:18:46,330 --> 00:18:50,049
moment as of a weird cycle between

00:18:48,220 --> 00:18:51,490
operators and app developers to let them

00:18:50,049 --> 00:18:52,539
know there's new software available and

00:18:51,490 --> 00:18:55,269
they're going to be upgrading on this

00:18:52,539 --> 00:18:56,710
date but you could move this over to

00:18:55,269 --> 00:18:58,450
allow the application developer

00:18:56,710 --> 00:19:00,700
to have some control of when they get to

00:18:58,450 --> 00:19:02,169
upgrade their service so you can see

00:19:00,700 --> 00:19:04,059
here that the we would use laboratory

00:19:02,169 --> 00:19:06,520
params to pass in you know upgrade

00:19:04,059 --> 00:19:08,590
command we could generate a manifest for

00:19:06,520 --> 00:19:12,250
the new version of Redis you know all

00:19:08,590 --> 00:19:13,270
controlled from the app developer so

00:19:12,250 --> 00:19:14,740
we're just going to look at it like is

00:19:13,270 --> 00:19:16,779
it time for a richer Cloud Foundry

00:19:14,740 --> 00:19:19,630
service experience and what would this

00:19:16,779 --> 00:19:22,630
experience possibly look like so these

00:19:19,630 --> 00:19:25,539
next few slides are not using real CFC

00:19:22,630 --> 00:19:27,909
ly commands that using potential CF CLI

00:19:25,539 --> 00:19:29,559
commands that achieve the same things as

00:19:27,909 --> 00:19:32,529
the previous slides did with arbitary

00:19:29,559 --> 00:19:34,899
parameters so what are the advantages to

00:19:32,529 --> 00:19:35,500
making CF upgrade service a first-class

00:19:34,899 --> 00:19:38,440
citizen

00:19:35,500 --> 00:19:41,049
well for one unifies the UX around

00:19:38,440 --> 00:19:43,270
upgrades if you had lots of services

00:19:41,049 --> 00:19:45,309
lots of service brokers offering

00:19:43,270 --> 00:19:46,809
upgrades with differently named RPG

00:19:45,309 --> 00:19:50,049
params that can get confusing and

00:19:46,809 --> 00:19:52,000
frustrating for the CLI user if upgrade

00:19:50,049 --> 00:19:55,270
service was a first-class citizen it's

00:19:52,000 --> 00:19:56,950
implied that CLI users app developers

00:19:55,270 --> 00:19:58,870
would be able to discover their upgrade

00:19:56,950 --> 00:20:01,480
path as well using the CLI rather than

00:19:58,870 --> 00:20:03,549
poking around in Bosh and asking service

00:20:01,480 --> 00:20:04,750
developers so that's that's a thing that

00:20:03,549 --> 00:20:09,640
potentially could be explored in the

00:20:04,750 --> 00:20:11,950
future similarly and same UX argument as

00:20:09,640 --> 00:20:13,570
before but for scaling scaling the

00:20:11,950 --> 00:20:15,669
instance count of clustered services is

00:20:13,570 --> 00:20:17,590
extremely common currently it's often

00:20:15,669 --> 00:20:19,659
accomplished through having lots of

00:20:17,590 --> 00:20:22,390
plans the advantage of doing it through

00:20:19,659 --> 00:20:24,309
an arbitrary parameter is that you deep

00:20:22,390 --> 00:20:26,500
clutter the services marketplace you

00:20:24,309 --> 00:20:27,850
don't have so many plans if the service

00:20:26,500 --> 00:20:29,919
developer wants to offer a large range

00:20:27,850 --> 00:20:32,500
of instance counts they can instead just

00:20:29,919 --> 00:20:37,480
pass that responsibility to to the app

00:20:32,500 --> 00:20:40,480
development so while this all sounds

00:20:37,480 --> 00:20:43,000
pretty awesome it does really make some

00:20:40,480 --> 00:20:44,440
huge operational challenges so imagine

00:20:43,000 --> 00:20:47,049
you've got an organization that's

00:20:44,440 --> 00:20:48,850
creating you know services you create 50

00:20:47,049 --> 00:20:50,740
registers you create 50 Cassandra

00:20:48,850 --> 00:20:52,539
clusters you've got a ton of boss

00:20:50,740 --> 00:20:54,850
deployments and Basch deployments mean

00:20:52,539 --> 00:20:57,010
like resource usage so the boss

00:20:54,850 --> 00:20:58,870
deployments we use your iers resources

00:20:57,010 --> 00:21:01,600
which you get charged for or it might

00:20:58,870 --> 00:21:02,799
use your internal you know vSphere again

00:21:01,600 --> 00:21:04,990
you're going to need some way of

00:21:02,799 --> 00:21:06,820
monitoring who's using the resources how

00:21:04,990 --> 00:21:08,260
much they're using are they efficiently

00:21:06,820 --> 00:21:09,549
using them you know does this

00:21:08,260 --> 00:21:11,230
development team really need the biggest

00:21:09,549 --> 00:21:13,480
Cassandra cluster

00:21:11,230 --> 00:21:15,580
another example would be quota

00:21:13,480 --> 00:21:17,559
management and chargebacks that's like a

00:21:15,580 --> 00:21:19,809
common request around services how do

00:21:17,559 --> 00:21:21,190
you manage this and then effectively as

00:21:19,809 --> 00:21:23,919
you're going to see your AWS bill

00:21:21,190 --> 00:21:25,149
ticking up and up and up you know you

00:21:23,919 --> 00:21:30,250
want might want some quota management

00:21:25,149 --> 00:21:32,140
around that so when I mentioned earlier

00:21:30,250 --> 00:21:34,090
that app developers having control of

00:21:32,140 --> 00:21:36,159
Aya's resource provisioning was a

00:21:34,090 --> 00:21:38,140
benefit for them it could also be

00:21:36,159 --> 00:21:40,539
considered a risk from the point of view

00:21:38,140 --> 00:21:42,490
of operators it's possible using all of

00:21:40,539 --> 00:21:44,980
these features today to build a very

00:21:42,490 --> 00:21:47,019
flexible service broker that puts almost

00:21:44,980 --> 00:21:49,539
full control of I's resources instance

00:21:47,019 --> 00:21:52,120
accounts etc upgrade life cycle even

00:21:49,539 --> 00:21:54,370
into the hands of app developers do

00:21:52,120 --> 00:21:56,409
operators want to permit a service

00:21:54,370 --> 00:21:58,330
broker on their platform that allows app

00:21:56,409 --> 00:22:00,429
developers to stay on an arbitrarily old

00:21:58,330 --> 00:22:02,980
version of Redis forever and then

00:22:00,429 --> 00:22:05,019
upgrade to the newer one using an

00:22:02,980 --> 00:22:07,510
unpredictable path do they want to

00:22:05,019 --> 00:22:09,220
permit service brokers that allow you

00:22:07,510 --> 00:22:11,559
know indefinite scaling of nodes

00:22:09,220 --> 00:22:13,480
probably not so the balance to be had

00:22:11,559 --> 00:22:17,529
here and this is a new challenge for

00:22:13,480 --> 00:22:18,639
operators yes so with that you know we

00:22:17,529 --> 00:22:20,080
hope you would given you something to

00:22:18,639 --> 00:22:22,600
think about especially with the last few

00:22:20,080 --> 00:22:25,120
slides and I believe we've still got a

00:22:22,600 --> 00:22:33,340
bit of time if some questions if anyone

00:22:25,120 --> 00:22:34,960
had a in the back left the example

00:22:33,340 --> 00:22:41,250
service poke you saw and this was not

00:22:34,960 --> 00:22:41,250
yet open source Hey

00:22:46,450 --> 00:22:51,159
yes so the failure so the question is

00:22:48,820 --> 00:22:52,600
around like Bosch failure which is quite

00:22:51,159 --> 00:22:54,669
an interesting scenario where the box

00:22:52,600 --> 00:22:56,169
deployment might not succeed and you

00:22:54,669 --> 00:22:58,749
might have some leftover resources that

00:22:56,169 --> 00:22:59,830
need to be cleaned up there you would

00:22:58,749 --> 00:23:01,419
need if you're building a service broke

00:22:59,830 --> 00:23:03,340
like this you'll need you know lots of

00:23:01,419 --> 00:23:05,619
logging and metrics and feedback cycle

00:23:03,340 --> 00:23:09,039
to operators if something did go wrong

00:23:05,619 --> 00:23:10,809
so there's also a UX element to this so

00:23:09,039 --> 00:23:12,789
when an asynchronous service

00:23:10,809 --> 00:23:15,070
provisioning or or update or deletion

00:23:12,789 --> 00:23:17,259
for that matter fails the service broker

00:23:15,070 --> 00:23:19,869
can send back some message that gets

00:23:17,259 --> 00:23:21,249
displayed on the CLI so again it's in

00:23:19,869 --> 00:23:22,659
the hands of the service developer do

00:23:21,249 --> 00:23:24,340
they download all the output from the

00:23:22,659 --> 00:23:26,799
Boche tasks and expose that yeah the app

00:23:24,340 --> 00:23:28,960
developer that's maybe that's some

00:23:26,799 --> 00:23:34,409
that's for the people who product wise

00:23:28,960 --> 00:23:34,409
these things too to decide anyone else

00:23:35,129 --> 00:23:38,540
okay great well thanks for listening and

00:23:37,690 --> 00:23:45,690
just

00:23:38,540 --> 00:23:45,690

YouTube URL: https://www.youtube.com/watch?v=reWJDcqCqPY


