Title: App Logging in Cloud Foundry for Kubernetes - Travis Patterson & Jesse Weaver, Vmware
Publication date: 2020-10-26
Playlist: Cloud Foundry Summit Europe 2020
Description: 
	App Logging in Cloud Foundry for Kubernetes - Travis Patterson & Jesse Weaver, Vmware

Transitioning to Cloud Foundry for Kubernetes has allowed the Logging and Metrics team at VMware to dramatically rethink and simplify the CF logging experience. In this presentation we'll talk about the new architecture, what operators can expect right now, and upcoming improvements.
Captions: 
	00:00:00,080 --> 00:00:03,840
hello everybody my name is jesse weaver

00:00:02,560 --> 00:00:07,040
i'm a product manager

00:00:03,840 --> 00:00:07,600
on the logging and metrics team been

00:00:07,040 --> 00:00:09,440
working on

00:00:07,600 --> 00:00:10,719
as a product manager on that team for

00:00:09,440 --> 00:00:13,920
about a year or so now

00:00:10,719 --> 00:00:16,400
previously a software developer with

00:00:13,920 --> 00:00:16,960
pivotal now vmware we're here to talk to

00:00:16,400 --> 00:00:18,640
you about

00:00:16,960 --> 00:00:21,279
app logging in cloud foundry for

00:00:18,640 --> 00:00:23,279
kubernetes and i am joined by

00:00:21,279 --> 00:00:24,640
hi there my name is travis patterson uh

00:00:23,279 --> 00:00:25,359
i'm an engineer on the logging and

00:00:24,640 --> 00:00:27,840
metrics team

00:00:25,359 --> 00:00:29,039
i've been working on the team for just

00:00:27,840 --> 00:00:31,920
under three years

00:00:29,039 --> 00:00:33,760
and i've worked in sort of a capacity as

00:00:31,920 --> 00:00:34,640
sort of an engineer and also the anchor

00:00:33,760 --> 00:00:37,840
on the team

00:00:34,640 --> 00:00:39,600
um and sort of i've kind of seen the

00:00:37,840 --> 00:00:44,399
evolution from kind of what we were

00:00:39,600 --> 00:00:45,760
to what we're trying to get to

00:00:44,399 --> 00:00:47,440
and so what we're going to talk about

00:00:45,760 --> 00:00:48,960
today is some of that history i just

00:00:47,440 --> 00:00:51,280
mentioned kind of where

00:00:48,960 --> 00:00:52,480
the logging system came from and sort of

00:00:51,280 --> 00:00:55,280
what informed

00:00:52,480 --> 00:00:56,800
our design decisions as we move forward

00:00:55,280 --> 00:01:00,079
what the new thing looks like

00:00:56,800 --> 00:01:01,760
uh cf kate's logging how to use it and

00:01:00,079 --> 00:01:03,440
by how to use it we're talking about

00:01:01,760 --> 00:01:04,960
sort of the expectations that you can

00:01:03,440 --> 00:01:07,600
have of the contracts

00:01:04,960 --> 00:01:08,720
around it and the apis and then sort of

00:01:07,600 --> 00:01:10,960
like what's next

00:01:08,720 --> 00:01:12,960
for the logging system what kind of

00:01:10,960 --> 00:01:15,840
ideas do we have to make it like better

00:01:12,960 --> 00:01:15,840
or more useful

00:01:17,040 --> 00:01:21,119
and so we've kind of got a short history

00:01:18,880 --> 00:01:22,320
the old logging system or the current

00:01:21,119 --> 00:01:26,159
logging system i guess

00:01:22,320 --> 00:01:28,960
in cf is called logger gator and it

00:01:26,159 --> 00:01:29,600
is essentially designed to vacuum up all

00:01:28,960 --> 00:01:31,840
of the

00:01:29,600 --> 00:01:32,640
application logs from the platform and

00:01:31,840 --> 00:01:34,880
egress them

00:01:32,640 --> 00:01:37,280
out of a single api endpoint that we've

00:01:34,880 --> 00:01:39,439
historically called the fire hose

00:01:37,280 --> 00:01:40,560
it facilitates the sort of like pub sub

00:01:39,439 --> 00:01:44,079
kind of interaction

00:01:40,560 --> 00:01:46,240
where operators or users can ask for

00:01:44,079 --> 00:01:48,560
usually some sort of filtered subset of

00:01:46,240 --> 00:01:50,159
the logs or everything at once to

00:01:48,560 --> 00:01:53,040
facilitate to facilitate

00:01:50,159 --> 00:01:54,479
integrations with the platform it was

00:01:53,040 --> 00:01:57,680
designed to scale

00:01:54,479 --> 00:02:00,000
uh pretty large so large foundations

00:01:57,680 --> 00:02:01,840
can commonly emit hundreds of thousands

00:02:00,000 --> 00:02:03,600
of logs and metrics a second

00:02:01,840 --> 00:02:05,600
and was also designed to sort of give

00:02:03,600 --> 00:02:08,080
integrators the option to

00:02:05,600 --> 00:02:10,560
filter and aggregate the metrics and

00:02:08,080 --> 00:02:12,239
logs in ways that they found useful

00:02:10,560 --> 00:02:13,760
over the years we've introduced several

00:02:12,239 --> 00:02:15,920
apis

00:02:13,760 --> 00:02:18,160
the first one being the sort of vanilla

00:02:15,920 --> 00:02:20,480
v1 fire hose this gives you

00:02:18,160 --> 00:02:22,480
all of the logs all of the logs and

00:02:20,480 --> 00:02:23,520
metrics or just all of the metrics

00:02:22,480 --> 00:02:26,000
so the filtering there is pretty

00:02:23,520 --> 00:02:27,520
coarse-grained then we introduced a v2

00:02:26,000 --> 00:02:28,800
api

00:02:27,520 --> 00:02:30,879
and that gives you sort of some more

00:02:28,800 --> 00:02:33,680
fine-grained filtering capabilities

00:02:30,879 --> 00:02:35,760
so you can sort of ask for logs from

00:02:33,680 --> 00:02:36,480
only a small subset of apps or you can

00:02:35,760 --> 00:02:39,040
ask for

00:02:36,480 --> 00:02:41,360
only a subset of metrics in addition to

00:02:39,040 --> 00:02:42,720
logs or any combination of those two

00:02:41,360 --> 00:02:44,800
and finally what we've done is for that

00:02:42,720 --> 00:02:45,920
v2 api there are two different ways that

00:02:44,800 --> 00:02:48,560
you can integrate with it

00:02:45,920 --> 00:02:49,680
one is via grpc via a bosch deployed

00:02:48,560 --> 00:02:51,519
component

00:02:49,680 --> 00:02:53,360
or an app that's sort of poked a

00:02:51,519 --> 00:02:56,319
security hole in to be able to

00:02:53,360 --> 00:03:00,560
access that or through an http api where

00:02:56,319 --> 00:03:00,560
we stream the logs by json back to you

00:03:01,360 --> 00:03:05,360
and so while aggregator has evolved to

00:03:03,360 --> 00:03:07,599
meet these needs and it's done a

00:03:05,360 --> 00:03:09,200
pretty good job of it it's managed to

00:03:07,599 --> 00:03:10,800
get hit a lot of these throughput goals

00:03:09,200 --> 00:03:12,480
it's managed to service a lot of these

00:03:10,800 --> 00:03:14,640
use cases

00:03:12,480 --> 00:03:16,159
but that hasn't come without pain

00:03:14,640 --> 00:03:18,640
unfortunately

00:03:16,159 --> 00:03:19,840
one of the biggest pains that people

00:03:18,640 --> 00:03:21,599
trying to

00:03:19,840 --> 00:03:23,599
work on this system people trying to

00:03:21,599 --> 00:03:25,360
operate the system run into

00:03:23,599 --> 00:03:28,080
is the complexity of the architecture

00:03:25,360 --> 00:03:28,560
involved what we see here is kind of the

00:03:28,080 --> 00:03:32,879
full

00:03:28,560 --> 00:03:35,840
flow left to right of logs and metrics

00:03:32,879 --> 00:03:37,200
from the systems components applications

00:03:35,840 --> 00:03:39,920
that are producing them

00:03:37,200 --> 00:03:42,239
through a couple of routing tiers to

00:03:39,920 --> 00:03:45,519
their final destination

00:03:42,239 --> 00:03:47,680
and this works but it's

00:03:45,519 --> 00:03:48,720
difficult to understand all of the flows

00:03:47,680 --> 00:03:51,920
that you need

00:03:48,720 --> 00:03:54,720
and it goes pretty concretely into the

00:03:51,920 --> 00:03:57,760
next pain point

00:03:54,720 --> 00:03:58,879
scaling this whole system so each one of

00:03:57,760 --> 00:04:01,680
these hops

00:03:58,879 --> 00:04:02,319
as lawson metrics travel through has

00:04:01,680 --> 00:04:05,120
their own

00:04:02,319 --> 00:04:06,560
complex scaling criteria they're metrics

00:04:05,120 --> 00:04:08,799
that need to be understood there are

00:04:06,560 --> 00:04:10,720
best practices in terms of vm sizing

00:04:08,799 --> 00:04:14,239
that need to be understood

00:04:10,720 --> 00:04:16,400
and understanding a final symptom of

00:04:14,239 --> 00:04:17,359
logs aren't coming out metrics aren't

00:04:16,400 --> 00:04:20,400
coming out

00:04:17,359 --> 00:04:22,800
my developers are unhappy my

00:04:20,400 --> 00:04:23,759
stakeholders are unhappy requires

00:04:22,800 --> 00:04:26,240
understanding this

00:04:23,759 --> 00:04:27,360
whole chain and making sure that each

00:04:26,240 --> 00:04:30,479
part of it

00:04:27,360 --> 00:04:33,759
is healthy this last

00:04:30,479 --> 00:04:35,840
pain that folks run into affects even

00:04:33,759 --> 00:04:39,440
people outside of the cloud foundry

00:04:35,840 --> 00:04:41,840
ecosystem because most of the components

00:04:39,440 --> 00:04:43,440
and formats that are used within logger

00:04:41,840 --> 00:04:45,280
are ones that have been originated

00:04:43,440 --> 00:04:48,240
within loggregator

00:04:45,280 --> 00:04:49,120
within the cloud foundry ecosystem for

00:04:48,240 --> 00:04:51,840
instance

00:04:49,120 --> 00:04:52,639
everything must consume the loggergator

00:04:51,840 --> 00:04:56,000
envelope

00:04:52,639 --> 00:04:59,759
format containing those laws and metrics

00:04:56,000 --> 00:05:03,600
this format has a v1 and v2 variant

00:04:59,759 --> 00:05:05,919
with some subtly different semantics and

00:05:03,600 --> 00:05:07,840
logging is the original focus of all of

00:05:05,919 --> 00:05:10,960
this metrics have been lunked

00:05:07,840 --> 00:05:13,520
into the same pipeline within the same

00:05:10,960 --> 00:05:14,479
envelope format so their transport is

00:05:13,520 --> 00:05:16,720
tied together

00:05:14,479 --> 00:05:18,160
even though your expectations of how

00:05:16,720 --> 00:05:19,199
many logs need to make it to a

00:05:18,160 --> 00:05:20,560
destination

00:05:19,199 --> 00:05:22,400
probably very different than your

00:05:20,560 --> 00:05:24,960
expectation of how many metrics

00:05:22,400 --> 00:05:25,600
need to get to their final destination

00:05:24,960 --> 00:05:28,479
and

00:05:25,600 --> 00:05:29,600
like they're both part of this same

00:05:28,479 --> 00:05:33,120
push-based

00:05:29,600 --> 00:05:33,919
single event based format and dealing

00:05:33,120 --> 00:05:37,440
with this

00:05:33,919 --> 00:05:40,000
api only helps integrators deal with

00:05:37,440 --> 00:05:41,600
cloud foundry this is something that

00:05:40,000 --> 00:05:44,320
needs to be replicated across

00:05:41,600 --> 00:05:46,240
each individual integrator or developer

00:05:44,320 --> 00:05:48,800
wanting to work with cloud foundry

00:05:46,240 --> 00:05:52,639
and that's not going to buy them much on

00:05:48,800 --> 00:05:54,639
any other platform

00:05:52,639 --> 00:05:56,479
so let's talk about where we've ended up

00:05:54,639 --> 00:05:58,240
and so the first thing we'll notice

00:05:56,479 --> 00:05:59,759
about our new architecture is that it's

00:05:58,240 --> 00:06:01,360
dramatically simpler

00:05:59,759 --> 00:06:03,680
and what we've done is we've focused it

00:06:01,360 --> 00:06:05,440
around a fluent de-daemon set

00:06:03,680 --> 00:06:06,720
we've also focused it around a couple of

00:06:05,440 --> 00:06:09,199
core use cases

00:06:06,720 --> 00:06:10,319
one of those being egress of the

00:06:09,199 --> 00:06:12,319
platform's

00:06:10,319 --> 00:06:14,160
application logs to some sort of third

00:06:12,319 --> 00:06:17,600
party integration service

00:06:14,160 --> 00:06:18,880
something like splunk or paper trail or

00:06:17,600 --> 00:06:20,880
something like that

00:06:18,880 --> 00:06:22,800
or sending logs in such a way that they

00:06:20,880 --> 00:06:26,240
could be accessed from the cfcli

00:06:22,800 --> 00:06:28,639
for your cf logs command so for

00:06:26,240 --> 00:06:29,680
application logs or things like build

00:06:28,639 --> 00:06:33,120
container logs

00:06:29,680 --> 00:06:35,680
um any sort of pod that has

00:06:33,120 --> 00:06:36,720
containers that have got associated app

00:06:35,680 --> 00:06:39,680
ids

00:06:36,720 --> 00:06:41,600
we just deploy a tail input plug-in with

00:06:39,680 --> 00:06:43,280
our fluentds and we sort of tail all the

00:06:41,600 --> 00:06:45,120
logs on all of the nodes

00:06:43,280 --> 00:06:46,720
and we slurp up the ones that are

00:06:45,120 --> 00:06:49,440
associated with apps

00:06:46,720 --> 00:06:51,280
we uh curate the metadata a little bit

00:06:49,440 --> 00:06:53,520
and then we send those logs along

00:06:51,280 --> 00:06:55,840
to one of these sort of third-party or

00:06:53,520 --> 00:06:58,080
uh cf logs integrations

00:06:55,840 --> 00:06:59,360
if there are other components that want

00:06:58,080 --> 00:07:02,479
their logs to be

00:06:59,360 --> 00:07:04,319
intermingled within the apps log stream

00:07:02,479 --> 00:07:05,840
and sort of examples of this are the

00:07:04,319 --> 00:07:08,560
routing tier for

00:07:05,840 --> 00:07:10,240
requests coming and going and some cappy

00:07:08,560 --> 00:07:11,759
logs for things like how your app is

00:07:10,240 --> 00:07:12,800
staging and where it is in that life

00:07:11,759 --> 00:07:15,520
cycle

00:07:12,800 --> 00:07:18,160
we have introduced a fluent forward api

00:07:15,520 --> 00:07:20,560
that that components can just send to

00:07:18,160 --> 00:07:22,000
um components have decided to do this in

00:07:20,560 --> 00:07:22,960
a couple of different ways it's pretty

00:07:22,000 --> 00:07:25,599
flexible

00:07:22,960 --> 00:07:26,319
so some components have just pulled in

00:07:25,599 --> 00:07:28,400
the

00:07:26,319 --> 00:07:29,360
logging libraries provided by fluent and

00:07:28,400 --> 00:07:32,160
there's one for

00:07:29,360 --> 00:07:33,440
several languages and others have

00:07:32,160 --> 00:07:35,280
actually sort of deployed their own

00:07:33,440 --> 00:07:37,919
fluent bit sidecars

00:07:35,280 --> 00:07:39,919
sort of the crux of this is that each

00:07:37,919 --> 00:07:42,000
component gets to decide how it handles

00:07:39,919 --> 00:07:43,120
its logs because it's sort of the expert

00:07:42,000 --> 00:07:45,919
in those logs

00:07:43,120 --> 00:07:48,000
and what we do is the logging layer is

00:07:45,919 --> 00:07:50,160
sort of make the guarantee that

00:07:48,000 --> 00:07:52,319
if you send logs that have a log or an

00:07:50,160 --> 00:07:54,720
app id to our api we'll make sure that

00:07:52,319 --> 00:07:57,440
they get where they need to go

00:07:54,720 --> 00:07:58,400
to service cf logs uh it's actually we

00:07:57,440 --> 00:08:00,319
we treat

00:07:58,400 --> 00:08:02,400
this use case as just a subset of a

00:08:00,319 --> 00:08:04,240
third-party integrator using the

00:08:02,400 --> 00:08:06,720
uh log cache component that we're

00:08:04,240 --> 00:08:08,960
bringing over from cf for bosch

00:08:06,720 --> 00:08:11,039
we've turned this into a syslog server

00:08:08,960 --> 00:08:13,120
and we just received the messages sent

00:08:11,039 --> 00:08:15,360
from the fluentdaemon set

00:08:13,120 --> 00:08:17,039
the cfcli now sort of goes to the log

00:08:15,360 --> 00:08:20,080
cache to pull stuff down

00:08:17,039 --> 00:08:21,039
and this cache of logs uh services both

00:08:20,080 --> 00:08:22,479
the needs of

00:08:21,039 --> 00:08:24,319
like a log's recent experience where we

00:08:22,479 --> 00:08:26,319
look into the recent past

00:08:24,319 --> 00:08:27,840
or streaming current logs to see what's

00:08:26,319 --> 00:08:30,479
going on now

00:08:27,840 --> 00:08:31,039
and sort of via the same api we can send

00:08:30,479 --> 00:08:34,000
things to

00:08:31,039 --> 00:08:35,599
external integrators like again splunk

00:08:34,000 --> 00:08:38,959
or paper trailer or really anything that

00:08:35,599 --> 00:08:41,279
understands the syslog rfc 5424 format

00:08:38,959 --> 00:08:44,880
so that we can sort of egress to some

00:08:41,279 --> 00:08:44,880
sort of third-party aggregator

00:08:45,680 --> 00:08:49,120
and so we've got some new sort of like

00:08:47,839 --> 00:08:50,399
contracts and assumptions

00:08:49,120 --> 00:08:52,240
in this logging architecture than what

00:08:50,399 --> 00:08:54,560
we had before and one of them

00:08:52,240 --> 00:08:56,720
is this idea of distributed log delivery

00:08:54,560 --> 00:08:58,800
no longer is there a single endpoint

00:08:56,720 --> 00:09:00,640
where all of your logs sort of are

00:08:58,800 --> 00:09:01,600
egressed too so there's no more fire

00:09:00,640 --> 00:09:03,200
hose

00:09:01,600 --> 00:09:05,600
the fire hose in our experience was used

00:09:03,200 --> 00:09:08,959
mostly for third-party integrations

00:09:05,600 --> 00:09:10,399
and we find that integrating is simpler

00:09:08,959 --> 00:09:12,399
if we treat those integrations as a

00:09:10,399 --> 00:09:13,040
generic syslog server and so any

00:09:12,399 --> 00:09:14,640
integration

00:09:13,040 --> 00:09:16,560
that you want to have with a platform

00:09:14,640 --> 00:09:19,839
now just needs to understand

00:09:16,560 --> 00:09:20,800
simple rfc 5424 this could be an r

00:09:19,839 --> 00:09:21,839
syslog cluster

00:09:20,800 --> 00:09:24,800
or it can be any one of those

00:09:21,839 --> 00:09:26,800
third-party tools namely sort of

00:09:24,800 --> 00:09:27,920
aggregation of logs is difficult and

00:09:26,800 --> 00:09:28,640
there are a bunch of products that do

00:09:27,920 --> 00:09:31,200
this really well

00:09:28,640 --> 00:09:32,480
so our goal is to make a contract that

00:09:31,200 --> 00:09:35,519
makes getting logs

00:09:32,480 --> 00:09:37,360
from the platform as easy as possible

00:09:35,519 --> 00:09:39,040
and the second big one is back pressure

00:09:37,360 --> 00:09:40,160
historically the logging pipeline has

00:09:39,040 --> 00:09:42,080
made guarantees

00:09:40,160 --> 00:09:43,920
around never putting back pressure on

00:09:42,080 --> 00:09:47,360
apps and this has sort of

00:09:43,920 --> 00:09:48,160
led to other decisions like the logging

00:09:47,360 --> 00:09:50,080
pipeline

00:09:48,160 --> 00:09:51,839
losing or dropping logs rather than

00:09:50,080 --> 00:09:52,480
stopping the emission of apps from law

00:09:51,839 --> 00:09:55,839
uh

00:09:52,480 --> 00:09:58,240
the admission of logs from apps and so

00:09:55,839 --> 00:09:59,920
in cf for kate's all of the apps first

00:09:58,240 --> 00:10:01,519
log to their container's file system so

00:09:59,920 --> 00:10:03,680
there's intrinsic back pressure

00:10:01,519 --> 00:10:04,560
and so if an app logs too much or too

00:10:03,680 --> 00:10:06,720
quickly

00:10:04,560 --> 00:10:07,760
it might be throttled by the apps or by

00:10:06,720 --> 00:10:10,480
the file system

00:10:07,760 --> 00:10:12,000
and as a result we now consider back

00:10:10,480 --> 00:10:13,839
pressure sort of part of the assumption

00:10:12,000 --> 00:10:16,839
of the way the system is built

00:10:13,839 --> 00:10:19,839
and we'll favor that instead of dropping

00:10:16,839 --> 00:10:21,600
logs

00:10:19,839 --> 00:10:23,519
and sort of as i've already touched on

00:10:21,600 --> 00:10:25,680
we really want to coalesce around

00:10:23,519 --> 00:10:27,920
community standard formats

00:10:25,680 --> 00:10:30,079
we found that integrating against sort

00:10:27,920 --> 00:10:32,560
of proprietary

00:10:30,079 --> 00:10:33,279
if open standards has caused pain for

00:10:32,560 --> 00:10:34,640
integrators

00:10:33,279 --> 00:10:36,240
and so we want to make this as easy as

00:10:34,640 --> 00:10:38,240
possible and just use syslog with

00:10:36,240 --> 00:10:40,959
structured data the structured data

00:10:38,240 --> 00:10:43,200
holds either what's in uh no sorry holds

00:10:40,959 --> 00:10:45,279
just just the metadata

00:10:43,200 --> 00:10:46,399
and sort of as a fun aside we've

00:10:45,279 --> 00:10:49,040
actually created a fluentd

00:10:46,399 --> 00:10:50,000
plugin that facilitates the egress of

00:10:49,040 --> 00:10:53,279
syslog

00:10:50,000 --> 00:10:55,200
rfc 5424 from whatever is coming into

00:10:53,279 --> 00:10:56,720
effluent so this hopefully helps

00:10:55,200 --> 00:10:57,600
integrators have a set of building

00:10:56,720 --> 00:11:00,800
blocks that they

00:10:57,600 --> 00:11:02,640
they can use and then sort of

00:11:00,800 --> 00:11:03,920
gone is the like idea of independent

00:11:02,640 --> 00:11:05,839
scaling

00:11:03,920 --> 00:11:07,040
because this is a fluent de-daymond set

00:11:05,839 --> 00:11:09,360
there's a logging

00:11:07,040 --> 00:11:11,200
sort of process on each one of the case

00:11:09,360 --> 00:11:13,040
nodes and so as you scale out your

00:11:11,200 --> 00:11:15,760
platform to service more workloads

00:11:13,040 --> 00:11:16,880
you intrinsically scale out your uh

00:11:15,760 --> 00:11:18,640
logging layer

00:11:16,880 --> 00:11:20,320
so that hopefully it keeps up with the

00:11:18,640 --> 00:11:21,680
amount of logs that you're producing so

00:11:20,320 --> 00:11:24,720
that you can sort of like egress them to

00:11:21,680 --> 00:11:24,720
where they're most useful

00:11:25,920 --> 00:11:30,160
and having achieved via this new

00:11:28,079 --> 00:11:32,560
architecture with its new contracts

00:11:30,160 --> 00:11:33,279
having achieved the baseline experience

00:11:32,560 --> 00:11:35,120
of

00:11:33,279 --> 00:11:37,440
i want my developers to be able to see

00:11:35,120 --> 00:11:39,680
their application logs through cf logs

00:11:37,440 --> 00:11:41,760
and i would like to take the whole

00:11:39,680 --> 00:11:42,160
foundations logs and send them somewhere

00:11:41,760 --> 00:11:44,959
else

00:11:42,160 --> 00:11:46,640
via syslog we have a few things on the

00:11:44,959 --> 00:11:49,760
horizon that we're

00:11:46,640 --> 00:11:52,639
looking to achieve one of the biggest

00:11:49,760 --> 00:11:54,800
ones is the concept of a resource drain

00:11:52,639 --> 00:11:55,839
for a long time within the cloud foundry

00:11:54,800 --> 00:11:57,600
logging system

00:11:55,839 --> 00:11:59,600
it's been possible to set up you might

00:11:57,600 --> 00:12:02,959
have heard a few different names for it

00:11:59,600 --> 00:12:05,120
a app log drain a cup strain

00:12:02,959 --> 00:12:07,519
any number of things but critically

00:12:05,120 --> 00:12:09,200
taking an applications logs

00:12:07,519 --> 00:12:11,040
and sending them to some outside

00:12:09,200 --> 00:12:14,240
destination

00:12:11,040 --> 00:12:15,920
now this is useful but oftentimes what

00:12:14,240 --> 00:12:18,639
you care about is not an app

00:12:15,920 --> 00:12:19,600
it's some larger unit of abstraction

00:12:18,639 --> 00:12:22,320
somewhere between an

00:12:19,600 --> 00:12:23,519
app and an entire foundation so we hope

00:12:22,320 --> 00:12:26,000
to make it easy

00:12:23,519 --> 00:12:29,040
and declarative using some of the new

00:12:26,000 --> 00:12:30,959
annotations features within the cf api

00:12:29,040 --> 00:12:32,240
we hope to make it possible to egress

00:12:30,959 --> 00:12:34,399
all of the

00:12:32,240 --> 00:12:37,360
logs for all the apps in an org or all

00:12:34,399 --> 00:12:39,279
the apps in a space

00:12:37,360 --> 00:12:40,800
the next thing that we have coming up

00:12:39,279 --> 00:12:43,040
that we're looking to bring in is per

00:12:40,800 --> 00:12:46,160
app throughput throttling

00:12:43,040 --> 00:12:48,240
this is something that has come into the

00:12:46,160 --> 00:12:49,760
cloud foundry on bosch ecosystem

00:12:48,240 --> 00:12:52,000
somewhat recently

00:12:49,760 --> 00:12:53,040
and it's a super useful feature that we

00:12:52,000 --> 00:12:56,320
want to preserve

00:12:53,040 --> 00:12:58,320
going forward in cf for kate's any

00:12:56,320 --> 00:13:00,000
individual noisy actor any

00:12:58,320 --> 00:13:02,160
individual app that's submitting just

00:13:00,000 --> 00:13:03,279
tons of logs shouldn't be able to

00:13:02,160 --> 00:13:05,519
overwhelm

00:13:03,279 --> 00:13:07,360
its own logging node or anything

00:13:05,519 --> 00:13:11,040
downstream

00:13:07,360 --> 00:13:13,600
and last but certainly not least

00:13:11,040 --> 00:13:14,639
while we've really worked to eliminate

00:13:13,600 --> 00:13:17,360
shared api

00:13:14,639 --> 00:13:18,800
shared pain points that all of the logs

00:13:17,360 --> 00:13:19,519
going through the system have to flow

00:13:18,800 --> 00:13:22,399
through

00:13:19,519 --> 00:13:24,880
there is still log cache servicing the

00:13:22,399 --> 00:13:26,959
cf logs api

00:13:24,880 --> 00:13:29,200
serving logs to cf logs and we want to

00:13:26,959 --> 00:13:31,600
make sure that that is highly available

00:13:29,200 --> 00:13:33,200
if one node goes down developers should

00:13:31,600 --> 00:13:35,440
still be able to see

00:13:33,200 --> 00:13:36,480
logs for their apps coming through when

00:13:35,440 --> 00:13:39,920
they're pushing

00:13:36,480 --> 00:13:39,920
monitoring what have you

00:13:42,320 --> 00:13:46,160
thank you very much for spending time

00:13:44,720 --> 00:13:49,279
with us

00:13:46,160 --> 00:13:50,800
you can reach us via email even better

00:13:49,279 --> 00:13:52,399
in the cloud foundry slack we have a

00:13:50,800 --> 00:13:53,920
channel logging and metrics where we

00:13:52,399 --> 00:13:55,199
would love for you to join us any

00:13:53,920 --> 00:13:57,920
conversations

00:13:55,199 --> 00:13:59,279
requests comments anything that is the

00:13:57,920 --> 00:14:02,320
top of your mind

00:13:59,279 --> 00:14:05,519
so thank you very much for your time

00:14:02,320 --> 00:14:09,680
thank you friends take care

00:14:05,519 --> 00:14:11,199
hello hello hello hello hooray

00:14:09,680 --> 00:14:17,839
i was typing an answer while the person

00:14:11,199 --> 00:14:17,839
was asking stuff i was like oh no

00:14:39,120 --> 00:14:45,839
come ask questions

00:14:52,320 --> 00:14:56,800
okay now i am not hearing your voice and

00:14:54,480 --> 00:14:59,600
your voice and my voice

00:14:56,800 --> 00:15:02,320
yeah that was that was a little rough

00:14:59,600 --> 00:15:05,760
very disorienting

00:15:02,320 --> 00:15:07,519
all right i'm gonna keep that page

00:15:05,760 --> 00:15:09,360
open because apparently the questions

00:15:07,519 --> 00:15:11,040
don't magically port themselves over to

00:15:09,360 --> 00:15:14,320
this breakout room

00:15:11,040 --> 00:15:15,040
um fair enough we got sort of looks like

00:15:14,320 --> 00:15:16,560
one cue

00:15:15,040 --> 00:15:19,920
or one question i've sort of been trying

00:15:16,560 --> 00:15:22,639
to answer stuff as it came in there

00:15:19,920 --> 00:15:22,639
yeah i see

00:15:24,240 --> 00:15:28,959
let's see if we have folks here yet oh

00:15:26,880 --> 00:15:41,839
it seems like it it puts all the

00:15:28,959 --> 00:15:41,839
people in here though questions

00:15:53,120 --> 00:15:57,120
any thoughts on making log cache an

00:15:55,120 --> 00:16:00,320
optional component

00:15:57,120 --> 00:16:03,199
uh i'm gonna answer that one live

00:16:00,320 --> 00:16:04,639
okay so we have a question in the chat

00:16:03,199 --> 00:16:06,320
from uh burn cranich

00:16:04,639 --> 00:16:08,480
about making log cache an optional

00:16:06,320 --> 00:16:10,160
component

00:16:08,480 --> 00:16:12,399
this is something we hadn't yet

00:16:10,160 --> 00:16:16,160
considered log cache is pretty critical

00:16:12,399 --> 00:16:17,279
for pushing apps and viewing their logs

00:16:16,160 --> 00:16:20,800
through the cfcli

00:16:17,279 --> 00:16:22,399
currently if neither of those are use

00:16:20,800 --> 00:16:23,440
cases that were used within a particular

00:16:22,399 --> 00:16:25,680
installation of cf

00:16:23,440 --> 00:16:27,519
for kate's i think we could have a chat

00:16:25,680 --> 00:16:29,199
about making those optional

00:16:27,519 --> 00:16:37,519
but at this time presently they're so

00:16:29,199 --> 00:16:40,720
integrated that we haven't offered that

00:16:37,519 --> 00:16:42,800
let's see uh

00:16:40,720 --> 00:16:44,399
next one we have a question on metrics

00:16:42,800 --> 00:16:47,199
travis do you want to handle that one

00:16:44,399 --> 00:16:47,600
yeah sure um so right now what we've

00:16:47,199 --> 00:16:49,440
been

00:16:47,600 --> 00:16:51,759
doing is sort of servicing the base

00:16:49,440 --> 00:16:52,639
metrics use case for sort of like the cf

00:16:51,759 --> 00:16:56,399
app experience

00:16:52,639 --> 00:16:58,399
from uh the cfcli and there's sort of a

00:16:56,399 --> 00:17:00,959
team and work is ongoing to see what

00:16:58,399 --> 00:17:02,079
metrics look like in cf for case going

00:17:00,959 --> 00:17:03,519
forward

00:17:02,079 --> 00:17:05,520
critically we sort of don't want them to

00:17:03,519 --> 00:17:05,839
be in log cache anymore because sort of

00:17:05,520 --> 00:17:08,799
the

00:17:05,839 --> 00:17:09,360
the things that jesse mentioned in the

00:17:08,799 --> 00:17:11,360
talk

00:17:09,360 --> 00:17:13,120
where kind of putting metrics in the log

00:17:11,360 --> 00:17:14,319
cache is kind of the worst of all worlds

00:17:13,120 --> 00:17:16,240
so we're sort of

00:17:14,319 --> 00:17:17,919
working to see what kind of uh first

00:17:16,240 --> 00:17:33,840
class metrics experience we can put

00:17:17,919 --> 00:17:33,840
together for that

00:17:35,360 --> 00:17:39,120
and i am typing up some of these

00:17:37,520 --> 00:17:41,520
questions and answers and dropping them

00:17:39,120 --> 00:17:44,160
into our slack channel uh logging and

00:17:41,520 --> 00:17:47,120
metrics in the cloud foundry slack

00:17:44,160 --> 00:17:47,679
uh also if you have any further

00:17:47,120 --> 00:17:51,360
questions

00:17:47,679 --> 00:17:55,600
we have an office hours next tuesday

00:17:51,360 --> 00:18:01,840
i believe it's at 1800 utc

00:17:55,600 --> 00:18:01,840
that is on the cf community calendar

00:18:19,360 --> 00:18:26,480
ah excellent we have a question from uh

00:18:23,600 --> 00:18:28,000
johan kostovsky uh asking about the

00:18:26,480 --> 00:18:29,919
shared nothing architecture i'm guessing

00:18:28,000 --> 00:18:32,960
this is the shared nothing architecture

00:18:29,919 --> 00:18:32,960
from the

00:18:33,760 --> 00:18:36,960
bosch world cf deployment world this is

00:18:36,160 --> 00:18:41,120
something

00:18:36,960 --> 00:18:45,039
yeah it's been considered experimental

00:18:41,120 --> 00:18:48,240
in some ways for quite some time

00:18:45,039 --> 00:18:50,240
um this is something that we actually

00:18:48,240 --> 00:18:52,080
have a fair amount of confidence in as

00:18:50,240 --> 00:18:54,640
it has gotten more and more

00:18:52,080 --> 00:18:56,400
used especially within some alternate

00:18:54,640 --> 00:18:59,200
deployments of cf

00:18:56,400 --> 00:19:00,480
um i wouldn't consider it experimental

00:18:59,200 --> 00:19:02,960
at this point we don't

00:19:00,480 --> 00:19:04,480
have as many integrations with the

00:19:02,960 --> 00:19:05,600
shared nothing architecture as perhaps

00:19:04,480 --> 00:19:07,760
we might hope

00:19:05,600 --> 00:19:09,360
but a lot of the components of it

00:19:07,760 --> 00:19:12,080
especially the syslog agent have been

00:19:09,360 --> 00:19:13,600
proven out fairly well at scale

00:19:12,080 --> 00:19:16,480
and then we got another question about

00:19:13,600 --> 00:19:19,039
sort of the lossiness of log cache

00:19:16,480 --> 00:19:19,679
um log cache has got sort of a lossy

00:19:19,039 --> 00:19:22,559
profile

00:19:19,679 --> 00:19:23,919
not super the same as the old logging

00:19:22,559 --> 00:19:25,440
pipeline where it sort of drops stuff

00:19:23,919 --> 00:19:26,960
on the floor if it gets super

00:19:25,440 --> 00:19:28,480
overwhelmed it will do that but it will

00:19:26,960 --> 00:19:29,200
sort of favor throttling and back

00:19:28,480 --> 00:19:32,480
pressure

00:19:29,200 --> 00:19:34,080
in cf for kate's over um dropping stuff

00:19:32,480 --> 00:19:36,080
and sort of the critical thing to

00:19:34,080 --> 00:19:37,360
realize about log cache is that it's

00:19:36,080 --> 00:19:40,799
just sort of an in-memory

00:19:37,360 --> 00:19:42,880
cache of logs where as logs come in um

00:19:40,799 --> 00:19:44,400
the oldest ones are expired and right

00:19:42,880 --> 00:19:46,640
now because we're servicing these sort

00:19:44,400 --> 00:19:47,840
of like cf logs and cflogs recent use

00:19:46,640 --> 00:19:49,760
cases with that

00:19:47,840 --> 00:19:51,679
uh the cache for each app is only the

00:19:49,760 --> 00:19:52,559
last thousand things and so if your app

00:19:51,679 --> 00:19:54,400
is logging

00:19:52,559 --> 00:19:55,520
tons and tons of things it will keep the

00:19:54,400 --> 00:19:57,280
last thousand things but it'll sort of

00:19:55,520 --> 00:19:58,720
like continuously expire them

00:19:57,280 --> 00:20:00,960
um and so it's really good for getting

00:19:58,720 --> 00:20:01,840
just a really recent cache of the logs

00:20:00,960 --> 00:20:05,120
but it's not

00:20:01,840 --> 00:20:06,080
good for um sort of persistent or even

00:20:05,120 --> 00:20:21,840
sort of like medium

00:20:06,080 --> 00:20:21,840
term storage

00:20:41,840 --> 00:20:46,880
any other questions this morning or this

00:20:45,200 --> 00:20:49,840
evening i guess wherever we happen to be

00:20:46,880 --> 00:20:49,840
located

00:20:50,799 --> 00:21:05,600
so we're just about it time

00:21:03,840 --> 00:21:07,360
haven't kicked us out yet i don't know

00:21:05,600 --> 00:21:08,720
if this stays not sure

00:21:07,360 --> 00:21:10,000
i'm not sure if it's gonna kick us out

00:21:08,720 --> 00:21:11,440
so if it doesn't please continue to ask

00:21:10,000 --> 00:21:13,120
questions otherwise please hit us up in

00:21:11,440 --> 00:21:14,720
the logging and metrics channel

00:21:13,120 --> 00:21:16,480
uh or come to one of our office hours

00:21:14,720 --> 00:21:17,679
we're sort of like really excited to

00:21:16,480 --> 00:21:19,039
talk to the community and answer

00:21:17,679 --> 00:21:22,480
questions and sort of

00:21:19,039 --> 00:21:24,559
uh understand what folks want or need

00:21:22,480 --> 00:21:26,080
oh excellent we have a couple of

00:21:24,559 --> 00:21:28,880
questions coming in

00:21:26,080 --> 00:21:32,080
nice perfect i'll take the first one

00:21:28,880 --> 00:21:35,120
about input and output plugins

00:21:32,080 --> 00:21:37,440
um so as

00:21:35,120 --> 00:21:38,640
to custom input and output plugins

00:21:37,440 --> 00:21:40,799
influent d

00:21:38,640 --> 00:21:41,760
this isn't a capability that we're

00:21:40,799 --> 00:21:44,480
offering

00:21:41,760 --> 00:21:45,679
just yet but it's a use case that we

00:21:44,480 --> 00:21:49,280
love to talk about

00:21:45,679 --> 00:21:51,120
more the trick about using fluentd for

00:21:49,280 --> 00:21:52,880
our use case where we're pulling from

00:21:51,120 --> 00:21:54,799
very specific sources

00:21:52,880 --> 00:21:56,080
filtering metadata in very specific ways

00:21:54,799 --> 00:21:57,280
and wanting to get it to downstream

00:21:56,080 --> 00:21:59,600
destinations

00:21:57,280 --> 00:22:00,559
is that we have to be pretty careful

00:21:59,600 --> 00:22:02,240
about

00:22:00,559 --> 00:22:03,760
how we integrate some of these

00:22:02,240 --> 00:22:07,360
customizations

00:22:03,760 --> 00:22:10,640
custom output plugins are probably the

00:22:07,360 --> 00:22:12,080
most feasible bit of custom config

00:22:10,640 --> 00:22:15,520
that's not something we have on the

00:22:12,080 --> 00:22:19,520
roadmap but i can definitely

00:22:15,520 --> 00:22:21,200
um drop that in as something to consider

00:22:19,520 --> 00:22:22,640
and if you have any like further

00:22:21,200 --> 00:22:23,280
clarifications anything you'd like to

00:22:22,640 --> 00:22:24,640
discuss

00:22:23,280 --> 00:22:26,640
please join us in slack we'd love to

00:22:24,640 --> 00:22:28,240
hear more

00:22:26,640 --> 00:22:29,840
um and then to sort of the use case

00:22:28,240 --> 00:22:30,880
around log cache log cache isn't so much

00:22:29,840 --> 00:22:31,760
for integrating with downstream

00:22:30,880 --> 00:22:33,440
consumers

00:22:31,760 --> 00:22:35,600
log cache is just for integrating for

00:22:33,440 --> 00:22:36,240
the most part with cf logs or cf logs

00:22:35,600 --> 00:22:38,080
recent or

00:22:36,240 --> 00:22:39,360
any consumer you want that's that you

00:22:38,080 --> 00:22:40,720
want that has got a similar sort of

00:22:39,360 --> 00:22:42,720
usage profile

00:22:40,720 --> 00:22:44,400
in general in cf for kate's for for

00:22:42,720 --> 00:22:47,039
integrating with downstream consumers

00:22:44,400 --> 00:22:48,159
what um we're trying to favor is sort of

00:22:47,039 --> 00:22:50,960
a syslog server

00:22:48,159 --> 00:22:51,600
so maybe even an r syslog cluster so

00:22:50,960 --> 00:22:53,600
that the

00:22:51,600 --> 00:22:54,880
uh nodes can each individually egress

00:22:53,600 --> 00:22:56,480
their own logs to some sort of

00:22:54,880 --> 00:22:58,159
downstream aggregator something like a

00:22:56,480 --> 00:22:59,600
splunk or a paper trailer or any of

00:22:58,159 --> 00:23:01,280
those products that do kind of

00:22:59,600 --> 00:23:09,840
a really good job at aggregating tons

00:23:01,280 --> 00:23:09,840
and tons of logs

00:23:21,840 --> 00:23:23,919
you

00:24:03,840 --> 00:24:05,919
you

00:24:28,720 --> 00:24:32,640
i'd say travis if we don't have any more

00:24:31,279 --> 00:24:34,960
questions by

00:24:32,640 --> 00:24:36,159
7 45 maybe 750 we close out the room

00:24:34,960 --> 00:24:38,720
sound like a plan

00:24:36,159 --> 00:24:41,200
i think that that is super reasonable

00:24:38,720 --> 00:24:41,200
next one

00:24:44,799 --> 00:24:50,240
although i may delay that until i'm

00:24:46,320 --> 00:24:50,240
finished typing up the questions and

00:24:58,840 --> 00:25:01,840
answers

00:25:31,200 --> 00:25:36,240
okay it is 7 45 now any last questions

00:25:34,240 --> 00:25:38,000
before we go

00:25:36,240 --> 00:25:39,679
and travis if you would like to drop off

00:25:38,000 --> 00:25:41,679
i can stay in because i'm not

00:25:39,679 --> 00:25:43,200
sure if the q a will persist if i drop

00:25:41,679 --> 00:25:44,400
out of the room so

00:25:43,200 --> 00:25:46,080
oh that's fair started that sort of

00:25:44,400 --> 00:25:47,120
thing yeah okay awesome thank you

00:25:46,080 --> 00:25:48,640
everyone um

00:25:47,120 --> 00:25:50,400
i'm happy to stick around to jesse while

00:25:48,640 --> 00:25:52,960
you're here to like answer questions and

00:25:50,400 --> 00:25:52,960
stuff uh

00:25:53,679 --> 00:25:57,200
in fact maybe what would be more

00:25:55,360 --> 00:26:00,640
effective i'll just copy

00:25:57,200 --> 00:26:02,400
this and then we can do it that way

00:26:00,640 --> 00:26:03,919
we have computers with all of these

00:26:02,400 --> 00:26:07,679
magical capabilities like

00:26:03,919 --> 00:26:07,679
saving text in files

00:26:08,240 --> 00:26:14,880
okay where is this

00:26:11,600 --> 00:26:18,400
how do i add a new note okay

00:26:14,880 --> 00:26:19,440
cool that's all been saved all right

00:26:18,400 --> 00:26:20,720
then i think we're probably good to

00:26:19,440 --> 00:26:22,320
close up thank you all so much for your

00:26:20,720 --> 00:26:23,120
time hope to see you in office hours for

00:26:22,320 --> 00:26:25,840
slack

00:26:23,120 --> 00:26:25,840

YouTube URL: https://www.youtube.com/watch?v=Vo9vO72MMF0


