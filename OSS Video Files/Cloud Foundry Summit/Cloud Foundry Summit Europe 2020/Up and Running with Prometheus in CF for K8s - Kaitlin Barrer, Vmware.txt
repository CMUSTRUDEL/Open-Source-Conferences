Title: Up and Running with Prometheus in CF for K8s - Kaitlin Barrer, Vmware
Publication date: 2020-10-26
Playlist: Cloud Foundry Summit Europe 2020
Description: 
	Up and Running with Prometheus in CF for K8s - Kaitlin Barrer, Vmware

Prometheus, an open-source metrics-based monitoring system, has become a widely adopted and standardized format for emitting metrics. It is the monitoring tool of choice for Kubernetes and Docker and is the standard for metrics in CF for K8s. This lightning talk will demonstrate how to get up and running with Prometheus in CF for K8s via ytt. Topics covered include: * How contributors to CF for K8s can setup components to emit Prometheus metrics * How application developers can deploy their application to emit Prometheus metrics * How to use Prometheus to monitor and gather useful information about the platform and deployed applications
Captions: 
	00:00:00,080 --> 00:00:03,840
hi this is caitlin i work on metrics in

00:00:02,560 --> 00:00:06,160
cf for cates

00:00:03,840 --> 00:00:07,680
and i'm here to talk about how to get

00:00:06,160 --> 00:00:10,719
prometheus up and running in your

00:00:07,680 --> 00:00:12,000
cfragate's cluster

00:00:10,719 --> 00:00:14,400
this talk will include a little

00:00:12,000 --> 00:00:16,720
background on why we chose prometheus

00:00:14,400 --> 00:00:17,600
how to use our current solution how we

00:00:16,720 --> 00:00:20,640
got here

00:00:17,600 --> 00:00:22,720
and finally what's to come

00:00:20,640 --> 00:00:24,640
first off why are metrics so important

00:00:22,720 --> 00:00:26,400
site reliability engineering is focused

00:00:24,640 --> 00:00:29,199
on tracking an app's reliability through

00:00:26,400 --> 00:00:30,480
its metrics or service level indicators

00:00:29,199 --> 00:00:32,480
these are the markers that can be

00:00:30,480 --> 00:00:34,559
measured in relation to a threshold or

00:00:32,480 --> 00:00:36,880
service level objective

00:00:34,559 --> 00:00:38,160
an example of a key sli is request

00:00:36,880 --> 00:00:39,840
latency

00:00:38,160 --> 00:00:41,760
in this example you can see that the

00:00:39,840 --> 00:00:43,360
agreement is that the request takes less

00:00:41,760 --> 00:00:44,800
than 300 milliseconds

00:00:43,360 --> 00:00:46,960
at 300 milliseconds people are getting

00:00:44,800 --> 00:00:49,200
paid to check it out but the goal is to

00:00:46,960 --> 00:00:51,360
have it below 200 milliseconds

00:00:49,200 --> 00:00:54,480
so these are the sorts of things you're

00:00:51,360 --> 00:00:54,480
tracking with prometheus

00:00:54,800 --> 00:00:58,079
now why prometheus created in soundcloud

00:00:57,280 --> 00:01:00,079
in 2012

00:00:58,079 --> 00:01:01,760
prometheus is now a standalone project

00:01:00,079 --> 00:01:02,960
hosted by the cloud native computing

00:01:01,760 --> 00:01:05,199
foundation

00:01:02,960 --> 00:01:06,000
it is considered to be the go-to choice

00:01:05,199 --> 00:01:07,920
for monitoring

00:01:06,000 --> 00:01:10,720
in kubernetes because of its flexible

00:01:07,920 --> 00:01:12,479
data model powerful query and language

00:01:10,720 --> 00:01:13,840
poll metrics model with the ability to

00:01:12,479 --> 00:01:15,680
do push metrics

00:01:13,840 --> 00:01:17,840
easy metrics exposition and service

00:01:15,680 --> 00:01:21,439
discovery and scalability because of

00:01:17,840 --> 00:01:21,439
autonomous single service nodes

00:01:23,040 --> 00:01:27,280
here's a teaser of what we built more to

00:01:25,040 --> 00:01:29,280
come on this this code is not yet

00:01:27,280 --> 00:01:31,600
integrated into the cf for case code

00:01:29,280 --> 00:01:31,600
base

00:01:31,840 --> 00:01:35,280
before i talk about how to use cfk's

00:01:33,840 --> 00:01:37,200
prometheus i want to talk about our

00:01:35,280 --> 00:01:40,159
goals for the first release

00:01:37,200 --> 00:01:41,840
since cf4cates uses ytt and cap for

00:01:40,159 --> 00:01:43,439
templating and deploying

00:01:41,840 --> 00:01:45,759
our goal was to make our prometheus

00:01:43,439 --> 00:01:46,640
instance plug into the existing ytt

00:01:45,759 --> 00:01:49,119
command

00:01:46,640 --> 00:01:51,600
we also needed to deploy our own ubuntu

00:01:49,119 --> 00:01:53,200
based image

00:01:51,600 --> 00:01:56,320
we wanted to get as many c4case

00:01:53,200 --> 00:01:57,920
components as possible scrapable in v1

00:01:56,320 --> 00:02:01,439
we wanted app developers to have their

00:01:57,920 --> 00:02:01,439
custom app metrics scrapable

00:02:01,600 --> 00:02:05,759
we wanted our prometheus request to be

00:02:03,360 --> 00:02:05,759
secure

00:02:06,240 --> 00:02:10,399
so how'd we do it's worth noting that

00:02:08,399 --> 00:02:12,640
app developers can currently cf push

00:02:10,399 --> 00:02:14,959
their apps with metrics pretty easily

00:02:12,640 --> 00:02:17,120
but they can't view them yet unless they

00:02:14,959 --> 00:02:18,879
have cube cuddle access

00:02:17,120 --> 00:02:20,319
and unfortunately we spent the majority

00:02:18,879 --> 00:02:22,160
of our efforts trying to make secure

00:02:20,319 --> 00:02:23,680
scraping work in the changing landscape

00:02:22,160 --> 00:02:25,520
of cfrcad's networking

00:02:23,680 --> 00:02:27,200
but in the 25th hour we had to scrap

00:02:25,520 --> 00:02:29,280
secure scraping because of a bug in

00:02:27,200 --> 00:02:31,760
istio that breaks prometheus tls

00:02:29,280 --> 00:02:31,760
requests

00:02:33,120 --> 00:02:37,360
let's talk about how to get component

00:02:34,640 --> 00:02:39,599
metrics scraped by prometheus

00:02:37,360 --> 00:02:40,800
the example here is for a cf for case

00:02:39,599 --> 00:02:43,280
component called metric

00:02:40,800 --> 00:02:44,879
proxy this is one that we built and it

00:02:43,280 --> 00:02:47,440
provides at metrics

00:02:44,879 --> 00:02:48,560
in the response to a cf push or cf app

00:02:47,440 --> 00:02:50,879
command

00:02:48,560 --> 00:02:53,040
we've exposed an endpoint slash metrics

00:02:50,879 --> 00:02:54,080
on port 9090 that we want prometheus to

00:02:53,040 --> 00:02:55,840
scrape

00:02:54,080 --> 00:02:57,440
when we deploy this ico will actually

00:02:55,840 --> 00:02:58,959
change the path import and display

00:02:57,440 --> 00:03:00,879
metrics from both our

00:02:58,959 --> 00:03:03,120
our container and istio's container at

00:03:00,879 --> 00:03:04,959
the new location

00:03:03,120 --> 00:03:06,720
once the component annotations have been

00:03:04,959 --> 00:03:07,519
vendored into the cfrcades config

00:03:06,720 --> 00:03:09,280
directory

00:03:07,519 --> 00:03:10,879
you can deploy both those changes and

00:03:09,280 --> 00:03:12,640
prometheus together

00:03:10,879 --> 00:03:15,200
at the top you can see the cfrcades

00:03:12,640 --> 00:03:17,519
deploy step that runs ytt

00:03:15,200 --> 00:03:19,200
and at the bottom you'll see how we have

00:03:17,519 --> 00:03:20,319
to modify that you'll currently need to

00:03:19,200 --> 00:03:22,800
clone our repo

00:03:20,319 --> 00:03:24,640
and include our config directory as part

00:03:22,800 --> 00:03:26,720
of that step

00:03:24,640 --> 00:03:27,920
moving on to custom map metrics if

00:03:26,720 --> 00:03:29,360
you've already defined them to have

00:03:27,920 --> 00:03:31,120
prometheus scrape them

00:03:29,360 --> 00:03:32,720
you'll need to add the same annotations

00:03:31,120 --> 00:03:36,000
as you would for components to your

00:03:32,720 --> 00:03:37,920
manifest file then cf push note that

00:03:36,000 --> 00:03:40,080
you'll need to be using cf7 instead of

00:03:37,920 --> 00:03:41,280
cf6 for these annotations to be picked

00:03:40,080 --> 00:03:43,200
up properly

00:03:41,280 --> 00:03:45,200
the code on the right is in another repo

00:03:43,200 --> 00:03:46,799
that we made that has an example of how

00:03:45,200 --> 00:03:50,000
to include custom map metrics it's

00:03:46,799 --> 00:03:51,440
called cf for kate's metrics examples

00:03:50,000 --> 00:03:52,959
after you've deployed make sure your

00:03:51,440 --> 00:03:56,239
metrics are being emitted correctly to

00:03:52,959 --> 00:03:56,239
be picked up by prometheus

00:03:57,439 --> 00:04:02,959
then port forward prometheus itself so

00:03:59,439 --> 00:04:05,920
you can check out its ui in your browser

00:04:02,959 --> 00:04:10,080
here for demo purposes you see that we

00:04:05,920 --> 00:04:10,080
have a cf push app called go app with

00:04:12,840 --> 00:04:16,160
metrics

00:04:14,480 --> 00:04:18,560
if you look at that code all it's doing

00:04:16,160 --> 00:04:20,079
is incrementing an account every second

00:04:18,560 --> 00:04:21,680
so it's a really simple app just for

00:04:20,079 --> 00:04:23,360
demo purposes

00:04:21,680 --> 00:04:25,280
the cf app command will hit our

00:04:23,360 --> 00:04:28,880
component called metric proxy

00:04:25,280 --> 00:04:30,000
to get the cpu and memory of the pod

00:04:28,880 --> 00:04:31,919
it's on

00:04:30,000 --> 00:04:34,320
note that it's showing zero for disk

00:04:31,919 --> 00:04:36,080
usage this metric is not accurate

00:04:34,320 --> 00:04:38,479
because kate's doesn't report it the

00:04:36,080 --> 00:04:40,160
same way bosh did

00:04:38,479 --> 00:04:42,240
now let's look at both the component and

00:04:40,160 --> 00:04:43,919
app metrics in prometheus here we're

00:04:42,240 --> 00:04:46,800
looking up the metric by its name

00:04:43,919 --> 00:04:47,440
and we see this linear line is tracking

00:04:46,800 --> 00:04:49,759
that count

00:04:47,440 --> 00:04:51,280
as it increments so that's this is for

00:04:49,759 --> 00:04:53,040
the custom map metric

00:04:51,280 --> 00:04:55,759
and over here we're querying for one of

00:04:53,040 --> 00:04:58,240
the metrics we expect for metric proxy

00:04:55,759 --> 00:05:00,080
in the graph there's a jump up at 20

00:04:58,240 --> 00:05:01,360
shortly after we made that cf app call

00:05:00,080 --> 00:05:03,680
because a request was made to our

00:05:01,360 --> 00:05:04,880
component

00:05:03,680 --> 00:05:06,880
now i'm going to talk a little about

00:05:04,880 --> 00:05:07,759
what challenges and considerations we've

00:05:06,880 --> 00:05:10,320
faced thus far

00:05:07,759 --> 00:05:12,400
in developing prometheus on cf for kids

00:05:10,320 --> 00:05:15,039
if you're not familiar with these tools

00:05:12,400 --> 00:05:15,759
helm is a package manager for kubernetes

00:05:15,039 --> 00:05:18,479
ytt

00:05:15,759 --> 00:05:20,560
as mentioned before is a templating tool

00:05:18,479 --> 00:05:22,639
network policies are a case construct

00:05:20,560 --> 00:05:23,120
that specify how a body can communicate

00:05:22,639 --> 00:05:26,000
across

00:05:23,120 --> 00:05:28,240
network entities and istio is a service

00:05:26,000 --> 00:05:28,240
mesh

00:05:29,280 --> 00:05:32,880
first we wanted to make sure helm was

00:05:30,960 --> 00:05:33,520
usable for customers who wanted to use

00:05:32,880 --> 00:05:35,360
it

00:05:33,520 --> 00:05:36,960
because we wanted to have istio sidecar

00:05:35,360 --> 00:05:38,639
injection in all pods

00:05:36,960 --> 00:05:40,800
we deployed it in the cf system

00:05:38,639 --> 00:05:44,479
namespace so the namespace would take

00:05:40,800 --> 00:05:44,479
care of sidecar injection for us

00:05:44,639 --> 00:05:48,240
next we made our own prometheus

00:05:46,400 --> 00:05:48,960
deployment that deployed our own docker

00:05:48,240 --> 00:05:51,280
image

00:05:48,960 --> 00:05:52,000
that wrap prometheus's code this was

00:05:51,280 --> 00:05:53,840
very straightforward

00:05:52,000 --> 00:05:57,440
using the helm templating command and

00:05:53,840 --> 00:05:57,440
worked with y2d templating

00:05:58,080 --> 00:06:01,520
next the networking team and cf for

00:05:59,680 --> 00:06:02,880
kates tightened up security by adding

00:06:01,520 --> 00:06:05,120
network policies

00:06:02,880 --> 00:06:07,759
this change required that every pod

00:06:05,120 --> 00:06:10,639
needed an explicit network policy

00:06:07,759 --> 00:06:11,199
to in place to allow pod traffic to and

00:06:10,639 --> 00:06:13,919
or from

00:06:11,199 --> 00:06:14,240
any other pod this could be defined at

00:06:13,919 --> 00:06:17,360
the

00:06:14,240 --> 00:06:19,120
pod or name space level

00:06:17,360 --> 00:06:20,800
so we had a network policy that allowed

00:06:19,120 --> 00:06:23,360
prometheus to scrape

00:06:20,800 --> 00:06:24,639
both the cf workloads and cf system

00:06:23,360 --> 00:06:28,639
namespaces

00:06:24,639 --> 00:06:28,639
and more for them to accept those groups

00:06:29,680 --> 00:06:33,600
next we found we could no longer

00:06:31,759 --> 00:06:35,039
leverage our namespace injecting

00:06:33,600 --> 00:06:37,759
sidecars for us

00:06:35,039 --> 00:06:38,720
and had to manually add our custom seo

00:06:37,759 --> 00:06:40,479
sidecar

00:06:38,720 --> 00:06:42,319
that would create certs and mount them

00:06:40,479 --> 00:06:43,600
in all pods that needed to be scraped

00:06:42,319 --> 00:06:46,880
via tls

00:06:43,600 --> 00:06:50,479
this was to make secure scraping work

00:06:46,880 --> 00:06:51,120
istio 1.7.1 introduced metrics merging

00:06:50,479 --> 00:06:53,360
in which the

00:06:51,120 --> 00:06:55,039
envoy sidecar would merge istio's

00:06:53,360 --> 00:06:56,160
metrics with the apps metrics and

00:06:55,039 --> 00:06:58,160
display them at a new

00:06:56,160 --> 00:06:59,840
path and port we thought we had a

00:06:58,160 --> 00:07:02,400
workaround to make

00:06:59,840 --> 00:07:03,199
tls requests work here but then we

00:07:02,400 --> 00:07:06,000
discovered

00:07:03,199 --> 00:07:07,840
a bug that i mentioned a previous slide

00:07:06,000 --> 00:07:10,400
and we ultimately had to revert

00:07:07,840 --> 00:07:12,000
secure scraping in our repo we're hoping

00:07:10,400 --> 00:07:14,560
to re-implement it when a patch comes

00:07:12,000 --> 00:07:17,360
out in istio with the fix

00:07:14,560 --> 00:07:19,120
finally what's to come we want to get

00:07:17,360 --> 00:07:20,160
our code into cf for kate so it's

00:07:19,120 --> 00:07:22,639
official

00:07:20,160 --> 00:07:24,319
out of the box part of cf for kids we

00:07:22,639 --> 00:07:25,440
want to get secure scraping to actually

00:07:24,319 --> 00:07:27,120
work

00:07:25,440 --> 00:07:30,080
and to get the remaining components to

00:07:27,120 --> 00:07:31,520
annotate their pods for metric scraping

00:07:30,080 --> 00:07:34,160
we want to get the prometheus push

00:07:31,520 --> 00:07:35,840
gateway also deployable via ytt

00:07:34,160 --> 00:07:37,440
so apps that cannot be scraped like

00:07:35,840 --> 00:07:39,680
short-running processes

00:07:37,440 --> 00:07:41,199
can still be seen in prometheus we want

00:07:39,680 --> 00:07:42,560
to get grafana integrated with our

00:07:41,199 --> 00:07:44,720
out-of-the-box solution

00:07:42,560 --> 00:07:45,919
and finally we don't know we don't know

00:07:44,720 --> 00:07:47,759
yet so

00:07:45,919 --> 00:07:50,400
we're hoping there's more exciting

00:07:47,759 --> 00:07:52,800
things to work on in the future too

00:07:50,400 --> 00:07:54,720
once again come find us at cf kate's

00:07:52,800 --> 00:07:56,800
prometheus or in slack

00:07:54,720 --> 00:07:58,560
this is very much still in development

00:07:56,800 --> 00:08:00,160
so don't expect what you see there today

00:07:58,560 --> 00:08:02,319
to be there tomorrow

00:08:00,160 --> 00:08:03,440
we love feedback in prs we hope to hear

00:08:02,319 --> 00:08:07,120
from you

00:08:03,440 --> 00:08:07,120
hello i think i'm live now

00:08:08,240 --> 00:08:12,000
um so i'm guessing you couldn't hear

00:08:10,720 --> 00:08:15,360
anything i was saying before

00:08:12,000 --> 00:08:18,400
this so i'll just summarize the

00:08:15,360 --> 00:08:19,919
questions that have come in so far the

00:08:18,400 --> 00:08:21,280
first one was about publishing the

00:08:19,919 --> 00:08:23,919
slides

00:08:21,280 --> 00:08:25,360
i can look into that after this call and

00:08:23,919 --> 00:08:28,560
i'll share them in our

00:08:25,360 --> 00:08:29,599
channel in cloud foundry slack

00:08:28,560 --> 00:08:31,680
i thought they should have been

00:08:29,599 --> 00:08:35,279
published so i'm not sure

00:08:31,680 --> 00:08:36,800
what happened the second one is are

00:08:35,279 --> 00:08:38,880
there any plans to make the metrics

00:08:36,800 --> 00:08:41,120
available to the tenants who own the

00:08:38,880 --> 00:08:44,480
apps in some way

00:08:41,120 --> 00:08:45,279
i'm not entirely sure what the tenants

00:08:44,480 --> 00:08:48,320
is referring to

00:08:45,279 --> 00:08:51,120
if this if we're talking about app

00:08:48,320 --> 00:08:54,959
developers themselves

00:08:51,120 --> 00:08:58,399
the answer that i have for now is it

00:08:54,959 --> 00:09:02,000
yes um it depends when

00:08:58,399 --> 00:09:04,000
and how depends on uh network

00:09:02,000 --> 00:09:05,200
implementation so it's not something

00:09:04,000 --> 00:09:08,320
that i could answer

00:09:05,200 --> 00:09:09,519
um or that my team i think could answer

00:09:08,320 --> 00:09:12,640
for the short term

00:09:09,519 --> 00:09:12,959
but yes definitely in some capacity um

00:09:12,640 --> 00:09:15,120
we

00:09:12,959 --> 00:09:16,080
we haven't talked about it as a team in

00:09:15,120 --> 00:09:18,560
a few months

00:09:16,080 --> 00:09:20,399
because everything was kind of paused

00:09:18,560 --> 00:09:23,920
for the first release

00:09:20,399 --> 00:09:27,200
and the implementation of details

00:09:23,920 --> 00:09:28,080
that networking was doing so i would

00:09:27,200 --> 00:09:30,160
have to um

00:09:28,080 --> 00:09:31,680
talk to some people on my team and get

00:09:30,160 --> 00:09:32,959
back to you but i can definitely do that

00:09:31,680 --> 00:09:35,040
in slack

00:09:32,959 --> 00:09:36,000
to just see what if we have a time an

00:09:35,040 --> 00:09:39,760
updated timeline for

00:09:36,000 --> 00:09:42,480
you and then the third question

00:09:39,760 --> 00:09:44,000
was about marketplace service metrics

00:09:42,480 --> 00:09:45,839
and i don't remember talking about this

00:09:44,000 --> 00:09:49,760
as a team but it's pretty interesting

00:09:45,839 --> 00:09:52,240
and uh graham

00:09:49,760 --> 00:09:53,040
sorry if i mispronounce your name um

00:09:52,240 --> 00:09:56,160
posted a

00:09:53,040 --> 00:09:59,760
link to a github issue um that i i

00:09:56,160 --> 00:10:00,959
sort of skimmed and i will talk to my

00:09:59,760 --> 00:10:05,440
team about this as well

00:10:00,959 --> 00:10:10,959
and put an answer in slack for that

00:10:05,440 --> 00:10:10,959
and let's see we're on the q a

00:10:11,200 --> 00:10:18,959
okay well in in our chat box

00:10:15,600 --> 00:10:20,480
okay sorry i see andy um followed up

00:10:18,959 --> 00:10:22,240
clarifying our use case we run a

00:10:20,480 --> 00:10:23,600
multi-tenant cloud foundry and we often

00:10:22,240 --> 00:10:26,480
think about how the different tenants

00:10:23,600 --> 00:10:26,480
will get metrics out

00:10:26,959 --> 00:10:32,800
got it yeah this is a good question for

00:10:30,240 --> 00:10:35,680
networking

00:10:32,800 --> 00:10:37,360
but i think stay tuned and it is

00:10:35,680 --> 00:10:39,279
important that our team

00:10:37,360 --> 00:10:40,640
has a finger on the pulse of this as

00:10:39,279 --> 00:10:43,760
well so

00:10:40,640 --> 00:10:44,880
i would keep looking at our channel and

00:10:43,760 --> 00:10:47,839
i'll certainly follow up

00:10:44,880 --> 00:10:49,200
right after this today about this in our

00:10:47,839 --> 00:10:51,680
channel

00:10:49,200 --> 00:10:52,800
but yeah we we should start publishing

00:10:51,680 --> 00:10:56,800
like some

00:10:52,800 --> 00:10:56,800
plans on how we want to implement this

00:10:58,839 --> 00:11:01,839
eventually

00:11:04,320 --> 00:11:15,839
this is our channel in slack

00:11:22,240 --> 00:11:25,839
um while i'm waiting for more questions

00:11:24,399 --> 00:11:27,279
i'll

00:11:25,839 --> 00:11:29,839
go try and figure out what's up with the

00:11:27,279 --> 00:11:29,839
slides

00:12:13,360 --> 00:12:16,959
one more thing to mention for anyone

00:12:14,880 --> 00:12:21,120
who's interested is that

00:12:16,959 --> 00:12:23,200
uh it's so our

00:12:21,120 --> 00:12:25,200
prometheus scrape requests are not

00:12:23,200 --> 00:12:27,600
secure as i mentioned

00:12:25,200 --> 00:12:28,880
in the video and what that actually

00:12:27,600 --> 00:12:31,279
means because i had to

00:12:28,880 --> 00:12:32,639
learn about this myself was that they

00:12:31,279 --> 00:12:37,440
are not

00:12:32,639 --> 00:12:37,440
encrypted and authenticated

00:12:37,519 --> 00:12:40,720
so there is there still are some

00:12:39,920 --> 00:12:42,800
security

00:12:40,720 --> 00:12:43,920
restrictions in place because of network

00:12:42,800 --> 00:12:47,920
policies

00:12:43,920 --> 00:12:51,519
so it's not like every metrics endpoint

00:12:47,920 --> 00:12:52,639
is totally accessible or prometheus is

00:12:51,519 --> 00:12:54,880
able to

00:12:52,639 --> 00:12:58,800
totally access everything the network

00:12:54,880 --> 00:13:00,480
policies are still fairly restricted

00:12:58,800 --> 00:13:02,560
so it's not like there's no security

00:13:00,480 --> 00:13:07,839
whatsoever

00:13:02,560 --> 00:13:07,839
or they're completely insecure

00:13:32,839 --> 00:13:35,839
so

00:13:45,600 --> 00:13:48,639
that's a really good question that i

00:13:47,199 --> 00:13:49,760
don't know okay sorry sorry there's

00:13:48,639 --> 00:13:52,320
another question

00:13:49,760 --> 00:13:54,480
um from graeme follow up on access

00:13:52,320 --> 00:13:55,279
control for metrics would the capi user

00:13:54,480 --> 00:13:57,839
identity

00:13:55,279 --> 00:13:59,760
be used as principle what component

00:13:57,839 --> 00:14:03,360
would be responsible for auth

00:13:59,760 --> 00:14:05,120
to met tricks metric server and cfr vms

00:14:03,360 --> 00:14:07,920
was playing this role

00:14:05,120 --> 00:14:10,079
um is it still in discussion as it was

00:14:07,920 --> 00:14:11,760
answered

00:14:10,079 --> 00:14:13,760
um that is a really good question that i

00:14:11,760 --> 00:14:16,959
also don't know the answer to

00:14:13,760 --> 00:14:20,800
we did not talk about that for ga

00:14:16,959 --> 00:14:24,800
so that's another one to

00:14:20,800 --> 00:14:24,800
look for follow-up

00:14:24,959 --> 00:14:31,839
on in our channel

00:14:36,800 --> 00:14:41,519
i apologize um i haven't been on this

00:14:40,000 --> 00:14:44,079
team

00:14:41,519 --> 00:14:45,760
uh for a long time and kind of the chaos

00:14:44,079 --> 00:14:49,680
of the pandemic

00:14:45,760 --> 00:14:51,360
push some of the strategic conversations

00:14:49,680 --> 00:14:53,440
um far back in my memory because they

00:14:51,360 --> 00:14:56,720
were happening like back in

00:14:53,440 --> 00:14:56,720
i don't know february march

00:14:56,800 --> 00:15:00,320
but now that we have our first release

00:14:59,760 --> 00:15:01,920
done

00:15:00,320 --> 00:15:13,839
i'm guessing these will come to the

00:15:01,920 --> 00:15:13,839
forefront again

00:15:33,279 --> 00:15:37,120
okay if there aren't any other questions

00:15:35,360 --> 00:15:39,600
right now

00:15:37,120 --> 00:15:41,199
please come visit us in our channel to

00:15:39,600 --> 00:15:43,680
see some of the answers to these

00:15:41,199 --> 00:15:45,519
and hopefully you all can give us some

00:15:43,680 --> 00:15:48,800
feedback on

00:15:45,519 --> 00:15:52,959
cf kate's prometheus thanks have a good

00:15:48,800 --> 00:15:52,959

YouTube URL: https://www.youtube.com/watch?v=ZoICAWSo__Q


