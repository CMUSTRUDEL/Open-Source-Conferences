Title: Pivotal - Four Levels of High Availability in Cloud Foundry (Cloud Foundry Summit 2014)
Publication date: 2014-07-03
Playlist: Cloud Foundry Summit 2014
Description: 
	Presenter: Cornelia Davis, Platform Engineer, Cloud Foundry, Pivotal

Platform as a Service is not just for the developer. It must provide equal or greater value to the application operator as well. The Cloud Foundry PaaS has four levels of HA built in! We'll explain each of them and show you how, collectively, they do an extraordinary job keeping application instances up and running in the face of failures. Your operators will spend less time on recovery and more time on innovation as a result.
Captions: 
	00:00:00,930 --> 00:00:04,220
[Music]

00:00:08,120 --> 00:00:12,780
my name is Cornelia Davis I work as a

00:00:10,620 --> 00:00:15,660
platform engineer at pivotal on the

00:00:12,780 --> 00:00:17,550
Cloud Foundry team those of you who know

00:00:15,660 --> 00:00:19,529
me know that I like to go deep into

00:00:17,550 --> 00:00:21,289
technology and so that's what we're

00:00:19,529 --> 00:00:23,670
gonna do here in the next five minutes

00:00:21,289 --> 00:00:25,199
so I've been working on the past for a

00:00:23,670 --> 00:00:27,660
couple of years and in the beginning I

00:00:25,199 --> 00:00:30,029
believed all of those stuff about how it

00:00:27,660 --> 00:00:31,320
was all about the developer pass was

00:00:30,029 --> 00:00:32,640
good for the developer good for the

00:00:31,320 --> 00:00:35,010
developer and so on

00:00:32,640 --> 00:00:36,570
since then though I've learned in the

00:00:35,010 --> 00:00:39,870
last few months that I'm I'm actually

00:00:36,570 --> 00:00:41,640
working on an Operations product so the

00:00:39,870 --> 00:00:44,399
pass is just as important for the

00:00:41,640 --> 00:00:46,950
operator as it is for the developer and

00:00:44,399 --> 00:00:50,160
so I want to talk to you about one of

00:00:46,950 --> 00:00:54,170
those operator based features which is

00:00:50,160 --> 00:00:57,149
the four levels of a che so number one

00:00:54,170 --> 00:00:59,190
availability zones when you deploy the

00:00:57,149 --> 00:01:01,020
Cloud Foundry elastic runtime you can

00:00:59,190 --> 00:01:04,650
deploy the DEA s across different

00:01:01,020 --> 00:01:08,700
availability zones then when your users

00:01:04,650 --> 00:01:10,350
deploy applications to the paths so now

00:01:08,700 --> 00:01:12,540
the application developer or the

00:01:10,350 --> 00:01:15,150
application operator is pushing that

00:01:12,540 --> 00:01:16,799
application that application when you

00:01:15,150 --> 00:01:18,780
have more than one instance will be

00:01:16,799 --> 00:01:21,420
evenly distributed across those

00:01:18,780 --> 00:01:25,259
availability zones we take care of that

00:01:21,420 --> 00:01:28,290
for you in the paths now if one of those

00:01:25,259 --> 00:01:30,720
availability zones goes down of course

00:01:28,290 --> 00:01:33,030
you've still got application instances

00:01:30,720 --> 00:01:37,439
that are serving traffic that's number

00:01:33,030 --> 00:01:39,689
one now number two what happens if

00:01:37,439 --> 00:01:42,479
another instance goes down it's not an

00:01:39,689 --> 00:01:44,729
AZ but an instance of my app goes down I

00:01:42,479 --> 00:01:47,790
wanted two instances but now I only have

00:01:44,729 --> 00:01:49,259
one how does that work what do we do to

00:01:47,790 --> 00:01:52,409
compensate for that

00:01:49,259 --> 00:01:55,799
well the DEA s are always sending out

00:01:52,409 --> 00:01:57,600
periodically heartbeat messages in in

00:01:55,799 --> 00:01:59,820
those heartbeat messages they're saying

00:01:57,600 --> 00:02:02,100
what they have running on them so each

00:01:59,820 --> 00:02:04,020
DEA is responsible for saying here's

00:02:02,100 --> 00:02:06,060
what I've got running we have a

00:02:04,020 --> 00:02:07,920
component called the health manager

00:02:06,060 --> 00:02:10,319
which is listening to those heartbeat

00:02:07,920 --> 00:02:12,550
messages and builds up the actual state

00:02:10,319 --> 00:02:14,410
of the cloud so it's constant

00:02:12,550 --> 00:02:16,840
we updating that actual state of the

00:02:14,410 --> 00:02:18,550
cloud the cloud controller is the

00:02:16,840 --> 00:02:21,430
component that knows what the desired

00:02:18,550 --> 00:02:23,440
state is so the health manager gets that

00:02:21,430 --> 00:02:26,500
desired state from the cloud controller

00:02:23,440 --> 00:02:28,360
does a comparison and see if there's a

00:02:26,500 --> 00:02:31,360
difference between the desired in the

00:02:28,360 --> 00:02:32,710
actual state if there is it advises the

00:02:31,360 --> 00:02:35,590
cloud controller and the cloud

00:02:32,710 --> 00:02:38,980
controller causes a new instance to be

00:02:35,590 --> 00:02:40,810
launched now I've got my state back the

00:02:38,980 --> 00:02:42,960
last thing that it does there is another

00:02:40,810 --> 00:02:45,400
operator feature in that the router is

00:02:42,960 --> 00:02:47,290
automatically updated so you don't have

00:02:45,400 --> 00:02:50,320
to update the router after that new

00:02:47,290 --> 00:02:53,230
instance has been deployed so those two

00:02:50,320 --> 00:02:55,360
were in the elastic runtime now when we

00:02:53,230 --> 00:02:57,010
move down into the Boche layer we have a

00:02:55,360 --> 00:02:59,110
number of other things you might say

00:02:57,010 --> 00:03:01,060
well that Health Manager is pretty

00:02:59,110 --> 00:03:03,000
important in the elastic runtime what

00:03:01,060 --> 00:03:05,860
happens if the health manager goes down

00:03:03,000 --> 00:03:07,510
well we're actually monitoring all of

00:03:05,860 --> 00:03:08,950
the processes that are running on the

00:03:07,510 --> 00:03:12,100
virtual machines than the elastic

00:03:08,950 --> 00:03:14,800
runtime if one of those processes goes

00:03:12,100 --> 00:03:17,830
down two things happen number one the

00:03:14,800 --> 00:03:20,470
process is restarted the second thing

00:03:17,830 --> 00:03:22,720
that happens is that the boss agent that

00:03:20,470 --> 00:03:25,270
is running on the health manager and all

00:03:22,720 --> 00:03:28,750
of those other nodes sends out a message

00:03:25,270 --> 00:03:31,060
to wash to the message bus the health

00:03:28,750 --> 00:03:32,709
monitor not to be confused with the

00:03:31,060 --> 00:03:35,650
health manager that's in the elastic

00:03:32,709 --> 00:03:38,590
runtime picks up that alert and can send

00:03:35,650 --> 00:03:42,040
out things like pages emails and send

00:03:38,590 --> 00:03:44,230
things up into monitoring software ah so

00:03:42,040 --> 00:03:46,540
now you think you've got me well doesn't

00:03:44,230 --> 00:03:48,850
that depend on the agent and what

00:03:46,540 --> 00:03:50,980
happens that the agent goes down well in

00:03:48,850 --> 00:03:52,660
a pattern that we're familiar with here

00:03:50,980 --> 00:03:54,870
you'll see that the agents they're all

00:03:52,660 --> 00:03:57,880
sending out heartbeat messages as well

00:03:54,870 --> 00:04:00,310
they get picked up by the health monitor

00:03:57,880 --> 00:04:02,230
that's emboss which checks that against

00:04:00,310 --> 00:04:05,290
the desired state which it retrieves

00:04:02,230 --> 00:04:08,290
from the boss director if there's a

00:04:05,290 --> 00:04:11,290
discrepancy so right now everything's

00:04:08,290 --> 00:04:13,810
fine but if something happens and one of

00:04:11,290 --> 00:04:16,120
those agents goes down or the machine

00:04:13,810 --> 00:04:18,790
goes down then we're going to be missing

00:04:16,120 --> 00:04:20,799
that heartbeat message the actual state

00:04:18,790 --> 00:04:24,220
will be updated and an alert will be

00:04:20,799 --> 00:04:25,550
processed pagers emails and in this case

00:04:24,220 --> 00:04:27,830
a special

00:04:25,550 --> 00:04:30,110
Responder called the resurrector which

00:04:27,830 --> 00:04:32,900
is going to use the bosch director

00:04:30,110 --> 00:04:37,370
through the CPI to spin up a new vm and

00:04:32,900 --> 00:04:39,409
start that process that's number four so

00:04:37,370 --> 00:04:42,050
what you can see is that we have four

00:04:39,409 --> 00:04:44,900
levels two of those are in the elastic

00:04:42,050 --> 00:04:46,940
runtime two of those levels are down in

00:04:44,900 --> 00:04:49,159
Bosch the fact that they're in bosch

00:04:46,940 --> 00:04:51,379
means that you get to take advantage of

00:04:49,159 --> 00:04:55,580
those not just for the elastic runtime

00:04:51,379 --> 00:04:58,550
but also for pivotal HD and anything

00:04:55,580 --> 00:05:00,409
else that's deployed with bosch if this

00:04:58,550 --> 00:05:02,120
lightning talk was too slow for you I

00:05:00,409 --> 00:05:04,580
invite you to take a look at this blog

00:05:02,120 --> 00:05:07,520
we do the same thing in less than 28

00:05:04,580 --> 00:05:11,640
seconds thank you very much one last

00:05:07,520 --> 00:05:16,210
thing to say this is freakin cool

00:05:11,640 --> 00:05:19,500
[Applause]

00:05:16,210 --> 00:05:19,500

YouTube URL: https://www.youtube.com/watch?v=D7BjBIQZDII


