Title: Managing Multiple Clouds with a Single BOSH Deployment
Publication date: 2015-05-12
Playlist: Cloud Foundry Summit 2015
Description: 
	Managing Multiple Clouds with a Single BOSH Deployment - 02 Alan Moran 720p
Captions: 
	00:00:01,700 --> 00:00:07,710
well good morning everyone my name is

00:00:04,410 --> 00:00:10,500
Salim alum Moran I work for a company

00:00:07,710 --> 00:00:12,380
named Al Toros and I've been working in

00:00:10,500 --> 00:00:15,710
Coventry for the past few years

00:00:12,380 --> 00:00:18,449
today I will be delivering to you a talk

00:00:15,710 --> 00:00:20,490
that was prepared by my friend Alexandra

00:00:18,449 --> 00:00:23,460
lamothe unfortunately he couldn't travel

00:00:20,490 --> 00:00:26,970
today so today we will talk about

00:00:23,460 --> 00:00:30,929
managing multiple clouds with only one

00:00:26,970 --> 00:00:33,329
boss installation we will particularly

00:00:30,929 --> 00:00:38,879
tackle two questions here how we could

00:00:33,329 --> 00:00:41,550
manage both employment or on a single

00:00:38,879 --> 00:00:47,010
multiple regions and how we could manage

00:00:41,550 --> 00:00:50,010
most employments or multiple clouds so

00:00:47,010 --> 00:00:53,250
let me tell you a few words about the

00:00:50,010 --> 00:00:55,170
Toros Altos is a consulting company we

00:00:53,250 --> 00:00:58,649
provide solutions from the cloud funder

00:00:55,170 --> 00:01:02,390
ecosystem to our clients we are in

00:00:58,649 --> 00:01:02,390
various locations around the world

00:01:02,449 --> 00:01:08,909
so how we starting working on this well

00:01:05,220 --> 00:01:12,210
a client came to us a health service

00:01:08,909 --> 00:01:14,509
provider came to us we've been working

00:01:12,210 --> 00:01:18,119
for them and they want a call foundry

00:01:14,509 --> 00:01:20,460
but they wanted to have canary all

00:01:18,119 --> 00:01:22,830
around the states and they wanted to be

00:01:20,460 --> 00:01:25,200
able to spin these casters on demand and

00:01:22,830 --> 00:01:27,750
that was not the only concern that we

00:01:25,200 --> 00:01:30,470
had at the old day we also wanted us to

00:01:27,750 --> 00:01:35,250
be able to deploy those cloud foundries

00:01:30,470 --> 00:01:38,310
on multiple infrastructures so we said

00:01:35,250 --> 00:01:40,200
okay we look into this problem and the

00:01:38,310 --> 00:01:42,540
community has been working on similar

00:01:40,200 --> 00:01:45,270
problems we look and we'll start working

00:01:42,540 --> 00:01:47,729
on a proof-of-concept in our own data

00:01:45,270 --> 00:01:50,460
centers we have offices Minsk and a

00:01:47,729 --> 00:01:53,579
cloud provider in Minsk and a cloud

00:01:50,460 --> 00:01:54,630
provider in the States so we said okay

00:01:53,579 --> 00:02:00,030
let's start working on a

00:01:54,630 --> 00:02:00,960
proof-of-concept but why we would want

00:02:00,030 --> 00:02:03,810
in the first place

00:02:00,960 --> 00:02:05,850
having multiple clouds implements which

00:02:03,810 --> 00:02:11,039
would be the reason that we would want

00:02:05,850 --> 00:02:13,860
that well to start with we would want to

00:02:11,039 --> 00:02:15,420
be as close as possible to our clients

00:02:13,860 --> 00:02:18,120
we want to be as close as possible to

00:02:15,420 --> 00:02:21,290
the user we want to have our class sir

00:02:18,120 --> 00:02:24,330
physically close to them in this way

00:02:21,290 --> 00:02:27,570
we'll have better response time less

00:02:24,330 --> 00:02:31,860
latency less probability of package

00:02:27,570 --> 00:02:36,500
losses and having multiple clusters also

00:02:31,860 --> 00:02:39,690
will bring us a system with full turns

00:02:36,500 --> 00:02:42,500
but let's think for a minute what about

00:02:39,690 --> 00:02:45,870
culinary how come foundry works over one

00:02:42,500 --> 00:02:47,640
when there are serious issues like the

00:02:45,870 --> 00:02:53,100
foundries not prepared to work over one

00:02:47,640 --> 00:02:56,310
out of the box I would just mention a

00:02:53,100 --> 00:02:58,740
couple of them for example the UAF con

00:02:56,310 --> 00:03:00,300
controller for those who don't know what

00:02:58,740 --> 00:03:02,930
I'm talking about the air con control

00:03:00,300 --> 00:03:06,209
two components of cloud foundry they

00:03:02,930 --> 00:03:08,010
manage the users and authentications on

00:03:06,209 --> 00:03:10,890
roll the clock on trailwood it's

00:03:08,010 --> 00:03:14,640
basically manage all the rest from app

00:03:10,890 --> 00:03:18,209
services spaces or everything and these

00:03:14,640 --> 00:03:20,780
two components persist data on sequel

00:03:18,209 --> 00:03:24,600
solutions such as my sequel and Postgres

00:03:20,780 --> 00:03:26,850
now if we if we wanna if you would want

00:03:24,600 --> 00:03:30,239
to call foundry deploy on multiple

00:03:26,850 --> 00:03:33,239
clouds we will have to make this

00:03:30,239 --> 00:03:36,060
component and this a call for this

00:03:33,239 --> 00:03:38,360
sequel solution to work over one so

00:03:36,060 --> 00:03:40,709
that's the first problem that we'll have

00:03:38,360 --> 00:03:44,130
and I'm gonna print a problem that I can

00:03:40,709 --> 00:03:46,410
mention is nuts for the ones who haven't

00:03:44,130 --> 00:03:48,480
heard about this component first this is

00:03:46,410 --> 00:03:49,920
the component that allows all the

00:03:48,480 --> 00:03:55,080
internal communications that happen

00:03:49,920 --> 00:03:57,150
within call foundry and the pro this is

00:03:55,080 --> 00:04:01,200
the lesson is not optimized to work over

00:03:57,150 --> 00:04:02,970
one and that's H node of nuts noon notes

00:04:01,200 --> 00:04:05,820
about a group of nodes of other nodes

00:04:02,970 --> 00:04:08,519
I mean it's just not prepared to work

00:04:05,820 --> 00:04:11,130
over one so if you want to take risk and

00:04:08,519 --> 00:04:13,830
we find a solution of a sequel database

00:04:11,130 --> 00:04:16,739
such as 30s that actually would work on

00:04:13,830 --> 00:04:19,620
different regions or or or distributed

00:04:16,739 --> 00:04:21,479
in the distributed way over one I will

00:04:19,620 --> 00:04:23,669
say okay let's try to the deployment we

00:04:21,479 --> 00:04:26,389
the first problems that we will find

00:04:23,669 --> 00:04:29,419
would be the internal communication

00:04:26,389 --> 00:04:33,520
between the components we will run into

00:04:29,419 --> 00:04:36,909
time on trial for example we will have

00:04:33,520 --> 00:04:39,979
unpredictable things happening right

00:04:36,909 --> 00:04:45,740
we could lose packages such as her bits

00:04:39,979 --> 00:04:50,779
and an app could be lunch or hour and

00:04:45,740 --> 00:04:57,080
the upstaging process could be may have

00:04:50,779 --> 00:04:58,699
problems too so we went we went forward

00:04:57,080 --> 00:05:00,560
and said okay the solution would be to

00:04:58,699 --> 00:05:02,719
to replicate the same cloth on

00:05:00,560 --> 00:05:05,599
reservations on each of the regions or

00:05:02,719 --> 00:05:09,080
clouds that will be together with this

00:05:05,599 --> 00:05:11,029
we would use a Geo DNS in this way we

00:05:09,080 --> 00:05:14,779
will distribute the lot between the

00:05:11,029 --> 00:05:16,819
different clusters and make sure that

00:05:14,779 --> 00:05:20,029
the closest cluster responds to the

00:05:16,819 --> 00:05:22,159
closest client and then we will leave

00:05:20,029 --> 00:05:26,330
the app deployment process to be

00:05:22,159 --> 00:05:28,460
distributed on all our clusters then the

00:05:26,330 --> 00:05:31,909
app developers who need to find a way of

00:05:28,460 --> 00:05:34,460
their apps to actually work over one if

00:05:31,909 --> 00:05:37,639
they need any storage solution at all

00:05:34,460 --> 00:05:41,240
but that this will build a digital taco

00:05:37,639 --> 00:05:44,120
and to apply this solution that this is

00:05:41,240 --> 00:05:45,860
what the community and we personally

00:05:44,120 --> 00:05:48,229
adulterous have been doing so far and

00:05:45,860 --> 00:05:51,139
whenever we have multiple clusters we

00:05:48,229 --> 00:05:53,029
always need at least one borscht

00:05:51,139 --> 00:05:58,250
installation in each of the regions or

00:05:53,029 --> 00:06:00,020
each of the clouds that we are at so we

00:05:58,250 --> 00:06:02,930
start thinking of possibilities we

00:06:00,020 --> 00:06:06,259
started thinking how hard it will be we

00:06:02,930 --> 00:06:10,639
know how Bosh works behind how hard it

00:06:06,259 --> 00:06:13,669
would be to do some changes from borscht

00:06:10,639 --> 00:06:15,379
and be able to to spin up multiple

00:06:13,669 --> 00:06:19,069
clusters from only one borscht

00:06:15,379 --> 00:06:21,259
installation um why we would want to do

00:06:19,069 --> 00:06:24,139
this well this plan in particular wanted

00:06:21,259 --> 00:06:28,819
to have different clients spin out on

00:06:24,139 --> 00:06:30,710
the band and it would be less less hard

00:06:28,819 --> 00:06:33,649
for us to have all the synchronisation

00:06:30,710 --> 00:06:36,949
in one cluster and also would save us

00:06:33,649 --> 00:06:38,690
the Bob's time and resources in

00:06:36,949 --> 00:06:39,879
particular because we have only one boss

00:06:38,690 --> 00:06:42,919
I would prefer

00:06:39,879 --> 00:06:45,789
as engineer to have a really robust

00:06:42,919 --> 00:06:47,780
Bosch installation instead of having

00:06:45,789 --> 00:06:51,229
multiple destinations on each of the

00:06:47,780 --> 00:06:52,520
regions so we went ahead and say okay

00:06:51,229 --> 00:06:54,949
let's let's first style this

00:06:52,520 --> 00:07:00,229
proof-of-concept internally and see if

00:06:54,949 --> 00:07:02,360
we managed to do it so how how we did it

00:07:00,229 --> 00:07:05,139
well first to understand how we did that

00:07:02,360 --> 00:07:07,970
we star I will explain briefly how

00:07:05,139 --> 00:07:10,069
borsch interacts with the different

00:07:07,970 --> 00:07:11,960
cloud providers I'll show the different

00:07:10,069 --> 00:07:20,780
changes that had to perform for for

00:07:11,960 --> 00:07:23,449
Bosch to to be able to to do this to

00:07:20,780 --> 00:07:25,280
simplify the scenario whenever we do a

00:07:23,449 --> 00:07:27,110
deployment or well little data

00:07:25,280 --> 00:07:31,490
deployment we have three three main

00:07:27,110 --> 00:07:33,710
inputs one is the release that is

00:07:31,490 --> 00:07:37,069
basically the recipes everything that we

00:07:33,710 --> 00:07:40,069
need to run our software we have a

00:07:37,069 --> 00:07:42,710
manifest which is a descriptive file

00:07:40,069 --> 00:07:45,979
that that describes the properties and

00:07:42,710 --> 00:07:49,520
the desire state of our cluster we have

00:07:45,979 --> 00:07:51,409
an extensive which is an image that is

00:07:49,520 --> 00:07:54,529
prepared to run on this particular

00:07:51,409 --> 00:07:56,509
provider that we are working with and

00:07:54,529 --> 00:08:00,380
also holds a piece of software that will

00:07:56,509 --> 00:08:02,870
let Bosch later communicate with this

00:08:00,380 --> 00:08:04,120
this p.m. so we get created on on our

00:08:02,870 --> 00:08:07,099
cloud

00:08:04,120 --> 00:08:09,259
so this inputs arrived to the director

00:08:07,099 --> 00:08:11,659
the director is responsible for

00:08:09,259 --> 00:08:13,520
castrating all deployments in Bosch and

00:08:11,659 --> 00:08:18,620
all updates on the whole life cycle of

00:08:13,520 --> 00:08:21,650
our deployments the director talks with

00:08:18,620 --> 00:08:24,349
the CBI and the CPI is a particular

00:08:21,650 --> 00:08:27,680
component that is develop one per cloud

00:08:24,349 --> 00:08:32,449
and how it makes in let's watch being

00:08:27,680 --> 00:08:34,399
agnostic to the cloud that we are and

00:08:32,449 --> 00:08:36,620
finally we have the cloud API that this

00:08:34,399 --> 00:08:38,089
will be like Dave Lewis API or the

00:08:36,620 --> 00:08:44,060
OpenStack API that we are actually

00:08:38,089 --> 00:08:46,850
talking to now for being able to for

00:08:44,060 --> 00:08:49,190
both being able to work as synchronously

00:08:46,850 --> 00:08:50,990
with deployments on multiple clouds we

00:08:49,190 --> 00:08:53,360
needed to do some changes from boss

00:08:50,990 --> 00:08:55,250
director so they can Hollins

00:08:53,360 --> 00:08:57,769
in one instance of abortion electrical

00:08:55,250 --> 00:08:59,810
hole they can work with different CPI's

00:08:57,769 --> 00:09:02,600
at the same time that was the first

00:08:59,810 --> 00:09:06,320
change that we need to do then we needed

00:09:02,600 --> 00:09:08,209
to address the inputs we have three

00:09:06,320 --> 00:09:10,640
different inputs here which are the

00:09:08,209 --> 00:09:13,100
release mindfulness stem cell but

00:09:10,640 --> 00:09:16,399
unfortunately only one is gone agnostic

00:09:13,100 --> 00:09:19,459
the release is the only input from our

00:09:16,399 --> 00:09:22,160
system that is cloud agnostic the

00:09:19,459 --> 00:09:24,860
manifests holds information about the

00:09:22,160 --> 00:09:28,779
cloud and the stem cell is it's also

00:09:24,860 --> 00:09:30,980
related with a particular cloud provider

00:09:28,779 --> 00:09:35,720
so let's start by addressing the

00:09:30,980 --> 00:09:37,519
manifest there is likely there's a we

00:09:35,720 --> 00:09:41,450
didn't have to do much work because on

00:09:37,519 --> 00:09:44,149
recent release of Bosch there's a cloud

00:09:41,450 --> 00:09:47,870
config feature when we can extract all

00:09:44,149 --> 00:09:53,630
the cloud related information and I'm

00:09:47,870 --> 00:09:55,490
putting on a separate file this is how

00:09:53,630 --> 00:09:59,649
it would look at this is an example how

00:09:55,490 --> 00:10:01,640
the cloud config file will look like and

00:09:59,649 --> 00:10:04,220
together with this feature they

00:10:01,640 --> 00:10:07,130
distributed on the clear the options to

00:10:04,220 --> 00:10:12,769
be able to set an output what we are

00:10:07,130 --> 00:10:16,180
actually having that file so we have our

00:10:12,769 --> 00:10:19,760
first problem address we would separate

00:10:16,180 --> 00:10:21,560
the hopefully all the cloud related

00:10:19,760 --> 00:10:22,640
information about our manifest in

00:10:21,560 --> 00:10:26,149
different cloud configs

00:10:22,640 --> 00:10:28,250
one per each of our infrastructures we

00:10:26,149 --> 00:10:31,459
now we still need to address the problem

00:10:28,250 --> 00:10:34,880
stem so this is not actually a problem

00:10:31,459 --> 00:10:36,740
if we if we would do a serial deployment

00:10:34,880 --> 00:10:38,570
we will first work with one cloud them

00:10:36,740 --> 00:10:41,300
with other but working on multiple

00:10:38,570 --> 00:10:45,620
clouds we will need to have a reference

00:10:41,300 --> 00:10:47,810
to it so to understand how how this

00:10:45,620 --> 00:10:53,690
system cell gets to the cloud API I will

00:10:47,810 --> 00:10:57,010
describe this process briefly both

00:10:53,690 --> 00:11:01,699
director sends the image file to the CPI

00:10:57,010 --> 00:11:04,580
now the CPI is responsible of talking

00:11:01,699 --> 00:11:07,880
with the cloud provider

00:11:04,580 --> 00:11:10,970
here the CPI since the the file of the

00:11:07,880 --> 00:11:13,820
image that we have to to the the cloud

00:11:10,970 --> 00:11:15,860
API and in response from the co lpa gets

00:11:13,820 --> 00:11:19,370
a reference a graph a reference in the

00:11:15,860 --> 00:11:20,120
domain of the cloud provider the then

00:11:19,370 --> 00:11:24,890
later

00:11:20,120 --> 00:11:27,380
boss would use to spin up machines so

00:11:24,890 --> 00:11:29,209
then this this referent ID came comes

00:11:27,380 --> 00:11:35,420
back to borscht and his sister in boss

00:11:29,209 --> 00:11:38,750
director database to be able to perform

00:11:35,420 --> 00:11:42,170
this we we did some changes we able to

00:11:38,750 --> 00:11:44,450
be able to tag the the OpenStack that

00:11:42,170 --> 00:11:48,079
the different stencils that we we want

00:11:44,450 --> 00:11:51,320
to to get to the system so we use this

00:11:48,079 --> 00:11:53,029
cloud tag in this example to to tag the

00:11:51,320 --> 00:11:56,360
different cloud so we're going to work

00:11:53,029 --> 00:11:58,430
with or in the in the current situation

00:11:56,360 --> 00:12:00,709
we could do this serial like we could

00:11:58,430 --> 00:12:02,870
just update the cloud configs and upload

00:12:00,709 --> 00:12:05,000
the different stem cells so that Bosch

00:12:02,870 --> 00:12:06,800
makes the different changes between the

00:12:05,000 --> 00:12:16,850
different cps that it needs to talk with

00:12:06,800 --> 00:12:18,770
each of the cloud providers so let's

00:12:16,850 --> 00:12:20,029
make a quick recap and we have

00:12:18,770 --> 00:12:22,790
everything ready right we have the

00:12:20,029 --> 00:12:25,880
manifest ready we have the different

00:12:22,790 --> 00:12:27,860
clock on fix we have the stem cell we

00:12:25,880 --> 00:12:29,839
have the release probably upload or rate

00:12:27,860 --> 00:12:32,709
wash we have everything ready to do the

00:12:29,839 --> 00:12:35,930
deployment or an update with Porsche

00:12:32,709 --> 00:12:37,550
so we will go briefly for the process of

00:12:35,930 --> 00:12:40,430
how this works and which are their

00:12:37,550 --> 00:12:44,420
modifications that we need to do to

00:12:40,430 --> 00:12:46,459
support these multiple clouds the first

00:12:44,420 --> 00:12:48,410
processes that happen our the binding

00:12:46,459 --> 00:12:53,390
deployment process and they create and

00:12:48,410 --> 00:12:59,209
the plan creation process during this

00:12:53,390 --> 00:13:01,730
process wash receives a manifest and in

00:12:59,209 --> 00:13:04,730
links or with what it knows that it has

00:13:01,730 --> 00:13:06,860
in the database it finds the deltas

00:13:04,730 --> 00:13:09,170
between the desire state and the actual

00:13:06,860 --> 00:13:10,970
state for example like the amount of

00:13:09,170 --> 00:13:13,100
machines that are actually created see

00:13:10,970 --> 00:13:15,800
if the their jobs are applying to deploy

00:13:13,100 --> 00:13:18,200
are the same amount and five the servers

00:13:15,800 --> 00:13:27,350
and while doing these it creates

00:13:18,200 --> 00:13:30,740
deployment plan so we have one problem

00:13:27,350 --> 00:13:34,100
here how we can do the binding for for

00:13:30,740 --> 00:13:36,500
motive for multiple clouds so for this

00:13:34,100 --> 00:13:40,430
we had to actually do some modifications

00:13:36,500 --> 00:13:43,220
emboss and and support a new entity

00:13:40,430 --> 00:13:45,290
which is cloud this is the database

00:13:43,220 --> 00:13:54,279
model of Porsche and we added the cloud

00:13:45,290 --> 00:13:57,139
entity here nextpart package compilation

00:13:54,279 --> 00:14:00,529
for those who don't know what happens

00:13:57,139 --> 00:14:02,329
here it basically grabs the package that

00:14:00,529 --> 00:14:05,120
hasn't been compiled for a particular

00:14:02,329 --> 00:14:08,649
stem cell and on a particular cloud

00:14:05,120 --> 00:14:10,699
provider and it compiles this package

00:14:08,649 --> 00:14:15,350
let's go through the process pre-flight

00:14:10,699 --> 00:14:17,990
to see what what happened behind so boss

00:14:15,350 --> 00:14:21,610
director talks with CPI CPI has talked

00:14:17,990 --> 00:14:24,829
with the cloud API and they create a VM

00:14:21,610 --> 00:14:28,300
this VM will its use with the stem cell

00:14:24,829 --> 00:14:32,860
that was previously uploaded and it will

00:14:28,300 --> 00:14:32,860
compile the packages from our release

00:14:34,060 --> 00:14:39,320
this packages later gets sent back to

00:14:37,250 --> 00:14:42,079
blobster so they get download full of

00:14:39,320 --> 00:14:46,269
buffs or pre compile and then gave a

00:14:42,079 --> 00:14:46,269
blow to browser compile now

00:14:49,580 --> 00:14:56,390
so the next problem how we make these

00:14:54,470 --> 00:14:58,670
Bluffs are accessible from multiple

00:14:56,390 --> 00:15:00,580
providers that deploy maybe in many

00:14:58,670 --> 00:15:03,050
regions or around the world

00:15:00,580 --> 00:15:05,269
well there are a couple of options that

00:15:03,050 --> 00:15:09,500
we analyze we could have like separated

00:15:05,269 --> 00:15:11,570
officers and seek them we could have

00:15:09,500 --> 00:15:13,339
separate blob source and compile on each

00:15:11,570 --> 00:15:19,250
of the blob source only what is related

00:15:13,339 --> 00:15:21,110
to its own cloud right we could use an

00:15:19,250 --> 00:15:24,440
external brach for public and everyone

00:15:21,110 --> 00:15:26,839
could point to that one or we could use

00:15:24,440 --> 00:15:29,480
well what we did actually ask as our

00:15:26,839 --> 00:15:31,279
solution which is use a program the

00:15:29,480 --> 00:15:34,279
current blob store and establish VPN

00:15:31,279 --> 00:15:44,240
connections from where we have our main

00:15:34,279 --> 00:15:46,579
borsch server to all the other clouds so

00:15:44,240 --> 00:15:49,959
the last problem creating jobs again

00:15:46,579 --> 00:15:49,959
let's see what happens here

00:15:50,649 --> 00:15:57,920
well when we create a VM we first send

00:15:54,290 --> 00:16:00,860
some agent settings that this will be we

00:15:57,920 --> 00:16:03,860
will put inside the VM and the stencil

00:16:00,860 --> 00:16:07,550
ID and the CPI later talks with the

00:16:03,860 --> 00:16:11,000
curve API and creates this VM in return

00:16:07,550 --> 00:16:15,860
for the coil Pai we get some information

00:16:11,000 --> 00:16:17,959
about this VM like for example IP so we

00:16:15,860 --> 00:16:29,240
know where we actually need to look for

00:16:17,959 --> 00:16:31,459
it now CPI sends somehow depending on

00:16:29,240 --> 00:16:33,529
which on the different clouds some

00:16:31,459 --> 00:16:39,079
initial configuration initial settings

00:16:33,529 --> 00:16:41,180
to that BM through the cloud API the VM

00:16:39,079 --> 00:16:43,940
and the boss session which is like a

00:16:41,180 --> 00:16:47,029
piece of software that lets that BM talk

00:16:43,940 --> 00:16:50,209
with with the boss insulation receive

00:16:47,029 --> 00:16:54,769
this these initial settings and from it

00:16:50,209 --> 00:16:58,100
are able to talk back with boss and they

00:16:54,769 --> 00:17:01,160
do this through nuts that is back in the

00:16:58,100 --> 00:17:03,579
picture here now it's in the context of

00:17:01,160 --> 00:17:03,579
boss

00:17:03,700 --> 00:17:11,660
so we will have only one nuts or or

00:17:08,720 --> 00:17:14,330
maybe highly available deployed but they

00:17:11,660 --> 00:17:17,270
will be on our own installation abortion

00:17:14,330 --> 00:17:20,690
we need to make not accessible somehow

00:17:17,270 --> 00:17:29,780
or be able to perform this processes at

00:17:20,690 --> 00:17:32,150
least then where we not then it go it

00:17:29,780 --> 00:17:33,860
goes with Nazis receives like the

00:17:32,150 --> 00:17:38,630
information on what it needs to run

00:17:33,860 --> 00:17:41,600
right the VM it's identified and it's

00:17:38,630 --> 00:17:43,550
assigned of a resource pool and it

00:17:41,600 --> 00:17:45,920
brings all the packages and shops that

00:17:43,550 --> 00:17:47,720
will run to start the actual system the

00:17:45,920 --> 00:17:51,320
actual deploy that were performing or

00:17:47,720 --> 00:17:53,450
update so again we have this problem

00:17:51,320 --> 00:17:55,970
what what we do we not how we establish

00:17:53,450 --> 00:18:01,030
this communication being on multiple

00:17:55,970 --> 00:18:04,430
clouds so our two options here there's

00:18:01,030 --> 00:18:07,220
the HTTP a messaging bus which is one

00:18:04,430 --> 00:18:08,570
option that doesn't use nuts which is

00:18:07,220 --> 00:18:10,190
the one that you apply when you deploy a

00:18:08,570 --> 00:18:12,950
microbe or Shore when you do a cloud in

00:18:10,190 --> 00:18:16,250
it or the second option that you have is

00:18:12,950 --> 00:18:18,170
establishing a VPN connection and this

00:18:16,250 --> 00:18:19,880
is the one we took is similar of what we

00:18:18,170 --> 00:18:21,680
did with the blobstore solution we

00:18:19,880 --> 00:18:23,660
stablish a VPN connection from each of

00:18:21,680 --> 00:18:27,640
the clouds providers that were

00:18:23,660 --> 00:18:27,640
connecting to our main portions nation

00:18:30,970 --> 00:18:36,560
so this is the picture of how it works

00:18:33,440 --> 00:18:38,600
we have a pin Center will have a VPN

00:18:36,560 --> 00:18:41,860
server on the data center that is

00:18:38,600 --> 00:18:41,860
connecting to our main Bosh

00:18:44,720 --> 00:18:51,800
now to recap we we proved and we finally

00:18:50,810 --> 00:18:54,890
got it working

00:18:51,800 --> 00:18:58,630
and I were - were - to the dissenters

00:18:54,890 --> 00:19:01,100
one OpenStack or Minsk one AWS

00:18:58,630 --> 00:19:04,220
deployment of Cloud Foundry on the

00:19:01,100 --> 00:19:06,050
state's working with one single borscht

00:19:04,220 --> 00:19:12,040
appointment that was per the was

00:19:06,050 --> 00:19:12,040
deployed on on Minsk we got this working

00:19:12,580 --> 00:19:19,790
and unfortunately I don't have time for

00:19:17,780 --> 00:19:23,540
demo because this process takes a long

00:19:19,790 --> 00:19:27,410
time but this week we'll be releasing a

00:19:23,540 --> 00:19:29,540
blog post we are looking forward to to

00:19:27,410 --> 00:19:32,090
work with the Bosch team and see if this

00:19:29,540 --> 00:19:35,030
is of any interesting to introduce to

00:19:32,090 --> 00:19:37,280
the main branch and in the blocks for

00:19:35,030 --> 00:19:38,780
that please check this this website

00:19:37,280 --> 00:19:41,630
during this week there will be a video

00:19:38,780 --> 00:19:45,830
of how this is actually working on our

00:19:41,630 --> 00:19:47,750
clusters furthermore we will work on on

00:19:45,830 --> 00:19:51,010
applying this solution for our the

00:19:47,750 --> 00:19:51,010
client that we've been working for

00:19:51,880 --> 00:19:56,630
finally let me say some words about

00:19:54,530 --> 00:19:59,570
Bosch we we proved that Bosch is

00:19:56,630 --> 00:20:01,700
extensible we proved that the washer SEP

00:19:59,570 --> 00:20:06,380
is a powerful tool and it's easy to work

00:20:01,700 --> 00:20:11,020
with and we are really thankful for

00:20:06,380 --> 00:20:11,020
washing for for making such a great tool

00:20:11,260 --> 00:20:17,450
again thanks to Lomov and are there any

00:20:15,260 --> 00:20:23,890
questions you guys might have or

00:20:17,450 --> 00:20:23,890
discipline yes

00:20:27,230 --> 00:20:33,270
well right

00:20:30,060 --> 00:20:37,580
no the you mean what do you ask in

00:20:33,270 --> 00:20:40,200
particular how do they keep absence Inc

00:20:37,580 --> 00:20:42,540
well we have an implemented solution for

00:20:40,200 --> 00:20:45,570
that but we could do we can work on on a

00:20:42,540 --> 00:20:46,950
plugin and just make sure that it

00:20:45,570 --> 00:20:51,030
managed a different reference to the

00:20:46,950 --> 00:20:54,270
different countries then on different on

00:20:51,030 --> 00:20:56,730
my experience and the the province is

00:20:54,270 --> 00:20:58,530
itself how the apps would would work on

00:20:56,730 --> 00:21:10,170
multiple clouds right which if they need

00:20:58,530 --> 00:21:12,830
to search in any type of data yes how do

00:21:10,170 --> 00:21:12,830
you manage the

00:21:29,090 --> 00:21:36,330
yeah well that's more on the developer

00:21:33,930 --> 00:21:39,270
side like how how you will develop your

00:21:36,330 --> 00:21:40,920
app first of all you have to find you

00:21:39,270 --> 00:21:43,410
will have to find solutions that work

00:21:40,920 --> 00:21:46,770
over one if you want to have sync your

00:21:43,410 --> 00:21:49,980
your your data layer or at that level

00:21:46,770 --> 00:22:02,490
then depends which type of apps we are

00:21:49,980 --> 00:22:04,800
working we're working with right oh you

00:22:02,490 --> 00:22:06,660
mean like how do how this war actually

00:22:04,800 --> 00:22:09,360
works in what regards to latency this

00:22:06,660 --> 00:22:11,640
VPN connections are established well at

00:22:09,360 --> 00:22:13,830
least we are still making distance on

00:22:11,640 --> 00:22:16,950
how does it work my regards to the

00:22:13,830 --> 00:22:19,470
lifecycle of the deployment using

00:22:16,950 --> 00:22:21,390
features such as the resurrector and we

00:22:19,470 --> 00:22:25,110
haven't worked on these things yet and

00:22:21,390 --> 00:22:28,110
we're still testing this and again this

00:22:25,110 --> 00:22:30,720
is a proof of concept bad but we at

00:22:28,110 --> 00:22:32,700
least the the latency is enough for for

00:22:30,720 --> 00:22:42,000
us being able to do perform a deployment

00:22:32,700 --> 00:22:45,660
let's say yes yeah actually we did

00:22:42,000 --> 00:22:48,240
consider you singing which is when this

00:22:45,660 --> 00:22:51,420
path because we implemented already that

00:22:48,240 --> 00:22:54,180
the VPN solution for nuts so we said ok

00:22:51,420 --> 00:23:00,170
let's just we have it there and which is

00:22:54,180 --> 00:23:00,170
supplied bad but yeah yes

00:23:16,530 --> 00:23:22,840
so you're saying the question is how do

00:23:19,600 --> 00:23:25,690
we manage data oscillation from the

00:23:22,840 --> 00:23:28,630
upside in different clusters this is

00:23:25,690 --> 00:23:30,400
correct well that depends if you really

00:23:28,630 --> 00:23:32,830
want data oscillation that depends of

00:23:30,400 --> 00:23:35,920
how you want each of the clusters to to

00:23:32,830 --> 00:23:38,560
work if you want like always same

00:23:35,920 --> 00:23:40,450
clients will address through GI DNS to

00:23:38,560 --> 00:23:41,800
the same clusters if they are located in

00:23:40,450 --> 00:23:44,200
the same place wise they move around

00:23:41,800 --> 00:23:46,840
they might be addressed to a different

00:23:44,200 --> 00:23:49,840
cluster so that I don't know if you

00:23:46,840 --> 00:23:51,280
that's again that's been of the use case

00:23:49,840 --> 00:24:04,060
that you're working with if you need

00:23:51,280 --> 00:24:06,010
data oscillation at all yeah yes I well

00:24:04,060 --> 00:24:10,930
I'm actually I haven't worked much in

00:24:06,010 --> 00:24:13,870
implementation unfortunately but what we

00:24:10,930 --> 00:24:17,350
did is add on the domain of of the boss

00:24:13,870 --> 00:24:27,580
database a new entity which is cloud so

00:24:17,350 --> 00:24:30,700
we can reference to that one if I have a

00:24:27,580 --> 00:24:31,300
way to speed up our orchestration

00:24:30,700 --> 00:24:35,260
process

00:24:31,300 --> 00:24:37,540
well no but by having only one boss it's

00:24:35,260 --> 00:24:39,310
already speed ups this feature that our

00:24:37,540 --> 00:24:42,760
client want in the very beginning which

00:24:39,310 --> 00:24:44,290
is having clouds on demand having one

00:24:42,760 --> 00:24:46,690
 so we don't need to go there

00:24:44,290 --> 00:24:48,550
they spin up a bomb microbe or should

00:24:46,690 --> 00:24:51,780
spin up a boss and then do our

00:24:48,550 --> 00:24:51,780
deployment which is have

00:25:00,650 --> 00:25:06,360
no there-there's no constraints in what

00:25:04,170 --> 00:25:07,830
regards to scaling as long as your board

00:25:06,360 --> 00:25:09,930
still has connection and you still have

00:25:07,830 --> 00:25:16,110
resources in your in your cloud provider

00:25:09,930 --> 00:25:20,540
Europe and we have only done

00:25:16,110 --> 00:25:24,270
simultaneously as synchronously

00:25:20,540 --> 00:25:26,970
deploying or two clusters of OpenStack

00:25:24,270 --> 00:25:29,040
and it'll yes that's what we have done

00:25:26,970 --> 00:25:45,210
so far we haven't done further tests

00:25:29,040 --> 00:25:49,320
yeah oh well let's yeah no we haven't

00:25:45,210 --> 00:25:51,570
work in any of those but the gdns is it

00:25:49,320 --> 00:25:59,090
it will redirect to the other IPS if

00:25:51,570 --> 00:25:59,090
it's down yeah

00:26:06,830 --> 00:26:14,960
I understand what you mean well if if

00:26:13,250 --> 00:26:19,000
any of the clusters failed that there

00:26:14,960 --> 00:26:19,000
will be they are providing at this point

00:26:19,510 --> 00:26:35,690
we haven't made a solution for that yet

00:26:22,430 --> 00:26:36,860
yeah yeah yeah the cloud config yeah we

00:26:35,690 --> 00:26:39,020
talked about that it's actually a

00:26:36,860 --> 00:26:41,510
feature that we we make use of and it's

00:26:39,020 --> 00:26:43,390
so one of the our issues actually it's

00:26:41,510 --> 00:26:47,680
great

00:26:43,390 --> 00:26:47,680
are there any other questions yes

00:26:54,440 --> 00:27:06,089
by didn't her what to say sorry not yet

00:27:03,539 --> 00:27:09,119
we are we are we are we're playing them

00:27:06,089 --> 00:27:11,099
I'm doing it in the next week or two we

00:27:09,119 --> 00:27:12,929
want to want to put this public and

00:27:11,099 --> 00:27:15,479
we'll be together with the blocks fault

00:27:12,929 --> 00:27:20,029
that we are we know mom is finishing

00:27:15,479 --> 00:27:24,709
work you know together there will be a

00:27:20,029 --> 00:27:26,519
video demo that shows all the different

00:27:24,709 --> 00:27:29,579
customizations that we did in Berkeley

00:27:26,519 --> 00:27:31,219
to interact with crowds and yeah it will

00:27:29,579 --> 00:27:36,010
be all the information will be there

00:27:31,219 --> 00:27:40,819
this week okay thank you very much

00:27:36,010 --> 00:27:40,819

YouTube URL: https://www.youtube.com/watch?v=Z-sqRtGZUyI


