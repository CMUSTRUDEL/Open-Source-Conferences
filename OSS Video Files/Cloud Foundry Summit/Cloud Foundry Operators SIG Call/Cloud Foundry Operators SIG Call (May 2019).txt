Title: Cloud Foundry Operators SIG Call (May 2019)
Publication date: 2019-05-31
Playlist: Cloud Foundry Operators SIG Call
Description: 
	
Captions: 
	00:00:02,000 --> 00:00:07,859
hello everyone so good evening good

00:00:05,310 --> 00:00:10,610
afternoon from different regions thanks

00:00:07,859 --> 00:00:14,940
for joining that the second call of sick

00:00:10,610 --> 00:00:18,510
operations meeting so we have three

00:00:14,940 --> 00:00:20,369
topics for this meeting today the first

00:00:18,510 --> 00:00:24,750
topic is basically about the cloud

00:00:20,369 --> 00:00:27,449
foundry at scales who maybe I can give

00:00:24,750 --> 00:00:29,220
it over to burn too right away kick

00:00:27,449 --> 00:00:30,689
start the meeting with the elephant at

00:00:29,220 --> 00:00:33,780
scale over to you Ben

00:00:30,689 --> 00:00:36,239
over to you burnt yeah okay thanks

00:00:33,780 --> 00:00:39,570
covering so actually I'm not going to

00:00:36,239 --> 00:00:42,360
present alone but Ian Susskind colleague

00:00:39,570 --> 00:00:46,590
of mine is is also the call we are both

00:00:42,360 --> 00:00:49,590
from the SA P cloud platform development

00:00:46,590 --> 00:00:51,420
organization against is an area product

00:00:49,590 --> 00:00:54,300
owner there and I'm a technical lead

00:00:51,420 --> 00:00:57,809
there and we are kind of pairing up to

00:00:54,300 --> 00:01:02,430
work on the topic of cloud foundry

00:00:57,809 --> 00:01:04,739
overall and I guess meanwhile we also in

00:01:02,430 --> 00:01:08,400
flame that we are running some of this

00:01:04,739 --> 00:01:10,560
out foundry deployments world by in this

00:01:08,400 --> 00:01:12,750
presentation we want to kind of

00:01:10,560 --> 00:01:15,420
summarize our our learnings and and

00:01:12,750 --> 00:01:19,770
experience from bringing cloud foundry

00:01:15,420 --> 00:01:22,740
to scale and and essentially also share

00:01:19,770 --> 00:01:25,680
a little bit the topics that we hit

00:01:22,740 --> 00:01:30,600
while we are in the progress of scaling

00:01:25,680 --> 00:01:32,610
cloud foundry so with that let's right

00:01:30,600 --> 00:01:34,890
away jump into the topic and this

00:01:32,610 --> 00:01:37,979
there's actually a couple of dimensions

00:01:34,890 --> 00:01:41,640
if we call or if we talk about scaling

00:01:37,979 --> 00:01:44,790
cloud foundry then one aspect to to

00:01:41,640 --> 00:01:46,920
actually look at is like how many cloud

00:01:44,790 --> 00:01:49,860
foundry foundations or cloud foundry

00:01:46,920 --> 00:01:53,270
deployments does one actually need to

00:01:49,860 --> 00:01:53,270
run and as

00:01:54,840 --> 00:02:02,159
that that is essentially also a topic of

00:01:59,390 --> 00:02:04,710
regional coverage so where where are you

00:02:02,159 --> 00:02:08,039
deployments located that that is

00:02:04,710 --> 00:02:09,929
definitely one one thing there but then

00:02:08,039 --> 00:02:12,510
also we are running a city cloud

00:02:09,929 --> 00:02:15,840
platform on top of the various hyper

00:02:12,510 --> 00:02:18,540
scale providers we will talk about that

00:02:15,840 --> 00:02:23,760
in the next slide in little more detail

00:02:18,540 --> 00:02:25,770
but that also for us brings additional

00:02:23,760 --> 00:02:28,739
effort and challenges in terms of

00:02:25,770 --> 00:02:30,750
scaling our offering but then last but

00:02:28,739 --> 00:02:33,360
not least which which is also a major

00:02:30,750 --> 00:02:36,390
focus of this presentation it's also

00:02:33,360 --> 00:02:41,280
about scaling up a single Cloud Foundry

00:02:36,390 --> 00:02:43,709
foundation so one deployment that at

00:02:41,280 --> 00:02:47,010
least we for a second our platform run

00:02:43,709 --> 00:02:51,360
in in a multi-tenant fashion for many

00:02:47,010 --> 00:02:55,019
many of our customers so by and large

00:02:51,360 --> 00:02:57,959
these are kind of the big dimensions

00:02:55,019 --> 00:03:00,060
that that we need to look at and now we

00:02:57,959 --> 00:03:04,860
are kind of diving in a little bit and

00:03:00,060 --> 00:03:08,910
in each of those so if we look at how we

00:03:04,860 --> 00:03:11,340
run on s ap cloud platform then this

00:03:08,910 --> 00:03:16,440
picture here pretty much describes on

00:03:11,340 --> 00:03:18,870
the various locations but then also data

00:03:16,440 --> 00:03:22,049
center providers that we offer a city

00:03:18,870 --> 00:03:24,959
cloud platform on so the orange one is a

00:03:22,049 --> 00:03:27,720
he owns data centers and then we

00:03:24,959 --> 00:03:31,500
essentially have a presence on on three

00:03:27,720 --> 00:03:35,160
big hyper scale as AWS Azure and Google

00:03:31,500 --> 00:03:38,310
cloud platform and because a city cloud

00:03:35,160 --> 00:03:40,739
platform kind of not only consists of

00:03:38,310 --> 00:03:44,459
Cloud Foundry but its origins actually

00:03:40,739 --> 00:03:46,890
date back pretty much back in time

00:03:44,459 --> 00:03:49,640
through a similar point in time then

00:03:46,890 --> 00:03:53,280
Cloud Foundry was was initially created

00:03:49,640 --> 00:03:55,019
we kind of have data centers that don't

00:03:53,280 --> 00:03:57,570
have Cloud Foundry but as you can see

00:03:55,019 --> 00:04:00,630
from from this visualization we also

00:03:57,570 --> 00:04:04,019
have quite a few data centers that that

00:04:00,630 --> 00:04:06,510
meanwhile run Cloud Foundry also in in

00:04:04,019 --> 00:04:08,489
the process of essentially taking a look

00:04:06,510 --> 00:04:10,859
at that metrics of

00:04:08,489 --> 00:04:14,489
data centers seeing where we need to

00:04:10,859 --> 00:04:16,560
build up additional regional coverage so

00:04:14,489 --> 00:04:18,840
that's like talking about global

00:04:16,560 --> 00:04:25,800
distribution that's roughly the scale

00:04:18,840 --> 00:04:30,030
that we have there then next one is

00:04:25,800 --> 00:04:32,669
essentially talking about like why is it

00:04:30,030 --> 00:04:35,630
challenge to to have that number of

00:04:32,669 --> 00:04:38,940
foundations that number of cloud foundry

00:04:35,630 --> 00:04:41,759
deployments out there in in the wild so

00:04:38,940 --> 00:04:45,300
to speak so it's it's a challenge on on

00:04:41,759 --> 00:04:46,800
a couple of fronts so first of all it's

00:04:45,300 --> 00:04:50,009
it's a challenge in in terms of

00:04:46,800 --> 00:04:51,870
monitoring so like obviously if you have

00:04:50,009 --> 00:04:53,910
one foundation you need to monitor that

00:04:51,870 --> 00:04:56,550
if you have multiple of those you need

00:04:53,910 --> 00:04:58,520
to make sure that each of those are are

00:04:56,550 --> 00:05:01,020
healthy so the question is essentially

00:04:58,520 --> 00:05:03,900
now that you have build your monitoring

00:05:01,020 --> 00:05:06,479
for one foundation how do you scale that

00:05:03,900 --> 00:05:08,580
up how do you make sure that your

00:05:06,479 --> 00:05:11,479
operations teams can actually monitor

00:05:08,580 --> 00:05:15,000
that whole set of Cloud Foundry

00:05:11,479 --> 00:05:17,970
deployments that I've depicted on on the

00:05:15,000 --> 00:05:19,460
previous slide then also because as I

00:05:17,970 --> 00:05:24,270
said we are talking multiple

00:05:19,460 --> 00:05:27,240
infrastructure providers this is also a

00:05:24,270 --> 00:05:29,669
challenge in development because like

00:05:27,240 --> 00:05:32,940
yes bush is a tool that that we

00:05:29,669 --> 00:05:35,820
definitely use quite quite a bit to to

00:05:32,940 --> 00:05:37,560
manage all those deployments and those

00:05:35,820 --> 00:05:40,620
deployments not only contain Cloud

00:05:37,560 --> 00:05:44,599
Foundry but they also contain things

00:05:40,620 --> 00:05:46,889
like packing services things like

00:05:44,599 --> 00:05:50,039
applications that we as I said he

00:05:46,889 --> 00:05:51,810
provides to our customers running on top

00:05:50,039 --> 00:05:54,780
of Cloud Foundry et cetera et cetera

00:05:51,810 --> 00:05:57,389
and so in development we need to make

00:05:54,780 --> 00:05:59,190
sure that like all those different

00:05:57,389 --> 00:06:01,229
infrastructure providers are are

00:05:59,190 --> 00:06:05,039
actually supported in the same way so

00:06:01,229 --> 00:06:07,229
our strategy is to have the same Cloud

00:06:05,039 --> 00:06:09,150
Foundry versions rolled out on all those

00:06:07,229 --> 00:06:11,639
infrastructure providers the same

00:06:09,150 --> 00:06:15,750
features enabled et cetera cetera so

00:06:11,639 --> 00:06:17,940
that roughly describes the the challenge

00:06:15,750 --> 00:06:19,590
that that we are facing in in the

00:06:17,940 --> 00:06:22,289
development organization and then

00:06:19,590 --> 00:06:24,180
obviously like it's not only enable

00:06:22,289 --> 00:06:28,499
those functionalities but then it's also

00:06:24,180 --> 00:06:31,139
about how do you test that stuff and

00:06:28,499 --> 00:06:33,839
then ultimately how do you update all

00:06:31,139 --> 00:06:36,180
those landscapes because for each of of

00:06:33,839 --> 00:06:38,909
the spots that you saw on on the

00:06:36,180 --> 00:06:41,189
previous world map you can essentially

00:06:38,909 --> 00:06:44,279
imagine that these were quote-unquote

00:06:41,189 --> 00:06:46,139
only our productive deployments but then

00:06:44,279 --> 00:06:49,710
for each of those productive deployments

00:06:46,139 --> 00:06:52,849
you have a set of deployments that are

00:06:49,710 --> 00:06:55,819
used for qualification that are used for

00:06:52,849 --> 00:06:59,279
testing hot fixes etcetera etcetera so

00:06:55,819 --> 00:07:02,249
it's kind of the world map that I've

00:06:59,279 --> 00:07:04,800
shown previously it's just a fraction of

00:07:02,249 --> 00:07:07,619
the number of cloud foundry foundations

00:07:04,800 --> 00:07:09,469
that we need to manage and then when it

00:07:07,619 --> 00:07:12,779
comes to updates we are essentially

00:07:09,469 --> 00:07:17,369
running a staged approach where

00:07:12,779 --> 00:07:19,919
obviously we qualify new updates to

00:07:17,369 --> 00:07:23,969
those foundations internally first and

00:07:19,919 --> 00:07:26,370
then we roll it out across the the hyper

00:07:23,969 --> 00:07:30,990
scalars across the regions etc etcetera

00:07:26,370 --> 00:07:34,379
and then obviously it's not only those

00:07:30,990 --> 00:07:36,059
those major updates but then and I guess

00:07:34,379 --> 00:07:37,949
everybody running Cloud Foundry

00:07:36,059 --> 00:07:41,189
deployment productively knows that

00:07:37,949 --> 00:07:43,830
there's also every now and then the

00:07:41,189 --> 00:07:46,639
requirement to basically patch those

00:07:43,830 --> 00:07:50,879
foundations and those might be

00:07:46,639 --> 00:07:53,389
functional fixes but those are also and

00:07:50,879 --> 00:07:56,459
this is where it gets time-critical

00:07:53,389 --> 00:07:58,319
fixes for known vulnerabilities there

00:07:56,459 --> 00:08:02,789
for example coming in via the Cloud

00:07:58,319 --> 00:08:07,249
Foundry Security Response process so as

00:08:02,789 --> 00:08:10,709
those fixes are sometimes time critical

00:08:07,249 --> 00:08:15,029
having that number of of Cloud Foundry

00:08:10,709 --> 00:08:18,839
foundations poses another challenge so

00:08:15,029 --> 00:08:21,240
that kind of describes roughly what we

00:08:18,839 --> 00:08:23,610
are facing in terms of infrastructure

00:08:21,240 --> 00:08:25,349
providers and then also regional or a

00:08:23,610 --> 00:08:27,539
distribution by the way I forgot to

00:08:25,349 --> 00:08:29,999
mention if you have questions at any

00:08:27,539 --> 00:08:33,240
point in time feel free to interrupt

00:08:29,999 --> 00:08:35,880
yeah so maybe band one one remark here

00:08:33,240 --> 00:08:38,280
is as well that we

00:08:35,880 --> 00:08:40,650
of try to stay on the latest CF

00:08:38,280 --> 00:08:44,820
deployment versions right and we do that

00:08:40,650 --> 00:08:46,590
in every every other week to consume

00:08:44,820 --> 00:08:49,440
those and there's also a major challenge

00:08:46,590 --> 00:08:53,610
in development to do that on five

00:08:49,440 --> 00:08:55,890
different gas providers right so this is

00:08:53,610 --> 00:08:58,530
definitely also challenge we have and

00:08:55,890 --> 00:09:01,590
when it comes to when it comes to

00:08:58,530 --> 00:09:04,770
patches it also means that you have to

00:09:01,590 --> 00:09:07,080
document what you change in the system

00:09:04,770 --> 00:09:10,530
that's not only true for petrus but also

00:09:07,080 --> 00:09:14,480
for updates and here if you have your

00:09:10,530 --> 00:09:16,650
platform certified like you have ISO or

00:09:14,480 --> 00:09:18,240
certifications and so on you also need

00:09:16,650 --> 00:09:20,880
to have proper change management

00:09:18,240 --> 00:09:24,270
processes in place and so on and so

00:09:20,880 --> 00:09:26,760
forth just yet this those yeah thank

00:09:24,270 --> 00:09:27,480
sense important points on that you

00:09:26,760 --> 00:09:34,140
brought up there

00:09:27,480 --> 00:09:36,180
yes definitely so then what what is the

00:09:34,140 --> 00:09:37,830
size of a single foundation so now that

00:09:36,180 --> 00:09:39,840
we have kind of briefly touched upon

00:09:37,830 --> 00:09:43,020
what is the challenge with with multiple

00:09:39,840 --> 00:09:45,480
foundations let's dive into the size of

00:09:43,020 --> 00:09:50,070
a single foundation and and these

00:09:45,480 --> 00:09:52,200
numbers here actually we took them for

00:09:50,070 --> 00:09:54,390
the Cloud Foundry summit way and said

00:09:52,200 --> 00:09:57,270
the presentation during the unconference

00:09:54,390 --> 00:10:00,060
talking very briefly about the topic of

00:09:57,270 --> 00:10:02,760
Cloud Foundry scaling and and this here

00:10:00,060 --> 00:10:05,940
are our numbers that we that we

00:10:02,760 --> 00:10:07,980
published back then actually I I looked

00:10:05,940 --> 00:10:10,650
at the number of service instances

00:10:07,980 --> 00:10:12,480
coincidentally just an hour ago and I

00:10:10,650 --> 00:10:15,870
can definitely tell though that number

00:10:12,480 --> 00:10:18,930
is growing immensely so and the same I

00:10:15,870 --> 00:10:21,540
think is true for for the other figures

00:10:18,930 --> 00:10:24,120
that we've provided to you so definitely

00:10:21,540 --> 00:10:27,450
we have quite some some uptake in in

00:10:24,120 --> 00:10:31,610
terms of people using our offering and

00:10:27,450 --> 00:10:34,560
that is both SAT teams that are

00:10:31,610 --> 00:10:36,810
developing and deploying and operating

00:10:34,560 --> 00:10:39,540
their solutions on top of our SAT cloud

00:10:36,810 --> 00:10:42,570
platform cloud foundry offering but it's

00:10:39,540 --> 00:10:46,770
also external customers that are using

00:10:42,570 --> 00:10:49,500
our platform and that kind of the

00:10:46,770 --> 00:10:49,710
remainder of that presentation is around

00:10:49,500 --> 00:10:52,440
that

00:10:49,710 --> 00:10:54,150
challenges that we face with those

00:10:52,440 --> 00:11:00,450
numbers that we have depicted here

00:10:54,150 --> 00:11:02,850
growing over and over so what are kind

00:11:00,450 --> 00:11:05,580
of by and large the rough categories

00:11:02,850 --> 00:11:07,380
that we see when we talk about the size

00:11:05,580 --> 00:11:10,380
of a single foundation where are the

00:11:07,380 --> 00:11:12,960
challenges there so first of all and

00:11:10,380 --> 00:11:15,450
you've seen like the number of CPUs that

00:11:12,960 --> 00:11:17,880
we have which you can then roughly

00:11:15,450 --> 00:11:20,940
translate to the number of virtual

00:11:17,880 --> 00:11:23,730
machines that are running their reality

00:11:20,940 --> 00:11:27,960
is obviously creating and deleting

00:11:23,730 --> 00:11:30,840
virtual machines just takes time and the

00:11:27,960 --> 00:11:33,960
way how much does updates today

00:11:30,840 --> 00:11:35,640
obviously means that you request the

00:11:33,960 --> 00:11:38,670
infrastructure layer to create a set of

00:11:35,640 --> 00:11:40,500
virtual machines which then depending on

00:11:38,670 --> 00:11:42,780
the underlying infrastructure takes a

00:11:40,500 --> 00:11:46,380
couple of minutes then you bring the

00:11:42,780 --> 00:11:48,360
software on you retire the old virtual

00:11:46,380 --> 00:11:50,550
machines and then you do that in in a

00:11:48,360 --> 00:11:54,300
rolling update fashion and those updates

00:11:50,550 --> 00:11:56,400
updates really take their time and we

00:11:54,300 --> 00:11:59,580
are talking about multiple days

00:11:56,400 --> 00:12:01,470
ultimately until a system is fully

00:11:59,580 --> 00:12:05,640
updated so that that is one challenge

00:12:01,470 --> 00:12:07,680
that that we are facing and that's the

00:12:05,640 --> 00:12:11,400
result of the sheer size of the

00:12:07,680 --> 00:12:13,250
deployments that we run the other area

00:12:11,400 --> 00:12:15,150
where we are facing challenges is

00:12:13,250 --> 00:12:17,540
sustainability of cloud foundry

00:12:15,150 --> 00:12:20,970
components themselves and we've just

00:12:17,540 --> 00:12:23,850
provided here again some rough headlines

00:12:20,970 --> 00:12:26,550
around things we have seen while while

00:12:23,850 --> 00:12:31,530
scaling up our landscapes so one fact

00:12:26,550 --> 00:12:34,410
factor that's majorly influencing the

00:12:31,530 --> 00:12:37,530
topic of scalability is the KPI of

00:12:34,410 --> 00:12:41,070
number of iego cells so based on the

00:12:37,530 --> 00:12:43,770
number of iego cells you'll see some

00:12:41,070 --> 00:12:46,290
some interesting effects if you scale

00:12:43,770 --> 00:12:48,390
that up and up and consequently

00:12:46,290 --> 00:12:50,970
obviously like with the number of Devo

00:12:48,390 --> 00:12:52,530
cells that that to increase you'll also

00:12:50,970 --> 00:12:54,690
increase the number of application

00:12:52,530 --> 00:12:57,120
instances that are running on on those

00:12:54,690 --> 00:12:59,700
teamkill cells and and sometimes we see

00:12:57,120 --> 00:13:01,800
effects where it's it's really the sheer

00:12:59,700 --> 00:13:03,390
number of application instances that

00:13:01,800 --> 00:13:06,900
that makes a difference in them

00:13:03,390 --> 00:13:09,810
ultimately if you scale that further and

00:13:06,900 --> 00:13:12,450
further will relate to to outage

00:13:09,810 --> 00:13:14,250
situations on on the landscapes but but

00:13:12,450 --> 00:13:16,620
sometimes we've also really seen the

00:13:14,250 --> 00:13:19,350
number of table cells factoring in into

00:13:16,620 --> 00:13:21,720
a certain calculation and then by

00:13:19,350 --> 00:13:23,310
experience you learn like this is the

00:13:21,720 --> 00:13:25,260
number of table cells that you can

00:13:23,310 --> 00:13:27,720
safely run and as soon as you hit that

00:13:25,260 --> 00:13:30,330
number you need to figure out what to do

00:13:27,720 --> 00:13:33,480
next essentially and and we will see

00:13:30,330 --> 00:13:35,450
later on in the slides one kind of

00:13:33,480 --> 00:13:38,190
countermeasure that we have taken to

00:13:35,450 --> 00:13:41,370
counter the growing number of Eagle

00:13:38,190 --> 00:13:44,160
cells the other area that we have seen

00:13:41,370 --> 00:13:45,870
is in the area of cloud controller I

00:13:44,160 --> 00:13:48,180
would say cloud controller in general

00:13:45,870 --> 00:13:50,550
but then specifically how cloud

00:13:48,180 --> 00:13:52,950
controller talks to the underlying

00:13:50,550 --> 00:13:55,670
database that stores the information of

00:13:52,950 --> 00:13:58,110
cloud controller and there we have seen

00:13:55,670 --> 00:14:00,780
challenges with a number of database

00:13:58,110 --> 00:14:03,660
connections towards that cloud

00:14:00,780 --> 00:14:05,520
controller database and here kind of

00:14:03,660 --> 00:14:07,080
hidden behind number of database

00:14:05,520 --> 00:14:09,330
connections is obviously also the

00:14:07,080 --> 00:14:11,130
question of how many cloud controller

00:14:09,330 --> 00:14:12,870
instances do you actually run because

00:14:11,130 --> 00:14:15,390
each of those cloud controller instances

00:14:12,870 --> 00:14:18,420
will open up their own set of database

00:14:15,390 --> 00:14:21,780
connections on them so that is a factor

00:14:18,420 --> 00:14:24,810
that we have seen we have also seen

00:14:21,780 --> 00:14:28,260
issues in in the Laura gaiter subsystem

00:14:24,810 --> 00:14:29,940
and one factor there again is like how

00:14:28,260 --> 00:14:32,520
many applications do we actually have

00:14:29,940 --> 00:14:34,470
and how much locks through those

00:14:32,520 --> 00:14:38,460
applications actually writes but then

00:14:34,470 --> 00:14:40,710
also and I guess many people running

00:14:38,460 --> 00:14:44,250
Cloud Foundry at scale have seen this as

00:14:40,710 --> 00:14:46,530
well there's also always those single

00:14:44,250 --> 00:14:48,510
applications going crazy like for

00:14:46,530 --> 00:14:51,510
example because they can't connect to

00:14:48,510 --> 00:14:54,180
their database and then they keep trying

00:14:51,510 --> 00:14:56,880
connecting to to that database but keep

00:14:54,180 --> 00:14:58,890
failing and put and the result is that

00:14:56,880 --> 00:15:01,800
you also write something like a Java

00:14:58,890 --> 00:15:04,260
stack trace in a very nice periodic

00:15:01,800 --> 00:15:06,660
rhythm every couple of milliseconds it

00:15:04,260 --> 00:15:08,550
will log and so then the question is how

00:15:06,660 --> 00:15:10,850
do you kind of make sure that that

00:15:08,550 --> 00:15:14,630
single application going crazy is not

00:15:10,850 --> 00:15:17,220
overloading the entire lore'l subsystem

00:15:14,630 --> 00:15:19,259
another aspect that we are currently

00:15:17,220 --> 00:15:22,430
King into is container networking

00:15:19,259 --> 00:15:24,899
because also there are the number of

00:15:22,430 --> 00:15:26,730
application instances and specifically

00:15:24,899 --> 00:15:30,180
in the number of application instances

00:15:26,730 --> 00:15:33,000
using container networking factors into

00:15:30,180 --> 00:15:36,600
some equations and then again there we

00:15:33,000 --> 00:15:39,000
are gaining experience around what a

00:15:36,600 --> 00:15:41,519
reasonable number of applications using

00:15:39,000 --> 00:15:43,620
container networking actually is and

00:15:41,519 --> 00:15:47,279
when the system then kind of goes

00:15:43,620 --> 00:15:51,360
critical and and starts failing CLI and

00:15:47,279 --> 00:15:54,689
tooling is another area so if you like

00:15:51,360 --> 00:15:56,519
us have thousands and thousands of cloud

00:15:54,689 --> 00:15:58,920
foundry organizations at cloud foundry

00:15:56,519 --> 00:16:01,800
spaces and service instances and

00:15:58,920 --> 00:16:04,500
applications then you will definitely

00:16:01,800 --> 00:16:07,079
also notice that certain command line

00:16:04,500 --> 00:16:09,870
interface interactions take quite a bit

00:16:07,079 --> 00:16:12,870
of time and part of the reason we have

00:16:09,870 --> 00:16:16,759
found is what I would call suboptimal

00:16:12,870 --> 00:16:19,110
sequel statements that are kind of the

00:16:16,759 --> 00:16:22,379
result of the fact that the cloud

00:16:19,110 --> 00:16:25,350
controller underneath uses a ruby based

00:16:22,379 --> 00:16:27,870
Omar metal on to generate those sequel

00:16:25,350 --> 00:16:30,839
statements unless you do something

00:16:27,870 --> 00:16:32,189
special there and that sequel statements

00:16:30,839 --> 00:16:34,860
that are generated are not always

00:16:32,189 --> 00:16:37,860
optimal or this may be also sometimes

00:16:34,860 --> 00:16:39,029
trivial things like indices which you

00:16:37,860 --> 00:16:41,670
would need to accelerate those

00:16:39,029 --> 00:16:44,579
statements are not in place so things

00:16:41,670 --> 00:16:46,680
like that but then also on and that

00:16:44,579 --> 00:16:49,379
depends on on the particular CLI command

00:16:46,680 --> 00:16:52,559
you come in situations where the CLI

00:16:49,379 --> 00:16:54,389
needs to trigger a set of cloud

00:16:52,559 --> 00:16:57,600
controller calls which then again

00:16:54,389 --> 00:16:59,939
cascade into quite a huge number of

00:16:57,600 --> 00:17:05,419
sequel statements towards the database

00:16:59,939 --> 00:17:08,069
and we've seen issues where like the CLI

00:17:05,419 --> 00:17:10,770
could also be optimized to to actually

00:17:08,069 --> 00:17:13,500
tree unless calls towards the cloud

00:17:10,770 --> 00:17:15,539
controller in in certain situations so

00:17:13,500 --> 00:17:18,390
that's an area that we have seen in the

00:17:15,539 --> 00:17:20,250
last but not least as we are running on

00:17:18,390 --> 00:17:23,549
on the big hyper scalars and the Pakeha

00:17:20,250 --> 00:17:26,429
scalars obviously know their limits and

00:17:23,549 --> 00:17:29,460
they introduce things like rate limits

00:17:26,429 --> 00:17:30,690
and and quotas to make sure that no

00:17:29,460 --> 00:17:35,039
single customer

00:17:30,690 --> 00:17:37,320
of that hyper scaler is kind of abusing

00:17:35,039 --> 00:17:41,190
the the capacity or that they've paid

00:17:37,320 --> 00:17:43,139
for we've also seen us hitting things

00:17:41,190 --> 00:17:45,419
like rate limits which means essentially

00:17:43,139 --> 00:17:47,250
the number of API calls towards the

00:17:45,419 --> 00:17:50,700
hyper scalar that you can do in a

00:17:47,250 --> 00:17:53,340
particular time unit and we've seen that

00:17:50,700 --> 00:17:55,710
in particular when when it comes to to

00:17:53,340 --> 00:17:59,039
updating our landscapes and then using

00:17:55,710 --> 00:18:03,210
gosh extensively to do that but then

00:17:59,039 --> 00:18:06,600
also guitars like how many discs can you

00:18:03,210 --> 00:18:10,799
actually have in your account what is

00:18:06,600 --> 00:18:13,110
the number of PM's of a certain size

00:18:10,799 --> 00:18:15,210
that the particular - skele can provide

00:18:13,110 --> 00:18:18,240
you in in a certain region so things

00:18:15,210 --> 00:18:21,629
like that are also factored into the

00:18:18,240 --> 00:18:24,690
overall size of a Cloud Foundry

00:18:21,629 --> 00:18:26,759
landscape and those are boundary

00:18:24,690 --> 00:18:28,110
conditions that are imposed by the

00:18:26,759 --> 00:18:32,399
particular hyperscale

00:18:28,110 --> 00:18:35,070
and then last but not least there's also

00:18:32,399 --> 00:18:37,409
unexpected behavior so like for for

00:18:35,070 --> 00:18:40,169
those kpi's up there we kind of know

00:18:37,409 --> 00:18:41,820
that there are limits and like this is

00:18:40,169 --> 00:18:45,360
what you need to watch over time and at

00:18:41,820 --> 00:18:47,340
gain experience and find ways to either

00:18:45,360 --> 00:18:49,919
work around those limits or push those

00:18:47,340 --> 00:18:52,649
limits etc etc but then there's also

00:18:49,919 --> 00:18:55,289
unexpected behavior where things looked

00:18:52,649 --> 00:18:57,470
relatively good at a certain point in

00:18:55,289 --> 00:19:00,330
time and then from a very surprising

00:18:57,470 --> 00:19:02,850
area from a component maybe that you

00:19:00,330 --> 00:19:05,789
didn't even have on the radar you

00:19:02,850 --> 00:19:08,759
essentially find out that there's some

00:19:05,789 --> 00:19:13,379
unexpected behavior exhibited and then

00:19:08,759 --> 00:19:15,629
you essentially also run in in outage

00:19:13,379 --> 00:19:18,480
situation which are obviously unpleasant

00:19:15,629 --> 00:19:20,460
because as soon as those outage

00:19:18,480 --> 00:19:22,379
situation happen on on a productive

00:19:20,460 --> 00:19:26,669
system you essentially need to react

00:19:22,379 --> 00:19:28,980
very quickly and fix whatever issue has

00:19:26,669 --> 00:19:31,679
has been created and that can be as

00:19:28,980 --> 00:19:33,330
simple as again scaling out particular

00:19:31,679 --> 00:19:36,179
components but it could also be as

00:19:33,330 --> 00:19:39,809
complicated as you need to have the fix

00:19:36,179 --> 00:19:44,070
in one of the components that make up

00:19:39,809 --> 00:19:46,710
the overall Cloud Foundry landscape so

00:19:44,070 --> 00:19:51,029
so those are roughly the areas that we

00:19:46,710 --> 00:19:54,929
have observed there then just to kind of

00:19:51,029 --> 00:19:58,080
mention one topic that as I as I said

00:19:54,929 --> 00:20:01,799
earlier we have seen a number of Diego

00:19:58,080 --> 00:20:04,739
cells is something that kind of moves

00:20:01,799 --> 00:20:07,409
Cloud Foundry foundations into a

00:20:04,739 --> 00:20:09,210
critical state so thinking through what

00:20:07,409 --> 00:20:12,499
we could do to to kind of reduce the

00:20:09,210 --> 00:20:15,090
number of gable cells and this is like

00:20:12,499 --> 00:20:17,629
something that I believe many many

00:20:15,090 --> 00:20:20,970
people coming in in those scaling limits

00:20:17,629 --> 00:20:23,099
also thinking about is can't we just

00:20:20,970 --> 00:20:25,529
have Peter Diego cells so that each

00:20:23,099 --> 00:20:28,710
Diego cell can actually host more

00:20:25,529 --> 00:20:32,399
applications and therefore we can again

00:20:28,710 --> 00:20:35,099
reduce the number of cables and here

00:20:32,399 --> 00:20:38,009
with without any like X or y-axis

00:20:35,099 --> 00:20:40,739
depicted there but but the orange system

00:20:38,009 --> 00:20:44,039
is our cannery system so our internal

00:20:40,739 --> 00:20:46,919
system that is used by SAV teams to

00:20:44,039 --> 00:20:51,859
develop their applications and then the

00:20:46,919 --> 00:20:54,809
gray line down there is our European

00:20:51,859 --> 00:20:57,690
deployment of our biggest foundation

00:20:54,809 --> 00:21:01,200
there and you essentially see the number

00:20:57,690 --> 00:21:03,019
of cables steadily growing until the

00:21:01,200 --> 00:21:05,759
point in time where we said okay let's

00:21:03,019 --> 00:21:07,379
double the number of CPUs let's double

00:21:05,759 --> 00:21:11,059
the number of RAM that each of those

00:21:07,379 --> 00:21:14,849
table cells has and then essentially you

00:21:11,059 --> 00:21:16,609
you can see the number of table cells

00:21:14,849 --> 00:21:19,950
dropping down again but then obviously

00:21:16,609 --> 00:21:23,159
as usage continues to grow or you also

00:21:19,950 --> 00:21:25,080
see that like on this particular

00:21:23,159 --> 00:21:27,720
maneuver has its limits and so the

00:21:25,080 --> 00:21:30,149
question is what the next step will be

00:21:27,720 --> 00:21:33,720
once we hit again those those upper

00:21:30,149 --> 00:21:35,570
limits that we have perceived so far so

00:21:33,720 --> 00:21:38,009
that's one kind of concrete

00:21:35,570 --> 00:21:40,259
countermeasure or you could also call it

00:21:38,009 --> 00:21:43,499
a workaround you essentially work

00:21:40,259 --> 00:21:52,019
against some of the scaling limits that

00:21:43,499 --> 00:21:54,269
at least we have seen so there like you

00:21:52,019 --> 00:21:56,770
also come into a more substantial

00:21:54,269 --> 00:21:58,360
substantial conversation around one

00:21:56,770 --> 00:22:02,710
are the options that you actually have

00:21:58,360 --> 00:22:06,340
to basically scale up such a Cloud

00:22:02,710 --> 00:22:09,190
Foundry deployment overall so assume

00:22:06,340 --> 00:22:12,460
that you have Cloud Foundry one single

00:22:09,190 --> 00:22:14,940
foundation running in a region and then

00:22:12,460 --> 00:22:17,770
obviously as I also mentioned before

00:22:14,940 --> 00:22:20,500
there's a certain set of measures that

00:22:17,770 --> 00:22:23,170
you can do to extend the limits of that

00:22:20,500 --> 00:22:26,020
single Cloud Foundry foundation and then

00:22:23,170 --> 00:22:28,780
one of the short-term measures we've

00:22:26,020 --> 00:22:31,270
just seen on the previous slide or just

00:22:28,780 --> 00:22:33,820
double the size of the Diigo cells and

00:22:31,270 --> 00:22:36,190
therefore buy some time until you again

00:22:33,820 --> 00:22:39,490
it's that critical number of the able

00:22:36,190 --> 00:22:42,070
cells in a single or foundation so this

00:22:39,490 --> 00:22:45,520
is something that we definitely do then

00:22:42,070 --> 00:22:49,240
doing synthetic scalability tests is

00:22:45,520 --> 00:22:51,610
another area that we are intensively

00:22:49,240 --> 00:22:53,020
working on and there will be a follow-up

00:22:51,610 --> 00:22:56,670
slideshow to talk a little bit more

00:22:53,020 --> 00:23:00,670
about that then obviously Cloud Foundry

00:22:56,670 --> 00:23:02,970
has a functionality called isolation

00:23:00,670 --> 00:23:06,130
segments which essentially allows you to

00:23:02,970 --> 00:23:09,720
slice a single Cloud Foundry foundation

00:23:06,130 --> 00:23:12,970
into pieces and and those pieces are

00:23:09,720 --> 00:23:15,310
independent so for example when it comes

00:23:12,970 --> 00:23:18,340
to to Diego cells so each of those

00:23:15,310 --> 00:23:20,410
isolation segments has an own set of

00:23:18,340 --> 00:23:22,720
table cells that are associated to it

00:23:20,410 --> 00:23:24,970
that's the smallest version of an

00:23:22,720 --> 00:23:27,460
isolation segment or the slightly bigger

00:23:24,970 --> 00:23:30,070
version of an isolation segment also can

00:23:27,460 --> 00:23:32,710
isolate things like the interest to the

00:23:30,070 --> 00:23:36,160
system so components like for example

00:23:32,710 --> 00:23:40,900
the the go router or can also be sliced

00:23:36,160 --> 00:23:43,780
into one or more smaller deployments and

00:23:40,900 --> 00:23:45,730
therefore some of those critical numbers

00:23:43,780 --> 00:23:48,150
when it comes to number of cells

00:23:45,730 --> 00:23:50,650
for example you can counter by

00:23:48,150 --> 00:23:52,900
introducing those isolation segments on

00:23:50,650 --> 00:23:57,070
the other hand the isolation segments

00:23:52,900 --> 00:23:59,260
still have a set of common components so

00:23:57,070 --> 00:24:02,050
things like for example cloud controller

00:23:59,260 --> 00:24:05,200
or also the local Gator are components

00:24:02,050 --> 00:24:07,390
that are still considered central or for

00:24:05,200 --> 00:24:09,790
isolation segments which means you

00:24:07,390 --> 00:24:10,160
cannot slice those and if you hit limits

00:24:09,790 --> 00:24:12,800
on

00:24:10,160 --> 00:24:15,200
those components than isolation segments

00:24:12,800 --> 00:24:17,990
are are not a means to to to counter

00:24:15,200 --> 00:24:20,780
those limits ultimately and then last

00:24:17,990 --> 00:24:23,510
but not least and this is because it's

00:24:20,780 --> 00:24:28,010
open source this is the way you should

00:24:23,510 --> 00:24:30,350
be doing things we are also active in in

00:24:28,010 --> 00:24:34,310
terms of pushing the scaling limits of

00:24:30,350 --> 00:24:38,540
individual components and that obviously

00:24:34,310 --> 00:24:42,110
also has a set of ways how you can

00:24:38,540 --> 00:24:43,790
achieve that so even if you don't know

00:24:42,110 --> 00:24:45,500
the ins and outs of a particular

00:24:43,790 --> 00:24:47,690
component one thing that you can

00:24:45,500 --> 00:24:50,990
definitely do is talk to the

00:24:47,690 --> 00:24:56,240
corresponding PM of that component the

00:24:50,990 --> 00:24:58,670
open source and make people aware of the

00:24:56,240 --> 00:25:01,010
issues that you have perceived that you

00:24:58,670 --> 00:25:03,950
have seen in in scaling a particular

00:25:01,010 --> 00:25:06,890
component and we have done that for for

00:25:03,950 --> 00:25:10,040
a set up of cloud foundry components and

00:25:06,890 --> 00:25:14,750
we keep updating the PM's of those

00:25:10,040 --> 00:25:16,730
components as we find new or as we

00:25:14,750 --> 00:25:19,130
uncover new findings for for those

00:25:16,730 --> 00:25:21,560
components but but then also and this is

00:25:19,130 --> 00:25:24,560
obviously in particular relevant if you

00:25:21,560 --> 00:25:27,290
know the coding of a component you can

00:25:24,560 --> 00:25:29,960
go in and obviously also file your own

00:25:27,290 --> 00:25:32,720
pull requests make things better work

00:25:29,960 --> 00:25:35,390
against those scaling limits by by

00:25:32,720 --> 00:25:39,920
putting in fixes and and then ultimately

00:25:35,390 --> 00:25:42,440
and this is why the second set of

00:25:39,920 --> 00:25:45,050
measures ultimately you will you'll find

00:25:42,440 --> 00:25:47,150
that each and every component has its

00:25:45,050 --> 00:25:50,630
architectural limits and once you get

00:25:47,150 --> 00:25:52,900
those then III guess you are essentially

00:25:50,630 --> 00:25:57,110
up for a major rewrite of that component

00:25:52,900 --> 00:25:59,090
unless you have other means and the

00:25:57,110 --> 00:26:02,450
other means that we are also actively

00:25:59,090 --> 00:26:05,000
looking into is scaling up an individual

00:26:02,450 --> 00:26:10,490
region by putting in you Cloud Foundry

00:26:05,000 --> 00:26:12,920
foundations into that region that again

00:26:10,490 --> 00:26:15,680
has an own set of challenges because at

00:26:12,920 --> 00:26:18,160
least we need to make sure that each of

00:26:15,680 --> 00:26:21,380
those Cloud Foundry foundations

00:26:18,160 --> 00:26:22,250
essentially has the same set of services

00:26:21,380 --> 00:26:24,770
in in the

00:26:22,250 --> 00:26:27,590
I'll controller service catalog so that

00:26:24,770 --> 00:26:30,770
is at least one topic that we are

00:26:27,590 --> 00:26:32,990
actively looking into and where we have

00:26:30,770 --> 00:26:35,990
with the open source component called

00:26:32,990 --> 00:26:39,110
therapy or also oftentimes referred to

00:26:35,990 --> 00:26:41,660
as service manager a means to quote

00:26:39,110 --> 00:26:43,430
unquote distributes this catalogs across

00:26:41,660 --> 00:26:46,130
multiple foundations so this is

00:26:43,430 --> 00:26:49,010
something that we are working on but

00:26:46,130 --> 00:26:51,170
then also we have things like a common

00:26:49,010 --> 00:26:55,730
user interface that we call the cloud

00:26:51,170 --> 00:26:57,500
cockpit for all the users of our city

00:26:55,730 --> 00:27:02,980
cloud platform Cloud Foundry offering

00:26:57,500 --> 00:27:19,539
and their one challenge is to

00:27:02,980 --> 00:27:23,019
point each user to be found they chance

00:27:19,539 --> 00:27:25,239
has an own disunited about for Colusa

00:27:23,019 --> 00:27:28,600
that is just locked in what is the end

00:27:25,239 --> 00:27:31,059
point that on the seasons to needs to to

00:27:28,600 --> 00:27:33,999
work against so that's one topic and

00:27:31,059 --> 00:27:35,769
then ultimately if you say let's go down

00:27:33,999 --> 00:27:38,679
the road of having multiple Cloud

00:27:35,769 --> 00:27:40,749
Foundry foundations in one region the

00:27:38,679 --> 00:27:42,879
most extreme form of that is to say

00:27:40,749 --> 00:27:45,519
let's just give every customer and own

00:27:42,879 --> 00:27:47,799
Cloud Foundry employment and this is

00:27:45,519 --> 00:27:51,730
essentially where one of the open source

00:27:47,799 --> 00:27:54,549
projects that we have originally kicked

00:27:51,730 --> 00:27:56,830
off - together with with IBM and Sousa

00:27:54,549 --> 00:28:00,549
comes in so that's the really neat

00:27:56,830 --> 00:28:02,950
project that was also talked about quite

00:28:00,549 --> 00:28:05,499
a bit during or the last two Cloud

00:28:02,950 --> 00:28:08,259
Foundry summit so essentially that idea

00:28:05,499 --> 00:28:10,899
of saying can we deploy cloud foundry

00:28:08,259 --> 00:28:14,379
not on virtual machines but instead on

00:28:10,899 --> 00:28:17,440
top of of kubernetes and that has I

00:28:14,379 --> 00:28:19,899
guess a set of benefits that we don't

00:28:17,440 --> 00:28:23,609
have the time to go into in this

00:28:19,899 --> 00:28:26,649
presentation but but one benefit is that

00:28:23,609 --> 00:28:31,210
by having kubernetes as an additional

00:28:26,649 --> 00:28:32,859
scaling layer you essentially have a

00:28:31,210 --> 00:28:35,710
more lightweight cloud foundry

00:28:32,859 --> 00:28:37,720
deployment - to basically run now

00:28:35,710 --> 00:28:40,929
obviously by putting Cloud Foundry on

00:28:37,720 --> 00:28:43,330
top of kubernetes you buy yourself some

00:28:40,929 --> 00:28:46,389
new challenges which is then you need to

00:28:43,330 --> 00:28:51,059
manage kubernetes clusters and usually

00:28:46,389 --> 00:28:55,029
you would say if you have multiple

00:28:51,059 --> 00:28:59,859
customers then basically you also need

00:28:55,029 --> 00:29:02,139
to have multiple kubernetes deployments

00:28:59,859 --> 00:29:06,100
all kubernetes clusters for those

00:29:02,139 --> 00:29:08,529
multiple customers so there's always a

00:29:06,100 --> 00:29:11,289
trade-off obviously and then this is

00:29:08,529 --> 00:29:15,350
something that we are also actively

00:29:11,289 --> 00:29:17,720
exploring at the moment so

00:29:15,350 --> 00:29:20,960
then I I already mentioned that we are

00:29:17,720 --> 00:29:24,170
running from synthetic scalability tests

00:29:20,960 --> 00:29:27,470
and this is kind of a rough picture of

00:29:24,170 --> 00:29:32,320
what we have done in in in that area so

00:29:27,470 --> 00:29:35,780
we we have set up a project that

00:29:32,320 --> 00:29:37,760
essentially had the purpose to say we

00:29:35,780 --> 00:29:41,900
know how big our biggest Cloud Foundry

00:29:37,760 --> 00:29:44,030
foundations are today but in terms of

00:29:41,900 --> 00:29:46,670
scaling we don't want to see issues only

00:29:44,030 --> 00:29:50,090
once we update those Cloud Foundry

00:29:46,670 --> 00:29:52,340
foundations to a new version but we want

00:29:50,090 --> 00:29:54,890
to kind of get a preview of the issues

00:29:52,340 --> 00:29:57,980
that we are seeing so we need to have an

00:29:54,890 --> 00:30:02,150
own what we call scaling landscape or

00:29:57,980 --> 00:30:03,800
scaling foundation that kind of gives us

00:30:02,150 --> 00:30:06,620
that revenue and that we run

00:30:03,800 --> 00:30:10,790
independently from our productive

00:30:06,620 --> 00:30:13,640
deployments we started by saying let's

00:30:10,790 --> 00:30:15,980
take our cannery system so essentially

00:30:13,640 --> 00:30:19,130
our our biggest system that's used as a

00:30:15,980 --> 00:30:21,950
key internally as a baseline as a

00:30:19,130 --> 00:30:24,440
baseline in terms of like certain KPIs

00:30:21,950 --> 00:30:26,780
like how many TiVo cells to be run how

00:30:24,440 --> 00:30:29,690
many application instances are are we

00:30:26,780 --> 00:30:33,700
running we use that baseline to then

00:30:29,690 --> 00:30:37,370
exercise an update process because as

00:30:33,700 --> 00:30:40,790
I've also mentioned in one of the

00:30:37,370 --> 00:30:44,120
previous slides update processes update

00:30:40,790 --> 00:30:46,430
procedures are one major source of

00:30:44,120 --> 00:30:50,810
issues when it comes to to running big

00:30:46,430 --> 00:30:53,770
Cloud Foundry foundation so by by

00:30:50,810 --> 00:30:56,930
updating on that baseline system

00:30:53,770 --> 00:31:00,350
bringing in a new version we gained

00:30:56,930 --> 00:31:03,290
experience regarding the issues that we

00:31:00,350 --> 00:31:05,750
were facing during that update we can

00:31:03,290 --> 00:31:08,330
say that today this system has twice the

00:31:05,750 --> 00:31:10,850
size of our calorie landscape which as I

00:31:08,330 --> 00:31:14,000
said was so far or the biggest landscape

00:31:10,850 --> 00:31:16,460
that we were running so by by running

00:31:14,000 --> 00:31:18,920
twice the size of that Kanuri landscape

00:31:16,460 --> 00:31:21,890
we obviously want to want to create some

00:31:18,920 --> 00:31:25,120
wiggle room for us to say okay this is

00:31:21,890 --> 00:31:28,590
how far we can scale a single foundation

00:31:25,120 --> 00:31:30,750
kind of knowing everything that

00:31:28,590 --> 00:31:32,909
from from those scalability tests and

00:31:30,750 --> 00:31:35,640
then the next step that we want to do

00:31:32,909 --> 00:31:37,980
once we have tackled the issues that

00:31:35,640 --> 00:31:41,549
came out of running the landscape in

00:31:37,980 --> 00:31:45,120
that size is we want to go beyond triple

00:31:41,549 --> 00:31:47,279
the size of our Camry landscape so

00:31:45,120 --> 00:31:51,020
that's like roughly what we do in in

00:31:47,279 --> 00:31:54,179
terms of synthetic scalability tests and

00:31:51,020 --> 00:31:56,880
then last but not least and this is this

00:31:54,179 --> 00:32:00,720
is indeed the last side of the

00:31:56,880 --> 00:32:03,210
presentation also a bit of kind of

00:32:00,720 --> 00:32:06,539
insights into what we found during those

00:32:03,210 --> 00:32:09,270
synthetic scalability tests and for two

00:32:06,539 --> 00:32:12,600
of those issues I've also leaked the

00:32:09,270 --> 00:32:17,100
corresponding github issues that we have

00:32:12,600 --> 00:32:19,289
created on so similar to to what I

00:32:17,100 --> 00:32:21,330
mentioned earlier we've seen issues in

00:32:19,289 --> 00:32:25,100
that scaling landscape in in a couple of

00:32:21,330 --> 00:32:29,130
areas so one is wash or kind of update

00:32:25,100 --> 00:32:32,159
processes in in general we've seen time

00:32:29,130 --> 00:32:34,679
outs especially when we were recreating

00:32:32,159 --> 00:32:39,179
many instances in in parallel and

00:32:34,679 --> 00:32:42,200
there's a github issue that where our

00:32:39,179 --> 00:32:46,559
Bosh team our open source Porsche team

00:32:42,200 --> 00:32:49,140
that is also on co-located on here in in

00:32:46,559 --> 00:32:52,080
Waldorf and our headquarters actually

00:32:49,140 --> 00:32:57,029
worked on fixing that particular issue

00:32:52,080 --> 00:32:59,010
so we obviously make sure that we bring

00:32:57,029 --> 00:33:01,830
those fixed this back into the open

00:32:59,010 --> 00:33:05,760
source and then and I think that has

00:33:01,830 --> 00:33:07,559
also been mentioned by the people from

00:33:05,760 --> 00:33:10,890
Taylor cromlech during the Cloud Foundry

00:33:07,559 --> 00:33:15,270
summit in Philadelphia we keep looking

00:33:10,890 --> 00:33:16,919
into the topic of no-ops when doing a

00:33:15,270 --> 00:33:18,779
BAS deploy so essentially Bosch

00:33:16,919 --> 00:33:21,120
ultimately finds out there's actually

00:33:18,779 --> 00:33:23,880
nothing to change like there's no new

00:33:21,120 --> 00:33:26,039
versions no new VMs need to be created

00:33:23,880 --> 00:33:29,190
no old be absolute to be deleted but

00:33:26,039 --> 00:33:33,149
you're waiting X amount of minutes for

00:33:29,190 --> 00:33:36,720
Bosch to actually figure that out our

00:33:33,149 --> 00:33:38,600
Bosch team is still looking into the

00:33:36,720 --> 00:33:41,940
topic and I believe free we already

00:33:38,600 --> 00:33:44,759
contributed some optimizations upstream

00:33:41,940 --> 00:33:48,269
still that X in X number of minutes is

00:33:44,759 --> 00:33:49,889
quite big so the team keeps looking into

00:33:48,269 --> 00:33:52,559
that topic and it has a couple of ideas

00:33:49,889 --> 00:33:55,080
on on how to improve that that even

00:33:52,559 --> 00:33:57,480
further on the other hand there's also

00:33:55,080 --> 00:34:01,490
the workaround obviously to say let's

00:33:57,480 --> 00:34:04,860
split the Bosch deployment that makes up

00:34:01,490 --> 00:34:07,080
the digo cells into multiple deployments

00:34:04,860 --> 00:34:10,349
so there we've essentially started by

00:34:07,080 --> 00:34:12,270
splitting CF deployment into two one

00:34:10,349 --> 00:34:14,280
Bush deployment that is updating the

00:34:12,270 --> 00:34:16,260
Cloud Foundry control plane and then

00:34:14,280 --> 00:34:18,659
another boss deployment that is updating

00:34:16,260 --> 00:34:20,790
all the geocells the next step that we

00:34:18,659 --> 00:34:23,010
want to look into there is splitting

00:34:20,790 --> 00:34:26,790
that wash deployment containing all the

00:34:23,010 --> 00:34:30,510
Diego cells further into reasonably

00:34:26,790 --> 00:34:33,000
sized chunks so that basically each of

00:34:30,510 --> 00:34:36,270
those chunks can can be updated in a

00:34:33,000 --> 00:34:40,280
much smaller time so that's something

00:34:36,270 --> 00:34:43,020
that that we are currently looking into

00:34:40,280 --> 00:34:46,589
looking into into scaling Cloud Foundry

00:34:43,020 --> 00:34:49,139
things that we've seen there is gable

00:34:46,589 --> 00:34:52,500
drain scripts that essentially never end

00:34:49,139 --> 00:34:55,740
um where ultimately Bush had to or

00:34:52,500 --> 00:34:58,079
forcefully shut down the Diego cells

00:34:55,740 --> 00:35:01,619
with those hanging drain strips and

00:34:58,079 --> 00:35:04,740
there's another github issue related to

00:35:01,619 --> 00:35:07,560
to that and then we have seen and this

00:35:04,740 --> 00:35:09,210
is just one example and we could name

00:35:07,560 --> 00:35:12,839
name a couple of more there as well

00:35:09,210 --> 00:35:15,150
we've seen the Diego scheduler using

00:35:12,839 --> 00:35:17,640
more CPU cycles than were actually

00:35:15,150 --> 00:35:19,650
available on on the VMS that we deployed

00:35:17,640 --> 00:35:22,560
to so one countermeasure there's

00:35:19,650 --> 00:35:25,619
obviously calling quote just by day or

00:35:22,560 --> 00:35:28,829
virtual machines and make sure that the

00:35:25,619 --> 00:35:32,119
Diego scheduler has more CPU cycles free

00:35:28,829 --> 00:35:35,760
to do its job and then under general

00:35:32,119 --> 00:35:38,040
like there's a set of other Cloud

00:35:35,760 --> 00:35:41,099
Foundry components or one component

00:35:38,040 --> 00:35:43,440
that's actually not part of CF

00:35:41,099 --> 00:35:43,920
deployment but is still part of the open

00:35:43,440 --> 00:35:47,160
source

00:35:43,920 --> 00:35:52,140
ETH a proxy which exists in in the form

00:35:47,160 --> 00:35:54,119
of an H a proxy Bush release when we

00:35:52,140 --> 00:35:55,950
were putting load on the system and in

00:35:54,119 --> 00:35:58,319
that particular case load in terms of

00:35:55,950 --> 00:36:00,660
number of requests that are calling from

00:35:58,319 --> 00:36:03,300
old foundry applications then we have

00:36:00,660 --> 00:36:06,750
seen certain situations where we needed

00:36:03,300 --> 00:36:09,720
to scale our age a proxy wash deployment

00:36:06,750 --> 00:36:13,020
and scaling meant scaling on various

00:36:09,720 --> 00:36:15,270
angles like disk sizes again size of the

00:36:13,020 --> 00:36:18,060
virtual machines etcetera etcetera so

00:36:15,270 --> 00:36:22,470
that's something interesting to to look

00:36:18,060 --> 00:36:25,619
into our monitoring of those system

00:36:22,470 --> 00:36:27,839
landscapes also at times couldn't cope

00:36:25,619 --> 00:36:29,849
with the number of metrics and the

00:36:27,839 --> 00:36:32,910
frequency of metrics that were reported

00:36:29,849 --> 00:36:34,859
by all the underlying Cloud Foundry

00:36:32,910 --> 00:36:37,140
components so we had to scale that up

00:36:34,859 --> 00:36:39,869
and then last but not least as I

00:36:37,140 --> 00:36:42,140
mentioned scaling the local Gaeta

00:36:39,869 --> 00:36:45,569
infrastructure depending on the load

00:36:42,140 --> 00:36:49,890
that's put on it by the cloud foundry

00:36:45,569 --> 00:36:53,910
applications that are running there so

00:36:49,890 --> 00:36:56,310
with that that kind of completes the

00:36:53,910 --> 00:36:59,069
tool of scaling cloud foundry and in

00:36:56,310 --> 00:37:02,310
terms of trying to summarize our

00:36:59,069 --> 00:37:04,770
experience with with the topic therefore

00:37:02,310 --> 00:37:08,550
we were also very happy to hear during

00:37:04,770 --> 00:37:10,829
the last summit in Philadelphia that

00:37:08,550 --> 00:37:13,339
there's more companies that are starting

00:37:10,829 --> 00:37:17,550
to see those those scaling challenges

00:37:13,339 --> 00:37:20,760
which is also I think good reason to

00:37:17,550 --> 00:37:22,339
continue exchanging information on the

00:37:20,760 --> 00:37:25,619
select channel that has been

00:37:22,339 --> 00:37:27,780
specifically created for people that are

00:37:25,619 --> 00:37:31,859
interested in in the scaling topic of

00:37:27,780 --> 00:37:34,349
all with that that's the end of the

00:37:31,859 --> 00:37:36,500
presentation I would open it up for for

00:37:34,349 --> 00:37:36,500
questions

00:37:39,380 --> 00:37:41,440
you

00:37:54,720 --> 00:38:01,359
that doesn't seem to be any so I guess

00:37:58,150 --> 00:38:05,950
going back back to you yeah thanks burn

00:38:01,359 --> 00:38:08,170
yeah very good presentation yeah so if

00:38:05,950 --> 00:38:10,630
there are no other questions maybe if we

00:38:08,170 --> 00:38:14,560
can jump into the the second topic it's

00:38:10,630 --> 00:38:22,210
more of an open discussion if our own in

00:38:14,560 --> 00:38:25,690
the call so I don't think so I find him

00:38:22,210 --> 00:38:28,869
so there's a topic from our own so

00:38:25,690 --> 00:38:30,849
basically about so thoughts on

00:38:28,869 --> 00:38:34,690
leveraging encrypted certificates for

00:38:30,849 --> 00:38:37,900
Caracas in general yeah so if someone

00:38:34,690 --> 00:38:40,119
have any pointers some thoughts on this

00:38:37,900 --> 00:38:53,140
topic so maybe yeah we can start discuss

00:38:40,119 --> 00:38:54,579
on this topic we'll jump in and my

00:38:53,140 --> 00:38:58,750
name's Richard I work at gov dot uk'

00:38:54,579 --> 00:39:01,900
Pass we use less encrypts for a lot of

00:38:58,750 --> 00:39:05,680
our production services we don't do the

00:39:01,900 --> 00:39:07,660
month ago roots level we do them is it

00:39:05,680 --> 00:39:10,390
yeah it's on a cloud from instance so we

00:39:07,660 --> 00:39:12,520
put cloud from in front of an Amazon ELB

00:39:10,390 --> 00:39:14,050
which is in front of an H a proxy which

00:39:12,520 --> 00:39:16,390
is in front of galleries and so there

00:39:14,050 --> 00:39:17,800
are less encrypt certs in our case but

00:39:16,390 --> 00:39:20,290
they managed quite a long way away from

00:39:17,800 --> 00:39:22,510
the Darius's and I'm not sure if we

00:39:20,290 --> 00:39:23,800
expose Garuda's directly I think we'd

00:39:22,510 --> 00:39:25,569
always put some kind of load balancer

00:39:23,800 --> 00:39:27,369
and from I'm not sure if that's exactly

00:39:25,569 --> 00:39:30,520
the idea that Aaron was raising they

00:39:27,369 --> 00:39:32,650
different team well I think like our

00:39:30,520 --> 00:39:36,300
experiences of trying to automate let's

00:39:32,650 --> 00:39:40,210
encrypt is it surprisingly difficult um

00:39:36,300 --> 00:39:42,040
like we've seen a whole bunch of failing

00:39:40,210 --> 00:39:43,780
cases where like a lot of the libraries

00:39:42,040 --> 00:39:47,680
for interacting with there aren't really

00:39:43,780 --> 00:39:49,869
designed to be worn in there like server

00:39:47,680 --> 00:39:54,819
fashion they're kind of written to be

00:39:49,869 --> 00:40:00,220
one by hand I guess like you totally

00:39:54,819 --> 00:40:03,520
could do it but like again if you

00:40:00,220 --> 00:40:05,109
no search to go back to itself I guess

00:40:03,520 --> 00:40:07,270
you then go back to why aren't you using

00:40:05,109 --> 00:40:10,900
a low balance of giving it to those like

00:40:07,270 --> 00:40:23,440
I wish I was around to explain exactly

00:40:10,900 --> 00:40:26,680
what he was after Dora said it might be

00:40:23,440 --> 00:40:28,930
worth reaching out to Aaron and see what

00:40:26,680 --> 00:40:31,119
exactly he was trying to get or what

00:40:28,930 --> 00:40:32,830
exactly it was his fashion so that the

00:40:31,119 --> 00:40:36,310
folks from the government UK

00:40:32,830 --> 00:40:38,619
richer in Mikey can maybe have a slight

00:40:36,310 --> 00:40:40,300
fall of slack discussion yeah sure a

00:40:38,619 --> 00:40:43,030
little pinged him unfortunately he's not

00:40:40,300 --> 00:40:45,280
there online so maybe yeah so I can

00:40:43,030 --> 00:40:48,040
think you offline and then sick so what

00:40:45,280 --> 00:40:57,940
exactly he was trained to look into it

00:40:48,040 --> 00:41:01,390
yeah yeah sure yeah so then the next

00:40:57,940 --> 00:41:04,480
stop he could be so basically we put

00:41:01,390 --> 00:41:08,410
this topic so we wanted to understand in

00:41:04,480 --> 00:41:09,910
general so how the availability of the

00:41:08,410 --> 00:41:13,680
cloud foundry platform is being measured

00:41:09,910 --> 00:41:15,940
so what all the factors in general

00:41:13,680 --> 00:41:20,530
should be considered so when you see a

00:41:15,940 --> 00:41:22,690
cloud platform availability so also I

00:41:20,530 --> 00:41:25,869
got some feedback from the community

00:41:22,690 --> 00:41:27,250
itself so let's say someone now so if

00:41:25,869 --> 00:41:29,380
you are measuring the platform

00:41:27,250 --> 00:41:32,050
availability so in general they will

00:41:29,380 --> 00:41:33,880
measure relative a PA uptime and then

00:41:32,050 --> 00:41:36,339
the staging availability which if you

00:41:33,880 --> 00:41:38,560
are using any services which you are

00:41:36,339 --> 00:41:40,180
able to bind to the telephone tree

00:41:38,560 --> 00:41:42,760
applications and then let's say the

00:41:40,180 --> 00:41:44,650
broker availability app availability so

00:41:42,760 --> 00:41:47,920
this how the most things most of the

00:41:44,650 --> 00:41:50,310
most important things in general anyone

00:41:47,920 --> 00:41:53,080
who is running the crowdfunding platform

00:41:50,310 --> 00:41:56,530
will measure it here so apart from this

00:41:53,080 --> 00:41:59,020
so anyone thinks are there any other

00:41:56,530 --> 00:42:01,920
important metrics okay which we should

00:41:59,020 --> 00:42:05,650
consider when you see the platform

00:42:01,920 --> 00:42:09,119
foundry platform availability yes maybe

00:42:05,650 --> 00:42:09,119
some inputs on this one

00:42:23,800 --> 00:42:34,480
I will dump in again just that just to

00:42:33,070 --> 00:42:40,090
say that we don't think we're very good

00:42:34,480 --> 00:42:42,430
at this we have what we'd like to say to

00:42:40,090 --> 00:42:45,030
our users is that we have like have an

00:42:42,430 --> 00:42:49,690
uptime service level agreement of say

00:42:45,030 --> 00:42:52,600
99.99% and some places we do say that

00:42:49,690 --> 00:42:54,340
but we don't exactly know we mean by it

00:42:52,600 --> 00:42:57,400
so we attempt to monitor application

00:42:54,340 --> 00:43:00,220
uptime basically by pinging some apps

00:42:57,400 --> 00:43:02,740
and seeing if L we also attempt to

00:43:00,220 --> 00:43:05,980
measure APR a P I uptime by pinging the

00:43:02,740 --> 00:43:07,510
API and seeing if that's up but a lot of

00:43:05,980 --> 00:43:08,980
the platform could be broken in a way

00:43:07,510 --> 00:43:10,390
that our users would not be happy with

00:43:08,980 --> 00:43:11,740
and those metrics would still be a

00:43:10,390 --> 00:43:13,150
hundred percent so for example the

00:43:11,740 --> 00:43:15,100
entire logging pipeline could be broken

00:43:13,150 --> 00:43:17,110
and our metrics would still so

00:43:15,100 --> 00:43:19,000
everything's up could be unable to push

00:43:17,110 --> 00:43:21,010
an app and our metrics would still say

00:43:19,000 --> 00:43:22,900
yeah everything was up because they

00:43:21,010 --> 00:43:25,060
don't actually touch that bit of the API

00:43:22,900 --> 00:43:29,260
and so it's something that we're looking

00:43:25,060 --> 00:43:31,720
at we have not got any easy answers yet

00:43:29,260 --> 00:43:37,060
yeah I'd say like one of the really

00:43:31,720 --> 00:43:39,310
messy points is like so we provide like

00:43:37,060 --> 00:43:43,380
post quest databases and things tenants

00:43:39,310 --> 00:43:45,640
so obviously like a real-time of that is

00:43:43,380 --> 00:43:49,270
completely variable depending on each

00:43:45,640 --> 00:43:52,170
instance we have like no ideas on how to

00:43:49,270 --> 00:44:03,190
wire to all of those in in the way it's

00:43:52,170 --> 00:44:05,950
it's difficult we'd love ideas okay so

00:44:03,190 --> 00:44:09,840
that's our new button Thanks this is

00:44:05,950 --> 00:44:12,340
andreas when you say you ping the API

00:44:09,840 --> 00:44:14,410
that means we really just check if the

00:44:12,340 --> 00:44:17,650
the API endpoint is available or do you

00:44:14,410 --> 00:44:20,110
really try a round-trip trying let's say

00:44:17,650 --> 00:44:21,910
to do is here flocking and if you see a

00:44:20,110 --> 00:44:23,890
rock and you take a see if you're a user

00:44:21,910 --> 00:44:28,240
or do you take a user which is coming

00:44:23,890 --> 00:44:30,070
from a different identity provider we

00:44:28,240 --> 00:44:31,720
have we have both actually but the thing

00:44:30,070 --> 00:44:34,210
that we used to generate the noise is

00:44:31,720 --> 00:44:36,070
just pinging the info endpoint okay

00:44:34,210 --> 00:44:37,310
we also have smoke test which actually

00:44:36,070 --> 00:44:39,230
push that I think so

00:44:37,310 --> 00:44:41,900
would notice in people enables push-ups

00:44:39,230 --> 00:44:47,180
yeah we'd notice and say it's down but

00:44:41,900 --> 00:44:51,260
our metrics would still say yeah so so

00:44:47,180 --> 00:44:52,760
one thing that that I'm wondering is so

00:44:51,260 --> 00:44:56,030
if you if you want to have a single

00:44:52,760 --> 00:44:59,480
number to say I'm up or down then then

00:44:56,030 --> 00:45:01,310
you really have to simplify a lot right

00:44:59,480 --> 00:45:02,990
so if you would say okay I measure

00:45:01,310 --> 00:45:07,580
everything that you could measure then

00:45:02,990 --> 00:45:09,530
probably hard to reach a lot of nines if

00:45:07,580 --> 00:45:12,980
you go to something totally simplistic

00:45:09,530 --> 00:45:15,350
and yeah you you as you said you're

00:45:12,980 --> 00:45:17,840
right you say I'm 99 I'm up I'm up but

00:45:15,350 --> 00:45:21,470
but your customers might experience and

00:45:17,840 --> 00:45:23,330
sound down so what would we try it at

00:45:21,470 --> 00:45:25,250
some point I'm was like doing some

00:45:23,330 --> 00:45:28,280
scenarios if we say this in this kind of

00:45:25,250 --> 00:45:29,540
scenario this is up and running and so

00:45:28,280 --> 00:45:31,580
on have you played around with something

00:45:29,540 --> 00:45:34,040
like this you said if I caught this crud

00:45:31,580 --> 00:45:36,770
that you also tried some pushing of apps

00:45:34,040 --> 00:45:38,360
so so like a which is it let's say

00:45:36,770 --> 00:45:40,850
already a bigger scenario cause you have

00:45:38,360 --> 00:45:42,410
quite a lot number of components you

00:45:40,850 --> 00:45:45,800
have in there quite a number of

00:45:42,410 --> 00:45:52,400
interactions that that go through the

00:45:45,800 --> 00:45:53,810
wire yeah so we haven't we have a bit of

00:45:52,400 --> 00:45:56,150
that with we're sort of starting to look

00:45:53,810 --> 00:45:57,500
at item item monitoring

00:45:56,150 --> 00:45:59,870
I had to get the sort of middle ground

00:45:57,500 --> 00:46:01,670
between absolutely everything's working

00:45:59,870 --> 00:46:03,410
which is sort of a smoke test do at the

00:46:01,670 --> 00:46:05,780
moment or at least the main things are

00:46:03,410 --> 00:46:08,270
working and like maybe some things are

00:46:05,780 --> 00:46:10,310
working which is what our nines stay so

00:46:08,270 --> 00:46:11,510
we're sort of currently trying to move

00:46:10,310 --> 00:46:15,140
the needle a bit towards a more

00:46:11,510 --> 00:46:17,060
realistic but there's lots of different

00:46:15,140 --> 00:46:18,410
things that we're doing on but with the

00:46:17,060 --> 00:46:22,670
very early day so I'd anything is worth

00:46:18,410 --> 00:46:27,200
going into much detail when you describe

00:46:22,670 --> 00:46:29,330
like defining scenarios is that like so

00:46:27,200 --> 00:46:31,520
you can look at like common use cases

00:46:29,330 --> 00:46:37,010
for the platform and look at how often

00:46:31,520 --> 00:46:41,270
will these people have problems yes well

00:46:37,010 --> 00:46:43,400
so basically one scenario you we we

00:46:41,270 --> 00:46:46,550
played around with or actually also use

00:46:43,400 --> 00:46:50,010
it and only for us as a team just as an

00:46:46,550 --> 00:46:52,950
additional sanity check is for example

00:46:50,010 --> 00:46:57,480
in pushing an app or binding service

00:46:52,950 --> 00:47:00,869
Bionic services starting the app seeing

00:46:57,480 --> 00:47:03,000
do we do we see log streaming and and

00:47:00,869 --> 00:47:05,700
can we actually reach the app and can

00:47:03,000 --> 00:47:08,790
the app do a successful communication

00:47:05,700 --> 00:47:10,470
with its backing services so let's say

00:47:08,790 --> 00:47:12,119
something where you are pretty sure that

00:47:10,470 --> 00:47:14,280
this app is working because it has

00:47:12,119 --> 00:47:19,020
worked a couple of thousands or million

00:47:14,280 --> 00:47:21,240
times before but let's say working with

00:47:19,020 --> 00:47:24,390
this there are so many things in between

00:47:21,240 --> 00:47:28,650
that could fail right that it's this

00:47:24,390 --> 00:47:30,930
kind of shake doesn't immediately tell

00:47:28,650 --> 00:47:33,030
you what is probably broken or is it the

00:47:30,930 --> 00:47:35,130
monitoring which is calling which is

00:47:33,030 --> 00:47:36,960
broken or is it actually the the

00:47:35,130 --> 00:47:38,880
platform that you're testing and so on

00:47:36,960 --> 00:47:41,250
so it took us some time to stabilize it

00:47:38,880 --> 00:47:46,369
for ourselves but it's not let's say

00:47:41,250 --> 00:47:50,040
that we say this is such a UH noise and

00:47:46,369 --> 00:47:52,609
English words such a immediately

00:47:50,040 --> 00:47:57,890
intuitive way of monitoring a platform

00:47:52,609 --> 00:48:00,569
that that we say this is a really good

00:47:57,890 --> 00:48:02,250
measurement s-curve we asked the

00:48:00,569 --> 00:48:04,500
question okay how do you say you are

00:48:02,250 --> 00:48:06,660
poor down this is just one aspect of it

00:48:04,500 --> 00:48:09,900
we find it helpful but how do you eat a

00:48:06,660 --> 00:48:21,609
half a crisp explanation of what you're

00:48:09,900 --> 00:48:24,579
testing there okay you see whether

00:48:21,609 --> 00:48:27,940
but maybe that is a discussion to to to

00:48:24,579 --> 00:48:29,680
let's say do on a little technical terms

00:48:27,940 --> 00:48:32,829
in the select channel to say okay these

00:48:29,680 --> 00:48:34,329
are the steps or so on - just see what

00:48:32,829 --> 00:48:36,339
are your thoughts on that because

00:48:34,329 --> 00:48:39,759
basically if that is something where we

00:48:36,339 --> 00:48:42,460
can say this is a good scenario to say

00:48:39,759 --> 00:48:43,930
this is a most simplistic developer

00:48:42,460 --> 00:48:45,519
round trip or so and that could be one

00:48:43,930 --> 00:48:47,589
interesting measurement that you

00:48:45,519 --> 00:48:49,180
probably don't say this is SLA relevant

00:48:47,589 --> 00:48:51,489
but that's at least other ways say that

00:48:49,180 --> 00:48:55,200
is a good health check that you want to

00:48:51,489 --> 00:48:57,309
implement as a child foundry provider

00:48:55,200 --> 00:48:59,789
yeah we'd certainly be interested in

00:48:57,309 --> 00:49:02,230
discussing more offline I think yeah

00:48:59,789 --> 00:49:05,259
just a quick a quick point for clavata

00:49:02,230 --> 00:49:07,630
we make the distinction between customer

00:49:05,259 --> 00:49:09,940
application availability and customer

00:49:07,630 --> 00:49:12,069
access availability so basically it's

00:49:09,940 --> 00:49:14,049
are your apps up and running which they

00:49:12,069 --> 00:49:15,819
generally tend to do in a lot of fail

00:49:14,049 --> 00:49:17,769
cases on Cloud Foundry yep go cells

00:49:15,819 --> 00:49:20,920
continue to run this stuff versus

00:49:17,769 --> 00:49:22,749
there's something wrong Kathy or brokers

00:49:20,920 --> 00:49:23,950
or something like that so by

00:49:22,749 --> 00:49:25,390
distinguishing those things it's much

00:49:23,950 --> 00:49:27,430
easier to talk to people about like

00:49:25,390 --> 00:49:28,539
uptime your applications versus like you

00:49:27,430 --> 00:49:29,710
know hey sometimes los scheduled

00:49:28,539 --> 00:49:32,920
maintenance for these other things or

00:49:29,710 --> 00:49:35,380
you know hey looking at our record the

00:49:32,920 --> 00:49:37,119
problems have always been and like capi

00:49:35,380 --> 00:49:39,279
scaling and like that's better issue but

00:49:37,119 --> 00:49:41,680
it hasn't been a problem for application

00:49:39,279 --> 00:49:43,390
availability so that that making that

00:49:41,680 --> 00:49:45,099
station seems to have been a like just

00:49:43,390 --> 00:49:46,119
that those two things seems to have been

00:49:45,099 --> 00:49:50,319
very helpful for talking to our

00:49:46,119 --> 00:49:52,539
customers so sometimes to say runtime

00:49:50,319 --> 00:49:55,930
and lifecycle management or fewer

00:49:52,539 --> 00:49:56,170
applications so to speak yeah something

00:49:55,930 --> 00:49:59,789
like that

00:49:56,170 --> 00:50:03,190
I look up the actual terms we use yeah

00:49:59,789 --> 00:50:05,259
okay do you know you Bret how you

00:50:03,190 --> 00:50:06,880
actually measure your application of

00:50:05,259 --> 00:50:09,700
time because the moment we just check

00:50:06,880 --> 00:50:12,519
like a single static Adam check that

00:50:09,700 --> 00:50:14,380
that's fine a lot of apps and apart from

00:50:12,519 --> 00:50:16,299
that be broken we wouldn't notice ACD

00:50:14,380 --> 00:50:17,799
check like actual production apps or do

00:50:16,299 --> 00:50:20,140
you have some sort of smoke apps that

00:50:17,799 --> 00:50:21,759
you use to check a representative sample

00:50:20,140 --> 00:50:26,529
or yeah we're wearing the smoke test

00:50:21,759 --> 00:50:30,239
basically constantly in production so

00:50:26,529 --> 00:50:32,650
the way we term it on our Status page is

00:50:30,239 --> 00:50:34,700
cloud backup customer applications and

00:50:32,650 --> 00:50:36,260
cloud backup customer access

00:50:34,700 --> 00:50:39,109
and those are further broken down into

00:50:36,260 --> 00:50:42,190
specific things in each of those I'll

00:50:39,109 --> 00:50:46,010
put the link in MS co-operators channel

00:50:42,190 --> 00:50:47,420
to our Status page I will caveat this by

00:50:46,010 --> 00:50:49,130
saying that our Status page like this is

00:50:47,420 --> 00:50:51,500
our human communications tool this is

00:50:49,130 --> 00:50:53,539
not like our monitoring tool so this is

00:50:51,500 --> 00:50:54,589
not like you know we might see alerts on

00:50:53,539 --> 00:50:56,119
different things but that's not feeding

00:50:54,589 --> 00:50:57,740
to say that this is about like when is a

00:50:56,119 --> 00:51:00,769
customer observed or customer reported

00:50:57,740 --> 00:51:08,569
ouch happening so I guess let's take in

00:51:00,769 --> 00:51:10,250
the chat here and in the channel but

00:51:08,569 --> 00:51:11,839
again just like for communicative

00:51:10,250 --> 00:51:13,039
customers like this is a logical

00:51:11,839 --> 00:51:15,680
breakdown that can get behind because

00:51:13,039 --> 00:51:17,510
they understand better like okay you

00:51:15,680 --> 00:51:42,289
know what is your track record what am I

00:51:17,510 --> 00:51:44,900
going to see inputs on this topic okay

00:51:42,289 --> 00:51:48,410
so if there's no so we can jump into the

00:51:44,900 --> 00:51:53,960
another discussion so Richard - can you

00:51:48,410 --> 00:51:54,890
take over yeah else again sorry I just

00:51:53,960 --> 00:51:58,670
thought we'd mention this cuz we had

00:51:54,890 --> 00:52:00,920
like a recent issue with it and we use

00:51:58,670 --> 00:52:04,009
safe deployment to manage our primary

00:52:00,920 --> 00:52:06,319
deployment and there's obviously a lot

00:52:04,009 --> 00:52:08,960
of certificates in there and there's

00:52:06,319 --> 00:52:10,460
quite a lot of difficulties and from

00:52:08,960 --> 00:52:11,930
time to time we need to rotate some

00:52:10,460 --> 00:52:14,420
certificates we need to rotate some

00:52:11,930 --> 00:52:15,920
difficulties and in the early days when

00:52:14,420 --> 00:52:17,539
we're getting everything set up we did

00:52:15,920 --> 00:52:20,059
some work to make it so that we could

00:52:17,539 --> 00:52:21,410
rotate either certificates or

00:52:20,059 --> 00:52:23,809
certificate or ''tis in a way that

00:52:21,410 --> 00:52:25,250
didn't cause any downtime for our API so

00:52:23,809 --> 00:52:29,000
it's possible to sort of roll and I

00:52:25,250 --> 00:52:31,759
gradually um but the way that we've done

00:52:29,000 --> 00:52:33,140
it has ended up taking a long time and

00:52:31,759 --> 00:52:34,880
it's become more and more painful as our

00:52:33,140 --> 00:52:36,170
foundation has grown we're now getting

00:52:34,880 --> 00:52:40,490
to the points that were mentioned at the

00:52:36,170 --> 00:52:42,140
beginning of the presentation about like

00:52:40,490 --> 00:52:44,390
it takes us maybe four or five hours to

00:52:42,140 --> 00:52:46,880
deploy a foundation we have to deploy it

00:52:44,390 --> 00:52:48,200
five or six times to rotate the search

00:52:46,880 --> 00:52:49,490
completely so

00:52:48,200 --> 00:52:52,070
we're talking about like a couple of

00:52:49,490 --> 00:52:53,420
days of work just like constantly change

00:52:52,070 --> 00:52:56,060
a little thing to boy a little thing I

00:52:53,420 --> 00:52:57,950
was wondering if anyone has a better way

00:52:56,060 --> 00:52:59,300
of rotating certificates or if there's

00:52:57,950 --> 00:53:02,720
any prior art that we're missing perhaps

00:52:59,300 --> 00:53:05,540
I guess we think we can do it in fewer

00:53:02,720 --> 00:53:07,430
steps but what's frustrating is is that

00:53:05,540 --> 00:53:12,080
we have to script this at all

00:53:07,430 --> 00:53:13,940
like we it feels like the kind of thing

00:53:12,080 --> 00:53:23,300
to see after deployment should offer but

00:53:13,940 --> 00:53:26,510
as far as we can tell it doesn't yeah I

00:53:23,300 --> 00:53:29,650
guess same thing for for us so we also

00:53:26,510 --> 00:53:32,000
have to script it so it might be

00:53:29,650 --> 00:53:34,580
worthwhile to to kind of exchange

00:53:32,000 --> 00:53:40,120
experiences on what works and maybe what

00:53:34,580 --> 00:53:40,120
doesn't seem much resting situations

00:53:42,610 --> 00:53:49,610
understand is why you do not use an

00:53:46,880 --> 00:53:55,130
external root certificate for all these

00:53:49,610 --> 00:53:56,870
internal stuff this would at least helps

00:53:55,130 --> 00:54:00,110
you to get rid of exchanging or

00:53:56,870 --> 00:54:03,830
replacing the trust every time so maybe

00:54:00,110 --> 00:54:06,590
it's not possible because the the CAS

00:54:03,830 --> 00:54:09,710
can then not be generated inside the

00:54:06,590 --> 00:54:14,540
landscape but maybe it's easier to to

00:54:09,710 --> 00:54:19,460
have some CAS replaced by using an

00:54:14,540 --> 00:54:22,960
external CA then then having multiple

00:54:19,460 --> 00:54:22,960
steps to rotate everything

00:54:26,830 --> 00:54:39,760
I guess they you make who winning a coin

00:54:36,150 --> 00:54:44,440
so the cia's would then public see me

00:54:39,760 --> 00:54:46,630
change less regularly but then we'd

00:54:44,440 --> 00:54:47,370
still have to be copying and pasting new

00:54:46,630 --> 00:54:49,950
certs

00:54:47,370 --> 00:54:58,630
where right now we live a big yeah mole

00:54:49,950 --> 00:55:01,060
faster but we put them in I guess it's

00:54:58,630 --> 00:55:04,120
just it feels really painful like we

00:55:01,060 --> 00:55:06,700
have squirts that moving things from

00:55:04,120 --> 00:55:11,470
like particularly name keys to that key

00:55:06,700 --> 00:55:13,390
name underscore old I guess is like if

00:55:11,470 --> 00:55:16,120
you work manually editing the a mole it

00:55:13,390 --> 00:55:20,700
would make sense but it was quick to

00:55:16,120 --> 00:55:23,020
point of view it's quite painful yeah

00:55:20,700 --> 00:55:25,150
okay I see someone has just said that

00:55:23,020 --> 00:55:36,040
this is recorded so I guess we should

00:55:25,150 --> 00:55:37,810
share this discussion to that team we

00:55:36,040 --> 00:55:39,520
can mention it to the broader team and

00:55:37,810 --> 00:55:41,200
also Brett you can probably ask your

00:55:39,520 --> 00:55:42,550
team to weigh in as well in the once

00:55:41,200 --> 00:55:44,920
they hear the recording they can rain on

00:55:42,550 --> 00:55:46,810
the slack channel well it might be worth

00:55:44,920 --> 00:55:48,490
mentioning with the release integration

00:55:46,810 --> 00:55:50,920
team as well it because it seems like

00:55:48,490 --> 00:55:54,930
consistent issue with I mean consistent

00:55:50,920 --> 00:55:54,930
kind of requirement across all the teams

00:56:00,780 --> 00:56:04,420
cool I think that's that's it for us we

00:56:03,190 --> 00:56:05,620
just wanted to check to see there wasn't

00:56:04,420 --> 00:56:08,140
a magic answer it sounds like there

00:56:05,620 --> 00:56:10,090
isn't yeah I'll paste some links to what

00:56:08,140 --> 00:56:13,350
we do in the channel but like we can

00:56:10,090 --> 00:56:13,350
chat about it in more detail

00:56:14,910 --> 00:56:21,540
yeah cool I know that we are reaching

00:56:18,550 --> 00:56:23,980
the and we are a difficulty hour so if

00:56:21,540 --> 00:56:25,480
is that was there anything else Gary

00:56:23,980 --> 00:56:28,630
Schenker that we were supposed to

00:56:25,480 --> 00:56:31,240
discuss on the call today I think yes

00:56:28,630 --> 00:56:36,360
who we don't have any other for the

00:56:31,240 --> 00:56:36,360
topics here we are done for the meeting

00:56:36,450 --> 00:56:40,600
this recording and post it on the

00:56:39,340 --> 00:56:43,170
YouTube channel

00:56:40,600 --> 00:56:46,540
break the slack town once it is up there

00:56:43,170 --> 00:56:50,620
and I do apologize for the timezone

00:56:46,540 --> 00:56:52,690
confusion and the Dozen confusion that

00:56:50,620 --> 00:56:55,330
we had this time I look it looked like

00:56:52,690 --> 00:56:59,350
we were split on two bridges thank you

00:56:55,330 --> 00:57:01,960
my we'll fix those two issues for the

00:56:59,350 --> 00:57:03,850
next call but this is good

00:57:01,960 --> 00:57:06,460
thank you very much for starting this

00:57:03,850 --> 00:57:07,150
I'm leading this thank you all thank you

00:57:06,460 --> 00:57:09,760
all very much

00:57:07,150 --> 00:57:12,810
yeah thank you thank you you see on the

00:57:09,760 --> 00:57:12,810

YouTube URL: https://www.youtube.com/watch?v=zv-Lgk9t4Ck


