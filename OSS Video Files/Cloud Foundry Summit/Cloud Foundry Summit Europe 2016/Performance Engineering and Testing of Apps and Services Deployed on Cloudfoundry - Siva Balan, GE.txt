Title: Performance Engineering and Testing of Apps and Services Deployed on Cloudfoundry - Siva Balan, GE
Publication date: 2016-09-30
Playlist: Cloud Foundry Summit Europe 2016
Description: 
	Performance Engineering and Testing of Apps and Services Deployed on Cloudfoundry - Siva Balan, GE

Performance engineering of apps and services deployed on Cloudfoundry is an art in itself. If there is any misconception that this is going to be very similar to performance engineering of on-premise apps, you are in for a rude awakening. This sessions explains the various nuances of doing non-functional testing and analysis of your services when deployed to cloudfoundry. The session will also cover some examples of how to effectively setup your environment for performance engineering and things to look for that may not be very obvious. We will also look at some performance engineering tools and frameworks that has been adopted successfully at GE Digital. The session will also showcase how this framework can be extended to include performance testing of your services as part of your CI/CD pipeline.

About Siva Balan
I currently wear a hat of a Performance Engineer for platform security services for GE Digital's Predix platform built on Cloudfoundry. I am actively involved in performance engineering of Predix services like UAA(User Account and Authentication), ACS(Access Control Service) and TMS(Tenant Management Service). I also wear a hat of Performance architect for the Predix platform and love to experiment with technologies to make performance engineering better. I am currently working on seamlessly integrating performance testing with the CI/CD pipeline and also making Predix Security Services auto-scale based on resource utilization.
Captions: 
	00:00:00,030 --> 00:00:07,589
I'm silver Balin I work at GE digital

00:00:03,840 --> 00:00:10,139
and I'm a performance engineer of the

00:00:07,589 --> 00:00:13,710
security services offered by the

00:00:10,139 --> 00:00:18,109
predicts platform that's developed in a

00:00:13,710 --> 00:00:20,580
G digital I'm here to as the slide says

00:00:18,109 --> 00:00:22,789
talk a little bit about how to do

00:00:20,580 --> 00:00:26,220
performance engineering and testing of

00:00:22,789 --> 00:00:29,699
services and apps developed on Cloud

00:00:26,220 --> 00:00:31,769
Foundry we it's basically the practice

00:00:29,699 --> 00:00:34,950
that we put into place G digital because

00:00:31,769 --> 00:00:38,730
we develop our services on top of Cloud

00:00:34,950 --> 00:00:41,399
Foundry and I just thought I would share

00:00:38,730 --> 00:00:42,930
this with you to see if it helps even a

00:00:41,399 --> 00:00:48,090
couple of people I think I think I've

00:00:42,930 --> 00:00:49,829
made my goal here so anyways I'm going

00:00:48,090 --> 00:00:52,829
to briefly walk you through the agenda

00:00:49,829 --> 00:00:54,510
so we're going to talk about why go

00:00:52,829 --> 00:00:55,770
through the hassle of doing performance

00:00:54,510 --> 00:00:58,800
engineering or testing in the first

00:00:55,770 --> 00:01:01,800
place and we'll look at some tools and

00:00:58,800 --> 00:01:02,820
techniques that we followed eg digital

00:01:01,800 --> 00:01:05,580
and I'm sure it's it's it's pretty

00:01:02,820 --> 00:01:08,520
common we use open source tools and it's

00:01:05,580 --> 00:01:10,290
nothing proprietary to us and yeah and

00:01:08,520 --> 00:01:12,780
anyone can take this up and and start

00:01:10,290 --> 00:01:16,500
using it and then I'll talk briefly

00:01:12,780 --> 00:01:18,750
about how we do this and how we've

00:01:16,500 --> 00:01:23,040
integrated this performance testing with

00:01:18,750 --> 00:01:25,830
our CI CD pipeline and how different is

00:01:23,040 --> 00:01:27,630
doing performance testing on apps that

00:01:25,830 --> 00:01:30,689
is part to Cloud Foundry versus apps

00:01:27,630 --> 00:01:34,350
that are on premise or not deployed to

00:01:30,689 --> 00:01:36,470
cloud cloud solutions I've seen some of

00:01:34,350 --> 00:01:38,400
some customers who were actually

00:01:36,470 --> 00:01:41,670
migrating from on-premise applications

00:01:38,400 --> 00:01:43,229
to cloud services and the mindset of

00:01:41,670 --> 00:01:45,090
doing performance testing or performance

00:01:43,229 --> 00:01:46,590
engineering on apps deployed on-premise

00:01:45,090 --> 00:01:48,149
applications are quite different from

00:01:46,590 --> 00:01:49,799
especially when it comes to Cloud

00:01:48,149 --> 00:01:52,350
Foundry I'm not going to talk about

00:01:49,799 --> 00:01:54,360
other offerings but at least on Cloud

00:01:52,350 --> 00:01:57,600
Foundry and because we did go through

00:01:54,360 --> 00:01:59,040
the process and we found some

00:01:57,600 --> 00:02:00,509
interesting findings I'm going to talk

00:01:59,040 --> 00:02:03,950
about the interesting findings that we

00:02:00,509 --> 00:02:06,210
had when moving from on-premise

00:02:03,950 --> 00:02:08,550
deployments to cloud chlorinate

00:02:06,210 --> 00:02:11,450
deployments just a slide on key

00:02:08,550 --> 00:02:14,380
takeaways and we'll start with questions

00:02:11,450 --> 00:02:17,080
so why go

00:02:14,380 --> 00:02:20,560
the hassle right so if if you've done

00:02:17,080 --> 00:02:22,270
performance engineering or even talked

00:02:20,560 --> 00:02:25,240
to performance engineers you know that

00:02:22,270 --> 00:02:29,770
it's very hard to find non-functional

00:02:25,240 --> 00:02:31,240
issues it's it's not it's not like you

00:02:29,770 --> 00:02:32,980
run a test and then you find the results

00:02:31,240 --> 00:02:36,370
right away so you typically some some

00:02:32,980 --> 00:02:39,310
are it takes a few hours some takes a

00:02:36,370 --> 00:02:42,970
few days to find especially issues like

00:02:39,310 --> 00:02:48,040
resource leaks memory leaks and stuff

00:02:42,970 --> 00:02:50,290
like that so it's usually in a software

00:02:48,040 --> 00:02:52,840
development lifecycle in most most

00:02:50,290 --> 00:02:54,400
developers and most project management

00:02:52,840 --> 00:02:57,310
project managers that have spoken to

00:02:54,400 --> 00:02:58,840
it's usually a tick box that you say a

00:02:57,310 --> 00:03:00,280
check box it say okay I've done my

00:02:58,840 --> 00:03:01,900
performance testing and it's ready to go

00:03:00,280 --> 00:03:05,530
to production it's usually the last step

00:03:01,900 --> 00:03:07,780
in the process but it what if what you

00:03:05,530 --> 00:03:10,030
found is that it's it makes it very

00:03:07,780 --> 00:03:12,610
difficult to fix the issues if it's

00:03:10,030 --> 00:03:16,240
going to be your check box for releasing

00:03:12,610 --> 00:03:18,880
a product into production or or for the

00:03:16,240 --> 00:03:20,860
customers to consume and it also helps

00:03:18,880 --> 00:03:23,530
in caching issues early on the software

00:03:20,860 --> 00:03:25,810
Altman lifecycle and especially if

00:03:23,530 --> 00:03:29,070
you're following agile methodology if

00:03:25,810 --> 00:03:31,090
you start here at least from our

00:03:29,070 --> 00:03:33,960
experience if you start your performance

00:03:31,090 --> 00:03:36,670
testing in sprint 2 or sprint 3 it

00:03:33,960 --> 00:03:39,010
really makes a big difference

00:03:36,670 --> 00:03:41,230
with the amount of time the developers

00:03:39,010 --> 00:03:42,430
take to fix the issue and the quality of

00:03:41,230 --> 00:03:45,100
the fix let me tell you this

00:03:42,430 --> 00:03:48,250
non-functional issues are not typically

00:03:45,100 --> 00:03:50,230
it's not fixed the first time so it goes

00:03:48,250 --> 00:03:51,550
to a developer a fix is set and then you

00:03:50,230 --> 00:03:54,040
run the test again I'm sharing go to

00:03:51,550 --> 00:03:56,290
cache the same issue or a similar issue

00:03:54,040 --> 00:03:59,290
again so it helps to give developers

00:03:56,290 --> 00:04:01,060
more time to fix the issues and catching

00:03:59,290 --> 00:04:02,650
it early on and running it as part of

00:04:01,060 --> 00:04:05,770
your CI CD pipeline really helps in this

00:04:02,650 --> 00:04:07,510
case and also I'm not sure how many of

00:04:05,770 --> 00:04:09,910
you woke up at odd hours to fix issues

00:04:07,510 --> 00:04:13,150
in production I've done it so it I think

00:04:09,910 --> 00:04:15,910
it it really helps in in in not having

00:04:13,150 --> 00:04:18,989
to wake up at all hours so some of the

00:04:15,910 --> 00:04:22,330
tools and techniques that we've used to

00:04:18,989 --> 00:04:24,729
do performance testing let me start with

00:04:22,330 --> 00:04:27,070
the type of tests that we do we start

00:04:24,729 --> 00:04:28,060
off with initially a capacity test where

00:04:27,070 --> 00:04:29,650
we take one

00:04:28,060 --> 00:04:31,060
we deploy the app or service to one

00:04:29,650 --> 00:04:33,700
instance of Cloud Foundry

00:04:31,060 --> 00:04:36,480
and after once we deploy it to one

00:04:33,700 --> 00:04:42,610
instance we then test it to make sure

00:04:36,480 --> 00:04:44,410
the service is tuned to for the most

00:04:42,610 --> 00:04:45,669
optimal performance in that one instance

00:04:44,410 --> 00:04:47,710
for example let me take a java

00:04:45,669 --> 00:04:50,410
application as an example so if you

00:04:47,710 --> 00:04:52,150
deploy a Java app to one instance we

00:04:50,410 --> 00:04:53,560
tune the heap we look at the heap we

00:04:52,150 --> 00:04:56,080
look at the usage we look at the garbage

00:04:53,560 --> 00:04:57,580
collection patterns we increase or

00:04:56,080 --> 00:05:00,010
decrease the amount of heap or the

00:04:57,580 --> 00:05:01,540
container size depending on how how

00:05:00,010 --> 00:05:04,030
often the garbage collection takes place

00:05:01,540 --> 00:05:07,060
so we look at various parameters and

00:05:04,030 --> 00:05:09,220
tune the application to the most optimal

00:05:07,060 --> 00:05:12,130
performance for that one instance and

00:05:09,220 --> 00:05:13,540
once we nailed it down we then move on

00:05:12,130 --> 00:05:15,639
to scalability test then we start

00:05:13,540 --> 00:05:18,100
scaling out the number of instances and

00:05:15,639 --> 00:05:21,160
we increase the load with proportionally

00:05:18,100 --> 00:05:24,639
so let's say you start your one instance

00:05:21,160 --> 00:05:27,810
of app is able to handle thousand

00:05:24,639 --> 00:05:31,300
requests per second or per minute and

00:05:27,810 --> 00:05:34,360
once and that's performing it's a 70%

00:05:31,300 --> 00:05:37,060
utilization with with a nice graph for

00:05:34,360 --> 00:05:39,250
your garbage collection

00:05:37,060 --> 00:05:41,169
now once you've nailed it down then you

00:05:39,250 --> 00:05:42,640
can down move to three instances and you

00:05:41,169 --> 00:05:45,220
can increase it increase your load to

00:05:42,640 --> 00:05:47,919
3,000 requests per minute and you should

00:05:45,220 --> 00:05:51,130
see a flat line where your throughput

00:05:47,919 --> 00:05:52,720
increases proportionally to the number

00:05:51,130 --> 00:05:54,940
of instances that you've scaled to so

00:05:52,720 --> 00:05:57,400
that's the kind of test that we do in

00:05:54,940 --> 00:05:59,080
scalability not test so we basically

00:05:57,400 --> 00:06:00,940
increase it to three five or ten

00:05:59,080 --> 00:06:03,760
instances depending on the requirement

00:06:00,940 --> 00:06:05,919
of the service huh sorry the endurance

00:06:03,760 --> 00:06:08,919
test that we do is essentially to run

00:06:05,919 --> 00:06:10,510
one instance or maybe three instance or

00:06:08,919 --> 00:06:12,490
farms and depending on how you wanted to

00:06:10,510 --> 00:06:14,350
test it it doesn't matter whether it's a

00:06:12,490 --> 00:06:16,660
single instance test or multi intense

00:06:14,350 --> 00:06:19,990
multi instance test but we run this

00:06:16,660 --> 00:06:21,970
typically for five days so what this

00:06:19,990 --> 00:06:25,419
catches is typically memory leaks

00:06:21,970 --> 00:06:27,070
resource leaks CPU utilization and it

00:06:25,419 --> 00:06:30,039
tells you if there are objects that are

00:06:27,070 --> 00:06:32,470
allocated or not removed from the heap

00:06:30,039 --> 00:06:36,580
all those issues are typically caught

00:06:32,470 --> 00:06:37,840
and in in endurance tests and I can't

00:06:36,580 --> 00:06:40,840
stress the importance of running

00:06:37,840 --> 00:06:41,650
endurance tests because literally every

00:06:40,840 --> 00:06:43,990
release

00:06:41,650 --> 00:06:47,520
introduces some bugs that causes memory

00:06:43,990 --> 00:06:50,410
leaks or resource leaks for you so it

00:06:47,520 --> 00:06:54,460
but the fact that you're running in claw

00:06:50,410 --> 00:06:55,960
foundry it hides all all these issues

00:06:54,460 --> 00:06:57,789
behind the scenes and I'll show you an

00:06:55,960 --> 00:06:58,630
example of what exactly what what this

00:06:57,789 --> 00:07:01,180
means

00:06:58,630 --> 00:07:03,370
but let's say you have a memory leak in

00:07:01,180 --> 00:07:05,130
your application and it runs in

00:07:03,370 --> 00:07:09,340
production you'll run for two days and

00:07:05,130 --> 00:07:11,889
your container will crash but your plot

00:07:09,340 --> 00:07:13,360
foundry is actually helping you to

00:07:11,889 --> 00:07:15,340
restart the container without even

00:07:13,360 --> 00:07:17,440
letting you know that there is a crash

00:07:15,340 --> 00:07:19,180
and you don't even know you don't even

00:07:17,440 --> 00:07:21,580
realize that there is a resource leak in

00:07:19,180 --> 00:07:24,160
your application and the only way to

00:07:21,580 --> 00:07:25,810
determine this is to really run these

00:07:24,160 --> 00:07:27,970
steps for tests for a longer period of

00:07:25,810 --> 00:07:29,949
time making sure that they are running

00:07:27,970 --> 00:07:32,500
and you have a nice resource utilization

00:07:29,949 --> 00:07:35,680
and I'll show you a brief finding that

00:07:32,500 --> 00:07:39,280
we had on the mound the memory leaks

00:07:35,680 --> 00:07:42,160
issue stress test this is something that

00:07:39,280 --> 00:07:45,970
we do to make sure how your application

00:07:42,160 --> 00:07:49,150
recovers after it after we go through a

00:07:45,970 --> 00:07:51,610
spike so typically we have spikes early

00:07:49,150 --> 00:07:55,810
on in the week or sometimes early on the

00:07:51,610 --> 00:07:58,720
mornings and auto-scaling is not there

00:07:55,810 --> 00:08:02,010
yet out of the box in cloud foundry

00:07:58,720 --> 00:08:04,630
unfortunately so if your application is

00:08:02,010 --> 00:08:06,849
set to run with three instances and

00:08:04,630 --> 00:08:08,229
you're running out of resources with

00:08:06,849 --> 00:08:10,479
three instances because of it because of

00:08:08,229 --> 00:08:13,300
a source spike I'm sorry our spike under

00:08:10,479 --> 00:08:17,229
number of requests coming in now

00:08:13,300 --> 00:08:18,970
it's it's gonna go down at some point

00:08:17,229 --> 00:08:21,340
and you're going to get alerted if there

00:08:18,970 --> 00:08:23,349
is if there is a problem with your

00:08:21,340 --> 00:08:25,570
application you're going to go increase

00:08:23,349 --> 00:08:27,669
the number of instances and it's going

00:08:25,570 --> 00:08:30,099
to fix the issue for you but you want to

00:08:27,669 --> 00:08:31,720
make sure that or at least you should be

00:08:30,099 --> 00:08:36,849
aware how your application is going to

00:08:31,720 --> 00:08:38,919
recover once the app wants as resource I

00:08:36,849 --> 00:08:41,800
know the requests number of requests

00:08:38,919 --> 00:08:44,140
will goes down so that helps in stress

00:08:41,800 --> 00:08:45,430
testing chaos monkey Tech testing is

00:08:44,140 --> 00:08:48,430
something that we have recently

00:08:45,430 --> 00:08:50,800
introduced of course this is this came

00:08:48,430 --> 00:08:52,200
out from the Netflix

00:08:50,800 --> 00:08:54,160
you know some of you might be aware

00:08:52,200 --> 00:08:58,920
essentially what we tried to do is we

00:08:54,160 --> 00:09:01,990
randomly try to remove services or

00:08:58,920 --> 00:09:05,860
instances from Cloud Foundry it's kind

00:09:01,990 --> 00:09:08,110
of difficult to target a particular

00:09:05,860 --> 00:09:10,090
instance in Platte 400 and destroy them

00:09:08,110 --> 00:09:13,060
so what we try to do is we try to scale

00:09:10,090 --> 00:09:16,960
down when there is a request spiked and

00:09:13,060 --> 00:09:20,560
we see how it handles the instances

00:09:16,960 --> 00:09:22,720
going up and down in in in real

00:09:20,560 --> 00:09:23,830
production we're trying to do this in

00:09:22,720 --> 00:09:25,120
production we're not there yet

00:09:23,830 --> 00:09:26,260
you're still doing it in performance

00:09:25,120 --> 00:09:27,820
testing to make sure how the performance

00:09:26,260 --> 00:09:31,360
test environment to see how this works

00:09:27,820 --> 00:09:33,940
but we're getting there slowly and some

00:09:31,360 --> 00:09:36,490
of the tools that we use is we use

00:09:33,940 --> 00:09:39,150
jmeter on docker for our load testing

00:09:36,490 --> 00:09:41,350
and we use New Relic for monitoring

00:09:39,150 --> 00:09:42,850
Jolokia for JMX this is something that

00:09:41,350 --> 00:09:45,400
we'll talk about as well unfortunately

00:09:42,850 --> 00:09:48,850
because in Platte foundry they know the

00:09:45,400 --> 00:09:51,520
only ports that are exposed or HTTP

00:09:48,850 --> 00:09:55,810
ports you can't really use traditional

00:09:51,520 --> 00:09:58,380
JMX tools for you to look at the the JMX

00:09:55,810 --> 00:10:00,550
metrics like jquan so for example so

00:09:58,380 --> 00:10:02,230
Jolokia gives you it's an open source

00:10:00,550 --> 00:10:05,080
tool that gives you an HTTP wrapper on

00:10:02,230 --> 00:10:07,320
top of J max and so that it's really you

00:10:05,080 --> 00:10:10,900
can you can use a cool request to get

00:10:07,320 --> 00:10:12,340
output of your DMX we use LK for

00:10:10,900 --> 00:10:16,000
persistence and I'll talk about this as

00:10:12,340 --> 00:10:18,850
well so this gives you a picture of how

00:10:16,000 --> 00:10:20,920
we typically do a performance testing so

00:10:18,850 --> 00:10:24,160
what happens is when a developer checks

00:10:20,920 --> 00:10:28,240
in a code in into the developer or the

00:10:24,160 --> 00:10:32,260
master branch we have the performance

00:10:28,240 --> 00:10:33,850
test framework checks out the code it

00:10:32,260 --> 00:10:35,410
builds the code pushes the code to the

00:10:33,850 --> 00:10:37,630
performance test environment in Cloud

00:10:35,410 --> 00:10:41,200
Foundry and once that's time then we

00:10:37,630 --> 00:10:43,150
have a job that kicks off its a docker

00:10:41,200 --> 00:10:44,830
container one or many docker containers

00:10:43,150 --> 00:10:47,650
depending on how many instances of

00:10:44,830 --> 00:10:50,590
jmeter you want to run and these start

00:10:47,650 --> 00:10:55,840
pushing load to Cloud Foundry so once

00:10:50,590 --> 00:10:58,240
that the load testing starts we then

00:10:55,840 --> 00:10:58,990
have every app that gets pushed into

00:10:58,240 --> 00:11:01,540
Cloud Foundry

00:10:58,990 --> 00:11:02,800
there's always bound to New Relic for

00:11:01,540 --> 00:11:04,570
monitoring purposes because or else

00:11:02,800 --> 00:11:11,080
without it we just flying blind

00:11:04,570 --> 00:11:13,390
and we also have Jolokia which so for

00:11:11,080 --> 00:11:16,660
the way we use Jolokia is that as I said

00:11:13,390 --> 00:11:18,370
it's an issue DP rapper / J Max and we

00:11:16,660 --> 00:11:22,510
actually call this using locks - so

00:11:18,370 --> 00:11:24,820
locks - keeps pulling every 30 seconds

00:11:22,510 --> 00:11:26,830
for into into the apps and flower

00:11:24,820 --> 00:11:29,320
foundry and gets the metrics and persist

00:11:26,830 --> 00:11:34,720
that in elasticsearch as you can see the

00:11:29,320 --> 00:11:37,450
what sorry this was this was a picture I

00:11:34,720 --> 00:11:40,690
was going to show so as you see the

00:11:37,450 --> 00:11:43,030
Jolokia persisted results in the

00:11:40,690 --> 00:11:45,730
elasticsearch as well and the results of

00:11:43,030 --> 00:11:48,880
jmeter also goes through rabbit and Q

00:11:45,730 --> 00:11:51,100
and that gets persisted in elasticsearch

00:11:48,880 --> 00:11:54,130
as well so locks - so essentially

00:11:51,100 --> 00:11:55,750
RabbitMQ is a subscriber for I'm sorry

00:11:54,130 --> 00:11:58,600
they last the locks - is a subscriber

00:11:55,750 --> 00:11:59,950
for rabbitmq and the publisher is

00:11:58,600 --> 00:12:02,770
actually the jmeter so the results of

00:11:59,950 --> 00:12:05,200
jmeter goes to RabbitMQ and RabbitMQ is

00:12:02,770 --> 00:12:08,320
the messaging bus that we use so that it

00:12:05,200 --> 00:12:10,600
can handle multiple test runs at the

00:12:08,320 --> 00:12:13,750
same time and of course new Dalek is

00:12:10,600 --> 00:12:18,670
constantly monitoring it your platform

00:12:13,750 --> 00:12:20,830
redeployments so typically we run these

00:12:18,670 --> 00:12:24,190
tests the capacity test on a daily basis

00:12:20,830 --> 00:12:26,380
and the results are persisted and a

00:12:24,190 --> 00:12:28,450
typical graph looks like this in our

00:12:26,380 --> 00:12:30,610
case so this is a dashboard that we

00:12:28,450 --> 00:12:33,930
built using key bonham and as you can

00:12:30,610 --> 00:12:36,190
see the first two boxes the transaction

00:12:33,930 --> 00:12:37,330
response time the transaction throughput

00:12:36,190 --> 00:12:40,270
come from jmeter

00:12:37,330 --> 00:12:43,390
and all the other boxes as you can see

00:12:40,270 --> 00:12:45,370
like the memory used file descriptors

00:12:43,390 --> 00:12:47,920
all these or jmx metrics that are

00:12:45,370 --> 00:12:49,480
collected using Jolokia and persisted in

00:12:47,920 --> 00:12:52,270
elasticsearch so we are now able to

00:12:49,480 --> 00:12:55,240
combine combine both the results of

00:12:52,270 --> 00:12:56,710
jmeter results of Jolokia into one one

00:12:55,240 --> 00:13:00,640
graph and you can you can you can show

00:12:56,710 --> 00:13:04,300
this and it's because it you have the

00:13:00,640 --> 00:13:07,690
capability to get the gmx metrics you

00:13:04,300 --> 00:13:09,400
can you can even have custom JMX metrics

00:13:07,690 --> 00:13:12,550
published into this dashboard as well

00:13:09,400 --> 00:13:14,050
it's it's again it again uses locks -

00:13:12,550 --> 00:13:15,940
jibon i elasticsearch it's all open

00:13:14,050 --> 00:13:16,840
source and it's nothing proprietary

00:13:15,940 --> 00:13:21,760
about what we do

00:13:16,840 --> 00:13:25,720
here and the CICE integration is

00:13:21,760 --> 00:13:29,140
something that we take it very seriously

00:13:25,720 --> 00:13:31,450
so what we the way we do that is we

00:13:29,140 --> 00:13:37,410
start with Jenkins we use Jenkins for

00:13:31,450 --> 00:13:39,640
our CI and the way we have deployed our

00:13:37,410 --> 00:13:41,950
from performance are we have integrated

00:13:39,640 --> 00:13:45,730
performance testing with the CI CI CD

00:13:41,950 --> 00:13:49,450
pipeline is that every time so of course

00:13:45,730 --> 00:13:51,670
Jenkins uses Jenkins gets the build from

00:13:49,450 --> 00:13:54,220
github it builds it pushes it to our

00:13:51,670 --> 00:13:57,730
develop branch and the develop branch is

00:13:54,220 --> 00:13:59,290
always the most current branch that we

00:13:57,730 --> 00:14:03,390
test on so that's where we get the

00:13:59,290 --> 00:14:05,800
latest bits from and we have Jenkins

00:14:03,390 --> 00:14:09,430
each of these linking slaves is deployed

00:14:05,800 --> 00:14:12,820
is has darker installed in it so every

00:14:09,430 --> 00:14:15,280
time we want to kick off a test it we we

00:14:12,820 --> 00:14:16,900
have a nightly test for performance

00:14:15,280 --> 00:14:18,970
testing because performance testing

00:14:16,900 --> 00:14:21,490
typically takes two to three hours to

00:14:18,970 --> 00:14:24,790
run so you don't want to do this for

00:14:21,490 --> 00:14:26,650
every check-in on a daily basis so we do

00:14:24,790 --> 00:14:28,480
it as a nightly run so what happens is

00:14:26,650 --> 00:14:31,120
whatever the last build for the day is

00:14:28,480 --> 00:14:32,530
we check that out we build it push it

00:14:31,120 --> 00:14:34,810
out to the performance test environment

00:14:32,530 --> 00:14:39,790
and we run the test for at least three

00:14:34,810 --> 00:14:42,160
hours so and the results of those tests

00:14:39,790 --> 00:14:44,470
get persisted in the elasticsearch and

00:14:42,160 --> 00:14:48,580
of course New Relic monitors the tests

00:14:44,470 --> 00:14:51,190
as well we also have alerts set up in

00:14:48,580 --> 00:14:54,730
Uralic so if there is an SLA breach in

00:14:51,190 --> 00:14:57,640
any of the test runs we get notified on

00:14:54,730 --> 00:15:02,410
the from New Relic and what we also do

00:14:57,640 --> 00:15:04,690
is the reports are emailed on daily

00:15:02,410 --> 00:15:06,100
basis or even weekly basis to all the

00:15:04,690 --> 00:15:08,290
stakeholders so that way we make sure

00:15:06,100 --> 00:15:09,670
that everybody is aware of what the

00:15:08,290 --> 00:15:11,440
performance test runs or what the

00:15:09,670 --> 00:15:14,710
results are and if there is any

00:15:11,440 --> 00:15:17,050
regression in performance between on our

00:15:14,710 --> 00:15:18,190
day to day basis or even from built we

00:15:17,050 --> 00:15:19,810
don't have it from built table because

00:15:18,190 --> 00:15:21,460
we don't run it for every bolt but at

00:15:19,810 --> 00:15:25,600
least on a day to day basis with the

00:15:21,460 --> 00:15:28,740
developers are aware of it so that's how

00:15:25,600 --> 00:15:32,459
we have it built as part of a Jenkins

00:15:28,740 --> 00:15:35,930
continuous integration now how different

00:15:32,459 --> 00:15:38,910
is troubleshooting in in Cloud Foundry

00:15:35,930 --> 00:15:42,270
at least because we were we moved our

00:15:38,910 --> 00:15:44,750
application from on-premise to Claude

00:15:42,270 --> 00:15:48,209
foundry you were able to get some

00:15:44,750 --> 00:15:49,760
information on how the troubleshooting

00:15:48,209 --> 00:15:52,740
is different from these two environments

00:15:49,760 --> 00:15:56,430
as I was mentioning there is no access

00:15:52,740 --> 00:15:59,459
to our my ports in in cloud foundry

00:15:56,430 --> 00:16:02,880
unfortunately so we had to come up with

00:15:59,459 --> 00:16:06,209
a way to do that and the and that's when

00:16:02,880 --> 00:16:09,810
that's how we started using Jolokia so

00:16:06,209 --> 00:16:10,890
Jolokia gives you an HTTP wrapper for

00:16:09,810 --> 00:16:14,190
jmx

00:16:10,890 --> 00:16:17,070
and you can you you can do all JMX

00:16:14,190 --> 00:16:18,630
operations using this using using

00:16:17,070 --> 00:16:20,700
Jolokia and this this has helped us

00:16:18,630 --> 00:16:23,459
tremendously to collect gem x matrix

00:16:20,700 --> 00:16:26,430
some are most of them are available by

00:16:23,459 --> 00:16:29,490
default in a new relic but in some cases

00:16:26,430 --> 00:16:31,440
like for example DB connection pools and

00:16:29,490 --> 00:16:34,980
other custom JMX metrics are not

00:16:31,440 --> 00:16:36,870
available and you have to use Jolokia

00:16:34,980 --> 00:16:38,430
for that too to get those values and of

00:16:36,870 --> 00:16:40,589
course as I said before we purchase

00:16:38,430 --> 00:16:45,630
those in our in elasticsearch and we're

00:16:40,589 --> 00:16:48,630
able to visualize them JVM crashes so if

00:16:45,630 --> 00:16:50,160
there is a JVM crash due to out of

00:16:48,630 --> 00:16:52,890
memory for example it crashes the

00:16:50,160 --> 00:16:54,779
container so you can't go back if it's

00:16:52,890 --> 00:16:58,380
an on-prem machine you can go back and

00:16:54,779 --> 00:17:01,220
look at your HSA red file if you're

00:16:58,380 --> 00:17:03,240
aware of that it usually creates some

00:17:01,220 --> 00:17:04,589
stack trace for you so you can look at

00:17:03,240 --> 00:17:06,959
the stack test to figure out what caused

00:17:04,589 --> 00:17:09,569
your memory leak or memory what cost

00:17:06,959 --> 00:17:11,040
your JVM to crash but unfortunately in

00:17:09,569 --> 00:17:13,829
this case because you use ephemeral

00:17:11,040 --> 00:17:16,439
containers you can't go back and figure

00:17:13,829 --> 00:17:18,929
out what is causing the crash for you so

00:17:16,439 --> 00:17:21,240
you rely on application logs that are

00:17:18,929 --> 00:17:23,040
what we do is our application logs are

00:17:21,240 --> 00:17:25,199
all persisted to elasticsearch s as well

00:17:23,040 --> 00:17:28,470
so you have to rely on allah the

00:17:25,199 --> 00:17:30,059
application logs are CF CLI gives you

00:17:28,470 --> 00:17:32,670
the CF events command I'll show you how

00:17:30,059 --> 00:17:35,700
that works as well how we use that as

00:17:32,670 --> 00:17:39,920
well so and and those are couple of ways

00:17:35,700 --> 00:17:42,360
that we've used to see how we can

00:17:39,920 --> 00:17:44,850
detect what happened with with it with

00:17:42,360 --> 00:17:46,860
the crash for example again traditional

00:17:44,850 --> 00:17:49,560
tools like Jay visual VMware J profiler

00:17:46,860 --> 00:17:52,380
don't work on Cloud Foundry and we have

00:17:49,560 --> 00:17:55,830
to rely on APM tools like New Relic

00:17:52,380 --> 00:17:57,540
or app dynamics to monitor application

00:17:55,830 --> 00:17:59,040
during a performance test and soar even

00:17:57,540 --> 00:18:01,170
in production for example we have to use

00:17:59,040 --> 00:18:02,610
these tools in production as well to

00:18:01,170 --> 00:18:03,840
give you a good insight on what's

00:18:02,610 --> 00:18:08,370
happening with their application how the

00:18:03,840 --> 00:18:10,740
resources are being used and and and

00:18:08,370 --> 00:18:12,960
it's it's there are ways around it and

00:18:10,740 --> 00:18:14,970
it's not it is not easy but it really

00:18:12,960 --> 00:18:16,380
works a bit over the past couple of

00:18:14,970 --> 00:18:20,670
years you kind of figured out the way

00:18:16,380 --> 00:18:25,050
how to make life make our life easier

00:18:20,670 --> 00:18:26,660
with using these tools so I'll just talk

00:18:25,050 --> 00:18:33,300
about an interesting finding that we had

00:18:26,660 --> 00:18:36,420
with as we because as we moved from on

00:18:33,300 --> 00:18:39,420
prime to cloud foundry deployments one

00:18:36,420 --> 00:18:41,580
of the things we found was that so we

00:18:39,420 --> 00:18:43,650
were we are pretty much most of our apps

00:18:41,580 --> 00:18:46,620
of java application so one of our app is

00:18:43,650 --> 00:18:49,290
a java spring boot app and when we

00:18:46,620 --> 00:18:50,430
deployed the springboard happens and the

00:18:49,290 --> 00:18:52,680
and of course we start we have

00:18:50,430 --> 00:18:55,380
performance testing that that we do on a

00:18:52,680 --> 00:18:57,630
daily basis and as we started doing our

00:18:55,380 --> 00:19:00,180
performance testing we found that the

00:18:57,630 --> 00:19:02,760
container would start crashing in couple

00:19:00,180 --> 00:19:04,460
of hours you would see that it there's

00:19:02,760 --> 00:19:08,100
always restarts that are happening and

00:19:04,460 --> 00:19:10,410
we checked our code up and down

00:19:08,100 --> 00:19:11,670
everywhere every bit of code and and we

00:19:10,410 --> 00:19:14,010
didn't find any leaks in the code it

00:19:11,670 --> 00:19:16,080
would work fine if you do that if you do

00:19:14,010 --> 00:19:17,730
the same testing on an on-prem machine

00:19:16,080 --> 00:19:19,980
it'll work fine we deployed on our

00:19:17,730 --> 00:19:21,480
laptops do the testing no no no leaks

00:19:19,980 --> 00:19:22,920
it worked perfectly fine so the leak

00:19:21,480 --> 00:19:27,360
happened only after we deployed it to

00:19:22,920 --> 00:19:29,750
cloud foundry so as we were looking

00:19:27,360 --> 00:19:33,300
through the jmx

00:19:29,750 --> 00:19:37,020
graphs and new relic graphs one of the

00:19:33,300 --> 00:19:38,730
things we found was from the start from

00:19:37,020 --> 00:19:41,010
the time we deployed the app to the time

00:19:38,730 --> 00:19:43,920
it crashed there was not a single full

00:19:41,010 --> 00:19:46,170
full garbage collection so that was

00:19:43,920 --> 00:19:50,720
pretty interesting so why would it the

00:19:46,170 --> 00:19:50,720
garbage collection not kick in right so

00:19:50,750 --> 00:19:56,830
that led us to believe

00:19:52,720 --> 00:20:00,940
that there is something that's crashing

00:19:56,830 --> 00:20:04,900
the container before the jvm decides to

00:20:00,940 --> 00:20:09,220
do the first garbage collection so what

00:20:04,900 --> 00:20:13,030
we had to do was well after a little bit

00:20:09,220 --> 00:20:15,580
of Investigation what we found out was

00:20:13,030 --> 00:20:17,380
the app that we were testing was

00:20:15,580 --> 00:20:19,960
slightly heavy on the native memory

00:20:17,380 --> 00:20:22,630
usage so what apparently happened was

00:20:19,960 --> 00:20:24,850
that your garbage so let me show you let

00:20:22,630 --> 00:20:28,390
me go back a little bit and show you a

00:20:24,850 --> 00:20:31,090
graph of how these thing looks so come

00:20:28,390 --> 00:20:34,690
back okay so I'm gonna show you a graph

00:20:31,090 --> 00:20:36,789
that looks normal so if you look at the

00:20:34,690 --> 00:20:37,630
heap memory usage on this you can see a

00:20:36,789 --> 00:20:39,669
very nice

00:20:37,630 --> 00:20:41,860
garbage collection happening this is in

00:20:39,669 --> 00:20:43,900
the last three hours is it actually a

00:20:41,860 --> 00:20:45,549
test running right now so the last three

00:20:43,900 --> 00:20:47,440
hours you can see it's it has done a

00:20:45,549 --> 00:20:51,820
couple of garbage collections here now

00:20:47,440 --> 00:20:57,299
I'll show you another graph where it

00:20:51,820 --> 00:20:57,299
crashes or not this is the other one

00:21:00,690 --> 00:21:09,280
think I lost the graph here maybe I'll

00:21:07,840 --> 00:21:10,809
pull up the graph a little bit later but

00:21:09,280 --> 00:21:12,640
I don't want to waste time to plane so

00:21:10,809 --> 00:21:14,289
essentially what happen is it'll go and

00:21:12,640 --> 00:21:16,570
you you'll actually not see a garbage

00:21:14,289 --> 00:21:20,830
collection at all so when that happens

00:21:16,570 --> 00:21:25,809
it actually one of the things we found

00:21:20,830 --> 00:21:30,789
out was that the we had to just the

00:21:25,809 --> 00:21:34,960
memory profile so it let me go back to

00:21:30,789 --> 00:21:37,690
that all right so one of the things we

00:21:34,960 --> 00:21:42,700
found out was the memory heuristics that

00:21:37,690 --> 00:21:46,390
was allocated to the percentage of

00:21:42,700 --> 00:21:50,020
memory allocated to the heap was pretty

00:21:46,390 --> 00:21:51,850
much very close to the total size of the

00:21:50,020 --> 00:21:54,549
container so I think it's 75% by default

00:21:51,850 --> 00:21:56,140
or 70% by default and we were using and

00:21:54,549 --> 00:22:00,010
there was only 10% of memory allocated

00:21:56,140 --> 00:22:04,860
to native and it would the native memory

00:22:00,010 --> 00:22:09,640
was using up a lot more memory than

00:22:04,860 --> 00:22:11,429
what the heap was actually allocated for

00:22:09,640 --> 00:22:14,500
us so in that case what's happening was

00:22:11,429 --> 00:22:16,330
when it reached to a point where it has

00:22:14,500 --> 00:22:17,529
to do a garbage collection it doesn't it

00:22:16,330 --> 00:22:18,610
didn't have any more container when we

00:22:17,529 --> 00:22:21,460
left the container was actually running

00:22:18,610 --> 00:22:23,440
out of memory not the heap itself so one

00:22:21,460 --> 00:22:26,529
of the things we did was we used a

00:22:23,440 --> 00:22:28,840
memory limit variable if you're aware of

00:22:26,529 --> 00:22:30,640
that and we can actually set that so for

00:22:28,840 --> 00:22:34,630
example if we push our app with two

00:22:30,640 --> 00:22:35,919
gigabytes of memory it what would what

00:22:34,630 --> 00:22:37,630
the memory heuristics will do is it'll

00:22:35,919 --> 00:22:40,029
give you it gives 70% of memory to the

00:22:37,630 --> 00:22:43,149
heap and 10% of the negative 10% of meta

00:22:40,029 --> 00:22:45,940
space and and that's how it divides up

00:22:43,149 --> 00:22:48,190
the total to gigabytes of memory now by

00:22:45,940 --> 00:22:50,559
setting this memory limit to say 1.3

00:22:48,190 --> 00:22:53,710
gigabyte I'm saying the memory

00:22:50,559 --> 00:22:55,720
heuristics to work on this 1.3 gigabytes

00:22:53,710 --> 00:22:58,270
and not on the entire two gigabytes so

00:22:55,720 --> 00:23:00,309
then what happens is that you have a lot

00:22:58,270 --> 00:23:01,750
less memory allocated to the heap and a

00:23:00,309 --> 00:23:05,710
lot more memory available for the native

00:23:01,750 --> 00:23:08,799
memory so that actually helped us to

00:23:05,710 --> 00:23:10,090
start seeing those nice garbage

00:23:08,799 --> 00:23:11,169
collection happening so once the garbage

00:23:10,090 --> 00:23:14,980
collection started happening

00:23:11,169 --> 00:23:16,419
the app just ran fine for more than 5

00:23:14,980 --> 00:23:20,919
days there was no issue so as you can

00:23:16,419 --> 00:23:25,880
see here I'll show you a quick so if you

00:23:20,919 --> 00:23:28,999
look at it's not

00:23:25,880 --> 00:23:28,999
[Music]

00:23:33,240 --> 00:23:44,500
right here this okay

00:23:38,169 --> 00:23:46,360
so there you can see you can see on the

00:23:44,500 --> 00:23:48,879
top all the crashes that has happened

00:23:46,360 --> 00:23:51,250
because I changed I'd remove the memory

00:23:48,879 --> 00:23:52,509
Malamud variable and ran the test for a

00:23:51,250 --> 00:23:54,250
couple of hours and you can see all the

00:23:52,509 --> 00:23:57,580
crashes was happening and then I reset

00:23:54,250 --> 00:23:59,379
the memory back memory limit back and

00:23:57,580 --> 00:24:02,409
you can see the test was test start run

00:23:59,379 --> 00:24:03,460
fine without any issues so this was one

00:24:02,409 --> 00:24:07,450
interesting finding that we found

00:24:03,460 --> 00:24:09,129
because of and we could find is only

00:24:07,450 --> 00:24:12,700
because we could drop you were running

00:24:09,129 --> 00:24:13,990
the performance test and in our CI CD

00:24:12,700 --> 00:24:16,539
pipeline and were able to detect it much

00:24:13,990 --> 00:24:17,740
before we could be deployed this

00:24:16,539 --> 00:24:21,490
reproduction we were able to get the

00:24:17,740 --> 00:24:33,190
memory limit in place the other let me

00:24:21,490 --> 00:24:35,440
come back to ya so one more interesting

00:24:33,190 --> 00:24:37,480
finding quickly so against the Java

00:24:35,440 --> 00:24:39,070
spring boot app the container would

00:24:37,480 --> 00:24:40,509
crash after 12 hours so we ran a test

00:24:39,070 --> 00:24:42,279
we're returning an endurance test and

00:24:40,509 --> 00:24:45,100
after 12 hours we would see the

00:24:42,279 --> 00:24:47,230
container crashes and the time we did

00:24:45,100 --> 00:24:49,509
have full GCSE in them but what it what

00:24:47,230 --> 00:24:51,940
we did find was the time interval

00:24:49,509 --> 00:24:53,679
between full GC would start going

00:24:51,940 --> 00:24:55,210
smaller and smaller and smaller and

00:24:53,679 --> 00:24:56,889
eventually it'll continuously be doing a

00:24:55,210 --> 00:24:59,259
full GC it would never have time to do

00:24:56,889 --> 00:25:01,120
scammin GCS at all and this is the

00:24:59,259 --> 00:25:02,500
typical memory like how it looks like if

00:25:01,120 --> 00:25:04,090
the Java has a memory leak this is

00:25:02,500 --> 00:25:06,759
typically how it would look like so you

00:25:04,090 --> 00:25:08,379
would see a continuous pattern of full

00:25:06,759 --> 00:25:09,879
GCS and then it'll start getting smaller

00:25:08,379 --> 00:25:11,230
and smaller and smaller it'll and

00:25:09,879 --> 00:25:14,110
eventually it will just be doing a full

00:25:11,230 --> 00:25:16,480
GC and we didn't of course find any code

00:25:14,110 --> 00:25:18,820
in any java code many leaks in java code

00:25:16,480 --> 00:25:21,309
but what happened was that when we

00:25:18,820 --> 00:25:25,500
started looking at the services that we

00:25:21,309 --> 00:25:28,450
are that are bound to the application

00:25:25,500 --> 00:25:31,269
the service that we were using to

00:25:28,450 --> 00:25:33,700
monitor the the leaks was actually the

00:25:31,269 --> 00:25:36,809
culprit of causing the leak itself so

00:25:33,700 --> 00:25:37,929
when we aren't when we unbound the

00:25:36,809 --> 00:25:40,230
noodle-like

00:25:37,929 --> 00:25:43,059
agent from the application and ran it

00:25:40,230 --> 00:25:44,669
luckily we had the JMX metrics collected

00:25:43,059 --> 00:25:47,009
through Jolokia

00:25:44,669 --> 00:25:48,330
and it ran fine for seven days without

00:25:47,009 --> 00:25:50,999
any problem as soon as we removed this

00:25:48,330 --> 00:25:52,350
one so and then we had report back to

00:25:50,999 --> 00:25:53,730
you know like to figure out what why the

00:25:52,350 --> 00:25:55,169
agent was causing problems so there was

00:25:53,730 --> 00:26:00,059
one particular version of New Relic that

00:25:55,169 --> 00:26:02,249
was causing a memory leak so all of

00:26:00,059 --> 00:26:04,409
these couldn't have been identified if

00:26:02,249 --> 00:26:06,749
if we weren't running any of those

00:26:04,409 --> 00:26:09,029
performance tests so some of the key

00:26:06,749 --> 00:26:11,399
takeaways I would say for running a

00:26:09,029 --> 00:26:13,350
performance tests are you have to start

00:26:11,399 --> 00:26:14,820
early in your in your in your in your

00:26:13,350 --> 00:26:17,309
Sprint's for running performance tests

00:26:14,820 --> 00:26:21,119
and you have to go deep just running one

00:26:17,309 --> 00:26:24,149
test and and checking a box is probably

00:26:21,119 --> 00:26:25,710
not helpful always use a good monitoring

00:26:24,149 --> 00:26:29,129
tool so without that you're literally

00:26:25,710 --> 00:26:31,259
flying blind and as far as possible try

00:26:29,129 --> 00:26:34,259
to automate your tests with CI and run

00:26:31,259 --> 00:26:36,179
as many tests as possible and you enable

00:26:34,259 --> 00:26:38,730
developers if possible to run

00:26:36,179 --> 00:26:42,570
performance tests on their own which we

00:26:38,730 --> 00:26:44,129
are trying to it in ng and then you have

00:26:42,570 --> 00:26:45,419
to make test results accessible to every

00:26:44,129 --> 00:26:47,009
developer because they have to look at

00:26:45,419 --> 00:26:48,330
to see what what they thought their code

00:26:47,009 --> 00:26:51,779
is performing and that makes a big

00:26:48,330 --> 00:26:55,619
difference so that's that's something we

00:26:51,779 --> 00:26:57,929
have learned as well so that's it I

00:26:55,619 --> 00:27:00,269
think I have about three minutes for

00:26:57,929 --> 00:27:03,049
questions if you have any questions that

00:27:00,269 --> 00:27:03,049
you might have - yes please

00:27:04,019 --> 00:27:11,309
Jolokia agent runs on so the agent

00:27:08,940 --> 00:27:13,080
actually runs on the application itself

00:27:11,309 --> 00:27:15,869
so it's a palm dependency because the

00:27:13,080 --> 00:27:18,629
spring springboard app so we just have

00:27:15,869 --> 00:27:22,440
Jolokia in the palm so as we deploy the

00:27:18,629 --> 00:27:26,869
application it gets included as part of

00:27:22,440 --> 00:27:26,869
the application yes

00:27:33,940 --> 00:27:37,309
it's totally dependent on what

00:27:36,320 --> 00:27:39,620
application is running for our

00:27:37,309 --> 00:27:40,910
application it was 1.3 gigabytes but for

00:27:39,620 --> 00:27:42,650
your application it might be much more

00:27:40,910 --> 00:27:44,929
native heavy so you may have to reduce

00:27:42,650 --> 00:27:46,700
it even more so you have to so we start

00:27:44,929 --> 00:27:49,190
off with one gig he slowly started

00:27:46,700 --> 00:27:50,809
increasing to 1.3 gig where we found the

00:27:49,190 --> 00:27:52,550
speech part and he said we'll stick to

00:27:50,809 --> 00:27:54,320
1.3 gig we didn't want to go to 1.5

00:27:52,550 --> 00:27:55,940
because we started seeing memory leaks

00:27:54,320 --> 00:27:57,320
at one point five so we scale back and

00:27:55,940 --> 00:28:00,470
said one point three is a good number

00:27:57,320 --> 00:28:02,570
for us so yeah it really depends on your

00:28:00,470 --> 00:28:05,960
application it's there is no one magic

00:28:02,570 --> 00:28:19,730
number yes sorry that was I think it was

00:28:05,960 --> 00:28:23,960
before yeah Oh reverse you're still on

00:28:19,730 --> 00:28:26,420
da I'm sorry so we're moving to Diego

00:28:23,960 --> 00:28:28,640
but I was told we're not going to be

00:28:26,420 --> 00:28:31,880
given necesitas in production for Diego

00:28:28,640 --> 00:28:33,350
for security purposes so I don't think

00:28:31,880 --> 00:28:40,370
it's going to work even in Diego for us

00:28:33,350 --> 00:28:42,170
so yes oh yeah for testing yes that's

00:28:40,370 --> 00:28:44,510
possible yeah I think it might be

00:28:42,170 --> 00:28:47,450
enabled but I think at some point we

00:28:44,510 --> 00:28:49,010
found that in some cases unexpected

00:28:47,450 --> 00:28:51,830
things happen in production too so I

00:28:49,010 --> 00:28:54,050
pretty I personally wish we had it says

00:28:51,830 --> 00:29:04,390
Jax as to it but yeah I think we will

00:28:54,050 --> 00:29:04,390
get it for performance testing yes okay

00:29:06,640 --> 00:29:09,940
okay yeah

00:29:14,980 --> 00:29:20,240
you can go change it yourself so what we

00:29:17,960 --> 00:29:21,769
have done is we've fork the built by

00:29:20,240 --> 00:29:22,970
built back at least for performance

00:29:21,769 --> 00:29:24,830
testing what I've done is I forked the

00:29:22,970 --> 00:29:26,630
bill back and I changed the memories

00:29:24,830 --> 00:29:33,380
heuristic testing that's setting in the

00:29:26,630 --> 00:29:34,399
open JDK yeah yeah well there are some

00:29:33,380 --> 00:29:36,529
things you can do and some things you

00:29:34,399 --> 00:29:37,789
cannot do there and I think one of the

00:29:36,529 --> 00:29:38,960
things the memory heuristics is

00:29:37,789 --> 00:29:40,700
something that we could do it from the

00:29:38,960 --> 00:29:41,419
manifest file we have to go change the

00:29:40,700 --> 00:30:01,070
bill pack for it

00:29:41,419 --> 00:30:03,470
oh maybe change okay but I'm not sure if

00:30:01,070 --> 00:30:04,789
that's a built back problem it probably

00:30:03,470 --> 00:30:06,470
might be something that you have to

00:30:04,789 --> 00:30:08,480
control on an application side I'm not

00:30:06,470 --> 00:30:09,919
sure how the built back and built back

00:30:08,480 --> 00:30:11,149
basically tells you how much I care how

00:30:09,919 --> 00:30:12,860
much memory is going to give it to your

00:30:11,149 --> 00:30:15,019
application that's pretty much it it

00:30:12,860 --> 00:30:16,610
doesn't care about how much native

00:30:15,019 --> 00:30:19,940
memory your application is using how

00:30:16,610 --> 00:30:21,679
much heap memory or so it doesn't

00:30:19,940 --> 00:30:23,750
control how much memory your application

00:30:21,679 --> 00:30:25,190
is using all it controls is that memory

00:30:23,750 --> 00:30:33,620
it's going to give to an application to

00:30:25,190 --> 00:30:36,279
use yes that's correct

00:30:33,620 --> 00:30:36,279
yes

00:30:44,879 --> 00:30:52,360
I believe there is a way to the only way

00:30:50,230 --> 00:30:55,360
I can think of is for you to come up

00:30:52,360 --> 00:30:56,799
with your own heuristics numbers and

00:30:55,360 --> 00:30:58,450
because they give us the option to

00:30:56,799 --> 00:31:00,340
change it so I think we should just go

00:30:58,450 --> 00:31:01,690
change it if we feel our applications

00:31:00,340 --> 00:31:03,580
not performing with the default numbers

00:31:01,690 --> 00:31:07,570
that are provided as part of the pill

00:31:03,580 --> 00:31:09,039
pack I'm not sure if there is any other

00:31:07,570 --> 00:31:11,679
way it is I can't think of at this time

00:31:09,039 --> 00:31:16,179
any other way to make it better

00:31:11,679 --> 00:31:19,269
so yeah sure

00:31:16,179 --> 00:31:20,499
any more questions all right I think

00:31:19,269 --> 00:31:22,940
we're out of time thank you

00:31:20,499 --> 00:31:25,589
oh yeah sure I'm sure

00:31:22,940 --> 00:31:25,589

YouTube URL: https://www.youtube.com/watch?v=-zA_0WiDSvU


