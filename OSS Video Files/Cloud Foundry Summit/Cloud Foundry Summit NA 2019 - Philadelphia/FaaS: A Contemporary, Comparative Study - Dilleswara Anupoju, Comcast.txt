Title: FaaS: A Contemporary, Comparative Study - Dilleswara Anupoju, Comcast
Publication date: 2019-04-11
Playlist: Cloud Foundry Summit NA 2019 - Philadelphia
Description: 
	FaaS: A Contemporary, Comparative Study - Dilleswara Anupoju, Comcast

What is the latest trend thatâ€™s catching up in the world of distributed computing? The latest buzz word is FaaS or Serverless- though serverless is a misnomer because these functions still need a run time environment some where; FaaS is simply a new level of abstraction above PaaS & IaaS so that developers can run and deploy snippets of code easily.

As the popularity for FaaS grows, there is a corresponding increase in the number of FaaS flavors, available in the market; each offering is unique in terms of the capabilities and the level of complexity/abstraction.


In this talk Dill Anupoju would like present a comparative study to describe what's out there, how they work so that devs can choose from wide variety of options that's right for their use case

About Dilleswara Anupoju
I am Dill(Dilleswara) Anupoju ,a Platform/Cloud engineer , part of a platform Architecture &Engineering team and provide application services to our developers here at Comcast. I have total 15yrs work ex , first 5 into software engineering, data structures, algorithms the next 5 heavily into java/spring frameworks, java/jee design patterns, SOA and micro services architecture later into data analytics and cloud based technologies 
- Sun Certified Enterprise Architect and Certified Cloud foundry developer. 

I love traveling, exploring new avenues, star-gazing, astro-physics and identify my-self as a thought leader and big believer of technology that builds a better world.

https://www.cloudfoundry.org/
Captions: 
	00:00:00,060 --> 00:00:09,679
so hello everyone yeah how are y'all

00:00:06,330 --> 00:00:14,570
doing I know it's pretty long day I

00:00:09,679 --> 00:00:17,910
think we can get started just in time so

00:00:14,570 --> 00:00:21,539
I'm delish Rhonda Paju

00:00:17,910 --> 00:00:24,090
I'm a senior platform engineer here at

00:00:21,539 --> 00:00:27,090
Comcast I have total 15 years of work x

00:00:24,090 --> 00:00:29,609
phosphide heavily into design patterns

00:00:27,090 --> 00:00:33,030
java print frameworks and then later on

00:00:29,609 --> 00:00:36,239
mode 2 so our micro services and later

00:00:33,030 --> 00:00:37,680
on moved to cloud-based technologies and

00:00:36,239 --> 00:00:39,510
also I'm proud to be part of an amazing

00:00:37,680 --> 00:00:43,559
platform architecture and engineering

00:00:39,510 --> 00:00:46,980
team we are a small team handful handful

00:00:43,559 --> 00:00:50,039
is like 10 ok engineers managing

00:00:46,980 --> 00:00:52,949
multiple platforms based on Cloud

00:00:50,039 --> 00:00:55,489
Foundry kubernetes to support wide

00:00:52,949 --> 00:00:57,539
variety of workloads and also

00:00:55,489 --> 00:00:59,730
abstracting multiple clouds under the

00:00:57,539 --> 00:01:03,270
hood ranging all the way from private to

00:00:59,730 --> 00:01:05,250
public clouds and we also have a

00:01:03,270 --> 00:01:08,689
thriving developer community of about

00:01:05,250 --> 00:01:11,310
1,500 slack users and also have about

00:01:08,689 --> 00:01:14,970
40,000 a eyes that are currently running

00:01:11,310 --> 00:01:18,060
in production across all our CF sites so

00:01:14,970 --> 00:01:20,430
that's all about me and my team just to

00:01:18,060 --> 00:01:23,040
get a little bit about you folks how

00:01:20,430 --> 00:01:25,799
many of you are using any kind of

00:01:23,040 --> 00:01:28,430
Savalas platform or are planning to use

00:01:25,799 --> 00:01:31,439
any kind of subtle cellulous platform

00:01:28,430 --> 00:01:33,229
all right that's handful we're a little

00:01:31,439 --> 00:01:35,670
I'm not surprised

00:01:33,229 --> 00:01:38,520
let me ask another question how many of

00:01:35,670 --> 00:01:40,710
you are using any kind of pass platform

00:01:38,520 --> 00:01:44,670
such as cloud foundry yeah pretty much

00:01:40,710 --> 00:01:46,439
everyone does but the question looks

00:01:44,670 --> 00:01:47,490
different but I asked the same question

00:01:46,439 --> 00:01:49,439
in a different way

00:01:47,490 --> 00:01:57,000
hold on to that thought I'll get back to

00:01:49,439 --> 00:01:59,610
that in a minute so the question is it

00:01:57,000 --> 00:02:02,040
almost sounds like yesterday we all

00:01:59,610 --> 00:02:04,380
started with pass just trying to wrap

00:02:02,040 --> 00:02:06,090
the head around and then Kass and then

00:02:04,380 --> 00:02:09,989
CFC are there are a lot of things going

00:02:06,090 --> 00:02:13,770
on while all this is going on we hear a

00:02:09,989 --> 00:02:18,060
lot of buzz around functions so alas

00:02:13,770 --> 00:02:24,300
fast platforms what's going on is this

00:02:18,060 --> 00:02:27,780
another new shiny thing unfortunately

00:02:24,300 --> 00:02:31,110
several as FAR's suffers from under the

00:02:27,780 --> 00:02:35,940
new shiny thinkers while it's not really

00:02:31,110 --> 00:02:38,160
true if you look at the timeline path

00:02:35,940 --> 00:02:41,880
our service platform was introduced back

00:02:38,160 --> 00:02:44,340
in 2014 by the team who are behind odd 0

00:02:41,880 --> 00:02:47,430
they kind of started web tasks and also

00:02:44,340 --> 00:02:50,640
hope that i/o they are the first solace

00:02:47,430 --> 00:02:52,860
function as a service platform they kind

00:02:50,640 --> 00:02:55,890
of support node and JavaScript functions

00:02:52,860 --> 00:02:59,280
few years later in 2016 there was a

00:02:55,890 --> 00:03:01,620
sudden explosion of Savalas fast

00:02:59,280 --> 00:03:03,720
platforms both in open source as well as

00:03:01,620 --> 00:03:06,660
hosted solutions by all the major

00:03:03,720 --> 00:03:09,120
players since then it's growing silently

00:03:06,660 --> 00:03:12,630
and organically just like how fast it in

00:03:09,120 --> 00:03:15,450
2011 it became silent soaked for a

00:03:12,630 --> 00:03:17,910
couple of years and then thought leaders

00:03:15,450 --> 00:03:21,000
and early adopters like Comcast kind of

00:03:17,910 --> 00:03:22,400
took it from there you know the rest is

00:03:21,000 --> 00:03:26,030
history

00:03:22,400 --> 00:03:29,700
so well all that sounds good

00:03:26,030 --> 00:03:31,680
but what exactly is this server less or

00:03:29,700 --> 00:03:38,550
fast mean there's a lot of confusion

00:03:31,680 --> 00:03:40,380
around it well in general terms cellular

00:03:38,550 --> 00:03:44,330
sounds very synonymous with fast

00:03:40,380 --> 00:03:46,200
function as a service and vice-versa but

00:03:44,330 --> 00:03:50,280
to be precise

00:03:46,200 --> 00:03:51,900
fast is a subset of server less sour

00:03:50,280 --> 00:03:54,390
less covers and rule of many other

00:03:51,900 --> 00:04:01,190
things but fast is just as a subsystem

00:03:54,390 --> 00:04:04,020
of that we also fast simply means that

00:04:01,190 --> 00:04:06,510
the end users of the platform that is

00:04:04,020 --> 00:04:10,950
the developers no longer have to think

00:04:06,510 --> 00:04:13,709
or manage about servers in other words

00:04:10,950 --> 00:04:15,870
if your platform operator or service

00:04:13,709 --> 00:04:17,910
provider of several as fast you'd be

00:04:15,870 --> 00:04:22,350
thinking about servers and managing it

00:04:17,910 --> 00:04:26,450
all the time well that sounds like pass

00:04:22,350 --> 00:04:26,450
isn't it how is it different from pass

00:04:26,629 --> 00:04:35,909
so you could consider fast as the first

00:04:30,330 --> 00:04:37,289
iteration of sour less and passes first

00:04:35,909 --> 00:04:41,310
iteration of serverless

00:04:37,289 --> 00:04:43,379
and fast could be sour less to dot oh

00:04:41,310 --> 00:04:48,419
these are some of the quotes that are

00:04:43,379 --> 00:04:50,699
taken back in 2016 by dr. Jules who kind

00:04:48,419 --> 00:04:52,979
of says either sour less is different

00:04:50,699 --> 00:04:55,949
than past than you or I have

00:04:52,979 --> 00:04:59,400
misunderstood the towns so we can safely

00:04:55,949 --> 00:05:02,159
say that pass is sour less one that oh

00:04:59,400 --> 00:05:05,310
well developers have to still think

00:05:02,159 --> 00:05:06,930
about how many a eyes they need or what

00:05:05,310 --> 00:05:10,139
kind of darker image that they need to

00:05:06,930 --> 00:05:11,759
push onto the platform in fast with sour

00:05:10,139 --> 00:05:14,069
less to dot oh they don't have to even

00:05:11,759 --> 00:05:16,289
think about it in terms of how much

00:05:14,069 --> 00:05:19,379
capacity they need in advance it is kind

00:05:16,289 --> 00:05:23,370
of going a little bit advanced that's

00:05:19,379 --> 00:05:26,879
all just another iteration well all that

00:05:23,370 --> 00:05:30,210
sounds good but why would anyone go to

00:05:26,879 --> 00:05:32,009
the trouble of managing platform and

00:05:30,210 --> 00:05:33,779
building the software in a new way when

00:05:32,009 --> 00:05:38,789
there's an already in existing way that

00:05:33,779 --> 00:05:41,069
that works fine well the primary reason

00:05:38,789 --> 00:05:43,199
the driver and the motivation is all

00:05:41,069 --> 00:05:46,110
about cost right the resource

00:05:43,199 --> 00:05:49,020
optimization utilization efficiency and

00:05:46,110 --> 00:05:52,349
agility the same reason why we kind of

00:05:49,020 --> 00:05:54,210
started with pass let's take a look at

00:05:52,349 --> 00:05:58,740
the scenario that would make it things

00:05:54,210 --> 00:06:01,250
more clear so this is the snapshot taken

00:05:58,740 --> 00:06:07,289
from one of our production environment

00:06:01,250 --> 00:06:09,330
and this is one of our largest site the

00:06:07,289 --> 00:06:11,569
first one is the traffic volume that

00:06:09,330 --> 00:06:14,190
flows 9:00 a.m. to 9:00 p.m.

00:06:11,569 --> 00:06:17,009
cycles through every day and the one

00:06:14,190 --> 00:06:19,159
below is the total number of application

00:06:17,009 --> 00:06:21,659
instances a is running on the platform

00:06:19,159 --> 00:06:24,990
just to put things in perspective there

00:06:21,659 --> 00:06:27,690
are about 4,000 a eyes that is roughly

00:06:24,990 --> 00:06:29,699
about 400 micro services with Dan a eyes

00:06:27,690 --> 00:06:33,000
each this is just an approximation

00:06:29,699 --> 00:06:34,830
though just to keep math easier not all

00:06:33,000 --> 00:06:38,030
the apps have same number of AI some has

00:06:34,830 --> 00:06:39,530
more some has less but what is the

00:06:38,030 --> 00:06:42,500
first thing that comes to your mind when

00:06:39,530 --> 00:06:45,800
you see this scenario like this with the

00:06:42,500 --> 00:06:47,210
corresponding drip dip in traffic did

00:06:45,800 --> 00:06:50,840
you notice any corresponding drop in

00:06:47,210 --> 00:06:52,910
number of a is no so that means that

00:06:50,840 --> 00:06:55,280
that's clearly an opportunity for

00:06:52,910 --> 00:06:57,260
resource optimization so we are talking

00:06:55,280 --> 00:06:58,640
about not ten or hundred instances we

00:06:57,260 --> 00:07:01,040
are talking about four thousand in say

00:06:58,640 --> 00:07:03,620
eyes so that's roughly about twelve

00:07:01,040 --> 00:07:07,940
hours of time right 9:00 9:00 p.m. to

00:07:03,620 --> 00:07:11,210
9:00 a.m. that sounds a lot and what do

00:07:07,940 --> 00:07:13,130
we do with that so definitely it's a

00:07:11,210 --> 00:07:15,560
no-brainer we could use an auto scaler

00:07:13,130 --> 00:07:17,870
that kind of detects the change in

00:07:15,560 --> 00:07:19,850
traffic pattern and ramps down the

00:07:17,870 --> 00:07:22,010
number of a eyes so it could go down

00:07:19,850 --> 00:07:24,950
anywhere more than half of them about

00:07:22,010 --> 00:07:28,220
two thousand areas can can be recycled

00:07:24,950 --> 00:07:32,870
and that kinds of releases lot of

00:07:28,220 --> 00:07:35,060
resources and the so auto song

00:07:32,870 --> 00:07:36,350
autoscaler sounds like the answer but

00:07:35,060 --> 00:07:38,540
the devil is in the details

00:07:36,350 --> 00:07:41,050
what happens next day my name in the

00:07:38,540 --> 00:07:43,400
morning the traffic Dixon the autoscaler

00:07:41,050 --> 00:07:46,400
detects the change in pattern and it

00:07:43,400 --> 00:07:48,620
tries to bring one A one A or

00:07:46,400 --> 00:07:50,680
application instance per service so

00:07:48,620 --> 00:07:53,420
you're looking about four hundred a eyes

00:07:50,680 --> 00:07:57,740
that are trying to start simultaneously

00:07:53,420 --> 00:07:59,900
on the platform and this can cause in

00:07:57,740 --> 00:08:03,530
event storm we have seen that several

00:07:59,900 --> 00:08:06,050
times and this event storm affects the

00:08:03,530 --> 00:08:08,330
response times of some of the apps that

00:08:06,050 --> 00:08:10,250
are on the critical path which which are

00:08:08,330 --> 00:08:13,190
kind of called by the downstream zaps

00:08:10,250 --> 00:08:14,630
and customer-facing apps and there are

00:08:13,190 --> 00:08:16,880
also other apps that are on the platform

00:08:14,630 --> 00:08:19,130
that are depend on these apps right

00:08:16,880 --> 00:08:21,620
overall this is kind of a hammer caios

00:08:19,130 --> 00:08:23,420
in terms of increasing the response time

00:08:21,620 --> 00:08:24,380
I don't think this is a great situation

00:08:23,420 --> 00:08:27,650
to be in

00:08:24,380 --> 00:08:30,590
especially during business hours but

00:08:27,650 --> 00:08:34,130
well wait a minute adding an auto scaler

00:08:30,590 --> 00:08:37,370
would cause such issues that sounds odd

00:08:34,130 --> 00:08:39,740
isn't it well let's pretend for now that

00:08:37,370 --> 00:08:43,430
the autoscaler has no known parts at

00:08:39,740 --> 00:08:44,350
this point and it works well when it

00:08:43,430 --> 00:08:49,640
comes to scale

00:08:44,350 --> 00:08:51,830
just pretend so what else is kind of

00:08:49,640 --> 00:08:53,450
left on the plate right probably

00:08:51,830 --> 00:08:58,190
let's take a look at the apps what's

00:08:53,450 --> 00:09:01,540
going on under the hood so some of the

00:08:58,190 --> 00:09:06,530
behavior challenges that we observe are

00:09:01,540 --> 00:09:08,960
with CF push right yeah not this is not

00:09:06,530 --> 00:09:11,930
again a generalization some of the apps

00:09:08,960 --> 00:09:13,640
again not intentional that slipped

00:09:11,930 --> 00:09:16,250
through the cracks and make it to

00:09:13,640 --> 00:09:17,840
production and the pushes takes longer

00:09:16,250 --> 00:09:20,330
than three minutes which is the default

00:09:17,840 --> 00:09:22,880
limit set by the platform and somehow

00:09:20,330 --> 00:09:25,490
the apps get pushed successfully by

00:09:22,880 --> 00:09:27,200
increasing the timeouts and then the

00:09:25,490 --> 00:09:29,060
admin the apps that are running on the

00:09:27,200 --> 00:09:30,920
platform takes longer than a second to

00:09:29,060 --> 00:09:32,690
pass the health check so they

00:09:30,920 --> 00:09:36,680
continuously crash and the platform is

00:09:32,690 --> 00:09:39,350
trying to bring them up so and then

00:09:36,680 --> 00:09:40,340
there are some apps which they think

00:09:39,350 --> 00:09:42,470
they don't want to go through this

00:09:40,340 --> 00:09:44,360
ramping down ramping up cycles so they

00:09:42,470 --> 00:09:46,430
kind of set the threshold way high like

00:09:44,360 --> 00:09:48,830
30 50 instances in order to take the

00:09:46,430 --> 00:09:50,510
production load and some apps go the

00:09:48,830 --> 00:09:52,700
other extreme they just go to one or two

00:09:50,510 --> 00:09:54,980
instances in production so we have seen

00:09:52,700 --> 00:09:57,200
all kinds of behavioral challenges with

00:09:54,980 --> 00:10:00,380
respect to the apps whether it's in

00:09:57,200 --> 00:10:02,990
though it's not intentional so the other

00:10:00,380 --> 00:10:05,600
part I just mentioned is autoscaler has

00:10:02,990 --> 00:10:07,520
some bugs and and and we noticed it and

00:10:05,600 --> 00:10:09,890
we kind of reported it it's kind of

00:10:07,520 --> 00:10:13,700
being worked upon with the respective

00:10:09,890 --> 00:10:15,380
teams so in a nutshell autoscaler is

00:10:13,700 --> 00:10:16,970
definitely a great place to start I

00:10:15,380 --> 00:10:19,160
would definitely recommend we should use

00:10:16,970 --> 00:10:20,780
it but it's not the end of all the

00:10:19,160 --> 00:10:25,640
problems that's the point I'm trying to

00:10:20,780 --> 00:10:27,800
make well so now that the the thing that

00:10:25,640 --> 00:10:30,050
is in our control is the app so let's

00:10:27,800 --> 00:10:31,970
start looking at apps what we can do in

00:10:30,050 --> 00:10:35,420
order to address some of the challenges

00:10:31,970 --> 00:10:38,210
that we just discussed a minute ago so

00:10:35,420 --> 00:10:40,130
we we are all already familiar right it

00:10:38,210 --> 00:10:40,640
it almost sounds like it started as

00:10:40,130 --> 00:10:42,500
today

00:10:40,640 --> 00:10:45,680
okay let's start breaking down the

00:10:42,500 --> 00:10:48,110
monoliths and into micro services now we

00:10:45,680 --> 00:10:49,940
are saying hey let's go break down this

00:10:48,110 --> 00:10:50,440
micro services into something even

00:10:49,940 --> 00:10:53,180
smaller

00:10:50,440 --> 00:10:56,690
we call them function some refer to them

00:10:53,180 --> 00:10:59,570
as even driven micro services yeah they

00:10:56,690 --> 00:11:01,160
can you can use them interchangeably so

00:10:59,570 --> 00:11:04,250
basically what we're trying to do is

00:11:01,160 --> 00:11:05,630
we're trying to break down these apps

00:11:04,250 --> 00:11:07,340
into much more smaller

00:11:05,630 --> 00:11:10,160
pieces so that we don't run into issues

00:11:07,340 --> 00:11:13,640
of you know SIA pushes taking longer

00:11:10,160 --> 00:11:16,160
health checks taking longer and and also

00:11:13,640 --> 00:11:18,140
the scaling on the autoscaler becomes a

00:11:16,160 --> 00:11:20,120
lot easier especially when the app

00:11:18,140 --> 00:11:22,640
starts in like within milliseconds

00:11:20,120 --> 00:11:24,830
within few milliseconds so one of the

00:11:22,640 --> 00:11:27,890
requirement for fast platform is that

00:11:24,830 --> 00:11:30,920
the function should start within like 20

00:11:27,890 --> 00:11:34,190
milliseconds in all the established Fast

00:11:30,920 --> 00:11:37,510
Pass platforms that we see so this kind

00:11:34,190 --> 00:11:40,970
of helps mitigate the the issue that we

00:11:37,510 --> 00:11:43,880
have seen before and also the beauty is

00:11:40,970 --> 00:11:45,770
these micro services and functions are

00:11:43,880 --> 00:11:48,050
event-driven micro services can coexist

00:11:45,770 --> 00:11:49,850
together and also you can chain them

00:11:48,050 --> 00:11:53,450
together just like how we are used to

00:11:49,850 --> 00:11:56,630
doing the UNIX kind of piping or Cheney

00:11:53,450 --> 00:12:01,700
so there are very important applications

00:11:56,630 --> 00:12:03,770
that we can leverage so let's look at

00:12:01,700 --> 00:12:06,860
some of the several as fast benefits

00:12:03,770 --> 00:12:09,440
right obviously less is more is what we

00:12:06,860 --> 00:12:12,590
are talking about we are going through

00:12:09,440 --> 00:12:15,050
breaking down these micro services are

00:12:12,590 --> 00:12:17,120
manageable services into much more

00:12:15,050 --> 00:12:21,440
smaller pieces the whole idea of

00:12:17,120 --> 00:12:24,350
breaking down is is the ideas so that we

00:12:21,440 --> 00:12:26,810
can develop and deploy and scale them

00:12:24,350 --> 00:12:27,970
independently and much faster way that's

00:12:26,810 --> 00:12:31,670
the whole idea

00:12:27,970 --> 00:12:33,260
and also it's easy to focus on and

00:12:31,670 --> 00:12:36,160
working on one function rather than

00:12:33,260 --> 00:12:38,870
working on a monolith or other service

00:12:36,160 --> 00:12:42,200
the other example this is not perfect

00:12:38,870 --> 00:12:44,540
let's let's take a restful api let's

00:12:42,200 --> 00:12:46,670
let's say accounts right slash accounts

00:12:44,540 --> 00:12:48,770
that as Bolivia typically contains five

00:12:46,670 --> 00:12:52,340
functions or methods get all with

00:12:48,770 --> 00:12:54,350
filters get by ID create an account

00:12:52,340 --> 00:12:56,900
which is slash post update an account

00:12:54,350 --> 00:12:58,910
slash put and delete an account and if

00:12:56,900 --> 00:13:01,730
you observe for at least from my

00:12:58,910 --> 00:13:03,230
experience for the most part fifty to

00:13:01,730 --> 00:13:06,500
sixty percent the time the guts are

00:13:03,230 --> 00:13:08,540
called heaviest and puts our posts are

00:13:06,500 --> 00:13:10,160
kind of in the middle the delete is at

00:13:08,540 --> 00:13:13,070
the rock bottom it's called like file

00:13:10,160 --> 00:13:14,870
less than five percent time so but still

00:13:13,070 --> 00:13:16,640
we are packaging all these functions

00:13:14,870 --> 00:13:18,440
together and then deploying it when it

00:13:16,640 --> 00:13:19,580
comes to scale we are scaling all of

00:13:18,440 --> 00:13:22,430
them together

00:13:19,580 --> 00:13:26,150
and only gets are used heavily right so

00:13:22,430 --> 00:13:28,550
we if what if we deploy more instances

00:13:26,150 --> 00:13:30,710
of GATS and five instances of delete

00:13:28,550 --> 00:13:34,130
that would kind of optimize the

00:13:30,710 --> 00:13:36,080
resources that's one example but what

00:13:34,130 --> 00:13:38,300
I'm getting there is I know it's not a

00:13:36,080 --> 00:13:40,970
perfect example there are some arguments

00:13:38,300 --> 00:13:42,680
against it how do you manage the

00:13:40,970 --> 00:13:45,830
database connections and everything like

00:13:42,680 --> 00:13:48,530
that but that's just an example to start

00:13:45,830 --> 00:13:51,230
with the most important reason is the

00:13:48,530 --> 00:13:54,440
cost and efficiency right we just talked

00:13:51,230 --> 00:13:57,410
about 200 a is that are running on the

00:13:54,440 --> 00:14:00,290
platform that whether whether there is a

00:13:57,410 --> 00:14:03,380
traffic or not right that that produce

00:14:00,290 --> 00:14:05,000
of waste would translate into a lot of

00:14:03,380 --> 00:14:09,560
cost savings which is the new currency

00:14:05,000 --> 00:14:13,550
and it could save capex and OPEX for a

00:14:09,560 --> 00:14:15,980
big big time for any enterprise the

00:14:13,550 --> 00:14:19,100
other important thing is the the way the

00:14:15,980 --> 00:14:21,110
pricing is done right in in pass world

00:14:19,100 --> 00:14:22,940
the pricing is done based on the number

00:14:21,110 --> 00:14:25,790
of areas that are running but in the

00:14:22,940 --> 00:14:28,880
fast world you're essentially paying for

00:14:25,790 --> 00:14:31,040
the actual execution time right even

00:14:28,880 --> 00:14:33,410
with the autoscaler so what do you say

00:14:31,040 --> 00:14:35,510
your account is it four thousand or two

00:14:33,410 --> 00:14:38,270
thousand because during the day you will

00:14:35,510 --> 00:14:39,680
be running four thousand and during

00:14:38,270 --> 00:14:41,840
offers let's say you will be running

00:14:39,680 --> 00:14:44,960
half of the capacity so that's kind of

00:14:41,840 --> 00:14:46,610
the calculation becomes tricky but when

00:14:44,960 --> 00:14:48,440
it comes to fast the pricing model is

00:14:46,610 --> 00:14:50,570
pretty clear you're just paying for the

00:14:48,440 --> 00:14:54,080
execution time but does it really

00:14:50,570 --> 00:14:56,060
translate to does it make really a huge

00:14:54,080 --> 00:14:59,240
difference so I just went ahead and

00:14:56,060 --> 00:15:01,970
tried one of the AWS calculator right I

00:14:59,240 --> 00:15:04,040
just tried an AWS lambda function and

00:15:01,970 --> 00:15:07,310
then I used two instance that is running

00:15:04,040 --> 00:15:10,400
on AWS API gateway I for the same number

00:15:07,310 --> 00:15:12,530
of calls that ever made or a period of

00:15:10,400 --> 00:15:15,440
month can you see the cost difference a

00:15:12,530 --> 00:15:18,830
dollar to a thousand is the isn't it

00:15:15,440 --> 00:15:21,290
like massive it always sounds like hey

00:15:18,830 --> 00:15:24,230
it might be you know it's not a big deal

00:15:21,290 --> 00:15:27,620
at the beginning but look at the cost

00:15:24,230 --> 00:15:29,300
differences right it is a massive cost

00:15:27,620 --> 00:15:31,460
difference so I think this is the most

00:15:29,300 --> 00:15:33,500
important factor that's driving towards

00:15:31,460 --> 00:15:36,740
going towards our less

00:15:33,500 --> 00:15:38,780
fast which is not something new which we

00:15:36,740 --> 00:15:43,460
are already kind of doing it it's just

00:15:38,780 --> 00:15:46,400
that we are a step behind well like any

00:15:43,460 --> 00:15:48,680
if like every other approach has pros

00:15:46,400 --> 00:15:50,870
and cons Savalas is not the perfect

00:15:48,680 --> 00:15:53,150
solution you cannot just because you can

00:15:50,870 --> 00:15:55,730
do even as fully appear in your function

00:15:53,150 --> 00:15:57,860
you should do it right just because you

00:15:55,730 --> 00:15:59,930
can do doesn't mean you should do it so

00:15:57,860 --> 00:16:02,660
there are always certain type of

00:15:59,930 --> 00:16:05,210
applications workloads that can go run

00:16:02,660 --> 00:16:07,190
on the soleus a platform some of the

00:16:05,210 --> 00:16:09,650
existing challenges as at least for now

00:16:07,190 --> 00:16:12,650
is the complexity again this is not

00:16:09,650 --> 00:16:14,410
something new for the fast platform this

00:16:12,650 --> 00:16:17,420
is also an existing challenge for the

00:16:14,410 --> 00:16:19,880
fast platform as well when you break

00:16:17,420 --> 00:16:21,710
down a monolith into micro services or

00:16:19,880 --> 00:16:23,570
there are functions or even - and micro

00:16:21,710 --> 00:16:25,310
services how do you arcus trade them

00:16:23,570 --> 00:16:29,300
together how do they talk to each other

00:16:25,310 --> 00:16:31,190
is always a challenge but luckily there

00:16:29,300 --> 00:16:33,260
are a few open source projects that are

00:16:31,190 --> 00:16:35,780
currently in progress

00:16:33,260 --> 00:16:37,160
this is an evolving space steel and on

00:16:35,780 --> 00:16:38,950
why you might have seen those talks

00:16:37,160 --> 00:16:42,200
trying to solve some of these problems

00:16:38,950 --> 00:16:45,380
of service discovery and sidecars and

00:16:42,200 --> 00:16:48,530
the second one is the cold start this is

00:16:45,380 --> 00:16:51,080
an interesting problem right when when

00:16:48,530 --> 00:16:53,150
the pass platform decides that there are

00:16:51,080 --> 00:16:55,700
no requests coming to a container it's

00:16:53,150 --> 00:16:57,350
going to tear it down and and whenever

00:16:55,700 --> 00:16:59,510
the new request comes it's going to spin

00:16:57,350 --> 00:17:01,430
up a new container what if there's a lag

00:16:59,510 --> 00:17:04,610
of like a couple of minutes right so

00:17:01,430 --> 00:17:06,829
that translate to the latency involved

00:17:04,610 --> 00:17:08,510
bringing up the container again to serve

00:17:06,829 --> 00:17:10,970
the request so this is one of the

00:17:08,510 --> 00:17:13,310
problem then fast was just beginning to

00:17:10,970 --> 00:17:15,709
start but now I don't think this is a

00:17:13,310 --> 00:17:17,600
huge problem there are different ways to

00:17:15,709 --> 00:17:20,569
keep the functions warm one is manually

00:17:17,600 --> 00:17:21,770
you can send requests but I don't think

00:17:20,569 --> 00:17:24,740
that's the best way to do it

00:17:21,770 --> 00:17:26,990
but now all the newer platforms allowing

00:17:24,740 --> 00:17:28,760
you to configure the interval how long

00:17:26,990 --> 00:17:29,840
you can keep the function warm before

00:17:28,760 --> 00:17:32,960
tearing it down

00:17:29,840 --> 00:17:36,080
I think there are ways to work with even

00:17:32,960 --> 00:17:38,390
cold starts the biggest challenge is the

00:17:36,080 --> 00:17:40,280
tooling as I mentioned this is still in

00:17:38,390 --> 00:17:41,510
our wall ring space how do we debug

00:17:40,280 --> 00:17:43,760
these functions because these are

00:17:41,510 --> 00:17:46,710
short-lived and how do we monitor them

00:17:43,760 --> 00:17:49,559
are dates logs integration testing we

00:17:46,710 --> 00:17:52,020
are still kind of elusive at the moment

00:17:49,559 --> 00:17:55,740
these are definitely need some summer

00:17:52,020 --> 00:17:57,480
maturity and tooling around it so these

00:17:55,740 --> 00:17:59,149
are some of the main challenges when it

00:17:57,480 --> 00:18:02,370
comes to solace

00:17:59,149 --> 00:18:04,890
so it's Ovilus being used anywhere or is

00:18:02,370 --> 00:18:07,500
it just in in theory no there are

00:18:04,890 --> 00:18:09,360
already some use cases that are being in

00:18:07,500 --> 00:18:13,200
already in place a lot of companies are

00:18:09,360 --> 00:18:15,299
using it at least for the line of

00:18:13,200 --> 00:18:18,630
business that Comcast is and we are into

00:18:15,299 --> 00:18:21,090
cable networking media entertainment and

00:18:18,630 --> 00:18:24,090
also home security home automation so

00:18:21,090 --> 00:18:26,880
some of the use cases that are relevant

00:18:24,090 --> 00:18:30,270
in in terms of comcast line of business

00:18:26,880 --> 00:18:32,340
in terms of IOT integration is we

00:18:30,270 --> 00:18:34,350
analyze a lot of media and image

00:18:32,340 --> 00:18:37,470
analysis so that we can provide

00:18:34,350 --> 00:18:39,270
recommendations and also with respect to

00:18:37,470 --> 00:18:41,700
customer service we need a lot of

00:18:39,270 --> 00:18:43,830
virtual assistant chat BOTS and also

00:18:41,700 --> 00:18:45,870
with mobile server less mobile backends

00:18:43,830 --> 00:18:47,789
and also some sort of machine learning

00:18:45,870 --> 00:18:50,130
workloads these are some of the use

00:18:47,789 --> 00:18:52,080
cases that are relevant because when we

00:18:50,130 --> 00:18:54,000
talk about fast for the most part

00:18:52,080 --> 00:18:56,039
everybody says hope I can use this for

00:18:54,000 --> 00:18:59,610
batch processing scheduling tasks and

00:18:56,039 --> 00:19:03,149
jobs but that that's not exactly true

00:18:59,610 --> 00:19:05,520
you can do it in multiple ways like with

00:19:03,149 --> 00:19:08,549
the Iowa to integration the other space

00:19:05,520 --> 00:19:11,610
that are potential use case is the homes

00:19:08,549 --> 00:19:14,370
automation and security we know all this

00:19:11,610 --> 00:19:16,710
is smart devices plugs and bulbs and

00:19:14,370 --> 00:19:19,620
smart sensors so we collect all the

00:19:16,710 --> 00:19:23,429
device telemetry data and then analyze

00:19:19,620 --> 00:19:26,010
it real time and also building smart

00:19:23,429 --> 00:19:28,440
homes and you might have seen the

00:19:26,010 --> 00:19:30,779
comcast technology center it's one of

00:19:28,440 --> 00:19:33,470
its kind you know definitely this

00:19:30,779 --> 00:19:39,059
technology enables building enables

00:19:33,470 --> 00:19:41,760
smart buildings so by now a quick

00:19:39,059 --> 00:19:44,909
summary is that we started with the

00:19:41,760 --> 00:19:47,039
existing platform some of the challenges

00:19:44,909 --> 00:19:49,350
that we are facing what is next how we

00:19:47,039 --> 00:19:52,080
can address these challenges and then

00:19:49,350 --> 00:19:54,029
fast seems to be a good fit for some of

00:19:52,080 --> 00:19:57,299
the workloads that I just talked about

00:19:54,029 --> 00:20:00,180
so by now you might be thinking sauer

00:19:57,299 --> 00:20:04,290
less right why not let's give it a shot

00:20:00,180 --> 00:20:07,920
so there is no shortage of options as a

00:20:04,290 --> 00:20:09,960
mansion in fact this is overwhelming to

00:20:07,920 --> 00:20:12,360
go through the vetting process to find

00:20:09,960 --> 00:20:16,080
out the one that best fits your

00:20:12,360 --> 00:20:20,280
ecosystem there are so many options both

00:20:16,080 --> 00:20:22,560
hosted as well as open source platforms

00:20:20,280 --> 00:20:24,120
for the scope of this talk because it's

00:20:22,560 --> 00:20:26,520
an open source conference I would like

00:20:24,120 --> 00:20:31,050
to limit this for all kinds of open

00:20:26,520 --> 00:20:32,850
source platforms so the the vetting

00:20:31,050 --> 00:20:36,480
process or the key selection criteria

00:20:32,850 --> 00:20:38,070
that I went through is nothing new the

00:20:36,480 --> 00:20:40,860
first thing that I looked is the trendy

00:20:38,070 --> 00:20:43,710
how is how many github commits are there

00:20:40,860 --> 00:20:46,770
how active the comments were made how

00:20:43,710 --> 00:20:49,530
many contributors were there and how

00:20:46,770 --> 00:20:51,180
many github stars were there and also I

00:20:49,530 --> 00:20:53,760
looked at the number of posts in Stack

00:20:51,180 --> 00:20:57,900
Overflow to see how the community is

00:20:53,760 --> 00:21:00,560
helping each other and it's growing the

00:20:57,900 --> 00:21:04,650
next thing I looked at the is the tools

00:21:00,560 --> 00:21:06,690
because right now things like docker is

00:21:04,650 --> 00:21:08,520
synonymous with containers kubernetes is

00:21:06,690 --> 00:21:11,130
synonymous with container Orchestrator

00:21:08,520 --> 00:21:13,710
Kafka synonymous with messaging though

00:21:11,130 --> 00:21:15,540
they can do much more you they can have

00:21:13,710 --> 00:21:18,120
much more use case so I just want to

00:21:15,540 --> 00:21:22,050
make sure the the platform uses set of

00:21:18,120 --> 00:21:26,060
standard tools so that we can it's easy

00:21:22,050 --> 00:21:28,860
to learn as these are pretty standard

00:21:26,060 --> 00:21:31,560
the other thing is while building

00:21:28,860 --> 00:21:33,300
managing the platform is it easy to get

00:21:31,560 --> 00:21:35,760
started with the existing documentation

00:21:33,300 --> 00:21:37,860
so I looked at the existing online dot

00:21:35,760 --> 00:21:40,260
machine is it just clear enough to get

00:21:37,860 --> 00:21:42,570
started and while managing the platform

00:21:40,260 --> 00:21:44,550
or while running the workloads just in

00:21:42,570 --> 00:21:47,040
case if I have questions is there at

00:21:44,550 --> 00:21:49,620
least a slack or an email support is is

00:21:47,040 --> 00:21:51,930
another thing I looked at and the other

00:21:49,620 --> 00:21:53,850
thing is what is this platform written

00:21:51,930 --> 00:21:56,400
in which language is it in golang or

00:21:53,850 --> 00:21:58,800
scale or what what the other languages

00:21:56,400 --> 00:22:01,020
that they used and at last but not the

00:21:58,800 --> 00:22:03,630
least for all this open source project

00:22:01,020 --> 00:22:06,180
who are the companies that are kind of

00:22:03,630 --> 00:22:10,950
backing up or supporting the ambach that

00:22:06,180 --> 00:22:12,690
has successful track records so this is

00:22:10,950 --> 00:22:14,010
like the bare minimum criteria but you

00:22:12,690 --> 00:22:17,250
can add more

00:22:14,010 --> 00:22:20,010
but this is how I started here are the

00:22:17,250 --> 00:22:23,400
numbers pretty much all my studies

00:22:20,010 --> 00:22:26,490
around this this sounds like a table but

00:22:23,400 --> 00:22:28,170
this is a lot of work as you can see the

00:22:26,490 --> 00:22:30,630
open risk has the highest number of

00:22:28,170 --> 00:22:36,030
github contributors and most of the

00:22:30,630 --> 00:22:37,620
contributors are from IBM in fact open

00:22:36,030 --> 00:22:39,650
risk is the core of the IBM cloud

00:22:37,620 --> 00:22:42,750
functions at least open risk is

00:22:39,650 --> 00:22:44,130
supported by Apache it's open source the

00:22:42,750 --> 00:22:46,920
other thing you would notice is pretty

00:22:44,130 --> 00:22:51,240
much all of this open source platform

00:22:46,920 --> 00:22:53,940
started somewhere in 2016 and pretty

00:22:51,240 --> 00:22:55,440
much all of them written in go except

00:22:53,940 --> 00:22:56,520
for the open Mis quiz which is written

00:22:55,440 --> 00:22:58,680
in Scala

00:22:56,520 --> 00:23:01,140
pretty much all of the platform uses

00:22:58,680 --> 00:23:04,140
dark current kubernetes for packaging

00:23:01,140 --> 00:23:06,180
and deploying functions and pretty much

00:23:04,140 --> 00:23:09,240
you can use ham charts to install any of

00:23:06,180 --> 00:23:13,080
them except for fission and iron

00:23:09,240 --> 00:23:15,420
functions most of these Ovilus platforms

00:23:13,080 --> 00:23:17,340
supports our lists are supported by

00:23:15,420 --> 00:23:19,190
serverless framework sovereignist

00:23:17,340 --> 00:23:22,740
frameworks allows it's really a

00:23:19,190 --> 00:23:24,780
fantastic thing because you wrote your

00:23:22,740 --> 00:23:27,570
cloud functions in AWS lambda now you

00:23:24,780 --> 00:23:29,310
want to run it and as your or are on IBM

00:23:27,570 --> 00:23:31,920
or even an open-source platforms like

00:23:29,310 --> 00:23:34,650
open fast so Savalas framework as the

00:23:31,920 --> 00:23:37,020
name indicates is a framework it's not a

00:23:34,650 --> 00:23:40,830
platform that allows you to write once

00:23:37,020 --> 00:23:47,160
but you can deploy it to any other fast

00:23:40,830 --> 00:23:49,380
platform and and as you can see even by

00:23:47,160 --> 00:23:52,170
the number of get commits made by the

00:23:49,380 --> 00:23:56,540
individual contributors are kind of more

00:23:52,170 --> 00:24:00,240
for open risk and some of the things

00:23:56,540 --> 00:24:01,650
around the technology is pretty much all

00:24:00,240 --> 00:24:05,490
of them are using Prometheus for

00:24:01,650 --> 00:24:07,830
collecting the matrix I mean it looks

00:24:05,490 --> 00:24:10,050
like pretty standard tool stack pretty

00:24:07,830 --> 00:24:12,570
much all of them but the other thing

00:24:10,050 --> 00:24:14,790
that you notice is the K native which is

00:24:12,570 --> 00:24:16,800
started somewhere last year which is

00:24:14,790 --> 00:24:19,590
which sounds like a newbie but it has

00:24:16,800 --> 00:24:21,990
catch up really fast and then now it's

00:24:19,590 --> 00:24:24,660
comparable with its contemporaries the

00:24:21,990 --> 00:24:27,210
reason is if you look at who are backing

00:24:24,660 --> 00:24:31,080
this project or sponsored by is

00:24:27,210 --> 00:24:32,549
Apache Google butyl IBM and Red Hat

00:24:31,080 --> 00:24:34,500
pretty much all the company's

00:24:32,549 --> 00:24:36,539
organization that have successful track

00:24:34,500 --> 00:24:39,840
records are kind of back in this project

00:24:36,539 --> 00:24:43,470
and and it's kind of really in in full

00:24:39,840 --> 00:24:47,159
swing but again the the it's still in

00:24:43,470 --> 00:24:49,500
our wallowing space though so and open

00:24:47,159 --> 00:24:52,470
fast is also pretty good and it's

00:24:49,500 --> 00:24:56,149
comparable it's backed by VMware the CLA

00:24:52,470 --> 00:24:59,850
is pretty easy to use and intuitive and

00:24:56,149 --> 00:25:02,159
you can connect open fast has a concept

00:24:59,850 --> 00:25:03,679
of EPA gateway you can use the CLI to

00:25:02,159 --> 00:25:06,029
connect synchronously or asynchronously

00:25:03,679 --> 00:25:07,500
pretty much all of them are using Nats

00:25:06,029 --> 00:25:10,620
messaging bus for asynchronous

00:25:07,500 --> 00:25:12,419
communication open risk I think they

00:25:10,620 --> 00:25:15,360
have put a lot of focus in terms of

00:25:12,419 --> 00:25:17,250
scalability and resiliency but the only

00:25:15,360 --> 00:25:19,679
thing is it requires developers or

00:25:17,250 --> 00:25:23,220
operators to have working knowledge of

00:25:19,679 --> 00:25:25,140
zookeeper couch CouchDB and Prometheus

00:25:23,220 --> 00:25:27,320
and things like that and for the most

00:25:25,140 --> 00:25:29,730
part I say I see some duplicate of

00:25:27,320 --> 00:25:31,890
overlap of functionality when using

00:25:29,730 --> 00:25:36,419
Couchbase or zookeeper when they're

00:25:31,890 --> 00:25:37,919
already using kubernetes I think and the

00:25:36,419 --> 00:25:40,919
other interesting thing I found was

00:25:37,919 --> 00:25:43,350
cublas cublas is purely built on

00:25:40,919 --> 00:25:46,020
kubernetes you can it does not require

00:25:43,350 --> 00:25:48,510
any custom CLI you can just use cubes it

00:25:46,020 --> 00:25:50,909
will cube CTL to deploy functions and

00:25:48,510 --> 00:25:51,419
they use custom resource definitions the

00:25:50,909 --> 00:25:53,549
ADIZ

00:25:51,419 --> 00:25:57,330
that's one pretty cool thing I find out

00:25:53,549 --> 00:26:00,149
which is also the approach taken by K

00:25:57,330 --> 00:26:03,750
native Canada uses C are these custom

00:26:00,149 --> 00:26:06,049
list definitions and uses sto and Envoy

00:26:03,750 --> 00:26:12,570
for service mash and discovery

00:26:06,049 --> 00:26:15,450
so overall this is the summary luckily

00:26:12,570 --> 00:26:17,990
there's nothing red here pretty much all

00:26:15,450 --> 00:26:21,440
Allah greens the most influenced

00:26:17,990 --> 00:26:24,600
influential factor here is the ecosystem

00:26:21,440 --> 00:26:26,309
because if you are already a part of the

00:26:24,600 --> 00:26:29,220
ecosystem as such as if you are already

00:26:26,309 --> 00:26:31,260
working on open source cloud foundry to

00:26:29,220 --> 00:26:32,730
be lot easier to leverage the tools on

00:26:31,260 --> 00:26:34,890
it or similarly if you are already

00:26:32,730 --> 00:26:38,309
working on AWS tools it will be lot

00:26:34,890 --> 00:26:40,630
easier to use AWS lambda so ecosystem

00:26:38,309 --> 00:26:42,640
definitely plays a critical role

00:26:40,630 --> 00:26:45,280
and kind of coming up with what exactly

00:26:42,640 --> 00:26:48,310
you wanted to go with that also helps

00:26:45,280 --> 00:26:50,440
with the learning curve and when it

00:26:48,310 --> 00:26:53,050
comes to the type of languages that this

00:26:50,440 --> 00:26:55,090
platform support pretty much all of them

00:26:53,050 --> 00:26:58,630
are using docker that means you can

00:26:55,090 --> 00:27:00,760
pretty much package any any any kind of

00:26:58,630 --> 00:27:02,710
function that you write in any language

00:27:00,760 --> 00:27:05,020
into your docker container and push it

00:27:02,710 --> 00:27:08,080
so I think in terms of the language

00:27:05,020 --> 00:27:10,180
support I think it's ok when it comes to

00:27:08,080 --> 00:27:13,690
reliability is what I just talked about

00:27:10,180 --> 00:27:16,510
who who is is the docs clear enough is

00:27:13,690 --> 00:27:18,600
is there any support with respect to

00:27:16,510 --> 00:27:21,040
slack are this backed by any

00:27:18,600 --> 00:27:23,230
organizations that has successful track

00:27:21,040 --> 00:27:25,060
records and things like that and the

00:27:23,230 --> 00:27:27,250
github activity that's happening is it

00:27:25,060 --> 00:27:29,830
active community so I think that kind of

00:27:27,250 --> 00:27:32,710
helps me to determine on the reliability

00:27:29,830 --> 00:27:34,450
factor so this is kind of this is not

00:27:32,710 --> 00:27:36,850
kind of a recommendation but these are

00:27:34,450 --> 00:27:40,600
kind of observations you can start from

00:27:36,850 --> 00:27:43,990
here when you're trying to choose your

00:27:40,600 --> 00:27:46,840
path platform so the other thing I tried

00:27:43,990 --> 00:27:49,480
was checking the Google Trends

00:27:46,840 --> 00:27:51,100
I just tried Google Trends and trying to

00:27:49,480 --> 00:27:53,410
compare with each of the existing open

00:27:51,100 --> 00:27:56,140
source platforms and this is what I find

00:27:53,410 --> 00:27:58,750
it and as I mentioned Kay native is kind

00:27:56,140 --> 00:28:00,910
of catching up really fast and it's kind

00:27:58,750 --> 00:28:03,340
of on the top of the charts pretty much

00:28:00,910 --> 00:28:05,730
consistently all through when compared

00:28:03,340 --> 00:28:10,960
to all other peers and contemporaries

00:28:05,730 --> 00:28:14,320
that's pretty interesting so of with all

00:28:10,960 --> 00:28:15,430
this study I would like to present a

00:28:14,320 --> 00:28:18,400
demo

00:28:15,430 --> 00:28:21,190
I chose Kennedy for the demo but the

00:28:18,400 --> 00:28:23,380
demo takes at least couple of hours so I

00:28:21,190 --> 00:28:25,390
kind of recorded it and squeezed it into

00:28:23,380 --> 00:28:33,130
like ten minutes so let's walk through

00:28:25,390 --> 00:28:36,490
the demo so so on a local cube so I

00:28:33,130 --> 00:28:39,220
chose mini cube to try this Kennedy of

00:28:36,490 --> 00:28:42,060
offering to see how simple it is from an

00:28:39,220 --> 00:28:44,590
T and installation updates and then

00:28:42,060 --> 00:28:47,410
deploying the workloads and testing them

00:28:44,590 --> 00:28:50,460
what kind of use cases it supports so

00:28:47,410 --> 00:28:50,460
let's run through this

00:28:57,840 --> 00:29:04,150
so I'm at the moment I'm installing a

00:29:00,970 --> 00:29:08,020
mini cube and then just checking crawl

00:29:04,150 --> 00:29:10,270
on the versions cube cuddle status then

00:29:08,020 --> 00:29:12,810
mini cube is up and running all the

00:29:10,270 --> 00:29:16,060
nodes up and running the cluster status

00:29:12,810 --> 00:29:21,700
and I'm using kale for kubernetes tail

00:29:16,060 --> 00:29:23,860
you can use given ad slots as well so

00:29:21,700 --> 00:29:25,630
this is the most important process of

00:29:23,860 --> 00:29:27,880
going through the key native install

00:29:25,630 --> 00:29:31,120
right k native uses custom resource

00:29:27,880 --> 00:29:34,360
definitions to install k native you

00:29:31,120 --> 00:29:36,520
could use direct download those yama

00:29:34,360 --> 00:29:38,830
files and install it or there is

00:29:36,520 --> 00:29:41,470
something cool called r if the project

00:29:38,830 --> 00:29:43,840
by pivotal you can use that to go

00:29:41,470 --> 00:29:46,030
through just roof system install will do

00:29:43,840 --> 00:29:48,430
the job for you the other thing I tried

00:29:46,030 --> 00:29:50,470
was because I'm doing it in my local I

00:29:48,430 --> 00:29:55,630
use the node port as the load balancer

00:29:50,470 --> 00:29:57,370
so this is one way to get the K native

00:29:55,630 --> 00:30:03,310
ingress when you are using an old port

00:29:57,370 --> 00:30:05,350
type so when you install Canadia the

00:30:03,310 --> 00:30:07,780
successful installation indicates that

00:30:05,350 --> 00:30:10,900
you have Bill serving and eventing

00:30:07,780 --> 00:30:12,730
module namespaces install so that kind

00:30:10,900 --> 00:30:14,890
of tells you the installation is

00:30:12,730 --> 00:30:17,350
successful so creative uses these

00:30:14,890 --> 00:30:19,300
concepts called serving build and

00:30:17,350 --> 00:30:22,270
eventing these are kind of really cool

00:30:19,300 --> 00:30:24,340
serving is actually you can even use

00:30:22,270 --> 00:30:27,280
your stateless micro services in

00:30:24,340 --> 00:30:30,730
addition to functions and eventing is

00:30:27,280 --> 00:30:32,980
eventing you can use functions to

00:30:30,730 --> 00:30:35,860
generate events and build is another

00:30:32,980 --> 00:30:38,830
cool thing they have started supporting

00:30:35,860 --> 00:30:40,990
build packs that are already kind of on

00:30:38,830 --> 00:30:43,120
the Cloud Foundry and also you can use

00:30:40,990 --> 00:30:44,230
your darker files to build images you

00:30:43,120 --> 00:30:46,210
don't have to do anything

00:30:44,230 --> 00:30:48,850
carbonate is detects it using build

00:30:46,210 --> 00:30:51,250
templates called Kenny Co and then

00:30:48,850 --> 00:30:54,340
builds the docker image and then pushes

00:30:51,250 --> 00:30:56,620
it to the docker repo that that internal

00:30:54,340 --> 00:30:58,630
dark report public Doppler doc repo

00:30:56,620 --> 00:31:02,350
whatever that you configure during the

00:30:58,630 --> 00:31:04,150
installation so this is just me trying

00:31:02,350 --> 00:31:06,190
the blue-green deployment

00:31:04,150 --> 00:31:17,470
in comparison to Cloud Foundry how we

00:31:06,190 --> 00:31:25,270
can how I can do this so the same thing

00:31:17,470 --> 00:31:29,320
I'm gonna create a namespace so I'm

00:31:25,270 --> 00:31:31,120
watching the kubernetes parts at this

00:31:29,320 --> 00:31:34,030
point I'm building a simple docker image

00:31:31,120 --> 00:31:38,320
that kind of takes HTTP requests and

00:31:34,030 --> 00:31:41,410
sends a response back and I'm pushing it

00:31:38,320 --> 00:31:43,360
to dark repo so here's the important

00:31:41,410 --> 00:31:45,850
thing all this code is on github it's

00:31:43,360 --> 00:31:47,710
going to be open so shortly and this

00:31:45,850 --> 00:31:52,780
will be available so you can try it

00:31:47,710 --> 00:31:54,520
later so all I did was if you see that

00:31:52,780 --> 00:31:57,490
that's all the installation is all but

00:31:54,520 --> 00:32:00,460
all I did was apply config yamo is the

00:31:57,490 --> 00:32:04,240
bare minimum that is required to deploy

00:32:00,460 --> 00:32:06,700
any microt service as you can see all

00:32:04,240 --> 00:32:09,310
the parts and up and running and the

00:32:06,700 --> 00:32:13,540
deployment is complete the parts are

00:32:09,310 --> 00:32:14,890
coming up three by three and if you

00:32:13,540 --> 00:32:18,610
notice there is something called

00:32:14,890 --> 00:32:22,540
revisions and configuration and routes

00:32:18,610 --> 00:32:25,660
if you can see the route has a row URL

00:32:22,540 --> 00:32:28,330
that you can use to curl so that's what

00:32:25,660 --> 00:32:31,120
I'm trying to do right now I deployed

00:32:28,330 --> 00:32:34,300
the version one the code is on github

00:32:31,120 --> 00:32:37,510
and my docker image is pushed to docker

00:32:34,300 --> 00:32:43,510
I didn't do anything right so it's all

00:32:37,510 --> 00:32:47,050
the magic so as you can see now I

00:32:43,510 --> 00:32:48,880
completely move to the version to the if

00:32:47,050 --> 00:32:51,310
you notice I'm running this in a loop

00:32:48,880 --> 00:32:53,170
this is what I meant by cold-start so

00:32:51,310 --> 00:32:55,270
usually these functions when you don't

00:32:53,170 --> 00:32:58,600
invoke it and keeps if you keep it ideal

00:32:55,270 --> 00:33:00,640
for a minute the the platform will tear

00:32:58,600 --> 00:33:02,140
it down so you cannot really make a

00:33:00,640 --> 00:33:03,790
request when you make a fresh request

00:33:02,140 --> 00:33:08,170
it's going to take a little bit little

00:33:03,790 --> 00:33:09,940
while until the content comes up so for

00:33:08,170 --> 00:33:12,070
the sake of demo I just need to keep

00:33:09,940 --> 00:33:15,640
this functions warm so I'm just running

00:33:12,070 --> 00:33:16,330
in the loop so you look at that you can

00:33:15,640 --> 00:33:17,920
still do it

00:33:16,330 --> 00:33:19,660
you can still deploy your

00:33:17,920 --> 00:33:21,400
let's micro-service you can you can

00:33:19,660 --> 00:33:23,710
still do your do your Bluegreen

00:33:21,400 --> 00:33:25,450
deployment and not only that we we also

00:33:23,710 --> 00:33:27,520
tried the weighted routing where I'm

00:33:25,450 --> 00:33:30,190
splitting the traffic 100% between

00:33:27,520 --> 00:33:33,550
version 1 and version 2 I really find

00:33:30,190 --> 00:33:36,580
that really cool without doing much work

00:33:33,550 --> 00:33:41,020
it is pretty much like ZF the latest CF

00:33:36,580 --> 00:33:42,760
demo that we have seen as today so the

00:33:41,020 --> 00:33:44,920
next thing I want to talk about how all

00:33:42,760 --> 00:33:46,180
this magic say is happening right so

00:33:44,920 --> 00:33:49,570
what are the bill packs and the

00:33:46,180 --> 00:33:52,570
templates that can a two supports can

00:33:49,570 --> 00:33:55,060
ativ uses can eco build templates for

00:33:52,570 --> 00:33:57,100
now to build the docker images and it

00:33:55,060 --> 00:34:00,760
uses any of the existing cloud 400 build

00:33:57,100 --> 00:34:03,550
packs to deploy any other you just push

00:34:00,760 --> 00:34:06,220
the code keanae to determines based on

00:34:03,550 --> 00:34:07,990
the code whether it's java or node and

00:34:06,220 --> 00:34:09,760
it looks for the cloud 400 build packs

00:34:07,990 --> 00:34:12,460
and uses that built back to build it so

00:34:09,760 --> 00:34:14,640
that's another thing really cool I find

00:34:12,460 --> 00:34:14,640
it

00:34:25,349 --> 00:34:30,490
so I'm watching for the parts as you

00:34:28,480 --> 00:34:43,119
notice there's just a darker file that's

00:34:30,490 --> 00:34:44,829
all I provide so that is the custom

00:34:43,119 --> 00:34:50,099
recess definition that I have to apply

00:34:44,829 --> 00:34:50,099
one time that's called koneko dot llamo

00:34:50,549 --> 00:34:55,299
so the most important thing that you

00:34:53,500 --> 00:34:57,099
would notice here I'm creating secrets

00:34:55,299 --> 00:35:00,910
and service accounts so that I can

00:34:57,099 --> 00:35:04,029
connect to the darker repo I'm

00:35:00,910 --> 00:35:09,279
leveraging the existing kubernetes

00:35:04,029 --> 00:35:12,250
secrets and service accounts and then I

00:35:09,279 --> 00:35:18,220
get the tentative ingress the same way

00:35:12,250 --> 00:35:20,859
because I'm using node port so the code

00:35:18,220 --> 00:35:25,299
is in github and it's as you can see the

00:35:20,859 --> 00:35:25,690
image is pushed and now I can I can call

00:35:25,299 --> 00:35:28,930
it

00:35:25,690 --> 00:35:32,799
using host headers and you can see the

00:35:28,930 --> 00:35:35,680
bill pack is created now I'm using CF

00:35:32,799 --> 00:35:37,779
bill pack instead of using Conoco as you

00:35:35,680 --> 00:35:40,269
can see there's no docker file here this

00:35:37,779 --> 00:35:42,250
is I think a node app yeah this is a

00:35:40,269 --> 00:35:45,220
node.js now let's see if it builds it or

00:35:42,250 --> 00:35:46,960
not the same thing I'm going to create

00:35:45,220 --> 00:35:54,039
secrets and service accounts create a

00:35:46,960 --> 00:36:01,480
different namespace set the key native

00:35:54,039 --> 00:36:07,750
ingress there you go you can see the

00:36:01,480 --> 00:36:09,640
parts coming up yeah so now the entire

00:36:07,750 --> 00:36:12,190
application is built using node.js built

00:36:09,640 --> 00:36:14,529
back so the latest build pack is pushed

00:36:12,190 --> 00:36:17,529
to docker repo and the core is here so

00:36:14,529 --> 00:36:20,500
basically all it's trying to do is it's

00:36:17,529 --> 00:36:22,569
pulling the source code from github repo

00:36:20,500 --> 00:36:26,250
and it's checking whether it's a node.js

00:36:22,569 --> 00:36:28,329
or Java app and pulling the entire

00:36:26,250 --> 00:36:31,619
source code and building the docker

00:36:28,329 --> 00:36:31,619
image and deploying it

00:36:38,620 --> 00:36:43,150
so this is using riff this is the most

00:36:40,780 --> 00:36:45,460
powerful use case that I tried what I

00:36:43,150 --> 00:36:48,240
tried was I created as process a

00:36:45,460 --> 00:36:50,860
function that kind of takes some

00:36:48,240 --> 00:36:52,930
messages from a queue and then encourse

00:36:50,860 --> 00:36:54,730
it and then puts it in another massive

00:36:52,930 --> 00:36:56,650
another queue call and coded messages

00:36:54,730 --> 00:36:58,360
and there's another process or a

00:36:56,650 --> 00:37:01,450
function that kind of decodes this

00:36:58,360 --> 00:37:04,060
message and then displays it this is a

00:37:01,450 --> 00:37:09,820
powerful abstraction of the use case

00:37:04,060 --> 00:37:15,490
that we can leverage using K native as

00:37:09,820 --> 00:37:17,890
you can see I pushed the Java code so

00:37:15,490 --> 00:37:22,720
I'm able to encode the message that I'm

00:37:17,890 --> 00:37:24,370
sending see as you can see Rufus it's

00:37:22,720 --> 00:37:28,690
detecting the Cloud Foundry built back

00:37:24,370 --> 00:37:30,280
and it's building it you already see the

00:37:28,690 --> 00:37:33,310
parts for message encoder

00:37:30,280 --> 00:37:34,990
now the decoder is coming up also the

00:37:33,310 --> 00:37:37,360
interesting thing that you notice is the

00:37:34,990 --> 00:37:40,870
message channels as you can see plain

00:37:37,360 --> 00:37:48,970
messages and encoded messages those are

00:37:40,870 --> 00:37:51,220
the cues or channels all right so I'm

00:37:48,970 --> 00:37:55,630
creating a channel I'm creating a

00:37:51,220 --> 00:38:01,540
subscription as you can see all those

00:37:55,630 --> 00:38:03,460
parts are available so you have a

00:38:01,540 --> 00:38:05,710
messaging channel you have a subscriber

00:38:03,460 --> 00:38:07,950
you have functions that you can attach

00:38:05,710 --> 00:38:07,950
to

00:38:11,300 --> 00:38:15,860
so this is the thing that I was talking

00:38:13,340 --> 00:38:18,350
about cold start especially to keep them

00:38:15,860 --> 00:38:20,720
warm all the code is on github this is

00:38:18,350 --> 00:38:22,730
spring boot app a decoder and encoder

00:38:20,720 --> 00:38:24,530
all the docker images were pushed

00:38:22,730 --> 00:38:28,100
automatically using this secrets in

00:38:24,530 --> 00:38:30,500
service account now the for for the sake

00:38:28,100 --> 00:38:31,940
of time all I did was I was connecting

00:38:30,500 --> 00:38:34,369
to one of the pod within that cluster

00:38:31,940 --> 00:38:36,770
and I'm posting the messages on the

00:38:34,369 --> 00:38:39,440
queue that is on plane messages as you

00:38:36,770 --> 00:38:41,300
can see the encoder and decoder the

00:38:39,440 --> 00:38:43,130
encoder is reading it and coding it

00:38:41,300 --> 00:38:45,500
putting it back on the encoded messages

00:38:43,130 --> 00:38:48,380
and the decoder decoder is reading it

00:38:45,500 --> 00:39:02,570
and and putting it back into the plane

00:38:48,380 --> 00:39:03,740
message and that's it so thanks thanks

00:39:02,570 --> 00:39:04,930
for attending and thanks for watching

00:39:03,740 --> 00:39:07,890
the demo

00:39:04,930 --> 00:39:07,890

YouTube URL: https://www.youtube.com/watch?v=vN6mLhESIi0


