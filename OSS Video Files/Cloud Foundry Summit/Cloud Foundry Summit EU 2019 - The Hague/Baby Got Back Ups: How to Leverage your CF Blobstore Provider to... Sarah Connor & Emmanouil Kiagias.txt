Title: Baby Got Back Ups: How to Leverage your CF Blobstore Provider to... Sarah Connor & Emmanouil Kiagias
Publication date: 2019-09-13
Playlist: Cloud Foundry Summit EU 2019 - The Hague
Description: 
	Baby Got Back Ups: How to Leverage your CF Blobstore Provider to Improve your Backup Experience - Sarah Connor & Emmanouil Kiagias, Pivotal Cloud Foundry 

Regardless of how sturdy a platform is setup, disasters are inevitable and a platform will need to be restored. Usually, backups can be a headache to maintain, can take ages to complete and can start to eat away at storage costs. Often times the decision is made to reduce the frequency or even stop taking backups at all!  The BOSH Backup and Restore cli can be used to backup and restore a CF foundation and provides a solid experience if configured properly.  This talk will cover how the setup of your platform impacts the size, speed and lifecycle management of your BBR backups. Different storage providers such as GCS, AWS S3, S3 compatible and WebDAV affect how the BBR cli backs up your CF deployment blobstore leading to a significant difference in the backup experience. Having a better understanding of these differences allows you make an informed decision about your backup strategy. 

For more info: https://www.cloudfoundry.org/
Captions: 
	00:00:00,089 --> 00:00:10,740
hello everyone hello welcome to our talk

00:00:06,350 --> 00:00:12,630
this is baby got backups or also known

00:00:10,740 --> 00:00:13,920
as how to leverage your CF co-op store

00:00:12,630 --> 00:00:18,859
provider to improve your backup

00:00:13,920 --> 00:00:18,859
experience I can see you're all excited

00:00:31,520 --> 00:00:46,160
it's not going imagine if we hadn't

00:00:35,090 --> 00:00:49,400
tested yeah isn't the downward alright

00:00:46,160 --> 00:00:51,379
so on that wonderful awkward note I'm

00:00:49,400 --> 00:00:54,019
Sarah Connor I am an engineering manager

00:00:51,379 --> 00:00:58,040
at pivotal and an engineer on the

00:00:54,019 --> 00:01:00,050
platform of coveri team and a manager

00:00:58,040 --> 00:01:03,230
some software engineer a platform

00:01:00,050 --> 00:01:05,059
recovery team we work together so in our

00:01:03,230 --> 00:01:06,979
today's talk let's look at a bid we'd

00:01:05,059 --> 00:01:08,960
like the agenda how do look like we're

00:01:06,979 --> 00:01:11,270
gonna throw we're gonna go through a

00:01:08,960 --> 00:01:12,979
bunch of stuff oh we're gonna talk about

00:01:11,270 --> 00:01:14,930
why backups are important we're gonna

00:01:12,979 --> 00:01:16,220
talk how the world looks like today then

00:01:14,930 --> 00:01:18,350
we're gonna see what's the aspects of

00:01:16,220 --> 00:01:20,299
backup that we care about and then we're

00:01:18,350 --> 00:01:21,979
gonna see how different blobs those

00:01:20,299 --> 00:01:24,260
backups are that this affect your whole

00:01:21,979 --> 00:01:25,490
backup experience and mainly internal

00:01:24,260 --> 00:01:28,159
versus external and then we're gonna

00:01:25,490 --> 00:01:29,270
visit them one by one then the big

00:01:28,159 --> 00:01:30,979
question do I really need to backup

00:01:29,270 --> 00:01:32,090
everything after all gonna do a recap

00:01:30,979 --> 00:01:35,299
and talk a little bit about the future

00:01:32,090 --> 00:01:36,530
depending on time so let's get this out

00:01:35,299 --> 00:01:38,270
of the picture we know the backups are

00:01:36,530 --> 00:01:39,829
important right so that's why we're here

00:01:38,270 --> 00:01:42,289
for let's look how the world looks like

00:01:39,829 --> 00:01:43,880
today so you get boss and then boss

00:01:42,289 --> 00:01:45,649
deploys your cloud foundry that you have

00:01:43,880 --> 00:01:47,719
most back up a tree so it's really backs

00:01:45,649 --> 00:01:49,520
up both of them but today we mainly

00:01:47,719 --> 00:01:51,320
gonna talk about like la foundry which

00:01:49,520 --> 00:01:53,270
has like many components but if you

00:01:51,320 --> 00:01:55,009
think about it it always goes down into

00:01:53,270 --> 00:01:56,539
stuff like a database and a blob so

00:01:55,009 --> 00:01:57,859
that's where the state is that's what we

00:01:56,539 --> 00:01:59,689
really want to backup and we're gonna

00:01:57,859 --> 00:02:02,329
focus mainly on the blob so the things

00:01:59,689 --> 00:02:04,009
we care about here like the DB Dom's

00:02:02,329 --> 00:02:06,170
usually contain information like users

00:02:04,009 --> 00:02:08,119
all spaces bindings credentials and this

00:02:06,170 --> 00:02:09,500
stuff don't really go very big so we

00:02:08,119 --> 00:02:11,030
don't really have trouble backing that

00:02:09,500 --> 00:02:12,650
up but we have problems backing up the

00:02:11,030 --> 00:02:14,540
blob store which has all the application

00:02:12,650 --> 00:02:17,300
artifacts which are like source code

00:02:14,540 --> 00:02:18,470
compile artifacts build backs everything

00:02:17,300 --> 00:02:20,540
and that's like grows big and bigger

00:02:18,470 --> 00:02:23,210
that's what's caused some problems in

00:02:20,540 --> 00:02:33,069
our experience now going to see the

00:02:23,210 --> 00:02:36,170
aspects of the backup sure very frequent

00:02:33,069 --> 00:02:38,720
you want very minimal about downtime you

00:02:36,170 --> 00:02:40,820
want your size of backups to be not too

00:02:38,720 --> 00:02:42,960
great because none of us wants to eat

00:02:40,820 --> 00:02:45,660
away storage cost based off of

00:02:42,960 --> 00:02:50,070
giant back up and you want that recovery

00:02:45,660 --> 00:02:52,560
period of time to be very small so we've

00:02:50,070 --> 00:02:55,290
got our boss director we've managed to

00:02:52,560 --> 00:02:57,470
deploy our CF and we started creating

00:02:55,290 --> 00:02:59,430
orgs and spaces and our application

00:02:57,470 --> 00:03:01,320
developers are now up and running they

00:02:59,430 --> 00:03:02,580
can start to pull you know their hot dog

00:03:01,320 --> 00:03:06,600
vendor app you've got some internal

00:03:02,580 --> 00:03:08,700
networking apps in another org but then

00:03:06,600 --> 00:03:10,050
everything goes on fire and that's where

00:03:08,700 --> 00:03:13,010
we start to panic that's where we're

00:03:10,050 --> 00:03:15,390
really in a situation where everything's

00:03:13,010 --> 00:03:17,540
not so great and you'd like no one to

00:03:15,390 --> 00:03:20,070
talk to you intend to interrupt you or

00:03:17,540 --> 00:03:22,320
just you know don't talk to me until

00:03:20,070 --> 00:03:24,900
this is back up and running so we're

00:03:22,320 --> 00:03:26,970
gonna talk about backup frequency if you

00:03:24,900 --> 00:03:28,530
had a backup and it was taken you know

00:03:26,970 --> 00:03:30,840
last week maybe the only thing that you

00:03:28,530 --> 00:03:32,430
lost was your hot dog vendor website and

00:03:30,840 --> 00:03:33,860
that's great you can just be push that

00:03:32,430 --> 00:03:37,380
one app and you're up and running again

00:03:33,860 --> 00:03:39,150
if maybe it was slightly older backup

00:03:37,380 --> 00:03:40,770
maybe you've lost your entire orbs and

00:03:39,150 --> 00:03:43,230
spaces maybe you have to recreate some

00:03:40,770 --> 00:03:44,940
users and you take more time to get back

00:03:43,230 --> 00:03:47,130
up and running

00:03:44,940 --> 00:03:48,780
maybe it's an even older backup maybe

00:03:47,130 --> 00:03:51,000
you only backed up your boss director

00:03:48,780 --> 00:03:52,290
and you are probably in a not a good

00:03:51,000 --> 00:03:54,690
situation you have to get everything

00:03:52,290 --> 00:03:56,760
back up so the more frequent your

00:03:54,690 --> 00:03:58,950
backups the last data you are losing the

00:03:56,760 --> 00:04:01,740
less time it takes to get back and up

00:03:58,950 --> 00:04:06,420
and running so let's talk about backup

00:04:01,740 --> 00:04:08,040
downtime so the are we talk about bbr it

00:04:06,420 --> 00:04:10,920
stands for a Bosch backup and restore

00:04:08,040 --> 00:04:13,650
it's a CLI originally designed to backup

00:04:10,920 --> 00:04:17,250
the Bosch director and it now is able to

00:04:13,650 --> 00:04:19,560
back up any sort of flash deployment it

00:04:17,250 --> 00:04:23,280
has four stages one is the lock phase

00:04:19,560 --> 00:04:25,050
this is each component tells the bbr CLI

00:04:23,280 --> 00:04:27,150
what it needs to walk up and in what

00:04:25,050 --> 00:04:28,710
order so this could be like you a a

00:04:27,150 --> 00:04:30,570
needs to lock up before crap out that

00:04:28,710 --> 00:04:32,790
sort of thing at that point we have a

00:04:30,570 --> 00:04:35,010
backup which is the actual physical

00:04:32,790 --> 00:04:37,410
copying the files DB dumps that sort of

00:04:35,010 --> 00:04:40,800
thing then we unlock and then we need to

00:04:37,410 --> 00:04:43,410
drain the backup artifacts off to your

00:04:40,800 --> 00:04:46,560
GEB box so what that looks like is we

00:04:43,410 --> 00:04:48,900
have a jump box it has you were running

00:04:46,560 --> 00:04:51,360
maybe our deployment deployments CF back

00:04:48,900 --> 00:04:55,600
up from that jump box it communicates to

00:04:51,360 --> 00:04:58,510
CF CF locks all of its ap ice

00:04:55,600 --> 00:05:02,110
and then starts to create the backup

00:04:58,510 --> 00:05:04,720
artifact locally within IBM and then at

00:05:02,110 --> 00:05:10,870
that point it unlocks its CF API and

00:05:04,720 --> 00:05:13,030
then starts to drain to the jump fox the

00:05:10,870 --> 00:05:14,800
more things in your CF deployment that

00:05:13,030 --> 00:05:19,420
you are backing up the longer this

00:05:14,800 --> 00:05:21,040
backup will take so just a recap of

00:05:19,420 --> 00:05:22,480
things that we are really aiming for

00:05:21,040 --> 00:05:26,080
when we talk about a really good backup

00:05:22,480 --> 00:05:27,430
strategy is minimal data loss minimal

00:05:26,080 --> 00:05:29,380
storage costs related to those backup

00:05:27,430 --> 00:05:32,470
artifacts and then also minimal downtime

00:05:29,380 --> 00:05:34,150
and at the very good one which is the

00:05:32,470 --> 00:05:36,640
low recovery time objective which is

00:05:34,150 --> 00:05:38,680
your RTO we really don't want to have to

00:05:36,640 --> 00:05:40,930
take that recovery time to take you know

00:05:38,680 --> 00:05:42,760
hours days weeks we want to be up and

00:05:40,930 --> 00:05:46,510
running within you know matters and

00:05:42,760 --> 00:05:48,310
minutes so I want my backups often I

00:05:46,510 --> 00:05:53,980
want my backups fast and one way backup

00:05:48,310 --> 00:05:56,680
small and I want to recover fast thank

00:05:53,980 --> 00:05:59,260
you sir so now we have a distinction now

00:05:56,680 --> 00:06:00,970
heads between the downtime in the

00:05:59,260 --> 00:06:02,980
overall backup time like the downtime is

00:06:00,970 --> 00:06:04,390
only when the platform is locked and

00:06:02,980 --> 00:06:05,950
then the backup time is the end-to-end

00:06:04,390 --> 00:06:07,810
until you get the backup artifact down

00:06:05,950 --> 00:06:10,060
now let's see if you have an internal

00:06:07,810 --> 00:06:11,680
blob saw the blob so lives inside this

00:06:10,060 --> 00:06:14,560
big like cloud which is your foundation

00:06:11,680 --> 00:06:16,540
so if something goes wrong with this

00:06:14,560 --> 00:06:18,220
thing here and cut this file then you

00:06:16,540 --> 00:06:20,050
lose all of your blob so it's very

00:06:18,220 --> 00:06:21,640
critical to get things out of there so

00:06:20,050 --> 00:06:23,260
in our case we need to get it out if

00:06:21,640 --> 00:06:25,870
it's an Intel of blob so like a web dub

00:06:23,260 --> 00:06:27,520
and if things got so far your deployment

00:06:25,870 --> 00:06:29,560
used to have your blobs outside there

00:06:27,520 --> 00:06:31,660
and you are covered now so the internal

00:06:29,560 --> 00:06:33,190
blob society's PD straightforward you

00:06:31,660 --> 00:06:34,690
just copy all the blobs and get it out

00:06:33,190 --> 00:06:37,030
of the deployment it's as simple as that

00:06:34,690 --> 00:06:39,190
and the blob start part looks something

00:06:37,030 --> 00:06:42,940
like that you have a number of blobs and

00:06:39,190 --> 00:06:45,520
you have some checksum for them so the

00:06:42,940 --> 00:06:46,990
local copy of the of the blobs is fast

00:06:45,520 --> 00:06:48,580
because we just create some hard links

00:06:46,990 --> 00:06:50,650
like in the local copy the thing that is

00:06:48,580 --> 00:06:52,180
takes role a lots of time is to drain

00:06:50,650 --> 00:06:53,680
all these things outside of the

00:06:52,180 --> 00:06:55,360
deployment you have one terabyte of blob

00:06:53,680 --> 00:06:56,830
so you need to download the terabyte to

00:06:55,360 --> 00:06:58,540
your example so wherever you run the

00:06:56,830 --> 00:07:00,820
backup from so that ends up being having

00:06:58,540 --> 00:07:03,070
a very big artifact because it contains

00:07:00,820 --> 00:07:04,960
all of the blobs and so it's aspects

00:07:03,070 --> 00:07:07,060
this has a sort downtime because it's

00:07:04,960 --> 00:07:08,590
just the hard links so good here but the

00:07:07,060 --> 00:07:09,310
long backup time because you need to get

00:07:08,590 --> 00:07:11,320
everything else

00:07:09,310 --> 00:07:13,570
sir you need to get everything out of

00:07:11,320 --> 00:07:14,800
there and you need a big buck apart the

00:07:13,570 --> 00:07:17,440
fact you end up having all of your

00:07:14,800 --> 00:07:18,850
blobstore local now in the situation

00:07:17,440 --> 00:07:20,350
where we have our blob stored in a

00:07:18,850 --> 00:07:23,530
storage provided the Pyxis looks like

00:07:20,350 --> 00:07:25,360
that one might say if my brought blob

00:07:23,530 --> 00:07:27,580
store is outside and things cans on fire

00:07:25,360 --> 00:07:29,770
then I still have my blobs are out it's

00:07:27,580 --> 00:07:32,410
partially true then what happens if you

00:07:29,770 --> 00:07:34,060
just manually delete a space then you're

00:07:32,410 --> 00:07:36,670
screwed because you don't have your

00:07:34,060 --> 00:07:38,650
blobs again so we really lose there I

00:07:36,670 --> 00:07:41,260
even if you even if we have them outside

00:07:38,650 --> 00:07:43,270
of your foundation so what do we do that

00:07:41,260 --> 00:07:45,130
we need we really need to back up a set

00:07:43,270 --> 00:07:46,750
of lobsters we come with these flavors

00:07:45,130 --> 00:07:48,730
right so Cloud Foundry can be configured

00:07:46,750 --> 00:07:51,640
with an s3 as the compatible blob sauce

00:07:48,730 --> 00:07:54,490
as you and this yes and let's thinking

00:07:51,640 --> 00:07:55,960
about how do we back it up can the

00:07:54,490 --> 00:07:58,780
service providers give us any small

00:07:55,960 --> 00:08:00,580
smarter ways to think of backing up of

00:07:58,780 --> 00:08:02,170
just like copying the blobs and the

00:08:00,580 --> 00:08:04,090
answer is sure most of the times and

00:08:02,170 --> 00:08:07,120
we're going to explore one by one let's

00:08:04,090 --> 00:08:10,660
start with us three so in the regular s3

00:08:07,120 --> 00:08:12,220
setup you're going to have a bucket and

00:08:10,660 --> 00:08:14,260
inside the bucket in time one you just

00:08:12,220 --> 00:08:16,000
have free apps or like three blobs NPHC

00:08:14,260 --> 00:08:18,010
and then imagine a time to greater than

00:08:16,000 --> 00:08:19,570
one you can just delete an apple just

00:08:18,010 --> 00:08:23,260
change the name and leaves you end up

00:08:19,570 --> 00:08:25,360
with being cs3 Nahas versioning let's

00:08:23,260 --> 00:08:26,890
see how the versioning feature of tree

00:08:25,360 --> 00:08:28,210
looks like in an s3 with version in

00:08:26,890 --> 00:08:30,070
greater having a bucket but now this

00:08:28,210 --> 00:08:32,080
time your blobs have also varies on IDs

00:08:30,070 --> 00:08:34,570
you have like version 1 2 and 3 which

00:08:32,080 --> 00:08:36,670
are like unique IDs for these blobs so

00:08:34,570 --> 00:08:38,830
infinite time - you just change a or

00:08:36,670 --> 00:08:41,080
delete a for instance instead of having

00:08:38,830 --> 00:08:43,180
that removed you essentially have the

00:08:41,080 --> 00:08:45,100
old a stay around and then a new version

00:08:43,180 --> 00:08:47,380
of a gets created so in that case our

00:08:45,100 --> 00:08:49,660
backup artifact consists of just taking

00:08:47,380 --> 00:08:51,700
a record of these things so the backup

00:08:49,660 --> 00:08:53,320
started Z looks like that list all the

00:08:51,700 --> 00:08:54,700
letters were sort of blobs record these

00:08:53,320 --> 00:08:56,170
versions and then we are done and the

00:08:54,700 --> 00:08:57,610
backup artifact is as simple as that you

00:08:56,170 --> 00:08:58,960
have the list of keys and then the

00:08:57,610 --> 00:09:01,270
version IDs so it's fairly

00:08:58,960 --> 00:09:04,330
straightforward so the backup is fast

00:09:01,270 --> 00:09:07,060
because it's as slow as it takes to list

00:09:04,330 --> 00:09:08,350
all of the blobs that is then the

00:09:07,060 --> 00:09:09,790
artifact is small because just like a

00:09:08,350 --> 00:09:12,670
text file containing just the version

00:09:09,790 --> 00:09:15,730
IDs and the backup is yeah overall great

00:09:12,670 --> 00:09:17,140
performance the question now is if I

00:09:15,730 --> 00:09:18,700
have things hanging around and I delete

00:09:17,140 --> 00:09:20,110
them and they stay behind won't like my

00:09:18,700 --> 00:09:21,460
blocks are always like getting bigger

00:09:20,110 --> 00:09:22,560
and big and the question is yes that's

00:09:21,460 --> 00:09:24,779
why we need to do some one

00:09:22,560 --> 00:09:26,790
clean up and s34 that has a thing called

00:09:24,779 --> 00:09:28,860
lifecycle policy where the lifecycle

00:09:26,790 --> 00:09:31,380
policy you can think of as a set of

00:09:28,860 --> 00:09:33,240
rules where you define that group of

00:09:31,380 --> 00:09:35,340
objects should do that after that amount

00:09:33,240 --> 00:09:37,440
of time for instance in our example we

00:09:35,340 --> 00:09:39,450
have if a blow-up is marked as deleted

00:09:37,440 --> 00:09:41,070
for seven days let's say please clean it

00:09:39,450 --> 00:09:47,160
up and that assumes it to take a backup

00:09:41,070 --> 00:09:50,010
every seven days yeah and it suspects or

00:09:47,160 --> 00:09:51,810
downtime sort backup time and small

00:09:50,010 --> 00:09:53,640
backup artifact is really very great if

00:09:51,810 --> 00:09:55,680
you have s3 with versioning the problem

00:09:53,640 --> 00:09:57,060
is that is every s3 provider those

00:09:55,680 --> 00:09:58,529
suppose the versioning feature because

00:09:57,060 --> 00:10:00,540
it's not like by default there and

00:09:58,529 --> 00:10:02,190
unfortunately no so we need to think of

00:10:00,540 --> 00:10:04,020
different ways of backing up the s3

00:10:02,190 --> 00:10:06,150
compatible API is that do not support

00:10:04,020 --> 00:10:07,710
versioning so in that case in the end

00:10:06,150 --> 00:10:09,390
very soon we have a bucket so imagine

00:10:07,710 --> 00:10:10,620
you have the blobs if you don't want to

00:10:09,390 --> 00:10:13,830
lose them you need to have a second

00:10:10,620 --> 00:10:15,570
bucket and just copy them over it's as

00:10:13,830 --> 00:10:19,350
simple as that so the backup strategy of

00:10:15,570 --> 00:10:21,089
that we have in terms of vocabulary we

00:10:19,350 --> 00:10:22,650
call this the bucket bucket and we name

00:10:21,089 --> 00:10:24,690
this a live bucket so the live bucket is

00:10:22,650 --> 00:10:26,279
the one of your foundation is using and

00:10:24,690 --> 00:10:29,760
the backup one is the one you stole your

00:10:26,279 --> 00:10:31,260
blobs in so this is what the backup

00:10:29,760 --> 00:10:34,050
really consists of a bucket bucket and

00:10:31,260 --> 00:10:36,150
the reference to these blobs in there so

00:10:34,050 --> 00:10:37,680
the strategy is just copy all the things

00:10:36,150 --> 00:10:40,050
from life to backup as simple as that

00:10:37,680 --> 00:10:41,700
the question is can we improve this if

00:10:40,050 --> 00:10:43,380
we are using the same backup bucket over

00:10:41,700 --> 00:10:45,390
and over for the same foundation or even

00:10:43,380 --> 00:10:47,610
for different foundations what can we do

00:10:45,390 --> 00:10:49,470
yes incremental backups in that case

00:10:47,610 --> 00:10:51,330
incremental backups looks like it like

00:10:49,470 --> 00:10:52,589
that imagine that this is an old back of

00:10:51,330 --> 00:10:55,230
the obvious and this is your foundation

00:10:52,589 --> 00:10:56,880
on a different point in time so we see

00:10:55,230 --> 00:10:58,980
in this picture that we have a and C now

00:10:56,880 --> 00:11:00,060
a previous backup and only these a new

00:10:58,980 --> 00:11:02,400
thing that we don't know about

00:11:00,060 --> 00:11:04,080
so imagine while the platform is down

00:11:02,400 --> 00:11:06,209
and the downtime that we care about we

00:11:04,080 --> 00:11:08,010
just copy over just D I cross the live

00:11:06,209 --> 00:11:09,570
bucket in the backup then we unlock the

00:11:08,010 --> 00:11:11,430
platform so we don't have any downtime

00:11:09,570 --> 00:11:13,530
and you can take our time and do some

00:11:11,430 --> 00:11:15,839
local copying design the backup and have

00:11:13,530 --> 00:11:16,680
a full new backup so the strategy looks

00:11:15,839 --> 00:11:19,860
a little bit like that

00:11:16,680 --> 00:11:21,360
during the lock time you just list the

00:11:19,860 --> 00:11:23,180
blobs from both alive in the bucket you

00:11:21,360 --> 00:11:25,589
calculate the Delta where the Delta is

00:11:23,180 --> 00:11:27,870
copy the new blocks from the life to

00:11:25,589 --> 00:11:29,760
backup I unlocked my platform because I

00:11:27,870 --> 00:11:31,500
don't want downtime and then I copy the

00:11:29,760 --> 00:11:35,030
same blobs within the same bucket bucket

00:11:31,500 --> 00:11:35,030
and this is how we do incremental

00:11:35,290 --> 00:11:39,160
and the blobs again look like that has

00:11:37,750 --> 00:11:42,910
like a reference for the director in the

00:11:39,160 --> 00:11:44,470
back a bucket in a list of your blobs so

00:11:42,910 --> 00:11:45,700
the first backup is slow as you can

00:11:44,470 --> 00:11:47,230
imagine because like the first time you

00:11:45,700 --> 00:11:50,050
take it back up your bucket bucket is

00:11:47,230 --> 00:11:52,630
empty so it's gonna be slow Marv the

00:11:50,050 --> 00:11:53,830
bigger and then future backups would be

00:11:52,630 --> 00:11:55,570
fast there and that's assuming that

00:11:53,830 --> 00:11:57,280
between the times you take backups on

00:11:55,570 --> 00:11:58,810
your blob so hasn't really changed that

00:11:57,280 --> 00:12:00,610
much so if you post only a couple of

00:11:58,810 --> 00:12:02,430
apps between the last backup the new

00:12:00,610 --> 00:12:05,020
backups should be fairly fast

00:12:02,430 --> 00:12:06,610
the artifact is small because we only

00:12:05,020 --> 00:12:08,470
keep records to the backup bucket but

00:12:06,610 --> 00:12:10,360
you don't avoid the storage cost at this

00:12:08,470 --> 00:12:13,120
point because you need a lot of space

00:12:10,360 --> 00:12:15,040
for the back like the blobs inside the

00:12:13,120 --> 00:12:17,080
bucket bucket but the good thing about

00:12:15,040 --> 00:12:18,670
this approach it works in every s3

00:12:17,080 --> 00:12:22,540
compatible implementation we don't need

00:12:18,670 --> 00:12:24,910
to worry about the vendor hey lovey yeah

00:12:22,540 --> 00:12:26,800
this works ah

00:12:24,910 --> 00:12:29,170
so the backup aspects like the variables

00:12:26,800 --> 00:12:30,310
downtime the first time is low next

00:12:29,170 --> 00:12:32,470
might be fast we don't really know

00:12:30,310 --> 00:12:34,000
that's why it's variable big backup time

00:12:32,470 --> 00:12:35,590
though so the end-to-end experience you

00:12:34,000 --> 00:12:37,120
need to take a full copy of your blob so

00:12:35,590 --> 00:12:39,340
somewhere maybe side the provider so

00:12:37,120 --> 00:12:41,560
that's slow by nature because you need

00:12:39,340 --> 00:12:43,720
yeah and then there's more backup

00:12:41,560 --> 00:12:45,670
artifact but you have all the blobs

00:12:43,720 --> 00:12:46,780
duplicating the storage provider so it's

00:12:45,670 --> 00:12:49,570
not fun either

00:12:46,780 --> 00:12:51,580
let's see about a zoo right that's also

00:12:49,570 --> 00:12:53,500
has any nice features we can use sue

00:12:51,580 --> 00:12:55,900
does it has soft elites what are soft

00:12:53,500 --> 00:12:57,460
elites you can think about it if I

00:12:55,900 --> 00:12:58,930
delete the blob it just marked as

00:12:57,460 --> 00:13:01,780
deleted that's why it's soft elite it's

00:12:58,930 --> 00:13:03,010
so every object very similar to the s3

00:13:01,780 --> 00:13:05,350
version ID we've seen the previous

00:13:03,010 --> 00:13:07,480
slides we have an e-tag ID and we just

00:13:05,350 --> 00:13:10,510
use that so the approach is almost

00:13:07,480 --> 00:13:13,120
identical to the s3 versioning so list

00:13:10,510 --> 00:13:14,890
of a tags of the blobs record a dark IDs

00:13:13,120 --> 00:13:17,080
and that's it and this is your bug apart

00:13:14,890 --> 00:13:19,570
fog as well and similarly to the s3

00:13:17,080 --> 00:13:22,120
versioning with backup is fast just the

00:13:19,570 --> 00:13:24,400
time to list the a tags the artifact is

00:13:22,120 --> 00:13:25,720
small the records always backup

00:13:24,400 --> 00:13:27,760
performance if we don't have multiple

00:13:25,720 --> 00:13:29,740
providers so if you have as you as er

00:13:27,760 --> 00:13:32,620
always works with soft deletes

00:13:29,740 --> 00:13:34,900
so it's great again we need to have a

00:13:32,620 --> 00:13:36,700
life cycle policy although in our zoos

00:13:34,900 --> 00:13:38,980
vocabulary called lifecycle management

00:13:36,700 --> 00:13:40,570
policy which is the same if a blob is

00:13:38,980 --> 00:13:42,670
matters deleted for seven days cleaned

00:13:40,570 --> 00:13:44,320
up or whatever your ex days you want to

00:13:42,670 --> 00:13:46,570
retain your backups for really up to the

00:13:44,320 --> 00:13:49,470
operators to configure that just to make

00:13:46,570 --> 00:13:52,150
sure you don't balloon your Lobster

00:13:49,470 --> 00:13:53,920
and we have so downtime sold backup

00:13:52,150 --> 00:13:55,600
times more backup artifact this also

00:13:53,920 --> 00:13:58,510
great candidates so as we serve deletes

00:13:55,600 --> 00:14:01,060
industry with versioning this yes this

00:13:58,510 --> 00:14:03,820
here has versioning but we cannot use it

00:14:01,060 --> 00:14:06,550
the reason we cannot use it is that it

00:14:03,820 --> 00:14:07,810
doesn't have a good life cycle command

00:14:06,550 --> 00:14:10,810
so for instance you cannot tell that

00:14:07,810 --> 00:14:12,400
this yes if that's blob is deleted for

00:14:10,810 --> 00:14:14,410
ten days please remove it it only has

00:14:12,400 --> 00:14:16,420
things related to AIDS if it's ten days

00:14:14,410 --> 00:14:18,370
old remove it and we don't want to play

00:14:16,420 --> 00:14:21,850
with AIDS we want to play with a deleted

00:14:18,370 --> 00:14:23,560
once so unfortunately it will always

00:14:21,850 --> 00:14:25,090
grow bigger if you start using that all

00:14:23,560 --> 00:14:27,640
we have people going manually deleting

00:14:25,090 --> 00:14:29,230
stuff we want to avoid so we treated as

00:14:27,640 --> 00:14:31,540
an investment blob so although it has

00:14:29,230 --> 00:14:33,070
features so we have to copy everything

00:14:31,540 --> 00:14:34,570
from the life to the backup and that's

00:14:33,070 --> 00:14:37,150
sad because it has features but we

00:14:34,570 --> 00:14:41,340
cannot really utilize them the backup

00:14:37,150 --> 00:14:43,600
looks like that and the backup is slow

00:14:41,340 --> 00:14:47,380
unfortunately the artifact is mobile you

00:14:43,600 --> 00:14:49,300
keep things around as well and if it

00:14:47,380 --> 00:14:51,910
sometime in the future GCS provides some

00:14:49,300 --> 00:14:53,620
kind of life policy lifecycle policy

00:14:51,910 --> 00:14:55,780
maybe we can switch to versioning or

00:14:53,620 --> 00:14:57,160
just Suites incremental because for now

00:14:55,780 --> 00:14:58,480
just the knife implementation copy

00:14:57,160 --> 00:15:02,410
everything we haven't done incremental

00:14:58,480 --> 00:15:04,390
for this years yet so long down time

00:15:02,410 --> 00:15:06,880
every backup is slow long backup time

00:15:04,390 --> 00:15:08,440
full copy of the blob so and the backup

00:15:06,880 --> 00:15:10,360
artifact is more badly held the storage

00:15:08,440 --> 00:15:13,120
costs and that should be off of the

00:15:10,360 --> 00:15:15,070
external blob source thank you

00:15:13,120 --> 00:15:16,900
so we talked about how different

00:15:15,070 --> 00:15:21,460
external blob stores in the internal

00:15:16,900 --> 00:15:23,530
blob store can kind of be used to have

00:15:21,460 --> 00:15:25,600
different backup performances and one of

00:15:23,530 --> 00:15:27,460
the things that we also asked ourselves

00:15:25,600 --> 00:15:30,160
and is a new feature of CF deployment is

00:15:27,460 --> 00:15:32,260
can we selectively backup the blobstore

00:15:30,160 --> 00:15:34,690
do we need everything in that blob store

00:15:32,260 --> 00:15:38,170
so we've been calling it selective

00:15:34,690 --> 00:15:40,089
backups and this is essentially going

00:15:38,170 --> 00:15:41,770
through the blob store and only

00:15:40,089 --> 00:15:42,280
selectively backing up certain aspects

00:15:41,770 --> 00:15:45,070
of it

00:15:42,280 --> 00:15:47,380
so the aspects of a CF blob store we

00:15:45,070 --> 00:15:49,240
have the bill PACs which is basically

00:15:47,380 --> 00:15:51,070
everything that your app needs to run so

00:15:49,240 --> 00:15:53,940
that'll be like the Java Runtime

00:15:51,070 --> 00:15:56,110
environment or Ruby or whatever you need

00:15:53,940 --> 00:15:58,300
you have your packages which is the

00:15:56,110 --> 00:16:00,460
source code of your app and you have

00:15:58,300 --> 00:16:00,920
droplets which is the stage version of

00:16:00,460 --> 00:16:03,730
your

00:16:00,920 --> 00:16:07,189
we'll be compiled versions of your app

00:16:03,730 --> 00:16:08,809
so in an example that we drew from some

00:16:07,189 --> 00:16:11,179
of our customers and this is a customer

00:16:08,809 --> 00:16:12,889
with a lot of job applications the

00:16:11,179 --> 00:16:15,859
majority of their blobstore about 70 to

00:16:12,889 --> 00:16:17,749
80 percent was actually entirely their

00:16:15,859 --> 00:16:20,059
droplets so the compiled versions of

00:16:17,749 --> 00:16:22,730
their apps the next big killer was the

00:16:20,059 --> 00:16:24,259
packages and the bill packs are actually

00:16:22,730 --> 00:16:26,199
quite minimal only about zero to five

00:16:24,259 --> 00:16:29,660
percent of the blobstore

00:16:26,199 --> 00:16:32,629
so one of where our motivations we were

00:16:29,660 --> 00:16:34,790
trying to reduce our backup downtime and

00:16:32,629 --> 00:16:37,669
we were also trying to reduce our backup

00:16:34,790 --> 00:16:40,419
size which impacts both the storage

00:16:37,669 --> 00:16:43,279
costs and how much downtime you incur

00:16:40,419 --> 00:16:45,199
the only problem is is that you then end

00:16:43,279 --> 00:16:49,639
up trading it off for RTO so your

00:16:45,199 --> 00:16:52,639
recovery time objective so if you have a

00:16:49,639 --> 00:16:56,959
very large full full blob store backup

00:16:52,639 --> 00:17:00,949
you incur higher downtime and higher

00:16:56,959 --> 00:17:05,149
storage costs but your recovery time is

00:17:00,949 --> 00:17:07,610
very low on the other hand if you reduce

00:17:05,149 --> 00:17:09,709
the size of your backup tune a selected

00:17:07,610 --> 00:17:11,620
backup then you end up trading it off

00:17:09,709 --> 00:17:14,630
for more RTO

00:17:11,620 --> 00:17:17,059
so in our restore workflow we have a

00:17:14,630 --> 00:17:20,899
disaster scenario we have a full backup

00:17:17,059 --> 00:17:24,100
and the process for recovery is just

00:17:20,899 --> 00:17:26,990
simply running BB our deployment restore

00:17:24,100 --> 00:17:29,210
wait some time and you're up and running

00:17:26,990 --> 00:17:31,580
and you're happy again in the other

00:17:29,210 --> 00:17:33,830
situation where you have a selected

00:17:31,580 --> 00:17:37,190
backup and there's two flavors in this

00:17:33,830 --> 00:17:38,840
one it is to exclude droplets at that

00:17:37,190 --> 00:17:41,120
point you have to run a BB our

00:17:38,840 --> 00:17:44,299
deployment restore you wait a bit of

00:17:41,120 --> 00:17:46,429
time and then at that point you have to

00:17:44,299 --> 00:17:48,350
get all of your app developers to

00:17:46,429 --> 00:17:51,500
restage their app so you have to do a CF

00:17:48,350 --> 00:17:53,620
restage of your app so that takes an

00:17:51,500 --> 00:17:55,669
additional cost to your recovery time

00:17:53,620 --> 00:17:58,580
but at that point you're up and running

00:17:55,669 --> 00:18:01,580
again if you're even more lean and you

00:17:58,580 --> 00:18:04,279
only selectively backup just your build

00:18:01,580 --> 00:18:06,889
packs then you end up doing your restore

00:18:04,279 --> 00:18:09,139
workflow and then you have to get every

00:18:06,889 --> 00:18:10,789
single to app developer to reach their

00:18:09,139 --> 00:18:12,070
apps and pushing means that they have to

00:18:10,789 --> 00:18:15,310
restage it and then it gets

00:18:12,070 --> 00:18:20,500
again and at that point obviously it has

00:18:15,310 --> 00:18:22,090
the highest recovery time of all right I

00:18:20,500 --> 00:18:23,950
think we have plenty of time for

00:18:22,090 --> 00:18:26,320
something all right we're really worried

00:18:23,950 --> 00:18:28,060
about time we have time so in summary

00:18:26,320 --> 00:18:29,740
the things that we backup the things we

00:18:28,060 --> 00:18:32,080
covered specifically in this talk was

00:18:29,740 --> 00:18:35,910
about CF deployment but we also the same

00:18:32,080 --> 00:18:40,690
tool could be used for Bosch for PKS and

00:18:35,910 --> 00:18:43,030
other things we specifically use the BB

00:18:40,690 --> 00:18:45,280
our CLI which is open source and there's

00:18:43,030 --> 00:18:47,440
also an SDK that you can deploy with CF

00:18:45,280 --> 00:18:49,450
which will come and come packaged with

00:18:47,440 --> 00:18:50,950
other things as well scripts to backup

00:18:49,450 --> 00:18:53,950
your int appointments and your blob

00:18:50,950 --> 00:18:56,740
stores and we talked about things that

00:18:53,950 --> 00:18:59,290
we desire out of a backup small backups

00:18:56,740 --> 00:19:03,100
frequent backups fast recovery time and

00:18:59,290 --> 00:19:05,950
very low downtime when we talk about the

00:19:03,100 --> 00:19:09,100
blob stores we talked about the downtime

00:19:05,950 --> 00:19:13,150
and specifically we have fairly good

00:19:09,100 --> 00:19:16,150
downtime for internal the only one that

00:19:13,150 --> 00:19:19,720
was like quite bad in terms of downtime

00:19:16,150 --> 00:19:23,110
was the GCS and the s3 incremental is

00:19:19,720 --> 00:19:25,000
it's not as optimal as it could be in

00:19:23,110 --> 00:19:27,760
terms of the time it actually takes to

00:19:25,000 --> 00:19:28,750
take the physical backup so not just the

00:19:27,760 --> 00:19:30,910
downtime itself

00:19:28,750 --> 00:19:32,800
internal takes quite a long time even

00:19:30,910 --> 00:19:35,260
though it's you know not during the

00:19:32,800 --> 00:19:36,670
downtime and the same thing with s3

00:19:35,260 --> 00:19:40,810
incremental issues that we've abstracted

00:19:36,670 --> 00:19:43,780
it away from the lock period in terms of

00:19:40,810 --> 00:19:45,580
artifact management and internal has the

00:19:43,780 --> 00:19:47,680
highest one because you have to do all

00:19:45,580 --> 00:19:50,920
of that yourself you are determining

00:19:47,680 --> 00:19:53,320
okay how is the lifecycle management of

00:19:50,920 --> 00:19:55,330
my artifacts gonna happen am I gonna be

00:19:53,320 --> 00:19:58,330
se peeing things over from John Fox a

00:19:55,330 --> 00:19:59,350
junk box that sort of thing and one of

00:19:58,330 --> 00:20:02,410
the great things about using the

00:19:59,350 --> 00:20:05,170
external database you end up an external

00:20:02,410 --> 00:20:07,420
blob store you end up having all that

00:20:05,170 --> 00:20:09,610
sort of features that come with you know

00:20:07,420 --> 00:20:11,460
it's up in an s3 bucket you don't have

00:20:09,610 --> 00:20:13,990
to worry about it too much

00:20:11,460 --> 00:20:15,910
and in terms of external storage costs

00:20:13,990 --> 00:20:17,350
obviously the internal one is the only

00:20:15,910 --> 00:20:21,130
one that doesn't incur external storage

00:20:17,350 --> 00:20:24,550
costs unless you choose to store it

00:20:21,130 --> 00:20:26,080
externally and then as well because

00:20:24,550 --> 00:20:29,080
there are

00:20:26,080 --> 00:20:31,960
storage of like actual physical copies

00:20:29,080 --> 00:20:37,480
of blobs the GCS and the s3 incremental

00:20:31,960 --> 00:20:40,330
have the highest and we also talked

00:20:37,480 --> 00:20:42,310
about how you can trade off the entirety

00:20:40,330 --> 00:20:47,650
of backing up your blob store with your

00:20:42,310 --> 00:20:49,450
recovery time cool one more thing that

00:20:47,650 --> 00:20:51,250
we'll mention just because we're here

00:20:49,450 --> 00:20:55,810
there are a few things that we kind of

00:20:51,250 --> 00:20:58,930
have on our ideas for things Bosch still

00:20:55,810 --> 00:21:00,970
has a very upfront like brute force

00:20:58,930 --> 00:21:03,670
backing up in this blob store so we're

00:21:00,970 --> 00:21:05,050
also thinking of how can we potentially

00:21:03,670 --> 00:21:08,010
select I'll be back up the box blob

00:21:05,050 --> 00:21:11,050
store as well can we get that size down

00:21:08,010 --> 00:21:12,850
we also want to be able to make it

00:21:11,050 --> 00:21:15,310
easier to switch between selective and

00:21:12,850 --> 00:21:16,750
full backups so right now doing a

00:21:15,310 --> 00:21:19,560
selective backup is something you choose

00:21:16,750 --> 00:21:21,730
at deploy time and obviously that's not

00:21:19,560 --> 00:21:23,800
ideal it would be great if you could do

00:21:21,730 --> 00:21:25,810
it at a cadence right so maybe do a full

00:21:23,800 --> 00:21:29,050
backup once a week select it backup

00:21:25,810 --> 00:21:30,910
daily that sort of thing and we also

00:21:29,050 --> 00:21:33,700
have something in the works where we

00:21:30,910 --> 00:21:36,010
want to be able to select to have app

00:21:33,700 --> 00:21:39,250
developers backup their service

00:21:36,010 --> 00:21:45,070
instances I specifically of the Yonder

00:21:39,250 --> 00:21:51,340
my broker do you have any questions for

00:21:45,070 --> 00:21:53,760
us so so we like to bring you the

00:21:51,340 --> 00:21:53,760
microphone

00:21:56,630 --> 00:22:02,070
hey I will mention it better I was just

00:22:00,150 --> 00:22:04,710
wondering like I can see really really

00:22:02,070 --> 00:22:06,870
obvious value for bbr with particularly

00:22:04,710 --> 00:22:08,940
sort of customers that we've got this

00:22:06,870 --> 00:22:10,440
snowflake app deployments a lot and

00:22:08,940 --> 00:22:12,540
things and it's quite hard to recover

00:22:10,440 --> 00:22:14,360
unless you've got back up like that buy

00:22:12,540 --> 00:22:17,430
one drink tea what would you say about

00:22:14,360 --> 00:22:18,960
the sort of minority of customers that

00:22:17,430 --> 00:22:21,300
we've got there got really really good

00:22:18,960 --> 00:22:23,280
automation for deployments which you

00:22:21,300 --> 00:22:26,250
could use that to recover what would you

00:22:23,280 --> 00:22:28,490
say about the value of bbr with that

00:22:26,250 --> 00:22:31,410
type of customers it's still like a much

00:22:28,490 --> 00:22:33,140
quicker recovery or yeah what would you

00:22:31,410 --> 00:22:35,700
say about it

00:22:33,140 --> 00:22:37,860
so these goes down the problem like

00:22:35,700 --> 00:22:39,620
recovery versus recreation so if you

00:22:37,860 --> 00:22:41,850
have the necessary automation to do it

00:22:39,620 --> 00:22:43,500
select the backups is one way to do it

00:22:41,850 --> 00:22:44,730
forward so you just keep your blobs

00:22:43,500 --> 00:22:46,680
though and you have your automated

00:22:44,730 --> 00:22:48,930
pipelines so you just recover user Sox

00:22:46,680 --> 00:22:50,310
spaces that's some input that we had and

00:22:48,930 --> 00:22:51,780
that was a main driver behind selected

00:22:50,310 --> 00:22:53,070
backups so you can take backups

00:22:51,780 --> 00:22:54,210
frequently and then you can reduce

00:22:53,070 --> 00:22:55,830
everything because you have the

00:22:54,210 --> 00:22:57,420
pipelines that way but we cannot make

00:22:55,830 --> 00:23:00,630
the assumption and everybody has this

00:22:57,420 --> 00:23:03,930
nice sort of automation I like in place

00:23:00,630 --> 00:23:08,730
but ideally that depends on your RTO how

00:23:03,930 --> 00:23:11,070
fast you want to recover and how flaky

00:23:08,730 --> 00:23:12,420
can be your staging of your apps because

00:23:11,070 --> 00:23:14,190
we think it's read forward but maybe

00:23:12,420 --> 00:23:15,450
like the whole staging process is not

00:23:14,190 --> 00:23:19,860
that straightforward so you don't have

00:23:15,450 --> 00:23:21,420
to I mean definitely like you would we

00:23:19,860 --> 00:23:22,560
there are there are quite a few

00:23:21,420 --> 00:23:26,760
customers that will just go for

00:23:22,560 --> 00:23:28,170
recreation instead but if you have like

00:23:26,760 --> 00:23:29,850
maybe in your company like auditing

00:23:28,170 --> 00:23:31,110
problems or you know specific

00:23:29,850 --> 00:23:32,520
requirements that we require that you

00:23:31,110 --> 00:23:34,830
always have like copies of things

00:23:32,520 --> 00:23:36,750
another strategy as well is just to have

00:23:34,830 --> 00:23:40,200
multiple platforms so you'll have

00:23:36,750 --> 00:23:41,730
multiple versions boss directors in

00:23:40,200 --> 00:23:45,800
different locations and stuff and then

00:23:41,730 --> 00:23:45,800
have that as your feel safe as well

00:23:50,070 --> 00:23:56,500
so if not using the CP was that it

00:23:53,440 --> 00:23:58,570
doesn't have a gleaming strategy or

00:23:56,500 --> 00:24:01,690
before it doesn't have versioning

00:23:58,570 --> 00:24:03,040
because sorry aha

00:24:01,690 --> 00:24:04,690
I run through the slides because in

00:24:03,040 --> 00:24:09,640
terms of time I wasn't necessary

00:24:04,690 --> 00:24:11,380
so the GCS has versioning features but

00:24:09,640 --> 00:24:13,600
then if you tell people turn on

00:24:11,380 --> 00:24:16,210
versioning and they don't have a nice

00:24:13,600 --> 00:24:18,670
straightforward way to clean up things

00:24:16,210 --> 00:24:21,070
afterwards we don't want to recommend it

00:24:18,670 --> 00:24:23,890
because it doesn't have good lifecycle

00:24:21,070 --> 00:24:25,660
policies to remove deleted blobs that

00:24:23,890 --> 00:24:27,400
was like the main problem and then you

00:24:25,660 --> 00:24:29,110
could have to do it on your own and I

00:24:27,400 --> 00:24:30,880
can potentially validate a backup you

00:24:29,110 --> 00:24:32,680
just took by removing a blob that you

00:24:30,880 --> 00:24:43,120
soon and then in recovery time you find

00:24:32,680 --> 00:24:44,860
out it's too late so we thought multiple

00:24:43,120 --> 00:24:46,390
things and no solution was

00:24:44,860 --> 00:24:48,130
straightforward enough and we didn't see

00:24:46,390 --> 00:24:50,260
like a great value we'd have like much

00:24:48,130 --> 00:24:51,550
input so we wanted just to cover that

00:24:50,260 --> 00:24:52,810
for people who are using this years they

00:24:51,550 --> 00:24:54,430
can still take a backup it just like

00:24:52,810 --> 00:24:56,770
takes longer that's like the main thing

00:24:54,430 --> 00:24:58,150
and if it was just waiting people to fix

00:24:56,770 --> 00:24:59,410
because we gave this feedback to GCS

00:24:58,150 --> 00:25:01,330
folks we talked with engineers from

00:24:59,410 --> 00:25:03,010
Google say are fine we'll do it and

00:25:01,330 --> 00:25:04,540
we're probably as soon as they do

00:25:03,010 --> 00:25:09,850
lifecycle policy properly with the

00:25:04,540 --> 00:25:12,330
Suites versioning and then solved any

00:25:09,850 --> 00:25:12,330
other questions

00:25:15,810 --> 00:25:20,160

YouTube URL: https://www.youtube.com/watch?v=Ovf4fjagKXQ


