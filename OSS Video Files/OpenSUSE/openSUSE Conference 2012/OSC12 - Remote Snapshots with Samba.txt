Title: OSC12 - Remote Snapshots with Samba
Publication date: 2012-10-24
Playlist: openSUSE Conference 2012
Description: 
	OSC12 - Remote Snapshots with Samba from openSUSE. Like this? Watch the latest episode of openSUSE on Blip! http://blip.tv/opensuse/watch 

Speaker: David Disseldorp, Arvin Schnell
Room: Riker

See all episodes of openSUSE http://blip.tv/opensuse#EpisodeArchive
Visit openSUSE's series page http://blip.tv/opensuse
Captions: 
	00:00:00,079 --> 00:00:08,610
yes good good day everybody so um we'll

00:00:05,609 --> 00:00:13,400
talk a bit about butter FS snapper and

00:00:08,610 --> 00:00:13,400
how summer is using these new features

00:00:15,379 --> 00:00:20,760
so maybe you have heard about battery as

00:00:18,060 --> 00:00:23,850
it is a relatively new file system for

00:00:20,760 --> 00:00:27,029
linux with that which s very interesting

00:00:23,850 --> 00:00:30,990
features for example it does check

00:00:27,029 --> 00:00:33,690
summing of all your or can do check

00:00:30,990 --> 00:00:38,190
something for all your metadata and data

00:00:33,690 --> 00:00:40,670
and if you have multiple devices and it

00:00:38,190 --> 00:00:44,570
detects an error in one of them it can

00:00:40,670 --> 00:00:48,329
restore the uncorrupted version it has

00:00:44,570 --> 00:00:52,649
redundancy multi-device support so it

00:00:48,329 --> 00:00:58,829
has modes like great 0 right rate 1 and

00:00:52,649 --> 00:01:02,340
great 10 and i am rate 5 & 6 are in

00:00:58,829 --> 00:01:04,409
preparation these two red nodes are a

00:01:02,340 --> 00:01:06,960
bit different the normal rate they are

00:01:04,409 --> 00:01:08,549
not like that every block is exactly

00:01:06,960 --> 00:01:11,310
matched at the same position on a

00:01:08,549 --> 00:01:13,229
different disks but it just guarantees

00:01:11,310 --> 00:01:16,619
that for example with meringue rate it

00:01:13,229 --> 00:01:20,900
has one copy on to disk somewhere that's

00:01:16,619 --> 00:01:25,080
all it guarantees here it has a

00:01:20,900 --> 00:01:28,799
compression it has subvolumes and

00:01:25,080 --> 00:01:31,590
snapshots which will em demonstrate

00:01:28,799 --> 00:01:36,119
later reboot and cone and connection

00:01:31,590 --> 00:01:39,509
with snapper and which is also very

00:01:36,119 --> 00:01:45,420
important it can do deduplication of

00:01:39,509 --> 00:01:48,060
your M data blocks so if you copy a file

00:01:45,420 --> 00:01:52,939
you can actually clone it and then the

00:01:48,060 --> 00:01:52,939
data is only occupied once on the disk

00:02:26,560 --> 00:02:34,520
so about one year ago we started it

00:02:29,810 --> 00:02:38,590
sousa to implement a new tool to manage

00:02:34,520 --> 00:02:44,030
these snapshots and we call this snapper

00:02:38,590 --> 00:02:47,120
it can manage your file system snapshots

00:02:44,030 --> 00:02:51,739
it does not only support butter of s but

00:02:47,120 --> 00:02:56,270
also x4 and very new to soon provisioned

00:02:51,739 --> 00:02:59,570
lvm snapshots and but right now in

00:02:56,270 --> 00:03:03,380
opensuse only butter if s is supportive

00:02:59,570 --> 00:03:06,310
x4 you need a special kernel and for lvm

00:03:03,380 --> 00:03:10,760
Tim provisions you would need new and

00:03:06,310 --> 00:03:12,830
userland m tools but at least lvm will

00:03:10,760 --> 00:03:17,780
be likely supporting the next release

00:03:12,830 --> 00:03:21,560
and snapshots are created there for once

00:03:17,780 --> 00:03:25,160
you can create them manually and snapper

00:03:21,560 --> 00:03:27,799
also keeps a timeline of snap cuts where

00:03:25,160 --> 00:03:32,360
you want it so it creates a snapshot

00:03:27,799 --> 00:03:34,670
every hour and then later on deletes

00:03:32,360 --> 00:03:36,980
them again so that you have a nice time

00:03:34,670 --> 00:03:39,440
line so if you you have the first one of

00:03:36,980 --> 00:03:43,660
each day the first one of each month and

00:03:39,440 --> 00:03:47,380
the first one of each year and so on and

00:03:43,660 --> 00:03:52,519
especially interesting is the

00:03:47,380 --> 00:03:55,010
combination was just in zipper and more

00:03:52,519 --> 00:03:57,320
about this also later yes only if

00:03:55,010 --> 00:04:00,410
automatic clean up is either time or

00:03:57,320 --> 00:04:04,329
number based we have a command-line tool

00:04:00,410 --> 00:04:04,329
and yes user interface

00:04:06,700 --> 00:04:13,130
so when you want to use snapper and you

00:04:11,270 --> 00:04:18,580
have to create one configuration for

00:04:13,130 --> 00:04:22,100
every subvolume want you snapshot and /

00:04:18,580 --> 00:04:24,230
snapshot we then keep some metadata this

00:04:22,100 --> 00:04:27,610
is something but her FS does not heat

00:04:24,230 --> 00:04:30,200
for you so for every snap that you can

00:04:27,610 --> 00:04:34,280
record a time date you can get a

00:04:30,200 --> 00:04:37,970
description user data deserves those are

00:04:34,280 --> 00:04:41,900
just and key value pairs and we also

00:04:37,970 --> 00:04:43,880
create who has Bobby we require who has

00:04:41,900 --> 00:04:47,330
created a snapshot and a few other

00:04:43,880 --> 00:04:50,180
things then very interesting we can't

00:04:47,330 --> 00:04:51,620
you can compare snapshots so if you have

00:04:50,180 --> 00:04:54,400
to snap sure to say what's the

00:04:51,620 --> 00:04:57,680
difference in the file system here and

00:04:54,400 --> 00:05:00,820
you can see either the files or even the

00:04:57,680 --> 00:05:04,120
content of the file that has changed and

00:05:00,820 --> 00:05:08,450
then you can revert single files or

00:05:04,120 --> 00:05:10,610
several files at once and one additional

00:05:08,450 --> 00:05:15,460
thing we have single pre and post

00:05:10,610 --> 00:05:18,080
snapshots those are just for bookkeeping

00:05:15,460 --> 00:05:21,890
single snapshots are just there for

00:05:18,080 --> 00:05:25,700
themselves and just create one and keep

00:05:21,890 --> 00:05:28,190
it like the first of each month or

00:05:25,700 --> 00:05:30,980
something like this and pre and post

00:05:28,190 --> 00:05:34,070
snapshots you create with with just and

00:05:30,980 --> 00:05:36,710
super where before yes modifies to

00:05:34,070 --> 00:05:38,890
supplier system we create a snapshot and

00:05:36,710 --> 00:05:41,920
after it has modified the file system

00:05:38,890 --> 00:05:45,740
then we compare these two snapshots and

00:05:41,920 --> 00:05:49,730
you can see what and just or super have

00:05:45,740 --> 00:05:52,130
done and if you don't like to change or

00:05:49,730 --> 00:05:55,390
you make some mistake you can easily

00:05:52,130 --> 00:05:55,390
revert it again

00:05:58,090 --> 00:06:05,350
so this now here is new we have created

00:06:02,139 --> 00:06:10,060
a device interface for snapper it was

00:06:05,350 --> 00:06:14,139
just released last week so it splits

00:06:10,060 --> 00:06:16,960
snapper into a client and the server the

00:06:14,139 --> 00:06:19,960
server is started by d-bus demon on

00:06:16,960 --> 00:06:24,120
demand and does all the operations only

00:06:19,960 --> 00:06:27,460
route is allowed to do or a few more but

00:06:24,120 --> 00:06:31,030
for example for the lvm all the lvm cool

00:06:27,460 --> 00:06:33,220
tools you can only use them as root but

00:06:31,030 --> 00:06:36,280
some actions are still done by the

00:06:33,220 --> 00:06:38,139
client like reverting files there's no

00:06:36,280 --> 00:06:41,770
need to do this in the server yet and

00:06:38,139 --> 00:06:45,820
it's more secure because the demon runs

00:06:41,770 --> 00:06:48,250
with root access and yes what's the

00:06:45,820 --> 00:06:52,090
great benefit it allows non-root users

00:06:48,250 --> 00:06:55,720
to make snapshots so you can set it up

00:06:52,090 --> 00:06:58,660
for the home directory of your users and

00:06:55,720 --> 00:07:04,960
they can on their own create snapshots

00:06:58,660 --> 00:07:11,130
delete them and so on yes and that's

00:07:04,960 --> 00:07:11,130
what I'm I'll now give a Depot ever

00:07:19,680 --> 00:07:31,210
so first we have we can look at what

00:07:28,680 --> 00:07:34,450
configurations never knows about so I

00:07:31,210 --> 00:07:38,380
have three and configurations one for

00:07:34,450 --> 00:07:40,630
the root filesystem 14 home linux and

00:07:38,380 --> 00:07:49,660
for home I schnell which is my home

00:07:40,630 --> 00:07:51,880
directory and then we can if I don't

00:07:49,660 --> 00:07:54,690
given configuration Amy route is the

00:07:51,880 --> 00:07:58,479
default so you can now see what

00:07:54,690 --> 00:08:04,510
snapshots has been created with the date

00:07:58,479 --> 00:08:11,530
and some description and now I can start

00:08:04,510 --> 00:08:17,850
just to for example and go to an easy

00:08:11,530 --> 00:08:17,850
module remote administration

00:08:26,030 --> 00:08:42,350
so i can now disable remote

00:08:28,740 --> 00:08:47,320
administration and could

00:08:42,350 --> 00:08:49,940
so for now list again UCT to new

00:08:47,320 --> 00:08:53,450
snapshots number 9 and number 10 and

00:08:49,940 --> 00:08:56,050
this description says yes remote so

00:08:53,450 --> 00:08:58,610
those were now created by us and

00:08:56,050 --> 00:09:02,330
currently the system is comparing those

00:08:58,610 --> 00:09:06,460
snapshots which unfortunately might take

00:09:02,330 --> 00:09:06,460
a few minutes on this little computer

00:09:06,970 --> 00:09:17,020
but I can now and ask for the changes

00:09:26,610 --> 00:09:29,610
hmm

00:09:34,240 --> 00:09:41,840
okay well this unfortunate still take

00:09:37,430 --> 00:09:45,290
some time but rescue is is in inside

00:09:41,840 --> 00:09:48,380
because this butter of svm supports some

00:09:45,290 --> 00:09:51,230
new features too and it's called

00:09:48,380 --> 00:09:54,500
send/receive where you can compare two

00:09:51,230 --> 00:09:57,080
snapshots and from the colonel directly

00:09:54,500 --> 00:09:58,580
get all the information and what has

00:09:57,080 --> 00:10:09,980
changed in the file system at the time

00:09:58,580 --> 00:10:15,260
and you can intend to use this yes well

00:10:09,980 --> 00:10:18,470
I can show you use for while this is

00:10:15,260 --> 00:10:27,890
still running in the background so here

00:10:18,470 --> 00:10:34,070
now the user linux and if i go say home

00:10:27,890 --> 00:10:36,800
linux the configuration and you see

00:10:34,070 --> 00:10:41,410
again some snapshots and the users now

00:10:36,800 --> 00:10:41,410
allowed to create

00:10:45,649 --> 00:11:00,420
is now allowed to create snapshots which

00:10:49,410 --> 00:11:03,600
wasn't the case and so far and see that

00:11:00,420 --> 00:11:05,850
is aya okay so now there's efforts have

00:11:03,600 --> 00:11:09,079
been compared and you see a few changes

00:11:05,850 --> 00:11:15,749
in this conflict display manager and

00:11:09,079 --> 00:11:19,649
when I say if you can get the content of

00:11:15,749 --> 00:11:23,759
the files that have changed so some

00:11:19,649 --> 00:11:31,129
variable to change here and you can see

00:11:23,759 --> 00:11:31,129
the same with the just snapper module

00:11:39,699 --> 00:11:48,600
we're on the left you have a file system

00:11:42,429 --> 00:11:51,730
tree and then you can select files and

00:11:48,600 --> 00:12:00,029
you see colorful output of what has

00:11:51,730 --> 00:12:12,119
changed what has been changed by us and

00:12:00,029 --> 00:12:15,879
then finally I can say undo change and

00:12:12,119 --> 00:12:21,579
sniper has reverted those m3 files so

00:12:15,879 --> 00:12:30,989
now and this change biased is and has

00:12:21,579 --> 00:12:30,989
been reverted yes any questions here yes

00:12:31,049 --> 00:12:39,249
yes yes hmm even it did yes it just

00:12:36,549 --> 00:12:41,529
copies the files from the snapshots into

00:12:39,249 --> 00:12:44,350
the running systems the physis the

00:12:41,529 --> 00:12:47,799
snapshots and snapper creates also read

00:12:44,350 --> 00:12:53,949
only where possible with Colonel

00:12:47,799 --> 00:12:56,139
supports that yes with all files in the

00:12:53,949 --> 00:12:59,109
file system that are under control of

00:12:56,139 --> 00:13:02,289
butter of s so boot for example which so

00:12:59,109 --> 00:13:07,209
far cannot be on butter FS you cannot

00:13:02,289 --> 00:13:10,839
regret those changes there but even here

00:13:07,209 --> 00:13:16,350
hope is M nearest that grapple support

00:13:10,839 --> 00:13:16,350
and butter FS

00:13:19,470 --> 00:13:22,649
we had

00:13:26,550 --> 00:13:35,940
okay then and over to David to will

00:13:30,880 --> 00:13:35,940
explain how zomba uses snapshots

00:14:24,150 --> 00:14:26,210
you

00:16:45,500 --> 00:16:52,080
so thank you oven so as mentioned I'm

00:16:50,160 --> 00:16:54,060
going to run through just some of the

00:16:52,080 --> 00:16:57,840
changes I've been making to Samba to

00:16:54,060 --> 00:17:01,890
make use of the awesome snap around but

00:16:57,840 --> 00:17:05,010
RFS teachers are so starting off we have

00:17:01,890 --> 00:17:08,640
shadow copies which is basically we no

00:17:05,010 --> 00:17:13,410
speak for for snapshots I'm so Explorer

00:17:08,640 --> 00:17:16,050
or Windows Explorer has already provides

00:17:13,410 --> 00:17:18,449
an interface to access previous versions

00:17:16,050 --> 00:17:21,120
for files so you can basically right

00:17:18,449 --> 00:17:23,990
click on a file and look at other

00:17:21,120 --> 00:17:27,390
versions they're provided by snapshots

00:17:23,990 --> 00:17:31,080
our windows accesses are those previous

00:17:27,390 --> 00:17:35,750
versions using gmt tokens in file paths

00:17:31,080 --> 00:17:38,670
and then finally there's also a new

00:17:35,750 --> 00:17:42,120
protocol for managing snapshots remotely

00:17:38,670 --> 00:17:45,480
so basically a windows server to k-12 a

00:17:42,120 --> 00:17:50,930
client can request a server create and

00:17:45,480 --> 00:17:53,640
expose shares as a snapshot share

00:17:50,930 --> 00:17:56,400
something we can also do now is

00:17:53,640 --> 00:18:00,270
server-side copy of flowed with butter

00:17:56,400 --> 00:18:04,320
FS so making use of the clone range I

00:18:00,270 --> 00:18:11,820
octyl in butter FS for very efficient

00:18:04,320 --> 00:18:13,890
fast server side copy operations so just

00:18:11,820 --> 00:18:17,280
showing here how Windows presents our

00:18:13,890 --> 00:18:20,810
previous versions in explorer so you can

00:18:17,280 --> 00:18:25,230
see we have a TPS report file here with

00:18:20,810 --> 00:18:27,870
22 snapshots are presenting previous

00:18:25,230 --> 00:18:30,870
versions from today and yesterday so

00:18:27,870 --> 00:18:35,720
what the user can do there is open

00:18:30,870 --> 00:18:39,090
previous versions make a copy or restore

00:18:35,720 --> 00:18:41,940
so what the client does in accessing

00:18:39,090 --> 00:18:45,500
these previous versions is it discovers

00:18:41,940 --> 00:18:48,810
them using a enumerate snapshots I octyl

00:18:45,500 --> 00:18:51,030
the server then then sends a list of

00:18:48,810 --> 00:18:55,020
these gmt tokens each

00:18:51,030 --> 00:18:57,180
presenting a snapshot and the client

00:18:55,020 --> 00:19:00,480
thing comes along in stats each file and

00:18:57,180 --> 00:19:04,050
only displays files or the file with

00:19:00,480 --> 00:19:06,510
differing modification times and as

00:19:04,050 --> 00:19:12,960
mentioned it accesses those previous

00:19:06,510 --> 00:19:16,680
versions using gmt tokens in the path so

00:19:12,960 --> 00:19:22,400
the file server remote VSS protocol or f

00:19:16,680 --> 00:19:26,190
sr vp is new with Windows Server 2012

00:19:22,400 --> 00:19:32,220
the client connects to a DC RPC named

00:19:26,190 --> 00:19:35,100
pipe and issues requests through that so

00:19:32,220 --> 00:19:37,440
the client is able to to determine which

00:19:35,100 --> 00:19:40,590
shares already presented by the SMB

00:19:37,440 --> 00:19:42,600
server capable of being snapshot it and

00:19:40,590 --> 00:19:45,810
then it can go ahead and request the

00:19:42,600 --> 00:19:52,940
creation exposure as a new share or

00:19:45,810 --> 00:19:56,820
deletion of of those shadow copies on

00:19:52,940 --> 00:19:59,090
Windows it integrates with what's known

00:19:56,820 --> 00:20:03,810
as a volume Shadow Copy Service

00:19:59,090 --> 00:20:07,130
ecosystem so VSS provides application

00:20:03,810 --> 00:20:10,860
specific application consistent backups

00:20:07,130 --> 00:20:13,560
so basically our prior to a backup

00:20:10,860 --> 00:20:17,910
occurring applications can register for

00:20:13,560 --> 00:20:20,460
notification of a pending backup the

00:20:17,910 --> 00:20:24,480
applications can then flush out any

00:20:20,460 --> 00:20:30,180
buffers they have prior to that snapshot

00:20:24,480 --> 00:20:32,610
being taken on the client side windows

00:20:30,180 --> 00:20:35,760
provides so there's a discotheque see

00:20:32,610 --> 00:20:38,910
command-line a client tool and it's also

00:20:35,760 --> 00:20:44,010
integrated with system center vpm which

00:20:38,910 --> 00:20:47,670
I haven't tested yet so the onto the

00:20:44,010 --> 00:20:52,820
server implementation in Samba so we

00:20:47,670 --> 00:20:57,590
four can you FSS demon which handles all

00:20:52,820 --> 00:21:00,270
remote shadow copy creation requests

00:20:57,590 --> 00:21:01,080
those requests are propagated through to

00:21:00,270 --> 00:21:03,510
the

00:21:01,080 --> 00:21:07,050
IVFs so we can manhandle laminar file

00:21:03,510 --> 00:21:10,320
system specific manner so if the Jeep

00:21:07,050 --> 00:21:14,070
IBM guys want to do a gpfs module any

00:21:10,320 --> 00:21:19,170
other file systems supporting snapshots

00:21:14,070 --> 00:21:22,800
this sort of thing we expose those new

00:21:19,170 --> 00:21:24,900
Shadow Copy shares using the registry

00:21:22,800 --> 00:21:28,500
configuration for samba so basically we

00:21:24,900 --> 00:21:34,470
can dynamically change Sam is running

00:21:28,500 --> 00:21:37,230
configuration from the emphasis demon so

00:21:34,470 --> 00:21:41,330
we have at the moment to the FS modules

00:21:37,230 --> 00:21:45,200
so VFS snapper yeah which uses the new

00:21:41,330 --> 00:21:51,660
device interface or for snapper to

00:21:45,200 --> 00:21:55,440
manage creation a deletion our prevents

00:21:51,660 --> 00:21:58,800
or provides mapping of the shadow copies

00:21:55,440 --> 00:22:01,740
or snapshots created by snap out to

00:21:58,800 --> 00:22:05,190
these gmt tokens so that we know his

00:22:01,740 --> 00:22:07,620
clients can access them we also have our

00:22:05,190 --> 00:22:09,810
VFS butter FS which was sort of a

00:22:07,620 --> 00:22:12,900
initial prototype which just issues a

00:22:09,810 --> 00:22:18,420
raw bar FSI Abdul's off the snapshot of

00:22:12,900 --> 00:22:22,730
creation so onto a demo the first one

00:22:18,420 --> 00:22:27,710
I'll do is just the cyber our pc client

00:22:22,730 --> 00:22:27,710
requesting snapshots on a Windows Server

00:23:12,120 --> 00:23:24,910
so I also have I'll just bring up the

00:23:15,810 --> 00:23:27,490
windows server in this case so at the

00:23:24,910 --> 00:23:30,220
moment we have Windows Server just with

00:23:27,490 --> 00:23:34,320
a single share I'm so what we can do

00:23:30,220 --> 00:23:34,320
let's just create some data there

00:23:42,490 --> 00:23:46,020
and now connect

00:23:52,360 --> 00:24:02,809
so is that share and we ask the server

00:24:00,620 --> 00:24:09,650
or we're asking the server to create and

00:24:02,809 --> 00:24:12,380
expose each shadow copy of this year so

00:24:09,650 --> 00:24:16,730
when he's provide some context for that

00:24:12,380 --> 00:24:19,190
creation so we're asking backup context

00:24:16,730 --> 00:24:23,320
which means it won't get cleaned up / /

00:24:19,190 --> 00:24:23,320
reboot that's a read-only snapshot

00:24:25,960 --> 00:24:37,790
initially now the server isn't running a

00:24:28,610 --> 00:24:40,549
episode p service not started up and the

00:24:37,790 --> 00:24:43,130
server comes back with a couple of goods

00:24:40,549 --> 00:24:46,429
are describing the Shadow Copy created

00:24:43,130 --> 00:24:56,660
and then and you share name so we go

00:24:46,429 --> 00:25:01,000
over to server now so there's a new

00:24:56,660 --> 00:25:01,000
share without our test file in there

00:25:04,440 --> 00:25:14,220
ok so now we'll go on to the Samba

00:25:10,050 --> 00:25:14,220
implementation or just have

00:25:19,840 --> 00:25:26,760
so we have a share here on Samba which

00:25:30,360 --> 00:25:36,220
allows for shadow copies and propagates

00:25:33,760 --> 00:25:40,860
those shadow copy requests through the

00:25:36,220 --> 00:25:40,860
snapper so again i'll just create

00:26:23,170 --> 00:26:30,280
and this time I'll run through and also

00:26:25,790 --> 00:26:33,470
showed the previous versions

00:26:30,280 --> 00:26:38,000
functionality provided so add so I've

00:26:33,470 --> 00:26:40,040
created our snapshot which we can see

00:26:38,000 --> 00:26:48,620
there it's exposed as a new share in

00:26:40,040 --> 00:26:58,190
this case if we then go in add some new

00:26:48,620 --> 00:27:01,370
data there so there we have a snapshot

00:26:58,190 --> 00:27:05,120
from other time stand strong yeah but a

00:27:01,370 --> 00:27:12,890
couple of minutes ago which were able to

00:27:05,120 --> 00:27:24,040
them so we can look at and then restore

00:27:12,890 --> 00:27:24,040
to be back to the base chair okay

00:27:33,779 --> 00:27:44,099
so now onto our server side copy so at

00:27:39,330 --> 00:27:46,549
the moment when a traditional copy in an

00:27:44,099 --> 00:27:49,440
SMB sense we have the data traveling

00:27:46,549 --> 00:27:51,419
from the disk to the server and then

00:27:49,440 --> 00:27:54,059
across the network to the client and the

00:27:51,419 --> 00:27:56,519
clients writing back that duplicate data

00:27:54,059 --> 00:27:59,759
all the way back to the server over the

00:27:56,519 --> 00:28:03,269
network and then finally to disk in a

00:27:59,759 --> 00:28:05,489
server-side copy situation the client

00:28:03,269 --> 00:28:07,999
offloads the copy operation to the

00:28:05,489 --> 00:28:11,039
server the server then is still

00:28:07,999 --> 00:28:14,399
generally reading their data off disk

00:28:11,039 --> 00:28:16,739
and writing duplicate data back down so

00:28:14,399 --> 00:28:18,299
in this case we're saving the network

00:28:16,739 --> 00:28:22,649
roundtrip it's still performing their

00:28:18,299 --> 00:28:26,129
disk i/o on a server in SMB there's a

00:28:22,649 --> 00:28:30,539
few I of tools for handling offload

00:28:26,129 --> 00:28:32,729
copies so there's copied chunk and then

00:28:30,539 --> 00:28:40,619
a couple of new offload read offload

00:28:32,729 --> 00:28:44,759
right I octaves for silva keith 2k12 so

00:28:40,619 --> 00:28:47,549
samba with butter FS enhancements yeah

00:28:44,759 --> 00:28:50,669
we can improve on the traditional copy

00:28:47,549 --> 00:28:53,460
offload in that we can translate this

00:28:50,669 --> 00:28:56,700
copy chunk requests into a butter FS

00:28:53,460 --> 00:28:58,889
phone range so that claim range is

00:28:56,700 --> 00:29:01,049
basically just a metadata operation on

00:28:58,889 --> 00:29:06,089
the file system we're not moving any of

00:29:01,049 --> 00:29:08,219
the source destination data around one

00:29:06,089 --> 00:29:10,859
limitation areas that it must be butter

00:29:08,219 --> 00:29:15,779
FS sector size a line which I think

00:29:10,859 --> 00:29:17,999
defaults still to 24 K so just showing

00:29:15,779 --> 00:29:21,089
it visually here in our traditional

00:29:17,999 --> 00:29:24,899
sense we have those thick lines the data

00:29:21,089 --> 00:29:27,149
travelling from disk over the network up

00:29:24,899 --> 00:29:30,979
to the client and back down we see the

00:29:27,149 --> 00:29:30,979
duplicate data there on disk

00:29:32,000 --> 00:29:36,860
using copy chunk or offload we're still

00:29:34,880 --> 00:29:40,370
seeing the data travel between the

00:29:36,860 --> 00:29:43,970
server and disk duplicate data on disk

00:29:40,370 --> 00:29:47,570
and finally our Samba copy chunk of

00:29:43,970 --> 00:29:50,180
butter FS a situation where we have the

00:29:47,570 --> 00:29:52,850
client offload the copy to the server

00:29:50,180 --> 00:29:56,090
and then the server doing the clone

00:29:52,850 --> 00:29:57,860
range iocked all metadata up updates and

00:29:56,090 --> 00:30:03,070
we have the destination and source

00:29:57,860 --> 00:30:03,070
pointing to the same extent data on disk

00:30:03,400 --> 00:30:14,260
okay so I'll just demonstrate the samba

00:30:07,790 --> 00:30:14,260
server using this with a 2k12 client

00:30:20,260 --> 00:30:28,450
so two shares here one not providing

00:30:24,600 --> 00:30:35,980
server-side copy so if we just try and

00:30:28,450 --> 00:30:38,020
copy this is a one gigabyte file we can

00:30:35,980 --> 00:30:41,670
see we're sort of odds thrashing my

00:30:38,020 --> 00:30:45,990
laptop disk and we're sort of yeah

00:30:41,670 --> 00:30:49,510
pretty average performance there and

00:30:45,990 --> 00:30:56,470
then over to our suicide cloned so we

00:30:49,510 --> 00:30:58,510
have again on details yes so I have it's

00:30:56,470 --> 00:31:04,140
sort of just a hack in there at the

00:30:58,510 --> 00:31:04,140
moment to disable it on specific chairs

00:31:05,730 --> 00:31:13,360
so we can see it's basically yeah I mean

00:31:10,930 --> 00:31:15,940
as you saw it's a meta data operation so

00:31:13,360 --> 00:31:18,000
it's sort of instantaneous clone so this

00:31:15,940 --> 00:31:20,380
is you know particularly useful for

00:31:18,000 --> 00:31:22,500
virtual machine provisioning this sort

00:31:20,380 --> 00:31:22,500
of thing

00:31:33,599 --> 00:31:36,989
where was I

00:31:37,510 --> 00:31:44,400
ok so just finishing up going through

00:31:41,590 --> 00:31:46,750
implementation state so at the moment

00:31:44,400 --> 00:31:50,290
the changes have been pushed up stream

00:31:46,750 --> 00:31:52,900
so currently going through the review

00:31:50,290 --> 00:31:55,680
process there's still some potential

00:31:52,900 --> 00:32:00,490
improvements so in the server side copy

00:31:55,680 --> 00:32:04,510
path is a new I octal such that the

00:32:00,490 --> 00:32:07,030
client can query the sector size so this

00:32:04,510 --> 00:32:09,490
allows us to advertise which sort of

00:32:07,030 --> 00:32:12,490
alignment we'd like in their requests

00:32:09,490 --> 00:32:16,810
coming from windows server to k-12

00:32:12,490 --> 00:32:18,820
clients to be good to see this or I'd

00:32:16,810 --> 00:32:22,060
like to work on i'm adding this to the

00:32:18,820 --> 00:32:25,300
linux kernel client so basically hooking

00:32:22,060 --> 00:32:29,140
that into the ref link functionality

00:32:25,300 --> 00:32:32,470
that's it's currently their support for

00:32:29,140 --> 00:32:35,820
the new offload read/write I octaves yes

00:32:32,470 --> 00:32:38,080
we can look at at some stage and then

00:32:35,820 --> 00:32:41,020
where it's possible adding the

00:32:38,080 --> 00:32:45,100
server-side copy support to other file

00:32:41,020 --> 00:32:48,610
system so ocfs2 I think does file based

00:32:45,100 --> 00:32:51,400
or file granularity clones I don't think

00:32:48,610 --> 00:32:56,740
you can do about crane jaw by trench

00:32:51,400 --> 00:33:01,560
clones at the moment and the snapshot or

00:32:56,740 --> 00:33:05,410
FS a VP server so the client and IDL

00:33:01,560 --> 00:33:07,300
test suite code is is all upstream the

00:33:05,410 --> 00:33:11,050
server server side code is still in

00:33:07,300 --> 00:33:15,850
review still some improvements to make

00:33:11,050 --> 00:33:18,460
so at the moment we are the the requests

00:33:15,850 --> 00:33:21,370
are propagated to the VFS asynchronously

00:33:18,460 --> 00:33:25,960
but we're still blocking on the d-bus

00:33:21,370 --> 00:33:28,680
calls two snapper occasion to avoid

00:33:25,960 --> 00:33:32,110
round trips so at the moment we're

00:33:28,680 --> 00:33:38,790
querying snapper for configuration to a

00:33:32,110 --> 00:33:41,380
base path for every snapshot operation

00:33:38,790 --> 00:33:43,180
support for read/write snapshots will be

00:33:41,380 --> 00:33:45,910
you dense a per hour so clients can

00:33:43,180 --> 00:33:49,440
currently request read write or read

00:33:45,910 --> 00:33:49,440
only snapshots from windows

00:33:52,059 --> 00:33:59,830
and that's it so any questions yes we

00:34:16,419 --> 00:34:21,040
are so they're on the windows side

00:34:21,639 --> 00:34:30,440
Microsoft was saying they're using the

00:34:24,370 --> 00:34:34,879
token-based scuzzy offload read right so

00:34:30,440 --> 00:34:38,080
basically they get a token for know so I

00:34:34,879 --> 00:34:40,990
think they're using so xcopy allows

00:34:38,080 --> 00:34:44,990
source destination upload to the storage

00:34:40,990 --> 00:34:47,389
with the sorts right with token and then

00:34:44,990 --> 00:34:49,190
there's something like request token so

00:34:47,389 --> 00:34:51,919
basically they get a token off disc or

00:34:49,190 --> 00:34:54,230
off the scuzzy array so this is a high

00:34:51,919 --> 00:34:56,600
end I mean you need high in scuzzy

00:34:54,230 --> 00:34:59,840
arrays for this I get a token and they

00:34:56,600 --> 00:35:02,660
do these right with token discuss the

00:34:59,840 --> 00:35:05,540
operations and that's what's required on

00:35:02,660 --> 00:35:16,570
the windows side to do this upload read

00:35:05,540 --> 00:35:16,570
write stuff any other questions

00:35:17,890 --> 00:35:28,630
Yeah right you could have shot okay this

00:35:25,030 --> 00:35:31,900
or you can actually also shoulder the

00:35:28,630 --> 00:35:33,730
other side my greatest national spot and

00:35:31,900 --> 00:35:35,080
why are we here so now I would like to

00:35:33,730 --> 00:35:39,790
see the nuclear site that it really

00:35:35,080 --> 00:35:53,550
honest naturalism sure so I can

00:35:39,790 --> 00:35:57,100
show so if we do a snap at least see

00:35:53,550 --> 00:35:58,660
yeah so we were using the basically the

00:35:57,100 --> 00:36:02,080
you that user that authenticated with

00:35:58,660 --> 00:36:04,480
snap with samba and then we add a

00:36:02,080 --> 00:36:08,790
description just saying the snapshot was

00:36:04,480 --> 00:36:13,780
created by tambah so that also allows

00:36:08,790 --> 00:36:16,060
any of the periodic snapshots provided

00:36:13,780 --> 00:36:26,830
by snapper all exposed to we knows

00:36:16,060 --> 00:36:31,300
clients I restore the file but now we

00:36:26,830 --> 00:36:34,080
can do it again if you like some minutes

00:36:31,300 --> 00:36:34,080
its lifetime

00:36:49,310 --> 00:36:51,370
ah

00:36:59,599 --> 00:37:04,299
so if you want to help me with the

00:37:01,190 --> 00:37:04,299
arguments here

00:37:33,079 --> 00:37:38,990
I'll so anything else you for the

00:37:36,660 --> 00:37:38,990
question

00:37:42,489 --> 00:37:46,660

YouTube URL: https://www.youtube.com/watch?v=jxSt9NDauS4


