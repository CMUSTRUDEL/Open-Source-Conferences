Title: OSC15 - Davor Guttierrez - Optimizing Linux Servers - what has been changed from last year?
Publication date: 2015-05-04
Playlist: openSUSE Conference 2015
Description: 
	Linux Server is optimized for average workloads. With most servers you can gain much by optimizing performance. Last year we discussed about optimizing old stuff, now we have 10 GB networks, new kernels and new hardware. How can we improve everything in our servers. We have virtualization on different platforms like KVM, XEN and Hyper-V, what is the best optimization for guest machines? We also have cloud platforms like OpenStack and Cloudstack and containers like LXC and Docker. Audience is anyone, who is interested in fast and optimized Linux servers.
Captions: 
	00:00:00,890 --> 00:00:12,660
ok we can I think we can start now it's

00:00:06,839 --> 00:00:14,940
1115 ok my name is david gutierrez I

00:00:12,660 --> 00:00:18,150
were talking something like about

00:00:14,940 --> 00:00:21,390
optimizing clinic servers this session

00:00:18,150 --> 00:00:24,630
is very similar to my last year's

00:00:21,390 --> 00:00:29,099
session isn't Dubrovnik I have added

00:00:24,630 --> 00:00:35,130
some slides about 40 gig 40 gig networks

00:00:29,099 --> 00:00:37,649
and technique networks so if you want to

00:00:35,130 --> 00:00:39,719
lose if you want to try to look me on

00:00:37,649 --> 00:00:43,079
the internet i have linkedin google+

00:00:39,719 --> 00:00:47,610
twitter facebook account you can just

00:00:43,079 --> 00:00:50,610
edit me like a friend ok today i will

00:00:47,610 --> 00:00:52,940
talk about what is optimization what is

00:00:50,610 --> 00:00:56,100
performance how to make server

00:00:52,940 --> 00:01:00,480
optimization what is server optimization

00:00:56,100 --> 00:01:02,879
how to make performance monitoring what

00:01:00,480 --> 00:01:08,840
are common view system monitoring tools

00:01:02,879 --> 00:01:11,580
on the pure linux without any very

00:01:08,840 --> 00:01:13,770
powerful tools just comment line tools

00:01:11,580 --> 00:01:17,729
and watcher which are the best

00:01:13,770 --> 00:01:22,290
benchmarking tools on linux okay at

00:01:17,729 --> 00:01:26,100
first what is optimization if you buy

00:01:22,290 --> 00:01:28,950
new server and our server is slow it's

00:01:26,100 --> 00:01:32,130
always problem we have by new very

00:01:28,950 --> 00:01:35,100
expensive server but everything it's

00:01:32,130 --> 00:01:39,450
working slow or not working we have

00:01:35,100 --> 00:01:41,790
problems with drivers with memory REM

00:01:39,450 --> 00:01:43,380
and so on we have a new linux

00:01:41,790 --> 00:01:47,100
distribution and this linux distribution

00:01:43,380 --> 00:01:50,009
are not going to run very well we're

00:01:47,100 --> 00:01:52,560
very well on our server we must

00:01:50,009 --> 00:01:55,470
determine to what is slow in your server

00:01:52,560 --> 00:01:57,930
may be too many services running maybe

00:01:55,470 --> 00:02:02,670
something broke wrong with hard disk I

00:01:57,930 --> 00:02:06,719
all network configuration and so on so

00:02:02,670 --> 00:02:09,780
what is performance to boost performance

00:02:06,719 --> 00:02:12,000
of our of a server we need just both its

00:02:09,780 --> 00:02:13,290
hardware and software components to make

00:02:12,000 --> 00:02:16,549
it operate efficient

00:02:13,290 --> 00:02:20,430
that's true when we are talking about

00:02:16,549 --> 00:02:23,819
server optimization we always talking

00:02:20,430 --> 00:02:27,420
about optimization of the web services

00:02:23,819 --> 00:02:30,209
web servers like Apache light httpd

00:02:27,420 --> 00:02:33,239
engines and so on we are always talking

00:02:30,209 --> 00:02:37,409
about disk block devices great

00:02:33,239 --> 00:02:40,680
controllers different file systems now

00:02:37,409 --> 00:02:43,439
in the t's Times's kazi disks and SSD

00:02:40,680 --> 00:02:46,049
disk solid-state disk about Colonel we

00:02:43,439 --> 00:02:50,400
now have a new version of Colonel like

00:02:46,049 --> 00:02:52,819
Colonel four-point old or newer we are

00:02:50,400 --> 00:02:56,010
always talking about net work input

00:02:52,819 --> 00:02:59,459
input and output of operation about

00:02:56,010 --> 00:03:01,709
tcp/ip network stack we have one gig

00:02:59,459 --> 00:03:06,150
networks 10 gig net force 40 gig

00:03:01,709 --> 00:03:10,280
networks and in another times is always

00:03:06,150 --> 00:03:12,720
almost always problems with a network

00:03:10,280 --> 00:03:15,000
when we are talking about optimization

00:03:12,720 --> 00:03:17,099
we always talk about firewalls intrusion

00:03:15,000 --> 00:03:20,099
prevention systems intrusion detection

00:03:17,099 --> 00:03:22,229
as well as we are talking about

00:03:20,099 --> 00:03:24,870
databases optimization about

00:03:22,229 --> 00:03:27,419
benchmarking and profiling and how to

00:03:24,870 --> 00:03:32,549
find bottlenecks in databases in

00:03:27,419 --> 00:03:35,819
optimization or in settings we are

00:03:32,549 --> 00:03:37,879
talking as well as about data storage

00:03:35,819 --> 00:03:42,180
tuning and disk and memory usage

00:03:37,879 --> 00:03:45,989
optimization but we always must start

00:03:42,180 --> 00:03:47,519
with installation always make custom

00:03:45,989 --> 00:03:50,010
installation of servers don't use

00:03:47,519 --> 00:03:53,359
default settings and default install I

00:03:50,010 --> 00:03:55,650
have seen many of servers were

00:03:53,359 --> 00:03:58,260
installation but just default next next

00:03:55,650 --> 00:04:01,379
next and then finish always use a custom

00:03:58,260 --> 00:04:05,010
partitioning q's may be multiple file

00:04:01,379 --> 00:04:06,689
systems installed only needed packages

00:04:05,010 --> 00:04:08,939
never install the whole group of

00:04:06,689 --> 00:04:11,120
packages make may be minimal

00:04:08,939 --> 00:04:14,159
installation of servers and tend at

00:04:11,120 --> 00:04:18,120
separate packages you don't need

00:04:14,159 --> 00:04:22,469
exibindo system organ amor HD on your

00:04:18,120 --> 00:04:25,200
server and console is always 80 point 25

00:04:22,469 --> 00:04:25,720
characters long and not SVGA or

00:04:25,200 --> 00:04:29,350
something

00:04:25,720 --> 00:04:31,950
like these graphics when we are talking

00:04:29,350 --> 00:04:34,480
about performers performance monitoring

00:04:31,950 --> 00:04:36,340
Linux system administrators should be

00:04:34,480 --> 00:04:39,970
proficient in Linux performance

00:04:36,340 --> 00:04:42,160
monitoring and tuning to identify system

00:04:39,970 --> 00:04:45,100
bottlenecks and come up with solutions

00:04:42,160 --> 00:04:47,950
to fix it you should always understand

00:04:45,100 --> 00:04:50,920
how various components of Linux works on

00:04:47,950 --> 00:04:52,600
a very high level following are the

00:04:50,920 --> 00:04:58,020
first subsystem that needs to be

00:04:52,600 --> 00:05:01,750
monitored CPU network aisle and memory

00:04:58,020 --> 00:05:03,490
when when we are talking about CPU you

00:05:01,750 --> 00:05:05,860
should always understand the four

00:05:03,490 --> 00:05:09,010
critical performance metrics for CPU

00:05:05,860 --> 00:05:12,970
this performance metric are contexts

00:05:09,010 --> 00:05:16,720
which run queue cpu utilization and load

00:05:12,970 --> 00:05:19,870
average when we are talking about

00:05:16,720 --> 00:05:22,890
context switch this is when cpu switches

00:05:19,870 --> 00:05:26,350
from one process or treat to another

00:05:22,890 --> 00:05:28,810
this is called context switch when a

00:05:26,350 --> 00:05:31,270
process which happens Colonel stores the

00:05:28,810 --> 00:05:34,390
current state of CPU of a process or

00:05:31,270 --> 00:05:36,669
Treat in the memory Colonel also

00:05:34,390 --> 00:05:39,130
retrieves the previously stored state of

00:05:36,669 --> 00:05:43,240
a protest or treat from the memory and

00:05:39,130 --> 00:05:45,490
puts it in the CPU context switching is

00:05:43,240 --> 00:05:49,720
very essential for multitasking of the

00:05:45,490 --> 00:05:51,660
CPU so all new CPUs a higher level of

00:05:49,720 --> 00:05:56,140
context switching can cause performance

00:05:51,660 --> 00:05:57,910
performance issues what is run queue run

00:05:56,140 --> 00:06:00,610
queue indicates the total number of

00:05:57,910 --> 00:06:03,520
active process in the current queue for

00:06:00,610 --> 00:06:06,490
CPU when cpu is ready to execute a

00:06:03,520 --> 00:06:08,979
process process it picks it up from the

00:06:06,490 --> 00:06:11,860
run queue based on the priority of the

00:06:08,979 --> 00:06:14,860
process processes that are in sleep

00:06:11,860 --> 00:06:18,190
state or I oh wait state are not in the

00:06:14,860 --> 00:06:20,830
run queue a higher number of processes

00:06:18,190 --> 00:06:26,140
in the run queue can cause performance

00:06:20,830 --> 00:06:29,100
issues like on cpu context which what is

00:06:26,140 --> 00:06:31,660
CPU utilization cpu utilization

00:06:29,100 --> 00:06:34,510
indicates how much of the CPU is

00:06:31,660 --> 00:06:37,060
currently get used we all know what is

00:06:34,510 --> 00:06:39,340
CPU utilization this is very straight

00:06:37,060 --> 00:06:42,070
forward and you can view the

00:06:39,340 --> 00:06:47,530
utilization from the GOP cannot comment

00:06:42,070 --> 00:06:53,470
like this one you all know about top you

00:06:47,530 --> 00:06:55,620
hit H top eight top and so on load

00:06:53,470 --> 00:07:01,240
average you can see here not average

00:06:55,620 --> 00:07:03,990
0.00 point 0 4 0 point 0 5 I would talk

00:07:01,240 --> 00:07:08,229
about what these three numbers mean

00:07:03,990 --> 00:07:10,360
sorry one hundred percent cpu

00:07:08,229 --> 00:07:20,380
utilization means that system is fueling

00:07:10,360 --> 00:07:23,110
old and yes if you i have here in this

00:07:20,380 --> 00:07:27,970
vm very machine i have two cpus you see

00:07:23,110 --> 00:07:31,960
see cpu one and cpu to but i think I

00:07:27,970 --> 00:07:40,870
don't have installed H stop just a

00:07:31,960 --> 00:07:44,860
second now I will install it later it's

00:07:40,870 --> 00:07:49,450
a maybe h top or a top has much better

00:07:44,860 --> 00:07:51,639
graphical view so one hundred percent

00:07:49,450 --> 00:07:53,860
cpu utilization means that system is

00:07:51,639 --> 00:07:56,490
really low hundred percent cpu

00:07:53,860 --> 00:08:02,070
utilization on one processor processor

00:07:56,490 --> 00:08:05,800
cpu is 1.0 when cpu is hundred percent

00:08:02,070 --> 00:08:08,680
utilized it's nothing bad it's okay a

00:08:05,800 --> 00:08:13,720
high percent of cpu utilization will

00:08:08,680 --> 00:08:20,530
cause some performance issues so what is

00:08:13,720 --> 00:08:26,010
load average this is this one so load

00:08:20,530 --> 00:08:33,339
average this up or you can see it with

00:08:26,010 --> 00:08:35,740
comment w you see load average so load

00:08:33,339 --> 00:08:39,279
average indicates the average cpu load

00:08:35,740 --> 00:08:41,529
over a specific time period on linux

00:08:39,279 --> 00:08:44,320
load average is displayed for the last

00:08:41,529 --> 00:08:51,180
one minute five minutes and fifteen

00:08:44,320 --> 00:08:54,760
minutes so one minute five minutes in 15

00:08:51,180 --> 00:08:58,540
load average of for example zero point

00:08:54,760 --> 00:09:00,730
25 1 point 20 and 5 1 point ninety

00:08:58,540 --> 00:09:03,190
indicates that a lot of the system is

00:09:00,730 --> 00:09:06,700
coming down zero point when T 5 is the

00:09:03,190 --> 00:09:08,590
load average in the last one minute one

00:09:06,700 --> 00:09:11,080
point 20 is the load average in the last

00:09:08,590 --> 00:09:13,540
five minutes and 190 is the load average

00:09:11,080 --> 00:09:15,790
in the last 15 minutes this load average

00:09:13,540 --> 00:09:17,560
is calculated by combining both the

00:09:15,790 --> 00:09:20,550
total number of protests in the queue

00:09:17,560 --> 00:09:25,360
and the total number of processes in the

00:09:20,550 --> 00:09:27,940
uninterruptible task state status so

00:09:25,360 --> 00:09:30,490
this was about load average when we are

00:09:27,940 --> 00:09:33,550
talking about disk i/o optimization

00:09:30,490 --> 00:09:36,400
linux systems currently shifts with four

00:09:33,550 --> 00:09:40,090
different out schedulers they are

00:09:36,400 --> 00:09:48,040
deadlines and on NLP anticipatory and c

00:09:40,090 --> 00:09:50,140
fq cfq is the default io scheduler there

00:09:48,040 --> 00:09:53,380
are many differences between these

00:09:50,140 --> 00:09:55,780
scheduling algorithms cfq like default

00:09:53,380 --> 00:09:58,150
this is the default algorithm is in most

00:09:55,780 --> 00:10:00,910
linux distributions it attempts to

00:09:58,150 --> 00:10:02,890
distribute all i all bandwidth evenly

00:10:00,910 --> 00:10:06,280
among all purchases requesting aisle

00:10:02,890 --> 00:10:09,340
it's ideal for most purposes then the

00:10:06,280 --> 00:10:11,440
second one is NLP this algorithm

00:10:09,340 --> 00:10:14,890
attempts to use as little cpu as

00:10:11,440 --> 00:10:17,350
possible it acts as a basic first-in

00:10:14,890 --> 00:10:19,390
first-out q expecting the hardware

00:10:17,350 --> 00:10:21,910
controller to handle the performance

00:10:19,390 --> 00:10:24,970
operations of the request then third

00:10:21,910 --> 00:10:27,610
anticipatory this algorithm attempts to

00:10:24,970 --> 00:10:30,670
reorder all disk i/o operations to

00:10:27,610 --> 00:10:33,100
optimize disk six disco six it's

00:10:30,670 --> 00:10:35,860
designed to increase performance of

00:10:33,100 --> 00:10:42,790
season played have slow disk like if we

00:10:35,860 --> 00:10:45,730
have server with 500 5400rpm disk we can

00:10:42,790 --> 00:10:49,150
use that it will increase some

00:10:45,730 --> 00:10:51,100
performance but not ideal then it afford

00:10:49,150 --> 00:10:53,770
the deadline t scheduling algorithm

00:10:51,100 --> 00:10:56,710
places i request in a priority queue so

00:10:53,770 --> 00:10:58,840
each is guaranteed to be run with within

00:10:56,710 --> 00:11:01,570
a certain time it's often used in a

00:10:58,840 --> 00:11:07,840
real-time operating systems

00:11:01,570 --> 00:11:11,380
so how to change these discs disc set io

00:11:07,840 --> 00:11:14,320
scheduler you can see it which one are

00:11:11,380 --> 00:11:17,920
using with this comment in a CS block

00:11:14,320 --> 00:11:25,390
sdh or whichever disc you're using q

00:11:17,920 --> 00:11:29,350
scheduler I have this comment here this

00:11:25,390 --> 00:11:33,070
is the default algorithm cfq and and

00:11:29,350 --> 00:11:37,720
change it to reteach this comment a hole

00:11:33,070 --> 00:11:40,440
in an LP right to scheduler or if you

00:11:37,720 --> 00:11:46,030
are using SUSE Linux you can change into

00:11:40,440 --> 00:11:48,400
within yes so changing schedules on the

00:11:46,030 --> 00:11:50,230
fly allows you to test and benchmarking

00:11:48,400 --> 00:11:53,590
the algorithms for your specific

00:11:50,230 --> 00:11:56,140
application what the change is used any

00:11:53,590 --> 00:11:59,080
current I operations will be executed

00:11:56,140 --> 00:12:02,800
before the new settler goes into effect

00:11:59,080 --> 00:12:05,110
so that change will not be instant also

00:12:02,800 --> 00:12:06,970
remember this that once one is set in

00:12:05,110 --> 00:12:08,980
performs to your liking be sure to set

00:12:06,970 --> 00:12:14,560
the change to be applied on the

00:12:08,980 --> 00:12:17,260
subsequent reboots if you have SS is a

00:12:14,560 --> 00:12:20,710
solid state drive it's often recommended

00:12:17,260 --> 00:12:25,150
to use NOP or deadline on any SSD drives

00:12:20,710 --> 00:12:28,180
we in our company now has the newer

00:12:25,150 --> 00:12:31,870
servers are all server with SSD drives

00:12:28,180 --> 00:12:36,130
we have changed io scheduler duties 12

00:12:31,870 --> 00:12:39,190
NOP maybe maybe it's has better

00:12:36,130 --> 00:12:42,160
performance but I didn't make any

00:12:39,190 --> 00:12:44,530
measurement there is usually no

00:12:42,160 --> 00:12:47,740
definitive answer to which algorithm to

00:12:44,530 --> 00:12:52,870
use if you may make a new installation

00:12:47,740 --> 00:12:55,480
of open source on your notebook the

00:12:52,870 --> 00:12:58,360
default algorithm will be NLP not

00:12:55,480 --> 00:13:01,870
anymore CF cube because it says that you

00:12:58,360 --> 00:13:04,720
are using SSD Drive bench you can

00:13:01,870 --> 00:13:07,240
benchmark each one in the sea which is

00:13:04,720 --> 00:13:09,190
your best options there are cases where

00:13:07,240 --> 00:13:11,560
cfq may not be the best scheduler

00:13:09,190 --> 00:13:14,180
because it's very old entities default

00:13:11,560 --> 00:13:17,670
in all these applications

00:13:14,180 --> 00:13:20,280
where c fq is not the best options it's

00:13:17,670 --> 00:13:23,820
example if you are using this grade

00:13:20,280 --> 00:13:27,890
controller with caching create disk

00:13:23,820 --> 00:13:31,950
array controller with caching battery

00:13:27,890 --> 00:13:34,890
much about I optimization what is aisle

00:13:31,950 --> 00:13:37,860
iowait is the amount of time cpu is

00:13:34,890 --> 00:13:40,350
waiting for input/output operation if

00:13:37,860 --> 00:13:42,930
you see consistent high i await on your

00:13:40,350 --> 00:13:45,510
system it indicates a problem in the

00:13:42,930 --> 00:13:47,940
disk subsystems you should you should

00:13:45,510 --> 00:13:50,640
also monitor read second and bright

00:13:47,940 --> 00:13:52,560
seconds this is measured in blocks in

00:13:50,640 --> 00:13:55,650
example number of blocks to read/write

00:13:52,560 --> 00:13:58,520
per second these are also referred as bi

00:13:55,650 --> 00:14:02,160
and Bo blocking and block out operations

00:13:58,520 --> 00:14:05,400
TPS indicates total total transactions

00:14:02,160 --> 00:14:09,270
per second which is summary of our TPS

00:14:05,400 --> 00:14:11,310
RT ps3 transaction per second and V TPS

00:14:09,270 --> 00:14:14,700
bright transaction per second it's

00:14:11,310 --> 00:14:18,660
really important if you have storage

00:14:14,700 --> 00:14:22,980
area network on fiber or something like

00:14:18,660 --> 00:14:26,520
that when we are talking about disk I

00:14:22,980 --> 00:14:28,830
optimization it's always important which

00:14:26,520 --> 00:14:31,830
file systems to use we have the most

00:14:28,830 --> 00:14:37,130
popular file systems are okay XA to it's

00:14:31,830 --> 00:14:41,190
very old then in distributions before /

00:14:37,130 --> 00:14:45,270
11 is less than or / 9 it's very popular

00:14:41,190 --> 00:14:48,900
writer FS but riser FS has no more any

00:14:45,270 --> 00:14:53,730
development we know we all know why then

00:14:48,900 --> 00:14:56,610
we have now XD for we have btrfs better

00:14:53,730 --> 00:14:59,160
file system which is really good for

00:14:56,610 --> 00:15:05,100
snapshotting and so on or we have maybe

00:14:59,160 --> 00:15:10,710
ZFS from oracle or sun microsystems and

00:15:05,100 --> 00:15:13,710
so on and you can always dune your file

00:15:10,710 --> 00:15:17,160
system which you are using in FS step

00:15:13,710 --> 00:15:21,300
you can add options like no attend now a

00:15:17,160 --> 00:15:23,130
deer on or saw something like that when

00:15:21,300 --> 00:15:25,550
we are talking about this customization

00:15:23,130 --> 00:15:29,400
it's always

00:15:25,550 --> 00:15:32,040
important which rate options we are

00:15:29,400 --> 00:15:36,870
using if we are using create 0 which is

00:15:32,040 --> 00:15:39,060
not safe it's very fast rate 1 i'm

00:15:36,870 --> 00:15:42,660
talking about software right a red one

00:15:39,060 --> 00:15:48,420
it's okay it's mirroring but it's not so

00:15:42,660 --> 00:15:51,240
fast rate 5 it's okay it's secure we

00:15:48,420 --> 00:15:55,290
have secured all files but it's not

00:15:51,240 --> 00:15:59,280
recommended because if one of disk has a

00:15:55,290 --> 00:16:02,040
failure our server will be very slow

00:15:59,280 --> 00:16:06,560
until we change the disk and we have 10

00:16:02,040 --> 00:16:13,530
I'll rate 10 which is the best but it

00:16:06,560 --> 00:16:15,990
will have all disc duplicated when we

00:16:13,530 --> 00:16:18,900
are talking about this customization we

00:16:15,990 --> 00:16:21,840
must use benchmarking tools one of very

00:16:18,900 --> 00:16:25,800
popular and very old benchmarking

00:16:21,840 --> 00:16:30,870
programs is Bonnie + + always use HD

00:16:25,800 --> 00:16:35,610
parm for ID disk or SD parm always try

00:16:30,870 --> 00:16:40,590
to upgrade biasa or bias or firmware of

00:16:35,610 --> 00:16:44,340
your disk and of your servers ok tonight

00:16:40,590 --> 00:16:48,300
the next popular is about network tuning

00:16:44,340 --> 00:16:54,120
I think that the network tuning is in

00:16:48,300 --> 00:16:56,070
these days the most important thing when

00:16:54,120 --> 00:16:59,130
we are talking about optimizing our

00:16:56,070 --> 00:17:03,780
servers because in ninety nine percent

00:16:59,130 --> 00:17:08,640
our bottleneck and server is working

00:17:03,780 --> 00:17:11,970
slow it's because of bad network slow

00:17:08,640 --> 00:17:14,700
packages no need for tuning and so on if

00:17:11,970 --> 00:17:16,560
we are talking about natural tuning we

00:17:14,700 --> 00:17:19,440
need a good understanding of tcp/ip

00:17:16,560 --> 00:17:21,839
concepts it's very helpful while

00:17:19,440 --> 00:17:24,810
analyzing analyzing Kenny networking

00:17:21,839 --> 00:17:26,850
issues for network interfaces we should

00:17:24,810 --> 00:17:29,100
monitor total number of packages and

00:17:26,850 --> 00:17:33,660
bytes which is received or sent through

00:17:29,100 --> 00:17:35,970
the interface how much anam packages are

00:17:33,660 --> 00:17:39,720
dropped and so on

00:17:35,970 --> 00:17:45,720
when we are talking about TCP tuning one

00:17:39,720 --> 00:17:47,850
of very popular tuning algorithm

00:17:45,720 --> 00:17:50,159
acidities for server started serving up

00:17:47,850 --> 00:17:52,500
huge numbers of concurrent session there

00:17:50,159 --> 00:17:55,530
are some TCP options that should

00:17:52,500 --> 00:17:57,390
probably be enabled with a large number

00:17:55,530 --> 00:17:59,580
of clients doing their best to kill the

00:17:57,390 --> 00:18:03,360
server it's probably not commented the

00:17:59,580 --> 00:18:07,850
server to have to twenty thousand or

00:18:03,360 --> 00:18:13,799
more open sockets so we must increase

00:18:07,850 --> 00:18:16,260
number of port to be available like IP

00:18:13,799 --> 00:18:18,390
local port range we can increase the

00:18:16,260 --> 00:18:22,080
amount of memory as associated with

00:18:18,390 --> 00:18:26,130
socket buffers this can significantly

00:18:22,080 --> 00:18:29,400
improve performance of our servers then

00:18:26,130 --> 00:18:32,190
to reduce the amount of work the TCP

00:18:29,400 --> 00:18:36,720
stake has to do so it's open helpful in

00:18:32,190 --> 00:18:42,350
this situation to turn off tcp second

00:18:36,720 --> 00:18:45,720
tcp timestamps it's totally okay to do

00:18:42,350 --> 00:18:48,750
something like that when we are talking

00:18:45,720 --> 00:18:53,789
about TCP tuning I'm talking now here

00:18:48,750 --> 00:18:57,299
especially for driver eat 1,000 which is

00:18:53,789 --> 00:19:00,169
I think often integrated into the

00:18:57,299 --> 00:19:07,890
motherboard the drivers default is to

00:19:00,169 --> 00:19:10,200
have 200 256 received and 256

00:19:07,890 --> 00:19:12,539
transmitted descriptors this is because

00:19:10,200 --> 00:19:15,780
early versions of the chipset only

00:19:12,539 --> 00:19:18,650
supported tease I talking about early

00:19:15,780 --> 00:19:21,960
versions of 2 t's chipset a 1000

00:19:18,650 --> 00:19:25,559
although the recent versions of these

00:19:21,960 --> 00:19:29,309
chips a 1000 which is as I said often

00:19:25,559 --> 00:19:34,350
integrated into motherboard it have it

00:19:29,309 --> 00:19:36,890
have possibility to have 4096 to

00:19:34,350 --> 00:19:39,510
transmit and receive dance turn

00:19:36,890 --> 00:19:43,679
descriptors but the driver doesn't out

00:19:39,510 --> 00:19:45,389
detectives so we will be using 256

00:19:43,679 --> 00:19:47,860
descriptors

00:19:45,389 --> 00:19:50,590
increasing the number of descriptors can

00:19:47,860 --> 00:19:54,759
improve performance dramatically on some

00:19:50,590 --> 00:19:57,399
holes if this is one VMware machine if I

00:19:54,759 --> 00:20:01,990
take a look how many how much

00:19:57,399 --> 00:20:05,399
descriptors I have on my network erotic

00:20:01,990 --> 00:20:09,279
network driver I just run this comment

00:20:05,399 --> 00:20:15,509
ath 2 minus G and the name of the

00:20:09,279 --> 00:20:20,440
interface I see proceed maximum is for

00:20:15,509 --> 00:20:24,100
4096 current harder settings is 256 so

00:20:20,440 --> 00:20:26,080
driver has not good auto detect you can

00:20:24,100 --> 00:20:29,799
try this on your servers if you have a

00:20:26,080 --> 00:20:33,999
1000 drivers on your chipset if you have

00:20:29,799 --> 00:20:37,779
some other drivers like BN x 2 or

00:20:33,999 --> 00:20:43,450
something like that you can also check

00:20:37,779 --> 00:20:46,869
these settings and change it you can as

00:20:43,450 --> 00:20:49,090
I said use HTH to will to check out the

00:20:46,869 --> 00:20:50,919
number of descriptors your network

00:20:49,090 --> 00:20:55,269
interface controller has with this

00:20:50,919 --> 00:21:00,009
comment or change it with HTH tool mean-

00:20:55,269 --> 00:21:02,590
big G H the name of the network card and

00:21:00,009 --> 00:21:08,549
how much received and transmitted the

00:21:02,590 --> 00:21:12,399
scriptures unit but before that make

00:21:08,549 --> 00:21:15,749
this is the name of the network card en

00:21:12,399 --> 00:21:20,559
all like network art in a vmware machine

00:21:15,749 --> 00:21:23,950
but if you may comment I have config you

00:21:20,559 --> 00:21:30,090
as you see you don't see the last two

00:21:23,950 --> 00:21:33,999
numbers c36 so make sure what is the

00:21:30,090 --> 00:21:37,690
full name of the card because if you're

00:21:33,999 --> 00:21:39,899
runt is comment it will set no such

00:21:37,690 --> 00:21:39,899
device

00:21:40,830 --> 00:21:49,780
when you are you changed is just execute

00:21:45,970 --> 00:21:52,360
as root this is a debug the seed that

00:21:49,780 --> 00:21:55,030
you can see that everything is all right

00:21:52,360 --> 00:21:59,200
that you will have now dropped packages

00:21:55,030 --> 00:22:04,050
to see any strange messages in this

00:21:59,200 --> 00:22:08,050
locker or something like that okay now

00:22:04,050 --> 00:22:10,360
we have in our company a few servers

00:22:08,050 --> 00:22:15,160
with 10 gig network interface

00:22:10,360 --> 00:22:19,800
controllers we have tested these think a

00:22:15,160 --> 00:22:24,430
lot and we have read on the forums of

00:22:19,800 --> 00:22:29,950
developers of network cards or of these

00:22:24,430 --> 00:22:33,580
servers that the best recommendations

00:22:29,950 --> 00:22:36,280
for tuning piston get 10 gigs network

00:22:33,580 --> 00:22:39,730
interface controller is to increase TCP

00:22:36,280 --> 00:22:43,060
maximum buffer size settable using set

00:22:39,730 --> 00:22:46,450
stock options to this to change net core

00:22:43,060 --> 00:22:49,110
arm and Max and net cord right ma'am max

00:22:46,450 --> 00:22:53,620
then the second one is to increase Linux

00:22:49,110 --> 00:22:55,330
auto-tuning TCP buffer limit then the

00:22:53,620 --> 00:22:57,940
dirt to increase the length of the

00:22:55,330 --> 00:23:00,460
protester input queue the fourth

00:22:57,940 --> 00:23:04,270
recommended the default conch congestion

00:23:00,460 --> 00:23:07,630
control issue is HTC p i will talk in

00:23:04,270 --> 00:23:11,050
the next slide so what is congestion

00:23:07,630 --> 00:23:13,450
control algorithms for and 450

00:23:11,050 --> 00:23:17,620
recommended for host with jumbo frames

00:23:13,450 --> 00:23:20,800
enabled but but if you are using 10 gigs

00:23:17,620 --> 00:23:23,760
needs Nick 10 gigs network interface

00:23:20,800 --> 00:23:31,600
controller you must use the jumbo frames

00:23:23,760 --> 00:23:35,620
jumbo frames MTU 9000 without this sorry

00:23:31,600 --> 00:23:39,100
without these settings your speed over

00:23:35,620 --> 00:23:41,800
the network on 10 gig network interface

00:23:39,100 --> 00:23:46,300
controller and 10 10 gigs which will be

00:23:41,800 --> 00:23:49,300
never hire like one or two gig when you

00:23:46,300 --> 00:23:52,840
are make this switch you will achieve

00:23:49,300 --> 00:23:56,890
about six maybe seven

00:23:52,840 --> 00:24:00,400
a gig over the network okay the next one

00:23:56,890 --> 00:24:03,610
is a little bit newer TCP tuning for 40

00:24:00,400 --> 00:24:09,760
gig Nick network interface controller i

00:24:03,610 --> 00:24:12,809
have tested this in IBM this center if

00:24:09,760 --> 00:24:15,630
you have 40 gig Nick then you are using

00:24:12,809 --> 00:24:18,520
definitely sandy bridge motherboards

00:24:15,630 --> 00:24:21,279
four holes with more than one processor

00:24:18,520 --> 00:24:23,740
socket not core this means you need to

00:24:21,279 --> 00:24:26,020
worry about what core is being used for

00:24:23,740 --> 00:24:28,899
both the interrupts and for your

00:24:26,020 --> 00:24:32,950
applications because higher cpu clock

00:24:28,899 --> 00:24:37,659
rate is far more important than hike or

00:24:32,950 --> 00:24:40,480
count for a 40 gig host it's very

00:24:37,659 --> 00:24:43,210
difficult to achieve 40 gig performance

00:24:40,480 --> 00:24:46,929
with with our cpa that runs more slot

00:24:43,210 --> 00:24:49,899
early tender three gigahertz per car

00:24:46,929 --> 00:24:54,669
it's very important that you have sandy

00:24:49,899 --> 00:24:59,470
bridge and that one core is always have

00:24:54,669 --> 00:25:01,750
more than three gigahertz tcp tuning up

00:24:59,470 --> 00:25:04,720
with a 40 gig network interface

00:25:01,750 --> 00:25:08,140
controller it's always the best to run

00:25:04,720 --> 00:25:10,750
the winter supply irq screech at the

00:25:08,140 --> 00:25:13,960
boot time to make sure your interrupts

00:25:10,750 --> 00:25:16,690
are using the right core we are talking

00:25:13,960 --> 00:25:19,510
about supplier of network interface

00:25:16,690 --> 00:25:24,220
controllers like mellanox hola chelsea

00:25:19,510 --> 00:25:27,610
oh they have on their download page irq

00:25:24,220 --> 00:25:30,490
scribbs which is the best if you run it

00:25:27,610 --> 00:25:37,870
all in our C dot local or something like

00:25:30,490 --> 00:25:41,850
that and to change these these tuning

00:25:37,870 --> 00:25:45,010
algorithms on the boot time okay i have

00:25:41,850 --> 00:25:48,010
told what is congressional idence

00:25:45,010 --> 00:25:52,809
algorithm we have one two three four

00:25:48,010 --> 00:25:56,470
five six maybe some more these

00:25:52,809 --> 00:25:58,899
algorithms we have algorithm renal which

00:25:56,470 --> 00:26:03,130
is traditional tcp used by almost all

00:25:58,899 --> 00:26:05,230
other operating systems so linux does

00:26:03,130 --> 00:26:08,140
not use to reno

00:26:05,230 --> 00:26:11,080
but Windows operating systems and solder

00:26:08,140 --> 00:26:16,390
are using this then we have cubic cubic

00:26:11,080 --> 00:26:19,210
TCP big big TCP Hamilton TCP hdcp it's

00:26:16,390 --> 00:26:22,270
very popular and if we are using 10 gig

00:26:19,210 --> 00:26:25,110
networks or one even one big networks is

00:26:22,270 --> 00:26:29,290
where it's a good recommendation to use

00:26:25,110 --> 00:26:31,690
HTTP the 10 Vegas this is TCP Vegas and

00:26:29,290 --> 00:26:35,260
westwood it's a vest booties optimized

00:26:31,690 --> 00:26:40,450
for those networks which one do you use

00:26:35,260 --> 00:26:44,130
just check it with see CTL in and it

00:26:40,450 --> 00:26:47,830
will write which algorithm are you using

00:26:44,130 --> 00:26:50,350
ok we have few minutes when we are

00:26:47,830 --> 00:26:53,770
talking about memory optimization if you

00:26:50,350 --> 00:26:56,799
have system a 16 gig memory installed on

00:26:53,770 --> 00:26:58,929
your system you have system gig 16 gigs

00:26:56,799 --> 00:27:03,100
of physical memory what is virtual

00:26:58,929 --> 00:27:05,470
memory virtual memory it's swap swap

00:27:03,100 --> 00:27:07,870
space available on the disk + physical

00:27:05,470 --> 00:27:11,049
memory the virtual memory contains both

00:27:07,870 --> 00:27:14,110
user space and kernel space using killer

00:27:11,049 --> 00:27:16,809
32-bit or 64-bit systems make a big

00:27:14,110 --> 00:27:20,020
difference in how much memory approaches

00:27:16,809 --> 00:27:22,390
can utilized on a 32-bit systems

00:27:20,020 --> 00:27:25,960
approaches can only access a maximum of

00:27:22,390 --> 00:27:30,070
4gb virtual memory so if you are using

00:27:25,960 --> 00:27:32,440
32-bit systems your swap file will the

00:27:30,070 --> 00:27:36,610
biggest what pal will be four gigabytes

00:27:32,440 --> 00:27:42,250
and not more on a 64-bit system terry's

00:27:36,610 --> 00:27:45,370
no such limitation a more about memory

00:27:42,250 --> 00:27:48,850
optimization unused memory will be used

00:27:45,370 --> 00:27:51,370
as file system cache vital Cornell Linux

00:27:48,850 --> 00:27:53,440
system will set a swap when it needs

00:27:51,370 --> 00:27:56,350
more memory in example when it needs

00:27:53,440 --> 00:27:59,320
more memory 10 we have the physical

00:27:56,350 --> 00:28:01,270
memory when it swaps it writes the least

00:27:59,320 --> 00:28:03,610
used memory pages from the physical

00:28:01,270 --> 00:28:08,710
memory to the swap space on this but

00:28:03,610 --> 00:28:11,440
this is not good or thesis slow lot of

00:28:08,710 --> 00:28:13,299
swapping can cause permanent issues as

00:28:11,440 --> 00:28:15,370
the disk is much slower than the

00:28:13,299 --> 00:28:18,190
physical memory and it takes time to

00:28:15,370 --> 00:28:18,650
swap the memory pages from memory to

00:28:18,190 --> 00:28:21,440
this

00:28:18,650 --> 00:28:25,760
if you are using some technical

00:28:21,440 --> 00:28:27,650
virtualization like kvm sand vmware or

00:28:25,760 --> 00:28:29,930
something like that you will see when

00:28:27,650 --> 00:28:33,160
one of your servers are going into

00:28:29,930 --> 00:28:37,850
swapping you will see the decreased

00:28:33,160 --> 00:28:40,130
performers of your disks when we are

00:28:37,850 --> 00:28:42,620
talking about memory optimization we are

00:28:40,130 --> 00:28:45,830
talking about dense memory which is hard

00:28:42,620 --> 00:28:51,160
for specific we are we must use Numa

00:28:45,830 --> 00:28:53,510
non-uniform memory access huge pages and

00:28:51,160 --> 00:28:57,110
we are talking about how to manage

00:28:53,510 --> 00:28:59,840
virtual memory pages new mutt is user

00:28:57,110 --> 00:29:02,300
level demon to automatically improve out

00:28:59,840 --> 00:29:05,840
of the Numa system performance it's

00:29:02,300 --> 00:29:10,190
available from fedora 17 Red Hat

00:29:05,840 --> 00:29:14,420
Enterprise Linux is 6.2 6.3 I think open

00:29:10,190 --> 00:29:18,500
suse 10.1 and it's not enabled by

00:29:14,420 --> 00:29:21,200
default not even now if you are using 10

00:29:18,500 --> 00:29:25,250
weeks or 40 gigs network you must turn

00:29:21,200 --> 00:29:27,890
on new mod no matter Deema in nuuma

00:29:25,250 --> 00:29:29,900
demon it monitors available system

00:29:27,890 --> 00:29:32,420
resources on a per node basis and

00:29:29,900 --> 00:29:34,490
assigns significant consumer processes

00:29:32,420 --> 00:29:37,580
to align resources for optimum

00:29:34,490 --> 00:29:40,670
performance it rebalances when necessary

00:29:37,580 --> 00:29:42,470
and provides replacement advice for the

00:29:40,670 --> 00:29:47,990
best initial protest placement in

00:29:42,470 --> 00:29:51,380
research affinity huge pages all we

00:29:47,990 --> 00:29:56,510
which we are using databases we must use

00:29:51,380 --> 00:29:59,810
huge pages it's to make space versus of

00:29:56,510 --> 00:30:03,020
4 kilo pages like which is standard in

00:29:59,810 --> 00:30:06,320
Linux page traditional huge pages are

00:30:03,020 --> 00:30:08,090
always pinned transparent huge pages are

00:30:06,320 --> 00:30:11,450
available from Red Hat Enterprise Linux

00:30:08,090 --> 00:30:16,270
6 and suse linux enterprise several 11

00:30:11,450 --> 00:30:20,750
and most databases support huge pages

00:30:16,270 --> 00:30:23,780
flashing cash when we are when we want

00:30:20,750 --> 00:30:26,750
to drop a new sketch we need to free

00:30:23,780 --> 00:30:28,330
unused memory file cache if the database

00:30:26,750 --> 00:30:31,750
use cash may

00:30:28,330 --> 00:30:36,039
may notice a slow down slow down if we

00:30:31,750 --> 00:30:39,220
want to flush cash we can free page page

00:30:36,039 --> 00:30:42,789
with this first comment sent a whole one

00:30:39,220 --> 00:30:45,850
to drop caches when we want to free slap

00:30:42,789 --> 00:30:48,880
cash with just sent a hoe to and when we

00:30:45,850 --> 00:30:51,640
want to free the both of them just we

00:30:48,880 --> 00:30:54,669
send a code three two dog cashes it

00:30:51,640 --> 00:30:57,039
helps but not always maybe the final

00:30:54,669 --> 00:31:00,100
solution will be to reboot your server

00:30:57,039 --> 00:31:02,200
or if you make any of these comments a

00:31:00,100 --> 00:31:04,120
whole one a hotel or a ho three you must

00:31:02,200 --> 00:31:06,539
wait a few minutes it will not be

00:31:04,120 --> 00:31:10,690
instantly like okay I need free memory

00:31:06,539 --> 00:31:16,539
2010 it will be freed it will take 5 10

00:31:10,690 --> 00:31:19,630
maybe 15 minutes I think we are almost

00:31:16,539 --> 00:31:22,059
finished with the time ok so happiness

00:31:19,630 --> 00:31:24,519
controls how aggressively the system

00:31:22,059 --> 00:31:27,370
reclaims mapped memory defaults weapon s

00:31:24,519 --> 00:31:30,190
is 60 persons decreasing is more

00:31:27,370 --> 00:31:32,860
aggressive or claiming of unmap page

00:31:30,190 --> 00:31:36,059
cache memory increasing more

00:31:32,860 --> 00:31:38,980
aggressively sweeping of mapped memory

00:31:36,059 --> 00:31:41,230
8020 rule maybe you know what is this

00:31:38,980 --> 00:31:43,059
eighty percent of the performance

00:31:41,230 --> 00:31:46,029
improvements comes from the tuning the

00:31:43,059 --> 00:31:48,450
application and the rest 20 person comes

00:31:46,029 --> 00:31:52,269
from the tuning of the infrastructure

00:31:48,450 --> 00:31:56,529
components maybe this is not anymore

00:31:52,269 --> 00:31:59,200
8020 like it's best fifty-fifty so

00:31:56,529 --> 00:32:02,289
system monitoring tools vmstat nets that

00:31:59,200 --> 00:32:06,480
PA stop eh stop eh stop em top I estate

00:32:02,289 --> 00:32:09,130
xos view which is four x window system

00:32:06,480 --> 00:32:11,710
when we are talking about Colonel tuning

00:32:09,130 --> 00:32:14,830
you can try to recompile your kernel

00:32:11,710 --> 00:32:18,269
exclude any unneeded modules maybe use

00:32:14,830 --> 00:32:21,940
realtime kernel if you have such

00:32:18,269 --> 00:32:26,139
applications make Crennel smaller you

00:32:21,940 --> 00:32:31,570
can try even what will happen if you use

00:32:26,139 --> 00:32:34,120
kernel for which is faster benchmarking

00:32:31,570 --> 00:32:36,700
a good set of benchmarking utilities are

00:32:34,120 --> 00:32:39,850
often very helpful it's impossible to

00:32:36,700 --> 00:32:40,940
duplicate real world situation in like a

00:32:39,850 --> 00:32:43,790
stinker

00:32:40,940 --> 00:32:44,840
production environment but it that isn't

00:32:43,790 --> 00:32:47,480
the real the goal of the good

00:32:44,840 --> 00:32:49,490
benchmarking a good benchmark typically

00:32:47,480 --> 00:32:51,560
it tries to measure the performance of

00:32:49,490 --> 00:32:53,960
the particular things very accurately if

00:32:51,560 --> 00:32:58,040
you understand what the benchmarks are

00:32:53,960 --> 00:33:02,570
doing they can be very useful tools few

00:32:58,040 --> 00:33:05,420
benchmarking tools and for the last

00:33:02,570 --> 00:33:08,090
slide identifying solve performance

00:33:05,420 --> 00:33:10,340
issues we need to understand the problem

00:33:08,090 --> 00:33:12,020
so half of the problem is solved when

00:33:10,340 --> 00:33:15,050
you clearly understand what the problem

00:33:12,020 --> 00:33:17,420
is we must monitor and collect data

00:33:15,050 --> 00:33:19,430
after defining the problem clearly

00:33:17,420 --> 00:33:21,710
monitor the system and try to collect as

00:33:19,430 --> 00:33:24,700
much data as possible on a various

00:33:21,710 --> 00:33:27,020
subsystems like network CPU memory

00:33:24,700 --> 00:33:30,410
eliminate and narrow down issues after

00:33:27,020 --> 00:33:32,930
having a list of potentially issues dive

00:33:30,410 --> 00:33:35,990
into each one of them and eliminate any

00:33:32,930 --> 00:33:39,290
non issues the most important always

00:33:35,990 --> 00:33:41,690
make one change at the time don't try to

00:33:39,290 --> 00:33:46,430
make multiple changes because you will

00:33:41,690 --> 00:33:51,800
not know what help and what not ok tits

00:33:46,430 --> 00:33:54,230
all I have five minute overtime if

00:33:51,800 --> 00:33:56,870
anyone have any question i will give

00:33:54,230 --> 00:33:58,880
place for another speaker i will be

00:33:56,870 --> 00:34:03,110
around here and you can ask me anything

00:33:58,880 --> 00:34:06,850
you want i hope that this session was

00:34:03,110 --> 00:34:06,850

YouTube URL: https://www.youtube.com/watch?v=Vyh3p-jyFa4


