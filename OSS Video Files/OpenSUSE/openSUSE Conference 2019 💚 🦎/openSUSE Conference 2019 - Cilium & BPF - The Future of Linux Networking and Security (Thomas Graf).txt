Title: openSUSE Conference 2019 - Cilium & BPF - The Future of Linux Networking and Security (Thomas Graf)
Publication date: 2019-05-25
Playlist: openSUSE Conference 2019 ðŸ’š ðŸ¦Ž
Description: 
	https://media.ccc.de/v/2555-cilium-bpf-the-future-of-linux-networking-and-security-keynote-thomas-graf-cilium



Linux is the dominant platform to run microservices using cloud-native architectures. These modern architectures impose new challenges on the platform serving the applications. We'll take a peek at BPF and Cilium and how it revolutionizes both networking and security to enable platforms built on top of it to fully utilize the benefits of cloud-native architectures. 

Thomas Graf is Co-Founder & CTO at Isovalent and creator of the Cilium project. Before this, Thomas has been a Linux kernel developer at RedHat for many years.


Linux is the dominant platform to run microservices using cloud-native architectures. These modern architectures impose new challenges on the platform serving the applications. We'll take a peek at BPF and Cilium and how it revolutionizes both networking and security to enable platforms built on top of it to fully utilize the benefits of cloud-native architectures. 

Thomas Graf is Co-Founder & CTO at Isovalent and creator of the Cilium project. Before this, Thomas has been a Linux kernel developer at RedHat for many years.


Thomas Graf
Captions: 
	00:00:05,670 --> 00:00:11,950
good morning or guten morgen my name is

00:00:09,309 --> 00:00:14,710
Thomas Krav I'm one of the founders of

00:00:11,950 --> 00:00:16,810
the solium project and the co-founder

00:00:14,710 --> 00:00:20,230
and CTO of the company behind it which

00:00:16,810 --> 00:00:23,350
is called ISO valent today I'm here to

00:00:20,230 --> 00:00:25,150
talk about so Liam and PPF and why we

00:00:23,350 --> 00:00:26,230
believe it is the future of networking

00:00:25,150 --> 00:00:29,019
and security

00:00:26,230 --> 00:00:31,720
my background is very Linux specific so

00:00:29,019 --> 00:00:32,650
I've been a kernel developer for about

00:00:31,720 --> 00:00:35,050
15 years

00:00:32,650 --> 00:00:37,899
not for Susie I was working for Red Hat

00:00:35,050 --> 00:00:42,969
for 10 years but obviously we all were

00:00:37,899 --> 00:00:45,820
all friends so let me grab my presenter

00:00:42,969 --> 00:00:48,489
so I would like to introduce to you why

00:00:45,820 --> 00:00:50,020
we actually why we started with cilium

00:00:48,489 --> 00:00:53,469
and for that I would like to give you

00:00:50,020 --> 00:00:56,800
some background and before I even

00:00:53,469 --> 00:00:59,920
started working in computers computers

00:00:56,800 --> 00:01:00,370
were a thing and this age that I'm about

00:00:59,920 --> 00:01:02,079
to present

00:01:00,370 --> 00:01:03,579
I didn't even experience myself but I

00:01:02,079 --> 00:01:05,680
would like to kind of walk you through

00:01:03,579 --> 00:01:10,090
how we have been running applications

00:01:05,680 --> 00:01:12,939
over the last 20 years plus in the very

00:01:10,090 --> 00:01:15,310
beginning that was this dark age where

00:01:12,939 --> 00:01:17,140
we had single tasking right the cpu was

00:01:15,310 --> 00:01:19,420
not even shared this I did not

00:01:17,140 --> 00:01:21,549
experience I was not I was not into

00:01:19,420 --> 00:01:24,460
computers when this happen but we were

00:01:21,549 --> 00:01:25,869
already running applications or code we

00:01:24,460 --> 00:01:28,000
went into a phase where we were

00:01:25,869 --> 00:01:31,119
introducing multitasking and all of a

00:01:28,000 --> 00:01:33,130
sudden the cpu memory was shared but the

00:01:31,119 --> 00:01:36,790
application would still run and directly

00:01:33,130 --> 00:01:38,530
consume CPU memory and so on this was

00:01:36,790 --> 00:01:41,020
the age when Linux distribution started

00:01:38,530 --> 00:01:43,119
popping up like Suzy got started radical

00:01:41,020 --> 00:01:45,909
started and so on we then entered a

00:01:43,119 --> 00:01:47,500
stage of virtualization we figured I

00:01:45,909 --> 00:01:49,659
don't want to actually deploy my

00:01:47,500 --> 00:01:51,909
application on a server and install it I

00:01:49,659 --> 00:01:53,860
would like to virtualize this run VMs

00:01:51,909 --> 00:01:56,799
and run many applications on a

00:01:53,860 --> 00:01:59,399
particular server but inside of a VM at

00:01:56,799 --> 00:02:01,930
this point we started virtualizing

00:01:59,399 --> 00:02:04,750
literally everything we had virtual

00:02:01,930 --> 00:02:07,270
routers virtual switches virtual storage

00:02:04,750 --> 00:02:10,329
everything we had before was done again

00:02:07,270 --> 00:02:12,910
but Raviv was put in front of it what

00:02:10,329 --> 00:02:15,430
were what we're going for right now is

00:02:12,910 --> 00:02:17,890
we're coming back we're hiding out of

00:02:15,430 --> 00:02:18,650
VMs again and we're running applications

00:02:17,890 --> 00:02:20,840
there are

00:02:18,650 --> 00:02:22,099
plea consuming Linux api's again so

00:02:20,840 --> 00:02:24,769
applications are actually like

00:02:22,099 --> 00:02:26,900
containers we are consuming Linux system

00:02:24,769 --> 00:02:29,120
called api's again and we're making

00:02:26,900 --> 00:02:30,590
applications share the operating system

00:02:29,120 --> 00:02:34,370
so we're kind of going back to the

00:02:30,590 --> 00:02:36,470
multitasking edge in some way and this

00:02:34,370 --> 00:02:38,510
change back this is why we started

00:02:36,470 --> 00:02:40,430
solium because most of the

00:02:38,510 --> 00:02:42,170
infrastructure tooling we have today was

00:02:40,430 --> 00:02:44,060
actually written for this virtualization

00:02:42,170 --> 00:02:45,950
edge right we're where we would

00:02:44,060 --> 00:02:48,709
typically serve network packets or

00:02:45,950 --> 00:02:52,129
storage for virtual machines and not for

00:02:48,709 --> 00:02:54,170
for applications specifically so what

00:02:52,129 --> 00:02:56,000
does that mean like how does the Linux

00:02:54,170 --> 00:02:58,400
kernel cope for this new age of micro

00:02:56,000 --> 00:03:00,349
services in cloud native world let's

00:02:58,400 --> 00:03:02,359
take a look at some of the problems that

00:03:00,349 --> 00:03:04,280
are kind of arise when we run micro

00:03:02,359 --> 00:03:06,709
services or containers on linux first of

00:03:04,280 --> 00:03:08,480
all linux the Linux kernel basically

00:03:06,709 --> 00:03:10,340
consists of a ton of abstractions that

00:03:08,480 --> 00:03:12,950
have been introduced over the years I'm

00:03:10,340 --> 00:03:14,299
listing a couple of here there are many

00:03:12,950 --> 00:03:16,280
many more right we have kind of the

00:03:14,299 --> 00:03:18,290
driver level on top of top of that we

00:03:16,280 --> 00:03:20,090
have kind of network or device level for

00:03:18,290 --> 00:03:23,930
example and traffic shaping built on top

00:03:20,090 --> 00:03:25,699
then routing IP tables filtering then we

00:03:23,930 --> 00:03:28,340
have sockets if the different protocol

00:03:25,699 --> 00:03:30,530
layers we cannot actually bypass many of

00:03:28,340 --> 00:03:32,299
those we're forced to consume each of

00:03:30,530 --> 00:03:34,849
them in the right order and over the

00:03:32,299 --> 00:03:36,829
years if we have accumulated a lot of

00:03:34,849 --> 00:03:38,750
code in the Linux kernel and right now

00:03:36,829 --> 00:03:40,669
this duffel increases the chance that

00:03:38,750 --> 00:03:42,650
you hit a Bay for example a performance

00:03:40,669 --> 00:03:45,560
penalty some of what we would actually

00:03:42,650 --> 00:03:47,419
like to get rid of in the last couple of

00:03:45,560 --> 00:03:49,220
years we've seen some of the complexity

00:03:47,419 --> 00:03:50,690
moved to user space for this purpose

00:03:49,220 --> 00:03:53,000
because not everybody was willing to pay

00:03:50,690 --> 00:03:54,560
this cost we we are we identified and

00:03:53,000 --> 00:03:57,500
said this is actually not ideal let's

00:03:54,560 --> 00:04:00,280
find a solution that we can what can

00:03:57,500 --> 00:04:03,379
work with the existing abstractions but

00:04:00,280 --> 00:04:06,440
but but bypass them when necessary for

00:04:03,379 --> 00:04:08,479
example go into the details another

00:04:06,440 --> 00:04:10,989
thing is that this is kind of the UNIX

00:04:08,479 --> 00:04:13,459
UNIX way of doing things every single

00:04:10,989 --> 00:04:16,760
subsystem in the Linux kernel has its

00:04:13,459 --> 00:04:19,430
own API right so we don't have one big

00:04:16,760 --> 00:04:21,709
tool to control everything every single

00:04:19,430 --> 00:04:24,199
subsystem is controlled by is by it by a

00:04:21,709 --> 00:04:26,210
separate tool like we have four bits

00:04:24,199 --> 00:04:28,580
networking specific bot but we have east

00:04:26,210 --> 00:04:30,289
tool they have IP they have if convict

00:04:28,580 --> 00:04:30,870
we have SATCOM we have IP tables the

00:04:30,289 --> 00:04:32,820
FTC's

00:04:30,870 --> 00:04:35,010
we have tcpdump we have British control

00:04:32,820 --> 00:04:38,100
we have obvious cattle and so on are

00:04:35,010 --> 00:04:40,650
white ears of tools and users have to

00:04:38,100 --> 00:04:42,900
consume every single tool and users

00:04:40,650 --> 00:04:44,910
that's not necessarily an actual human

00:04:42,900 --> 00:04:46,680
that could be an automated tool that

00:04:44,910 --> 00:04:49,140
controls the system and all of these

00:04:46,680 --> 00:04:51,170
tools are calling calling it's api's it

00:04:49,140 --> 00:04:53,580
is becoming very difficult to actually

00:04:51,170 --> 00:04:56,070
orchestrate all of them together a very

00:04:53,580 --> 00:04:59,310
specific example is if you have five six

00:04:56,070 --> 00:05:01,560
tools on your machine on your nodes all

00:04:59,310 --> 00:05:03,420
consuming iptables and trying to install

00:05:01,560 --> 00:05:07,890
IP TripIt table rules that then actually

00:05:03,420 --> 00:05:10,920
conflict with each other the last kind

00:05:07,890 --> 00:05:14,310
of example that makes it difficult is

00:05:10,920 --> 00:05:16,410
that cloud native cognitive computing

00:05:14,310 --> 00:05:18,960
requires that the operating system

00:05:16,410 --> 00:05:20,790
continues evolving because it now again

00:05:18,960 --> 00:05:23,610
consumes the operating system in a very

00:05:20,790 --> 00:05:25,890
native way the Linux kernel development

00:05:23,610 --> 00:05:27,330
process has some good sides and some bad

00:05:25,890 --> 00:05:31,380
sides so like the good sides are

00:05:27,330 --> 00:05:32,910
definitely its own open and it's an open

00:05:31,380 --> 00:05:35,760
transparent process this is probably the

00:05:32,910 --> 00:05:37,730
biggest biggest benefit of Linux that

00:05:35,760 --> 00:05:40,350
it's completely open

00:05:37,730 --> 00:05:43,050
excellent code quality at least we think

00:05:40,350 --> 00:05:44,730
so it's very stable because a lot of

00:05:43,050 --> 00:05:46,530
people are running it and has been as

00:05:44,730 --> 00:05:48,210
been stabilized over many years it's

00:05:46,530 --> 00:05:51,680
available everywhere relational runs on

00:05:48,210 --> 00:05:51,680
every piece of every piece of hardware

00:05:52,520 --> 00:05:58,410
it's almost entirely vendor neutral but

00:05:56,250 --> 00:05:59,970
then there's some bad things as well how

00:05:58,410 --> 00:06:03,330
much light pointer is a bit bit slow

00:05:59,970 --> 00:06:05,460
here that's why I'm base charlie it's

00:06:03,330 --> 00:06:07,830
really really hard to change so getting

00:06:05,460 --> 00:06:10,170
a Linux kernel change in literally takes

00:06:07,830 --> 00:06:12,060
weeks or months from intent to

00:06:10,170 --> 00:06:14,640
implementation to getting a change in

00:06:12,060 --> 00:06:16,260
takes weeks and then it takes months or

00:06:14,640 --> 00:06:18,600
a year until that change actually makes

00:06:16,260 --> 00:06:20,640
it down to the users so once we have

00:06:18,600 --> 00:06:22,710
identified a need for a change

00:06:20,640 --> 00:06:25,500
it takes us years to actually get to the

00:06:22,710 --> 00:06:27,690
end user for consumptions this is what

00:06:25,500 --> 00:06:30,840
we see most of the kind of tooling that

00:06:27,690 --> 00:06:33,570
we built consuming very old API is right

00:06:30,840 --> 00:06:35,340
like cloud native computing tooling is

00:06:33,570 --> 00:06:38,160
currently built on for example IP tables

00:06:35,340 --> 00:06:39,990
which has been built 25 years ago it's

00:06:38,160 --> 00:06:41,520
not been intended for this at all but it

00:06:39,990 --> 00:06:43,350
we're really struggling to do something

00:06:41,520 --> 00:06:44,500
else because it's so hard to change the

00:06:43,350 --> 00:06:48,430
column and make that change

00:06:44,500 --> 00:06:50,140
available to users quickly it has a very

00:06:48,430 --> 00:06:51,760
large and complicated code base and this

00:06:50,140 --> 00:06:53,350
is simply because of backwards

00:06:51,760 --> 00:06:55,360
compatibility right we were never

00:06:53,350 --> 00:06:57,400
actually removing code we're only adding

00:06:55,360 --> 00:06:59,350
adding adding and then everything we

00:06:57,400 --> 00:07:02,320
ever added we have to support for the

00:06:59,350 --> 00:07:05,790
next how many years like we're never

00:07:02,320 --> 00:07:08,410
actually removing anything ever again

00:07:05,790 --> 00:07:09,850
upstream the code is hard are not just

00:07:08,410 --> 00:07:11,590
from a complexity perspective but also

00:07:09,850 --> 00:07:14,080
from a consensus finding perspective

00:07:11,590 --> 00:07:16,180
everything will change pretty much

00:07:14,080 --> 00:07:20,980
everybody has to agree to it this is

00:07:16,180 --> 00:07:24,100
making it hard time-consuming of course

00:07:20,980 --> 00:07:25,630
and then yeah I already talked about

00:07:24,100 --> 00:07:29,020
this it can be it can take years to

00:07:25,630 --> 00:07:30,940
become available so these are some of

00:07:29,020 --> 00:07:39,310
the problems you have been struggling

00:07:30,940 --> 00:07:41,169
with and then also the last one the

00:07:39,310 --> 00:07:43,120
kernel doesn't actually really know what

00:07:41,169 --> 00:07:48,010
a container is or what kind of the base

00:07:43,120 --> 00:07:49,690
the base base unit of an application is

00:07:48,010 --> 00:07:51,040
at this point so let's figure out what

00:07:49,690 --> 00:07:53,580
the kernel actually knows and what it

00:07:51,040 --> 00:07:56,020
doesn't know so what the kernel nose is

00:07:53,580 --> 00:07:57,550
it knows about processes and it knows

00:07:56,020 --> 00:08:00,220
about threat groups right he doesn't

00:07:57,550 --> 00:08:02,280
actually know specifically what is an

00:08:00,220 --> 00:08:06,850
application it knows about cgroups

00:08:02,280 --> 00:08:08,800
container is consuming cgroups it has

00:08:06,850 --> 00:08:10,150
limits like it can do accounting it can

00:08:08,800 --> 00:08:13,800
do it can limit the CPU

00:08:10,150 --> 00:08:17,050
I can limit memory can limit Network

00:08:13,800 --> 00:08:18,970
this cgroups is configured by the

00:08:17,050 --> 00:08:21,520
container on time we see it knows about

00:08:18,970 --> 00:08:23,260
namespaces this is where the confusion

00:08:21,520 --> 00:08:24,700
or kind of the assumption is coming from

00:08:23,260 --> 00:08:27,250
that containers are some sort of

00:08:24,700 --> 00:08:28,660
isolation but literally all there is is

00:08:27,250 --> 00:08:31,270
that the kernel will kind of namespace

00:08:28,660 --> 00:08:33,010
certain data structures and for example

00:08:31,270 --> 00:08:35,020
have multiple Network namespaces or

00:08:33,010 --> 00:08:36,820
multiple username spaces or multiple

00:08:35,020 --> 00:08:38,050
mount namespaces and so on it doesn't

00:08:36,820 --> 00:08:40,030
actually still don't know what a

00:08:38,050 --> 00:08:43,979
container is all it knows is that I have

00:08:40,030 --> 00:08:43,979
multiple namespaces for data structures

00:08:46,020 --> 00:08:51,490
it knows about IP addresses and port

00:08:48,610 --> 00:08:52,839
numbers this is called this is kind of

00:08:51,490 --> 00:08:54,339
figured butter container networking and

00:08:52,839 --> 00:08:56,050
it knows about system calls made Eddie

00:08:54,339 --> 00:08:57,600
knows about the selinux context this is

00:08:56,050 --> 00:08:59,279
pretty much what

00:08:57,600 --> 00:09:00,839
the colonel knows about it does not

00:08:59,279 --> 00:09:08,370
actually know that I'm running this

00:09:00,839 --> 00:09:09,810
particular container so examples here of

00:09:08,370 --> 00:09:12,360
things that the colonel has no clue

00:09:09,810 --> 00:09:14,160
about the colonel does not know what

00:09:12,360 --> 00:09:15,660
kubernetes is the colonel does not know

00:09:14,160 --> 00:09:17,220
what a keeping at his parties the

00:09:15,660 --> 00:09:20,490
colonel does not know what the container

00:09:17,220 --> 00:09:23,639
ID is no clue the colonel does not know

00:09:20,490 --> 00:09:24,930
what the what the application actually

00:09:23,639 --> 00:09:26,759
would like to run so if you're running a

00:09:24,930 --> 00:09:28,470
kubernetes part which consists of

00:09:26,759 --> 00:09:29,790
multiple containers the colonel does not

00:09:28,470 --> 00:09:34,019
know that these containers are actually

00:09:29,790 --> 00:09:35,790
supposed to kind of work together so all

00:09:34,019 --> 00:09:37,470
of these things kind of makes makes the

00:09:35,790 --> 00:09:39,750
colonel struggle to provide a good

00:09:37,470 --> 00:09:42,120
application framework because it's there

00:09:39,750 --> 00:09:43,589
is no concept no native concept such as

00:09:42,120 --> 00:09:45,389
a container in the kernel it only

00:09:43,589 --> 00:09:50,370
provides the tooling and the container

00:09:45,389 --> 00:09:52,230
on time on top provides kind of the the

00:09:50,370 --> 00:09:57,620
instruments for a container run time to

00:09:52,230 --> 00:09:59,730
to use that so what do we do like

00:09:57,620 --> 00:10:01,529
containers a clear thing and containers

00:09:59,730 --> 00:10:04,139
are waiting so what do we do we have a

00:10:01,529 --> 00:10:06,630
couple of options we can give all of

00:10:04,139 --> 00:10:08,189
kind of gift hauteur a way to use your

00:10:06,630 --> 00:10:10,800
space your space can kind of rewrite

00:10:08,189 --> 00:10:12,569
everything from scratch like we've seen

00:10:10,800 --> 00:10:15,060
that a couple of examples would be DP d

00:10:12,569 --> 00:10:17,819
k UD MA typically this has been done for

00:10:15,060 --> 00:10:20,970
performance not for functionality not

00:10:17,819 --> 00:10:22,920
for functionality needs another one

00:10:20,970 --> 00:10:25,110
other alternative would be unicorn ultra

00:10:22,920 --> 00:10:27,449
we can start I kind of just rewriting a

00:10:25,110 --> 00:10:29,250
new kernel subsystem unit kernel and

00:10:27,449 --> 00:10:32,040
start half applications consume their

00:10:29,250 --> 00:10:35,459
own own pieces of operating system on

00:10:32,040 --> 00:10:37,680
only consume what they actually need we

00:10:35,459 --> 00:10:39,329
can move the entire operating system to

00:10:37,680 --> 00:10:41,279
user space like user mostly you know

00:10:39,329 --> 00:10:43,560
user mode Linux has been a thing so it

00:10:41,279 --> 00:10:45,990
has been tried and some people are using

00:10:43,560 --> 00:10:48,420
it or we can decide to rewrite the

00:10:45,990 --> 00:10:51,029
entire Linux kernel which is probably a

00:10:48,420 --> 00:10:52,980
hard task and quite expensive the

00:10:51,029 --> 00:10:55,050
calculation up on the slide is very all

00:10:52,980 --> 00:10:56,850
it's probably way more expensive to

00:10:55,050 --> 00:11:00,949
actually really do it but this is an

00:10:56,850 --> 00:11:00,949
option that we could we could follow

00:11:02,210 --> 00:11:11,130
come on so we're not kind of fading into

00:11:08,870 --> 00:11:12,840
this is the background like so it's

00:11:11,130 --> 00:11:14,760
clearly not a perfect fit so let's look

00:11:12,840 --> 00:11:17,370
at like how we could do it better and in

00:11:14,760 --> 00:11:19,350
order to understand BPF is what we're

00:11:17,370 --> 00:11:21,570
using we need to understand what the

00:11:19,350 --> 00:11:24,030
kernel actually does it's fundamentally

00:11:21,570 --> 00:11:26,010
an event-driven program we have

00:11:24,030 --> 00:11:28,200
interrupts coming from the hardware side

00:11:26,010 --> 00:11:29,970
and we have system calls coming from our

00:11:28,200 --> 00:11:32,220
application and processes and the kernel

00:11:29,970 --> 00:11:34,050
will execute code based on these events

00:11:32,220 --> 00:11:35,460
that's fondler are fundamentally what

00:11:34,050 --> 00:11:40,560
the kernel does there's not much more

00:11:35,460 --> 00:11:42,720
than it actually does so it takes about

00:11:40,560 --> 00:11:48,180
one minute or like 10 seconds to go to

00:11:42,720 --> 00:11:51,330
the next slide so what is BPF so BPF is

00:11:48,180 --> 00:11:53,580
consuming this base assumption that

00:11:51,330 --> 00:11:55,740
everything is event-driven and it makes

00:11:53,580 --> 00:11:57,690
the Linux kernel programmable so it

00:11:55,740 --> 00:11:59,520
introduces what we call a highly

00:11:57,690 --> 00:12:02,250
efficient in kernel virtual machine

00:11:59,520 --> 00:12:05,070
which means that we have some sandbox

00:12:02,250 --> 00:12:06,090
concept where we can run code in a safe

00:12:05,070 --> 00:12:08,460
and efficient manner

00:12:06,090 --> 00:12:10,890
every time certain events are being

00:12:08,460 --> 00:12:13,080
handled or are being are popping up

00:12:10,890 --> 00:12:14,670
inside of the Linux kernel and we'll

00:12:13,080 --> 00:12:17,550
look at a couple of examples on the next

00:12:14,670 --> 00:12:20,280
slide so we can run a BPF program every

00:12:17,550 --> 00:12:22,890
time a system call is being made or we

00:12:20,280 --> 00:12:25,380
can run a DPF program every time a block

00:12:22,890 --> 00:12:28,020
IO device is being accessed we can call

00:12:25,380 --> 00:12:29,790
a and run a BPF program every time a

00:12:28,020 --> 00:12:32,130
network packet is being received or sent

00:12:29,790 --> 00:12:33,660
we can call it for every trace form so

00:12:32,130 --> 00:12:35,820
we can call it for example when a tree

00:12:33,660 --> 00:12:37,590
CP retransmission event happens we can

00:12:35,820 --> 00:12:39,720
call it for kernel probes so for

00:12:37,590 --> 00:12:41,730
arbitrary kernel functions and even for

00:12:39,720 --> 00:12:44,280
user space application functions you

00:12:41,730 --> 00:12:46,500
probes so you can run a BPF program when

00:12:44,280 --> 00:12:49,830
your application code calls a particular

00:12:46,500 --> 00:12:52,110
function Wow so we can we can extend and

00:12:49,830 --> 00:12:54,060
program the Linux kernel with arbitrary

00:12:52,110 --> 00:12:56,070
additional logic when certain events

00:12:54,060 --> 00:12:57,570
happen so this is the promise of BPF and

00:12:56,070 --> 00:13:02,280
this is why so many people are excited

00:12:57,570 --> 00:13:04,080
about this BPF in the wild seems to

00:13:02,280 --> 00:13:06,780
struggle to kind of load some of the

00:13:04,080 --> 00:13:09,420
logos so the first example on the on the

00:13:06,780 --> 00:13:12,450
top left is is Facebook so Facebook is a

00:13:09,420 --> 00:13:14,460
heavy heavy heavy user of BPF all

00:13:12,450 --> 00:13:15,540
infrastructure low plan saying DDoS

00:13:14,460 --> 00:13:19,339
mitigation lope

00:13:15,540 --> 00:13:22,769
is all done in BPF today second example

00:13:19,339 --> 00:13:24,690
Google QoS traffic optimization or

00:13:22,769 --> 00:13:26,070
security profiling we don't know that

00:13:24,690 --> 00:13:29,910
much about this because they're just

00:13:26,070 --> 00:13:31,410
consuming vpf in its raw form and to do

00:13:29,910 --> 00:13:33,660
all of these things but don't tell the

00:13:31,410 --> 00:13:35,310
world a lot about it there is you can go

00:13:33,660 --> 00:13:37,319
find information at some conferences

00:13:35,310 --> 00:13:40,130
what I do talks but typically they're

00:13:37,319 --> 00:13:44,279
not broadcasting everything publicly

00:13:40,130 --> 00:13:47,490
then Suzy Suzy is using solid-like BPF

00:13:44,279 --> 00:13:49,079
via wire solium to do networking

00:13:47,490 --> 00:13:51,269
advanced security Lopo lansing and

00:13:49,079 --> 00:13:54,329
traffic optimization CloudFlare is using

00:13:51,269 --> 00:13:56,790
vpf to do DDoS mitigation Cystic falco

00:13:54,329 --> 00:14:00,540
is using PPA for container runtime and

00:13:56,790 --> 00:14:03,449
behavioral security profiling relatives

00:14:00,540 --> 00:14:04,470
using vpf for profiling tracing and

00:14:03,449 --> 00:14:06,449
they're working on an IP tables

00:14:04,470 --> 00:14:08,310
replacement upstream then of course

00:14:06,449 --> 00:14:10,800
psyllium which we'll talk about next and

00:14:08,310 --> 00:14:14,209
then even chrome is using vpf so when

00:14:10,800 --> 00:14:18,569
you have chrome plugins and you run them

00:14:14,209 --> 00:14:20,069
BPF is used to isolate the plugins and

00:14:18,569 --> 00:14:22,079
make sure that can only execute certain

00:14:20,069 --> 00:14:24,480
system calls so all of you you're

00:14:22,079 --> 00:14:26,579
already using heavily using vpf but so

00:14:24,480 --> 00:14:31,380
far it has been well hidden as kind of a

00:14:26,579 --> 00:14:36,959
kernel level implementation detail now

00:14:31,380 --> 00:14:39,660
they're coming up so how does how does

00:14:36,959 --> 00:14:41,339
BPF look like so like why it's a virtual

00:14:39,660 --> 00:14:42,720
machine what does that mean so what it

00:14:41,339 --> 00:14:46,290
really means in practice I can write a

00:14:42,720 --> 00:14:49,740
program like this simple example and I

00:14:46,290 --> 00:14:52,800
can say this program role runs when the

00:14:49,740 --> 00:14:55,230
x AK system call is is executed and the

00:14:52,800 --> 00:14:58,350
returns and this in this example I'm

00:14:55,230 --> 00:15:00,149
collecting some samples and for example

00:14:58,350 --> 00:15:01,889
measuring how many of those system calls

00:15:00,149 --> 00:15:03,480
am i making but I could actually make

00:15:01,889 --> 00:15:05,189
this program more complex and for

00:15:03,480 --> 00:15:07,680
example say no you are not allowed to

00:15:05,189 --> 00:15:10,050
make this this system call or I could

00:15:07,680 --> 00:15:12,689
modify the system call the system call

00:15:10,050 --> 00:15:14,579
the system call system call arguments so

00:15:12,689 --> 00:15:16,259
I have a lot of flexibility in what I

00:15:14,579 --> 00:15:20,180
can do but this is a very simplistic

00:15:16,259 --> 00:15:22,410
example that shows you what you can do I

00:15:20,180 --> 00:15:24,769
will do a very quick introduction of

00:15:22,410 --> 00:15:28,050
kind of what you can do with PPF so

00:15:24,769 --> 00:15:28,950
nutshell you write code in pseudo Z code

00:15:28,050 --> 00:15:30,360
you can

00:15:28,950 --> 00:15:32,130
pile that you load that into the loons

00:15:30,360 --> 00:15:35,160
colonel balloons colonel will verify

00:15:32,130 --> 00:15:36,630
that the program is safe it will chit

00:15:35,160 --> 00:15:39,090
compile it we'll talk about later and

00:15:36,630 --> 00:15:40,740
then run it in order for these programs

00:15:39,090 --> 00:15:42,930
to kind of communicate to the outside

00:15:40,740 --> 00:15:44,970
role which would be user space you can

00:15:42,930 --> 00:15:47,040
use BPF maps which are data structures

00:15:44,970 --> 00:15:49,350
that can be accessed from both BPF

00:15:47,040 --> 00:15:51,570
programs and also user space this is how

00:15:49,350 --> 00:15:54,710
you can expose for example data that you

00:15:51,570 --> 00:15:57,630
have gathered with a user space process

00:15:54,710 --> 00:15:59,970
there's many types of BPF maps hash

00:15:57,630 --> 00:16:09,510
tables array is perforin but for answer

00:15:59,970 --> 00:16:12,210
what we can do we can call BPF helpers

00:16:09,510 --> 00:16:14,160
or BPF helpers allow BPF programs to

00:16:12,210 --> 00:16:15,750
interact with the Linux kernel so not

00:16:14,160 --> 00:16:18,000
everything has to be done natively in

00:16:15,750 --> 00:16:20,520
BPF bytecode and BPF code you can

00:16:18,000 --> 00:16:22,800
actually call kernel helpers for example

00:16:20,520 --> 00:16:24,270
to change content in a network packet or

00:16:22,800 --> 00:16:27,000
to redirect a packet to another network

00:16:24,270 --> 00:16:29,790
device and so on so all of this is done

00:16:27,000 --> 00:16:33,030
by BPF helpers we can do tail calls so

00:16:29,790 --> 00:16:36,600
we can we can call other BPF programs

00:16:33,030 --> 00:16:38,220
it's similar to function calls we can

00:16:36,600 --> 00:16:40,860
use a JIT compiler which means we've

00:16:38,220 --> 00:16:42,960
write software bytecode which is

00:16:40,860 --> 00:16:44,490
arbitrary runs on any and infrastructure

00:16:42,960 --> 00:16:46,200
and that should compiler in the Linux

00:16:44,490 --> 00:16:49,380
kernel then automatically compile that

00:16:46,200 --> 00:16:52,230
in either into x86 into R and PPC

00:16:49,380 --> 00:16:55,710
whatever so it will run at native at

00:16:52,230 --> 00:16:57,990
native execution speed this is a

00:16:55,710 --> 00:17:00,210
snapshot of the BPF contributors list to

00:16:57,990 --> 00:17:02,100
kind of understand who is behind BPF and

00:17:00,210 --> 00:17:04,589
there's many many companies behind this

00:17:02,100 --> 00:17:06,900
it is maintained by two main engine

00:17:04,589 --> 00:17:09,300
engineer Daniel Bachman and Alex a-star

00:17:06,900 --> 00:17:10,920
avoid of Daniel is working for southern

00:17:09,300 --> 00:17:12,540
frost Alexey is working for Facebook

00:17:10,920 --> 00:17:16,079
while you can see contributions from

00:17:12,540 --> 00:17:18,690
reddit metronome Facebook CloudFlare

00:17:16,079 --> 00:17:20,790
from us and so on so it's a it's not a

00:17:18,690 --> 00:17:25,110
solium specific implementation in any

00:17:20,790 --> 00:17:27,240
way this is widely widely supported who

00:17:25,110 --> 00:17:29,040
uses BPF while Facebook is probably the

00:17:27,240 --> 00:17:31,650
most prominent example was I think they

00:17:29,040 --> 00:17:33,960
started while scale first basically I

00:17:31,650 --> 00:17:36,420
think in 2018 one of the traffic

00:17:33,960 --> 00:17:38,370
engineers came up and talked and

00:17:36,420 --> 00:17:40,770
basically said at the conference well

00:17:38,370 --> 00:17:42,060
every single packet into a facebook data

00:17:40,770 --> 00:17:45,030
center since May 20

00:17:42,060 --> 00:17:46,080
17 has gone through a BPF program and

00:17:45,030 --> 00:17:48,270
they were always kind of Wow

00:17:46,080 --> 00:17:51,870
like nobody had any clue that they were

00:17:48,270 --> 00:17:54,150
using this in production for so long so

00:17:51,870 --> 00:17:56,400
let's let's transition into solium so I

00:17:54,150 --> 00:17:59,460
talked about PPF on it sounds exciting

00:17:56,400 --> 00:18:01,560
right but who wants to write low level C

00:17:59,460 --> 00:18:04,110
code or I actually write these programs

00:18:01,560 --> 00:18:06,210
so this is why we saw this potential

00:18:04,110 --> 00:18:08,760
like this incredible potential of BPF

00:18:06,210 --> 00:18:10,800
and figure how can we apply this to this

00:18:08,760 --> 00:18:13,320
clown Eddie for all T how we can can we

00:18:10,800 --> 00:18:15,270
apply this to darker cuban areas like

00:18:13,320 --> 00:18:17,760
and so on and this is why we created

00:18:15,270 --> 00:18:20,940
sodium so salim is open source open

00:18:17,760 --> 00:18:23,250
source project apache licensed and it

00:18:20,940 --> 00:18:27,900
provides networking security and load

00:18:23,250 --> 00:18:29,790
balancing for cloud native world I will

00:18:27,900 --> 00:18:31,800
dive deep dive into into into several of

00:18:29,790 --> 00:18:34,110
example a very simple one is Q Panetta's

00:18:31,800 --> 00:18:36,090
networking it's called C and I in this

00:18:34,110 --> 00:18:38,520
kind of simple model we simply provide

00:18:36,090 --> 00:18:40,020
networking for Cuban ideas so if your

00:18:38,520 --> 00:18:41,970
own containers if your own parts in

00:18:40,020 --> 00:18:43,680
Cuban Etta's Solem will do all of the

00:18:41,970 --> 00:18:46,110
routing all of the networking for these

00:18:43,680 --> 00:18:48,690
parts and ensure that pots can can talk

00:18:46,110 --> 00:18:51,720
to each other we implement Cuban anis

00:18:48,690 --> 00:18:54,210
services Cuba native services are a way

00:18:51,720 --> 00:18:57,270
to have to make applications scalable

00:18:54,210 --> 00:18:59,700
and give them a virtual IP or a service

00:18:57,270 --> 00:19:03,000
IP so you can reach many replicas of the

00:18:59,700 --> 00:19:04,770
same container while one single RP this

00:19:03,000 --> 00:19:08,460
is how you can make your services highly

00:19:04,770 --> 00:19:10,470
available so Liam with PPF can provides

00:19:08,460 --> 00:19:12,330
a BPF based implementation which scales

00:19:10,470 --> 00:19:15,750
better the main reason it scales better

00:19:12,330 --> 00:19:17,730
to the traditional iptables model is in

00:19:15,750 --> 00:19:19,290
IP tables model is a linear list of

00:19:17,730 --> 00:19:21,240
rules so you literally scan through the

00:19:19,290 --> 00:19:24,180
list of rules until you find a matching

00:19:21,240 --> 00:19:26,190
entry and then execute this the BPF

00:19:24,180 --> 00:19:29,790
application uses a scalable hash table

00:19:26,190 --> 00:19:32,310
that just is faster and better we can do

00:19:29,790 --> 00:19:35,490
cluster mesh so we can we can connect

00:19:32,310 --> 00:19:37,020
multiple clusters together not only on

00:19:35,490 --> 00:19:38,730
the networking level but we can also do

00:19:37,020 --> 00:19:41,310
service low planting across multiple

00:19:38,730 --> 00:19:43,590
clusters so for example say that this

00:19:41,310 --> 00:19:45,120
service should be highly available so I

00:19:43,590 --> 00:19:46,890
will distribute it or deployed over

00:19:45,120 --> 00:19:49,530
multiple clusters and have solium do the

00:19:46,890 --> 00:19:51,210
low planting that when all the replicas

00:19:49,530 --> 00:19:52,380
in one cluster fail it will

00:19:51,210 --> 00:19:54,590
automatically failover

00:19:52,380 --> 00:19:55,890
you can define service affinity and say

00:19:54,590 --> 00:19:58,620
choose all

00:19:55,890 --> 00:20:00,960
prefer a local a local replica first and

00:19:58,620 --> 00:20:03,150
if no local replicas are available move

00:20:00,960 --> 00:20:06,120
over so we can connect multiple clusters

00:20:03,150 --> 00:20:09,210
together we can do identity based

00:20:06,120 --> 00:20:11,700
security what does that mean very simple

00:20:09,210 --> 00:20:13,650
typically firewalls used to work on IP

00:20:11,700 --> 00:20:15,870
addresses so you would either directly

00:20:13,650 --> 00:20:17,790
configure the firewall to say allow from

00:20:15,870 --> 00:20:20,460
this ope allowed to this IP or allow

00:20:17,790 --> 00:20:22,110
this subnet what we're doing is a bit

00:20:20,460 --> 00:20:23,970
more modern we're actually giving an

00:20:22,110 --> 00:20:26,160
identity to every service to every

00:20:23,970 --> 00:20:27,960
container and we're encoding the

00:20:26,160 --> 00:20:29,940
identity in all network in all

00:20:27,960 --> 00:20:33,180
communication on our packets that are

00:20:29,940 --> 00:20:35,460
being being emitted you can see it is

00:20:33,180 --> 00:20:36,990
here this yellow box here and then when

00:20:35,460 --> 00:20:38,640
we receive those packets we can actually

00:20:36,990 --> 00:20:41,400
authenticate and validate the identity

00:20:38,640 --> 00:20:44,670
of the sending container this is more

00:20:41,400 --> 00:20:46,920
secure and much more scalable we can do

00:20:44,670 --> 00:20:49,380
API where authorization like what what

00:20:46,920 --> 00:20:51,900
does that mean it's again it's kind of a

00:20:49,380 --> 00:20:53,790
step from the root of the VM age into

00:20:51,900 --> 00:20:55,140
the container age because typically we

00:20:53,790 --> 00:20:57,210
would have done something like this we

00:20:55,140 --> 00:20:59,160
would have either allow kind of an l-3

00:20:57,210 --> 00:21:00,270
firewall rule or you say this service

00:20:59,160 --> 00:21:01,800
can talk to this service or this

00:21:00,270 --> 00:21:03,510
container can talk to this container and

00:21:01,800 --> 00:21:05,730
typically what do it is based on IP

00:21:03,510 --> 00:21:08,580
addresses or container names were Paul

00:21:05,730 --> 00:21:10,290
labels you can kind of say okay I want

00:21:08,580 --> 00:21:12,090
to be a bit more fine-grained and lock

00:21:10,290 --> 00:21:14,910
it down to a particular port let's say

00:21:12,090 --> 00:21:16,410
you can only talk on port 80 but this is

00:21:14,910 --> 00:21:18,780
still a problem in this new cloud native

00:21:16,410 --> 00:21:21,480
age because everybody's using to your PC

00:21:18,780 --> 00:21:23,610
REST API and so on so literally as you

00:21:21,480 --> 00:21:26,310
open up let's say port 80 you open up

00:21:23,610 --> 00:21:27,780
your entire rest API so what we can do

00:21:26,310 --> 00:21:30,180
is we can for example lock it down and

00:21:27,780 --> 00:21:32,310
say yeah you can talk on port 80 but you

00:21:30,180 --> 00:21:33,690
can only do a gap to slash foo and

00:21:32,310 --> 00:21:35,670
everything else is blocked so if you do

00:21:33,690 --> 00:21:37,320
a put to slash bar we will block it

00:21:35,670 --> 00:21:39,480
automatically that's kind of thing a

00:21:37,320 --> 00:21:41,640
cloud 84 a container aware or an API

00:21:39,480 --> 00:21:43,560
where firewall this is what we believe

00:21:41,640 --> 00:21:46,800
is necessary for this new edge that is

00:21:43,560 --> 00:21:49,050
coming up give you a simple example we

00:21:46,800 --> 00:21:50,490
support many protocols HTTP is obviously

00:21:49,050 --> 00:21:53,160
one but cassandra is another one

00:21:50,490 --> 00:21:55,230
so go as deep and say hey I actually

00:21:53,160 --> 00:21:56,670
want this container to be able to talk

00:21:55,230 --> 00:21:58,320
to my Cassandra cluster but it should

00:21:56,670 --> 00:21:58,920
only be able to do is select and only on

00:21:58,320 --> 00:22:01,800
this table

00:21:58,920 --> 00:22:03,420
so no inserts no updates and you cannot

00:22:01,800 --> 00:22:05,280
access any other table so you can really

00:22:03,420 --> 00:22:07,170
start locking it down and this is

00:22:05,280 --> 00:22:08,910
absolutely fundamental in the age of

00:22:07,170 --> 00:22:09,280
kind of containers and micro-services

00:22:08,910 --> 00:22:11,110
because

00:22:09,280 --> 00:22:13,750
you will have many services talking to

00:22:11,110 --> 00:22:16,300
shared resources cassandra cough comm

00:22:13,750 --> 00:22:18,580
readies memcache d all of them will be

00:22:16,300 --> 00:22:23,740
shared and you need security to actually

00:22:18,580 --> 00:22:26,290
lock this down properly getting going

00:22:23,740 --> 00:22:28,420
deeper right yeah we'll have services

00:22:26,290 --> 00:22:29,350
that talk to outside of your cluster

00:22:28,420 --> 00:22:30,820
it's not just service the service

00:22:29,350 --> 00:22:32,800
communication you might have a service

00:22:30,820 --> 00:22:36,250
that is talking let's say to Susie Susie

00:22:32,800 --> 00:22:37,930
de how do you secure this like Zeus ad

00:22:36,250 --> 00:22:40,060
may may only be backed by a couple of

00:22:37,930 --> 00:22:41,800
dozen IPS or something like this but as

00:22:40,060 --> 00:22:45,370
you start talking to something like AWS

00:22:41,800 --> 00:22:47,440
s3 or drive.google.com these services

00:22:45,370 --> 00:22:49,330
they're literally backed by thousands of

00:22:47,440 --> 00:22:51,970
IP addresses and there is no way you can

00:22:49,330 --> 00:22:53,470
you can whitelist that based on IPs it's

00:22:51,970 --> 00:22:55,060
not even bet you there's not even a

00:22:53,470 --> 00:22:57,390
known subnet that would represent that

00:22:55,060 --> 00:23:00,250
service so how do you how do you specify

00:22:57,390 --> 00:23:02,620
security that allows the service to talk

00:23:00,250 --> 00:23:04,510
to a3 or to drive that Google calm but

00:23:02,620 --> 00:23:08,110
not to anything else in this case we're

00:23:04,510 --> 00:23:10,180
using DNS server policy so a simple

00:23:08,110 --> 00:23:13,080
example there's a front-end service and

00:23:10,180 --> 00:23:18,010
it's doing an HTTP request to Susie de

00:23:13,080 --> 00:23:21,370
obviously it would do a DNS request so

00:23:18,010 --> 00:23:23,530
it would resolve Susie D and in this

00:23:21,370 --> 00:23:25,270
case the case of kubernetes the DNS

00:23:23,530 --> 00:23:28,870
server will return back and say hey this

00:23:25,270 --> 00:23:31,300
is the IP address of Susie dotty we've

00:23:28,870 --> 00:23:33,640
Solon we can define a policy that says

00:23:31,300 --> 00:23:35,770
hey you can talk but you can only talk

00:23:33,640 --> 00:23:40,030
to something that resolves to start

00:23:35,770 --> 00:23:42,550
Susie D and sullen with PPF will come in

00:23:40,030 --> 00:23:45,850
and look at the DNS communication and

00:23:42,550 --> 00:23:48,310
we'll record the IP that was returned by

00:23:45,850 --> 00:23:50,500
the DNS server and then only whitelist

00:23:48,310 --> 00:23:52,330
that particular IP so it's not kind of

00:23:50,500 --> 00:23:54,670
polling or trying to look up all the

00:23:52,330 --> 00:23:56,410
possible IPS off of the DNS name it's

00:23:54,670 --> 00:23:58,390
actually looking what the DNS server

00:23:56,410 --> 00:24:00,610
response and then only allowing that

00:23:58,390 --> 00:24:02,800
communication so that's another example

00:24:00,610 --> 00:24:05,860
of clownery for where or cloud every

00:24:02,800 --> 00:24:06,820
cloud native security that we need then

00:24:05,860 --> 00:24:10,750
we can do fancy stuff

00:24:06,820 --> 00:24:13,690
who knows about service mesh couple of

00:24:10,750 --> 00:24:16,180
ads grapes so service match very briefly

00:24:13,690 --> 00:24:18,850
concept that you're running a sidecar

00:24:16,180 --> 00:24:20,260
proxy in every in every community spot

00:24:18,850 --> 00:24:22,270
or in every part and all the

00:24:20,260 --> 00:24:23,020
communication between services is going

00:24:22,270 --> 00:24:24,280
through that side

00:24:23,020 --> 00:24:27,280
Cara proxy and it's basically getting

00:24:24,280 --> 00:24:30,040
proxy this allows to implement mutual

00:24:27,280 --> 00:24:32,800
TLS retries tracing

00:24:30,040 --> 00:24:35,020
lopa Lansing for example path based low

00:24:32,800 --> 00:24:37,720
plants and canna releases and so on the

00:24:35,020 --> 00:24:39,850
downside is that this introduces a lot

00:24:37,720 --> 00:24:41,650
of overhead because instead of having

00:24:39,850 --> 00:24:43,780
one connection between services you have

00:24:41,650 --> 00:24:46,240
a connection from service to proxy proxy

00:24:43,780 --> 00:24:48,790
to proxy and proxy to service right so

00:24:46,240 --> 00:24:51,250
from 1 to 3 so the memory consumption

00:24:48,790 --> 00:24:53,650
explodes the latency explodes and so on

00:24:51,250 --> 00:24:55,990
this site called proxies always running

00:24:53,650 --> 00:24:59,560
on the same node on the same machine as

00:24:55,990 --> 00:25:01,330
the service why do TCP write so TCP was

00:24:59,560 --> 00:25:04,240
done to survive a nuclear blast why

00:25:01,330 --> 00:25:07,030
would we want to do TCP there so what we

00:25:04,240 --> 00:25:09,520
do is we recognize this connection and

00:25:07,030 --> 00:25:11,140
we see that both sockets the socket of

00:25:09,520 --> 00:25:13,510
the application and socket of the proxy

00:25:11,140 --> 00:25:15,100
are on the same note and we simply start

00:25:13,510 --> 00:25:17,350
copying the data between the sockets and

00:25:15,100 --> 00:25:19,450
this gives us like as 3x performance

00:25:17,350 --> 00:25:24,490
agrees you can see it on the slice there

00:25:19,450 --> 00:25:26,260
I kids like it's fantastic all thanks to

00:25:24,490 --> 00:25:28,690
the power of PPF which gives us this

00:25:26,260 --> 00:25:31,030
flexibility and then kind of looking

00:25:28,690 --> 00:25:33,310
into into the future we can do something

00:25:31,030 --> 00:25:34,990
like transparent SSL visibility maybe

00:25:33,310 --> 00:25:38,500
some of you have heard about Katie Ellis

00:25:34,990 --> 00:25:40,300
kernel TLS it was done by some of the

00:25:38,500 --> 00:25:42,430
big providers of video streaming content

00:25:40,300 --> 00:25:44,140
when they started enabling TLS they

00:25:42,430 --> 00:25:47,380
really started to care about how

00:25:44,140 --> 00:25:49,330
expensive it is to to to basically

00:25:47,380 --> 00:25:51,460
produce that video or deliver that video

00:25:49,330 --> 00:25:53,530
with if SSL encryption and it turns out

00:25:51,460 --> 00:25:55,630
if we offload the SSL encryption from

00:25:53,530 --> 00:25:57,580
the application library into the Linux

00:25:55,630 --> 00:25:59,770
kernel gives us a three to four percent

00:25:57,580 --> 00:26:02,680
increase of performance so this is why

00:25:59,770 --> 00:26:04,780
Katie Ellis has been done all right we

00:26:02,680 --> 00:26:07,150
can use K TLS to basically even if the

00:26:04,780 --> 00:26:09,430
application is using SSL encryption to

00:26:07,150 --> 00:26:11,290
gain insights into the data that the

00:26:09,430 --> 00:26:13,840
application is sending and for example

00:26:11,290 --> 00:26:15,670
do did you do that layer seven or the

00:26:13,840 --> 00:26:19,150
HTTP aware filtering even if the

00:26:15,670 --> 00:26:21,100
application is using SSL if you want to

00:26:19,150 --> 00:26:23,200
learn more about this there's AQ Khan

00:26:21,100 --> 00:26:27,400
talk from last year that goes into all

00:26:23,200 --> 00:26:29,350
of the details of this so Solem use

00:26:27,400 --> 00:26:31,120
cases we kind of went through them this

00:26:29,350 --> 00:26:33,100
is a summary so southern provides

00:26:31,120 --> 00:26:35,290
container networking right it's highly

00:26:33,100 --> 00:26:36,340
efficient it's using the same the same

00:26:35,290 --> 00:26:38,320
techniques in the same

00:26:36,340 --> 00:26:40,390
as Facebook and Google and all the

00:26:38,320 --> 00:26:42,370
others are using internally you can use

00:26:40,390 --> 00:26:44,049
you can run in multiple modes you can

00:26:42,370 --> 00:26:46,240
run it in kind of routing mode you can

00:26:44,049 --> 00:26:48,940
do overlays you can do cloud provider

00:26:46,240 --> 00:26:50,980
native modes we support IP for ipv6 in

00:26:48,940 --> 00:26:53,080
fact we have been at v6 only for the

00:26:50,980 --> 00:26:54,760
first year we tried to cope like really

00:26:53,080 --> 00:26:56,740
native and say everything will be at

00:26:54,760 --> 00:26:59,020
least six at some point we can do multi

00:26:56,740 --> 00:27:01,120
cluster routing we can do service load

00:26:59,020 --> 00:27:03,730
balancing like really scalable we're not

00:27:01,120 --> 00:27:06,340
doing any l7 no path based routing but

00:27:03,730 --> 00:27:08,080
we're doing efficient lvl 4 implement

00:27:06,340 --> 00:27:11,860
cube another services replacing queue

00:27:08,080 --> 00:27:14,049
proxy we can do service affinity we can

00:27:11,860 --> 00:27:16,140
talk we can do cloud native security all

00:27:14,049 --> 00:27:19,390
the examples we provided identity based

00:27:16,140 --> 00:27:21,850
like layered layer 7 aware DNS aware and

00:27:19,390 --> 00:27:24,549
so on we could do encryption so we can

00:27:21,850 --> 00:27:25,899
encrypt everything on transparently and

00:27:24,549 --> 00:27:27,880
basically turn us all and we will

00:27:25,899 --> 00:27:29,740
encrypt everything inside of cluster and

00:27:27,880 --> 00:27:31,299
across clusters and we can do the

00:27:29,740 --> 00:27:35,200
service mesh acceleration and all of

00:27:31,299 --> 00:27:37,299
these are key components to run services

00:27:35,200 --> 00:27:39,880
or containers in a very efficient and

00:27:37,299 --> 00:27:42,460
secure way on Linux so all of this we do

00:27:39,880 --> 00:27:44,230
as part of the Linux kernel which means

00:27:42,460 --> 00:27:45,850
it's all completely transparent to the

00:27:44,230 --> 00:27:47,440
application because it's basically it

00:27:45,850 --> 00:27:51,850
looks like it's a property of the

00:27:47,440 --> 00:27:53,919
operating system so if this this all the

00:27:51,850 --> 00:27:55,480
slides I had I'm sure you guys have

00:27:53,919 --> 00:28:02,340
several questions I think we have some

00:27:55,480 --> 00:28:02,340
time for questions yeah

00:28:02,590 --> 00:28:07,420
[Applause]

00:28:08,890 --> 00:28:18,170
yes I will also repeat the question so

00:28:11,390 --> 00:28:20,570
feel free to shout the question is does

00:28:18,170 --> 00:28:22,340
it support mutual s-salam itself does

00:28:20,570 --> 00:28:24,860
not do mutuality last but you can run on

00:28:22,340 --> 00:28:27,020
voice do link IDI or anything on top so

00:28:24,860 --> 00:28:29,480
Liam does support encryption and

00:28:27,020 --> 00:28:31,400
authentication but we're not using TLS

00:28:29,480 --> 00:28:33,560
so you have a method that we can

00:28:31,400 --> 00:28:37,160
integrate with for example beef is beef

00:28:33,560 --> 00:28:39,500
is in a service that energy provider but

00:28:37,160 --> 00:28:40,670
we will use IPSec in the lens kernel to

00:28:39,500 --> 00:28:43,610
actually enforce it so you get the

00:28:40,670 --> 00:28:52,430
transparent education but it's not until

00:28:43,610 --> 00:28:53,660
us specifically any more questions all

00:28:52,430 --> 00:28:55,820
right thank you very much if you want to

00:28:53,660 --> 00:28:59,320
learn more here the links slack getup

00:28:55,820 --> 00:29:04,450
website Twitter and so on

00:28:59,320 --> 00:29:04,450

YouTube URL: https://www.youtube.com/watch?v=Bk8h4gZVIug


