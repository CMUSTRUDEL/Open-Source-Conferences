Title: LinuxTag2012: Wikidata: A Game Changer for Wikipedia and beyond
Publication date: 2012-05-25
Playlist: LinuxTag 2012
Description: 
	Lydia Pintscher (Wikimedia Deutschland/KDE)
Captions: 
	                              yes sir I'm very proud to announce ludia                               pincher Lydia is not only working with                               and for Vicki data and Vicki media but                               also with the car EE community but now                               she is talking about a project new                               project of Vicki of the wikimedia                               foundation and especially of the german                               chapter of wikimedia wikimedia                               Deutschland and she will tell you about                                Vicki data right thank you um so wicked                                data is a new project for Wikimedia and                                it's being developed in Jimmy here in                                Berlin and yeah I want to give you a                                short intro to the project and then                                maybe also demo um so                                okay um so division of wikimedia                                foundation and everything around it is                                to to get to a world where every single                                person is given free access to the sum                                of all human knowledge this is of course                                quite an ambitious goal quite an                                ambitious mission but we're working hard                                on it so you might know some of the                                projects of leukemia for example the                                most famous one is probably Wikipedia um                                but there's also wikiversity for example                                or me mediawiki and the software project                                and all the others so as I said the most                                famous ones probably Wikipedia um with                                more than                                                            than                                                                    big but there are problems when you look                                at wikipedia and compared to division we                                have the four biggest one wikipedias are                                the English German French and Dutch                                language traditions and they have more                                than                                                                    the Eddie other than language traditions                                and you see that                                                       than one hundred thousand articles each                                and if you want to know how many have                                more than                                                           language editions but there's still a                                huge gap to over                                                      are a lot of quick appears were less                                than                                                um a nice illustration maybe of this is                                here these are ordered light every for                                every article that has some kind of geo                                coordinates in the english-language                                wikipedia so you can pretty much see um                                the whole world nicely lined out and if                                you go to the french wikipedia it's                                getting a bit less but you can still see                                and of course francesa cetera um and                                then when you look at catalan if someone                                can explain this to me please do oh and                                then if you look at Italy there isn't                                really much about places outside of                                Italy and it's even worse the crease for                                example um so this is this is obviously                                a problem when we want to achieve access                                to all human knowledge for every person                                on this planet because language is still                                barrier and there there's another                                problem wikipedia knows a lot for                                example ugh knows all the cities and in                                those deer populations and it knows who                                the mayor of a big city is um so some                                people say okay um can I I sweetie                                Pierre who will see or for list of the                                largest cities with a female mayor um                                and friend of mine did and he got this                                um as you can see you get an answer what                                the problem is um doesnot all cities                                they are not the biggest ones and they                                don't have a few male mayor so this is                                kind of fail but wikipedia has an artist                                to that and it's called lists for                                example you have to list of countries by                                GDP you have a list of asteroids named                                after people you have a translation of                                this list of asteroids named after                                people in a different language position                                um and you have stuff like list of                                problems off by MacGyver but you don't                                have a list of the ten largest cities                                with a female mayor so Wikipedia doesn't                                have all the answers unfortunately um                                and this is why we working on wikidata                                here in Berlin to make Wikipedia smaller                                among other things what you see here is                                a very early mock-up of what we want to                                do the project is divided into three                                phases and the first phase is about                                language links language drinks are these                                links you have in the left-hand sidebar                                of each Wikipedia article that links to                                articles about the same subject in a                                 different language and what happens                                 right now is that each language has                                 information in the source of the article                                 saying okay and this is the Arctic about                                 the same subject in the French Wikipedia                                 and this is the one about the same                                 subject in the kiswahili wikipedia and                                 so on and each of these other languages                                 have the same thing so there's a lot of                                 redundancy in earnest and it's also kind                                 of a tedious work to keep them updated                                 as a huge wad framework that tries to                                 keep them and sink and stuff it's a bit                                 messy so what we want to do is take                                 these out of the source of the article                                 and put it into one central repository                                 so you have only one place where you                                 have to maintain them and then                                 update them all in one place and each                                 Wikipedia gets the list from the head                                 just once just to illustrate this this                                 is how this currently looks am in each                                 article and if you have a very or if you                                 have a subject that's covered in many                                 languages and this list gets really                                 really long um and this is how this                                 could look like in wiki data so you have                                 a list basically of these language links                                 and what the corresponding article in                                 that language edition is um this is what                                 we're working on right now and there is                                 a demo already which are very early demo                                 which you can check out later at                                 Wikimedia booth downstairs um the second                                 phase it's about infoboxes so this is                                 what's on the right-hand side of a lot                                 of articles in Wikipedia like you can                                 see here for Germany so does stuff like                                 who's to gentler who it's the best                                 president of the bonus hard GDP and all                                 of this um and just with like with the                                 language drinks I talked about earlier                                 these links or this this information is                                 repeated in each article and each                                 language edition in the article about                                 Germany so if someone finds out o our GP                                 changes then this has to be updated in                                 all the language editions this is of                                 course not really ideal so what we want                                 to do in the second phase is take this                                 data and make it possible to storage                                 centrally in wiki data and have the                                 articles pull that data from there and                                 so you have it in one place already to                                 updated and more place only to collect                                 it or more place and thereby also                                 helping the smaller wikipedias who don't                                 have the manpower to research all these                                 facts about                                 Germany they can just take advantage of                                 the larger language editions that can                                 then do a lot of the busy work that                                 needs to be done this by the way is how                                 one of these infoboxes looks like right                                 now in the source of the article which                                 isn't really pretty and this kind of                                 intimidating for someone who is new to                                 editing Wikipedia so we hope to improve                                 that was a nicer interface with forms                                 and stuff like that and the last phase                                 we will be working on early next year is                                 to enable inline queries which basically                                 means that we want to be able to get                                 generate these articles or dis lists                                 articles like the list of problems                                 McIver soft automatically based on data                                 that is collected in wiki data instead                                 of having to craft them by hand and                                 update them by hand for example right                                 now if United States elect a new                                 president the list of the article called                                 list of presidents of the United States                                 needs to be updated in each language                                 that has one of those articles and we                                 hope to once we get data is ready and                                 running that this will not be necessary                                 and once we have that we can also do                                 pretty realizations based on this data                                 of course which now is also done by hand                                 a lot and it's tedious work to update                                 for example across of unemployment rates                                 in different countries and stuff like                                 that so we hope that wiki data will                                 bring us closer to giving everyone                                 access to the sum of all human knowledge                                 um and um thank you for your attention                                 if you want a demo I'm happy to see you                                 at the Wikimedia booth downstairs and if                                 you have questions you can ask me now if                                 you want to learn even more about the                                 project or even                                 take part URL at the top matric Amelia                                 do lock / wiki / wiki data is to place                                 to be um and I post daily updates on                                 Twitter for example right any questions                                 yes dissing lying queries to have a                                 mock-up of it no not yet and when it is                                 as far as I know wiki data is going to                                 be running for about a year he's                                 rattling and then you will give it over                                 to the wikimedia from danger we're not                                 going to be this inline queries                                 available for at least for viewing                                 whatever it's it's a good hard to tell                                 but the plan is currently that or we                                 have one year we started in april so end                                 of march next year the project ends and                                 by then we need to have the development                                 basically done and we hope that the                                 second phase is finished by the end of                                 this year and then we start working on a                                 third phase um which should then be                                 ready by the end of March the question                                 that is really interesting though is                                 when will this be available on Wikipedia                                 of course now and I I can't tell it will                                 probably take a bit to deploy it of                                 course to get it to a stage where the                                 wikimedia foundation size over here yes                                 we run this on all our servers and so on                                 yeah but i hope next year right and once                                 again one other thing it was just                                 thinking of it said um in in this                                 project in this one year we were                                 focusing on wikipedia but it will be                                 possible to access the data of course                                 that we that will be collected from the                                 outside so if someone wants to write an                                 application that relies on on the stator                                 that's very possible and we are also                                 going to release or we are already                                 releasing the code so that people can                                 deploy their own wiki data instance and                                 collect data that they care about right                                 you had a second question                                 yes the team from wiki data are actually                                 the developers from Symantec mediawiki I                                 like you studies not help but yes I read                                 something about it are you planning to                                 fuse to consolidate both of it into on                                 one thing up early because at the end of                                 the day at least the third phase this in                                 line queries this is what semantic                                 mediawiki does and they do it quite well                                 I know they have a few problems with                                 some performance for very big week is                                 but other than that this is essentially                                 this is what semantic mediawiki does                                 exactly um so to answer your question um                                 this um is stuff from Symantec mediawiki                                 and we will try to rely on the code that                                 has been already developed for cemented                                 when you work you for these                                 visualizations because yes they are good                                 and they work and all of that when it                                 comes to Virginia projects no unlikely                                 we will share code and all of that and                                 we're working closely together as I said                                 there are people in both teams but the                                 goal of wiki data is very narrow and it                                 has to run on a scale as large as                                 Wikipedia the fifth largest website                                 there is on the internet so this is                                 really really difficult semantic                                 mediawiki could maybe be shoehorned into                                 something that works for that and but it                                 would lose a lot of its power and it                                 would lose a lot of what what it is able                                 to do now that we can run on server set                                 or run Wikipedia for example semantic                                 mediawiki can do really really powerful                                 queries that take a lot of computing                                 power and you just can't run that                                 wikipedia so um do the queries you will                                 be able to do will be more limited than                                 what semantic mediawiki obviously                                 because yeah you just can't do that on                                 that scale right more questions                                 um how we go about the population of                                 wikigta here so we'll use project like                                 GV pedia or something to see the data                                 usually right so the                                                   on an initial development here in Berlin                                 said we will not put data into Wikipedia                                 automatic Erika data automatically there                                 are several reasons for that the main                                 one is that we don't want a lot of data                                 without the community to maintain it the                                 goal is not to have the biggest data                                 repository that is completely outdated I                                 mean that would be kind of defeating the                                 point right so so we want to grow it                                 slowly pull the community run it and                                 make sure that it is um a healthy                                 project that being said I am pretty sure                                 that at some point the community will                                 decide okay let's import this whole                                 bunch of data from there because it's                                 already there and it's easy but that's                                 up to them then and yeah it will be                                 possible the the phase one of your                                 project is essentially do you want to                                 create this wiki data database where you                                 have a common repository where all the                                 info boxes from Wikipedia at some point                                 we'll get the data from however you are                                 already doing this for a long time for                                 example for scientific databases the                                 info boxes they know to to gene bank or                                 to DNA star and whatever all of them and                                 you get the data from them so at least                                 in my mind it doesn't make any sense at                                 all to change this this part of it                                 because the truth doesn't lie in wiki                                 data but in a completely different                                 database right outside so you would keep                                 this part I mean being able from an                                 infobox template to access yes doing                                 external completely external data is                                 okay right so everything that is                                 can right now and will also work in the                                 future oki data is a is an offer another                                 mandate so um if someone decides okay                                 for this specific article it doesn't                                 make sense at all to use data for with                                 you later then it's fine and in the                                 other thing though is that wiki data                                 would be a secondary database that means                                 we will store we will not be the main                                 place where stuff is stored but instead                                 we will say okay this source says that                                 took relation size                                                Germany is doesn't that we will store                                 this data in wiki date huh but we will                                 not be the main place where red is a                                 store maybe that makes more sense okay                                 more questions                                 so I'm wondering about the technology do                                 use some some predefined vocabulary to                                 for big data from the semantic web                                 ontology so are you making up your own                                 vocabulary for for things like like                                 major you would use the no free base                                 with capillaries which are already                                 zeroed right um so there is a data model                                 on meta camellia walk / which is very                                 good data that you can look at it's                                 pretty flexible and that's actually how                                 we want it right now if there's feedback                                 that this doesn't make sense then yeah                                 and I mean yes free beds and also                                 dbpedia I have done a lot of work that                                 is interesting in terms of how stuff is                                 structured on Wikipedia how how things                                 are connected and so on so yes this is                                 definitely something we are looking at                                 and working with more questions                                 no well thank you very much and if you                                 want a demo please come down to data to                                 wikimedia bull i will be there to answer                                 questions and they want thank you very                                 much
YouTube URL: https://www.youtube.com/watch?v=xb08DUnPuPE


