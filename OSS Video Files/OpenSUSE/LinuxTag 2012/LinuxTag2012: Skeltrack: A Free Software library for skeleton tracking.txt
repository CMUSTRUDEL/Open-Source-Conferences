Title: LinuxTag2012: Skeltrack: A Free Software library for skeleton tracking
Publication date: 2012-05-26
Playlist: LinuxTag 2012
Description: 
	Joaquim Rocha (Igalia)
Captions: 
	                              so the next talk here is from dragging                               watcher from Galia he's from protocol he                               will talk he has worked on some                               applications like the blue pad jivey                               Java to mobile application for PC remote                               controls                               he has parted the eye of chrome tool to                               Mamo he did an app for tracking TV shows                               on the Mamo foon five and SS master                                Tasers he wrote some tool called with                                the our feeder which converts printed                                documents into an open document format                                so and now he's talking about skeleton                                tracking framework this was made because                                the Xbox device the kinetics device from                                Microsoft was the first camera on the                                market which was cheap to get and                                provided you deaf informations but they                                were only closed frameworks for more                                complex work on with this informations                                like skeleton tracking and so on and so                                he developed a library called sky rack                                or a framework now he talks about this                                library warm welcome to drop him hey                                guys                                so I was already introduced                                I'm joking so I work at the Galia it's a                                company in Spain it's based in Spain but                                it's joining hackers around the world                                it's it's just a well it's a free                                software consultancy the company if you                                want to check it out anyway so just like                                you said I worked on OCR feeder and also                                a program called seriously not detract                                series because I like doing innovative                                stuff something that just you know                                tackles a need a problem like I think we                                all like to do last year I was here                                introducing OCR feeder                                I really like the feedback that I that I                                had from German folks and today I'm                                gonna present this skull track thing so                                first let's talk a bit about the Kinect                                so the Kinect was the first camera with                                a price affordable to the public the                                first depth camera that there is that                                people could afford because it's just                                over a hundred euros and almost every                                developer can afford that to heck so one                                thing is that one good thing is that                                Microsoft they said they said it was                                haulin all on purpose but the the the                                USB connection of of the Kinect is open                                so you can get the signal and you can do                                stuff using live live USB with it so I                                think I heard that in the beginning they                                didn't like really that people hack the                                Kinect but then they saw the tremendous                                success that it had and they said oh we                                left it just like that on purpose                                so I don't know which which sorry to                                believe but anyway so because of the                                connection being open it originated                                open-source projects like the delivery                                necked which allows you to control the                                Kinect using you know this independent                                library not from Microsoft and you can                                use it on Windows or Mac OS and on Linux                                so in agalya we do a lot of working in                                genome and we like the dilip library                                thank you                                so we developed a wrapper around                                lead-free nekked to be more friendly                                with the way that we do stuff in genome                                by the way who who knows jelly bore have                                used it here                                only one person - okay three well                                so we developed this wrapper and it                                offers some nice stuff light and the                                synchronous API which is cool because it                                won't block your UI when you're trying                                to connect with the Kinect so yeah we                                also have some synchronous functions                                because for example one of the functions                                one of the things that you can do with                                the Kinect is that it has a tilt it's                                called the tilt which is a little engine                                that makes it go up and down when you                                put it on top of your TV or whatever so                                we have an a synchronous function for                                that so you just say okay put me the                                tilt at zero degrees and if it's on                                   degrees which is the maximum it you you                                do not have to wait because it's a                                synchronous so it will do it something                                like and then you will have a callback                                when it finishes but sometimes you don't                                need you don't want to do that if you                                have a common line application for                                 example you just want to wait until it's                                 on zero so we offer some synchronous                                 functions as well one good reason to use                                 Ghalib is that it offers you the object                                 introspection so G object is like the                                 base for every object for every object                                 in the engine lip so it                                 Dileep kind of offers object orientation                                 on C and the G object introspection I                                 don't know if you know about it but it's                                 really interesting because before you                                 needed to do a binding for every library                                 that was written in in G lip right now                                 with the object introspection you just                                 need to do the bindings for the                                 languages you want but but you do the                                 bindings for a glue code that will load                                 other libraries by itself so in the case                                 of Python you got the PI G object and                                 that's that's the the piece that people                                 need to do the bindings by hand but once                                 that is done and it's done you can load                                 libraries dynamically on C                                 so this is like free bindings and you                                 can use it on Python on JavaScript and                                 on voila                                 well this kind of a c-sharp language for                                 now so some people think that the Kinect                                 is a stereoscopic camera stereoscopic                                 would be like like we humans do we have                                 two eyes and our brain just do the                                 calculations and says okay so I'm                                 looking at this microphone and it should                                 be around this distance because I'm used                                 to two things being this distance and I                                 can compare all inside my brain                                 so the Kinect this does not do this the                                 Kinect what it does is that you see the                                 the the circle on the left the farm was                                 left that's that emits a an IR pattern a                                 light pattern so the light then reaches                                 you or whoever is in front of the camera                                 in the rightmost circle it's a different                                 camera so that captures it and the                                 Kinect just sees the distortions in the                                 in the in the image and from that it can                                 calculate the depth the circle in the in                                 the in the middle is a regular RGB                                 camera so people usually think that two                                 of those cameras are the stereoscopic                                 thing but it's not like that                                 and this technique is called structured                                 light camera okay but anyway that                                 information that it does is just raw                                 values from                                                             so I'm telling you this because people                                 usually think that the Kinect already                                 gives you the skeleton thing my brother                                 used to attend computer science is now                                 moved to being a to be a male nurse but                                 he he told he what's my the video I did                                 for scale track and I asked him so do                                 you think it's cool and say oh it's                                 pretty cool what camera did you use I                                 said I use the Kinect and said so what                                 did you really do because they connect                                 away it does that the kinetic does not                                 do                                 what I'm gonna show you they can that                                 just gives you information about what's                                 closer or what's for further and the lip                                 reenact and of course the the rapper we                                 did the different net gives though and                                 give those values in millimeters so this                                 is what you usually capture using the                                 different act that that's me by the way                                 so it's kind of difficult to see because                                 it's in grayscale but what I did was to                                 put a threshold so it it didn't capture                                 the walls and the chairs and everything                                 that was in the office beside behind me                                 but it just captured like a threshold                                 and it's difficult to see but that upper                                 hand it's closer to the cameras like                                 this than this one so it should be it                                 should be darker but it I think you                                 cannot really perceive that from that                                 anyway this what you just saw does not                                 does not tell you that that there is a                                 person in the in the picture all right                                 it also does not tell you it's a cow or                                 even the mple man let alone a skeleton                                 and where the joints are because for                                 that you need another piece of software                                 on top of this which is called a                                 skeleton tracking solution so as always                                 you have proprietary stuff to do that so                                 let's do a bit of commercial work for                                 Microsoft and you got the the Microsoft                                 Kinect SDK which is for non-commercial                                 work only so that is if you want to                                 develop business using this this SDK you                                 cannot you can just do it for your                                 independent or student stuff because you                                 know if you if you want to do money you                                 want to create value with it Microsoft                                 wants a piece of that                                 then you got the the open knee or open                                 and I whatever so this one is more open                                 as in in the system they have parts of                                 the this is like a framework and they                                 have parts that are open and its                                 commercial compatible the problem is                                 that it's got some binary blobs that you                                 need to install and you need to accept a                                 EUL a license to use the skeleton                                 striking part so yeah not not enough for                                 me recently Microsoft released what they                                 call the Kinect for Windows which is a                                 commercial it allows commercial usage of                                 it but it's incompatible I don't know if                                 it's incompatible or in the technical                                 way or just in the legal way but it's                                 incompatible with the Xbox Kinect so                                 what it means is that you need to go to                                 Microsoft or to or to their providers                                 and buy a Kinect that is a little bit                                 more expensive than the regular one and                                 here's the share that you need to give                                 to Microsoft because you're gonna do                                 commercial work with it sorry and of                                 course Microsoft does not really care                                 about us who use Linux and other stuff                                 so it's only for Windows and that's                                 unacceptable so the conclusion is there                                 are no free or there were no free                                 solutions to perform skeleton tracking                                 so we decided to build one I think this                                 is the way that open-source works and                                 should work is that you see something                                 that you are not satisfied with and you                                 should try to put your your skills to                                 work into it                                 even though it's not really as easy as                                 sometimes it sounds so what we wanted                                 was a shared library by the way as I as                                 I said it's called scale Trek and we                                 wanted a shared library                                 no face SDK it's not even a framework                                 like it was introduced but no problem we                                 wanted it to be device independent so I                                 gave you all this lecture about the                                 Kinect for a reason which is if you are                                 going to hack on something with a depth                                 camera it's likely that you are going to                                 buy a Kinect unless you have more money                                 to spend on another but we wanted to                                 make it device independent not like the                                 other solutions I told you about which                                 expect you to connect the device to it                                 with we expect non device to be                                 connected so we also didn't want pattern                                 matching or databases because that's                                 another complexity to the whole thing                                 and of course we wanted it to be easy to                                 use because everybody wants that and                                 this of course is not really straight                                 forward so I was researching about it                                 and I found this paper by a German                                 researcher called Andres Bock and it's                                 got this very descriptive name so we                                 based our work on it not completely of                                 course because this paper uses a                                 database of poses so they they capture                                 we do more or less what they do that I'm                                 gonna explain but they once they know                                 where your points of interest are they                                 match it they match them with a database                                 and they say ok so this guy looks to be                                 like this or this guy looks a bit like                                 this                                 that's pretty good but I don't know how                                 it goes when when you need real-time so                                 so how this Scout rec really works first                                 we need to find the extremist the                                 extremist is like if you imagine a                                 starfish starfish is like this like this                                 right a starfish the extreme use of the                                 starfish is like this and this and this                                 so it's the it's the points you can say                                 that it's are the points far away                                 further away from from the                                 so to get the extremist we first need to                                 make a graph whose nodes are the depth                                 pixels so we take the depth buffer that                                 the lip reenact or in our library gave                                 you from a                                                               of it the way to make a graph that is of                                 it the way to make the graph is that the                                 nodes are the vertices should be                                 connected to each other if the if their                                 neighbors and I and I look for eight                                 neighbors if they are less than a given                                 value they are too far away like this                                 point is too far away from this point I                                 do not connect them but I connect this                                 point with this point with this point                                 and so it goes so another thing is that                                 the connect I don't know if you if you                                 tried it with a lip for neck but it it                                 produces a lot of noise so you I don't                                 know if you saw on YouTube or something                                 that you see the depth map and it's                                 always like flickering and that's                                 because of the of the light stuff that I                                 told you about and also there is another                                 thing to consider which is when you when                                 you for example you are like this you                                 have an arm here there is an area below                                 your arm that is completely black and by                                 black I mean that the Kinect doesn't                                 know what was there and that happens                                 because you're creating kind of a shadow                                 to this part because you know the light                                 comes from one place and the camera                                 captures it from a slightly different                                 place and it produces shadows so this                                 means that we sometimes end up with two                                 components of a graph and that's not                                 good                                 so we need to connect the components so                                 if I like this I have a component which                                 goes from my arm up and another                                 component that goes from my arm down and                                 the same happens when you are like this                                 you can have a component just for your                                 hand so you need to connect them so the                                 way to connect them that is from the                                 from the paper from back it's to get the                                 closest points                                 to the to the component that has the the                                 greatest number of of nodes so if the                                 greatest number of nodes is my torso and                                 I'm like this and this is a different                                 component I connect the closest points                                 of this component together with this                                 component so I just draw an edge from a                                 point here to here anyway                                 don't worry about the math so yeah so                                 then we need to choose a starting point                                 and to use the Dijkstra's algorithm                                 there's an algorithm as you might have                                 studied in computer science if that's                                 your background is is an algorithm to to                                 calculate the shortest but the shortest                                 path between two nodes in the graph so                                 we need to calculate this from a                                 starting point to every other nodes and                                 then we choose the farthest point and                                 that means that you get an extreme so                                 what it means is that if my starting                                 point is this one and I'm like this I                                 choose the the point that is further                                 away and it of course will find my leg                                 in this case or if you are seeing just                                 for my waistline up it might find my arm                                 is because it's the one that is far away                                 okay so once we find those extremist                                 what we need to do is to connect them                                 with the point where we started from and                                 we connect them with a zero cost edge                                 what it means is that well what it means                                 is that the next time you calculate                                 dicks                                 dextra from from the starting point you                                 will no longer get the same extrema                                 because you already have a path to that                                 extrema that cost zero so you'll be like                                 that in there so this means that you                                 will not have repeated extremis okay                                 once you once you have that you also                                 change the starting point you say that                                 the starting point is now the extrema                                 that you just found and this means that                                 if my starting point was this and the                                 first x                                                                  the second extrema will be this                                 because it's further away from both                                 points and you can do this n times to                                 find an extremist so the first differs                                 from what we did to to box paper is when                                 choosing the the starting-point box                                 paper but chooses a starting point that                                 is a centroid point the way to do this                                 you can do it in many ways but one way                                 of doing this is to get an arithmetic                                 average of all the points and you and                                 then you get you get your you get your                                 centroid well what it means is that if                                 you are like this you get a centroid                                 that is if you are calculating from the                                 whole body get a centroid that is that                                 should be like this but if you are like                                 this your centroid will go up so we                                 first wanted to focus on the upper body                                 so this means that if I am like this and                                 I get the starting point here and I                                 start calculating extremist it's okay                                 but if I do this my centroid point will                                 go up and this means that points below                                 will be farther away and that I will end                                 there I will have more trouble to find                                 the upper body part which is the one I'm                                 interested in so what we do is that we                                 calculate the centroid point and then we                                 choose the point that is lowest                                 vertically but horizontally aligned to                                 the starting point that is if I am like                                 this and I'm recording the whole of me I                                 get the central point the centroid point                                 and then I calculate the one that is                                 below until I don't have data so it                                 would be my feet if you are calculating                                 from my belly up it would be around here                                 and this is good because this assures                                 that you will always get the extremists                                 up in your upper body I don't know if                                 you are understanding anything but we                                 can talk later so so when you so you do                                 all this and you get the extremis so                                 what to do with them because okay you                                 know that there is a point in there that                                 might be ahead that might be a hand                                 that might be a shoulder you don't                                 really know so you need to interpret                                 them and the way we do this unlike Bach                                 who uses a database we use heuristics in                                 this case so these are just educated                                 guesses that work for most of the cases                                 we hope so anyway we're winding a bit we                                 calculation to get the extremist for                                 three extremist why three extremists                                 because we are focusing on the upper                                 body and the upper body has three                                 extremists ahead in the in both hands so                                 the next step to identify them is to is                                 to check each of them and to hope that                                 they are the head the way we do this is                                 that we go through a check extrema and                                 we look for the points where the                                 shoulders should be this means that if                                 the if the first extreme is this hand                                 and my hand is like this for example I                                 go here and I say okay so the shoulders                                 should be around here here and here and                                 you do not have data in there by the way                                 the the values of these two imaginary                                 shoulder points are go figure go so you                                 do this here it will fail you do this                                 here it will fill you do it to the head                                 and you get the shoulders of course that                                 sometimes if you are like this you might                                 get one shoulder here and one shoulder                                 here we are trying to settle that one so                                 if they obey these rules you get the                                 head and shoulders so about the                                 remaining two extremist you also need to                                 do some work because they might be hands                                 or they might be elbows why is that                                 because sometimes you are like this and                                 of course if you are calculating from                                 your starting point here it will not                                 give you the hand it will give you                                 something far away but we saw that for                                 example a usual case that when you are                                 like this and the furthest point are the                                 elbows so to calculate to see to see if                                 if they are hands or elbows we calculate                                 Dijkstra from the                                 the remaining extremist to the shoulder                                 points so in this first step for example                                 I calculate from here to here and I get                                 a distance and I also calculate from                                 here to here and to here this means that                                 I do this for both shoulders and not not                                 just the shoulder that is horizontally                                 aligned with the extrema because if you                                 are like this it will say that this is                                 my left hand when it's not and by doing                                 this trick to the shoulders you will                                 you'll get that fixed                                 so above the hand in a in the elbow that                                 I was explaining once you know that an                                 extreme way is the left one and the                                 right one what we do is that we check if                                 the distance to the shoulder is less                                 than a then the defined value which can                                 be changed as well according to your                                 needs so if it's less than the value for                                 example if or if it's further than than                                 a value like if it's further than this                                 for example I say okay so I got a point                                 here and it's it's greater than this                                 distance say it's not an elbow it's a                                 hand but if I am like this and I get the                                 extrema here it will be an elbow still                                 if you find a hand we still need the                                 elbow so what we do is that we use the                                 the path that we calculated before from                                 the extrema to the shoulder and we check                                 the the point that is close to that to                                 that elbow distance so it will always                                 give you a point that is really close to                                 the elbow this way and you got yourself                                 skeleton tracking with this so but there                                 are some some things missing so this                                 will be the future work of course if you                                 get the elbows I still do not find the                                 ends this way so I need to do something                                 for when you are like this I need to                                 check probably abusing Dijkstra's                                 algorithm again to check where the hand                                 is in the promise this is that I need to                                 check that it's this way and not this                                 way for example also smoothing so                                 because of the noise and all the things                                 you also you get a lot of chittering in                                 the in the in the extremist this also                                 happens we in openly and and also                                 Microsoft's SDK and all of that and they                                 have values to tweak this to just make                                 it a little better so I need to do this                                 that as well                                 robustness we need some restrictions                                 because we right now if you have a chair                                 next to you it might be considered part                                 of your body so we need to do something                                 to exclude some elements and multi user                                 because right now we track one person it                                 will be fairly simple to track more than                                 one person and of course get the rest of                                 the of the extremist of the joints sorry                                 the knees and the feet know that so how                                 to use this you get the synchronous API                                 that we did for this so you how many                                 people know see here okay                                 quite some okay so we just initialize                                 skeleton instance right and the first                                 line and then we call the the                                 synchronous method track joints we give                                 them the skeleton we give them the depth                                 buffer as you see there is no connect                                 involved here you have to give of course                                 the width and the height of the of the                                 buffer the first no argument it's a jika                                 sellable it's part of jelly of jalebis                                 api for synchronous functions so i have                                 an only there means that i do not have a                                 callable function that i will call to                                 castle to cancel this this processing                                 and of course I give them my callback                                 there is the on-track joint which will                                 be called was the the joints are tracked                                 the remaining argument is no because I                                 do not want to assign any errors in the                                 error variable so you define your call                                 back on track joints it has of course                                 some some predefined arguments then we                                 initialize                                 some joints and we and we just declare a                                 list and the way to get the list of                                 giants is by doing a skeleton track                                 joints finish and we will get you a list                                 that might be empty or not if you have a                                 person or not in the in front of the                                 Kinect and then if you if you want the                                 head for example you just need to do                                 this to the list list get joints and you                                 pass it the the head ID and the same for                                 other extremist so we also have a                                 synchronous API which with just this                                 call you can do skeleton tracking this                                 is good for offline processing there is                                 a Greek company that is the that is                                 using the synchronous API so a skeleton                                 joint currently has these many variables                                 it has an ID to identify if it's a head                                 left elbow right elbow it has an x and                                 y-coordinate in the real world in                                 millimeters and it has a crane X and                                 screen Y coordinates which is in pixels                                 because you might want your your values                                 in pixels to draw something on screen so                                 if you want to to submit patches or our                                 open issues you got the github in there                                 you also if you want to develop with it                                 you can get the different neck like I                                 said and I developed also something                                 called different neck details which is                                 cool for for developing so this is the                                 different necked Python example it's                                 written in Python in you can control the                                 Kinect using this it's part of different                                 neck this is one of the nifty tools that                                 is part of different neck details and                                 it's a record depth file                                 well actually but it's it's I I must                                 take it so this is the depth File Viewer                                 you just press them a depth file and you                                 can also give them coordinates to to be                                 put in there so this is cool because you                                 can use the skull track get the                                 coordinates and just check where they                                 are without                                 rendering it on real time and this is                                 the record file file a depth file this                                 is a colleague of mine the one that                                 developed different neck and you just                                 launch this and you see how it how you                                 look in there and you press space to                                 take a shot of you so it will record a                                 depth file that you can view with this                                 and that's it we got no more time so                                 questions thank you very much for this                                 interesting talk and this interesting                                 work undisclosed device so any questions                                 no questions at all is that possible                                 oh by the way I've got I've got two a                                 gallium marks for for the best question                                 so you might as well do one so your work                                 is related to a very simple body model                                 and for example if you won't want to                                 take a picture of your cat or your dog                                 this will not fit course not by skeleton                                 tracking I mean human skeleton tracking                                 so what happens if you have a tool like                                 a stick or something for for basic game                                 is it possible to grow distinguish the                                 stick from an elbow no no not really                                 because you know we're just aiming for                                 people to do the stuff that they usually                                 do with the Kinect or                                 and I'm not even talking about gaming                                 only you might for example have an                                 architecture firm you want to show                                 models                                                                  you can use a Kinect you skel track and                                 you just rotate them like this or                                 however you can oh I got I got some                                 videos to show you I don't know if there                                 is time or not but it's one minute yes                                 you control it okay okay so yeah almost                                 forgot                                 so let's see                                 how much time do we got                                 Oh for me that's more than enough so                                 this is the Kinect test that comes with                                 the library and as you see this is real                                 time I swear to you this is not                                 post-processing                                 I do not usually only wear this t-shirt                                 but it's just coincidence so as you see                                 my hands in there and the left the                                 circles kind of are bigger when you when                                 they are closer to the to the camera                                 what's going on                                 yeah so so you can see that the circles                                 are slightly smaller when they are far                                 away and bigger when they are closer                                 right so this is kind of interesting but                                 what people really liked and that's the                                 reason this one disappeared on Ars                                 Technica and pc world and so i stud and                                 whatever is this video how many people                                 saw this already                                 nobody alright so this is the gnome                                 desktop and I just did a small piece of                                 code on top of scale track to control X                                 slip I connect it to ignore three and                                 you get a desktop like Minority Report                                 and stuff this is also real time you can                                 see the connect here in the right and                                 this is just a regular TV that we have                                 in our office                                 no the the code the code uses actually                                 but just just because I had to use                                 something to feed genome with the events                                 so it's it's really simulating your                                 mouse right and UK when I do pinch                                 I just simulate my mouse wheel up                                 control mouse wheel up you can do                                 questions if you were actually if you                                 have a plan truck knives if the person                                 is looking at you are looking at the way                                 for you away from you                                 sorry if you have to skeleton after                                 information if the person is looking at                                 you at the camera if it's looking in a                                 way it's fun it's it's about the same if                                 I'm looking towards camera no because                                 because we do not track the face that's                                 actually one of the things I need to                                 consider like when I get the extremist                                 probably it's it's a good way of making                                 it more robust just to use OpenCV around                                 the extremist area and to do face                                 detection so of course a hand will not                                 will not be positive when you are                                 looking for a face in this way we could                                 be always certain that it's it's a face                                 when we're looking for it yeah so you                                 can also play games in Linux using this                                 cool are there any more questions okay                                 actually it's a real-time how small can                                 the hardware be to have the information                                 in real time actually a little arm box                                 with three                                                               keep talking about the mini-mall aspects                                 yeah I don't really know this is running                                 on my laptop this one so I really don't                                 know it's a matter of trying it out                                 anyway I did this of course because                                 there were no solutions but because we                                 have a small team Mini golly that is                                 trying to try to get into interactive                                 installations using free software so we                                 will try to run this on minimal hardware                                 it's not it's not gonna run and                                 no Arduino I assume but but yeah any                                 more questions                                 Duff I can tell you also that the                                 funniest case I received a lot of emails                                 because of this in the funniest case                                 that somebody asked me about was that                                 it's a researcher in Costa Rica I think                                 he said that he's tracking monkeys in a                                 zoo or a forest I don't know                                 so he tried to use open e and he didn't                                 work because they are slightly different                                 than us he tried to contact the open the                                 guys in no answer he tried to use                                 Microsoft he couldn't he tried to                                 contact Microsoft forget about it so                                 he's trying to use this to track monkey                                 see which is something I didn't imagine                                 okay so thank you for this interesting                                 tool tool and this interesting work and                                 the talk here applause please from yufka                                 the next
YouTube URL: https://www.youtube.com/watch?v=dk8EaNksAXA


