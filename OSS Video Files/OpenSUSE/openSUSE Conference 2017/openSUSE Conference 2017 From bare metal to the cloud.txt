Title: openSUSE Conference 2017 From bare metal to the cloud
Publication date: 2017-05-28
Playlist: openSUSE Conference 2017
Description: 
	https://media.ccc.de/v/1384-from-bare-metal-to-the-cloud

Bring your application to Kubernetes

Kubernetes is an open source project for orchestrating containerized applications.
But how to containerize your workload? How to bring your containerized application into Kubernetes?

This talk will show how we transferred our application to Kubernetes.
- This includes containerizing the application (based on an openSUSE docker image)
- How to expose your application services via Kubernetes.
- How to create a shared file system for all Pod belonging to your application via Kubernetes.

I will show how to do that plus a demo on a running Kubernetes System provided by SUSE CaaS



Stefan Haas
Captions: 
	00:00:00,000 --> 00:00:02,000
Oh

00:00:08,130 --> 00:00:13,260
welcome everybody so I will tell

00:00:10,890 --> 00:00:17,420
how to bring your application or your

00:00:13,260 --> 00:00:20,730
workload from bare metal to the cloud so

00:00:17,420 --> 00:00:22,740
I'm pretty lucky that at least a couple

00:00:20,730 --> 00:00:24,720
of people join so a couple of seconds

00:00:22,740 --> 00:00:29,160
only one guy was here so it was a bit

00:00:24,720 --> 00:00:31,470
afraid if nobody will come okay this

00:00:29,160 --> 00:00:33,690
will be a gender of my talk so I will do

00:00:31,470 --> 00:00:36,840
a short introduction on which in the end

00:00:33,690 --> 00:00:40,739
means Who am I what's my background of

00:00:36,840 --> 00:00:42,480
that topic I will give you really just a

00:00:40,739 --> 00:00:45,660
couple of words how to talk arise your

00:00:42,480 --> 00:00:47,520
application on how you bring how you can

00:00:45,660 --> 00:00:51,710
bring your darker image into the cloud

00:00:47,520 --> 00:00:56,250
which means in my case to kubernetes am

00:00:51,710 --> 00:00:59,160
at the end we will do a short demo yeah

00:00:56,250 --> 00:01:01,649
so you will see how to how to start

00:00:59,160 --> 00:01:03,210
generate all these files and how to

00:01:01,649 --> 00:01:06,090
bring that in a running company this

00:01:03,210 --> 00:01:09,390
cluster and there's always question

00:01:06,090 --> 00:01:11,880
answers Who am I

00:01:09,390 --> 00:01:14,430
so my name is Stefan Haase I'm senior

00:01:11,880 --> 00:01:18,600
software engineer at Unova cooperation

00:01:14,430 --> 00:01:21,210
this is a small American company so I'm

00:01:18,600 --> 00:01:23,369
a former Susy employee but this is now

00:01:21,210 --> 00:01:25,860
meanwhile nine years ago so I brought my

00:01:23,369 --> 00:01:28,649
diploma thesis and the yes team back

00:01:25,860 --> 00:01:30,329
then after that I started to work for

00:01:28,649 --> 00:01:34,740
sunlight Sun Microsystems

00:01:30,329 --> 00:01:37,490
later for Oracle Duty acquisition so and

00:01:34,740 --> 00:01:40,259
I was part of the development team for

00:01:37,490 --> 00:01:43,920
Grid Engine

00:01:40,259 --> 00:01:47,369
this is our also meanwhile the main

00:01:43,920 --> 00:01:48,869
product of my current company so and the

00:01:47,369 --> 00:01:51,079
integrated engine will be the test

00:01:48,869 --> 00:01:53,340
object for this talk so we will try to

00:01:51,079 --> 00:01:56,100
containerize grade engine and bring that

00:01:53,340 --> 00:02:00,390
into the kubernetes cloud my current

00:01:56,100 --> 00:02:02,130
main focus is nav UPS command this is a

00:02:00,390 --> 00:02:04,409
product though this is more or less a

00:02:02,130 --> 00:02:05,070
scheduler and policy management system

00:02:04,409 --> 00:02:07,920
for kubernetes

00:02:05,070 --> 00:02:10,830
so we are exchanging to stop stock

00:02:07,920 --> 00:02:14,910
schedule of kubernetes but that's

00:02:10,830 --> 00:02:16,620
another topic first of all just a small

00:02:14,910 --> 00:02:18,510
introduction what univer growth engine

00:02:16,620 --> 00:02:20,989
is so that you have a bit of an overview

00:02:18,510 --> 00:02:24,630
what we want to get into the cloud cloud

00:02:20,989 --> 00:02:27,300
so you GE so the approbation

00:02:24,630 --> 00:02:29,850
a batch queuing systems some of you

00:02:27,300 --> 00:02:32,070
might remember it as Sun Grid Engine or

00:02:29,850 --> 00:02:34,410
Oracle Grid Engine so it's all the same

00:02:32,070 --> 00:02:36,180
product so it's a batch queueing system

00:02:34,410 --> 00:02:38,940
or if you want the grid computing

00:02:36,180 --> 00:02:40,650
cluster software or somebody some folks

00:02:38,940 --> 00:02:44,220
call it distributed resource management

00:02:40,650 --> 00:02:47,520
system so whatever you want the main

00:02:44,220 --> 00:02:53,880
parts in this architectural overview are

00:02:47,520 --> 00:02:55,980
the Ute at the grid engine master the

00:02:53,880 --> 00:02:59,280
the master is responsible for all

00:02:55,980 --> 00:03:01,290
incoming requests by the user like you

00:02:59,280 --> 00:03:05,120
sub which means submitting a job into

00:03:01,290 --> 00:03:07,950
your batch system or if some

00:03:05,120 --> 00:03:10,620
administrator wants to configure it like

00:03:07,950 --> 00:03:13,440
you comp or stuff like that and also it

00:03:10,620 --> 00:03:15,980
everything goes to the to the master the

00:03:13,440 --> 00:03:18,860
master is also responsible for

00:03:15,980 --> 00:03:21,900
scheduling the chops and for the actual

00:03:18,860 --> 00:03:24,930
dispatching of the incoming jobs to the

00:03:21,900 --> 00:03:28,440
execution demons and the execution

00:03:24,930 --> 00:03:31,980
daemon is actually the second part we

00:03:28,440 --> 00:03:33,630
need to contain arise and the execution

00:03:31,980 --> 00:03:36,780
team is actually responsible for really

00:03:33,630 --> 00:03:39,780
executing your workload and for

00:03:36,780 --> 00:03:44,280
monitoring the job on your informal

00:03:39,780 --> 00:03:46,440
times on bare metal machine so see as

00:03:44,280 --> 00:03:49,530
again these are the two components we

00:03:46,440 --> 00:03:51,870
want to bring into the cloud so we will

00:03:49,530 --> 00:03:54,060
end up with just one image which which

00:03:51,870 --> 00:03:57,500
includes the master as also the

00:03:54,060 --> 00:04:00,690
execution demon and but you will see how

00:03:57,500 --> 00:04:02,940
how at boot up time of this container it

00:04:00,690 --> 00:04:07,110
will recognize what it has to start in

00:04:02,940 --> 00:04:09,510
one AD so first of all I want to start

00:04:07,110 --> 00:04:11,700
on how you can docker eyes your

00:04:09,510 --> 00:04:13,590
application or your workload so first of

00:04:11,700 --> 00:04:15,350
all we do not create containers we

00:04:13,590 --> 00:04:19,320
create images so what's the difference

00:04:15,350 --> 00:04:21,510
my image is let me cite a standalone an

00:04:19,320 --> 00:04:23,070
executable package which includes

00:04:21,510 --> 00:04:25,680
everything we need to run our

00:04:23,070 --> 00:04:27,930
application and the container on the

00:04:25,680 --> 00:04:31,020
other hand so this is the real runtime

00:04:27,930 --> 00:04:33,530
instance of that image so usually by

00:04:31,020 --> 00:04:36,150
default if you don't do anything fancy

00:04:33,530 --> 00:04:38,130
container is completely isolated from

00:04:36,150 --> 00:04:43,450
the host environment by

00:04:38,130 --> 00:04:47,560
if you want to create a docker container

00:04:43,450 --> 00:04:50,680
a docker image you have to to create a

00:04:47,560 --> 00:04:53,470
manifest or a recipe in the docker world

00:04:50,680 --> 00:04:56,230
you have to create a docker file so a

00:04:53,470 --> 00:05:00,340
docker file defines what goes inside

00:04:56,230 --> 00:05:02,770
your container so you can access the

00:05:00,340 --> 00:05:05,440
route you can set access to resources

00:05:02,770 --> 00:05:07,570
like network interfaces which are

00:05:05,440 --> 00:05:11,200
usually not available from outside of

00:05:07,570 --> 00:05:13,210
the container for example you map some

00:05:11,200 --> 00:05:15,370
chords port 80 if you want to have some

00:05:13,210 --> 00:05:18,280
some nginx instance or something like

00:05:15,370 --> 00:05:20,790
that you have also to specify what files

00:05:18,280 --> 00:05:24,220
you want to copy inside your container

00:05:20,790 --> 00:05:27,100
so first of all we need to copy our

00:05:24,220 --> 00:05:28,360
application inside of the container so

00:05:27,100 --> 00:05:32,080
let's have a look at a real world

00:05:28,360 --> 00:05:35,130
example so if you're talking about grid

00:05:32,080 --> 00:05:35,130
engine we want to see that

00:05:57,409 --> 00:06:05,669
so in the first line it's a you you say

00:06:02,909 --> 00:06:08,610
what image you will base on so as this

00:06:05,669 --> 00:06:10,319
is openSUSE conference and this is a

00:06:08,610 --> 00:06:13,800
real-world example so we are running

00:06:10,319 --> 00:06:16,620
that at customers our grid engine image

00:06:13,800 --> 00:06:18,090
on openSUSE just as a bit of a

00:06:16,620 --> 00:06:20,340
background we choose that first of all

00:06:18,090 --> 00:06:23,939
because i'm openSUSE member and second

00:06:20,340 --> 00:06:26,909
of that the openSUSE image is way

00:06:23,939 --> 00:06:29,189
smaller than most of the competitors so

00:06:26,909 --> 00:06:31,439
the base open through the image which

00:06:29,189 --> 00:06:34,289
just includes 42 we are using 42 third

00:06:31,439 --> 00:06:36,330
one is about 100 mac if you compare it

00:06:34,289 --> 00:06:42,210
with arm centers or something like that

00:06:36,330 --> 00:06:44,189
you're at 150 or even 200 max so you

00:06:42,210 --> 00:06:46,680
have to say the maintainer this is in

00:06:44,189 --> 00:06:50,069
this case I am so we are running

00:06:46,680 --> 00:06:54,240
commands so for running grid engine in

00:06:50,069 --> 00:06:56,580
that in that container and for later on

00:06:54,240 --> 00:06:59,339
running workload in that container which

00:06:56,580 --> 00:07:01,770
means workload in in the meaning of

00:06:59,339 --> 00:07:04,440
workload with which runs as grid engine

00:07:01,770 --> 00:07:08,069
jobs I'm installing a couple of

00:07:04,440 --> 00:07:11,639
additional packages in this case we're

00:07:08,069 --> 00:07:13,860
installing SSD we eye which is needed

00:07:11,639 --> 00:07:18,240
for the configuration of of grid engine

00:07:13,860 --> 00:07:21,529
and we also need Java because our REST

00:07:18,240 --> 00:07:24,599
API in grid engine is written in Java

00:07:21,529 --> 00:07:28,080
after that we clean all the temporary

00:07:24,599 --> 00:07:32,039
files from zipper we define a working

00:07:28,080 --> 00:07:34,469
directory so this means on the working

00:07:32,039 --> 00:07:37,250
the current working directory which you

00:07:34,469 --> 00:07:41,339
get when you start up your container um

00:07:37,250 --> 00:07:43,949
I copy a bunch of files into that

00:07:41,339 --> 00:07:45,719
working directory so in this this is the

00:07:43,949 --> 00:07:47,699
scheduler configuration for grid engine

00:07:45,719 --> 00:07:50,699
these are details which are not that

00:07:47,699 --> 00:07:54,120
important we are copying this one is

00:07:50,699 --> 00:07:57,210
important wrapper script and renaming it

00:07:54,120 --> 00:08:00,439
to uge this will be later on our so

00:07:57,210 --> 00:08:05,399
called entry point the entry point is

00:08:00,439 --> 00:08:07,289
this process or script which gets

00:08:05,399 --> 00:08:10,050
executed when you start

00:08:07,289 --> 00:08:12,389
you're docker container and without any

00:08:10,050 --> 00:08:15,869
additional command so if you do a docker

00:08:12,389 --> 00:08:17,520
run image name it will start on these

00:08:15,869 --> 00:08:20,249
entries what you use state your res

00:08:17,520 --> 00:08:23,339
entry point as soon as this entry point

00:08:20,249 --> 00:08:25,800
script our application process stops

00:08:23,339 --> 00:08:31,430
your container will automatically also

00:08:25,800 --> 00:08:34,139
stop you can also as you have seen here

00:08:31,430 --> 00:08:36,360
reciprocal of I do here also a couple of

00:08:34,139 --> 00:08:38,940
run command so I'm installing here for

00:08:36,360 --> 00:08:41,159
example an additional rpm which is not

00:08:38,940 --> 00:08:44,579
available by default in any of the

00:08:41,159 --> 00:08:46,560
repositories and here this is also this

00:08:44,579 --> 00:08:49,050
is another interesting thing I have to

00:08:46,560 --> 00:08:51,810
expose a couple of ports so as set

00:08:49,050 --> 00:08:53,160
usually no port of a container is

00:08:51,810 --> 00:08:56,850
available from the outside of the

00:08:53,160 --> 00:09:00,209
container so I have to expose the ports

00:08:56,850 --> 00:09:02,790
for my cue master process said my

00:09:00,209 --> 00:09:05,910
execution demons can communicate with

00:09:02,790 --> 00:09:07,290
the cue master I have to exposed on this

00:09:05,910 --> 00:09:09,870
port which is responsible for the

00:09:07,290 --> 00:09:12,779
execution daemon and the last one is the

00:09:09,870 --> 00:09:20,100
responsible port for my ute rest

00:09:12,779 --> 00:09:22,430
interface okay let's go back to the

00:09:20,100 --> 00:09:22,430
slides

00:09:27,240 --> 00:09:37,750
start from so if you want to generate

00:09:35,259 --> 00:09:40,660
and test your image you simply have to

00:09:37,750 --> 00:09:44,079
do a darker build - tea - tea means on

00:09:40,660 --> 00:09:46,269
you you give it a tag and the name and

00:09:44,079 --> 00:09:50,500
you have to say where where docker will

00:09:46,269 --> 00:09:52,089
find your your dakka dakka file after

00:09:50,500 --> 00:09:55,240
that you simply can execute a docker

00:09:52,089 --> 00:09:58,959
images and you hopefully will find your

00:09:55,240 --> 00:10:01,569
application something like that with the

00:09:58,959 --> 00:10:04,630
tag if you do not add attack it will

00:10:01,569 --> 00:10:07,389
automatically do a call it latest with a

00:10:04,630 --> 00:10:10,089
certain image ID so I will not show you

00:10:07,389 --> 00:10:11,800
how to build the docker image because at

00:10:10,089 --> 00:10:13,420
least in the case of great engine it

00:10:11,800 --> 00:10:16,199
takes about 10 minutes to build all that

00:10:13,420 --> 00:10:18,490
stuff it has to grep to complete arm

00:10:16,199 --> 00:10:20,079
openSUSE image which is about hundred

00:10:18,490 --> 00:10:23,500
mega install all this additional

00:10:20,079 --> 00:10:26,079
software and after that you can locally

00:10:23,500 --> 00:10:30,399
execute your container by a docker run

00:10:26,079 --> 00:10:33,250
your app and again this will just start

00:10:30,399 --> 00:10:38,230
inside of your container the application

00:10:33,250 --> 00:10:41,560
you you configure it as entry point so

00:10:38,230 --> 00:10:43,600
but if you now we have a docker image

00:10:41,560 --> 00:10:47,649
that's okay but we want to have a

00:10:43,600 --> 00:10:50,500
cluster of grid engine nodes and you do

00:10:47,649 --> 00:10:52,329
not want to to go to every of your nodes

00:10:50,500 --> 00:10:55,779
and install the docker image and

00:10:52,329 --> 00:10:59,260
starting boot it up by hand or manually

00:10:55,779 --> 00:11:01,959
if you would do it like that there is no

00:10:59,260 --> 00:11:04,690
meaning in doing it in a docker image so

00:11:01,959 --> 00:11:07,420
for that we are using kubernetes so

00:11:04,690 --> 00:11:10,750
what's happening is this is an open

00:11:07,420 --> 00:11:13,870
source system held by the CN CF the

00:11:10,750 --> 00:11:16,420
cloud native Foundation console or

00:11:13,870 --> 00:11:21,310
something like that originally invented

00:11:16,420 --> 00:11:24,069
by Google it's a tool for automating

00:11:21,310 --> 00:11:25,600
deployment and management of

00:11:24,069 --> 00:11:29,649
containerized applications

00:11:25,600 --> 00:11:31,810
so not only darker but I think um so at

00:11:29,649 --> 00:11:35,050
least what I the customers we have I

00:11:31,810 --> 00:11:36,970
think at least 95% are running docker

00:11:35,050 --> 00:11:39,010
images when using coburn it is and

00:11:36,970 --> 00:11:40,270
nothing else

00:11:39,010 --> 00:11:43,870
kubernetes follow

00:11:40,270 --> 00:11:46,630
similar to grid engine the master/slave

00:11:43,870 --> 00:11:50,230
architecture so the components can be

00:11:46,630 --> 00:11:53,320
easily divided into those who manage the

00:11:50,230 --> 00:11:55,570
individual notes here the most important

00:11:53,320 --> 00:11:57,760
part is the so-called couplet which is

00:11:55,570 --> 00:12:00,160
responsible for starting the pots so

00:11:57,760 --> 00:12:02,740
part I will talk till the later what is

00:12:00,160 --> 00:12:05,230
this but to be easy this is the

00:12:02,740 --> 00:12:09,520
container itself and we have the

00:12:05,230 --> 00:12:13,290
kubernetes master which includes the

00:12:09,520 --> 00:12:17,500
stock scheduler and for example the HDD

00:12:13,290 --> 00:12:22,120
instance which is a key pair our key key

00:12:17,500 --> 00:12:24,459
value pair instant server instance for

00:12:22,120 --> 00:12:29,890
do it for storing all the configuration

00:12:24,459 --> 00:12:33,790
of kubernetes so to do a short overview

00:12:29,890 --> 00:12:36,250
of the namings in kubernetes so that you

00:12:33,790 --> 00:12:39,370
know what i'm talking all about the

00:12:36,250 --> 00:12:42,970
reverse thing which I just said a couple

00:12:39,370 --> 00:12:46,510
of seconds ago is a part this is the

00:12:42,970 --> 00:12:48,910
basic block of kubernetes so it's more

00:12:46,510 --> 00:12:53,020
or less the process in on your

00:12:48,910 --> 00:12:57,490
kubernetes host ya node apart

00:12:53,020 --> 00:12:59,440
encapsulate a container or more you can

00:12:57,490 --> 00:13:02,320
have running as many containers if you

00:12:59,440 --> 00:13:07,060
are as you want in a container in a pod

00:13:02,320 --> 00:13:09,100
as also resources like storage so we

00:13:07,060 --> 00:13:11,079
will see that in our example I'm in

00:13:09,100 --> 00:13:15,160
great engine we need additional storage

00:13:11,079 --> 00:13:17,500
for for our demons and you can also

00:13:15,160 --> 00:13:20,950
encapsulate resources like network

00:13:17,500 --> 00:13:22,810
interfaces and stuff like that the next

00:13:20,950 --> 00:13:26,440
thing I want to shortly talk about is

00:13:22,810 --> 00:13:31,029
controller so controller in kubernetes

00:13:26,440 --> 00:13:33,520
is easy said concept or a manifest how

00:13:31,029 --> 00:13:38,350
you want to deploy your pots in a

00:13:33,520 --> 00:13:39,880
cluster for example which I choose for

00:13:38,350 --> 00:13:41,500
the execution even a replication

00:13:39,880 --> 00:13:43,839
controller and the replication

00:13:41,500 --> 00:13:47,380
controller is responsible so you say I

00:13:43,839 --> 00:13:49,240
have this execution demon you have have

00:13:47,380 --> 00:13:54,040
a template of a part this execution

00:13:49,240 --> 00:13:54,529
demon wants to have a storage he wants

00:13:54,040 --> 00:13:57,050
that the

00:13:54,529 --> 00:13:59,420
detect this container wants to have the

00:13:57,050 --> 00:14:01,730
storage mounted to this and that pass

00:13:59,420 --> 00:14:04,220
and the controller is responsible for

00:14:01,730 --> 00:14:06,350
how many of them you want to have for

00:14:04,220 --> 00:14:09,009
example five replicas and the controller

00:14:06,350 --> 00:14:12,050
is responsible that you always have

00:14:09,009 --> 00:14:13,850
these five controllers running in the

00:14:12,050 --> 00:14:15,920
system so in case of a replication

00:14:13,850 --> 00:14:18,290
controller so if one of the containers

00:14:15,920 --> 00:14:21,350
departs dies a replication controller

00:14:18,290 --> 00:14:23,569
will automatically start up a new one if

00:14:21,350 --> 00:14:26,120
you downscale a replication controller

00:14:23,569 --> 00:14:27,980
you do not want to have five anymore you

00:14:26,120 --> 00:14:32,120
you're okay with three it will

00:14:27,980 --> 00:14:34,100
automatically kill two of them the last

00:14:32,120 --> 00:14:39,709
thing i wanna i want to shortly

00:14:34,100 --> 00:14:42,350
introduce the service pots in the

00:14:39,709 --> 00:14:45,230
kubernetes world they call it they are

00:14:42,350 --> 00:14:48,079
ephemeral or mortal this means they are

00:14:45,230 --> 00:14:51,529
born and when they died they do not get

00:14:48,079 --> 00:14:53,839
resurrected or stuff like that so while

00:14:51,529 --> 00:14:56,480
each pot gets it old gets its own IP

00:14:53,839 --> 00:14:59,029
address even those RP addresses cannot

00:14:56,480 --> 00:15:02,449
be you cannot rely on those IP addresses

00:14:59,029 --> 00:15:05,240
to be stable over time so kubernetes

00:15:02,449 --> 00:15:07,519
servers is small as an abstraction which

00:15:05,240 --> 00:15:12,379
defines a logical set of pots you can

00:15:07,519 --> 00:15:16,309
have Mel pots in SS service and the

00:15:12,379 --> 00:15:20,329
policy by which to access these arm

00:15:16,309 --> 00:15:23,180
these pots so let's sink on a multi-tier

00:15:20,329 --> 00:15:27,139
application so you have a web server

00:15:23,180 --> 00:15:30,170
database and you do not want to access a

00:15:27,139 --> 00:15:32,480
real instance a real part on your

00:15:30,170 --> 00:15:36,920
kubernetes cluster so you want to access

00:15:32,480 --> 00:15:38,689
the service for all that stuff so when

00:15:36,920 --> 00:15:40,550
it comes to bringing your docker image

00:15:38,689 --> 00:15:42,620
to kubernetes first of all we have to

00:15:40,550 --> 00:15:44,990
decide what controller fits best for

00:15:42,620 --> 00:15:45,649
your application so here's another

00:15:44,990 --> 00:15:48,199
example

00:15:45,649 --> 00:15:49,970
I'm a demon set so with the demons that

00:15:48,199 --> 00:15:52,749
you can ensure that every node in the

00:15:49,970 --> 00:15:56,839
cluster runs an instance of your pot and

00:15:52,749 --> 00:15:59,209
and we you have to prepare storage for

00:15:56,839 --> 00:16:02,689
your application so we need to do that

00:15:59,209 --> 00:16:06,589
so a storage in communities can be NFS

00:16:02,689 --> 00:16:08,150
ffs Amazon EBS and can be an azure drive

00:16:06,589 --> 00:16:10,730
or something in the Google cloud

00:16:08,150 --> 00:16:13,190
wherever you want and it also can be a

00:16:10,730 --> 00:16:15,920
so-called host pass which simply means a

00:16:13,190 --> 00:16:19,760
local pass or local directory on your

00:16:15,920 --> 00:16:24,320
node which is only for reasonable for

00:16:19,760 --> 00:16:26,030
for demoing purposes so again real world

00:16:24,320 --> 00:16:27,490
example first of all I want to show you

00:16:26,030 --> 00:16:29,810
my demo environment

00:16:27,490 --> 00:16:31,730
unfortunately the demo gods haven't been

00:16:29,810 --> 00:16:34,760
with me so I destroyed yesterday and

00:16:31,730 --> 00:16:39,290
even in my cache installation so I have

00:16:34,760 --> 00:16:42,110
to fall back to mini cube mini cube is a

00:16:39,290 --> 00:16:45,020
virtual machine which runs kubernetes

00:16:42,110 --> 00:16:47,540
inside so that's also the reason why I'm

00:16:45,020 --> 00:16:49,160
now relying on a local gear a host pass

00:16:47,540 --> 00:16:52,460
usually I'm showing that stuff design

00:16:49,160 --> 00:16:55,040
and NFS server running as a pod ok

00:16:52,460 --> 00:16:57,920
nevertheless first of all we have to

00:16:55,040 --> 00:17:00,140
create a PV so persistent volume this is

00:16:57,920 --> 00:17:03,110
a storage provision by the administrator

00:17:00,140 --> 00:17:06,200
again this can be NFS whatever you want

00:17:03,110 --> 00:17:09,440
and the administrator has to say ok I

00:17:06,200 --> 00:17:12,980
have here an NFS share this is mounted

00:17:09,440 --> 00:17:15,500
on this server you can you can have

00:17:12,980 --> 00:17:20,480
access to the Y at this NFS server and

00:17:15,500 --> 00:17:23,570
there are 30 gigs of memory we need a

00:17:20,480 --> 00:17:27,440
PVC this is the persistent volume claim

00:17:23,570 --> 00:17:30,230
this is a the request for storage by a

00:17:27,440 --> 00:17:33,470
user so a user usually does not care

00:17:30,230 --> 00:17:36,110
where his storage is so a user does not

00:17:33,470 --> 00:17:38,510
want to know if this is on Amazon if

00:17:36,110 --> 00:17:40,610
this is on Microsoft Microsoft Azure if

00:17:38,510 --> 00:17:41,990
this is somewhere in the Google Cloud it

00:17:40,610 --> 00:17:45,440
doesn't care the only thing he wants to

00:17:41,990 --> 00:17:51,020
he says ok I need here five gigs stuff

00:17:45,440 --> 00:17:54,920
like that for the Ute execution daemon I

00:17:51,020 --> 00:17:57,410
choose a replication controller arm just

00:17:54,920 --> 00:17:59,570
for demo purposes usually you would say

00:17:57,410 --> 00:18:02,090
for execution even you would choose a

00:17:59,570 --> 00:18:03,650
daemon set which means that you have one

00:18:02,090 --> 00:18:06,140
execution daemon per node in your

00:18:03,650 --> 00:18:09,700
company this cluster but in a mini cube

00:18:06,140 --> 00:18:09,700
environment this doesn't make many cents

00:18:10,600 --> 00:18:18,560
for the ugq master I choose a stateful

00:18:15,470 --> 00:18:20,060
set a stateful set is pretty similar to

00:18:18,560 --> 00:18:21,490
a replication controller with the

00:18:20,060 --> 00:18:23,920
difference

00:18:21,490 --> 00:18:27,970
a stateful set provides a unique

00:18:23,920 --> 00:18:30,250
identity to your pot this means the

00:18:27,970 --> 00:18:30,700
first one will get called ugq master -

00:18:30,250 --> 00:18:33,130
OH

00:18:30,700 --> 00:18:35,620
the second one - one - two and so on and

00:18:33,130 --> 00:18:38,170
so on instead of if you do a replication

00:18:35,620 --> 00:18:45,540
control of you good ug execution daemon

00:18:38,170 --> 00:18:48,760
- some arbitrary numbers and and letters

00:18:45,540 --> 00:18:51,100
another good thing about the stateful

00:18:48,760 --> 00:18:54,670
set is that it provides a guarantee

00:18:51,100 --> 00:18:58,210
about the ordering of scaling and

00:18:54,670 --> 00:19:00,130
deleting so as said you you can counter

00:18:58,210 --> 00:19:04,480
the numbers and if you down scale or

00:19:00,130 --> 00:19:06,580
your stateful set you can you you can

00:19:04,480 --> 00:19:09,550
get sure that the last one will get

00:19:06,580 --> 00:19:11,760
killed first you cannot get your natural

00:19:09,550 --> 00:19:15,309
in case of a replication control and

00:19:11,760 --> 00:19:18,040
last but not least we need a service so

00:19:15,309 --> 00:19:21,250
in this case we need a headless service

00:19:18,040 --> 00:19:25,270
as we have only one cue master running

00:19:21,250 --> 00:19:27,670
and this headless service is tied to

00:19:25,270 --> 00:19:33,300
this stateful set which means we get an

00:19:27,670 --> 00:19:36,100
DNS entry directly for this ugq master

00:19:33,300 --> 00:19:37,960
part so we have we can connect from the

00:19:36,100 --> 00:19:41,050
outside to our univariate engine cluster

00:19:37,960 --> 00:19:42,850
so we can do IQ SAP or Q comes even from

00:19:41,050 --> 00:19:49,410
outside of a cube of kubernetes if you

00:19:42,850 --> 00:19:52,410
want ok let's go back to the examples

00:19:49,410 --> 00:19:52,410
and

00:20:25,210 --> 00:20:34,000
oh let's start with the persistent

00:20:31,300 --> 00:20:36,670
volume again this is what you as

00:20:34,000 --> 00:20:39,460
administrator has to create so you have

00:20:36,670 --> 00:20:43,000
to to to create or prepare some storage

00:20:39,460 --> 00:20:45,790
that on the your parts or controllers or

00:20:43,000 --> 00:20:48,400
whatever can rely on so this is pretty

00:20:45,790 --> 00:20:51,190
pretty simple example you can get that

00:20:48,400 --> 00:20:55,120
as sophisticated as you want so first of

00:20:51,190 --> 00:20:57,090
all I say out so let's you can you can

00:20:55,120 --> 00:21:01,540
do your configuration in kubernetes

00:20:57,090 --> 00:21:03,490
either via JSON files or llamó so in my

00:21:01,540 --> 00:21:06,430
opinion IMO file is more easy to read so

00:21:03,490 --> 00:21:08,980
I choose that for the demonstration so

00:21:06,430 --> 00:21:11,860
the first line says okay this is all

00:21:08,980 --> 00:21:14,170
about a persistent volume in communities

00:21:11,860 --> 00:21:16,270
yours you always have to say which API

00:21:14,170 --> 00:21:22,390
version this persistent volume belongs

00:21:16,270 --> 00:21:22,600
to you you have to give it a name for

00:21:22,390 --> 00:21:24,910
sure

00:21:22,600 --> 00:21:28,060
and in kubernetes you can add labels

00:21:24,910 --> 00:21:30,820
these are just simple key value pairs

00:21:28,060 --> 00:21:33,880
where you can do sort and ordering later

00:21:30,820 --> 00:21:35,800
on so the there is nothing special about

00:21:33,880 --> 00:21:40,630
that in kubernetes itself it's just for

00:21:35,800 --> 00:21:44,410
monitoring and stuff like that so I I

00:21:40,630 --> 00:21:46,630
said okay this is the type of local you

00:21:44,410 --> 00:21:49,210
have to specify what what kind of

00:21:46,630 --> 00:21:53,920
persistent volume this is so I give it a

00:21:49,210 --> 00:21:56,530
capacity of 10 gig of memory you have to

00:21:53,920 --> 00:21:58,390
to specify the access mode this in this

00:21:56,530 --> 00:22:02,830
case I said read/write many this means

00:21:58,390 --> 00:22:04,660
that on many notes you from many nodes

00:22:02,830 --> 00:22:06,160
many different notes you can read and

00:22:04,660 --> 00:22:09,550
write at the same time to disarm

00:22:06,160 --> 00:22:11,590
persistent volume and I have to say what

00:22:09,550 --> 00:22:14,860
kind of persistent volume this is so in

00:22:11,590 --> 00:22:17,650
this case it's a host pass which means

00:22:14,860 --> 00:22:20,500
it's a local directory on the node the

00:22:17,650 --> 00:22:22,540
persistent volume gets created on so if

00:22:20,500 --> 00:22:26,350
you would have an NFS server if you

00:22:22,540 --> 00:22:28,330
would have to say here NFS here you have

00:22:26,350 --> 00:22:31,110
would have something like a server entry

00:22:28,330 --> 00:22:31,110
and stuff like that

00:22:39,940 --> 00:22:44,820
[Music]

00:22:41,540 --> 00:22:47,400
this is the persistent volume claim that

00:22:44,820 --> 00:22:50,700
this is the thing the user will create

00:22:47,400 --> 00:22:53,750
the user will rely on so again I said

00:22:50,700 --> 00:22:56,640
it's a persistent volume claim the kind

00:22:53,750 --> 00:22:59,670
the name is uge claim I have the same

00:22:56,640 --> 00:23:03,120
access mode and I want to get three I so

00:22:59,670 --> 00:23:05,700
I need for my my workload my application

00:23:03,120 --> 00:23:14,100
my pot I need to have three gig of

00:23:05,700 --> 00:23:16,080
available so this is my request this

00:23:14,100 --> 00:23:33,120
would be all about the storage so let's

00:23:16,080 --> 00:23:35,370
dive into the controllers this is the

00:23:33,120 --> 00:23:38,370
replication controller responsible for

00:23:35,370 --> 00:23:39,870
the execution daemon and again you have

00:23:38,370 --> 00:23:42,950
to give it a name you have to say what

00:23:39,870 --> 00:23:44,970
it is at all this is dispatch the

00:23:42,950 --> 00:23:47,070
specification for the replication

00:23:44,970 --> 00:23:48,990
controller so when creating that

00:23:47,070 --> 00:23:52,260
replication controller it will boot up

00:23:48,990 --> 00:23:54,360
no pot so far so you could also say I

00:23:52,260 --> 00:23:58,650
want to have a boot up 10 or something

00:23:54,360 --> 00:24:01,050
like that then you have to specify what

00:23:58,650 --> 00:24:03,210
container you want to run inside this

00:24:01,050 --> 00:24:04,950
pot or containers again you can have

00:24:03,210 --> 00:24:07,560
multiple containers running in Dicer

00:24:04,950 --> 00:24:10,410
inside that so in this case we have only

00:24:07,560 --> 00:24:13,140
one container running inside I name that

00:24:10,410 --> 00:24:16,560
contain execution daemon you have to say

00:24:13,140 --> 00:24:19,530
where I'm kubernetes can download this

00:24:16,560 --> 00:24:23,150
image in my case I have it aligned on

00:24:19,530 --> 00:24:26,100
the Google cloud and you have to you can

00:24:23,150 --> 00:24:29,850
additionally add a so-called pool policy

00:24:26,100 --> 00:24:32,400
so in my case it says if if it's not

00:24:29,850 --> 00:24:34,950
present on the node you want to put up

00:24:32,400 --> 00:24:36,990
or to start this pot please go to this

00:24:34,950 --> 00:24:39,660
direction and download it you also can

00:24:36,990 --> 00:24:43,770
say something like always in this case

00:24:39,660 --> 00:24:46,410
it will always go to this to this path

00:24:43,770 --> 00:24:49,230
and look up if there is a new version of

00:24:46,410 --> 00:24:53,039
your of your application

00:24:49,230 --> 00:24:54,809
and you can down pass environment

00:24:53,039 --> 00:24:59,730
variables directly inside of your

00:24:54,809 --> 00:25:02,549
container so in my case I have a couple

00:24:59,730 --> 00:25:05,820
one so this one is the the first one -

00:25:02,549 --> 00:25:07,799
ugh type this says what inside what the

00:25:05,820 --> 00:25:10,620
container should start inside so in this

00:25:07,799 --> 00:25:13,529
case it should start an execution demon

00:25:10,620 --> 00:25:16,289
this is just for Democrats is so if this

00:25:13,529 --> 00:25:19,260
wouldn't be oh so usually ug deletion

00:25:16,289 --> 00:25:22,110
time at the it would cause the pot to

00:25:19,260 --> 00:25:24,149
destroy itself if for example you have

00:25:22,110 --> 00:25:29,490
don't have for 10 seconds workload on

00:25:24,149 --> 00:25:32,010
your execution demon running and I want

00:25:29,490 --> 00:25:34,980
you to know inside the container in

00:25:32,010 --> 00:25:36,480
which namespace I'm running so in in

00:25:34,980 --> 00:25:40,919
kubernetes you can have different

00:25:36,480 --> 00:25:44,639
namespaces which is a pretty basic and

00:25:40,919 --> 00:25:47,220
simple way to to divide your or your to

00:25:44,639 --> 00:25:49,380
cluster your your kubernetes cluster or

00:25:47,220 --> 00:25:52,080
divide your class your abilities cluster

00:25:49,380 --> 00:25:56,940
in different sections for example you

00:25:52,080 --> 00:26:02,220
have some development you want to have a

00:25:56,940 --> 00:26:05,850
development namespace and you have

00:26:02,220 --> 00:26:09,630
additionally some for the production you

00:26:05,850 --> 00:26:12,000
can also add lifecycle hooks so in this

00:26:09,630 --> 00:26:16,500
example I added a pre stop hook which

00:26:12,000 --> 00:26:19,019
means as soon as before the pot actually

00:26:16,500 --> 00:26:21,149
gets stopped or killed by kubernetes it

00:26:19,019 --> 00:26:24,179
should execute that command so this

00:26:21,149 --> 00:26:25,919
command will only go to the queue master

00:26:24,179 --> 00:26:29,100
and say ok I will be not available in a

00:26:25,919 --> 00:26:33,389
couple of seconds anymore and again like

00:26:29,100 --> 00:26:36,120
in like in docker you have to to say

00:26:33,389 --> 00:26:40,230
which ports should be accessible from

00:26:36,120 --> 00:26:46,409
outside of off-grid engine sorry for off

00:26:40,230 --> 00:26:50,279
of kubernetes the the last couple of

00:26:46,409 --> 00:26:55,289
lines here says ok I want to have I want

00:26:50,279 --> 00:26:58,080
to mount a pass inside of my of my of my

00:26:55,289 --> 00:27:00,809
container and this container at this

00:26:58,080 --> 00:27:02,350
pass should be from the persistent

00:27:00,809 --> 00:27:04,480
volume claim we

00:27:02,350 --> 00:27:06,610
we just created this is this so-called

00:27:04,480 --> 00:27:11,559
youichi claim so this one should be

00:27:06,610 --> 00:27:14,910
available at all my later at all my part

00:27:11,559 --> 00:27:14,910
of execution human parts

00:27:24,310 --> 00:27:29,420
so this is the stateful set for cue

00:27:26,720 --> 00:27:31,430
master it's pretty the same except that

00:27:29,420 --> 00:27:35,300
it's a stateful set and I want to put up

00:27:31,430 --> 00:27:37,130
one replica at a time yeah and there are

00:27:35,300 --> 00:27:39,440
a couple of environment variables

00:27:37,130 --> 00:27:41,690
missing which are not unnecessary for

00:27:39,440 --> 00:27:44,480
the cue master but again I want to have

00:27:41,690 --> 00:27:46,730
a shared directory between the execution

00:27:44,480 --> 00:27:48,740
Amanda cue master so you can see here

00:27:46,730 --> 00:27:52,130
this is the same persistent volume claim

00:27:48,740 --> 00:27:53,720
both of them are available so this claim

00:27:52,130 --> 00:27:56,240
will be you should be available in my

00:27:53,720 --> 00:28:07,340
cue master rep parts as also in my

00:27:56,240 --> 00:28:08,750
execution demon parts well this takes a

00:28:07,340 --> 00:28:11,720
while I have to boot up my mini cube

00:28:08,750 --> 00:28:20,600
cluster which is just should take a

00:28:11,720 --> 00:28:25,250
couple of seconds so I created a script

00:28:20,600 --> 00:28:27,470
which will add all these yellow files to

00:28:25,250 --> 00:28:32,990
to my queue beneath this cluster and

00:28:27,470 --> 00:28:36,230
because they we have here four different

00:28:32,990 --> 00:28:37,970
five we have the service also and it's

00:28:36,230 --> 00:28:41,000
always the same you do a cube control

00:28:37,970 --> 00:28:44,870
create dash F and this yellow file so we

00:28:41,000 --> 00:28:55,190
do not have to look at that so okay

00:28:44,870 --> 00:28:58,190
mini cube is up and running so there are

00:28:55,190 --> 00:29:08,090
no pots running so far so let's create

00:28:58,190 --> 00:29:09,230
our ug cluster so as you can see here

00:29:08,090 --> 00:29:12,650
the first what I did

00:29:09,230 --> 00:29:15,110
I created this persistent volume after

00:29:12,650 --> 00:29:18,110
that I was able to create my persistent

00:29:15,110 --> 00:29:21,500
volume claim started up my ug q master

00:29:18,110 --> 00:29:23,530
so my as I created my stateful side for

00:29:21,500 --> 00:29:25,880
the Q master and I created the

00:29:23,530 --> 00:29:28,790
replication controller so usually now we

00:29:25,880 --> 00:29:32,050
should have one Q master replica running

00:29:28,790 --> 00:29:32,050
but no execution demon

00:29:42,060 --> 00:29:45,390
[Music]

00:29:48,830 --> 00:29:54,870
yeah so we have one cue master running

00:29:51,990 --> 00:30:29,550
here one of one so let's add a couple of

00:29:54,870 --> 00:30:37,560
execution demands okay so it says I

00:30:29,550 --> 00:30:38,940
scaled my stuff now you can see that we

00:30:37,560 --> 00:30:41,400
have three execution daemons up and

00:30:38,940 --> 00:30:44,310
running and now we can go inside of the

00:30:41,400 --> 00:30:45,900
cue master just to demonstrate that they

00:30:44,310 --> 00:30:49,670
are really up and running and that we

00:30:45,900 --> 00:30:49,670
really have a running red engine cluster

00:31:19,050 --> 00:31:25,630
so for those who are familiar for me

00:31:23,680 --> 00:31:28,780
this great engine so you can see here

00:31:25,630 --> 00:31:31,060
I'm on my cue master host and I have

00:31:28,780 --> 00:31:33,580
here three different execution demons

00:31:31,060 --> 00:31:36,670
running inside which are exactly the

00:31:33,580 --> 00:31:40,510
parts we just put it up here in my mini

00:31:36,670 --> 00:31:45,060
cuba environment so that's what I wanted

00:31:40,510 --> 00:31:45,060
to show you are there any questions

00:31:46,380 --> 00:31:54,690

YouTube URL: https://www.youtube.com/watch?v=HjjsOG3xHwA


