Title: Tips for Writing Good Tests for Linux - Tim Bird, Sony
Publication date: 2018-03-13
Playlist: Embedded Linux Conference + OpenIoT Summit NA 2018
Description: 
	Tips for Writing Good Tests for Linux - Tim Bird, Sony

As maintainer of the Fuego test framework, I see lots of bad tests. The goal of this talk is to help you write tests that are more robust, easier to automate, and shareable with others in the Open Source community.

This talk will review and compare different test writing frameworks, including kselftest, LTP, and Fuego, and describe each one's strengths and weaknesses. A basic introduction to writing a test in each one will be given.

This talk will present tips for writing good individual tests, including which framework to use, what the test output should be, how to deal with test dependencies, how to make the test results more analyzable and usable, and other practical issues.

Following these tips should help you improve your own QA efforts. But my hidden agenda is to get you to write tests that I can use in my own Linux projects.

About Tim Bird
Tim Bird is a Senior Software Engineer for Sony Corporation, where he helps Sony use Linux and other open source software in their products. Tim is the maintainer of the Fuego test framework, and is involved in various groups in the Linux Foundation. Tim created the Embedded Linux Conference, and has spoken at it numerous times.

Tim's overall goal is to improve Linux for use in consumer electronics products, by improving Linux system testing, directing technical initiatives of the Linux Foundation, and encouraging companies to participate in the open source community. Tim has been working with Linux for over 20 years.
Captions: 
	00:00:00,030 --> 00:00:04,910
okay sorry for the slight delay here had

00:00:02,610 --> 00:00:07,859
some issues with my laptop connectivity

00:00:04,910 --> 00:00:13,170
but welcome to this session my name is

00:00:07,859 --> 00:00:17,010
Tim bird and I've been giving talks and

00:00:13,170 --> 00:00:20,100
stuff at ELC for a long time but today

00:00:17,010 --> 00:00:23,039
I'm going to talk about testing I have

00:00:20,100 --> 00:00:25,430
recently started well I recently became

00:00:23,039 --> 00:00:28,109
a maintainer of the fuego test system

00:00:25,430 --> 00:00:31,109
and I'm a current I'm a senior software

00:00:28,109 --> 00:00:32,700
engineer at sunny electronics and so I

00:00:31,109 --> 00:00:35,040
feel a little bit bad because it's

00:00:32,700 --> 00:00:37,170
taking me away from some of my kernel

00:00:35,040 --> 00:00:40,500
work but I think that testing is really

00:00:37,170 --> 00:00:43,500
important so here's a basic outline of

00:00:40,500 --> 00:00:45,360
what I want to talk about today I think

00:00:43,500 --> 00:00:48,090
that there are some problems in terms of

00:00:45,360 --> 00:00:50,250
the test ecosystem open source ecosystem

00:00:48,090 --> 00:00:51,660
around testing I'm going to talk

00:00:50,250 --> 00:00:53,219
specifically about three different test

00:00:51,660 --> 00:00:55,309
frameworks there are lots of different

00:00:53,219 --> 00:00:59,070
test frameworks but I chose these three

00:00:55,309 --> 00:01:01,440
and I the really the heart of the talk

00:00:59,070 --> 00:01:03,090
is the last half where I'm going to talk

00:01:01,440 --> 00:01:05,519
about what I consider to be attributes

00:01:03,090 --> 00:01:09,740
of a good test as the maintainer of a

00:01:05,519 --> 00:01:12,330
test framework I see lots of tests and

00:01:09,740 --> 00:01:14,689
some are really easy to deal with and

00:01:12,330 --> 00:01:17,490
some are not so easy to deal with and so

00:01:14,689 --> 00:01:20,720
my hidden agenda not some hidden I guess

00:01:17,490 --> 00:01:23,250
is that I'd like to kind of help you

00:01:20,720 --> 00:01:25,770
understand from from a test framework

00:01:23,250 --> 00:01:27,810
standpoint what are some of the things

00:01:25,770 --> 00:01:29,549
that make it easier or harder to run

00:01:27,810 --> 00:01:32,159
your tests for someone else to adopt

00:01:29,549 --> 00:01:33,240
them to use them to automate them and so

00:01:32,159 --> 00:01:37,110
I'm going to provide a whole bunch of

00:01:33,240 --> 00:01:39,060
tips and then I've got some pointers to

00:01:37,110 --> 00:01:41,310
resources so so that's the outline so

00:01:39,060 --> 00:01:43,860
let's just get right into it so what are

00:01:41,310 --> 00:01:45,240
the problems that I see well I don't

00:01:43,860 --> 00:01:47,790
think that there's enough sharing going

00:01:45,240 --> 00:01:50,850
on there's an awful lot of test

00:01:47,790 --> 00:01:52,799
frameworks there's and there actually

00:01:50,850 --> 00:01:55,320
are some tests available there's the

00:01:52,799 --> 00:01:57,030
Linux test project case self-test

00:01:55,320 --> 00:01:59,100
there's lots of benchmarks out there

00:01:57,030 --> 00:02:02,909
kind of stand-alone programs and those

00:01:59,100 --> 00:02:04,680
are all open source but when companies

00:02:02,909 --> 00:02:07,229
actually release a product based on

00:02:04,680 --> 00:02:09,450
Linux there's a whole lot of testing

00:02:07,229 --> 00:02:10,920
that they do that is not based on open

00:02:09,450 --> 00:02:13,260
source software is based on custom

00:02:10,920 --> 00:02:13,620
in-house software and the question that

00:02:13,260 --> 00:02:17,129
comes

00:02:13,620 --> 00:02:19,890
- mine is why why are why is not more of

00:02:17,129 --> 00:02:21,989
this stuff shared part of it is that

00:02:19,890 --> 00:02:23,700
there's for a lot of the custom stuff

00:02:21,989 --> 00:02:25,769
that companies right there's no upstream

00:02:23,700 --> 00:02:26,819
for it and a lot of companies are not

00:02:25,769 --> 00:02:28,370
going to go out and create their own

00:02:26,819 --> 00:02:35,010
open-source projects

00:02:28,370 --> 00:02:37,079
excuse me and so and the other the other

00:02:35,010 --> 00:02:38,640
aspect of this is that a lot of these

00:02:37,079 --> 00:02:41,129
tests are written to custom in-house

00:02:38,640 --> 00:02:44,790
test rigs right so if you're testing for

00:02:41,129 --> 00:02:47,190
example just at Sony we have USB is in

00:02:44,790 --> 00:02:48,930
almost every Sony product cameras and

00:02:47,190 --> 00:02:51,150
TVs and everything and so we have a

00:02:48,930 --> 00:02:54,540
whole big internal set up to test USB

00:02:51,150 --> 00:02:56,970
compatibility well that has custom

00:02:54,540 --> 00:02:58,769
hardware and even if we were using

00:02:56,970 --> 00:03:01,260
off-the-shelf hardware it be custom

00:02:58,769 --> 00:03:02,700
setup involved and so that USB

00:03:01,260 --> 00:03:04,340
compatibility testing that we do even

00:03:02,700 --> 00:03:07,230
though we have it automated inside Sony

00:03:04,340 --> 00:03:08,609
it's not really something that we could

00:03:07,230 --> 00:03:10,470
put out to the world because there's no

00:03:08,609 --> 00:03:11,129
it's not based on any standards or

00:03:10,470 --> 00:03:13,109
anything like that

00:03:11,129 --> 00:03:16,019
in particular the interface between the

00:03:13,109 --> 00:03:19,230
DUT the device under test and the test

00:03:16,019 --> 00:03:21,120
system and the test itself none of that

00:03:19,230 --> 00:03:22,500
is all is standardized and I think that

00:03:21,120 --> 00:03:25,440
those standards are something that we're

00:03:22,500 --> 00:03:28,380
missing I'll hopefully be able to circle

00:03:25,440 --> 00:03:29,790
back to that in terms of existing test

00:03:28,380 --> 00:03:31,829
problems if you look at the tests

00:03:29,790 --> 00:03:34,160
themselves that are out in open source a

00:03:31,829 --> 00:03:36,569
lot of them have a big learning curve

00:03:34,160 --> 00:03:39,060
they generate a lot of false positives

00:03:36,569 --> 00:03:42,209
and quite frankly there's a lot of

00:03:39,060 --> 00:03:44,790
useless tests as the open source kind of

00:03:42,209 --> 00:03:46,319
moves on I'm actually gonna talk about

00:03:44,790 --> 00:03:47,639
each of these so the learning curve so

00:03:46,319 --> 00:03:49,699
for any particular test that you would

00:03:47,639 --> 00:03:52,769
decide you want to run on your system

00:03:49,699 --> 00:03:54,810
the QA developer has got to learn how to

00:03:52,769 --> 00:03:57,359
build it how to run it how to install it

00:03:54,810 --> 00:03:59,970
now sometimes tests are integrated into

00:03:57,359 --> 00:04:01,590
things like the octo project in fact I

00:03:59,970 --> 00:04:04,169
think the octo project has a package for

00:04:01,590 --> 00:04:06,299
LTP so that one's relatively easy to get

00:04:04,169 --> 00:04:07,560
up and running but if you go and look at

00:04:06,299 --> 00:04:10,340
you know you want to run something like

00:04:07,560 --> 00:04:13,889
cyclic test or you want to XFS test or

00:04:10,340 --> 00:04:17,430
one of the CVE testers none of that

00:04:13,889 --> 00:04:19,260
stuff is available really readily and so

00:04:17,430 --> 00:04:22,860
as a test developer you have to go learn

00:04:19,260 --> 00:04:24,000
all this stuff and then you're going to

00:04:22,860 --> 00:04:26,130
need to customize it for your

00:04:24,000 --> 00:04:27,240
environment there may be certain things

00:04:26,130 --> 00:04:30,210
that you're concerned

00:04:27,240 --> 00:04:31,500
about well in the in the case of cyclic

00:04:30,210 --> 00:04:33,599
test every board has different

00:04:31,500 --> 00:04:35,310
characteristics and so what path what

00:04:33,599 --> 00:04:37,080
may constitute a pass for you will be a

00:04:35,310 --> 00:04:39,030
fail for someone else or vice versa

00:04:37,080 --> 00:04:41,639
and then you have how to interpret the

00:04:39,030 --> 00:04:43,740
results okay so you run LTP and it's

00:04:41,639 --> 00:04:49,280
very very common that when you run a

00:04:43,740 --> 00:04:53,340
linux test project LTP to get 1056

00:04:49,280 --> 00:04:54,720
passes and you know 45 fails and it's

00:04:53,340 --> 00:04:56,729
like well okay great

00:04:54,720 --> 00:04:58,680
what should I do with that do I report

00:04:56,729 --> 00:04:59,970
these fails are they real failures are

00:04:58,680 --> 00:05:02,400
they prop some problems with my

00:04:59,970 --> 00:05:04,409
configuration you don't know exactly how

00:05:02,400 --> 00:05:07,229
to interpret the results what to do with

00:05:04,409 --> 00:05:08,729
them what developers need to learn in

00:05:07,229 --> 00:05:11,190
dealing with these tests is if you want

00:05:08,729 --> 00:05:12,599
to report bugs upstream or if you want

00:05:11,190 --> 00:05:14,430
to find out if these are real bugs you

00:05:12,599 --> 00:05:16,139
need to reproduce the results you need

00:05:14,430 --> 00:05:17,580
to have third parties reproduce it maybe

00:05:16,139 --> 00:05:20,490
a kernel maintainer you want to have him

00:05:17,580 --> 00:05:22,169
reproduce the same same problem and you

00:05:20,490 --> 00:05:23,190
need to report these issues upstream and

00:05:22,169 --> 00:05:25,620
these are all things that you have to

00:05:23,190 --> 00:05:29,789
learn how to do it's a it's a big hill

00:05:25,620 --> 00:05:32,219
to climb in terms of false positives a

00:05:29,789 --> 00:05:35,039
lot of tests have bad or missing

00:05:32,219 --> 00:05:36,840
dependencies so the LTP tests often

00:05:35,039 --> 00:05:39,960
don't do a good job of checking for

00:05:36,840 --> 00:05:42,419
dependencies for example so the test

00:05:39,960 --> 00:05:44,570
just some of them do but a lot of tests

00:05:42,419 --> 00:05:48,060
just kind of fail and you don't know why

00:05:44,570 --> 00:05:51,030
and the one I spent like a week chasing

00:05:48,060 --> 00:05:53,669
this bug that had had to do with it was

00:05:51,030 --> 00:05:55,050
known to only work on to not work on a

00:05:53,669 --> 00:05:56,699
particular kernel version and there was

00:05:55,050 --> 00:06:00,120
no that was none wasn't documented

00:05:56,699 --> 00:06:01,620
anywhere and it didn't check the kernel

00:06:00,120 --> 00:06:03,210
version and so you can get these

00:06:01,620 --> 00:06:04,919
failures that come out of nowhere and

00:06:03,210 --> 00:06:07,110
you have to go basically figure them out

00:06:04,919 --> 00:06:09,599
yourself a lot of tests are too

00:06:07,110 --> 00:06:11,190
sensitive to the test conditions of the

00:06:09,599 --> 00:06:15,650
environment they're like not very stable

00:06:11,190 --> 00:06:17,550
and so you get on your on your

00:06:15,650 --> 00:06:19,919
visualization you get what I call blinky

00:06:17,550 --> 00:06:21,930
lights where the test fails and passes

00:06:19,919 --> 00:06:23,159
and fails and passes and and it's

00:06:21,930 --> 00:06:25,800
intermittent you can't really pin it

00:06:23,159 --> 00:06:27,770
down those are really a pain to track

00:06:25,800 --> 00:06:30,180
down

00:06:27,770 --> 00:06:32,099
so sometimes it's extra load on the

00:06:30,180 --> 00:06:34,800
machine sometimes it's bad Network bad

00:06:32,099 --> 00:06:39,620
flash some server unavailability in your

00:06:34,800 --> 00:06:39,620
in your test environment

00:06:39,650 --> 00:06:43,370
and then there's a whole category of

00:06:41,900 --> 00:06:44,870
tests that are kind of useless and

00:06:43,370 --> 00:06:46,310
there's kind of an extreme of tests

00:06:44,870 --> 00:06:49,219
there are tests that test things that

00:06:46,310 --> 00:06:50,749
are way too simple you know that you

00:06:49,219 --> 00:06:52,669
just know is not going to fail right you

00:06:50,749 --> 00:06:55,340
don't need to test it's just the open

00:06:52,669 --> 00:06:58,879
syscall probably because it's being used

00:06:55,340 --> 00:07:02,139
in a bazillion places and and brazilian

00:06:58,879 --> 00:07:05,449
is actually the right SI unit for that

00:07:02,139 --> 00:07:08,300
so opens not gonna fail but there's you

00:07:05,449 --> 00:07:10,069
know in LTP there's an open Cisco tester

00:07:08,300 --> 00:07:12,080
that's like okay great

00:07:10,069 --> 00:07:14,449
and some test conditions will get

00:07:12,080 --> 00:07:16,219
exercised just by just by booting the

00:07:14,449 --> 00:07:17,960
machine you know that you know the

00:07:16,219 --> 00:07:21,110
machine is capable of opening a file if

00:07:17,960 --> 00:07:22,849
you can run your test framework but and

00:07:21,110 --> 00:07:25,370
so you have things that test things that

00:07:22,849 --> 00:07:27,409
are really unlikely to fail some things

00:07:25,370 --> 00:07:29,389
are super super rare they're just so

00:07:27,409 --> 00:07:30,560
unexpected that they would fail that

00:07:29,389 --> 00:07:33,189
it's really a waste of your test

00:07:30,560 --> 00:07:36,919
bandwidth to be executing cycles on it

00:07:33,189 --> 00:07:40,249
so it's kind of more cost to execute

00:07:36,919 --> 00:07:42,800
than it's worth to find a bug so what

00:07:40,249 --> 00:07:44,509
are the solutions to these problems well

00:07:42,800 --> 00:07:47,089
we'd like to see well I would like to

00:07:44,509 --> 00:07:50,060
see a test ecosystem where people can

00:07:47,089 --> 00:07:51,229
actually start working on tests that

00:07:50,060 --> 00:07:53,839
have been developed by other people we

00:07:51,229 --> 00:07:56,659
can use the open source effect to

00:07:53,839 --> 00:08:01,339
develop a good body of test and a good

00:07:56,659 --> 00:08:02,569
body of of useful QA materials so we

00:08:01,339 --> 00:08:04,939
need to have tests that are well

00:08:02,569 --> 00:08:07,339
documented we want to make them easy to

00:08:04,939 --> 00:08:09,979
automate so that means handling building

00:08:07,339 --> 00:08:12,199
and installation automatically we want

00:08:09,979 --> 00:08:14,089
tests that are robust that can handle

00:08:12,199 --> 00:08:16,819
these dependencies and skip problematic

00:08:14,089 --> 00:08:18,319
tests and more most importantly I think

00:08:16,819 --> 00:08:19,819
we want tests that are shareable with

00:08:18,319 --> 00:08:22,039
others so they need to work in a lot of

00:08:19,819 --> 00:08:24,169
different scenarios they need to work on

00:08:22,039 --> 00:08:27,020
lots of different devices and it should

00:08:24,169 --> 00:08:28,729
be easy to customize them so shouldn't

00:08:27,020 --> 00:08:32,569
have a lot of baked in assumptions in

00:08:28,729 --> 00:08:34,640
the tests and I will I promise get to

00:08:32,569 --> 00:08:36,829
some actual these are these are kind of

00:08:34,640 --> 00:08:38,899
high level of cloud level suggestions a

00:08:36,829 --> 00:08:40,250
hundred thousand foot I'll get to some

00:08:38,899 --> 00:08:42,380
specific things that I think will help

00:08:40,250 --> 00:08:45,290
with that before I do that I'm going to

00:08:42,380 --> 00:08:48,649
take a little bit of a side tour and I

00:08:45,290 --> 00:08:51,030
gotta figure out my timing here so this

00:08:48,649 --> 00:08:56,220
session is a 40-minute session

00:08:51,030 --> 00:08:57,570
so I end it 12:30 is that right if you

00:08:56,220 --> 00:09:01,950
don't tell me I'm gonna go over eyes

00:08:57,570 --> 00:09:04,710
yeah okay so twelve twelve forty I think

00:09:01,950 --> 00:09:06,330
so it's a 50-minute session okay I just

00:09:04,710 --> 00:09:09,180
need to pace myself so I'm gonna talk

00:09:06,330 --> 00:09:14,790
about three test frameworks LTP okay

00:09:09,180 --> 00:09:16,590
self test and fuego and so let's just

00:09:14,790 --> 00:09:18,720
dive into those right now so LTP is a

00:09:16,590 --> 00:09:21,270
big umbrella project it's got a whole

00:09:18,720 --> 00:09:23,190
bunch of tests in it it provides helper

00:09:21,270 --> 00:09:25,860
functions for setup results reporting

00:09:23,190 --> 00:09:30,150
and cleanup it was founded a long time

00:09:25,860 --> 00:09:32,520
ago if you look at it it's mostly not

00:09:30,150 --> 00:09:34,800
exclusively but mostly C and POSIX shell

00:09:32,520 --> 00:09:37,050
tests of kernel and core system

00:09:34,800 --> 00:09:40,230
functionality there's no benchmarks in

00:09:37,050 --> 00:09:42,510
it it's really a functional test it has

00:09:40,230 --> 00:09:44,160
lots of tests there are over 3,000 tests

00:09:42,510 --> 00:09:47,250
and they're in three broad categories

00:09:44,160 --> 00:09:49,380
there's the functional testing there's

00:09:47,250 --> 00:09:52,200
actually a the POSIX test suite was

00:09:49,380 --> 00:09:53,400
actually swallowed into LTP and then

00:09:52,200 --> 00:09:55,890
they've got a bunch of real-time tests

00:09:53,400 --> 00:09:58,230
as well it's kind of hard to assess the

00:09:55,890 --> 00:09:59,610
coverage it's not it's not done in a

00:09:58,230 --> 00:10:02,070
formal enough way that you can say oh

00:09:59,610 --> 00:10:03,750
yes we've tested you know every single

00:10:02,070 --> 00:10:05,070
item in the spec well maybe the POSIX

00:10:03,750 --> 00:10:07,589
does but the functional testing is

00:10:05,070 --> 00:10:09,570
really kind of scattershot and new

00:10:07,589 --> 00:10:11,760
syscalls keep showing up in linux right

00:10:09,570 --> 00:10:13,560
and so like the static system assist

00:10:11,760 --> 00:10:16,200
call is a new syscall relatively

00:10:13,560 --> 00:10:19,500
recently and you don't know how much of

00:10:16,200 --> 00:10:21,750
its behavior is kind of tested by LTP so

00:10:19,500 --> 00:10:24,150
it's kind of hard to know I mean you

00:10:21,750 --> 00:10:27,060
know if LTP shows you a bug but you

00:10:24,150 --> 00:10:29,100
don't know what you're missing LTP

00:10:27,060 --> 00:10:32,700
historically has had a very heavy focus

00:10:29,100 --> 00:10:34,860
on testing air conditions and so it

00:10:32,700 --> 00:10:36,390
basically it looks to see you know if I

00:10:34,860 --> 00:10:37,920
pass a string that's too long to the

00:10:36,390 --> 00:10:42,810
mount command does it give me the right

00:10:37,920 --> 00:10:45,120
air no that type of stuff and it does

00:10:42,810 --> 00:10:47,400
include a little mini test harness a

00:10:45,120 --> 00:10:49,530
really lightweight test harness so tests

00:10:47,400 --> 00:10:51,570
can be run individually or they can be

00:10:49,530 --> 00:10:52,860
run in groups or in stress

00:10:51,570 --> 00:10:54,810
configurations I don't think a lot of

00:10:52,860 --> 00:10:56,070
people do this and maybe maybe there are

00:10:54,810 --> 00:10:57,150
people out there doing this that I'm not

00:10:56,070 --> 00:11:00,540
aware of but there's something called

00:10:57,150 --> 00:11:02,580
LTP pan I have tried to find out what

00:11:00,540 --> 00:11:04,380
the pan stands for someone knows let me

00:11:02,580 --> 00:11:07,200
know just

00:11:04,380 --> 00:11:08,610
curiosity but LTB pan is a little

00:11:07,200 --> 00:11:13,320
command-line tool that allows you to run

00:11:08,610 --> 00:11:16,520
a series of LTP test programs so each

00:11:13,320 --> 00:11:19,560
each program in LTP there's a there's a

00:11:16,520 --> 00:11:21,630
separate individual compiled program and

00:11:19,560 --> 00:11:24,750
it will run a named collection of these

00:11:21,630 --> 00:11:28,860
and it can do them it repeatedly can run

00:11:24,750 --> 00:11:30,480
a bunch of them in in parallel and for a

00:11:28,860 --> 00:11:32,520
period of time you can customize the

00:11:30,480 --> 00:11:34,230
pram the command-line parameters it's

00:11:32,520 --> 00:11:36,030
pretty flexible and this is I think

00:11:34,230 --> 00:11:37,470
intended to be able to allow you to do

00:11:36,030 --> 00:11:40,350
stress testing over a long period of

00:11:37,470 --> 00:11:43,620
time I don't the thing about it though

00:11:40,350 --> 00:11:46,170
is that I don't think you're going to

00:11:43,620 --> 00:11:47,820
actually find like open returns a

00:11:46,170 --> 00:11:50,780
different era know if you run it a

00:11:47,820 --> 00:11:53,100
million times versus a hundred times so

00:11:50,780 --> 00:11:54,810
to some degree I don't think I think

00:11:53,100 --> 00:11:56,550
like things like sis killer or some of

00:11:54,810 --> 00:11:59,700
those other ones or there are other

00:11:56,550 --> 00:12:01,770
stress tests or buzzers that do a better

00:11:59,700 --> 00:12:04,200
job of testing that type of thing

00:12:01,770 --> 00:12:07,110
and then finally there's LTP run which

00:12:04,200 --> 00:12:08,760
runs groups of tests and there are many

00:12:07,110 --> 00:12:10,800
many groups to find there's about 80

00:12:08,760 --> 00:12:13,170
different groups so there's sis calls

00:12:10,800 --> 00:12:16,680
you can test input file systems

00:12:13,170 --> 00:12:17,850
networking math Numa all these different

00:12:16,680 --> 00:12:21,600
groups of tests so you don't have to

00:12:17,850 --> 00:12:26,100
test everything at once but you can test

00:12:21,600 --> 00:12:27,720
to define groups the output of this is

00:12:26,100 --> 00:12:30,180
one of the strengths of LTP is its

00:12:27,720 --> 00:12:32,610
output it's got a very kind of rigorous

00:12:30,180 --> 00:12:35,430
output at least for the the regular

00:12:32,610 --> 00:12:36,450
functional type tests it turns out that

00:12:35,430 --> 00:12:39,330
each of those three groups I mentioned

00:12:36,450 --> 00:12:40,590
the POSIX conformance and the real-time

00:12:39,330 --> 00:12:43,730
and the functional test each of those

00:12:40,590 --> 00:12:46,140
has their own different output formats

00:12:43,730 --> 00:12:47,640
the functional test at least is all kind

00:12:46,140 --> 00:12:49,470
of regularize because they've been

00:12:47,640 --> 00:12:54,030
written to a common framework and so you

00:12:49,470 --> 00:12:55,620
get a nice schema consistent set of text

00:12:54,030 --> 00:12:57,630
strings indicating the different

00:12:55,620 --> 00:12:59,790
conditions the results and then you get

00:12:57,630 --> 00:13:01,950
additional metadata when you use their

00:12:59,790 --> 00:13:03,600
test harness like the command line that

00:13:01,950 --> 00:13:09,150
was used the duration of the test system

00:13:03,600 --> 00:13:10,890
times that type of thing so I thought

00:13:09,150 --> 00:13:14,520
I'd just show you really quickly a

00:13:10,890 --> 00:13:15,990
couple of quick things about an LTP test

00:13:14,520 --> 00:13:18,329
I don't want to dwell on this too long

00:13:15,990 --> 00:13:19,499
the slides will be online so you can go

00:13:18,329 --> 00:13:22,559
look at it but this is from the you

00:13:19,499 --> 00:13:24,899
mount o2 test this is what the output

00:13:22,559 --> 00:13:27,929
looks like from this you can see that

00:13:24,899 --> 00:13:29,399
each line most of these lines I don't

00:13:27,929 --> 00:13:31,829
know if the laser still works here all

00:13:29,399 --> 00:13:34,379
it does a little bit so there's some

00:13:31,829 --> 00:13:36,509
information lines as its as the test is

00:13:34,379 --> 00:13:41,929
doing test setup and then these are the

00:13:36,509 --> 00:13:44,759
actual lines indicating the the specific

00:13:41,929 --> 00:13:46,699
tests that it checks for so it checked

00:13:44,759 --> 00:13:50,279
for already mounted or invalid address

00:13:46,699 --> 00:13:55,499
directory not found and then it has a

00:13:50,279 --> 00:13:57,449
summary of the test down here so if you

00:13:55,499 --> 00:13:59,819
actually go look at the code there's

00:13:57,449 --> 00:14:01,829
some nice things that the code for the

00:13:59,819 --> 00:14:03,089
you mount is actually fairly simple and

00:14:01,829 --> 00:14:04,559
I don't actually I'm not actually I show

00:14:03,089 --> 00:14:06,689
you the code that does the real testing

00:14:04,559 --> 00:14:08,610
just some of the stuff surrounding it to

00:14:06,689 --> 00:14:11,999
give you a flavor of what it's like to

00:14:08,610 --> 00:14:15,509
write a test in this case so we have

00:14:11,999 --> 00:14:17,999
these safe macros that help you do some

00:14:15,509 --> 00:14:21,480
of your setup in a in a controlled

00:14:17,999 --> 00:14:24,540
fashion and LTP will well if something

00:14:21,480 --> 00:14:27,089
goes wrong will help you back stuff out

00:14:24,540 --> 00:14:29,249
and and cleanup for you automatically

00:14:27,089 --> 00:14:31,499
and so you write a setup function you

00:14:29,249 --> 00:14:32,970
write a cleanup function and you try to

00:14:31,499 --> 00:14:34,649
make these mirror images of each other

00:14:32,970 --> 00:14:36,929
in fact I think I say this on the next

00:14:34,649 --> 00:14:39,419
slide so you clean up in opposite order

00:14:36,929 --> 00:14:41,639
of resource allocation fairly standard

00:14:39,419 --> 00:14:42,929
practice and you can use there's a whole

00:14:41,639 --> 00:14:45,989
bunch of helper functions that start

00:14:42,929 --> 00:14:48,449
with TST underscore and there are a lot

00:14:45,989 --> 00:14:50,339
of them to handle common operations like

00:14:48,449 --> 00:14:53,549
setting up you know like we just saw

00:14:50,339 --> 00:14:57,989
like setting up for mounting file

00:14:53,549 --> 00:14:59,850
systems or for setting up for system

00:14:57,989 --> 00:15:01,379
calls or creating temporary files or

00:14:59,850 --> 00:15:03,809
that type of thing

00:15:01,379 --> 00:15:06,569
if you look at the test itself the main

00:15:03,809 --> 00:15:09,360
the main this is from again from part of

00:15:06,569 --> 00:15:12,119
it the main body of this there's a set

00:15:09,360 --> 00:15:14,100
of test cases this struct key case this

00:15:12,119 --> 00:15:16,919
is specifically to specific to the you

00:15:14,100 --> 00:15:19,259
mount o2 dot C file but it just has a

00:15:16,919 --> 00:15:22,470
list of you know the description of what

00:15:19,259 --> 00:15:23,579
it's going to test some extra parameter

00:15:22,470 --> 00:15:25,319
here and then what

00:15:23,579 --> 00:15:27,779
whatare know it's expecting to find and

00:15:25,319 --> 00:15:30,809
so if it finds the finds a particular

00:15:27,779 --> 00:15:32,810
error no it returns a t fail and it's

00:15:30,809 --> 00:15:37,010
using TST underscore

00:15:32,810 --> 00:15:38,930
so that's test result so that is using a

00:15:37,010 --> 00:15:42,050
library function to get that common

00:15:38,930 --> 00:15:46,850
output format and then if something fail

00:15:42,050 --> 00:15:48,740
if it passes then you print out this

00:15:46,850 --> 00:15:52,820
material if it fails you print out some

00:15:48,740 --> 00:15:54,650
additional material so so verify you mod

00:15:52,820 --> 00:15:56,840
is the main test routine in this case

00:15:54,650 --> 00:15:59,810
it's called with the sub test case now

00:15:56,840 --> 00:16:05,330
sub test case number and test res is

00:15:59,810 --> 00:16:07,460
used to report result and the main in

00:16:05,330 --> 00:16:10,820
terms of looking at the test LTP test

00:16:07,460 --> 00:16:19,150
API the main thing is this struct test

00:16:10,820 --> 00:16:21,650
test or TST test which has the test ID

00:16:19,150 --> 00:16:24,470
account of the number of sub test cases

00:16:21,650 --> 00:16:26,570
and then by specifying a couple of

00:16:24,470 --> 00:16:29,300
variables here need root need tempter

00:16:26,570 --> 00:16:31,280
the LTP system will automatically create

00:16:29,300 --> 00:16:32,990
those for you so in your test program

00:16:31,280 --> 00:16:34,940
you don't actually have a main there's a

00:16:32,990 --> 00:16:37,100
main somewhere else that's handling some

00:16:34,940 --> 00:16:39,800
of this automatic setup and teardown for

00:16:37,100 --> 00:16:40,760
you and then you specify some function

00:16:39,800 --> 00:16:43,610
pointers so it's a little bit

00:16:40,760 --> 00:16:44,960
object-oriented but it's in pure C so

00:16:43,610 --> 00:16:46,370
yeah you just declare your setup

00:16:44,960 --> 00:16:48,740
function your clean up function and then

00:16:46,370 --> 00:16:51,530
the actual test routine that's going to

00:16:48,740 --> 00:16:52,910
get called in this case in a loop

00:16:51,530 --> 00:16:57,080
because you have more than one sub to

00:16:52,910 --> 00:16:59,020
its case and I think I just described

00:16:57,080 --> 00:17:03,050
all the that was that was on this page

00:16:59,020 --> 00:17:05,450
okay so that was my what's under under

00:17:03,050 --> 00:17:07,130
five minute introduction to LTP so

00:17:05,450 --> 00:17:10,910
you're now all LTP experts are at least

00:17:07,130 --> 00:17:14,450
as much as I am and there's a really

00:17:10,910 --> 00:17:16,339
good couple there's some good resources

00:17:14,450 --> 00:17:19,959
the documentation for LTP is not

00:17:16,339 --> 00:17:23,030
fabulous I got to tell you but it is

00:17:19,959 --> 00:17:25,660
there are there are tutorials online and

00:17:23,030 --> 00:17:28,970
there's obviously lots of code examples

00:17:25,660 --> 00:17:30,710
and there's a lightning talk actually

00:17:28,970 --> 00:17:33,830
just at FOSDEM just a like a month ago

00:17:30,710 --> 00:17:35,770
or on introduction and status of LTP

00:17:33,830 --> 00:17:39,950
that's that's worth taking a look at

00:17:35,770 --> 00:17:41,990
okay and so LTP conclusion has a lot of

00:17:39,950 --> 00:17:45,290
support for writing a good test

00:17:41,990 --> 00:17:47,580
it needs more tests to help keep it stay

00:17:45,290 --> 00:17:50,260
relevant

00:17:47,580 --> 00:17:51,909
please go out and use it please add

00:17:50,260 --> 00:17:53,200
stuff to it and fix anything you find

00:17:51,909 --> 00:17:54,700
that it broken the more people that use

00:17:53,200 --> 00:17:56,320
it the more that we can create an

00:17:54,700 --> 00:17:58,059
ecosystem around it like a lot of open

00:17:56,320 --> 00:18:00,669
source projects it's got a corps of

00:17:58,059 --> 00:18:02,860
developers that maybe about four really

00:18:00,669 --> 00:18:04,870
key developers and then kind of a

00:18:02,860 --> 00:18:06,610
peripheral set of developers the more

00:18:04,870 --> 00:18:08,710
people to add to it the more benefit

00:18:06,610 --> 00:18:10,630
that we can get as whole industry so

00:18:08,710 --> 00:18:13,870
here's a couple of ideas for projects if

00:18:10,630 --> 00:18:15,340
you if you just you know have so much

00:18:13,870 --> 00:18:17,440
idle time that you're just wondering

00:18:15,340 --> 00:18:19,330
what should I do you know on my weekends

00:18:17,440 --> 00:18:23,919
well you should go out and work on LTP

00:18:19,330 --> 00:18:26,950
of course that seems obvious okay so

00:18:23,919 --> 00:18:29,860
moving right along Kay self-test soak a

00:18:26,950 --> 00:18:32,679
self-test is a whole different thing

00:18:29,860 --> 00:18:35,080
it's the kernel unit test framework it's

00:18:32,679 --> 00:18:37,419
inside the kernel source tree it

00:18:35,080 --> 00:18:40,210
supports both local execution of tests

00:18:37,419 --> 00:18:42,220
or remote installation so you can build

00:18:40,210 --> 00:18:44,740
a tar file that you then have go and

00:18:42,220 --> 00:18:47,950
manually install on another machine or

00:18:44,740 --> 00:18:49,780
another device and it can cross compile

00:18:47,950 --> 00:18:53,470
just like the the kernel can be cross

00:18:49,780 --> 00:18:55,570
compiled and you can select on the on

00:18:53,470 --> 00:18:56,860
the make line when you when you make

00:18:55,570 --> 00:18:58,750
this stuff you can select us an

00:18:56,860 --> 00:19:00,820
individual set of tests to run again it

00:18:58,750 --> 00:19:02,679
has groups of tests that are in

00:19:00,820 --> 00:19:04,900
directories there's about fifty two

00:19:02,679 --> 00:19:07,659
directories 350 different source files

00:19:04,900 --> 00:19:09,669
and this is where the kernel developers

00:19:07,659 --> 00:19:10,900
themselves put their unit tests or where

00:19:09,669 --> 00:19:13,360
they're supposed to put their unit tests

00:19:10,900 --> 00:19:17,980
not everybody's on board yet but it's

00:19:13,360 --> 00:19:19,750
kind of gathering steam this is super

00:19:17,980 --> 00:19:21,130
convenient if you happen to be a kernel

00:19:19,750 --> 00:19:23,200
developer because it's right there in

00:19:21,130 --> 00:19:24,580
your source tree your if you type to

00:19:23,200 --> 00:19:26,919
make to build your kernel all you have

00:19:24,580 --> 00:19:28,570
to do is type make K self test to test

00:19:26,919 --> 00:19:29,830
your kernel if you happen to be on the

00:19:28,570 --> 00:19:31,419
same machine there's a couple extra

00:19:29,830 --> 00:19:34,900
steps if you're testing a different

00:19:31,419 --> 00:19:37,210
machine than the one you're on but K

00:19:34,900 --> 00:19:39,460
self test is fairly primitive it does

00:19:37,210 --> 00:19:42,340
not provide a harness it doesn't provide

00:19:39,460 --> 00:19:45,909
any helpers for setup or cleanup and

00:19:42,340 --> 00:19:47,890
it's really ad hoc so people this is

00:19:45,909 --> 00:19:50,890
basically the kernel community has

00:19:47,890 --> 00:19:52,450
started to gather their own unit tests

00:19:50,890 --> 00:19:53,919
that we're outside the kernel and it

00:19:52,450 --> 00:19:55,870
hasn't just kind of have jammed them

00:19:53,919 --> 00:19:59,140
together so they're trying to migrate

00:19:55,870 --> 00:19:59,800
now towards a common format right now

00:19:59,140 --> 00:20:01,810
every ten

00:19:59,800 --> 00:20:05,020
looks different the output is different

00:20:01,810 --> 00:20:07,390
and I was going to show an example K

00:20:05,020 --> 00:20:10,660
self-test but there's really not a good

00:20:07,390 --> 00:20:11,770
example I have a test on size in here

00:20:10,660 --> 00:20:13,770
but I don't want to that would be

00:20:11,770 --> 00:20:16,300
gratuitous for me to show my own test

00:20:13,770 --> 00:20:20,830
each test is different so there's really

00:20:16,300 --> 00:20:22,750
kind of no canonical example of of the

00:20:20,830 --> 00:20:24,760
API because there's kind of no really

00:20:22,750 --> 00:20:26,110
API there there is a little bit of an

00:20:24,760 --> 00:20:26,710
API each way it run is written from

00:20:26,110 --> 00:20:30,670
scratch

00:20:26,710 --> 00:20:31,930
so what's going on lately with K self

00:20:30,670 --> 00:20:34,120
tests is they've been trying to convert

00:20:31,930 --> 00:20:37,020
to the tap format for the output format

00:20:34,120 --> 00:20:43,450
so tap stands for test anything protocol

00:20:37,020 --> 00:20:47,890
it's a very very simple one page one

00:20:43,450 --> 00:20:51,640
page specification for how the output of

00:20:47,890 --> 00:20:52,960
a test should look not should as a not

00:20:51,640 --> 00:20:55,210
but you know if you're following the

00:20:52,960 --> 00:20:57,490
spec this is specifies what the output

00:20:55,210 --> 00:20:59,200
is supposed to look like you can see

00:20:57,490 --> 00:21:01,060
it's very very simple it's line oriented

00:20:59,200 --> 00:21:04,960
each line starts with either ok or not

00:21:01,060 --> 00:21:08,890
OK and then has a test number so there

00:21:04,960 --> 00:21:11,410
are some helper api's in k self-test for

00:21:08,890 --> 00:21:14,140
test to produce this output rather than

00:21:11,410 --> 00:21:15,880
their own ad hoc output and people in

00:21:14,140 --> 00:21:19,570
the kernel are starting to migrate to

00:21:15,880 --> 00:21:22,000
this format so if you use KS FTE test

00:21:19,570 --> 00:21:25,780
result pass it'll output your message in

00:21:22,000 --> 00:21:28,480
tap format which is good that's that's a

00:21:25,780 --> 00:21:30,040
good start in the right direction and

00:21:28,480 --> 00:21:33,670
then here's some resources if you want

00:21:30,040 --> 00:21:35,260
to get started with K self-test a couple

00:21:33,670 --> 00:21:38,080
of tips if you happen to go down this

00:21:35,260 --> 00:21:39,820
route don't assume that you're building

00:21:38,080 --> 00:21:42,630
or running on the latest version of the

00:21:39,820 --> 00:21:45,130
kernel I see this a lot in K self-test

00:21:42,630 --> 00:21:47,080
so don't rely on features of the current

00:21:45,130 --> 00:21:51,250
kernel version try to make your test

00:21:47,080 --> 00:21:53,230
backwards compatible because well I'm

00:21:51,250 --> 00:21:54,760
speaking I'm preaching to the choir here

00:21:53,230 --> 00:21:57,700
because we're all in better developers I

00:21:54,760 --> 00:22:01,630
know you all most of you are not running

00:21:57,700 --> 00:22:03,250
like the 4.16 kernel right so so I this

00:22:01,630 --> 00:22:06,280
is a plea to the guys who are working on

00:22:03,250 --> 00:22:09,130
the 4.16 kernel to to please throw us a

00:22:06,280 --> 00:22:11,960
bone when we're working back on 318 or 4

00:22:09,130 --> 00:22:15,110
4 or whatever kernel we

00:22:11,960 --> 00:22:17,930
we happen to have in our products so

00:22:15,110 --> 00:22:19,210
check for it if you're writing tests try

00:22:17,930 --> 00:22:21,290
to check for dependencies at runtime

00:22:19,210 --> 00:22:23,840
notify the user if they're not filled

00:22:21,290 --> 00:22:25,580
check if you need to run as a root user

00:22:23,840 --> 00:22:28,100
please check for that

00:22:25,580 --> 00:22:30,290
don't just silently fail in weird ways

00:22:28,100 --> 00:22:33,920
and check the kernel configuration for

00:22:30,290 --> 00:22:35,990
required configs okay so if Wego so this

00:22:33,920 --> 00:22:37,370
is near and dear to my heart you might

00:22:35,990 --> 00:22:39,320
think I'd spend a whole lot of time on

00:22:37,370 --> 00:22:43,250
this I'll spend a medium amount of time

00:22:39,320 --> 00:22:44,540
on this but fuego just if you haven't

00:22:43,250 --> 00:22:46,910
seen this before don't know what it is

00:22:44,540 --> 00:22:50,290
it's kind of a host test distribution

00:22:46,910 --> 00:22:52,610
plus a bunch of tests and test wrappers

00:22:50,290 --> 00:22:55,310
packaged along with a Jenkins interface

00:22:52,610 --> 00:22:59,120
all inside a docker container it is

00:22:55,310 --> 00:23:00,950
intrinsically host target okay so the

00:22:59,120 --> 00:23:02,570
enterprise guys and the cloud guys

00:23:00,950 --> 00:23:04,310
they're all lucky they get to they can

00:23:02,570 --> 00:23:05,570
they can develop their software and test

00:23:04,310 --> 00:23:08,480
their software all on their development

00:23:05,570 --> 00:23:10,070
machines if they want but we're often we

00:23:08,480 --> 00:23:13,280
often have a big disparity between our

00:23:10,070 --> 00:23:14,840
develop machines and our products and so

00:23:13,280 --> 00:23:16,670
we need an environment where we can

00:23:14,840 --> 00:23:18,770
cross compile and drive the testing from

00:23:16,670 --> 00:23:22,310
a more powerful machine than the one

00:23:18,770 --> 00:23:24,890
we're testing this is an analogy I just

00:23:22,310 --> 00:23:27,380
barely came up with that Fuego is like

00:23:24,890 --> 00:23:30,500
the Debian of QA software so it's more

00:23:27,380 --> 00:23:33,860
like a distribution than it is test

00:23:30,500 --> 00:23:36,230
harness well it has distribution like

00:23:33,860 --> 00:23:38,390
attributes so there's a bunch of tests

00:23:36,230 --> 00:23:41,060
in Fuego and each one has kind of its

00:23:38,390 --> 00:23:43,580
own little package that tells it how to

00:23:41,060 --> 00:23:45,650
run how to install that type of thing

00:23:43,580 --> 00:23:47,990
right now we have about 150 different

00:23:45,650 --> 00:23:51,170
test suites that are included in fuego

00:23:47,990 --> 00:23:52,630
and these are not some of them are Fuego

00:23:51,170 --> 00:23:55,820
specific tests but most of these are

00:23:52,630 --> 00:23:57,980
wrappers around existing tests and I

00:23:55,820 --> 00:24:00,350
think it's on the next yeah so it's more

00:23:57,980 --> 00:24:03,140
like a packaging system than an

00:24:00,350 --> 00:24:05,540
individual test go test

00:24:03,140 --> 00:24:07,430
so the fuego test shell which every

00:24:05,540 --> 00:24:09,740
testing FICO has is a wrapper for

00:24:07,430 --> 00:24:12,170
building deploying running and

00:24:09,740 --> 00:24:14,420
collecting the results for a test and

00:24:12,170 --> 00:24:17,630
then you can also provide a parser so

00:24:14,420 --> 00:24:20,510
whatever weird output format that test

00:24:17,630 --> 00:24:22,130
has that you're trying to wrap you can

00:24:20,510 --> 00:24:24,980
collect that information and put it into

00:24:22,130 --> 00:24:25,280
a standardized output format we can

00:24:24,980 --> 00:24:28,460
apply

00:24:25,280 --> 00:24:31,190
a pass criteria again the pass criteria

00:24:28,460 --> 00:24:35,270
can be shared the way to customize the

00:24:31,190 --> 00:24:36,620
tests can be shared and that parser

00:24:35,270 --> 00:24:39,980
allows us to collect that individual

00:24:36,620 --> 00:24:43,930
test data I'm not going to go into great

00:24:39,980 --> 00:24:47,120
detail this is the architecture diagram

00:24:43,930 --> 00:24:49,730
we run a bunch of stuff Lego scripts on

00:24:47,120 --> 00:24:52,190
the host inside a docker container we've

00:24:49,730 --> 00:24:54,860
got a web control interface for starting

00:24:52,190 --> 00:24:56,930
tests or monitoring their results doing

00:24:54,860 --> 00:24:59,150
visualization on it but all of the real

00:24:56,930 --> 00:25:01,580
action happens over on the right there

00:24:59,150 --> 00:25:03,650
on the target board where the test

00:25:01,580 --> 00:25:05,090
program so we do building we actually

00:25:03,650 --> 00:25:06,140
build from source and some people don't

00:25:05,090 --> 00:25:07,760
like that

00:25:06,140 --> 00:25:09,890
but I think it's really important then

00:25:07,760 --> 00:25:11,810
when I get to my tip section I'll tell

00:25:09,890 --> 00:25:14,510
you why but we build the test from

00:25:11,810 --> 00:25:16,550
source we put it over on the target we

00:25:14,510 --> 00:25:19,190
execute it collect the results back to

00:25:16,550 --> 00:25:21,200
the host analyze the results parse it

00:25:19,190 --> 00:25:28,310
and and then present it in the in the

00:25:21,200 --> 00:25:32,150
GUI interface so oh wait did I go the

00:25:28,310 --> 00:25:33,650
right direction oh yeah so like I said

00:25:32,150 --> 00:25:36,410
if I go test is usually a wrapper around

00:25:33,650 --> 00:25:39,200
an existing test some examples are like

00:25:36,410 --> 00:25:41,420
i/o zone LTP Bonney iperf dry stone

00:25:39,200 --> 00:25:44,420
cyclic test so the real-time test file

00:25:41,420 --> 00:25:46,250
system tests networking tests those are

00:25:44,420 --> 00:25:49,340
all existing tests that we just have

00:25:46,250 --> 00:25:51,320
wrappers for that kind of hooked allow

00:25:49,340 --> 00:25:53,480
you to hook those into our system so you

00:25:51,320 --> 00:25:56,240
can actually if you want to go out and

00:25:53,480 --> 00:25:58,010
write a new individual test you know

00:25:56,240 --> 00:26:02,240
something that you want to test on on

00:25:58,010 --> 00:26:04,100
Linux and put it into fuego and usually

00:26:02,240 --> 00:26:06,980
if it's simple enough you can actually

00:26:04,100 --> 00:26:08,630
put it in the Floyd go test shell script

00:26:06,980 --> 00:26:10,640
but a lot of times it's easiest and it's

00:26:08,630 --> 00:26:12,440
more clear if you you take the material

00:26:10,640 --> 00:26:14,240
that's going to run on target put it in

00:26:12,440 --> 00:26:16,510
a standalone shell script or a

00:26:14,240 --> 00:26:20,840
standalone native program and then

00:26:16,510 --> 00:26:22,850
launch it from from Fuego and then a

00:26:20,840 --> 00:26:24,890
test consists of like I said the spray

00:26:22,850 --> 00:26:26,690
go test shell and partial PI and then

00:26:24,890 --> 00:26:29,480
there's a bunch of other files that you

00:26:26,690 --> 00:26:33,950
may as you start to customize the test

00:26:29,480 --> 00:26:38,030
get into writing this is hello world in

00:26:33,950 --> 00:26:39,260
Fuego land it's very very simple we

00:26:38,030 --> 00:26:41,090
specify the

00:26:39,260 --> 00:26:43,250
our ball where you get the the hello

00:26:41,090 --> 00:26:48,170
world program from you can also have a

00:26:43,250 --> 00:26:49,730
get reference there and you do pre check

00:26:48,170 --> 00:26:51,860
to make sure that there's a variable to

00:26:49,730 --> 00:26:53,180
find this is the pre check function is

00:26:51,860 --> 00:26:54,410
where you would check for dependencies

00:26:53,180 --> 00:26:55,610
and there's a whole bunch of helper

00:26:54,410 --> 00:26:57,260
routines for checking different

00:26:55,610 --> 00:26:58,880
dependencies whether you need to be

00:26:57,260 --> 00:27:00,350
route if you have certain kernel configs

00:26:58,880 --> 00:27:01,640
that type of thing this one is checking

00:27:00,350 --> 00:27:05,030
to make sure that this variable is

00:27:01,640 --> 00:27:07,850
defined and then the build function is

00:27:05,030 --> 00:27:10,610
make hello world is doesn't need to be

00:27:07,850 --> 00:27:13,310
configured well new does but this this

00:27:10,610 --> 00:27:16,220
one is very simple hello world and the

00:27:13,310 --> 00:27:18,440
deploy function just uses put the put

00:27:16,220 --> 00:27:21,170
command put the hello onto the board and

00:27:18,440 --> 00:27:24,650
then we run it and we collect the

00:27:21,170 --> 00:27:26,630
results with the report function so

00:27:24,650 --> 00:27:32,240
we're gonna CD into that directory

00:27:26,630 --> 00:27:35,150
run hello and that's the first time I've

00:27:32,240 --> 00:27:38,450
noticed there's a typo in there hello

00:27:35,150 --> 00:27:41,360
and pass it that argument that that we

00:27:38,450 --> 00:27:42,770
checked for and then the results if I go

00:27:41,360 --> 00:27:44,330
collects the results for us and we do

00:27:42,770 --> 00:27:46,070
some log processing on it we're looking

00:27:44,330 --> 00:27:47,480
for the single word success this is not

00:27:46,070 --> 00:27:51,590
your standard hello world program it

00:27:47,480 --> 00:27:52,760
also prints at the end success so so

00:27:51,590 --> 00:27:54,370
it's very simple I mean you can

00:27:52,760 --> 00:27:58,130
understand what's going on here

00:27:54,370 --> 00:28:02,000
hopefully in terms of output every test

00:27:58,130 --> 00:28:05,030
in Fuego produces run JSON file so the

00:28:02,000 --> 00:28:08,030
test metadata the logs and the results

00:28:05,030 --> 00:28:10,250
are either referred to from this file or

00:28:08,030 --> 00:28:15,050
embedded in the file and then we have a

00:28:10,250 --> 00:28:18,380
result schema that's very much like LTP

00:28:15,050 --> 00:28:20,330
in terms of pass/fail error skip okay so

00:28:18,380 --> 00:28:21,740
why go advocacy this is the part where I

00:28:20,330 --> 00:28:25,730
convince you all the right way go tests

00:28:21,740 --> 00:28:28,610
actually not if you have don't write

00:28:25,730 --> 00:28:31,190
your device under test program in Fuego

00:28:28,610 --> 00:28:33,440
I mean I don't really care if you write

00:28:31,190 --> 00:28:36,170
a Fuego test actually I mean if you want

00:28:33,440 --> 00:28:39,470
to I'm not going to stop you but I'd

00:28:36,170 --> 00:28:43,790
rather if you have a new test put it in

00:28:39,470 --> 00:28:45,800
LTP or in case self test because way go

00:28:43,790 --> 00:28:48,350
runs both of those so I get it

00:28:45,800 --> 00:28:50,000
automatically and then you can use some

00:28:48,350 --> 00:28:51,190
of the helper functions and features of

00:28:50,000 --> 00:28:56,800
LTP or

00:28:51,190 --> 00:28:58,180
or or k self-test if however and the

00:28:56,800 --> 00:28:59,890
whole industry benefits not just the

00:28:58,180 --> 00:29:01,600
fuego community you know I should be I

00:28:59,890 --> 00:29:05,110
should be more dogmatic about driving

00:29:01,600 --> 00:29:06,160
people to Fuego but you know do do

00:29:05,110 --> 00:29:07,990
something that can be shared with the

00:29:06,160 --> 00:29:09,580
widest number of people we I will

00:29:07,990 --> 00:29:12,190
benefit if you write it to LTP so I

00:29:09,580 --> 00:29:13,540
don't I don't mind saying that if you

00:29:12,190 --> 00:29:14,950
are writing a multi node test though

00:29:13,540 --> 00:29:17,080
here's the problem that's where things

00:29:14,950 --> 00:29:20,310
start to fall down there is there are no

00:29:17,080 --> 00:29:23,830
standards for writing multi node tests

00:29:20,310 --> 00:29:25,900
so Fuego supports host client operations

00:29:23,830 --> 00:29:28,270
so we can do some multi node stuff so we

00:29:25,900 --> 00:29:29,380
have tests that do serial port assuming

00:29:28,270 --> 00:29:30,940
you have a serial connection to the

00:29:29,380 --> 00:29:33,910
target which a lot of times you do in

00:29:30,940 --> 00:29:35,320
your board farm configuration we can do

00:29:33,910 --> 00:29:37,300
Network obviously we have network

00:29:35,320 --> 00:29:38,410
connections to the target but if you're

00:29:37,300 --> 00:29:40,990
doing if you're doing things like

00:29:38,410 --> 00:29:43,600
testing audio or testing video output

00:29:40,990 --> 00:29:45,940
right that requires additional hardware

00:29:43,600 --> 00:29:48,970
that's capturing that or you're doing

00:29:45,940 --> 00:29:50,950
like USB testing you need to to toggle

00:29:48,970 --> 00:29:53,170
the USB bus to test connect and

00:29:50,950 --> 00:29:54,880
disconnect that requires hardware that's

00:29:53,170 --> 00:29:56,920
not there's no standard interface for

00:29:54,880 --> 00:29:58,840
that board control and this is something

00:29:56,920 --> 00:30:00,190
that's really lacking in the industry

00:29:58,840 --> 00:30:01,870
and something we've actually set up a

00:30:00,190 --> 00:30:04,140
mailing list based on discussions we had

00:30:01,870 --> 00:30:07,390
at embedded Linux conference Europe and

00:30:04,140 --> 00:30:10,420
we are trying to work through defining

00:30:07,390 --> 00:30:12,580
some of those standards and I'm hoping

00:30:10,420 --> 00:30:14,320
that you know so I put it on this page

00:30:12,580 --> 00:30:15,670
so it kind of commits me to doing this

00:30:14,320 --> 00:30:19,570
but I'm trying to put together a board

00:30:15,670 --> 00:30:20,890
control summit at plumbers next year to

00:30:19,570 --> 00:30:22,150
talk through a lot of these issues

00:30:20,890 --> 00:30:24,190
there's a lot of different groups to

00:30:22,150 --> 00:30:27,010
have different systems lava has their

00:30:24,190 --> 00:30:33,340
own system there's a group called lab

00:30:27,010 --> 00:30:34,510
grid can are for control anyway we'd

00:30:33,340 --> 00:30:36,850
like to get together and actually

00:30:34,510 --> 00:30:38,050
confirm this because multi node testing

00:30:36,850 --> 00:30:40,570
is kind of where it's at if you're going

00:30:38,050 --> 00:30:42,970
to test drivers well the drivers are are

00:30:40,570 --> 00:30:44,290
doing something you know you can test

00:30:42,970 --> 00:30:45,550
file system drivers because that's a

00:30:44,290 --> 00:30:48,040
local operation but most of the other

00:30:45,550 --> 00:30:50,350
drivers our bus drivers or you know

00:30:48,040 --> 00:30:51,670
panel drivers or things like that that

00:30:50,350 --> 00:30:53,050
are controlling hardware that you need

00:30:51,670 --> 00:30:56,260
to control remotely if you want to test

00:30:53,050 --> 00:30:58,540
it effectively okay if I go resources

00:30:56,260 --> 00:31:02,230
how am i doing on time oh no okay here's

00:30:58,540 --> 00:31:04,090
my scorecard I'll let you look through

00:31:02,230 --> 00:31:05,440
the scorecard at your leisure and decide

00:31:04,090 --> 00:31:08,920
which of these you want to you

00:31:05,440 --> 00:31:12,970
I already kind of gave you my my tips on

00:31:08,920 --> 00:31:15,100
this and in terms of choosing a

00:31:12,970 --> 00:31:16,750
framework if you're doing white box

00:31:15,100 --> 00:31:18,580
testing in the current Linux kernel I

00:31:16,750 --> 00:31:20,770
think you should use case self-test if

00:31:18,580 --> 00:31:25,450
you're doing black box functional

00:31:20,770 --> 00:31:28,480
testing of kernel behavior use LTP if

00:31:25,450 --> 00:31:30,340
you're doing benchmarks don't write your

00:31:28,480 --> 00:31:31,780
own go out and extend one of the

00:31:30,340 --> 00:31:34,210
existing ones there are there are

00:31:31,780 --> 00:31:37,810
benchmarks for basically every kind of

00:31:34,210 --> 00:31:39,760
category of stuff so you've got you know

00:31:37,810 --> 00:31:42,040
file system tests you got memory tests

00:31:39,760 --> 00:31:43,000
you have network tests so just go extend

00:31:42,040 --> 00:31:44,590
one of those or figure out how to

00:31:43,000 --> 00:31:46,360
customize it a lot of these tests have a

00:31:44,590 --> 00:31:48,250
ton of options and you just need to

00:31:46,360 --> 00:31:50,860
figure out you know which options do you

00:31:48,250 --> 00:31:52,990
pick to do the tests that you want to

00:31:50,860 --> 00:31:55,180
perform and then if you're doing dual

00:31:52,990 --> 00:31:56,650
machine tests of course UsWe go that's

00:31:55,180 --> 00:32:00,280
I'm going to get back on my head Fuuka

00:31:56,650 --> 00:32:02,560
seahorse because we do support host

00:32:00,280 --> 00:32:05,920
target operation and we're working on a

00:32:02,560 --> 00:32:08,470
control API okay so now the second half

00:32:05,920 --> 00:32:10,360
which is ostensibly the reason you all

00:32:08,470 --> 00:32:13,150
came which are my tips for good writing

00:32:10,360 --> 00:32:14,590
good tests okay so in four broad

00:32:13,150 --> 00:32:18,130
categories that I'm going to go into in

00:32:14,590 --> 00:32:21,610
detail produce good output make test

00:32:18,130 --> 00:32:24,150
Universal avoid false positives and for

00:32:21,610 --> 00:32:27,580
heaven's sake test something useful and

00:32:24,150 --> 00:32:29,920
I will now tell you how to do those so

00:32:27,580 --> 00:32:31,450
the six elements of good test output are

00:32:29,920 --> 00:32:33,700
intrinsically you want to have a test

00:32:31,450 --> 00:32:35,500
case identifier you want to have a

00:32:33,700 --> 00:32:38,950
description you want to actually have

00:32:35,500 --> 00:32:40,780
the result that's important it's nice if

00:32:38,950 --> 00:32:44,350
you can include the behavior what you

00:32:40,780 --> 00:32:46,480
expected versus what you saw a lot of

00:32:44,350 --> 00:32:48,970
tests leave that out right they just say

00:32:46,480 --> 00:32:50,530
all of that failed it's like well what

00:32:48,970 --> 00:32:54,430
failed now I got to go read your source

00:32:50,530 --> 00:32:57,540
to figure out and then if you can if you

00:32:54,430 --> 00:32:59,910
if you if you have a heart in your soul

00:32:57,540 --> 00:33:02,260
tell us how to interpret the results

00:32:59,910 --> 00:33:04,150
what does it mean if this doesn't work

00:33:02,260 --> 00:33:06,280
you know should I be worried about it or

00:33:04,150 --> 00:33:07,540
is this is like no big deal

00:33:06,280 --> 00:33:09,670
the other thing it's important to this

00:33:07,540 --> 00:33:12,850
in your output distinguish results from

00:33:09,670 --> 00:33:14,830
errors every if you've done testing

00:33:12,850 --> 00:33:17,890
before you know that things can go wrong

00:33:14,830 --> 00:33:18,970
besides what you were testing for right

00:33:17,890 --> 00:33:21,730
and so you need

00:33:18,970 --> 00:33:24,250
to distinguish that because if you if

00:33:21,730 --> 00:33:26,320
you if the network kind of Boches up in

00:33:24,250 --> 00:33:29,200
your test lab you know everything will

00:33:26,320 --> 00:33:31,929
go red across the board but that's not

00:33:29,200 --> 00:33:33,880
actually a failure right that's just an

00:33:31,929 --> 00:33:35,799
error okay so that's that's the

00:33:33,880 --> 00:33:38,409
nomenclature the nomenclature is a

00:33:35,799 --> 00:33:40,539
result of a test is pass or fail if

00:33:38,409 --> 00:33:42,250
something has gone horribly wrong that's

00:33:40,539 --> 00:33:45,340
unrelated to what your to the test

00:33:42,250 --> 00:33:46,390
that's an error and the all of the test

00:33:45,340 --> 00:33:48,850
harnesses that I'm familiar with

00:33:46,390 --> 00:33:51,159
distinguish those and and that's really

00:33:48,850 --> 00:33:53,380
important because you don't want to it's

00:33:51,159 --> 00:33:55,990
it's just confusing it happens all the

00:33:53,380 --> 00:33:58,659
time in fact my minnowboard just went

00:33:55,990 --> 00:34:00,159
down in the lab on Friday and and you

00:33:58,659 --> 00:34:02,799
know boards go down because I don't know

00:34:00,159 --> 00:34:05,260
flash wears out or network goes sideways

00:34:02,799 --> 00:34:07,090
or something and so I had you know I had

00:34:05,260 --> 00:34:09,250
a whole bunch of tests but luckily I

00:34:07,090 --> 00:34:11,530
could tell the difference between you

00:34:09,250 --> 00:34:14,349
know minnowboard being not reachable and

00:34:11,530 --> 00:34:17,889
you know open syscalls suddenly

00:34:14,349 --> 00:34:20,679
returning the wrong here no okay for

00:34:17,889 --> 00:34:23,440
test output make the test results

00:34:20,679 --> 00:34:26,139
machine parsable but human readable you

00:34:23,440 --> 00:34:28,149
want both of those attributes okay you

00:34:26,139 --> 00:34:29,770
should use unique strings for the test

00:34:28,149 --> 00:34:32,260
results outputs something that's not

00:34:29,770 --> 00:34:34,540
going to be a normal English word use

00:34:32,260 --> 00:34:38,560
that if you want

00:34:34,540 --> 00:34:41,859
we have words already use T pass okay

00:34:38,560 --> 00:34:44,560
don't or not okay which is the the tap

00:34:41,859 --> 00:34:47,800
one but use something standardized don't

00:34:44,560 --> 00:34:50,500
just you know say you know don't don't

00:34:47,800 --> 00:34:53,139
right right you know my open Cisco went

00:34:50,500 --> 00:34:55,810
sideways okay that's that's harder to

00:34:53,139 --> 00:34:58,930
grep for you want optimally you want to

00:34:55,810 --> 00:35:00,760
be able to grep for this stuff so you

00:34:58,930 --> 00:35:02,619
want unique strings for the results

00:35:00,760 --> 00:35:05,109
output you want a common result schema

00:35:02,619 --> 00:35:06,339
okay again you don't have to make up

00:35:05,109 --> 00:35:08,980
your own there are schemas out there

00:35:06,339 --> 00:35:10,330
just use one of the existing ones use

00:35:08,980 --> 00:35:11,619
unique and persistent test case

00:35:10,330 --> 00:35:14,170
identifiers I've got a whole slide on

00:35:11,619 --> 00:35:19,390
that I use line based output so you can

00:35:14,170 --> 00:35:20,800
grep it and the results exposition so a

00:35:19,390 --> 00:35:23,740
lot of times you want to explain what's

00:35:20,800 --> 00:35:26,200
going on with the test either put it all

00:35:23,740 --> 00:35:28,359
before the results or put it all after

00:35:26,200 --> 00:35:30,520
the result but for heaven's sake don't

00:35:28,359 --> 00:35:31,800
sprinkle it before and after results

00:35:30,520 --> 00:35:36,660
that is

00:35:31,800 --> 00:35:38,430
obnoxious to parse and in some in some

00:35:36,660 --> 00:35:40,800
cases it's impossible to parse right

00:35:38,430 --> 00:35:42,750
yeah the the parser has to understand

00:35:40,800 --> 00:35:45,390
all the possible strings you could be

00:35:42,750 --> 00:35:49,230
outputting so the general idea is that

00:35:45,390 --> 00:35:52,170
you want to use your result line as the

00:35:49,230 --> 00:35:53,700
marker between test cases so it's a

00:35:52,170 --> 00:35:55,110
unique enough string that you can

00:35:53,700 --> 00:35:57,930
identify when a test case says that

00:35:55,110 --> 00:35:59,940
either ended or started and use that to

00:35:57,930 --> 00:36:02,610
obtain the result this makes the parser

00:35:59,940 --> 00:36:04,200
so much easier okay we've had to write

00:36:02,610 --> 00:36:08,310
obnoxious parsers we don't like it

00:36:04,200 --> 00:36:11,220
please help us out okay test case

00:36:08,310 --> 00:36:15,410
identifier x' don't just use numbers the

00:36:11,220 --> 00:36:18,060
number of tests where you know it's like

00:36:15,410 --> 00:36:20,490
this happens a lot number of tests you

00:36:18,060 --> 00:36:25,050
see that where the result is you know

00:36:20,490 --> 00:36:27,810
one to one pass to pass three pass four

00:36:25,050 --> 00:36:30,450
fail five passed six pass it's like oh

00:36:27,810 --> 00:36:33,600
great five well that's helpful

00:36:30,450 --> 00:36:35,490
you have no idea a lot of times you'll

00:36:33,600 --> 00:36:39,420
get some exposition after that but if

00:36:35,490 --> 00:36:41,580
you if you have a test case identifier

00:36:39,420 --> 00:36:44,060
that is kind of human readable that's a

00:36:41,580 --> 00:36:48,240
real string and that is unique and

00:36:44,060 --> 00:36:50,670
persistent then you have what I call a

00:36:48,240 --> 00:36:52,800
teague wid a test globally unique

00:36:50,670 --> 00:36:54,810
identifier now what is what could

00:36:52,800 --> 00:36:57,180
possibly be valuable about that well the

00:36:54,810 --> 00:36:59,070
great the value in that is that now I

00:36:57,180 --> 00:37:01,020
can take my test results and I can

00:36:59,070 --> 00:37:03,930
compare them to yours on the other side

00:37:01,020 --> 00:37:06,840
of the planet right so if I want to find

00:37:03,930 --> 00:37:09,960
out why hypothetically not

00:37:06,840 --> 00:37:13,170
hypothetically at all I notify oh six

00:37:09,960 --> 00:37:15,060
kept rebooting my Beagle bone right then

00:37:13,170 --> 00:37:16,530
I can use that unique string and say hey

00:37:15,060 --> 00:37:19,020
someone over there with a beagle bone

00:37:16,530 --> 00:37:22,320
what what do you what does I notify l6

00:37:19,020 --> 00:37:24,480
do on yours and it turned out to be a

00:37:22,320 --> 00:37:27,300
sub case of I notify oh six that did

00:37:24,480 --> 00:37:29,580
that so the idea is to create

00:37:27,300 --> 00:37:32,040
essentially a namespace for these tests

00:37:29,580 --> 00:37:34,380
identifier that is global and unique and

00:37:32,040 --> 00:37:35,760
then we when as we share test results

00:37:34,380 --> 00:37:38,130
with each other we can actually collect

00:37:35,760 --> 00:37:39,420
data and find out the answers to our

00:37:38,130 --> 00:37:41,970
questions without having to run

00:37:39,420 --> 00:37:44,760
everything ourselves I don't know if I

00:37:41,970 --> 00:37:46,800
explained that very well but but

00:37:44,760 --> 00:37:49,100
this is this is one of my pet peeves

00:37:46,800 --> 00:37:52,020
please make sure that your that your

00:37:49,100 --> 00:37:54,270
identifiers are persistent and globally

00:37:52,020 --> 00:37:56,070
unique and string-based if you can I

00:37:54,270 --> 00:37:58,800
don't like numbers numbers daren't don't

00:37:56,070 --> 00:38:01,110
help your users find problems

00:37:58,800 --> 00:38:03,120
another thing about tests please make

00:38:01,110 --> 00:38:05,460
your tests universal and this means

00:38:03,120 --> 00:38:07,500
unfortunately they probably need to

00:38:05,460 --> 00:38:09,240
limit the languages used so you see

00:38:07,500 --> 00:38:11,760
tests written in Java you see tests

00:38:09,240 --> 00:38:13,800
written in Python well I can't use those

00:38:11,760 --> 00:38:15,030
on a lot of machines right if I don't

00:38:13,800 --> 00:38:18,300
have the Python interpreter I don't have

00:38:15,030 --> 00:38:20,730
Java so it really comes down to and this

00:38:18,300 --> 00:38:22,710
is what LTP kind of settled on

00:38:20,730 --> 00:38:24,360
although LTP has some exceptions some

00:38:22,710 --> 00:38:27,480
tests and Python you're either talking

00:38:24,360 --> 00:38:31,800
about a native program or a POSIX shell

00:38:27,480 --> 00:38:34,710
program okay no bash isms don't assume

00:38:31,800 --> 00:38:36,300
device under test capabilities and use

00:38:34,710 --> 00:38:38,340
minimal resources I don't expand on

00:38:36,300 --> 00:38:40,770
those so a compiled language almost

00:38:38,340 --> 00:38:42,600
everybody is writing their low-level

00:38:40,770 --> 00:38:46,380
tests in C that's the most common

00:38:42,600 --> 00:38:49,410
denominator I know it's it's 20 20 18

00:38:46,380 --> 00:38:51,060
you'd think we could get B on C but but

00:38:49,410 --> 00:38:53,760
that you just know that C is going to be

00:38:51,060 --> 00:38:55,890
supported on your board provide source

00:38:53,760 --> 00:38:57,510
not binaries do not provide binaries

00:38:55,890 --> 00:38:59,760
because we can't put that on other

00:38:57,510 --> 00:39:01,950
platforms make the source cross compile

00:38:59,760 --> 00:39:03,960
able don't discern assume the

00:39:01,950 --> 00:39:06,260
architecture is either 32 or 64-bit or

00:39:03,960 --> 00:39:08,610
anything else about the architecture

00:39:06,260 --> 00:39:11,640
statically link if possible to avoid

00:39:08,610 --> 00:39:13,080
dependencies on libraries in terms of

00:39:11,640 --> 00:39:16,350
the shell some of the things that you

00:39:13,080 --> 00:39:18,960
can do is use POSIX features onlys do

00:39:16,350 --> 00:39:22,050
not use bash isms there's actually a

00:39:18,960 --> 00:39:23,940
tool in Ubuntu you can install it it may

00:39:22,050 --> 00:39:27,300
it's probably already on your on your

00:39:23,940 --> 00:39:28,710
machine called check bash isms and it

00:39:27,300 --> 00:39:31,230
will give you it'll do a line-by-line

00:39:28,710 --> 00:39:35,520
analysis of your of your of a shell

00:39:31,230 --> 00:39:37,260
script and tell you what is not what is

00:39:35,520 --> 00:39:39,330
unsupported in the POSIX shell standard

00:39:37,260 --> 00:39:42,060
and then of course go get rid of those

00:39:39,330 --> 00:39:43,410
things because on these tiny tiny

00:39:42,060 --> 00:39:45,270
devices what are we all running we're

00:39:43,410 --> 00:39:47,040
either running busybox or toybox we

00:39:45,270 --> 00:39:50,370
don't have bash you know I'm not

00:39:47,040 --> 00:39:52,890
spending 800 K on some bash things and

00:39:50,370 --> 00:39:54,660
then if you have another interpreted

00:39:52,890 --> 00:39:55,890
language I'm not saying you can't do an

00:39:54,660 --> 00:39:57,990
interpreter language but if you have

00:39:55,890 --> 00:39:58,570
another interpreted language provide the

00:39:57,990 --> 00:40:00,820
VM for

00:39:58,570 --> 00:40:02,230
as part of your test okay so like if

00:40:00,820 --> 00:40:03,640
you're doing something lua or if you're

00:40:02,230 --> 00:40:05,980
doing Python maybe you can get away with

00:40:03,640 --> 00:40:08,920
having micro Python and just ship that

00:40:05,980 --> 00:40:10,690
over to the board with your test but you

00:40:08,920 --> 00:40:13,240
have to limit yourself in order to make

00:40:10,690 --> 00:40:14,950
it your test as widely applicable to

00:40:13,240 --> 00:40:17,770
every possible scenario as possible I'm

00:40:14,950 --> 00:40:20,080
actually I have a side project that I'm

00:40:17,770 --> 00:40:22,780
trying to see if I can get boy go to run

00:40:20,080 --> 00:40:28,210
on EDX right I want to run it on an on

00:40:22,780 --> 00:40:30,400
Linux POSIX ish OS and see how many of

00:40:28,210 --> 00:40:31,990
these tests can run there's some

00:40:30,400 --> 00:40:33,880
problems we have some dependencies on

00:40:31,990 --> 00:40:38,320
proc insist but we if we can get rid of

00:40:33,880 --> 00:40:40,600
those most of this stuff should work use

00:40:38,320 --> 00:40:42,970
minimal resources avoid dependencies on

00:40:40,600 --> 00:40:45,760
things you don't need for C programs you

00:40:42,970 --> 00:40:49,180
can limit the usage library calls use a

00:40:45,760 --> 00:40:50,620
POSIX subset and it depends of course on

00:40:49,180 --> 00:40:52,780
what you're testing if you're testing

00:40:50,620 --> 00:40:54,460
for font stuff you can't you know you

00:40:52,780 --> 00:40:57,130
got to test actually the font libraries

00:40:54,460 --> 00:41:00,880
but OS kit it turns out defines a good

00:40:57,130 --> 00:41:02,320
subset minimal C library subset you can

00:41:00,880 --> 00:41:05,920
ignore the weird parts of the memory

00:41:02,320 --> 00:41:09,310
allocator and on that resource but

00:41:05,920 --> 00:41:12,600
assume minimal OS features so for the

00:41:09,310 --> 00:41:17,710
size test that I wrote for K self tests

00:41:12,600 --> 00:41:19,450
it uses two sis calls which which I

00:41:17,710 --> 00:41:21,190
thought was important because that's the

00:41:19,450 --> 00:41:23,830
whole idea of size you might actually be

00:41:21,190 --> 00:41:25,840
eliminating most of your sis calls well

00:41:23,830 --> 00:41:32,410
3 I think because we used open read and

00:41:25,840 --> 00:41:34,210
there was one other one so so it's

00:41:32,410 --> 00:41:37,770
important not to assume that something

00:41:34,210 --> 00:41:39,730
is there to in order to make the test as

00:41:37,770 --> 00:41:42,460
runnable in as many places as possible

00:41:39,730 --> 00:41:43,930
for shell scripts the same applies

00:41:42,460 --> 00:41:45,640
except now you're talking instead of

00:41:43,930 --> 00:41:48,630
api's we're talking external commands so

00:41:45,640 --> 00:41:51,310
don't don't go using esoteric weird

00:41:48,630 --> 00:41:52,810
external commands this is my mech

00:41:51,310 --> 00:41:55,540
recommended minimum list this is the

00:41:52,810 --> 00:41:57,460
minimum list that Fuego has just about

00:41:55,540 --> 00:42:01,240
any busy box capable system is going to

00:41:57,460 --> 00:42:04,150
have these and then if you can limit the

00:42:01,240 --> 00:42:05,500
use of proc insists because someday

00:42:04,150 --> 00:42:09,150
maybe I want to run your tests on

00:42:05,500 --> 00:42:11,650
nedick's or a zephyr or something else

00:42:09,150 --> 00:42:12,310
the detect dependencies when you have

00:42:11,650 --> 00:42:14,590
dependency

00:42:12,310 --> 00:42:15,940
and you will have dependencies on

00:42:14,590 --> 00:42:17,980
something or other

00:42:15,940 --> 00:42:19,990
it's good idea to detect the detective

00:42:17,980 --> 00:42:21,640
dependency during the test don't just

00:42:19,990 --> 00:42:24,790
fall over because something's missing

00:42:21,640 --> 00:42:27,490
that you expected so that means you have

00:42:24,790 --> 00:42:29,500
to probe the system and hopefully abort

00:42:27,490 --> 00:42:32,349
early with a message don't just don't

00:42:29,500 --> 00:42:34,060
just exit it's much nicer to have some

00:42:32,349 --> 00:42:36,849
some message about what's going on or

00:42:34,060 --> 00:42:42,720
what's missing and this is the fourth

00:42:36,849 --> 00:42:48,310
part of the kind of a schema of results

00:42:42,720 --> 00:42:50,200
don't report pass or fail or error in

00:42:48,310 --> 00:42:52,920
this case if you're missing a dependency

00:42:50,200 --> 00:42:56,859
the industry standard is to report skip

00:42:52,920 --> 00:42:59,320
ok that's and so that is kind of an

00:42:56,859 --> 00:43:01,960
extra indicator that what happened was

00:42:59,320 --> 00:43:04,030
different than than expected so skip and

00:43:01,960 --> 00:43:05,500
they have a different name for it in LTP

00:43:04,030 --> 00:43:10,030
they call it t conf which is

00:43:05,500 --> 00:43:11,290
configuration error but basically you're

00:43:10,030 --> 00:43:13,930
skipping something because what you

00:43:11,290 --> 00:43:16,690
could wanted to test was not really

00:43:13,930 --> 00:43:18,640
available or not configured and then

00:43:16,690 --> 00:43:21,330
another thing with dependencies is allow

00:43:18,640 --> 00:43:23,230
the user to specify what tests to run

00:43:21,330 --> 00:43:25,030
sometimes if you know that there's a

00:43:23,230 --> 00:43:26,320
whole class of machines like say 32-bit

00:43:25,030 --> 00:43:28,510
machines that your test is not going to

00:43:26,320 --> 00:43:31,150
run on but the rest of your test case is

00:43:28,510 --> 00:43:34,720
valid well let the user select that and

00:43:31,150 --> 00:43:36,609
then and then so support skip lists or

00:43:34,720 --> 00:43:40,060
be able to auto handle skip lists is

00:43:36,609 --> 00:43:42,280
even the better case but don't make your

00:43:40,060 --> 00:43:47,260
test case identifier change but numeric

00:43:42,280 --> 00:43:49,810
values if you skip tests ok don't assume

00:43:47,260 --> 00:43:50,530
the capacity or speed of your device

00:43:49,810 --> 00:43:53,230
under test

00:43:50,530 --> 00:43:56,609
so don't hard-code loops or sizes we get

00:43:53,230 --> 00:43:59,170
a lot of test failures in Fuego because

00:43:56,609 --> 00:44:00,760
you know boards we're running on a wide

00:43:59,170 --> 00:44:02,800
range of boards we're running on boards

00:44:00,760 --> 00:44:05,550
that are only 100 megahertz boards that

00:44:02,800 --> 00:44:08,109
are gigahertz and we actually have

00:44:05,550 --> 00:44:10,660
surprisingly we have a lot of tests that

00:44:08,109 --> 00:44:11,950
fail or at least a couple that I can

00:44:10,660 --> 00:44:14,730
think of that fail because the board is

00:44:11,950 --> 00:44:16,630
too fast it goes so fast that the test

00:44:14,730 --> 00:44:20,589
assumes something has gone wrong and

00:44:16,630 --> 00:44:24,040
reports an error so try to automatically

00:44:20,589 --> 00:44:25,390
detect your loop sizes probe the

00:44:24,040 --> 00:44:27,130
capabilities

00:44:25,390 --> 00:44:28,810
consider doing a calibration run if you

00:44:27,130 --> 00:44:31,720
need to to figure out kind of what

00:44:28,810 --> 00:44:33,910
machine you're on and as a last resort

00:44:31,720 --> 00:44:35,260
so all of that is kind of the automatic

00:44:33,910 --> 00:44:37,480
way that's the user-friendly writer hood

00:44:35,260 --> 00:44:39,010
if you if you just can't get around it

00:44:37,480 --> 00:44:41,680
at least let the user specify on the

00:44:39,010 --> 00:44:44,620
command line and then and then they can

00:44:41,680 --> 00:44:46,210
control what kind of parameters so but

00:44:44,620 --> 00:44:48,580
test parameters are pain to deal with

00:44:46,210 --> 00:44:50,110
that increases that that decreases the

00:44:48,580 --> 00:44:53,980
usability of your test if you now have

00:44:50,110 --> 00:45:00,390
to know some command line option to run

00:44:53,980 --> 00:45:03,670
it so in terms of making tests reusable

00:45:00,390 --> 00:45:04,990
you want to you want to make tests so

00:45:03,670 --> 00:45:07,000
they can be used on lots of different

00:45:04,990 --> 00:45:08,650
things the the secret here is to

00:45:07,000 --> 00:45:11,830
parameterize your test what I just was

00:45:08,650 --> 00:45:15,910
talking about and also to allow for

00:45:11,830 --> 00:45:18,460
external results criteria okay and what

00:45:15,910 --> 00:45:20,140
does that mean well in the case of like

00:45:18,460 --> 00:45:23,890
LTP I was mentioning where you get a

00:45:20,140 --> 00:45:26,230
thousand fifty six passes and a whole

00:45:23,890 --> 00:45:27,940
bunch of fails well what will happen is

00:45:26,230 --> 00:45:29,830
if you submit that report back to your

00:45:27,940 --> 00:45:32,560
management your management's gonna say

00:45:29,830 --> 00:45:34,090
why are these tests failing what is you

00:45:32,560 --> 00:45:36,220
know we got to go fix that and it's like

00:45:34,090 --> 00:45:38,680
well some of those would probably don't

00:45:36,220 --> 00:45:40,390
need to fix they're either errors in our

00:45:38,680 --> 00:45:42,190
in our test system or they're just

00:45:40,390 --> 00:45:46,060
because the test was written badly and

00:45:42,190 --> 00:45:48,760
so when you run these huge systems you

00:45:46,060 --> 00:45:50,560
want to have a way to specify we I don't

00:45:48,760 --> 00:45:54,430
basically I don't care about some of the

00:45:50,560 --> 00:45:56,530
results let's see and in the case of

00:45:54,430 --> 00:45:58,570
benchmarks every benchmark is gonna

00:45:56,530 --> 00:46:00,700
depend on your board and on the flash

00:45:58,570 --> 00:46:02,140
you chose and on the network hardware

00:46:00,700 --> 00:46:03,970
that you've got on there so the

00:46:02,140 --> 00:46:05,470
benchmarks have to be customized if

00:46:03,970 --> 00:46:07,210
you're if you're doing pass or fail on

00:46:05,470 --> 00:46:09,630
the benchmarks you have to allow the

00:46:07,210 --> 00:46:13,180
user to specify what the threshold is

00:46:09,630 --> 00:46:15,360
for success or failure and Fuego Fuego

00:46:13,180 --> 00:46:18,580
does that through the criteria JSON file

00:46:15,360 --> 00:46:21,700
okay so parameterize intest if you're

00:46:18,580 --> 00:46:23,800
going to do it this should not be used

00:46:21,700 --> 00:46:26,950
this allows people to adapt your test

00:46:23,800 --> 00:46:31,560
usually done through command lines try

00:46:26,950 --> 00:46:31,560
not to use environment variables because

00:46:32,490 --> 00:46:36,490
just I won't go into the details because

00:46:35,410 --> 00:46:37,590
I'm running out of time here I've got

00:46:36,490 --> 00:46:39,210
one more minute

00:46:37,590 --> 00:46:41,580
but don't use environment values

00:46:39,210 --> 00:46:48,410
command-line arguments and document your

00:46:41,580 --> 00:46:52,110
parameters so this is all kind of vyas

00:46:48,410 --> 00:46:53,640
test automation you should try to try to

00:46:52,110 --> 00:46:57,230
make a test that's automatable use

00:46:53,640 --> 00:46:58,530
standard build tropes make stuff

00:46:57,230 --> 00:47:04,460
deterministic

00:46:58,530 --> 00:47:07,380
let's see digit okay test robustness

00:47:04,460 --> 00:47:09,630
this is basically just talking about if

00:47:07,380 --> 00:47:10,800
you're making a robust test what are

00:47:09,630 --> 00:47:13,500
some of the things I just talked about

00:47:10,800 --> 00:47:16,170
that help make a test robust checking

00:47:13,500 --> 00:47:19,590
for dependencies creating the needed

00:47:16,170 --> 00:47:21,060
resources at the test time and then

00:47:19,590 --> 00:47:23,570
tuning for the device under test

00:47:21,060 --> 00:47:26,070
capabilities handling errors gracefully

00:47:23,570 --> 00:47:28,710
and then finally test something useful

00:47:26,070 --> 00:47:30,420
is the last idea really and I promise

00:47:28,710 --> 00:47:32,630
well I was gonna promise I'm not going

00:47:30,420 --> 00:47:36,630
to go over but I that ship has sailed

00:47:32,630 --> 00:47:38,820
so the idea here is test behavior that

00:47:36,630 --> 00:47:41,100
your program relies on that is stuff

00:47:38,820 --> 00:47:43,560
that would break if your break your app

00:47:41,100 --> 00:47:45,150
if it changed okay so if you're relying

00:47:43,560 --> 00:47:49,890
on some behavior of the kernel a

00:47:45,150 --> 00:47:52,530
sisyphus file path or you know the way

00:47:49,890 --> 00:47:55,110
this call behaves or the way a library

00:47:52,530 --> 00:47:56,430
behaves tests that don't just blindly go

00:47:55,110 --> 00:47:57,870
into the specs this is one of the

00:47:56,430 --> 00:47:59,160
problems that plagued LTP is they

00:47:57,870 --> 00:48:00,690
blindly went into the specs and they

00:47:59,160 --> 00:48:04,770
tested and just like every arrow in

00:48:00,690 --> 00:48:06,630
there and if you test behavior that you

00:48:04,770 --> 00:48:11,430
don't rely on it just mean it just means

00:48:06,630 --> 00:48:13,050
that the kernel now has to adhere to

00:48:11,430 --> 00:48:15,750
that behavior even though nobody relies

00:48:13,050 --> 00:48:18,420
on it so instead of reading the kernel

00:48:15,750 --> 00:48:20,040
code or reading the specs in order to

00:48:18,420 --> 00:48:21,990
figure out what you want to test you

00:48:20,040 --> 00:48:24,960
shouldn't be reading your own code so

00:48:21,990 --> 00:48:26,610
see what your code relies on and then

00:48:24,960 --> 00:48:28,140
test for that make the test for that and

00:48:26,610 --> 00:48:29,730
then the other thing the other major

00:48:28,140 --> 00:48:34,860
category of tests is things that you

00:48:29,730 --> 00:48:36,900
know broke it's kind of well it things

00:48:34,860 --> 00:48:39,570
things that have broken in the past are

00:48:36,900 --> 00:48:41,670
more likely to break in the future

00:48:39,570 --> 00:48:43,080
so if you create regression tests every

00:48:41,670 --> 00:48:44,370
time a fix goes into the kernel if you

00:48:43,080 --> 00:48:48,240
create a regression test for that that's

00:48:44,370 --> 00:48:50,820
that's something that's valuable final

00:48:48,240 --> 00:48:51,579
thing this is not the final good use CLI

00:48:50,820 --> 00:48:53,589
test if you

00:48:51,579 --> 00:48:54,999
ever use this for shell shell script

00:48:53,589 --> 00:48:56,920
testing it's a really handy little tool

00:48:54,999 --> 00:48:59,589
we use it employee go in a couple of

00:48:56,920 --> 00:49:02,709
places you have to look at the slides to

00:48:59,589 --> 00:49:06,160
get it and then okay I think this is my

00:49:02,709 --> 00:49:09,819
final slide yes okay go back there

00:49:06,160 --> 00:49:11,410
so my advice this is hopefully there's

00:49:09,819 --> 00:49:13,739
been some useful tips in here

00:49:11,410 --> 00:49:16,029
sorry I've gone by this stuff so fast

00:49:13,739 --> 00:49:18,700
but if you have questions you can ask me

00:49:16,029 --> 00:49:21,029
afterwards if you're writing new

00:49:18,700 --> 00:49:23,589
functional tests please do it in LTP

00:49:21,029 --> 00:49:25,359
they have a good test library the build

00:49:23,589 --> 00:49:26,619
system gets you cross compilation for

00:49:25,359 --> 00:49:30,039
free they have a consistent output

00:49:26,619 --> 00:49:31,599
schema and there's many many harnesses

00:49:30,039 --> 00:49:34,660
that already know how to run LTP and

00:49:31,599 --> 00:49:37,599
visualize the results including Fuego if

00:49:34,660 --> 00:49:40,150
you have an existing test please publish

00:49:37,599 --> 00:49:43,989
it okay put it out on github somewhere

00:49:40,150 --> 00:49:45,999
and then add Fuego advil wrapper for

00:49:43,989 --> 00:49:47,920
that test and then anybody who runs way

00:49:45,999 --> 00:49:49,269
we can do it boy who can handle some of

00:49:47,920 --> 00:49:51,430
the dirty work for you we can automate

00:49:49,269 --> 00:49:53,349
it we can document it we can make the

00:49:51,430 --> 00:49:57,069
results shareable provide visualization

00:49:53,349 --> 00:49:59,619
for it personally I'd love to seek a

00:49:57,069 --> 00:50:01,359
self test develop a little bit more and

00:49:59,619 --> 00:50:03,190
I'd love to see them actually adopt the

00:50:01,359 --> 00:50:05,640
ltp test library so there's not kind of

00:50:03,190 --> 00:50:08,079
a schism in the in the ecosystem and

00:50:05,640 --> 00:50:09,489
finally we need board standards and so

00:50:08,079 --> 00:50:11,709
that's actually gonna be my focus the

00:50:09,489 --> 00:50:13,599
next maybe well I don't know how long

00:50:11,709 --> 00:50:15,959
it'll take but I'm putting some energy

00:50:13,599 --> 00:50:19,839
into that to try to make that happen so

00:50:15,959 --> 00:50:21,819
with that go forth and test and please

00:50:19,839 --> 00:50:22,869
share your tests and I'm sorry we don't

00:50:21,819 --> 00:50:24,340
have time for questions but thank you

00:50:22,869 --> 00:50:30,320
very much for your time

00:50:24,340 --> 00:50:30,320

YouTube URL: https://www.youtube.com/watch?v=NzJFwCUGJtc


