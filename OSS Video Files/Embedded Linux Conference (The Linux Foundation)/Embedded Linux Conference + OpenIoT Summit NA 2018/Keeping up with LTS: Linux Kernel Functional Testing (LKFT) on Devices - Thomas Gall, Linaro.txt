Title: Keeping up with LTS: Linux Kernel Functional Testing (LKFT) on Devices - Thomas Gall, Linaro
Publication date: 2018-03-13
Playlist: Embedded Linux Conference + OpenIoT Summit NA 2018
Description: 
	Keeping up with LTS: Linux Kernel Functional Testing (LKFT) on Devices - Thomas Gall, Linaro

Long Term Support (LTS) Linux kernels are great to use in devices because a continuous stream of fixes is available for an extended period of time. (2-6 years typically) The Android Open Source Project (AOSP) aggressively keeps up with LTS fixes for 4.4, 4.9 and 4.14.

The community has boot testing in kernelci, and x86 testing using zero-day, but there was a gap in testing on embedded devices. Our goal is to catch regressions as quickly as possible during the LTS RC test cycle, and increase confidence that consumer devices are able to upgrade to the latest LTS.

This talk will cover:
- Linux Kernel Functional Test (LKFT)
- Infrastructure in use
- Experiences with devices and complicated test suites
- Experiences with tracking LTS, triaging bugs and regressions, and communities that could benefit
- How to get involved

About Thomas Gall
Tom's Linux experience started by sacrificing a pile of OS/2 install floppies to install SLS. Tom worked for IBM's Linux Technology Center before joining Linaro. As director of the Linaro Mobile Group, he oversees collaborative engineering involving Android and the Linux Kernel by a wide range of SoC vendors, handset vendors and Google.
Captions: 
	00:00:00,000 --> 00:00:03,870
all right well why don't we go ahead and

00:00:01,260 --> 00:00:06,180
get started so thanks everybody for for

00:00:03,870 --> 00:00:10,440
coming today so this is the Keeping Up

00:00:06,180 --> 00:00:12,809
with LTS Linux kernel functional testing

00:00:10,440 --> 00:00:15,450
on devices and just to introduce myself

00:00:12,809 --> 00:00:17,510
quickly my name is Tom gall I'm the

00:00:15,450 --> 00:00:20,699
director of the Lonardo mobile group and

00:00:17,510 --> 00:00:22,949
so what I want to just kind of start to

00:00:20,699 --> 00:00:25,080
talk off very very quickly touching on a

00:00:22,949 --> 00:00:27,060
little bit about what is Lennar oh and

00:00:25,080 --> 00:00:28,439
sort of who we are so we're sort of like

00:00:27,060 --> 00:00:29,609
a consortium of companies that get

00:00:28,439 --> 00:00:32,369
together and we do collaborative

00:00:29,609 --> 00:00:33,660
engineering so kind of the idea with

00:00:32,369 --> 00:00:35,579
Lennar o is you have these member

00:00:33,660 --> 00:00:37,829
companies they basically decide hey this

00:00:35,579 --> 00:00:40,170
is a priority in the open source world

00:00:37,829 --> 00:00:41,790
we they throw in some of their employees

00:00:40,170 --> 00:00:43,350
we have some of our own are our

00:00:41,790 --> 00:00:45,000
employees and we work on various

00:00:43,350 --> 00:00:47,700
projects and kind of solve problems if

00:00:45,000 --> 00:00:49,890
you will we're primarily involved with

00:00:47,700 --> 00:00:53,879
the the arm ecosystem that's really our

00:00:49,890 --> 00:00:56,489
big area focus but we work all across a

00:00:53,879 --> 00:00:58,920
wide variety of open-source projects and

00:00:56,489 --> 00:01:01,170
so that's everything from you know Linux

00:00:58,920 --> 00:01:03,809
kernel as you don't expect in Android

00:01:01,170 --> 00:01:05,729
and you know kind of the the smaller

00:01:03,809 --> 00:01:07,920
name stuff - that would be strategic

00:01:05,729 --> 00:01:10,100
towards torus various kinds of things

00:01:07,920 --> 00:01:12,450
and so this particular project here and

00:01:10,100 --> 00:01:14,509
what I'm going to talk about is lkf T

00:01:12,450 --> 00:01:16,259
and something called project sharp and

00:01:14,509 --> 00:01:18,960
starting out with a little bit of the

00:01:16,259 --> 00:01:20,369
background information so when it comes

00:01:18,960 --> 00:01:21,540
to Linux kernel on devices and

00:01:20,369 --> 00:01:23,430
specifically I'm going to talk about the

00:01:21,540 --> 00:01:24,990
Android space in particular of course

00:01:23,430 --> 00:01:27,270
we've got the Android common kernel and

00:01:24,990 --> 00:01:30,360
the Android common kernel these days

00:01:27,270 --> 00:01:32,070
largely tracks - LTS kernel releases so

00:01:30,360 --> 00:01:34,700
that's four four four nine and now four

00:01:32,070 --> 00:01:37,590
fourteen it also tracks mainline as well

00:01:34,700 --> 00:01:39,960
and so upstream of that of course you've

00:01:37,590 --> 00:01:41,670
got the the LTS community which is

00:01:39,960 --> 00:01:46,200
working on everything from the current

00:01:41,670 --> 00:01:48,509
415 stable to the for for long term and

00:01:46,200 --> 00:01:50,100
then of course mainline itself and and

00:01:48,509 --> 00:01:51,630
Linux next it's stuff so you haven't up

00:01:50,100 --> 00:01:53,820
having these you know sort of almost

00:01:51,630 --> 00:01:55,920
waterfall of past kernels that are still

00:01:53,820 --> 00:01:58,290
getting fixes applied to them in there

00:01:55,920 --> 00:01:59,670
LTS versions as well as the main line

00:01:58,290 --> 00:02:03,390
which of course is everybody's main

00:01:59,670 --> 00:02:06,119
focus so all that said if you go and you

00:02:03,390 --> 00:02:08,640
take a look at Android devices today so

00:02:06,119 --> 00:02:11,039
I've got a couple of screenshots here

00:02:08,640 --> 00:02:12,690
from a couple of devices and I'm not

00:02:11,039 --> 00:02:13,200
going to name names or shame anybody

00:02:12,690 --> 00:02:15,660
that's

00:02:13,200 --> 00:02:17,730
not the purpose of the talk but one of

00:02:15,660 --> 00:02:21,269
these and it's bit of an eye test is

00:02:17,730 --> 00:02:23,220
running a 4.4 13 kernel and if you look

00:02:21,269 --> 00:02:29,480
really really closely they built that

00:02:23,220 --> 00:02:32,130
kernel on January 25th of this year so

00:02:29,480 --> 00:02:35,310
413 if you don't remember came out on

00:02:32,130 --> 00:02:36,870
June 8th of 2016 that was a long time

00:02:35,310 --> 00:02:38,160
ago now certainly you know this is a

00:02:36,870 --> 00:02:39,840
responsible company they've been

00:02:38,160 --> 00:02:41,910
cherry-picking you know security fixes

00:02:39,840 --> 00:02:45,720
and and pulling down some things which

00:02:41,910 --> 00:02:52,290
are relevant but they've left a lot of

00:02:45,720 --> 00:02:53,970
the LTS fixes behind that's that's not

00:02:52,290 --> 00:02:56,940
great news now the other one here is is

00:02:53,970 --> 00:02:58,650
better it's a four 478 but still that's

00:02:56,940 --> 00:03:01,769
all going all the way back to Jan and

00:02:58,650 --> 00:03:04,019
our June July 21st of 2017 so that's

00:03:01,769 --> 00:03:07,019
almost nine months ago that's still

00:03:04,019 --> 00:03:09,450
missing you know nine months of LTS

00:03:07,019 --> 00:03:12,269
fixes and the thing about LTS in

00:03:09,450 --> 00:03:16,110
particular is the LTS project long-term

00:03:12,269 --> 00:03:19,500
support project it doesn't do anything

00:03:16,110 --> 00:03:20,850
to label security fixes so if there's a

00:03:19,500 --> 00:03:22,560
search or something like that sure you

00:03:20,850 --> 00:03:24,840
know that's that's an obvious thing but

00:03:22,560 --> 00:03:27,299
there can be fixes that go into LTS that

00:03:24,840 --> 00:03:29,489
it fixes a security issue it also fixes

00:03:27,299 --> 00:03:31,650
a bug and it may not be labeled as such

00:03:29,489 --> 00:03:33,690
so unless you're really really smart and

00:03:31,650 --> 00:03:36,389
picking up some of that stuff you can be

00:03:33,690 --> 00:03:38,069
missing things the other thing that's

00:03:36,389 --> 00:03:41,040
very important to keep in mind is when

00:03:38,069 --> 00:03:44,459
LTS as a project releases it doesn't

00:03:41,040 --> 00:03:49,590
test anything but all of the patches

00:03:44,459 --> 00:03:53,790
included in one you know one one tarball

00:03:49,590 --> 00:03:54,870
as of one release it doesn't test

00:03:53,790 --> 00:03:56,760
anything having to do with cherry

00:03:54,870 --> 00:04:00,030
picking so when you're taking a patch

00:03:56,760 --> 00:04:01,889
out of the context of LTS you're really

00:04:00,030 --> 00:04:03,599
losing out on all of the testing that's

00:04:01,889 --> 00:04:04,709
gone in and around the kernel

00:04:03,599 --> 00:04:07,680
engineering that's happened for that

00:04:04,709 --> 00:04:11,010
particular patch so you know that's

00:04:07,680 --> 00:04:12,840
that's an area of risk okay so all that

00:04:11,010 --> 00:04:14,069
said let's get into now kind of the

00:04:12,840 --> 00:04:15,120
point of the project and what I really

00:04:14,069 --> 00:04:16,829
want to talk about today and that's

00:04:15,120 --> 00:04:19,919
something called project sharp and

00:04:16,829 --> 00:04:22,650
something called L kft and the goal of

00:04:19,919 --> 00:04:24,990
these two activities together is to

00:04:22,650 --> 00:04:26,030
catch kernel regressions what we want to

00:04:24,990 --> 00:04:28,820
do is

00:04:26,030 --> 00:04:30,950
the architectures that are using LTS

00:04:28,820 --> 00:04:32,630
kernels and then their direct down

00:04:30,950 --> 00:04:36,290
streams like the Android common kernel

00:04:32,630 --> 00:04:39,860
is essentially make a promise to say

00:04:36,290 --> 00:04:42,560
that we're not breaking the kernel we're

00:04:39,860 --> 00:04:44,750
not introducing any regressions and that

00:04:42,560 --> 00:04:47,630
that kernel is just as good as the prior

00:04:44,750 --> 00:04:50,060
LTS release so this goes across four

00:04:47,630 --> 00:04:52,910
four four nine for 14 current stable

00:04:50,060 --> 00:04:55,730
mainline that we want to be vigilant and

00:04:52,910 --> 00:04:57,889
watching for for regressions it also

00:04:55,730 --> 00:04:59,930
spans architectures so while Lonardo is

00:04:57,889 --> 00:05:02,780
primarily interested in arm architecture

00:04:59,930 --> 00:05:05,480
we knew and we took on this project that

00:05:02,780 --> 00:05:06,830
we couldn't just test on arm to be you

00:05:05,480 --> 00:05:07,970
know to be taken seriously and what we

00:05:06,830 --> 00:05:09,980
were trying to do we also have to

00:05:07,970 --> 00:05:12,800
include x86 and we also have to be open

00:05:09,980 --> 00:05:15,890
to other architectures as well and you

00:05:12,800 --> 00:05:18,530
know this project is essentially it was

00:05:15,890 --> 00:05:20,150
slide where one year ago so in this past

00:05:18,530 --> 00:05:21,650
year and you know what I'm going to be

00:05:20,150 --> 00:05:24,889
talking about is what's been an

00:05:21,650 --> 00:05:26,479
accomplished in that period of time the

00:05:24,889 --> 00:05:29,180
other thing that we've we know is very

00:05:26,479 --> 00:05:33,350
important to is the use of compilers now

00:05:29,180 --> 00:05:35,960
in you know for the most part across the

00:05:33,350 --> 00:05:37,820
the Linux universe you know GCC is the

00:05:35,960 --> 00:05:40,760
reigning king compiler that's used but

00:05:37,820 --> 00:05:42,740
in the Android space as it turns out the

00:05:40,760 --> 00:05:44,810
switch over to clang has begun quite a

00:05:42,740 --> 00:05:46,370
while ago for applications and now it's

00:05:44,810 --> 00:05:48,530
happening for kernel development as well

00:05:46,370 --> 00:05:50,479
so when it comes to finding kernel

00:05:48,530 --> 00:05:52,370
regressions we need to take into account

00:05:50,479 --> 00:05:54,410
multiple different kernel or multiple

00:05:52,370 --> 00:05:56,660
different compiler versions as well as

00:05:54,410 --> 00:05:59,930
multiple different compilers themselves

00:05:56,660 --> 00:06:01,760
between clang and GCC the other thing

00:05:59,930 --> 00:06:05,840
that we set as a goal is we have to keep

00:06:01,760 --> 00:06:09,080
up with the LTS community as a project

00:06:05,840 --> 00:06:10,580
and so what will happen is is when an RC

00:06:09,080 --> 00:06:13,010
gets introduced so this is a set of

00:06:10,580 --> 00:06:16,370
candidate patches that will constitute

00:06:13,010 --> 00:06:19,220
the next LTS release we basically have

00:06:16,370 --> 00:06:20,870
about a 48-hour window to pick up all of

00:06:19,220 --> 00:06:22,640
those patches build them for all the

00:06:20,870 --> 00:06:25,100
architecture and OS combinations that

00:06:22,640 --> 00:06:27,800
we're going to test submit those tests

00:06:25,100 --> 00:06:31,070
get the results and then do some level

00:06:27,800 --> 00:06:33,979
of initial triage on the data that comes

00:06:31,070 --> 00:06:36,890
back and if there are issues we need to

00:06:33,979 --> 00:06:38,780
have you know a pretty bright line to

00:06:36,890 --> 00:06:39,600
report where the regression is to be

00:06:38,780 --> 00:06:42,600
effective

00:06:39,600 --> 00:06:46,260
in the LDS community so--that's was a

00:06:42,600 --> 00:06:48,750
very key thing that we needed to do now

00:06:46,260 --> 00:06:52,260
by taking on this kind of activity what

00:06:48,750 --> 00:06:54,600
this does is this helps make LTS kernels

00:06:52,260 --> 00:06:56,130
you know I'd like to use the word more

00:06:54,600 --> 00:06:58,040
viable but it also makes them you know

00:06:56,130 --> 00:07:00,780
real more realistic for long-term

00:06:58,040 --> 00:07:02,970
projects and products and those kinds of

00:07:00,780 --> 00:07:07,560
things so you know there's been a bit of

00:07:02,970 --> 00:07:09,120
trade press stories about the 4/4 LTS

00:07:07,560 --> 00:07:11,700
kernel lasting for six years

00:07:09,120 --> 00:07:13,410
we don't want to see that just for the

00:07:11,700 --> 00:07:15,300
for for kernel we also want to see that

00:07:13,410 --> 00:07:17,580
for for nine we also want to see that

00:07:15,300 --> 00:07:19,920
for 14 so that when you have a company

00:07:17,580 --> 00:07:22,170
that is you know they're putting out a

00:07:19,920 --> 00:07:23,970
phone or something else in this space

00:07:22,170 --> 00:07:26,250
they know that they're gonna they can

00:07:23,970 --> 00:07:28,500
rely on a fixed stream for any one of

00:07:26,250 --> 00:07:32,240
those kernel LTS kernel releases to be

00:07:28,500 --> 00:07:35,910
around and seeing fixes for some time

00:07:32,240 --> 00:07:38,460
okay and then when you have a set of

00:07:35,910 --> 00:07:41,400
data that's coming from the the testing

00:07:38,460 --> 00:07:43,080
activity the other thing that we need to

00:07:41,400 --> 00:07:44,430
do is a project you know as I kind of

00:07:43,080 --> 00:07:46,170
alluded to earlier we need to be able to

00:07:44,430 --> 00:07:47,850
triage that data and we want to keep

00:07:46,170 --> 00:07:49,170
track of that data for historical

00:07:47,850 --> 00:07:51,660
purposes and we'll see why in a minute

00:07:49,170 --> 00:07:54,780
why that's interesting and important and

00:07:51,660 --> 00:07:56,970
empowering for developers but it also

00:07:54,780 --> 00:08:00,480
means that we ourselves have to at a

00:07:56,970 --> 00:08:02,010
minimum do the triage we have to sign

00:08:00,480 --> 00:08:05,400
ourselves up for that on a week-to-week

00:08:02,010 --> 00:08:07,050
basis and while we may be looking for

00:08:05,400 --> 00:08:11,250
help from the community we know that we

00:08:07,050 --> 00:08:13,830
may or may not get it okay now as with

00:08:11,250 --> 00:08:15,750
science you know there's the common

00:08:13,830 --> 00:08:18,030
saying you've probably heard where we

00:08:15,750 --> 00:08:20,580
all stand on the solder on the shoulders

00:08:18,030 --> 00:08:22,140
of giants and there are numerous other

00:08:20,580 --> 00:08:23,550
you know kind of kernel testing

00:08:22,140 --> 00:08:26,580
activities that are out there so when we

00:08:23,550 --> 00:08:28,980
started KL l kft one of the things that

00:08:26,580 --> 00:08:30,930
we had to ask ourselves is do we start

00:08:28,980 --> 00:08:33,719
from Colonel CI do we build that

00:08:30,930 --> 00:08:35,460
capability in kernel CI or do we start

00:08:33,719 --> 00:08:37,800
with something new we're you know kind

00:08:35,460 --> 00:08:39,360
of a set of pieces are we gonna do so we

00:08:37,800 --> 00:08:41,789
kind of had to go through this initial

00:08:39,360 --> 00:08:43,229
sort of exercise as far as what was the

00:08:41,789 --> 00:08:45,600
right thing to get the project off the

00:08:43,229 --> 00:08:47,250
ground get results and be effective as

00:08:45,600 --> 00:08:49,230
quickly as possible and so for us

00:08:47,250 --> 00:08:51,630
unfortunately that meant that we need to

00:08:49,230 --> 00:08:52,710
do we needed to do an initial sort of

00:08:51,630 --> 00:08:54,960
break from kernel

00:08:52,710 --> 00:08:56,490
but knew that going on in the future

00:08:54,960 --> 00:08:57,840
that we initially wanted these two

00:08:56,490 --> 00:08:59,580
projects to kind of come back together

00:08:57,840 --> 00:09:02,190
again at some point in time has that

00:08:59,580 --> 00:09:04,890
made sense so colonel CI for those who

00:09:02,190 --> 00:09:06,360
may not be fully up to speed on what

00:09:04,890 --> 00:09:10,020
that does primarily what they're doing

00:09:06,360 --> 00:09:11,610
is is they're doing boot testing and you

00:09:10,020 --> 00:09:13,380
know so they have a minimal amount of

00:09:11,610 --> 00:09:14,550
user space or operating system that is

00:09:13,380 --> 00:09:16,650
sitting on top of the kernels that

00:09:14,550 --> 00:09:18,710
they're testing now they have gone so

00:09:16,650 --> 00:09:21,230
far as to start to enable case self-test

00:09:18,710 --> 00:09:23,400
but when we're running our test Suites

00:09:21,230 --> 00:09:25,730
like LTP and stuff like that these are

00:09:23,400 --> 00:09:28,260
things that tend to have a lot of

00:09:25,730 --> 00:09:30,000
software requirements in order to run so

00:09:28,260 --> 00:09:31,620
that means we need a substantial OS

00:09:30,000 --> 00:09:34,530
that's going to be able to support those

00:09:31,620 --> 00:09:36,930
test suites and and be able to to work

00:09:34,530 --> 00:09:42,390
efficiently as opposed to something when

00:09:36,930 --> 00:09:44,160
kernel CI which is fairly cut-down the

00:09:42,390 --> 00:09:46,230
other thing about kernel CI is of course

00:09:44,160 --> 00:09:47,880
it is a community and so they have

00:09:46,230 --> 00:09:50,850
community driven goals at community

00:09:47,880 --> 00:09:52,620
driven consensus and for us we wanted to

00:09:50,850 --> 00:09:55,230
just hit the ground running as quickly

00:09:52,620 --> 00:09:57,090
as possible so we figured if we were

00:09:55,230 --> 00:09:58,470
gonna be working through kernel CI we

00:09:57,090 --> 00:09:59,880
might have a little bit of a slower

00:09:58,470 --> 00:10:01,770
track and maybe that was the wrong

00:09:59,880 --> 00:10:03,540
assumption on our part but that was

00:10:01,770 --> 00:10:06,000
something that was a bit of a concern

00:10:03,540 --> 00:10:08,010
for us another thing that was important

00:10:06,000 --> 00:10:10,710
to us as well was the hardware side of

00:10:08,010 --> 00:10:13,140
things so kernel CI has a very vast set

00:10:10,710 --> 00:10:15,900
of boards within their farms they really

00:10:13,140 --> 00:10:18,960
have a very incredible amount of

00:10:15,900 --> 00:10:21,690
hardware at their beck and call we knew

00:10:18,960 --> 00:10:23,640
because of what we wanted to test and

00:10:21,690 --> 00:10:25,620
how we wanted to test and the operating

00:10:23,640 --> 00:10:28,560
systems involved that it was probably

00:10:25,620 --> 00:10:30,360
gonna be a small subset of boards and so

00:10:28,560 --> 00:10:34,530
again that's a little bit different than

00:10:30,360 --> 00:10:36,990
what kernel CI does okay so moving quiet

00:10:34,530 --> 00:10:38,430
along then so lkf T and I'm not going to

00:10:36,990 --> 00:10:39,720
read read this chart here but it's

00:10:38,430 --> 00:10:42,210
certainly available on the slides that

00:10:39,720 --> 00:10:45,480
are attached with the attach to the

00:10:42,210 --> 00:10:47,580
schedule is we really wanted to make

00:10:45,480 --> 00:10:49,620
sure that we would set up a system that

00:10:47,580 --> 00:10:53,610
was going to go from git repositories to

00:10:49,620 --> 00:10:55,110
emailed results you know and kind of set

00:10:53,610 --> 00:10:57,480
up a whole infrastructure and so that

00:10:55,110 --> 00:10:59,970
infrastructure looks largely like this

00:10:57,480 --> 00:11:01,890
where you have a git tree which is

00:10:59,970 --> 00:11:03,750
ultimately monitored so in the case of

00:11:01,890 --> 00:11:05,640
the LTS trees that's Gregg Cartman's

00:11:03,750 --> 00:11:06,579
trees in the case of Android command

00:11:05,640 --> 00:11:07,899
kernel trees that we

00:11:06,579 --> 00:11:10,869
work with that's of course comes from

00:11:07,899 --> 00:11:13,149
the AOSP project as those things change

00:11:10,869 --> 00:11:16,959
we detect that change we kickoff builds

00:11:13,149 --> 00:11:18,339
inside of Jenkins that then results in a

00:11:16,959 --> 00:11:22,239
bunch of test jobs which are then

00:11:18,339 --> 00:11:25,980
shipped off to lava and then lava will

00:11:22,239 --> 00:11:29,350
dispatch this all across our board farm

00:11:25,980 --> 00:11:32,079
tests are often in the case of larger

00:11:29,350 --> 00:11:33,699
more complicated test suites like LTP

00:11:32,079 --> 00:11:36,699
they're sharded so that we're running

00:11:33,699 --> 00:11:40,149
subsections of LTP at a time we're not

00:11:36,699 --> 00:11:42,850
running all of LTP on one board we chunk

00:11:40,149 --> 00:11:44,529
it up into pieces and then those results

00:11:42,850 --> 00:11:46,600
of course get pulled into a database

00:11:44,529 --> 00:11:48,220
that database then is made available to

00:11:46,600 --> 00:11:52,629
something called squad and then squad

00:11:48,220 --> 00:11:54,549
puts out both a web UI as well as an

00:11:52,629 --> 00:11:58,709
email report that then ultimately goes

00:11:54,549 --> 00:12:01,480
up to the upstream community we don't

00:11:58,709 --> 00:12:04,959
generally I should say in the early days

00:12:01,480 --> 00:12:06,819
we didn't just kick out the report we

00:12:04,959 --> 00:12:09,759
would kind of hold it back and you know

00:12:06,819 --> 00:12:11,860
sort of not trusted and and really kind

00:12:09,759 --> 00:12:15,339
of look out for things like false

00:12:11,860 --> 00:12:16,929
positives and flaky test cases and just

00:12:15,339 --> 00:12:18,610
kind of all sorts of things that were a

00:12:16,929 --> 00:12:20,949
little distrusting of the system until

00:12:18,610 --> 00:12:22,269
we had put a lot of time under our belt

00:12:20,949 --> 00:12:24,819
so you know here we are a year later

00:12:22,269 --> 00:12:28,600
we're very confident in our results and

00:12:24,819 --> 00:12:30,220
so from an RC out to reporting results

00:12:28,600 --> 00:12:33,669
we're looking at about an eight hour

00:12:30,220 --> 00:12:35,829
turnaround time and that's that's taken

00:12:33,669 --> 00:12:37,269
quite a bit to get there this

00:12:35,829 --> 00:12:39,819
infrastructure that I just talked about

00:12:37,269 --> 00:12:43,149
it's largely completely open it's all

00:12:39,819 --> 00:12:46,059
you know open source pieces and the

00:12:43,149 --> 00:12:48,549
individual parts of the system are all

00:12:46,059 --> 00:12:50,799
out on the web so if you go into kernels

00:12:48,549 --> 00:12:52,360
so yeah our I should say CIL Inara org

00:12:50,799 --> 00:12:55,299
and see the jobs as they're coming in

00:12:52,360 --> 00:12:57,699
you can watch the board farm in L kft

00:12:55,299 --> 00:13:00,699
validation llanera org and then the

00:12:57,699 --> 00:13:02,439
reports that are kicked out you can go

00:13:00,699 --> 00:13:04,329
directly to the web interface or if you

00:13:02,439 --> 00:13:09,549
watch the Linux table project you'll see

00:13:04,329 --> 00:13:11,919
those things get reported by the lonardo

00:13:09,549 --> 00:13:15,249
folks so there's a few people that'll

00:13:11,919 --> 00:13:16,370
that'll post them by by hand even though

00:13:15,249 --> 00:13:19,899
there

00:13:16,370 --> 00:13:22,670
kicked out by the system automatically

00:13:19,899 --> 00:13:27,620
okay so just to put this in statistical

00:13:22,670 --> 00:13:30,350
terms here so anytime a 4 4 4 9 4 14 4 4

00:13:27,620 --> 00:13:34,249
15 main line or next set of changes

00:13:30,350 --> 00:13:36,620
lands that's going to kick off some set

00:13:34,249 --> 00:13:38,269
of builds and those builds depend on the

00:13:36,620 --> 00:13:40,249
board and the operating system

00:13:38,269 --> 00:13:42,709
combination and of course the kernel

00:13:40,249 --> 00:13:45,860
version as well as the test case version

00:13:42,709 --> 00:13:47,600
that you're going to ultimately run so

00:13:45,860 --> 00:13:49,819
you got several different things that

00:13:47,600 --> 00:13:51,829
you don't want changed or you want to

00:13:49,819 --> 00:13:53,269
minimalize change and you put have to

00:13:51,829 --> 00:13:57,350
put all those things together into a

00:13:53,269 --> 00:13:58,309
build and then once those builds are all

00:13:57,350 --> 00:14:00,350
done

00:13:58,309 --> 00:14:01,970
or as they seriously serially get

00:14:00,350 --> 00:14:03,620
completed then we'll kick them off into

00:14:01,970 --> 00:14:07,579
the lava farm so that's ultimately about

00:14:03,620 --> 00:14:10,819
20 lava jobs per kernel version and then

00:14:07,579 --> 00:14:13,339
that's about 5,500 individual tests that

00:14:10,819 --> 00:14:17,269
are ultimately going to be run again per

00:14:13,339 --> 00:14:21,170
kernel version so it's a lot of activity

00:14:17,269 --> 00:14:24,050
when you see a new LTS release happen or

00:14:21,170 --> 00:14:27,019
a new RC out on mainline or we have you

00:14:24,050 --> 00:14:30,319
it generate some activity so that

00:14:27,019 --> 00:14:32,959
activity shows up in this so this is lkf

00:14:30,319 --> 00:14:34,279
T it's a bit of an eye chart here but

00:14:32,959 --> 00:14:37,339
down here at the bottom there's a list

00:14:34,279 --> 00:14:40,220
of boards that are that data is getting

00:14:37,339 --> 00:14:43,249
kicked off of so this is a screenshot of

00:14:40,220 --> 00:14:44,870
an active day that was in February so at

00:14:43,249 --> 00:14:47,540
this time you know we've got some be 20

00:14:44,870 --> 00:14:49,970
to 60 boards from St we've got dragon

00:14:47,540 --> 00:14:52,490
board for 10 C from Qualcomm we've got

00:14:49,970 --> 00:14:55,639
the Heike board which is a high silicon

00:14:52,490 --> 00:14:58,040
device a Juneau r2 which is a dev board

00:14:55,639 --> 00:15:01,069
from arm they're about they're they're

00:14:58,040 --> 00:15:03,769
fairly expensive but they're nice boards

00:15:01,069 --> 00:15:08,089
there's QM we've got qmu and so in this

00:15:03,769 --> 00:15:11,300
case we do qmu for x86 but we're about

00:15:08,089 --> 00:15:13,790
to get both arm 32 and arm 64 running on

00:15:11,300 --> 00:15:16,040
the QM new environment as well

00:15:13,790 --> 00:15:18,410
x-15 was just a 32-bit arm device from

00:15:16,040 --> 00:15:21,679
Ti and then of course good old bog

00:15:18,410 --> 00:15:24,350
standard x86 devices and so of course

00:15:21,679 --> 00:15:26,689
these queues will fill up as the lab

00:15:24,350 --> 00:15:28,279
jobs land things gets dispatched and

00:15:26,689 --> 00:15:30,320
ultimately then well we'll start to see

00:15:28,279 --> 00:15:31,400
some results so

00:15:30,320 --> 00:15:34,700
now I kind of want to go into a little

00:15:31,400 --> 00:15:35,840
bit of a the reporting side of the talk

00:15:34,700 --> 00:15:36,830
and so what I want to do is I want to

00:15:35,840 --> 00:15:39,620
talk a little bit about some of our

00:15:36,830 --> 00:15:41,990
experiences along the way building the

00:15:39,620 --> 00:15:44,180
system and what we've sort of discovered

00:15:41,990 --> 00:15:47,060
so one of the things that hit us

00:15:44,180 --> 00:15:48,320
initially early on was is okay across

00:15:47,060 --> 00:15:51,770
all these different dev boards that are

00:15:48,320 --> 00:15:54,610
out here different boards with different

00:15:51,770 --> 00:15:57,560
connectors are actually hard to scale up

00:15:54,610 --> 00:16:00,140
we have a standard called 96 boards and

00:15:57,560 --> 00:16:01,790
as a you know the nice thing about 96

00:16:00,140 --> 00:16:03,740
boards is all of the connectors are in

00:16:01,790 --> 00:16:05,570
the same place and so everything is more

00:16:03,740 --> 00:16:07,370
or less standard so that makes the that

00:16:05,570 --> 00:16:09,860
particular board design really nice and

00:16:07,370 --> 00:16:12,740
really easy to to kind of set up in a

00:16:09,860 --> 00:16:14,330
system like this so that that's our

00:16:12,740 --> 00:16:16,130
that's a really good quality to have

00:16:14,330 --> 00:16:20,360
when you're trying to build a system

00:16:16,130 --> 00:16:22,340
like this at scale reliability doesn't

00:16:20,360 --> 00:16:25,010
just happen you you end up having to

00:16:22,340 --> 00:16:28,370
write some checks for above-average

00:16:25,010 --> 00:16:31,460
hardware we had a problem because we had

00:16:28,370 --> 00:16:34,100
low quality USB cables at one time and

00:16:31,460 --> 00:16:36,740
you know how that would show up in the

00:16:34,100 --> 00:16:38,930
environment is well 10% of your test

00:16:36,740 --> 00:16:40,790
jobs are just fallen over and exploding

00:16:38,930 --> 00:16:44,150
in large mushroom clouds off into the

00:16:40,790 --> 00:16:46,250
ditch what's going on you know is this a

00:16:44,150 --> 00:16:48,950
kernel bug is this a test-case bug is

00:16:46,250 --> 00:16:50,930
this you know and trying to ferret that

00:16:48,950 --> 00:16:53,240
out is really annoying until you realize

00:16:50,930 --> 00:16:55,220
oh this cable here is a piece of junk

00:16:53,240 --> 00:16:56,630
throw it away let's button build

00:16:55,220 --> 00:16:59,140
something you know pick something out

00:16:56,630 --> 00:17:02,270
here that's actually some decent quality

00:16:59,140 --> 00:17:04,640
USB hubs was actually another thing that

00:17:02,270 --> 00:17:06,890
was very important that we found we have

00:17:04,640 --> 00:17:08,660
seen variability in USB hubs where

00:17:06,890 --> 00:17:10,579
low-quality stuff will again cause

00:17:08,660 --> 00:17:12,140
boards to look like they're failing when

00:17:10,579 --> 00:17:14,750
in fact it's not the board's problem

00:17:12,140 --> 00:17:16,459
it's the hub's fault so that was

00:17:14,750 --> 00:17:19,310
something where again skipping on on

00:17:16,459 --> 00:17:22,220
hardware really cost us time and energy

00:17:19,310 --> 00:17:23,689
and we had to learn through the school

00:17:22,220 --> 00:17:27,400
of hard knocks that that was something

00:17:23,689 --> 00:17:29,510
not to skimp on firmware updates so

00:17:27,400 --> 00:17:31,010
board manufacture will come along and

00:17:29,510 --> 00:17:33,260
say well we've got a new and updated

00:17:31,010 --> 00:17:36,410
firmware maybe it manages power a little

00:17:33,260 --> 00:17:37,610
bit better than the old one did or does

00:17:36,410 --> 00:17:40,400
something better with booting or

00:17:37,610 --> 00:17:43,310
what-have-you and changes

00:17:40,400 --> 00:17:46,160
that firmware can just cause us to go

00:17:43,310 --> 00:17:48,830
crazy because what oftentimes can happen

00:17:46,160 --> 00:17:50,990
is is that those firmware changes can

00:17:48,830 --> 00:17:53,720
include changes to the interfaces and so

00:17:50,990 --> 00:17:56,450
those interfaces are something that the

00:17:53,720 --> 00:17:59,150
system ultimately will integrate with

00:17:56,450 --> 00:18:00,650
and so you know if anything changed in

00:17:59,150 --> 00:18:02,330
for instance how you partition the board

00:18:00,650 --> 00:18:04,550
or ship something down or ultimately

00:18:02,330 --> 00:18:06,230
work with that board the environment now

00:18:04,550 --> 00:18:08,300
has to catch up to how the firmware just

00:18:06,230 --> 00:18:10,420
changed and that takes time somebody's

00:18:08,300 --> 00:18:12,710
got to come up to speed on that and

00:18:10,420 --> 00:18:14,600
understand what those changes are and

00:18:12,710 --> 00:18:18,740
what that means inside of the system

00:18:14,600 --> 00:18:20,450
itself so you know we would love to see

00:18:18,740 --> 00:18:23,270
standardization in that space in

00:18:20,450 --> 00:18:26,420
particular but it's it's something that

00:18:23,270 --> 00:18:28,670
clearly were not there okay another area

00:18:26,420 --> 00:18:30,650
that we had from a device perspective is

00:18:28,670 --> 00:18:32,000
you know each board that we're going to

00:18:30,650 --> 00:18:33,740
connect into the system

00:18:32,000 --> 00:18:35,720
there's actually four cables that go

00:18:33,740 --> 00:18:38,000
into that particular device so you've

00:18:35,720 --> 00:18:39,970
got cereal you got OTG you got Ethernet

00:18:38,000 --> 00:18:41,840
or power

00:18:39,970 --> 00:18:45,350
ideally sometimes you could just have

00:18:41,840 --> 00:18:49,040
Wi-Fi you got your power brick that you

00:18:45,350 --> 00:18:51,410
got to deal with and you know that ends

00:18:49,040 --> 00:18:53,980
up being a mess of spaghetti that is not

00:18:51,410 --> 00:18:57,080
fun to to deal with in a lab environment

00:18:53,980 --> 00:18:58,190
okay so the other area that I want to

00:18:57,080 --> 00:19:00,860
talk a little bit about is some of the

00:18:58,190 --> 00:19:02,900
test suites that we that we use so cased

00:19:00,860 --> 00:19:06,650
health test it was a natural one that we

00:19:02,900 --> 00:19:10,160
turn to this is of course the Linux

00:19:06,650 --> 00:19:12,650
kernels internal test suite it's a it's

00:19:10,160 --> 00:19:13,970
a good test suite it's still not

00:19:12,650 --> 00:19:16,850
something that all of the Linux kernel

00:19:13,970 --> 00:19:19,250
sub maintainer x' contribute to or

00:19:16,850 --> 00:19:20,870
necessarily believe in but you know

00:19:19,250 --> 00:19:23,120
that's you know hopefully something that

00:19:20,870 --> 00:19:25,220
will get figured out in time one of the

00:19:23,120 --> 00:19:29,690
things that we do though is we use the

00:19:25,220 --> 00:19:32,870
latest version of K self-test across the

00:19:29,690 --> 00:19:35,630
board so that means we'll take a 415

00:19:32,870 --> 00:19:38,120
version of K self-test and we will run

00:19:35,630 --> 00:19:41,090
that on top of four four we'll run it on

00:19:38,120 --> 00:19:42,980
top of four nine and that was a little

00:19:41,090 --> 00:19:44,330
bit of a controversial change and we had

00:19:42,980 --> 00:19:45,920
gone out to the community and said tell

00:19:44,330 --> 00:19:49,760
us what the right thing to do is and

00:19:45,920 --> 00:19:51,380
I'll give us some direction here and it

00:19:49,760 --> 00:19:52,920
doesn't seem like that there's a really

00:19:51,380 --> 00:19:54,330
a good way

00:19:52,920 --> 00:19:56,490
we're another because the problem is is

00:19:54,330 --> 00:19:58,470
that when it comes to K self-test itself

00:19:56,490 --> 00:20:00,720
we noticed that there aren't necessarily

00:19:58,470 --> 00:20:02,700
patches that would go into like a 4/4

00:20:00,720 --> 00:20:05,070
kernel to update k self-test as patches

00:20:02,700 --> 00:20:09,150
were landing to fix particular problems

00:20:05,070 --> 00:20:11,790
in the kernel so what do you do you know

00:20:09,150 --> 00:20:15,030
you you end up sort of using aggressive

00:20:11,790 --> 00:20:16,710
skip lists for test suites that are for

00:20:15,030 --> 00:20:17,700
tests that are in K cell tests are just

00:20:16,710 --> 00:20:20,850
not appropriate for that particular

00:20:17,700 --> 00:20:23,340
kernel version it's just it's just the

00:20:20,850 --> 00:20:25,440
way that it goes now across K self-test

00:20:23,340 --> 00:20:27,890
itself there's a lot of inconsistencies

00:20:25,440 --> 00:20:31,560
as far as how the tests are designed

00:20:27,890 --> 00:20:33,210
sometimes in the cases of the setup

00:20:31,560 --> 00:20:35,070
that's required for those K self-test

00:20:33,210 --> 00:20:36,720
sometimes it's not necessarily totally

00:20:35,070 --> 00:20:39,240
obvious what kernel configurations you

00:20:36,720 --> 00:20:40,590
have to turn on so working with K

00:20:39,240 --> 00:20:42,840
self-test can be a little bit of an

00:20:40,590 --> 00:20:46,200
extra style exercise in frustration but

00:20:42,840 --> 00:20:47,850
it's still well worth it and as you know

00:20:46,200 --> 00:20:50,460
it's a body of tests you know if you've

00:20:47,850 --> 00:20:53,280
got time and to put effort into putting

00:20:50,460 --> 00:20:54,810
patches to improve K self-test please do

00:20:53,280 --> 00:20:58,170
you are helping the universe at large

00:20:54,810 --> 00:20:59,700
when you do so so you know take that

00:20:58,170 --> 00:21:01,950
into take that into account if you've

00:20:59,700 --> 00:21:05,580
got some n spare cycles another one that

00:21:01,950 --> 00:21:06,930
we use is LTP so LTP is kind of

00:21:05,580 --> 00:21:09,360
approaching things from the opposite

00:21:06,930 --> 00:21:11,130
angle so where k self-test is ingrained

00:21:09,360 --> 00:21:12,960
and testing from the inside of the

00:21:11,130 --> 00:21:15,060
kernel k self-test or I should say LTP

00:21:12,960 --> 00:21:16,770
is from essentially coming down on user

00:21:15,060 --> 00:21:19,070
space so it's running things like sis

00:21:16,770 --> 00:21:21,150
calls it's running things like you know

00:21:19,070 --> 00:21:22,980
some of the environmental stuff that's

00:21:21,150 --> 00:21:25,980
on top of Linux and so it you know tries

00:21:22,980 --> 00:21:31,080
to tickle the kernel and and find you

00:21:25,980 --> 00:21:34,590
know err cases in doing so so it is a

00:21:31,080 --> 00:21:36,410
test suite that's reasonably mature it's

00:21:34,590 --> 00:21:41,970
updated still about every four months

00:21:36,410 --> 00:21:43,590
and as a you know test environment we've

00:21:41,970 --> 00:21:47,520
you know we've we've been fairly happy

00:21:43,590 --> 00:21:49,800
with it the one downside to LTP is when

00:21:47,520 --> 00:21:52,980
we want to be doing things with Android

00:21:49,800 --> 00:21:54,840
well there are you know vast loss of LTP

00:21:52,980 --> 00:21:57,120
tests that just don't run on any

00:21:54,840 --> 00:21:59,100
operating system but traditional Linux

00:21:57,120 --> 00:22:01,670
itself and it would be nice if that

00:21:59,100 --> 00:22:01,670
wasn't the case

00:22:02,360 --> 00:22:09,360
okay so as I kind of mentioned you know

00:22:07,170 --> 00:22:11,130
when it comes to individual test Suites

00:22:09,360 --> 00:22:12,600
you know we would kind of see some best

00:22:11,130 --> 00:22:15,930
practices things that we'd like to see

00:22:12,600 --> 00:22:23,070
generally cleaned up we do run CTS we do

00:22:15,930 --> 00:22:25,170
run BTS from the land of Android and VTS

00:22:23,070 --> 00:22:28,110
in particular does contain an internal

00:22:25,170 --> 00:22:30,420
copy of case self-test and LTP you know

00:22:28,110 --> 00:22:31,680
highly you know selective as far as what

00:22:30,420 --> 00:22:34,290
they run they don't run all of those

00:22:31,680 --> 00:22:35,520
those test Suites but they you know pare

00:22:34,290 --> 00:22:39,870
down to something that's appropriate for

00:22:35,520 --> 00:22:41,430
the Android environment and this

00:22:39,870 --> 00:22:43,380
reflects back into what I sort of had

00:22:41,430 --> 00:22:45,390
mentioned before with LTP in so much it

00:22:43,380 --> 00:22:47,820
makes assumptions as far as sometimes

00:22:45,390 --> 00:22:49,440
the hardware that it's running on like

00:22:47,820 --> 00:22:50,940
Princess Elsa mount sometimes they'll go

00:22:49,440 --> 00:22:52,830
out and they'll make a three gig file

00:22:50,940 --> 00:22:55,830
well if you're on a small embedded

00:22:52,830 --> 00:22:57,780
device making a three gig file may not

00:22:55,830 --> 00:23:00,510
fit into the size of the emmc that you

00:22:57,780 --> 00:23:02,670
have on the device so you know you have

00:23:00,510 --> 00:23:04,500
to sort of run into these these tests

00:23:02,670 --> 00:23:06,600
and you know throw them out because

00:23:04,500 --> 00:23:11,700
they're just not appropriate for the

00:23:06,600 --> 00:23:15,450
environment there is unfortunately

00:23:11,700 --> 00:23:17,340
across you know a lot of these test

00:23:15,450 --> 00:23:20,100
suites there's just no unified standard

00:23:17,340 --> 00:23:23,100
for doing reporting of results and logs

00:23:20,100 --> 00:23:24,780
and errors and skip lists and so you

00:23:23,100 --> 00:23:27,450
know in designing a system like this we

00:23:24,780 --> 00:23:28,860
sort of had to manage things together if

00:23:27,450 --> 00:23:30,270
you're at a talk earlier today by

00:23:28,860 --> 00:23:32,370
timbered for instance he was complaining

00:23:30,270 --> 00:23:34,680
that you know really tests need to have

00:23:32,370 --> 00:23:39,120
a universal ID so that when you do

00:23:34,680 --> 00:23:41,730
comparisons you know you could do that

00:23:39,120 --> 00:23:43,110
effectively by knowing okay this test is

00:23:41,730 --> 00:23:44,370
really the same test you just ran them

00:23:43,110 --> 00:23:46,470
on two different architectures and

00:23:44,370 --> 00:23:48,780
that's something that should not be hard

00:23:46,470 --> 00:23:50,460
it would be it would be really good if

00:23:48,780 --> 00:23:55,460
again we could find some sort of

00:23:50,460 --> 00:23:58,350
standard so on the case of reporting you

00:23:55,460 --> 00:24:00,330
know it's interesting that even like BTS

00:23:58,350 --> 00:24:02,160
and CTS even though they're both from

00:24:00,330 --> 00:24:05,940
the Android universe they come out

00:24:02,160 --> 00:24:07,980
reporting completely differently and so

00:24:05,940 --> 00:24:09,690
that results in inconsistencies k

00:24:07,980 --> 00:24:13,970
self-test when it runs it throws its

00:24:09,690 --> 00:24:15,920
logs in to slash temp you know it just

00:24:13,970 --> 00:24:17,780
these things layer by layer you have to

00:24:15,920 --> 00:24:21,400
kind of tear them apart and and work

00:24:17,780 --> 00:24:25,160
with them okay so let's move on to

00:24:21,400 --> 00:24:27,010
Android and so I've mentioned that we

00:24:25,160 --> 00:24:29,270
work with the Android common kernel and

00:24:27,010 --> 00:24:31,070
so of course you know this is everything

00:24:29,270 --> 00:24:32,600
from mainline all the way through the

00:24:31,070 --> 00:24:35,990
LTS versions from four four four nine

00:24:32,600 --> 00:24:38,630
four fourteen the thing about the

00:24:35,990 --> 00:24:40,820
Android common kernel is it's largely

00:24:38,630 --> 00:24:42,350
in sync with LTS so when a new LTS

00:24:40,820 --> 00:24:44,720
release comes out the Android common

00:24:42,350 --> 00:24:47,900
kernel rebase is to that but then it has

00:24:44,720 --> 00:24:49,760
a set of out of tree kernel patches and

00:24:47,900 --> 00:24:52,220
the out of tree kernel patches has been

00:24:49,760 --> 00:24:53,750
largely decreasing in size which is

00:24:52,220 --> 00:24:55,790
which is generally a good thing but it

00:24:53,750 --> 00:24:57,680
still results in the android common

00:24:55,790 --> 00:25:01,820
kernel is different than the linux

00:24:57,680 --> 00:25:05,450
upstream and what we found in our and

00:25:01,820 --> 00:25:09,020
our testing to detect kernel regressions

00:25:05,450 --> 00:25:12,020
is that openembedded is the operating

00:25:09,020 --> 00:25:16,460
system that we put our most time and

00:25:12,020 --> 00:25:20,120
effort into finding problems and so open

00:25:16,460 --> 00:25:23,240
embedded you know anything that we find

00:25:20,120 --> 00:25:25,130
there typically isn't going to result in

00:25:23,240 --> 00:25:28,610
something that's gonna spill over into

00:25:25,130 --> 00:25:30,080
the android common kernel anything that

00:25:28,610 --> 00:25:31,580
then is you know showing up as a

00:25:30,080 --> 00:25:34,280
regression in the android common kernel

00:25:31,580 --> 00:25:36,260
tends to be actually from that you know

00:25:34,280 --> 00:25:37,550
set of auditory kernel patches so that's

00:25:36,260 --> 00:25:40,040
it's kind of a nice little way how

00:25:37,550 --> 00:25:42,040
things how things work but we have a bit

00:25:40,040 --> 00:25:46,400
of a blind spot because as I mentioned

00:25:42,040 --> 00:25:48,800
VTS contains a subset of LTP and it

00:25:46,400 --> 00:25:50,690
contains a subset of K self-test because

00:25:48,800 --> 00:25:53,480
it's just not able to run everything so

00:25:50,690 --> 00:25:55,400
you know this kind of doesn't feel right

00:25:53,480 --> 00:25:56,690
you know we'd like to again have parity

00:25:55,400 --> 00:25:58,010
in our testing so that it doesn't matter

00:25:56,690 --> 00:26:02,960
if we're on Android or for an open

00:25:58,010 --> 00:26:05,300
embedded we can run everything but again

00:26:02,960 --> 00:26:07,130
at least you know today you know open

00:26:05,300 --> 00:26:09,020
and embedded is is really our lead

00:26:07,130 --> 00:26:11,030
operating system and it does seem to do

00:26:09,020 --> 00:26:13,580
a really good job and finding finding

00:26:11,030 --> 00:26:15,320
issues okay so as I mentioned before

00:26:13,580 --> 00:26:17,570
just when it comes to keeping up with

00:26:15,320 --> 00:26:22,760
LTS as a project there's you know maybe

00:26:17,570 --> 00:26:25,530
one to two sometimes three LTS releases

00:26:22,760 --> 00:26:26,610
on the average week and we have

00:26:25,530 --> 00:26:28,140
you know as I mentioned we've got that

00:26:26,610 --> 00:26:30,570
48-hour window that we have to deal with

00:26:28,140 --> 00:26:32,640
and typically our turnaround time is as

00:26:30,570 --> 00:26:34,590
we'll get results back in about eight

00:26:32,640 --> 00:26:36,150
hours so if you think about that there's

00:26:34,590 --> 00:26:38,850
really two ways to look at that process

00:26:36,150 --> 00:26:40,320
there's building running and results and

00:26:38,850 --> 00:26:41,670
that's results if you have everything is

00:26:40,320 --> 00:26:44,310
green everything worked out really

00:26:41,670 --> 00:26:46,110
really well and then you have that

00:26:44,310 --> 00:26:47,370
situation where you have an error and

00:26:46,110 --> 00:26:48,870
you have to figure out what's going on

00:26:47,370 --> 00:26:50,130
did you have something that went wrong

00:26:48,870 --> 00:26:51,330
with your infrastructure do you have

00:26:50,130 --> 00:26:52,800
something that went wrong with a board

00:26:51,330 --> 00:26:55,440
do you have something that went wrong

00:26:52,800 --> 00:26:57,780
for a particular family so maybe it was

00:26:55,440 --> 00:27:00,210
across all of the ARM architecture where

00:26:57,780 --> 00:27:03,360
an air showed up maybe it was something

00:27:00,210 --> 00:27:05,340
that was specific to one board and you

00:27:03,360 --> 00:27:07,410
know one particular kernel so you have

00:27:05,340 --> 00:27:09,420
to sort of take a look at the data in

00:27:07,410 --> 00:27:11,370
you know a number of context and figure

00:27:09,420 --> 00:27:14,820
out what all you know what's going on

00:27:11,370 --> 00:27:16,500
and ultimately you want bisect and end

00:27:14,820 --> 00:27:18,510
up with a fix that then you can report

00:27:16,500 --> 00:27:21,240
back that's really really hard to do in

00:27:18,510 --> 00:27:23,070
a 40-hour at window matter of fact I

00:27:21,240 --> 00:27:25,680
would say it for the most part unless

00:27:23,070 --> 00:27:27,900
it's something pretty obvious it tends

00:27:25,680 --> 00:27:29,250
to be next to impossible you can bisect

00:27:27,900 --> 00:27:31,710
to say that this is probably the bad

00:27:29,250 --> 00:27:33,120
patch but taking it that next mount

00:27:31,710 --> 00:27:35,250
saying well here's exactly what you need

00:27:33,120 --> 00:27:38,910
to do to fix that that's that's where

00:27:35,250 --> 00:27:40,140
the difficulty comes in okay so I want

00:27:38,910 --> 00:27:42,810
to start going through some examples

00:27:40,140 --> 00:27:44,820
what l kft puts out and ultimately what

00:27:42,810 --> 00:27:46,710
we report so the very first thing I want

00:27:44,820 --> 00:27:49,110
to start out with is our most important

00:27:46,710 --> 00:27:53,910
management reporting mechanism that's by

00:27:49,110 --> 00:27:56,730
email so if you're on the stable Linux

00:27:53,910 --> 00:27:59,160
kernel mailing list so stable at beecher

00:27:56,730 --> 00:28:01,320
you what you will see occasionally is

00:27:59,160 --> 00:28:03,090
you'll see these reports pop up from lk

00:28:01,320 --> 00:28:05,280
ft and again it's a little bit of an eye

00:28:03,090 --> 00:28:07,380
test but what we try to do in this email

00:28:05,280 --> 00:28:09,510
summary is to put up very up at the very

00:28:07,380 --> 00:28:12,270
top is to say everything worked

00:28:09,510 --> 00:28:14,910
no regressions you know no need to look

00:28:12,270 --> 00:28:17,430
any further in this email that's all you

00:28:14,910 --> 00:28:19,440
need to know everything just worked if

00:28:17,430 --> 00:28:22,260
there is a failure then we'll pop that

00:28:19,440 --> 00:28:24,000
in up at the top and we'll try to put in

00:28:22,260 --> 00:28:26,310
as much detail as far as what's going on

00:28:24,000 --> 00:28:28,920
to kind of help the community at large

00:28:26,310 --> 00:28:31,170
figure out what's going on what's kind

00:28:28,920 --> 00:28:33,390
of neat here too is if you look down at

00:28:31,170 --> 00:28:35,760
the list and that's kind of a breakdown

00:28:33,390 --> 00:28:38,630
of how we shard tests so you know you

00:28:35,760 --> 00:28:41,360
can see LTPS file cap tests and f

00:28:38,630 --> 00:28:43,700
tests and huge TLB tests and IO and so

00:28:41,360 --> 00:28:44,600
on and so forth so that's kind of you

00:28:43,700 --> 00:28:47,000
know something that we could probably

00:28:44,600 --> 00:28:48,980
roll up in report a little bit better

00:28:47,000 --> 00:28:51,230
but right now we've kept that broken out

00:28:48,980 --> 00:28:52,610
just to give everybody an idea of what

00:28:51,230 --> 00:28:54,560
exactly it is that we're running and

00:28:52,610 --> 00:28:56,030
then we break it down by the

00:28:54,560 --> 00:28:57,350
architecture and the board combinations

00:28:56,030 --> 00:28:59,330
which since we've added more and more

00:28:57,350 --> 00:29:00,920
boards I've gotten that email to be

00:28:59,330 --> 00:29:06,320
pretty long so again that's something we

00:29:00,920 --> 00:29:11,000
probably need to look at okay so besides

00:29:06,320 --> 00:29:16,040
email we also have a web UI so this is Q

00:29:11,000 --> 00:29:18,710
a dot Q a reports Lenora org and so this

00:29:16,040 --> 00:29:21,920
is an example page specifically from 414

00:29:18,710 --> 00:29:25,040
and so if we had the whole window here

00:29:21,920 --> 00:29:26,960
you know we'd go down to 4 14.90 nand so

00:29:25,040 --> 00:29:28,580
on and so for all through time and so we

00:29:26,960 --> 00:29:31,130
keep a keep a long history of what's

00:29:28,580 --> 00:29:32,450
been going on and in one of these you

00:29:31,130 --> 00:29:33,830
know so at the very top at the green one

00:29:32,450 --> 00:29:35,150
you can see all the test runs that are

00:29:33,830 --> 00:29:36,770
there and this is all something that's

00:29:35,150 --> 00:29:38,600
available on live links the other thing

00:29:36,770 --> 00:29:39,650
that we have here but the top error I

00:29:38,600 --> 00:29:42,410
should say about in the middle of the

00:29:39,650 --> 00:29:44,060
page is this is the metadata that goes

00:29:42,410 --> 00:29:45,710
with this particular build so we think

00:29:44,060 --> 00:29:47,930
it's very very important that we give

00:29:45,710 --> 00:29:50,240
enough information to have the the

00:29:47,930 --> 00:29:52,490
commit IDs the exact branches that were

00:29:50,240 --> 00:29:54,080
in use and that includes not only the

00:29:52,490 --> 00:29:55,340
kernel but the test suites that were

00:29:54,080 --> 00:29:57,350
involved you know the whole kit and

00:29:55,340 --> 00:29:59,960
kaboodle so that somebody can go and

00:29:57,350 --> 00:30:01,460
replicate this entire build outside of

00:29:59,960 --> 00:30:03,950
our own lab they don't have to pick up

00:30:01,460 --> 00:30:05,440
our binary images to to replicate

00:30:03,950 --> 00:30:07,670
everything they can rebuild it

00:30:05,440 --> 00:30:11,690
specifically from source 2 if they want

00:30:07,670 --> 00:30:14,240
to that reproducibility is is just huge

00:30:11,690 --> 00:30:16,070
in our world ok so now in the case that

00:30:14,240 --> 00:30:20,210
there's an error I've gone ahead and and

00:30:16,070 --> 00:30:22,250
pulled out a this was again from back in

00:30:20,210 --> 00:30:24,440
February and environment and time when

00:30:22,250 --> 00:30:26,390
we had something were failures had

00:30:24,440 --> 00:30:27,800
popped out and so this is something

00:30:26,390 --> 00:30:28,880
where you know if you're a triage

00:30:27,800 --> 00:30:30,410
engineer and you're looking at this

00:30:28,880 --> 00:30:32,960
wondering what's going on you click on

00:30:30,410 --> 00:30:35,510
it this will take you to a report page

00:30:32,960 --> 00:30:36,920
that's gonna look about like this and so

00:30:35,510 --> 00:30:38,900
this is one of those cases where again

00:30:36,920 --> 00:30:40,850
you're looking for trends you know early

00:30:38,900 --> 00:30:42,020
on in the in the stage you're saying ok

00:30:40,850 --> 00:30:43,640
was this something it's just just

00:30:42,020 --> 00:30:45,650
affecting one board is it affecting a

00:30:43,640 --> 00:30:47,480
whole architecture is it affecting you

00:30:45,650 --> 00:30:48,950
know all of you know everybody in which

00:30:47,480 --> 00:30:49,720
case you know maybe this is a generic

00:30:48,950 --> 00:30:52,630
you know

00:30:49,720 --> 00:30:54,940
Linux kernel issue and you know

00:30:52,630 --> 00:30:56,020
therefore the you know importance of

00:30:54,940 --> 00:30:59,410
trying to get to the bottom of it and

00:30:56,020 --> 00:31:00,670
you know increases the other thing of

00:30:59,410 --> 00:31:02,980
course that you can see on this this

00:31:00,670 --> 00:31:04,690
particular page then is you can see you

00:31:02,980 --> 00:31:05,920
know just for the LTP syscalls you can

00:31:04,690 --> 00:31:08,110
see how many tests there were and how

00:31:05,920 --> 00:31:09,760
many pass and you also notice that there

00:31:08,110 --> 00:31:11,080
are skips and the reason why those

00:31:09,760 --> 00:31:13,120
skipped numbers are so big is because

00:31:11,080 --> 00:31:15,490
there are tests and LTP which are not

00:31:13,120 --> 00:31:17,230
appropriate for all architectures and so

00:31:15,490 --> 00:31:18,310
this is all sort of conglomerated

00:31:17,230 --> 00:31:20,350
together and the numbers that you're

00:31:18,310 --> 00:31:22,750
seeing so when we look at a particular

00:31:20,350 --> 00:31:24,460
test run then so we're looking now at

00:31:22,750 --> 00:31:26,500
one of the particular failures this is

00:31:24,460 --> 00:31:28,330
on the 32-bit version so the test

00:31:26,500 --> 00:31:30,010
environment is X 15s that's a like I

00:31:28,330 --> 00:31:33,370
mentioned before that's a 32-bit TI

00:31:30,010 --> 00:31:36,010
board we'll see here's our - here's our

00:31:33,370 --> 00:31:38,320
two tests that failed now in this case

00:31:36,010 --> 00:31:42,430
here it's actually not two tests it's

00:31:38,320 --> 00:31:43,600
just one the run LTP syscalls that's

00:31:42,430 --> 00:31:45,340
actually the name of the shell script

00:31:43,600 --> 00:31:47,860
that runs that then kicks off a number

00:31:45,340 --> 00:31:50,290
of activities and it's one of these sub

00:31:47,860 --> 00:31:52,660
activities that fail so that's the FA

00:31:50,290 --> 00:31:53,860
notify o6 that actually failed but the

00:31:52,660 --> 00:31:55,390
nice thing that we've got in this

00:31:53,860 --> 00:31:57,880
environment then is is we can go back

00:31:55,390 --> 00:31:59,290
and you know click on that link off on

00:31:57,880 --> 00:32:01,870
the right hand side that says show in

00:31:59,290 --> 00:32:03,490
full you'll see the log that's that's

00:32:01,870 --> 00:32:06,010
there for that particular test run for

00:32:03,490 --> 00:32:07,480
that individual test case so you're not

00:32:06,010 --> 00:32:09,850
looking at some huge file if you don't

00:32:07,480 --> 00:32:12,610
want to you can zeroed in down in on the

00:32:09,850 --> 00:32:14,620
individual data another particular view

00:32:12,610 --> 00:32:16,870
that we consider very very important as

00:32:14,620 --> 00:32:19,450
a historical information because as it

00:32:16,870 --> 00:32:24,790
turns out there are test suite test

00:32:19,450 --> 00:32:26,470
suites that have flaky tests and it'll

00:32:24,790 --> 00:32:29,940
be phase of the moon

00:32:26,470 --> 00:32:32,140
it'll be different weather conditions

00:32:29,940 --> 00:32:34,840
sunspots whatever you want to call it

00:32:32,140 --> 00:32:36,130
that test will work and then it'll fail

00:32:34,840 --> 00:32:38,140
and then it'll work

00:32:36,130 --> 00:32:39,730
and then it'll work and it'll work it'll

00:32:38,140 --> 00:32:43,120
work for six weeks and then it'll fail

00:32:39,730 --> 00:32:45,730
and it tracking those things down is

00:32:43,120 --> 00:32:47,740
really not any fun it's an exercise in

00:32:45,730 --> 00:32:48,820
frustration now in this case here we're

00:32:47,740 --> 00:32:50,620
looking at something where we've got a

00:32:48,820 --> 00:32:55,120
real bright line fails all across the

00:32:50,620 --> 00:32:57,280
board and it was working prior on at

00:32:55,120 --> 00:32:58,960
least the arm architectures but on on

00:32:57,280 --> 00:33:01,810
some of the other ones here it was a

00:32:58,960 --> 00:33:03,640
skip now that probably brings up an

00:33:01,810 --> 00:33:04,690
interesting situation so

00:33:03,640 --> 00:33:06,670
went from something that was being

00:33:04,690 --> 00:33:08,500
skipped on a 32-bit arm device to now

00:33:06,670 --> 00:33:11,980
something that's failing we'll get to

00:33:08,500 --> 00:33:14,500
that in a minute okay so as a triage

00:33:11,980 --> 00:33:16,270
engineer is what we do is we have our

00:33:14,500 --> 00:33:18,430
team go out and create Bugzilla entries

00:33:16,270 --> 00:33:21,310
and so we start to collect you know data

00:33:18,430 --> 00:33:23,050
and get everything here in preparation

00:33:21,310 --> 00:33:24,310
for handing off to appropriate teams

00:33:23,050 --> 00:33:27,640
because if you have something that's a

00:33:24,310 --> 00:33:28,960
kernel error that is only specific to a

00:33:27,640 --> 00:33:30,160
particular board what you want to do is

00:33:28,960 --> 00:33:31,870
you want to bring in the team that

00:33:30,160 --> 00:33:33,160
supports that particular board and hand

00:33:31,870 --> 00:33:34,600
it off to them because it's probably not

00:33:33,160 --> 00:33:36,340
something that's a generic kernel issue

00:33:34,600 --> 00:33:39,850
it's probably something that's more just

00:33:36,340 --> 00:33:41,350
specific to their environment so anyways

00:33:39,850 --> 00:33:44,320
this is the particular bug entry that

00:33:41,350 --> 00:33:47,350
went with this particularly LTP failure

00:33:44,320 --> 00:33:50,530
and now this brings together another

00:33:47,350 --> 00:33:53,050
part of what I wanted to call out was

00:33:50,530 --> 00:33:57,130
this was a test case issue so when you

00:33:53,050 --> 00:33:59,080
notice before back in that trend page so

00:33:57,130 --> 00:34:01,630
on this one right here so it wasn't

00:33:59,080 --> 00:34:03,070
running on x-15 and then suddenly it was

00:34:01,630 --> 00:34:05,740
running on x-15 or at least had been

00:34:03,070 --> 00:34:08,740
attempted and it failed well that was

00:34:05,740 --> 00:34:11,710
because what had happened is that the

00:34:08,740 --> 00:34:14,440
test had been updated so our system

00:34:11,710 --> 00:34:16,120
right now doesn't really have a great

00:34:14,440 --> 00:34:18,250
way of calling out that oh by the way we

00:34:16,120 --> 00:34:19,690
just upgraded LTP so the test case might

00:34:18,250 --> 00:34:22,570
have changed so therefore you know

00:34:19,690 --> 00:34:24,610
something might have come from that but

00:34:22,570 --> 00:34:28,419
in this case right here there was a

00:34:24,610 --> 00:34:30,580
small update to the test this is

00:34:28,419 --> 00:34:33,280
actually the fix that was that was on

00:34:30,580 --> 00:34:35,140
the LTP mailing list and so this one was

00:34:33,280 --> 00:34:36,490
just a test case issue it was not

00:34:35,140 --> 00:34:37,600
something that was involving the Linux

00:34:36,490 --> 00:34:41,050
kernel in general it was not a

00:34:37,600 --> 00:34:44,020
regression you know for the most part

00:34:41,050 --> 00:34:48,130
not not a big deal but that's not always

00:34:44,020 --> 00:34:49,870
the case in this case here this is

00:34:48,130 --> 00:34:52,630
something that was from the huge T of

00:34:49,870 --> 00:34:54,550
the FS tests and so we had noticed

00:34:52,630 --> 00:34:57,070
something going on where you know you

00:34:54,550 --> 00:35:00,160
get the failure in the huge TLB FS tests

00:34:57,070 --> 00:35:01,840
that we run if something that we were

00:35:00,160 --> 00:35:03,400
able to bisect we'd go ahead and throw

00:35:01,840 --> 00:35:06,490
this out onto the Linux kernel mailing

00:35:03,400 --> 00:35:09,040
list and you know notify the maintainer

00:35:06,490 --> 00:35:12,640
hey thank you so much for you know the

00:35:09,040 --> 00:35:15,040
the report you know we did our jobs and

00:35:12,640 --> 00:35:16,960
therefore you know this bad patch was

00:35:15,040 --> 00:35:17,470
found it was fixed everything was was

00:35:16,960 --> 00:35:19,780
kosher

00:35:17,470 --> 00:35:21,099
which was great and that brings me to

00:35:19,780 --> 00:35:23,740
another thing that I you know I really

00:35:21,099 --> 00:35:27,430
want to point out here is well we're

00:35:23,740 --> 00:35:29,829
testing LTS and we're testing main line

00:35:27,430 --> 00:35:32,230
and we're testing Android common the

00:35:29,829 --> 00:35:34,869
place that we find where the most

00:35:32,230 --> 00:35:37,750
regressions are is actually on main line

00:35:34,869 --> 00:35:39,460
so just like you would expect you know

00:35:37,750 --> 00:35:41,470
the most interesting place to do Linux

00:35:39,460 --> 00:35:43,869
kernel development is on the mainline

00:35:41,470 --> 00:35:46,329
kernel you know no surprise here and

00:35:43,869 --> 00:35:48,670
it's also you know you can see with

00:35:46,329 --> 00:35:51,250
regular you know there's the regular

00:35:48,670 --> 00:35:52,660
cycle so when our C's open up with our C

00:35:51,250 --> 00:35:54,970
one you have the most current

00:35:52,660 --> 00:35:57,369
regressions that pop out and that's gets

00:35:54,970 --> 00:35:59,410
detected by the system as you go through

00:35:57,369 --> 00:36:02,670
the RC cycles and get down to our C 6

00:35:59,410 --> 00:36:06,160
and our C seven those things disappear

00:36:02,670 --> 00:36:08,050
so it's it's kind of I think affirming

00:36:06,160 --> 00:36:09,790
that the system is finding those things

00:36:08,050 --> 00:36:11,800
it is seeing and you know that kind of

00:36:09,790 --> 00:36:14,290
helps you know solidify on our minds

00:36:11,800 --> 00:36:18,099
that this is a good way to detect kernel

00:36:14,290 --> 00:36:20,740
regressions now you know we don't run

00:36:18,099 --> 00:36:21,849
every test suite on the planet we think

00:36:20,740 --> 00:36:24,520
there are a lot of test suites that are

00:36:21,849 --> 00:36:26,380
probably need to be written yet you know

00:36:24,520 --> 00:36:28,950
more to be done but at least this is a

00:36:26,380 --> 00:36:28,950
good start

00:36:30,450 --> 00:36:37,180
ok getting involved the biggest area

00:36:35,650 --> 00:36:38,650
that I think that people can can get

00:36:37,180 --> 00:36:40,869
involved and help things out is actually

00:36:38,650 --> 00:36:43,780
in the upstream world so you know

00:36:40,869 --> 00:36:46,150
there's the Linux table list so when an

00:36:43,780 --> 00:36:48,250
you know an RC comes out you know taking

00:36:46,150 --> 00:36:50,109
at taking a crack at those patches

00:36:48,250 --> 00:36:51,579
picking them up you know compiling them

00:36:50,109 --> 00:36:53,349
in those kernels and you know working

00:36:51,579 --> 00:36:54,790
with them in your world you know that's

00:36:53,349 --> 00:36:57,220
that's a contribution to the community

00:36:54,790 --> 00:36:58,599
and that's that's really meaningful you

00:36:57,220 --> 00:37:00,310
know working with the mainline our C's

00:36:58,599 --> 00:37:02,530
same thing that's a really valuable

00:37:00,310 --> 00:37:06,460
thing to go off and do and spend spend

00:37:02,530 --> 00:37:08,710
time and effort on improving tests and

00:37:06,460 --> 00:37:12,130
the test Suites themselves that's also a

00:37:08,710 --> 00:37:14,140
very very good thing to go off and do so

00:37:12,130 --> 00:37:16,060
getting involved to K self-test you know

00:37:14,140 --> 00:37:17,950
getting involved with LTP you know

00:37:16,060 --> 00:37:20,530
helping that kernel maintainer out who

00:37:17,950 --> 00:37:21,819
has a you know set of K self tests or

00:37:20,530 --> 00:37:23,589
maybe they don't even have any case self

00:37:21,819 --> 00:37:24,940
tests at all maybe we can help you know

00:37:23,589 --> 00:37:27,339
you can help convince them to do that

00:37:24,940 --> 00:37:29,640
and you just you know give them tests

00:37:27,339 --> 00:37:32,910
that's a really really you

00:37:29,640 --> 00:37:34,140
good thing to do to make the universe

00:37:32,910 --> 00:37:36,150
better which is kind of what this is

00:37:34,140 --> 00:37:38,099
this project is really all about you

00:37:36,150 --> 00:37:40,680
know finding these kernel regressions so

00:37:38,099 --> 00:37:42,359
that we as a kernel community can you

00:37:40,680 --> 00:37:44,369
know stand by our promise that we gave

00:37:42,359 --> 00:37:45,960
you a reliable kernel and we just gave

00:37:44,369 --> 00:37:47,579
you some fixes and we didn't regress

00:37:45,960 --> 00:37:49,680
those those fit you know we didn't

00:37:47,579 --> 00:37:51,779
regress the kernel so that you can you

00:37:49,680 --> 00:37:54,890
know continue to have confidence in

00:37:51,779 --> 00:37:58,349
what's been what's been given to you and

00:37:54,890 --> 00:37:59,700
you know for us as a project going

00:37:58,349 --> 00:38:02,099
forward you know we do think that more

00:37:59,700 --> 00:38:03,900
boards and more eyes ultimately are

00:38:02,099 --> 00:38:06,119
going to be making a difference now in

00:38:03,900 --> 00:38:10,559
our board farm you know we don't have a

00:38:06,119 --> 00:38:13,140
lot of boards but we do have plans where

00:38:10,559 --> 00:38:16,200
we will be talking and connect next week

00:38:13,140 --> 00:38:19,349
about how you know others can basically

00:38:16,200 --> 00:38:21,510
pick up lava and lkf tea and be able to

00:38:19,349 --> 00:38:23,250
run their own remote labs you know we we

00:38:21,510 --> 00:38:25,109
think this is something that you know we

00:38:23,250 --> 00:38:28,680
would like to see more of and help out

00:38:25,109 --> 00:38:30,869
and make that easier to do working with

00:38:28,680 --> 00:38:32,910
lava is a little bit of a challenge at

00:38:30,869 --> 00:38:34,950
least it has been but we've we put a lot

00:38:32,910 --> 00:38:37,559
of time and effort to to make that

00:38:34,950 --> 00:38:39,359
easier so look for look for that talk to

00:38:37,559 --> 00:38:42,720
be online here and uh I'm guessing

00:38:39,359 --> 00:38:44,490
probably about two to three weeks so you

00:38:42,720 --> 00:38:47,250
know another piece of this you know

00:38:44,490 --> 00:38:50,519
making the world better story is you

00:38:47,250 --> 00:38:52,289
know exercising more tests and it

00:38:50,519 --> 00:38:54,240
doesn't necessarily mean exercising

00:38:52,289 --> 00:38:57,059
kernel tests either you know it can be

00:38:54,240 --> 00:38:58,589
just running user space code as well you

00:38:57,059 --> 00:39:00,539
know is that necessary effective way of

00:38:58,589 --> 00:39:02,460
finding kernel regressions maybe maybe

00:39:00,539 --> 00:39:05,069
not but you know we have seen instances

00:39:02,460 --> 00:39:07,170
where for instance there was an LCS

00:39:05,069 --> 00:39:11,339
regression it only got detected because

00:39:07,170 --> 00:39:14,099
DHCP broke and it wasn't every version

00:39:11,339 --> 00:39:16,650
of DHC of dhb client so the embedded

00:39:14,099 --> 00:39:19,170
DHCP client P clients were just fine it

00:39:16,650 --> 00:39:20,730
was actually you know one that was the

00:39:19,170 --> 00:39:24,059
DHCP client that was on Ubuntu that

00:39:20,730 --> 00:39:25,500
found it so you know don't just take

00:39:24,059 --> 00:39:27,450
away from this that it's only K

00:39:25,500 --> 00:39:31,140
self-test and you have to have kernel

00:39:27,450 --> 00:39:31,859
test in order to find things so that's

00:39:31,140 --> 00:39:33,839
it

00:39:31,859 --> 00:39:35,130
I guess I'll open the floor up to

00:39:33,839 --> 00:39:39,500
questions if everybody has one and

00:39:35,130 --> 00:39:39,500
thanks for thanks for being here yes

00:39:47,150 --> 00:39:50,450
so with LT s itself

00:39:48,620 --> 00:39:52,280
LTS is really really stable it's a

00:39:50,450 --> 00:39:55,190
really rare day that you'll find a

00:39:52,280 --> 00:39:56,390
regression there in the case of again

00:39:55,190 --> 00:39:59,360
like mainline like I mentioned before

00:39:56,390 --> 00:40:00,860
that you know RC one you're going to

00:39:59,360 --> 00:40:02,780
probably have maybe like ten regressions

00:40:00,860 --> 00:40:05,320
that'll pop up from an average RC one

00:40:02,780 --> 00:40:05,320
that we've seen

00:40:13,400 --> 00:40:16,360
yes question

00:40:20,970 --> 00:40:26,280
okay so the question is is the compiler

00:40:24,329 --> 00:40:27,780
wasn't listed in the metadata so there's

00:40:26,280 --> 00:40:30,569
a little twist twist e on that

00:40:27,780 --> 00:40:32,670
particular page and so if I expanded it

00:40:30,569 --> 00:40:34,619
out there's a whole bunch of information

00:40:32,670 --> 00:40:37,770
that would would get included in the

00:40:34,619 --> 00:40:40,170
compiler is one of those lkf t is a

00:40:37,770 --> 00:40:41,520
project we were just about at that point

00:40:40,170 --> 00:40:45,089
where we're gonna start turning on the

00:40:41,520 --> 00:40:46,800
ability to run multiple compilers so you

00:40:45,089 --> 00:40:48,119
know clang belt kernels in particular

00:40:46,800 --> 00:40:56,970
something that really really is

00:40:48,119 --> 00:40:58,349
interesting to us well if there aren't

00:40:56,970 --> 00:41:02,780
any other questions again thanks for

00:40:58,349 --> 00:41:02,780

YouTube URL: https://www.youtube.com/watch?v=tc92uw3m-SI


