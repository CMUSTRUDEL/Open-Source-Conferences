Title: DjangoCon US 2017 - Butter smooth, interactive applications with Django... by Ganesh Swami
Publication date: 2017-09-08
Playlist: DjangoCon US 2017
Description: 
	DjangoCon US 2017 - Butter smooth, interactive applications with Django and Websockets by Ganesh Swami

Web applications have changed significantly over the years â€“ from simple static pages, to sprinkling interactiveness with JQuery/AJAX, to full dynamic single page apps. Through each evolution, weâ€™re adding more complexity, more data and more asynchronous behavior to our applications.

In this new world, where does the synchronous nature of Djangoâ€™s request-response cycle fit in?

My talk will focus on the topics around asynchronous Django applications. Iâ€™ll be sharing some lessons we learnt while building and scaling an interactive web application within the confines of Django and django-channels.

This topic is interesting because thereâ€™s been a lot of interest with meteor-like frameworks that have synchronized state between the frontend and backend. My intention is to show the audience that you can accomplish the same end-result with Django, without the need to learn and deploy a brand new framework.

An outline I have in mind:

What does asynchrony mean, and why you need it.

Traditional methods of achieving asynchrony (delayed jobs using worker queues like celery, long-polling for messaging, etc.)

Why django-channels changes the game.

How to architect your state.

What are the available options for deployment.

Gotchas, and what to do when things go wrong.

Just a basic knowledge of Django is required, as the topics are transferable to other frameworks. We did not have to monkey-patch any of the drivers to achieve asynchrony, so what youâ€™ll learn at my talk will apply cleanly to a stock Django.

This talk was presented at: https://2017.djangocon.us/talks/butter-smooth-interactive-applications-with-django-and-websockets/

LINKS:
Follow Ganesh Swami ðŸ‘‡
On Twitter: https://twitter.com/gane5h
Official homepage: http://www.silota.com

Follow DjangCon US ðŸ‘‡
https://twitter.com/djangocon

Follow DEFNA ðŸ‘‡
https://twitter.com/defnado
https://www.defna.org/
Captions: 
	00:00:00,000 --> 00:00:17,290
[Music]

00:00:13,420 --> 00:00:19,940
thanks mark you guys hear me good

00:00:17,290 --> 00:00:23,869
awesome excited to be here

00:00:19,940 --> 00:00:25,700
Django Khan my first Django Khan besides

00:00:23,869 --> 00:00:27,550
the people who are always Python

00:00:25,700 --> 00:00:30,290
community is a plus the food was

00:00:27,550 --> 00:00:31,790
exceptional I think a lot of people a

00:00:30,290 --> 00:00:35,260
lot of you guys are still in the food

00:00:31,790 --> 00:00:39,489
coma after lunch but let's take it easy

00:00:35,260 --> 00:00:42,260
so the title of my talk is butter smooth

00:00:39,489 --> 00:00:45,410
interactive applications with Django and

00:00:42,260 --> 00:00:48,680
WebSockets so I'm gonna be giving a

00:00:45,410 --> 00:00:50,510
little preview of interactiveness on the

00:00:48,680 --> 00:00:53,120
internet with regards to web

00:00:50,510 --> 00:00:56,510
applications and then build up to its

00:00:53,120 --> 00:00:58,340
django channels and WebSockets and the

00:00:56,510 --> 00:01:00,500
kinds of problems that be faced

00:00:58,340 --> 00:01:03,710
I'm not going to go too much detail into

00:01:00,500 --> 00:01:05,239
how web Django's channels work because

00:01:03,710 --> 00:01:07,280
it's a work in progress and there I

00:01:05,239 --> 00:01:10,160
believe there was a full tutorial on

00:01:07,280 --> 00:01:12,350
django channels and a lot of the other

00:01:10,160 --> 00:01:14,570
talks talk about Django channels

00:01:12,350 --> 00:01:16,880
specifically so I'm gonna be talking

00:01:14,570 --> 00:01:23,840
about the tooling and some of the

00:01:16,880 --> 00:01:26,840
deployment issues that we've had a more

00:01:23,840 --> 00:01:30,439
formal introduction about myself I've

00:01:26,840 --> 00:01:33,439
been working with Python data for over

00:01:30,439 --> 00:01:36,829
10 years started my career writing

00:01:33,439 --> 00:01:39,530
assembly programming and just woke my

00:01:36,829 --> 00:01:42,049
way up to up the stack so I'm like a

00:01:39,530 --> 00:01:44,329
full stack dev but stops at the at a

00:01:42,049 --> 00:01:48,049
silver level so I've written programs

00:01:44,329 --> 00:01:51,049
for GPUs a lot of that kind of stuff but

00:01:48,049 --> 00:01:54,469
I really love Python I love Django I

00:01:51,049 --> 00:01:56,780
love how clean and none of the magic nor

00:01:54,469 --> 00:01:59,360
the black box stuff you can just open up

00:01:56,780 --> 00:02:01,520
the code and see what's going on I've

00:01:59,360 --> 00:02:02,860
been doing data analysis and sequel for

00:02:01,520 --> 00:02:06,740
the past couple of years

00:02:02,860 --> 00:02:12,380
my claim to fame is I wrote the first

00:02:06,740 --> 00:02:14,630
wiki engine for Emacs and wiki blog

00:02:12,380 --> 00:02:17,360
engine so that was pretty cool it was

00:02:14,630 --> 00:02:19,790
accepted into mainland mainland Emacs

00:02:17,360 --> 00:02:22,760
and this was a long time ago I currently

00:02:19,790 --> 00:02:24,709
run Saluda which is a is a is a data

00:02:22,760 --> 00:02:26,640
analysis tool for professional data

00:02:24,709 --> 00:02:31,769
analysts

00:02:26,640 --> 00:02:34,019
sequel recipes which our product is

00:02:31,769 --> 00:02:36,769
something like this this is just to give

00:02:34,019 --> 00:02:39,540
you a context on the challenges we faced

00:02:36,769 --> 00:02:42,209
you type in sequel there it's a text box

00:02:39,540 --> 00:02:44,670
and you hit run and it creates these

00:02:42,209 --> 00:02:47,129
charts and then you can schedule these

00:02:44,670 --> 00:02:49,019
chart share these charts and do whatever

00:02:47,129 --> 00:02:52,129
you want so that's essentially our

00:02:49,019 --> 00:02:55,200
product who uses our product

00:02:52,129 --> 00:02:58,799
professional data analysts so if your

00:02:55,200 --> 00:03:00,989
it's not sequel like the ORM style

00:02:58,799 --> 00:03:03,510
sequel it's for building histograms

00:03:00,989 --> 00:03:05,640
correlations doing forecasting

00:03:03,510 --> 00:03:07,920
regressions all the kinds of data

00:03:05,640 --> 00:03:10,799
analysis stuff that you would do but

00:03:07,920 --> 00:03:13,980
using sequel so if you google for Saluda

00:03:10,799 --> 00:03:15,810
sequel recipes there's a full list of I

00:03:13,980 --> 00:03:16,560
think two dozen recipes you can

00:03:15,810 --> 00:03:24,359
copy/paste

00:03:16,560 --> 00:03:27,450
everything is straight-up sequel so this

00:03:24,359 --> 00:03:31,139
is a timeline of asynchronous behavior

00:03:27,450 --> 00:03:33,980
on the web how many of you guys are

00:03:31,139 --> 00:03:37,639
familiar with iframes

00:03:33,980 --> 00:03:40,049
that's awesome so but 20 years ago

00:03:37,639 --> 00:03:42,750
iframes was how you be you get

00:03:40,049 --> 00:03:44,700
interactive web applications if you guys

00:03:42,750 --> 00:03:47,700
are familiar with MapQuest and some of

00:03:44,700 --> 00:03:50,160
the I guess the pre web 1.0 kind of

00:03:47,700 --> 00:03:53,310
applications you click a button and then

00:03:50,160 --> 00:03:56,099
it dynamically generates iframe URLs and

00:03:53,310 --> 00:03:58,019
then it refreshes I believe in even

00:03:56,099 --> 00:03:59,970
hotmail the first version of hotmail

00:03:58,019 --> 00:04:02,340
worked that way so you click send and

00:03:59,970 --> 00:04:06,120
then it refreshes his iframe so that was

00:04:02,340 --> 00:04:09,900
like interactive web apps and then

00:04:06,120 --> 00:04:13,709
around 99 Microsoft introduced xml

00:04:09,900 --> 00:04:16,349
httprequest which is the precursor to

00:04:13,709 --> 00:04:20,940
ajax it's a way of creating asynchronous

00:04:16,349 --> 00:04:23,130
request responses around 2004 Gmail

00:04:20,940 --> 00:04:26,160
launched and Gmail was the first I would

00:04:23,130 --> 00:04:28,590
say kind of a single-page app so there

00:04:26,160 --> 00:04:33,690
was no full page refresh when you hit

00:04:28,590 --> 00:04:37,580
send to send an email around 2005 Ajax

00:04:33,690 --> 00:04:39,800
the dome Ajax was coined 2005 was when

00:04:37,580 --> 00:04:43,970
Django was

00:04:39,800 --> 00:04:46,970
released publicly and then 2012

00:04:43,970 --> 00:04:48,860
meteor.js how many of you guys are

00:04:46,970 --> 00:04:49,669
familiar with meteor.js or heard of

00:04:48,860 --> 00:04:53,479
awesome

00:04:49,669 --> 00:04:55,520
so meteors is like was mind-blowing when

00:04:53,479 --> 00:04:59,090
I first saw well how it worked

00:04:55,520 --> 00:05:01,460
so it was like interactive fluid web

00:04:59,090 --> 00:05:03,770
framework where there was a subset of

00:05:01,460 --> 00:05:06,409
your database being held on the front

00:05:03,770 --> 00:05:08,180
end so you query your front-end and it's

00:05:06,409 --> 00:05:10,460
it's pretty fluid it's pretty amazing

00:05:08,180 --> 00:05:14,710
how it all works I I still don't know if

00:05:10,460 --> 00:05:18,680
it's a good idea but it's pretty sweet

00:05:14,710 --> 00:05:21,560
2014 react was public started gaining

00:05:18,680 --> 00:05:25,490
adoption I believe that's when the

00:05:21,560 --> 00:05:28,940
single page app acronym s PA was started

00:05:25,490 --> 00:05:30,710
getting into the mainstream 2016 I

00:05:28,940 --> 00:05:35,090
believe there's a small framework called

00:05:30,710 --> 00:05:38,210
rails they now include WebSockets

00:05:35,090 --> 00:05:42,940
support into their mainline they call it

00:05:38,210 --> 00:05:50,210
act action cable so that's roughly the

00:05:42,940 --> 00:05:52,190
outline of interactiveness on the web so

00:05:50,210 --> 00:05:55,330
this is a very common way to visualize

00:05:52,190 --> 00:05:58,340
how technologies grow and get adopted

00:05:55,330 --> 00:06:02,060
across a wide spectrum so I would say

00:05:58,340 --> 00:06:04,219
pre 2004 a lot of the innovative web's a

00:06:02,060 --> 00:06:07,669
lot of risky applications were being

00:06:04,219 --> 00:06:09,080
built probably only 10 or 15% of the

00:06:07,669 --> 00:06:12,889
browsers out there support of the

00:06:09,080 --> 00:06:14,779
technologies but those are that's the

00:06:12,889 --> 00:06:17,840
innovative innovation and

00:06:14,779 --> 00:06:21,560
interactiveness being introduced 2004 to

00:06:17,840 --> 00:06:23,870
2014 early majority big teams a lot of

00:06:21,560 --> 00:06:26,360
resources very expensive to build these

00:06:23,870 --> 00:06:30,860
interactive web apps but it was being

00:06:26,360 --> 00:06:33,740
done case in case in point Gmail Google

00:06:30,860 --> 00:06:38,900
Maps a lot of the first version of the

00:06:33,740 --> 00:06:42,289
web streaming services and so on 2014

00:06:38,900 --> 00:06:44,930
and up to now I believe you're inching

00:06:42,289 --> 00:06:46,930
towards the promised land it's a lot of

00:06:44,930 --> 00:06:49,370
the best practices have been established

00:06:46,930 --> 00:06:52,279
there's still some challenges on the

00:06:49,370 --> 00:06:52,970
fringes but more or less we understand

00:06:52,279 --> 00:06:55,130
how to build

00:06:52,970 --> 00:06:57,950
single page app what are the concerns

00:06:55,130 --> 00:06:59,930
what are the difficulties there at least

00:06:57,950 --> 00:07:02,630
three or four mature front-end

00:06:59,930 --> 00:07:05,570
frameworks that that look out-of-the-box

00:07:02,630 --> 00:07:08,450
view Jas is a popular one react.js is

00:07:05,570 --> 00:07:11,300
another popular one a lot of folks use

00:07:08,450 --> 00:07:13,130
Ember GS so that's pretty awesome so I

00:07:11,300 --> 00:07:15,770
think we're getting there

00:07:13,130 --> 00:07:18,710
between 2014 around then there have been

00:07:15,770 --> 00:07:22,490
a lot of the commercial applications of

00:07:18,710 --> 00:07:24,350
these fluid you know push notifications

00:07:22,490 --> 00:07:28,040
and other kind of stuff so socket IO

00:07:24,350 --> 00:07:31,670
pusher firebase meteor GS these are all

00:07:28,040 --> 00:07:34,420
a hybrid of open source and a back end

00:07:31,670 --> 00:07:42,920
as a service kind of system to have

00:07:34,420 --> 00:07:46,880
interactive web apps so the main

00:07:42,920 --> 00:07:49,010
question is why do you need this like

00:07:46,880 --> 00:07:51,020
what's uh what's the need

00:07:49,010 --> 00:07:54,970
right because Jango has been around for

00:07:51,020 --> 00:07:58,310
ten plus years and it works pretty sweet

00:07:54,970 --> 00:08:00,970
why would you want to change something

00:07:58,310 --> 00:08:04,070
that'sthat's working perfectly fine so

00:08:00,970 --> 00:08:07,669
in sort of answering this broad question

00:08:04,070 --> 00:08:10,970
about why I'm gonna be scoping it into

00:08:07,669 --> 00:08:14,110
our web app and why we saw the need for

00:08:10,970 --> 00:08:19,060
web sockets and interactiveness and why

00:08:14,110 --> 00:08:19,060
just regular web apps didn't cut it

00:08:23,460 --> 00:08:29,010
so as I mentioned our product is a is a

00:08:25,920 --> 00:08:32,580
sequel editor essentially you have a

00:08:29,010 --> 00:08:35,010
text box you hit run and then it creates

00:08:32,580 --> 00:08:36,990
these charts and then you go through

00:08:35,010 --> 00:08:39,210
this workflow over and over and over

00:08:36,990 --> 00:08:42,720
again so that's basically what our

00:08:39,210 --> 00:08:45,900
product does so if you were to draw a

00:08:42,720 --> 00:08:47,940
schematic on how this works you have the

00:08:45,900 --> 00:08:50,790
app which is the web app running the

00:08:47,940 --> 00:08:53,190
browser there's an ajax request that

00:08:50,790 --> 00:08:55,710
reaches the back end and then the back

00:08:53,190 --> 00:08:59,180
end which is django executes the sequel

00:08:55,710 --> 00:09:02,160
query and then returns a HTTP response

00:08:59,180 --> 00:09:05,400
so that's basically the the lifecycle of

00:09:02,160 --> 00:09:08,040
your one one single iteration if there

00:09:05,400 --> 00:09:10,530
is a mistake in your sequel your execute

00:09:08,040 --> 00:09:12,480
c-cool throws an exception and then it's

00:09:10,530 --> 00:09:12,990
sent back as an HTTP response for the

00:09:12,480 --> 00:09:15,660
right

00:09:12,990 --> 00:09:19,830
error code and your friend and handles

00:09:15,660 --> 00:09:22,430
that so this this work for you know

00:09:19,830 --> 00:09:25,260
version 1.0 when we had no users

00:09:22,430 --> 00:09:27,540
everything worked great so it's always

00:09:25,260 --> 00:09:31,200
pretty fun to see you hit run and then

00:09:27,540 --> 00:09:33,120
it it works okay so awesome so let's go

00:09:31,200 --> 00:09:35,400
to production the minute we hit

00:09:33,120 --> 00:09:37,560
production and once we got a couple of

00:09:35,400 --> 00:09:39,630
users we started seeing these problems

00:09:37,560 --> 00:09:41,670
that were creeping up so I'm just going

00:09:39,630 --> 00:09:45,150
to enumerate some of the problems we've

00:09:41,670 --> 00:09:51,690
had with this regular request response

00:09:45,150 --> 00:09:56,040
cycle the first problem is unbounded run

00:09:51,690 --> 00:09:59,070
time for the request so here essentially

00:09:56,040 --> 00:10:02,760
what's happening is we let the user type

00:09:59,070 --> 00:10:04,950
in arbitrary sequel so we do not know

00:10:02,760 --> 00:10:07,260
beforehand how long this sequel is going

00:10:04,950 --> 00:10:09,150
to take it could take you know three

00:10:07,260 --> 00:10:11,040
minutes it could take 30 minutes it

00:10:09,150 --> 00:10:13,290
could take half a day nobody knows

00:10:11,040 --> 00:10:15,030
because it's up to the user what what

00:10:13,290 --> 00:10:18,450
kind of model or what kind of analytics

00:10:15,030 --> 00:10:20,100
they're running so the problem was some

00:10:18,450 --> 00:10:22,230
of our users were typing their sequel

00:10:20,100 --> 00:10:24,420
hitting run and then closing their

00:10:22,230 --> 00:10:27,600
laptop because they knew it's gonna take

00:10:24,420 --> 00:10:29,280
half a day to run the query and from our

00:10:27,600 --> 00:10:31,320
side you know having that connection

00:10:29,280 --> 00:10:34,080
that recurse response coming back and

00:10:31,320 --> 00:10:39,170
restoring the state was being was a big

00:10:34,080 --> 00:10:39,170
challenge so that's the first difficulty

00:10:40,630 --> 00:10:46,990
the second difficulty was what is this

00:10:43,120 --> 00:10:49,180
what we call 8:00 a.m. traffic spikes so

00:10:46,990 --> 00:10:51,400
in our product you can organise the

00:10:49,180 --> 00:10:53,110
sequel queries into a dashboard so you

00:10:51,400 --> 00:10:55,870
can have half a dozen to a dozen

00:10:53,110 --> 00:11:00,430
different charts and create a dashboard

00:10:55,870 --> 00:11:02,440
and at 8:00 a.m. our users load up these

00:11:00,430 --> 00:11:04,570
dashboards and you have 15 queries

00:11:02,440 --> 00:11:06,760
hitting our back-end and they're all

00:11:04,570 --> 00:11:09,430
trying to run and so the the ratio

00:11:06,760 --> 00:11:13,030
between the peak load to the low point

00:11:09,430 --> 00:11:15,070
was about 7x so you had to provision 7x

00:11:13,030 --> 00:11:18,610
the number of servers and resources to

00:11:15,070 --> 00:11:20,980
handle that load so when I casually

00:11:18,610 --> 00:11:22,750
talked to my non-technical friends I'm

00:11:20,980 --> 00:11:24,760
so yeah I was at the office at 8:00 a.m.

00:11:22,750 --> 00:11:26,740
it's like oh good for you you wake up at

00:11:24,760 --> 00:11:28,360
6 hit the gym go for a run make your

00:11:26,740 --> 00:11:31,270
breakfast and then you were at work at

00:11:28,360 --> 00:11:33,490
8:00 a.m. no actually no I I get paged

00:11:31,270 --> 00:11:35,050
at 7:55 that the servers are down and

00:11:33,490 --> 00:11:37,330
they're rushed to the office to fix them

00:11:35,050 --> 00:11:39,810
but I don't tell them and say yeah I hit

00:11:37,330 --> 00:11:43,060
the gym and you know do all that stuff

00:11:39,810 --> 00:11:45,580
the third challenge was about deployment

00:11:43,060 --> 00:11:48,100
because the Django servers were actually

00:11:45,580 --> 00:11:50,680
executing these queries you couldn't

00:11:48,100 --> 00:11:54,520
really swap out new versions of the code

00:11:50,680 --> 00:11:57,430
so if you have let's say five servers

00:11:54,520 --> 00:11:59,170
that are executing these sequel queries

00:11:57,430 --> 00:12:02,400
and they could take anywhere from 30

00:11:59,170 --> 00:12:04,030
minutes to let's say three hours

00:12:02,400 --> 00:12:06,100
deployment was a problem because

00:12:04,030 --> 00:12:08,860
deployment would kill that executing

00:12:06,100 --> 00:12:12,130
query and the user would never see the

00:12:08,860 --> 00:12:14,440
results so you know we believe in active

00:12:12,130 --> 00:12:16,600
deployments quick deployments the minute

00:12:14,440 --> 00:12:19,270
the unit tests change or they succeed

00:12:16,600 --> 00:12:20,800
they just push into production but we

00:12:19,270 --> 00:12:23,740
were not able to do that because our

00:12:20,800 --> 00:12:25,660
users queries were failing or were being

00:12:23,740 --> 00:12:28,720
terminated so that was a big challenge

00:12:25,660 --> 00:12:30,450
so that is you know a summary of the

00:12:28,720 --> 00:12:34,330
challenges that we've had with

00:12:30,450 --> 00:12:38,770
synchronous request response cycle so we

00:12:34,330 --> 00:12:40,960
had to look for a alternate solution so

00:12:38,770 --> 00:12:42,730
looking around you know I think I met

00:12:40,960 --> 00:12:45,070
Andrew last year or the year before and

00:12:42,730 --> 00:12:46,990
he was just starting out maybe this is

00:12:45,070 --> 00:12:49,660
like version point zero zero one of

00:12:46,990 --> 00:12:51,400
Jango channels and I was pretty excited

00:12:49,660 --> 00:12:53,200
about it it's like okay Janet

00:12:51,400 --> 00:12:55,630
your channel seems like the Holy Grail

00:12:53,200 --> 00:12:59,770
right what can go wrong so let's let's

00:12:55,630 --> 00:13:02,140
play with it and so high level how

00:12:59,770 --> 00:13:05,200
django channel works is that you still

00:13:02,140 --> 00:13:07,720
have your synchronous request response

00:13:05,200 --> 00:13:09,930
cycle which is under on the top half and

00:13:07,720 --> 00:13:12,580
then you have a persistent

00:13:09,930 --> 00:13:16,210
bi-directional connection based on

00:13:12,580 --> 00:13:19,840
WebSockets in the lower half and so you

00:13:16,210 --> 00:13:22,690
send a message to your back-end to the

00:13:19,840 --> 00:13:25,510
Ajax request and then the back end sends

00:13:22,690 --> 00:13:28,600
in the response through HP response just

00:13:25,510 --> 00:13:30,490
as usual but at the same time you can

00:13:28,600 --> 00:13:33,760
send messages back and forth through the

00:13:30,490 --> 00:13:36,940
WebSocket so your server can initiate a

00:13:33,760 --> 00:13:38,680
message without having a matching HTTP

00:13:36,940 --> 00:13:42,610
request or Ajax request

00:13:38,680 --> 00:13:45,370
so that's conceptually how WebSockets or

00:13:42,610 --> 00:13:47,680
Django channels work they don't replace

00:13:45,370 --> 00:13:54,010
anything it's just an add-on to your

00:13:47,680 --> 00:13:56,860
existing workflow so the the method we

00:13:54,010 --> 00:13:59,710
used was you continue to so when our

00:13:56,860 --> 00:14:02,830
users hit run it still makes a HTTP

00:13:59,710 --> 00:14:06,370
request to your back in and then your

00:14:02,830 --> 00:14:09,730
back end which is Django elf loads it to

00:14:06,370 --> 00:14:13,030
this worker queue excuse a sequel and

00:14:09,730 --> 00:14:15,540
once it's done using WebSockets notifies

00:14:13,030 --> 00:14:20,220
the front-end that the results are ready

00:14:15,540 --> 00:14:20,220
so we're able to push it out of band

00:14:22,890 --> 00:14:28,510
so the just as a thought experiment the

00:14:26,320 --> 00:14:31,780
alternate old-school approach would

00:14:28,510 --> 00:14:34,720
would have been using a thread on the on

00:14:31,780 --> 00:14:37,750
the front end to pull your back end for

00:14:34,720 --> 00:14:40,870
results and if there were results you

00:14:37,750 --> 00:14:43,390
get a response but then that's undue

00:14:40,870 --> 00:14:45,430
load right you can't set the polling

00:14:43,390 --> 00:14:47,050
interval based on the query because you

00:14:45,430 --> 00:14:48,870
don't know so you're gonna hit the back

00:14:47,050 --> 00:14:53,200
end let's say every 30 seconds and

00:14:48,870 --> 00:14:56,830
that's gonna break if the user queries

00:14:53,200 --> 00:15:04,230
only take two seconds to run so the long

00:14:56,830 --> 00:15:06,670
pulling approach had its own issues so

00:15:04,230 --> 00:15:09,160
pretty amazing just went to the

00:15:06,670 --> 00:15:11,710
documentation copy paste examples into

00:15:09,160 --> 00:15:13,720
our code two days and we had it all

00:15:11,710 --> 00:15:15,670
working at least was working everything

00:15:13,720 --> 00:15:18,010
was working on my laptop okay

00:15:15,670 --> 00:15:21,550
amazing let's go out for drinks because

00:15:18,010 --> 00:15:24,730
this project is done you know where can

00:15:21,550 --> 00:15:28,090
I sign up for my bonus check well no not

00:15:24,730 --> 00:15:29,860
really it took us about six weeks to

00:15:28,090 --> 00:15:32,530
make it production ready

00:15:29,860 --> 00:15:33,640
so going from our laptop to our cluster

00:15:32,530 --> 00:15:36,340
servers

00:15:33,640 --> 00:15:38,710
took a lot of time so you can copy/paste

00:15:36,340 --> 00:15:40,720
examples from the Jango channels but the

00:15:38,710 --> 00:15:43,120
rest of my talk is going to go into the

00:15:40,720 --> 00:15:45,730
challenges we faced taking it to

00:15:43,120 --> 00:15:49,570
production which I guess is the meat of

00:15:45,730 --> 00:15:54,010
my presentation so it works it all out

00:15:49,570 --> 00:15:57,550
on my laptop you know an MVP it's a

00:15:54,010 --> 00:15:59,500
proof of concept the challenges seem to

00:15:57,550 --> 00:16:01,030
you know that it looked promising so

00:15:59,500 --> 00:16:03,610
this is when you sit down and write a

00:16:01,030 --> 00:16:04,780
business case for how to reorder tech

00:16:03,610 --> 00:16:06,310
your app because this is pretty

00:16:04,780 --> 00:16:08,380
expensive you're writing the core or

00:16:06,310 --> 00:16:14,800
rewriting the core of how you're doing

00:16:08,380 --> 00:16:17,440
work so we came up with this a list of

00:16:14,800 --> 00:16:21,370
bullet points and I'll just walk through

00:16:17,440 --> 00:16:23,980
them so the the big overarching aim of

00:16:21,370 --> 00:16:26,110
this project was to make the backend the

00:16:23,980 --> 00:16:28,900
driver of work the front end just

00:16:26,110 --> 00:16:31,900
because the user says run this we're not

00:16:28,900 --> 00:16:34,210
going to obey that command we're going

00:16:31,900 --> 00:16:35,570
to schedule it and work on that query

00:16:34,210 --> 00:16:38,209
when VC

00:16:35,570 --> 00:16:39,410
when we see is a good time so we're

00:16:38,209 --> 00:16:43,160
going to be the back end is going to be

00:16:39,410 --> 00:16:46,790
the driver rather than the client saying

00:16:43,160 --> 00:16:49,279
hain handling of state you know they the

00:16:46,790 --> 00:16:52,040
state could be a query is in progress

00:16:49,279 --> 00:16:54,579
the query has failed the query has

00:16:52,040 --> 00:16:57,139
succeeded the query is ready to be run

00:16:54,579 --> 00:16:58,850
and then there disconnections in the

00:16:57,139 --> 00:17:01,519
middle because people could go to trains

00:16:58,850 --> 00:17:03,529
people could shut down their laptop so

00:17:01,519 --> 00:17:05,299
you just have to you know map out all

00:17:03,529 --> 00:17:07,459
the possible states and try to

00:17:05,299 --> 00:17:12,230
understand what's going on just a clear

00:17:07,459 --> 00:17:14,329
picture server-side events there are

00:17:12,230 --> 00:17:16,250
lots of approaches for doing this but

00:17:14,329 --> 00:17:19,160
the silver should be able to communicate

00:17:16,250 --> 00:17:21,829
new data to the front end without the

00:17:19,160 --> 00:17:24,980
front end asking for it I think that's a

00:17:21,829 --> 00:17:27,319
very powerful concept no propriety

00:17:24,980 --> 00:17:29,720
solutions not that I'm against propriety

00:17:27,319 --> 00:17:32,330
solutions but I feel that when you're

00:17:29,720 --> 00:17:34,660
working with brand-new technology it's a

00:17:32,330 --> 00:17:37,490
lot harder to debug propriety technology

00:17:34,660 --> 00:17:41,659
solutions so one of the difficulties I

00:17:37,490 --> 00:17:44,299
have had with socket IO is you have to

00:17:41,659 --> 00:17:47,950
run socket IO on the back end which is

00:17:44,299 --> 00:17:52,549
no js' and it was pretty challenging to

00:17:47,950 --> 00:17:54,620
debug what was going on because I come

00:17:52,549 --> 00:17:58,040
from a Python back-end and debugging and

00:17:54,620 --> 00:18:00,380
the external stack was was a challenge

00:17:58,040 --> 00:18:03,559
keep investments in Python plus Django

00:18:00,380 --> 00:18:05,299
stack I guess what a lot of other people

00:18:03,559 --> 00:18:08,030
would have done is they were just thrown

00:18:05,299 --> 00:18:11,179
in meteor j/s or a node.js stack and

00:18:08,030 --> 00:18:14,630
then offload this asynchronous component

00:18:11,179 --> 00:18:15,830
and due to no js' and let no js' deal

00:18:14,630 --> 00:18:17,450
with this because there are lots of

00:18:15,830 --> 00:18:20,150
frameworks on nodejs that help you do

00:18:17,450 --> 00:18:22,370
this we did not want to do that because

00:18:20,150 --> 00:18:24,260
every time you have an architectural

00:18:22,370 --> 00:18:27,169
decision and you add a new layer to the

00:18:24,260 --> 00:18:30,200
stack i think your your product becomes

00:18:27,169 --> 00:18:31,850
kind of a Frankenstein product and it

00:18:30,200 --> 00:18:33,440
just it's just too much to keep in your

00:18:31,850 --> 00:18:35,059
head because now if you're trying to

00:18:33,440 --> 00:18:37,040
hire someone there you're asking them

00:18:35,059 --> 00:18:39,409
for like react front-end experience

00:18:37,040 --> 00:18:41,720
you're asking them for Django experience

00:18:39,409 --> 00:18:43,820
you're asking for no J's experience and

00:18:41,720 --> 00:18:46,190
then the deployment options it's just

00:18:43,820 --> 00:18:49,170
too much so we wanted to keep everything

00:18:46,190 --> 00:18:53,310
standard out-of-the-box Python

00:18:49,170 --> 00:18:55,440
Django off-the-shelf AWS components our

00:18:53,310 --> 00:18:59,130
stack is completely on Amazon Web

00:18:55,440 --> 00:19:01,650
Services so we do not want to build

00:18:59,130 --> 00:19:04,860
something custom which means no

00:19:01,650 --> 00:19:07,260
recompiling nginx to add WebSocket

00:19:04,860 --> 00:19:09,210
support because we wanted to use

00:19:07,260 --> 00:19:12,360
Amazon's load balancer for example

00:19:09,210 --> 00:19:13,440
because it has a lot of benefits it

00:19:12,360 --> 00:19:16,260
gives you health checks

00:19:13,440 --> 00:19:20,040
it has good logging a good logging

00:19:16,260 --> 00:19:21,810
framework it does DDoS attacks a lot of

00:19:20,040 --> 00:19:24,090
lot of good features and we wanted to

00:19:21,810 --> 00:19:25,730
tie into that ecosystem so it didn't

00:19:24,090 --> 00:19:28,260
make sense a lot of sense for us to

00:19:25,730 --> 00:19:35,670
bring in our own infrastructure

00:19:28,260 --> 00:19:38,640
components so roughly this is this is

00:19:35,670 --> 00:19:41,330
our architecture diagram so we have our

00:19:38,640 --> 00:19:43,740
clients on the bottom which could be I

00:19:41,330 --> 00:19:46,860
just found this in some kind of stencil

00:19:43,740 --> 00:19:48,930
program there it's a phone it's a laptop

00:19:46,860 --> 00:19:51,930
and it's a desktop so three kinds of

00:19:48,930 --> 00:19:54,540
clients and they connect you a load

00:19:51,930 --> 00:19:57,840
balancer which has WebSocket support and

00:19:54,540 --> 00:20:00,990
these are the load balancer then starts

00:19:57,840 --> 00:20:02,700
to load balance to a back-end which

00:20:00,990 --> 00:20:05,010
could be the web sockets plus the

00:20:02,700 --> 00:20:07,440
regular g-unit con so it's a it's a

00:20:05,010 --> 00:20:09,810
hybrid it with the synchronous in the

00:20:07,440 --> 00:20:12,270
asynchronous part and then Redis is the

00:20:09,810 --> 00:20:15,150
persistent layer where the channels are

00:20:12,270 --> 00:20:17,610
being shared so if you go through the

00:20:15,150 --> 00:20:21,000
Django channel's documentation this is

00:20:17,610 --> 00:20:22,680
one approach that's recommended using

00:20:21,000 --> 00:20:24,410
Redis as the backing server and of

00:20:22,680 --> 00:20:26,640
course you still have your standard

00:20:24,410 --> 00:20:28,950
Django components you have a database

00:20:26,640 --> 00:20:35,190
you have your RM and all that stuff but

00:20:28,950 --> 00:20:38,250
roughly this is the architecture so now

00:20:35,190 --> 00:20:41,760
the challenges why did it take us six

00:20:38,250 --> 00:20:43,350
weeks you know that's that's a little

00:20:41,760 --> 00:20:45,240
odd you know did I go on vacation for

00:20:43,350 --> 00:20:47,160
four weeks doing the project no not

00:20:45,240 --> 00:20:48,420
really because we were iterating through

00:20:47,160 --> 00:20:49,920
the solutions and we found that

00:20:48,420 --> 00:20:51,780
something was wrong and then we had to

00:20:49,920 --> 00:20:53,130
go back to the drawing board and then we

00:20:51,780 --> 00:20:55,260
were trying to swap out this stuff I

00:20:53,130 --> 00:20:57,150
think there was some conflict with our

00:20:55,260 --> 00:20:59,460
initial motivations and our business

00:20:57,150 --> 00:21:03,149
plan where we wanted to stick to just a

00:20:59,460 --> 00:21:05,399
Python stack so it was a lot lot

00:21:03,149 --> 00:21:08,580
or effort to get it to work but I think

00:21:05,399 --> 00:21:11,129
in now I'm really happy with how it's

00:21:08,580 --> 00:21:13,229
all working out and going forward it's

00:21:11,129 --> 00:21:16,619
gonna be a breeze to maintain because

00:21:13,229 --> 00:21:19,049
there's no custom code anywhere so the

00:21:16,619 --> 00:21:20,729
first challenge was cloud deployment I'm

00:21:19,049 --> 00:21:27,749
gonna go step by step into the

00:21:20,729 --> 00:21:29,460
challenges we faced so if you remember

00:21:27,749 --> 00:21:31,769
the architecture diagram we need a load

00:21:29,460 --> 00:21:34,769
balancer in front of G you know Khan and

00:21:31,769 --> 00:21:36,509
the asynchronous web server the problem

00:21:34,769 --> 00:21:40,109
with a lot of these standard

00:21:36,509 --> 00:21:43,379
off-the-shelf webs load balancers is

00:21:40,109 --> 00:21:45,719
that they're HTTP load balancers but

00:21:43,379 --> 00:21:48,749
what WebSockets needs is a TCP load

00:21:45,719 --> 00:21:50,940
balancer so all the stuff if you're

00:21:48,749 --> 00:21:53,969
familiar with Django's cookie base

00:21:50,940 --> 00:21:56,190
authentication cookies are HTTP layer

00:21:53,969 --> 00:21:58,200
concern so if you have a TCP load

00:21:56,190 --> 00:21:59,879
balancer you can't really attach that

00:21:58,200 --> 00:22:01,710
cookies like it can't read the cookies

00:21:59,879 --> 00:22:03,809
so if you're trying to have sticky

00:22:01,710 --> 00:22:07,049
sessions based on cookies it's not

00:22:03,809 --> 00:22:08,909
really gonna work and I was surprised to

00:22:07,049 --> 00:22:10,950
see this but look a lot of the load

00:22:08,909 --> 00:22:13,649
balancers out there on the cloud we're

00:22:10,950 --> 00:22:17,969
all HTTP load balancers so Google Cloud

00:22:13,649 --> 00:22:20,219
Azure Amazon but fortunately Amazon

00:22:17,969 --> 00:22:22,379
launched a brand new load balancer last

00:22:20,219 --> 00:22:24,299
summer called the application load

00:22:22,379 --> 00:22:28,799
balancer which is a TCP level load

00:22:24,299 --> 00:22:30,929
balancer but the problem with a lot of

00:22:28,799 --> 00:22:32,609
Amazon's products there is is that the

00:22:30,929 --> 00:22:36,269
documentation is just straight out wrong

00:22:32,609 --> 00:22:37,769
or they say yeah we don't recommend you

00:22:36,269 --> 00:22:41,429
doing this but that is exactly what you

00:22:37,769 --> 00:22:42,659
need to do so I was kind of fortunate

00:22:41,429 --> 00:22:45,419
that I was taking the train from

00:22:42,659 --> 00:22:48,179
Vancouver BC which is home for me down

00:22:45,419 --> 00:22:50,460
to Portland for PyCon and one of the

00:22:48,179 --> 00:22:52,440
elastic Beanstalk engineer has gone on

00:22:50,460 --> 00:22:54,299
the train so I just fed him like tons of

00:22:52,440 --> 00:22:56,190
beer and asked him like why the hell is

00:22:54,299 --> 00:22:58,229
this not working what's wrong with this

00:22:56,190 --> 00:22:59,369
why is it documentation wrong what do

00:22:58,229 --> 00:23:01,440
you have three versions of the same

00:22:59,369 --> 00:23:04,229
stuff which are all like in different

00:23:01,440 --> 00:23:06,089
layers of compatibility so the lesson

00:23:04,229 --> 00:23:08,369
here is make sure it's working with the

00:23:06,089 --> 00:23:09,899
application load balancer the

00:23:08,369 --> 00:23:11,369
deployments on your laptop are very

00:23:09,899 --> 00:23:14,489
different from the deployments on the

00:23:11,369 --> 00:23:16,590
cloud and try to try to figure out how

00:23:14,489 --> 00:23:23,820
application load balancer works with

00:23:16,590 --> 00:23:28,350
rest of your stack the second challenge

00:23:23,820 --> 00:23:31,620
we had was to do with missed messages on

00:23:28,350 --> 00:23:34,350
disconnect so here's an example let's

00:23:31,620 --> 00:23:36,179
say Django periodically sends a silver

00:23:34,350 --> 00:23:38,460
send message to your friend right so

00:23:36,179 --> 00:23:40,350
it's moving upwards and so the green

00:23:38,460 --> 00:23:42,480
bars is when your client is connected to

00:23:40,350 --> 00:23:44,460
the back end and then for some reason is

00:23:42,480 --> 00:23:46,230
disconnected either the user goes

00:23:44,460 --> 00:23:48,419
through a tunnel or there's some kind of

00:23:46,230 --> 00:23:50,700
disconnection notice and the server

00:23:48,419 --> 00:23:52,320
sends a message but this message has

00:23:50,700 --> 00:23:54,809
nowhere to go because the client is not

00:23:52,320 --> 00:23:57,029
connected so that's the stop sign or the

00:23:54,809 --> 00:23:59,399
no entry sign and then the client

00:23:57,029 --> 00:24:02,370
reconnects and it's missed those

00:23:59,399 --> 00:24:03,990
messages and then it happens again so if

00:24:02,370 --> 00:24:05,760
you're going to be missing a lot of the

00:24:03,990 --> 00:24:08,460
messages that your backhand sends you

00:24:05,760 --> 00:24:11,429
and the back end has no no kind of

00:24:08,460 --> 00:24:13,350
system to to acknowledge that these

00:24:11,429 --> 00:24:15,750
messages that have been received you're

00:24:13,350 --> 00:24:17,940
gonna be left in a very bad shape your

00:24:15,750 --> 00:24:19,830
your client state is just going to be an

00:24:17,940 --> 00:24:22,919
invalid set it's it's pretty challenging

00:24:19,830 --> 00:24:25,830
and I was surprised to find that on the

00:24:22,919 --> 00:24:28,590
cloud it's actually quite frequent to

00:24:25,830 --> 00:24:31,770
disconnect persistent connections

00:24:28,590 --> 00:24:34,470
there's just not not a guarantee there

00:24:31,770 --> 00:24:36,630
is an NPM package called reconnecting

00:24:34,470 --> 00:24:39,059
WebSockets essentially does a for loop

00:24:36,630 --> 00:24:42,960
and if it's a disconnect it tries to

00:24:39,059 --> 00:24:45,690
reconnect so that was easy but what we

00:24:42,960 --> 00:24:49,649
had to do is actually fix the missed

00:24:45,690 --> 00:24:51,840
messages on the back end so our solution

00:24:49,649 --> 00:24:53,690
to that was to serialize all of the

00:24:51,840 --> 00:24:56,970
messages being sent from the back end

00:24:53,690 --> 00:24:57,929
timestamp it and implement a cursor on

00:24:56,970 --> 00:25:00,390
the client side

00:24:57,929 --> 00:25:03,059
so if the back end sends message one

00:25:00,390 --> 00:25:05,159
message to message three message for the

00:25:03,059 --> 00:25:06,840
client keeps track of one two and then

00:25:05,159 --> 00:25:09,000
it receives four okay you know what

00:25:06,840 --> 00:25:13,500
there's a problem so go back to two and

00:25:09,000 --> 00:25:15,840
give me all the messages since two so

00:25:13,500 --> 00:25:18,840
that's roughly how it's essentially a

00:25:15,840 --> 00:25:21,630
table that we store on the back end and

00:25:18,840 --> 00:25:23,730
then the client implements this logic

00:25:21,630 --> 00:25:26,309
whereas there there's a gap in the

00:25:23,730 --> 00:25:28,940
sequence it can go back and rewind that

00:25:26,309 --> 00:25:28,940
cursor

00:25:30,149 --> 00:25:36,909
so what we did here as an implementation

00:25:33,909 --> 00:25:39,549
level detail is not distorted in our

00:25:36,909 --> 00:25:42,370
database but Redis has this data

00:25:39,549 --> 00:25:45,129
structure called sorted sets and so you

00:25:42,370 --> 00:25:47,350
can actually pop and push into this

00:25:45,129 --> 00:25:49,990
reddit structure and it's actually

00:25:47,350 --> 00:25:53,580
really fast so there's no there's no

00:25:49,990 --> 00:25:57,580
delay in in trying to store this this

00:25:53,580 --> 00:25:59,259
ring buffer we also wrote a middleware

00:25:57,580 --> 00:26:00,700
because we wanted to make sure that

00:25:59,259 --> 00:26:02,980
every message going from the back end

00:26:00,700 --> 00:26:05,350
was going through was being time-stamped

00:26:02,980 --> 00:26:13,049
and sequentialized so it was important

00:26:05,350 --> 00:26:16,570
to go through that single stream our

00:26:13,049 --> 00:26:19,869
third problem was a friend architecture

00:26:16,570 --> 00:26:24,399
our front end is a single page react app

00:26:19,869 --> 00:26:26,440
and these messages from the back end you

00:26:24,399 --> 00:26:28,749
don't really know when they're going to

00:26:26,440 --> 00:26:30,490
come they could be out of order it could

00:26:28,749 --> 00:26:32,499
be different components because it's a

00:26:30,490 --> 00:26:34,960
single bus that all these messages come

00:26:32,499 --> 00:26:37,090
in and so we were actually pretty

00:26:34,960 --> 00:26:40,659
confused in terms of how do you update

00:26:37,090 --> 00:26:43,809
your front-end State and so what we did

00:26:40,659 --> 00:26:44,980
there this is an example let's say

00:26:43,809 --> 00:26:47,259
that's your web app and you have a

00:26:44,980 --> 00:26:49,240
notification system that gives you a

00:26:47,259 --> 00:26:51,879
drop-down with all the new messages and

00:26:49,240 --> 00:26:53,769
then you have a feed which tells you all

00:26:51,879 --> 00:26:57,190
the new elements that are inserted into

00:26:53,769 --> 00:27:00,340
your feed system and our WebSocket

00:26:57,190 --> 00:27:03,700
handler gets all these messages and then

00:27:00,340 --> 00:27:05,710
you use standard J queries on messaging

00:27:03,700 --> 00:27:08,610
so you essentially implement your own

00:27:05,710 --> 00:27:11,590
messaging system on the front end to

00:27:08,610 --> 00:27:14,110
dispatch these messages so if you guys

00:27:11,590 --> 00:27:16,389
are familiar with how I OS apps are

00:27:14,110 --> 00:27:17,440
built there's a single bus and you get

00:27:16,389 --> 00:27:19,059
these messages and then they're

00:27:17,440 --> 00:27:21,850
dispatched through different views and

00:27:19,059 --> 00:27:24,580
these views listen when they loaded and

00:27:21,850 --> 00:27:27,249
then they destroy the handlers when they

00:27:24,580 --> 00:27:29,110
unload so the same kind of concept that

00:27:27,249 --> 00:27:30,970
way your notification system and your

00:27:29,110 --> 00:27:32,889
feet are not tying directly into

00:27:30,970 --> 00:27:35,499
WebSockets there's an abstraction layer

00:27:32,889 --> 00:27:37,840
there and for whatever reason if

00:27:35,499 --> 00:27:39,789
WebSockets is not supported you can

00:27:37,840 --> 00:27:41,980
always fall back this is just an

00:27:39,789 --> 00:27:47,650
architectural idea

00:27:41,980 --> 00:27:50,590
how to organize your front-end problem

00:27:47,650 --> 00:27:52,740
number four debugging debugging testing

00:27:50,590 --> 00:27:56,679
all of this was was a big challenge

00:27:52,740 --> 00:27:59,830
because you cannot use coal to mark

00:27:56,679 --> 00:28:02,020
requests a lot of the Django test

00:27:59,830 --> 00:28:06,460
clients and all that stuff doesn't work

00:28:02,020 --> 00:28:08,230
so what we did is you know that example

00:28:06,460 --> 00:28:10,870
with the middle way that serialized the

00:28:08,230 --> 00:28:13,690
messages we just stored that as as our

00:28:10,870 --> 00:28:16,390
fixture so we were able to bring up a

00:28:13,690 --> 00:28:18,280
friend incline and then feed it messages

00:28:16,390 --> 00:28:22,120
from the backend based on this fixture

00:28:18,280 --> 00:28:24,040
and then it's pretty important to keep

00:28:22,120 --> 00:28:26,500
that stream of messages on your back-end

00:28:24,040 --> 00:28:28,720
and the stream of messages received on

00:28:26,500 --> 00:28:30,549
the front end and push them both into a

00:28:28,720 --> 00:28:32,919
centralized data store so you can

00:28:30,549 --> 00:28:34,780
reconcile the messages that have been

00:28:32,919 --> 00:28:35,860
sent from the backend and the messages

00:28:34,780 --> 00:28:38,190
that have been received from the

00:28:35,860 --> 00:28:41,169
front-end and see if there are any gaps

00:28:38,190 --> 00:28:44,080
so without this unified view across the

00:28:41,169 --> 00:28:47,790
client and the server it's kind of

00:28:44,080 --> 00:28:47,790
difficult to figure out what's going on

00:28:49,440 --> 00:28:55,900
here's another tip chrome as is pretty

00:28:52,660 --> 00:28:58,270
awesome ws tab I spent two weeks

00:28:55,900 --> 00:29:01,000
debugging Chrome WebSockets without

00:28:58,270 --> 00:29:02,380
knowing chrome had this built in so you

00:29:01,000 --> 00:29:04,450
can just click on the frames and this

00:29:02,380 --> 00:29:06,250
gives you a sequential list of all the

00:29:04,450 --> 00:29:08,380
messages received through the WebSockets

00:29:06,250 --> 00:29:11,049
it's either outgoing or incoming no

00:29:08,380 --> 00:29:13,330
problem it just shows it to you and we

00:29:11,049 --> 00:29:15,370
just use JSON as a transport so you can

00:29:13,330 --> 00:29:19,410
you can inspect it

00:29:15,370 --> 00:29:19,410
you can purify it whatever you want

00:29:22,500 --> 00:29:39,149
so guys that concludes my talk and I am

00:29:29,250 --> 00:29:41,159
open to questions thanks for the talk in

00:29:39,149 --> 00:29:44,190
one of your earlier diagrams it looked

00:29:41,159 --> 00:29:47,940
like you were basically accepting the

00:29:44,190 --> 00:29:49,649
initial HTTP request via Ajax running

00:29:47,940 --> 00:29:53,429
the sequel query like on a different

00:29:49,649 --> 00:29:56,519
django box on a worker somewhere how are

00:29:53,429 --> 00:29:58,110
you able is that true first of all were

00:29:56,519 --> 00:30:03,230
you doing it like in celery in the

00:29:58,110 --> 00:30:06,029
background or yeah that one there we go

00:30:03,230 --> 00:30:08,370
right are those two separate django web

00:30:06,029 --> 00:30:12,389
servers that's exactly right

00:30:08,370 --> 00:30:15,120
so we were offloading the query to a

00:30:12,389 --> 00:30:18,450
celery worker so how are you able to

00:30:15,120 --> 00:30:20,549
basically keep the WebSocket alive but

00:30:18,450 --> 00:30:22,470
when you move it from the initial

00:30:20,549 --> 00:30:26,029
machine that got the request to the

00:30:22,470 --> 00:30:28,580
celery web server so the Django channels

00:30:26,029 --> 00:30:32,730
documentation recommends Redis as a

00:30:28,580 --> 00:30:36,210
persistent layer so from any web server

00:30:32,730 --> 00:30:38,759
you can talk to a client no matter what

00:30:36,210 --> 00:30:41,399
actual web server it's connected to so

00:30:38,759 --> 00:30:44,399
it gives you a unified view of all of

00:30:41,399 --> 00:30:46,710
the clients connected you mentioned that

00:30:44,399 --> 00:30:50,460
use the an event bus on the front end

00:30:46,710 --> 00:30:53,580
with react it did you did you use

00:30:50,460 --> 00:30:57,899
something like Redux or what was the

00:30:53,580 --> 00:31:00,509
handle one for for doing that we just

00:30:57,899 --> 00:31:05,610
used something built on jQuery jQuery

00:31:00,509 --> 00:31:10,350
event emitters okay yeah I have a

00:31:05,610 --> 00:31:14,490
question you mentioned sort of the the

00:31:10,350 --> 00:31:15,929
hiccup in the original deployment when

00:31:14,490 --> 00:31:19,620
you were just using Ajax request

00:31:15,929 --> 00:31:22,470
response and I wonder how how you handle

00:31:19,620 --> 00:31:24,960
sort of that in this architecture where

00:31:22,470 --> 00:31:27,299
you still need to you know replace the

00:31:24,960 --> 00:31:29,759
code in that worker that's running the

00:31:27,299 --> 00:31:34,200
query huh how do you handle the

00:31:29,759 --> 00:31:35,810
deployment of the worker that may be

00:31:34,200 --> 00:31:40,800
still doing work

00:31:35,810 --> 00:31:43,470
very good question so our deployment

00:31:40,800 --> 00:31:46,830
cycles are different for the jangle app

00:31:43,470 --> 00:31:48,960
and the celery workers the workers it's

00:31:46,830 --> 00:31:52,220
okay to run with let's say v1 of the

00:31:48,960 --> 00:31:55,980
code and then you can actually do

00:31:52,220 --> 00:31:58,350
delayed deployments all new workers have

00:31:55,980 --> 00:32:00,540
version 2 and version 1 is still running

00:31:58,350 --> 00:32:03,060
no problem it's not you're not killing

00:32:00,540 --> 00:32:06,840
the existing worker so one worker one

00:32:03,060 --> 00:32:10,370
instance of the worker is one grade just

00:32:06,840 --> 00:32:13,050
a lot easier how do you get this static

00:32:10,370 --> 00:32:15,570
data in there do you just use do you

00:32:13,050 --> 00:32:19,010
just do a regular ETL to a Postgres

00:32:15,570 --> 00:32:22,500
database and then have them as unmanaged

00:32:19,010 --> 00:32:24,480
you know like the meta unmanaged Jango

00:32:22,500 --> 00:32:28,740
models so that there's a connection to

00:32:24,480 --> 00:32:31,680
the front-end did that question make

00:32:28,740 --> 00:32:34,440
sense so you must be running sequel on

00:32:31,680 --> 00:32:35,880
some static type of data right like if

00:32:34,440 --> 00:32:38,940
you're doing data analysis you know

00:32:35,880 --> 00:32:42,660
could be gigabytes of data from flat

00:32:38,940 --> 00:32:46,310
files you load it into Postgres then do

00:32:42,660 --> 00:32:49,530
you somehow introspect and generate

00:32:46,310 --> 00:32:51,390
unmanaged models and and the reason I

00:32:49,530 --> 00:32:55,560
say unmanaged is because you don't want

00:32:51,390 --> 00:32:59,850
to you don't want to spoil any of the

00:32:55,560 --> 00:33:01,440
static data and accidentally have so you

00:32:59,850 --> 00:33:03,900
know what I'm saying but manage is

00:33:01,440 --> 00:33:06,360
confusing but it's the meta tag for the

00:33:03,900 --> 00:33:08,430
model to not have it migrate visit

00:33:06,360 --> 00:33:10,260
beyond you know you have to do a

00:33:08,430 --> 00:33:13,950
migration for it but yeah very good

00:33:10,260 --> 00:33:16,980
question ok so the question was we

00:33:13,950 --> 00:33:19,860
execute the sequel against some unknown

00:33:16,980 --> 00:33:21,720
schema and his question was do you

00:33:19,860 --> 00:33:24,680
import that schema into your Jango

00:33:21,720 --> 00:33:28,020
models or does it pollute your clean

00:33:24,680 --> 00:33:30,510
sanitized curated schema or not right

00:33:28,020 --> 00:33:32,100
because there could be unknown and the

00:33:30,510 --> 00:33:34,140
answer that question is we don't manage

00:33:32,100 --> 00:33:35,940
any of our customers data they don't

00:33:34,140 --> 00:33:38,990
even touch our Jango or Django nose

00:33:35,940 --> 00:33:42,930
knows nothing about it and so we

00:33:38,990 --> 00:33:45,840
literally send that raw text in that

00:33:42,930 --> 00:33:47,820
execute sequel box through a SSH tunnel

00:33:45,840 --> 00:33:48,870
to the customers database which they

00:33:47,820 --> 00:33:51,179
host

00:33:48,870 --> 00:33:52,440
so we don't we don't import any models

00:33:51,179 --> 00:33:54,470
we don't do it's nothing to do with

00:33:52,440 --> 00:33:56,820
Django our customers don't even know

00:33:54,470 --> 00:33:59,580
we're using Django in the back end so

00:33:56,820 --> 00:34:02,539
the clear separation between our app and

00:33:59,580 --> 00:34:05,070
the customers data model so make sense

00:34:02,539 --> 00:34:07,230
how did you solve the authentication

00:34:05,070 --> 00:34:09,510
issue maybe you I answered it and I just

00:34:07,230 --> 00:34:12,000
didn't hear it but you said that we

00:34:09,510 --> 00:34:13,859
weren't sending the cookies over and

00:34:12,000 --> 00:34:17,790
then you gotta like just maybe jumped

00:34:13,859 --> 00:34:20,040
ahead and it's a there's a full section

00:34:17,790 --> 00:34:22,169
in the Django channel's documentation on

00:34:20,040 --> 00:34:24,899
authentication but essentially what it

00:34:22,169 --> 00:34:27,720
does is it passes off the HTTP session

00:34:24,899 --> 00:34:31,169
to the Django sesh channels session and

00:34:27,720 --> 00:34:33,690
that handoff is done during Connect and

00:34:31,169 --> 00:34:36,270
so the subsequent messages don't have

00:34:33,690 --> 00:34:38,220
any kind of cookie header or anything so

00:34:36,270 --> 00:34:41,429
but the Django channels documentation

00:34:38,220 --> 00:34:43,379
goes into a lot of detail there so you

00:34:41,429 --> 00:34:47,970
just have to add some decorators to your

00:34:43,379 --> 00:34:49,080
channel views essentially you mentioned

00:34:47,970 --> 00:34:55,609
that one of the reasons you wanted to

00:34:49,080 --> 00:34:58,470
adopt the solution was the 8:00 a.m.

00:34:55,609 --> 00:35:00,900
server load other than the removal of

00:34:58,470 --> 00:35:04,109
the long poles and are you ready yet

00:35:00,900 --> 00:35:09,570
type messages did this solve that

00:35:04,109 --> 00:35:12,089
problem in any other way so we we

00:35:09,570 --> 00:35:14,160
definitely partially solved the problem

00:35:12,089 --> 00:35:16,440
in the sense that we still have that big

00:35:14,160 --> 00:35:18,690
spike of Ajax requests but the

00:35:16,440 --> 00:35:20,700
difference now is that that full

00:35:18,690 --> 00:35:23,010
lifecycle there is less than 15

00:35:20,700 --> 00:35:26,339
milliseconds it's not a long-standing

00:35:23,010 --> 00:35:28,170
connection so you can connect 7,000 you

00:35:26,339 --> 00:35:30,510
can open up 7,000 connections that are

00:35:28,170 --> 00:35:33,720
50 milliseconds each rather than having

00:35:30,510 --> 00:35:37,830
7,000 connections which are three

00:35:33,720 --> 00:35:39,990
minutes long that's the difference you

00:35:37,830 --> 00:35:47,369
mentioned you're using TCP load

00:35:39,990 --> 00:35:51,300
balancing and they're so in in the TCP I

00:35:47,369 --> 00:35:55,470
mean you're so essentially are you able

00:35:51,300 --> 00:35:58,609
to get the same level of affinity that

00:35:55,470 --> 00:36:02,220
you would in sort of a higher level

00:35:58,609 --> 00:36:02,720
scheme for load balancing such as HTTP

00:36:02,220 --> 00:36:08,150
and

00:36:02,720 --> 00:36:10,040
cookie and session-based affinity that's

00:36:08,150 --> 00:36:13,010
been a challenge for us

00:36:10,040 --> 00:36:15,980
sticky session is an unsolved problem in

00:36:13,010 --> 00:36:18,440
this scenario another challenge that we

00:36:15,980 --> 00:36:20,480
have is the IP addresses of the clients

00:36:18,440 --> 00:36:23,960
keep changing and so you can't really

00:36:20,480 --> 00:36:25,910
reconnect to the same WebSocket

00:36:23,960 --> 00:36:27,140
connection so I think that's the reason

00:36:25,910 --> 00:36:29,300
why there are a lot of disconnects and

00:36:27,140 --> 00:36:30,680
reconnects I haven't gotten to the

00:36:29,300 --> 00:36:32,359
bottom of that yet but that is

00:36:30,680 --> 00:36:35,450
definitely an unsolved problem in this

00:36:32,359 --> 00:36:36,830
scenario how do you manage lifetime's of

00:36:35,450 --> 00:36:39,740
connections because I could imagine that

00:36:36,830 --> 00:36:42,890
the reconnection example that you showed

00:36:39,740 --> 00:36:44,599
could look very similar to a user saying

00:36:42,890 --> 00:36:46,670
oh I'm done with your website

00:36:44,599 --> 00:36:49,940
I don't I don't actually want any

00:36:46,670 --> 00:36:51,890
updates which which portion which

00:36:49,940 --> 00:36:54,050
lifecycle from the web app to the back

00:36:51,890 --> 00:36:57,020
end or the back end to the customers

00:36:54,050 --> 00:36:59,210
database so the WebSocket connections if

00:36:57,020 --> 00:37:01,070
if they go away they can't be

00:36:59,210 --> 00:37:04,609
unintentionally going away or it could

00:37:01,070 --> 00:37:06,710
be a connection issue so when they go

00:37:04,609 --> 00:37:09,710
away it unloads the app so we disconnect

00:37:06,710 --> 00:37:13,880
the WebSocket right now there is no way

00:37:09,710 --> 00:37:17,240
for you to go offline essentially right

00:37:13,880 --> 00:37:19,430
there's no way to go offline we we're

00:37:17,240 --> 00:37:22,130
you know pretty aggressive in

00:37:19,430 --> 00:37:24,140
reconnecting and trying to reconnect we

00:37:22,130 --> 00:37:27,160
have an exponential back-off there just

00:37:24,140 --> 00:37:29,690
in case the back end is actually down

00:37:27,160 --> 00:37:32,060
then you don't want to like hammer your

00:37:29,690 --> 00:37:33,650
back in with every trying to reconnect

00:37:32,060 --> 00:37:36,980
every 50 milliseconds or 500

00:37:33,650 --> 00:37:39,050
milliseconds so you back off 500 1

00:37:36,980 --> 00:37:40,609
second 2 seconds 4 seconds just like

00:37:39,050 --> 00:37:43,040
Gmail the Gmail you see it's

00:37:40,609 --> 00:37:45,050
reconnecting in 3 seconds and then if it

00:37:43,040 --> 00:37:46,760
can reconnect reconnecting in 7 seconds

00:37:45,050 --> 00:37:49,040
and then reconnecting in 12 seconds

00:37:46,760 --> 00:37:50,839
reconnecting tomorrow and so on right so

00:37:49,040 --> 00:37:54,640
it's the same kind of deal thank you

00:37:50,839 --> 00:37:54,640
again for sharing your expertise awesome

00:37:56,570 --> 00:37:59,749

YouTube URL: https://www.youtube.com/watch?v=BRCx6lSA0fM


