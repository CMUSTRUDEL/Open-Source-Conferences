Title: DjangoCon US 2017 -  Using Django, Docker, and Scikit... by Lorena Mesa
Publication date: 2017-09-07
Playlist: DjangoCon US 2017
Description: 
	DjangoCon US 2017 -  Using Django, Docker, and Scikit-learn to Bootstrap Your Machine Learning Project by Lorena Mesa

Reproducible results can be the bane of a data engineer or data scientistâ€™s existence. Perhaps a data scientist prototyped a model some months ago, tabled the project, only to return to it today. Itâ€™s now when they notice the inaccurate or lack of documentation in the feature engineering process. No one wins in that scenario.

In this talk weâ€™ll walk through how you can use Django to spin up a Docker container to handle the feature engineering required for a machine learning project and spit out a pickled model. From the version controlled Docker container we can version our models, store them as needed and use scikit-learn to generate predictions moving forward. Django will allow us to easily bootstrap a machine learning project removing the downtown required to setup a project and permit us to move quickly to having a model ready for exploration and ultimately production.

Machine learning done a bit easier? Yes please!

This talk was presented at: https://2017.djangocon.us/talks/using-django-docker-and-scikit-learn-to-bootstrap-your-machine-learning-project/

LINKS:
Follow Lorena Mesa ðŸ‘‡
On Twitter: https://twitter.com/loooorenanicole
Official homepage: http://lorenamesa.com
Github: https://github.com/lorenanicole/

Follow DjangCon US ðŸ‘‡
https://twitter.com/djangocon

Follow DEFNA ðŸ‘‡
https://twitter.com/defnado
https://www.defna.org/
Captions: 
	00:00:00,000 --> 00:00:17,250
[Music]

00:00:14,089 --> 00:00:17,730
brilliant okay so thank you so much for

00:00:17,250 --> 00:00:20,130
joining me

00:00:17,730 --> 00:00:23,610
especially after lunch so I hope you're

00:00:20,130 --> 00:00:25,259
all really excited to basically look at

00:00:23,610 --> 00:00:27,239
every single technology that I try not

00:00:25,259 --> 00:00:28,410
to make my title too long but we will at

00:00:27,239 --> 00:00:29,399
least touch on some of these which is

00:00:28,410 --> 00:00:32,399
fantastic

00:00:29,399 --> 00:00:34,590
so just to recap just to recap the title

00:00:32,399 --> 00:00:36,870
of this talk it's titled using Django

00:00:34,590 --> 00:00:38,610
docker and scikit-learn

00:00:36,870 --> 00:00:40,710
to bootstrap your machine learning

00:00:38,610 --> 00:00:42,059
project something I do want to point out

00:00:40,710 --> 00:00:44,609
is that all these slides are actually

00:00:42,059 --> 00:00:47,309
available with a bitly link on the

00:00:44,609 --> 00:00:49,589
bottom left hand corner I also will be

00:00:47,309 --> 00:00:51,359
sharing on Twitter and I will also be

00:00:49,589 --> 00:00:52,890
sharing the code which I will not be

00:00:51,359 --> 00:00:55,440
doing any live code today but I do have

00:00:52,890 --> 00:00:57,359
a repository up and would love people to

00:00:55,440 --> 00:00:58,710
use things break things tell me that I

00:00:57,359 --> 00:01:01,800
need to add things so that would be

00:00:58,710 --> 00:01:03,210
really fantastic but yeah so I would

00:01:01,800 --> 00:01:05,729
like to start off a little bit with a

00:01:03,210 --> 00:01:06,630
story about something that happened to

00:01:05,729 --> 00:01:08,880
me recently

00:01:06,630 --> 00:01:11,000
so I'm guessing many of us use some kind

00:01:08,880 --> 00:01:15,300
of communication tool like slack at work

00:01:11,000 --> 00:01:18,420
yes okay great so on August 1st I got

00:01:15,300 --> 00:01:21,630
this fantastic ping from a co-worker of

00:01:18,420 --> 00:01:24,120
mine Matthew who basically was like hey

00:01:21,630 --> 00:01:27,090
like I've got questions the interface on

00:01:24,120 --> 00:01:28,770
this model change like what happened

00:01:27,090 --> 00:01:31,200
what's going on

00:01:28,770 --> 00:01:33,180
blah blah blah and I'm like wait hold up

00:01:31,200 --> 00:01:35,670
there's a few models and there's a lot

00:01:33,180 --> 00:01:37,350
what changed what explicitly is like the

00:01:35,670 --> 00:01:38,640
model version you're talking about I

00:01:37,350 --> 00:01:40,620
don't understand

00:01:38,640 --> 00:01:42,570
and I think this right now speaks she

00:01:40,620 --> 00:01:44,520
kind of like the problem space I'm

00:01:42,570 --> 00:01:46,920
currently in which is tooling around

00:01:44,520 --> 00:01:48,270
data science teams um so god this just

00:01:46,920 --> 00:01:50,790
happened to me in August first and it's

00:01:48,270 --> 00:01:52,710
only August 15th so the struggle is real

00:01:50,790 --> 00:01:54,030
I'm still on this and I'm still in this

00:01:52,710 --> 00:01:56,130
problem space tried to think through

00:01:54,030 --> 00:01:58,830
this quite a lot and would love to hear

00:01:56,130 --> 00:02:00,660
any feedback you have so I guess first

00:01:58,830 --> 00:02:03,090
Matthew pings me I'm like okay well

00:02:00,660 --> 00:02:05,909
maybe I can go and piece together what

00:02:03,090 --> 00:02:07,170
this model is I go jump on github and

00:02:05,909 --> 00:02:10,019
look at where the data scientists are

00:02:07,170 --> 00:02:12,000
chucking Cody I go into one of the data

00:02:10,019 --> 00:02:14,879
scientists projects repository and

00:02:12,000 --> 00:02:18,120
there's just like 10 Jupiter notebooks

00:02:14,879 --> 00:02:20,370
in there with like a lot of code a lot

00:02:18,120 --> 00:02:21,450
of things I don't understand in them and

00:02:20,370 --> 00:02:23,760
I'm just like okay I have

00:02:21,450 --> 00:02:26,970
no idea which of these cheaper notebooks

00:02:23,760 --> 00:02:28,769
jumped the model that is on this that is

00:02:26,970 --> 00:02:31,620
on this kubernetes service that Matthew

00:02:28,769 --> 00:02:33,750
you were using so hold on let me go look

00:02:31,620 --> 00:02:35,430
so go look and see if I can piece

00:02:33,750 --> 00:02:38,580
together the story from the pickled

00:02:35,430 --> 00:02:41,010
version of the model and we store that

00:02:38,580 --> 00:03:24,239
was on s3 I'm looking at us three you'll

00:02:41,010 --> 00:03:26,609
notice jun 12 2015 6 to do a quick

00:03:24,239 --> 00:03:29,130
introduction to who i am

00:03:26,609 --> 00:03:32,370
hi my name is Lorena Meza and as our

00:03:29,130 --> 00:03:34,950
session runner indicated I am totally a

00:03:32,370 --> 00:03:37,139
big Star Trek nerd I paid way too much

00:03:34,950 --> 00:03:39,660
money to meet Captain jean-luc Picard

00:03:37,139 --> 00:03:41,209
which was fantastic but I'm something a

00:03:39,660 --> 00:03:43,139
little bit about me is I've actually

00:03:41,209 --> 00:03:45,420
come out of the world of being a

00:03:43,139 --> 00:03:48,329
political scientist so a few years ago I

00:03:45,420 --> 00:03:50,579
was like I can do sequel and Python and

00:03:48,329 --> 00:03:52,889
I like this code thing so I went through

00:03:50,579 --> 00:03:55,980
an immersion program at dev bootcamp in

00:03:52,889 --> 00:03:59,310
Chicago and I've been with the sprout

00:03:55,980 --> 00:04:02,400
social engineering team ever since May

00:03:59,310 --> 00:04:04,109
5th 2014 it's been really exciting in my

00:04:02,400 --> 00:04:06,329
time there I've been on the platform

00:04:04,109 --> 00:04:08,340
team working on two different parts of

00:04:06,329 --> 00:04:10,440
the platform and last year and some

00:04:08,340 --> 00:04:13,410
change I've been on our brand new data

00:04:10,440 --> 00:04:14,940
science team I will talk a little bit

00:04:13,410 --> 00:04:16,859
about the anatomy of our data science

00:04:14,940 --> 00:04:19,560
team but what I do want to point out is

00:04:16,859 --> 00:04:21,030
our data science team is newer and we

00:04:19,560 --> 00:04:23,580
are growing quickly which is kind of

00:04:21,030 --> 00:04:26,070
where this talk comes from some other

00:04:23,580 --> 00:04:27,990
things I do I help run pi ladies Chicago

00:04:26,070 --> 00:04:30,210
and I do sit on the Python Software

00:04:27,990 --> 00:04:32,190
Foundation Board of Directors I think

00:04:30,210 --> 00:04:33,720
there's a few of us here at Jango conce

00:04:32,190 --> 00:04:35,280
if you do have any questions or want to

00:04:33,720 --> 00:04:37,710
know more about the PSF

00:04:35,280 --> 00:04:39,300
this is just my call to you come speak

00:04:37,710 --> 00:04:41,130
with us we're super happy to get to know

00:04:39,300 --> 00:04:44,700
who you are and learn more about your

00:04:41,130 --> 00:04:45,900
needs so in regards to today's talk

00:04:44,700 --> 00:04:48,660
we're gonna be kind of going through

00:04:45,900 --> 00:04:49,980
these five items we're gonna chat a

00:04:48,660 --> 00:04:52,260
little bit to get some common language

00:04:49,980 --> 00:04:53,700
around what machine learning is we're

00:04:52,260 --> 00:04:55,380
going to talk about the anatomy of a

00:04:53,700 --> 00:04:57,330
data science team because I know with

00:04:55,380 --> 00:05:00,000
Django and with Python we can get people

00:04:57,330 --> 00:05:01,290
from a broad variety of disciplines so I

00:05:00,000 --> 00:05:03,419
do want to make sure we talk a little

00:05:01,290 --> 00:05:05,880
bit about data science and how my team

00:05:03,419 --> 00:05:08,310
kind of functions then we will

00:05:05,880 --> 00:05:10,620
high-level talk about the engineering of

00:05:08,310 --> 00:05:12,990
a machine learning problem will then

00:05:10,620 --> 00:05:14,669
move into thinking about machine

00:05:12,990 --> 00:05:16,050
learning engineering using some of the

00:05:14,669 --> 00:05:16,919
latest and greatest buzzwords like

00:05:16,050 --> 00:05:19,130
docker

00:05:16,919 --> 00:05:20,400
Jango because we're at Jango Cod

00:05:19,130 --> 00:05:23,669
scikit-learn

00:05:20,400 --> 00:05:25,890
and some other goodies and then we'll

00:05:23,669 --> 00:05:27,690
kind of leave with some open questions

00:05:25,890 --> 00:05:29,850
about what could be next for the project

00:05:27,690 --> 00:05:31,680
I'm working on maybe what are some ideas

00:05:29,850 --> 00:05:33,870
for you all if you work on data science

00:05:31,680 --> 00:05:36,090
teams what we could use in the ecosystem

00:05:33,870 --> 00:05:40,380
for data science infrastructure and then

00:05:36,090 --> 00:05:45,630
also tools for more learning so great

00:05:40,380 --> 00:05:47,580
what is machine learning oh I always get

00:05:45,630 --> 00:05:48,720
a little bit of a kick out of when

00:05:47,580 --> 00:05:52,320
people think about what machine learning

00:05:48,720 --> 00:05:54,060
is like input hi I'm Johnny Five if you

00:05:52,320 --> 00:05:56,910
don't know what Johnny Five is it's a

00:05:54,060 --> 00:05:58,740
really ridiculous movie kids movie from

00:05:56,910 --> 00:06:01,590
when I was little where you have like a

00:05:58,740 --> 00:06:03,240
super fancy like intelligent robot who

00:06:01,590 --> 00:06:04,410
can do all the things and I think

00:06:03,240 --> 00:06:05,550
sometimes that's what people may think

00:06:04,410 --> 00:06:07,350
when they think of machine learning

00:06:05,550 --> 00:06:09,060
especially if they don't work in an

00:06:07,350 --> 00:06:11,430
organization that has some kind of data

00:06:09,060 --> 00:06:13,380
science practice already but for for

00:06:11,430 --> 00:06:15,300
lack of a better word iid like to always

00:06:13,380 --> 00:06:16,919
try to find some common jargon just to

00:06:15,300 --> 00:06:18,840
kind of orient myself and think through

00:06:16,919 --> 00:06:19,979
well when we talk about mean machine

00:06:18,840 --> 00:06:22,440
learning what is it that we're actually

00:06:19,979 --> 00:06:24,030
getting into so rather than read this

00:06:22,440 --> 00:06:26,130
ball of text I just want to kind of

00:06:24,030 --> 00:06:28,350
highlight some of the big things here so

00:06:26,130 --> 00:06:30,390
machine learning it's a few a subfield

00:06:28,350 --> 00:06:31,919
in computer science does pattern

00:06:30,390 --> 00:06:34,530
recognition computational learning

00:06:31,919 --> 00:06:36,300
artificial intelligence blahblah I'm

00:06:34,530 --> 00:06:37,560
sure we've heard a lot of that so I

00:06:36,300 --> 00:06:40,620
don't really care so much about that

00:06:37,560 --> 00:06:42,360
what I do really want to focus on is

00:06:40,620 --> 00:06:43,979
machine learning explores the

00:06:42,360 --> 00:06:46,560
construction and study of algorithms

00:06:43,979 --> 00:06:48,419
that that can learn from and make

00:06:46,560 --> 00:06:49,130
predictions on data so the big thing

00:06:48,419 --> 00:06:52,670
here

00:06:49,130 --> 00:06:54,620
algorithms we all know what that is data

00:06:52,670 --> 00:06:57,410
we could work with it all the time and

00:06:54,620 --> 00:06:59,120
making predictions on data cool we now

00:06:57,410 --> 00:07:02,180
have some ground and liquid language to

00:06:59,120 --> 00:07:04,130
think about machine learning but what's

00:07:02,180 --> 00:07:05,660
not sup there let's think about it maybe

00:07:04,130 --> 00:07:08,750
in a little bit more of a traditional

00:07:05,660 --> 00:07:11,360
way that some of us who maybe have

00:07:08,750 --> 00:07:12,710
computer science degrees may have been

00:07:11,360 --> 00:07:15,140
exposed to machine learning in a

00:07:12,710 --> 00:07:16,640
language like this so I found this

00:07:15,140 --> 00:07:18,830
language to be very useful comes from

00:07:16,640 --> 00:07:21,050
Tom Mitchell computer science professor

00:07:18,830 --> 00:07:23,330
at Carnegie Mellon where he frames

00:07:21,050 --> 00:07:26,180
machine learning with these with these

00:07:23,330 --> 00:07:29,060
three pieces emphasis here is that a

00:07:26,180 --> 00:07:32,180
computer program is said to learn from

00:07:29,060 --> 00:07:35,720
experience II with respect to some tasks

00:07:32,180 --> 00:07:37,640
T and some performance measure P if it's

00:07:35,720 --> 00:07:40,880
performance on T as measured by P

00:07:37,640 --> 00:07:42,530
improves that it experience e so when we

00:07:40,880 --> 00:07:43,850
are talking about our algorithms our

00:07:42,530 --> 00:07:45,890
algorithms are going to be doing some

00:07:43,850 --> 00:07:47,810
task they're gonna be using data and

00:07:45,890 --> 00:07:49,880
from that is from that data we're gonna

00:07:47,810 --> 00:07:52,010
be trying to derive some insights so

00:07:49,880 --> 00:07:55,820
that we can go ahead and make

00:07:52,010 --> 00:07:57,170
predictions on what new things may be

00:07:55,820 --> 00:07:58,580
happening out there depending on the

00:07:57,170 --> 00:08:00,380
features you're building there's gonna

00:07:58,580 --> 00:08:02,780
be some tasks some kind of thing we want

00:08:00,380 --> 00:08:04,520
to accomplish and how do we know if

00:08:02,780 --> 00:08:08,540
we're doing things correct well we have

00:08:04,520 --> 00:08:10,700
some idea of a performance metric okay

00:08:08,540 --> 00:08:13,370
so just because I like to kill

00:08:10,700 --> 00:08:14,630
everything with details I think it's

00:08:13,370 --> 00:08:17,060
always good to have a little bit of a

00:08:14,630 --> 00:08:19,070
toy problem to think about when we think

00:08:17,060 --> 00:08:20,780
about you know what might be some ways

00:08:19,070 --> 00:08:22,640
in which we do machine learning in our

00:08:20,780 --> 00:08:25,040
day-to-day and what are some toy

00:08:22,640 --> 00:08:28,010
projects we work on so sprout social

00:08:25,040 --> 00:08:29,600
where I work is a is a largely

00:08:28,010 --> 00:08:32,030
business-to-business social media

00:08:29,600 --> 00:08:33,740
management and analytics tool so

00:08:32,030 --> 00:08:35,750
something we work a lot with social

00:08:33,740 --> 00:08:36,650
media data so text data that's a really

00:08:35,750 --> 00:08:38,360
big thing for me

00:08:36,650 --> 00:08:40,250
so text data that's something that I

00:08:38,360 --> 00:08:41,990
think we might have all heard about we

00:08:40,250 --> 00:08:43,790
we've all had things like the spam

00:08:41,990 --> 00:08:46,490
filter in our inbox it marks something

00:08:43,790 --> 00:08:48,320
if it's spam or not well let's let's

00:08:46,490 --> 00:08:49,430
maybe take that example a little bit

00:08:48,320 --> 00:08:53,270
further and think about a different

00:08:49,430 --> 00:08:54,560
example so the idea here we of something

00:08:53,270 --> 00:08:56,360
else we could think about as a machine

00:08:54,560 --> 00:08:58,700
learning problem could be predicting

00:08:56,360 --> 00:09:02,000
altruism with a naive Bayes classifier

00:08:58,700 --> 00:09:02,900
so I'm guessing some of us I hope many

00:09:02,000 --> 00:09:05,450
of us like the

00:09:02,900 --> 00:09:08,240
yes especially if that's what the words

00:09:05,450 --> 00:09:11,450
free associated with it that makes me

00:09:08,240 --> 00:09:14,060
really excited so what would you all do

00:09:11,450 --> 00:09:16,100
to get free pizza do not scream it out

00:09:14,060 --> 00:09:20,210
loud I'm just gonna brainstorm up here

00:09:16,100 --> 00:09:21,010
um let's see would you maybe run a

00:09:20,210 --> 00:09:23,360
marathon

00:09:21,010 --> 00:09:24,890
perhaps cuz maybe those carbs are so

00:09:23,360 --> 00:09:28,610
much better after you run a marathon

00:09:24,890 --> 00:09:30,230
um would you I don't know would you do

00:09:28,610 --> 00:09:33,020
interpretive dance in front of Django

00:09:30,230 --> 00:09:34,550
Khan for 45 minutes maybe I don't know

00:09:33,020 --> 00:09:37,130
what your requirements are for getting

00:09:34,550 --> 00:09:40,670
free pizza but this is actually a really

00:09:37,130 --> 00:09:43,030
fun little toy example that someone

00:09:40,670 --> 00:09:45,320
actually put into the world and actually

00:09:43,030 --> 00:09:46,670
clean data for us so that we can

00:09:45,320 --> 00:09:49,180
actually start working I'm thinking

00:09:46,670 --> 00:09:52,390
about measuring and predicting altruism

00:09:49,180 --> 00:09:54,380
with this idea that if you get Pizza

00:09:52,390 --> 00:09:56,780
someone gives you pizza that's an

00:09:54,380 --> 00:09:59,420
altruistic act so where does this where

00:09:56,780 --> 00:10:01,910
does this example come from on reddit

00:09:59,420 --> 00:10:04,100
there's a subreddit called random acts

00:10:01,910 --> 00:10:06,860
of Pizza and essentially what this

00:10:04,100 --> 00:10:09,290
subreddit is is it's basically invites

00:10:06,860 --> 00:10:11,510
people to get to come on and say hey you

00:10:09,290 --> 00:10:13,280
can make a request as you'll notice here

00:10:11,510 --> 00:10:15,200
there are some there is some structure

00:10:13,280 --> 00:10:16,670
for how our request happens which is

00:10:15,200 --> 00:10:19,100
pretty nice because in the era of

00:10:16,670 --> 00:10:20,570
unstructured data having some structure

00:10:19,100 --> 00:10:22,460
to your data is great especially when

00:10:20,570 --> 00:10:25,490
you're doing machine learning so in the

00:10:22,460 --> 00:10:27,650
in line item two we have write your

00:10:25,490 --> 00:10:29,720
request post and submit it remember to

00:10:27,650 --> 00:10:31,400
start the title with requests so yeah

00:10:29,720 --> 00:10:34,430
there's some ideas here but essentially

00:10:31,400 --> 00:10:36,170
this is a subreddit on reddit where

00:10:34,430 --> 00:10:39,290
people can go and basically make

00:10:36,170 --> 00:10:41,240
requests for for free pizza and then the

00:10:39,290 --> 00:10:43,310
community will upvote or downvote and

00:10:41,240 --> 00:10:45,500
based on the rules of how this works

00:10:43,310 --> 00:10:47,120
eventually when you have so many votes

00:10:45,500 --> 00:10:49,280
yep you're gonna get a free pizza or

00:10:47,120 --> 00:10:50,900
someone might just buy it for you so if

00:10:49,280 --> 00:10:51,970
you're hungry tonight maybe you can do

00:10:50,900 --> 00:10:56,140
this tonight

00:10:51,970 --> 00:10:58,250
some examples of texts of free pizza

00:10:56,140 --> 00:11:00,680
goodness I've really got a kick out of

00:10:58,250 --> 00:11:03,080
these the first one I actually have

00:11:00,680 --> 00:11:05,870
money for the pizza but all I have is a

00:11:03,080 --> 00:11:07,880
$50 bill and the delivery boys don't

00:11:05,870 --> 00:11:10,040
accept anything larger than a $20 bill

00:11:07,880 --> 00:11:12,920
so that was actually the text of

00:11:10,040 --> 00:11:15,560
someone's request another another

00:11:12,920 --> 00:11:16,620
request that someone made was I've got a

00:11:15,560 --> 00:11:19,590
guitar and

00:11:16,620 --> 00:11:20,760
and on the other a pizza pie so I guess

00:11:19,590 --> 00:11:22,800
they were just like trying to get

00:11:20,760 --> 00:11:24,330
someone excited like I'm already almost

00:11:22,800 --> 00:11:26,580
there you just have to buy me the pizza

00:11:24,330 --> 00:11:28,950
but as you can see that it these these

00:11:26,580 --> 00:11:30,420
kind of requests they can be all over

00:11:28,950 --> 00:11:32,010
the place they can be kind of silly and

00:11:30,420 --> 00:11:35,730
some of them were actually a little

00:11:32,010 --> 00:11:39,540
heartbreaking to read so in the in this

00:11:35,730 --> 00:11:42,480
toy example the data science competition

00:11:39,540 --> 00:11:44,820
website Cagle actually already had

00:11:42,480 --> 00:11:47,970
cleaned this data set and made it easily

00:11:44,820 --> 00:11:49,890
downloadable so it's probably very hard

00:11:47,970 --> 00:11:52,430
to see but on the right hand side is a

00:11:49,890 --> 00:11:54,630
snippet of some of the JSON blobs that

00:11:52,430 --> 00:11:56,940
represent the training data for this

00:11:54,630 --> 00:12:00,000
problem you've got a lot of features in

00:11:56,940 --> 00:12:01,800
there including the request text which

00:12:00,000 --> 00:12:05,430
is some examples of things I gave you

00:12:01,800 --> 00:12:07,560
you've got the number of votes you have

00:12:05,430 --> 00:12:10,230
the user information of who requested it

00:12:07,560 --> 00:12:12,120
the date it was requested things like

00:12:10,230 --> 00:12:13,770
that so that's kind of example of your

00:12:12,120 --> 00:12:17,040
training data and then essentially what

00:12:13,770 --> 00:12:20,910
this problem does is it says hey I want

00:12:17,040 --> 00:12:23,220
you given these 5,000 671 requests of

00:12:20,910 --> 00:12:25,500
which nine hundred and ninety four of

00:12:23,220 --> 00:12:27,390
them are labeled as true and the rest

00:12:25,500 --> 00:12:29,010
are labeled as false I want you to write

00:12:27,390 --> 00:12:31,620
a model a machine learning model that

00:12:29,010 --> 00:12:33,600
can actually predict and tell me if when

00:12:31,620 --> 00:12:35,670
I get a new request coming in if that

00:12:33,600 --> 00:12:37,830
request is going to be successful or not

00:12:35,670 --> 00:12:39,480
so for a machine learning problem this

00:12:37,830 --> 00:12:41,340
might be an example of a classifier I

00:12:39,480 --> 00:12:44,190
don't know maybe you're you've got a new

00:12:41,340 --> 00:12:45,780
wonky app idea where you want to I don't

00:12:44,190 --> 00:12:47,790
know hack your way to all the free food

00:12:45,780 --> 00:12:49,110
in the world maybe this is your way of

00:12:47,790 --> 00:12:51,060
like bringing machine learning to your

00:12:49,110 --> 00:12:52,920
application so you have some idea of

00:12:51,060 --> 00:12:55,530
text data and you've got some or

00:12:52,920 --> 00:12:57,570
historically labeled examples of things

00:12:55,530 --> 00:12:58,980
that were successful or not and then you

00:12:57,570 --> 00:13:00,600
can use that when you're constructing

00:12:58,980 --> 00:13:03,840
your model to help you make future

00:13:00,600 --> 00:13:05,670
predictions so to reframe this in the

00:13:03,840 --> 00:13:07,470
language that we saw earlier from Tom

00:13:05,670 --> 00:13:09,630
Mitchell we have the task which is

00:13:07,470 --> 00:13:11,850
classifying a piece of data essentially

00:13:09,630 --> 00:13:14,760
the question is is a pizza request

00:13:11,850 --> 00:13:17,700
successful or if we ask them differently

00:13:14,760 --> 00:13:21,150
is that is this an act of altruism or

00:13:17,700 --> 00:13:22,230
not our experience here is going to be

00:13:21,150 --> 00:13:24,210
the label training data which

00:13:22,230 --> 00:13:26,490
essentially is like a CSV where you have

00:13:24,210 --> 00:13:28,020
a request ID and you just got a boolean

00:13:26,490 --> 00:13:29,800
representing true or false if that

00:13:28,020 --> 00:13:32,290
request was successful or not

00:13:29,800 --> 00:13:34,689
and our performance measurement is the

00:13:32,290 --> 00:13:36,160
label correct that's pretty much your

00:13:34,689 --> 00:13:37,420
performance measurement because when

00:13:36,160 --> 00:13:38,679
you're working with label data you're

00:13:37,420 --> 00:13:40,269
actually going to go ahead and predict

00:13:38,679 --> 00:13:41,800
on some of that training data if you

00:13:40,269 --> 00:13:43,600
have a label already you can go just in

00:13:41,800 --> 00:13:45,389
check and see hey did I actually

00:13:43,600 --> 00:13:48,129
successfully predict this thing or not

00:13:45,389 --> 00:13:49,660
so in the in example kind of machine

00:13:48,129 --> 00:13:51,850
learning maybe you have some kind of

00:13:49,660 --> 00:13:55,420
classifier problem like this you have

00:13:51,850 --> 00:13:57,279
your tasks you have your experience and

00:13:55,420 --> 00:13:59,019
now you've got your you've got some

00:13:57,279 --> 00:14:03,189
notion of a performance measurement

00:13:59,019 --> 00:14:05,559
what next okay so we've talked a little

00:14:03,189 --> 00:14:08,079
bit about what machine learning may look

00:14:05,559 --> 00:14:09,999
like for you as an engineer what kind of

00:14:08,079 --> 00:14:11,920
decisions you have to think about what

00:14:09,999 --> 00:14:13,839
kind of data you may be working with so

00:14:11,920 --> 00:14:16,360
it could be tux data it could be other

00:14:13,839 --> 00:14:18,459
things about the pizza request maybe

00:14:16,360 --> 00:14:20,980
you're looking for if something is

00:14:18,459 --> 00:14:22,629
incorrectly capitalized in the request

00:14:20,980 --> 00:14:24,369
maybe there's other characteristics of

00:14:22,629 --> 00:14:27,129
the data that you want to look at beyond

00:14:24,369 --> 00:14:29,009
just like the words that are in it well

00:14:27,129 --> 00:14:31,509
with uh with a data science team

00:14:29,009 --> 00:14:32,799
something to think about is that you've

00:14:31,509 --> 00:14:34,749
got kind of a few folks who are working

00:14:32,799 --> 00:14:35,350
on these problems it's not just gonna be

00:14:34,749 --> 00:14:38,079
your development

00:14:35,350 --> 00:14:40,509
you've not just your developers so kind

00:14:38,079 --> 00:14:42,790
of borrowing this from IBM's UX personas

00:14:40,509 --> 00:14:44,889
as applied to engineering they've

00:14:42,790 --> 00:14:46,509
they've kind of think they highlight the

00:14:44,889 --> 00:14:48,579
idea and the differences between the app

00:14:46,509 --> 00:14:50,740
developer the data scientists and the

00:14:48,579 --> 00:14:51,939
data engineer so the data scientist is

00:14:50,740 --> 00:14:54,009
actually going to be someone who's going

00:14:51,939 --> 00:14:56,290
to be going in there doing a lot of the

00:14:54,009 --> 00:14:57,759
future engineering they're they're the

00:14:56,290 --> 00:14:59,860
ones who are going to be trained on the

00:14:57,759 --> 00:15:02,619
different statistical methods and

00:14:59,860 --> 00:15:03,999
algorithms and your data engineers gonna

00:15:02,619 --> 00:15:07,029
be the one probably building the

00:15:03,999 --> 00:15:09,910
pipeline but the infrastructure around

00:15:07,029 --> 00:15:11,439
this making this thing happen and then

00:15:09,910 --> 00:15:13,119
your app developers perhaps are the ones

00:15:11,439 --> 00:15:15,549
actually bringing the model and putting

00:15:13,119 --> 00:15:18,279
it into the application and making it so

00:15:15,549 --> 00:15:21,639
a user can can actually use this feature

00:15:18,279 --> 00:15:24,220
or not so in in that world let's talk a

00:15:21,639 --> 00:15:27,129
little bit about my data science team so

00:15:24,220 --> 00:15:29,139
you may have seen this this den grant

00:15:27,129 --> 00:15:32,889
Venn diagram of madness as I like to

00:15:29,139 --> 00:15:34,509
call it before we're you know within the

00:15:32,889 --> 00:15:36,399
idea that someone has all of these

00:15:34,509 --> 00:15:38,169
skills that's to me is just a total

00:15:36,399 --> 00:15:40,600
fallacy the idea that you're gonna have

00:15:38,169 --> 00:15:42,369
math stats subject area expertise and

00:15:40,600 --> 00:15:43,209
computer science and that's the unicorn

00:15:42,369 --> 00:15:45,399
which Ally

00:15:43,209 --> 00:15:48,279
data scientists know I can tell you

00:15:45,399 --> 00:15:50,800
that's definitely not the case in the

00:15:48,279 --> 00:15:52,240
kind of the context of my team we've

00:15:50,800 --> 00:15:54,279
we've got a team that's been growing

00:15:52,240 --> 00:15:56,499
pretty quickly like I said about a year

00:15:54,279 --> 00:15:58,600
and some change so we've got four data

00:15:56,499 --> 00:16:00,670
scientists we've got someone who comes

00:15:58,600 --> 00:16:02,619
from natural language processing and PhD

00:16:00,670 --> 00:16:05,559
who has spent a lot of time in computer

00:16:02,619 --> 00:16:07,119
science and working with NLP we have

00:16:05,559 --> 00:16:09,999
folks who've come from predictive

00:16:07,119 --> 00:16:11,769
analytics economics now we also have a

00:16:09,999 --> 00:16:14,559
person who came out of their postdoc

00:16:11,769 --> 00:16:16,899
doing chemistry then there is me the

00:16:14,559 --> 00:16:18,999
lone soul software engineer and the team

00:16:16,899 --> 00:16:20,649
and like I said I came I came from the

00:16:18,999 --> 00:16:22,769
platform engineering side of things and

00:16:20,649 --> 00:16:27,550
I've done a little data and alloc and

00:16:22,769 --> 00:16:30,069
analytics in my time as a as a person in

00:16:27,550 --> 00:16:31,749
the professional world we do also have

00:16:30,069 --> 00:16:34,420
some designated infrastructure support

00:16:31,749 --> 00:16:38,800
but largely that is still kind of in our

00:16:34,420 --> 00:16:42,129
wheelhouse so why is that a problem

00:16:38,800 --> 00:16:44,649
great we've got PhDs who are wearing the

00:16:42,129 --> 00:16:46,209
title of of data scientist there's me

00:16:44,649 --> 00:16:49,480
and we have some infrastructure report

00:16:46,209 --> 00:16:54,369
why do I care about that well I think

00:16:49,480 --> 00:16:57,459
this can give you an idea so from the

00:16:54,369 --> 00:16:59,949
keynote that Jack ponder posted this

00:16:57,459 --> 00:17:02,110
year in Portland he talks a lot about

00:16:59,949 --> 00:17:03,490
the variety of tools that are in pythons

00:17:02,110 --> 00:17:05,740
scientific stack

00:17:03,490 --> 00:17:07,569
you've got scikit-learn you've got a lot

00:17:05,740 --> 00:17:10,390
of different ideas you can use like data

00:17:07,569 --> 00:17:11,980
grip you have tools like pandas you have

00:17:10,390 --> 00:17:14,260
a lot of visualization tools and

00:17:11,980 --> 00:17:17,199
plotting tools and also just like the

00:17:14,260 --> 00:17:19,510
actual work of developing the model and

00:17:17,199 --> 00:17:22,600
executing you've got things like jupiter

00:17:19,510 --> 00:17:25,720
notebooks this is a big world that you

00:17:22,600 --> 00:17:30,940
that people can pick up and select tools

00:17:25,720 --> 00:17:32,080
from so that's cool why is Python the

00:17:30,940 --> 00:17:34,270
place that people are going to if

00:17:32,080 --> 00:17:35,919
they're doing a lot of modeling work the

00:17:34,270 --> 00:17:37,630
good thing I like to think about and why

00:17:35,919 --> 00:17:40,720
I get excited about data science and

00:17:37,630 --> 00:17:43,480
python is namely that it really is a it

00:17:40,720 --> 00:17:45,490
really is a place where it really is a

00:17:43,480 --> 00:17:47,649
place where we can kind of mash a lot of

00:17:45,490 --> 00:17:49,299
things together in the scientific

00:17:47,649 --> 00:17:50,799
community there's a lot of there's a lot

00:17:49,299 --> 00:17:52,960
of work for example in the Astronomy

00:17:50,799 --> 00:17:56,230
field using Python to do a lot of

00:17:52,960 --> 00:17:58,059
analytics and visualization kind of

00:17:56,230 --> 00:18:00,730
again reframing what Jake vanden plas

00:17:58,059 --> 00:18:02,260
highlights Python acts as a glue it

00:18:00,730 --> 00:18:04,750
plays well with other languages we've

00:18:02,260 --> 00:18:06,190
got our batteries included kind of idea

00:18:04,750 --> 00:18:07,990
here we don't have to go and write a lot

00:18:06,190 --> 00:18:09,600
of proprietary code just go in and start

00:18:07,990 --> 00:18:12,250
working with data right from the get-go

00:18:09,600 --> 00:18:15,779
Python simple and dynamic and it has an

00:18:12,250 --> 00:18:19,059
open ethos well-suited to science so

00:18:15,779 --> 00:18:20,860
that's all fine and dandy but again on

00:18:19,059 --> 00:18:23,020
my side I'm the one software engineer on

00:18:20,860 --> 00:18:24,070
my team with people who come from a

00:18:23,020 --> 00:18:27,370
variety of different academic

00:18:24,070 --> 00:18:30,010
disciplines and the kind of tools that

00:18:27,370 --> 00:18:31,659
they can use can broadly vary depending

00:18:30,010 --> 00:18:35,110
on the types of machine learning

00:18:31,659 --> 00:18:36,730
problems we're working on so to kind of

00:18:35,110 --> 00:18:39,039
think about what is the model for my

00:18:36,730 --> 00:18:41,789
team or maybe what's model for me as a

00:18:39,039 --> 00:18:46,149
person supporting a data science team

00:18:41,789 --> 00:18:48,399
I'm gonna modify professor Ralph

00:18:46,149 --> 00:18:51,429
Johnson's quote here and instead of

00:18:48,399 --> 00:18:52,630
saying before software can be useful it

00:18:51,429 --> 00:18:54,700
must be reusable I'm gonna say

00:18:52,630 --> 00:18:57,159
explicitly before machine learning can

00:18:54,700 --> 00:18:59,260
be usable it must be reusable we have a

00:18:57,159 --> 00:19:01,000
lot of different expertise we have a lot

00:18:59,260 --> 00:19:02,380
of open-source tools we have a lot of

00:19:01,000 --> 00:19:05,649
different kinds of problems people can

00:19:02,380 --> 00:19:07,510
use and I think it's leading to it can

00:19:05,649 --> 00:19:10,539
be a little overwhelming it's kind of

00:19:07,510 --> 00:19:13,000
thing I want to highlight so back to

00:19:10,539 --> 00:19:15,250
this idea of machine learning one thing

00:19:13,000 --> 00:19:16,570
that we've had to think a bit about is

00:19:15,250 --> 00:19:18,789
what kind of problems are we gonna

00:19:16,570 --> 00:19:20,620
answer and what does that look like when

00:19:18,789 --> 00:19:25,389
we're answering those problems so back

00:19:20,620 --> 00:19:27,190
to that example of the the predicting if

00:19:25,389 --> 00:19:29,860
you're gonna get a free pizza or not so

00:19:27,190 --> 00:19:31,510
we might have text data there but that

00:19:29,860 --> 00:19:32,799
could depending on the machine learning

00:19:31,510 --> 00:19:34,210
problem you're working on you might have

00:19:32,799 --> 00:19:36,340
a variety of other data sources that

00:19:34,210 --> 00:19:38,620
you're integrating and this kind of

00:19:36,340 --> 00:19:40,990
component of like shaping the data in

00:19:38,620 --> 00:19:42,610
the format that you need selecting the

00:19:40,990 --> 00:19:43,860
data and then maybe munching the data

00:19:42,610 --> 00:19:46,539
into the format that you need as well

00:19:43,860 --> 00:19:50,559
can be quite expensive so we call this

00:19:46,539 --> 00:19:52,690
feature engineering this representation

00:19:50,559 --> 00:19:55,419
kind of on the left hand side gives kind

00:19:52,690 --> 00:19:58,649
of a broadly simplistic idea of what may

00:19:55,419 --> 00:20:01,299
be a pipeline for a supervised learning

00:19:58,649 --> 00:20:03,580
approach to machine learning so you can

00:20:01,299 --> 00:20:06,490
see like maybe we've got data in our in

00:20:03,580 --> 00:20:08,559
our in our data in our production

00:20:06,490 --> 00:20:09,430
databases maybe we have logs maybe we

00:20:08,559 --> 00:20:11,170
have

00:20:09,430 --> 00:20:12,940
so examples of some logs maybe we have

00:20:11,170 --> 00:20:14,350
some metrics in which we're kind of

00:20:12,940 --> 00:20:16,750
capturing how people are using the

00:20:14,350 --> 00:20:18,580
application maybe we've also got some

00:20:16,750 --> 00:20:21,520
proprietary data sets that we've paid

00:20:18,580 --> 00:20:22,750
for there can be a quite a few series of

00:20:21,520 --> 00:20:24,760
things that we're taking together and

00:20:22,750 --> 00:20:27,040
we're integrating and we're globbing

00:20:24,760 --> 00:20:29,590
together into a new format so this idea

00:20:27,040 --> 00:20:30,760
here of getting the data merging it

00:20:29,590 --> 00:20:33,430
together and then that feature

00:20:30,760 --> 00:20:35,110
extraction and pre-processing that is

00:20:33,430 --> 00:20:38,080
gonna be a lot of the work of our data

00:20:35,110 --> 00:20:39,970
science team then we have AI once we

00:20:38,080 --> 00:20:41,590
have data and in the format and and

00:20:39,970 --> 00:20:43,120
we've selected the features that we want

00:20:41,590 --> 00:20:46,000
we can then go ahead and apply our

00:20:43,120 --> 00:20:48,280
learning algorithm great from there

00:20:46,000 --> 00:20:50,230
we're able to get a model and then using

00:20:48,280 --> 00:20:53,290
that model we can go and make

00:20:50,230 --> 00:20:55,240
predictions in the example of our of our

00:20:53,290 --> 00:20:57,070
classifier we can go and make a we can

00:20:55,240 --> 00:20:58,780
go make predictions on future pieces of

00:20:57,070 --> 00:21:01,060
data and say hey that thing is

00:20:58,780 --> 00:21:03,040
successful or hey no it isn't but the

00:21:01,060 --> 00:21:05,320
broad idea here is we're munching a lot

00:21:03,040 --> 00:21:06,930
of things together there's going to be

00:21:05,320 --> 00:21:09,610
different areas of expertise and

00:21:06,930 --> 00:21:10,330
depending on who is doing what work we

00:21:09,610 --> 00:21:12,820
need to think a little bit more

00:21:10,330 --> 00:21:16,390
critically about that and so this gets

00:21:12,820 --> 00:21:19,000
me to one really big question the way

00:21:16,390 --> 00:21:20,230
that application developers use use the

00:21:19,000 --> 00:21:22,270
data that we're collecting and our

00:21:20,230 --> 00:21:24,070
proprietary data first how I might be

00:21:22,270 --> 00:21:26,860
using of the data versus maybe how data

00:21:24,070 --> 00:21:28,600
science data scientist perhaps

00:21:26,860 --> 00:21:31,120
themselves or even using the data can be

00:21:28,600 --> 00:21:32,440
quite different and we've actually got

00:21:31,120 --> 00:21:33,940
an entirely different kind of

00:21:32,440 --> 00:21:36,510
infrastructure that we need to start

00:21:33,940 --> 00:21:39,370
developing and building and with that

00:21:36,510 --> 00:21:41,200
the question then ultimately becomes you

00:21:39,370 --> 00:21:43,030
know where is the handoff between data

00:21:41,200 --> 00:21:44,620
science and production what does that

00:21:43,030 --> 00:21:47,550
look like what should our social

00:21:44,620 --> 00:21:49,750
contract be because the way that I'm

00:21:47,550 --> 00:21:51,610
collecting and shaping data and the kind

00:21:49,750 --> 00:21:54,100
of data pipelines that we're laying down

00:21:51,610 --> 00:21:55,360
aren't going to be of aren't going to be

00:21:54,100 --> 00:21:57,250
of importance to the application

00:21:55,360 --> 00:22:00,790
developers who are responding to user

00:21:57,250 --> 00:22:03,610
facing features so let's break this down

00:22:00,790 --> 00:22:06,670
a little bit okay so in the kind of

00:22:03,610 --> 00:22:08,470
flows that we that I'm going to be

00:22:06,670 --> 00:22:10,450
talking about we've we've talked a

00:22:08,470 --> 00:22:13,930
little bit about the git and shape the

00:22:10,450 --> 00:22:15,580
data that's the first thing the second

00:22:13,930 --> 00:22:17,190
example the second stuff of that is

00:22:15,580 --> 00:22:20,050
training the model on the data

00:22:17,190 --> 00:22:21,250
third we want to pickle the model we

00:22:20,050 --> 00:22:23,120
could save it with something like in

00:22:21,250 --> 00:22:25,970
Python Java Lib

00:22:23,120 --> 00:22:28,250
and then forth we can go ahead and use

00:22:25,970 --> 00:22:30,500
it and make predictions on the data so

00:22:28,250 --> 00:22:33,140
in this in this kind of example here

00:22:30,500 --> 00:22:35,270
using pythons ecosystem you might have

00:22:33,140 --> 00:22:37,700
some kind of script and this is quite

00:22:35,270 --> 00:22:39,530
quite simplified but you might have a

00:22:37,700 --> 00:22:42,830
script like what we see in the left hand

00:22:39,530 --> 00:22:45,080
side so in the Python Scientifics in the

00:22:42,830 --> 00:22:47,350
Python scientific stack we have SK learn

00:22:45,080 --> 00:22:49,940
why I asked you learn why not tensorflow

00:22:47,350 --> 00:22:52,160
SK learn is tried true-blue and that's

00:22:49,940 --> 00:22:54,200
actually what my team uses so you might

00:22:52,160 --> 00:22:56,780
have something like this where you're

00:22:54,200 --> 00:22:59,780
saying okay we've got the example of the

00:22:56,780 --> 00:23:01,280
pizza we want we have data that we've

00:22:59,780 --> 00:23:03,590
been collecting and now we want to be

00:23:01,280 --> 00:23:05,660
able to apply a model and make

00:23:03,590 --> 00:23:08,390
predictions on it so with using

00:23:05,660 --> 00:23:10,880
scikit-learn we actually have all those

00:23:08,390 --> 00:23:12,920
algorithms built in so naive Bayes one

00:23:10,880 --> 00:23:15,140
one variant of that is the multinomial

00:23:12,920 --> 00:23:17,000
naive bayes and the flow is going to

00:23:15,140 --> 00:23:19,160
kind of look like this in the Python

00:23:17,000 --> 00:23:22,100
code you may receive something to the

00:23:19,160 --> 00:23:24,679
extent of hey let's split that data into

00:23:22,100 --> 00:23:26,720
the training and the test on the

00:23:24,679 --> 00:23:30,110
training sets and then the test set and

00:23:26,720 --> 00:23:32,420
we're gonna go ahead and fit that

00:23:30,110 --> 00:23:34,130
multinomial model or whatever model

00:23:32,420 --> 00:23:36,620
you're using you're gonna fit it on that

00:23:34,130 --> 00:23:38,450
training data and essentially what that

00:23:36,620 --> 00:23:40,040
does on the training data is it starts

00:23:38,450 --> 00:23:41,720
to represent whatever features you

00:23:40,040 --> 00:23:44,150
selected so if you're doing something

00:23:41,720 --> 00:23:46,309
like working with words perhaps you're

00:23:44,150 --> 00:23:49,910
turning that into a numerical vector

00:23:46,309 --> 00:23:52,780
saying hey words that appear most often

00:23:49,910 --> 00:23:55,910
in requests that you are successful for

00:23:52,780 --> 00:23:58,100
winning a pizza here's their here's

00:23:55,910 --> 00:24:00,710
their kind of histogram count and the

00:23:58,100 --> 00:24:03,350
ones that aren't successful in getting

00:24:00,710 --> 00:24:05,240
pizza here's here's a vectorized format

00:24:03,350 --> 00:24:06,380
of those word counts that could be one

00:24:05,240 --> 00:24:07,940
example of a feature there might be

00:24:06,380 --> 00:24:10,850
other features you're including and you

00:24:07,940 --> 00:24:12,170
can represent that in a numeric format

00:24:10,850 --> 00:24:14,090
but essentially when we're fitting

00:24:12,170 --> 00:24:15,830
against historical data there's a

00:24:14,090 --> 00:24:18,410
process like that happening underneath

00:24:15,830 --> 00:24:20,990
once you've fitted on that historical

00:24:18,410 --> 00:24:23,270
data you can go ahead and say hey I have

00:24:20,990 --> 00:24:25,429
now got a model that's ready to go ahead

00:24:23,270 --> 00:24:28,970
and be used and that's where we're gonna

00:24:25,429 --> 00:24:32,150
go ahead and dump out the the model in a

00:24:28,970 --> 00:24:34,610
pickled format so again that that kind

00:24:32,150 --> 00:24:36,310
of shaping of the data like what kind of

00:24:34,610 --> 00:24:38,440
prep work am I going to be doing

00:24:36,310 --> 00:24:40,690
I'm not doing a talk that's very deep on

00:24:38,440 --> 00:24:42,730
psychic pipelines if you are curious

00:24:40,690 --> 00:24:45,100
about that there's a fantastic talk

00:24:42,730 --> 00:24:47,890
I recommend from PI data Chicago in

00:24:45,100 --> 00:24:49,600
August 2016 about 40 minutes that goes

00:24:47,890 --> 00:24:51,280
in and talks about different

00:24:49,600 --> 00:24:52,660
transformations you can use and things

00:24:51,280 --> 00:24:54,820
like that I have it linked to my slides

00:24:52,660 --> 00:24:56,410
but that all being said when you have

00:24:54,820 --> 00:24:58,470
your data you're gonna have to do some

00:24:56,410 --> 00:25:00,940
kind of munching of it of it together

00:24:58,470 --> 00:25:03,490
getting it to work and you can use

00:25:00,940 --> 00:25:05,140
transformers from scikit-learn to

00:25:03,490 --> 00:25:07,780
actually get it in the way you want so

00:25:05,140 --> 00:25:09,090
to think back to the idea of what might

00:25:07,780 --> 00:25:11,770
be an example of a transformation

00:25:09,090 --> 00:25:14,740
perhaps you have a bag of words with a

00:25:11,770 --> 00:25:16,570
lot of a the but we call these stock

00:25:14,740 --> 00:25:19,300
words these are words that don't provide

00:25:16,570 --> 00:25:21,250
a lot of context perhaps maybe the

00:25:19,300 --> 00:25:23,590
frequency of these words can throw off

00:25:21,250 --> 00:25:27,930
or introduce bias into your model that

00:25:23,590 --> 00:25:30,430
says hey I'm gonna over by it's an over

00:25:27,930 --> 00:25:33,010
overestimate that this is likely going

00:25:30,430 --> 00:25:35,230
to be a successful request or not so a

00:25:33,010 --> 00:25:37,180
transformer might be breaking your bag

00:25:35,230 --> 00:25:38,620
into a pack of words removing stop words

00:25:37,180 --> 00:25:40,690
you might also be doing something like

00:25:38,620 --> 00:25:43,300
stemming which is trading words like

00:25:40,690 --> 00:25:45,610
shop and shopping as the same word

00:25:43,300 --> 00:25:47,020
you're gonna remove that ing but

00:25:45,610 --> 00:25:49,150
transformers like that you can write

00:25:47,020 --> 00:25:51,040
your own custom ones you can do that

00:25:49,150 --> 00:25:53,980
with the scikit-learn pipeline operators

00:25:51,040 --> 00:25:56,200
so when we're back into this flow we've

00:25:53,980 --> 00:25:59,320
got training we've got training examples

00:25:56,200 --> 00:26:01,000
we've got the forming of the of the data

00:25:59,320 --> 00:26:02,470
and the informatic needs and then we're

00:26:01,000 --> 00:26:03,840
gonna go ahead and apply that that

00:26:02,470 --> 00:26:05,950
learning algorithm

00:26:03,840 --> 00:26:07,720
what's pretty nifty to about

00:26:05,950 --> 00:26:09,460
scikit-learn is you've got a variety of

00:26:07,720 --> 00:26:12,580
things in there so if you are kind of

00:26:09,460 --> 00:26:14,710
new to machine learning there's a lot of

00:26:12,580 --> 00:26:17,230
ease of use for you to go ahead and

00:26:14,710 --> 00:26:19,150
start getting to work pretty quickly so

00:26:17,230 --> 00:26:21,070
I would encourage you to go ahead and

00:26:19,150 --> 00:26:22,570
explore a lot of that and then you do

00:26:21,070 --> 00:26:24,220
have some metrics that are also built

00:26:22,570 --> 00:26:25,990
into scikit-learn well we'll see that a

00:26:24,220 --> 00:26:28,450
little bit at the end but for the

00:26:25,990 --> 00:26:30,370
context of the machine learning that I'm

00:26:28,450 --> 00:26:32,200
talking about and that I work with this

00:26:30,370 --> 00:26:34,180
is historically our flow

00:26:32,200 --> 00:26:35,950
we've got supervised learning we have

00:26:34,180 --> 00:26:38,470
some previous data that's been formatted

00:26:35,950 --> 00:26:40,690
in some way we'll use scikit-learn apply

00:26:38,470 --> 00:26:42,430
transformations get it into the format

00:26:40,690 --> 00:26:43,840
that we need then we can go ahead and

00:26:42,430 --> 00:26:45,910
fit the model on it we'll take that

00:26:43,840 --> 00:26:48,520
model from scikit-learn and then we can

00:26:45,910 --> 00:26:49,250
dump that model using job Lib in a

00:26:48,520 --> 00:26:52,730
pickled form

00:26:49,250 --> 00:26:54,590
and then that thing is ready to go cool

00:26:52,730 --> 00:26:57,049
okay so I was talking a little bit about

00:26:54,590 --> 00:26:58,669
earlier about reusability so we've got a

00:26:57,049 --> 00:27:01,730
flow we've talked a little bit about

00:26:58,669 --> 00:27:03,169
what the code may look like for for if

00:27:01,730 --> 00:27:05,360
you're using Python to do machine

00:27:03,169 --> 00:27:08,080
learning explicitly following with

00:27:05,360 --> 00:27:12,260
example of a supervised naivebayes

00:27:08,080 --> 00:27:15,710
example so reproducibility does matter

00:27:12,260 --> 00:27:18,679
so how do I be engineer for that okay

00:27:15,710 --> 00:27:22,520
I really think social media data is just

00:27:18,679 --> 00:27:24,830
so fantastic imagine you have to develop

00:27:22,520 --> 00:27:27,289
a machine learning model that says hey

00:27:24,830 --> 00:27:29,630
the sentiment of this tweet is positive

00:27:27,289 --> 00:27:30,860
or it's like a warm good feeling you

00:27:29,630 --> 00:27:32,240
know however you want to slice and dice

00:27:30,860 --> 00:27:34,850
that you'd have to like separate

00:27:32,240 --> 00:27:39,169
negative from positive well here's a

00:27:34,850 --> 00:27:41,150
thing emojis are part of text data the

00:27:39,169 --> 00:27:44,929
the idea of having tied

00:27:41,150 --> 00:27:46,940
I think it's called tears of joy people

00:27:44,929 --> 00:27:48,289
use that so differently it's you have

00:27:46,940 --> 00:27:49,429
some folks who think that that's

00:27:48,289 --> 00:27:51,169
actually like someone who's like

00:27:49,429 --> 00:27:53,000
sneezing and crying you have people who

00:27:51,169 --> 00:27:55,820
use that and they may think that it's

00:27:53,000 --> 00:27:58,669
like a very positive exciting thing so

00:27:55,820 --> 00:28:00,289
the example here from the tweet it says

00:27:58,669 --> 00:28:02,960
I'm laughing so hard

00:28:00,289 --> 00:28:05,049
tears of joy tears of joy tears of joy

00:28:02,960 --> 00:28:08,510
lots more tears of joy

00:28:05,049 --> 00:28:11,409
hashtag mentally dating Justin Bieber

00:28:08,510 --> 00:28:13,820
and the shirt says single taken acts

00:28:11,409 --> 00:28:15,860
eventually dating Justin Bieber so if I

00:28:13,820 --> 00:28:18,530
were to ask you is this a positive or

00:28:15,860 --> 00:28:20,659
negative thing I'm very curious what you

00:28:18,530 --> 00:28:22,909
would say cuz I would say not so

00:28:20,659 --> 00:28:25,070
positive I'm not a huge Justin Bieber

00:28:22,909 --> 00:28:26,510
fan like I would think that that tears

00:28:25,070 --> 00:28:29,210
of joy is tears of just like utter

00:28:26,510 --> 00:28:31,789
destruction I don't care this is not a

00:28:29,210 --> 00:28:33,890
positive tweet another really fun one

00:28:31,789 --> 00:28:38,450
that I've come across before is the

00:28:33,890 --> 00:28:40,490
purple heart emoji so you know super sad

00:28:38,450 --> 00:28:44,090
that Prince is no longer with us but

00:28:40,490 --> 00:28:46,130
Prince purple is the color of Prince and

00:28:44,090 --> 00:28:47,360
if you're looking at tweets that use the

00:28:46,130 --> 00:28:49,220
Purple Heart especially around the

00:28:47,360 --> 00:28:51,919
anniversary of Prince's passing which I

00:28:49,220 --> 00:28:53,720
believe was April of this year was the

00:28:51,919 --> 00:28:56,120
one-year anniversary you start getting a

00:28:53,720 --> 00:28:57,860
lot of purple hearts and so let's look

00:28:56,120 --> 00:29:00,590
at this tweet the princess date has

00:28:57,860 --> 00:29:01,480
announced at Pantone's new purple hue

00:29:00,590 --> 00:29:03,850
named an honor

00:29:01,480 --> 00:29:05,440
of princes famous love symbol so to me

00:29:03,850 --> 00:29:07,390
I'd be like oh that's so cool

00:29:05,440 --> 00:29:09,490
remembering print and we're empowering

00:29:07,390 --> 00:29:12,490
prints to other people they might still

00:29:09,490 --> 00:29:15,700
just be you know watching Purple Rain

00:29:12,490 --> 00:29:17,650
and just utterly destroyed by things so

00:29:15,700 --> 00:29:18,970
you know we have all these examples of

00:29:17,650 --> 00:29:21,130
kind of inconsistencies right so

00:29:18,970 --> 00:29:22,960
reproducibility does matter if I have a

00:29:21,130 --> 00:29:25,120
machine learning model that's predicting

00:29:22,960 --> 00:29:26,669
the sentiment of something ideally we

00:29:25,120 --> 00:29:30,190
would want it to be consistent right

00:29:26,669 --> 00:29:32,140
yeah I would hope so but there's a lot

00:29:30,190 --> 00:29:33,250
of there's a lot of context there and so

00:29:32,140 --> 00:29:35,350
this is where things can get a little

00:29:33,250 --> 00:29:38,290
tricky and I'm not even gonna start on

00:29:35,350 --> 00:29:41,650
the hashtag lol sob because that is just

00:29:38,290 --> 00:29:43,450
that's a silly one so the idea here

00:29:41,650 --> 00:29:45,880
about data and kind of data governance

00:29:43,450 --> 00:29:47,530
who owns the data who's doing what how

00:29:45,880 --> 00:29:51,640
are we going to get consistent results

00:29:47,530 --> 00:29:53,230
so in the pipeline operator of things I

00:29:51,640 --> 00:29:55,150
want to be able to look at my system and

00:29:53,230 --> 00:29:56,799
think of black boxes I know that I've

00:29:55,150 --> 00:29:58,210
got the black box at shapes data and

00:29:56,799 --> 00:29:59,919
does thing I've got the black box that

00:29:58,210 --> 00:30:01,450
spits out a model and then I've got the

00:29:59,919 --> 00:30:03,549
black box that can go how to be called

00:30:01,450 --> 00:30:05,260
and make a prediction right so I'm gonna

00:30:03,549 --> 00:30:07,660
say as an engineer what I care about is

00:30:05,260 --> 00:30:12,040
developing tools that will help me get

00:30:07,660 --> 00:30:14,799
this reproducibility so that's where I'm

00:30:12,040 --> 00:30:17,110
gonna start saying docker is fantastic

00:30:14,799 --> 00:30:19,270
and also I just really like Dockers

00:30:17,110 --> 00:30:22,210
imagery it makes me very excited so

00:30:19,270 --> 00:30:24,160
containers there is there is a very

00:30:22,210 --> 00:30:26,290
awesome talk later today on kubernetes

00:30:24,160 --> 00:30:28,630
and there's also a talk it's saying like

00:30:26,290 --> 00:30:30,220
it's I think the talk is end to end

00:30:28,630 --> 00:30:32,830
Jango on kubernetes which is fantastic

00:30:30,220 --> 00:30:33,970
what yeah so containers let's get into

00:30:32,830 --> 00:30:34,630
containers and talk a little bit about

00:30:33,970 --> 00:30:38,110
it

00:30:34,630 --> 00:30:39,520
so docker and guess I'm probably most of

00:30:38,110 --> 00:30:42,490
you have used it but it's always good to

00:30:39,520 --> 00:30:44,830
get a refresher if you have not so you

00:30:42,490 --> 00:30:47,559
can think of docker as basically a big

00:30:44,830 --> 00:30:50,410
executable tar ball that has an explicit

00:30:47,559 --> 00:30:52,750
format so for me as an engineer I might

00:30:50,410 --> 00:30:55,540
be like oh the code that that actually

00:30:52,750 --> 00:30:57,040
does the thing any kind of libraries I

00:30:55,540 --> 00:30:58,980
need to help me write the code to do the

00:30:57,040 --> 00:31:03,040
thing and maybe any system tools I need

00:30:58,980 --> 00:31:05,290
cool well here's the fun gotcha in data

00:31:03,040 --> 00:31:07,419
science that might also include this

00:31:05,290 --> 00:31:09,700
data because we don't want this weird

00:31:07,419 --> 00:31:13,090
inconsistency around the purple the

00:31:09,700 --> 00:31:14,590
Purple Heart the lol sob whatever is the

00:31:13,090 --> 00:31:14,860
latest and greatest thing that someone's

00:31:14,590 --> 00:31:17,260
injured

00:31:14,860 --> 00:31:19,120
to sing into the world so yeah data is

00:31:17,260 --> 00:31:20,140
also probably going to be a big thing if

00:31:19,120 --> 00:31:24,250
you're talking about supervised learning

00:31:20,140 --> 00:31:25,630
problems so docker can also Inc you know

00:31:24,250 --> 00:31:27,880
when we think of docker maybe that

00:31:25,630 --> 00:31:29,740
tarball can also learn how to get that

00:31:27,880 --> 00:31:31,720
training data down so that when we

00:31:29,740 --> 00:31:33,910
introduce new versions of models it can

00:31:31,720 --> 00:31:38,140
retrain on the same thing because this

00:31:33,910 --> 00:31:41,290
consistency is good and again you know

00:31:38,140 --> 00:31:44,770
why use docker I just have to steal from

00:31:41,290 --> 00:31:47,110
from Kelsi Hightower who eloquently said

00:31:44,770 --> 00:31:48,910
the first rule of Python is that you

00:31:47,110 --> 00:31:52,570
don't use the system installed version

00:31:48,910 --> 00:31:54,970
of Python I mean I sure many of us have

00:31:52,570 --> 00:31:56,830
struggled I know having your own django

00:31:54,970 --> 00:31:59,200
girls quite a few times telling everyone

00:31:56,830 --> 00:32:02,880
do not use the Python that's installed

00:31:59,200 --> 00:32:06,250
on your machine I will lol sob all day

00:32:02,880 --> 00:32:09,100
so obviously as we know as we know

00:32:06,250 --> 00:32:11,679
setting projects up can be difficult but

00:32:09,100 --> 00:32:13,150
then introduce other complications with

00:32:11,679 --> 00:32:16,380
machine learning like the data that

00:32:13,150 --> 00:32:18,040
we're using the correct order of

00:32:16,380 --> 00:32:19,240
transformations that we have to do

00:32:18,040 --> 00:32:20,620
there's other things that start to

00:32:19,240 --> 00:32:23,350
become more complicated and we talk

00:32:20,620 --> 00:32:26,679
about machine learning problems so for

00:32:23,350 --> 00:32:28,480
the docker end of this I'm gonna say

00:32:26,679 --> 00:32:30,070
what's really cool is docker allows us

00:32:28,480 --> 00:32:31,929
to make a container which basically

00:32:30,070 --> 00:32:34,150
takes a snapshot of how that code works

00:32:31,929 --> 00:32:36,130
at that given moment and then we can

00:32:34,150 --> 00:32:38,230
just put it somewhere and then we could

00:32:36,130 --> 00:32:39,429
check it out later if we want so we do

00:32:38,230 --> 00:32:41,230
this with the docker file and

00:32:39,429 --> 00:32:42,760
essentially what the docker file does is

00:32:41,230 --> 00:32:44,530
you'll have steps in your code and

00:32:42,760 --> 00:32:46,030
what's really nifty is if you have the

00:32:44,530 --> 00:32:49,360
same procedure and you're in your docker

00:32:46,030 --> 00:32:51,070
file time after time you won't need to

00:32:49,360 --> 00:32:52,990
redownload everything it's essentially

00:32:51,070 --> 00:32:54,730
caching layers so only when you make

00:32:52,990 --> 00:32:56,049
changes in your docker file will it have

00:32:54,730 --> 00:32:57,730
to go and redownload things which is

00:32:56,049 --> 00:33:00,130
great we're now making our lives a

00:32:57,730 --> 00:33:01,780
little bit easier with setup so when we

00:33:00,130 --> 00:33:03,520
write the docker file we're gonna then

00:33:01,780 --> 00:33:05,080
the second step is you build the docker

00:33:03,520 --> 00:33:08,320
image which would look something like

00:33:05,080 --> 00:33:09,820
build docker built with the top this is

00:33:08,320 --> 00:33:12,490
the name the model predicting altruism

00:33:09,820 --> 00:33:14,169
give it a tag of latest and then if I

00:33:12,490 --> 00:33:15,400
wanted to run that docker container it

00:33:14,169 --> 00:33:18,250
might look like from the command line

00:33:15,400 --> 00:33:21,130
docker run detached

00:33:18,250 --> 00:33:23,980
Mearing uh associating port eight eight

00:33:21,130 --> 00:33:28,039
eight eight eight and use a mountable

00:33:23,980 --> 00:33:29,350
data directory volume so

00:33:28,039 --> 00:33:31,309
as an example of a dockerfile

00:33:29,350 --> 00:33:33,379
essentially what this is doing top to

00:33:31,309 --> 00:33:34,940
bottom this is an example of maybe what

00:33:33,379 --> 00:33:37,039
I would give a data scientist for them

00:33:34,940 --> 00:33:39,830
to go ahead and start working on their

00:33:37,039 --> 00:33:41,960
stuff so that I can say okay now save

00:33:39,830 --> 00:33:44,210
things so that I can check things out

00:33:41,960 --> 00:33:45,529
when you give me the thumbs up that

00:33:44,210 --> 00:33:47,720
you've got a model that you want me to

00:33:45,529 --> 00:33:49,190
download and work with essentially from

00:33:47,720 --> 00:33:51,859
the top to the bottom what this is doing

00:33:49,190 --> 00:33:54,289
it says use a Python 3 image go ahead

00:33:51,859 --> 00:33:57,080
add some users I'm gonna go ahead and

00:33:54,289 --> 00:33:59,960
mount a data directory volume onto my

00:33:57,080 --> 00:34:01,639
docker image and then I'm gonna go how

00:33:59,960 --> 00:34:03,259
to install the requirements and then I

00:34:01,639 --> 00:34:06,409
have this entry point which basically

00:34:03,259 --> 00:34:10,040
says spin up a Jupiter notebook that's

00:34:06,409 --> 00:34:12,859
my docker file pretty straightforward so

00:34:10,040 --> 00:34:15,470
with docker files we can easily start

00:34:12,859 --> 00:34:17,119
controlling wind changes happen because

00:34:15,470 --> 00:34:19,220
you can build a snapshot of what the

00:34:17,119 --> 00:34:21,950
code what the data what all that looked

00:34:19,220 --> 00:34:23,809
like at a point in time so I'm a big fan

00:34:21,950 --> 00:34:25,970
of using the mountable data directories

00:34:23,809 --> 00:34:28,309
essentially what that allows us to do is

00:34:25,970 --> 00:34:30,770
it takes data on a directory in your

00:34:28,309 --> 00:34:33,260
local system and then it's gonna go

00:34:30,770 --> 00:34:35,450
ahead and mount that into the image so

00:34:33,260 --> 00:34:38,030
like I said we want reproducible results

00:34:35,450 --> 00:34:40,190
so if I have one of my data scientists

00:34:38,030 --> 00:34:42,379
who found a really cool dataset and

00:34:40,190 --> 00:34:44,419
maybe they want to work on that but they

00:34:42,379 --> 00:34:46,159
want to use the same model well they can

00:34:44,419 --> 00:34:48,169
go ahead and build a new image and maybe

00:34:46,159 --> 00:34:53,030
rename it with this is the name of the

00:34:48,169 --> 00:34:55,790
training data that I had so in thinking

00:34:53,030 --> 00:34:57,530
about how I can get my data scientists

00:34:55,790 --> 00:35:01,309
to work essentially what I would argue

00:34:57,530 --> 00:35:03,230
for them to do is go ahead work I want

00:35:01,309 --> 00:35:04,910
you to use this docker file we're gonna

00:35:03,230 --> 00:35:06,799
have a mountable data directory which

00:35:04,910 --> 00:35:08,990
includes your Jupiter notebook which is

00:35:06,799 --> 00:35:11,329
going to have your exploratory code to

00:35:08,990 --> 00:35:13,880
again batch that process if scikit-learn

00:35:11,329 --> 00:35:16,309
pick pick the naivebayes or whatever

00:35:13,880 --> 00:35:19,400
classifier you're using then go ahead

00:35:16,309 --> 00:35:21,410
and transform the model transform the

00:35:19,400 --> 00:35:23,720
data using those transformers as the

00:35:21,410 --> 00:35:25,130
data scientist selects and then pickle

00:35:23,720 --> 00:35:27,470
the model and build it and dump it into

00:35:25,130 --> 00:35:29,299
the stock ER image they can dump it into

00:35:27,470 --> 00:35:31,640
the docker image that's fine where that

00:35:29,299 --> 00:35:33,470
where that where that model will

00:35:31,640 --> 00:35:35,900
ultimately wind up then at least I know

00:35:33,470 --> 00:35:37,520
I can go check out that docker image and

00:35:35,900 --> 00:35:38,059
then I've got the training code that

00:35:37,520 --> 00:35:40,849
goes with it

00:35:38,059 --> 00:35:41,609
at the Jupiter notebook that is ideally

00:35:40,849 --> 00:35:44,700
with some name

00:35:41,609 --> 00:35:46,859
conventions it explicitly tells me when

00:35:44,700 --> 00:35:49,289
it was last touched who owned it things

00:35:46,859 --> 00:35:51,329
like that but now I'm basically creating

00:35:49,289 --> 00:35:53,640
kind of abstractions for them to work in

00:35:51,329 --> 00:35:54,930
where they control the modeling side I

00:35:53,640 --> 00:35:56,999
can check out the thing that they're

00:35:54,930 --> 00:36:01,319
working on and continued it on my merry

00:35:56,999 --> 00:36:05,160
way so if I'm using a docker container

00:36:01,319 --> 00:36:08,069
what I could do is use in Python we've

00:36:05,160 --> 00:36:10,470
got a docker module which allows us to

00:36:08,069 --> 00:36:14,369
create an image so if I were to stand up

00:36:10,470 --> 00:36:16,019
a docker endpoint in a in a Django API

00:36:14,369 --> 00:36:18,119
maybe the URL looks something like this

00:36:16,019 --> 00:36:22,230
crate image name of model

00:36:18,119 --> 00:36:23,999
go ahead create image in that that will

00:36:22,230 --> 00:36:26,190
kind of go ahead and go through the

00:36:23,999 --> 00:36:27,900
procedure of saying hey I'm gonna read

00:36:26,190 --> 00:36:30,119
the docker file I'm gonna go ahead and

00:36:27,900 --> 00:36:31,890
build this image and I'm gonna go ahead

00:36:30,119 --> 00:36:34,079
and stuff it somewhere and what I want

00:36:31,890 --> 00:36:36,690
to return back is basically like a URL

00:36:34,079 --> 00:36:41,700
of where of where that docker image

00:36:36,690 --> 00:36:44,460
lives for context there is demo also

00:36:41,700 --> 00:36:46,319
here on my repository so when I do share

00:36:44,460 --> 00:36:47,519
those slides you can check that out but

00:36:46,319 --> 00:36:49,319
essentially that's where Jango kind of

00:36:47,519 --> 00:36:51,809
comes in we can now basically stand up

00:36:49,319 --> 00:36:54,140
an endpoint use docker abstract away

00:36:51,809 --> 00:36:56,549
what they need to do and then allow the

00:36:54,140 --> 00:36:57,720
allow the data scientist to say okay I'm

00:36:56,549 --> 00:36:59,940
going to hit this endpoint

00:36:57,720 --> 00:37:02,130
it's called predicting altruism and I'm

00:36:59,940 --> 00:37:04,230
gonna go ahead and ask them to to go

00:37:02,130 --> 00:37:07,230
ahead and build it a new snapshot of the

00:37:04,230 --> 00:37:08,579
work that I'm working on so in the duper

00:37:07,230 --> 00:37:11,130
notebook it might have something like

00:37:08,579 --> 00:37:12,720
this an example here of the clean text

00:37:11,130 --> 00:37:15,059
tokenizer kind of what I was talking

00:37:12,720 --> 00:37:16,650
about before of breaking up words into a

00:37:15,059 --> 00:37:18,960
bag of words and then maybe doing

00:37:16,650 --> 00:37:20,279
whatever other transformers you need but

00:37:18,960 --> 00:37:22,470
in the Jupiter notebook that they're

00:37:20,279 --> 00:37:23,880
working in essentially when we build

00:37:22,470 --> 00:37:26,220
that note when we build that docker

00:37:23,880 --> 00:37:28,650
image we're then able to in that docker

00:37:26,220 --> 00:37:30,630
image dump the pickled model and have it

00:37:28,650 --> 00:37:33,450
live somewhere so essentially what we

00:37:30,630 --> 00:37:35,880
can do with the with the docker API is

00:37:33,450 --> 00:37:38,069
basically built in this docker workflow

00:37:35,880 --> 00:37:42,150
where a data scientist as they're

00:37:38,069 --> 00:37:44,249
working on their on their on their super

00:37:42,150 --> 00:37:46,619
notebook when they're ready to go ahead

00:37:44,249 --> 00:37:48,359
and save it basically posts to a Django

00:37:46,619 --> 00:37:49,950
end point and then Django endpoint is

00:37:48,359 --> 00:37:52,559
going to create an image and that image

00:37:49,950 --> 00:37:54,990
is going to be tagged with a mutually

00:37:52,559 --> 00:37:56,910
agreeable model name and

00:37:54,990 --> 00:37:59,580
and that we agree on such that when

00:37:56,910 --> 00:38:02,430
Matthew asks me hey I need I need to

00:37:59,580 --> 00:38:04,530
know about this model I can say okay

00:38:02,430 --> 00:38:06,690
well the last one that was updated on to

00:38:04,530 --> 00:38:08,460
docker is here and here's the URL you

00:38:06,690 --> 00:38:10,020
can use to go ahead and check it out

00:38:08,460 --> 00:38:13,350
we've now kind of abstracted away those

00:38:10,020 --> 00:38:16,350
processes from people so the big thing

00:38:13,350 --> 00:38:18,180
that I did not talk about to keep in

00:38:16,350 --> 00:38:19,590
mind is it's not just that we want to

00:38:18,180 --> 00:38:21,300
automate kind of the building of these

00:38:19,590 --> 00:38:24,630
things but we want to understand how

00:38:21,300 --> 00:38:26,760
models will do over time right that's

00:38:24,630 --> 00:38:27,990
the big thing here that I think is kind

00:38:26,760 --> 00:38:29,970
of the elephant in the room is we want

00:38:27,990 --> 00:38:31,500
to be able to store analytics as well so

00:38:29,970 --> 00:38:34,500
currently what my team's working on is

00:38:31,500 --> 00:38:36,600
we're using the jingo admin to start

00:38:34,500 --> 00:38:38,010
bringing in some of the analytics that

00:38:36,600 --> 00:38:40,050
we get with scikit-learn so on the right

00:38:38,010 --> 00:38:42,390
hand side you'll see there's a chart of

00:38:40,050 --> 00:38:43,590
false positive versus false negative see

00:38:42,390 --> 00:38:45,060
if we can start lifting some of those

00:38:43,590 --> 00:38:47,850
metrics out so that when we train

00:38:45,060 --> 00:38:49,260
against that historical training set we

00:38:47,850 --> 00:38:51,780
now have consistency it's like okay

00:38:49,260 --> 00:38:53,520
model variant one here's the results of

00:38:51,780 --> 00:38:55,320
false positive false negative model

00:38:53,520 --> 00:38:57,450
variant number two here's the results

00:38:55,320 --> 00:38:58,980
such that when we start looking at maybe

00:38:57,450 --> 00:39:02,060
what's the best model we can start

00:38:58,980 --> 00:39:04,109
surfacing those in the Django admin view

00:39:02,060 --> 00:39:07,140
some other things to kind of think about

00:39:04,109 --> 00:39:09,930
- is there some other things to think

00:39:07,140 --> 00:39:11,400
about too is we haven't gone the path of

00:39:09,930 --> 00:39:13,350
talking about kubernetes in this talk

00:39:11,400 --> 00:39:14,970
but kubernetes is a great way to stand

00:39:13,350 --> 00:39:17,070
up an image and stand it behind an

00:39:14,970 --> 00:39:19,560
endpoint so again taking that containers

00:39:17,070 --> 00:39:21,570
technology to the next step and allowing

00:39:19,560 --> 00:39:23,460
people then who are on who are the

00:39:21,570 --> 00:39:25,410
application developers to go ahead start

00:39:23,460 --> 00:39:27,540
hitting an endpoint kubernetes can also

00:39:25,410 --> 00:39:29,670
allow us to get to work and start doing

00:39:27,540 --> 00:39:31,200
that so if you are curious about

00:39:29,670 --> 00:39:34,050
kubernetes I'm gonna make a plug for

00:39:31,200 --> 00:39:35,640
that talk at 4:10 and then also Jango is

00:39:34,050 --> 00:39:38,270
a great framework in which to use you

00:39:35,640 --> 00:39:40,080
can build upon some of the great robust

00:39:38,270 --> 00:39:42,090
libraries that are out there like the

00:39:40,080 --> 00:39:44,340
Django admin and using some of the other

00:39:42,090 --> 00:39:46,440
visualization tools but there's also

00:39:44,340 --> 00:39:48,090
other web frameworks maybe you might

00:39:46,440 --> 00:39:49,800
want to think about so I know that at

00:39:48,090 --> 00:39:53,250
5:00 today there's a Django verse flask

00:39:49,800 --> 00:39:55,200
talk I have also used Falcon as well I

00:39:53,250 --> 00:39:56,580
think it really depends on what your

00:39:55,200 --> 00:39:57,780
team needs but I think Django is a

00:39:56,580 --> 00:39:59,369
really good place to start cuz it's got

00:39:57,780 --> 00:40:01,140
really dry bus support and integration

00:39:59,369 --> 00:40:03,720
with a lot of these tools we've talked

00:40:01,140 --> 00:40:06,570
about so if you're curious about kind of

00:40:03,720 --> 00:40:07,840
like what next there's a lot of places

00:40:06,570 --> 00:40:09,970
we can go next

00:40:07,840 --> 00:40:12,580
I really enjoy rob stories talk bridging

00:40:09,970 --> 00:40:13,000
Python to JVM because that's the other

00:40:12,580 --> 00:40:15,610
thing

00:40:13,000 --> 00:40:17,020
maybe we prototype remodel and Python

00:40:15,610 --> 00:40:18,700
but we want to make use of the JVM

00:40:17,020 --> 00:40:19,960
is there something we can do that well

00:40:18,700 --> 00:40:22,030
yeah we can definitely do this with our

00:40:19,960 --> 00:40:24,580
flow we just might need to transform

00:40:22,030 --> 00:40:26,470
that pickled model into a different into

00:40:24,580 --> 00:40:28,960
a different format how can we do that so

00:40:26,470 --> 00:40:30,100
there's there's some discussion there if

00:40:28,960 --> 00:40:31,870
you want to learn more about the psyche

00:40:30,100 --> 00:40:35,140
other scikit-learn pipelines that's a

00:40:31,870 --> 00:40:37,000
link to that but also last but not least

00:40:35,140 --> 00:40:38,920
I do have two repositories one that

00:40:37,000 --> 00:40:41,980
allows you to work with the mountable

00:40:38,920 --> 00:40:44,110
data volumes with already a full fledged

00:40:41,980 --> 00:40:46,450
pizza L true is a model that you can use

00:40:44,110 --> 00:40:48,130
and do what you want to your heart's

00:40:46,450 --> 00:40:49,720
content to start playing with and then

00:40:48,130 --> 00:40:52,930
also I do have it stood up in a Django

00:40:49,720 --> 00:40:55,150
wrapper which is pretty great so that

00:40:52,930 --> 00:40:58,720
all being said what do you see in the

00:40:55,150 --> 00:41:00,670
image cartoon clip art network I don't

00:40:58,720 --> 00:41:02,920
know I'll say I hope we see lots of free

00:41:00,670 --> 00:41:03,610
pizza so thank you so much my name is

00:41:02,920 --> 00:41:04,960
Lorena

00:41:03,610 --> 00:41:06,490
I'm excited y'all have been here today

00:41:04,960 --> 00:41:07,860
and if you have any questions I'll be

00:41:06,490 --> 00:41:16,079
around Thanks

00:41:07,860 --> 00:41:16,079

YouTube URL: https://www.youtube.com/watch?v=zaT7DRsB9Cw


