Title: DjangoCon US 2015 - Minimum Viable Security by Jacob Kaplan-Moss
Publication date: 2017-11-03
Playlist: DjangoCon US 2015
Description: 
	Minimum Viable Security

We'll look at creating a full security program for a startup-sized company, one that can start quite small, but can be iterated on continually, and grown to match the growth of your business. This talk uses the conceit of a five day program, to be completed in a one-week sprint, but the steps could easily be scaled down to just a few hours, spread out, or otherwise modified to fit your time and organization.

Day 1 - Training: for a security program to work, it needs to be everybody's responsibility, not just a select few. So your first step in creating a security program is to establish a minimum bar for secure coding techniques. Luckily, basic secure coding is easily explained and taught, and there are great free guides and resources that can form the backbone of a simple, easy training program. On Day 1, you'll pull together these guides and create a training manual.

Day 2 - Secure Development Lifecycle: now we know how to write good code, but how do we ensure that best practices are followed? As we learn lessons about our own product and its security posture, how do we make sure those learnings are captured, retained, and applied in the future? The answer to these questions lies in creating a Secure Development Lifecycle, which is just a fancy name for procedures and checklists that capture your best practices, and help remind you of them as you ship new features. On day 2, you'll write those checklists, adopt some lightweight process, and being tracking your product security.

Day 3 - Incident Response: sooner or later, something will go wrong. When it does, will you be able to respond? Trying to make up an incident response process when something's already on fire is an unpleasant experience, and you can avoid it with a little bit of preparation. On day 3, you'll develop a basic IR plan, run a table-top exercise to try it out, and be ready to respond if and when something goes bump in the night.

Day 4 - Governance, Risk, and Compliance: there's an alphabet soup of security standards: ISO, SOC, SIG, PCI, HIPAA, FIPS, FISMA, FedRAMP... oh my! At small scale, most of these are formal attestations probably aren't worth the investment. However, at larger scale these ways of formally proving security standards start to become increasingly important. Completely ignoring formal risk programs can get you into a bind if you decide to pursue them later. Thus, on day 4 you'll lay the groundwork for a formal GRC program, making sure you're ready to start down this path once your business grows to that point.

Day 5: Brag about it! At this point, you've got a security program far better than most startups (and better than many established businesses). This is great! Security is increasingly a concern even for non-technical customers, and now that you've got a good story to tell, you should tell it! On day 5, you'll lay out that security story, publicly, and make sure your customers know about all your hard work.
Captions: 
	00:00:15,740 --> 00:00:22,050
had folks so I'm going here today is to

00:00:20,189 --> 00:00:25,380
get you thinking systemically about

00:00:22,050 --> 00:00:28,260
security not thinking about the the what

00:00:25,380 --> 00:00:32,759
not you know cryptography and hashing

00:00:28,260 --> 00:00:35,130
and password security and and using

00:00:32,759 --> 00:00:36,149
template auto escaping you know I'm not

00:00:35,130 --> 00:00:38,940
talking about the technical details

00:00:36,149 --> 00:00:40,079
although Kelsey gave a talk earlier

00:00:38,940 --> 00:00:41,790
today which covers a lot of those

00:00:40,079 --> 00:00:44,250
technical details in depth so if you

00:00:41,790 --> 00:00:47,250
want to know more about that watch the

00:00:44,250 --> 00:00:49,920
video well what I'm going to talk about

00:00:47,250 --> 00:00:52,140
is how does your organization think

00:00:49,920 --> 00:00:54,809
about security what is it what is your

00:00:52,140 --> 00:00:56,910
security program um let me get a quick

00:00:54,809 --> 00:00:58,379
reading how many people here work for an

00:00:56,910 --> 00:01:03,149
organization that you would say has an

00:00:58,379 --> 00:01:04,229
established security program Wow okay

00:01:03,149 --> 00:01:08,130
that's awesome that's actually more than

00:01:04,229 --> 00:01:10,170
I thought and how many of you do some

00:01:08,130 --> 00:01:12,270
form of security in your day job but

00:01:10,170 --> 00:01:14,159
don't really understand exactly how it

00:01:12,270 --> 00:01:18,540
fits into a larger picture of your

00:01:14,159 --> 00:01:20,520
organization's security posture all

00:01:18,540 --> 00:01:23,430
right if you were okay cool so I'm

00:01:20,520 --> 00:01:25,439
speaking I was speaking to the people

00:01:23,430 --> 00:01:27,390
who raised their hand the second time

00:01:25,439 --> 00:01:29,070
and I'm speaking to the people who

00:01:27,390 --> 00:01:31,079
didn't raise their hands at all who

00:01:29,070 --> 00:01:32,340
don't think that they have a part or

00:01:31,079 --> 00:01:34,409
don't understand their part in an

00:01:32,340 --> 00:01:36,299
organization security you know really I

00:01:34,409 --> 00:01:37,950
want to answer a simple question here

00:01:36,299 --> 00:01:40,710
which is what what a Minimum Viable

00:01:37,950 --> 00:01:42,420
security program look like you can't you

00:01:40,710 --> 00:01:44,430
know I work for Heroku which is part of

00:01:42,420 --> 00:01:46,439
Salesforce right Salesforce 15,000

00:01:44,430 --> 00:01:49,100
employees we've got a security program

00:01:46,439 --> 00:01:51,149
we've got lots of security programs I

00:01:49,100 --> 00:01:53,280
want to answer what does this look like

00:01:51,149 --> 00:01:55,799
if you're if you're for people if you're

00:01:53,280 --> 00:01:57,840
12 people if you're a small development

00:01:55,799 --> 00:02:00,570
team within a larger context that needs

00:01:57,840 --> 00:02:02,310
to sort of get its act together remember

00:02:00,570 --> 00:02:05,100
we talked about Minimum Viable products

00:02:02,310 --> 00:02:07,110
we're not talking about we're not

00:02:05,100 --> 00:02:08,399
talking about just one part right i love

00:02:07,110 --> 00:02:10,979
i love this image because it really

00:02:08,399 --> 00:02:13,360
describes like exactly how you should

00:02:10,979 --> 00:02:15,100
think about what minimum viable means it

00:02:13,360 --> 00:02:16,360
mean let's just build one part of it it

00:02:15,100 --> 00:02:20,140
means let's build something that

00:02:16,360 --> 00:02:23,200
satisfies so in this example I'm I want

00:02:20,140 --> 00:02:25,660
to tell you how to build a skateboard so

00:02:23,200 --> 00:02:27,040
the conceit of this talk is let's say

00:02:25,660 --> 00:02:28,630
you've got one week you're going to

00:02:27,040 --> 00:02:30,070
sprint on this for a week you sit down

00:02:28,630 --> 00:02:32,040
with your co-workers and the end of that

00:02:30,070 --> 00:02:37,810
week you want to have an established

00:02:32,040 --> 00:02:39,760
defined measured successful security

00:02:37,810 --> 00:02:42,940
program ready to be iterated on over the

00:02:39,760 --> 00:02:45,130
next five weeks 5 months 5 years and

00:02:42,940 --> 00:02:48,880
that's what we're building so here's

00:02:45,130 --> 00:02:50,440
what we'll do monday we're going to want

00:02:48,880 --> 00:02:52,390
to develop our training program to make

00:02:50,440 --> 00:02:55,450
sure that developers understand what

00:02:52,390 --> 00:02:57,310
building secure software means Tuesday

00:02:55,450 --> 00:03:00,400
we're going to develop an SD l which is

00:02:57,310 --> 00:03:02,760
a fancy version of saying what is

00:03:00,400 --> 00:03:05,080
security here and how does it work

00:03:02,760 --> 00:03:08,130
Wednesday we're going to plan for when

00:03:05,080 --> 00:03:10,570
the hits the fan excuse my French

00:03:08,130 --> 00:03:12,040
Thursday we're going to talk about what

00:03:10,570 --> 00:03:14,230
a lot of people think of as sort of the

00:03:12,040 --> 00:03:16,600
boring parts of security governance risk

00:03:14,230 --> 00:03:18,760
and compliance formal security programs

00:03:16,600 --> 00:03:20,140
and Friday you're going to tell the

00:03:18,760 --> 00:03:25,620
world that you've just done some awesome

00:03:20,140 --> 00:03:28,600
work let's dive in so train your staff

00:03:25,620 --> 00:03:31,269
so security is a shared responsibility a

00:03:28,600 --> 00:03:32,380
system is only as strong as its weakest

00:03:31,269 --> 00:03:36,040
link and this means we need to

00:03:32,380 --> 00:03:38,410
strengthen all of the links every single

00:03:36,040 --> 00:03:41,200
person at your organization is in some

00:03:38,410 --> 00:03:43,060
sense accountable for the security of

00:03:41,200 --> 00:03:44,830
your organization whether they are a

00:03:43,060 --> 00:03:47,590
developer who needs to write code that

00:03:44,830 --> 00:03:51,360
protects against sequel injection or an

00:03:47,590 --> 00:03:54,040
admin who needs to not fall prey to a

00:03:51,360 --> 00:03:57,850
phishing attack and share corporate

00:03:54,040 --> 00:04:01,030
calendars or a janitor who needs to keep

00:03:57,850 --> 00:04:05,680
the doors locked or a manager who needs

00:04:01,030 --> 00:04:07,780
to not you know up let someone approve a

00:04:05,680 --> 00:04:09,370
change that that would be a bad idea for

00:04:07,780 --> 00:04:11,709
the company's overall risk profile right

00:04:09,370 --> 00:04:13,600
these are all actions that people need

00:04:11,709 --> 00:04:16,840
to take to ensure that we're doing our

00:04:13,600 --> 00:04:20,500
best job protecting our organization and

00:04:16,840 --> 00:04:22,840
most importantly our customers so you

00:04:20,500 --> 00:04:24,370
really need to have holistic security

00:04:22,840 --> 00:04:27,040
awareness training for everyone at the

00:04:24,370 --> 00:04:30,030
company this this isn't optional

00:04:27,040 --> 00:04:32,170
I'll talk a bit about why in a minute

00:04:30,030 --> 00:04:35,890
and what so what I suggest you do is

00:04:32,170 --> 00:04:39,760
focus on some some very basic security

00:04:35,890 --> 00:04:42,340
hygiene practices good passwords is that

00:04:39,760 --> 00:04:44,050
is the easy one luckily there are

00:04:42,340 --> 00:04:48,370
several good password management

00:04:44,050 --> 00:04:50,440
utilities LastPass in one pass then they

00:04:48,370 --> 00:04:52,000
are not hard to use I hesitated in a

00:04:50,440 --> 00:04:53,710
minute last pass is a little hard to use

00:04:52,000 --> 00:04:55,180
but it has some good features so it's

00:04:53,710 --> 00:04:57,610
kind of worth it so you can make a

00:04:55,180 --> 00:04:59,730
decision there about you x versus

00:04:57,610 --> 00:05:01,660
features and decide which one you like

00:04:59,730 --> 00:05:03,630
train your staff at using a password

00:05:01,660 --> 00:05:07,000
manager that will dramatically level up

00:05:03,630 --> 00:05:08,890
how to the sort of organizational

00:05:07,000 --> 00:05:12,460
security posture of of their platform

00:05:08,890 --> 00:05:14,320
shared password reuse that is using the

00:05:12,460 --> 00:05:16,360
same password on one side and another

00:05:14,320 --> 00:05:18,460
and then site a gets compromised and

00:05:16,360 --> 00:05:21,970
attackers use it on site B is an

00:05:18,460 --> 00:05:24,430
incredibly common exploit vector there

00:05:21,970 --> 00:05:28,210
was an interesting breach a number of

00:05:24,430 --> 00:05:30,070
years ago of a company was their name

00:05:28,210 --> 00:05:32,140
they were they were a mongodb like as a

00:05:30,070 --> 00:05:34,870
service provider and the way that they

00:05:32,140 --> 00:05:37,450
were compromised was that the password

00:05:34,870 --> 00:05:41,080
that was used was used by a staff member

00:05:37,450 --> 00:05:44,290
on Adobe's website and Adobe was

00:05:41,080 --> 00:05:46,270
compromised and with the compromise to

00:05:44,290 --> 00:05:48,670
the provider a shared password

00:05:46,270 --> 00:05:50,410
used by a user of that service was used

00:05:48,670 --> 00:05:51,970
to compromise another serve as a

00:05:50,410 --> 00:05:54,400
continuous integration service and so

00:05:51,970 --> 00:05:56,250
you have this chain of the attacker

00:05:54,400 --> 00:05:58,390
moving from platform to platform

00:05:56,250 --> 00:06:00,730
harvesting passwords and trying them

00:05:58,390 --> 00:06:01,990
across other other systems so cutting

00:06:00,730 --> 00:06:03,550
out password reuse through the use of

00:06:01,990 --> 00:06:06,910
technology is a really good way to cut

00:06:03,550 --> 00:06:08,710
that down multi-factor off is a thing it

00:06:06,910 --> 00:06:12,190
works train your you can train your

00:06:08,710 --> 00:06:15,550
staff how to use it and basic training

00:06:12,190 --> 00:06:17,130
in in customer privacy procedures is

00:06:15,550 --> 00:06:19,390
something that you should probably be

00:06:17,130 --> 00:06:21,370
spending some time writing down and

00:06:19,390 --> 00:06:22,830
helping your staff understand this will

00:06:21,370 --> 00:06:25,630
differ from organization to organization

00:06:22,830 --> 00:06:30,160
depending on who your customers are and

00:06:25,630 --> 00:06:33,400
what what privacy means to them but this

00:06:30,160 --> 00:06:35,680
is worth worth the investment let's talk

00:06:33,400 --> 00:06:38,169
a bit about fishing because that's the

00:06:35,680 --> 00:06:40,240
biggest threat that you'll probably face

00:06:38,169 --> 00:06:40,790
to this sort of general population of

00:06:40,240 --> 00:06:45,920
your

00:06:40,790 --> 00:06:48,170
f so fishing this is from the verizon

00:06:45,920 --> 00:06:50,050
does a yearly data breach investigation

00:06:48,170 --> 00:06:52,700
report where they compile data on

00:06:50,050 --> 00:06:55,640
security breaches from hundreds of

00:06:52,700 --> 00:06:59,350
organizations and do a bunch of analysis

00:06:55,640 --> 00:07:02,900
and grouping of the types of

00:06:59,350 --> 00:07:06,230
vulnerabilities and they find that more

00:07:02,900 --> 00:07:07,760
than two-thirds of incidents that that

00:07:06,230 --> 00:07:11,090
follow this pattern of trying to steal

00:07:07,760 --> 00:07:13,940
data feature fishing most attacks start

00:07:11,090 --> 00:07:16,730
with either a targeted or an untargeted

00:07:13,940 --> 00:07:18,170
phishing email what's really scary if

00:07:16,730 --> 00:07:20,600
you're in the security field is that

00:07:18,170 --> 00:07:22,850
almost a quarter of recipients open

00:07:20,600 --> 00:07:25,490
phishing messages and ten percent of

00:07:22,850 --> 00:07:28,340
them click on attachments which means

00:07:25,490 --> 00:07:31,430
that just 10 emails gives you a ninety

00:07:28,340 --> 00:07:33,020
percent success rate right that's pretty

00:07:31,430 --> 00:07:35,270
scary that means as an attacker I only

00:07:33,020 --> 00:07:38,360
need to send you to your company ten

00:07:35,270 --> 00:07:41,270
emails to have a fairly good chance of

00:07:38,360 --> 00:07:43,070
successfully fishing someone so what can

00:07:41,270 --> 00:07:44,870
we do about this this is a big threat

00:07:43,070 --> 00:07:47,270
and it's really hard to address because

00:07:44,870 --> 00:07:50,420
it's it's it's people so there's some

00:07:47,270 --> 00:07:55,100
technology tools you good email

00:07:50,420 --> 00:07:57,680
filtering helps Gmail's great being able

00:07:55,100 --> 00:07:59,750
to store and archive all of your

00:07:57,680 --> 00:08:01,640
organization's email so that you can you

00:07:59,750 --> 00:08:03,290
can determine the scope of a phishing

00:08:01,640 --> 00:08:06,050
attack if one occurs is another great

00:08:03,290 --> 00:08:07,610
technological stuff but really training

00:08:06,050 --> 00:08:11,870
is the main thing that you that you have

00:08:07,610 --> 00:08:15,620
to do here the same the same study the

00:08:11,870 --> 00:08:17,510
the d.i.b are also found that the best

00:08:15,620 --> 00:08:20,900
early warning system for phishing

00:08:17,510 --> 00:08:22,670
attacks is is your own staff a properly

00:08:20,900 --> 00:08:24,530
trained staff the average time to

00:08:22,670 --> 00:08:26,720
respond to a phishing attack was 20

00:08:24,530 --> 00:08:28,840
minutes so if you have a staff that

00:08:26,720 --> 00:08:31,100
knows what fishing is and understands

00:08:28,840 --> 00:08:33,410
what it is and how to report it to you

00:08:31,100 --> 00:08:35,810
and how to how to sort of tell you that

00:08:33,410 --> 00:08:37,220
something something's up you have a

00:08:35,810 --> 00:08:39,710
better than average chance of catching

00:08:37,220 --> 00:08:42,200
an attack early on you can do this

00:08:39,710 --> 00:08:44,300
yourself you can also pay for this fish

00:08:42,200 --> 00:08:46,160
mecom is really good they'll they'll run

00:08:44,300 --> 00:08:48,710
phishing attacks against your staff for

00:08:46,160 --> 00:08:50,990
you you give them your staff email lists

00:08:48,710 --> 00:08:53,450
and they do targeted and different types

00:08:50,990 --> 00:08:54,860
of phishing attacks and anyone who

00:08:53,450 --> 00:08:57,710
for one gets taken to a special

00:08:54,860 --> 00:09:00,620
customized training specifically for

00:08:57,710 --> 00:09:02,030
that style of fishing attack so it's a

00:09:00,620 --> 00:09:04,130
it's a good service i can i can

00:09:02,030 --> 00:09:05,330
recommend them if you've if throwing

00:09:04,130 --> 00:09:11,600
money at the problem is something you

00:09:05,330 --> 00:09:13,310
can do the other part of this is writing

00:09:11,600 --> 00:09:14,300
code or in a program in conference so

00:09:13,310 --> 00:09:18,230
i'd be remiss if i didn't talk about

00:09:14,300 --> 00:09:19,970
code a little bit so who do you think

00:09:18,230 --> 00:09:22,520
should be responsible for writing secure

00:09:19,970 --> 00:09:25,400
code whose job is it to write secure

00:09:22,520 --> 00:09:26,900
code I heard someone say everyone and

00:09:25,400 --> 00:09:29,210
it's you know it's the same question is

00:09:26,900 --> 00:09:30,860
who's responsible for writing tests you

00:09:29,210 --> 00:09:32,420
know we used to have this we used to

00:09:30,860 --> 00:09:33,920
have this idea about software testing

00:09:32,420 --> 00:09:36,380
that you had like test engineers and

00:09:33,920 --> 00:09:40,190
they would like test code and then the

00:09:36,380 --> 00:09:42,080
the other engineers would write you know

00:09:40,190 --> 00:09:44,570
the code code and then they'd like I

00:09:42,080 --> 00:09:48,680
don't know meet with pistols at dawn or

00:09:44,570 --> 00:09:51,800
something on and like yeah safe to say

00:09:48,680 --> 00:09:53,630
that didn't work you know one of the the

00:09:51,800 --> 00:09:56,240
main innovation of test-driven

00:09:53,630 --> 00:09:58,340
development isn't necessarily the the

00:09:56,240 --> 00:10:00,200
acronyms and the and the styles and the

00:09:58,340 --> 00:10:02,420
kenda and the and the functions but just

00:10:00,200 --> 00:10:04,610
the idea that testing and coding are

00:10:02,420 --> 00:10:06,790
this inextricably linked cycle and it's

00:10:04,610 --> 00:10:11,020
the same way with secure development

00:10:06,790 --> 00:10:14,420
presa Tabriz who runs chrome security

00:10:11,020 --> 00:10:17,390
has said that one of the key factors in

00:10:14,420 --> 00:10:19,130
her success at Google has been to push

00:10:17,390 --> 00:10:21,590
decisions around security as far down

00:10:19,130 --> 00:10:23,180
the chain as possible and this is kind

00:10:21,590 --> 00:10:25,720
of counterintuitive because you might

00:10:23,180 --> 00:10:28,340
you might intuitively think you know

00:10:25,720 --> 00:10:30,590
these are company-wide risks we need to

00:10:28,340 --> 00:10:32,030
have the director of security making all

00:10:30,590 --> 00:10:34,280
the security decisions because then

00:10:32,030 --> 00:10:36,260
we'll be really secure and it doesn't

00:10:34,280 --> 00:10:38,990
really work that way the further you get

00:10:36,260 --> 00:10:40,250
from the you know the hands on keyboard

00:10:38,990 --> 00:10:42,140
the people writing the code the less

00:10:40,250 --> 00:10:44,210
context and information you have and the

00:10:42,140 --> 00:10:47,090
less able you are to really assess a

00:10:44,210 --> 00:10:48,530
risk and so you know if you like me or

00:10:47,090 --> 00:10:51,680
someone in management your main job

00:10:48,530 --> 00:10:53,120
should be to be empower and push those

00:10:51,680 --> 00:10:55,130
decisions as far down the sack as

00:10:53,120 --> 00:10:56,720
possible sure in the middle of an

00:10:55,130 --> 00:11:00,080
incident you need command and control

00:10:56,720 --> 00:11:01,340
right you need top down you know crisis

00:11:00,080 --> 00:11:03,710
mode leadership in the middle of an

00:11:01,340 --> 00:11:06,980
incident but for the day-to-day bread

00:11:03,710 --> 00:11:07,130
and butter of writing code it's got to

00:11:06,980 --> 00:11:09,140
be

00:11:07,130 --> 00:11:11,330
II you know it's got to be people

00:11:09,140 --> 00:11:14,360
average developers writing code

00:11:11,330 --> 00:11:15,710
day-to-day and so there's some good news

00:11:14,360 --> 00:11:18,440
here which is that actually writing

00:11:15,710 --> 00:11:20,420
secure code is easy now there's there's

00:11:18,440 --> 00:11:21,890
this idea that like security is really

00:11:20,420 --> 00:11:25,190
really hard so we need to leave it to

00:11:21,890 --> 00:11:28,610
the experts and I want to I want to push

00:11:25,190 --> 00:11:30,800
back on that um yes there are parts of

00:11:28,610 --> 00:11:34,730
security that are hard cryptography is

00:11:30,800 --> 00:11:37,250
impossible I barely understand how um

00:11:34,730 --> 00:11:38,720
how sort of prime factorization crypto

00:11:37,250 --> 00:11:41,270
works and now we've got this elliptical

00:11:38,720 --> 00:11:46,400
key stuff and I mean you left me behind

00:11:41,270 --> 00:11:48,770
a long time ago but but most most coding

00:11:46,400 --> 00:11:54,260
does not involve that right most coding

00:11:48,770 --> 00:11:58,190
is day-to-day fairly easy basic security

00:11:54,260 --> 00:12:00,440
hygiene and basic security hygiene can

00:11:58,190 --> 00:12:03,920
get you a surprisingly far away when you

00:12:00,440 --> 00:12:06,200
look into breach reports those that have

00:12:03,920 --> 00:12:08,390
happened because of vulnerable software

00:12:06,200 --> 00:12:10,540
they're always basic stuff sequel

00:12:08,390 --> 00:12:13,370
injection cross-site scripting

00:12:10,540 --> 00:12:15,080
cross-site request forgery the basics

00:12:13,370 --> 00:12:18,470
the stuff that's that's in the OWASP top

00:12:15,080 --> 00:12:20,480
10 is rare for a truly novel and hard

00:12:18,470 --> 00:12:22,730
security vulnerability to actually do a

00:12:20,480 --> 00:12:24,350
real world compromise so by expending a

00:12:22,730 --> 00:12:26,930
small amount of effort in basic training

00:12:24,350 --> 00:12:29,180
you can get really really far and

00:12:26,930 --> 00:12:31,490
there's a lot of good resources out

00:12:29,180 --> 00:12:35,690
there these are four of my favorite

00:12:31,490 --> 00:12:38,270
there's probably quite a few others OS

00:12:35,690 --> 00:12:40,100
maintained a sort of top 10 security

00:12:38,270 --> 00:12:43,280
risks with information on how to address

00:12:40,100 --> 00:12:45,950
them and how to and and what they look

00:12:43,280 --> 00:12:49,610
like and you know pointers to different

00:12:45,950 --> 00:12:51,160
languages Mozilla's secure coding

00:12:49,610 --> 00:12:53,780
guidelines are probably the best

00:12:51,160 --> 00:12:55,250
publicly available application security

00:12:53,780 --> 00:12:57,080
guidelines they're somewhat language

00:12:55,250 --> 00:12:58,910
agnostic although Mozilla writes a lot

00:12:57,080 --> 00:13:01,780
of their code in python and django so

00:12:58,910 --> 00:13:04,850
it'll play well to this crowd

00:13:01,780 --> 00:13:08,780
microsoft's guidelines are a little more

00:13:04,850 --> 00:13:10,460
focus towards compiled software as our

00:13:08,780 --> 00:13:12,710
apples and so depending on what

00:13:10,460 --> 00:13:14,810
environment you're writing for and what

00:13:12,710 --> 00:13:17,780
type of software you're writing one or

00:13:14,810 --> 00:13:20,390
more of these may make a good secure

00:13:17,780 --> 00:13:20,960
coding guide and your company's secure

00:13:20,390 --> 00:13:22,910
coding god

00:13:20,960 --> 00:13:25,970
could literally be go read the OWASP top

00:13:22,910 --> 00:13:28,760
10 that would be you know that would

00:13:25,970 --> 00:13:33,850
already put you many many feet above

00:13:28,760 --> 00:13:36,080
average all right so monday is complete

00:13:33,850 --> 00:13:37,910
you've developed a basic security

00:13:36,080 --> 00:13:39,800
awareness training program covering

00:13:37,910 --> 00:13:41,810
phishing attacks multi-factor off how to

00:13:39,800 --> 00:13:43,310
use password managers and you've picked

00:13:41,810 --> 00:13:45,380
a secure coding guide maybe you've

00:13:43,310 --> 00:13:47,810
customized it a little bit maybe you've

00:13:45,380 --> 00:13:52,210
just taken one off the shelf and put

00:13:47,810 --> 00:13:55,580
some resources linking out to your staff

00:13:52,210 --> 00:13:58,640
so tuesday we're going to build an SD l

00:13:55,580 --> 00:14:00,020
okay so it's a buzzword I'm sorry sdl

00:13:58,640 --> 00:14:03,680
stands for secure development lifecycle

00:14:00,020 --> 00:14:05,660
and and depending on the level of

00:14:03,680 --> 00:14:07,550
formality view of your organization this

00:14:05,660 --> 00:14:09,770
this could involve lots of fancy flow

00:14:07,550 --> 00:14:11,960
charts and diagrams that look like

00:14:09,770 --> 00:14:14,000
they're off a government slide but

00:14:11,960 --> 00:14:16,640
really an SD l is an answer to a very

00:14:14,000 --> 00:14:18,950
basic question okay we've told people

00:14:16,640 --> 00:14:22,040
how to light secure code how do we make

00:14:18,950 --> 00:14:24,320
sure it happens right we know what the

00:14:22,040 --> 00:14:26,690
best practices are we know that our

00:14:24,320 --> 00:14:28,280
staff is smart and wants to do them what

00:14:26,690 --> 00:14:32,690
is our mechanism for making sure that

00:14:28,280 --> 00:14:35,600
they do and for me the heart of an SD l

00:14:32,690 --> 00:14:37,820
is figuring out this virtuous cycle is

00:14:35,600 --> 00:14:40,790
figuring out how we take we take the

00:14:37,820 --> 00:14:42,830
things that we know we translate them

00:14:40,790 --> 00:14:45,230
into best practices for our organization

00:14:42,830 --> 00:14:48,620
we follow those best practices in

00:14:45,230 --> 00:14:51,740
development things happen either

00:14:48,620 --> 00:14:54,770
successes or failures we analyze them

00:14:51,740 --> 00:14:57,440
and that builds more knowledge how do we

00:14:54,770 --> 00:14:59,270
build this program so that we are

00:14:57,440 --> 00:15:00,830
continually feeding in the results of

00:14:59,270 --> 00:15:04,400
the things that we learn about security

00:15:00,830 --> 00:15:07,520
as we develop software continuously so

00:15:04,400 --> 00:15:10,550
for me the minimum sdl needs to answer

00:15:07,520 --> 00:15:13,640
three basic questions when do we do

00:15:10,550 --> 00:15:15,230
security at what point during join our

00:15:13,640 --> 00:15:18,260
software development lifecycle do we

00:15:15,230 --> 00:15:22,550
think about security who is doing that

00:15:18,260 --> 00:15:25,940
thinking and what does doing security

00:15:22,550 --> 00:15:28,580
even mean so you could answer these

00:15:25,940 --> 00:15:31,720
questions in several ways I have a

00:15:28,580 --> 00:15:35,199
suggestion visit how I've answered them

00:15:31,720 --> 00:15:37,029
I think doing security throughout

00:15:35,199 --> 00:15:39,910
development as much as possible it is

00:15:37,029 --> 00:15:42,310
the best way to go we have an internal

00:15:39,910 --> 00:15:46,449
security mailing list we have a chat

00:15:42,310 --> 00:15:49,149
channel we use you know github comments

00:15:46,449 --> 00:15:51,610
we have met there are multiple ways at

00:15:49,149 --> 00:15:53,529
Heroku for staff to get in touch with us

00:15:51,610 --> 00:15:55,720
and ask us questions ranging from very

00:15:53,529 --> 00:15:58,480
simple like hey what library do we use

00:15:55,720 --> 00:16:01,050
for OAuth again to you know I'm

00:15:58,480 --> 00:16:03,430
designing an entirely new you know

00:16:01,050 --> 00:16:06,699
crypto widget and I need a lot of help

00:16:03,430 --> 00:16:08,410
right any size of engagement when we're

00:16:06,699 --> 00:16:10,569
there so you know being of having

00:16:08,410 --> 00:16:13,180
experts available for questions and and

00:16:10,569 --> 00:16:14,949
and you know building a culture where

00:16:13,180 --> 00:16:16,689
it's cool to ask that stuff and and

00:16:14,949 --> 00:16:20,500
where people help each other out with it

00:16:16,689 --> 00:16:24,240
as much as possible um it's probably a

00:16:20,500 --> 00:16:27,040
good idea to have an explicit security

00:16:24,240 --> 00:16:29,740
step when you're sort of planning and

00:16:27,040 --> 00:16:31,709
building a new product and probably

00:16:29,740 --> 00:16:34,420
again a review just before you ship

00:16:31,709 --> 00:16:37,660
these these are hard when it comes to

00:16:34,420 --> 00:16:40,480
agile because we we don't have as many

00:16:37,660 --> 00:16:42,699
explicit design up front steps and

00:16:40,480 --> 00:16:47,319
shipping might be something that we do

00:16:42,699 --> 00:16:49,029
tens or hundreds of times a day it's so

00:16:47,319 --> 00:16:50,559
I don't have a great answer here this is

00:16:49,029 --> 00:16:51,879
still one of these you know really hard

00:16:50,559 --> 00:16:54,730
problem sort of figuring out how to

00:16:51,879 --> 00:16:56,500
integrate security and agile is is an

00:16:54,730 --> 00:16:58,959
ongoing problem and something that's

00:16:56,500 --> 00:17:00,790
sort of you know pretty tricky but but I

00:16:58,959 --> 00:17:03,370
still think you can identify moments

00:17:00,790 --> 00:17:05,260
where you can identify sort of touch

00:17:03,370 --> 00:17:07,270
points you know if you're about to

00:17:05,260 --> 00:17:08,260
launch a new feature if someone's going

00:17:07,270 --> 00:17:10,480
to take the time to write a blog post

00:17:08,260 --> 00:17:11,559
about it yeah maybe at the same time you

00:17:10,480 --> 00:17:15,520
might want to take some time to do an

00:17:11,559 --> 00:17:18,189
explicit security review so who does

00:17:15,520 --> 00:17:20,770
this work again you should be pushing

00:17:18,189 --> 00:17:23,439
security decisions down as far as

00:17:20,770 --> 00:17:26,640
possible so we really focus on giving

00:17:23,439 --> 00:17:29,860
engineers tools and documentation and

00:17:26,640 --> 00:17:31,659
authority to make decisions and taking a

00:17:29,860 --> 00:17:34,679
default position of trust you know we

00:17:31,659 --> 00:17:36,880
are basic assumption is that everyone is

00:17:34,679 --> 00:17:38,650
reasonably competent at their job and

00:17:36,880 --> 00:17:40,419
trying to do it well and that the

00:17:38,650 --> 00:17:42,070
decisions they make are more informed

00:17:40,419 --> 00:17:43,750
the decisions that we make and so we

00:17:42,070 --> 00:17:46,320
should start from a default of trusting

00:17:43,750 --> 00:17:49,690
what average staff do

00:17:46,320 --> 00:17:50,710
if you have dedicated security staff and

00:17:49,690 --> 00:17:52,900
you're lucky enough to have a dedicated

00:17:50,710 --> 00:17:54,610
security team I think the best position

00:17:52,900 --> 00:17:57,880
for that team is sort of a consulting

00:17:54,610 --> 00:18:01,240
role right you're not necessarily saying

00:17:57,880 --> 00:18:05,620
this is the architecture or yes you may

00:18:01,240 --> 00:18:06,850
build that or no you may not your

00:18:05,620 --> 00:18:08,290
consultant you're asking questions

00:18:06,850 --> 00:18:11,470
you're answering questions you're giving

00:18:08,290 --> 00:18:13,870
expert feedback we have a thing we

00:18:11,470 --> 00:18:17,440
talked about on the team about we try

00:18:13,870 --> 00:18:20,140
not to say no we try to say yes if right

00:18:17,440 --> 00:18:22,360
so don't just say like securities well

00:18:20,140 --> 00:18:24,700
shouldn't be you can't do that it should

00:18:22,360 --> 00:18:27,970
be there are risks how do you plan to

00:18:24,700 --> 00:18:30,910
address them and the decision about how

00:18:27,970 --> 00:18:33,490
far up those disses the risk decisions

00:18:30,910 --> 00:18:35,890
make need to be based on some some

00:18:33,490 --> 00:18:37,780
fairly good understanding of what risk

00:18:35,890 --> 00:18:39,429
means for your organization there is

00:18:37,780 --> 00:18:40,960
such a thing as acceptable risk right

00:18:39,429 --> 00:18:43,960
you're going to come up with a situation

00:18:40,960 --> 00:18:45,460
where you've got a known problem but if

00:18:43,960 --> 00:18:47,260
you don't ship tomorrow it's going to

00:18:45,460 --> 00:18:50,140
cost your company forty thousand dollars

00:18:47,260 --> 00:18:52,390
and so you have to make a decision do we

00:18:50,140 --> 00:18:54,429
do we pay them is this security risk but

00:18:52,390 --> 00:18:56,919
so bad that we need to pay the money or

00:18:54,429 --> 00:18:58,840
do we have a plan to remediate it in a

00:18:56,919 --> 00:19:02,470
reasonable enough period of time that

00:18:58,840 --> 00:19:04,630
it's worth it's worth the risk and the

00:19:02,470 --> 00:19:06,669
greater the risk and the green on either

00:19:04,630 --> 00:19:09,070
side the higher up you probably want to

00:19:06,669 --> 00:19:10,780
push that decision that's a company-wide

00:19:09,070 --> 00:19:15,370
risk decision so it probably needs to be

00:19:10,780 --> 00:19:17,549
made company-wide we build tools this is

00:19:15,370 --> 00:19:19,809
one that we have we have a little we

00:19:17,549 --> 00:19:21,100
refer to this as the twine game it's

00:19:19,809 --> 00:19:23,559
like a choose-your-own-adventure sort of

00:19:21,100 --> 00:19:25,720
point and click to sort of figure out

00:19:23,559 --> 00:19:27,640
what level of risk a particular project

00:19:25,720 --> 00:19:30,400
is going to be and sort of self-service

00:19:27,640 --> 00:19:35,410
the decision about whether you might

00:19:30,400 --> 00:19:37,299
want to involve our team or not so what

00:19:35,410 --> 00:19:39,040
does doing security mean this is the

00:19:37,299 --> 00:19:40,470
last part here what do we what are we

00:19:39,040 --> 00:19:43,090
talking about when we say doing security

00:19:40,470 --> 00:19:45,190
so I think checklists are the greatest

00:19:43,090 --> 00:19:46,960
invention since uh since sliced bread

00:19:45,190 --> 00:19:48,280
probably better i would i would give up

00:19:46,960 --> 00:19:50,669
sliced bread if I if I got to keep

00:19:48,280 --> 00:19:50,669
checklists

00:19:51,660 --> 00:19:55,740
and a good introduction to checklist is

00:19:53,700 --> 00:19:57,450
in tool Galante's book the checklist

00:19:55,740 --> 00:19:59,670
manifesto great book he's an amazing

00:19:57,450 --> 00:20:04,610
writer really good to read in one

00:19:59,670 --> 00:20:07,920
example he gives is so there's there's a

00:20:04,610 --> 00:20:10,380
doctor at Hopkins called Peter Pronovost

00:20:07,920 --> 00:20:12,180
to sort of the invention of using

00:20:10,380 --> 00:20:15,360
checklist in inventor of using checklist

00:20:12,180 --> 00:20:18,030
in medicine and they were having a big

00:20:15,360 --> 00:20:20,220
problem with central line infections and

00:20:18,030 --> 00:20:22,470
so he designed a checklist I think that

00:20:20,220 --> 00:20:24,630
five items on was really simple like do

00:20:22,470 --> 00:20:27,360
you have clean drapes is the needle

00:20:24,630 --> 00:20:31,050
clean if you washed your hands like it

00:20:27,360 --> 00:20:32,850
was really really basic stuff so free so

00:20:31,050 --> 00:20:34,590
they gave this to to all the doctors and

00:20:32,850 --> 00:20:37,830
nurses doing central lines and monitor

00:20:34,590 --> 00:20:39,330
the results the 10-day infection rate

00:20:37,830 --> 00:20:43,080
went from eleven percent one in 10

00:20:39,330 --> 00:20:44,610
patients were getting infected 20 and in

00:20:43,080 --> 00:20:45,750
fact they were so surprised by this

00:20:44,610 --> 00:20:47,520
result they thought they were doing

00:20:45,750 --> 00:20:50,040
something wrong so they measured it for

00:20:47,520 --> 00:20:51,570
another 18 months because they thought

00:20:50,040 --> 00:20:54,000
that they had messed something up and

00:20:51,570 --> 00:20:56,010
and so all in all in that two and a half

00:20:54,000 --> 00:20:57,750
years there were two central line

00:20:56,010 --> 00:21:00,390
infections after the introduction of the

00:20:57,750 --> 00:21:06,000
checklist down from one in ten to two

00:21:00,390 --> 00:21:08,130
over to a half years grande notes that

00:21:06,000 --> 00:21:09,630
there are there are these three kinds of

00:21:08,130 --> 00:21:12,000
problems in the world there are simple

00:21:09,630 --> 00:21:13,560
problems like baking a cake once you

00:21:12,000 --> 00:21:14,970
know how to bake a cake you can do it

00:21:13,560 --> 00:21:16,680
repeatedly over and over again you can

00:21:14,970 --> 00:21:18,780
give someone a recipe who's never baked

00:21:16,680 --> 00:21:21,360
a cake and they can probably do an okay

00:21:18,780 --> 00:21:23,400
job of it there are complicated problems

00:21:21,360 --> 00:21:25,860
like sending a rocket to a moon the

00:21:23,400 --> 00:21:28,620
recipe is much much longer but there's

00:21:25,860 --> 00:21:30,240
still a recipe we know more or less what

00:21:28,620 --> 00:21:32,340
all the steps are we get it wrong more

00:21:30,240 --> 00:21:34,110
often because it's more complicated but

00:21:32,340 --> 00:21:35,340
we could write a checklist for sending a

00:21:34,110 --> 00:21:36,960
rocket to the moon it would be a lot

00:21:35,340 --> 00:21:39,810
longer than the cake but it would be a

00:21:36,960 --> 00:21:42,060
thing then our complex problems like

00:21:39,810 --> 00:21:44,630
raising a child there's no one way to

00:21:42,060 --> 00:21:47,160
raise a child you can't give someone a

00:21:44,630 --> 00:21:50,250
laminated checklist on how to raise a

00:21:47,160 --> 00:21:54,690
child and expect that to work repeatedly

00:21:50,250 --> 00:21:56,760
every time or even like any time and the

00:21:54,690 --> 00:22:00,860
key observation is that we are besieged

00:21:56,760 --> 00:22:03,540
by simple problems life is full of

00:22:00,860 --> 00:22:05,460
fairly easy things that we just don't

00:22:03,540 --> 00:22:06,870
know how to do or that we just don't do

00:22:05,460 --> 00:22:09,299
instantly and so checklist or how we

00:22:06,870 --> 00:22:11,520
solve simple problems we hand someone a

00:22:09,299 --> 00:22:12,990
checklist that reminds them how to do

00:22:11,520 --> 00:22:16,470
the simple problem so these are a couple

00:22:12,990 --> 00:22:19,649
of hours let's see what are these this

00:22:16,470 --> 00:22:21,960
isn't this is a initial this is sort of

00:22:19,649 --> 00:22:23,070
a project level assessment like this is

00:22:21,960 --> 00:22:24,120
a self-service checklist that a

00:22:23,070 --> 00:22:25,140
developer would walk through when

00:22:24,120 --> 00:22:28,500
they're getting ready to write a new

00:22:25,140 --> 00:22:31,190
component or or reviewing one we have a

00:22:28,500 --> 00:22:33,630
checklist for vulnerability management

00:22:31,190 --> 00:22:35,669
that's when you know we find out that

00:22:33,630 --> 00:22:37,620
there's a vulnerability in openssl just

00:22:35,669 --> 00:22:41,610
hypothetically and have to decide what

00:22:37,620 --> 00:22:44,520
we're going to do about it we have a lot

00:22:41,610 --> 00:22:46,760
of these we think they're great if you

00:22:44,520 --> 00:22:49,140
want to get into dive into the checklist

00:22:46,760 --> 00:22:52,230
world there is yes there is a checklist

00:22:49,140 --> 00:22:54,000
for writing checklists that will tell

00:22:52,230 --> 00:22:55,950
you how to write a good a good checklist

00:22:54,000 --> 00:23:00,330
and of course there's guantes book which

00:22:55,950 --> 00:23:02,039
is pretty fantastic so tuesday you've

00:23:00,330 --> 00:23:04,500
tried you created an STL you've

00:23:02,039 --> 00:23:06,720
documented your virtuous cycle when do

00:23:04,500 --> 00:23:09,929
we do security who does security and

00:23:06,720 --> 00:23:11,309
what is doing security and you know if

00:23:09,929 --> 00:23:12,809
you take only one idea away from this

00:23:11,309 --> 00:23:15,120
talk like please let it be checklist

00:23:12,809 --> 00:23:17,809
they are great they are an incredibly

00:23:15,120 --> 00:23:20,010
lightweight way of introducing

00:23:17,809 --> 00:23:22,190
introducing something you can call a

00:23:20,010 --> 00:23:26,309
process without the sort of like

00:23:22,190 --> 00:23:28,559
overhead and and sort of a you know

00:23:26,309 --> 00:23:30,419
business e that you normally

00:23:28,559 --> 00:23:41,549
associate with words like process and

00:23:30,419 --> 00:23:43,649
policy okay so you you know your staff

00:23:41,549 --> 00:23:45,779
is trained you know how to ID secure

00:23:43,649 --> 00:23:48,330
software now it's time to start thinking

00:23:45,779 --> 00:23:50,760
about when things go wrong you know as

00:23:48,330 --> 00:23:54,809
Bob Dylan said everybody must get owned

00:23:50,760 --> 00:23:56,070
I think I have that right the fact is

00:23:54,809 --> 00:23:59,399
though that this is this is sort of

00:23:56,070 --> 00:24:02,279
unfortunately true bruchschnauser

00:23:59,399 --> 00:24:05,760
observed that we're starting to sort of

00:24:02,279 --> 00:24:09,090
view breaches as a fact of life and this

00:24:05,760 --> 00:24:11,520
is so this is depressing because it

00:24:09,090 --> 00:24:13,200
shows just how bad we are at our jobs

00:24:11,520 --> 00:24:16,750
and how much we need to really level up

00:24:13,200 --> 00:24:19,340
here to stay ahead of the black hats but

00:24:16,750 --> 00:24:21,530
there's some there's some silver lining

00:24:19,340 --> 00:24:23,210
to that for people involved in security

00:24:21,530 --> 00:24:25,490
because it means that more and more were

00:24:23,210 --> 00:24:28,190
judged on our response our time to

00:24:25,490 --> 00:24:32,320
respond our ability to contain an attack

00:24:28,190 --> 00:24:35,750
our transparency our security practices

00:24:32,320 --> 00:24:39,020
really interesting point this this is a

00:24:35,750 --> 00:24:40,940
tangent but this just happened the there

00:24:39,020 --> 00:24:44,600
was just a circuit court that ruled that

00:24:40,940 --> 00:24:46,880
the FTC has the authority to find

00:24:44,600 --> 00:24:49,580
companies for violating security

00:24:46,880 --> 00:24:51,860
practices under the under the idea that

00:24:49,580 --> 00:24:53,660
it's deceptive trade practice to offer

00:24:51,860 --> 00:24:56,810
your customers privacy and then not

00:24:53,660 --> 00:24:58,430
follow basic security practices this is

00:24:56,810 --> 00:25:01,520
a really interesting decision because it

00:24:58,430 --> 00:25:04,040
implies that the FTC might actually be

00:25:01,520 --> 00:25:05,510
getting into that courts and and

00:25:04,040 --> 00:25:09,200
regulators are getting into the business

00:25:05,510 --> 00:25:10,640
not just of like you know regulating PCI

00:25:09,200 --> 00:25:13,400
and HIPAA and those sorts of things but

00:25:10,640 --> 00:25:14,780
actually like do you have a swirl you

00:25:13,400 --> 00:25:16,010
don't has your passwords that's an

00:25:14,780 --> 00:25:18,140
accepted best practice we're going to

00:25:16,010 --> 00:25:19,850
fine you for doing it and so suddenly I

00:25:18,140 --> 00:25:21,530
think we're reaching a point where

00:25:19,850 --> 00:25:23,690
companies security practices are being

00:25:21,530 --> 00:25:25,760
critiqued certainly in the court of

00:25:23,690 --> 00:25:28,610
public opinion as we've seen with with

00:25:25,760 --> 00:25:29,930
Sony and Ashley Madison but I think

00:25:28,610 --> 00:25:31,490
we're actually shortly going to start

00:25:29,930 --> 00:25:35,180
seeing companies security practices

00:25:31,490 --> 00:25:36,380
critiqued in the court of courts and I

00:25:35,180 --> 00:25:38,450
think that's nothing but a good thing

00:25:36,380 --> 00:25:40,280
right I think that will drive much more

00:25:38,450 --> 00:25:46,850
adherence to the things that we already

00:25:40,280 --> 00:25:49,250
know are our best practices but so what

00:25:46,850 --> 00:25:50,360
this means for us is that we need to we

00:25:49,250 --> 00:25:53,750
need to get our house in order before

00:25:50,360 --> 00:25:56,570
anything happens there's no way if your

00:25:53,750 --> 00:25:58,430
incident response planning starts when

00:25:56,570 --> 00:26:00,290
you get that phone call telling you that

00:25:58,430 --> 00:26:01,640
something's wrong or that there are

00:26:00,290 --> 00:26:03,020
attackers on the network or that there

00:26:01,640 --> 00:26:06,170
was a log in from someone who left the

00:26:03,020 --> 00:26:08,120
company a year and a half ago yeah I

00:26:06,170 --> 00:26:10,670
mean it's just going to be it's going to

00:26:08,120 --> 00:26:15,170
be disastrous I know one company that

00:26:10,670 --> 00:26:16,880
was breached last year that I spoke to a

00:26:15,170 --> 00:26:19,520
person who introduced themselves as

00:26:16,880 --> 00:26:23,450
their see so their director of security

00:26:19,520 --> 00:26:25,400
I found out later that they didn't have

00:26:23,450 --> 00:26:27,760
a security department and when the

00:26:25,400 --> 00:26:30,190
breach began the CEO called this person

00:26:27,760 --> 00:26:35,130
said I'm promoting you to our chief

00:26:30,190 --> 00:26:40,180
security officer deal with this yeah

00:26:35,130 --> 00:26:42,220
don't don't do that so it's hard for me

00:26:40,180 --> 00:26:44,440
to be more p as prescriptive as I've

00:26:42,220 --> 00:26:46,240
been in in previous points here because

00:26:44,440 --> 00:26:47,620
I think the details of what an incident

00:26:46,240 --> 00:26:50,140
response plan will be are going to be

00:26:47,620 --> 00:26:52,630
very specific to your organization and

00:26:50,140 --> 00:26:55,000
your risk profile and your your

00:26:52,630 --> 00:26:57,730
regulatory exposure and your customer

00:26:55,000 --> 00:26:59,320
base and your product and etc so I just

00:26:57,730 --> 00:27:02,200
want to give you some questions to think

00:26:59,320 --> 00:27:04,720
about and a framework to structure your

00:27:02,200 --> 00:27:06,640
incident response response plan and and

00:27:04,720 --> 00:27:09,520
the work in writing an incident response

00:27:06,640 --> 00:27:13,360
plan is is answering these questions so

00:27:09,520 --> 00:27:17,520
so I break down I are into and into five

00:27:13,360 --> 00:27:20,260
steps the first one is you know

00:27:17,520 --> 00:27:23,110
initiating a response how does someone

00:27:20,260 --> 00:27:24,790
report a breach how do we track

00:27:23,110 --> 00:27:26,710
incidents you know you have a bug

00:27:24,790 --> 00:27:29,740
tracker do you used you have a

00:27:26,710 --> 00:27:31,380
whiteboard do you use Trello where do

00:27:29,740 --> 00:27:33,760
you track that stuff what are the

00:27:31,380 --> 00:27:35,350
another good point what happens if the

00:27:33,760 --> 00:27:37,570
thing that you use to track is the thing

00:27:35,350 --> 00:27:39,520
that's been compromised good question to

00:27:37,570 --> 00:27:40,870
ask what are the roles and

00:27:39,520 --> 00:27:44,140
responsibilities doing during an

00:27:40,870 --> 00:27:45,370
incident as you move into actually

00:27:44,140 --> 00:27:47,080
managing the incident you need to

00:27:45,370 --> 00:27:50,080
understand how communication is going to

00:27:47,080 --> 00:27:52,150
be happening who communicates where does

00:27:50,080 --> 00:27:54,940
it happen who's involved how often do

00:27:52,150 --> 00:27:56,860
you send situation updates you know an

00:27:54,940 --> 00:28:00,610
important question for people at the

00:27:56,860 --> 00:28:02,590
sort of senior management level is like

00:28:00,610 --> 00:28:04,690
at what point do I need to wake up you

00:28:02,590 --> 00:28:06,370
know the CEO the executive team like how

00:28:04,690 --> 00:28:09,460
severe doesn't need to get when I need

00:28:06,370 --> 00:28:14,410
to bring in lawyers you know those sorts

00:28:09,460 --> 00:28:16,660
of questions we need to figure out

00:28:14,410 --> 00:28:17,610
what's even going wrong like and how are

00:28:16,660 --> 00:28:20,620
we going to collect this information

00:28:17,610 --> 00:28:23,370
who's going to follow up this can be

00:28:20,620 --> 00:28:25,630
fairly lightweight a preferred tool for

00:28:23,370 --> 00:28:27,850
assessment during a breach is just a

00:28:25,630 --> 00:28:29,290
google doc we open is saying we open a

00:28:27,850 --> 00:28:31,210
google doc and everyone just writes in

00:28:29,290 --> 00:28:33,400
it and by the end of the incident there

00:28:31,210 --> 00:28:36,310
might be a hundred pages of just random

00:28:33,400 --> 00:28:38,080
notes and output from firewall logs and

00:28:36,310 --> 00:28:40,960
just random in there but now we've

00:28:38,080 --> 00:28:41,350
got a nice complete time-stamped log

00:28:40,960 --> 00:28:42,940
about

00:28:41,350 --> 00:28:44,220
thing that we did during during the

00:28:42,940 --> 00:28:46,720
response so it doesn't need to be

00:28:44,220 --> 00:28:48,880
heavyweight stuff but knowing that

00:28:46,720 --> 00:28:51,220
that's what you're going to do saves you

00:28:48,880 --> 00:28:52,480
those five minutes of arguing about what

00:28:51,220 --> 00:28:56,289
you're going where you're going to track

00:28:52,480 --> 00:28:59,740
your work so once we figured out how

00:28:56,289 --> 00:29:01,660
severe a problem is we need to know what

00:28:59,740 --> 00:29:05,440
our response SLA needs to be I mean you

00:29:01,660 --> 00:29:08,020
know the reality is that not every not

00:29:05,440 --> 00:29:10,720
every incident is everything's on fire

00:29:08,020 --> 00:29:13,630
all hands on deck stop the presses some

00:29:10,720 --> 00:29:16,900
things are yeah you know this thing is

00:29:13,630 --> 00:29:18,940
bad but you know worse would be waking

00:29:16,900 --> 00:29:20,530
up the team responsible let's get them

00:29:18,940 --> 00:29:22,390
in the morning to fix it and you should

00:29:20,530 --> 00:29:25,260
have some system for determining that so

00:29:22,390 --> 00:29:28,419
it's not a seat-of-the-pants decision

00:29:25,260 --> 00:29:30,700
once once you fix things a really common

00:29:28,419 --> 00:29:32,350
problem is to sort of knee-jerk and fix

00:29:30,700 --> 00:29:34,750
the one thing that happened in that

00:29:32,350 --> 00:29:37,750
situation even though it actually maybe

00:29:34,750 --> 00:29:39,159
that's not the root cause or maybe this

00:29:37,750 --> 00:29:41,140
incident exposes a lot of other

00:29:39,159 --> 00:29:42,370
long-term things so how do you how

00:29:41,140 --> 00:29:45,490
you're going to ensure that any

00:29:42,370 --> 00:29:50,549
long-term remediation tasks are actually

00:29:45,490 --> 00:29:52,870
followed through on and for people with

00:29:50,549 --> 00:29:55,470
customer notification requirements you

00:29:52,870 --> 00:29:58,179
know it's important to know what your

00:29:55,470 --> 00:30:00,880
your legal your ethical your moral

00:29:58,179 --> 00:30:04,630
requirements are around notifying your

00:30:00,880 --> 00:30:07,120
customers there are likely going to be

00:30:04,630 --> 00:30:10,360
both legal requirements and then there I

00:30:07,120 --> 00:30:11,620
hope also ethical requirements around

00:30:10,360 --> 00:30:15,220
when you tell your customers that

00:30:11,620 --> 00:30:17,620
something happened and finally you know

00:30:15,220 --> 00:30:18,970
all of this is useless if you don't

00:30:17,620 --> 00:30:20,950
learn something from it and so you

00:30:18,970 --> 00:30:22,720
should have a you should understand how

00:30:20,950 --> 00:30:25,720
you're going to reflect back on the work

00:30:22,720 --> 00:30:27,460
and explore the causes and what what do

00:30:25,720 --> 00:30:28,780
we need to correct you know what do we

00:30:27,460 --> 00:30:31,059
need to collect what sort of information

00:30:28,780 --> 00:30:34,419
do we need to know again there may be

00:30:31,059 --> 00:30:36,669
legal reasons for this you know we have

00:30:34,419 --> 00:30:38,700
some requirements around the information

00:30:36,669 --> 00:30:41,049
we have to collect around incidents for

00:30:38,700 --> 00:30:43,720
for being able to sort of talk about

00:30:41,049 --> 00:30:45,460
this to our customers but you may also

00:30:43,720 --> 00:30:46,960
want to be able to collect metric on you

00:30:45,460 --> 00:30:48,400
know root cause so you can go back in

00:30:46,960 --> 00:30:50,500
five years and say you know hey five

00:30:48,400 --> 00:30:52,450
years ago half of our vulnerabilities

00:30:50,500 --> 00:30:54,070
we're network related and now only you

00:30:52,450 --> 00:30:54,850
know a quarter of them are we should

00:30:54,070 --> 00:30:58,600
focus elsewhere

00:30:54,850 --> 00:31:02,350
whatever it is so a lot more reading

00:30:58,600 --> 00:31:04,840
I'll give you a few pointers we wrote

00:31:02,350 --> 00:31:07,680
about incident response at Heroku the

00:31:04,840 --> 00:31:10,150
the pattern that we use for handling

00:31:07,680 --> 00:31:12,580
this blog post in particular is about

00:31:10,150 --> 00:31:14,290
production outages when a service goes

00:31:12,580 --> 00:31:16,090
down but we use the same system for

00:31:14,290 --> 00:31:19,270
managing security incidents and it's

00:31:16,090 --> 00:31:22,600
based on the the incident command system

00:31:19,270 --> 00:31:28,600
from like search and response teams and

00:31:22,600 --> 00:31:32,050
then this last one magoo Ryan last name

00:31:28,600 --> 00:31:33,550
is escaping me he ran security at he

00:31:32,050 --> 00:31:35,110
worked in security at Facebook he went

00:31:33,550 --> 00:31:38,640
security coinbase he's got a pretty good

00:31:35,110 --> 00:31:42,430
pedigree and he kind of wrote like a oh

00:31:38,640 --> 00:31:43,600
 you've been owned guide and and you

00:31:42,430 --> 00:31:46,060
you could do a lot worse than just

00:31:43,600 --> 00:31:52,720
starting with that as your as your I our

00:31:46,060 --> 00:31:54,940
guide so wednesday this is this hump

00:31:52,720 --> 00:31:57,490
date is the hardest part of your of your

00:31:54,940 --> 00:32:01,450
week creating your incident response

00:31:57,490 --> 00:32:03,630
plan so thursday governance risk and

00:32:01,450 --> 00:32:08,130
compliance this is the awesome part

00:32:03,630 --> 00:32:10,540
there is an absolute alphabet soup of

00:32:08,130 --> 00:32:15,550
governance and compliance regimes out

00:32:10,540 --> 00:32:16,780
there for four companies and and for end

00:32:15,550 --> 00:32:18,430
for organizations these are just the

00:32:16,780 --> 00:32:20,730
ones I know of in the US like I'm sure

00:32:18,430 --> 00:32:23,770
that there are like 37 million more

00:32:20,730 --> 00:32:25,750
across the world and for the vast

00:32:23,770 --> 00:32:28,840
majority of at least small organizations

00:32:25,750 --> 00:32:30,370
none of these are worth your time now

00:32:28,840 --> 00:32:32,830
this may not be true if you're a health

00:32:30,370 --> 00:32:35,080
information start up like that HIPAA

00:32:32,830 --> 00:32:37,180
spec all 800 pages of it it is your best

00:32:35,080 --> 00:32:39,190
friend if you're in the pay if you're

00:32:37,180 --> 00:32:41,380
taking credit card payments you better

00:32:39,190 --> 00:32:43,360
know PCI if you want to sell things to

00:32:41,380 --> 00:32:45,610
people in Europe safe harbors going to

00:32:43,360 --> 00:32:48,910
be pretty important but for most smaller

00:32:45,610 --> 00:32:52,720
organizations you can skip right over

00:32:48,910 --> 00:32:55,150
these things but you ignore formal risk

00:32:52,720 --> 00:32:56,950
programs at your peril because sooner or

00:32:55,150 --> 00:32:58,390
later you will want to take credit card

00:32:56,950 --> 00:32:59,980
payments you will want to get into the

00:32:58,390 --> 00:33:01,750
health information market you will want

00:32:59,980 --> 00:33:03,010
to sell to people in Europe and it's

00:33:01,750 --> 00:33:05,020
going to be very important when that

00:33:03,010 --> 00:33:06,490
happens for you not to have shot

00:33:05,020 --> 00:33:08,150
yourself in the foot in the early days

00:33:06,490 --> 00:33:10,880
by completely ignoring this work

00:33:08,150 --> 00:33:12,830
so you can save yourself a ton of effort

00:33:10,880 --> 00:33:15,050
by laying a very easy and simple

00:33:12,830 --> 00:33:17,540
groundwork right now for a formal risk

00:33:15,050 --> 00:33:20,330
program and really what we mean when we

00:33:17,540 --> 00:33:22,970
talk about GRC is documentation right

00:33:20,330 --> 00:33:24,500
we're we're at the Django conference I

00:33:22,970 --> 00:33:25,910
don't have to sell you on documentation

00:33:24,500 --> 00:33:28,070
like we know it's a good thing so

00:33:25,910 --> 00:33:29,870
document your security work right have

00:33:28,070 --> 00:33:33,530
you made a decision about company policy

00:33:29,870 --> 00:33:35,660
write it down really really easy stuff

00:33:33,530 --> 00:33:37,700
but surprisingly a lot of sort of

00:33:35,660 --> 00:33:40,730
company policy decisions stay in email

00:33:37,700 --> 00:33:43,100
you know hey everyone from from today

00:33:40,730 --> 00:33:46,250
forward you must use multi-factor off

00:33:43,100 --> 00:33:47,570
with your github account and then you

00:33:46,250 --> 00:33:49,520
don't actually track that anywhere and

00:33:47,570 --> 00:33:50,990
so someone when an auditor asks for

00:33:49,520 --> 00:33:53,180
years later like oh ha what's your

00:33:50,990 --> 00:33:55,130
policy around multi-factor on for github

00:33:53,180 --> 00:33:56,450
you can't produce anything to show them

00:33:55,130 --> 00:33:59,030
whereas if you just take in that email

00:33:56,450 --> 00:34:03,380
and put it on like a wiki somewhere now

00:33:59,030 --> 00:34:04,880
you've got a policy you don't need to

00:34:03,380 --> 00:34:07,220
worry about formal language there's this

00:34:04,880 --> 00:34:09,500
idea a lot in compliance that like you

00:34:07,220 --> 00:34:12,649
need to use this very stilted legalistic

00:34:09,500 --> 00:34:14,510
business language the audience here are

00:34:12,649 --> 00:34:18,490
not judges and lawyers they can be very

00:34:14,510 --> 00:34:22,429
informal our official password policy

00:34:18,490 --> 00:34:25,159
allows it requires that you use at least

00:34:22,429 --> 00:34:29,330
two of letters numbers uppercase

00:34:25,159 --> 00:34:31,370
lowercase and emoji and nearly every

00:34:29,330 --> 00:34:33,350
auditor we've showed that to highlights

00:34:31,370 --> 00:34:39,590
the little emoji line and then gives us

00:34:33,350 --> 00:34:41,330
a big thumbs up about it um the other

00:34:39,590 --> 00:34:43,490
part of this is just is tracking as much

00:34:41,330 --> 00:34:46,669
as you can so you know someone asks you

00:34:43,490 --> 00:34:48,409
for access to a github repo you know

00:34:46,669 --> 00:34:50,030
reply back with an email yes I'm

00:34:48,409 --> 00:34:52,610
confirming I'm giving you access to this

00:34:50,030 --> 00:34:54,530
repo it seems a little formal and weird

00:34:52,610 --> 00:34:55,940
but it ensures that you have a paper

00:34:54,530 --> 00:34:57,770
trail and again this is when you get

00:34:55,940 --> 00:34:59,120
into the point of being audited this is

00:34:57,770 --> 00:35:01,700
what an auditor is going to look for is

00:34:59,120 --> 00:35:04,460
a paper trail of what you've done even

00:35:01,700 --> 00:35:07,130
better most of us are engineers or work

00:35:04,460 --> 00:35:09,350
with them right a system to track access

00:35:07,130 --> 00:35:13,520
control and access requests we wrote one

00:35:09,350 --> 00:35:16,480
it's great otters love it I also which

00:35:13,520 --> 00:35:20,180
suggest that you write three documents

00:35:16,480 --> 00:35:21,710
to become the skeleton of your risk

00:35:20,180 --> 00:35:24,770
program

00:35:21,710 --> 00:35:26,839
a data classification guide what data

00:35:24,770 --> 00:35:29,089
you have where it's stored who has

00:35:26,839 --> 00:35:31,130
access to it what controls are around

00:35:29,089 --> 00:35:33,500
around it what category is it is it is

00:35:31,130 --> 00:35:36,140
it PII personally identifiable

00:35:33,500 --> 00:35:38,780
information is it payment data is it

00:35:36,140 --> 00:35:40,480
customer data you know how do you

00:35:38,780 --> 00:35:44,830
classify and think about your data and

00:35:40,480 --> 00:35:47,900
control access to it the second are

00:35:44,830 --> 00:35:49,400
checklists for access control think

00:35:47,900 --> 00:35:50,780
onboarding and off boarding right when

00:35:49,400 --> 00:35:52,730
someone starts or leaves your

00:35:50,780 --> 00:35:54,890
organization you need to make sure that

00:35:52,730 --> 00:35:57,980
their accounts are turned up and turned

00:35:54,890 --> 00:36:01,820
down this is important for formal audits

00:35:57,980 --> 00:36:04,010
but it's also a common way for people to

00:36:01,820 --> 00:36:05,359
get breached is you know some someone

00:36:04,010 --> 00:36:07,640
who used to work there three years ago

00:36:05,359 --> 00:36:09,109
still has access to github for some

00:36:07,640 --> 00:36:10,820
reason and their email account gets

00:36:09,109 --> 00:36:14,720
taken over and yeah you can do the math

00:36:10,820 --> 00:36:16,670
from there so having a checklist of who

00:36:14,720 --> 00:36:18,560
gets access to what when and how and

00:36:16,670 --> 00:36:21,080
tracking that and then you can go

00:36:18,560 --> 00:36:24,260
through and uncheck items one by one as

00:36:21,080 --> 00:36:25,849
you as the person off boards and the

00:36:24,260 --> 00:36:27,380
third thing is a weird thing to document

00:36:25,849 --> 00:36:29,180
when you don't have much process already

00:36:27,380 --> 00:36:30,770
but I think it's one of the most

00:36:29,180 --> 00:36:32,660
important things you can have is what is

00:36:30,770 --> 00:36:34,190
your exception process there are always

00:36:32,660 --> 00:36:35,630
going to be exceptions they're always

00:36:34,190 --> 00:36:39,380
going to be situations where you need to

00:36:35,630 --> 00:36:42,530
break a rule and it's so much better to

00:36:39,380 --> 00:36:44,780
know how to break rules than to pretend

00:36:42,530 --> 00:36:47,119
the rules never get broken because if

00:36:44,780 --> 00:36:50,180
you just think that everyone always

00:36:47,119 --> 00:36:53,000
follows this policy always then you

00:36:50,180 --> 00:36:55,220
never know when someone's not and it

00:36:53,000 --> 00:36:57,050
bites you to come later but if you spend

00:36:55,220 --> 00:36:58,700
the time to decide you know who approves

00:36:57,050 --> 00:37:00,349
exceptions at what level do they need to

00:36:58,700 --> 00:37:03,380
go out how are they track those sort of

00:37:00,349 --> 00:37:04,760
basic things again auditors love it and

00:37:03,380 --> 00:37:09,589
it's going to level up your your

00:37:04,760 --> 00:37:13,720
company's security posture so document

00:37:09,589 --> 00:37:13,720
everything right some basic policies

00:37:18,310 --> 00:37:24,500
so you've done most of the work now it's

00:37:21,860 --> 00:37:26,300
time to tell people about it you know

00:37:24,500 --> 00:37:29,180
the fact is if you if you actually work

00:37:26,300 --> 00:37:32,270
through this this checklist you will be

00:37:29,180 --> 00:37:34,490
better off than most of your peers let's

00:37:32,270 --> 00:37:36,050
say no I mean look like again we only

00:37:34,490 --> 00:37:38,420
have to look back over the history of

00:37:36,050 --> 00:37:40,940
data breaches over the last few years to

00:37:38,420 --> 00:37:43,790
see that people are getting owned

00:37:40,940 --> 00:37:45,320
through some pretty basic stuff so if

00:37:43,790 --> 00:37:47,990
you've taken the time to address the

00:37:45,320 --> 00:37:49,700
basic stuff you are doing a really good

00:37:47,990 --> 00:37:51,880
job and I know that this stuff is scary

00:37:49,700 --> 00:37:56,230
and I know that security seems like a

00:37:51,880 --> 00:37:58,760
battle we can't win and maybe it is but

00:37:56,230 --> 00:38:00,410
we can win it most of the time and we

00:37:58,760 --> 00:38:03,050
can win against most of the attacks and

00:38:00,410 --> 00:38:05,870
if you've taken the time to address this

00:38:03,050 --> 00:38:07,910
basic stuff you're in you're pretty good

00:38:05,870 --> 00:38:09,470
shape you should feel fairly good about

00:38:07,910 --> 00:38:11,630
this foundation and you should be

00:38:09,470 --> 00:38:13,070
comfortable and happy bragging to your

00:38:11,630 --> 00:38:17,660
customers about the work that you've

00:38:13,070 --> 00:38:20,780
done so I'd suggest a three things you

00:38:17,660 --> 00:38:22,220
do need a privacy policy this is a legal

00:38:20,780 --> 00:38:23,030
requirement if you if you're taking any

00:38:22,220 --> 00:38:26,810
sort of personally identifiable

00:38:23,030 --> 00:38:30,290
information and that should live at your

00:38:26,810 --> 00:38:33,530
site / privacy I'd suggest a security

00:38:30,290 --> 00:38:35,690
page as well that talks about what you

00:38:33,530 --> 00:38:37,070
what you do about security you know

00:38:35,690 --> 00:38:40,010
document some of the stuff that we've

00:38:37,070 --> 00:38:41,690
talked about earlier and and you should

00:38:40,010 --> 00:38:43,670
maintain a security sort of knowledge

00:38:41,690 --> 00:38:45,140
base I'm talk a bit later about whether

00:38:43,670 --> 00:38:49,490
this should be public or private that's

00:38:45,140 --> 00:38:51,860
a that's an interesting question so the

00:38:49,490 --> 00:38:53,180
privacy policy is necessary it's legal

00:38:51,860 --> 00:38:55,430
requirement a lot of companies just

00:38:53,180 --> 00:38:57,140
won't even do business with you you know

00:38:55,430 --> 00:39:00,380
catwalk for Salesforce again when I want

00:38:57,140 --> 00:39:02,750
to buy buy a thing the form that I fill

00:39:00,380 --> 00:39:05,930
out to send for the initial legal review

00:39:02,750 --> 00:39:08,120
like there's a you know link for where I

00:39:05,930 --> 00:39:09,710
need to put in the link to their privacy

00:39:08,120 --> 00:39:11,570
policy and if I don't if they don't have

00:39:09,710 --> 00:39:14,570
one like I can't even get the request

00:39:11,570 --> 00:39:16,910
started right like you know our our

00:39:14,570 --> 00:39:18,980
procurement team are legal review team

00:39:16,910 --> 00:39:20,630
just won't even think about buying from

00:39:18,980 --> 00:39:25,100
you if you don't have a privacy policy

00:39:20,630 --> 00:39:27,410
it's just a non-starter if you have

00:39:25,100 --> 00:39:30,650
lawyers they'll write one for you if you

00:39:27,410 --> 00:39:32,040
don't automatic has published a couple

00:39:30,650 --> 00:39:35,040
of templates that are worth star

00:39:32,040 --> 00:39:36,810
for weirdly automatic and WordPress have

00:39:35,040 --> 00:39:40,050
different privacy policies even though

00:39:36,810 --> 00:39:42,540
they're the same company so I don't hmm

00:39:40,050 --> 00:39:43,710
but I had to figure that out maybe

00:39:42,540 --> 00:39:44,880
they're just two different versions of

00:39:43,710 --> 00:39:47,910
the same template but they're both good

00:39:44,880 --> 00:39:52,190
so you could you could steal you could

00:39:47,910 --> 00:39:57,270
steal and a tribute and and share alike

00:39:52,190 --> 00:39:59,150
and use them your security page you

00:39:57,270 --> 00:40:02,490
should summarize your security practices

00:39:59,150 --> 00:40:03,630
this can be less formal the the best way

00:40:02,490 --> 00:40:05,190
to think about this is sort of this is

00:40:03,630 --> 00:40:06,980
where you tell your security narrative

00:40:05,190 --> 00:40:11,010
right like this is where you talk about

00:40:06,980 --> 00:40:12,540
at a high level what what your security

00:40:11,010 --> 00:40:15,690
program is trying to accomplish you know

00:40:12,540 --> 00:40:16,890
you can kind of explain their what the

00:40:15,690 --> 00:40:19,350
things that you do what your program

00:40:16,890 --> 00:40:21,300
looks like and you know you can brag a

00:40:19,350 --> 00:40:24,090
little bit about how you have a you have

00:40:21,300 --> 00:40:26,370
a risk program and a documented it's in

00:40:24,090 --> 00:40:28,530
a response plan and you know well

00:40:26,370 --> 00:40:30,000
documented privacy policies and you know

00:40:28,530 --> 00:40:33,830
you can talk about all of this stuff and

00:40:30,000 --> 00:40:36,420
in somewhat somewhat bragging languages

00:40:33,830 --> 00:40:38,670
if you have any formal adaptations if

00:40:36,420 --> 00:40:42,420
you've done pci or hippo or etc you

00:40:38,670 --> 00:40:43,530
should list them here and the most

00:40:42,420 --> 00:40:45,810
important thing that you should have on

00:40:43,530 --> 00:40:49,050
this page is tell people how to report

00:40:45,810 --> 00:40:50,580
vulnerabilities you should probably have

00:40:49,050 --> 00:40:53,490
a security mailing list you should

00:40:50,580 --> 00:40:58,140
probably have a pgp key that's kind of

00:40:53,490 --> 00:40:59,340
like a brown mmm test like look that up

00:40:58,140 --> 00:41:01,590
in Wikipedia if you don't get the

00:40:59,340 --> 00:41:03,540
reference the idea is it's sort of a

00:41:01,590 --> 00:41:04,980
sniff test like a way of people for

00:41:03,540 --> 00:41:08,550
people to tell that you're serious is if

00:41:04,980 --> 00:41:09,990
you have a pgp key i'll tell you in like

00:41:08,550 --> 00:41:12,500
two and a half years at Heroku think one

00:41:09,990 --> 00:41:18,360
person is sent us an encrypted email so

00:41:12,500 --> 00:41:20,430
there you go but if you tell people how

00:41:18,360 --> 00:41:23,790
to get in touch with your security team

00:41:20,430 --> 00:41:26,730
uh they'll be much more likely to

00:41:23,790 --> 00:41:29,130
actually do that and not publish

00:41:26,730 --> 00:41:30,750
something publicly about how they tried

00:41:29,130 --> 00:41:34,440
to report a vulnerability and you didn't

00:41:30,750 --> 00:41:36,810
listen so the last one is the security

00:41:34,440 --> 00:41:38,220
faq the way I think about this is every

00:41:36,810 --> 00:41:40,950
time a customer asks you a question

00:41:38,220 --> 00:41:43,950
about security or an internal person a

00:41:40,950 --> 00:41:45,810
product manager a salesperson a market

00:41:43,950 --> 00:41:47,940
person your non technical role asks you

00:41:45,810 --> 00:41:49,950
about security write down the answer and

00:41:47,940 --> 00:41:51,960
over time you'll discover there are some

00:41:49,950 --> 00:41:53,040
natural groupings you know Apple oku of

00:41:51,960 --> 00:41:55,590
course there are a lot of questions

00:41:53,040 --> 00:41:58,260
about containerization like how how do

00:41:55,590 --> 00:42:00,480
we separate one Dino from another Dino

00:41:58,260 --> 00:42:01,650
this comes up a lot and so there's a lot

00:42:00,480 --> 00:42:03,120
of questions in there and we've kind of

00:42:01,650 --> 00:42:06,150
grouped them all around like container

00:42:03,120 --> 00:42:07,920
security you'll notice that we don't

00:42:06,150 --> 00:42:10,470
publish ours publicly and this is an

00:42:07,920 --> 00:42:13,140
interesting point transparency is a

00:42:10,470 --> 00:42:15,780
really important value but there are

00:42:13,140 --> 00:42:17,850
also some good reasons to limit this

00:42:15,780 --> 00:42:20,070
information there may be confidential

00:42:17,850 --> 00:42:21,750
information in there there may be things

00:42:20,070 --> 00:42:25,140
that disclose information about other

00:42:21,750 --> 00:42:28,890
customers that you might not want there

00:42:25,140 --> 00:42:30,570
may be information about the level of

00:42:28,890 --> 00:42:32,160
your security readiness program that you

00:42:30,570 --> 00:42:33,330
want to be transparent with customers

00:42:32,160 --> 00:42:35,780
but you probably don't want to share

00:42:33,330 --> 00:42:38,160
with non customers because they're not

00:42:35,780 --> 00:42:40,260
you know because that's a much broader

00:42:38,160 --> 00:42:42,840
group of people and they're not under

00:42:40,260 --> 00:42:44,730
NDA so my witness litmus test for

00:42:42,840 --> 00:42:47,160
publishing security information is is

00:42:44,730 --> 00:42:50,310
transparency going to make my customers

00:42:47,160 --> 00:42:52,590
safer if it is publish it even if it

00:42:50,310 --> 00:42:54,900
hurts if it's not if it's going to make

00:42:52,590 --> 00:43:00,570
them less safe don't publish it even if

00:42:54,900 --> 00:43:04,260
it hurts so that's your day five privacy

00:43:00,570 --> 00:43:07,800
policy security page and a security FAQ

00:43:04,260 --> 00:43:12,270
so to recap your Minimum Viable security

00:43:07,800 --> 00:43:15,000
program is train your staff develop an

00:43:12,270 --> 00:43:16,860
sdl of virtuous cycle to ensure that you

00:43:15,000 --> 00:43:19,980
continually develop and learn from your

00:43:16,860 --> 00:43:22,500
software development practices have plan

00:43:19,980 --> 00:43:24,960
for incident response when something

00:43:22,500 --> 00:43:28,410
goes wrong be ready to do something

00:43:24,960 --> 00:43:31,820
about it lay the foundations for a

00:43:28,410 --> 00:43:34,260
formal risk program and tell the world

00:43:31,820 --> 00:43:37,220
good job you've built a security program

00:43:34,260 --> 00:43:37,220
thank you

00:43:43,410 --> 00:43:46,960
so i'll be around in the halls and the

00:43:45,490 --> 00:43:49,330
rest of the week and there's contact

00:43:46,960 --> 00:43:51,880
info there so you can ask me questions

00:43:49,330 --> 00:43:55,680
in any of those formats but i won't be

00:43:51,880 --> 00:43:55,680

YouTube URL: https://www.youtube.com/watch?v=r-fjUVMPidk


