Title: DjangoCon US 2015 - Making Django Really, Really, Ridiculously Secure (CW) by Kelsey Gilmore-Innis
Publication date: 2017-11-03
Playlist: DjangoCon US 2015
Description: 
	Callisto (http://projectcallisto.org/) is an online reporting system designed to provide a more empowering, transparent, and confidential reporting experience for college sexual assault survivors. It's absolutely essential that we keep our user's data secure. So essential, in fact, that we couldn't leave it up to developers alone. We'll go over what Django settings, libraries and practices we used to ensure that on the development end. Then we'll walk through the process of obtaining, undergoing, and acting on a formal security audit from a professional security firm. You'll find out what they were looking for, what we missed, and how we fixed it, and how you might approach similar challenges for your companies and applications.
Captions: 
	00:00:15,980 --> 00:00:23,730
okay I have a tradition I like to take a

00:00:20,100 --> 00:00:25,320
speaker selfie if you all indulge me in

00:00:23,730 --> 00:00:31,189
it in a second hang on

00:00:25,320 --> 00:00:31,189
I remember how to work Twitter okay

00:00:38,820 --> 00:00:49,920
thank you yes ah there's an underscore

00:00:48,270 --> 00:00:51,480
on the front of that sorry

00:00:49,920 --> 00:00:53,969
it changed my Twitter to be less

00:00:51,480 --> 00:00:55,050
discoverable which kind of goes against

00:00:53,969 --> 00:00:57,930
the purpose of putting it on a slide

00:00:55,050 --> 00:01:02,100
isn't it so am i I am Kelsey with an

00:00:57,930 --> 00:01:04,680
underscore in front on Twitter I am a

00:01:02,100 --> 00:01:07,560
developer I am NOT a security expert my

00:01:04,680 --> 00:01:09,710
background is in back-end development in

00:01:07,560 --> 00:01:13,799
Scala for many years in Java before that

00:01:09,710 --> 00:01:15,509
I joined sexual health innovations a

00:01:13,799 --> 00:01:21,659
little bit for the beginning of the year

00:01:15,509 --> 00:01:24,270
to build Callisto consumers as the

00:01:21,659 --> 00:01:27,090
patrons fabulous intro explained a

00:01:24,270 --> 00:01:29,360
confidential and secure reporting system

00:01:27,090 --> 00:01:33,090
for sexual assault on college campuses

00:01:29,360 --> 00:01:37,200
it is live as of last week at two

00:01:33,090 --> 00:01:38,460
schools Pomona and USF in California and

00:01:37,200 --> 00:01:40,320
there's a lot of things that cluster

00:01:38,460 --> 00:01:41,100
does there's some really amazing UX

00:01:40,320 --> 00:01:45,000
around it

00:01:41,100 --> 00:01:47,579
we've designed a UX that's meant to be

00:01:45,000 --> 00:01:49,530
supportive and survivor focused and to

00:01:47,579 --> 00:01:52,020
follow best practices an information

00:01:49,530 --> 00:01:55,200
design and interview design which is its

00:01:52,020 --> 00:01:57,600
own field also to surface resources at a

00:01:55,200 --> 00:01:59,759
campus for people who have had a victim

00:01:57,600 --> 00:02:01,860
of this kind of thing there's a ton of

00:01:59,759 --> 00:02:04,530
it that's another talk on the UX stuff

00:02:01,860 --> 00:02:06,899
which has lots of benefits and is really

00:02:04,530 --> 00:02:07,860
exciting but data rise what's important

00:02:06,899 --> 00:02:10,229
about Kalista is that it's an

00:02:07,860 --> 00:02:11,640
information escrow what that means is

00:02:10,229 --> 00:02:12,870
that survivors can come to the site and

00:02:11,640 --> 00:02:13,210
they can write down what happened to

00:02:12,870 --> 00:02:15,040
them

00:02:13,210 --> 00:02:16,240
and they can store it securely until

00:02:15,040 --> 00:02:18,460
they decide what they want to do with

00:02:16,240 --> 00:02:21,700
that information this is kind of a new

00:02:18,460 --> 00:02:23,260
idea you're probably familiar with the

00:02:21,700 --> 00:02:24,370
concept of ESCO in terms of money

00:02:23,260 --> 00:02:26,650
because you do it off when you have a

00:02:24,370 --> 00:02:27,880
house you give money to a trusted third

00:02:26,650 --> 00:02:29,650
party information asked or you give

00:02:27,880 --> 00:02:31,210
information to a trusted third party and

00:02:29,650 --> 00:02:31,540
then you can release it when you're

00:02:31,210 --> 00:02:37,180
ready

00:02:31,540 --> 00:02:38,530
and the challenge for us data wise then

00:02:37,180 --> 00:02:40,720
is to keep that information really

00:02:38,530 --> 00:02:43,780
secure while the survivor decides what

00:02:40,720 --> 00:02:46,000
to do with it so I'm going to talk to

00:02:43,780 --> 00:02:49,210
you about what we did to do that what we

00:02:46,000 --> 00:02:51,760
used in Django to do that a little bit

00:02:49,210 --> 00:02:54,400
about why we chose Django one caveat I

00:02:51,760 --> 00:02:56,500
want to put in at the beginning there is

00:02:54,400 --> 00:02:58,180
no user uploaded content on this site

00:02:56,500 --> 00:03:02,740
besides text so there's no files that

00:02:58,180 --> 00:03:04,180
are uploaded that would be dragons if

00:03:02,740 --> 00:03:06,340
you're doing that there's a whole host

00:03:04,180 --> 00:03:07,630
of security concerns that you need to be

00:03:06,340 --> 00:03:11,800
worried about I'm not going to touch on

00:03:07,630 --> 00:03:15,820
it but just so you know so you can't

00:03:11,800 --> 00:03:18,480
secure data on the Internet so the

00:03:15,820 --> 00:03:22,320
Ashley Madison hack was like

00:03:18,480 --> 00:03:24,910
professionally really bad timing for me

00:03:22,320 --> 00:03:26,020
probably one of the few people who would

00:03:24,910 --> 00:03:28,450
say that it doesn't work at Ashley

00:03:26,020 --> 00:03:30,010
Madison just because suddenly this idea

00:03:28,450 --> 00:03:31,150
of data loss is in the news right and

00:03:30,010 --> 00:03:32,680
there's a ton of fear around it

00:03:31,150 --> 00:03:35,830
understandably it was a really scary

00:03:32,680 --> 00:03:37,150
situation and you know in a lot of ways

00:03:35,830 --> 00:03:38,560
this is true if someone comes up and

00:03:37,150 --> 00:03:40,060
tells you that they can have data that's

00:03:38,560 --> 00:03:43,990
perfectly secure they're selling you

00:03:40,060 --> 00:03:46,710
snake oil right though almost all of the

00:03:43,990 --> 00:03:49,090
practice of security in a big way

00:03:46,710 --> 00:03:50,830
revolves around being pessimistic you

00:03:49,090 --> 00:03:52,420
assume a breach and you work from there

00:03:50,830 --> 00:03:54,090
you want to figure out what the breach

00:03:52,420 --> 00:03:56,590
might be and how you can mitigate it

00:03:54,090 --> 00:03:58,690
that's that's where you should start

00:03:56,590 --> 00:04:01,300
from when you're securing your apps you

00:03:58,690 --> 00:04:03,520
should have a plan for when a breach

00:04:01,300 --> 00:04:04,990
happens you should have a plan for

00:04:03,520 --> 00:04:07,750
knowing that a breach happened which is

00:04:04,990 --> 00:04:09,790
really big and thankfully a Jacob Kaplan

00:04:07,750 --> 00:04:12,820
mas is here to talk a lot about

00:04:09,790 --> 00:04:14,890
practices and sort of organizational

00:04:12,820 --> 00:04:16,109
tools you can build around that so go to

00:04:14,890 --> 00:04:20,049
his talk and we'll go to the next slide

00:04:16,109 --> 00:04:20,830
and I think it's in an hour so that said

00:04:20,049 --> 00:04:23,260
right

00:04:20,830 --> 00:04:24,490
I am personally kind of frustrated with

00:04:23,260 --> 00:04:27,250
some of the press around the Ashley

00:04:24,490 --> 00:04:29,230
Madison hack right because yes

00:04:27,250 --> 00:04:30,910
data on the internet there's a lot of

00:04:29,230 --> 00:04:32,650
security concerns in general with the

00:04:30,910 --> 00:04:35,470
whole concept of data but the Ashley

00:04:32,650 --> 00:04:37,570
Madison breach specifically what we had

00:04:35,470 --> 00:04:39,520
was a really deeply unethical company

00:04:37,570 --> 00:04:41,110
doing really deeply unethical things

00:04:39,520 --> 00:04:44,830
with other people's incredibly sensitive

00:04:41,110 --> 00:04:46,510
data right obviously you can do things

00:04:44,830 --> 00:04:48,580
that are reasonably secure on the

00:04:46,510 --> 00:04:50,460
Internet I assume many of us Bank on the

00:04:48,580 --> 00:04:53,050
internet for example which is incredibly

00:04:50,460 --> 00:04:56,440
sensitive information many of us use

00:04:53,050 --> 00:04:59,140
sayed internet connected health

00:04:56,440 --> 00:04:59,650
information providing offerings and

00:04:59,140 --> 00:05:01,480
things like that

00:04:59,650 --> 00:05:02,740
right there are things we can do and in

00:05:01,480 --> 00:05:04,450
some ways I feel like this narrative

00:05:02,740 --> 00:05:05,830
that like that's what you get if you put

00:05:04,450 --> 00:05:07,600
information on the Internet it'll be out

00:05:05,830 --> 00:05:09,550
there it's kind of a cop out right

00:05:07,600 --> 00:05:11,890
because if you look at the specifics of

00:05:09,550 --> 00:05:13,660
Ashley Madison hack the hackers have

00:05:11,890 --> 00:05:15,430
actually come out and said we were in

00:05:13,660 --> 00:05:17,290
there for years and they didn't notice

00:05:15,430 --> 00:05:18,370
we were using default passwords from the

00:05:17,290 --> 00:05:20,710
internet I mean you know they're

00:05:18,370 --> 00:05:21,820
anonymous ha like you have to take all

00:05:20,710 --> 00:05:23,080
this with a grain of salt but there's a

00:05:21,820 --> 00:05:24,730
lot of evidence out there that this was

00:05:23,080 --> 00:05:28,660
a company that wasn't taking care of

00:05:24,730 --> 00:05:30,430
their consumers data they actually said

00:05:28,660 --> 00:05:31,900
there is no indication of any software

00:05:30,430 --> 00:05:33,960
vulnerability being exploited during

00:05:31,900 --> 00:05:37,870
this incident what that means is that

00:05:33,960 --> 00:05:39,370
people were able to get access through

00:05:37,870 --> 00:05:41,140
the same means that other people were

00:05:39,370 --> 00:05:44,140
getting access whether it was because it

00:05:41,140 --> 00:05:45,400
was and disgruntled employee which is

00:05:44,140 --> 00:05:48,340
what some people said or they just

00:05:45,400 --> 00:05:50,380
didn't lock down their stuff is you know

00:05:48,340 --> 00:05:52,540
still we don't know when we may never

00:05:50,380 --> 00:05:54,100
know but it's important to like be clear

00:05:52,540 --> 00:05:55,870
that there are ethical things you can

00:05:54,100 --> 00:05:58,419
and should do and you have people's data

00:05:55,870 --> 00:06:00,520
that they're trusting to you so

00:05:58,419 --> 00:06:02,140
obviously I would say that right because

00:06:00,520 --> 00:06:03,729
I built this too soon for you - we're

00:06:02,140 --> 00:06:07,030
taking really sensitive data and putting

00:06:03,729 --> 00:06:08,080
it on the Internet so let me talk let me

00:06:07,030 --> 00:06:09,100
start talking about one things we

00:06:08,080 --> 00:06:11,320
learned one of the things we did to

00:06:09,100 --> 00:06:13,630
secure that data and to continue to

00:06:11,320 --> 00:06:15,010
secure that data so one of the things

00:06:13,630 --> 00:06:17,350
it's really awesome but Jenga is that

00:06:15,010 --> 00:06:19,419
you totally get a lot for free Django is

00:06:17,350 --> 00:06:20,800
is a pretty security minded web

00:06:19,419 --> 00:06:23,979
framework they do care about security

00:06:20,800 --> 00:06:25,540
they being you and me and their people

00:06:23,979 --> 00:06:28,870
who comprise Django do care about

00:06:25,540 --> 00:06:30,729
security like one example for an example

00:06:28,870 --> 00:06:32,350
that I found when I was sort of you know

00:06:30,729 --> 00:06:33,490
I did a lot of due diligence when I was

00:06:32,350 --> 00:06:35,099
picking the framework I was using

00:06:33,490 --> 00:06:37,599
because this was a huge concern of ours

00:06:35,099 --> 00:06:40,249
one example is that passwords or what's

00:06:37,599 --> 00:06:42,019
called cryptographically agile what that

00:06:40,249 --> 00:06:44,479
means is so you don't store passwords in

00:06:42,019 --> 00:06:47,539
plain text you derive a key from the

00:06:44,479 --> 00:06:50,629
password or you hash it right and Django

00:06:47,539 --> 00:06:53,389
uses the the algorithm that is sort of

00:06:50,629 --> 00:06:55,999
recommended which is pbkdf2 I don't know

00:06:53,389 --> 00:06:57,559
what that stands for look it up and it's

00:06:55,999 --> 00:06:59,479
an algorithm that uses a certain number

00:06:57,559 --> 00:07:01,129
of iterations it's called a work factor

00:06:59,479 --> 00:07:03,889
and the idea being that you can slow it

00:07:01,129 --> 00:07:06,319
down enough that like large-scale brute

00:07:03,889 --> 00:07:08,929
force is too expensive to actually crack

00:07:06,319 --> 00:07:12,109
something but you can still have that be

00:07:08,929 --> 00:07:13,819
within the bounds of being usable that

00:07:12,109 --> 00:07:15,739
iteration number depends on the power of

00:07:13,819 --> 00:07:18,259
computer of the computer being used both

00:07:15,739 --> 00:07:21,079
to generate the password for real uses

00:07:18,259 --> 00:07:22,639
and to try to crack it so you want to

00:07:21,079 --> 00:07:25,009
increase that as computers get more

00:07:22,639 --> 00:07:27,139
powerful as we know they do and Django

00:07:25,009 --> 00:07:30,949
actually not only uses this best sort of

00:07:27,139 --> 00:07:34,039
best practice one but it's built into as

00:07:30,949 --> 00:07:37,729
as computers get faster and as the

00:07:34,039 --> 00:07:39,799
algorithm gets improved you can you you

00:07:37,729 --> 00:07:41,929
can get increased iterations for free so

00:07:39,799 --> 00:07:43,399
it stores it and it'll recalculate it so

00:07:41,929 --> 00:07:45,469
even if you logged in with an older

00:07:43,399 --> 00:07:48,289
version of Django and you only used say

00:07:45,469 --> 00:07:49,699
you know X number of iterations the next

00:07:48,289 --> 00:07:52,519
time you log in if the developer has

00:07:49,699 --> 00:07:54,289
updated Django it'll recalculate in the

00:07:52,519 --> 00:07:55,369
background and get to accelerations

00:07:54,289 --> 00:07:56,779
that's really cool that's kind of like

00:07:55,369 --> 00:07:59,179
best that's like cutting-edge stuff

00:07:56,779 --> 00:08:00,559
right not all web frameworks do that so

00:07:59,179 --> 00:08:03,019
you get a lot for free that's built in

00:08:00,559 --> 00:08:04,819
just by using Django you also get a lot

00:08:03,019 --> 00:08:07,249
for cheap if you could if you do some

00:08:04,819 --> 00:08:09,169
like basic things that that Django and

00:08:07,249 --> 00:08:11,629
the the ecosystem make really easy to do

00:08:09,169 --> 00:08:13,399
so one of those set your secret secret

00:08:11,629 --> 00:08:14,899
key correctly right like that that is a

00:08:13,399 --> 00:08:16,489
basic one that I'm sure you all do

00:08:14,899 --> 00:08:18,619
there's also a bunch of basic checks

00:08:16,489 --> 00:08:20,659
that you can do that take literally less

00:08:18,619 --> 00:08:22,969
than five minutes Erik's Pony checkup is

00:08:20,659 --> 00:08:24,709
a good one Django secure ism it is it

00:08:22,969 --> 00:08:26,959
gives a management command that lets you

00:08:24,709 --> 00:08:28,249
run checks very similar to jenga's Pony

00:08:26,959 --> 00:08:30,019
checkup and you can integrate that into

00:08:28,249 --> 00:08:31,969
your continuous integration or your

00:08:30,019 --> 00:08:33,169
build system by the way I have a blog

00:08:31,969 --> 00:08:34,459
post don't you don't have to like

00:08:33,169 --> 00:08:36,439
frantically google this stuff or write

00:08:34,459 --> 00:08:38,449
it down if you don't want I'm gonna it's

00:08:36,439 --> 00:08:39,500
posted on my website but I didn't put it

00:08:38,449 --> 00:08:41,360
up yet because you're all in here

00:08:39,500 --> 00:08:43,099
listening to me and not stressing out

00:08:41,360 --> 00:08:46,250
about looking things up but I will share

00:08:43,099 --> 00:08:47,750
it at the end of the talk they're sort

00:08:46,250 --> 00:08:49,550
of basic checks that we did that we're

00:08:47,750 --> 00:08:52,100
really cheap and easy and got us pretty

00:08:49,550 --> 00:08:54,170
far was

00:08:52,100 --> 00:08:55,819
two scoops of Jenga which is excellent

00:08:54,170 --> 00:08:57,110
the security chapter is almost like a

00:08:55,819 --> 00:09:00,110
checklist you can go down and make sure

00:08:57,110 --> 00:09:02,360
you're doing each one I know I'm not the

00:09:00,110 --> 00:09:04,040
first person today to rave about Jenga

00:09:02,360 --> 00:09:05,480
debug toolbar but you can look at

00:09:04,040 --> 00:09:07,100
everything that you're sending and

00:09:05,480 --> 00:09:08,660
getting back and storing really easily

00:09:07,100 --> 00:09:11,060
with Jango debug toolbar and it is so

00:09:08,660 --> 00:09:13,370
easy to use which is amazing another

00:09:11,060 --> 00:09:16,370
easy thing that we did was we slapped a

00:09:13,370 --> 00:09:18,170
CDN in front of our content which is a

00:09:16,370 --> 00:09:20,360
content delivery network and not a Wii

00:09:18,170 --> 00:09:21,980
U's CloudFlare which bill provides some

00:09:20,360 --> 00:09:24,440
DDoS protection which means that you're

00:09:21,980 --> 00:09:26,089
not sending every request through so you

00:09:24,440 --> 00:09:28,519
get a little bit of like a rudimentary

00:09:26,089 --> 00:09:30,139
block in front of it that's all stuff

00:09:28,519 --> 00:09:32,000
you get basically out of the box like

00:09:30,139 --> 00:09:33,589
some of those who might have to like put

00:09:32,000 --> 00:09:35,000
in one installed app or like go to a

00:09:33,589 --> 00:09:36,139
website but those are all things that

00:09:35,000 --> 00:09:37,730
you could do in under an hour

00:09:36,139 --> 00:09:39,889
when you're starting to get into the

00:09:37,730 --> 00:09:43,430
like nitty gritty like the more more

00:09:39,889 --> 00:09:45,440
serious stuff of preventing data loss in

00:09:43,430 --> 00:09:47,930
securing your site the first step really

00:09:45,440 --> 00:09:49,759
is knowing your threats and so you can

00:09:47,930 --> 00:09:51,110
say threat modeling cuz that's the term

00:09:49,759 --> 00:09:52,690
that's used and you sound like really

00:09:51,110 --> 00:09:56,000
like a leet hacks or when you talk about

00:09:52,690 --> 00:09:57,410
threat modeling what's basic it's like

00:09:56,000 --> 00:09:59,149
it's what it says in the name right you

00:09:57,410 --> 00:10:01,519
want to know what info is an attacker

00:09:59,149 --> 00:10:04,149
looking for and how will they get it and

00:10:01,519 --> 00:10:07,009
then what will they use it for right

00:10:04,149 --> 00:10:08,810
what this requires is you really need to

00:10:07,009 --> 00:10:11,360
know your data model and flow really

00:10:08,810 --> 00:10:12,319
well before you can assess this and so

00:10:11,360 --> 00:10:14,329
it's a little bit of a chicken-and-egg

00:10:12,319 --> 00:10:16,339
you can have an idea of what what

00:10:14,329 --> 00:10:18,259
attackers might be looking for but until

00:10:16,339 --> 00:10:19,939
you feel like you really know what I did

00:10:18,259 --> 00:10:21,259
it is coming from and going to in your

00:10:19,939 --> 00:10:22,759
app you don't have a good idea so that's

00:10:21,259 --> 00:10:24,560
the first step of threat modeling is

00:10:22,759 --> 00:10:25,970
actually system modeling which is

00:10:24,560 --> 00:10:29,449
instructive anyway when you're building

00:10:25,970 --> 00:10:30,350
a site so it's it's it's it's something

00:10:29,449 --> 00:10:31,430
that you should be thinking about early

00:10:30,350 --> 00:10:33,079
on in your process because you're

00:10:31,430 --> 00:10:36,199
already doing part of the stuff that you

00:10:33,079 --> 00:10:38,689
need to do to keep it secure for us for

00:10:36,199 --> 00:10:39,829
Callisto we had two aspects that came

00:10:38,689 --> 00:10:43,310
out during our threat model that are a

00:10:39,829 --> 00:10:46,130
little unusual from say your standard I

00:10:43,310 --> 00:10:47,600
don't know ecommerce website right one

00:10:46,130 --> 00:10:50,329
is that we anticipated this data would

00:10:47,600 --> 00:10:52,339
be really valuable for specific personal

00:10:50,329 --> 00:10:56,180
attackers there might be reason to think

00:10:52,339 --> 00:10:57,920
that a specific person's report would be

00:10:56,180 --> 00:11:00,230
interesting to somebody who had the

00:10:57,920 --> 00:11:02,209
knowledge and ability to do this we also

00:11:00,230 --> 00:11:03,730
had reason along those lines to think

00:11:02,209 --> 00:11:06,250
that an attacker may have acts

00:11:03,730 --> 00:11:08,260
to one of our users computers or to

00:11:06,250 --> 00:11:09,790
their accounts even so that was a threat

00:11:08,260 --> 00:11:11,529
model we were dealing with it you may

00:11:09,790 --> 00:11:12,940
not be with that you may not be or that

00:11:11,529 --> 00:11:15,490
may be less important to you and as a

00:11:12,940 --> 00:11:17,139
result we really we put some more focus

00:11:15,490 --> 00:11:19,000
on looking at things like brute force

00:11:17,139 --> 00:11:21,459
attacks for example someone new

00:11:19,000 --> 00:11:23,350
close to the password or elements of a

00:11:21,459 --> 00:11:25,839
password that someone was using you know

00:11:23,350 --> 00:11:27,279
again like if I know your dog's name I

00:11:25,839 --> 00:11:30,070
can probably get into your email like

00:11:27,279 --> 00:11:32,139
that kind of thing also session based

00:11:30,070 --> 00:11:34,110
attacks we want to make sure that we're

00:11:32,139 --> 00:11:36,579
operating in a college context and we

00:11:34,110 --> 00:11:38,290
the user research we did indicated that

00:11:36,579 --> 00:11:40,899
there are a lot of shared computing

00:11:38,290 --> 00:11:42,579
resources they get used um so making

00:11:40,899 --> 00:11:43,720
sure that our sessions were really well

00:11:42,579 --> 00:11:46,410
locked down and that people weren't

00:11:43,720 --> 00:11:49,449
accidentally exposing stuff another

00:11:46,410 --> 00:11:51,519
threat for us a threat vector for us

00:11:49,449 --> 00:11:52,720
that you probably won't be dealing with

00:11:51,519 --> 00:11:55,660
depending on what you're working on is

00:11:52,720 --> 00:11:57,339
that we not only anticipate but frankly

00:11:55,660 --> 00:12:00,760
expect to be subpoenaed at some point

00:11:57,339 --> 00:12:02,320
for this data because our the user data

00:12:00,760 --> 00:12:06,040
that we're storing could potentially be

00:12:02,320 --> 00:12:07,899
a factor in a court case now that's a

00:12:06,040 --> 00:12:09,579
really interesting threat model to sort

00:12:07,899 --> 00:12:12,339
of as a other come as an engineer right

00:12:09,579 --> 00:12:14,880
to look at your system and to have this

00:12:12,339 --> 00:12:17,199
threat model that that you can't really

00:12:14,880 --> 00:12:19,149
necessarily build a moat around right

00:12:17,199 --> 00:12:21,250
making the walls taller and it harder to

00:12:19,149 --> 00:12:22,510
break in doesn't matter if someone is

00:12:21,250 --> 00:12:25,089
knocking on your door from like the

00:12:22,510 --> 00:12:27,850
sheriff's office so that would that was

00:12:25,089 --> 00:12:29,680
a big factor in our design what we ended

00:12:27,850 --> 00:12:33,579
up doing with that is we actually store

00:12:29,680 --> 00:12:35,620
the reports I'm most to say outright

00:12:33,579 --> 00:12:37,779
zero knowledge but the concept is is

00:12:35,620 --> 00:12:39,610
that we encrypt them with a key that's

00:12:37,779 --> 00:12:41,079
known only to our users this is separate

00:12:39,610 --> 00:12:42,819
from their password it's a secret key

00:12:41,079 --> 00:12:44,560
that they create and put it into the

00:12:42,819 --> 00:12:46,329
website and we encrypt it and we don't

00:12:44,560 --> 00:12:47,829
store that key anywhere we don't have

00:12:46,329 --> 00:12:50,079
any way to recover it because if you can

00:12:47,829 --> 00:12:51,699
reset that key we could then reset it to

00:12:50,079 --> 00:12:55,180
something we knew and get that

00:12:51,699 --> 00:12:57,910
information so this is this is sort of

00:12:55,180 --> 00:12:59,949
this came out of our model as an escrow

00:12:57,910 --> 00:13:02,410
right we're just storing this

00:12:59,949 --> 00:13:04,870
information until the user is ready to

00:13:02,410 --> 00:13:07,000
use it themselves so we had the we we

00:13:04,870 --> 00:13:09,279
were able to build this encryption model

00:13:07,000 --> 00:13:10,930
that we think will be fairly safe from

00:13:09,279 --> 00:13:12,610
subpoena in that if you subpoenaed our

00:13:10,930 --> 00:13:14,709
data if you said give me all the data

00:13:12,610 --> 00:13:16,940
for this person we could give it to them

00:13:14,709 --> 00:13:19,550
but it would be unreadable

00:13:16,940 --> 00:13:22,220
it would just be a blob of of binary

00:13:19,550 --> 00:13:26,690
data so that was sort of what came out

00:13:22,220 --> 00:13:28,460
of our threat modeling process so the

00:13:26,690 --> 00:13:30,770
biggest thing is in this ear in this

00:13:28,460 --> 00:13:33,710
room or you know someone that you know

00:13:30,770 --> 00:13:36,080
and what I mean by this is I don't mean

00:13:33,710 --> 00:13:37,250
like I don't even necessarily mean like

00:13:36,080 --> 00:13:38,990
what we were talking what I was talking

00:13:37,250 --> 00:13:40,220
about briefly with like disgruntled

00:13:38,990 --> 00:13:44,200
employees although that's absolutely a

00:13:40,220 --> 00:13:47,480
thing has anyone heard of all Crypt

00:13:44,200 --> 00:13:50,420
anyone okay so all cliff does this sir I

00:13:47,480 --> 00:13:54,080
got one all cooked is this amazing story

00:13:50,420 --> 00:13:57,590
of this Bitcoin exchange and they I mean

00:13:54,080 --> 00:14:00,020
again like they were they were storing

00:13:57,590 --> 00:14:01,700
data that directly impact that was money

00:14:00,020 --> 00:14:04,190
basically cuz that's how that works

00:14:01,700 --> 00:14:06,200
and they ended up shutting down this was

00:14:04,190 --> 00:14:08,450
earlier this year and let me see if I

00:14:06,200 --> 00:14:11,690
can get this right they had a technical

00:14:08,450 --> 00:14:13,880
contractor working on their site who was

00:14:11,690 --> 00:14:15,230
you know very technically adept very

00:14:13,880 --> 00:14:17,360
trained someone who had an interest in

00:14:15,230 --> 00:14:18,800
security but this person was running a

00:14:17,360 --> 00:14:20,870
private email server on their own

00:14:18,800 --> 00:14:22,130
machine and that was how they did all

00:14:20,870 --> 00:14:23,840
their work email was on this private

00:14:22,130 --> 00:14:27,170
email server that only this contractor

00:14:23,840 --> 00:14:30,890
had access to someone and it's not clear

00:14:27,170 --> 00:14:33,710
who by anyone someone sent a fraudulent

00:14:30,890 --> 00:14:35,690
password reset email on their WordPress

00:14:33,710 --> 00:14:37,820
blog nothing to do with yet with the

00:14:35,690 --> 00:14:39,710
Bitcoin parts of the system santé

00:14:37,820 --> 00:14:41,600
password reset for the wordpress log to

00:14:39,710 --> 00:14:42,950
a marketing person on the team the

00:14:41,600 --> 00:14:44,090
marketing person had been well trained

00:14:42,950 --> 00:14:45,350
and they had good policies and the

00:14:44,090 --> 00:14:47,660
marketing person said I didn't request

00:14:45,350 --> 00:14:49,490
this I'm going to make sure that this

00:14:47,660 --> 00:14:53,990
isn't an exploit and forward it to the

00:14:49,490 --> 00:14:59,630
technical team however so that private

00:14:53,990 --> 00:15:03,470
mail server had been had been taken over

00:14:59,630 --> 00:15:05,570
by someone malicious and when the email

00:15:03,470 --> 00:15:08,450
with the the marketing person correctly

00:15:05,570 --> 00:15:11,150
forwarded to this technical contractor

00:15:08,450 --> 00:15:13,790
with this password reset but email came

00:15:11,150 --> 00:15:15,050
the person who had who was had access to

00:15:13,790 --> 00:15:16,520
that private email server was able to

00:15:15,050 --> 00:15:20,030
reset the password get into the

00:15:16,520 --> 00:15:21,560
WordPress admin upload PHP files that

00:15:20,030 --> 00:15:23,720
gave access to the rest of the machine

00:15:21,560 --> 00:15:25,790
which happened to contain the databases

00:15:23,720 --> 00:15:28,370
that had all of the Bitcoin relevant

00:15:25,790 --> 00:15:30,050
information and they stole 40 Bitcoin

00:15:28,370 --> 00:15:31,279
which I think at the time was like over

00:15:30,050 --> 00:15:34,130
10,000

00:15:31,279 --> 00:15:36,620
that is an amazing story like glacis

00:15:34,130 --> 00:15:38,510
talk about like you know English majors

00:15:36,620 --> 00:15:41,330
and code like that's like some Agatha

00:15:38,510 --> 00:15:43,339
Christie stuff I love it but I bring it

00:15:41,330 --> 00:15:45,140
up because that's that's a thing that

00:15:43,339 --> 00:15:47,540
did a lot of things right and still

00:15:45,140 --> 00:15:50,000
managed to get totally taken their

00:15:47,540 --> 00:15:53,480
shirts taken right because they didn't

00:15:50,000 --> 00:15:54,920
really have the right sort of protocol

00:15:53,480 --> 00:15:56,959
for their employees so this really

00:15:54,920 --> 00:15:58,580
should be something that your your team

00:15:56,959 --> 00:16:00,260
is caped taking care of you got to have

00:15:58,580 --> 00:16:01,880
good password hygiene you've gotta be

00:16:00,260 --> 00:16:03,740
tracking all your data including email

00:16:01,880 --> 00:16:05,300
you want to have clean separation of

00:16:03,740 --> 00:16:07,010
concern from like your marketing and

00:16:05,300 --> 00:16:09,470
blog and user forum and support stuff

00:16:07,010 --> 00:16:11,180
and your actual business logic you want

00:16:09,470 --> 00:16:12,920
to again have strong employee policies

00:16:11,180 --> 00:16:14,779
and if you do end up having that

00:16:12,920 --> 00:16:16,399
disgruntled employee situation that you

00:16:14,779 --> 00:16:19,459
have a way to both detect that and

00:16:16,399 --> 00:16:22,070
mitigate it change your specific

00:16:19,459 --> 00:16:24,500
information in this lock down your admin

00:16:22,070 --> 00:16:26,600
because that's a really that's actually

00:16:24,500 --> 00:16:29,260
like when people are attacking a jingo

00:16:26,600 --> 00:16:31,970
site that's the first place they go

00:16:29,260 --> 00:16:34,370
change the URL is a really common one

00:16:31,970 --> 00:16:36,440
that's suggested you can use Django

00:16:34,370 --> 00:16:37,760
admin honeypot puts up a fake page there

00:16:36,440 --> 00:16:39,649
and lets you know if anyone's trying to

00:16:37,760 --> 00:16:42,980
get in through your fake admin page your

00:16:39,649 --> 00:16:46,010
default admin page I would suggest what

00:16:42,980 --> 00:16:47,750
we decided to do don't use admin so what

00:16:46,010 --> 00:16:49,820
we have is we have a staging site that

00:16:47,750 --> 00:16:51,740
my co-workers who edit the content can

00:16:49,820 --> 00:16:54,079
log into and they can edit content there

00:16:51,740 --> 00:16:56,540
and then I export over to prod when I

00:16:54,079 --> 00:16:58,399
need to we don't have a prod admin so

00:16:56,540 --> 00:17:01,130
that's one less vector of attack

00:16:58,399 --> 00:17:04,459
you also can IP limit it and I have some

00:17:01,130 --> 00:17:06,110
links for ways to do that so your second

00:17:04,459 --> 00:17:09,770
biggest threat though is on the user

00:17:06,110 --> 00:17:10,309
side I would say right it's sort of cold

00:17:09,770 --> 00:17:11,929
comfort

00:17:10,309 --> 00:17:14,300
if you've locked everything down on your

00:17:11,929 --> 00:17:17,030
server and code side if your user is

00:17:14,300 --> 00:17:19,280
either you know encouraged to allowed to

00:17:17,030 --> 00:17:20,510
make security choices that expose their

00:17:19,280 --> 00:17:22,220
data they're not gonna make that

00:17:20,510 --> 00:17:24,319
distinction and neither will your out

00:17:22,220 --> 00:17:27,880
your other customers frankly it's it's a

00:17:24,319 --> 00:17:30,530
messaging thing so a lot of security

00:17:27,880 --> 00:17:32,240
concerns can be mitigated with really

00:17:30,530 --> 00:17:34,850
good UX and that was another thing we

00:17:32,240 --> 00:17:40,610
focused on password strength is a big

00:17:34,850 --> 00:17:43,070
one here right so we used a project that

00:17:40,610 --> 00:17:44,750
I'm excited about which is Dropbox's zxc

00:17:43,070 --> 00:17:46,820
vbn which is a password

00:17:44,750 --> 00:17:49,240
meter that operates on a sort of more

00:17:46,820 --> 00:17:51,370
sophisticated concept of entropy and

00:17:49,240 --> 00:17:53,660
complexity this is a really like

00:17:51,370 --> 00:17:55,190
password strength and password designers

00:17:53,660 --> 00:17:57,410
are really interesting and deep topic

00:17:55,190 --> 00:17:59,090
there's a lot of of academic and

00:17:57,410 --> 00:18:00,950
industry work being done on it I would

00:17:59,090 --> 00:18:02,030
suggest that if you have a site that

00:18:00,950 --> 00:18:04,460
people log in to you should read up

00:18:02,030 --> 00:18:07,400
about this like eight or more characters

00:18:04,460 --> 00:18:09,050
and one special special character or

00:18:07,400 --> 00:18:10,550
whatever is it doesn't really cut it for

00:18:09,050 --> 00:18:12,770
example and so this is a password

00:18:10,550 --> 00:18:15,470
strength meter that for example if you

00:18:12,770 --> 00:18:17,060
know what is the xkcd example is correct

00:18:15,470 --> 00:18:18,800
horse battery staple which is very

00:18:17,060 --> 00:18:20,590
memorable and long it's gonna get a

00:18:18,800 --> 00:18:23,960
higher score on that password meter then

00:18:20,590 --> 00:18:26,740
password one with an ad instead of the a

00:18:23,960 --> 00:18:29,030
which is a really common password

00:18:26,740 --> 00:18:30,830
another thing I like about this is and

00:18:29,030 --> 00:18:34,280
it's it's also a little experimental but

00:18:30,830 --> 00:18:37,130
it uses a it uses a meter instead of

00:18:34,280 --> 00:18:39,140
just being like low medium good and this

00:18:37,130 --> 00:18:41,270
is pretty arbitrary but it actually

00:18:39,140 --> 00:18:42,920
tells you an estimate of how long it

00:18:41,270 --> 00:18:44,600
would take to crack the given password

00:18:42,920 --> 00:18:45,950
it's an interesting reminder right there

00:18:44,600 --> 00:18:47,900
what's at stake when you're choosing a

00:18:45,950 --> 00:18:49,310
password so it's kind of a cool way and

00:18:47,900 --> 00:18:50,960
we're continuing to explore and to work

00:18:49,310 --> 00:18:53,120
with folks on password security because

00:18:50,960 --> 00:18:54,770
we have this unusual password UX which

00:18:53,120 --> 00:18:56,930
is like a password that you can't

00:18:54,770 --> 00:18:58,460
recover which like is the death knell

00:18:56,930 --> 00:19:00,500
for UX it's a pattern that you don't

00:18:58,460 --> 00:19:02,210
normally see another thing that you want

00:19:00,500 --> 00:19:03,740
to look at is rate limiting particularly

00:19:02,210 --> 00:19:08,110
if you've identified brute force as a

00:19:03,740 --> 00:19:10,370
potential likely attack vector so a

00:19:08,110 --> 00:19:11,900
couple of django apps that makes oh and

00:19:10,370 --> 00:19:14,090
they're sorry i will put on the website

00:19:11,900 --> 00:19:16,520
there's a couple jing implementations or

00:19:14,090 --> 00:19:18,860
like integrations of zxe vb and that's

00:19:16,520 --> 00:19:20,930
the last row on your keyboard if you're

00:19:18,860 --> 00:19:22,970
wondering why it's called that there's a

00:19:20,930 --> 00:19:24,260
couple Jing implementations we ended up

00:19:22,970 --> 00:19:25,700
sort of rolling our own just because the

00:19:24,260 --> 00:19:28,160
UI wasn't exactly what we wanted but

00:19:25,700 --> 00:19:31,070
there's a bunch out there rate-limiting

00:19:28,160 --> 00:19:34,490
so general axis is a really common use

00:19:31,070 --> 00:19:37,610
one it's on your know-it-all PI two your

00:19:34,490 --> 00:19:39,110
authentication model and that one is you

00:19:37,610 --> 00:19:40,730
can lock out users and you can do

00:19:39,110 --> 00:19:42,320
combinations of users in IP if people

00:19:40,730 --> 00:19:44,840
are trying too many times I give a

00:19:42,320 --> 00:19:46,610
password for a given user we also needed

00:19:44,840 --> 00:19:48,110
to rate limit our encryption and

00:19:46,610 --> 00:19:49,940
decryption function like entering your

00:19:48,110 --> 00:19:51,650
secret key so we use something called

00:19:49,940 --> 00:19:53,300
Django rate limit which lets you apply

00:19:51,650 --> 00:19:56,690
that to various different views it's a

00:19:53,300 --> 00:19:58,070
decorator I in terms of road map stuff

00:19:56,690 --> 00:20:00,500
that I want to do I would like to

00:19:58,070 --> 00:20:02,270
I'm an exponential back-off so you start

00:20:00,500 --> 00:20:04,940
even at the first one putting in a

00:20:02,270 --> 00:20:06,500
little imperceptible delay because with

00:20:04,940 --> 00:20:08,810
brute force you can expect sort of

00:20:06,500 --> 00:20:10,130
scripting to attack and you make it

00:20:08,810 --> 00:20:11,750
longer and longer as you go eventually

00:20:10,130 --> 00:20:14,750
locking out another thing that you can

00:20:11,750 --> 00:20:16,220
do is default to CAPTCHAs so you know

00:20:14,750 --> 00:20:17,600
sometimes we forget passwords especially

00:20:16,220 --> 00:20:19,280
in our case where we've got a password

00:20:17,600 --> 00:20:20,630
that we don't let you recover so

00:20:19,280 --> 00:20:22,610
figuring out the balance between

00:20:20,630 --> 00:20:24,260
security and UX there's ago one another

00:20:22,610 --> 00:20:25,610
one is session security expiring

00:20:24,260 --> 00:20:27,530
sessions after a given amount of

00:20:25,610 --> 00:20:28,880
inactivity making sure in general that

00:20:27,530 --> 00:20:29,870
your sessions actually expire and you

00:20:28,880 --> 00:20:31,940
don't keep them around forever and

00:20:29,870 --> 00:20:33,350
there's a middleware JavaScript

00:20:31,940 --> 00:20:34,640
combination called session security that

00:20:33,350 --> 00:20:36,140
we use to do that and it's pretty nice

00:20:34,640 --> 00:20:38,570
out-of-the-box and you can customize all

00:20:36,140 --> 00:20:41,810
kinds of ways another one that we have

00:20:38,570 --> 00:20:43,400
not implemented yet and may not ever but

00:20:41,810 --> 00:20:45,080
that you should probably look into is

00:20:43,400 --> 00:20:47,180
two-factor authentication so it's using

00:20:45,080 --> 00:20:50,420
another piece of information that the

00:20:47,180 --> 00:20:51,650
user has access to often it'll be a text

00:20:50,420 --> 00:20:54,950
message or an email

00:20:51,650 --> 00:20:58,430
we are still user testing it people have

00:20:54,950 --> 00:21:00,230
a lot of sort of they're wary to put

00:20:58,430 --> 00:21:01,760
their information into our website which

00:21:00,230 --> 00:21:04,490
is understandable and we want to sort of

00:21:01,760 --> 00:21:06,770
reduce friction in terms of registering

00:21:04,490 --> 00:21:08,330
so we're still figuring out whether that

00:21:06,770 --> 00:21:10,070
would work at all for us but it's

00:21:08,330 --> 00:21:11,330
definitely there's a ton of different

00:21:10,070 --> 00:21:12,830
things and there's now third-party

00:21:11,330 --> 00:21:16,040
services that will do a bunch of that

00:21:12,830 --> 00:21:18,350
stuff for you which is really cool so

00:21:16,040 --> 00:21:22,090
basically boundaries are hard this is a

00:21:18,350 --> 00:21:24,260
lesson from my mother no I'm kidding so

00:21:22,090 --> 00:21:26,420
any of us that you're sending data

00:21:24,260 --> 00:21:27,470
around when you do that threat model

00:21:26,420 --> 00:21:29,240
that's what you want to look at right

00:21:27,470 --> 00:21:32,960
besides the sort of obvious ones like is

00:21:29,240 --> 00:21:34,940
my org got good in you know information

00:21:32,960 --> 00:21:36,980
security and do my users have the tools

00:21:34,940 --> 00:21:38,390
they need to be secure any place where

00:21:36,980 --> 00:21:40,280
you're sending data across service

00:21:38,390 --> 00:21:42,590
boundaries or even you know in and out

00:21:40,280 --> 00:21:44,900
of a DB serializing deserializing that's

00:21:42,590 --> 00:21:47,410
where you want to look at looking at

00:21:44,900 --> 00:21:50,720
what whether you can avoid those kind of

00:21:47,410 --> 00:21:54,190
that data being readable at all or even

00:21:50,720 --> 00:21:57,470
moving across that we do store some data

00:21:54,190 --> 00:21:59,030
as anonymous as possible because we want

00:21:57,470 --> 00:22:01,460
to evaluate the use of our system and

00:21:59,030 --> 00:22:05,240
also make sure that we can provide

00:22:01,460 --> 00:22:07,640
information to our schools about sort of

00:22:05,240 --> 00:22:10,010
broad statistics about what's going on

00:22:07,640 --> 00:22:11,270
in the climate in campus we decided to

00:22:10,010 --> 00:22:11,910
store that in a way that wasn't

00:22:11,270 --> 00:22:13,710
accessible on

00:22:11,910 --> 00:22:16,500
line so we haven't encrypted with

00:22:13,710 --> 00:22:18,090
asymmetric encryption and we don't put

00:22:16,500 --> 00:22:19,800
the key on line ever so we have to

00:22:18,090 --> 00:22:21,480
actually pull that data off and put it

00:22:19,800 --> 00:22:23,940
on a machine that we can lock down in

00:22:21,480 --> 00:22:25,410
various different ways you know and to

00:22:23,940 --> 00:22:26,880
read it because we don't need it real

00:22:25,410 --> 00:22:28,980
time so think about whether you need to

00:22:26,880 --> 00:22:31,590
cross those boundaries another one

00:22:28,980 --> 00:22:35,160
that's a little wavy err I would say is

00:22:31,590 --> 00:22:37,770
the boundary of your app versus not your

00:22:35,160 --> 00:22:39,570
app and that's kind of like you know

00:22:37,770 --> 00:22:41,790
we're getting into definitely into user

00:22:39,570 --> 00:22:43,500
design considerations but stuff like you

00:22:41,790 --> 00:22:46,410
know if you're doing really sensitive

00:22:43,500 --> 00:22:48,960
data like how far away can someone read

00:22:46,410 --> 00:22:50,610
it off someone's screen right like yeah

00:22:48,960 --> 00:22:53,190
that's not your responsibility but it's

00:22:50,610 --> 00:22:55,050
something you can help mitigate and one

00:22:53,190 --> 00:22:57,210
of our big things is when someone

00:22:55,050 --> 00:22:59,730
actually decides to report to deliver

00:22:57,210 --> 00:23:02,310
their report to a school we didn't have

00:22:59,730 --> 00:23:04,980
to get it into an admins hands right so

00:23:02,310 --> 00:23:06,360
that's a big data boundary for us and we

00:23:04,980 --> 00:23:08,220
think we have a reasonably secure

00:23:06,360 --> 00:23:11,490
process it involves asymmetric

00:23:08,220 --> 00:23:13,290
encryption PGP um what that means is I'm

00:23:11,490 --> 00:23:16,050
teaching regular people who are

00:23:13,290 --> 00:23:17,940
University admins to use PGP which if

00:23:16,050 --> 00:23:20,130
you've ever you know done IT support for

00:23:17,940 --> 00:23:22,650
university or use PGP you might be like

00:23:20,130 --> 00:23:24,630
horrified right now and like it's it is

00:23:22,650 --> 00:23:26,400
a really difficult thing UX wise and

00:23:24,630 --> 00:23:27,600
this there's different solutions we

00:23:26,400 --> 00:23:28,980
could do to make that easier but you

00:23:27,600 --> 00:23:30,780
know we talk to people and what they're

00:23:28,980 --> 00:23:31,980
doing is they're taking these reports

00:23:30,780 --> 00:23:34,080
and putting them into their Student

00:23:31,980 --> 00:23:35,400
Conduct tracking systems and if we can

00:23:34,080 --> 00:23:38,220
figure out and this is our goal to

00:23:35,400 --> 00:23:40,200
integrate with those we all have much

00:23:38,220 --> 00:23:41,670
more control over that boundary and it's

00:23:40,200 --> 00:23:44,070
one less spot okay I have just a few

00:23:41,670 --> 00:23:45,480
more slides this is like the number one

00:23:44,070 --> 00:23:48,330
city or anything I learned like don't

00:23:45,480 --> 00:23:49,470
get cute no new crypto look for audited

00:23:48,330 --> 00:23:51,090
libraries look for libraries have been

00:23:49,470 --> 00:23:52,290
around for a long time you don't want to

00:23:51,090 --> 00:23:55,920
be the first user you don't want to be

00:23:52,290 --> 00:23:57,420
the zero day pioneer we're using PI salt

00:23:55,920 --> 00:23:59,880
which is a wrapper of a very

00:23:57,420 --> 00:24:01,170
well-regarded C library and another

00:23:59,880 --> 00:24:02,820
thing about this is you want to tell

00:24:01,170 --> 00:24:04,200
your story to people and the section of

00:24:02,820 --> 00:24:05,970
a party security is getting people to

00:24:04,200 --> 00:24:07,950
trust your security and the more

00:24:05,970 --> 00:24:11,610
complicated that is the harder that is

00:24:07,950 --> 00:24:12,990
so finally pay something smarter this is

00:24:11,610 --> 00:24:15,110
a really good use of your budget to

00:24:12,990 --> 00:24:17,040
consult with someone and we did this

00:24:15,110 --> 00:24:18,390
when they want to point out I didn't

00:24:17,040 --> 00:24:20,370
mention any network security we're

00:24:18,390 --> 00:24:22,380
hosting on Heroku that was a trade-off

00:24:20,370 --> 00:24:25,110
for us because of some of our subpoena

00:24:22,380 --> 00:24:27,270
issues but we could not afford

00:24:25,110 --> 00:24:30,540
to hire someone to lock down our

00:24:27,270 --> 00:24:32,640
networks and our servers the way that

00:24:30,540 --> 00:24:34,320
Heroku can I think this is a really like

00:24:32,640 --> 00:24:38,280
no-brainer if you're starting with low

00:24:34,320 --> 00:24:40,650
resources and I don't wanna recommend

00:24:38,280 --> 00:24:42,780
specific shops for like a pen tester

00:24:40,650 --> 00:24:44,610
security review in like I given talk

00:24:42,780 --> 00:24:46,140
that ask your friends if you are looking

00:24:44,610 --> 00:24:47,630
for this talk to me because I have a big

00:24:46,140 --> 00:24:50,040
spreadsheet of stuff we looked into

00:24:47,630 --> 00:24:52,830
finally I want to thank our security

00:24:50,040 --> 00:24:54,540
board members who helped us with the

00:24:52,830 --> 00:24:56,190
security stuff which involve consulting

00:24:54,540 --> 00:24:58,080
on this Lee Honeywell Sophie Hoskins

00:24:56,190 --> 00:25:01,290
Sina Bahram Selina Jekyll man Chris

00:24:58,080 --> 00:25:03,630
valasek Don Bailey and generalise I want

00:25:01,290 --> 00:25:05,160
to thank as I'm sure we almost all of us

00:25:03,630 --> 00:25:07,830
do the incomparable Lisa Williams

00:25:05,160 --> 00:25:10,140
Henschel funds who helped out we've been

00:25:07,830 --> 00:25:12,750
huge Jakob Kaplan Moss and his team and

00:25:10,140 --> 00:25:14,100
Andrew Becker at NCC group ask your

00:25:12,750 --> 00:25:17,160
funds we should talk about this more

00:25:14,100 --> 00:25:18,900
it's security is scary and I think that

00:25:17,160 --> 00:25:20,760
there's a high barrier to entry and the

00:25:18,900 --> 00:25:24,350
better we can do to lower that the

00:25:20,760 --> 00:25:24,350

YouTube URL: https://www.youtube.com/watch?v=H2llNbMe-V4


