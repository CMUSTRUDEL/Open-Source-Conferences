Title: DjangoCon 2019 - Keynote: The Natural State of Computers by Amber Brown
Publication date: 2019-10-25
Playlist: DjangoCon US 2019
Description: 
	DjangoCon 2019 - Keynote: The Natural State of Computers by Amber Brown

TBD

This talk was presented at: https://2019.djangocon.us/talk/keynote-amber-brown/

LINKS:
Follow Amber Brown ðŸ‘‡
On Twitter: https://twitter.com/hawkieowl


Follow DjangCon US ðŸ‘‡
https://twitter.com/djangocon

Follow DEFNA ðŸ‘‡
https://twitter.com/defnado
https://www.defna.org/

Intro music: "This Is How We Quirk It" by Avocado Junkie.
Video production by Confreaks TV.
Captions by White Coat Captioning.
Captions: 
	00:00:00,000 --> 00:00:12,679
[Music]

00:00:14,440 --> 00:00:21,110
hello I am here to talk about the

00:00:18,170 --> 00:00:22,760
natural state of computers and even

00:00:21,110 --> 00:00:26,210
though it ends up being something like

00:00:22,760 --> 00:00:28,010
this most of the time I'm going to go

00:00:26,210 --> 00:00:30,670
into a you know a bit more about how

00:00:28,010 --> 00:00:35,000
things work before it gets to this point

00:00:30,670 --> 00:00:38,390
so I am amber Hockey Brown my Twitter

00:00:35,000 --> 00:00:40,970
account is at hockey owl I'm from

00:00:38,390 --> 00:00:46,820
Melbourne Australia so it's been quite a

00:00:40,970 --> 00:00:48,500
long trip to get here look when you live

00:00:46,820 --> 00:00:52,430
in Melbourne it's hard to get picture of

00:00:48,500 --> 00:00:54,290
Melbourne so I had to make do it's from

00:00:52,430 --> 00:00:58,010
when I went to play Cascades yeah the

00:00:54,290 --> 00:01:00,680
same thing good copy most people know me

00:00:58,010 --> 00:01:02,449
for my work on twisted so twisted is a

00:01:00,680 --> 00:01:05,960
asynchronous networking framework which

00:01:02,449 --> 00:01:07,310
will be relevant to my talk but it's

00:01:05,960 --> 00:01:10,840
been around for quite a long time and I

00:01:07,310 --> 00:01:17,090
am its release manager and one of its

00:01:10,840 --> 00:01:20,090
longest standing contributors so this is

00:01:17,090 --> 00:01:23,119
sort of a bookend to a talk given nearly

00:01:20,090 --> 00:01:24,500
five years ago at this point at a

00:01:23,119 --> 00:01:26,920
conference called Django under the hood

00:01:24,500 --> 00:01:32,170
of which the deep dives day is sort of

00:01:26,920 --> 00:01:32,170
inspired by God I look you

00:01:33,359 --> 00:01:43,110
and yeah still do I got carded the other

00:01:37,390 --> 00:01:46,630
day anyway so this was given in 2015 and

00:01:43,110 --> 00:01:49,030
around that time we had Jango channels

00:01:46,630 --> 00:01:51,640
was nearing 1.0 was 1.0 it was in

00:01:49,030 --> 00:01:54,549
development so the early version of

00:01:51,640 --> 00:01:56,649
Durango channels was more oriented

00:01:54,549 --> 00:01:58,780
around keeping Jango sort of synchronous

00:01:56,649 --> 00:02:01,030
as it was but having a sort of

00:01:58,780 --> 00:02:02,890
asynchronous shell around it so that you

00:02:01,030 --> 00:02:05,289
could do asynchronous things without

00:02:02,890 --> 00:02:08,849
having to care so much about your actual

00:02:05,289 --> 00:02:11,140
Jango being natively asynchronous so

00:02:08,849 --> 00:02:13,750
I've got a couple of slides from that

00:02:11,140 --> 00:02:16,150
talk and at that point I was I was

00:02:13,750 --> 00:02:17,530
fairly convinced that the original

00:02:16,150 --> 00:02:20,349
channels would kind of work out because

00:02:17,530 --> 00:02:23,079
it seemed pretty injuries laughing in

00:02:20,349 --> 00:02:25,299
the front row that would work out

00:02:23,079 --> 00:02:27,489
because it seemed relatively low effort

00:02:25,299 --> 00:02:29,739
low impact and if I know anything from

00:02:27,489 --> 00:02:33,250
software that doing too much at one time

00:02:29,739 --> 00:02:35,290
usually ends up hit failure but I sort

00:02:33,250 --> 00:02:38,079
of was thinking about a sort of an

00:02:35,290 --> 00:02:41,880
alternate situation from what I was

00:02:38,079 --> 00:02:44,739
assuming was the foregone conclusion and

00:02:41,880 --> 00:02:47,290
that conclusion was that we needed to

00:02:44,739 --> 00:02:50,410
replace whiskey because whiskey is at

00:02:47,290 --> 00:02:52,780
its core as a synchronous II style

00:02:50,410 --> 00:02:55,180
interface you don't have an asynchronous

00:02:52,780 --> 00:02:56,980
event loop or anything around it and you

00:02:55,180 --> 00:02:58,180
generally run in a thread and it just

00:02:56,980 --> 00:03:00,599
didn't work for that sort of

00:02:58,180 --> 00:03:04,030
asynchronous future you could do

00:03:00,599 --> 00:03:05,950
responses asynchronously but it didn't

00:03:04,030 --> 00:03:10,780
work for asynchronous protocols as whole

00:03:05,950 --> 00:03:11,290
like WebSockets now that has come to

00:03:10,780 --> 00:03:14,680
fruition

00:03:11,290 --> 00:03:16,120
which is SB 3.0 it's stable it's

00:03:14,680 --> 00:03:17,980
well-defined and it's got multiple

00:03:16,120 --> 00:03:19,569
servers so I think we're in a world

00:03:17,980 --> 00:03:24,819
where that whiskey two sort of does

00:03:19,569 --> 00:03:26,829
exist I also talked about how maybe in

00:03:24,819 --> 00:03:30,130
this world where we have an asynchronous

00:03:26,829 --> 00:03:31,630
whiskey that's Jango might be able to

00:03:30,130 --> 00:03:33,940
spawn both asynchronous and synchronous

00:03:31,630 --> 00:03:37,720
views and that could be pretty

00:03:33,940 --> 00:03:39,700
interesting and I was considering at

00:03:37,720 --> 00:03:41,590
that point that maybe a native

00:03:39,700 --> 00:03:45,370
asynchronous method would be the long

00:03:41,590 --> 00:03:49,299
term way forward but it would

00:03:45,370 --> 00:03:52,360
would be rather invasive and later on

00:03:49,299 --> 00:03:54,519
Andrew will be talking about how how

00:03:52,360 --> 00:03:56,440
that project has been less invasive and

00:03:54,519 --> 00:03:58,510
not required hopefully any of our

00:03:56,440 --> 00:04:02,230
connectors at all maybe some fried ones

00:03:58,510 --> 00:04:06,150
but no broken ones so think of this talk

00:04:02,230 --> 00:04:09,250
as a book into that 2015 talk because

00:04:06,150 --> 00:04:11,440
2015 we didn't have what we have now now

00:04:09,250 --> 00:04:14,980
we have in development a synchronous

00:04:11,440 --> 00:04:17,139
capable Jango SB is developed and stable

00:04:14,980 --> 00:04:20,799
and we've multiple implementations of

00:04:17,139 --> 00:04:23,169
ascii clients and ascii servers but

00:04:20,799 --> 00:04:25,960
let's start from the start and talk

00:04:23,169 --> 00:04:30,580
about why asynchronous stuff is a big

00:04:25,960 --> 00:04:32,800
deal now when I say async through this

00:04:30,580 --> 00:04:35,050
talk I mean async ris input and output

00:04:32,800 --> 00:04:36,729
it refers to specific programming

00:04:35,050 --> 00:04:38,919
techniques that minimize the amount of

00:04:36,729 --> 00:04:43,260
time that you code blocks waiting on

00:04:38,919 --> 00:04:46,300
external data walking can be quite bad

00:04:43,260 --> 00:04:48,669
when responsiveness is key such as in

00:04:46,300 --> 00:04:50,710
graphical interfaces blocking on waiting

00:04:48,669 --> 00:04:52,780
on external data or blocking on heavy

00:04:50,710 --> 00:04:56,470
processing can turn your application

00:04:52,780 --> 00:04:58,210
into a stubby slow mess usually the

00:04:56,470 --> 00:05:00,330
solution is to move any sort of

00:04:58,210 --> 00:05:03,669
processing into an alternate thread

00:05:00,330 --> 00:05:06,280
leaving your main UI thread to be very

00:05:03,669 --> 00:05:07,750
snappy very responsive and just

00:05:06,280 --> 00:05:10,000
delegating anything that will take any

00:05:07,750 --> 00:05:12,630
significant amount of time to worker

00:05:10,000 --> 00:05:14,889
threads or processes

00:05:12,630 --> 00:05:18,310
unfortunately in Python it isn't that

00:05:14,889 --> 00:05:20,169
easy we simply can't make a thread on

00:05:18,310 --> 00:05:22,060
put on another course who doubled the

00:05:20,169 --> 00:05:24,520
amount of work we can do because a voice

00:05:22,060 --> 00:05:26,050
called the global interpreter lock the

00:05:24,520 --> 00:05:27,639
global interpreter lock is both in a

00:05:26,050 --> 00:05:30,910
central part of Python and makes it very

00:05:27,639 --> 00:05:32,650
easy to program in Python and have some

00:05:30,910 --> 00:05:34,990
threads occasionally without having to

00:05:32,650 --> 00:05:37,800
learn entirely about how to write for it

00:05:34,990 --> 00:05:41,199
safe code but is also its Achilles heel

00:05:37,800 --> 00:05:43,810
it allows Python code to execute on only

00:05:41,199 --> 00:05:44,260
one thread in that process at any one

00:05:43,810 --> 00:05:46,990
time

00:05:44,260 --> 00:05:49,720
we don't have to worry about one bit of

00:05:46,990 --> 00:05:52,349
Python changing a list or a dictionary

00:05:49,720 --> 00:05:54,490
from underneath us which can happen with

00:05:52,349 --> 00:05:56,380
asynchronous things in other languages

00:05:54,490 --> 00:05:58,720
usually you have to have a lock and make

00:05:56,380 --> 00:06:00,340
sure that things you know all know

00:05:58,720 --> 00:06:04,390
things underneath it are changing in

00:06:00,340 --> 00:06:07,150
python we don't have to do that the gill

00:06:04,390 --> 00:06:09,220
is a very rough flock as the global in

00:06:07,150 --> 00:06:10,840
the name like hint it means that we can

00:06:09,220 --> 00:06:12,460
simply say that this code over here

00:06:10,840 --> 00:06:15,790
doesn't need the guarantees it provides

00:06:12,460 --> 00:06:17,770
or then it safely locks because if we

00:06:15,790 --> 00:06:20,200
were to turn it off code that we depend

00:06:17,770 --> 00:06:22,240
on and call would likely break horribly

00:06:20,200 --> 00:06:23,260
because when you're writing Python

00:06:22,240 --> 00:06:25,390
you're not only writing your own code

00:06:23,260 --> 00:06:28,000
but often losing lots and lots of other

00:06:25,390 --> 00:06:29,890
libraries that maybe don't have those

00:06:28,000 --> 00:06:31,810
sort of I'm okay with being

00:06:29,890 --> 00:06:34,660
multi-threaded and a lot of Python code

00:06:31,810 --> 00:06:38,170
is not multi-thread safe so for now

00:06:34,660 --> 00:06:39,910
we're stuck with it so if we can

00:06:38,170 --> 00:06:42,340
effectively only run Python on one

00:06:39,910 --> 00:06:45,610
thread at any given time how can we best

00:06:42,340 --> 00:06:48,100
make the use of that well if we only

00:06:45,610 --> 00:06:50,200
have one thread and do all the work on

00:06:48,100 --> 00:06:52,330
that we don't have to pay you all the

00:06:50,200 --> 00:06:55,780
costs of threading like thread switching

00:06:52,330 --> 00:06:57,220
and locking and memory overhead but if

00:06:55,780 --> 00:06:59,080
we want to block when waiting for

00:06:57,220 --> 00:07:02,140
external data we'd only be able to

00:06:59,080 --> 00:07:05,800
request to process one request or one

00:07:02,140 --> 00:07:08,410
thing at once but instead we can use non

00:07:05,800 --> 00:07:10,540
blocking techniques for our and process

00:07:08,410 --> 00:07:15,520
as many requests as we have the CPU time

00:07:10,540 --> 00:07:18,430
for so the solution to blocking and only

00:07:15,520 --> 00:07:20,080
having one thread is rather than using

00:07:18,430 --> 00:07:22,330
rather than waiting for the data to

00:07:20,080 --> 00:07:25,300
arrive we use the operating systems

00:07:22,330 --> 00:07:27,790
non-blocking i/o functionality it's not

00:07:25,300 --> 00:07:29,770
instant since we have to shove the data

00:07:27,790 --> 00:07:32,710
off to the operating system but it

00:07:29,770 --> 00:07:34,419
blocks as little as possible when we

00:07:32,710 --> 00:07:35,650
want to receive data we just have to

00:07:34,419 --> 00:07:36,970
check for it instead of stopping the

00:07:35,650 --> 00:07:41,290
world and waiting for everything to

00:07:36,970 --> 00:07:44,740
arrive at once async isn't new

00:07:41,290 --> 00:07:46,210
and because asynchronous i/o underpins

00:07:44,740 --> 00:07:48,370
basically every high-performance

00:07:46,210 --> 00:07:51,180
networking system there is operating

00:07:48,370 --> 00:07:54,190
system support is nearly Universal our

00:07:51,180 --> 00:07:56,650
particular are the e pol and KQ AP is on

00:07:54,190 --> 00:07:59,050
the smbs DS and io completion ports on

00:07:56,650 --> 00:08:02,050
Windows and it's not you in Python Eva

00:07:59,050 --> 00:08:03,550
because twisted and tornado had been

00:08:02,050 --> 00:08:06,580
using these interfaces for many many

00:08:03,550 --> 00:08:08,169
years and G events and similar things

00:08:06,580 --> 00:08:11,229
like that being alternate so almost as

00:08:08,169 --> 00:08:12,790
long twisted and tornado are quite

00:08:11,229 --> 00:08:14,320
similar and built on the concept

00:08:12,790 --> 00:08:16,270
of an event loop or a reactor which

00:08:14,320 --> 00:08:18,370
we'll get into or to vent was a bit

00:08:16,270 --> 00:08:21,640
different and used a sort of green light

00:08:18,370 --> 00:08:23,320
rather than an explicit event loop green

00:08:21,640 --> 00:08:25,420
lights are similar to threads and have a

00:08:23,320 --> 00:08:27,190
lot of the same downsides but a managed

00:08:25,420 --> 00:08:29,380
in user space instead by the operating

00:08:27,190 --> 00:08:32,080
system which gives your program more

00:08:29,380 --> 00:08:34,360
control all these options are very

00:08:32,080 --> 00:08:36,870
mature and in wide use by sections of

00:08:34,360 --> 00:08:39,400
the community that need them

00:08:36,870 --> 00:08:42,280
unfortunately it is a little bit hard to

00:08:39,400 --> 00:08:44,580
do asynchronous code in Python due to

00:08:42,280 --> 00:08:47,410
its lack of first-class language support

00:08:44,580 --> 00:08:50,710
back in a you know the Python 2 days you

00:08:47,410 --> 00:08:52,390
could implement Co routines which make

00:08:50,710 --> 00:08:54,940
it you can make it a lot easier you

00:08:52,390 --> 00:08:57,250
could implement it using generators but

00:08:54,940 --> 00:09:00,370
they're slow and give messy trace back

00:08:57,250 --> 00:09:03,670
since generators work on exceptions to

00:09:00,370 --> 00:09:06,880
finish finish them and they're very easy

00:09:03,670 --> 00:09:08,620
to miss use one of my co-workers has a

00:09:06,880 --> 00:09:11,670
post-it note on his monitor that says

00:09:08,620 --> 00:09:15,550
have you remembered to yield

00:09:11,670 --> 00:09:16,710
since when using these old sort of hack

00:09:15,550 --> 00:09:19,360
ting co-routines

00:09:16,710 --> 00:09:20,890
forgetting to yield on something python

00:09:19,360 --> 00:09:23,010
had no way of telling you we didn't know

00:09:20,890 --> 00:09:24,850
that you were supposed to do that

00:09:23,010 --> 00:09:27,580
fortunately everything's a bit better

00:09:24,850 --> 00:09:31,240
now we have real co-routines real ish

00:09:27,580 --> 00:09:34,360
and you can write them using async death

00:09:31,240 --> 00:09:38,860
and then inside that instead of yielding

00:09:34,360 --> 00:09:41,200
use a weight to the user the flow looks

00:09:38,860 --> 00:09:43,240
like you're blocking or waiting for the

00:09:41,200 --> 00:09:44,860
thing you will wait it to finish the

00:09:43,240 --> 00:09:48,160
await keyword actually gives control

00:09:44,860 --> 00:09:50,260
back to back to python and the

00:09:48,160 --> 00:09:52,660
asynchronous system meaning that you're

00:09:50,260 --> 00:09:55,450
not actually blocking your code just

00:09:52,660 --> 00:09:57,040
seems like it is so it's much easier to

00:09:55,450 --> 00:10:00,250
follow if you're you know used to

00:09:57,040 --> 00:10:01,990
regular synchronous techniques it's much

00:10:00,250 --> 00:10:04,180
easier to understand the your callback

00:10:01,990 --> 00:10:06,630
method of doing it and it's a very

00:10:04,180 --> 00:10:08,710
familiar sort of API

00:10:06,630 --> 00:10:09,390
of course there's new kids on the block

00:10:08,710 --> 00:10:12,010
as well

00:10:09,390 --> 00:10:13,540
Aysen KO was designed as a common kernel

00:10:12,010 --> 00:10:15,460
for all the asynchronous systems in

00:10:13,540 --> 00:10:18,370
python but has kind of become a thing on

00:10:15,460 --> 00:10:20,080
it of its own frameworks like trio turn

00:10:18,370 --> 00:10:22,240
the conventional systems on his head

00:10:20,080 --> 00:10:23,920
using the new native cur teens to

00:10:22,240 --> 00:10:26,380
provide a bit of a different API for

00:10:23,920 --> 00:10:28,390
your non-blocking i/o

00:10:26,380 --> 00:10:31,750
but I'm here to talk about Django as

00:10:28,390 --> 00:10:33,850
well Django 3.0 will come with native

00:10:31,750 --> 00:10:36,730
asynchronous support for quite a few of

00:10:33,850 --> 00:10:38,400
its API is meaning that asynchronous IO

00:10:36,730 --> 00:10:40,870
is going to be something that

00:10:38,400 --> 00:10:42,490
innumerable Python developers will now

00:10:40,870 --> 00:10:45,760
get to take advantage of on a day to day

00:10:42,490 --> 00:10:47,680
basis this is really unspeakably huge as

00:10:45,760 --> 00:10:49,930
it brings async truly into the Python

00:10:47,680 --> 00:10:52,030
main screen the effect of async I own

00:10:49,930 --> 00:10:54,550
twisted is going to be relatively small

00:10:52,030 --> 00:10:59,920
compared to frameworks such as Django

00:10:54,550 --> 00:11:01,780
adopting these systems but if twisted is

00:10:59,920 --> 00:11:03,760
been around for nearly 20 years and

00:11:01,780 --> 00:11:05,860
async IO has been around for five well I

00:11:03,760 --> 00:11:09,160
said only now that something like Django

00:11:05,860 --> 00:11:11,410
is adopting its ideas the benefits of

00:11:09,160 --> 00:11:13,180
using asynchronous IO especially in web

00:11:11,410 --> 00:11:16,180
development have been clear for a long

00:11:13,180 --> 00:11:21,070
time but we're sort of approaching a

00:11:16,180 --> 00:11:22,390
tipping point it seems now that async is

00:11:21,070 --> 00:11:25,420
no longer something that you can just

00:11:22,390 --> 00:11:27,730
opt out of supporting after no js' came

00:11:25,420 --> 00:11:31,510
onto the scene the time sort of started

00:11:27,730 --> 00:11:33,670
turning no Jess Ennis early days was

00:11:31,510 --> 00:11:35,920
very similar to Python at the time where

00:11:33,670 --> 00:11:37,210
had little language support a native

00:11:35,920 --> 00:11:38,740
language support for doing anything

00:11:37,210 --> 00:11:40,720
asynchronous things it was bound by

00:11:38,740 --> 00:11:42,880
single thread limits but despite that

00:11:40,720 --> 00:11:46,570
people were able to lots of new and

00:11:42,880 --> 00:11:48,460
exciting things with it we all know now

00:11:46,570 --> 00:11:49,810
that async and JavaScript is more or

00:11:48,460 --> 00:11:51,910
less as good as you can get in an

00:11:49,810 --> 00:11:53,800
interpretive language interpreter

00:11:51,910 --> 00:11:55,870
problem funnily enough it was actually

00:11:53,800 --> 00:11:58,120
JavaScript that adopted twisted side

00:11:55,870 --> 00:12:00,370
ia's first what we know is promises

00:11:58,120 --> 00:12:02,590
a-plus actually started out as a port of

00:12:00,370 --> 00:12:04,510
twisted stafford to javascript which was

00:12:02,590 --> 00:12:06,520
then subsequently iterated on through

00:12:04,510 --> 00:12:10,000
different frameworks and standardized to

00:12:06,520 --> 00:12:12,220
the form we know today now upon seeing

00:12:10,000 --> 00:12:14,230
sort of how good async could be everyone

00:12:12,220 --> 00:12:16,930
sort of wanted in on them wanted this

00:12:14,230 --> 00:12:18,340
native support languages that didn't

00:12:16,930 --> 00:12:21,910
have a good story at the time like

00:12:18,340 --> 00:12:23,820
Python ended up losing users too once it

00:12:21,910 --> 00:12:26,950
did like go

00:12:23,820 --> 00:12:30,910
so first-class support for asynchronous

00:12:26,950 --> 00:12:33,190
code seems to be a must last last month

00:12:30,910 --> 00:12:35,350
the Russ long are coming async/await

00:12:33,190 --> 00:12:39,010
support landed and I'm very much looking

00:12:35,350 --> 00:12:40,449
forward to see where that goes but what

00:12:39,010 --> 00:12:43,659
is this require

00:12:40,449 --> 00:12:45,759
for a nice Inc story driven by is it

00:12:43,659 --> 00:12:47,229
just people you know wanting this fancy

00:12:45,759 --> 00:12:51,639
new feature is there some technical

00:12:47,229 --> 00:12:53,289
reason why it's so effective I think

00:12:51,639 --> 00:12:56,199
it's that computers are not getting

00:12:53,289 --> 00:12:57,759
faster we're having to be more efficient

00:12:56,199 --> 00:13:00,909
with what we have and for a lot of

00:12:57,759 --> 00:13:02,639
networking based workloads which which a

00:13:00,909 --> 00:13:04,509
lot of web development sort of goes

00:13:02,639 --> 00:13:06,999
focuses on especially when you're

00:13:04,509 --> 00:13:08,769
talking to web clients and databases and

00:13:06,999 --> 00:13:11,129
all that much do your time is not

00:13:08,769 --> 00:13:13,389
actually in Python but in networking and

00:13:11,129 --> 00:13:14,859
when you're doing that asynchronous i/o

00:13:13,389 --> 00:13:19,749
is far more efficient than that of a

00:13:14,859 --> 00:13:22,539
traditional blocking regime so you might

00:13:19,749 --> 00:13:24,970
think computers are getting faster very

00:13:22,539 --> 00:13:27,369
much so why would we buy these new ones

00:13:24,970 --> 00:13:29,259
if they weren't getting faster this is

00:13:27,369 --> 00:13:31,479
the history of you know mid-range Intel

00:13:29,259 --> 00:13:34,029
CPUs for the past ten years and as you

00:13:31,479 --> 00:13:41,319
can see that the passport numbers are

00:13:34,029 --> 00:13:45,209
going up faster it's close right but

00:13:41,319 --> 00:13:48,129
benchmarks don't tell the whole story

00:13:45,209 --> 00:13:51,699
those jumps in performance are because

00:13:48,129 --> 00:13:53,499
those CPUs added more cores if we divide

00:13:51,699 --> 00:13:55,689
that performance by the number of cores

00:13:53,499 --> 00:13:57,009
and the clock speed we can see that

00:13:55,689 --> 00:13:59,739
there hasn't been a significant increase

00:13:57,009 --> 00:14:03,519
on the whole since the core i5 660

00:13:59,739 --> 00:14:05,559
launched in 2009 in fact performance has

00:14:03,519 --> 00:14:10,569
even dipped a bit for the past couple

00:14:05,559 --> 00:14:12,869
generations why is this Specter and

00:14:10,569 --> 00:14:15,429
meltdown has sort of ruined everything

00:14:12,869 --> 00:14:17,139
they round back nearly every relative

00:14:15,429 --> 00:14:18,729
performance improvement that Intel CPUs

00:14:17,139 --> 00:14:21,819
have had since they're called core

00:14:18,729 --> 00:14:23,589
series's inception and even the tenth

00:14:21,819 --> 00:14:25,029
generation Intel CPUs doodle launcher

00:14:23,589 --> 00:14:27,129
Christmas won't really improve at that

00:14:25,029 --> 00:14:29,019
much all these improvements that we've

00:14:27,129 --> 00:14:30,819
been getting are based on things in the

00:14:29,019 --> 00:14:34,479
insecure and we're now having to roll

00:14:30,819 --> 00:14:35,979
them back of course we have improved

00:14:34,479 --> 00:14:38,319
technology to the point where there is a

00:14:35,979 --> 00:14:41,199
point to new CPUs they use less power

00:14:38,319 --> 00:14:43,419
and that means that even if our CPUs are

00:14:41,199 --> 00:14:44,679
the same performance clock for clock we

00:14:43,419 --> 00:14:47,709
can still run them at a higher clock

00:14:44,679 --> 00:14:49,989
speed to a limit add more cores and stay

00:14:47,709 --> 00:14:52,059
within the same power envelope that's a

00:14:49,989 --> 00:14:53,710
massive boon for consumers as even a

00:14:52,059 --> 00:14:55,360
low-power CPU can

00:14:53,710 --> 00:14:57,520
turbo reached to four gigahertz and

00:14:55,360 --> 00:14:59,530
higher for short times but it doesn't

00:14:57,520 --> 00:15:01,600
really help those of us that deploy to

00:14:59,530 --> 00:15:03,580
servers or do enough work that the

00:15:01,600 --> 00:15:07,860
frequency boosts eventually have to stop

00:15:03,580 --> 00:15:10,660
because you're causing too much heat and

00:15:07,860 --> 00:15:12,580
I don't think that this is just the past

00:15:10,660 --> 00:15:14,170
ten years I don't think that the next 10

00:15:12,580 --> 00:15:18,070
years is going to get as fast to

00:15:14,170 --> 00:15:19,660
computers either arm is looming on the

00:15:18,070 --> 00:15:21,940
fries and ready to take over the server

00:15:19,660 --> 00:15:25,720
market but that's because of price and

00:15:21,940 --> 00:15:27,460
power efficiency not speed you can fit

00:15:25,720 --> 00:15:29,710
more theoretical performance per square

00:15:27,460 --> 00:15:31,870
foot with an arm cluster but each one of

00:15:29,710 --> 00:15:33,970
those individual CPUs is slower than an

00:15:31,870 --> 00:15:37,420
equivalent x86 core and might well

00:15:33,970 --> 00:15:40,630
always be other contenders like risk 5

00:15:37,420 --> 00:15:42,580
are promising but yet to be proven the

00:15:40,630 --> 00:15:44,800
first few letters in risk stand for

00:15:42,580 --> 00:15:46,870
restricted instruction set in contrast

00:15:44,800 --> 00:15:50,230
to the complex instruction set of sisk

00:15:46,870 --> 00:15:51,880
processes like x86 Intel's early

00:15:50,230 --> 00:15:54,370
solutions to performance problems was to

00:15:51,880 --> 00:15:56,350
introduce instructions that did more per

00:15:54,370 --> 00:15:57,730
single instruction therefore getting

00:15:56,350 --> 00:16:00,310
more performance out of less

00:15:57,730 --> 00:16:03,100
instructions per clock cycle that you

00:16:00,310 --> 00:16:04,450
get in an sis regime this let them

00:16:03,100 --> 00:16:06,670
dominate the computing space for the

00:16:04,450 --> 00:16:08,410
next few decades but the complexity of

00:16:06,670 --> 00:16:10,330
sisk processors now makes the relative

00:16:08,410 --> 00:16:13,000
simplicity of platforms like most quite

00:16:10,330 --> 00:16:15,040
attractive not for performance or really

00:16:13,000 --> 00:16:16,420
for security but for the ability for a

00:16:15,040 --> 00:16:19,170
human to maybe understand what the hell

00:16:16,420 --> 00:16:21,490
is going on inside of it

00:16:19,170 --> 00:16:23,830
it's unfortunate though that we are

00:16:21,490 --> 00:16:26,620
ultimately hitting the limitations of

00:16:23,830 --> 00:16:28,360
our control of physics the smaller our

00:16:26,620 --> 00:16:29,800
transistors the harder they are to make

00:16:28,360 --> 00:16:32,170
the lower the yields and the more

00:16:29,800 --> 00:16:34,450
difficult the next iteration we have

00:16:32,170 --> 00:16:36,400
taken every easy option available in the

00:16:34,450 --> 00:16:39,340
hardware so it's time to start taking

00:16:36,400 --> 00:16:42,250
the harder ones so what are the kind of

00:16:39,340 --> 00:16:44,320
processors and platforms we as Python

00:16:42,250 --> 00:16:47,800
developers or developers at large will

00:16:44,320 --> 00:16:49,270
have to operate on in the future we can

00:16:47,800 --> 00:16:52,780
look at the present for what the future

00:16:49,270 --> 00:16:54,550
holds this is the rice and 5 3600 the

00:16:52,780 --> 00:16:58,480
CPU that's in my desktop at home it's

00:16:54,550 --> 00:17:00,220
actually picture it's a consumer CPU but

00:16:58,480 --> 00:17:02,250
it's very similar to the high-end and

00:17:00,220 --> 00:17:04,839
server processors that AMD are releasing

00:17:02,250 --> 00:17:07,040
just use they're using the same core

00:17:04,839 --> 00:17:08,720
architecture and even the same silicon

00:17:07,040 --> 00:17:12,170
just arranged differently on on larger

00:17:08,720 --> 00:17:13,699
chips this cpu with six cores here costs

00:17:12,170 --> 00:17:16,970
200 American dollars

00:17:13,699 --> 00:17:19,430
well the epic 77042 you might find in a

00:17:16,970 --> 00:17:22,459
new render farm server cost seven and a

00:17:19,430 --> 00:17:25,550
half thousand US dollars but that has 64

00:17:22,459 --> 00:17:29,840
cores and 128 threads they have a lot of

00:17:25,550 --> 00:17:32,180
products in between but it's worth

00:17:29,840 --> 00:17:34,700
looking at what we'll do with those ones

00:17:32,180 --> 00:17:36,890
in between and it's likely that you'll

00:17:34,700 --> 00:17:39,020
find things similar to this or working

00:17:36,890 --> 00:17:40,520
on the same architecture in render farms

00:17:39,020 --> 00:17:43,580
and general-purpose servers over the

00:17:40,520 --> 00:17:46,940
coming months but again it's not about

00:17:43,580 --> 00:17:49,370
any one CPU or any any one series of

00:17:46,940 --> 00:17:50,920
CPUs it's a small scale replica of where

00:17:49,370 --> 00:17:54,440
the industry's going

00:17:50,920 --> 00:17:57,140
multiple and more CPUs and cause on a

00:17:54,440 --> 00:18:00,560
single processor and all of the

00:17:57,140 --> 00:18:02,060
interestingness step that implies intel

00:18:00,560 --> 00:18:03,650
has announced a similar topology in

00:18:02,060 --> 00:18:06,350
their future service EP use having

00:18:03,650 --> 00:18:09,170
multiple chips inside the same processor

00:18:06,350 --> 00:18:11,120
and it is logically similar to the

00:18:09,170 --> 00:18:15,950
existing multi CPU boards you can find

00:18:11,120 --> 00:18:20,390
its servers now if we look under the

00:18:15,950 --> 00:18:23,750
hood this CPU has an i/o die which is on

00:18:20,390 --> 00:18:25,610
the left and a chip late-- which has six

00:18:23,750 --> 00:18:26,810
cores on it you can see underneath the

00:18:25,610 --> 00:18:28,610
text there's a bit of a room for a

00:18:26,810 --> 00:18:29,930
second one and that sort of is the core

00:18:28,610 --> 00:18:31,490
of this architecture is that you have

00:18:29,930 --> 00:18:33,110
the ayodhya and then you can add

00:18:31,490 --> 00:18:37,550
couplets to get the number of course you

00:18:33,110 --> 00:18:39,680
want on each one of those quarter

00:18:37,550 --> 00:18:41,510
Chipola dies there are two core

00:18:39,680 --> 00:18:44,300
complexes you can see them vertically

00:18:41,510 --> 00:18:47,200
each core complex or CCX

00:18:44,300 --> 00:18:50,060
has 16 megabytes of l3 cache each and

00:18:47,200 --> 00:18:53,030
512 kilobytes of l2 cache for each of

00:18:50,060 --> 00:18:55,040
its four cores since the phase 600 only

00:18:53,030 --> 00:18:58,670
has six cores two of the calls on this

00:18:55,040 --> 00:19:00,860
die are fused off and inoperative MD has

00:18:58,670 --> 00:19:02,780
built their entire CPU line server and

00:19:00,860 --> 00:19:04,370
consumer around these eight core giblets

00:19:02,780 --> 00:19:06,500
and use the ones to have faulty cores

00:19:04,370 --> 00:19:10,130
but otherwise work in lower spec

00:19:06,500 --> 00:19:12,260
products similar to the Athlon X 3s that

00:19:10,130 --> 00:19:15,050
were about 20 years ago now they were

00:19:12,260 --> 00:19:16,760
four core chips that had one faulty core

00:19:15,050 --> 00:19:18,720
so they sold it off and made a three

00:19:16,760 --> 00:19:20,850
quarter

00:19:18,720 --> 00:19:22,410
now they're using these eight core

00:19:20,850 --> 00:19:25,130
triplets in everything from their

00:19:22,410 --> 00:19:27,540
consumer CPUs to their server CPUs in

00:19:25,130 --> 00:19:29,700
something like the epic 77042 I

00:19:27,540 --> 00:19:31,980
mentioned before it would have a single

00:19:29,700 --> 00:19:34,020
of those iodized and eight of those

00:19:31,980 --> 00:19:38,520
fully operational triplets to provide

00:19:34,020 --> 00:19:40,320
the 64 cores as we can see with this

00:19:38,520 --> 00:19:42,900
little diagram the core complex has a

00:19:40,320 --> 00:19:45,480
chunk of l3 cache and - cause they're

00:19:42,900 --> 00:19:47,040
associated l2 cache mirrored on each

00:19:45,480 --> 00:19:49,350
side so you can see the two cores

00:19:47,040 --> 00:19:53,970
Neal - in the l3 and it's the same on

00:19:49,350 --> 00:19:55,920
the other side the Yoda is sort of

00:19:53,970 --> 00:19:57,660
marketed by Intel as controlling what

00:19:55,920 --> 00:19:59,670
they call the Infinity fabric which is

00:19:57,660 --> 00:20:02,130
basically just a marketing term to refer

00:19:59,670 --> 00:20:04,710
to the high-speed connection between the

00:20:02,130 --> 00:20:06,120
i/o die and the chip lots which scales

00:20:04,710 --> 00:20:09,060
up depending on how many triplets you

00:20:06,120 --> 00:20:11,160
have on this single triplet CPU doesn't

00:20:09,060 --> 00:20:13,460
really have a lot of benefits but it's

00:20:11,160 --> 00:20:16,110
important to think about architectural

00:20:13,460 --> 00:20:18,240
now the ayodhya is responsible for

00:20:16,110 --> 00:20:20,250
connecting to your RAM as well as being

00:20:18,240 --> 00:20:20,760
what physically hosts the PCI Express

00:20:20,250 --> 00:20:23,070
Lanes

00:20:20,760 --> 00:20:24,870
it also has some high-speed USB and that

00:20:23,070 --> 00:20:27,290
sort of thing that's the responsibility

00:20:24,870 --> 00:20:31,110
of this die and not that chipler cause

00:20:27,290 --> 00:20:33,180
the chip tlit just has CPU well this IOT

00:20:31,110 --> 00:20:37,200
has the other peripheral things that you

00:20:33,180 --> 00:20:39,150
would expect a CPU to host some of those

00:20:37,200 --> 00:20:41,280
PCI lanes then go to the motherboard

00:20:39,150 --> 00:20:45,570
chipset which then hosts things like

00:20:41,280 --> 00:20:47,250
SATA and more USB ports and all of these

00:20:45,570 --> 00:20:49,200
parts have to communicate and

00:20:47,250 --> 00:20:51,140
synchronously and it's a hard

00:20:49,200 --> 00:20:53,430
requirement that they have to

00:20:51,140 --> 00:20:55,590
asynchronous communication between your

00:20:53,430 --> 00:20:57,330
motherboard in your CPU is core to

00:20:55,590 --> 00:20:59,520
allowing different parts of a computer

00:20:57,330 --> 00:21:02,870
to get faster without requiring the

00:20:59,520 --> 00:21:02,870
others to act in lockstep

00:21:14,139 --> 00:21:19,669
nowadays everything on your computer

00:21:16,239 --> 00:21:21,440
will have a different clock speed PCI

00:21:19,669 --> 00:21:23,080
Express has a different clock speed than

00:21:21,440 --> 00:21:25,999
your CPU and your AM

00:21:23,080 --> 00:21:28,700
this wasn't always the case as the old

00:21:25,999 --> 00:21:31,129
frontside bus design of of 90s and early

00:21:28,700 --> 00:21:32,989
2000s computers and a frontside bus

00:21:31,129 --> 00:21:35,539
clock speed and then a CPU clock speed

00:21:32,989 --> 00:21:37,129
multiplier your frontside bus clock

00:21:35,539 --> 00:21:39,200
speed often had to be the same as your

00:21:37,129 --> 00:21:40,639
RAM clock speed which would introduce a

00:21:39,200 --> 00:21:42,139
bottleneck especially since your

00:21:40,639 --> 00:21:44,299
frontside bus clock speed on some

00:21:42,139 --> 00:21:45,950
systems would also dictate the clock

00:21:44,299 --> 00:21:48,710
speed that your PCI devices had to

00:21:45,950 --> 00:21:51,169
operate so this one clock speed not only

00:21:48,710 --> 00:21:55,369
made how fast your PCI was in your RAM

00:21:51,169 --> 00:21:56,839
was but also how fast your CPU was one

00:21:55,369 --> 00:21:58,789
computer support all of these having

00:21:56,839 --> 00:22:00,019
different clocks and to have different

00:21:58,789 --> 00:22:02,719
clocks you need to run them and

00:22:00,019 --> 00:22:04,549
communicate synchronously in fact the

00:22:02,719 --> 00:22:06,679
frontside bus on computers no longer

00:22:04,549 --> 00:22:09,169
exists and the CPU will often have its

00:22:06,679 --> 00:22:10,849
own memory controller and will interface

00:22:09,169 --> 00:22:14,450
with things like PCI Express and etc

00:22:10,849 --> 00:22:17,089
directly on the newer CPU architectures

00:22:14,450 --> 00:22:18,830
like the Zen 2 of the Rison 3600 even

00:22:17,089 --> 00:22:21,859
the clock speed of the Infinity fabric

00:22:18,830 --> 00:22:23,839
interconnect between the i/o die and the

00:22:21,859 --> 00:22:26,179
chip le'ts can be independent of the

00:22:23,839 --> 00:22:28,399
ayodhya and the giblets meaning that you

00:22:26,179 --> 00:22:32,349
can overclock those giblets without

00:22:28,399 --> 00:22:32,349
overclocking the i/o die or vice versa

00:22:32,799 --> 00:22:38,259
who remembers these I don't

00:22:38,360 --> 00:22:46,070
a little bit now I was an Amiga kid

00:22:42,700 --> 00:22:48,260
anyway these two keyboards are - the the

00:22:46,070 --> 00:22:50,149
real real-world ones operated on a

00:22:48,260 --> 00:22:51,019
interrupts system when they had

00:22:50,149 --> 00:22:52,580
something to report

00:22:51,019 --> 00:22:54,919
like a mouse movement or a key press

00:22:52,580 --> 00:22:56,289
they would send a CPU interrupt to tell

00:22:54,919 --> 00:22:58,820
the CPU that something had happened

00:22:56,289 --> 00:23:00,950
it kind of is what it sounds like it

00:22:58,820 --> 00:23:03,470
interrupts the entire CPU she gets

00:23:00,950 --> 00:23:04,640
message through this as you can guess

00:23:03,470 --> 00:23:07,250
kind of sucks if you're trying to do

00:23:04,640 --> 00:23:08,779
other things with your CPU so we

00:23:07,250 --> 00:23:12,260
eventually replaced it with asynchronous

00:23:08,779 --> 00:23:14,210
systems such as USB USB is instead a

00:23:12,260 --> 00:23:15,830
polling based interface where it's up to

00:23:14,210 --> 00:23:17,389
the host computer to query think from a

00:23:15,830 --> 00:23:20,510
device to make things a lot simpler as

00:23:17,389 --> 00:23:22,190
well for certain devices like mice and

00:23:20,510 --> 00:23:24,649
keyboards the instant response of

00:23:22,190 --> 00:23:26,210
interrupts was advantageous but with

00:23:24,649 --> 00:23:28,429
modern gaming mice pulling it like a

00:23:26,210 --> 00:23:30,919
thousand Hertz this is no longer really

00:23:28,429 --> 00:23:32,299
a problem and it means that when we have

00:23:30,919 --> 00:23:34,010
multiple cores we're not shutting down

00:23:32,299 --> 00:23:37,460
the world to tell you that your mouse

00:23:34,010 --> 00:23:39,049
moved polling doesn't quite work with

00:23:37,460 --> 00:23:42,710
everything though especially higher

00:23:39,049 --> 00:23:44,110
performance platforms things like PCI

00:23:42,710 --> 00:23:46,610
Express use a bi-directional

00:23:44,110 --> 00:23:48,200
asynchronous communication system which

00:23:46,610 --> 00:23:51,260
is always comparable to something like

00:23:48,200 --> 00:23:53,419
F&N you send packets of data down to the

00:23:51,260 --> 00:23:55,970
BC ie device and it sends packets of

00:23:53,419 --> 00:23:58,820
data back like it like it were speaking

00:23:55,970 --> 00:24:02,299
ethany getting these messages doesn't

00:23:58,820 --> 00:24:04,039
halt the CPU and we've liked these newer

00:24:02,299 --> 00:24:08,029
things for the I die it's actually quite

00:24:04,039 --> 00:24:10,610
far away from CPU cause the PCI data is

00:24:08,029 --> 00:24:13,700
then funneled over the interconnect to

00:24:10,610 --> 00:24:15,080
the CPUs which again is running can run

00:24:13,700 --> 00:24:17,809
at a different clock speed than both the

00:24:15,080 --> 00:24:19,309
CPU and the PCI Express bus this gets

00:24:17,809 --> 00:24:21,470
relatively important when you look at

00:24:19,309 --> 00:24:25,100
for example the new PCI Express v4 which

00:24:21,470 --> 00:24:27,740
is even higher speed because if you were

00:24:25,100 --> 00:24:28,639
limited by how fast your CPU was we

00:24:27,740 --> 00:24:30,919
wouldn't be able to get these

00:24:28,639 --> 00:24:33,080
improvements in hardware without having

00:24:30,919 --> 00:24:35,269
to have entirely new generations of CPUs

00:24:33,080 --> 00:24:38,059
that are much faster because we can't

00:24:35,269 --> 00:24:40,059
get much faster with the CPUs we have to

00:24:38,059 --> 00:24:44,000
you know untie them

00:24:40,059 --> 00:24:46,159
of course the ayodhya being central and

00:24:44,000 --> 00:24:48,110
separate to the CPU cores sidesteps a

00:24:46,159 --> 00:24:50,899
significant problem and there's Numa

00:24:48,110 --> 00:24:51,700
Numa stands for non-uniform memory

00:24:50,899 --> 00:24:53,019
access

00:24:51,700 --> 00:24:54,909
and describes an architecture where you

00:24:53,019 --> 00:24:57,130
have multiple CPUs that don't all share

00:24:54,909 --> 00:25:00,309
the same memory you can have a large

00:24:57,130 --> 00:25:02,230
common memory bank but that can increase

00:25:00,309 --> 00:25:04,059
licensee as the memory gets physically

00:25:02,230 --> 00:25:06,850
further away from the CPUs on the

00:25:04,059 --> 00:25:08,820
motherboard and in the chip and more

00:25:06,850 --> 00:25:10,929
CPUs are using a limited common bus

00:25:08,820 --> 00:25:12,760
instead when you have lots and lots and

00:25:10,929 --> 00:25:14,889
lots of cores a Numa system will have

00:25:12,760 --> 00:25:17,649
some CPUs having local memory which is

00:25:14,889 --> 00:25:19,779
very close in high performance and an

00:25:17,649 --> 00:25:26,019
ability to ask other CPUs to pass

00:25:19,779 --> 00:25:27,279
through memory that it controls now the

00:25:26,019 --> 00:25:29,529
previous generation of AMD's

00:25:27,279 --> 00:25:31,659
high-performance systems implemented

00:25:29,529 --> 00:25:34,450
Numa and I was a real brain scrambler

00:25:31,659 --> 00:25:36,820
for traditional software you had close

00:25:34,450 --> 00:25:38,230
memory in file memory and a lot of

00:25:36,820 --> 00:25:40,419
software that we arrived doesn't

00:25:38,230 --> 00:25:42,639
interact well with that in Python

00:25:40,419 --> 00:25:45,220
there's no way of saying no no no keep

00:25:42,639 --> 00:25:47,110
things over here and avoid calling out

00:25:45,220 --> 00:25:49,330
over there and this was the case for

00:25:47,110 --> 00:25:52,059
games and that sort of thing this got

00:25:49,330 --> 00:25:55,360
better because Windows and Linux and

00:25:52,059 --> 00:25:56,679
that decided decided to keep things in

00:25:55,360 --> 00:25:58,539
the memory that they were dealing with

00:25:56,679 --> 00:25:59,860
but early on it would just put them

00:25:58,539 --> 00:26:03,669
anywhere and you'd end up paying these

00:25:59,860 --> 00:26:05,139
Numa costs without any real benefit now

00:26:03,669 --> 00:26:08,019
that's not the case with these newer

00:26:05,139 --> 00:26:09,669
CPUs but if you have multiple CPU

00:26:08,019 --> 00:26:11,799
sockets per machine you still have those

00:26:09,669 --> 00:26:13,960
Numa characteristics because each CPU

00:26:11,799 --> 00:26:15,669
will have its own memory banks even if

00:26:13,960 --> 00:26:19,720
all the cores share the same memory bank

00:26:15,669 --> 00:26:22,179
on its CPU so what does this leave us

00:26:19,720 --> 00:26:24,730
with we have small cores which is great

00:26:22,179 --> 00:26:26,740
everyone loves more cores we can access

00:26:24,730 --> 00:26:28,330
more memory especially on your soccer

00:26:26,740 --> 00:26:31,210
machines because of improvements over

00:26:28,330 --> 00:26:32,710
the past 10 years and high-powered

00:26:31,210 --> 00:26:34,960
interconnects means that we have more

00:26:32,710 --> 00:26:37,090
bandwidth to everything such as PC or

00:26:34,960 --> 00:26:40,600
RAM or whatever or between different

00:26:37,090 --> 00:26:43,120
chips but these performance improvements

00:26:40,600 --> 00:26:44,950
have an architectural cost we've got

00:26:43,120 --> 00:26:47,769
lower single core performance especially

00:26:44,950 --> 00:26:49,539
in alternative platforms like arm we've

00:26:47,769 --> 00:26:51,490
increased latency because things like

00:26:49,539 --> 00:26:54,450
the i/o die are simply more things

00:26:51,490 --> 00:26:57,190
between us and things for accessing and

00:26:54,450 --> 00:26:59,260
even if it allows us to access more at a

00:26:57,190 --> 00:27:01,899
higher bandwidth we're still gonna have

00:26:59,260 --> 00:27:04,269
to wait longer and it adds a bunch more

00:27:01,899 --> 00:27:05,190
complexity and every level especially

00:27:04,269 --> 00:27:08,820
when you factor in things

00:27:05,190 --> 00:27:10,680
cache coherency so let's look at one of

00:27:08,820 --> 00:27:13,410
those things let's see because that

00:27:10,680 --> 00:27:14,940
factors internetworking it's important

00:27:13,410 --> 00:27:16,830
when you think about asynchronous i/o

00:27:14,940 --> 00:27:18,150
but it's also important to recognize

00:27:16,830 --> 00:27:19,590
what affects latency has on the

00:27:18,150 --> 00:27:21,840
different things we might to do might

00:27:19,590 --> 00:27:25,230
want to do on the on local to the

00:27:21,840 --> 00:27:27,840
computer so 3.6 gigahertz CPU like my

00:27:25,230 --> 00:27:32,270
one does 3.6 billion cycles per second

00:27:27,840 --> 00:27:35,580
each shaking 0.7 nanoseconds each

00:27:32,270 --> 00:27:38,190
now the l3 cache on that chip takes

00:27:35,580 --> 00:27:41,430
about 40 clock cycles to communicate

00:27:38,190 --> 00:27:44,760
with which is about 11 nanoseconds the

00:27:41,430 --> 00:27:45,330
ddr4 to 666 which is fairly decent Ram

00:27:44,760 --> 00:27:48,240
mm-hm

00:27:45,330 --> 00:27:51,600
take 55 clocks a clock cycles to access

00:27:48,240 --> 00:27:53,940
and that's pretty good as well now the

00:27:51,600 --> 00:27:55,290
fastest SSD you can buy and we're

00:27:53,940 --> 00:28:00,360
talking tens of thousands of dollars

00:27:55,290 --> 00:28:02,730
here we'll take 220,000 clock cycles or

00:28:00,360 --> 00:28:08,310
60,000 and a seconds so it's quite a big

00:28:02,730 --> 00:28:11,250
jump from cache and RAM to SSD now my

00:28:08,310 --> 00:28:13,290
local router to my local ISP takes about

00:28:11,250 --> 00:28:16,200
12 milliseconds or 12 million

00:28:13,290 --> 00:28:19,560
nanoseconds it's about 45 million clock

00:28:16,200 --> 00:28:21,150
cycles after we do Australia to Los

00:28:19,560 --> 00:28:23,790
Angeles which Melbourne to Los Angeles

00:28:21,150 --> 00:28:27,390
which was the flight I took for a person

00:28:23,790 --> 00:28:29,250
that took 14 hours for a packet it takes

00:28:27,390 --> 00:28:30,270
three hundred and fifteen milliseconds

00:28:29,250 --> 00:28:34,920
and I can tell you which one I would

00:28:30,270 --> 00:28:36,840
prefer but that's like 1.2 billion clock

00:28:34,920 --> 00:28:40,050
cycles since you know getting quite

00:28:36,840 --> 00:28:43,410
large think of us like the Katia's like

00:28:40,050 --> 00:28:45,300
your desk you grab the paper the DDF is

00:28:43,410 --> 00:28:47,180
the filing cabinet maybe in the next

00:28:45,300 --> 00:28:50,190
room depending on the speed of your RAM

00:28:47,180 --> 00:28:52,590
the SSD is you know an in-state parcel

00:28:50,190 --> 00:28:54,510
coming in and sending something to Los

00:28:52,590 --> 00:28:57,000
Angeles's quite literally just flying to

00:28:54,510 --> 00:29:01,050
Pluto it's it's like most of a human

00:28:57,000 --> 00:29:05,310
lifetime in comparison so how do we make

00:29:01,050 --> 00:29:08,820
the best of this kind of latency well

00:29:05,310 --> 00:29:12,660
when I said that the rise in 3600 had

00:29:08,820 --> 00:29:13,680
six cause dos 12 threads and that means

00:29:12,660 --> 00:29:16,110
that supports simultaneous

00:29:13,680 --> 00:29:17,460
multi-threading now simultaneous

00:29:16,110 --> 00:29:18,720
multi-threading is the practice of

00:29:17,460 --> 00:29:21,180
having two virtual

00:29:18,720 --> 00:29:23,130
or two or more virtual calls / real call

00:29:21,180 --> 00:29:25,440
with the assumption that one of those

00:29:23,130 --> 00:29:28,110
virtual cores will be waiting on RAM or

00:29:25,440 --> 00:29:29,550
disk to do anything meaning that the

00:29:28,110 --> 00:29:31,320
other can actually use the processing

00:29:29,550 --> 00:29:33,540
parts of the CPU all the other one is

00:29:31,320 --> 00:29:35,820
waiting it's not something you can

00:29:33,540 --> 00:29:37,530
really control but it's worth knowing

00:29:35,820 --> 00:29:40,290
that some workloads operate better with

00:29:37,530 --> 00:29:41,670
it and some don't in the context of

00:29:40,290 --> 00:29:44,040
Python because we're accessing things

00:29:41,670 --> 00:29:46,260
like the RAM a lot and they did I disc a

00:29:44,040 --> 00:29:48,060
lot it is likely that they will operate

00:29:46,260 --> 00:29:50,190
on the whole with a performance

00:29:48,060 --> 00:29:52,290
improvement you can get about 150

00:29:50,190 --> 00:29:54,360
percent of the performance of a single

00:29:52,290 --> 00:29:56,430
core with this because you're simply

00:29:54,360 --> 00:29:59,430
slotting things in when they're ready

00:29:56,430 --> 00:30:02,790
and utilizing that actual processing

00:29:59,430 --> 00:30:04,170
part of the CPU more effectively it's

00:30:02,790 --> 00:30:07,230
also important to maintain cache

00:30:04,170 --> 00:30:09,630
coherency with maaan CPUs having upwards

00:30:07,230 --> 00:30:10,020
of 16 megabytes of l3 cache per set of

00:30:09,630 --> 00:30:12,540
cores

00:30:10,020 --> 00:30:15,210
keeping that case valid and closed is

00:30:12,540 --> 00:30:17,850
extremely important by staying on the

00:30:15,210 --> 00:30:19,770
same core or the same core complex it

00:30:17,850 --> 00:30:22,950
will stay coherent and fresh and close

00:30:19,770 --> 00:30:25,080
and that means that with such a large

00:30:22,950 --> 00:30:27,360
amount of case you can store significant

00:30:25,080 --> 00:30:28,830
parts of executables in your cache

00:30:27,360 --> 00:30:31,620
without having to load it from disk

00:30:28,830 --> 00:30:33,330
again things like sending CPU affinity

00:30:31,620 --> 00:30:35,490
keeping processes local to their cache

00:30:33,330 --> 00:30:39,170
therefore can become extremely important

00:30:35,490 --> 00:30:41,730
for getting the most out of those CPUs

00:30:39,170 --> 00:30:44,730
so the best thing to do in this sort of

00:30:41,730 --> 00:30:46,710
scheme is having every available working

00:30:44,730 --> 00:30:50,910
core have only one thread running on it

00:30:46,710 --> 00:30:53,130
staying as active as possible but

00:30:50,910 --> 00:30:56,010
sometimes waiting is unavoidable those

00:30:53,130 --> 00:30:57,330
fetches from Ram or disks will block

00:30:56,010 --> 00:30:59,370
your application no matter what you do

00:30:57,330 --> 00:31:01,230
and it's not like we can avoid fetching

00:30:59,370 --> 00:31:03,060
from Ram or avoid fetching from a disk

00:31:01,230 --> 00:31:06,290
sometimes there's things that we have to

00:31:03,060 --> 00:31:09,450
do but the point of asynchronous i/o is

00:31:06,290 --> 00:31:13,070
avoiding it where you can and networking

00:31:09,450 --> 00:31:15,270
is a great place where you can avoid it

00:31:13,070 --> 00:31:17,010
pre-emptive multitasking can be a bit of

00:31:15,270 --> 00:31:18,180
a mine killer here as well as the

00:31:17,010 --> 00:31:19,710
operating system will see that

00:31:18,180 --> 00:31:22,980
potentially you're waiting on some RAM

00:31:19,710 --> 00:31:24,510
or CPU or hell even networking and will

00:31:22,980 --> 00:31:26,510
attempt to go oh well you don't need a

00:31:24,510 --> 00:31:28,920
CPU so I'll put something else there

00:31:26,510 --> 00:31:30,630
settings CP affinity means that you

00:31:28,920 --> 00:31:32,040
won't get moved to other cores

00:31:30,630 --> 00:31:33,420
but the offering system my

00:31:32,040 --> 00:31:35,490
put something there that overwrites all

00:31:33,420 --> 00:31:38,250
your precious cases while you're waiting

00:31:35,490 --> 00:31:39,450
for disc read so there's things you can

00:31:38,250 --> 00:31:41,670
do in your operating system to avoid

00:31:39,450 --> 00:31:44,550
that but basically just reducing the

00:31:41,670 --> 00:31:46,410
number of things that can be scheduled

00:31:44,550 --> 00:31:47,910
there's having lighter weight servers

00:31:46,410 --> 00:31:51,930
that run just what they need to is also

00:31:47,910 --> 00:31:54,690
important but again waiting is

00:31:51,930 --> 00:31:57,720
unavoidable factors from around will

00:31:54,690 --> 00:31:59,160
block you no matter what you can do but

00:31:57,720 --> 00:32:02,580
the point is sitting not sitting around

00:31:59,160 --> 00:32:05,700
for longer than we need to and how do we

00:32:02,580 --> 00:32:07,010
do that by using asynchronous networking

00:32:05,700 --> 00:32:09,990
techniques like I've been going on about

00:32:07,010 --> 00:32:12,600
we can avoid the blocking to be just

00:32:09,990 --> 00:32:14,280
those things that we can't avoid but

00:32:12,600 --> 00:32:16,610
keeping the networking which again takes

00:32:14,280 --> 00:32:20,730
many to many many many times longer

00:32:16,610 --> 00:32:24,090
making that not take not having that not

00:32:20,730 --> 00:32:27,030
block a loss level we want non blocking

00:32:24,090 --> 00:32:29,100
sockets these will not block when we try

00:32:27,030 --> 00:32:31,230
and do things with them like reading and

00:32:29,100 --> 00:32:32,850
running will instead rely on us checking

00:32:31,230 --> 00:32:37,050
on their readiness state before we try

00:32:32,850 --> 00:32:39,150
and do it if the socket has no data then

00:32:37,050 --> 00:32:41,610
it'll Razer would block error telling us

00:32:39,150 --> 00:32:43,350
to come back later as well as if we turn

00:32:41,610 --> 00:32:44,910
right too much data to it and the

00:32:43,350 --> 00:32:46,740
operating systems write buffers become

00:32:44,910 --> 00:32:50,370
full it'll tell no I can't accept any

00:32:46,740 --> 00:32:53,370
more data without blocking so we have

00:32:50,370 --> 00:32:55,320
the problem where we can't always talk

00:32:53,370 --> 00:32:58,740
to these sockets so how do we figure out

00:32:55,320 --> 00:33:00,240
when we can now select is the standard

00:32:58,740 --> 00:33:02,040
UNIX API for working with these

00:33:00,240 --> 00:33:03,660
non-blocking sockets there's

00:33:02,040 --> 00:33:05,520
improvements to the same basic formula

00:33:03,660 --> 00:33:07,530
in KQ any Paul which are the things that

00:33:05,520 --> 00:33:09,840
you you know actually use but the main

00:33:07,530 --> 00:33:12,090
uses the main core of it is the same you

00:33:09,840 --> 00:33:14,010
give it the sockets you want to know if

00:33:12,090 --> 00:33:16,170
you can use and it'll tell you which

00:33:14,010 --> 00:33:18,060
ones can be read from written written to

00:33:16,170 --> 00:33:22,140
more or have errors such as being

00:33:18,060 --> 00:33:23,820
unexpectedly closed we've this basic API

00:33:22,140 --> 00:33:26,370
we can then implement what's called an

00:33:23,820 --> 00:33:27,990
event loop the parts of our application

00:33:26,370 --> 00:33:30,600
that then use these non-blocking sockets

00:33:27,990 --> 00:33:32,160
registro on this event loop and the

00:33:30,600 --> 00:33:34,650
event loop will then notify them when

00:33:32,160 --> 00:33:37,980
the sockets already turning this more

00:33:34,650 --> 00:33:40,410
into sort of our hey tell me when this

00:33:37,980 --> 00:33:44,880
is ready okay here's the event which is

00:33:40,410 --> 00:33:45,960
data the olaf analog is leaving in

00:33:44,880 --> 00:33:48,000
microwave to do it state

00:33:45,960 --> 00:33:50,789
until it beeps rather than standing

00:33:48,000 --> 00:33:52,919
there and waiting for yourself I mean

00:33:50,789 --> 00:33:54,210
standing there is simpler you you can

00:33:52,919 --> 00:33:55,950
you don't have to go anywhere you can

00:33:54,210 --> 00:33:57,029
just look at it you don't do anything

00:33:55,950 --> 00:33:58,230
you don't worry about the microwave

00:33:57,029 --> 00:34:00,330
beeping more in your middle of some

00:33:58,230 --> 00:34:05,190
other task but you are being inefficient

00:34:00,330 --> 00:34:06,990
with your time being natively async lets

00:34:05,190 --> 00:34:08,520
us work within the greater asynchronous

00:34:06,990 --> 00:34:10,950
system there's a computer and avoid

00:34:08,520 --> 00:34:13,669
wasting time you're taking advantage of

00:34:10,950 --> 00:34:17,010
its natural state a synchronicity

00:34:13,669 --> 00:34:21,020
totally what let's say see how I'm doing

00:34:17,010 --> 00:34:21,020
Python got a drink first

00:34:22,490 --> 00:34:26,599
well this async is making me thirsty

00:34:27,080 --> 00:34:31,800
so let's look at conventional grab and

00:34:29,909 --> 00:34:33,119
I'm sorry but this is floss because I

00:34:31,800 --> 00:34:41,359
couldn't fit a Django wipe on one screen

00:34:33,119 --> 00:34:43,649
I love you but you have a lot of code

00:34:41,359 --> 00:34:46,470
but this hopefully you should get

00:34:43,649 --> 00:34:48,179
through my point so we have the flask

00:34:46,470 --> 00:34:50,369
app and we have a routes and we have

00:34:48,179 --> 00:34:52,889
main and we do request don't get to

00:34:50,369 --> 00:34:54,270
fetch something from say localhost which

00:34:52,889 --> 00:34:55,589
is why I've been using from my

00:34:54,270 --> 00:34:59,700
benchmarks I've got a local web server

00:34:55,589 --> 00:35:03,000
running that's nginx and then we return

00:34:59,700 --> 00:35:07,800
the content from now how does this look

00:35:03,000 --> 00:35:11,760
in in asynchronous web app so client is

00:35:07,800 --> 00:35:13,980
sort of a implementation of flask like

00:35:11,760 --> 00:35:16,109
API but using twisted and asynchronous

00:35:13,980 --> 00:35:17,339
things so as you can see the code is

00:35:16,109 --> 00:35:19,380
very similar

00:35:17,339 --> 00:35:23,670
we have track which is like requests but

00:35:19,380 --> 00:35:25,859
twisted what credit naming and instead

00:35:23,670 --> 00:35:29,750
of just calling it we have to await it

00:35:25,859 --> 00:35:34,109
because it does some sort of networking

00:35:29,750 --> 00:35:36,450
now I'm using deff async and await there

00:35:34,109 --> 00:35:39,780
which is syntactic sugar for callbacks

00:35:36,450 --> 00:35:41,970
if we were to look at the raw third

00:35:39,780 --> 00:35:44,550
callback in way of doing it this is what

00:35:41,970 --> 00:35:46,589
would look like it's you know not much

00:35:44,550 --> 00:35:48,349
more complex here but we've larger code

00:35:46,589 --> 00:35:50,790
bases it does make a lot of sense and

00:35:48,349 --> 00:35:53,609
using callback system with like loops

00:35:50,790 --> 00:35:58,440
can be quite difficult so async to F in

00:35:53,609 --> 00:35:59,430
a way makes things quite easy now the

00:35:58,440 --> 00:36:01,589
cool part of a

00:35:59,430 --> 00:36:03,240
code in Python is that you don't end up

00:36:01,589 --> 00:36:07,200
returning something like a promise or a

00:36:03,240 --> 00:36:10,530
deferred it's usually some sort of shell

00:36:07,200 --> 00:36:12,720
that says hey in Python I kind of have

00:36:10,530 --> 00:36:15,030
to return something but the values not

00:36:12,720 --> 00:36:19,380
here yet so here's a box that will have

00:36:15,030 --> 00:36:23,160
the value at some other date now in a

00:36:19,380 --> 00:36:25,200
co-routine you when you will wait it you

00:36:23,160 --> 00:36:27,180
actually await that promise or 2/3 which

00:36:25,200 --> 00:36:31,410
will then suspend the co-routine add a

00:36:27,180 --> 00:36:33,720
callback or such onto the refer return

00:36:31,410 --> 00:36:36,690
2/3 or future and then resume it when

00:36:33,720 --> 00:36:40,859
that treats so all of that call backing

00:36:36,690 --> 00:36:44,160
sort of happens invisibly to you now

00:36:40,859 --> 00:36:47,460
can't see them here some kind of okay so

00:36:44,160 --> 00:36:49,859
this is a chart of our concurrency so on

00:36:47,460 --> 00:36:52,380
the left is requests handle per second

00:36:49,859 --> 00:36:54,270
and on the bottom is the number of

00:36:52,380 --> 00:36:56,940
concurrent requests I'm throwing it so

00:36:54,270 --> 00:37:00,599
at once so this is on my right since a

00:36:56,940 --> 00:37:02,099
600 so it's quite beefy so I don't

00:37:00,599 --> 00:37:03,660
expect to run into any problems where

00:37:02,099 --> 00:37:06,690
I'm hitting CPU lib that's quite yet so

00:37:03,660 --> 00:37:08,940
as you can see being asynchronous

00:37:06,690 --> 00:37:13,740
actually is not doing well it's actually

00:37:08,940 --> 00:37:15,450
slower and why is that the case now when

00:37:13,740 --> 00:37:17,010
we have low latency such as

00:37:15,450 --> 00:37:19,410
communicating with local host for this

00:37:17,010 --> 00:37:21,839
benchmark we block for less time and

00:37:19,410 --> 00:37:24,480
working on a local machine like this

00:37:21,839 --> 00:37:25,829
effectively has zero latency meaning

00:37:24,480 --> 00:37:27,990
that the threaded solution will not

00:37:25,829 --> 00:37:30,960
actually block much more than the

00:37:27,990 --> 00:37:32,790
asynchronous one and because there's not

00:37:30,960 --> 00:37:35,520
much walking difference between them the

00:37:32,790 --> 00:37:37,349
extra computation handling the event

00:37:35,520 --> 00:37:38,700
loop and registering you know the

00:37:37,349 --> 00:37:40,799
sockets and all that sort of thing

00:37:38,700 --> 00:37:42,329
means that we actually spend more CPU

00:37:40,799 --> 00:37:45,089
time serving each request in the federal

00:37:42,329 --> 00:37:46,740
model which bottlenecks us but what

00:37:45,089 --> 00:37:47,880
happens if we changed at zero

00:37:46,740 --> 00:37:51,599
milliseconds Lansing

00:37:47,880 --> 00:37:53,390
introduced 350 milliseconds latency well

00:37:51,599 --> 00:37:56,910
things end up being quite different I

00:37:53,390 --> 00:37:58,770
actually had to add a second grunick on

00:37:56,910 --> 00:38:01,799
there with 12 threads and 12 workers

00:37:58,770 --> 00:38:03,990
instead of just a normal four so in this

00:38:01,799 --> 00:38:06,210
case the single threaded twister

00:38:03,990 --> 00:38:09,720
application handles many many more

00:38:06,210 --> 00:38:12,540
requests per second now the reason for

00:38:09,720 --> 00:38:13,319
this is fretful exhaustion because when

00:38:12,540 --> 00:38:15,299
you're running a

00:38:13,319 --> 00:38:16,619
flasks a pink unicorn you have a limited

00:38:15,299 --> 00:38:19,859
number of threads that you can run it in

00:38:16,619 --> 00:38:21,209
and when you hit that thread limit where

00:38:19,859 --> 00:38:23,849
all of them are waiting for that lesson

00:38:21,209 --> 00:38:27,029
see you can't serve any more requests

00:38:23,849 --> 00:38:29,160
you have to wait for a thread to finish

00:38:27,029 --> 00:38:31,769
and then you can put new requests in

00:38:29,160 --> 00:38:33,029
while twisted and upper asynchronous

00:38:31,769 --> 00:38:34,799
systems don't really care and can just

00:38:33,029 --> 00:38:40,920
keep adding adding them to the event

00:38:34,799 --> 00:38:42,690
loop so you end up with doesn't show up

00:38:40,920 --> 00:38:45,809
on here so I need to remember what

00:38:42,690 --> 00:38:49,229
charts I'm looking at so the 95th

00:38:45,809 --> 00:38:51,869
percentile licensee you can see here

00:38:49,229 --> 00:38:55,079
that the licensee goes far UPS and the

00:38:51,869 --> 00:38:58,529
95th percentile is like the the worst

00:38:55,079 --> 00:39:00,539
five percent of requests is that guna

00:38:58,529 --> 00:39:01,890
corn will get really bad when you give

00:39:00,539 --> 00:39:04,739
it more requests and it starts

00:39:01,890 --> 00:39:05,670
exhausting it twisted will happen not

00:39:04,739 --> 00:39:08,069
far behind

00:39:05,670 --> 00:39:12,029
but we've twisted on pi pi which is a

00:39:08,069 --> 00:39:15,839
just-in-time into a compiler interpreter

00:39:12,029 --> 00:39:18,239
for Python which lowers the CPU load

00:39:15,839 --> 00:39:20,509
that it sort of levels out of it because

00:39:18,239 --> 00:39:24,059
at that point we're running out of CPU

00:39:20,509 --> 00:39:28,109
and that's what's causing twisted Leslie

00:39:24,059 --> 00:39:31,619
to spike so we can see the concurrency

00:39:28,109 --> 00:39:33,930
limits here with unicorn and other

00:39:31,619 --> 00:39:35,219
similar thread of systems the hard

00:39:33,930 --> 00:39:38,249
concurrency women is a number of

00:39:35,219 --> 00:39:39,930
possible threads you can run with async

00:39:38,249 --> 00:39:44,279
it's a bit different because it's your

00:39:39,930 --> 00:39:46,739
single core performance once you start

00:39:44,279 --> 00:39:48,690
having more than one second of work per

00:39:46,739 --> 00:39:51,029
second your event loop is no longer

00:39:48,690 --> 00:39:55,140
reactive and it falls behind and

00:39:51,029 --> 00:39:57,059
licensees go up so we can add more

00:39:55,140 --> 00:39:59,430
threads that always works

00:39:57,059 --> 00:40:02,400
but we can't always add more sync or

00:39:59,430 --> 00:40:06,029
performance so that sort of puts a hard

00:40:02,400 --> 00:40:07,769
limit on us and the Python gel means no

00:40:06,029 --> 00:40:09,420
apply for multi-threading so there's not

00:40:07,769 --> 00:40:11,069
really that many ways to make that

00:40:09,420 --> 00:40:13,170
better because we can't just start up a

00:40:11,069 --> 00:40:17,400
second event loop in the same thread and

00:40:13,170 --> 00:40:21,630
handle but there are methods such as

00:40:17,400 --> 00:40:23,309
shining now you are limited by your

00:40:21,630 --> 00:40:24,599
single core performance but there are

00:40:23,309 --> 00:40:27,000
tricks to make it so that you can have

00:40:24,599 --> 00:40:28,910
more processors which

00:40:27,000 --> 00:40:32,040
have their own single core performance

00:40:28,910 --> 00:40:33,810
limiting them so multiple processes

00:40:32,040 --> 00:40:35,730
accepting incoming connections on the

00:40:33,810 --> 00:40:37,920
same socket works very well so that just

00:40:35,730 --> 00:40:39,990
round robins between the multiple

00:40:37,920 --> 00:40:41,970
services arguing the requests which

00:40:39,990 --> 00:40:44,310
means that then effectively you double

00:40:41,970 --> 00:40:45,990
your performance you can do this with

00:40:44,310 --> 00:40:48,300
some linux api ins that will let you

00:40:45,990 --> 00:40:49,920
bind twice on the same socket or you can

00:40:48,300 --> 00:40:51,510
have something like a char a proxy on

00:40:49,920 --> 00:40:55,170
the front end that then directs the

00:40:51,510 --> 00:40:57,420
between multiple servers you can also

00:40:55,170 --> 00:40:59,850
have a single process doing these

00:40:57,420 --> 00:41:01,830
accepts and then delegating it to sub

00:40:59,850 --> 00:41:03,930
processes and because those sub

00:41:01,830 --> 00:41:06,450
processes are in different processes the

00:41:03,930 --> 00:41:08,250
duel doesn't affect them this works much

00:41:06,450 --> 00:41:09,720
better with not with this lengthy thing

00:41:08,250 --> 00:41:11,550
which way you do no work but say you

00:41:09,720 --> 00:41:13,680
need to do a little bit of work and you

00:41:11,550 --> 00:41:17,070
hang your cpu performance limit based on

00:41:13,680 --> 00:41:19,500
that by delegating you can level it out

00:41:17,070 --> 00:41:23,250
but at the end you're going to have a

00:41:19,500 --> 00:41:25,980
limit where you can't serve more ross

00:41:23,250 --> 00:41:27,810
TCP connections you're going to hit that

00:41:25,980 --> 00:41:28,830
limit eventually which is what we are

00:41:27,810 --> 00:41:30,990
seeing there where it was like several

00:41:28,830 --> 00:41:33,390
hundred and this is a desktop computer

00:41:30,990 --> 00:41:35,040
and we've faster servers you might be

00:41:33,390 --> 00:41:37,250
able to handle thousands of requests a

00:41:35,040 --> 00:41:40,080
second before having to run into that

00:41:37,250 --> 00:41:43,550
now these sort of things are workarounds

00:41:40,080 --> 00:41:46,410
and they don't solve every problem but

00:41:43,550 --> 00:41:48,600
they do sort of turn some synchronous

00:41:46,410 --> 00:41:51,960
problems such as processing into

00:41:48,600 --> 00:41:53,970
asynchronous problems if you have a

00:41:51,960 --> 00:41:55,620
subprocess worker pool or a distributed

00:41:53,970 --> 00:41:57,210
worker cluster those things that you

00:41:55,620 --> 00:41:59,730
might otherwise do in your application

00:41:57,210 --> 00:42:02,040
you can just put somewhere else and this

00:41:59,730 --> 00:42:05,370
works very well if you have different

00:42:02,040 --> 00:42:07,590
kinds of workloads so say your

00:42:05,370 --> 00:42:09,780
application is something it does some

00:42:07,590 --> 00:42:12,390
data forecasting and they send some JSON

00:42:09,780 --> 00:42:15,510
and you get that JSON and then you put

00:42:12,390 --> 00:42:17,760
it in the you decode it and go yep this

00:42:15,510 --> 00:42:21,170
is a valid request encoded again we

00:42:17,760 --> 00:42:24,240
don't know what on a worker send it off

00:42:21,170 --> 00:42:25,920
the characteristics of your application

00:42:24,240 --> 00:42:28,440
that you're writing and off the worker

00:42:25,920 --> 00:42:30,300
don't have to be the same your worker

00:42:28,440 --> 00:42:33,090
could be running on something like pi pi

00:42:30,300 --> 00:42:35,100
that's extremely fast and consider like

00:42:33,090 --> 00:42:37,770
a deserialize into your lies json very

00:42:35,100 --> 00:42:39,570
quickly while your workers might be

00:42:37,770 --> 00:42:40,980
running on very beefy servers with lots

00:42:39,570 --> 00:42:43,770
and lots and lots of

00:42:40,980 --> 00:42:47,130
running cpython we have numpy and C

00:42:43,770 --> 00:42:48,960
extensions and maybe GPUs so by adopting

00:42:47,130 --> 00:42:50,220
this sort of thing for any significant

00:42:48,960 --> 00:42:52,530
amount of work you need to do

00:42:50,220 --> 00:42:57,510
that's heavy processing you sort of

00:42:52,530 --> 00:42:59,070
allow yourself some level of scaling but

00:42:57,510 --> 00:43:00,990
now I have a distributed system you say

00:42:59,070 --> 00:43:02,190
I've got a worker pool and all of and

00:43:00,990 --> 00:43:04,080
that's things that you kind of have to

00:43:02,190 --> 00:43:06,840
care about and it's too bad you already

00:43:04,080 --> 00:43:09,350
have one threads are a distributed

00:43:06,840 --> 00:43:11,700
system and when we start up more threads

00:43:09,350 --> 00:43:14,400
we kind of don't realize some of the

00:43:11,700 --> 00:43:15,600
implications that that means if we're

00:43:14,400 --> 00:43:16,910
running something on the thread it's

00:43:15,600 --> 00:43:20,220
like okay we don't have to worry about

00:43:16,910 --> 00:43:21,990
the worker going away but it is there

00:43:20,220 --> 00:43:25,200
are potentials where a thread can jam

00:43:21,990 --> 00:43:27,560
where a thread can trigger an out of

00:43:25,200 --> 00:43:31,200
memory exception that sort of thing so

00:43:27,560 --> 00:43:33,270
when you run into these limits where you

00:43:31,200 --> 00:43:35,160
have you know distributed system

00:43:33,270 --> 00:43:37,140
problems with threads everything just

00:43:35,160 --> 00:43:38,640
falls down in a heap well if you do it

00:43:37,140 --> 00:43:44,070
properly you have things like retries

00:43:38,640 --> 00:43:46,740
and locks but I've been talking a lot

00:43:44,070 --> 00:43:49,800
about performance and for me that's one

00:43:46,740 --> 00:43:52,440
of the main benefits I in my day job

00:43:49,800 --> 00:43:54,000
work on making networking systems that

00:43:52,440 --> 00:43:56,430
can scale to thousands and thousands of

00:43:54,000 --> 00:44:00,420
concurrent users not everyone has this

00:43:56,430 --> 00:44:02,490
problem but it does being asynchronous

00:44:00,420 --> 00:44:04,140
does give you some benefits apart from

00:44:02,490 --> 00:44:06,900
just being able to serve more users at

00:44:04,140 --> 00:44:08,310
once now I'm gonna say something

00:44:06,900 --> 00:44:10,770
controversial and say that server-side

00:44:08,310 --> 00:44:12,120
rendering is effectively dead and if

00:44:10,770 --> 00:44:13,430
it's not it's at least half way to

00:44:12,120 --> 00:44:16,230
planning for Fodor's

00:44:13,430 --> 00:44:18,870
we instead shipping data to the client

00:44:16,230 --> 00:44:22,230
not rendered HTML if we are shipping

00:44:18,870 --> 00:44:24,660
rendered HTML that's not that much often

00:44:22,230 --> 00:44:26,280
this is over things like by like

00:44:24,660 --> 00:44:28,620
WebSockets which is bi-directional or

00:44:26,280 --> 00:44:30,750
with server sent events leveraging

00:44:28,620 --> 00:44:33,000
longer-lived connections that the

00:44:30,750 --> 00:44:35,610
synchronous request response cycle does

00:44:33,000 --> 00:44:36,780
not feel well with being asynchronous

00:44:35,610 --> 00:44:38,520
means that we can not only communicate

00:44:36,780 --> 00:44:40,530
asynchronously with the things we're

00:44:38,520 --> 00:44:43,260
getting data from the things with any

00:44:40,530 --> 00:44:44,420
data - and when you look at things like

00:44:43,260 --> 00:44:47,460
Mobile's

00:44:44,420 --> 00:44:50,100
that can be extremely important because

00:44:47,460 --> 00:44:53,710
when you have a mobile setting up one

00:44:50,100 --> 00:44:56,080
TCP connection over a 4G network takes

00:44:53,710 --> 00:44:58,330
several hundred milliseconds if your web

00:44:56,080 --> 00:45:00,250
application requires setting up a TCP

00:44:58,330 --> 00:45:02,530
connection every time you open the page

00:45:00,250 --> 00:45:04,390
to load the HTML that's going to be

00:45:02,530 --> 00:45:07,390
slower than if you had client-side

00:45:04,390 --> 00:45:09,450
rendering and a concurrent connection

00:45:07,390 --> 00:45:12,670
that just sent the data over WebSockets

00:45:09,450 --> 00:45:14,800
things like KGB to sort of hack around

00:45:12,670 --> 00:45:17,530
this by letting you send you know blobs

00:45:14,800 --> 00:45:19,870
of HTML over one connection like sending

00:45:17,530 --> 00:45:21,700
a lots of pages over one connection but

00:45:19,870 --> 00:45:24,040
there are certain situations where

00:45:21,700 --> 00:45:26,890
sending the small potentially smaller

00:45:24,040 --> 00:45:30,580
data over the wire to those clients is

00:45:26,890 --> 00:45:33,010
potentially better and we're not dealing

00:45:30,580 --> 00:45:35,410
with big data big data isn't really a

00:45:33,010 --> 00:45:39,490
thing we're dealing with lots and lots

00:45:35,410 --> 00:45:42,070
of small data very often sure when you

00:45:39,490 --> 00:45:44,620
know it's added up it becomes a big data

00:45:42,070 --> 00:45:46,120
but those problems are usually not our

00:45:44,620 --> 00:45:47,920
problems and they're usually in the

00:45:46,120 --> 00:45:50,380
domain of the data warehouses the people

00:45:47,920 --> 00:45:53,470
that care about like handling those big

00:45:50,380 --> 00:45:57,340
data that because we're handling with

00:45:53,470 --> 00:45:59,230
the small data we have to deal with

00:45:57,340 --> 00:46:01,540
being able to get it to where it becomes

00:45:59,230 --> 00:46:04,060
big data and doing things results that

00:46:01,540 --> 00:46:04,240
come out and doing that in an effective

00:46:04,060 --> 00:46:07,390
way

00:46:04,240 --> 00:46:08,800
so being asynchronous we can send lots

00:46:07,390 --> 00:46:11,440
of little bits of data to various

00:46:08,800 --> 00:46:14,820
different systems and do that without

00:46:11,440 --> 00:46:17,560
you know blocking the web request

00:46:14,820 --> 00:46:20,680
message passing systems are great and

00:46:17,560 --> 00:46:23,190
simple to scale relatively because

00:46:20,680 --> 00:46:25,690
talking to other systems such as sending

00:46:23,190 --> 00:46:28,560
signals or sending messages to other

00:46:25,690 --> 00:46:31,120
parts of your distributed system or

00:46:28,560 --> 00:46:33,340
writing to the database for example for

00:46:31,120 --> 00:46:36,490
statistics because it no longer strictly

00:46:33,340 --> 00:46:38,730
blocks the response we don't have to

00:46:36,490 --> 00:46:41,140
worry about making it technically slower

00:46:38,730 --> 00:46:43,270
this gives a lot of potential for moving

00:46:41,140 --> 00:46:45,670
things weird usually do in a request to

00:46:43,270 --> 00:46:47,320
a message queue for example to be picked

00:46:45,670 --> 00:46:49,810
up by an independently scaling system

00:46:47,320 --> 00:46:52,060
that's maybe more formal it also means

00:46:49,810 --> 00:46:54,280
that when we're doing requests we can be

00:46:52,060 --> 00:46:56,410
like oh we need to update this counter

00:46:54,280 --> 00:46:57,700
that's no longer something that strictly

00:46:56,410 --> 00:46:59,470
means that you're going to make your

00:46:57,700 --> 00:47:01,420
requests slower because you can update

00:46:59,470 --> 00:47:04,620
that counter and serve the users request

00:47:01,420 --> 00:47:04,620
at the same time

00:47:05,380 --> 00:47:15,290
so Django it's coming soon thanks to the

00:47:11,540 --> 00:47:17,390
work of a very determined individuals in

00:47:15,290 --> 00:47:19,700
this room looking at one but there are

00:47:17,390 --> 00:47:24,350
many others that are working on making

00:47:19,700 --> 00:47:25,910
this reality yay it's something that

00:47:24,350 --> 00:47:28,190
really excites me is someone that is not

00:47:25,910 --> 00:47:30,950
being a Django developer for quite a

00:47:28,190 --> 00:47:33,740
while because it means that now I can

00:47:30,950 --> 00:47:35,600
use Django for these applications that I

00:47:33,740 --> 00:47:37,670
would otherwise have to go and use

00:47:35,600 --> 00:47:40,010
twisted or a sink eye or something for

00:47:37,670 --> 00:47:41,390
and you know all of these things aren't

00:47:40,010 --> 00:47:43,160
quite in there yet but handling things

00:47:41,390 --> 00:47:45,620
like WebSockets and simultaneous

00:47:43,160 --> 00:47:47,420
database queries and highlight and see

00:47:45,620 --> 00:47:49,340
things like triggering Web books is now

00:47:47,420 --> 00:47:51,500
something that I can just be like okay

00:47:49,340 --> 00:47:52,730
I'm gonna write this in Django I'm gonna

00:47:51,500 --> 00:47:55,400
have the nice things that Django gives

00:47:52,730 --> 00:47:56,960
me I'm gonna have Django migrations I'm

00:47:55,400 --> 00:47:58,280
gonna have tango middleware I'm gonna

00:47:56,960 --> 00:48:02,090
have all this stuff that I like and not

00:47:58,280 --> 00:48:04,400
have to sacrifice for it of course

00:48:02,090 --> 00:48:06,380
this new sort of asynchronous Django is

00:48:04,400 --> 00:48:08,690
not built on whiskey although it is

00:48:06,380 --> 00:48:10,580
backwards compatible with whiskey but

00:48:08,690 --> 00:48:14,600
for the native async stuff you need to

00:48:10,580 --> 00:48:16,400
use ASCII Yuva corn or Daphne are two

00:48:14,600 --> 00:48:18,110
such servers that will serve ASCII

00:48:16,400 --> 00:48:19,490
hopefully I'm getting support in twisted

00:48:18,110 --> 00:48:23,360
soon's that you you know you can just

00:48:19,490 --> 00:48:24,980
set something up very simply and this is

00:48:23,360 --> 00:48:27,590
kind of exciting because you've a corn

00:48:24,980 --> 00:48:29,000
and Daphne are Python so we're no longer

00:48:27,590 --> 00:48:31,580
worrying about something like nginx

00:48:29,000 --> 00:48:35,450
controlling our web servers it's Python

00:48:31,580 --> 00:48:37,280
serving - serving HTTP is just Python

00:48:35,450 --> 00:48:39,680
all the way down which means that us as

00:48:37,280 --> 00:48:42,110
Python developers we now control the

00:48:39,680 --> 00:48:43,970
whole stack we get to do really neat

00:48:42,110 --> 00:48:46,250
things at the HTTP layer without going

00:48:43,970 --> 00:48:47,960
well that happens in nginx and we can't

00:48:46,250 --> 00:48:50,390
improve that we just have to wait for in

00:48:47,960 --> 00:48:52,640
the next fix well we know we want to

00:48:50,390 --> 00:48:55,940
support htv-3 cool let's get some typing

00:48:52,640 --> 00:48:58,400
develops around and make that happen it

00:48:55,940 --> 00:48:59,660
sort of gives our sort of brings the

00:48:58,400 --> 00:49:01,940
destiny for that sort of thing into our

00:48:59,660 --> 00:49:05,390
own hands instead of worrying about what

00:49:01,940 --> 00:49:07,220
everyone else is doing and when you have

00:49:05,390 --> 00:49:08,930
got a server you don't really have to

00:49:07,220 --> 00:49:10,700
just limit yourself to ASCII and nothing

00:49:08,930 --> 00:49:12,050
else because you're natively

00:49:10,700 --> 00:49:14,330
asynchronous you can run other

00:49:12,050 --> 00:49:15,890
asynchronous things inside that process

00:49:14,330 --> 00:49:19,040
and have them all kind of work well

00:49:15,890 --> 00:49:20,840
together most useful things

00:49:19,040 --> 00:49:23,450
for debugging I've ever used is twisted

00:49:20,840 --> 00:49:25,730
twisted college manhole allows you to

00:49:23,450 --> 00:49:27,530
SSH or telnet into your running Python

00:49:25,730 --> 00:49:29,240
process and get an asynchronous rifle

00:49:27,530 --> 00:49:32,300
like you're a Teenage Mutant Ninja

00:49:29,240 --> 00:49:33,590
Turtle debugging Mac hassle it's great

00:49:32,300 --> 00:49:40,550
and you shouldn't do it in production

00:49:33,590 --> 00:49:42,860
but I do sometimes you can also

00:49:40,550 --> 00:49:44,780
implement protocols like DNS and run

00:49:42,860 --> 00:49:46,700
that as a novel service inside the same

00:49:44,780 --> 00:49:48,410
process having your async Jango app

00:49:46,700 --> 00:49:51,020
serve the web interface and hosts the

00:49:48,410 --> 00:49:53,210
database now that seems so like oh cool

00:49:51,020 --> 00:49:55,940
you can do DNS but when you look at the

00:49:53,210 --> 00:49:58,790
success of something like PI hole which

00:49:55,940 --> 00:50:01,400
is ad blocker that you can run on your

00:49:58,790 --> 00:50:04,730
Raspberry Pi or other things that blocks

00:50:01,400 --> 00:50:06,770
DNS dynamically it actually kind of

00:50:04,730 --> 00:50:08,000
seems a bit more interesting because you

00:50:06,770 --> 00:50:08,800
could now do that sort of thing in

00:50:08,000 --> 00:50:11,660
Python

00:50:08,800 --> 00:50:13,010
when IOT means that you have all these

00:50:11,660 --> 00:50:16,430
little things around with all these

00:50:13,010 --> 00:50:17,840
protocols it means that being a native

00:50:16,430 --> 00:50:20,840
village a synchronous allows you to do a

00:50:17,840 --> 00:50:22,700
bit more and the sky's the limit here

00:50:20,840 --> 00:50:25,340
you're no longer constrained by water

00:50:22,700 --> 00:50:26,360
wizz gap can or can't do cuz now you can

00:50:25,340 --> 00:50:28,430
do anything that you're synchronous

00:50:26,360 --> 00:50:31,090
Python can you can do asynchronous

00:50:28,430 --> 00:50:36,110
serial to an Arduino or web to the world

00:50:31,090 --> 00:50:38,330
DNS or serving SMTP or even XMPP you

00:50:36,110 --> 00:50:41,420
don't only have to be able to talk them

00:50:38,330 --> 00:50:44,570
you can now serve them from what is your

00:50:41,420 --> 00:50:46,990
Django app and this is kind of important

00:50:44,570 --> 00:50:49,340
for Python in the sort of IOT space

00:50:46,990 --> 00:50:51,290
because when you have your Django app

00:50:49,340 --> 00:50:54,740
you might want to talk to say

00:50:51,290 --> 00:50:55,850
ZigBee and you can now sort of do that a

00:50:54,740 --> 00:50:57,410
little bit better because you're not

00:50:55,850 --> 00:50:58,550
worrying about the thread that goes away

00:50:57,410 --> 00:51:01,790
you can have your persistent

00:50:58,550 --> 00:51:04,070
communication and your app and then just

00:51:01,790 --> 00:51:07,520
have it all in one process maybe not the

00:51:04,070 --> 00:51:08,810
best solution but hey getting something

00:51:07,520 --> 00:51:12,920
working is better than something it

00:51:08,810 --> 00:51:16,970
doesn't work so what kind of progress

00:51:12,920 --> 00:51:19,100
are we at so DEP triple zero 9 has been

00:51:16,970 --> 00:51:24,290
accepted which talks about the

00:51:19,100 --> 00:51:26,300
implementation of Django async the S key

00:51:24,290 --> 00:51:30,890
support has this pheromone oil landed

00:51:26,300 --> 00:51:32,120
yep Django 3.0 will ship with async fuse

00:51:30,890 --> 00:51:37,340
and icing no

00:51:32,120 --> 00:51:40,970
No when did this change Oh God

00:51:37,340 --> 00:51:45,260
okay just ignore that Gengo

00:51:40,970 --> 00:51:51,520
three-point-something django 3.0 on my

00:51:45,260 --> 00:51:51,520
heart just use Django develop it's fine

00:51:52,420 --> 00:51:58,040
okay so ignore the numbers here I wrote

00:51:55,730 --> 00:52:00,320
this a month ago before this change so a

00:51:58,040 --> 00:52:00,650
Django will ship with a sing for you to

00:52:00,320 --> 00:52:03,440
wear

00:52:00,650 --> 00:52:06,350
hey Gengo after that point will ship

00:52:03,440 --> 00:52:08,660
with an async capable RM not an async

00:52:06,350 --> 00:52:11,240
native ORM and potentially a sink

00:52:08,660 --> 00:52:13,130
Templar you and the future is sort of

00:52:11,240 --> 00:52:15,350
upgrading the rest of the parts of can

00:52:13,130 --> 00:52:17,000
go to sporting like asynchronously

00:52:15,350 --> 00:52:19,010
sending emails so it doesn't block your

00:52:17,000 --> 00:52:21,650
requests and having a natively

00:52:19,010 --> 00:52:22,970
asynchronous ORM that interacts in that

00:52:21,650 --> 00:52:24,020
event loop natively you rather than

00:52:22,970 --> 00:52:28,670
putting it in a furball

00:52:24,020 --> 00:52:31,010
I want it now if you want now with

00:52:28,670 --> 00:52:37,760
Django you maybe can just go Sandra I'm

00:52:31,010 --> 00:52:40,460
going hey okay honey async for me I want

00:52:37,760 --> 00:52:42,800
spacing and then you know which I'm sure

00:52:40,460 --> 00:52:43,880
will be happening at the sprints yes so

00:52:42,800 --> 00:52:44,990
at the sprints if you would like to get

00:52:43,880 --> 00:52:48,610
a taste of it in Django

00:52:44,990 --> 00:52:53,990
going away Andrew and help him love God

00:52:48,610 --> 00:52:55,190
love of God burn so but if you want it

00:52:53,990 --> 00:52:57,050
now and you want to play with

00:52:55,190 --> 00:52:59,270
asynchronous systems there's a couple of

00:52:57,050 --> 00:53:02,840
options so twisted is the one that I'm

00:52:59,270 --> 00:53:05,990
biased towards obviously so there's

00:53:02,840 --> 00:53:07,730
client which is works too based API and

00:53:05,990 --> 00:53:09,350
twist it as track which is a request

00:53:07,730 --> 00:53:12,310
space API and takes photographs which

00:53:09,350 --> 00:53:14,930
gives you natively a single post gross

00:53:12,310 --> 00:53:17,450
for a sink a oh there's library slang a

00:53:14,930 --> 00:53:20,710
HTTP in a sink PG they let you do

00:53:17,450 --> 00:53:24,290
Postgres trio which is very interesting

00:53:20,710 --> 00:53:26,540
has H Levin which is a HP 1.1

00:53:24,290 --> 00:53:28,580
implementation and Sri o PG which is

00:53:26,540 --> 00:53:30,320
async Postgres and is something to

00:53:28,580 --> 00:53:32,480
perhaps look into and play around with

00:53:30,320 --> 00:53:35,890
just to sort of see what's possible even

00:53:32,480 --> 00:53:39,970
if you don't you know username anger and

00:53:35,890 --> 00:53:42,410
at this website this website my web ring

00:53:39,970 --> 00:53:45,020
I've got some links to all of this

00:53:42,410 --> 00:53:45,680
various thing various parts of things

00:53:45,020 --> 00:53:48,230
for you

00:53:45,680 --> 00:53:50,510
to look at such as depth zero zero zero

00:53:48,230 --> 00:53:53,000
nine and various announcements as well

00:53:50,510 --> 00:53:55,640
as background posts from me and glyphs

00:53:53,000 --> 00:53:59,510
and others about asynchronous systems in

00:53:55,640 --> 00:54:02,000
general now it's been lovely being here

00:53:59,510 --> 00:54:06,349
and I'm loving you know being in States

00:54:02,000 --> 00:54:08,059
again sort of as much as I can and this

00:54:06,349 --> 00:54:09,800
is my first django con and it's been

00:54:08,059 --> 00:54:12,710
wonderful and thank you all for having

00:54:09,800 --> 00:54:14,510
me and I hope you all have a wonderful

00:54:12,710 --> 00:54:15,800
day and that you all go see Andrews talk

00:54:14,510 --> 00:54:18,460
where you see about how this is

00:54:15,800 --> 00:54:20,530
happening in Django in reality and

00:54:18,460 --> 00:54:25,010
that's all thank you very much

00:54:20,530 --> 00:54:38,310
[Applause]

00:54:25,010 --> 00:54:38,310

YouTube URL: https://www.youtube.com/watch?v=YxP1I-tm_2c


