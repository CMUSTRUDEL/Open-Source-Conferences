Title: DjangoCon 2019 -Forklifting Django: Migrating A Complex Django App To Kubernetes by Noah Kantrowitz
Publication date: 2019-10-25
Playlist: DjangoCon US 2019
Description: 
	DjangoCon 2019 -Forklifting Django: Migrating A Complex Django App To Kubernetes by Noah Kantrowitz

Everyone is talking about Kubernetes, but migrating existing applications is often easier said than done. This talk will cover the tale of migrating our main Django application to Kubernetes, and all the problems and solutions we ran into along the way.

This talk was presented at: https://2019.djangocon.us/talks/forklifting-django-migrating-a-complex/

LINKS:
Follow Noah Kantrowitz ğŸ‘‡
On Twitter: https://twitter.com/kantrn
Official homepage: https://coderanger.net/

Follow DjangCon US ğŸ‘‡
https://twitter.com/djangocon

Follow DEFNA ğŸ‘‡
https://twitter.com/defnado
https://www.defna.org/

Intro music: "This Is How We Quirk It" by Avocado Junkie.
Video production by Confreaks TV.
Captions by White Coat Captioning.
Captions: 
	00:00:00,000 --> 00:00:20,109
[Music]

00:00:54,970 --> 00:01:04,250
my life now awesome alright so with the

00:01:01,460 --> 00:01:06,170
rise of new tools came new challenges so

00:01:04,250 --> 00:01:07,940
let's set the stage my main application

00:01:06,170 --> 00:01:09,830
is a fairly standard Django monolith

00:01:07,940 --> 00:01:11,479
we're still on Python 2 but that's not

00:01:09,830 --> 00:01:13,130
really relevant for deployment

00:01:11,479 --> 00:01:15,649
we've got celery for background tasks

00:01:13,130 --> 00:01:17,329
channels for WebSockets we're using

00:01:15,649 --> 00:01:20,240
Postgres for the sequel database and we

00:01:17,329 --> 00:01:21,799
use Redis and RabbitMQ additionally one

00:01:20,240 --> 00:01:23,450
sort of complicating thing is that my

00:01:21,799 --> 00:01:24,890
main application is single tenant that

00:01:23,450 --> 00:01:27,320
means we deploy one instance per

00:01:24,890 --> 00:01:28,460
customer mostly this just means that we

00:01:27,320 --> 00:01:30,170
have all the same problems as everyone

00:01:28,460 --> 00:01:31,850
else but much more so because we have to

00:01:30,170 --> 00:01:33,320
deploy a lot more environment so whereas

00:01:31,850 --> 00:01:35,000
most people would have you know a couple

00:01:33,320 --> 00:01:36,859
of dev environment environments one

00:01:35,000 --> 00:01:41,359
staging one prod we have a dozen or two

00:01:36,859 --> 00:01:43,039
prods so this leads into what our old

00:01:41,359 --> 00:01:45,740
deployment system looked like there were

00:01:43,039 --> 00:01:47,960
two main pieces terraform for setting up

00:01:45,740 --> 00:01:49,280
all the stuff on AWS and then ansible

00:01:47,960 --> 00:01:50,630
for configuring the systems and

00:01:49,280 --> 00:01:51,829
deploying the actual application code

00:01:50,630 --> 00:01:52,909
along with some Python scripts for

00:01:51,829 --> 00:01:55,789
things that didn't fit into either of

00:01:52,909 --> 00:01:57,380
those this was a good system secrets

00:01:55,789 --> 00:01:59,840
lived in ansible vault access controls

00:01:57,380 --> 00:02:01,579
managed via SSH key distribution pretty

00:01:59,840 --> 00:02:03,289
solid all around but there were some

00:02:01,579 --> 00:02:05,719
downsides setting up a new instance took

00:02:03,289 --> 00:02:06,979
an hour to of work over all running a

00:02:05,719 --> 00:02:07,850
whole bunch of terraform stuff making

00:02:06,979 --> 00:02:09,740
sure that everything was all up-to-date

00:02:07,850 --> 00:02:11,720
dealing with bugs and equipments last

00:02:09,740 --> 00:02:14,030
time we did it and that hour had to be

00:02:11,720 --> 00:02:15,440
someone on my team similarly scaling up

00:02:14,030 --> 00:02:17,510
and down if we need to boot a new web

00:02:15,440 --> 00:02:18,920
server that took a little while and we

00:02:17,510 --> 00:02:21,980
really couldn't even think about doing

00:02:18,920 --> 00:02:23,239
auto scaling so good but not great we

00:02:21,980 --> 00:02:25,370
also have much of micro services but I'm

00:02:23,239 --> 00:02:27,440
not going to talk about those

00:02:25,370 --> 00:02:28,400
so we had some constraints for what we

00:02:27,440 --> 00:02:29,330
wanted to build as part of the new

00:02:28,400 --> 00:02:30,770
system we knew we wanted to use

00:02:29,330 --> 00:02:32,030
kubernetes we'd already been using it

00:02:30,770 --> 00:02:33,530
for some other projects and it's my

00:02:32,030 --> 00:02:34,100
weapon of choice for container wrangling

00:02:33,530 --> 00:02:36,350
overall

00:02:34,100 --> 00:02:38,180
additionally we wanted to keep using RDS

00:02:36,350 --> 00:02:39,350
and cloud AMQP for databases I'm

00:02:38,180 --> 00:02:40,880
probably more in favor of running

00:02:39,350 --> 00:02:41,930
databases on kubernetes than most people

00:02:40,880 --> 00:02:43,130
but I do have a very small

00:02:41,930 --> 00:02:45,140
infrastructure team and so I'll

00:02:43,130 --> 00:02:47,030
basically always trade money for not

00:02:45,140 --> 00:02:47,900
having to worry about databases also

00:02:47,030 --> 00:02:49,250
that would make the production

00:02:47,900 --> 00:02:51,860
migrations easier cuz we don't have to

00:02:49,250 --> 00:02:53,870
move any data around what we mean by a

00:02:51,860 --> 00:02:56,360
forklift migration this means I can make

00:02:53,870 --> 00:02:58,070
changes the application but not like a

00:02:56,360 --> 00:03:00,320
green fields rewrite everything and go

00:02:58,070 --> 00:03:02,030
and make everything glorious we had an

00:03:00,320 --> 00:03:03,860
application we wanted to pick up the

00:03:02,030 --> 00:03:06,100
entire application basically the way it

00:03:03,860 --> 00:03:08,150
was and just drop it into kubernetes

00:03:06,100 --> 00:03:10,220
before I start talking specifics about

00:03:08,150 --> 00:03:12,170
my application let's define some jargon

00:03:10,220 --> 00:03:13,940
people that haven't heard it before two

00:03:12,170 --> 00:03:15,830
generic terms a container is a cool way

00:03:13,940 --> 00:03:18,230
to run a process and an image the larval

00:03:15,830 --> 00:03:19,370
form of a container kubernetes and many

00:03:18,230 --> 00:03:21,110
things to many people but for the

00:03:19,370 --> 00:03:22,850
purposes of this talk kubernetes is an

00:03:21,110 --> 00:03:25,459
API for making containers jump through

00:03:22,850 --> 00:03:27,050
hoops to do useful work and pod is a

00:03:25,459 --> 00:03:28,040
container specific term that every time

00:03:27,050 --> 00:03:29,620
you hear it you can basically just

00:03:28,040 --> 00:03:32,030
pretend that I said the word container

00:03:29,620 --> 00:03:33,620
so all that laid out I was ready to roll

00:03:32,030 --> 00:03:35,540
up my sleeves and jump into porting my

00:03:33,620 --> 00:03:37,430
application to Boober netis first

00:03:35,540 --> 00:03:39,380
definite an erisa any application is to

00:03:37,430 --> 00:03:41,209
make a container age multi-stage builds

00:03:39,380 --> 00:03:43,160
are super useful for Python applications

00:03:41,209 --> 00:03:45,079
because Python apps usually have much

00:03:43,160 --> 00:03:48,410
bigger build time dependencies than

00:03:45,079 --> 00:03:49,430
runtime dependencies one thing to note

00:03:48,410 --> 00:03:50,660
here is the fact that I'm not using a

00:03:49,430 --> 00:03:52,250
virtual end some people will disagree

00:03:50,660 --> 00:03:53,360
with me but I don't really see the point

00:03:52,250 --> 00:03:54,620
in using a virtual end when it's a

00:03:53,360 --> 00:03:57,070
single purpose container in the first

00:03:54,620 --> 00:03:59,390
place but so here's our build image and

00:03:57,070 --> 00:04:01,280
then our run image so we ran the build

00:03:59,390 --> 00:04:03,110
phase first and then we copy over just

00:04:01,280 --> 00:04:05,329
the files we need into a much smaller

00:04:03,110 --> 00:04:06,829
run image along with setting up non-root

00:04:05,329 --> 00:04:07,760
user for the application to run as and

00:04:06,829 --> 00:04:11,239
anything else that sort of runtime

00:04:07,760 --> 00:04:12,799
specific my first attempt to get things

00:04:11,239 --> 00:04:15,140
set up in kubernetes was very very

00:04:12,799 --> 00:04:17,030
simple just static kubernetes manifest

00:04:15,140 --> 00:04:19,220
yeah Mille no automation beyond coop

00:04:17,030 --> 00:04:21,320
cuddle apply fitting an entire community

00:04:19,220 --> 00:04:22,850
ml file on screen is really not going to

00:04:21,320 --> 00:04:25,310
work so here's just sort of the core of

00:04:22,850 --> 00:04:27,770
it but it gives you a general idea

00:04:25,310 --> 00:04:29,210
start up the container mount up a

00:04:27,770 --> 00:04:30,830
configuration file we put all our

00:04:29,210 --> 00:04:33,830
configs in yamo him and read them in the

00:04:30,830 --> 00:04:35,960
settings top I run some migrations and

00:04:33,830 --> 00:04:36,830
then launch - unicorn pretty simple like

00:04:35,960 --> 00:04:37,490
these are all the steps that you'll

00:04:36,830 --> 00:04:39,199
probably have

00:04:37,490 --> 00:04:42,500
a million times just done inside

00:04:39,199 --> 00:04:44,330
kubernetes a quick improvement from

00:04:42,500 --> 00:04:45,770
there was to move the migrations from

00:04:44,330 --> 00:04:47,030
being run just sort of as part of the

00:04:45,770 --> 00:04:48,770
main container into a thing called an

00:04:47,030 --> 00:04:52,310
init container which only runs the first

00:04:48,770 --> 00:04:54,500
time a pod is launched and for bonus

00:04:52,310 --> 00:04:55,729
points this sort of shows a very easy

00:04:54,500 --> 00:04:57,970
way to do some dynamic configuration

00:04:55,729 --> 00:05:00,050
injection again using init containers

00:04:57,970 --> 00:05:01,580
but they still had a lot of issues of

00:05:00,050 --> 00:05:03,949
ordering init containers run every time

00:05:01,580 --> 00:05:05,449
a pod starts including every time you

00:05:03,949 --> 00:05:06,919
launch another replica of the pods if we

00:05:05,449 --> 00:05:09,050
wanted for web servers it would try to

00:05:06,919 --> 00:05:10,039
run the migrations four times which

00:05:09,050 --> 00:05:12,319
isn't really what we want

00:05:10,039 --> 00:05:14,000
Jenga migrations are generally safe to

00:05:12,319 --> 00:05:15,380
run more than once but you can get some

00:05:14,000 --> 00:05:17,750
weird locking issues and things like

00:05:15,380 --> 00:05:19,370
that it was just not a good scene we

00:05:17,750 --> 00:05:20,569
also had issues where like because we

00:05:19,370 --> 00:05:22,220
weren't running the migrations first

00:05:20,569 --> 00:05:23,509
when we were upgrading celery D it would

00:05:22,220 --> 00:05:24,740
roll out the new code before the

00:05:23,509 --> 00:05:27,500
migrations to finish and everything

00:05:24,740 --> 00:05:28,880
would get really confused so good start

00:05:27,500 --> 00:05:30,770
this proved that we could run our

00:05:28,880 --> 00:05:32,389
application under kubernetes but we

00:05:30,770 --> 00:05:35,210
clearly needed a more organized

00:05:32,389 --> 00:05:36,289
deployment system underneath it a few

00:05:35,210 --> 00:05:38,000
things I glossed over too so we're

00:05:36,289 --> 00:05:39,470
keeping track of them the other three

00:05:38,000 --> 00:05:40,639
main daemons work exactly like the

00:05:39,470 --> 00:05:42,080
jewnicorn pods they just run at

00:05:40,639 --> 00:05:43,490
different commands that of jewnicorn

00:05:42,080 --> 00:05:47,360
it's running celery to your daphne or

00:05:43,490 --> 00:05:48,979
the channel worker thing we build all of

00:05:47,360 --> 00:05:50,719
the daemons into the same container

00:05:48,979 --> 00:05:52,250
image as opposed to building separate

00:05:50,719 --> 00:05:54,949
images for each one this was mostly

00:05:52,250 --> 00:05:55,969
because the shared dependencies are so

00:05:54,949 --> 00:05:57,680
much bigger than anything that's

00:05:55,969 --> 00:05:59,599
specific to web or celery to your

00:05:57,680 --> 00:06:00,680
channels that it made release management

00:05:59,599 --> 00:06:02,630
a lot easier to have one release

00:06:00,680 --> 00:06:04,430
artifact instead of four

00:06:02,630 --> 00:06:06,380
I'm also ignoring celery beet for right

00:06:04,430 --> 00:06:07,940
now we will get to it later my

00:06:06,380 --> 00:06:09,919
application is mostly an API that's used

00:06:07,940 --> 00:06:11,120
by mobile applications so we do have web

00:06:09,919 --> 00:06:12,409
interfaces in it but they're mostly

00:06:11,120 --> 00:06:14,330
either used rarely used by

00:06:12,409 --> 00:06:16,009
administrative staff so I decided to

00:06:14,330 --> 00:06:17,990
keep things simple and try to avoid

00:06:16,009 --> 00:06:19,639
using s3 for the static files for things

00:06:17,990 --> 00:06:21,860
that are dynamic like you know user

00:06:19,639 --> 00:06:23,300
uploaded media files that still has to

00:06:21,860 --> 00:06:25,370
go on s3 because you need a shared

00:06:23,300 --> 00:06:27,319
system of some kind but for the like

00:06:25,370 --> 00:06:28,699
actual static files we build that into

00:06:27,319 --> 00:06:30,380
the image and we serve it using a

00:06:28,699 --> 00:06:32,270
cut-down version of the Cadi web server

00:06:30,380 --> 00:06:33,500
so that just means that we don't have to

00:06:32,270 --> 00:06:36,650
separately deal with versioning the

00:06:33,500 --> 00:06:39,169
static assets and the deployed image and

00:06:36,650 --> 00:06:40,940
for the initial phase I was going to

00:06:39,169 --> 00:06:42,500
sort of start with RDS because we notice

00:06:40,940 --> 00:06:44,389
what we wanted to use in the end but

00:06:42,500 --> 00:06:46,460
launching and destroying RDS cluster

00:06:44,389 --> 00:06:47,779
takes about 30 minutes and that was

00:06:46,460 --> 00:06:49,460
getting really annoying for rapid

00:06:47,779 --> 00:06:50,750
development so we did most of the

00:06:49,460 --> 00:06:54,320
initial phases of prototyping using

00:06:50,750 --> 00:06:55,730
Salon des Postgres operator so by this

00:06:54,320 --> 00:06:56,960
point I had a working proof of concept I

00:06:55,730 --> 00:06:58,550
could deploy my entire stack on

00:06:56,960 --> 00:06:59,990
kubernetes and use the application the

00:06:58,550 --> 00:07:01,700
application itself worked like normal

00:06:59,990 --> 00:07:02,900
but deploying it was still not really

00:07:01,700 --> 00:07:06,020
great we needed something that's more

00:07:02,900 --> 00:07:07,310
repeatable and reliable so next tool the

00:07:06,020 --> 00:07:08,600
standard kubernetes quiver is a thing

00:07:07,310 --> 00:07:09,920
called helm it calls itself the

00:07:08,600 --> 00:07:11,630
kubernetes package manager

00:07:09,920 --> 00:07:13,430
there's overall fairly similar what we

00:07:11,630 --> 00:07:15,110
had before the idea is you just take the

00:07:13,430 --> 00:07:16,970
existing static manifest you dump them

00:07:15,110 --> 00:07:18,470
into a helm chart and then you can

00:07:16,970 --> 00:07:20,420
install that chart as many times as you

00:07:18,470 --> 00:07:21,290
need with different inputs I'm not gonna

00:07:20,420 --> 00:07:22,610
go over the chart itself because

00:07:21,290 --> 00:07:24,590
basically same thing we saw before just

00:07:22,610 --> 00:07:26,120
more curly braces but overall helm did

00:07:24,590 --> 00:07:27,620
improve some things made deploying

00:07:26,120 --> 00:07:29,810
multiple environments way easier we

00:07:27,620 --> 00:07:31,370
could store just the values that have to

00:07:29,810 --> 00:07:33,410
vary between the environments and yamo

00:07:31,370 --> 00:07:33,740
files and feed them into helm that part

00:07:33,410 --> 00:07:35,960
was great

00:07:33,740 --> 00:07:37,310
it's also widely supported by basically

00:07:35,960 --> 00:07:39,350
everything the kubernetes ecosystem

00:07:37,310 --> 00:07:40,550
because it's such a standard tool and we

00:07:39,350 --> 00:07:43,010
had some operational experience with

00:07:40,550 --> 00:07:45,200
helm from other projects but it also

00:07:43,010 --> 00:07:46,820
brought some problems it basically

00:07:45,200 --> 00:07:48,440
doesn't help us with the ordering and

00:07:46,820 --> 00:07:50,270
sequencing issues we had with migrations

00:07:48,440 --> 00:07:52,040
and things running out of order it does

00:07:50,270 --> 00:07:54,230
have a thing called hooks they let you

00:07:52,040 --> 00:07:56,030
kind of do what you would think like

00:07:54,230 --> 00:07:58,310
before I deploy please run the

00:07:56,030 --> 00:08:00,050
migrations but we ran into no end of

00:07:58,310 --> 00:08:01,970
problems with it error handling wasn't

00:08:00,050 --> 00:08:03,080
great debugging wasn't great and in the

00:08:01,970 --> 00:08:05,060
end we just decided that it was too

00:08:03,080 --> 00:08:06,979
complex to work with for that function

00:08:05,060 --> 00:08:09,020
there's also some major gaps in the helm

00:08:06,979 --> 00:08:11,540
ecosystem unit integration testing of

00:08:09,020 --> 00:08:12,979
helm charts is basically impossible and

00:08:11,540 --> 00:08:16,280
secrets management exists but is

00:08:12,979 --> 00:08:17,960
basically delegated to plugins and then

00:08:16,280 --> 00:08:19,610
the big problem with helm tiller I'm not

00:08:17,960 --> 00:08:21,860
gonna talk a ton about this because they

00:08:19,610 --> 00:08:23,270
have already released a beta of helm 3

00:08:21,860 --> 00:08:24,760
which removes tiller but the rough

00:08:23,270 --> 00:08:28,130
version is it's a security nightmare

00:08:24,760 --> 00:08:30,140
it's a single point that all requests

00:08:28,130 --> 00:08:31,640
have to go through and everyone gets

00:08:30,140 --> 00:08:33,440
access to whatever permissions tiller

00:08:31,640 --> 00:08:35,539
itself runs with which is usually the

00:08:33,440 --> 00:08:38,240
cluster give me all permissions admin

00:08:35,539 --> 00:08:40,310
role they are removing this so it's

00:08:38,240 --> 00:08:41,960
going to get better but it's not there

00:08:40,310 --> 00:08:43,099
yet and all of the workarounds for not

00:08:41,960 --> 00:08:46,430
running with tiller have various

00:08:43,099 --> 00:08:48,650
downsides that we didn't love ok helm

00:08:46,430 --> 00:08:50,150
worked we could use it but it wasn't

00:08:48,650 --> 00:08:51,470
quite as smooth as we wanted it to be we

00:08:50,150 --> 00:08:52,760
had a lot of problems with what happens

00:08:51,470 --> 00:08:54,790
if there's an error during deployment

00:08:52,760 --> 00:08:56,600
how do we deal with that and it made

00:08:54,790 --> 00:08:57,770
self-service fairly tricky to set up

00:08:56,600 --> 00:09:00,320
because of the permissions issues I

00:08:57,770 --> 00:09:01,880
mentioned with tiller and so with that

00:09:00,320 --> 00:09:04,020
we have our current and hopefully final

00:09:01,880 --> 00:09:05,460
approach a kubernetes operator

00:09:04,020 --> 00:09:07,380
this would be the bulk of the rest of

00:09:05,460 --> 00:09:09,150
the talk kourounis operators tied

00:09:07,380 --> 00:09:10,770
together three main concepts CR DS

00:09:09,150 --> 00:09:13,830
watches and controllers let's go over

00:09:10,770 --> 00:09:15,600
each of those CRT or custom resource

00:09:13,830 --> 00:09:17,670
definition is a way to add new object

00:09:15,600 --> 00:09:19,740
types into kubernetes just like pods and

00:09:17,670 --> 00:09:21,210
services existing kubernetes we can make

00:09:19,740 --> 00:09:22,290
our own in this case we call some

00:09:21,210 --> 00:09:25,110
platform because that's the name of my

00:09:22,290 --> 00:09:26,820
Jango monolith let's add a new object

00:09:25,110 --> 00:09:28,230
type and we can add whatever fields and

00:09:26,820 --> 00:09:31,800
parameters we want on that just like any

00:09:28,230 --> 00:09:33,480
other object in the queue Brandis API in

00:09:31,800 --> 00:09:34,980
this case you can see we have a version

00:09:33,480 --> 00:09:36,330
field which takes a string of what

00:09:34,980 --> 00:09:38,610
version we want to deploy and we have a

00:09:36,330 --> 00:09:39,840
config thing that takes a dict of some

00:09:38,610 --> 00:09:42,990
Django settings in this case just

00:09:39,840 --> 00:09:44,640
turning debug true this is a bit more

00:09:42,990 --> 00:09:46,320
verbose than a helm values file for

00:09:44,640 --> 00:09:47,640
anyone that's worked with those but it

00:09:46,320 --> 00:09:49,500
does allow for some nice things like you

00:09:47,640 --> 00:09:50,910
can have type validation on your

00:09:49,500 --> 00:09:52,920
variables which is the thing that helmet

00:09:50,910 --> 00:09:54,390
self does not natively support and you

00:09:52,920 --> 00:09:55,740
can use tools like coop cuddle apply

00:09:54,390 --> 00:09:57,090
with this directly as opposed to having

00:09:55,740 --> 00:10:00,930
to go through multiple intermediary

00:09:57,090 --> 00:10:02,400
tools so the CRT gives us place to put

00:10:00,930 --> 00:10:03,900
all of our configuration it holds the

00:10:02,400 --> 00:10:05,220
data for what we want to deploy what we

00:10:03,900 --> 00:10:06,390
want our configuration to be all that

00:10:05,220 --> 00:10:08,130
kind of stuff but now we need to

00:10:06,390 --> 00:10:09,780
actually do something with it and the

00:10:08,130 --> 00:10:12,150
driver for those our thing called an API

00:10:09,780 --> 00:10:14,130
watch basically like push notifications

00:10:12,150 --> 00:10:16,050
for the kubernetes api whenever an

00:10:14,130 --> 00:10:17,910
instance of my custom objects changes or

00:10:16,050 --> 00:10:19,740
is created or is deleted I want to get a

00:10:17,910 --> 00:10:22,290
notification in my code so that I can do

00:10:19,740 --> 00:10:24,300
something with that new data or lack of

00:10:22,290 --> 00:10:26,730
data if it's a delete the heart of an

00:10:24,300 --> 00:10:28,800
operator is a controller each controller

00:10:26,730 --> 00:10:30,960
sets up some API watches waits for a

00:10:28,800 --> 00:10:31,980
change and then does its best to make

00:10:30,960 --> 00:10:33,990
sure that the state of the world

00:10:31,980 --> 00:10:36,240
reflects the new config repeat

00:10:33,990 --> 00:10:38,550
indefinitely that's what an operator or

00:10:36,240 --> 00:10:40,680
what a controller is sort of deep down

00:10:38,550 --> 00:10:41,910
in the heart of an operator before we

00:10:40,680 --> 00:10:43,980
dive into talk more of the specifics of

00:10:41,910 --> 00:10:45,720
our Jango controller let's pull back a

00:10:43,980 --> 00:10:47,520
bit and talk about building convergent

00:10:45,720 --> 00:10:48,600
systems and before we do that let's pull

00:10:47,520 --> 00:10:50,880
even further back and talk about the

00:10:48,600 --> 00:10:53,220
opposite which is procedural systems a

00:10:50,880 --> 00:10:54,690
procedural system is built by giving the

00:10:53,220 --> 00:10:55,920
system all of the steps that you want to

00:10:54,690 --> 00:10:59,640
run in the order you want to run them

00:10:55,920 --> 00:11:01,560
like say a bash script that is the steps

00:10:59,640 --> 00:11:03,210
that you want the code to take in the

00:11:01,560 --> 00:11:05,970
order you want it to take them real

00:11:03,210 --> 00:11:07,890
simple easy to write as opposed to a

00:11:05,970 --> 00:11:09,390
convergent system where we don't tell it

00:11:07,890 --> 00:11:11,070
what steps we want to take we just say

00:11:09,390 --> 00:11:13,610
this is the state that I want the system

00:11:11,070 --> 00:11:15,810
to be in when you are done figure it out

00:11:13,610 --> 00:11:17,310
so if you've worked with ansible for

00:11:15,810 --> 00:11:17,550
instance it is a convergent system you

00:11:17,310 --> 00:11:18,779
don't

00:11:17,550 --> 00:11:20,760
tell it what steps you wanted to take

00:11:18,779 --> 00:11:22,529
you say this is what state I want the

00:11:20,760 --> 00:11:23,940
system to be in when you are done and it

00:11:22,529 --> 00:11:24,410
figures out what it has to do to get

00:11:23,940 --> 00:11:26,430
there

00:11:24,410 --> 00:11:27,330
very briefly two other important

00:11:26,430 --> 00:11:30,420
concepts that I'll be mentioning

00:11:27,330 --> 00:11:32,310
throughout this idempotence or a system

00:11:30,420 --> 00:11:34,470
being idempotent means that it take it

00:11:32,310 --> 00:11:36,089
only takes action when it needs to to

00:11:34,470 --> 00:11:37,680
correct the state of the system so going

00:11:36,089 --> 00:11:39,060
back to the ansible example if you tell

00:11:37,680 --> 00:11:40,529
it you want a package installed and the

00:11:39,060 --> 00:11:42,300
package is already installed it doesn't

00:11:40,529 --> 00:11:45,750
try to install it again that's all it

00:11:42,300 --> 00:11:47,670
means long word simple promise theory is

00:11:45,750 --> 00:11:49,260
a mathematical framework for designing

00:11:47,670 --> 00:11:51,000
convergent systems by breaking them down

00:11:49,260 --> 00:11:53,160
into smaller subsystems that adhere to a

00:11:51,000 --> 00:11:54,690
specific contract of you give me this

00:11:53,160 --> 00:11:55,910
data and I will try to make the state

00:11:54,690 --> 00:11:57,870
like that

00:11:55,910 --> 00:11:59,370
promise theory systems can work at

00:11:57,870 --> 00:12:01,529
several levels so we can start with

00:11:59,370 --> 00:12:03,300
small promise Theory actors and compose

00:12:01,529 --> 00:12:05,279
those into bigger actors and compose

00:12:03,300 --> 00:12:06,930
those into bigger actors in practical

00:12:05,279 --> 00:12:08,610
terms this means taking the thing that

00:12:06,930 --> 00:12:10,470
you want to do and in our case deploying

00:12:08,610 --> 00:12:12,600
a django app and trying to break it down

00:12:10,470 --> 00:12:13,920
into multiple smaller convergent bits

00:12:12,600 --> 00:12:16,140
that can each be built and tested

00:12:13,920 --> 00:12:18,029
independently which helps to reduce the

00:12:16,140 --> 00:12:19,320
surface area of your actors and keeps

00:12:18,029 --> 00:12:22,350
the code a lot more manageable so we

00:12:19,320 --> 00:12:24,300
don't write a single giant function that

00:12:22,350 --> 00:12:26,700
does everything instead we write a small

00:12:24,300 --> 00:12:28,050
object that creates a rabid mqv host and

00:12:26,700 --> 00:12:30,329
a small object that creates an s3 bucket

00:12:28,050 --> 00:12:32,579
and then we use those in building our

00:12:30,329 --> 00:12:33,600
deployment just like again I keep

00:12:32,579 --> 00:12:36,300
harping on ansible because the thing

00:12:33,600 --> 00:12:38,490
most people here have most here people

00:12:36,300 --> 00:12:40,050
have most likely used when you're

00:12:38,490 --> 00:12:43,620
writing a role you can compose that out

00:12:40,050 --> 00:12:45,360
of other roles why does all of this

00:12:43,620 --> 00:12:46,950
design in theory matter because part of

00:12:45,360 --> 00:12:48,630
being successful with kubernetes or any

00:12:46,950 --> 00:12:50,880
convergent system is to rotate your

00:12:48,630 --> 00:12:51,990
thinking from procedural to convergent

00:12:50,880 --> 00:12:53,399
you might have noticed that my brief

00:12:51,990 --> 00:12:54,720
description of promise Theory lines up

00:12:53,399 --> 00:12:56,220
very well with also how I briefly

00:12:54,720 --> 00:12:59,250
described kubernetes controllers and

00:12:56,220 --> 00:13:01,380
that's no accident kubernetes uses these

00:12:59,250 --> 00:13:03,240
patterns because over the last decade or

00:13:01,380 --> 00:13:05,160
two we figured out that when you're

00:13:03,240 --> 00:13:06,630
managing big complex distributed systems

00:13:05,160 --> 00:13:08,190
it is far better to work with a

00:13:06,630 --> 00:13:10,140
convergent system than a procedural one

00:13:08,190 --> 00:13:11,310
the real problem deep down and we'll

00:13:10,140 --> 00:13:13,470
talk more about this a little bit is

00:13:11,310 --> 00:13:14,970
state drift failures happen like there's

00:13:13,470 --> 00:13:17,370
going to be errors during deployment and

00:13:14,970 --> 00:13:18,750
after that error occurs you don't really

00:13:17,370 --> 00:13:20,160
know what state your system is in you

00:13:18,750 --> 00:13:21,720
could go and find out and try and

00:13:20,160 --> 00:13:23,790
correct it but that's very time

00:13:21,720 --> 00:13:26,100
consuming and if you got say just like a

00:13:23,790 --> 00:13:27,720
big bash deployment script with like our

00:13:26,100 --> 00:13:28,560
sink and all that stuff a lot of people

00:13:27,720 --> 00:13:31,190
have written those I've definitely

00:13:28,560 --> 00:13:33,620
written those but unless you account

00:13:31,190 --> 00:13:35,360
for every possible starting state if the

00:13:33,620 --> 00:13:36,650
system is in an error state of some kind

00:13:35,360 --> 00:13:39,320
and it's in some weird configuration

00:13:36,650 --> 00:13:40,730
your script may just break randomly like

00:13:39,320 --> 00:13:42,980
you're trying to are sink in the

00:13:40,730 --> 00:13:44,300
destination folder doesn't exist what's

00:13:42,980 --> 00:13:45,860
it gonna do it doesn't know how to deal

00:13:44,300 --> 00:13:47,060
with that but if you are building a

00:13:45,860 --> 00:13:49,610
converter system and you just tell it

00:13:47,060 --> 00:13:52,100
that folder must exist no matter what

00:13:49,610 --> 00:13:53,300
errors kind of go on it'll make it right

00:13:52,100 --> 00:13:54,220
and it'll eventually get you to the goal

00:13:53,300 --> 00:13:56,630
State

00:13:54,220 --> 00:13:58,190
so controllers can be used for all kinds

00:13:56,630 --> 00:13:59,990
of things but most of them increment it

00:13:58,190 --> 00:14:02,090
does follow this pattern and any change

00:13:59,990 --> 00:14:03,380
to an object read that object in

00:14:02,090 --> 00:14:05,270
generate a whole bunch of other

00:14:03,380 --> 00:14:07,520
kubernetes goop apply that into

00:14:05,270 --> 00:14:09,200
kubernetes api or sometimes like talk to

00:14:07,520 --> 00:14:10,790
external systems so like the one that

00:14:09,200 --> 00:14:13,630
makes s3 instead of talking into the

00:14:10,790 --> 00:14:16,310
community api it talks to the AWS api

00:14:13,630 --> 00:14:18,170
and just loop this forever

00:14:16,310 --> 00:14:19,910
so every time there is a change you get

00:14:18,170 --> 00:14:22,190
the object you read what was requested

00:14:19,910 --> 00:14:23,600
like I want an s3 bucket called foo and

00:14:22,190 --> 00:14:26,600
it should have you know permissions

00:14:23,600 --> 00:14:28,070
public talk to the AWS API if the bucket

00:14:26,600 --> 00:14:28,940
doesn't exist create it if the

00:14:28,070 --> 00:14:32,480
permissions don't match what was

00:14:28,940 --> 00:14:33,950
requested fix them repeat forever this

00:14:32,480 --> 00:14:36,830
loop ensures that everything gets

00:14:33,950 --> 00:14:38,300
rebuilt effectively from scratch so if

00:14:36,830 --> 00:14:40,010
we are just sort of running and I go and

00:14:38,300 --> 00:14:41,840
delete that s3 bucket the next time it

00:14:40,010 --> 00:14:43,220
reconciles it'll just recreate it system

00:14:41,840 --> 00:14:45,260
doesn't have to care about what error

00:14:43,220 --> 00:14:46,910
state things were in all it wants to do

00:14:45,260 --> 00:14:48,080
is know what is the current state of the

00:14:46,910 --> 00:14:51,020
universe and what is the desired state

00:14:48,080 --> 00:14:52,880
of the universe every custom type will

00:14:51,020 --> 00:14:54,620
have usually one custom controller that

00:14:52,880 --> 00:14:56,330
has attached to it package up all of

00:14:54,620 --> 00:14:57,620
those multiple controllers and multiple

00:14:56,330 --> 00:15:00,710
custom types together and you end up

00:14:57,620 --> 00:15:02,770
with an operator but ok enough about the

00:15:00,710 --> 00:15:04,790
ideas behind the system where's the code

00:15:02,770 --> 00:15:06,500
unfortunately writing complex operators

00:15:04,790 --> 00:15:08,660
in Python is doable but a bit tricky

00:15:06,500 --> 00:15:09,770
there's two main projects that are

00:15:08,660 --> 00:15:11,660
trying to make it easier to write

00:15:09,770 --> 00:15:12,800
kinetise operators in python one is

00:15:11,660 --> 00:15:14,570
called cop and one of the other is

00:15:12,800 --> 00:15:16,100
called meta controller they're both

00:15:14,570 --> 00:15:17,510
however aimed at relatively simple use

00:15:16,100 --> 00:15:19,460
cases and they're pretty early in

00:15:17,510 --> 00:15:21,440
development there is also a low-level

00:15:19,460 --> 00:15:23,720
client library that's auto-generated for

00:15:21,440 --> 00:15:25,760
Python but then you have to write all of

00:15:23,720 --> 00:15:28,280
the custom controller and custom tools

00:15:25,760 --> 00:15:29,810
custom types specific stuff yourself and

00:15:28,280 --> 00:15:31,700
no one has really written a thing to

00:15:29,810 --> 00:15:33,350
make that easy yet so in the end we

00:15:31,700 --> 00:15:34,610
decided to go with the more community

00:15:33,350 --> 00:15:35,960
standard cout builder and controller

00:15:34,610 --> 00:15:38,420
runtime libraries even though those are

00:15:35,960 --> 00:15:40,280
in go I'm going to summarize the things

00:15:38,420 --> 00:15:42,140
that we wrote in Python pseudocode from

00:15:40,280 --> 00:15:43,850
here but if you go and look at my actual

00:15:42,140 --> 00:15:44,270
repository which we linked at the end it

00:15:43,850 --> 00:15:48,470
will

00:15:44,270 --> 00:15:50,000
and go Soviet so the first problem that

00:15:48,470 --> 00:15:51,740
we tackled as we're writing our custom

00:15:50,000 --> 00:15:53,930
operator was the big problem we had with

00:15:51,740 --> 00:15:55,250
helm sequencing and ordering we added a

00:15:53,930 --> 00:15:56,540
lightweight state machine to figure out

00:15:55,250 --> 00:15:58,940
sort of where in the deployment process

00:15:56,540 --> 00:16:00,440
our system was the first phase

00:15:58,940 --> 00:16:01,400
initializing covers the setup of

00:16:00,440 --> 00:16:02,720
databases and other underlying

00:16:01,400 --> 00:16:04,130
infrastructure is sort of like big

00:16:02,720 --> 00:16:06,590
global stuff that's usually done once

00:16:04,130 --> 00:16:08,780
and then we had migrations run per

00:16:06,590 --> 00:16:13,130
version deploying per version and then

00:16:08,780 --> 00:16:14,690
ready and error when that happens this

00:16:13,130 --> 00:16:17,420
is some of this pseudocode specifically

00:16:14,690 --> 00:16:18,500
around dealing with migrations this is

00:16:17,420 --> 00:16:19,880
one of the nice things about writing

00:16:18,500 --> 00:16:20,960
custom operators though and we'll see

00:16:19,880 --> 00:16:23,600
this a couple of times throughout the

00:16:20,960 --> 00:16:25,220
talk is that because this is real code

00:16:23,600 --> 00:16:26,990
as opposed to just being a declarative

00:16:25,220 --> 00:16:29,750
system like helm or other yellow-based

00:16:26,990 --> 00:16:32,360
tools we control it and we can make

00:16:29,750 --> 00:16:34,340
whatever behavior we want so it allows

00:16:32,360 --> 00:16:36,830
very very careful customization of

00:16:34,340 --> 00:16:39,170
exactly how migrations work in Jango say

00:16:36,830 --> 00:16:40,850
which is subtly different than other

00:16:39,170 --> 00:16:42,650
frameworks and lets us very carefully

00:16:40,850 --> 00:16:44,840
control the behavior of what happens if

00:16:42,650 --> 00:16:46,310
say there is an error during migrations

00:16:44,840 --> 00:16:47,990
what do we do like what does that mean

00:16:46,310 --> 00:16:50,060
in the case of Jango it doesn't attempt

00:16:47,990 --> 00:16:51,770
to auto rollback for example so we have

00:16:50,060 --> 00:16:54,350
to understand that there was an error

00:16:51,770 --> 00:16:55,550
and flag that to an operator there's

00:16:54,350 --> 00:16:59,870
some other frameworks where it'll auto

00:16:55,550 --> 00:17:01,760
rollback and you just try again I put a

00:16:59,870 --> 00:17:03,800
slide celery bit earlier so now's a good

00:17:01,760 --> 00:17:05,089
time to pull it back out there's two

00:17:03,800 --> 00:17:06,920
problems with celery beet for anyone

00:17:05,089 --> 00:17:09,560
that runs up the first is that if you

00:17:06,920 --> 00:17:11,000
run two copies of celery beets it's the

00:17:09,560 --> 00:17:12,830
thing that schedules all of your

00:17:11,000 --> 00:17:14,900
scheduled tasks so basically it's like

00:17:12,830 --> 00:17:16,700
cron for celery and if you run two

00:17:14,900 --> 00:17:19,339
copies of it your scheduled tasks just

00:17:16,700 --> 00:17:21,530
run twice if your tasks are all

00:17:19,339 --> 00:17:23,120
perfectly idempotent that can sometimes

00:17:21,530 --> 00:17:25,250
be okay but it's still gonna be a load

00:17:23,120 --> 00:17:26,810
increase and usually you'll end up with

00:17:25,250 --> 00:17:29,210
one or two tasks that if they run twice

00:17:26,810 --> 00:17:30,320
bad things happen it's certainly easy to

00:17:29,210 --> 00:17:32,870
happen unexpectedly

00:17:30,320 --> 00:17:34,190
and people do not understand why the

00:17:32,870 --> 00:17:37,220
second problem with celery beet is it as

00:17:34,190 --> 00:17:39,020
a stateful tool it stores a bit of

00:17:37,220 --> 00:17:39,890
information for every task like when it

00:17:39,020 --> 00:17:42,200
was run last

00:17:39,890 --> 00:17:43,640
by default it stores that in a file on

00:17:42,200 --> 00:17:45,290
the local file system there's a tool

00:17:43,640 --> 00:17:47,780
called Jango celery meat that puts into

00:17:45,290 --> 00:17:49,580
Jango sequel database but that's a lot

00:17:47,780 --> 00:17:52,070
of write load like we have a couple

00:17:49,580 --> 00:17:54,050
dozen tasks running every I think five

00:17:52,070 --> 00:17:55,520
seconds and so that would just be an

00:17:54,050 --> 00:17:57,630
enormous amount of write load our sequel

00:17:55,520 --> 00:17:59,760
database that we didn't really want

00:17:57,630 --> 00:18:01,950
so this brings me to a tool that I hope

00:17:59,760 --> 00:18:05,010
everyone will now be able to use called

00:18:01,950 --> 00:18:07,530
celery BX BX solves both of these

00:18:05,010 --> 00:18:09,330
problems on the first the first phase it

00:18:07,530 --> 00:18:10,590
does locking between multiple instances

00:18:09,330 --> 00:18:13,170
of celery beet so if you have more than

00:18:10,590 --> 00:18:15,090
one running only one will be active and

00:18:13,170 --> 00:18:17,340
it also allows storing the celery beet

00:18:15,090 --> 00:18:19,920
state into your cash back end so either

00:18:17,340 --> 00:18:21,600
Redis or memcache which is usually a lot

00:18:19,920 --> 00:18:24,480
better for live data like that than

00:18:21,600 --> 00:18:26,610
sequel there is a catch though which is

00:18:24,480 --> 00:18:28,050
Python 3 only and if you remember my app

00:18:26,610 --> 00:18:30,630
is not yet on Python 3 so I actually

00:18:28,050 --> 00:18:32,970
can't use this so be better than me

00:18:30,630 --> 00:18:34,320
use celery mutex otherwise you got to

00:18:32,970 --> 00:18:37,800
deploy it on a staple set and it's kind

00:18:34,320 --> 00:18:40,290
of a pain in the ass so again with

00:18:37,800 --> 00:18:42,870
pseudocode this is another example of

00:18:40,290 --> 00:18:44,550
why it is nice to be able to control at

00:18:42,870 --> 00:18:47,160
a code level what is going on during our

00:18:44,550 --> 00:18:49,710
deployment this is an example of we auto

00:18:47,160 --> 00:18:51,090
generate the passwords for all of our

00:18:49,710 --> 00:18:53,130
database users as we're creating them

00:18:51,090 --> 00:18:55,440
automatically and so we wanted to feed

00:18:53,130 --> 00:18:56,880
those passwords back into Django I

00:18:55,440 --> 00:18:59,970
mentioned before that we put all our

00:18:56,880 --> 00:19:02,610
config into gamal so we haven't want to

00:18:59,970 --> 00:19:05,220
read the dynamic passwords for our

00:19:02,610 --> 00:19:07,380
database users both sequel and RabbitMQ

00:19:05,220 --> 00:19:09,270
we put those into the yeah Mel

00:19:07,380 --> 00:19:10,680
dynamically render some yeah Mel put

00:19:09,270 --> 00:19:12,660
them back in a secret that gets mounted

00:19:10,680 --> 00:19:14,190
into our container and then the setting

00:19:12,660 --> 00:19:16,350
stop I can read it as if it were a file

00:19:14,190 --> 00:19:18,090
and because this is in the controller

00:19:16,350 --> 00:19:20,010
anytime anything changes so if we want

00:19:18,090 --> 00:19:21,360
to rotate all the passwords we tell the

00:19:20,010 --> 00:19:22,500
system to update the passwords then

00:19:21,360 --> 00:19:26,100
it'll cascade through the system

00:19:22,500 --> 00:19:27,990
naturally so that covers the underlying

00:19:26,100 --> 00:19:29,550
tech what about workflow that's just as

00:19:27,990 --> 00:19:30,660
important as having good deployments as

00:19:29,550 --> 00:19:33,300
well as having good deployment workflow

00:19:30,660 --> 00:19:35,760
our original was a fairly simple

00:19:33,300 --> 00:19:38,580
deployed sh it just wrapped running

00:19:35,760 --> 00:19:40,080
ansible pretty simple repeatable but it

00:19:38,580 --> 00:19:41,690
had some issues the biggest ones were

00:19:40,080 --> 00:19:45,900
that there was a source of truth

00:19:41,690 --> 00:19:48,870
mismatch and that because convergence

00:19:45,900 --> 00:19:51,570
was both partial and manual things could

00:19:48,870 --> 00:19:53,490
drift over time with the source of truth

00:19:51,570 --> 00:19:55,290
the idea of mapping out sources of truth

00:19:53,490 --> 00:19:57,720
is to figure out where in your system a

00:19:55,290 --> 00:19:59,610
given piece of data is authoritative so

00:19:57,720 --> 00:20:01,680
for example with our ansible code that

00:19:59,610 --> 00:20:04,110
was authoritative and get get defined

00:20:01,680 --> 00:20:07,890
what was the correct way to configure a

00:20:04,110 --> 00:20:09,660
system but where did the information of

00:20:07,890 --> 00:20:11,410
the versions that should live on each

00:20:09,660 --> 00:20:12,880
server

00:20:11,410 --> 00:20:14,260
in our case that didn't really go

00:20:12,880 --> 00:20:16,120
anywhere it was basically authoritative

00:20:14,260 --> 00:20:17,920
on the running systems themselves based

00:20:16,120 --> 00:20:20,230
on what version was get cloned on to

00:20:17,920 --> 00:20:22,870
them so that we had no like centralized

00:20:20,230 --> 00:20:24,640
overview of what versions were where and

00:20:22,870 --> 00:20:26,020
there was no easy way to like backup and

00:20:24,640 --> 00:20:28,120
restore that information because it was

00:20:26,020 --> 00:20:29,290
just what was on the machines and this

00:20:28,120 --> 00:20:31,210
also comes up if you're using Jenkins

00:20:29,290 --> 00:20:33,250
parameterised build jobs for doing the

00:20:31,210 --> 00:20:35,770
appointments same problem the thing that

00:20:33,250 --> 00:20:38,470
records where your versions live is

00:20:35,770 --> 00:20:40,030
Jenkins build parameters which isn't a

00:20:38,470 --> 00:20:43,360
thing that you can easily like review

00:20:40,030 --> 00:20:46,600
and backup and restore and then the

00:20:43,360 --> 00:20:48,760
related issue of drift because doing a

00:20:46,600 --> 00:20:50,020
push becomes a manual action it is

00:20:48,760 --> 00:20:52,210
possible for things to be missed and to

00:20:50,020 --> 00:20:53,650
slowly drift over time usually in our

00:20:52,210 --> 00:20:55,930
case this meant an old test server

00:20:53,650 --> 00:20:57,640
sitting in a disused corner of our AWS

00:20:55,930 --> 00:20:59,040
account that was unpatched for months or

00:20:57,640 --> 00:21:01,870
years

00:20:59,040 --> 00:21:03,850
so git ops the central idea of get ops

00:21:01,870 --> 00:21:06,460
is that git is your only source of truth

00:21:03,850 --> 00:21:08,860
all information configuration code

00:21:06,460 --> 00:21:10,990
everything has to let in get somewhere

00:21:08,860 --> 00:21:12,760
somehow and then you have some

00:21:10,990 --> 00:21:14,320
automation that is reading out reading

00:21:12,760 --> 00:21:16,060
configuration and infrastructure changes

00:21:14,320 --> 00:21:19,240
out of git and affecting them on to the

00:21:16,060 --> 00:21:21,010
universe this purge gets you a lot of

00:21:19,240 --> 00:21:22,510
great things because the full state of

00:21:21,010 --> 00:21:24,370
your configuration is reflected in get

00:21:22,510 --> 00:21:25,990
at all times the automation can

00:21:24,370 --> 00:21:27,430
continuously clean up that drip so if

00:21:25,990 --> 00:21:29,860
you make a change to your deployments

00:21:27,430 --> 00:21:32,320
system somehow it will take effect

00:21:29,860 --> 00:21:33,430
across every machine simultaneously that

00:21:32,320 --> 00:21:34,690
also means that you can take down all

00:21:33,430 --> 00:21:37,000
the fraud simultaneously so make sure

00:21:34,690 --> 00:21:39,940
you have good tests but it is nice that

00:21:37,000 --> 00:21:41,560
things will never be out of sync it also

00:21:39,940 --> 00:21:43,540
means that if there's an emergency you

00:21:41,560 --> 00:21:44,890
have all of your stuff in one place I

00:21:43,540 --> 00:21:46,330
can push one button and restore my

00:21:44,890 --> 00:21:48,070
entire infrastructure because it's all

00:21:46,330 --> 00:21:49,900
in one place and that is the

00:21:48,070 --> 00:21:52,150
authoritative source

00:21:49,900 --> 00:21:53,890
it also helps just bringing a more code

00:21:52,150 --> 00:21:56,320
based workflow to operational changes

00:21:53,890 --> 00:21:58,180
you get things like code reviews and

00:21:56,320 --> 00:22:00,250
commit messages and things like that it

00:21:58,180 --> 00:22:02,470
even can be used as a kind of discount

00:22:00,250 --> 00:22:05,050
audit log of seeing who made changes

00:22:02,470 --> 00:22:06,490
when and hopefully why but it's not

00:22:05,050 --> 00:22:08,290
perfect the biggest friction we've had

00:22:06,490 --> 00:22:10,240
in switching our teams to get ops is

00:22:08,290 --> 00:22:12,100
frustration that they have to get what

00:22:10,240 --> 00:22:13,560
they feel are minor operational changes

00:22:12,100 --> 00:22:15,790
fully through a code review process

00:22:13,560 --> 00:22:18,130
we're currently using the github branch

00:22:15,790 --> 00:22:20,140
protection rule system and it's it's got

00:22:18,130 --> 00:22:22,600
some flexibility in determining who does

00:22:20,140 --> 00:22:23,290
reviews but not a lot of flexibility in

00:22:22,600 --> 00:22:26,770
what

00:22:23,290 --> 00:22:29,350
be reviewed so our goal is to eventually

00:22:26,770 --> 00:22:31,120
try to replace that with a custom review

00:22:29,350 --> 00:22:32,260
management system but we haven't yet

00:22:31,120 --> 00:22:33,400
built that so there's been a lot of

00:22:32,260 --> 00:22:35,650
frustration from some of our team

00:22:33,400 --> 00:22:37,480
members also we've had some team members

00:22:35,650 --> 00:22:39,580
that are engineering adjacent they're

00:22:37,480 --> 00:22:40,990
not working in code day-to-day but they

00:22:39,580 --> 00:22:42,730
do need to interact with the deployment

00:22:40,990 --> 00:22:44,110
system and they didn't necessarily have

00:22:42,730 --> 00:22:45,520
github accounts they didn't know how to

00:22:44,110 --> 00:22:47,950
use it very well so we've had to guide

00:22:45,520 --> 00:22:49,090
them through that it's been okay since

00:22:47,950 --> 00:22:51,040
then but it was definitely a thing that

00:22:49,090 --> 00:22:52,270
we sort of forgot to factor in is that

00:22:51,040 --> 00:22:55,810
there are people that don't sit in

00:22:52,270 --> 00:22:58,060
github all day and of course if your

00:22:55,810 --> 00:22:59,830
team members don't fill in good commit

00:22:58,060 --> 00:23:01,390
messages or don't review things

00:22:59,830 --> 00:23:02,770
consistently then that data source is

00:23:01,390 --> 00:23:06,070
not going to be very useful we do have a

00:23:02,770 --> 00:23:10,330
lot of update Fujiyama as the commit

00:23:06,070 --> 00:23:11,800
message which so it goes so put it all

00:23:10,330 --> 00:23:14,200
together and we get a new end end

00:23:11,800 --> 00:23:16,870
workflow based on git ops we use a tool

00:23:14,200 --> 00:23:18,940
called agro CD to do the critical watch

00:23:16,870 --> 00:23:21,040
your git repositories and sync them into

00:23:18,940 --> 00:23:22,840
kubernetes but there's a lot of tools

00:23:21,040 --> 00:23:25,540
around there find one that works for you

00:23:22,840 --> 00:23:28,710
the general idea is to have github be or

00:23:25,540 --> 00:23:30,940
get in general be the source of truth

00:23:28,710 --> 00:23:32,920
all right some bonus things because we

00:23:30,940 --> 00:23:35,500
do have a few extra minutes second piece

00:23:32,920 --> 00:23:37,600
of the puzzle that we built was a CLI

00:23:35,500 --> 00:23:39,400
tool to handle common tasks that our

00:23:37,600 --> 00:23:40,480
engineers would come up with the first

00:23:39,400 --> 00:23:41,830
two of these for example are just

00:23:40,480 --> 00:23:44,290
wrappers around the coop cuddle x'q

00:23:41,830 --> 00:23:46,030
command line tool to give you a bash

00:23:44,290 --> 00:23:47,920
shell or a Python shell on a given

00:23:46,030 --> 00:23:49,600
instance of the application the last one

00:23:47,920 --> 00:23:51,370
is a wrapper and piece equal to pull the

00:23:49,600 --> 00:23:53,260
right database information user password

00:23:51,370 --> 00:23:54,490
host name and just feed it into PC cool

00:23:53,260 --> 00:23:56,680
so they don't have to go find that every

00:23:54,490 --> 00:23:58,570
time we've been adding more debugging

00:23:56,680 --> 00:23:59,860
assistance tools over our to it over

00:23:58,570 --> 00:24:00,730
time and it's been generally I think

00:23:59,860 --> 00:24:03,310
well-received

00:24:00,730 --> 00:24:06,370
we took a cue from homebrew and we added

00:24:03,310 --> 00:24:08,260
a command to our thing to both examine

00:24:06,370 --> 00:24:10,420
environmental issues and potentially

00:24:08,260 --> 00:24:11,650
auto fix them if it knows how to this

00:24:10,420 --> 00:24:13,120
has been very helpful in just getting

00:24:11,650 --> 00:24:15,130
more people set up on the new platform

00:24:13,120 --> 00:24:16,390
we can just tell them hey please run

00:24:15,130 --> 00:24:20,800
right if it'll doctor and paste me the

00:24:16,390 --> 00:24:21,820
output and this is still mostly in

00:24:20,800 --> 00:24:25,120
testing we haven't rolled it out to

00:24:21,820 --> 00:24:26,800
production yet as an ops person I like

00:24:25,120 --> 00:24:28,630
command-line tools so I'm cool just like

00:24:26,800 --> 00:24:30,460
coop Ketel describe as my interface to a

00:24:28,630 --> 00:24:32,110
lot of things but not everyone on all of

00:24:30,460 --> 00:24:33,670
our teams feels the same way so we

00:24:32,110 --> 00:24:36,240
started to build a fairly simple

00:24:33,670 --> 00:24:37,890
read-only user interface

00:24:36,240 --> 00:24:39,510
so that they could navigate things via

00:24:37,890 --> 00:24:44,370
the web and see nice graphical pretty

00:24:39,510 --> 00:24:46,350
things so well our Django deployment

00:24:44,370 --> 00:24:48,210
logic in this thing is definitely fairly

00:24:46,350 --> 00:24:50,580
tailored to our needs it's still pretty

00:24:48,210 --> 00:24:52,290
general Django and it is all open source

00:24:50,580 --> 00:24:54,690
which is nice but it's not particularly

00:24:52,290 --> 00:24:56,610
well documented but it is open if you

00:24:54,690 --> 00:24:58,920
want to go look at it steal ideas steal

00:24:56,610 --> 00:25:01,710
whole sections of code that is highly

00:24:58,920 --> 00:25:04,880
recommended and yeah thank you so much

00:25:01,710 --> 00:25:04,880
for having me any questions

00:25:07,730 --> 00:25:13,080
Hey I think sort of talked it was really

00:25:10,110 --> 00:25:18,000
insightful one of my biggest fears from

00:25:13,080 --> 00:25:20,480
moving to a paas like Heroku to a more

00:25:18,000 --> 00:25:22,560
flexible kubernetes environment is

00:25:20,480 --> 00:25:27,510
Hiroki does so much for me

00:25:22,560 --> 00:25:29,730
we've managed Redis Postgres like they

00:25:27,510 --> 00:25:32,130
tell me when maintenance needs to be

00:25:29,730 --> 00:25:34,470
done they do it if you still have you I

00:25:32,130 --> 00:25:36,690
guess my question is have you still kept

00:25:34,470 --> 00:25:41,430
that managed or you you managed in that

00:25:36,690 --> 00:25:45,120
yourself for most so for Postgres we use

00:25:41,430 --> 00:25:46,350
RDS for rabbitmq use cloud NPP Redis in

00:25:45,120 --> 00:25:49,200
particular we've decided to run

00:25:46,350 --> 00:25:51,570
ourselves because Amazon does offer

00:25:49,200 --> 00:25:53,130
ElastiCache Redis but it is remarkably

00:25:51,570 --> 00:25:56,160
expensive and Redis is pretty easy to

00:25:53,130 --> 00:25:58,200
run but yeah I will point out that you

00:25:56,160 --> 00:26:00,030
can actually use Heroku Postgres without

00:25:58,200 --> 00:26:01,350
using Heroku they don't like super

00:26:00,030 --> 00:26:03,660
advertise that fact but if you're on

00:26:01,350 --> 00:26:05,070
Amazon it's running in Amazon you can

00:26:03,660 --> 00:26:08,190
just keep using Heroku Postgres if you

00:26:05,070 --> 00:26:11,400
like it I like that yeah okay thank you

00:26:08,190 --> 00:26:13,650
very much oh yeah thanks for the talk um

00:26:11,400 --> 00:26:15,750
I have a question you know as someone

00:26:13,650 --> 00:26:17,520
who's tinkered with docker and you know

00:26:15,750 --> 00:26:19,170
kind of been getting into these types of

00:26:17,520 --> 00:26:21,420
technologies maybe even using them in

00:26:19,170 --> 00:26:24,300
production well how would you recommend

00:26:21,420 --> 00:26:28,020
someone diving into kubernetes as kind

00:26:24,300 --> 00:26:30,570
of the next next level really just what

00:26:28,020 --> 00:26:32,670
I showed in the talk of start writing

00:26:30,570 --> 00:26:34,110
some yeah Mille like pick an application

00:26:32,670 --> 00:26:36,420
the one I generally recommend is

00:26:34,110 --> 00:26:38,160
WordPress because it is really like it's

00:26:36,420 --> 00:26:40,590
got a slick installation process and

00:26:38,160 --> 00:26:42,240
there's a million-and-a-half guides to

00:26:40,590 --> 00:26:45,060
every possible flavor WordPress thing

00:26:42,240 --> 00:26:47,580
you want to do so just like start

00:26:45,060 --> 00:26:49,890
writing some big yamo files to deploy

00:26:47,580 --> 00:26:50,220
like deploy I guess my sequel if you're

00:26:49,890 --> 00:26:52,950
doing we're

00:26:50,220 --> 00:26:54,360
press deploy a wordpress container like

00:26:52,950 --> 00:26:55,650
it's got a fairly well polished docker

00:26:54,360 --> 00:26:58,830
image already so you don't have to make

00:26:55,650 --> 00:27:01,590
that yourself and just try deploying

00:26:58,830 --> 00:27:03,870
stuff like gke is really easy to get

00:27:01,590 --> 00:27:04,890
started with and if you remember to shut

00:27:03,870 --> 00:27:08,460
it down when you've been using it it's

00:27:04,890 --> 00:27:11,760
pretty cheap so yeah that's that's where

00:27:08,460 --> 00:27:13,260
I begin hey yeah I was just curious when

00:27:11,760 --> 00:27:15,330
you were in the section regarding

00:27:13,260 --> 00:27:17,760
get-ups and you're talking about getting

00:27:15,330 --> 00:27:19,860
people engaged in that process you said

00:27:17,760 --> 00:27:22,289
that there was difficulty with people

00:27:19,860 --> 00:27:24,510
who weren't engineers being engaged of

00:27:22,289 --> 00:27:26,760
that process who is not that's not

00:27:24,510 --> 00:27:29,700
engineer cares enough about your deploys

00:27:26,760 --> 00:27:31,740
to get involved in that anyway

00:27:29,700 --> 00:27:35,280
mostly the the product management team

00:27:31,740 --> 00:27:37,590
and the release management team are not

00:27:35,280 --> 00:27:40,110
necessarily we have team has some

00:27:37,590 --> 00:27:42,600
engineers on it but it also has more PME

00:27:40,110 --> 00:27:43,950
kind of people that do want to be

00:27:42,600 --> 00:27:45,330
involved they want to like see when

00:27:43,950 --> 00:27:48,120
deploys are happening because it's part

00:27:45,330 --> 00:27:50,520
of their checklists but they're not like

00:27:48,120 --> 00:27:52,320
living and breathing in github one of

00:27:50,520 --> 00:27:53,700
them like had a github account but

00:27:52,320 --> 00:27:54,900
haven't logged in in a couple years a

00:27:53,700 --> 00:27:58,440
couple of them had never had github

00:27:54,900 --> 00:28:01,289
accounts stuff like that so when you as

00:27:58,440 --> 00:28:02,940
you finished up that more like friendly

00:28:01,289 --> 00:28:04,320
UI is the intent that a lot of those

00:28:02,940 --> 00:28:05,610
people would just be pushed towards that

00:28:04,320 --> 00:28:07,049
because it's mostly about communicating

00:28:05,610 --> 00:28:09,360
to them not necessarily them

00:28:07,049 --> 00:28:10,740
contributing yeah probably

00:28:09,360 --> 00:28:12,150
if they want to be able to see like

00:28:10,740 --> 00:28:13,140
system status and we're also working on

00:28:12,150 --> 00:28:14,700
sort of custom tools especially

00:28:13,140 --> 00:28:17,130
rivalry's management team like they

00:28:14,700 --> 00:28:19,320
really want to be able to see not just

00:28:17,130 --> 00:28:21,690
what version is in one place they want a

00:28:19,320 --> 00:28:23,460
big overview of like which given a you

00:28:21,690 --> 00:28:24,419
know what versions are in prod and where

00:28:23,460 --> 00:28:26,730
are they

00:28:24,419 --> 00:28:28,200
but because everything is just in EML

00:28:26,730 --> 00:28:29,370
files it's pretty easy for us to just

00:28:28,200 --> 00:28:30,870
write a little script that like

00:28:29,370 --> 00:28:33,299
generates them a nightly report or

00:28:30,870 --> 00:28:34,950
whatever and emails it to them so a mix

00:28:33,299 --> 00:28:36,929
of that web UI and just writing little

00:28:34,950 --> 00:28:38,640
custom integrations that either talk to

00:28:36,929 --> 00:28:41,700
the kubernetes API directly or just read

00:28:38,640 --> 00:28:44,610
and parse EML files out of github cool

00:28:41,700 --> 00:28:45,770
thanks awesome thank you so much and

00:28:44,610 --> 00:28:49,510
enjoy your break

00:28:45,770 --> 00:29:02,809
[Applause]

00:28:49,510 --> 00:29:02,809

YouTube URL: https://www.youtube.com/watch?v=Dr_U8tjghwc


