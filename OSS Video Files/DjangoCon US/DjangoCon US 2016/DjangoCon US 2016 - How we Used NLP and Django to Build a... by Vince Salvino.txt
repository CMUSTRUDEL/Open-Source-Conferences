Title: DjangoCon US 2016 - How we Used NLP and Django to Build a... by Vince Salvino
Publication date: 2016-08-25
Playlist: DjangoCon US 2016
Description: 
	How we Used NLP and Django to Build a Movie Suggestion Website & Twitterbot by Vince Salvino

The Cleveland International Film Festival (CIFF) is a two-week long event featuring hundreds of foreign, independent, and new films making their debut on the silver screen. For anyone less than a film buff, choosing a movie to watch at the film fest is a hard choice: there are no reviews, no IMDb info, and no Netflix/Hulu suggestions. Yes, itâ€™s truly byzantine in that one must actually read all the movie descriptions to decide which one to watch.

With a handful of Python libraries, and 2 days, we developers at CodeRed built a movie recommendation engine for the CIFF. This talk outlines each step we took to build the recommendation engine, website, and twitterbot all centered around a Django project. Overall, this talk offers a complete look at the various parts and pieces that go into building a feature-full Django site, as well as exposure to doing entry-level Artificial Intelligence in Python.

This talk was presented at: https://2016.djangocon.us/schedule/presentation/30/

LINKS:
Follow DjangCon US ðŸ‘‡
https://twitter.com/djangocon

Follow DEFNA ðŸ‘‡
https://twitter.com/defnado
https://www.defna.org/
Captions: 
	00:00:15,289 --> 00:00:20,310
hi everyone thank you it's my first time

00:00:18,570 --> 00:00:24,960
speaking at Jango cow so I'm very

00:00:20,310 --> 00:00:27,180
excited to be here yeah as this is my

00:00:24,960 --> 00:00:29,630
email so if you have any questions or

00:00:27,180 --> 00:00:32,430
anything please feel free to reach out

00:00:29,630 --> 00:00:35,640
and real quick if anyone likes to follow

00:00:32,430 --> 00:00:37,469
along these slides can be downloaded at

00:00:35,640 --> 00:00:40,200
that URL

00:00:37,469 --> 00:00:47,489
kasing it's just a PDF in case anyone is

00:00:40,200 --> 00:00:49,649
looking for that so real quick to give

00:00:47,489 --> 00:00:51,420
you an overview of what we did is this

00:00:49,649 --> 00:00:54,059
is gonna be sort of a talking about

00:00:51,420 --> 00:00:55,350
project we implemented so we work with

00:00:54,059 --> 00:00:59,520
the Cleveland International Film

00:00:55,350 --> 00:01:01,379
Festival to build a little bit of

00:00:59,520 --> 00:01:04,559
software for them it was sort of a hobby

00:01:01,379 --> 00:01:06,150
project that we did and wrote briefly

00:01:04,559 --> 00:01:07,920
about the Cleveland International Film

00:01:06,150 --> 00:01:13,939
Festival it's a two week long event you

00:01:07,920 --> 00:01:19,259
know similar to like Toronto or the Sun

00:01:13,939 --> 00:01:21,330
Sun being the other film fest and they

00:01:19,259 --> 00:01:25,799
have a lot of independent films it was

00:01:21,330 --> 00:01:27,299
held in April this year and it's a

00:01:25,799 --> 00:01:29,189
pretty big event for Cleveland so we

00:01:27,299 --> 00:01:32,640
were really excited to do some stuff

00:01:29,189 --> 00:01:35,670
with it I myself am NOT a film buff I'm

00:01:32,640 --> 00:01:37,439
sure many of you in the room are shout

00:01:35,670 --> 00:01:39,090
out to a movie I saw there works from

00:01:37,439 --> 00:01:42,150
America was an independent film very

00:01:39,090 --> 00:01:45,390
good and I'm not affiliated with the

00:01:42,150 --> 00:01:49,829
clean Cleveland Film Fest so just it's

00:01:45,390 --> 00:01:53,820
my disclaimer and about the project

00:01:49,829 --> 00:01:55,560
that's our little robot guy there so we

00:01:53,820 --> 00:01:58,110
built the movie recommendation engine

00:01:55,560 --> 00:02:00,420
you know there's about over 400 films at

00:01:58,110 --> 00:02:02,790
this festival and they're all pretty

00:02:00,420 --> 00:02:04,420
much all brand-new releases independent

00:02:02,790 --> 00:02:06,220
then they've never been seen

00:02:04,420 --> 00:02:08,110
they've never been reviewed the only

00:02:06,220 --> 00:02:10,840
thing we have on them is it just a title

00:02:08,110 --> 00:02:13,599
and description so when you're deciding

00:02:10,840 --> 00:02:15,459
which one to see especially if you don't

00:02:13,599 --> 00:02:18,459
know the producers or don't know who's

00:02:15,459 --> 00:02:22,600
making the film you know it's kind of

00:02:18,459 --> 00:02:24,459
intimidating for an average person so we

00:02:22,600 --> 00:02:26,170
decided to take the publicly available

00:02:24,459 --> 00:02:28,690
data that they published on their

00:02:26,170 --> 00:02:31,000
website and do a little bit of natural

00:02:28,690 --> 00:02:33,400
language processing on it to identify

00:02:31,000 --> 00:02:35,739
which films were similar to the other

00:02:33,400 --> 00:02:38,650
films so we could know have a bit of

00:02:35,739 --> 00:02:40,750
guide as to what to watch and we also

00:02:38,650 --> 00:02:43,900
did the Twitter bot too as sort of a fun

00:02:40,750 --> 00:02:46,660
aspect of it that would tweet out during

00:02:43,900 --> 00:02:48,549
the show times it would say you know

00:02:46,660 --> 00:02:50,019
this film is starting and then when the

00:02:48,549 --> 00:02:52,150
film was over it would say this film was

00:02:50,019 --> 00:02:54,100
ending if you liked it catch this other

00:02:52,150 --> 00:02:56,519
film that's similar and it was all done

00:02:54,100 --> 00:02:59,530
through is all computer-generated

00:02:56,519 --> 00:03:01,510
statistics about that so it was a quick

00:02:59,530 --> 00:03:04,170
thing we did in a couple days it's 100%

00:03:01,510 --> 00:03:06,069
Python except for the use of cron

00:03:04,170 --> 00:03:08,019
there's all built with open source

00:03:06,069 --> 00:03:12,609
software and once again the data was all

00:03:08,019 --> 00:03:14,500
publicly available from their website so

00:03:12,609 --> 00:03:18,280
what we're gonna look at and this talk

00:03:14,500 --> 00:03:20,950
is we're gonna put on our search engine

00:03:18,280 --> 00:03:23,230
hats first of all and figure out how to

00:03:20,950 --> 00:03:26,320
scrape the data from their website and

00:03:23,230 --> 00:03:29,290
get it into our django database into our

00:03:26,320 --> 00:03:30,910
models the second thing we're gonna do

00:03:29,290 --> 00:03:32,620
is look at some django management

00:03:30,910 --> 00:03:34,720
commands which are pretty simple but

00:03:32,620 --> 00:03:37,660
maybe new for a few people they're very

00:03:34,720 --> 00:03:40,269
useful and then we're gonna get into the

00:03:37,660 --> 00:03:41,650
meat of the talk and look at some

00:03:40,269 --> 00:03:45,280
concepts in natural language processing

00:03:41,650 --> 00:03:47,950
just some basic stuff and then explore

00:03:45,280 --> 00:03:51,010
functionality in the NLT pay which is

00:03:47,950 --> 00:03:53,019
the natural language toolkit it's an

00:03:51,010 --> 00:03:55,150
open-source toolkit it's all in Python

00:03:53,019 --> 00:03:57,609
it's very easy to use and it's a great

00:03:55,150 --> 00:04:00,370
way to learn natural language processing

00:03:57,609 --> 00:04:03,340
or entry-level AI if you're interested

00:04:00,370 --> 00:04:04,989
and then we're gonna look at using the

00:04:03,340 --> 00:04:08,950
Twitter API to make sort of a dumb

00:04:04,989 --> 00:04:10,670
Twitter bot we're not making a Microsoft

00:04:08,950 --> 00:04:14,750
Tay or anything like that

00:04:10,670 --> 00:04:17,780
and we're gonna use the cron job to sort

00:04:14,750 --> 00:04:20,750
of give life to our Twitter bot to tweet

00:04:17,780 --> 00:04:22,820
out at the appropriate times and if we

00:04:20,750 --> 00:04:24,860
have time I'll go into the whoosh and

00:04:22,820 --> 00:04:29,660
the haystack searching of the movie

00:04:24,860 --> 00:04:32,300
database so the first things first is we

00:04:29,660 --> 00:04:33,919
need to identify you know we're

00:04:32,300 --> 00:04:35,830
basically starting from nothing we need

00:04:33,919 --> 00:04:38,150
to look at their website and identify

00:04:35,830 --> 00:04:40,130
what's the data and how what do we need

00:04:38,150 --> 00:04:41,870
to do to represent it and we need to

00:04:40,130 --> 00:04:44,060
make some models so the most obvious

00:04:41,870 --> 00:04:47,419
models are the movie model to represent

00:04:44,060 --> 00:04:48,950
the film itself and the Showtime to

00:04:47,419 --> 00:04:50,660
represent the time that the film is

00:04:48,950 --> 00:04:53,180
playing because they some of them will

00:04:50,660 --> 00:04:59,570
play two or three times over the course

00:04:53,180 --> 00:05:11,870
of the film fest so I will just go to

00:04:59,570 --> 00:05:13,610
their website real quick and they've got

00:05:11,870 --> 00:05:15,880
a whole list of films now this may have

00:05:13,610 --> 00:05:23,270
changed a little bit since it's all over

00:05:15,880 --> 00:05:25,430
but here's a film on their website and

00:05:23,270 --> 00:05:27,919
as you can see they you know it's a very

00:05:25,430 --> 00:05:30,560
nice-looking site it has all the

00:05:27,919 --> 00:05:32,240
information laid out but once again

00:05:30,560 --> 00:05:34,400
putting on our search engine hats how

00:05:32,240 --> 00:05:36,530
are we going to identify what is what on

00:05:34,400 --> 00:05:39,770
the page you know we know that this is a

00:05:36,530 --> 00:05:42,110
description but how will Python know and

00:05:39,770 --> 00:05:48,070
we know that this is a title help icon

00:05:42,110 --> 00:05:48,070
now so for that we use two libraries

00:05:51,669 --> 00:05:56,360
one which is URL live which I'm sure

00:05:54,800 --> 00:05:57,530
many people have used in here and the

00:05:56,360 --> 00:05:59,930
other is beautiful suit

00:05:57,530 --> 00:06:03,830
so URL live basically just gives you the

00:05:59,930 --> 00:06:05,780
ability to do requests sort of network

00:06:03,830 --> 00:06:10,010
type things beautifulsoup

00:06:05,780 --> 00:06:12,020
is it sort of builds the HTML document

00:06:10,010 --> 00:06:14,540
in the markup and lets you query that so

00:06:12,020 --> 00:06:17,210
if you've ever used jQuery beautifulsoup

00:06:14,540 --> 00:06:19,270
is sort of a Python way of doing a

00:06:17,210 --> 00:06:22,490
similar thing querying the different

00:06:19,270 --> 00:06:24,080
HTML tags on the page and identifying

00:06:22,490 --> 00:06:28,220
what's in there parsing the data out of

00:06:24,080 --> 00:06:30,979
them etc so I did want to open-source

00:06:28,220 --> 00:06:34,970
this but because we could potentially

00:06:30,979 --> 00:06:37,520
DDoS their site from crawling it way too

00:06:34,970 --> 00:06:40,030
much I didn't but I'm going to show you

00:06:37,520 --> 00:06:40,030
that code

00:06:43,870 --> 00:06:50,000
so basically URL live is a pretty simple

00:06:47,740 --> 00:06:52,210
tool that will let you oh that's

00:06:50,000 --> 00:06:52,210
actually

00:07:05,569 --> 00:07:11,959
so URL Lib basically just lets you make

00:07:08,819 --> 00:07:13,739
a request to any any web bum any

00:07:11,959 --> 00:07:16,080
resource out there it's very

00:07:13,739 --> 00:07:20,399
straightforward it reads that then into

00:07:16,080 --> 00:07:23,129
memory and from there we will take what

00:07:20,399 --> 00:07:23,729
we just read and parts that with

00:07:23,129 --> 00:07:28,649
beautifulsoup

00:07:23,729 --> 00:07:31,349
as HTML so now we have this whole soup

00:07:28,649 --> 00:07:34,079
object which is essentially the HTML

00:07:31,349 --> 00:07:36,569
document and from here we can query

00:07:34,079 --> 00:07:38,459
through it so you would the obvious

00:07:36,569 --> 00:07:40,619
thing is okay the h1 is probably going

00:07:38,459 --> 00:07:43,009
to be the title right so we go through

00:07:40,619 --> 00:07:45,629
and we parse some of that stuff but as

00:07:43,009 --> 00:07:48,689
you will as you have seen in your

00:07:45,629 --> 00:07:51,089
careers probably webpages aren't always

00:07:48,689 --> 00:07:53,489
formatted in a way that makes sense

00:07:51,089 --> 00:07:57,509
especially when you get JavaScript and

00:07:53,489 --> 00:07:59,279
stuff going on so this ended up being a

00:07:57,509 --> 00:08:01,349
little bit more complicated than we

00:07:59,279 --> 00:08:03,929
initially thought to try and find okay

00:08:01,349 --> 00:08:05,279
where is something existing you know we

00:08:03,929 --> 00:08:08,699
have to look through different columns

00:08:05,279 --> 00:08:11,069
on the page etc so naturally this is a

00:08:08,699 --> 00:08:14,039
little bit hard coded more than a

00:08:11,069 --> 00:08:15,209
regular search engine would be but you

00:08:14,039 --> 00:08:17,849
can basically just loop through

00:08:15,209 --> 00:08:21,959
everything on the page and parse out

00:08:17,849 --> 00:08:23,909
that info using jQuery slice query

00:08:21,959 --> 00:08:26,069
similar to like jQuery like right here

00:08:23,909 --> 00:08:28,319
you see we're gonna find all divs that

00:08:26,069 --> 00:08:31,439
have these certain classes and then

00:08:28,319 --> 00:08:34,409
within there find the paragraph tags so

00:08:31,439 --> 00:08:37,019
and then right there you've got an

00:08:34,409 --> 00:08:38,550
object that you can play with and get

00:08:37,019 --> 00:08:39,930
the content out of so that's beautiful

00:08:38,550 --> 00:08:43,949
soup it's really great if you need to

00:08:39,930 --> 00:08:46,050
course any HTML so we basically go

00:08:43,949 --> 00:08:47,850
through that painstakingly until we're

00:08:46,050 --> 00:08:52,529
able to identify everything on the page

00:08:47,850 --> 00:08:54,029
and then loop through here and we we

00:08:52,529 --> 00:08:56,990
just create our Django objects right

00:08:54,029 --> 00:09:00,779
from that so this is our movie object

00:08:56,990 --> 00:09:03,240
our model I should say and we we just

00:09:00,779 --> 00:09:07,069
create it from this stuff that we parsed

00:09:03,240 --> 00:09:09,959
and now we have a database full of data

00:09:07,069 --> 00:09:11,850
but we need to run this because this is

00:09:09,959 --> 00:09:13,130
sort of a script right it's almost like

00:09:11,850 --> 00:09:14,630
a migration

00:09:13,130 --> 00:09:16,400
because you have to populate your

00:09:14,630 --> 00:09:19,550
database before we can even do anything

00:09:16,400 --> 00:09:21,800
with it and then the other quick thing

00:09:19,550 --> 00:09:23,450
I'll note is that do pay attention to

00:09:21,800 --> 00:09:25,190
time zones if you're ever dealing with

00:09:23,450 --> 00:09:28,700
dates because that can really throw some

00:09:25,190 --> 00:09:31,880
things that a whack so here we are using

00:09:28,700 --> 00:09:35,090
the US eastern time zone so just always

00:09:31,880 --> 00:09:37,540
something to be cognizant of so we've

00:09:35,090 --> 00:09:40,390
got our big long function there that

00:09:37,540 --> 00:09:44,450
we've got our big long function that

00:09:40,390 --> 00:09:46,820
takes care of requesting the pages from

00:09:44,450 --> 00:09:50,930
the website and then identifying the

00:09:46,820 --> 00:09:54,250
data in them but how are we gonna run

00:09:50,930 --> 00:09:56,990
that so Django management command

00:09:54,250 --> 00:09:59,000
they're very simple to do they really

00:09:56,990 --> 00:10:03,080
are this easy they may seem a little bit

00:09:59,000 --> 00:10:08,600
cryptic but when you in a Django

00:10:03,080 --> 00:10:10,880
management command is just um from my

00:10:08,600 --> 00:10:14,540
virtual E&B I can just do you know

00:10:10,880 --> 00:10:16,700
Python manage you know run server that's

00:10:14,540 --> 00:10:19,220
the obvious one but if you just do help

00:10:16,700 --> 00:10:21,500
it will list them all and you can see

00:10:19,220 --> 00:10:24,140
down here that we have a few of our

00:10:21,500 --> 00:10:26,960
custom ones and the one we're interested

00:10:24,140 --> 00:10:29,540
in is great movies so all that is to

00:10:26,960 --> 00:10:33,830
make a jangle management command is you

00:10:29,540 --> 00:10:38,590
put a file in within your project my

00:10:33,830 --> 00:10:41,210
project is called web management

00:10:38,590 --> 00:10:43,370
commands it's a straightforward as it

00:10:41,210 --> 00:10:46,960
can get and then the name of your

00:10:43,370 --> 00:10:49,580
command and it's not a Python file and

00:10:46,960 --> 00:10:52,430
it really is that simple that all you

00:10:49,580 --> 00:10:56,540
have to do is call a Python function

00:10:52,430 --> 00:11:01,970
from inside your handler so creating

00:10:56,540 --> 00:11:03,650
this one simple file will give you the

00:11:01,970 --> 00:11:05,930
Django management command that shows up

00:11:03,650 --> 00:11:07,580
right down there and if you notice I had

00:11:05,930 --> 00:11:17,860
a little help string in there so if you

00:11:07,580 --> 00:11:21,050
do help and then it will output my help

00:11:17,860 --> 00:11:23,550
command right up here and all of the

00:11:21,050 --> 00:11:25,200
standard options so

00:11:23,550 --> 00:11:26,550
it's it's very easy to make a django

00:11:25,200 --> 00:11:31,680
management command and then all I have

00:11:26,550 --> 00:11:33,270
to do is run that which I'm not going to

00:11:31,680 --> 00:11:34,980
run now because that will make hundreds

00:11:33,270 --> 00:11:38,280
of requests to their site to scrape

00:11:34,980 --> 00:11:40,650
everything but it's as easy that to do

00:11:38,280 --> 00:11:42,600
so I would run my migrations make my

00:11:40,650 --> 00:11:47,580
database and then run this and it will

00:11:42,600 --> 00:11:50,610
populate my database so now we've got

00:11:47,580 --> 00:11:53,040
all that stuff taken care of and it's

00:11:50,610 --> 00:11:55,620
code tip number one and once again you

00:11:53,040 --> 00:11:59,520
see it just gives you the management

00:11:55,620 --> 00:12:01,320
command right there so that part wasn't

00:11:59,520 --> 00:12:03,030
principle pretty easy but it took a

00:12:01,320 --> 00:12:06,930
little bit longer than expected to once

00:12:03,030 --> 00:12:10,530
again find the HTML it's sort of an SEO

00:12:06,930 --> 00:12:12,740
thing almost now under the good part

00:12:10,530 --> 00:12:18,690
which is the natural language processing

00:12:12,740 --> 00:12:23,190
so before we look at any code for that

00:12:18,690 --> 00:12:24,600
I'm gonna go over a few concepts so as

00:12:23,190 --> 00:12:27,470
you as you know natural language

00:12:24,600 --> 00:12:30,360
processing is is basically understanding

00:12:27,470 --> 00:12:32,910
texts in a way that a human would but

00:12:30,360 --> 00:12:34,770
you're doing it with the machine so in

00:12:32,910 --> 00:12:38,370
our case what we're trying to understand

00:12:34,770 --> 00:12:41,190
is how similar are two movies you know

00:12:38,370 --> 00:12:43,710
if we've got one about war and one about

00:12:41,190 --> 00:12:46,230
love how's the computer going to know

00:12:43,710 --> 00:12:48,510
that those are even similar and the most

00:12:46,230 --> 00:12:50,460
obvious way is look at the words that

00:12:48,510 --> 00:12:51,210
are in the document so that's what

00:12:50,460 --> 00:12:54,720
tf-idf

00:12:51,210 --> 00:12:57,540
is it stands for term frequency document

00:12:54,720 --> 00:12:59,670
inverse and frequency and basically what

00:12:57,540 --> 00:13:01,920
that means is it looks at both of the

00:12:59,670 --> 00:13:04,860
documents and says which terms show up

00:13:01,920 --> 00:13:07,650
most frequently within those documents

00:13:04,860 --> 00:13:09,720
so if you have three documents and one

00:13:07,650 --> 00:13:12,270
of them has the term love in it you know

00:13:09,720 --> 00:13:15,030
repeated ten times and another one has

00:13:12,270 --> 00:13:18,480
the term love once and the third one has

00:13:15,030 --> 00:13:20,670
the term love five times then document

00:13:18,480 --> 00:13:22,710
one and document three will be

00:13:20,670 --> 00:13:26,640
determined to be the most similar out of

00:13:22,710 --> 00:13:28,770
that group so it's because of the

00:13:26,640 --> 00:13:32,910
simplicity it's relatively easy to

00:13:28,770 --> 00:13:33,850
implement but the problem is it's not

00:13:32,910 --> 00:13:35,709
very smart

00:13:33,850 --> 00:13:37,690
because it only looks it literally just

00:13:35,709 --> 00:13:41,319
counts up the words and says which has

00:13:37,690 --> 00:13:42,819
the most in common and one other thing I

00:13:41,319 --> 00:13:45,430
should mention is that when you are

00:13:42,819 --> 00:13:48,490
making this comparison you remove what's

00:13:45,430 --> 00:13:50,589
known as stop words so like the a and

00:13:48,490 --> 00:13:53,199
you know your prepositions that type of

00:13:50,589 --> 00:13:55,720
thing so you're really only looking at

00:13:53,199 --> 00:13:59,949
words that actually have context or

00:13:55,720 --> 00:14:04,480
meaning rather than just words that are

00:13:59,949 --> 00:14:06,399
there for structure so let's look at

00:14:04,480 --> 00:14:10,060
these two sentences right I went to the

00:14:06,399 --> 00:14:13,959
bank to deposit money compared to I slid

00:14:10,060 --> 00:14:15,610
down the bank by the lake tf-idf would

00:14:13,959 --> 00:14:18,040
say oh they're both similar you know

00:14:15,610 --> 00:14:20,560
they are short and they both contain the

00:14:18,040 --> 00:14:23,500
word bank so they they must be similar

00:14:20,560 --> 00:14:25,839
but we know because we are humans that

00:14:23,500 --> 00:14:27,699
the word Bank has two completely

00:14:25,839 --> 00:14:31,209
different meanings in this context and

00:14:27,699 --> 00:14:33,190
the one of the more traditional examples

00:14:31,209 --> 00:14:35,980
that you see in textbooks is you know I

00:14:33,190 --> 00:14:38,709
gave my dog a bone or the Sailor dogs

00:14:35,980 --> 00:14:41,560
the barmaid right one is being used as a

00:14:38,709 --> 00:14:43,300
verb and means to to pester and one is

00:14:41,560 --> 00:14:44,889
being used as a noun it means an animal

00:14:43,300 --> 00:14:48,850
you know completely different meanings

00:14:44,889 --> 00:14:51,490
so tf-idf really isn't that good at

00:14:48,850 --> 00:14:53,620
solving this but half of the time it

00:14:51,490 --> 00:14:56,709
will get pretty accurate because our

00:14:53,620 --> 00:14:59,019
language isn't that diverse so what's a

00:14:56,709 --> 00:15:01,060
better way to approach this a better way

00:14:59,019 --> 00:15:04,180
is to look at the word sense

00:15:01,060 --> 00:15:06,639
disambiguation and what this means is

00:15:04,180 --> 00:15:08,860
that you actually look at the meaning of

00:15:06,639 --> 00:15:11,620
every word based on the context that

00:15:08,860 --> 00:15:14,920
it's in so once you understand the

00:15:11,620 --> 00:15:16,720
context you know that ok this word

00:15:14,920 --> 00:15:19,000
refers to something completely different

00:15:16,720 --> 00:15:24,069
than it does in this other context

00:15:19,000 --> 00:15:25,839
therefore they are not similar and the

00:15:24,069 --> 00:15:27,189
way you would go about this is you can't

00:15:25,839 --> 00:15:29,170
just sum up all the words in the

00:15:27,189 --> 00:15:31,120
document you have to look at it sentence

00:15:29,170 --> 00:15:35,230
by sentence so that you can get the

00:15:31,120 --> 00:15:37,750
correct context so once you determine

00:15:35,230 --> 00:15:41,350
the meaning of each word within each

00:15:37,750 --> 00:15:44,139
context you would take another step and

00:15:41,350 --> 00:15:46,730
look at the lemmas now ulema is

00:15:44,139 --> 00:15:49,760
basically like an adjective

00:15:46,730 --> 00:15:52,070
but the true way of describing one ulema

00:15:49,760 --> 00:15:54,320
is is its it's the meaning of the word

00:15:52,070 --> 00:15:56,540
when it's in your head before you

00:15:54,320 --> 00:15:58,040
actually speak the word that's that's

00:15:56,540 --> 00:16:00,529
the true definition it's hard to

00:15:58,040 --> 00:16:03,589
describe but it's basically a synonym so

00:16:00,529 --> 00:16:08,240
it's the true like abstracted meaning of

00:16:03,589 --> 00:16:11,000
that word so we will look at each

00:16:08,240 --> 00:16:12,829
sentence identify the meaning of the

00:16:11,000 --> 00:16:15,829
word within that sentence and then look

00:16:12,829 --> 00:16:18,380
at lemmas or synonyms of that word

00:16:15,829 --> 00:16:20,300
within its context and when we do that

00:16:18,380 --> 00:16:22,160
and compare two documents we'll

00:16:20,300 --> 00:16:27,709
definitely have a much better sense for

00:16:22,160 --> 00:16:30,410
how similar they are so here's our same

00:16:27,709 --> 00:16:34,910
example once again I went to the bank to

00:16:30,410 --> 00:16:37,699
deposit money here we identify bank as a

00:16:34,910 --> 00:16:40,370
meaning and it is in this case I find a

00:16:37,699 --> 00:16:43,130
financial institution that accepts

00:16:40,370 --> 00:16:46,699
deposits and channels the money dilemmas

00:16:43,130 --> 00:16:49,360
would be Bank banking company financial

00:16:46,699 --> 00:16:52,459
institution there's probably more and

00:16:49,360 --> 00:16:54,829
then in our other example I slid down

00:16:52,459 --> 00:16:57,100
the bank by the lake here we identify

00:16:54,829 --> 00:17:00,579
the meaning of Bank to mean sloping land

00:16:57,100 --> 00:17:04,160
especially besides a body of water and

00:17:00,579 --> 00:17:09,079
dilemmas would be slope curved side edge

00:17:04,160 --> 00:17:11,929
Shore shoreline etc so if we were using

00:17:09,079 --> 00:17:14,329
word sense disambiguation to compare the

00:17:11,929 --> 00:17:17,799
similarity of these we would not even

00:17:14,329 --> 00:17:17,799
put them in the same class whatsoever

00:17:18,189 --> 00:17:24,199
and then the third topic on natural

00:17:22,640 --> 00:17:27,140
language processing that we used was

00:17:24,199 --> 00:17:29,600
sentiment analysis now this is something

00:17:27,140 --> 00:17:31,669
that can be very difficult and things

00:17:29,600 --> 00:17:34,970
such as the IBM Watson and many other

00:17:31,669 --> 00:17:37,070
big AI programs you know really try to

00:17:34,970 --> 00:17:39,530
pinpoint this down but there are some

00:17:37,070 --> 00:17:41,630
very simple ways of doing it but

00:17:39,530 --> 00:17:43,940
basically what sentiment analysis means

00:17:41,630 --> 00:17:46,130
is determining the feeling of the text

00:17:43,940 --> 00:17:47,919
you know is it positive or is it

00:17:46,130 --> 00:17:50,660
negative that's the most common

00:17:47,919 --> 00:17:53,179
implementation of it but when you

00:17:50,660 --> 00:17:56,470
combine it with other forms of NLP you

00:17:53,179 --> 00:17:59,740
can get a deeper level of what kind of

00:17:56,470 --> 00:18:02,380
is actually being expressed you know

00:17:59,740 --> 00:18:04,330
product reviews negative comments on

00:18:02,380 --> 00:18:08,110
things you know they might indicate

00:18:04,330 --> 00:18:10,030
different sentiments within the realm of

00:18:08,110 --> 00:18:11,860
positive and negative so for this

00:18:10,030 --> 00:18:14,559
example we're just gonna do positive or

00:18:11,860 --> 00:18:20,080
negative but we will be determining that

00:18:14,559 --> 00:18:24,809
on every movie description so now to get

00:18:20,080 --> 00:18:28,299
into a little bit of the code so TF idea

00:18:24,809 --> 00:18:30,220
we're getting to is ml TK and we're also

00:18:28,299 --> 00:18:33,159
gonna use Sai kit for this because

00:18:30,220 --> 00:18:34,840
tf-idf is sort of a mathematical thing

00:18:33,159 --> 00:18:37,690
more than anything you're summing up the

00:18:34,840 --> 00:18:40,690
words and comparing the vectors of each

00:18:37,690 --> 00:18:42,460
each document so this is the code that

00:18:40,690 --> 00:18:44,250
we used to do that it's very simple when

00:18:42,460 --> 00:18:49,120
you use the Sai kit

00:18:44,250 --> 00:18:53,289
so Sai kit gives you a tf-idf vectorizer

00:18:49,120 --> 00:18:58,030
and it also gives you the and from there

00:18:53,289 --> 00:18:59,650
you can basically do a fit transform so

00:18:58,030 --> 00:19:01,919
you the first thing you need to do of

00:18:59,650 --> 00:19:05,970
course is clean all the stop words

00:19:01,919 --> 00:19:09,340
punctuation etc out get it into a pure

00:19:05,970 --> 00:19:11,760
pure list of words essentially and we're

00:19:09,340 --> 00:19:13,720
doing that on our film descriptions and

00:19:11,760 --> 00:19:17,830
then we just run them through the

00:19:13,720 --> 00:19:20,590
vectorizer and this here is basically

00:19:17,830 --> 00:19:23,679
building a matrix because you're

00:19:20,590 --> 00:19:27,070
comparing every single film every single

00:19:23,679 --> 00:19:29,890
other film so if there's 400 films

00:19:27,070 --> 00:19:31,929
it's basically Big O of N squared you're

00:19:29,890 --> 00:19:33,490
not comparing it to itself because that

00:19:31,929 --> 00:19:37,929
would be a hundred percent match so it's

00:19:33,490 --> 00:19:40,960
Big O of N squared minus n but what the

00:19:37,929 --> 00:19:43,720
result is is a huge grid of you know you

00:19:40,960 --> 00:19:46,690
can think of all the movies on access Y

00:19:43,720 --> 00:19:49,059
and all the movies once again on axis X

00:19:46,690 --> 00:19:53,130
and how well do they compare to each

00:19:49,059 --> 00:19:55,600
other so it's a big amount of data and

00:19:53,130 --> 00:19:57,370
this link here the site gets pretty

00:19:55,600 --> 00:19:59,350
well-documented so if you're interested

00:19:57,370 --> 00:20:02,020
definitely check it out it's a little

00:19:59,350 --> 00:20:04,870
bit difficult to install imp it because

00:20:02,020 --> 00:20:07,059
it requires Syfy as a

00:20:04,870 --> 00:20:09,100
pre-requisite and doing all those

00:20:07,059 --> 00:20:11,679
requires a good amount of compiling and

00:20:09,100 --> 00:20:13,929
C libraries and stuff but it is just a

00:20:11,679 --> 00:20:17,799
pit package so you can definitely

00:20:13,929 --> 00:20:22,270
install that so it's very easy to do

00:20:17,799 --> 00:20:26,529
tf--idf word sense disambiguation a lot

00:20:22,270 --> 00:20:36,400
more difficult so we'll dive into the

00:20:26,529 --> 00:20:44,080
code a little bit for that so you can

00:20:36,400 --> 00:20:46,380
see that my are tf-idf function can't

00:20:44,080 --> 00:20:46,380
see it

00:20:51,750 --> 00:20:56,909
so the tf-idf function this is the exact

00:20:55,299 --> 00:20:59,230
same code that was just in the slide

00:20:56,909 --> 00:21:04,149
relatively simple you know you basically

00:20:59,230 --> 00:21:08,169
use a SK learn to build a vector for

00:21:04,149 --> 00:21:09,970
that word sense disambiguation is a

00:21:08,169 --> 00:21:12,460
little bit more involved because you'll

00:21:09,970 --> 00:21:14,350
basically want to do the same thing you

00:21:12,460 --> 00:21:17,080
want to build a matrix to see how

00:21:14,350 --> 00:21:19,390
similar are is is each movie to each

00:21:17,080 --> 00:21:21,250
other movie but you're not looking

00:21:19,390 --> 00:21:23,799
exactly at the words in that description

00:21:21,250 --> 00:21:26,320
you're looking at the meaning of each

00:21:23,799 --> 00:21:29,500
word and then breaking back down and to

00:21:26,320 --> 00:21:32,950
look for similar lemmas so if in the

00:21:29,500 --> 00:21:35,260
case of the bank example if one document

00:21:32,950 --> 00:21:37,090
contains the word Bank and we know that

00:21:35,260 --> 00:21:38,740
it means a financial institution and

00:21:37,090 --> 00:21:42,250
another document contains the word

00:21:38,740 --> 00:21:43,779
finance we will still count those as

00:21:42,250 --> 00:21:46,870
being similar even though they're

00:21:43,779 --> 00:21:49,120
different words so to do that there's a

00:21:46,870 --> 00:21:52,149
lot of looping and a lot of good stuff

00:21:49,120 --> 00:21:54,820
that needs to happen and in this

00:21:52,149 --> 00:21:58,600
implementation I sort of fit it manually

00:21:54,820 --> 00:22:00,279
we did not use the tf-idf vectorizer so

00:21:58,600 --> 00:22:04,210
basically loop through each sentence

00:22:00,279 --> 00:22:07,360
here tokenize it based on the sentence

00:22:04,210 --> 00:22:09,039
level not if the word level look for the

00:22:07,360 --> 00:22:10,809
important words which is basically

00:22:09,039 --> 00:22:15,460
removing all the stop words you know

00:22:10,809 --> 00:22:18,929
remove your does and etc and then use

00:22:15,460 --> 00:22:21,370
the less word sense disambiguation

00:22:18,929 --> 00:22:24,429
algorithm which is built right into NL

00:22:21,370 --> 00:22:27,850
TK and it's the less algorithm I'm not

00:22:24,429 --> 00:22:29,710
exactly sure about the details of what

00:22:27,850 --> 00:22:34,120
these algorithms do but it's built into

00:22:29,710 --> 00:22:36,789
NL TK and this what this does here this

00:22:34,120 --> 00:22:39,399
is really the magic function call you

00:22:36,789 --> 00:22:41,530
give it the tokens from the sentence and

00:22:39,399 --> 00:22:43,090
the specific word that you want to

00:22:41,530 --> 00:22:45,399
identify the meaning of it in the

00:22:43,090 --> 00:22:47,830
sentence so in this case word would be

00:22:45,399 --> 00:22:51,429
Bank and the sentence would be I

00:22:47,830 --> 00:22:53,409
deposited money in the bank and it will

00:22:51,429 --> 00:22:55,630
give you the sin set in return which is

00:22:53,409 --> 00:22:59,020
the list of all the letters and the

00:22:55,630 --> 00:23:00,980
synonyms so what I'm going to do now is

00:22:59,020 --> 00:23:03,799
add all of those synonyms

00:23:00,980 --> 00:23:05,690
everything to my words to check for so

00:23:03,799 --> 00:23:07,370
the words that I'm checking for might

00:23:05,690 --> 00:23:09,440
actually be larger than the document

00:23:07,370 --> 00:23:13,549
itself because I want to find everything

00:23:09,440 --> 00:23:15,980
that's similar to it and then from there

00:23:13,549 --> 00:23:18,260
we basically now we have a complete list

00:23:15,980 --> 00:23:20,929
of words check for based on meanings and

00:23:18,260 --> 00:23:23,540
the llamas two synonyms now we're going

00:23:20,929 --> 00:23:25,640
to do the the nested for loop where we

00:23:23,540 --> 00:23:28,750
that we look through and build that

00:23:25,640 --> 00:23:33,020
matrix and cross compare every document

00:23:28,750 --> 00:23:35,570
so the results of this are sometimes

00:23:33,020 --> 00:23:42,280
very similar to tf-idf and sometimes

00:23:35,570 --> 00:23:42,280
very different and I will show you

00:23:57,789 --> 00:24:06,080
the comparator object was what I'm using

00:24:01,340 --> 00:24:09,200
to compare the similarity of two movies

00:24:06,080 --> 00:24:12,650
so here you can see one one film name

00:24:09,200 --> 00:24:14,720
xylose one name you carry me the tf-idf

00:24:12,650 --> 00:24:15,770
which is basically seeing how many words

00:24:14,720 --> 00:24:19,120
that they have in common

00:24:15,770 --> 00:24:23,210
it's scores point zero one three zero

00:24:19,120 --> 00:24:27,049
means zero in common one means 100% in

00:24:23,210 --> 00:24:29,419
common here at 0.01 which means not

00:24:27,049 --> 00:24:32,000
there not very close at all the word

00:24:29,419 --> 00:24:34,130
Sanson disambiguation actually scores a

00:24:32,000 --> 00:24:40,070
little bit higher because there probably

00:24:34,130 --> 00:24:42,980
are some synonyms if you look at a few

00:24:40,070 --> 00:24:45,590
others you can see that there are some

00:24:42,980 --> 00:24:47,809
differences usually the word sense

00:24:45,590 --> 00:24:52,130
disambiguation scores them more similar

00:24:47,809 --> 00:24:55,100
than term frequency document and

00:24:52,130 --> 00:24:56,990
frequency so we go through those metrics

00:24:55,100 --> 00:25:07,940
to when we're deciding okay how similar

00:24:56,990 --> 00:25:09,650
really are these and then the third but

00:25:07,940 --> 00:25:11,150
kind of the fun one here is sentiment

00:25:09,650 --> 00:25:14,510
analysis and this one's also really easy

00:25:11,150 --> 00:25:17,240
to do because it meant ltk so we're

00:25:14,510 --> 00:25:19,340
using the Vator sentiment and analyzer

00:25:17,240 --> 00:25:22,669
which is once again an algorithm and

00:25:19,340 --> 00:25:24,620
it's built into NLT kay it's

00:25:22,669 --> 00:25:27,980
particularly relevant in our case

00:25:24,620 --> 00:25:30,590
because the way this algorithm works is

00:25:27,980 --> 00:25:32,630
it was trained from a data set and this

00:25:30,590 --> 00:25:34,850
data set consisted of ten thousand

00:25:32,630 --> 00:25:37,640
tweets and ten thousand movie reviews

00:25:34,850 --> 00:25:40,570
and I forget when this was trained but I

00:25:37,640 --> 00:25:43,700
want to say it was a maybe like

00:25:40,570 --> 00:25:44,809
2011-2012 sometime around then it may

00:25:43,700 --> 00:25:48,590
have changed a little bit

00:25:44,809 --> 00:25:50,929
but in each one of those tweets and

00:25:48,590 --> 00:25:53,690
movie reviews was tagged by human as

00:25:50,929 --> 00:25:56,480
saying okay this one's positive or this

00:25:53,690 --> 00:25:59,210
one's negative you then feed those into

00:25:56,480 --> 00:26:03,270
the into the computer into the algorithm

00:25:59,210 --> 00:26:05,850
and it learns based on the

00:26:03,270 --> 00:26:09,690
syntax and grammar and and the word

00:26:05,850 --> 00:26:12,659
choices what a positive text looks like

00:26:09,690 --> 00:26:15,630
and what a negative text looks like so

00:26:12,659 --> 00:26:17,010
from here you can basically feed

00:26:15,630 --> 00:26:19,620
anything you want into the Vator

00:26:17,010 --> 00:26:21,960
algorithm and it will scale it from

00:26:19,620 --> 00:26:24,750
negative one to positive one

00:26:21,960 --> 00:26:28,080
whether it's 100% negative or hundred

00:26:24,750 --> 00:26:32,190
percent positive based on its learning

00:26:28,080 --> 00:26:33,900
data its training set so because it was

00:26:32,190 --> 00:26:40,740
trained on movie reviews it was pretty

00:26:33,900 --> 00:26:42,690
pretty relevant to us I think and once

00:26:40,740 --> 00:26:46,260
again the code is very simple for this

00:26:42,690 --> 00:26:49,230
because it already exists in the NLT kay

00:26:46,260 --> 00:26:52,169
you have a sentiment intensity analyzer

00:26:49,230 --> 00:26:57,750
object you're looking easier than that

00:26:52,169 --> 00:26:59,789
so all you have to do is in our case

00:26:57,750 --> 00:27:01,950
clean up the data a little bit run it

00:26:59,789 --> 00:27:04,200
through the polarity scoring function

00:27:01,950 --> 00:27:06,960
and what we're looking for is the

00:27:04,200 --> 00:27:09,659
compound score it does produce a lot of

00:27:06,960 --> 00:27:12,030
other scores and metrics the compound

00:27:09,659 --> 00:27:14,760
score is sort of the overall the average

00:27:12,030 --> 00:27:17,850
just you know which is what we wanted in

00:27:14,760 --> 00:27:19,230
this case and and that's really all you

00:27:17,850 --> 00:27:21,830
have to do so we just loop through the

00:27:19,230 --> 00:27:24,090
movies run it through the NLT kay

00:27:21,830 --> 00:27:26,220
functionality and it gives you that so

00:27:24,090 --> 00:27:28,520
in some ways it makes you seem a lot

00:27:26,220 --> 00:27:30,690
smarter than you actually are

00:27:28,520 --> 00:27:31,950
and I'll show you a quick example I

00:27:30,690 --> 00:27:38,010
should have started out with this too

00:27:31,950 --> 00:27:40,710
but this was the the site that we made

00:27:38,010 --> 00:27:43,380
and it used to show you now playing and

00:27:40,710 --> 00:27:46,559
recently ended obviously it's all over

00:27:43,380 --> 00:27:51,870
but there are a few lists that we can

00:27:46,559 --> 00:27:56,789
pull from and we represented that as a

00:27:51,870 --> 00:27:58,440
dark plot or a upbeat plot because if

00:27:56,789 --> 00:28:00,450
pertaining to movie reviews that's what

00:27:58,440 --> 00:28:02,309
are not reviews but movie descriptions

00:28:00,450 --> 00:28:06,720
that's what it it most closely

00:28:02,309 --> 00:28:09,000
correspond to so this chart here just

00:28:06,720 --> 00:28:14,480
goes from negative one to positive one

00:28:09,000 --> 00:28:17,150
and it varies per it varies per film

00:28:14,480 --> 00:28:19,160
I did read through a few of them myself

00:28:17,150 --> 00:28:20,720
to kind of spot check-in in general it's

00:28:19,160 --> 00:28:23,270
pretty accurate there are a few that

00:28:20,720 --> 00:28:26,299
we're kind of off but in general it was

00:28:23,270 --> 00:28:29,179
pretty accurate so very good

00:28:26,299 --> 00:28:31,010
functionality right there in ml TK an NL

00:28:29,179 --> 00:28:33,320
TK is primarily designed to be a

00:28:31,010 --> 00:28:36,380
academic type thing just to learn and to

00:28:33,320 --> 00:28:38,120
play on it's probably not very good for

00:28:36,380 --> 00:28:40,220
doing any real you know if you're

00:28:38,120 --> 00:28:41,540
looking at a business functionality or

00:28:40,220 --> 00:28:44,480
something it would not be good for that

00:28:41,540 --> 00:28:53,780
but for projects like this you know it's

00:28:44,480 --> 00:28:55,580
great so that's what we did and so now

00:28:53,780 --> 00:28:59,480
that we have established three different

00:28:55,580 --> 00:29:01,970
forms of natural language processing the

00:28:59,480 --> 00:29:03,040
descriptions of these movies it's time

00:29:01,970 --> 00:29:05,840
to crunch the numbers

00:29:03,040 --> 00:29:08,090
so our crawler pulled in three hundred

00:29:05,840 --> 00:29:11,500
and four hundred and thirty six films

00:29:08,090 --> 00:29:15,169
from the cleveland film that org website

00:29:11,500 --> 00:29:17,540
we did tf-idf on each film compared to

00:29:15,169 --> 00:29:20,660
each one so that was a big ol n squared

00:29:17,540 --> 00:29:24,260
and we also did the word sense

00:29:20,660 --> 00:29:25,940
disambiguation on each one so we broke

00:29:24,260 --> 00:29:29,090
it down into every sentence of every

00:29:25,940 --> 00:29:30,440
review and cross compared all that once

00:29:29,090 --> 00:29:32,299
again we ended up with one hundred

00:29:30,440 --> 00:29:34,549
eighty nine thousand comparisons by the

00:29:32,299 --> 00:29:37,669
time our database was fully populated

00:29:34,549 --> 00:29:41,090
and as I mentioned we use the comparator

00:29:37,669 --> 00:29:44,090
model to store the the comparison

00:29:41,090 --> 00:29:46,130
between each each film so the actual

00:29:44,090 --> 00:29:47,630
movie model itself doesn't contain any

00:29:46,130 --> 00:29:55,570
of that it just contains the movie

00:29:47,630 --> 00:29:58,429
information and how we did that was

00:29:55,570 --> 00:30:01,160
through a set of management commands

00:29:58,429 --> 00:30:02,929
okay and I'm going way too slow here so

00:30:01,160 --> 00:30:05,720
I'll speed it up that was a general

00:30:02,929 --> 00:30:09,640
management command and then the last

00:30:05,720 --> 00:30:12,530
good part of this was the Twitter API so

00:30:09,640 --> 00:30:14,000
doing this is very very simple if you're

00:30:12,530 --> 00:30:18,200
just doing it with your own Twitter

00:30:14,000 --> 00:30:19,850
account this is what we did which looks

00:30:18,200 --> 00:30:24,320
a little bit complicated but the simple

00:30:19,850 --> 00:30:26,070
form using twice on is super simple you

00:30:24,320 --> 00:30:30,010
just create a Twitter app

00:30:26,070 --> 00:30:32,679
at a Twitter comm since you're the owner

00:30:30,010 --> 00:30:34,540
of it has access to your account and you

00:30:32,679 --> 00:30:38,710
can access all of your API keys right

00:30:34,540 --> 00:30:41,530
there a tap Twitter comm you basically

00:30:38,710 --> 00:30:44,350
plug those into into twice on and you

00:30:41,530 --> 00:30:48,250
can send a tweet so I will send a quick

00:30:44,350 --> 00:30:55,300
tweet here just to just to show it off

00:30:48,250 --> 00:30:58,920
because it's kind of cool and I made my

00:30:55,300 --> 00:30:58,920
Django Khan tweet function here

00:31:08,300 --> 00:31:13,490
as literally as simple as doing that

00:31:11,150 --> 00:31:16,370
calling twice on Twitter about update

00:31:13,490 --> 00:31:30,020
status and if I run my management

00:31:16,370 --> 00:31:35,500
command I get a Django 1.10 deprecation

00:31:30,020 --> 00:31:46,040
warning but then I also get we did and

00:31:35,500 --> 00:31:50,620
if you check out the Twitter site right

00:31:46,040 --> 00:31:50,620
there so all we did was use a cron job

00:31:51,010 --> 00:31:57,230
which is basically a one-liner where you

00:31:53,960 --> 00:32:01,310
in your cron entry you enter the virtual

00:31:57,230 --> 00:32:03,890
environment that your your projects

00:32:01,310 --> 00:32:08,090
running in you run the management

00:32:03,890 --> 00:32:10,880
command and then you just specify to log

00:32:08,090 --> 00:32:12,350
it so we just ran that every five

00:32:10,880 --> 00:32:15,050
minutes and it would run through and

00:32:12,350 --> 00:32:18,500
query the database and tweet out what

00:32:15,050 --> 00:32:20,030
was coming up so so that's uh that's the

00:32:18,500 --> 00:32:21,440
bulk of our project I hope you got

00:32:20,030 --> 00:32:25,540
something out of it I don't know if we

00:32:21,440 --> 00:32:25,540
have any time for Q&A few minutes maybe

00:32:30,190 --> 00:32:33,190
prevent

00:32:40,870 --> 00:32:44,570
thanks for talk I was just gonna say the

00:32:42,980 --> 00:32:46,250
website look really nice I was going to

00:32:44,570 --> 00:32:48,200
ask what sort of friend frameworks to

00:32:46,250 --> 00:32:51,650
use for that so for this one we just

00:32:48,200 --> 00:32:55,730
used materialized CSS it's basically a

00:32:51,650 --> 00:32:57,620
clone of the Google material design it's

00:32:55,730 --> 00:32:59,659
very simple pretty good I found a couple

00:32:57,620 --> 00:33:01,820
little bugs in it we normally use

00:32:59,659 --> 00:33:03,049
bootstrap for most stuff but we we

00:33:01,820 --> 00:33:05,030
wanted this to have a little Android

00:33:03,049 --> 00:33:14,659
feel since it's kind of robot theme so

00:33:05,030 --> 00:33:17,289
yeah materialize that CSS have you

00:33:14,659 --> 00:33:22,250
thought about the possibility of

00:33:17,289 --> 00:33:25,460
evaluating your comparison algorithm by

00:33:22,250 --> 00:33:27,650
say piping a front-end into something

00:33:25,460 --> 00:33:29,750
like Netflix where there's a what we

00:33:27,650 --> 00:33:31,700
already have a wide knowledge of the

00:33:29,750 --> 00:33:33,830
movies that are out there and you would

00:33:31,700 --> 00:33:37,130
be able to you could you can make a kind

00:33:33,830 --> 00:33:40,220
of a qualitative analysis of how well

00:33:37,130 --> 00:33:42,710
your engine performed with movies that

00:33:40,220 --> 00:33:45,470
would be yeah that's a great idea and

00:33:42,710 --> 00:33:48,860
once again enlarging our data set to

00:33:45,470 --> 00:33:50,510
would be great because the sentiment

00:33:48,860 --> 00:33:53,120
analysis was just off with a small

00:33:50,510 --> 00:33:55,549
subset of ten thousand reviews and our

00:33:53,120 --> 00:33:57,230
own comparisons were just programmatic

00:33:55,549 --> 00:34:00,260
they were not going off of any existing

00:33:57,230 --> 00:34:01,909
data so yeah probably for version two we

00:34:00,260 --> 00:34:06,610
would want to compare that to an outside

00:34:01,909 --> 00:34:06,610
source of data for even more accuracy

00:34:08,530 --> 00:34:12,830
hey yeah

00:34:10,099 --> 00:34:17,869
so I'm not terribly deeply familiar with

00:34:12,830 --> 00:34:19,280
n LT K but I wondered the previous

00:34:17,869 --> 00:34:21,589
question did you test how well it

00:34:19,280 --> 00:34:27,230
performed and how could you do that was

00:34:21,589 --> 00:34:32,780
was good I also wondered why you did the

00:34:27,230 --> 00:34:35,300
parsing with beautifulsoup more by hand

00:34:32,780 --> 00:34:38,960
than using a tool like scrapy that is

00:34:35,300 --> 00:34:44,060
probably probably heavier you know it's

00:34:38,960 --> 00:34:45,679
just it's just 300 movies so but I think

00:34:44,060 --> 00:34:49,339
the biggest thing I wanted to mention is

00:34:45,679 --> 00:34:49,970
that it turns out looking googling on n

00:34:49,339 --> 00:34:51,590
LT care

00:34:49,970 --> 00:34:54,649
while you're doing the presentation

00:34:51,590 --> 00:34:57,290
since I'm familiar with open NLP and you

00:34:54,649 --> 00:34:59,720
know Java stuff is that it was developed

00:34:57,290 --> 00:35:07,849
at you can and the other comment I

00:34:59,720 --> 00:35:10,670
wanted to make was that because this was

00:35:07,849 --> 00:35:12,800
it took me a moment to understand I had

00:35:10,670 --> 00:35:17,320
to sort of think about it myself while

00:35:12,800 --> 00:35:20,540
you were talking because this was for

00:35:17,320 --> 00:35:23,170
Cleveland Film Festival there wasn't any

00:35:20,540 --> 00:35:25,099
need to do a search function you know

00:35:23,170 --> 00:35:26,990
people were already there they were

00:35:25,099 --> 00:35:30,230
looking at the schedule what do I go see

00:35:26,990 --> 00:35:31,940
next you know and I think if you do this

00:35:30,230 --> 00:35:33,170
again that would be a good thing to

00:35:31,940 --> 00:35:35,359
point out because people of Raleigh

00:35:33,170 --> 00:35:37,790
familiar with you know how you would do

00:35:35,359 --> 00:35:39,800
this with search just pipe it into solar

00:35:37,790 --> 00:35:42,830
or something or elasticsearch you know

00:35:39,800 --> 00:35:44,660
yeah and actually I if we had a little

00:35:42,830 --> 00:35:48,500
more time I I went a little too in

00:35:44,660 --> 00:35:50,119
detail but I did there if you want to

00:35:48,500 --> 00:35:53,119
download the slides there are a few

00:35:50,119 --> 00:35:56,420
additional ones with haystack and woosh

00:35:53,119 --> 00:35:58,070
just to do a really simple search and it

00:35:56,420 --> 00:36:00,680
wasn't really relevant to any of the NLP

00:35:58,070 --> 00:36:05,300
stuff it was just part of the website

00:36:00,680 --> 00:36:07,400
that we made you know to search through

00:36:05,300 --> 00:36:10,820
that information it just made a simple

00:36:07,400 --> 00:36:12,890
search up there so once again not

00:36:10,820 --> 00:36:14,660
relevant to the NLP or the Twitter part

00:36:12,890 --> 00:36:16,940
but it was part of the whole project so

00:36:14,660 --> 00:36:18,800
there are a few slides on implementing a

00:36:16,940 --> 00:36:21,380
really simple haystack search and like

00:36:18,800 --> 00:36:24,369
three steps so if you are interested in

00:36:21,380 --> 00:36:24,369
in some searching

00:36:27,830 --> 00:36:38,420
I didn't understand why you used the

00:36:35,600 --> 00:36:41,960
managed PI interfaces so just calling

00:36:38,420 --> 00:36:44,630
the Python code directly so the reason

00:36:41,960 --> 00:36:46,490
we use that was because every all the

00:36:44,630 --> 00:36:50,030
Python code needed to run within the

00:36:46,490 --> 00:36:52,250
Django environment so oh yeah so that's

00:36:50,030 --> 00:36:55,940
fine I guess you could drop into the

00:36:52,250 --> 00:36:57,470
Django shell and call it but the

00:36:55,940 --> 00:36:59,480
management command provides sort of a

00:36:57,470 --> 00:37:01,520
simple way to do that rather than having

00:36:59,480 --> 00:37:03,380
to drop into the management shell so

00:37:01,520 --> 00:37:05,920
that you can access the models in the

00:37:03,380 --> 00:37:05,920
environment

00:37:24,079 --> 00:37:28,279
since you did the work to have the word

00:37:26,059 --> 00:37:31,130
sense disambiguation why did you keep

00:37:28,279 --> 00:37:33,799
the original method against the word

00:37:31,130 --> 00:37:37,160
count comparison we sort of kept it

00:37:33,799 --> 00:37:40,219
almost as a crude benchmark to see is

00:37:37,160 --> 00:37:42,650
there really a difference and originally

00:37:40,219 --> 00:37:44,390
when we had our when we had the the

00:37:42,650 --> 00:37:47,599
website where you it would show you the

00:37:44,390 --> 00:37:50,029
similarity you know this is just making

00:37:47,599 --> 00:37:52,099
a simple jangled query to pulled up the

00:37:50,029 --> 00:37:57,529
most similar ones just ordering top -

00:37:52,099 --> 00:37:59,569
Louis we we did it with tf-idf and then

00:37:57,529 --> 00:38:00,829
some of them are not very similar so

00:37:59,569 --> 00:38:04,630
we're like ok let's try a better way so

00:38:00,829 --> 00:38:07,130
we did word sense disambiguation and the

00:38:04,630 --> 00:38:09,619
similarity results changed when we

00:38:07,130 --> 00:38:11,839
reloaded the page basically and they're

00:38:09,619 --> 00:38:14,119
a lot more accurate so we have both in

00:38:11,839 --> 00:38:16,039
there for reference but we primarily

00:38:14,119 --> 00:38:23,779
looked at the word sense disambiguation

00:38:16,039 --> 00:38:25,459
first tf-idf second all right thank you

00:38:23,779 --> 00:38:27,789
everyone for coming another hand for

00:38:25,459 --> 00:38:27,789

YouTube URL: https://www.youtube.com/watch?v=aXFFHKkQcQg


