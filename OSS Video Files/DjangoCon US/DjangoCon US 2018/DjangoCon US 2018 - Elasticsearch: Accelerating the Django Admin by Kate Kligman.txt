Title: DjangoCon US 2018 - Elasticsearch: Accelerating the Django Admin by Kate Kligman
Publication date: 2018-11-08
Playlist: DjangoCon US 2018
Description: 
	DjangoCon US 2018 - Elasticsearch: Accelerating the Django Admin by Kate Kligman

The Django Admin offers quick solutions and rapid feature development for new websites. But as your website expands, and datasets grow, it can become unwieldy and slow. Enter Elasticsearch: an easy way to quickly accelerate your Django administration tools and searches.

At Grove Collaborative, weâ€™ve experimented with Elasticsearch technology and developed reusable patterns that brought new life to our aging Django administration system. This presentation will teach you how to leverage easy Elasticsearch wins while avoiding common pitfalls.

This talk was presented at: https://2018.djangocon.us/talk/elasticsearch-accelerating-the-django/

LINKS:
Follow Kate Kligman ðŸ‘‡
On Twitter: https://twitter.com/KateKligman
Official homepage: https://www.katekligman.com

Follow DjangCon US ðŸ‘‡
https://twitter.com/djangocon

Follow DEFNA ðŸ‘‡
https://twitter.com/defnado
https://www.defna.org/
Captions: 
	00:00:00,050 --> 00:00:07,709
[Music]

00:00:15,770 --> 00:00:21,779
all right so we're just about ready to

00:00:19,109 --> 00:00:24,109
start thank you everyone for coming to

00:00:21,779 --> 00:00:27,119
my talk today I'll be talking about

00:00:24,109 --> 00:00:29,939
elasticsearch and accelerating the

00:00:27,119 --> 00:00:32,520
Django admin my name is Kate Kligman and

00:00:29,939 --> 00:00:35,280
I am a staff engineer on Grove

00:00:32,520 --> 00:00:37,680
collaborative platform team I'll be

00:00:35,280 --> 00:00:39,719
posting the slides for this talk on my

00:00:37,680 --> 00:00:42,239
Twitter account and website soon after

00:00:39,719 --> 00:00:46,950
so you'll be able to look at some of the

00:00:42,239 --> 00:00:50,370
code snippets growth collaborative is a

00:00:46,950 --> 00:00:52,500
SAN francisco-based startup we are a

00:00:50,370 --> 00:00:56,879
django shop right now we're running a

00:00:52,500 --> 00:00:59,579
monolithic setup with the 1.11 line we

00:00:56,879 --> 00:01:02,280
host with Heroku I'd say we're kind of

00:00:59,579 --> 00:01:04,400
like mid to end of life on Heroku

00:01:02,280 --> 00:01:07,760
because we are expanding quite rapidly

00:01:04,400 --> 00:01:08,939
we also have a fairly beefy set up on

00:01:07,760 --> 00:01:12,659
Amazon's

00:01:08,939 --> 00:01:15,119
RDS Postgres and our solution for a long

00:01:12,659 --> 00:01:18,119
time has been if the website is slow add

00:01:15,119 --> 00:01:21,930
another read replica and everything will

00:01:18,119 --> 00:01:25,200
be all right but then there was that one

00:01:21,930 --> 00:01:29,310
time that we grew over 7,000 percent in

00:01:25,200 --> 00:01:32,520
three years and adding read replicas

00:01:29,310 --> 00:01:36,030
didn't quite cut it anymore on the one

00:01:32,520 --> 00:01:38,340
hand we made ink Magazine's top 5,000

00:01:36,030 --> 00:01:41,640
fast growing startups we were number 37

00:01:38,340 --> 00:01:44,610
on the list this year but on the other

00:01:41,640 --> 00:01:46,710
hand we had a Django admin that we

00:01:44,610 --> 00:01:49,860
desperately wanted to survive this

00:01:46,710 --> 00:01:53,399
transition the Django admin has been

00:01:49,860 --> 00:01:56,189
very important for us in the past

00:01:53,399 --> 00:01:58,560
because we hadn't yet reached the point

00:01:56,189 --> 00:02:00,540
where a lot of our customer service

00:01:58,560 --> 00:02:02,880
tools would be spun off into their own

00:02:00,540 --> 00:02:05,670
systems the company started with a

00:02:02,880 --> 00:02:08,340
monolith and we still have that monolith

00:02:05,670 --> 00:02:10,860
and so protecting the monolith so that

00:02:08,340 --> 00:02:13,110
we can move into the next phases of

00:02:10,860 --> 00:02:16,870
growth was critically important to us

00:02:13,110 --> 00:02:19,840
likewise preserving the Django admins

00:02:16,870 --> 00:02:22,780
full-text search was important as well

00:02:19,840 --> 00:02:25,570
we have customer service representatives

00:02:22,780 --> 00:02:28,510
who have to perform a substantial amount

00:02:25,570 --> 00:02:31,150
of customer lookups and it's much less

00:02:28,510 --> 00:02:33,100
cognitively challenging for someone to

00:02:31,150 --> 00:02:35,500
rapid-fire lookup if they're just

00:02:33,100 --> 00:02:39,910
pointing and clicking into a single text

00:02:35,500 --> 00:02:43,240
field so we didn't care so much about

00:02:39,910 --> 00:02:45,280
the other portions of the admin quite

00:02:43,240 --> 00:02:47,320
simply put we wanted to be able to

00:02:45,280 --> 00:02:49,920
search from it and display records and

00:02:47,320 --> 00:02:52,990
then navigate the data structures

00:02:49,920 --> 00:02:58,630
without the admin taking too long to do

00:02:52,990 --> 00:03:01,150
so this was our data model for search we

00:02:58,630 --> 00:03:03,880
simply had a first name a last name an

00:03:01,150 --> 00:03:06,340
email address and phone number and the

00:03:03,880 --> 00:03:12,400
first line of a customer's street

00:03:06,340 --> 00:03:16,810
address just one address but behind the

00:03:12,400 --> 00:03:21,700
scenes Django would produce a query like

00:03:16,810 --> 00:03:25,239
this now it would full text search all

00:03:21,700 --> 00:03:26,970
of the fields transform them and then on

00:03:25,239 --> 00:03:30,010
top of that it would walk any

00:03:26,970 --> 00:03:32,350
relationships that we had when there

00:03:30,010 --> 00:03:33,940
were a few thousand records this flu it

00:03:32,350 --> 00:03:36,400
was pretty good when there were a few

00:03:33,940 --> 00:03:38,320
hundred thousand records worked fine a

00:03:36,400 --> 00:03:41,260
few million records that still worked

00:03:38,320 --> 00:03:44,130
but it would add a few seconds to the

00:03:41,260 --> 00:03:47,650
search but as we expanded beyond that

00:03:44,130 --> 00:03:50,140
the time that it took to perform a

00:03:47,650 --> 00:03:52,000
search increased considerably at the

00:03:50,140 --> 00:03:54,489
time we started the project to migrate

00:03:52,000 --> 00:03:57,310
our search to elastic we were at the 12

00:03:54,489 --> 00:04:02,860
second mark meaning that one query took

00:03:57,310 --> 00:04:04,420
12 seconds and the doing a single field

00:04:02,860 --> 00:04:06,340
full-text search almost doesn't matter

00:04:04,420 --> 00:04:08,799
if it takes so long to actually search

00:04:06,340 --> 00:04:12,310
on you have an interface that pretty

00:04:08,799 --> 00:04:14,799
much is unusable and for every couple of

00:04:12,310 --> 00:04:17,109
weeks that we didn't have a solution one

00:04:14,799 --> 00:04:19,600
second would be added to the search time

00:04:17,109 --> 00:04:23,590
so we were it was it was visibly the

00:04:19,600 --> 00:04:25,820
ship was kind of visibly sinking so we

00:04:23,590 --> 00:04:27,230
decided elasticsearch

00:04:25,820 --> 00:04:29,840
we knew we were gonna use a lactis

00:04:27,230 --> 00:04:31,130
elasticsearch almost right away we had

00:04:29,840 --> 00:04:33,410
heard good things about it

00:04:31,130 --> 00:04:36,830
we had some domain experience at the

00:04:33,410 --> 00:04:38,720
company with large data sets and more

00:04:36,830 --> 00:04:40,730
importantly we were designing for

00:04:38,720 --> 00:04:43,400
exponential growth we didn't know when

00:04:40,730 --> 00:04:44,930
our growth would end but we also didn't

00:04:43,400 --> 00:04:46,550
want to be in a position a couple of

00:04:44,930 --> 00:04:48,830
years from now or even six months from

00:04:46,550 --> 00:04:50,810
now where we went with a lesser solution

00:04:48,830 --> 00:04:52,930
and then had to re-engineer everything

00:04:50,810 --> 00:04:56,990
finding ourselves right back in the

00:04:52,930 --> 00:04:58,910
place that we were so full speed ahead

00:04:56,990 --> 00:05:02,240
on elastic search elastic search is an

00:04:58,910 --> 00:05:05,420
open-source project it's written in Java

00:05:02,240 --> 00:05:08,060
it is built by and maintained to the

00:05:05,420 --> 00:05:11,800
folks at elastico so it's a company

00:05:08,060 --> 00:05:11,800
backed well-funded open-source project

00:05:11,830 --> 00:05:17,240
the terminology is a little bit

00:05:14,840 --> 00:05:20,450
different because elastic search itself

00:05:17,240 --> 00:05:22,310
is not a database and it's also not

00:05:20,450 --> 00:05:24,410
really a document store it's an actual

00:05:22,310 --> 00:05:28,850
search engine but it has a lot of

00:05:24,410 --> 00:05:31,850
similarities to sequel so for example an

00:05:28,850 --> 00:05:35,030
elastic search and index is kind of like

00:05:31,850 --> 00:05:37,550
a database and you define mappings which

00:05:35,030 --> 00:05:40,280
sort of act like a schema to define your

00:05:37,550 --> 00:05:42,770
data fields are kind of like columns and

00:05:40,280 --> 00:05:46,900
because elastic searches document based

00:05:42,770 --> 00:05:49,790
that sort of kind of resembles a row

00:05:46,900 --> 00:05:51,650
but unlike sequel elastic search

00:05:49,790 --> 00:05:54,740
mappings are brittle if I wanted to

00:05:51,650 --> 00:05:57,050
change or manipulate my fields after

00:05:54,740 --> 00:05:59,420
I've stored data in them in elastic

00:05:57,050 --> 00:06:02,030
search it's not an uncommon proposition

00:05:59,420 --> 00:06:04,550
to drop the index or the database all

00:06:02,030 --> 00:06:07,280
together and then re-import your data

00:06:04,550 --> 00:06:09,320
and sequel that wouldn't really fly so

00:06:07,280 --> 00:06:11,900
well with large data sets but an elastic

00:06:09,320 --> 00:06:16,010
search because it is so fast it's not a

00:06:11,900 --> 00:06:18,950
problem at all likewise it is fast

00:06:16,010 --> 00:06:20,900
because it uses inverted indexes if I

00:06:18,950 --> 00:06:24,530
had a document that says Django is

00:06:20,900 --> 00:06:28,420
awesome elastic search would split it up

00:06:24,530 --> 00:06:30,890
as directed by us it would then produce

00:06:28,420 --> 00:06:33,470
tokens for each of the things to be

00:06:30,890 --> 00:06:37,220
searched on and it would map them to a

00:06:33,470 --> 00:06:39,620
document ID so if I search for Django

00:06:37,220 --> 00:06:42,590
and this elastic search would say

00:06:39,620 --> 00:06:46,100
document 1 2 3 4 5 has Django and send

00:06:42,590 --> 00:06:48,860
that back to me this is perfect for

00:06:46,100 --> 00:06:51,110
hooking it into the Django ORM 5 a

00:06:48,860 --> 00:06:53,240
customer record and I've split it out

00:06:51,110 --> 00:06:55,670
and this particular one it's my name

00:06:53,240 --> 00:06:58,190
Kate Kligman and a phone number I can

00:06:55,670 --> 00:07:01,790
then correlate that to an elastic search

00:06:58,190 --> 00:07:04,870
document ID and I can set that ID to be

00:07:01,790 --> 00:07:09,140
the primary one of the primary keys on

00:07:04,870 --> 00:07:11,420
my Django model so customer 1 2 3 4 5

00:07:09,140 --> 00:07:15,980
could be my customer ID and this makes

00:07:11,420 --> 00:07:18,110
it very easy to hook into the ORM this

00:07:15,980 --> 00:07:21,650
is what the workflow looks like so I

00:07:18,110 --> 00:07:24,860
perform a search and the admin search

00:07:21,650 --> 00:07:26,860
gets shipped off to elastic elastic

00:07:24,860 --> 00:07:30,110
search will return a list of ID's

00:07:26,860 --> 00:07:32,570
corresponding to the ORM and to my

00:07:30,110 --> 00:07:34,580
sequel databases list of IDs for these

00:07:32,570 --> 00:07:37,550
records and then all I have to do is go

00:07:34,580 --> 00:07:40,760
back to Postgres and look them up and

00:07:37,550 --> 00:07:45,680
rehydrate them this is what it looks

00:07:40,760 --> 00:07:48,380
like so in the top block I'm pulling out

00:07:45,680 --> 00:07:51,410
the IDS that I've set for the results of

00:07:48,380 --> 00:07:53,210
an elastic search query and one cool

00:07:51,410 --> 00:07:56,000
thing about elastic search is that

00:07:53,210 --> 00:08:01,550
because it is a search engine it does

00:07:56,000 --> 00:08:03,440
ranked ordering as well so if I didn't

00:08:01,550 --> 00:08:05,600
care so much about the order of what was

00:08:03,440 --> 00:08:07,400
being returned I could just simply look

00:08:05,600 --> 00:08:09,920
it up using the ORM but in this case

00:08:07,400 --> 00:08:13,360
I've added a little bit of extra code so

00:08:09,920 --> 00:08:17,000
that we can preserve a specificity and

00:08:13,360 --> 00:08:18,800
now that my lookup is a query set I can

00:08:17,000 --> 00:08:22,630
feed that right back into the admin and

00:08:18,800 --> 00:08:22,630
we have a complete customer search

00:08:22,870 --> 00:08:30,080
hooking it into the admin is also pretty

00:08:25,880 --> 00:08:32,690
simple so when I perform a full text

00:08:30,080 --> 00:08:36,530
query search django uses in this case

00:08:32,690 --> 00:08:39,260
for us the Q parameter I can then hook

00:08:36,530 --> 00:08:42,370
it into the class definition there is a

00:08:39,260 --> 00:08:46,220
function called get search results that

00:08:42,370 --> 00:08:48,710
will take a parameter we can then take

00:08:46,220 --> 00:08:53,270
that query there's query terms ship them

00:08:48,710 --> 00:08:55,850
off to elastic and then receive the

00:08:53,270 --> 00:08:58,160
setback rehydrate it into a query set

00:08:55,850 --> 00:09:02,090
and ship it into the admin it's actually

00:08:58,160 --> 00:09:04,700
the simple to do it updating

00:09:02,090 --> 00:09:06,770
elasticsearch isn't so bad either we can

00:09:04,700 --> 00:09:10,010
use post save post create and post

00:09:06,770 --> 00:09:11,330
delete signals model hooks can also be

00:09:10,010 --> 00:09:14,450
used when we're adding data to

00:09:11,330 --> 00:09:16,810
elasticsearch we have to keep it up to

00:09:14,450 --> 00:09:19,550
date I would highly recommend using

00:09:16,810 --> 00:09:21,440
streaming services or scheduled jobs so

00:09:19,550 --> 00:09:24,350
for growth collaborative what we did is

00:09:21,440 --> 00:09:27,260
we have a celery beet process that runs

00:09:24,350 --> 00:09:29,120
every couple of minutes and we pull the

00:09:27,260 --> 00:09:31,580
customers table to see if any records

00:09:29,120 --> 00:09:35,030
have been updated if they've been

00:09:31,580 --> 00:09:37,190
updated then we pull the records ship

00:09:35,030 --> 00:09:40,450
the relevant portions off to

00:09:37,190 --> 00:09:44,360
elasticsearch and we are good to go and

00:09:40,450 --> 00:09:46,070
in our particular use case the interval

00:09:44,360 --> 00:09:49,360
is important because we have customer

00:09:46,070 --> 00:09:52,100
service representatives querying this

00:09:49,360 --> 00:09:53,960
system all of the time so for customer

00:09:52,100 --> 00:09:55,460
within the first few minutes of a

00:09:53,960 --> 00:09:57,980
customer's interaction with our website

00:09:55,460 --> 00:09:59,630
they need customer support help the

00:09:57,980 --> 00:10:01,160
customer service representative is going

00:09:59,630 --> 00:10:04,130
to have to be able to find their records

00:10:01,160 --> 00:10:06,230
in very short order and so this is a

00:10:04,130 --> 00:10:07,580
this particular pattern is something

00:10:06,230 --> 00:10:11,300
you'll see again and again I don't

00:10:07,580 --> 00:10:13,340
recommend hooking in individual records

00:10:11,300 --> 00:10:16,240
simply because if you're designing too

00:10:13,340 --> 00:10:18,800
for a system that could scale massively

00:10:16,240 --> 00:10:24,530
it's much much better to use batch

00:10:18,800 --> 00:10:27,500
inserts that left us with having to

00:10:24,530 --> 00:10:30,020
figure out how to get the data in and

00:10:27,500 --> 00:10:33,380
out an of elasticsearch one of the first

00:10:30,020 --> 00:10:36,020
things we did was check to see if this

00:10:33,380 --> 00:10:37,880
was a solved problem there are many

00:10:36,020 --> 00:10:39,980
folks with django admins and there are

00:10:37,880 --> 00:10:42,080
many folks using elasticsearch so we

00:10:39,980 --> 00:10:43,880
went through and looked at django

00:10:42,080 --> 00:10:47,360
modules that could help advance us

00:10:43,880 --> 00:10:49,940
fairly quickly we decided to do our own

00:10:47,360 --> 00:10:52,700
implementation for two reasons the first

00:10:49,940 --> 00:10:55,610
is that elasticsearch moves very quickly

00:10:52,700 --> 00:10:57,320
as a search engine and many of the

00:10:55,610 --> 00:11:00,500
modules that were publicly supported

00:10:57,320 --> 00:11:03,470
were pre beta 1.0 I think I saw one for

00:11:00,500 --> 00:11:05,180
2.0 and there was one for 5 but it

00:11:03,470 --> 00:11:07,459
didn't look very well maintained or

00:11:05,180 --> 00:11:10,879
supported elasticsearch

00:11:07,459 --> 00:11:13,129
now is up to version 6.4 and every major

00:11:10,879 --> 00:11:16,449
version change is almost like a new

00:11:13,129 --> 00:11:18,379
engine even the minor versions are

00:11:16,449 --> 00:11:22,160
substantially different from each other

00:11:18,379 --> 00:11:23,629
and I will get back to that likewise we

00:11:22,160 --> 00:11:25,759
didn't know how long we would keep her

00:11:23,629 --> 00:11:27,889
Django admin we wanted to have we'd

00:11:25,759 --> 00:11:30,379
already started to break out search into

00:11:27,889 --> 00:11:32,839
separate API endpoints we knew we wanted

00:11:30,379 --> 00:11:35,420
the admin to work this year we probably

00:11:32,839 --> 00:11:37,369
wanted it to work next year but we

00:11:35,420 --> 00:11:40,279
didn't want to isolate and cement

00:11:37,369 --> 00:11:42,259
ourselves into a heavily Django fide

00:11:40,279 --> 00:11:43,399
system if we didn't know that was the

00:11:42,259 --> 00:11:45,970
direction we were going to go

00:11:43,399 --> 00:11:48,470
nevertheless we had to get it working

00:11:45,970 --> 00:11:51,949
there are two official Python

00:11:48,470 --> 00:11:54,860
implementations for elasticsearch there

00:11:51,949 --> 00:11:57,709
is a high-level DSL library that makes

00:11:54,860 --> 00:12:00,230
it ridiculously easy to model and

00:11:57,709 --> 00:12:03,199
serialize and query data from

00:12:00,230 --> 00:12:03,920
elasticsearch it sits on top of a

00:12:03,199 --> 00:12:07,100
lower-level

00:12:03,920 --> 00:12:10,839
Python library called elasticsearch pi

00:12:07,100 --> 00:12:14,420
that more closely resembles the

00:12:10,839 --> 00:12:16,129
elasticsearch documentation and any like

00:12:14,420 --> 00:12:17,600
raw queries you might see if any of you

00:12:16,129 --> 00:12:20,600
have looked at YouTube videos on how to

00:12:17,600 --> 00:12:22,879
use elasticsearch the output you've seen

00:12:20,600 --> 00:12:27,129
is probably closer to elasticsearch dot

00:12:22,879 --> 00:12:29,600
pi so here's our customer data model

00:12:27,129 --> 00:12:32,809
modeling this into the high-level

00:12:29,600 --> 00:12:35,569
elasticsearch DSL was trivial this is

00:12:32,809 --> 00:12:38,480
the model well we have to do is create a

00:12:35,569 --> 00:12:41,839
class define a few fields and library

00:12:38,480 --> 00:12:43,939
did the rest for us the main difference

00:12:41,839 --> 00:12:46,129
between the keyword field and the text

00:12:43,939 --> 00:12:49,179
field in this case are that the keyword

00:12:46,129 --> 00:12:51,679
field is an immutable field where

00:12:49,179 --> 00:12:53,240
elasticsearch when it sees a text field

00:12:51,679 --> 00:12:55,490
it will sometimes shred it depending on

00:12:53,240 --> 00:12:57,379
how you define it within the search but

00:12:55,490 --> 00:12:59,720
other than that this is functionally

00:12:57,379 --> 00:13:02,360
equivalent to a bunch of fields storing

00:12:59,720 --> 00:13:05,299
strings and we were off to the races it

00:13:02,360 --> 00:13:08,509
was very easy the queries were simple

00:13:05,299 --> 00:13:09,949
too we could define a search here there

00:13:08,509 --> 00:13:11,839
was a little bit of work in looking up

00:13:09,949 --> 00:13:15,230
the elasticsearch documentation and then

00:13:11,839 --> 00:13:17,919
trying to translate it into the DSL but

00:13:15,230 --> 00:13:21,440
our search needs were very simple and

00:13:17,919 --> 00:13:24,660
everything appeared to work fine

00:13:21,440 --> 00:13:27,480
but there was one issue with that and

00:13:24,660 --> 00:13:30,000
the issue was that the more we used

00:13:27,480 --> 00:13:32,490
elasticsearch the more we wanted to use

00:13:30,000 --> 00:13:34,530
it and do more things with it suddenly

00:13:32,490 --> 00:13:36,750
our needs changed we were originally

00:13:34,530 --> 00:13:40,230
modeling just one line of the customers

00:13:36,750 --> 00:13:41,610
address but a few months later we

00:13:40,230 --> 00:13:43,640
realized that we actually wanted to

00:13:41,610 --> 00:13:47,610
model more than one address per customer

00:13:43,640 --> 00:13:51,180
which necessitates a nested query with

00:13:47,610 --> 00:13:53,280
an elastic we went to look up the DSL

00:13:51,180 --> 00:13:55,380
implementation and we found out that it

00:13:53,280 --> 00:13:57,360
wasn't quite there now things have

00:13:55,380 --> 00:13:59,430
changed since then some of the bugs and

00:13:57,360 --> 00:14:02,220
issues that we encountered have most

00:13:59,430 --> 00:14:04,140
more than likely been resolved but we

00:14:02,220 --> 00:14:08,100
found that as our implementation got

00:14:04,140 --> 00:14:10,550
more complex every time that we wanted

00:14:08,100 --> 00:14:13,950
to utilize the DSL for its simplicity it

00:14:10,550 --> 00:14:15,510
became almost a major undertaking trying

00:14:13,950 --> 00:14:18,600
to figure out what the translation would

00:14:15,510 --> 00:14:22,920
look like eventually we got to the point

00:14:18,600 --> 00:14:24,960
where it became a hazard we didn't have

00:14:22,920 --> 00:14:27,180
a full-time elasticsearch developer on

00:14:24,960 --> 00:14:30,900
this people would float in and out of

00:14:27,180 --> 00:14:33,330
the project and so having an abstraction

00:14:30,900 --> 00:14:36,320
that was so abstract that we couldn't

00:14:33,330 --> 00:14:40,890
match it up to the public documentation

00:14:36,320 --> 00:14:42,450
yeah was was a hazard because with

00:14:40,890 --> 00:14:44,160
developers floating in and out of it

00:14:42,450 --> 00:14:45,690
they would have to learn they would have

00:14:44,160 --> 00:14:47,520
to understand the documentation then

00:14:45,690 --> 00:14:48,900
understand the DSL then try to figure

00:14:47,520 --> 00:14:50,700
out if like what they were doing in the

00:14:48,900 --> 00:14:52,950
DSL was really actually close to the

00:14:50,700 --> 00:14:55,650
documentation and then also figure out

00:14:52,950 --> 00:14:58,410
any bugs and underlying structure so we

00:14:55,650 --> 00:14:59,910
walked back our DSL implementation and

00:14:58,410 --> 00:15:02,820
decided to just go straight

00:14:59,910 --> 00:15:07,110
elasticsearch which is what I presume

00:15:02,820 --> 00:15:09,390
everyone else does this is what the new

00:15:07,110 --> 00:15:11,190
query looked like it's to me it's

00:15:09,390 --> 00:15:14,250
actually a little bit more readable than

00:15:11,190 --> 00:15:17,130
the old one it's the same form and

00:15:14,250 --> 00:15:22,020
structure it's JSON its dictionary if

00:15:17,130 --> 00:15:25,020
I'd JSON if I'd Python and as our

00:15:22,020 --> 00:15:26,820
queries got more complex the structure

00:15:25,020 --> 00:15:28,680
got a little bit more complex but this

00:15:26,820 --> 00:15:30,180
matches what's on the website I can go

00:15:28,680 --> 00:15:32,670
to the elasticsearch website right now

00:15:30,180 --> 00:15:34,290
and if I don't quite remember something

00:15:32,670 --> 00:15:38,970
I can tweak it and look it up

00:15:34,290 --> 00:15:41,339
it'll work 100% so the takeaway from

00:15:38,970 --> 00:15:44,279
this one is own your search if you

00:15:41,339 --> 00:15:46,230
abstract your search it might not lead

00:15:44,279 --> 00:15:49,079
you where you want to go particularly if

00:15:46,230 --> 00:15:51,149
your complexity increases and keeping

00:15:49,079 --> 00:15:55,199
parity with the official Docs for us was

00:15:51,149 --> 00:15:56,730
a huge way to de-risk our project all

00:15:55,199 --> 00:15:58,889
right the second lesson we learned is

00:15:56,730 --> 00:16:02,279
that elasticsearch is pretty cool

00:15:58,889 --> 00:16:05,430
if you don't define a mapping which is a

00:16:02,279 --> 00:16:08,730
schema for your data elasticsearch will

00:16:05,430 --> 00:16:12,889
define one for you and it might not do

00:16:08,730 --> 00:16:17,370
the best job or any job for that matter

00:16:12,889 --> 00:16:19,250
it'll just run away with it and that

00:16:17,370 --> 00:16:22,170
will result in your queries

00:16:19,250 --> 00:16:23,970
malfunctioning in our case we would the

00:16:22,170 --> 00:16:26,220
queries would not quite they would work

00:16:23,970 --> 00:16:28,470
but not quite work they were slower than

00:16:26,220 --> 00:16:30,420
we expected our performance inelastic

00:16:28,470 --> 00:16:33,630
searches near instance for a millions

00:16:30,420 --> 00:16:35,040
and millions of Records but that one

00:16:33,630 --> 00:16:37,589
time that we forgot to create our own

00:16:35,040 --> 00:16:39,089
mapping really nailed us and the

00:16:37,589 --> 00:16:40,470
solution is just delete and try again

00:16:39,089 --> 00:16:42,019
because it takes almost no time to

00:16:40,470 --> 00:16:45,779
import entire data sets into

00:16:42,019 --> 00:16:46,949
elasticsearch I will also say that when

00:16:45,779 --> 00:16:51,120
you're working on your elasticsearch

00:16:46,949 --> 00:16:52,740
implementation like 99.9 percent of the

00:16:51,120 --> 00:16:55,139
time if you ever have a problem with

00:16:52,740 --> 00:16:57,810
elasticsearch like this is the problem

00:16:55,139 --> 00:17:03,750
just you're done this is it just see

00:16:57,810 --> 00:17:07,189
this slide okay this is a more

00:17:03,750 --> 00:17:07,189
embarrassing version of the same problem

00:17:07,309 --> 00:17:11,669
elasticsearch changes very very

00:17:09,360 --> 00:17:14,549
frequently even the minor point changes

00:17:11,669 --> 00:17:17,549
can reflect substantial renaming of

00:17:14,549 --> 00:17:19,110
terms elasticsearch also doesn't have

00:17:17,549 --> 00:17:21,419
it's not very verbose with its error

00:17:19,110 --> 00:17:24,449
messages it'll just tell you like the

00:17:21,419 --> 00:17:25,829
seal doesn't exist so when you're

00:17:24,449 --> 00:17:28,409
designing your queries and you're

00:17:25,829 --> 00:17:30,270
modeling your data be very sure that you

00:17:28,409 --> 00:17:31,830
are looking at the exact version of

00:17:30,270 --> 00:17:35,730
elasticsearch that you were using

00:17:31,830 --> 00:17:37,770
because it does matter and it matters

00:17:35,730 --> 00:17:39,690
quite a lot they make it very easy to do

00:17:37,770 --> 00:17:42,179
on the website and they also make it

00:17:39,690 --> 00:17:44,790
very easy to accidentally ignore so when

00:17:42,179 --> 00:17:45,900
we started we were at version 6.0 which

00:17:44,790 --> 00:17:49,200
was current

00:17:45,900 --> 00:17:50,130
and as the implementation progressed and

00:17:49,200 --> 00:17:52,430
we got busy with other things

00:17:50,130 --> 00:17:55,740
elasticsearch move to six point four

00:17:52,430 --> 00:17:57,600
last week I was working on modeling sort

00:17:55,740 --> 00:18:00,030
orders with nested data and I was using

00:17:57,600 --> 00:18:02,550
the six point four version and that did

00:18:00,030 --> 00:18:05,070
not work out so well for me so this is a

00:18:02,550 --> 00:18:06,710
very simple risk mitigation strategy and

00:18:05,070 --> 00:18:10,440
it will save you a lot of time

00:18:06,710 --> 00:18:12,809
okay testing this is a big one spot

00:18:10,440 --> 00:18:16,050
checks on elastic search queries can

00:18:12,809 --> 00:18:20,580
appear to be quite valid my name is Kate

00:18:16,050 --> 00:18:21,929
Kligman so it's a very unique name not

00:18:20,580 --> 00:18:22,400
very many people have the name kate

00:18:21,929 --> 00:18:24,900
Kligman

00:18:22,400 --> 00:18:27,600
when i was testing our customer search

00:18:24,900 --> 00:18:30,450
implementation i used my name to test it

00:18:27,600 --> 00:18:33,210
and voila everything seems to work great

00:18:30,450 --> 00:18:36,000
the queries were working they were

00:18:33,210 --> 00:18:38,370
finding me it was perfect but my spot

00:18:36,000 --> 00:18:42,230
check wasn't enough because we had a

00:18:38,370 --> 00:18:46,230
co-founder named Chris Clark which is a

00:18:42,230 --> 00:18:48,390
more common name so and that did not

00:18:46,230 --> 00:18:50,340
exactly produce the results that we were

00:18:48,390 --> 00:18:51,750
expecting testing these queries is

00:18:50,340 --> 00:18:54,540
important because the last six search

00:18:51,750 --> 00:18:56,100
can be very very specific depending on

00:18:54,540 --> 00:18:58,559
how you rate the queries and model the

00:18:56,100 --> 00:18:59,820
data or can be very very expansive and

00:18:58,559 --> 00:19:02,100
there's a there's kind of like a fine

00:18:59,820 --> 00:19:04,230
point between in your queries where

00:19:02,100 --> 00:19:05,550
you're returning just enough data to be

00:19:04,230 --> 00:19:06,990
relevant to what you want to do

00:19:05,550 --> 00:19:08,790
particularly if you're searching very

00:19:06,990 --> 00:19:11,490
large data sets and the searches

00:19:08,790 --> 00:19:13,980
themselves are a bit fuzzy how we

00:19:11,490 --> 00:19:16,500
mitigated this risk was we started

00:19:13,980 --> 00:19:19,230
running batch sets of data through a

00:19:16,500 --> 00:19:21,210
testing system to check the ordering and

00:19:19,230 --> 00:19:24,030
this became part of our integration

00:19:21,210 --> 00:19:26,730
tests for elasticsearch so now whenever

00:19:24,030 --> 00:19:29,490
we decide to modify elasticsearch in any

00:19:26,730 --> 00:19:31,980
way we have sets of predefined data that

00:19:29,490 --> 00:19:34,110
go through it first we compare it to

00:19:31,980 --> 00:19:36,720
data that was run through previously and

00:19:34,110 --> 00:19:38,820
that lets us know if the scope of our

00:19:36,720 --> 00:19:41,309
search changed or if there's anything

00:19:38,820 --> 00:19:42,840
else that's going on it helps to keep

00:19:41,309 --> 00:19:45,030
our searches honest and I can't

00:19:42,840 --> 00:19:46,679
recommend this enough because with

00:19:45,030 --> 00:19:48,809
elastic search sometimes you're

00:19:46,679 --> 00:19:51,960
potentially potentially searching such a

00:19:48,809 --> 00:19:56,070
wide amount of data you can't spot-check

00:19:51,960 --> 00:19:58,150
it it's not possible so use use tools to

00:19:56,070 --> 00:20:00,520
your advantage to do this

00:19:58,150 --> 00:20:03,700
all right this is a big one explore all

00:20:00,520 --> 00:20:07,180
of your hosting options when we started

00:20:03,700 --> 00:20:12,040
our implementation we hosted on Postgres

00:20:07,180 --> 00:20:14,470
through Amazon so it made sense that we

00:20:12,040 --> 00:20:16,210
should also host elasticsearch on Amazon

00:20:14,470 --> 00:20:19,870
so that we could have all of our managed

00:20:16,210 --> 00:20:23,500
hosting together in one place perfectly

00:20:19,870 --> 00:20:26,230
logical at the time but what I found was

00:20:23,500 --> 00:20:28,900
or what we found was that not all

00:20:26,230 --> 00:20:31,300
managed hosting is created equal with

00:20:28,900 --> 00:20:35,020
now this list I'm presenting this

00:20:31,300 --> 00:20:37,240
without endorsement this is not an

00:20:35,020 --> 00:20:39,670
inclusive list by any means there are

00:20:37,240 --> 00:20:43,450
many providers here you can also host

00:20:39,670 --> 00:20:45,400
elasticsearch yourself but when we when

00:20:43,450 --> 00:20:47,860
we made that decision to go into Amazon

00:20:45,400 --> 00:20:50,530
our first roadblock was that it's hard

00:20:47,860 --> 00:20:54,040
to connect to Amazon Elastic search

00:20:50,530 --> 00:20:55,630
instances are very easy if you are going

00:20:54,040 --> 00:20:57,190
to have an open data set that's visible

00:20:55,630 --> 00:21:00,580
to the world you can just set it up in

00:20:57,190 --> 00:21:02,680
one click but if you want any kind of

00:21:00,580 --> 00:21:04,420
security or authentication particularly

00:21:02,680 --> 00:21:06,610
at the time we did it you have to go

00:21:04,420 --> 00:21:09,550
through a more advanced header signing

00:21:06,610 --> 00:21:11,530
mechanism and there was not any clear

00:21:09,550 --> 00:21:14,350
documentation on how to go about doing

00:21:11,530 --> 00:21:16,890
that so it became like an extra bit of

00:21:14,350 --> 00:21:19,690
work we had to do but that wasn't it

00:21:16,890 --> 00:21:22,450
Amazon also didn't support a lot of the

00:21:19,690 --> 00:21:24,790
plugins that we wanted to use in fact

00:21:22,450 --> 00:21:26,290
they were pretty inflexible about it my

00:21:24,790 --> 00:21:27,940
understanding is this has changed a

00:21:26,290 --> 00:21:30,220
little bit but at the time we were

00:21:27,940 --> 00:21:32,500
diving in we could have really used that

00:21:30,220 --> 00:21:35,290
support there are workarounds now for

00:21:32,500 --> 00:21:36,880
things but honestly when I look at the

00:21:35,290 --> 00:21:39,400
amount of operational work that goes

00:21:36,880 --> 00:21:41,260
into running something that is available

00:21:39,400 --> 00:21:43,210
by default on another managed hosting

00:21:41,260 --> 00:21:45,430
provider you know I don't know if we

00:21:43,210 --> 00:21:48,430
would have made the same decision but

00:21:45,430 --> 00:21:50,800
not to knock Amazon they did do one

00:21:48,430 --> 00:21:53,140
incredible thing for us and that is

00:21:50,800 --> 00:21:56,170
their high availability for their

00:21:53,140 --> 00:21:59,440
hosting so I gave a version of this talk

00:21:56,170 --> 00:22:01,780
a few months ago at a django con meet up

00:21:59,440 --> 00:22:03,880
and I was praising Amazon oh they're

00:22:01,780 --> 00:22:07,120
never down our hosting is great and the

00:22:03,880 --> 00:22:09,779
day after my talk the day after we had a

00:22:07,120 --> 00:22:14,279
hardware failure on one of the nodes

00:22:09,779 --> 00:22:16,950
it was Karma maybe and but with Amazon

00:22:14,279 --> 00:22:19,200
itself healed and we were back up before

00:22:16,950 --> 00:22:20,970
I could even sit down in action you know

00:22:19,200 --> 00:22:23,250
and take action to deal with the failure

00:22:20,970 --> 00:22:25,379
so there is something to say for managed

00:22:23,250 --> 00:22:27,389
hosting particularly if you don't have a

00:22:25,379 --> 00:22:32,279
dedicated team or a dedicated developer

00:22:27,389 --> 00:22:35,639
who just does elasticsearch right this

00:22:32,279 --> 00:22:38,370
was our final solution we went with the

00:22:35,639 --> 00:22:42,809
lower-level elasticsearch PI to have

00:22:38,370 --> 00:22:45,509
parity with the website documentation we

00:22:42,809 --> 00:22:48,419
finished on elasticsearch 6 we haven't

00:22:45,509 --> 00:22:50,159
had a reason to move to 6.4 simply

00:22:48,419 --> 00:22:55,820
because every time our data models

00:22:50,159 --> 00:22:59,250
change 6 seems to do fine for us our

00:22:55,820 --> 00:23:01,500
Django admin uses the same search as an

00:22:59,250 --> 00:23:04,169
API endpoint that we have so we achieve

00:23:01,500 --> 00:23:07,320
that goal and we preserved our admin and

00:23:04,169 --> 00:23:09,840
our searches are really really fast

00:23:07,320 --> 00:23:12,690
in fact the latency is the is the

00:23:09,840 --> 00:23:14,639
largest factor in our search speed the

00:23:12,690 --> 00:23:16,860
elastic search portion is hardly

00:23:14,639 --> 00:23:19,889
measurable it's also very high precision

00:23:16,860 --> 00:23:21,840
we replaced this amorphous full-text

00:23:19,889 --> 00:23:24,299
search in Postgres with a high precision

00:23:21,840 --> 00:23:26,610
search engine that does a much much

00:23:24,299 --> 00:23:30,720
better job of collating the records that

00:23:26,610 --> 00:23:34,669
we need so this this like I said I can't

00:23:30,720 --> 00:23:38,730
recommend elasticsearch enough for this

00:23:34,669 --> 00:23:43,230
these are some resources for elastic

00:23:38,730 --> 00:23:46,440
search I would suggest checking out some

00:23:43,230 --> 00:23:48,090
of the Django projects in particular for

00:23:46,440 --> 00:23:49,710
this to decide if you're going to do is

00:23:48,090 --> 00:23:52,169
like a small date elastic search

00:23:49,710 --> 00:23:53,549
solution or if you're planning to grow

00:23:52,169 --> 00:23:57,750
and scale with your company or your

00:23:53,549 --> 00:24:00,570
business for a long time and I do

00:23:57,750 --> 00:24:02,720
believe yeah and we have some time for

00:24:00,570 --> 00:24:02,720
questions

00:24:06,769 --> 00:24:13,590
hi you said before that you were using

00:24:10,409 --> 00:24:16,289
DSL yes in the first place I'm wondering

00:24:13,590 --> 00:24:21,269
how hard is to convert from DSL to use

00:24:16,289 --> 00:24:22,740
the electors PI sure so it's as hurt as

00:24:21,269 --> 00:24:26,460
the learning curve of learning

00:24:22,740 --> 00:24:28,320
elasticsearch in the first place we are

00:24:26,460 --> 00:24:31,740
with our particular issue we were using

00:24:28,320 --> 00:24:33,990
the DSL as a crutch because we wanted to

00:24:31,740 --> 00:24:35,909
be up and running very quickly we were

00:24:33,990 --> 00:24:38,610
under time pressure the admin was saying

00:24:35,909 --> 00:24:40,919
it was not doing so well and the DSL

00:24:38,610 --> 00:24:44,639
seemed like the way to go the largest

00:24:40,919 --> 00:24:46,919
portion that we spent time wise was

00:24:44,639 --> 00:24:50,909
learning how to map a lot of the data

00:24:46,919 --> 00:24:52,440
ourselves and then to some extent

00:24:50,909 --> 00:24:54,899
performing the queries that we could not

00:24:52,440 --> 00:24:57,029
do with the DSL so I say the difficulty

00:24:54,899 --> 00:25:00,260
level is medium if you already have an

00:24:57,029 --> 00:25:03,710
implementation you are halfway there and

00:25:00,260 --> 00:25:07,320
the query syntax doesn't change so much

00:25:03,710 --> 00:25:09,210
no I'm the real issue with the DSL is if

00:25:07,320 --> 00:25:11,190
you're completely embedded in it later

00:25:09,210 --> 00:25:12,529
and then you have to go back and change

00:25:11,190 --> 00:25:16,230
everything

00:25:12,529 --> 00:25:18,299
so can you can you say that it's like

00:25:16,230 --> 00:25:20,070
pretty you will be pretty early when you

00:25:18,299 --> 00:25:22,919
hit that point that you have to switch

00:25:20,070 --> 00:25:25,950
from DSL 2 pi because I'm wondering like

00:25:22,919 --> 00:25:29,700
if I want to use like search for one of

00:25:25,950 --> 00:25:31,679
the one of the project in the company I

00:25:29,700 --> 00:25:33,690
want to do like a little demo first at

00:25:31,679 --> 00:25:35,850
you and presented to everyone and to the

00:25:33,690 --> 00:25:37,889
oh this is a good and then we dive into

00:25:35,850 --> 00:25:39,480
it and whoa like pretty early will we

00:25:37,889 --> 00:25:42,350
know that hallway we have to switch to

00:25:39,480 --> 00:25:44,610
PI I should have a down they like it oh

00:25:42,350 --> 00:25:46,590
so there's a little bit of reputation on

00:25:44,610 --> 00:25:49,559
the line for not having to walk back

00:25:46,590 --> 00:25:51,510
yeah I would say go directly to PI I'm

00:25:49,559 --> 00:25:54,870
skip the DSL it's not where it's not

00:25:51,510 --> 00:25:56,639
worth it hey thanks maybe I missed this

00:25:54,870 --> 00:25:58,769
but how did you did you create a new

00:25:56,639 --> 00:26:00,240
custom UI or did you just somehow like

00:25:58,769 --> 00:26:02,909
hook into the Django admin and it's

00:26:00,240 --> 00:26:04,860
maintained the UI but then it hit the

00:26:02,909 --> 00:26:08,460
elasticsearch back-end to replace the

00:26:04,860 --> 00:26:10,769
results cool so what we did is so if I

00:26:08,460 --> 00:26:12,480
understand your question correctly we

00:26:10,769 --> 00:26:15,899
said we kept the we kept to the Django

00:26:12,480 --> 00:26:17,450
admin we created a separate class to

00:26:15,899 --> 00:26:19,880
encapsulate the

00:26:17,450 --> 00:26:22,639
hydrate the rehydration logic and then

00:26:19,880 --> 00:26:24,980
the admin would just use that class feed

00:26:22,639 --> 00:26:28,399
it the search parameters and then spend

00:26:24,980 --> 00:26:30,649
it back and we were also able to reuse

00:26:28,399 --> 00:26:33,220
that class for multiple API endpoints

00:26:30,649 --> 00:26:36,950
and other search use cases down the line

00:26:33,220 --> 00:26:39,110
cool talk you mentioned that you when

00:26:36,950 --> 00:26:41,659
you have problems with implicit schema

00:26:39,110 --> 00:26:43,760
mappings you just delete in like we

00:26:41,659 --> 00:26:45,980
create or create a new index is it easy

00:26:43,760 --> 00:26:47,720
to move data out of one index into

00:26:45,980 --> 00:26:50,480
another very quickly especially were

00:26:47,720 --> 00:26:52,850
changing the mapping yes it is elastic

00:26:50,480 --> 00:26:54,950
search has some features of its own that

00:26:52,850 --> 00:26:57,200
will that that can allow you to like

00:26:54,950 --> 00:26:59,000
migrate to perform data migrations

00:26:57,200 --> 00:27:02,059
without having to do a full external

00:26:59,000 --> 00:27:05,480
import in our case though it was so fast

00:27:02,059 --> 00:27:09,049
to simply just drop everything and redo

00:27:05,480 --> 00:27:10,970
our setup that that's that's still how

00:27:09,049 --> 00:27:13,220
we're managing that particular use case

00:27:10,970 --> 00:27:16,450
do you care about losing data when you

00:27:13,220 --> 00:27:19,789
drop in no because we use a form of

00:27:16,450 --> 00:27:22,940
versioning so each of our indexes or

00:27:19,789 --> 00:27:25,100
databases is a version and if we are

00:27:22,940 --> 00:27:27,470
making a schema change what we will do

00:27:25,100 --> 00:27:29,389
is increment the version number by one

00:27:27,470 --> 00:27:31,700
and the index is named the database

00:27:29,389 --> 00:27:33,470
effectively is named by version and then

00:27:31,700 --> 00:27:36,470
we will go ahead and pour it all of the

00:27:33,470 --> 00:27:38,929
data and set it up as a mirror and then

00:27:36,470 --> 00:27:41,600
we will flip our system over to use the

00:27:38,929 --> 00:27:43,399
new index and then drop the old one but

00:27:41,600 --> 00:27:45,200
it happens very very fast when we

00:27:43,399 --> 00:27:47,000
initially did this implementation we

00:27:45,200 --> 00:27:49,039
would just turn elasticsearch off wait

00:27:47,000 --> 00:27:50,570
10 minutes for everything to import and

00:27:49,039 --> 00:27:52,880
then turn it back on it takes a little

00:27:50,570 --> 00:27:55,299
bit longer than 10 minutes now so we

00:27:52,880 --> 00:27:58,190
switched to having rolling indexes but

00:27:55,299 --> 00:27:59,360
yes but yes answer your question yes a

00:27:58,190 --> 00:28:01,730
lot of times if you're changing the

00:27:59,360 --> 00:28:04,429
mappings you do have to drop the

00:28:01,730 --> 00:28:06,409
database or the index or it's a little

00:28:04,429 --> 00:28:08,389
bit more involved with elastic to have

00:28:06,409 --> 00:28:10,159
it migrate some of the data from one to

00:28:08,389 --> 00:28:12,620
the other oh here can you repeat the

00:28:10,159 --> 00:28:15,440
question into the microphone how big is

00:28:12,620 --> 00:28:17,779
the customer table and how often you

00:28:15,440 --> 00:28:19,760
query it to like push it to elastic

00:28:17,779 --> 00:28:21,980
search and any any insights or gotchas

00:28:19,760 --> 00:28:25,039
all right there what I can say about the

00:28:21,980 --> 00:28:27,679
size of our customer table is this for

00:28:25,039 --> 00:28:30,320
every 1 million customer rows it

00:28:27,679 --> 00:28:31,340
distills down and to less than a hundred

00:28:30,320 --> 00:28:35,570
megabytes

00:28:31,340 --> 00:28:37,039
of elasticsearch storage so far we have

00:28:35,570 --> 00:28:39,919
not been able to make a dent in the

00:28:37,039 --> 00:28:42,769
query speed um with how many records

00:28:39,919 --> 00:28:44,720
we've been adding and our update

00:28:42,769 --> 00:28:47,419
frequency I believe that was the second

00:28:44,720 --> 00:28:49,429
part of your question is two minutes so

00:28:47,419 --> 00:28:53,330
we have a task that just pulls every two

00:28:49,429 --> 00:28:56,299
minutes to look for updates hello thank

00:28:53,330 --> 00:29:00,799
you good talk this is semi comment semi

00:28:56,299 --> 00:29:03,409
question over here when we okay I have a

00:29:00,799 --> 00:29:05,899
question to when we implemented our

00:29:03,409 --> 00:29:09,320
search a couple years ago one of the

00:29:05,899 --> 00:29:11,990
problems we encountered was with using

00:29:09,320 --> 00:29:13,399
signals was race conditions and we kept

00:29:11,990 --> 00:29:15,320
getting records that were being deleted

00:29:13,399 --> 00:29:16,820
and added at the same time is that

00:29:15,320 --> 00:29:18,649
something that you encountered when you

00:29:16,820 --> 00:29:20,869
tried signals out or did you try that at

00:29:18,649 --> 00:29:22,610
all yeah I looked at signals early on

00:29:20,869 --> 00:29:24,590
but it became clear from the sheer

00:29:22,610 --> 00:29:27,470
volume of data that we didn't want to do

00:29:24,590 --> 00:29:29,809
it piecemeal and that like bulk updates

00:29:27,470 --> 00:29:32,749
were a much better choice for us so we

00:29:29,809 --> 00:29:34,279
dodged that particular bullet I was just

00:29:32,749 --> 00:29:37,070
wondering if you could say a little

00:29:34,279 --> 00:29:39,769
about doing geographical searches and

00:29:37,070 --> 00:29:42,230
how that affects query time ooh I have

00:29:39,769 --> 00:29:44,659
not done geographical searches I feel

00:29:42,230 --> 00:29:46,460
like I have done I worked on a different

00:29:44,659 --> 00:29:48,470
implementation than a customer search I

00:29:46,460 --> 00:29:51,590
did the product search for a Grove as

00:29:48,470 --> 00:29:53,659
well and we used almost every type of

00:29:51,590 --> 00:29:56,809
search that elastic offers internally

00:29:53,659 --> 00:30:00,190
except you so okay I'll have to try it

00:29:56,809 --> 00:30:03,259
yeah just give it a try talk about it I

00:30:00,190 --> 00:30:05,539
did did you if you guys are using

00:30:03,259 --> 00:30:10,159
Postgres did you look into the full text

00:30:05,539 --> 00:30:11,929
search properties of post grass as

00:30:10,159 --> 00:30:13,960
opposed to going straight to elastic

00:30:11,929 --> 00:30:16,279
search oh yeah yeah there were several

00:30:13,960 --> 00:30:18,710
more than several attempts were made to

00:30:16,279 --> 00:30:22,190
save the Postgres implementation it

00:30:18,710 --> 00:30:24,529
didn't end well why was that that it

00:30:22,190 --> 00:30:29,240
didn't end well yeah I would say for

00:30:24,529 --> 00:30:31,070
each attempt that we made like our like

00:30:29,240 --> 00:30:33,169
the amount of data that we had to

00:30:31,070 --> 00:30:34,759
process increase because we were at the

00:30:33,169 --> 00:30:39,590
time we were working on an exponential

00:30:34,759 --> 00:30:41,059
curve and so for us we would make a dent

00:30:39,590 --> 00:30:43,309
in it with Postgres we would we would

00:30:41,059 --> 00:30:44,960
we'd like we added indexes we worked on

00:30:43,309 --> 00:30:47,510
some of the full-text feature

00:30:44,960 --> 00:30:49,550
and what we found is we were spending a

00:30:47,510 --> 00:30:52,010
lot of time massaging something that was

00:30:49,550 --> 00:30:54,590
still slowing down and since we didn't

00:30:52,010 --> 00:30:55,970
have an end point for when our growth

00:30:54,590 --> 00:30:58,250
would stop hopefully there is no end

00:30:55,970 --> 00:31:00,590
point for that we decided to go with a

00:30:58,250 --> 00:31:02,230
longer lasting solution you mentioned

00:31:00,590 --> 00:31:05,980
that sometimes when you handle like a

00:31:02,230 --> 00:31:08,270
large number of Records you went in

00:31:05,980 --> 00:31:11,840
elasticsearch it can become really slow

00:31:08,270 --> 00:31:14,840
and you said something about finding us

00:31:11,840 --> 00:31:17,210
we spot you know oh yeah to get just

00:31:14,840 --> 00:31:19,550
enough data for the search what criteria

00:31:17,210 --> 00:31:21,440
are you using to kind of limit the scope

00:31:19,550 --> 00:31:24,050
of the search cool that's a that's a

00:31:21,440 --> 00:31:26,150
great question so the first thing is we

00:31:24,050 --> 00:31:28,340
tried to figure out exactly how much

00:31:26,150 --> 00:31:31,550
data any given search should return if

00:31:28,340 --> 00:31:33,110
I'm a customer happiness representative

00:31:31,550 --> 00:31:35,930
and I'm searching for a very specific

00:31:33,110 --> 00:31:37,690
customer address I might be disappointed

00:31:35,930 --> 00:31:40,610
if more than 10 records are returned

00:31:37,690 --> 00:31:43,310
where I have to cognitively go through a

00:31:40,610 --> 00:31:44,990
lot of extra results so the first

00:31:43,310 --> 00:31:48,350
parameter was always a business case

00:31:44,990 --> 00:31:50,090
like what would a good search look like

00:31:48,350 --> 00:31:53,240
from the perspective of the user

00:31:50,090 --> 00:31:56,030
performing the search with elasticsearch

00:31:53,240 --> 00:31:57,830
itself they have a there's there's

00:31:56,030 --> 00:32:00,740
something that's very similar to sequels

00:31:57,830 --> 00:32:02,390
limit parameters so you can just cap the

00:32:00,740 --> 00:32:03,950
number of queries or you can cap the

00:32:02,390 --> 00:32:06,050
number of search results you want back

00:32:03,950 --> 00:32:08,960
from it and elastic will use its

00:32:06,050 --> 00:32:12,170
algorithms internally to adjust how it

00:32:08,960 --> 00:32:14,510
queries and it's an interesting point

00:32:12,170 --> 00:32:16,670
because I found that if you say I don't

00:32:14,510 --> 00:32:18,860
want any more than a hundred records to

00:32:16,670 --> 00:32:20,720
be returned elasticsearch doesn't

00:32:18,860 --> 00:32:23,090
consider that a hard limit it'll say oh

00:32:20,720 --> 00:32:27,470
okay I'll give you 50 to 80 instead of

00:32:23,090 --> 00:32:29,780
100 another thing that we looked at was

00:32:27,470 --> 00:32:33,320
elastic search has a lot of implicit

00:32:29,780 --> 00:32:35,690
syntax in its queries very very early on

00:32:33,320 --> 00:32:39,230
we were hit with slow elastic queries

00:32:35,690 --> 00:32:43,580
because we had one of our queries had an

00:32:39,230 --> 00:32:46,400
implicit or instead of an and and so

00:32:43,580 --> 00:32:49,100
elastic was doing too much work to query

00:32:46,400 --> 00:32:50,720
too large of a data set and we didn't

00:32:49,100 --> 00:32:52,610
actually need most of the records that

00:32:50,720 --> 00:32:55,670
it was querying so keeping the search is

00:32:52,610 --> 00:32:58,080
very very specific and also matching

00:32:55,670 --> 00:33:01,230
them up with your use cases it's really

00:32:58,080 --> 00:33:03,419
I've also found that there there really

00:33:01,230 --> 00:33:05,490
aren't a lot of use cases that could

00:33:03,419 --> 00:33:08,100
overload elastic at least for our

00:33:05,490 --> 00:33:09,990
purposes simply because there was never

00:33:08,100 --> 00:33:11,909
really a scenario where we want

00:33:09,990 --> 00:33:14,460
elasticsearch to return more records

00:33:11,909 --> 00:33:16,559
than our systems could handle we are

00:33:14,460 --> 00:33:20,009
most the scope of our searches was never

00:33:16,559 --> 00:33:23,009
more than 300 records at a time thanks

00:33:20,009 --> 00:33:27,269
for the talk you mentioned you are using

00:33:23,009 --> 00:33:29,789
also elastic search for ordering and you

00:33:27,269 --> 00:33:35,669
are using the case when to get the index

00:33:29,789 --> 00:33:38,909
yes so those that paginates well or it

00:33:35,669 --> 00:33:42,929
just like generates for all records do

00:33:38,909 --> 00:33:44,850
you have an answer for that oh yeah we

00:33:42,929 --> 00:33:46,259
were able to get so we're I guess we're

00:33:44,850 --> 00:33:48,570
kind of cheating we're able to get away

00:33:46,259 --> 00:33:50,220
with that simply because the number of

00:33:48,570 --> 00:33:52,950
records that we ultimately want to

00:33:50,220 --> 00:33:54,330
return is small okay so if you're if you

00:33:52,950 --> 00:33:56,610
want this to return like a hundred

00:33:54,330 --> 00:33:58,470
thousand records okay slightly different

00:33:56,610 --> 00:34:01,289
way yes I don't know if both ways like

00:33:58,470 --> 00:34:03,960
paginates using that or like it

00:34:01,289 --> 00:34:04,379
generates for our records of the of the

00:34:03,960 --> 00:34:06,389
query

00:34:04,379 --> 00:34:08,520
okay can you repeat that because like

00:34:06,389 --> 00:34:10,980
you are doing a case win and expression

00:34:08,520 --> 00:34:14,129
right and like you are you could be

00:34:10,980 --> 00:34:16,770
paginating by that expression like on

00:34:14,129 --> 00:34:19,800
this on the front end for Django at me I

00:34:16,770 --> 00:34:22,950
don't know if post queries will partly

00:34:19,800 --> 00:34:25,710
using part of the result or it will

00:34:22,950 --> 00:34:27,899
generate out the case win and then after

00:34:25,710 --> 00:34:29,369
passing oh that's a good question so the

00:34:27,899 --> 00:34:33,510
answer is that it will generate them all

00:34:29,369 --> 00:34:35,639
okay it won't yeah yeah and how we are

00:34:33,510 --> 00:34:37,950
able to get away with us is because our

00:34:35,639 --> 00:34:39,649
query needs because our the data sets

00:34:37,950 --> 00:34:42,839
are large but our query needs are small

00:34:39,649 --> 00:34:45,119
we eventually dropped pagination from

00:34:42,839 --> 00:34:47,280
our Django admin okay if we wanted to

00:34:45,119 --> 00:34:50,579
add pagination it's a it's it's fairly

00:34:47,280 --> 00:34:54,000
easy we can return the larger subset and

00:34:50,579 --> 00:34:56,010
truncate it or we could have

00:34:54,000 --> 00:34:58,440
elasticsearch elasticsearch itself is

00:34:56,010 --> 00:35:00,390
capable of pagination too and so we

00:34:58,440 --> 00:35:04,530
could add a little bit more complexity

00:35:00,390 --> 00:35:07,500
to our system to to enable that okay but

00:35:04,530 --> 00:35:10,050
if you paginate on elasticsearch and

00:35:07,500 --> 00:35:11,160
like you add an additional filter on the

00:35:10,050 --> 00:35:13,950
Django side

00:35:11,160 --> 00:35:15,780
then you wouldn't be able right we are

00:35:13,950 --> 00:35:18,150
doing only futures oh yeah yeah that's

00:35:15,780 --> 00:35:19,950
right okay yeah so it's it's yeah it's

00:35:18,150 --> 00:35:22,530
kind of okay between between both

00:35:19,950 --> 00:35:24,630
systems that's great thank you okay well

00:35:22,530 --> 00:35:26,610
then let's um thank you all for your

00:35:24,630 --> 00:35:27,520
questions and let's thank Kate again for

00:35:26,610 --> 00:35:34,380
her wonderful talk

00:35:27,520 --> 00:35:34,380

YouTube URL: https://www.youtube.com/watch?v=JjjpAYEnK7k


