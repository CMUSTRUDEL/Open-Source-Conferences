Title: DevOpsDays Philadelphia 2019 - Arrested DevOps Live...
Publication date: 2019-11-03
Playlist: DevOpsDays Philadelphia 2019
Description: 
	DevOpsDays Philadelphia 2019 - Arrested DevOps Live with Jocelyn Harper, Tim Gross, Bridget Kromhout & Peter Shannon

Itâ€™s time for the devopsdays Philadelphia live studio audience Arrested DevOps podcast, wherein devopsdays Philadelphia discusses operating your team and organization for maximum devops awesomeness.
Captions: 
	00:00:00,410 --> 00:00:11,839
[Music]

00:00:14,200 --> 00:00:18,710
it's time for arrested DevOps the

00:00:17,330 --> 00:00:21,259
podcasts where we help you achieve

00:00:18,710 --> 00:00:23,750
understanding develop good practices and

00:00:21,259 --> 00:00:26,599
operate your team and organization for

00:00:23,750 --> 00:00:29,899
maximum DevOps awesomeness I'm Bridgette

00:00:26,599 --> 00:00:34,530
Crum ho today we're live at DevOps Days

00:00:29,899 --> 00:00:37,960
Philly applause sign make some noise and

00:00:34,530 --> 00:00:40,579
[Applause]

00:00:37,960 --> 00:00:43,190
we're gonna talk to a great panel in a

00:00:40,579 --> 00:00:43,969
minute here but first a word from our

00:00:43,190 --> 00:00:47,269
sponsors

00:00:43,969 --> 00:00:49,579
I have literally no idea what's gonna

00:00:47,269 --> 00:00:51,969
get edited into here so it would be

00:00:49,579 --> 00:00:51,969
surprised

00:00:52,449 --> 00:00:59,420
okay so DevOps stays Philly we have a

00:00:56,690 --> 00:01:01,489
great panel I'm gonna ask them to

00:00:59,420 --> 00:01:03,920
introduce themselves starting to my

00:01:01,489 --> 00:01:05,480
right my name is Tim Gross I'm a

00:01:03,920 --> 00:01:15,380
software engineer with hashey Corp

00:01:05,480 --> 00:01:17,710
working on the Nomad project software

00:01:15,380 --> 00:01:17,710
engineer

00:01:20,200 --> 00:01:24,830
everyone my name is Peter Shannon I'm a

00:01:22,820 --> 00:01:33,250
senior software engineer at instacart

00:01:24,830 --> 00:01:37,420
and also the head organizer okay

00:01:33,250 --> 00:01:40,760
activate applause turn down thank you

00:01:37,420 --> 00:01:43,220
all right fantastic so I want to start

00:01:40,760 --> 00:01:44,930
with you Peter and you are the head

00:01:43,220 --> 00:01:47,660
organizer of DevOps Tastefully you

00:01:44,930 --> 00:01:49,280
brought this program to us can you talk

00:01:47,660 --> 00:01:51,530
a little bit cuz I want to dive into

00:01:49,280 --> 00:01:53,420
what some of our current and past

00:01:51,530 --> 00:01:55,130
speakers have talked about but can you

00:01:53,420 --> 00:01:57,740
talk a little bit about the curation

00:01:55,130 --> 00:01:59,360
process like how do you decide that not

00:01:57,740 --> 00:02:00,350
every single talk should be kubernetes

00:01:59,360 --> 00:02:03,680
hmm

00:02:00,350 --> 00:02:08,000
good question because really they should

00:02:03,680 --> 00:02:09,950
all be about kubernetes so it's a single

00:02:08,000 --> 00:02:13,340
track conference right so that's that's

00:02:09,950 --> 00:02:16,849
one constraint and so with that we have

00:02:13,340 --> 00:02:18,709
to try and find a balance of culture

00:02:16,849 --> 00:02:21,459
talks technical talks talks that we

00:02:18,709 --> 00:02:25,060
think might be culturally relevant or

00:02:21,459 --> 00:02:28,420
timely and fit that all into the sky

00:02:25,060 --> 00:02:30,280
and it can be challenging because this

00:02:28,420 --> 00:02:32,860
is our fourth year doing this and I've

00:02:30,280 --> 00:02:34,450
heard from folks you know I feel like

00:02:32,860 --> 00:02:37,090
the talks are too cultural

00:02:34,450 --> 00:02:38,770
I'd really like it if you know you had

00:02:37,090 --> 00:02:43,000
more Tech Talks I've heard the inverse

00:02:38,770 --> 00:02:44,769
of that and so what we try to do is we

00:02:43,000 --> 00:02:47,830
try and take all those components and we

00:02:44,769 --> 00:02:50,080
try and mix them in as best we can to

00:02:47,830 --> 00:02:51,819
have you know a culture talk to have a

00:02:50,080 --> 00:02:55,860
technical talk to have talks that are

00:02:51,819 --> 00:02:59,170
timely and I think for me in particular

00:02:55,860 --> 00:03:01,810
I always try and have the opening talks

00:02:59,170 --> 00:03:04,299
be something that does tend to lean more

00:03:01,810 --> 00:03:05,890
towards cultural and in particular

00:03:04,299 --> 00:03:10,420
something that I think is culturally

00:03:05,890 --> 00:03:14,140
relevant or timely and from there we

00:03:10,420 --> 00:03:16,060
might if we can try and frame other

00:03:14,140 --> 00:03:18,430
talks throughout the conference around

00:03:16,060 --> 00:03:20,260
to sort of kick it off as a theme but

00:03:18,430 --> 00:03:23,739
that can be challenging as well yeah

00:03:20,260 --> 00:03:25,900
absolutely so I Jocelyn gave a wonderful

00:03:23,739 --> 00:03:28,150
opening keynote here and I'm wondering

00:03:25,900 --> 00:03:31,750
Jocelyn if you can kind of summarize for

00:03:28,150 --> 00:03:33,640
our podcast audience and for the people

00:03:31,750 --> 00:03:35,769
who may have not been quite caffeinated

00:03:33,640 --> 00:03:38,049
enough yesterday morning um what are

00:03:35,769 --> 00:03:41,560
what are some of the high points about

00:03:38,049 --> 00:03:43,870
your talk so my talk was essentially

00:03:41,560 --> 00:03:46,239
about ethics within technology and that

00:03:43,870 --> 00:03:49,870
responsibility that we as technologists

00:03:46,239 --> 00:03:53,889
need to understand that we have I

00:03:49,870 --> 00:03:55,359
highlighted prey primarily that we as

00:03:53,889 --> 00:03:56,829
technologists we can seem to be

00:03:55,359 --> 00:03:59,200
indifferent to things that are happening

00:03:56,829 --> 00:04:02,290
in the world that larger tech companies

00:03:59,200 --> 00:04:04,150
that we either use in some way or that

00:04:02,290 --> 00:04:06,340
we work for we just tend to ignore the

00:04:04,150 --> 00:04:09,010
issues that they present to other human

00:04:06,340 --> 00:04:12,160
beings and perhaps not technologists so

00:04:09,010 --> 00:04:15,670
I found that it was really interesting

00:04:12,160 --> 00:04:18,160
and apt that I would talk to y'all about

00:04:15,670 --> 00:04:19,900
that very early in the morning and make

00:04:18,160 --> 00:04:22,810
you understand and have that

00:04:19,900 --> 00:04:25,330
introspection to see that where your

00:04:22,810 --> 00:04:27,340
ethics lie and how to apply that to

00:04:25,330 --> 00:04:29,169
situations that have happened just this

00:04:27,340 --> 00:04:31,639
year in the year isn't even over yet and

00:04:29,169 --> 00:04:34,280
it was why a lot of them

00:04:31,639 --> 00:04:36,080
it is amazing when we look at kind of

00:04:34,280 --> 00:04:39,469
your and review things and we're talking

00:04:36,080 --> 00:04:40,189
here in mid-october but close to the end

00:04:39,469 --> 00:04:42,919
of October

00:04:40,189 --> 00:04:44,569
it's all very upsetting um you know

00:04:42,919 --> 00:04:47,509
we're close to the end of a decade too

00:04:44,569 --> 00:04:50,389
and it's just amazing to think about but

00:04:47,509 --> 00:04:52,430
when when we're having these discussions

00:04:50,389 --> 00:04:54,590
when we're considering this stuff I

00:04:52,430 --> 00:04:57,259
think sometimes it's useful to realize

00:04:54,590 --> 00:05:00,979
that these aren't even new discussions

00:04:57,259 --> 00:05:03,620
and they're not unique to us no not at

00:05:00,979 --> 00:05:06,020
all they're not new in any sort of the

00:05:03,620 --> 00:05:07,639
way so it's very interesting and I said

00:05:06,020 --> 00:05:11,210
this in my talk as well how social media

00:05:07,639 --> 00:05:13,400
has been a vehicle for people that may

00:05:11,210 --> 00:05:14,689
have not been heard in companies and

00:05:13,400 --> 00:05:16,159
that's not to say that people within

00:05:14,689 --> 00:05:18,020
companies haven't been bringing these

00:05:16,159 --> 00:05:20,990
issues to the forefront but it's a lot

00:05:18,020 --> 00:05:22,729
easier for people in higher places to

00:05:20,990 --> 00:05:24,169
push them aside when nobody else knows

00:05:22,729 --> 00:05:26,000
about the talks that are happening and

00:05:24,169 --> 00:05:28,069
so I specifically mentioned Twitter

00:05:26,000 --> 00:05:29,990
because I'm very active there that

00:05:28,069 --> 00:05:31,610
Twitter is definitely the vehicle for

00:05:29,990 --> 00:05:32,990
the general public and more

00:05:31,610 --> 00:05:34,520
technologists who know about these

00:05:32,990 --> 00:05:37,310
things that are going on and it's been

00:05:34,520 --> 00:05:40,789
really helpful in inhibiting change

00:05:37,310 --> 00:05:43,669
there so yeah absolutely and several

00:05:40,789 --> 00:05:46,550
like in past years Tim you've key noted

00:05:43,669 --> 00:05:50,539
here at DevOps Days Philly and made an

00:05:46,550 --> 00:05:52,039
argument about software defining culture

00:05:50,539 --> 00:05:54,919
I'm wondering if you want to give us

00:05:52,039 --> 00:05:56,690
take a stab at what have you seen in

00:05:54,919 --> 00:05:59,620
that space sure

00:05:56,690 --> 00:06:02,389
so the talk was kind of like turning

00:05:59,620 --> 00:06:05,449
John I think John referred to Conway's

00:06:02,389 --> 00:06:07,669
law earlier today and we were talking at

00:06:05,449 --> 00:06:09,469
where the organizational structure

00:06:07,669 --> 00:06:10,879
defines you know with the systems that

00:06:09,469 --> 00:06:12,710
you build and the idea around the talk

00:06:10,879 --> 00:06:13,819
was like well that's the systems that we

00:06:12,710 --> 00:06:15,560
build and the choices that we make

00:06:13,819 --> 00:06:17,360
around those systems can also have

00:06:15,560 --> 00:06:19,039
greater impacts on both our

00:06:17,360 --> 00:06:21,259
organization's culture and the culture

00:06:19,039 --> 00:06:23,330
that we kind of it's within a context of

00:06:21,259 --> 00:06:25,639
so you know and some of those are about

00:06:23,330 --> 00:06:27,889
like building for reliability because it

00:06:25,639 --> 00:06:29,689
it makes your people trust each other

00:06:27,889 --> 00:06:31,580
better but it ripples all the way down

00:06:29,689 --> 00:06:33,020
to you know which technical communities

00:06:31,580 --> 00:06:34,370
do you sy to be part of like are you

00:06:33,020 --> 00:06:35,629
part of a language community that's

00:06:34,370 --> 00:06:40,430
really taught has a lot of toxic

00:06:35,629 --> 00:06:42,319
behaviors and and kind of like and I I'm

00:06:40,430 --> 00:06:44,270
AI kind of continued that theme in

00:06:42,319 --> 00:06:45,560
another talk I gave at DevOps tased me

00:06:44,270 --> 00:06:47,750
Annapolis last year

00:06:45,560 --> 00:06:50,690
about kind of like the much larger

00:06:47,750 --> 00:06:51,770
cultural impact that we have where you

00:06:50,690 --> 00:06:53,900
know are we just are we building

00:06:51,770 --> 00:06:56,660
technologies that like don't have a good

00:06:53,900 --> 00:06:58,070
purpose or can we build technologies

00:06:56,660 --> 00:06:59,930
that like maybe they have a neutral

00:06:58,070 --> 00:07:01,220
purpose but can be using bad ways and

00:06:59,930 --> 00:07:05,620
can we make technical decisions that

00:07:01,220 --> 00:07:08,330
like drive those things to a better

00:07:05,620 --> 00:07:14,210
endpoint than and kind of like the open

00:07:08,330 --> 00:07:15,980
ended and so if that sounds too abstract

00:07:14,210 --> 00:07:18,370
I want to kind of give one of the

00:07:15,980 --> 00:07:19,910
specific examples you talked about as

00:07:18,370 --> 00:07:23,419
technologists we're making decisions

00:07:19,910 --> 00:07:25,790
every day about you know state like that

00:07:23,419 --> 00:07:27,820
thing where the customer data lives so

00:07:25,790 --> 00:07:31,580
any production system probably has it

00:07:27,820 --> 00:07:33,650
and how do you deal with state and

00:07:31,580 --> 00:07:36,500
versioning and maybe you have to think

00:07:33,650 --> 00:07:38,930
about GDP are that maybe you just have

00:07:36,500 --> 00:07:42,200
to think about what are we storing that

00:07:38,930 --> 00:07:45,530
somebody could use for evil like a lot

00:07:42,200 --> 00:07:47,300
of times I feel like as technologists we

00:07:45,530 --> 00:07:51,050
sometimes look at the happy path and

00:07:47,300 --> 00:07:53,180
we're like in ideal circumstances this

00:07:51,050 --> 00:07:54,080
will be used exactly this way and never

00:07:53,180 --> 00:07:56,960
abused

00:07:54,080 --> 00:08:00,169
well how realistic is that I mean it's

00:07:56,960 --> 00:08:02,330
like what what have you seen P yeah I

00:08:00,169 --> 00:08:05,060
think as technologists we tend to look

00:08:02,330 --> 00:08:07,190
at things more from least in my

00:08:05,060 --> 00:08:10,430
experiences more from like almost like a

00:08:07,190 --> 00:08:13,250
variable perspective so you know we need

00:08:10,430 --> 00:08:15,889
our service to do X and these are the

00:08:13,250 --> 00:08:18,500
inputs right so and those inputs could

00:08:15,889 --> 00:08:21,919
end up being extremely sensitive data

00:08:18,500 --> 00:08:23,870
maybe some of that data could be used in

00:08:21,919 --> 00:08:25,850
ways that you're not even thinking of

00:08:23,870 --> 00:08:29,240
because you're thinking how do I get

00:08:25,850 --> 00:08:31,190
this service to work right and so it

00:08:29,240 --> 00:08:35,240
definitely starts to beg the question

00:08:31,190 --> 00:08:37,010
about is there something we can do more

00:08:35,240 --> 00:08:40,099
is there some type of training is there

00:08:37,010 --> 00:08:41,659
is there some you know a different way

00:08:40,099 --> 00:08:43,490
of thinking that when we look at this

00:08:41,659 --> 00:08:46,490
data we should assume to have a

00:08:43,490 --> 00:08:49,100
responsibility and say you know this

00:08:46,490 --> 00:08:51,230
data is really critical and the people

00:08:49,100 --> 00:08:55,120
who own this data like the people who

00:08:51,230 --> 00:08:58,160
the days of you know they would be

00:08:55,120 --> 00:08:59,480
potentially you know harm during a

00:08:58,160 --> 00:09:01,130
you know could could end up being

00:08:59,480 --> 00:09:02,630
financially ruined or who knows what it

00:09:01,130 --> 00:09:03,980
is if the data were to get into the

00:09:02,630 --> 00:09:06,080
wrong hands and start thinking about it

00:09:03,980 --> 00:09:07,850
more like that instead of just a bunch

00:09:06,080 --> 00:09:09,650
of bits stored in our database what it

00:09:07,850 --> 00:09:11,960
stuff yeah well if we're thinking about

00:09:09,650 --> 00:09:14,960
threat models I feel like this is where

00:09:11,960 --> 00:09:18,380
as technologists who might look around

00:09:14,960 --> 00:09:20,240
our organizations and see a homogeneous

00:09:18,380 --> 00:09:21,920
sea of people who have gone to similar

00:09:20,240 --> 00:09:24,860
educational institutions and are from

00:09:21,920 --> 00:09:27,260
similar backgrounds and you know don't

00:09:24,860 --> 00:09:29,270
have the same threat models and that

00:09:27,260 --> 00:09:31,550
means we are gonna build better products

00:09:29,270 --> 00:09:35,120
if we make sure that we have people in

00:09:31,550 --> 00:09:37,490
the entire product chain who maybe are

00:09:35,120 --> 00:09:39,770
people of color maybe women of color

00:09:37,490 --> 00:09:41,960
maybe have actually experienced some of

00:09:39,770 --> 00:09:43,460
the threats that the product designers

00:09:41,960 --> 00:09:46,220
who weren't listening to them might not

00:09:43,460 --> 00:09:48,920
have even ever seen know I think that's

00:09:46,220 --> 00:09:54,830
very true and I also think that as far

00:09:48,920 --> 00:09:56,960
as just data overall is such a large

00:09:54,830 --> 00:09:59,150
discussion right now it's in the general

00:09:56,960 --> 00:10:01,520
populace not just with technologists and

00:09:59,150 --> 00:10:03,920
I think that we need to start analyzing

00:10:01,520 --> 00:10:05,780
our systems in the way that we design

00:10:03,920 --> 00:10:07,910
things a bit better I think we also need

00:10:05,780 --> 00:10:10,010
to start asking our asking ourselves the

00:10:07,910 --> 00:10:11,810
question does do we really need this

00:10:10,010 --> 00:10:14,300
data in order to perform the function

00:10:11,810 --> 00:10:15,980
that we have and I think that we have

00:10:14,300 --> 00:10:18,710
just gotten to the point where as

00:10:15,980 --> 00:10:20,720
technologists we just give all of the

00:10:18,710 --> 00:10:22,700
data just because it comes with it and

00:10:20,720 --> 00:10:24,860
that's that's fine and we'll just put in

00:10:22,700 --> 00:10:26,330
the database and we have security and

00:10:24,860 --> 00:10:27,770
it's fine and it's just not like that we

00:10:26,330 --> 00:10:29,270
need to start having more thoughtful

00:10:27,770 --> 00:10:32,060
discussions about when it comes to the

00:10:29,270 --> 00:10:33,740
architecture of these services do we

00:10:32,060 --> 00:10:35,480
need all of this data in order to

00:10:33,740 --> 00:10:38,360
perform the function that we have and

00:10:35,480 --> 00:10:40,790
that is something that we all need to do

00:10:38,360 --> 00:10:42,350
moving forward yeah I can think of a

00:10:40,790 --> 00:10:45,920
specific example at an organization I

00:10:42,350 --> 00:10:47,420
work with a couple of jobs ago where it

00:10:45,920 --> 00:10:49,460
was a sensor device that was designed

00:10:47,420 --> 00:10:51,020
they account people and detect movement

00:10:49,460 --> 00:10:52,730
through a space right and the idea

00:10:51,020 --> 00:10:56,060
behind it was that it was designed

00:10:52,730 --> 00:10:57,560
around giving large facility owners the

00:10:56,060 --> 00:10:59,780
ability to make decisions about how

00:10:57,560 --> 00:11:02,150
their space was being used but the

00:10:59,780 --> 00:11:03,920
designers recognized early on what

00:11:02,150 --> 00:11:05,600
abuses something like that kind of data

00:11:03,920 --> 00:11:07,280
could be used for if it was used to

00:11:05,600 --> 00:11:08,510
identify individuals right and you see

00:11:07,280 --> 00:11:09,920
there's a bunt there was a article

00:11:08,510 --> 00:11:11,850
recently that came out about this like

00:11:09,920 --> 00:11:13,560
horrible like badge

00:11:11,850 --> 00:11:15,270
you can give people and like track all

00:11:13,560 --> 00:11:16,260
their movements in individually like how

00:11:15,270 --> 00:11:18,990
much time are they spending in the

00:11:16,260 --> 00:11:21,390
bathroom and this device was designed

00:11:18,990 --> 00:11:23,010
kind of like up front to make it

00:11:21,390 --> 00:11:25,740
impossible for us to get that data from

00:11:23,010 --> 00:11:27,030
you know innate about individuals from

00:11:25,740 --> 00:11:28,320
the thing and there was what was

00:11:27,030 --> 00:11:29,790
interesting about that what they found

00:11:28,320 --> 00:11:30,990
was that it turned out to be a

00:11:29,790 --> 00:11:31,800
competitive advantage because it was

00:11:30,990 --> 00:11:33,350
something that none of the other

00:11:31,800 --> 00:11:35,190
providers in that space could do

00:11:33,350 --> 00:11:36,570
everybody else wanted to be able to

00:11:35,190 --> 00:11:38,040
identify individuals and there were many

00:11:36,570 --> 00:11:39,660
companies who said you know many

00:11:38,040 --> 00:11:41,310
organizations who said you know we don't

00:11:39,660 --> 00:11:43,920
want to be able to do that because our

00:11:41,310 --> 00:11:45,870
workers aren't gonna like that so though

00:11:43,920 --> 00:11:49,230
didn't you tell me about a funny corner

00:11:45,870 --> 00:11:51,480
case yeah it because it like detected

00:11:49,230 --> 00:11:53,100
the shape of human beings like you if

00:11:51,480 --> 00:11:54,960
you moved mannequins through a doorway

00:11:53,100 --> 00:11:57,360
like it would detect that as a person

00:11:54,960 --> 00:11:59,370
and so that's very confusing like people

00:11:57,360 --> 00:12:05,430
carrying mannequin yes people turn like

00:11:59,370 --> 00:12:08,220
in retail case it's it's it's it's

00:12:05,430 --> 00:12:09,450
definitely interesting though and I you

00:12:08,220 --> 00:12:11,250
hadn't told me that story before and I

00:12:09,450 --> 00:12:14,010
think that's that's really neat that the

00:12:11,250 --> 00:12:16,440
customers sort of police themselves and

00:12:14,010 --> 00:12:17,820
said like that's a really neat feature

00:12:16,440 --> 00:12:19,650
that some of your competitors are

00:12:17,820 --> 00:12:22,290
offering but you know we don't even want

00:12:19,650 --> 00:12:24,390
to go into that right now we don't want

00:12:22,290 --> 00:12:28,760
to know who's doing what we just want to

00:12:24,390 --> 00:12:31,710
know if somebody's in this space right

00:12:28,760 --> 00:12:33,330
and it's interesting that you that the

00:12:31,710 --> 00:12:35,280
company actually came at that from from

00:12:33,330 --> 00:12:36,960
a product decision but kind of what

00:12:35,280 --> 00:12:39,390
you're saying is restoring everything in

00:12:36,960 --> 00:12:41,100
databases and I think I think that is

00:12:39,390 --> 00:12:44,160
the general consensus for most companies

00:12:41,100 --> 00:12:45,750
it's that I remember at sea years ago

00:12:44,160 --> 00:12:47,490
and this was more towards storing

00:12:45,750 --> 00:12:50,190
metrics they said if it moved Grafton

00:12:47,490 --> 00:12:52,410
and I think when it comes to storing

00:12:50,190 --> 00:12:54,240
customer data its if if there's a data

00:12:52,410 --> 00:12:56,640
point if there's something to get you

00:12:54,240 --> 00:13:00,150
grab it because who knows maybe we'll

00:12:56,640 --> 00:13:01,980
need it storing bits is cheap right

00:13:00,150 --> 00:13:05,280
I mean it's cheap until the lawsuit

00:13:01,980 --> 00:13:08,160
right yeah because like several jobs

00:13:05,280 --> 00:13:10,320
back well let's put it this way when the

00:13:08,160 --> 00:13:13,650
Cambridge analytical stuff happened I

00:13:10,320 --> 00:13:19,860
wasn't surprised because I too used to

00:13:13,650 --> 00:13:21,730
be evil and the the idea of harvesting

00:13:19,860 --> 00:13:23,440
peoples like say

00:13:21,730 --> 00:13:25,510
you used to be able to get people's

00:13:23,440 --> 00:13:27,310
friends likes from Facebook and then

00:13:25,510 --> 00:13:29,140
target things to them based on that they

00:13:27,310 --> 00:13:30,820
turned that off in 2015 but there's

00:13:29,140 --> 00:13:35,020
still a lot of dark patterns out there

00:13:30,820 --> 00:13:37,450
and I think that if you are in a space

00:13:35,020 --> 00:13:39,880
where whether it's ad hoc or something

00:13:37,450 --> 00:13:42,010
else where it seems relevant to your

00:13:39,880 --> 00:13:45,730
business interest to grab all of that

00:13:42,010 --> 00:13:48,310
data I would say but think about where

00:13:45,730 --> 00:13:50,470
you're going to have someone upset about

00:13:48,310 --> 00:13:52,900
how you're using how you're storing it

00:13:50,470 --> 00:13:55,090
what you're leaking when there is a data

00:13:52,900 --> 00:13:57,310
breach because it seems like every other

00:13:55,090 --> 00:14:00,340
day there's a new data breach I mean I

00:13:57,310 --> 00:14:02,020
just kind of assumed that shrug if

00:14:00,340 --> 00:14:04,450
something happens with my credit card or

00:14:02,020 --> 00:14:06,310
my data like at this point it just seems

00:14:04,450 --> 00:14:09,250
like it's being breached constantly but

00:14:06,310 --> 00:14:11,620
if you're the person making decisions

00:14:09,250 --> 00:14:13,870
about what to store I forget who it was

00:14:11,620 --> 00:14:15,850
who said think of your think of the the

00:14:13,870 --> 00:14:18,010
PII and the customer data as being kind

00:14:15,850 --> 00:14:20,080
of like toxic waste it's like this isn't

00:14:18,010 --> 00:14:21,730
necessarily an asset it's something you

00:14:20,080 --> 00:14:25,330
have to think about how you're gonna

00:14:21,730 --> 00:14:26,860
carefully Corral and store it and what I

00:14:25,330 --> 00:14:30,610
find is yeah I've only been at two

00:14:26,860 --> 00:14:34,240
organizations that had HIPAA data and in

00:14:30,610 --> 00:14:36,970
both cases it was it was amazing at how

00:14:34,240 --> 00:14:39,720
much care went into that data right so

00:14:36,970 --> 00:14:42,130
like you know legal would have their say

00:14:39,720 --> 00:14:43,360
we had to be extremely careful with who

00:14:42,130 --> 00:14:45,310
had access you had to go through

00:14:43,360 --> 00:14:47,650
training there was all sorts of hurdles

00:14:45,310 --> 00:14:49,150
that you had to go through to even be

00:14:47,650 --> 00:14:52,150
able to work on the systems that had

00:14:49,150 --> 00:14:54,250
access to HIPAA data but then for some

00:14:52,150 --> 00:14:59,020
reason with almost everything else it's

00:14:54,250 --> 00:15:00,550
kind of like and then you know kind of

00:14:59,020 --> 00:15:02,590
kind of back to your point with with the

00:15:00,550 --> 00:15:04,870
with the IOT device

00:15:02,590 --> 00:15:06,610
it's interesting how maybe sometimes

00:15:04,870 --> 00:15:08,680
you're capturing a whole bunch of data

00:15:06,610 --> 00:15:10,690
points that seem meaningless but they

00:15:08,680 --> 00:15:13,990
can be combined in a way where they can

00:15:10,690 --> 00:15:16,330
be extremely harmful and you might not

00:15:13,990 --> 00:15:17,530
even realize it until years later you

00:15:16,330 --> 00:15:19,330
might not even realize it until you're

00:15:17,530 --> 00:15:22,630
breached and then the data is combined

00:15:19,330 --> 00:15:24,220
by somebody else I think I think there's

00:15:22,630 --> 00:15:28,420
a there's been some examples of where

00:15:24,220 --> 00:15:29,980
that's been you know the the we talk we

00:15:28,420 --> 00:15:32,530
talk about this kind of like there was

00:15:29,980 --> 00:15:34,570
this discussion yesterday about ml ops

00:15:32,530 --> 00:15:37,030
right and this idea that we're having

00:15:34,570 --> 00:15:39,040
was AI ops right and it's this idea that

00:15:37,030 --> 00:15:40,840
we're applying machine learning to you

00:15:39,040 --> 00:15:42,070
know to data metrics that we're getting

00:15:40,840 --> 00:15:43,360
off our devices now but we're applying

00:15:42,070 --> 00:15:46,720
that to all kinds of today that we

00:15:43,360 --> 00:15:48,610
collect and and what's interesting

00:15:46,720 --> 00:15:50,410
frightening about that as the data is

00:15:48,610 --> 00:15:51,820
coming in as kind of this like see you

00:15:50,410 --> 00:15:53,830
know the people like use the term data

00:15:51,820 --> 00:15:56,800
Lake which is very ridiculous but but

00:15:53,830 --> 00:15:57,970
but it kind of like you know reveals the

00:15:56,800 --> 00:15:59,350
problem right which is that it's just

00:15:57,970 --> 00:16:01,120
kind of like a big blob of data that

00:15:59,350 --> 00:16:02,470
we're operating on it and then the

00:16:01,120 --> 00:16:04,450
models that are applied to do it you

00:16:02,470 --> 00:16:07,840
know they're not actually magic right

00:16:04,450 --> 00:16:10,510
they're applied using you know the the

00:16:07,840 --> 00:16:11,950
the preconditions that the person who's

00:16:10,510 --> 00:16:14,830
developing those are setting and so

00:16:11,950 --> 00:16:16,210
there's this weird thing that people say

00:16:14,830 --> 00:16:18,130
oh well it's the algorithm the deciding

00:16:16,210 --> 00:16:20,110
this but we're really encoding like all

00:16:18,130 --> 00:16:22,210
the biases of the people who are doing

00:16:20,110 --> 00:16:24,400
that work into those models so you see

00:16:22,210 --> 00:16:27,400
things like you know machine learning

00:16:24,400 --> 00:16:29,500
models being used to as part of like

00:16:27,400 --> 00:16:30,850
parole processes right to say like oh is

00:16:29,500 --> 00:16:33,190
this person there likely to be you know

00:16:30,850 --> 00:16:34,810
is their recidivism rates you know

00:16:33,190 --> 00:16:37,450
likely to be are they likely to be riaf

00:16:34,810 --> 00:16:38,950
end and then oh weird it turns out that

00:16:37,450 --> 00:16:43,000
that algorithm is completely racist

00:16:38,950 --> 00:16:50,620
right yes and they blame the algorithm

00:16:43,000 --> 00:16:53,170
right well it's just an algorithm yeah I

00:16:50,620 --> 00:16:54,910
just find data collection very

00:16:53,170 --> 00:16:56,500
problematic and that's probably not

00:16:54,910 --> 00:16:59,730
something has a software engineer I

00:16:56,500 --> 00:17:02,020
should say I think it's beyond just

00:16:59,730 --> 00:17:05,380
collecting and storing the data it's

00:17:02,020 --> 00:17:07,000
more so also why are we collecting that

00:17:05,380 --> 00:17:09,730
data and for what purpose are we

00:17:07,000 --> 00:17:13,480
collecting that data because it goes

00:17:09,730 --> 00:17:15,640
back to is it good or is it bad and for

00:17:13,480 --> 00:17:17,860
me just collecting data just to have it

00:17:15,640 --> 00:17:20,800
and to store it for something that may

00:17:17,860 --> 00:17:22,930
be relevant to you in the future isn't a

00:17:20,800 --> 00:17:25,300
good enough reason to collect it and to

00:17:22,930 --> 00:17:27,190
store it so that also comes in to the

00:17:25,300 --> 00:17:29,500
point where I think that we as

00:17:27,190 --> 00:17:31,480
individuals need to start having more

00:17:29,500 --> 00:17:33,810
insight and more control into the data

00:17:31,480 --> 00:17:36,310
that these companies are collecting

00:17:33,810 --> 00:17:37,630
because it's gotten to the point where

00:17:36,310 --> 00:17:39,610
it's ridiculous I know you mentioned

00:17:37,630 --> 00:17:41,530
earlier about breaches for me at this

00:17:39,610 --> 00:17:43,600
point from all the breaches that have

00:17:41,530 --> 00:17:45,730
happened over like the past five ish

00:17:43,600 --> 00:17:47,580
years I just assume if something hits my

00:17:45,730 --> 00:17:48,960
credit card I already have my credit

00:17:47,580 --> 00:17:52,650
it's frozen from something like three

00:17:48,960 --> 00:17:54,540
years ago but but it's just the fact is

00:17:52,650 --> 00:17:56,790
the matter is that there's no real

00:17:54,540 --> 00:17:58,560
repercussions for companies or anything

00:17:56,790 --> 00:18:00,690
that happens that way so I think we just

00:17:58,560 --> 00:18:03,600
need to start taking more control from

00:18:00,690 --> 00:18:05,580
like a consumer standpoint you were

00:18:03,600 --> 00:18:07,140
talking a little bit about like you know

00:18:05,580 --> 00:18:09,300
our responsibility as technologists as

00:18:07,140 --> 00:18:10,800
part of that process and you know what

00:18:09,300 --> 00:18:13,020
we're just what decisions were making

00:18:10,800 --> 00:18:15,390
and I think that extends also to the

00:18:13,020 --> 00:18:17,160
kind of general what kind of software

00:18:15,390 --> 00:18:18,360
are we working on I think there's been a

00:18:17,160 --> 00:18:20,940
really interesting discussion right now

00:18:18,360 --> 00:18:22,110
about I mean I'm changing the subject a

00:18:20,940 --> 00:18:23,760
little bit here but there's been a

00:18:22,110 --> 00:18:26,580
really interesting discussion going on

00:18:23,760 --> 00:18:28,050
about like - what uses is our software

00:18:26,580 --> 00:18:31,200
being applied coming in the general

00:18:28,050 --> 00:18:32,310
world and there's there are some

00:18:31,200 --> 00:18:33,900
technologies that are kind of like

00:18:32,310 --> 00:18:36,690
inherently neutral right so like

00:18:33,900 --> 00:18:38,670
kubernetes is effectively neutral right

00:18:36,690 --> 00:18:46,890
it's not like it's not an inherently

00:18:38,670 --> 00:18:48,540
nefarious I mean so it's it's like not

00:18:46,890 --> 00:18:50,580
it's a kind of a neutral product in and

00:18:48,540 --> 00:18:52,050
of itself now someone you know if if we

00:18:50,580 --> 00:18:54,240
as technologists really believe the

00:18:52,050 --> 00:18:55,890
story that we say that like oh what we

00:18:54,240 --> 00:18:57,240
do really helps accelerate you were

00:18:55,890 --> 00:18:59,070
saying this yesterday accelerate and

00:18:57,240 --> 00:19:00,390
innovate and and like if the technology

00:18:59,070 --> 00:19:02,820
we do really actually helps the

00:19:00,390 --> 00:19:05,190
organizations we're doing then you know

00:19:02,820 --> 00:19:07,140
all technologies can be turned to like

00:19:05,190 --> 00:19:08,130
some bad end right so but there is a

00:19:07,140 --> 00:19:09,570
question of like there are certain

00:19:08,130 --> 00:19:11,820
technologies though that kind of having

00:19:09,570 --> 00:19:13,500
an inherently bad end we're like where

00:19:11,820 --> 00:19:15,450
you say okay well machine learning is

00:19:13,500 --> 00:19:17,280
pretty neutral but like are there

00:19:15,450 --> 00:19:18,930
actually any really good uses for

00:19:17,280 --> 00:19:20,430
Facebook facial recognition which is

00:19:18,930 --> 00:19:22,290
kind of like that extended you know if

00:19:20,430 --> 00:19:24,600
you're working on that like are there

00:19:22,290 --> 00:19:25,530
any non nefarious uses for that and I

00:19:24,600 --> 00:19:26,790
kind of question if you're a

00:19:25,530 --> 00:19:30,060
technologist and you're making you're

00:19:26,790 --> 00:19:32,460
saying you know it's kind of like making

00:19:30,060 --> 00:19:34,710
bombs it's like well you know like at

00:19:32,460 --> 00:19:36,420
the end of the day like you know maybe

00:19:34,710 --> 00:19:37,800
they're right people get bombed which is

00:19:36,420 --> 00:19:41,070
kind of like but like somebody gets

00:19:37,800 --> 00:19:43,410
bombed and that's kind of like I and you

00:19:41,070 --> 00:19:44,640
know it's just people they I mean a lot

00:19:43,410 --> 00:19:46,560
of people they may not feel as

00:19:44,640 --> 00:19:48,540
passionately about this there's a lot of

00:19:46,560 --> 00:19:50,430
other soft engineers and for them it's

00:19:48,540 --> 00:19:51,900
just a job and they go there to code and

00:19:50,430 --> 00:19:54,090
then they go home and they don't think

00:19:51,900 --> 00:19:55,440
about the impact outside of that and

00:19:54,090 --> 00:19:57,630
there's a lot of people there and

00:19:55,440 --> 00:19:59,580
hopefully from this and from my talk

00:19:57,630 --> 00:20:01,140
people understand that like no it's your

00:19:59,580 --> 00:20:02,850
responsibility to think about

00:20:01,140 --> 00:20:05,010
just because you're not on the executive

00:20:02,850 --> 00:20:06,120
board or a CEO doesn't mean that you're

00:20:05,010 --> 00:20:08,060
not allowed to have an opinion about

00:20:06,120 --> 00:20:10,680
what you're working on is being used for

00:20:08,060 --> 00:20:13,650
and I think that we've seen a lot of

00:20:10,680 --> 00:20:16,080
examples of in the last year or so of

00:20:13,650 --> 00:20:18,930
people working at various companies

00:20:16,080 --> 00:20:21,090
having opinions you know collectively or

00:20:18,930 --> 00:20:22,650
individually speaking out and I think

00:20:21,090 --> 00:20:25,560
that sometimes we can look at that and

00:20:22,650 --> 00:20:28,320
think well that seems dramatic and risky

00:20:25,560 --> 00:20:31,530
or whatever and maybe you don't have to

00:20:28,320 --> 00:20:33,570
make a dramatic splash maybe the best

00:20:31,530 --> 00:20:36,330
thing to do is just to think about this

00:20:33,570 --> 00:20:40,440
data collection think about your threat

00:20:36,330 --> 00:20:41,160
models like think about sure think of it

00:20:40,440 --> 00:20:43,530
this way

00:20:41,160 --> 00:20:45,810
if you are somebody who is thinking

00:20:43,530 --> 00:20:47,430
about software operability then you're

00:20:45,810 --> 00:20:49,710
also thinking about the ways that it can

00:20:47,430 --> 00:20:51,990
break and that doesn't just extend to

00:20:49,710 --> 00:20:54,690
downtime and getting paged that could

00:20:51,990 --> 00:20:58,490
extend to data breaches or your

00:20:54,690 --> 00:21:00,780
customers privacy being invaded or

00:20:58,490 --> 00:21:02,490
unintentional side effects that maybe

00:21:00,780 --> 00:21:04,800
you need to model when you're building

00:21:02,490 --> 00:21:06,930
your systems like our deployments work

00:21:04,800 --> 00:21:09,810
this way everything goes into this

00:21:06,930 --> 00:21:11,940
available bucket and then we have no

00:21:09,810 --> 00:21:13,770
protections on it I recently got an

00:21:11,940 --> 00:21:15,780
email from a provider that I had used

00:21:13,770 --> 00:21:17,340
that was like and then everything is in

00:21:15,780 --> 00:21:18,870
this s3 bucket that's open to the world

00:21:17,340 --> 00:21:21,480
we're not gonna do that anymore and I'm

00:21:18,870 --> 00:21:24,510
like why did you okay yeah I mean I know

00:21:21,480 --> 00:21:27,330
why right because ship it was the answer

00:21:24,510 --> 00:21:31,290
I mean it's it's it's really challenging

00:21:27,330 --> 00:21:32,820
right because all these companies want

00:21:31,290 --> 00:21:36,150
to move fast right they want to deliver

00:21:32,820 --> 00:21:38,790
and so in in order to I mean if we're

00:21:36,150 --> 00:21:42,750
talking specifically about security

00:21:38,790 --> 00:21:44,910
related to like the jump from security

00:21:42,750 --> 00:21:48,900
to ethics to say like well if you know

00:21:44,910 --> 00:21:51,600
this this data is taken um you know who

00:21:48,900 --> 00:21:53,580
works somewhere where everything is

00:21:51,600 --> 00:21:56,250
secure right and who works somewhere

00:21:53,580 --> 00:21:59,610
where security is really prioritized as

00:21:56,250 --> 00:22:00,930
heavily as it should be or where you

00:21:59,610 --> 00:22:04,890
know they have a team that actually

00:22:00,930 --> 00:22:06,540
works you know cooperatively in

00:22:04,890 --> 00:22:08,070
conjunction and everything just flows

00:22:06,540 --> 00:22:10,020
naturally with other teams to make it

00:22:08,070 --> 00:22:13,790
work because there's so many different

00:22:10,020 --> 00:22:17,840
facets and layers to security

00:22:13,790 --> 00:22:19,540
and I think ultimately it comes down to

00:22:17,840 --> 00:22:22,310
[Music]

00:22:19,540 --> 00:22:24,860
probably money to be honest I mean what

00:22:22,310 --> 00:22:28,040
is the financial impact if you get

00:22:24,860 --> 00:22:30,740
breached if it's if it's if it's if it's

00:22:28,040 --> 00:22:33,220
company ending then there's a good

00:22:30,740 --> 00:22:36,590
chance that that area's been bolted down

00:22:33,220 --> 00:22:38,510
but if it's okay you know we have to pay

00:22:36,590 --> 00:22:40,970
some money here we have we have some PR

00:22:38,510 --> 00:22:44,720
issues we have to deal with then maybe

00:22:40,970 --> 00:22:47,030
the cost of fixing things is more than

00:22:44,720 --> 00:22:48,380
the cost of dealing with the damage and

00:22:47,030 --> 00:22:50,420
that's something that I think has to

00:22:48,380 --> 00:22:52,040
change I think that I mean some of

00:22:50,420 --> 00:22:53,960
that's kind of like a bigger social

00:22:52,040 --> 00:22:55,580
question than what we as individual

00:22:53,960 --> 00:22:57,010
technologists can do I think we can

00:22:55,580 --> 00:22:59,360
advocate for it which is that like

00:22:57,010 --> 00:23:00,830
companies have been much like pollution

00:22:59,360 --> 00:23:03,110
companies have been allowed to

00:23:00,830 --> 00:23:04,850
externalize those costs right to say

00:23:03,110 --> 00:23:07,160
well the society will deal with that

00:23:04,850 --> 00:23:08,780
cost not us is it you know like it's

00:23:07,160 --> 00:23:10,040
like putting out you know small great

00:23:08,780 --> 00:23:12,200
like well they don't get better get

00:23:10,040 --> 00:23:14,420
charge for it we probably need to change

00:23:12,200 --> 00:23:17,570
that kind of on a on a bigger social

00:23:14,420 --> 00:23:19,280
level but I think that you know if we as

00:23:17,570 --> 00:23:22,310
technologists operating within our org

00:23:19,280 --> 00:23:24,170
or deciding which orders to work for can

00:23:22,310 --> 00:23:28,550
have influence over that and and say

00:23:24,170 --> 00:23:30,740
okay you know we we should maybe not

00:23:28,550 --> 00:23:34,340
wait like because I've been a reservoir

00:23:30,740 --> 00:23:35,960
well eventually we'll eventually you

00:23:34,340 --> 00:23:37,970
know if things get to a certain point

00:23:35,960 --> 00:23:41,420
like at a certain point the rest like

00:23:37,970 --> 00:23:43,160
the idiots in Congress will decide that

00:23:41,420 --> 00:23:45,020
they're gonna be the ones to decide how

00:23:43,160 --> 00:23:46,400
technology should work because they're

00:23:45,020 --> 00:23:47,840
sick of you know because of the American

00:23:46,400 --> 00:23:50,210
folks you know we're here in America

00:23:47,840 --> 00:23:51,770
like are tired of data breaches right

00:23:50,210 --> 00:23:53,480
and they'll act they'll do something

00:23:51,770 --> 00:23:56,240
this is something let's do it right and

00:23:53,480 --> 00:23:57,290
like nobody thinks that that's probably

00:23:56,240 --> 00:23:58,160
gonna be a really good technical

00:23:57,290 --> 00:23:59,480
solution because they're not

00:23:58,160 --> 00:24:01,130
particularly good at that kind of thing

00:23:59,480 --> 00:24:03,650
so you know it's probably something that

00:24:01,130 --> 00:24:05,540
we we should fix ourselves before it

00:24:03,650 --> 00:24:08,150
comes to that point I'm glad that you

00:24:05,540 --> 00:24:10,430
brought up Congress because I do think

00:24:08,150 --> 00:24:12,200
that at some point as far as making sure

00:24:10,430 --> 00:24:15,590
that all data is handled appropriately

00:24:12,200 --> 00:24:18,050
and equally um I do think at some point

00:24:15,590 --> 00:24:20,060
it's going to take some federal law to

00:24:18,050 --> 00:24:21,950
make these companies realize because you

00:24:20,060 --> 00:24:24,050
mentioned the money and absolutely I

00:24:21,950 --> 00:24:26,160
mean when businesses go to the books

00:24:24,050 --> 00:24:28,800
it's like well is it going to cost

00:24:26,160 --> 00:24:33,360
they're costs why I'm gonna go with X so

00:24:28,800 --> 00:24:35,370
well let's make that penalty be damaging

00:24:33,360 --> 00:24:36,840
to the company because it should be you

00:24:35,370 --> 00:24:37,950
should be thinking about security you

00:24:36,840 --> 00:24:39,780
should be thinking about how you're

00:24:37,950 --> 00:24:41,400
using that data and I'm not sure if it's

00:24:39,780 --> 00:24:43,710
gonna happen within this decade or

00:24:41,400 --> 00:24:45,690
perhaps even when I'm alive but it's

00:24:43,710 --> 00:24:48,120
going to I mean there there are actual

00:24:45,690 --> 00:24:50,190
penalties with teeth and GDP are so

00:24:48,120 --> 00:24:52,410
maybe one of the initial conversations

00:24:50,190 --> 00:24:54,900
is maybe we should be looking at that

00:24:52,410 --> 00:24:56,850
for the u.s. because the solution that

00:24:54,900 --> 00:24:58,170
some us-based companies have if you go

00:24:56,850 --> 00:25:00,030
to Europe and you try to go to some

00:24:58,170 --> 00:25:01,710
websites and they're like we just don't

00:25:00,030 --> 00:25:03,750
have this website in Europe anymore

00:25:01,710 --> 00:25:05,100
because we don't want to fix our systems

00:25:03,750 --> 00:25:10,410
and you're like excellent I don't want

00:25:05,100 --> 00:25:12,300
to use your site but that's with him

00:25:10,410 --> 00:25:14,340
that you know California has now enacted

00:25:12,300 --> 00:25:17,550
a very similar law and it does have some

00:25:14,340 --> 00:25:18,990
pretty nasty teeth and most US companies

00:25:17,550 --> 00:25:21,150
are not going to cut off California in

00:25:18,990 --> 00:25:22,380
the same way so I think you know and

00:25:21,150 --> 00:25:25,170
it's it's to have that follow-through

00:25:22,380 --> 00:25:28,170
with the government to actually say no

00:25:25,170 --> 00:25:30,870
we are going to find you right because

00:25:28,170 --> 00:25:32,460
if it's if it's if it's a toothless if

00:25:30,870 --> 00:25:34,230
it's a toothless law if it's a toothless

00:25:32,460 --> 00:25:36,090
policy it's not going to work the

00:25:34,230 --> 00:25:39,420
companies have to feel the pressure in

00:25:36,090 --> 00:25:41,490
order to do it it has to be you know it

00:25:39,420 --> 00:25:43,560
has to be a multiple right it has to be

00:25:41,490 --> 00:25:46,380
like it's X numbers of dollars for every

00:25:43,560 --> 00:25:50,190
infraction not just like a one-time fee

00:25:46,380 --> 00:25:52,650
right yeah and I feel like this is a

00:25:50,190 --> 00:25:54,750
conversation that we probably maybe

00:25:52,650 --> 00:25:58,460
perhaps people will continue in open

00:25:54,750 --> 00:26:01,440
space because we are short on time here

00:25:58,460 --> 00:26:04,950
so I would love to have our panel just

00:26:01,440 --> 00:26:08,760
kind of give their summary what strikes

00:26:04,950 --> 00:26:12,360
you as something that individual

00:26:08,760 --> 00:26:14,340
technologists can do should do you know

00:26:12,360 --> 00:26:18,600
might already be doing that we should

00:26:14,340 --> 00:26:21,650
encourage in order to have this data

00:26:18,600 --> 00:26:23,910
protection and privacy security and

00:26:21,650 --> 00:26:28,050
accountability be something that we

00:26:23,910 --> 00:26:30,990
carry forward sure I mean I think the

00:26:28,050 --> 00:26:32,720
first thing for me is to you know is

00:26:30,990 --> 00:26:35,640
that we should all remember that

00:26:32,720 --> 00:26:38,240
relative to a lot of folks we have a lot

00:26:35,640 --> 00:26:40,220
of privilege right we

00:26:38,240 --> 00:26:42,410
leave us do very well for ourselves we

00:26:40,220 --> 00:26:44,420
have a lot of I mean you know if I were

00:26:42,410 --> 00:26:46,700
to ask who here is hiring like everybody

00:26:44,420 --> 00:26:48,440
would raise your hand right which means

00:26:46,700 --> 00:26:50,360
that we have a lot of power that gives

00:26:48,440 --> 00:26:52,520
us as technologists a lot of power and

00:26:50,360 --> 00:26:54,200
not just the act of writing code but in

00:26:52,520 --> 00:26:55,910
our ability to decide who were gonna

00:26:54,200 --> 00:26:57,620
work with what projects were gonna work

00:26:55,910 --> 00:26:59,990
with who our customers are going to be

00:26:57,620 --> 00:27:01,760
and you know I think it's you know it's

00:26:59,990 --> 00:27:03,650
become time for us to start exercising

00:27:01,760 --> 00:27:09,530
that power and we should probably do it

00:27:03,650 --> 00:27:11,480
together sure I think at first we'll

00:27:09,530 --> 00:27:14,420
start with how you interact with people

00:27:11,480 --> 00:27:16,370
at work because perhaps maybe some of

00:27:14,420 --> 00:27:19,280
you don't want to use your privilege to

00:27:16,370 --> 00:27:22,160
do things like piano podcasts or go give

00:27:19,280 --> 00:27:23,600
talks about it but I mean be that

00:27:22,160 --> 00:27:25,820
squeaky wheel at work

00:27:23,600 --> 00:27:28,880
when you see something that you don't

00:27:25,820 --> 00:27:30,380
agree with keep speaking up and maybe

00:27:28,880 --> 00:27:32,840
something may not happen with that

00:27:30,380 --> 00:27:34,940
because that happens to me it happens to

00:27:32,840 --> 00:27:37,220
everybody but as long as you keep

00:27:34,940 --> 00:27:39,350
vocalizing that at every turn at every

00:27:37,220 --> 00:27:40,640
point that's brought up you can feel

00:27:39,350 --> 00:27:42,679
better with yourself because you're

00:27:40,640 --> 00:27:44,480
voicing your concerns about it

00:27:42,679 --> 00:27:46,670
however if you are somebody that wants

00:27:44,480 --> 00:27:49,280
to exercise that privilege that you have

00:27:46,670 --> 00:27:50,960
outside of work I would definitely say

00:27:49,280 --> 00:27:53,480
start with Twitter that's where I

00:27:50,960 --> 00:27:56,780
started and now I'm on podcasts and

00:27:53,480 --> 00:27:58,670
giving talks um because you you do have

00:27:56,780 --> 00:28:00,020
power within your voice and Twitter does

00:27:58,670 --> 00:28:02,300
work I know a lot of people are like

00:28:00,020 --> 00:28:05,030
Twitter activism doesn't work and we've

00:28:02,300 --> 00:28:07,070
seen I've seen very real just in the

00:28:05,030 --> 00:28:09,290
past 48 hours actually that Twitter

00:28:07,070 --> 00:28:10,910
activism does work and it does have real

00:28:09,290 --> 00:28:14,030
consequences so I would suggest you

00:28:10,910 --> 00:28:17,179
start there yeah I think for me I'd

00:28:14,030 --> 00:28:19,610
probably echo very similar to it both of

00:28:17,179 --> 00:28:20,929
us said because you know I've been

00:28:19,610 --> 00:28:22,790
thinking about this a lot recently too

00:28:20,929 --> 00:28:24,500
it seems that every time something

00:28:22,790 --> 00:28:25,520
happens with like a product launch right

00:28:24,500 --> 00:28:26,990
and it seems to happen a lot in the

00:28:25,520 --> 00:28:28,880
gaming community and things like this

00:28:26,990 --> 00:28:30,020
everyone gets up in arms and they say

00:28:28,880 --> 00:28:31,790
vote with your wallet vote with your

00:28:30,020 --> 00:28:33,080
wallet right like don't you know boycott

00:28:31,790 --> 00:28:36,410
this product don't give money of that

00:28:33,080 --> 00:28:38,210
and you know a lot of these really

00:28:36,410 --> 00:28:41,480
really big tech companies have been in

00:28:38,210 --> 00:28:44,540
the news recently if folks are upset

00:28:41,480 --> 00:28:46,490
about it but people still go to work

00:28:44,540 --> 00:28:49,790
there every day and I think we can make

00:28:46,490 --> 00:28:51,980
choices about where we want to work and

00:28:49,790 --> 00:28:53,900
you know sort of back to your talk

00:28:51,980 --> 00:28:56,480
I know it can be extremely difficult for

00:28:53,900 --> 00:28:58,429
some folks to to be able to make those

00:28:56,480 --> 00:29:00,950
choices right to have the option to say

00:28:58,429 --> 00:29:04,850
like I'm gonna leave this this job here

00:29:00,950 --> 00:29:07,730
out of principles right but I think if

00:29:04,850 --> 00:29:10,520
if as a community if we banded together

00:29:07,730 --> 00:29:12,140
and showed some of these companies that

00:29:10,520 --> 00:29:13,760
you know what we don't think it's okay

00:29:12,140 --> 00:29:14,240
and we're just not gonna work there

00:29:13,760 --> 00:29:16,940
anymore

00:29:14,240 --> 00:29:18,530
we'll find another company that has you

00:29:16,940 --> 00:29:20,299
know a better code of conduct a better

00:29:18,530 --> 00:29:23,090
way of doing things I think it would

00:29:20,299 --> 00:29:25,880
really really send ripples through the

00:29:23,090 --> 00:29:29,660
industry because as Tim said everybody's

00:29:25,880 --> 00:29:31,309
hiring and they you know what are they

00:29:29,660 --> 00:29:32,270
gonna do if they start if they start

00:29:31,309 --> 00:29:35,570
losing people they don't have people

00:29:32,270 --> 00:29:37,610
doing the work right yeah all right I

00:29:35,570 --> 00:29:41,600
think that's powerful sentiments we

00:29:37,610 --> 00:29:44,929
leave it at that and thank you so much

00:29:41,600 --> 00:29:46,970
to our panel I think this has been very

00:29:44,929 --> 00:29:49,370
thought-provoking and informative so

00:29:46,970 --> 00:29:51,790
thank you thank you thank you

00:29:49,370 --> 00:29:58,900
[Applause]

00:29:51,790 --> 00:29:58,900
[Music]

00:30:01,610 --> 00:30:03,670

YouTube URL: https://www.youtube.com/watch?v=lZNgNVxu-cM


