Title: DevOpsDays Chicago 2019 - Arrested Devops LIVE!
Publication date: 2019-09-09
Playlist: DevOpsDays Chicago 2019
Description: 
	Arrested Devops LIVE!
Captions: 
	00:00:13,780 --> 00:00:14,780
Arrested DevOps Live!

00:00:14,780 --> 00:00:15,780
>> Hello.

00:00:15,780 --> 00:00:16,780
>> Testing.

00:00:16,780 --> 00:00:17,780
>> Emphasis on my Ps.

00:00:17,780 --> 00:00:18,780
>> All right.

00:00:18,780 --> 00:00:19,780
>> Trevor, you need to watch the timer.

00:00:19,780 --> 00:00:22,470
>> I will give you the 5, 4, 3 -- >> Before we get started on the podcast recording,

00:00:22,470 --> 00:00:28,360
how many people here listen to -- (drop in audio) -- so coming -- I'm from New York City,

00:00:28,360 --> 00:00:34,860
and I want to know what to expect, how does it work, and how does public transit work

00:00:34,860 --> 00:00:41,140
when you are not in New York City anyway and all of those things that you are worried about

00:00:41,140 --> 00:00:42,660
when you are traveling?

00:00:42,660 --> 00:00:49,559
And one thing that is phenomenal is how much support the team has given -- I tweeted earlier,

00:00:49,559 --> 00:00:53,379
shortly after I was accepted, they asked the speakers, would they like a special song when

00:00:53,379 --> 00:00:54,429
they go on to the stage?

00:00:54,429 --> 00:00:59,670
I was like, I love this group more than anything else in the world.

00:00:59,670 --> 00:01:08,110
Not only are they like, we're going to help you figure out transportation and make this

00:01:08,110 --> 00:01:16,820
and that part easy and you have the support and you will eat the best food ever, but we

00:01:16,820 --> 00:01:25,080
make you feel amazing when you walk on to a stage.

00:01:25,080 --> 00:01:26,680
How about that?

00:01:26,680 --> 00:01:30,380
That's the first impression I have, and so far, nothing has surprised me.

00:01:30,380 --> 00:01:32,840
So hoo-rah, I see the moving parts moving smoothly.

00:01:32,840 --> 00:01:37,380
>> Jeff, what have you seen over the years you have been here, how does the event feel

00:01:37,380 --> 00:01:38,380
different?

00:01:38,380 --> 00:01:41,560
>> In a lot of ways, it feels the same, in other ways, it is different.

00:01:41,560 --> 00:01:49,460
You see the event grow and you see the process get smoother, the audio and video -- it has

00:01:49,460 --> 00:01:51,310
gotten a lot smoother.

00:01:51,310 --> 00:01:56,159
But the community just continues to grow.

00:01:56,159 --> 00:02:00,720
It is absolutely one of my favorite conferences.

00:02:00,720 --> 00:02:06,670
Even if I was not speaking I would attend because of the participants, who are great,

00:02:06,670 --> 00:02:16,620
the open space is fantastic, and there's an energy for me that is unmatched in a lot of

00:02:16,620 --> 00:02:17,620
conferences.

00:02:17,620 --> 00:02:21,240
>> And Jessie, you went to DevOpsDays and this is your first time in Chicago, what did

00:02:21,240 --> 00:02:28,790
you -- from what you participated in so far, what are your initial feels?

00:02:28,790 --> 00:02:36,040
>> Yeah I would say that it is organized well, not to suck up.

00:02:36,040 --> 00:02:44,870
But, yeah, and also just the varied audience backgrounds.

00:02:44,870 --> 00:02:47,989
So people who come from different fields, I was talking to someone who does data science,

00:02:47,989 --> 00:02:50,900
and one that is a data -- a technical writer, and it is nice when conferences can draw different

00:02:50,900 --> 00:02:55,189
groups of people versus just, like, having group thought or whatever.

00:02:55,189 --> 00:02:56,189
>> Fantastic.

00:02:56,189 --> 00:02:57,189
So I want to -- oh.

00:02:57,189 --> 00:02:58,189
>> I was going to say, too.

00:02:58,189 --> 00:03:00,680
We are only halfway through the event at this point.

00:03:00,680 --> 00:03:05,939
What are your favorite conversations we've had so far in the last couple days?

00:03:05,939 --> 00:03:16,299
>> So I think that one thing that has been really exciting to me, a lot of the talks

00:03:16,299 --> 00:03:17,299
are neat.

00:03:17,299 --> 00:03:24,420
My background is not DevOps, I'm giving a talk that is interesting to a lot of folks

00:03:24,420 --> 00:03:26,260
but a varied conversation.

00:03:26,260 --> 00:03:33,810
And so kind of hearing talks where people are describing, like, situations that occur

00:03:33,810 --> 00:03:43,430
within DevOps, but also within the context of something a human would experience, you

00:03:43,430 --> 00:03:50,200
know, we had talks involve things going viral online and getting tickets because signs are

00:03:50,200 --> 00:03:51,200
difficult.

00:03:51,200 --> 00:03:58,220
And a favorite conversation is when we go to open spaces and what makes an interesting

00:03:58,220 --> 00:04:03,120
-- what is one hoak you can have on a talk submission is bringing in ways you can bring

00:04:03,120 --> 00:04:05,549
in the technical with the lived experience portions.

00:04:05,549 --> 00:04:10,110
>> I think there was a really interesting parallel between Jeff's talk and Jessie's

00:04:10,110 --> 00:04:12,110
talk in different ways, though.

00:04:12,110 --> 00:04:18,989
So my first question, did anybody but me -- because Jessie's talk was in the afternoon.

00:04:18,989 --> 00:04:21,930
I want to give context -- >> Yeah.

00:04:21,930 --> 00:04:27,520
>> Either the three of you, did any of you see Jessie's talk?

00:04:27,520 --> 00:04:28,520
>> Yes.

00:04:28,520 --> 00:04:35,740
>> So he said that he talked about why open source firmware was important, and I like

00:04:35,740 --> 00:04:43,400
to think about this talk that scares the shit out of you, when you realize how terrible

00:04:43,400 --> 00:04:45,070
it is.

00:04:45,070 --> 00:04:52,860
And we are the thought around those ethics is where it comes in, because it seemed like

00:04:52,860 --> 00:04:59,930
a good idea to put a web server in there, because what could go wrong, is how can the

00:04:59,930 --> 00:05:02,960
-- how can these things be misused.

00:05:02,960 --> 00:05:08,490
And I'm interested to see where you see those parallels.

00:05:08,490 --> 00:05:15,990
>> Yeah, it is definitely something that happens, right?

00:05:15,990 --> 00:05:20,630
And when you see technologies misapplied, and we do it ourselves in the operations space

00:05:20,630 --> 00:05:25,729
and the engineering space, where we choose a technology for the wrong purposes, we want

00:05:25,729 --> 00:05:35,690
to play around with it and it is interesting, and not thinking of the downstream implications.

00:05:35,690 --> 00:05:44,580
I thought of the Zoom breach, were they were like, we will install a local web server to

00:05:44,580 --> 00:05:46,090
re-install the software.

00:05:46,090 --> 00:05:52,669
And they did not mean to be malicious, but to make it easier to accomplish X.

00:05:52,669 --> 00:06:00,130
It makes it difficult to think about the different paths that technology can take us down and

00:06:00,130 --> 00:06:01,130
the consequences that come from it.

00:06:01,130 --> 00:06:03,699
So the only thing is to have more conversations around it and more viewpoints.

00:06:03,699 --> 00:06:09,819
And Google had the -- there was not a black eye in that room.

00:06:09,819 --> 00:06:11,630
And people got caught.

00:06:11,630 --> 00:06:18,690
There was opening the conversation, broadening the perspectives, and one step beyond what

00:06:18,690 --> 00:06:27,910
I'm trying to get done right now, and thinking about the wrong-term implications.

00:06:27,910 --> 00:06:35,389
>> And Maddy start would the question, what could go wrong with putting in a web server

00:06:35,389 --> 00:06:37,229
in the system?

00:06:37,229 --> 00:06:42,040
We never asked the question, what could go right?

00:06:42,040 --> 00:06:46,100
>> We never asked the question, what could go wrong.

00:06:46,100 --> 00:06:48,350
But I was asking rhetorically.

00:06:48,350 --> 00:06:50,160
>> Literally rather than facetiously.

00:06:50,160 --> 00:06:57,060
>> I was asking for permissions in AWS, and the policy, and the CID for the profile was,

00:06:57,060 --> 00:06:59,830
what could go wrong, allow, star star.

00:06:59,830 --> 00:07:02,099
>> At least that is self-aware.

00:07:02,099 --> 00:07:11,169
>> A lot of employees are very process-oriented, if it is not a part of your process to think

00:07:11,169 --> 00:07:19,449
-- or even ask that question, what could go wrong, you just do ABCD and then your finish

00:07:19,449 --> 00:07:20,449
your task.

00:07:20,449 --> 00:07:26,669
And sometimes at what point were you thinking or, you know, wondering what could go wrong.

00:07:26,669 --> 00:07:32,880
>> Yeah, what do you think drives that, you know, ticketing the boxes and going through

00:07:32,880 --> 00:07:35,539
the motions kind of thing.

00:07:35,539 --> 00:07:40,180
Most people are wanting to do good work, but there is something within the organization,

00:07:40,180 --> 00:07:44,669
there is something that has caused this to be the, I'm just sort of taking, going through

00:07:44,669 --> 00:07:45,669
the motions?

00:07:45,669 --> 00:07:47,889
>> I think sometimes it is a matter of psychological safety within our organization, I certainly

00:07:47,889 --> 00:07:50,910
have been in positions where it would be extremely difficult to push process and to say, why

00:07:50,910 --> 00:07:54,660
don't we X, and then also there have been situations where people are very open to that.

00:07:54,660 --> 00:08:00,520
And the amount of, like, we talk about innovation a lot in tech, and the amount that you can

00:08:00,520 --> 00:08:06,610
do in an environment where it is like, okay, to say why is it like this, and to take more

00:08:06,610 --> 00:08:08,759
time to do research is -- they are night and day.

00:08:08,759 --> 00:08:15,800
And also, what people feel comfortable asking for in doing is really, like, guides how much

00:08:15,800 --> 00:08:21,841
-- it puts us in a position where it is best to check the boxes, and maybe there is --

00:08:21,841 --> 00:08:30,110
>> If we tie it back to what Jeff was saying this morning, and the idea of some sort of

00:08:30,110 --> 00:08:34,700
ethical body around technology, I think one of the reasons why we make the split-second

00:08:34,700 --> 00:08:40,229
decisions to do something potentially unsafe is we have a pressure saying we need to get

00:08:40,229 --> 00:08:42,140
something accomplished or something finished.

00:08:42,140 --> 00:08:46,380
But we don't have the moral pressure to challenge just getting something done.

00:08:46,380 --> 00:08:53,450
You may do something that you know, like setting all stars in an access policy, you may need

00:08:53,450 --> 00:09:00,460
to do that just to get the tasks done, but you don't have the authority, maybe, or the

00:09:00,460 --> 00:09:09,490
moral authority to say, this is wrong, and it is going to cause us a big problem.

00:09:09,490 --> 00:09:18,440
>> And it is sometimes organizational standards and culture.

00:09:18,440 --> 00:09:24,610
You think of a world where though things aren't allowed.

00:09:24,610 --> 00:09:34,350
10 years ago, I was at a job and putting a password in a config file wasn't that crazy.

00:09:34,350 --> 00:09:42,340
And then you go to a job, what is wrong with you, why would you do that?

00:09:42,340 --> 00:09:47,090
That is not acceptable here, and it keeps moving up and up the pipeline and getting

00:09:47,090 --> 00:09:48,090
more sophisticated.

00:09:48,090 --> 00:09:50,560
Does anyone at Google submit a new function without unit testing?

00:09:50,560 --> 00:09:53,680
They probably are laughed out the door, I hope.

00:09:53,680 --> 00:09:54,680
Probably not.

00:09:54,680 --> 00:09:55,680
>> Yeah, definitely culture.

00:09:55,680 --> 00:09:59,270
If your culture is make money, even if it comes from the expense of exploiting your

00:09:59,270 --> 00:10:04,170
own customers and nobody has ramifications for doing that, then --

00:10:04,170 --> 00:10:09,340
>> We were in a research center where we were not putting anything in the cloud yet, we

00:10:09,340 --> 00:10:14,260
don't trust the cloud and, especially, as a large government research center, we definitely

00:10:14,260 --> 00:10:15,260
don't.

00:10:15,260 --> 00:10:18,540
And so things are stored and hopefully duplicated.

00:10:18,540 --> 00:10:23,310
And then, if something crashed, we lost data and that was -- there was definitely -- you

00:10:23,310 --> 00:10:30,000
lose data, grieve a little, and then you put your head down and create again.

00:10:30,000 --> 00:10:34,550
That was an unexpected process, it happened sometimes.

00:10:34,550 --> 00:10:51,070
Now when I think about that, it sounds bizarre to me, that we put ourselves in this situation.

00:10:51,070 --> 00:11:00,590
>> We are talking about people being in a place of psychological safety.

00:11:00,590 --> 00:11:08,100
We like to speak in practicalities on the show now and then, so this would be a good

00:11:08,100 --> 00:11:11,010
time, given the balance of this panel.

00:11:11,010 --> 00:11:13,620
So Jeff, you're a management-type person.

00:11:13,620 --> 00:11:16,460
I mean that in a nice way.

00:11:16,460 --> 00:11:26,040
So you are a leader, you lead teams, so first I want to think from the perspective of, if

00:11:26,040 --> 00:11:37,460
you are someone saying I want to build more psychological safety on a team that I lead,

00:11:37,460 --> 00:11:44,330
what are some things that you do -- hopefully you are doing things.

00:11:44,330 --> 00:11:45,330
I believe you are.

00:11:45,330 --> 00:11:46,330
>> Vulnerability.

00:11:46,330 --> 00:11:51,660
>> That is probably the biggest thing you can do, showing vulnerability, not being afraid

00:11:51,660 --> 00:11:53,190
to say I don't know.

00:11:53,190 --> 00:12:00,350
One big thing on a team, I don't know is an okay answer, it is not the end of a conversation.

00:12:00,350 --> 00:12:02,550
You have to figure things out.

00:12:02,550 --> 00:12:10,010
And giving people that room and that space to learn and explore.

00:12:10,010 --> 00:12:14,140
Another thing I like to do is to push education as part of your job.

00:12:14,140 --> 00:12:16,080
There is no reason -- you are on call.

00:12:16,080 --> 00:12:20,450
Why should you have to learn this new technology for my company's benefit on your own time?

00:12:20,450 --> 00:12:27,310
Spend time at work learning this thing, it is part of your job.

00:12:27,310 --> 00:12:31,830
I don't expect you to know it.

00:12:31,830 --> 00:12:36,850
So if you have to take an hour or two hours a week to sit in the kitchen and read, that's

00:12:36,850 --> 00:12:37,850
fine.

00:12:37,850 --> 00:12:40,440
I want to make sure that you are comfortable doing that.

00:12:40,440 --> 00:12:44,000
So between those things, people begin to get comfortable.

00:12:44,000 --> 00:12:49,310
When people want to dissent on an opinion, create a safe space and a dialogue that we

00:12:49,310 --> 00:12:50,310
can have about it.

00:12:50,310 --> 00:12:53,110
That is a space where -- people don't feel comfortable disagreeing, so they go along

00:12:53,110 --> 00:12:56,850
with something that they know is wrong or feel strongly against, creating an atmosphere

00:12:56,850 --> 00:13:05,820
where people disagree in a constructive manner, at the end of the day, we are a team and will

00:13:05,820 --> 00:13:13,300
figure this thing out -- it is a testament if the teams disagree, and in the end, we

00:13:13,300 --> 00:13:17,430
come to a resolution and everyone is still all in.

00:13:17,430 --> 00:13:23,610
>> A bit more on the education piece, one thing I have noticed, I have been in work

00:13:23,610 --> 00:13:28,800
environments that are very helpful in this regard and could be very unhelpful as well.

00:13:28,800 --> 00:13:34,350
And the major difference was having that time to be able to learn and, when things did go

00:13:34,350 --> 00:13:41,780
wrong, in my research life, one time, we had a piece of machinery that had a problem that

00:13:41,780 --> 00:13:47,430
no one realized for a month, and there was a lot of back-tracking that needed to happen.

00:13:47,430 --> 00:13:50,360
But we went through in what we would call a blameness way.

00:13:50,360 --> 00:13:54,740
It was an educational experience for everybody.

00:13:54,740 --> 00:14:03,720
We said, okay, and we all knew how that machine worked in the end, we had something go wrong

00:14:03,720 --> 00:14:08,620
cost us time and we had to trace back.

00:14:08,620 --> 00:14:17,280
And those two pieces, sitting at the kitchen, getting better at your job at your job instead

00:14:17,280 --> 00:14:26,500
of it having something burning you out in the evenings and having a situation, when

00:14:26,500 --> 00:14:32,920
something goes wrong, it is less about the person who made the commit and who made the

00:14:32,920 --> 00:14:38,350
process better, that is something that the team needs to do, it has been imeasurable

00:14:38,350 --> 00:14:39,510
in both fields I worked at, actually.

00:14:39,510 --> 00:14:43,010
>> What are some -- again, thinking -- we talked about things that leadership can do.

00:14:43,010 --> 00:14:51,850
Maybe -- sometimes we are in a position where we are not leading the team, or an individual

00:14:51,850 --> 00:14:59,580
contributor, we might be in a position where we don't feel that level of psychological

00:14:59,580 --> 00:15:00,580
safety.

00:15:00,580 --> 00:15:06,890
How can we help influence leadership and the team, based on your experiences, hopefully

00:15:06,890 --> 00:15:07,890
positive ones?

00:15:07,890 --> 00:15:16,580
>> I would say, in most cases I was in situations like that, I tend to be -- I have a lot of

00:15:16,580 --> 00:15:23,430
can dor with leadership, and that can go one of two ways, depending on who the person is.

00:15:23,430 --> 00:15:30,030
So I myself, like, if someone came to me and did what I did to other people, I would be

00:15:30,030 --> 00:15:35,830
super happy to know exactly what they felt and some people do not like knowing how people

00:15:35,830 --> 00:15:36,830
feel.

00:15:36,830 --> 00:15:37,830
So, yeah, it depends.

00:15:37,830 --> 00:15:40,260
I just want to work with you.

00:15:40,260 --> 00:15:47,230
>> It is also important to think about leadership as a role, not a position, because I have

00:15:47,230 --> 00:15:51,870
been on teams where I wasn't the manager but the leader of the team.

00:15:51,870 --> 00:15:56,000
I don't know what the author said, if you work into a group of people, you can pick

00:15:56,000 --> 00:15:58,980
out who the leader is regardless of their position.

00:15:58,980 --> 00:16:01,440
So if you are the emotional leader of the team, there's psychological safety conch you

00:16:01,440 --> 00:16:08,040
can provide for the team, and you can put your manager in and say, listen, XYZ isn't

00:16:08,040 --> 00:16:17,820
working out for us, we can try something different and solicit the opinions and everything that

00:16:17,820 --> 00:16:22,030
has fallen flat, I know Max is stewing about this thing, he hates Node.js.

00:16:22,030 --> 00:16:26,950
So we will give max an opportunity to talk about it.

00:16:26,950 --> 00:16:32,420
And creating the environments where it is clear that you have that person's back and

00:16:32,420 --> 00:16:34,959
set them up to respectfully disagree.

00:16:34,959 --> 00:16:42,110
>>>> We think of one of the definitions with a high level of psychological safety, as an

00:16:42,110 --> 00:16:45,950
example, there is equal amount of conversation, everyone speaks an equal amount.

00:16:45,950 --> 00:16:48,710
And that is easier said than done.

00:16:48,710 --> 00:16:54,430
If you think a couple years ago, there was a talk on lending privilege.

00:16:54,430 --> 00:16:58,750
If you lend privilege, you have a responsibility to drive that.

00:16:58,750 --> 00:17:05,800
It is easy for me to talk a lot than a person at the event all day.

00:17:05,800 --> 00:17:12,760
Think about ways I can use that ability, that I feel safe doing that all day long, to help

00:17:12,760 --> 00:17:14,610
people who are not necessarily in that position.

00:17:14,610 --> 00:17:16,289
>> I think that's a huge point.

00:17:16,289 --> 00:17:23,690
When I first started, in technology, I was taking any job that anyone would give me.

00:17:23,690 --> 00:17:29,230
As I became more experienced and more confident now, I feel comfortable putting stuff on the

00:17:29,230 --> 00:17:37,870
line and saying, this is a bad idea, I don't like calling you out on that.

00:17:37,870 --> 00:17:46,500
And lending privilege to shield someone, max has a good point, we can talk about this,

00:17:46,500 --> 00:17:47,660
that is huge for someone.

00:17:47,660 --> 00:17:50,420
If I'm laid off or fired, I can get another job.

00:17:50,420 --> 00:17:55,260
Someone else is not confident in that position and lending that privilege is huge for them,

00:17:55,260 --> 00:17:56,260
so they need to speak up.

00:17:56,260 --> 00:18:02,700
>> Starting my career, I was not the person that could be aggressive and get away with

00:18:02,700 --> 00:18:03,700
it.

00:18:03,700 --> 00:18:11,120
But now I have, like, so found myself in such a position, yeah, I will do that whenever

00:18:11,120 --> 00:18:17,040
needs be, known the other side of it and when you can't speak up, I try to say something.

00:18:17,040 --> 00:18:21,580
>> Jumping back a little bit, when you are approaching and taking the position, I want

00:18:21,580 --> 00:18:28,500
to approach my manager, one thing I found helpful is the level of praise in private,

00:18:28,500 --> 00:18:29,500
reprimand in public -- no, other way.

00:18:29,500 --> 00:18:31,280
>> I see you worked for the person I worked for.

00:18:31,280 --> 00:18:37,920
>> You need to go back to that person, they are feeling their own vulnerabilities, we

00:18:37,920 --> 00:18:44,620
have comfort and leadership in that role, they have their face on, figuring things out

00:18:44,620 --> 00:18:47,750
and are as vulnerable as you are.

00:18:47,750 --> 00:18:55,350
So taking the time when that time is available and trying to make that a smooth conversation

00:18:55,350 --> 00:18:56,530
can help a lot.

00:18:56,530 --> 00:19:01,520
Some of the worst workplaces, I have been in, would involve people just coming up -- ambushing

00:19:01,520 --> 00:19:03,590
you in the hallway situations.

00:19:03,590 --> 00:19:07,890
And that -- it can be really stressful and ruin your whole prospect on what your day

00:19:07,890 --> 00:19:10,590
is and make you want to hide in the bathroom.

00:19:10,590 --> 00:19:12,059
We don't need that.

00:19:12,059 --> 00:19:18,590
>> When it comes to lending privilege, I don't need to be in the moment, in front of that

00:19:18,590 --> 00:19:19,590
person, either.

00:19:19,590 --> 00:19:25,220
Bringing people up in conversation, reminding people that the idea that came -- that you

00:19:25,220 --> 00:19:30,830
are all moving forward with somebody's idea and talking about them and that light lets

00:19:30,830 --> 00:19:37,700
them shine in the best way possible is another way and an important way to lend that privilege.

00:19:37,700 --> 00:19:44,890
>> So as we're starting to get towards wrapping up, I wanted to go back to your talks and

00:19:44,890 --> 00:19:46,980
to the things that you talked about today.

00:19:46,980 --> 00:19:53,930
If you had one key message from the presentation today, what would be the thing that you want

00:19:53,930 --> 00:19:57,760
people to take away?

00:19:57,760 --> 00:20:08,500
>> That we need to take a bit of responsibility for the things that we're creating, and we

00:20:08,500 --> 00:20:15,670
need to own some of that -- some of those consequences so that these aren't things that

00:20:15,670 --> 00:20:17,000
are just happening in a vacuum.

00:20:17,000 --> 00:20:24,110
So when there are bad actions happening, we can't just pass the buck on that.

00:20:24,110 --> 00:20:29,270
It is up for us to say something is wrong.

00:20:29,270 --> 00:20:46,510
Maybe we are not in a position where we are safe doing that, but it is on us to figure

00:20:46,510 --> 00:20:50,130
out how to make it safe for people to do it.

00:20:50,130 --> 00:20:54,630
As technology is more advanced, the stakes are higher and higher.

00:20:54,630 --> 00:20:58,560
>> Your comments are a form of documentation, and documentation is good.

00:20:58,560 --> 00:21:09,540
We should make sure that we are supporting people and doing the best documentation for

00:21:09,540 --> 00:21:12,970
them.

00:21:12,970 --> 00:21:19,960
>> I would say the people who work on various layers of software should talk to each other

00:21:19,960 --> 00:21:28,840
more, in talking to each other, actively listen and try to come to a solution on the problems

00:21:28,840 --> 00:21:31,940
between the interfaces.

00:21:31,940 --> 00:21:34,070
>> Fantastic.

00:21:34,070 --> 00:21:44,020
And one last thing I would like to do, and then before we wrap up, we have a panel who

00:21:44,020 --> 00:21:59,030
is doing all sorts of interesting and different things and we want to give you an opportunity

00:21:59,030 --> 00:22:14,420
to plug a thing you're doing, whether it is your podcast, whether it is -- I'm not going

00:22:14,420 --> 00:22:15,740
to tell you.

00:22:15,740 --> 00:22:18,600
So we are willing to start.

00:22:18,600 --> 00:22:21,840
>> God, I'm in the process of writing a book.

00:22:21,840 --> 00:22:34,320
Maybe one day I will finish it, but I'm writing on a book called real-world DevOps and we

00:22:34,320 --> 00:22:45,810
will give it from the perspective of an individual contributor and what they can do in imperfect

00:22:45,810 --> 00:22:46,810
organizations.

00:22:46,810 --> 00:22:58,890
There's a lot of work out there for leaders that want to do a top-down approach, and a

00:22:58,890 --> 00:23:06,760
lot of people who are struggling in environments where there's a lot of stuff they can do,

00:23:06,760 --> 00:23:11,820
and they need a field guide on how to go about accomplishing that.

00:23:11,820 --> 00:23:15,670
That's the target audience for my book, due out 2020.

00:23:15,670 --> 00:23:16,830
>> Plus or minus.

00:23:16,830 --> 00:23:19,280
>> Matt, how is that book you are writing?

00:23:19,280 --> 00:23:23,120
>> Hold on to your hats, this is my first time announcing this.

00:23:23,120 --> 00:23:27,460
I met two other fabulous speakers when I spoke for the first time this February.

00:23:27,460 --> 00:23:34,240
And the three of us are starting the quick developer guides YouTube channel, and we're

00:23:34,240 --> 00:23:41,190
going to have a series of 10-minute videos on, like, everything from how do you get started

00:23:41,190 --> 00:23:47,240
using version control to, like, so you're thinking of quitting your job and doing this

00:23:47,240 --> 00:23:58,430
I'm going to be a dev thing, how are you going to budget for that?

00:23:58,430 --> 00:24:09,570
So a bunch of different skills that people want to consider if they are getting started

00:24:09,570 --> 00:24:10,909
in this whole world.

00:24:10,909 --> 00:24:15,640
>> Yet again, a new project is announced for the first time on arrested DevOps.

00:24:15,640 --> 00:24:19,460
The Michael Ross podcast was announced first here, Jessie and Andrew started.

00:24:19,460 --> 00:24:20,460
So breaking news.

00:24:20,460 --> 00:24:21,850
What do you want to plug?

00:24:21,850 --> 00:24:41,400
>> So Ben Horowitz's, how to 

00:24:41,400 --> 00:24:45,820
think about hard things.

00:24:45,820 --> 00:24:57,720
>> I'm not actively looking for a job.

00:24:57,720 --> 00:25:07,600
>> [ Laughter ]. >> I will say it is -- every time, wherever

00:25:07,600 --> 00:25:11,559
I'm working, and something happens, yeah.

00:25:11,559 --> 00:25:18,309
Do you know what you're talking about.

00:25:18,309 --> 00:25:29,810
So this is great, I'm glad to have another -- wrap-up another arrested DevOps podcast

00:25:29,810 --> 00:25:31,490
here at DevOpsDays Chicago.

00:25:31,490 --> 00:25:36,800
I want to thank our awesome panel for joining us.

00:25:36,800 --> 00:25:47,110
As an organizer, thank you for being part of our program.

00:25:47,110 --> 00:25:58,330
Thank you, we will give it up for our panel.

00:25:58,330 --> 00:26:16,350
It is a live studio audience, applaud!

00:26:16,350 --> 00:26:18,330
When we recorded this in Indianapolis, we had applause signs.

00:26:18,330 --> 00:26:20,930
At least I didn't do that to you.

00:26:20,930 --> 00:26:56,830
Check us out on the internet, Arrested DevOps.com, you can find us on iTunes, leave us a review

00:26:56,830 --> 00:27:07,540
on the iTunes store.

00:27:07,540 --> 00:27:13,950
We are now on iHeartRadio and Spotify!

00:27:13,950 --> 00:27:17,920
You can listen to your heart's content.

00:27:17,920 --> 00:27:19,800
I'm your cohost, Matt Stratton.

00:27:19,800 --> 00:27:33,490
We are Arrested DevOps, and there's always DevOps in the banana stand.

00:27:33,490 --> 00:27:37,030
Thank you, everybody.

00:27:37,030 --> 00:27:45,630
That's the end of the show.

00:27:45,630 --> 00:27:50,920
One of my friends is a composer randomly through that together for us.

00:27:50,920 --> 00:27:55,080
I was like, should I credit you?

00:27:55,080 --> 00:27:56,650
He said...

00:27:56,650 --> 00:27:57,650
no.

00:27:57,650 --> 00:28:04,309
We do have, and by we, I mean me, we have Arrested DevOps stickers, not right here.

00:28:04,309 --> 00:28:12,600
If you want some, find me tomorrow when I have them in my pocket.

00:28:12,600 --> 00:28:13,950
Yeah, great.

00:28:13,950 --> 00:28:32,790
Thank you for being part of 

00:28:32,790 --> 00:28:34,420
the show.

00:28:34,420 --> 00:28:54,740
Don't disappear, because we will want to be back here in, I don't know, five minutes?

00:28:54,740 --> 00:28:57,500
The closing ceremony is in five minutes.

00:28:57,500 --> 00:29:03,620
Hang out here, we will do closing ceremony.

00:29:03,620 --> 00:29:07,210
Thank you, everybody.

00:29:07,210 --> 00:29:12,009
And thank you, guests.

00:29:12,009 --> 00:29:13,210

YouTube URL: https://www.youtube.com/watch?v=UO37w65jTQg


