Title: DevOpsDays Boston 2019 - Infrastructure As Data by Tobias Macey
Publication date: 2019-10-11
Playlist: DevOpsDays Boston 2019
Description: 
	Infrastructure As Data by Tobias Macey

Our ability to build and maintain infrastructure has been made easier and faster by the introduction of technologies such as server virtualization, cloud platforms, container orchestrators, and configuration management frameworks. This has led to the mantra of “infrastructure as code”. Unfortunately, this abstraction is leaky and ignores the inherent statefulness of already deployed services.

Some of the challenges that arise when working on infrastructure as code are the inevitable refactorings and how they will interact with the current state of our environments. Adding and removing capacity can be fairly painless because you can largely ignore your current state. The real difficulty arises when you need to evolve or modify existing systems, especially when your data model isn’t structured in a way that is easy to extend.

In this talk we will explore the pain points that happen when dealing with assumptions about your requirements that are invalidated by new or udpated demands on your infrastructure. By doing some up-front design and establishing a domain model that will grow with your business we can avoid some of the incidental complexity that prevents us from evolving our infrastructure in a clean and sustainable manner.

#DevOpsDays #DevOpsDaysBoston
Captions: 
	00:00:18,939 --> 00:00:19,949
Yeah, so.

00:00:19,949 --> 00:00:25,309
As she said I'm here to talk about infrastructure as data, the main modeling for your deployments.

00:00:25,309 --> 00:00:30,460
So most of the people in this room are probably familiar with the idea of infrastructure as

00:00:30,460 --> 00:00:38,500
code, where writing software artifact that manifest as servers running somewhere do whatever

00:00:38,500 --> 00:00:41,930
we tell them to do.

00:00:41,930 --> 00:00:47,360
It can be prone to entrepreneurial logic where you just say do this then do this, then do

00:00:47,360 --> 00:00:53,469
this, which ends up being brittle, inflexible and it's easy to write it first for the days

00:00:53,469 --> 00:00:59,670
you're concerned, but as you go into the maintenance cycle of trying to manage and evolve these

00:00:59,670 --> 00:01:05,240
services over months and years, it starts to become a problem.

00:01:05,240 --> 00:01:07,729
And so then you start reaching for something else.

00:01:07,729 --> 00:01:11,890
And I'm here to say that something else might be data.

00:01:11,890 --> 00:01:18,280
Infrastructure as data, where you're treating your infrastructure as a stateful service

00:01:18,280 --> 00:01:25,060
using principles of data management and data evolution, and trying to bring in different

00:01:25,060 --> 00:01:32,550
aspects of evolutionary design, so that rather than trying to write everything as one monolithic,

00:01:32,550 --> 00:01:37,690
deployable piece of infrastructure, you try to componentize it.

00:01:37,690 --> 00:01:46,170
And as I said, it's easier to go as infrastructure with code instead of trying to understand

00:01:46,170 --> 00:01:49,470
what your abstractions are that requires a more up-front planning.

00:01:49,470 --> 00:01:52,019
You want to go into eyes wide open.

00:01:52,019 --> 00:02:02,720
Knowing I might do something today but next week it might come back to bite me.

00:02:02,720 --> 00:02:09,530
So day 0 usually you need to stand up your network environments, whether it's an Amazon

00:02:09,530 --> 00:02:14,220
or something in Google Cloud or if you've got on-prem infrastructure.

00:02:14,220 --> 00:02:18,860
And then you need to figure out where all the subnets, how do I get everything to talk

00:02:18,860 --> 00:02:22,930
about, deploy my databases, back in services.

00:02:22,930 --> 00:02:28,000
You need to have a fair bit of understanding as to what the requirements are, what you're

00:02:28,000 --> 00:02:34,230
trying to deploy, but you can approach it as I just need to get this running, I'll figure

00:02:34,230 --> 00:02:36,430
everything else out later.

00:02:36,430 --> 00:02:38,950
So you want to be watching your servers.

00:02:38,950 --> 00:02:43,200
This is where Terraform does really well on these day 0 concerns.

00:02:43,200 --> 00:02:49,170
I need to have this repeatable so if I have to tear this whole thing down or build it

00:02:49,170 --> 00:02:54,340
up again, it's not a big problem.

00:02:54,340 --> 00:02:57,840
Where it does become a problem is on day 1 forward.

00:02:57,840 --> 00:03:03,910
Where you say oh, actually this application that I've been running has some new requirement.

00:03:03,910 --> 00:03:08,960
I was using RDS but now I need to have a Q service deployed.

00:03:08,960 --> 00:03:13,850
And you can probably hack that into your procedural logic, everything will keep working.

00:03:13,850 --> 00:03:18,600
But as you get more and more of these additional requirements, things will start to snowball,

00:03:18,600 --> 00:03:26,720
you have brittle code, we're all testing our infrastructure code, I'm sure.

00:03:26,720 --> 00:03:31,510
Being able to replicate those environments where you say okay, this is working well but

00:03:31,510 --> 00:03:37,780
maybe now I need to deploy this again for a different customer that has stringent compliance

00:03:37,780 --> 00:03:41,410
requirements, that means that I can't have all of their servers in the same network as

00:03:41,410 --> 00:03:43,380
a different company.

00:03:43,380 --> 00:03:47,620
So you need to be able to figure out a way to make sure that the code that you write

00:03:47,620 --> 00:04:01,209
is reusable, composable and something that you can extend when the need arises.

00:04:01,209 --> 00:04:05,520
So the way that you do that is, first you need to identify your abstractions.

00:04:05,520 --> 00:04:10,370
What is it that I need to think about.

00:04:10,370 --> 00:04:13,489
How do I identify everything ties together.

00:04:13,489 --> 00:04:17,570
If it's procedural logic you've got everything in one file.

00:04:17,570 --> 00:04:20,060
You can say this ties to this.

00:04:20,060 --> 00:04:29,940
Things like Terraform, you need to think more about from a software architecture, domain

00:04:29,940 --> 00:04:35,380
modeling approach, the abstraction is maybe the entirety of this service.

00:04:35,380 --> 00:04:41,850
It's not just a server and a database and a queue it's all of those things working in

00:04:41,850 --> 00:04:47,430
concert as a single deployable artifact that I need to be able to reason about and evolve

00:04:47,430 --> 00:04:49,300
as those things change.

00:04:49,300 --> 00:04:54,430
As the application grows in complexity and needs more capabilities, or I need to be able

00:04:54,430 --> 00:04:59,540
to expand the pool of servers or resize them.

00:04:59,540 --> 00:05:02,570
That's where having a good data model defined makes it easier.

00:05:02,570 --> 00:05:06,760
Because you can say okay, the size of the server, that's an input variable that I can

00:05:06,760 --> 00:05:09,400
define in my data model.

00:05:09,400 --> 00:05:14,200
The number of servers is an input variable I can define in my data model.

00:05:14,200 --> 00:05:19,600
Thinking about it from a data-first perspective makes it easier to modularize the code, where

00:05:19,600 --> 00:05:27,130
you just say this piece of code takes these inputs and I can reuse it anywhere.

00:05:27,130 --> 00:05:30,801
So you can deploy your QA environment, you can deploy your production environment, you

00:05:30,801 --> 00:05:35,980
can deploy another production environment for other customer.

00:05:35,980 --> 00:05:45,350
The other thing to be aware of is you need to be able to revisit and refactor periodically,

00:05:45,350 --> 00:05:49,000
because the only constant in our work is change.

00:05:49,000 --> 00:05:54,550
So having statically defined data model isn't going to do you any good if it stops being

00:05:54,550 --> 00:05:57,030
applicable to your actual requirements.

00:05:57,030 --> 00:06:03,280
So you need to go back an say does this assumption that I made on week three of this infrastructure

00:06:03,280 --> 00:06:06,460
still make sense three years later.

00:06:06,460 --> 00:06:08,940
And that's where a lot of problems crop up.

00:06:08,940 --> 00:06:13,530
Is because we're not thinking ahead enough about how all of this plays together in the

00:06:13,530 --> 00:06:19,690
long term.

00:06:19,690 --> 00:06:29,620
The way to modularize is taking the data model as an input rather than having it be a computer

00:06:29,620 --> 00:06:31,840
value based on those initial inputs.

00:06:31,840 --> 00:06:38,030
You want to be able to have a high level view at the outset of this is all the information

00:06:38,030 --> 00:06:42,880
that I need to know about to understand what's actually running.

00:06:42,880 --> 00:06:48,110
Because once you hit deploy, you can go back to your AWS console or your Google cloud console

00:06:48,110 --> 00:06:54,290
and see what all is running, but it's not going to tell you what actually talk to what,

00:06:54,290 --> 00:06:58,580
what you need to know to understand the big picture of the entire service from an end

00:06:58,580 --> 00:07:03,860
user perspective as to how it's actually going to function.

00:07:03,860 --> 00:07:08,400
Another thing that's useful for making a modular, is if you don't bring this in from day one

00:07:08,400 --> 00:07:13,450
is you need to identify the seams of your infrastructure.

00:07:13,450 --> 00:07:18,070
Those seams might be vertical where you have an abstraction along your application boundaries,

00:07:18,070 --> 00:07:23,370
where an application needs a database and an object storage bucket and a queue and it's

00:07:23,370 --> 00:07:29,530
needs to be in this BPC or it can be a horizontal seam where you say I've got a seam along all

00:07:29,530 --> 00:07:37,590
my BPCs they need to be able to have public Internet access and another layer you've got

00:07:37,590 --> 00:07:38,590
databases.

00:07:38,590 --> 00:07:42,340
They all need to be configured so they're not using the default parameter groups so

00:07:42,340 --> 00:07:48,259
I can change that down the road without having to reboot.

00:07:48,259 --> 00:08:00,140
And then as you add new capabilities and new services try to encapsulate them I already

00:08:00,140 --> 00:08:06,660
have this block of code and it gives me application and all the new services, I'm just going to

00:08:06,660 --> 00:08:08,610
jam it into this file.

00:08:08,610 --> 00:08:12,060
Everything is great until you need to use it for a different service.

00:08:12,060 --> 00:08:16,669
Then you have to say okay, I'm just going to copy this over here and that's when things

00:08:16,669 --> 00:08:23,610
start going wrong and you have no idea where of truth is.

00:08:23,610 --> 00:08:26,100
Treat it all as a software artifact.

00:08:26,100 --> 00:08:33,740
Treat it as an independently reasonable piece of logic so you can say this component is

00:08:33,740 --> 00:08:36,839
useable here, I plug it into this data model.

00:08:36,839 --> 00:08:41,329
It then talks to these other services because I understand at a high level how it's all

00:08:41,329 --> 00:08:48,480
supposed to fit together.

00:08:48,480 --> 00:08:55,230
Story time!

00:08:55,230 --> 00:09:04,000
One of the things we do is run the open edX platform.

00:09:04,000 --> 00:09:06,480
We got it running, everything was fine.

00:09:06,480 --> 00:09:10,540
But then all of a sudden now we actually need to be able to deploy the next version while

00:09:10,540 --> 00:09:13,700
still supporting the version that we're currently running.

00:09:13,700 --> 00:09:21,200
So one option is to play to an entirely new environment, but when you have to run RDS

00:09:21,200 --> 00:09:28,030
and rapid MQ and console and whatever other services are necessary, that gets pretty expensive

00:09:28,030 --> 00:09:29,030
quick.

00:09:29,030 --> 00:09:32,040
When all you want to do is to be able to test out a new set of changes.

00:09:32,040 --> 00:09:38,300
So what we ended up doing was retrofitting a domain model into our infrastructure to

00:09:38,300 --> 00:09:45,830
say actually this needs a logical schema and doesn't have to be a different piece of hardware.

00:09:45,830 --> 00:09:50,770
We're going to come up with this idea of purposes, where this application serves this purpose

00:09:50,770 --> 00:09:57,020
of a current deployed edX environment and the other purpose for this one is the next

00:09:57,020 --> 00:09:59,220
QA environment.

00:09:59,220 --> 00:10:03,640
So we were able to bring that in and thread that through all of our deployment logic and

00:10:03,640 --> 00:10:09,020
say okay, now we can run just a sit of different application servers talking to the same physical

00:10:09,020 --> 00:10:14,260
back ends, with different logical schemas so that we can reduce cost and increase our

00:10:14,260 --> 00:10:20,480
overall velocity of being able to test these changes, verify everything is working.

00:10:20,480 --> 00:10:25,050
And when we're happy with it, we change the purpose and we deploy it to the other set

00:10:25,050 --> 00:10:28,960
of servers.

00:10:28,960 --> 00:10:33,490
It didn't always fit great with the other applications that we were running or ended

00:10:33,490 --> 00:10:34,580
up having to run.

00:10:34,580 --> 00:10:39,500
That's where having to retrofit this domain model came into play and I started to wish

00:10:39,500 --> 00:10:43,130
I had been thinking about this from day 0.

00:10:43,130 --> 00:10:48,269
Because once your code is there, it's hard to be able to be sure that everything is going

00:10:48,269 --> 00:10:53,300
to work as it's supposed to, since you already have state deployed services.

00:10:53,300 --> 00:10:58,490
You can't say I forgot to think about this, I'm going to completely tear down this environment,

00:10:58,490 --> 00:11:02,160
destroy the database and start from scratch.

00:11:02,160 --> 00:11:05,590
There is an inherent state in all that.

00:11:05,590 --> 00:11:09,130
The application that you're running, the S3 buckets.

00:11:09,130 --> 00:11:10,350
That's Allstate.

00:11:10,350 --> 00:11:14,690
Some of it might be something that we can rebuild easily, but there's certain amount

00:11:14,690 --> 00:11:20,360
of cost involved, not necessarily just monetary, but in terms of your attention and ability

00:11:20,360 --> 00:11:24,220
to comprehend what is going on.

00:11:24,220 --> 00:11:29,270
Where you want to be able to evolve the schema and add new things but you don't necessarily

00:11:29,270 --> 00:11:33,529
want to tear everything down and rebuild it from the ground up because that's not always

00:11:33,529 --> 00:11:38,500
a viable approach.

00:11:38,500 --> 00:11:44,710
So that actually did end up needing to recreate an entire environment for production, because

00:11:44,710 --> 00:11:49,580
these domain models that we came up with didn't map cleanly into how things head bend before

00:11:49,580 --> 00:11:51,970
we started going down this approach.

00:11:51,970 --> 00:11:56,540
Fortunately we were able to have some planned down time but having to migrate the entire

00:11:56,540 --> 00:12:05,140
environment to a new schema meant a longer down time than we had planned where we could

00:12:05,140 --> 00:12:13,870
have easily snapshot and recreate, we needed to actually pipe it from one database to another.

00:12:13,870 --> 00:12:19,830
And then as we kept going, we were saying okay, purposes are working great, we're starting

00:12:19,830 --> 00:12:25,140
to factor those into our other applications where we can map it to a logical concept of

00:12:25,140 --> 00:12:28,959
this application serves this purpose, whether it's QA or production.

00:12:28,959 --> 00:12:37,130
In our case we have the additional complexity between QA and our next QA where one set of

00:12:37,130 --> 00:12:43,260
servers was for a staging environment, both in QA and production and there was a live

00:12:43,260 --> 00:12:44,260
environment.

00:12:44,260 --> 00:12:48,410
So the professors can create content in one set of servers and copy it over into the other

00:12:48,410 --> 00:12:50,730
one for students to take advantage of.

00:12:50,730 --> 00:12:56,010
There is a lot of different dimensions and axes to be thinking about to make sure all

00:12:56,010 --> 00:13:01,589
the sets of services were talking to the right back ends to understand how things tied together

00:13:01,589 --> 00:13:06,230
and also be able to carry that forward into production.

00:13:06,230 --> 00:13:15,630
Recently we ended up having to deploy different servers so it's not just about purposes and

00:13:15,630 --> 00:13:20,240
not just about environments, we have different business units we need to be thinking about.

00:13:20,240 --> 00:13:37,110
That's another axis of our dimensionality that we had to incur as far as overall complexity.

00:13:37,110 --> 00:13:39,089
That's where you need to be careful.

00:13:39,089 --> 00:13:44,820
You can say I've got this attribute, then I'm going to add another one and another one,

00:13:44,820 --> 00:13:49,860
and each one of those different attributes increases the complexity of your environment

00:13:49,860 --> 00:13:52,010
or the complexity of your logic exponentially.

00:13:52,010 --> 00:13:57,070
Where you say okay, if I change this attribute and this attribute, it's not just I have two

00:13:57,070 --> 00:14:01,360
different ways that I can pick a value for and so on.

00:14:01,360 --> 00:14:06,740
You want to be able to limit the number of attributes that factor into the high level

00:14:06,740 --> 00:14:11,470
of how your application environments work together so that you don't drive yourself

00:14:11,470 --> 00:14:19,390
mad trying to figure out what's the entire vector space that I have to be thinking about.

00:14:19,390 --> 00:14:30,430
We added in business units where we had different roles and then we added the purpose.

00:14:30,430 --> 00:14:35,540
Now we've got four different dimensions to be reasoning about and it took a lot of refactoring

00:14:35,540 --> 00:14:38,670
and thinking to make sure we didn't break everything while it was still running while

00:14:38,670 --> 00:14:46,500
still being able to support new services.

00:14:46,500 --> 00:14:47,630
Where we are now.

00:14:47,630 --> 00:14:52,269
We've got four dimensions in our domain model.

00:14:52,269 --> 00:14:58,800
And the thing that really helped us carry this forward is we extracted all the necessary

00:14:58,800 --> 00:15:05,290
information into an environments file where we can say this environment has these different

00:15:05,290 --> 00:15:06,290
services.

00:15:06,290 --> 00:15:11,200
That's where we define our RDS databases.

00:15:11,200 --> 00:15:15,220
That acts as input into an orchestration file that will create the databases for us.

00:15:15,220 --> 00:15:20,339
We don't have to say I'm creating a database for this service so now I need to think about

00:15:20,339 --> 00:15:23,680
what are all the different parameters because we already got it defined ahead of time.

00:15:23,680 --> 00:15:30,240
We just say create this -- fill out this data model with all the different attributes.

00:15:30,240 --> 00:15:34,320
We run this script and make sure we have all the databases that are supposed to exist.

00:15:34,320 --> 00:15:38,019
They're all connected to vault, they're all listening on the proper ports, they've got

00:15:38,019 --> 00:15:43,130
the proper user permissions set up.

00:15:43,130 --> 00:15:47,431
And so having that high level view makes it a lot easier for us to understand when we

00:15:47,431 --> 00:15:52,420
go to the AWS console what everything really means because week say okay, it's this environment

00:15:52,420 --> 00:15:53,590
for this purpose.

00:15:53,590 --> 00:15:57,440
They all talk to these things.

00:15:57,440 --> 00:16:00,470
All of the code that we've written is very data-driven.

00:16:00,470 --> 00:16:03,500
So we don't rely on saying okay, I need to make a change.

00:16:03,500 --> 00:16:08,530
I'm going to copy this file over, make a couple of changes to it and that will live as a separate

00:16:08,530 --> 00:16:14,209
artifact because then you get drift.

00:16:14,209 --> 00:16:17,769
So we lean heavily on data inputs.

00:16:17,769 --> 00:16:23,730
Pretty much every tool has that capability.

00:16:23,730 --> 00:16:31,060
We use the pillar system in salt stack, so you want to make sure that you encapsulate

00:16:31,060 --> 00:16:38,459
all of your critical domain in those variables so that you can compose them together.

00:16:38,459 --> 00:16:43,139
So one of the nice things with pillar data, I'm not sure exactly how it works on the other

00:16:43,139 --> 00:16:46,699
tools, is that it has a hierarchical flow where you can say I'm going to define the

00:16:46,699 --> 00:16:50,779
base set of information that I need, and I'm going to overlay this other environment.

00:16:50,779 --> 00:16:57,199
It will override the attributes that overlap, but at the end I'm going to have the entire

00:16:57,199 --> 00:16:59,350
sort of meshed set of data.

00:16:59,350 --> 00:17:05,470
So it makes it much easier to create different environments with slightly different use cases,

00:17:05,470 --> 00:17:07,100
without having to change any of our code.

00:17:07,100 --> 00:17:11,079
We just make sure that the data models stays up to date.

00:17:11,079 --> 00:17:15,270
The problem that we've got now is that our abstractions are starting to leak because

00:17:15,270 --> 00:17:21,299
we didn't define the data model at the outset, we're starting to have to say okay, for databases

00:17:21,299 --> 00:17:24,459
we have this set of information that we need.

00:17:24,459 --> 00:17:30,470
For S3 buckets, at first we just need this set of information, but then as applications,

00:17:30,470 --> 00:17:32,450
actually I need three different buckets.

00:17:32,450 --> 00:17:35,019
Then things start to become difficult to manage.

00:17:35,019 --> 00:17:39,139
They don't quite fit into the way that we're doing things that's where this revisit and

00:17:39,139 --> 00:17:47,779
refactor step comes into play.

00:17:47,779 --> 00:17:57,850
So the next thing that we need to do is identify what actually is the critical abstraction.

00:17:57,850 --> 00:18:04,409
Where before it was more around the service level of databases, queues, caches, applications,

00:18:04,409 --> 00:18:07,820
we want to be a little more holistic about it where we say we actually have an application.

00:18:07,820 --> 00:18:14,979
So an application might just be a database and a queue for some cases, or it might be

00:18:14,979 --> 00:18:19,779
a set of EC2 servers, it might be a database, some S3 buckets.

00:18:19,779 --> 00:18:24,229
How do we think about that as a single unit so that we can tie everything together so

00:18:24,229 --> 00:18:27,009
that we're not having bespoke changes.

00:18:27,009 --> 00:18:34,350
So we initially created our model and as new requirements came up we'll add another attribute

00:18:34,350 --> 00:18:39,539
to it and factor that into our code and we've been able to push the boundaries further by

00:18:39,539 --> 00:18:42,919
doing that, but there are cases where it doesn't quite map up.

00:18:42,919 --> 00:18:49,999
So now we have some cases where, for instance, they changed some of their expectations of

00:18:49,999 --> 00:18:51,149
their model.

00:18:51,149 --> 00:18:56,159
So we have to have some workarounds to say in some cases post grid databases are sometimes

00:18:56,159 --> 00:18:58,570
post grid, sometimes it's QL.

00:18:58,570 --> 00:19:02,809
How do we encapsulate that without having to rewrite everything.

00:19:02,809 --> 00:19:07,480
Now we have to add that's the actual attribute that we're actually pull in.

00:19:07,480 --> 00:19:12,809
This one is MySQL or EDB.

00:19:12,809 --> 00:19:20,799
Being able to not have to have all those different random attributes, we want to revisit and

00:19:20,799 --> 00:19:28,460
refactor our overall logic to say this is what we actually care about, of an application

00:19:28,460 --> 00:19:29,460
boundary.

00:19:29,460 --> 00:19:33,629
So we're trying to go along the vertical seams.

00:19:33,629 --> 00:19:38,820
Another thing is that because edX is one of the first services we had to manage using

00:19:38,820 --> 00:19:44,370
our infrastructure automation it sort of leaked into everything else that we were doing.

00:19:44,370 --> 00:19:50,859
And so now a decent portion of our core code base for infrastructure is dedicated to just

00:19:50,859 --> 00:19:51,859
edX.

00:19:51,859 --> 00:19:56,109
So we need to be able to break that out into its own component so we can deploy that as

00:19:56,109 --> 00:20:00,340
its own thing without necessarily having that wend its way through the rest of our code

00:20:00,340 --> 00:20:01,779
base accidentally.

00:20:01,779 --> 00:20:07,630
We need to figure out what are all the assumptions we made about this environment, about this

00:20:07,630 --> 00:20:14,080
application, that are solely applicable to that so we can capture that logic separately,

00:20:14,080 --> 00:20:18,070
pull it into its own module, and that will make it more useful for other people.

00:20:18,070 --> 00:20:23,090
Because as I mentioned in one of my past talks, everything that we do is open source.

00:20:23,090 --> 00:20:27,999
So our infrastructure is publicly visible, in terms of how we manage it.

00:20:27,999 --> 00:20:32,769
So by factoring edX into its own component, anybody else who needs to run it will be able

00:20:32,769 --> 00:20:34,890
to use the work that we've done.

00:20:34,890 --> 00:20:41,130
Whereas right now it's fairly tightly coupled to the specifics of our environment.

00:20:41,130 --> 00:20:46,559
The other thing is that we want to add more helper code to encapsulate some of those edge

00:20:46,559 --> 00:20:53,599
cases of tying together different application environments, where we might need to run something

00:20:53,599 --> 00:20:59,039
in three or four different stages to be able to get fully operational environment, we want

00:20:59,039 --> 00:21:00,409
to be able to run it in one.

00:21:00,409 --> 00:21:05,799
We need to be able to create logic that ties together all those different domain models,

00:21:05,799 --> 00:21:11,250
pulls it together into an artifact we can deploy without having to track each stage

00:21:11,250 --> 00:21:19,190
without having to do it manually.

00:21:19,190 --> 00:21:23,440
So one of the things that definitely worked well for us is being able to have that multi-ant

00:21:23,440 --> 00:21:29,809
environment for our edX environments where we can say have our current set of instances

00:21:29,809 --> 00:21:32,919
that we're maintaining because that's what's running in production.

00:21:32,919 --> 00:21:36,960
This is the version we're going to be deploying next and we're actually able to extend it

00:21:36,960 --> 00:21:45,200
beyond just the initial requirement saying we're also going to deploy a master branch,

00:21:45,200 --> 00:21:51,559
or we need to be able to run isolated sandbox instances that are just for coupling to an

00:21:51,559 --> 00:21:53,500
application that we're developing.

00:21:53,500 --> 00:21:58,149
So by having this domain model of this is what an edX environment needs, this is all

00:21:58,149 --> 00:22:03,970
the services it talks to, we are able to reuse that in multiple different ways beyond just

00:22:03,970 --> 00:22:06,070
what the initial requirements were.

00:22:06,070 --> 00:22:13,320
Whereas if we were trying to do it all procedurally, it would have been a lot more painful.

00:22:13,320 --> 00:22:17,639
As I mentioned we also use Vault pretty heavily for our secrets manage.

00:22:17,639 --> 00:22:23,750
So when we were defining the way that we were laying out the different paths and the different

00:22:23,750 --> 00:22:28,830
mount points, we had started establishing our domain model which made it a lot easier

00:22:28,830 --> 00:22:33,269
to reason about how is this going to evolve in the future to make sure we just don't have

00:22:33,269 --> 00:22:37,720
a bunch of random paths that don't make any semantic sense.

00:22:37,720 --> 00:22:43,989
So we said pretty early on, every mount point is going to be mapped to a specific business

00:22:43,989 --> 00:22:47,419
unit and the environment.

00:22:47,419 --> 00:22:52,499
And then within those mount points we're going say this applies to either globally or super

00:22:52,499 --> 00:22:55,840
environments and we pull out the purpose data as well.

00:22:55,840 --> 00:23:01,630
So if you need to know what's the secret key for an application, it's going to be in secret-micromasters/QA

00:23:01,630 --> 00:23:08,690
slash JGOXYZ.

00:23:08,690 --> 00:23:15,710
Rather than going hunting and pecking through paths that might exist.

00:23:15,710 --> 00:23:21,970
As I said before, having that high level document of the environments file is really simplified

00:23:21,970 --> 00:23:26,740
our ability to understand what is it that we need to be able to get a new deployment

00:23:26,740 --> 00:23:32,639
running, because we can see what we've already got, we can see what's actually in -- what's

00:23:32,639 --> 00:23:33,639
actually present.

00:23:33,639 --> 00:23:40,820
One of the challenges is if we do make modifications on ad hoc bases on a running server, be able

00:23:40,820 --> 00:23:42,600
to reflect it back to that file.

00:23:42,600 --> 00:23:51,409
We have to make sure we have a good amount of diligence.

00:23:51,409 --> 00:23:55,619
So we put that into our code so that the code is actually representative of what's running

00:23:55,619 --> 00:23:56,619
in production.

00:23:56,619 --> 00:24:00,849
Because otherwise you get a lot of confusion and say well this environment file says T3

00:24:00,849 --> 00:24:10,400
large I need to redeploy it and actually fell over because there aren't enough resources.

00:24:10,400 --> 00:24:19,690
Another thing we learned is you need to be consistent in how you name things and suffixes

00:24:19,690 --> 00:24:21,419
and prefixes.

00:24:21,419 --> 00:24:26,609
For a while, production environments didn't have any suffix because they were sort of

00:24:26,609 --> 00:24:29,499
the canonical source of what we wanted.

00:24:29,499 --> 00:24:40,039
But then QA without dash RC or dash CI so when we're writing our code it becomes painful

00:24:40,039 --> 00:24:45,429
to say I'm actually going to pull in this suffix but with prod do I pull in an empty

00:24:45,429 --> 00:24:46,429
string?

00:24:46,429 --> 00:24:49,349
Do I have a conditional case with a special case with it?

00:24:49,349 --> 00:24:55,070
Where if we thought about it ahead of time, all prod environments are going to have dash

00:24:55,070 --> 00:25:02,159
prod and then it's easier to know that's production and not just something.

00:25:02,159 --> 00:25:06,419
And also it reduces the overall complexity of our logic to be able to say I'm just going

00:25:06,419 --> 00:25:07,419
to pull in the suffix.

00:25:07,419 --> 00:25:10,720
I don't have to care about which case it's addressing.

00:25:10,720 --> 00:25:12,200
It's just pulling in the data.

00:25:12,200 --> 00:25:16,219
That's all I care about right now.

00:25:16,219 --> 00:25:21,769
The other thing is don't make too many assumptions about what one application is going to need.

00:25:21,769 --> 00:25:26,349
Because you're guaranteed to have something completely bespoke for the next thing.

00:25:26,349 --> 00:25:32,730
So, for instance, when we had to deploy this separate entirely exX environment for a business

00:25:32,730 --> 00:25:38,309
unit, it was pretty painful because a lot of configuration data that we had applied

00:25:38,309 --> 00:25:44,871
to the set of servers that were used by students, had leaked into the overall mapping of what

00:25:44,871 --> 00:25:46,739
this is what an edX environment is.

00:25:46,739 --> 00:25:50,760
But in reality we didn't want those feature flags turned on.

00:25:50,760 --> 00:25:57,999
We needed to figure out what is the actual base set of information we need to get something

00:25:57,999 --> 00:26:02,159
running and these are the pieces that are specific to these different environments so

00:26:02,159 --> 00:26:11,919
we can compose it all up into a single set of information to deploy one of those instances.

00:26:11,919 --> 00:26:17,240
Identifying and paying down modeling debt, as well as just general debt has been absolutely

00:26:17,240 --> 00:26:22,210
crucial for our ability to continue to build and scale new services.

00:26:22,210 --> 00:26:27,490
Because there have been any number of times, for instance, when we were introducing purposes,

00:26:27,490 --> 00:26:31,840
where, if we hadn't done that, then we would have just been accruing too much technical

00:26:31,840 --> 00:26:35,019
debt where any change would have been too risky.

00:26:35,019 --> 00:26:37,899
It would have been taken us months to get something new in production.

00:26:37,899 --> 00:26:43,330
Whereas being diligent in identifying the way in approaching this right now isn't going

00:26:43,330 --> 00:26:46,100
to work for the thing I'm trying to do today.

00:26:46,100 --> 00:26:49,450
So rather than trying to pull forward an get something functional, we need to actually

00:26:49,450 --> 00:26:56,519
take the time to refactor it so that it addresses all of my needs today and try to identify

00:26:56,519 --> 00:26:59,580
potential use cases for tomorrow.

00:26:59,580 --> 00:27:05,509
So that you're not blindsided when those changes do come down.

00:27:05,509 --> 00:27:10,779
And then in terms of the dimensionality of your attributes, it's definitely necessary

00:27:10,779 --> 00:27:15,399
to try and identify attributes that have a hierarchical relation to them.

00:27:15,399 --> 00:27:20,389
Because if they're all just many the many, the complexity becomes too much to deal with.

00:27:20,389 --> 00:27:26,149
Whereas by having things a bit more hierarchical in terms of a business unit has a set of environments,

00:27:26,149 --> 00:27:30,469
has a set of applications that might have different purposes, each time you scope into

00:27:30,469 --> 00:27:36,789
one of those attributes, it eliminates a certain set of the other possible values for attributes

00:27:36,789 --> 00:27:41,960
that you're then going to go to so you don't just have a Cartesian explosion of what are

00:27:41,960 --> 00:27:45,809
all the different problem spaces you're going to be dealing with.

00:27:45,809 --> 00:27:49,799
And the other thing we learned is retrofitting a domain model is hard.

00:27:49,799 --> 00:27:53,429
Having to do it after the fact, after you've already got services running, after you've

00:27:53,429 --> 00:27:58,320
got code committed that's doing what you want it to do, being able to go back and say actually

00:27:58,320 --> 00:28:02,999
I need to pull out all this information into a separate artifact that I can see and reason

00:28:02,999 --> 00:28:06,230
about and evolve, it's just a lot of work.

00:28:06,230 --> 00:28:12,559
So trying to identify that early on, trying to establish the necessary abstractions as

00:28:12,559 --> 00:28:22,059
early as possible, reduces a lot of potential pain and bugs down the road.

00:28:22,059 --> 00:28:26,899
So if anybody is interested you can find me online at a bunch of different places.

00:28:26,899 --> 00:28:31,339
At Laura said I run the tech ops team at Open Learning.

00:28:31,339 --> 00:28:37,859
If you're ever looking for information about the overall space of data engineering and

00:28:37,859 --> 00:28:42,279
data structure and there are a couple of podcasts if that's something you're into and you can

00:28:42,279 --> 00:28:44,500
find me on Twitter and LinkedIn.

00:28:44,500 --> 00:28:51,349
I'll be running an open space at 1:00 this afternoon to talk about domain modeling and

00:28:51,349 --> 00:28:56,809
treating your infrastructure as a data problem not just a code problem.

00:28:56,809 --> 00:29:01,970
And a couple of references that might be useful to understand a bit about what I was talking

00:29:01,970 --> 00:29:02,970
about.

00:29:02,970 --> 00:29:11,309
The environments file that I was referencing, you can see and an example of a data-driven

00:29:11,309 --> 00:29:16,350
approach to managing infrastructure is the code that we use for managing RDS deployments

00:29:16,350 --> 00:29:23,929
that pulls information from that file and runs it against Amazon where it will say this

00:29:23,929 --> 00:29:26,510
instance is already there, I don't need to make any changes.

00:29:26,510 --> 00:29:30,359
This instance doesn't exist yet so I'm going go ahead and deploy it.

00:29:30,359 --> 00:29:36,839
So it looks like I might have a few minutes for questions.

00:29:36,839 --> 00:29:46,219
>> No minutes for questions.

00:29:46,219 --> 00:29:48,559
[ Laughter ]

00:29:48,559 --> 00:29:50,899

YouTube URL: https://www.youtube.com/watch?v=A_cx1dRUSUs


