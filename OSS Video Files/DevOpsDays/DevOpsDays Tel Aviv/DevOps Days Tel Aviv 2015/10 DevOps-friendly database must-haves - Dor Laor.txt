Title: 10 DevOps-friendly database must-haves - Dor Laor
Publication date: 2015-11-01
Playlist: DevOps Days Tel Aviv 2015
Description: 
	http://www.devopsdays.org/events/2015-telaviv/

How would you pick the right database for you? There are so many databases, ranging from mighty Oracle that can do it all but you need a special funding round just for it, towards specific databases that can store your data in special memory called RAM..

The talk does not try to compare Mongo to Cassandra but to point toward features which make a database devops-friendly. The list starts with trivials such as integrated-collectd / JSON-as-a-format / docker packaging to more sophisticated features such as distributed backup, Spark connectors, etc.

What's distributed backup you ask? Oh, does your database independently backup each node separately in a non-consistent manner and save 3 different copies of the replicas? Restore is another issue and many database projects expect you to restore on an identical set of hardware you backed it up which is a big no-no.

Performance is a factor too. The fact that your database scales out linearly doesn't hold if a single node performs as low as few thousands transaction/s. Tail latency is more important than average latency unless you agree that on average you and Bill Gates are billionaires. Lastly, performance tuning should be clear and expected and not black magic (remember, we're in the data-science business).

In the era of XXX-as-a-service, one expects multi-tenancy features, great analytic integration and map reduce for the mass. The session will provide examples from a wide range of common, existing databases.

About the speaker - Dor Laor

Dor Laor is the CEO of Scylla. Previously, Dor was part of the founding team of the KVM hypervisor under Qumranet that was acquired by Red Hat. At Red Hat Dor was managing the KVM and Xen development for several years. Dor holds an MSc from the Technion and a Phd in snowboarding.
Captions: 
	00:00:10,610 --> 00:00:17,539
so hi I'm door so I'm here to speak

00:00:14,759 --> 00:00:19,589
about DevOps friendly databases

00:00:17,539 --> 00:00:22,230
practically I'm not going to talk about

00:00:19,589 --> 00:00:26,099
any specific database even the one that

00:00:22,230 --> 00:00:28,289
my company manufactures and I can say

00:00:26,099 --> 00:00:30,749
like honestly the one that we

00:00:28,289 --> 00:00:32,610
manufacture doesn't of course apply to

00:00:30,749 --> 00:00:36,989
all of the good properties that I'll go

00:00:32,610 --> 00:00:39,510
into detail here so the idea is to bring

00:00:36,989 --> 00:00:41,940
up to the surface a lot of properties

00:00:39,510 --> 00:00:45,989
that a good database should follow and

00:00:41,940 --> 00:00:48,480
should be a practically serve you as a

00:00:45,989 --> 00:00:51,269
DevOps in your day-to-day lives so

00:00:48,480 --> 00:00:53,940
that's that's the idea and before we get

00:00:51,269 --> 00:00:57,359
into talking about the about databases

00:00:53,940 --> 00:01:00,390
let's talk about what DevOps must have

00:00:57,359 --> 00:01:02,989
in general and it's it's of course

00:01:00,390 --> 00:01:05,430
natural to think about what's good for

00:01:02,989 --> 00:01:07,530
your own application running Adele

00:01:05,430 --> 00:01:10,170
DevOps but maybe database it in that

00:01:07,530 --> 00:01:15,450
aspect is a bit different because it's

00:01:10,170 --> 00:01:18,840
more for a software component that

00:01:15,450 --> 00:01:24,000
doesn't move this fast as regular

00:01:18,840 --> 00:01:27,150
application so of course so always on 24

00:01:24,000 --> 00:01:29,510
months by seven and multi-zone in all

00:01:27,150 --> 00:01:32,330
all the things related that and

00:01:29,510 --> 00:01:35,040
automation friendly databases should be

00:01:32,330 --> 00:01:37,830
automated of course especially in this

00:01:35,040 --> 00:01:43,470
era where everything is scalable and

00:01:37,830 --> 00:01:48,840
elastic now the main thing that you

00:01:43,470 --> 00:01:51,500
would want from your database is to have

00:01:48,840 --> 00:01:55,230
no fear in changing your environment

00:01:51,500 --> 00:01:58,200
that's the main thing because it's also

00:01:55,230 --> 00:02:02,520
relates to automation if you have good

00:01:58,200 --> 00:02:04,890
automation then the risk of change

00:02:02,520 --> 00:02:07,650
become lower if you don't have it then

00:02:04,890 --> 00:02:10,319
of course the risk is huge and you

00:02:07,650 --> 00:02:12,470
shouldn't do anything so practically the

00:02:10,319 --> 00:02:18,590
old idea is to decrease

00:02:12,470 --> 00:02:20,570
the fear and the fear decreases by good

00:02:18,590 --> 00:02:27,380
properties of the database and your

00:02:20,570 --> 00:02:31,880
environment of course so that's so of

00:02:27,380 --> 00:02:35,690
course everybody do get push and that's

00:02:31,880 --> 00:02:38,810
normally not the case for putting

00:02:35,690 --> 00:02:41,060
updates on your schemas but but it is it

00:02:38,810 --> 00:02:44,090
is possible to do but you of course

00:02:41,060 --> 00:02:46,459
don't look and see if it fails you try

00:02:44,090 --> 00:02:48,950
to have some infrastructure in place to

00:02:46,459 --> 00:02:52,790
prevent that so basically most of the

00:02:48,950 --> 00:02:56,930
talk is how to try to improve upgrades

00:02:52,790 --> 00:03:01,010
and and cope with situations in the

00:02:56,930 --> 00:03:06,110
field and of course the risk should be

00:03:01,010 --> 00:03:09,470
kept also upgrades are simple down

00:03:06,110 --> 00:03:13,280
grades aren't necessarily as simple as

00:03:09,470 --> 00:03:16,280
that a some product supports rolling

00:03:13,280 --> 00:03:19,940
upgrades recent ones but with downwards

00:03:16,280 --> 00:03:23,120
that's that's harder who knows what's

00:03:19,940 --> 00:03:25,690
the best way to downgrade any software

00:03:23,120 --> 00:03:25,690
component

00:03:28,350 --> 00:03:37,390
so it's a clue it's related to get or

00:03:34,690 --> 00:03:40,540
it's the best I would say it's the best

00:03:37,390 --> 00:03:44,590
practice that mostly did this path is

00:03:40,540 --> 00:03:48,190
mostly never taken but with gates when

00:03:44,590 --> 00:03:51,400
you push a commit and you need to push

00:03:48,190 --> 00:03:54,280
it back you don't a reset to the

00:03:51,400 --> 00:03:56,980
previous head unless it's your your own

00:03:54,280 --> 00:04:00,220
development environment what's usually a

00:03:56,980 --> 00:04:03,940
good practice is to commit a revert so

00:04:00,220 --> 00:04:05,980
with the downgrade if a good database or

00:04:03,940 --> 00:04:09,010
a good software product allows that the

00:04:05,980 --> 00:04:11,670
best thing is to upgrade to the previous

00:04:09,010 --> 00:04:15,640
version so that'll be a fantastic

00:04:11,670 --> 00:04:17,320
practice of course and I don't know if

00:04:15,640 --> 00:04:20,140
they're there is a tool out there that

00:04:17,320 --> 00:04:22,510
supports it but but that's definitely an

00:04:20,140 --> 00:04:24,990
interesting aspect to to downgrades and

00:04:22,510 --> 00:04:28,480
I think that you'll agree with me that

00:04:24,990 --> 00:04:31,210
it's it's reduces the amount of passive

00:04:28,480 --> 00:04:34,530
and reduces the friction so I think

00:04:31,210 --> 00:04:34,530
that's the right way to go

00:04:35,260 --> 00:04:43,240
and one last and important thing is to

00:04:38,980 --> 00:04:45,760
prevent silos sometimes silos are a good

00:04:43,240 --> 00:04:48,880
thing especially if you have lots of

00:04:45,760 --> 00:04:54,400
regulations or things like that but but

00:04:48,880 --> 00:04:57,060
normally a silos are a bad thing it's

00:04:54,400 --> 00:05:01,180
great create rolla fication of services

00:04:57,060 --> 00:05:03,010
it's it's great legacy islands so it's

00:05:01,180 --> 00:05:05,800
it's a bad thing and you should prevent

00:05:03,010 --> 00:05:11,590
that also it the same case goes with

00:05:05,800 --> 00:05:14,670
your database so I am I want going to

00:05:11,590 --> 00:05:19,090
cover and and I want going to compare

00:05:14,670 --> 00:05:22,240
Cassandra to to my sequel and so

00:05:19,090 --> 00:05:25,210
I'm going to skip over that but but do

00:05:22,240 --> 00:05:28,150
you know that I work for a company

00:05:25,210 --> 00:05:29,830
called the silla de bead and you need to

00:05:28,150 --> 00:05:35,170
pronounce it right at the end of the

00:05:29,830 --> 00:05:37,090
session and they just to put things on

00:05:35,170 --> 00:05:39,670
here because i'll be talking about

00:05:37,090 --> 00:05:41,380
performance our idea is real

00:05:39,670 --> 00:05:43,690
implementation of Cassandra from scratch

00:05:41,380 --> 00:05:45,520
that provides you all of the good

00:05:43,690 --> 00:05:49,000
properties of Cassandra with the speed

00:05:45,520 --> 00:05:56,620
of Redis actually a bit faster but

00:05:49,000 --> 00:05:59,170
that's for sale so M are going to

00:05:56,620 --> 00:06:01,930
mention 10 things that which makes a

00:05:59,170 --> 00:06:04,990
database DevOps friendly there are of

00:06:01,930 --> 00:06:06,670
course more than 10 things so I in the

00:06:04,990 --> 00:06:11,650
first one I put just straightforward

00:06:06,670 --> 00:06:14,500
things so and I a merge several things

00:06:11,650 --> 00:06:16,870
that are unrelated so I will will

00:06:14,500 --> 00:06:20,440
continue will quickly move into the more

00:06:16,870 --> 00:06:24,310
interesting stuff so of course security

00:06:20,440 --> 00:06:27,100
and multi-platform and audit and logs

00:06:24,310 --> 00:06:29,650
etc are super important nice thing about

00:06:27,100 --> 00:06:33,460
to notice with regard to security is

00:06:29,650 --> 00:06:36,790
that encryption between the client and

00:06:33,460 --> 00:06:39,340
between the nodes is straightforward of

00:06:36,790 --> 00:06:43,780
course not everybody needs that within

00:06:39,340 --> 00:06:45,639
your own private land but there are some

00:06:43,780 --> 00:06:49,030
that do need it

00:06:45,639 --> 00:06:51,430
aim when you do need it it's important

00:06:49,030 --> 00:06:55,240
to manage the keys correctly but because

00:06:51,430 --> 00:06:57,520
that's something that many will fall so

00:06:55,240 --> 00:06:59,860
pay attention to this and there are

00:06:57,520 --> 00:07:02,229
products out there that do manage the

00:06:59,860 --> 00:07:07,270
keys normally it's an add-on to your

00:07:02,229 --> 00:07:09,909
database so let's move into more

00:07:07,270 --> 00:07:14,740
interesting stuff like backup and

00:07:09,909 --> 00:07:17,020
restore so of course that's trivial a I

00:07:14,740 --> 00:07:19,870
think that's why s3 was invented in

00:07:17,020 --> 00:07:23,199
order to do backup and restore boobity

00:07:19,870 --> 00:07:31,240
is that's really the case with modern

00:07:23,199 --> 00:07:33,580
databases so I don't think so what's the

00:07:31,240 --> 00:07:36,580
problem the problem that modern

00:07:33,580 --> 00:07:39,610
databases are eventually consistent so

00:07:36,580 --> 00:07:42,279
if you're eventually consistent on your

00:07:39,610 --> 00:07:44,499
day-to-day transactions then certainly

00:07:42,279 --> 00:07:47,830
you'll be eventually consistent when you

00:07:44,499 --> 00:07:49,419
take a snapshot of your database even

00:07:47,830 --> 00:07:51,639
taking a snapshot of the database is

00:07:49,419 --> 00:07:55,000
super hard because it's distributed and

00:07:51,639 --> 00:07:57,659
contain dozens or hundreds of nodes and

00:07:55,000 --> 00:08:02,099
that's also a nightmare to manage so

00:07:57,659 --> 00:08:07,080
most most products today out there just

00:08:02,099 --> 00:08:10,509
do some type of local node snapshots and

00:08:07,080 --> 00:08:12,399
within that snapshot you get to keep all

00:08:10,509 --> 00:08:14,439
of the replica the data from all of the

00:08:12,399 --> 00:08:18,580
replicas and of course the data is

00:08:14,439 --> 00:08:21,039
eventually inconsistent or temple in

00:08:18,580 --> 00:08:26,270
consistency within your snapshots and

00:08:21,039 --> 00:08:30,730
and you need to be aware of that just

00:08:26,270 --> 00:08:30,730
I jumped one thing too quick

00:08:31,280 --> 00:08:38,229
alright so is it is that totally wrong

00:08:35,360 --> 00:08:44,050
or is that a bad thing to snapshot into

00:08:38,229 --> 00:08:44,050
to back up eventually consistent data

00:08:46,580 --> 00:08:54,080
that's the right answer actually so it

00:08:51,020 --> 00:08:55,880
depends because if if that's what you'd

00:08:54,080 --> 00:08:58,370
like to do and if your application or

00:08:55,880 --> 00:09:00,860
the database that you are restores from

00:08:58,370 --> 00:09:02,900
this eventually consistent data knows

00:09:00,860 --> 00:09:05,510
that I knows how to keep cope with that

00:09:02,900 --> 00:09:10,010
and you won't modify the eventual

00:09:05,510 --> 00:09:13,490
consistent algorithm then it can be

00:09:10,010 --> 00:09:16,010
totally fine and that's fine but if it's

00:09:13,490 --> 00:09:20,210
not the case and you'd like to take the

00:09:16,010 --> 00:09:22,370
snapshot and move it into some offline

00:09:20,210 --> 00:09:25,820
analytics processing and you really rely

00:09:22,370 --> 00:09:29,650
on data that's the problem so make sure

00:09:25,820 --> 00:09:32,000
you know what you do when you take a

00:09:29,650 --> 00:09:34,460
distributed eventual consistent staff

00:09:32,000 --> 00:09:37,700
shot and i would say that what's

00:09:34,460 --> 00:09:42,650
desirable is that database lenders will

00:09:37,700 --> 00:09:45,860
not only offer regular snapshots or a

00:09:42,650 --> 00:09:51,290
single node snapshots which are which

00:09:45,860 --> 00:09:53,510
can be a consistency even for let's say

00:09:51,290 --> 00:09:57,050
my sequel but once you're distributed

00:09:53,510 --> 00:10:01,010
then it's really a super hard task it's

00:09:57,050 --> 00:10:03,680
still possible and I wonder actually in

00:10:01,010 --> 00:10:06,380
the industry on whether there's is there

00:10:03,680 --> 00:10:08,750
a demand for such a snapshot or maybe

00:10:06,380 --> 00:10:10,540
it's like to farfetch and most people

00:10:08,750 --> 00:10:13,150
are good with the eventual consistence

00:10:10,540 --> 00:10:18,400
snapshots

00:10:13,150 --> 00:10:22,780
for most people just hope that their

00:10:18,400 --> 00:10:26,320
backup one day will be usable and that's

00:10:22,780 --> 00:10:29,680
the that's the restore pass so mostly

00:10:26,320 --> 00:10:33,580
when you restore you're just happy if

00:10:29,680 --> 00:10:36,460
it's work then wonderful but a problem

00:10:33,580 --> 00:10:38,740
with sophisticated infrastructure is

00:10:36,460 --> 00:10:40,300
that you're going to restore not

00:10:38,740 --> 00:10:44,310
necessarily on the same piece of

00:10:40,300 --> 00:10:47,170
hardware that you took the snapshot and

00:10:44,310 --> 00:10:52,480
usually it means that you support

00:10:47,170 --> 00:10:54,490
multi-zone so so it will work on a

00:10:52,480 --> 00:10:56,610
different scenario with different IPS

00:10:54,490 --> 00:11:00,400
and potentially different environments

00:10:56,610 --> 00:11:04,080
another thing is you may want to restore

00:11:00,400 --> 00:11:07,180
on a different set of hardware a

00:11:04,080 --> 00:11:09,640
different number of servers especially

00:11:07,180 --> 00:11:12,160
if you'd like to even upgrade your

00:11:09,640 --> 00:11:15,820
environment and that's a challenge

00:11:12,160 --> 00:11:18,000
because if you took the snapshot and the

00:11:15,820 --> 00:11:20,740
snapshot was taken per server and

00:11:18,000 --> 00:11:23,440
withhold it all of the shouting in place

00:11:20,740 --> 00:11:25,000
now you need to modify it or on the on a

00:11:23,440 --> 00:11:30,690
boot time that that's really challenging

00:11:25,000 --> 00:11:30,690
so good tools need to cope with that

00:11:33,980 --> 00:11:41,390
another thing is scale there are mainly

00:11:38,790 --> 00:11:46,730
two things with scales scaling up and

00:11:41,390 --> 00:11:51,120
scaling out so I I call anything below

00:11:46,730 --> 00:11:54,750
50,000 ops operation per second quite

00:11:51,120 --> 00:11:58,770
poor scaling and and with today's

00:11:54,750 --> 00:12:00,720
computer with dozens of course a 10

00:11:58,770 --> 00:12:03,540
gigabit networks even now that the

00:12:00,720 --> 00:12:07,740
meadowlarks came with 100 gigabits per

00:12:03,540 --> 00:12:10,529
networks per second nvme drives there's

00:12:07,740 --> 00:12:13,560
no reason in the world why you should be

00:12:10,529 --> 00:12:19,680
satisfied with a few thousands or

00:12:13,560 --> 00:12:22,410
thousand thousand a of a fox usually the

00:12:19,680 --> 00:12:24,930
problem is that of course however is

00:12:22,410 --> 00:12:28,529
cheap you can buy more and labour is

00:12:24,930 --> 00:12:32,190
expensive so all right I'll throw more

00:12:28,529 --> 00:12:36,180
horsepower at the problem and it will

00:12:32,190 --> 00:12:41,610
just take care for itself the problem is

00:12:36,180 --> 00:12:45,390
that the the more your cluster gets

00:12:41,610 --> 00:12:48,720
bigger then the more problems appear on

00:12:45,390 --> 00:12:51,810
the surface and the more edge cases that

00:12:48,720 --> 00:12:53,520
show up especially in distributed

00:12:51,810 --> 00:12:57,000
systems and the mean time between

00:12:53,520 --> 00:12:59,310
failure is constant for the hardware so

00:12:57,000 --> 00:13:02,339
the more harder you get let's say you

00:12:59,310 --> 00:13:04,860
use you keep consistently replication

00:13:02,339 --> 00:13:07,620
factor of 3 then you'll get real

00:13:04,860 --> 00:13:10,140
problems and even data loss if your

00:13:07,620 --> 00:13:12,570
cluster grows and grows indefinitely so

00:13:10,140 --> 00:13:16,610
take that in mind was there a question

00:13:12,570 --> 00:13:16,610
or just in each

00:13:18,890 --> 00:13:29,970
another thing is and read the guy from

00:13:24,870 --> 00:13:33,060
the keynotes talked about mm mechanic

00:13:29,970 --> 00:13:37,890
mechanicals sympathy or engineering

00:13:33,060 --> 00:13:40,380
beauty and if the system can't can't

00:13:37,890 --> 00:13:44,190
performs it means that it's engineered

00:13:40,380 --> 00:13:46,350
poorly so probably there are other cases

00:13:44,190 --> 00:13:52,410
within the product that are aren't as

00:13:46,350 --> 00:13:55,910
good so usually sometimes people say

00:13:52,410 --> 00:13:58,770
that they're going to develop fast and

00:13:55,910 --> 00:14:01,800
ignore performance in early stages but

00:13:58,770 --> 00:14:04,310
I'm pretty sure that's a no a bunch of

00:14:01,800 --> 00:14:04,310
other things

00:14:06,750 --> 00:14:14,230
one additional thing for database is if

00:14:10,960 --> 00:14:16,330
it's slow then you plant a cache in

00:14:14,230 --> 00:14:18,850
front of it in the form of memcache in

00:14:16,330 --> 00:14:20,589
race but that's another set of

00:14:18,850 --> 00:14:24,100
complexity and now you need to make sure

00:14:20,589 --> 00:14:26,380
that these caches are a coherent and of

00:14:24,100 --> 00:14:31,180
course another set of glasser to manage

00:14:26,380 --> 00:14:34,270
so good databases do not need a cash the

00:14:31,180 --> 00:14:36,490
good databases employ a cache of stem

00:14:34,270 --> 00:14:38,740
cells and actually if you save the

00:14:36,490 --> 00:14:41,290
external database external cash I'm

00:14:38,740 --> 00:14:43,870
sorry then you can apply all of the

00:14:41,290 --> 00:14:46,540
round from that set up it first there's

00:14:43,870 --> 00:14:49,240
no labor in managing it there's no labor

00:14:46,540 --> 00:14:53,080
in keeping the cache consistent and of

00:14:49,240 --> 00:14:55,899
course you can move the daram from the

00:14:53,080 --> 00:14:58,709
cash into your database and get even

00:14:55,899 --> 00:14:58,709
better performance

00:15:00,760 --> 00:15:11,230
and in lastly many time and people use

00:15:06,010 --> 00:15:14,260
no sequel as really plain key value and

00:15:11,230 --> 00:15:18,640
just plant instead of using wide rows or

00:15:14,260 --> 00:15:22,390
nested a data they just use it as a as

00:15:18,640 --> 00:15:24,640
one big blob which can work of course

00:15:22,390 --> 00:15:27,610
but then why would you use the database

00:15:24,640 --> 00:15:30,340
go ahead and use a simple key value like

00:15:27,610 --> 00:15:33,220
reddish and memcache if you do not need

00:15:30,340 --> 00:15:34,330
a database if you do need a database you

00:15:33,220 --> 00:15:37,710
would like to use all the good

00:15:34,330 --> 00:15:41,530
properties of the database like maps and

00:15:37,710 --> 00:15:44,230
indexes and all of these things but of

00:15:41,530 --> 00:15:47,940
course they come with the cost so the

00:15:44,230 --> 00:15:52,440
lower you begin then it will only get

00:15:47,940 --> 00:15:52,440
degrade from that that point

00:15:55,820 --> 00:16:02,820
second thing is scaling out and a no

00:16:00,900 --> 00:16:06,260
matter how strong your performance is

00:16:02,820 --> 00:16:08,910
you need to scale out first you got to

00:16:06,260 --> 00:16:11,460
take care for high availability and

00:16:08,910 --> 00:16:13,670
folder tolerance so that's a must help

00:16:11,460 --> 00:16:18,720
regardless of your performance and

00:16:13,670 --> 00:16:21,540
beyond that still the every system can

00:16:18,720 --> 00:16:24,900
get to ease its knees so you do need to

00:16:21,540 --> 00:16:26,820
scale out if you do skate out it's it's

00:16:24,900 --> 00:16:29,670
really good to keep it symmetric of

00:16:26,820 --> 00:16:31,410
course I'm not even talking about single

00:16:29,670 --> 00:16:34,740
point of failures but but keep that

00:16:31,410 --> 00:16:37,110
symmetric so you wouldn't need to create

00:16:34,740 --> 00:16:40,350
like a ratio four three two one with

00:16:37,110 --> 00:16:43,260
some sort of a directory or naming

00:16:40,350 --> 00:16:46,110
service and other services because then

00:16:43,260 --> 00:16:51,920
you'll have areas of either lots of

00:16:46,110 --> 00:16:56,580
inefficiency or or bottlenecks now the

00:16:51,920 --> 00:16:59,760
the the book a scale out is just a

00:16:56,580 --> 00:17:03,270
linear graph with some factor but but

00:16:59,760 --> 00:17:05,760
that's that's what normally you have in

00:17:03,270 --> 00:17:10,170
in the books or in very nice benchmarks

00:17:05,760 --> 00:17:15,810
but in real life you get this messy

00:17:10,170 --> 00:17:20,510
picture so any guesses what we try to

00:17:15,810 --> 00:17:20,510
achieve with this fantastic graph

00:17:22,559 --> 00:17:35,230
no it's with garbage collector you

00:17:25,720 --> 00:17:39,130
should get down eventually so these are

00:17:35,230 --> 00:17:42,610
ops and that's over over time and over

00:17:39,130 --> 00:17:45,730
time we added notes it's a Cassandra

00:17:42,610 --> 00:17:49,659
cluster that started with a two nodes

00:17:45,730 --> 00:17:51,700
and we hit it with as many client as

00:17:49,659 --> 00:17:55,860
possible to check the throughput and

00:17:51,700 --> 00:17:58,809
check the effect of adding nodes every

00:17:55,860 --> 00:18:02,409
every couple of minutes so the idea is

00:17:58,809 --> 00:18:04,960
to let the cluster get to a consistent

00:18:02,409 --> 00:18:08,140
state and every two minute or so we

00:18:04,960 --> 00:18:12,490
added a note the the existing nodes had

00:18:08,140 --> 00:18:16,210
to synchronize the new node and then the

00:18:12,490 --> 00:18:18,549
performance improved a bit but in each

00:18:16,210 --> 00:18:22,270
point in the way there was a huge drop

00:18:18,549 --> 00:18:25,750
when we added that node and the existing

00:18:22,270 --> 00:18:29,470
wood had to synchronize the new ones so

00:18:25,750 --> 00:18:32,500
it's quite a horrible a graph and we

00:18:29,470 --> 00:18:35,890
were really surprised with this behavior

00:18:32,500 --> 00:18:40,320
we tested it over and over again we have

00:18:35,890 --> 00:18:43,390
a get project with ansible for testing

00:18:40,320 --> 00:18:47,200
these type of things it's open source by

00:18:43,390 --> 00:18:50,169
the way in contests whatever you like so

00:18:47,200 --> 00:18:52,000
you are welcome to use it but but

00:18:50,169 --> 00:18:55,059
eventually that's the pattern we got and

00:18:52,000 --> 00:18:59,020
of course it's pretty bad so if you do

00:18:55,059 --> 00:19:02,110
take a database for this drive test each

00:18:59,020 --> 00:19:04,779
scale up abilities and I think that

00:19:02,110 --> 00:19:07,210
that's mostly the reason that most

00:19:04,779 --> 00:19:10,960
people have a static infrastructure and

00:19:07,210 --> 00:19:13,330
not fully elastic auto scale which is

00:19:10,960 --> 00:19:17,909
one of the requirements for a really

00:19:13,330 --> 00:19:17,909
good database or overall application

00:19:25,400 --> 00:19:32,580
eventually it got eventually we stopped

00:19:28,020 --> 00:19:35,580
so it is possible to add nodes but a the

00:19:32,580 --> 00:19:41,370
pattern was identified and with enough

00:19:35,580 --> 00:19:46,860
force it wasn't too big so I assume that

00:19:41,370 --> 00:19:52,350
the bigger the data sets then a that's

00:19:46,860 --> 00:19:54,990
true and with this tool of hours then it

00:19:52,350 --> 00:19:57,390
so it's also possible to to set the

00:19:54,990 --> 00:20:03,720
period of adding nodes and the data sets

00:19:57,390 --> 00:20:06,210
as well consistent a later latency so of

00:20:03,720 --> 00:20:09,030
course low latency is important but

00:20:06,210 --> 00:20:12,950
Taillon Layton sees way were more

00:20:09,030 --> 00:20:15,780
important than ever average latency and

00:20:12,950 --> 00:20:18,330
of course if your infrastructure is

00:20:15,780 --> 00:20:22,080
implemented using Java then you're going

00:20:18,330 --> 00:20:26,300
to suffer from GC in one point or the

00:20:22,080 --> 00:20:29,370
other and it will make you pay for it

00:20:26,300 --> 00:20:32,460
sometimes you pay in in in your time

00:20:29,370 --> 00:20:34,980
sometime you may go to azle for example

00:20:32,460 --> 00:20:38,880
this graph is taken for muscle and

00:20:34,980 --> 00:20:43,140
compares a acyl garbage collector and

00:20:38,880 --> 00:20:45,540
JVM vs oracle and that compares either

00:20:43,140 --> 00:20:49,790
did yeah that's the maximum latency in

00:20:45,540 --> 00:20:53,010
milliseconds so there's more than 100

00:20:49,790 --> 00:20:55,680
milliseconds I'm sorry there's more than

00:20:53,010 --> 00:20:58,710
500 millisecond half a second with

00:20:55,680 --> 00:21:01,860
Oracle and much less with a little very

00:20:58,710 --> 00:21:05,930
very impressive what they don't show you

00:21:01,860 --> 00:21:05,930
here is how much time

00:21:06,580 --> 00:21:16,059
all right I'm good in spinning up things

00:21:11,620 --> 00:21:19,090
so I'll see that up so what they don't

00:21:16,059 --> 00:21:23,320
show you here is that Ozil are fantastic

00:21:19,090 --> 00:21:24,669
in terms of latency but of course c++ we

00:21:23,320 --> 00:21:27,490
will do better than that good

00:21:24,669 --> 00:21:31,990
implementation but it comes on the

00:21:27,490 --> 00:21:35,470
expense of throughput so that's one of

00:21:31,990 --> 00:21:38,260
their magic seen in here a really cool

00:21:35,470 --> 00:21:40,809
thing phenomenal about latency and tail

00:21:38,260 --> 00:21:45,279
agency is a coordinated the mission

00:21:40,809 --> 00:21:48,610
because if all of the events come one

00:21:45,279 --> 00:21:51,970
after the other and they're not parallel

00:21:48,610 --> 00:21:56,440
then if you have an actor outlier like

00:21:51,970 --> 00:22:00,100
the first graph then all right one a one

00:21:56,440 --> 00:22:04,510
or few requests got it and that's it but

00:22:00,100 --> 00:22:06,789
a field experiment will actually cause

00:22:04,510 --> 00:22:09,990
all of the parallel request to slow down

00:22:06,789 --> 00:22:13,269
as well so the actual graph will look

00:22:09,990 --> 00:22:15,690
like this and more percentiles will be

00:22:13,269 --> 00:22:15,690
hurt by it

00:22:19,710 --> 00:22:31,840
okay so automation so database databases

00:22:29,259 --> 00:22:33,460
or any good good other product should

00:22:31,840 --> 00:22:37,059
take care for its own configuration

00:22:33,460 --> 00:22:40,830
whether it's garbage collection or OST

00:22:37,059 --> 00:22:44,320
Nobles like the number of huge pages and

00:22:40,830 --> 00:22:49,239
number for playing files and any number

00:22:44,320 --> 00:22:51,340
any buffer sizes and all the database or

00:22:49,239 --> 00:22:52,690
if you develop an application your

00:22:51,340 --> 00:22:55,210
application need to take care of it

00:22:52,690 --> 00:22:59,019
don't throw it on the user because it's

00:22:55,210 --> 00:23:04,799
horrible the number of options just

00:22:59,019 --> 00:23:08,619
expose and if eventually him in Oracle

00:23:04,799 --> 00:23:13,119
in Java Java one world they open their

00:23:08,619 --> 00:23:16,239
talk by saying try to rerun your

00:23:13,119 --> 00:23:19,450
application without all of the GC flags

00:23:16,239 --> 00:23:21,669
that you you added over the years

00:23:19,450 --> 00:23:25,239
normally there are more conflicting

00:23:21,669 --> 00:23:28,979
flags in your very same command line so

00:23:25,239 --> 00:23:31,779
you know bills are pretty notorious and

00:23:28,979 --> 00:23:36,599
vendors should take care to come with

00:23:31,779 --> 00:23:36,599
their best defaults and that's it

00:23:37,349 --> 00:23:44,559
another thing is elasticity so auto

00:23:40,539 --> 00:23:49,649
scaling is important as as I showed

00:23:44,559 --> 00:23:51,820
before it's pretty sudden to see that

00:23:49,649 --> 00:23:54,249
sometimes with a lot of products for

00:23:51,820 --> 00:23:57,639
instance Cassandra and also the same

00:23:54,249 --> 00:23:59,859
database that we manufacture suffering

00:23:57,639 --> 00:24:03,729
from the same thing is you can't

00:23:59,859 --> 00:24:05,919
automatically join many nodes to an

00:24:03,729 --> 00:24:08,470
existing cluster like if you have a

00:24:05,919 --> 00:24:10,989
cluster of let's say 10 notes and you

00:24:08,470 --> 00:24:13,299
want to grow it to 20 you cannot do it

00:24:10,989 --> 00:24:15,070
immediately at once like boom add

00:24:13,299 --> 00:24:18,220
another 10 nodes and let the database

00:24:15,070 --> 00:24:21,669
take care for itself who knows why

00:24:18,220 --> 00:24:25,539
or what's the excuse there's no excuse

00:24:21,669 --> 00:24:30,210
real excuse for it but why vendors

00:24:25,539 --> 00:24:30,210
choose to throw this on on you as a user

00:24:31,140 --> 00:24:37,010
I'm sorry

00:24:34,110 --> 00:24:37,010
sequence

00:24:37,650 --> 00:24:43,500
the sequence is less important the main

00:24:40,770 --> 00:24:45,810
issue that it's consistency because if

00:24:43,500 --> 00:24:48,090
you had eight a node cluster and now

00:24:45,810 --> 00:24:49,590
you're going to have 20 there will be a

00:24:48,090 --> 00:24:51,810
moment in time that you lose the

00:24:49,590 --> 00:24:53,370
majority and if the database is

00:24:51,810 --> 00:24:56,850
eventually consistent they need to

00:24:53,370 --> 00:25:00,270
manage an internal majority and the

00:24:56,850 --> 00:25:03,810
consistency but really it's an excuse a

00:25:00,270 --> 00:25:05,790
good database should manage it and not

00:25:03,810 --> 00:25:09,750
necessarily promote all of the nodes at

00:25:05,790 --> 00:25:11,940
once but instead of you making the

00:25:09,750 --> 00:25:14,010
automation for them then that's the

00:25:11,940 --> 00:25:17,460
vendor who needs to do the automation

00:25:14,010 --> 00:25:20,160
for you another like interesting stuff

00:25:17,460 --> 00:25:23,070
that we discovered on our database

00:25:20,160 --> 00:25:27,000
journey is that normally database

00:25:23,070 --> 00:25:29,760
vendors expect the user to run repair or

00:25:27,000 --> 00:25:31,860
ongoing repair ongoing the compaction or

00:25:29,760 --> 00:25:34,260
major compaction it's all needs to be

00:25:31,860 --> 00:25:36,900
automatically scheduled by the database

00:25:34,260 --> 00:25:39,110
itself and should come out of the box

00:25:36,900 --> 00:25:42,060
not throw it throw it on the user

00:25:39,110 --> 00:25:45,540
sometimes it throw it gets thrown on the

00:25:42,060 --> 00:25:50,130
user because the database itself is

00:25:45,540 --> 00:25:52,950
bottlenecks and it cannot serve requests

00:25:50,130 --> 00:25:56,580
as in parallel to do regular maintenance

00:25:52,950 --> 00:25:58,920
jobs which may trigger excessive vaios

00:25:56,580 --> 00:26:01,470
but but it's just an excuse good

00:25:58,920 --> 00:26:07,110
database shouldn't should need should do

00:26:01,470 --> 00:26:08,880
it all by itself and the force sharding

00:26:07,110 --> 00:26:12,390
that's another good properties of a

00:26:08,880 --> 00:26:14,490
database if you manage database by

00:26:12,390 --> 00:26:16,650
yourself like my sequel for instance

00:26:14,490 --> 00:26:18,630
then you need to do your own sharding

00:26:16,650 --> 00:26:21,810
but charting is hard especially

00:26:18,630 --> 00:26:24,150
regarding the our solution then there

00:26:21,810 --> 00:26:26,580
are virtual nodes for that but that's

00:26:24,150 --> 00:26:30,230
quite a painting it should come out of

00:26:26,580 --> 00:26:30,230
the box from the database center

00:26:30,980 --> 00:26:35,730
extensibility that's of course obvious

00:26:33,510 --> 00:26:38,430
you want to import and export in the

00:26:35,730 --> 00:26:42,210
format you like and the common ones no

00:26:38,430 --> 00:26:47,970
need to that everyone will we do all of

00:26:42,210 --> 00:26:51,270
the things em that's the case for a

00:26:47,970 --> 00:26:54,090
user-defined function scripts as well

00:26:51,270 --> 00:26:55,760
the last lead or mainly the most

00:26:54,090 --> 00:26:59,160
important thing about this bullet is

00:26:55,760 --> 00:27:03,000
building blocks so database shouldn't be

00:26:59,160 --> 00:27:05,040
a one-trick pony database needs to be an

00:27:03,000 --> 00:27:07,320
infrastructure that's a base case when

00:27:05,040 --> 00:27:11,250
you choose database try to choose one

00:27:07,320 --> 00:27:16,650
that will serve lots of use of usage

00:27:11,250 --> 00:27:19,260
within your expected patterns and will

00:27:16,650 --> 00:27:22,410
be able to run things like time series

00:27:19,260 --> 00:27:23,790
and the graph databases and plenty of

00:27:22,410 --> 00:27:26,460
other things on the very same

00:27:23,790 --> 00:27:28,770
infrastructure if you get that that's

00:27:26,460 --> 00:27:31,940
that's a success no no matter what

00:27:28,770 --> 00:27:31,940
database you picked

00:27:34,120 --> 00:27:44,690
so who knows and they call me maybe who

00:27:40,580 --> 00:27:51,440
knows the database that passes a COS

00:27:44,690 --> 00:27:53,799
test which is it zookeeper mm-hmm that's

00:27:51,440 --> 00:28:00,650
one how many database do you know

00:27:53,799 --> 00:28:05,750
overall yeah that's pretty sad situation

00:28:00,650 --> 00:28:10,040
where a one tool manages to pass it and

00:28:05,750 --> 00:28:13,100
that's a wonderful tool whether if if

00:28:10,040 --> 00:28:15,860
you're going to test a zookeeper or some

00:28:13,100 --> 00:28:19,160
other infrastructure I I strongly urge

00:28:15,860 --> 00:28:20,990
you to go ahead and and we do all of the

00:28:19,160 --> 00:28:22,940
tests and ask yourself the questions

00:28:20,990 --> 00:28:25,460
when you develop your own your own

00:28:22,940 --> 00:28:27,530
application because probably it's

00:28:25,460 --> 00:28:29,590
clustered it's distributed so it's

00:28:27,530 --> 00:28:33,169
worthwhile to look into other people's a

00:28:29,590 --> 00:28:35,210
solution or other people's test not

00:28:33,169 --> 00:28:41,660
necessarily solutions because only one

00:28:35,210 --> 00:28:43,640
it manages to pass it well that's basics

00:28:41,660 --> 00:28:46,880
that your database needs to be

00:28:43,640 --> 00:28:51,559
integrated to with dupe and spark and

00:28:46,880 --> 00:28:55,760
good tools for analytics but it's also

00:28:51,559 --> 00:28:58,610
shouldn't and the idea is that your

00:28:55,760 --> 00:29:01,669
database should be self-contained so all

00:28:58,610 --> 00:29:03,230
of these tools are great but what if

00:29:01,669 --> 00:29:06,020
your database can do most of the work

00:29:03,230 --> 00:29:09,110
for you then it'll definitely be more

00:29:06,020 --> 00:29:11,720
simple if you won't need to to grab your

00:29:09,110 --> 00:29:14,600
analytics experts and we'll be able to

00:29:11,720 --> 00:29:16,400
do aggregation on the database level and

00:29:14,600 --> 00:29:18,470
that's definitely will going to be

00:29:16,400 --> 00:29:21,890
faster than anything out there in the

00:29:18,470 --> 00:29:24,020
market using a spark but because the

00:29:21,890 --> 00:29:26,000
aggregations are done in the database

00:29:24,020 --> 00:29:28,640
layer closer to the data and data

00:29:26,000 --> 00:29:31,360
doesn't need to pass between the

00:29:28,640 --> 00:29:31,360
different clusters

00:29:31,910 --> 00:29:35,150
hopes up

00:29:36,380 --> 00:29:45,660
another wishful feature that I have is a

00:29:42,420 --> 00:29:48,930
test in that environment so some do have

00:29:45,660 --> 00:29:51,660
but but what I'm aiming here is that

00:29:48,930 --> 00:29:53,430
your database or the way you build your

00:29:51,660 --> 00:29:55,920
database so it doesn't necessarily means

00:29:53,430 --> 00:29:58,170
that the database vendor needs to

00:29:55,920 --> 00:30:00,300
provide it although i think it's it's it

00:29:58,170 --> 00:30:03,020
would be a great thing it can come up

00:30:00,300 --> 00:30:06,270
with the tools that wrap the database

00:30:03,020 --> 00:30:09,240
think for for instance that if you'd

00:30:06,270 --> 00:30:12,000
like to if you could have an environment

00:30:09,240 --> 00:30:15,450
where you proxy and duplicate all of the

00:30:12,000 --> 00:30:17,670
requests that come to the database to to

00:30:15,450 --> 00:30:21,120
a neighboring environment that will be

00:30:17,670 --> 00:30:23,700
friendly for tests and Dev then using

00:30:21,120 --> 00:30:27,120
the same real life patterns and the same

00:30:23,700 --> 00:30:30,200
releif data you'll be able to test your

00:30:27,120 --> 00:30:33,179
own application on the live data without

00:30:30,200 --> 00:30:36,360
damaging the the real data if you'll

00:30:33,179 --> 00:30:39,150
just clone either sometimes you can do

00:30:36,360 --> 00:30:42,210
it in the client level and just have the

00:30:39,150 --> 00:30:45,540
client sent duplicate rights to the

00:30:42,210 --> 00:30:47,730
database and to a new test in dev

00:30:45,540 --> 00:30:50,790
environment but but of course that

00:30:47,730 --> 00:30:53,250
forces you to to change the client and

00:30:50,790 --> 00:30:55,890
that's complicated it would have been

00:30:53,250 --> 00:30:57,750
perfect if it could it could have been

00:30:55,890 --> 00:31:01,340
done either in the database layer or the

00:30:57,750 --> 00:31:01,340
tools that wrap the database

00:31:07,670 --> 00:31:12,430
spitting off that data stream

00:31:10,000 --> 00:31:14,610
think bold things like sampling which

00:31:12,430 --> 00:31:14,610
has

00:31:15,230 --> 00:31:18,100
opposition's

00:31:22,119 --> 00:31:28,209
well it's not necessarily you can

00:31:25,439 --> 00:31:31,059
authenticate in a different manner you

00:31:28,209 --> 00:31:35,559
can make it more complex the question is

00:31:31,059 --> 00:31:37,839
how common is that and like sampling it

00:31:35,559 --> 00:31:40,629
is possible to do it like with without

00:31:37,839 --> 00:31:43,959
sampling just clone the entire traffic

00:31:40,629 --> 00:31:49,449
and normally it shouldn't be a problem

00:31:43,959 --> 00:31:53,739
with the regular levels of way of

00:31:49,449 --> 00:31:56,469
resource utilization but it's not

00:31:53,739 --> 00:32:00,359
necessarily out of the box but it may

00:31:56,469 --> 00:32:00,359
fit one organization and not the other

00:32:03,250 --> 00:32:11,800
lopa i I just I revealed the number one

00:32:07,240 --> 00:32:14,830
yeah I mean I'm a about to finish number

00:32:11,800 --> 00:32:17,970
two which really is a Holy Grail is

00:32:14,830 --> 00:32:21,550
multi-tenancy in the database level so

00:32:17,970 --> 00:32:23,680
things like Mark microservices push us

00:32:21,550 --> 00:32:26,470
to create more and more services and

00:32:23,680 --> 00:32:28,630
these services needs the database so you

00:32:26,470 --> 00:32:31,570
find yourself running more and more

00:32:28,630 --> 00:32:33,460
databases more and more clusters in each

00:32:31,570 --> 00:32:35,530
of the clustered needs to have its own

00:32:33,460 --> 00:32:39,700
high availability in multi zoning etc

00:32:35,530 --> 00:32:43,120
etc so there's a lot of idle time and

00:32:39,700 --> 00:32:46,060
resource waste lies in all of these

00:32:43,120 --> 00:32:47,770
multiple clusters and of course a lot of

00:32:46,060 --> 00:32:52,660
administration time that goes into

00:32:47,770 --> 00:32:56,650
managing those those multiple clusters

00:32:52,660 --> 00:32:59,260
and you also going to have silos of a

00:32:56,650 --> 00:33:02,350
really old version that no one touches

00:32:59,260 --> 00:33:04,330
and it's really a bad situation the

00:33:02,350 --> 00:33:07,660
reason that people get to this situation

00:33:04,330 --> 00:33:10,210
is because most of the databases out

00:33:07,660 --> 00:33:13,000
there I can provide really good essay

00:33:10,210 --> 00:33:16,270
lays between the different potential

00:33:13,000 --> 00:33:19,060
tenants so you can define key spaces and

00:33:16,270 --> 00:33:21,510
tables that's not a problem but if you

00:33:19,060 --> 00:33:25,090
have an analytics offline batch

00:33:21,510 --> 00:33:28,480
processing and a real time requirements

00:33:25,090 --> 00:33:30,790
for some other service with under one

00:33:28,480 --> 00:33:33,400
millisecond requirements these things

00:33:30,790 --> 00:33:37,090
will going to clash and that's what what

00:33:33,400 --> 00:33:39,670
that's why things happen like this will

00:33:37,090 --> 00:33:42,070
it is a really desirable thing is to

00:33:39,670 --> 00:33:44,980
support mele tendency in the database

00:33:42,070 --> 00:33:48,610
layer and to define SLI pertinent and

00:33:44,980 --> 00:33:53,350
this way pretty much if you're familiar

00:33:48,610 --> 00:33:55,690
with DynamoDB on AWS pretty much bring

00:33:53,350 --> 00:33:58,990
the SLI to the contract with the user

00:33:55,690 --> 00:34:01,780
and actually make it some sort of assess

00:33:58,990 --> 00:34:04,020
so even though you may be running this

00:34:01,780 --> 00:34:07,900
database within your own organization

00:34:04,020 --> 00:34:10,659
only one administrator is needed for the

00:34:07,900 --> 00:34:13,169
real database and 4-d tenants that they

00:34:10,659 --> 00:34:16,300
just don't need to supply the SLA and

00:34:13,169 --> 00:34:17,740
need to eventually pay for the service

00:34:16,300 --> 00:34:21,950
that

00:34:17,740 --> 00:34:26,000
it need to be charged so that's

00:34:21,950 --> 00:34:29,060
desirable but an implementation from for

00:34:26,000 --> 00:34:31,340
that is if you're familiar with resource

00:34:29,060 --> 00:34:34,250
group from containers and docker world

00:34:31,340 --> 00:34:37,430
then a good implementation for that will

00:34:34,250 --> 00:34:40,070
define the level of RAM that you

00:34:37,430 --> 00:34:44,270
allocate for tenant the the number of I

00:34:40,070 --> 00:34:47,270
ops the number of network packets that

00:34:44,270 --> 00:34:50,330
you allow for the tenants etc or in the

00:34:47,270 --> 00:34:53,030
number of of the volume that you

00:34:50,330 --> 00:34:55,250
allocate for it but basically what once

00:34:53,030 --> 00:34:58,250
you take care for all of these you're

00:34:55,250 --> 00:35:01,040
going to have a fantastic system these

00:34:58,250 --> 00:35:04,940
systems I think other than Oracle no one

00:35:01,040 --> 00:35:07,340
else hey offered them we don't offer

00:35:04,940 --> 00:35:16,360
them too but but we will in the future a

00:35:07,340 --> 00:35:19,700
a get to this scenario and lastly open I

00:35:16,360 --> 00:35:23,180
think openness is the key for everything

00:35:19,700 --> 00:35:27,950
and I'm talking about it could be either

00:35:23,180 --> 00:35:29,930
open source or fantastic open api's it

00:35:27,950 --> 00:35:31,670
not doesn't necessarily has to be open

00:35:29,930 --> 00:35:35,420
source but open source has a lot of

00:35:31,670 --> 00:35:38,390
value because the all of the code is out

00:35:35,420 --> 00:35:40,700
there sometimes our great product with

00:35:38,390 --> 00:35:43,130
00 a really good api's and that that

00:35:40,700 --> 00:35:45,410
should be pretty sufficient for your

00:35:43,130 --> 00:35:48,010
needs that's a must have because with

00:35:45,410 --> 00:35:51,940
this tool you'll be able to automate and

00:35:48,010 --> 00:35:57,010
reduce your risk to your environment

00:35:51,940 --> 00:35:59,970
m and now we probably have two minutes

00:35:57,010 --> 00:35:59,970
for Q&A

00:36:18,830 --> 00:36:29,690
so I definitely agree would you like to

00:36:23,330 --> 00:36:32,240
share like a wishful thinking or provide

00:36:29,690 --> 00:36:35,200
an example for a client that does better

00:36:32,240 --> 00:36:35,200
jobs and others

00:37:07,330 --> 00:37:10,350
I definitely agree

00:37:11,740 --> 00:37:18,650
anything else

00:37:13,890 --> 00:37:18,650

YouTube URL: https://www.youtube.com/watch?v=vFf5ocxjNEU


