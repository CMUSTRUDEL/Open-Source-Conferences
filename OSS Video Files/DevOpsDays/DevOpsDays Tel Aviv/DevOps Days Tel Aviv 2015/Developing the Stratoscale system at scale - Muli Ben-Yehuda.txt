Title: Developing the Stratoscale system at scale - Muli Ben-Yehuda
Publication date: 2015-11-01
Playlist: DevOps Days Tel Aviv 2015
Description: 
	Stratoscale is building a distributed operating system for clouds that manages the compute, storage, and network resources of thousands of machines connected over myriad networks and spanning multiple data centers. The company has grown in two years from two founders to an army of scores of developers, all constantly developing new code and pushing the system to its limits.

This talk will focus not on the Stratoscale system but rather on how the development team develops, tests, deploys and operates it. How do we get tens of developers to work productively at a high velocity while maintaining system cohesion and quality? How can we tame the inherent complexity of such a distributed system? How do we continuously integrate, test, deploy and operate it? How do we take devops to the limit? And just how tasty is our own dog food?

We will share the lessons we've learned, what worked for us and what didn't, and our thoughts on tackling the next challenge: an order of magnitude increase in the number of developers/operators.

About the speaker - Muli Ben-Yehuda

Muli Ben-Yehuda is a systems researcher and an expert in the area of machine and I/O virtualization. He holds a B.A. (cum laude) from the Open University of Israel and an M.Sc. in Computer Science from the Technion -- Israel Institute of Technology. From 2002 until 2012 he held senior research and managerial positions at IBM Research, where he was also an IBM Master Inventor. In 2013 he founded a boutique virtualization and cloud computing consulting company, Hypervisor Technologies and Consulting Ltd, that provided expert consulting services to select clients. Currently he is solving hard cloud computing problems as Stratoscale's Chief Scientist.

Muli has co-authored over forty academic publications and holds over thirty-five US patents in such areas as machine and I/O virtualization, cloud computing, and operating system and hypervisor design and implementation. His code and ideas are included in many operating systems and hypervisors, including the Linux kernel and the Xen and KVM hypervisors. His work on The Turtles Project: Design and Implementation of Nested Virtualization has won the prestigious OSDI Jay Lepreau Best Paper Award and the IBM Research Pat Goldberg Memorial Best Paper Award.
Captions: 
	00:00:10,589 --> 00:00:16,660
okay hello everyone

00:00:13,419 --> 00:00:19,720
it's a pleasure to be here before I get

00:00:16,660 --> 00:00:22,120
started I'd like to ask you guys if you

00:00:19,720 --> 00:00:24,160
have any questions or comments don't

00:00:22,120 --> 00:00:26,830
hesitate let's try and make this

00:00:24,160 --> 00:00:29,290
interactive it will probably be more

00:00:26,830 --> 00:00:32,920
interesting for you guys and for me so

00:00:29,290 --> 00:00:38,950
without further ado I'm going to be

00:00:32,920 --> 00:00:42,640
talking about strata scale in our system

00:00:38,950 --> 00:00:46,600
and in particular how we grew the

00:00:42,640 --> 00:00:51,579
development of the system from two

00:00:46,600 --> 00:00:54,460
founders to 54 developers as of

00:00:51,579 --> 00:00:58,020
yesterday and growing okay this is about

00:00:54,460 --> 00:01:00,700
this is a story about our journey and

00:00:58,020 --> 00:01:04,839
the DevOps related aspects of it of

00:01:00,700 --> 00:01:07,180
course so to give you guys context this

00:01:04,839 --> 00:01:08,950
is not a product pitch if you want the

00:01:07,180 --> 00:01:11,110
product pitch come to our table later

00:01:08,950 --> 00:01:13,540
and I'll give you the full product pitch

00:01:11,110 --> 00:01:16,659
that's not a problem this is just to put

00:01:13,540 --> 00:01:20,940
what I'll talk about in context so what

00:01:16,659 --> 00:01:24,840
does straddle scale do we are building

00:01:20,940 --> 00:01:29,170
private clouds or more accurately

00:01:24,840 --> 00:01:31,420
operating systems or private clouds you

00:01:29,170 --> 00:01:37,210
buy a bunch of servers anywhere from one

00:01:31,420 --> 00:01:39,820
server to several racks of servers you

00:01:37,210 --> 00:01:42,909
install our operating system based on

00:01:39,820 --> 00:01:47,350
Linux of course on those servers and you

00:01:42,909 --> 00:01:49,720
get a full-featured private cloud you

00:01:47,350 --> 00:01:52,540
get a compute lair you get a storage

00:01:49,720 --> 00:01:54,189
layer you get a networking layer you get

00:01:52,540 --> 00:01:56,409
the cloud management that wraps all of

00:01:54,189 --> 00:02:01,049
this together we're building software

00:01:56,409 --> 00:02:03,189
for private clouds okay unlike a lot of

00:02:01,049 --> 00:02:05,799
stuff that I expect we'll be talking

00:02:03,189 --> 00:02:08,799
about during this conference our

00:02:05,799 --> 00:02:11,290
software runs on the customers premise

00:02:08,799 --> 00:02:12,910
this is a private cloud okay this is for

00:02:11,290 --> 00:02:13,980
people who want something like Amazon

00:02:12,910 --> 00:02:16,050
except

00:02:13,980 --> 00:02:19,470
their own data center and that's

00:02:16,050 --> 00:02:21,569
important to keep in mind a little bit

00:02:19,470 --> 00:02:25,560
about the company it was founded in

00:02:21,569 --> 00:02:27,840
early 2013 we've grown in the last

00:02:25,560 --> 00:02:30,900
two-and-a-half three years from two

00:02:27,840 --> 00:02:34,470
founders to seventy plus people 54 of

00:02:30,900 --> 00:02:36,230
them developers we have a bunch of

00:02:34,470 --> 00:02:38,730
different expertise in different areas

00:02:36,230 --> 00:02:40,349
we raised a bunch of money blah blah

00:02:38,730 --> 00:02:42,930
blah that's not important okay the

00:02:40,349 --> 00:02:46,799
important thing is we're on a growth

00:02:42,930 --> 00:02:49,349
trajectory so what is this talk about

00:02:46,799 --> 00:02:51,260
this talk is about scaling and in

00:02:49,349 --> 00:02:54,140
particular how do you scale your

00:02:51,260 --> 00:02:57,209
development and operations and testing

00:02:54,140 --> 00:02:59,609
how do you scale the people how to scale

00:02:57,209 --> 00:03:04,739
the processes the systems that you use

00:02:59,609 --> 00:03:08,160
to do this how we scaled every aspect of

00:03:04,739 --> 00:03:12,870
the company pretty much again to put it

00:03:08,160 --> 00:03:14,519
in context this is not your often when

00:03:12,870 --> 00:03:19,530
we talk about DevOps we're talking about

00:03:14,519 --> 00:03:22,980
complex web applications multi-tier but

00:03:19,530 --> 00:03:28,440
they all have some things in common our

00:03:22,980 --> 00:03:32,630
system is different because it's built

00:03:28,440 --> 00:03:35,989
from the ground up we have our own

00:03:32,630 --> 00:03:39,079
memory management at a hypervisor layer

00:03:35,989 --> 00:03:42,090
we have remote memory in the system

00:03:39,079 --> 00:03:44,819
software based remote memory enabling

00:03:42,090 --> 00:03:46,560
one no to access another notes memory we

00:03:44,819 --> 00:03:51,150
have our own scale our distributed

00:03:46,560 --> 00:03:53,299
storage subsystem written in C++ okay

00:03:51,150 --> 00:03:56,760
this is very much not a web application

00:03:53,299 --> 00:03:59,819
this stuff it's all written in C and in

00:03:56,760 --> 00:04:02,720
assembly okay that raises all sorts of

00:03:59,819 --> 00:04:05,160
interesting challenges when you come to

00:04:02,720 --> 00:04:08,220
developing testing and operating and

00:04:05,160 --> 00:04:10,739
deploying and operating it we have of

00:04:08,220 --> 00:04:13,139
course the cloud management stack and

00:04:10,739 --> 00:04:15,780
our own cluster in glass so this is a

00:04:13,139 --> 00:04:18,199
big distributed system and that raises a

00:04:15,780 --> 00:04:20,639
whole slew of different challenges

00:04:18,199 --> 00:04:23,250
there's the management aspects there you

00:04:20,639 --> 00:04:27,030
are UX aspects and this is all just one

00:04:23,250 --> 00:04:31,380
big system so how do you develop test

00:04:27,030 --> 00:04:35,639
deploy operate running as I mentioned

00:04:31,380 --> 00:04:38,010
many different aspects and when the

00:04:35,639 --> 00:04:42,960
company said this was a vision from day

00:04:38,010 --> 00:04:45,780
one whereas other companies might pick

00:04:42,960 --> 00:04:47,820
just one of these aspects and build a

00:04:45,780 --> 00:04:51,360
product around that we decided to do

00:04:47,820 --> 00:04:53,130
everything we are very fond of when

00:04:51,360 --> 00:04:56,220
asking should we do this or should we do

00:04:53,130 --> 00:04:59,850
that we should the answer is often let's

00:04:56,220 --> 00:05:02,190
do both so we're trying to do all of

00:04:59,850 --> 00:05:04,590
this and in the context of the

00:05:02,190 --> 00:05:07,890
development system we want all of it to

00:05:04,590 --> 00:05:09,450
be developed as a single system and I'll

00:05:07,890 --> 00:05:12,120
talk about some of the implications of

00:05:09,450 --> 00:05:14,700
that in a bit so let's talk about the

00:05:12,120 --> 00:05:18,540
beginning in the beginning there were

00:05:14,700 --> 00:05:21,570
anywhere from 0 to 10 developers we used

00:05:18,540 --> 00:05:24,330
a single deep repository for all the

00:05:21,570 --> 00:05:26,910
company's source code the kernel bits

00:05:24,330 --> 00:05:29,940
storage bits the networking bits the

00:05:26,910 --> 00:05:32,880
cloud management bits in Python in our

00:05:29,940 --> 00:05:35,490
case mostly although not necessarily the

00:05:32,880 --> 00:05:40,620
UI bits all of it in a single git

00:05:35,490 --> 00:05:43,470
repository we were very focused on

00:05:40,620 --> 00:05:46,650
testing and on deploying stuff very

00:05:43,470 --> 00:05:49,289
quickly in an automated manner from the

00:05:46,650 --> 00:05:51,510
get-go we initially used at Lacy and

00:05:49,289 --> 00:05:53,700
bamboo for our continuous integration

00:05:51,510 --> 00:05:55,620
and continuous delivery how many of you

00:05:53,700 --> 00:05:58,620
done I'm just curious how many of you

00:05:55,620 --> 00:06:03,810
use it or have used it ok not too many

00:05:58,620 --> 00:06:07,440
we don't use it anymore through no fault

00:06:03,810 --> 00:06:12,330
of bamboo it just wasn't a very good fit

00:06:07,440 --> 00:06:16,140
for us when it came to the kernel bits

00:06:12,330 --> 00:06:18,990
in particular it's pretty good for stuff

00:06:16,140 --> 00:06:21,810
that's higher up in the stack but our

00:06:18,990 --> 00:06:24,539
kernel developers really did not get the

00:06:21,810 --> 00:06:28,919
experience that we were looking for when

00:06:24,539 --> 00:06:31,140
using bamboo and SoftLayer for

00:06:28,919 --> 00:06:31,970
continuous integration and delivery in

00:06:31,140 --> 00:06:35,250
testing

00:06:31,970 --> 00:06:39,900
so that was what we started with

00:06:35,250 --> 00:06:42,780
I didn't pan out as I mentioned so you

00:06:39,900 --> 00:06:46,889
know the company has grown a little bit

00:06:42,780 --> 00:06:51,300
by that time and we figured out you know

00:06:46,889 --> 00:06:56,280
why don't we write our own CI system how

00:06:51,300 --> 00:06:58,050
hard can it be and that's what we set

00:06:56,280 --> 00:07:00,240
out to do and we were sure you know

00:06:58,050 --> 00:07:02,460
we're on the promised road we're gonna

00:07:00,240 --> 00:07:06,419
get to shangri-la it's gonna be awesome

00:07:02,460 --> 00:07:08,160
and in fact it was pretty good this is

00:07:06,419 --> 00:07:09,419
what it looked at and every time I look

00:07:08,160 --> 00:07:09,930
at this this brings back a lot of

00:07:09,419 --> 00:07:12,930
memories

00:07:09,930 --> 00:07:15,780
laughs it's a bit too small this monitor

00:07:12,930 --> 00:07:18,060
you guys probably can't read it but let

00:07:15,780 --> 00:07:20,180
me tell you guys what we're seeing here

00:07:18,060 --> 00:07:24,889
you're seeing a web application running

00:07:20,180 --> 00:07:27,990
on a server in our data center that's

00:07:24,889 --> 00:07:30,690
continuously monitoring our single git

00:07:27,990 --> 00:07:34,470
repository for branches that have either

00:07:30,690 --> 00:07:38,699
pool request or push request as a prefix

00:07:34,470 --> 00:07:42,990
in the name every such branch once it is

00:07:38,699 --> 00:07:45,300
found is automatically run through at

00:07:42,990 --> 00:07:48,599
the point of time when this stranger was

00:07:45,300 --> 00:07:50,729
taken we had 95 different integration

00:07:48,599 --> 00:07:52,500
tests I'll talk about unit tests and

00:07:50,729 --> 00:07:54,659
white book tests in a bit

00:07:52,500 --> 00:07:57,570
these are integration tests so every

00:07:54,659 --> 00:08:00,270
such branch is run through the 95

00:07:57,570 --> 00:08:02,970
different tests and if it passes all of

00:08:00,270 --> 00:08:04,949
them it is automatically committed to

00:08:02,970 --> 00:08:07,320
the tree and becomes the new head of the

00:08:04,949 --> 00:08:10,889
tree that everyone's supposed to rebase

00:08:07,320 --> 00:08:13,259
themselves against just sure just so you

00:08:10,889 --> 00:08:15,630
know I get a better feel for you guys

00:08:13,259 --> 00:08:18,659
when I talk about rebasing and pull

00:08:15,630 --> 00:08:20,789
requests is this Chinese to many of you

00:08:18,659 --> 00:08:24,570
or are we all on the same page when it

00:08:20,789 --> 00:08:26,400
comes to get ok this is the technical

00:08:24,570 --> 00:08:32,150
track I'm not showing you guys any code

00:08:26,400 --> 00:08:32,150
but I'm taking some liberties so

00:08:32,820 --> 00:08:38,310
pull requests go into matically into the

00:08:35,490 --> 00:08:39,090
tree they run through the tests are run

00:08:38,310 --> 00:08:42,300
automatically

00:08:39,090 --> 00:08:45,960
if they pass everything's great right

00:08:42,300 --> 00:08:47,880
that was the vision and any change that

00:08:45,960 --> 00:08:50,420
any developer makes that passes the

00:08:47,880 --> 00:08:53,900
testing is automatically committed

00:08:50,420 --> 00:08:53,900
sounds great right

00:08:54,080 --> 00:09:01,200
unfortunately let me tell you guys what

00:08:57,960 --> 00:09:03,780
happened when we grew okay this worked

00:09:01,200 --> 00:09:05,850
pretty well for a time or maybe I'm just

00:09:03,780 --> 00:09:09,170
being nostalgic but I think it worked

00:09:05,850 --> 00:09:14,400
pretty well for a time but when we grew

00:09:09,170 --> 00:09:18,660
things just burst at the seams you can

00:09:14,400 --> 00:09:24,180
see some hints of trouble to come even

00:09:18,660 --> 00:09:28,590
here let me go over them see this list

00:09:24,180 --> 00:09:30,270
up here that's by the way this was taken

00:09:28,590 --> 00:09:33,990
as it happens a couple of these pool

00:09:30,270 --> 00:09:36,840
requests are mine and I seem to recall I

00:09:33,990 --> 00:09:39,470
sent them pretty late at night so we're

00:09:36,840 --> 00:09:43,320
talking about a late hour in the day and

00:09:39,470 --> 00:09:46,740
were we have what is it seven pool

00:09:43,320 --> 00:09:49,050
requests just waiting to be tested now

00:09:46,740 --> 00:09:51,090
the testing that we did at this point in

00:09:49,050 --> 00:09:52,470
time we didn't have a data center we

00:09:51,090 --> 00:09:57,450
didn't have a lot of iron a lot of

00:09:52,470 --> 00:10:00,030
servers so everything here an remember

00:09:57,450 --> 00:10:02,730
our system is a cluster of bare metal

00:10:00,030 --> 00:10:04,350
nodes but since we didn't have enough

00:10:02,730 --> 00:10:06,710
clusters and big enough clusters

00:10:04,350 --> 00:10:10,920
everything here ran in virtual machines

00:10:06,710 --> 00:10:16,440
each virtual machine standing for a bare

00:10:10,920 --> 00:10:19,650
metal node okay for those of you who are

00:10:16,440 --> 00:10:21,360
familiar with KVM this everything our

00:10:19,650 --> 00:10:24,810
system and everything I'm talking about

00:10:21,360 --> 00:10:27,090
here is based on KVM so for those of you

00:10:24,810 --> 00:10:30,310
who are familiar with KVM you should

00:10:27,090 --> 00:10:34,389
probably be thinking right now oh no

00:10:30,310 --> 00:10:37,389
nested virtualization okay

00:10:34,389 --> 00:10:39,339
nested virtualization which I was

00:10:37,389 --> 00:10:44,920
involved in developing in a previous

00:10:39,339 --> 00:10:47,230
life while at IBM research I think this

00:10:44,920 --> 00:10:50,680
might have been one of them biggest uses

00:10:47,230 --> 00:10:53,620
of nested virtualization to do something

00:10:50,680 --> 00:10:56,620
concrete and we ran into all sorts of

00:10:53,620 --> 00:10:59,529
problems that you don't expect to run

00:10:56,620 --> 00:11:02,139
into while building a CI system lost

00:10:59,529 --> 00:11:04,959
interrupts okay a colleague of mine

00:11:02,139 --> 00:11:07,089
spent two weeks hunting for why an

00:11:04,959 --> 00:11:11,439
interrupt which happened to be pretty

00:11:07,089 --> 00:11:17,589
important got lost we found it by the

00:11:11,439 --> 00:11:20,740
way so tests are running slowly tests

00:11:17,589 --> 00:11:22,089
are failing because of artifacts of the

00:11:20,740 --> 00:11:24,089
environment the fact that we're running

00:11:22,089 --> 00:11:27,579
in a nested virtualization environment

00:11:24,089 --> 00:11:30,879
tests are failing pool requests don't go

00:11:27,579 --> 00:11:33,220
in pull requests don't go in developers

00:11:30,879 --> 00:11:35,680
who are convinced their code is perfect

00:11:33,220 --> 00:11:38,800
and in many cases were actually right

00:11:35,680 --> 00:11:42,910
it's the CI system that's failing tests

00:11:38,800 --> 00:11:45,189
it's not the tests that are failing they

00:11:42,910 --> 00:11:48,160
just send their pool requests again and

00:11:45,189 --> 00:11:51,430
again this causes LOD load this causes

00:11:48,160 --> 00:11:54,220
delays ok this causes frustration lots

00:11:51,430 --> 00:11:58,629
and lots of frustration we're seeing

00:11:54,220 --> 00:12:01,149
here for example that the last build

00:11:58,629 --> 00:12:05,470
that actually succeeded was actually a

00:12:01,149 --> 00:12:09,339
push request we had a mechanism wielded

00:12:05,470 --> 00:12:12,550
by select few such as Rotom hill to

00:12:09,339 --> 00:12:15,129
bypass the whole system because

00:12:12,550 --> 00:12:17,319
sometimes you know the computer is wrong

00:12:15,129 --> 00:12:19,360
the person is right and this code should

00:12:17,319 --> 00:12:21,759
actually go in and when you have such a

00:12:19,360 --> 00:12:27,100
bypass mechanism you know that you're

00:12:21,759 --> 00:12:29,860
you have problems so in more in a more

00:12:27,100 --> 00:12:33,160
structured way once we got to run 20

00:12:29,860 --> 00:12:35,949
developers the build times were long and

00:12:33,160 --> 00:12:38,110
getting longer now we're talking about I

00:12:35,949 --> 00:12:41,350
think an hour and a half

00:12:38,110 --> 00:12:44,440
for one build two run of the tests that

00:12:41,350 --> 00:12:47,200
order of magnitude we had multiple build

00:12:44,440 --> 00:12:48,760
types trying to speed things up maybe

00:12:47,200 --> 00:12:50,459
we'll just do partial builds let's do

00:12:48,760 --> 00:12:53,790
cache and let's do all sorts of things

00:12:50,459 --> 00:12:58,470
that you shouldn't do unless you have to

00:12:53,790 --> 00:13:00,730
the rapid growth of the company caused a

00:12:58,470 --> 00:13:05,320
bunch of artifacts in the way that

00:13:00,730 --> 00:13:07,180
people were improving the CI system just

00:13:05,320 --> 00:13:09,940
not being aware of what was done before

00:13:07,180 --> 00:13:12,820
I mentioned that at this stage all of

00:13:09,940 --> 00:13:14,980
our bare metal nodes were actually

00:13:12,820 --> 00:13:17,380
running in virtual machines we had

00:13:14,980 --> 00:13:19,959
templates of these virtual machines to

00:13:17,380 --> 00:13:22,029
speed up instantiating nodes because

00:13:19,959 --> 00:13:23,950
before a test could run you had to build

00:13:22,029 --> 00:13:26,589
up a cluster so that was obviously an

00:13:23,950 --> 00:13:29,260
important part of the cycle initially we

00:13:26,589 --> 00:13:31,360
had a single template but then people

00:13:29,260 --> 00:13:33,459
need new templates and it was easier to

00:13:31,360 --> 00:13:35,829
create their own templates which were

00:13:33,459 --> 00:13:37,870
subtly different than the original

00:13:35,829 --> 00:13:40,390
templates but identical in every other

00:13:37,870 --> 00:13:42,579
way and use that and we ended up I think

00:13:40,390 --> 00:13:44,620
with five or maybe more

00:13:42,579 --> 00:13:46,870
Vanilla's and that was a problem because

00:13:44,620 --> 00:13:49,779
it started being a big unmaintainable

00:13:46,870 --> 00:13:52,839
mess another issue with the single git

00:13:49,779 --> 00:13:56,860
repository approach that we had is that

00:13:52,839 --> 00:14:02,020
we had this mentality we had a lot of

00:13:56,860 --> 00:14:05,380
interesting mental quirks that I can't

00:14:02,020 --> 00:14:06,910
go into in this polite company but buy

00:14:05,380 --> 00:14:08,200
me a beer sometime and I'll tell you all

00:14:06,910 --> 00:14:10,420
about it

00:14:08,200 --> 00:14:12,970
but one of the quickest that I can talk

00:14:10,420 --> 00:14:15,670
about is this everyone is an owner okay

00:14:12,970 --> 00:14:17,170
everyone should feel ownership of every

00:14:15,670 --> 00:14:19,720
part of the code you know what this

00:14:17,170 --> 00:14:23,440
translates to it translates to no one is

00:14:19,720 --> 00:14:25,899
an owner okay ownership is not so easy

00:14:23,440 --> 00:14:27,910
and if you say everyone's an hour the

00:14:25,899 --> 00:14:29,440
owner and you know you have a deadline

00:14:27,910 --> 00:14:31,510
you have this critical fix that you want

00:14:29,440 --> 00:14:33,370
to get in you have this feature that you

00:14:31,510 --> 00:14:35,500
really really want to put into the code

00:14:33,370 --> 00:14:37,630
and you just found a problem some other

00:14:35,500 --> 00:14:39,459
part you're not thinking oh I own that

00:14:37,630 --> 00:14:42,850
as well you're thinking someone else

00:14:39,459 --> 00:14:45,640
will fix it and that's not a that's not

00:14:42,850 --> 00:14:47,800
a good way to build systems and the last

00:14:45,640 --> 00:14:50,230
issue is that again similar git

00:14:47,800 --> 00:14:51,490
repository every aspect of the system is

00:14:50,230 --> 00:14:54,630
built in the

00:14:51,490 --> 00:14:59,339
same way changes in one part unless

00:14:54,630 --> 00:15:02,470
you're very strict about modularity and

00:14:59,339 --> 00:15:06,160
building components with the right level

00:15:02,470 --> 00:15:09,100
of abstraction which we to be honest

00:15:06,160 --> 00:15:12,670
were not we were not as rigorous as we

00:15:09,100 --> 00:15:15,339
should have been and as we are today you

00:15:12,670 --> 00:15:17,770
get into cascading changes okay someone

00:15:15,339 --> 00:15:19,990
makes a change in one place supposedly

00:15:17,770 --> 00:15:21,810
completely unrelated to some other thing

00:15:19,990 --> 00:15:27,760
but that other thing just broke and that

00:15:21,810 --> 00:15:31,149
happened a lot so at this point in time

00:15:27,760 --> 00:15:32,980
one of our key developers swami matheson

00:15:31,149 --> 00:15:37,000
who's not here today but he's an awesome

00:15:32,980 --> 00:15:42,310
guy started thinking you know what we

00:15:37,000 --> 00:15:47,850
have right now that's a pretty much

00:15:42,310 --> 00:15:51,040
okay my son what we want is a skyscraper

00:15:47,850 --> 00:15:53,709
we want we're growing we're constantly

00:15:51,040 --> 00:15:57,130
growing this is not a foundation that we

00:15:53,709 --> 00:16:02,140
can build on what we had how do you

00:15:57,130 --> 00:16:05,529
build the tools that process says the

00:16:02,140 --> 00:16:09,310
testing to enable you to build a

00:16:05,529 --> 00:16:14,890
skyscraper to grow in an order of

00:16:09,310 --> 00:16:16,540
magnitude so what we did what Shlomi

00:16:14,890 --> 00:16:20,709
mostly did initially and then others

00:16:16,540 --> 00:16:23,740
joined into the effort is to build first

00:16:20,709 --> 00:16:26,320
of all a set of tools for 50-plus

00:16:23,740 --> 00:16:28,329
developers as I mentioned today were 54

00:16:26,320 --> 00:16:32,260
developers and here we're talking about

00:16:28,329 --> 00:16:33,850
a year or in a year and a half ago so

00:16:32,260 --> 00:16:36,490
the first things remitted Shlomi is a

00:16:33,850 --> 00:16:39,430
great guy but he really likes to invent

00:16:36,490 --> 00:16:41,079
things which sometimes that's exactly

00:16:39,430 --> 00:16:43,779
what you need

00:16:41,079 --> 00:16:45,940
he built a bunch of tools first he built

00:16:43,779 --> 00:16:48,100
an arsenic replacement because our sink

00:16:45,940 --> 00:16:49,870
wasn't good enough and I'm happy to say

00:16:48,100 --> 00:16:52,089
that when he came to me and said you

00:16:49,870 --> 00:16:53,770
know our sink is not good enough I said

00:16:52,089 --> 00:16:56,200
what the hell are you talking about

00:16:53,770 --> 00:16:58,390
but then he showed me that for a bunch

00:16:56,200 --> 00:17:00,940
of stuff that we needed to arcing for

00:16:58,390 --> 00:17:03,000
our specific use cases when we were

00:17:00,940 --> 00:17:06,820
building

00:17:03,000 --> 00:17:10,270
they're filesystems of our cluster nodes

00:17:06,820 --> 00:17:12,250
our sink actually spent a lot of time or

00:17:10,270 --> 00:17:14,440
if you combine some concepts from get

00:17:12,250 --> 00:17:17,170
the concepts of objects and diffs

00:17:14,440 --> 00:17:19,300
between objects you could actually speed

00:17:17,170 --> 00:17:22,960
that up a lot so that's a tool called

00:17:19,300 --> 00:17:24,760
osmosis you can think of it as an

00:17:22,960 --> 00:17:27,910
arsenic replacement without getting into

00:17:24,760 --> 00:17:29,800
the details solvent is built on top of a

00:17:27,910 --> 00:17:32,170
smoothness and is a build artifact

00:17:29,800 --> 00:17:36,730
repository okay it knows how to use the

00:17:32,170 --> 00:17:39,070
osmosis protocol so osmosis is at the

00:17:36,730 --> 00:17:41,290
level of objects solvent is at the

00:17:39,070 --> 00:17:44,500
levels is at a level of files

00:17:41,290 --> 00:17:47,980
okay so solvent you basically are tied I

00:17:44,500 --> 00:17:49,510
want version 17 of some specific

00:17:47,980 --> 00:17:51,430
component of our system

00:17:49,510 --> 00:17:53,860
maybe it's an executable maybe it's a

00:17:51,430 --> 00:17:56,490
daemon maybe it's an RPM package maybe

00:17:53,860 --> 00:17:58,960
it's a docker container maybe it's a

00:17:56,490 --> 00:18:01,720
maybe it's a library whatever and

00:17:58,960 --> 00:18:04,180
solvent will get you that version very

00:18:01,720 --> 00:18:07,030
very quickly by the way I didn't mention

00:18:04,180 --> 00:18:08,830
it barrel system runs both virtual

00:18:07,030 --> 00:18:12,000
machines and containers and I'll talk

00:18:08,830 --> 00:18:16,270
about that it puts more in a bit ok

00:18:12,000 --> 00:18:19,060
inaugurate er is a tiny Linux image the

00:18:16,270 --> 00:18:20,620
way that our machines and it doesn't

00:18:19,060 --> 00:18:23,500
matter right now if these are virtual

00:18:20,620 --> 00:18:24,820
machines or bare metal servers the way

00:18:23,500 --> 00:18:27,160
that they work in our testing

00:18:24,820 --> 00:18:29,290
environment is that the inaugurate er is

00:18:27,160 --> 00:18:31,420
the first thing that boots and then it

00:18:29,290 --> 00:18:34,960
talks with the object and file

00:18:31,420 --> 00:18:36,640
repository and basically brings that

00:18:34,960 --> 00:18:39,280
system to the state that you want it to

00:18:36,640 --> 00:18:41,740
be in to run a specific test or to run a

00:18:39,280 --> 00:18:44,260
specific set of tests so that's the

00:18:41,740 --> 00:18:47,830
inaugurate ur we also built a tool

00:18:44,260 --> 00:18:49,810
called up Seto the reason why it's

00:18:47,830 --> 00:18:50,950
called up Seto is because we had a tool

00:18:49,810 --> 00:18:52,900
called this Prado

00:18:50,950 --> 00:18:56,440
so Shlomi was distraught with this

00:18:52,900 --> 00:19:00,460
trudeau and he built upset oh yeah I

00:18:56,440 --> 00:19:01,780
don't desk upset oh there's a big

00:19:00,460 --> 00:19:03,580
difference between what the vision was

00:19:01,780 --> 00:19:06,040
and what ended up happening in the end

00:19:03,580 --> 00:19:08,440
in the end we used it mostly as a good

00:19:06,040 --> 00:19:09,320
sub model replacement or a repo

00:19:08,440 --> 00:19:10,760
replacement

00:19:09,320 --> 00:19:14,090
for those of you who are not familiar

00:19:10,760 --> 00:19:17,720
with these concepts we wanted to take

00:19:14,090 --> 00:19:19,640
this one big git repository and break it

00:19:17,720 --> 00:19:24,050
up into multiple repositories for

00:19:19,640 --> 00:19:26,960
various reasons now this is not this is

00:19:24,050 --> 00:19:28,550
not a must for example I don't know how

00:19:26,960 --> 00:19:31,610
many of you have seen it but it recently

00:19:28,550 --> 00:19:34,610
came out that Google uses a single large

00:19:31,610 --> 00:19:38,030
repository for all company source code

00:19:34,610 --> 00:19:40,160
okay single large repository of course

00:19:38,030 --> 00:19:42,170
that repository is carved up and split

00:19:40,160 --> 00:19:44,720
in various different ways but it is

00:19:42,170 --> 00:19:46,520
still a single repository we decided to

00:19:44,720 --> 00:19:49,100
do something that's more traditional I

00:19:46,520 --> 00:19:51,200
would say and have just multiple models

00:19:49,100 --> 00:19:53,660
and multiple peach repositories for

00:19:51,200 --> 00:19:55,430
different aspects of the code this is

00:19:53,660 --> 00:19:57,890
probably a good time to mention that

00:19:55,430 --> 00:19:59,750
these tools and many other are actually

00:19:57,890 --> 00:20:02,330
available on github we've open sourced

00:19:59,750 --> 00:20:04,010
them this is not our product this is

00:20:02,330 --> 00:20:06,410
just the stuff that we use for our

00:20:04,010 --> 00:20:08,390
infrastructure for developing and

00:20:06,410 --> 00:20:11,420
testing and operating and running our

00:20:08,390 --> 00:20:17,630
product let me see what time it is okay

00:20:11,420 --> 00:20:21,080
we're good we ditched our homegrown CI

00:20:17,630 --> 00:20:24,080
system and switch to how many of you are

00:20:21,080 --> 00:20:25,730
familiar with this most of you we switch

00:20:24,080 --> 00:20:29,960
to Jenkins like pretty much everyone

00:20:25,730 --> 00:20:32,120
else so this is the R Jenkins server

00:20:29,960 --> 00:20:33,980
which runs a whole bunch of jobs to do a

00:20:32,120 --> 00:20:37,070
whole bunch of different things most

00:20:33,980 --> 00:20:38,780
importantly it enables you through some

00:20:37,070 --> 00:20:44,210
other bits that I'll talk about in a bit

00:20:38,780 --> 00:20:46,910
it enables you to spawn up clusters of

00:20:44,210 --> 00:20:49,070
various sizes with specific versions of

00:20:46,910 --> 00:20:51,560
our software and then run a bunch of

00:20:49,070 --> 00:20:53,840
scenarios on them and we use this

00:20:51,560 --> 00:20:56,750
capability for continuous integration

00:20:53,840 --> 00:20:59,420
and continuous delivery so that we

00:20:56,750 --> 00:21:01,430
always run in addition to a bunch of

00:20:59,420 --> 00:21:05,660
other things the latest bists over a

00:21:01,430 --> 00:21:07,370
code on the system for those of you who

00:21:05,660 --> 00:21:10,610
are familiar with Jenkins you know that

00:21:07,370 --> 00:21:12,730
it has agents or slaves because we're

00:21:10,610 --> 00:21:16,520
big believers in eating gone dog food

00:21:12,730 --> 00:21:18,980
our Jenkins slaves and everything

00:21:16,520 --> 00:21:20,210
related to Jenkins runs on the Stratos

00:21:18,980 --> 00:21:22,470
scale system

00:21:20,210 --> 00:21:26,310
obviously we don't update it every day

00:21:22,470 --> 00:21:29,970
we try to keep to the stable version but

00:21:26,310 --> 00:21:32,100
it's running as of as of the last time I

00:21:29,970 --> 00:21:35,580
looked it was running for several weeks

00:21:32,100 --> 00:21:37,850
without any particular issues and this

00:21:35,580 --> 00:21:41,640
is extremely important to us that all

00:21:37,850 --> 00:21:44,970
the stuff that we use internally runs on

00:21:41,640 --> 00:21:46,650
our own stuff I want to talk about

00:21:44,970 --> 00:21:50,880
testing for a bit and then I'll talk

00:21:46,650 --> 00:21:53,070
about another aspect it became obvious

00:21:50,880 --> 00:21:55,800
that if we want to scale the development

00:21:53,070 --> 00:21:58,620
process we want to develop more stuff

00:21:55,800 --> 00:22:01,710
faster we have to be more rigorous when

00:21:58,620 --> 00:22:04,550
it comes to testing so we employ four

00:22:01,710 --> 00:22:07,950
different kinds of testing methodologies

00:22:04,550 --> 00:22:12,510
we do unit tests for the function or

00:22:07,950 --> 00:22:14,670
class level basically just making sure

00:22:12,510 --> 00:22:18,120
that a bunch of code does what it is

00:22:14,670 --> 00:22:20,760
supposed to do in isolation we use white

00:22:18,120 --> 00:22:22,680
box testing our system is composed of

00:22:20,760 --> 00:22:26,550
multiple demons they do a bunch of

00:22:22,680 --> 00:22:28,440
different things you can think of it as

00:22:26,550 --> 00:22:30,600
a micro servers architecture although

00:22:28,440 --> 00:22:34,020
many many of our demons are not micro

00:22:30,600 --> 00:22:38,250
they're actually Makua big instead of

00:22:34,020 --> 00:22:42,390
small but we're working on that so white

00:22:38,250 --> 00:22:45,090
box testing are used to test a demon in

00:22:42,390 --> 00:22:47,100
isolation using mocks of other objects

00:22:45,090 --> 00:22:49,380
or demons so that we don't have to test

00:22:47,100 --> 00:22:51,360
everything together we use something

00:22:49,380 --> 00:22:53,640
called voodoo that you can also look up

00:22:51,360 --> 00:22:56,940
on github that I won't go into for lack

00:22:53,640 --> 00:22:58,530
of time we run subsystem tests on each

00:22:56,940 --> 00:23:00,420
other a different subsystem there is a

00:22:58,530 --> 00:23:02,850
bunch of kernel specific tests

00:23:00,420 --> 00:23:05,970
hypervisor specific tests memory

00:23:02,850 --> 00:23:10,050
specific tests storage specific tests

00:23:05,970 --> 00:23:12,630
these test features ok thanks for such

00:23:10,050 --> 00:23:14,370
as for example our remote memory there

00:23:12,630 --> 00:23:16,890
would be a bunch of subsystem tests that

00:23:14,370 --> 00:23:20,400
test just that specific aspect over the

00:23:16,890 --> 00:23:22,620
system they also test how well parts of

00:23:20,400 --> 00:23:24,050
integrated with other parts of the

00:23:22,620 --> 00:23:27,100
system

00:23:24,050 --> 00:23:30,050
and of course we have system tests that

00:23:27,100 --> 00:23:34,220
do end-to-end testing usually using our

00:23:30,050 --> 00:23:37,100
API or CLI or a web UI just running user

00:23:34,220 --> 00:23:40,310
scenarios on the entire system so for

00:23:37,100 --> 00:23:42,500
different types of tests to cover as

00:23:40,310 --> 00:23:50,500
much as possible every aspect of the

00:23:42,500 --> 00:23:53,840
system now we it became obvious that as

00:23:50,500 --> 00:23:56,300
we grow both the company and the scale

00:23:53,840 --> 00:23:58,370
of the system and I don't think I

00:23:56,300 --> 00:24:01,190
mentioned this but our late latest

00:23:58,370 --> 00:24:03,890
release which is out now supports up to

00:24:01,190 --> 00:24:07,250
100 nodes our next release will support

00:24:03,890 --> 00:24:10,610
up to 1,000 nodes it became obvious that

00:24:07,250 --> 00:24:12,800
you know running testing at that scale

00:24:10,610 --> 00:24:15,860
in nested virtual machines that wasn't

00:24:12,800 --> 00:24:18,020
going to fly so the lay layer last part

00:24:15,860 --> 00:24:18,740
of our two stack is something we call

00:24:18,020 --> 00:24:23,150
the Rack Attack

00:24:18,740 --> 00:24:27,380
okay Rack Attack is a system for very

00:24:23,150 --> 00:24:30,530
quickly allocating provisioning and then

00:24:27,380 --> 00:24:33,320
reclaiming bare metal servers this is

00:24:30,530 --> 00:24:36,980
pretty awesome you run a command and

00:24:33,320 --> 00:24:40,400
five seconds later you have a bunch of

00:24:36,980 --> 00:24:43,610
servers as many as you want I'll talk

00:24:40,400 --> 00:24:46,040
about this ill in a bit you have a bunch

00:24:43,610 --> 00:24:48,710
of servers that have been allocated for

00:24:46,040 --> 00:24:51,110
your use our system raccattack

00:24:48,710 --> 00:24:55,100
automatically installs a specific

00:24:51,110 --> 00:25:01,400
version of our system on those servers

00:24:55,100 --> 00:25:03,260
and then you can start using it okay it

00:25:01,400 --> 00:25:05,750
is using all of the other parts of that

00:25:03,260 --> 00:25:07,910
devstack did I mention started osmosis

00:25:05,750 --> 00:25:11,510
and solved with an inaugurate ur and

00:25:07,910 --> 00:25:13,400
this is what it looks like this is from

00:25:11,510 --> 00:25:15,500
yesterday during the day when I was

00:25:13,400 --> 00:25:18,710
preparing these slides what we're seeing

00:25:15,500 --> 00:25:20,660
here is that we have five racks in the

00:25:18,710 --> 00:25:23,840
system right now each rack has

00:25:20,660 --> 00:25:27,020
approximately 64 servers if you recall

00:25:23,840 --> 00:25:29,360
correctly so this is 300 some servers at

00:25:27,020 --> 00:25:31,640
this point we've times 73 of them are

00:25:29,360 --> 00:25:34,220
actually free the rest of them are

00:25:31,640 --> 00:25:35,470
allocated for various purposes mostly

00:25:34,220 --> 00:25:38,330
running tests

00:25:35,470 --> 00:25:40,429
okay of course there is a way to look

00:25:38,330 --> 00:25:44,629
into the systems see what's going on

00:25:40,429 --> 00:25:47,149
debug them etc but the cool bits here

00:25:44,629 --> 00:25:50,090
are that you just run a command line and

00:25:47,149 --> 00:25:52,480
you get an allocation of as many servers

00:25:50,090 --> 00:25:55,399
as you need

00:25:52,480 --> 00:25:58,429
for example this job which is one of our

00:25:55,399 --> 00:26:00,950
CI jobs we're seeing here again sorry

00:25:58,429 --> 00:26:02,570
this is a bit small or saying here that

00:26:00,950 --> 00:26:05,690
it has a bunch of different servers

00:26:02,570 --> 00:26:10,960
these 8 servers these are their IPs you

00:26:05,690 --> 00:26:10,960
can log into them etc yes

00:26:16,760 --> 00:26:22,950
excellent question so for a networking

00:26:20,270 --> 00:26:26,580
no we do not assume a flat networking

00:26:22,950 --> 00:26:29,490
space our system also has a networking

00:26:26,580 --> 00:26:31,230
component which means we expect virtual

00:26:29,490 --> 00:26:35,190
machines and containers to be running in

00:26:31,230 --> 00:26:38,370
their own networks we have the necessary

00:26:35,190 --> 00:26:40,620
bits in raccattack to give each of these

00:26:38,370 --> 00:26:43,549
environments its own isolated network

00:26:40,620 --> 00:26:45,780
environment so that you can run

00:26:43,549 --> 00:26:49,620
networking related functionality on it

00:26:45,780 --> 00:26:51,690
with regards to storage our system comes

00:26:49,620 --> 00:26:54,410
with a built-in distributed storage

00:26:51,690 --> 00:26:59,549
layer which is what most of these uses

00:26:54,410 --> 00:27:03,870
and then each of the serve sorry each of

00:26:59,549 --> 00:27:05,910
the disks or SSDs on the machines you

00:27:03,870 --> 00:27:08,370
have been allocated is for your user

00:27:05,910 --> 00:27:10,620
storage subsystem runs on them and makes

00:27:08,370 --> 00:27:12,480
of the storage space available to the

00:27:10,620 --> 00:27:17,240
rest of the cluster just like it would

00:27:12,480 --> 00:27:21,799
in the field other questions feel free

00:27:17,240 --> 00:27:21,799
yes so we do just a second

00:27:23,170 --> 00:27:28,870
there is some similarity with with

00:27:25,840 --> 00:27:31,450
methyl messes with kubernetes with nomad

00:27:28,870 --> 00:27:33,190
i could explain the differences on why

00:27:31,450 --> 00:27:35,500
were much better but then i would be

00:27:33,190 --> 00:27:38,370
virgin game to product speech category

00:27:35,500 --> 00:27:41,490
so let's talk about that outside okay

00:27:38,370 --> 00:27:51,640
you wanted to ask something else though

00:27:41,490 --> 00:27:53,530
yeah okay so first of all yes in the

00:27:51,640 --> 00:27:56,560
version that we've just released we're

00:27:53,530 --> 00:27:58,750
relying on VLANs physical villains the

00:27:56,560 --> 00:28:02,260
next version will support VX lon and

00:27:58,750 --> 00:28:04,180
others such encapsulation protocols env

00:28:02,260 --> 00:28:09,490
GRE etc we can talk about this more

00:28:04,180 --> 00:28:13,290
later okay so are we good we're at the

00:28:09,490 --> 00:28:16,090
scale of 50-plus developers right now

00:28:13,290 --> 00:28:19,390
we've we have really fast

00:28:16,090 --> 00:28:22,510
develop test deploy on a real cluster

00:28:19,390 --> 00:28:25,750
run debug etcetera cycles on the order

00:28:22,510 --> 00:28:28,750
of minutes we can provision bare metal

00:28:25,750 --> 00:28:31,660
and virtual test environments very

00:28:28,750 --> 00:28:34,540
quickly developers get rapid test

00:28:31,660 --> 00:28:36,550
feedback that's pretty awesome and we

00:28:34,540 --> 00:28:40,090
have a bunch of automated tools for

00:28:36,550 --> 00:28:42,310
developing testing operating systems and

00:28:40,090 --> 00:28:45,280
of course importantly a lot of this is

00:28:42,310 --> 00:28:49,240
running on our own systems so that it's

00:28:45,280 --> 00:28:53,620
all good right no because it's a long

00:28:49,240 --> 00:28:56,380
road to scaling a product in a company

00:28:53,620 --> 00:28:59,380
such as ours what we have right now

00:28:56,380 --> 00:29:02,560
works pretty well for 50 50 something

00:28:59,380 --> 00:29:05,260
developers but we're actually aiming at

00:29:02,560 --> 00:29:05,980
a two orders of magnitude increasing

00:29:05,260 --> 00:29:10,060
scaling

00:29:05,980 --> 00:29:15,000
why two orders were aiming for 200 plus

00:29:10,060 --> 00:29:19,540
developers in the next in the near term

00:29:15,000 --> 00:29:22,330
as I mentioned our next release will

00:29:19,540 --> 00:29:24,400
support up to 1,000 nodes that's a lot

00:29:22,330 --> 00:29:27,220
of developers running a lot of big

00:29:24,400 --> 00:29:30,840
clusters so that's a challenge how do we

00:29:27,220 --> 00:29:30,840
support that without

00:29:31,210 --> 00:29:34,809
hold on a second

00:29:37,820 --> 00:29:41,260
I think I lost a slide

00:29:41,560 --> 00:29:45,910
okay this is actually one of our racks

00:29:44,380 --> 00:29:49,170
in our data center okay

00:29:45,910 --> 00:29:56,010
we have several of these how do we grow

00:29:49,170 --> 00:29:57,760
two to two

00:29:56,010 --> 00:29:59,740
okay I'm going in the wrong direction

00:29:57,760 --> 00:30:03,340
that's what I'm not finding the slide

00:29:59,740 --> 00:30:07,000
that I want so how do we grow it to this

00:30:03,340 --> 00:30:08,920
scale without you know becoming a large

00:30:07,000 --> 00:30:12,550
data center operator which is not the

00:30:08,920 --> 00:30:16,180
business that were in it's a question

00:30:12,550 --> 00:30:18,010
that we're thinking about a lot we need

00:30:16,180 --> 00:30:19,870
better API definitions between

00:30:18,010 --> 00:30:21,670
components as the system grows it

00:30:19,870 --> 00:30:23,440
becomes more and more important to have

00:30:21,670 --> 00:30:27,070
well-defined api's and boundaries

00:30:23,440 --> 00:30:30,610
between different components were very

00:30:27,070 --> 00:30:32,850
very focused on testing I like to say if

00:30:30,610 --> 00:30:36,070
it's not tested it's broken

00:30:32,850 --> 00:30:38,740
okay it's that simple someone comes to

00:30:36,070 --> 00:30:40,420
me says it works I'm asking is it tested

00:30:38,740 --> 00:30:42,670
if it's not tested it's broken I don't

00:30:40,420 --> 00:30:47,650
care you know how much you think that it

00:30:42,670 --> 00:30:49,750
works even when it's tested if the

00:30:47,650 --> 00:30:52,000
cupboards not is not high enough if you

00:30:49,750 --> 00:30:53,980
didn't cover off the test all of the

00:30:52,000 --> 00:30:57,300
interesting cases that you could run

00:30:53,980 --> 00:30:59,650
into we talked about tools like it like

00:30:57,300 --> 00:31:02,430
Justin or Jepsen I don't remember

00:30:59,650 --> 00:31:04,540
exactly the name in the previous talk

00:31:02,430 --> 00:31:07,270
it's really easy to break stuff

00:31:04,540 --> 00:31:12,310
unfortunately even without trying very

00:31:07,270 --> 00:31:14,290
hard we need as the development

00:31:12,310 --> 00:31:17,920
organization grows you need better best

00:31:14,290 --> 00:31:20,140
practices you have a lot of talented

00:31:17,920 --> 00:31:22,180
people but there are not all talented in

00:31:20,140 --> 00:31:25,420
the same things so how do you make all

00:31:22,180 --> 00:31:27,760
of them really good it's what you need

00:31:25,420 --> 00:31:31,720
them to do we need even more continuous

00:31:27,760 --> 00:31:34,150
integration and delivery in particular

00:31:31,720 --> 00:31:35,920
and I'm sort of mixing here on internal

00:31:34,150 --> 00:31:40,930
environments and what our product does

00:31:35,920 --> 00:31:45,070
but we would like to be able to

00:31:40,930 --> 00:31:48,040
continuously update our cloud just like

00:31:45,070 --> 00:31:50,290
you expect from public clouds but our

00:31:48,040 --> 00:31:53,770
clouds run on the customers premise

00:31:50,290 --> 00:31:57,910
okay we have limited access there are

00:31:53,770 --> 00:31:59,560
different expectations how do you how do

00:31:57,910 --> 00:32:01,210
you do that that's a challenge that

00:31:59,560 --> 00:32:03,580
we're looking into and of course the

00:32:01,210 --> 00:32:05,710
whole concept of serviceability both for

00:32:03,580 --> 00:32:08,860
internal systems and for the systems

00:32:05,710 --> 00:32:12,580
that were selling that's an ongoing

00:32:08,860 --> 00:32:14,980
effort so these are just some of the

00:32:12,580 --> 00:32:18,970
challenges that we have and in

00:32:14,980 --> 00:32:21,550
conclusion scaling gap is hard to do but

00:32:18,970 --> 00:32:23,620
it's a great sense of accomplishment

00:32:21,550 --> 00:32:25,810
if you succeed and then you move on to

00:32:23,620 --> 00:32:28,000
the next problem we've found in our

00:32:25,810 --> 00:32:29,950
personal experience that different

00:32:28,000 --> 00:32:33,340
approaches work best for different

00:32:29,950 --> 00:32:35,410
stages of growth you don't do the same

00:32:33,340 --> 00:32:38,400
thing for one developer as you do for

00:32:35,410 --> 00:32:41,680
ten or for 100 it's pretty obvious but

00:32:38,400 --> 00:32:45,220
there is a strong tendency to just go

00:32:41,680 --> 00:32:46,450
with with what you've got but it's not

00:32:45,220 --> 00:32:49,840
the right thing to do you need to

00:32:46,450 --> 00:32:53,710
continuously invest testing is crucial

00:32:49,840 --> 00:32:56,170
and I hope I've shown to some small

00:32:53,710 --> 00:32:59,290
extent the DevOps it's not just for web

00:32:56,170 --> 00:33:03,330
apps okay you can apply the concepts of

00:32:59,290 --> 00:33:06,840
DevOps in many many different areas so

00:33:03,330 --> 00:33:06,840
thank you very much

00:33:11,650 --> 00:33:16,460
thank you very much in case it wasn't

00:33:14,000 --> 00:33:18,290
obvious we're hiring and you're more

00:33:16,460 --> 00:33:22,340
than welcome to come and talk to me or

00:33:18,290 --> 00:33:23,840
Pavel or wrote them outside at our table

00:33:22,340 --> 00:33:31,580
and with that I'm happy to take any

00:33:23,840 --> 00:33:34,850
questions that you guys have excellent

00:33:31,580 --> 00:33:37,490
question so we did it defers between

00:33:34,850 --> 00:33:41,000
unit testing for example where coverage

00:33:37,490 --> 00:33:43,309
might be lines of code obviously but for

00:33:41,000 --> 00:33:45,200
system testing for example taking the

00:33:43,309 --> 00:33:49,340
other side of the spectrum we try to

00:33:45,200 --> 00:33:52,280
define as many different scenarios as we

00:33:49,340 --> 00:33:54,380
think are interesting and then we pick

00:33:52,280 --> 00:33:57,140
which ones we cover the most important

00:33:54,380 --> 00:33:58,880
ones and having done that we know that

00:33:57,140 --> 00:34:02,929
we haven't covered nearly as much as we

00:33:58,880 --> 00:34:04,640
think we have okay there are as I

00:34:02,929 --> 00:34:06,440
mentioned in a previous life I used to

00:34:04,640 --> 00:34:09,320
work at IBM Research we had a whole

00:34:06,440 --> 00:34:11,980
department looking from an academic

00:34:09,320 --> 00:34:16,550
perspective at that particular question

00:34:11,980 --> 00:34:19,550
how do you define coverage how do you in

00:34:16,550 --> 00:34:21,790
a bounded effort okay I have this many

00:34:19,550 --> 00:34:25,879
CPU cycles I have this many man-hours

00:34:21,790 --> 00:34:29,750
how do I not just increase my coverage

00:34:25,879 --> 00:34:32,960
but get the best coverage and it's an

00:34:29,750 --> 00:34:35,919
open question so like I expect most of

00:34:32,960 --> 00:34:38,750
you guys we're aware of what's the

00:34:35,919 --> 00:34:45,250
what's the state of the art and then we

00:34:38,750 --> 00:34:45,250
do what we can any other questions yes

00:34:49,810 --> 00:34:55,820
okay so different approaches for

00:34:53,090 --> 00:34:58,790
different growth stages when we had our

00:34:55,820 --> 00:35:01,730
own CI system we actually had when a

00:34:58,790 --> 00:35:04,160
test failed run it five times if four of

00:35:01,730 --> 00:35:06,200
them pass and one fail call that a pass

00:35:04,160 --> 00:35:08,270
because maybe there were timing issues

00:35:06,200 --> 00:35:10,010
maybe there was a network bleed maybe

00:35:08,270 --> 00:35:14,300
the nested virtualization screwed us up

00:35:10,010 --> 00:35:16,760
whatever okay now when the company has

00:35:14,300 --> 00:35:19,670
grown in our environment is much better

00:35:16,760 --> 00:35:21,860
and much more stable if it fails and

00:35:19,670 --> 00:35:23,900
it's probably the system's fault not the

00:35:21,860 --> 00:35:26,810
tests or the environments problem so we

00:35:23,900 --> 00:35:29,720
don't rerun it again the developer gets

00:35:26,810 --> 00:35:31,910
some sort of feedback hey your test

00:35:29,720 --> 00:35:34,100
failed and then it will just run again

00:35:31,910 --> 00:35:36,020
in the next cycle and we'll see and we

00:35:34,100 --> 00:35:38,990
of course track this so that we say

00:35:36,020 --> 00:35:41,030
which tests have sporadic failures if it

00:35:38,990 --> 00:35:43,760
has this failing constantly we either

00:35:41,030 --> 00:35:45,170
take it out or fix it obviously take it

00:35:43,760 --> 00:35:49,990
off it's no longer relevant that

00:35:45,170 --> 00:35:49,990
happened a few times yes

00:36:00,970 --> 00:36:10,960
yes short answer is yes how fast minutes

00:36:06,780 --> 00:36:12,579
minutes yeah by the way if you guys want

00:36:10,960 --> 00:36:14,800
the demo we can try and put one together

00:36:12,579 --> 00:36:16,839
outside with pleasure

00:36:14,800 --> 00:36:18,790
okay we'll break here and I don't want

00:36:16,839 --> 00:36:21,190
to be what's left between you guys and

00:36:18,790 --> 00:36:23,760
lunch so thank you very much and there

00:36:21,190 --> 00:36:23,760

YouTube URL: https://www.youtube.com/watch?v=_lv46rwborc


