Title: Monitoring Unknown Unknowns with AI - Guy Fighel - DevOpsDays Tel Aviv 2017
Publication date: 2017-11-28
Playlist: DevOpsDays Tel Aviv 2017
Description: 
	In this talk, veteran DevOps engineer Guy Fighel dissects a few real world examples where not knowing what you don’t know led to massive outages and service disruptions. He’ll explore how despite the fact that modern DevOps teams have multiple monitoring tools, hundreds of metrics instrumented and are capturing billions of data points…downtime still happens. How about instead of implementing more monitoring, we bring forward a future where DevOps teams can augment their existing tooling with AI and machine learning to draw richer correlations across events, metrics and logs to surface insights about threats to uptime that aren’t even being monitored. Or put another way, how DevOps teams can get closer to a state of “known knowns!”
Captions: 
	00:00:05,150 --> 00:00:09,750
we're going to talk about unknown

00:00:07,230 --> 00:00:11,340
unknowns today and I'm gonna introduce

00:00:09,750 --> 00:00:14,880
myself in a second but I have a question

00:00:11,340 --> 00:00:19,580
for everyone who had a downtime lately

00:00:14,880 --> 00:00:24,330
something cool Wow

00:00:19,580 --> 00:00:27,330
too much downtime so if you think about

00:00:24,330 --> 00:00:30,410
what we are all doing in down times what

00:00:27,330 --> 00:00:36,750
is the first thing come to mind

00:00:30,410 --> 00:00:39,840
wait all right what else why

00:00:36,750 --> 00:00:46,440
so why okay and what is it that was the

00:00:39,840 --> 00:00:49,289
first action that we all do okay all

00:00:46,440 --> 00:00:49,860
right like restarting the data yeah fine

00:00:49,289 --> 00:00:52,680
okay

00:00:49,860 --> 00:00:56,070
so we're going to talk about that in a

00:00:52,680 --> 00:00:59,309
second and we'll see like why like what

00:00:56,070 --> 00:01:01,379
we do just as a first reaction actually

00:00:59,309 --> 00:01:04,170
it's a little bit wrong so we're gonna

00:01:01,379 --> 00:01:08,700
talk about that but who am I so my name

00:01:04,170 --> 00:01:11,460
is guy and I'm kind of a paranoid person

00:01:08,700 --> 00:01:13,650
actually I call myself like an on-call

00:01:11,460 --> 00:01:15,540
engineer by nature because I'm

00:01:13,650 --> 00:01:20,009
constantly looking for what's wrong

00:01:15,540 --> 00:01:23,580
although my background is back in

00:01:20,009 --> 00:01:26,040
engineering and development and then I

00:01:23,580 --> 00:01:28,590
saw a site reliability engineering today

00:01:26,040 --> 00:01:31,740
I'm co-founder and CTO it signify which

00:01:28,590 --> 00:01:34,320
is a company dealing with them making

00:01:31,740 --> 00:01:35,610
sure that people like us are much more

00:01:34,320 --> 00:01:36,900
focused in what's happening in

00:01:35,610 --> 00:01:38,430
production but I'm not going to talk

00:01:36,900 --> 00:01:39,900
about that because it's not a vendor

00:01:38,430 --> 00:01:42,810
pitch and what I'm going to talk about

00:01:39,900 --> 00:01:45,720
is my personal experience and try to

00:01:42,810 --> 00:01:47,460
share how and what we need to start

00:01:45,720 --> 00:01:50,640
thinking about when we want to start

00:01:47,460 --> 00:01:54,149
building an intelligent platform for for

00:01:50,640 --> 00:01:56,579
our monitoring solution that's that's

00:01:54,149 --> 00:01:58,079
what we're going to talk about so you

00:01:56,579 --> 00:01:59,790
know I always have this feeling like

00:01:58,079 --> 00:02:01,710
something is wrong production and I'm

00:01:59,790 --> 00:02:04,920
kind like I don't know what it is but

00:02:01,710 --> 00:02:08,129
something is definitely wrong so it's

00:02:04,920 --> 00:02:10,349
like maybe it's just me I don't know so

00:02:08,129 --> 00:02:12,330
there is this thing called observability

00:02:10,349 --> 00:02:14,730
I'm sure all of you are aware of it's a

00:02:12,330 --> 00:02:17,460
little bit of kind of

00:02:14,730 --> 00:02:20,610
kind of an adaptation to the monitoring

00:02:17,460 --> 00:02:22,620
and I'm kind of like I like it I like

00:02:20,610 --> 00:02:24,870
the definition of observability and what

00:02:22,620 --> 00:02:27,690
it means it's much more advanced than

00:02:24,870 --> 00:02:30,180
just monitoring because with

00:02:27,690 --> 00:02:33,390
observability you know it's it's a

00:02:30,180 --> 00:02:36,090
mixture between monitoring and then

00:02:33,390 --> 00:02:39,270
instrumentation so it gives you much

00:02:36,090 --> 00:02:42,780
more context into what's going on in

00:02:39,270 --> 00:02:44,430
production but I'm like kind of thinking

00:02:42,780 --> 00:02:47,220
about it like do you really know what to

00:02:44,430 --> 00:02:50,730
observe right it's like monitoring right

00:02:47,220 --> 00:02:54,030
and then do you really want to kind of

00:02:50,730 --> 00:02:56,190
enforce all of your developers or ask to

00:02:54,030 --> 00:02:58,560
actually instrument everything in code

00:02:56,190 --> 00:03:01,140
and that's pretty hard to actually

00:02:58,560 --> 00:03:04,020
enforce so the problem with the

00:03:01,140 --> 00:03:05,820
observability is actually the the

00:03:04,020 --> 00:03:07,890
observability that we are all talking

00:03:05,820 --> 00:03:10,110
about it's actually completely not the

00:03:07,890 --> 00:03:13,100
the mathematical definition of

00:03:10,110 --> 00:03:17,700
observability so the mathematical

00:03:13,100 --> 00:03:20,130
definition is that you have to know from

00:03:17,700 --> 00:03:23,010
the output of your system the entire

00:03:20,130 --> 00:03:25,290
situation and then the entire state of

00:03:23,010 --> 00:03:27,750
your system and that's usually what's

00:03:25,290 --> 00:03:29,550
not happening so if you think about it

00:03:27,750 --> 00:03:31,890
usually when we are all looking into our

00:03:29,550 --> 00:03:34,980
monitoring solutions and graphs and

00:03:31,890 --> 00:03:38,670
alerts and states and all of that we are

00:03:34,980 --> 00:03:41,520
trying to guess what is the entire

00:03:38,670 --> 00:03:44,360
system status and we don't really know

00:03:41,520 --> 00:03:46,860
we're trying to figure it out so like

00:03:44,360 --> 00:03:48,630
what I want to claim is actually the way

00:03:46,860 --> 00:03:52,560
we think about observability is

00:03:48,630 --> 00:03:54,630
completely wrong and in order to get

00:03:52,560 --> 00:03:57,090
closer into that definition the

00:03:54,630 --> 00:03:59,940
mathematical definition of observability

00:03:57,090 --> 00:04:03,450
we need to start thinking about it from

00:03:59,940 --> 00:04:05,880
a completely different approach and try

00:04:03,450 --> 00:04:08,550
there are no known knowns there are

00:04:05,880 --> 00:04:10,530
things we know we know we also know

00:04:08,550 --> 00:04:12,330
there are known unknowns that is to say

00:04:10,530 --> 00:04:15,870
we know there's some things we do not

00:04:12,330 --> 00:04:18,609
know but there are also unknown unknowns

00:04:15,870 --> 00:04:21,689
the ones we don't know we don't know

00:04:18,609 --> 00:04:24,250
excuse me but is this an unknown oh

00:04:21,689 --> 00:04:26,500
let's put it into context the unknown

00:04:24,250 --> 00:04:29,289
unknowns and this is based on Johar

00:04:26,500 --> 00:04:31,479
window which is a completely cognitive

00:04:29,289 --> 00:04:33,699
psychology tool to help understand like

00:04:31,479 --> 00:04:36,189
relationship between people but if you

00:04:33,699 --> 00:04:38,229
take that model and you kind of take

00:04:36,189 --> 00:04:40,300
their approach into observability you

00:04:38,229 --> 00:04:41,680
get observability quadrat which is

00:04:40,300 --> 00:04:43,719
something that are completely invented

00:04:41,680 --> 00:04:47,259
and you know maybe it's just

00:04:43,719 --> 00:04:49,180
but it looks make sense basically and on

00:04:47,259 --> 00:04:51,129
the right on the right and left side you

00:04:49,180 --> 00:04:55,050
see like what are the approaches that we

00:04:51,129 --> 00:04:57,550
take and then inside the quadrat you see

00:04:55,050 --> 00:05:00,009
the definitions of the knowns and

00:04:57,550 --> 00:05:03,099
unknowns and the combinations right so

00:05:00,009 --> 00:05:06,340
like let's take some practical examples

00:05:03,099 --> 00:05:08,680
so what is unknown known which is it's

00:05:06,340 --> 00:05:10,449
basically what we all what we're all

00:05:08,680 --> 00:05:13,840
dealing with in productions so you have

00:05:10,449 --> 00:05:16,210
like you know you have a container and

00:05:13,840 --> 00:05:19,090
just got restarted you can go in you can

00:05:16,210 --> 00:05:21,279
basically understand or something is not

00:05:19,090 --> 00:05:24,430
working you go in you you look into that

00:05:21,279 --> 00:05:27,039
process ad you understand it's hang you

00:05:24,430 --> 00:05:30,520
get restarted everything is fine right

00:05:27,039 --> 00:05:32,319
so basically you based on the

00:05:30,520 --> 00:05:34,690
information you know what to do you took

00:05:32,319 --> 00:05:39,250
an action or good so that's an unknown

00:05:34,690 --> 00:05:40,599
an unknown known is something like for

00:05:39,250 --> 00:05:44,050
example you deploy something into

00:05:40,599 --> 00:05:45,909
production and then something is wrong

00:05:44,050 --> 00:05:47,529
but you don't even understand or you

00:05:45,909 --> 00:05:50,020
don't even know it's wrong for example

00:05:47,529 --> 00:05:54,069
you have a tiny little error rate which

00:05:50,020 --> 00:05:56,770
is completely like you know maybe 1/2

00:05:54,069 --> 00:06:00,400
percent that your threshold didn't even

00:05:56,770 --> 00:06:02,229
trigger about so you don't even know

00:06:00,400 --> 00:06:03,819
about it but when you look into the

00:06:02,229 --> 00:06:06,520
error rate and you understand there is a

00:06:03,819 --> 00:06:08,740
small tiny spike you can say oh I

00:06:06,520 --> 00:06:10,659
actually get it there are small error

00:06:08,740 --> 00:06:13,569
rates and this is based on a deployment

00:06:10,659 --> 00:06:15,789
event that just happened so you don't

00:06:13,569 --> 00:06:19,089
know it but once you figure out like

00:06:15,789 --> 00:06:21,339
once you determine the once you see a

00:06:19,089 --> 00:06:23,500
sign then you actually understand that

00:06:21,339 --> 00:06:25,449
and then the others I'm not going to go

00:06:23,500 --> 00:06:27,639
into all of the different examples but

00:06:25,449 --> 00:06:29,440
just I have one single example which

00:06:27,639 --> 00:06:32,470
kind of makes sense if you think about

00:06:29,440 --> 00:06:34,720
it there is a like production system

00:06:32,470 --> 00:06:37,270
you know and it's a mobile application

00:06:34,720 --> 00:06:39,280
and you deploy code then you have mobile

00:06:37,270 --> 00:06:40,900
clients all around the world and then

00:06:39,280 --> 00:06:42,340
your application is working in the u.s.

00:06:40,900 --> 00:06:44,470
everything is cool but then some

00:06:42,340 --> 00:06:46,900
customers in China are telling you hey

00:06:44,470 --> 00:06:48,400
the app is not working like what the

00:06:46,900 --> 00:06:50,530
hell like everything is working

00:06:48,400 --> 00:06:52,990
Marton systems are all cool everything

00:06:50,530 --> 00:06:55,450
is green what's going on you have no

00:06:52,990 --> 00:06:58,930
clue it's a nano then you need to start

00:06:55,450 --> 00:07:01,150
investigate and then suddenly you get

00:06:58,930 --> 00:07:03,580
this notion of hey maybe it's my city

00:07:01,150 --> 00:07:05,440
and provider and then you try to explore

00:07:03,580 --> 00:07:07,390
your city and providers and then they

00:07:05,440 --> 00:07:10,810
are telling you yeah it's all good and

00:07:07,390 --> 00:07:14,230
then actually you figure out that one of

00:07:10,810 --> 00:07:16,570
your engineer heard about firewall

00:07:14,230 --> 00:07:18,160
blockage in China region that now all

00:07:16,570 --> 00:07:20,080
your traffic is getting blocked and

00:07:18,160 --> 00:07:22,300
that's what's causing people in the in

00:07:20,080 --> 00:07:24,400
China not to actually get service from

00:07:22,300 --> 00:07:27,190
your application so completely different

00:07:24,400 --> 00:07:28,540
source I call it the externality has

00:07:27,190 --> 00:07:30,610
nothing to do with your monitoring

00:07:28,540 --> 00:07:33,310
solution everything is green there's no

00:07:30,610 --> 00:07:35,230
way for you to understand this is

00:07:33,310 --> 00:07:37,030
happening impacting your production but

00:07:35,230 --> 00:07:39,520
actually it is so it's completely

00:07:37,030 --> 00:07:41,440
unknown it's very hard to detect but if

00:07:39,520 --> 00:07:43,990
you think about it so now you're

00:07:41,440 --> 00:07:47,290
monitoring infrastructure is it's not

00:07:43,990 --> 00:07:49,330
just your servers and data centers and

00:07:47,290 --> 00:07:52,830
your CDN providers it's like other

00:07:49,330 --> 00:07:57,490
things that can impact your customers

00:07:52,830 --> 00:08:01,510
behaviors or being able to be served

00:07:57,490 --> 00:08:03,550
from your application so let's talk

00:08:01,510 --> 00:08:05,770
about human driven detection and that's

00:08:03,550 --> 00:08:08,440
what we are all doing every single day

00:08:05,770 --> 00:08:11,650
we're trying to detect problems this is

00:08:08,440 --> 00:08:14,650
how we this our thing is that we try to

00:08:11,650 --> 00:08:17,800
identify pattern we use percent eyes we

00:08:14,650 --> 00:08:20,320
use a lot of different tools and that's

00:08:17,800 --> 00:08:24,310
pretty much static so this is pretty

00:08:20,320 --> 00:08:27,700
much things that are biased you know we

00:08:24,310 --> 00:08:30,900
are trying to kind of match patterns in

00:08:27,700 --> 00:08:33,430
our head and that's that's pretty

00:08:30,900 --> 00:08:35,350
limited and there's a great research

00:08:33,430 --> 00:08:37,840
about it I don't know if you guys are

00:08:35,350 --> 00:08:42,160
familiar with it but it's from a

00:08:37,840 --> 00:08:43,990
completely different area which I really

00:08:42,160 --> 00:08:45,860
like to give an example because we are

00:08:43,990 --> 00:08:48,589
all basically if you think about what

00:08:45,860 --> 00:08:51,920
we do we are all experts okay because we

00:08:48,589 --> 00:08:54,829
have that knowledge we can look into

00:08:51,920 --> 00:08:57,769
experts from different area so there was

00:08:54,829 --> 00:09:00,589
a great psychology experiment with

00:08:57,769 --> 00:09:06,410
twenty four ideologies that they were

00:09:00,589 --> 00:09:11,390
given a and kind of a picture a way to

00:09:06,410 --> 00:09:14,839
detect problem in the in in a picture

00:09:11,390 --> 00:09:16,579
and then at the last frame

00:09:14,839 --> 00:09:19,820
they put a guerrilla inside you can see

00:09:16,579 --> 00:09:22,550
the guerrilla right there right and they

00:09:19,820 --> 00:09:25,670
said okay detect like what's wrong in

00:09:22,550 --> 00:09:27,920
those news pictures and you know

00:09:25,670 --> 00:09:30,019
eighty-three percent of them couldn't do

00:09:27,920 --> 00:09:32,120
it like eighty three percent of them

00:09:30,019 --> 00:09:34,430
didn't detect there is a gorilla which

00:09:32,120 --> 00:09:36,709
has nothing to do with with the picture

00:09:34,430 --> 00:09:41,420
and and there is a there is a good

00:09:36,709 --> 00:09:44,060
reason why and the reason is as experts

00:09:41,420 --> 00:09:48,490
we are trying to detect patterns based

00:09:44,060 --> 00:09:50,899
on the last occurrence of what we are

00:09:48,490 --> 00:09:54,589
the pattern that we've detected in the

00:09:50,899 --> 00:10:01,540
past so what happens here is because it

00:09:54,589 --> 00:10:05,510
was multiple pictures multiple screens

00:10:01,540 --> 00:10:08,180
the basically the expert was trying to

00:10:05,510 --> 00:10:10,430
pattern match for the last known picture

00:10:08,180 --> 00:10:11,839
so they didn't detect the gorilla they

00:10:10,430 --> 00:10:14,300
didn't even see that

00:10:11,839 --> 00:10:16,940
although when they were analyzing the

00:10:14,300 --> 00:10:18,980
eyes and the eyes movement they could

00:10:16,940 --> 00:10:21,829
definitely see that the eyes looked at

00:10:18,980 --> 00:10:23,779
the gorilla okay and and why did

00:10:21,829 --> 00:10:26,029
something as we all need to think about

00:10:23,779 --> 00:10:28,519
when we're trying to detect what's wrong

00:10:26,029 --> 00:10:32,600
in our production system because we

00:10:28,519 --> 00:10:35,079
really like those things right we all

00:10:32,600 --> 00:10:39,260
have those things all those graphs

00:10:35,079 --> 00:10:39,709
dashboards the great love it I mean it's

00:10:39,260 --> 00:10:43,220
beautiful

00:10:39,709 --> 00:10:46,880
really but it's almost useless for

00:10:43,220 --> 00:10:50,839
unknowns unknowns why because usually

00:10:46,880 --> 00:10:52,970
those graphs are biased by because we're

00:10:50,839 --> 00:10:56,240
the one to actually create them so we're

00:10:52,970 --> 00:10:58,940
the one to try to figure out what is he

00:10:56,240 --> 00:10:59,750
that I'm gonna that I'm going to need to

00:10:58,940 --> 00:11:02,480
detect

00:10:59,750 --> 00:11:04,449
and then I'm creating a dashboard now

00:11:02,480 --> 00:11:06,970
not to said it's completely useless

00:11:04,449 --> 00:11:10,009
definitely useful I'm using it as well

00:11:06,970 --> 00:11:12,410
but when it comes to things that you

00:11:10,009 --> 00:11:16,730
didn't predict in advance and it's very

00:11:12,410 --> 00:11:19,579
hard you will not find there and and

00:11:16,730 --> 00:11:21,910
that's actually the reason why in the

00:11:19,579 --> 00:11:24,560
previous experiment that I've just shown

00:11:21,910 --> 00:11:26,209
experts couldn't detect the quarry lie

00:11:24,560 --> 00:11:28,670
and if actually it's the same thing if

00:11:26,209 --> 00:11:31,360
you think about it there is a gorilla's

00:11:28,670 --> 00:11:34,009
somewhere in our production system and

00:11:31,360 --> 00:11:35,660
there's no way we're gonna detect it or

00:11:34,009 --> 00:11:37,310
there's a very small percentage we're

00:11:35,660 --> 00:11:39,230
going to detect it and if we will detect

00:11:37,310 --> 00:11:40,970
it it will take a lot of time which we

00:11:39,230 --> 00:11:43,310
actually don't have when we are in a

00:11:40,970 --> 00:11:46,009
downtime situation so we need something

00:11:43,310 --> 00:11:48,170
a little bit different and just to prove

00:11:46,009 --> 00:11:51,050
it like anyone can detect the anomaly

00:11:48,170 --> 00:11:53,029
here right so let's think about it this

00:11:51,050 --> 00:11:56,509
is like this is a production status you

00:11:53,029 --> 00:11:59,300
got your alert your on call and the

00:11:56,509 --> 00:12:00,920
clock is ticking like it's it's very

00:11:59,300 --> 00:12:05,800
hard right and there is a there is a

00:12:00,920 --> 00:12:11,529
reason why it's hard what about now

00:12:05,800 --> 00:12:16,850
right it's pretty obvious so again first

00:12:11,529 --> 00:12:19,870
scale matters okay so now when we shift

00:12:16,850 --> 00:12:25,160
the scale it's obvious to our brain

00:12:19,870 --> 00:12:27,019
before not so much now the bad news is

00:12:25,160 --> 00:12:28,610
that a lot of the downturns and a lot of

00:12:27,019 --> 00:12:31,670
the graphs actually not going to be

00:12:28,610 --> 00:12:33,949
scaled based on what we we can detect

00:12:31,670 --> 00:12:35,600
automatically in our brain so we need to

00:12:33,949 --> 00:12:39,050
actually work very hard in order to do

00:12:35,600 --> 00:12:41,930
that so that's the first thing the the

00:12:39,050 --> 00:12:44,870
second is the stationary noise matters

00:12:41,930 --> 00:12:47,199
right so if it's if it's a noisy signal

00:12:44,870 --> 00:12:51,290
it will be harder for us to detect it

00:12:47,199 --> 00:12:53,589
and then the other is we it's very hard

00:12:51,290 --> 00:12:56,660
for us to do autocorrelation detection

00:12:53,589 --> 00:12:58,819
meaning like we cannot take two signals

00:12:56,660 --> 00:13:01,759
or the same signal and shift it in time

00:12:58,819 --> 00:13:07,000
and then see what are the differences so

00:13:01,759 --> 00:13:10,730
it's pretty much almost impossible so

00:13:07,000 --> 00:13:13,130
luckily there is a there are different

00:13:10,730 --> 00:13:14,960
libraries and options that can

00:13:13,130 --> 00:13:17,210
actually help us with that I'm just

00:13:14,960 --> 00:13:19,190
going I'm just gonna show one of them

00:13:17,210 --> 00:13:24,140
which I pretty pretty much liking it's

00:13:19,190 --> 00:13:26,810
all Python so basically it's a pip

00:13:24,140 --> 00:13:29,450
install nap I type I and scikit-learn

00:13:26,810 --> 00:13:32,290
and just call a pre-processing and then

00:13:29,450 --> 00:13:35,750
you can transform any type of

00:13:32,290 --> 00:13:38,660
information and data into it so in that

00:13:35,750 --> 00:13:41,360
case basically I'm putting like a log

00:13:38,660 --> 00:13:44,570
transformation which scales the entire

00:13:41,360 --> 00:13:47,870
signal and then it's a much easier to

00:13:44,570 --> 00:13:50,210
detect so if you start to think about

00:13:47,870 --> 00:13:52,610
how can I use like automation and

00:13:50,210 --> 00:13:55,820
statistical analysis and and different

00:13:52,610 --> 00:13:59,870
types of libraries to do that work for

00:13:55,820 --> 00:14:02,390
me now my brain is much more relevant in

00:13:59,870 --> 00:14:05,240
terms of automation detection and

00:14:02,390 --> 00:14:08,930
analysis on a much clearer signal in

00:14:05,240 --> 00:14:12,080
data so that's that's one example of how

00:14:08,930 --> 00:14:15,350
how when you start to understand what

00:14:12,080 --> 00:14:19,460
are our capabilities we can automate our

00:14:15,350 --> 00:14:24,100
way through the other example I really

00:14:19,460 --> 00:14:26,690
like to use is ICA which is basically

00:14:24,100 --> 00:14:30,370
independent component analysis and it

00:14:26,690 --> 00:14:33,500
splits between multi variant signals

00:14:30,370 --> 00:14:35,540
into sub components so if you have a

00:14:33,500 --> 00:14:38,090
very noisy signal and if you have

00:14:35,540 --> 00:14:40,850
multiple of them so think about IO and

00:14:38,090 --> 00:14:42,740
CPU and memory may be networking and

00:14:40,850 --> 00:14:45,440
they're all kind of cross together and

00:14:42,740 --> 00:14:47,570
you really want to start to separate

00:14:45,440 --> 00:14:50,060
between them and then run on top of that

00:14:47,570 --> 00:14:53,600
correlation analysis you can start doing

00:14:50,060 --> 00:14:58,100
that by again just call this function

00:14:53,600 --> 00:15:00,170
same library it I will not lie to you it

00:14:58,100 --> 00:15:02,840
will you will need to work a little bit

00:15:00,170 --> 00:15:05,750
to get it really split and there are

00:15:02,840 --> 00:15:07,340
multiple parameters but it's a great way

00:15:05,750 --> 00:15:10,160
of actually start looking into

00:15:07,340 --> 00:15:12,860
automation of your multiple streams of

00:15:10,160 --> 00:15:16,000
signals now again dashboards are good

00:15:12,860 --> 00:15:19,040
but if you take the data and you start

00:15:16,000 --> 00:15:21,200
pushing the data points into for example

00:15:19,040 --> 00:15:23,060
such a library and there are multiple

00:15:21,200 --> 00:15:26,180
adders and there multiple ways of doing

00:15:23,060 --> 00:15:26,720
it now you can actually get much more

00:15:26,180 --> 00:15:30,259
meaningful

00:15:26,720 --> 00:15:32,149
information and create your graphs out

00:15:30,259 --> 00:15:35,269
of them and then it's much easier to

00:15:32,149 --> 00:15:37,129
detect if you want to detect it as as a

00:15:35,269 --> 00:15:39,110
human and again my entire talk is not

00:15:37,129 --> 00:15:42,230
about replacing the humans with machines

00:15:39,110 --> 00:15:44,689
it's actually enhancing our capabilities

00:15:42,230 --> 00:15:47,959
at the end I truly believe that there's

00:15:44,689 --> 00:15:49,250
no way to replace us we know the we are

00:15:47,959 --> 00:15:52,610
the experts we know the production

00:15:49,250 --> 00:15:54,379
environment the best so we just need a

00:15:52,610 --> 00:15:58,370
little bit more automation a little bit

00:15:54,379 --> 00:16:00,649
more help other example that I like to

00:15:58,370 --> 00:16:03,800
give is like you know there's that

00:16:00,649 --> 00:16:06,350
there's a CPU spike here and let's let's

00:16:03,800 --> 00:16:08,800
find a problem right where is where is

00:16:06,350 --> 00:16:12,439
it on the on the graph

00:16:08,800 --> 00:16:14,269
someone can detect it pretty obvious

00:16:12,439 --> 00:16:15,889
right yeah it's nothing it's not a

00:16:14,269 --> 00:16:18,050
tricky question it's pretty obvious so

00:16:15,889 --> 00:16:20,209
for all of us you know

00:16:18,050 --> 00:16:25,430
here's there is some kind of an anomaly

00:16:20,209 --> 00:16:27,920
here it was pretty easy to detect but

00:16:25,430 --> 00:16:31,120
what if I would tell you that that

00:16:27,920 --> 00:16:36,470
specific time there was a change in

00:16:31,120 --> 00:16:38,420
instance type from big in sense from

00:16:36,470 --> 00:16:42,079
small to big or the other way around

00:16:38,420 --> 00:16:46,309
right depending on the graph is it

00:16:42,079 --> 00:16:49,100
normally now no okay so what does it

00:16:46,309 --> 00:16:53,149
tells us basically context and events

00:16:49,100 --> 00:16:54,680
really matters really helpful so when

00:16:53,149 --> 00:16:57,860
you start to think about it

00:16:54,680 --> 00:17:00,709
add context to your events to your

00:16:57,860 --> 00:17:03,189
telemetry to everything and it's super

00:17:00,709 --> 00:17:05,600
helpful without the context without

00:17:03,189 --> 00:17:08,750
enriching with multiple different types

00:17:05,600 --> 00:17:12,140
of events matrix and dilemma trees are

00:17:08,750 --> 00:17:14,120
actually useless especially when it

00:17:12,140 --> 00:17:17,809
comes to automation and detection you

00:17:14,120 --> 00:17:19,939
want to enrich it with a lot of data now

00:17:17,809 --> 00:17:22,309
there are some problems with a lot of

00:17:19,939 --> 00:17:24,490
data you need to analyze them fast but

00:17:22,309 --> 00:17:28,520
that's exactly what machines are good at

00:17:24,490 --> 00:17:31,340
so so what machine can do actually they

00:17:28,520 --> 00:17:34,450
can really handle a lot of information

00:17:31,340 --> 00:17:38,059
process them really fast and reach them

00:17:34,450 --> 00:17:39,920
adapt an automaton normally detection

00:17:38,059 --> 00:17:42,560
when you gave the model

00:17:39,920 --> 00:17:43,610
it's up to you to give it then I can

00:17:42,560 --> 00:17:46,700
actually adapt automatically

00:17:43,610 --> 00:17:48,920
automatically they can't they are pretty

00:17:46,700 --> 00:17:51,350
good at autocorrelation models so they

00:17:48,920 --> 00:17:55,940
can actually run signal shifts for you

00:17:51,350 --> 00:17:59,720
when you automate it and it's definitely

00:17:55,940 --> 00:18:02,030
much better to adopt over time weed user

00:17:59,720 --> 00:18:05,030
interaction so again not taking the

00:18:02,030 --> 00:18:08,150
human out of the equation but having you

00:18:05,030 --> 00:18:10,250
know all of us trying to inform the

00:18:08,150 --> 00:18:12,020
machine whether it it was doing

00:18:10,250 --> 00:18:13,460
something good or bad so we call it

00:18:12,020 --> 00:18:20,200
supervised learning we'll talk about it

00:18:13,460 --> 00:18:24,200
in a second so what is the goal the goal

00:18:20,200 --> 00:18:25,880
the way I see it is centralization okay

00:18:24,200 --> 00:18:27,620
because what's happening right now

00:18:25,880 --> 00:18:29,000
usually in typical and production

00:18:27,620 --> 00:18:30,620
environment you have different types of

00:18:29,000 --> 00:18:32,780
systems Sam

00:18:30,620 --> 00:18:36,320
monitors data points some alerts some

00:18:32,780 --> 00:18:39,290
events and there are a lot of data so

00:18:36,320 --> 00:18:40,880
the first thing that I really we we all

00:18:39,290 --> 00:18:42,980
need to think about is how can we

00:18:40,880 --> 00:18:45,500
centralize all of the data bring it all

00:18:42,980 --> 00:18:48,800
into a different into a single source of

00:18:45,500 --> 00:18:51,710
truth to be able to analyze it and reach

00:18:48,800 --> 00:18:53,930
it and then create the models and create

00:18:51,710 --> 00:18:56,450
and use all the different libraries that

00:18:53,930 --> 00:19:00,080
I just show a couple of examples on top

00:18:56,450 --> 00:19:03,020
of the data when we have sparse data

00:19:00,080 --> 00:19:07,360
sources there's no way for for us to

00:19:03,020 --> 00:19:13,000
automate it it will be very very hard so

00:19:07,360 --> 00:19:16,130
use basically a lot of events in

00:19:13,000 --> 00:19:18,200
symptoms detection for inference it

00:19:16,130 --> 00:19:21,800
helps a lot and what that means is that

00:19:18,200 --> 00:19:23,600
again events can be deployment event and

00:19:21,800 --> 00:19:26,270
it's not just gonna be like okay

00:19:23,600 --> 00:19:28,430
deployment event happened it would be

00:19:26,270 --> 00:19:30,980
like what is for example what is the

00:19:28,430 --> 00:19:33,560
repo who is the who is a committer

00:19:30,980 --> 00:19:35,600
what are the changes all of that can

00:19:33,560 --> 00:19:37,940
come with the same event so now you have

00:19:35,600 --> 00:19:43,580
context so now you can start to infer

00:19:37,940 --> 00:19:46,550
logic around so it's really important

00:19:43,580 --> 00:19:48,770
and when we think about events and start

00:19:46,550 --> 00:19:51,260
to centralize all of them it's really

00:19:48,770 --> 00:19:53,000
important to actually add those events

00:19:51,260 --> 00:19:53,810
into the metrics themselves so if you

00:19:53,000 --> 00:19:58,280
get like

00:19:53,810 --> 00:20:00,230
CPU and now the CPUs like 80% with

00:19:58,280 --> 00:20:05,090
events and central and centralization

00:20:00,230 --> 00:20:07,970
will be 80% and decipi the the instance

00:20:05,090 --> 00:20:11,450
type and the machine or and the for

00:20:07,970 --> 00:20:13,430
example the availability zone and was

00:20:11,450 --> 00:20:16,220
there a deployment event or not related

00:20:13,430 --> 00:20:18,520
to at the same time so all of that comes

00:20:16,220 --> 00:20:21,850
with the metric and now it's pretty

00:20:18,520 --> 00:20:24,680
pretty easy to extract that information

00:20:21,850 --> 00:20:26,540
use a lot of different tools and there

00:20:24,680 --> 00:20:28,670
are different tools to help with

00:20:26,540 --> 00:20:30,530
automation related to machine

00:20:28,670 --> 00:20:32,030
intelligence and there are a couple of

00:20:30,530 --> 00:20:35,000
them there I want to kind of highlight

00:20:32,030 --> 00:20:36,380
so all of those tools are Python based

00:20:35,000 --> 00:20:39,770
and there is a reason why I'm using

00:20:36,380 --> 00:20:43,010
Python because most of us probably used

00:20:39,770 --> 00:20:44,930
to the language so from PI torch which

00:20:43,010 --> 00:20:49,610
is a great open source like deep

00:20:44,930 --> 00:20:50,570
learning library created by Facebook or

00:20:49,610 --> 00:20:53,830
Tiano

00:20:50,570 --> 00:20:57,080
or the entire scikit-learn package

00:20:53,830 --> 00:21:00,410
Chara's which is a great high layer API

00:20:57,080 --> 00:21:02,960
for deep learning and classifications

00:21:00,410 --> 00:21:05,900
and there are actually not that

00:21:02,960 --> 00:21:07,580
complicated to start get going so you do

00:21:05,900 --> 00:21:10,430
need to understand the theory behind it

00:21:07,580 --> 00:21:13,250
a little bit but you don't need to kind

00:21:10,430 --> 00:21:15,280
of create the entire code base and you

00:21:13,250 --> 00:21:18,380
can actually operate in a higher

00:21:15,280 --> 00:21:19,970
abstraction level the other thing that I

00:21:18,380 --> 00:21:23,000
want to point out I don't know if you

00:21:19,970 --> 00:21:25,850
guys can see that it's as frames it's a

00:21:23,000 --> 00:21:28,580
great library that I really like very

00:21:25,850 --> 00:21:32,690
similar to data frame which basically

00:21:28,580 --> 00:21:35,630
allows you to work with data set and

00:21:32,690 --> 00:21:37,850
large data set and as opposed to data

00:21:35,630 --> 00:21:40,130
frame in any cell in Python as opposed

00:21:37,850 --> 00:21:42,170
to data frame that you can just work

00:21:40,130 --> 00:21:44,990
with the amount of memory that you have

00:21:42,170 --> 00:21:47,300
as frame actually persists to disk so if

00:21:44,990 --> 00:21:49,160
you have SSD and you have enough memory

00:21:47,300 --> 00:21:52,640
and disk you can actually load and

00:21:49,160 --> 00:21:55,730
manipulate a lot of data right there and

00:21:52,640 --> 00:21:58,670
it's great library check it out you can

00:21:55,730 --> 00:22:01,490
actually operate with a sequel like kind

00:21:58,670 --> 00:22:05,150
of language in Python the pythonic way

00:22:01,490 --> 00:22:06,680
of sequel on top of it you can do time

00:22:05,150 --> 00:22:10,120
shifts you can do a lot of turns

00:22:06,680 --> 00:22:12,620
nation is great so combine that with

00:22:10,120 --> 00:22:14,300
different types of libraries actually

00:22:12,620 --> 00:22:16,760
makes your life easier

00:22:14,300 --> 00:22:20,090
stan is another one which most of the

00:22:16,760 --> 00:22:23,780
people are not used to

00:22:20,090 --> 00:22:27,440
it's a probabilistic approach and model

00:22:23,780 --> 00:22:30,800
type library which is really super cool

00:22:27,440 --> 00:22:32,570
and great especially for for the

00:22:30,800 --> 00:22:35,060
unknowns if you think about it you want

00:22:32,570 --> 00:22:36,710
to create like probabilities and being

00:22:35,060 --> 00:22:39,500
able to enrich probabilities based on

00:22:36,710 --> 00:22:41,270
user interaction so I can say oh here's

00:22:39,500 --> 00:22:43,310
the probability that something happened

00:22:41,270 --> 00:22:45,440
in the past what is the probability the

00:22:43,310 --> 00:22:47,450
same thing will happen in the future or

00:22:45,440 --> 00:22:49,850
similar things so Stan allows you to

00:22:47,450 --> 00:22:52,040
actually create those models Markov

00:22:49,850 --> 00:22:53,840
chains and other and other mathematical

00:22:52,040 --> 00:22:58,120
approaches there as well

00:22:53,840 --> 00:22:58,120
that's another another thing that I like

00:22:58,390 --> 00:23:02,840
so when we centralize all of the

00:23:00,920 --> 00:23:06,490
information into a single place it is

00:23:02,840 --> 00:23:08,830
crucial to actually have a schema a

00:23:06,490 --> 00:23:11,420
centralized schema behind it I

00:23:08,830 --> 00:23:12,980
personally like Apache Avro but there

00:23:11,420 --> 00:23:15,110
are multiple schemas it doesn't really

00:23:12,980 --> 00:23:17,480
matter as long as you use one why

00:23:15,110 --> 00:23:20,290
because then when all of your metrics

00:23:17,480 --> 00:23:23,390
and events and logs are all the same

00:23:20,290 --> 00:23:25,430
platform they're all the same schema you

00:23:23,390 --> 00:23:28,870
can actually put all of the learning

00:23:25,430 --> 00:23:32,800
models on top and you have a unified

00:23:28,870 --> 00:23:34,700
kind of a data layer to work with I

00:23:32,800 --> 00:23:38,240
already think that event should be

00:23:34,700 --> 00:23:40,880
agnostic so start to think about your

00:23:38,240 --> 00:23:43,850
logs as events and not just as logs

00:23:40,880 --> 00:23:46,610
start to think about your events as

00:23:43,850 --> 00:23:49,550
events and data points as well so it can

00:23:46,610 --> 00:23:52,640
be like a user action a click can be an

00:23:49,550 --> 00:23:55,460
event and metric can be an event log can

00:23:52,640 --> 00:23:59,600
actually be transformed into a structure

00:23:55,460 --> 00:24:01,280
log and be an event so when you start to

00:23:59,600 --> 00:24:03,260
actually centralize all those different

00:24:01,280 --> 00:24:05,180
data sources into a single schema and

00:24:03,260 --> 00:24:07,310
then on top of them you start to build

00:24:05,180 --> 00:24:11,270
your models using s frame using

00:24:07,310 --> 00:24:12,800
something like Kara's actually you have

00:24:11,270 --> 00:24:16,940
all of the data right there and you can

00:24:12,800 --> 00:24:20,180
start automating it some of the best

00:24:16,940 --> 00:24:23,060
practices from experience is like

00:24:20,180 --> 00:24:25,700
don't start with deep learning it will

00:24:23,060 --> 00:24:28,840
not work don't start with something

00:24:25,700 --> 00:24:31,640
super complex because it will take time

00:24:28,840 --> 00:24:34,640
so start with a simple thing like fuzzy

00:24:31,640 --> 00:24:36,770
logic work works great especially with

00:24:34,640 --> 00:24:39,080
the single data source you can start

00:24:36,770 --> 00:24:41,150
create your logic in your head and

00:24:39,080 --> 00:24:45,350
actually automate it with fuzzy logic so

00:24:41,150 --> 00:24:48,140
fuzzy logic fuzzy logic is very similar

00:24:45,350 --> 00:24:51,950
to like if-else rule sets but the model

00:24:48,140 --> 00:24:54,140
can adapt rules the same so if you think

00:24:51,950 --> 00:24:56,600
about okay I don't know exactly what

00:24:54,140 --> 00:24:58,970
will happen and I'm not I'm not trying

00:24:56,600 --> 00:25:00,950
to predict the unknown but hey I know

00:24:58,970 --> 00:25:02,750
that if something here is bad and

00:25:00,950 --> 00:25:03,680
something there happened I don't know if

00:25:02,750 --> 00:25:05,540
it's better or not

00:25:03,680 --> 00:25:08,120
then I'm going to do something about it

00:25:05,540 --> 00:25:09,890
so that kind of logic that is coming

00:25:08,120 --> 00:25:13,220
from the expert from the operator can

00:25:09,890 --> 00:25:15,770
actually be encoded and automated into

00:25:13,220 --> 00:25:18,530
your monitoring system or the new kind

00:25:15,770 --> 00:25:22,520
of intelligent monitoring system based

00:25:18,530 --> 00:25:25,070
on all of your existing sources so

00:25:22,520 --> 00:25:27,200
choose the logic run it across the data

00:25:25,070 --> 00:25:29,240
not just on a single data source because

00:25:27,200 --> 00:25:33,440
you need a context and that's based on

00:25:29,240 --> 00:25:35,990
the schema really helpfully similarity

00:25:33,440 --> 00:25:38,030
checks so if you think about it now when

00:25:35,990 --> 00:25:39,890
you have events now you have semantics

00:25:38,030 --> 00:25:44,000
so it's not just the data point it's not

00:25:39,890 --> 00:25:46,520
just a t30 1 2 etc but you have some

00:25:44,000 --> 00:25:49,960
kind of structure logs or you have

00:25:46,520 --> 00:25:53,570
deployment happens so you can start

00:25:49,960 --> 00:25:55,880
responding to those semantics analyzing

00:25:53,570 --> 00:26:00,190
them start to find similarity matches

00:25:55,880 --> 00:26:02,420
start to find existence existent of

00:26:00,190 --> 00:26:04,550
terms and there are a couple of

00:26:02,420 --> 00:26:08,270
algorithms that actually works really

00:26:04,550 --> 00:26:11,210
well so tf-idf is one being 25 is

00:26:08,270 --> 00:26:12,950
another one fuzzy of course and there

00:26:11,210 --> 00:26:17,540
are other classifiers that you can run

00:26:12,950 --> 00:26:21,530
on top of your streams correlations so

00:26:17,540 --> 00:26:22,850
correlations pretty fun topic but there

00:26:21,530 --> 00:26:24,800
are two different types of correlations

00:26:22,850 --> 00:26:27,020
one semantic correlations that now

00:26:24,800 --> 00:26:29,930
actually you can start to work operating

00:26:27,020 --> 00:26:32,840
on your strings and strings themselves

00:26:29,930 --> 00:26:34,559
and also autocorrelation on streams of

00:26:32,840 --> 00:26:36,239
data

00:26:34,559 --> 00:26:39,720
and now you can actually do it

00:26:36,239 --> 00:26:41,729
automatically so multiple stream of data

00:26:39,720 --> 00:26:43,679
points run autocorrelation with

00:26:41,729 --> 00:26:44,999
something like scikit-learn there is a

00:26:43,679 --> 00:26:50,549
function for that and it will actually

00:26:44,999 --> 00:26:53,460
create it automatically and then start

00:26:50,549 --> 00:26:55,440
using statistics first before any again

00:26:53,460 --> 00:26:57,690
any deep learning model like if you just

00:26:55,440 --> 00:27:00,929
start with statistics for prediction

00:26:57,690 --> 00:27:04,200
actually - it works very well and then

00:27:00,929 --> 00:27:06,359
the last point is time and then the

00:27:04,200 --> 00:27:07,950
dimensionality it's actually something

00:27:06,359 --> 00:27:10,019
that not a lot of people are thinking

00:27:07,950 --> 00:27:13,259
about but now that you have all of your

00:27:10,019 --> 00:27:15,389
data in structure logs and events in a

00:27:13,259 --> 00:27:18,119
single source now you can actually apply

00:27:15,389 --> 00:27:20,340
time dimensionality on top look into

00:27:18,119 --> 00:27:22,049
time and patterns look into the

00:27:20,340 --> 00:27:25,769
distances between the time between the

00:27:22,049 --> 00:27:27,809
different between the different texts as

00:27:25,769 --> 00:27:31,499
well between different metrics and

00:27:27,809 --> 00:27:34,200
combine all of them together last point

00:27:31,499 --> 00:27:35,700
is really test this thing in production

00:27:34,200 --> 00:27:37,440
actually and not in your test

00:27:35,700 --> 00:27:40,440
environment because in production you

00:27:37,440 --> 00:27:44,279
will get the real deal and the way to do

00:27:40,440 --> 00:27:47,549
it is by switching traffic and building

00:27:44,279 --> 00:27:50,009
your your model in your system inside

00:27:47,549 --> 00:27:51,840
your production system in a way that it

00:27:50,009 --> 00:27:55,229
doesn't interfere with your real

00:27:51,840 --> 00:27:56,879
production data in an application there

00:27:55,229 --> 00:27:59,849
are different ways of doing that and

00:27:56,879 --> 00:28:02,609
always test it with your own users and

00:27:59,849 --> 00:28:05,099
the users are all of us the uncle people

00:28:02,609 --> 00:28:07,259
and other engineers that are responsible

00:28:05,099 --> 00:28:09,210
for production environment to be able to

00:28:07,259 --> 00:28:10,950
get interaction and user feedback and

00:28:09,210 --> 00:28:13,099
that's where supervised learning or

00:28:10,950 --> 00:28:15,659
semi-supervised learning come into play

00:28:13,099 --> 00:28:18,779
when you're getting interaction from an

00:28:15,659 --> 00:28:22,549
expert then you can actually adapt the

00:28:18,779 --> 00:28:24,690
ranking of your model in real time and

00:28:22,549 --> 00:28:27,389
your model becomes better and better

00:28:24,690 --> 00:28:30,389
there are different tools that I like

00:28:27,389 --> 00:28:33,299
whether it's spark or Apache mahute

00:28:30,389 --> 00:28:36,419
which is another project that it's

00:28:33,299 --> 00:28:38,700
pretty great for rancors other tools

00:28:36,419 --> 00:28:41,820
like solar or elasticsearch as we all

00:28:38,700 --> 00:28:44,580
know pretty good at semantic analysis

00:28:41,820 --> 00:28:47,640
and some of the algorithms are kind of

00:28:44,580 --> 00:28:49,890
baked into into those tools as well

00:28:47,640 --> 00:28:52,800
needs a lot of tuning need to understand

00:28:49,890 --> 00:28:54,510
to get into a working model you actually

00:28:52,800 --> 00:28:58,620
need to understand what those algorithms

00:28:54,510 --> 00:29:02,250
are our doing behind the scenes but at

00:28:58,620 --> 00:29:03,900
least the framework is there so at the

00:29:02,250 --> 00:29:06,030
end it's really about the team and the

00:29:03,900 --> 00:29:08,490
expertise in your team and it's and it's

00:29:06,030 --> 00:29:12,990
about the knowledge of the team to adapt

00:29:08,490 --> 00:29:16,170
the model over time so with that I'm I'm

00:29:12,990 --> 00:29:21,990
here to take any questions anything

00:29:16,170 --> 00:29:24,360
anyone want to raise cool so the

00:29:21,990 --> 00:29:26,520
question was whether it's really useful

00:29:24,360 --> 00:29:28,560
in production is just a radical or is it

00:29:26,520 --> 00:29:30,270
actually working what are we gonna do

00:29:28,560 --> 00:29:32,880
with false-positive how much time it

00:29:30,270 --> 00:29:34,440
takes start up the model right so so

00:29:32,880 --> 00:29:37,470
absolutely yes it is working in

00:29:34,440 --> 00:29:41,010
production I will not lie to you there

00:29:37,470 --> 00:29:43,080
are different ways to adapt the model I

00:29:41,010 --> 00:29:44,520
looked at different different models

00:29:43,080 --> 00:29:46,890
there is more deterministic approach

00:29:44,520 --> 00:29:49,560
with fuzzy logic and rules that actually

00:29:46,890 --> 00:29:51,330
will work right away you will have very

00:29:49,560 --> 00:29:53,760
little false positives because it's

00:29:51,330 --> 00:29:55,350
based on your own logic so think about

00:29:53,760 --> 00:29:57,810
it now that you have everything into a

00:29:55,350 --> 00:29:59,790
centralized pool of data you have more

00:29:57,810 --> 00:30:02,520
information you can start to think about

00:29:59,790 --> 00:30:04,920
you know your threshold just instead of

00:30:02,520 --> 00:30:06,570
thresholds to the to basically just

00:30:04,920 --> 00:30:08,010
configure your single monitoring

00:30:06,570 --> 00:30:11,700
solution now you were thinking about a

00:30:08,010 --> 00:30:15,240
scenario across different events logs

00:30:11,700 --> 00:30:18,270
data points all of that so start to put

00:30:15,240 --> 00:30:20,730
that logic in you will see very little

00:30:18,270 --> 00:30:23,310
false positives on the things that are

00:30:20,730 --> 00:30:24,750
more adaptive that's why I mentioned

00:30:23,310 --> 00:30:27,480
supervised learning and semi-supervised

00:30:24,750 --> 00:30:29,640
learning which will take a little bit

00:30:27,480 --> 00:30:31,620
time how much time really depending on

00:30:29,640 --> 00:30:34,140
the amount of data that you have

00:30:31,620 --> 00:30:36,330
it usually takes from my experience at

00:30:34,140 --> 00:30:38,850
least a week if not more depending on

00:30:36,330 --> 00:30:42,540
the size and the different algorithms

00:30:38,850 --> 00:30:46,800
that you are actually using but it's

00:30:42,540 --> 00:30:48,870
it's an ongoing interactive mode so it's

00:30:46,800 --> 00:30:51,630
it's kind of their never-ending story

00:30:48,870 --> 00:30:53,190
and you you keep adapting your models

00:30:51,630 --> 00:30:55,290
all the time to become better and better

00:30:53,190 --> 00:30:57,360
but you do it in production and you're

00:30:55,290 --> 00:31:00,300
doing it with real users you're doing it

00:30:57,360 --> 00:31:00,930
with your own teams so actually you get

00:31:00,300 --> 00:31:03,210
a reward

00:31:00,930 --> 00:31:04,830
right away and the and and it is much

00:31:03,210 --> 00:31:06,930
more accurate over time so the

00:31:04,830 --> 00:31:08,850
combination between unsupervised

00:31:06,930 --> 00:31:12,330
learning supervised learning and

00:31:08,850 --> 00:31:15,150
deterministic approach is is what I

00:31:12,330 --> 00:31:17,040
believe is the way to go to have like an

00:31:15,150 --> 00:31:22,170
immediate satisfaction in production and

00:31:17,040 --> 00:31:24,000
then adapt it over time yeah it's great

00:31:22,170 --> 00:31:26,460
so the question was like there are

00:31:24,000 --> 00:31:28,770
third-party applications and product

00:31:26,460 --> 00:31:31,020
that can do things around this area and

00:31:28,770 --> 00:31:33,420
whether we should like just go and buy

00:31:31,020 --> 00:31:35,940
them or should we develop our own so

00:31:33,420 --> 00:31:37,680
it's a great question and you know it's

00:31:35,940 --> 00:31:41,130
it's always a question versus build

00:31:37,680 --> 00:31:42,720
versus buy so I think the first question

00:31:41,130 --> 00:31:44,940
you need to ask yourself is do you have

00:31:42,720 --> 00:31:47,580
the expertise in-house if you don't have

00:31:44,940 --> 00:31:49,620
the expertise and you do understand your

00:31:47,580 --> 00:31:52,680
data and you have the time in cycles

00:31:49,620 --> 00:31:54,630
then yes you can go and build it and use

00:31:52,680 --> 00:31:57,690
like open source libraries as I show

00:31:54,630 --> 00:31:59,370
several of them and then maintain it on

00:31:57,690 --> 00:32:01,740
the other hand you know if you're a

00:31:59,370 --> 00:32:03,900
small develop shop or even if you're a

00:32:01,740 --> 00:32:06,240
huge enterprise and you don't have the

00:32:03,900 --> 00:32:09,630
expertise of deep learning machine

00:32:06,240 --> 00:32:11,430
learning data science and you know you

00:32:09,630 --> 00:32:15,060
want to focus on your business and

00:32:11,430 --> 00:32:17,240
uptime then you go and buy and some some

00:32:15,060 --> 00:32:20,970
are doing both you know some are

00:32:17,240 --> 00:32:23,670
basically maintaining like the data

00:32:20,970 --> 00:32:25,770
pipeline by themselves and then ship

00:32:23,670 --> 00:32:27,990
those their pipelines to other products

00:32:25,770 --> 00:32:29,910
and then get them back like you know

00:32:27,990 --> 00:32:31,920
there are other there are tools out

00:32:29,910 --> 00:32:35,040
there that just gives you like a very

00:32:31,920 --> 00:32:38,190
good anomaly detection and that's great

00:32:35,040 --> 00:32:40,650
and then you can actually take that dead

00:32:38,190 --> 00:32:43,200
data like was there an anomaly yes now

00:32:40,650 --> 00:32:46,880
and then take that as an event and

00:32:43,200 --> 00:32:49,710
stream it back so it's really up to you

00:32:46,880 --> 00:32:52,190
cool so if you like to talk about this

00:32:49,710 --> 00:32:54,660
kind of thing come talk to me later

00:32:52,190 --> 00:32:56,960
happy to talk about this discuss more in

00:32:54,660 --> 00:32:57,330
details thank you very much

00:32:56,960 --> 00:32:58,540
[Applause]

00:32:57,330 --> 00:33:00,600
[Music]

00:32:58,540 --> 00:33:00,600

YouTube URL: https://www.youtube.com/watch?v=Y0PccB_PC-Y


