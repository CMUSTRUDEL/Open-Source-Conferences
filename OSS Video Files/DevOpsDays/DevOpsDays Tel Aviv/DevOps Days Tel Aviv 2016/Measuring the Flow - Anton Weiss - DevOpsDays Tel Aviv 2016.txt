Title: Measuring the Flow - Anton Weiss - DevOpsDays Tel Aviv 2016
Publication date: 2017-01-08
Playlist: DevOps Days Tel Aviv 2016
Description: 
	
Captions: 
	00:00:02,710 --> 00:00:11,090
[Music]

00:00:07,390 --> 00:00:15,110
okay this is going to be a boring talk

00:00:11,090 --> 00:00:18,769
and not not not like the talk ahead

00:00:15,110 --> 00:00:21,289
yesterday about measuring things an

00:00:18,769 --> 00:00:24,919
enabling scientific approach like you

00:00:21,289 --> 00:00:29,989
know try things analyze the results and

00:00:24,919 --> 00:00:32,360
proceed on the outcomes so we need to do

00:00:29,989 --> 00:00:34,040
this because we're doing a DevOps or

00:00:32,360 --> 00:00:37,040
specifically continuous delivery in

00:00:34,040 --> 00:00:40,250
order to deliver better software faster

00:00:37,040 --> 00:00:47,030
which means heightened release agility

00:00:40,250 --> 00:00:50,300
without compromising quality so in

00:00:47,030 --> 00:00:51,530
general what we want to measure yeah and

00:00:50,300 --> 00:00:53,420
we're not talking about you know

00:00:51,530 --> 00:00:56,390
operational metrics or business metrics

00:00:53,420 --> 00:00:59,030
these are process metrics or flow

00:00:56,390 --> 00:01:02,180
metrics so two things we want to measure

00:00:59,030 --> 00:01:07,579
across two parallels velocity and

00:01:02,180 --> 00:01:10,909
quality and the concept of flow comes

00:01:07,579 --> 00:01:13,490
from lean management practices meaning

00:01:10,909 --> 00:01:15,469
basically the amount of change amount of

00:01:13,490 --> 00:01:17,659
work you can move through our pipeline

00:01:15,469 --> 00:01:21,619
and given unit of time so how do we

00:01:17,659 --> 00:01:24,469
measure this well there is no one recite

00:01:21,619 --> 00:01:28,700
but what we've come up with is a set of

00:01:24,469 --> 00:01:32,450
12 KPIs 64 velocity-6 for quality with

00:01:28,700 --> 00:01:34,340
him now presenting here you can use them

00:01:32,450 --> 00:01:37,340
you can comment on them if you have your

00:01:34,340 --> 00:01:40,880
own I'll be happy to hear okay so here

00:01:37,340 --> 00:01:44,869
we go we'll start with velocity first of

00:01:40,880 --> 00:01:46,789
all the the most low granularity metric

00:01:44,869 --> 00:01:48,649
which is mainly time which means how

00:01:46,789 --> 00:01:52,880
long does it take for a bit of code to

00:01:48,649 --> 00:01:57,350
get built tested and deployed and then

00:01:52,880 --> 00:02:00,020
we've got the daily change rate which

00:01:57,350 --> 00:02:02,060
means in the number of changing changes

00:02:00,020 --> 00:02:04,310
getting committed to mainline and test

00:02:02,060 --> 00:02:06,139
it per day of course it has to be tested

00:02:04,310 --> 00:02:09,860
because if it's not tested and verified

00:02:06,139 --> 00:02:12,110
it doesn't count and then we have the

00:02:09,860 --> 00:02:14,400
meantime to environment which means how

00:02:12,110 --> 00:02:16,769
long does it take devs or testers

00:02:14,400 --> 00:02:20,579
whoever needs an environment to wait for

00:02:16,769 --> 00:02:22,920
environment to come up of course if

00:02:20,579 --> 00:02:25,170
we're already doing continuous delivery

00:02:22,920 --> 00:02:27,989
and everything's automated this takes

00:02:25,170 --> 00:02:32,609
seconds but we usually don't start at

00:02:27,989 --> 00:02:34,620
that point and meantime to detect which

00:02:32,609 --> 00:02:36,239
means how much time passes since the

00:02:34,620 --> 00:02:40,829
original commit of the code until the

00:02:36,239 --> 00:02:44,640
bhagat it reduced gets detected okay and

00:02:40,829 --> 00:02:46,319
very important of course when everything

00:02:44,640 --> 00:02:50,030
is automated and we're testing things

00:02:46,319 --> 00:02:53,159
well we expect this to be very fast and

00:02:50,030 --> 00:02:55,440
mean times result once about God

00:02:53,159 --> 00:02:58,200
detected how much time it takes us to

00:02:55,440 --> 00:03:00,239
resolve this if we're very agile and we

00:02:58,200 --> 00:03:02,370
can react fast this is a good thing

00:03:00,239 --> 00:03:05,519
we're actually doing continuous delivery

00:03:02,370 --> 00:03:08,760
and mean time to prove how much time it

00:03:05,519 --> 00:03:11,639
takes us to very fun and proven release

00:03:08,760 --> 00:03:14,310
again if we're doing continues

00:03:11,639 --> 00:03:16,620
everything this will be probably seconds

00:03:14,310 --> 00:03:20,190
but we usually start with Mon click

00:03:16,620 --> 00:03:21,900
water releases and we need to be able to

00:03:20,190 --> 00:03:24,299
track if we're going in the right

00:03:21,900 --> 00:03:27,989
direction if we're actually making this

00:03:24,299 --> 00:03:31,290
smaller and shorter and now two on two

00:03:27,989 --> 00:03:34,260
quality build failure rate okay how many

00:03:31,290 --> 00:03:37,799
of our bills are failing the this going

00:03:34,260 --> 00:03:40,049
up isn't necessarily a bad sign because

00:03:37,799 --> 00:03:44,540
if we're doing more bills probably more

00:03:40,049 --> 00:03:48,359
more bills will will fail but anyway

00:03:44,540 --> 00:03:50,729
something that's good to track and also

00:03:48,359 --> 00:03:54,030
the deployment failure rate different

00:03:50,729 --> 00:03:57,030
metric but related and who well the

00:03:54,030 --> 00:03:59,760
failures by themselves are probably less

00:03:57,030 --> 00:04:02,129
interesting what interests us is how

00:03:59,760 --> 00:04:04,260
many of those failures are related to

00:04:02,129 --> 00:04:09,239
infrastructure such as things such as

00:04:04,260 --> 00:04:11,760
disk space network you name it important

00:04:09,239 --> 00:04:16,049
and we have to have to put in this data

00:04:11,760 --> 00:04:18,930
and we will create how much of tickets

00:04:16,049 --> 00:04:22,800
are getting reopened which means how

00:04:18,930 --> 00:04:24,840
good are we testing what we do automate

00:04:22,800 --> 00:04:26,909
a detection rate okay how much of our

00:04:24,840 --> 00:04:27,960
defects are getting detected by

00:04:26,909 --> 00:04:30,479
automated

00:04:27,960 --> 00:04:32,250
testing cycles again once we have

00:04:30,479 --> 00:04:35,880
everything automated this will probably

00:04:32,250 --> 00:04:38,880
be around one hundred percent this is

00:04:35,880 --> 00:04:42,830
division at list okay and unplanned work

00:04:38,880 --> 00:04:46,020
rate which means how good are we at

00:04:42,830 --> 00:04:50,220
predicting all kinds of unplanned

00:04:46,020 --> 00:04:52,530
and and then it becomes planned if we

00:04:50,220 --> 00:04:54,419
can predict it of course okay so where

00:04:52,530 --> 00:04:55,919
where do we collect all this data we of

00:04:54,419 --> 00:04:58,530
course start with project management

00:04:55,919 --> 00:05:00,810
tools and then source control tools and

00:04:58,530 --> 00:05:03,270
CI server and we need humans to input

00:05:00,810 --> 00:05:06,570
this data because otherwise it won't be

00:05:03,270 --> 00:05:08,490
anywhere and we need of course our tools

00:05:06,570 --> 00:05:10,919
to be integrated we need to be able to

00:05:08,490 --> 00:05:14,580
track all our changes across all the

00:05:10,919 --> 00:05:18,180
tools and where do we store the data

00:05:14,580 --> 00:05:21,270
well probably okay is a good place or we

00:05:18,180 --> 00:05:25,020
can use graph on ax as a dashboard for

00:05:21,270 --> 00:05:27,990
prettier graphs and of course we should

00:05:25,020 --> 00:05:29,970
communicate this on any of the knowledge

00:05:27,990 --> 00:05:34,139
sharing tools were using like confluence

00:05:29,970 --> 00:05:36,120
or whatever else and the important thing

00:05:34,139 --> 00:05:38,610
to remember that we're doing this not to

00:05:36,120 --> 00:05:41,130
put blame not to point fingers but just

00:05:38,610 --> 00:05:44,160
for the purpose of continuous

00:05:41,130 --> 00:05:48,589
improvement of what we're doing thanks

00:05:44,160 --> 00:05:48,589

YouTube URL: https://www.youtube.com/watch?v=FvBffquohIQ


