Title: Data Science in DevOps SysOps - Boaz Shuster - DevOpsDays Tel Aviv 2018
Publication date: 2019-01-03
Playlist: DevOpsDays Tel Aviv 2018
Description: 
	I will explain how collecting data from your continuous integration and delivery environments can help improve production releases. This talk is inspired by my previous job where I had the chance to boost the release pipeline using metrics and data.
Captions: 
	00:00:04,850 --> 00:00:09,719
in the last decade like so amazing

00:00:07,230 --> 00:00:12,090
things around DevOps and operation

00:00:09,719 --> 00:00:14,219
engineering and also seeing data

00:00:12,090 --> 00:00:16,619
engineering and data science being used

00:00:14,219 --> 00:00:20,310
to recommend us movies or to detect Bank

00:00:16,619 --> 00:00:23,550
frauds got me thinking hmm how can I use

00:00:20,310 --> 00:00:27,779
that at my work - and here are some

00:00:23,550 --> 00:00:29,849
examples simple ones we had a staging

00:00:27,779 --> 00:00:33,840
environment where we deployed services

00:00:29,849 --> 00:00:36,450
in containers anyone could run any

00:00:33,840 --> 00:00:38,520
container on it the problem was people

00:00:36,450 --> 00:00:40,620
tend to forget about their old running

00:00:38,520 --> 00:00:45,270
containers and writing cleaning script

00:00:40,620 --> 00:00:47,309
wasn't good enough for us so we

00:00:45,270 --> 00:00:49,950
collected information about the

00:00:47,309 --> 00:00:52,920
containers intact their duration time

00:00:49,950 --> 00:00:55,770
and when they can be deleted then we

00:00:52,920 --> 00:00:58,199
process that data table using a decision

00:00:55,770 --> 00:01:00,989
tree algorithm and we got a machine that

00:00:58,199 --> 00:01:05,070
predicts when to stop and to delete any

00:01:00,989 --> 00:01:08,100
given container that was awesome one

00:01:05,070 --> 00:01:10,619
because one day we realized some Chinese

00:01:08,100 --> 00:01:13,439
guy was trying to run Bitcoin miners on

00:01:10,619 --> 00:01:17,460
our environment but didn't manage thanks

00:01:13,439 --> 00:01:21,570
to our trained machine the second thing

00:01:17,460 --> 00:01:23,939
was that it took us months to merge new

00:01:21,570 --> 00:01:27,600
changes to production and we wanted to

00:01:23,939 --> 00:01:30,630
reduce that time we tried to do it by

00:01:27,600 --> 00:01:34,079
breaking testing stage into small parts

00:01:30,630 --> 00:01:37,049
and run them in parallel but that didn't

00:01:34,079 --> 00:01:39,540
do any significant long-term impact so

00:01:37,049 --> 00:01:42,390
we collected metadata about testing

00:01:39,540 --> 00:01:45,540
builds things like the duration time the

00:01:42,390 --> 00:01:49,530
operating system that was used what what

00:01:45,540 --> 00:01:53,490
host run the tests the size of the

00:01:49,530 --> 00:01:56,040
change and etc first we found out that

00:01:53,490 --> 00:01:59,939
on a particular host test were slower

00:01:56,040 --> 00:02:02,579
than on others and it was dot too bad

00:01:59,939 --> 00:02:07,200
kernel configurations on that host which

00:02:02,579 --> 00:02:11,370
we later fixed and made things work

00:02:07,200 --> 00:02:12,280
better for us we also we also use

00:02:11,370 --> 00:02:14,800
support

00:02:12,280 --> 00:02:18,310
drum machine to set up timeouts to tests

00:02:14,800 --> 00:02:20,620
if that timeout reached the test was

00:02:18,310 --> 00:02:22,600
suspended and the resources were were

00:02:20,620 --> 00:02:25,210
relocated to the next commit in the

00:02:22,600 --> 00:02:27,910
queue while someone was investigating

00:02:25,210 --> 00:02:31,570
why the test to clog longer than we

00:02:27,910 --> 00:02:34,750
fought and obviously if it was a false

00:02:31,570 --> 00:02:35,620
alarm we always could continue the test

00:02:34,750 --> 00:02:39,930
from that point

00:02:35,620 --> 00:02:44,650
thanks to containers and snapshot and

00:02:39,930 --> 00:02:46,989
and we updated our history data so we

00:02:44,650 --> 00:02:51,280
can train our machine and set a better

00:02:46,989 --> 00:02:54,280
timeouts now we wariness now we were in

00:02:51,280 --> 00:02:57,010
a stage where a taste when a test failed

00:02:54,280 --> 00:02:59,980
or was suspended it will take us days to

00:02:57,010 --> 00:03:02,560
figure out why which brings me to the

00:02:59,980 --> 00:03:05,170
next thing and that's a better way to

00:03:02,560 --> 00:03:08,560
determine why tests fail or we're

00:03:05,170 --> 00:03:12,310
suspended now I'm going to throw a lot

00:03:08,560 --> 00:03:15,040
of buzzwords so using ID FDF to

00:03:12,310 --> 00:03:17,799
vectorize diagrams from known issues

00:03:15,040 --> 00:03:20,560
logs we discovered unique keywords that

00:03:17,799 --> 00:03:22,269
indicate on those issues basically we

00:03:20,560 --> 00:03:24,610
could predict why a new test bill

00:03:22,269 --> 00:03:26,680
getting passed successfully by looking

00:03:24,610 --> 00:03:30,160
out for these keywords in the log files

00:03:26,680 --> 00:03:32,950
that was great it save us time looking

00:03:30,160 --> 00:03:35,980
what part failed and got us focused on

00:03:32,950 --> 00:03:38,440
how to fix it moreover if a new issue

00:03:35,980 --> 00:03:42,820
was rised we had to investigate it only

00:03:38,440 --> 00:03:44,829
once during that time I learned new

00:03:42,820 --> 00:03:47,110
algorithms and methods to solve

00:03:44,829 --> 00:03:49,299
challenging problems I got exposed to

00:03:47,110 --> 00:03:53,110
libraries and tools in Python and

00:03:49,299 --> 00:03:55,000
elasticsearch that I wouldn't have in

00:03:53,110 --> 00:03:57,489
the future I hope to see more data

00:03:55,000 --> 00:04:00,280
science in DevOps and operation injuring

00:03:57,489 --> 00:04:03,579
engineering things like a machine that

00:04:00,280 --> 00:04:06,280
summarizes a failure log for me will

00:04:03,579 --> 00:04:08,140
really help me instead of like going

00:04:06,280 --> 00:04:10,840
through all the data all the log

00:04:08,140 --> 00:04:12,640
understanding what happening or a

00:04:10,840 --> 00:04:14,920
machine that deploys my source code

00:04:12,640 --> 00:04:16,709
without scripts docker files or

00:04:14,920 --> 00:04:19,450
configure configuration management

00:04:16,709 --> 00:04:21,910
simply by determining the program

00:04:19,450 --> 00:04:24,220
programming language and packages that

00:04:21,910 --> 00:04:26,230
are used it will generate the docker

00:04:24,220 --> 00:04:29,350
file for me awesome

00:04:26,230 --> 00:04:32,500
and ultimately the only grail of all

00:04:29,350 --> 00:04:35,020
with deep learning and reinforcement to

00:04:32,500 --> 00:04:37,600
have seesaw BOTS that will do our TD

00:04:35,020 --> 00:04:40,800
work while we will do the fun and

00:04:37,600 --> 00:04:40,800
interesting stuff

00:04:40,940 --> 00:04:50,769
[Applause]

00:04:45,640 --> 00:04:50,769

YouTube URL: https://www.youtube.com/watch?v=HB95xfSV1O4


