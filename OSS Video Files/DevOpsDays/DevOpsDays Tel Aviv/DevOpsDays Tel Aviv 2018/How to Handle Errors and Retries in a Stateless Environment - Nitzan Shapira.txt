Title: How to Handle Errors and Retries in a Stateless Environment - Nitzan Shapira
Publication date: 2019-01-03
Playlist: DevOpsDays Tel Aviv 2018
Description: 
	DevOpsDays Tel Aviv 2018 

Errors happen in every application. In serverless, additional failures exist - timeouts, out of memory, and more. In many cases, errors are handled by the cloud vendor using a retry mechanism. Since the code is stateless, how can you be sure that the application actually works?
Captions: 
	00:00:01,980 --> 00:00:10,530
[Music]

00:00:05,960 --> 00:00:12,300
everyone I'm its aunt from Epsilon I'm

00:00:10,530 --> 00:00:14,370
going to talk about stateless

00:00:12,300 --> 00:00:16,410
environments and serverless environments

00:00:14,370 --> 00:00:17,970
and how do you handle the different

00:00:16,410 --> 00:00:20,939
problems that you can have in this kind

00:00:17,970 --> 00:00:22,529
of environments so I'm from Mexico and

00:00:20,939 --> 00:00:23,100
we are a company that is focused on

00:00:22,529 --> 00:00:25,410
serverless

00:00:23,100 --> 00:00:27,420
and on monitoring in production and

00:00:25,410 --> 00:00:30,179
troubleshooting so we help customers and

00:00:27,420 --> 00:00:32,189
companies use serverless in production

00:00:30,179 --> 00:00:34,140
better so they can understand what's

00:00:32,189 --> 00:00:35,989
going on and fix problems first because

00:00:34,140 --> 00:00:39,809
there are many challenges there and a

00:00:35,989 --> 00:00:41,550
few words about me I'm I'm an engineer

00:00:39,809 --> 00:00:43,460
so my background is mostly in

00:00:41,550 --> 00:00:46,320
cybersecurity reverse engineering

00:00:43,460 --> 00:00:47,760
infrastructure and for the last a year

00:00:46,320 --> 00:00:51,890
and a half I'm one of the founders in

00:00:47,760 --> 00:00:56,190
the CEO of epsilon and here in tel-aviv

00:00:51,890 --> 00:00:57,329
they have this thing yes okay and what

00:00:56,190 --> 00:00:58,710
we're going to talk about today so I'm

00:00:57,329 --> 00:01:01,469
gonna start with an introduction about

00:00:58,710 --> 00:01:04,049
service in general of course stateless

00:01:01,469 --> 00:01:06,000
is not just service but I'm gonna focus

00:01:04,049 --> 00:01:08,310
on it because it's one of the main use

00:01:06,000 --> 00:01:10,260
cases today for stateless environments

00:01:08,310 --> 00:01:12,630
and of course many of you are working in

00:01:10,260 --> 00:01:14,130
the cloud so it's very relevant for

00:01:12,630 --> 00:01:15,930
companies that are starting in the cloud

00:01:14,130 --> 00:01:19,799
today and also already in the cloud and

00:01:15,930 --> 00:01:21,509
then we're going to talk about different

00:01:19,799 --> 00:01:22,950
problems you can you can have in this

00:01:21,509 --> 00:01:25,380
kind of environments and what are the

00:01:22,950 --> 00:01:27,570
best ways to handle them including

00:01:25,380 --> 00:01:29,369
technologies such as distributed tracing

00:01:27,570 --> 00:01:32,100
and automation for many of the things

00:01:29,369 --> 00:01:33,420
and then hopefully my goal is that some

00:01:32,100 --> 00:01:35,820
of you can actually take this knowledge

00:01:33,420 --> 00:01:38,579
and start experimenting with servers in

00:01:35,820 --> 00:01:42,930
your job today even if it's for small

00:01:38,579 --> 00:01:44,880
things it can be very helpful so quick

00:01:42,930 --> 00:01:46,829
introduction about servers so I don't

00:01:44,880 --> 00:01:51,780
know how many you feel here are familiar

00:01:46,829 --> 00:01:53,040
with serverless ok so most people and

00:01:51,780 --> 00:01:55,290
when they think about services think

00:01:53,040 --> 00:01:57,570
about stuff like AWS lambda which is the

00:01:55,290 --> 00:02:00,390
most popular function as a service

00:01:57,570 --> 00:02:03,750
service today but service is not just

00:02:00,390 --> 00:02:06,689
AWS lamda it's a concept of writing

00:02:03,750 --> 00:02:09,030
software without managing infrastructure

00:02:06,689 --> 00:02:10,890
or less managing of infrastructure and

00:02:09,030 --> 00:02:13,310
basically focus more on your business

00:02:10,890 --> 00:02:16,140
logic so as a company you can

00:02:13,310 --> 00:02:18,359
work faster you can spend your

00:02:16,140 --> 00:02:21,269
developers time more efficiently and the

00:02:18,359 --> 00:02:23,489
DevOps times on things that are not just

00:02:21,269 --> 00:02:25,530
you know scaling more scanning less

00:02:23,489 --> 00:02:27,420
managing the infrastructure every day

00:02:25,530 --> 00:02:28,920
because there are spikes and so on so

00:02:27,420 --> 00:02:30,659
many of these things are taken care of

00:02:28,920 --> 00:02:32,489
by the cloud provider when you work in

00:02:30,659 --> 00:02:34,709
service and in practice it's a

00:02:32,489 --> 00:02:36,720
combination of both services such as

00:02:34,709 --> 00:02:39,060
function as a service such as lambda and

00:02:36,720 --> 00:02:41,430
today you can have also container the

00:02:39,060 --> 00:02:43,620
service for example AWS target if you

00:02:41,430 --> 00:02:45,569
know it and then mixing those with

00:02:43,620 --> 00:02:48,180
managed services an API is for example a

00:02:45,569 --> 00:02:49,739
database storage element message queue

00:02:48,180 --> 00:02:51,569
anything you need you make it managed

00:02:49,739 --> 00:02:54,419
and then you get a service application

00:02:51,569 --> 00:02:56,760
that is really scalable and managed for

00:02:54,419 --> 00:02:58,889
you and eventually the company you can

00:02:56,760 --> 00:03:01,980
go to market faster this way and the

00:02:58,889 --> 00:03:04,409
most popular one is by AWS so lambda but

00:03:01,980 --> 00:03:07,260
there are similar services by agile

00:03:04,409 --> 00:03:09,299
Google IBM and also some open source

00:03:07,260 --> 00:03:11,609
projects like the K native by Google

00:03:09,299 --> 00:03:14,609
recently so basically these are services

00:03:11,609 --> 00:03:16,769
from function is a service and the

00:03:14,609 --> 00:03:18,569
benefits for a company using service is

00:03:16,769 --> 00:03:20,519
first of all the financial benefit so

00:03:18,569 --> 00:03:23,040
basically you can save a lot of money on

00:03:20,519 --> 00:03:24,569
the cloud computing because if you look

00:03:23,040 --> 00:03:26,879
at the right side this is how a server

00:03:24,569 --> 00:03:29,280
is usually working in a company there

00:03:26,879 --> 00:03:31,949
are traffic spikes and in many companies

00:03:29,280 --> 00:03:34,889
the utilization of servers is 10 to 20

00:03:31,949 --> 00:03:36,030
percent so basically why because there

00:03:34,889 --> 00:03:37,650
is a spike in you don't know when it's

00:03:36,030 --> 00:03:39,810
gonna comes you have to be prepared but

00:03:37,650 --> 00:03:42,750
basically 80 to 90 percent of the bill

00:03:39,810 --> 00:03:44,609
is paid for nothing and so paper use

00:03:42,750 --> 00:03:46,409
means that you will only pay for the

00:03:44,609 --> 00:03:48,329
time your code is running so every

00:03:46,409 --> 00:03:51,479
hundred milliseconds we charge very

00:03:48,329 --> 00:03:53,849
little of course if you take it in sorry

00:03:51,479 --> 00:03:55,439
it's not necessarily so little but you

00:03:53,849 --> 00:03:58,229
can save a lot of money companies saved

00:03:55,439 --> 00:04:00,599
90% of their compute by moving to stuff

00:03:58,229 --> 00:04:02,819
like lambda and for me the biggest

00:04:00,599 --> 00:04:05,489
advantage is actually the other stuff

00:04:02,819 --> 00:04:08,250
the auto scheduling and it's called low

00:04:05,489 --> 00:04:10,799
ups so instead of DevOps you do less

00:04:08,250 --> 00:04:13,979
DevOps around infrastructure management

00:04:10,799 --> 00:04:15,329
and more around for example automation

00:04:13,979 --> 00:04:17,250
and testing and things that really

00:04:15,329 --> 00:04:19,139
impact the application and not just you

00:04:17,250 --> 00:04:20,820
know making sure things are working now

00:04:19,139 --> 00:04:23,340
in production because there are traffic

00:04:20,820 --> 00:04:25,220
spikes so eventually as a company it's

00:04:23,340 --> 00:04:26,750
all about developer

00:04:25,220 --> 00:04:28,729
DevOps in general it's a lot about

00:04:26,750 --> 00:04:30,500
developer velocity but services again

00:04:28,729 --> 00:04:32,870
developers can just write their code

00:04:30,500 --> 00:04:36,620
ship it and the cloud provider will take

00:04:32,870 --> 00:04:39,199
care of a lot of this stuff so it sounds

00:04:36,620 --> 00:04:41,330
great right it sounds like many of you

00:04:39,199 --> 00:04:42,889
want to try it right now and so there

00:04:41,330 --> 00:04:45,289
are limitation of course it doesn't come

00:04:42,889 --> 00:04:47,479
free so first of all the functions

00:04:45,289 --> 00:04:49,970
themselves are limited limited running

00:04:47,479 --> 00:04:52,280
time limited memory so basically for

00:04:49,970 --> 00:04:54,199
example a lambda can run it was five

00:04:52,280 --> 00:04:56,090
minutes now it's up to 15 minutes it's

00:04:54,199 --> 00:04:57,590
it's not bad but it's not suitable for

00:04:56,090 --> 00:04:59,300
everything so you need to design or

00:04:57,590 --> 00:05:01,430
application differently you need to

00:04:59,300 --> 00:05:03,860
choose how much memory the code has so

00:05:01,430 --> 00:05:05,199
the more you choose the more you pay so

00:05:03,860 --> 00:05:07,699
you have a very good reason to choose

00:05:05,199 --> 00:05:09,080
128 megabytes for a lambda but maybe the

00:05:07,699 --> 00:05:10,819
lambda we'll get out of memory because

00:05:09,080 --> 00:05:12,409
it's just not enough and you don't know

00:05:10,819 --> 00:05:14,330
how much you want to choose so that's a

00:05:12,409 --> 00:05:16,250
program again then you have those cold

00:05:14,330 --> 00:05:18,199
starts so it takes some time to start

00:05:16,250 --> 00:05:19,940
some time so it it can impact

00:05:18,199 --> 00:05:22,879
performance and I'm gonna talk about

00:05:19,940 --> 00:05:25,370
stateless as one of the it's not exactly

00:05:22,879 --> 00:05:27,500
a limitation it's a part of the design

00:05:25,370 --> 00:05:28,849
but it makes you design applications

00:05:27,500 --> 00:05:30,830
differently and it makes it more

00:05:28,849 --> 00:05:32,360
challenging to troubleshoot and

00:05:30,830 --> 00:05:37,039
understand problems that have been in

00:05:32,360 --> 00:05:38,569
production and eventually if you think

00:05:37,039 --> 00:05:41,029
of several s applications the way they

00:05:38,569 --> 00:05:43,069
look like essentially the microservices

00:05:41,029 --> 00:05:44,779
architecture so you have functions and

00:05:43,069 --> 00:05:46,969
you have services that are all connected

00:05:44,779 --> 00:05:48,889
in between and if you take a look at the

00:05:46,969 --> 00:05:50,960
right side you see an example of lambda

00:05:48,889 --> 00:05:53,930
triggered by an api gateway which is a

00:05:50,960 --> 00:05:56,449
web server service so an HTTP request

00:05:53,930 --> 00:05:59,000
comes in the lambda handles the request

00:05:56,449 --> 00:06:00,979
creates a file in s3 which is a managed

00:05:59,000 --> 00:06:03,379
service for storage triggers another

00:06:00,979 --> 00:06:05,110
lambda takes this file and does some

00:06:03,379 --> 00:06:07,520
calculation writes it to a database

00:06:05,110 --> 00:06:09,409
DynamoDB which is a managed no SQL

00:06:07,520 --> 00:06:11,449
database so there everything is

00:06:09,409 --> 00:06:13,909
completely managed after you deploy this

00:06:11,449 --> 00:06:15,979
and it's running if it's working you can

00:06:13,909 --> 00:06:17,440
basically forget about it about scale

00:06:15,979 --> 00:06:19,879
about anything it's just gonna work

00:06:17,440 --> 00:06:23,539
4,000 users and a million users is going

00:06:19,879 --> 00:06:26,090
to be the same in theory so the several

00:06:23,539 --> 00:06:28,159
applications are highly distributed and

00:06:26,090 --> 00:06:30,590
highly run driven which means that

00:06:28,159 --> 00:06:33,259
because each function is very small you

00:06:30,590 --> 00:06:34,699
end up with bigger architectures so in

00:06:33,259 --> 00:06:36,860
terms of software design it's more

00:06:34,699 --> 00:06:37,330
complicated more challenging to design

00:06:36,860 --> 00:06:39,220
and

00:06:37,330 --> 00:06:40,659
more difficult to operate if you think

00:06:39,220 --> 00:06:43,300
about the more complicated problems that

00:06:40,659 --> 00:06:44,860
you can have and one of the key things

00:06:43,300 --> 00:06:46,870
that you need to consider is using as

00:06:44,860 --> 00:06:50,500
many managed services as you can via

00:06:46,870 --> 00:06:52,810
api's so even stuff like zero and stripe

00:06:50,500 --> 00:06:54,069
can save you from writing code and it

00:06:52,810 --> 00:06:56,199
will eventually make your lambdas

00:06:54,069 --> 00:06:57,879
smaller and make them more efficient so

00:06:56,199 --> 00:07:01,900
using more and more api is one of the

00:06:57,879 --> 00:07:03,819
key characteristics and just an example

00:07:01,900 --> 00:07:07,330
from the reinvent that i was in about

00:07:03,819 --> 00:07:09,009
2/3 ago this is an example for my hsbc a

00:07:07,330 --> 00:07:11,440
company that you all know in a banking

00:07:09,009 --> 00:07:12,759
industry and as you can see they have a

00:07:11,440 --> 00:07:15,699
pretty interesting service architecture

00:07:12,759 --> 00:07:17,620
in production it's not not just on paper

00:07:15,699 --> 00:07:19,960
it's really in production so it's not

00:07:17,620 --> 00:07:22,270
just a buzzword people using it today to

00:07:19,960 --> 00:07:24,250
develop software faster everyone is

00:07:22,270 --> 00:07:26,889
doing it including us so we are a

00:07:24,250 --> 00:07:29,409
company pretty small startup company we

00:07:26,889 --> 00:07:31,330
are just 11 people but we have about 400

00:07:29,409 --> 00:07:32,680
kilometers in production in very high

00:07:31,330 --> 00:07:35,050
scale compared to a company our size

00:07:32,680 --> 00:07:37,060
because we digest all the events from

00:07:35,050 --> 00:07:39,580
our customers in their environments and

00:07:37,060 --> 00:07:42,400
we use it a lot because it does scale it

00:07:39,580 --> 00:07:43,990
is very good it's not easy but now that

00:07:42,400 --> 00:07:46,419
we are in it we are not going back I

00:07:43,990 --> 00:07:50,650
mean it's just adding more because you

00:07:46,419 --> 00:07:53,409
kind of get addicted to it ok so what

00:07:50,650 --> 00:07:55,240
are the challenges eventually I describe

00:07:53,409 --> 00:07:58,120
some characteristics but if you took an

00:07:55,240 --> 00:08:00,039
example of this application that this

00:07:58,120 --> 00:08:02,080
guy on the right yun quiz one of the top

00:08:00,039 --> 00:08:05,520
bloggers in service today is an engineer

00:08:02,080 --> 00:08:08,409
that did this experiment by of migrating

00:08:05,520 --> 00:08:09,520
monolithic application into service so

00:08:08,409 --> 00:08:12,759
on the right side you have a fully

00:08:09,520 --> 00:08:14,710
serverless application 100% on AWS and

00:08:12,759 --> 00:08:17,020
you see the complexity the left side is

00:08:14,710 --> 00:08:19,029
very simple the right side is just huge

00:08:17,020 --> 00:08:21,669
you know the number of functions the

00:08:19,029 --> 00:08:23,979
api's the events how are you going to

00:08:21,669 --> 00:08:25,960
operate this thing so even if you have

00:08:23,979 --> 00:08:27,789
this on design you deploy it on into

00:08:25,960 --> 00:08:29,680
production what you get from the cloud

00:08:27,789 --> 00:08:32,769
provider is just logs and logs and log

00:08:29,680 --> 00:08:33,940
is just not a good description of what's

00:08:32,769 --> 00:08:36,039
really going on in this kind of

00:08:33,940 --> 00:08:38,199
application what about all the events or

00:08:36,039 --> 00:08:39,969
the API is how we can fix issues fast

00:08:38,199 --> 00:08:41,589
how do you know the customers are

00:08:39,969 --> 00:08:43,659
getting good experienced with this kind

00:08:41,589 --> 00:08:45,579
of application so these are big

00:08:43,659 --> 00:08:47,560
challenges and one example for

00:08:45,579 --> 00:08:48,990
troubleshooting so if you have a problem

00:08:47,560 --> 00:08:51,240
in this function maybe

00:08:48,990 --> 00:08:52,709
there were five events before it came

00:08:51,240 --> 00:08:54,510
and you won't understand exactly why it

00:08:52,709 --> 00:08:57,810
happened but what you get is basically

00:08:54,510 --> 00:08:59,970
logs and rocks and logs and logs are not

00:08:57,810 --> 00:09:01,920
the right tool for using to troubleshoot

00:08:59,970 --> 00:09:03,930
distributed systems this is something

00:09:01,920 --> 00:09:08,399
people already realized today so just

00:09:03,930 --> 00:09:10,110
one example and the community agrees

00:09:08,399 --> 00:09:11,690
that debugging and monitoring are the

00:09:10,110 --> 00:09:14,430
biggest challenges to their in service

00:09:11,690 --> 00:09:16,260
this year in the year before it only

00:09:14,430 --> 00:09:18,810
gets more complicated and the tools are

00:09:16,260 --> 00:09:21,029
still very basic the ones that provided

00:09:18,810 --> 00:09:25,110
by the cloud provider for example so

00:09:21,029 --> 00:09:27,360
let's go into hello handling so I'm

00:09:25,110 --> 00:09:28,830
gonna yeah this is some introduction

00:09:27,360 --> 00:09:30,450
about serverless so I guess now you're

00:09:28,830 --> 00:09:32,070
all more familiar with what service is

00:09:30,450 --> 00:09:35,010
now I'm gonna go a bit back and talk

00:09:32,070 --> 00:09:36,600
about Ln general how do you fix problems

00:09:35,010 --> 00:09:39,029
in production how do you understand that

00:09:36,600 --> 00:09:40,860
there is a problem so in all the

00:09:39,029 --> 00:09:42,800
traditional applications not necessarily

00:09:40,860 --> 00:09:45,089
old but in traditional applications

00:09:42,800 --> 00:09:46,709
monolithic applications for example you

00:09:45,089 --> 00:09:49,709
have a server you have an application

00:09:46,709 --> 00:09:52,140
there is usually a log and log is a very

00:09:49,709 --> 00:09:53,820
easy way to use to understand what

00:09:52,140 --> 00:09:55,770
happened if the log has the information

00:09:53,820 --> 00:09:57,899
inside you can go and go and see what

00:09:55,770 --> 00:10:00,029
happened and you know maybe it's very

00:09:57,899 --> 00:10:01,740
helpful if it's not enough you can

00:10:00,029 --> 00:10:03,720
connect to the machine maybe you can

00:10:01,740 --> 00:10:04,800
even connect the debugger to the staging

00:10:03,720 --> 00:10:08,029
environment you can do different things

00:10:04,800 --> 00:10:10,529
to kind of understand what happened and

00:10:08,029 --> 00:10:12,630
so that's that's the way it's used it's

00:10:10,529 --> 00:10:15,060
done until today and every kind of

00:10:12,630 --> 00:10:18,029
products they have logs and companies do

00:10:15,060 --> 00:10:19,829
use stuff like ALK to aggregate logs

00:10:18,029 --> 00:10:21,810
from all the projects or the products

00:10:19,829 --> 00:10:25,440
and search and it's very straightforward

00:10:21,810 --> 00:10:27,810
right now what happens in stateless

00:10:25,440 --> 00:10:30,390
environment so serverless is stateless

00:10:27,810 --> 00:10:32,370
each one of these functions doesn't have

00:10:30,390 --> 00:10:34,890
a state it's it has an event a trigger

00:10:32,370 --> 00:10:36,899
it starts to run then it stops to run it

00:10:34,890 --> 00:10:38,579
can happen one billion times a day but

00:10:36,899 --> 00:10:40,620
still it doesn't have a state so you

00:10:38,579 --> 00:10:43,110
have to take the state and save it

00:10:40,620 --> 00:10:43,680
somewhere usually a database storage and

00:10:43,110 --> 00:10:45,959
so on

00:10:43,680 --> 00:10:48,500
but then eventually it's all events

00:10:45,959 --> 00:10:50,640
function wakes up triggers an event

00:10:48,500 --> 00:10:52,500
publishes the message triggers another

00:10:50,640 --> 00:10:54,300
function and so on so this is what I

00:10:52,500 --> 00:10:56,700
mean by stateless and event-driven and

00:10:54,300 --> 00:10:58,170
then it's pretty difficult to

00:10:56,700 --> 00:11:00,630
troubleshoot because you cannot connect

00:10:58,170 --> 00:11:02,550
to any server you cannot connect the

00:11:00,630 --> 00:11:04,350
debugger you only have logs

00:11:02,550 --> 00:11:06,630
and but the logs are not in context one

00:11:04,350 --> 00:11:08,820
function can write a log and one minute

00:11:06,630 --> 00:11:10,440
later the other function is triggered

00:11:08,820 --> 00:11:11,640
writes another log how are you gonna

00:11:10,440 --> 00:11:13,740
know that these two are connected

00:11:11,640 --> 00:11:15,630
together basically and you can have

00:11:13,740 --> 00:11:17,730
billions of them so it's very

00:11:15,630 --> 00:11:20,160
challenging and it's even difficult to

00:11:17,730 --> 00:11:21,750
know what the system health is so I can

00:11:20,160 --> 00:11:23,850
measure if the functions of failing

00:11:21,750 --> 00:11:25,860
that's okay but is the application

00:11:23,850 --> 00:11:29,420
working are the customers getting the

00:11:25,860 --> 00:11:31,980
right experience that's a tough question

00:11:29,420 --> 00:11:33,930
so what can you do in this curve kind of

00:11:31,980 --> 00:11:37,740
environments to understand what's going

00:11:33,930 --> 00:11:39,630
on and to troubleshoot the issues so

00:11:37,740 --> 00:11:42,150
let's talk about some problems that can

00:11:39,630 --> 00:11:44,010
happen in service application so the

00:11:42,150 --> 00:11:46,110
most typical problem is you have a bug

00:11:44,010 --> 00:11:48,480
in the code exception not necessarily a

00:11:46,110 --> 00:11:50,070
bug but the problem in the code and then

00:11:48,480 --> 00:11:51,990
you can handle it you can catch the

00:11:50,070 --> 00:11:54,960
exception you can write it to the log

00:11:51,990 --> 00:11:56,580
but again if the logs are not going to

00:11:54,960 --> 00:11:59,550
tell the entire story how are you going

00:11:56,580 --> 00:12:01,290
to tell the next function in the chain

00:11:59,550 --> 00:12:03,990
that something happened are you going to

00:12:01,290 --> 00:12:06,150
publish a message that describes a novel

00:12:03,990 --> 00:12:08,700
to the next function it it's not really

00:12:06,150 --> 00:12:10,800
a good practice so again even problems

00:12:08,700 --> 00:12:13,260
that are small can be difficult to trace

00:12:10,800 --> 00:12:15,240
back you need to somehow understand what

00:12:13,260 --> 00:12:17,520
was the entire story and then you get

00:12:15,240 --> 00:12:19,140
timeouts out of memories so it's pretty

00:12:17,520 --> 00:12:21,000
much like someone will take the computer

00:12:19,140 --> 00:12:23,490
out of the plug the function will just

00:12:21,000 --> 00:12:25,230
get a timeout AWS is measuring and

00:12:23,490 --> 00:12:26,760
that's it the function is dead you

00:12:25,230 --> 00:12:28,770
cannot do anything you cannot recover

00:12:26,760 --> 00:12:31,200
from it that's one of the worst things

00:12:28,770 --> 00:12:32,640
that can happen in service and maybe

00:12:31,200 --> 00:12:34,830
it's not even because of your own code

00:12:32,640 --> 00:12:35,730
maybe you are calling some API for

00:12:34,830 --> 00:12:38,040
authentication

00:12:35,730 --> 00:12:40,350
it doesn't reply for some reason and

00:12:38,040 --> 00:12:42,330
your function has five seconds limit and

00:12:40,350 --> 00:12:44,960
it's dead so these problems are very

00:12:42,330 --> 00:12:47,850
complicated to predict so again it's

00:12:44,960 --> 00:12:50,030
it's difficult to predict and to

00:12:47,850 --> 00:12:52,400
troubleshoot after so just for example

00:12:50,030 --> 00:12:55,440
so I'm going to talk about one of the

00:12:52,400 --> 00:12:57,840
useful ways to handle these problems

00:12:55,440 --> 00:13:00,720
since as I described it's pretty

00:12:57,840 --> 00:13:02,940
difficult to understand and to fix and

00:13:00,720 --> 00:13:05,370
to think about it in advance usually

00:13:02,940 --> 00:13:07,350
people use something called retries so

00:13:05,370 --> 00:13:09,630
it eyes are kind of like they sound you

00:13:07,350 --> 00:13:12,660
do the same thing again and you hope

00:13:09,630 --> 00:13:14,100
that it will work this time of course

00:13:12,660 --> 00:13:15,720
it's not so simple because you cannot

00:13:14,100 --> 00:13:17,950
always do something too

00:13:15,720 --> 00:13:20,110
with it working something that's gonna

00:13:17,950 --> 00:13:23,010
change something and some of the

00:13:20,110 --> 00:13:26,020
examples of retries are for example

00:13:23,010 --> 00:13:28,090
someone called your application and you

00:13:26,020 --> 00:13:30,280
failed and then the other person chose

00:13:28,090 --> 00:13:32,320
to call it again this is their choice

00:13:30,280 --> 00:13:33,490
they can call you twice if they think

00:13:32,320 --> 00:13:36,010
it's going to work that's fine

00:13:33,490 --> 00:13:38,200
that's not your problem so this is what

00:13:36,010 --> 00:13:40,090
I call synchronous events so if someone

00:13:38,200 --> 00:13:42,040
chooses to do something twice that's

00:13:40,090 --> 00:13:43,390
fine it's up to you but the more

00:13:42,040 --> 00:13:45,670
interesting use cases are things that

00:13:43,390 --> 00:13:48,970
are actually embedded in the cloud

00:13:45,670 --> 00:13:51,700
provider infrastructure so for example

00:13:48,970 --> 00:13:53,770
on the right side you see the SNS that's

00:13:51,700 --> 00:13:56,140
triggering a lambda function then the

00:13:53,770 --> 00:13:58,960
lambda fails so by default SNS will try

00:13:56,140 --> 00:14:01,420
to run the lambda up to three more two

00:13:58,960 --> 00:14:03,820
more times total of three in this

00:14:01,420 --> 00:14:05,500
specific time interval so for example

00:14:03,820 --> 00:14:08,350
it's quick it will try to run it again

00:14:05,500 --> 00:14:11,050
and again so is this something good no

00:14:08,350 --> 00:14:12,940
well you don't know depends what this

00:14:11,050 --> 00:14:14,950
lambda is doing but this is the default

00:14:12,940 --> 00:14:16,690
way and the same happens with Kinesis

00:14:14,950 --> 00:14:18,790
which is stream based events so can this

00:14:16,690 --> 00:14:21,160
is something this can be used to analyze

00:14:18,790 --> 00:14:23,650
that quick so you get pieces of data

00:14:21,160 --> 00:14:25,450
anyone analyze them so it will try to

00:14:23,650 --> 00:14:29,170
analyze it again and again as long as

00:14:25,450 --> 00:14:31,750
the time didn't go away so again we

00:14:29,170 --> 00:14:33,010
tries are things that are being used and

00:14:31,750 --> 00:14:35,260
they can be very useful if your

00:14:33,010 --> 00:14:38,950
application is designed in the right way

00:14:35,260 --> 00:14:41,110
so what can happen when you do a retry

00:14:38,950 --> 00:14:43,930
eventually you change the logical flow

00:14:41,110 --> 00:14:46,210
if the function is expecting a number

00:14:43,930 --> 00:14:48,250
and then it takes this number and pays

00:14:46,210 --> 00:14:49,570
this amount in dollars you don't want to

00:14:48,250 --> 00:14:51,340
do it two times because you're just

00:14:49,570 --> 00:14:54,130
gonna pay the money twice obviously this

00:14:51,340 --> 00:14:56,110
is not a situation when you retry is

00:14:54,130 --> 00:14:59,880
going to be effective so when retry is a

00:14:56,110 --> 00:15:01,630
good good thing to use when the system

00:14:59,880 --> 00:15:03,820
is something called

00:15:01,630 --> 00:15:06,130
I didn't put in so this is a

00:15:03,820 --> 00:15:07,660
mathematical property that is described

00:15:06,130 --> 00:15:09,520
in Wikipedia it's the property of

00:15:07,660 --> 00:15:11,350
certain operations in mathematics and

00:15:09,520 --> 00:15:13,090
computer science that they can be

00:15:11,350 --> 00:15:14,350
applied multiple times without changing

00:15:13,090 --> 00:15:16,990
the result behind the initial

00:15:14,350 --> 00:15:19,630
application so in some situations when

00:15:16,990 --> 00:15:22,360
the application is of this property you

00:15:19,630 --> 00:15:24,730
can do things multiple time so some

00:15:22,360 --> 00:15:26,500
examples for example if you update the

00:15:24,730 --> 00:15:28,380
database you can do it more than once

00:15:26,500 --> 00:15:29,670
it's gonna stay the same that's

00:15:28,380 --> 00:15:31,350
some things you can do more than once as

00:15:29,670 --> 00:15:33,150
long as nobody else is trying to do it

00:15:31,350 --> 00:15:34,440
the same time as you if you want to

00:15:33,150 --> 00:15:36,090
authenticate the user you can do it

00:15:34,440 --> 00:15:38,070
twice because it will remain

00:15:36,090 --> 00:15:39,570
authenticated and same for if you want

00:15:38,070 --> 00:15:41,550
to check if the file exists if it

00:15:39,570 --> 00:15:44,040
doesn't exist you create it if not it's

00:15:41,550 --> 00:15:46,770
okay so it's things that you can do more

00:15:44,040 --> 00:15:47,820
than once but that's nice to say but

00:15:46,770 --> 00:15:49,500
especially when you design an

00:15:47,820 --> 00:15:51,570
application with hundreds of functions

00:15:49,500 --> 00:15:54,000
thousands of functions how we are going

00:15:51,570 --> 00:15:56,040
to design each point to be of this

00:15:54,000 --> 00:15:58,380
property it's pretty difficult and it's

00:15:56,040 --> 00:16:00,120
not the way a developer's things think

00:15:58,380 --> 00:16:03,180
it's not something that people are used

00:16:00,120 --> 00:16:04,500
to and that's why there are services

00:16:03,180 --> 00:16:06,210
that can help you do it

00:16:04,500 --> 00:16:09,090
so for example something like step

00:16:06,210 --> 00:16:12,420
functions and how many are familiar with

00:16:09,090 --> 00:16:14,130
step functions yeah it's pretty new and

00:16:12,420 --> 00:16:16,020
not so many people still used in

00:16:14,130 --> 00:16:18,060
production I mean relatively to lambda

00:16:16,020 --> 00:16:20,340
for example but it's basically an

00:16:18,060 --> 00:16:23,310
orchestration service so you design a

00:16:20,340 --> 00:16:25,350
state machine in AWS and then each part

00:16:23,310 --> 00:16:27,690
is a lambda function or some condition

00:16:25,350 --> 00:16:29,190
and if it happens it goes to the next

00:16:27,690 --> 00:16:32,520
step it's like your design state machine

00:16:29,190 --> 00:16:34,680
in general but things inside are already

00:16:32,520 --> 00:16:36,180
meant to deal with retries and

00:16:34,680 --> 00:16:38,250
everything like that so basically this

00:16:36,180 --> 00:16:40,200
is very resilient once you deploy this

00:16:38,250 --> 00:16:42,270
and you do it right it can work very

00:16:40,200 --> 00:16:44,130
well with retries of course it doesn't

00:16:42,270 --> 00:16:46,890
come cheap I mean that's come free it

00:16:44,130 --> 00:16:49,050
costs an additional amount that you pay

00:16:46,890 --> 00:16:50,670
to AWS but of course it's a managed

00:16:49,050 --> 00:16:52,200
service like anything else it can save

00:16:50,670 --> 00:16:52,650
you a lot of time so maybe it's worth it

00:16:52,200 --> 00:16:57,210
for you

00:16:52,650 --> 00:16:59,490
and just some example from what we do so

00:16:57,210 --> 00:17:02,130
this is a screenshot from our product so

00:16:59,490 --> 00:17:04,110
for example if you have this transaction

00:17:02,130 --> 00:17:06,089
involving lambda functions and the

00:17:04,110 --> 00:17:07,620
second function failed one of the things

00:17:06,089 --> 00:17:10,350
that we do to save a lot of time is to

00:17:07,620 --> 00:17:11,850
automatically say you had retries so

00:17:10,350 --> 00:17:13,589
these three invocations are actually

00:17:11,850 --> 00:17:16,079
part of the same transaction and you

00:17:13,589 --> 00:17:18,420
don't need to you know go one by one and

00:17:16,079 --> 00:17:20,430
understand what this is in relations so

00:17:18,420 --> 00:17:23,339
just in a way to save a lot of time when

00:17:20,430 --> 00:17:24,900
debugging just an example and this is

00:17:23,339 --> 00:17:27,120
another example so if you have a lambda

00:17:24,900 --> 00:17:28,830
that is triggered by an SNS so you can

00:17:27,120 --> 00:17:30,810
take the whole logic of the lambda and

00:17:28,830 --> 00:17:32,790
actually trigger a step machine instead

00:17:30,810 --> 00:17:35,580
and then you can do a lot of logic

00:17:32,790 --> 00:17:38,820
inside with every order retries and so

00:17:35,580 --> 00:17:41,670
on many people use lambda for a kind of

00:17:38,820 --> 00:17:42,090
cron jobs like a substitute to corn jobs

00:17:41,670 --> 00:17:45,299
because

00:17:42,090 --> 00:17:46,470
very easy but this is not usually what

00:17:45,299 --> 00:17:48,929
I'm talking about I'm talking about

00:17:46,470 --> 00:17:51,270
actually logical applications so if you

00:17:48,929 --> 00:17:53,070
have a complicated script you want to

00:17:51,270 --> 00:17:54,750
convert it into lambda maybe you can do

00:17:53,070 --> 00:17:56,760
it in a step machine that will have

00:17:54,750 --> 00:17:58,620
different conditions and basically once

00:17:56,760 --> 00:18:02,400
you deploy it you can forget about it if

00:17:58,620 --> 00:18:03,659
if you wait right this just some example

00:18:02,400 --> 00:18:05,130
don't look at the code so much but this

00:18:03,659 --> 00:18:07,350
is how where you can describe that

00:18:05,130 --> 00:18:09,690
machine using a ml with service

00:18:07,350 --> 00:18:12,360
framework which is one of the popular

00:18:09,690 --> 00:18:14,490
tools for deploying like people using C

00:18:12,360 --> 00:18:16,559
sed a lot so you basically described is

00:18:14,490 --> 00:18:18,240
the ML file you deploy it you can do it

00:18:16,559 --> 00:18:22,679
in a cloud formation in different ways

00:18:18,240 --> 00:18:24,870
telephone and so on okay so we talked

00:18:22,679 --> 00:18:27,090
about stateless we talked about about

00:18:24,870 --> 00:18:28,020
handling and retries now the second part

00:18:27,090 --> 00:18:29,880
of the talk is gonna be about

00:18:28,020 --> 00:18:31,320
observability in general and we're going

00:18:29,880 --> 00:18:33,210
to talk about observability for

00:18:31,320 --> 00:18:35,880
stateless environments and how do you

00:18:33,210 --> 00:18:38,730
know that applications are working as

00:18:35,880 --> 00:18:40,890
you expect so eventually observability

00:18:38,730 --> 00:18:43,380
or monitoring or everyone calls it in

00:18:40,890 --> 00:18:44,820
different ways you have you always have

00:18:43,380 --> 00:18:46,830
the same goals you want to know that

00:18:44,820 --> 00:18:48,330
your system is working so if you have

00:18:46,830 --> 00:18:49,649
something in production you want to know

00:18:48,330 --> 00:18:51,179
that it's working you're not gonna wait

00:18:49,649 --> 00:18:53,970
for a customer to call you with a

00:18:51,179 --> 00:18:56,100
problem you want to get some alert some

00:18:53,970 --> 00:18:57,960
number some measurement to tell you that

00:18:56,100 --> 00:18:59,580
that it's working and that's a different

00:18:57,960 --> 00:19:02,880
difficult question because what is

00:18:59,580 --> 00:19:06,240
working is working equals zero levels is

00:19:02,880 --> 00:19:07,980
it latency less than 200 milliseconds it

00:19:06,240 --> 00:19:10,320
depends on the application so this is a

00:19:07,980 --> 00:19:12,659
tough question usually and in complex

00:19:10,320 --> 00:19:15,149
complex microservices applications it's

00:19:12,659 --> 00:19:17,070
pretty difficult and then you want to be

00:19:15,149 --> 00:19:18,390
able to fix problems fast so even to

00:19:17,070 --> 00:19:20,549
know about the problems before they

00:19:18,390 --> 00:19:22,049
happen and then fix them as soon as

00:19:20,549 --> 00:19:24,480
possible because your customers are

00:19:22,049 --> 00:19:26,520
experiencing problems you want to give

00:19:24,480 --> 00:19:28,590
them the best experience and the last

00:19:26,520 --> 00:19:31,289
thing is optimizations and bottlenecks

00:19:28,590 --> 00:19:33,870
how do you detect them how do you make

00:19:31,289 --> 00:19:35,760
decisions based on this data and in

00:19:33,870 --> 00:19:37,890
serverless is not just performance also

00:19:35,760 --> 00:19:41,130
cost because you pay per use so if you

00:19:37,890 --> 00:19:43,679
can improve something to be 50% faster

00:19:41,130 --> 00:19:45,990
you're gonna pay 50 percent less dollars

00:19:43,679 --> 00:19:49,830
so it's another reason to want to

00:19:45,990 --> 00:19:52,110
optimize your systems so I'm gonna go

00:19:49,830 --> 00:19:54,210
one by one for these things and to see

00:19:52,110 --> 00:19:55,590
how they apply in state licensed service

00:19:54,210 --> 00:19:56,999
so let's say you want to track your

00:19:55,590 --> 00:19:59,279
system health and you have this big

00:19:56,999 --> 00:20:00,659
application that I showed you before how

00:19:59,279 --> 00:20:02,940
do you know that it's working is it

00:20:00,659 --> 00:20:04,379
essentially just checking the functions

00:20:02,940 --> 00:20:06,600
is it enough to look at the function

00:20:04,379 --> 00:20:08,730
metrics so I can look at the arrows I

00:20:06,600 --> 00:20:10,619
can look at the duration so first of all

00:20:08,730 --> 00:20:11,940
it is useful to look at functions and by

00:20:10,619 --> 00:20:14,249
looking at the function metrics you can

00:20:11,940 --> 00:20:15,990
identify problems very easily so you

00:20:14,249 --> 00:20:17,999
know if the func if all your functions

00:20:15,990 --> 00:20:19,710
are failing all the time there is a good

00:20:17,999 --> 00:20:21,929
chance the application is not working

00:20:19,710 --> 00:20:24,389
very well but it doesn't mean that if

00:20:21,929 --> 00:20:26,279
they all don't fail ever then everything

00:20:24,389 --> 00:20:27,929
is working but it's a good thing to make

00:20:26,279 --> 00:20:29,850
sure you don't have many hours time outs

00:20:27,929 --> 00:20:31,559
out of memories cords doubt these are

00:20:29,850 --> 00:20:34,080
useful to identify via the function

00:20:31,559 --> 00:20:35,700
matrix but then if you look at this

00:20:34,080 --> 00:20:38,279
application you see that it's more than

00:20:35,700 --> 00:20:40,169
just functions there are flows there are

00:20:38,279 --> 00:20:43,049
events the API is everything is

00:20:40,169 --> 00:20:45,269
connected and if you want to understand

00:20:43,049 --> 00:20:46,769
what's the user experience is maybe just

00:20:45,269 --> 00:20:49,259
looking at function metrics is not

00:20:46,769 --> 00:20:51,119
enough and eventually a server

00:20:49,259 --> 00:20:54,330
application is more than the functions

00:20:51,119 --> 00:20:56,850
it's a combination of functions API is

00:20:54,330 --> 00:20:58,259
and what we call transactions so a

00:20:56,850 --> 00:21:00,330
transaction is basically something that

00:20:58,259 --> 00:21:02,879
starts for example with an HTTP request

00:21:00,330 --> 00:21:05,159
triggers multiple events until it ends

00:21:02,879 --> 00:21:07,350
so this is really something that tells

00:21:05,159 --> 00:21:10,169
the story of the user with the

00:21:07,350 --> 00:21:11,340
application and if you think about

00:21:10,169 --> 00:21:14,159
troubleshooting and I showed this

00:21:11,340 --> 00:21:15,480
example before so again the functions

00:21:14,159 --> 00:21:17,399
are not enough and the logs are not

00:21:15,480 --> 00:21:18,990
enough what eventually you would want is

00:21:17,399 --> 00:21:21,029
to somehow track those events together

00:21:18,990 --> 00:21:23,429
all the way to the end and then

00:21:21,029 --> 00:21:25,559
troubleshoot faster and understand the

00:21:23,429 --> 00:21:29,009
performance from end to end and not just

00:21:25,559 --> 00:21:30,389
for particular functions and this is

00:21:29,009 --> 00:21:32,369
just an abstraction of what the

00:21:30,389 --> 00:21:36,119
transaction looks like it's just arrows

00:21:32,369 --> 00:21:38,850
basically with a start and an end and if

00:21:36,119 --> 00:21:40,649
I talk about asynchronous invocations

00:21:38,850 --> 00:21:41,940
how you want to connect them so for

00:21:40,649 --> 00:21:43,769
example if the first function is

00:21:41,940 --> 00:21:46,679
triggered you would want to know that

00:21:43,769 --> 00:21:48,179
these functions are triggered later so

00:21:46,679 --> 00:21:50,129
being able to connect these two together

00:21:48,179 --> 00:21:51,960
is something that's not possible to do

00:21:50,129 --> 00:21:53,460
via the logs because the logs don't have

00:21:51,960 --> 00:21:55,440
a context this is something that is

00:21:53,460 --> 00:21:57,450
related to tracing I'm going to talk

00:21:55,440 --> 00:22:00,299
about in a second and the second thing

00:21:57,450 --> 00:22:02,279
is to us by identify requests outside

00:22:00,299 --> 00:22:03,899
the cloud for vitals for example if you

00:22:02,279 --> 00:22:05,680
call the different cloud provider like

00:22:03,899 --> 00:22:08,350
other if you call all

00:22:05,680 --> 00:22:10,150
your authentication you want to know how

00:22:08,350 --> 00:22:11,890
much time these things take because they

00:22:10,150 --> 00:22:13,690
can cause your function to timeout and

00:22:11,890 --> 00:22:15,370
also you're gonna pay each time you're

00:22:13,690 --> 00:22:18,610
quiet calling an API you're paying money

00:22:15,370 --> 00:22:21,370
and there is a good reason to do it fast

00:22:18,610 --> 00:22:23,200
and now I'm going to talk about

00:22:21,370 --> 00:22:25,150
distributed tracing which is one of the

00:22:23,200 --> 00:22:26,800
key technologies to understand

00:22:25,150 --> 00:22:29,260
distributed systems and circuits in

00:22:26,800 --> 00:22:30,940
general well how many are familiar with

00:22:29,260 --> 00:22:33,400
a distributed tracing or heard about the

00:22:30,940 --> 00:22:36,850
term go so many people do they use

00:22:33,400 --> 00:22:38,740
microservices containers and some of the

00:22:36,850 --> 00:22:40,960
things that people realized some point

00:22:38,740 --> 00:22:42,790
is that I can't really understand what's

00:22:40,960 --> 00:22:45,130
going on just by looking at the logs of

00:22:42,790 --> 00:22:47,140
the service because there's not just one

00:22:45,130 --> 00:22:48,850
service there are four services they are

00:22:47,140 --> 00:22:50,950
connecting talking to each other and

00:22:48,850 --> 00:22:52,540
this is what's called the distributed

00:22:50,950 --> 00:22:54,760
trace something comes in going to

00:22:52,540 --> 00:22:56,290
multiple services until it ends and the

00:22:54,760 --> 00:22:58,990
trace is something that tells the story

00:22:56,290 --> 00:23:01,060
of this request for example so

00:22:58,990 --> 00:23:03,430
distributed tracing is technology to

00:23:01,060 --> 00:23:06,340
understand distributed systems and this

00:23:03,430 --> 00:23:08,950
is just one example of client building

00:23:06,340 --> 00:23:10,750
application and eventually when you get

00:23:08,950 --> 00:23:12,610
a distributed tracing data you can put

00:23:10,750 --> 00:23:15,070
it in some tools for example this is

00:23:12,610 --> 00:23:18,340
yogur a popular tool for visualization

00:23:15,070 --> 00:23:19,960
of the time lines and waterfall charts

00:23:18,340 --> 00:23:22,420
you can quickly identify how much time

00:23:19,960 --> 00:23:25,270
every operation took but how do you get

00:23:22,420 --> 00:23:26,650
this data how do you know how everything

00:23:25,270 --> 00:23:28,870
is connected it's so it's not so easy

00:23:26,650 --> 00:23:31,270
and this is why people use different

00:23:28,870 --> 00:23:34,330
frameworks for example open tracing open

00:23:31,270 --> 00:23:36,370
sensors they are very popular for micro

00:23:34,330 --> 00:23:38,320
services to implement distributed

00:23:36,370 --> 00:23:40,090
tracing in your company and companies

00:23:38,320 --> 00:23:41,470
today are putting a lot of focus and

00:23:40,090 --> 00:23:43,750
effort in the training into

00:23:41,470 --> 00:23:44,950
implementation of these services I know

00:23:43,750 --> 00:23:47,380
they use it in some of the bigger

00:23:44,950 --> 00:23:50,440
companies in Israel and once you do it

00:23:47,380 --> 00:23:51,820
you can gain great success of visibility

00:23:50,440 --> 00:23:54,550
troubleshooting and so on

00:23:51,820 --> 00:23:56,110
the problem is that it's difficult it

00:23:54,550 --> 00:23:58,990
takes a lot of time a lot of maintenance

00:23:56,110 --> 00:24:00,820
there is a potential of errors and

00:23:58,990 --> 00:24:02,800
eventually you're gonna tell your

00:24:00,820 --> 00:24:05,020
developers and developers ok now you

00:24:02,800 --> 00:24:07,240
have to spend 30 percent of your time

00:24:05,020 --> 00:24:08,740
doing this thing because otherwise we

00:24:07,240 --> 00:24:10,660
have no idea what's going on in our

00:24:08,740 --> 00:24:12,790
production so people want to go fast

00:24:10,660 --> 00:24:14,680
they want to deploy fast or go to market

00:24:12,790 --> 00:24:16,630
fast but then they have to go back or

00:24:14,680 --> 00:24:18,250
wait we have no idea what's going on we

00:24:16,630 --> 00:24:18,730
need to do this thing so that's kind of

00:24:18,250 --> 00:24:21,640
a bad

00:24:18,730 --> 00:24:23,980
that is is going on today and if you

00:24:21,640 --> 00:24:26,020
take it to server less then the question

00:24:23,980 --> 00:24:28,299
is does it really make sense that it

00:24:26,020 --> 00:24:30,490
makes sense to implement something so

00:24:28,299 --> 00:24:33,010
manual in applications it's supposed to

00:24:30,490 --> 00:24:34,929
be so fast best to deploy and maybe have

00:24:33,010 --> 00:24:36,580
thousands of functions so does it make

00:24:34,929 --> 00:24:38,830
sense to deploy it in thousands of

00:24:36,580 --> 00:24:40,390
functions and maintain it over time what

00:24:38,830 --> 00:24:43,480
about the developer Velocity's was the

00:24:40,390 --> 00:24:45,640
main reason to go into service so what

00:24:43,480 --> 00:24:47,110
we are working on is to do it

00:24:45,640 --> 00:24:50,260
automatically and to save you a lot of

00:24:47,110 --> 00:24:52,330
time and eventually automation is

00:24:50,260 --> 00:24:54,490
generally something that I really

00:24:52,330 --> 00:24:57,100
believe in not just servers in general

00:24:54,490 --> 00:24:58,900
in operations in development everything

00:24:57,100 --> 00:25:01,090
you can automate today he will get

00:24:58,900 --> 00:25:03,130
gained great amount of time because

00:25:01,090 --> 00:25:05,320
eventually over time the applications

00:25:03,130 --> 00:25:07,419
become complicated and maintaining those

00:25:05,320 --> 00:25:09,610
can take a lot of time so automation is

00:25:07,419 --> 00:25:12,400
very very helpful and I'm going to talk

00:25:09,610 --> 00:25:14,260
about some example that shows what you

00:25:12,400 --> 00:25:17,620
would expect from a distributed tracing

00:25:14,260 --> 00:25:19,929
for service how it will help you so if

00:25:17,620 --> 00:25:22,390
you think about this trace I mean this

00:25:19,929 --> 00:25:23,799
request comes in to an API gateway to

00:25:22,390 --> 00:25:25,840
alarm the function that does

00:25:23,799 --> 00:25:28,600
authentication with all-zero an external

00:25:25,840 --> 00:25:31,990
API publishes a message to an SNS which

00:25:28,600 --> 00:25:33,549
is kind of similar to RabbitMQ and then

00:25:31,990 --> 00:25:36,250
triggers another one the function that

00:25:33,549 --> 00:25:37,840
fails so now you have the failure and we

00:25:36,250 --> 00:25:39,730
saw how it looks with law is just get

00:25:37,840 --> 00:25:40,780
logs but it's difficult to understand

00:25:39,730 --> 00:25:42,669
what's going on so distribute the

00:25:40,780 --> 00:25:44,679
tracing enables you to really trace back

00:25:42,669 --> 00:25:46,000
what happened so starting from the first

00:25:44,679 --> 00:25:48,580
function to see what was the arrow

00:25:46,000 --> 00:25:50,320
actually the exception in the code to

00:25:48,580 --> 00:25:52,360
look at the function parameters what was

00:25:50,320 --> 00:25:53,830
the running time was the record start

00:25:52,360 --> 00:25:56,980
anything that happens in the function

00:25:53,830 --> 00:25:59,260
and the log then going back to the SNS

00:25:56,980 --> 00:26:00,700
to get what was the JSON message that

00:25:59,260 --> 00:26:01,929
actually triggered the RAM the sooner

00:26:00,700 --> 00:26:03,700
you go step back you know what was the

00:26:01,929 --> 00:26:05,530
input for the lambda even if it wasn't

00:26:03,700 --> 00:26:07,840
in the log you have it by the trace and

00:26:05,530 --> 00:26:09,220
then for the second first lambda to see

00:26:07,840 --> 00:26:10,690
what happened there so oh the

00:26:09,220 --> 00:26:12,669
authentication failed so maybe the

00:26:10,690 --> 00:26:13,960
problem was that the first lamp that

00:26:12,669 --> 00:26:16,150
continued even though it failed

00:26:13,960 --> 00:26:18,640
authentication so the problem wasn't

00:26:16,150 --> 00:26:21,040
actually in the second lambda and the o0

00:26:18,640 --> 00:26:23,650
returned that authentication indeed

00:26:21,040 --> 00:26:26,440
failed 401 and all the way the API gate

00:26:23,650 --> 00:26:28,090
can tell you who was the user involved

00:26:26,440 --> 00:26:29,740
in this request so everything is

00:26:28,090 --> 00:26:31,890
automatically traced so when something

00:26:29,740 --> 00:26:34,350
happens you can go inside and fix it in

00:26:31,890 --> 00:26:36,590
instead of hours or even days this is

00:26:34,350 --> 00:26:38,730
what we've seen companies doing and

00:26:36,590 --> 00:26:41,070
another example why you should care

00:26:38,730 --> 00:26:44,610
about external API so in this example

00:26:41,070 --> 00:26:46,590
you use o0 and Twilio I don't know if

00:26:44,610 --> 00:26:49,230
you see the numbers but basically all 0

00:26:46,590 --> 00:26:51,210
is about 700 milliseconds because it was

00:26:49,230 --> 00:26:53,550
configured to the wrong region when you

00:26:51,210 --> 00:26:56,520
work in US but maybe r0 is configured to

00:26:53,550 --> 00:26:58,590
Europe but then these 700 milliseconds

00:26:56,520 --> 00:27:00,870
compared to 50 milliseconds in all the

00:26:58,590 --> 00:27:02,790
rest add up and if it happens a billion

00:27:00,870 --> 00:27:04,500
times today it's going to be major

00:27:02,790 --> 00:27:07,380
bottleneck in your application and maybe

00:27:04,500 --> 00:27:09,450
80% of your total cost is gonna go just

00:27:07,380 --> 00:27:11,910
waiting for this API so understanding

00:27:09,450 --> 00:27:15,960
the bottlenecks for any external API is

00:27:11,910 --> 00:27:19,200
also very important and the last thing

00:27:15,960 --> 00:27:21,360
is also to kind of take these individual

00:27:19,200 --> 00:27:22,980
transactions and start to gain insights

00:27:21,360 --> 00:27:24,750
about the performance of the system so

00:27:22,980 --> 00:27:26,730
of course it's good to look at

00:27:24,750 --> 00:27:29,010
individual transactions but what about

00:27:26,730 --> 00:27:31,200
the performance of the world so what is

00:27:29,010 --> 00:27:35,130
the user experience in the aggregated

00:27:31,200 --> 00:27:36,510
way so is it one second over time

00:27:35,130 --> 00:27:38,430
what are the arrows where is the

00:27:36,510 --> 00:27:39,480
bottleneck not just now but in the last

00:27:38,430 --> 00:27:41,670
24 hours

00:27:39,480 --> 00:27:43,050
so seeing this kind of business flops

00:27:41,670 --> 00:27:45,330
can really help you and can tell you

00:27:43,050 --> 00:27:48,420
okay I have a user subscribe to the

00:27:45,330 --> 00:27:50,190
system the subscription takes 500

00:27:48,420 --> 00:27:51,900
milliseconds and this is happening 1

00:27:50,190 --> 00:27:54,000
million times a day and I have another

00:27:51,900 --> 00:27:55,860
one that is a payment transfer and this

00:27:54,000 --> 00:27:57,540
is happening 100 million times a day and

00:27:55,860 --> 00:27:59,700
it's taking this much time very

00:27:57,540 --> 00:28:02,280
important for me that this one would be

00:27:59,700 --> 00:28:04,290
much faster and the other flow maybe is

00:28:02,280 --> 00:28:06,300
not that important so you can choose and

00:28:04,290 --> 00:28:08,520
make decisions on optimizations and say

00:28:06,300 --> 00:28:09,900
I want to optimize this flow because

00:28:08,520 --> 00:28:12,450
it's more frequent and it's more

00:28:09,900 --> 00:28:16,410
important to my business and then you

00:28:12,450 --> 00:28:18,930
can make these decisions okay I think

00:28:16,410 --> 00:28:22,130
the last thing I want to finish with is

00:28:18,930 --> 00:28:25,140
that first of all Cerberus is not

00:28:22,130 --> 00:28:27,210
something that AWS made up to just to

00:28:25,140 --> 00:28:28,980
make more money everyone is doing it all

00:28:27,210 --> 00:28:30,990
the companies are experimenting with it

00:28:28,980 --> 00:28:34,020
and eventually it's meant to develop

00:28:30,990 --> 00:28:36,000
software faster and to ship it faster so

00:28:34,020 --> 00:28:38,400
companies can basically go to market

00:28:36,000 --> 00:28:40,230
faster so if you want to adopt server

00:28:38,400 --> 00:28:41,520
less think event-driven don't don't you

00:28:40,230 --> 00:28:43,530
think of lambda functions is a

00:28:41,520 --> 00:28:45,049
substitute to a cron job it's something

00:28:43,530 --> 00:28:47,450
that can be used input

00:28:45,049 --> 00:28:49,580
for really meaningful applications very

00:28:47,450 --> 00:28:52,190
high scale and companies are doing it

00:28:49,580 --> 00:28:54,200
today but if you do it you have to

00:28:52,190 --> 00:28:55,249
design it properly and you have to use

00:28:54,200 --> 00:28:57,019
the right tools

00:28:55,249 --> 00:28:59,179
orchestration like step functions is

00:28:57,019 --> 00:29:01,009
very helpful and automation is again

00:28:59,179 --> 00:29:03,320
it's something that can help you really

00:29:01,009 --> 00:29:04,789
enjoy the benefit of serverless not just

00:29:03,320 --> 00:29:06,100
say I want to do service but then I'm

00:29:04,789 --> 00:29:08,450
going to spend 50% of my time

00:29:06,100 --> 00:29:10,309
understanding what's going on so using

00:29:08,450 --> 00:29:12,049
the proper tools can help you move

00:29:10,309 --> 00:29:14,450
faster with service and really enjoy all

00:29:12,049 --> 00:29:18,590
the benefits and eventually go to market

00:29:14,450 --> 00:29:26,570
faster so thank you if you have

00:29:18,590 --> 00:29:28,989
questions feel free yeah it actually is

00:29:26,570 --> 00:29:31,249
one of the tools provided by the ws for

00:29:28,989 --> 00:29:33,289
profiling of lambda functions so you can

00:29:31,249 --> 00:29:35,210
say I want to understand how much time

00:29:33,289 --> 00:29:37,190
I'm spending in each of my functions and

00:29:35,210 --> 00:29:39,230
you can start x-ray and then it will

00:29:37,190 --> 00:29:42,980
tell you oh the DynamoDB took this much

00:29:39,230 --> 00:29:45,080
time it's useful some we actually don't

00:29:42,980 --> 00:29:47,179
use it but some some companies use it

00:29:45,080 --> 00:29:48,679
for different measurements it doesn't

00:29:47,179 --> 00:29:50,929
really give you the entire picture of

00:29:48,679 --> 00:29:53,869
the end-to-end events because it only

00:29:50,929 --> 00:29:55,850
goes in the function and what's going on

00:29:53,869 --> 00:29:57,889
around that function and it's not you

00:29:55,850 --> 00:30:01,039
know a monitoring product it won't send

00:29:57,889 --> 00:30:03,679
you alerts it won't let you understand

00:30:01,039 --> 00:30:05,720
the application just the basic latency

00:30:03,679 --> 00:30:08,539
measurements so it's a tool that can be

00:30:05,720 --> 00:30:10,340
used usually with other tools so some

00:30:08,539 --> 00:30:21,619
people take x-ray that time they stream

00:30:10,340 --> 00:30:23,600
it somewhere stuff like this yeah that's

00:30:21,619 --> 00:30:25,669
the problem you don't manage counters

00:30:23,600 --> 00:30:27,739
you need to use a database or you need

00:30:25,669 --> 00:30:30,649
to use something like step functions

00:30:27,739 --> 00:30:33,200
that will do it for you you you don't

00:30:30,649 --> 00:30:36,830
store a variable in the memory of a

00:30:33,200 --> 00:30:38,779
function to use it as a counter also the

00:30:36,830 --> 00:30:40,100
cold start what is the cold start I mean

00:30:38,779 --> 00:30:42,139
the way it's all implemented is by

00:30:40,100 --> 00:30:43,580
containers so there is a container it's

00:30:42,139 --> 00:30:45,200
being set up and then your code is

00:30:43,580 --> 00:30:48,350
loaded and it's running and these

00:30:45,200 --> 00:30:50,210
containers are not always starting from

00:30:48,350 --> 00:30:52,190
fresh because they want to do it fast so

00:30:50,210 --> 00:30:53,899
they are staying there and then your

00:30:52,190 --> 00:30:55,940
variable will keep in the memory this is

00:30:53,899 --> 00:30:57,440
actually how we identify cold start in

00:30:55,940 --> 00:30:59,269
library we have a library that does

00:30:57,440 --> 00:31:02,659
instrumentation but you don't know when

00:30:59,269 --> 00:31:05,779
the container will die and it it happens

00:31:02,659 --> 00:31:07,850
between several minutes two hours but

00:31:05,779 --> 00:31:10,190
when it's gonna go fresh there is

00:31:07,850 --> 00:31:11,419
nothing left there so basically you

00:31:10,190 --> 00:31:12,669
don't want to use cold source you want

00:31:11,419 --> 00:31:15,679
to use an event-driven architecture

00:31:12,669 --> 00:31:29,000
where if you want to counter its you can

00:31:15,679 --> 00:31:30,860
go to a no SQL database for example to

00:31:29,000 --> 00:31:32,419
get distributed tracing in general in

00:31:30,860 --> 00:31:35,029
theory it's not possible to do it

00:31:32,419 --> 00:31:37,490
without going inside the code in a way

00:31:35,029 --> 00:31:40,549
you need to somehow tell someone what's

00:31:37,490 --> 00:31:43,340
going on specifically what we do we do

00:31:40,549 --> 00:31:45,620
automated instrumentation so we go

00:31:43,340 --> 00:31:47,570
inside the code automatically you can do

00:31:45,620 --> 00:31:50,480
it via you know plug into the deployment

00:31:47,570 --> 00:31:52,100
framework we are now partners of AWS

00:31:50,480 --> 00:31:54,110
lambda layers or no if you know it but

00:31:52,100 --> 00:31:56,240
basically you can have something already

00:31:54,110 --> 00:31:58,070
included in lambda before it's loaded so

00:31:56,240 --> 00:31:59,179
you can have us as well included in a

00:31:58,070 --> 00:32:02,509
lambda and then the code would build

00:31:59,179 --> 00:32:04,100
automatically instrumented so as you

00:32:02,509 --> 00:32:07,519
know as a developer as an Operations

00:32:04,100 --> 00:32:09,320
person it's it can be zero touch

00:32:07,519 --> 00:32:12,289
basically you don't have to change even

00:32:09,320 --> 00:32:13,730
your code repository it goes just when

00:32:12,289 --> 00:32:18,110
the court is going to production that's

00:32:13,730 --> 00:32:20,659
where the library goes in so if you use

00:32:18,110 --> 00:32:23,179
the layers there is lambda layers it's

00:32:20,659 --> 00:32:25,730
already in the AWS platform so when the

00:32:23,179 --> 00:32:27,649
lambda is loaded a library that you

00:32:25,730 --> 00:32:29,960
choose is already pre-loaded with it and

00:32:27,649 --> 00:32:32,120
then it goes inside so there you don't

00:32:29,960 --> 00:32:33,470
even have to be aware of course

00:32:32,120 --> 00:32:39,259
something's done sometimes you do want

00:32:33,470 --> 00:32:42,049
manual stuff if you need no technically

00:32:39,259 --> 00:32:44,120
it's a wrapper for the function but the

00:32:42,049 --> 00:32:46,730
way the code this change is automated so

00:32:44,120 --> 00:32:56,750
you don't need to annotate anything by

00:32:46,730 --> 00:33:01,049
your own your own group by

00:32:56,750 --> 00:33:06,990
videos or something like that view of

00:33:01,049 --> 00:33:09,090
the stock in your products you you

00:33:06,990 --> 00:33:12,179
really tackle the like I want to debunk

00:33:09,090 --> 00:33:16,830
the specific function how do you provide

00:33:12,179 --> 00:33:18,660
a way to get a high level your game yes

00:33:16,830 --> 00:33:19,940
so actually if you think about something

00:33:18,660 --> 00:33:23,400
like that

00:33:19,940 --> 00:33:25,410
right so this is the difference between

00:33:23,400 --> 00:33:28,020
going inside a function and going

00:33:25,410 --> 00:33:30,540
outside the application is exactly that

00:33:28,020 --> 00:33:32,940
the distributed approach I think what

00:33:30,540 --> 00:33:35,100
you mean is stuff around like not just

00:33:32,940 --> 00:33:37,679
functions but other services in AWI so I

00:33:35,100 --> 00:33:38,460
want a Molitor I don't know my tree or

00:33:37,679 --> 00:33:46,460
something like that

00:33:38,460 --> 00:33:51,290
is that what you mean series child of

00:33:46,460 --> 00:33:57,960
500 function how many five hundred I get

00:33:51,290 --> 00:34:01,530
those like yeah so this is something

00:33:57,960 --> 00:34:02,700
that is again is on the function level

00:34:01,530 --> 00:34:04,470
you can do it

00:34:02,700 --> 00:34:05,730
you don't need distributed tracing for

00:34:04,470 --> 00:34:07,049
that you can just look at the return

00:34:05,730 --> 00:34:08,730
value of the function you can put it in

00:34:07,049 --> 00:34:11,520
the log as you said and put it into

00:34:08,730 --> 00:34:13,679
something like a log aggregation service

00:34:11,520 --> 00:34:17,940
or you can use the metrics provided by

00:34:13,679 --> 00:34:20,070
the cloud provider in some ways our

00:34:17,940 --> 00:34:22,080
focus in the company is on APM so it's

00:34:20,070 --> 00:34:23,730
basically you know the whole application

00:34:22,080 --> 00:34:26,220
and this is one of the things that you

00:34:23,730 --> 00:34:28,230
can for example what you described you

00:34:26,220 --> 00:34:29,790
can do something like custom metrics you

00:34:28,230 --> 00:34:31,260
can send a custom metric from the front

00:34:29,790 --> 00:34:34,350
from the function every time it's

00:34:31,260 --> 00:34:37,169
running and then a money toll that the

00:34:34,350 --> 00:34:39,149
number of times you get this value in

00:34:37,169 --> 00:34:41,580
the metric is not more than X percent

00:34:39,149 --> 00:34:43,139
and then get alert this is one option to

00:34:41,580 --> 00:34:46,590
do it but like what you described is

00:34:43,139 --> 00:34:48,750
also a variable option but to connect

00:34:46,590 --> 00:34:50,940
these things together through the SNS to

00:34:48,750 --> 00:34:53,240
the dynamodb trigger and Kinesis trigger

00:34:50,940 --> 00:34:55,800
is the challenge that we are tackling

00:34:53,240 --> 00:34:58,590
because these things cannot be

00:34:55,800 --> 00:34:59,900
understood just from logs basically okay

00:34:58,590 --> 00:35:03,430
thank you

00:34:59,900 --> 00:35:09,390
[Applause]

00:35:03,430 --> 00:35:09,390

YouTube URL: https://www.youtube.com/watch?v=BuZgGOohGq4


