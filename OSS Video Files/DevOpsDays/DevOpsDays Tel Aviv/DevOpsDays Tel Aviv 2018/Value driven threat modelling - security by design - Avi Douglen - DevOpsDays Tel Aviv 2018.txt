Title: Value driven threat modelling - security by design - Avi Douglen - DevOpsDays Tel Aviv 2018
Publication date: 2019-01-03
Playlist: DevOpsDays Tel Aviv 2018
Description: 
	Threat Modeling is a great method to identify potential security flaws, part of any secure design. But instead of investing time + budget in a top-heavy, big-model-up-front threat modeling methodology, we can use a lightweight value-driven approach to embed security right into the agile dev process!
Captions: 
	00:00:05,180 --> 00:00:10,380
recently as the study came out

00:00:07,770 --> 00:00:12,509
statistics say that for what every 100

00:00:10,380 --> 00:00:15,269
developers there's only one security

00:00:12,509 --> 00:00:17,820
person now that's great for job

00:00:15,269 --> 00:00:20,520
stability boy that's great for you know

00:00:17,820 --> 00:00:23,039
my future that's fine but it's not very

00:00:20,520 --> 00:00:24,359
sustainable it's not very healthy and

00:00:23,039 --> 00:00:25,369
you know what it's not even that fun for

00:00:24,359 --> 00:00:28,859
me either

00:00:25,369 --> 00:00:32,460
so my point is I'm gonna tell you right

00:00:28,859 --> 00:00:34,980
now up front I want everybody here now

00:00:32,460 --> 00:00:36,780
on all developers to start doing threat

00:00:34,980 --> 00:00:39,120
modeling threat modeling is hands down

00:00:36,780 --> 00:00:41,700
time and time again been proven to be

00:00:39,120 --> 00:00:43,760
the most effective security activity you

00:00:41,700 --> 00:00:46,469
can do to ensure the level of security

00:00:43,760 --> 00:00:48,450
of your of your system of your

00:00:46,469 --> 00:00:49,980
application who here knows ever heard of

00:00:48,450 --> 00:00:52,980
threat modeling is Dell threat modeling

00:00:49,980 --> 00:00:54,329
is that modeling done for you a few of

00:00:52,980 --> 00:00:56,250
you I'm gonna go through it and I'm

00:00:54,329 --> 00:00:58,920
gonna explain what threat modeling is

00:00:56,250 --> 00:01:01,800
how to do it and why you would want to

00:00:58,920 --> 00:01:03,660
do it but then I'm gonna stake it take a

00:01:01,800 --> 00:01:05,750
step back and I'm gonna tell you what's

00:01:03,660 --> 00:01:07,560
wrong with everything that I just said

00:01:05,750 --> 00:01:10,229
you know I've been doing this for a lot

00:01:07,560 --> 00:01:11,310
of years try modeling and security and

00:01:10,229 --> 00:01:13,380
I've been on both sides of the table

00:01:11,310 --> 00:01:15,630
that's the expensive consultant that

00:01:13,380 --> 00:01:17,100
comes in to do the threat modeling or

00:01:15,630 --> 00:01:18,659
the internal security team I've been on

00:01:17,100 --> 00:01:22,920
the developer side that has had threat

00:01:18,659 --> 00:01:24,479
modeling done to me and you know time

00:01:22,920 --> 00:01:26,280
and time again a lot of the same

00:01:24,479 --> 00:01:30,210
objections keep coming up a lot of the

00:01:26,280 --> 00:01:31,650
same issues keep recurring so I'm gonna

00:01:30,210 --> 00:01:32,850
take a page out of Stephens book from

00:01:31,650 --> 00:01:34,920
this morning and actually listen to

00:01:32,850 --> 00:01:36,600
people and say you know what okay maybe

00:01:34,920 --> 00:01:38,759
these are actually valid reasons why we

00:01:36,600 --> 00:01:40,710
can't integrate threat modeling in the

00:01:38,759 --> 00:01:42,540
process we're going to go through some

00:01:40,710 --> 00:01:44,369
of those objections and I'm gonna answer

00:01:42,540 --> 00:01:47,040
them and I'm going to give you a better

00:01:44,369 --> 00:01:49,229
process that can actually integrate very

00:01:47,040 --> 00:01:53,759
well with your DevOps process with your

00:01:49,229 --> 00:01:55,829
agile workflow the trick is to focus up

00:01:53,759 --> 00:01:57,479
by using a lightweight threat modeling

00:01:55,829 --> 00:01:58,740
methodology or lightweight threat

00:01:57,479 --> 00:02:01,200
modeling approach what I'm gonna show

00:01:58,740 --> 00:02:04,200
you and the key to it all is by focusing

00:02:01,200 --> 00:02:05,579
on business value ironically not by

00:02:04,200 --> 00:02:06,659
focusing on all the threats and the

00:02:05,579 --> 00:02:09,420
fallacious attacks and things like that

00:02:06,659 --> 00:02:11,430
but focusing on the business value now

00:02:09,420 --> 00:02:12,569
this is really important to do one way

00:02:11,430 --> 00:02:13,950
or the other because if you don't

00:02:12,569 --> 00:02:16,020
integrate

00:02:13,950 --> 00:02:17,640
security at the beginning gonna wind up

00:02:16,020 --> 00:02:19,950
getting breached fixing it

00:02:17,640 --> 00:02:23,099
breach fix patch breech patch breech

00:02:19,950 --> 00:02:24,870
patch and you're not getting anywhere so

00:02:23,099 --> 00:02:26,819
let me introduce myself now that's my

00:02:24,870 --> 00:02:28,739
internet face over there my contact

00:02:26,819 --> 00:02:30,360
details on Twitter as a secretary and

00:02:28,739 --> 00:02:31,500
the important things you need to know

00:02:30,360 --> 00:02:33,989
about me if you ever want to buy me a

00:02:31,500 --> 00:02:36,510
drink I like my whiskey stout I like

00:02:33,989 --> 00:02:38,519
what my whiskey smoky my beer style I

00:02:36,510 --> 00:02:40,709
like my coffee black it's very important

00:02:38,519 --> 00:02:42,060
I do have five kids at home so you know

00:02:40,709 --> 00:02:43,230
it's very important the other things you

00:02:42,060 --> 00:02:45,690
might want to know about me is that I

00:02:43,230 --> 00:02:48,510
have security consulting booty called

00:02:45,690 --> 00:02:50,940
bounce security we do security research

00:02:48,510 --> 00:02:52,230
development of security modules security

00:02:50,940 --> 00:02:54,840
architecture things like that

00:02:52,230 --> 00:02:56,250
I'm also the moderator of security Stock

00:02:54,840 --> 00:02:58,410
Exchange I've been here have a profile

00:02:56,250 --> 00:03:00,360
of security and security Stock Exchange

00:02:58,410 --> 00:03:02,280
anybody heard of it it's exactly like

00:03:00,360 --> 00:03:05,750
Stack Overflow but for security

00:03:02,280 --> 00:03:07,920
questions really recommend opening up a

00:03:05,750 --> 00:03:10,319
account there I'm also one of the

00:03:07,920 --> 00:03:12,420
leaders of the OS Israel chapter and the

00:03:10,319 --> 00:03:14,160
co-founder and the project leader of the

00:03:12,420 --> 00:03:18,239
threat modeling project for OSP

00:03:14,160 --> 00:03:19,530
anybody here know Hospice that's great

00:03:18,239 --> 00:03:20,880
for those that not I'm gonna give you a

00:03:19,530 --> 00:03:22,680
quick rundown I also spent some time

00:03:20,880 --> 00:03:24,510
volunteering for a high school mentoring

00:03:22,680 --> 00:03:27,090
some students and cyber topics used to

00:03:24,510 --> 00:03:28,380
be a program very rewarding very

00:03:27,090 --> 00:03:30,180
fulfilling I recommend it highly for

00:03:28,380 --> 00:03:31,560
everybody those are you not familiar oh

00:03:30,180 --> 00:03:34,139
so I'll tell you quickly what it is it's

00:03:31,560 --> 00:03:36,870
an open source community open web and

00:03:34,139 --> 00:03:39,389
application security project open source

00:03:36,870 --> 00:03:43,109
community focused on software security

00:03:39,389 --> 00:03:44,670
building software purely now this is

00:03:43,109 --> 00:03:47,010
based on both libraries that you can

00:03:44,670 --> 00:03:49,350
plug into your software and lots of

00:03:47,010 --> 00:03:51,420
different kinds of languages tools that

00:03:49,350 --> 00:03:52,620
you could use to scan your application

00:03:51,420 --> 00:03:55,079
or to build your application or all

00:03:52,620 --> 00:03:57,540
kinds of things and a lot of guides your

00:03:55,079 --> 00:03:59,549
coding guides testing guide a lot of

00:03:57,540 --> 00:04:01,200
things like that including the OS pop 10

00:03:59,549 --> 00:04:04,230
which a lot of people have heard of the

00:04:01,200 --> 00:04:06,200
top 10 most vulnerable most common

00:04:04,230 --> 00:04:08,459
vulnerabilities and web applications

00:04:06,200 --> 00:04:09,780
here in Israel we actually have a really

00:04:08,459 --> 00:04:12,720
great chapter it's been around for about

00:04:09,780 --> 00:04:14,400
a dozen years we have of every year we

00:04:12,720 --> 00:04:16,590
have a fantastic app secular conference

00:04:14,400 --> 00:04:19,079
it was just recently September we had

00:04:16,590 --> 00:04:21,180
over 800 people attending the conference

00:04:19,079 --> 00:04:23,940
and in addition we also had an

00:04:21,180 --> 00:04:26,640
additional day of free training for

00:04:23,940 --> 00:04:27,430
developers on secure coding entire day

00:04:26,640 --> 00:04:30,970
of how to

00:04:27,430 --> 00:04:33,250
right code better free please come next

00:04:30,970 --> 00:04:35,500
time in 2019 we're actually we're

00:04:33,250 --> 00:04:38,259
requested to host the wasp

00:04:35,500 --> 00:04:41,860
global event known as apps like Europe

00:04:38,259 --> 00:04:43,180
here in tel-aviv next May so hopefully

00:04:41,860 --> 00:04:45,400
some of you will be interested in seeing

00:04:43,180 --> 00:04:49,840
that and you're gonna have a hundreds of

00:04:45,400 --> 00:04:51,039
people come in take a look at that all

00:04:49,840 --> 00:04:54,580
right let's talk about threat modeling

00:04:51,039 --> 00:04:56,380
enough about me what is threat modeling

00:04:54,580 --> 00:04:58,150
modeling could be a framework

00:04:56,380 --> 00:05:00,550
methodology approach does not what you

00:04:58,150 --> 00:05:03,220
call it it comes down to doing a

00:05:00,550 --> 00:05:06,310
security based analysis taking your

00:05:03,220 --> 00:05:08,110
design your architecture and analyzing

00:05:06,310 --> 00:05:10,300
it for what security issues might

00:05:08,110 --> 00:05:12,639
possibly be this is long before you even

00:05:10,300 --> 00:05:14,889
get to start with a penetration test or

00:05:12,639 --> 00:05:17,919
any things like that this is a simply

00:05:14,889 --> 00:05:20,260
design activity architectural analysis

00:05:17,919 --> 00:05:22,570
what are the security issues when we

00:05:20,260 --> 00:05:24,400
understand the issues we can prioritize

00:05:22,570 --> 00:05:29,080
them we all understand the risk and will

00:05:24,400 --> 00:05:30,310
understand how to fix them why do we

00:05:29,080 --> 00:05:32,380
need to do threat modeling let's just

00:05:30,310 --> 00:05:34,840
you know build it at best we'll run a

00:05:32,380 --> 00:05:37,000
scan it's compliant you know it passes

00:05:34,840 --> 00:05:39,430
complex that's all we need to do except

00:05:37,000 --> 00:05:41,470
that it's a lot more effective so number

00:05:39,430 --> 00:05:42,909
one using threat modeling we could find

00:05:41,470 --> 00:05:44,409
the unexpected attacks if you're doing

00:05:42,909 --> 00:05:47,110
pen testing you're testing for the

00:05:44,409 --> 00:05:48,789
things that you expect obviously the

00:05:47,110 --> 00:05:50,710
things that you know about using threat

00:05:48,789 --> 00:05:51,729
modeling you can uncover a whole bunch

00:05:50,710 --> 00:05:54,400
of other things that you wouldn't have

00:05:51,729 --> 00:05:57,010
expected otherwise it helps you

00:05:54,400 --> 00:06:00,430
understand the risk a whole lot better

00:05:57,010 --> 00:06:02,590
the risk of the potential attacks to

00:06:00,430 --> 00:06:06,669
help understand what could possibly

00:06:02,590 --> 00:06:09,400
happen with it and you get to prioritize

00:06:06,669 --> 00:06:11,139
accordingly now that lets you focus on

00:06:09,400 --> 00:06:12,340
the important things and just as

00:06:11,139 --> 00:06:14,380
important let you skip the less

00:06:12,340 --> 00:06:16,990
important things instead of well we have

00:06:14,380 --> 00:06:18,430
to fix everything no I understood the

00:06:16,990 --> 00:06:20,199
idea threat modeling I understand the

00:06:18,430 --> 00:06:21,639
risk I'm willing to accept that I'm

00:06:20,199 --> 00:06:23,289
gonna stick that on the side and not

00:06:21,639 --> 00:06:26,590
bother with that now because it's not a

00:06:23,289 --> 00:06:30,250
high enough risk it does help a lot with

00:06:26,590 --> 00:06:31,810
communication sharing what risk profile

00:06:30,250 --> 00:06:32,800
but these are the things that we care

00:06:31,810 --> 00:06:34,570
about these are the fact that we're

00:06:32,800 --> 00:06:36,460
gonna take care about these are how to

00:06:34,570 --> 00:06:38,289
work securely these are this is how you

00:06:36,460 --> 00:06:41,550
don't and obviously everything is

00:06:38,289 --> 00:06:44,020
documented why we built these things

00:06:41,550 --> 00:06:45,700
so typically we're talking about classic

00:06:44,020 --> 00:06:47,170
fret talk about threat modeling you look

00:06:45,700 --> 00:06:49,660
on Wikipedia and you look I know us we

00:06:47,170 --> 00:06:51,040
can find any source you're gonna find

00:06:49,660 --> 00:06:52,900
how to do threat modeling you're gonna

00:06:51,040 --> 00:06:55,870
find typically most of these things

00:06:52,900 --> 00:06:58,270
focusing mostly on data flows if you

00:06:55,870 --> 00:06:59,620
understand the attack surface how the

00:06:58,270 --> 00:07:02,260
attacker can get into the application

00:06:59,620 --> 00:07:04,570
where the data comes from that's already

00:07:02,260 --> 00:07:08,080
going to be most of the attacks right

00:07:04,570 --> 00:07:09,640
that's going to be most of the the ways

00:07:08,080 --> 00:07:12,220
that attackers will try to penetrate

00:07:09,640 --> 00:07:14,050
your system typically you're going to

00:07:12,220 --> 00:07:18,580
want to protect your assets your

00:07:14,050 --> 00:07:20,050
database your files your bank accounts

00:07:18,580 --> 00:07:21,520
credit cards whatever it whatever your

00:07:20,050 --> 00:07:24,250
assets are gonna focus on protecting

00:07:21,520 --> 00:07:27,100
those and you do this typically by

00:07:24,250 --> 00:07:29,140
locating your trust boundaries for

00:07:27,100 --> 00:07:30,880
example anything from outside the system

00:07:29,140 --> 00:07:33,520
has to cross a trust boundary to get

00:07:30,880 --> 00:07:35,680
into the system anything from your front

00:07:33,520 --> 00:07:37,210
end has to cross the trust boundary to

00:07:35,680 --> 00:07:40,150
get to the back end machines or to a

00:07:37,210 --> 00:07:42,880
third-party service very classic

00:07:40,150 --> 00:07:44,890
usually this is done using data DFT data

00:07:42,880 --> 00:07:46,660
flow diagrams but you do this with

00:07:44,890 --> 00:07:48,870
really any diagrams that you have most

00:07:46,660 --> 00:07:51,580
people don't use DFDS nowadays that much

00:07:48,870 --> 00:07:52,900
if you do that's great if you have

00:07:51,580 --> 00:07:55,450
something else that works - anything

00:07:52,900 --> 00:07:57,220
visual is very useful if you take a look

00:07:55,450 --> 00:07:59,290
here there's a typical D of D you have

00:07:57,220 --> 00:08:01,330
here the process you have over here your

00:07:59,290 --> 00:08:03,880
database you have over there your audit

00:08:01,330 --> 00:08:06,100
log your policies and of course over

00:08:03,880 --> 00:08:08,650
here you have another user coming from

00:08:06,100 --> 00:08:11,530
outside the system Crossing a trust

00:08:08,650 --> 00:08:14,140
boundary to send a request to withdraw

00:08:11,530 --> 00:08:16,990
money whatever that is crossing the

00:08:14,140 --> 00:08:18,280
trust boundary and another response so

00:08:16,990 --> 00:08:20,020
we could take a look at all these data

00:08:18,280 --> 00:08:21,700
flows and obviously the one crossing the

00:08:20,020 --> 00:08:22,930
trust boundary is gonna be the most

00:08:21,700 --> 00:08:26,550
interesting that's what we're gonna

00:08:22,930 --> 00:08:31,690
start looking at very basic very simple

00:08:26,550 --> 00:08:34,120
Fred modeling usually look like this is

00:08:31,690 --> 00:08:36,849
four-step process before the four-step

00:08:34,120 --> 00:08:38,590
process is a pre step of scoping the

00:08:36,849 --> 00:08:39,610
model these are the parts of the

00:08:38,590 --> 00:08:41,620
architecture that we're gonna include

00:08:39,610 --> 00:08:43,510
these are the parts that were not how

00:08:41,620 --> 00:08:44,950
deep we're gonna go very basic

00:08:43,510 --> 00:08:47,940
understanding which part of the

00:08:44,950 --> 00:08:50,050
architecture are in our threat model

00:08:47,940 --> 00:08:52,600
after we understand what we're modeling

00:08:50,050 --> 00:08:54,850
we do step number one decompose the

00:08:52,600 --> 00:08:56,980
application we take the design so

00:08:54,850 --> 00:08:59,350
design the architecture and we break it

00:08:56,980 --> 00:09:01,649
down to its parts to each of the moving

00:08:59,350 --> 00:09:03,730
parts the modules the components

00:09:01,649 --> 00:09:06,430
everything that has a data flow between

00:09:03,730 --> 00:09:09,819
it basically a long line so that we

00:09:06,430 --> 00:09:11,050
build the dfd okay we understand we fill

00:09:09,819 --> 00:09:12,490
that out with as much information we

00:09:11,050 --> 00:09:15,399
have to understand what protocols are

00:09:12,490 --> 00:09:17,380
there and so on based on that now we can

00:09:15,399 --> 00:09:20,670
go and do step two which is identify the

00:09:17,380 --> 00:09:22,750
threats we understand based on this

00:09:20,670 --> 00:09:24,819
architecture these components this

00:09:22,750 --> 00:09:26,649
component might have this kind of threat

00:09:24,819 --> 00:09:27,759
approach attached to it kind of a

00:09:26,649 --> 00:09:29,110
component will have that kind of a

00:09:27,759 --> 00:09:30,940
threat or we look at that a moment

00:09:29,110 --> 00:09:32,500
understand once we understand the

00:09:30,940 --> 00:09:35,259
threats we could understand the risk

00:09:32,500 --> 00:09:38,980
level for each one based on step two we

00:09:35,259 --> 00:09:40,509
can then depth step three rather easy to

00:09:38,980 --> 00:09:41,709
define the countermeasures we understand

00:09:40,509 --> 00:09:44,139
but the threat is we can now define a

00:09:41,709 --> 00:09:46,449
fix that's usually a lot easier look it

00:09:44,139 --> 00:09:46,930
up on stackoverflow security Stack

00:09:46,449 --> 00:09:48,670
Exchange

00:09:46,930 --> 00:09:51,220
and step number four kind of an

00:09:48,670 --> 00:09:53,500
introspective we analyze the result did

00:09:51,220 --> 00:09:55,899
does the DFT currently represent the

00:09:53,500 --> 00:09:58,300
actual system design very often it's not

00:09:55,899 --> 00:10:00,970
did we capture enough detail did we

00:09:58,300 --> 00:10:02,949
identify all the threats did we can fix

00:10:00,970 --> 00:10:05,769
all the threats do we fix the right

00:10:02,949 --> 00:10:08,319
threats does the fix that we designed

00:10:05,769 --> 00:10:09,880
actually completely fix the three fix

00:10:08,319 --> 00:10:14,470
the threat does it introduce any new

00:10:09,880 --> 00:10:16,870
threats so it's kind of a cycle here now

00:10:14,470 --> 00:10:19,000
one way to identify the threats what are

00:10:16,870 --> 00:10:20,980
the common ways using stride was

00:10:19,000 --> 00:10:22,209
developed in Microsoft stride is

00:10:20,980 --> 00:10:23,620
spoofing tampering repudiation

00:10:22,209 --> 00:10:25,029
information disclosure Dolf service and

00:10:23,620 --> 00:10:27,250
elevation of privileges I'll go through

00:10:25,029 --> 00:10:30,069
them one by one this is a set of kind of

00:10:27,250 --> 00:10:33,670
a classification of the six categories

00:10:30,069 --> 00:10:35,769
of the attackers goals from a technical

00:10:33,670 --> 00:10:37,360
perspective and almost this pretty holds

00:10:35,769 --> 00:10:39,910
up pretty well over years that's been

00:10:37,360 --> 00:10:41,279
around and holds up pretty well spoofing

00:10:39,910 --> 00:10:43,480
pretending to be somebody or not

00:10:41,279 --> 00:10:46,209
tampering changing data you shouldn't

00:10:43,480 --> 00:10:48,970
have access to repudiation claiming you

00:10:46,209 --> 00:10:50,529
didn't do something that you did for

00:10:48,970 --> 00:10:52,060
example the bank claims that I

00:10:50,529 --> 00:10:53,889
transferred money from my account to a

00:10:52,060 --> 00:10:56,350
third party account I would say no it

00:10:53,889 --> 00:10:59,069
was it now the bank has to go and prove

00:10:56,350 --> 00:11:01,209
that it was information disclosure

00:10:59,069 --> 00:11:03,490
reading data that you shouldn't have

00:11:01,209 --> 00:11:05,139
access to denial of service blocking

00:11:03,490 --> 00:11:07,360
access from users that should have

00:11:05,139 --> 00:11:09,160
access to the data and evasion of

00:11:07,360 --> 00:11:10,300
privileges basically do

00:11:09,160 --> 00:11:13,120
anything that you shouldn't be allowed

00:11:10,300 --> 00:11:15,250
to do administrative activities or

00:11:13,120 --> 00:11:17,500
reading somebody else's account no note

00:11:15,250 --> 00:11:19,389
this is kind of classification you don't

00:11:17,500 --> 00:11:21,670
need to get hung up on categorization if

00:11:19,389 --> 00:11:24,310
you find if it doesn't matter which

00:11:21,670 --> 00:11:26,139
category it's in don't start arguing

00:11:24,310 --> 00:11:28,000
well as if I'm reading somebody else's

00:11:26,139 --> 00:11:28,990
account that's a disclosure but I'm also

00:11:28,000 --> 00:11:30,009
doing something that I shouldn't be like

00:11:28,990 --> 00:11:32,980
don't worry about it

00:11:30,009 --> 00:11:36,180
this is just to help you bring some up

00:11:32,980 --> 00:11:41,709
with the ideas of what could possibly be

00:11:36,180 --> 00:11:43,750
threats and to achieve that goal now

00:11:41,709 --> 00:11:46,959
what we do is we take that stride we do

00:11:43,750 --> 00:11:49,569
we apply it per each element in our

00:11:46,959 --> 00:11:51,490
design in our DFT so for example we take

00:11:49,569 --> 00:11:54,040
the browser and if the browser sending

00:11:51,490 --> 00:11:56,470
an HTTP request to the web server and we

00:11:54,040 --> 00:11:58,149
start going through stride is there

00:11:56,470 --> 00:12:00,069
spoofing threats here well if it wasn't

00:11:58,149 --> 00:12:02,680
HTTP let's ignore the s for a second if

00:12:00,069 --> 00:12:04,360
it wasn't HTTPS I could say well I could

00:12:02,680 --> 00:12:06,670
put up my own web server and pretend to

00:12:04,360 --> 00:12:08,680
be the actual application or I could

00:12:06,670 --> 00:12:11,560
pretend to be a different user spoofing

00:12:08,680 --> 00:12:13,779
attack tampering if it's not HTTP sure

00:12:11,560 --> 00:12:16,180
if I'm if the user is accessing my

00:12:13,779 --> 00:12:18,639
system it at a cafe it opened a Wi-Fi

00:12:16,180 --> 00:12:20,439
hotspot I might be able to go into that

00:12:18,639 --> 00:12:22,569
and change you know tamper with the data

00:12:20,439 --> 00:12:24,189
and you'll see something different and

00:12:22,569 --> 00:12:26,620
get the wrong information or send the

00:12:24,189 --> 00:12:28,569
wrong amount of transfer and so on and

00:12:26,620 --> 00:12:31,240
so on through the whole ride for each

00:12:28,569 --> 00:12:33,069
element but we can also apply that for

00:12:31,240 --> 00:12:34,779
the backend elements let's take a look

00:12:33,069 --> 00:12:35,589
how the application server talks to the

00:12:34,779 --> 00:12:37,779
messaging bus

00:12:35,589 --> 00:12:39,790
now usually back-end applicant reprise

00:12:37,779 --> 00:12:42,130
applications don't have encryption on

00:12:39,790 --> 00:12:44,230
the wire here or really any kind of

00:12:42,130 --> 00:12:47,680
back-end authentication very often so

00:12:44,230 --> 00:12:50,620
let's ask spoofing so number one can I

00:12:47,680 --> 00:12:52,509
pretend to be the messaging bus and the

00:12:50,620 --> 00:12:55,990
application server will send its

00:12:52,509 --> 00:12:57,550
messages to me instead all right can I

00:12:55,990 --> 00:12:59,800
pretend to be the application server and

00:12:57,550 --> 00:13:02,559
send the wrong messages to the actual

00:12:59,800 --> 00:13:04,029
messaging bus can I tap on with a

00:13:02,559 --> 00:13:05,439
messages being sent between the

00:13:04,029 --> 00:13:08,709
applications server in the messaging bus

00:13:05,439 --> 00:13:10,449
or the responses or if this is a message

00:13:08,709 --> 00:13:13,389
queue maybe I can interfere with the

00:13:10,449 --> 00:13:16,029
queue there can I go and I go through

00:13:13,389 --> 00:13:18,309
the entire stride for each and every

00:13:16,029 --> 00:13:20,439
element and this could produce a huge

00:13:18,309 --> 00:13:22,029
matrix for each element each data flow

00:13:20,439 --> 00:13:23,260
in the system you're going to get a few

00:13:22,029 --> 00:13:25,990
key a few threats for each

00:13:23,260 --> 00:13:29,140
category of dried or maybe last but

00:13:25,990 --> 00:13:30,730
you'll get huge matrix of all possible

00:13:29,140 --> 00:13:32,950
threats now you can apply this very well

00:13:30,730 --> 00:13:34,680
the really great thing there is that if

00:13:32,950 --> 00:13:37,450
you go through this methodologically

00:13:34,680 --> 00:13:38,890
you're gonna have a pretty good view

00:13:37,450 --> 00:13:41,080
that these are the possible threats that

00:13:38,890 --> 00:13:41,410
could happen in your system if you fix

00:13:41,080 --> 00:13:44,170
them

00:13:41,410 --> 00:13:47,980
you're probably usually safe if you

00:13:44,170 --> 00:13:48,940
don't well it's pretty expected that

00:13:47,980 --> 00:13:51,070
those are the threats that somebody's

00:13:48,940 --> 00:13:52,750
gonna attack you with now if you don't

00:13:51,070 --> 00:13:54,610
have a DFT you could apply this to a

00:13:52,750 --> 00:13:56,140
process diagram or really any kind of

00:13:54,610 --> 00:14:00,070
diagram you have you still probably the

00:13:56,140 --> 00:14:03,810
entire stret a stride framework to each

00:14:00,070 --> 00:14:07,030
element here now that's really nice

00:14:03,810 --> 00:14:09,370
another approach is using what's called

00:14:07,030 --> 00:14:11,380
attack trees so we take over here the

00:14:09,370 --> 00:14:13,060
logical not detective stride was the

00:14:11,380 --> 00:14:16,900
technical goals now we're gonna take the

00:14:13,060 --> 00:14:18,070
logical goal that the attacker has in

00:14:16,900 --> 00:14:19,780
the system for example this is a

00:14:18,070 --> 00:14:21,850
messaging application let's say Facebook

00:14:19,780 --> 00:14:23,890
messages the attacker may be able to

00:14:21,850 --> 00:14:25,120
read other users messages well if it's

00:14:23,890 --> 00:14:26,080
Facebook messages I could probably just

00:14:25,120 --> 00:14:30,100
pay the money and they'll send me the

00:14:26,080 --> 00:14:31,360
messages but um current events aside but

00:14:30,100 --> 00:14:32,800
then you have here a whole bunch of

00:14:31,360 --> 00:14:35,470
different approaches a few different

00:14:32,800 --> 00:14:38,290
vectors that the attacker could use to

00:14:35,470 --> 00:14:40,150
gain access to his end goal for example

00:14:38,290 --> 00:14:42,820
might be able to use SQL injection or

00:14:40,150 --> 00:14:46,480
authorization bypass or the browser

00:14:42,820 --> 00:14:48,550
history might cash messages now for each

00:14:46,480 --> 00:14:51,040
one of these vectors I can see here a

00:14:48,550 --> 00:14:52,620
countermeasure attached I'm going to do

00:14:51,040 --> 00:14:54,490
a data validation I'm going to do

00:14:52,620 --> 00:14:56,440
parameterize queries I'm going to do

00:14:54,490 --> 00:14:58,450
authorization checks and so on

00:14:56,440 --> 00:14:59,860
and for each one so here we have a few

00:14:58,450 --> 00:15:01,900
counter measures that you need more than

00:14:59,860 --> 00:15:03,700
one counter measure fantastic now very

00:15:01,900 --> 00:15:06,580
easily you could see over here there's a

00:15:03,700 --> 00:15:08,770
leaf that hat does not have any counter

00:15:06,580 --> 00:15:10,780
measure attached well that's an actual

00:15:08,770 --> 00:15:12,460
threat we need to go and fix that that

00:15:10,780 --> 00:15:14,920
we're going to go and mitigate right now

00:15:12,460 --> 00:15:16,330
and now we understand exactly how the

00:15:14,920 --> 00:15:18,270
attacker is gonna try and breach the

00:15:16,330 --> 00:15:20,830
system that's a lot easier fix

00:15:18,270 --> 00:15:23,350
interestingly this is also very good for

00:15:20,830 --> 00:15:25,810
testing I don't need to try and test

00:15:23,350 --> 00:15:27,370
every possible way to get access to

00:15:25,810 --> 00:15:29,110
another users messages I'm gonna test

00:15:27,370 --> 00:15:31,210
SQL injection I'm going to test

00:15:29,110 --> 00:15:32,890
authorization checks this is very

00:15:31,210 --> 00:15:35,620
testable we're off the test the unknown

00:15:32,890 --> 00:15:37,120
this should be implemented if it's not

00:15:35,620 --> 00:15:38,530
implemented correctly that's easy

00:15:37,120 --> 00:15:40,840
and that's a functional test that's a

00:15:38,530 --> 00:15:42,580
lot easier to do another very

00:15:40,840 --> 00:15:44,290
interesting approach is called pasta we

00:15:42,580 --> 00:15:46,600
just had a really good lunch so I want

00:15:44,290 --> 00:15:49,840
to have to not making anybody hungry I

00:15:46,600 --> 00:15:52,210
think the one of the creators was

00:15:49,840 --> 00:15:53,740
Italian so he came up with pasta process

00:15:52,210 --> 00:15:55,660
for attack simulation and threat

00:15:53,740 --> 00:15:58,270
analysis okay this is a risk based

00:15:55,660 --> 00:16:01,510
method risk based methodology it has a

00:15:58,270 --> 00:16:05,740
lot more statistics and data big data

00:16:01,510 --> 00:16:09,280
information and threat Intel and a whole

00:16:05,740 --> 00:16:10,810
lot more rigor involved in this process

00:16:09,280 --> 00:16:12,820
and you're gonna be very rigorous and

00:16:10,810 --> 00:16:14,650
not just go through okay I think there's

00:16:12,820 --> 00:16:17,260
a few threats here it's based on data

00:16:14,650 --> 00:16:18,790
statistics you get a lot more hard

00:16:17,260 --> 00:16:20,800
analysis which is really cool and it's

00:16:18,790 --> 00:16:24,160
done by using a seven seven stage

00:16:20,800 --> 00:16:26,110
process this same four stages before is

00:16:24,160 --> 00:16:27,610
broken down in a lot more detail and

00:16:26,110 --> 00:16:30,160
seven stages I'm not going to go through

00:16:27,610 --> 00:16:33,340
the whole thing now it's pretty high-end

00:16:30,160 --> 00:16:36,430
pretty rigorous pretty heavy now this is

00:16:33,340 --> 00:16:39,520
fantastic for security team right it's

00:16:36,430 --> 00:16:42,610
pretty good for a CEO of international

00:16:39,520 --> 00:16:46,300
bank it's amazing for a chief risk

00:16:42,610 --> 00:16:51,580
officer of a fortune 500 you know it's

00:16:46,300 --> 00:16:53,950
not so good for thank you it's not good

00:16:51,580 --> 00:16:56,140
for developers let's take a look at why

00:16:53,950 --> 00:16:57,400
now I spent as I said I spent a lot of

00:16:56,140 --> 00:17:01,060
years doing this hearing the same thing

00:16:57,400 --> 00:17:02,260
and at some point just listen and here's

00:17:01,060 --> 00:17:04,630
me listening to what developers

00:17:02,260 --> 00:17:07,060
including myself at some point have said

00:17:04,630 --> 00:17:11,890
why I cannot do any of these processes

00:17:07,060 --> 00:17:12,670
as part of my development workflow so

00:17:11,890 --> 00:17:14,709
let's take a look at some of the

00:17:12,670 --> 00:17:16,569
objections number one of them takes a

00:17:14,709 --> 00:17:18,430
lot of time no doubt about that right I

00:17:16,569 --> 00:17:20,140
mean I could send it away to my security

00:17:18,430 --> 00:17:22,420
team and get an answer back in three

00:17:20,140 --> 00:17:24,459
weeks or send it out to an expensive

00:17:22,420 --> 00:17:27,490
consultant and you know two months work

00:17:24,459 --> 00:17:28,990
and meanwhile we've moved on right yeah

00:17:27,490 --> 00:17:31,180
you could take up a lot of developer

00:17:28,990 --> 00:17:32,950
time that's great but we're working in

00:17:31,180 --> 00:17:33,970
two weeks prints here we're doing

00:17:32,950 --> 00:17:36,700
continuous integration continuous

00:17:33,970 --> 00:17:37,870
deployment we have time for you and

00:17:36,700 --> 00:17:40,060
while this threat modeling every time we

00:17:37,870 --> 00:17:41,010
develop a new feature and something like

00:17:40,060 --> 00:17:43,030
that

00:17:41,010 --> 00:17:45,520
security is everybody's job anybody here

00:17:43,030 --> 00:17:47,850
that it's kind of annoying whose job

00:17:45,520 --> 00:17:50,940
here is security

00:17:47,850 --> 00:17:53,340
yeah yeah I'm sure a lot of you your

00:17:50,940 --> 00:17:54,750
real job is actually DevOps and somebody

00:17:53,340 --> 00:17:58,350
told you well now your job is also

00:17:54,750 --> 00:18:01,170
security well um it's not really true

00:17:58,350 --> 00:18:03,360
developers job is to develop code to

00:18:01,170 --> 00:18:06,270
help DevOps job is to do DevOps the

00:18:03,360 --> 00:18:08,610
point is to add value to the system that

00:18:06,270 --> 00:18:11,600
value to other organization developing

00:18:08,610 --> 00:18:16,200
features developing user experience

00:18:11,600 --> 00:18:18,960
developing better value now developers

00:18:16,200 --> 00:18:20,610
already have eight bosses eight boss

00:18:18,960 --> 00:18:22,080
it's Bob right

00:18:20,610 --> 00:18:24,780
I don't think security needs to be

00:18:22,080 --> 00:18:26,940
number nine sure you know it's one of

00:18:24,780 --> 00:18:28,590
the forces that you need to contend with

00:18:26,940 --> 00:18:29,610
is whether responsibilities you need to

00:18:28,590 --> 00:18:32,130
deal with but it's not your job

00:18:29,610 --> 00:18:34,920
anybody's job unless it's unless it's

00:18:32,130 --> 00:18:36,030
literally your job now think like an

00:18:34,920 --> 00:18:37,950
attacker I don't know everybody's heard

00:18:36,030 --> 00:18:39,930
this is particularly insidious because

00:18:37,950 --> 00:18:41,130
it sounds good just think like an attack

00:18:39,930 --> 00:18:42,270
on come up with everything that the

00:18:41,130 --> 00:18:44,460
attacker is going to try and do against

00:18:42,270 --> 00:18:46,170
your application except you know it

00:18:44,460 --> 00:18:47,550
doesn't give very much guidance it's not

00:18:46,170 --> 00:18:48,840
very helpful now many people have been

00:18:47,550 --> 00:18:50,760
trained to think like an attacker we're

00:18:48,840 --> 00:18:53,400
doing guesswork and what the attacker

00:18:50,760 --> 00:18:55,430
wants we can't go and do user studies on

00:18:53,400 --> 00:18:57,680
what the attacker wants from your system

00:18:55,430 --> 00:19:02,400
it's as if I were to say to everybody

00:18:57,680 --> 00:19:03,840
quick drink like a chef is all of a

00:19:02,400 --> 00:19:05,880
sudden you're a cake coming out better I

00:19:03,840 --> 00:19:07,290
don't understand how soup isn't eight

00:19:05,880 --> 00:19:09,390
off some think like a chef and I could

00:19:07,290 --> 00:19:15,450
make a fantastic soup it's not very

00:19:09,390 --> 00:19:16,620
helpful on the other hand well they're

00:19:15,450 --> 00:19:18,150
gonna steal our money they're gonna

00:19:16,620 --> 00:19:20,400
steal credit cards it's obvious why are

00:19:18,150 --> 00:19:22,020
you bothering doing a two-month process

00:19:20,400 --> 00:19:23,340
of threat modeling when we know what

00:19:22,020 --> 00:19:24,440
they're going to do there's nothing to

00:19:23,340 --> 00:19:27,390
talk about

00:19:24,440 --> 00:19:30,170
no threat modeling needs a lot of detail

00:19:27,390 --> 00:19:33,450
you know detail spec kind of a use case

00:19:30,170 --> 00:19:35,670
detail level of detail which is really

00:19:33,450 --> 00:19:37,470
kind of waterfall II all right as

00:19:35,670 --> 00:19:39,540
opposed to you know user story

00:19:37,470 --> 00:19:41,490
development invitation to a conversation

00:19:39,540 --> 00:19:44,010
minimal bit of information we'll just

00:19:41,490 --> 00:19:47,160
we'll figure it out as we go and as

00:19:44,010 --> 00:19:49,410
everybody has heard agile likes no big

00:19:47,160 --> 00:19:51,780
design up front right but if you don't

00:19:49,410 --> 00:19:53,610
have a big design up front you can't

00:19:51,780 --> 00:19:55,920
really do a big model up front if you

00:19:53,610 --> 00:19:57,900
try to do big model without having a big

00:19:55,920 --> 00:19:58,920
design you're gonna kind of squeeze

00:19:57,900 --> 00:20:02,160
yourself into hole that you're gonna

00:19:58,920 --> 00:20:04,320
regret being in now

00:20:02,160 --> 00:20:06,570
gives you something very good you had a

00:20:04,320 --> 00:20:09,300
nice big threat model document these are

00:20:06,570 --> 00:20:10,980
the things that we care about from a

00:20:09,300 --> 00:20:14,130
security perspective this is how we're

00:20:10,980 --> 00:20:16,770
going to fix them except that when you

00:20:14,130 --> 00:20:18,990
read the functional design you don't

00:20:16,770 --> 00:20:20,820
have a lot of security information you

00:20:18,990 --> 00:20:23,490
have to start cross-referencing the

00:20:20,820 --> 00:20:25,350
threat model document and that doesn't

00:20:23,490 --> 00:20:26,850
help you understand why this was built

00:20:25,350 --> 00:20:30,510
this way or how to go about an employee

00:20:26,850 --> 00:20:32,100
implements something that way and kind

00:20:30,510 --> 00:20:35,040
of connected to that is that by the time

00:20:32,100 --> 00:20:36,660
the threat model comes back three weeks

00:20:35,040 --> 00:20:38,070
or two months later the design has

00:20:36,660 --> 00:20:39,540
already changed well there's the

00:20:38,070 --> 00:20:40,860
problems with that feature oh we decided

00:20:39,540 --> 00:20:43,110
not to have that feature anyway or we

00:20:40,860 --> 00:20:45,150
completely decided to completely change

00:20:43,110 --> 00:20:47,070
how that's implemented so you know be

00:20:45,150 --> 00:20:47,910
ephemeral it's not really relevant but

00:20:47,070 --> 00:20:51,450
yeah it's good

00:20:47,910 --> 00:20:52,920
Thanks good work and you know as they

00:20:51,450 --> 00:20:54,990
said have done this a lot of times and I

00:20:52,920 --> 00:20:57,360
used to just give a long excel sheet

00:20:54,990 --> 00:20:59,100
with dozens or even a couple hundred

00:20:57,360 --> 00:21:00,750
different threats and they're all

00:20:59,100 --> 00:21:02,820
relevant and they're all interesting and

00:21:00,750 --> 00:21:04,470
they're all great and you know the

00:21:02,820 --> 00:21:05,790
customer is very happy with that and

00:21:04,470 --> 00:21:07,320
it's always a customer because it's

00:21:05,790 --> 00:21:08,910
always an external expensive consultant

00:21:07,320 --> 00:21:11,310
and the customer is very happy this

00:21:08,910 --> 00:21:13,380
these are really interesting threats but

00:21:11,310 --> 00:21:16,440
then the developer has this nice long

00:21:13,380 --> 00:21:19,470
excel sheet of threats and then he goes

00:21:16,440 --> 00:21:20,610
to work on his JIRA backlog it's not in

00:21:19,470 --> 00:21:23,310
the backlog I can't do anything with it

00:21:20,610 --> 00:21:26,130
and there's no real way to connect

00:21:23,310 --> 00:21:29,910
between what I'm working on and that big

00:21:26,130 --> 00:21:31,890
threat model document and the good thing

00:21:29,910 --> 00:21:34,590
about threat modeling is for one thing

00:21:31,890 --> 00:21:36,810
you don't waste time on building things

00:21:34,590 --> 00:21:38,850
that you don't need to worry about

00:21:36,810 --> 00:21:40,920
building fixes for are threats that are

00:21:38,850 --> 00:21:43,200
not really relevant but you do waste

00:21:40,920 --> 00:21:45,600
time modeling them and then the endless

00:21:43,200 --> 00:21:47,220
discussions of let's not fix this

00:21:45,600 --> 00:21:49,440
because whatever and that goes on and on

00:21:47,220 --> 00:21:51,450
and on and you waste a lot of time on

00:21:49,440 --> 00:21:53,490
the threat model on the unrealistic

00:21:51,450 --> 00:21:57,600
threats ones that are not even relevant

00:21:53,490 --> 00:22:00,000
to you now developers the Stallions run

00:21:57,600 --> 00:22:01,710
forward two-week sprints continuous

00:22:00,000 --> 00:22:03,570
integration continues deployment pushing

00:22:01,710 --> 00:22:05,570
things out all the time and security

00:22:03,570 --> 00:22:10,380
people we like to tear things apart

00:22:05,570 --> 00:22:12,000
that's not a good match there and of

00:22:10,380 --> 00:22:14,090
course everybody's seen the security of

00:22:12,000 --> 00:22:16,460
a security team every

00:22:14,090 --> 00:22:20,180
once a quarter they drop in and say hey

00:22:16,460 --> 00:22:20,870
stop what you've been doing tell me

00:22:20,180 --> 00:22:22,760
what's up

00:22:20,870 --> 00:22:25,880
explain to me like I haven't been here

00:22:22,760 --> 00:22:29,180
for the past three months yeah that's

00:22:25,880 --> 00:22:31,730
kind of throws you out of your flow that

00:22:29,180 --> 00:22:33,020
kind of I don't even remember myself

00:22:31,730 --> 00:22:34,580
what I did three months ago you want me

00:22:33,020 --> 00:22:38,150
to explain to you why made those

00:22:34,580 --> 00:22:40,520
decisions not really and you know part

00:22:38,150 --> 00:22:42,530
of this is because a security team likes

00:22:40,520 --> 00:22:45,620
to pretend that we have these big drone

00:22:42,530 --> 00:22:47,360
armies it's simply not true okay there's

00:22:45,620 --> 00:22:50,240
not enough security people to go around

00:22:47,360 --> 00:22:55,520
one security person for every 100

00:22:50,240 --> 00:22:58,840
developers simply not enough of us now

00:22:55,520 --> 00:23:02,030
all this leads to the simple fact that

00:22:58,840 --> 00:23:03,410
security will usually either get shut

00:23:02,030 --> 00:23:06,050
out or be shutting the developers out

00:23:03,410 --> 00:23:08,360
and either way there's not really much

00:23:06,050 --> 00:23:10,940
communication going on over there and

00:23:08,360 --> 00:23:12,620
what happens is that we're left to stuck

00:23:10,940 --> 00:23:14,900
holding our shovel paddling upstream

00:23:12,620 --> 00:23:17,210
hoping all these threats and the

00:23:14,900 --> 00:23:20,540
possible attacks won't come back to

00:23:17,210 --> 00:23:23,600
drown us and flood us next season so

00:23:20,540 --> 00:23:25,580
we're using the wrong tools here okay

00:23:23,600 --> 00:23:28,070
we're spending a whole lot of effort and

00:23:25,580 --> 00:23:32,330
we're getting really very we're getting

00:23:28,070 --> 00:23:34,160
nowhere really fast so let's try

00:23:32,330 --> 00:23:36,530
something a little bit different okay we

00:23:34,160 --> 00:23:39,610
talked about classic threat modeling we

00:23:36,530 --> 00:23:42,650
understood why it's important but I also

00:23:39,610 --> 00:23:47,030
showed why it doesn't you work in a

00:23:42,650 --> 00:23:48,800
modern agile devops workflow so let's

00:23:47,030 --> 00:23:53,120
take a look at something else now Adam

00:23:48,800 --> 00:23:55,220
szostak who is a kind of the Godfather

00:23:53,120 --> 00:23:56,660
of modern threat modeling he literally

00:23:55,220 --> 00:23:58,100
wrote the book on threat modeling he

00:23:56,660 --> 00:24:00,170
says doctor by what methodology are

00:23:58,100 --> 00:24:02,350
using to do threat modeling it all comes

00:24:00,170 --> 00:24:05,390
down to answering these four questions

00:24:02,350 --> 00:24:07,880
number one what are you building this is

00:24:05,390 --> 00:24:09,800
your design the dfd the application

00:24:07,880 --> 00:24:11,990
decomposition number two what can go

00:24:09,800 --> 00:24:14,630
wrong these are the threats right and

00:24:11,990 --> 00:24:15,950
the risks involved what are you gonna do

00:24:14,630 --> 00:24:18,380
about it these are the countermeasures

00:24:15,950 --> 00:24:20,570
mitigations the fixes and number four

00:24:18,380 --> 00:24:22,880
did we do a good job is the

00:24:20,570 --> 00:24:25,610
introspective this is the process

00:24:22,880 --> 00:24:28,290
analysis step four

00:24:25,610 --> 00:24:30,809
now address our stack likes quoting

00:24:28,290 --> 00:24:33,330
George box and I like misquoting Adam so

00:24:30,809 --> 00:24:36,000
Adam does not say very often all threat

00:24:33,330 --> 00:24:37,650
models are wrong some are useful all

00:24:36,000 --> 00:24:39,300
threat models are polymers and some are

00:24:37,650 --> 00:24:40,620
useful if there's one thing you take

00:24:39,300 --> 00:24:42,750
away from my talk today make it be this

00:24:40,620 --> 00:24:45,360
all throughout models are wrong some are

00:24:42,750 --> 00:24:46,440
useful even if it's wrong it's still

00:24:45,360 --> 00:24:49,020
useful that's great

00:24:46,440 --> 00:24:51,870
lean into it grab the wrongness with

00:24:49,020 --> 00:24:53,760
both hands and optimized for usefulness

00:24:51,870 --> 00:24:55,650
don't worry that you're building a wrong

00:24:53,760 --> 00:24:57,000
threat model don't say oh the security

00:24:55,650 --> 00:24:58,200
person needs to do the threat model

00:24:57,000 --> 00:25:01,820
because I'm going to do it wrong that's

00:24:58,200 --> 00:25:04,320
fine it's a lot more useful if you do it

00:25:01,820 --> 00:25:06,929
so let me take those four questions and

00:25:04,320 --> 00:25:09,050
put a small spin on it and rephrase it

00:25:06,929 --> 00:25:11,250
I'm going to spin around a certain

00:25:09,050 --> 00:25:12,900
concept which I'll get into in a moment

00:25:11,250 --> 00:25:14,730
but I'm going to take those four

00:25:12,900 --> 00:25:17,490
questions and rephrase them thusly

00:25:14,730 --> 00:25:18,990
number one why are we building this when

00:25:17,490 --> 00:25:21,420
I do the threat model I need you to

00:25:18,990 --> 00:25:24,450
start explaining to me what you're

00:25:21,420 --> 00:25:26,309
building I'm an external consultant and

00:25:24,450 --> 00:25:27,990
I don't know what's going on because I

00:25:26,309 --> 00:25:29,610
just dropped in but you know if you're

00:25:27,990 --> 00:25:32,790
doing the threat model you don't you

00:25:29,610 --> 00:25:34,380
again okay you don't you go through the

00:25:32,790 --> 00:25:38,179
hole what are you building all over

00:25:34,380 --> 00:25:41,520
again you should focus on the why

00:25:38,179 --> 00:25:43,830
typically in adult the wise gets lost in

00:25:41,520 --> 00:25:47,040
the epic or in the future but the why

00:25:43,830 --> 00:25:49,559
are you building this user story okay

00:25:47,040 --> 00:25:52,440
what business value or go are you trying

00:25:49,559 --> 00:25:56,040
to achieve here what user benefit does

00:25:52,440 --> 00:25:57,660
this provide okay what is the value of

00:25:56,040 --> 00:26:01,140
this user story why is this one being

00:25:57,660 --> 00:26:02,970
built and not that other one okay why

00:26:01,140 --> 00:26:05,370
are we building it number two what needs

00:26:02,970 --> 00:26:08,460
to go right in order to achieve that

00:26:05,370 --> 00:26:10,860
value okay this is usually there in the

00:26:08,460 --> 00:26:13,260
user story already the conditions this

00:26:10,860 --> 00:26:15,630
the state of the system state of the

00:26:13,260 --> 00:26:17,580
user different parameters this is

00:26:15,630 --> 00:26:20,130
usually there in the user story but it

00:26:17,580 --> 00:26:21,900
needs to be made explicit and number

00:26:20,130 --> 00:26:23,520
three how do we make sure that happens

00:26:21,900 --> 00:26:25,559
that there's a certain condition or if

00:26:23,520 --> 00:26:27,630
there's an assumption built into that

00:26:25,559 --> 00:26:29,160
user story we need to make it explicit

00:26:27,630 --> 00:26:34,320
we need to validate it we need to

00:26:29,160 --> 00:26:36,990
enforce it okay it's all pivoted around

00:26:34,320 --> 00:26:39,270
this change

00:26:36,990 --> 00:26:41,070
security people like focusing on the FUD

00:26:39,270 --> 00:26:43,740
on the snark everything is broken

00:26:41,070 --> 00:26:45,270
everything's gonna be bad and you know

00:26:43,740 --> 00:26:48,330
we know everything's broken that's fine

00:26:45,270 --> 00:26:49,620
we'll build around it we're building on

00:26:48,330 --> 00:26:51,299
the beach fine let's build a house of

00:26:49,620 --> 00:26:52,919
cards it doesn't matter have you seen

00:26:51,299 --> 00:26:57,179
the internet everything is broken that's

00:26:52,919 --> 00:26:59,159
fine we can make it happen anyway as a

00:26:57,179 --> 00:27:01,649
big difference because I noticed a few

00:26:59,159 --> 00:27:04,169
months ago on Twitter and an argument as

00:27:01,649 --> 00:27:05,460
things happen on Twitter but one very

00:27:04,169 --> 00:27:08,340
interesting thing came out of this

00:27:05,460 --> 00:27:11,669
argument is somebody noted this guy Rob

00:27:08,340 --> 00:27:14,039
noted that in Aviation's industry they

00:27:11,669 --> 00:27:16,200
don't talk about preventing accidents or

00:27:14,039 --> 00:27:18,750
the the equivalent care of blocking

00:27:16,200 --> 00:27:22,740
attacks or preventing threats no they

00:27:18,750 --> 00:27:24,809
talk about safe transportation giant

00:27:22,740 --> 00:27:28,200
sounds subtle but it's very powerful

00:27:24,809 --> 00:27:32,010
it's a huge difference focusing on

00:27:28,200 --> 00:27:34,679
adding value securely building secure

00:27:32,010 --> 00:27:38,520
features whatever features were trying

00:27:34,679 --> 00:27:42,029
to add just make sure it's safe because

00:27:38,520 --> 00:27:43,710
at the end of the day people work

00:27:42,029 --> 00:27:45,630
according to their own incentives one

00:27:43,710 --> 00:27:48,029
way or the other and we want to change

00:27:45,630 --> 00:27:50,669
where I want you to change the workflow

00:27:48,029 --> 00:27:55,590
to include security it needs to align

00:27:50,669 --> 00:27:57,690
with your incentives and it can ok so

00:27:55,590 --> 00:28:01,669
let's take a look at what process I'm

00:27:57,690 --> 00:28:03,809
actually ok what process I'm actually

00:28:01,669 --> 00:28:06,960
suggesting so number one we have to

00:28:03,809 --> 00:28:08,730
focus focus we don't need to worry about

00:28:06,960 --> 00:28:11,370
things that we already know about yeah

00:28:08,730 --> 00:28:13,200
there's a SQL injection threats I find

00:28:11,370 --> 00:28:16,049
that's a given I don't need to worry

00:28:13,200 --> 00:28:17,010
about ok there's a web there's a web

00:28:16,049 --> 00:28:18,690
server I don't need to worry about

00:28:17,010 --> 00:28:19,950
putting HTTPS on that that's obvious

00:28:18,690 --> 00:28:22,080
that's not something I need to spend

00:28:19,950 --> 00:28:24,539
time modeling the possible threats that

00:28:22,080 --> 00:28:26,779
could happen if I don't use HTTPS ok

00:28:24,539 --> 00:28:29,850
let's start with a standard base line

00:28:26,779 --> 00:28:33,299
code hygiene we assume that everybody's

00:28:29,850 --> 00:28:34,409
running good code good system and if you

00:28:33,299 --> 00:28:36,149
don't maybe that's where security

00:28:34,409 --> 00:28:38,690
training needs to come in threat

00:28:36,149 --> 00:28:41,399
libraries are very powerful for a given

00:28:38,690 --> 00:28:42,990
architecture for a given design pattern

00:28:41,399 --> 00:28:44,940
these are the threat patterns that are

00:28:42,990 --> 00:28:47,899
that apply some commercial tools provide

00:28:44,940 --> 00:28:50,070
this pretty very well some open-source

00:28:47,899 --> 00:28:52,560
libraries are available

00:28:50,070 --> 00:28:54,780
but that saves a lot of time on dealing

00:28:52,560 --> 00:28:55,800
with the known threats and that just

00:28:54,780 --> 00:28:58,500
leaves us to deal with the unknown

00:28:55,800 --> 00:29:00,930
threats which is fantastic now we're

00:28:58,500 --> 00:29:03,060
gonna do this for every user story that

00:29:00,930 --> 00:29:06,510
we're building designing epic feature

00:29:03,060 --> 00:29:08,160
whatever so during the discovery of this

00:29:06,510 --> 00:29:10,610
user story or the sprint planning

00:29:08,160 --> 00:29:13,140
whatever we're doing just enough design

00:29:10,610 --> 00:29:16,260
we're gonna do just enough threat model

00:29:13,140 --> 00:29:19,470
and we're gonna make that be part of the

00:29:16,260 --> 00:29:21,060
user story okay it's not gonna be a

00:29:19,470 --> 00:29:25,770
separate design document it's going bill

00:29:21,060 --> 00:29:29,010
into the user story how do we do that

00:29:25,770 --> 00:29:32,700
for each user story for each user story

00:29:29,010 --> 00:29:35,580
we find the value usually it's follow

00:29:32,700 --> 00:29:37,020
the money right is the value chain for

00:29:35,580 --> 00:29:40,040
most features we've built sometimes it's

00:29:37,020 --> 00:29:42,240
how do people die okay sometimes

00:29:40,040 --> 00:29:44,400
sometimes it's something else but it

00:29:42,240 --> 00:29:46,620
usually comes back to what user benefit

00:29:44,400 --> 00:29:49,230
is we follow the money whatever the

00:29:46,620 --> 00:29:51,030
value of this user story is why we're

00:29:49,230 --> 00:29:52,860
why we're building this user story

00:29:51,030 --> 00:29:56,070
that's what we need to find we're gonna

00:29:52,860 --> 00:29:58,080
focus on that so what is the workflow

00:29:56,070 --> 00:29:59,850
look like we're gonna be very explicit

00:29:58,080 --> 00:30:01,800
about the goal of this user story what

00:29:59,850 --> 00:30:03,570
is the value that we're trying to

00:30:01,800 --> 00:30:05,910
achieve here we're going to be very

00:30:03,570 --> 00:30:08,100
explicit about the correct flow but also

00:30:05,910 --> 00:30:10,440
about the failure states that part

00:30:08,100 --> 00:30:12,840
usually very often gets skipped out from

00:30:10,440 --> 00:30:15,300
the user stories we're gonna be explicit

00:30:12,840 --> 00:30:16,680
about our assumptions finding how to be

00:30:15,300 --> 00:30:18,570
explicit about assumptions as a whole

00:30:16,680 --> 00:30:20,400
other thing about you know if it's

00:30:18,570 --> 00:30:22,110
you're something you don't always know

00:30:20,400 --> 00:30:23,580
that it's an assumption or you're gonna

00:30:22,110 --> 00:30:26,340
be explicit about the assumptions and

00:30:23,580 --> 00:30:30,450
the conditions that allow the correct

00:30:26,340 --> 00:30:32,580
flow all right then based on that it's

00:30:30,450 --> 00:30:33,900
very easy to now go and enforce those

00:30:32,580 --> 00:30:35,850
conditions and validate those

00:30:33,900 --> 00:30:37,860
assumptions and we're going to be very

00:30:35,850 --> 00:30:40,350
explicit about dealing with the failure

00:30:37,860 --> 00:30:42,360
state that's it that's the whole flow

00:30:40,350 --> 00:30:44,790
this is something that architects and

00:30:42,360 --> 00:30:46,350
product owners usually do anyway just

00:30:44,790 --> 00:30:49,710
need to be a bit more rigorous a bit

00:30:46,350 --> 00:30:51,410
more explicit about these issues now I

00:30:49,710 --> 00:30:54,030
was going to go through a quick example

00:30:51,410 --> 00:30:56,400
but I'm running out of time about how to

00:30:54,030 --> 00:30:59,250
take okay this is anybody familiar with

00:30:56,400 --> 00:31:01,380
auto shop it's a great location not to

00:30:59,250 --> 00:31:03,780
buy juice on the internet a modern

00:31:01,380 --> 00:31:05,670
application that's in securely built

00:31:03,780 --> 00:31:08,460
and there's one little feature that I

00:31:05,670 --> 00:31:11,280
was gonna highlight here about a coupon

00:31:08,460 --> 00:31:13,530
you can get a coupon online I'm just

00:31:11,280 --> 00:31:15,990
gonna be real quick got a coupon online

00:31:13,530 --> 00:31:18,090
you save 30 percent now that's pretty

00:31:15,990 --> 00:31:20,100
easy pretty straightforward I can go and

00:31:18,090 --> 00:31:23,340
break that but the real question that

00:31:20,100 --> 00:31:26,130
needs to be asked here is why why are we

00:31:23,340 --> 00:31:31,260
doing this feature what is the purpose

00:31:26,130 --> 00:31:34,260
anybody it's not for cheaper juice it's

00:31:31,260 --> 00:31:35,970
to get new customers now if we focus on

00:31:34,260 --> 00:31:38,310
the element of new customers marketing

00:31:35,970 --> 00:31:39,840
team probably came out with we do 30%

00:31:38,310 --> 00:31:42,360
off for a month we'll probably get an

00:31:39,840 --> 00:31:44,160
uptick of 20% more sales half of those

00:31:42,360 --> 00:31:47,640
will be recurring customers after they

00:31:44,160 --> 00:31:50,310
see how great are your juices great so

00:31:47,640 --> 00:31:52,740
let's focus on that not just ask well

00:31:50,310 --> 00:31:54,390
can we use this past the date can we

00:31:52,740 --> 00:31:58,200
make instead of 30 per second we make it

00:31:54,390 --> 00:32:01,080
60 percent or 90 percent or 200% but

00:31:58,200 --> 00:32:03,270
let's turn it around and say can I cause

00:32:01,080 --> 00:32:05,370
customers to start paying more for your

00:32:03,270 --> 00:32:07,700
juice or to give them a bad experience

00:32:05,370 --> 00:32:10,950
crash the system when you use the code

00:32:07,700 --> 00:32:13,500
focus on the new customers and that

00:32:10,950 --> 00:32:14,940
suddenly highlights a whole lot more

00:32:13,500 --> 00:32:16,710
interesting threats that you're gonna

00:32:14,940 --> 00:32:18,630
take a look at now I'm going to give you

00:32:16,710 --> 00:32:20,190
a few quick techniques everybody's

00:32:18,630 --> 00:32:22,950
familiar with the user story format as a

00:32:20,190 --> 00:32:24,060
mmm I love mmm so that right as a

00:32:22,950 --> 00:32:27,510
customer I want to complete a purchase

00:32:24,060 --> 00:32:30,270
so that I get my juice in every morning

00:32:27,510 --> 00:32:33,180
just when I need it now I'm gonna stick

00:32:30,270 --> 00:32:35,580
a pin in that and say without very small

00:32:33,180 --> 00:32:37,800
claws as a customer I want to complete a

00:32:35,580 --> 00:32:39,960
purchase so that my kits so that I get

00:32:37,800 --> 00:32:41,220
my juice when I want it without my

00:32:39,960 --> 00:32:43,320
credit card being stolen

00:32:41,220 --> 00:32:45,720
now there's zero level of detail there

00:32:43,320 --> 00:32:47,700
but then again there's no detail in the

00:32:45,720 --> 00:32:49,260
rest of the user story either but that's

00:32:47,700 --> 00:32:51,390
gonna give me a little flag that I need

00:32:49,260 --> 00:32:53,880
to develop and go understand when I do

00:32:51,390 --> 00:32:55,680
the minimal design for the user story

00:32:53,880 --> 00:32:57,210
I'm gonna need to flesh that out and

00:32:55,680 --> 00:32:59,430
understand what that means what that

00:32:57,210 --> 00:33:01,500
entails so that's going to give us it's

00:32:59,430 --> 00:33:05,870
a very powerful feature of the user

00:33:01,500 --> 00:33:10,130
story to be able to plug security into

00:33:05,870 --> 00:33:10,130
the users into the design

00:33:10,580 --> 00:33:13,700
toughen criteria obviously we're gonna

00:33:11,990 --> 00:33:15,919
plug in some security requirements there

00:33:13,700 --> 00:33:19,070
without login you know for the user

00:33:15,919 --> 00:33:20,360
story for the login story we're not

00:33:19,070 --> 00:33:22,519
logging with wrong password I should be

00:33:20,360 --> 00:33:24,590
locked out after certain amount of times

00:33:22,519 --> 00:33:26,690
and of course the security unit tests

00:33:24,590 --> 00:33:29,600
that apply to that security requirement

00:33:26,690 --> 00:33:31,940
test that they're locked out after the X

00:33:29,600 --> 00:33:33,409
number of attempts and correlated with

00:33:31,940 --> 00:33:35,929
that is that they're unlocked after

00:33:33,409 --> 00:33:37,490
certain amount of time everybody's

00:33:35,929 --> 00:33:39,260
familiar with a fret / with a yeah food

00:33:37,490 --> 00:33:41,539
pyramid you know you this amount of

00:33:39,260 --> 00:33:44,330
grains and this amount of fruit no more

00:33:41,539 --> 00:33:47,179
no less comply the same thing to threats

00:33:44,330 --> 00:33:49,519
it's pointless to talk sorry this is the

00:33:47,179 --> 00:33:51,529
Maslow's hierarchy of needs let's talk

00:33:49,519 --> 00:33:53,929
about self-esteem before you worry about

00:33:51,529 --> 00:33:55,490
your physiological and safety needs in

00:33:53,929 --> 00:33:57,070
the same we're going to apply this to

00:33:55,490 --> 00:34:00,169
threats it's pointless to talk about

00:33:57,070 --> 00:34:02,179
data leakage or user access threats

00:34:00,169 --> 00:34:04,909
while you still have a whole lot of code

00:34:02,179 --> 00:34:06,110
execution running on your system but

00:34:04,909 --> 00:34:08,599
we're going to take this and apply this

00:34:06,110 --> 00:34:09,830
more to the value driven approach it's

00:34:08,599 --> 00:34:12,649
pointless to talk about somebody's

00:34:09,830 --> 00:34:15,440
stealing juice while you are have an

00:34:12,649 --> 00:34:18,589
exposed bank account or leaking credit

00:34:15,440 --> 00:34:21,290
cards and PII so this tells you that

00:34:18,589 --> 00:34:25,339
where you need to focus more and where

00:34:21,290 --> 00:34:27,080
you can focus less abuser stories are

00:34:25,339 --> 00:34:29,839
very similar to user stories but from an

00:34:27,080 --> 00:34:31,220
app attackers perspective ok as an

00:34:29,839 --> 00:34:32,869
attacker I want to push say another user

00:34:31,220 --> 00:34:34,460
so I can steal their juice box now

00:34:32,869 --> 00:34:36,200
notice I'm not worried about the attack

00:34:34,460 --> 00:34:38,179
what the attacker wants to do this does

00:34:36,200 --> 00:34:40,190
not think like an attacker this is how

00:34:38,179 --> 00:34:42,230
an attacker could possibly affect my

00:34:40,190 --> 00:34:47,030
value this is my juice box that he's

00:34:42,230 --> 00:34:49,280
stealing how this effects my users what

00:34:47,030 --> 00:34:51,050
this helps flesh out sometimes helps

00:34:49,280 --> 00:34:53,750
flesh out some more detail of a possible

00:34:51,050 --> 00:34:55,909
threat now everybody's story points

00:34:53,750 --> 00:34:58,099
write a very rough estimate of how much

00:34:55,909 --> 00:35:00,380
it's not an amount of time but how much

00:34:58,099 --> 00:35:01,460
work is this compared to some other

00:35:00,380 --> 00:35:02,990
story

00:35:01,460 --> 00:35:05,359
now I blame the fact that I was in

00:35:02,990 --> 00:35:06,650
artillery and I don't hear so well but

00:35:05,359 --> 00:35:09,109
somebody was I was talking to somebody

00:35:06,650 --> 00:35:11,869
about story points and I said sorry

00:35:09,109 --> 00:35:12,500
points what's that that sounds

00:35:11,869 --> 00:35:15,170
fascinating

00:35:12,500 --> 00:35:17,780
tell me more well sorry points is very

00:35:15,170 --> 00:35:21,020
similarly a relative estimate of how bad

00:35:17,780 --> 00:35:23,420
this story could possibly be if it

00:35:21,020 --> 00:35:24,470
explodes in your face using the same

00:35:23,420 --> 00:35:25,790
methodology

00:35:24,470 --> 00:35:28,430
you could use Fibonacci you could use

00:35:25,790 --> 00:35:30,130
t-shirt sizes whatever it is how bad if

00:35:28,430 --> 00:35:32,810
everything explodes it goes left and

00:35:30,130 --> 00:35:35,570
everything goes absolutely the wrongest

00:35:32,810 --> 00:35:37,250
way possible how bad could possibly be

00:35:35,570 --> 00:35:38,990
are we talking about a few hours of

00:35:37,250 --> 00:35:40,520
overtime to fix it are we talking about

00:35:38,990 --> 00:35:44,720
Brian Krebs reporting on me in the news

00:35:40,520 --> 00:35:46,730
are we talking about a couple of pythons

00:35:44,720 --> 00:35:48,109
being shipped every user with a shark

00:35:46,730 --> 00:35:51,619
eating dingo chasing them down the

00:35:48,109 --> 00:35:54,250
street how bad could it possibly be now

00:35:51,619 --> 00:35:57,530
this is a very good tool for escalation

00:35:54,250 --> 00:35:59,030
you know a small store a small story

00:35:57,530 --> 00:36:01,099
point you might be able to do yourself

00:35:59,030 --> 00:36:03,320
medium you might want to call a buddy in

00:36:01,099 --> 00:36:05,300
large you'll get a security team or an

00:36:03,320 --> 00:36:07,250
external consultant to come and tell you

00:36:05,300 --> 00:36:08,720
to do a full stride metrics or whatever

00:36:07,250 --> 00:36:10,790
now I gotta finish up so I'm just gonna

00:36:08,720 --> 00:36:12,830
you throw out definitions done you know

00:36:10,790 --> 00:36:14,180
every user story needs to have a threat

00:36:12,830 --> 00:36:18,230
model security test whatever they are

00:36:14,180 --> 00:36:19,520
even if it's just the without okay I'm

00:36:18,230 --> 00:36:22,880
gonna go through this real quickly I

00:36:19,520 --> 00:36:25,490
have two minutes two minutes benefits it

00:36:22,880 --> 00:36:26,660
helps you very efficiently protect your

00:36:25,490 --> 00:36:28,640
application you find out what's wrong

00:36:26,660 --> 00:36:30,890
you can fix that and it's now focusing

00:36:28,640 --> 00:36:33,380
on everything that can go bad you focus

00:36:30,890 --> 00:36:36,200
on what can what needs to go right and

00:36:33,380 --> 00:36:39,920
why it helps you be efficient you don't

00:36:36,200 --> 00:36:41,650
need to waste time fixing things that

00:36:39,920 --> 00:36:44,750
don't really affect your bottom line

00:36:41,650 --> 00:36:45,880
okay and it helps you know not to fix

00:36:44,750 --> 00:36:48,800
some things

00:36:45,880 --> 00:36:51,380
it is integrated with your a gel design

00:36:48,800 --> 00:36:53,839
gel design process part of your DevOps

00:36:51,380 --> 00:36:56,630
workflow it can work together with that

00:36:53,839 --> 00:36:59,810
it gives you a better ownership of

00:36:56,630 --> 00:37:02,510
security requirements and helps you

00:36:59,810 --> 00:37:04,580
share your understanding of what your

00:37:02,510 --> 00:37:06,410
security profile is these are the things

00:37:04,580 --> 00:37:08,240
we care about those are the things that

00:37:06,410 --> 00:37:11,680
not you want to take care of these

00:37:08,240 --> 00:37:14,210
things this is what you need to do and

00:37:11,680 --> 00:37:15,560
most importantly you don't need to keep

00:37:14,210 --> 00:37:17,869
throwing money at big expensive

00:37:15,560 --> 00:37:19,550
consultants like me I don't mind I don't

00:37:17,869 --> 00:37:20,030
think it's sustainable and I don't enjoy

00:37:19,550 --> 00:37:22,040
it very much

00:37:20,030 --> 00:37:24,230
I think the money's fine it's the

00:37:22,040 --> 00:37:27,200
constantly doing these kind of products

00:37:24,230 --> 00:37:29,330
now that's what's good again what's bad

00:37:27,200 --> 00:37:31,730
about this approach compared to classic

00:37:29,330 --> 00:37:34,070
scrub modeling this is not a complete

00:37:31,730 --> 00:37:35,960
threat model okay if you're designing

00:37:34,070 --> 00:37:38,090
hospital security systems or aviation

00:37:35,960 --> 00:37:39,530
security systems or if

00:37:38,090 --> 00:37:42,110
designing something for the DoD or

00:37:39,530 --> 00:37:44,900
Citibank this is probably not enough

00:37:42,110 --> 00:37:47,620
it's a good place to start but it's not

00:37:44,900 --> 00:37:51,050
enough eventually you're gonna need more

00:37:47,620 --> 00:37:53,090
ok so just in time getting to the

00:37:51,050 --> 00:37:55,340
summary and here's the bottom line

00:37:53,090 --> 00:37:57,620
developers need to do threat modeling

00:37:55,340 --> 00:37:59,930
even lightweight threat modeling this

00:37:57,620 --> 00:38:02,810
adds a huge amount of value it helps you

00:37:59,930 --> 00:38:05,900
build secure features and the security

00:38:02,810 --> 00:38:08,270
features that you need make it be part

00:38:05,900 --> 00:38:09,770
of the workflow by focusing on the

00:38:08,270 --> 00:38:12,710
business value this is something that

00:38:09,770 --> 00:38:16,370
most of you know how to do anyway focus

00:38:12,710 --> 00:38:18,320
on protecting that value just need to

00:38:16,370 --> 00:38:20,570
worry about useful it's wrong that's

00:38:18,320 --> 00:38:21,470
fine it doesn't need to be perfect you

00:38:20,570 --> 00:38:24,620
don't need to call me in to make it

00:38:21,470 --> 00:38:26,920
perfect do what is useful don't worry

00:38:24,620 --> 00:38:29,180
about overkill again when you need it

00:38:26,920 --> 00:38:31,160
then you can worry about doing the full

00:38:29,180 --> 00:38:33,430
size threat model most of the time you

00:38:31,160 --> 00:38:34,070
don't need to thank you very much

00:38:33,430 --> 00:38:42,770
[Applause]

00:38:34,070 --> 00:38:42,770

YouTube URL: https://www.youtube.com/watch?v=Ym1-7DJlevA


