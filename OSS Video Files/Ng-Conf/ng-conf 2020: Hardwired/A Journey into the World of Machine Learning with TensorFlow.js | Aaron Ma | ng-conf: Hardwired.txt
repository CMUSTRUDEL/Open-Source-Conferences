Title: A Journey into the World of Machine Learning with TensorFlow.js | Aaron Ma | ng-conf: Hardwired
Publication date: 2020-09-07
Playlist: ng-conf 2020: Hardwired
Description: 
	Get your free ticket to EnterpriseNG conference Keynote: https://ng-conf.org

This talk is the flagship machine learning with TensorFlow.js that delivers unique learning with immersive projects that stretches your mind. Weâ€™ll start by learning the basics and perfect your knowledge of Machine Learning and TensorFlow.js by building a digit classifier. Then, weâ€™ll develop our expertise in core TensorFlow.js concepts and Reinforcement Learning(RL) and develop a self-driving car that learns how to drive itself. Weâ€™ll finish off by adding a touch of the magic of neural networks to our Angular application by building an image classifier. (all demos made with ðŸ’– using Angular 9+)

Watch all the ng-conf: Hardwired presentations/videos at https://videos.ng-conf.org

ng-conf is a three-day Angular conference focused on delivering the highest quality training in the Angular JavaScript framework. 1500+ developers from across the globe converge on Salt Lake City, UT every year to attend talks and workshops by the Angular team and community experts.

ng-conf: Hardwired is brought to you by:
- https://thinkster.io/ The best Angular and JavaScript tutorials on the web
- https://herodevs.com/ Engineering and consulting by web development experts
- https://xlts.dev/  Extended support for AngularJS

Follow us on twitter https://twitter.com/ngconf
Official Website: https://www.ng-conf.org/
Captions: 
	00:00:00,180 --> 00:00:02,970
[Music]

00:00:02,400 --> 00:00:16,320
[Applause]

00:00:02,970 --> 00:00:17,359
[Music]

00:00:16,320 --> 00:00:20,160
hello

00:00:17,359 --> 00:00:22,000
it's aaron today i'll be talking about a

00:00:20,160 --> 00:00:25,039
journey into the world of machine

00:00:22,000 --> 00:00:28,320
learning with tensorflow.js

00:00:25,039 --> 00:00:30,240
so who am i well i'm erin mall i'm 11

00:00:28,320 --> 00:00:31,679
years old and i have tremendous passion

00:00:30,240 --> 00:00:34,320
in computer science

00:00:31,679 --> 00:00:36,000
ever since i was five i'm a hardcore

00:00:34,320 --> 00:00:37,840
software and hardware developer

00:00:36,000 --> 00:00:39,920
and i'm the world's youngest tensorflow

00:00:37,840 --> 00:00:40,719
contributor of the world's youngest

00:00:39,920 --> 00:00:43,200
graduating

00:00:40,719 --> 00:00:44,320
from nasi sultering our engineering

00:00:43,200 --> 00:00:46,079
review program

00:00:44,320 --> 00:00:48,559
and much more and you can follow me on

00:00:46,079 --> 00:00:51,280
twitter at aaronhmaw

00:00:48,559 --> 00:00:53,520
so every day when i go to my computer i

00:00:51,280 --> 00:00:54,480
always go to google.com to see today's

00:00:53,520 --> 00:00:56,000
google

00:00:54,480 --> 00:00:58,600
some of these journals will celebrate an

00:00:56,000 --> 00:00:59,760
event for example when friends want the

00:00:58,600 --> 00:01:02,000
00:00:59,760 --> 00:01:03,440
fifa world cup some youtubers will

00:01:02,000 --> 00:01:06,080
celebrate a festival like

00:01:03,440 --> 00:01:07,840
children's day 2019. some of these

00:01:06,080 --> 00:01:10,560
drizzles are just fun to watch

00:01:07,840 --> 00:01:12,240
but this doodle is my favorite this

00:01:10,560 --> 00:01:13,439
journal celebrates the burst of johann

00:01:12,240 --> 00:01:16,000
sebastian back

00:01:13,439 --> 00:01:16,560
and that is best ever it's the world's

00:01:16,000 --> 00:01:19,280
first

00:01:16,560 --> 00:01:21,040
artificial intelligent power doodle

00:01:19,280 --> 00:01:22,479
let's take a look at this

00:01:21,040 --> 00:01:24,400
so as you can see here there's a very

00:01:22,479 --> 00:01:26,400
cool open box experience here

00:01:24,400 --> 00:01:28,960
so once this box has been opened you can

00:01:26,400 --> 00:01:30,880
start randomly clicking notes here

00:01:28,960 --> 00:01:32,240
then you can click harmonize and the in

00:01:30,880 --> 00:01:33,520
browser machine learning will

00:01:32,240 --> 00:01:34,320
automatically add notes to your

00:01:33,520 --> 00:01:35,680
composition

00:01:34,320 --> 00:01:37,119
to make your composition sound like

00:01:35,680 --> 00:01:38,720
where fat would have played it it feels

00:01:37,119 --> 00:01:41,200
alive

00:01:38,720 --> 00:01:43,280
once it's done you can download it share

00:01:41,200 --> 00:01:46,399
with your friends and also edit it

00:01:43,280 --> 00:01:48,880
in only three days more than 50

00:01:46,399 --> 00:01:49,600
million people have interacted with this

00:01:48,880 --> 00:01:52,079
tool

00:01:49,600 --> 00:01:53,600
and reach every single content on earth

00:01:52,079 --> 00:01:55,759
except antarctica

00:01:53,600 --> 00:01:57,520
it also became a social phenomenon when

00:01:55,759 --> 00:02:00,399
i was trending on twitter

00:01:57,520 --> 00:02:02,399
so why was it so successful but because

00:02:00,399 --> 00:02:04,399
the in-boundary machine learning allowed

00:02:02,399 --> 00:02:04,960
highly interactive experiments to take

00:02:04,399 --> 00:02:07,920
place

00:02:04,960 --> 00:02:10,080
on various devices plus there are no

00:02:07,920 --> 00:02:12,560
drivers or installations in the process

00:02:10,080 --> 00:02:13,360
and also it's secure since all the data

00:02:12,560 --> 00:02:15,520
stays on

00:02:13,360 --> 00:02:17,040
device so users know they have a secure

00:02:15,520 --> 00:02:19,480
connection

00:02:17,040 --> 00:02:21,520
so this doodle is powered by

00:02:19,480 --> 00:02:23,760
tensorflow.js

00:02:21,520 --> 00:02:25,280
so most of you here at ngcom hardwire

00:02:23,760 --> 00:02:27,280
are angular experts

00:02:25,280 --> 00:02:29,200
with the touch of the magic of machine

00:02:27,280 --> 00:02:31,760
learning you can make your web

00:02:29,200 --> 00:02:33,599
angular and machine learning power plus

00:02:31,760 --> 00:02:34,080
customers will love your ml power web

00:02:33,599 --> 00:02:36,959
app

00:02:34,080 --> 00:02:38,720
so what exactly is machine learning well

00:02:36,959 --> 00:02:40,080
it's a study of a complex algorithm in

00:02:38,720 --> 00:02:42,080
statistical models

00:02:40,080 --> 00:02:43,680
it has the ability to learn and improve

00:02:42,080 --> 00:02:44,800
its own experience without being

00:02:43,680 --> 00:02:46,480
explicitly programmed

00:02:44,800 --> 00:02:49,200
without any human intervention or

00:02:46,480 --> 00:02:50,959
assistance the goal of machine learning

00:02:49,200 --> 00:02:52,800
is to find the algorithm along the

00:02:50,959 --> 00:02:54,400
weights and biases by tweaking the input

00:02:52,800 --> 00:02:56,720
hyperparameters

00:02:54,400 --> 00:02:58,000
so machine learning is not magic as we

00:02:56,720 --> 00:03:00,959
are using technology

00:02:58,000 --> 00:03:02,319
to answer questions based on data so on

00:03:00,959 --> 00:03:03,040
the left hand side of the machine learn

00:03:02,319 --> 00:03:04,720
pipeline

00:03:03,040 --> 00:03:06,560
we gather our data and apply a

00:03:04,720 --> 00:03:08,400
pre-processing technique to the data to

00:03:06,560 --> 00:03:09,440
make sure it is in a suitable format for

00:03:08,400 --> 00:03:11,280
ml

00:03:09,440 --> 00:03:12,720
then on the right hand side of the ml

00:03:11,280 --> 00:03:13,760
pipeline we can apply a learning

00:03:12,720 --> 00:03:15,599
algorithm to the data

00:03:13,760 --> 00:03:16,959
and then train our model when training

00:03:15,599 --> 00:03:18,560
our model our model will learn the

00:03:16,959 --> 00:03:19,760
relationship between the data set and

00:03:18,560 --> 00:03:21,360
the answers

00:03:19,760 --> 00:03:23,120
finally once a month has been trained we

00:03:21,360 --> 00:03:24,400
can test our model to see how well the

00:03:23,120 --> 00:03:25,519
model has learned dana said during

00:03:24,400 --> 00:03:27,599
training

00:03:25,519 --> 00:03:28,799
so let's take a look at that in a human

00:03:27,599 --> 00:03:31,360
friendly way

00:03:28,799 --> 00:03:32,400
so let's meet john john loves listening

00:03:31,360 --> 00:03:34,640
to new music

00:03:32,400 --> 00:03:35,920
he loves music that's a fast tempo in

00:03:34,640 --> 00:03:38,159
the john a rock

00:03:35,920 --> 00:03:39,599
but he dislikes music with a slow tempo

00:03:38,159 --> 00:03:41,519
in the genre of pop

00:03:39,599 --> 00:03:42,720
so he can plot his like music and

00:03:41,519 --> 00:03:45,440
dislike music on

00:03:42,720 --> 00:03:47,840
x y axis graph as you can see here the

00:03:45,440 --> 00:03:48,560
x-axis is the music genre from pop to

00:03:47,840 --> 00:03:50,400
rock

00:03:48,560 --> 00:03:51,680
the y-axis is the music tempo from

00:03:50,400 --> 00:03:53,200
relaxing fast

00:03:51,680 --> 00:03:55,599
so let's say john's listening to a new

00:03:53,200 --> 00:03:58,239
song master of puppet spy metallica

00:03:55,599 --> 00:04:00,080
where do you think the point will be at

00:03:58,239 --> 00:04:01,439
if you guess the point of somewhere here

00:04:00,080 --> 00:04:04,319
you're correct

00:04:01,439 --> 00:04:05,439
how about bad guys where do you think

00:04:04,319 --> 00:04:06,959
the point will be at

00:04:05,439 --> 00:04:08,480
if you get still somewhere in here

00:04:06,959 --> 00:04:10,560
you're correct

00:04:08,480 --> 00:04:11,519
but what we can do here is use a machine

00:04:10,560 --> 00:04:13,760
learning technique

00:04:11,519 --> 00:04:14,879
known as k-nearest neighbor's algorithm

00:04:13,760 --> 00:04:17,600
or k n

00:04:14,879 --> 00:04:18,799
what this does is draws a circle around

00:04:17,600 --> 00:04:20,479
our data plane

00:04:18,799 --> 00:04:21,759
now we can safely kill the majority and

00:04:20,479 --> 00:04:22,560
say that john would probably like the

00:04:21,759 --> 00:04:24,000
song

00:04:22,560 --> 00:04:27,360
now let's talk about traditional

00:04:24,000 --> 00:04:29,040
learning versus the new machine learning

00:04:27,360 --> 00:04:30,720
so program traditional self-development

00:04:29,040 --> 00:04:31,919
we already know the input in the

00:04:30,720 --> 00:04:33,040
algorithm we'll just write a function

00:04:31,919 --> 00:04:34,880
that gets the output

00:04:33,040 --> 00:04:36,720
but in machine learning we take in pairs

00:04:34,880 --> 00:04:37,280
and pairs and pairs of dependent output

00:04:36,720 --> 00:04:38,800
data

00:04:37,280 --> 00:04:40,639
and write a model that figures out the

00:04:38,800 --> 00:04:42,160
algorithm you may notice

00:04:40,639 --> 00:04:43,680
in traditional software moment we're

00:04:42,160 --> 00:04:45,440
more focusing on our code

00:04:43,680 --> 00:04:47,919
on machine learning we're more focusing

00:04:45,440 --> 00:04:49,360
on how game has been represented

00:04:47,919 --> 00:04:51,199
let's take a look at a simple scenario

00:04:49,360 --> 00:04:53,840
of that hello

00:04:51,199 --> 00:04:55,199
hola bonjour there are so many languages

00:04:53,840 --> 00:04:57,040
to say hello

00:04:55,199 --> 00:04:58,880
so in traditional software development

00:04:57,040 --> 00:04:59,520
let's write some code that based on the

00:04:58,880 --> 00:05:02,000
text

00:04:59,520 --> 00:05:02,720
knows what language it is so in english

00:05:02,000 --> 00:05:04,479
it's hello

00:05:02,720 --> 00:05:06,000
so the text is hello the language is

00:05:04,479 --> 00:05:08,320
definitely english

00:05:06,000 --> 00:05:10,320
in french hello is bonjour so the text

00:05:08,320 --> 00:05:12,240
is not hello then the language is french

00:05:10,320 --> 00:05:13,440
in spanish it's olaf so if the text is

00:05:12,240 --> 00:05:15,039
not hello onboard

00:05:13,440 --> 00:05:18,080
then the language is definitely spanish

00:05:15,039 --> 00:05:21,280
but one ninja existed hello what lane

00:05:18,080 --> 00:05:22,240
oh no our ball has no idea what that

00:05:21,280 --> 00:05:23,919
means

00:05:22,240 --> 00:05:25,520
so the problem was was that in

00:05:23,919 --> 00:05:26,400
traditional self-development would

00:05:25,520 --> 00:05:27,919
explicitly see

00:05:26,400 --> 00:05:29,520
every single possible scenario that

00:05:27,919 --> 00:05:31,520
might happen so by the time you're

00:05:29,520 --> 00:05:33,039
done with that you'll be like this but

00:05:31,520 --> 00:05:34,479
anyways oh no there's so many other

00:05:33,039 --> 00:05:37,120
phrases that you ever write like what's

00:05:34,479 --> 00:05:39,520
your name and goodbye

00:05:37,120 --> 00:05:40,479
now what well let's use the magic wand

00:05:39,520 --> 00:05:42,479
of machine learning

00:05:40,479 --> 00:05:43,600
to start off we'll gather data and then

00:05:42,479 --> 00:05:45,680
train on that data set

00:05:43,600 --> 00:05:46,639
and training our monitoring relationship

00:05:45,680 --> 00:05:48,800
between the data

00:05:46,639 --> 00:05:50,160
and the answers to get out of the rules

00:05:48,800 --> 00:05:52,720
so let's run it again hello

00:05:50,160 --> 00:05:54,720
what language and our machine learning

00:05:52,720 --> 00:05:57,360
model has a prediction that is 92

00:05:54,720 --> 00:05:59,759
is chinese so we can safely go and say

00:05:57,360 --> 00:06:02,240
that the language is probably chinese

00:05:59,759 --> 00:06:03,840
much better so now they're thinking

00:06:02,240 --> 00:06:04,160
which machine learning library should i

00:06:03,840 --> 00:06:07,520
use

00:06:04,160 --> 00:06:09,199
well i got you covered friend

00:06:07,520 --> 00:06:11,199
so the top three machine learning

00:06:09,199 --> 00:06:14,720
libraries as of today

00:06:11,199 --> 00:06:16,160
are tendril js rangers and ml5 js

00:06:14,720 --> 00:06:17,759
let's take a look at statistics i

00:06:16,160 --> 00:06:20,160
suggest never lie

00:06:17,759 --> 00:06:21,919
but clearly hendrias wins in almost

00:06:20,160 --> 00:06:23,360
every single category

00:06:21,919 --> 00:06:24,960
how about google trends in the past 12

00:06:23,360 --> 00:06:25,680
months clearly kendall days is the

00:06:24,960 --> 00:06:27,919
winner

00:06:25,680 --> 00:06:28,800
npm downloads in the past many months

00:06:27,919 --> 00:06:30,880
but clearly

00:06:28,800 --> 00:06:32,240
central days is still a winner in fact

00:06:30,880 --> 00:06:34,960
as of march 29

00:06:32,240 --> 00:06:36,080
the dow is almost 3x over brain.js

00:06:34,960 --> 00:06:37,840
download

00:06:36,080 --> 00:06:39,199
so the winner of the machine learning

00:06:37,840 --> 00:06:43,120
javascript live battle

00:06:39,199 --> 00:06:43,120
is drumroll please

00:06:43,199 --> 00:06:49,759
support js yes

00:06:47,199 --> 00:06:51,520
so tetraj's contribution in the past 12

00:06:49,759 --> 00:06:54,720
months has skyrocketed

00:06:51,520 --> 00:06:56,639
there's more than 1.4 million npm and 10

00:06:54,720 --> 00:06:58,479
million cd and hits

00:06:56,639 --> 00:07:00,319
so now you're thinking what exactly is

00:06:58,479 --> 00:07:01,840
this 1020s thing

00:07:00,319 --> 00:07:03,520
well it's an open source artificial

00:07:01,840 --> 00:07:05,199
intelligence platform that allows you to

00:07:03,520 --> 00:07:07,199
develop machining models right

00:07:05,199 --> 00:07:08,479
in javascript and use machine learning

00:07:07,199 --> 00:07:11,039
directly in the browser

00:07:08,479 --> 00:07:12,880
or with node.js and designed to be

00:07:11,039 --> 00:07:14,240
consistent with tensorflow

00:07:12,880 --> 00:07:16,400
which means it's a complete react from

00:07:14,240 --> 00:07:18,000
scratch not about intensive flow

00:07:16,400 --> 00:07:20,000
and can run anywhere as long as

00:07:18,000 --> 00:07:22,960
javascript can run plus it's really fast

00:07:20,000 --> 00:07:25,039
as a gpu accelerator

00:07:22,960 --> 00:07:26,880
so the term tensorflow is reflecting

00:07:25,039 --> 00:07:28,160
what's happening inside the form where

00:07:26,880 --> 00:07:31,120
tensors are flowing through neural

00:07:28,160 --> 00:07:32,800
networks and other data processing nodes

00:07:31,120 --> 00:07:34,560
so a tensor you can think of it as a

00:07:32,800 --> 00:07:35,680
type of data that's commonly used in

00:07:34,560 --> 00:07:37,840
linear algebra

00:07:35,680 --> 00:07:39,599
it's immutable but can be calculated

00:07:37,840 --> 00:07:41,199
with arithmetic operations

00:07:39,599 --> 00:07:42,639
so you can think of tensions as just

00:07:41,199 --> 00:07:44,400
like a javascript ray

00:07:42,639 --> 00:07:45,840
or more like a multi-dimensional

00:07:44,400 --> 00:07:47,280
javascript array

00:07:45,840 --> 00:07:48,879
so there are multiple ways to use

00:07:47,280 --> 00:07:50,720
tensorflow.js

00:07:48,879 --> 00:07:52,720
the first way is to use a pretrained

00:07:50,720 --> 00:07:54,160
mouse directly for inferencing

00:07:52,720 --> 00:07:56,080
or use appreciating model of the

00:07:54,160 --> 00:07:58,160
customization of your own data

00:07:56,080 --> 00:07:59,840
and finally develop and train models

00:07:58,160 --> 00:08:02,080
from scratch using intuitive and

00:07:59,840 --> 00:08:04,000
flexible apis

00:08:02,080 --> 00:08:06,000
so tenfold.js currently supports four

00:08:04,000 --> 00:08:07,759
backgrounds there's a cpu back-end which

00:08:06,000 --> 00:08:10,479
is available for all devices

00:08:07,759 --> 00:08:11,120
a webgl vacuum which is for 53 of all

00:08:10,479 --> 00:08:13,919
devices

00:08:11,120 --> 00:08:15,280
and it's gpu based and a node.js backend

00:08:13,919 --> 00:08:16,319
that allows model instrument on the

00:08:15,280 --> 00:08:18,080
server

00:08:16,319 --> 00:08:19,520
on the browser and also internet of

00:08:18,080 --> 00:08:21,440
things devices and also

00:08:19,520 --> 00:08:23,680
awesome which is cp based and allows c

00:08:21,440 --> 00:08:26,720
plus plus code to execute in the browser

00:08:23,680 --> 00:08:27,520
finally web ppu is coming soon and it's

00:08:26,720 --> 00:08:30,240
expected to have

00:08:27,520 --> 00:08:32,240
even better performance than webgl so

00:08:30,240 --> 00:08:34,240
now it's time to get potential.js for

00:08:32,240 --> 00:08:36,880
interior angular power web app

00:08:34,240 --> 00:08:38,240
so let's get started today you can use

00:08:36,880 --> 00:08:39,919
preaching models directly for

00:08:38,240 --> 00:08:40,719
inferencing but i'll cover about that in

00:08:39,919 --> 00:08:42,159
the next slide

00:08:40,719 --> 00:08:44,560
or convert an existing model to a

00:08:42,159 --> 00:08:45,519
central gs readable format using tetrags

00:08:44,560 --> 00:08:46,959
converter wizard

00:08:45,519 --> 00:08:48,959
where finally you can run signals

00:08:46,959 --> 00:08:50,560
directly without any convergence in

00:08:48,959 --> 00:08:52,800
nodejs

00:08:50,560 --> 00:08:54,080
so central js provides preaching model

00:08:52,800 --> 00:08:54,800
for the most common machine learning

00:08:54,080 --> 00:08:57,279
tasks

00:08:54,800 --> 00:08:58,959
including but not limited to image

00:08:57,279 --> 00:09:00,720
classification computer mission

00:08:58,959 --> 00:09:02,399
object detection and speech man

00:09:00,720 --> 00:09:04,399
recognization for natural language

00:09:02,399 --> 00:09:05,839
processing

00:09:04,399 --> 00:09:07,600
you can find the source code and like

00:09:05,839 --> 00:09:08,320
demo of all these pre-trained models on

00:09:07,600 --> 00:09:10,560
the

00:09:08,320 --> 00:09:11,519
central js models github repository you

00:09:10,560 --> 00:09:15,040
can download them on

00:09:11,519 --> 00:09:17,680
npm currently there are 13 npm packages

00:09:15,040 --> 00:09:19,360
but the list is growing every single day

00:09:17,680 --> 00:09:21,680
of central models

00:09:19,360 --> 00:09:22,800
so some ideas for what that's along with

00:09:21,680 --> 00:09:25,600
temporal js

00:09:22,800 --> 00:09:27,279
is augmented in reality for example the

00:09:25,600 --> 00:09:28,640
real company made a virtual makeup and

00:09:27,279 --> 00:09:31,120
hair color try on app

00:09:28,640 --> 00:09:32,720
with potential js and there's also real

00:09:31,120 --> 00:09:34,880
time body segmentation

00:09:32,720 --> 00:09:37,440
it runs around 25 frames per second on

00:09:34,880 --> 00:09:40,399
the 2018 15 inch macbook pro

00:09:37,440 --> 00:09:41,920
and 21 frames per second on an apple

00:09:40,399 --> 00:09:44,640
iphone x

00:09:41,920 --> 00:09:46,240
so tentative is a very vibrant community

00:09:44,640 --> 00:09:48,080
their extensions libraries

00:09:46,240 --> 00:09:49,519
and so much more that are all built on

00:09:48,080 --> 00:09:51,680
top of 104gs

00:09:49,519 --> 00:09:52,720
just to name a few extensions how about

00:09:51,680 --> 00:09:56,320
base e5 js

00:09:52,720 --> 00:09:58,000
handshake js and ml5.js base api js

00:09:56,320 --> 00:09:59,839
allows real-time base detection

00:09:58,000 --> 00:10:01,839
each estimation and emotion and gender

00:09:59,839 --> 00:10:04,720
recognition in the browser

00:10:01,839 --> 00:10:06,560
of tensorflow.js handshake.s allows

00:10:04,720 --> 00:10:08,079
real-time hand detection based on hand

00:10:06,560 --> 00:10:10,480
gestures in the browser

00:10:08,079 --> 00:10:12,240
finally ml5.js from access to more

00:10:10,480 --> 00:10:14,560
amazing machine learning algorithms

00:10:12,240 --> 00:10:16,320
and models in banger it's all been on

00:10:14,560 --> 00:10:18,800
top of control gs to support even

00:10:16,320 --> 00:10:20,880
broader public audience

00:10:18,800 --> 00:10:22,079
so they were thinking how fast is

00:10:20,880 --> 00:10:23,680
tendrils.js

00:10:22,079 --> 00:10:25,760
well let's use the mobilenet v2

00:10:23,680 --> 00:10:28,000
benchmark on a laptop

00:10:25,760 --> 00:10:28,959
pendril js runs around 20 milliseconds

00:10:28,000 --> 00:10:31,120
of inference time

00:10:28,959 --> 00:10:32,240
while apple's iphone x is around 22

00:10:31,120 --> 00:10:34,240
milliseconds

00:10:32,240 --> 00:10:36,560
but google's pixel 3 needs a lot of

00:10:34,240 --> 00:10:37,760
improvement but the infrastructure is 78

00:10:36,560 --> 00:10:39,760
milliseconds

00:10:37,760 --> 00:10:41,200
the pinterest team is actively working

00:10:39,760 --> 00:10:43,440
on addressing them

00:10:41,200 --> 00:10:45,279
somewhat on a server side well known on

00:10:43,440 --> 00:10:46,160
cpu is around 23 milliseconds of

00:10:45,279 --> 00:10:48,079
entrance time

00:10:46,160 --> 00:10:49,279
while on a gpu it's around 9

00:10:48,079 --> 00:10:51,600
milliseconds

00:10:49,279 --> 00:10:52,959
the performance run unknown is on par

00:10:51,600 --> 00:10:56,399
with python on c

00:10:52,959 --> 00:11:00,079
both cpu and gpu in fact in some cases

00:10:56,399 --> 00:11:01,760
even faster than the native tensorflow

00:11:00,079 --> 00:11:04,000
once you write your tensionable js code

00:11:01,760 --> 00:11:06,640
you can run anywhere on a modern browser

00:11:04,000 --> 00:11:07,040
mobile device node.js and also electron

00:11:06,640 --> 00:11:09,040
and

00:11:07,040 --> 00:11:10,720
raspberry pi for internet of things it

00:11:09,040 --> 00:11:13,600
truly is a bill once

00:11:10,720 --> 00:11:15,279
run anywhere philosophy so let's get

00:11:13,600 --> 00:11:16,640
started with tendril days in your

00:11:15,279 --> 00:11:19,040
angular application

00:11:16,640 --> 00:11:20,720
to start off create a new english cli

00:11:19,040 --> 00:11:23,120
application

00:11:20,720 --> 00:11:24,320
then install tentroxias using yarn or

00:11:23,120 --> 00:11:26,880
npm

00:11:24,320 --> 00:11:28,800
make sure in your test config.json you

00:11:26,880 --> 00:11:29,920
set skip library check to true in your

00:11:28,800 --> 00:11:31,279
compiler options

00:11:29,920 --> 00:11:33,360
also you might get a compile arrow

00:11:31,279 --> 00:11:35,600
trying to compile

00:11:33,360 --> 00:11:37,680
as with all google projects control gs

00:11:35,600 --> 00:11:39,920
provides highly detailed documentation

00:11:37,680 --> 00:11:41,920
and tutorials on how to get started and

00:11:39,920 --> 00:11:42,560
i highly recommend you check them out

00:11:41,920 --> 00:11:44,160
for now

00:11:42,560 --> 00:11:46,880
consider this your polaroid application

00:11:44,160 --> 00:11:48,480
control gs here we're importing version

00:11:46,880 --> 00:11:49,839
and tensor from central gis

00:11:48,480 --> 00:11:51,519
just like how you import things from

00:11:49,839 --> 00:11:54,000
rxjs then

00:11:51,519 --> 00:11:55,600
on engine on init function here i'm

00:11:54,000 --> 00:11:56,079
console.logging when control j is

00:11:55,600 --> 00:11:57,600
working

00:11:56,079 --> 00:11:59,760
and a two-dimensional attendant to the

00:11:57,600 --> 00:12:02,399
browser developer tool console

00:11:59,760 --> 00:12:03,600
trust me if you can learn rxj guess you

00:12:02,399 --> 00:12:07,040
can definitely master

00:12:03,600 --> 00:12:10,399
temporal js now my grand finale

00:12:07,040 --> 00:12:11,920
drum roll please working digit

00:12:10,399 --> 00:12:14,800
classification lab

00:12:11,920 --> 00:12:16,639
in this lab we'll build a potential gsm

00:12:14,800 --> 00:12:18,399
in the browser from scratch

00:12:16,639 --> 00:12:20,560
they'll recognize handling digits that

00:12:18,399 --> 00:12:21,440
we will write the convolutional neural

00:12:20,560 --> 00:12:23,200
network

00:12:21,440 --> 00:12:25,120
so here's the plan we'll first train the

00:12:23,200 --> 00:12:26,800
classifier by teaching it thousands of

00:12:25,120 --> 00:12:29,200
handwritten digits images

00:12:26,800 --> 00:12:30,480
and their separate labels in a separate

00:12:29,200 --> 00:12:32,240
binary file

00:12:30,480 --> 00:12:34,480
then we'll evaluate the classifies

00:12:32,240 --> 00:12:36,160
accuracy using parent digits that we

00:12:34,480 --> 00:12:38,079
will write that the model has never seen

00:12:36,160 --> 00:12:39,760
before fyi

00:12:38,079 --> 00:12:41,680
this lab uses the latest version of

00:12:39,760 --> 00:12:43,920
angular and tensorflow.js

00:12:41,680 --> 00:12:44,880
so as with all machine learning projects

00:12:43,920 --> 00:12:46,639
you need data

00:12:44,880 --> 00:12:49,040
so the data that we're using is endless

00:12:46,639 --> 00:12:50,480
data or modifying national institute of

00:12:49,040 --> 00:12:53,360
standards technology

00:12:50,480 --> 00:12:55,760
and there's 65 total images in this data

00:12:53,360 --> 00:12:58,720
set it's all comprised of one spy

00:12:55,760 --> 00:13:01,040
and it's around 10 megabytes so each of

00:12:58,720 --> 00:13:04,560
these images 28 by 28 pixels

00:13:01,040 --> 00:13:06,480
and solid grayscale so let's take a look

00:13:04,560 --> 00:13:07,839
at a demo of this you can either click

00:13:06,480 --> 00:13:10,160
this link here

00:13:07,839 --> 00:13:11,680
but i'll be showing it here so not

00:13:10,160 --> 00:13:13,040
everyone can see here

00:13:11,680 --> 00:13:15,279
so here's the place where we will be

00:13:13,040 --> 00:13:16,880
drawing the numbers between 0 and 9

00:13:15,279 --> 00:13:18,800
and the textual just predicted number

00:13:16,880 --> 00:13:20,480
will be shown here

00:13:18,800 --> 00:13:21,839
so i haven't trained my model yet so

00:13:20,480 --> 00:13:24,160
let's say i just write two

00:13:21,839 --> 00:13:24,880
and then say no more foul okay so i

00:13:24,160 --> 00:13:27,920
train my mall

00:13:24,880 --> 00:13:27,920
with four epochs

00:13:28,160 --> 00:13:32,240
so you can see that the data is all 28

00:13:30,240 --> 00:13:33,760
by 28 pixels in this gray cell

00:13:32,240 --> 00:13:36,959
so my visor here i can see my model

00:13:33,760 --> 00:13:39,199
architecture and also my model training

00:13:36,959 --> 00:13:40,000
statistics don't worry if this doesn't

00:13:39,199 --> 00:13:43,519
make sense

00:13:40,000 --> 00:13:45,680
i'll talk about it in just a few minutes

00:13:43,519 --> 00:13:47,920
so now that my model has been trained

00:13:45,680 --> 00:13:48,639
now i can start writing digits for

00:13:47,920 --> 00:13:50,959
example

00:13:48,639 --> 00:13:50,959
one

00:13:52,800 --> 00:13:55,040
one

00:14:01,120 --> 00:14:04,560
okay i guess this doesn't work but let's

00:14:02,560 --> 00:14:06,560
just go to 10 epochs

00:14:04,560 --> 00:14:08,800
so um for 10 epochs let's say i write

00:14:06,560 --> 00:14:09,600
two and it's protected it's two that's

00:14:08,800 --> 00:14:12,959
pretty good

00:14:09,600 --> 00:14:16,399
how about three and predicted it's

00:14:12,959 --> 00:14:17,839
nine and how about nine

00:14:16,399 --> 00:14:19,600
and it's particularly it's nine so my

00:14:17,839 --> 00:14:22,639
models for 10 epochs is

00:14:19,600 --> 00:14:23,279
pretty good except for misclassified one

00:14:22,639 --> 00:14:26,160
of them

00:14:23,279 --> 00:14:27,680
so let's say i train for 40 epochs let's

00:14:26,160 --> 00:14:29,519
take a look at my model again

00:14:27,680 --> 00:14:31,279
so i'm just gonna write two and

00:14:29,519 --> 00:14:34,639
predicted it's two that's pretty good

00:14:31,279 --> 00:14:37,760
how about six and clearly my model here

00:14:34,639 --> 00:14:39,920
for 40 epochs is pretty good but what

00:14:37,760 --> 00:14:42,000
just happened there

00:14:39,920 --> 00:14:43,760
well let's take a look at that so to

00:14:42,000 --> 00:14:45,199
start first step of all machine learning

00:14:43,760 --> 00:14:46,720
projects is that you need to clean the

00:14:45,199 --> 00:14:48,399
data and then load a data

00:14:46,720 --> 00:14:49,519
since the data is already cleaned we

00:14:48,399 --> 00:14:50,480
don't need to clean the data we just

00:14:49,519 --> 00:14:52,959
need to load it there

00:14:50,480 --> 00:14:54,480
so my code i'm calling the mnist data

00:14:52,959 --> 00:14:56,079
class which you can find the source code

00:14:54,480 --> 00:14:58,320
at this url here

00:14:56,079 --> 00:14:59,199
so what this class does is fetches the

00:14:58,320 --> 00:15:01,519
sprite image

00:14:59,199 --> 00:15:03,920
and returns a shuffled image list as you

00:15:01,519 --> 00:15:05,920
can see all these images are 20 by 28

00:15:03,920 --> 00:15:08,399
pixels in our gray scale

00:15:05,920 --> 00:15:10,320
one more important thing that this class

00:15:08,399 --> 00:15:12,160
does is splits data into a training data

00:15:10,320 --> 00:15:14,000
set and a testing data set

00:15:12,160 --> 00:15:15,600
the training data set the data that i'm

00:15:14,000 --> 00:15:17,519
going to use to teach my model

00:15:15,600 --> 00:15:20,000
well a test data set is a date i'm going

00:15:17,519 --> 00:15:21,360
to use to evaluate the performance of my

00:15:20,000 --> 00:15:23,839
model

00:15:21,360 --> 00:15:25,279
so now we need to build my mob to build

00:15:23,839 --> 00:15:26,000
my mouth i'm going to use a sequential

00:15:25,279 --> 00:15:27,600
model

00:15:26,000 --> 00:15:29,759
which by far is the most simplest and

00:15:27,600 --> 00:15:32,079
most popular model architecture

00:15:29,759 --> 00:15:33,680
so this my model aperture will have six

00:15:32,079 --> 00:15:35,440
layers the first layer is going to be my

00:15:33,680 --> 00:15:38,720
input layer where i'll feed my data and

00:15:35,440 --> 00:15:40,240
do my model then there will be four

00:15:38,720 --> 00:15:42,320
hidden layers which will perform the

00:15:40,240 --> 00:15:46,320
required computation for my model

00:15:42,320 --> 00:15:48,880
finally a hidden layer which will

00:15:46,320 --> 00:15:49,440
be the output of my model so i'm going

00:15:48,880 --> 00:15:52,000
to add

00:15:49,440 --> 00:15:53,440
a input layer using the model.and api

00:15:52,000 --> 00:15:54,160
with a convolutional two dimensional

00:15:53,440 --> 00:15:55,279
layer

00:15:54,160 --> 00:15:56,800
what this does is creates a

00:15:55,279 --> 00:15:58,240
convolutional kernel which produces

00:15:56,800 --> 00:16:01,120
tensor outputs

00:15:58,240 --> 00:16:03,440
so my input shape is 28 by 28 by one the

00:16:01,120 --> 00:16:04,000
28 by 28 represents the width times the

00:16:03,440 --> 00:16:06,160
height

00:16:04,000 --> 00:16:07,199
and the one is the image channel which

00:16:06,160 --> 00:16:08,800
is ratio

00:16:07,199 --> 00:16:10,880
i'll also be using the rayleigh

00:16:08,800 --> 00:16:12,560
activation function which keeps all the

00:16:10,880 --> 00:16:15,040
positive values which basically zeroes

00:16:12,560 --> 00:16:17,120
out all of the negative values

00:16:15,040 --> 00:16:18,320
then in my output layer i'm going to

00:16:17,120 --> 00:16:20,079
create a dense line which you can think

00:16:18,320 --> 00:16:22,079
of as a fully connected neural network

00:16:20,079 --> 00:16:23,120
with 10 output units the number of

00:16:22,079 --> 00:16:25,440
output units in

00:16:23,120 --> 00:16:26,720
type problem like this is basically just

00:16:25,440 --> 00:16:28,320
the number of classes that you're

00:16:26,720 --> 00:16:30,880
feeding into your neural network

00:16:28,320 --> 00:16:32,880
in this case 10 and i'll also be using

00:16:30,880 --> 00:16:34,480
the soft mass activation function

00:16:32,880 --> 00:16:36,320
which sums the tenuous probability

00:16:34,480 --> 00:16:37,920
distributions into one

00:16:36,320 --> 00:16:39,440
it's whatever the probability index is

00:16:37,920 --> 00:16:40,800
the highest is going to be our predicted

00:16:39,440 --> 00:16:42,959
number

00:16:40,800 --> 00:16:44,320
so now we need to compile our model we

00:16:42,959 --> 00:16:45,279
can compile our model using the

00:16:44,320 --> 00:16:47,680
model.compile

00:16:45,279 --> 00:16:48,560
api when compiling modeling you set the

00:16:47,680 --> 00:16:51,600
optimizer

00:16:48,560 --> 00:16:53,920
loss and the metrics the optimizer

00:16:51,600 --> 00:16:55,440
is how we're going to tell our model to

00:16:53,920 --> 00:16:56,880
improve on its accuracy

00:16:55,440 --> 00:16:58,639
and loss is how we can validate the

00:16:56,880 --> 00:17:00,160
error and metrics can evaluate the

00:16:58,639 --> 00:17:02,240
performance of our model

00:17:00,160 --> 00:17:04,240
for the optimizer we'll use atom or

00:17:02,240 --> 00:17:05,439
adaptive moment estimation

00:17:04,240 --> 00:17:07,199
and it's most commonly used for

00:17:05,439 --> 00:17:08,160
fantastic gradient descent let's take a

00:17:07,199 --> 00:17:09,600
look at that

00:17:08,160 --> 00:17:11,360
so as you can see from this slide here

00:17:09,600 --> 00:17:11,839
gradient descent you think of it as a

00:17:11,360 --> 00:17:14,160
ball

00:17:11,839 --> 00:17:15,919
and the lowest point of the ball is our

00:17:14,160 --> 00:17:17,439
goal

00:17:15,919 --> 00:17:19,199
we also need to set a learning rate you

00:17:17,439 --> 00:17:20,640
can think of it as a ball so

00:17:19,199 --> 00:17:22,799
you can think of it as a ball putting it

00:17:20,640 --> 00:17:24,319
into a drain so you shoot the ball too

00:17:22,799 --> 00:17:26,240
fast go right past that drain

00:17:24,319 --> 00:17:27,919
if you shoot the ball too slow you're

00:17:26,240 --> 00:17:28,480
not going to have enough momentum to get

00:17:27,919 --> 00:17:30,960
to the

00:17:28,480 --> 00:17:32,400
ball into the bowl and the last thing

00:17:30,960 --> 00:17:33,919
i'll be using is the categorical cost

00:17:32,400 --> 00:17:35,520
entropy which will measure the error

00:17:33,919 --> 00:17:37,360
between the probability distribution

00:17:35,520 --> 00:17:38,960
divided by the last layer of the model

00:17:37,360 --> 00:17:40,960
and the probability distribution given

00:17:38,960 --> 00:17:42,400
by the true label

00:17:40,960 --> 00:17:44,880
and for the metrics i'm going to set

00:17:42,400 --> 00:17:46,400
accuracy so now we need to train them

00:17:44,880 --> 00:17:47,919
all when training our model we need to

00:17:46,400 --> 00:17:50,240
train them all on the trend

00:17:47,919 --> 00:17:51,039
data set in this case train x which is

00:17:50,240 --> 00:17:52,400
our data set

00:17:51,039 --> 00:17:54,880
and training which is going to be the

00:17:52,400 --> 00:17:56,080
training labels we'll also set the batch

00:17:54,880 --> 00:17:58,240
size of 500 tall

00:17:56,080 --> 00:17:59,520
and the usual to find the e-box the

00:17:58,240 --> 00:18:00,080
total number of batches we'll train on

00:17:59,520 --> 00:18:02,400
will be

00:18:00,080 --> 00:18:04,480
512 times the number of epochs and the

00:18:02,400 --> 00:18:06,000
validations data which is the parameter

00:18:04,480 --> 00:18:08,559
of the data that we'll be

00:18:06,000 --> 00:18:09,600
um using to validate our model is test x

00:18:08,559 --> 00:18:10,799
and test y

00:18:09,600 --> 00:18:12,720
we'll also be setting the shuffle

00:18:10,799 --> 00:18:14,240
parameter true

00:18:12,720 --> 00:18:16,320
which is going to make sure our data set

00:18:14,240 --> 00:18:17,840
is not in the given order

00:18:16,320 --> 00:18:19,600
so on the graph here on the first graph

00:18:17,840 --> 00:18:21,360
here you can see the lines moving down

00:18:19,600 --> 00:18:23,200
that's good as we're minimizing the

00:18:21,360 --> 00:18:24,640
error of our model the second graph

00:18:23,200 --> 00:18:26,320
there's a line that's going up

00:18:24,640 --> 00:18:28,400
that's telling us that our model is

00:18:26,320 --> 00:18:28,880
maximizing its accuracy in machine

00:18:28,400 --> 00:18:30,160
learning

00:18:28,880 --> 00:18:32,960
our goal is to minimize the loss and

00:18:30,160 --> 00:18:35,120
also maximize the accuracy of our model

00:18:32,960 --> 00:18:36,000
so i trained my model on 25 epochs and

00:18:35,120 --> 00:18:38,320
this is what i got

00:18:36,000 --> 00:18:39,120
i got an accuracy and a confusion matrix

00:18:38,320 --> 00:18:42,080
so accuracy

00:18:39,120 --> 00:18:42,720
for example henry digit class 9 i fit in

00:18:42,080 --> 00:18:45,840
00:18:42,720 --> 00:18:46,720
um samples to my model and got 100 of

00:18:45,840 --> 00:18:48,240
accuracy

00:18:46,720 --> 00:18:50,000
but some of these are not so good for

00:18:48,240 --> 00:18:53,039
example the henry integer class

00:18:50,000 --> 00:18:53,520
3. i fit in 54 in my samples from a

00:18:53,039 --> 00:18:56,320
model

00:18:53,520 --> 00:18:57,600
and i only got around 89 accuracy here's

00:18:56,320 --> 00:18:59,200
a challenge for you

00:18:57,600 --> 00:19:00,880
trying to play around with my model and

00:18:59,200 --> 00:19:02,640
also the number of epochs trained

00:19:00,880 --> 00:19:04,000
to get a better validation score than

00:19:02,640 --> 00:19:05,919
what i got

00:19:04,000 --> 00:19:07,440
so now we need to make our predictions

00:19:05,919 --> 00:19:09,280
so whenever the user

00:19:07,440 --> 00:19:10,960
writes something in the canvas when you

00:19:09,280 --> 00:19:12,400
call the pc model and execute the

00:19:10,960 --> 00:19:13,840
internet for the input tensor

00:19:12,400 --> 00:19:16,559
and convert that to your stream and show

00:19:13,840 --> 00:19:18,320
it to the user back in the ui

00:19:16,559 --> 00:19:21,760
so you can find the source code for this

00:19:18,320 --> 00:19:23,440
demo at this github repository here

00:19:21,760 --> 00:19:25,280
so congratulations on making through

00:19:23,440 --> 00:19:26,480
this talk just a few more slides before

00:19:25,280 --> 00:19:28,240
i'm done here

00:19:26,480 --> 00:19:29,440
so currently there's a twitter campaign

00:19:28,240 --> 00:19:29,919
where you can see what the community has

00:19:29,440 --> 00:19:31,840
made

00:19:29,919 --> 00:19:33,200
and share your work in central.js using

00:19:31,840 --> 00:19:36,960
that hashtag

00:19:33,200 --> 00:19:38,799
made with tfjs as larry page who's the

00:19:36,960 --> 00:19:40,720
co-founder of google once said

00:19:38,799 --> 00:19:41,840
artificial intelligence was the ultimate

00:19:40,720 --> 00:19:43,440
version of google

00:19:41,840 --> 00:19:44,880
thank you for that inspirational quote

00:19:43,440 --> 00:19:46,160
about ai land page

00:19:44,880 --> 00:19:48,160
so here's some next update on machine

00:19:46,160 --> 00:19:49,200
learning you can see all these stuff and

00:19:48,160 --> 00:19:51,520
you're like

00:19:49,200 --> 00:19:53,360
which one should i do now first well

00:19:51,520 --> 00:19:56,160
that's why i'm today i'm watching

00:19:53,360 --> 00:19:58,080
awesome tensorflow.js which you can find

00:19:56,160 --> 00:19:58,880
at this dinner repository which is a

00:19:58,080 --> 00:20:01,280
current

00:19:58,880 --> 00:20:02,159
list of data entertaining resources to

00:20:01,280 --> 00:20:05,360
help you

00:20:02,159 --> 00:20:06,240
master tensorflow.js now my takeaways in

00:20:05,360 --> 00:20:08,320
my talk

00:20:06,240 --> 00:20:09,760
machine learning is using technology to

00:20:08,320 --> 00:20:11,200
answer questions with data

00:20:09,760 --> 00:20:13,039
and machine learning is more concept

00:20:11,200 --> 00:20:15,280
heavy and cone less

00:20:13,039 --> 00:20:16,799
and currently technologies is the most

00:20:15,280 --> 00:20:17,360
popular machine learning javascript

00:20:16,799 --> 00:20:19,200
library

00:20:17,360 --> 00:20:21,679
and getting started with central js is

00:20:19,200 --> 00:20:23,440
as easy as using rxjs

00:20:21,679 --> 00:20:24,960
and machine learning is for everyone

00:20:23,440 --> 00:20:27,360
machine learning for

00:20:24,960 --> 00:20:28,080
everyone which means you yeah you send

00:20:27,360 --> 00:20:29,440
yours here

00:20:28,080 --> 00:20:31,280
you can become a machine learning

00:20:29,440 --> 00:20:35,520
engineer with a little help from

00:20:31,280 --> 00:20:37,760
google's js

00:20:35,520 --> 00:20:37,760
um

00:20:38,960 --> 00:20:41,600
can you hear me

00:20:42,390 --> 00:20:45,840
[Music]

00:20:43,679 --> 00:20:47,600
machine learning is for everyone and

00:20:45,840 --> 00:20:50,000
machine is for everyone which means

00:20:47,600 --> 00:20:51,679
you yeah you sit in your chair you can

00:20:50,000 --> 00:20:54,159
become a machine learning engineer with

00:20:51,679 --> 00:20:56,320
a little help from google's tentacle.js

00:20:54,159 --> 00:20:57,600
so thank you for listening i'm aaron

00:20:56,320 --> 00:20:59,039
matt don't forget to check out my cool

00:20:57,600 --> 00:21:00,720
website aaronhmatt.com

00:20:59,039 --> 00:21:02,720
sending you a high at earringsman.com

00:21:00,720 --> 00:21:04,080
available for 14 hours seven days

00:21:02,720 --> 00:21:06,000
and don't forget to follow me on twitter

00:21:04,080 --> 00:21:07,919
at aaron small i'll be posting my slide

00:21:06,000 --> 00:21:09,679
deck and all of the demos used and also

00:21:07,919 --> 00:21:10,159
regular tips and tricks into machine

00:21:09,679 --> 00:21:13,760
learning

00:21:10,159 --> 00:21:13,760
thank you for listening and have a great

00:21:14,840 --> 00:21:19,770
day

00:21:16,610 --> 00:21:19,770
[Applause]

00:21:20,070 --> 00:21:25,449
[Music]

00:21:20,830 --> 00:21:25,449
[Applause]

00:21:26,320 --> 00:21:28,400

YouTube URL: https://www.youtube.com/watch?v=zIbeUR0eAvg


