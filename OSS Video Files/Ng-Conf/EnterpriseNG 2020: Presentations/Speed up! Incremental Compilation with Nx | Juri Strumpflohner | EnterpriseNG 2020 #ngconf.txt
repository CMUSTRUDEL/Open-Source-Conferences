Title: Speed up! Incremental Compilation with Nx | Juri Strumpflohner | EnterpriseNG 2020Â #ngconf
Publication date: 2021-06-14
Playlist: EnterpriseNG 2020: Presentations
Description: 
	At Nrwl we work with some of the worldâ€™s biggest companies. By working alongside their teams, we directly experience the problems and pain points they face on a daily basis, especially when it comes to scaling products and code bases across such large enterprises. These lessons directly influence how we build Nx. We understand the importance of proper DX and how much time and money it can save businesses.

Speed is one such important characteristic. The fewer time developers have to wait for their CI pipeline to finish, or their app to recompile, the less they get distracted and hence can be more focused and productive. We recently introduced Nxâ€™s computation caching, which together with Nx Cloud addresses precisely that problem. In this talk, weâ€™re exploring how computation caching enables us to go to the next level: implementing incremental compilation in Nx.

Learn the best ways to build reliable web applications, write quality code, choose scalable architectures, and create effective automated tests at the Reliable Web Summit this August 26-27, 2021. Powered by the team at ng-conf.
Get your ticket ðŸ‘‰ https://reliablewebsummit.com/

ng-conf is a multi-day Angular conference focused on delivering the highest quality training in the Angular JavaScript framework. 1000's of developers from across the globe join together to attend talks and workshops by the Angular team and other community experts.

Follow us on twitter https://twitter.com/ngconfâ€‹ 
Official Website: https://www.ng-conf.org/
Captions: 
	00:00:00,120 --> 00:00:17,920
[Music]

00:00:03,840 --> 00:00:21,279
let us

00:00:17,920 --> 00:00:23,279
all right welcome everyone and i'm super

00:00:21,279 --> 00:00:23,920
happy to be here today and be able to

00:00:23,279 --> 00:00:26,000
talk to you

00:00:23,920 --> 00:00:27,680
about speed up incremental compilation

00:00:26,000 --> 00:00:29,439
with annex

00:00:27,680 --> 00:00:31,359
but before we start let me quickly

00:00:29,439 --> 00:00:33,440
introduce myself

00:00:31,359 --> 00:00:35,520
my name is your stromflower i'm from the

00:00:33,440 --> 00:00:37,120
very northern part of italy

00:00:35,520 --> 00:00:38,800
i'm a google developer expert in web

00:00:37,120 --> 00:00:41,120
technologies in angular

00:00:38,800 --> 00:00:43,680
i'm also an instructor at a head i o and

00:00:41,120 --> 00:00:45,840
cypress ambassador

00:00:43,680 --> 00:00:47,840
i work at novel as a javascript

00:00:45,840 --> 00:00:50,320
architect and engineering manager

00:00:47,840 --> 00:00:52,320
and as you probably know already novel

00:00:50,320 --> 00:00:53,199
has been founded by viktor saffin and

00:00:52,320 --> 00:00:55,360
jeff gross

00:00:53,199 --> 00:00:56,399
now already i think like four years ago

00:00:55,360 --> 00:00:59,199
already

00:00:56,399 --> 00:00:59,600
and what we try to do there or what we

00:00:59,199 --> 00:01:02,160
do

00:00:59,600 --> 00:01:03,840
is basically help your team learn grow

00:01:02,160 --> 00:01:06,400
and be successful

00:01:03,840 --> 00:01:08,080
and we do that in a variety of ways and

00:01:06,400 --> 00:01:08,880
so first of all we help you plan your

00:01:08,080 --> 00:01:11,360
priorities

00:01:08,880 --> 00:01:13,280
lay out the road map and especially help

00:01:11,360 --> 00:01:15,280
identify potential technical constraints

00:01:13,280 --> 00:01:16,320
that might hinder you achieving your end

00:01:15,280 --> 00:01:18,479
goal

00:01:16,320 --> 00:01:20,000
and what we also do obviously is to do

00:01:18,479 --> 00:01:21,680
training uh we do that

00:01:20,000 --> 00:01:23,840
in forms of workshops which we hold

00:01:21,680 --> 00:01:25,520
online or on-site we talk at conferences

00:01:23,840 --> 00:01:27,840
like this one today

00:01:25,520 --> 00:01:29,680
but anyhow the preferred way of

00:01:27,840 --> 00:01:31,040
collaboration for us is definitely to be

00:01:29,680 --> 00:01:33,200
embedded and partisan

00:01:31,040 --> 00:01:35,200
of your team because obviously that's

00:01:33,200 --> 00:01:36,079
where we actually see the daily problems

00:01:35,200 --> 00:01:38,880
as they come up

00:01:36,079 --> 00:01:40,000
we can help you coach you specifically

00:01:38,880 --> 00:01:42,000
on those problems

00:01:40,000 --> 00:01:43,600
and basically have an ongoing training

00:01:42,000 --> 00:01:45,840
and collaboration as the project

00:01:43,600 --> 00:01:48,240
progresses

00:01:45,840 --> 00:01:49,360
so today i would like to mostly talk

00:01:48,240 --> 00:01:52,159
about nx

00:01:49,360 --> 00:01:53,840
and x is our open source dev tools for

00:01:52,159 --> 00:01:54,079
monorepo and you can actually check it

00:01:53,840 --> 00:01:58,399
out

00:01:54,079 --> 00:02:01,040
on nx.dev or directly on github

00:01:58,399 --> 00:02:01,920
so let's talk about speed and now we at

00:02:01,040 --> 00:02:04,399
novel are

00:02:01,920 --> 00:02:05,360
strong believers in monterey post and

00:02:04,399 --> 00:02:06,960
that's for

00:02:05,360 --> 00:02:08,800
a couple of different reasons like first

00:02:06,960 --> 00:02:11,360
of all we obviously believe that

00:02:08,800 --> 00:02:12,959
it helps you ship code much faster and

00:02:11,360 --> 00:02:14,800
that's because you can share

00:02:12,959 --> 00:02:16,959
code more easily you have everything

00:02:14,800 --> 00:02:18,560
like in one repository and you can build

00:02:16,959 --> 00:02:20,560
things there much more efficiently and

00:02:18,560 --> 00:02:22,080
identify issues much earlier than you

00:02:20,560 --> 00:02:25,200
would in a much distributed

00:02:22,080 --> 00:02:26,640
fashion but there are downsides as well

00:02:25,200 --> 00:02:27,840
of course and that's where tooling comes

00:02:26,640 --> 00:02:31,440
into place and that's where

00:02:27,840 --> 00:02:33,840
like nx comes into place so normally

00:02:31,440 --> 00:02:35,920
what an approach could be is that you

00:02:33,840 --> 00:02:37,840
start with an application in nx and in

00:02:35,920 --> 00:02:39,599
the next you have basically

00:02:37,840 --> 00:02:41,760
abs and lips that's the main structure

00:02:39,599 --> 00:02:43,599
like that's the building block

00:02:41,760 --> 00:02:45,680
and you basically as you develop and you

00:02:43,599 --> 00:02:47,120
continue you might even like identify

00:02:45,680 --> 00:02:48,080
that that single application could be

00:02:47,120 --> 00:02:50,640
split up into

00:02:48,080 --> 00:02:52,319
multiple ones which will again help you

00:02:50,640 --> 00:02:54,000
scale in the long term because now you

00:02:52,319 --> 00:02:55,599
have like two different applications

00:02:54,000 --> 00:02:57,680
which can be deployed

00:02:55,599 --> 00:02:59,519
in a different scaling environment you

00:02:57,680 --> 00:03:02,000
can like scale up the public one

00:02:59,519 --> 00:03:03,680
much much more than maybe the more back

00:03:02,000 --> 00:03:04,640
office administration part of your

00:03:03,680 --> 00:03:06,400
application

00:03:04,640 --> 00:03:07,680
and you can already see how those

00:03:06,400 --> 00:03:09,920
applications simply

00:03:07,680 --> 00:03:11,280
reference the libraries where most of

00:03:09,920 --> 00:03:14,480
the part of the code

00:03:11,280 --> 00:03:15,440
actually lives and as you continue in a

00:03:14,480 --> 00:03:17,120
modern repo

00:03:15,440 --> 00:03:19,040
you might even add other technologies

00:03:17,120 --> 00:03:21,040
like not just angular but you might also

00:03:19,040 --> 00:03:23,040
add back-end technologies ideally

00:03:21,040 --> 00:03:25,519
for instance like nest js applications

00:03:23,040 --> 00:03:27,200
or node plane node express apps

00:03:25,519 --> 00:03:29,120
and they should be able to share code

00:03:27,200 --> 00:03:30,959
with your front end you might even add a

00:03:29,120 --> 00:03:31,360
react front or some other type of front

00:03:30,959 --> 00:03:35,040
end

00:03:31,360 --> 00:03:37,920
technology there but obviously

00:03:35,040 --> 00:03:38,879
as things continue you don't always want

00:03:37,920 --> 00:03:41,840
to like

00:03:38,879 --> 00:03:43,120
build test lint everything like like if

00:03:41,840 --> 00:03:46,080
you develop a new feature

00:03:43,120 --> 00:03:48,159
and you create a new pr on your ci

00:03:46,080 --> 00:03:50,159
pipeline then you don't want to run the

00:03:48,159 --> 00:03:52,080
build of all the various products which

00:03:50,159 --> 00:03:53,519
you might have in your moderator

00:03:52,080 --> 00:03:55,360
because like initially when you have

00:03:53,519 --> 00:03:56,159
just one or two apps it might even work

00:03:55,360 --> 00:03:58,720
but as like

00:03:56,159 --> 00:04:00,319
your applications grow and you have like

00:03:58,720 --> 00:04:02,159
much more and more libraries which could

00:04:00,319 --> 00:04:03,680
even go into hundreds of libraries

00:04:02,159 --> 00:04:06,480
then you can imagine that this would

00:04:03,680 --> 00:04:08,720
simply not scale

00:04:06,480 --> 00:04:10,480
so for instance a naive run here which

00:04:08,720 --> 00:04:12,159
is visualized by this timeline here you

00:04:10,480 --> 00:04:13,680
can see like that one project follows

00:04:12,159 --> 00:04:15,280
after the other so the different colors

00:04:13,680 --> 00:04:16,160
represent different projects that have

00:04:15,280 --> 00:04:17,919
to be built

00:04:16,160 --> 00:04:19,759
and obviously the time you have to spend

00:04:17,919 --> 00:04:22,000
on ci in this scenario

00:04:19,759 --> 00:04:25,680
is basically the total time of all the

00:04:22,000 --> 00:04:27,199
projects being built one after the other

00:04:25,680 --> 00:04:29,360
and so what happens usually in the

00:04:27,199 --> 00:04:31,120
development so you have your

00:04:29,360 --> 00:04:32,960
git repository where you have like your

00:04:31,120 --> 00:04:33,919
master or main which is the main branch

00:04:32,960 --> 00:04:35,759
basically

00:04:33,919 --> 00:04:36,960
people then your developers pick out

00:04:35,759 --> 00:04:39,360
features or

00:04:36,960 --> 00:04:40,400
or fix fixes for like potential issues

00:04:39,360 --> 00:04:41,919
that you have

00:04:40,400 --> 00:04:43,759
and so they're developing their feature

00:04:41,919 --> 00:04:45,440
branches which they then submit up into

00:04:43,759 --> 00:04:48,240
the ci pipeline

00:04:45,440 --> 00:04:50,400
usually bias on pr and as things

00:04:48,240 --> 00:04:52,720
continue then this ti pipeline picks out

00:04:50,400 --> 00:04:54,720
those prs it runs the building testing

00:04:52,720 --> 00:04:56,400
linting whatever you actually execute on

00:04:54,720 --> 00:04:58,960
your ci pipeline

00:04:56,400 --> 00:05:00,240
and once that like passes it gets merged

00:04:58,960 --> 00:05:02,400
in back into master

00:05:00,240 --> 00:05:04,240
and so this could basically guarantees

00:05:02,400 --> 00:05:05,759
the health of your development cycle the

00:05:04,240 --> 00:05:06,960
quality of the code that ends up in

00:05:05,759 --> 00:05:08,960
master

00:05:06,960 --> 00:05:10,560
now you can imagine as we continue and

00:05:08,960 --> 00:05:11,840
as more developers work on your

00:05:10,560 --> 00:05:14,160
repository

00:05:11,840 --> 00:05:15,680
that queue on the ci pipeline might soon

00:05:14,160 --> 00:05:16,639
become the bottleneck because like what

00:05:15,680 --> 00:05:19,039
happens there

00:05:16,639 --> 00:05:20,720
is you basically have also like

00:05:19,039 --> 00:05:22,479
reviewing process going on so you might

00:05:20,720 --> 00:05:24,639
have to do changes you might have to

00:05:22,479 --> 00:05:26,320
update your pr based on the latest

00:05:24,639 --> 00:05:28,639
changes that happen in master and so do

00:05:26,320 --> 00:05:30,400
a rebasing basically

00:05:28,639 --> 00:05:32,240
and so this is clearly the potential

00:05:30,400 --> 00:05:33,759
bottleneck as we continue because like

00:05:32,240 --> 00:05:35,520
if that pr

00:05:33,759 --> 00:05:38,000
like if a single pr can only be

00:05:35,520 --> 00:05:40,400
processed like in an hour or even more

00:05:38,000 --> 00:05:42,240
by your ci server then obviously you can

00:05:40,400 --> 00:05:45,280
only get that much into your

00:05:42,240 --> 00:05:47,440
master branch in a given day

00:05:45,280 --> 00:05:49,280
and so an x helps there with the

00:05:47,440 --> 00:05:52,240
so-called affected commands

00:05:49,280 --> 00:05:52,720
and i also kind of always or often call

00:05:52,240 --> 00:05:54,880
them

00:05:52,720 --> 00:05:56,000
like an x knows what you're actually

00:05:54,880 --> 00:05:58,479
building

00:05:56,000 --> 00:06:01,120
so why is that well basically behind the

00:05:58,479 --> 00:06:02,000
scenes nx has the so-called dependency

00:06:01,120 --> 00:06:04,160
graph

00:06:02,000 --> 00:06:05,440
and in like you know that small terminal

00:06:04,160 --> 00:06:06,960
there on the slide you can actually see

00:06:05,440 --> 00:06:08,560
how you can invoke that and you can

00:06:06,960 --> 00:06:10,560
basically at any point run

00:06:08,560 --> 00:06:12,160
an x depth graph which will visualize

00:06:10,560 --> 00:06:14,400
your this dependency graph

00:06:12,160 --> 00:06:16,240
which is the current representation of

00:06:14,400 --> 00:06:17,840
the relations between your

00:06:16,240 --> 00:06:20,160
apps and libraries and even between

00:06:17,840 --> 00:06:21,919
libraries themselves

00:06:20,160 --> 00:06:23,840
and now this is obviously super powerful

00:06:21,919 --> 00:06:25,199
because if it's not something you

00:06:23,840 --> 00:06:27,600
like create as part of your

00:06:25,199 --> 00:06:29,120
documentation and we all know that

00:06:27,600 --> 00:06:31,199
as we create those diagrams they are

00:06:29,120 --> 00:06:31,680
often already out of date or they don't

00:06:31,199 --> 00:06:34,240
reflect

00:06:31,680 --> 00:06:34,800
actual truth and since this is being

00:06:34,240 --> 00:06:36,479
like

00:06:34,800 --> 00:06:39,360
read out of your current source code

00:06:36,479 --> 00:06:41,840
state this is always up to date

00:06:39,360 --> 00:06:42,960
but moreover there's a an important

00:06:41,840 --> 00:06:44,639
thing here

00:06:42,960 --> 00:06:46,400
this dependency graph is not just for

00:06:44,639 --> 00:06:47,280
visualization purposes but it's actually

00:06:46,400 --> 00:06:50,560
being used by an

00:06:47,280 --> 00:06:51,759
x in order to optimize certain commands

00:06:50,560 --> 00:06:53,840
and so for instance there is the

00:06:51,759 --> 00:06:55,680
so-called affected dependency graph or

00:06:53,840 --> 00:06:58,160
the affected commands in general

00:06:55,680 --> 00:07:00,479
which allows you to identify only what

00:06:58,160 --> 00:07:02,720
changed in a given feature request

00:07:00,479 --> 00:07:05,520
so imagine like your developer creates a

00:07:02,720 --> 00:07:07,199
pr it changes a couple of libraries

00:07:05,520 --> 00:07:09,680
and then it pushes them up as a pr

00:07:07,199 --> 00:07:11,759
basically on your ci server

00:07:09,680 --> 00:07:12,720
if you use those affected commands nx

00:07:11,759 --> 00:07:15,039
can actually

00:07:12,720 --> 00:07:16,720
read those comments that have been made

00:07:15,039 --> 00:07:17,919
compare them to the baseline which is

00:07:16,720 --> 00:07:20,639
usually like

00:07:17,919 --> 00:07:22,240
master or main and then identify based

00:07:20,639 --> 00:07:23,520
on those comments which projects have

00:07:22,240 --> 00:07:24,960
been touched

00:07:23,520 --> 00:07:26,720
so in this case for instance we can see

00:07:24,960 --> 00:07:28,560
that just those three basically

00:07:26,720 --> 00:07:30,160
are affected and so they have been

00:07:28,560 --> 00:07:31,840
basically modified

00:07:30,160 --> 00:07:33,520
and all the other projects in this

00:07:31,840 --> 00:07:35,120
entire graph basically

00:07:33,520 --> 00:07:37,440
can be left untouched and so we don't

00:07:35,120 --> 00:07:39,440
even have to execute the testing linting

00:07:37,440 --> 00:07:41,039
whatever on all those projects and you

00:07:39,440 --> 00:07:42,560
can imagine like this drastically

00:07:41,039 --> 00:07:44,639
already improves the speed

00:07:42,560 --> 00:07:47,039
because now only those three have to be

00:07:44,639 --> 00:07:48,800
touched and treated

00:07:47,039 --> 00:07:51,199
and you can use those effective commands

00:07:48,800 --> 00:07:52,800
basically with that nx affected colon

00:07:51,199 --> 00:07:53,440
and then the target you want to execute

00:07:52,800 --> 00:07:56,479
which could be

00:07:53,440 --> 00:07:59,759
test building or even targets you define

00:07:56,479 --> 00:08:00,879
by your own and so if you compare that

00:07:59,759 --> 00:08:02,639
again now to

00:08:00,879 --> 00:08:04,639
the main naive approach which we had

00:08:02,639 --> 00:08:06,720
initially we can already see that we can

00:08:04,639 --> 00:08:08,160
cut down the times quite a lot

00:08:06,720 --> 00:08:09,840
obviously this depends on the change you

00:08:08,160 --> 00:08:10,479
make and how many libraries you actually

00:08:09,840 --> 00:08:12,400
touch

00:08:10,479 --> 00:08:14,080
but like this could be a good average

00:08:12,400 --> 00:08:16,479
which we actually observe with our

00:08:14,080 --> 00:08:16,479
clients

00:08:16,560 --> 00:08:19,759
we can even go ahead and what we can do

00:08:19,120 --> 00:08:22,960
is we can

00:08:19,759 --> 00:08:25,280
parallelize work so basically

00:08:22,960 --> 00:08:27,680
we can again take that nx affected

00:08:25,280 --> 00:08:30,400
command but now we pass into dash dash

00:08:27,680 --> 00:08:31,440
parallel or dash dash max parallel

00:08:30,400 --> 00:08:33,440
equals four

00:08:31,440 --> 00:08:35,519
and what that does what does what that

00:08:33,440 --> 00:08:38,320
does is basically just like

00:08:35,519 --> 00:08:39,279
spawn different threads that run the

00:08:38,320 --> 00:08:40,880
different kind of

00:08:39,279 --> 00:08:42,240
test ones so in this case we are

00:08:40,880 --> 00:08:43,599
executing tests and so this would

00:08:42,240 --> 00:08:45,440
basically divide them up

00:08:43,599 --> 00:08:47,279
into equal batches and run them into

00:08:45,440 --> 00:08:50,640
different processes

00:08:47,279 --> 00:08:52,000
and the max parallel actually tells nx

00:08:50,640 --> 00:08:52,880
like how many of those should be

00:08:52,000 --> 00:08:54,480
instantiated

00:08:52,880 --> 00:08:56,160
and that's mostly for limiting basically

00:08:54,480 --> 00:08:59,279
the capacity you have in your machine or

00:08:56,160 --> 00:09:01,680
you're on your ci server

00:08:59,279 --> 00:09:03,839
you can even go further you cannot only

00:09:01,680 --> 00:09:06,240
just parallelize but we can also

00:09:03,839 --> 00:09:08,000
distribute them across different nodes

00:09:06,240 --> 00:09:09,600
so in this screenshot here you can see

00:09:08,000 --> 00:09:12,720
like an actual run on

00:09:09,600 --> 00:09:15,200
a gitlab which where basically the tests

00:09:12,720 --> 00:09:16,800
are not only paralyzed within each node

00:09:15,200 --> 00:09:18,560
but they're also distributed among

00:09:16,800 --> 00:09:20,000
different kind of machines in this case

00:09:18,560 --> 00:09:21,360
eight different machines

00:09:20,000 --> 00:09:23,120
and so you can imagine this already

00:09:21,360 --> 00:09:24,640
speeds up things a lot and if you're

00:09:23,120 --> 00:09:27,200
interested in distributing

00:09:24,640 --> 00:09:28,720
your ci pipeline then there's a link on

00:09:27,200 --> 00:09:30,560
this slide on the very lower

00:09:28,720 --> 00:09:32,160
right which you can like click on and we

00:09:30,560 --> 00:09:32,800
have a couple of example configurations

00:09:32,160 --> 00:09:35,360
there

00:09:32,800 --> 00:09:38,720
uh to get you started and like continue

00:09:35,360 --> 00:09:38,720
and set it up for your own build

00:09:38,800 --> 00:09:43,440
and so again if we now take this into

00:09:40,640 --> 00:09:44,959
account then the longest like your total

00:09:43,440 --> 00:09:46,800
ci time basically

00:09:44,959 --> 00:09:48,480
is equal to the slowest part right

00:09:46,800 --> 00:09:50,399
because now we run them in parallel and

00:09:48,480 --> 00:09:52,320
no more in sequence and therefore the

00:09:50,399 --> 00:09:55,120
slowest one determines the total time

00:09:52,320 --> 00:09:56,240
you need to run on your ci but you

00:09:55,120 --> 00:09:59,200
already can see

00:09:56,240 --> 00:09:59,200
a lot of improvements

00:09:59,360 --> 00:10:04,079
another thing i'm super excited about is

00:10:01,279 --> 00:10:05,760
the actual computation caching so what

00:10:04,079 --> 00:10:08,079
computation caching does

00:10:05,760 --> 00:10:10,000
uh this is something on top basically on

00:10:08,079 --> 00:10:12,240
of the factor command

00:10:10,000 --> 00:10:13,360
and what happens there is that if you

00:10:12,240 --> 00:10:15,920
execute nx

00:10:13,360 --> 00:10:17,440
run for instance shop card feature which

00:10:15,920 --> 00:10:20,399
could be like own library

00:10:17,440 --> 00:10:22,240
and the tests on top of that library

00:10:20,399 --> 00:10:22,720
what the nx does in this case it

00:10:22,240 --> 00:10:24,959
actually

00:10:22,720 --> 00:10:26,800
takes the source files into account it

00:10:24,959 --> 00:10:27,920
also takes like the config files which

00:10:26,800 --> 00:10:29,680
you might have

00:10:27,920 --> 00:10:31,120
some runtime inputs which you can even

00:10:29,680 --> 00:10:32,160
define on your own like environment

00:10:31,120 --> 00:10:34,560
variables

00:10:32,160 --> 00:10:35,680
and then it verifies whether that

00:10:34,560 --> 00:10:37,600
command against

00:10:35,680 --> 00:10:39,440
those different artifacts has already

00:10:37,600 --> 00:10:41,200
been executed before

00:10:39,440 --> 00:10:42,800
if it has not been executed it actually

00:10:41,200 --> 00:10:44,720
executes the command like in this case

00:10:42,800 --> 00:10:46,720
it runs a couple of chest tests

00:10:44,720 --> 00:10:48,399
and then stores the result in a local

00:10:46,720 --> 00:10:50,720
cache which usually lives

00:10:48,399 --> 00:10:53,200
in a node modules folder dot cache could

00:10:50,720 --> 00:10:55,920
even be configured if wanted

00:10:53,200 --> 00:10:57,360
however if that command has already been

00:10:55,920 --> 00:10:59,279
executed in the past

00:10:57,360 --> 00:11:00,640
it doesn't actually re-execute it

00:10:59,279 --> 00:11:01,279
because there's no point to execute

00:11:00,640 --> 00:11:03,279
actual

00:11:01,279 --> 00:11:04,800
command again but what the next does on

00:11:03,279 --> 00:11:07,519
this uh like instead

00:11:04,800 --> 00:11:09,040
is restore that cache output and

00:11:07,519 --> 00:11:11,920
visualize it in your

00:11:09,040 --> 00:11:13,440
console cli so in that case for a test

00:11:11,920 --> 00:11:15,440
run you would actually see just

00:11:13,440 --> 00:11:16,800
like the actual output with some small

00:11:15,440 --> 00:11:19,120
note that this has been like

00:11:16,800 --> 00:11:20,240
taken out of the cache but this doesn't

00:11:19,120 --> 00:11:22,560
only work for like

00:11:20,240 --> 00:11:23,519
printing the output on ci like on your

00:11:22,560 --> 00:11:25,680
cli

00:11:23,519 --> 00:11:27,600
but also for process like to build where

00:11:25,680 --> 00:11:28,560
you actually create artifacts that are

00:11:27,600 --> 00:11:30,160
being like placed

00:11:28,560 --> 00:11:32,160
like actual javascript files which are

00:11:30,160 --> 00:11:35,519
being placed into this folder

00:11:32,160 --> 00:11:37,279
they would also be restored

00:11:35,519 --> 00:11:39,360
and so if you take now into account

00:11:37,279 --> 00:11:41,519
though these caching features

00:11:39,360 --> 00:11:43,360
what we observe is we even we can even

00:11:41,519 --> 00:11:45,360
speed up things even more

00:11:43,360 --> 00:11:47,440
because now we don't even just run them

00:11:45,360 --> 00:11:47,760
in parallel but it might happen that we

00:11:47,440 --> 00:11:50,399
have

00:11:47,760 --> 00:11:50,880
executed those commands before so in our

00:11:50,399 --> 00:11:53,040
like

00:11:50,880 --> 00:11:54,639
local execution of the test runs we

00:11:53,040 --> 00:11:55,279
might already have executed certain

00:11:54,639 --> 00:11:57,040
libraries

00:11:55,279 --> 00:11:58,720
and so the caching like a computation

00:11:57,040 --> 00:12:00,560
cache would actually deal with that

00:11:58,720 --> 00:12:01,920
and not execute those commands again so

00:12:00,560 --> 00:12:05,920
we can even reduce them

00:12:01,920 --> 00:12:05,920
based on what we executed in the past

00:12:07,200 --> 00:12:10,800
it gets even more interesting if we now

00:12:09,519 --> 00:12:14,720
distribute that because

00:12:10,800 --> 00:12:16,800
as we have said just now what happens

00:12:14,720 --> 00:12:18,639
is that those caching results are just

00:12:16,800 --> 00:12:20,399
local to each developer

00:12:18,639 --> 00:12:22,240
and so they are locally in your node

00:12:20,399 --> 00:12:23,920
modules folder and you can benefit from

00:12:22,240 --> 00:12:24,800
what you executed but you cannot really

00:12:23,920 --> 00:12:28,000
benefited

00:12:24,800 --> 00:12:30,079
benefit from what your teammate executed

00:12:28,000 --> 00:12:31,760
and so this gets much more powerful if

00:12:30,079 --> 00:12:34,480
we wire in annex cloud

00:12:31,760 --> 00:12:36,000
and so what nx cloud does is actually it

00:12:34,480 --> 00:12:37,760
takes your local cache

00:12:36,000 --> 00:12:39,519
and it synchronizes it to a central

00:12:37,760 --> 00:12:41,760
location in the cloud

00:12:39,519 --> 00:12:43,760
and so basically if i'm a developer on a

00:12:41,760 --> 00:12:45,760
team and i executed like a couple of

00:12:43,760 --> 00:12:47,519
tests on our project like i use one of

00:12:45,760 --> 00:12:49,760
those affected commands to run all of

00:12:47,519 --> 00:12:51,839
the tests of a feature branch

00:12:49,760 --> 00:12:53,360
and so basically in that case these are

00:12:51,839 --> 00:12:54,800
being cached they're being uploaded to

00:12:53,360 --> 00:12:57,200
nx cloud

00:12:54,800 --> 00:12:58,639
if my teammate now comes into work and

00:12:57,200 --> 00:13:00,000
just like boots up the application like

00:12:58,639 --> 00:13:02,320
the nx workspace

00:13:00,000 --> 00:13:04,000
executes again also test run which

00:13:02,320 --> 00:13:06,160
happens to overlap with some of the

00:13:04,000 --> 00:13:07,600
tests that i've been executed those

00:13:06,160 --> 00:13:09,279
wouldn't be executed again but they

00:13:07,600 --> 00:13:10,800
would simply be taken down from the next

00:13:09,279 --> 00:13:12,800
cloud into the local cache

00:13:10,800 --> 00:13:14,320
and then restore it from there and so

00:13:12,800 --> 00:13:17,519
you can imagine that this array speeds

00:13:14,320 --> 00:13:19,680
up things a lot in your development team

00:13:17,519 --> 00:13:21,360
more interesting it gets even when you

00:13:19,680 --> 00:13:23,040
also wire in the ci server

00:13:21,360 --> 00:13:25,279
because like as we have seen in the

00:13:23,040 --> 00:13:27,040
picture we've seen before

00:13:25,279 --> 00:13:29,040
like one of the bottlenecks is often a

00:13:27,040 --> 00:13:31,040
ci server and the reason is that it

00:13:29,040 --> 00:13:31,519
executes a lot of different kind of

00:13:31,040 --> 00:13:34,160
building

00:13:31,519 --> 00:13:35,680
linking and test runs and so it's also

00:13:34,160 --> 00:13:37,680
able to not only leverage

00:13:35,680 --> 00:13:40,000
existing runs which maybe like

00:13:37,680 --> 00:13:41,839
developers have executed before locally

00:13:40,000 --> 00:13:43,760
but it's also able to produce a lot of

00:13:41,839 --> 00:13:44,560
cached results which then developer can

00:13:43,760 --> 00:13:46,880
benefit

00:13:44,560 --> 00:13:49,519
while they develop on features on their

00:13:46,880 --> 00:13:52,480
own machines

00:13:49,519 --> 00:13:54,240
and so in general like this idea behind

00:13:52,480 --> 00:13:55,600
that computation cache is that the

00:13:54,240 --> 00:13:57,519
duration of the invoke

00:13:55,600 --> 00:13:59,440
operations should only be proportional

00:13:57,519 --> 00:14:01,920
to actually what you changed

00:13:59,440 --> 00:14:03,440
so you shouldn't basically as you grow

00:14:01,920 --> 00:14:05,120
your build time should more or less be

00:14:03,440 --> 00:14:05,680
constant because like you should always

00:14:05,120 --> 00:14:07,279
only

00:14:05,680 --> 00:14:09,360
really have to build what you change and

00:14:07,279 --> 00:14:11,360
what you touched

00:14:09,360 --> 00:14:13,440
and so if you take all those different

00:14:11,360 --> 00:14:16,240
things into account again now

00:14:13,440 --> 00:14:17,600
we can see that we can even get better

00:14:16,240 --> 00:14:19,920
results with just

00:14:17,600 --> 00:14:20,720
with now the online nx cloud distributed

00:14:19,920 --> 00:14:22,480
cache

00:14:20,720 --> 00:14:24,240
compared to what we had before with just

00:14:22,480 --> 00:14:26,240
local cache because obviously now i

00:14:24,240 --> 00:14:28,639
benefit from the caching i produce

00:14:26,240 --> 00:14:29,279
but also what the ci server might have

00:14:28,639 --> 00:14:32,639
produced

00:14:29,279 --> 00:14:36,000
or my teammates and so times get even

00:14:32,639 --> 00:14:36,000
smaller get even faster

00:14:37,199 --> 00:14:41,199
but there's another open part like what

00:14:38,880 --> 00:14:42,959
about nx serve and now here we are

00:14:41,199 --> 00:14:44,160
really talking about super large mono

00:14:42,959 --> 00:14:45,839
repos like where

00:14:44,160 --> 00:14:47,920
you have like an application with like

00:14:45,839 --> 00:14:48,639
hundreds of libraries where an nx serve

00:14:47,920 --> 00:14:51,600
might take

00:14:48,639 --> 00:14:53,360
minutes right up to five minutes maybe

00:14:51,600 --> 00:14:53,760
so five minutes is really a long time if

00:14:53,360 --> 00:14:56,240
you

00:14:53,760 --> 00:14:58,079
have to start up the application like as

00:14:56,240 --> 00:14:59,680
you run it webpack does some work behind

00:14:58,079 --> 00:15:01,360
the scenes obviously in caching and

00:14:59,680 --> 00:15:02,079
things like that so like incremental

00:15:01,360 --> 00:15:04,160
building

00:15:02,079 --> 00:15:06,079
as you change things like to change some

00:15:04,160 --> 00:15:07,600
files it might be faster

00:15:06,079 --> 00:15:09,600
but if for some reason you have to

00:15:07,600 --> 00:15:11,199
restart webpack again you again have to

00:15:09,600 --> 00:15:12,880
wait five minutes which is a super long

00:15:11,199 --> 00:15:15,519
time

00:15:12,880 --> 00:15:16,720
so what what can we do about nx serve

00:15:15,519 --> 00:15:18,959
and this is where the whole

00:15:16,720 --> 00:15:21,279
concept of incrementality comes into

00:15:18,959 --> 00:15:23,760
play

00:15:21,279 --> 00:15:24,880
so what happens uh usually when we build

00:15:23,760 --> 00:15:27,600
an application

00:15:24,880 --> 00:15:28,240
we actually execute nx build or annex

00:15:27,600 --> 00:15:31,040
serve

00:15:28,240 --> 00:15:31,600
at the top level application part now in

00:15:31,040 --> 00:15:33,440
nx

00:15:31,600 --> 00:15:34,959
all the libraries are usually not

00:15:33,440 --> 00:15:35,759
libraries that are intended to be

00:15:34,959 --> 00:15:37,680
published

00:15:35,759 --> 00:15:39,680
like built and published to npm

00:15:37,680 --> 00:15:40,720
somewhere but rarity are just linked

00:15:39,680 --> 00:15:42,560
into the application

00:15:40,720 --> 00:15:45,120
and so what happens is these are plain

00:15:42,560 --> 00:15:46,160
imports and so whenever we execute annex

00:15:45,120 --> 00:15:48,800
build or

00:15:46,160 --> 00:15:50,079
an excerpt application it just basically

00:15:48,800 --> 00:15:53,279
links those libraries

00:15:50,079 --> 00:15:56,160
and builds them into one single build

00:15:53,279 --> 00:15:58,800
of the application so we don't really

00:15:56,160 --> 00:16:01,360
have an incrementality there

00:15:58,800 --> 00:16:02,079
now what we did or what our plans are

00:16:01,360 --> 00:16:04,320
for annex

00:16:02,079 --> 00:16:05,680
11 is to actually have incremental

00:16:04,320 --> 00:16:07,199
builds

00:16:05,680 --> 00:16:08,880
and these are basically the plans which

00:16:07,199 --> 00:16:09,600
you have publicly online so you can go

00:16:08,880 --> 00:16:12,639
through the

00:16:09,600 --> 00:16:13,920
gen x repository on the issues this is a

00:16:12,639 --> 00:16:16,240
pinned issue

00:16:13,920 --> 00:16:17,120
about our like roadmap for nx11 and

00:16:16,240 --> 00:16:20,160
ongoing

00:16:17,120 --> 00:16:22,399
and incremental builds is one of those

00:16:20,160 --> 00:16:24,800
so what does that mean first of all what

00:16:22,399 --> 00:16:25,040
we had to change or how we had to adapt

00:16:24,800 --> 00:16:27,600
an

00:16:25,040 --> 00:16:28,240
x is we needed to have buildable

00:16:27,600 --> 00:16:30,079
libraries

00:16:28,240 --> 00:16:31,759
so not just like plain normal libraries

00:16:30,079 --> 00:16:33,600
but we wanted to have the library also

00:16:31,759 --> 00:16:35,440
as a buildable target

00:16:33,600 --> 00:16:36,639
and so what we introduced already like a

00:16:35,440 --> 00:16:40,160
couple of versions ago

00:16:36,639 --> 00:16:41,680
is the dash dash buildable flag which is

00:16:40,160 --> 00:16:43,680
kind of different than the publishable

00:16:41,680 --> 00:16:44,480
flag as it does not as much as the

00:16:43,680 --> 00:16:46,959
publishable

00:16:44,480 --> 00:16:48,480
builder but it does a bit less in an

00:16:46,959 --> 00:16:49,519
optimized way because it needs to be

00:16:48,480 --> 00:16:51,279
fast

00:16:49,519 --> 00:16:52,959
and so you can generate a library with

00:16:51,279 --> 00:16:54,800
that buildable flag

00:16:52,959 --> 00:16:58,480
and what that allows us to do is to

00:16:54,800 --> 00:17:00,480
actually build those parts independently

00:16:58,480 --> 00:17:03,120
so as a result what happens now is that

00:17:00,480 --> 00:17:05,760
whenever we execute annex build app

00:17:03,120 --> 00:17:08,240
what it does it is actually going to

00:17:05,760 --> 00:17:10,079
build all those libraries before

00:17:08,240 --> 00:17:12,079
and for being able to do that we

00:17:10,079 --> 00:17:12,720
actually need that with dependency flag

00:17:12,079 --> 00:17:14,720
as well

00:17:12,720 --> 00:17:16,319
which is another addition which we added

00:17:14,720 --> 00:17:19,360
because otherwise if we just

00:17:16,319 --> 00:17:20,240
execute an nx build my app then actually

00:17:19,360 --> 00:17:22,640
what would happen

00:17:20,240 --> 00:17:24,319
is it would just build that application

00:17:22,640 --> 00:17:26,720
or it would even fail because like some

00:17:24,319 --> 00:17:28,240
of its dependencies haven't been built

00:17:26,720 --> 00:17:30,160
now the width dependencies flag

00:17:28,240 --> 00:17:31,200
leverages again the dependency graph

00:17:30,160 --> 00:17:33,679
behind the scenes

00:17:31,200 --> 00:17:35,039
it walks down the tree and what it does

00:17:33,679 --> 00:17:38,160
is it starts to build

00:17:35,039 --> 00:17:39,039
like the lowest level node of that tree

00:17:38,160 --> 00:17:41,200
and so in this case for instance it

00:17:39,039 --> 00:17:43,120
would go to the shared it would actually

00:17:41,200 --> 00:17:45,280
execute the build against it but at that

00:17:43,120 --> 00:17:47,039
point again annex cloud or the local

00:17:45,280 --> 00:17:47,360
computation cache would jump in and say

00:17:47,039 --> 00:17:48,880
like

00:17:47,360 --> 00:17:50,799
this is already cached because someone

00:17:48,880 --> 00:17:52,799
else built it already

00:17:50,799 --> 00:17:53,840
and similarly you might have with core

00:17:52,799 --> 00:17:55,440
with courses

00:17:53,840 --> 00:17:57,120
with sales we actually have to build it

00:17:55,440 --> 00:17:57,600
because we might have made a change in

00:17:57,120 --> 00:18:00,240
our

00:17:57,600 --> 00:18:02,000
feature request or someone else that it

00:18:00,240 --> 00:18:03,600
simply hasn't been built yet

00:18:02,000 --> 00:18:05,360
and similarly with the coupons it is

00:18:03,600 --> 00:18:07,280
also cached and so now you can

00:18:05,360 --> 00:18:08,880
see like how this already improves the

00:18:07,280 --> 00:18:10,480
build performance law because like we

00:18:08,880 --> 00:18:13,200
have really just to build

00:18:10,480 --> 00:18:13,760
one single sales library in this case

00:18:13,200 --> 00:18:15,600
and this is

00:18:13,760 --> 00:18:18,000
actually what the whole incremental

00:18:15,600 --> 00:18:19,679
builds concept is about

00:18:18,000 --> 00:18:22,240
and so if you look at some statistics

00:18:19,679 --> 00:18:23,440
here is what you can see here is this is

00:18:22,240 --> 00:18:24,720
just a normal build

00:18:23,440 --> 00:18:27,440
like this is what you would have

00:18:24,720 --> 00:18:29,280
nowadays with an angular cli build or an

00:18:27,440 --> 00:18:31,760
nx build where it just

00:18:29,280 --> 00:18:32,640
execute nx build right so the blue one

00:18:31,760 --> 00:18:34,960
basically

00:18:32,640 --> 00:18:36,160
tells you the time that is needed in a

00:18:34,960 --> 00:18:38,320
large repository

00:18:36,160 --> 00:18:40,400
to just build application and so here we

00:18:38,320 --> 00:18:42,320
are around 68 seconds

00:18:40,400 --> 00:18:43,840
a serve is similar it's a bit more

00:18:42,320 --> 00:18:44,960
optimized because it doesn't do that

00:18:43,840 --> 00:18:47,919
much probably

00:18:44,960 --> 00:18:50,080
uh so it's like 62 seconds and the file

00:18:47,919 --> 00:18:52,000
change is pretty acceptable in in this

00:18:50,080 --> 00:18:54,320
example repository which we created so

00:18:52,000 --> 00:18:56,240
it's around six seconds

00:18:54,320 --> 00:18:57,840
now if we compare it to an incremental

00:18:56,240 --> 00:18:59,679
build but without having

00:18:57,840 --> 00:19:01,679
any caching in place because it's the

00:18:59,679 --> 00:19:03,919
first time ever which we executed

00:19:01,679 --> 00:19:06,080
then it takes slightly longer and the

00:19:03,919 --> 00:19:07,440
reason here is mostly because we

00:19:06,080 --> 00:19:09,520
actually have to go through all the

00:19:07,440 --> 00:19:12,559
libraries we have to rebuild them

00:19:09,520 --> 00:19:14,799
and for angular we use ng packager and

00:19:12,559 --> 00:19:16,400
so that takes a bit more than just like

00:19:14,799 --> 00:19:19,840
linking them together and actually

00:19:16,400 --> 00:19:21,919
building with like webpack

00:19:19,840 --> 00:19:23,600
the interesting part however is that a

00:19:21,919 --> 00:19:24,000
code repository where you don't have any

00:19:23,600 --> 00:19:26,720
cache

00:19:24,000 --> 00:19:27,520
is not really super realistic right so

00:19:26,720 --> 00:19:30,640
at some point

00:19:27,520 --> 00:19:32,080
either the ci server or some teammate

00:19:30,640 --> 00:19:33,600
might have already built it

00:19:32,080 --> 00:19:35,679
and so these are the numbers which you

00:19:33,600 --> 00:19:37,919
get from a warm cache

00:19:35,679 --> 00:19:39,679
so you can see like the annex build just

00:19:37,919 --> 00:19:41,120
takes six seconds because like

00:19:39,679 --> 00:19:42,720
it has already built the libraries

00:19:41,120 --> 00:19:44,480
they're already in place so it just goes

00:19:42,720 --> 00:19:46,400
ahead and just restores them from the

00:19:44,480 --> 00:19:48,640
cloud cache

00:19:46,400 --> 00:19:49,600
and an excerpt takes seven seconds so

00:19:48,640 --> 00:19:52,080
pretty similar

00:19:49,600 --> 00:19:53,840
also like an incremental build like you

00:19:52,080 --> 00:19:54,480
change some file some component and

00:19:53,840 --> 00:19:56,640
rebuild it

00:19:54,480 --> 00:19:59,360
takes another seven seconds so you can

00:19:56,640 --> 00:20:00,960
see like this speeds up things a lot and

00:19:59,360 --> 00:20:03,919
makes like working much more pleasant

00:20:00,960 --> 00:20:05,360
obviously in super large repositories

00:20:03,919 --> 00:20:06,960
and so if you're curious about this and

00:20:05,360 --> 00:20:08,080
you want to play around with it we have

00:20:06,960 --> 00:20:10,799
a repository

00:20:08,080 --> 00:20:13,120
on our novel github account which is

00:20:10,799 --> 00:20:14,480
like the annex incremental large repo

00:20:13,120 --> 00:20:16,240
so you can go there there's a readme

00:20:14,480 --> 00:20:18,080
that explains like how to download the

00:20:16,240 --> 00:20:21,200
repository how to bootstrap it and

00:20:18,080 --> 00:20:23,280
what actually you can find there

00:20:21,200 --> 00:20:25,200
and so just to kind of conclude like

00:20:23,280 --> 00:20:25,760
what is the status about this and what's

00:20:25,200 --> 00:20:27,440
next

00:20:25,760 --> 00:20:29,039
so what we did with incremental billing

00:20:27,440 --> 00:20:31,200
in nx over the last

00:20:29,039 --> 00:20:33,280
couple of weeks and months is first of

00:20:31,200 --> 00:20:34,799
all we use now a builder which is based

00:20:33,280 --> 00:20:37,120
on android packager but it is

00:20:34,799 --> 00:20:38,640
kind of faster because we don't do like

00:20:37,120 --> 00:20:40,080
for instance umd bundling and

00:20:38,640 --> 00:20:41,039
minification because like in an

00:20:40,080 --> 00:20:43,440
incremental build

00:20:41,039 --> 00:20:45,039
it's not really needed since we don't

00:20:43,440 --> 00:20:46,960
intend to publish that package but just

00:20:45,039 --> 00:20:49,360
used as an intermediate part

00:20:46,960 --> 00:20:51,120
for the application build we also

00:20:49,360 --> 00:20:53,360
created a custom builder to work

00:20:51,120 --> 00:20:55,520
uh like for the application builds that

00:20:53,360 --> 00:20:56,559
rewrites the ts paths like typescript

00:20:55,520 --> 00:20:58,000
mapping paths

00:20:56,559 --> 00:20:59,520
and that's needed because now it

00:20:58,000 --> 00:21:01,280
basically needs to not point to the

00:20:59,520 --> 00:21:03,360
actual source code but to the pre-built

00:21:01,280 --> 00:21:06,080
library once that has been built

00:21:03,360 --> 00:21:07,360
and also we added a simple nxserv

00:21:06,080 --> 00:21:09,280
command because right now

00:21:07,360 --> 00:21:10,880
we don't use webpack for serving during

00:21:09,280 --> 00:21:11,440
development but it's kind of a custom

00:21:10,880 --> 00:21:13,039
setup

00:21:11,440 --> 00:21:16,799
that watches the actual pre-built

00:21:13,039 --> 00:21:19,120
artifact and instantiates it from there

00:21:16,799 --> 00:21:21,120
as a point that we are like going

00:21:19,120 --> 00:21:22,559
onwards like going ahead from now we

00:21:21,120 --> 00:21:24,000
will definitely investigate into

00:21:22,559 --> 00:21:25,840
speeding up things even more

00:21:24,000 --> 00:21:27,440
we might even invest like into how we

00:21:25,840 --> 00:21:28,960
can speed up webpack or

00:21:27,440 --> 00:21:30,880
whether we can actually use some

00:21:28,960 --> 00:21:33,840
alternative for those incremental

00:21:30,880 --> 00:21:35,520
servings and then incremental builds

00:21:33,840 --> 00:21:37,120
so thanks a lot uh if there are

00:21:35,520 --> 00:21:38,720
questions uh definitely also reach out

00:21:37,120 --> 00:21:39,520
to me on twitter or connect with me on

00:21:38,720 --> 00:21:42,320
twitter and

00:21:39,520 --> 00:21:43,200
write me at dms like mediamps are open

00:21:42,320 --> 00:21:46,000
or just

00:21:43,200 --> 00:21:47,840
visit our company novel io twitter

00:21:46,000 --> 00:21:54,799
account or our website

00:21:47,840 --> 00:21:54,799

YouTube URL: https://www.youtube.com/watch?v=fvYKjY4eyhI


