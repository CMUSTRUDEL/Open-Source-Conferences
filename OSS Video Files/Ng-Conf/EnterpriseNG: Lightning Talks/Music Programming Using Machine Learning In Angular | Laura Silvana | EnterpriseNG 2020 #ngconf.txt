Title: Music Programming Using Machine Learning In Angular | Laura Silvana | EnterpriseNG 2020 #ngconf
Publication date: 2021-01-02
Playlist: EnterpriseNG: Lightning Talks
Description: 
	ng-conf is a three-day Angular conference focused on delivering the highest quality training in the Angular JavaScript framework. 1500+ developers from across the globe converge on Salt Lake City, UT every year to attend talks and workshops by the Angular team and community experts.

Follow us on twitter https://twitter.com/ngconf
Official Website: https://www.ng-conf.org/
Captions: 
	00:00:04,710 --> 00:00:08,809
[Music]

00:00:14,320 --> 00:00:17,359
i'm laura

00:00:15,280 --> 00:00:19,680
i'm a front-end developer at swedbank

00:00:17,359 --> 00:00:21,680
and welcome to my talk about user

00:00:19,680 --> 00:00:24,800
programming using machine learning

00:00:21,680 --> 00:00:28,240
in angular a lot of buzzwords right but

00:00:24,800 --> 00:00:31,880
let's start with the most unknown term

00:00:28,240 --> 00:00:35,920
among developers music programming

00:00:31,880 --> 00:00:37,360
1843 1843 this is the year that music

00:00:35,920 --> 00:00:40,559
programming was introduced

00:00:37,360 --> 00:00:42,640
as an idea and as you imagine we did not

00:00:40,559 --> 00:00:43,440
have the computers as we understand them

00:00:42,640 --> 00:00:45,600
today

00:00:43,440 --> 00:00:48,000
but despite that at the level is

00:00:45,600 --> 00:00:50,000
described in her works that computing

00:00:48,000 --> 00:00:51,199
engine which wear mainly for math

00:00:50,000 --> 00:00:53,520
calculations

00:00:51,199 --> 00:00:55,920
might be as a perfect tool to create

00:00:53,520 --> 00:00:59,280
precise and scientific music

00:00:55,920 --> 00:01:02,239
no surprises nowadays we have different

00:00:59,280 --> 00:01:03,520
ways how we can actually create music

00:01:02,239 --> 00:01:05,760
with coding

00:01:03,520 --> 00:01:07,760
and today i will cover music programming

00:01:05,760 --> 00:01:09,680
in front-end applications

00:01:07,760 --> 00:01:11,439
by getting some help from machine

00:01:09,680 --> 00:01:14,400
learning

00:01:11,439 --> 00:01:16,400
magenta magenta is an open source

00:01:14,400 --> 00:01:18,159
research project exploring the role of

00:01:16,400 --> 00:01:20,799
machine learning as a tool

00:01:18,159 --> 00:01:21,600
in the creative process that covers not

00:01:20,799 --> 00:01:24,320
only music

00:01:21,600 --> 00:01:26,799
but art in general and the subset of

00:01:24,320 --> 00:01:30,079
that is magenta js

00:01:26,799 --> 00:01:33,119
which provides javascript api uh to use

00:01:30,079 --> 00:01:35,280
magenta models in browsers and today i

00:01:33,119 --> 00:01:38,720
will show you a quick demo

00:01:35,280 --> 00:01:42,720
how to use those models for music

00:01:38,720 --> 00:01:44,880
uh in the application

00:01:42,720 --> 00:01:47,360
let's start with the result this is the

00:01:44,880 --> 00:01:50,560
application i'm using here magenta

00:01:47,360 --> 00:01:53,600
in three different ways the first one

00:01:50,560 --> 00:01:54,000
uh here i'm just using that to place

00:01:53,600 --> 00:01:57,850
some

00:01:54,000 --> 00:02:05,840
predefined melody as for example

00:01:57,850 --> 00:02:07,600
[Music]

00:02:05,840 --> 00:02:09,679
i want to be clear that i'm not

00:02:07,600 --> 00:02:11,680
providing some audio track here

00:02:09,679 --> 00:02:14,080
i'm literally providing notes which due

00:02:11,680 --> 00:02:17,280
to the web or the api capabilities

00:02:14,080 --> 00:02:20,560
we can transfer the browser as

00:02:17,280 --> 00:02:21,760
sounds but at current mode i'm not using

00:02:20,560 --> 00:02:23,920
any models

00:02:21,760 --> 00:02:25,120
that's why let's look into the second

00:02:23,920 --> 00:02:27,360
approach where

00:02:25,120 --> 00:02:28,800
i will use the recurrent neural network

00:02:27,360 --> 00:02:32,879
model in order to

00:02:28,800 --> 00:02:37,840
continue the melody we just heard

00:02:32,879 --> 00:02:37,840
for example

00:02:39,110 --> 00:02:46,160
[Music]

00:02:43,519 --> 00:02:46,800
so basically here i'm using the magenta

00:02:46,160 --> 00:02:48,720
model

00:02:46,800 --> 00:02:51,440
i'm providing the original melodies

00:02:48,720 --> 00:02:53,680
baseline and according to those few

00:02:51,440 --> 00:02:55,760
options i'm getting the result and

00:02:53,680 --> 00:02:57,599
whenever i click the button i always

00:02:55,760 --> 00:03:01,920
requesting for the results

00:02:57,599 --> 00:03:01,920
that's why i always getting something

00:03:02,840 --> 00:03:05,840
new

00:03:08,190 --> 00:03:13,599
[Music]

00:03:10,560 --> 00:03:14,720
and the last approach is another type of

00:03:13,599 --> 00:03:17,200
the model

00:03:14,720 --> 00:03:19,360
which actually just generates some sort

00:03:17,200 --> 00:03:32,080
of the totally new melody according

00:03:19,360 --> 00:03:34,480
to the model itself so for example

00:03:32,080 --> 00:03:35,519
so now we are relying more on the model

00:03:34,480 --> 00:03:37,120
and as well

00:03:35,519 --> 00:03:47,840
every time i'm clicking i'm getting

00:03:37,120 --> 00:03:52,000
something new

00:03:47,840 --> 00:03:52,000
okay let's look into the code now

00:03:52,720 --> 00:03:55,760
so basically here i'm having angular

00:03:54,799 --> 00:03:58,400
application i

00:03:55,760 --> 00:04:00,400
installed magenta via npm and this is

00:03:58,400 --> 00:04:02,720
one of the components uh

00:04:00,400 --> 00:04:03,439
to start with during initialization i

00:04:02,720 --> 00:04:05,519
actually need to

00:04:03,439 --> 00:04:06,799
create some sort of the instrument via

00:04:05,519 --> 00:04:09,200
which we will play

00:04:06,799 --> 00:04:09,920
the melodies either we are using models

00:04:09,200 --> 00:04:13,519
or not

00:04:09,920 --> 00:04:16,000
so for example here i'm creating player

00:04:13,519 --> 00:04:18,160
and then later on as for example when i

00:04:16,000 --> 00:04:21,519
am playing the original melody

00:04:18,160 --> 00:04:24,320
i'm just starting some sort of the notes

00:04:21,519 --> 00:04:26,080
jump song are predefined notes notes

00:04:24,320 --> 00:04:27,280
might be described in different formats

00:04:26,080 --> 00:04:30,080
but this is one of them

00:04:27,280 --> 00:04:31,600
this is how i describe the jump song by

00:04:30,080 --> 00:04:34,320
setting the pitch start time

00:04:31,600 --> 00:04:34,800
and time and this is how we can describe

00:04:34,320 --> 00:04:37,919
different

00:04:34,800 --> 00:04:39,759
notes and at this moment that is

00:04:37,919 --> 00:04:41,440
just that we just playing those

00:04:39,759 --> 00:04:43,040
predefined notes

00:04:41,440 --> 00:04:44,479
but then let's look into the

00:04:43,040 --> 00:04:46,880
continuation

00:04:44,479 --> 00:04:48,320
in this way we actually need to use some

00:04:46,880 --> 00:04:51,520
sort of the model

00:04:48,320 --> 00:04:52,800
and that's why during initialization we

00:04:51,520 --> 00:04:56,080
are initializing

00:04:52,800 --> 00:04:58,320
music rnn music neural network and we

00:04:56,080 --> 00:05:01,520
need to initialize that by providing

00:04:58,320 --> 00:05:02,320
checkpoint for example here i'm

00:05:01,520 --> 00:05:06,240
providing

00:05:02,320 --> 00:05:07,440
basic rnn and then later on when i click

00:05:06,240 --> 00:05:10,240
the button

00:05:07,440 --> 00:05:11,199
i'm changing firstly the format of notes

00:05:10,240 --> 00:05:14,240
i'm doing that

00:05:11,199 --> 00:05:17,600
i'm changing to the quantized format

00:05:14,240 --> 00:05:21,520
and then i can just simple a request

00:05:17,600 --> 00:05:24,080
for the result from the model itself

00:05:21,520 --> 00:05:26,000
and there are three important options as

00:05:24,080 --> 00:05:27,039
well for which one we can control the

00:05:26,000 --> 00:05:29,039
result

00:05:27,039 --> 00:05:31,039
one of them for example steps we can

00:05:29,039 --> 00:05:34,240
control the duration of the

00:05:31,039 --> 00:05:34,639
uh result then temperature temperature

00:05:34,240 --> 00:05:36,960
is

00:05:34,639 --> 00:05:40,080
is randomization weight that in short

00:05:36,960 --> 00:05:43,199
means that how far from the original

00:05:40,080 --> 00:05:46,160
node's pitch and length might be

00:05:43,199 --> 00:05:47,120
the result of notes and then steps per

00:05:46,160 --> 00:05:48,880
quarter

00:05:47,120 --> 00:05:51,600
which basically just sets the tempo

00:05:48,880 --> 00:05:52,320
itself so there are a few ways we can

00:05:51,600 --> 00:05:55,039
control

00:05:52,320 --> 00:05:57,039
uh the result in those three options

00:05:55,039 --> 00:05:59,680
then by changing the checkpoint

00:05:57,039 --> 00:06:02,319
and then by changing the base melody as

00:05:59,680 --> 00:06:05,360
here i'm using the junk song

00:06:02,319 --> 00:06:08,479
and another uh model uh which called

00:06:05,360 --> 00:06:09,360
me music uh variational auto encoder

00:06:08,479 --> 00:06:11,280
here

00:06:09,360 --> 00:06:13,759
uh it's initialized in pretty similar

00:06:11,280 --> 00:06:16,880
way by providing the checkpoint

00:06:13,759 --> 00:06:19,680
but used in a different a different way

00:06:16,880 --> 00:06:20,800
i here for example i only need to say

00:06:19,680 --> 00:06:23,520
that i want to have

00:06:20,800 --> 00:06:25,039
one sample and the temperature might be

00:06:23,520 --> 00:06:26,639
around this one

00:06:25,039 --> 00:06:28,639
and that is it this is how we are

00:06:26,639 --> 00:06:30,880
getting the totally new

00:06:28,639 --> 00:06:31,919
melody without providing some sort of

00:06:30,880 --> 00:06:35,120
the base

00:06:31,919 --> 00:06:37,199
baseline and that is it there

00:06:35,120 --> 00:06:39,280
this was the brief introduction about

00:06:37,199 --> 00:06:42,720
music programming using machine

00:06:39,280 --> 00:06:44,800
learning in angular and if you find that

00:06:42,720 --> 00:06:48,000
interesting you can check my other talks

00:06:44,800 --> 00:06:50,560
and articles and now i

00:06:48,000 --> 00:06:52,479
want to leave you with some music uh

00:06:50,560 --> 00:06:55,039
music which was created by

00:06:52,479 --> 00:06:56,080
a layering many generated melodies of

00:06:55,039 --> 00:06:59,599
magenta

00:06:56,080 --> 00:07:02,560
drums and bassline were added by human

00:06:59,599 --> 00:07:02,880
in order to show how well magenta might

00:07:02,560 --> 00:07:05,759
be

00:07:02,880 --> 00:07:16,880
incorporated thanks a lot for joining me

00:07:05,759 --> 00:07:23,350
it was my pleasure to be here

00:07:16,880 --> 00:07:28,840
[Music]

00:07:23,350 --> 00:07:31,840
[Applause]

00:07:28,840 --> 00:07:31,840
so

00:07:32,150 --> 00:07:37,260
[Applause]

00:07:34,090 --> 00:07:40,300
[Music]

00:07:37,260 --> 00:07:40,300
[Applause]

00:07:42,340 --> 00:07:45,370
[Music]

00:07:47,039 --> 00:07:49,120

YouTube URL: https://www.youtube.com/watch?v=oJuyRjKYf_Y


