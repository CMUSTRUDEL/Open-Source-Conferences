Title: Va Barbosa - Deep Learning at the Edge with TensorFlow.js
Publication date: 2019-11-04
Playlist: All Things Open 2019
Description: 
	With TensorFlow.js developers can embed pre-trained deep learning models directly within a Node.js or web application. Deep learning can be used for many tasks including image or audio classification, facial recognition, object recognition, image caption generation, and natural language processing. TensorFlow.js enables inferencing on deep learning models at the edge, removing the dependency on potentially slow and unreliable network API calls. Weâ€™ll explore the opportunities and the challenges around deploying pre-trained deep learning models to edge environments.
Captions: 
	00:00:09,139 --> 00:00:13,769
all right hello everyone thank you for

00:00:12,240 --> 00:00:16,410
coming and staying for the last session

00:00:13,769 --> 00:00:18,539
of the day hey my name is var baboso I'm

00:00:16,410 --> 00:00:20,640
a developer advocate at the Center for

00:00:18,539 --> 00:00:23,789
open source data and AI technologies at

00:00:20,640 --> 00:00:25,320
IBM or Cote for short and the goal for

00:00:23,789 --> 00:00:29,689
coding is we try to make it easier to

00:00:25,320 --> 00:00:32,279
create deploy manage AI models in the

00:00:29,689 --> 00:00:34,890
technologies and our goal is to make it

00:00:32,279 --> 00:00:37,320
more open and more consumable by all

00:00:34,890 --> 00:00:39,149
developers and I should probably start

00:00:37,320 --> 00:00:42,000
by saying that I am NOT a machine

00:00:39,149 --> 00:00:44,250
learning expert nor am i data scientist

00:00:42,000 --> 00:00:46,140
I sort of stumbled my way into a machine

00:00:44,250 --> 00:00:48,480
learning and now I'm him just talk about

00:00:46,140 --> 00:00:50,370
it what I've learned in how to get

00:00:48,480 --> 00:00:54,809
JavaScript developers more involved in

00:00:50,370 --> 00:00:56,879
machine learning so this is where I'll

00:00:54,809 --> 00:00:59,730
be telling you about machine learning is

00:00:56,879 --> 00:01:03,359
everywhere it's all the hype behind AI

00:00:59,730 --> 00:01:04,799
and but there's a whole track of machine

00:01:03,359 --> 00:01:06,689
learning here at this conference and

00:01:04,799 --> 00:01:08,640
there are people here who can probably

00:01:06,689 --> 00:01:10,140
do a lot better job of explaining all

00:01:08,640 --> 00:01:14,640
that to you than myself so I'm gonna

00:01:10,140 --> 00:01:16,950
skip over this part here and actually

00:01:14,640 --> 00:01:18,720
fewer yesterday's open keynote you would

00:01:16,950 --> 00:01:21,210
have probably also heard Erika Stanley

00:01:18,720 --> 00:01:24,509
give a great introduction to AI machine

00:01:21,210 --> 00:01:26,520
learning and deep learning models and

00:01:24,509 --> 00:01:27,900
what I'm not gonna repeat what she says

00:01:26,520 --> 00:01:30,360
but don't think I'm gonna say here is

00:01:27,900 --> 00:01:31,950
the key takeaway is with machine

00:01:30,360 --> 00:01:34,500
learning and deep learning implicit is

00:01:31,950 --> 00:01:36,810
all you need is the right set of input

00:01:34,500 --> 00:01:39,060
data and answers and then the Machine

00:01:36,810 --> 00:01:41,369
will learn or infer with of rules of

00:01:39,060 --> 00:01:43,470
prediction are what the rules are and

00:01:41,369 --> 00:01:45,119
once you have those rules you have your

00:01:43,470 --> 00:01:47,040
model and then once you provided new

00:01:45,119 --> 00:01:49,290
data it'll go edit and run predictions

00:01:47,040 --> 00:01:52,020
it give you the predictions or the

00:01:49,290 --> 00:01:56,219
probability of what that new data is or

00:01:52,020 --> 00:01:58,979
represents so and that's done through

00:01:56,219 --> 00:02:01,170
what we like to call artificial neural

00:01:58,979 --> 00:02:03,390
networks and I'm left hand side you see

00:02:01,170 --> 00:02:05,189
an example of a single neuron and

00:02:03,390 --> 00:02:07,590
artificial neural networks they just

00:02:05,189 --> 00:02:09,770
basically mimic what the biological

00:02:07,590 --> 00:02:12,350
neural networks in the human brain Duke

00:02:09,770 --> 00:02:14,960
and in a single neuron you can have any

00:02:12,350 --> 00:02:17,270
number of inputs here and the label by

00:02:14,960 --> 00:02:19,550
the X's here and each of these inputs I

00:02:17,270 --> 00:02:21,650
have some sort of weight associated with

00:02:19,550 --> 00:02:25,210
them and with the neuron basically does

00:02:21,650 --> 00:02:28,660
it takes some sum of the weights and

00:02:25,210 --> 00:02:31,550
inputs and then adds some sort of bias

00:02:28,660 --> 00:02:33,620
and to adjust that sum and then it runs

00:02:31,550 --> 00:02:35,420
it through we call an activation

00:02:33,620 --> 00:02:37,520
function and depending on the activation

00:02:35,420 --> 00:02:39,740
function it of the term whether or not

00:02:37,520 --> 00:02:42,320
that neuron fires or what output it

00:02:39,740 --> 00:02:44,330
produces and on the right hand side you

00:02:42,320 --> 00:02:46,730
have a very simple example of what

00:02:44,330 --> 00:02:49,280
neural network would look like and it's

00:02:46,730 --> 00:02:51,260
just a number of connected neurons so

00:02:49,280 --> 00:02:53,650
you have your input where for example

00:02:51,260 --> 00:02:56,690
with an image those could be the

00:02:53,650 --> 00:02:58,910
individual values of a pixel and then

00:02:56,690 --> 00:03:00,890
you have your output which is your

00:02:58,910 --> 00:03:02,810
prediction and for example it could be

00:03:00,890 --> 00:03:05,420
the probability that this image was of a

00:03:02,810 --> 00:03:07,460
dog or a cat and so on and in the middle

00:03:05,420 --> 00:03:09,830
you have your hidden layers and the

00:03:07,460 --> 00:03:12,740
hidden layers basically fire depending

00:03:09,830 --> 00:03:14,810
on what the input is it basically a fire

00:03:12,740 --> 00:03:16,630
and connect to the other days and you

00:03:14,810 --> 00:03:19,670
can have any number of hidden layers and

00:03:16,630 --> 00:03:22,790
in a lot more this is a very simplified

00:03:19,670 --> 00:03:26,030
explanation but in a lot more cases what

00:03:22,790 --> 00:03:29,150
you would have is anywhere from hundreds

00:03:26,030 --> 00:03:32,060
to thousands maybe of inputs and dozens

00:03:29,150 --> 00:03:33,770
to hundreds of hidden layers and then

00:03:32,060 --> 00:03:37,430
your output would give you a prediction

00:03:33,770 --> 00:03:40,280
and a lot of this takes a lot of time

00:03:37,430 --> 00:03:42,710
resources a lot of data a lot of

00:03:40,280 --> 00:03:47,060
computing power and a lot of knowledge

00:03:42,710 --> 00:03:48,590
around machine learning but if you want

00:03:47,060 --> 00:03:49,970
to get into creating these machine

00:03:48,590 --> 00:03:52,280
learning models there are plenty of

00:03:49,970 --> 00:03:53,810
tools out there for you which try to

00:03:52,280 --> 00:03:56,690
help you and make it a little easier for

00:03:53,810 --> 00:03:58,760
you and one such tool is tensorflow

00:03:56,690 --> 00:04:01,130
which I want to point out over here one

00:03:58,760 --> 00:04:03,890
in the top left and tensorflow was

00:04:01,130 --> 00:04:08,240
developed by Google and it was open

00:04:03,890 --> 00:04:11,080
source I believe in 2015 and what it is

00:04:08,240 --> 00:04:15,710
is basically a machine learning library

00:04:11,080 --> 00:04:18,020
to help create and excuse me top create

00:04:15,710 --> 00:04:20,690
and define your machine learning model

00:04:18,020 --> 00:04:23,360
and perform linear mathematical

00:04:20,690 --> 00:04:26,120
equations on it and most of these

00:04:23,360 --> 00:04:28,129
in fact all these tend to be Python

00:04:26,120 --> 00:04:33,430
basically given the Pythons community

00:04:28,129 --> 00:04:36,740
and the adoption in research academics a

00:04:33,430 --> 00:04:38,719
Python tends to be the go-to language

00:04:36,740 --> 00:04:40,580
for machine learning model but with

00:04:38,719 --> 00:04:43,849
tensorflow it was actually initially

00:04:40,580 --> 00:04:46,460
written in C and there later on I had

00:04:43,849 --> 00:04:48,199
the bindings for Python Java as well as

00:04:46,460 --> 00:04:50,719
other programming languages and there's

00:04:48,199 --> 00:04:52,849
even binding for JavaScript called

00:04:50,719 --> 00:04:55,069
tensorflow version of it's not a binding

00:04:52,849 --> 00:04:57,860
it's a version of it called tensorflow

00:04:55,069 --> 00:05:00,199
J's for JavaScript so what exactly is

00:04:57,860 --> 00:05:03,050
tensorflow Jess it's an open source

00:05:00,199 --> 00:05:05,330
library the train and deploy machine

00:05:03,050 --> 00:05:09,110
learning models all within JavaScript it

00:05:05,330 --> 00:05:11,419
was started out as deep learn Jas and it

00:05:09,110 --> 00:05:13,520
was actually brought into the tensorflow

00:05:11,419 --> 00:05:14,060
family a little over a year ago and

00:05:13,520 --> 00:05:16,490
renamed

00:05:14,060 --> 00:05:19,219
tensorflow J's and earlier this year

00:05:16,490 --> 00:05:20,629
version 1.0 was released and with the

00:05:19,219 --> 00:05:23,000
release of one probably know they even

00:05:20,629 --> 00:05:25,819
tied it even more tightly to the

00:05:23,000 --> 00:05:28,190
tensorflow api so you may be thinking to

00:05:25,819 --> 00:05:30,500
yourself with Python as the go-to

00:05:28,190 --> 00:05:33,319
language for machine learning why even

00:05:30,500 --> 00:05:35,240
bother with JavaScript well first of all

00:05:33,319 --> 00:05:37,400
without my JavaScript and JavaScript is

00:05:35,240 --> 00:05:40,300
everywhere so why not in machine

00:05:37,400 --> 00:05:42,800
learning but more importantly though is

00:05:40,300 --> 00:05:44,719
there are over 12 million JavaScript

00:05:42,800 --> 00:05:46,159
that nodejs developers out there so if

00:05:44,719 --> 00:05:48,650
you can bring machine learning into

00:05:46,159 --> 00:05:51,949
JavaScript you take it out of just

00:05:48,650 --> 00:05:55,129
strictly being a Python ecosystem think

00:05:51,949 --> 00:05:56,900
to that perhaps the widest or most

00:05:55,129 --> 00:06:00,139
widely used programming language in the

00:05:56,900 --> 00:06:02,120
world in addition with like edge devices

00:06:00,139 --> 00:06:03,949
and browser with browsers and edge

00:06:02,120 --> 00:06:05,930
devices you have sensors you have

00:06:03,949 --> 00:06:08,089
cameras you have microphones you have

00:06:05,930 --> 00:06:09,949
access to all this data and as we know

00:06:08,089 --> 00:06:12,080
what machine learning you need lots and

00:06:09,949 --> 00:06:13,879
lots and lots of data and also with

00:06:12,080 --> 00:06:16,310
browsers you have interactive your eyes

00:06:13,879 --> 00:06:20,270
and this can allow for very interesting

00:06:16,310 --> 00:06:22,879
and unique sort of applications and then

00:06:20,270 --> 00:06:24,620
there's data security and with data

00:06:22,879 --> 00:06:26,960
security if you think about it in a

00:06:24,620 --> 00:06:30,500
traditional machine learning flow the

00:06:26,960 --> 00:06:33,169
data is taken from the client and then

00:06:30,500 --> 00:06:35,479
sent on to a server somewhere where the

00:06:33,169 --> 00:06:36,240
training can happen or the prediction

00:06:35,479 --> 00:06:37,590
can be ruined

00:06:36,240 --> 00:06:41,699
and then the information is sent back to

00:06:37,590 --> 00:06:44,130
the end client and now if you think

00:06:41,699 --> 00:06:46,979
about the alternative where you have the

00:06:44,130 --> 00:06:48,360
machine learning and the model excuse me

00:06:46,979 --> 00:06:50,069
you have the data and the machine

00:06:48,360 --> 00:06:52,050
learning model directly on the device

00:06:50,069 --> 00:06:54,150
then the training can happen on the

00:06:52,050 --> 00:06:55,680
device and the prediction is all can

00:06:54,150 --> 00:06:57,389
happen on the device without having to

00:06:55,680 --> 00:07:00,000
send or worry about sending the data

00:06:57,389 --> 00:07:02,819
over the network to some security server

00:07:00,000 --> 00:07:05,460
elsewhere excuse me and then there's the

00:07:02,819 --> 00:07:07,319
offline and low bandwidth scenario where

00:07:05,460 --> 00:07:09,659
if you think about it both the model and

00:07:07,319 --> 00:07:12,150
the data on the same device you can

00:07:09,659 --> 00:07:14,789
perform inferencing or prediction and

00:07:12,150 --> 00:07:17,580
also do training all offline while the

00:07:14,789 --> 00:07:20,220
device is not connected or has hours an

00:07:17,580 --> 00:07:23,220
environment where it excuse me is an

00:07:20,220 --> 00:07:26,009
environment where network is not easily

00:07:23,220 --> 00:07:28,759
accessible or not really reliable so you

00:07:26,009 --> 00:07:31,680
can have real time and machine learning

00:07:28,759 --> 00:07:33,330
happening on the device offline in

00:07:31,680 --> 00:07:37,590
remote environments where there is no

00:07:33,330 --> 00:07:39,180
connection to any sort of network so

00:07:37,590 --> 00:07:41,639
with that out of the way we can take a

00:07:39,180 --> 00:07:44,370
more closely look at tensorflow Jas and

00:07:41,639 --> 00:07:46,650
when you download technical genis or you

00:07:44,370 --> 00:07:48,180
install it you basically get what's in

00:07:46,650 --> 00:07:50,430
those four boxes there and you actually

00:07:48,180 --> 00:07:52,530
can download each of the individual

00:07:50,430 --> 00:07:54,840
modules individually if you don't want

00:07:52,530 --> 00:07:57,719
to all four of them together but first

00:07:54,840 --> 00:08:01,080
we have the TF layers and what that is

00:07:57,719 --> 00:08:02,849
is the higher level abstraction to the

00:08:01,080 --> 00:08:05,520
model it's where you would use to create

00:08:02,849 --> 00:08:08,190
the layers and the models that I showed

00:08:05,520 --> 00:08:10,560
earlier where you can line up the layers

00:08:08,190 --> 00:08:12,750
and figure out how the agent connect in

00:08:10,560 --> 00:08:15,050
to connect with one another and then you

00:08:12,750 --> 00:08:18,569
have tfj ascore that's the low-level

00:08:15,050 --> 00:08:21,659
portion of the T fjs and that runs all

00:08:18,569 --> 00:08:23,789
your mathematical or computational they

00:08:21,659 --> 00:08:27,000
heavy duty computations and what that

00:08:23,789 --> 00:08:29,460
does is it actually uses the GPU by way

00:08:27,000 --> 00:08:34,409
of the WebGL so if you're not familiar

00:08:29,460 --> 00:08:36,750
with a WebGL it's a 2d 3d drawing

00:08:34,409 --> 00:08:39,300
library but rather than use it for

00:08:36,750 --> 00:08:41,370
drawing tfj ascore uses it to perform

00:08:39,300 --> 00:08:43,800
some of that heavy mathematics and uses

00:08:41,370 --> 00:08:46,199
the GPU but if there's no WebGL or

00:08:43,800 --> 00:08:49,900
there's no web GPU in place it'll

00:08:46,199 --> 00:08:52,210
default back to using the CPU

00:08:49,900 --> 00:08:53,620
next we have the tfj s converter and I'm

00:08:52,210 --> 00:08:55,810
actually going to touch on that a little

00:08:53,620 --> 00:08:58,440
bit later on but that's used to convert

00:08:55,810 --> 00:09:01,840
models between different formats and

00:08:58,440 --> 00:09:03,700
then we have TF data and that he was

00:09:01,840 --> 00:09:06,250
just for handling and parsing and

00:09:03,700 --> 00:09:09,340
inputting and reading in the data of all

00:09:06,250 --> 00:09:11,710
sorts of various formats and then we

00:09:09,340 --> 00:09:13,600
have TF viz which is the visualization

00:09:11,710 --> 00:09:16,480
library to help you visualize the

00:09:13,600 --> 00:09:18,400
behavior that the model is outputting

00:09:16,480 --> 00:09:21,040
and to also see some of the objects with

00:09:18,400 --> 00:09:24,250
intensive flow Jas and then last thing

00:09:21,040 --> 00:09:27,940
we have TF j s node which is the node

00:09:24,250 --> 00:09:30,130
library is the node module and unlike TF

00:09:27,940 --> 00:09:32,530
j s core where in TF j s core or

00:09:30,130 --> 00:09:35,500
actually in all of TF j s everything is

00:09:32,530 --> 00:09:37,840
written in javascript with TF j s node

00:09:35,500 --> 00:09:39,790
much like the Python and Java and the

00:09:37,840 --> 00:09:42,520
other programs as a binding to the

00:09:39,790 --> 00:09:45,220
tensorflow C library so it'll reuse a

00:09:42,520 --> 00:09:49,000
lot of that code and also has access to

00:09:45,220 --> 00:09:50,590
the GPU and there are other parts to TF

00:09:49,000 --> 00:09:53,680
J's which I don't include there's a TF j

00:09:50,590 --> 00:09:55,420
s react native component which allows

00:09:53,680 --> 00:10:00,850
you to use it within react

00:09:55,420 --> 00:10:04,420
there's also oh yes there's ongoing work

00:10:00,850 --> 00:10:06,400
happening with web GPU which is a new

00:10:04,420 --> 00:10:07,900
standard coming up on far as accessing

00:10:06,400 --> 00:10:12,040
GPU through the javascript in the

00:10:07,900 --> 00:10:15,250
browser client so with that said we have

00:10:12,040 --> 00:10:19,330
a tensors operations and layers which

00:10:15,250 --> 00:10:21,550
make up the core building blocks of the

00:10:19,330 --> 00:10:24,850
TF j SN your machine learning model

00:10:21,550 --> 00:10:26,250
tensors are the basic units and tensors

00:10:24,850 --> 00:10:28,930
basically you can think of them as

00:10:26,250 --> 00:10:31,150
buckets of numbers they can be they're

00:10:28,930 --> 00:10:33,670
basically an n dimensional array like

00:10:31,150 --> 00:10:34,900
structure and tensors the one thing to

00:10:33,670 --> 00:10:37,120
keep in mind with them is they're

00:10:34,900 --> 00:10:39,370
immutable so once you create a tensor

00:10:37,120 --> 00:10:41,500
you're unable to change it if you need

00:10:39,370 --> 00:10:42,760
to change or make any updates to it

00:10:41,500 --> 00:10:45,670
you're basically going to get yourself a

00:10:42,760 --> 00:10:47,560
new tensor back and operations are what

00:10:45,670 --> 00:10:49,510
you use to manipulate or perform

00:10:47,560 --> 00:10:51,390
operations on those tensors and like I

00:10:49,510 --> 00:10:53,560
mentioned since tensors are immutable

00:10:51,390 --> 00:10:56,230
operations every operation you perform

00:10:53,560 --> 00:10:59,580
will actually turn you a new a new

00:10:56,230 --> 00:11:02,110
tensor and then we have layers which is

00:10:59,580 --> 00:11:03,150
basically the layers for the different

00:11:02,110 --> 00:11:05,040
model and you

00:11:03,150 --> 00:11:06,450
that to create and build your model and

00:11:05,040 --> 00:11:08,700
define how your network would look like

00:11:06,450 --> 00:11:13,920
and we can actually take a quick look at

00:11:08,700 --> 00:11:16,650
this and actually this is the tenth

00:11:13,920 --> 00:11:19,230
floor jazz website and it's it's a very

00:11:16,650 --> 00:11:21,330
good as far as documentation as all the

00:11:19,230 --> 00:11:22,860
AP is and all the commands and all the

00:11:21,330 --> 00:11:24,120
functionality available to it as you can

00:11:22,860 --> 00:11:26,130
see it's pretty extensive and pretty

00:11:24,120 --> 00:11:28,440
long and each one of these you can

00:11:26,130 --> 00:11:30,089
actually go in here and actually run and

00:11:28,440 --> 00:11:33,779
test most of the commands directly

00:11:30,089 --> 00:11:35,700
within the browser itself there but what

00:11:33,779 --> 00:11:42,120
I wanted to show you is here can you see

00:11:35,700 --> 00:11:43,920
that yep all right so the first thing we

00:11:42,120 --> 00:11:46,500
have up here is I'm defining a tensor

00:11:43,920 --> 00:11:47,730
and it's basically just TF tensor and in

00:11:46,500 --> 00:11:50,430
this case I'm using an N dimensional

00:11:47,730 --> 00:11:52,440
array two dimensional array to go ahead

00:11:50,430 --> 00:11:53,850
and define the tensor and I'm just going

00:11:52,440 --> 00:11:56,130
to create the tensor and print it and

00:11:53,850 --> 00:11:58,470
then after that it shows in a different

00:11:56,130 --> 00:12:01,170
way to define a tensor and this one I

00:11:58,470 --> 00:12:02,520
just basically use a flat array I pass

00:12:01,170 --> 00:12:03,990
it in the neck but also pass it the

00:12:02,520 --> 00:12:05,820
shape that I want the tensor to be which

00:12:03,990 --> 00:12:08,010
is a three by two by one in this case

00:12:05,820 --> 00:12:12,120
and then the type which can be int a

00:12:08,010 --> 00:12:14,640
string see the int string float and I

00:12:12,120 --> 00:12:17,010
believe boolean and then lastly there's

00:12:14,640 --> 00:12:18,510
some helpful utilities that allow you to

00:12:17,010 --> 00:12:20,130
create the tensor more quickly so you

00:12:18,510 --> 00:12:22,500
can do CF star scale if you're just

00:12:20,130 --> 00:12:24,120
creating a number or for example TF dot

00:12:22,500 --> 00:12:28,250
4d if you want a four dimensional array

00:12:24,120 --> 00:12:30,270
or 5d and so on so if I quickly run this

00:12:28,250 --> 00:12:31,980
it's not going to do much except just

00:12:30,270 --> 00:12:33,959
print out those values of the tensor

00:12:31,980 --> 00:12:35,700
there I create there and you can see

00:12:33,959 --> 00:12:38,190
we're basically with the definition of a

00:12:35,700 --> 00:12:45,600
tensor in action let me do this so you

00:12:38,190 --> 00:12:46,709
can see a little bit more this will

00:12:45,600 --> 00:12:53,700
print out a little bit more information

00:12:46,709 --> 00:12:56,400
about the tensors alright so you see it

00:12:53,700 --> 00:12:58,680
has the type the rank the shape and then

00:12:56,400 --> 00:13:00,930
the values of the tensor so that is a

00:12:58,680 --> 00:13:01,580
tensor object and if we go a little

00:13:00,930 --> 00:13:04,580
further down

00:13:01,580 --> 00:13:04,580
whoops

00:13:06,200 --> 00:13:11,210
we can quickly take a look at operations

00:13:14,930 --> 00:13:19,680
so here I'm it's just a simple ad

00:13:18,000 --> 00:13:21,330
operation I'm just taking one tensor

00:13:19,680 --> 00:13:23,460
adding it to another and then printing

00:13:21,330 --> 00:13:24,570
the output but in the bottom and doing a

00:13:23,460 --> 00:13:27,150
little bit something a little bit more

00:13:24,570 --> 00:13:29,760
complex not really but it's a little bit

00:13:27,150 --> 00:13:31,500
I guess so we had to take one tensor we

00:13:29,760 --> 00:13:33,810
perform a dot product with another

00:13:31,500 --> 00:13:40,980
tensor then we square it and print it so

00:13:33,810 --> 00:13:42,750
if I run that real quick see we get the

00:13:40,980 --> 00:13:44,250
output of both of those sensors now you

00:13:42,750 --> 00:13:46,050
see two tensors there in the output but

00:13:44,250 --> 00:13:48,630
like I mentioned these ten Thursday

00:13:46,050 --> 00:13:50,610
immutable so when I'm over here when I'm

00:13:48,630 --> 00:13:52,650
running through this particular car here

00:13:50,610 --> 00:13:54,150
where I create one tensor a one D tensor

00:13:52,650 --> 00:13:55,980
a 2 D tensor then the dot the square

00:13:54,150 --> 00:13:58,339
that adds actually ends up creating four

00:13:55,980 --> 00:14:02,010
tensors so now there are four tensors in

00:13:58,339 --> 00:14:05,000
memory so we can look at how to deal

00:14:02,010 --> 00:14:05,000
with memory here

00:14:15,580 --> 00:14:20,240
so that for example here I just threw

00:14:18,470 --> 00:14:21,890
some code in the edges performing a

00:14:20,240 --> 00:14:24,080
bunch of operations and then I'm going

00:14:21,890 --> 00:14:29,260
to print out the TF dot memory and we

00:14:24,080 --> 00:14:29,260
can see what's in memory at this point

00:14:31,090 --> 00:14:34,490
and we see there tells us the number of

00:14:33,170 --> 00:14:36,410
bytes being used and the number of

00:14:34,490 --> 00:14:38,360
tenths is five so even though I just

00:14:36,410 --> 00:14:40,610
have an A and B there's actually five

00:14:38,360 --> 00:14:42,740
tensors that are created here and one

00:14:40,610 --> 00:14:44,300
thing you can do and you can imagine if

00:14:42,740 --> 00:14:46,010
this is in a for loop then you start

00:14:44,300 --> 00:14:48,410
having all these tensors that you need

00:14:46,010 --> 00:14:49,700
to keep track of and try to take care of

00:14:48,410 --> 00:14:53,600
before you start running into memory

00:14:49,700 --> 00:14:55,970
leaks so one thing one way to resolve

00:14:53,600 --> 00:15:01,240
that is to call a dispose function so I

00:14:55,970 --> 00:15:06,770
can do for example a dot dispose and B

00:15:01,240 --> 00:15:11,390
coups and that'll go ahead and dispose

00:15:06,770 --> 00:15:14,630
and clean up the tensor so once I run

00:15:11,390 --> 00:15:15,800
this again we can see now I only cleaned

00:15:14,630 --> 00:15:17,660
up a and B they're still three other

00:15:15,800 --> 00:15:18,890
tensors that are running in there which

00:15:17,660 --> 00:15:21,440
I did an assignment they're still in

00:15:18,890 --> 00:15:22,670
there so another alternative if you

00:15:21,440 --> 00:15:25,370
don't want to keep track of each of the

00:15:22,670 --> 00:15:28,460
tensors yourself you can go ahead and

00:15:25,370 --> 00:15:32,750
they use a TF tidy which tends before

00:15:28,460 --> 00:15:34,640
we'll go ahead and keep track of the

00:15:32,750 --> 00:15:36,080
tenses for you for you and then once the

00:15:34,640 --> 00:15:43,850
function is done it'll go ahead and

00:15:36,080 --> 00:15:45,680
clean them all so if I run this one we

00:15:43,850 --> 00:15:47,030
see a clean up all the tenses for us and

00:15:45,680 --> 00:15:49,100
everything and they're all they're all

00:15:47,030 --> 00:15:50,450
the other commands on there so for

00:15:49,100 --> 00:15:53,570
example if you wanted to keep the a

00:15:50,450 --> 00:15:55,190
tensor after the TF tidy that runs in

00:15:53,570 --> 00:15:58,820
you know you can there's that keep that

00:15:55,190 --> 00:16:00,500
you can call but now if we go a little

00:15:58,820 --> 00:16:06,010
further down we can look at layers real

00:16:00,500 --> 00:16:08,450
quick and defining a tensor flow model

00:16:06,010 --> 00:16:10,970
so if we look at this code right here

00:16:08,450 --> 00:16:12,950
first I'm defining the type of model I

00:16:10,970 --> 00:16:15,050
want and in this case I'm I have a

00:16:12,950 --> 00:16:16,520
sequential model and a sequential model

00:16:15,050 --> 00:16:18,440
is basically just a stack of layers

00:16:16,520 --> 00:16:20,390
feeding linearly one from another and

00:16:18,440 --> 00:16:22,460
then once I have that model I can go

00:16:20,390 --> 00:16:24,110
ahead and add the layers they for

00:16:22,460 --> 00:16:26,390
example like you saw in the neural

00:16:24,110 --> 00:16:28,230
network diagram and here I'm telling you

00:16:26,390 --> 00:16:30,960
there's if 50

00:16:28,230 --> 00:16:32,430
neurons in this particular layer this is

00:16:30,960 --> 00:16:34,380
the activation function that it's going

00:16:32,430 --> 00:16:35,880
to use there several of them you can get

00:16:34,380 --> 00:16:37,770
it all from the API this is the

00:16:35,880 --> 00:16:40,170
activation function is going to use to

00:16:37,770 --> 00:16:41,730
fire on those neurons and then I also

00:16:40,170 --> 00:16:44,430
since this is the first layer I have to

00:16:41,730 --> 00:16:46,590
provide it the shape of what the what's

00:16:44,430 --> 00:16:48,000
going to be coming in and then I add in

00:16:46,590 --> 00:16:49,830
this case I added the second layer and

00:16:48,000 --> 00:16:52,110
this layer only has one network one

00:16:49,830 --> 00:16:53,820
neuron and it's going to activate on the

00:16:52,110 --> 00:16:55,950
linear function so once you have your

00:16:53,820 --> 00:16:57,570
model defined what you would do is you

00:16:55,950 --> 00:16:59,910
would run the compile on it and this

00:16:57,570 --> 00:17:02,190
configures and compared and prepares the

00:16:59,910 --> 00:17:04,170
model for training and evaluation and in

00:17:02,190 --> 00:17:06,720
here you're going to provide it the loss

00:17:04,170 --> 00:17:09,180
function and the loss function is what's

00:17:06,720 --> 00:17:12,780
going to be used during training to

00:17:09,180 --> 00:17:15,600
determine how accurate the model is and

00:17:12,780 --> 00:17:17,250
then the depending on how accurate and

00:17:15,600 --> 00:17:20,550
how many iterations are long it's going

00:17:17,250 --> 00:17:22,110
to use the optimizer to go back it use

00:17:20,550 --> 00:17:23,910
the optimized algorithm to go back and

00:17:22,110 --> 00:17:30,150
adjust those weights and and biases that

00:17:23,910 --> 00:17:32,280
we saw before so here in the X&Y is I

00:17:30,150 --> 00:17:34,050
just creating some tensors would suggest

00:17:32,280 --> 00:17:35,940
some random values but when you're ready

00:17:34,050 --> 00:17:36,990
to train the model you go ahead and run

00:17:35,940 --> 00:17:39,150
modeled outfit

00:17:36,990 --> 00:17:41,790
you'd pass a your input or your X's and

00:17:39,150 --> 00:17:44,250
then your expected output your wise and

00:17:41,790 --> 00:17:46,110
then you provide it a box or how many

00:17:44,250 --> 00:17:47,790
iterations you wanted to train so I have

00:17:46,110 --> 00:17:49,500
to each one of those literation x' is

00:17:47,790 --> 00:17:52,230
going to check the loss and then apply

00:17:49,500 --> 00:17:54,690
the optimization function and adjust the

00:17:52,230 --> 00:17:57,210
weights and biases and then run it again

00:17:54,690 --> 00:18:00,180
and here all I'm doing is going ahead

00:17:57,210 --> 00:18:02,430
and printing they with the lost value is

00:18:00,180 --> 00:18:04,620
at that point and in this case I'm going

00:18:02,430 --> 00:18:06,990
to run it a hundred times and then once

00:18:04,620 --> 00:18:08,730
it's done I'm ready to use it to use the

00:18:06,990 --> 00:18:10,380
model I can save the model or in this

00:18:08,730 --> 00:18:11,640
case I'm just going to run a prediction

00:18:10,380 --> 00:18:13,200
against that model with some random

00:18:11,640 --> 00:18:14,130
values so I'm going to go ahead and run

00:18:13,200 --> 00:18:15,420
this it's not going to do anything

00:18:14,130 --> 00:18:18,680
interesting because I'm just using a

00:18:15,420 --> 00:18:18,680
bunch of random values

00:18:23,880 --> 00:18:28,870
and see as it's going here through each

00:18:26,560 --> 00:18:30,280
of the iterations the loss is getting a

00:18:28,870 --> 00:18:34,210
little better it's getting less and less

00:18:30,280 --> 00:18:36,400
and the goal is always to try to get

00:18:34,210 --> 00:18:38,290
your loss as low as possible when you're

00:18:36,400 --> 00:18:40,420
trying to train and and it all depends

00:18:38,290 --> 00:18:41,980
on the data you have and the this type

00:18:40,420 --> 00:18:44,920
of model how quickly that's going to

00:18:41,980 --> 00:18:49,090
happen and how much work needs to get

00:18:44,920 --> 00:18:53,890
put into that all right so that's

00:18:49,090 --> 00:18:58,600
tensors operations and layers let's go

00:18:53,890 --> 00:19:00,370
back so now that you have these basic

00:18:58,600 --> 00:19:01,930
building blocks in place you can go

00:19:00,370 --> 00:19:05,590
ahead and start your own AI revolution

00:19:01,930 --> 00:19:07,900
correct probably so what some of you may

00:19:05,590 --> 00:19:09,790
be thinking is there's a lot of models

00:19:07,900 --> 00:19:11,680
out there there are a lot more complex

00:19:09,790 --> 00:19:14,590
and what I showed you some very basic

00:19:11,680 --> 00:19:16,690
stuff and a lot of these models the

00:19:14,590 --> 00:19:19,810
training portion due to the complexity

00:19:16,690 --> 00:19:23,410
can take days if not weeks to Train and

00:19:19,810 --> 00:19:25,510
that does not make good for experience

00:19:23,410 --> 00:19:29,410
in the browser or on a mobile device or

00:19:25,510 --> 00:19:32,350
some edge devices so what can you do in

00:19:29,410 --> 00:19:34,360
that case well instead of training what

00:19:32,350 --> 00:19:37,030
a lot of the community has been doing

00:19:34,360 --> 00:19:39,220
and what we are Cote tend to focus on is

00:19:37,030 --> 00:19:42,010
actually running pre train models and

00:19:39,220 --> 00:19:43,690
with intensive ojs and what this is is

00:19:42,010 --> 00:19:45,760
basically taking a model that's been

00:19:43,690 --> 00:19:47,410
trained elsewhere and then bringing it

00:19:45,760 --> 00:19:50,140
into ten soldiers and then just running

00:19:47,410 --> 00:19:53,290
it they on the browser on the mobile or

00:19:50,140 --> 00:19:56,080
edge device and the way you get to this

00:19:53,290 --> 00:19:58,000
is through the TF j TF excuse me

00:19:56,080 --> 00:20:00,490
tensorflow J is converted to which is

00:19:58,000 --> 00:20:03,040
basically a Python command line utility

00:20:00,490 --> 00:20:07,810
that is used to convert it models from

00:20:03,040 --> 00:20:09,520
one format to another format and then

00:20:07,810 --> 00:20:11,140
once you have it in though once you

00:20:09,520 --> 00:20:14,010
convert it into the web format you can

00:20:11,140 --> 00:20:17,500
go ahead and load it into the in a tfj

00:20:14,010 --> 00:20:18,670
application I run over there and to run

00:20:17,500 --> 00:20:19,960
tensorflow just once you have it

00:20:18,670 --> 00:20:22,270
installed it's pretty straightforward

00:20:19,960 --> 00:20:24,070
you just provided the input of the model

00:20:22,270 --> 00:20:25,900
that you're working with the format of

00:20:24,070 --> 00:20:27,460
the model working with the preferred

00:20:25,900 --> 00:20:29,200
output that you want it to convert to

00:20:27,460 --> 00:20:30,760
and then the path of where I can find

00:20:29,200 --> 00:20:34,290
the model and the path of where it is to

00:20:30,760 --> 00:20:34,290
save the converted model

00:20:34,950 --> 00:20:40,059
so if you think about that that sounds

00:20:38,259 --> 00:20:42,159
really wonderful you can take your model

00:20:40,059 --> 00:20:44,409
train it on some server that's really

00:20:42,159 --> 00:20:47,200
beefy that's really been SPECT it's

00:20:44,409 --> 00:20:48,399
dedicated to creating it to training and

00:20:47,200 --> 00:20:50,320
running these models and it can be

00:20:48,399 --> 00:20:52,210
running for days weeks on and if asked

00:20:50,320 --> 00:20:54,820
to then once you have them are you can

00:20:52,210 --> 00:20:56,440
go ahead convert it and then take it and

00:20:54,820 --> 00:20:58,899
run it into your JavaScript application

00:20:56,440 --> 00:21:02,440
so you get the best of both worlds and

00:20:58,899 --> 00:21:04,059
that is true but the thing that to come

00:21:02,440 --> 00:21:06,549
to mind and to think about is

00:21:04,059 --> 00:21:10,509
unfortunately not all models can be

00:21:06,549 --> 00:21:13,509
converted and the first thing a block

00:21:10,509 --> 00:21:16,899
they run into is the convertor supports

00:21:13,509 --> 00:21:18,789
only tensorflow and caris models so if

00:21:16,899 --> 00:21:20,769
you have a safe model which is the

00:21:18,789 --> 00:21:23,470
preferred format of tensorflow

00:21:20,769 --> 00:21:25,749
or you have a frozen you can convert it

00:21:23,470 --> 00:21:27,580
if you have a frozen graph and actually

00:21:25,749 --> 00:21:31,509
this has changed as of tensorflow j/s

00:21:27,580 --> 00:21:33,220
converter a 1.0 frozen graphs are no

00:21:31,509 --> 00:21:35,080
longer supported so if you actually want

00:21:33,220 --> 00:21:37,509
to convert a frozen graph you would have

00:21:35,080 --> 00:21:39,669
to it's recommended for you to downgrade

00:21:37,509 --> 00:21:42,190
to an older version of the converter but

00:21:39,669 --> 00:21:44,019
you have hdf5 models which are Kerris

00:21:42,190 --> 00:21:46,419
models and in there's also tensorflow

00:21:44,019 --> 00:21:48,009
hub models so if you have these models

00:21:46,419 --> 00:21:50,350
you can go ahead and convert them to the

00:21:48,009 --> 00:21:52,929
web format but if you if you have an

00:21:50,350 --> 00:21:54,220
Onix model or a PI torch model then

00:21:52,929 --> 00:21:56,080
you're not gonna be able to convert that

00:21:54,220 --> 00:21:57,700
model and unfortunately that model won't

00:21:56,080 --> 00:22:01,990
be able to run in your tensorflow J's

00:21:57,700 --> 00:22:05,440
environment the other thing to think

00:22:01,990 --> 00:22:07,299
about is the the model requirements so

00:22:05,440 --> 00:22:08,980
there's some models require special

00:22:07,299 --> 00:22:11,230
pre-processing of the import and special

00:22:08,980 --> 00:22:12,669
post-processing of the output so you've

00:22:11,230 --> 00:22:14,619
got to think about these really special

00:22:12,669 --> 00:22:16,389
pre and post-processing and can they be

00:22:14,619 --> 00:22:18,610
handled or are they even worth doing in

00:22:16,389 --> 00:22:20,049
JavaScript it may not be it may be the

00:22:18,610 --> 00:22:21,519
case that they can't be done in

00:22:20,049 --> 00:22:22,990
JavaScript in which case you probably

00:22:21,519 --> 00:22:24,970
not going to be able to use that model

00:22:22,990 --> 00:22:27,009
if you can really process its import or

00:22:24,970 --> 00:22:29,139
in or output the other thing is the size

00:22:27,009 --> 00:22:31,480
of the model and the performance so

00:22:29,139 --> 00:22:33,970
although you may be able to convert 700

00:22:31,480 --> 00:22:36,249
megabyte model it may not be wise to

00:22:33,970 --> 00:22:39,279
actually try to run a model that size in

00:22:36,249 --> 00:22:42,340
a mobile device so that's something to

00:22:39,279 --> 00:22:44,590
think about and there are studies and

00:22:42,340 --> 00:22:45,520
options that you can do and work being

00:22:44,590 --> 00:22:48,789
done

00:22:45,520 --> 00:22:50,860
in model optimization but there's still

00:22:48,789 --> 00:22:53,200
there's some out of that there's only so

00:22:50,860 --> 00:22:54,580
much optimization that you can do and so

00:22:53,200 --> 00:22:56,559
much performance gains that you can be

00:22:54,580 --> 00:22:58,240
had so in those cases JavaScript

00:22:56,559 --> 00:23:07,480
probably is just not gonna cut it for

00:22:58,240 --> 00:23:09,970
you and perhaps the biggest a constraint

00:23:07,480 --> 00:23:12,460
with converting models is the number of

00:23:09,970 --> 00:23:14,649
supported operations where tensorflow

00:23:12,460 --> 00:23:16,059
J's is still fairly new and they I don't

00:23:14,649 --> 00:23:19,080
remember the exact number but it

00:23:16,059 --> 00:23:21,250
supports roughly around 200 or so

00:23:19,080 --> 00:23:23,380
operations well

00:23:21,250 --> 00:23:26,110
tensile on the other hand supports over

00:23:23,380 --> 00:23:28,750
800 operations so what that means is if

00:23:26,110 --> 00:23:31,299
you have an operation if your model has

00:23:28,750 --> 00:23:33,340
an operation that is not supported by

00:23:31,299 --> 00:23:35,590
tensorflow J's yeah you're not going to

00:23:33,340 --> 00:23:37,090
be able to convert that model now there

00:23:35,590 --> 00:23:38,679
are things you can do with that so

00:23:37,090 --> 00:23:40,929
depending on where within the model

00:23:38,679 --> 00:23:42,820
graph that operation is and what that

00:23:40,929 --> 00:23:45,850
operation is you may be able to work

00:23:42,820 --> 00:23:48,360
around that but in some cases you're not

00:23:45,850 --> 00:23:51,760
gonna be able to go ahead and support

00:23:48,360 --> 00:23:53,529
and convert that model to tensile ojs

00:23:51,760 --> 00:23:56,590
without the support of that operation

00:23:53,529 --> 00:23:59,020
and there's work going on now to try to

00:23:56,590 --> 00:24:00,640
increase these number of operations and

00:23:59,020 --> 00:24:02,500
with each release more and more

00:24:00,640 --> 00:24:05,470
operations get introduced but it's gonna

00:24:02,500 --> 00:24:06,130
take time to get on par or even close to

00:24:05,470 --> 00:24:12,549
what tensorflow

00:24:06,130 --> 00:24:15,779
currently has so even though with those

00:24:12,549 --> 00:24:18,580
limitations in place I should probably

00:24:15,779 --> 00:24:20,500
let you know that you can still do a lot

00:24:18,580 --> 00:24:22,149
with tensorflow Jess so you don't need

00:24:20,500 --> 00:24:23,980
to wait for all those operations to

00:24:22,149 --> 00:24:26,520
become available you don't need to wait

00:24:23,980 --> 00:24:29,820
for the browser or the mobile device to

00:24:26,520 --> 00:24:32,529
gain significant performance

00:24:29,820 --> 00:24:34,600
enhancements and you also don't need to

00:24:32,529 --> 00:24:36,370
wait wait till you get your PhD degree

00:24:34,600 --> 00:24:37,539
in machine learning to start playing

00:24:36,370 --> 00:24:40,000
around with machine learning and

00:24:37,539 --> 00:24:42,100
experiment experimenting with testicle

00:24:40,000 --> 00:24:43,690
Jess and I'm gonna show you just a

00:24:42,100 --> 00:24:48,100
couple examples of things that are being

00:24:43,690 --> 00:24:50,080
done currently with tensorflow Jess so

00:24:48,100 --> 00:24:53,049
the first is this command-line utility

00:24:50,080 --> 00:24:56,200
called magic hat and what it does is it

00:24:53,049 --> 00:24:58,500
basically takes in an image or directory

00:24:56,200 --> 00:25:00,299
of images and then

00:24:58,500 --> 00:25:02,820
it gives you the information on all the

00:25:00,299 --> 00:25:05,070
objects found within those images so you

00:25:02,820 --> 00:25:06,510
can use that to basically scan through a

00:25:05,070 --> 00:25:08,250
directory of images find an image that

00:25:06,510 --> 00:25:11,580
has a particular object that you're

00:25:08,250 --> 00:25:13,590
interested in or you can use it to crop

00:25:11,580 --> 00:25:16,770
out a particular object out of the image

00:25:13,590 --> 00:25:20,039
so for example in this example and this

00:25:16,770 --> 00:25:21,600
image up here I go ahead scan the

00:25:20,039 --> 00:25:23,940
directory had two images in the

00:25:21,600 --> 00:25:26,280
directory one of a cow and another one

00:25:23,940 --> 00:25:28,140
of the sheep and the sheep image also

00:25:26,280 --> 00:25:30,690
had a person in it but then what I do is

00:25:28,140 --> 00:25:32,460
I use the magic cat and I also tell it

00:25:30,690 --> 00:25:33,659
to remove the cop from the image so I

00:25:32,460 --> 00:25:38,130
actually creates a brand new image

00:25:33,659 --> 00:25:39,780
without the cow in it and this way it

00:25:38,130 --> 00:25:43,020
was actually created by a colleague of

00:25:39,780 --> 00:25:45,360
mine in a casting and he actually uses

00:25:43,020 --> 00:25:47,130
the image segmentation model and just

00:25:45,360 --> 00:25:49,559
converted it to tensorflow jeaious and

00:25:47,130 --> 00:25:55,679
then runs it in a node application

00:25:49,559 --> 00:25:59,159
command-line utility another interesting

00:25:55,679 --> 00:26:01,559
and fun application that I got to work

00:25:59,159 --> 00:26:03,299
on with John Konya who's an IBM

00:26:01,559 --> 00:26:06,000
distinguished engineer and our resident

00:26:03,299 --> 00:26:09,390
mad scientist is this idea of a video

00:26:06,000 --> 00:26:11,640
Thurman so basically what we did is if

00:26:09,390 --> 00:26:15,240
we try to make music there using the

00:26:11,640 --> 00:26:17,429
webcam on your phone or on the laptop

00:26:15,240 --> 00:26:19,559
and basically make music as your arms

00:26:17,429 --> 00:26:24,600
we're just moving your arms around so

00:26:19,559 --> 00:26:26,549
let's see if this plays so as you can

00:26:24,600 --> 00:26:28,980
see he's basically just moving his arms

00:26:26,549 --> 00:26:34,260
around and then depending on what he

00:26:28,980 --> 00:26:37,530
does it plays different music so neither

00:26:34,260 --> 00:26:39,360
one of us are musicians so we can't play

00:26:37,530 --> 00:26:41,309
nothing really well but it shows you

00:26:39,360 --> 00:26:43,679
some of the stuff you can do now with

00:26:41,309 --> 00:26:45,720
the key thing here is we used our open

00:26:43,679 --> 00:26:48,059
excuse me the pose net model for

00:26:45,720 --> 00:26:50,850
tensorflow j/s and what that model does

00:26:48,059 --> 00:26:53,490
is it basically it takes in an image and

00:26:50,850 --> 00:26:55,530
returns the supposed information of a

00:26:53,490 --> 00:26:56,820
person that in that for all the people

00:26:55,530 --> 00:26:58,590
in that image in this case it's just one

00:26:56,820 --> 00:27:02,580
person so then we take that pose

00:26:58,590 --> 00:27:05,100
information and we go ahead and we we go

00:27:02,580 --> 00:27:06,960
ahead and transform it to MIDI notes and

00:27:05,100 --> 00:27:08,730
we take those MIDI notes and you can use

00:27:06,960 --> 00:27:10,840
it to control a MIDI device or in this

00:27:08,730 --> 00:27:18,700
case we just use it to play audio in the

00:27:10,840 --> 00:27:21,660
using the Web Audio API and while those

00:27:18,700 --> 00:27:23,910
were some pretty entertaining and fun

00:27:21,660 --> 00:27:28,270
applications that we've created more

00:27:23,910 --> 00:27:33,040
serious and a more real-world use case

00:27:28,270 --> 00:27:35,680
is drone aid and for people who are not

00:27:33,040 --> 00:27:38,440
familiar drone aid actually came about

00:27:35,680 --> 00:27:40,030
from IBM's call for code global

00:27:38,440 --> 00:27:42,070
challenge and if you don't know what

00:27:40,030 --> 00:27:45,220
call for code is it's a worldwide

00:27:42,070 --> 00:27:47,590
challenge for developers it's come up

00:27:45,220 --> 00:27:51,090
with technical solutions around natural

00:27:47,590 --> 00:27:53,680
disaster recovery preparedness and

00:27:51,090 --> 00:27:55,900
responsiveness and drone aid was an

00:27:53,680 --> 00:27:58,810
entry last year and the gentleman Pedro

00:27:55,900 --> 00:28:02,350
Cruz is actually from Puerto Rico and he

00:27:58,810 --> 00:28:04,150
has this amazing story on the

00:28:02,350 --> 00:28:06,190
inspiration behind creating journal read

00:28:04,150 --> 00:28:08,950
and I'll definitely ask you to check

00:28:06,190 --> 00:28:11,800
that out but basically what drone a does

00:28:08,950 --> 00:28:14,950
is it takes video streams and coming

00:28:11,800 --> 00:28:16,630
from drones flying over for example an

00:28:14,950 --> 00:28:18,660
area that's been hit by a natural

00:28:16,630 --> 00:28:22,300
disaster and it's going to look for

00:28:18,660 --> 00:28:24,580
certain signs of help like SOS images or

00:28:22,300 --> 00:28:26,500
signals and then I'll take that

00:28:24,580 --> 00:28:30,580
information and it can either plot it on

00:28:26,500 --> 00:28:32,620
a map or send it over you over to the

00:28:30,580 --> 00:28:36,250
first responders with the location and

00:28:32,620 --> 00:28:38,260
what sort of help is required there so

00:28:36,250 --> 00:28:41,320
what I have here is basically I was just

00:28:38,260 --> 00:28:43,470
play a live actually it's been two weeks

00:28:41,320 --> 00:28:46,210
now two weeks ago they released this

00:28:43,470 --> 00:28:48,070
open source with the 10th floor jns

00:28:46,210 --> 00:28:50,830
model and they've actually joined a

00:28:48,070 --> 00:28:52,780
Linux Foundation as a project that's

00:28:50,830 --> 00:28:54,190
part of the Linux Foundation and the

00:28:52,780 --> 00:28:56,350
screenshot here is basically me just

00:28:54,190 --> 00:28:58,960
playing around with the 10th floor jazz

00:28:56,350 --> 00:29:02,170
version of that model trying to detect

00:28:58,960 --> 00:29:03,640
different signals with a pre-recorded I

00:29:02,170 --> 00:29:05,710
didn't have a drone at the time so I

00:29:03,640 --> 00:29:08,560
basically just used a pre-recorded video

00:29:05,710 --> 00:29:10,810
taken on my phone to go ahead and run

00:29:08,560 --> 00:29:13,060
the model again and as it's the videos

00:29:10,810 --> 00:29:14,710
playing in the model is detecting all

00:29:13,060 --> 00:29:16,330
these signals and then just giving a

00:29:14,710 --> 00:29:19,560
count for them in this particular

00:29:16,330 --> 00:29:19,560
instance here

00:29:21,840 --> 00:29:26,350
so with that I hopefully have inspired

00:29:24,520 --> 00:29:28,570
you to think about machine learning in a

00:29:26,350 --> 00:29:31,150
different way and some experimenting

00:29:28,570 --> 00:29:33,040
with tensorflow Jas so what I want to

00:29:31,150 --> 00:29:35,170
say is thank you for coming here and

00:29:33,040 --> 00:29:37,270
listening to this talk specially been

00:29:35,170 --> 00:29:39,640
the last one of the day and you can go

00:29:37,270 --> 00:29:41,940
ahead and reach out to me as far baboso

00:29:39,640 --> 00:29:44,470
across most social media networks and

00:29:41,940 --> 00:29:46,840
the URL on the bottom is actually the

00:29:44,470 --> 00:29:49,810
URL for the slides where you can get all

00:29:46,840 --> 00:29:51,640
this notes for the slide along with it

00:29:49,810 --> 00:29:53,770
all the links to all the content that I

00:29:51,640 --> 00:29:55,840
talked about so at this time I'm just

00:29:53,770 --> 00:29:58,120
gonna say and see if anybody has any

00:29:55,840 --> 00:29:59,950
questions or wanted me to go over

00:29:58,120 --> 00:30:09,850
something that I may have missed or they

00:29:59,950 --> 00:30:11,170
were hoping to get it covered so no

00:30:09,850 --> 00:30:13,210
questions at this time well I'll be

00:30:11,170 --> 00:30:14,830
around a little bit longer if anybody

00:30:13,210 --> 00:30:16,340
needs anything and again thank you very

00:30:14,830 --> 00:30:20,150
much

00:30:16,340 --> 00:30:20,150

YouTube URL: https://www.youtube.com/watch?v=VkDtIjXo6Dk


