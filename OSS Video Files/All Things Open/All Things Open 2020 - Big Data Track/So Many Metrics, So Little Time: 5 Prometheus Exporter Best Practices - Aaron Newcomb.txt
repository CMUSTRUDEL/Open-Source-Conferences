Title: So Many Metrics, So Little Time: 5 Prometheus Exporter Best Practices - Aaron Newcomb
Publication date: 2020-12-11
Playlist: All Things Open 2020 - Big Data Track
Description: 
	Presented by: Aaron Newcomb, Sysdig
Presented at All Things Open 2020 - Big Data Track

Abstract: If you are using Prometheus exporters to gather information from third-party applications and cloud services, it can sometimes feel like the wild west. There are many exporters to choose from and they have to be configured and maintained correctly to make sure you are getting the most value out of them. In this webinar, we will share some best practices to implement when choosing and deploying Prometheus exporters, dashboards and alerts that will apply not just to a single DevOps team, but to your extended teams and entire environment as well.

Join us to discover why these five best practices are so important:

- Find the right Prometheus exporter
- Understand your exporter metrics
- Set alerts that matter and are actionable
- Enable your team to use your data
- Have a plan for scale
Captions: 
	00:00:04,960 --> 00:00:10,000
my name is erin newcombe i'm

00:00:06,799 --> 00:00:12,960
director of product marketing at systig

00:00:10,000 --> 00:00:13,440
i've been around monitoring for a little

00:00:12,960 --> 00:00:16,480
while

00:00:13,440 --> 00:00:18,960
i about five years six years

00:00:16,480 --> 00:00:20,320
i spent some time at new relic also

00:00:18,960 --> 00:00:23,600
worked at app dynamics

00:00:20,320 --> 00:00:26,720
and then came over to sysdig and

00:00:23,600 --> 00:00:27,439
long enterprise uh hardware and software

00:00:26,720 --> 00:00:30,720
background

00:00:27,439 --> 00:00:34,399
before that with companies like hpe and

00:00:30,720 --> 00:00:36,880
sun microsystems uh oracle etc etc

00:00:34,399 --> 00:00:37,840
um but for monitoring you know i would

00:00:36,880 --> 00:00:40,239
say i'm i'm

00:00:37,840 --> 00:00:41,760
i'm still relatively new uh but i have a

00:00:40,239 --> 00:00:44,000
pretty good background so

00:00:41,760 --> 00:00:45,120
i'm gonna be talking today about the

00:00:44,000 --> 00:00:48,079
best practices

00:00:45,120 --> 00:00:49,760
around selecting choosing implementing

00:00:48,079 --> 00:00:53,600
prometheus exporters

00:00:49,760 --> 00:00:53,600
so let's go ahead and get right started

00:00:54,320 --> 00:00:58,480
this is what i'd like to spend some time

00:00:55,920 --> 00:00:59,280
talking about today and if you do have

00:00:58,480 --> 00:01:00,800
questions

00:00:59,280 --> 00:01:03,120
happy to take some time to answer those

00:01:00,800 --> 00:01:05,199
i'll try to end up

00:01:03,120 --> 00:01:06,240
with enough time to have a discussion if

00:01:05,199 --> 00:01:07,680
you'd like

00:01:06,240 --> 00:01:09,600
but certainly feel free to throw some

00:01:07,680 --> 00:01:10,560
questions in and i will try to answer

00:01:09,600 --> 00:01:12,640
those

00:01:10,560 --> 00:01:14,560
as soon as i can so we're gonna be

00:01:12,640 --> 00:01:16,159
talking about just to level set what's

00:01:14,560 --> 00:01:17,920
prometheus and what's an exporter in

00:01:16,159 --> 00:01:21,200
case there's folks on the call that

00:01:17,920 --> 00:01:22,960
aren't aware um we'll talk about five

00:01:21,200 --> 00:01:26,080
prometheus exporters

00:01:22,960 --> 00:01:28,000
best practices and then if there's time

00:01:26,080 --> 00:01:29,280
i'll do a little demo to show you what

00:01:28,000 --> 00:01:31,360
it actually looks like

00:01:29,280 --> 00:01:32,880
uh at least with the systick product and

00:01:31,360 --> 00:01:35,600
then as i said there will be time for

00:01:32,880 --> 00:01:35,600
questions as well

00:01:37,759 --> 00:01:43,680
so at cystig we like to talk about um

00:01:41,200 --> 00:01:45,280
five workloads that we see our customers

00:01:43,680 --> 00:01:47,200
running in

00:01:45,280 --> 00:01:49,200
their secure devops environment and

00:01:47,200 --> 00:01:51,840
secure devops is really just

00:01:49,200 --> 00:01:53,600
um a trend that we're seeing where

00:01:51,840 --> 00:01:54,399
security is playing a bigger and bigger

00:01:53,600 --> 00:01:58,000
role

00:01:54,399 --> 00:01:59,040
in devops teams and so there's really

00:01:58,000 --> 00:02:01,520
five things that we see

00:01:59,040 --> 00:02:03,040
image scanning runtime security

00:02:01,520 --> 00:02:06,840
compliance which hand which

00:02:03,040 --> 00:02:10,560
occurs at all stages throughout the um

00:02:06,840 --> 00:02:13,280
uh um application development process

00:02:10,560 --> 00:02:15,040
as well as monitoring kubernetes and

00:02:13,280 --> 00:02:17,040
containers and then finally

00:02:15,040 --> 00:02:19,520
application and cloud service monitoring

00:02:17,040 --> 00:02:21,440
now this last point is the topic of

00:02:19,520 --> 00:02:22,879
today's discussion which is where these

00:02:21,440 --> 00:02:24,560
best practices come in

00:02:22,879 --> 00:02:26,160
and these best practices will apply to

00:02:24,560 --> 00:02:28,560
any tool

00:02:26,160 --> 00:02:30,319
or methodology that you choose of course

00:02:28,560 --> 00:02:32,879
i do work for systig so i'm going to be

00:02:30,319 --> 00:02:34,720
using systick as examples here

00:02:32,879 --> 00:02:36,000
but you can take this information and

00:02:34,720 --> 00:02:38,800
use it in your own environment

00:02:36,000 --> 00:02:40,000
you don't have to necessarily use systig

00:02:38,800 --> 00:02:41,360
for any of this

00:02:40,000 --> 00:02:43,040
but that's what i'm going to be showing

00:02:41,360 --> 00:02:43,440
because that's the tool that i happen to

00:02:43,040 --> 00:02:45,840
have

00:02:43,440 --> 00:02:45,840
at hand

00:02:46,560 --> 00:02:51,599
so first of all what is prometheus well

00:02:49,760 --> 00:02:52,959
prometheus is a project that lives in

00:02:51,599 --> 00:02:55,760
the cncf

00:02:52,959 --> 00:02:57,360
um but we'll talk about the progression

00:02:55,760 --> 00:02:58,560
and popularity of prometheus as a

00:02:57,360 --> 00:03:01,040
project in a minute

00:02:58,560 --> 00:03:01,840
but essentially it's a time series based

00:03:01,040 --> 00:03:05,120
monitoring

00:03:01,840 --> 00:03:06,319
system so it captures uh metrics from

00:03:05,120 --> 00:03:08,800
your system

00:03:06,319 --> 00:03:10,480
um and stores them for you and then you

00:03:08,800 --> 00:03:11,680
can go back and analyze those

00:03:10,480 --> 00:03:13,599
to see what's going on in your

00:03:11,680 --> 00:03:16,319
environment but it's not just that

00:03:13,599 --> 00:03:18,480
it's also a set of client libraries so

00:03:16,319 --> 00:03:20,159
if you're running your own code

00:03:18,480 --> 00:03:21,760
and you need a library you want to

00:03:20,159 --> 00:03:23,120
instrument it you can instrument it with

00:03:21,760 --> 00:03:25,680
prometheus

00:03:23,120 --> 00:03:28,159
by using the client libraries for python

00:03:25,680 --> 00:03:31,120
or java or go etc etc

00:03:28,159 --> 00:03:32,720
and you can do that fairly easily it's

00:03:31,120 --> 00:03:35,360
also an ecosystem

00:03:32,720 --> 00:03:36,799
with exporters for lots of different

00:03:35,360 --> 00:03:39,120
third-party applications

00:03:36,799 --> 00:03:40,799
so if you're not uh developing your own

00:03:39,120 --> 00:03:42,400
application you're using somebody else's

00:03:40,799 --> 00:03:44,959
you can find an exporter for it we'll

00:03:42,400 --> 00:03:47,040
talk more about that in a minute

00:03:44,959 --> 00:03:48,879
it also exposes metrics in a human

00:03:47,040 --> 00:03:51,680
readable format so that you can use

00:03:48,879 --> 00:03:52,799
things like prom ql the query language

00:03:51,680 --> 00:03:54,720
for prometheus

00:03:52,799 --> 00:03:56,000
to go in and take a look at those and

00:03:54,720 --> 00:03:57,200
have them make sense

00:03:56,000 --> 00:04:00,480
hopefully in the way that they're

00:03:57,200 --> 00:04:02,480
presented to you it also allows for

00:04:00,480 --> 00:04:04,080
service discovery mechanisms so that you

00:04:02,480 --> 00:04:05,599
can more easily find things as they're

00:04:04,080 --> 00:04:08,720
deployed if you're automating

00:04:05,599 --> 00:04:10,640
your environment it's also worth noting

00:04:08,720 --> 00:04:13,040
that it's the standard way to monitor

00:04:10,640 --> 00:04:13,760
kubernetes environments so if you are

00:04:13,040 --> 00:04:17,199
deploying

00:04:13,760 --> 00:04:19,919
your workloads on kubernetes

00:04:17,199 --> 00:04:21,359
the two really go hand in hand uh in

00:04:19,919 --> 00:04:22,639
fact prometheus is

00:04:21,359 --> 00:04:25,759
depending on how you measure it the

00:04:22,639 --> 00:04:28,720
second most popular project at the cncf

00:04:25,759 --> 00:04:29,919
behind kubernetes itself so and you can

00:04:28,720 --> 00:04:32,800
see some of the

00:04:29,919 --> 00:04:34,720
uh they call it velocity this is

00:04:32,800 --> 00:04:37,360
actually these stats are taken from

00:04:34,720 --> 00:04:38,479
a report that the cncf put out almost a

00:04:37,360 --> 00:04:40,560
year ago

00:04:38,479 --> 00:04:41,759
but so these trends have continued to go

00:04:40,560 --> 00:04:44,000
up since then

00:04:41,759 --> 00:04:45,520
but it shows the velocity and the way

00:04:44,000 --> 00:04:47,680
they measure velocity of a particular

00:04:45,520 --> 00:04:48,400
project is by combining the number of

00:04:47,680 --> 00:04:49,759
commits

00:04:48,400 --> 00:04:51,919
the number of pull requests the number

00:04:49,759 --> 00:04:54,560
of issues and the number of authors

00:04:51,919 --> 00:04:56,720
and by that they can take a stab at

00:04:54,560 --> 00:04:59,280
judging the health of the project

00:04:56,720 --> 00:05:00,880
and so you can see that not only is it

00:04:59,280 --> 00:05:01,759
the second most popular project but it's

00:05:00,880 --> 00:05:04,639
also

00:05:01,759 --> 00:05:05,440
growing uh in not only popularity but

00:05:04,639 --> 00:05:07,600
also in

00:05:05,440 --> 00:05:08,960
the number of contributions that are

00:05:07,600 --> 00:05:10,800
happening in the

00:05:08,960 --> 00:05:12,240
prometheus the various prometheus

00:05:10,800 --> 00:05:12,880
projects there's actually more than one

00:05:12,240 --> 00:05:15,840
obviously

00:05:12,880 --> 00:05:15,840
if you look at github

00:05:15,919 --> 00:05:18,720
uh now we also just to level set again

00:05:17,600 --> 00:05:20,639
we need to talk about what is an

00:05:18,720 --> 00:05:23,199
exporter if you're not familiar so

00:05:20,639 --> 00:05:24,880
uh exporters are for as i mentioned

00:05:23,199 --> 00:05:26,880
third-party applications

00:05:24,880 --> 00:05:28,639
that don't expose prometheus metrics

00:05:26,880 --> 00:05:29,759
natively there are some applications out

00:05:28,639 --> 00:05:32,560
there that do

00:05:29,759 --> 00:05:33,440
or at least have that option um but many

00:05:32,560 --> 00:05:36,000
of them don't

00:05:33,440 --> 00:05:38,000
and it can be difficult for a maintainer

00:05:36,000 --> 00:05:40,479
of a large project to

00:05:38,000 --> 00:05:41,680
add uh prometheus instrumentation into

00:05:40,479 --> 00:05:43,039
their project and so

00:05:41,680 --> 00:05:44,880
what's happened in the community is the

00:05:43,039 --> 00:05:46,960
community has come together and said

00:05:44,880 --> 00:05:48,880
we're going to develop these exporters

00:05:46,960 --> 00:05:49,840
that will allow us to convert the

00:05:48,880 --> 00:05:51,120
metrics

00:05:49,840 --> 00:05:52,960
uh that we're pulling out of a

00:05:51,120 --> 00:05:54,479
particular application into a format

00:05:52,960 --> 00:05:55,840
that prometheus understands

00:05:54,479 --> 00:05:57,680
so that i can get all those metrics

00:05:55,840 --> 00:05:58,400
hopefully in one place to better analyze

00:05:57,680 --> 00:06:00,560
them

00:05:58,400 --> 00:06:02,720
as i mentioned if you're coding your own

00:06:00,560 --> 00:06:04,960
application of bespoke application

00:06:02,720 --> 00:06:06,000
you can do direct instrumentation with

00:06:04,960 --> 00:06:07,840
prometheus there

00:06:06,000 --> 00:06:09,280
so you don't necessarily need an

00:06:07,840 --> 00:06:12,160
exporter but

00:06:09,280 --> 00:06:14,000
for third-party applications in most

00:06:12,160 --> 00:06:14,800
cases you will need an exporter in order

00:06:14,000 --> 00:06:18,319
to get those

00:06:14,800 --> 00:06:18,319
metrics out of those applications

00:06:18,400 --> 00:06:21,759
all right so let's jump into the five

00:06:19,840 --> 00:06:22,800
best practices now that we all are on

00:06:21,759 --> 00:06:25,199
the same page

00:06:22,800 --> 00:06:27,039
so the first best practice is finding

00:06:25,199 --> 00:06:29,039
the right exporter how do you do that

00:06:27,039 --> 00:06:30,720
what's the most efficient way

00:06:29,039 --> 00:06:32,479
understanding the metrics that are

00:06:30,720 --> 00:06:33,919
coming out of a particular exporter that

00:06:32,479 --> 00:06:36,479
you choose

00:06:33,919 --> 00:06:37,759
being able to set alerts that are

00:06:36,479 --> 00:06:39,600
significant

00:06:37,759 --> 00:06:41,199
enabling your team to use the data that

00:06:39,600 --> 00:06:42,720
you're pulling when you're using

00:06:41,199 --> 00:06:45,360
prometheus exporters

00:06:42,720 --> 00:06:47,360
and then also having a plan for scale

00:06:45,360 --> 00:06:49,360
for prometheus as you implement

00:06:47,360 --> 00:06:50,800
exporters so we'll talk about why all

00:06:49,360 --> 00:06:51,759
those things are important or why i

00:06:50,800 --> 00:06:53,280
think they're important

00:06:51,759 --> 00:06:55,120
there may be other things that you feel

00:06:53,280 --> 00:06:56,639
that are added to the to this list or

00:06:55,120 --> 00:06:57,599
should be considered and if that's the

00:06:56,639 --> 00:06:59,120
case

00:06:57,599 --> 00:07:01,039
go ahead and either put them in the chat

00:06:59,120 --> 00:07:02,960
or let me know via a question and we can

00:07:01,039 --> 00:07:04,319
talk about those

00:07:02,960 --> 00:07:06,560
at the end of the presentation i'd love

00:07:04,319 --> 00:07:07,759
to hear your thoughts

00:07:06,560 --> 00:07:10,319
but let's go ahead and walk through

00:07:07,759 --> 00:07:11,840
these now um and these are things again

00:07:10,319 --> 00:07:13,680
they're not specific to cystic but i

00:07:11,840 --> 00:07:14,960
will be using some cystic examples as we

00:07:13,680 --> 00:07:17,759
go through

00:07:14,960 --> 00:07:19,199
so uh where do you find exporters

00:07:17,759 --> 00:07:21,840
generally finding exporters

00:07:19,199 --> 00:07:23,680
isn't necessarily the problem you can do

00:07:21,840 --> 00:07:24,720
a google search and find an exporter but

00:07:23,680 --> 00:07:27,919
what you may find

00:07:24,720 --> 00:07:31,039
is uh that there are multiple exporters

00:07:27,919 --> 00:07:32,800
so you do a google search for uh aws

00:07:31,039 --> 00:07:33,680
cloudwatch for example you'll find five

00:07:32,800 --> 00:07:35,039
or six

00:07:33,680 --> 00:07:36,720
exporters that have been written over

00:07:35,039 --> 00:07:39,039
time the question isn't finding the

00:07:36,720 --> 00:07:40,639
exporter it's choosing the right one

00:07:39,039 --> 00:07:42,400
here are some places that you could look

00:07:40,639 --> 00:07:43,120
to get an indication for which one to

00:07:42,400 --> 00:07:45,599
choose

00:07:43,120 --> 00:07:46,240
there's the the first link on the page

00:07:45,599 --> 00:07:49,520
is the

00:07:46,240 --> 00:07:51,199
prometheus project documentation itself

00:07:49,520 --> 00:07:52,479
and they try to capture all of those

00:07:51,199 --> 00:07:52,960
there it's a little bit of the kitchen

00:07:52,479 --> 00:07:54,879
sink

00:07:52,960 --> 00:07:57,520
model but you can get a good idea for

00:07:54,879 --> 00:07:59,440
what exporters are out there

00:07:57,520 --> 00:08:01,599
another interesting place to check is

00:07:59,440 --> 00:08:03,520
the uh this wiki page

00:08:01,599 --> 00:08:05,680
which lists the prometheus default port

00:08:03,520 --> 00:08:07,440
allocations and by looking at the

00:08:05,680 --> 00:08:08,960
the various ports the default ports for

00:08:07,440 --> 00:08:12,240
particular applications you can find

00:08:08,960 --> 00:08:12,240
exporters there as well

00:08:12,479 --> 00:08:16,479
and since it's on a wiki page you can

00:08:14,879 --> 00:08:18,000
actually add exporters there over time

00:08:16,479 --> 00:08:20,319
really easily

00:08:18,000 --> 00:08:22,240
another place i'll talk about more is

00:08:20,319 --> 00:08:23,919
the promcat.io

00:08:22,240 --> 00:08:25,280
this is a separate website it is

00:08:23,919 --> 00:08:27,680
maintained by systig and we have

00:08:25,280 --> 00:08:29,280
engineers working on this

00:08:27,680 --> 00:08:31,840
but i'll talk about that let's actually

00:08:29,280 --> 00:08:33,279
just jump in and talk about

00:08:31,840 --> 00:08:35,599
prom cat real quick and i'll go back

00:08:33,279 --> 00:08:38,080
since we're on the topic so

00:08:35,599 --> 00:08:39,200
promcat as i mentioned is a is a

00:08:38,080 --> 00:08:42,399
separate website from

00:08:39,200 --> 00:08:45,519
cystic.com it is for the community

00:08:42,399 --> 00:08:47,040
but the issue that we're trying to solve

00:08:45,519 --> 00:08:48,399
with it is that we heard from a lot of

00:08:47,040 --> 00:08:50,320
customers over time

00:08:48,399 --> 00:08:52,160
when they go to try to choose an

00:08:50,320 --> 00:08:54,000
exporter they are spending way too much

00:08:52,160 --> 00:08:55,519
time in the maintenance process the

00:08:54,000 --> 00:08:58,880
selection process

00:08:55,519 --> 00:09:00,560
um the configuration process

00:08:58,880 --> 00:09:02,240
because all of these are most of these

00:09:00,560 --> 00:09:04,399
are github projects some of them come

00:09:02,240 --> 00:09:07,839
with better documentation than others

00:09:04,399 --> 00:09:09,279
and so what we wanted to do was create a

00:09:07,839 --> 00:09:10,000
resource for the community that they

00:09:09,279 --> 00:09:11,440
could go in

00:09:10,000 --> 00:09:13,360
and find all of those things i just

00:09:11,440 --> 00:09:16,640
mentioned in one place

00:09:13,360 --> 00:09:18,160
so we curate uh exporters we try to pick

00:09:16,640 --> 00:09:18,880
the best one that most of our customers

00:09:18,160 --> 00:09:21,120
tell us

00:09:18,880 --> 00:09:22,480
is working and is working well if it's

00:09:21,120 --> 00:09:23,920
not working if it needs a little

00:09:22,480 --> 00:09:24,399
adjustment or if there's issues that

00:09:23,920 --> 00:09:26,080
that

00:09:24,399 --> 00:09:27,519
perhaps need to be addressed our

00:09:26,080 --> 00:09:29,200
developers will actually go in and help

00:09:27,519 --> 00:09:30,640
that open source project resolve those

00:09:29,200 --> 00:09:32,000
issues if they can

00:09:30,640 --> 00:09:33,600
and then they'll augment the

00:09:32,000 --> 00:09:34,640
documentation with configuration

00:09:33,600 --> 00:09:36,640
information

00:09:34,640 --> 00:09:38,240
and dashboards and alerts and i'll show

00:09:36,640 --> 00:09:40,160
you an example of those if there's time

00:09:38,240 --> 00:09:42,399
at the end

00:09:40,160 --> 00:09:44,080
but if you're not using promcat how do

00:09:42,399 --> 00:09:46,080
you know if the exporter that you have

00:09:44,080 --> 00:09:47,279
is right for your needs well

00:09:46,080 --> 00:09:49,120
there's a couple different things that i

00:09:47,279 --> 00:09:51,200
would recommend looking at

00:09:49,120 --> 00:09:52,800
one is go to the github page see how

00:09:51,200 --> 00:09:54,160
many stars it has

00:09:52,800 --> 00:09:55,920
how many issues it has how many

00:09:54,160 --> 00:09:56,720
contributors it has just like we

00:09:55,920 --> 00:09:59,519
mentioned with

00:09:56,720 --> 00:10:01,920
cncf how they do that velocity metric

00:09:59,519 --> 00:10:04,560
you can use those same indicators to see

00:10:01,920 --> 00:10:05,760
is this exporter a good exporter to have

00:10:04,560 --> 00:10:08,800
um

00:10:05,760 --> 00:10:10,800
is this a particular exporter led by a

00:10:08,800 --> 00:10:12,079
company or an individual or hopefully a

00:10:10,800 --> 00:10:13,680
set of contributors

00:10:12,079 --> 00:10:15,200
so that everybody is putting in their

00:10:13,680 --> 00:10:16,800
two cents so to speak and

00:10:15,200 --> 00:10:18,560
working on features that are important

00:10:16,800 --> 00:10:21,040
to the actual users

00:10:18,560 --> 00:10:22,480
of that exporter how long has the

00:10:21,040 --> 00:10:25,680
development been going on for

00:10:22,480 --> 00:10:29,040
also when you know has is it still under

00:10:25,680 --> 00:10:30,480
current development i guess i would say

00:10:29,040 --> 00:10:32,000
hard-coded deployment specific

00:10:30,480 --> 00:10:33,200
assumptions those can be difficult

00:10:32,000 --> 00:10:35,279
because

00:10:33,200 --> 00:10:37,040
if i'm writing an exporter form for an

00:10:35,279 --> 00:10:38,640
application in my environment

00:10:37,040 --> 00:10:40,000
then i'm taking my environment into

00:10:38,640 --> 00:10:41,200
consideration that may be different than

00:10:40,000 --> 00:10:43,680
your environment

00:10:41,200 --> 00:10:44,959
so it's important to know is the has

00:10:43,680 --> 00:10:47,760
this been coded

00:10:44,959 --> 00:10:51,360
well enough to be flexible for various

00:10:47,760 --> 00:10:51,360
uh situations that may occur

00:10:51,600 --> 00:10:54,399
and then of course is anybody actually

00:10:53,200 --> 00:10:56,240
looking at the issues take a look at the

00:10:54,399 --> 00:10:57,920
issues page and just see

00:10:56,240 --> 00:11:00,640
are issues being fixed is there just got

00:10:57,920 --> 00:11:02,160
good discussion happening are people

00:11:00,640 --> 00:11:04,320
posting examples of issues when they

00:11:02,160 --> 00:11:05,920
happen what's going on etc

00:11:04,320 --> 00:11:08,399
so those are some ways that you can try

00:11:05,920 --> 00:11:10,640
to figure out which exporter might be

00:11:08,399 --> 00:11:14,800
one that's active and worth pursuing in

00:11:10,640 --> 00:11:17,360
your environment

00:11:14,800 --> 00:11:19,040
the next best practice is taking a look

00:11:17,360 --> 00:11:20,880
at the metrics that are coming out of

00:11:19,040 --> 00:11:22,640
the exporter and trying to understand

00:11:20,880 --> 00:11:24,720
how they fit in your environment

00:11:22,640 --> 00:11:26,959
one easy way to do that is by taking a

00:11:24,720 --> 00:11:29,440
look at the project page project pages

00:11:26,959 --> 00:11:30,480
are encouraged by prometheus the

00:11:29,440 --> 00:11:34,160
prometheus team

00:11:30,480 --> 00:11:36,079
to be explicit in the

00:11:34,160 --> 00:11:37,680
types of metrics they're collecting the

00:11:36,079 --> 00:11:38,399
cardinality of those metrics in other

00:11:37,680 --> 00:11:42,079
words how many

00:11:38,399 --> 00:11:44,160
um bits of information am i going to get

00:11:42,079 --> 00:11:46,640
back from that particular metric

00:11:44,160 --> 00:11:48,480
if i'm um checking for it and then what

00:11:46,640 --> 00:11:49,040
does that particular metric do what does

00:11:48,480 --> 00:11:50,880
it measure

00:11:49,040 --> 00:11:52,720
be specific about what it's doing so

00:11:50,880 --> 00:11:54,240
that you can understand

00:11:52,720 --> 00:11:56,240
uh what the metric is doing and whether

00:11:54,240 --> 00:11:58,399
it's important to you or not

00:11:56,240 --> 00:11:59,920
the other thing that i would add to this

00:11:58,399 --> 00:12:02,800
is to make sure that you're using

00:11:59,920 --> 00:12:04,240
labels some people call these instance

00:12:02,800 --> 00:12:06,240
labels some people call them target

00:12:04,240 --> 00:12:09,200
labels

00:12:06,240 --> 00:12:09,680
both are important instance labels would

00:12:09,200 --> 00:12:11,839
be

00:12:09,680 --> 00:12:12,800
things about the particular application

00:12:11,839 --> 00:12:15,120
itself

00:12:12,800 --> 00:12:16,800
uh some singular feature that's

00:12:15,120 --> 00:12:18,480
important and a target label would be

00:12:16,800 --> 00:12:20,720
something more generic like

00:12:18,480 --> 00:12:22,000
uh what region that application is

00:12:20,720 --> 00:12:24,240
running in or

00:12:22,000 --> 00:12:25,600
is this production or development and

00:12:24,240 --> 00:12:27,120
that can help you later when you're

00:12:25,600 --> 00:12:28,800
going to analyze your metrics

00:12:27,120 --> 00:12:30,480
you'll be able to narrow down your focus

00:12:28,800 --> 00:12:31,360
on just the environment that's important

00:12:30,480 --> 00:12:34,079
for you

00:12:31,360 --> 00:12:35,519
your particular devops team and so using

00:12:34,079 --> 00:12:39,040
labels

00:12:35,519 --> 00:12:41,440
uh in this way adding labels to your uh

00:12:39,040 --> 00:12:42,320
exporter definition is really important

00:12:41,440 --> 00:12:44,000
so that you can

00:12:42,320 --> 00:12:45,839
go back later and save a lot of time so

00:12:44,000 --> 00:12:47,040
that you're not confusing things in your

00:12:45,839 --> 00:12:47,760
environment make sure you're looking at

00:12:47,040 --> 00:12:49,360
the right

00:12:47,760 --> 00:12:50,639
entity when you go if you do have a

00:12:49,360 --> 00:12:53,839
problem and you're trying to figure out

00:12:50,639 --> 00:12:53,839
what's going on

00:12:54,560 --> 00:12:58,000
another thing that's important is

00:12:57,120 --> 00:13:00,079
alerting

00:12:58,000 --> 00:13:01,600
so what typically happens in these

00:13:00,079 --> 00:13:03,360
environments is that when you get

00:13:01,600 --> 00:13:04,560
started using exporters it opens up the

00:13:03,360 --> 00:13:06,800
possibility

00:13:04,560 --> 00:13:08,160
for alerting on a lot of interesting

00:13:06,800 --> 00:13:10,240
data that's coming in

00:13:08,160 --> 00:13:12,000
through these prometheus exporters and

00:13:10,240 --> 00:13:14,800
what we always encourage people to do

00:13:12,000 --> 00:13:16,160
is use the golden signal methodology

00:13:14,800 --> 00:13:18,560
that was put forward

00:13:16,160 --> 00:13:20,240
uh in lots of places but in part in the

00:13:18,560 --> 00:13:23,680
google sre handbook

00:13:20,240 --> 00:13:25,519
to try to get a handle on

00:13:23,680 --> 00:13:26,800
you know if i've got 10 000 different

00:13:25,519 --> 00:13:29,040
metrics coming in which ones are

00:13:26,800 --> 00:13:31,120
important and what's the threshold for

00:13:29,040 --> 00:13:32,720
something that should be considered

00:13:31,120 --> 00:13:34,320
something i need to go look into

00:13:32,720 --> 00:13:36,480
that might be a service level indicator

00:13:34,320 --> 00:13:39,040
for example

00:13:36,480 --> 00:13:41,120
or something that just happens all the

00:13:39,040 --> 00:13:44,399
time and isn't really a problem

00:13:41,120 --> 00:13:45,199
so being able to take a look at these

00:13:44,399 --> 00:13:49,040
four things

00:13:45,199 --> 00:13:52,000
traffic latency errors and saturation

00:13:49,040 --> 00:13:52,800
um and setting alerts on those as

00:13:52,000 --> 00:13:55,839
opposed to

00:13:52,800 --> 00:13:57,440
any you know any random type of signal

00:13:55,839 --> 00:13:59,440
that's happening in your environment

00:13:57,440 --> 00:14:00,800
a good example that i came across

00:13:59,440 --> 00:14:01,440
recently that you might want to check

00:14:00,800 --> 00:14:04,320
out is

00:14:01,440 --> 00:14:06,000
awesome prometheus alerts and you can

00:14:04,320 --> 00:14:07,040
find the url at the bottom of the page

00:14:06,000 --> 00:14:08,560
there

00:14:07,040 --> 00:14:10,480
if you're new to setting alerts in

00:14:08,560 --> 00:14:12,240
prometheus this is a great way to

00:14:10,480 --> 00:14:13,440
actually go in and get some examples to

00:14:12,240 --> 00:14:14,880
see

00:14:13,440 --> 00:14:16,320
what other people are doing what other

00:14:14,880 --> 00:14:18,240
people have suggested is important to

00:14:16,320 --> 00:14:19,680
alert on for a given environment so i'd

00:14:18,240 --> 00:14:20,320
highly recommend you if you're new

00:14:19,680 --> 00:14:22,639
especially

00:14:20,320 --> 00:14:24,000
or even if if you're not new take a look

00:14:22,639 --> 00:14:25,519
at that page because there's a lot of

00:14:24,000 --> 00:14:26,639
really great examples that may be an eye

00:14:25,519 --> 00:14:28,480
opener and to something

00:14:26,639 --> 00:14:30,160
that you should be taking a look at or

00:14:28,480 --> 00:14:32,560
setting an alert on that that you're not

00:14:30,160 --> 00:14:32,560
currently

00:14:33,519 --> 00:14:37,199
um i also mentioned setting alerts that

00:14:35,360 --> 00:14:38,560
are actionable and what does that mean

00:14:37,199 --> 00:14:40,959
well

00:14:38,560 --> 00:14:41,920
if you've been in a support role at any

00:14:40,959 --> 00:14:44,240
given point in time

00:14:41,920 --> 00:14:47,519
you've probably had more than one

00:14:44,240 --> 00:14:49,519
instance where you had an alert storm

00:14:47,519 --> 00:14:51,199
or you just had so many alerts coming in

00:14:49,519 --> 00:14:54,079
so frequently on a given

00:14:51,199 --> 00:14:56,000
topic that you start ignoring them oh

00:14:54,079 --> 00:14:59,360
it's just another alert

00:14:56,000 --> 00:15:00,800
for xyz application this happens all the

00:14:59,360 --> 00:15:02,720
time i'm not going to take a look

00:15:00,800 --> 00:15:04,639
what you might not know is that that one

00:15:02,720 --> 00:15:06,399
time that it comes in is actually

00:15:04,639 --> 00:15:07,680
something that's impacting customers or

00:15:06,399 --> 00:15:08,639
revenue so you really should pay

00:15:07,680 --> 00:15:11,360
attention to it

00:15:08,639 --> 00:15:12,000
so this is an important topic also

00:15:11,360 --> 00:15:13,519
important we talked

00:15:12,000 --> 00:15:15,839
about golden signals but also important

00:15:13,519 --> 00:15:19,199
is to be able to alert on symptoms

00:15:15,839 --> 00:15:20,880
and not causes so for example you may

00:15:19,199 --> 00:15:24,320
have a situation where

00:15:20,880 --> 00:15:26,480
there's a cpu spike or high cpu

00:15:24,320 --> 00:15:28,000
happening on your system well that could

00:15:26,480 --> 00:15:29,759
be important to know

00:15:28,000 --> 00:15:31,759
what's even more important is what's

00:15:29,759 --> 00:15:32,880
causing that particular high cpu load in

00:15:31,759 --> 00:15:34,720
your environment

00:15:32,880 --> 00:15:36,079
so this is where prometheus exporters

00:15:34,720 --> 00:15:37,120
can really play a big part in

00:15:36,079 --> 00:15:38,399
understanding

00:15:37,120 --> 00:15:40,560
all those various metrics for a

00:15:38,399 --> 00:15:41,920
particular application and which one is

00:15:40,560 --> 00:15:44,720
going beyond

00:15:41,920 --> 00:15:46,079
normal to cause that cpu problem and

00:15:44,720 --> 00:15:47,759
that will certainly help

00:15:46,079 --> 00:15:51,519
reduce the amount of time it takes to go

00:15:47,759 --> 00:15:51,519
in and fix that particular problem as

00:15:52,839 --> 00:15:57,040
well

00:15:54,880 --> 00:15:58,480
so this is an interesting one uh as far

00:15:57,040 --> 00:16:00,320
as the best practice goes but it should

00:15:58,480 --> 00:16:02,720
be intuitive to people that work in

00:16:00,320 --> 00:16:04,320
larger organizations or efficient

00:16:02,720 --> 00:16:08,880
smaller organizations which is

00:16:04,320 --> 00:16:10,560
enable your teams um doing things like

00:16:08,880 --> 00:16:13,279
creating dashboard templates

00:16:10,560 --> 00:16:14,800
uh to share with your team so that when

00:16:13,279 --> 00:16:16,160
a new person comes on board and they're

00:16:14,800 --> 00:16:17,360
asked to create a dashboard for their

00:16:16,160 --> 00:16:19,279
particular application

00:16:17,360 --> 00:16:20,959
they have an example to go look at of

00:16:19,279 --> 00:16:23,680
something that's been done previous

00:16:20,959 --> 00:16:24,959
so they don't have to reinvent the wheel

00:16:23,680 --> 00:16:27,120
one of the things that we do

00:16:24,959 --> 00:16:28,399
within systig is we take the feedback we

00:16:27,120 --> 00:16:30,240
get from our customers

00:16:28,399 --> 00:16:31,680
and we're always creating new dashboard

00:16:30,240 --> 00:16:33,759
templates in the product

00:16:31,680 --> 00:16:35,120
that are based on that real world real

00:16:33,759 --> 00:16:38,480
rear but a

00:16:35,120 --> 00:16:40,880
real world example um

00:16:38,480 --> 00:16:43,360
that for example here you can see the

00:16:40,880 --> 00:16:45,040
kubernetes node overview for example

00:16:43,360 --> 00:16:46,399
what we did was we went out to customers

00:16:45,040 --> 00:16:47,759
we looked at what they were monitoring

00:16:46,399 --> 00:16:49,279
and why they were monitoring it

00:16:47,759 --> 00:16:51,040
and then we created a template so that

00:16:49,279 --> 00:16:52,160
any users of system once they get the

00:16:51,040 --> 00:16:54,160
agent installed

00:16:52,160 --> 00:16:56,240
can go ahead and pull this up and take a

00:16:54,160 --> 00:16:57,440
look at this information and if i was a

00:16:56,240 --> 00:17:00,160
new user of

00:16:57,440 --> 00:17:01,600
kubernetes maybe i was new to a team or

00:17:00,160 --> 00:17:02,240
maybe i was a developer that didn't have

00:17:01,600 --> 00:17:05,280
to work in

00:17:02,240 --> 00:17:06,880
ops necessarily all the time but

00:17:05,280 --> 00:17:08,160
i did want to understand take a look at

00:17:06,880 --> 00:17:08,640
that dashboard and understand what it

00:17:08,160 --> 00:17:10,480
means

00:17:08,640 --> 00:17:12,160
this can be incredibly useful and time

00:17:10,480 --> 00:17:14,160
saving you can see some of the

00:17:12,160 --> 00:17:14,799
information that we put in is not only

00:17:14,160 --> 00:17:16,319
just

00:17:14,799 --> 00:17:18,799
having a template itself but also

00:17:16,319 --> 00:17:20,480
explaining for example in a text field

00:17:18,799 --> 00:17:22,160
just like you would if you were coding

00:17:20,480 --> 00:17:23,600
in a comment you would use a comment to

00:17:22,160 --> 00:17:25,360
explain what what this is

00:17:23,600 --> 00:17:26,720
what's going on so that other people

00:17:25,360 --> 00:17:28,559
that can come after you

00:17:26,720 --> 00:17:30,080
and take a look at it we do the same

00:17:28,559 --> 00:17:31,679
thing at cystic and we encourage

00:17:30,080 --> 00:17:33,200
everyone to do that in the templates

00:17:31,679 --> 00:17:35,120
if they're creating a template for their

00:17:33,200 --> 00:17:37,760
team

00:17:35,120 --> 00:17:39,039
um also uh a best practice that we're

00:17:37,760 --> 00:17:41,039
seeing more and more of from our

00:17:39,039 --> 00:17:43,679
customers is using git to store

00:17:41,039 --> 00:17:45,039
configs as a repository for configs and

00:17:43,679 --> 00:17:47,520
not just for code

00:17:45,039 --> 00:17:50,320
so in doing that you can enable your

00:17:47,520 --> 00:17:52,799
team to take part in a safe way

00:17:50,320 --> 00:17:54,080
and edit configurations have them

00:17:52,799 --> 00:17:55,600
visible for everybody

00:17:54,080 --> 00:17:56,960
but also have them be able to edit and

00:17:55,600 --> 00:17:57,760
make changes and have those changes

00:17:56,960 --> 00:17:59,520
reviewed

00:17:57,760 --> 00:18:01,200
before they're implemented and then it

00:17:59,520 --> 00:18:03,679
also is just an easy place to go

00:18:01,200 --> 00:18:05,039
and find uh the config that you need

00:18:03,679 --> 00:18:06,080
when you're setting up the architecture

00:18:05,039 --> 00:18:08,080
for your particular

00:18:06,080 --> 00:18:10,480
workload you want to go deploy a

00:18:08,080 --> 00:18:11,600
prometheus exporter for example

00:18:10,480 --> 00:18:13,440
it would be great to have your

00:18:11,600 --> 00:18:14,480
particular configuration information

00:18:13,440 --> 00:18:16,320
stored in git

00:18:14,480 --> 00:18:19,120
where it can be changed in a responsible

00:18:16,320 --> 00:18:19,120
way over time

00:18:21,120 --> 00:18:25,600
so enterprise ready access controls is

00:18:23,760 --> 00:18:29,280
another way to

00:18:25,600 --> 00:18:30,960
both enable a team or not enable a team

00:18:29,280 --> 00:18:33,039
as the case may be and there may be some

00:18:30,960 --> 00:18:34,480
circumstances where you want to do that

00:18:33,039 --> 00:18:37,120
so for example

00:18:34,480 --> 00:18:38,320
you may have a team that just for sake

00:18:37,120 --> 00:18:40,240
of efficiency

00:18:38,320 --> 00:18:41,840
only needs to see their particular

00:18:40,240 --> 00:18:42,720
environment they don't need the kitchen

00:18:41,840 --> 00:18:44,880
sink approach

00:18:42,720 --> 00:18:45,840
they just need to see the applications

00:18:44,880 --> 00:18:48,960
uh and

00:18:45,840 --> 00:18:50,480
um infrastructure that's particular to

00:18:48,960 --> 00:18:52,640
them and what they're working on

00:18:50,480 --> 00:18:55,600
and so one of the tools we have at

00:18:52,640 --> 00:18:58,880
systig is the ability to tie in

00:18:55,600 --> 00:19:00,720
our back access controls into sso

00:18:58,880 --> 00:19:02,320
and ldap and things so that an

00:19:00,720 --> 00:19:03,600
administrator of a monitoring platform

00:19:02,320 --> 00:19:06,480
can come in and say

00:19:03,600 --> 00:19:07,200
look this is the payments team for

00:19:06,480 --> 00:19:08,880
example

00:19:07,200 --> 00:19:10,960
they really only need to see payment

00:19:08,880 --> 00:19:12,640
stuff by default

00:19:10,960 --> 00:19:13,919
and that way they're not worried about

00:19:12,640 --> 00:19:14,400
you know when they go to look up a

00:19:13,919 --> 00:19:15,919
problem

00:19:14,400 --> 00:19:17,919
are they getting mixed signals because

00:19:15,919 --> 00:19:19,440
of other things that they're able to see

00:19:17,919 --> 00:19:20,960
they can really fine-tune it down to

00:19:19,440 --> 00:19:22,880
their particular environment

00:19:20,960 --> 00:19:25,679
the other thing that may come in is of

00:19:22,880 --> 00:19:27,280
course compliance regulations

00:19:25,679 --> 00:19:30,240
things like that where if you're

00:19:27,280 --> 00:19:32,000
managing a shopping application

00:19:30,240 --> 00:19:33,360
credit card information flowing in or

00:19:32,000 --> 00:19:35,280
sensitive information

00:19:33,360 --> 00:19:36,880
you obviously need to be able to control

00:19:35,280 --> 00:19:40,720
who sees that information

00:19:36,880 --> 00:19:45,039
and so by having a system

00:19:40,720 --> 00:19:49,840
in place that can actually limit the um

00:19:45,039 --> 00:19:51,440
the data that various teams can see

00:19:49,840 --> 00:19:53,360
is really really important especially as

00:19:51,440 --> 00:19:55,200
you start deploying more and more

00:19:53,360 --> 00:19:56,480
of these prometheus exporters in your

00:19:55,200 --> 00:19:57,760
environment that are pulling in all

00:19:56,480 --> 00:19:59,520
sorts of information

00:19:57,760 --> 00:20:02,080
that may or may not be appropriate for

00:19:59,520 --> 00:20:02,080
people to see

00:20:02,960 --> 00:20:06,000
now let's talk a little bit about the

00:20:05,120 --> 00:20:07,760
the last

00:20:06,000 --> 00:20:10,159
best practice which is have a plan for

00:20:07,760 --> 00:20:10,799
scale why do you need to have a plan for

00:20:10,159 --> 00:20:14,080
skill

00:20:10,799 --> 00:20:17,120
well uh in in in way of telling this

00:20:14,080 --> 00:20:17,919
i'll use a story uh methodology here or

00:20:17,120 --> 00:20:20,000
a typical

00:20:17,919 --> 00:20:21,840
journey that you might take as you're

00:20:20,000 --> 00:20:22,799
deploying prometheus and prometheus

00:20:21,840 --> 00:20:25,039
exporters

00:20:22,799 --> 00:20:27,679
typically the way that most development

00:20:25,039 --> 00:20:29,679
teams or devops teams start out

00:20:27,679 --> 00:20:31,039
is you know they first they stand up an

00:20:29,679 --> 00:20:32,480
environment on kubernetes

00:20:31,039 --> 00:20:34,080
need to find a way to monitor it they

00:20:32,480 --> 00:20:35,679
have a little dev environment so they

00:20:34,080 --> 00:20:37,520
put prometheus out there

00:20:35,679 --> 00:20:39,039
and it's it works pretty well they get

00:20:37,520 --> 00:20:41,120
prometheus installed

00:20:39,039 --> 00:20:42,720
um perhaps they install grafana they get

00:20:41,120 --> 00:20:44,559
a dashboard up and working

00:20:42,720 --> 00:20:46,159
right away everybody's happy in the dev

00:20:44,559 --> 00:20:48,080
environment and

00:20:46,159 --> 00:20:49,760
then at some point they make a decision

00:20:48,080 --> 00:20:51,200
to after it's been running and tested

00:20:49,760 --> 00:20:53,039
and they're not having any issues

00:20:51,200 --> 00:20:54,480
uh it's running so well they want to

00:20:53,039 --> 00:20:57,760
roll that out into

00:20:54,480 --> 00:21:00,400
maybe a test environment uh or a prod

00:20:57,760 --> 00:21:02,400
environment eventually

00:21:00,400 --> 00:21:04,480
and and things are working great the

00:21:02,400 --> 00:21:06,240
only issue is that you start having a

00:21:04,480 --> 00:21:07,760
little bit of um

00:21:06,240 --> 00:21:09,600
uh distinction between these

00:21:07,760 --> 00:21:11,840
environments so now

00:21:09,600 --> 00:21:14,080
instead of just having one uh browser

00:21:11,840 --> 00:21:16,159
window up to go to my grafana

00:21:14,080 --> 00:21:17,840
for my dev environment uh you know i'm

00:21:16,159 --> 00:21:19,520
if i'm certainly if i'm a

00:21:17,840 --> 00:21:22,480
an sre or an ops person i'm going to

00:21:19,520 --> 00:21:24,640
have to have uh two or three of these up

00:21:22,480 --> 00:21:26,159
uh at the same time so that i can go

00:21:24,640 --> 00:21:27,360
take a look at these different

00:21:26,159 --> 00:21:28,480
environments and so now i'm switching

00:21:27,360 --> 00:21:30,080
back and forth

00:21:28,480 --> 00:21:32,480
don't necessarily have all the data in

00:21:30,080 --> 00:21:33,840
one place so it could be a little bit

00:21:32,480 --> 00:21:35,600
confusing

00:21:33,840 --> 00:21:37,280
but things are still working fine at

00:21:35,600 --> 00:21:38,960
this point

00:21:37,280 --> 00:21:40,880
and then you start rolling this out in a

00:21:38,960 --> 00:21:43,120
much bigger way and this is where some

00:21:40,880 --> 00:21:44,320
of the questions typically creep in

00:21:43,120 --> 00:21:46,960
for example what are you going to do

00:21:44,320 --> 00:21:48,960
with data retention when you're

00:21:46,960 --> 00:21:50,799
installing prometheus exporters they can

00:21:48,960 --> 00:21:54,400
expose

00:21:50,799 --> 00:21:56,080
tens of thousands of time series in your

00:21:54,400 --> 00:21:57,679
environment

00:21:56,080 --> 00:21:59,039
it varies based on the exporter that

00:21:57,679 --> 00:22:00,000
you're using in the environment that

00:21:59,039 --> 00:22:01,520
you're monitoring

00:22:00,000 --> 00:22:04,000
um but there can be a lot of data coming

00:22:01,520 --> 00:22:05,679
in and it can be difficult to store

00:22:04,000 --> 00:22:07,360
uh certainly it can be difficult to

00:22:05,679 --> 00:22:09,200
store for long term

00:22:07,360 --> 00:22:11,840
another thing is how do you scale that

00:22:09,200 --> 00:22:14,559
how do you keep your prometheus instance

00:22:11,840 --> 00:22:15,600
from uh becoming too large if that's a

00:22:14,559 --> 00:22:17,919
concern for you or

00:22:15,600 --> 00:22:18,640
running out of space or uh various other

00:22:17,919 --> 00:22:20,960
things

00:22:18,640 --> 00:22:22,320
um i mentioned unified query before the

00:22:20,960 --> 00:22:25,039
ability to

00:22:22,320 --> 00:22:26,080
take those you know dev prod user

00:22:25,039 --> 00:22:30,320
acceptance

00:22:26,080 --> 00:22:33,440
scale that up by 10x or 20x or 100x

00:22:30,320 --> 00:22:36,720
how do i then start to manage um

00:22:33,440 --> 00:22:38,400
having all of that data in one place

00:22:36,720 --> 00:22:40,080
and how does this affect my workflow is

00:22:38,400 --> 00:22:41,120
my workflow becoming more efficient or

00:22:40,080 --> 00:22:43,919
less efficient

00:22:41,120 --> 00:22:45,440
as i scale up my prometheus environment

00:22:43,919 --> 00:22:47,200
and so one of the ways that you can

00:22:45,440 --> 00:22:48,880
try to deal with this is by centralizing

00:22:47,200 --> 00:22:50,640
grafana so

00:22:48,880 --> 00:22:52,320
you can have one grafana instance or

00:22:50,640 --> 00:22:53,600
maybe a few grafana instances that are

00:22:52,320 --> 00:22:56,400
collecting all this data

00:22:53,600 --> 00:22:58,159
from your prometheus monitoring systems

00:22:56,400 --> 00:23:01,919
that will certainly cut down

00:22:58,159 --> 00:23:04,080
on um the

00:23:01,919 --> 00:23:05,919
the confusion but you still have an

00:23:04,080 --> 00:23:08,240
issue of how to store all that data

00:23:05,919 --> 00:23:10,000
so the way that prometheus typically

00:23:08,240 --> 00:23:13,039
scales

00:23:10,000 --> 00:23:14,240
is vertically but not necessarily

00:23:13,039 --> 00:23:16,960
horizontally

00:23:14,240 --> 00:23:18,640
so the way that you want this to scale

00:23:16,960 --> 00:23:21,360
in this kitten example is

00:23:18,640 --> 00:23:22,000
you start out with one prometheus server

00:23:21,360 --> 00:23:24,960
you want it to

00:23:22,000 --> 00:23:26,480
scale in the same way every time um

00:23:24,960 --> 00:23:27,760
horizontally and you want all of those

00:23:26,480 --> 00:23:28,799
instances to be able to talk to each

00:23:27,760 --> 00:23:30,960
other and look the same

00:23:28,799 --> 00:23:32,640
but what actually happens in practice is

00:23:30,960 --> 00:23:33,360
uh not that you have a bunch of

00:23:32,640 --> 00:23:36,159
different cats

00:23:33,360 --> 00:23:37,919
running around different colors and over

00:23:36,159 --> 00:23:39,440
time the configurations start to drift

00:23:37,919 --> 00:23:41,360
for that particular workload

00:23:39,440 --> 00:23:43,279
in that particular environment some of

00:23:41,360 --> 00:23:44,799
them have plenty of uh storage

00:23:43,279 --> 00:23:47,679
available to them to store all these

00:23:44,799 --> 00:23:50,159
metrics for long term some of them don't

00:23:47,679 --> 00:23:51,600
you may start running into memory issues

00:23:50,159 --> 00:23:53,039
which has always been a long time

00:23:51,600 --> 00:23:54,320
concern for the prometheus team they've

00:23:53,039 --> 00:23:56,240
done some great work

00:23:54,320 --> 00:23:57,360
on being able to scale memory for

00:23:56,240 --> 00:24:00,080
example but

00:23:57,360 --> 00:24:01,919
you still end up having these different

00:24:00,080 --> 00:24:03,360
systems and it can be confusing

00:24:01,919 --> 00:24:06,480
when you have lots of different cats

00:24:03,360 --> 00:24:08,400
running around so to speak

00:24:06,480 --> 00:24:09,919
one way we try to solve this at systig

00:24:08,400 --> 00:24:11,919
is by

00:24:09,919 --> 00:24:13,360
our back end is actually fully

00:24:11,919 --> 00:24:16,159
prometheus compatible

00:24:13,360 --> 00:24:18,159
so you can point your prometheus

00:24:16,159 --> 00:24:20,000
exporters for example if you will at the

00:24:18,159 --> 00:24:21,520
at our back end our agent will

00:24:20,000 --> 00:24:22,400
automatically scrape them and pull them

00:24:21,520 --> 00:24:24,080
in

00:24:22,400 --> 00:24:25,679
along with other metrics like system

00:24:24,080 --> 00:24:27,279
metrics network metrics

00:24:25,679 --> 00:24:28,880
uh metrics about your kubernetes

00:24:27,279 --> 00:24:31,919
environment

00:24:28,880 --> 00:24:32,720
statsd jmx custom metrics etc so we'll

00:24:31,919 --> 00:24:34,720
pull those in

00:24:32,720 --> 00:24:36,480
and we are able to provide a much larger

00:24:34,720 --> 00:24:38,880
storage and typically you would be able

00:24:36,480 --> 00:24:40,559
to do with a typical prometheus

00:24:38,880 --> 00:24:42,159
environment so you can consolidate all

00:24:40,559 --> 00:24:43,600
of those on our back end

00:24:42,159 --> 00:24:46,000
and then because we're compatible with

00:24:43,600 --> 00:24:47,440
prometheus you can use promql for

00:24:46,000 --> 00:24:49,200
example the same way you normally would

00:24:47,440 --> 00:24:51,360
in a grafana dashboard or in our

00:24:49,200 --> 00:24:53,760
dashboards in systick monitor

00:24:51,360 --> 00:24:55,360
you can export if you have an alert or

00:24:53,760 --> 00:24:56,799
that triggers for example

00:24:55,360 --> 00:24:58,480
you can export that information into

00:24:56,799 --> 00:25:02,320
pager due to your slack

00:24:58,480 --> 00:25:05,039
it just provides a a paid supported way

00:25:02,320 --> 00:25:06,159
to scale prometheus in your environment

00:25:05,039 --> 00:25:07,440
if you're at that point

00:25:06,159 --> 00:25:10,559
where you're experiencing some of those

00:25:07,440 --> 00:25:10,559
pains i mentioned before

00:25:12,480 --> 00:25:15,760
so let's take a look at some resources

00:25:14,559 --> 00:25:17,120
real quick and then i want to get to

00:25:15,760 --> 00:25:18,240
some questions if there are already

00:25:17,120 --> 00:25:19,760
and if there's still a little bit of

00:25:18,240 --> 00:25:20,720
time i'll show you some examples of what

00:25:19,760 --> 00:25:24,080
this looks like

00:25:20,720 --> 00:25:25,760
at least from a cystic perspective

00:25:24,080 --> 00:25:27,120
one of the things that i would mention

00:25:25,760 --> 00:25:29,200
if you are interested

00:25:27,120 --> 00:25:30,320
in following along with the development

00:25:29,200 --> 00:25:32,240
of prometheus

00:25:30,320 --> 00:25:34,159
or the development of prometheus

00:25:32,240 --> 00:25:37,279
integrations and how to deploy them

00:25:34,159 --> 00:25:39,279
is to take a look at systick.com blog so

00:25:37,279 --> 00:25:41,120
there's a number of uh there's a number

00:25:39,279 --> 00:25:42,480
there's a blog post that comes out you

00:25:41,120 --> 00:25:43,919
know almost daily

00:25:42,480 --> 00:25:45,440
about something about prometheus

00:25:43,919 --> 00:25:46,480
monitoring something about kubernetes

00:25:45,440 --> 00:25:48,960
monitoring

00:25:46,480 --> 00:25:50,400
we also have a secure product so lots of

00:25:48,960 --> 00:25:51,360
information right now going back and

00:25:50,400 --> 00:25:54,080
forth about

00:25:51,360 --> 00:25:54,400
um how to secure kubernetes environments

00:25:54,080 --> 00:25:56,159
um

00:25:54,400 --> 00:25:57,600
how to scan your images and that type of

00:25:56,159 --> 00:25:59,520
thing so if you're interested

00:25:57,600 --> 00:26:02,000
um in this space and would like a kind

00:25:59,520 --> 00:26:03,200
of a a regular update on what's going on

00:26:02,000 --> 00:26:03,840
i'd highly recommend checking out the

00:26:03,200 --> 00:26:05,520
blog

00:26:03,840 --> 00:26:07,600
i mentioned promcat already so i won't

00:26:05,520 --> 00:26:09,440
do that again but there's also a

00:26:07,600 --> 00:26:13,039
kubernetes monitoring guide

00:26:09,440 --> 00:26:14,559
that is available in the resources

00:26:13,039 --> 00:26:17,520
section on cystic.com

00:26:14,559 --> 00:26:19,360
it's about a 50-page guide i think and

00:26:17,520 --> 00:26:21,039
it goes into everything about kubernetes

00:26:19,360 --> 00:26:22,799
that you need to know what is kubernetes

00:26:21,039 --> 00:26:24,480
what is the control plane what are good

00:26:22,799 --> 00:26:25,760
alerts what's the best practices around

00:26:24,480 --> 00:26:28,320
monitoring kubernetes

00:26:25,760 --> 00:26:29,440
what are some examples of of deployments

00:26:28,320 --> 00:26:31,200
that you can

00:26:29,440 --> 00:26:32,640
pick up and use right away so if you're

00:26:31,200 --> 00:26:33,360
new to kubernetes or you just want to

00:26:32,640 --> 00:26:34,559
learn more

00:26:33,360 --> 00:26:36,480
i would highly recommend going and

00:26:34,559 --> 00:26:38,000
checking out that guide and just as a

00:26:36,480 --> 00:26:40,080
sneak peek we'll be deploying

00:26:38,000 --> 00:26:41,120
an updated prometheus monitoring guide

00:26:40,080 --> 00:26:42,960
as well uh

00:26:41,120 --> 00:26:44,880
in the coming uh month probably in

00:26:42,960 --> 00:26:47,679
november so be on the lookout for that

00:26:44,880 --> 00:26:47,679
resource as well

00:26:48,000 --> 00:26:53,039
uh you can also sign up for a free trial

00:26:49,840 --> 00:26:54,159
just a just a plug here for the system

00:26:53,039 --> 00:26:55,360
product

00:26:54,159 --> 00:26:57,039
you can see some of these things in

00:26:55,360 --> 00:26:58,000
action you can get a free 30-day trial

00:26:57,039 --> 00:26:59,600
so

00:26:58,000 --> 00:27:01,279
just a plug if you want to try it out

00:26:59,600 --> 00:27:02,159
there's no cost involved pick an

00:27:01,279 --> 00:27:03,440
environment

00:27:02,159 --> 00:27:05,600
install the agent maybe it's a dev

00:27:03,440 --> 00:27:07,200
environment install the agent and see

00:27:05,600 --> 00:27:09,039
if there's value that you get out of

00:27:07,200 --> 00:27:10,559
running systag monitor or assisting

00:27:09,039 --> 00:27:11,840
secure in your environment

00:27:10,559 --> 00:27:14,080
and you can see some of the things that

00:27:11,840 --> 00:27:15,760
i mentioned before actually in practice

00:27:14,080 --> 00:27:17,200
in your own environment it's a great way

00:27:15,760 --> 00:27:21,440
to check out the tool

00:27:17,200 --> 00:27:23,279
and see if it would be of use to you

00:27:21,440 --> 00:27:24,720
uh and also just a plug for our webinars

00:27:23,279 --> 00:27:26,159
here there's some good ones coming up

00:27:24,720 --> 00:27:28,000
the cards against containers if you're

00:27:26,159 --> 00:27:30,000
familiar with cards against humanity

00:27:28,000 --> 00:27:31,279
uh we developed a game called cards

00:27:30,000 --> 00:27:34,640
against containers

00:27:31,279 --> 00:27:36,880
and we'll be donating to feeding america

00:27:34,640 --> 00:27:38,320
for those people that attend so the more

00:27:36,880 --> 00:27:39,120
people that attend the more that cystic

00:27:38,320 --> 00:27:40,840
will donate

00:27:39,120 --> 00:27:42,240
to feeding america so go to

00:27:40,840 --> 00:27:43,840
cystic.webinars

00:27:42,240 --> 00:27:45,200
and check these out and definitely sign

00:27:43,840 --> 00:27:46,159
up for cards against containers it's a

00:27:45,200 --> 00:27:48,559
really fun game

00:27:46,159 --> 00:27:49,840
if you haven't played it um and it's

00:27:48,559 --> 00:27:51,360
kind of fun to see

00:27:49,840 --> 00:27:53,120
what it looks like when you put cards

00:27:51,360 --> 00:27:55,760
against humanity uh

00:27:53,120 --> 00:27:59,039
into a container paradigm uh what you

00:27:55,760 --> 00:28:00,960
can come up with it's pretty funny

00:27:59,039 --> 00:28:02,640
so i'm gonna pause there and see if

00:28:00,960 --> 00:28:04,240
there's any questions

00:28:02,640 --> 00:28:07,200
that i can answer quickly on the line

00:28:04,240 --> 00:28:07,200
and then i will

00:28:08,240 --> 00:28:16,559
jump into a quick demo but first let's

00:28:11,360 --> 00:28:20,480
see if there's any questions i'm not

00:28:16,559 --> 00:28:20,480
seeing any questions at this point

00:28:23,440 --> 00:28:26,799
so let me show you in that case let me

00:28:25,120 --> 00:28:30,000
show you some of the things that are

00:28:26,799 --> 00:28:32,559
in um let me pull up my

00:28:30,000 --> 00:28:32,559
chat here

00:28:37,760 --> 00:28:40,720
oh yeah i think i mentioned the first

00:28:39,120 --> 00:28:42,840
one so these questions are coming in in

00:28:40,720 --> 00:28:45,520
chat

00:28:42,840 --> 00:28:46,640
um are there best practices related to

00:28:45,520 --> 00:28:48,799
where

00:28:46,640 --> 00:28:50,559
where to host a prometheus scraper some

00:28:48,799 --> 00:28:52,240
people seem to advise

00:28:50,559 --> 00:28:53,840
using two servers and combining data

00:28:52,240 --> 00:28:56,240
later which actually you can do

00:28:53,840 --> 00:28:57,840
um there are techniques for federation

00:28:56,240 --> 00:28:59,360
if you want to do that but that also

00:28:57,840 --> 00:29:00,080
creates some problems down the road so

00:28:59,360 --> 00:29:02,399
just be

00:29:00,080 --> 00:29:03,279
be careful uh with scaling when you're

00:29:02,399 --> 00:29:06,159
federating

00:29:03,279 --> 00:29:07,679
um it can cause some confusion if you're

00:29:06,159 --> 00:29:09,600
if you're not careful

00:29:07,679 --> 00:29:10,880
and don't have the right metadata into

00:29:09,600 --> 00:29:12,720
which

00:29:10,880 --> 00:29:14,880
set of metrics you're actually looking

00:29:12,720 --> 00:29:14,880
at

00:29:15,039 --> 00:29:18,399
so let's go ahead i'll switch gears real

00:29:17,279 --> 00:29:21,360
quick and

00:29:18,399 --> 00:29:21,360
bring up my

00:29:22,320 --> 00:29:27,840
demo environment and just show you what

00:29:24,159 --> 00:29:27,840
this actually looks like

00:29:29,679 --> 00:29:33,039
there we go hopefully you can see that

00:29:31,279 --> 00:29:34,320
so this is promcat this is the resource

00:29:33,039 --> 00:29:35,440
i mentioned

00:29:34,320 --> 00:29:37,840
[Music]

00:29:35,440 --> 00:29:38,480
that we're cataloging or curating all of

00:29:37,840 --> 00:29:41,520
these

00:29:38,480 --> 00:29:43,600
exporters or as many as we can this is

00:29:41,520 --> 00:29:44,720
something we just started six months ago

00:29:43,600 --> 00:29:46,159
and we're getting a lot of great

00:29:44,720 --> 00:29:47,200
feedback on it if you look down here

00:29:46,159 --> 00:29:49,679
there's a lot of

00:29:47,200 --> 00:29:50,240
different exporters that we want to add

00:29:49,679 --> 00:29:51,600
uh

00:29:50,240 --> 00:29:54,080
in the near future but we've been

00:29:51,600 --> 00:29:56,480
rolling out on average one or two

00:29:54,080 --> 00:29:58,000
exporters a week and so if you click on

00:29:56,480 --> 00:29:59,600
available here you can narrow down to

00:29:58,000 --> 00:30:00,320
just the exporters that are available

00:29:59,600 --> 00:30:01,520
right now

00:30:00,320 --> 00:30:03,520
you can see we've been doing a lot of

00:30:01,520 --> 00:30:06,159
work on aws lately so

00:30:03,520 --> 00:30:07,360
cloud service exporters to be able to

00:30:06,159 --> 00:30:09,200
monitor

00:30:07,360 --> 00:30:11,360
data coming in from cloudwatch and other

00:30:09,200 --> 00:30:12,799
environments in aws

00:30:11,360 --> 00:30:14,960
is where we've been focusing a lot of

00:30:12,799 --> 00:30:16,080
our time over the past few months

00:30:14,960 --> 00:30:17,520
if we take a look at one of these

00:30:16,080 --> 00:30:20,159
exporters just by clicking on it i'll

00:30:17,520 --> 00:30:23,279
show you what i was talking about before

00:30:20,159 --> 00:30:25,279
we include a description of uh

00:30:23,279 --> 00:30:27,279
things that are important to know about

00:30:25,279 --> 00:30:29,840
lambda monitoring for example

00:30:27,279 --> 00:30:31,679
um we include a setup guide pretty

00:30:29,840 --> 00:30:33,600
detailed setup glide actually

00:30:31,679 --> 00:30:34,880
so even beyond the exporter itself

00:30:33,600 --> 00:30:36,320
things like making sure that you're

00:30:34,880 --> 00:30:39,360
creating

00:30:36,320 --> 00:30:40,880
an aws iam policy and how to do that in

00:30:39,360 --> 00:30:43,840
your environment

00:30:40,880 --> 00:30:45,200
setting up the credentials uh if you're

00:30:43,840 --> 00:30:46,720
running the cystic agent

00:30:45,200 --> 00:30:48,159
things that you need to know about

00:30:46,720 --> 00:30:50,080
specific things around setting up the

00:30:48,159 --> 00:30:52,399
cystic agent to do the scraping

00:30:50,080 --> 00:30:53,440
and then we give you example files that

00:30:52,399 --> 00:30:56,240
you can download

00:30:53,440 --> 00:30:57,440
and you can see we list the example yaml

00:30:56,240 --> 00:31:00,000
that you're going to need

00:30:57,440 --> 00:31:00,559
for for your environment so you can pick

00:31:00,000 --> 00:31:02,240
this up

00:31:00,559 --> 00:31:03,600
it's a great shortcut for people that

00:31:02,240 --> 00:31:04,880
are going through this of course

00:31:03,600 --> 00:31:06,240
your credentials are going to be

00:31:04,880 --> 00:31:07,279
different there's some environment

00:31:06,240 --> 00:31:08,960
variables here

00:31:07,279 --> 00:31:10,640
that are going to change based on the

00:31:08,960 --> 00:31:12,640
names in your environment

00:31:10,640 --> 00:31:14,000
but we give you this so that you can go

00:31:12,640 --> 00:31:15,200
have a place to start at least

00:31:14,000 --> 00:31:17,360
so that you don't have to come up with

00:31:15,200 --> 00:31:19,600
this from scratch

00:31:17,360 --> 00:31:21,360
the other thing we offer are dashboards

00:31:19,600 --> 00:31:22,720
and we offer these dashboards in most

00:31:21,360 --> 00:31:24,559
cases for

00:31:22,720 --> 00:31:25,600
the our systick monitor product where

00:31:24,559 --> 00:31:26,559
i'll give you i'll show you what that

00:31:25,600 --> 00:31:28,240
looks like in a minute

00:31:26,559 --> 00:31:29,600
but also for grafana because we have a

00:31:28,240 --> 00:31:32,080
lot of customers that

00:31:29,600 --> 00:31:33,120
just run defrona they like to run it

00:31:32,080 --> 00:31:35,679
they're used to that tool

00:31:33,120 --> 00:31:37,200
and so we have no problem being fully

00:31:35,679 --> 00:31:40,240
prometheus compatible

00:31:37,200 --> 00:31:40,960
in people using grafana if they choose

00:31:40,240 --> 00:31:42,720
to

00:31:40,960 --> 00:31:44,880
and then some sample alerts that you

00:31:42,720 --> 00:31:46,159
might be interested in or

00:31:44,880 --> 00:31:48,080
things that you might want to consider i

00:31:46,159 --> 00:31:48,880
mentioned the alerting methodologies

00:31:48,080 --> 00:31:50,240
before

00:31:48,880 --> 00:31:52,240
of trying to figure out what's important

00:31:50,240 --> 00:31:53,840
we do some of that heavy lifting for you

00:31:52,240 --> 00:31:56,000
but we can't do it all because every

00:31:53,840 --> 00:31:57,600
environment is different

00:31:56,000 --> 00:31:59,360
so that's promcat let me show you what

00:31:57,600 --> 00:32:00,640
this looks like when once you implement

00:31:59,360 --> 00:32:03,039
it

00:32:00,640 --> 00:32:04,000
this is cystic monitor product and what

00:32:03,039 --> 00:32:08,080
we're looking at here

00:32:04,000 --> 00:32:10,240
is the aws aws lambda dashboard

00:32:08,080 --> 00:32:12,559
that came in from that was imported from

00:32:10,240 --> 00:32:14,240
that page i just showed you before

00:32:12,559 --> 00:32:16,240
and you can see that we're using some

00:32:14,240 --> 00:32:18,720
golden signals methodology here

00:32:16,240 --> 00:32:19,760
looking at things like error rates

00:32:18,720 --> 00:32:23,039
looking at things

00:32:19,760 --> 00:32:25,679
like um throughput in terms of

00:32:23,039 --> 00:32:26,240
invocations and duration again those

00:32:25,679 --> 00:32:27,840
terms

00:32:26,240 --> 00:32:29,679
differ depending on the environment that

00:32:27,840 --> 00:32:31,279
you're looking at

00:32:29,679 --> 00:32:32,640
but understanding those golden signals

00:32:31,279 --> 00:32:33,760
that are important to you and then being

00:32:32,640 --> 00:32:35,679
able to track

00:32:33,760 --> 00:32:37,039
um you can see here that we had multiple

00:32:35,679 --> 00:32:39,120
implications happening

00:32:37,039 --> 00:32:40,840
at 11 30. by the way as i move this

00:32:39,120 --> 00:32:43,919
around you'll notice that that

00:32:40,840 --> 00:32:45,200
um indicator also moves on all of the

00:32:43,919 --> 00:32:45,919
other graphs so that you can see what's

00:32:45,200 --> 00:32:49,039
going on

00:32:45,919 --> 00:32:51,679
but you can see here at 11 30 if you

00:32:49,039 --> 00:32:53,039
look down here at duration we had a

00:32:51,679 --> 00:32:54,720
this particular function this is just

00:32:53,039 --> 00:32:57,440
one function you could have many

00:32:54,720 --> 00:32:58,399
on here but this particular function had

00:32:57,440 --> 00:33:00,640
some long-running

00:32:58,399 --> 00:33:02,240
indications so not only the number of

00:33:00,640 --> 00:33:05,840
indication invocations

00:33:02,240 --> 00:33:07,919
but how long did they run on average

00:33:05,840 --> 00:33:09,360
or what was the maximum run time for

00:33:07,919 --> 00:33:11,279
that particular

00:33:09,360 --> 00:33:12,960
function and that's important because

00:33:11,279 --> 00:33:14,559
obviously the longer your functions run

00:33:12,960 --> 00:33:16,559
the higher your

00:33:14,559 --> 00:33:17,600
lambda bill is going to be as part of

00:33:16,559 --> 00:33:21,039
your aws bill

00:33:17,600 --> 00:33:21,039
so that's important to take a look at

00:33:21,519 --> 00:33:25,440
in terms of those templates i mentioned

00:33:23,120 --> 00:33:26,399
before and having a having a curated

00:33:25,440 --> 00:33:28,799
view of the world

00:33:26,399 --> 00:33:30,159
that is easy for you to understand this

00:33:28,799 --> 00:33:31,840
is an example of our

00:33:30,159 --> 00:33:33,919
overview page for clusters in your

00:33:31,840 --> 00:33:35,200
environment where we stack rank these

00:33:33,919 --> 00:33:35,840
depending on the number of events that

00:33:35,200 --> 00:33:37,519
you have

00:33:35,840 --> 00:33:39,760
show you the events that that are

00:33:37,519 --> 00:33:42,159
related to those particular environments

00:33:39,760 --> 00:33:43,279
and then allow you to drill down easily

00:33:42,159 --> 00:33:45,360
into

00:33:43,279 --> 00:33:47,120
various parts of the cluster and you'll

00:33:45,360 --> 00:33:48,720
notice on top here that we pull in the

00:33:47,120 --> 00:33:49,440
scope as well the scope of what you're

00:33:48,720 --> 00:33:51,760
looking at

00:33:49,440 --> 00:33:53,600
we maintain that so as you drill down in

00:33:51,760 --> 00:33:55,039
here onto some suspect environments that

00:33:53,600 --> 00:33:57,600
you might want to troubleshoot

00:33:55,039 --> 00:33:59,279
take a look at the workloads for example

00:33:57,600 --> 00:34:02,159
you'll see that this

00:33:59,279 --> 00:34:03,039
scope that we're looking at is pulled as

00:34:02,159 --> 00:34:05,519
well

00:34:03,039 --> 00:34:06,559
into as we go further and further down

00:34:05,519 --> 00:34:08,480
the

00:34:06,559 --> 00:34:10,320
rabbit hole so to speak if we take a

00:34:08,480 --> 00:34:11,520
look at the cop the kubernetes pod

00:34:10,320 --> 00:34:12,720
overview this is a template as i

00:34:11,520 --> 00:34:15,040
mentioned before

00:34:12,720 --> 00:34:17,040
again we've inherited all that scope

00:34:15,040 --> 00:34:19,359
this is jk cluster

00:34:17,040 --> 00:34:20,320
sorry gke cluster it's the shock shop

00:34:19,359 --> 00:34:23,599
namespace

00:34:20,320 --> 00:34:26,879
it's the cartdb uh workload

00:34:23,599 --> 00:34:30,240
so this is some sort of a database

00:34:26,879 --> 00:34:32,240
environment for uh processing the um

00:34:30,240 --> 00:34:34,560
the the orders we're taking in for new

00:34:32,240 --> 00:34:36,399
and interesting socks i guess but

00:34:34,560 --> 00:34:38,480
you can see here that even though this

00:34:36,399 --> 00:34:39,679
is a template it's showing us valuable

00:34:38,480 --> 00:34:42,240
information like

00:34:39,679 --> 00:34:43,599
uh what what are workload resources and

00:34:42,240 --> 00:34:44,159
which ones should i be paying attention

00:34:43,599 --> 00:34:45,679
to

00:34:44,159 --> 00:34:49,280
and then from here i can customize this

00:34:45,679 --> 00:34:50,879
dashboard to my heart's content

00:34:49,280 --> 00:34:52,800
and again looking at some of the other

00:34:50,879 --> 00:34:55,440
templates that we have in here

00:34:52,800 --> 00:34:57,040
things like gold golden signals for

00:34:55,440 --> 00:34:58,880
kubernetes service for example

00:34:57,040 --> 00:35:00,800
again looking at things like response

00:34:58,880 --> 00:35:03,200
time looking at things like error rates

00:35:00,800 --> 00:35:04,560
those golden signals that should guide

00:35:03,200 --> 00:35:06,960
your help you get

00:35:04,560 --> 00:35:08,400
more meaningful set more meaningful

00:35:06,960 --> 00:35:10,400
alerts in your environment and

00:35:08,400 --> 00:35:12,240
get more meaningful data out of your

00:35:10,400 --> 00:35:15,359
prometheus exporters or just out of in

00:35:12,240 --> 00:35:16,960
this case your kubernetes environment

00:35:15,359 --> 00:35:18,720
you can see how that becomes very very

00:35:16,960 --> 00:35:20,400
important over time

00:35:18,720 --> 00:35:22,320
to narrow down on on what's important in

00:35:20,400 --> 00:35:23,839
your environment so those are just a few

00:35:22,320 --> 00:35:27,280
examples of how you might

00:35:23,839 --> 00:35:27,760
take a prometheus exporter deploy it and

00:35:27,280 --> 00:35:29,440
then

00:35:27,760 --> 00:35:31,599
get the information out of it in a quick

00:35:29,440 --> 00:35:33,680
and easy way without having to spend so

00:35:31,599 --> 00:35:35,839
much time on maintenance

00:35:33,680 --> 00:35:37,280
because that really is the big killer

00:35:35,839 --> 00:35:38,640
here when there's hundreds of prometheus

00:35:37,280 --> 00:35:41,040
exporters potentially

00:35:38,640 --> 00:35:43,599
that you need to evaluate deploy and

00:35:41,040 --> 00:35:43,599
maintain

00:35:43,680 --> 00:35:46,800
having a good methodology and best

00:35:45,359 --> 00:35:48,240
practices around doing that

00:35:46,800 --> 00:35:50,800
is going to save you a lot of time and a

00:35:48,240 --> 00:35:52,480
lot of pain at the end of the day

00:35:50,800 --> 00:35:55,520
so with that i'm going to stop sharing

00:35:52,480 --> 00:35:58,640
and just see if there's any more

00:35:55,520 --> 00:35:59,599
questions out there i'm looking at the q

00:35:58,640 --> 00:36:02,560
and i don't see

00:35:59,599 --> 00:36:04,000
in the chat and i don't see any more

00:36:02,560 --> 00:36:06,960
questions so

00:36:04,000 --> 00:36:08,400
um with that i'm going to thank

00:36:06,960 --> 00:36:09,760
everybody for joining i guess

00:36:08,400 --> 00:36:11,440
but i'll hang out and just in case

00:36:09,760 --> 00:36:13,839
there's more questions

00:36:11,440 --> 00:36:13,839
that you have

00:36:24,880 --> 00:36:28,079
or if there's any discussion maybe you

00:36:26,160 --> 00:36:28,840
don't have a question but you took issue

00:36:28,079 --> 00:36:30,800
with something i said

00:36:28,840 --> 00:36:32,240
[Laughter]

00:36:30,800 --> 00:36:34,000
that's always a dangerous thing to open

00:36:32,240 --> 00:36:35,839
it up to i think there's a there's the

00:36:34,000 --> 00:36:37,680
possibility if you bring it up in q a

00:36:35,839 --> 00:36:41,839
that we can unmute your line

00:36:37,680 --> 00:36:41,839
and have a discussion

00:37:02,079 --> 00:37:05,280
uh we we one of the questions that came

00:37:04,160 --> 00:37:08,079
up last time

00:37:05,280 --> 00:37:08,640
i actually did this presentation was

00:37:08,079 --> 00:37:10,560
around

00:37:08,640 --> 00:37:12,480
prom ql i mentioned that we support

00:37:10,560 --> 00:37:14,800
promql

00:37:12,480 --> 00:37:15,920
we support primeql in the dashboards and

00:37:14,800 --> 00:37:18,240
in our alerts

00:37:15,920 --> 00:37:19,520
um and you can of course query from your

00:37:18,240 --> 00:37:22,560
end if you have a

00:37:19,520 --> 00:37:23,839
uh by using the standard api method

00:37:22,560 --> 00:37:25,040
you can query our backend for

00:37:23,839 --> 00:37:26,160
information about your environment so

00:37:25,040 --> 00:37:28,079
you have a script running

00:37:26,160 --> 00:37:29,200
on a host that's using promptql to pull

00:37:28,079 --> 00:37:31,839
information to make

00:37:29,200 --> 00:37:33,440
some determination you can do that and

00:37:31,839 --> 00:37:35,920
you can configure

00:37:33,440 --> 00:37:37,520
panels in our dashboard by using promql

00:37:35,920 --> 00:37:39,599
or by using

00:37:37,520 --> 00:37:42,160
a form-based methodology where you click

00:37:39,599 --> 00:37:43,599
and choose which

00:37:42,160 --> 00:37:45,200
which information you want to see so you

00:37:43,599 --> 00:37:46,960
can choose if you don't know promql

00:37:45,200 --> 00:37:49,119
you're not locked into promql you can

00:37:46,960 --> 00:37:49,760
actually use our form-based method and

00:37:49,119 --> 00:37:52,320
get the same

00:37:49,760 --> 00:37:53,680
information that way so just fyi that

00:37:52,320 --> 00:37:55,760
was something that i didn't make clear

00:37:53,680 --> 00:37:58,480
in the last time i presented this

00:37:55,760 --> 00:38:00,720
uh there is a question from alejandro he

00:37:58,480 --> 00:38:00,720
says

00:38:02,000 --> 00:38:05,680
in security monitoring have you seen

00:38:03,920 --> 00:38:07,599
companies using prometheus yes

00:38:05,680 --> 00:38:11,040
absolutely

00:38:07,599 --> 00:38:13,280
um the two kind of go hand in hand

00:38:11,040 --> 00:38:14,160
so we have uh lots of companies big

00:38:13,280 --> 00:38:17,760
companies

00:38:14,160 --> 00:38:20,880
that are using prometheus and also doing

00:38:17,760 --> 00:38:22,240
security monitoring as well many times

00:38:20,880 --> 00:38:22,800
with security monitoring what you're

00:38:22,240 --> 00:38:25,119
looking at

00:38:22,800 --> 00:38:26,240
are things like the falco rules falco's

00:38:25,119 --> 00:38:27,200
an open source project that we

00:38:26,240 --> 00:38:31,040
contributed

00:38:27,200 --> 00:38:34,400
to the cncf and its rules for

00:38:31,040 --> 00:38:36,079
um for your environment that

00:38:34,400 --> 00:38:38,400
you can set up and make sure aren't

00:38:36,079 --> 00:38:40,000
being violated and

00:38:38,400 --> 00:38:41,839
so the community can jump in and create

00:38:40,000 --> 00:38:42,960
new rules or once you've once you have

00:38:41,839 --> 00:38:44,800
those rules available to you you can

00:38:42,960 --> 00:38:47,119
modify them to your heart's content

00:38:44,800 --> 00:38:48,560
so not necessarily prometheus but

00:38:47,119 --> 00:38:49,839
certainly having another open source

00:38:48,560 --> 00:38:50,880
project like falco

00:38:49,839 --> 00:38:53,119
that can help you secure your

00:38:50,880 --> 00:38:55,200
environment is very important and

00:38:53,119 --> 00:38:56,880
uh we fully support that obviously in

00:38:55,200 --> 00:38:58,000
our secure product so take a look at

00:38:56,880 --> 00:38:59,760
that

00:38:58,000 --> 00:39:01,119
sign up for a trial and see if you can

00:38:59,760 --> 00:39:02,880
turn on some image scanning

00:39:01,119 --> 00:39:04,240
and get some interesting information

00:39:02,880 --> 00:39:05,760
that's always what happens

00:39:04,240 --> 00:39:07,280
when people try the secure product is

00:39:05,760 --> 00:39:10,160
they say oh i didn't know

00:39:07,280 --> 00:39:11,040
that i was uh out of date or i had a

00:39:10,160 --> 00:39:14,320
vulnerable

00:39:11,040 --> 00:39:16,079
package in in my container image

00:39:14,320 --> 00:39:18,800
and you can quickly go in and fix those

00:39:16,079 --> 00:39:22,320
things so check that out as well

00:39:18,800 --> 00:39:24,480
any other questions all right so

00:39:22,320 --> 00:39:27,440
i'm going to wrap it up and just i say i

00:39:24,480 --> 00:39:29,280
hope everybody stays safe

00:39:27,440 --> 00:39:30,400
ah here's another question i knew if i

00:39:29,280 --> 00:39:30,960
waited there would be another one that

00:39:30,400 --> 00:39:32,480
came in

00:39:30,960 --> 00:39:34,960
how does one contribute to the

00:39:32,480 --> 00:39:37,440
prometheus configurations catalog

00:39:34,960 --> 00:39:38,800
um the way that you contribute is by

00:39:37,440 --> 00:39:41,119
contributing to the

00:39:38,800 --> 00:39:42,640
open source projects themselves so again

00:39:41,119 --> 00:39:44,640
the catalog is something that we're

00:39:42,640 --> 00:39:48,240
doing at sysdig

00:39:44,640 --> 00:39:49,440
to to kind of have it to kind of narrow

00:39:48,240 --> 00:39:51,760
down on the

00:39:49,440 --> 00:39:52,800
the prometheus exporters that we feel

00:39:51,760 --> 00:39:54,560
are most important and that our

00:39:52,800 --> 00:39:55,839
customers tell us are most important

00:39:54,560 --> 00:39:57,920
so that's the other way that you can

00:39:55,839 --> 00:40:00,640
contribute is by

00:39:57,920 --> 00:40:01,040
uh letting us know which ones you think

00:40:00,640 --> 00:40:05,040
are

00:40:01,040 --> 00:40:05,920
our best and um why they're working for

00:40:05,040 --> 00:40:07,760
you or or

00:40:05,920 --> 00:40:10,800
if we've missed one or if you say hey

00:40:07,760 --> 00:40:13,839
look you know you've rolled out 30 um

00:40:10,800 --> 00:40:15,680
exporters on promcat but you don't have

00:40:13,839 --> 00:40:17,359
xyz exporter and i really need that for

00:40:15,680 --> 00:40:18,800
my environment let us know because the

00:40:17,359 --> 00:40:21,200
more that we hear from you

00:40:18,800 --> 00:40:22,560
uh the more focus will be put on by our

00:40:21,200 --> 00:40:24,160
team that manages that

00:40:22,560 --> 00:40:25,839
um and does all the testing and

00:40:24,160 --> 00:40:27,680
maintenance of

00:40:25,839 --> 00:40:29,040
the exporters that live on promcat they

00:40:27,680 --> 00:40:31,839
will take that into account

00:40:29,040 --> 00:40:32,720
and go focus on that particular exporter

00:40:31,839 --> 00:40:34,400
that you need

00:40:32,720 --> 00:40:36,800
so let us know if you want to see a new

00:40:34,400 --> 00:40:38,319
one and if there's one that you think

00:40:36,800 --> 00:40:39,760
could be better should be better

00:40:38,319 --> 00:40:41,359
definitely go to the github page for

00:40:39,760 --> 00:40:43,520
that exporter and

00:40:41,359 --> 00:40:45,520
see if you can contribute in some way by

00:40:43,520 --> 00:40:48,079
helping test issues

00:40:45,520 --> 00:40:50,079
improve the documentation etc we don't

00:40:48,079 --> 00:40:51,839
take anything from the community

00:40:50,079 --> 00:40:54,400
and host it ourselves and claim that we

00:40:51,839 --> 00:40:56,880
own it uh we always give it back

00:40:54,400 --> 00:40:58,720
so we link to those projects and we're

00:40:56,880 --> 00:41:02,319
helping augment those projects

00:40:58,720 --> 00:41:02,319
certainly not take over anything

00:41:03,599 --> 00:41:06,880
okay i think i'm gonna wrap it up there

00:41:05,520 --> 00:41:08,400
again as i was saying just i hope

00:41:06,880 --> 00:41:10,319
everybody stays safe

00:41:08,400 --> 00:41:11,599
uh out there and thanks for joining if

00:41:10,319 --> 00:41:13,119
you have questions feel free to reach

00:41:11,599 --> 00:41:21,440
out to me directly

00:41:13,119 --> 00:41:21,440

YouTube URL: https://www.youtube.com/watch?v=0PDP49qFzAE


