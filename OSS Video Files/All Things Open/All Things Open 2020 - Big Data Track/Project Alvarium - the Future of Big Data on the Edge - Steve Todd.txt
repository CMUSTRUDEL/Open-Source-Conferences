Title: Project Alvarium - the Future of Big Data on the Edge - Steve Todd
Publication date: 2020-12-11
Playlist: All Things Open 2020 - Big Data Track
Description: 
	Presented by: Steve Todd, Dell Technologies
Presented at All Things Open 2020 - Big Data Track

Abstract: Big data has big trust problems on the edge.

The high level of trust assigned to enterprise data does not always extend to data born at the edge. The principles of enterprise trust insertion, however, can serve as guideposts for increasing edge data trustworthiness. This presentation introduces the motivation behind The LINUX Foundation’s Project Alvarium, as well as the building of the first Data Confidence Fabric (DCF). A DCF is a framework in which edge data is annotated with trust metrics as it flows towards applications. This talk will reveal the motivation behind Project Alvarium, describe the trust measurement techniques used within a DCF, and highlight how the value of the resulting data increases.

Project Alvarium will focus on … “building the concept of a Data Confidence Fabric (DCF) to facilitate measurable trust and confidence in data and applications spanning heterogeneous systems.  (http://alvarium.org). Alvarium is a Latin word for “beehive”, in which the community works in an environment of trust to accomplish a common goal: build an open Data Confidence Fabric.

When enterprise data flows between storage systems and applications, it is handled by various layers of hardware and software trust insertion as part of a data path or stack. This stack is often created and maintained by highly-trained enterprise architects and security practitioners. As such the data is implicitly trusted when it arrives at an application.

Extending this implicit trust to edge and IoT data is challenging. The data flows over a wide variety of heterogeneous technology and networks, across an ecosystem so large that it is often beyond the reach and capabilities of an enterprise security team. 

Applications, therefore, must learn to trust edge and IoT data explicitly by examining trusted annotations that accompany the data.  These “trust insertions” generate metadata and scores that are forwarded alongside the data. Annotations, when they arrive at an application, allow the confidence of that data to be “measured.”

Higher confidence scores lead to higher value: risk is reduced (e.g., regulatory fines) and new forms of revenue from data become possible (e.g., data marketplaces).

The presentation will describe the results achieved from building and running the industry’s first Data Confidence Fabric and will include an invitation to join the Alvarium open community and work together on trust configuration, annotation, and scoring methodologies.
Captions: 
	00:00:05,440 --> 00:00:09,440
my name's steve todd

00:00:07,440 --> 00:00:11,040
and i will be doing the next

00:00:09,440 --> 00:00:14,400
presentation

00:00:11,040 --> 00:00:18,880
on project alvarium

00:00:14,400 --> 00:00:22,400
the future of big data on the edge

00:00:18,880 --> 00:00:26,000
and this presentation really builds on

00:00:22,400 --> 00:00:28,080
what jackie just presented not only how

00:00:26,000 --> 00:00:29,599
can you get high quality data but how

00:00:28,080 --> 00:00:33,360
can you measure

00:00:29,599 --> 00:00:35,680
that your data is high quality

00:00:33,360 --> 00:00:37,120
so the agenda for today is i'll

00:00:35,680 --> 00:00:39,520
introduce myself

00:00:37,120 --> 00:00:41,840
and give you a little bit of background

00:00:39,520 --> 00:00:44,719
about project alvarium

00:00:41,840 --> 00:00:46,960
i'll talk about the challenges with

00:00:44,719 --> 00:00:50,239
artificial intelligence

00:00:46,960 --> 00:00:52,160
on edge environments and then i'll dive

00:00:50,239 --> 00:00:54,000
into a solution

00:00:52,160 --> 00:00:55,280
which we're calling a data confidence

00:00:54,000 --> 00:00:58,079
fabric

00:00:55,280 --> 00:00:59,359
and how we're starting an open source

00:00:58,079 --> 00:01:03,199
project

00:00:59,359 --> 00:01:04,720
to build data confidence fabrics

00:01:03,199 --> 00:01:06,240
so just as a quick introduction for

00:01:04,720 --> 00:01:10,479
myself

00:01:06,240 --> 00:01:13,760
i was a software engineer building

00:01:10,479 --> 00:01:15,360
intelligent data storage systems uh for

00:01:13,760 --> 00:01:17,759
25 years

00:01:15,360 --> 00:01:19,200
and uh on the left we have a picture of

00:01:17,759 --> 00:01:21,439
one of those storage systems

00:01:19,200 --> 00:01:23,600
the architecture and this would run

00:01:21,439 --> 00:01:26,640
inside a data center

00:01:23,600 --> 00:01:27,680
starting in 2014 i began to study the

00:01:26,640 --> 00:01:31,439
value

00:01:27,680 --> 00:01:33,439
of data especially for corporations or

00:01:31,439 --> 00:01:36,640
enterprises

00:01:33,439 --> 00:01:40,400
and that led me to do some research into

00:01:36,640 --> 00:01:42,320
blockchain and how dell could work

00:01:40,400 --> 00:01:43,920
with our customers on blockchain

00:01:42,320 --> 00:01:45,360
solutions

00:01:43,920 --> 00:01:48,079
and then in recent years i've been

00:01:45,360 --> 00:01:51,600
looking at decentralization

00:01:48,079 --> 00:01:54,479
uh decentralized identity decentralized

00:01:51,600 --> 00:01:56,640
storage systems like ipfs

00:01:54,479 --> 00:01:58,640
and decentralized ledgers like

00:01:56,640 --> 00:02:00,399
hyperledger fabric

00:01:58,640 --> 00:02:02,240
and when i looked at these new

00:02:00,399 --> 00:02:04,640
technologies

00:02:02,240 --> 00:02:07,119
i realized that more and more data will

00:02:04,640 --> 00:02:10,000
be analyzed on the edge

00:02:07,119 --> 00:02:12,160
but these systems uh the the these

00:02:10,000 --> 00:02:15,440
decentralized systems

00:02:12,160 --> 00:02:17,040
trustworthy data is a problem so how

00:02:15,440 --> 00:02:19,760
could we learn some lessons

00:02:17,040 --> 00:02:22,239
from earlier storage systems to help us

00:02:19,760 --> 00:02:25,920
solve this problem

00:02:22,239 --> 00:02:29,200
so here um we're going to borrow

00:02:25,920 --> 00:02:31,120
from what we did for enterprise storage

00:02:29,200 --> 00:02:32,959
systems so here i have a picture of some

00:02:31,120 --> 00:02:35,840
disk drives

00:02:32,959 --> 00:02:36,080
and as data moves from the surface of

00:02:35,840 --> 00:02:40,879
the

00:02:36,080 --> 00:02:44,400
disk up to applications

00:02:40,879 --> 00:02:47,440
it moves through a variety of trust

00:02:44,400 --> 00:02:50,400
insertion technologies for example

00:02:47,440 --> 00:02:52,160
raid technology redundant array of

00:02:50,400 --> 00:02:54,560
inexpensive disks

00:02:52,160 --> 00:02:56,000
allows your application to continue

00:02:54,560 --> 00:02:59,440
reading and writing

00:02:56,000 --> 00:03:01,519
even if there was a failure one of those

00:02:59,440 --> 00:03:03,280
disks was inaccessible

00:03:01,519 --> 00:03:06,560
you have technologies like load

00:03:03,280 --> 00:03:08,959
balancing which allow you to

00:03:06,560 --> 00:03:10,319
go down another path if one of the paths

00:03:08,959 --> 00:03:14,400
fails

00:03:10,319 --> 00:03:17,040
so we built this trusted data delivery

00:03:14,400 --> 00:03:18,720
mechanism and what are some of the key

00:03:17,040 --> 00:03:22,080
insights from building

00:03:18,720 --> 00:03:23,200
this system well number one when we were

00:03:22,080 --> 00:03:26,080
able to deliver

00:03:23,200 --> 00:03:27,360
trusted data to applications those

00:03:26,080 --> 00:03:31,120
applications

00:03:27,360 --> 00:03:33,519
helped the business on the balance sheet

00:03:31,120 --> 00:03:34,959
it helped them increase their revenues

00:03:33,519 --> 00:03:37,760
and make money

00:03:34,959 --> 00:03:38,799
it helped them reduce their operating

00:03:37,760 --> 00:03:41,760
expenditures

00:03:38,799 --> 00:03:42,080
and save money and it also helped them

00:03:41,760 --> 00:03:45,200
to

00:03:42,080 --> 00:03:46,080
decrease their risk right the more

00:03:45,200 --> 00:03:49,440
trustworthy

00:03:46,080 --> 00:03:51,599
the data the less chance that they would

00:03:49,440 --> 00:03:53,360
expose that data and expose themselves

00:03:51,599 --> 00:03:56,720
to fines

00:03:53,360 --> 00:03:59,360
but the other key insight is this

00:03:56,720 --> 00:04:01,280
trusted the delivery of trusted data is

00:03:59,360 --> 00:04:04,879
implicit

00:04:01,280 --> 00:04:07,680
the application doesn't need to verify

00:04:04,879 --> 00:04:10,480
that the data is trustworthy

00:04:07,680 --> 00:04:11,280
because somebody has went out and

00:04:10,480 --> 00:04:13,840
purchased

00:04:11,280 --> 00:04:16,720
an enterprise class storage system with

00:04:13,840 --> 00:04:19,359
all of these advanced features

00:04:16,720 --> 00:04:20,239
and usually there's a dedicated security

00:04:19,359 --> 00:04:23,280
team

00:04:20,239 --> 00:04:25,759
making sure the data is trustworthy

00:04:23,280 --> 00:04:26,880
so when we think about this paradigm

00:04:25,759 --> 00:04:30,320
right moving

00:04:26,880 --> 00:04:33,840
trusted data to an application

00:04:30,320 --> 00:04:35,680
on the edge that trust has to be

00:04:33,840 --> 00:04:39,520
explicit

00:04:35,680 --> 00:04:40,560
and it has to be auditable so so let's

00:04:39,520 --> 00:04:44,479
look

00:04:40,560 --> 00:04:45,199
at this edge problem so i'm using an

00:04:44,479 --> 00:04:47,680
example

00:04:45,199 --> 00:04:48,960
a retail example here where i have a

00:04:47,680 --> 00:04:51,600
store

00:04:48,960 --> 00:04:53,040
with a variety of smart sensors in the

00:04:51,600 --> 00:04:56,000
store

00:04:53,040 --> 00:04:58,080
my company has written an artificial

00:04:56,000 --> 00:05:01,120
intelligence algorithm

00:04:58,080 --> 00:05:02,960
that it wants to move down into the

00:05:01,120 --> 00:05:05,759
store environment

00:05:02,960 --> 00:05:06,560
and the belief is that when that

00:05:05,759 --> 00:05:09,680
application

00:05:06,560 --> 00:05:12,960
runs in a retail store and it's

00:05:09,680 --> 00:05:15,039
closer to consumers there's a chance to

00:05:12,960 --> 00:05:16,720
give those consumers a better customer

00:05:15,039 --> 00:05:20,400
experience

00:05:16,720 --> 00:05:23,120
and increase their purchasing habits

00:05:20,400 --> 00:05:23,840
similarly there's a belief that when you

00:05:23,120 --> 00:05:27,039
move this

00:05:23,840 --> 00:05:29,520
application down into a store closer to

00:05:27,039 --> 00:05:32,160
the sales associates

00:05:29,520 --> 00:05:33,280
they can operate more efficiently and

00:05:32,160 --> 00:05:36,400
reduce

00:05:33,280 --> 00:05:38,080
their operational expenditures the

00:05:36,400 --> 00:05:41,919
problem is

00:05:38,080 --> 00:05:45,280
that the data coming to that

00:05:41,919 --> 00:05:48,560
uh ai software

00:05:45,280 --> 00:05:50,960
is unknown potentially

00:05:48,560 --> 00:05:52,800
and there's so much of it and it's from

00:05:50,960 --> 00:05:56,560
so many sources

00:05:52,800 --> 00:05:59,759
the company exposes themselves to risk

00:05:56,560 --> 00:06:01,199
if the data is garbage if the data is

00:05:59,759 --> 00:06:04,400
malicious

00:06:01,199 --> 00:06:06,960
or if the data is highly regulated

00:06:04,400 --> 00:06:08,000
so this is the problem that project

00:06:06,960 --> 00:06:11,440
alvarium

00:06:08,000 --> 00:06:13,520
is trying to solve and the way it's

00:06:11,440 --> 00:06:16,800
trying to solve it

00:06:13,520 --> 00:06:17,680
is by creating what's called a data

00:06:16,800 --> 00:06:22,479
confidence

00:06:17,680 --> 00:06:26,479
fabric so we've defined a dcf

00:06:22,479 --> 00:06:30,400
as a fabric when data travels

00:06:26,479 --> 00:06:33,680
over it it's always annotated

00:06:30,400 --> 00:06:36,560
and it's scored so from the moment

00:06:33,680 --> 00:06:37,520
that it's born to the moment that it's

00:06:36,560 --> 00:06:41,039
delivered

00:06:37,520 --> 00:06:44,560
to an application annotation

00:06:41,039 --> 00:06:47,600
and scoring happens so so this is

00:06:44,560 --> 00:06:48,400
the idea behind a data confidence fabric

00:06:47,600 --> 00:06:53,919
right that

00:06:48,400 --> 00:06:57,360
that ai model not only analyzes the data

00:06:53,919 --> 00:06:59,840
but it can analyze a score about how

00:06:57,360 --> 00:07:03,039
trustworthy is that data

00:06:59,840 --> 00:07:06,560
and how was that trust

00:07:03,039 --> 00:07:09,199
score calculated so let's take a look at

00:07:06,560 --> 00:07:10,479
we decided to build the first data

00:07:09,199 --> 00:07:15,120
confidence fabric

00:07:10,479 --> 00:07:17,919
in our own lab and here's what we did

00:07:15,120 --> 00:07:19,120
on the bottom right hand side we're

00:07:17,919 --> 00:07:22,800
using gray

00:07:19,120 --> 00:07:27,039
the gray color to signify that without

00:07:22,800 --> 00:07:30,319
a data confidence fabric any sensor data

00:07:27,039 --> 00:07:32,240
that is being sent northward to an

00:07:30,319 --> 00:07:36,080
application

00:07:32,240 --> 00:07:39,520
has zero trust for a score

00:07:36,080 --> 00:07:41,800
and on the left hand side we assembled

00:07:39,520 --> 00:07:42,960
different hardware and software

00:07:41,800 --> 00:07:46,319
technologies

00:07:42,960 --> 00:07:49,440
that could insert trust

00:07:46,319 --> 00:07:51,199
into the journey of the data now some of

00:07:49,440 --> 00:07:54,560
these technologies

00:07:51,199 --> 00:07:57,599
are open technologies and some of them

00:07:54,560 --> 00:08:02,400
are proprietary technologies

00:07:57,599 --> 00:08:02,400
so let's just move up the stack here

00:08:02,560 --> 00:08:08,319
perhaps there's a gateway that has a tpm

00:08:05,520 --> 00:08:11,440
chip a trusted platform module

00:08:08,319 --> 00:08:13,680
that adds a digital signature to the

00:08:11,440 --> 00:08:16,479
data

00:08:13,680 --> 00:08:18,080
that digital the fact that that digital

00:08:16,479 --> 00:08:21,440
signature occurred

00:08:18,080 --> 00:08:25,360
can be annotated and the score

00:08:21,440 --> 00:08:27,520
can be increased by one and now you have

00:08:25,360 --> 00:08:29,199
not unknown trust but a low trust

00:08:27,520 --> 00:08:32,080
situation

00:08:29,199 --> 00:08:33,599
moving up to the next level we actually

00:08:32,080 --> 00:08:37,200
used a dell product called

00:08:33,599 --> 00:08:39,200
boomi to gather information about the

00:08:37,200 --> 00:08:41,919
source of the data

00:08:39,200 --> 00:08:43,760
where was it collected what operating

00:08:41,919 --> 00:08:47,040
system was used

00:08:43,760 --> 00:08:48,240
what type of gateway was it and so that

00:08:47,040 --> 00:08:51,040
annotation was

00:08:48,240 --> 00:08:52,560
added to the list and the score was

00:08:51,040 --> 00:08:55,040
increased

00:08:52,560 --> 00:08:56,160
we used an open source technology from

00:08:55,040 --> 00:08:59,680
vmware called

00:08:56,160 --> 00:09:00,560
lightwave which was a secure token

00:08:59,680 --> 00:09:03,360
server

00:09:00,560 --> 00:09:04,480
and a certificate authority authority

00:09:03,360 --> 00:09:07,519
this prevented

00:09:04,480 --> 00:09:10,640
unauthorized people from looking

00:09:07,519 --> 00:09:12,240
at the sensor data which also increased

00:09:10,640 --> 00:09:15,120
the score

00:09:12,240 --> 00:09:15,600
as we move up the stack we stored that

00:09:15,120 --> 00:09:19,760
data

00:09:15,600 --> 00:09:22,240
using ipfs and that's a storage system

00:09:19,760 --> 00:09:25,120
that calculates

00:09:22,240 --> 00:09:27,760
a content address so that you can tell

00:09:25,120 --> 00:09:30,000
the data hasn't been tampered with

00:09:27,760 --> 00:09:32,240
and then finally we used an open source

00:09:30,000 --> 00:09:35,279
project another one from vmware called

00:09:32,240 --> 00:09:39,600
project concord which took

00:09:35,279 --> 00:09:42,800
all of these annotations and the score

00:09:39,600 --> 00:09:44,640
and put them in a ledger so that ledger

00:09:42,800 --> 00:09:47,839
can't be deleted

00:09:44,640 --> 00:09:50,720
and it can't be altered so

00:09:47,839 --> 00:09:51,360
the end result is now your applications

00:09:50,720 --> 00:09:54,959
can not

00:09:51,360 --> 00:09:56,000
only look at the data and analyze the

00:09:54,959 --> 00:09:58,720
data

00:09:56,000 --> 00:10:00,959
but they can also look at a ledger and

00:09:58,720 --> 00:10:03,200
they can see the journey of the data

00:10:00,959 --> 00:10:04,880
and they can see a score associated with

00:10:03,200 --> 00:10:07,760
the data

00:10:04,880 --> 00:10:08,800
so when we built this framework inside

00:10:07,760 --> 00:10:13,200
our lab

00:10:08,800 --> 00:10:14,800
at dell we recognized that

00:10:13,200 --> 00:10:16,640
this is not a product that we could

00:10:14,800 --> 00:10:19,680
build on our own

00:10:16,640 --> 00:10:22,959
we would need to build some sort of open

00:10:19,680 --> 00:10:23,760
framework that allowed for industry

00:10:22,959 --> 00:10:26,959
standard

00:10:23,760 --> 00:10:31,120
annotation and scoring and

00:10:26,959 --> 00:10:33,839
that project is called alvarium

00:10:31,120 --> 00:10:35,600
so you can see this announcement which

00:10:33,839 --> 00:10:39,839
occurred over a year ago

00:10:35,600 --> 00:10:42,160
about an intent to form project alvarium

00:10:39,839 --> 00:10:43,839
so that people in the industry could

00:10:42,160 --> 00:10:46,800
come together

00:10:43,839 --> 00:10:48,480
and build annotations and build trust

00:10:46,800 --> 00:10:52,720
score mechanisms

00:10:48,480 --> 00:10:56,000
as data was being moved across the edge

00:10:52,720 --> 00:10:58,839
from the source of the device out to

00:10:56,000 --> 00:11:00,079
the application itself wherever it would

00:10:58,839 --> 00:11:04,800
live

00:11:00,079 --> 00:11:06,959
so this is a picture of how that works

00:11:04,800 --> 00:11:08,320
on the left you have a variety of

00:11:06,959 --> 00:11:12,079
sensors

00:11:08,320 --> 00:11:14,240
sending a data stream and as that data

00:11:12,079 --> 00:11:17,680
moves from left to right

00:11:14,240 --> 00:11:20,000
to gateways to ed servers

00:11:17,680 --> 00:11:22,720
potentially all the way to a cloud where

00:11:20,000 --> 00:11:26,560
an application is running

00:11:22,720 --> 00:11:30,240
alvarium is a lightweight api

00:11:26,560 --> 00:11:34,480
that allows for trust metadata

00:11:30,240 --> 00:11:37,200
and confidence scores to be appended

00:11:34,480 --> 00:11:39,519
like a sidecar that's riding alongside

00:11:37,200 --> 00:11:40,959
of a motorcycle right if the motorcycle

00:11:39,519 --> 00:11:43,200
is the data

00:11:40,959 --> 00:11:45,519
the sidecar is really a collection of

00:11:43,200 --> 00:11:48,079
annotations and scores

00:11:45,519 --> 00:11:49,600
so just in this example the gateway is

00:11:48,079 --> 00:11:53,440
saying

00:11:49,600 --> 00:11:55,600
i validated that the signature is valid

00:11:53,440 --> 00:11:57,360
i went through a secure boot process

00:11:55,600 --> 00:12:01,519
successfully

00:11:57,360 --> 00:12:05,120
and i have enabled authentication

00:12:01,519 --> 00:12:05,600
and these three readings and annotations

00:12:05,120 --> 00:12:08,560
are then

00:12:05,600 --> 00:12:09,760
passed along with the data up to the

00:12:08,560 --> 00:12:12,480
edge server

00:12:09,760 --> 00:12:14,480
where more annotations are generated and

00:12:12,480 --> 00:12:16,480
so on and so forth

00:12:14,480 --> 00:12:18,240
so down here in the bottom right you see

00:12:16,480 --> 00:12:21,440
the benefit of this approach

00:12:18,240 --> 00:12:22,399
number one you can still analyze the raw

00:12:21,440 --> 00:12:25,200
data

00:12:22,399 --> 00:12:26,079
but number two now you have a ledger

00:12:25,200 --> 00:12:29,360
entry

00:12:26,079 --> 00:12:32,160
that contains a confidence score and

00:12:29,360 --> 00:12:33,600
a list of annotations so what are the

00:12:32,160 --> 00:12:36,959
benefits of this approach

00:12:33,600 --> 00:12:40,079
well now your ai

00:12:36,959 --> 00:12:43,519
software can produce

00:12:40,079 --> 00:12:45,680
measurably trustworthy insights so not

00:12:43,519 --> 00:12:48,880
only can you analyze data

00:12:45,680 --> 00:12:52,160
but you can also analyze a score and

00:12:48,880 --> 00:12:54,639
annotations associated with the data so

00:12:52,160 --> 00:12:56,959
if the score is low

00:12:54,639 --> 00:12:58,480
you might not trust your insights if the

00:12:56,959 --> 00:12:59,920
score is high they might be more

00:12:58,480 --> 00:13:02,639
trustworthy

00:12:59,920 --> 00:13:05,760
and finally over here on the right being

00:13:02,639 --> 00:13:09,920
that all of these annotations and scores

00:13:05,760 --> 00:13:13,200
are recorded permanently in a ledger

00:13:09,920 --> 00:13:17,040
you now have a great opportunity to

00:13:13,200 --> 00:13:20,560
satisfy any audits and prove

00:13:17,040 --> 00:13:22,399
compliance with regulations related to

00:13:20,560 --> 00:13:24,959
data

00:13:22,399 --> 00:13:26,320
so you know what we just heard about in

00:13:24,959 --> 00:13:29,839
our last talk

00:13:26,320 --> 00:13:32,880
data quality that could be one

00:13:29,839 --> 00:13:36,399
element of a confidence score

00:13:32,880 --> 00:13:39,440
did this piece of data go through

00:13:36,399 --> 00:13:42,320
quality checks before my application

00:13:39,440 --> 00:13:43,680
checked it all these things can be

00:13:42,320 --> 00:13:46,079
measured

00:13:43,680 --> 00:13:49,360
and checked for auditability during an

00:13:46,079 --> 00:13:52,560
audit process and then looking forward

00:13:49,360 --> 00:13:53,279
uh the place where we really feel that

00:13:52,560 --> 00:13:55,519
this

00:13:53,279 --> 00:13:57,279
project alvarium can be beneficial in

00:13:55,519 --> 00:14:00,800
the future

00:13:57,279 --> 00:14:04,880
is the use of data marketplaces

00:14:00,800 --> 00:14:06,480
so data marketplaces are on the rise

00:14:04,880 --> 00:14:09,440
and what we're seeing with data

00:14:06,480 --> 00:14:13,120
marketplaces is

00:14:09,440 --> 00:14:17,360
the ability to sell and buy

00:14:13,120 --> 00:14:21,040
data using cryptocurrency

00:14:17,360 --> 00:14:23,920
or other forms of payment and if

00:14:21,040 --> 00:14:25,120
we've been able to determine that the

00:14:23,920 --> 00:14:28,720
ledger

00:14:25,120 --> 00:14:30,480
contains a history and an ownership in a

00:14:28,720 --> 00:14:32,320
provenance of the data

00:14:30,480 --> 00:14:34,480
the theory is that this data would be

00:14:32,320 --> 00:14:37,839
more valuable if sold

00:14:34,480 --> 00:14:37,839
into a data marketplace

00:14:38,079 --> 00:14:43,120
so that's the presentation for today

00:14:41,360 --> 00:14:45,680
i'm going to stop sharing and we can

00:14:43,120 --> 00:14:48,959
take questions for either of us

00:14:45,680 --> 00:14:58,160
in the chat or the q a or

00:14:48,959 --> 00:14:58,160

YouTube URL: https://www.youtube.com/watch?v=BNbJC9yqyVU


