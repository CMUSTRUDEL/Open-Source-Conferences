Title: Apache Druid: Why Speed In Analytics Matters - Rommel Garcia
Publication date: 2020-12-11
Playlist: All Things Open 2020 - Big Data Track
Description: 
	Presented by: Rommel Garcia, Imply Data
Presented at All Things Open 2020 - Big Data Track

Abstract: Advertising auction, product pricing optimization, anomaly detection, network optimization and application monitoring all require an infrastructure that provides a low latency access to data so critical decisions can be made in a very short amount of time. Apache Druid is used as the backend for these use cases to empower users to analyze their data in realtime.  Rommel will be talking about the architecture, deployment model of Druid and how to tune it for performance.
Captions: 
	00:00:04,960 --> 00:00:09,599
thank you for joining

00:00:07,520 --> 00:00:11,519
so a little bit about myself i'm the

00:00:09,599 --> 00:00:12,639
head of partner engineering at imply

00:00:11,519 --> 00:00:15,679
i've been in implied

00:00:12,639 --> 00:00:19,520
for more than two years now but a

00:00:15,679 --> 00:00:23,039
majority of my experience pretty much

00:00:19,520 --> 00:00:27,119
is a combination of

00:00:23,039 --> 00:00:31,039
you know cloud optimizations in

00:00:27,119 --> 00:00:34,399
gcp and azure in aws

00:00:31,039 --> 00:00:36,000
even data warehouse and oil tp in all

00:00:34,399 --> 00:00:39,280
app in general

00:00:36,000 --> 00:00:41,120
and jvm performance tuning so about 10

00:00:39,280 --> 00:00:45,280
years of experience are pretty much

00:00:41,120 --> 00:00:49,039
focused on tuning applications to

00:00:45,280 --> 00:00:52,320
squeeze as much performance as i can get

00:00:49,039 --> 00:00:56,480
from these different applications

00:00:52,320 --> 00:01:00,800
um so you know speed is one thing that i

00:00:56,480 --> 00:01:04,000
really get excited about and

00:01:00,800 --> 00:01:07,439
the the trend in

00:01:04,000 --> 00:01:10,080
the big data space has been moving to

00:01:07,439 --> 00:01:11,280
a open source project you know called

00:01:10,080 --> 00:01:14,320
druid which we will

00:01:11,280 --> 00:01:18,080
dig deeper into it um

00:01:14,320 --> 00:01:19,040
but i'd like to you know show you guys

00:01:18,080 --> 00:01:22,320
here

00:01:19,040 --> 00:01:25,040
a set of three different

00:01:22,320 --> 00:01:26,560
um components of the overall

00:01:25,040 --> 00:01:30,799
presentation

00:01:26,560 --> 00:01:33,759
and starts with the real time decisions

00:01:30,799 --> 00:01:34,720
which touches on a lot of the different

00:01:33,759 --> 00:01:37,439
upcoming

00:01:34,720 --> 00:01:38,720
use cases that you might have heard of

00:01:37,439 --> 00:01:41,040
and some of them are already running

00:01:38,720 --> 00:01:43,840
production for a couple years

00:01:41,040 --> 00:01:45,280
and apache drew it as the tool to

00:01:43,840 --> 00:01:48,880
essentially empower

00:01:45,280 --> 00:01:51,119
those different real-time applications

00:01:48,880 --> 00:01:53,600
and then we'll dig deeper into its

00:01:51,119 --> 00:01:55,200
performance anatomy on why druid is such

00:01:53,600 --> 00:01:58,079
a good fit

00:01:55,200 --> 00:01:59,920
for real-time platforms to real-time

00:01:58,079 --> 00:02:02,799
applications that would require

00:01:59,920 --> 00:02:02,799
fast decisions

00:02:03,360 --> 00:02:08,000
all right so a lot of the organizations

00:02:06,560 --> 00:02:11,920
has been moving

00:02:08,000 --> 00:02:14,080
to a data-driven culture

00:02:11,920 --> 00:02:15,520
as you can see here at the bottom and

00:02:14,080 --> 00:02:18,560
this has been going on

00:02:15,520 --> 00:02:22,160
for you know at least eight

00:02:18,560 --> 00:02:24,080
years and organizations are still moving

00:02:22,160 --> 00:02:26,080
there because it takes a while

00:02:24,080 --> 00:02:28,000
for an organization to change the

00:02:26,080 --> 00:02:30,080
culture and if they don't want if they

00:02:28,000 --> 00:02:31,840
want to be data-driven it really starts

00:02:30,080 --> 00:02:33,200
from the top and then it you know goes

00:02:31,840 --> 00:02:37,920
at the bottom

00:02:33,200 --> 00:02:39,920
um and the majority of what

00:02:37,920 --> 00:02:41,120
they're looking at at this point since

00:02:39,920 --> 00:02:44,800
they have established

00:02:41,120 --> 00:02:48,400
you know all of their um data standards

00:02:44,800 --> 00:02:51,920
internally is making sense of that

00:02:48,400 --> 00:02:55,840
right and by making sense of that um

00:02:51,920 --> 00:02:57,920
the aai and machine learning workload

00:02:55,840 --> 00:03:01,920
has become so popular

00:02:57,920 --> 00:03:03,200
that it uh become a became the standard

00:03:01,920 --> 00:03:06,080
for

00:03:03,200 --> 00:03:06,959
really improving the business bottom

00:03:06,080 --> 00:03:08,879
line

00:03:06,959 --> 00:03:11,040
now the other thing too here as part of

00:03:08,879 --> 00:03:11,920
the equation is the real-time analytics

00:03:11,040 --> 00:03:13,920
which is very

00:03:11,920 --> 00:03:15,360
different from you know ai and machine

00:03:13,920 --> 00:03:19,519
learning

00:03:15,360 --> 00:03:22,080
real-time analytics is mainly driven by

00:03:19,519 --> 00:03:24,080
a lot of the use cases that we see today

00:03:22,080 --> 00:03:25,840
where data gets generated

00:03:24,080 --> 00:03:27,519
really really fast and on the fly and

00:03:25,840 --> 00:03:28,799
you have to analyze the data like

00:03:27,519 --> 00:03:32,159
immediately

00:03:28,799 --> 00:03:37,840
so it's a little bit different and all

00:03:32,159 --> 00:03:37,840
and both of these um approaches for

00:03:38,000 --> 00:03:43,599
analyzing the data eventually helps

00:03:41,680 --> 00:03:45,440
a lot of the analysts and business

00:03:43,599 --> 00:03:48,080
stakeholders to make

00:03:45,440 --> 00:03:48,560
decisions that are revenue generating so

00:03:48,080 --> 00:03:52,560
so this

00:03:48,560 --> 00:03:55,760
is the the trend that we're seeing in

00:03:52,560 --> 00:03:58,840
the basic foundation really for

00:03:55,760 --> 00:04:00,239
organizations to be successful in their

00:03:58,840 --> 00:04:02,480
business

00:04:00,239 --> 00:04:04,560
so we're going to focus on the real-time

00:04:02,480 --> 00:04:07,200
analytics piece of things um so

00:04:04,560 --> 00:04:08,879
one use case that you see here is the

00:04:07,200 --> 00:04:10,640
smart transportation

00:04:08,879 --> 00:04:12,400
um you know trucks in the old days you

00:04:10,640 --> 00:04:15,760
really don't have sensors right but

00:04:12,400 --> 00:04:16,639
um now they're putting a lot of sensors

00:04:15,760 --> 00:04:19,519
into it

00:04:16,639 --> 00:04:20,959
uh not just the refrigeration system but

00:04:19,519 --> 00:04:24,080
you know also the tires

00:04:20,959 --> 00:04:27,600
and um rigging the

00:04:24,080 --> 00:04:30,880
truck to have a gps information

00:04:27,600 --> 00:04:34,000
and then measuring how fast the truck is

00:04:30,880 --> 00:04:37,040
going um humidity and temperature

00:04:34,000 --> 00:04:39,759
freight monitoring and so on right so

00:04:37,040 --> 00:04:41,600
all of these information are actually

00:04:39,759 --> 00:04:45,199
generated in real time

00:04:41,600 --> 00:04:47,840
and then that information then gets

00:04:45,199 --> 00:04:49,919
sent to the back office so that the all

00:04:47,840 --> 00:04:53,280
of this real-time information can be

00:04:49,919 --> 00:04:55,919
analyzed immediately so

00:04:53,280 --> 00:04:56,720
the value essentially that organizations

00:04:55,919 --> 00:04:59,919
can get

00:04:56,720 --> 00:05:02,479
from this kind of setup especially on

00:04:59,919 --> 00:05:04,240
you know like trucking companies or in

00:05:02,479 --> 00:05:07,440
supply chain business

00:05:04,240 --> 00:05:10,639
is to maximize

00:05:07,440 --> 00:05:13,600
the usage of their assets

00:05:10,639 --> 00:05:14,639
you know on the road by routing them to

00:05:13,600 --> 00:05:17,680
the fastest route

00:05:14,639 --> 00:05:20,560
and also avoiding any kind of spoilage

00:05:17,680 --> 00:05:21,759
that the truck is carrying on its

00:05:20,560 --> 00:05:24,320
payload

00:05:21,759 --> 00:05:26,000
that's got refrigeration system into it

00:05:24,320 --> 00:05:27,199
and then for safety purposes as well

00:05:26,000 --> 00:05:29,199
right so now

00:05:27,199 --> 00:05:30,560
tire pressures can be measured as well

00:05:29,199 --> 00:05:31,440
and then there could be trends that can

00:05:30,560 --> 00:05:34,560
be

00:05:31,440 --> 00:05:37,759
uh either predicted or

00:05:34,560 --> 00:05:38,800
identified where um you know trying to

00:05:37,759 --> 00:05:41,039
avoid any kind of like

00:05:38,800 --> 00:05:42,800
accident because you see all this truck

00:05:41,039 --> 00:05:45,759
sometimes starts just blowing out

00:05:42,800 --> 00:05:47,600
and so before they do based on this data

00:05:45,759 --> 00:05:49,680
you can alert the driver and say hey

00:05:47,600 --> 00:05:50,880
um looks like you might need to change

00:05:49,680 --> 00:05:53,440
your tire

00:05:50,880 --> 00:05:54,320
soon before it blows up for safety

00:05:53,440 --> 00:05:57,120
reasons

00:05:54,320 --> 00:05:58,319
so um smart transportation is becoming a

00:05:57,120 --> 00:06:00,960
reality

00:05:58,319 --> 00:06:01,600
in a smart city as well australia has

00:06:00,960 --> 00:06:06,000
done this

00:06:01,600 --> 00:06:07,919
and some other cities as well and

00:06:06,000 --> 00:06:10,319
it is really putting the intelligence at

00:06:07,919 --> 00:06:14,319
a hyper local base within the city

00:06:10,319 --> 00:06:17,919
um perfect example is uh smart you know

00:06:14,319 --> 00:06:20,800
smart buses where um

00:06:17,919 --> 00:06:22,000
these buses are pretty much electric in

00:06:20,800 --> 00:06:27,840
nature

00:06:22,000 --> 00:06:30,400
and based on information around the city

00:06:27,840 --> 00:06:31,440
for traffic information then that bus

00:06:30,400 --> 00:06:33,919
can be

00:06:31,440 --> 00:06:34,720
you know rerouted on a path where

00:06:33,919 --> 00:06:38,000
there's a

00:06:34,720 --> 00:06:39,039
list traffic on it and especially this

00:06:38,000 --> 00:06:42,080
uh

00:06:39,039 --> 00:06:45,919
bus is um uh

00:06:42,080 --> 00:06:49,360
driverless right um and another thing

00:06:45,919 --> 00:06:53,199
uh when a sports event happens

00:06:49,360 --> 00:06:56,880
um where uh near the arena

00:06:53,199 --> 00:07:00,880
you have this um you know pedestrian

00:06:56,880 --> 00:07:03,120
signals right and

00:07:00,880 --> 00:07:03,919
this pedestal signals can be actually

00:07:03,120 --> 00:07:07,759
converted as

00:07:03,919 --> 00:07:10,080
a parking space and so that signal

00:07:07,759 --> 00:07:10,960
can be dynamic in terms of display

00:07:10,080 --> 00:07:14,960
information

00:07:10,960 --> 00:07:18,240
where before event happens at the arena

00:07:14,960 --> 00:07:21,520
that could be a pedestrian signal

00:07:18,240 --> 00:07:22,960
but then once sports event happens there

00:07:21,520 --> 00:07:25,039
then they could change that into like a

00:07:22,960 --> 00:07:28,080
parking signal

00:07:25,039 --> 00:07:31,759
so a lot of information um

00:07:28,080 --> 00:07:35,440
are gathered in real time and

00:07:31,759 --> 00:07:37,520
the goal for the city itself is to

00:07:35,440 --> 00:07:39,360
provide safety for the citizens and

00:07:37,520 --> 00:07:40,880
enable citizens to communicate

00:07:39,360 --> 00:07:43,199
with the government by via this

00:07:40,880 --> 00:07:46,639
infrastructure in real time

00:07:43,199 --> 00:07:50,319
and then optimizing really any kind of

00:07:46,639 --> 00:07:53,360
resources that the the city has

00:07:50,319 --> 00:07:56,800
um smart homes is another um

00:07:53,360 --> 00:07:59,199
residue is a company who is essentially

00:07:56,800 --> 00:08:01,840
a leader in the smart home intelligence

00:07:59,199 --> 00:08:02,560
space or smart home in general where

00:08:01,840 --> 00:08:06,160
they provide

00:08:02,560 --> 00:08:09,840
sensors to you know detect water leak or

00:08:06,160 --> 00:08:11,360
carbon monoxide levels um smart switches

00:08:09,840 --> 00:08:13,680
and so on right so there's a lot of

00:08:11,360 --> 00:08:17,280
sensors that goes into the house now

00:08:13,680 --> 00:08:19,199
and so homeowners have the ability to

00:08:17,280 --> 00:08:20,720
download the app and look at

00:08:19,199 --> 00:08:22,160
all of these different readings that

00:08:20,720 --> 00:08:24,319
comes from all of these sensors for

00:08:22,160 --> 00:08:26,080
safety purposes

00:08:24,319 --> 00:08:29,120
and they can be alerted if the carbon

00:08:26,080 --> 00:08:32,240
monoxide goes to a level where it's

00:08:29,120 --> 00:08:35,120
becoming more of a threat to them

00:08:32,240 --> 00:08:36,479
at home and so this kind of real-time

00:08:35,120 --> 00:08:40,000
data is very useful

00:08:36,479 --> 00:08:43,360
for the homeowners um

00:08:40,000 --> 00:08:45,200
another is the industrial 4.0

00:08:43,360 --> 00:08:47,120
revolution i used to work for perkin

00:08:45,200 --> 00:08:49,680
element of electronics

00:08:47,120 --> 00:08:50,800
uh where it was responsible for building

00:08:49,680 --> 00:08:53,920
circuit boards for

00:08:50,800 --> 00:08:55,120
space shuttle back in the day and um

00:08:53,920 --> 00:08:58,080
everything was uh

00:08:55,120 --> 00:08:59,040
pretty much manual at that point where

00:08:58,080 --> 00:09:02,000
uh at anger

00:08:59,040 --> 00:09:04,399
at every single step of the process in a

00:09:02,000 --> 00:09:06,880
production line you have an operator

00:09:04,399 --> 00:09:09,040
doing things assembling things and

00:09:06,880 --> 00:09:12,160
checking for

00:09:09,040 --> 00:09:13,680
parameters that would actually uh make

00:09:12,160 --> 00:09:16,080
like a quality check

00:09:13,680 --> 00:09:18,000
for that product that the operator had

00:09:16,080 --> 00:09:19,200
you know put together and pass it on to

00:09:18,000 --> 00:09:21,440
different operator

00:09:19,200 --> 00:09:23,120
this stage is fully you know automated

00:09:21,440 --> 00:09:25,600
and there are a lot of sensors

00:09:23,120 --> 00:09:26,480
that are rigged into the production line

00:09:25,600 --> 00:09:28,640
and so

00:09:26,480 --> 00:09:30,800
these sensors are then responsible for

00:09:28,640 --> 00:09:32,720
emitting all of the information

00:09:30,800 --> 00:09:35,519
and this information can be then

00:09:32,720 --> 00:09:38,640
analyzed in a way where

00:09:35,519 --> 00:09:42,320
it can be trended to a yield so yield is

00:09:38,640 --> 00:09:44,800
just a uh foundation for

00:09:42,320 --> 00:09:45,519
measuring how effective the production

00:09:44,800 --> 00:09:47,120
line is

00:09:45,519 --> 00:09:48,640
in terms of producing good quality

00:09:47,120 --> 00:09:51,839
products so if you have

00:09:48,640 --> 00:09:54,959
you know if you put in 100

00:09:51,839 --> 00:09:55,440
parts and you expect it to produce you

00:09:54,959 --> 00:09:57,519
know

00:09:55,440 --> 00:09:58,800
10 parts or 10 products out of the

00:09:57,519 --> 00:10:02,320
production line

00:09:58,800 --> 00:10:04,399
and then um five of the products

00:10:02,320 --> 00:10:06,880
are pretty much the defected then that's

00:10:04,399 --> 00:10:10,240
like 50 yield and they don't want that

00:10:06,880 --> 00:10:13,600
and so uh the ability to detect um

00:10:10,240 --> 00:10:16,800
trends where the the yield um

00:10:13,600 --> 00:10:18,240
goes down or even before it goes down um

00:10:16,800 --> 00:10:20,800
can be averted

00:10:18,240 --> 00:10:22,560
by you know having this information at

00:10:20,800 --> 00:10:25,360
the tip of the fingers

00:10:22,560 --> 00:10:26,800
for plant managers to take a look at and

00:10:25,360 --> 00:10:29,600
start

00:10:26,800 --> 00:10:32,079
necessary you know making changes

00:10:29,600 --> 00:10:33,680
necessary to prevent

00:10:32,079 --> 00:10:36,560
the production line producing more

00:10:33,680 --> 00:10:36,560
defective products

00:10:36,800 --> 00:10:40,560
another thing here is the you know from

00:10:39,360 --> 00:10:44,240
financial space

00:10:40,560 --> 00:10:46,720
anti-money laundering and

00:10:44,240 --> 00:10:47,440
there are organizations banks is to be

00:10:46,720 --> 00:10:52,720
specific

00:10:47,440 --> 00:10:55,680
using applications like druid to

00:10:52,720 --> 00:10:57,920
detect if there are some transactions

00:10:55,680 --> 00:11:02,480
that are anomalous in nature

00:10:57,920 --> 00:11:02,480
and what banks will do is decrease

00:11:02,959 --> 00:11:09,040
false positives and also

00:11:06,160 --> 00:11:10,959
false negative and be more accurate in

00:11:09,040 --> 00:11:13,600
terms of

00:11:10,959 --> 00:11:14,720
identifying what transactions are

00:11:13,600 --> 00:11:18,160
actually

00:11:14,720 --> 00:11:20,240
anomalous um from a security space

00:11:18,160 --> 00:11:22,399
uh you have you know your typical

00:11:20,240 --> 00:11:27,519
compliance and fraud as well

00:11:22,399 --> 00:11:30,880
um and obviously security is such a

00:11:27,519 --> 00:11:33,760
a big initiative for each

00:11:30,880 --> 00:11:36,000
organizations and that's because of uh

00:11:33,760 --> 00:11:39,120
one protecting the reputation

00:11:36,000 --> 00:11:42,399
and then also um either

00:11:39,120 --> 00:11:44,800
reducing fines um

00:11:42,399 --> 00:11:46,240
or completely eliminating fines by

00:11:44,800 --> 00:11:49,519
complying to

00:11:46,240 --> 00:11:50,399
all of the standards that the public and

00:11:49,519 --> 00:11:53,200
private

00:11:50,399 --> 00:11:54,720
organizations are putting place for

00:11:53,200 --> 00:11:56,639
companies especially in the financial

00:11:54,720 --> 00:11:58,880
space so um

00:11:56,639 --> 00:12:01,200
all of the events that are pretty much

00:11:58,880 --> 00:12:03,040
coming into organizations are

00:12:01,200 --> 00:12:05,440
measured in real time analyzed in real

00:12:03,040 --> 00:12:07,839
time to detect any kind of

00:12:05,440 --> 00:12:09,360
um you know fraud activity that are

00:12:07,839 --> 00:12:13,040
happening

00:12:09,360 --> 00:12:15,760
including crime crime through right so

00:12:13,040 --> 00:12:17,839
we talked about smart city earlier and

00:12:15,760 --> 00:12:19,920
one thing that smart city can do as well

00:12:17,839 --> 00:12:21,440
from our crime perspective is enable all

00:12:19,920 --> 00:12:22,399
the cameras that they have along the

00:12:21,440 --> 00:12:25,519
road

00:12:22,399 --> 00:12:28,480
and then based on giving a video feed

00:12:25,519 --> 00:12:29,839
they can analyze that if a certain event

00:12:28,480 --> 00:12:32,720
that would lead to a crime

00:12:29,839 --> 00:12:32,720
might happen soon

00:12:33,200 --> 00:12:37,680
and this uh uh you know this digital

00:12:35,920 --> 00:12:38,079
marketing space has been around for a

00:12:37,680 --> 00:12:41,440
while

00:12:38,079 --> 00:12:43,120
but it's also a big driver for a lot of

00:12:41,440 --> 00:12:46,240
the real-time analytics there

00:12:43,120 --> 00:12:50,399
so you have your typical advertising

00:12:46,240 --> 00:12:53,519
um social media live streaming and so on

00:12:50,399 --> 00:12:54,399
all of this different information uh

00:12:53,519 --> 00:12:58,639
requires

00:12:54,399 --> 00:13:00,880
real-time analytics as well and so

00:12:58,639 --> 00:13:02,639
all of these different use cases are

00:13:00,880 --> 00:13:04,959
real time in nature

00:13:02,639 --> 00:13:06,320
and so we're seeing this strand of

00:13:04,959 --> 00:13:09,440
organizations start

00:13:06,320 --> 00:13:10,240
using druid as their next generation

00:13:09,440 --> 00:13:14,000
platform

00:13:10,240 --> 00:13:14,800
to enable them to analyze data in real

00:13:14,000 --> 00:13:18,480
time

00:13:14,800 --> 00:13:21,760
so let's go ahead and drill down into

00:13:18,480 --> 00:13:24,959
what drew it is so druid is

00:13:21,760 --> 00:13:26,399
a um you know high performance analytics

00:13:24,959 --> 00:13:29,040
data store

00:13:26,399 --> 00:13:29,920
uh event driven data it's you know whole

00:13:29,040 --> 00:13:31,519
a whole

00:13:29,920 --> 00:13:34,079
a lot of words in there but if we break

00:13:31,519 --> 00:13:37,200
that down into four parts

00:13:34,079 --> 00:13:40,959
high performance really is uh

00:13:37,200 --> 00:13:44,560
giving you a very very very locally

00:13:40,959 --> 00:13:45,839
latency even in the millisecond strain

00:13:44,560 --> 00:13:48,959
so it's very

00:13:45,839 --> 00:13:51,519
doable to get double digit millisecond

00:13:48,959 --> 00:13:53,040
and up to you know a couple hundred

00:13:51,519 --> 00:13:54,399
milliseconds and that's like the sweet

00:13:53,040 --> 00:13:56,160
spot for druid

00:13:54,399 --> 00:13:57,519
and then high interest rates where you

00:13:56,160 --> 00:14:00,320
can ingest um

00:13:57,519 --> 00:14:00,959
data even you know millions per second

00:14:00,320 --> 00:14:04,320
if

00:14:00,959 --> 00:14:06,000
if you want to so it's analytics data

00:14:04,320 --> 00:14:07,360
store which is actually columnar

00:14:06,000 --> 00:14:09,519
database

00:14:07,360 --> 00:14:11,680
and then you can do your typical

00:14:09,519 --> 00:14:15,760
counting ranking

00:14:11,680 --> 00:14:16,560
group by and time trending and it's a

00:14:15,760 --> 00:14:20,079
data store

00:14:16,560 --> 00:14:23,360
which means that you have a

00:14:20,079 --> 00:14:25,360
cluster that stores copy of your data

00:14:23,360 --> 00:14:27,839
so that all of the processing are done

00:14:25,360 --> 00:14:29,440
locally and with shared nutting

00:14:27,839 --> 00:14:32,880
architecture

00:14:29,440 --> 00:14:35,440
event driven data as we saw

00:14:32,880 --> 00:14:37,279
earlier from the different use cases

00:14:35,440 --> 00:14:39,519
that's the sweet spot

00:14:37,279 --> 00:14:41,199
for druid you have your typical click

00:14:39,519 --> 00:14:45,120
stream netflows data

00:14:41,199 --> 00:14:49,199
digital marketing server metrics for apm

00:14:45,120 --> 00:14:49,199
in an iot and user behavior as well

00:14:49,680 --> 00:14:56,399
key features you can ingest data from

00:14:52,880 --> 00:14:58,639
kafka or kinesis there are other

00:14:56,399 --> 00:14:59,680
areas where you can also ingest in real

00:14:58,639 --> 00:15:02,720
time

00:14:59,680 --> 00:15:03,920
you can also backload from hadoop and s3

00:15:02,720 --> 00:15:07,040
and pre-aggregate

00:15:03,920 --> 00:15:09,199
your data upon ingest but you can also

00:15:07,040 --> 00:15:12,399
do aggregation on the fly

00:15:09,199 --> 00:15:14,240
if that is needed on your data

00:15:12,399 --> 00:15:16,399
it's very schema-like you only have to

00:15:14,240 --> 00:15:20,240
deal with one table

00:15:16,399 --> 00:15:22,560
that's how druid actually stores data

00:15:20,240 --> 00:15:23,839
so you have a denormalized table and

00:15:22,560 --> 00:15:27,120
that table could have

00:15:23,839 --> 00:15:28,639
you know a couple of columns to multiple

00:15:27,120 --> 00:15:29,920
thousands even up to two thousand

00:15:28,639 --> 00:15:33,440
columns

00:15:29,920 --> 00:15:35,759
um ad-hoc queries and then

00:15:33,440 --> 00:15:37,440
doing the exact and approximate

00:15:35,759 --> 00:15:39,839
algorithms

00:15:37,440 --> 00:15:41,600
especially in the add text space

00:15:39,839 --> 00:15:43,759
approximate algorithms are

00:15:41,600 --> 00:15:46,000
fairly useful and that's because the

00:15:43,759 --> 00:15:48,720
data that's coming from the web

00:15:46,000 --> 00:15:50,320
for advertising purposes this very high

00:15:48,720 --> 00:15:54,079
cardinality data

00:15:50,320 --> 00:15:57,440
and so it's really hard for analysts to

00:15:54,079 --> 00:15:59,519
do an exact um function

00:15:57,440 --> 00:16:01,759
on very high carbon another data that

00:15:59,519 --> 00:16:03,519
would require a very low latency

00:16:01,759 --> 00:16:05,279
query on that data and so approximate

00:16:03,519 --> 00:16:08,480
algorithms are there

00:16:05,279 --> 00:16:10,800
even giving you the ability to do

00:16:08,480 --> 00:16:12,079
between you know two to three percent um

00:16:10,800 --> 00:16:14,000
error rate which is really

00:16:12,079 --> 00:16:16,320
pretty good because the standard in the

00:16:14,000 --> 00:16:18,639
statistics is 95

00:16:16,320 --> 00:16:20,399
confidence levels so even if you have

00:16:18,639 --> 00:16:22,560
five percent error rate um

00:16:20,399 --> 00:16:23,600
the the data or the information you're

00:16:22,560 --> 00:16:26,240
getting is still

00:16:23,600 --> 00:16:27,440
pretty good and then you can keep a lot

00:16:26,240 --> 00:16:30,560
of history of data

00:16:27,440 --> 00:16:34,000
even years um so

00:16:30,560 --> 00:16:37,759
these are the key features that um

00:16:34,000 --> 00:16:42,000
kinesis can or imply or

00:16:37,759 --> 00:16:46,720
i'm sorry druid can give you

00:16:42,000 --> 00:16:50,320
um the uh

00:16:46,720 --> 00:16:52,240
the really the heart of druid is

00:16:50,320 --> 00:16:53,600
based on the intersection of these three

00:16:52,240 --> 00:16:55,759
different products

00:16:53,600 --> 00:16:57,199
you have your time series databases data

00:16:55,759 --> 00:17:00,639
warehouses

00:16:57,199 --> 00:17:03,440
and then search systems the

00:17:00,639 --> 00:17:04,959
time series databases are great they

00:17:03,440 --> 00:17:08,959
have their own purpose

00:17:04,959 --> 00:17:10,959
um but typically we the challenges there

00:17:08,959 --> 00:17:12,640
is that it's it's really hard to scale

00:17:10,959 --> 00:17:15,520
them horizontally

00:17:12,640 --> 00:17:16,720
and then you can only look at a subset

00:17:15,520 --> 00:17:19,120
of the data

00:17:16,720 --> 00:17:20,079
but druid has borrowed how time series

00:17:19,120 --> 00:17:24,160
databases

00:17:20,079 --> 00:17:25,919
functions uh for analyzing the data

00:17:24,160 --> 00:17:28,319
in another piece to this are the data

00:17:25,919 --> 00:17:31,520
warehouses where

00:17:28,319 --> 00:17:32,240
a lot of the all up type processing also

00:17:31,520 --> 00:17:35,280
exists

00:17:32,240 --> 00:17:39,600
in druid so we're borrowing

00:17:35,280 --> 00:17:41,600
um a lot of the typical

00:17:39,600 --> 00:17:43,520
way of accessing data you know that

00:17:41,600 --> 00:17:44,960
you're typically used to from there data

00:17:43,520 --> 00:17:47,840
or greenplum or even

00:17:44,960 --> 00:17:48,960
cloud data warehouses like snowflake and

00:17:47,840 --> 00:17:51,679
google bigquery

00:17:48,960 --> 00:17:53,679
and then search systems um you know they

00:17:51,679 --> 00:17:57,919
they're great for what they do

00:17:53,679 --> 00:18:01,039
but once you start doing a heavy

00:17:57,919 --> 00:18:03,679
analysis of your data from uh

00:18:01,039 --> 00:18:04,400
all ups type all of type analysis

00:18:03,679 --> 00:18:07,760
analysis

00:18:04,400 --> 00:18:11,440
then um your you know

00:18:07,760 --> 00:18:11,440
the system starts uh really

00:18:11,679 --> 00:18:17,200
have a hard time doing the work of

00:18:15,600 --> 00:18:20,240
finishing the query

00:18:17,200 --> 00:18:22,799
really really quick so

00:18:20,240 --> 00:18:24,880
druid borrows also some of this

00:18:22,799 --> 00:18:26,640
capabilities that search system has and

00:18:24,880 --> 00:18:29,200
package them into one

00:18:26,640 --> 00:18:30,960
and then really enable organizations to

00:18:29,200 --> 00:18:32,320
query a large amount of data even in the

00:18:30,960 --> 00:18:35,520
petabytes range

00:18:32,320 --> 00:18:38,799
and so um so this is

00:18:35,520 --> 00:18:40,840
the trend that we're seeing as well from

00:18:38,799 --> 00:18:44,400
organizations where

00:18:40,840 --> 00:18:47,440
um the the need

00:18:44,400 --> 00:18:49,520
to not only use all of type processing

00:18:47,440 --> 00:18:52,480
like your typical you know

00:18:49,520 --> 00:18:54,400
group by counting and ranking but you

00:18:52,480 --> 00:18:55,520
want to also search on a particular

00:18:54,400 --> 00:18:58,080
dimension

00:18:55,520 --> 00:18:59,760
and then add on top of that your query

00:18:58,080 --> 00:19:01,679
and then doing some time functions as

00:18:59,760 --> 00:19:02,799
well on top of that so that's a very

00:19:01,679 --> 00:19:06,000
typical

00:19:02,799 --> 00:19:07,600
um way of accessing that we're seeing

00:19:06,000 --> 00:19:11,520
from a lot of these new real-time

00:19:07,600 --> 00:19:14,559
systems that are coming up

00:19:11,520 --> 00:19:16,960
so let's dig in into the performance

00:19:14,559 --> 00:19:18,799
anatomy and just quickly checking here

00:19:16,960 --> 00:19:19,280
if there are any other questions so let

00:19:18,799 --> 00:19:21,760
me know

00:19:19,280 --> 00:19:23,919
finish if you have if you see anything

00:19:21,760 --> 00:19:27,280
in here

00:19:23,919 --> 00:19:27,840
so really the heart of the performance

00:19:27,280 --> 00:19:31,120
of

00:19:27,840 --> 00:19:34,640
druid lies in how it stores the data

00:19:31,120 --> 00:19:36,320
or creates the data so

00:19:34,640 --> 00:19:38,000
there's what we call segment and this is

00:19:36,320 --> 00:19:41,360
immutable and this represents

00:19:38,000 --> 00:19:44,720
the the data that lives in druid

00:19:41,360 --> 00:19:47,760
it's time partition for fast reading

00:19:44,720 --> 00:19:50,640
and then it's a bitmap index

00:19:47,760 --> 00:19:51,360
so all of the strings that are in the

00:19:50,640 --> 00:19:54,640
records

00:19:51,360 --> 00:19:57,520
are actually index using bitmap

00:19:54,640 --> 00:19:58,640
and the advantage of using bitmap is

00:19:57,520 --> 00:20:00,559
that

00:19:58,640 --> 00:20:02,480
you can compress them really really good

00:20:00,559 --> 00:20:03,520
even reaching up to 10 to 15 times

00:20:02,480 --> 00:20:05,360
compression

00:20:03,520 --> 00:20:06,640
but at the same time operate it as

00:20:05,360 --> 00:20:09,760
they're compressed

00:20:06,640 --> 00:20:11,200
operate in in bits as opposed to true

00:20:09,760 --> 00:20:13,600
value so

00:20:11,200 --> 00:20:14,799
so that really gives you the speed of

00:20:13,600 --> 00:20:18,080
computation

00:20:14,799 --> 00:20:22,080
and then you prune before you also

00:20:18,080 --> 00:20:25,840
compute your data so um so this indexes

00:20:22,080 --> 00:20:28,400
then becomes the the engine to

00:20:25,840 --> 00:20:29,120
prune quickly any records that shouldn't

00:20:28,400 --> 00:20:31,919
be read

00:20:29,120 --> 00:20:33,440
and processed uh based on given filters

00:20:31,919 --> 00:20:34,000
that are provided in the query which i

00:20:33,440 --> 00:20:37,440
will show you

00:20:34,000 --> 00:20:39,280
an example later on dictionary encoding

00:20:37,440 --> 00:20:42,000
is also another one where we avoid

00:20:39,280 --> 00:20:44,880
unnecessary string manipulation

00:20:42,000 --> 00:20:45,840
and so you'll see this encoding you know

00:20:44,880 --> 00:20:48,799
in numbers

00:20:45,840 --> 00:20:49,360
as opposed to manipulating it in strings

00:20:48,799 --> 00:20:52,720
because

00:20:49,360 --> 00:20:54,480
string manipulation is very heavy and so

00:20:52,720 --> 00:20:56,799
dictionary encoding really helps us with

00:20:54,480 --> 00:20:59,600
the crease speed as well

00:20:56,799 --> 00:21:00,480
and obviously the segment is compressed

00:20:59,600 --> 00:21:02,240
we will be

00:21:00,480 --> 00:21:03,600
written to this really really fast and

00:21:02,240 --> 00:21:06,159
then you can read

00:21:03,600 --> 00:21:07,120
as well really really fast so this is

00:21:06,159 --> 00:21:10,159
the

00:21:07,120 --> 00:21:12,000
basic building block of how druid

00:21:10,159 --> 00:21:14,640
performs really well from a query

00:21:12,000 --> 00:21:14,640
perspective

00:21:14,960 --> 00:21:21,520
the optimal uh segment size is

00:21:18,240 --> 00:21:24,960
around 700 nb and the way

00:21:21,520 --> 00:21:28,320
how this size

00:21:24,960 --> 00:21:31,679
affects performance is uh pretty immense

00:21:28,320 --> 00:21:32,480
so the way how do it works is um it

00:21:31,679 --> 00:21:36,159
spawns

00:21:32,480 --> 00:21:39,120
one thread per segment and that thread

00:21:36,159 --> 00:21:42,000
will then scan that 700 mbf data

00:21:39,120 --> 00:21:43,840
and the scanning could go from you know

00:21:42,000 --> 00:21:45,600
less than one millisecond to double

00:21:43,840 --> 00:21:46,400
digit milliseconds it's really really

00:21:45,600 --> 00:21:49,280
fast

00:21:46,400 --> 00:21:49,679
and so we wouldn't want to waste a cycle

00:21:49,280 --> 00:21:53,360
of

00:21:49,679 --> 00:21:54,799
reading a lot of small um segment sizes

00:21:53,360 --> 00:21:56,559
because that would then reduce your

00:21:54,799 --> 00:22:00,640
computational bandwidth

00:21:56,559 --> 00:22:03,039
and then also choking the jvm

00:22:00,640 --> 00:22:04,000
so this is the best size for each

00:22:03,039 --> 00:22:08,720
segment

00:22:04,000 --> 00:22:08,720
for optimal jvm utilization as well

00:22:08,880 --> 00:22:12,480
so peeling back the onion more here this

00:22:12,080 --> 00:22:15,360
is

00:22:12,480 --> 00:22:16,880
you know how a segment looks like from a

00:22:15,360 --> 00:22:20,320
record perspective

00:22:16,880 --> 00:22:23,120
so we have about five dimensions here

00:22:20,320 --> 00:22:24,000
and um we have a couple of string

00:22:23,120 --> 00:22:28,159
dimensions

00:22:24,000 --> 00:22:31,280
and some numbers so all of the records

00:22:28,159 --> 00:22:33,520
actually have time stamp in long

00:22:31,280 --> 00:22:36,080
and then all of the strings which are

00:22:33,520 --> 00:22:39,200
arctis and city are actually

00:22:36,080 --> 00:22:41,280
index by default and then

00:22:39,200 --> 00:22:44,080
you can see in here that there are three

00:22:41,280 --> 00:22:45,039
blocks of information that represents a

00:22:44,080 --> 00:22:48,240
string

00:22:45,039 --> 00:22:51,600
the data itself which are

00:22:48,240 --> 00:22:52,720
pretty much encoded and then the mapping

00:22:51,600 --> 00:22:54,799
of the

00:22:52,720 --> 00:22:55,919
encoded data with the dictionary as you

00:22:54,799 --> 00:22:58,640
can see here

00:22:55,919 --> 00:23:00,320
an example which is some of the artists

00:22:58,640 --> 00:23:03,039
that we see justin bieber

00:23:00,320 --> 00:23:04,640
and you have zero representation so the

00:23:03,039 --> 00:23:07,840
first two records here actually

00:23:04,640 --> 00:23:10,640
justin bieber's and then we have the

00:23:07,840 --> 00:23:12,720
index so the index is pretty much

00:23:10,640 --> 00:23:13,600
relative to the position of our record

00:23:12,720 --> 00:23:16,240
in the dictionary

00:23:13,600 --> 00:23:17,440
so this arrangement is pretty much

00:23:16,240 --> 00:23:20,000
exactly

00:23:17,440 --> 00:23:20,640
how it's laid out here on the index

00:23:20,000 --> 00:23:22,640
block

00:23:20,640 --> 00:23:23,679
so the first the record is actually

00:23:22,640 --> 00:23:26,720
justin's

00:23:23,679 --> 00:23:29,520
um so you have your

00:23:26,720 --> 00:23:30,799
index uh key here and then your filter

00:23:29,520 --> 00:23:33,679
information

00:23:30,799 --> 00:23:34,720
um same thing with the city since you

00:23:33,679 --> 00:23:39,200
can see here

00:23:34,720 --> 00:23:42,240
you have three different cities and then

00:23:39,200 --> 00:23:43,360
the price is actually representative of

00:23:42,240 --> 00:23:46,159
the

00:23:43,360 --> 00:23:47,279
total price with the number of tickets

00:23:46,159 --> 00:23:50,720
sold

00:23:47,279 --> 00:23:54,480
for a particular artist in a given city

00:23:50,720 --> 00:23:58,720
so let's take a look for example here

00:23:54,480 --> 00:23:59,919
a query so we have a very simple query

00:23:58,720 --> 00:24:03,200
that pretty much

00:23:59,919 --> 00:24:07,440
selects the city and groups by city

00:24:03,200 --> 00:24:10,799
based on the total price

00:24:07,440 --> 00:24:14,960
for a given concert in a given city by

00:24:10,799 --> 00:24:18,320
a specific artist in this case justin

00:24:14,960 --> 00:24:21,200
and so what happens is once that

00:24:18,320 --> 00:24:22,880
query runs what do it does first is look

00:24:21,200 --> 00:24:26,320
at the where clause

00:24:22,880 --> 00:24:28,960
and then maps the the artist

00:24:26,320 --> 00:24:30,799
based on the given value and so it will

00:24:28,960 --> 00:24:33,200
look at this column

00:24:30,799 --> 00:24:35,440
and then goes to the very first record

00:24:33,200 --> 00:24:39,600
here in the index information

00:24:35,440 --> 00:24:43,120
and then grabs all of that and

00:24:39,600 --> 00:24:46,720
the key right here that you see

00:24:43,120 --> 00:24:49,840
is actually representative of the

00:24:46,720 --> 00:24:53,360
city as well which is zero one and two

00:24:49,840 --> 00:24:56,880
um and so uh what query what

00:24:53,360 --> 00:24:59,039
druid does in this query is uh once it

00:24:56,880 --> 00:25:03,520
runs

00:24:59,039 --> 00:25:06,880
we have the uh information on the city

00:25:03,520 --> 00:25:10,159
and then also the prices uh

00:25:06,880 --> 00:25:12,320
for those cities based on

00:25:10,159 --> 00:25:14,400
you know the tickets that were sold and

00:25:12,320 --> 00:25:17,679
in this case we see

00:25:14,400 --> 00:25:20,960
um you know dc la

00:25:17,679 --> 00:25:24,240
and san francisco um there's

00:25:20,960 --> 00:25:28,159
really no value for dc

00:25:24,240 --> 00:25:31,520
and so we only have um the

00:25:28,159 --> 00:25:34,880
prices for la and san francisco

00:25:31,520 --> 00:25:38,240
and this result actually uh

00:25:34,880 --> 00:25:40,400
lives uh off heap and

00:25:38,240 --> 00:25:41,559
what jewelry does is it that's what we

00:25:40,400 --> 00:25:45,200
call late

00:25:41,559 --> 00:25:48,960
materialization which means that

00:25:45,200 --> 00:25:48,960
it would only actually

00:25:49,279 --> 00:25:54,159
need the real value of the data once

00:25:52,480 --> 00:25:55,679
it's done with the computation and send

00:25:54,159 --> 00:25:56,000
it back to the calling client just so

00:25:55,679 --> 00:25:58,960
they can

00:25:56,000 --> 00:26:01,039
see it in in a text form so in this case

00:25:58,960 --> 00:26:04,720
it's still operating on the

00:26:01,039 --> 00:26:06,799
dictionary encoding but once it's uh

00:26:04,720 --> 00:26:08,559
completely done with all of the

00:26:06,799 --> 00:26:11,679
computation

00:26:08,559 --> 00:26:14,320
it would swap the

00:26:11,679 --> 00:26:15,840
dictionary encoding with the real value

00:26:14,320 --> 00:26:17,520
and then don't do anything with this you

00:26:15,840 --> 00:26:20,000
will actually drop that

00:26:17,520 --> 00:26:21,679
and then send it over back to the

00:26:20,000 --> 00:26:25,520
calling client

00:26:21,679 --> 00:26:28,720
um so uh so that's how

00:26:25,520 --> 00:26:30,320
the query actually executes uh with this

00:26:28,720 --> 00:26:34,400
particular record

00:26:30,320 --> 00:26:36,559
and the uh

00:26:34,400 --> 00:26:38,720
uh the other thing that i'd like to

00:26:36,559 --> 00:26:42,960
point out here is

00:26:38,720 --> 00:26:46,080
the data which is including

00:26:42,960 --> 00:26:47,200
all of these data dictionary indexes are

00:26:46,080 --> 00:26:49,760
actually

00:26:47,200 --> 00:26:50,320
residing in memory along with this price

00:26:49,760 --> 00:26:54,080
and

00:26:50,320 --> 00:26:56,880
counts as well um dictionaries on heap

00:26:54,080 --> 00:26:58,240
but the data indexes are actually

00:26:56,880 --> 00:27:01,360
off-heap

00:26:58,240 --> 00:27:04,960
um so driven memory maps that data

00:27:01,360 --> 00:27:07,440
so that can be accessed faster and then

00:27:04,960 --> 00:27:08,559
adding on top of that its ability to use

00:27:07,440 --> 00:27:12,159
dictionary encoding

00:27:08,559 --> 00:27:12,159
indexes makes it even better

00:27:12,240 --> 00:27:19,919
so this is the architecture of druid and

00:27:16,080 --> 00:27:23,039
we have a couple of different

00:27:19,919 --> 00:27:25,679
services here and as you can see here

00:27:23,039 --> 00:27:28,559
master server the coordinator and apache

00:27:25,679 --> 00:27:31,679
zookeeper are responsible for

00:27:28,559 --> 00:27:33,919
monitoring the

00:27:31,679 --> 00:27:36,559
overall health of the cluster and also

00:27:33,919 --> 00:27:39,039
managing the segments so coordinator

00:27:36,559 --> 00:27:40,399
is responsible for managing that segment

00:27:39,039 --> 00:27:43,600
so it has to

00:27:40,399 --> 00:27:45,679
know where the segment lives

00:27:43,600 --> 00:27:48,320
across the different services here on

00:27:45,679 --> 00:27:50,320
the data server tier

00:27:48,320 --> 00:27:52,399
so the data server right here is where

00:27:50,320 --> 00:27:55,760
all of the segments are actually

00:27:52,399 --> 00:27:56,880
stored and generated so if we look at

00:27:55,760 --> 00:28:00,240
through the right side you have

00:27:56,880 --> 00:28:02,320
streaming data and batch data

00:28:00,240 --> 00:28:03,919
this streaming data for example you know

00:28:02,320 --> 00:28:06,480
if it's coming from uh

00:28:03,919 --> 00:28:07,120
apache kafka the index are responsible

00:28:06,480 --> 00:28:08,720
for

00:28:07,120 --> 00:28:11,440
receiving all of that data and then

00:28:08,720 --> 00:28:13,360
generating the the segments and then

00:28:11,440 --> 00:28:15,679
publishing that segment over to the dip

00:28:13,360 --> 00:28:16,159
storage which is your long-term storage

00:28:15,679 --> 00:28:19,039
um

00:28:16,159 --> 00:28:19,840
and this is typically you know your s3

00:28:19,039 --> 00:28:22,480
or

00:28:19,840 --> 00:28:24,080
gcs or azure blood storage or azure data

00:28:22,480 --> 00:28:27,840
lake

00:28:24,080 --> 00:28:30,640
and once all of the segments are in here

00:28:27,840 --> 00:28:32,559
then an announcement is made by the

00:28:30,640 --> 00:28:34,640
coordinator

00:28:32,559 --> 00:28:37,200
passing in that information to the

00:28:34,640 --> 00:28:39,200
historicals and historicals will then

00:28:37,200 --> 00:28:41,039
receive the segments or pull the

00:28:39,200 --> 00:28:43,760
segments from deep storage

00:28:41,039 --> 00:28:44,799
and make it available for querying and

00:28:43,760 --> 00:28:48,080
so the broker

00:28:44,799 --> 00:28:50,559
is just a service that fronting all of

00:28:48,080 --> 00:28:54,399
the clients receiving all of this query

00:28:50,559 --> 00:28:54,799
and the broker has information on all of

00:28:54,399 --> 00:28:57,279
the

00:28:54,799 --> 00:28:58,559
segments and where they live across the

00:28:57,279 --> 00:29:01,919
data servers

00:28:58,559 --> 00:29:02,480
so that it knows where to actually send

00:29:01,919 --> 00:29:06,000
over

00:29:02,480 --> 00:29:09,120
the the queries

00:29:06,000 --> 00:29:12,480
so indexer also

00:29:09,120 --> 00:29:14,960
serves as a layer of

00:29:12,480 --> 00:29:17,039
providing real-time information because

00:29:14,960 --> 00:29:18,880
some queries might say hey i want all of

00:29:17,039 --> 00:29:21,760
the data

00:29:18,880 --> 00:29:23,840
that are from the last you know minute

00:29:21,760 --> 00:29:26,559
or even the last second

00:29:23,840 --> 00:29:27,600
and so that data will come from the

00:29:26,559 --> 00:29:30,240
indexer

00:29:27,600 --> 00:29:32,000
and then any other data would come from

00:29:30,240 --> 00:29:35,360
the historical

00:29:32,000 --> 00:29:37,760
so deep storage pretty much serves as a

00:29:35,360 --> 00:29:39,520
place where your data is protected

00:29:37,760 --> 00:29:41,440
and then you with the combination of

00:29:39,520 --> 00:29:44,960
your master server and this storage

00:29:41,440 --> 00:29:46,480
even if your cluster is totally busted

00:29:44,960 --> 00:29:48,240
and you can recover from it

00:29:46,480 --> 00:29:50,960
as long as you have your disk storage

00:29:48,240 --> 00:29:54,720
and your master service

00:29:50,960 --> 00:29:57,120
then uh in general um

00:29:54,720 --> 00:29:58,640
the uh when i say master service here is

00:29:57,120 --> 00:30:00,480
the uh

00:29:58,640 --> 00:30:02,720
the meta store layer which is uh not

00:30:00,480 --> 00:30:03,039
shown um so the meta store is part of

00:30:02,720 --> 00:30:04,960
the

00:30:03,039 --> 00:30:07,039
master service so as long as your meta

00:30:04,960 --> 00:30:10,159
store and your dip storage

00:30:07,039 --> 00:30:10,799
are actually protected and live and

00:30:10,159 --> 00:30:13,120
running

00:30:10,799 --> 00:30:14,080
then you can rebuild your cluster from

00:30:13,120 --> 00:30:16,159
scratch and point

00:30:14,080 --> 00:30:17,520
this cluster to the dip storage and to

00:30:16,159 --> 00:30:19,679
the meta store

00:30:17,520 --> 00:30:20,720
and you're back in business so it's very

00:30:19,679 --> 00:30:23,039
resilient

00:30:20,720 --> 00:30:24,080
and it takes care of both streaming and

00:30:23,039 --> 00:30:26,159
batch data

00:30:24,080 --> 00:30:27,520
and also allowing you to query data from

00:30:26,159 --> 00:30:30,480
you know the last second

00:30:27,520 --> 00:30:31,760
um i've seen organizations even creating

00:30:30,480 --> 00:30:34,840
it but in milliseconds

00:30:31,760 --> 00:30:37,760
and then up to a week so it's very very

00:30:34,840 --> 00:30:40,320
flexible

00:30:37,760 --> 00:30:41,840
and from a ingest architecture

00:30:40,320 --> 00:30:45,200
perspective

00:30:41,840 --> 00:30:47,520
we have overlord is really

00:30:45,200 --> 00:30:49,760
a service where it starts everything so

00:30:47,520 --> 00:30:53,200
once a

00:30:49,760 --> 00:30:56,240
task is submitted over overlord

00:30:53,200 --> 00:30:57,360
has it over through the indexer indexer

00:30:56,240 --> 00:31:00,799
has what we call the

00:30:57,360 --> 00:31:01,360
pions that are responsible for capturing

00:31:00,799 --> 00:31:05,039
data

00:31:01,360 --> 00:31:07,360
from a queue in this case

00:31:05,039 --> 00:31:08,559
some example is kafka it would pull all

00:31:07,360 --> 00:31:11,360
of that data

00:31:08,559 --> 00:31:13,600
and then creates the segment files and

00:31:11,360 --> 00:31:16,720
then

00:31:13,600 --> 00:31:19,440
once those are created then it will

00:31:16,720 --> 00:31:22,640
publish it through the dip storage

00:31:19,440 --> 00:31:24,480
and once that is published a state

00:31:22,640 --> 00:31:26,720
is actually written to the metadata

00:31:24,480 --> 00:31:28,559
store that says these are the set of

00:31:26,720 --> 00:31:30,960
segments that were created

00:31:28,559 --> 00:31:33,200
and published to the dip storage and

00:31:30,960 --> 00:31:34,480
then um the met the coordinate

00:31:33,200 --> 00:31:37,840
coordinator will then

00:31:34,480 --> 00:31:39,200
uh and it pulls the metadata store

00:31:37,840 --> 00:31:41,279
and as soon as it sees that there are

00:31:39,200 --> 00:31:42,080
new segments there you'd make an

00:31:41,279 --> 00:31:44,840
announcement

00:31:42,080 --> 00:31:46,799
to historicals and say hey store girls

00:31:44,840 --> 00:31:48,960
um we have these

00:31:46,799 --> 00:31:50,399
segments that are available now for you

00:31:48,960 --> 00:31:53,919
to actually get

00:31:50,399 --> 00:31:57,440
so you can expose it to be read

00:31:53,919 --> 00:31:59,279
and executed um and so historic also

00:31:57,440 --> 00:32:00,159
then go to the div storage and grab all

00:31:59,279 --> 00:32:02,320
of those

00:32:00,159 --> 00:32:04,320
segments and then all of the segments

00:32:02,320 --> 00:32:07,360
will then be available in store calls

00:32:04,320 --> 00:32:10,640
and they would be used for

00:32:07,360 --> 00:32:14,320
querying purposes uh

00:32:10,640 --> 00:32:17,200
query flow this is a

00:32:14,320 --> 00:32:18,880
uh i know this is an eye chart there's a

00:32:17,200 --> 00:32:20,960
lot of moving parts in here

00:32:18,880 --> 00:32:22,000
um but let's start at the bottom left

00:32:20,960 --> 00:32:25,840
here which is the

00:32:22,000 --> 00:32:29,039
segment and as we discussed earlier um

00:32:25,840 --> 00:32:30,640
you know that's uh pretty much the basic

00:32:29,039 --> 00:32:34,000
foundation of all performance

00:32:30,640 --> 00:32:35,519
in druid but this segment is actually

00:32:34,000 --> 00:32:39,120
memory mapped from disk

00:32:35,519 --> 00:32:42,399
into uh off-heap ram

00:32:39,120 --> 00:32:44,559
on the historical servers or data nodes

00:32:42,399 --> 00:32:47,600
is what we call it

00:32:44,559 --> 00:32:51,039
so the

00:32:47,600 --> 00:32:52,000
the segments are then loaded into offhip

00:32:51,039 --> 00:32:55,279
memory

00:32:52,000 --> 00:32:58,000
and available for reading

00:32:55,279 --> 00:32:58,880
by the queries that are being submitted

00:32:58,000 --> 00:33:01,440
by

00:32:58,880 --> 00:33:04,080
the broker which is also same as the

00:33:01,440 --> 00:33:07,279
query notes here

00:33:04,080 --> 00:33:10,000
the thing to note here is that the

00:33:07,279 --> 00:33:12,000
segments actually belong to a table

00:33:10,000 --> 00:33:13,679
which is a denormalized table so these

00:33:12,000 --> 00:33:17,120
segments could be spread out into

00:33:13,679 --> 00:33:20,799
multiple historicals or data nodes

00:33:17,120 --> 00:33:21,440
that make up one table so once data is

00:33:20,799 --> 00:33:25,519
in there

00:33:21,440 --> 00:33:27,919
then that will be available for querying

00:33:25,519 --> 00:33:28,880
and so when a query happens um query

00:33:27,919 --> 00:33:32,960
submitted over

00:33:28,880 --> 00:33:36,320
to uh the broker or query nodes

00:33:32,960 --> 00:33:39,679
and then within

00:33:36,320 --> 00:33:40,640
the broker or query node we have this

00:33:39,679 --> 00:33:43,760
concept of

00:33:40,640 --> 00:33:47,519
uh lanes and lanes are

00:33:43,760 --> 00:33:50,240
essentially a a guard

00:33:47,519 --> 00:33:51,120
against other queries that are running

00:33:50,240 --> 00:33:55,120
within

00:33:51,120 --> 00:33:58,000
the same box so that no other query

00:33:55,120 --> 00:34:00,159
is actually using more resources than

00:33:58,000 --> 00:34:03,760
they are allotted to use

00:34:00,159 --> 00:34:06,159
and so that would really enforce the

00:34:03,760 --> 00:34:07,360
enforcer guarantee the sla for the

00:34:06,159 --> 00:34:10,159
particular

00:34:07,360 --> 00:34:12,000
query that was submitted and so once

00:34:10,159 --> 00:34:15,599
query submitted

00:34:12,000 --> 00:34:18,399
over to the broker query nodes then

00:34:15,599 --> 00:34:20,240
it would actually split that query based

00:34:18,399 --> 00:34:22,480
on where the segments are

00:34:20,240 --> 00:34:23,679
so in this case very simplified you know

00:34:22,480 --> 00:34:26,639
we have two

00:34:23,679 --> 00:34:28,480
historicals or data nodes and then data

00:34:26,639 --> 00:34:33,040
nodes would then

00:34:28,480 --> 00:34:36,399
receive the segment ids

00:34:33,040 --> 00:34:40,639
and then read those segments

00:34:36,399 --> 00:34:44,079
from memory uh and enforcing as well

00:34:40,639 --> 00:34:47,200
uh query laning uh to guarantee

00:34:44,079 --> 00:34:49,839
the sla for that particular query and

00:34:47,200 --> 00:34:49,839
then

00:34:50,000 --> 00:34:55,919
once it reads the segments and then

00:34:53,440 --> 00:34:58,400
prunes it and then it's got what is

00:34:55,919 --> 00:35:01,119
needed to essentially compute the data

00:34:58,400 --> 00:35:03,680
then it would apply a vectorization on

00:35:01,119 --> 00:35:06,640
the

00:35:03,680 --> 00:35:08,800
query which means as supposed to reading

00:35:06,640 --> 00:35:11,359
one wrote a time it would take

00:35:08,800 --> 00:35:12,640
um a thousand or ten thousand and that's

00:35:11,359 --> 00:35:14,000
configurable

00:35:12,640 --> 00:35:16,079
so that you can apply the same

00:35:14,000 --> 00:35:17,280
computation on a big block of robots as

00:35:16,079 --> 00:35:20,000
opposed to one

00:35:17,280 --> 00:35:21,680
which also helps with performance and

00:35:20,000 --> 00:35:24,880
then

00:35:21,680 --> 00:35:27,359
it would use the buffer

00:35:24,880 --> 00:35:28,960
for all of the intermediate compute and

00:35:27,359 --> 00:35:30,079
then once the intermediate the

00:35:28,960 --> 00:35:33,040
computations are done

00:35:30,079 --> 00:35:34,560
it would cache the result for that

00:35:33,040 --> 00:35:38,400
subqueries

00:35:34,560 --> 00:35:40,320
and then once it's cast it would use an

00:35:38,400 --> 00:35:43,599
office memory to store

00:35:40,320 --> 00:35:44,000
all of the result sets and shoot it over

00:35:43,599 --> 00:35:47,760
back

00:35:44,000 --> 00:35:49,760
to the query node or broker nodes

00:35:47,760 --> 00:35:52,400
and same thing for the other data nodes

00:35:49,760 --> 00:35:57,520
as well and so once the query nodes

00:35:52,400 --> 00:36:00,480
receive the results from this

00:35:57,520 --> 00:36:01,119
different data nodes then it would do

00:36:00,480 --> 00:36:03,680
what we call

00:36:01,119 --> 00:36:06,160
parallel merging so there are multiple

00:36:03,680 --> 00:36:08,880
threads that's responsible for

00:36:06,160 --> 00:36:11,200
combining all of these records and then

00:36:08,880 --> 00:36:14,000
applying the aggregation

00:36:11,200 --> 00:36:16,000
and then once that's done uh they would

00:36:14,000 --> 00:36:19,280
also cash the result

00:36:16,000 --> 00:36:21,359
and then the result stays

00:36:19,280 --> 00:36:22,960
off and then sends it back to the

00:36:21,359 --> 00:36:26,880
calling client

00:36:22,960 --> 00:36:27,440
now the cluster that i'm showing you

00:36:26,880 --> 00:36:31,280
here

00:36:27,440 --> 00:36:34,880
um is on tier one we have this

00:36:31,280 --> 00:36:38,240
concept in druid called tiering where

00:36:34,880 --> 00:36:41,200
you can partition a cluster into several

00:36:38,240 --> 00:36:42,880
parts where the first part could be for

00:36:41,200 --> 00:36:45,040
you know high speed query

00:36:42,880 --> 00:36:46,079
which you call tier one and then another

00:36:45,040 --> 00:36:47,920
tier for

00:36:46,079 --> 00:36:50,480
you know slower queries and not interior

00:36:47,920 --> 00:36:51,680
for maybe very very cold queries where

00:36:50,480 --> 00:36:52,800
they don't even care when the query

00:36:51,680 --> 00:36:56,240
comes back

00:36:52,800 --> 00:36:57,680
um so you have a partition all right

00:36:56,240 --> 00:37:00,720
this one's literally have 10 minutes

00:36:57,680 --> 00:37:03,280
remaining thank you

00:37:00,720 --> 00:37:05,440
so so partitioning ordering is

00:37:03,280 --> 00:37:09,599
essentially a way to segment

00:37:05,440 --> 00:37:12,320
the cluster to make sure that

00:37:09,599 --> 00:37:13,920
you have also guaranteed resources

00:37:12,320 --> 00:37:17,119
available to support

00:37:13,920 --> 00:37:18,960
slas across different queries there are

00:37:17,119 --> 00:37:19,680
also other computational strategies that

00:37:18,960 --> 00:37:22,960
you can use

00:37:19,680 --> 00:37:25,200
like approximate algorithm quantiles

00:37:22,960 --> 00:37:26,160
status sketches and so on are there for

00:37:25,200 --> 00:37:28,400
you to use

00:37:26,160 --> 00:37:30,320
this is shared mounting architecture

00:37:28,400 --> 00:37:32,720
it's distributed in nature

00:37:30,320 --> 00:37:34,800
the biggest cluster that i have seen so

00:37:32,720 --> 00:37:37,200
far is about 2000 nodes

00:37:34,800 --> 00:37:38,400
and very high concurrency you can even

00:37:37,200 --> 00:37:41,440
do it by the thousandths

00:37:38,400 --> 00:37:43,280
of a concurrent query per second

00:37:41,440 --> 00:37:45,200
and then total isolation between read

00:37:43,280 --> 00:37:47,040
and write so you can actually

00:37:45,200 --> 00:37:48,480
write while also querying the data at

00:37:47,040 --> 00:37:51,839
the same time which is very hard to do

00:37:48,480 --> 00:37:51,839

YouTube URL: https://www.youtube.com/watch?v=QkQhFYIM21Y


