Title: Multi-Cluster Kubernetes and Service Mesh Patterns - Christian Posta
Publication date: 2020-12-10
Playlist: All Things Open 2020 - Linux Infrastructure Track
Description: 
	Presented by: Christian Posta, Solo.io
Presented at All Things Open 2020 - Linux/Infrastructure Track

Abstract: Building applications for cloud-native infrastructure that are resilient, scalable, secure, and meet compliance and IT objectives gets complicated. Another wrinkle for the organizations with which we work is the fact they need to run across a hybrid deployment footprint, not just Kubernetes. At Solo.io, we build application networking technology on Envoy Proxy that helps solve difficult multi-deployment, multi-cluster, and even multi-mesh problems.

In this webinar, we’re going to explore different options and patterns for building secure, scalable, resilient applications using technology like Kubernetes and Service Mesh without leaving behind existing IT investments. We’ll see why and when to use multi-cluster topologies, how to build for high availability and team autonomy, and solve for things like service discovery, identity federation, traffic routing, and access control.

This talk will cover:
- Multi-cluster design patterns with Kubernetes and Service Mesh
- Service discovery across a hybrid environment
- Identity federation, including SPIFFE, in a multi-cluster world
- Emerging technology to help simplify multi-cluster and multi-mesh architectures
Captions: 
	00:00:05,040 --> 00:00:07,759
thank you

00:00:05,839 --> 00:00:09,120
uh tyler and thanks red hat for

00:00:07,759 --> 00:00:11,840
sponsoring

00:00:09,120 --> 00:00:13,040
and thank you all for joining this uh

00:00:11,840 --> 00:00:14,320
this session where we're going to talk

00:00:13,040 --> 00:00:17,440
about

00:00:14,320 --> 00:00:18,640
service mesh and multi-cluster

00:00:17,440 --> 00:00:21,600
multi-deployment

00:00:18,640 --> 00:00:23,519
of of the service mesh and we're going

00:00:21,600 --> 00:00:26,560
to go through this

00:00:23,519 --> 00:00:28,160
from a uh like like what are the

00:00:26,560 --> 00:00:30,560
problems that we're trying to solve

00:00:28,160 --> 00:00:31,840
type lens and we'll look at some of the

00:00:30,560 --> 00:00:35,040
foundational pieces

00:00:31,840 --> 00:00:36,640
of how one would solve this and where

00:00:35,040 --> 00:00:40,640
the service mesh comes in

00:00:36,640 --> 00:00:43,680
and provides value

00:00:40,640 --> 00:00:45,200
so let's get started um we're gonna

00:00:43,680 --> 00:00:47,120
we're gonna have a demo at the end

00:00:45,200 --> 00:00:50,559
please ask your questions in the

00:00:47,120 --> 00:00:53,600
in the q a section of

00:00:50,559 --> 00:00:54,960
the the zoom meeting here and uh

00:00:53,600 --> 00:00:57,039
just to give you a little background my

00:00:54,960 --> 00:01:00,320
name is christian i

00:00:57,039 --> 00:01:02,480
work at a startup called solo.io

00:01:00,320 --> 00:01:03,840
i used to work at red hat i was the

00:01:02,480 --> 00:01:07,200
chief architect of

00:01:03,840 --> 00:01:09,840
cloud native application architecture

00:01:07,200 --> 00:01:10,960
and that's right around when some of the

00:01:09,840 --> 00:01:14,080
service mesh

00:01:10,960 --> 00:01:14,799
stuff started to come out i worked with

00:01:14,080 --> 00:01:16,720
the large

00:01:14,799 --> 00:01:19,520
customers at red hat and now here at

00:01:16,720 --> 00:01:21,840
solo adopting cloud native technology

00:01:19,520 --> 00:01:23,360
going to microservices style

00:01:21,840 --> 00:01:26,560
architectures

00:01:23,360 --> 00:01:27,840
and more recently i guess recently in

00:01:26,560 --> 00:01:31,119
the last three years

00:01:27,840 --> 00:01:32,159
um working with uh some of the the next

00:01:31,119 --> 00:01:34,720
gen

00:01:32,159 --> 00:01:36,400
application networking technology like

00:01:34,720 --> 00:01:38,000
like service match so i've written a few

00:01:36,400 --> 00:01:39,119
books on this on these topics i'm in the

00:01:38,000 --> 00:01:41,600
middle of writing

00:01:39,119 --> 00:01:43,680
istio in action which i've been writing

00:01:41,600 --> 00:01:46,240
for a couple years now but is

00:01:43,680 --> 00:01:48,320
more recently taking a little bit more

00:01:46,240 --> 00:01:49,280
momentum so i think i feel really good

00:01:48,320 --> 00:01:50,720
about uh

00:01:49,280 --> 00:01:52,560
the quality in the direction of the book

00:01:50,720 --> 00:01:54,640
now it should come out hopefully in the

00:01:52,560 --> 00:01:58,960
in the spring

00:01:54,640 --> 00:02:01,840
so at solo so i i joined solo

00:01:58,960 --> 00:02:04,399
a couple almost two years ago and the

00:02:01,840 --> 00:02:07,520
reason i did that is because i thought

00:02:04,399 --> 00:02:10,560
that building large-scale

00:02:07,520 --> 00:02:12,160
cloud native app applications and these

00:02:10,560 --> 00:02:14,000
microservice architectures and so forth

00:02:12,160 --> 00:02:16,879
deploying across multiple

00:02:14,000 --> 00:02:19,280
clusters multiple availability zones

00:02:16,879 --> 00:02:21,040
geographically distributed and so on

00:02:19,280 --> 00:02:22,319
to maintain things like high

00:02:21,040 --> 00:02:24,239
availability

00:02:22,319 --> 00:02:26,239
the main things maintain things like

00:02:24,239 --> 00:02:28,160
localized message processing and data

00:02:26,239 --> 00:02:30,480
processing and so on

00:02:28,160 --> 00:02:31,360
failover and and being able to withstand

00:02:30,480 --> 00:02:34,720
those things

00:02:31,360 --> 00:02:36,640
that to me was a much bigger problem

00:02:34,720 --> 00:02:39,440
that i was interested in

00:02:36,640 --> 00:02:40,640
working with customers to solve than

00:02:39,440 --> 00:02:42,560
just saying

00:02:40,640 --> 00:02:44,560
you know service mesh is a check the box

00:02:42,560 --> 00:02:48,080
for a particular platform

00:02:44,560 --> 00:02:51,040
and at solo we

00:02:48,080 --> 00:02:52,720
work with organizations to be able to to

00:02:51,040 --> 00:02:55,120
do that and so this ties into

00:02:52,720 --> 00:02:56,400
the rest of my talk is the the part that

00:02:55,120 --> 00:02:57,200
we're going to be talking about today is

00:02:56,400 --> 00:03:00,080
sort of

00:02:57,200 --> 00:03:01,599
in the middle uh between where people

00:03:00,080 --> 00:03:03,040
get started and they might start

00:03:01,599 --> 00:03:06,080
adopting some of this

00:03:03,040 --> 00:03:08,080
technology you know deploying containers

00:03:06,080 --> 00:03:09,680
deploying into kubernetes and then once

00:03:08,080 --> 00:03:11,280
you've deployed your containers these

00:03:09,680 --> 00:03:13,920
services need to talk with each other

00:03:11,280 --> 00:03:16,080
right so on the far left side of this

00:03:13,920 --> 00:03:18,959
slide we see

00:03:16,080 --> 00:03:20,560
that you know people people starting to

00:03:18,959 --> 00:03:23,200
adopt this will start with

00:03:20,560 --> 00:03:23,760
envoy proxy start with a gateway and so

00:03:23,200 --> 00:03:25,920
on the

00:03:23,760 --> 00:03:28,000
they'll slowly move out into a more

00:03:25,920 --> 00:03:28,400
scaled architecture and might be looking

00:03:28,000 --> 00:03:30,640
at

00:03:28,400 --> 00:03:32,560
things like service mesh and and so on

00:03:30,640 --> 00:03:36,560
and then there's things beyond that

00:03:32,560 --> 00:03:39,920
uh being able to extend the service mesh

00:03:36,560 --> 00:03:42,319
being able to program your network um

00:03:39,920 --> 00:03:43,519
and building controllers and so on to be

00:03:42,319 --> 00:03:45,760
able to

00:03:43,519 --> 00:03:47,120
automatically respond when there's

00:03:45,760 --> 00:03:48,879
security intrusion

00:03:47,120 --> 00:03:50,720
or there's uh you know you're doing a

00:03:48,879 --> 00:03:52,319
new release or you need to do some

00:03:50,720 --> 00:03:54,000
advanced debugging and so on

00:03:52,319 --> 00:03:55,040
so the service mesh and these

00:03:54,000 --> 00:03:56,560
capabilities that we're going to be

00:03:55,040 --> 00:03:57,920
talking about in general but what we're

00:03:56,560 --> 00:04:00,799
doing in solo

00:03:57,920 --> 00:04:01,840
is specifically geared toward how do you

00:04:00,799 --> 00:04:04,239
how do you get the most

00:04:01,840 --> 00:04:05,680
out of your your network and abstract

00:04:04,239 --> 00:04:08,640
that so that you can

00:04:05,680 --> 00:04:10,720
uh build higher value on top of that and

00:04:08,640 --> 00:04:13,599
so it's all that kind of looks like

00:04:10,720 --> 00:04:16,239
uh from the edge so we heavily invested

00:04:13,599 --> 00:04:18,400
in envoy proxy we think onboard proxy is

00:04:16,239 --> 00:04:20,400
the correct technology on which to build

00:04:18,400 --> 00:04:21,199
this and that comes in the form of

00:04:20,400 --> 00:04:24,479
gateways

00:04:21,199 --> 00:04:26,000
service mesh and of course running this

00:04:24,479 --> 00:04:27,840
in a real enterprise

00:04:26,000 --> 00:04:29,199
you need some level of management

00:04:27,840 --> 00:04:30,960
federation especially across

00:04:29,199 --> 00:04:33,759
geographically distributed

00:04:30,960 --> 00:04:35,360
systems being able to extend it with

00:04:33,759 --> 00:04:37,280
things like web assembly

00:04:35,360 --> 00:04:39,280
and then of course being able to derive

00:04:37,280 --> 00:04:40,639
value out of those services and apis

00:04:39,280 --> 00:04:43,440
that are running in it

00:04:40,639 --> 00:04:44,639
so that's what that's why i left and

00:04:43,440 --> 00:04:46,880
went to solo and

00:04:44,639 --> 00:04:48,479
that's sort of my passion and where i

00:04:46,880 --> 00:04:51,120
work with customers and that

00:04:48,479 --> 00:04:52,000
is also contributing to some of the

00:04:51,120 --> 00:04:53,919
patterns and

00:04:52,000 --> 00:04:55,440
things that we talk about today in this

00:04:53,919 --> 00:04:58,720
session

00:04:55,440 --> 00:05:00,960
so let's take a step back and

00:04:58,720 --> 00:05:02,000
build up to what the the problem really

00:05:00,960 --> 00:05:04,639
is here

00:05:02,000 --> 00:05:05,440
as we go to build micro service install

00:05:04,639 --> 00:05:07,440
architectures

00:05:05,440 --> 00:05:08,639
and we might and we want to do that in

00:05:07,440 --> 00:05:11,600
certain cases

00:05:08,639 --> 00:05:12,240
as an optimization for teams to be able

00:05:11,600 --> 00:05:14,479
to move

00:05:12,240 --> 00:05:15,520
faster and deliver software faster how

00:05:14,479 --> 00:05:18,240
can they move

00:05:15,520 --> 00:05:19,440
without having to synchronize without

00:05:18,240 --> 00:05:22,880
having to

00:05:19,440 --> 00:05:24,639
um you know change a bunch of different

00:05:22,880 --> 00:05:25,600
services all at once how can they just

00:05:24,639 --> 00:05:28,400
focus on their

00:05:25,600 --> 00:05:29,680
particular part of the pie and and move

00:05:28,400 --> 00:05:32,720
independently

00:05:29,680 --> 00:05:35,520
but when we start to break down services

00:05:32,720 --> 00:05:37,520
and teams and processes and

00:05:35,520 --> 00:05:40,479
organizations around this

00:05:37,520 --> 00:05:42,639
more self-service and sort of ownership

00:05:40,479 --> 00:05:44,560
of services

00:05:42,639 --> 00:05:46,080
we start to create more services and

00:05:44,560 --> 00:05:48,240
more teams and

00:05:46,080 --> 00:05:50,160
we have a lot more to manage and deal

00:05:48,240 --> 00:05:51,919
with but

00:05:50,160 --> 00:05:53,440
just the services them taught themselves

00:05:51,919 --> 00:05:54,240
when they're communicating talking with

00:05:53,440 --> 00:05:57,520
each other

00:05:54,240 --> 00:05:59,919
it creates a lot more complexity and

00:05:57,520 --> 00:06:01,680
opportunities for failure between these

00:05:59,919 --> 00:06:05,199
services than we've had

00:06:01,680 --> 00:06:08,479
previously and so that's where

00:06:05,199 --> 00:06:09,680
the service mesh technology fits and

00:06:08,479 --> 00:06:11,039
then the problems that it's trying to

00:06:09,680 --> 00:06:13,919
solve

00:06:11,039 --> 00:06:15,280
is how do we have these these smart

00:06:13,919 --> 00:06:17,280
proxies or these

00:06:15,280 --> 00:06:18,880
enhancements of the application without

00:06:17,280 --> 00:06:21,680
the application even knowing

00:06:18,880 --> 00:06:23,280
to kind of solve some of the challenges

00:06:21,680 --> 00:06:26,080
of communicating over the network

00:06:23,280 --> 00:06:27,199
and doing that securely and doing that

00:06:26,080 --> 00:06:28,880
reliably

00:06:27,199 --> 00:06:31,520
and doing that in a way that can be

00:06:28,880 --> 00:06:32,160
observed so that when things start to go

00:06:31,520 --> 00:06:35,120
wrong

00:06:32,160 --> 00:06:37,840
you can quickly figure that out and know

00:06:35,120 --> 00:06:39,680
where to look and and start debugging

00:06:37,840 --> 00:06:41,520
so there's various service mesh

00:06:39,680 --> 00:06:45,199
implementations

00:06:41,520 --> 00:06:47,199
that you'll find there the interesting

00:06:45,199 --> 00:06:48,639
common thread between these mesh

00:06:47,199 --> 00:06:50,160
implementations at least the ones that

00:06:48,639 --> 00:06:52,720
we show here

00:06:50,160 --> 00:06:53,919
is that they've adopted a particular

00:06:52,720 --> 00:06:57,199
pattern

00:06:53,919 --> 00:06:58,160
and a particular technology to be that

00:06:57,199 --> 00:07:01,360
smart

00:06:58,160 --> 00:07:02,319
proxy or that that extension to your

00:07:01,360 --> 00:07:05,680
applications

00:07:02,319 --> 00:07:09,199
so let's take a look at what that is so

00:07:05,680 --> 00:07:12,639
in the service mesh deployment what we

00:07:09,199 --> 00:07:15,039
what we do is we inject a

00:07:12,639 --> 00:07:16,000
a proxy or an agent that lives with the

00:07:15,039 --> 00:07:18,800
application

00:07:16,000 --> 00:07:20,319
itself and when the application tries to

00:07:18,800 --> 00:07:23,759
talk out over the network

00:07:20,319 --> 00:07:26,319
it's this proxy that's responsible for

00:07:23,759 --> 00:07:27,360
or or is where we implement the

00:07:26,319 --> 00:07:30,880
capabilities

00:07:27,360 --> 00:07:33,120
of a secure observable reliable network

00:07:30,880 --> 00:07:34,400
and so in this model the traffic is

00:07:33,120 --> 00:07:36,639
going through the proxy

00:07:34,400 --> 00:07:38,479
and then going to the outside world the

00:07:36,639 --> 00:07:40,800
proxy can capture telemetry

00:07:38,479 --> 00:07:42,400
that proxy can enforce things like

00:07:40,800 --> 00:07:43,759
timeouts and retries and circuit

00:07:42,400 --> 00:07:46,960
breaking policies

00:07:43,759 --> 00:07:47,759
it can do things like enabling mutual

00:07:46,960 --> 00:07:50,639
tls

00:07:47,759 --> 00:07:52,160
between uh the services that are

00:07:50,639 --> 00:07:54,400
communicating

00:07:52,160 --> 00:07:55,840
i can do authorization checks and that

00:07:54,400 --> 00:07:59,280
kind of thing

00:07:55,840 --> 00:08:01,759
and so when you build a a topology where

00:07:59,280 --> 00:08:04,639
all of the application instances have

00:08:01,759 --> 00:08:06,560
this smart proxy living next to it

00:08:04,639 --> 00:08:07,759
then you know it starts to form a

00:08:06,560 --> 00:08:09,759
communications

00:08:07,759 --> 00:08:13,919
mesh so that's where the term service

00:08:09,759 --> 00:08:17,599
mesh comes from service mesh technology

00:08:13,919 --> 00:08:20,960
typically provides a a

00:08:17,599 --> 00:08:22,400
a set of capabilities around things like

00:08:20,960 --> 00:08:24,720
service discovery

00:08:22,400 --> 00:08:26,160
so in this model when app on the left

00:08:24,720 --> 00:08:27,039
side is trying to talk to the app on the

00:08:26,160 --> 00:08:28,639
right side

00:08:27,039 --> 00:08:30,879
it's the proxy that actually knows where

00:08:28,639 --> 00:08:32,800
those apps live right

00:08:30,879 --> 00:08:34,800
so we have service discovery load

00:08:32,800 --> 00:08:37,120
client-side load balancing

00:08:34,800 --> 00:08:37,919
we can do things like end-to-end

00:08:37,120 --> 00:08:40,159
identity

00:08:37,919 --> 00:08:41,440
verification and encryption of the

00:08:40,159 --> 00:08:44,000
transport

00:08:41,440 --> 00:08:44,959
we can control the traffic routing

00:08:44,000 --> 00:08:47,519
between

00:08:44,959 --> 00:08:48,160
the different services because we have

00:08:47,519 --> 00:08:50,880
this

00:08:48,160 --> 00:08:51,519
this smart proxy and smart agent between

00:08:50,880 --> 00:08:55,519
the

00:08:51,519 --> 00:08:57,279
the services it's highly decentralized

00:08:55,519 --> 00:08:58,560
so in this model we don't have a

00:08:57,279 --> 00:09:00,240
centralized

00:08:58,560 --> 00:09:01,839
proxy through which everything flows

00:09:00,240 --> 00:09:04,320
through for

00:09:01,839 --> 00:09:05,920
east-west or internal traffic that might

00:09:04,320 --> 00:09:07,519
be appropriate at the edge

00:09:05,920 --> 00:09:09,200
but for service to service traffic

00:09:07,519 --> 00:09:11,360
inside the uh

00:09:09,200 --> 00:09:12,480
inside a boundary that that you know you

00:09:11,360 --> 00:09:14,560
take extra hops

00:09:12,480 --> 00:09:15,519
just to just to get that and in the

00:09:14,560 --> 00:09:18,399
service mesh

00:09:15,519 --> 00:09:18,800
world here we we co-locate those proxies

00:09:18,399 --> 00:09:21,279
with

00:09:18,800 --> 00:09:22,640
the application themselves and then the

00:09:21,279 --> 00:09:26,080
last part

00:09:22,640 --> 00:09:26,480
is the mesh itself if you come back to

00:09:26,080 --> 00:09:30,959
this

00:09:26,480 --> 00:09:33,519
this diagram has a a controller

00:09:30,959 --> 00:09:34,320
or you know networking terms this is a

00:09:33,519 --> 00:09:37,839
control plane

00:09:34,320 --> 00:09:38,880
that's used to configure and change the

00:09:37,839 --> 00:09:42,720
behavior

00:09:38,880 --> 00:09:44,880
of the networking data plane

00:09:42,720 --> 00:09:45,920
so that would which would be the proxies

00:09:44,880 --> 00:09:48,160
here

00:09:45,920 --> 00:09:49,519
and the interesting part about this

00:09:48,160 --> 00:09:51,920
control plane

00:09:49,519 --> 00:09:52,720
is that it exposes an api to the

00:09:51,920 --> 00:09:55,120
operators

00:09:52,720 --> 00:09:55,839
to the users the sres or the developer

00:09:55,120 --> 00:09:58,880
teams

00:09:55,839 --> 00:10:01,519
it exposes an api that

00:09:58,880 --> 00:10:02,640
it allows you to configure the mesh and

00:10:01,519 --> 00:10:06,240
do that dynamically

00:10:02,640 --> 00:10:08,560
so this can be changed on the fly so

00:10:06,240 --> 00:10:09,680
what that means is this api becomes very

00:10:08,560 --> 00:10:11,839
powerful

00:10:09,680 --> 00:10:12,800
this allows you to build i'll type all

00:10:11,839 --> 00:10:14,959
types of

00:10:12,800 --> 00:10:17,760
different automation on top of that and

00:10:14,959 --> 00:10:21,040
we're going to take a look at that

00:10:17,760 --> 00:10:24,079
now part of the challenge is

00:10:21,040 --> 00:10:26,560
when you look at concrete deployments

00:10:24,079 --> 00:10:27,920
and how those deployments are influenced

00:10:26,560 --> 00:10:31,360
by

00:10:27,920 --> 00:10:32,720
real enterprise constraints things like

00:10:31,360 --> 00:10:34,800
compliance

00:10:32,720 --> 00:10:36,160
things like well the process has been

00:10:34,800 --> 00:10:39,200
set up for

00:10:36,160 --> 00:10:43,120
for this you have dmz's you have

00:10:39,200 --> 00:10:44,959
private networks you have existing cons

00:10:43,120 --> 00:10:46,800
security constraints you need high

00:10:44,959 --> 00:10:48,640
availability you want to separate teams

00:10:46,800 --> 00:10:49,680
out for autonomy and isolation and so

00:10:48,640 --> 00:10:52,800
forth

00:10:49,680 --> 00:10:54,240
what we see is more especially when

00:10:52,800 --> 00:10:54,959
you're adopting kubernetes and some of

00:10:54,240 --> 00:10:58,560
these types of

00:10:54,959 --> 00:11:00,959
uh container platforms that you're

00:10:58,560 --> 00:11:02,560
we're going toward a model where there

00:11:00,959 --> 00:11:05,120
are more of these

00:11:02,560 --> 00:11:06,079
smaller clusters and more of these types

00:11:05,120 --> 00:11:08,560
of deployments

00:11:06,079 --> 00:11:10,079
which themselves need management and so

00:11:08,560 --> 00:11:11,680
on but we're just going to take a look

00:11:10,079 --> 00:11:13,440
at this from the from the networking

00:11:11,680 --> 00:11:16,800
perspective

00:11:13,440 --> 00:11:18,160
so across multiple deployment targets

00:11:16,800 --> 00:11:19,519
which could be clusters

00:11:18,160 --> 00:11:21,360
could be availability zones could be

00:11:19,519 --> 00:11:24,240
geographically distributed

00:11:21,360 --> 00:11:24,720
data centers or it could be on-prem

00:11:24,240 --> 00:11:27,760
versus

00:11:24,720 --> 00:11:28,560
versus a public cloud the patterns that

00:11:27,760 --> 00:11:30,959
we're going to look at here

00:11:28,560 --> 00:11:32,480
are similar so when you're trying to

00:11:30,959 --> 00:11:34,640
cross boundaries

00:11:32,480 --> 00:11:35,839
the first pattern that we'll look at is

00:11:34,640 --> 00:11:38,079
well

00:11:35,839 --> 00:11:39,440
the boundary is a soft boundary and

00:11:38,079 --> 00:11:40,640
actually all these endpoints can

00:11:39,440 --> 00:11:43,600
communicate with each other because

00:11:40,640 --> 00:11:46,480
we're talking over a flat network

00:11:43,600 --> 00:11:48,640
and we do run into users and and

00:11:46,480 --> 00:11:49,839
customers that have this topology but

00:11:48,640 --> 00:11:52,720
it's not always

00:11:49,839 --> 00:11:53,600
that that common in this model it's

00:11:52,720 --> 00:11:56,000
fairly simple

00:11:53,600 --> 00:11:56,880
an account service that needs to talk to

00:11:56,000 --> 00:11:59,920
a peer

00:11:56,880 --> 00:12:01,440
service or collaborator service can just

00:11:59,920 --> 00:12:02,560
call the service directly they're living

00:12:01,440 --> 00:12:03,519
in a different boundary but they're

00:12:02,560 --> 00:12:06,560
still addressable

00:12:03,519 --> 00:12:10,000
directly in

00:12:06,560 --> 00:12:13,120
a a different model where

00:12:10,000 --> 00:12:14,320
these are these different clusters these

00:12:13,120 --> 00:12:16,079
different boundaries are living in

00:12:14,320 --> 00:12:19,519
different networks

00:12:16,079 --> 00:12:21,440
we can instead of address them directly

00:12:19,519 --> 00:12:22,800
over the network what we can do is set

00:12:21,440 --> 00:12:26,079
up intermediaries

00:12:22,800 --> 00:12:28,079
or gateways for each of these services

00:12:26,079 --> 00:12:31,519
that need to be

00:12:28,079 --> 00:12:34,480
that you need to communicate with and

00:12:31,519 --> 00:12:35,200
use those as the end points to which

00:12:34,480 --> 00:12:36,560
these

00:12:35,200 --> 00:12:38,320
services for example in cluster one

00:12:36,560 --> 00:12:41,519
account would talk to

00:12:38,320 --> 00:12:43,440
a vip or a gateway um that would

00:12:41,519 --> 00:12:44,959
represent what cluster two is that might

00:12:43,440 --> 00:12:47,279
be in a different network

00:12:44,959 --> 00:12:48,800
and then that that gateway can do the

00:12:47,279 --> 00:12:50,839
translation to

00:12:48,800 --> 00:12:52,079
the different network and do the routing

00:12:50,839 --> 00:12:55,440
correctly

00:12:52,079 --> 00:12:59,519
now this pattern is also kind of common

00:12:55,440 --> 00:13:01,920
now in a in a on-premises or

00:12:59,519 --> 00:13:03,440
public cloud setting where spinning up

00:13:01,920 --> 00:13:05,680
additional load balancers

00:13:03,440 --> 00:13:08,480
or gateways to handle this type of

00:13:05,680 --> 00:13:10,959
pattern can become expensive

00:13:08,480 --> 00:13:12,399
the you know the preference is to go

00:13:10,959 --> 00:13:15,279
more towards something

00:13:12,399 --> 00:13:15,680
like this where the traffic is going

00:13:15,279 --> 00:13:17,279
from

00:13:15,680 --> 00:13:19,839
one network to the other through a

00:13:17,279 --> 00:13:21,680
gateway but that one gateway is

00:13:19,839 --> 00:13:23,920
responsible for servicing

00:13:21,680 --> 00:13:25,360
all of the services that might live in

00:13:23,920 --> 00:13:28,079
that other network

00:13:25,360 --> 00:13:29,760
so we don't have this proliferation of

00:13:28,079 --> 00:13:32,560
load balancers now we have

00:13:29,760 --> 00:13:34,160
a single load balancer a single gateway

00:13:32,560 --> 00:13:36,240
that is smart enough to

00:13:34,160 --> 00:13:37,279
do the routing do the translation do the

00:13:36,240 --> 00:13:40,560
security and

00:13:37,279 --> 00:13:43,920
and so on so in

00:13:40,560 --> 00:13:45,440
some of the previous slides we saw that

00:13:43,920 --> 00:13:46,880
there's a

00:13:45,440 --> 00:13:49,360
what is what is the role of the service

00:13:46,880 --> 00:13:51,120
mesh what are some of the service

00:13:49,360 --> 00:13:53,519
measures that exist we saw istio

00:13:51,120 --> 00:13:54,480
and osm and console app match these

00:13:53,519 --> 00:13:57,600
types of

00:13:54,480 --> 00:13:58,560
service meshes and one thing i said was

00:13:57,600 --> 00:14:01,440
very common

00:13:58,560 --> 00:14:03,600
to them and that was the proxy that they

00:14:01,440 --> 00:14:06,800
chose to be their data plane

00:14:03,600 --> 00:14:10,160
is based on the envoy proxy

00:14:06,800 --> 00:14:12,800
project and when we look at starting to

00:14:10,160 --> 00:14:14,480
try to implement some of these patterns

00:14:12,800 --> 00:14:17,600
whether that's with a service measure

00:14:14,480 --> 00:14:20,399
not doesn't matter envoy proxy

00:14:17,600 --> 00:14:21,760
can become a crucial and uh very

00:14:20,399 --> 00:14:24,720
powerful piece

00:14:21,760 --> 00:14:25,920
to this puzzle both in terms of the

00:14:24,720 --> 00:14:27,120
obvious which is

00:14:25,920 --> 00:14:29,279
you know maybe maybe it could play the

00:14:27,120 --> 00:14:33,040
role of a gateway i mean it is a proxy

00:14:29,279 --> 00:14:35,440
but it also has the capabilities

00:14:33,040 --> 00:14:36,880
to be smart about how to route when to

00:14:35,440 --> 00:14:40,480
route

00:14:36,880 --> 00:14:43,360
across multiple clusters between

00:14:40,480 --> 00:14:44,000
multiple zones and across global data

00:14:43,360 --> 00:14:48,160
centers and

00:14:44,000 --> 00:14:51,440
and so on so like i said envoy proxy

00:14:48,160 --> 00:14:52,320
is a foundational piece to building this

00:14:51,440 --> 00:14:55,360
type of

00:14:52,320 --> 00:14:57,680
framework this type of solution

00:14:55,360 --> 00:14:58,560
envoy is a proxy that implements things

00:14:57,680 --> 00:15:01,120
like

00:14:58,560 --> 00:15:02,639
zone aware routing priority and locality

00:15:01,120 --> 00:15:05,680
load balancing

00:15:02,639 --> 00:15:08,720
circuit breaking timeouts retries

00:15:05,680 --> 00:15:09,600
retry budgets it can collect a lot of

00:15:08,720 --> 00:15:11,680
telemetry

00:15:09,600 --> 00:15:13,279
and be very informative about what's

00:15:11,680 --> 00:15:15,040
happening on the network for a

00:15:13,279 --> 00:15:18,000
particular application or between

00:15:15,040 --> 00:15:18,720
applications it can do things like uh

00:15:18,000 --> 00:15:21,760
tracing

00:15:18,720 --> 00:15:24,160
uh distributed tracing and so on

00:15:21,760 --> 00:15:24,959
some of the security properties and so

00:15:24,160 --> 00:15:28,800
envoy

00:15:24,959 --> 00:15:32,240
envoy is a very powerful um

00:15:28,800 --> 00:15:35,040
piece of technology that is being used

00:15:32,240 --> 00:15:36,240
very widely now as sort of the de facto

00:15:35,040 --> 00:15:37,680
standard if you're gonna if

00:15:36,240 --> 00:15:39,680
if you're gonna look at a service mesh

00:15:37,680 --> 00:15:40,240
or even build a surface mesh envoy is

00:15:39,680 --> 00:15:44,320
your

00:15:40,240 --> 00:15:47,600
starting point but going back to

00:15:44,320 --> 00:15:48,959
like how this helps in a multi-cluster

00:15:47,600 --> 00:15:52,399
setting or a

00:15:48,959 --> 00:15:55,519
multi-zone setting envoy is

00:15:52,399 --> 00:15:58,480
smart about or can be smart about

00:15:55,519 --> 00:15:59,519
where its collaborator or peer services

00:15:58,480 --> 00:16:02,079
live

00:15:59,519 --> 00:16:02,959
uh what zone they live what sort of

00:16:02,079 --> 00:16:04,560
weighting

00:16:02,959 --> 00:16:06,399
or weight routing and so on that they

00:16:04,560 --> 00:16:09,519
should do

00:16:06,399 --> 00:16:10,639
and plays the role of the side car in in

00:16:09,519 --> 00:16:13,759
the service mesh

00:16:10,639 --> 00:16:16,480
model as you can see here

00:16:13,759 --> 00:16:17,040
so in in those patterns what that might

00:16:16,480 --> 00:16:20,800
look like

00:16:17,040 --> 00:16:24,639
is envoy living with the applications

00:16:20,800 --> 00:16:26,480
and envoy at the edge as as a gateway

00:16:24,639 --> 00:16:28,480
and when envoy's living with the

00:16:26,480 --> 00:16:31,440
applications and directing

00:16:28,480 --> 00:16:32,320
the the control of its uh of the traffic

00:16:31,440 --> 00:16:34,160
routing when

00:16:32,320 --> 00:16:35,440
when in an example where the account

00:16:34,160 --> 00:16:36,399
service wants to talk to the user

00:16:35,440 --> 00:16:38,240
service

00:16:36,399 --> 00:16:40,320
ongoing can be smart enough to know hey

00:16:38,240 --> 00:16:42,959
just let's use the one that's local

00:16:40,320 --> 00:16:44,480
to the cluster in which the account

00:16:42,959 --> 00:16:46,959
service lives already

00:16:44,480 --> 00:16:47,839
and if that starts to fail then spill

00:16:46,959 --> 00:16:49,839
over to

00:16:47,839 --> 00:16:51,519
a different cluster different zone

00:16:49,839 --> 00:16:53,680
different data center

00:16:51,519 --> 00:16:55,120
and and also be smart about how you do

00:16:53,680 --> 00:16:57,120
that

00:16:55,120 --> 00:16:58,880
so let's dig into what that what that

00:16:57,120 --> 00:17:01,920
means what what

00:16:58,880 --> 00:17:03,759
what is envoy what can it be smart about

00:17:01,920 --> 00:17:05,120
what can it do in these types of

00:17:03,759 --> 00:17:06,079
scenarios where you need high

00:17:05,120 --> 00:17:09,280
availability

00:17:06,079 --> 00:17:12,480
low latency failover and

00:17:09,280 --> 00:17:12,480
um and security

00:17:12,640 --> 00:17:16,079
some of these other features include

00:17:14,799 --> 00:17:18,720
doing things

00:17:16,079 --> 00:17:20,319
some of these advanced things but like i

00:17:18,720 --> 00:17:23,520
said envoy lives

00:17:20,319 --> 00:17:26,880
out of process from the application

00:17:23,520 --> 00:17:28,319
so from the interaction with the

00:17:26,880 --> 00:17:30,559
application itself

00:17:28,319 --> 00:17:32,480
and the operator who's configuring it

00:17:30,559 --> 00:17:34,559
it's transparent to

00:17:32,480 --> 00:17:36,240
the application the application thinks

00:17:34,559 --> 00:17:39,440
it's talking over the network

00:17:36,240 --> 00:17:40,559
but because of this programmable service

00:17:39,440 --> 00:17:42,960
mesh

00:17:40,559 --> 00:17:44,320
we we can give it transparently we can

00:17:42,960 --> 00:17:47,840
give it additional

00:17:44,320 --> 00:17:47,840
capabilities like like some of these

00:17:48,000 --> 00:17:53,120
so request hedging or request racing

00:17:51,679 --> 00:17:54,960
some of these these different types of

00:17:53,120 --> 00:17:57,280
load balancing algorithms

00:17:54,960 --> 00:17:59,280
um being zone aware and so on so let's

00:17:57,280 --> 00:18:01,919
take a look at those a little closer

00:17:59,280 --> 00:18:02,880
so request racing or request hedging

00:18:01,919 --> 00:18:05,840
happens

00:18:02,880 --> 00:18:07,679
when you're making calls so so the

00:18:05,840 --> 00:18:10,960
account service is trying to talk to

00:18:07,679 --> 00:18:14,160
a peer service and

00:18:10,960 --> 00:18:16,320
envoy in the service mesh setting is

00:18:14,160 --> 00:18:17,200
is you know the the proxy through which

00:18:16,320 --> 00:18:20,000
that traffic is fl

00:18:17,200 --> 00:18:21,919
is flowing only can make the call out to

00:18:20,000 --> 00:18:25,600
that peer service

00:18:21,919 --> 00:18:28,240
and if it hits a timeout what envoy can

00:18:25,600 --> 00:18:30,000
automatically do is retry and that's the

00:18:28,240 --> 00:18:32,320
normal behavior

00:18:30,000 --> 00:18:33,039
if you configure it to retry if if you

00:18:32,320 --> 00:18:34,960
hit an

00:18:33,039 --> 00:18:36,480
error or timeout or something we can

00:18:34,960 --> 00:18:37,600
automatically retry

00:18:36,480 --> 00:18:40,000
application doesn't even have to know

00:18:37,600 --> 00:18:42,240
anything about that

00:18:40,000 --> 00:18:43,840
now what's interesting about request

00:18:42,240 --> 00:18:47,039
hedging is

00:18:43,840 --> 00:18:48,640
if we make that retry but the original

00:18:47,039 --> 00:18:50,720
request which timed out

00:18:48,640 --> 00:18:51,679
actually returns so we'll stay and wait

00:18:50,720 --> 00:18:52,799
for it even though it's timed out we're

00:18:51,679 --> 00:18:56,480
not going to close it we'll say

00:18:52,799 --> 00:18:59,840
wait for it in this model um then we'll

00:18:56,480 --> 00:19:01,919
we'll take whichever response is fastest

00:18:59,840 --> 00:19:03,440
whether it's the original request that

00:19:01,919 --> 00:19:04,480
originally timed out but we're still

00:19:03,440 --> 00:19:08,080
waiting for it

00:19:04,480 --> 00:19:10,160
or the retry that we that we

00:19:08,080 --> 00:19:11,840
uh sent out right so now you effectively

00:19:10,160 --> 00:19:14,640
have two requests that are out

00:19:11,840 --> 00:19:14,960
but whichever one comes back first will

00:19:14,640 --> 00:19:17,520
uh

00:19:14,960 --> 00:19:18,960
will respond with that request so this

00:19:17,520 --> 00:19:21,120
allows you to work around

00:19:18,960 --> 00:19:22,160
uh potentially slow services or

00:19:21,120 --> 00:19:25,200
intermittently

00:19:22,160 --> 00:19:28,240
slow services and

00:19:25,200 --> 00:19:30,160
even fail over to or try calling other

00:19:28,240 --> 00:19:32,960
endpoints that might respond

00:19:30,160 --> 00:19:35,440
faster so that's one one of these nice

00:19:32,960 --> 00:19:39,120
features of envoy

00:19:35,440 --> 00:19:41,440
another one is giving envoy

00:19:39,120 --> 00:19:42,640
enough information up front to know what

00:19:41,440 --> 00:19:45,679
zone

00:19:42,640 --> 00:19:49,280
availability zone or grouping that

00:19:45,679 --> 00:19:51,679
it lives in and what zone the other

00:19:49,280 --> 00:19:52,960
workloads that it's trying to talk to

00:19:51,679 --> 00:19:56,080
live in

00:19:52,960 --> 00:19:56,799
and knowing that information when envoy

00:19:56,080 --> 00:20:00,720
starts to see

00:19:56,799 --> 00:20:03,120
degradation or slowdowns or failures of

00:20:00,720 --> 00:20:04,640
services and peer services that it

00:20:03,120 --> 00:20:07,679
thinks or it knows that

00:20:04,640 --> 00:20:09,280
it are in its own zone same zone

00:20:07,679 --> 00:20:10,480
that envoy can automatically make the

00:20:09,280 --> 00:20:11,600
decision to all right let's start

00:20:10,480 --> 00:20:14,080
spilling over to

00:20:11,600 --> 00:20:15,679
different zones and so this is unvoiced

00:20:14,080 --> 00:20:19,280
zone aware

00:20:15,679 --> 00:20:23,120
routing capabilities a variant

00:20:19,280 --> 00:20:25,039
of that model is instead of ongoing

00:20:23,120 --> 00:20:26,799
making the decision

00:20:25,039 --> 00:20:28,640
about how and when to fail over two

00:20:26,799 --> 00:20:31,679
different zones

00:20:28,640 --> 00:20:34,320
what we can do is have a control plane

00:20:31,679 --> 00:20:35,360
pre-pro pre-populate what that decision

00:20:34,320 --> 00:20:37,120
should look like

00:20:35,360 --> 00:20:38,880
so what that means is the the control

00:20:37,120 --> 00:20:41,280
plane will say

00:20:38,880 --> 00:20:41,919
here when it delivers the config to

00:20:41,280 --> 00:20:44,080
envoy

00:20:41,919 --> 00:20:45,760
for in this case the account service it

00:20:44,080 --> 00:20:48,080
can say

00:20:45,760 --> 00:20:49,280
when you start talking to these peer

00:20:48,080 --> 00:20:51,360
services

00:20:49,280 --> 00:20:53,200
i want you to give them a priority and a

00:20:51,360 --> 00:20:56,640
weight different

00:20:53,200 --> 00:20:59,280
depending on what zone they existed and

00:20:56,640 --> 00:21:01,520
then just you know follow your same

00:20:59,280 --> 00:21:04,960
failover

00:21:01,520 --> 00:21:06,640
mechanisms based on the the priority

00:21:04,960 --> 00:21:08,960
and the weight that the control plane

00:21:06,640 --> 00:21:10,320
has given to to the proxy so

00:21:08,960 --> 00:21:12,000
the control plane typically will see

00:21:10,320 --> 00:21:13,760
more and have a more understanding of

00:21:12,000 --> 00:21:17,600
what the topology looks like

00:21:13,760 --> 00:21:20,720
it can discover that at runtime and then

00:21:17,600 --> 00:21:24,159
drive individual configurations for

00:21:20,720 --> 00:21:26,880
the data plane to to be aware of that

00:21:24,159 --> 00:21:28,000
information like locality for example

00:21:26,880 --> 00:21:31,520
and give it different priorities in

00:21:28,000 --> 00:21:36,400
different ways based on based on that

00:21:31,520 --> 00:21:41,280
the last thing is uh is sort of a um

00:21:36,400 --> 00:21:43,039
a refinement of the previous

00:21:41,280 --> 00:21:44,640
functionality that we saw with the

00:21:43,039 --> 00:21:47,440
control plane

00:21:44,640 --> 00:21:49,280
owning the configuration and the weights

00:21:47,440 --> 00:21:52,000
and locality and that kind of stuff

00:21:49,280 --> 00:21:53,039
for the data plane uh this just gives

00:21:52,000 --> 00:21:54,799
you a little bit more fine grained

00:21:53,039 --> 00:21:56,240
control over how it calls

00:21:54,799 --> 00:21:58,080
the different surfaces potentially in

00:21:56,240 --> 00:21:59,520
this case across different zones

00:21:58,080 --> 00:22:02,720
different regions and

00:21:59,520 --> 00:22:04,000
and globally so bringing and tying all

00:22:02,720 --> 00:22:05,520
of this back

00:22:04,000 --> 00:22:06,799
what we and we're going to use a real

00:22:05,520 --> 00:22:08,240
example in this case now we're going to

00:22:06,799 --> 00:22:10,400
use issio

00:22:08,240 --> 00:22:12,080
um you know tying all these different

00:22:10,400 --> 00:22:13,679
patterns back to their implementation

00:22:12,080 --> 00:22:15,440
what envoy can do under the covers and

00:22:13,679 --> 00:22:18,559
what this might look like

00:22:15,440 --> 00:22:19,520
so in this in the first pattern that we

00:22:18,559 --> 00:22:22,159
saw we saw

00:22:19,520 --> 00:22:24,080
two different boundaries on the same

00:22:22,159 --> 00:22:27,120
flat network

00:22:24,080 --> 00:22:29,760
and how this would be implemented with a

00:22:27,120 --> 00:22:30,159
service mesh would be well you see you

00:22:29,760 --> 00:22:32,480
have

00:22:30,159 --> 00:22:34,960
the data plane the proxy's living with

00:22:32,480 --> 00:22:38,080
each of the service instances

00:22:34,960 --> 00:22:40,480
and you have a single control plane that

00:22:38,080 --> 00:22:42,640
knows about the services running in

00:22:40,480 --> 00:22:44,799
cluster one and cluster two

00:22:42,640 --> 00:22:46,240
and since the network is flat they can

00:22:44,799 --> 00:22:48,159
directly address

00:22:46,240 --> 00:22:50,400
each other so the account service when

00:22:48,159 --> 00:22:52,159
it talks to the user service

00:22:50,400 --> 00:22:53,919
can talk to the one in cluster one but

00:22:52,159 --> 00:22:55,600
it can also talk to the user service

00:22:53,919 --> 00:22:57,840
that's deployed in cluster 2.

00:22:55,600 --> 00:22:59,440
and the control plane here sees where

00:22:57,840 --> 00:23:02,240
these deployments live

00:22:59,440 --> 00:23:02,720
and uses that information to configure

00:23:02,240 --> 00:23:06,840
the

00:23:02,720 --> 00:23:08,640
proxies that live in in each of the data

00:23:06,840 --> 00:23:11,919
planes

00:23:08,640 --> 00:23:16,159
the second option is

00:23:11,919 --> 00:23:19,919
to have again a single control plane

00:23:16,159 --> 00:23:21,679
and share that control plane across

00:23:19,919 --> 00:23:23,280
multiple different clusters and multiple

00:23:21,679 --> 00:23:27,039
different boundaries

00:23:23,280 --> 00:23:28,080
and in this model the traffic flows from

00:23:27,039 --> 00:23:30,000
cluster one to

00:23:28,080 --> 00:23:31,120
cluster two which would be in a separate

00:23:30,000 --> 00:23:33,760
network

00:23:31,120 --> 00:23:35,200
through a gateway as we saw earlier

00:23:33,760 --> 00:23:37,440
which would do

00:23:35,200 --> 00:23:39,919
handle the translation and you know

00:23:37,440 --> 00:23:43,600
going from one network to the other

00:23:39,919 --> 00:23:44,000
and in this model the workloads that are

00:23:43,600 --> 00:23:47,279
running

00:23:44,000 --> 00:23:48,880
in cluster two share their information

00:23:47,279 --> 00:23:52,000
with the control plane that's running

00:23:48,880 --> 00:23:55,120
in cluster one

00:23:52,000 --> 00:23:55,840
so this is a this is a fine model i

00:23:55,120 --> 00:23:57,520
think to get

00:23:55,840 --> 00:23:59,679
you know kind of playing around with

00:23:57,520 --> 00:24:01,520
where you extend things that are living

00:23:59,679 --> 00:24:02,960
in the same data center probably in the

00:24:01,520 --> 00:24:06,559
same zones

00:24:02,960 --> 00:24:09,919
but one downside to this model is

00:24:06,559 --> 00:24:11,360
if cluster one goes down then you've

00:24:09,919 --> 00:24:13,919
lost the control plane

00:24:11,360 --> 00:24:15,360
for your other clusters right so you

00:24:13,919 --> 00:24:18,640
don't have that

00:24:15,360 --> 00:24:22,080
separation of the of

00:24:18,640 --> 00:24:23,919
your failure boundaries around um

00:24:22,080 --> 00:24:25,440
which you typically try to architect for

00:24:23,919 --> 00:24:27,679
high availability

00:24:25,440 --> 00:24:29,120
so if one particular cluster messes up

00:24:27,679 --> 00:24:32,880
that affects your other clusters

00:24:29,120 --> 00:24:36,400
not ideal so

00:24:32,880 --> 00:24:39,679
the the third option is to

00:24:36,400 --> 00:24:42,400
have the control planes running

00:24:39,679 --> 00:24:43,279
in their own failure boundaries and in

00:24:42,400 --> 00:24:45,520
this case it would be

00:24:43,279 --> 00:24:46,720
per cluster the control plane is

00:24:45,520 --> 00:24:51,360
responsible

00:24:46,720 --> 00:24:53,520
for administering the config for

00:24:51,360 --> 00:24:54,720
the data planes that live in that in its

00:24:53,520 --> 00:24:56,400
own cluster

00:24:54,720 --> 00:24:58,840
communication still going through the

00:24:56,400 --> 00:25:00,000
gateways as it traverses different

00:24:58,840 --> 00:25:03,039
networks

00:25:00,000 --> 00:25:04,720
and in this model to make each control

00:25:03,039 --> 00:25:07,520
plane smarter

00:25:04,720 --> 00:25:09,120
about what lives in the other cluster so

00:25:07,520 --> 00:25:10,720
for example in cluster one

00:25:09,120 --> 00:25:13,360
we have an account service and a user

00:25:10,720 --> 00:25:15,360
service and the service mesh for that

00:25:13,360 --> 00:25:17,440
cluster knows only about those

00:25:15,360 --> 00:25:20,799
services but there is another user

00:25:17,440 --> 00:25:23,039
service and it lives in cluster two

00:25:20,799 --> 00:25:25,120
so somehow we have to make cluster one

00:25:23,039 --> 00:25:28,240
in the service mesh they're aware

00:25:25,120 --> 00:25:31,120
of the the presence of

00:25:28,240 --> 00:25:32,799
the user service in cluster 2 how to

00:25:31,120 --> 00:25:34,480
communicate with cluster 2 how to

00:25:32,799 --> 00:25:37,120
communicate with the user service

00:25:34,480 --> 00:25:38,320
what is the right credentials and

00:25:37,120 --> 00:25:41,679
certificates

00:25:38,320 --> 00:25:43,919
and mtls that you can use to make that

00:25:41,679 --> 00:25:46,960
that connection happen

00:25:43,919 --> 00:25:48,480
so multiple

00:25:46,960 --> 00:25:50,559
clusters we talked about why we might

00:25:48,480 --> 00:25:54,559
want to do that for various compliance

00:25:50,559 --> 00:25:54,559
scale and high availability reasons

00:25:55,200 --> 00:25:59,840
if we look at the capabilities of

00:25:57,679 --> 00:26:03,440
something like envoy which is

00:25:59,840 --> 00:26:06,320
very powerful and and can be very um

00:26:03,440 --> 00:26:07,919
useful in this in this context and

00:26:06,320 --> 00:26:08,720
bringing that into a service mesh and

00:26:07,919 --> 00:26:10,799
how do you

00:26:08,720 --> 00:26:12,960
build and run and deploy that you can

00:26:10,799 --> 00:26:15,440
see this gets pretty complicated

00:26:12,960 --> 00:26:16,799
pretty quickly now there are no easy

00:26:15,440 --> 00:26:19,360
solutions to this

00:26:16,799 --> 00:26:20,640
but some of the problems that you start

00:26:19,360 --> 00:26:22,840
to run into

00:26:20,640 --> 00:26:24,159
when you start to go down this path are

00:26:22,840 --> 00:26:27,120
around

00:26:24,159 --> 00:26:28,240
uh manage managing these these things

00:26:27,120 --> 00:26:29,360
you have multiple clusters you have to

00:26:28,240 --> 00:26:30,559
manage the clusters

00:26:29,360 --> 00:26:31,760
you probably if you're going down that

00:26:30,559 --> 00:26:32,480
path you probably have something to

00:26:31,760 --> 00:26:34,720
manage

00:26:32,480 --> 00:26:36,320
uh the git ops workflows and and the

00:26:34,720 --> 00:26:40,400
kubernetes uh backup

00:26:36,320 --> 00:26:42,320
seds and all that stuff right but

00:26:40,400 --> 00:26:44,640
when you start to go a little bit layer

00:26:42,320 --> 00:26:45,840
higher about what are the applications

00:26:44,640 --> 00:26:48,000
now where do they live

00:26:45,840 --> 00:26:49,840
what are the failover rules and stuff

00:26:48,000 --> 00:26:52,159
that we should have here

00:26:49,840 --> 00:26:53,840
um it's there's a lot of work that the

00:26:52,159 --> 00:26:57,200
operator has to do

00:26:53,840 --> 00:27:00,799
the operator has to make sure that

00:26:57,200 --> 00:27:03,279
um each of these clusters

00:27:00,799 --> 00:27:04,320
and the identities that they provide for

00:27:03,279 --> 00:27:05,520
their

00:27:04,320 --> 00:27:07,840
their workloads that live in each of

00:27:05,520 --> 00:27:08,480
those clusters is something that can be

00:27:07,840 --> 00:27:11,039
unified

00:27:08,480 --> 00:27:13,200
across the different clusters we need to

00:27:11,039 --> 00:27:15,679
write configurations

00:27:13,200 --> 00:27:17,440
in multiple clusters to make each

00:27:15,679 --> 00:27:18,240
cluster aware of where the other

00:27:17,440 --> 00:27:21,360
services

00:27:18,240 --> 00:27:23,279
live we need to define higher level

00:27:21,360 --> 00:27:24,480
semantics around failover and

00:27:23,279 --> 00:27:26,799
localization

00:27:24,480 --> 00:27:27,919
what happens traffic should stay local

00:27:26,799 --> 00:27:30,640
most of the time

00:27:27,919 --> 00:27:32,080
but when it fails how should it or when

00:27:30,640 --> 00:27:33,120
it should when it fails over how should

00:27:32,080 --> 00:27:35,760
it fail over

00:27:33,120 --> 00:27:37,360
should it fail over to the next locality

00:27:35,760 --> 00:27:39,840
should it fail over to

00:27:37,360 --> 00:27:40,880
pinned specific clusters for compliance

00:27:39,840 --> 00:27:43,679
reasons

00:27:40,880 --> 00:27:44,640
um you know figuring out what those

00:27:43,679 --> 00:27:47,279
fault domains

00:27:44,640 --> 00:27:48,399
are and and how to administer those

00:27:47,279 --> 00:27:50,799
that's a lot of

00:27:48,399 --> 00:27:52,000
uh stuff that the operator has to work

00:27:50,799 --> 00:27:54,159
out

00:27:52,000 --> 00:27:55,600
now we're working on an open source

00:27:54,159 --> 00:27:58,320
project at solo

00:27:55,600 --> 00:27:59,679
called service mesh hub that is intended

00:27:58,320 --> 00:28:02,640
specifically to solve

00:27:59,679 --> 00:28:04,399
the difficult challenges around running

00:28:02,640 --> 00:28:07,679
a service mesh

00:28:04,399 --> 00:28:09,279
and running it across multiple clusters

00:28:07,679 --> 00:28:11,600
and so what service mesh hub does is

00:28:09,279 --> 00:28:14,799
provide a management plane

00:28:11,600 --> 00:28:18,240
that basically orchestrates

00:28:14,799 --> 00:28:20,960
the different independent service mesh

00:28:18,240 --> 00:28:22,320
control planes right so if you have if i

00:28:20,960 --> 00:28:24,080
go to this

00:28:22,320 --> 00:28:25,440
this diagram you have these different

00:28:24,080 --> 00:28:27,520
clusters

00:28:25,440 --> 00:28:31,039
each with their own independent service

00:28:27,520 --> 00:28:32,480
mesh deployment um on on

00:28:31,039 --> 00:28:35,120
multi so if we see two clusters here it

00:28:32,480 --> 00:28:38,480
could be 10 300 and what service mesh

00:28:35,120 --> 00:28:41,520
hub does is it discovers

00:28:38,480 --> 00:28:44,720
the meshes that are running there it

00:28:41,520 --> 00:28:47,120
automates the placement of configuration

00:28:44,720 --> 00:28:47,919
it provides an api that is multi-cluster

00:28:47,120 --> 00:28:50,960
aware so

00:28:47,919 --> 00:28:54,640
all you see is an api that

00:28:50,960 --> 00:28:56,960
abstracts away this detail and you

00:28:54,640 --> 00:28:58,640
deal with what's called a virtual mesh

00:28:56,960 --> 00:28:59,760
you write your configurations against a

00:28:58,640 --> 00:29:01,760
virtual mesh

00:28:59,760 --> 00:29:03,600
and then service mesh hub ends up

00:29:01,760 --> 00:29:04,960
translating and orchestrating the

00:29:03,600 --> 00:29:08,240
configurations

00:29:04,960 --> 00:29:10,559
in in the right clusters now it's it

00:29:08,240 --> 00:29:11,360
what makes this interesting is that what

00:29:10,559 --> 00:29:13,919
in my experience

00:29:11,360 --> 00:29:15,360
in a real enterprise uh you end up

00:29:13,919 --> 00:29:16,880
getting in a situation where of course

00:29:15,360 --> 00:29:18,399
you have multiple clusters multiple

00:29:16,880 --> 00:29:20,880
multiple deployments and so on

00:29:18,399 --> 00:29:21,520
but you might even get in a situation

00:29:20,880 --> 00:29:24,080
where

00:29:21,520 --> 00:29:25,760
you take your on-prem deployments and

00:29:24,080 --> 00:29:26,720
say all right now i'm ready to go to a

00:29:25,760 --> 00:29:29,440
public cloud

00:29:26,720 --> 00:29:31,279
and when you get there you realize well

00:29:29,440 --> 00:29:33,120
there's a lot of value that public cloud

00:29:31,279 --> 00:29:35,279
offers in terms of compute and

00:29:33,120 --> 00:29:37,600
automation and management

00:29:35,279 --> 00:29:39,279
and they have their own service mesh

00:29:37,600 --> 00:29:41,760
sometimes and and it'll be

00:29:39,279 --> 00:29:43,679
it'll be true uh more in the future they

00:29:41,760 --> 00:29:44,640
have their own service mesh aws has that

00:29:43,679 --> 00:29:47,919
mesh

00:29:44,640 --> 00:29:50,559
um so how do you unify these

00:29:47,919 --> 00:29:51,440
networking layers that might run in

00:29:50,559 --> 00:29:52,840
different clusters

00:29:51,440 --> 00:29:54,799
and might be completely different

00:29:52,840 --> 00:29:57,840
implementations um

00:29:54,799 --> 00:30:00,960
so that that is the goal of where

00:29:57,840 --> 00:30:01,840
uh servicemen hub is going to be able to

00:30:00,960 --> 00:30:05,039
make

00:30:01,840 --> 00:30:08,159
operating a service mesh in

00:30:05,039 --> 00:30:11,200
an enterprise large deployment feasible

00:30:08,159 --> 00:30:12,720
and realistic and uh and improve that

00:30:11,200 --> 00:30:13,600
that experience both from the user

00:30:12,720 --> 00:30:16,720
perspective as well as

00:30:13,600 --> 00:30:17,360
operator perspective so i have a few

00:30:16,720 --> 00:30:22,320
minutes here

00:30:17,360 --> 00:30:24,080
let me get uh let me get to a quick demo

00:30:22,320 --> 00:30:26,000
as we do the short one here

00:30:24,080 --> 00:30:28,000
today so what we have where we're

00:30:26,000 --> 00:30:28,640
starting is a deployment that looks like

00:30:28,000 --> 00:30:31,760
this

00:30:28,640 --> 00:30:34,240
we have istio running in cluster one

00:30:31,760 --> 00:30:35,360
and cluster two and then we've deployed

00:30:34,240 --> 00:30:38,960
the service mesh hub

00:30:35,360 --> 00:30:41,279
management plane into a third cluster

00:30:38,960 --> 00:30:42,480
now cluster one and cluster two live on

00:30:41,279 --> 00:30:44,320
gke

00:30:42,480 --> 00:30:46,159
the management plane lives on a kind

00:30:44,320 --> 00:30:50,080
cluster running on my

00:30:46,159 --> 00:30:51,679
on my local machine so the first thing

00:30:50,080 --> 00:30:53,919
that oh and we're going to also point

00:30:51,679 --> 00:30:56,320
out that uh we have uh we'll follow

00:30:53,919 --> 00:30:59,279
along in the ui so there's

00:30:56,320 --> 00:31:00,159
it it's you typically interact with

00:30:59,279 --> 00:31:02,399
service mesh hub

00:31:00,159 --> 00:31:04,640
through a cli or through a git ops

00:31:02,399 --> 00:31:06,880
workflow it uses declarative

00:31:04,640 --> 00:31:08,880
configuration but there's also a

00:31:06,880 --> 00:31:11,519
read-only ui that we can use to

00:31:08,880 --> 00:31:13,120
observe and watch what is what does the

00:31:11,519 --> 00:31:15,679
deployment look like

00:31:13,120 --> 00:31:16,960
so the first thing we're going to do is

00:31:15,679 --> 00:31:20,240
register

00:31:16,960 --> 00:31:23,120
cluster 1 and cluster 2 with

00:31:20,240 --> 00:31:24,320
the management plane and so what this is

00:31:23,120 --> 00:31:24,960
going to do is allow the management

00:31:24,320 --> 00:31:27,440
plane

00:31:24,960 --> 00:31:28,399
to then go discover what are the meshes

00:31:27,440 --> 00:31:30,720
running there

00:31:28,399 --> 00:31:32,159
what are the workloads running there and

00:31:30,720 --> 00:31:34,799
what other context

00:31:32,159 --> 00:31:36,720
lives in that in that service mesh so

00:31:34,799 --> 00:31:37,360
that the management plane can be smart

00:31:36,720 --> 00:31:40,399
about how

00:31:37,360 --> 00:31:44,000
it orchestrates and controls the rest of

00:31:40,399 --> 00:31:46,399
the the clusters so we registered

00:31:44,000 --> 00:31:49,200
cluster one let's do the same thing for

00:31:46,399 --> 00:31:49,200
cluster two

00:31:50,799 --> 00:31:54,399
and we'll give that a second what it's

00:31:52,399 --> 00:31:57,440
doing is it's in installing

00:31:54,399 --> 00:32:00,720
some uh agents specifically to handle

00:31:57,440 --> 00:32:02,559
things like security and certificates

00:32:00,720 --> 00:32:04,720
and then it's doing the discovery as i

00:32:02,559 --> 00:32:08,159
mentioned

00:32:04,720 --> 00:32:11,679
the next thing that we want to do is

00:32:08,159 --> 00:32:13,120
we want to unify these two different

00:32:11,679 --> 00:32:13,760
clusters because right now they're two

00:32:13,120 --> 00:32:16,960
independent

00:32:13,760 --> 00:32:20,240
service meshes what we want to do

00:32:16,960 --> 00:32:23,039
is unify them under a single abstraction

00:32:20,240 --> 00:32:24,640
unify the identity domains unit unify

00:32:23,039 --> 00:32:28,000
the configuration

00:32:24,640 --> 00:32:30,720
api and we can do that fairly simply

00:32:28,000 --> 00:32:32,240
with the service wish hub virtual mesh

00:32:30,720 --> 00:32:33,440
so if we take a look at the virtual mesh

00:32:32,240 --> 00:32:35,679
resource

00:32:33,440 --> 00:32:36,960
what we're saying is hey include these

00:32:35,679 --> 00:32:39,440
meshes

00:32:36,960 --> 00:32:42,240
in this virtual mesh abstraction these

00:32:39,440 --> 00:32:44,480
happen to both be istio

00:32:42,240 --> 00:32:46,480
federate them so in this case we're

00:32:44,480 --> 00:32:48,000
going to supply the service discovery

00:32:46,480 --> 00:32:51,679
information necessary

00:32:48,000 --> 00:32:53,679
for both clusters to know about

00:32:51,679 --> 00:32:54,960
what services live where right so the

00:32:53,679 --> 00:32:57,600
services in cluster

00:32:54,960 --> 00:32:58,480
two will be made of aware to services

00:32:57,600 --> 00:33:00,399
running in

00:32:58,480 --> 00:33:01,519
cluster one and the last thing we're

00:33:00,399 --> 00:33:02,080
going to do is we're going to configure

00:33:01,519 --> 00:33:04,480
the

00:33:02,080 --> 00:33:05,919
the tls and the identity the root

00:33:04,480 --> 00:33:08,559
identity domains

00:33:05,919 --> 00:33:10,399
uh to be coming from a single root ca in

00:33:08,559 --> 00:33:13,679
this case

00:33:10,399 --> 00:33:15,840
so let's apply the virtual mesh

00:33:13,679 --> 00:33:16,960
and now under the covers what service

00:33:15,840 --> 00:33:19,120
mesh hub is going to do

00:33:16,960 --> 00:33:20,320
is it's going to reach out to these

00:33:19,120 --> 00:33:22,960
different clusters

00:33:20,320 --> 00:33:24,159
configure them security wise and so on

00:33:22,960 --> 00:33:25,760
so that

00:33:24,159 --> 00:33:27,200
they now when they try to communicate

00:33:25,760 --> 00:33:27,919
with each other they appear as though

00:33:27,200 --> 00:33:31,679
they're one

00:33:27,919 --> 00:33:34,240
single uh surface mesh

00:33:31,679 --> 00:33:37,200
so if we get the mesh across our fingers

00:33:34,240 --> 00:33:40,000
okay we see in the status fields that

00:33:37,200 --> 00:33:42,080
all of the configuration orchestration

00:33:40,000 --> 00:33:43,440
has happened and it has been accepted

00:33:42,080 --> 00:33:46,159
and that's good if we come over here we

00:33:43,440 --> 00:33:49,279
should start to see

00:33:46,159 --> 00:33:51,519
some more information about we have

00:33:49,279 --> 00:33:52,799
one virtual mesh we have two different

00:33:51,519 --> 00:33:54,000
clusters we have

00:33:52,799 --> 00:33:56,240
a bunch of workloads that have been

00:33:54,000 --> 00:33:57,120
discovered in this case the workloads

00:33:56,240 --> 00:34:00,640
that have been discovered

00:33:57,120 --> 00:34:02,880
are the the book info istio

00:34:00,640 --> 00:34:06,159
demo that we that we typically run when

00:34:02,880 --> 00:34:09,599
we look at istio

00:34:06,159 --> 00:34:11,040
so what we've done under the covers is

00:34:09,599 --> 00:34:13,919
we've created

00:34:11,040 --> 00:34:15,280
the a root ca and we could have used an

00:34:13,919 --> 00:34:17,040
existing one

00:34:15,280 --> 00:34:19,280
then what we did is we told the

00:34:17,040 --> 00:34:20,879
different service meshes

00:34:19,280 --> 00:34:22,320
here you know create a certificate

00:34:20,879 --> 00:34:23,520
signing request or intermediate

00:34:22,320 --> 00:34:26,399
certificate

00:34:23,520 --> 00:34:27,839
for each of the individual meshes that

00:34:26,399 --> 00:34:30,960
have a root

00:34:27,839 --> 00:34:33,040
a common root a shared root

00:34:30,960 --> 00:34:34,159
and then from there each mesh can

00:34:33,040 --> 00:34:36,079
they'll go pre

00:34:34,159 --> 00:34:37,760
provision its own workload uh

00:34:36,079 --> 00:34:39,919
certificates and so on

00:34:37,760 --> 00:34:41,679
but they all run you know they all

00:34:39,919 --> 00:34:44,240
terminate in the same route

00:34:41,679 --> 00:34:45,280
so betw the traffic from one cluster to

00:34:44,240 --> 00:34:47,919
the other

00:34:45,280 --> 00:34:49,040
should be able to make an end to end the

00:34:47,919 --> 00:34:51,280
mutual tls

00:34:49,040 --> 00:34:52,480
connection and ident and trust the

00:34:51,280 --> 00:34:54,560
identity

00:34:52,480 --> 00:34:55,919
um between the different clusters

00:34:54,560 --> 00:34:58,960
without the application having to know

00:34:55,919 --> 00:34:58,960
or do anything about that

00:34:59,119 --> 00:35:04,560
so that looks good

00:35:02,240 --> 00:35:05,839
real quick before we continue so if we

00:35:04,560 --> 00:35:09,040
look in cluster one

00:35:05,839 --> 00:35:12,800
if i get uh the pod from

00:35:09,040 --> 00:35:15,839
context still cluster one we see we have

00:35:12,800 --> 00:35:16,320
the the book info demo running product

00:35:15,839 --> 00:35:19,599
page

00:35:16,320 --> 00:35:21,520
details reviews v1 and v2

00:35:19,599 --> 00:35:24,240
which allows us to change the behavior

00:35:21,520 --> 00:35:28,079
of the app at runtime

00:35:24,240 --> 00:35:30,400
on cluster 2 we see we have the same app

00:35:28,079 --> 00:35:31,440
but we also have reviews v3 running

00:35:30,400 --> 00:35:34,000
there

00:35:31,440 --> 00:35:34,960
so on cluster one we don't have reviews

00:35:34,000 --> 00:35:36,000
v3

00:35:34,960 --> 00:35:37,440
what we're going to show in the next

00:35:36,000 --> 00:35:39,839
part of the demo is how we can route

00:35:37,440 --> 00:35:43,280
traffic from cluster one and cluster two

00:35:39,839 --> 00:35:47,040
achieve a mutual tls and and encryption

00:35:43,280 --> 00:35:50,000
and um and and do that using

00:35:47,040 --> 00:35:51,359
um using configuration and using the api

00:35:50,000 --> 00:35:54,079
to drive that

00:35:51,359 --> 00:35:54,960
declarative configuration so the first

00:35:54,079 --> 00:35:57,040
thing we're going to do is we're going

00:35:54,960 --> 00:36:00,400
to take a look at our book info

00:35:57,040 --> 00:36:02,400
app so if i refresh the book info app

00:36:00,400 --> 00:36:04,640
here

00:36:02,400 --> 00:36:06,240
it is looking at cluster one we can see

00:36:04,640 --> 00:36:09,599
that we balance between

00:36:06,240 --> 00:36:10,560
reviews v1 and v2 we never see reviews

00:36:09,599 --> 00:36:12,880
v3

00:36:10,560 --> 00:36:14,720
which would be which would have red

00:36:12,880 --> 00:36:17,680
stars we don't see that here as we

00:36:14,720 --> 00:36:17,680
refresh a few times

00:36:18,079 --> 00:36:24,240
now let's explicitly control the traffic

00:36:21,200 --> 00:36:26,480
where we are going to say

00:36:24,240 --> 00:36:27,760
using our traffic policy the mesh uh

00:36:26,480 --> 00:36:29,920
service membership api

00:36:27,760 --> 00:36:31,280
using the traffic policy we're going to

00:36:29,920 --> 00:36:34,160
say if you try to talk

00:36:31,280 --> 00:36:35,200
to the review service and in this case

00:36:34,160 --> 00:36:37,040
if you're trying to talk the review

00:36:35,200 --> 00:36:39,200
service in cluster one

00:36:37,040 --> 00:36:40,160
then let's actually route some of that

00:36:39,200 --> 00:36:43,839
traffic

00:36:40,160 --> 00:36:44,560
to v1 of reviews which lives in cluster

00:36:43,839 --> 00:36:47,599
one

00:36:44,560 --> 00:36:50,480
and some of that traffic to v3 which

00:36:47,599 --> 00:36:52,640
lives in a different cluster right and

00:36:50,480 --> 00:36:54,880
some of that traffic will go to v2

00:36:52,640 --> 00:36:56,160
but the interesting point here is we're

00:36:54,880 --> 00:36:59,680
making 75

00:36:56,160 --> 00:37:01,520
of the traffic go to cluster 2.

00:36:59,680 --> 00:37:04,000
so if we apply this and cross our

00:37:01,520 --> 00:37:04,000
fingers

00:37:05,599 --> 00:37:11,200
then what we should see under the covers

00:37:08,800 --> 00:37:12,880
let's make sure that we do that the

00:37:11,200 --> 00:37:14,400
service mesh hub

00:37:12,880 --> 00:37:16,320
has orchestrated the different

00:37:14,400 --> 00:37:18,000
configurations

00:37:16,320 --> 00:37:19,520
it's created virtual services

00:37:18,000 --> 00:37:21,280
destination rules

00:37:19,520 --> 00:37:25,040
service entries all of these things that

00:37:21,280 --> 00:37:27,920
are mesh specific in this case it's isco

00:37:25,040 --> 00:37:29,520
but it's configuring it in a smart way

00:37:27,920 --> 00:37:30,880
such that the workloads can then

00:37:29,520 --> 00:37:33,440
communicate with each other

00:37:30,880 --> 00:37:34,640
across the cluster they can trust their

00:37:33,440 --> 00:37:37,040
identity and and

00:37:34,640 --> 00:37:38,560
everything is under mutual tlf so if i

00:37:37,040 --> 00:37:41,040
refresh this

00:37:38,560 --> 00:37:41,599
and cross fingers we should see the red

00:37:41,040 --> 00:37:44,480
stars

00:37:41,599 --> 00:37:45,359
red stars v3 of reviews refresh a few

00:37:44,480 --> 00:37:47,599
times

00:37:45,359 --> 00:37:49,280
we should see 75 percent of traffic

00:37:47,599 --> 00:37:50,160
should go to red star so we should also

00:37:49,280 --> 00:37:53,520
see

00:37:50,160 --> 00:37:54,480
um some traffic going to the the non-red

00:37:53,520 --> 00:37:58,240
stars but

00:37:54,480 --> 00:37:59,920
there we go um i'm running out of time

00:37:58,240 --> 00:38:01,359
there's more to this right because once

00:37:59,920 --> 00:38:03,520
you've built once you have this

00:38:01,359 --> 00:38:07,119
management plane that is smart

00:38:03,520 --> 00:38:09,520
about where the workloads live

00:38:07,119 --> 00:38:10,960
what are the different control planes

00:38:09,520 --> 00:38:15,119
how to configure them

00:38:10,960 --> 00:38:18,480
on the fly and you've exposed an api

00:38:15,119 --> 00:38:19,760
to the end user that is that abstracts

00:38:18,480 --> 00:38:20,640
away the fact that there's multiple

00:38:19,760 --> 00:38:22,640
clusters and

00:38:20,640 --> 00:38:24,720
whatever the details of the service met

00:38:22,640 --> 00:38:26,720
that api that is specific to what the

00:38:24,720 --> 00:38:29,119
end user is trying to do

00:38:26,720 --> 00:38:30,560
um then you've built some you know

00:38:29,119 --> 00:38:32,560
foundation for building some

00:38:30,560 --> 00:38:33,520
powerful capabilities like the next in

00:38:32,560 --> 00:38:35,119
the next section i was going to show

00:38:33,520 --> 00:38:39,040
access control or

00:38:35,119 --> 00:38:41,599
failover and um and so on now

00:38:39,040 --> 00:38:42,240
the ui is powerful enough that of course

00:38:41,599 --> 00:38:44,560
we can see

00:38:42,240 --> 00:38:46,240
our different meshes we see our virtual

00:38:44,560 --> 00:38:48,640
mesh here

00:38:46,240 --> 00:38:49,920
if i look at the different meshes we can

00:38:48,640 --> 00:38:52,720
see what

00:38:49,920 --> 00:38:53,839
workloads and and traffic targets and

00:38:52,720 --> 00:38:56,480
policy rules and

00:38:53,839 --> 00:38:58,720
all that kind of stuff we can also see

00:38:56,480 --> 00:39:00,480
if i click on debug

00:38:58,720 --> 00:39:02,240
the configurations for the specific

00:39:00,480 --> 00:39:03,280
meshes themselves so if we look at

00:39:02,240 --> 00:39:05,599
cluster one

00:39:03,280 --> 00:39:07,040
we can see we have the virtual services

00:39:05,599 --> 00:39:07,680
the issue of virtual services that we've

00:39:07,040 --> 00:39:09,280
created

00:39:07,680 --> 00:39:11,440
we have some of the service entries that

00:39:09,280 --> 00:39:12,480
are used to kind of glue this stuff

00:39:11,440 --> 00:39:15,599
together

00:39:12,480 --> 00:39:16,400
uh destination rules and and so forth so

00:39:15,599 --> 00:39:19,520
let me stop

00:39:16,400 --> 00:39:22,320
there i know we have some questions um

00:39:19,520 --> 00:39:25,200
and i have about it looks like five

00:39:22,320 --> 00:39:27,040
minutes unless i get corrected

00:39:25,200 --> 00:39:28,480
um five minutes that's what i was

00:39:27,040 --> 00:39:31,680
getting ready to jump in and tell you

00:39:28,480 --> 00:39:35,040
okay perfect uh let me leave this

00:39:31,680 --> 00:39:36,720
here so first of all uh i

00:39:35,040 --> 00:39:38,880
i want to thank you for attending

00:39:36,720 --> 00:39:41,599
hopefully this was useful

00:39:38,880 --> 00:39:42,000
for you there's there's a lot to dig

00:39:41,599 --> 00:39:46,000
into

00:39:42,000 --> 00:39:49,040
here um it's a pretty exciting way of

00:39:46,000 --> 00:39:52,560
solving some of these challenges so

00:39:49,040 --> 00:39:53,760
please i believe these slides

00:39:52,560 --> 00:39:55,839
i don't remember if i posted them

00:39:53,760 --> 00:39:57,599
already but if not then i will post them

00:39:55,839 --> 00:39:59,839
up on slideshare

00:39:57,599 --> 00:40:01,200
um do reach out to me on social media or

00:39:59,839 --> 00:40:02,800
email or however you would like if you

00:40:01,200 --> 00:40:04,400
have questions and though

00:40:02,800 --> 00:40:06,079
i've had people come up and ask hey is

00:40:04,400 --> 00:40:07,280
it okay if i reach out to you well i'll

00:40:06,079 --> 00:40:10,079
come up and ask myself

00:40:07,280 --> 00:40:12,000
when i've done this in person um and

00:40:10,079 --> 00:40:12,640
i've said yes exactly that's why i put

00:40:12,000 --> 00:40:14,000
my

00:40:12,640 --> 00:40:16,240
information on here so that you can

00:40:14,000 --> 00:40:17,520
reach out um and ask any questions there

00:40:16,240 --> 00:40:18,160
are no stupid questions i know this

00:40:17,520 --> 00:40:20,560
stuff

00:40:18,160 --> 00:40:22,480
is is kind of complicated um please

00:40:20,560 --> 00:40:26,400
reach out and ask questions

00:40:22,480 --> 00:40:28,640
you can dig in at these different urls

00:40:26,400 --> 00:40:30,480
for more go check out the various

00:40:28,640 --> 00:40:34,000
service mesh communities

00:40:30,480 --> 00:40:36,880
the envoy proxy community of course our

00:40:34,000 --> 00:40:37,680
communities around glue which is a api

00:40:36,880 --> 00:40:40,160
gateway

00:40:37,680 --> 00:40:42,079
built on envoy service mesh hub web

00:40:40,160 --> 00:40:43,760
assembly helping these types of things

00:40:42,079 --> 00:40:45,200
definitely there's a lot of information

00:40:43,760 --> 00:40:47,520
out there but but reach out if you have

00:40:45,200 --> 00:40:48,800
questions so

00:40:47,520 --> 00:40:53,440
let me take a look at some of these

00:40:48,800 --> 00:40:56,079
questions um let me see

00:40:53,440 --> 00:40:57,520
what's the security risk for having the

00:40:56,079 --> 00:41:01,200
side car

00:40:57,520 --> 00:41:03,359
handle that mtls and tls termination

00:41:01,200 --> 00:41:05,119
and then having traffic forwarded on the

00:41:03,359 --> 00:41:08,319
application container

00:41:05,119 --> 00:41:09,359
over the plain text protocol okay so

00:41:08,319 --> 00:41:10,560
that's a good question let's come back

00:41:09,359 --> 00:41:14,000
to one of these slides so we can

00:41:10,560 --> 00:41:15,200
take a take a deep uh take a closer look

00:41:14,000 --> 00:41:18,000
at it

00:41:15,200 --> 00:41:18,560
so the question is what is the security

00:41:18,000 --> 00:41:21,200
risk

00:41:18,560 --> 00:41:22,000
when you're sort of offloading tls and

00:41:21,200 --> 00:41:25,839
mtls to

00:41:22,000 --> 00:41:28,960
the proxy and in this use case

00:41:25,839 --> 00:41:32,160
the app is talking to the proxy and

00:41:28,960 --> 00:41:33,280
the proxy then is taking and that could

00:41:32,160 --> 00:41:36,400
be over plain text

00:41:33,280 --> 00:41:38,160
which is what the question said and the

00:41:36,400 --> 00:41:39,359
proxy then

00:41:38,160 --> 00:41:41,839
says oh you're okay you're trying to

00:41:39,359 --> 00:41:45,040
talk to host xyz

00:41:41,839 --> 00:41:45,839
well when i talk to host xyz i'm going

00:41:45,040 --> 00:41:48,800
to open up

00:41:45,839 --> 00:41:49,760
a tls connection to that i'm going to

00:41:48,800 --> 00:41:52,079
send

00:41:49,760 --> 00:41:53,119
uh my client credentials because i

00:41:52,079 --> 00:41:56,800
expect

00:41:53,119 --> 00:41:59,200
um i expect a mutual tls connection here

00:41:56,800 --> 00:41:59,920
and i'm going to expect the server to

00:41:59,200 --> 00:42:01,200
send their

00:41:59,920 --> 00:42:03,520
credentials and you know i'm going to

00:42:01,200 --> 00:42:05,280
verify them and so on so the security

00:42:03,520 --> 00:42:08,000
risk here is

00:42:05,280 --> 00:42:09,760
in for example if we're talking about uh

00:42:08,000 --> 00:42:12,079
a vm

00:42:09,760 --> 00:42:13,040
and the proxies lives on that vm but so

00:42:12,079 --> 00:42:15,760
does the application

00:42:13,040 --> 00:42:16,800
lives on that vm now the question is how

00:42:15,760 --> 00:42:20,079
does the app talk

00:42:16,800 --> 00:42:23,280
to the proxy and

00:42:20,079 --> 00:42:25,440
so the security risk is over that

00:42:23,280 --> 00:42:27,760
uh that communication there istio for

00:42:25,440 --> 00:42:30,960
example sets up communication so that

00:42:27,760 --> 00:42:31,839
iptables does automatic redirect to a a

00:42:30,960 --> 00:42:34,400
port

00:42:31,839 --> 00:42:35,440
on localhost so that all traffic coming

00:42:34,400 --> 00:42:38,800
from the app

00:42:35,440 --> 00:42:42,560
should get redirected to the proxy

00:42:38,800 --> 00:42:44,640
a a localhost port

00:42:42,560 --> 00:42:46,480
so the communication will happen on

00:42:44,640 --> 00:42:48,800
localhost loopback

00:42:46,480 --> 00:42:50,079
so there's there's your part of your

00:42:48,800 --> 00:42:52,240
security risk there

00:42:50,079 --> 00:42:53,359
second part is well what if the app

00:42:52,240 --> 00:42:55,359
somehow circumvents

00:42:53,359 --> 00:42:56,560
the the proxy right so how do you lock

00:42:55,359 --> 00:42:58,560
down the app

00:42:56,560 --> 00:43:00,000
in terms of how how and what it's

00:42:58,560 --> 00:43:02,640
allowed to do

00:43:00,000 --> 00:43:04,079
uh when it talks over the network now

00:43:02,640 --> 00:43:05,119
there are things you can do to mitigate

00:43:04,079 --> 00:43:06,800
this

00:43:05,119 --> 00:43:08,560
uh so for example you can use unix

00:43:06,800 --> 00:43:10,640
domain sockets to talk to

00:43:08,560 --> 00:43:12,800
the proxy and and so forth but that

00:43:10,640 --> 00:43:15,760
that's the area in which you want to

00:43:12,800 --> 00:43:17,040
uh pay pay closes attention hopefully

00:43:15,760 --> 00:43:19,599
that helps

00:43:17,040 --> 00:43:19,599
um

00:43:20,560 --> 00:43:25,520
is it a sidecar pattern so i assume

00:43:23,359 --> 00:43:29,359
they're asked this question is about

00:43:25,520 --> 00:43:32,560
how the capabilities of the service mesh

00:43:29,359 --> 00:43:35,520
get implemented in a deployment

00:43:32,560 --> 00:43:37,119
and that's when the proxy is injected

00:43:35,520 --> 00:43:40,000
lives next to

00:43:37,119 --> 00:43:40,800
the application instance so we talked

00:43:40,000 --> 00:43:43,280
about vms

00:43:40,800 --> 00:43:45,520
a second ago does the same thing is true

00:43:43,280 --> 00:43:47,599
in a kubernetes context

00:43:45,520 --> 00:43:49,200
where each instance of your application

00:43:47,599 --> 00:43:52,240
gets deployed

00:43:49,200 --> 00:43:54,079
with this sidecar proxy so yes so the

00:43:52,240 --> 00:43:56,720
pattern that is being used here is

00:43:54,079 --> 00:43:59,280
is the sidecar pattern where the app

00:43:56,720 --> 00:44:02,400
gets deployed as its own container

00:43:59,280 --> 00:44:03,280
with the sidecar container and then

00:44:02,400 --> 00:44:04,720
kubernetes

00:44:03,280 --> 00:44:07,119
gives you that really nice abstraction

00:44:04,720 --> 00:44:08,800
for grouping those things atomically

00:44:07,119 --> 00:44:10,319
but the proxy ends up becoming a sidecar

00:44:08,800 --> 00:44:13,520
there

00:44:10,319 --> 00:44:15,680
um can we get slides

00:44:13,520 --> 00:44:16,560
yes uh the slides will be on my

00:44:15,680 --> 00:44:18,160
slideshare

00:44:16,560 --> 00:44:19,920
i can submit them to the conference

00:44:18,160 --> 00:44:21,040
organizers as well and i'm not sure

00:44:19,920 --> 00:44:24,240
exactly how that

00:44:21,040 --> 00:44:26,079
gets gets distributed here we have a

00:44:24,240 --> 00:44:27,839
question

00:44:26,079 --> 00:44:29,359
in our environment we have about 50

00:44:27,839 --> 00:44:33,359
back-end api

00:44:29,359 --> 00:44:35,280
eyes managed by ibm's

00:44:33,359 --> 00:44:37,440
connect api connect and backed by

00:44:35,280 --> 00:44:39,040
services routes and kubernetes

00:44:37,440 --> 00:44:40,800
we aren't load balancing across clusters

00:44:39,040 --> 00:44:44,400
yet all

00:44:40,800 --> 00:44:46,000
apps either route from api connect to

00:44:44,400 --> 00:44:47,760
one of the clusters or another depending

00:44:46,000 --> 00:44:49,760
on where the service is housed

00:44:47,760 --> 00:44:51,680
can you envision how istio and

00:44:49,760 --> 00:44:55,119
servicemesh would function

00:44:51,680 --> 00:44:58,240
in this this scenario um

00:44:55,119 --> 00:45:00,960
and i think the answer to this is

00:44:58,240 --> 00:45:02,000
yeah so the the traffic that you're

00:45:00,960 --> 00:45:04,400
talking about

00:45:02,000 --> 00:45:07,280
so far is traffic coming into the

00:45:04,400 --> 00:45:09,040
cluster and using api connect to kind of

00:45:07,280 --> 00:45:11,520
send the traffic off to where it needs

00:45:09,040 --> 00:45:15,040
to go um

00:45:11,520 --> 00:45:18,160
and that can be the the discovery

00:45:15,040 --> 00:45:18,720
of the apps the health checking of the

00:45:18,160 --> 00:45:22,000
apps

00:45:18,720 --> 00:45:23,280
and so on can be improved with something

00:45:22,000 --> 00:45:26,000
like a service mesh

00:45:23,280 --> 00:45:28,079
if you look at our glue api gateway we

00:45:26,000 --> 00:45:30,480
have something called glue federation

00:45:28,079 --> 00:45:32,240
that also it works with the surface mesh

00:45:30,480 --> 00:45:36,800
to solve this type of problem

00:45:32,240 --> 00:45:38,800
um i'll leave the the link right here

00:45:36,800 --> 00:45:40,160
i would say go go to glue and check the

00:45:38,800 --> 00:45:41,680
the federation

00:45:40,160 --> 00:45:44,880
and the integration with with service

00:45:41,680 --> 00:45:48,880
mesh so i think i'm out of time

00:45:44,880 --> 00:45:51,440
um there's another question

00:45:48,880 --> 00:45:52,880
uh from justin let me let me take that

00:45:51,440 --> 00:45:56,560
question

00:45:52,880 --> 00:46:00,720
copy and paste it and i will answer that

00:45:56,560 --> 00:46:02,720
on twitter hey christian um

00:46:00,720 --> 00:46:04,800
yeah so we are out of time i i just

00:46:02,720 --> 00:46:06,960
wanted to thank everyone for coming um

00:46:04,800 --> 00:46:09,280
however i think the session after this

00:46:06,960 --> 00:46:11,599
actually was cancelled so if you want to

00:46:09,280 --> 00:46:13,440
answer that question live you can we

00:46:11,599 --> 00:46:14,480
have a couple extra minutes that we can

00:46:13,440 --> 00:46:16,880
spare

00:46:14,480 --> 00:46:18,400
sure okay yeah be happy too our next

00:46:16,880 --> 00:46:20,160
session is not going to be

00:46:18,400 --> 00:46:22,160
uh just so that i have correct

00:46:20,160 --> 00:46:24,160
information for everyone

00:46:22,160 --> 00:46:25,359
i believe our next session is going to

00:46:24,160 --> 00:46:28,640
be at 1

00:46:25,359 --> 00:46:32,240
30. um the a tour of open source

00:46:28,640 --> 00:46:33,920
on the mainframe okay

00:46:32,240 --> 00:46:35,440
awesome so yeah then let me ask answer

00:46:33,920 --> 00:46:38,640
this so the question

00:46:35,440 --> 00:46:40,319
is can you substitute

00:46:38,640 --> 00:46:42,240
the onboard proxy that handles

00:46:40,319 --> 00:46:43,839
north-south traffic and the service

00:46:42,240 --> 00:46:47,040
mission implementation

00:46:43,839 --> 00:46:49,200
between different clusters with another

00:46:47,040 --> 00:46:50,720
gateway service like azure application

00:46:49,200 --> 00:46:54,839
gateway or kong

00:46:50,720 --> 00:46:58,319
api gateway um so the answer

00:46:54,839 --> 00:47:03,119
is that's a good question

00:46:58,319 --> 00:47:04,880
um the gateways that we use in istio

00:47:03,119 --> 00:47:06,640
versus the gateways that are typically

00:47:04,880 --> 00:47:09,760
used for edge

00:47:06,640 --> 00:47:10,880
ingress um first of all play a different

00:47:09,760 --> 00:47:14,560
role

00:47:10,880 --> 00:47:18,720
so in in istio for example the gateway

00:47:14,560 --> 00:47:20,800
is is um is really used just

00:47:18,720 --> 00:47:24,000
sit simply to get traffic into the

00:47:20,800 --> 00:47:26,880
cluster whereas a gateway like

00:47:24,000 --> 00:47:27,599
azure api gateway or glue for example

00:47:26,880 --> 00:47:29,760
glue is

00:47:27,599 --> 00:47:30,800
another example of an envoy based api

00:47:29,760 --> 00:47:33,200
gateway

00:47:30,800 --> 00:47:34,800
that plays a different role from what

00:47:33,200 --> 00:47:38,319
istio's ingress gateway does

00:47:34,800 --> 00:47:41,200
which is how do we verify the

00:47:38,319 --> 00:47:43,200
trusted user uh how do we you know

00:47:41,200 --> 00:47:45,119
enforce oidc flows

00:47:43,200 --> 00:47:46,880
how do we do things like request and

00:47:45,119 --> 00:47:49,359
message transformation

00:47:46,880 --> 00:47:51,440
uh and decouple the apis and maybe build

00:47:49,359 --> 00:47:54,400
an api developer portal and so on

00:47:51,440 --> 00:47:56,800
so glue or you know azure or any of

00:47:54,400 --> 00:47:59,119
these api management vendors

00:47:56,800 --> 00:48:00,720
that that's the role of those gateways

00:47:59,119 --> 00:48:03,440
now the question is can

00:48:00,720 --> 00:48:04,319
they play the same role in allowing

00:48:03,440 --> 00:48:06,400
multi-cluster

00:48:04,319 --> 00:48:07,760
communication uh the answer is just

00:48:06,400 --> 00:48:10,400
going to come down to when in

00:48:07,760 --> 00:48:11,920
the multi-cluster fashion what is

00:48:10,400 --> 00:48:15,920
gateway is doing

00:48:11,920 --> 00:48:18,880
is fairly simple um and transparent

00:48:15,920 --> 00:48:19,599
sni routing so because we're

00:48:18,880 --> 00:48:22,559
establishing an

00:48:19,599 --> 00:48:25,119
end-to-end mtls connection between the

00:48:22,559 --> 00:48:27,359
workloads in cluster one and cluster two

00:48:25,119 --> 00:48:29,680
the the workloads in cluster one are

00:48:27,359 --> 00:48:32,319
talking to the endpoint

00:48:29,680 --> 00:48:33,440
that is really is really the gateway for

00:48:32,319 --> 00:48:36,400
cluster two

00:48:33,440 --> 00:48:38,160
but all that gateway is doing is sni

00:48:36,400 --> 00:48:40,160
routing sniffing this and i host and say

00:48:38,160 --> 00:48:43,119
oh you want to talk to this one so let's

00:48:40,160 --> 00:48:43,599
let's pass through the connection to the

00:48:43,119 --> 00:48:45,359
to the

00:48:43,599 --> 00:48:46,839
to the actual workload and the workload

00:48:45,359 --> 00:48:50,720
ends up terminating

00:48:46,839 --> 00:48:52,960
the um terminating the connection

00:48:50,720 --> 00:48:54,079
so in that case the gateway can be

00:48:52,960 --> 00:48:57,280
anything that that'll do

00:48:54,079 --> 00:49:00,000
sni uh routing um

00:48:57,280 --> 00:49:01,359
things like issue ingress gateway or

00:49:00,000 --> 00:49:03,119
glue for example they

00:49:01,359 --> 00:49:04,400
you know that can be handled pretty

00:49:03,119 --> 00:49:06,559
pretty simply

00:49:04,400 --> 00:49:08,559
um i believe you can do that with some

00:49:06,559 --> 00:49:11,599
of the other gateways as well

00:49:08,559 --> 00:49:14,400
uh now when it comes to automating the

00:49:11,599 --> 00:49:15,359
you know a large deployment of this

00:49:14,400 --> 00:49:17,680
that's where

00:49:15,359 --> 00:49:19,280
things like a service mesh hub or

00:49:17,680 --> 00:49:21,680
whatever orchestration you're using

00:49:19,280 --> 00:49:23,200
it would be nice to have consistent apis

00:49:21,680 --> 00:49:25,680
it would be nice to have consistent

00:49:23,200 --> 00:49:28,480
implementation of how those gateways are

00:49:25,680 --> 00:49:28,960
debugged and you know turn on logging

00:49:28,480 --> 00:49:31,520
and

00:49:28,960 --> 00:49:32,640
and so on um kind of one of the reasons

00:49:31,520 --> 00:49:34,880
why envoy was

00:49:32,640 --> 00:49:35,920
was built if you look back at what lift

00:49:34,880 --> 00:49:38,640
did

00:49:35,920 --> 00:49:40,240
lift built envoy initially to be sidecar

00:49:38,640 --> 00:49:42,400
proxy then realize

00:49:40,240 --> 00:49:43,760
wait a minute it's hard to manage all

00:49:42,400 --> 00:49:46,480
these albs

00:49:43,760 --> 00:49:47,920
all these edge you know nginx and ha

00:49:46,480 --> 00:49:48,640
proxy and all these different gateways

00:49:47,920 --> 00:49:52,319
that have

00:49:48,640 --> 00:49:52,800
different um operational characteristics

00:49:52,319 --> 00:49:54,880
and

00:49:52,800 --> 00:49:56,400
debugging characteristics and so on so

00:49:54,880 --> 00:49:59,280
just use envelope in

00:49:56,400 --> 00:50:00,640
at the edge as well uh but to answer

00:49:59,280 --> 00:50:01,520
your question as long as it can do an s

00:50:00,640 --> 00:50:03,119
when i pass through

00:50:01,520 --> 00:50:05,200
it might take a little bit of heavy

00:50:03,119 --> 00:50:08,480
lifting to to get it all working but

00:50:05,200 --> 00:50:10,800
that is the technical requirement there

00:50:08,480 --> 00:50:12,480
so i appreciate all the questions i

00:50:10,800 --> 00:50:15,119
appreciate the folks who took uh who

00:50:12,480 --> 00:50:16,559
stood around and

00:50:15,119 --> 00:50:17,920
first saw the presentation and then

00:50:16,559 --> 00:50:19,760
afterward for the questions just reach

00:50:17,920 --> 00:50:27,839
out to me if there's other questions

00:50:19,760 --> 00:50:27,839
and again many thanks for for joining

00:50:27,920 --> 00:50:30,000

YouTube URL: https://www.youtube.com/watch?v=2dtxttnBySc


