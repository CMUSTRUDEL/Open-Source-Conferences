Title: Think Cloud, Develop Locally - Michael Blakeney
Publication date: 2020-12-17
Playlist: All Things Open 2020 - Back-End Dev Track
Description: 
	Presented by: Michael Blakeney, Terazo
Presented at All Things Open 2020 - Back-End Dev Track

Abstract: Developing applications for the cloud presents a new set of problems for engineers and teams.  From handling cloud based service dependencies like queues and blob storage to spinning up new environments all locally,  building an app for the cloud is challenging and can really create drag for a team.  Using modern tools like docker containers, we will dig into some of tactics that can be used to effectively mitigate common issues and help your team accelerate its development.
Captions: 
	00:00:05,359 --> 00:00:08,400
this afternoon we're going to be looking

00:00:06,640 --> 00:00:10,320
at

00:00:08,400 --> 00:00:11,599
a talk called think cloud developed

00:00:10,320 --> 00:00:13,840
locally

00:00:11,599 --> 00:00:15,200
first a little introduction about who i

00:00:13,840 --> 00:00:17,440
am my name is

00:00:15,200 --> 00:00:18,320
michael blatany mike blakeney i've been

00:00:17,440 --> 00:00:20,080
building and

00:00:18,320 --> 00:00:21,359
designing solutions for customers for

00:00:20,080 --> 00:00:22,480
the last nine years and

00:00:21,359 --> 00:00:24,160
i started out as an independent

00:00:22,480 --> 00:00:25,439
contractor eventually made my way over

00:00:24,160 --> 00:00:27,760
to terrazzo

00:00:25,439 --> 00:00:28,880
and now as a lead architect my primary

00:00:27,760 --> 00:00:31,439
focus is on

00:00:28,880 --> 00:00:33,440
designing solutions for customers along

00:00:31,439 --> 00:00:36,239
with supporting and enabling

00:00:33,440 --> 00:00:37,280
our teams to deliver quality platforms

00:00:36,239 --> 00:00:39,040
talk with that

00:00:37,280 --> 00:00:40,879
we have a beautiful 10 month old

00:00:39,040 --> 00:00:41,280
daughter that keeps my wife and i very

00:00:40,879 --> 00:00:43,920
much

00:00:41,280 --> 00:00:46,160
on our toes so we're going to be

00:00:43,920 --> 00:00:48,480
exploring some strategies and tactics

00:00:46,160 --> 00:00:50,079
on analyzing your software development

00:00:48,480 --> 00:00:50,879
work streams and workflows to help

00:00:50,079 --> 00:00:52,559
identify

00:00:50,879 --> 00:00:54,399
and mitigate some of the unique

00:00:52,559 --> 00:00:57,280
challenges in building cloud native

00:00:54,399 --> 00:00:58,079
applications first let's kind of align

00:00:57,280 --> 00:00:59,680
ourselves and

00:00:58,079 --> 00:01:01,600
what we are talking about when we talk

00:00:59,680 --> 00:01:02,800
about a cloud native application

00:01:01,600 --> 00:01:05,519
i want to look at two different

00:01:02,800 --> 00:01:08,000
definitions here the first one is from

00:01:05,519 --> 00:01:09,840
the cloud native foundation

00:01:08,000 --> 00:01:12,240
they say that cloud native technologies

00:01:09,840 --> 00:01:13,680
empower organizations to build and run

00:01:12,240 --> 00:01:16,080
scalable applications

00:01:13,680 --> 00:01:18,799
in modern dynamic environments such as

00:01:16,080 --> 00:01:21,200
the public and private hybrid clouds

00:01:18,799 --> 00:01:22,479
container service meshes microservices

00:01:21,200 --> 00:01:24,560
immutable infrastructure

00:01:22,479 --> 00:01:25,680
and declarative apis exemplify this

00:01:24,560 --> 00:01:27,600
approach

00:01:25,680 --> 00:01:29,040
these techniques enable loosely coupled

00:01:27,600 --> 00:01:31,520
systems that are resilient

00:01:29,040 --> 00:01:33,520
manageable and observable combined with

00:01:31,520 --> 00:01:34,240
robust automation they allow engineers

00:01:33,520 --> 00:01:36,479
to make high

00:01:34,240 --> 00:01:37,439
impact changes frequently and

00:01:36,479 --> 00:01:40,799
predictably

00:01:37,439 --> 00:01:44,320
with minimum toll over

00:01:40,799 --> 00:01:46,079
on the microsoft azure website they talk

00:01:44,320 --> 00:01:48,320
about cloud native applications as cloud

00:01:46,079 --> 00:01:50,799
native apps are built from the ground up

00:01:48,320 --> 00:01:52,159
to optimize for cloud scale and

00:01:50,799 --> 00:01:54,159
performance they're based on

00:01:52,159 --> 00:01:56,560
microservice architectures

00:01:54,159 --> 00:01:58,000
use managed services and take advantage

00:01:56,560 --> 00:01:59,920
of continuous delivery to achieve

00:01:58,000 --> 00:02:02,000
reliability and faster time

00:01:59,920 --> 00:02:03,920
to market so we're talking about

00:02:02,000 --> 00:02:06,079
building applications

00:02:03,920 --> 00:02:07,040
that are specifically designed for the

00:02:06,079 --> 00:02:09,840
cloud

00:02:07,040 --> 00:02:10,239
typically they're loosely coupled they

00:02:09,840 --> 00:02:12,000
have

00:02:10,239 --> 00:02:15,040
resiliency built into them from the

00:02:12,000 --> 00:02:16,560
get-go uh we look at observability so

00:02:15,040 --> 00:02:17,760
we're able to understand what's

00:02:16,560 --> 00:02:20,319
happening to our requests

00:02:17,760 --> 00:02:22,239
as they go from entry to whatever

00:02:20,319 --> 00:02:24,720
business logic we want them to run

00:02:22,239 --> 00:02:25,520
and in the end we ultimately want to be

00:02:24,720 --> 00:02:29,040
able to make

00:02:25,520 --> 00:02:31,520
high impact changes for our cup for our

00:02:29,040 --> 00:02:31,520
businesses

00:02:32,080 --> 00:02:35,040
but there are some challenges to

00:02:33,440 --> 00:02:36,000
building cloud native applications

00:02:35,040 --> 00:02:38,640
because there's a big

00:02:36,000 --> 00:02:39,519
difference to taking what you are

00:02:38,640 --> 00:02:41,360
currently running

00:02:39,519 --> 00:02:43,040
and lifting and shifting it for the

00:02:41,360 --> 00:02:45,120
cloud

00:02:43,040 --> 00:02:46,959
for example building cloud native

00:02:45,120 --> 00:02:48,000
applications have these interesting

00:02:46,959 --> 00:02:48,800
challenges that just need to be

00:02:48,000 --> 00:02:51,440
addressed

00:02:48,800 --> 00:02:52,560
for example like addition to scaling

00:02:51,440 --> 00:02:55,120
horizontally

00:02:52,560 --> 00:02:56,480
we need to be able to typically deploy

00:02:55,120 --> 00:02:57,840
an application that's distributed in

00:02:56,480 --> 00:02:59,360
nature

00:02:57,840 --> 00:03:02,080
this creates challenges when you start

00:02:59,360 --> 00:03:05,360
talking about setting up access control

00:03:02,080 --> 00:03:06,400
for alerting monitoring and logging

00:03:05,360 --> 00:03:09,120
when we're talking about cloud native

00:03:06,400 --> 00:03:11,200
apps are oftentimes just one part of an

00:03:09,120 --> 00:03:12,959
overarching workflow that have multiple

00:03:11,200 --> 00:03:14,080
data points scattered throughout several

00:03:12,959 --> 00:03:15,920
data stores

00:03:14,080 --> 00:03:17,760
and so now we have to talk about how do

00:03:15,920 --> 00:03:20,400
we bring all that together to make sense

00:03:17,760 --> 00:03:22,879
as to what's going on in our platform

00:03:20,400 --> 00:03:25,120
and usually you're deploying a cloud

00:03:22,879 --> 00:03:27,120
native app into a third-party provider

00:03:25,120 --> 00:03:29,680
like amazon web services

00:03:27,120 --> 00:03:30,720
google cloud or microsoft azure and that

00:03:29,680 --> 00:03:32,319
just made your team

00:03:30,720 --> 00:03:35,519
will need to start interacting with the

00:03:32,319 --> 00:03:36,879
nuances of that provider's services

00:03:35,519 --> 00:03:38,400
and a lot of times cloud native

00:03:36,879 --> 00:03:40,159
applications are deployed within

00:03:38,400 --> 00:03:41,760
containers which means

00:03:40,159 --> 00:03:44,159
the involvement of a container

00:03:41,760 --> 00:03:45,920
management platform

00:03:44,159 --> 00:03:47,440
you also have the typical coordination

00:03:45,920 --> 00:03:48,480
across multiple teams that you have to

00:03:47,440 --> 00:03:50,879
deal with

00:03:48,480 --> 00:03:52,159
and then lever then ultimately again

00:03:50,879 --> 00:03:53,040
we're gonna be able to leverage the full

00:03:52,159 --> 00:03:55,040
capabilities

00:03:53,040 --> 00:03:56,560
of the cloud in terms of scalability

00:03:55,040 --> 00:03:59,680
security and cost management

00:03:56,560 --> 00:04:01,599
so how do we begin to look at our

00:03:59,680 --> 00:04:03,040
software development workflows to

00:04:01,599 --> 00:04:05,760
address some of these challenges

00:04:03,040 --> 00:04:06,239
early on and make the most out of

00:04:05,760 --> 00:04:09,120
building

00:04:06,239 --> 00:04:09,120
cloud native apps

00:04:10,000 --> 00:04:14,159
if there's one thing that i'd like for

00:04:12,560 --> 00:04:17,280
you to take away from this conversation

00:04:14,159 --> 00:04:19,759
or this talk is how you work

00:04:17,280 --> 00:04:21,199
is just as important as what you do how

00:04:19,759 --> 00:04:24,160
you work is just as important

00:04:21,199 --> 00:04:26,320
as the work you do everything else that

00:04:24,160 --> 00:04:29,759
we are going to look at today

00:04:26,320 --> 00:04:31,360
is anchored on that one idea

00:04:29,759 --> 00:04:33,520
we're going to be exploring and looking

00:04:31,360 --> 00:04:37,840
at ways of work that can help

00:04:33,520 --> 00:04:37,840
improve the work that we actually do

00:04:39,040 --> 00:04:42,720
so an approach that we can take is

00:04:40,800 --> 00:04:45,840
applying lean processes

00:04:42,720 --> 00:04:48,240
to our workflows what do we mean by that

00:04:45,840 --> 00:04:49,840
well the whole idea of lean process

00:04:48,240 --> 00:04:51,759
analysis looks at

00:04:49,840 --> 00:04:54,400
your current workflow of how you build a

00:04:51,759 --> 00:04:56,880
product and identifies waste and

00:04:54,400 --> 00:04:57,840
tactics for reducing that waste so

00:04:56,880 --> 00:04:58,800
that's what we're going to do we're

00:04:57,840 --> 00:05:01,919
going to look at a

00:04:58,800 --> 00:05:04,479
an example of a development workflow

00:05:01,919 --> 00:05:05,680
analyze that workflow and begin to

00:05:04,479 --> 00:05:08,639
figure out what are some

00:05:05,680 --> 00:05:09,280
tactics we can take to reduce the waste

00:05:08,639 --> 00:05:12,320
reduce

00:05:09,280 --> 00:05:15,360
the time it takes to create code

00:05:12,320 --> 00:05:16,479
so that we can optimize not only that

00:05:15,360 --> 00:05:18,639
individual

00:05:16,479 --> 00:05:20,639
work stream for that application but

00:05:18,639 --> 00:05:22,000
also explore how we can take that and

00:05:20,639 --> 00:05:22,800
bring that out to the rest of the

00:05:22,000 --> 00:05:24,160
organization

00:05:22,800 --> 00:05:25,600
so the rest of the organization can

00:05:24,160 --> 00:05:28,320
benefit from that from those

00:05:25,600 --> 00:05:28,320
optimizations

00:05:28,720 --> 00:05:33,919
so the first step is to look at a

00:05:31,759 --> 00:05:35,039
workflow so this would be an example of

00:05:33,919 --> 00:05:37,759
a value stream

00:05:35,039 --> 00:05:39,440
value stream maps out the steps it takes

00:05:37,759 --> 00:05:40,400
to basically produce a product and get

00:05:39,440 --> 00:05:42,479
it out to the market

00:05:40,400 --> 00:05:44,479
when we talk about software development

00:05:42,479 --> 00:05:45,919
we want to look at what it takes to take

00:05:44,479 --> 00:05:47,840
what it takes to get that one line of

00:05:45,919 --> 00:05:50,320
code in your ide

00:05:47,840 --> 00:05:51,039
from your ide so that it's actually

00:05:50,320 --> 00:05:53,520
running

00:05:51,039 --> 00:05:54,639
in front of a customer so here's an

00:05:53,520 --> 00:05:55,759
example

00:05:54,639 --> 00:05:57,840
you can see that we start out by

00:05:55,759 --> 00:05:59,039
checking code we might set up a

00:05:57,840 --> 00:06:02,000
development environment

00:05:59,039 --> 00:06:03,199
set up some testing do some committing

00:06:02,000 --> 00:06:05,039
we're going to have some

00:06:03,199 --> 00:06:06,479
code review going on in there and have a

00:06:05,039 --> 00:06:08,639
qa process

00:06:06,479 --> 00:06:09,919
it's a pretty straightforward workflow

00:06:08,639 --> 00:06:12,800
in terms of

00:06:09,919 --> 00:06:14,160
writing code and getting it out the door

00:06:12,800 --> 00:06:14,960
if you think about your context in your

00:06:14,160 --> 00:06:17,199
situation

00:06:14,960 --> 00:06:18,160
you might have some additional steps

00:06:17,199 --> 00:06:20,639
that will introduce

00:06:18,160 --> 00:06:22,080
complexity for example architecture

00:06:20,639 --> 00:06:24,080
reviews or compliance reviews

00:06:22,080 --> 00:06:26,000
are additional gates and checks that

00:06:24,080 --> 00:06:27,520
would be added to a works to a value

00:06:26,000 --> 00:06:30,880
stream like this

00:06:27,520 --> 00:06:33,440
to to be able to map that out

00:06:30,880 --> 00:06:34,960
and to properly look at where we are

00:06:33,440 --> 00:06:38,479
where we are producing

00:06:34,960 --> 00:06:38,479
waste in our workflow

00:06:39,440 --> 00:06:43,680
the next important step we need to take

00:06:41,199 --> 00:06:46,000
is identify what actually flows through

00:06:43,680 --> 00:06:46,880
our value stream so it's not just it's

00:06:46,000 --> 00:06:49,199
not just

00:06:46,880 --> 00:06:51,120
code that flows through our work stream

00:06:49,199 --> 00:06:53,280
that code carries value with it

00:06:51,120 --> 00:06:54,880
the code carries particular attributes

00:06:53,280 --> 00:06:57,280
with it

00:06:54,880 --> 00:06:59,840
uh in in the book project to product uh

00:06:57,280 --> 00:07:02,800
dr mick kirsten describes four artifacts

00:06:59,840 --> 00:07:05,280
that can flow through your work stream

00:07:02,800 --> 00:07:06,960
it talks about features defects risks

00:07:05,280 --> 00:07:09,039
and debt

00:07:06,960 --> 00:07:10,319
we can also think about how we can put

00:07:09,039 --> 00:07:11,919
controls and checks

00:07:10,319 --> 00:07:14,000
around these four things features

00:07:11,919 --> 00:07:17,280
defects risk and debt

00:07:14,000 --> 00:07:19,520
putting controls and checks on these

00:07:17,280 --> 00:07:20,880
allow us to appropriately make the kinds

00:07:19,520 --> 00:07:23,280
of decisions as to

00:07:20,880 --> 00:07:25,039
how many features do we deploy how many

00:07:23,280 --> 00:07:27,120
defects do we allow through in order to

00:07:25,039 --> 00:07:29,919
get that functionality to a customer

00:07:27,120 --> 00:07:31,440
how much risk is acceptable and what

00:07:29,919 --> 00:07:32,240
amount of technical debt do we want to

00:07:31,440 --> 00:07:35,120
take on

00:07:32,240 --> 00:07:36,639
in order to deploy this application so

00:07:35,120 --> 00:07:37,919
it's important for us as technical teams

00:07:36,639 --> 00:07:39,599
to recognize that

00:07:37,919 --> 00:07:41,120
it's not just code that flows through

00:07:39,599 --> 00:07:44,240
our work stream

00:07:41,120 --> 00:07:46,160
but it is it's also these four

00:07:44,240 --> 00:07:47,919
attributes of that code that's important

00:07:46,160 --> 00:07:49,120
for us to evaluate and analyze and have

00:07:47,919 --> 00:07:51,520
conversations

00:07:49,120 --> 00:07:52,960
with our product owners and our business

00:07:51,520 --> 00:07:55,360
stakeholders during the development

00:07:52,960 --> 00:07:55,360
process

00:07:55,759 --> 00:08:01,759
so we have an idea as to

00:07:59,199 --> 00:08:03,520
what it means to have a value stream

00:08:01,759 --> 00:08:06,000
what that value stream might look like

00:08:03,520 --> 00:08:08,240
we also have an idea of what's flowing

00:08:06,000 --> 00:08:13,280
through that work stream

00:08:08,240 --> 00:08:17,199
what about the kind of waste that our

00:08:13,280 --> 00:08:20,479
process might produce a research study

00:08:17,199 --> 00:08:22,960
done in may 2017 by pivotal

00:08:20,479 --> 00:08:25,599
identified nine different kinds of waste

00:08:22,960 --> 00:08:28,240
across their customer projects

00:08:25,599 --> 00:08:29,199
so a few of them include things like

00:08:28,240 --> 00:08:32,560
extraneous

00:08:29,199 --> 00:08:33,279
cognitive load this would be when an

00:08:32,560 --> 00:08:35,279
engineer

00:08:33,279 --> 00:08:36,479
need engineer receives something like

00:08:35,279 --> 00:08:39,200
maybe a complex

00:08:36,479 --> 00:08:39,680
or large story for them to go implement

00:08:39,200 --> 00:08:41,680
or

00:08:39,680 --> 00:08:42,959
maybe there's a diverse array of how

00:08:41,680 --> 00:08:46,399
local development environments

00:08:42,959 --> 00:08:46,880
are are stood up and so in the first

00:08:46,399 --> 00:08:49,440
case

00:08:46,880 --> 00:08:50,240
it takes an extra amount of thinking and

00:08:49,440 --> 00:08:52,800
thought

00:08:50,240 --> 00:08:53,600
that could be going into solving novel

00:08:52,800 --> 00:08:55,839
business

00:08:53,600 --> 00:08:56,800
process novel business problems but it

00:08:55,839 --> 00:08:58,080
said that engineer

00:08:56,800 --> 00:09:00,560
has the responsibility of trying to

00:08:58,080 --> 00:09:03,839
figure out what this what this ask

00:09:00,560 --> 00:09:06,720
is psychological distress

00:09:03,839 --> 00:09:09,760
can impact a team things like low team

00:09:06,720 --> 00:09:12,880
morale interpersonal team conflict

00:09:09,760 --> 00:09:15,360
waiting is another form of waste

00:09:12,880 --> 00:09:16,080
this is when you are waiting for access

00:09:15,360 --> 00:09:19,120
provisioning

00:09:16,080 --> 00:09:22,480
or maybe you're waiting on another team

00:09:19,120 --> 00:09:24,080
to complete complete their portion of a

00:09:22,480 --> 00:09:26,240
project in order to move forward with

00:09:24,080 --> 00:09:27,920
your portion of a project

00:09:26,240 --> 00:09:29,760
new resource creation we're talking

00:09:27,920 --> 00:09:32,080
about cloud environments here right

00:09:29,760 --> 00:09:33,120
so we would be talking about deploying

00:09:32,080 --> 00:09:36,640
and and

00:09:33,120 --> 00:09:39,680
utilizing uh cloud resources

00:09:36,640 --> 00:09:41,440
and then overarching slow uh ci city

00:09:39,680 --> 00:09:44,080
pipelines as well

00:09:41,440 --> 00:09:44,480
we also have things like knowledge churn

00:09:44,080 --> 00:09:47,440
when

00:09:44,480 --> 00:09:49,200
new team members are coming in and out

00:09:47,440 --> 00:09:50,000
are maybe we have that one team member

00:09:49,200 --> 00:09:52,240
that knows all

00:09:50,000 --> 00:09:53,839
about just one part knows all about one

00:09:52,240 --> 00:09:55,360
part of an application and no one else

00:09:53,839 --> 00:09:57,440
knows about it

00:09:55,360 --> 00:09:59,200
these are usually the functions or the

00:09:57,440 --> 00:10:01,760
outputs of

00:09:59,200 --> 00:10:03,519
low priority on documentation but that

00:10:01,760 --> 00:10:07,120
knowledge loss

00:10:03,519 --> 00:10:08,800
produces waste in the team we also have

00:10:07,120 --> 00:10:09,600
things like unnecessarily complex

00:10:08,800 --> 00:10:11,360
solutions

00:10:09,600 --> 00:10:12,640
where maybe your application is

00:10:11,360 --> 00:10:15,839
depending upon

00:10:12,640 --> 00:10:17,360
way too many external services or

00:10:15,839 --> 00:10:18,959
the tools that you're using to build

00:10:17,360 --> 00:10:20,640
your software

00:10:18,959 --> 00:10:22,240
they just don't integrate well together

00:10:20,640 --> 00:10:24,640
and you end up having to

00:10:22,240 --> 00:10:27,279
hack some things together to actually be

00:10:24,640 --> 00:10:28,959
able to do your dev work

00:10:27,279 --> 00:10:31,120
and then there's the classic rework

00:10:28,959 --> 00:10:32,160
right where maybe there's technical debt

00:10:31,120 --> 00:10:34,959
where you got to go back

00:10:32,160 --> 00:10:37,040
and fix something or stories that

00:10:34,959 --> 00:10:39,680
weren't implemented correctly because

00:10:37,040 --> 00:10:41,600
the original feature asked what wasn't

00:10:39,680 --> 00:10:44,399
agreed upon or wasn't clear

00:10:41,600 --> 00:10:46,000
clear for all the parties involved maybe

00:10:44,399 --> 00:10:48,880
there's no clear definition of done

00:10:46,000 --> 00:10:50,560
for a development team or just plain old

00:10:48,880 --> 00:10:52,160
defects that are caught later on in the

00:10:50,560 --> 00:10:54,560
process

00:10:52,160 --> 00:10:55,839
now you may have noticed that some of

00:10:54,560 --> 00:10:58,560
the categories of

00:10:55,839 --> 00:11:00,240
waste have overlap with some of the

00:10:58,560 --> 00:11:02,959
things that flow through our

00:11:00,240 --> 00:11:04,959
work stream these are particularly

00:11:02,959 --> 00:11:06,160
important to address because the further

00:11:04,959 --> 00:11:07,120
into the flow they're allowed to

00:11:06,160 --> 00:11:09,200
continue

00:11:07,120 --> 00:11:11,279
the more costly and time consuming they

00:11:09,200 --> 00:11:13,680
become to address

00:11:11,279 --> 00:11:15,600
in other words the longer i allow a

00:11:13,680 --> 00:11:17,519
defect to flow through my stream the

00:11:15,600 --> 00:11:19,839
more expensive and time-consuming it's

00:11:17,519 --> 00:11:21,760
going to be for me to actually fix it

00:11:19,839 --> 00:11:23,519
this is where we get the idea of

00:11:21,760 --> 00:11:25,279
shifting things to the left

00:11:23,519 --> 00:11:26,640
we want to shift things to the left in

00:11:25,279 --> 00:11:29,040
this work stream

00:11:26,640 --> 00:11:30,640
so that we can catch this type the type

00:11:29,040 --> 00:11:33,600
of voice that we want to reduce

00:11:30,640 --> 00:11:35,760
early on in the development process and

00:11:33,600 --> 00:11:36,320
work to mitigate that so that we're able

00:11:35,760 --> 00:11:42,800
to

00:11:36,320 --> 00:11:44,240
optimize across our value stream

00:11:42,800 --> 00:11:47,040
so here's our here's our value stream

00:11:44,240 --> 00:11:48,640
again and then going back to our flow

00:11:47,040 --> 00:11:51,279
you know each individual step

00:11:48,640 --> 00:11:52,240
and transition can introduce waste into

00:11:51,279 --> 00:11:54,800
our flow

00:11:52,240 --> 00:11:57,040
so as i move from each one of these and

00:11:54,800 --> 00:11:58,800
as i work in each one of these stages

00:11:57,040 --> 00:12:01,040
there's a potential for introduction of

00:11:58,800 --> 00:12:01,920
waste so we want to put together some

00:12:01,040 --> 00:12:04,399
tactics

00:12:01,920 --> 00:12:05,040
that we can begin to take that will help

00:12:04,399 --> 00:12:08,480
us

00:12:05,040 --> 00:12:10,480
both identify and reduce that waste

00:12:08,480 --> 00:12:12,800
and then propagate these tactics across

00:12:10,480 --> 00:12:16,480
the organization so that optimizations

00:12:12,800 --> 00:12:19,920
can have a maximum impact

00:12:16,480 --> 00:12:21,519
remember there if there's one thing that

00:12:19,920 --> 00:12:22,839
i would love for you to take away and be

00:12:21,519 --> 00:12:24,639
convinced of as a result of this

00:12:22,839 --> 00:12:26,800
conversation is that

00:12:24,639 --> 00:12:28,160
how you work is just as important as the

00:12:26,800 --> 00:12:30,160
work you do

00:12:28,160 --> 00:12:32,320
so the strategy that we can take to

00:12:30,160 --> 00:12:34,160
implement this concept

00:12:32,320 --> 00:12:35,839
of using these lean principles is we're

00:12:34,160 --> 00:12:38,079
going to look at different ways of

00:12:35,839 --> 00:12:40,000
encapsulating optimization

00:12:38,079 --> 00:12:41,600
into what maybe we can call reusable

00:12:40,000 --> 00:12:44,160
project patterns

00:12:41,600 --> 00:12:46,079
reusable project patterns are solutions

00:12:44,160 --> 00:12:47,040
that can be easily shared across your

00:12:46,079 --> 00:12:49,519
team

00:12:47,040 --> 00:12:51,040
and organization they can be in the form

00:12:49,519 --> 00:12:53,200
of example projects

00:12:51,040 --> 00:12:55,519
startup projects reusable project

00:12:53,200 --> 00:12:58,000
configurations and automation

00:12:55,519 --> 00:13:00,160
the important thing to identify here is

00:12:58,000 --> 00:13:02,720
that the artifact is a pattern

00:13:00,160 --> 00:13:03,519
and it's shared across the team and

00:13:02,720 --> 00:13:06,639
ideally

00:13:03,519 --> 00:13:07,760
beyond that so let's look at a possible

00:13:06,639 --> 00:13:10,800
roadmap

00:13:07,760 --> 00:13:13,600
we can go down to help us find some of

00:13:10,800 --> 00:13:13,600
these patterns

00:13:14,399 --> 00:13:17,839
all right the first tactic for reducing

00:13:17,360 --> 00:13:20,480
waste

00:13:17,839 --> 00:13:21,760
is to build your pipelines as soon as

00:13:20,480 --> 00:13:23,519
possible

00:13:21,760 --> 00:13:25,360
ideally this is the first thing that

00:13:23,519 --> 00:13:26,560
gets built out in any project that you

00:13:25,360 --> 00:13:29,040
do

00:13:26,560 --> 00:13:31,120
your pipeline is what moves the code

00:13:29,040 --> 00:13:32,079
from station to station and your

00:13:31,120 --> 00:13:33,920
workflow

00:13:32,079 --> 00:13:36,160
it's what gets your code off of your

00:13:33,920 --> 00:13:37,839
desk into a development environment

00:13:36,160 --> 00:13:40,000
out of a development environment into a

00:13:37,839 --> 00:13:42,639
qa and out to production

00:13:40,000 --> 00:13:44,160
it automates all of those steps so that

00:13:42,639 --> 00:13:46,639
so that when they are done

00:13:44,160 --> 00:13:47,360
they're done exactly the same way every

00:13:46,639 --> 00:13:49,440
single time

00:13:47,360 --> 00:13:51,440
and with as minimal human interaction as

00:13:49,440 --> 00:13:53,600
possible

00:13:51,440 --> 00:13:54,959
this doesn't have to be a lot of

00:13:53,600 --> 00:13:56,880
functionality built out

00:13:54,959 --> 00:13:58,480
built out into it as either we're

00:13:56,880 --> 00:14:00,399
talking about a first pass we're just

00:13:58,480 --> 00:14:02,800
laying the foundation here

00:14:00,399 --> 00:14:03,760
so for example if your project is to

00:14:02,800 --> 00:14:06,959
build out an api

00:14:03,760 --> 00:14:07,600
just build a single endpoint roll that

00:14:06,959 --> 00:14:09,360
out

00:14:07,600 --> 00:14:11,120
and have a pipeline that's going to be

00:14:09,360 --> 00:14:13,440
able to take that in

00:14:11,120 --> 00:14:14,399
deploy it and you're able to test it out

00:14:13,440 --> 00:14:17,600
in product in a

00:14:14,399 --> 00:14:18,959
in a dev-like environment

00:14:17,600 --> 00:14:20,800
think about what is the minimal amount

00:14:18,959 --> 00:14:22,480
of work you need to be able to lay that

00:14:20,800 --> 00:14:24,880
first pipeline out and get some code

00:14:22,480 --> 00:14:26,480
pushed into it

00:14:24,880 --> 00:14:27,760
another advantage to doing this is that

00:14:26,480 --> 00:14:29,120
your development team begins

00:14:27,760 --> 00:14:31,519
conversations

00:14:29,120 --> 00:14:32,480
with the with the with a traditional

00:14:31,519 --> 00:14:34,880
operations group

00:14:32,480 --> 00:14:36,320
sooner rather than later i've lost track

00:14:34,880 --> 00:14:38,000
of the number of features that

00:14:36,320 --> 00:14:40,160
i've been involved in throughout my

00:14:38,000 --> 00:14:42,720
career where we've built amazing stuff

00:14:40,160 --> 00:14:43,600
really cool stuff but we're completely

00:14:42,720 --> 00:14:45,680
stopped because

00:14:43,600 --> 00:14:47,199
we did not initiate that conversation

00:14:45,680 --> 00:14:49,760
with our colleagues earlier

00:14:47,199 --> 00:14:51,440
this is no one's fault it's really just

00:14:49,760 --> 00:14:51,920
a really just a function of tunnel

00:14:51,440 --> 00:14:54,639
vision

00:14:51,920 --> 00:14:56,240
where as a team we get excited about

00:14:54,639 --> 00:14:57,680
building cool software that helps our

00:14:56,240 --> 00:15:00,480
customers

00:14:57,680 --> 00:15:01,360
so start those conversations early

00:15:00,480 --> 00:15:04,079
figure out

00:15:01,360 --> 00:15:05,760
who's involved in getting your code into

00:15:04,079 --> 00:15:07,360
production

00:15:05,760 --> 00:15:09,199
this is why the mapping out your value

00:15:07,360 --> 00:15:10,399
stream is so important it helps you

00:15:09,199 --> 00:15:13,040
identify

00:15:10,399 --> 00:15:14,320
those key teams and key players that you

00:15:13,040 --> 00:15:16,560
need to have conversations

00:15:14,320 --> 00:15:19,279
early on about bring them in and bring

00:15:16,560 --> 00:15:22,000
them along for the ride in your process

00:15:19,279 --> 00:15:22,800
i even go so far as to to say you know

00:15:22,000 --> 00:15:25,839
set up

00:15:22,800 --> 00:15:26,800
monthly or twice a month meetings with

00:15:25,839 --> 00:15:29,920
these individuals

00:15:26,800 --> 00:15:32,079
where it's more or less a

00:15:29,920 --> 00:15:33,199
um a town hall type meeting where you're

00:15:32,079 --> 00:15:34,800
presenting

00:15:33,199 --> 00:15:37,120
this is where we are do you have any

00:15:34,800 --> 00:15:39,040
questions an open book about it

00:15:37,120 --> 00:15:40,480
so that you're able to begin addressing

00:15:39,040 --> 00:15:43,279
their concerns earlier

00:15:40,480 --> 00:15:43,279
rather than later

00:15:44,880 --> 00:15:48,320
the next hop on our roadmap is to

00:15:46,800 --> 00:15:50,160
localize quality

00:15:48,320 --> 00:15:51,600
and what i mean by that is we want to

00:15:50,160 --> 00:15:52,320
allow our engineers to be able to

00:15:51,600 --> 00:15:55,519
discover

00:15:52,320 --> 00:15:58,399
and fix quality related issues sooner

00:15:55,519 --> 00:15:59,920
rather than later remember that defects

00:15:58,399 --> 00:16:02,320
is one of the categories of waste that

00:15:59,920 --> 00:16:05,279
can flow through your value stream

00:16:02,320 --> 00:16:06,160
as such catching defects and similar

00:16:05,279 --> 00:16:08,079
types of waste

00:16:06,160 --> 00:16:09,839
before they get too far down the value

00:16:08,079 --> 00:16:11,040
stream is going to save time money and

00:16:09,839 --> 00:16:13,600
stress

00:16:11,040 --> 00:16:15,440
so how do we do this we can leverage

00:16:13,600 --> 00:16:18,639
tools like static analysis

00:16:15,440 --> 00:16:20,240
and linting directly into our ides

00:16:18,639 --> 00:16:21,759
use git hooks and other tools to

00:16:20,240 --> 00:16:23,199
integrate quality assurance at the time

00:16:21,759 --> 00:16:25,600
of committing

00:16:23,199 --> 00:16:26,399
additionally put these tools into your

00:16:25,600 --> 00:16:28,000
pipeline

00:16:26,399 --> 00:16:30,079
and make the alerts very clear and

00:16:28,000 --> 00:16:31,920
accessible to engineers

00:16:30,079 --> 00:16:33,440
and then enforce unit and integration

00:16:31,920 --> 00:16:35,680
testing were appropriate

00:16:33,440 --> 00:16:37,199
all of these things together help

00:16:35,680 --> 00:16:39,440
engineers get the feedback

00:16:37,199 --> 00:16:41,040
faster they need to address quality

00:16:39,440 --> 00:16:43,199
issues earlier

00:16:41,040 --> 00:16:45,920
so let's look at a few examples of how

00:16:43,199 --> 00:16:45,920
we might do that

00:16:47,199 --> 00:16:50,639
one open source tool that you can

00:16:48,560 --> 00:16:53,519
consider bringing into your to your

00:16:50,639 --> 00:16:55,199
workflow is tool called sonarland it's

00:16:53,519 --> 00:16:57,839
created by sonarcube

00:16:55,199 --> 00:16:59,199
or sonar source rather who also makes a

00:16:57,839 --> 00:17:01,920
product called sonarcube

00:16:59,199 --> 00:17:03,199
what's really convenient about solarland

00:17:01,920 --> 00:17:05,520
is that it brings

00:17:03,199 --> 00:17:06,720
up brings a lot of the power sonar cube

00:17:05,520 --> 00:17:10,000
directly to

00:17:06,720 --> 00:17:13,199
your ide so for languages

00:17:10,000 --> 00:17:15,120
like typescript java python

00:17:13,199 --> 00:17:16,240
sonarland can be installed and ran

00:17:15,120 --> 00:17:18,160
directly

00:17:16,240 --> 00:17:20,160
and independently of an active sonar

00:17:18,160 --> 00:17:22,640
cube instance

00:17:20,160 --> 00:17:24,480
this means where in a typical sonarqube

00:17:22,640 --> 00:17:25,199
flow you might have something where a

00:17:24,480 --> 00:17:27,520
developer

00:17:25,199 --> 00:17:29,039
writes their code they commit and push

00:17:27,520 --> 00:17:31,760
to a trunk and then

00:17:29,039 --> 00:17:33,919
perhaps uh sonarqube picks up on that

00:17:31,760 --> 00:17:35,679
change and does the analysis

00:17:33,919 --> 00:17:37,120
sonarland is right there running

00:17:35,679 --> 00:17:41,039
alongside with you

00:17:37,120 --> 00:17:42,080
and the the uh as the engineer is making

00:17:41,039 --> 00:17:44,960
code changes

00:17:42,080 --> 00:17:46,160
they can get the feedback directly from

00:17:44,960 --> 00:17:50,799
sonar cube

00:17:46,160 --> 00:17:50,799
sonarlin here's an example

00:17:51,200 --> 00:17:55,760
here we see sonarland picking up what

00:17:54,000 --> 00:17:57,600
it's calling cognitive complexity

00:17:55,760 --> 00:17:59,840
basically it's ran an algorithm that's

00:17:57,600 --> 00:18:00,720
done a count on the complexity of this

00:17:59,840 --> 00:18:03,760
function

00:18:00,720 --> 00:18:04,480
and it's telling the engineer hey is

00:18:03,760 --> 00:18:07,840
function

00:18:04,480 --> 00:18:08,640
is a bit complicated you need to

00:18:07,840 --> 00:18:10,799
consider

00:18:08,640 --> 00:18:12,840
decomposing it into smaller more

00:18:10,799 --> 00:18:16,000
bite-sized

00:18:12,840 --> 00:18:18,000
pieces it's also an example of something

00:18:16,000 --> 00:18:20,400
that maybe a static analysis tool

00:18:18,000 --> 00:18:21,840
or maybe some more traditional

00:18:20,400 --> 00:18:24,480
traditional lenting tools

00:18:21,840 --> 00:18:25,280
may not necessarily catch because of the

00:18:24,480 --> 00:18:29,520
the complex

00:18:25,280 --> 00:18:31,679
nature of this kind of check

00:18:29,520 --> 00:18:33,440
another here's another example from

00:18:31,679 --> 00:18:35,679
centerlint as well

00:18:33,440 --> 00:18:36,960
here this is a javascript or typescript

00:18:35,679 --> 00:18:38,480
example where

00:18:36,960 --> 00:18:40,320
it's just calling out that you know you

00:18:38,480 --> 00:18:40,640
really don't need to have this await

00:18:40,320 --> 00:18:43,120
here

00:18:40,640 --> 00:18:43,919
on line 10. everything's already wrapped

00:18:43,120 --> 00:18:46,160
in a promise

00:18:43,919 --> 00:18:48,080
so why throw another weight here get rid

00:18:46,160 --> 00:18:49,520
of it there's no need for it

00:18:48,080 --> 00:18:53,039
and it just makes your code that much

00:18:49,520 --> 00:18:53,039
more cleaner and less complex

00:18:54,960 --> 00:18:58,400
so after we have a basic pipeline in

00:18:57,440 --> 00:19:00,720
place

00:18:58,400 --> 00:19:01,520
and we are beginning to push quality

00:19:00,720 --> 00:19:04,000
checks

00:19:01,520 --> 00:19:06,000
to the engineers we can look at

00:19:04,000 --> 00:19:08,720
beginning to decouple our application

00:19:06,000 --> 00:19:10,960
from outside dependencies specifically

00:19:08,720 --> 00:19:12,720
we can look at what apis we might be

00:19:10,960 --> 00:19:14,640
dependent on

00:19:12,720 --> 00:19:16,080
these become candidates for either

00:19:14,640 --> 00:19:18,400
taking those apps taking those

00:19:16,080 --> 00:19:20,400
dependencies and running them locally

00:19:18,400 --> 00:19:22,880
or figuring out how we might mock out

00:19:20,400 --> 00:19:24,240
the apis and be able to develop against

00:19:22,880 --> 00:19:27,200
a set of mock apis

00:19:24,240 --> 00:19:27,200
before integrating

00:19:27,280 --> 00:19:30,720
some of the things that you're going to

00:19:28,160 --> 00:19:32,640
want to consider when deciding to run a

00:19:30,720 --> 00:19:34,799
dependency locally

00:19:32,640 --> 00:19:36,880
would look like this so you would have

00:19:34,799 --> 00:19:38,400
you'd have to ask yourself

00:19:36,880 --> 00:19:39,760
does the service itself that you want to

00:19:38,400 --> 00:19:40,799
bring in does it have its own

00:19:39,760 --> 00:19:43,360
dependencies

00:19:40,799 --> 00:19:46,160
and a microservice architecture that

00:19:43,360 --> 00:19:47,760
wouldn't be too uncommon

00:19:46,160 --> 00:19:49,440
does the service need its own data

00:19:47,760 --> 00:19:52,880
storage or

00:19:49,440 --> 00:19:54,880
or seating data and can it be ran

00:19:52,880 --> 00:19:56,400
in a container you know one of the

00:19:54,880 --> 00:19:59,039
themes that we're going to see here

00:19:56,400 --> 00:20:00,559
is the idea that we want to leverage

00:19:59,039 --> 00:20:01,600
docker containers as part of our

00:20:00,559 --> 00:20:04,640
workflow

00:20:01,600 --> 00:20:05,760
this allows us to reduce the amount of

00:20:04,640 --> 00:20:07,919
dependencies that an

00:20:05,760 --> 00:20:09,679
engineer needs to have in order to come

00:20:07,919 --> 00:20:12,640
on board to a project

00:20:09,679 --> 00:20:14,720
it in other words we're able to wrap in

00:20:12,640 --> 00:20:16,400
all those dependencies into a container

00:20:14,720 --> 00:20:17,919
and run those containers rather than

00:20:16,400 --> 00:20:20,960
having to install all the other

00:20:17,919 --> 00:20:21,760
all the components you might need a lot

00:20:20,960 --> 00:20:24,159
of times it's

00:20:21,760 --> 00:20:26,240
it's just a lot simpler to mock service

00:20:24,159 --> 00:20:28,000
dependency apis

00:20:26,240 --> 00:20:30,240
this is particularly useful when you

00:20:28,000 --> 00:20:32,000
have an api client like a front end that

00:20:30,240 --> 00:20:33,679
needs to be built in parallel with the

00:20:32,000 --> 00:20:34,880
back end that's like the classic example

00:20:33,679 --> 00:20:37,280
of this

00:20:34,880 --> 00:20:38,480
so taking an api first approach and

00:20:37,280 --> 00:20:41,600
mocking the end points

00:20:38,480 --> 00:20:44,640
can be done with a few open source tools

00:20:41,600 --> 00:20:46,000
here here's here are some of them so the

00:20:44,640 --> 00:20:49,280
first tool we're going to look at is the

00:20:46,000 --> 00:20:51,840
using open api spec to define your api

00:20:49,280 --> 00:20:52,320
the open api spec is the next iteration

00:20:51,840 --> 00:20:55,120
of

00:20:52,320 --> 00:20:57,280
what was called swagger it supports

00:20:55,120 --> 00:20:58,320
definitions for not just the endpoints

00:20:57,280 --> 00:21:00,320
in your api

00:20:58,320 --> 00:21:02,480
but also their return types their

00:21:00,320 --> 00:21:04,000
statuses responses

00:21:02,480 --> 00:21:05,520
and all the kind of different

00:21:04,000 --> 00:21:08,400
authorization methods that

00:21:05,520 --> 00:21:10,400
your api would want to support there are

00:21:08,400 --> 00:21:12,080
numerous tools that leverage the open

00:21:10,400 --> 00:21:15,360
api spec

00:21:12,080 --> 00:21:16,880
including code generation for clients

00:21:15,360 --> 00:21:20,159
and back-end

00:21:16,880 --> 00:21:22,000
and interactive api documentation one of

00:21:20,159 --> 00:21:24,240
the one of the tools that

00:21:22,000 --> 00:21:26,400
that i really like to use is the swagger

00:21:24,240 --> 00:21:28,080
ui tool

00:21:26,400 --> 00:21:30,159
this too can be spun up in a container

00:21:28,080 --> 00:21:34,159
and essentially you feed it your

00:21:30,159 --> 00:21:37,520
api your swagger api your open api spec

00:21:34,159 --> 00:21:38,080
and the the ui tool spins up and it

00:21:37,520 --> 00:21:40,480
presents

00:21:38,080 --> 00:21:42,400
a nice interactive documentation page

00:21:40,480 --> 00:21:44,960
for your api

00:21:42,400 --> 00:21:46,880
so the ap open api spec is basically

00:21:44,960 --> 00:21:48,559
going to become that contract

00:21:46,880 --> 00:21:51,919
that your client and backend

00:21:48,559 --> 00:21:51,919
applications are going to agree on

00:21:53,520 --> 00:21:57,760
the next tool that can help with your

00:21:55,440 --> 00:22:00,640
dependencies is prism

00:21:57,760 --> 00:22:01,919
prism takes your api spec and the

00:22:00,640 --> 00:22:04,640
examples you define

00:22:01,919 --> 00:22:05,120
to launch a mock server for you so

00:22:04,640 --> 00:22:08,080
imagine

00:22:05,120 --> 00:22:09,360
imagine that scenario you've agreed upon

00:22:08,080 --> 00:22:12,159
an open api

00:22:09,360 --> 00:22:12,960
it's defined in this specification and

00:22:12,159 --> 00:22:15,600
now you have

00:22:12,960 --> 00:22:16,000
a tool that can be used to quickly spin

00:22:15,600 --> 00:22:19,280
up

00:22:16,000 --> 00:22:22,559
this uh the the api with mock data

00:22:19,280 --> 00:22:23,360
in containers now what i really like

00:22:22,559 --> 00:22:25,919
about prism

00:22:23,360 --> 00:22:28,000
is it takes this to the next level you

00:22:25,919 --> 00:22:29,280
can also run prism in what's called a

00:22:28,000 --> 00:22:31,760
proxy mode

00:22:29,280 --> 00:22:33,280
which is going to do two things first

00:22:31,760 --> 00:22:34,000
it's going to attempt to proxy the

00:22:33,280 --> 00:22:37,120
requests

00:22:34,000 --> 00:22:39,440
to the service so the scenario is

00:22:37,120 --> 00:22:40,320
i've got my client and it's trying to

00:22:39,440 --> 00:22:44,640
utilize

00:22:40,320 --> 00:22:46,720
a yet to be fully completed back-end api

00:22:44,640 --> 00:22:49,760
so i have a handful of api endpoints

00:22:46,720 --> 00:22:49,760
that are actually functioning

00:22:50,159 --> 00:22:57,280
i tell prism hey proxy to

00:22:53,440 --> 00:23:00,320
that service and here's my open api spec

00:22:57,280 --> 00:23:02,320
prism is going to

00:23:00,320 --> 00:23:04,400
attempt to send the request to the

00:23:02,320 --> 00:23:05,919
service if the service responds

00:23:04,400 --> 00:23:09,039
then it's going to forward that request

00:23:05,919 --> 00:23:11,919
back to the front end or the client

00:23:09,039 --> 00:23:13,120
if the service responds back with a 501

00:23:11,919 --> 00:23:15,760
status code

00:23:13,120 --> 00:23:16,640
then prism is going to fall back to your

00:23:15,760 --> 00:23:18,480
open api

00:23:16,640 --> 00:23:20,559
spec which will read this which will

00:23:18,480 --> 00:23:23,600
then return the mock data

00:23:20,559 --> 00:23:24,080
this allows you to incrementally build

00:23:23,600 --> 00:23:26,640
out

00:23:24,080 --> 00:23:27,520
your backend service for for your

00:23:26,640 --> 00:23:30,559
clients

00:23:27,520 --> 00:23:32,880
uh without having to do a complete on

00:23:30,559 --> 00:23:35,039
off am i using mock data or am i using

00:23:32,880 --> 00:23:37,679
the handful of implemented

00:23:35,039 --> 00:23:40,080
uh service api endpoints that have been

00:23:37,679 --> 00:23:40,080
developed

00:23:42,159 --> 00:23:45,440
and we've already talked about using

00:23:43,520 --> 00:23:47,279
containers but how

00:23:45,440 --> 00:23:49,679
what what can we use to orchestrate this

00:23:47,279 --> 00:23:50,320
together one tool that's really helpful

00:23:49,679 --> 00:23:52,720
is

00:23:50,320 --> 00:23:54,080
leveraging docker compose so docker

00:23:52,720 --> 00:23:57,200
compose

00:23:54,080 --> 00:23:58,400
it basically takes a yaml file yaml

00:23:57,200 --> 00:24:01,279
specification

00:23:58,400 --> 00:24:02,840
of the containers that you want to run

00:24:01,279 --> 00:24:04,799
and the configurations for those

00:24:02,840 --> 00:24:07,760
containers

00:24:04,799 --> 00:24:08,720
this is an example of how you can use

00:24:07,760 --> 00:24:12,559
docker to

00:24:08,720 --> 00:24:14,880
spin up prism in mock mode

00:24:12,559 --> 00:24:16,320
by committing the open api spec along

00:24:14,880 --> 00:24:18,880
with this docker composiable to your

00:24:16,320 --> 00:24:20,880
code repository a new team member

00:24:18,880 --> 00:24:22,640
simply installs docker and docker

00:24:20,880 --> 00:24:24,480
compose and then run doc

00:24:22,640 --> 00:24:26,640
runs docker compose up to launch the

00:24:24,480 --> 00:24:28,799
dependency for your application

00:24:26,640 --> 00:24:31,360
so there's no more having to figure out

00:24:28,799 --> 00:24:33,039
what kinds of dependencies

00:24:31,360 --> 00:24:35,440
prism might need or any other service

00:24:33,039 --> 00:24:38,000
that you want to deploy or run

00:24:35,440 --> 00:24:39,760
you simply you simply execute docker

00:24:38,000 --> 00:24:42,559
compose up

00:24:39,760 --> 00:24:44,400
now there's one caveat to keep in mind

00:24:42,559 --> 00:24:46,240
docker compose can be

00:24:44,400 --> 00:24:47,919
very challenging to manage as the number

00:24:46,240 --> 00:24:48,240
of dependencies that your application

00:24:47,919 --> 00:24:51,039
has

00:24:48,240 --> 00:24:52,159
grows this is where you as a team need

00:24:51,039 --> 00:24:53,520
to figure out

00:24:52,159 --> 00:24:55,919
how you want to handle those

00:24:53,520 --> 00:24:58,159
complexities keep in mind that the

00:24:55,919 --> 00:25:01,360
docker compose tactic here

00:24:58,159 --> 00:25:03,039
is really best suited for uh the single

00:25:01,360 --> 00:25:05,600
application that you're working on

00:25:03,039 --> 00:25:06,480
and its dependencies you're going you

00:25:05,600 --> 00:25:08,240
will quickly hit

00:25:06,480 --> 00:25:10,559
diminishing returns if you begin to

00:25:08,240 --> 00:25:12,559
include every service application in

00:25:10,559 --> 00:25:14,080
your stack or in your platform

00:25:12,559 --> 00:25:17,279
and you're trying to run all of those in

00:25:14,080 --> 00:25:17,279
a single docker compose

00:25:20,080 --> 00:25:23,120
while we're talking about the subject of

00:25:21,600 --> 00:25:25,840
containerization let's talk about

00:25:23,120 --> 00:25:27,840
containerizing your databases

00:25:25,840 --> 00:25:30,320
in the same way we can use containers to

00:25:27,840 --> 00:25:32,159
run the apis or services we need

00:25:30,320 --> 00:25:34,559
we can set up docker compose to run our

00:25:32,159 --> 00:25:36,880
databases locally

00:25:34,559 --> 00:25:40,000
this is especially true for popular open

00:25:36,880 --> 00:25:42,000
source databases like mysql and postgres

00:25:40,000 --> 00:25:43,120
your team can leverage these tools as

00:25:42,000 --> 00:25:45,279
well for handling

00:25:43,120 --> 00:25:46,640
uh schema migration and seeders to

00:25:45,279 --> 00:25:48,960
efficiently make changes and run

00:25:46,640 --> 00:25:51,679
consistent versions of the database

00:25:48,960 --> 00:25:54,080
locally thus removing dependencies that

00:25:51,679 --> 00:25:56,320
a team might have on a shared database

00:25:54,080 --> 00:25:57,600
and help minimize or bring down the

00:25:56,320 --> 00:26:00,159
amount of

00:25:57,600 --> 00:26:01,120
collisions that might occur with the all

00:26:00,159 --> 00:26:05,360
with the

00:26:01,120 --> 00:26:05,360
whole team leveraging one database

00:26:06,240 --> 00:26:09,279
so here's an example of what you might

00:26:08,960 --> 00:26:11,520
do

00:26:09,279 --> 00:26:13,120
to for a postgres database in your

00:26:11,520 --> 00:26:15,279
docker compose file

00:26:13,120 --> 00:26:16,880
note that we're also running the server

00:26:15,279 --> 00:26:18,559
this prism service as well

00:26:16,880 --> 00:26:20,159
and we introduced another tool called

00:26:18,559 --> 00:26:23,200
addminer um

00:26:20,159 --> 00:26:27,919
to help give us a nice web ui

00:26:23,200 --> 00:26:27,919
for for postgres

00:26:28,559 --> 00:26:32,720
and again it gives us this gives us a

00:26:31,039 --> 00:26:34,960
great starting point for new engineers

00:26:32,720 --> 00:26:36,159
to onboard to your project

00:26:34,960 --> 00:26:38,080
so if we walk through this docker

00:26:36,159 --> 00:26:40,000
compose file we see we have our

00:26:38,080 --> 00:26:41,679
my database service which consists of

00:26:40,000 --> 00:26:44,960
the postgres database

00:26:41,679 --> 00:26:47,600
we're exposing or providing ports 5432

00:26:44,960 --> 00:26:50,400
for our our application under

00:26:47,600 --> 00:26:52,720
development to access

00:26:50,400 --> 00:26:53,600
we're leveraging adminer which like we

00:26:52,720 --> 00:26:56,799
said before

00:26:53,600 --> 00:26:59,520
is just a real simple uh web ui

00:26:56,799 --> 00:27:00,400
uh that you can set up to interact with

00:26:59,520 --> 00:27:03,679
your database

00:27:00,400 --> 00:27:05,840
giving you a visual um a visual ui

00:27:03,679 --> 00:27:06,720
against your database and then we have

00:27:05,840 --> 00:27:10,240
the pet store

00:27:06,720 --> 00:27:12,640
api that's being ran with prism

00:27:10,240 --> 00:27:14,000
under mock mode one thing to keep in

00:27:12,640 --> 00:27:16,799
mind because we're using docker

00:27:14,000 --> 00:27:19,120
containers here

00:27:16,799 --> 00:27:20,480
is that all the networking for these

00:27:19,120 --> 00:27:23,600
different containers is

00:27:20,480 --> 00:27:25,279
some is pretty much self-contained so

00:27:23,600 --> 00:27:26,720
where if you were to run add miner on

00:27:25,279 --> 00:27:28,720
your local right on your

00:27:26,720 --> 00:27:30,000
machine you might you might point admire

00:27:28,720 --> 00:27:32,840
you might try and point admire to

00:27:30,000 --> 00:27:35,360
postgres using like localhost 5432

00:27:32,840 --> 00:27:37,200
right um however you got to remember

00:27:35,360 --> 00:27:38,880
that addminer in this instance is

00:27:37,200 --> 00:27:42,000
running within its container

00:27:38,880 --> 00:27:43,440
and if i were to point it to localhost

00:27:42,000 --> 00:27:45,360
it i'm actually pointing it to the

00:27:43,440 --> 00:27:47,440
localhost on addminer

00:27:45,360 --> 00:27:49,279
so what what dockercompose brings to the

00:27:47,440 --> 00:27:51,919
table to help you with here

00:27:49,279 --> 00:27:54,080
is across all of these services docker

00:27:51,919 --> 00:27:56,159
compose will resolve the host name

00:27:54,080 --> 00:27:58,159
based on the service name so to

00:27:56,159 --> 00:28:00,399
configure addminer in this case

00:27:58,159 --> 00:28:03,440
we would say we would tell addminer to

00:28:00,399 --> 00:28:05,360
look at my database 5432

00:28:03,440 --> 00:28:06,720
and then docker compose behind the seeds

00:28:05,360 --> 00:28:09,120
takes care of

00:28:06,720 --> 00:28:10,799
resolving that that address and making

00:28:09,120 --> 00:28:17,200
the correct routing calls so that you're

00:28:10,799 --> 00:28:20,000
able to interact with that container

00:28:17,200 --> 00:28:22,559
schema migration tools enable teams to

00:28:20,000 --> 00:28:24,640
make incremental changes to databases

00:28:22,559 --> 00:28:26,320
one of the primary advantages to using a

00:28:24,640 --> 00:28:28,960
schema migration tool is that it

00:28:26,320 --> 00:28:31,440
guarantees that the changes are made to

00:28:28,960 --> 00:28:34,640
the database in the exact same way

00:28:31,440 --> 00:28:36,480
every time additionally

00:28:34,640 --> 00:28:37,919
if you think about a scenario where

00:28:36,480 --> 00:28:41,039
you've checked out a

00:28:37,919 --> 00:28:42,799
sql file that is representative of the

00:28:41,039 --> 00:28:44,720
current state of your database so i have

00:28:42,799 --> 00:28:46,000
this sql file i checked it out of my

00:28:44,720 --> 00:28:47,840
code repository

00:28:46,000 --> 00:28:49,360
and it looks just like it tells me

00:28:47,840 --> 00:28:52,000
exactly how

00:28:49,360 --> 00:28:53,520
to create the database schema say as it

00:28:52,000 --> 00:28:55,679
is today

00:28:53,520 --> 00:28:57,200
coming back in a couple days or a couple

00:28:55,679 --> 00:29:00,159
weeks or a couple months

00:28:57,200 --> 00:29:01,440
and finding a new sql file with a new

00:29:00,159 --> 00:29:03,360
state

00:29:01,440 --> 00:29:05,200
is going to present a certain set of

00:29:03,360 --> 00:29:06,799
problems for me one

00:29:05,200 --> 00:29:08,720
is it's not really guaranteed that that

00:29:06,799 --> 00:29:12,080
sql file is going to have

00:29:08,720 --> 00:29:14,640
the correct state of changes that i need

00:29:12,080 --> 00:29:17,679
to be able to go from v1 to v2

00:29:14,640 --> 00:29:20,799
if i'm just doing a straight export

00:29:17,679 --> 00:29:22,720
of v1 of my schema and then an export of

00:29:20,799 --> 00:29:24,000
v2 of my schema

00:29:22,720 --> 00:29:26,320
it's going to require me to completely

00:29:24,000 --> 00:29:29,360
drop my database and then

00:29:26,320 --> 00:29:31,679
bring up a new set of tables with the v2

00:29:29,360 --> 00:29:34,240
configurations

00:29:31,679 --> 00:29:35,679
one way of helping address problems like

00:29:34,240 --> 00:29:38,880
this and others

00:29:35,679 --> 00:29:40,000
is using a series of migrations that

00:29:38,880 --> 00:29:42,240
declare things

00:29:40,000 --> 00:29:43,440
like the creation the table creation and

00:29:42,240 --> 00:29:46,799
update column

00:29:43,440 --> 00:29:47,679
um in a in a series of of incremental

00:29:46,799 --> 00:29:50,559
changes

00:29:47,679 --> 00:29:52,320
now you could do this with pure sql you

00:29:50,559 --> 00:29:54,880
can have a set of sql

00:29:52,320 --> 00:29:56,960
commands sql migration files that are

00:29:54,880 --> 00:29:58,399
just pure sql

00:29:56,960 --> 00:30:00,240
but there are also other tools that are

00:29:58,399 --> 00:30:03,039
out there that can help maybe

00:30:00,240 --> 00:30:04,159
bring down some of the the effort in

00:30:03,039 --> 00:30:06,559
that process

00:30:04,159 --> 00:30:08,159
for example liquid base is a tool that

00:30:06,559 --> 00:30:10,640
allows you to define these

00:30:08,159 --> 00:30:12,799
these changes in a variety of different

00:30:10,640 --> 00:30:16,320
markup languages like xml

00:30:12,799 --> 00:30:17,360
json or yaml by leveraging a tool like

00:30:16,320 --> 00:30:19,440
liquid base

00:30:17,360 --> 00:30:20,799
uh you're able to commit these changes

00:30:19,440 --> 00:30:22,799
and so you're

00:30:20,799 --> 00:30:24,640
instead of having one sql file with all

00:30:22,799 --> 00:30:26,640
of your database changes

00:30:24,640 --> 00:30:27,679
database state in it you have a

00:30:26,640 --> 00:30:29,840
collection of seek

00:30:27,679 --> 00:30:31,520
of migration files that get ran

00:30:29,840 --> 00:30:35,279
incrementally

00:30:31,520 --> 00:30:37,919
additionally tools like liquid base have

00:30:35,279 --> 00:30:39,600
checks in them that are used to

00:30:37,919 --> 00:30:40,240
guarantee and validate that the current

00:30:39,600 --> 00:30:43,520
state

00:30:40,240 --> 00:30:44,000
of your database is accurate one example

00:30:43,520 --> 00:30:46,799
of this

00:30:44,000 --> 00:30:47,360
is that when uh when liquid base goes

00:30:46,799 --> 00:30:50,880
through

00:30:47,360 --> 00:30:53,200
and runs your migrations

00:30:50,880 --> 00:30:55,360
it looks at each of the migration files

00:30:53,200 --> 00:30:56,640
and validates that the migration files

00:30:55,360 --> 00:30:59,039
have not changed

00:30:56,640 --> 00:31:00,799
since the last time those migrations

00:30:59,039 --> 00:31:01,919
have been ran on the database if any of

00:31:00,799 --> 00:31:04,159
them have

00:31:01,919 --> 00:31:05,440
has changed liquid base halts and lets

00:31:04,159 --> 00:31:08,000
you know that hey

00:31:05,440 --> 00:31:08,960
a migration that you've already ran has

00:31:08,000 --> 00:31:11,120
actually been

00:31:08,960 --> 00:31:14,080
changed so there's a conflict here and

00:31:11,120 --> 00:31:14,080
it needs to be resolved

00:31:14,240 --> 00:31:18,159
this is an example snippet from from a

00:31:17,039 --> 00:31:21,120
liquid-based

00:31:18,159 --> 00:31:23,279
yaml migration file it's going to create

00:31:21,120 --> 00:31:24,880
a new table for your database and

00:31:23,279 --> 00:31:26,799
again this is just an example you'd have

00:31:24,880 --> 00:31:29,039
a series of these

00:31:26,799 --> 00:31:30,480
running and you can quite simply put

00:31:29,039 --> 00:31:32,880
these in a pipeline

00:31:30,480 --> 00:31:33,919
and tell liquid base to run and have

00:31:32,880 --> 00:31:38,000
confidence that your

00:31:33,919 --> 00:31:38,000
the database is up to date

00:31:39,919 --> 00:31:43,679
when building cloud native applications

00:31:42,320 --> 00:31:46,640
with cloud providers

00:31:43,679 --> 00:31:48,159
you're probably going to want to use

00:31:46,640 --> 00:31:50,960
some of their

00:31:48,159 --> 00:31:53,039
sas offerings these are things like

00:31:50,960 --> 00:31:54,640
queues and blob stores

00:31:53,039 --> 00:31:56,159
you still need to interact with these

00:31:54,640 --> 00:31:57,919
apis but

00:31:56,159 --> 00:32:00,240
also want to be able to develop without

00:31:57,919 --> 00:32:01,360
having to directly depend on these

00:32:00,240 --> 00:32:03,519
services

00:32:01,360 --> 00:32:05,440
in other words it would be really nice

00:32:03,519 --> 00:32:06,559
to be able to swap out the backing

00:32:05,440 --> 00:32:08,880
service

00:32:06,559 --> 00:32:10,240
for something you could run locally and

00:32:08,880 --> 00:32:11,679
then swap it around

00:32:10,240 --> 00:32:14,080
when you want to integrate with the

00:32:11,679 --> 00:32:16,320
cloud provider this is a technique that

00:32:14,080 --> 00:32:17,360
orms have been doing for a while with

00:32:16,320 --> 00:32:19,679
databases

00:32:17,360 --> 00:32:22,480
where the whole fact that i'm using a

00:32:19,679 --> 00:32:24,480
postgresql mysql or sqlite database

00:32:22,480 --> 00:32:26,159
is usually abstracted away from me when

00:32:24,480 --> 00:32:28,559
i'm using an orm

00:32:26,159 --> 00:32:31,279
we could take a similar approach when

00:32:28,559 --> 00:32:34,559
we're dealing with these other types of

00:32:31,279 --> 00:32:37,679
resources like queues and blob stores so

00:32:34,559 --> 00:32:38,559
instead of coding the algorithms or the

00:32:37,679 --> 00:32:41,760
the functions

00:32:38,559 --> 00:32:42,640
directly to the cloud provider we can

00:32:41,760 --> 00:32:44,799
use

00:32:42,640 --> 00:32:46,080
we can use a strategy pattern to

00:32:44,799 --> 00:32:50,080
abstract that away

00:32:46,080 --> 00:32:51,760
and give us a collection of of

00:32:50,080 --> 00:32:54,000
algorithms that we can then bring in

00:32:51,760 --> 00:32:56,880
when we need them

00:32:54,000 --> 00:32:58,720
here's an example so in this example

00:32:56,880 --> 00:33:01,120
we're modeling out

00:32:58,720 --> 00:33:01,760
what you might construct to be able to

00:33:01,120 --> 00:33:04,880
run

00:33:01,760 --> 00:33:06,000
rabbitmq for example locally and then

00:33:04,880 --> 00:33:09,279
toggle to

00:33:06,000 --> 00:33:12,559
sqs for queuing when you are wanting to

00:33:09,279 --> 00:33:12,559
switch over to aws

00:33:12,720 --> 00:33:17,279
the strategy context encapsulates which

00:33:15,120 --> 00:33:19,360
strategy to actually execute

00:33:17,279 --> 00:33:20,799
while the application is completely

00:33:19,360 --> 00:33:23,440
agnostic to

00:33:20,799 --> 00:33:25,600
whether it's interacting with sqs or

00:33:23,440 --> 00:33:27,600
rabbitmq

00:33:25,600 --> 00:33:30,159
the context can easily be set through

00:33:27,600 --> 00:33:32,799
something like an environment variable

00:33:30,159 --> 00:33:35,120
and once you have the specific rabbitmq

00:33:32,799 --> 00:33:36,880
and sqs strategies built out

00:33:35,120 --> 00:33:38,960
developers just need to focus on the

00:33:36,880 --> 00:33:40,720
business logic for how the specific use

00:33:38,960 --> 00:33:43,039
case is going to interact with a generic

00:33:40,720 --> 00:33:43,039
queue

00:33:43,200 --> 00:33:46,799
in the above example a development a

00:33:44,880 --> 00:33:48,640
developer can just set an environment

00:33:46,799 --> 00:33:50,320
variable to point them to

00:33:48,640 --> 00:33:52,720
using a rabbitmq when they're building

00:33:50,320 --> 00:33:54,880
things out locally and then

00:33:52,720 --> 00:33:56,320
when they're ready to deploy it they can

00:33:54,880 --> 00:33:57,919
just lean on a pipeline to

00:33:56,320 --> 00:34:01,039
configure what needs to be configured

00:33:57,919 --> 00:34:04,080
for interacting with an sqs

00:34:01,039 --> 00:34:06,320
this this this allows the developer to

00:34:04,080 --> 00:34:07,600
focus on the solving the business

00:34:06,320 --> 00:34:10,079
problem at hand

00:34:07,600 --> 00:34:10,639
and worry about integration after

00:34:10,079 --> 00:34:13,040
they've done

00:34:10,639 --> 00:34:14,720
a level of testing locally and have an

00:34:13,040 --> 00:34:17,200
amount of enough confidence to do an

00:34:14,720 --> 00:34:19,040
integration style testing

00:34:17,200 --> 00:34:21,679
and like we saw in some of the previous

00:34:19,040 --> 00:34:23,280
tactics docker compose can be used to

00:34:21,679 --> 00:34:26,240
spin up rabbitmq

00:34:23,280 --> 00:34:26,240
and run that locally

00:34:27,679 --> 00:34:32,960
this brings us to our last tactic here

00:34:31,040 --> 00:34:34,960
and that's adopting some standard

00:34:32,960 --> 00:34:38,639
architecture models patterns or

00:34:34,960 --> 00:34:39,119
just general uh general key thoughts

00:34:38,639 --> 00:34:42,000
around

00:34:39,119 --> 00:34:43,040
how we want to approach designing your

00:34:42,000 --> 00:34:44,560
applications

00:34:43,040 --> 00:34:46,800
and why would we even want to do this

00:34:44,560 --> 00:34:48,399
well for one it's going to teach best

00:34:46,800 --> 00:34:50,800
practices when you have new engineers

00:34:48,399 --> 00:34:52,960
coming onto the project

00:34:50,800 --> 00:34:54,000
being able to look at a project and say

00:34:52,960 --> 00:34:56,560
yes that is

00:34:54,000 --> 00:34:57,520
that is implementing our best practices

00:34:56,560 --> 00:34:59,119
or

00:34:57,520 --> 00:35:00,640
being able to point to an example

00:34:59,119 --> 00:35:02,560
application and saying yeah

00:35:00,640 --> 00:35:03,920
that's an example of what we consider

00:35:02,560 --> 00:35:06,400
best practices

00:35:03,920 --> 00:35:07,359
can be very instrumental in helping new

00:35:06,400 --> 00:35:09,440
engineers

00:35:07,359 --> 00:35:11,520
come on board and get ramped up to how

00:35:09,440 --> 00:35:13,599
you do your work

00:35:11,520 --> 00:35:15,680
second it reinforces the best practices

00:35:13,599 --> 00:35:17,839
with the rest of the team and finally

00:35:15,680 --> 00:35:19,440
it produces examples for how to solve

00:35:17,839 --> 00:35:21,920
common problems

00:35:19,440 --> 00:35:22,640
so that the so that your the engineers

00:35:21,920 --> 00:35:27,200
on your team

00:35:22,640 --> 00:35:31,920
can focus on the hard to solve problems

00:35:27,200 --> 00:35:34,400
here's an example one framework that

00:35:31,920 --> 00:35:37,119
fits really well with the cloud native

00:35:34,400 --> 00:35:39,920
model is the 12 factor app

00:35:37,119 --> 00:35:42,160
the 12 factor app was introduced as a

00:35:39,920 --> 00:35:43,040
framework or way of thinking about cloud

00:35:42,160 --> 00:35:46,640
native apps

00:35:43,040 --> 00:35:49,359
by heroku back in 2007

00:35:46,640 --> 00:35:50,720
the principles still apply today and

00:35:49,359 --> 00:35:52,480
there it's even more so

00:35:50,720 --> 00:35:54,640
given the significant shift that we've

00:35:52,480 --> 00:35:57,200
seen to using containers

00:35:54,640 --> 00:35:58,320
in production environments so for

00:35:57,200 --> 00:36:00,720
example

00:35:58,320 --> 00:36:02,800
12-factor apps should use environment

00:36:00,720 --> 00:36:04,000
variables to configure per-environment

00:36:02,800 --> 00:36:06,240
settings

00:36:04,000 --> 00:36:08,400
12-factor apps should scale horizontally

00:36:06,240 --> 00:36:10,800
with single-processed designs

00:36:08,400 --> 00:36:11,440
logs should be streamed through standard

00:36:10,800 --> 00:36:13,680
out

00:36:11,440 --> 00:36:15,920
and there should only be one application

00:36:13,680 --> 00:36:17,839
to a code base

00:36:15,920 --> 00:36:19,839
all of these remain very important

00:36:17,839 --> 00:36:21,359
concepts to apply when building cloud

00:36:19,839 --> 00:36:24,960
native apps

00:36:21,359 --> 00:36:28,079
and when you adopt adopt and apply

00:36:24,960 --> 00:36:28,800
best practices for containers out of the

00:36:28,079 --> 00:36:30,480
box

00:36:28,800 --> 00:36:33,200
you are going to be implementing

00:36:30,480 --> 00:36:36,400
12-factor apps

00:36:33,200 --> 00:36:39,280
here's an example the

00:36:36,400 --> 00:36:40,160
process factor states that applications

00:36:39,280 --> 00:36:43,520
should be deployed

00:36:40,160 --> 00:36:44,320
as one or more stateless processes with

00:36:43,520 --> 00:36:47,680
persistent

00:36:44,320 --> 00:36:49,599
data stored on a backing service

00:36:47,680 --> 00:36:50,960
this means that stateless architectures

00:36:49,599 --> 00:36:53,359
are paramount

00:36:50,960 --> 00:36:55,680
to building scalable and reliable cloud

00:36:53,359 --> 00:36:57,599
native applications

00:36:55,680 --> 00:37:00,000
achieving stateless applications means

00:36:57,599 --> 00:37:00,800
that nothing is directly shared across

00:37:00,000 --> 00:37:03,359
processes

00:37:00,800 --> 00:37:04,400
in other words even if the application

00:37:03,359 --> 00:37:07,040
horizontally

00:37:04,400 --> 00:37:08,000
scales it shouldn't be concerned with

00:37:07,040 --> 00:37:11,040
what state is stored

00:37:08,000 --> 00:37:12,960
in the memory of one of its one of the

00:37:11,040 --> 00:37:14,400
side application that's running

00:37:12,960 --> 00:37:17,040
applications should prefer to use

00:37:14,400 --> 00:37:18,640
databases or redis type tools

00:37:17,040 --> 00:37:19,520
this can be particularly tricky when

00:37:18,640 --> 00:37:21,359
you're working with real-time

00:37:19,520 --> 00:37:23,520
applications especially

00:37:21,359 --> 00:37:25,760
or you need or any need for a persistent

00:37:23,520 --> 00:37:27,920
tcp connection

00:37:25,760 --> 00:37:29,520
how does this connect back to containers

00:37:27,920 --> 00:37:31,599
well containers

00:37:29,520 --> 00:37:32,640
ought to be able to die and come back we

00:37:31,599 --> 00:37:34,720
should be able to

00:37:32,640 --> 00:37:35,760
throw them out and bring them back in

00:37:34,720 --> 00:37:39,599
and that's where this

00:37:35,760 --> 00:37:41,920
this other factor plays in disposability

00:37:39,599 --> 00:37:43,280
disposability means that we the fast

00:37:41,920 --> 00:37:44,240
start we want a fast startup and

00:37:43,280 --> 00:37:47,280
shutdown

00:37:44,240 --> 00:37:49,920
um are an advocate and advocated for a

00:37:47,280 --> 00:37:51,359
more robust and resilient system

00:37:49,920 --> 00:37:53,200
disposability is

00:37:51,359 --> 00:37:55,040
pretty much succinctly summarized in the

00:37:53,200 --> 00:37:57,200
familiar microservice saying of we want

00:37:55,040 --> 00:37:58,480
to build cattle not pets

00:37:57,200 --> 00:38:00,480
we all live in a world where

00:37:58,480 --> 00:38:02,480
applications are going to fail

00:38:00,480 --> 00:38:05,280
and it is much more efficient to treat

00:38:02,480 --> 00:38:06,720
running processes as disposable things

00:38:05,280 --> 00:38:08,640
than to spend the money effort and

00:38:06,720 --> 00:38:09,920
emotional energy it takes to maintain a

00:38:08,640 --> 00:38:12,079
single server

00:38:09,920 --> 00:38:13,760
that can never go down what's

00:38:12,079 --> 00:38:15,359
significant with this factor is that it

00:38:13,760 --> 00:38:17,200
is dependent on

00:38:15,359 --> 00:38:19,520
many of the many of the many of the

00:38:17,200 --> 00:38:22,160
previous or other factors including

00:38:19,520 --> 00:38:23,520
uh configuring into environments running

00:38:22,160 --> 00:38:26,720
backing services

00:38:23,520 --> 00:38:28,400
and concurrency because we use docker

00:38:26,720 --> 00:38:29,680
containers and follow best practices

00:38:28,400 --> 00:38:31,359
regarding construction

00:38:29,680 --> 00:38:32,880
of our images and running the running

00:38:31,359 --> 00:38:33,520
the containers were able to quickly

00:38:32,880 --> 00:38:37,599
create

00:38:33,520 --> 00:38:37,599
and destroy and restart applications

00:38:37,920 --> 00:38:40,960
we mentioned concurrency how does

00:38:39,440 --> 00:38:43,680
concurrency play into this

00:38:40,960 --> 00:38:45,520
well concurrency is advocated by scaling

00:38:43,680 --> 00:38:48,320
individual processes

00:38:45,520 --> 00:38:49,280
so one of the primary primary advantages

00:38:48,320 --> 00:38:51,599
of

00:38:49,280 --> 00:38:53,200
building cloud-native applications is

00:38:51,599 --> 00:38:54,000
the design of the applications is the

00:38:53,200 --> 00:38:56,640
ability to

00:38:54,000 --> 00:38:57,760
seamlessly scale horizontally this means

00:38:56,640 --> 00:39:00,640
instead of adding

00:38:57,760 --> 00:39:02,400
more cpu or memory to your server you

00:39:00,640 --> 00:39:03,839
simply create more instances of the

00:39:02,400 --> 00:39:06,240
application and distribute the load

00:39:03,839 --> 00:39:08,160
across those instances

00:39:06,240 --> 00:39:10,240
this approach leads itself to more

00:39:08,160 --> 00:39:13,440
efficient use of resources particularly

00:39:10,240 --> 00:39:14,000
with in the cloud context now by

00:39:13,440 --> 00:39:15,760
following best

00:39:14,000 --> 00:39:17,520
practices recommend best practice

00:39:15,760 --> 00:39:20,160
recommendations of running only

00:39:17,520 --> 00:39:21,200
one process in a docker container the

00:39:20,160 --> 00:39:24,079
outcome is not only

00:39:21,200 --> 00:39:25,760
better running docker containers but

00:39:24,079 --> 00:39:26,560
applications that follow the concurrency

00:39:25,760 --> 00:39:29,760
factor

00:39:26,560 --> 00:39:31,520
out of the box here's an example

00:39:29,760 --> 00:39:33,839
if we need to run a different process

00:39:31,520 --> 00:39:35,680
say mysql database instead of creating a

00:39:33,839 --> 00:39:36,560
new process in the docker container

00:39:35,680 --> 00:39:39,200
running the

00:39:36,560 --> 00:39:40,240
main application we will create a

00:39:39,200 --> 00:39:42,720
separate container

00:39:40,240 --> 00:39:44,079
whose only process is running that mysql

00:39:42,720 --> 00:39:45,839
instance

00:39:44,079 --> 00:39:47,280
and this way we're able to adhere to the

00:39:45,839 --> 00:39:49,680
concurrency factor

00:39:47,280 --> 00:39:50,880
additionally if the application itself

00:39:49,680 --> 00:39:53,119
needs to scale

00:39:50,880 --> 00:39:55,280
we do not need to create new processes

00:39:53,119 --> 00:39:56,640
in the existing container

00:39:55,280 --> 00:39:58,720
the appropriate way to scale this out is

00:39:56,640 --> 00:40:02,079
to create new containers each running

00:39:58,720 --> 00:40:02,079
a single application process

00:40:05,920 --> 00:40:10,079
with all this in mind you can get to a

00:40:08,160 --> 00:40:12,480
point to where you're able to extract

00:40:10,079 --> 00:40:13,599
or reuse components patterns and ways of

00:40:12,480 --> 00:40:15,440
work

00:40:13,599 --> 00:40:17,599
these become the building blocks for

00:40:15,440 --> 00:40:20,960
your library of reusable patterns

00:40:17,599 --> 00:40:23,200
and ultimately into starter applications

00:40:20,960 --> 00:40:25,680
that are completely scaffolded out with

00:40:23,200 --> 00:40:27,680
best practices and optimizations

00:40:25,680 --> 00:40:28,960
and all of that encapsulates the lessons

00:40:27,680 --> 00:40:32,160
learned by your team

00:40:28,960 --> 00:40:32,160
and by others on your team

00:40:33,200 --> 00:40:37,839
so thank you again for uh for spending

00:40:36,640 --> 00:40:41,839
some time and

00:40:37,839 --> 00:40:44,319
listening to uh this talk about uh

00:40:41,839 --> 00:40:45,520
building uh thinking locally and and

00:40:44,319 --> 00:40:46,880
building in the cloud so

00:40:45,520 --> 00:40:50,960
um i think right now i'm gonna see if

00:40:46,880 --> 00:40:53,839
there's any questions and uh

00:40:50,960 --> 00:40:53,839
go from there

00:40:54,800 --> 00:40:58,480
so i see one question will the slide be

00:40:56,560 --> 00:41:01,200
made available yeah i will provide

00:40:58,480 --> 00:41:03,040
an updated version of the sides to the

00:41:01,200 --> 00:41:06,640
um

00:41:03,040 --> 00:41:08,160
uh to the uh ato to ato folks so that

00:41:06,640 --> 00:41:10,880
they can um

00:41:08,160 --> 00:41:11,760
they can get that out or um you have my

00:41:10,880 --> 00:41:14,480
linkedin there

00:41:11,760 --> 00:41:14,880
you can shoot me a message on linkedin

00:41:14,480 --> 00:41:17,280
or

00:41:14,880 --> 00:41:21,839
uh you know send me a message and i can

00:41:17,280 --> 00:41:21,839

YouTube URL: https://www.youtube.com/watch?v=44ZiQLJW-VM


