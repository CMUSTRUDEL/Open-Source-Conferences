Title: Cassandra Architecture: Understanding, Scaling and Optimizing - Ben Bromhead
Publication date: 2020-12-10
Playlist: All Things Open 2020 - Databases Track
Description: 
	Presented by: Ben Bromhead, Instaclustr
Presented at All Things Open 2020 - Databases Track

Abstract: Apache Cassandra is built to support the high availability, scalability, and performance requirements of enterprise applications. Understanding its architecture can be tricky – this extended session tells you what you need to know.

The architecture of the open source Cassandra database is designed to provide uniquely simple and powerful scalability – ideal for applications utilizing the cloud, big data, and other data-intensive use cases. With Cassandra, adding capacity is a matter of adding additional nodes to existing clusters, which can be done while the cluster is active. This architecture can capably serve millions of users concurrently, and handle massive quantities of operations or data loads with impressive alacrity and performance. This is true even when operating Cassandra across multiple data centers or even multiple clouds. Cassandra’s architecture also avoids including any single point of failure – an advantage over sharded or master-slave architectures – to achieve the continuous availability and uptime crucial to many applications.

While the benefits of the database are clear and proven, properly scaling and optimizing Cassandra requires a healthy knowledge of its underlying architecture. Attendees will come away from this tutorial understanding of:

- The key components and concepts of Cassandra architecture, including data partitioning, data replication, consistent hashing, etc.
- Cassandra write process
- Cassandra read process
- Cassandra network topology
- How Cassandra architecture tolerates failure scenarios
Captions: 
	00:00:04,960 --> 00:00:09,920
thank you very much

00:00:06,319 --> 00:00:10,480
um good afternoon uh and good morning to

00:00:09,920 --> 00:00:12,240
everyone

00:00:10,480 --> 00:00:13,759
uh depending on where you are in the

00:00:12,240 --> 00:00:16,400
world attending this

00:00:13,759 --> 00:00:17,600
um today i'll be getting into uh a

00:00:16,400 --> 00:00:20,640
little bit around

00:00:17,600 --> 00:00:22,880
uh cassandra architecture um

00:00:20,640 --> 00:00:25,039
and really you know hopefully hopefully

00:00:22,880 --> 00:00:26,240
give everyone here a little bit more

00:00:25,039 --> 00:00:28,080
of an understanding around what's

00:00:26,240 --> 00:00:30,640
happening under the hood um so you can

00:00:28,080 --> 00:00:33,280
start to make some some better decisions

00:00:30,640 --> 00:00:34,640
around what's happening there um so the

00:00:33,280 --> 00:00:37,360
first thing that we're going to cover

00:00:34,640 --> 00:00:39,280
is a very very high level around the

00:00:37,360 --> 00:00:41,200
cassandra architecture

00:00:39,280 --> 00:00:42,480
um you know how it's kind of structured

00:00:41,200 --> 00:00:44,960
what that means for you

00:00:42,480 --> 00:00:46,079
well then touch on um tunable

00:00:44,960 --> 00:00:48,000
consistency

00:00:46,079 --> 00:00:50,399
um which is fundamental to the

00:00:48,000 --> 00:00:52,480
architecture of apache cassandra

00:00:50,399 --> 00:00:54,399
uh and how that relates and how you can

00:00:52,480 --> 00:00:56,320
use those mechanisms uh in your

00:00:54,399 --> 00:00:57,600
day-to-day job as a developer

00:00:56,320 --> 00:00:59,680
to kind of get things done and to

00:00:57,600 --> 00:01:02,239
achieve the goals you need to achieve

00:00:59,680 --> 00:01:03,920
uh and then we'll also touch on um a

00:01:02,239 --> 00:01:05,439
little bit of how cassandra works under

00:01:03,920 --> 00:01:07,840
the hood when it comes to

00:01:05,439 --> 00:01:09,200
uh the read and write path right so

00:01:07,840 --> 00:01:10,720
what's actually happening

00:01:09,200 --> 00:01:12,400
mechanically under the hood so you can

00:01:10,720 --> 00:01:13,760
get an understanding of how that might

00:01:12,400 --> 00:01:16,080
impact performance

00:01:13,760 --> 00:01:18,640
um and how that might impact the way you

00:01:16,080 --> 00:01:21,360
go and build things

00:01:18,640 --> 00:01:22,159
um but first of course um a little bit

00:01:21,360 --> 00:01:24,880
around

00:01:22,159 --> 00:01:25,360
um who enters the cluster is and who i

00:01:24,880 --> 00:01:28,000
am

00:01:25,360 --> 00:01:29,119
um so i am the cto and co-founder of

00:01:28,000 --> 00:01:32,880
insta cluster

00:01:29,119 --> 00:01:34,159
um we've been around um coming up almost

00:01:32,880 --> 00:01:36,720
eight years now

00:01:34,159 --> 00:01:37,200
um doing lots and lots of cool fun stuff

00:01:36,720 --> 00:01:39,520
uh

00:01:37,200 --> 00:01:41,680
not only with cassandra um but also with

00:01:39,520 --> 00:01:43,600
kafka and spark and elasticsearch and

00:01:41,680 --> 00:01:45,200
you know all those really fun highly

00:01:43,600 --> 00:01:48,000
available highly scalable

00:01:45,200 --> 00:01:48,640
um data infrastructure projects that

00:01:48,000 --> 00:01:51,200
that

00:01:48,640 --> 00:01:52,399
you're probably familiar with um and we

00:01:51,200 --> 00:01:54,320
just love to run those

00:01:52,399 --> 00:01:55,439
on behalf of you right so that's what we

00:01:54,320 --> 00:01:58,240
do um

00:01:55,439 --> 00:01:59,439
we do manage services and databases and

00:01:58,240 --> 00:02:01,280
services around these

00:01:59,439 --> 00:02:04,320
i'm also more than happy to support you

00:02:01,280 --> 00:02:06,560
in an on-premise environment

00:02:04,320 --> 00:02:08,160
um again i'll try and get into the meat

00:02:06,560 --> 00:02:10,959
of the content um but

00:02:08,160 --> 00:02:13,520
you know is just a very very dense

00:02:10,959 --> 00:02:16,000
information dense slider on what we do

00:02:13,520 --> 00:02:17,280
um it is being recorded so uh if you

00:02:16,000 --> 00:02:19,840
want to learn more please pause and have

00:02:17,280 --> 00:02:22,959
a read or go to our website

00:02:19,840 --> 00:02:24,480
um so so first of all uh why why would

00:02:22,959 --> 00:02:27,040
you look into cassandra right

00:02:24,480 --> 00:02:28,560
um so it tends to be um first and

00:02:27,040 --> 00:02:30,959
foremost very low latency

00:02:28,560 --> 00:02:33,440
um you know database we're talking about

00:02:30,959 --> 00:02:35,840
single digit millisecond latency um so

00:02:33,440 --> 00:02:38,000
great for high throughput data ingestion

00:02:35,840 --> 00:02:39,599
and you can nowadays um also get some

00:02:38,000 --> 00:02:40,319
pretty solid read performance out of the

00:02:39,599 --> 00:02:43,680
back of it

00:02:40,319 --> 00:02:44,560
right um now low latency is obviously a

00:02:43,680 --> 00:02:46,160
relative term

00:02:44,560 --> 00:02:48,400
um you know for example if you're doing

00:02:46,160 --> 00:02:48,959
high frequency uh training or things

00:02:48,400 --> 00:02:51,360
that you know

00:02:48,959 --> 00:02:53,040
talk need nanoseconds um you know you

00:02:51,360 --> 00:02:54,519
might want to look somewhere else

00:02:53,040 --> 00:02:56,319
but from modern day web app or

00:02:54,519 --> 00:02:58,720
microservices uh

00:02:56,319 --> 00:03:00,000
architecture um you know cassandra is an

00:02:58,720 --> 00:03:01,519
awesome choice when it comes to the

00:03:00,000 --> 00:03:04,000
latency side of things

00:03:01,519 --> 00:03:05,280
um it's incredibly scalable and we'll

00:03:04,000 --> 00:03:07,680
get into how that kind of works a little

00:03:05,280 --> 00:03:10,720
bit in the architecture side of things

00:03:07,680 --> 00:03:14,000
but i think first and foremost um

00:03:10,720 --> 00:03:15,920
you know it is incredibly reliable um

00:03:14,000 --> 00:03:18,400
you know database right so it certainly

00:03:15,920 --> 00:03:19,440
brings the concept of having replicas of

00:03:18,400 --> 00:03:21,200
redundancy

00:03:19,440 --> 00:03:22,480
uh into the way you work as a first

00:03:21,200 --> 00:03:23,840
class citizen

00:03:22,480 --> 00:03:24,959
and when you're building and structuring

00:03:23,840 --> 00:03:26,239
your queries you're gonna have to make

00:03:24,959 --> 00:03:27,519
some choices around that

00:03:26,239 --> 00:03:29,519
right but because you have to think

00:03:27,519 --> 00:03:31,280
about it up front it makes for a much

00:03:29,519 --> 00:03:32,799
more stable and much more reliable

00:03:31,280 --> 00:03:35,840
experience

00:03:32,799 --> 00:03:37,280
when you're running this in production

00:03:35,840 --> 00:03:39,280
um so some of the key differences

00:03:37,280 --> 00:03:42,799
between say apache cassandra

00:03:39,280 --> 00:03:44,480
and raw and a traditional database um

00:03:42,799 --> 00:03:46,400
you're like a relational a traditional

00:03:44,480 --> 00:03:49,840
relational database i should say

00:03:46,400 --> 00:03:50,319
um is well the the big one is the data

00:03:49,840 --> 00:03:53,360
model

00:03:50,319 --> 00:03:56,400
right um so cassandra is

00:03:53,360 --> 00:03:58,319
a what a wide column um storage engine

00:03:56,400 --> 00:04:00,159
um different to a columnar storage

00:03:58,319 --> 00:04:02,239
engine uh and

00:04:00,159 --> 00:04:04,000
you know it kind of applies very much

00:04:02,239 --> 00:04:06,480
like a key key value

00:04:04,000 --> 00:04:08,400
methodology to that what that means from

00:04:06,480 --> 00:04:10,640
a data model perspective though is with

00:04:08,400 --> 00:04:12,319
relational you tend to build

00:04:10,640 --> 00:04:14,000
a model that reflects real world

00:04:12,319 --> 00:04:15,760
entities and relationships

00:04:14,000 --> 00:04:17,519
and then you know you start to normalize

00:04:15,760 --> 00:04:18,400
that right to build some efficiencies

00:04:17,519 --> 00:04:21,359
into your table

00:04:18,400 --> 00:04:22,079
right and then you will join data if you

00:04:21,359 --> 00:04:24,400
need

00:04:22,079 --> 00:04:25,360
indexing for performance you might do a

00:04:24,400 --> 00:04:27,040
few other things

00:04:25,360 --> 00:04:28,320
um you might even denormalize for

00:04:27,040 --> 00:04:29,360
performance sometimes in relational

00:04:28,320 --> 00:04:30,960
databases

00:04:29,360 --> 00:04:32,960
as well but generally you're trying to

00:04:30,960 --> 00:04:36,080
model those relationships right

00:04:32,960 --> 00:04:37,520
um whereas with cassandra um you

00:04:36,080 --> 00:04:39,199
actually design based on the principle

00:04:37,520 --> 00:04:40,400
that right and data storage is

00:04:39,199 --> 00:04:42,960
incredibly cheap

00:04:40,400 --> 00:04:44,400
which it is nowadays um and then you

00:04:42,960 --> 00:04:46,080
know you optimize your model based

00:04:44,400 --> 00:04:47,520
around how you want to retrieve the data

00:04:46,080 --> 00:04:49,680
so you should be

00:04:47,520 --> 00:04:51,040
storing the data uh storing data in the

00:04:49,680 --> 00:04:52,800
way you're going to read it back right

00:04:51,040 --> 00:04:54,800
so that gives you those fast reads

00:04:52,800 --> 00:04:56,000
it may mean you duplicate a little bit

00:04:54,800 --> 00:04:58,080
as well but again

00:04:56,000 --> 00:05:00,479
we're operating under the premise that

00:04:58,080 --> 00:05:03,280
storage is somewhat cheap

00:05:00,479 --> 00:05:04,080
um cassandra doesn't have um much query

00:05:03,280 --> 00:05:07,360
capability

00:05:04,080 --> 00:05:10,320
in the terms of joins right um

00:05:07,360 --> 00:05:11,280
so again by doing away with joins um we

00:05:10,320 --> 00:05:13,440
get the benefit

00:05:11,280 --> 00:05:14,800
of being able to be incredibly scalable

00:05:13,440 --> 00:05:16,320
um right and

00:05:14,800 --> 00:05:18,160
it allows and simplifies a number of

00:05:16,320 --> 00:05:20,479
things when it comes to

00:05:18,160 --> 00:05:22,000
um you know having relationship

00:05:20,479 --> 00:05:23,120
consistency because we don't need to

00:05:22,000 --> 00:05:26,800
worry about it

00:05:23,120 --> 00:05:28,080
um and you know

00:05:26,800 --> 00:05:29,919
you'll you will see a few other

00:05:28,080 --> 00:05:30,400
restrictions around that it does get a

00:05:29,919 --> 00:05:32,240
little bit

00:05:30,400 --> 00:05:34,000
um interesting because the query

00:05:32,240 --> 00:05:37,280
language that cassandra has

00:05:34,000 --> 00:05:39,360
uh is very very similar to sql

00:05:37,280 --> 00:05:41,520
right in fact deliberately so to make it

00:05:39,360 --> 00:05:44,240
easier for people to adopt cassandra

00:05:41,520 --> 00:05:45,520
um but it also on the flip side can be a

00:05:44,240 --> 00:05:47,600
little bit challenging because you may

00:05:45,520 --> 00:05:52,240
be used to doing things with sql

00:05:47,600 --> 00:05:55,199
that won't work with cassandra

00:05:52,240 --> 00:05:56,479
um and so you know to cover what i just

00:05:55,199 --> 00:05:57,919
said previously we've kind of got a

00:05:56,479 --> 00:05:59,280
little bit of like here's what you could

00:05:57,919 --> 00:06:00,639
call the pros and the cons

00:05:59,280 --> 00:06:03,120
right of choosing this database and

00:06:00,639 --> 00:06:06,880
every database will have it right so

00:06:03,120 --> 00:06:08,800
um cassandra on um the the pro side you

00:06:06,880 --> 00:06:11,759
know it does get it is highly available

00:06:08,800 --> 00:06:14,000
it is um you know masterless and it does

00:06:11,759 --> 00:06:16,400
bring that that linear scalability

00:06:14,000 --> 00:06:18,160
right um but on the flip side you do

00:06:16,400 --> 00:06:19,600
have a reduction in the flexibility when

00:06:18,160 --> 00:06:21,840
it comes to things like joins

00:06:19,600 --> 00:06:21,840
right

00:06:22,800 --> 00:06:27,440
um and so when it comes to the way that

00:06:25,600 --> 00:06:30,400
you think about apache cassandra

00:06:27,440 --> 00:06:31,759
um we'll just very quickly touch on a

00:06:30,400 --> 00:06:34,479
core

00:06:31,759 --> 00:06:36,560
uh concept that's kind of needed to

00:06:34,479 --> 00:06:39,759
think about the way that cassandra works

00:06:36,560 --> 00:06:43,120
um and um that is the cap theorem

00:06:39,759 --> 00:06:46,319
right um i won't go into it too much

00:06:43,120 --> 00:06:48,319
i'm sure most people who um

00:06:46,319 --> 00:06:50,080
have looked at distributed databases are

00:06:48,319 --> 00:06:53,520
kind of at least loosely familiar with

00:06:50,080 --> 00:06:55,120
um with this theory um

00:06:53,520 --> 00:06:56,800
but what it is is that on any

00:06:55,120 --> 00:06:59,680
distributed system

00:06:56,800 --> 00:07:00,400
um it will generally exhibit three

00:06:59,680 --> 00:07:04,400
properties

00:07:00,400 --> 00:07:08,639
right sorry it will be able to exhibit

00:07:04,400 --> 00:07:11,919
um three of one of or two of these

00:07:08,639 --> 00:07:14,080
um i guess attributes right

00:07:11,919 --> 00:07:16,479
um some databases will actually exhibit

00:07:14,080 --> 00:07:18,479
zero which is interesting um

00:07:16,479 --> 00:07:20,319
but the first one is consistency which

00:07:18,479 --> 00:07:21,120
is every client has the same view of the

00:07:20,319 --> 00:07:22,960
data

00:07:21,120 --> 00:07:24,639
every read receives the most recent

00:07:22,960 --> 00:07:27,520
write or an error

00:07:24,639 --> 00:07:29,280
right uh availability every read or

00:07:27,520 --> 00:07:31,520
write request receives a response in a

00:07:29,280 --> 00:07:33,360
reasonable amount of time

00:07:31,520 --> 00:07:35,520
and then partition tolerance so the

00:07:33,360 --> 00:07:37,039
system continues to operate despite an

00:07:35,520 --> 00:07:38,080
arbitrary number of messages being

00:07:37,039 --> 00:07:41,280
dropped by the network

00:07:38,080 --> 00:07:43,520
right and generally

00:07:41,280 --> 00:07:44,639
a distributed system will only be able

00:07:43,520 --> 00:07:48,319
to exhibit

00:07:44,639 --> 00:07:50,240
two of these attributes um and

00:07:48,319 --> 00:07:51,759
um you know cassandra gives you a few

00:07:50,240 --> 00:07:53,599
options around um

00:07:51,759 --> 00:07:56,000
how you play within this particular

00:07:53,599 --> 00:07:59,039
space

00:07:56,000 --> 00:08:00,000
um so in and so one other thing to

00:07:59,039 --> 00:08:01,280
remember about this

00:08:00,000 --> 00:08:02,800
is you know how do you think about this

00:08:01,280 --> 00:08:03,599
when it comes to value models right

00:08:02,800 --> 00:08:06,639
because this is

00:08:03,599 --> 00:08:10,000
a way of describing how values happen

00:08:06,639 --> 00:08:12,639
um so in a distributed system network

00:08:10,000 --> 00:08:13,520
values um we tend to assume they always

00:08:12,639 --> 00:08:15,360
occur

00:08:13,520 --> 00:08:16,800
um so one would argue that you need to

00:08:15,360 --> 00:08:20,080
be partition tolerant

00:08:16,800 --> 00:08:22,319
right um and so with cap theorem you

00:08:20,080 --> 00:08:25,759
need to choose generally between

00:08:22,319 --> 00:08:28,479
um you know cp or ap

00:08:25,759 --> 00:08:29,199
right so um consistent and partition

00:08:28,479 --> 00:08:31,520
tolerant

00:08:29,199 --> 00:08:33,120
or available on partition tolerance it's

00:08:31,520 --> 00:08:36,000
really hard to have

00:08:33,120 --> 00:08:38,240
all of it right or if possible right um

00:08:36,000 --> 00:08:39,839
with cassandra you can have the balance

00:08:38,240 --> 00:08:41,279
uh you can balance the level of

00:08:39,839 --> 00:08:42,800
consistency and the level of

00:08:41,279 --> 00:08:43,120
availability right so that's what we

00:08:42,800 --> 00:08:45,839
call

00:08:43,120 --> 00:08:47,519
tunable consistency so on a per query

00:08:45,839 --> 00:08:49,120
basis we can actually change the

00:08:47,519 --> 00:08:52,000
constraints of the query

00:08:49,120 --> 00:08:55,279
to favor either you know a consistent

00:08:52,000 --> 00:08:57,680
partition tolerant um

00:08:55,279 --> 00:09:00,000
database or a highly available and

00:08:57,680 --> 00:09:02,080
petition tolerant database

00:09:00,000 --> 00:09:06,160
but the way that you'll see most central

00:09:02,080 --> 00:09:08,160
deployments is that it favors ap

00:09:06,160 --> 00:09:10,000
um and and here's another example of the

00:09:08,160 --> 00:09:11,839
way this works with cassandra um we'll

00:09:10,000 --> 00:09:12,880
get into what some of these terms mean

00:09:11,839 --> 00:09:15,680
in a second

00:09:12,880 --> 00:09:16,800
um but on a per query basis you're able

00:09:15,680 --> 00:09:19,519
to choose

00:09:16,800 --> 00:09:19,920
uh for example how many replicas respond

00:09:19,519 --> 00:09:22,160
to

00:09:19,920 --> 00:09:23,680
a given um query and you can do that on

00:09:22,160 --> 00:09:25,920
a per query basis

00:09:23,680 --> 00:09:28,160
um and so you can either ask for all of

00:09:25,920 --> 00:09:32,240
the the replicas to respond

00:09:28,160 --> 00:09:35,760
excuse me excuse me um

00:09:32,240 --> 00:09:37,200
and uh you know if you choose all of the

00:09:35,760 --> 00:09:41,120
replicas that will be a highly

00:09:37,200 --> 00:09:41,519
consistent query um however if only one

00:09:41,120 --> 00:09:43,200
of those

00:09:41,519 --> 00:09:44,640
replicas is down you then lose the

00:09:43,200 --> 00:09:46,800
availability

00:09:44,640 --> 00:09:48,320
on the other side of it you can then ask

00:09:46,800 --> 00:09:49,600
for hey just give me one answer of the

00:09:48,320 --> 00:09:52,160
given replica

00:09:49,600 --> 00:09:52,880
um and you know that means you can

00:09:52,160 --> 00:09:56,320
sustain

00:09:52,880 --> 00:09:58,480
multiple replicas being down however

00:09:56,320 --> 00:10:02,399
you know the response might not be

00:09:58,480 --> 00:10:02,399
consistent with the most recent right

00:10:02,800 --> 00:10:06,160
there are two consistency levers that

00:10:04,560 --> 00:10:09,200
you can kind of play with here

00:10:06,160 --> 00:10:10,959
right um one is the replication factor

00:10:09,200 --> 00:10:13,040
so that is the number

00:10:10,959 --> 00:10:14,640
of copies of a row that you seem to

00:10:13,040 --> 00:10:15,600
restore on a number of different

00:10:14,640 --> 00:10:18,000
replicas

00:10:15,600 --> 00:10:18,800
um and this is determined at schema

00:10:18,000 --> 00:10:20,240
definition

00:10:18,800 --> 00:10:21,920
right and then you've got the

00:10:20,240 --> 00:10:24,000
consistency level so that's

00:10:21,920 --> 00:10:26,079
on a per query basis the number of

00:10:24,000 --> 00:10:30,399
replicas that must respond

00:10:26,079 --> 00:10:30,399
or answer a query um

00:10:30,720 --> 00:10:35,279
whenever you issue it right um and so

00:10:33,360 --> 00:10:36,079
again because you can change and play

00:10:35,279 --> 00:10:38,079
with that

00:10:36,079 --> 00:10:40,800
um that's where you give have that that

00:10:38,079 --> 00:10:43,440
tunable consistency

00:10:40,800 --> 00:10:45,040
so this is what a cassandra database uh

00:10:43,440 --> 00:10:46,560
generally looks like from a high-level

00:10:45,040 --> 00:10:49,839
architectural perspective

00:10:46,560 --> 00:10:53,040
right um you have this concept of

00:10:49,839 --> 00:10:55,120
a node um a node is

00:10:53,040 --> 00:10:56,640
a single server or a single instance or

00:10:55,120 --> 00:10:58,640
if it's single you know

00:10:56,640 --> 00:11:00,800
jvm right so it's a single logical

00:10:58,640 --> 00:11:04,399
instance of cassandra

00:11:00,800 --> 00:11:06,959
running uh cassandra has a

00:11:04,399 --> 00:11:09,360
a masterless architecture right so that

00:11:06,959 --> 00:11:11,360
means every single node is equal

00:11:09,360 --> 00:11:12,800
and is capable of serving any given

00:11:11,360 --> 00:11:15,120
request right

00:11:12,800 --> 00:11:16,720
however each node will only own a

00:11:15,120 --> 00:11:19,600
portion of the data and we'll kind of

00:11:16,720 --> 00:11:22,320
show you how that works in a little bit

00:11:19,600 --> 00:11:22,800
uh and then on top of that cassandra has

00:11:22,320 --> 00:11:24,399
um

00:11:22,800 --> 00:11:26,640
you know some really really great

00:11:24,399 --> 00:11:28,480
awareness of the topology in which it's

00:11:26,640 --> 00:11:32,160
being deployed into right

00:11:28,480 --> 00:11:32,560
so you can tell cassandra uh like what

00:11:32,160 --> 00:11:34,320
rack

00:11:32,560 --> 00:11:36,240
in a data center has been placed in what

00:11:34,320 --> 00:11:38,160
data center it's been placed in

00:11:36,240 --> 00:11:40,000
um on the cloud side of things you know

00:11:38,160 --> 00:11:41,760
you can say what availability zone

00:11:40,000 --> 00:11:42,000
that's been placed in what region that's

00:11:41,760 --> 00:11:45,120
been

00:11:42,000 --> 00:11:48,480
placed in uh and then cassandra will

00:11:45,120 --> 00:11:51,600
actually place replicas um

00:11:48,480 --> 00:11:54,000
in a manner where you know each replica

00:11:51,600 --> 00:11:55,519
is in a different value domain right so

00:11:54,000 --> 00:11:56,160
it'll you know within a single data

00:11:55,519 --> 00:11:57,839
center

00:11:56,160 --> 00:12:00,880
if you ask for a replication factor of

00:11:57,839 --> 00:12:03,200
say three um it'll go and make sure

00:12:00,880 --> 00:12:05,120
that it's placing each one of those

00:12:03,200 --> 00:12:06,639
replicas in a different rack so if that

00:12:05,120 --> 00:12:09,040
entire rack goes down

00:12:06,639 --> 00:12:11,120
right so let's say you have you know

00:12:09,040 --> 00:12:12,720
atop a switch failure

00:12:11,120 --> 00:12:14,639
or you know a networking cable to that

00:12:12,720 --> 00:12:16,560
rack goes um

00:12:14,639 --> 00:12:18,399
you know then you're going to have your

00:12:16,560 --> 00:12:20,240
replicas in those other racks

00:12:18,399 --> 00:12:22,399
right it won't be placing all those

00:12:20,240 --> 00:12:23,279
replicas in three servers within that

00:12:22,399 --> 00:12:26,000
single rack

00:12:23,279 --> 00:12:27,360
right um so some great flexibility when

00:12:26,000 --> 00:12:29,680
it comes to

00:12:27,360 --> 00:12:31,360
uh you know how you structure your

00:12:29,680 --> 00:12:32,959
availability

00:12:31,360 --> 00:12:35,600
uh and this is just a really really nice

00:12:32,959 --> 00:12:37,519
example of that right um and so see here

00:12:35,600 --> 00:12:39,600
down the bottom we've got data center

00:12:37,519 --> 00:12:41,360
one our replication factor there

00:12:39,600 --> 00:12:42,800
is three right so if we look at our

00:12:41,360 --> 00:12:45,440
table across here

00:12:42,800 --> 00:12:47,600
um you know we've got uh you know that

00:12:45,440 --> 00:12:49,519
first row with the name of alice

00:12:47,600 --> 00:12:51,040
um well the record for that is going to

00:12:49,519 --> 00:12:54,000
be placed

00:12:51,040 --> 00:12:55,760
along three different uh nodes within

00:12:54,000 --> 00:12:57,120
that particular data center

00:12:55,760 --> 00:12:59,120
and then we've got a replication factor

00:12:57,120 --> 00:13:01,120
of one and the other data center

00:12:59,120 --> 00:13:02,320
um and you know so we're only placing

00:13:01,120 --> 00:13:07,040
one replica there

00:13:02,320 --> 00:13:07,680
right um and so the number of replicas

00:13:07,040 --> 00:13:09,760
that must

00:13:07,680 --> 00:13:11,200
uh as i mentioned before we've got the

00:13:09,760 --> 00:13:13,519
consistency level right

00:13:11,200 --> 00:13:14,560
so that will tell us how many of these

00:13:13,519 --> 00:13:16,480
different nodes back

00:13:14,560 --> 00:13:17,600
um on the previous page that i showed

00:13:16,480 --> 00:13:20,480
you um

00:13:17,600 --> 00:13:21,519
will actually respond to a request right

00:13:20,480 --> 00:13:24,959
um

00:13:21,519 --> 00:13:25,600
and again always remember consistency

00:13:24,959 --> 00:13:28,639
level

00:13:25,600 --> 00:13:31,440
can be configured on a per request basis

00:13:28,639 --> 00:13:33,279
um and the consistency level is a client

00:13:31,440 --> 00:13:34,160
or application property right so that's

00:13:33,279 --> 00:13:38,320
something you

00:13:34,160 --> 00:13:41,199
specify on the query and it's on a per

00:13:38,320 --> 00:13:41,199
query basis

00:13:41,360 --> 00:13:44,800
there are a number of different uh

00:13:43,040 --> 00:13:47,279
consistency levels that you can choose

00:13:44,800 --> 00:13:49,839
from when you go to build your query

00:13:47,279 --> 00:13:51,760
and again this is purely based on the

00:13:49,839 --> 00:13:55,680
requirements that you have

00:13:51,760 --> 00:13:57,519
for um you know how available or how

00:13:55,680 --> 00:13:58,240
consistent you need your application to

00:13:57,519 --> 00:14:01,279
be

00:13:58,240 --> 00:14:02,639
right so at the top the most consistent

00:14:01,279 --> 00:14:04,160
we've got all

00:14:02,639 --> 00:14:05,680
and then all the way down the bottom is

00:14:04,160 --> 00:14:08,480
any just hey any of

00:14:05,680 --> 00:14:10,320
any replica can respond to this right

00:14:08,480 --> 00:14:11,839
what we tend to see is that most people

00:14:10,320 --> 00:14:14,880
choose quorum

00:14:11,839 --> 00:14:18,079
and quorum is kind of a shorthand for

00:14:14,880 --> 00:14:20,160
saying um i need a majority of replicas

00:14:18,079 --> 00:14:21,040
this what is the smallest majority of

00:14:20,160 --> 00:14:25,360
replicas

00:14:21,040 --> 00:14:26,400
that will respond to my particular query

00:14:25,360 --> 00:14:28,839
right

00:14:26,400 --> 00:14:31,760
[Music]

00:14:28,839 --> 00:14:34,320
so what that means is that with

00:14:31,760 --> 00:14:35,360
quorum we can potentially start to

00:14:34,320 --> 00:14:38,800
construct

00:14:35,360 --> 00:14:40,800
some ideas or a theory around how do we

00:14:38,800 --> 00:14:44,160
build strong consistency

00:14:40,800 --> 00:14:45,279
but potentially still have one or two

00:14:44,160 --> 00:14:48,480
nodes go down

00:14:45,279 --> 00:14:49,920
right um and so cassandra brings in this

00:14:48,480 --> 00:14:51,199
concept of what's called strong

00:14:49,920 --> 00:14:53,120
consistency

00:14:51,199 --> 00:14:54,560
uh and that's where the consistency

00:14:53,120 --> 00:14:57,360
level um

00:14:54,560 --> 00:14:57,680
or the sort of rate of the read that you

00:14:57,360 --> 00:14:59,600
do

00:14:57,680 --> 00:15:01,279
plus the consistency level of the right

00:14:59,600 --> 00:15:01,920
that you do and what i mean when i say

00:15:01,279 --> 00:15:03,519
plus

00:15:01,920 --> 00:15:06,959
we're talking about the number of

00:15:03,519 --> 00:15:09,760
replicas that must respond

00:15:06,959 --> 00:15:12,480
so um you know for the reads if we say

00:15:09,760 --> 00:15:14,560
we've got a replication factor of three

00:15:12,480 --> 00:15:16,480
but on the read side we say hey we need

00:15:14,560 --> 00:15:18,480
at least two to respond

00:15:16,480 --> 00:15:20,800
plus on the right side we say we need

00:15:18,480 --> 00:15:22,639
another two to at least respond

00:15:20,800 --> 00:15:24,639
as long as that is greater than the

00:15:22,639 --> 00:15:26,399
replication factor

00:15:24,639 --> 00:15:28,079
we will actually guarantee that we

00:15:26,399 --> 00:15:31,440
always get um

00:15:28,079 --> 00:15:34,320
we could we always query a node that has

00:15:31,440 --> 00:15:35,920
the most up-to-date previous right right

00:15:34,320 --> 00:15:38,480
so that ticks that

00:15:35,920 --> 00:15:40,880
box for consistency right going back to

00:15:38,480 --> 00:15:42,320
the cap theorem we've got cp as a

00:15:40,880 --> 00:15:43,920
property that we might want to get

00:15:42,320 --> 00:15:47,279
because we want a consistent

00:15:43,920 --> 00:15:50,079
view of the data in our database um

00:15:47,279 --> 00:15:50,480
but again because we're kind of relying

00:15:50,079 --> 00:15:53,440
on this

00:15:50,480 --> 00:15:54,880
overlap right what we can do is we can

00:15:53,440 --> 00:15:56,720
also then get a little bit of that high

00:15:54,880 --> 00:15:58,800
availability and sustain

00:15:56,720 --> 00:16:00,399
uh any particular outages that we might

00:15:58,800 --> 00:16:02,320
have right

00:16:00,399 --> 00:16:03,839
and so this is a great example right so

00:16:02,320 --> 00:16:04,880
we've got on the bottom left of the

00:16:03,839 --> 00:16:06,800
screen here

00:16:04,880 --> 00:16:08,480
you can see the client performs a right

00:16:06,800 --> 00:16:12,959
to cassandra

00:16:08,480 --> 00:16:15,920
that right goes to three nodes right um

00:16:12,959 --> 00:16:16,639
and you know it could even potentially

00:16:15,920 --> 00:16:19,519
have

00:16:16,639 --> 00:16:20,480
let's have a look on the the right hand

00:16:19,519 --> 00:16:22,880
side

00:16:20,480 --> 00:16:24,480
if that right only succeeds on two out

00:16:22,880 --> 00:16:26,160
of those three nodes even though we're

00:16:24,480 --> 00:16:27,199
telling cassandra to distribute to at

00:16:26,160 --> 00:16:30,639
least three nodes

00:16:27,199 --> 00:16:33,279
but something goes wrong um and then we

00:16:30,639 --> 00:16:36,240
issue a read

00:16:33,279 --> 00:16:37,680
then you can see how because we've got

00:16:36,240 --> 00:16:39,600
that overlap

00:16:37,680 --> 00:16:40,720
right um you know we're going to have a

00:16:39,600 --> 00:16:43,440
strongly consistent

00:16:40,720 --> 00:16:45,120
answer because we're including at least

00:16:43,440 --> 00:16:45,839
one of those nodes that has that

00:16:45,120 --> 00:16:48,480
particular

00:16:45,839 --> 00:16:50,639
right um i'll just pause here because we

00:16:48,480 --> 00:16:51,199
do have one question that has has come

00:16:50,639 --> 00:16:54,959
through

00:16:51,199 --> 00:16:56,639
uh in the chat um and

00:16:54,959 --> 00:16:59,120
that is uh so what are the applications

00:16:56,639 --> 00:17:00,959
of casino um that is a very good but

00:16:59,120 --> 00:17:06,400
also broad-ranging question

00:17:00,959 --> 00:17:08,000
um so fundamentally it comes down to

00:17:06,400 --> 00:17:10,959
what is things that you would generally

00:17:08,000 --> 00:17:13,199
see a normal relational database handle

00:17:10,959 --> 00:17:14,480
on the transactional side that's where

00:17:13,199 --> 00:17:16,400
i'd say you've got a good

00:17:14,480 --> 00:17:17,919
good scope to have a look at cassandra

00:17:16,400 --> 00:17:19,120
if you've got the requirements to be

00:17:17,919 --> 00:17:22,160
highly available

00:17:19,120 --> 00:17:25,919
or highly scalable um

00:17:22,160 --> 00:17:28,480
there's probably a um

00:17:25,919 --> 00:17:29,760
a better way of also looking at this

00:17:28,480 --> 00:17:31,360
which is what are some things that

00:17:29,760 --> 00:17:32,640
cassandra is not great for

00:17:31,360 --> 00:17:34,799
and there's definitely some things that

00:17:32,640 --> 00:17:36,480
it is not good at um

00:17:34,799 --> 00:17:38,400
i would definitely not use it as a

00:17:36,480 --> 00:17:40,799
primary analytics data store

00:17:38,400 --> 00:17:41,760
right um you know you're much better off

00:17:40,799 --> 00:17:44,000
using

00:17:41,760 --> 00:17:46,880
um you know look let's go through some

00:17:44,000 --> 00:17:49,520
parquet files up in s3 right

00:17:46,880 --> 00:17:51,039
or hdfs if you know you live in that

00:17:49,520 --> 00:17:54,240
particular world

00:17:51,039 --> 00:17:56,640
um as a graph database um there are some

00:17:54,240 --> 00:17:59,039
graph capabilities built on top of it

00:17:56,640 --> 00:18:00,559
um for scale out you know graph database

00:17:59,039 --> 00:18:02,000
something of things like you know titan

00:18:00,559 --> 00:18:03,840
db

00:18:02,000 --> 00:18:06,160
um which do leverage cassandra to do

00:18:03,840 --> 00:18:08,559
that um you know and so that's certainly

00:18:06,160 --> 00:18:10,080
you know useful um from a real-time

00:18:08,559 --> 00:18:12,400
graph perspective

00:18:10,080 --> 00:18:14,320
um but at the the flip side you know i

00:18:12,400 --> 00:18:16,559
tend to point people towards well hey

00:18:14,320 --> 00:18:18,480
if you're going to do graph stuff graph

00:18:16,559 --> 00:18:19,840
traversals graph analytics whatever that

00:18:18,480 --> 00:18:21,520
kind of stuff is you know you're better

00:18:19,840 --> 00:18:23,120
off looking at something that's

00:18:21,520 --> 00:18:24,880
largely in memory and just buying a

00:18:23,120 --> 00:18:26,960
really big machine to do that

00:18:24,880 --> 00:18:28,000
um it tends to be a heck of a lot

00:18:26,960 --> 00:18:29,919
quicker

00:18:28,000 --> 00:18:31,280
and that's because graph relationships

00:18:29,919 --> 00:18:33,120
are you know highly linked

00:18:31,280 --> 00:18:34,880
right which can break down a little bit

00:18:33,120 --> 00:18:37,280
from a performance perspective

00:18:34,880 --> 00:18:38,480
um in a scaled out architecture that's

00:18:37,280 --> 00:18:39,679
not to say you can't do it

00:18:38,480 --> 00:18:42,160
you know it's just there's some

00:18:39,679 --> 00:18:44,480
trade-offs involved a great question

00:18:42,160 --> 00:18:44,480
thanks

00:18:46,240 --> 00:18:50,720
so we've talked a lot about consistency

00:18:49,280 --> 00:18:53,039
we've talked a lot about

00:18:50,720 --> 00:18:53,919
um how cassandra will do different

00:18:53,039 --> 00:18:56,559
placements

00:18:53,919 --> 00:18:58,559
um based on you know what rack what

00:18:56,559 --> 00:19:02,799
availability zone you're in

00:18:58,559 --> 00:19:03,840
um all that kind of fun stuff um but

00:19:02,799 --> 00:19:06,080
some of you might be thinking well

00:19:03,840 --> 00:19:09,200
that's that's all well and good right

00:19:06,080 --> 00:19:11,760
but how how does cassandra

00:19:09,200 --> 00:19:14,400
you know actually split the data up

00:19:11,760 --> 00:19:14,400
right because

00:19:14,880 --> 00:19:18,160
in order to scale out as you add more

00:19:17,120 --> 00:19:20,080
nodes

00:19:18,160 --> 00:19:21,679
you don't want every single one of those

00:19:20,080 --> 00:19:23,280
nodes to own all the data

00:19:21,679 --> 00:19:24,720
right because you know yes you're

00:19:23,280 --> 00:19:26,480
increasing your availability you're

00:19:24,720 --> 00:19:29,520
increasing your durability

00:19:26,480 --> 00:19:32,000
um but you know you're not actually

00:19:29,520 --> 00:19:32,640
um increasing the number of resources

00:19:32,000 --> 00:19:34,400
per

00:19:32,640 --> 00:19:36,080
gigabyte of data that you're stored

00:19:34,400 --> 00:19:37,520
right which is how you kind of scale out

00:19:36,080 --> 00:19:41,120
that capability

00:19:37,520 --> 00:19:43,200
um and so what cassandra does is it

00:19:41,120 --> 00:19:45,600
actually splits up the data set

00:19:43,200 --> 00:19:46,400
um and stores only a portion of it on

00:19:45,600 --> 00:19:48,080
each node

00:19:46,400 --> 00:19:50,960
right now each node is capable of

00:19:48,080 --> 00:19:52,880
serving any particular request

00:19:50,960 --> 00:19:54,240
but some of those requests may end up

00:19:52,880 --> 00:19:55,520
being routed to other nodes that

00:19:54,240 --> 00:19:59,039
actually own the data

00:19:55,520 --> 00:20:00,480
so how does cassandra know or allocate

00:19:59,039 --> 00:20:02,080
where that data lives

00:20:00,480 --> 00:20:04,240
and how does it do it in a way that's

00:20:02,080 --> 00:20:07,120
easy or cheap to kind of look up

00:20:04,240 --> 00:20:07,679
right um and that comes really down to

00:20:07,120 --> 00:20:09,919
hashing

00:20:07,679 --> 00:20:12,000
right um so at the end of the day

00:20:09,919 --> 00:20:15,120
concept is actually like a distributed

00:20:12,000 --> 00:20:16,000
um hashmap right um it has a hashing

00:20:15,120 --> 00:20:18,080
function

00:20:16,000 --> 00:20:19,600
um you pass data into it and it says

00:20:18,080 --> 00:20:21,520
spits it out and says this is where it

00:20:19,600 --> 00:20:23,840
lives right here's the bucket within my

00:20:21,520 --> 00:20:27,039
map that it lives

00:20:23,840 --> 00:20:28,640
um and you might be thinking well what's

00:20:27,039 --> 00:20:29,760
a what's a ha what's the hash function

00:20:28,640 --> 00:20:32,000
if you haven't you know

00:20:29,760 --> 00:20:34,799
done much in this particular space right

00:20:32,000 --> 00:20:37,120
um so it's a mathematical function

00:20:34,799 --> 00:20:38,480
um that can be used to map data of any

00:20:37,120 --> 00:20:41,919
arbitrary size

00:20:38,480 --> 00:20:43,600
to fixed size values right um and

00:20:41,919 --> 00:20:45,520
there are a number of other properties

00:20:43,600 --> 00:20:46,320
that a lot of people find very useful

00:20:45,520 --> 00:20:48,640
around

00:20:46,320 --> 00:20:49,600
hashing um either from a security

00:20:48,640 --> 00:20:51,520
perspective

00:20:49,600 --> 00:20:53,520
a randomness perspective a distribution

00:20:51,520 --> 00:20:55,760
perspective a speed perspective

00:20:53,520 --> 00:20:57,120
i won't get into that um but the thing

00:20:55,760 --> 00:21:00,000
you need to know for today

00:20:57,120 --> 00:21:00,400
is that a hash function you pass in any

00:21:00,000 --> 00:21:03,120
book

00:21:00,400 --> 00:21:03,440
like blob of data it does some maths on

00:21:03,120 --> 00:21:06,080
it

00:21:03,440 --> 00:21:06,880
and then it spits out a fixed size value

00:21:06,080 --> 00:21:08,480
um

00:21:06,880 --> 00:21:10,400
and in the case cassandra uses the

00:21:08,480 --> 00:21:11,760
members free hash which tends to

00:21:10,400 --> 00:21:14,960
guarantee

00:21:11,760 --> 00:21:17,120
that um the distribution um will be

00:21:14,960 --> 00:21:18,000
somewhat random right so if i take a big

00:21:17,120 --> 00:21:19,600
large blob

00:21:18,000 --> 00:21:22,080
let's say you know it's one megabyte

00:21:19,600 --> 00:21:24,159
long and i hash that with member three

00:21:22,080 --> 00:21:25,840
it'll spin out one number if i just

00:21:24,159 --> 00:21:28,400
change a single bit

00:21:25,840 --> 00:21:30,400
it will spit out a wildly different

00:21:28,400 --> 00:21:31,840
number as well right so we can get some

00:21:30,400 --> 00:21:33,679
great distribution around there and

00:21:31,840 --> 00:21:34,640
that's how we evenly distribute data

00:21:33,679 --> 00:21:38,799
around

00:21:34,640 --> 00:21:38,799
um around cassandra

00:21:38,880 --> 00:21:43,360
uh and so within that let's have a

00:21:41,760 --> 00:21:45,280
little bit of a look around

00:21:43,360 --> 00:21:47,120
an example and one thing i will say as

00:21:45,280 --> 00:21:49,760
well um so

00:21:47,120 --> 00:21:50,799
with with the hashing function um each

00:21:49,760 --> 00:21:53,760
cassandra node

00:21:50,799 --> 00:21:56,000
will actually own a proportion um of

00:21:53,760 --> 00:21:56,880
what we call the um the hash's address

00:21:56,000 --> 00:21:59,919
space

00:21:56,880 --> 00:22:04,240
right um so

00:21:59,919 --> 00:22:06,400
um if we have a uh a hash function

00:22:04,240 --> 00:22:07,600
um it take it it takes it's a consistent

00:22:06,400 --> 00:22:09,440
hash it takes a value

00:22:07,600 --> 00:22:10,960
and it spits out a number between one

00:22:09,440 --> 00:22:14,080
and nine right

00:22:10,960 --> 00:22:15,919
what we can do is we can actually say

00:22:14,080 --> 00:22:18,080
well we know that the entire address

00:22:15,919 --> 00:22:19,760
space of this hash function

00:22:18,080 --> 00:22:21,440
there's only nine numbers right so let's

00:22:19,760 --> 00:22:23,120
actually allocate those

00:22:21,440 --> 00:22:24,480
and say okay the first node in our

00:22:23,120 --> 00:22:27,039
cassandra cluster

00:22:24,480 --> 00:22:27,760
right that's going to own between one

00:22:27,039 --> 00:22:29,840
and three

00:22:27,760 --> 00:22:31,919
right so any value that hashes to that

00:22:29,840 --> 00:22:35,039
that'll end up living on node one

00:22:31,919 --> 00:22:35,440
right no two anything between four and

00:22:35,039 --> 00:22:37,840
six

00:22:35,440 --> 00:22:38,880
that lives on node two right same with

00:22:37,840 --> 00:22:41,840
seven to nine

00:22:38,880 --> 00:22:41,840
lives on node three

00:22:43,120 --> 00:22:46,559
let's apply our consistent hash function

00:22:45,840 --> 00:22:49,600
right

00:22:46,559 --> 00:22:52,960
um so we hash the value alice

00:22:49,600 --> 00:22:56,080
that row ends up living on node three

00:22:52,960 --> 00:22:57,840
wonderful right we end up doing a

00:22:56,080 --> 00:23:00,640
consistent hash of bob

00:22:57,840 --> 00:23:02,400
that ends up living on node one right

00:23:00,640 --> 00:23:03,280
the great thing about this particular

00:23:02,400 --> 00:23:06,840
scheme

00:23:03,280 --> 00:23:08,159
is that the client the driver the client

00:23:06,840 --> 00:23:11,200
application

00:23:08,159 --> 00:23:14,080
can actually um hash

00:23:11,200 --> 00:23:15,760
a query before it sends it to cassandra

00:23:14,080 --> 00:23:18,400
and as long as it knows

00:23:15,760 --> 00:23:19,679
this this um the mapping of which nodes

00:23:18,400 --> 00:23:22,159
own which particular

00:23:19,679 --> 00:23:23,440
um you know addresses or tokens within

00:23:22,159 --> 00:23:26,799
the address space

00:23:23,440 --> 00:23:27,919
um it knows that it just uh it knows

00:23:26,799 --> 00:23:31,360
that it can send

00:23:27,919 --> 00:23:32,799
a query to a particular node um and that

00:23:31,360 --> 00:23:34,400
node will have the data and it doesn't

00:23:32,799 --> 00:23:35,039
have to do any lookups it doesn't have

00:23:34,400 --> 00:23:36,640
to ask

00:23:35,039 --> 00:23:38,720
all the nodes within the cluster hey

00:23:36,640 --> 00:23:39,919
who's got this data so it makes it for a

00:23:38,720 --> 00:23:42,240
really really efficient

00:23:39,919 --> 00:23:42,240
scheme

00:23:42,960 --> 00:23:46,400
and this consistent hashing approach is

00:23:45,679 --> 00:23:49,200
also

00:23:46,400 --> 00:23:51,440
where cassandra gets its ability to

00:23:49,200 --> 00:23:53,440
scale up in a linear fashion

00:23:51,440 --> 00:23:54,799
right and this is probably one of the

00:23:53,440 --> 00:23:58,080
most powerful um

00:23:54,799 --> 00:23:58,799
things about this concept of consistent

00:23:58,080 --> 00:24:01,440
hashing

00:23:58,799 --> 00:24:02,320
uh and the address space right um is

00:24:01,440 --> 00:24:04,799
what we can do

00:24:02,320 --> 00:24:05,520
is we can actually take our three node

00:24:04,799 --> 00:24:08,880
cluster

00:24:05,520 --> 00:24:12,240
right and if we decide to add another uh

00:24:08,880 --> 00:24:14,559
six nodes to it right what we can do is

00:24:12,240 --> 00:24:18,400
we divide up that hash space

00:24:14,559 --> 00:24:20,880
right so again whereas uh node one used

00:24:18,400 --> 00:24:23,919
to own one two and three

00:24:20,880 --> 00:24:24,559
it now has uh node one just only owns

00:24:23,919 --> 00:24:27,840
one

00:24:24,559 --> 00:24:30,400
and it gave up ownership of its range to

00:24:27,840 --> 00:24:32,080
um node two node three right these

00:24:30,400 --> 00:24:34,720
additional nodes that we added in

00:24:32,080 --> 00:24:38,000
there what that means is if you've

00:24:34,720 --> 00:24:42,320
equally sized all your servers

00:24:38,000 --> 00:24:44,320
is you've now got more resources

00:24:42,320 --> 00:24:45,919
applied to a smaller proportion of that

00:24:44,320 --> 00:24:46,640
hash space right so you've got more

00:24:45,919 --> 00:24:48,880
resources

00:24:46,640 --> 00:24:50,240
serving a smaller proportion of your

00:24:48,880 --> 00:24:51,440
data set right

00:24:50,240 --> 00:24:54,240
and that's how you get linear

00:24:51,440 --> 00:24:54,240
scalability

00:24:55,039 --> 00:24:59,679
so how does hashing and replication

00:24:58,559 --> 00:25:01,520
factor interact

00:24:59,679 --> 00:25:04,480
right so you know i've talked a lot

00:25:01,520 --> 00:25:08,000
about well hey this one node now owns

00:25:04,480 --> 00:25:09,679
right this particular row what happens

00:25:08,000 --> 00:25:11,520
or how does that work with a replication

00:25:09,679 --> 00:25:12,559
factor of three right we know how to

00:25:11,520 --> 00:25:14,480
hash

00:25:12,559 --> 00:25:16,080
a value we know how to figure out which

00:25:14,480 --> 00:25:17,679
node it should live on but

00:25:16,080 --> 00:25:19,279
what happens when it's like well hey we

00:25:17,679 --> 00:25:23,120
need three copies of this

00:25:19,279 --> 00:25:26,000
right um what cassandra does

00:25:23,120 --> 00:25:27,840
um is it works out the consistent hash

00:25:26,000 --> 00:25:29,919
on it and then it just looks at well hey

00:25:27,840 --> 00:25:33,600
what's the next node

00:25:29,919 --> 00:25:35,120
that owns the next logical token um

00:25:33,600 --> 00:25:37,120
along and what we're going to do is

00:25:35,120 --> 00:25:40,000
we're actually going to put the replica

00:25:37,120 --> 00:25:41,120
for that data on that node right so all

00:25:40,000 --> 00:25:44,559
it needs to do

00:25:41,120 --> 00:25:46,480
is go clockwise around the ring and it

00:25:44,559 --> 00:25:49,360
and it fills up each next node until

00:25:46,480 --> 00:25:51,120
it's satisfied the replication factor

00:25:49,360 --> 00:25:53,120
and this works for a replication factor

00:25:51,120 --> 00:25:54,799
of three

00:25:53,120 --> 00:25:57,039
it works for a replication factor of

00:25:54,799 --> 00:25:58,720
five whatever that might be

00:25:57,039 --> 00:26:00,559
it just goes clockwise around the ring

00:25:58,720 --> 00:26:02,880
and because we know

00:26:00,559 --> 00:26:04,080
who owns what hash space or what what

00:26:02,880 --> 00:26:07,039
token space

00:26:04,080 --> 00:26:08,720
we then also know where to look up any

00:26:07,039 --> 00:26:12,000
given particular replica

00:26:08,720 --> 00:26:15,840
um or of a given piece of data

00:26:12,000 --> 00:26:18,559
right um i'll pause here for a second

00:26:15,840 --> 00:26:19,440
um we kind of covered some very heavy uh

00:26:18,559 --> 00:26:21,919
concepts

00:26:19,440 --> 00:26:24,080
uh and i'll answer a few questions right

00:26:21,919 --> 00:26:27,039
um so we've had someone uh

00:26:24,080 --> 00:26:28,480
ask what is the relationship between

00:26:27,039 --> 00:26:31,840
apache hadoop

00:26:28,480 --> 00:26:36,640
hbase hive and cassandra

00:26:31,840 --> 00:26:36,640
um so this one's pretty easy to um

00:26:36,960 --> 00:26:42,240
oh here let me sorry i'm just figuring

00:26:39,360 --> 00:26:44,640
out how to actually

00:26:42,240 --> 00:26:45,679
zoom and answer questions um so yeah the

00:26:44,640 --> 00:26:48,960
relationship between

00:26:45,679 --> 00:26:50,240
hadoop hbase5 and cassandra um there's

00:26:48,960 --> 00:26:52,240
actually no relationship

00:26:50,240 --> 00:26:54,320
between them other than what i would say

00:26:52,240 --> 00:26:55,679
is they are big data technologies and

00:26:54,320 --> 00:26:56,720
they all live under the apache

00:26:55,679 --> 00:26:59,200
foundation

00:26:56,720 --> 00:27:00,400
um hbase and hive are very much

00:26:59,200 --> 00:27:04,400
components of

00:27:00,400 --> 00:27:07,120
the hadoop ecosystem um hive is probably

00:27:04,400 --> 00:27:10,880
the most similar to cassandra

00:27:07,120 --> 00:27:13,200
it is a you know a scale out database

00:27:10,880 --> 00:27:15,120
however it does focus on being

00:27:13,200 --> 00:27:17,200
consistent and

00:27:15,120 --> 00:27:19,279
partition tolerant it is not incredibly

00:27:17,200 --> 00:27:20,640
highly available

00:27:19,279 --> 00:27:22,960
there are some things you can do that

00:27:20,640 --> 00:27:25,600
can help out with that um it also

00:27:22,960 --> 00:27:28,320
largely runs on top of hdfs

00:27:25,600 --> 00:27:30,640
um as well now that is me going off

00:27:28,320 --> 00:27:34,000
knowledge about uh apache hive from

00:27:30,640 --> 00:27:35,679
two or three years ago so um if anyone

00:27:34,000 --> 00:27:38,640
knows far more about it and that has

00:27:35,679 --> 00:27:40,880
since changed i deeply apologize

00:27:38,640 --> 00:27:42,960
uh and then hadoop um you know it's

00:27:40,880 --> 00:27:45,039
essentially a you know it's a mapreduce

00:27:42,960 --> 00:27:47,679
framework right so it's about crunching

00:27:45,039 --> 00:27:49,279
uh a lot of data across a lot of nodes

00:27:47,679 --> 00:27:51,120
whereas again cassandra is more

00:27:49,279 --> 00:27:53,840
focused on the transactional data

00:27:51,120 --> 00:27:53,840
storage layer

00:27:53,919 --> 00:27:58,880
uh someone has just someone has just

00:27:57,440 --> 00:28:02,720
asked

00:27:58,880 --> 00:28:05,679
does cassandra work on windows

00:28:02,720 --> 00:28:07,120
kaida um so it does so i believe from

00:28:05,679 --> 00:28:10,720
kiss android 2

00:28:07,120 --> 00:28:11,360
2.1 or 2.2 there has been first class

00:28:10,720 --> 00:28:14,840
support

00:28:11,360 --> 00:28:17,919
for uh windows

00:28:14,840 --> 00:28:19,760
however um i believe within it with the

00:28:17,919 --> 00:28:20,640
new really upcoming release of cassandra

00:28:19,760 --> 00:28:23,760
4.0

00:28:20,640 --> 00:28:26,799
um windows support may

00:28:23,760 --> 00:28:28,399
is likely to be deprecated um

00:28:26,799 --> 00:28:30,799
i think just within the community we

00:28:28,399 --> 00:28:33,679
haven't seen a ton of support

00:28:30,799 --> 00:28:34,240
or interest or large production users

00:28:33,679 --> 00:28:36,399
running it

00:28:34,240 --> 00:28:37,919
on on windows it certainly does work and

00:28:36,399 --> 00:28:38,399
but there's a few kind of gnarly bits

00:28:37,919 --> 00:28:40,799
around

00:28:38,399 --> 00:28:41,919
keeping it compatible um but i think

00:28:40,799 --> 00:28:45,520
most importantly

00:28:41,919 --> 00:28:47,360
is um so wsl um

00:28:45,520 --> 00:28:48,720
windows system for linux the linux

00:28:47,360 --> 00:28:51,679
compatibility layer

00:28:48,720 --> 00:28:52,159
um we've seen a lot of uh developers um

00:28:51,679 --> 00:28:54,720
actually

00:28:52,159 --> 00:28:56,240
use cassandra with that um with with

00:28:54,720 --> 00:28:59,200
some great success

00:28:56,240 --> 00:29:00,720
um wsl one uh was a little bit gnarly

00:28:59,200 --> 00:29:03,120
when it came to the performance

00:29:00,720 --> 00:29:04,480
side of it um it wasn't particularly

00:29:03,120 --> 00:29:07,600
high performance on the i o

00:29:04,480 --> 00:29:08,320
side i believe the usl two um is a lot

00:29:07,600 --> 00:29:12,399
better

00:29:08,320 --> 00:29:14,559
at that um but but yeah no cassandra is

00:29:12,399 --> 00:29:15,679
very much it it lives and brazen in the

00:29:14,559 --> 00:29:17,520
linux space

00:29:15,679 --> 00:29:20,000
um but you can't get it working on

00:29:17,520 --> 00:29:20,000
windows

00:29:21,840 --> 00:29:26,320
all right uh we'll do uh we'll do just

00:29:25,440 --> 00:29:29,520
two more questions

00:29:26,320 --> 00:29:32,320
uh and then i'll get back into it um

00:29:29,520 --> 00:29:34,080
so here's one uh so since the data is

00:29:32,320 --> 00:29:35,919
just distributed by hashing

00:29:34,080 --> 00:29:37,679
would it be bad a bad use case to use

00:29:35,919 --> 00:29:39,919
cassandra for a data set that is

00:29:37,679 --> 00:29:41,200
ordered um it seems like there would be

00:29:39,919 --> 00:29:42,720
a lot of network traffic in that

00:29:41,200 --> 00:29:44,080
scenario since you would be hitting a

00:29:42,720 --> 00:29:44,880
lot of different nodes which you could

00:29:44,080 --> 00:29:46,559
be avoided

00:29:44,880 --> 00:29:48,080
it could be avoided using a different

00:29:46,559 --> 00:29:50,240
technology

00:29:48,080 --> 00:29:51,840
uh that is a really really good question

00:29:50,240 --> 00:29:55,679
right so

00:29:51,840 --> 00:29:56,720
um in the so cassandra actually supports

00:29:55,679 --> 00:29:59,840
the concept of

00:29:56,720 --> 00:30:03,520
pluggable hashing mechanisms right

00:29:59,840 --> 00:30:06,399
um and uh i believe

00:30:03,520 --> 00:30:07,360
uh i think it it got deprecated or

00:30:06,399 --> 00:30:10,480
unsupported

00:30:07,360 --> 00:30:12,720
um but there is actually a consistent

00:30:10,480 --> 00:30:14,799
order hashing mechanism

00:30:12,720 --> 00:30:16,240
um that you can apply to apache

00:30:14,799 --> 00:30:18,080
cassandra right so

00:30:16,240 --> 00:30:19,919
you can guarantee that your table will

00:30:18,080 --> 00:30:21,120
actually be in order or stored in order

00:30:19,919 --> 00:30:23,600
around the ring

00:30:21,120 --> 00:30:25,840
um there were a lot of downsides with

00:30:23,600 --> 00:30:27,440
doing that um with most use cases that

00:30:25,840 --> 00:30:29,200
actually ended up we ended up seeing

00:30:27,440 --> 00:30:32,480
cassandra get deployed for

00:30:29,200 --> 00:30:33,279
um because it is consistently ordering

00:30:32,480 --> 00:30:36,080
that

00:30:33,279 --> 00:30:37,120
um you tend to see a lot of hot spots

00:30:36,080 --> 00:30:40,720
right so

00:30:37,120 --> 00:30:44,159
for example if you um were hashing

00:30:40,720 --> 00:30:46,720
on um a primary key value of name

00:30:44,159 --> 00:30:48,559
right for example um you would start to

00:30:46,720 --> 00:30:50,559
see hot spots

00:30:48,559 --> 00:30:51,760
you know trending for different names

00:30:50,559 --> 00:30:52,640
that were popular in different

00:30:51,760 --> 00:30:55,840
geographical

00:30:52,640 --> 00:30:57,519
locations right um you know so for

00:30:55,840 --> 00:31:00,960
example

00:30:57,519 --> 00:31:01,919
if you had uh you know a largely western

00:31:00,960 --> 00:31:05,039
focus

00:31:01,919 --> 00:31:07,760
um user base um you know you might see

00:31:05,039 --> 00:31:08,880
you know lots of like rebecca's and

00:31:07,760 --> 00:31:12,399
john's and

00:31:08,880 --> 00:31:14,399
um you know dave's for example right

00:31:12,399 --> 00:31:16,640
um in other locations you know you might

00:31:14,399 --> 00:31:19,039
see lots of like mohammed's for example

00:31:16,640 --> 00:31:20,960
um and so what that means is because of

00:31:19,039 --> 00:31:21,760
that that consistent ordering it makes

00:31:20,960 --> 00:31:24,559
it really good to

00:31:21,760 --> 00:31:26,480
kind of um scan the entire table around

00:31:24,559 --> 00:31:28,320
the ring makes it very easy

00:31:26,480 --> 00:31:30,240
but there would be one or two nodes that

00:31:28,320 --> 00:31:31,039
just had way too much data compared to

00:31:30,240 --> 00:31:33,919
the other ones

00:31:31,039 --> 00:31:34,880
right so um that's only made it made it

00:31:33,919 --> 00:31:38,240
challenging

00:31:34,880 --> 00:31:40,559
um and then to page through an entire

00:31:38,240 --> 00:31:43,919
table if it's ordered randomly

00:31:40,559 --> 00:31:45,760
um you know you definitely it

00:31:43,919 --> 00:31:49,039
you can do it efficiently like it'll

00:31:45,760 --> 00:31:51,760
only hit each particular record once

00:31:49,039 --> 00:31:52,799
um but yes the problem then is it's out

00:31:51,760 --> 00:31:54,640
of order

00:31:52,799 --> 00:31:57,039
um the other thing as well is if you're

00:31:54,640 --> 00:32:00,080
doing lots of those whole table scans

00:31:57,039 --> 00:32:01,679
um the way that you query because it's

00:32:00,080 --> 00:32:03,039
it's request responses like hey give me

00:32:01,679 --> 00:32:03,519
this one thing hey give me this one

00:32:03,039 --> 00:32:04,559
thing

00:32:03,519 --> 00:32:06,399
and you know you can do some

00:32:04,559 --> 00:32:07,120
optimizations and you can say hey give

00:32:06,399 --> 00:32:09,120
me all the tote

00:32:07,120 --> 00:32:10,640
you know all the rows with within this

00:32:09,120 --> 00:32:11,360
token space that makes a little bit more

00:32:10,640 --> 00:32:14,720
efficient

00:32:11,360 --> 00:32:17,840
but cassandra is not really designed um

00:32:14,720 --> 00:32:20,960
you know to to be um you know kind of

00:32:17,840 --> 00:32:22,480
that that full query oh sorry that full

00:32:20,960 --> 00:32:24,159
analytics capability where you're

00:32:22,480 --> 00:32:25,840
scanning the entire table

00:32:24,159 --> 00:32:27,360
right so there's a lot of inefficiencies

00:32:25,840 --> 00:32:28,640
on the read side we'll get into that in

00:32:27,360 --> 00:32:30,320
a sec

00:32:28,640 --> 00:32:32,880
about why that's not a particularly good

00:32:30,320 --> 00:32:35,919
idea so

00:32:32,880 --> 00:32:36,960
long quest a long answer the short

00:32:35,919 --> 00:32:40,480
version of that

00:32:36,960 --> 00:32:42,480
um is you know if you needed

00:32:40,480 --> 00:32:43,919
an ordered data set like the entire

00:32:42,480 --> 00:32:46,399
table was ordered not just

00:32:43,919 --> 00:32:48,000
components within that and you needed to

00:32:46,399 --> 00:32:49,600
query the entire table

00:32:48,000 --> 00:32:52,480
often i probably wouldn't look at

00:32:49,600 --> 00:32:52,480
cassandra for that

00:32:55,120 --> 00:32:57,679
uh and then the last question i'll

00:32:56,399 --> 00:32:58,720
answer there are more coming in but

00:32:57,679 --> 00:32:59,039
we'll kind of deal with those a little

00:32:58,720 --> 00:33:01,360
bit

00:32:59,039 --> 00:33:02,240
um later is cassandra demands a schemer

00:33:01,360 --> 00:33:04,640
i guess

00:33:02,240 --> 00:33:05,760
um can it fits variable schemas in the

00:33:04,640 --> 00:33:09,360
same table

00:33:05,760 --> 00:33:10,080
so yes cassandra is um a schema based

00:33:09,360 --> 00:33:13,360
database

00:33:10,080 --> 00:33:16,080
in the past it was a schema-less

00:33:13,360 --> 00:33:18,480
database right um however i think very

00:33:16,080 --> 00:33:20,880
wisely a lot of folks in the project

00:33:18,480 --> 00:33:22,399
you know decided to implement a schema

00:33:20,880 --> 00:33:23,679
it makes it a little bit easier to do a

00:33:22,399 --> 00:33:24,720
number of things from a data science

00:33:23,679 --> 00:33:28,559
perspective

00:33:24,720 --> 00:33:30,960
uh but importantly um you know

00:33:28,559 --> 00:33:32,000
whether you define a schema logically or

00:33:30,960 --> 00:33:35,039
formally

00:33:32,000 --> 00:33:38,399
um or you don't there is an

00:33:35,039 --> 00:33:40,240
inherent or an implied schema right

00:33:38,399 --> 00:33:41,760
having said that there are a number of

00:33:40,240 --> 00:33:43,360
schemas where there is a certain amount

00:33:41,760 --> 00:33:46,399
of flexibility around

00:33:43,360 --> 00:33:48,159
you know um for example different

00:33:46,399 --> 00:33:49,760
properties things can have

00:33:48,159 --> 00:33:51,279
uh and you know you see that in document

00:33:49,760 --> 00:33:54,559
models and that kind of thing

00:33:51,279 --> 00:33:56,640
um you can model um you know flexible

00:33:54,559 --> 00:33:57,600
things like that within within cassandra

00:33:56,640 --> 00:33:59,120
it is very

00:33:57,600 --> 00:34:01,039
doable but you will be defining a

00:33:59,120 --> 00:34:02,720
schemer upfront anyway that allows you

00:34:01,039 --> 00:34:06,480
to do that

00:34:02,720 --> 00:34:09,200
a great question

00:34:06,480 --> 00:34:09,919
cool so going on um we'll try and get

00:34:09,200 --> 00:34:12,800
through this

00:34:09,919 --> 00:34:14,159
very very quickly um because we do have

00:34:12,800 --> 00:34:15,520
a little bit to cover

00:34:14,159 --> 00:34:17,599
at the end and i've only got a few more

00:34:15,520 --> 00:34:20,079
minutes um this is what multi-dc

00:34:17,599 --> 00:34:21,679
replication also looks like right so you

00:34:20,079 --> 00:34:24,159
know exact same thing

00:34:21,679 --> 00:34:25,359
um it just you know it's it sends that

00:34:24,159 --> 00:34:27,440
right off to the other

00:34:25,359 --> 00:34:29,520
of the other dc the other dc lives in

00:34:27,440 --> 00:34:30,800
the same um hashing address space so

00:34:29,520 --> 00:34:31,599
you're not talking about two different

00:34:30,800 --> 00:34:33,440
spaces

00:34:31,599 --> 00:34:34,800
um but cassandra will kind of interleave

00:34:33,440 --> 00:34:40,159
those for you

00:34:34,800 --> 00:34:40,159
and then understand which dc's are where

00:34:41,280 --> 00:34:45,119
um so here's an example of a number of

00:34:43,280 --> 00:34:47,040
different consistency levels right this

00:34:45,119 --> 00:34:48,560
is a consistency level of one

00:34:47,040 --> 00:34:50,480
we've got that central node being the

00:34:48,560 --> 00:34:53,359
coordinator node uh

00:34:50,480 --> 00:34:55,200
and it only needs one response right we

00:34:53,359 --> 00:34:57,440
can see that there

00:34:55,200 --> 00:34:58,720
um and you can see here that if one of

00:34:57,440 --> 00:34:59,920
those nodes fails

00:34:58,720 --> 00:35:01,680
we're still getting a response we're

00:34:59,920 --> 00:35:02,480
getting at least one response from those

00:35:01,680 --> 00:35:05,440
other nodes

00:35:02,480 --> 00:35:06,000
swayed so our query succeeds consistency

00:35:05,440 --> 00:35:08,880
level of

00:35:06,000 --> 00:35:10,800
all we send a query hey we get a

00:35:08,880 --> 00:35:13,119
response from all those replicas

00:35:10,800 --> 00:35:14,800
wonderful that query succeeds as soon as

00:35:13,119 --> 00:35:18,079
one of those files

00:35:14,800 --> 00:35:19,119
the whole query fails and this is quorum

00:35:18,079 --> 00:35:21,920
as well right

00:35:19,119 --> 00:35:22,480
um so if you remember um from before

00:35:21,920 --> 00:35:25,040
quorum

00:35:22,480 --> 00:35:26,160
is the smallest possible majority within

00:35:25,040 --> 00:35:28,560
um

00:35:26,160 --> 00:35:30,000
you know the replication factor or you

00:35:28,560 --> 00:35:31,920
can think of it as

00:35:30,000 --> 00:35:33,520
um you know divide the replication

00:35:31,920 --> 00:35:36,720
factor in half

00:35:33,520 --> 00:35:40,079
uh round down then add one right

00:35:36,720 --> 00:35:42,800
so we still got a success there right

00:35:40,079 --> 00:35:43,599
awesome so that's a very very very quick

00:35:42,800 --> 00:35:46,640
high level

00:35:43,599 --> 00:35:49,119
view of cassandra's um

00:35:46,640 --> 00:35:50,160
partitioning the consistency levels that

00:35:49,119 --> 00:35:52,640
it has

00:35:50,160 --> 00:35:54,079
um and let's get a little bit into the

00:35:52,640 --> 00:35:57,280
the read and write path right

00:35:54,079 --> 00:35:57,599
um and i think what has probably come up

00:35:57,280 --> 00:35:59,440
in

00:35:57,599 --> 00:36:01,359
uh some of my questions that i have

00:35:59,440 --> 00:36:03,520
answered um

00:36:01,359 --> 00:36:04,960
is there's this overwhelming theme that

00:36:03,520 --> 00:36:06,880
that you kind of need to be a little bit

00:36:04,960 --> 00:36:09,680
mechanically sympathetic to

00:36:06,880 --> 00:36:11,440
cassandra right um and that was really

00:36:09,680 --> 00:36:14,240
illustrated by that previous question

00:36:11,440 --> 00:36:15,680
around well hey what about if i've got

00:36:14,240 --> 00:36:17,200
some data that's ordered

00:36:15,680 --> 00:36:19,119
right is cassandra a good choice for

00:36:17,200 --> 00:36:20,720
that um

00:36:19,119 --> 00:36:22,240
and you know really you need to be

00:36:20,720 --> 00:36:23,599
thinking around what is cassandra good

00:36:22,240 --> 00:36:26,800
at what is its strengths

00:36:23,599 --> 00:36:28,720
right um and picking or designing your

00:36:26,800 --> 00:36:29,920
data model towards those strengths

00:36:28,720 --> 00:36:31,280
right you know it's not like a

00:36:29,920 --> 00:36:33,119
relational database where you just

00:36:31,280 --> 00:36:34,640
describe the relationships

00:36:33,119 --> 00:36:36,480
um and kind of just hope it keeps on

00:36:34,640 --> 00:36:39,119
working and then maybe do a few indexes

00:36:36,480 --> 00:36:40,400
um to kind of help things out um

00:36:39,119 --> 00:36:42,560
cassandra you really got to be thinking

00:36:40,400 --> 00:36:46,560
about the way it behaves um up front

00:36:42,560 --> 00:36:48,160
right so in terms of

00:36:46,560 --> 00:36:50,079
you know what does a single right look

00:36:48,160 --> 00:36:52,000
like uh we've kind of covered what that

00:36:50,079 --> 00:36:53,839
looks like from a broad system

00:36:52,000 --> 00:36:55,680
perspective right so it hits coordinator

00:36:53,839 --> 00:36:57,440
node um

00:36:55,680 --> 00:36:59,680
and you know it works out which you know

00:36:57,440 --> 00:37:01,359
tokens basically it belongs to

00:36:59,680 --> 00:37:03,119
uh and then it'll go and route that

00:37:01,359 --> 00:37:04,000
query to the other replicas if it needs

00:37:03,119 --> 00:37:05,839
to

00:37:04,000 --> 00:37:07,119
um but what does it actually look like

00:37:05,839 --> 00:37:10,480
on the node itself

00:37:07,119 --> 00:37:13,839
right um so

00:37:10,480 --> 00:37:14,480
on the uh the right path um we have this

00:37:13,839 --> 00:37:19,040
concept

00:37:14,480 --> 00:37:21,119
of a commit log right so the commit log

00:37:19,040 --> 00:37:22,240
is the very very very first thing that

00:37:21,119 --> 00:37:24,800
cassandra will

00:37:22,240 --> 00:37:25,440
put the data in before it does anything

00:37:24,800 --> 00:37:27,200
else

00:37:25,440 --> 00:37:29,040
right as long as it's the owner for that

00:37:27,200 --> 00:37:31,599
particular uh

00:37:29,040 --> 00:37:33,359
query um and what it is is it's

00:37:31,599 --> 00:37:35,839
essentially like the same as

00:37:33,359 --> 00:37:37,359
write ahead log in postgres a journal a

00:37:35,839 --> 00:37:37,839
transaction log whatever you might call

00:37:37,359 --> 00:37:40,560
it

00:37:37,839 --> 00:37:42,320
so saying hey i received this if

00:37:40,560 --> 00:37:44,000
anything goes wrong while i'm processing

00:37:42,320 --> 00:37:46,320
and figuring out what to do with it

00:37:44,000 --> 00:37:47,839
and i have to reboot or restart i can

00:37:46,320 --> 00:37:49,839
replay this from my command log

00:37:47,839 --> 00:37:51,839
right so the first thing as soon as a

00:37:49,839 --> 00:37:53,920
client inserts or writes me this

00:37:51,839 --> 00:37:55,200
data cassandra is going to grab that

00:37:53,920 --> 00:37:57,280
coordinator node's going to

00:37:55,200 --> 00:37:59,599
right wicked i'm going to throw that in

00:37:57,280 --> 00:38:02,839
my commit load

00:37:59,599 --> 00:38:04,079
um cassandra will flush that commit log

00:38:02,839 --> 00:38:06,800
periodically

00:38:04,079 --> 00:38:08,400
by default every 20 seconds i believe

00:38:06,800 --> 00:38:09,760
there's a number of databases out there

00:38:08,400 --> 00:38:12,720
that will actually

00:38:09,760 --> 00:38:14,640
fsync every single right on their commit

00:38:12,720 --> 00:38:15,280
log so they make sure it's persistent to

00:38:14,640 --> 00:38:16,800
disk

00:38:15,280 --> 00:38:18,720
cassandra can be played a little bit

00:38:16,800 --> 00:38:22,560
looser with that because again

00:38:18,720 --> 00:38:24,480
it's making the bet that there's also

00:38:22,560 --> 00:38:26,000
another node or another two nodes or

00:38:24,480 --> 00:38:27,680
another three nodes that are also

00:38:26,000 --> 00:38:29,440
getting that right

00:38:27,680 --> 00:38:30,960
and the is going to persist that to

00:38:29,440 --> 00:38:33,599
their commit logs as well

00:38:30,960 --> 00:38:35,440
right so um you've got a little bit of

00:38:33,599 --> 00:38:37,280
flexibility in that as well so you're

00:38:35,440 --> 00:38:40,560
not having to have sync every single

00:38:37,280 --> 00:38:40,560
every single um right

00:38:42,000 --> 00:38:45,760
um the next thing uh that the node will

00:38:44,160 --> 00:38:47,920
will do and again this is all about

00:38:45,760 --> 00:38:49,040
persisting it through the local node

00:38:47,920 --> 00:38:50,640
itself so you've already got the

00:38:49,040 --> 00:38:51,839
coordinator layer sending off the right

00:38:50,640 --> 00:38:53,359
to the other nodes as well that's

00:38:51,839 --> 00:38:57,280
already kind of happened

00:38:53,359 --> 00:39:01,440
um and it will then insert

00:38:57,280 --> 00:39:03,280
that right into a mem table right so um

00:39:01,440 --> 00:39:04,560
it's essentially in memory storage for

00:39:03,280 --> 00:39:06,240
rights um

00:39:04,560 --> 00:39:08,400
all rights will go to the mem table

00:39:06,240 --> 00:39:11,440
after being written to the commit log

00:39:08,400 --> 00:39:14,320
um and

00:39:11,440 --> 00:39:15,520
you could argue and i i i act somewhat a

00:39:14,320 --> 00:39:17,200
as a case

00:39:15,520 --> 00:39:19,359
um but it's essentially it's just the

00:39:17,200 --> 00:39:20,160
primary um data structure that cassandra

00:39:19,359 --> 00:39:23,920
has

00:39:20,160 --> 00:39:27,280
to operate on data in memory right um

00:39:23,920 --> 00:39:28,800
what'll happen then is it will only be

00:39:27,280 --> 00:39:29,920
able to keep a certain number of those

00:39:28,800 --> 00:39:32,960
mem tables

00:39:29,920 --> 00:39:36,720
uh in in memory right you know because

00:39:32,960 --> 00:39:38,560
um memory is more expensive than disk

00:39:36,720 --> 00:39:41,359
um and what will happen is once it

00:39:38,560 --> 00:39:43,440
reaches a pre-configured threshold

00:39:41,359 --> 00:39:44,560
it'll flush or it'll take that mem table

00:39:43,440 --> 00:39:47,680
and write it to death

00:39:44,560 --> 00:39:47,680
to disk right

00:39:48,480 --> 00:39:52,320
and that mem table when it's written to

00:39:50,240 --> 00:39:54,160
disk it's called an ss table it's the

00:39:52,320 --> 00:39:56,079
exact same data structure it's just the

00:39:54,160 --> 00:39:59,119
ss table is the

00:39:56,079 --> 00:40:03,119
kind of preserved or stored in memory

00:39:59,119 --> 00:40:05,520
representation on disk ss um

00:40:03,119 --> 00:40:07,440
i believe that stands for sorted string

00:40:05,520 --> 00:40:09,440
table

00:40:07,440 --> 00:40:11,440
and there's a number of other mechanisms

00:40:09,440 --> 00:40:13,599
as well that cassandra has

00:40:11,440 --> 00:40:15,920
both in memory and on disk and they're

00:40:13,599 --> 00:40:18,319
largely there to try and reduce

00:40:15,920 --> 00:40:20,240
um you know the the total time it takes

00:40:18,319 --> 00:40:23,200
to serve a particular query

00:40:20,240 --> 00:40:24,800
right sorry for interrupting but we have

00:40:23,200 --> 00:40:27,920
five minutes left

00:40:24,800 --> 00:40:29,440
wonderful thank you very much um

00:40:27,920 --> 00:40:30,960
i'll jump through this super duper

00:40:29,440 --> 00:40:32,800
quickly um as

00:40:30,960 --> 00:40:34,000
as well um luckily because i've been

00:40:32,800 --> 00:40:36,800
answering questions

00:40:34,000 --> 00:40:38,960
throughout the session um we we won't

00:40:36,800 --> 00:40:41,040
have to do too many questions at the end

00:40:38,960 --> 00:40:42,480
um and so this is the ss table which i

00:40:41,040 --> 00:40:45,760
just described before

00:40:42,480 --> 00:40:47,599
um keep in mind so most importantly um

00:40:45,760 --> 00:40:50,480
it never gets modified once it's written

00:40:47,599 --> 00:40:53,839
to disk it never gets modified

00:40:50,480 --> 00:40:56,079
however um it can be deleted or it can

00:40:53,839 --> 00:40:59,359
be merged with another ss table

00:40:56,079 --> 00:41:00,000
right um and then so that's so under the

00:40:59,359 --> 00:41:03,280
hood

00:41:00,000 --> 00:41:06,560
all these ss tables form a merge uh

00:41:03,280 --> 00:41:09,040
merge structured uh sorry a merge

00:41:06,560 --> 00:41:10,079
uh log trade right i might be getting

00:41:09,040 --> 00:41:12,319
that a little bit wrong

00:41:10,079 --> 00:41:13,440
um but essentially what it means is that

00:41:12,319 --> 00:41:16,079
in order to

00:41:13,440 --> 00:41:16,800
um you know kind of write assist data it

00:41:16,079 --> 00:41:19,119
has also

00:41:16,800 --> 00:41:21,040
all these ss tables and it can only like

00:41:19,119 --> 00:41:24,319
merge or

00:41:21,040 --> 00:41:26,079
delete them right um and so we'll kind

00:41:24,319 --> 00:41:29,839
of get into how that also

00:41:26,079 --> 00:41:29,839
impacts on the ring side in a little bit

00:41:29,920 --> 00:41:34,160
as i mentioned um these ss tables can

00:41:32,319 --> 00:41:35,280
get merged a lot of them will get flush

00:41:34,160 --> 00:41:37,040
from memory on

00:41:35,280 --> 00:41:39,440
disk so you can end up with like a lot

00:41:37,040 --> 00:41:40,720
of small ones you can end up with with

00:41:39,440 --> 00:41:44,160
ones where

00:41:40,720 --> 00:41:45,520
a particular row might be updated um say

00:41:44,160 --> 00:41:47,200
a few hours ago

00:41:45,520 --> 00:41:48,720
that's in one ss table then it gets

00:41:47,200 --> 00:41:51,119
updated again and then

00:41:48,720 --> 00:41:53,040
that update is in another ss table right

00:41:51,119 --> 00:41:54,800
so cassandra has this process called

00:41:53,040 --> 00:41:57,200
compaction where it merges those

00:41:54,800 --> 00:41:58,079
ss tables together so that it can try

00:41:57,200 --> 00:42:01,280
and keep as

00:41:58,079 --> 00:42:03,359
many of um you know those rows in the

00:42:01,280 --> 00:42:06,560
same ss table as well which makes for

00:42:03,359 --> 00:42:09,760
way more efficient reads

00:42:06,560 --> 00:42:12,560
so on the read side of things um again

00:42:09,760 --> 00:42:13,760
we've got that same um high-level

00:42:12,560 --> 00:42:15,520
architectural process

00:42:13,760 --> 00:42:17,200
so that same high-level distributed

00:42:15,520 --> 00:42:18,160
process that happens the client sends a

00:42:17,200 --> 00:42:21,520
request to a

00:42:18,160 --> 00:42:23,760
coordinator works out what the um

00:42:21,520 --> 00:42:24,560
what particular token or what what node

00:42:23,760 --> 00:42:26,160
owns that

00:42:24,560 --> 00:42:27,599
and then it sends that request onto that

00:42:26,160 --> 00:42:28,640
the coordinator may also be that

00:42:27,599 --> 00:42:31,359
particular one

00:42:28,640 --> 00:42:32,720
right um what'll happen then is it's got

00:42:31,359 --> 00:42:35,680
a number of caches

00:42:32,720 --> 00:42:37,359
um that'll first check right um it also

00:42:35,680 --> 00:42:38,000
uses some bloom filters to figure out

00:42:37,359 --> 00:42:39,599
where

00:42:38,000 --> 00:42:41,280
you know those keys might actually be

00:42:39,599 --> 00:42:43,760
either in the caches or

00:42:41,280 --> 00:42:45,839
on disk uh and then it tries and

00:42:43,760 --> 00:42:50,640
fulfills that particular request

00:42:45,839 --> 00:42:50,640
right um the

00:42:51,760 --> 00:42:58,560
partition of you know summary

00:42:55,440 --> 00:43:00,720
um is what's used um

00:42:58,560 --> 00:43:02,000
as well as the index to locate data on

00:43:00,720 --> 00:43:04,000
desk so first it checks

00:43:02,000 --> 00:43:05,839
all the stuff in memory right so we're

00:43:04,000 --> 00:43:07,119
talking about mem tables the rotation if

00:43:05,839 --> 00:43:10,160
it's enabled

00:43:07,119 --> 00:43:10,880
um and any and then potentially the key

00:43:10,160 --> 00:43:12,720
case

00:43:10,880 --> 00:43:14,400
um but then we'll look at the petition

00:43:12,720 --> 00:43:15,119
summaries and indexes on disk to try and

00:43:14,400 --> 00:43:18,160
figure out where

00:43:15,119 --> 00:43:19,280
where it lives we'll jump through this a

00:43:18,160 --> 00:43:22,000
little bit more

00:43:19,280 --> 00:43:23,520
um the keycase is potentially useful it

00:43:22,000 --> 00:43:25,440
is what it sounds like

00:43:23,520 --> 00:43:27,359
um it makes lookups a little bit faster

00:43:25,440 --> 00:43:29,200
and it kind of keeps those hot um keys

00:43:27,359 --> 00:43:30,720
in memory

00:43:29,200 --> 00:43:32,319
uh and then a row case is actually

00:43:30,720 --> 00:43:33,920
storing essentially a result of the

00:43:32,319 --> 00:43:34,960
entire query which is really great if

00:43:33,920 --> 00:43:36,480
you have a lot of

00:43:34,960 --> 00:43:40,319
queries that are the same and hitting

00:43:36,480 --> 00:43:43,280
the same note time and time again

00:43:40,319 --> 00:43:45,119
and as i mentioned a bloom filter um it

00:43:43,280 --> 00:43:49,119
is essentially a data structure

00:43:45,119 --> 00:43:51,520
that allows you to work out whether

00:43:49,119 --> 00:43:54,720
something may be in a given set and it

00:43:51,520 --> 00:43:56,319
does it in a very efficient manner

00:43:54,720 --> 00:43:58,160
cool so we kind of got to the end here i

00:43:56,319 --> 00:44:01,200
know i'm almost out of time

00:43:58,160 --> 00:44:02,800
i've got kind of like 20 seconds um i

00:44:01,200 --> 00:44:03,520
think the key takeaways there are a

00:44:02,800 --> 00:44:05,440
number

00:44:03,520 --> 00:44:07,200
from this particular talk around the

00:44:05,440 --> 00:44:09,920
technicalities

00:44:07,200 --> 00:44:11,200
but the main one is get an understanding

00:44:09,920 --> 00:44:12,480
of the way that cassandra works under

00:44:11,200 --> 00:44:14,319
the hood it is a

00:44:12,480 --> 00:44:16,079
database that requires a good degree of

00:44:14,319 --> 00:44:18,480
mechanical sympathy

00:44:16,079 --> 00:44:20,000
um but once you kind of understand that

00:44:18,480 --> 00:44:20,319
you can build your data model around

00:44:20,000 --> 00:44:22,240
that

00:44:20,319 --> 00:44:23,839
um you kind of have this rock solid

00:44:22,240 --> 00:44:26,000
bulletproof scalable

00:44:23,839 --> 00:44:27,359
database um you know that can kind of

00:44:26,000 --> 00:44:30,560
take you from

00:44:27,359 --> 00:44:32,880
10 nodes all the way to a thousand so

00:44:30,560 --> 00:44:34,240
thank you all very much um for for

00:44:32,880 --> 00:44:35,440
coming today um it's been really

00:44:34,240 --> 00:44:44,160
wonderful to answer some of those

00:44:35,440 --> 00:44:44,160

YouTube URL: https://www.youtube.com/watch?v=0mntwB6nbc0


