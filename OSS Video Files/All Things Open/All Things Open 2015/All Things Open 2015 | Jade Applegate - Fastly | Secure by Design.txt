Title: All Things Open 2015 | Jade Applegate - Fastly | Secure by Design
Publication date: 2015-11-19
Playlist: All Things Open 2015
Description: 
	All Things Open 2015, October 19th and 20th, Raleigh NC.
Captions: 
	00:00:04,040 --> 00:00:11,040
um let's get started and thanks for

00:00:08,069 --> 00:00:12,300
bearing with me today I'd like to talk

00:00:11,040 --> 00:00:15,420
to you about the intersection of

00:00:12,300 --> 00:00:17,520
security and design and ways to help

00:00:15,420 --> 00:00:19,380
users make better choices and make

00:00:17,520 --> 00:00:24,240
better decisions in terms of staying

00:00:19,380 --> 00:00:26,699
safe online so I'm Jade Applegate and

00:00:24,240 --> 00:00:28,800
I'm a user experience engineer this is

00:00:26,699 --> 00:00:30,929
my first time to raleigh and i live in

00:00:28,800 --> 00:00:33,630
the san francisco bay area for the last

00:00:30,929 --> 00:00:35,489
four years if you have questions for me

00:00:33,630 --> 00:00:38,809
during or after the presentation you can

00:00:35,489 --> 00:00:41,850
always tweet at me at jade applegate i

00:00:38,809 --> 00:00:44,879
work for a company called fastly where i

00:00:41,850 --> 00:00:47,039
am an engineer on the UX team and fastly

00:00:44,879 --> 00:00:49,020
is a real-time content delivery network

00:00:47,039 --> 00:00:51,719
where we serve dynamic and static

00:00:49,020 --> 00:00:55,559
content for companies like Pinterest

00:00:51,719 --> 00:00:57,870
imager github and many others so we are

00:00:55,559 --> 00:01:00,930
involved in and we support several open

00:00:57,870 --> 00:01:02,760
source projects and my team specifically

00:01:00,930 --> 00:01:05,250
is planning to release two more in the

00:01:02,760 --> 00:01:09,090
beginning of 2016 so it's pretty

00:01:05,250 --> 00:01:10,860
exciting for us in terms of as a place

00:01:09,090 --> 00:01:13,590
to work it's great we have four offices

00:01:10,860 --> 00:01:15,420
and all around the country and all

00:01:13,590 --> 00:01:18,830
around the world we have one in San

00:01:15,420 --> 00:01:20,670
Francisco New York London and Tokyo and

00:01:18,830 --> 00:01:23,430
please come find you if you'd like to

00:01:20,670 --> 00:01:25,830
learn more so with that out of the way

00:01:23,430 --> 00:01:30,450
my little spiel so they'll let me come

00:01:25,830 --> 00:01:33,090
here let's get started so user

00:01:30,450 --> 00:01:36,150
experience generally focuses on reducing

00:01:33,090 --> 00:01:38,369
friction for users that are on the happy

00:01:36,150 --> 00:01:40,829
path so typically these things are

00:01:38,369 --> 00:01:42,720
viewed as a conversion or acquisition

00:01:40,829 --> 00:01:45,990
funnel and we're all pretty familiar

00:01:42,720 --> 00:01:48,299
with this type of cycle as an example if

00:01:45,990 --> 00:01:51,720
you have a shopping website you would

00:01:48,299 --> 00:01:54,000
want a customer to create an account put

00:01:51,720 --> 00:01:56,700
something into their cart complete that

00:01:54,000 --> 00:01:58,890
checkout process and even perhaps return

00:01:56,700 --> 00:02:01,979
again in the future to make another

00:01:58,890 --> 00:02:04,140
purchase your site would be optimized

00:02:01,979 --> 00:02:06,299
for this flow for the shopping flow

00:02:04,140 --> 00:02:09,450
because that's how your business works

00:02:06,299 --> 00:02:11,280
and that's how you make money and what

00:02:09,450 --> 00:02:12,780
I'd like to talk today instead is

00:02:11,280 --> 00:02:14,970
putting the emphasis

00:02:12,780 --> 00:02:17,100
on designing and planning the user

00:02:14,970 --> 00:02:19,410
experience for destructive actions on

00:02:17,100 --> 00:02:21,930
your site like deleting an item from

00:02:19,410 --> 00:02:25,819
your shopping cart or canceling an order

00:02:21,930 --> 00:02:28,650
or deleting someone's entire account

00:02:25,819 --> 00:02:30,540
typically these so-called destructive

00:02:28,650 --> 00:02:33,000
actions and warnings are less thought

00:02:30,540 --> 00:02:35,100
through because they don't contribute to

00:02:33,000 --> 00:02:38,580
that happy path of customer acquisition

00:02:35,100 --> 00:02:39,900
or revenue but in some cases they're

00:02:38,580 --> 00:02:42,390
just as important for the user

00:02:39,900 --> 00:02:45,090
experience especially when the topic of

00:02:42,390 --> 00:02:46,830
security is involved so today let's skip

00:02:45,090 --> 00:02:49,290
the happy path and talk about the

00:02:46,830 --> 00:02:51,570
opposite which is adding friction to the

00:02:49,290 --> 00:02:54,120
user experience and we'll talk about

00:02:51,570 --> 00:02:56,130
where that makes sense to do so and I'll

00:02:54,120 --> 00:02:59,250
introduce you to some relevant security

00:02:56,130 --> 00:03:03,900
related research as well as some UX

00:02:59,250 --> 00:03:05,400
guidelines worth paying attention to so

00:03:03,900 --> 00:03:07,590
user experience should typically be

00:03:05,400 --> 00:03:09,810
frictionless until it isn't so what does

00:03:07,590 --> 00:03:12,569
that really mean here are a few examples

00:03:09,810 --> 00:03:14,370
that will go through best practices when

00:03:12,569 --> 00:03:17,370
it comes to designing destructive

00:03:14,370 --> 00:03:20,100
actions in your applications this is

00:03:17,370 --> 00:03:22,680
where designers took time and empathize

00:03:20,100 --> 00:03:25,709
with users and made it easier for them

00:03:22,680 --> 00:03:27,720
to navigate this type of transition they

00:03:25,709 --> 00:03:30,360
purposely put in some sort of roadblock

00:03:27,720 --> 00:03:32,850
roadblock to confirm and bring awareness

00:03:30,360 --> 00:03:34,560
to the action they're about to make even

00:03:32,850 --> 00:03:36,750
though it's not part of the happy path

00:03:34,560 --> 00:03:39,720
that we talked about so these are all

00:03:36,750 --> 00:03:41,400
what I like to refer to as the are you

00:03:39,720 --> 00:03:45,049
sure because there's no turning back

00:03:41,400 --> 00:03:47,760
after this action so let's take a look

00:03:45,049 --> 00:03:49,950
this first example is from Google's

00:03:47,760 --> 00:03:51,329
design specs and it's regarding the

00:03:49,950 --> 00:03:53,549
language that you use when you're

00:03:51,329 --> 00:03:56,220
discarding a draft and as you can see

00:03:53,549 --> 00:03:58,170
it's important that you not use yes or

00:03:56,220 --> 00:04:01,109
no because those are pretty ambiguous

00:03:58,170 --> 00:04:03,480
and you should instead use some sort of

00:04:01,109 --> 00:04:05,670
explicit language to help the user focus

00:04:03,480 --> 00:04:08,280
on the outcome of what will happen after

00:04:05,670 --> 00:04:10,739
they make this decision so this helps

00:04:08,280 --> 00:04:12,959
eliminate any confusion and it makes it

00:04:10,739 --> 00:04:16,979
easier for the user to understand what

00:04:12,959 --> 00:04:19,560
will what exactly will happen next the

00:04:16,979 --> 00:04:21,539
second example comes from the fast lap

00:04:19,560 --> 00:04:23,950
that I'm currently working on that's in

00:04:21,539 --> 00:04:26,380
private beta where we are

00:04:23,950 --> 00:04:28,840
designing our website so we pop up a

00:04:26,380 --> 00:04:31,540
modal confirmation with a delete action

00:04:28,840 --> 00:04:33,910
and the name of the item you're about to

00:04:31,540 --> 00:04:36,700
delete and sometimes it makes sense to

00:04:33,910 --> 00:04:38,230
double check with your users before they

00:04:36,700 --> 00:04:40,570
complete that sort of deleting or

00:04:38,230 --> 00:04:42,550
destructive action and you'll want to

00:04:40,570 --> 00:04:45,820
note here that the button says confirm

00:04:42,550 --> 00:04:47,590
and delete rather than yes and cancel

00:04:45,820 --> 00:04:49,090
instead of no based on what we learned

00:04:47,590 --> 00:04:52,780
in the previous slide about being

00:04:49,090 --> 00:04:54,970
specific so this third example is from

00:04:52,780 --> 00:04:57,730
github it's one of my favorites it's

00:04:54,970 --> 00:05:00,100
when you're in the danger zone so it's

00:04:57,730 --> 00:05:03,130
important to alert users when they're in

00:05:00,100 --> 00:05:05,590
a place that their changes will have

00:05:03,130 --> 00:05:07,510
some real consequences and sometimes

00:05:05,590 --> 00:05:09,850
these consequences you can't go back

00:05:07,510 --> 00:05:11,770
from since the stakes here are so high

00:05:09,850 --> 00:05:14,680
like when you're deleting a repository

00:05:11,770 --> 00:05:17,080
for example we even have to type in the

00:05:14,680 --> 00:05:19,360
name of the repository in order to

00:05:17,080 --> 00:05:21,010
proceed with the delete and this makes

00:05:19,360 --> 00:05:23,230
the user actively engage in the

00:05:21,010 --> 00:05:24,700
experience and has less of a margin for

00:05:23,230 --> 00:05:27,880
error since there's so much involved in

00:05:24,700 --> 00:05:30,550
that process so these are a few examples

00:05:27,880 --> 00:05:32,710
of adding friction to the user

00:05:30,550 --> 00:05:34,690
experience and I know they're small but

00:05:32,710 --> 00:05:37,900
I wanted to point them out as good

00:05:34,690 --> 00:05:39,910
design and good implementation in order

00:05:37,900 --> 00:05:42,520
to help users make better choices online

00:05:39,910 --> 00:05:45,100
a lot of the times users can be on

00:05:42,520 --> 00:05:48,460
autopilot I'm sure we can all feel what

00:05:45,100 --> 00:05:50,950
that's like and it's especially useful

00:05:48,460 --> 00:05:53,200
to do this when someone's on a site they

00:05:50,950 --> 00:05:55,390
use frequently because they're so

00:05:53,200 --> 00:05:57,280
familiar with what they're doing so they

00:05:55,390 --> 00:05:58,750
can be distracted and not realize the

00:05:57,280 --> 00:06:02,380
repercussions of just clicking a button

00:05:58,750 --> 00:06:04,270
for example so that's why even those

00:06:02,380 --> 00:06:06,490
these are not the happy path actions

00:06:04,270 --> 00:06:08,320
that we talked about it's important to

00:06:06,490 --> 00:06:10,150
purposely add friction to your

00:06:08,320 --> 00:06:12,070
application so you can snap someone out

00:06:10,150 --> 00:06:14,680
of it before they do something they

00:06:12,070 --> 00:06:16,780
didn't intend to so by putting yourself

00:06:14,680 --> 00:06:19,420
in their shoes and understanding what

00:06:16,780 --> 00:06:22,180
they'll go through you can empathize and

00:06:19,420 --> 00:06:26,200
design and implement a better flow so

00:06:22,180 --> 00:06:29,710
let's take a bit of a deeper dive into a

00:06:26,200 --> 00:06:33,130
few case studies where they share some

00:06:29,710 --> 00:06:34,750
of the same principles so one thing that

00:06:33,130 --> 00:06:37,330
really intrigues me within the world of

00:06:34,750 --> 00:06:37,930
user experience design is that seemingly

00:06:37,330 --> 00:06:39,639
small

00:06:37,930 --> 00:06:42,100
provements can have a big payoff and

00:06:39,639 --> 00:06:45,310
there are two really fantastic studies

00:06:42,100 --> 00:06:47,650
done by researchers at Google that I'd

00:06:45,310 --> 00:06:49,960
like to share with you today and these

00:06:47,650 --> 00:06:52,030
both focus on improving browser warnings

00:06:49,960 --> 00:06:59,080
using user experience and design

00:06:52,030 --> 00:07:01,270
principles let me grab a water so as we

00:06:59,080 --> 00:07:04,270
know browsers show an authentication

00:07:01,270 --> 00:07:07,449
warning or an SSL warning when the users

00:07:04,270 --> 00:07:10,810
information as that is at risk so this

00:07:07,449 --> 00:07:12,130
browser warning is an example of the

00:07:10,810 --> 00:07:14,650
importance of adding friction to the

00:07:12,130 --> 00:07:16,840
user experience so this first study

00:07:14,650 --> 00:07:19,270
which was entitled experimenting at

00:07:16,840 --> 00:07:21,820
scale with google chrome's SSL warning

00:07:19,270 --> 00:07:23,620
it was published last year and it

00:07:21,820 --> 00:07:25,720
focused on figuring out why use your

00:07:23,620 --> 00:07:29,289
behavior differ dramatically between

00:07:25,720 --> 00:07:33,190
chrome and firefox browsers when an SSL

00:07:29,289 --> 00:07:34,990
warning was shown so first this study is

00:07:33,190 --> 00:07:37,630
focused on the metric of a click-through

00:07:34,990 --> 00:07:40,389
rate so let's define that just so we're

00:07:37,630 --> 00:07:43,650
on the same page when the SSL warning

00:07:40,389 --> 00:07:46,360
appears users have two options one is to

00:07:43,650 --> 00:07:49,750
abandon their destination website and

00:07:46,360 --> 00:07:52,210
return to safety or two to consider the

00:07:49,750 --> 00:07:54,699
warning and then dismiss it and proceed

00:07:52,210 --> 00:07:57,220
to their intended destination so the

00:07:54,699 --> 00:07:59,949
percentage of times that a user selects

00:07:57,220 --> 00:08:02,020
that second option and proceeds despite

00:07:59,949 --> 00:08:04,180
the warning determines the click-through

00:08:02,020 --> 00:08:06,970
rate so typically a high click-through

00:08:04,180 --> 00:08:08,949
rate is a good thing if you're working

00:08:06,970 --> 00:08:11,889
on any other type of site but when it's

00:08:08,949 --> 00:08:14,770
in the case of ignoring the SSL warning

00:08:11,889 --> 00:08:17,650
it's not a good thing you may also be

00:08:14,770 --> 00:08:19,570
familiar with the term adherence in this

00:08:17,650 --> 00:08:21,070
case adherence to the warning is one

00:08:19,570 --> 00:08:22,720
hundred percent minus the click-through

00:08:21,070 --> 00:08:26,349
rate if you want to think about it like

00:08:22,720 --> 00:08:29,650
that so prior research showed that the

00:08:26,349 --> 00:08:32,770
mozilla firefox SSL warning had a much

00:08:29,650 --> 00:08:35,349
lower click through rate than chrome in

00:08:32,770 --> 00:08:37,599
fact in firefox the click-through rate

00:08:35,349 --> 00:08:39,880
was thirty-three percent whereas in

00:08:37,599 --> 00:08:43,419
chrome it with 70 so pretty significant

00:08:39,880 --> 00:08:45,490
the difference here because it was so

00:08:43,419 --> 00:08:47,470
significant they wanted to know why and

00:08:45,490 --> 00:08:49,630
how to improve their click-through rate

00:08:47,470 --> 00:08:51,329
in real or der to keep users safer

00:08:49,630 --> 00:08:54,310
online

00:08:51,329 --> 00:08:56,589
so the author's stated that their goal

00:08:54,310 --> 00:08:58,680
was to decrease the number of users who

00:08:56,589 --> 00:09:01,660
ignore the warnings in chrome and

00:08:58,680 --> 00:09:03,579
unfortunately users struggle to really

00:09:01,660 --> 00:09:06,060
understand and often disregard these

00:09:03,579 --> 00:09:08,379
types of warnings in this study they

00:09:06,060 --> 00:09:10,300
investigated several factors that could

00:09:08,379 --> 00:09:12,279
be responsible in that difference in

00:09:10,300 --> 00:09:14,500
click-through rate and we'll explore two

00:09:12,279 --> 00:09:17,860
of those today one is the use of imagery

00:09:14,500 --> 00:09:20,649
and to our style choices both seemingly

00:09:17,860 --> 00:09:23,949
small things so just to test these

00:09:20,649 --> 00:09:26,350
factors they ran six different SSL

00:09:23,949 --> 00:09:28,720
warnings in production and they were

00:09:26,350 --> 00:09:32,230
used in google chrome 29 and seen by

00:09:28,720 --> 00:09:34,959
about 130,000 people and these warnings

00:09:32,230 --> 00:09:37,509
were designed to test several hypotheses

00:09:34,959 --> 00:09:39,910
that the researchers had about how users

00:09:37,509 --> 00:09:44,199
might respond to different manipulations

00:09:39,910 --> 00:09:45,639
in the design as I mentioned the first

00:09:44,199 --> 00:09:48,160
factor that was tested was the use of

00:09:45,639 --> 00:09:51,129
images and their hypothesis was that

00:09:48,160 --> 00:09:53,949
since the brain's social response to

00:09:51,129 --> 00:09:56,139
human images is instinctive that by

00:09:53,949 --> 00:09:57,730
including the images that should suggest

00:09:56,139 --> 00:10:00,310
the feeling that they're being watched

00:09:57,730 --> 00:10:03,639
and thus click reduce the click-through

00:10:00,310 --> 00:10:05,860
rate however that didn't actually end up

00:10:03,639 --> 00:10:07,720
being the case at all it didn't have any

00:10:05,860 --> 00:10:09,699
change in the click-through rate even

00:10:07,720 --> 00:10:12,339
though they included these human faces

00:10:09,699 --> 00:10:14,759
like the policeman and the criminal and

00:10:12,339 --> 00:10:16,720
the red traffic light to indicate stop

00:10:14,759 --> 00:10:18,550
there was no difference in the

00:10:16,720 --> 00:10:20,250
click-through rate so let's look at the

00:10:18,550 --> 00:10:24,910
other factor which might be responsible

00:10:20,250 --> 00:10:26,589
which were the styling choices so in

00:10:24,910 --> 00:10:29,529
addition to testing slides with the

00:10:26,589 --> 00:10:32,079
images that we just saw the researchers

00:10:29,529 --> 00:10:34,149
also use three different styles so this

00:10:32,079 --> 00:10:36,069
first style tested was the existing

00:10:34,149 --> 00:10:38,230
google chrome warning this is what users

00:10:36,069 --> 00:10:40,779
would see and it says this is probably

00:10:38,230 --> 00:10:42,550
not the site you're looking for you

00:10:40,779 --> 00:10:44,589
should not proceed and that has two

00:10:42,550 --> 00:10:49,089
options that are equally weighted recede

00:10:44,589 --> 00:10:50,920
anyways or back to safety this is the

00:10:49,089 --> 00:10:53,170
second style they tested and it was a

00:10:50,920 --> 00:10:55,389
mock of the Firefox warning they took

00:10:53,170 --> 00:10:57,209
what was in Firefox they copied it over

00:10:55,389 --> 00:11:00,130
and it says this connection is untrusted

00:10:57,209 --> 00:11:04,450
what should I do I understand

00:11:00,130 --> 00:11:08,110
risks get or get me out of here and the

00:11:04,450 --> 00:11:10,360
third style tested was the content of

00:11:08,110 --> 00:11:13,360
the Firefox warning Plus Google Chrome

00:11:10,360 --> 00:11:15,910
styling and so it says this connection

00:11:13,360 --> 00:11:17,560
is untrusted what should I do get me out

00:11:15,910 --> 00:11:20,740
of here has a little bit more of a

00:11:17,560 --> 00:11:22,780
Google look and feel and they thought

00:11:20,740 --> 00:11:26,500
that by applying corporate style

00:11:22,780 --> 00:11:29,350
guidelines to a warning since warnings

00:11:26,500 --> 00:11:31,090
typically resemble corporate products

00:11:29,350 --> 00:11:33,310
don't stand out as unusual that blue

00:11:31,090 --> 00:11:34,300
button doesn't seem unusual that it

00:11:33,310 --> 00:11:35,950
would actually increase the

00:11:34,300 --> 00:11:39,070
click-through rate and they might see

00:11:35,950 --> 00:11:41,560
something above seventy percent but what

00:11:39,070 --> 00:11:43,300
they saw was that no changes to the

00:11:41,560 --> 00:11:46,780
styling had any difference at all so

00:11:43,300 --> 00:11:50,050
styling doesn't work and images didn't

00:11:46,780 --> 00:11:51,700
work so we've ruled those both out so

00:11:50,050 --> 00:11:54,580
they're still looking at what makes this

00:11:51,700 --> 00:11:56,620
SSL warning so much more effective in

00:11:54,580 --> 00:11:59,620
Firefox and Chrome and remember it was

00:11:56,620 --> 00:12:01,660
thirty-three percent versus 70 so they

00:11:59,620 --> 00:12:03,940
thought and they looked at Firefox

00:12:01,660 --> 00:12:06,130
warning and they notice the warnings

00:12:03,940 --> 00:12:07,810
text and the layout and the default

00:12:06,130 --> 00:12:11,260
button choices were different so maybe

00:12:07,810 --> 00:12:13,990
they're responsible and they notice that

00:12:11,260 --> 00:12:16,480
the warning and Firefox avoided

00:12:13,990 --> 00:12:18,910
technical language it identified

00:12:16,480 --> 00:12:22,420
specific ways to mitigate the security

00:12:18,910 --> 00:12:26,110
risk and it hit the technical details by

00:12:22,420 --> 00:12:29,200
default giving only one default choice

00:12:26,110 --> 00:12:31,540
as an option so to be able to get all of

00:12:29,200 --> 00:12:33,550
these elements right is pretty

00:12:31,540 --> 00:12:36,730
complicated from a user experience

00:12:33,550 --> 00:12:38,950
design standpoint and the team was

00:12:36,730 --> 00:12:41,140
intrigued so they explore this in a

00:12:38,950 --> 00:12:45,250
subsequent study and this is where it

00:12:41,140 --> 00:12:46,960
gets fun as things start to happen so

00:12:45,250 --> 00:12:49,750
the follow-up study was called improving

00:12:46,960 --> 00:12:51,310
SSL warnings comprehension and adherence

00:12:49,750 --> 00:12:53,950
and it was published earlier this year

00:12:51,310 --> 00:12:56,500
and it focused on the warnings in chrome

00:12:53,950 --> 00:12:59,290
and they thought that they would just

00:12:56,500 --> 00:13:01,360
have a goal of improving comprehension

00:12:59,290 --> 00:13:04,270
maybe people aren't understanding the

00:13:01,360 --> 00:13:06,100
warnings that they're seeing and they

00:13:04,270 --> 00:13:07,450
thought that by improving comprehension

00:13:06,100 --> 00:13:09,310
the click-through rate would be lower

00:13:07,450 --> 00:13:11,379
and they might get closer to matching

00:13:09,310 --> 00:13:13,809
that of Firefox

00:13:11,379 --> 00:13:15,609
so their first goal was to help users

00:13:13,809 --> 00:13:18,069
understand the situation that they're in

00:13:15,609 --> 00:13:19,959
when they see this morning and if that

00:13:18,069 --> 00:13:23,369
wasn't possible to at least help guide

00:13:19,959 --> 00:13:28,449
them to safety and get them out of there

00:13:23,369 --> 00:13:30,129
so this was tested in chrome 36 and it

00:13:28,449 --> 00:13:32,229
was tested in a lab setting through

00:13:30,129 --> 00:13:35,829
different interviews and it involved

00:13:32,229 --> 00:13:37,509
about 7500 responses so the three topics

00:13:35,829 --> 00:13:40,449
that they looked at that will touch on

00:13:37,509 --> 00:13:42,849
our comprehension language and the topic

00:13:40,449 --> 00:13:47,319
of opinionated design which I think you

00:13:42,849 --> 00:13:49,269
will really like so the main goal of

00:13:47,319 --> 00:13:51,729
this study was to increase comprehension

00:13:49,269 --> 00:13:53,999
and to achieve that goal the ideal

00:13:51,729 --> 00:13:56,529
warning would convey these three things

00:13:53,999 --> 00:14:00,519
it would convey the source of the threat

00:13:56,529 --> 00:14:03,759
and let an in-form user know that they

00:14:00,519 --> 00:14:06,369
would not need to evaluate how benign or

00:14:03,759 --> 00:14:09,039
malicious the destination website was

00:14:06,369 --> 00:14:11,709
but they should instead realize that

00:14:09,039 --> 00:14:14,529
there's a maybe in a checker at some

00:14:11,709 --> 00:14:17,319
point between the users computer and the

00:14:14,529 --> 00:14:20,669
website server so they wanted to convey

00:14:17,319 --> 00:14:23,439
that succinctly the second thing was

00:14:20,669 --> 00:14:26,259
which information was at risk an

00:14:23,439 --> 00:14:28,149
informed user would consider the

00:14:26,259 --> 00:14:30,729
sensitivity of the data that they had

00:14:28,149 --> 00:14:32,289
ever entered on that website and not

00:14:30,729 --> 00:14:36,069
just the information that they might

00:14:32,289 --> 00:14:38,350
enter if they proceeded and thirdly the

00:14:36,069 --> 00:14:40,029
potential for false positives so when

00:14:38,350 --> 00:14:43,389
weighing the likelihood of a false

00:14:40,029 --> 00:14:45,909
positive the user would consider the

00:14:43,389 --> 00:14:47,769
websites reputation and whether or not

00:14:45,909 --> 00:14:52,379
they've gone to this website before and

00:14:47,769 --> 00:14:55,059
it works normally so now that we know

00:14:52,379 --> 00:14:56,409
what was needed to be understood let's

00:14:55,059 --> 00:14:58,659
talk about how they might go about

00:14:56,409 --> 00:15:01,539
understanding this so in general

00:14:58,659 --> 00:15:04,569
technical jargon you want to avoid it

00:15:01,539 --> 00:15:06,339
because when you're designing a good

00:15:04,569 --> 00:15:08,619
user experience it's pretty ineffective

00:15:06,339 --> 00:15:11,019
to include that very technical jargon

00:15:08,619 --> 00:15:13,389
given your audience so people are more

00:15:11,019 --> 00:15:15,879
likely to read beyond the first sentence

00:15:13,389 --> 00:15:18,699
of a warning if you use a simple

00:15:15,879 --> 00:15:20,649
language and advertisements and warnings

00:15:18,699 --> 00:15:23,350
that have really technical language in

00:15:20,649 --> 00:15:24,850
them usually hold less interest and are

00:15:23,350 --> 00:15:28,360
less likely to be remembered

00:15:24,850 --> 00:15:30,610
even obeyed so as a non-tech example if

00:15:28,360 --> 00:15:33,490
you are preparing to paint a room in

00:15:30,610 --> 00:15:36,490
your house people who are more likely to

00:15:33,490 --> 00:15:39,339
follow the simple instruction to open a

00:15:36,490 --> 00:15:41,980
window than to use the paint in a

00:15:39,339 --> 00:15:45,459
well-ventilated area just think about

00:15:41,980 --> 00:15:47,470
that for a second and since Firefox has

00:15:45,459 --> 00:15:50,019
less technical terms in their warning

00:15:47,470 --> 00:15:53,620
and chrome uses many technical terms

00:15:50,019 --> 00:15:56,949
like server operating system security

00:15:53,620 --> 00:16:00,699
certificate and trusted authority this

00:15:56,949 --> 00:16:03,250
can get very confusing so for these

00:16:00,699 --> 00:16:05,019
reasons the researchers decided that the

00:16:03,250 --> 00:16:06,910
language that they develop in the

00:16:05,019 --> 00:16:10,509
warning should follow three guidelines

00:16:06,910 --> 00:16:13,000
they wanted it to be brief large

00:16:10,509 --> 00:16:14,970
quantities of text that look like they

00:16:13,000 --> 00:16:18,579
will take a lot of effort to read

00:16:14,970 --> 00:16:21,940
generally people read none of it so a

00:16:18,579 --> 00:16:23,769
complication here is that they needed to

00:16:21,940 --> 00:16:26,290
explain this really complicated threat

00:16:23,769 --> 00:16:28,810
in a succinct manner but they figured

00:16:26,290 --> 00:16:30,880
that given the choice they'd rather the

00:16:28,810 --> 00:16:34,149
user read some of the texts rather than

00:16:30,880 --> 00:16:36,670
none the second thing is using an

00:16:34,149 --> 00:16:38,980
appropriate reading level so ideally

00:16:36,670 --> 00:16:41,050
language for a general audience needs to

00:16:38,980 --> 00:16:43,930
be at a 6th grade reading level so that

00:16:41,050 --> 00:16:46,509
everyone can understand it so by

00:16:43,930 --> 00:16:48,699
avoiding the technical jargon they need

00:16:46,509 --> 00:16:50,199
to be at the 6th grade reading level and

00:16:48,699 --> 00:16:53,740
the third thing that they needed to

00:16:50,199 --> 00:16:58,180
convey was the specific risks of their

00:16:53,740 --> 00:17:00,310
data so previous research has shown that

00:16:58,180 --> 00:17:03,670
people are more likely to comprehend

00:17:00,310 --> 00:17:06,490
with and comply with a warning if it

00:17:03,670 --> 00:17:09,789
describes specifically the risks that

00:17:06,490 --> 00:17:12,309
might happen so when possible it's best

00:17:09,789 --> 00:17:14,650
to describe all the data types that

00:17:12,309 --> 00:17:16,689
might be at risk like your password or

00:17:14,650 --> 00:17:19,209
your credit card information or the

00:17:16,689 --> 00:17:21,240
messages that you send rather than just

00:17:19,209 --> 00:17:25,569
saying your information might be at risk

00:17:21,240 --> 00:17:27,880
which makes sense so based on these

00:17:25,569 --> 00:17:31,799
comprehension and language guidelines

00:17:27,880 --> 00:17:33,850
this is the proposed warning on the Left

00:17:31,799 --> 00:17:35,950
compared with the warning that they were

00:17:33,850 --> 00:17:38,140
currently using and I'd like to read

00:17:35,950 --> 00:17:40,000
these to you so there

00:17:38,140 --> 00:17:42,490
as language says your connection is not

00:17:40,000 --> 00:17:44,940
private attackers might be trying to

00:17:42,490 --> 00:17:49,330
steal your information from facebook com

00:17:44,940 --> 00:17:51,400
for example passwords messages or credit

00:17:49,330 --> 00:17:54,280
cards and has the option to ignore the

00:17:51,400 --> 00:17:57,840
error and what they're currently using

00:17:54,280 --> 00:18:01,090
says your site this site's security

00:17:57,840 --> 00:18:03,340
certificate is not trusted you attempted

00:18:01,090 --> 00:18:05,620
to reach facebook com but the server

00:18:03,340 --> 00:18:07,960
presented a certificate issued by an

00:18:05,620 --> 00:18:10,810
entity that is not trusted by your

00:18:07,960 --> 00:18:12,670
computer's operating system this may

00:18:10,810 --> 00:18:15,940
mean that the server has generated its

00:18:12,670 --> 00:18:18,100
own security credentials okay which your

00:18:15,940 --> 00:18:20,740
browser cannot rely on for identity

00:18:18,100 --> 00:18:22,900
information or an attacker might be

00:18:20,740 --> 00:18:25,960
trying to intercept your communications

00:18:22,900 --> 00:18:27,520
you should not proceed especially if

00:18:25,960 --> 00:18:30,510
you've never seen this warning before

00:18:27,520 --> 00:18:33,250
and it gives you the option to ignore so

00:18:30,510 --> 00:18:34,930
which would be easier for someone to act

00:18:33,250 --> 00:18:37,660
on obviously the one that they spent all

00:18:34,930 --> 00:18:39,480
the research on so by applying the three

00:18:37,660 --> 00:18:41,800
language related terms of brevity

00:18:39,480 --> 00:18:43,930
reading level and describing the

00:18:41,800 --> 00:18:46,810
specific data risk it actually boils

00:18:43,930 --> 00:18:52,240
down to a pretty succinct one sentence

00:18:46,810 --> 00:18:54,370
message so now that the researchers had

00:18:52,240 --> 00:18:56,440
decided on what information the warning

00:18:54,370 --> 00:18:58,510
should contain the next step was

00:18:56,440 --> 00:19:03,070
determine how that information should

00:18:58,510 --> 00:19:05,560
look and here they introduce the concept

00:19:03,070 --> 00:19:08,560
of opinionated design which I love and

00:19:05,560 --> 00:19:10,960
it's the use of visual cues to promote a

00:19:08,560 --> 00:19:12,970
recommended course of action because

00:19:10,960 --> 00:19:15,790
simply providing information without

00:19:12,970 --> 00:19:19,960
clear instructions doesn't necessarily

00:19:15,790 --> 00:19:21,880
influence behavior for example you don't

00:19:19,960 --> 00:19:24,180
always choose a healthier food to eat

00:19:21,880 --> 00:19:26,710
because you've read the nutrition labels

00:19:24,180 --> 00:19:28,390
so there are two important concepts of

00:19:26,710 --> 00:19:30,660
opinionated design that I'd like to

00:19:28,390 --> 00:19:32,860
emphasize and I'll introduce you to both

00:19:30,660 --> 00:19:35,890
one is the concept of choice

00:19:32,860 --> 00:19:38,110
attractiveness the researchers wanted

00:19:35,890 --> 00:19:40,660
the safe choice to be more visually

00:19:38,110 --> 00:19:44,890
attractive they use that familiar bright

00:19:40,660 --> 00:19:47,200
blue primary action coloring so that

00:19:44,890 --> 00:19:50,230
users would associate that button as a

00:19:47,200 --> 00:19:53,380
default action so it's this button here

00:19:50,230 --> 00:19:57,010
back to safety and not know or cancel as

00:19:53,380 --> 00:19:59,470
we talked about before and the other

00:19:57,010 --> 00:20:02,230
important concept is choice visibility

00:19:59,470 --> 00:20:04,540
so it's where the unsaved choice to

00:20:02,230 --> 00:20:07,179
proceed or the unsafe choice to proceed

00:20:04,540 --> 00:20:09,580
given how technical you are it's hidden

00:20:07,179 --> 00:20:11,919
behind this advanced link and when you

00:20:09,580 --> 00:20:14,590
click on that link you can see this

00:20:11,919 --> 00:20:16,960
extra information here and there's a

00:20:14,590 --> 00:20:19,179
link that says okay proceed to this

00:20:16,960 --> 00:20:23,010
website and it says unsafe next to it

00:20:19,179 --> 00:20:26,260
but it does give you the option and by

00:20:23,010 --> 00:20:28,900
having this hidden choice requires some

00:20:26,260 --> 00:20:30,730
effort to get to the researchers believe

00:20:28,900 --> 00:20:33,100
that in doing so they would view it as

00:20:30,730 --> 00:20:35,500
not recommended also the fact that it

00:20:33,100 --> 00:20:38,020
says unsafe next to it but there are a

00:20:35,500 --> 00:20:40,510
few downsides here one is that there's

00:20:38,020 --> 00:20:42,250
an increased amount of effort to ignore

00:20:40,510 --> 00:20:44,049
a false positive if you're going to your

00:20:42,250 --> 00:20:45,610
banking website and you're used to

00:20:44,049 --> 00:20:47,110
seeing this information you have to go

00:20:45,610 --> 00:20:49,720
through and click that every time in

00:20:47,110 --> 00:20:51,970
order to proceed and the second downside

00:20:49,720 --> 00:20:54,429
is that users may not even realize

00:20:51,970 --> 00:20:56,620
there's another choice other than back

00:20:54,429 --> 00:21:01,240
to safety if they don't explore that

00:20:56,620 --> 00:21:03,309
advanced configuration so let's look at

00:21:01,240 --> 00:21:05,860
this final SSL warning that did they

00:21:03,309 --> 00:21:08,110
designed and as a result of optimizing

00:21:05,860 --> 00:21:10,150
for language comprehension and applying

00:21:08,110 --> 00:21:12,730
the new styling that we talked about and

00:21:10,150 --> 00:21:15,160
using the opinionated design principles

00:21:12,730 --> 00:21:18,130
this is the proposed design that was

00:21:15,160 --> 00:21:21,250
released as the new google SSL warning

00:21:18,130 --> 00:21:23,679
in chrome 37 and with this new design

00:21:21,250 --> 00:21:26,530
the click-through rate went from seventy

00:21:23,679 --> 00:21:29,530
percent to forty two percent bringing it

00:21:26,530 --> 00:21:32,320
pretty pretty close to the firefox rate

00:21:29,530 --> 00:21:33,790
of thirty three percent so this with

00:21:32,320 --> 00:21:35,860
this really meant was that there were

00:21:33,790 --> 00:21:38,290
millions of additional users per month

00:21:35,860 --> 00:21:40,360
that were choosing to act safely due to

00:21:38,290 --> 00:21:42,730
this warning design change and these

00:21:40,360 --> 00:21:45,010
changes might seem small when you parcel

00:21:42,730 --> 00:21:49,120
them out but they had a huge impact in

00:21:45,010 --> 00:21:50,799
terms of user security so what is the

00:21:49,120 --> 00:21:53,350
purpose of all of this and why should it

00:21:50,799 --> 00:21:55,750
matter to you first you might not think

00:21:53,350 --> 00:21:57,730
to optimize something like this by

00:21:55,750 --> 00:22:00,820
default because so much of the time

00:21:57,730 --> 00:22:03,420
we're focused on the happy path but as

00:22:00,820 --> 00:22:06,120
we've seen making these small changes

00:22:03,420 --> 00:22:08,760
to something like a browser warning can

00:22:06,120 --> 00:22:11,370
have a huge security impact in the

00:22:08,760 --> 00:22:12,930
millions of millions of users but

00:22:11,370 --> 00:22:15,330
looking back to the examples we looked

00:22:12,930 --> 00:22:16,860
at at the beginning of the talk you

00:22:15,330 --> 00:22:19,260
don't even need an entire research

00:22:16,860 --> 00:22:22,280
teamed or to have millions of users to

00:22:19,260 --> 00:22:25,170
verify your results these techniques are

00:22:22,280 --> 00:22:28,440
applicable to you even in on a smaller

00:22:25,170 --> 00:22:31,320
scale and even the most basic JavaScript

00:22:28,440 --> 00:22:34,050
alert that says are you sure before you

00:22:31,320 --> 00:22:36,210
cancel or delete something is better

00:22:34,050 --> 00:22:40,590
than adding no friction at all to your

00:22:36,210 --> 00:22:42,720
user experience so secondly this matters

00:22:40,590 --> 00:22:45,870
or this might matter to you or your team

00:22:42,720 --> 00:22:49,350
or your company be because applying this

00:22:45,870 --> 00:22:52,470
type of friction to UX where it makes

00:22:49,350 --> 00:22:55,250
sense to do so has a lot of upsides it

00:22:52,470 --> 00:22:58,530
results in less support requests because

00:22:55,250 --> 00:23:00,230
you've optimized certain edge cases you

00:22:58,530 --> 00:23:04,350
hadn't thought about before and it

00:23:00,230 --> 00:23:06,300
reduces user errors it also provides a

00:23:04,350 --> 00:23:07,950
better user experience regardless of

00:23:06,300 --> 00:23:10,380
whether or not that user is contributing

00:23:07,950 --> 00:23:13,260
to your conversion funnel or your bottom

00:23:10,380 --> 00:23:16,470
line and finally it gives the user

00:23:13,260 --> 00:23:21,120
control over specific actions and innate

00:23:16,470 --> 00:23:23,010
and it enables and empowers them think

00:23:21,120 --> 00:23:25,380
back to the danger zone from the github

00:23:23,010 --> 00:23:27,030
example I mean how badass do you feel

00:23:25,380 --> 00:23:29,880
when you're in the danger zone and you

00:23:27,030 --> 00:23:31,410
have that control if you've optimized

00:23:29,880 --> 00:23:33,780
for comprehension when you're designing

00:23:31,410 --> 00:23:35,640
these things you're more comfortable

00:23:33,780 --> 00:23:37,680
giving the user control because you're

00:23:35,640 --> 00:23:40,470
confident in their understanding of

00:23:37,680 --> 00:23:42,720
what's happening I mean imagine emailing

00:23:40,470 --> 00:23:45,060
github every time you wanted to delete a

00:23:42,720 --> 00:23:49,560
repository that wouldn't make any sense

00:23:45,060 --> 00:23:52,110
and by doing that and giving some

00:23:49,560 --> 00:23:55,950
control to your users it can take some

00:23:52,110 --> 00:23:58,710
manual work off of your team and these

00:23:55,950 --> 00:24:01,110
changes can be done in a confident way

00:23:58,710 --> 00:24:03,480
by a user rather than having to rely on

00:24:01,110 --> 00:24:05,700
an internal or ad hoc process every time

00:24:03,480 --> 00:24:08,730
something needs to happen that's a

00:24:05,700 --> 00:24:10,560
little too scary to give away so I hope

00:24:08,730 --> 00:24:12,660
that you'll find some of these topics

00:24:10,560 --> 00:24:15,750
interesting and you might use some

00:24:12,660 --> 00:24:16,570
friction in your next project where it

00:24:15,750 --> 00:24:18,730
makes sense

00:24:16,570 --> 00:24:20,529
and thank you for being such a great

00:24:18,730 --> 00:24:23,769
audience and I'm happy to take any

00:24:20,529 --> 00:24:26,320
questions that you have if there are any

00:24:23,769 --> 00:24:29,380
you can also find me after this or

00:24:26,320 --> 00:24:31,630
online at Jade applegate I put my slides

00:24:29,380 --> 00:24:34,269
and other resources including the two

00:24:31,630 --> 00:24:37,179
research papers we went over up online

00:24:34,269 --> 00:24:41,370
on my github account so you can have fun

00:24:37,179 --> 00:24:41,370
reading those on your own thank you

00:24:45,720 --> 00:24:53,559
question time I saw a lot of you taking

00:24:49,720 --> 00:24:56,820
notes so I'm happy to take any questions

00:24:53,559 --> 00:24:56,820
now if there are any

00:25:08,920 --> 00:25:15,380
well one thing I love like in gmail is

00:25:11,870 --> 00:25:18,290
that when you hit Send on an email you

00:25:15,380 --> 00:25:20,630
can you have 30 seconds to undo and it's

00:25:18,290 --> 00:25:22,310
like a nervous person I'm always like oh

00:25:20,630 --> 00:25:25,520
maybe I want to undo it I mean that

00:25:22,310 --> 00:25:28,010
option is nice but that also delays your

00:25:25,520 --> 00:25:31,670
message by 30 seconds so you may want to

00:25:28,010 --> 00:25:33,440
kind of like way those options it

00:25:31,670 --> 00:25:36,410
depends on like how you're deleting

00:25:33,440 --> 00:25:40,010
things from your database maybe you know

00:25:36,410 --> 00:25:42,320
if it's gone it's gone sometimes it just

00:25:40,010 --> 00:25:43,400
gets hidden so things like that it's

00:25:42,320 --> 00:25:46,400
going to have to weigh the consequences

00:25:43,400 --> 00:25:50,750
of holding on to that information and

00:25:46,400 --> 00:25:56,930
how long you would want to do that yeah

00:25:50,750 --> 00:26:08,060
absolutely anyone else sure and I'll get

00:25:56,930 --> 00:26:13,700
you high oh why was it forty two percent

00:26:08,060 --> 00:26:21,830
and 33 um be happy with what you get um

00:26:13,700 --> 00:26:24,710
no I think yeah they really wanted to

00:26:21,830 --> 00:26:27,230
match that thirty-three percent in and

00:26:24,710 --> 00:26:29,930
they couldn't and so it really just

00:26:27,230 --> 00:26:32,480
warrants more research it's none of the

00:26:29,930 --> 00:26:34,550
things that they explored I mean if you

00:26:32,480 --> 00:26:36,260
remember that first study had no impact

00:26:34,550 --> 00:26:39,110
at all and what they did so they said

00:26:36,260 --> 00:26:43,490
that that nine percent or so must be

00:26:39,110 --> 00:26:44,900
related to other factors but if you want

00:26:43,490 --> 00:26:47,210
to have a really great time I would

00:26:44,900 --> 00:26:48,980
recommend reading the 17 page paper and

00:26:47,210 --> 00:26:51,560
they really get into like all the

00:26:48,980 --> 00:26:53,810
reasons why or things they might test in

00:26:51,560 --> 00:26:57,620
the future in future studies but they

00:26:53,810 --> 00:27:01,270
were just so happy with 72 42 that it

00:26:57,620 --> 00:27:01,270
was so significant of a change

00:27:05,740 --> 00:27:10,700
absolutely he said that the user base

00:27:09,050 --> 00:27:12,350
did they consider that it might be

00:27:10,700 --> 00:27:14,330
different and that absolutely could be

00:27:12,350 --> 00:27:18,230
the case they could have less technical

00:27:14,330 --> 00:27:20,090
people using one browser versus the

00:27:18,230 --> 00:27:22,310
other I mean there are Chromebooks that

00:27:20,090 --> 00:27:24,230
are really easy to get and they're cheap

00:27:22,310 --> 00:27:25,370
and you know I parents have one and I

00:27:24,230 --> 00:27:27,560
don't think they really even know how to

00:27:25,370 --> 00:27:29,030
use a computer that well so you know you

00:27:27,560 --> 00:27:32,050
might want to like consider your user

00:27:29,030 --> 00:27:33,920
base in terms of what you're

00:27:32,050 --> 00:27:46,870
investigating that's a really great

00:27:33,920 --> 00:27:46,870
point yep right there user development

00:27:47,350 --> 00:27:52,610
yep so I when they went to particular

00:27:49,940 --> 00:27:55,820
stock yeah ok now the page looks

00:27:52,610 --> 00:27:59,150
different but I'm motivated to keep

00:27:55,820 --> 00:28:00,800
clicking through yeah whatever yep and

00:27:59,150 --> 00:28:03,350
if you'll remember like the difference

00:28:00,800 --> 00:28:05,660
in the message was so significant they

00:28:03,350 --> 00:28:07,670
probably just ignored that forever that

00:28:05,660 --> 00:28:09,140
big long paragraph about certificate

00:28:07,670 --> 00:28:12,860
authority that doesn't really make sense

00:28:09,140 --> 00:28:16,610
unless you're like really well versed in

00:28:12,860 --> 00:28:18,350
that so they probably have become

00:28:16,610 --> 00:28:20,300
accustomed to just ignoring so there

00:28:18,350 --> 00:28:23,210
might be a section of their user base

00:28:20,300 --> 00:28:25,070
that still kept going through despite

00:28:23,210 --> 00:28:27,830
the changes that's also a great point I

00:28:25,070 --> 00:28:30,080
mean that's why it's always have a good

00:28:27,830 --> 00:28:35,410
certificate on you're absolutely right

00:28:30,080 --> 00:28:35,410
knee users to do the wrong thing yes

00:28:36,030 --> 00:28:41,290
yeah people are really get accustomed to

00:28:38,950 --> 00:28:44,490
the flow that they're working with so

00:28:41,290 --> 00:28:47,230
sometimes even if the design is better

00:28:44,490 --> 00:28:51,040
they will prefer the old design because

00:28:47,230 --> 00:28:54,480
at least they knew how to use that did

00:28:51,040 --> 00:28:57,480
you have a question just stretching okay

00:28:54,480 --> 00:28:57,480
okay

00:29:01,770 --> 00:29:10,140
they were published in a journal I can't

00:29:06,630 --> 00:29:14,100
remember which one but they are linked

00:29:10,140 --> 00:29:16,470
on the github to PDFs of those so you

00:29:14,100 --> 00:29:19,140
can read them for free I think it was

00:29:16,470 --> 00:29:21,840
like a CM or some journal I can't

00:29:19,140 --> 00:29:24,270
remember I had a hard time actually

00:29:21,840 --> 00:29:26,070
tracking them down when they weren't

00:29:24,270 --> 00:29:28,890
just like the abstract behind a firewall

00:29:26,070 --> 00:29:31,020
actually so the PDFs are there so you

00:29:28,890 --> 00:29:32,400
don't have to hunt them down but I know

00:29:31,020 --> 00:29:33,930
that they were published in a couple

00:29:32,400 --> 00:29:41,850
places and then they gave talks about

00:29:33,930 --> 00:29:46,050
them yes absolutely they would have put

00:29:41,850 --> 00:29:47,820
them on their own website as well okay

00:29:46,050 --> 00:29:49,890
thank you guys so much i was really

00:29:47,820 --> 00:29:52,340
wonderful and thanks for all the great

00:29:49,890 --> 00:29:52,340

YouTube URL: https://www.youtube.com/watch?v=1s_yPSExvrU


