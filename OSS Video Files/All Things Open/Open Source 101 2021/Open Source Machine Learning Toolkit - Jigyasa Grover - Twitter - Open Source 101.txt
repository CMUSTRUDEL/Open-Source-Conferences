Title: Open Source Machine Learning Toolkit - Jigyasa Grover - Twitter - Open Source 101
Publication date: 2021-04-10
Playlist: Open Source 101 2021
Description: 
	Jigyasa Grover, Machine Learning Engineer at Twitter, delivered the talk "Open Source Machine Learning Toolkit" at Open Source 101 on Tuesday, March 30, 2021.

Abstract:
The last couple of years have seen a rapid bloom and dominance of Machine Learning in multiple domains. Needless to say, the Open Source environment has assisted this immense growth by dispensing up-to-date tools. There is a vast variety of Open Source ML frameworks and libraries available for us to ply, but it is valuable that we focus on our experience depth-wise. So letâ€™s discuss some essential ones which will help us excel in this field of Machine Learning and Data Science.

Jigyasa on the internets:
Twitter: https://twitter.com/jigyasa_grover
Instagram: https://www.instagram.com/jigyasa.grover/
GitHub: https://jigyasa-grover.github.io/
Personal Website: https://jigyasa-grover.github.io/
Captions: 
	00:00:04,400 --> 00:00:07,359
hey everyone um

00:00:05,600 --> 00:00:08,880
thank you so much uh for the kind

00:00:07,359 --> 00:00:11,519
introduction uh

00:00:08,880 --> 00:00:12,559
and i work as a machine learning

00:00:11,519 --> 00:00:14,160
engineer at vida

00:00:12,559 --> 00:00:16,560
um i've been associated with open source

00:00:14,160 --> 00:00:18,720
101 for quite some while

00:00:16,560 --> 00:00:20,480
um it's been always like a pleasure to

00:00:18,720 --> 00:00:23,199
come and talk to you folks

00:00:20,480 --> 00:00:25,439
um i recently wrote a book which is

00:00:23,199 --> 00:00:27,840
known as sculpting data for ml

00:00:25,439 --> 00:00:29,039
and uh let's begin today we'll discuss

00:00:27,840 --> 00:00:30,880
about some tools

00:00:29,039 --> 00:00:32,800
or toolkit you might need for you know

00:00:30,880 --> 00:00:34,320
open source or

00:00:32,800 --> 00:00:35,840
like open source tools for machine

00:00:34,320 --> 00:00:38,160
learning

00:00:35,840 --> 00:00:39,920
um so the last couple of years have seen

00:00:38,160 --> 00:00:41,520
an immense growth of machine learning in

00:00:39,920 --> 00:00:44,000
multiple domains

00:00:41,520 --> 00:00:45,520
from influencing our shopping lists to

00:00:44,000 --> 00:00:48,079
cars self-driving

00:00:45,520 --> 00:00:50,160
themselves on the town unquestionably

00:00:48,079 --> 00:00:51,920
machine learning is the most used and

00:00:50,160 --> 00:00:54,239
abused sub-domain of artificial

00:00:51,920 --> 00:00:56,320
intelligence presently

00:00:54,239 --> 00:00:58,239
it is being wielded improving healthcare

00:00:56,320 --> 00:00:59,039
advanced warfare scrutinizing your

00:00:58,239 --> 00:01:02,719
resume

00:00:59,039 --> 00:01:04,640
to determining your credit worthiness um

00:01:02,719 --> 00:01:06,560
it also helps in like you know creative

00:01:04,640 --> 00:01:08,720
aspects like creating music and

00:01:06,560 --> 00:01:10,799
meaningful lyrics to even synthesizing

00:01:08,720 --> 00:01:12,960
pictures and videos of non-existent

00:01:10,799 --> 00:01:14,799
people and so on so it's kind of like

00:01:12,960 --> 00:01:17,040
everywhere and regardless of our

00:01:14,799 --> 00:01:18,880
fascination or lot of it

00:01:17,040 --> 00:01:20,799
it is influencing our decision-making

00:01:18,880 --> 00:01:22,720
powers and is dominating our lives

00:01:20,799 --> 00:01:26,560
heavily

00:01:22,720 --> 00:01:28,400
um to describe um like for someone who

00:01:26,560 --> 00:01:30,880
needs like a brief introduction

00:01:28,400 --> 00:01:32,320
machine learning would encompass um

00:01:30,880 --> 00:01:35,200
enabling computers to learn

00:01:32,320 --> 00:01:37,759
on their own and this power of spotting

00:01:35,200 --> 00:01:39,360
patterns on their own in like big data

00:01:37,759 --> 00:01:41,040
without the requirement of actually

00:01:39,360 --> 00:01:41,840
programming each and every rule is the

00:01:41,040 --> 00:01:44,079
biggest edge

00:01:41,840 --> 00:01:45,520
these decision-making systems have over

00:01:44,079 --> 00:01:47,600
the others

00:01:45,520 --> 00:01:49,200
researchers keep traversing unexplored

00:01:47,600 --> 00:01:51,759
territories of machine learning

00:01:49,200 --> 00:01:53,520
whereas according to experts the

00:01:51,759 --> 00:01:56,320
businesses have just seen the tip of the

00:01:53,520 --> 00:02:00,079
algorithmic iceberg

00:01:56,320 --> 00:02:01,119
um according to finances online 28.5 us

00:02:00,079 --> 00:02:03,119
billion dollars

00:02:01,119 --> 00:02:04,880
um were allocated to machine learning

00:02:03,119 --> 00:02:06,399
worldwide in just the first quarter of

00:02:04,880 --> 00:02:08,959
2019 which was like

00:02:06,399 --> 00:02:11,039
almost two years back and it's expected

00:02:08,959 --> 00:02:12,480
to grow 40 billion us dollars by the end

00:02:11,039 --> 00:02:14,400
of 2025

00:02:12,480 --> 00:02:17,200
uh where it just started from a meager

00:02:14,400 --> 00:02:19,760
1.3 billion us dollars in 2019.

00:02:17,200 --> 00:02:20,560
so the growth has been exponential uh

00:02:19,760 --> 00:02:22,400
even in

00:02:20,560 --> 00:02:24,319
the number of companies almost 50

00:02:22,400 --> 00:02:26,239
percent of the companies worldwide

00:02:24,319 --> 00:02:27,599
have either been exploring or planning

00:02:26,239 --> 00:02:28,080
to do machine learning in the near

00:02:27,599 --> 00:02:30,800
future

00:02:28,080 --> 00:02:32,400
so definitely it's a good skill to have

00:02:30,800 --> 00:02:33,599
even the number of startups small

00:02:32,400 --> 00:02:35,280
startups uh

00:02:33,599 --> 00:02:38,160
focusing on pure machine learning

00:02:35,280 --> 00:02:39,280
services are having like a 14 times rate

00:02:38,160 --> 00:02:43,040
of increase

00:02:39,280 --> 00:02:46,000
currently um if if you're like a mobile

00:02:43,040 --> 00:02:47,280
user 97 percent of mobile users use

00:02:46,000 --> 00:02:48,560
machine learning trained voice

00:02:47,280 --> 00:02:51,360
assistants like

00:02:48,560 --> 00:02:52,800
siri with the 40 search now just powered

00:02:51,360 --> 00:02:54,640
by voice

00:02:52,800 --> 00:02:56,560
advancement in the software aspect has

00:02:54,640 --> 00:02:57,599
also led to a projected growth of 120

00:02:56,560 --> 00:02:59,680
billion us

00:02:57,599 --> 00:03:02,000
dollars global sales of ai powered

00:02:59,680 --> 00:03:04,239
hardware by the end of 2025.

00:03:02,000 --> 00:03:05,599
even as i'm setting my new house i'm

00:03:04,239 --> 00:03:07,920
planning on like all these

00:03:05,599 --> 00:03:09,440
um machine learning powered hardware you

00:03:07,920 --> 00:03:12,159
know right from like doorbells

00:03:09,440 --> 00:03:13,120
and motion sensing lights and so on so

00:03:12,159 --> 00:03:16,080
all these things

00:03:13,120 --> 00:03:16,480
they work on a certain aspect and it's

00:03:16,080 --> 00:03:18,480
very

00:03:16,480 --> 00:03:20,080
necessary to understand that machine

00:03:18,480 --> 00:03:23,680
learning is the future

00:03:20,080 --> 00:03:26,400
but is it magic definitely not um

00:03:23,680 --> 00:03:27,920
this is the entire workflow that someone

00:03:26,400 --> 00:03:28,879
should focus on when you're doing like

00:03:27,920 --> 00:03:30,319
machine learning

00:03:28,879 --> 00:03:32,959
right from like defining the problem

00:03:30,319 --> 00:03:34,560
statement to developing an intuition of

00:03:32,959 --> 00:03:35,680
how machine learning can tackle the

00:03:34,560 --> 00:03:38,959
problem and

00:03:35,680 --> 00:03:41,280
challenges then begin begins like

00:03:38,959 --> 00:03:42,319
sourcing the data or fabricating our own

00:03:41,280 --> 00:03:43,840
data set

00:03:42,319 --> 00:03:46,319
then you process the data set and

00:03:43,840 --> 00:03:48,159
perform feature engineering

00:03:46,319 --> 00:03:49,680
then you have to like define the metrics

00:03:48,159 --> 00:03:51,680
appropriate metrics to measure the

00:03:49,680 --> 00:03:53,840
success of the intelligent solution that

00:03:51,680 --> 00:03:55,519
you might be proposing

00:03:53,840 --> 00:03:58,080
and then you choose the appropriate

00:03:55,519 --> 00:03:59,439
model and learning algorithm to address

00:03:58,080 --> 00:04:02,159
the problem

00:03:59,439 --> 00:04:03,680
then goes uh deploying the model and

00:04:02,159 --> 00:04:05,040
monitoring the predictions

00:04:03,680 --> 00:04:06,560
maintaining new streams of data and

00:04:05,040 --> 00:04:08,080
refreshing model parameters and it's

00:04:06,560 --> 00:04:10,319
kind of like an iterative process that

00:04:08,080 --> 00:04:12,640
goes on

00:04:10,319 --> 00:04:14,239
so to have a successful career or to

00:04:12,640 --> 00:04:16,079
have a successful journey in future

00:04:14,239 --> 00:04:18,320
technologies like data science

00:04:16,079 --> 00:04:19,840
machine learning and analytics you need

00:04:18,320 --> 00:04:22,720
a combination of

00:04:19,840 --> 00:04:24,320
basically two complementary skill sets

00:04:22,720 --> 00:04:26,400
the first that we talked about was the

00:04:24,320 --> 00:04:28,639
first half of the workflow which is an

00:04:26,400 --> 00:04:30,240
instinctive understanding of the problem

00:04:28,639 --> 00:04:32,320
like how do you define a problem

00:04:30,240 --> 00:04:33,840
statement formally with like a proper

00:04:32,320 --> 00:04:34,720
input and an output like what do you

00:04:33,840 --> 00:04:37,120
expect

00:04:34,720 --> 00:04:37,840
an instinctive uh understanding of the

00:04:37,120 --> 00:04:40,960
data

00:04:37,840 --> 00:04:43,360
like what the data is what are the

00:04:40,960 --> 00:04:44,320
like you know essential data signals and

00:04:43,360 --> 00:04:47,440
so on

00:04:44,320 --> 00:04:49,360
with and the other part is a practical

00:04:47,440 --> 00:04:51,280
expertise with relevant tools which

00:04:49,360 --> 00:04:52,880
mostly comes in handy for the last half

00:04:51,280 --> 00:04:55,280
of the workflow which is when you

00:04:52,880 --> 00:04:56,080
force the data set um you feature

00:04:55,280 --> 00:04:57,840
engineering

00:04:56,080 --> 00:04:59,759
you do feature engineering and then you

00:04:57,840 --> 00:05:01,120
like create the model deploy the model

00:04:59,759 --> 00:05:03,199
and so on

00:05:01,120 --> 00:05:04,960
so while the first half which is

00:05:03,199 --> 00:05:06,000
developing an instinctive understanding

00:05:04,960 --> 00:05:08,400
of data

00:05:06,000 --> 00:05:10,000
is a long-term immersive endeavor

00:05:08,400 --> 00:05:12,080
basically you just keep on learning

00:05:10,000 --> 00:05:13,759
every day like as you change domains you

00:05:12,080 --> 00:05:15,520
have to like keep on learning

00:05:13,759 --> 00:05:16,800
uh ads may have a different domain like

00:05:15,520 --> 00:05:17,600
movie recommendation may have a

00:05:16,800 --> 00:05:18,960
different domain

00:05:17,600 --> 00:05:21,120
so you have to like learn according to

00:05:18,960 --> 00:05:22,800
the domain but then for the tools you

00:05:21,120 --> 00:05:24,320
can always start learning because tools

00:05:22,800 --> 00:05:25,759
pretty much remain the same regardless

00:05:24,320 --> 00:05:28,400
of the domain or regardless of the

00:05:25,759 --> 00:05:31,759
problem statement you have in mind

00:05:28,400 --> 00:05:33,919
so let's start about the toolkit uh

00:05:31,759 --> 00:05:36,160
especially in terms of open source which

00:05:33,919 --> 00:05:39,360
might help you

00:05:36,160 --> 00:05:40,960
so the first is programming languages uh

00:05:39,360 --> 00:05:42,800
what kind of programming languages are

00:05:40,960 --> 00:05:45,600
good to know

00:05:42,800 --> 00:05:48,080
so instinctively to our mind comes like

00:05:45,600 --> 00:05:49,759
python and then the second would be r

00:05:48,080 --> 00:05:51,840
even though python was initially

00:05:49,759 --> 00:05:54,000
designed and is still used as like a

00:05:51,840 --> 00:05:55,600
general purpose programming language

00:05:54,000 --> 00:05:57,199
today it's one of the most popular

00:05:55,600 --> 00:05:59,280
languages for machine learning and

00:05:57,199 --> 00:06:01,039
you know data science native data

00:05:59,280 --> 00:06:02,160
scientists favor python because it's

00:06:01,039 --> 00:06:04,319
minimalistic

00:06:02,160 --> 00:06:05,360
intuitive readable and has a vast

00:06:04,319 --> 00:06:08,960
repository

00:06:05,360 --> 00:06:11,520
of libraries for specific purposes

00:06:08,960 --> 00:06:12,639
you can use python for data set curation

00:06:11,520 --> 00:06:14,160
for data analysis

00:06:12,639 --> 00:06:16,160
feature engineering modeling

00:06:14,160 --> 00:06:17,759
visualization basically

00:06:16,160 --> 00:06:19,600
most of the things that would come in

00:06:17,759 --> 00:06:21,120
that workflow

00:06:19,600 --> 00:06:22,319
uh it's a popular language with high

00:06:21,120 --> 00:06:24,880
quality machine learning and date

00:06:22,319 --> 00:06:28,319
analysis libraries as we talked about

00:06:24,880 --> 00:06:29,440
um so one of the biggest advantages i

00:06:28,319 --> 00:06:32,000
would say python

00:06:29,440 --> 00:06:34,000
provides is its model development and

00:06:32,000 --> 00:06:36,400
the fastest prototyping

00:06:34,000 --> 00:06:37,919
uh because of the amazing libraries you

00:06:36,400 --> 00:06:39,840
have it helps you know to quickly

00:06:37,919 --> 00:06:40,400
prototype let's say you have an idea in

00:06:39,840 --> 00:06:42,319
mind

00:06:40,400 --> 00:06:43,759
and you want to like show quickly on

00:06:42,319 --> 00:06:44,960
like a small data set how it would

00:06:43,759 --> 00:06:47,440
perform

00:06:44,960 --> 00:06:49,199
python comes in handy like really then

00:06:47,440 --> 00:06:50,000
uh the second language that we usually

00:06:49,199 --> 00:06:53,199
talk about is

00:06:50,000 --> 00:06:55,360
r um r is a statistical computing

00:06:53,199 --> 00:06:57,280
language and it is favored more by data

00:06:55,360 --> 00:06:58,800
analysts and statisticians

00:06:57,280 --> 00:07:00,400
uh who are trying to make their way into

00:06:58,800 --> 00:07:01,919
ml uh though and

00:07:00,400 --> 00:07:04,240
like python is known for its like

00:07:01,919 --> 00:07:06,240
predictive accuracy and is more

00:07:04,240 --> 00:07:07,680
of prevalent in artificial intelligence

00:07:06,240 --> 00:07:09,919
circles r

00:07:07,680 --> 00:07:12,000
is mostly common uh where people do more

00:07:09,919 --> 00:07:13,759
of like statistical inferences

00:07:12,000 --> 00:07:16,160
and definitely is one of the most

00:07:13,759 --> 00:07:18,880
popular languages for data analysts

00:07:16,160 --> 00:07:20,000
so uh statistics visualization data

00:07:18,880 --> 00:07:22,000
analyst

00:07:20,000 --> 00:07:23,199
for data analysis r is a popular

00:07:22,000 --> 00:07:24,800
language but if you want like a

00:07:23,199 --> 00:07:27,120
wholesome language i would definitely

00:07:24,800 --> 00:07:29,039
recommend python

00:07:27,120 --> 00:07:30,160
uh now once you're done with the

00:07:29,039 --> 00:07:32,240
languages

00:07:30,160 --> 00:07:34,319
then comes the analytical and

00:07:32,240 --> 00:07:36,160
visualization tools you need

00:07:34,319 --> 00:07:38,400
to analyze the data to visualize the

00:07:36,160 --> 00:07:40,000
data because you don't suddenly like

00:07:38,400 --> 00:07:43,520
jump into machine learning frameworks

00:07:40,000 --> 00:07:43,520
you have to like build it step by step

00:07:43,599 --> 00:07:47,280
so the first tool that usually like and

00:07:45,680 --> 00:07:47,599
one of the oldest tools i would rather

00:07:47,280 --> 00:07:50,720
say

00:07:47,599 --> 00:07:52,479
is uh sql so from database to data

00:07:50,720 --> 00:07:53,440
science is something of a journey that's

00:07:52,479 --> 00:07:55,759
equalizing

00:07:53,440 --> 00:07:57,599
the most common tool uh the data

00:07:55,759 --> 00:07:58,560
scientists apply for extracting data

00:07:57,599 --> 00:08:00,560
from both

00:07:58,560 --> 00:08:02,319
relational and non-relational database

00:08:00,560 --> 00:08:04,080
this is sql because most

00:08:02,319 --> 00:08:06,400
a popular kind of data is the tabular

00:08:04,080 --> 00:08:08,240
data right

00:08:06,400 --> 00:08:10,720
it helps you write structured queries to

00:08:08,240 --> 00:08:12,240
extract data basically and see different

00:08:10,720 --> 00:08:14,400
views of data and it's a very

00:08:12,240 --> 00:08:15,680
fundamental skill every machine learning

00:08:14,400 --> 00:08:17,840
engineer everybody

00:08:15,680 --> 00:08:19,919
data scientists should actually have

00:08:17,840 --> 00:08:20,560
because when you don't see the data by

00:08:19,919 --> 00:08:22,800
yourself

00:08:20,560 --> 00:08:24,800
um and when you don't immerse yourself

00:08:22,800 --> 00:08:26,800
fully into the data it's very hard for

00:08:24,800 --> 00:08:27,599
you to like uh make predictive

00:08:26,800 --> 00:08:29,360
influences

00:08:27,599 --> 00:08:31,120
and you know brainstorm and come up with

00:08:29,360 --> 00:08:34,240
new ideas

00:08:31,120 --> 00:08:34,800
um on similar lines uh comes pandas

00:08:34,240 --> 00:08:37,440
which is

00:08:34,800 --> 00:08:38,880
a python software library primarily used

00:08:37,440 --> 00:08:40,959
in data analysis and

00:08:38,880 --> 00:08:42,000
manipulation of the numerical tables and

00:08:40,959 --> 00:08:44,080
time series

00:08:42,000 --> 00:08:45,360
um it is of high performance and it's

00:08:44,080 --> 00:08:47,200
very easy to use so

00:08:45,360 --> 00:08:48,720
um i would say again this is a very

00:08:47,200 --> 00:08:49,519
handy tool like all the tools that i'm

00:08:48,720 --> 00:08:52,320
talking about

00:08:49,519 --> 00:08:53,519
are very handy uh and like kind of like

00:08:52,320 --> 00:08:54,880
must-haves

00:08:53,519 --> 00:08:57,040
uh i will also talk about some

00:08:54,880 --> 00:08:58,480
alternatives that might come in um

00:08:57,040 --> 00:09:00,800
so pandas are something that you should

00:08:58,480 --> 00:09:03,200
learn uh it is you know for importing

00:09:00,800 --> 00:09:05,440
cleaning manipulating data as you know

00:09:03,200 --> 00:09:06,399
a pre-preparation for building machine

00:09:05,440 --> 00:09:08,240
learning models

00:09:06,399 --> 00:09:11,760
it enables data scientists to perform

00:09:08,240 --> 00:09:14,800
complex data analysis workflows uh

00:09:11,760 --> 00:09:16,480
and um yeah basically you can do

00:09:14,800 --> 00:09:19,519
analysis by converting

00:09:16,480 --> 00:09:21,360
like csv json tsv files or even sql

00:09:19,519 --> 00:09:23,279
databases into like kind of like a data

00:09:21,360 --> 00:09:25,680
frame which is inherent to pandas

00:09:23,279 --> 00:09:26,880
so any format of um in which the data

00:09:25,680 --> 00:09:29,040
exists you

00:09:26,880 --> 00:09:29,920
uh import it into pandas as like a data

00:09:29,040 --> 00:09:32,080
frame

00:09:29,920 --> 00:09:33,920
and then it works like an object or you

00:09:32,080 --> 00:09:35,920
can combine it with so many other

00:09:33,920 --> 00:09:38,080
different tools and you know just

00:09:35,920 --> 00:09:40,800
enhance performance and support a

00:09:38,080 --> 00:09:44,240
collaborative work

00:09:40,800 --> 00:09:46,959
so after pandas comes uh matplotlib

00:09:44,240 --> 00:09:48,080
so macro.lib is nothing just like a

00:09:46,959 --> 00:09:50,720
visualization

00:09:48,080 --> 00:09:52,240
uh library so previously the two that we

00:09:50,720 --> 00:09:53,440
talked about like sql and pandas are

00:09:52,240 --> 00:09:55,839
more of like analysis

00:09:53,440 --> 00:09:57,360
this is more for visualization uh you

00:09:55,839 --> 00:10:00,640
can do like 2d plotting

00:09:57,360 --> 00:10:02,079
uh 3d plotting contour plotting lines

00:10:00,640 --> 00:10:04,640
scatter polar image

00:10:02,079 --> 00:10:06,240
histogram like most of like the charts

00:10:04,640 --> 00:10:07,600
you can do to visualize how the data

00:10:06,240 --> 00:10:08,880
looks like because it's very necessary

00:10:07,600 --> 00:10:11,519
to also see like

00:10:08,880 --> 00:10:13,839
the percentage of like labels positive

00:10:11,519 --> 00:10:17,120
labels negative labels uh to see

00:10:13,839 --> 00:10:19,839
how the features hydrating and so on so

00:10:17,120 --> 00:10:22,079
uh again in that plotlib uh you can

00:10:19,839 --> 00:10:23,279
easily integrate with python toolset and

00:10:22,079 --> 00:10:26,079
you can use with other

00:10:23,279 --> 00:10:27,600
libraries like you know that we'll talk

00:10:26,079 --> 00:10:29,040
in the future about like numpy or

00:10:27,600 --> 00:10:31,120
pytorch and so on

00:10:29,040 --> 00:10:32,959
um again multi-platform data

00:10:31,120 --> 00:10:36,320
visualization library that you should be

00:10:32,959 --> 00:10:36,959
no no uh you can say cborn is kind of

00:10:36,320 --> 00:10:39,760
like

00:10:36,959 --> 00:10:41,600
an alternative if or maybe just like an

00:10:39,760 --> 00:10:43,760
enhancement or matplotlib

00:10:41,600 --> 00:10:45,680
because uh it is for like more

00:10:43,760 --> 00:10:49,680
attractive data visualization

00:10:45,680 --> 00:10:52,160
so um it is again based on matplotlib

00:10:49,680 --> 00:10:54,160
but then uh if you want to like go one

00:10:52,160 --> 00:10:54,959
step further it offers like a high level

00:10:54,160 --> 00:10:56,800
interface

00:10:54,959 --> 00:10:58,399
and you know more like customized themes

00:10:56,800 --> 00:10:59,279
you could give like a color scheme and

00:10:58,399 --> 00:11:01,600
so on for

00:10:59,279 --> 00:11:02,880
visually enhanced statistical graphics

00:11:01,600 --> 00:11:04,800
uh it also has

00:11:02,880 --> 00:11:07,120
the accurate um the ability to

00:11:04,800 --> 00:11:08,800
accurately visualize data frames

00:11:07,120 --> 00:11:10,240
uh which we talked like the pandas data

00:11:08,800 --> 00:11:12,800
frames uh

00:11:10,240 --> 00:11:14,079
which like inherently matlar clip kind

00:11:12,800 --> 00:11:16,720
of like struggles it

00:11:14,079 --> 00:11:18,320
so cbon uh like if you're just starting

00:11:16,720 --> 00:11:20,000
with machine learning and data analysis

00:11:18,320 --> 00:11:20,480
and visualization you could choose one

00:11:20,000 --> 00:11:23,600
of them

00:11:20,480 --> 00:11:25,440
but c1 is just like one step uh ahead of

00:11:23,600 --> 00:11:27,040
matplotlib and you know more like

00:11:25,440 --> 00:11:30,880
customized themes and high level

00:11:27,040 --> 00:11:33,279
interface for the statistical graphics

00:11:30,880 --> 00:11:34,640
so now you know like the analysis tool

00:11:33,279 --> 00:11:36,480
the visualization tool

00:11:34,640 --> 00:11:38,399
now let's go for some like rich

00:11:36,480 --> 00:11:40,079
interactive input output system where

00:11:38,399 --> 00:11:42,160
you can you know

00:11:40,079 --> 00:11:43,440
run your systems like run your models

00:11:42,160 --> 00:11:45,519
and just you know give an

00:11:43,440 --> 00:11:46,959
input come with an output and jupyter is

00:11:45,519 --> 00:11:49,120
one such tool

00:11:46,959 --> 00:11:50,320
so although it was traditionally used in

00:11:49,120 --> 00:11:52,160
academia as

00:11:50,320 --> 00:11:54,240
a notebook kind of tool it actually is a

00:11:52,160 --> 00:11:55,440
notebook because you write it has like

00:11:54,240 --> 00:11:56,959
different cells

00:11:55,440 --> 00:11:59,120
you write the input you get the output

00:11:56,959 --> 00:12:01,360
and like so on uh it was used in

00:11:59,120 --> 00:12:02,720
academia to record research notes and

00:12:01,360 --> 00:12:05,279
computation findings

00:12:02,720 --> 00:12:05,760
but today jupiter notebook has found its

00:12:05,279 --> 00:12:08,000
place

00:12:05,760 --> 00:12:10,800
in like the entire data visualization

00:12:08,000 --> 00:12:12,880
run programmers and ml professionals use

00:12:10,800 --> 00:12:15,200
jupyter notebook across

00:12:12,880 --> 00:12:16,959
for various reasons like data cleansing

00:12:15,200 --> 00:12:19,839
numerical simulations statistical

00:12:16,959 --> 00:12:23,200
modeling data visualization and so on

00:12:19,839 --> 00:12:25,279
uh the good part about jupiter is it

00:12:23,200 --> 00:12:26,800
supports not only python like

00:12:25,279 --> 00:12:28,639
people usually think it supports python

00:12:26,800 --> 00:12:29,600
but it supports over 40 programming

00:12:28,639 --> 00:12:31,200
languages

00:12:29,600 --> 00:12:32,880
and you can easily integrate with you

00:12:31,200 --> 00:12:35,120
know big data processing tools like

00:12:32,880 --> 00:12:37,760
apache spark and so on

00:12:35,120 --> 00:12:39,279
uh it is very helpful for a

00:12:37,760 --> 00:12:41,839
collaborative work

00:12:39,279 --> 00:12:43,440
capability so that you know um you can

00:12:41,839 --> 00:12:44,959
ask people to collaborate with you on

00:12:43,440 --> 00:12:46,240
the same notebook you just do like kind

00:12:44,959 --> 00:12:48,160
of like a link sharing

00:12:46,240 --> 00:12:51,200
it is very rich in functionality and

00:12:48,160 --> 00:12:54,480
provides various use case scenarios

00:12:51,200 --> 00:12:56,320
um so one of the alternatives that i

00:12:54,480 --> 00:12:58,880
would like to talk about jupiter is

00:12:56,320 --> 00:13:00,800
this is uh google collab so google

00:12:58,880 --> 00:13:04,399
collab is also kind of like a notebook

00:13:00,800 --> 00:13:06,399
uh environment created by google

00:13:04,399 --> 00:13:08,160
uh but the only difference is it's kind

00:13:06,399 --> 00:13:09,839
of like on a cloud service just like you

00:13:08,160 --> 00:13:10,480
know you have google docs and google

00:13:09,839 --> 00:13:12,240
sheets

00:13:10,480 --> 00:13:13,760
there's a new feature known as like

00:13:12,240 --> 00:13:15,600
google collab new product

00:13:13,760 --> 00:13:17,440
it supports libraries like pie torch

00:13:15,600 --> 00:13:18,399
keras tensorflow opencv again that we'll

00:13:17,440 --> 00:13:20,079
talk about but

00:13:18,399 --> 00:13:21,920
just an alternative to jupiter if you

00:13:20,079 --> 00:13:22,720
don't need to have need the hazard you

00:13:21,920 --> 00:13:24,399
know set up at

00:13:22,720 --> 00:13:27,040
all itself you can just create like a

00:13:24,399 --> 00:13:28,959
small notebook on the cloud

00:13:27,040 --> 00:13:30,639
so now that we've talked about all the

00:13:28,959 --> 00:13:31,519
you know tools that we might need to

00:13:30,639 --> 00:13:33,040
prep

00:13:31,519 --> 00:13:34,880
for like you know have like a place

00:13:33,040 --> 00:13:36,399
where we can run or like to do data

00:13:34,880 --> 00:13:39,279
visualization and

00:13:36,399 --> 00:13:41,120
you know just like find out uh

00:13:39,279 --> 00:13:42,240
interesting patterns in the data like

00:13:41,120 --> 00:13:44,720
initially

00:13:42,240 --> 00:13:46,560
um let's come to like libraries and

00:13:44,720 --> 00:13:48,480
frameworks which is one of the

00:13:46,560 --> 00:13:49,839
biggest aspect people think about when

00:13:48,480 --> 00:13:51,680
they think about machine learning right

00:13:49,839 --> 00:13:53,120
like modeling how do you create models

00:13:51,680 --> 00:13:54,959
and how do you write them

00:13:53,120 --> 00:13:57,040
uh so let's talk about some libraries

00:13:54,959 --> 00:13:58,800
and frameworks so the first thing that

00:13:57,040 --> 00:14:00,880
showed before even if you go for like

00:13:58,800 --> 00:14:02,800
you know those big heavy duty uh

00:14:00,880 --> 00:14:04,800
libraries and frameworks it's important

00:14:02,800 --> 00:14:06,320
to know numpy which is like an extension

00:14:04,800 --> 00:14:08,079
package for kind of

00:14:06,320 --> 00:14:09,760
uh doing scientific computing with

00:14:08,079 --> 00:14:12,720
python you know do quick

00:14:09,760 --> 00:14:14,079
uh arrow multiplications divisions uh

00:14:12,720 --> 00:14:17,360
multi-dimensional

00:14:14,079 --> 00:14:18,720
arrays and uh matrices uh because most

00:14:17,360 --> 00:14:20,399
of the machine learning data

00:14:18,720 --> 00:14:22,560
is represented in kind of like vector

00:14:20,399 --> 00:14:23,839
format or array format

00:14:22,560 --> 00:14:26,480
or like matrix if it's like

00:14:23,839 --> 00:14:29,199
two-dimensional and so on so it contains

00:14:26,480 --> 00:14:31,920
uh broadcasting tools uh

00:14:29,199 --> 00:14:33,600
for like numpy to do perform like linear

00:14:31,920 --> 00:14:34,800
algebra and like random number

00:14:33,600 --> 00:14:37,519
capabilities

00:14:34,800 --> 00:14:38,880
so it is a very effective method like

00:14:37,519 --> 00:14:40,880
container kind of storage for

00:14:38,880 --> 00:14:44,160
multi-dimensional generic data

00:14:40,880 --> 00:14:45,760
and you can define arbitrary data types

00:14:44,160 --> 00:14:48,240
and quickly integrate with tons of

00:14:45,760 --> 00:14:50,560
databases uh so it's kind of like

00:14:48,240 --> 00:14:52,880
all-in-one mathematical toolkit that you

00:14:50,560 --> 00:14:55,120
might need uh

00:14:52,880 --> 00:14:56,720
for um especially to use in python to

00:14:55,120 --> 00:14:58,720
like you know manipulate the data and do

00:14:56,720 --> 00:15:00,880
like quick scientific computation

00:14:58,720 --> 00:15:02,480
scipy is another alternative that you

00:15:00,880 --> 00:15:05,199
can consider

00:15:02,480 --> 00:15:07,600
nozampa is like very popular now coming

00:15:05,199 --> 00:15:09,440
to actual machine learning modeling uh

00:15:07,600 --> 00:15:11,440
one of the most beginner friendly tools

00:15:09,440 --> 00:15:13,440
i would say is a psychic learn

00:15:11,440 --> 00:15:15,360
it's a multi-purpose python library

00:15:13,440 --> 00:15:16,800
primarily used for data mining and

00:15:15,360 --> 00:15:18,959
analysis modeling

00:15:16,800 --> 00:15:20,959
uh it is used across all kinds of

00:15:18,959 --> 00:15:22,160
supervisor and supervised algorithms it

00:15:20,959 --> 00:15:25,279
has one of the best

00:15:22,160 --> 00:15:27,040
um i would say uh documentation

00:15:25,279 --> 00:15:28,480
and like lots of tutorials available

00:15:27,040 --> 00:15:30,320
online for use businesses like

00:15:28,480 --> 00:15:32,160
classification regression clustering

00:15:30,320 --> 00:15:33,680
pre-processing and model selection

00:15:32,160 --> 00:15:36,240
so if you're just beginning out and you

00:15:33,680 --> 00:15:38,000
need to like try out different models um

00:15:36,240 --> 00:15:39,680
cyclic learn is the way to go because

00:15:38,000 --> 00:15:40,000
that's what i did as well when i just

00:15:39,680 --> 00:15:42,320
got

00:15:40,000 --> 00:15:43,360
started it is favored by those working

00:15:42,320 --> 00:15:45,680
in you know

00:15:43,360 --> 00:15:47,279
like simple uh things like spam

00:15:45,680 --> 00:15:48,639
detection image recognition

00:15:47,279 --> 00:15:50,240
text classification if you just want to

00:15:48,639 --> 00:15:51,199
get your hands dirty with it this is the

00:15:50,240 --> 00:15:53,680
tool to start

00:15:51,199 --> 00:15:55,600
it's open source built on top of sci-fi

00:15:53,680 --> 00:15:58,240
numpy and matplotlib

00:15:55,600 --> 00:15:59,920
so these are the three uh libraries it

00:15:58,240 --> 00:16:00,880
is based on to create that modeling

00:15:59,920 --> 00:16:04,000
framework

00:16:00,880 --> 00:16:06,560
uh it's very simple transparent um and

00:16:04,000 --> 00:16:08,399
the tools can be like widely adopted so

00:16:06,560 --> 00:16:11,279
definitely something that one should

00:16:08,399 --> 00:16:11,279
check out um

00:16:11,440 --> 00:16:14,639
and next comes tensorflow you might have

00:16:13,199 --> 00:16:18,000
like heard a lot about it

00:16:14,639 --> 00:16:20,320
it is like developed by google and like

00:16:18,000 --> 00:16:22,079
like currently being uh supported by

00:16:20,320 --> 00:16:24,079
google and then machine learning

00:16:22,079 --> 00:16:25,680
it is for machine learning at scale so

00:16:24,079 --> 00:16:27,279
it is a computational framework for

00:16:25,680 --> 00:16:30,880
building machine learning models

00:16:27,279 --> 00:16:32,160
um and they use basically it is

00:16:30,880 --> 00:16:33,440
for image recognition text

00:16:32,160 --> 00:16:34,560
classification natural language

00:16:33,440 --> 00:16:36,480
processing

00:16:34,560 --> 00:16:38,800
and uh it kind of like mimics the

00:16:36,480 --> 00:16:39,279
anatomy of the human brain in terms of

00:16:38,800 --> 00:16:41,759
like

00:16:39,279 --> 00:16:44,079
neurons uh i don't want to go deep into

00:16:41,759 --> 00:16:46,480
it because uh this presentation was like

00:16:44,079 --> 00:16:48,000
mostly projected as like tools you could

00:16:46,480 --> 00:16:50,079
get started with and i wanted to

00:16:48,000 --> 00:16:51,920
divide it it's like a very flexible

00:16:50,079 --> 00:16:53,839
framework for large scale machine

00:16:51,920 --> 00:16:55,920
learning um

00:16:53,839 --> 00:16:58,320
another advantage of this framework is

00:16:55,920 --> 00:17:00,160
it works both for research and recording

00:16:58,320 --> 00:17:02,000
machine learning task recording would be

00:17:00,160 --> 00:17:04,240
for example you are at a startup and you

00:17:02,000 --> 00:17:05,520
need to serve like every second uh like

00:17:04,240 --> 00:17:07,280
a request comes in

00:17:05,520 --> 00:17:09,039
so it is very helpful in that and also

00:17:07,280 --> 00:17:10,799
very useful in academia

00:17:09,039 --> 00:17:12,959
uh it can be used across various of

00:17:10,799 --> 00:17:14,559
computation platforms it supports cpus

00:17:12,959 --> 00:17:18,880
gpus cpus

00:17:14,559 --> 00:17:21,520
and uh from runs on any os uh

00:17:18,880 --> 00:17:22,400
and like variety of uh basically uh

00:17:21,520 --> 00:17:24,240
devices

00:17:22,400 --> 00:17:25,679
from desktops to clusters to servers to

00:17:24,240 --> 00:17:27,760
mobiles and to ed systems

00:17:25,679 --> 00:17:29,360
it even has like a tensorflow lite for

00:17:27,760 --> 00:17:31,280
uh machine learning for like smaller

00:17:29,360 --> 00:17:34,000
devices

00:17:31,280 --> 00:17:35,360
uh definitely something to look at if

00:17:34,000 --> 00:17:37,120
you're looking to get started with you

00:17:35,360 --> 00:17:39,840
know neural network and wanted to do

00:17:37,120 --> 00:17:40,640
machine learning at scale uh with

00:17:39,840 --> 00:17:42,720
tensorflow

00:17:40,640 --> 00:17:44,320
stencil board uh i wanted to mention it

00:17:42,720 --> 00:17:44,960
in the visualization tool but it's not

00:17:44,320 --> 00:17:47,520
something that

00:17:44,960 --> 00:17:48,320
is kind of like a must-have it this is a

00:17:47,520 --> 00:17:50,559
good tool for

00:17:48,320 --> 00:17:52,480
model training visualization especially

00:17:50,559 --> 00:17:55,840
in conjugation with tensorflow

00:17:52,480 --> 00:17:57,520
um it gives out like throws um

00:17:55,840 --> 00:17:59,280
summary data observations about a

00:17:57,520 --> 00:18:00,000
specific model's operations being

00:17:59,280 --> 00:18:01,919
generated by

00:18:00,000 --> 00:18:03,679
tensorflow's running like live data

00:18:01,919 --> 00:18:05,520
statistics about the model

00:18:03,679 --> 00:18:07,679
uh the model structure is shown with

00:18:05,520 --> 00:18:09,919
graph allows researchers to make sure

00:18:07,679 --> 00:18:11,520
uh the model components are working fine

00:18:09,919 --> 00:18:13,760
and where they're located

00:18:11,520 --> 00:18:15,919
and if they're connected properly or not

00:18:13,760 --> 00:18:17,360
uh so this graph visualizer

00:18:15,919 --> 00:18:20,000
you can explore like different layers of

00:18:17,360 --> 00:18:22,240
user abstraction and so on

00:18:20,000 --> 00:18:25,840
so definitely something if you're

00:18:22,240 --> 00:18:29,840
working with tensorflow to look at

00:18:25,840 --> 00:18:29,840
did i miss a chat or something

00:18:32,160 --> 00:18:38,400
um got it so um

00:18:35,760 --> 00:18:40,320
next comes weka uh personally i haven't

00:18:38,400 --> 00:18:43,520
used a lot just like checked it out

00:18:40,320 --> 00:18:45,919
as a two per se uh but i would say that

00:18:43,520 --> 00:18:46,559
if you're looking for you know a nice

00:18:45,919 --> 00:18:49,679
gui

00:18:46,559 --> 00:18:52,000
kind of a thing for machine learning uh

00:18:49,679 --> 00:18:53,840
definitely check look at this it

00:18:52,000 --> 00:18:55,440
actually it's the learning curves

00:18:53,840 --> 00:18:57,360
for people who are not confident in

00:18:55,440 --> 00:18:59,440
their coding skills um

00:18:57,360 --> 00:19:00,960
yet they want to do uh you know machine

00:18:59,440 --> 00:19:02,640
learning

00:19:00,960 --> 00:19:04,880
this is something to look at because it

00:19:02,640 --> 00:19:06,880
has like tasks such as pre-processing

00:19:04,880 --> 00:19:08,320
classification association regression

00:19:06,880 --> 00:19:10,000
clustering visualization

00:19:08,320 --> 00:19:12,000
all the shenanigans but with you know a

00:19:10,000 --> 00:19:12,720
nice uh graphical centrifuge like as

00:19:12,000 --> 00:19:14,799
compared to

00:19:12,720 --> 00:19:15,840
those so it is a tried and tested open

00:19:14,799 --> 00:19:17,200
source machine and

00:19:15,840 --> 00:19:19,600
software that can be accessed through

00:19:17,200 --> 00:19:21,039
like a gui and standard terminal

00:19:19,600 --> 00:19:23,280
applications as well

00:19:21,039 --> 00:19:25,120
it is widely used for people who want to

00:19:23,280 --> 00:19:27,280
like teach uh to people who

00:19:25,120 --> 00:19:29,200
uh and for research and for industrial

00:19:27,280 --> 00:19:31,440
applications and it has like a lot of

00:19:29,200 --> 00:19:32,559
built-in tools for machine learning uh

00:19:31,440 --> 00:19:35,360
so definitely if you

00:19:32,559 --> 00:19:36,320
are someone who likes their user

00:19:35,360 --> 00:19:38,000
interface

00:19:36,320 --> 00:19:39,440
and are like just getting started and

00:19:38,000 --> 00:19:41,360
then like super confident in their

00:19:39,440 --> 00:19:42,160
coding skills uh this is something you

00:19:41,360 --> 00:19:45,200
know for

00:19:42,160 --> 00:19:47,760
trying out machine learning for once

00:19:45,200 --> 00:19:49,440
now let's talk about uh some specific

00:19:47,760 --> 00:19:50,880
libraries and frameworks for specific

00:19:49,440 --> 00:19:54,080
tasks for example

00:19:50,880 --> 00:19:55,120
uh you are like heavily uh inclined

00:19:54,080 --> 00:19:57,039
towards

00:19:55,120 --> 00:19:58,640
real-time computer vision applications

00:19:57,039 --> 00:20:00,480
image processing

00:19:58,640 --> 00:20:03,039
video capture and you know face

00:20:00,480 --> 00:20:05,760
detection object detection kind of uh

00:20:03,039 --> 00:20:07,440
tasks so in that case opencv is like a

00:20:05,760 --> 00:20:09,520
cross platform library that you can you

00:20:07,440 --> 00:20:12,400
know work on again open source

00:20:09,520 --> 00:20:13,520
uh specifically for that task and again

00:20:12,400 --> 00:20:15,600
if you're like

00:20:13,520 --> 00:20:17,280
looking for natural language processing

00:20:15,600 --> 00:20:21,039
tasks you know uh to work with

00:20:17,280 --> 00:20:23,440
python programs uh for human language

00:20:21,039 --> 00:20:24,240
this is something uh like nltk is a

00:20:23,440 --> 00:20:26,080
python based

00:20:24,240 --> 00:20:27,600
language data process and platform that

00:20:26,080 --> 00:20:30,159
one can get

00:20:27,600 --> 00:20:32,320
um this is a standard library for text

00:20:30,159 --> 00:20:33,360
processing and has many useful features

00:20:32,320 --> 00:20:35,120
especially when you're doing like

00:20:33,360 --> 00:20:37,120
feature answering sort of tasks

00:20:35,120 --> 00:20:38,240
uh different types of text sentences

00:20:37,120 --> 00:20:40,240
word processing

00:20:38,240 --> 00:20:41,520
speech tagging sentence structure

00:20:40,240 --> 00:20:43,520
analysis

00:20:41,520 --> 00:20:45,440
named entity recognition text

00:20:43,520 --> 00:20:47,039
classification i know i'm like throwing

00:20:45,440 --> 00:20:47,440
these stuff out but it's good to know at

00:20:47,039 --> 00:20:50,000
least

00:20:47,440 --> 00:20:50,640
term so that you can always look them up

00:20:50,000 --> 00:20:52,400
uh

00:20:50,640 --> 00:20:54,400
the libraries are like free and they

00:20:52,400 --> 00:20:57,280
provide enough functionality for solving

00:20:54,400 --> 00:21:00,159
like majority of tasks

00:20:57,280 --> 00:21:01,919
so now that we're done with um say

00:21:00,159 --> 00:21:03,840
visualization tools and

00:21:01,919 --> 00:21:05,600
analysis tools and even like the basic

00:21:03,840 --> 00:21:07,200
libraries you would need to get started

00:21:05,600 --> 00:21:09,760
with machine learning like cyclical

00:21:07,200 --> 00:21:11,039
and tensorflow it's also good to look at

00:21:09,760 --> 00:21:12,960
the deep learning tools

00:21:11,039 --> 00:21:15,200
so what are like deep learning tools

00:21:12,960 --> 00:21:17,360
would be deep learning is effortless

00:21:15,200 --> 00:21:19,360
uh when you do like modeling with neural

00:21:17,360 --> 00:21:22,240
networks but with more than like

00:21:19,360 --> 00:21:23,200
two plus layers you your network becomes

00:21:22,240 --> 00:21:24,960
deeply

00:21:23,200 --> 00:21:27,600
technically it should be more but yeah

00:21:24,960 --> 00:21:30,320
that's how deep learning is defined

00:21:27,600 --> 00:21:30,640
so in that case sometimes it's necessary

00:21:30,320 --> 00:21:32,720
uh

00:21:30,640 --> 00:21:34,320
for you to have like pre-trained models

00:21:32,720 --> 00:21:35,840
because you can you know like warm start

00:21:34,320 --> 00:21:37,360
from i'll get started from it

00:21:35,840 --> 00:21:39,120
and there are specific tools which are

00:21:37,360 --> 00:21:39,760
developed just for you know those kind

00:21:39,120 --> 00:21:42,559
of like

00:21:39,760 --> 00:21:43,520
deep learning tasks so one of them is

00:21:42,559 --> 00:21:46,159
keras

00:21:43,520 --> 00:21:47,520
uh after tensorflow which we consider an

00:21:46,159 --> 00:21:50,240
all-purpose ml tool

00:21:47,520 --> 00:21:51,919
uh and not just not for deep learning

00:21:50,240 --> 00:21:53,600
because it has like grown since

00:21:51,919 --> 00:21:55,440
it was like developed as a deep learning

00:21:53,600 --> 00:21:58,559
tool uh is callous

00:21:55,440 --> 00:22:01,039
uh it is for evaluation um

00:21:58,559 --> 00:22:02,080
it's cross-platform open source neural

00:22:01,039 --> 00:22:04,640
network library

00:22:02,080 --> 00:22:06,080
again written in python uh so that's why

00:22:04,640 --> 00:22:07,760
i said like python is something that is

00:22:06,080 --> 00:22:08,720
very useful if you're getting started

00:22:07,760 --> 00:22:10,240
machine learning and

00:22:08,720 --> 00:22:12,000
you just want to build a career in data

00:22:10,240 --> 00:22:14,240
analysis uh better than r

00:22:12,000 --> 00:22:15,280
in my opinion i did start with both of

00:22:14,240 --> 00:22:17,520
them initially but then

00:22:15,280 --> 00:22:18,320
obviously steered towards python uh

00:22:17,520 --> 00:22:21,440
keras is

00:22:18,320 --> 00:22:23,360
built to enable fast easy and convenient

00:22:21,440 --> 00:22:26,240
deployment of deep learning models

00:22:23,360 --> 00:22:27,440
it's very modular minimal extensive and

00:22:26,240 --> 00:22:29,440
python driven

00:22:27,440 --> 00:22:31,120
um it might be easy to say so but when

00:22:29,440 --> 00:22:32,960
you start working with it you would

00:22:31,120 --> 00:22:34,640
get to realize that it helps prototyping

00:22:32,960 --> 00:22:35,919
at like lightning speed so

00:22:34,640 --> 00:22:37,840
you have a model in mind you want to

00:22:35,919 --> 00:22:38,720
just like showcase build like the first

00:22:37,840 --> 00:22:42,080
prototype

00:22:38,720 --> 00:22:44,000
this is something to start with and uh

00:22:42,080 --> 00:22:46,720
it can run on gpu cpu and support both

00:22:44,000 --> 00:22:48,400
recurrent rnns and cnns basically as

00:22:46,720 --> 00:22:49,360
well as like a combination of both of

00:22:48,400 --> 00:22:52,720
them

00:22:49,360 --> 00:22:54,320
uh on the similar front we have pytorch

00:22:52,720 --> 00:22:56,240
and is also a flexible and modular

00:22:54,320 --> 00:22:58,559
framework for ai and ml

00:22:56,240 --> 00:23:00,240
uh it was developed by um currently

00:22:58,559 --> 00:23:01,600
supported by an ai research team at

00:23:00,240 --> 00:23:03,600
facebook um

00:23:01,600 --> 00:23:04,720
and it's also used in computer vision

00:23:03,600 --> 00:23:07,520
and nlp

00:23:04,720 --> 00:23:09,600
uh it boasts the ability to expediate

00:23:07,520 --> 00:23:10,880
experimentation to move models with you

00:23:09,600 --> 00:23:13,520
to production

00:23:10,880 --> 00:23:14,559
again it has both python and c plus plus

00:23:13,520 --> 00:23:16,159
interfaces and

00:23:14,559 --> 00:23:17,840
helps in distributed training and

00:23:16,159 --> 00:23:22,960
extensive range of tools

00:23:17,840 --> 00:23:26,159
uh yeah so pie tarts and carrots

00:23:22,960 --> 00:23:28,159
are one of the two most common um

00:23:26,159 --> 00:23:30,159
deep learning tools that i know of and

00:23:28,159 --> 00:23:31,760
i've tried and i would recommend people

00:23:30,159 --> 00:23:35,039
to get started with

00:23:31,760 --> 00:23:36,720
um now comes uh the last half of

00:23:35,039 --> 00:23:38,159
basically like the last two parts of the

00:23:36,720 --> 00:23:39,760
workshop that we talked about

00:23:38,159 --> 00:23:42,000
so you have built your model and you

00:23:39,760 --> 00:23:42,559
want to like deploy those in production

00:23:42,000 --> 00:23:44,559
um

00:23:42,559 --> 00:23:46,640
by deployment i would mean like you want

00:23:44,559 --> 00:23:47,120
them to run like one after the other and

00:23:46,640 --> 00:23:49,279
then

00:23:47,120 --> 00:23:51,039
also serve in real time and then you

00:23:49,279 --> 00:23:53,039
want like sometimes you need like

00:23:51,039 --> 00:23:54,559
tasks to repeat you know like online

00:23:53,039 --> 00:23:56,559
training kind of thing you need

00:23:54,559 --> 00:23:58,320
where as and when the new data comes in

00:23:56,559 --> 00:24:00,000
it goes into the pipeline you know

00:23:58,320 --> 00:24:01,360
uh feature engineering happens that new

00:24:00,000 --> 00:24:05,440
features get formed like

00:24:01,360 --> 00:24:07,600
in the same rows like new roles uh

00:24:05,440 --> 00:24:09,120
and then basically uh like keep the

00:24:07,600 --> 00:24:10,720
tasks running so that's when like

00:24:09,120 --> 00:24:12,400
deployment comes into place you have to

00:24:10,720 --> 00:24:13,120
like do kind of like resource allocation

00:24:12,400 --> 00:24:14,720
and so on

00:24:13,120 --> 00:24:16,799
so the tools that usually come in handy

00:24:14,720 --> 00:24:19,520
like one of them would be ml flow

00:24:16,799 --> 00:24:21,279
it was designed to work with any machine

00:24:19,520 --> 00:24:23,039
learning library or algorithm

00:24:21,279 --> 00:24:24,760
and manage its entire life cycle

00:24:23,039 --> 00:24:28,000
including experimentation

00:24:24,760 --> 00:24:30,000
reproducibility deployment and so on

00:24:28,000 --> 00:24:31,760
it is currently in alpha and it has like

00:24:30,000 --> 00:24:32,799
three main like tracking projects and

00:24:31,760 --> 00:24:34,720
models like

00:24:32,799 --> 00:24:36,000
these kind of like three main components

00:24:34,720 --> 00:24:38,159
it has have

00:24:36,000 --> 00:24:40,159
uh something that i've used personally

00:24:38,159 --> 00:24:43,440
uh would be tensorflow extended

00:24:40,159 --> 00:24:45,760
uh again it's like you can use in

00:24:43,440 --> 00:24:46,960
conjugation tensorflow uh tensorboard

00:24:45,760 --> 00:24:49,200
and tensorflow extended

00:24:46,960 --> 00:24:51,120
so tfx is an end-to-end platform for

00:24:49,200 --> 00:24:52,720
deploying machine learning pipelines uh

00:24:51,120 --> 00:24:53,520
when you're ready to move from research

00:24:52,720 --> 00:24:55,600
to production

00:24:53,520 --> 00:24:57,679
it helps to create like a manageable

00:24:55,600 --> 00:25:00,559
pipeline with different components

00:24:57,679 --> 00:25:02,240
uh it's developed by google and it

00:25:00,559 --> 00:25:04,080
provides a configuration framework and

00:25:02,240 --> 00:25:04,960
shared libraries to integrate common

00:25:04,080 --> 00:25:06,960
components

00:25:04,960 --> 00:25:08,240
so the components that i'm talking about

00:25:06,960 --> 00:25:11,200
would be like you know

00:25:08,240 --> 00:25:12,720
um fetch data so something like that and

00:25:11,200 --> 00:25:16,320
you can always change the function

00:25:12,720 --> 00:25:19,039
inside of it how it fetches data um

00:25:16,320 --> 00:25:20,080
it might be like very uh easy to say so

00:25:19,039 --> 00:25:22,799
but when it comes to

00:25:20,080 --> 00:25:23,600
it is very intense and something that is

00:25:22,799 --> 00:25:25,520
really helpful

00:25:23,600 --> 00:25:27,120
for production even at like big scale

00:25:25,520 --> 00:25:30,320
companies uh

00:25:27,120 --> 00:25:32,159
for developing pipelines so

00:25:30,320 --> 00:25:33,919
after you've deployed sometimes you need

00:25:32,159 --> 00:25:35,440
to like uh these are some additional

00:25:33,919 --> 00:25:37,200
tools that i would like to talk about

00:25:35,440 --> 00:25:40,480
when you have like lots of data

00:25:37,200 --> 00:25:42,480
so apache spark is something for cluster

00:25:40,480 --> 00:25:44,000
computer programming and for big data

00:25:42,480 --> 00:25:47,279
analytics

00:25:44,000 --> 00:25:49,120
it is favored because of speed and easy

00:25:47,279 --> 00:25:51,760
to use and highly

00:25:49,120 --> 00:25:53,039
integrable across various platforms and

00:25:51,760 --> 00:25:56,000
data sources

00:25:53,039 --> 00:25:57,200
um so it's faster more convenient and

00:25:56,000 --> 00:25:59,600
basically you can

00:25:57,200 --> 00:26:01,360
perform everything in parallel and that

00:25:59,600 --> 00:26:02,880
is where mapreduce also

00:26:01,360 --> 00:26:04,880
comes into place because it's

00:26:02,880 --> 00:26:06,559
heavyweight in data manipulation it's

00:26:04,880 --> 00:26:08,880
a kind of like a programming model for

00:26:06,559 --> 00:26:11,520
big data processing on clusters

00:26:08,880 --> 00:26:12,240
um i didn't want to like go deep into it

00:26:11,520 --> 00:26:13,679
because

00:26:12,240 --> 00:26:15,840
i just wanted her to like share the

00:26:13,679 --> 00:26:17,679
names of the tools like that's what

00:26:15,840 --> 00:26:20,080
i was intending to but if you're

00:26:17,679 --> 00:26:22,480
something if you're someone who works

00:26:20,080 --> 00:26:24,400
with big data definitely try checking

00:26:22,480 --> 00:26:26,559
out apache spark and you know map reduce

00:26:24,400 --> 00:26:27,919
programming model because it helps uh

00:26:26,559 --> 00:26:30,640
doing parallelizing

00:26:27,919 --> 00:26:33,120
uh computations across huge volumes of

00:26:30,640 --> 00:26:36,799
data both unstructured and structured

00:26:33,120 --> 00:26:37,440
um so yeah that's uh again coming back

00:26:36,799 --> 00:26:39,760
to the

00:26:37,440 --> 00:26:40,640
workflow it is very easy to see workflow

00:26:39,760 --> 00:26:42,320
but um

00:26:40,640 --> 00:26:43,919
when you're just getting started machine

00:26:42,320 --> 00:26:46,960
learning uh people

00:26:43,919 --> 00:26:48,400
try to focus on uh this aspect of the

00:26:46,960 --> 00:26:50,240
workflow link just when they're starting

00:26:48,400 --> 00:26:52,159
out like defining appropriate metrics to

00:26:50,240 --> 00:26:53,760
measure the success of

00:26:52,159 --> 00:26:56,159
intelligent solution and choosing the

00:26:53,760 --> 00:26:58,240
appropriate model

00:26:56,159 --> 00:26:59,520
many times they end up forgetting that

00:26:58,240 --> 00:27:00,559
this is where you should actually be

00:26:59,520 --> 00:27:02,320
starting with like

00:27:00,559 --> 00:27:04,480
sourcing the data and fabricating your

00:27:02,320 --> 00:27:06,799
own data set uh because if you don't

00:27:04,480 --> 00:27:08,720
have data like the kind of data you

00:27:06,799 --> 00:27:09,360
input is how your model would perform

00:27:08,720 --> 00:27:11,840
right and

00:27:09,360 --> 00:27:12,799
processing the data doing uh data

00:27:11,840 --> 00:27:14,400
analysis

00:27:12,799 --> 00:27:15,760
um data pre-processing data

00:27:14,400 --> 00:27:16,240
transformation feature engineering are

00:27:15,760 --> 00:27:18,159
like

00:27:16,240 --> 00:27:19,440
solely as important as the modeling

00:27:18,159 --> 00:27:21,760
aspect of it

00:27:19,440 --> 00:27:23,600
your data is your model is as good as

00:27:21,760 --> 00:27:26,000
data it gets

00:27:23,600 --> 00:27:27,520
so in that uh if you're interested uh in

00:27:26,000 --> 00:27:29,520
you know building data sets

00:27:27,520 --> 00:27:31,200
uh from scratch like creating your own

00:27:29,520 --> 00:27:33,279
data set be it for like you know

00:27:31,200 --> 00:27:34,880
uh fun purposes or to solve like a

00:27:33,279 --> 00:27:36,960
specific problem you have in mind

00:27:34,880 --> 00:27:38,320
um i recently wrote like a book with my

00:27:36,960 --> 00:27:39,600
co-author which is known as sculpting

00:27:38,320 --> 00:27:41,840
data for ml

00:27:39,600 --> 00:27:42,880
uh it is a hands-on book in python and

00:27:41,840 --> 00:27:44,399
beautiful soup

00:27:42,880 --> 00:27:47,520
so you'll get like code snippets and

00:27:44,399 --> 00:27:49,039
access to a github repository as well

00:27:47,520 --> 00:27:50,799
it tells you about significance of data

00:27:49,039 --> 00:27:51,520
and machine learning identification of

00:27:50,799 --> 00:27:53,520
like

00:27:51,520 --> 00:27:55,520
relevant data signals if you have like

00:27:53,520 --> 00:27:57,200
bundles of data how do you

00:27:55,520 --> 00:27:58,720
like identify which is important which

00:27:57,200 --> 00:28:01,120
is not and

00:27:58,720 --> 00:28:02,960
um end-to-end process of how to collect

00:28:01,120 --> 00:28:04,080
data and basically construct your own

00:28:02,960 --> 00:28:07,679
data set

00:28:04,080 --> 00:28:09,279
with uh python code examples um and it

00:28:07,679 --> 00:28:10,559
also helps to feature engineering and

00:28:09,279 --> 00:28:12,559
data pre-processing

00:28:10,559 --> 00:28:14,720
so if you're someone who's interested in

00:28:12,559 --> 00:28:16,720
this uh this book is endorsed by leading

00:28:14,720 --> 00:28:18,480
ml experts microphone of like lawrence

00:28:16,720 --> 00:28:20,640
morning from google julian mccauley from

00:28:18,480 --> 00:28:23,840
uc san diego and ranking from

00:28:20,640 --> 00:28:26,080
uh microsoft you can definitely check

00:28:23,840 --> 00:28:27,200
the book out and with that thank you so

00:28:26,080 --> 00:28:29,679
much uh for

00:28:27,200 --> 00:28:31,520
uh listening to me and i just wanted to

00:28:29,679 --> 00:28:34,960
share different tools

00:28:31,520 --> 00:28:34,960
but we can go on to questions

00:28:40,720 --> 00:28:43,840
right so there's some questions in the

00:28:42,000 --> 00:28:47,039
chat for you jason

00:28:43,840 --> 00:28:49,520
yeah sure definitely um

00:28:47,039 --> 00:28:51,600
we are watching hi hi uh shambi says

00:28:49,520 --> 00:28:52,880
hello from colombia and she has enjoyed

00:28:51,600 --> 00:28:55,919
the book almost

00:28:52,880 --> 00:28:57,679
hey sami thank you so much uh yeah i i

00:28:55,919 --> 00:28:58,080
saw on twitter that you won the giveaway

00:28:57,679 --> 00:29:00,000
so

00:28:58,080 --> 00:29:01,440
i thought didn't give away the open

00:29:00,000 --> 00:29:02,240
source meet app so in case you're

00:29:01,440 --> 00:29:03,679
interested

00:29:02,240 --> 00:29:05,679
you can also everyone can check out the

00:29:03,679 --> 00:29:08,320
book but yeah thank you so much

00:29:05,679 --> 00:29:10,159
john said um you look very familiar have

00:29:08,320 --> 00:29:12,240
you done some online courses

00:29:10,159 --> 00:29:14,159
talking about me uh i've done like a

00:29:12,240 --> 00:29:16,159
couple of like open source talks and

00:29:14,159 --> 00:29:18,720
machine learning talks and

00:29:16,159 --> 00:29:19,919
quite active on twitter if that you say

00:29:18,720 --> 00:29:21,679
so but yeah

00:29:19,919 --> 00:29:23,120
can we get the link for the slides

00:29:21,679 --> 00:29:25,039
definitely um

00:29:23,120 --> 00:29:26,640
i haven't like posted them online

00:29:25,039 --> 00:29:27,600
somewhere but yeah i can definitely

00:29:26,640 --> 00:29:29,440
share the links

00:29:27,600 --> 00:29:31,120
once i have or i can now start to you

00:29:29,440 --> 00:29:32,480
know maybe send it in the newsletter or

00:29:31,120 --> 00:29:35,600
something

00:29:32,480 --> 00:29:38,840
uh do you happen to have uh

00:29:35,600 --> 00:29:41,840
yeah sure um i can

00:29:38,840 --> 00:29:41,840
just

00:29:42,399 --> 00:29:49,440
sorry i'm a bit slow at this

00:29:45,520 --> 00:29:51,520
yes um going back to the chat uh you um

00:29:49,440 --> 00:29:52,559
can we get link for the size of says

00:29:51,520 --> 00:29:54,080
i'll post and phone

00:29:52,559 --> 00:29:55,760
i happen to have a link where we can

00:29:54,080 --> 00:29:56,399
find all open source libraries for data

00:29:55,760 --> 00:29:58,320
science

00:29:56,399 --> 00:29:59,520
i'm not sure but if i can share the link

00:29:58,320 --> 00:30:00,720
of the slides of knowledge like google

00:29:59,520 --> 00:30:03,840
their map

00:30:00,720 --> 00:30:03,840
i guess that would be it

00:30:04,799 --> 00:30:08,240
so this is uh can you please share the

00:30:07,200 --> 00:30:11,120
name of the book again

00:30:08,240 --> 00:30:13,600
for sure so this is the link and the

00:30:11,120 --> 00:30:18,720
book is known as sculpting data for ml

00:30:13,600 --> 00:30:18,720
uh the first act of machine learning

00:30:19,440 --> 00:30:23,840
how do i send it to all yeah

00:30:25,600 --> 00:30:29,840
so uh if you someone who's who likes

00:30:28,399 --> 00:30:30,880
like data science and feature

00:30:29,840 --> 00:30:33,600
engineering and

00:30:30,880 --> 00:30:34,000
pre-processing and transformation before

00:30:33,600 --> 00:30:35,840
uh

00:30:34,000 --> 00:30:37,520
like obviously we do talk about models

00:30:35,840 --> 00:30:39,840
in the last chapter but initially it's

00:30:37,520 --> 00:30:41,760
more about like code examples in python

00:30:39,840 --> 00:30:43,360
uh how to like you know create your own

00:30:41,760 --> 00:30:45,120
data set if you don't want to use

00:30:43,360 --> 00:30:46,960
and these are based on like a real-life

00:30:45,120 --> 00:30:48,799
data sets that you put up on kegel and

00:30:46,960 --> 00:30:50,960
everything like lots of love

00:30:48,799 --> 00:30:54,320
uh so yeah definitely check it out and

00:30:50,960 --> 00:30:54,320
look forward to your feedback

00:30:54,640 --> 00:30:59,360
um your questions

00:31:01,600 --> 00:31:05,360
actually you know what i can just

00:31:03,600 --> 00:31:19,840
download it as pdf

00:31:05,360 --> 00:31:19,840
and maybe send it right here

00:31:30,840 --> 00:31:33,840
uh

00:31:35,760 --> 00:31:39,360
there's also some questions in the q a

00:31:37,519 --> 00:31:42,640
do you see those

00:31:39,360 --> 00:31:47,120
oh okay yeah um sorry i didn't uh

00:31:42,640 --> 00:31:49,039
yeah so i'm just trying to share my um

00:31:47,120 --> 00:31:51,679
i just shared the slides if someone's

00:31:49,039 --> 00:31:55,120
interested in like i shared like a pdf

00:31:51,679 --> 00:31:55,120
and then go back to q a

00:31:55,200 --> 00:31:59,120
okay can we get the link uh on rudolph i

00:31:58,000 --> 00:32:02,640
just posted the

00:31:59,120 --> 00:32:04,159
file itself on the chat mark it says

00:32:02,640 --> 00:32:06,000
solutions for graph based data rather

00:32:04,159 --> 00:32:07,919
than tabular data mining graphs clean

00:32:06,000 --> 00:32:11,919
and convert into tabular data from

00:32:07,919 --> 00:32:13,360
pandas oh okay so i'll be like very

00:32:11,919 --> 00:32:14,960
honest um i haven't

00:32:13,360 --> 00:32:16,640
mentioned about tools which i haven't

00:32:14,960 --> 00:32:18,559
used that personally and personally i've

00:32:16,640 --> 00:32:21,039
always worked with tabular data

00:32:18,559 --> 00:32:22,480
or so i might not be like someone who's

00:32:21,039 --> 00:32:24,640
like

00:32:22,480 --> 00:32:26,320
good enough kind of like to recommend uh

00:32:24,640 --> 00:32:28,000
solutions for graph based data i hope

00:32:26,320 --> 00:32:31,760
you understand that

00:32:28,000 --> 00:32:35,440
um uh

00:32:31,760 --> 00:32:37,039
yeah and sharp uh saurabhs and

00:32:35,440 --> 00:32:38,799
she says you talked a bit about

00:32:37,039 --> 00:32:40,399
observability with tensorflow

00:32:38,799 --> 00:32:42,480
board could you talk about tools for

00:32:40,399 --> 00:32:44,720
other observability tools example

00:32:42,480 --> 00:32:46,159
tools to extract your metrics specifying

00:32:44,720 --> 00:32:47,440
dashboard includes etc

00:32:46,159 --> 00:32:49,519
especially in production since data

00:32:47,440 --> 00:32:51,440
science yeah of course

00:32:49,519 --> 00:32:53,519
so uh i can talk from my experience so

00:32:51,440 --> 00:32:56,799
currently i've been using uh

00:32:53,519 --> 00:32:57,279
uh with gcp and i think it has like a

00:32:56,799 --> 00:33:00,240
nice

00:32:57,279 --> 00:33:01,120
uh platform for like uh like nice

00:33:00,240 --> 00:33:03,519
dashboard

00:33:01,120 --> 00:33:05,519
to load and extract rules so not only i

00:33:03,519 --> 00:33:08,799
can see my entire pipeline in there

00:33:05,519 --> 00:33:10,640
like gcp and in conjugation uh

00:33:08,799 --> 00:33:12,080
and it also it's good in production

00:33:10,640 --> 00:33:12,559
because it's something that we're using

00:33:12,080 --> 00:33:15,120
and

00:33:12,559 --> 00:33:18,640
um we can always see metrics online so

00:33:15,120 --> 00:33:18,640
that is something that i'd recommend

00:33:19,039 --> 00:33:22,240
uh yeah i hope that answered all your

00:33:21,519 --> 00:33:39,840
questions

00:33:22,240 --> 00:33:39,840
um any other questions that i could help

00:33:53,919 --> 00:33:59,440
question just came up in the q a

00:33:57,519 --> 00:34:01,039
okay is it possible to do machine

00:33:59,440 --> 00:34:02,559
learning and building without actual

00:34:01,039 --> 00:34:06,000
coding

00:34:02,559 --> 00:34:09,679
so uh selena i would say um

00:34:06,000 --> 00:34:11,280
it is like as i said like there are um

00:34:09,679 --> 00:34:13,040
programs like weka you know you could

00:34:11,280 --> 00:34:14,960
get started with machine learning if you

00:34:13,040 --> 00:34:17,440
want to just like fill out how it feels

00:34:14,960 --> 00:34:19,440
like you know how it would work and all

00:34:17,440 --> 00:34:20,960
but in all honesty if you want to do

00:34:19,440 --> 00:34:21,280
like lots of customization and you know

00:34:20,960 --> 00:34:23,599
like

00:34:21,280 --> 00:34:25,119
really grow forward uh coding is

00:34:23,599 --> 00:34:26,399
something that i would highly recommend

00:34:25,119 --> 00:34:28,079
you could do like a bit of like data

00:34:26,399 --> 00:34:28,960
analysis and all the like sql where you

00:34:28,079 --> 00:34:31,520
don't require a lot of

00:34:28,960 --> 00:34:33,919
programming skills but it's definitely

00:34:31,520 --> 00:34:35,599
you have an upper hand if uh

00:34:33,919 --> 00:34:36,960
you can learn programming you can you

00:34:35,599 --> 00:34:39,040
know start to

00:34:36,960 --> 00:34:40,800
maybe in parallel like start with gui

00:34:39,040 --> 00:34:41,280
and like learn the basics of machine

00:34:40,800 --> 00:34:44,159
learning

00:34:41,280 --> 00:34:45,280
on like data science but when you have

00:34:44,159 --> 00:34:47,200
like grow further

00:34:45,280 --> 00:34:48,320
coding is definitely that will come in

00:34:47,200 --> 00:34:49,760
handy because you would have to do like

00:34:48,320 --> 00:34:51,280
a lot of customizations and you know

00:34:49,760 --> 00:34:53,440
tweaks here and there which

00:34:51,280 --> 00:34:54,720
uh pre built-in tools might not allow

00:34:53,440 --> 00:34:57,919
you to do that

00:34:54,720 --> 00:34:57,919
uh i hope that happens

00:34:59,440 --> 00:35:01,920
would you share your experience in

00:35:00,720 --> 00:35:03,280
dealing with the pace of machine

00:35:01,920 --> 00:35:07,040
learning

00:35:03,280 --> 00:35:10,480
it moves quickly yeah

00:35:07,040 --> 00:35:12,160
that's actually so true so uh one of the

00:35:10,480 --> 00:35:13,680
reason like one of the things that i

00:35:12,160 --> 00:35:14,560
would suggest doing is like when you

00:35:13,680 --> 00:35:16,800
work

00:35:14,560 --> 00:35:18,000
somewhere or when you're a student

00:35:16,800 --> 00:35:20,079
always um

00:35:18,000 --> 00:35:22,079
like focus on the basics that's for sure

00:35:20,079 --> 00:35:23,920
but you can you know maybe try joining a

00:35:22,079 --> 00:35:25,920
group like a reading group or something

00:35:23,920 --> 00:35:26,960
where people do like research readings

00:35:25,920 --> 00:35:30,000
and so on

00:35:26,960 --> 00:35:31,760
uh and like that's for us like

00:35:30,000 --> 00:35:33,440
for me at work that that's what has

00:35:31,760 --> 00:35:34,960
helped because people you know like for

00:35:33,440 --> 00:35:35,920
the new contents that come up and new

00:35:34,960 --> 00:35:37,119
research papers

00:35:35,920 --> 00:35:38,800
they'll share so you don't have like

00:35:37,119 --> 00:35:39,520
read every paper on yourself like by

00:35:38,800 --> 00:35:40,880
yourself

00:35:39,520 --> 00:35:42,079
there would be someone who'd explain the

00:35:40,880 --> 00:35:43,359
idea and if you find that idea

00:35:42,079 --> 00:35:44,079
interesting you could always like go

00:35:43,359 --> 00:35:46,160
ahead

00:35:44,079 --> 00:35:48,240
but yeah definitely it moves really fast

00:35:46,160 --> 00:35:50,480
and it's difficult to keep up but

00:35:48,240 --> 00:35:51,760
sometimes it's okay not to like grasp

00:35:50,480 --> 00:35:54,320
everything that comes our way

00:35:51,760 --> 00:35:56,079
like take it slow and like filter

00:35:54,320 --> 00:35:57,520
whatever you need and whatever

00:35:56,079 --> 00:36:01,200
like suits you and whatever interests

00:35:57,520 --> 00:36:01,200
you the best so totally fine

00:36:01,440 --> 00:36:05,839
and selena says do you know any website

00:36:03,440 --> 00:36:08,160
or courses to take to learn python

00:36:05,839 --> 00:36:09,280
so uh to learn python i would uh

00:36:08,160 --> 00:36:11,760
recommend uh the

00:36:09,280 --> 00:36:14,000
python documentation itself so for the

00:36:11,760 --> 00:36:16,160
basics that would be really helpful

00:36:14,000 --> 00:36:17,920
and um for example if you want to do

00:36:16,160 --> 00:36:19,440
like

00:36:17,920 --> 00:36:21,119
try going with some projects if you want

00:36:19,440 --> 00:36:22,960
to do like online courses

00:36:21,119 --> 00:36:24,320
university courses are nice but then

00:36:22,960 --> 00:36:28,400
again like um

00:36:24,320 --> 00:36:31,359
websites like udacity or uh

00:36:28,400 --> 00:36:32,400
dex they might help i can try finding a

00:36:31,359 --> 00:36:34,480
few from my end

00:36:32,400 --> 00:36:36,640
and help but it's been like long uh

00:36:34,480 --> 00:36:39,760
since i started fighting so

00:36:36,640 --> 00:36:43,280
not sure uh yeah

00:36:39,760 --> 00:36:45,119
i can try looking them up but yeah again

00:36:43,280 --> 00:36:46,640
my knowledge would be as limited because

00:36:45,119 --> 00:36:48,320
um it's been

00:36:46,640 --> 00:36:50,390
a lot of years since i've started with

00:36:48,320 --> 00:36:52,240
just python

00:36:50,390 --> 00:36:53,760
[Music]

00:36:52,240 --> 00:36:55,520
could you also talk about model training

00:36:53,760 --> 00:36:57,440
and serving there are some magazines

00:36:55,520 --> 00:36:58,880
like sagemaker.ml but would love to know

00:36:57,440 --> 00:37:00,400
some open source alternatives your

00:36:58,880 --> 00:37:03,839
experience with them anyway

00:37:00,400 --> 00:37:05,680
hi so i do not have experience with uh

00:37:03,839 --> 00:37:08,320
like automated managed services like

00:37:05,680 --> 00:37:09,760
model training and serving because uh

00:37:08,320 --> 00:37:11,359
i feel that i've been currently working

00:37:09,760 --> 00:37:12,800
and we've been trying to do it ourselves

00:37:11,359 --> 00:37:14,880
uh so i would have

00:37:12,800 --> 00:37:15,920
and uh they are not open source at the

00:37:14,880 --> 00:37:17,760
moment so

00:37:15,920 --> 00:37:19,200
would have shared if i would have any

00:37:17,760 --> 00:37:23,680
but yeah currently no

00:37:19,200 --> 00:37:25,200
uh suggestions regarding that sorry um

00:37:23,680 --> 00:37:26,960
do you have recommendations for library

00:37:25,200 --> 00:37:30,800
for doing ml grade say

00:37:26,960 --> 00:37:33,760
connected vehicles um

00:37:30,800 --> 00:37:35,040
not uh really like again i said uh i

00:37:33,760 --> 00:37:37,839
only share the tools that i have

00:37:35,040 --> 00:37:39,119
experience with because

00:37:37,839 --> 00:37:41,359
yeah it's easier to answer questions

00:37:39,119 --> 00:37:43,760
regarding them but yeah i don't have any

00:37:41,359 --> 00:37:47,040
uh like i haven't checked them out like

00:37:43,760 --> 00:37:47,040
for vehicles etc

00:37:48,880 --> 00:37:52,720
but i believe opencv might be helpful

00:37:51,040 --> 00:37:54,400
because when you're kind of like

00:37:52,720 --> 00:37:55,839
driving cars and stuff you need to do

00:37:54,400 --> 00:37:57,839
object detection and

00:37:55,839 --> 00:37:59,440
uh stuff like that so maybe getting like

00:37:57,839 --> 00:38:00,000
if you're just getting started with that

00:37:59,440 --> 00:38:02,320
uh

00:38:00,000 --> 00:38:03,520
that might be like a really helpful uh

00:38:02,320 --> 00:38:07,040
library to look at but

00:38:03,520 --> 00:38:07,040
yeah not further right now

00:38:07,440 --> 00:38:12,960
uh yeshua says hi hi um

00:38:11,359 --> 00:38:14,400
john says the only link i see is the

00:38:12,960 --> 00:38:16,240
link to your book on amazon i really

00:38:14,400 --> 00:38:19,280
appreciate but that do not sling

00:38:16,240 --> 00:38:20,480
can you please oh uh can someone confirm

00:38:19,280 --> 00:38:33,839
that i

00:38:20,480 --> 00:38:33,839
have sent the file itself on the chat

00:38:34,000 --> 00:38:36,240
uh

00:38:37,760 --> 00:38:41,280
yeah let me just confirm because i

00:38:39,119 --> 00:38:41,520
thought i just posted an entire file as

00:38:41,280 --> 00:38:44,800
it

00:38:41,520 --> 00:38:47,839
is oh got it got

00:38:44,800 --> 00:38:47,839
marcus said yes

00:38:56,880 --> 00:39:00,400
okay cool uh yes this is any free

00:38:59,520 --> 00:39:02,560
documentation

00:39:00,400 --> 00:39:04,560
uh documentation that you found helpful

00:39:02,560 --> 00:39:07,839
to start off with machine learning

00:39:04,560 --> 00:39:08,400
for um sure so as i said uh things that

00:39:07,839 --> 00:39:09,760
i found

00:39:08,400 --> 00:39:12,160
interesting while machine learning

00:39:09,760 --> 00:39:15,040
especially the first half would be like

00:39:12,160 --> 00:39:16,960
uh i documented in my own book so if

00:39:15,040 --> 00:39:19,200
you'd like to check that out yes

00:39:16,960 --> 00:39:20,880
uh because um all the things that i

00:39:19,200 --> 00:39:21,520
learned from work from various different

00:39:20,880 --> 00:39:25,040
courses

00:39:21,520 --> 00:39:26,960
uh my school projects and uh tutorials

00:39:25,040 --> 00:39:28,400
and all so i've like documented them in

00:39:26,960 --> 00:39:30,000
my own work and

00:39:28,400 --> 00:39:31,680
uh the first four chapters would be

00:39:30,000 --> 00:39:33,520
heavily inclined towards data because

00:39:31,680 --> 00:39:35,680
that's what i feel as well like

00:39:33,520 --> 00:39:37,359
uh how good your model is dependent on

00:39:35,680 --> 00:39:38,560
how good your data is and then the last

00:39:37,359 --> 00:39:41,280
chapters

00:39:38,560 --> 00:39:42,079
gives you like a brief overview of like

00:39:41,280 --> 00:39:44,400
all the different

00:39:42,079 --> 00:39:45,760
um kinds of machine learning models that

00:39:44,400 --> 00:39:47,040
you have and what kind of data would

00:39:45,760 --> 00:39:48,480
suit you the best so

00:39:47,040 --> 00:39:51,040
yeah that is something that i'd

00:39:48,480 --> 00:39:51,040
recommend

00:39:55,280 --> 00:40:02,800
alternative yes uh

00:39:59,359 --> 00:40:06,720
yeah thank you mark yeah thank you

00:40:02,800 --> 00:40:08,160
um jan i hope you got the slides now uh

00:40:06,720 --> 00:40:11,839
it'll be great if you could like let me

00:40:08,160 --> 00:40:11,839
know and so i can chat again

00:40:34,319 --> 00:40:39,839
i'll just show it again

00:40:50,839 --> 00:40:57,680
oh i tried sharing it again

00:40:54,560 --> 00:40:57,680
and just panelist

00:41:03,040 --> 00:41:06,880
otherwise i'll just like host online and

00:41:04,880 --> 00:41:08,400
like ask doc to lecture it in a

00:41:06,880 --> 00:41:10,800
newsletter or something like that i

00:41:08,400 --> 00:41:10,800
could do

00:41:17,760 --> 00:41:22,800
oh yeah she'll did you get

00:41:20,960 --> 00:41:24,480
so if i'm pronouncing everyone's names

00:41:22,800 --> 00:41:28,240
wrong but yeah did you get

00:41:24,480 --> 00:41:30,800
access to the slides um because i did

00:41:28,240 --> 00:41:30,800
post it

00:41:31,119 --> 00:41:35,839
okay do we have more q a

00:41:47,680 --> 00:41:51,520
yeah i think if it's not working maybe

00:41:49,520 --> 00:41:54,079
i'll have to like ask someone to like

00:41:51,520 --> 00:41:58,400
send it over as a link when i host it so

00:41:54,079 --> 00:42:03,839
yeah sorry about that folks uh

00:41:58,400 --> 00:42:03,839
i wish i could send you

00:42:06,800 --> 00:42:13,599
uh if you like um send me

00:42:11,119 --> 00:42:17,839
yeah maybe connect with me on twitter

00:42:13,599 --> 00:42:17,839
perhaps i can send you later then

00:42:21,920 --> 00:42:27,440
sorry folks i haven't hosted them yet so

00:42:25,119 --> 00:42:28,560
what is the best programming language so

00:42:27,440 --> 00:42:30,960
i talked about in my

00:42:28,560 --> 00:42:32,800
um just in the presentation that i would

00:42:30,960 --> 00:42:35,280
say python like i would highly recommend

00:42:32,800 --> 00:42:35,280
python

00:42:36,960 --> 00:42:41,119
so yeah that is something that i would

00:42:38,640 --> 00:42:41,119
recommend

00:42:42,480 --> 00:42:45,440
you could get started with power but

00:42:43,920 --> 00:42:46,800
then if you look at all the libraries

00:42:45,440 --> 00:42:48,800
and frameworks that we've talked about

00:42:46,800 --> 00:42:50,319
and which are like mostly popular and

00:42:48,800 --> 00:42:52,480
people use it in the industry as well as

00:42:50,319 --> 00:42:59,839
in research academia

00:42:52,480 --> 00:42:59,839
uh python is the way to go

00:43:01,280 --> 00:43:04,880
oh strangely i don't know why it doesn't

00:43:03,760 --> 00:43:13,839
uh

00:43:04,880 --> 00:43:13,839
show the file

00:43:35,359 --> 00:43:41,839
yeah sure yeah i i and dm you i don't

00:43:38,000 --> 00:43:41,839
worry about that

00:43:43,440 --> 00:43:47,119
do you think ruby can incorporate

00:43:45,040 --> 00:43:50,800
scripts can do machine learning

00:43:47,119 --> 00:43:54,319
um yeah i believe like they can like for

00:43:50,800 --> 00:43:56,079
sure uh

00:43:54,319 --> 00:43:57,599
you can do like cross-platform

00:43:56,079 --> 00:44:00,640
integrations uh but

00:43:57,599 --> 00:44:02,400
once um it's easier for you to do like

00:44:00,640 --> 00:44:03,920
everything in the language i believe

00:44:02,400 --> 00:44:06,560
because especially

00:44:03,920 --> 00:44:08,400
like not building like a very um

00:44:06,560 --> 00:44:11,119
high-tech uh system like

00:44:08,400 --> 00:44:12,000
uh you're not doing like a huge pipeline

00:44:11,119 --> 00:44:14,400
let's say

00:44:12,000 --> 00:44:15,440
um we're not doing um for example when

00:44:14,400 --> 00:44:17,040
at work we do

00:44:15,440 --> 00:44:18,960
use like a lot of languages to do like a

00:44:17,040 --> 00:44:20,640
lot of passive integrations

00:44:18,960 --> 00:44:22,880
uh but when you're just like starting

00:44:20,640 --> 00:44:25,359
out and uh trying to different things

00:44:22,880 --> 00:44:26,880
um definitely we can incorporate but

00:44:25,359 --> 00:44:30,400
then having something that

00:44:26,880 --> 00:44:32,000
python can do which ruby also does

00:44:30,400 --> 00:44:33,839
or would be great on your end because

00:44:32,000 --> 00:44:35,280
you just record programming skills in

00:44:33,839 --> 00:44:37,839
that language

00:44:35,280 --> 00:44:51,839
and help you with integrations like save

00:44:37,839 --> 00:44:51,839
you some time

00:44:54,640 --> 00:44:59,200
thank you folks uh that is time yeah

00:44:57,920 --> 00:45:01,280
good to see you

00:44:59,200 --> 00:45:03,040
uh like yeah e meeting everyone if you

00:45:01,280 --> 00:45:04,640
and uh definitely send me a message on

00:45:03,040 --> 00:45:07,200
twitter or like

00:45:04,640 --> 00:45:08,720
you can find me on my website and if you

00:45:07,200 --> 00:45:09,200
have any questions feel free to reach

00:45:08,720 --> 00:45:19,040
out

00:45:09,200 --> 00:45:28,000
and i'll see how i can share my slides

00:45:19,040 --> 00:45:28,000

YouTube URL: https://www.youtube.com/watch?v=HglHw8YnAjY


