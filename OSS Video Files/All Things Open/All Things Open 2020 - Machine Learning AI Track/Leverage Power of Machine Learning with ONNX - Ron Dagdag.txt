Title: Leverage Power of Machine Learning with ONNX - Ron Dagdag
Publication date: 2020-12-14
Playlist: All Things Open 2020 - Machine Learning AI Track
Description: 
	Presented by: Ron Dagdag, Spacee
Presented at All Things Open 2020 - Machine Learning/AI Track

Abstract: Have you ever wanted to make your apps “smarter”? This session will cover what every ML/AI developer should know about Open Neural Network Exchange (ONNX) . Why it’s important and how it can reduce friction in incorporating machine learning models to your apps. We will show how to train models using the framework of your choice, save or convert models into ONNX, and deploy to cloud and edge using a high-performance runtime.
Captions: 
	00:00:05,120 --> 00:00:09,280
good morning

00:00:06,480 --> 00:00:10,320
good evening good afternoon anywhere

00:00:09,280 --> 00:00:13,360
around the world

00:00:10,320 --> 00:00:15,360
with our virtual conference today

00:00:13,360 --> 00:00:17,760
my name is ron dagdag let me share my

00:00:15,360 --> 00:00:21,439
screen real quick

00:00:17,760 --> 00:00:22,800
all right and today we'll be talking

00:00:21,439 --> 00:00:26,400
about leveraging

00:00:22,800 --> 00:00:30,720
the power of machine learning with onyx

00:00:26,400 --> 00:00:33,840
hi my name is ron dagdag i on twitter

00:00:30,720 --> 00:00:37,520
my twitter's handle is at ron dagdag

00:00:33,840 --> 00:00:39,360
and today

00:00:37,520 --> 00:00:40,960
just to clear things up we're going to

00:00:39,360 --> 00:00:44,000
be talking about onyx

00:00:40,960 --> 00:00:46,640
not for you know

00:00:44,000 --> 00:00:48,879
for pokemon audience we're not going to

00:00:46,640 --> 00:00:50,399
be talking about the pokemon onyx and

00:00:48,879 --> 00:00:52,719
also not the mineral

00:00:50,399 --> 00:00:54,559
onyx if you're kind of confused with the

00:00:52,719 --> 00:00:58,079
title that is on

00:00:54,559 --> 00:01:01,280
the agenda so if you're interested

00:00:58,079 --> 00:01:04,000
in getting information about

00:01:01,280 --> 00:01:04,960
the slides or the presentation i have

00:01:04,000 --> 00:01:08,000
today

00:01:04,960 --> 00:01:09,520
you can go to this link or qr code

00:01:08,000 --> 00:01:12,080
if you want to follow through i'm also

00:01:09,520 --> 00:01:16,720
going to post this later on

00:01:12,080 --> 00:01:16,720
at this end of my presentation

00:01:17,040 --> 00:01:20,159
if you're my name is ron dagdag i'm

00:01:19,280 --> 00:01:22,320
interested in

00:01:20,159 --> 00:01:24,080
augmented reality virtual reality and

00:01:22,320 --> 00:01:25,439
internet of things and the convergence

00:01:24,080 --> 00:01:29,119
of all those

00:01:25,439 --> 00:01:31,200
so we think about

00:01:29,119 --> 00:01:33,680
programming the traditional programming

00:01:31,200 --> 00:01:35,280
is about this way right you

00:01:33,680 --> 00:01:36,960
figure out an algorithm and you have a

00:01:35,280 --> 00:01:42,240
series of input

00:01:36,960 --> 00:01:42,240
and just it spits out the answers

00:01:42,320 --> 00:01:45,759
in machine learning it flipped the other

00:01:44,560 --> 00:01:48,960
way around right

00:01:45,759 --> 00:01:52,560
you have you have the same input but

00:01:48,960 --> 00:01:53,280
you have answers meaning the desired

00:01:52,560 --> 00:01:55,759
output

00:01:53,280 --> 00:01:56,719
and you train the machine to build an

00:01:55,759 --> 00:01:59,119
algorithm

00:01:56,719 --> 00:01:59,119
for you

00:02:02,079 --> 00:02:05,759
so in traditional programming the way we

00:02:04,960 --> 00:02:07,600
look at it

00:02:05,759 --> 00:02:08,879
right you have your algorithm your input

00:02:07,600 --> 00:02:10,239
and your answers

00:02:08,879 --> 00:02:12,160
and then of course in machine learning

00:02:10,239 --> 00:02:15,280
world we have the answers input

00:02:12,160 --> 00:02:17,440
and spits out an algorithm

00:02:15,280 --> 00:02:19,520
so in machine learning world that's

00:02:17,440 --> 00:02:22,560
called training data

00:02:19,520 --> 00:02:23,840
and we use a training frame framework to

00:02:22,560 --> 00:02:26,480
spit out a model

00:02:23,840 --> 00:02:28,640
and that model we would use for our

00:02:26,480 --> 00:02:32,160
program

00:02:28,640 --> 00:02:36,400
to deliver

00:02:32,160 --> 00:02:39,680
that and it's called inferencing

00:02:36,400 --> 00:02:43,680
and we use a machine learning runtime

00:02:39,680 --> 00:02:45,840
in order inferencing runtime in order to

00:02:43,680 --> 00:02:47,360
spit you know spits out our answer and

00:02:45,840 --> 00:02:48,000
then of course the answers to we get

00:02:47,360 --> 00:02:50,080
there

00:02:48,000 --> 00:02:53,920
we collect them as part of our training

00:02:50,080 --> 00:02:56,640
data as a cycle

00:02:53,920 --> 00:02:58,159
guys if you have questions feel free to

00:02:56,640 --> 00:03:05,680
place them in the chat

00:02:58,159 --> 00:03:09,360
and also we will answer them for you

00:03:05,680 --> 00:03:12,560
so typically in

00:03:09,360 --> 00:03:14,879
you know in machine learning

00:03:12,560 --> 00:03:16,480
right uh there's machine learning

00:03:14,879 --> 00:03:16,879
frameworks that is available out there

00:03:16,480 --> 00:03:19,519
and

00:03:16,879 --> 00:03:20,319
how you typically would do it you have

00:03:19,519 --> 00:03:22,959
high torch

00:03:20,319 --> 00:03:24,000
device or you you have pi torch you

00:03:22,959 --> 00:03:27,040
write it in pi

00:03:24,000 --> 00:03:28,239
torch and you run it locally in your

00:03:27,040 --> 00:03:30,239
machine

00:03:28,239 --> 00:03:32,799
and then i found out you know

00:03:30,239 --> 00:03:36,239
researching more about ai

00:03:32,799 --> 00:03:38,480
and there's a bunch more uh machine

00:03:36,239 --> 00:03:40,000
learning uh frameworks out there just

00:03:38,480 --> 00:03:42,080
like any you know if you're a

00:03:40,000 --> 00:03:43,680
javascript developer there's a lot of

00:03:42,080 --> 00:03:45,599
javascript developer

00:03:43,680 --> 00:03:47,120
javascript frameworks the same way in

00:03:45,599 --> 00:03:49,040
the machine learning world

00:03:47,120 --> 00:03:50,879
and of course when you try to deploy

00:03:49,040 --> 00:03:53,840
these machine learning

00:03:50,879 --> 00:03:55,439
models you have to figure out where to

00:03:53,840 --> 00:03:55,760
deploy and then there's different types

00:03:55,439 --> 00:03:58,959
now

00:03:55,760 --> 00:04:02,239
right you deploy it through cpu or gpu

00:03:58,959 --> 00:04:03,120
you use it use your phone or you deploy

00:04:02,239 --> 00:04:05,280
in the cloud

00:04:03,120 --> 00:04:07,599
in different areas right and internet of

00:04:05,280 --> 00:04:10,400
things devices

00:04:07,599 --> 00:04:11,280
and that's what onyx does and that's the

00:04:10,400 --> 00:04:15,040
bridge

00:04:11,280 --> 00:04:18,560
between the frameworks into

00:04:15,040 --> 00:04:21,759
the deployment side which machines it

00:04:18,560 --> 00:04:21,759
would uh would run

00:04:21,840 --> 00:04:28,160
so onyx it's open neural network

00:04:25,199 --> 00:04:30,080
exchange it's an open format for machine

00:04:28,160 --> 00:04:31,120
learning model it is on github it's open

00:04:30,080 --> 00:04:33,680
source

00:04:31,120 --> 00:04:35,120
and there's links out there you can you

00:04:33,680 --> 00:04:35,840
can visit if you're interested in

00:04:35,120 --> 00:04:39,280
learning more

00:04:35,840 --> 00:04:41,440
about about onyx and

00:04:39,280 --> 00:04:43,199
through the years there's a lot of

00:04:41,440 --> 00:04:45,360
partners out there that

00:04:43,199 --> 00:04:46,479
have in you know integrated their

00:04:45,360 --> 00:04:50,800
technology into

00:04:46,479 --> 00:04:54,240
onyx and some uh added capabilities

00:04:50,800 --> 00:04:54,800
into it was started by a partnership

00:04:54,240 --> 00:04:57,759
with

00:04:54,800 --> 00:04:58,320
microsoft and also facebook but through

00:04:57,759 --> 00:04:59,600
the years

00:04:58,320 --> 00:05:02,320
all these different companies have

00:04:59,600 --> 00:05:02,320
collaborated

00:05:03,199 --> 00:05:07,360
if you look at it on github it's about 9

00:05:05,360 --> 00:05:10,880
000 stars out there it's a very

00:05:07,360 --> 00:05:14,479
active community 1700 pull requests

00:05:10,880 --> 00:05:18,000
about 175 contributors

00:05:14,479 --> 00:05:21,120
and it's growing and

00:05:18,000 --> 00:05:24,080
model zoo is something that you

00:05:21,120 --> 00:05:25,759
you you may be able to use existing

00:05:24,080 --> 00:05:26,639
models that you may be able to use and

00:05:25,759 --> 00:05:31,440
integrate

00:05:26,639 --> 00:05:31,440
it to your software or your programs

00:05:32,960 --> 00:05:36,560
so today our agenda we'll be talking

00:05:35,840 --> 00:05:39,759
about

00:05:36,560 --> 00:05:42,880
what is onyx and

00:05:39,759 --> 00:05:46,160
how to create an onyx model

00:05:42,880 --> 00:05:48,720
and how to do we integrate and deploy it

00:05:46,160 --> 00:05:53,759
with our existing applications or new

00:05:48,720 --> 00:05:56,240
applications that we're building

00:05:53,759 --> 00:05:57,759
so like i said on the create side right

00:05:56,240 --> 00:05:59,440
here

00:05:57,759 --> 00:06:00,880
you know that that would be your step

00:05:59,440 --> 00:06:02,479
one and then of course

00:06:00,880 --> 00:06:04,000
we'll talk about step two which is the

00:06:02,479 --> 00:06:07,520
deployment side

00:06:04,000 --> 00:06:11,520
so step one how do we create it so as

00:06:07,520 --> 00:06:15,360
data scientist or computer vision

00:06:11,520 --> 00:06:18,880
specialist treat them as

00:06:15,360 --> 00:06:22,560
the best baker in town right

00:06:18,880 --> 00:06:25,759
they are the ones that responsible for

00:06:22,560 --> 00:06:26,639
figuring out their secret recipe of your

00:06:25,759 --> 00:06:28,720
company

00:06:26,639 --> 00:06:30,639
you think about they try different

00:06:28,720 --> 00:06:33,360
algorithms they try different

00:06:30,639 --> 00:06:34,000
uh formulas or different training

00:06:33,360 --> 00:06:37,039
techniques

00:06:34,000 --> 00:06:41,360
in order to build to

00:06:37,039 --> 00:06:44,160
to create the best brand right

00:06:41,360 --> 00:06:44,160
for your company

00:06:44,960 --> 00:06:48,319
and so four ways to get an onyx model

00:06:47,680 --> 00:06:52,400
right

00:06:48,319 --> 00:06:56,639
is using the onyx model zoo

00:06:52,400 --> 00:06:59,840
azure custom vision service to convert

00:06:56,639 --> 00:07:03,039
an existing models that you've trained

00:06:59,840 --> 00:07:05,120
through pytorch or tensorflow

00:07:03,039 --> 00:07:06,080
also you can train models in machine

00:07:05,120 --> 00:07:08,639
learning

00:07:06,080 --> 00:07:11,120
and using automated machine learning

00:07:08,639 --> 00:07:11,120
techniques

00:07:12,080 --> 00:07:18,639
so onyx model zoo are

00:07:15,360 --> 00:07:20,560
converted models existing models

00:07:18,639 --> 00:07:22,960
out there so if you're interested in

00:07:20,560 --> 00:07:25,440
integrating rest net mobile net

00:07:22,960 --> 00:07:26,319
and you know image classification models

00:07:25,440 --> 00:07:28,800
that's out there

00:07:26,319 --> 00:07:30,240
check out the onyx model zoom it may

00:07:28,800 --> 00:07:32,479
already have it in there

00:07:30,240 --> 00:07:33,360
and you can just download those on those

00:07:32,479 --> 00:07:36,960
models so

00:07:33,360 --> 00:07:40,560
trader onyx is kind of like pdf

00:07:36,960 --> 00:07:44,720
right you know you write

00:07:40,560 --> 00:07:48,080
to different port processors

00:07:44,720 --> 00:07:50,479
and pdf once is a format that

00:07:48,080 --> 00:07:51,199
allows you to be able to view it in

00:07:50,479 --> 00:07:54,240
different

00:07:51,199 --> 00:07:56,879
machines you know view it in phone or

00:07:54,240 --> 00:07:58,080
be able to uh print it out without

00:07:56,879 --> 00:08:01,520
requiring the original

00:07:58,080 --> 00:08:04,639
software where it was written on

00:08:01,520 --> 00:08:08,080
as long as you have any pdf viewer

00:08:04,639 --> 00:08:10,319
so think of it that way and how we would

00:08:08,080 --> 00:08:10,319
use

00:08:10,840 --> 00:08:14,160
onyx so

00:08:14,639 --> 00:08:19,919
another way is through customvision.ai

00:08:17,759 --> 00:08:20,879
uh this is you know a lot of the cloud

00:08:19,919 --> 00:08:24,319
providers

00:08:20,879 --> 00:08:28,080
can uh create these now i'm looking at

00:08:24,319 --> 00:08:28,879
i'm showing you what what is available

00:08:28,080 --> 00:08:31,440
in azure

00:08:28,879 --> 00:08:33,039
where you can upload images and these

00:08:31,440 --> 00:08:35,279
images you can tag them

00:08:33,039 --> 00:08:36,479
and once you're stacked you can train

00:08:35,279 --> 00:08:38,399
and then export

00:08:36,479 --> 00:08:40,880
and download onyx from there so it's a

00:08:38,399 --> 00:08:45,440
three-step process that simplifies

00:08:40,880 --> 00:08:45,440
the uh vision service for you

00:08:46,399 --> 00:08:49,839
of course converting models you know

00:08:49,200 --> 00:08:52,720
different

00:08:49,839 --> 00:08:55,200
teams in you know data science teams

00:08:52,720 --> 00:08:55,760
have different expertise and different

00:08:55,200 --> 00:08:59,120
knowledge

00:08:55,760 --> 00:09:01,440
on frameworks and what they are used to

00:08:59,120 --> 00:09:04,480
or what they are trained or how they

00:09:01,440 --> 00:09:06,560
they feel best at it so

00:09:04,480 --> 00:09:08,160
it makes sense that converting models to

00:09:06,560 --> 00:09:12,240
onyx allows you to

00:09:08,160 --> 00:09:12,240
be able to deploy it

00:09:14,720 --> 00:09:18,959
so how you would convert models load an

00:09:17,839 --> 00:09:21,440
existing one

00:09:18,959 --> 00:09:22,160
you know there's converters for

00:09:21,440 --> 00:09:25,519
different

00:09:22,160 --> 00:09:28,480
type of frameworks and then you save it

00:09:25,519 --> 00:09:28,480
to an onyx model

00:09:28,959 --> 00:09:34,839
there's also a

00:09:32,000 --> 00:09:36,320
utility out there called netron that

00:09:34,839 --> 00:09:39,120
visualizes

00:09:36,320 --> 00:09:40,399
the uh graph of the operation so what

00:09:39,120 --> 00:09:43,440
onyx is doing is

00:09:40,399 --> 00:09:46,560
actually uh in internal

00:09:43,440 --> 00:09:49,200
representation of the commands or the

00:09:46,560 --> 00:09:50,399
uh you know the algorithms that is being

00:09:49,200 --> 00:09:53,120
used by your

00:09:50,399 --> 00:09:54,880
neural network or your traditional

00:09:53,120 --> 00:09:57,279
machine learning operations

00:09:54,880 --> 00:09:59,200
so it has a list of all the operations

00:09:57,279 --> 00:09:59,839
and it gets converted and uses that so

00:09:59,200 --> 00:10:03,120
it's

00:09:59,839 --> 00:10:05,519
it's an open spec

00:10:03,120 --> 00:10:08,240
so you would use netron to visualize it

00:10:05,519 --> 00:10:11,519
to it also helps developers to know

00:10:08,240 --> 00:10:15,120
what is the input and output of uh

00:10:11,519 --> 00:10:18,720
an existing model so in without

00:10:15,120 --> 00:10:21,839
going back to the data scientist and

00:10:18,720 --> 00:10:24,959
and and then and then

00:10:21,839 --> 00:10:26,560
identifying which ones right so it

00:10:24,959 --> 00:10:28,079
it looks something like this so i have

00:10:26,560 --> 00:10:30,320
netron

00:10:28,079 --> 00:10:32,000
turned on here so i can say oh these are

00:10:30,320 --> 00:10:34,399
my inputs and this is my output

00:10:32,000 --> 00:10:35,600
this is just the simplest example i can

00:10:34,399 --> 00:10:38,640
see it tells me

00:10:35,600 --> 00:10:40,079
right here what the format is and then

00:10:38,640 --> 00:10:42,880
it's only what version

00:10:40,079 --> 00:10:44,079
but the input that is required in order

00:10:42,880 --> 00:10:48,959
to run

00:10:44,079 --> 00:10:48,959
in order to use the onyx model

00:10:51,050 --> 00:10:59,200
[Music]

00:10:56,240 --> 00:11:00,399
so a typical example how you would use

00:10:59,200 --> 00:11:03,920
this in pytorch

00:11:00,399 --> 00:11:07,440
in this case i'm using alexnet and

00:11:03,920 --> 00:11:09,120
typically there is a torch.onyx.export

00:11:07,440 --> 00:11:11,040
you just have to know which one

00:11:09,120 --> 00:11:12,959
depending on the framework that you're

00:11:11,040 --> 00:11:15,120
you're using there's a way you can

00:11:12,959 --> 00:11:16,720
export to onyx and specify the output

00:11:15,120 --> 00:11:19,760
file

00:11:16,720 --> 00:11:20,800
based from that you can there's also a

00:11:19,760 --> 00:11:24,320
command line

00:11:20,800 --> 00:11:28,399
that if you want to uh to try out and uh

00:11:24,320 --> 00:11:29,519
and test and it is a lot of it is in

00:11:28,399 --> 00:11:32,000
python

00:11:29,519 --> 00:11:33,680
and uh you know like in this case it's

00:11:32,000 --> 00:11:37,040
center tensorflow onyx

00:11:33,680 --> 00:11:39,040
convert um with

00:11:37,040 --> 00:11:43,200
you know your same model path and also

00:11:39,040 --> 00:11:45,440
the output path

00:11:43,200 --> 00:11:45,440
cool

00:11:47,680 --> 00:11:54,160
uh the title talk it says onyx but it's

00:11:51,079 --> 00:11:57,680
o-n-y-x but this is called

00:11:54,160 --> 00:12:01,040
onnx just to clear it out

00:11:57,680 --> 00:12:01,920
how to train the models in azure machine

00:12:01,040 --> 00:12:04,079
learning

00:12:01,920 --> 00:12:06,160
uh so you can also use azure machine

00:12:04,079 --> 00:12:08,399
learning to to do your training or

00:12:06,160 --> 00:12:10,320
or on the cloud where you can do

00:12:08,399 --> 00:12:13,839
automated machine learning hyper

00:12:10,320 --> 00:12:16,560
parameter tuning but the idea there is

00:12:13,839 --> 00:12:17,600
you have this part where you do your

00:12:16,560 --> 00:12:19,680
experiments

00:12:17,600 --> 00:12:20,639
right and you do your training on the

00:12:19,680 --> 00:12:23,120
cloud

00:12:20,639 --> 00:12:24,720
and then there's that registration piece

00:12:23,120 --> 00:12:28,160
you know think of it as

00:12:24,720 --> 00:12:28,880
ai ops right instead of devops ai ops

00:12:28,160 --> 00:12:31,120
where

00:12:28,880 --> 00:12:32,000
you know the data scientists would do

00:12:31,120 --> 00:12:34,399
their training

00:12:32,000 --> 00:12:35,200
and then be able to register and manage

00:12:34,399 --> 00:12:39,600
that model

00:12:35,200 --> 00:12:43,680
you know the same way as we you know we

00:12:39,600 --> 00:12:45,920
publish to uh you know docker con

00:12:43,680 --> 00:12:48,000
docker registry you think about this is

00:12:45,920 --> 00:12:50,880
a you know model registry

00:12:48,000 --> 00:12:51,680
and then we now we can mix and match

00:12:50,880 --> 00:12:54,560
with this

00:12:51,680 --> 00:12:56,240
image use this model and then deploy it

00:12:54,560 --> 00:12:58,560
in the cloud

00:12:56,240 --> 00:13:01,680
so that's where you would do your art

00:12:58,560 --> 00:13:01,680
orchestration that way

00:13:02,480 --> 00:13:08,560
and of course whenever we talk about

00:13:05,680 --> 00:13:09,120
you know when we deploy machine learning

00:13:08,560 --> 00:13:11,760
models

00:13:09,120 --> 00:13:12,240
you know one thing to to consider is you

00:13:11,760 --> 00:13:13,760
know

00:13:12,240 --> 00:13:15,360
if you're a developer you're going to

00:13:13,760 --> 00:13:17,440
see this where they talk about

00:13:15,360 --> 00:13:20,160
tensors and i just want to clear out to

00:13:17,440 --> 00:13:23,440
everyone what a tensor is

00:13:20,160 --> 00:13:25,680
and uh it is a high dimensional matrices

00:13:23,440 --> 00:13:27,040
when you think about this this is a one

00:13:25,680 --> 00:13:30,720
dimensional

00:13:27,040 --> 00:13:34,079
uh tensor a tensor of dimension of

00:13:30,720 --> 00:13:35,839
six right and this one right here it is

00:13:34,079 --> 00:13:39,839
a matrix of six by four

00:13:35,839 --> 00:13:42,480
which is a tension off dimension six

00:13:39,839 --> 00:13:44,399
and four and so of course if you're

00:13:42,480 --> 00:13:45,199
doing computer vision most likely you'll

00:13:44,399 --> 00:13:48,320
have

00:13:45,199 --> 00:13:51,920
you know x y and z which is

00:13:48,320 --> 00:13:54,959
uh tensor of dimension of

00:13:51,920 --> 00:13:54,959
like in this case three

00:13:55,120 --> 00:13:58,880
four four two

00:13:56,020 --> 00:14:03,279
[Music]

00:13:58,880 --> 00:14:06,240
so we we did talk about how you create

00:14:03,279 --> 00:14:07,199
onyx models i'm going to focus the rest

00:14:06,240 --> 00:14:11,279
of my talk

00:14:07,199 --> 00:14:14,639
about how do we deploy machine learning

00:14:11,279 --> 00:14:14,639
models or onyx models

00:14:14,959 --> 00:14:22,000
so on the previous slide i talked about

00:14:18,800 --> 00:14:25,120
you know data scientist being the

00:14:22,000 --> 00:14:27,440
best baker in town but there's actually

00:14:25,120 --> 00:14:30,560
a difference between

00:14:27,440 --> 00:14:31,680
you know baker being a baker even if

00:14:30,560 --> 00:14:34,320
it's your passion

00:14:31,680 --> 00:14:36,399
becoming the best baker in town and

00:14:34,320 --> 00:14:39,279
there's that difference between

00:14:36,399 --> 00:14:40,079
starting a bakery it's a different skill

00:14:39,279 --> 00:14:43,199
set

00:14:40,079 --> 00:14:44,800
and for me i came from a software

00:14:43,199 --> 00:14:45,839
engineer background or development

00:14:44,800 --> 00:14:48,399
background

00:14:45,839 --> 00:14:49,680
and i whenever i see new technology i

00:14:48,399 --> 00:14:52,320
focus on

00:14:49,680 --> 00:14:52,880
how do you incorporate two existing

00:14:52,320 --> 00:14:56,079
systems

00:14:52,880 --> 00:14:59,199
or to so i see

00:14:56,079 --> 00:15:02,079
as software engineers we're

00:14:59,199 --> 00:15:03,279
expert we're expert at starting a bakery

00:15:02,079 --> 00:15:05,199
we know where we put

00:15:03,279 --> 00:15:07,760
need to put the cash register we know

00:15:05,199 --> 00:15:10,959
how to orchestrate systems how to

00:15:07,760 --> 00:15:14,480
uh make sure that that model or

00:15:10,959 --> 00:15:17,440
you know that bread is shippable right

00:15:14,480 --> 00:15:18,000
how do you how do you be able to scale

00:15:17,440 --> 00:15:20,399
it up

00:15:18,000 --> 00:15:22,000
right and be able to share that

00:15:20,399 --> 00:15:25,600
knowledge or share that

00:15:22,000 --> 00:15:27,839
that yummy goodness that's my analogy on

00:15:25,600 --> 00:15:27,839
it

00:15:28,560 --> 00:15:33,839
so like on this side on the deploy side

00:15:32,320 --> 00:15:34,720
you know you can look at it you can

00:15:33,839 --> 00:15:37,680
deploy it

00:15:34,720 --> 00:15:39,199
into you know in this case in azure but

00:15:37,680 --> 00:15:41,120
you can deploy it into

00:15:39,199 --> 00:15:43,040
other cloud services and what i'm trying

00:15:41,120 --> 00:15:46,160
to show here you can do

00:15:43,040 --> 00:15:49,120
it on a linux device or windows device

00:15:46,160 --> 00:15:49,600
or you can run it on an iot edge devices

00:15:49,120 --> 00:15:53,040
or

00:15:49,600 --> 00:15:53,040
a phone

00:15:53,120 --> 00:16:00,480
or ios and android devices

00:15:56,959 --> 00:16:00,480
different ways how you can deploy

00:16:00,880 --> 00:16:05,120
and every time you you would decide

00:16:03,839 --> 00:16:07,360
where to deploy

00:16:05,120 --> 00:16:08,320
a machine learning model you have to

00:16:07,360 --> 00:16:10,240
think about

00:16:08,320 --> 00:16:11,680
you know you can deploy it in the cloud

00:16:10,240 --> 00:16:14,880
or in the edge

00:16:11,680 --> 00:16:17,040
the same way as you know different

00:16:14,880 --> 00:16:18,720
restaurants they have to decide

00:16:17,040 --> 00:16:20,320
where do they cook their bread right

00:16:18,720 --> 00:16:24,000
mcdonald's they source

00:16:20,320 --> 00:16:27,600
their bread in a factory somewhere

00:16:24,000 --> 00:16:29,199
right a food factory but you think about

00:16:27,600 --> 00:16:31,759
subway

00:16:29,199 --> 00:16:32,399
they break you know they they bake their

00:16:31,759 --> 00:16:36,000
bread

00:16:32,399 --> 00:16:38,560
closer to the restaurant you know so

00:16:36,000 --> 00:16:39,199
i would consider one restaurant as your

00:16:38,560 --> 00:16:43,440
edge

00:16:39,199 --> 00:16:43,839
right because uh it's closer to the user

00:16:43,440 --> 00:16:45,360
so

00:16:43,839 --> 00:16:48,320
those are things you have to think about

00:16:45,360 --> 00:16:51,040
every time you do deployment

00:16:48,320 --> 00:16:52,720
model management the good thing about uh

00:16:51,040 --> 00:16:53,920
you know on the machine learning side or

00:16:52,720 --> 00:16:56,000
on the cloud side

00:16:53,920 --> 00:16:57,680
is you can deploy it as a web service

00:16:56,000 --> 00:16:58,959
and just call that and be able to

00:16:57,680 --> 00:17:00,399
capture telemetry

00:16:58,959 --> 00:17:02,160
so that's on the cloud side there's a

00:17:00,399 --> 00:17:05,280
lot of examples out there

00:17:02,160 --> 00:17:07,199
you would use it uh but for

00:17:05,280 --> 00:17:09,120
you know like in this case on this right

00:17:07,199 --> 00:17:10,959
side where we are deploying

00:17:09,120 --> 00:17:12,319
right you can deploy it up to the cloud

00:17:10,959 --> 00:17:16,559
and manage it that way

00:17:12,319 --> 00:17:16,559
you know with the with our cloud

00:17:16,839 --> 00:17:22,480
infrastructure

00:17:19,280 --> 00:17:22,480
any questions so far

00:17:22,959 --> 00:17:26,319
guys feel free to send questions if you

00:17:25,679 --> 00:17:29,760
have

00:17:26,319 --> 00:17:29,760
through the chat window

00:17:31,039 --> 00:17:34,080
okay i'm gonna move on uh so what is the

00:17:33,520 --> 00:17:37,520
edge

00:17:34,080 --> 00:17:40,720
uh i define the edge as

00:17:37,520 --> 00:17:42,880
whichever is closest to the user right

00:17:40,720 --> 00:17:44,960
so typically we have all our data

00:17:42,880 --> 00:17:45,520
centers they're all hosted out in the

00:17:44,960 --> 00:17:47,360
cloud

00:17:45,520 --> 00:17:49,440
you know it's other person's computer

00:17:47,360 --> 00:17:51,120
right and

00:17:49,440 --> 00:17:53,039
and of course in between that between

00:17:51,120 --> 00:17:53,760
the edge and the cloud and if you've

00:17:53,039 --> 00:17:57,360
heard about

00:17:53,760 --> 00:18:02,320
fog which nodes you know treat it as

00:17:57,360 --> 00:18:06,080
you know your 5g network where they have

00:18:02,320 --> 00:18:08,559
computing closer not necessarily

00:18:06,080 --> 00:18:09,760
in a data somewhere but your data center

00:18:08,559 --> 00:18:11,840
is moving to

00:18:09,760 --> 00:18:13,200
your street lamps right your data center

00:18:11,840 --> 00:18:16,480
is moving somewhere

00:18:13,200 --> 00:18:20,559
closer to where the user is but

00:18:16,480 --> 00:18:22,799
not uh you know compared to devices

00:18:20,559 --> 00:18:23,679
right devices would be like your phone

00:18:22,799 --> 00:18:27,440
right

00:18:23,679 --> 00:18:30,720
or your laptop your pc or an iot device

00:18:27,440 --> 00:18:32,960
uh device or some uh

00:18:30,720 --> 00:18:34,240
your lamps and those kind of your watch

00:18:32,960 --> 00:18:38,960
those are considered uh

00:18:34,240 --> 00:18:38,960
edge devices so

00:18:40,000 --> 00:18:43,520
so why would you want uh you know your

00:18:42,160 --> 00:18:46,640
ai on the

00:18:43,520 --> 00:18:47,200
on the edge right why what what makes

00:18:46,640 --> 00:18:50,000
sense

00:18:47,200 --> 00:18:51,039
uh if you want something that has low

00:18:50,000 --> 00:18:52,720
latency

00:18:51,039 --> 00:18:54,320
that means you want it real quick if

00:18:52,720 --> 00:18:56,320
you're talking about images

00:18:54,320 --> 00:18:58,080
and you're sending those images to the

00:18:56,320 --> 00:19:00,320
cloud every time that's

00:18:58,080 --> 00:19:01,200
you know takes longer to upload those

00:19:00,320 --> 00:19:03,280
images

00:19:01,200 --> 00:19:05,440
do inferencing and then download the

00:19:03,280 --> 00:19:06,240
results so you want to move the

00:19:05,440 --> 00:19:10,400
processing

00:19:06,240 --> 00:19:14,960
closer to the user another one is

00:19:10,400 --> 00:19:16,960
scalability uh like on my previous slide

00:19:14,960 --> 00:19:18,960
uh data centers there's thousands of

00:19:16,960 --> 00:19:22,080
devices in terms of deployment

00:19:18,960 --> 00:19:22,880
but for uh if we're talking about edge

00:19:22,080 --> 00:19:24,720
devices

00:19:22,880 --> 00:19:26,080
you know there's billions and millions

00:19:24,720 --> 00:19:29,200
of devices out there

00:19:26,080 --> 00:19:32,000
think about how many uh devices

00:19:29,200 --> 00:19:33,120
that you have in your house and all

00:19:32,000 --> 00:19:36,000
these different

00:19:33,120 --> 00:19:36,480
iot devices in terms of scalability it

00:19:36,000 --> 00:19:40,000
costs

00:19:36,480 --> 00:19:44,000
less to run machine learning models

00:19:40,000 --> 00:19:45,760
at the edge rather than than the cloud

00:19:44,000 --> 00:19:47,520
and also flexibility there are some

00:19:45,760 --> 00:19:49,520
things that you don't want to ship

00:19:47,520 --> 00:19:51,840
outside of your company or if your boss

00:19:49,520 --> 00:19:53,919
doesn't or sometimes regulations right

00:19:51,840 --> 00:19:56,240
out

00:19:53,919 --> 00:19:57,120
outside the certain countries you won't

00:19:56,240 --> 00:19:59,679
be able to

00:19:57,120 --> 00:20:02,400
send any data out so it makes sense to

00:19:59,679 --> 00:20:05,600
run it locally

00:20:02,400 --> 00:20:08,720
you know in terms one good example is

00:20:05,600 --> 00:20:11,600
if if i'm flying or

00:20:08,720 --> 00:20:12,559
riding an airplane and i lost internet

00:20:11,600 --> 00:20:15,360
connectivity

00:20:12,559 --> 00:20:17,520
my system still runs because it's

00:20:15,360 --> 00:20:19,679
flexible enough to handle that

00:20:17,520 --> 00:20:21,840
without internet connection during the

00:20:19,679 --> 00:20:21,840
flight

00:20:23,120 --> 00:20:27,039
so on onyx you can also use it as

00:20:25,679 --> 00:20:30,240
intermediate

00:20:27,039 --> 00:20:30,559
format meaning you can convert you know

00:20:30,240 --> 00:20:33,840
a pi

00:20:30,559 --> 00:20:37,039
torch model in this case into

00:20:33,840 --> 00:20:40,000
a tensorflow model yeah using

00:20:37,039 --> 00:20:40,640
uh onyx and then now you can use it for

00:20:40,000 --> 00:20:43,039
android

00:20:40,640 --> 00:20:44,159
right or same way as you would convert

00:20:43,039 --> 00:20:47,600
your existing

00:20:44,159 --> 00:20:52,159
uh pi torch model or tensorflow model

00:20:47,600 --> 00:20:54,320
converted to be able to use in core ml

00:20:52,159 --> 00:20:55,200
and and so there's conversions you can

00:20:54,320 --> 00:20:58,000
also

00:20:55,200 --> 00:20:59,440
use it for fine tuning so especially for

00:20:58,000 --> 00:21:04,080
uh

00:20:59,440 --> 00:21:04,080
for onyx model for computer vision where

00:21:04,400 --> 00:21:11,120
you'll be able to have existing models

00:21:08,000 --> 00:21:12,240
onyx model and then be able to do a

00:21:11,120 --> 00:21:16,240
transfer learning

00:21:12,240 --> 00:21:19,600
based from that

00:21:16,240 --> 00:21:22,240
there is also an onyx

00:21:19,600 --> 00:21:23,200
runtime that is available out there that

00:21:22,240 --> 00:21:27,039
you can use

00:21:23,200 --> 00:21:27,600
to run your onyx models it also supports

00:21:27,039 --> 00:21:30,799
onyx

00:21:27,600 --> 00:21:31,600
ml which is onyx ml spec is for

00:21:30,799 --> 00:21:33,440
traditional

00:21:31,600 --> 00:21:35,280
machine learning models not necessarily

00:21:33,440 --> 00:21:38,159
neural networks

00:21:35,280 --> 00:21:38,960
and it has extensible architecture

00:21:38,159 --> 00:21:41,919
plug-in

00:21:38,960 --> 00:21:43,679
for different hardware accelerators so

00:21:41,919 --> 00:21:47,280
if you're using

00:21:43,679 --> 00:21:48,720
nvidia jetson devices there's an

00:21:47,280 --> 00:21:52,559
accelerator there

00:21:48,720 --> 00:21:54,480
there's uh also for intel openvino

00:21:52,559 --> 00:21:56,400
there's an hardware accelerator there

00:21:54,480 --> 00:22:00,320
too

00:21:56,400 --> 00:22:00,720
and api support so onyx runtime it is on

00:22:00,320 --> 00:22:04,240
uh

00:22:00,720 --> 00:22:06,960
github if you go and uh

00:22:04,240 --> 00:22:08,720
see the cool thing about onyx runtime i

00:22:06,960 --> 00:22:10,400
believe is that you can use different

00:22:08,720 --> 00:22:13,120
operating systems

00:22:10,400 --> 00:22:14,720
so if you go to their website you can

00:22:13,120 --> 00:22:16,720
pick and choose and it will give you the

00:22:14,720 --> 00:22:18,559
installation instructions when

00:22:16,720 --> 00:22:20,000
you would use it i will demo how you

00:22:18,559 --> 00:22:22,640
would use this

00:22:20,000 --> 00:22:23,600
today so in this case if you're using

00:22:22,640 --> 00:22:26,320
linux and in

00:22:23,600 --> 00:22:28,400
c-sharp and you know if you want default

00:22:26,320 --> 00:22:29,520
cpu or cuda you'll be able to do that

00:22:28,400 --> 00:22:32,240
it'll give you

00:22:29,520 --> 00:22:33,760
the nuget packages in this case so you

00:22:32,240 --> 00:22:35,440
see the different hardware

00:22:33,760 --> 00:22:37,120
accelerators that are out there and it's

00:22:35,440 --> 00:22:39,440
growing every day so

00:22:37,120 --> 00:22:41,360
depending on the chip or depending on

00:22:39,440 --> 00:22:44,400
what you're you're doing

00:22:41,360 --> 00:22:46,000
with the internet of things device or

00:22:44,400 --> 00:22:48,640
different hardwares that you want to

00:22:46,000 --> 00:22:48,640
deploy these

00:22:49,679 --> 00:22:52,559
it allows you to

00:22:53,520 --> 00:22:56,960
in windows there's also windows ai

00:22:55,520 --> 00:23:00,240
platform that

00:22:56,960 --> 00:23:02,880
runs on top of onyx runtime so

00:23:00,240 --> 00:23:03,600
the idea there there is i don't have to

00:23:02,880 --> 00:23:06,400
select

00:23:03,600 --> 00:23:08,320
if i use windows ml api i don't have to

00:23:06,400 --> 00:23:11,039
select if it's cpu gpu

00:23:08,320 --> 00:23:12,000
vpu or xpu right it automatically

00:23:11,039 --> 00:23:15,280
detects

00:23:12,000 --> 00:23:17,200
and so uh if your device

00:23:15,280 --> 00:23:19,520
your program wants and if your device

00:23:17,200 --> 00:23:22,240
has a gpu use the gpu

00:23:19,520 --> 00:23:23,919
if it has and then it falls back to cpu

00:23:22,240 --> 00:23:26,960
if it does not have one

00:23:23,919 --> 00:23:28,559
and it's using also direct ml now

00:23:26,960 --> 00:23:31,840
there's a direct ml api

00:23:28,559 --> 00:23:32,559
if you're if you're creating a video

00:23:31,840 --> 00:23:34,720
games

00:23:32,559 --> 00:23:37,200
you can and you're targeting it on

00:23:34,720 --> 00:23:37,919
windows you can go directly to direct ml

00:23:37,200 --> 00:23:40,559
api

00:23:37,919 --> 00:23:41,520
that sits on top of directx to run your

00:23:40,559 --> 00:23:44,559
machine learning

00:23:41,520 --> 00:23:47,840
models that way but all that is

00:23:44,559 --> 00:23:47,840
compatible with the onyx

00:23:48,840 --> 00:23:51,840
runtime

00:23:54,000 --> 00:23:57,760
one capability you can do also and if

00:23:56,320 --> 00:24:00,640
you don't want to install

00:23:57,760 --> 00:24:01,679
any onyx stuff in your machine there's a

00:24:00,640 --> 00:24:04,000
docker image

00:24:01,679 --> 00:24:05,360
for a jupyter notebook environment if

00:24:04,000 --> 00:24:08,400
you want just want to

00:24:05,360 --> 00:24:11,440
try it out the onyx converters

00:24:08,400 --> 00:24:14,480
you know you can just get the onyx

00:24:11,440 --> 00:24:16,480
ecosystem docker image and then be able

00:24:14,480 --> 00:24:18,720
to

00:24:16,480 --> 00:24:20,480
create and generate onyx models and do

00:24:18,720 --> 00:24:22,960
your inferencing that way

00:24:20,480 --> 00:24:25,520
there's this onyx base that you can use

00:24:22,960 --> 00:24:28,799
as a minimal dependency that you can uh

00:24:25,520 --> 00:24:33,039
use as your starting

00:24:28,799 --> 00:24:36,559
image container or starting image

00:24:33,039 --> 00:24:36,559
and and expand from there

00:24:37,440 --> 00:24:41,520
so i'm going to go through the demo

00:24:39,520 --> 00:24:43,919
before i do that are there any questions

00:24:41,520 --> 00:24:43,919
so far

00:24:45,200 --> 00:24:47,840
cool

00:24:48,559 --> 00:24:50,880
all right

00:24:53,279 --> 00:24:58,320
so what i have here is i i have a

00:24:55,760 --> 00:25:01,679
jupiter notebook

00:24:58,320 --> 00:25:03,840
and this one right here this jupiter

00:25:01,679 --> 00:25:04,880
notebook i'm not writing it in python i

00:25:03,840 --> 00:25:06,960
am writing it in c

00:25:04,880 --> 00:25:08,240
sharp so i just want to show you the

00:25:06,960 --> 00:25:11,679
capabilities

00:25:08,240 --> 00:25:14,400
of you know if my team

00:25:11,679 --> 00:25:15,360
knows ml.net which is the machine

00:25:14,400 --> 00:25:18,559
learning

00:25:15,360 --> 00:25:21,039
and i want to use it in that same model

00:25:18,559 --> 00:25:22,640
in python i would be able to so in this

00:25:21,039 --> 00:25:29,200
case i did run

00:25:22,640 --> 00:25:30,640
the this model a few minutes ago and

00:25:29,200 --> 00:25:32,960
you know this is how you would install

00:25:30,640 --> 00:25:38,240
these nuget packages for the

00:25:32,960 --> 00:25:41,200
ml.net uh there is a microsoft.ml

00:25:38,240 --> 00:25:42,320
that onyx transformer and onyx converter

00:25:41,200 --> 00:25:46,240
that you can use

00:25:42,320 --> 00:25:47,120
to export uh the machine learning models

00:25:46,240 --> 00:25:51,039
that you train

00:25:47,120 --> 00:25:51,039
in ml.net to onyx

00:25:52,080 --> 00:25:57,840
so this one right here you know you know

00:25:54,559 --> 00:25:57,840
like i said i'm using

00:25:58,000 --> 00:26:04,960
ml.net to be able to display and to

00:26:01,440 --> 00:26:08,159
be able to uh

00:26:04,960 --> 00:26:11,600
format my screen uh

00:26:08,159 --> 00:26:14,720
the output to this

00:26:11,600 --> 00:26:15,360
so i have on this example i have this

00:26:14,720 --> 00:26:18,559
csv

00:26:15,360 --> 00:26:20,799
file and so the simplest example i can

00:26:18,559 --> 00:26:23,520
find and it may not be the best

00:26:20,799 --> 00:26:24,480
uh use case for machine learning i have

00:26:23,520 --> 00:26:27,279
one column for

00:26:24,480 --> 00:26:28,400
input one column for output you put your

00:26:27,279 --> 00:26:29,870
years experience

00:26:28,400 --> 00:26:32,400
it will give you an output

00:26:29,870 --> 00:26:35,760
[Music]

00:26:32,400 --> 00:26:36,320
so again so i specify i load the csv

00:26:35,760 --> 00:26:39,120
file

00:26:36,320 --> 00:26:41,679
and that's my data sample set data set

00:26:39,120 --> 00:26:41,679
that i have

00:26:42,559 --> 00:26:47,840
and it tells me right here minimum and

00:26:45,279 --> 00:26:47,840
maximum

00:26:48,880 --> 00:26:55,600
that i can describe it and this one

00:26:52,159 --> 00:26:58,799
is part of the code and if you want to

00:26:55,600 --> 00:27:01,840
to be able to make

00:26:58,799 --> 00:27:02,880
to try this out this python notebook i

00:27:01,840 --> 00:27:05,679
actually have

00:27:02,880 --> 00:27:06,400
available on github if you go to that

00:27:05,679 --> 00:27:08,159
link

00:27:06,400 --> 00:27:09,760
and there's a button there that you can

00:27:08,159 --> 00:27:11,360
you can try it on without installing

00:27:09,760 --> 00:27:14,080
anything on your machine

00:27:11,360 --> 00:27:16,960
uh there's uh that you can run this

00:27:14,080 --> 00:27:16,960
python notebook

00:27:18,240 --> 00:27:21,840
and this one what this one does is it

00:27:20,720 --> 00:27:24,080
actually

00:27:21,840 --> 00:27:26,320
splits your data between training and

00:27:24,080 --> 00:27:29,200
test

00:27:26,320 --> 00:27:29,520
just randomize it and then how i would

00:27:29,200 --> 00:27:32,840
use

00:27:29,520 --> 00:27:35,840
ml.net of course you would use using

00:27:32,840 --> 00:27:35,840
microsoft.ml

00:27:36,240 --> 00:27:42,000
and it all is in part of

00:27:39,360 --> 00:27:42,960
ml context so once you have the ml

00:27:42,000 --> 00:27:46,159
context you

00:27:42,960 --> 00:27:49,520
specify here the transform as

00:27:46,159 --> 00:27:51,360
one of my feature is you know to do my

00:27:49,520 --> 00:27:53,679
training

00:27:51,360 --> 00:27:54,880
to create that pipeline and once i have

00:27:53,679 --> 00:27:57,919
that pipeline

00:27:54,880 --> 00:27:59,279
i would create a transformer and once i

00:27:57,919 --> 00:28:03,679
have the transformer

00:27:59,279 --> 00:28:07,440
it gives me a right here a

00:28:03,679 --> 00:28:11,840
um metrics

00:28:07,440 --> 00:28:14,640
to be able to you know to

00:28:11,840 --> 00:28:16,080
identify or to kind of understand what

00:28:14,640 --> 00:28:19,919
this model

00:28:16,080 --> 00:28:20,720
does or you know the results of my

00:28:19,919 --> 00:28:22,159
training

00:28:20,720 --> 00:28:24,640
and once i have the results of my

00:28:22,159 --> 00:28:25,760
training i can the important part here

00:28:24,640 --> 00:28:28,840
is i can say

00:28:25,760 --> 00:28:30,240
convert context the model that converts

00:28:28,840 --> 00:28:33,679
onyx

00:28:30,240 --> 00:28:36,080
once i convert that i specify

00:28:33,679 --> 00:28:37,760
where the file is right this one right

00:28:36,080 --> 00:28:40,480
here which is a model name

00:28:37,760 --> 00:28:41,760
which is model.honyx and once i save

00:28:40,480 --> 00:28:44,320
that

00:28:41,760 --> 00:28:46,880
and i open it on netron you know it will

00:28:44,320 --> 00:28:49,679
save this file right here model.onyx

00:28:46,880 --> 00:28:52,159
it would look something like this so

00:28:49,679 --> 00:28:55,120
what i'm trying to showcase here is that

00:28:52,159 --> 00:28:55,919
onyx is not just limited to neural

00:28:55,120 --> 00:28:58,559
networks

00:28:55,919 --> 00:28:58,960
you know for computer vision it's also

00:28:58,559 --> 00:29:01,279
for

00:28:58,960 --> 00:29:02,880
traditional machine learning model

00:29:01,279 --> 00:29:06,000
models that you can deploy

00:29:02,880 --> 00:29:06,000
and integrate with your

00:29:06,080 --> 00:29:13,679
and integrate uh so this this is what

00:29:10,000 --> 00:29:17,039
uh it would look like in

00:29:13,679 --> 00:29:21,120
a new neutron netron right

00:29:17,039 --> 00:29:24,480
netron and it gives the developers

00:29:21,120 --> 00:29:27,200
what the inputs in the output of that

00:29:24,480 --> 00:29:27,840
existing model once they incorporate to

00:29:27,200 --> 00:29:31,120
their

00:29:27,840 --> 00:29:34,159
to their apps so

00:29:31,120 --> 00:29:36,480
i have another python notebook here

00:29:34,159 --> 00:29:38,080
and what this one does is it's using the

00:29:36,480 --> 00:29:42,880
onyx runtime

00:29:38,080 --> 00:29:42,880
so and this one is written in python now

00:29:44,320 --> 00:29:51,840
so you just do pip install onyx runtime

00:29:48,000 --> 00:29:54,159
and it would you can get that

00:29:51,840 --> 00:29:55,120
model onyx loaded to this inference

00:29:54,159 --> 00:29:58,559
session

00:29:55,120 --> 00:29:58,559
so once you have a session

00:30:02,159 --> 00:30:08,559
like in this case it will give me the

00:30:05,360 --> 00:30:12,559
the inputs so i'm reading the contents

00:30:08,559 --> 00:30:14,480
of that onyx model to give me the

00:30:12,559 --> 00:30:16,080
you know like the input like in this

00:30:14,480 --> 00:30:21,200
case

00:30:16,080 --> 00:30:24,320
input 0 gives me the years experience

00:30:21,200 --> 00:30:25,600
which is if you open in netron you'll be

00:30:24,320 --> 00:30:28,159
able to see here

00:30:25,600 --> 00:30:29,360
that that year's experience right that's

00:30:28,159 --> 00:30:30,799
part of your input

00:30:29,360 --> 00:30:33,360
and then there's another one called

00:30:30,799 --> 00:30:33,360
salary

00:30:33,520 --> 00:30:41,919
so that was the another input

00:30:37,840 --> 00:30:44,559
year's experience in salary which is

00:30:41,919 --> 00:30:44,559
the next one

00:30:47,440 --> 00:30:51,279
and then going back through here yeah

00:30:50,640 --> 00:30:53,600
you have your

00:30:51,279 --> 00:30:54,880
input year's experience and salary in

00:30:53,600 --> 00:30:56,720
order to get the output

00:30:54,880 --> 00:30:58,320
what we're really interested here is

00:30:56,720 --> 00:31:01,440
this score that output

00:30:58,320 --> 00:31:04,880
because that is the result of our

00:31:01,440 --> 00:31:06,399
inference right so all these are just

00:31:04,880 --> 00:31:08,720
you know one-to-one mapping but the

00:31:06,399 --> 00:31:09,360
result after it runs through the linear

00:31:08,720 --> 00:31:13,279
regression

00:31:09,360 --> 00:31:15,760
regressor it goes through here

00:31:13,279 --> 00:31:16,880
so that would be my output in this case

00:31:15,760 --> 00:31:18,799
you know you can

00:31:16,880 --> 00:31:20,000
you know since it's an array you can go

00:31:18,799 --> 00:31:23,519
through each one

00:31:20,000 --> 00:31:26,880
and you can see uh you know

00:31:23,519 --> 00:31:30,240
one two three a zero one two three four

00:31:26,880 --> 00:31:34,320
i think that's that's

00:31:30,240 --> 00:31:34,320
that's the four fifth one on our list

00:31:34,880 --> 00:31:42,240
and in order to uh

00:31:39,039 --> 00:31:43,039
so in this case my input data is two and

00:31:42,240 --> 00:31:47,519
a half

00:31:43,039 --> 00:31:49,600
and i have to put them in a tensor array

00:31:47,519 --> 00:31:50,880
uh i have to put them in array of array

00:31:49,600 --> 00:31:54,320
right in order to

00:31:50,880 --> 00:31:57,600
to be able to feed them into this

00:31:54,320 --> 00:32:01,440
uh session.run because it requires

00:31:57,600 --> 00:32:04,159
uh the input years experience which is

00:32:01,440 --> 00:32:05,279
it requires this tensor float with this

00:32:04,159 --> 00:32:08,080
shape

00:32:05,279 --> 00:32:08,480
so that's what i'm trying to do here to

00:32:08,080 --> 00:32:11,679
get

00:32:08,480 --> 00:32:12,720
to that correct shape and so i can feed

00:32:11,679 --> 00:32:16,799
it

00:32:12,720 --> 00:32:20,080
this is my input and then this is

00:32:16,799 --> 00:32:23,200
my output so the output name

00:32:20,080 --> 00:32:26,840
and where where it goes

00:32:23,200 --> 00:32:29,039
so once i do that it will give me a

00:32:26,840 --> 00:32:32,080
result

00:32:29,039 --> 00:32:36,320
and then i can i can pick it up

00:32:32,080 --> 00:32:37,919
from there cool

00:32:36,320 --> 00:32:40,880
so if you think about what happened

00:32:37,919 --> 00:32:43,679
right i have a data scientist

00:32:40,880 --> 00:32:45,039
he's really good at ml.net he knows

00:32:43,679 --> 00:32:48,559
ml.net

00:32:45,039 --> 00:32:52,080
i export it to an onyx model and i can

00:32:48,559 --> 00:32:54,080
integrate it to my python program

00:32:52,080 --> 00:32:55,519
but wait there's more there's one thing

00:32:54,080 --> 00:33:00,480
i want to show you guys

00:32:55,519 --> 00:33:03,679
onyx you can also use it for

00:33:00,480 --> 00:33:05,679
node so the onyx runtime you can also

00:33:03,679 --> 00:33:09,600
use it under

00:33:05,679 --> 00:33:13,200
a node application so in this case

00:33:09,600 --> 00:33:16,080
it was ml.net we

00:33:13,200 --> 00:33:17,679
exported to onyx and now we're going to

00:33:16,080 --> 00:33:21,039
incorporate to a simple

00:33:17,679 --> 00:33:24,320
node application so you can just include

00:33:21,039 --> 00:33:30,240
onyx runtime on this

00:33:24,320 --> 00:33:30,240
on my package json and on app.js

00:33:31,600 --> 00:33:36,399
it's pretty much the same pattern as

00:33:33,919 --> 00:33:40,000
what we did in python

00:33:36,399 --> 00:33:42,559
where we create and load that onyx model

00:33:40,000 --> 00:33:44,240
to a session and at the end of the day

00:33:42,559 --> 00:33:47,840
it's a matter of

00:33:44,240 --> 00:33:51,200
uh plugging in the right input

00:33:47,840 --> 00:33:52,640
and converting it to a tensor so it

00:33:51,200 --> 00:33:56,240
already has existing

00:33:52,640 --> 00:33:59,279
this way and how you would create uh

00:33:56,240 --> 00:34:00,640
in onyx runtime how you would create a

00:33:59,279 --> 00:34:02,559
tensor

00:34:00,640 --> 00:34:04,559
it's like in this case the shape of my

00:34:02,559 --> 00:34:06,799
tensor it requires me to have a one by

00:34:04,559 --> 00:34:06,799
one

00:34:07,679 --> 00:34:14,320
and with with this i specify

00:34:10,960 --> 00:34:18,320
the value in this case i'm let's do

00:34:14,320 --> 00:34:22,079
2.2 sorry

00:34:18,320 --> 00:34:25,040
so let's try this 2.2

00:34:22,079 --> 00:34:25,760
and one thing that i've you know since

00:34:25,040 --> 00:34:28,240
this

00:34:25,760 --> 00:34:29,520
this you know as a developer when you're

00:34:28,240 --> 00:34:32,560
looking at this

00:34:29,520 --> 00:34:35,040
it says i don't know why i'm required to

00:34:32,560 --> 00:34:36,879
incorporate salary but it is required

00:34:35,040 --> 00:34:37,599
for some reason when i convert to onyx

00:34:36,879 --> 00:34:40,639
model

00:34:37,599 --> 00:34:42,399
so i place it in there so that's

00:34:40,639 --> 00:34:44,879
that's kind of like a stub that i don't

00:34:42,399 --> 00:34:46,480
use but it was required in order to run

00:34:44,879 --> 00:34:50,000
it

00:34:46,480 --> 00:34:53,280
and so i plug in those two data

00:34:50,000 --> 00:34:53,280
as part of my input

00:34:54,399 --> 00:34:59,760
and then i do session.run feeding that

00:34:59,839 --> 00:35:02,880
input and it'll give me the result and

00:35:02,240 --> 00:35:05,599
of course

00:35:02,880 --> 00:35:06,400
like we said in here we're more

00:35:05,599 --> 00:35:09,839
interested

00:35:06,400 --> 00:35:11,520
in the score.output and it tells me that

00:35:09,839 --> 00:35:14,560
it's actually one by one i don't know

00:35:11,520 --> 00:35:17,920
why for some reason the latest model

00:35:14,560 --> 00:35:20,800
uh that gets exported it plugs in

00:35:17,920 --> 00:35:24,960
negative one by one which is

00:35:20,800 --> 00:35:28,839
weird but and then it would

00:35:24,960 --> 00:35:31,119
then i can get that data and get that

00:35:28,839 --> 00:35:32,640
predicted salary

00:35:31,119 --> 00:35:34,400
so in this case i'm going to run this

00:35:32,640 --> 00:35:36,800
node app just to show you

00:35:34,400 --> 00:35:38,240
that the program runs as it goes through

00:35:36,800 --> 00:35:41,359
here and it prints

00:35:38,240 --> 00:35:42,839
that predicted salary based from the

00:35:41,359 --> 00:35:45,839
input

00:35:42,839 --> 00:35:45,839
2.2

00:35:48,000 --> 00:35:56,400
cool isn't that cool so we created

00:35:51,440 --> 00:36:00,000
the ml.net model we exported to onyx

00:35:56,400 --> 00:36:03,599
it was written in dot net

00:36:00,000 --> 00:36:07,280
we imp we loaded the onyx model

00:36:03,599 --> 00:36:09,839
into a python program use it without

00:36:07,280 --> 00:36:11,200
installing ml.net or not knowing about

00:36:09,839 --> 00:36:12,880
ml.net

00:36:11,200 --> 00:36:14,240
we were able to incorporate or

00:36:12,880 --> 00:36:17,440
incorporate it to

00:36:14,240 --> 00:36:20,240
our to our

00:36:17,440 --> 00:36:21,599
python program and also we were able to

00:36:20,240 --> 00:36:24,000
incorporate

00:36:21,599 --> 00:36:25,599
this onyx model into our node

00:36:24,000 --> 00:36:28,000
application

00:36:25,599 --> 00:36:29,359
and that right there that right there

00:36:28,000 --> 00:36:32,400
opens up a lot of

00:36:29,359 --> 00:36:35,119
opportunities on how to leverage machine

00:36:32,400 --> 00:36:39,119
learning into our application

00:36:35,119 --> 00:36:41,839
so let me go back to the presentation

00:36:39,119 --> 00:36:44,079
as we continue along so there's also

00:36:41,839 --> 00:36:46,320
reference implementation

00:36:44,079 --> 00:36:48,400
out there i don't know about you guys i

00:36:46,320 --> 00:36:51,839
think i'm really excited about this

00:36:48,400 --> 00:36:53,920
i mean when i first you know

00:36:51,839 --> 00:36:55,359
learned about onyx i'm like you know

00:36:53,920 --> 00:36:58,000
what is this technology

00:36:55,359 --> 00:36:58,960
i mean it's it's not a framework it's

00:36:58,000 --> 00:37:00,960
not something

00:36:58,960 --> 00:37:02,480
but it opens up a lot of that

00:37:00,960 --> 00:37:05,280
opportunity for us

00:37:02,480 --> 00:37:05,839
to be able to like in this case right

00:37:05,280 --> 00:37:08,640
run it

00:37:05,839 --> 00:37:09,680
in in edge devices you know like in

00:37:08,640 --> 00:37:13,760
jetson nano

00:37:09,680 --> 00:37:19,040
or be able to use it for openvino

00:37:13,760 --> 00:37:21,359
and be able to export that capability

00:37:19,040 --> 00:37:22,960
so there's reference implementations out

00:37:21,359 --> 00:37:27,119
there if you are interested in

00:37:22,960 --> 00:37:27,119
incorporating that to your edge devices

00:37:28,079 --> 00:37:35,119
and there's also a way you can run onyx

00:37:31,520 --> 00:37:35,760
into your into a javascript i'm not

00:37:35,119 --> 00:37:38,000
talking about

00:37:35,760 --> 00:37:39,440
node right i'm talking about the

00:37:38,000 --> 00:37:41,520
javascript library

00:37:39,440 --> 00:37:43,359
in the browser so run onyx there's a

00:37:41,520 --> 00:37:46,000
project called onyx.js

00:37:43,359 --> 00:37:47,040
that runs onyx models or loads onyx

00:37:46,000 --> 00:37:49,680
model

00:37:47,040 --> 00:37:52,560
into the browser and it's using

00:37:49,680 --> 00:37:56,320
webassembly and webgl technology

00:37:52,560 --> 00:38:00,079
technologies and it could it could uh

00:37:56,320 --> 00:38:03,680
it's optimized to run

00:38:00,079 --> 00:38:06,880
for both cpus or gpus so

00:38:03,680 --> 00:38:09,440
if you want to be able to load

00:38:06,880 --> 00:38:10,800
that onyx model in the front end your

00:38:09,440 --> 00:38:13,920
angular app or view

00:38:10,800 --> 00:38:16,640
or typescript it now it is now

00:38:13,920 --> 00:38:18,880
possible it allows us to be able to do

00:38:16,640 --> 00:38:22,720
that with this onyx.js

00:38:18,880 --> 00:38:25,760
and compatibility wise you know chrome

00:38:22,720 --> 00:38:30,160
edge firefox electron

00:38:25,760 --> 00:38:33,280
app you can you can do it uh

00:38:30,160 --> 00:38:35,599
in in ios and android devices

00:38:33,280 --> 00:38:36,880
you see the capabilities right there it

00:38:35,599 --> 00:38:41,119
opens up a lot of the

00:38:36,880 --> 00:38:41,119
to our mobile platforms too

00:38:43,280 --> 00:38:46,320
but wait there is there's more there's

00:38:45,760 --> 00:38:49,599
more

00:38:46,320 --> 00:38:52,160
to onyx you can actually use onyx

00:38:49,599 --> 00:38:54,160
as an intermediate you know to where

00:38:52,160 --> 00:38:57,520
there's this embedded

00:38:54,160 --> 00:39:00,720
learning library that is uh

00:38:57,520 --> 00:39:01,280
also open source on github that you can

00:39:00,720 --> 00:39:04,000
train

00:39:01,280 --> 00:39:05,920
your model as long as you can export it

00:39:04,000 --> 00:39:08,640
to an onyx format

00:39:05,920 --> 00:39:09,680
and be able to there's a converter to

00:39:08,640 --> 00:39:12,640
this

00:39:09,680 --> 00:39:14,079
onyx file to ell format that converts it

00:39:12,640 --> 00:39:17,280
to where it would run on a

00:39:14,079 --> 00:39:20,720
an mcu without

00:39:17,280 --> 00:39:22,800
you know going through that traditional

00:39:20,720 --> 00:39:25,280
uh you know linux device or windows

00:39:22,800 --> 00:39:28,400
device or

00:39:25,280 --> 00:39:29,280
but there's a way you can you'll be able

00:39:28,400 --> 00:39:31,839
to

00:39:29,280 --> 00:39:31,839
to do that

00:39:32,720 --> 00:39:39,440
so just to summarize when do we use

00:39:35,920 --> 00:39:42,720
onyx when when's the best time to use it

00:39:39,440 --> 00:39:45,280
when you want high latency or high

00:39:42,720 --> 00:39:48,320
influence latency for production use

00:39:45,280 --> 00:39:48,320
you know if you have to

00:39:48,960 --> 00:39:54,880
if you want really really fast

00:39:52,720 --> 00:39:56,560
machine learning models running for

00:39:54,880 --> 00:39:58,320
production i would recommend looking

00:39:56,560 --> 00:40:02,320
into onyx

00:39:58,320 --> 00:40:03,280
train it in python how do you know if

00:40:02,320 --> 00:40:04,960
it's

00:40:03,280 --> 00:40:08,000
if it's something that is trained in

00:40:04,960 --> 00:40:10,960
python and then be able to deploy

00:40:08,000 --> 00:40:12,880
to a c-sharp app like what we did demo

00:40:10,960 --> 00:40:15,200
today to a

00:40:12,880 --> 00:40:17,440
javascript application to a java

00:40:15,200 --> 00:40:20,560
application or to mobile devices

00:40:17,440 --> 00:40:22,960
that is one way or when you would use an

00:40:20,560 --> 00:40:22,960
onyx

00:40:23,200 --> 00:40:28,079
model if it's a resource constraint

00:40:26,880 --> 00:40:31,359
device or if it's an

00:40:28,079 --> 00:40:34,000
iot or an edge devices i would look into

00:40:31,359 --> 00:40:34,880
uh how you would convert your model into

00:40:34,000 --> 00:40:38,319
onyx

00:40:34,880 --> 00:40:41,520
there's a way you can even optimize

00:40:38,319 --> 00:40:44,800
an rx model to be able to run on

00:40:41,520 --> 00:40:47,359
a constraint devices

00:40:44,800 --> 00:40:48,319
if you train it somewhere let's say you

00:40:47,359 --> 00:40:50,880
train it on

00:40:48,319 --> 00:40:52,160
a linux device and you have or a windows

00:40:50,880 --> 00:40:54,560
device and then you

00:40:52,160 --> 00:40:55,520
have to have a different os or different

00:40:54,560 --> 00:40:59,200
hardware

00:40:55,520 --> 00:41:02,560
uh you have a gpu or

00:40:59,200 --> 00:41:04,880
you know you have a

00:41:02,560 --> 00:41:06,880
fpga if you want to run it i would

00:41:04,880 --> 00:41:10,079
recommend looking into

00:41:06,880 --> 00:41:12,800
onyx how you would convert your model

00:41:10,079 --> 00:41:14,240
if it's also you have two different

00:41:12,800 --> 00:41:17,200
models that you're trying to

00:41:14,240 --> 00:41:18,240
com not necessarily combine them but use

00:41:17,200 --> 00:41:20,160
them

00:41:18,240 --> 00:41:21,359
you know one after the other or

00:41:20,160 --> 00:41:24,000
streamline them

00:41:21,359 --> 00:41:25,200
i would look into onyx and how you would

00:41:24,000 --> 00:41:28,240
combine

00:41:25,200 --> 00:41:28,720
let's say you know this data science

00:41:28,240 --> 00:41:31,359
team

00:41:28,720 --> 00:41:33,040
they use it in pytorch or they train

00:41:31,359 --> 00:41:34,000
their model in pytorch and then you have

00:41:33,040 --> 00:41:37,359
another data science

00:41:34,000 --> 00:41:40,560
team they turn they they train it using

00:41:37,359 --> 00:41:43,200
um you know tensorflow

00:41:40,560 --> 00:41:45,520
and whatever those exported when once

00:41:43,200 --> 00:41:47,839
you export it in onyx model then you can

00:41:45,520 --> 00:41:49,520
you know you have one pipeline and pipe

00:41:47,839 --> 00:41:52,560
flow

00:41:49,520 --> 00:41:53,200
as as it goes from one model does it to

00:41:52,560 --> 00:41:55,680
the other

00:41:53,200 --> 00:41:57,680
and there's also somebody just something

00:41:55,680 --> 00:42:01,359
new which is on preview

00:41:57,680 --> 00:42:03,920
right now is through

00:42:01,359 --> 00:42:05,119
uh when when transformer models there's

00:42:03,920 --> 00:42:09,200
a way you can

00:42:05,119 --> 00:42:14,000
train where the training happens

00:42:09,200 --> 00:42:16,000
in in the onyx model itself

00:42:14,000 --> 00:42:17,760
there's lots of tutorials out there i

00:42:16,000 --> 00:42:20,640
haven't really tried it myself

00:42:17,760 --> 00:42:23,920
but i think it's it's uh it's still in

00:42:20,640 --> 00:42:23,920
preview it's still early bits

00:42:24,000 --> 00:42:27,599
after all this this is how i felt right

00:42:26,800 --> 00:42:30,079
there's

00:42:27,599 --> 00:42:31,280
it's like it opens up a lot of that

00:42:30,079 --> 00:42:35,280
possibilities

00:42:31,280 --> 00:42:39,839
of how we can deploy and how we can

00:42:35,280 --> 00:42:42,960
use you know and be able to share

00:42:39,839 --> 00:42:46,000
those existing models

00:42:42,960 --> 00:42:47,839
in interoperability i think that's you

00:42:46,000 --> 00:42:51,119
know this is this the way i see it is

00:42:47,839 --> 00:42:55,359
it's how we can democratize ai

00:42:51,119 --> 00:42:57,920
to be able to use it

00:42:55,359 --> 00:42:58,560
everywhere in a lot of places so what is

00:42:57,920 --> 00:43:00,960
onix

00:42:58,560 --> 00:43:02,319
it's an open standard that you can use

00:43:00,960 --> 00:43:04,800
with the right tools

00:43:02,319 --> 00:43:06,560
of what you're currently using right now

00:43:04,800 --> 00:43:10,400
and would run efficiently

00:43:06,560 --> 00:43:12,720
on your target program or platform

00:43:10,400 --> 00:43:13,760
how you would create it there's

00:43:12,720 --> 00:43:17,200
different ways

00:43:13,760 --> 00:43:20,640
that you can convert existing models

00:43:17,200 --> 00:43:22,079
or create from different frameworks

00:43:20,640 --> 00:43:24,960
how you would deploy it i would

00:43:22,079 --> 00:43:27,160
recommend using onyx runtime

00:43:24,960 --> 00:43:28,319
you can also use windows ml there's

00:43:27,160 --> 00:43:31,359
onyx.js

00:43:28,319 --> 00:43:33,920
that you can use in order to

00:43:31,359 --> 00:43:34,480
deploy it to your devices or to your

00:43:33,920 --> 00:43:37,359
machine

00:43:34,480 --> 00:43:37,359
to different machines

00:43:37,599 --> 00:43:42,400
i would you know if you're a python

00:43:40,720 --> 00:43:43,359
developer there's onyx runtime i would

00:43:42,400 --> 00:43:46,400
recommend

00:43:43,359 --> 00:43:49,599
to to try it out if you're interested in

00:43:46,400 --> 00:43:53,280
in getting the slides

00:43:49,599 --> 00:43:56,319
or the presentation material

00:43:53,280 --> 00:43:56,960
there's the link down there and be able

00:43:56,319 --> 00:43:59,599
to

00:43:56,960 --> 00:43:59,599
to connect

00:44:00,720 --> 00:44:04,400
and if you're interested in learning

00:44:02,319 --> 00:44:06,000
more about me i'm a lead software

00:44:04,400 --> 00:44:09,599
engineer at spacey

00:44:06,000 --> 00:44:12,319
i'm a microsoft mvp the best

00:44:09,599 --> 00:44:12,800
uh the best way to connect to me is

00:44:12,319 --> 00:44:15,839
through

00:44:12,800 --> 00:44:17,119
twitter or linkedin you connect me via

00:44:15,839 --> 00:44:20,319
linkedin

00:44:17,119 --> 00:44:23,680
and i appreciate you taking time uh

00:44:20,319 --> 00:44:31,680
geeking out with me about onyx

00:44:23,680 --> 00:44:31,680

YouTube URL: https://www.youtube.com/watch?v=FfDsyviwaPw


