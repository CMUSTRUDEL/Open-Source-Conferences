Title: Digitizing 125 Years of Images - Suman Roy & William P. Davis
Publication date: 2020-12-14
Playlist: All Things Open 2020 - Case Study Demo Track
Description: 
	Presented by: Suman Roy & William P. Davis, The New York Times
Presented at All Things Open 2020 - Case Study/Demo Track

Abstract: Photographs first appeared in The New York Times on Sept. 6, 1896 and have been an integral part of our journalism ever since. The New York Times has a vast archive of physical photos stored in hundreds of file cabinets in the “morgue”, organized by folders. This archive has significant historical value, some of these photos can be found nowhere else in the world.

The Times began a project in 2018 to digitize these images in order to preserve them and make the archive more easily searchable and researchable. An index card catalogue was the only way to research the archive. The backs of the images and the folders containing the images have rich information that were not indexed in any form.

The talk will review how we build a system to ingest millions of photos, and make them findable Cloud Storage, Pub/Sub, Kubernetes, Postgres, Golang, Imagemagick and a host of other technologies.

We will also touch on how we built search, which has been a fascinating experience because of the difficulties around OCRing hand-written text and dates.
Captions: 
	00:00:04,960 --> 00:00:09,840
hello

00:00:06,480 --> 00:00:11,599
thank you for joining our talk um i am

00:00:09,840 --> 00:00:12,799
schumann roy and i have with me my

00:00:11,599 --> 00:00:15,599
friend and colleague

00:00:12,799 --> 00:00:16,480
will davis we work at the new york times

00:00:15,599 --> 00:00:18,160
and today

00:00:16,480 --> 00:00:19,840
we would like to tell you about a really

00:00:18,160 --> 00:00:22,240
fun project that we worked on at the

00:00:19,840 --> 00:00:22,240
times

00:00:23,119 --> 00:00:26,480
it's hard to imagine journalism and

00:00:26,000 --> 00:00:29,599
indeed

00:00:26,480 --> 00:00:30,160
life without images photographs didn't

00:00:29,599 --> 00:00:34,239
appear

00:00:30,160 --> 00:00:35,760
in the times until the late 1800s

00:00:34,239 --> 00:00:38,239
and obviously they have been an integral

00:00:35,760 --> 00:00:41,360
part of our journalism ever since

00:00:38,239 --> 00:00:42,480
over the last 100 plus years the times

00:00:41,360 --> 00:00:45,760
has built up

00:00:42,480 --> 00:00:46,719
a large archive of physical photos this

00:00:45,760 --> 00:00:49,280
archive has

00:00:46,719 --> 00:00:50,719
significant historical value it serves

00:00:49,280 --> 00:00:54,239
as a visual record

00:00:50,719 --> 00:00:56,480
of the entire 20th century of life in

00:00:54,239 --> 00:00:57,840
this country and indeed beyond it

00:00:56,480 --> 00:00:59,680
some of these photos can be found

00:00:57,840 --> 00:01:03,120
nowhere else in the world

00:00:59,680 --> 00:01:04,400
in 2018 we began a project to digitize

00:01:03,120 --> 00:01:06,479
these images

00:01:04,400 --> 00:01:07,760
in order to preserve them and make the

00:01:06,479 --> 00:01:10,880
archive more easily

00:01:07,760 --> 00:01:13,439
searchable and researchable in this talk

00:01:10,880 --> 00:01:15,680
we will review how we did that we'll

00:01:13,439 --> 00:01:17,600
dive into challenges with off-the-shelf

00:01:15,680 --> 00:01:19,280
machine learning tools for image and

00:01:17,600 --> 00:01:22,080
text recognition

00:01:19,280 --> 00:01:24,159
we'll also tell you how we repurposed

00:01:22,080 --> 00:01:25,280
analog metadata for a digital search

00:01:24,159 --> 00:01:27,600
experience

00:01:25,280 --> 00:01:29,119
so the first question where do we keep

00:01:27,600 --> 00:01:32,240
these photos

00:01:29,119 --> 00:01:33,200
the answer is in a basement three floors

00:01:32,240 --> 00:01:35,360
underground

00:01:33,200 --> 00:01:37,600
next to the new york times headquarters

00:01:35,360 --> 00:01:40,799
just a block away from times square

00:01:37,600 --> 00:01:43,280
and hundreds of steel filing cabinets

00:01:40,799 --> 00:01:44,000
for more than a century librarians

00:01:43,280 --> 00:01:45,600
organized

00:01:44,000 --> 00:01:47,439
millions of prints of photos into

00:01:45,600 --> 00:01:50,720
folders based on their subject

00:01:47,439 --> 00:01:51,600
and who is pictured this collection is

00:01:50,720 --> 00:01:54,640
effective

00:01:51,600 --> 00:01:55,360
affectionately known as the morgue as

00:01:54,640 --> 00:01:57,360
you can tell

00:01:55,360 --> 00:01:59,520
journalists have a pretty morbid sense

00:01:57,360 --> 00:02:03,759
of humor

00:01:59,520 --> 00:02:06,880
it is a 600 000 pound archive

00:02:03,759 --> 00:02:08,959
of photos newspaper clippings

00:02:06,880 --> 00:02:10,640
encyclopedias and books in fact it's so

00:02:08,959 --> 00:02:13,360
heavy that the flooring had to be

00:02:10,640 --> 00:02:16,160
specially made to support the weight

00:02:13,360 --> 00:02:18,480
let's now watch a clip where jeff roth

00:02:16,160 --> 00:02:23,840
researcher and archive caretaker

00:02:18,480 --> 00:02:23,840
describes the morgan what is it

00:02:38,720 --> 00:02:50,640
first new york city subway in 1904

00:02:41,840 --> 00:02:54,239
and there you have it

00:02:50,640 --> 00:02:55,120
the morgue is what makes the times the

00:02:54,239 --> 00:02:58,080
times

00:02:55,120 --> 00:02:59,360
there's 600 cabinets a few thousand

00:02:58,080 --> 00:03:00,879
drawers

00:02:59,360 --> 00:03:03,120
six to eight million photographs dating

00:03:00,879 --> 00:03:06,400
from the late 1800s on until

00:03:03,120 --> 00:03:10,159
the 1990s this is

00:03:06,400 --> 00:03:12,159
the flying hunters this ran in 1930.

00:03:10,159 --> 00:03:13,280
george washington bridge france's

00:03:12,159 --> 00:03:15,680
biggest naval ship

00:03:13,280 --> 00:03:17,440
american soldier greeting his mom

00:03:15,680 --> 00:03:19,040
christmas at penn station

00:03:17,440 --> 00:03:21,360
i mean there's pretty much anything and

00:03:19,040 --> 00:03:25,519
everything the history of the world

00:03:21,360 --> 00:03:25,519
through the eyes of the new york times

00:03:26,720 --> 00:03:30,159
again that was jeff roth researcher and

00:03:29,280 --> 00:03:33,280
archive

00:03:30,159 --> 00:03:33,840
caretaker for the new york times so one

00:03:33,280 --> 00:03:36,879
question

00:03:33,840 --> 00:03:36,879
we get is

00:03:36,959 --> 00:03:43,280
why do we do this now um and

00:03:40,239 --> 00:03:44,480
and the reason is most of the material

00:03:43,280 --> 00:03:46,560
in the archive is

00:03:44,480 --> 00:03:48,319
is not available on the internet much of

00:03:46,560 --> 00:03:51,440
it is not available anywhere else

00:03:48,319 --> 00:03:53,360
so it remains a valuable resource for

00:03:51,440 --> 00:03:55,760
storytelling and reporting

00:03:53,360 --> 00:03:56,799
a recent example of this is the coverage

00:03:55,760 --> 00:03:59,040
on ruth

00:03:56,799 --> 00:04:01,280
bader ginsburg and we'll see more on

00:03:59,040 --> 00:04:04,799
that later

00:04:01,280 --> 00:04:07,760
but uh a trip to the archive

00:04:04,799 --> 00:04:08,239
is going to run you a minimum of 30

00:04:07,760 --> 00:04:10,080
minutes

00:04:08,239 --> 00:04:11,519
and that is if you know exactly what

00:04:10,080 --> 00:04:13,599
you're looking for

00:04:11,519 --> 00:04:15,280
and if you have access to the office

00:04:13,599 --> 00:04:17,759
more likely it'll take you

00:04:15,280 --> 00:04:20,000
hours to find what you're looking for so

00:04:17,759 --> 00:04:22,800
as valuable a resource as it is

00:04:20,000 --> 00:04:23,680
it is expensive to use and of course

00:04:22,800 --> 00:04:25,840
there's a risk of

00:04:23,680 --> 00:04:28,800
losing the archive some of you may

00:04:25,840 --> 00:04:31,680
remember in 2018 there was a fire

00:04:28,800 --> 00:04:32,800
in the national museum in rio in brazil

00:04:31,680 --> 00:04:36,320
and they lost

00:04:32,800 --> 00:04:39,199
much of their archive and we had our own

00:04:36,320 --> 00:04:41,680
scare too we had a burst pipe

00:04:39,199 --> 00:04:43,520
over a weekend and luckily someone was

00:04:41,680 --> 00:04:46,639
in there doing research on that day

00:04:43,520 --> 00:04:47,520
and the damage was minimal and the other

00:04:46,639 --> 00:04:50,960
thing was

00:04:47,520 --> 00:04:53,440
in 2018 a lot of technology around

00:04:50,960 --> 00:04:55,440
image recognition and text recognition

00:04:53,440 --> 00:04:57,199
were really becoming widely available

00:04:55,440 --> 00:04:58,720
across a lot of different providers so

00:04:57,199 --> 00:05:00,800
we felt that the technology was

00:04:58,720 --> 00:05:03,440
also at the right point to really help

00:05:00,800 --> 00:05:03,440
us do this

00:05:03,600 --> 00:05:07,520
so at this point you're asking yourself

00:05:05,440 --> 00:05:09,440
how do how does one

00:05:07,520 --> 00:05:10,800
navigate the archive and how does one

00:05:09,440 --> 00:05:13,840
find photos in the archive

00:05:10,800 --> 00:05:16,800
the answer is the index card catalog

00:05:13,840 --> 00:05:17,440
so here is an index card of william veek

00:05:16,800 --> 00:05:21,120
who is a

00:05:17,440 --> 00:05:22,080
mlb franchise owner and this was the

00:05:21,120 --> 00:05:24,639
only way to

00:05:22,080 --> 00:05:26,000
research the archive so it's some of you

00:05:24,639 --> 00:05:27,840
may remember this is similar to the

00:05:26,000 --> 00:05:30,720
dewey decimal system of libraries

00:05:27,840 --> 00:05:32,320
you you look up the topic and then that

00:05:30,720 --> 00:05:36,120
then the card tells you

00:05:32,320 --> 00:05:38,960
where the subject is located so we have

00:05:36,120 --> 00:05:40,800
850 000 index cards you know from

00:05:38,960 --> 00:05:42,560
acapella all the way to zz

00:05:40,800 --> 00:05:44,639
top and you come here you look at what

00:05:42,560 --> 00:05:46,160
you're looking for you find the folder

00:05:44,639 --> 00:05:47,120
number just which are the numbers on the

00:05:46,160 --> 00:05:49,120
right

00:05:47,120 --> 00:05:51,360
and then you go locate the folder and

00:05:49,120 --> 00:05:53,440
look for your photos

00:05:51,360 --> 00:05:55,199
so let's walk through an example let's

00:05:53,440 --> 00:05:57,600
say you're doing a story

00:05:55,199 --> 00:05:58,479
on professional dog walkers in new york

00:05:57,600 --> 00:06:01,199
city

00:05:58,479 --> 00:06:02,240
and maybe you happen to know that jim

00:06:01,199 --> 00:06:04,720
buck

00:06:02,240 --> 00:06:06,160
the professional the original dog walker

00:06:04,720 --> 00:06:08,080
in new york city

00:06:06,160 --> 00:06:10,639
so you go to the card catalog you you

00:06:08,080 --> 00:06:12,000
thumb you thumb your way to the card for

00:06:10,639 --> 00:06:14,080
gym buck and you locate

00:06:12,000 --> 00:06:15,280
but oh we might have some stuff about

00:06:14,080 --> 00:06:18,960
jim buck in

00:06:15,280 --> 00:06:20,800
folder 4645-l dashboard

00:06:18,960 --> 00:06:22,319
odds are though you started in the

00:06:20,800 --> 00:06:24,080
animal section

00:06:22,319 --> 00:06:26,080
you made your way to dogs and then you

00:06:24,080 --> 00:06:26,960
found pets pet shows and miscellaneous

00:06:26,080 --> 00:06:28,880
and then you found

00:06:26,960 --> 00:06:30,240
something that might be worth looking

00:06:28,880 --> 00:06:32,479
into

00:06:30,240 --> 00:06:35,199
so okay so things are telling you to go

00:06:32,479 --> 00:06:37,840
into four six 4645-40 so you go find

00:06:35,199 --> 00:06:40,160
that folder in one of the drawers

00:06:37,840 --> 00:06:41,600
and you see okay there's a lot of photos

00:06:40,160 --> 00:06:44,319
in here let's see what's in there

00:06:41,600 --> 00:06:46,160
you open it and there you have jim buck

00:06:44,319 --> 00:06:48,639
in the flash and it's a good picture

00:06:46,160 --> 00:06:50,800
and you're like oh i want to use this

00:06:48,639 --> 00:06:53,280
this is this is a nice photo

00:06:50,800 --> 00:06:54,400
you ask yourself do i have the right to

00:06:53,280 --> 00:06:56,240
use this photo

00:06:54,400 --> 00:06:57,919
i should mention that even you know a

00:06:56,240 --> 00:06:59,840
lot of the photos that we have it's not

00:06:57,919 --> 00:07:01,919
clear if we actually have the runs to be

00:06:59,840 --> 00:07:04,639
printed to run it

00:07:01,919 --> 00:07:06,319
so you flip over the photo and whoa

00:07:04,639 --> 00:07:09,280
there's a lot of information there

00:07:06,319 --> 00:07:09,680
including the original caption in this

00:07:09,280 --> 00:07:12,319
case

00:07:09,680 --> 00:07:13,919
the times does have the right to this

00:07:12,319 --> 00:07:16,240
photo and in fact we did a story

00:07:13,919 --> 00:07:17,840
recently about dreadlock but

00:07:16,240 --> 00:07:20,000
you can see the challenge the challenge

00:07:17,840 --> 00:07:21,919
is you have to extract all this

00:07:20,000 --> 00:07:22,479
information from the cards the folder

00:07:21,919 --> 00:07:24,560
the

00:07:22,479 --> 00:07:26,319
front and backs of photos and organize

00:07:24,560 --> 00:07:27,520
that content in a way so you can find

00:07:26,319 --> 00:07:29,199
what you're looking for

00:07:27,520 --> 00:07:30,639
and let's face it what you're not

00:07:29,199 --> 00:07:32,720
looking for

00:07:30,639 --> 00:07:35,440
this had to be a system that promoted

00:07:32,720 --> 00:07:38,319
serendipity and browsability

00:07:35,440 --> 00:07:39,599
so where do we start what's step zero

00:07:38,319 --> 00:07:41,360
well as you can imagine

00:07:39,599 --> 00:07:42,639
step zero is really scanning these

00:07:41,360 --> 00:07:44,240
images

00:07:42,639 --> 00:07:45,840
when we started the project we were

00:07:44,240 --> 00:07:47,199
fortunate that the index cards had

00:07:45,840 --> 00:07:50,319
already been scanned

00:07:47,199 --> 00:07:51,759
so as soon as we ingested those cards in

00:07:50,319 --> 00:07:53,599
we had a starting point people could

00:07:51,759 --> 00:07:54,319
still people could already start using

00:07:53,599 --> 00:07:57,039
the system

00:07:54,319 --> 00:07:58,080
before we had scanned all the photos so

00:07:57,039 --> 00:08:00,400
that's step zero is

00:07:58,080 --> 00:08:02,400
scanning we had a team of scanners

00:08:00,400 --> 00:08:04,479
meticulously bring up drawers with

00:08:02,400 --> 00:08:06,960
folders and scan the front and back and

00:08:04,479 --> 00:08:10,240
feed it into the system

00:08:06,960 --> 00:08:12,400
what's next well somewhere around step

00:08:10,240 --> 00:08:14,240
50 you wind up with an architecture that

00:08:12,400 --> 00:08:15,919
looks a lot like this

00:08:14,240 --> 00:08:17,919
and obviously there were lots of twists

00:08:15,919 --> 00:08:19,599
and turns and things you know we kept

00:08:17,919 --> 00:08:21,360
and we didn't keep but

00:08:19,599 --> 00:08:23,039
obviously no time to get through all of

00:08:21,360 --> 00:08:25,280
that so today we'll focus on

00:08:23,039 --> 00:08:27,599
the image analysis part in particular

00:08:25,280 --> 00:08:29,599
ocr and card to folder mapping

00:08:27,599 --> 00:08:31,520
and will will take you through the next

00:08:29,599 --> 00:08:35,440
section

00:08:31,520 --> 00:08:36,880
thanks shimon so to start

00:08:35,440 --> 00:08:39,360
modern images come with a lot of

00:08:36,880 --> 00:08:40,640
metadata that metadata is provided by

00:08:39,360 --> 00:08:41,519
cameras and by the photographers

00:08:40,640 --> 00:08:43,760
themselves

00:08:41,519 --> 00:08:45,360
and so this is an example of an image

00:08:43,760 --> 00:08:47,200
that was sent to us recently

00:08:45,360 --> 00:08:48,880
and you can see for example the date

00:08:47,200 --> 00:08:50,800
that the image was taken that's provided

00:08:48,880 --> 00:08:52,800
by the camera

00:08:50,800 --> 00:08:54,000
you can see when the image was sent to

00:08:52,800 --> 00:08:56,480
us originally

00:08:54,000 --> 00:08:57,279
the photographer provided their name and

00:08:56,480 --> 00:09:00,399
a caption

00:08:57,279 --> 00:09:01,760
a description of that image and so and

00:09:00,399 --> 00:09:03,279
oftentimes there's even location

00:09:01,760 --> 00:09:04,880
information from the camera

00:09:03,279 --> 00:09:07,040
so we know by just by looking at the

00:09:04,880 --> 00:09:09,680
metadata of this image that this is

00:09:07,040 --> 00:09:10,959
scoffagos in uh in iceland and that was

00:09:09,680 --> 00:09:13,360
taken by

00:09:10,959 --> 00:09:15,360
uh bera for the new york times that we

00:09:13,360 --> 00:09:17,920
own the rights to this image

00:09:15,360 --> 00:09:19,279
so none of our scans did not have any

00:09:17,920 --> 00:09:20,399
other information embedded all we had

00:09:19,279 --> 00:09:22,480
was the information

00:09:20,399 --> 00:09:24,320
from the time of scanning which was

00:09:22,480 --> 00:09:27,040
basically useless

00:09:24,320 --> 00:09:28,720
so as shimon mentioned one of the

00:09:27,040 --> 00:09:29,360
reasons why it made sense to do this

00:09:28,720 --> 00:09:31,600
project

00:09:29,360 --> 00:09:33,200
now was because it seemed like there was

00:09:31,600 --> 00:09:35,279
a good set of off-the-shelf tools to

00:09:33,200 --> 00:09:37,839
help make the archive searchable

00:09:35,279 --> 00:09:39,760
and when we started we had an idea in

00:09:37,839 --> 00:09:41,279
our heads of some of the technologies

00:09:39,760 --> 00:09:42,800
that we were hoping

00:09:41,279 --> 00:09:46,000
would allow us to get as much value out

00:09:42,800 --> 00:09:46,000
of the photographs as possible

00:09:46,080 --> 00:09:50,720
so as an example when we started the

00:09:49,360 --> 00:09:53,760
technology

00:09:50,720 --> 00:09:55,279
um when we started the project we

00:09:53,760 --> 00:09:56,399
thought that object detection might help

00:09:55,279 --> 00:09:58,720
us identify

00:09:56,399 --> 00:09:59,839
what is actually going on in the images

00:09:58,720 --> 00:10:00,560
and um

00:09:59,839 --> 00:10:02,959
you know that was one of the

00:10:00,560 --> 00:10:04,399
technologies that seemed most promising

00:10:02,959 --> 00:10:06,640
the ability for machine learning to

00:10:04,399 --> 00:10:09,519
apply terms to the image to identify the

00:10:06,640 --> 00:10:11,279
location based on landmarks for example

00:10:09,519 --> 00:10:13,279
as we started experimenting with those

00:10:11,279 --> 00:10:13,839
technologies what we started running

00:10:13,279 --> 00:10:16,560
into

00:10:13,839 --> 00:10:18,160
were some complications based on the

00:10:16,560 --> 00:10:21,839
unique attributes of our archive

00:10:18,160 --> 00:10:25,680
so for example um here is a photo

00:10:21,839 --> 00:10:27,680
this is um the presentation's lagging a

00:10:25,680 --> 00:10:29,839
little bit for me sorry

00:10:27,680 --> 00:10:31,360
here's a photo this is obviously taken

00:10:29,839 --> 00:10:33,040
in paris you've got the eiffel tower in

00:10:31,360 --> 00:10:34,480
the background

00:10:33,040 --> 00:10:38,000
one of the most distinctive structures

00:10:34,480 --> 00:10:38,959
in the world these are probably tourists

00:10:38,000 --> 00:10:40,959
and when you start looking at the

00:10:38,959 --> 00:10:41,920
objects in the photo and classifying the

00:10:40,959 --> 00:10:44,079
photo you know

00:10:41,920 --> 00:10:45,279
this guy is carrying a camera they're

00:10:44,079 --> 00:10:48,399
both wearing coats

00:10:45,279 --> 00:10:49,440
this is obviously a city scene so if i

00:10:48,399 --> 00:10:50,800
were a photo editor

00:10:49,440 --> 00:10:52,959
i would probably want to search for

00:10:50,800 --> 00:10:56,320
something like tourists eiffel tower

00:10:52,959 --> 00:10:56,959
paris something like that so if we run

00:10:56,320 --> 00:11:00,480
this photo

00:10:56,959 --> 00:11:01,360
through google's vision api um this is

00:11:00,480 --> 00:11:02,640
what it gives us

00:11:01,360 --> 00:11:04,720
and there's some pretty cool information

00:11:02,640 --> 00:11:06,399
here um first of all that identifies

00:11:04,720 --> 00:11:08,880
this photo as being in paris

00:11:06,399 --> 00:11:11,120
which is pretty cool and it picks out

00:11:08,880 --> 00:11:12,880
the arc to as a landmark

00:11:11,120 --> 00:11:14,320
it identifies that the subjects are

00:11:12,880 --> 00:11:16,560
wearing coats and that this is a photo

00:11:14,320 --> 00:11:18,320
of an urban area

00:11:16,560 --> 00:11:19,519
the thing though is the objects and

00:11:18,320 --> 00:11:21,760
labels that it pulls out aren't

00:11:19,519 --> 00:11:23,600
necessarily useful as search terms

00:11:21,760 --> 00:11:25,279
um for for the most part the high

00:11:23,600 --> 00:11:26,839
confidence terms

00:11:25,279 --> 00:11:28,800
may actually serve to money search

00:11:26,839 --> 00:11:31,200
results and

00:11:28,800 --> 00:11:31,920
as we dug into this example we started

00:11:31,200 --> 00:11:34,399
to believe

00:11:31,920 --> 00:11:35,760
that you know google may be searching

00:11:34,399 --> 00:11:37,279
the the internet to see

00:11:35,760 --> 00:11:38,800
if it can find this image or an image

00:11:37,279 --> 00:11:41,279
like it and applying

00:11:38,800 --> 00:11:42,480
um you know some some of these terms

00:11:41,279 --> 00:11:43,839
based on that search

00:11:42,480 --> 00:11:45,519
and the reason we believe that is

00:11:43,839 --> 00:11:47,200
because um

00:11:45,519 --> 00:11:48,560
in this example the arctic triumph is

00:11:47,200 --> 00:11:49,519
not actually visible in the photo it's

00:11:48,560 --> 00:11:51,440
what they're standing

00:11:49,519 --> 00:11:52,800
on and this is a photo that had been

00:11:51,440 --> 00:11:54,079
published israeli in the new york times

00:11:52,800 --> 00:11:55,680
with a caption indicating that they're

00:11:54,079 --> 00:11:59,279
sitting on the ark to triumph

00:11:55,680 --> 00:12:02,480
so that is pretty cool but for

00:11:59,279 --> 00:12:03,600
an archive that exists mostly um

00:12:02,480 --> 00:12:05,200
that for the most part has not been

00:12:03,600 --> 00:12:06,959
published on the internet it wasn't

00:12:05,200 --> 00:12:10,480
going to be as helpful

00:12:06,959 --> 00:12:10,480
the other problem that we ran into

00:12:10,639 --> 00:12:18,160
this is a common optical illusion

00:12:14,800 --> 00:12:19,600
is this a duck or a rabbit and based on

00:12:18,160 --> 00:12:23,279
the rotation of the image google's

00:12:19,600 --> 00:12:26,399
vision api returns a different answer

00:12:23,279 --> 00:12:27,120
that makes a lot of sense um the problem

00:12:26,399 --> 00:12:29,040
is that

00:12:27,120 --> 00:12:30,240
most of our scans all of our scans

00:12:29,040 --> 00:12:31,440
actually do not come in with any

00:12:30,240 --> 00:12:34,399
rotation metadata

00:12:31,440 --> 00:12:35,279
so this is how this image was actually

00:12:34,399 --> 00:12:38,480
delivered to us

00:12:35,279 --> 00:12:40,160
how it was scanned and without

00:12:38,480 --> 00:12:42,399
rotating this image you see we start to

00:12:40,160 --> 00:12:43,200
lose some of the responses from the

00:12:42,399 --> 00:12:45,920
vision api

00:12:43,200 --> 00:12:47,920
we no longer get landmark information we

00:12:45,920 --> 00:12:50,839
lose a lot of the relevant

00:12:47,920 --> 00:12:53,279
objects and labels that google had

00:12:50,839 --> 00:12:54,720
detected and we start to get

00:12:53,279 --> 00:12:56,560
some responses that are not very

00:12:54,720 --> 00:13:00,000
accurate they're excuse me

00:12:56,560 --> 00:13:02,399
things like top shoe and room

00:13:00,000 --> 00:13:03,839
so we tried automatically determining

00:13:02,399 --> 00:13:06,480
the correct orientation

00:13:03,839 --> 00:13:07,760
of the image unfortunately that was

00:13:06,480 --> 00:13:09,279
pretty inconsistent as well we tried

00:13:07,760 --> 00:13:11,839
things like horizon detection

00:13:09,279 --> 00:13:13,120
without too much success so object

00:13:11,839 --> 00:13:15,680
recognition wasn't going to be as

00:13:13,120 --> 00:13:18,320
helpful as we had initially thought

00:13:15,680 --> 00:13:20,000
so we looked at facial recognition the

00:13:18,320 --> 00:13:22,240
idea that computers can recognize

00:13:20,000 --> 00:13:23,120
faces from any image has become almost a

00:13:22,240 --> 00:13:24,800
meme

00:13:23,120 --> 00:13:25,760
uh particularly if you talk to people

00:13:24,800 --> 00:13:28,000
who aren't as familiar with the

00:13:25,760 --> 00:13:31,360
technology

00:13:28,000 --> 00:13:33,120
here we have uh john this is john lennon

00:13:31,360 --> 00:13:36,639
and yoko ono

00:13:33,120 --> 00:13:37,279
in 1972 it's hard to see yoga on in this

00:13:36,639 --> 00:13:38,639
picture

00:13:37,279 --> 00:13:40,720
but obviously john lennon is a pretty

00:13:38,639 --> 00:13:42,959
recognizable face and the sort of

00:13:40,720 --> 00:13:46,160
person that you would expect that facial

00:13:42,959 --> 00:13:48,800
recognition might be able to recognize

00:13:46,160 --> 00:13:50,480
so first off a lot of companies shy away

00:13:48,800 --> 00:13:51,120
from recognizing faces for obvious

00:13:50,480 --> 00:13:53,120
reasons

00:13:51,120 --> 00:13:54,880
privacy for one thing and there's been i

00:13:53,120 --> 00:13:56,800
think a lot written about

00:13:54,880 --> 00:13:58,560
facial recognition's ability or

00:13:56,800 --> 00:14:00,399
inability to distinguish between people

00:13:58,560 --> 00:14:03,120
of color

00:14:00,399 --> 00:14:04,720
google as an example uh that we're

00:14:03,120 --> 00:14:06,800
looking at here will identify

00:14:04,720 --> 00:14:08,160
where the faces in a photo are but it

00:14:06,800 --> 00:14:08,560
just tells you some attributes about the

00:14:08,160 --> 00:14:10,399
face

00:14:08,560 --> 00:14:12,320
like is the person likely to be happy or

00:14:10,399 --> 00:14:15,120
sad are they wearing a hat it doesn't

00:14:12,320 --> 00:14:18,240
actually tell you the name of the person

00:14:15,120 --> 00:14:21,040
amazon does have an api

00:14:18,240 --> 00:14:22,720
a celebrity recognition api it doesn't

00:14:21,040 --> 00:14:24,880
recognize mr lennon here and you know

00:14:22,720 --> 00:14:26,720
whether that's because it's an old photo

00:14:24,880 --> 00:14:27,920
it's black and white maybe it's because

00:14:26,720 --> 00:14:29,040
you know the peace sign that he's

00:14:27,920 --> 00:14:33,440
flashing

00:14:29,040 --> 00:14:35,440
is obscuring too much of his face

00:14:33,440 --> 00:14:37,120
various companies also allow you to

00:14:35,440 --> 00:14:38,800
provide your own set of human classified

00:14:37,120 --> 00:14:40,160
images to train a model to recognize a

00:14:38,800 --> 00:14:42,480
face

00:14:40,160 --> 00:14:43,440
that is pretty expensive and time

00:14:42,480 --> 00:14:45,120
consuming

00:14:43,440 --> 00:14:47,600
for an archive that spans a few hundred

00:14:45,120 --> 00:14:49,440
thousand notable people over 100 years

00:14:47,600 --> 00:14:51,680
so we decided that that was too

00:14:49,440 --> 00:14:54,800
expensive

00:14:51,680 --> 00:14:56,480
and so finally we're left with uh text

00:14:54,800 --> 00:15:00,240
recognition the ability to read

00:14:56,480 --> 00:15:02,639
text from photographs and so here's that

00:15:00,240 --> 00:15:05,040
photo from earlier and if we look at the

00:15:02,639 --> 00:15:08,079
back of this image

00:15:05,040 --> 00:15:09,519
you will see this image was published in

00:15:08,079 --> 00:15:11,199
the new york times

00:15:09,519 --> 00:15:12,959
and one of the things that the archivist

00:15:11,199 --> 00:15:14,000
did when an image was published was to

00:15:12,959 --> 00:15:15,600
paste or tape

00:15:14,000 --> 00:15:16,800
the caption as it was published to the

00:15:15,600 --> 00:15:17,760
back of the print and so that's what

00:15:16,800 --> 00:15:20,639
you're seeing here

00:15:17,760 --> 00:15:22,399
in a brisk wind atop the arctic if

00:15:20,639 --> 00:15:23,920
we run the back of this image through

00:15:22,399 --> 00:15:25,920
text recognition

00:15:23,920 --> 00:15:27,360
this is what google's vision api

00:15:25,920 --> 00:15:30,399
recognizes

00:15:27,360 --> 00:15:33,440
um and i've built

00:15:30,399 --> 00:15:35,839
the caption you can see it's great

00:15:33,440 --> 00:15:38,160
it's perfect even um all of the search

00:15:35,839 --> 00:15:40,959
terms that we wanted from before

00:15:38,160 --> 00:15:42,160
are there we've got paris we've got the

00:15:40,959 --> 00:15:44,320
eiffel tower

00:15:42,160 --> 00:15:45,440
taurus arctic triumph you've even got

00:15:44,320 --> 00:15:48,079
the name of the photographer

00:15:45,440 --> 00:15:48,560
there's a few dates that the vision api

00:15:48,079 --> 00:15:50,240
uh

00:15:48,560 --> 00:15:52,399
recognized in text that might be

00:15:50,240 --> 00:15:55,360
relevant

00:15:52,399 --> 00:15:56,800
it's not always that easy though so

00:15:55,360 --> 00:15:57,440
here's amelia earhart with one of her

00:15:56,800 --> 00:15:59,680
planes

00:15:57,440 --> 00:16:01,600
if we look at the back of this image

00:15:59,680 --> 00:16:04,000
we'll see again

00:16:01,600 --> 00:16:05,839
there's that caption that's been pasted

00:16:04,000 --> 00:16:07,839
but it's been damaged

00:16:05,839 --> 00:16:09,440
and as you can see the vision api did

00:16:07,839 --> 00:16:11,759
not do as well with it as it did with

00:16:09,440 --> 00:16:14,160
the last example

00:16:11,759 --> 00:16:16,240
earhart nor wheeler field were

00:16:14,160 --> 00:16:18,320
recognized from the caption

00:16:16,240 --> 00:16:19,360
it didn't pick up ms erhart's name and

00:16:18,320 --> 00:16:22,639
handwriting

00:16:19,360 --> 00:16:23,839
and the dates are all wrong if we look

00:16:22,639 --> 00:16:27,120
at another example

00:16:23,839 --> 00:16:28,639
this is amelia earhart again and

00:16:27,120 --> 00:16:30,160
we look at the back of that image

00:16:28,639 --> 00:16:32,480
there's no caption this time

00:16:30,160 --> 00:16:33,680
it's just stamps and handwriting and you

00:16:32,480 --> 00:16:35,360
know i should say we were pretty

00:16:33,680 --> 00:16:37,440
impressed by what text recognition could

00:16:35,360 --> 00:16:40,079
read when it came to handwriting

00:16:37,440 --> 00:16:41,759
but as you can see here it did not read

00:16:40,079 --> 00:16:43,600
amelia earhart correctly it read it as

00:16:41,759 --> 00:16:45,440
limia carhart

00:16:43,600 --> 00:16:47,040
and there are photos in the archive with

00:16:45,440 --> 00:16:48,880
even less information than this one

00:16:47,040 --> 00:16:50,720
so it became pretty clear that we

00:16:48,880 --> 00:16:52,480
weren't going to be able to build

00:16:50,720 --> 00:16:53,759
a good search experience that relied

00:16:52,480 --> 00:16:54,959
just on the information that we got from

00:16:53,759 --> 00:16:55,839
the images alone that we were going to

00:16:54,959 --> 00:16:59,120
have to

00:16:55,839 --> 00:16:59,120
to look further afield

00:16:59,440 --> 00:17:05,199
but we had a trump card our archive was

00:17:02,320 --> 00:17:07,520
already classified

00:17:05,199 --> 00:17:09,199
and that's a pretty great thing because

00:17:07,520 --> 00:17:11,280
for more than a century we had

00:17:09,199 --> 00:17:14,240
librarians clipping and cataloging and

00:17:11,280 --> 00:17:16,839
categorizing content by topic

00:17:14,240 --> 00:17:20,480
and that was always going to be our best

00:17:16,839 --> 00:17:23,439
input on forming our search engine

00:17:20,480 --> 00:17:23,839
so let's get into it the first thing we

00:17:23,439 --> 00:17:26,160
had

00:17:23,839 --> 00:17:27,120
are folder covers so remember the folder

00:17:26,160 --> 00:17:28,799
in which

00:17:27,120 --> 00:17:31,360
for example the email air hard pictures

00:17:28,799 --> 00:17:32,080
came from so folder covers are easy to

00:17:31,360 --> 00:17:34,000
read

00:17:32,080 --> 00:17:35,440
uh but they have a very broad

00:17:34,000 --> 00:17:37,440
categorization

00:17:35,440 --> 00:17:39,600
so this is pretty easy to tell here that

00:17:37,440 --> 00:17:42,720
this is this folder is gonna have

00:17:39,600 --> 00:17:43,679
photos probably of family life within ir

00:17:42,720 --> 00:17:45,280
heart

00:17:43,679 --> 00:17:47,520
and even though it's handwritten it's

00:17:45,280 --> 00:17:49,520
block text so most of the text

00:17:47,520 --> 00:17:51,200
recognition apis and systems are gonna

00:17:49,520 --> 00:17:53,039
be able to pull this out

00:17:51,200 --> 00:17:54,640
the problem though is it's broad i mean

00:17:53,039 --> 00:17:56,320
there are probably gonna be other photos

00:17:54,640 --> 00:17:58,480
in here that are not

00:17:56,320 --> 00:18:00,799
directly connected to this topic and

00:17:58,480 --> 00:18:03,600
you're gonna have false positives

00:18:00,799 --> 00:18:05,520
but we have the card catalog which as

00:18:03,600 --> 00:18:07,760
we'll see can be hard to read

00:18:05,520 --> 00:18:11,360
certainly by machines but it is it has a

00:18:07,760 --> 00:18:13,600
rich and granular classification

00:18:11,360 --> 00:18:14,559
so here is one of the cards for melee

00:18:13,600 --> 00:18:17,760
earhart

00:18:14,559 --> 00:18:19,919
and as you can see um based on

00:18:17,760 --> 00:18:21,840
what some of our tax recognition you

00:18:19,919 --> 00:18:23,360
guys recognize it actually pulled out

00:18:21,840 --> 00:18:25,039
enough of this

00:18:23,360 --> 00:18:26,480
to make a pretty decent search

00:18:25,039 --> 00:18:29,679
experience

00:18:26,480 --> 00:18:31,679
but even the best text recognition is

00:18:29,679 --> 00:18:33,200
is not going to make it a good

00:18:31,679 --> 00:18:34,799
experience to read this you're always

00:18:33,200 --> 00:18:37,200
going to want to read the original text

00:18:34,799 --> 00:18:38,720
and google books for example follows

00:18:37,200 --> 00:18:39,600
this model where when you search you

00:18:38,720 --> 00:18:41,600
search

00:18:39,600 --> 00:18:43,840
the ocr text but when you're looking at

00:18:41,600 --> 00:18:48,320
the book you're looking at the original

00:18:43,840 --> 00:18:49,919
document the images of the original book

00:18:48,320 --> 00:18:52,720
and then also your brain the human

00:18:49,919 --> 00:18:54,400
brain's programmed to fill in the gaps

00:18:52,720 --> 00:18:56,480
this card the top of this card is

00:18:54,400 --> 00:18:59,280
damaged but the human brain can figure

00:18:56,480 --> 00:19:01,200
out this is probably male 1

00:18:59,280 --> 00:19:02,320
but but one thing that became apparent

00:19:01,200 --> 00:19:04,559
to us is we still

00:19:02,320 --> 00:19:06,160
wanted to give our digital users this

00:19:04,559 --> 00:19:07,760
experience of being able to go through

00:19:06,160 --> 00:19:09,760
the cards both for additional

00:19:07,760 --> 00:19:11,280
context and sometimes it gives you other

00:19:09,760 --> 00:19:12,960
avenues to explore

00:19:11,280 --> 00:19:14,320
so we wanted to have this experience for

00:19:12,960 --> 00:19:16,880
our users

00:19:14,320 --> 00:19:18,320
and it needed to be um you know not a

00:19:16,880 --> 00:19:19,520
jarring experience things need to be

00:19:18,320 --> 00:19:21,120
uniform and straight

00:19:19,520 --> 00:19:22,960
as we'll see examples of later that's

00:19:21,120 --> 00:19:24,960
not always the case

00:19:22,960 --> 00:19:26,080
one other thing with text recognition is

00:19:24,960 --> 00:19:28,240
when you have

00:19:26,080 --> 00:19:29,760
cards that are mostly handwritten like

00:19:28,240 --> 00:19:33,120
our earlier example about

00:19:29,760 --> 00:19:34,799
william veek um you know the handwritten

00:19:33,120 --> 00:19:36,880
cards are even harder to read so you

00:19:34,799 --> 00:19:38,960
definitely want the original text

00:19:36,880 --> 00:19:41,919
to refer to and you want to have a good

00:19:38,960 --> 00:19:45,200
linear uniform experience as you scroll

00:19:41,919 --> 00:19:47,360
scrolling the cards so what are some of

00:19:45,200 --> 00:19:48,559
the flaws and defects of fuel that i was

00:19:47,360 --> 00:19:51,039
talking about

00:19:48,559 --> 00:19:52,000
so here's an example some of our carts

00:19:51,039 --> 00:19:53,919
actually a lot of our

00:19:52,000 --> 00:19:55,760
carts came upside down in crooked and

00:19:53,919 --> 00:19:57,200
they had this black border around them

00:19:55,760 --> 00:19:59,840
obviously you wouldn't want to scan this

00:19:57,200 --> 00:20:02,000
this would be very jarring

00:19:59,840 --> 00:20:03,200
but it's easy to figure out and then you

00:20:02,000 --> 00:20:05,039
can straighten it

00:20:03,200 --> 00:20:06,400
here's another example that's harder to

00:20:05,039 --> 00:20:09,360
clean um this

00:20:06,400 --> 00:20:11,360
is there's obviously an overlap here and

00:20:09,360 --> 00:20:11,679
and so we not only have to get rid of

00:20:11,360 --> 00:20:13,440
the

00:20:11,679 --> 00:20:15,280
card underneath it we also have to go

00:20:13,440 --> 00:20:19,840
back and make sure that that other card

00:20:15,280 --> 00:20:21,919
was an archive in our digitized archive

00:20:19,840 --> 00:20:24,240
another example it's a really quite

00:20:21,919 --> 00:20:26,080
crooked and a corner is cut off so

00:20:24,240 --> 00:20:27,919
i should mention that the crookedness

00:20:26,080 --> 00:20:29,440
and the upside down that really affects

00:20:27,919 --> 00:20:31,919
the quality of the ocr

00:20:29,440 --> 00:20:32,720
so you really want text going you know

00:20:31,919 --> 00:20:34,960
right to left

00:20:32,720 --> 00:20:37,039
top to bottom and ocr tends to do a lot

00:20:34,960 --> 00:20:39,440
better in that situation

00:20:37,039 --> 00:20:41,520
so this is a recurring theme that we ran

00:20:39,440 --> 00:20:44,320
into with the various things

00:20:41,520 --> 00:20:46,240
we were constantly cleaning data you

00:20:44,320 --> 00:20:48,080
know we were detecting problems we were

00:20:46,240 --> 00:20:49,440
figuring out techniques to clean them

00:20:48,080 --> 00:20:51,280
or validating them and we'd find

00:20:49,440 --> 00:20:52,159
something else and this was an endless

00:20:51,280 --> 00:20:54,080
quest

00:20:52,159 --> 00:20:56,480
and not only with cards you know when

00:20:54,080 --> 00:20:58,159
we're doing text detection on backs of

00:20:56,480 --> 00:21:00,799
images and folders

00:20:58,159 --> 00:21:02,720
you know orientations and maybe a

00:21:00,799 --> 00:21:03,600
specific question just to pull out the

00:21:02,720 --> 00:21:06,000
dates

00:21:03,600 --> 00:21:07,919
all of these different things had you

00:21:06,000 --> 00:21:08,240
know this sort of process of detection

00:21:07,919 --> 00:21:10,000
and

00:21:08,240 --> 00:21:12,400
cleaning and validating it had a very

00:21:10,000 --> 00:21:13,520
long tail and in my case my product

00:21:12,400 --> 00:21:15,440
manager was will

00:21:13,520 --> 00:21:17,280
and when he's your product manager he's

00:21:15,440 --> 00:21:17,760
going to push you as far along to the

00:21:17,280 --> 00:21:21,120
right

00:21:17,760 --> 00:21:22,080
as practical and possible um so this was

00:21:21,120 --> 00:21:23,919
this was something we're

00:21:22,080 --> 00:21:25,440
constantly doing and we did a lot of

00:21:23,919 --> 00:21:27,679
things you know to help us

00:21:25,440 --> 00:21:28,960
detect you know we would send send up

00:21:27,679 --> 00:21:31,520
structured information

00:21:28,960 --> 00:21:32,960
to bigquery we'd do the analysis there

00:21:31,520 --> 00:21:33,679
we would use jupiter notebooks to do

00:21:32,960 --> 00:21:36,559
analysis

00:21:33,679 --> 00:21:38,799
we would clean uh cards and images with

00:21:36,559 --> 00:21:40,159
opencv and image magic and a host of

00:21:38,799 --> 00:21:42,240
other tools so this was

00:21:40,159 --> 00:21:44,799
while this may seem arduous and tedious

00:21:42,240 --> 00:21:47,440
it was really fun actually to do this

00:21:44,799 --> 00:21:49,120
so here's let's walk through an example

00:21:47,440 --> 00:21:50,880
so here is a crooked card again

00:21:49,120 --> 00:21:52,400
um so we want to straighten this we want

00:21:50,880 --> 00:21:54,000
to get rid of the borders how would one

00:21:52,400 --> 00:21:55,840
do that

00:21:54,000 --> 00:21:57,440
turns out the best way to do that is you

00:21:55,840 --> 00:21:59,200
want to detect the corners

00:21:57,440 --> 00:22:00,720
and there are a couple of well-known

00:21:59,200 --> 00:22:02,799
algorithms to do that there's a sheet

00:22:00,720 --> 00:22:04,080
omasi algorithm and a harris detection

00:22:02,799 --> 00:22:06,400
algorithm both of which

00:22:04,080 --> 00:22:08,080
are implemented by opencv the very

00:22:06,400 --> 00:22:10,840
famous computer machine

00:22:08,080 --> 00:22:12,159
open source library so you detect the

00:22:10,840 --> 00:22:13,760
corners

00:22:12,159 --> 00:22:15,360
for the sheet of mossy i should say you

00:22:13,760 --> 00:22:16,480
may want to blur the image first because

00:22:15,360 --> 00:22:18,559
that leads to better

00:22:16,480 --> 00:22:20,000
edge detection and hence better corner

00:22:18,559 --> 00:22:22,159
detection

00:22:20,000 --> 00:22:24,080
so once you have the corners it's easy

00:22:22,159 --> 00:22:27,200
to determine the angle of rotation

00:22:24,080 --> 00:22:29,120
just using basic high school trick so

00:22:27,200 --> 00:22:30,400
you know the corners you have the angle

00:22:29,120 --> 00:22:33,039
of rotation

00:22:30,400 --> 00:22:34,640
you straighten the card that's great and

00:22:33,039 --> 00:22:36,159
so now you still have the coordinates

00:22:34,640 --> 00:22:37,679
the straightened coordinates and you can

00:22:36,159 --> 00:22:39,120
crop out the part of the image that you

00:22:37,679 --> 00:22:40,480
want and then you wind up with something

00:22:39,120 --> 00:22:41,840
like this

00:22:40,480 --> 00:22:43,919
so these were the kinds of problems that

00:22:41,840 --> 00:22:46,559
we're solving and you know as i said it

00:22:43,919 --> 00:22:48,559
was it was a really fun experience

00:22:46,559 --> 00:22:50,480
so let's talk about another set of

00:22:48,559 --> 00:22:53,440
problems that we ran into

00:22:50,480 --> 00:22:54,720
problems with ocr text in particular as

00:22:53,440 --> 00:22:56,080
we've seen examples you know

00:22:54,720 --> 00:22:57,679
sierra's great but it's going to have a

00:22:56,080 --> 00:23:00,559
hard time with white space with

00:22:57,679 --> 00:23:02,400
handwritten text with type of characters

00:23:00,559 --> 00:23:04,320
and so we had to figure out strategies

00:23:02,400 --> 00:23:07,280
to cope with those

00:23:04,320 --> 00:23:09,360
so here's an example of a card with

00:23:07,280 --> 00:23:11,760
typewritten text we found that

00:23:09,360 --> 00:23:13,120
um some of the tools really had a hard

00:23:11,760 --> 00:23:15,280
time distinguishing between

00:23:13,120 --> 00:23:17,360
alls and ones so here it detected a one

00:23:15,280 --> 00:23:19,440
instead of a help

00:23:17,360 --> 00:23:20,640
occasionally it would insert white

00:23:19,440 --> 00:23:23,120
spaces so here

00:23:20,640 --> 00:23:24,240
it inserted the space between af and

00:23:23,120 --> 00:23:26,640
afghanistan

00:23:24,240 --> 00:23:27,919
and that is a problem because text space

00:23:26,640 --> 00:23:31,280
is very important

00:23:27,919 --> 00:23:32,720
uh as the default um strategy in most

00:23:31,280 --> 00:23:35,840
search engines have had

00:23:32,720 --> 00:23:37,120
separating words and tokenizing words

00:23:35,840 --> 00:23:39,360
and so on

00:23:37,120 --> 00:23:40,320
so you know this this would cause us

00:23:39,360 --> 00:23:42,720
problems uh

00:23:40,320 --> 00:23:44,320
for a lot of queries i should also say

00:23:42,720 --> 00:23:44,880
that we were using postgres in the

00:23:44,320 --> 00:23:47,200
beginning

00:23:44,880 --> 00:23:48,480
uh for a lot of this um until we

00:23:47,200 --> 00:23:50,880
couldn't you know we

00:23:48,480 --> 00:23:52,080
started using elasticsearch after that

00:23:50,880 --> 00:23:55,039
for a variety of reasons which we're

00:23:52,080 --> 00:23:55,039
happy to talk to you about

00:23:55,120 --> 00:23:58,640
um okay let's see another example here

00:23:56,880 --> 00:24:01,120
so this is again handwritten text

00:23:58,640 --> 00:24:02,080
this is about gerald varbark who's a

00:24:01,120 --> 00:24:04,640
cellist

00:24:02,080 --> 00:24:06,159
but but we we got chenis back and

00:24:04,640 --> 00:24:08,240
obviously that one too

00:24:06,159 --> 00:24:09,919
so we needed a problem we need to think

00:24:08,240 --> 00:24:12,799
of something to help us with this

00:24:09,919 --> 00:24:15,760
and that's where will came up with a tax

00:24:12,799 --> 00:24:18,480
recognition bake off

00:24:15,760 --> 00:24:19,440
so as jim i mentioned you know we were

00:24:18,480 --> 00:24:20,640
running into these problems with

00:24:19,440 --> 00:24:21,919
textbook condition and

00:24:20,640 --> 00:24:23,360
and we looked at playing around with

00:24:21,919 --> 00:24:23,760
them by trying to adjust the search

00:24:23,360 --> 00:24:25,840
engine

00:24:23,760 --> 00:24:27,360
but we also started to wonder how other

00:24:25,840 --> 00:24:30,480
tools would perform

00:24:27,360 --> 00:24:32,240
um when it came to text recognition and

00:24:30,480 --> 00:24:34,159
if you have shimon as an engineering

00:24:32,240 --> 00:24:36,320
manager he's going to make you work

00:24:34,159 --> 00:24:38,400
really hard to prove that it's worth the

00:24:36,320 --> 00:24:41,520
effort before we go off and implement

00:24:38,400 --> 00:24:44,240
a different provider so we set up a test

00:24:41,520 --> 00:24:46,240
so we started by hand transcribing

00:24:44,240 --> 00:24:47,279
hundreds of cards and folder covers

00:24:46,240 --> 00:24:49,360
and then we ran them through text

00:24:47,279 --> 00:24:50,000
recognition services from google and

00:24:49,360 --> 00:24:51,760
amazon

00:24:50,000 --> 00:24:53,440
and two different services from

00:24:51,760 --> 00:24:54,960
microsoft and then we measured the

00:24:53,440 --> 00:24:56,880
accuracy of the results

00:24:54,960 --> 00:24:58,159
so here's the same card from here from

00:24:56,880 --> 00:24:59,520
gerald varberg

00:24:58,159 --> 00:25:01,440
and the darker the green the more

00:24:59,520 --> 00:25:03,039
accurate the text recognition was

00:25:01,440 --> 00:25:04,559
you can see the hand transcribed text

00:25:03,039 --> 00:25:05,840
and the results from each of the

00:25:04,559 --> 00:25:08,000
different providers

00:25:05,840 --> 00:25:08,960
and you can see here that microsoft's

00:25:08,000 --> 00:25:10,960
handwriting

00:25:08,960 --> 00:25:12,400
recognition api was the most accurate

00:25:10,960 --> 00:25:14,640
here which doesn't

00:25:12,400 --> 00:25:16,640
um not a huge surprise because

00:25:14,640 --> 00:25:18,559
considering this is handwriting

00:25:16,640 --> 00:25:20,799
but which provider was more accurate

00:25:18,559 --> 00:25:23,279
really dependent on the example

00:25:20,799 --> 00:25:24,080
so as i mentioned you know we were

00:25:23,279 --> 00:25:26,080
really

00:25:24,080 --> 00:25:27,679
impressed by the handwriting that some

00:25:26,080 --> 00:25:29,279
of these services could read

00:25:27,679 --> 00:25:31,360
and you know this example for example i

00:25:29,279 --> 00:25:32,159
can barely read that i'm still not sure

00:25:31,360 --> 00:25:35,360
if that's an o

00:25:32,159 --> 00:25:36,880
or an a in huge already's name and

00:25:35,360 --> 00:25:39,279
you can see here google was the most

00:25:36,880 --> 00:25:40,400
accurate in identifying this or at least

00:25:39,279 --> 00:25:42,320
identifying it

00:25:40,400 --> 00:25:45,120
as as we read it and the results are

00:25:42,320 --> 00:25:48,320
totally different from the other example

00:25:45,120 --> 00:25:50,159
so we found out a couple things one is

00:25:48,320 --> 00:25:51,279
that each provider has its own strengths

00:25:50,159 --> 00:25:53,679
and weaknesses

00:25:51,279 --> 00:25:56,159
so the right solution for your project

00:25:53,679 --> 00:25:58,000
probably depends on the source material

00:25:56,159 --> 00:25:59,520
for what we were trying to do no one

00:25:58,000 --> 00:26:02,320
provider was a silver bullet

00:25:59,520 --> 00:26:04,400
between handwriting which can either be

00:26:02,320 --> 00:26:07,120
surprisingly good or just gibberish

00:26:04,400 --> 00:26:08,240
when machines try to read it and type

00:26:07,120 --> 00:26:10,159
written text

00:26:08,240 --> 00:26:12,240
which none of our providers seem to do

00:26:10,159 --> 00:26:12,799
very well with our best chances of

00:26:12,240 --> 00:26:14,320
success

00:26:12,799 --> 00:26:15,919
were when we allowed multiple algorithms

00:26:14,320 --> 00:26:18,880
to take a crockett

00:26:15,919 --> 00:26:20,799
and when we had multiple results the

00:26:18,880 --> 00:26:22,240
chances that we captured everything

00:26:20,799 --> 00:26:24,480
successfully between

00:26:22,240 --> 00:26:26,080
all of those providers increased by

00:26:24,480 --> 00:26:27,120
anywhere from between 35

00:26:26,080 --> 00:26:29,440
when you're dealing with typewritten

00:26:27,120 --> 00:26:30,559
texts and 300 when you're dealing with

00:26:29,440 --> 00:26:32,640
handwriting

00:26:30,559 --> 00:26:33,679
so i should mention here by the way you

00:26:32,640 --> 00:26:34,880
know there have been new products that

00:26:33,679 --> 00:26:35,520
have come out since the last time we

00:26:34,880 --> 00:26:39,039
tested this

00:26:35,520 --> 00:26:42,880
so your results might vary a little bit

00:26:39,039 --> 00:26:45,520
so now we have at least you know

00:26:42,880 --> 00:26:47,600
in all together some reasonably accurate

00:26:45,520 --> 00:26:49,600
text off of our index cards

00:26:47,600 --> 00:26:51,679
and the big last step in order to put it

00:26:49,600 --> 00:26:53,600
to use was to structure it so that it

00:26:51,679 --> 00:26:54,000
can be more easily searched and applied

00:26:53,600 --> 00:26:57,360
to

00:26:54,000 --> 00:26:59,919
photo photos so

00:26:57,360 --> 00:27:01,840
let's take an example from before this

00:26:59,919 --> 00:27:04,960
is that same

00:27:01,840 --> 00:27:08,480
index card referencing jim buck

00:27:04,960 --> 00:27:11,679
and when we start to break it up

00:27:08,480 --> 00:27:14,159
what you find is there's a topic there's

00:27:11,679 --> 00:27:15,200
a sub-topic or a description for that

00:27:14,159 --> 00:27:16,320
topic

00:27:15,200 --> 00:27:18,799
and it tells you where to find those

00:27:16,320 --> 00:27:19,600
images in this case what this card is

00:27:18,799 --> 00:27:21,279
telling you

00:27:19,600 --> 00:27:22,799
is that you can find photos of jim buck

00:27:21,279 --> 00:27:25,840
in this other folder

00:27:22,799 --> 00:27:27,440
animals dogs pets and this

00:27:25,840 --> 00:27:29,200
isn't a folder exclusively about jim

00:27:27,440 --> 00:27:30,720
buck this is a folder about dogs and

00:27:29,200 --> 00:27:32,840
pets primarily

00:27:30,720 --> 00:27:34,159
this is what we would call an indirect

00:27:32,840 --> 00:27:37,360
reference

00:27:34,159 --> 00:27:39,039
so what we would do is basically

00:27:37,360 --> 00:27:40,399
using the responses from the text

00:27:39,039 --> 00:27:42,000
recognition software

00:27:40,399 --> 00:27:43,600
go through line by line look at the

00:27:42,000 --> 00:27:45,760
coordinates of the text with the

00:27:43,600 --> 00:27:48,320
services we call bounding boxes

00:27:45,760 --> 00:27:50,880
to determine what's on each line and to

00:27:48,320 --> 00:27:54,679
break the cards down into these pieces

00:27:50,880 --> 00:27:57,200
and what you get here is folder id

00:27:54,679 --> 00:27:59,039
4645l40 the name of that folder is

00:27:57,200 --> 00:28:01,279
animals dogs pets

00:27:59,039 --> 00:28:03,200
and this includes photos of jim buck

00:28:01,279 --> 00:28:06,399
professional dog walker

00:28:03,200 --> 00:28:09,360
so that's easy enough but the examples

00:28:06,399 --> 00:28:10,159
quickly get more complicated so here's

00:28:09,360 --> 00:28:12,640
another card for

00:28:10,159 --> 00:28:13,600
from earlier this has a ton of

00:28:12,640 --> 00:28:15,200
references

00:28:13,600 --> 00:28:17,120
it has direct references and indirect

00:28:15,200 --> 00:28:18,799
references and subtopics

00:28:17,120 --> 00:28:20,240
and references that are both direct

00:28:18,799 --> 00:28:22,000
references and subtopics or other

00:28:20,240 --> 00:28:25,360
interact preferences

00:28:22,000 --> 00:28:26,799
and you know so so quickly

00:28:25,360 --> 00:28:29,200
you start to add a lot of complexity to

00:28:26,799 --> 00:28:30,399
your app as you start to go through

00:28:29,200 --> 00:28:33,279
these lines so

00:28:30,399 --> 00:28:33,919
for example uh that first reference

00:28:33,279 --> 00:28:36,720
there

00:28:33,919 --> 00:28:37,520
you've got papillon that's a direct

00:28:36,720 --> 00:28:41,279
reference

00:28:37,520 --> 00:28:44,159
to 4645l 64.

00:28:41,279 --> 00:28:45,600
you've got pedigrees um if you want to

00:28:44,159 --> 00:28:48,080
see photos of pedigrees you have to go

00:28:45,600 --> 00:28:51,520
look in the dodson folder

00:28:48,080 --> 00:28:53,520
and then you've got um at the bottom

00:28:51,520 --> 00:28:55,279
you've got that pets pet shows and

00:28:53,520 --> 00:28:58,480
miscellaneous reference

00:28:55,279 --> 00:29:00,080
that's folder 4645l40

00:28:58,480 --> 00:29:02,000
that's again a that's a direct reference

00:29:00,080 --> 00:29:03,760
so that's the title of that folder

00:29:02,000 --> 00:29:05,520
and from before we have that that folder

00:29:03,760 --> 00:29:06,799
includes jim buck professional dog

00:29:05,520 --> 00:29:09,360
walker

00:29:06,799 --> 00:29:10,880
and then at the very bottom you've got

00:29:09,360 --> 00:29:13,679
this indirect reference

00:29:10,880 --> 00:29:14,559
there are more photos of pets pet shows

00:29:13,679 --> 00:29:18,880
and miscellaneous

00:29:14,559 --> 00:29:22,720
in this other folder shows 1990

00:29:18,880 --> 00:29:24,480
and so as i said it gets pretty complex

00:29:22,720 --> 00:29:26,799
if you do it wrong the results can

00:29:24,480 --> 00:29:29,600
really get disastrous and so

00:29:26,799 --> 00:29:30,399
here's an example from an early attempt

00:29:29,600 --> 00:29:33,200
this is

00:29:30,399 --> 00:29:35,360
a folder about koi dogs but you can see

00:29:33,200 --> 00:29:38,480
in the tags there all this text that we

00:29:35,360 --> 00:29:39,120
applied from the card catalog you've got

00:29:38,480 --> 00:29:41,840
things like

00:29:39,120 --> 00:29:43,600
cows cougars collies all kinds of things

00:29:41,840 --> 00:29:46,480
that aren't actually in that folder

00:29:43,600 --> 00:29:47,600
and we we're pretty successful in making

00:29:46,480 --> 00:29:49,440
the search experience

00:29:47,600 --> 00:29:51,360
at this point a lot more frustrating for

00:29:49,440 --> 00:29:54,640
users than helpful

00:29:51,360 --> 00:29:55,679
but if you do it right and once you put

00:29:54,640 --> 00:29:58,159
all of the pieces

00:29:55,679 --> 00:29:59,200
the information we extracted from cards

00:29:58,159 --> 00:30:00,720
from folders

00:29:59,200 --> 00:30:02,880
and from the photos themselves all

00:30:00,720 --> 00:30:03,760
together you get a search experience

00:30:02,880 --> 00:30:06,399
like this

00:30:03,760 --> 00:30:08,080
so here we are we're going to do a

00:30:06,399 --> 00:30:09,600
search for jim buck

00:30:08,080 --> 00:30:11,840
before this would have taken hours to

00:30:09,600 --> 00:30:14,559
find these photos but now you put this

00:30:11,840 --> 00:30:15,919
search term in you get the dogs folder

00:30:14,559 --> 00:30:17,679
it tells you that jim buck

00:30:15,919 --> 00:30:19,600
is in that folder and you can jump

00:30:17,679 --> 00:30:22,960
directly to photos in that folder

00:30:19,600 --> 00:30:24,559
showing jim buck professional dog walker

00:30:22,960 --> 00:30:26,240
we did a number of other things to try

00:30:24,559 --> 00:30:27,200
and improve search and adjusting these

00:30:26,240 --> 00:30:29,039
images

00:30:27,200 --> 00:30:30,960
right now we're working on date

00:30:29,039 --> 00:30:33,360
extraction the ability to determine when

00:30:30,960 --> 00:30:35,279
a photo is actually from

00:30:33,360 --> 00:30:36,960
we played around a lot with the default

00:30:35,279 --> 00:30:38,880
elasticsearch settings

00:30:36,960 --> 00:30:40,559
to try and make sure that that things

00:30:38,880 --> 00:30:42,720
returned as expected

00:30:40,559 --> 00:30:43,840
we even tried correlating photos from

00:30:42,720 --> 00:30:46,399
our archive with

00:30:43,840 --> 00:30:48,159
scans of our newspapers of our archival

00:30:46,399 --> 00:30:50,880
newspapers to to get good information

00:30:48,159 --> 00:30:53,120
about when things happened

00:30:50,880 --> 00:30:54,240
and so finally i just want to mention

00:30:53,120 --> 00:30:55,760
you know there's been so much great

00:30:54,240 --> 00:30:57,919
visual storytelling that we've published

00:30:55,760 --> 00:30:59,039
as a result of this project

00:30:57,919 --> 00:31:01,279
here's some recent examples that our

00:30:59,039 --> 00:31:03,679
colleagues put together for example

00:31:01,279 --> 00:31:05,440
um when ruth vader ginsburg died we did

00:31:03,679 --> 00:31:08,880
a photo essay on her life

00:31:05,440 --> 00:31:08,880
using some photos from the morgue

00:31:09,760 --> 00:31:13,279
i love this one of her with the horse we

00:31:12,720 --> 00:31:16,840
did an

00:31:13,279 --> 00:31:19,679
essay on the first new york city pride

00:31:16,840 --> 00:31:20,960
march

00:31:19,679 --> 00:31:23,600
and these are all photos from the new

00:31:20,960 --> 00:31:26,640
york times and from our archive

00:31:23,600 --> 00:31:27,760
uh this is a great one um this is a

00:31:26,640 --> 00:31:30,720
private investigator

00:31:27,760 --> 00:31:32,960
from the 90s and we did an essay on all

00:31:30,720 --> 00:31:36,240
the different ways that she used two

00:31:32,960 --> 00:31:36,240
disguises that she used to wear

00:31:36,799 --> 00:31:40,320
and when muhammad ali died we did a big

00:31:38,880 --> 00:31:43,279
special section in the paper

00:31:40,320 --> 00:31:43,279
memorializing him

00:31:44,799 --> 00:31:48,240
so thank you very very much for coming

00:31:46,480 --> 00:31:50,880
the last thing i just wanted to say

00:31:48,240 --> 00:31:51,840
is the times is hiring uh if you want to

00:31:50,880 --> 00:31:54,960
work on

00:31:51,840 --> 00:31:57,360
fun projects like this um

00:31:54,960 --> 00:31:58,240
feel free to to browse the job openings

00:31:57,360 --> 00:32:01,679
that we have or

00:31:58,240 --> 00:32:02,960
reach out to shimon or me via our email

00:32:01,679 --> 00:32:05,600
thanks very much i think we've got about

00:32:02,960 --> 00:32:07,919
10 minutes for questions

00:32:05,600 --> 00:32:07,919
thank you

00:32:09,120 --> 00:32:14,880
so just looking at a couple of the

00:32:11,279 --> 00:32:17,120
questions that we had here

00:32:14,880 --> 00:32:20,080
one of the questions was around can can

00:32:17,120 --> 00:32:23,519
normal people access this information

00:32:20,080 --> 00:32:24,880
so right now unfortunately not um

00:32:23,519 --> 00:32:26,640
it's not available outside the building

00:32:24,880 --> 00:32:29,440
and the reason is because

00:32:26,640 --> 00:32:30,320
you know shimon mentioned we saved

00:32:29,440 --> 00:32:31,760
everything

00:32:30,320 --> 00:32:33,600
and that included a lot of things that

00:32:31,760 --> 00:32:36,240
we don't actually own

00:32:33,600 --> 00:32:38,080
so we have to be careful in what we use

00:32:36,240 --> 00:32:40,240
and what we show outside the building

00:32:38,080 --> 00:32:41,679
um one of the things one of the reasons

00:32:40,240 --> 00:32:43,679
that we're working on extracting dates

00:32:41,679 --> 00:32:45,120
from the backs of the images

00:32:43,679 --> 00:32:47,200
is so that we can more accurately

00:32:45,120 --> 00:32:48,799
determine whether the times actually

00:32:47,200 --> 00:32:50,640
owns the rights to it and you know we

00:32:48,799 --> 00:32:52,640
would love if if someday

00:32:50,640 --> 00:32:54,080
we're able to open this archive up to

00:32:52,640 --> 00:32:56,960
everybody else because it really is a

00:32:54,080 --> 00:32:59,679
tremendous archive

00:32:56,960 --> 00:33:01,440
yeah i see a question here about army

00:32:59,679 --> 00:33:04,559
feeding findings

00:33:01,440 --> 00:33:07,679
back to the providers um

00:33:04,559 --> 00:33:10,320
initially when we started doing this

00:33:07,679 --> 00:33:11,600
there we had a bit of a partnership with

00:33:10,320 --> 00:33:13,279
google and we were definitely

00:33:11,600 --> 00:33:15,919
talking to them a lot about some of the

00:33:13,279 --> 00:33:18,159
challenges we were running into

00:33:15,919 --> 00:33:19,200
but you know we haven't they haven't

00:33:18,159 --> 00:33:20,559
asked for

00:33:19,200 --> 00:33:22,880
none of the providers have really asked

00:33:20,559 --> 00:33:23,200
for us to feed the data back into them

00:33:22,880 --> 00:33:24,480
but

00:33:23,200 --> 00:33:28,080
i mean there was some of that back and

00:33:24,480 --> 00:33:28,080
forth with google in the beginning

00:33:28,640 --> 00:33:35,279
yeah and i'll also add you know the

00:33:31,760 --> 00:33:36,480
we hand categorized a very small subset

00:33:35,279 --> 00:33:39,600
of

00:33:36,480 --> 00:33:41,679
of the cards and the folder covers um

00:33:39,600 --> 00:33:43,360
it it was enough to sort of get a sense

00:33:41,679 --> 00:33:44,399
of how much more accurate it was to use

00:33:43,360 --> 00:33:46,399
the other providers

00:33:44,399 --> 00:33:48,960
but i don't believe it was actually

00:33:46,399 --> 00:33:50,480
enough to accurately train a model

00:33:48,960 --> 00:33:52,480
and this has been a big problem any time

00:33:50,480 --> 00:33:53,519
that we've looked at anything requires

00:33:52,480 --> 00:33:55,840
training a model

00:33:53,519 --> 00:33:57,120
there's just so many so much variation

00:33:55,840 --> 00:33:59,279
in the archive over

00:33:57,120 --> 00:34:00,240
you know it's a full century's worth of

00:33:59,279 --> 00:34:02,240
of

00:34:00,240 --> 00:34:03,760
you know people's individual preferences

00:34:02,240 --> 00:34:05,360
in terms of how they like to write

00:34:03,760 --> 00:34:07,600
things and that sort of stuff

00:34:05,360 --> 00:34:08,399
and it's just you know from the

00:34:07,600 --> 00:34:09,679
perspective of

00:34:08,399 --> 00:34:12,079
training something it's it's a real

00:34:09,679 --> 00:34:12,079
nightmare

00:34:12,720 --> 00:34:17,760
um i'll see the next one um so

00:34:15,839 --> 00:34:19,040
i think if you're asking about scanners

00:34:17,760 --> 00:34:22,480
i think we had a team of

00:34:19,040 --> 00:34:24,720
three scanners um going uh scanning them

00:34:22,480 --> 00:34:25,520
at any given time um in terms of

00:34:24,720 --> 00:34:27,200
engineers

00:34:25,520 --> 00:34:28,720
i think we've always had at least a

00:34:27,200 --> 00:34:31,760
couple of engineers up to

00:34:28,720 --> 00:34:33,359
three and will was the product manager

00:34:31,760 --> 00:34:35,839
and we had an excellent designer who

00:34:33,359 --> 00:34:38,079
really sort of focused on

00:34:35,839 --> 00:34:39,760
jenny i should really call her at uh who

00:34:38,079 --> 00:34:42,480
really sort of made the experience

00:34:39,760 --> 00:34:44,800
of the search as high quality as

00:34:42,480 --> 00:34:44,800
possible

00:34:44,960 --> 00:34:49,200
yeah dan asks about how do we choose

00:34:47,919 --> 00:34:50,960
which provider to use

00:34:49,200 --> 00:34:52,320
for text recognition for each card

00:34:50,960 --> 00:34:55,359
that's a good question dan

00:34:52,320 --> 00:34:58,240
um what we did was um

00:34:55,359 --> 00:34:58,640
we would in our search index we would

00:34:58,240 --> 00:35:00,320
use

00:34:58,640 --> 00:35:02,160
all of the text that all the recognizers

00:35:00,320 --> 00:35:05,280
provide all the

00:35:02,160 --> 00:35:06,640
providers recognized and the result of

00:35:05,280 --> 00:35:08,480
that was we were getting

00:35:06,640 --> 00:35:10,560
you know our best shot across all of

00:35:08,480 --> 00:35:12,720
them for the most part we found if

00:35:10,560 --> 00:35:13,599
if a provider recognized something

00:35:12,720 --> 00:35:15,520
incorrectly

00:35:13,599 --> 00:35:17,280
it was closer to gibberish than it was

00:35:15,520 --> 00:35:19,119
to a real word that was likely to yield

00:35:17,280 --> 00:35:21,280
an incorrect result

00:35:19,119 --> 00:35:23,440
when the user would search for for

00:35:21,280 --> 00:35:24,880
example ruth bader ginsburg

00:35:23,440 --> 00:35:26,480
we would look across all of those

00:35:24,880 --> 00:35:28,880
providers and then

00:35:26,480 --> 00:35:29,680
whichever the first provider that

00:35:28,880 --> 00:35:32,720
actually

00:35:29,680 --> 00:35:33,920
had that text in that response that's

00:35:32,720 --> 00:35:34,720
the one that we would actually display

00:35:33,920 --> 00:35:36,160
to the user

00:35:34,720 --> 00:35:37,920
so we were searching all three and then

00:35:36,160 --> 00:35:39,839
picking whatever one we thought was most

00:35:37,920 --> 00:35:44,240
relevant based on

00:35:39,839 --> 00:35:46,160
on the query

00:35:44,240 --> 00:35:47,839
uh we have a question from karen about

00:35:46,160 --> 00:35:50,000
what happens to the original photos

00:35:47,839 --> 00:35:51,680
yes yeah we keep them around uh

00:35:50,000 --> 00:35:53,359
occasionally there is a workflow where

00:35:51,680 --> 00:35:55,760
we want to rescan something

00:35:53,359 --> 00:35:57,280
because the original scan maybe wasn't

00:35:55,760 --> 00:35:58,560
as high quality as it could be so we

00:35:57,280 --> 00:36:01,920
definitely keep them and

00:35:58,560 --> 00:36:03,680
we're gonna keep them forever i hope

00:36:01,920 --> 00:36:05,440
yeah and we frequently the other thing

00:36:03,680 --> 00:36:06,800
i'll add to that is there's a lot of

00:36:05,440 --> 00:36:08,240
markings on the images you know the way

00:36:06,800 --> 00:36:11,599
that we used to

00:36:08,240 --> 00:36:12,800
um order up an image was you essentially

00:36:11,599 --> 00:36:15,680
write on it with a grease

00:36:12,800 --> 00:36:16,320
pen so all the scans have those markings

00:36:15,680 --> 00:36:17,760
on them

00:36:16,320 --> 00:36:19,200
a lot of times if we want to reuse that

00:36:17,760 --> 00:36:20,079
image we'll go back we'll see if we can

00:36:19,200 --> 00:36:23,280
find

00:36:20,079 --> 00:36:24,960
um the the negative we'll see if we can

00:36:23,280 --> 00:36:28,560
clean off the scan just to get an even

00:36:24,960 --> 00:36:30,880
cleaner version of that image

00:36:28,560 --> 00:36:31,680
um eugene asked if we came up with this

00:36:30,880 --> 00:36:34,880
project

00:36:31,680 --> 00:36:37,119
um we did not um you know

00:36:34,880 --> 00:36:39,440
the editors knew what a goldmine the

00:36:37,119 --> 00:36:41,520
morgue was we we've been using this

00:36:39,440 --> 00:36:43,440
for a very very long time we stopped

00:36:41,520 --> 00:36:46,960
putting new images in the morgue

00:36:43,440 --> 00:36:50,960
um back in i think the

00:36:46,960 --> 00:36:53,920
early to mid 90s but we've been using it

00:36:50,960 --> 00:36:55,920
you know almost daily even since then

00:36:53,920 --> 00:37:00,640
and if you go down there there are still

00:36:55,920 --> 00:37:02,400
you know folders of um you know

00:37:00,640 --> 00:37:05,200
really wonderful portraits just waiting

00:37:02,400 --> 00:37:05,200
to be used

00:37:05,359 --> 00:37:10,160
so i think i remember who actually came

00:37:08,320 --> 00:37:11,599
up with the idea for the project first

00:37:10,160 --> 00:37:13,359
we talked about digitizing this for a

00:37:11,599 --> 00:37:15,599
long time we

00:37:13,359 --> 00:37:16,960
um had looked at various companies who

00:37:15,599 --> 00:37:19,839
might be able to do this for us

00:37:16,960 --> 00:37:20,880
for cost for fee the problem with that

00:37:19,839 --> 00:37:23,680
was that

00:37:20,880 --> 00:37:25,200
any of those would require basically

00:37:23,680 --> 00:37:26,640
shipping that archive off for a period

00:37:25,200 --> 00:37:28,160
of time and not having access to it and

00:37:26,640 --> 00:37:29,599
so that was a real no-go

00:37:28,160 --> 00:37:32,079
and so the team that maintains the

00:37:29,599 --> 00:37:34,960
archive did sort of a proof of concept

00:37:32,079 --> 00:37:36,560
showing hey we can scan this many photos

00:37:34,960 --> 00:37:37,119
with this many people in this period of

00:37:36,560 --> 00:37:38,880
time

00:37:37,119 --> 00:37:40,560
and it's going to cost this much money

00:37:38,880 --> 00:37:42,320
and so it's actually more cost effective

00:37:40,560 --> 00:37:45,200
to do it in-house

00:37:42,320 --> 00:37:46,960
and then and then the technology i think

00:37:45,200 --> 00:37:50,079
the the cto and one of the

00:37:46,960 --> 00:37:51,440
svps at the time got involved to

00:37:50,079 --> 00:37:53,760
help build the idea of building this

00:37:51,440 --> 00:37:53,760
tool

00:37:57,200 --> 00:37:59,599
um shima do you want to take the next

00:37:58,240 --> 00:38:01,760
one do you see those questions in the q

00:37:59,599 --> 00:38:01,760
a

00:38:02,160 --> 00:38:05,760
uh i actually don't see it am i reading

00:38:04,400 --> 00:38:08,880
it i can read it then

00:38:05,760 --> 00:38:10,480
um so how much manual intervention did

00:38:08,880 --> 00:38:12,000
we have to do

00:38:10,480 --> 00:38:15,440
and where are we completely able to

00:38:12,000 --> 00:38:18,640
completely scan all the archive

00:38:15,440 --> 00:38:20,480
right um there was um

00:38:18,640 --> 00:38:21,760
i think so obviously the scanning is

00:38:20,480 --> 00:38:23,839
pretty manual uh

00:38:21,760 --> 00:38:25,920
and then sort of putting them in a

00:38:23,839 --> 00:38:26,640
directory is manual but once that

00:38:25,920 --> 00:38:28,800
happens

00:38:26,640 --> 00:38:30,640
there is a process that sort of pushes

00:38:28,800 --> 00:38:31,920
it up to the google cloud storage and

00:38:30,640 --> 00:38:32,960
that sort of kicks off the whole

00:38:31,920 --> 00:38:34,480
pipeline i mean

00:38:32,960 --> 00:38:36,560
initially when we're building it as i

00:38:34,480 --> 00:38:39,440
said we'd run into flaws and challenges

00:38:36,560 --> 00:38:41,839
and we'd have to go fix them

00:38:39,440 --> 00:38:43,599
but i mean right now the development on

00:38:41,839 --> 00:38:45,839
the system is stopped

00:38:43,599 --> 00:38:47,920
so we expect it to be functioning until

00:38:45,839 --> 00:38:49,680
the scanning is done we haven't finished

00:38:47,920 --> 00:38:51,839
the scanning yet it's a lot of images to

00:38:49,680 --> 00:38:53,440
scan obviously the pandemic has really

00:38:51,839 --> 00:38:54,880
put a damper on that we haven't been

00:38:53,440 --> 00:38:56,480
scanning anything for the last six or

00:38:54,880 --> 00:39:00,320
seven months

00:38:56,480 --> 00:39:01,760
but but we the manual interventions

00:39:00,320 --> 00:39:04,160
so the answers are a lot in the

00:39:01,760 --> 00:39:06,000
beginning uh as we ran into problems

00:39:04,160 --> 00:39:07,440
but fewer and fewer and now it's it's

00:39:06,000 --> 00:39:09,200
almost fully automated

00:39:07,440 --> 00:39:10,800
i mean it is fully automated that's the

00:39:09,200 --> 00:39:12,800
idea if there's a problem

00:39:10,800 --> 00:39:14,560
you know we'd get some kind of error

00:39:12,800 --> 00:39:16,880
about it and we'd investigate after the

00:39:14,560 --> 00:39:16,880
fact

00:39:17,040 --> 00:39:21,520
yeah and we had a really close um we

00:39:20,160 --> 00:39:23,200
were in really close communication

00:39:21,520 --> 00:39:24,880
with the team that was doing the

00:39:23,200 --> 00:39:26,800
scanning who had also reviewed the

00:39:24,880 --> 00:39:28,720
images as they got into the tool

00:39:26,800 --> 00:39:30,160
and as much as possible obviously we

00:39:28,720 --> 00:39:31,839
wanted to to correct

00:39:30,160 --> 00:39:33,839
any problems programmatically rather

00:39:31,839 --> 00:39:36,480
than having to devote people time

00:39:33,839 --> 00:39:38,240
either now to correct problems up front

00:39:36,480 --> 00:39:40,839
or to make you know make it if it's

00:39:38,240 --> 00:39:43,839
going to take longer when you're

00:39:40,839 --> 00:39:43,839
searching

00:39:45,200 --> 00:39:49,040
all right well thank you thank you for

00:39:46,640 --> 00:39:49,040
having us

00:39:49,520 --> 00:39:57,839

YouTube URL: https://www.youtube.com/watch?v=Qxv7ADhE4m0


