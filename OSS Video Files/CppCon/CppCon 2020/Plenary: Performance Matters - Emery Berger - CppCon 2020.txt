Title: Plenary: Performance Matters - Emery Berger - CppCon 2020
Publication date: 2020-09-29
Playlist: CppCon 2020
Description: 
	https://cppcon.org/
https://github.com/CppCon/CppCon2020/blob/main/Presentations/performance_matters/performance_matters__emery_berger__cppcon_2020.pdf
---
Performance is one of the chief reasons why many C++ programmers love the language. In the past, Moore's Law meant that our programs ran faster every year. Now that Dennard scaling has ended, C++ programmers have to work harder to get high performance for their applications. In this talk, I'll first discuss some of the significant and surprising challenges facing C++ programmers trying to achieve high performance on modern hardware platforms: performance is far less stable and predictable than you might think! I'll present some experimental evidence that strongly suggests we can't count on compiler optimizations to help us out of this hole: in particular, I'll show -- using a new experimental methodology -- that the difference between clang's -O2 and -O3 optimization levels is essentially indistinguishable from noise.

Since compiler optimizations have run out of steam, we need better profiling support, especially for modern concurrent, multi-threaded applications. I'll talk about a new approach to profiling, which I call "causal profiling". Causal profiling lets programmers optimize for throughput or latency, and which pinpoints and accurately predicts the impact of optimizations. It works by running performance experiments, based on the idea of "virtual speedups". We've built a causal profiler called Coz, which now ships as part of standard Linux distros, and which also works for C++ and Rust (there's even a Java version). Using it, we find that Coz can unlock previously unknown optimization opportunities. Guided by Coz, we improved the performance of Memcached (9%), SQLite (25%), and accelerated six other applications by as much as 68%; in most cases, this involved modifying less than 10 lines of code and took under half an hour (without any prior understanding of the programs!).

---
Emery Berger is a Professor in the College of Information and Computer Sciences at the University of Massachusetts Amherst, the flagship campus of the UMass system, where he co-directs the PLASMA @ UMass lab. He graduated with a Ph.D. in Computer Science from the University of Texas at Austin in 2002. Professor Berger has been a Visiting Scientist at Microsoft Research and at the Universitat Politècnica de Catalunya (UPC) / Barcelona Supercomputing Center (BSC). Professor Berger’s research spans programming languages, runtime systems, and operating systems, with a particular focus on systems that transparently improve reliability, security, and performance. He and his collaborators have created a number of influential software systems including Hoard, a fast and scalable memory manager that accelerates multithreaded applications (used by companies including British Telecom, Cisco, Crédit Suisse, Reuters, Royal Bank of Canada, SAP, and Tata, and on which the Mac OS X memory manager is based); DieHard, an error-avoiding memory manager that directly influenced the design of the Windows 7 Fault-Tolerant Heap; and DieHarder, a secure memory manager that was an inspiration for hardening changes made to the Windows 8 heap. His honors include a Microsoft Research Fellowship, an NSF CAREER Award, a Lilly Teaching Fellowship, the Distinguished Artifact Award for PLDI 2014, the Most Influential Paper Award at OOPSLA 2012, the Most Influential Paper Award at PLDI 2016, three CACM Research Highlights, a Google Research Award, a Microsoft SEIF Award, and Best Paper Awards at FAST, OOPSLA, and SOSP; he was named an ACM Distinguished Member in 2018. Professor Berger is currently serving his second term as an elected member of the SIGPLAN Executive Committee; he served for a decade (2007-2017) as Associate Editor of the ACM Transactions on Programming Languages and Systems, and was Program Chair for PLDI 2016.

---
Streamed & Edited by Digital Medium Ltd - events.digital-medium.co.uk
events@digital-medium.co.uk
Captions: 
	00:00:08,960 --> 00:00:12,240
um so today i'll be talking about

00:00:10,639 --> 00:00:14,160
performance matters

00:00:12,240 --> 00:00:15,920
this is joint work with my former

00:00:14,160 --> 00:00:18,800
graduate student charlie kurtzinger

00:00:15,920 --> 00:00:20,720
who is now professor at grinnell college

00:00:18,800 --> 00:00:23,920
so we'll start with a little story

00:00:20,720 --> 00:00:25,599
um it's a short time ago in a valley far

00:00:23,920 --> 00:00:29,439
far away

00:00:25,599 --> 00:00:32,239
not this valley which is really far away

00:00:29,439 --> 00:00:33,920
but this valley uh which for some of us

00:00:32,239 --> 00:00:37,440
is quite close and some still

00:00:33,920 --> 00:00:41,120
still far um and in this valley we have

00:00:37,440 --> 00:00:43,520
um our hero luke um so luke

00:00:41,120 --> 00:00:44,320
uh being in silicon valley and not on

00:00:43,520 --> 00:00:46,800
tatooine

00:00:44,320 --> 00:00:47,920
has an idea for an app uh that's how

00:00:46,800 --> 00:00:51,680
he's going to uh

00:00:47,920 --> 00:00:52,559
to resist i guess um so his idea for an

00:00:51,680 --> 00:00:56,719
app

00:00:52,559 --> 00:00:59,520
is is super compelling it involves cats

00:00:56,719 --> 00:01:01,600
so it's guaranteed to be a success and

00:00:59,520 --> 00:01:04,640
the way that the app is going to work

00:01:01,600 --> 00:01:06,320
is that luke is going to

00:01:04,640 --> 00:01:08,159
have this application that lets you take

00:01:06,320 --> 00:01:09,680
pictures of cats

00:01:08,159 --> 00:01:12,159
and then it will go search for similar

00:01:09,680 --> 00:01:13,760
pictures of cats so you'll get just

00:01:12,159 --> 00:01:15,280
uh as many cat memes as you could

00:01:13,760 --> 00:01:16,720
possibly want just take a picture of a

00:01:15,280 --> 00:01:18,400
cat and you get cadmiums

00:01:16,720 --> 00:01:20,400
and he's a great idea for this killer

00:01:18,400 --> 00:01:22,880
app he calls it ogle

00:01:20,400 --> 00:01:25,280
um suspiciously sounds like another

00:01:22,880 --> 00:01:27,759
successful company which is a good sign

00:01:25,280 --> 00:01:29,520
um luke is convinced it's going to

00:01:27,759 --> 00:01:32,079
totally disrupt image search

00:01:29,520 --> 00:01:33,119
uh unfortunately uh luke has not heard

00:01:32,079 --> 00:01:34,640
of uh

00:01:33,119 --> 00:01:36,240
google image search but that's okay

00:01:34,640 --> 00:01:38,079
nobody tell him alright

00:01:36,240 --> 00:01:41,360
so uh so luke goes out and he sets out

00:01:38,079 --> 00:01:43,360
to create his prototype of ogle

00:01:41,360 --> 00:01:45,119
and to get a little deeper into the

00:01:43,360 --> 00:01:46,799
software architecture of how augla is

00:01:45,119 --> 00:01:48,159
going to work

00:01:46,799 --> 00:01:50,240
the way it works like i said you take a

00:01:48,159 --> 00:01:52,079
picture and then it's going to upload it

00:01:50,240 --> 00:01:54,240
to ogle servers

00:01:52,079 --> 00:01:55,920
ogle servers will do something with the

00:01:54,240 --> 00:01:57,280
image um

00:01:55,920 --> 00:02:00,159
first it's going to store it to a

00:01:57,280 --> 00:02:01,840
database so uh can be used later

00:02:00,159 --> 00:02:03,280
and then it's going to find similar

00:02:01,840 --> 00:02:04,479
pictures right it's going to find all of

00:02:03,280 --> 00:02:06,399
these memes

00:02:04,479 --> 00:02:08,640
and then send them back and make the

00:02:06,399 --> 00:02:11,120
ogle user super happy

00:02:08,640 --> 00:02:12,879
so under the covers of course uh that's

00:02:11,120 --> 00:02:13,920
not all going to happen in sequence it's

00:02:12,879 --> 00:02:15,680
going to be

00:02:13,920 --> 00:02:17,840
naturally a multi-threaded highly

00:02:15,680 --> 00:02:18,640
concurrent super performance c plus plus

00:02:17,840 --> 00:02:21,680
app because

00:02:18,640 --> 00:02:25,280
um uh of course luke loves c plus plus

00:02:21,680 --> 00:02:27,760
it wants everything to go quickly so

00:02:25,280 --> 00:02:29,520
here is a high level diagram of the

00:02:27,760 --> 00:02:31,040
software architecture in pictures

00:02:29,520 --> 00:02:33,840
when a request comes in it's going to

00:02:31,040 --> 00:02:36,000
get split off into multiple threads

00:02:33,840 --> 00:02:37,040
in one thread it's going to do some

00:02:36,000 --> 00:02:38,800
image compression

00:02:37,040 --> 00:02:40,560
it's not necessarily required that it

00:02:38,800 --> 00:02:42,160
save everything in the image

00:02:40,560 --> 00:02:44,000
it could be coming in as raw we want to

00:02:42,160 --> 00:02:46,480
save it as jpeg

00:02:44,000 --> 00:02:47,760
it writes it to a three and a half inch

00:02:46,480 --> 00:02:50,879
floppy disk

00:02:47,760 --> 00:02:52,800
as one does um and then

00:02:50,879 --> 00:02:54,720
it goes and it does the kind of let's

00:02:52,800 --> 00:02:56,480
call it ai part

00:02:54,720 --> 00:02:58,560
it does feature extraction so it

00:02:56,480 --> 00:03:00,879
extracts some features from the image

00:02:58,560 --> 00:03:03,040
so that it can then do some retrieval

00:03:00,879 --> 00:03:06,159
and find those similar pictures

00:03:03,040 --> 00:03:09,360
and then it mails them back uh to the uh

00:03:06,159 --> 00:03:12,319
to the ogle client uh via paper airplane

00:03:09,360 --> 00:03:13,840
all right so um then of course once

00:03:12,319 --> 00:03:17,040
those two threads have

00:03:13,840 --> 00:03:20,400
done their work uh they join up and the

00:03:17,040 --> 00:03:22,000
uh this the server action is complete

00:03:20,400 --> 00:03:23,840
now i've simplified a lot in this

00:03:22,000 --> 00:03:26,000
diagram obviously there could be a lot

00:03:23,840 --> 00:03:28,080
more threads a lot more stuff happening

00:03:26,000 --> 00:03:29,280
um and uh so i'm just showing the one

00:03:28,080 --> 00:03:31,760
thread of course

00:03:29,280 --> 00:03:33,280
um in these threads it's also the case

00:03:31,760 --> 00:03:34,000
that there's going to be synchronization

00:03:33,280 --> 00:03:35,440
to prevent

00:03:34,000 --> 00:03:37,920
things from being overwritten or

00:03:35,440 --> 00:03:40,319
corrupted so you're going to have locks

00:03:37,920 --> 00:03:42,159
locks are going to to change this order

00:03:40,319 --> 00:03:42,720
and so on and this will become important

00:03:42,159 --> 00:03:44,959
later

00:03:42,720 --> 00:03:46,720
but at a high level this is the idea and

00:03:44,959 --> 00:03:48,959
every client is more or less independent

00:03:46,720 --> 00:03:51,360
and executing this code

00:03:48,959 --> 00:03:52,480
so great so luke goes and posts this to

00:03:51,360 --> 00:03:55,040
the app store

00:03:52,480 --> 00:03:55,840
uh and immediately uh millions of users

00:03:55,040 --> 00:03:58,799
start downloading

00:03:55,840 --> 00:04:00,000
ugl and luke is sure that he's on his

00:03:58,799 --> 00:04:03,439
way to uh to be

00:04:00,000 --> 00:04:06,080
at the next fortune um uh in uh

00:04:03,439 --> 00:04:07,360
in silicon valley he's the unicorn uh

00:04:06,080 --> 00:04:10,640
but then

00:04:07,360 --> 00:04:13,439
under load what starts to happen is that

00:04:10,640 --> 00:04:15,599
uh augle gets too slow so stuff is

00:04:13,439 --> 00:04:18,000
loading and it's kind of stuck

00:04:15,599 --> 00:04:19,680
and so now luke has a problem right luke

00:04:18,000 --> 00:04:20,720
was just poised to become super

00:04:19,680 --> 00:04:23,919
successful

00:04:20,720 --> 00:04:28,000
uh and you know a a mogul if you will

00:04:23,919 --> 00:04:30,240
um an ogle fogel um

00:04:28,000 --> 00:04:31,360
and uh and now his app is performing

00:04:30,240 --> 00:04:32,560
really poorly

00:04:31,360 --> 00:04:34,080
and this is going to scare away all the

00:04:32,560 --> 00:04:35,280
users and he's going to be a failure and

00:04:34,080 --> 00:04:38,240
he's going to end up

00:04:35,280 --> 00:04:40,160
uh having to move to um to some other

00:04:38,240 --> 00:04:40,800
land that is not as exciting as silicon

00:04:40,160 --> 00:04:43,440
valley

00:04:40,800 --> 00:04:44,479
back to tadween all right so before we

00:04:43,440 --> 00:04:45,919
talk about how

00:04:44,479 --> 00:04:47,680
we're going to rescue luke from this

00:04:45,919 --> 00:04:50,320
terrible situation um

00:04:47,680 --> 00:04:50,880
let me talk about another luke uh this

00:04:50,320 --> 00:04:53,759
is uh

00:04:50,880 --> 00:04:54,800
this is cool luke this is luke in the

00:04:53,759 --> 00:04:57,040
80s

00:04:54,800 --> 00:04:57,840
so the sunglasses the ray-bans are meant

00:04:57,040 --> 00:05:00,880
to show he's

00:04:57,840 --> 00:05:02,479
uh in the 80s of course in the 80s those

00:05:00,880 --> 00:05:05,120
of you who are old enough to remember

00:05:02,479 --> 00:05:06,639
know there were no cell phones um and

00:05:05,120 --> 00:05:07,600
when people had computers they didn't

00:05:06,639 --> 00:05:10,320
look like this

00:05:07,600 --> 00:05:11,759
they looked like this um image

00:05:10,320 --> 00:05:14,720
resolution all will also

00:05:11,759 --> 00:05:16,000
kind of lacking um so your cat might

00:05:14,720 --> 00:05:18,479
look like this

00:05:16,000 --> 00:05:19,039
so fine so this is ogle in the 80s and

00:05:18,479 --> 00:05:21,600
of course

00:05:19,039 --> 00:05:23,120
being an ogle application i'm sorry

00:05:21,600 --> 00:05:25,120
being an application in the 80s

00:05:23,120 --> 00:05:27,520
it has to have a really 80s name so

00:05:25,120 --> 00:05:30,000
here's ogle 84 1.0

00:05:27,520 --> 00:05:32,400
um and so you know this is what ogle

00:05:30,000 --> 00:05:34,000
does in the 80s it has a text interface

00:05:32,400 --> 00:05:35,919
it goes and searches the database and it

00:05:34,000 --> 00:05:39,120
comes up with some results

00:05:35,919 --> 00:05:40,720
all right great now the thing is is that

00:05:39,120 --> 00:05:43,280
luke in the 80s

00:05:40,720 --> 00:05:44,800
and luke in the present day whoops well

00:05:43,280 --> 00:05:46,560
it went a little too fast

00:05:44,800 --> 00:05:48,880
luke in the 80s and luke in the present

00:05:46,560 --> 00:05:50,080
day both have this problem that things

00:05:48,880 --> 00:05:52,560
are slow

00:05:50,080 --> 00:05:55,440
right so what happened so in the 80s of

00:05:52,560 --> 00:05:57,280
course computers were really slow

00:05:55,440 --> 00:05:58,720
and uh but they got faster and faster

00:05:57,280 --> 00:06:01,120
over time so

00:05:58,720 --> 00:06:03,440
um notice these two graphs so the graph

00:06:01,120 --> 00:06:06,000
on the left is transistors in millions

00:06:03,440 --> 00:06:07,199
on the graph on the right is clock speed

00:06:06,000 --> 00:06:08,800
in megahertz

00:06:07,199 --> 00:06:10,960
and it's important to note that these

00:06:08,800 --> 00:06:14,240
are log scale graphs

00:06:10,960 --> 00:06:15,120
so these x's are actual points of

00:06:14,240 --> 00:06:17,360
processors

00:06:15,120 --> 00:06:18,880
in terms of the number of transistors

00:06:17,360 --> 00:06:22,880
and their clock speed

00:06:18,880 --> 00:06:24,960
over time till roughly 2003

00:06:22,880 --> 00:06:26,560
and what you can see is that these lines

00:06:24,960 --> 00:06:30,960
look almost the same

00:06:26,560 --> 00:06:33,280
right so uh as the number of transistors

00:06:30,960 --> 00:06:34,240
got small basically transistors got

00:06:33,280 --> 00:06:36,160
smaller and smaller

00:06:34,240 --> 00:06:37,280
so you could pack many many more of them

00:06:36,160 --> 00:06:39,120
onto a chip

00:06:37,280 --> 00:06:41,039
we were able to actually increase the

00:06:39,120 --> 00:06:43,199
clock speed of these processors

00:06:41,039 --> 00:06:44,960
faster and faster and the two kind of

00:06:43,199 --> 00:06:47,039
kept uh equal pace

00:06:44,960 --> 00:06:48,800
and this was great so what this meant

00:06:47,039 --> 00:06:51,440
was literally

00:06:48,800 --> 00:06:51,840
you could just buy new hardware every

00:06:51,440 --> 00:06:54,160
year

00:06:51,840 --> 00:06:55,759
or every one and a half years and your

00:06:54,160 --> 00:06:59,039
code would automatically run

00:06:55,759 --> 00:07:01,680
a lot faster so that was a great

00:06:59,039 --> 00:07:03,120
situation again i feel bad for those of

00:07:01,680 --> 00:07:04,000
you in the audience who are too young to

00:07:03,120 --> 00:07:06,080
remember this

00:07:04,000 --> 00:07:08,479
um what would happen is you'd buy a

00:07:06,080 --> 00:07:10,000
computer uh and then your next computer

00:07:08,479 --> 00:07:10,639
would blow that other computer out of

00:07:10,000 --> 00:07:12,400
the water

00:07:10,639 --> 00:07:13,680
and this happened over and over and over

00:07:12,400 --> 00:07:16,000
again and we just got used to it we

00:07:13,680 --> 00:07:18,000
thought it was gonna last forever

00:07:16,000 --> 00:07:20,000
so in the 80s which you can see is

00:07:18,000 --> 00:07:21,440
really early in this curve right it's

00:07:20,000 --> 00:07:23,039
like in the middle of this

00:07:21,440 --> 00:07:25,360
everybody expects this is going to go on

00:07:23,039 --> 00:07:27,759
forever and those of us

00:07:25,360 --> 00:07:29,680
in the future know that it doesn't uh

00:07:27,759 --> 00:07:31,840
performance improvement in the 80s

00:07:29,680 --> 00:07:34,160
yeah it was hard to get performance out

00:07:31,840 --> 00:07:37,440
unless you were just willing to wait

00:07:34,160 --> 00:07:40,080
so if you kick back and wait a year

00:07:37,440 --> 00:07:41,520
your code will magically run almost

00:07:40,080 --> 00:07:44,720
twice as fast

00:07:41,520 --> 00:07:48,400
and so honestly luke's best option

00:07:44,720 --> 00:07:52,160
in the 80s cool luke was to just go

00:07:48,400 --> 00:07:55,520
find a beach get a mojito and chill

00:07:52,160 --> 00:07:57,039
and then one year later come back and be

00:07:55,520 --> 00:07:57,440
like well everything is now twice as

00:07:57,039 --> 00:08:00,720
fast

00:07:57,440 --> 00:08:03,360
problem solved so those were great times

00:08:00,720 --> 00:08:04,000
many mojitos were consumed uh they are

00:08:03,360 --> 00:08:05,440
delicious

00:08:04,000 --> 00:08:07,039
it is a wonderful time to be a

00:08:05,440 --> 00:08:10,160
performance engineer

00:08:07,039 --> 00:08:10,800
however in present day that is not the

00:08:10,160 --> 00:08:14,000
case

00:08:10,800 --> 00:08:17,039
one sad tier um the problem is

00:08:14,000 --> 00:08:18,160
that performance is no longer so easy no

00:08:17,039 --> 00:08:20,479
more mojitos

00:08:18,160 --> 00:08:21,360
so here on these two graphs i've

00:08:20,479 --> 00:08:24,479
illustrated

00:08:21,360 --> 00:08:25,599
what would have happened if the if the

00:08:24,479 --> 00:08:27,919
transit continued

00:08:25,599 --> 00:08:29,039
as expected all right so it's pretty

00:08:27,919 --> 00:08:30,479
straightforward straight line

00:08:29,039 --> 00:08:33,680
interpolation

00:08:30,479 --> 00:08:35,279
um unfortunately while transistors

00:08:33,680 --> 00:08:36,880
followed this trend they continue to

00:08:35,279 --> 00:08:39,839
follow this trend in fact

00:08:36,880 --> 00:08:40,560
transistor accounts continue to increase

00:08:39,839 --> 00:08:43,680
this is

00:08:40,560 --> 00:08:47,680
in fact what is known as moore's law

00:08:43,680 --> 00:08:49,360
moore's law is not yet dead um it's uh

00:08:47,680 --> 00:08:51,839
you know the rumors of its death have

00:08:49,360 --> 00:08:53,040
been exaggerated for quite some time

00:08:51,839 --> 00:08:54,959
eventually it's going to run out of

00:08:53,040 --> 00:08:55,519
steam but it has not yet run out of

00:08:54,959 --> 00:08:57,839
steam

00:08:55,519 --> 00:08:59,519
however there's another phenomenon which

00:08:57,839 --> 00:09:00,480
is the phenomenon on the right which

00:08:59,519 --> 00:09:03,279
turns out to be

00:09:00,480 --> 00:09:05,600
actually separate from moore's law it's

00:09:03,279 --> 00:09:08,640
a phenomenon called denard scaling

00:09:05,600 --> 00:09:10,560
and dinard scaling is what allowed

00:09:08,640 --> 00:09:13,279
these clock speeds to keep getting

00:09:10,560 --> 00:09:16,080
ramped up as feature size diminished

00:09:13,279 --> 00:09:17,600
unfortunately it has now become

00:09:16,080 --> 00:09:20,399
dominated by power

00:09:17,600 --> 00:09:22,480
and current leakage on these chips as

00:09:20,399 --> 00:09:25,519
the feature sizes have gotten smaller

00:09:22,480 --> 00:09:27,600
and in short the chips are just too hot

00:09:25,519 --> 00:09:28,800
to be able to actually pump them up to a

00:09:27,600 --> 00:09:30,480
higher clock speed

00:09:28,800 --> 00:09:34,000
so while we might have hoped we'd be in

00:09:30,480 --> 00:09:36,399
a land of 100 gigahertz processors

00:09:34,000 --> 00:09:37,680
if this trend had continued we are not

00:09:36,399 --> 00:09:39,120
right we're in the land of three

00:09:37,680 --> 00:09:41,519
gigahertz processors

00:09:39,120 --> 00:09:42,399
four if they're overclocked so this

00:09:41,519 --> 00:09:44,880
means that

00:09:42,399 --> 00:09:46,959
really performance is kind of stuck uh

00:09:44,880 --> 00:09:47,920
we do have more transistors this means

00:09:46,959 --> 00:09:49,600
that we

00:09:47,920 --> 00:09:51,839
have to work a lot harder if we want to

00:09:49,600 --> 00:09:53,120
get performance how do we exploit those

00:09:51,839 --> 00:09:54,880
other transistors

00:09:53,120 --> 00:09:56,720
they're in the form of multi-core

00:09:54,880 --> 00:09:58,000
they're in the form of gpus they're in

00:09:56,720 --> 00:09:59,760
the form of accelerators

00:09:58,000 --> 00:10:01,600
this is all a lot more work than sitting

00:09:59,760 --> 00:10:04,880
back and drinking mojitos

00:10:01,600 --> 00:10:06,880
so unfortunately it is hard uh to

00:10:04,880 --> 00:10:08,800
harness all of these uh these additional

00:10:06,880 --> 00:10:11,760
uh processor features

00:10:08,800 --> 00:10:13,600
and the result has been that performance

00:10:11,760 --> 00:10:14,959
matters now more than it ever did so

00:10:13,600 --> 00:10:15,839
this crowd obviously appreciates

00:10:14,959 --> 00:10:19,600
performance

00:10:15,839 --> 00:10:22,160
but i i did a roundup um just looking

00:10:19,600 --> 00:10:23,680
at iphone updates an iphone you know

00:10:22,160 --> 00:10:27,120
under the covers is running

00:10:23,680 --> 00:10:29,600
basically c or c plus um

00:10:27,120 --> 00:10:30,240
whether it's objectionable c or uh or

00:10:29,600 --> 00:10:33,680
not

00:10:30,240 --> 00:10:35,920
um and at the end of the day uh

00:10:33,680 --> 00:10:36,880
many many many of these applications

00:10:35,920 --> 00:10:38,880
come up and say

00:10:36,880 --> 00:10:41,120
bug fixes and performance improvements

00:10:38,880 --> 00:10:43,600
bug fixes and performance improvements

00:10:41,120 --> 00:10:45,200
um my favorite message was from yelp

00:10:43,600 --> 00:10:46,560
we've decided to start referring to

00:10:45,200 --> 00:10:49,120
performance improvements

00:10:46,560 --> 00:10:50,160
as app engine calibrations because it

00:10:49,120 --> 00:10:51,839
sounds cooler

00:10:50,160 --> 00:10:53,200
therefore for this version we further

00:10:51,839 --> 00:10:56,880
calibrated the app engine

00:10:53,200 --> 00:10:58,880
okay fine but every single application

00:10:56,880 --> 00:11:01,200
basically is getting shipped and then it

00:10:58,880 --> 00:11:02,800
runs into performance problems

00:11:01,200 --> 00:11:04,240
so every app needs to improve its

00:11:02,800 --> 00:11:06,560
performance more or less

00:11:04,240 --> 00:11:07,519
or calibrate its app engine uh depending

00:11:06,560 --> 00:11:10,160
on

00:11:07,519 --> 00:11:11,279
on your preference of terms so so why is

00:11:10,160 --> 00:11:12,959
this so hard

00:11:11,279 --> 00:11:14,399
right i mean it's hard to get programs

00:11:12,959 --> 00:11:16,640
to run correctly

00:11:14,399 --> 00:11:17,440
but when they fail because they ran

00:11:16,640 --> 00:11:19,920
incorrectly

00:11:17,440 --> 00:11:21,360
you can tell you like oh you do some

00:11:19,920 --> 00:11:22,959
sort of root cause analysis and you're

00:11:21,360 --> 00:11:24,320
like oh this shouldn't have printed out

00:11:22,959 --> 00:11:25,360
food when it was supposed to print out

00:11:24,320 --> 00:11:27,680
hello world

00:11:25,360 --> 00:11:28,560
um performance is much more complicated

00:11:27,680 --> 00:11:31,760
like it runs slow

00:11:28,560 --> 00:11:35,120
why is it running slow so it turns out

00:11:31,760 --> 00:11:38,399
that there are actually two big problems

00:11:35,120 --> 00:11:41,200
with how performance is being analyzed

00:11:38,399 --> 00:11:42,320
and how we use performance profilers to

00:11:41,200 --> 00:11:45,839
actually

00:11:42,320 --> 00:11:48,480
get at how to make programs run faster

00:11:45,839 --> 00:11:49,519
so um in the rest of this talk i'm going

00:11:48,480 --> 00:11:52,000
to talk about

00:11:49,519 --> 00:11:53,839
the right way to do performance analysis

00:11:52,000 --> 00:11:55,839
i'm going to talk about some pitfalls

00:11:53,839 --> 00:11:57,760
that you might not be aware of

00:11:55,839 --> 00:11:59,920
that have arisen because of the

00:11:57,760 --> 00:12:01,360
complexity of modern day hardware

00:11:59,920 --> 00:12:03,040
um and then i'm going to talk about

00:12:01,360 --> 00:12:05,600
performance profilers

00:12:03,040 --> 00:12:06,399
why existing performance profilers fall

00:12:05,600 --> 00:12:08,639
short

00:12:06,399 --> 00:12:10,720
in this modern brave new world and how

00:12:08,639 --> 00:12:12,160
to do it better

00:12:10,720 --> 00:12:14,000
so first i'm going to focus on like i

00:12:12,160 --> 00:12:14,480
said performance analysis how to do it

00:12:14,000 --> 00:12:16,720
right

00:12:14,480 --> 00:12:20,160
i'm going to walk through the typical

00:12:16,720 --> 00:12:23,360
way that performance analysis works

00:12:20,160 --> 00:12:24,880
so here's luke luke's got program a

00:12:23,360 --> 00:12:26,720
uh and here's some code it doesn't

00:12:24,880 --> 00:12:30,079
matter what the code does

00:12:26,720 --> 00:12:32,800
but luke has an idea luke says ah i have

00:12:30,079 --> 00:12:35,279
an idea of how to make this run faster

00:12:32,800 --> 00:12:37,200
so luke goes and you know refactor some

00:12:35,279 --> 00:12:39,760
code rewrite some things

00:12:37,200 --> 00:12:41,519
reorder some things factors out some

00:12:39,760 --> 00:12:44,160
fast paths and so on

00:12:41,519 --> 00:12:44,720
right and eventually is left with a new

00:12:44,160 --> 00:12:47,200
program

00:12:44,720 --> 00:12:48,880
and this new program is a prime all

00:12:47,200 --> 00:12:51,839
right and so

00:12:48,880 --> 00:12:52,639
luke now wants to know well was he

00:12:51,839 --> 00:12:55,360
successful

00:12:52,639 --> 00:12:56,800
right so he had this great idea uh and

00:12:55,360 --> 00:12:58,880
said i made a bunch of changes

00:12:56,800 --> 00:13:00,560
and now how do i know if it's faster

00:12:58,880 --> 00:13:01,279
well the way he's gonna know that it's

00:13:00,560 --> 00:13:03,440
faster

00:13:01,279 --> 00:13:05,839
is he's gonna test it right so he has

00:13:03,440 --> 00:13:06,480
some input program or input data and he

00:13:05,839 --> 00:13:08,959
runs it

00:13:06,480 --> 00:13:10,480
he runs it on a which is the old version

00:13:08,959 --> 00:13:12,800
and took 90 seconds

00:13:10,480 --> 00:13:15,120
it's great he runs it on a prime it

00:13:12,800 --> 00:13:18,959
takes 87.5 seconds

00:13:15,120 --> 00:13:21,360
all right so that is 2.8 percent faster

00:13:18,959 --> 00:13:22,160
this is clear proof uh that luke is a

00:13:21,360 --> 00:13:25,600
genius

00:13:22,160 --> 00:13:27,519
uh and 2.8 percent faster uh huge win

00:13:25,600 --> 00:13:28,880
right uh he's a gigantic genius and he's

00:13:27,519 --> 00:13:29,600
radically improved the performance of

00:13:28,880 --> 00:13:34,000
this code

00:13:29,600 --> 00:13:36,480
all right so fine uh he's done right

00:13:34,000 --> 00:13:38,240
so uh some of you may be aware that this

00:13:36,480 --> 00:13:41,199
is not really how things work

00:13:38,240 --> 00:13:41,519
right you run things uh you know you run

00:13:41,199 --> 00:13:43,360
it

00:13:41,519 --> 00:13:45,279
you run it one time you see an

00:13:43,360 --> 00:13:48,320
improvement you might be thinking

00:13:45,279 --> 00:13:51,600
well yeah it's faster this one time but

00:13:48,320 --> 00:13:53,760
what about variants right computers

00:13:51,600 --> 00:13:55,440
have a little bit of stuff going on they

00:13:53,760 --> 00:13:55,920
have maybe background demons that wake

00:13:55,440 --> 00:13:58,399
up

00:13:55,920 --> 00:13:59,839
uh maybe there's other things about the

00:13:58,399 --> 00:14:00,959
load that are going on that you want to

00:13:59,839 --> 00:14:04,560
be careful about

00:14:00,959 --> 00:14:07,199
so you say well i'll run it more times

00:14:04,560 --> 00:14:08,720
so let's go crazy uh we're going to run

00:14:07,199 --> 00:14:12,320
it 30 times

00:14:08,720 --> 00:14:13,279
all right so we run a a prime 30 times a

00:14:12,320 --> 00:14:15,519
30 times

00:14:13,279 --> 00:14:17,279
and you can see on this graph that it's

00:14:15,519 --> 00:14:20,000
pretty clearly a separation

00:14:17,279 --> 00:14:20,399
between the old version a which is in

00:14:20,000 --> 00:14:22,560
blue

00:14:20,399 --> 00:14:24,160
on the right and the new version a prime

00:14:22,560 --> 00:14:26,480
which is in green on the left

00:14:24,160 --> 00:14:28,399
and in fact it's still on average 2.8

00:14:26,480 --> 00:14:31,040
percent faster

00:14:28,399 --> 00:14:33,519
great luke is a genius i rated 30 luke

00:14:31,040 --> 00:14:36,560
ran it 30 times it's 2.8 percent faster

00:14:33,519 --> 00:14:40,320
done print ship

00:14:36,560 --> 00:14:43,199
but not not so fast so why

00:14:40,320 --> 00:14:44,000
is a prime faster than a you might think

00:14:43,199 --> 00:14:46,399
that the reason

00:14:44,000 --> 00:14:47,440
is of course the code change uh that

00:14:46,399 --> 00:14:49,440
luke is

00:14:47,440 --> 00:14:51,519
uh you know a genius programmer and

00:14:49,440 --> 00:14:53,920
figured out to change the code

00:14:51,519 --> 00:14:54,959
like this optimization but it turns out

00:14:53,920 --> 00:14:59,440
it could have been

00:14:54,959 --> 00:15:01,199
just an accident basically a coincidence

00:14:59,440 --> 00:15:03,120
so this is somewhat surprising and

00:15:01,199 --> 00:15:03,760
distressing uh you can see luke looks

00:15:03,120 --> 00:15:06,480
very sad

00:15:03,760 --> 00:15:08,480
by this prospect let me dig in a little

00:15:06,480 --> 00:15:09,360
bit and explain what i mean and why this

00:15:08,480 --> 00:15:11,760
can happen

00:15:09,360 --> 00:15:12,720
and why small percentage increases in

00:15:11,760 --> 00:15:15,040
performance

00:15:12,720 --> 00:15:16,160
and even pretty substantial ones can

00:15:15,040 --> 00:15:17,839
actually be a total

00:15:16,160 --> 00:15:19,279
accident and why you have to be really

00:15:17,839 --> 00:15:20,720
really careful when you're analyzing

00:15:19,279 --> 00:15:23,600
performance

00:15:20,720 --> 00:15:25,279
so there's a beautiful paper uh by todd

00:15:23,600 --> 00:15:27,600
mcglitch and

00:15:25,279 --> 00:15:28,959
colleagues i'll show you the the actual

00:15:27,600 --> 00:15:30,320
paper title in a second because it's

00:15:28,959 --> 00:15:32,880
also brilliant

00:15:30,320 --> 00:15:33,759
and what it shows is there's a huge

00:15:32,880 --> 00:15:37,279
impact

00:15:33,759 --> 00:15:39,279
on of layout that is where code and

00:15:37,279 --> 00:15:42,639
where data ends up in memory

00:15:39,279 --> 00:15:44,399
on performance all right so let me

00:15:42,639 --> 00:15:46,480
go to the next slide so this is the

00:15:44,399 --> 00:15:49,360
title of the paper producing wrong data

00:15:46,480 --> 00:15:51,360
without doing anything obviously wrong

00:15:49,360 --> 00:15:54,720
um you can look this up online it

00:15:51,360 --> 00:15:56,720
appeared at the asp conference in 2009

00:15:54,720 --> 00:15:58,160
um and what it shows is there's a bunch

00:15:56,720 --> 00:16:00,480
of things that seem

00:15:58,160 --> 00:16:02,320
very minor uh and seem like they

00:16:00,480 --> 00:16:03,920
shouldn't have any impact on anything

00:16:02,320 --> 00:16:05,440
and yet they can have really really

00:16:03,920 --> 00:16:08,720
large impacts so

00:16:05,440 --> 00:16:11,440
what are some of those things so one is

00:16:08,720 --> 00:16:12,720
suppose your makefile changes when your

00:16:11,440 --> 00:16:15,199
make file changes

00:16:12,720 --> 00:16:16,639
uh and you change where the dot o's are

00:16:15,199 --> 00:16:19,120
so suppose you literally had

00:16:16,639 --> 00:16:21,199
fu.o and bar. and you reorder them and

00:16:19,120 --> 00:16:22,639
you make it bar.o and fu.o

00:16:21,199 --> 00:16:26,720
you've now changed all the function

00:16:22,639 --> 00:16:28,959
addresses this can have a huge impact

00:16:26,720 --> 00:16:30,560
here's a quite surprising one

00:16:28,959 --> 00:16:32,160
environment variables

00:16:30,560 --> 00:16:33,440
you might think environment variables

00:16:32,160 --> 00:16:34,320
clearly should have nothing to do with

00:16:33,440 --> 00:16:36,399
performance

00:16:34,320 --> 00:16:38,959
but it turns out in most operating

00:16:36,399 --> 00:16:41,040
systems the environment variables

00:16:38,959 --> 00:16:42,320
are actually loaded into memory and then

00:16:41,040 --> 00:16:44,480
the stack is loaded

00:16:42,320 --> 00:16:47,120
afterwards and what this means is that

00:16:44,480 --> 00:16:48,959
the size of the environment variables

00:16:47,120 --> 00:16:50,880
has an effect on where all of your stack

00:16:48,959 --> 00:16:52,399
frames end up in memory

00:16:50,880 --> 00:16:53,759
okay so it's like yes this changes

00:16:52,399 --> 00:16:54,399
addresses how much of a difference can

00:16:53,759 --> 00:16:57,440
it make

00:16:54,399 --> 00:16:59,600
well it turns out pretty huge in fact it

00:16:57,440 --> 00:17:02,959
can be larger than the impact of dash

00:16:59,600 --> 00:17:05,760
03 versus dash 0. that is to say

00:17:02,959 --> 00:17:08,079
highly optimized code versus just

00:17:05,760 --> 00:17:11,199
compile the most brain dead way possible

00:17:08,079 --> 00:17:12,799
so you can get swings of 40

00:17:11,199 --> 00:17:14,880
just by changing these apparently

00:17:12,799 --> 00:17:17,199
innocuous things and so

00:17:14,880 --> 00:17:18,319
yes luke didn't change the link order

00:17:17,199 --> 00:17:19,360
and maybe he didn't change the

00:17:18,319 --> 00:17:22,079
environment variables

00:17:19,360 --> 00:17:23,439
but what did he do well what he did do

00:17:22,079 --> 00:17:25,439
is he changed the code

00:17:23,439 --> 00:17:26,799
and when you change the code you are

00:17:25,439 --> 00:17:29,120
changing the addresses

00:17:26,799 --> 00:17:30,240
of all of the code right so if you move

00:17:29,120 --> 00:17:32,400
this thing here

00:17:30,240 --> 00:17:34,080
you've shifted everything else down so

00:17:32,400 --> 00:17:37,440
you've moved a lot of things around

00:17:34,080 --> 00:17:40,000
so it could have been the case that here

00:17:37,440 --> 00:17:42,240
uh some hot code ended up matching

00:17:40,000 --> 00:17:45,039
mapping to the same cache set

00:17:42,240 --> 00:17:45,520
so the way caches work it's if they're

00:17:45,039 --> 00:17:47,760
not

00:17:45,520 --> 00:17:49,200
fully associative is that they are split

00:17:47,760 --> 00:17:51,760
into these things called sets

00:17:49,200 --> 00:17:53,520
uh and there's a limit of how many

00:17:51,760 --> 00:17:55,039
things can be how many entries can end

00:17:53,520 --> 00:17:56,240
up in the same set

00:17:55,039 --> 00:17:58,720
and so if you have too many things that

00:17:56,240 --> 00:18:00,960
map to the same set you get misses

00:17:58,720 --> 00:18:03,039
that aren't because uh your cash was

00:18:00,960 --> 00:18:04,799
full it's just because they all map to

00:18:03,039 --> 00:18:06,160
the same set and so it's getting poorly

00:18:04,799 --> 00:18:08,799
utilized

00:18:06,160 --> 00:18:09,919
this is referred to as a conflict-ness

00:18:08,799 --> 00:18:12,559
so

00:18:09,919 --> 00:18:13,280
that could have been the case in a and

00:18:12,559 --> 00:18:17,360
then by

00:18:13,280 --> 00:18:20,400
total accident by just blind luck

00:18:17,360 --> 00:18:23,120
a prime ended up moving things around

00:18:20,400 --> 00:18:24,080
so that stuff and the top thing no

00:18:23,120 --> 00:18:25,840
longer maps to

00:18:24,080 --> 00:18:27,280
anything that conflicts with it see

00:18:25,840 --> 00:18:29,440
there's no conflict

00:18:27,280 --> 00:18:31,200
and so now you get a performance

00:18:29,440 --> 00:18:32,880
increase because you're taking better

00:18:31,200 --> 00:18:36,400
advantage of the cache

00:18:32,880 --> 00:18:38,320
so they're in in modern architectures

00:18:36,400 --> 00:18:40,240
there are instruction caches and data

00:18:38,320 --> 00:18:41,360
caches at the lower levels they're

00:18:40,240 --> 00:18:43,360
usually together

00:18:41,360 --> 00:18:45,440
at the higher levels they are not that

00:18:43,360 --> 00:18:46,960
is closer to the cpu itself

00:18:45,440 --> 00:18:48,640
you have a separate instruction cache in

00:18:46,960 --> 00:18:50,400
a data cache so moving around

00:18:48,640 --> 00:18:52,640
instructions can have a big impact

00:18:50,400 --> 00:18:54,720
moving around data can have a big impact

00:18:52,640 --> 00:18:55,440
so obviously the culprit here is the

00:18:54,720 --> 00:18:57,600
cache

00:18:55,440 --> 00:18:58,720
and we should all get rid of caches um

00:18:57,600 --> 00:19:00,000
that's not true we definitely don't want

00:18:58,720 --> 00:19:02,400
to get rid of caches

00:19:00,000 --> 00:19:04,559
they have a huge impact on performance

00:19:02,400 --> 00:19:07,919
but it turns out

00:19:04,559 --> 00:19:10,880
sadly the cache is not the only thing

00:19:07,919 --> 00:19:12,000
to blame here modern chips are super

00:19:10,880 --> 00:19:13,440
complicated

00:19:12,000 --> 00:19:15,600
and they have lots of performance

00:19:13,440 --> 00:19:18,640
sensitive micro architectural features

00:19:15,600 --> 00:19:21,600
that depend on some sort of function

00:19:18,640 --> 00:19:23,280
of the program or data addresses so this

00:19:21,600 --> 00:19:25,760
is not a complete list

00:19:23,280 --> 00:19:26,559
but there's the cache there's the branch

00:19:25,760 --> 00:19:29,440
predictor

00:19:26,559 --> 00:19:30,000
which tries to decide well where am i

00:19:29,440 --> 00:19:32,240
jumping

00:19:30,000 --> 00:19:34,559
in my code and it has tables and those

00:19:32,240 --> 00:19:37,280
tables are based on the program counters

00:19:34,559 --> 00:19:38,320
which are connected to the addresses of

00:19:37,280 --> 00:19:40,720
code

00:19:38,320 --> 00:19:42,480
and if they fill up then you can end up

00:19:40,720 --> 00:19:44,640
with branch predictor misses caused by

00:19:42,480 --> 00:19:47,360
conflicts

00:19:44,640 --> 00:19:49,600
it can be a problem in the tlb the tlb

00:19:47,360 --> 00:19:51,679
is the thing that maps

00:19:49,600 --> 00:19:53,280
virtual memory to physical memory the

00:19:51,679 --> 00:19:56,799
tlb is also fixed size

00:19:53,280 --> 00:19:57,280
and also can use uh well affected by

00:19:56,799 --> 00:19:59,200
layout

00:19:57,280 --> 00:20:00,480
usually not because of hashing but

00:19:59,200 --> 00:20:02,559
because of capacity

00:20:00,480 --> 00:20:04,720
and if stuff suddenly is spanning two

00:20:02,559 --> 00:20:07,120
pages when it used to be on one page

00:20:04,720 --> 00:20:08,799
you can actually create tlb pressure and

00:20:07,120 --> 00:20:10,480
that can have a very large impact on

00:20:08,799 --> 00:20:11,360
performance because when you miss in the

00:20:10,480 --> 00:20:13,200
tlb

00:20:11,360 --> 00:20:14,400
you have to go out to main memory which

00:20:13,200 --> 00:20:17,039
is quite far away

00:20:14,400 --> 00:20:18,799
so it's many many more cycles beyond

00:20:17,039 --> 00:20:20,640
that there's the branch target predictor

00:20:18,799 --> 00:20:22,320
which tries to predict where a jump is

00:20:20,640 --> 00:20:24,799
actually going to go

00:20:22,320 --> 00:20:26,320
um modern ships also have very

00:20:24,799 --> 00:20:28,000
sophisticated prefetchers

00:20:26,320 --> 00:20:29,360
which try to anticipate where your

00:20:28,000 --> 00:20:31,679
memory is going to be

00:20:29,360 --> 00:20:33,120
loaded next so they can hide the latency

00:20:31,679 --> 00:20:35,520
of bringing it in from ram

00:20:33,120 --> 00:20:36,640
again all of these things depend on

00:20:35,520 --> 00:20:39,919
addresses

00:20:36,640 --> 00:20:42,159
so in a way it's blaming any layout the

00:20:39,919 --> 00:20:44,000
layout is a problem

00:20:42,159 --> 00:20:45,520
so fine so you might be like okay fine

00:20:44,000 --> 00:20:47,280
fine fine emery yes

00:20:45,520 --> 00:20:48,799
there's all this complexity but i don't

00:20:47,280 --> 00:20:52,000
care a prime

00:20:48,799 --> 00:20:52,960
freaking rocks a prime is 2.8 faster or

00:20:52,000 --> 00:20:55,360
whatever i said

00:20:52,960 --> 00:20:56,720
all right and you're like good print 2.8

00:20:55,360 --> 00:21:00,320
percent faster

00:20:56,720 --> 00:21:02,720
fine okay so i agree with you that

00:21:00,320 --> 00:21:04,559
it's true maybe that it's faster and

00:21:02,720 --> 00:21:05,039
maybe it was just blind luck but it is

00:21:04,559 --> 00:21:07,280
faster

00:21:05,039 --> 00:21:08,400
so great let's keep it but here's the

00:21:07,280 --> 00:21:12,080
thing

00:21:08,400 --> 00:21:14,559
so yeah it's faster today but any

00:21:12,080 --> 00:21:15,120
other change you make can upset this

00:21:14,559 --> 00:21:16,400
behavior

00:21:15,120 --> 00:21:18,320
right and you can end up right back

00:21:16,400 --> 00:21:20,480
where you were or worse one

00:21:18,320 --> 00:21:23,039
more call to new is going to change the

00:21:20,480 --> 00:21:25,280
layout of your entire heap

00:21:23,039 --> 00:21:27,360
if you change one class and you add a

00:21:25,280 --> 00:21:30,320
method or you move some stuff around

00:21:27,360 --> 00:21:32,080
you're going to disrupt layout right

00:21:30,320 --> 00:21:32,640
obviously if you change even some lines

00:21:32,080 --> 00:21:34,480
of code

00:21:32,640 --> 00:21:35,760
again it could basically throw

00:21:34,480 --> 00:21:37,120
everything away

00:21:35,760 --> 00:21:38,960
there's some things that are really more

00:21:37,120 --> 00:21:41,919
insidious

00:21:38,960 --> 00:21:43,200
if you upgrade a library uh that library

00:21:41,919 --> 00:21:45,600
is changing layout

00:21:43,200 --> 00:21:47,280
right and this happens all the time um

00:21:45,600 --> 00:21:49,679
here's the craziest part

00:21:47,280 --> 00:21:51,840
uh this is personally burned me uh this

00:21:49,679 --> 00:21:54,960
actually happened to me with a student

00:21:51,840 --> 00:21:58,000
where my code uh where my suggested

00:21:54,960 --> 00:22:01,280
optimization ran faster on my computer

00:21:58,000 --> 00:22:02,000
or apparently than on his but it turns

00:22:01,280 --> 00:22:04,880
out

00:22:02,000 --> 00:22:05,840
that running in a new directory changes

00:22:04,880 --> 00:22:08,720
layout

00:22:05,840 --> 00:22:09,919
right so if you are in slash user slash

00:22:08,720 --> 00:22:12,720
vader

00:22:09,919 --> 00:22:14,080
you change to user slash luke you're off

00:22:12,720 --> 00:22:15,360
by one character

00:22:14,080 --> 00:22:18,240
now you've changed the environment

00:22:15,360 --> 00:22:19,679
variables size right by one character

00:22:18,240 --> 00:22:21,440
and that can actually shift things

00:22:19,679 --> 00:22:22,480
enough to have a significant performance

00:22:21,440 --> 00:22:25,280
impact

00:22:22,480 --> 00:22:26,000
and in fact what happened in particular

00:22:25,280 --> 00:22:27,679
with me and my

00:22:26,000 --> 00:22:30,000
students was that we have different

00:22:27,679 --> 00:22:31,280
usernames and they have different

00:22:30,000 --> 00:22:32,960
lengths

00:22:31,280 --> 00:22:34,320
and the username gets copied into the

00:22:32,960 --> 00:22:37,440
environment variable

00:22:34,320 --> 00:22:39,360
and then that change layout right so

00:22:37,440 --> 00:22:41,200
obviously we should all just do this and

00:22:39,360 --> 00:22:44,400
i'll be like luke all the time

00:22:41,200 --> 00:22:46,400
um you know but you may not want to tell

00:22:44,400 --> 00:22:48,799
all of your users that they should be

00:22:46,400 --> 00:22:49,520
changing their usernames all right so

00:22:48,799 --> 00:22:51,039
again

00:22:49,520 --> 00:22:53,280
not only is this the case for

00:22:51,039 --> 00:22:54,320
performance uh like i'm just trying to

00:22:53,280 --> 00:22:56,559
optimize code

00:22:54,320 --> 00:22:58,159
but all of these caveats apply to

00:22:56,559 --> 00:23:00,080
performance regression

00:22:58,159 --> 00:23:01,840
right the exact same thing can happen i

00:23:00,080 --> 00:23:04,559
made some changes in the code

00:23:01,840 --> 00:23:06,400
performance drops and i'm like oh my god

00:23:04,559 --> 00:23:08,640
back out that code back out that code

00:23:06,400 --> 00:23:09,919
right but it might be tomorrow when i

00:23:08,640 --> 00:23:11,440
put in a little more code

00:23:09,919 --> 00:23:13,120
all the performance will come back

00:23:11,440 --> 00:23:13,840
because all i did was shift around some

00:23:13,120 --> 00:23:15,840
layout

00:23:13,840 --> 00:23:18,240
it had nothing to do with me per se it

00:23:15,840 --> 00:23:21,039
was just kind of collateral damage

00:23:18,240 --> 00:23:22,000
this is pretty grim um layout is really

00:23:21,039 --> 00:23:24,240
brittle

00:23:22,000 --> 00:23:25,600
um and now we're in this world where

00:23:24,240 --> 00:23:26,320
it's like well i don't know what did

00:23:25,600 --> 00:23:28,799
anything

00:23:26,320 --> 00:23:29,919
right so layout bias is measurement um

00:23:28,799 --> 00:23:32,240
can we eliminate the

00:23:29,919 --> 00:23:33,120
effective layout that seems weird right

00:23:32,240 --> 00:23:35,520
like how do we

00:23:33,120 --> 00:23:37,200
lay new things out and then avoid the

00:23:35,520 --> 00:23:40,000
impact of these things

00:23:37,200 --> 00:23:40,720
so um what i'm going to talk about for

00:23:40,000 --> 00:23:43,600
the next

00:23:40,720 --> 00:23:44,720
chunk of my talk is how we can eliminate

00:23:43,600 --> 00:23:46,480
the effective layout

00:23:44,720 --> 00:23:48,320
and if you eliminate the effective

00:23:46,480 --> 00:23:50,880
layout if you incorporate

00:23:48,320 --> 00:23:52,799
randomization then randomization

00:23:50,880 --> 00:23:55,360
actually allows you to see through

00:23:52,799 --> 00:23:57,520
all of these layout effects and you can

00:23:55,360 --> 00:23:59,039
do performance analysis

00:23:57,520 --> 00:24:01,279
and so i'm going to talk to you about

00:23:59,039 --> 00:24:02,880
how we did that so we built a tool to

00:24:01,279 --> 00:24:03,760
allow us to do this sort of performance

00:24:02,880 --> 00:24:05,840
analysis

00:24:03,760 --> 00:24:06,880
and then the conclusions the conclusions

00:24:05,840 --> 00:24:09,360
are rather bleak

00:24:06,880 --> 00:24:10,559
about the hope of compiler optimizations

00:24:09,360 --> 00:24:12,480
taking out of this hole that we're

00:24:10,559 --> 00:24:14,000
currently in

00:24:12,480 --> 00:24:16,640
so we built this system we call

00:24:14,000 --> 00:24:17,679
stabilizer like i said memory layout

00:24:16,640 --> 00:24:19,200
affects performance

00:24:17,679 --> 00:24:21,200
and it makes performance evaluation

00:24:19,200 --> 00:24:23,039
difficult what we're going to do is

00:24:21,200 --> 00:24:24,720
we're going to use randomization

00:24:23,039 --> 00:24:26,159
to eliminate the effective layout and

00:24:24,720 --> 00:24:28,159
i'll explain how

00:24:26,159 --> 00:24:29,440
and i'll show that it enables sound

00:24:28,159 --> 00:24:32,880
performance evaluation

00:24:29,440 --> 00:24:36,000
and by sound i mean i can actually say

00:24:32,880 --> 00:24:37,760
this performance this code change uh was

00:24:36,000 --> 00:24:40,080
responsible for an optimization

00:24:37,760 --> 00:24:41,279
regardless of its impact on layout and

00:24:40,080 --> 00:24:43,440
so it is

00:24:41,279 --> 00:24:45,600
really due to that particular thing and

00:24:43,440 --> 00:24:46,799
not due to collateral damage

00:24:45,600 --> 00:24:49,440
right and i'm going to do some case

00:24:46,799 --> 00:24:51,279
studies and talk about those as well

00:24:49,440 --> 00:24:53,279
so what does stabilizer do this is

00:24:51,279 --> 00:24:54,799
something that part of this you could

00:24:53,279 --> 00:24:56,559
you could actually do yourself in your

00:24:54,799 --> 00:25:00,080
own code pretty straightforwardly

00:24:56,559 --> 00:25:02,080
um stabilizer actually depends on lvm

00:25:00,080 --> 00:25:03,279
it randomizes the layout of a lot of

00:25:02,080 --> 00:25:05,840
things so

00:25:03,279 --> 00:25:07,360
it randomizes where functions and end up

00:25:05,840 --> 00:25:09,600
getting put

00:25:07,360 --> 00:25:11,279
it randomizes stack frame sizes which

00:25:09,600 --> 00:25:13,200
affects the offset of where things end

00:25:11,279 --> 00:25:15,679
up in the stack

00:25:13,200 --> 00:25:17,279
it randomizes heap allocations so it has

00:25:15,679 --> 00:25:19,600
a randomizing heap

00:25:17,279 --> 00:25:21,760
that ensures that one allocation here or

00:25:19,600 --> 00:25:24,559
there is not going to have an effect

00:25:21,760 --> 00:25:26,000
over time when you do this randomization

00:25:24,559 --> 00:25:27,600
so it doesn't just do this once it

00:25:26,000 --> 00:25:28,640
doesn't do it at startup it does it

00:25:27,600 --> 00:25:31,120
repeatedly

00:25:28,640 --> 00:25:31,679
as the program is running so the code is

00:25:31,120 --> 00:25:33,760
running

00:25:31,679 --> 00:25:35,200
and it's shifting things around and then

00:25:33,760 --> 00:25:36,240
it shifts things around again and shifts

00:25:35,200 --> 00:25:37,760
them around again and you might be

00:25:36,240 --> 00:25:39,679
thinking my god that's crazy why on

00:25:37,760 --> 00:25:42,240
earth would you do that

00:25:39,679 --> 00:25:43,679
so the reason is that if the layout is

00:25:42,240 --> 00:25:46,080
constantly shifting

00:25:43,679 --> 00:25:47,520
and you test one thing with it shifting

00:25:46,080 --> 00:25:48,480
and another thing with it shifting and

00:25:47,520 --> 00:25:51,440
they're random

00:25:48,480 --> 00:25:52,080
and you see an effect then the only

00:25:51,440 --> 00:25:54,640
cause

00:25:52,080 --> 00:25:56,080
could have been your change because

00:25:54,640 --> 00:25:57,840
you've randomized out

00:25:56,080 --> 00:25:59,120
everything else as a cause right it's

00:25:57,840 --> 00:26:01,679
the exact same insight

00:25:59,120 --> 00:26:02,559
as randomized control trials for drug

00:26:01,679 --> 00:26:04,559
testing

00:26:02,559 --> 00:26:06,000
right you randomize who's in group a you

00:26:04,559 --> 00:26:08,400
randomize who's in group b

00:26:06,000 --> 00:26:09,679
you give everybody a drug if the drug

00:26:08,400 --> 00:26:11,200
has a significant impact

00:26:09,679 --> 00:26:13,039
then you say it's the drug it's not

00:26:11,200 --> 00:26:14,720
because everybody comes from

00:26:13,039 --> 00:26:16,640
a healthy place over here and from a

00:26:14,720 --> 00:26:19,919
terrible place over here for example

00:26:16,640 --> 00:26:22,240
all right so by definition

00:26:19,919 --> 00:26:22,960
a completely random layout can't bias

00:26:22,240 --> 00:26:26,880
results

00:26:22,960 --> 00:26:29,840
that's the definition of bias all right

00:26:26,880 --> 00:26:31,360
so we built this tool we call stabilizer

00:26:29,840 --> 00:26:32,799
let me show you what happens when we run

00:26:31,360 --> 00:26:34,320
stabilizer

00:26:32,799 --> 00:26:35,840
and we go back to this idea of doing

00:26:34,320 --> 00:26:37,840
performance evaluation

00:26:35,840 --> 00:26:39,840
so we've got our a and our a prime this

00:26:37,840 --> 00:26:42,320
is luke's optimized version

00:26:39,840 --> 00:26:44,559
and we run it and we get a curve now now

00:26:42,320 --> 00:26:46,799
we get a distribution and i'll explain

00:26:44,559 --> 00:26:47,840
in a couple slides why we get this kind

00:26:46,799 --> 00:26:50,000
of more broad

00:26:47,840 --> 00:26:51,039
distribution that's kind of a bell curve

00:26:50,000 --> 00:26:54,080
shape

00:26:51,039 --> 00:26:56,880
but take a look at this graph now

00:26:54,080 --> 00:26:58,960
um if i could see you all i would ask

00:26:56,880 --> 00:27:02,880
you to raise your hands but i can't

00:26:58,960 --> 00:27:04,720
so um i'm going to ask you to

00:27:02,880 --> 00:27:06,880
at home raise your hand even though i

00:27:04,720 --> 00:27:08,720
can't see it tell me

00:27:06,880 --> 00:27:11,600
if you think by raising your hand which

00:27:08,720 --> 00:27:14,000
i can't see if a prime is faster than a

00:27:11,600 --> 00:27:16,799
right so a prime is the green one uh the

00:27:14,000 --> 00:27:18,720
average is centered around 87.5 seconds

00:27:16,799 --> 00:27:20,640
the blue one is centered around 90.0

00:27:18,720 --> 00:27:23,279
seconds all right now keep your hands

00:27:20,640 --> 00:27:25,200
up okay so think to yourself yeah

00:27:23,279 --> 00:27:27,919
probably most of you agree

00:27:25,200 --> 00:27:29,760
a prime pretty much looks faster than a

00:27:27,919 --> 00:27:31,120
there's some overlap but it's faster

00:27:29,760 --> 00:27:33,760
than a

00:27:31,120 --> 00:27:35,279
all right now i'm going to advance

00:27:33,760 --> 00:27:37,200
through some slides and keep your hand

00:27:35,279 --> 00:27:42,080
up if you still believe

00:27:37,200 --> 00:27:42,080
a prime is faster than a now

00:27:42,240 --> 00:27:46,399
it's getting closer right the overlap is

00:27:44,399 --> 00:27:49,200
a lot larger

00:27:46,399 --> 00:27:50,960
and now how about here is a prime faster

00:27:49,200 --> 00:27:53,440
than a

00:27:50,960 --> 00:27:54,480
so what you all are doing right now

00:27:53,440 --> 00:27:57,279
probably

00:27:54,480 --> 00:27:58,960
is you got less and less comfortable as

00:27:57,279 --> 00:28:00,000
these curves got closer and closer

00:27:58,960 --> 00:28:01,760
together

00:28:00,000 --> 00:28:03,200
and what you're applying is something

00:28:01,760 --> 00:28:06,000
that i like to refer to as

00:28:03,200 --> 00:28:07,279
eyeball statistics you're eyeballing

00:28:06,000 --> 00:28:09,520
these two curves

00:28:07,279 --> 00:28:11,120
and you're saying god that curve wow

00:28:09,520 --> 00:28:14,799
they're far apart that looks great

00:28:11,120 --> 00:28:16,399
they're closer i'm less happy

00:28:14,799 --> 00:28:17,840
right and then obviously if it swaps

00:28:16,399 --> 00:28:21,039
then definitely a problem

00:28:17,840 --> 00:28:23,279
all right um that's great it's

00:28:21,039 --> 00:28:26,000
totally reasonable to do this um it's

00:28:23,279 --> 00:28:28,240
not very rigorous or scientific

00:28:26,000 --> 00:28:30,559
it turns out that eyeball statistics is

00:28:28,240 --> 00:28:31,919
not actually a thing uh if you go to

00:28:30,559 --> 00:28:33,120
wikipedia

00:28:31,919 --> 00:28:35,120
you could ask for it to be created

00:28:33,120 --> 00:28:36,880
please don't ask for it to be created um

00:28:35,120 --> 00:28:38,399
it is a terrible idea this is not how we

00:28:36,880 --> 00:28:39,200
do statistics this is not how you do

00:28:38,399 --> 00:28:42,159
analysis

00:28:39,200 --> 00:28:43,279
so when you have your graphs right you

00:28:42,159 --> 00:28:45,200
have these curves

00:28:43,279 --> 00:28:47,679
what you're actually supposed to do is

00:28:45,200 --> 00:28:48,720
apply some sort of real statistical

00:28:47,679 --> 00:28:51,520
technique

00:28:48,720 --> 00:28:53,360
so there are classically two approaches

00:28:51,520 --> 00:28:55,279
i'm going to focus on one

00:28:53,360 --> 00:28:58,080
and this one is referred to as null

00:28:55,279 --> 00:28:59,840
hypothesis significance testing

00:28:58,080 --> 00:29:01,840
and in null hypothesis significance

00:28:59,840 --> 00:29:03,679
testing you assume

00:29:01,840 --> 00:29:05,679
a null which is that there's no

00:29:03,679 --> 00:29:08,640
difference typically

00:29:05,679 --> 00:29:10,559
and then you ask the question what is

00:29:08,640 --> 00:29:11,520
the likelihood that i would see this

00:29:10,559 --> 00:29:14,720
result

00:29:11,520 --> 00:29:16,960
by random chance right so

00:29:14,720 --> 00:29:19,279
if the result the probability is

00:29:16,960 --> 00:29:20,640
extremely low like it's one in a million

00:29:19,279 --> 00:29:22,480
that this would happen randomly

00:29:20,640 --> 00:29:24,240
i might be very convinced oh that's a

00:29:22,480 --> 00:29:27,360
pretty significant difference

00:29:24,240 --> 00:29:29,120
if it's one over two like i flip a coin

00:29:27,360 --> 00:29:30,880
and i would see that kind of result

00:29:29,120 --> 00:29:32,320
i would probably not be convinced that

00:29:30,880 --> 00:29:34,159
it's very important

00:29:32,320 --> 00:29:35,919
all right so this is the whole notion of

00:29:34,159 --> 00:29:40,159
significance testing

00:29:35,919 --> 00:29:41,679
so you ask if a a prime equals a what is

00:29:40,159 --> 00:29:43,279
the probability of observing this kind

00:29:41,679 --> 00:29:45,120
of gap it turns out this is easy to

00:29:43,279 --> 00:29:47,279
compute for the normal distribution

00:29:45,120 --> 00:29:49,600
you don't need a normal distribution but

00:29:47,279 --> 00:29:52,960
if you can get one you should take it

00:29:49,600 --> 00:29:54,240
it makes analysis really easy so you all

00:29:52,960 --> 00:29:57,120
have seen the normal distribution

00:29:54,240 --> 00:29:58,799
before roughly 68 of things are going to

00:29:57,120 --> 00:30:00,559
be clustered in one standard deviation

00:29:58,799 --> 00:30:01,760
away from the mean and so on

00:30:00,559 --> 00:30:03,840
um and we'll get back to this in a

00:30:01,760 --> 00:30:04,240
minute again i just want to stress you

00:30:03,840 --> 00:30:05,679
don't

00:30:04,240 --> 00:30:08,080
need normal distribution to do

00:30:05,679 --> 00:30:10,320
statistics it just makes things easier

00:30:08,080 --> 00:30:11,679
but we are going to be relying on it in

00:30:10,320 --> 00:30:14,399
some parts of this talk

00:30:11,679 --> 00:30:15,600
so what we're going to do instead of

00:30:14,399 --> 00:30:17,440
looking at green and red

00:30:15,600 --> 00:30:18,720
and saying these seem comfortably far

00:30:17,440 --> 00:30:21,039
apart or they do not

00:30:18,720 --> 00:30:22,480
we're going to actually pose this as a

00:30:21,039 --> 00:30:26,080
null hypothesis test

00:30:22,480 --> 00:30:29,360
so we're going to say if the probability

00:30:26,080 --> 00:30:32,080
of it happening by random chance is low

00:30:29,360 --> 00:30:33,520
enough then we're going to assert that

00:30:32,080 --> 00:30:36,080
the speed up is real

00:30:33,520 --> 00:30:37,200
and because we're doing randomization

00:30:36,080 --> 00:30:38,880
we're going to know

00:30:37,200 --> 00:30:40,559
that it's not due to the effect on

00:30:38,880 --> 00:30:43,039
memory layout

00:30:40,559 --> 00:30:44,000
all right it must be due to the actual

00:30:43,039 --> 00:30:47,679
code change

00:30:44,000 --> 00:30:50,480
made by luke our hero so i've mentioned

00:30:47,679 --> 00:30:50,880
that we repeatedly randomized the layout

00:30:50,480 --> 00:30:52,559
um

00:30:50,880 --> 00:30:54,640
and you might be wondering why on earth

00:30:52,559 --> 00:30:56,640
we would do this and it turns out that

00:30:54,640 --> 00:30:57,360
one randomization is just simply not

00:30:56,640 --> 00:31:00,240
enough

00:30:57,360 --> 00:31:01,440
um so here is some actual data uh where

00:31:00,240 --> 00:31:04,080
we ran a program

00:31:01,440 --> 00:31:05,919
and we did one random layout per run and

00:31:04,080 --> 00:31:08,000
you can see that you end up with a very

00:31:05,919 --> 00:31:10,480
non-normal distribution

00:31:08,000 --> 00:31:12,640
things are totally separate it basically

00:31:10,480 --> 00:31:14,240
is like there's a good place

00:31:12,640 --> 00:31:16,480
that one of the random things when you

00:31:14,240 --> 00:31:18,000
start random ends up in and then there's

00:31:16,480 --> 00:31:18,399
a kind of bad place that most of them

00:31:18,000 --> 00:31:20,640
end up

00:31:18,399 --> 00:31:22,399
in i'm sorry the other way around this

00:31:20,640 --> 00:31:24,559
is the good place where it's faster

00:31:22,399 --> 00:31:26,559
um and the bad places where it's slow

00:31:24,559 --> 00:31:28,399
however repeated randomization

00:31:26,559 --> 00:31:30,080
you get everything in a curve this is

00:31:28,399 --> 00:31:31,760
real data by the way and it really does

00:31:30,080 --> 00:31:32,720
look like a normal distribution for very

00:31:31,760 --> 00:31:34,559
good reasons

00:31:32,720 --> 00:31:36,080
so let me explain why you get this

00:31:34,559 --> 00:31:39,200
beautiful tight curve

00:31:36,080 --> 00:31:41,120
around this spot so what stabilizer does

00:31:39,200 --> 00:31:43,600
is it generates a new random layout

00:31:41,120 --> 00:31:45,760
every half second this is a tunable

00:31:43,600 --> 00:31:47,440
parameter but that's what we stick with

00:31:45,760 --> 00:31:47,919
and the total execution time is of

00:31:47,440 --> 00:31:49,440
course

00:31:47,919 --> 00:31:51,840
the sum of all of those periods right so

00:31:49,440 --> 00:31:53,600
you have randomized uh you know run

00:31:51,840 --> 00:31:54,640
randomized run randomized run and you

00:31:53,600 --> 00:31:57,360
just add them all up

00:31:54,640 --> 00:31:58,960
so this is pretty obvious but uh it

00:31:57,360 --> 00:32:02,000
allows us to appeal

00:31:58,960 --> 00:32:04,960
to the central limit theorem so we have

00:32:02,000 --> 00:32:06,399
the sum of a sufficient number uh if

00:32:04,960 --> 00:32:07,200
your program runs long enough that a

00:32:06,399 --> 00:32:10,159
half second

00:32:07,200 --> 00:32:10,880
say it runs 20 seconds or 100 seconds

00:32:10,159 --> 00:32:13,840
this should be

00:32:10,880 --> 00:32:15,279
sufficient um they're independent

00:32:13,840 --> 00:32:16,799
because they're randomized

00:32:15,279 --> 00:32:18,480
they're identically just distributed

00:32:16,799 --> 00:32:20,080
because they come from the same code

00:32:18,480 --> 00:32:22,159
they're random variables because they're

00:32:20,080 --> 00:32:22,880
random um that's the central limit

00:32:22,159 --> 00:32:25,360
theorem

00:32:22,880 --> 00:32:27,440
so no matter what happens here whatever

00:32:25,360 --> 00:32:29,200
the the distributions were originally

00:32:27,440 --> 00:32:31,519
when you add them up after doing them

00:32:29,200 --> 00:32:34,559
all random you're going to get

00:32:31,519 --> 00:32:37,039
almost certainly unless something is is

00:32:34,559 --> 00:32:39,279
skewed in some very special way you're

00:32:37,039 --> 00:32:41,279
going to get a normal distribution

00:32:39,279 --> 00:32:44,000
and so this is actually something that

00:32:41,279 --> 00:32:45,760
that you could do with stabilizer

00:32:44,000 --> 00:32:47,279
if you wanted to make sure that your

00:32:45,760 --> 00:32:49,919
performance was in fact

00:32:47,279 --> 00:32:51,919
stable you could use stabilizer and have

00:32:49,919 --> 00:32:53,440
this randomization and you would know

00:32:51,919 --> 00:32:55,200
that the chance of having a performance

00:32:53,440 --> 00:32:57,600
outlier no matter what you do

00:32:55,200 --> 00:32:58,399
is going to be quite low but we're not

00:32:57,600 --> 00:33:00,159
going to use that

00:32:58,399 --> 00:33:01,840
uh we're going to take advantage of that

00:33:00,159 --> 00:33:04,480
here we're going to instead use this

00:33:01,840 --> 00:33:06,240
as an analytical tool for doing a case

00:33:04,480 --> 00:33:09,279
study

00:33:06,240 --> 00:33:10,320
so we want to understand whether llvm's

00:33:09,279 --> 00:33:12,960
optimizations

00:33:10,320 --> 00:33:13,600
actually matter um so we're going to do

00:33:12,960 --> 00:33:15,279
it on

00:33:13,600 --> 00:33:17,120
a suite of benchmarks we're going to do

00:33:15,279 --> 00:33:19,919
it one at a time and then we're going to

00:33:17,120 --> 00:33:21,360
do it across the entire benchmark screen

00:33:19,919 --> 00:33:23,600
so we built these benchmarks with

00:33:21,360 --> 00:33:26,640
stabilizer which again is just an lvm

00:33:23,600 --> 00:33:29,039
plug-in um you can

00:33:26,640 --> 00:33:29,679
optionally just randomize the code or

00:33:29,039 --> 00:33:31,519
just

00:33:29,679 --> 00:33:33,200
randomize the stack or just randomize

00:33:31,519 --> 00:33:34,159
the heap by default it randomizes

00:33:33,200 --> 00:33:35,919
everything

00:33:34,159 --> 00:33:38,159
we built it so that it had all the

00:33:35,919 --> 00:33:40,480
support and then we ran the benchmarks

00:33:38,159 --> 00:33:42,080
so again we're going to follow the same

00:33:40,480 --> 00:33:44,320
sort of trick as you know we're going to

00:33:42,080 --> 00:33:46,240
run things 30 times 30 is too many but

00:33:44,320 --> 00:33:47,120
anyway you run the things a bunch of

00:33:46,240 --> 00:33:50,000
times

00:33:47,120 --> 00:33:51,600
you drop the results into the statistics

00:33:50,000 --> 00:33:54,640
package of your choice

00:33:51,600 --> 00:33:56,159
let's say it's r and again

00:33:54,640 --> 00:33:58,480
you're going to get a resulting graph

00:33:56,159 --> 00:34:00,640
you're not going to ask this question

00:33:58,480 --> 00:34:01,840
because again that's eyeball statistics

00:34:00,640 --> 00:34:02,640
what we're going to do is we're going to

00:34:01,840 --> 00:34:04,720
say

00:34:02,640 --> 00:34:06,000
assume the null hypothesis is true

00:34:04,720 --> 00:34:07,919
there's no difference

00:34:06,000 --> 00:34:09,919
uh how likely is it that we would

00:34:07,919 --> 00:34:11,760
observe this by chance

00:34:09,919 --> 00:34:13,520
um for this we're going to use the

00:34:11,760 --> 00:34:17,359
student's t-test

00:34:13,520 --> 00:34:17,839
um this is the the incantation to do

00:34:17,359 --> 00:34:22,480
this in

00:34:17,839 --> 00:34:23,919
r um there's lots of uh of

00:34:22,480 --> 00:34:25,520
i mean it's every statistical test under

00:34:23,919 --> 00:34:26,879
the sun inside of r we actually have a

00:34:25,520 --> 00:34:28,399
separate project to make running

00:34:26,879 --> 00:34:30,800
statistics much much easier

00:34:28,399 --> 00:34:32,320
that we call t t e a i'd be happy to

00:34:30,800 --> 00:34:33,440
talk about that offline it's a python

00:34:32,320 --> 00:34:36,399
package

00:34:33,440 --> 00:34:38,000
um but that's material right now what

00:34:36,399 --> 00:34:40,960
we're going to be asking is

00:34:38,000 --> 00:34:42,560
is this probability which is generally

00:34:40,960 --> 00:34:45,599
known as the p-value

00:34:42,560 --> 00:34:47,760
low enough that we consider it to be

00:34:45,599 --> 00:34:49,119
unlikely so i said one in a million

00:34:47,760 --> 00:34:52,240
before that's

00:34:49,119 --> 00:34:56,240
very very uh that's super rigorous

00:34:52,240 --> 00:34:58,000
um most people when they do science

00:34:56,240 --> 00:35:00,079
pick a p-value that's not quite so

00:34:58,000 --> 00:35:02,320
stringent they say if it was random and

00:35:00,079 --> 00:35:03,280
it came up one in 20 times that would be

00:35:02,320 --> 00:35:05,040
enough

00:35:03,280 --> 00:35:06,160
or it comes up one in a hundred times

00:35:05,040 --> 00:35:07,599
that would be enough so here we're going

00:35:06,160 --> 00:35:09,200
to stick with one in 20

00:35:07,599 --> 00:35:10,960
we'll be a little generous so that's a

00:35:09,200 --> 00:35:13,200
p-value of five percent

00:35:10,960 --> 00:35:14,160
so if the p-value is less than or equal

00:35:13,200 --> 00:35:15,200
to five percent

00:35:14,160 --> 00:35:17,359
we're going to reject the null

00:35:15,200 --> 00:35:19,440
hypothesis they are not the same

00:35:17,359 --> 00:35:21,119
random chance is not why these two

00:35:19,440 --> 00:35:23,119
things matter are different

00:35:21,119 --> 00:35:24,160
they're different because luke is a

00:35:23,119 --> 00:35:26,000
freaking genius

00:35:24,160 --> 00:35:27,920
all right and the optimization is real

00:35:26,000 --> 00:35:29,119
right so here we're actually going to do

00:35:27,920 --> 00:35:31,200
this for lvm

00:35:29,119 --> 00:35:33,280
so nobody's changing any code manually

00:35:31,200 --> 00:35:35,119
we're just running lvm

00:35:33,280 --> 00:35:37,040
dash o something versus dash or

00:35:35,119 --> 00:35:38,560
something else and i can tell you you'll

00:35:37,040 --> 00:35:41,040
be unsurprised to learn

00:35:38,560 --> 00:35:41,839
dash 01 versus dash of zero makes a big

00:35:41,040 --> 00:35:44,160
difference

00:35:41,839 --> 00:35:45,599
optimizing versus not optimizing is

00:35:44,160 --> 00:35:48,240
indeed real

00:35:45,599 --> 00:35:50,000
dash02 versus dash01 also makes a

00:35:48,240 --> 00:35:51,760
significant difference

00:35:50,000 --> 00:35:53,839
and i should note there is a big

00:35:51,760 --> 00:35:56,240
difference between significance

00:35:53,839 --> 00:35:58,079
which is that yes it's unlikely that

00:35:56,240 --> 00:36:01,200
you'd observe this by chance um

00:35:58,079 --> 00:36:03,440
and the effect right so you can see

00:36:01,200 --> 00:36:05,280
in the middle for example also on the

00:36:03,440 --> 00:36:07,359
far end you can see a very very

00:36:05,280 --> 00:36:08,880
it's significant and it's substantial

00:36:07,359 --> 00:36:11,520
it's a 20 improvement

00:36:08,880 --> 00:36:12,079
that's pretty sweet um here in the

00:36:11,520 --> 00:36:15,520
middle

00:36:12,079 --> 00:36:17,520
you can see an actually um

00:36:15,520 --> 00:36:18,800
one non-significant difference but all

00:36:17,520 --> 00:36:20,160
the ones to the right are significant

00:36:18,800 --> 00:36:21,839
and they're very very small

00:36:20,160 --> 00:36:23,440
so just because it's unlikely that you

00:36:21,839 --> 00:36:24,960
observe something due to random chance

00:36:23,440 --> 00:36:27,440
doesn't mean that it matters

00:36:24,960 --> 00:36:29,200
um but if it if it's you know basically

00:36:27,440 --> 00:36:30,000
random chance then it definitely doesn't

00:36:29,200 --> 00:36:33,200
matter

00:36:30,000 --> 00:36:34,960
on here uh strangely we observed um

00:36:33,200 --> 00:36:36,400
some statistically significant

00:36:34,960 --> 00:36:38,000
performance drops

00:36:36,400 --> 00:36:39,440
and this means that they actually were

00:36:38,000 --> 00:36:41,839
just lucking into

00:36:39,440 --> 00:36:43,520
layout optimizations and it had nothing

00:36:41,839 --> 00:36:44,079
to do really with the optimization

00:36:43,520 --> 00:36:45,520
itself

00:36:44,079 --> 00:36:47,200
because the code optimizations

00:36:45,520 --> 00:36:49,200
themselves

00:36:47,200 --> 00:36:50,400
really sort of intuitively should be

00:36:49,200 --> 00:36:53,760
increasing speed

00:36:50,400 --> 00:36:56,000
but actually they may have been overfit

00:36:53,760 --> 00:36:58,160
to these particular benchmarks

00:36:56,000 --> 00:37:00,160
all right so that's dash02 versus dash01

00:36:58,160 --> 00:37:03,680
great you should all use dash02

00:37:00,160 --> 00:37:05,200
sounds good how about dash03

00:37:03,680 --> 00:37:06,720
so you can see these numbers have

00:37:05,200 --> 00:37:09,680
plummeted

00:37:06,720 --> 00:37:10,720
so i actually have to zoom in from going

00:37:09,680 --> 00:37:14,880
to negative 10

00:37:10,720 --> 00:37:16,800
to 20 to zero percent to 1.5

00:37:14,880 --> 00:37:18,320
so we can actually see these results and

00:37:16,800 --> 00:37:19,200
you can see it's really quite a mixed

00:37:18,320 --> 00:37:20,640
bag

00:37:19,200 --> 00:37:22,880
um you have some things that are

00:37:20,640 --> 00:37:25,040
significant quite a few things that are

00:37:22,880 --> 00:37:27,359
statistically not significant at all

00:37:25,040 --> 00:37:29,680
and a few statistically significant very

00:37:27,359 --> 00:37:31,599
very minor performance degradations

00:37:29,680 --> 00:37:34,000
all right great so what do these results

00:37:31,599 --> 00:37:35,520
mean so

00:37:34,000 --> 00:37:37,040
the thing is is that those results that

00:37:35,520 --> 00:37:39,359
i just talked about are about

00:37:37,040 --> 00:37:40,480
individual opt-in individual benchmarks

00:37:39,359 --> 00:37:41,359
we really want to be able to say

00:37:40,480 --> 00:37:43,760
something about

00:37:41,359 --> 00:37:45,920
all of the um the benchmarks at the same

00:37:43,760 --> 00:37:47,200
time right so we run this benchmark and

00:37:45,920 --> 00:37:49,520
that benchmark and those

00:37:47,200 --> 00:37:50,240
benchmarks blah blah blah we get a bunch

00:37:49,520 --> 00:37:52,160
of graphs

00:37:50,240 --> 00:37:54,240
some are faster some are slower and the

00:37:52,160 --> 00:37:57,200
question we wanted to ask was

00:37:54,240 --> 00:37:58,720
is dash 03 faster than dasho 2 like is

00:37:57,200 --> 00:38:00,560
there a statistically significant

00:37:58,720 --> 00:38:03,839
difference

00:38:00,560 --> 00:38:05,760
um you know here you can see that uh

00:38:03,839 --> 00:38:08,930
dash003 is slower

00:38:05,760 --> 00:38:10,320
and then here dash03 is faster so

00:38:08,930 --> 00:38:13,200
[Music]

00:38:10,320 --> 00:38:13,839
is dasho 3 faster we look at these

00:38:13,200 --> 00:38:16,240
graphs

00:38:13,839 --> 00:38:18,079
this is eyeball statistics again not the

00:38:16,240 --> 00:38:19,440
way we should be doing things let's

00:38:18,079 --> 00:38:20,560
reframe it in terms of the null

00:38:19,440 --> 00:38:23,359
hypothesis

00:38:20,560 --> 00:38:24,800
the null is that they're equal and is it

00:38:23,359 --> 00:38:27,200
likely that we would observe

00:38:24,800 --> 00:38:28,560
these differences by chance so the way

00:38:27,200 --> 00:38:31,520
to do this for more than

00:38:28,560 --> 00:38:33,359
one thing is a technique called analysis

00:38:31,520 --> 00:38:36,480
of variance or anova

00:38:33,359 --> 00:38:39,839
um this is the uh a

00:38:36,480 --> 00:38:41,280
sort of hideous incantation in in our

00:38:39,839 --> 00:38:43,440
not my favorite language in case you

00:38:41,280 --> 00:38:47,119
were you're doubting

00:38:43,440 --> 00:38:48,560
um however uh this is a way of getting

00:38:47,119 --> 00:38:51,280
at this particular thing we

00:38:48,560 --> 00:38:54,160
model it as a the effect of the

00:38:51,280 --> 00:38:57,599
optimization plus some gaussian error

00:38:54,160 --> 00:38:59,359
and we we run this analysis right

00:38:57,599 --> 00:39:00,880
so again we're going to test if the

00:38:59,359 --> 00:39:01,839
p-value is less than or equal to five

00:39:00,880 --> 00:39:02,960
percent

00:39:01,839 --> 00:39:05,599
then we're going to reject the null

00:39:02,960 --> 00:39:09,359
hypothesis great so we run

00:39:05,599 --> 00:39:12,320
anova with uh 03 and o2

00:39:09,359 --> 00:39:13,440
and the p-value that we get is drum roll

00:39:12,320 --> 00:39:17,200
please

00:39:13,440 --> 00:39:18,160
26.4 uh our threshold that we set was

00:39:17,200 --> 00:39:20,560
five percent

00:39:18,160 --> 00:39:21,280
and it came up that one quarter of the

00:39:20,560 --> 00:39:22,880
time

00:39:21,280 --> 00:39:25,359
you will get this impact that you

00:39:22,880 --> 00:39:26,960
observe just by random chance

00:39:25,359 --> 00:39:28,960
in effect one in four experiments will

00:39:26,960 --> 00:39:30,880
show an effect that kind of doesn't

00:39:28,960 --> 00:39:31,760
exist at all it's just a kind of coin

00:39:30,880 --> 00:39:33,680
flip

00:39:31,760 --> 00:39:35,760
so obviously we fail to reject the null

00:39:33,680 --> 00:39:36,640
hypothesis and in essence we have to

00:39:35,760 --> 00:39:38,240
conclude

00:39:36,640 --> 00:39:40,839
that the effective dash o three over

00:39:38,240 --> 00:39:42,079
dash o two is indistinguishable from

00:39:40,839 --> 00:39:44,800
noise

00:39:42,079 --> 00:39:45,760
so that's too bad um it means that luke

00:39:44,800 --> 00:39:50,240
is stuck

00:39:45,760 --> 00:39:53,440
um one kind of funny thing about um

00:39:50,240 --> 00:39:55,359
about uh dash o is that you actually

00:39:53,440 --> 00:39:58,079
will see projects checked into github

00:39:55,359 --> 00:39:58,880
that have dash 09 and i think this is

00:39:58,079 --> 00:40:02,560
beautiful

00:39:58,880 --> 00:40:05,119
and sweet this is people who are

00:40:02,560 --> 00:40:06,960
just so optimistic about the ability of

00:40:05,119 --> 00:40:08,720
optimizers to do something

00:40:06,960 --> 00:40:10,560
unfortunately dash of nine is just dash

00:40:08,720 --> 00:40:13,359
of three all right great

00:40:10,560 --> 00:40:14,800
so what should luke be doing right lou

00:40:13,359 --> 00:40:15,280
can't use the compiler to get him out of

00:40:14,800 --> 00:40:18,240
this

00:40:15,280 --> 00:40:19,760
he's going to have to use a profiler so

00:40:18,240 --> 00:40:21,200
to a first approximation what do

00:40:19,760 --> 00:40:23,440
profilers do

00:40:21,200 --> 00:40:24,640
so profilers this is a bit of a

00:40:23,440 --> 00:40:27,359
caricature

00:40:24,640 --> 00:40:28,079
essentially look at the functions that

00:40:27,359 --> 00:40:30,079
ran

00:40:28,079 --> 00:40:31,920
uh they give you the number of calls to

00:40:30,079 --> 00:40:34,079
each function they give you the runtime

00:40:31,920 --> 00:40:36,079
for each function

00:40:34,079 --> 00:40:37,520
there are different profilers that can

00:40:36,079 --> 00:40:39,599
be more precise they can do things

00:40:37,520 --> 00:40:41,440
the levels of lines there's other

00:40:39,599 --> 00:40:43,839
somewhat more sophisticated profilers

00:40:41,440 --> 00:40:45,839
but at the end of the day the guidance

00:40:43,839 --> 00:40:48,720
that you get from a traditional profiler

00:40:45,839 --> 00:40:49,520
is here are some frequently executed

00:40:48,720 --> 00:40:51,760
code

00:40:49,520 --> 00:40:53,119
and code that executes for a long time

00:40:51,760 --> 00:40:54,640
those are the things the profiler is

00:40:53,119 --> 00:40:56,960
going to surface for you

00:40:54,640 --> 00:40:58,640
and so you might think well that's

00:40:56,960 --> 00:40:59,839
probably where luke should focus on his

00:40:58,640 --> 00:41:00,880
performance right those are the things

00:40:59,839 --> 00:41:04,319
that matter

00:41:00,880 --> 00:41:05,119
so would this speed up ogle so basically

00:41:04,319 --> 00:41:07,599
luke goes

00:41:05,119 --> 00:41:09,280
and runs a profiler and finds the code

00:41:07,599 --> 00:41:10,720
that is frequently executed and runs for

00:41:09,280 --> 00:41:12,720
a long period of time

00:41:10,720 --> 00:41:14,480
applies all the optimizations that he

00:41:12,720 --> 00:41:17,920
can think of to that code

00:41:14,480 --> 00:41:20,079
and then runs it and it turns out it

00:41:17,920 --> 00:41:21,839
made the loading thing blink faster but

00:41:20,079 --> 00:41:22,880
it didn't do anything else right this is

00:41:21,839 --> 00:41:25,920
really sad

00:41:22,880 --> 00:41:27,040
so why did that happen well frequently

00:41:25,920 --> 00:41:29,440
executed code

00:41:27,040 --> 00:41:30,480
and code that runs for a long time uh

00:41:29,440 --> 00:41:32,560
that loading

00:41:30,480 --> 00:41:34,240
dialog right that that message shows up

00:41:32,560 --> 00:41:34,800
the whole time that the thing is

00:41:34,240 --> 00:41:38,160
happening

00:41:34,800 --> 00:41:38,800
and it's executed all the time so in

00:41:38,160 --> 00:41:41,359
short

00:41:38,800 --> 00:41:42,640
profilers just do a bad job finding

00:41:41,359 --> 00:41:44,800
important code

00:41:42,640 --> 00:41:46,160
in parallel asynchronous and concurrent

00:41:44,800 --> 00:41:47,920
programs

00:41:46,160 --> 00:41:49,520
so we need to do better we need some way

00:41:47,920 --> 00:41:52,000
to help

00:41:49,520 --> 00:41:54,000
so ideally what we would have is

00:41:52,000 --> 00:41:54,880
something that we refer to as a causal

00:41:54,000 --> 00:41:57,359
profile

00:41:54,880 --> 00:41:58,400
so a causal profile answers this

00:41:57,359 --> 00:42:00,720
question

00:41:58,400 --> 00:42:01,440
so the graph that you see the x-axis is

00:42:00,720 --> 00:42:04,160
speed up

00:42:01,440 --> 00:42:06,000
to the right is better and that's

00:42:04,160 --> 00:42:06,880
speeding up like a particular line or

00:42:06,000 --> 00:42:09,839
function

00:42:06,880 --> 00:42:11,200
and then the uh the y-axis is overall

00:42:09,839 --> 00:42:14,160
program speed

00:42:11,200 --> 00:42:15,520
and so you can see like here if i speed

00:42:14,160 --> 00:42:18,240
up this red one

00:42:15,520 --> 00:42:18,640
by this much just that component then i

00:42:18,240 --> 00:42:20,720
get

00:42:18,640 --> 00:42:22,160
this overall speed up in the program

00:42:20,720 --> 00:42:23,839
that means your program will run this

00:42:22,160 --> 00:42:26,160
much faster

00:42:23,839 --> 00:42:27,359
so if we had a graph like this that was

00:42:26,160 --> 00:42:29,440
handed down to us on

00:42:27,359 --> 00:42:30,560
in you know on a tablet from mount sinai

00:42:29,440 --> 00:42:33,280
we would just look at it

00:42:30,560 --> 00:42:35,040
and we'd be like oh i will probably

00:42:33,280 --> 00:42:37,280
start optimizing the yellow thing

00:42:35,040 --> 00:42:38,160
first uh then i'll try to optimize the

00:42:37,280 --> 00:42:40,240
red thing

00:42:38,160 --> 00:42:41,359
and i will never spend any time on the

00:42:40,240 --> 00:42:43,119
bluetooth

00:42:41,359 --> 00:42:45,599
right so this is perfect this is

00:42:43,119 --> 00:42:47,119
essentially a god or an oracle

00:42:45,599 --> 00:42:48,720
telling you here's what you should be

00:42:47,119 --> 00:42:50,079
doing now of course

00:42:48,720 --> 00:42:52,240
this is great right it would be

00:42:50,079 --> 00:42:53,920
wonderful to have this information

00:42:52,240 --> 00:42:55,680
but how are we going to get it right we

00:42:53,920 --> 00:42:59,520
need to know this change

00:42:55,680 --> 00:42:59,920
has this effect so what we're going to

00:42:59,520 --> 00:43:01,359
do

00:42:59,920 --> 00:43:03,440
and i'll explain how we're going to do

00:43:01,359 --> 00:43:04,640
this is we're going to run experiments

00:43:03,440 --> 00:43:07,520
and so the experiments that we're going

00:43:04,640 --> 00:43:11,119
to run we call performance experiments

00:43:07,520 --> 00:43:13,920
now if we could magically speed up

00:43:11,119 --> 00:43:15,599
a component like here this is the the

00:43:13,920 --> 00:43:18,480
indexing search

00:43:15,599 --> 00:43:20,319
if we could speed it up magically we

00:43:18,480 --> 00:43:21,119
could observe oh if i speed this up by

00:43:20,319 --> 00:43:23,599
this much

00:43:21,119 --> 00:43:25,760
i look at the the end you can see that

00:43:23,599 --> 00:43:27,359
that's the effect of the whole program

00:43:25,760 --> 00:43:29,119
so that would be awesome

00:43:27,359 --> 00:43:30,560
right and then i could do it again right

00:43:29,119 --> 00:43:31,520
so i'm getting more and more points for

00:43:30,560 --> 00:43:33,359
this graph right i

00:43:31,520 --> 00:43:35,040
speed it up a little more i observe that

00:43:33,359 --> 00:43:36,480
there's more speed up and so on

00:43:35,040 --> 00:43:38,319
and then i do this for every single

00:43:36,480 --> 00:43:40,160
component in the program right i

00:43:38,319 --> 00:43:42,000
discover no program speed up by

00:43:40,160 --> 00:43:43,920
you know accelerating saving to the

00:43:42,000 --> 00:43:46,720
floppy disk um

00:43:43,920 --> 00:43:49,040
unfortunately that's magic right you

00:43:46,720 --> 00:43:51,440
can't just speed up code arbitrarily

00:43:49,040 --> 00:43:52,319
um you know if you could speed up code

00:43:51,440 --> 00:43:53,839
arbitrarily

00:43:52,319 --> 00:43:55,520
you wouldn't be speeding it up a little

00:43:53,839 --> 00:43:57,920
bit and observing its effect

00:43:55,520 --> 00:43:58,720
you just do this right you would speed

00:43:57,920 --> 00:44:01,920
up everything to

00:43:58,720 --> 00:44:03,200
take zero run time so fine so we're

00:44:01,920 --> 00:44:04,960
clearly not going to do this and we

00:44:03,200 --> 00:44:08,000
can't do it it's impossible

00:44:04,960 --> 00:44:09,520
uh because sadly magic does not exist i

00:44:08,000 --> 00:44:12,400
am sorry to break it to you

00:44:09,520 --> 00:44:12,960
um so um so what we're going to do is we

00:44:12,400 --> 00:44:15,119
have this

00:44:12,960 --> 00:44:17,200
clever trick which is essentially based

00:44:15,119 --> 00:44:18,319
on the theory of relativity

00:44:17,200 --> 00:44:20,720
what we're going to do is we're going to

00:44:18,319 --> 00:44:22,000
speed up a component by slowing

00:44:20,720 --> 00:44:24,079
everything else down

00:44:22,000 --> 00:44:26,319
that's running concurrently with it so

00:44:24,079 --> 00:44:27,599
we'll have the relative effect of having

00:44:26,319 --> 00:44:30,240
run faster

00:44:27,599 --> 00:44:31,599
so here what we're going to do is when

00:44:30,240 --> 00:44:33,680
the

00:44:31,599 --> 00:44:36,240
transmission part is running we're going

00:44:33,680 --> 00:44:37,359
to slow down the saving part and then

00:44:36,240 --> 00:44:39,839
you'll observe

00:44:37,359 --> 00:44:41,440
that this speed up which is really

00:44:39,839 --> 00:44:44,800
slowing down everything else

00:44:41,440 --> 00:44:46,000
has this impact and so then we can add a

00:44:44,800 --> 00:44:48,079
point to this graph

00:44:46,000 --> 00:44:49,680
that corresponds to this right so we

00:44:48,079 --> 00:44:50,640
just are going to rinse and repeat doing

00:44:49,680 --> 00:44:53,040
this

00:44:50,640 --> 00:44:55,119
we're going to run the program apply

00:44:53,040 --> 00:44:57,280
these speed ups which are really

00:44:55,119 --> 00:44:58,640
slow down so they're virtual speed ups

00:44:57,280 --> 00:44:59,280
and then we're going to observe the

00:44:58,640 --> 00:45:01,200
impact

00:44:59,280 --> 00:45:02,560
and then we're going to get these graphs

00:45:01,200 --> 00:45:03,520
we can do this for every single

00:45:02,560 --> 00:45:06,000
component

00:45:03,520 --> 00:45:07,040
again something is running you slow down

00:45:06,000 --> 00:45:08,400
the stuff

00:45:07,040 --> 00:45:10,160
the thing that you're testing you slow

00:45:08,400 --> 00:45:11,599
down everything else that's running we

00:45:10,160 --> 00:45:13,760
do this with sampling

00:45:11,599 --> 00:45:14,800
um and and other techniques that we

00:45:13,760 --> 00:45:16,480
described in detail

00:45:14,800 --> 00:45:18,319
in the paper they're happy to point you

00:45:16,480 --> 00:45:20,160
to um and

00:45:18,319 --> 00:45:22,720
you observe all the impacts you get

00:45:20,160 --> 00:45:25,839
graphs eventually you get all the graphs

00:45:22,720 --> 00:45:27,359
for all of the components now um i just

00:45:25,839 --> 00:45:28,800
want to draw your attention briefly

00:45:27,359 --> 00:45:30,319
obviously you can see there's some that

00:45:28,800 --> 00:45:32,000
are increasing there's some that are

00:45:30,319 --> 00:45:34,640
flat and there's some that are actually

00:45:32,000 --> 00:45:35,280
below the line where if you had been

00:45:34,640 --> 00:45:37,599
told

00:45:35,280 --> 00:45:39,440
you should work on optimizing that code

00:45:37,599 --> 00:45:40,880
you would have slowed down the program

00:45:39,440 --> 00:45:42,319
you might be thinking how the hell could

00:45:40,880 --> 00:45:43,280
i slow down the program by speeding

00:45:42,319 --> 00:45:46,319
something up

00:45:43,280 --> 00:45:46,880
but aha in the world of concurrency you

00:45:46,319 --> 00:45:48,880
can have

00:45:46,880 --> 00:45:50,800
problems where you have too many things

00:45:48,880 --> 00:45:54,079
that show up to a lock at the same time

00:45:50,800 --> 00:45:56,400
you have lock contention and this causes

00:45:54,079 --> 00:45:57,440
uh significant performance degradation

00:45:56,400 --> 00:45:59,200
you can have

00:45:57,440 --> 00:46:01,119
a terrible phenomenon called false

00:45:59,200 --> 00:46:02,240
sharing where things are banging on the

00:46:01,119 --> 00:46:04,160
same cache line

00:46:02,240 --> 00:46:05,280
if you accelerate one that's banging on

00:46:04,160 --> 00:46:07,440
the cache line more

00:46:05,280 --> 00:46:09,760
you're hurting the other one all right

00:46:07,440 --> 00:46:11,599
so there's lots of complexity in this

00:46:09,760 --> 00:46:13,200
the nice thing is that a causal profile

00:46:11,599 --> 00:46:14,720
would reveal this to you so you wouldn't

00:46:13,200 --> 00:46:16,160
waste your time trying to optimize

00:46:14,720 --> 00:46:16,480
things that would have a bad effect on

00:46:16,160 --> 00:46:18,720
your

00:46:16,480 --> 00:46:20,480
uh your overall program all right so

00:46:18,720 --> 00:46:24,640
let's see what happens if we apply

00:46:20,480 --> 00:46:25,920
causal profiling to ogle so here's ogle

00:46:24,640 --> 00:46:28,160
right this is the whole thing i showed

00:46:25,920 --> 00:46:29,520
you before so let's implement toggle

00:46:28,160 --> 00:46:30,640
uh if we're going to implement it we're

00:46:29,520 --> 00:46:31,520
going to have to answer a couple

00:46:30,640 --> 00:46:34,400
questions

00:46:31,520 --> 00:46:35,040
right about performance so first we care

00:46:34,400 --> 00:46:37,599
about

00:46:35,040 --> 00:46:39,119
latency right how long does it take

00:46:37,599 --> 00:46:41,280
between a request

00:46:39,119 --> 00:46:43,440
and a response that clearly matters

00:46:41,280 --> 00:46:45,920
right how fast do results come back

00:46:43,440 --> 00:46:47,119
uh is another question right how many

00:46:45,920 --> 00:46:49,680
results are coming back

00:46:47,119 --> 00:46:50,960
in total that's what we call throughput

00:46:49,680 --> 00:46:52,160
right so there's two different things

00:46:50,960 --> 00:46:55,440
that we want to actually

00:46:52,160 --> 00:46:57,839
test uh or or optimize for

00:46:55,440 --> 00:46:59,119
and it turns out that existing profilers

00:46:57,839 --> 00:47:01,040
only handle the latter

00:46:59,119 --> 00:47:02,560
they only really deal with throughput in

00:47:01,040 --> 00:47:04,400
a very oblique way

00:47:02,560 --> 00:47:05,920
they really are just like i ran my

00:47:04,400 --> 00:47:06,400
program and it spent a lot of time doing

00:47:05,920 --> 00:47:08,240
something

00:47:06,400 --> 00:47:10,319
it's not really connected to latency or

00:47:08,240 --> 00:47:12,560
throughput but as you'll see causal

00:47:10,319 --> 00:47:14,000
profiling is directly

00:47:12,560 --> 00:47:16,880
related to these things and lets you

00:47:14,000 --> 00:47:19,520
answer these questions precisely

00:47:16,880 --> 00:47:20,160
so the way causal profiling works

00:47:19,520 --> 00:47:21,920
departs

00:47:20,160 --> 00:47:23,680
a bit from traditional profilers and it

00:47:21,920 --> 00:47:24,800
requires a little more assistance for

00:47:23,680 --> 00:47:28,880
the programmer

00:47:24,800 --> 00:47:29,760
so suppose luke wants to send responses

00:47:28,880 --> 00:47:31,839
faster

00:47:29,760 --> 00:47:33,760
that is to say there should be more

00:47:31,839 --> 00:47:35,920
responses coming out per second

00:47:33,760 --> 00:47:38,079
so that's a throughput question so what

00:47:35,920 --> 00:47:39,920
you do in a causal profiler is

00:47:38,079 --> 00:47:41,359
you mark this as a so-called progress

00:47:39,920 --> 00:47:44,319
point um and

00:47:41,359 --> 00:47:44,800
every time the code runs uh it goes and

00:47:44,319 --> 00:47:46,960
it

00:47:44,800 --> 00:47:48,640
it increments a counter right and so you

00:47:46,960 --> 00:47:49,599
want that thing to happen faster and

00:47:48,640 --> 00:47:51,839
faster

00:47:49,599 --> 00:47:53,599
so when you have many of them in flight

00:47:51,839 --> 00:47:54,319
right many requests coming from multiple

00:47:53,599 --> 00:47:56,000
users

00:47:54,319 --> 00:47:58,400
right it's getting bing bing bing bing

00:47:56,000 --> 00:47:59,839
on all of them and one progress point is

00:47:58,400 --> 00:48:01,760
going to measure throughput and then

00:47:59,839 --> 00:48:02,880
it's going to test the effect of these

00:48:01,760 --> 00:48:06,160
experiments

00:48:02,880 --> 00:48:07,040
on throughput all right so that's one

00:48:06,160 --> 00:48:09,520
progress point

00:48:07,040 --> 00:48:10,559
if i speed up something how much faster

00:48:09,520 --> 00:48:13,200
do i get

00:48:10,559 --> 00:48:15,280
uh output on this progress point so

00:48:13,200 --> 00:48:17,760
great so that's throughput

00:48:15,280 --> 00:48:19,359
what about latency so suppose luke wants

00:48:17,760 --> 00:48:21,839
to minimize response time

00:48:19,359 --> 00:48:23,280
so here we have another notion of

00:48:21,839 --> 00:48:25,200
progress points that we call latency

00:48:23,280 --> 00:48:27,359
progress points which are just a begin

00:48:25,200 --> 00:48:28,720
progress point and an end progress point

00:48:27,359 --> 00:48:31,280
so you place in your code

00:48:28,720 --> 00:48:32,559
a begin you place a like the start of a

00:48:31,280 --> 00:48:33,680
transaction at the end of the

00:48:32,559 --> 00:48:35,520
transaction

00:48:33,680 --> 00:48:38,160
and then the console profiler is going

00:48:35,520 --> 00:48:40,400
to actually optimize to reduce latency

00:48:38,160 --> 00:48:41,760
and the way it works uh is that every

00:48:40,400 --> 00:48:43,280
time something comes in

00:48:41,760 --> 00:48:44,880
it actually updates the number of

00:48:43,280 --> 00:48:47,359
transactions in flight

00:48:44,880 --> 00:48:48,240
um and it when it leaves it drops the

00:48:47,359 --> 00:48:50,000
number of transactions

00:48:48,240 --> 00:48:51,280
in flight it doesn't need any more

00:48:50,000 --> 00:48:53,839
plumbing in the code

00:48:51,280 --> 00:48:55,359
because we take advantage of this lovely

00:48:53,839 --> 00:48:57,119
result from queuing theory called

00:48:55,359 --> 00:48:59,520
little's law

00:48:57,119 --> 00:49:00,559
briefly uh this is a restatement of

00:48:59,520 --> 00:49:04,240
little's law

00:49:00,559 --> 00:49:05,920
but latency essentially on average

00:49:04,240 --> 00:49:08,480
equals the number of transactions in the

00:49:05,920 --> 00:49:09,839
system divided by the throughput

00:49:08,480 --> 00:49:11,920
and we already know how to measure

00:49:09,839 --> 00:49:14,079
throughput which is through this measure

00:49:11,920 --> 00:49:15,920
of how many things run through the

00:49:14,079 --> 00:49:17,440
either one of the transaction points and

00:49:15,920 --> 00:49:18,640
then we have the counter

00:49:17,440 --> 00:49:20,880
and that's enough to allow us to

00:49:18,640 --> 00:49:22,559
optimize for latency

00:49:20,880 --> 00:49:24,960
so we've built a causal profiler for

00:49:22,559 --> 00:49:26,880
linux it ships with debian and ubuntu

00:49:24,960 --> 00:49:29,520
it's also on github

00:49:26,880 --> 00:49:30,319
unfortunately it does not work on on

00:49:29,520 --> 00:49:33,839
windows

00:49:30,319 --> 00:49:34,640
but uh what are you going to do um so

00:49:33,839 --> 00:49:37,119
what you're going to do is you're going

00:49:34,640 --> 00:49:38,720
to use linux to do this um so this is

00:49:37,119 --> 00:49:41,440
how you run it you say cause

00:49:38,720 --> 00:49:41,839
run dash dash dash that that consumes

00:49:41,440 --> 00:49:43,520
all the

00:49:41,839 --> 00:49:46,319
command line arguments then you write

00:49:43,520 --> 00:49:47,839
your program code so just as usual

00:49:46,319 --> 00:49:50,160
and the important thing to understand

00:49:47,839 --> 00:49:51,680
here with cause is it actually goes back

00:49:50,160 --> 00:49:53,599
to the beginning of the talk

00:49:51,680 --> 00:49:55,599
these performance experiments are random

00:49:53,599 --> 00:49:57,599
and this randomness disrupts the way

00:49:55,599 --> 00:49:59,440
things are actually scheduled

00:49:57,599 --> 00:50:01,119
so when an experiment happens it

00:49:59,440 --> 00:50:01,839
randomly picks some line of code that's

00:50:01,119 --> 00:50:03,359
running

00:50:01,839 --> 00:50:05,599
and runs the performance experiment

00:50:03,359 --> 00:50:08,240
either for latency or for throughput

00:50:05,599 --> 00:50:09,920
and because things are concurrent and

00:50:08,240 --> 00:50:11,280
because things are asynchronous

00:50:09,920 --> 00:50:13,520
and because they're being probed in

00:50:11,280 --> 00:50:15,599
random ways you get the effect

00:50:13,520 --> 00:50:17,520
of it being random and so this means

00:50:15,599 --> 00:50:20,000
that the results are going to be due to

00:50:17,520 --> 00:50:22,400
the performance change that is predicted

00:50:20,000 --> 00:50:23,359
so let's go ahead and use it with ogle

00:50:22,400 --> 00:50:26,400
um

00:50:23,359 --> 00:50:28,720
so if you are uh running ogle

00:50:26,400 --> 00:50:30,880
right well we need code to run algol so

00:50:28,720 --> 00:50:32,160
we took a bunch of programs from this

00:50:30,880 --> 00:50:34,960
thing called parsec

00:50:32,160 --> 00:50:36,559
uh and we combined them uh so we have a

00:50:34,960 --> 00:50:38,880
thing that does deduplication

00:50:36,559 --> 00:50:40,640
so when you take an image it compresses

00:50:38,880 --> 00:50:42,240
it and i'll explain how

00:50:40,640 --> 00:50:44,000
uh we have a thing that does image

00:50:42,240 --> 00:50:46,000
comparison called ferret

00:50:44,000 --> 00:50:48,079
uh these all come from parsec and then

00:50:46,000 --> 00:50:49,680
the database we use sqlite

00:50:48,079 --> 00:50:52,079
so let me focus on ferret which was

00:50:49,680 --> 00:50:55,040
quite easy and quite nice

00:50:52,079 --> 00:50:56,480
um so this is a resulting causal profile

00:50:55,040 --> 00:50:58,640
produced by cause

00:50:56,480 --> 00:51:00,400
uh and so it's at a line level and you

00:50:58,640 --> 00:51:01,839
can read this exactly as i showed in the

00:51:00,400 --> 00:51:04,400
graph before there's a little bit

00:51:01,839 --> 00:51:06,319
prettier and more abstract um it goes

00:51:04,400 --> 00:51:08,240
from zero to 100 on the x-axis that's

00:51:06,319 --> 00:51:10,240
how much you speed up a line

00:51:08,240 --> 00:51:11,680
and then the y-axis is overall program

00:51:10,240 --> 00:51:12,960
speed up so we were just testing

00:51:11,680 --> 00:51:15,440
throughput here

00:51:12,960 --> 00:51:16,319
um and the cool part is that these lines

00:51:15,440 --> 00:51:19,520
of code

00:51:16,319 --> 00:51:21,359
corresponded to discrete parts of ferret

00:51:19,520 --> 00:51:23,119
to a ranking part and indexing part of

00:51:21,359 --> 00:51:25,280
the segmentation part

00:51:23,119 --> 00:51:26,319
and the way that ferret was structured

00:51:25,280 --> 00:51:29,520
is that it actually

00:51:26,319 --> 00:51:30,960
sets up a number of threads so it comes

00:51:29,520 --> 00:51:31,280
up you know it says how many cpus you

00:51:30,960 --> 00:51:32,640
have

00:51:31,280 --> 00:51:36,079
it figures out how many threads to

00:51:32,640 --> 00:51:38,559
create and it evenly spread them across

00:51:36,079 --> 00:51:39,359
so as you can see the gray part feature

00:51:38,559 --> 00:51:40,960
extraction

00:51:39,359 --> 00:51:42,400
right this is this image pipeline the

00:51:40,960 --> 00:51:44,400
feature extraction part was not

00:51:42,400 --> 00:51:45,040
highlighted by cause as being important

00:51:44,400 --> 00:51:47,200
at all

00:51:45,040 --> 00:51:48,720
so it probably needs fewer threads so

00:51:47,200 --> 00:51:50,720
what we did is we just

00:51:48,720 --> 00:51:51,920
took away some of its spreads and gave

00:51:50,720 --> 00:51:53,599
them to the ones where

00:51:51,920 --> 00:51:56,079
we expected there to be more bang for

00:51:53,599 --> 00:51:59,119
the buck as predicted by cause

00:51:56,079 --> 00:51:59,680
and the result was a 21 speed up so

00:51:59,119 --> 00:52:02,079
great

00:51:59,680 --> 00:52:02,800
so that was great we're all happy with

00:52:02,079 --> 00:52:05,440
the 21

00:52:02,800 --> 00:52:06,720
speed up because it's random we have

00:52:05,440 --> 00:52:08,480
high confidence that's going to be a

00:52:06,720 --> 00:52:09,440
robust result so it's not just here

00:52:08,480 --> 00:52:13,040
today

00:52:09,440 --> 00:52:16,319
what did it predict well cause

00:52:13,040 --> 00:52:18,240
predicted um that if you

00:52:16,319 --> 00:52:20,319
basically uh increase the ranking

00:52:18,240 --> 00:52:21,920
throughput by 27

00:52:20,319 --> 00:52:23,839
which is what we did we increased from

00:52:21,920 --> 00:52:26,319
16 to 22 threads

00:52:23,839 --> 00:52:27,680
um if you go and you look at the graph

00:52:26,319 --> 00:52:30,800
that's 27

00:52:27,680 --> 00:52:33,359
on the x-axis and on the y-axis you get

00:52:30,800 --> 00:52:35,520
this result which is a 21 improvement

00:52:33,359 --> 00:52:38,559
which is exactly what we observed

00:52:35,520 --> 00:52:40,160
so cause is actually doing

00:52:38,559 --> 00:52:41,760
not only pointing us to where the

00:52:40,160 --> 00:52:43,920
optimization makes a big difference

00:52:41,760 --> 00:52:46,000
but it's doing it accurately uh and this

00:52:43,920 --> 00:52:48,319
happens over and over again

00:52:46,000 --> 00:52:50,240
um so we did this with other uh these

00:52:48,319 --> 00:52:52,720
other applications like d-dupe

00:52:50,240 --> 00:52:55,119
so in d-dupe uh the way g-dupe works

00:52:52,720 --> 00:52:57,359
it's compression via deduplication

00:52:55,119 --> 00:52:58,559
uh like its name suggests so if you have

00:52:57,359 --> 00:53:00,240
your image here

00:52:58,559 --> 00:53:02,000
and somebody else has already saved this

00:53:00,240 --> 00:53:03,200
meme you can see that there's a pretty

00:53:02,000 --> 00:53:06,480
common chunk

00:53:03,200 --> 00:53:07,920
right this is it and so rather than

00:53:06,480 --> 00:53:09,200
representing every image as an

00:53:07,920 --> 00:53:11,920
individual item

00:53:09,200 --> 00:53:12,880
you represent it as multiple items so

00:53:11,920 --> 00:53:15,839
here

00:53:12,880 --> 00:53:17,040
we split up an image so grumpy count one

00:53:15,839 --> 00:53:19,760
is now these three pieces

00:53:17,040 --> 00:53:21,520
the top the bottom and the middle and

00:53:19,760 --> 00:53:24,559
fun is awful.jpg

00:53:21,520 --> 00:53:26,240
is now the three pieces and uh one of

00:53:24,559 --> 00:53:26,960
them is the same big giant chunk in the

00:53:26,240 --> 00:53:29,920
middle

00:53:26,960 --> 00:53:31,520
all right so the way detube works it

00:53:29,920 --> 00:53:33,760
applies a hash function

00:53:31,520 --> 00:53:35,520
um and that it maintains a bunch of

00:53:33,760 --> 00:53:36,240
buckets for where all these things are

00:53:35,520 --> 00:53:37,760
kept

00:53:36,240 --> 00:53:39,599
right so it computes a hash function

00:53:37,760 --> 00:53:40,079
over an image and it jams it into the

00:53:39,599 --> 00:53:43,280
bucket

00:53:40,079 --> 00:53:46,400
it's a pretty straightforward linear

00:53:43,280 --> 00:53:48,960
linear chaining hash table um

00:53:46,400 --> 00:53:50,480
and so it does the usual stuff it adds

00:53:48,960 --> 00:53:52,480
everything to these buckets

00:53:50,480 --> 00:53:54,400
great the hash table is accessed

00:53:52,480 --> 00:53:56,640
concurrently by many threads

00:53:54,400 --> 00:53:57,520
cause actually said hey this is a

00:53:56,640 --> 00:53:59,520
bottleneck

00:53:57,520 --> 00:54:00,960
and we're like oh maybe there's

00:53:59,520 --> 00:54:01,440
something really stupid about this hash

00:54:00,960 --> 00:54:04,240
table

00:54:01,440 --> 00:54:05,839
like it's got one big lock it does not

00:54:04,240 --> 00:54:08,240
it has many locks

00:54:05,839 --> 00:54:09,280
uh so we were like hmm that's confusing

00:54:08,240 --> 00:54:11,359
uh so

00:54:09,280 --> 00:54:13,920
it's not a concurrency problem what on

00:54:11,359 --> 00:54:16,400
earth could it be

00:54:13,920 --> 00:54:17,920
so cause specifically said the code that

00:54:16,400 --> 00:54:20,000
was in this list

00:54:17,920 --> 00:54:21,359
was important that the loop was like

00:54:20,000 --> 00:54:21,839
where it iterates through this thing

00:54:21,359 --> 00:54:24,720
looking

00:54:21,839 --> 00:54:26,480
for a hit or are looking for a bucket an

00:54:24,720 --> 00:54:29,520
empty place to insert something

00:54:26,480 --> 00:54:31,680
was very important so we thought wow

00:54:29,520 --> 00:54:32,559
maybe the hash table is just too small

00:54:31,680 --> 00:54:34,160
right

00:54:32,559 --> 00:54:35,440
there there's just too many of these

00:54:34,160 --> 00:54:37,119
like there's maybe a small number of

00:54:35,440 --> 00:54:39,040
these things and we said okay

00:54:37,119 --> 00:54:40,240
we need to spread out the list better

00:54:39,040 --> 00:54:42,559
and so we

00:54:40,240 --> 00:54:44,000
added a bunch of hash buckets and so in

00:54:42,559 --> 00:54:45,280
principle more hash buckets should lead

00:54:44,000 --> 00:54:47,200
to fewer collisions

00:54:45,280 --> 00:54:48,319
but in practice we got no performance

00:54:47,200 --> 00:54:51,520
improvement

00:54:48,319 --> 00:54:54,160
so what else could be causing collisions

00:54:51,520 --> 00:54:55,520
um and somebody at home is definitely

00:54:54,160 --> 00:54:58,799
got the answer here

00:54:55,520 --> 00:55:01,440
the answer is the freaking hash function

00:54:58,799 --> 00:55:02,880
so uh the moral of the story here a

00:55:01,440 --> 00:55:04,240
brief moral is don't

00:55:02,880 --> 00:55:05,280
try this at home don't build your own

00:55:04,240 --> 00:55:06,400
hash function unless you know what

00:55:05,280 --> 00:55:08,319
you're doing

00:55:06,400 --> 00:55:10,400
um here we actually graph the

00:55:08,319 --> 00:55:13,200
utilization of the hash function

00:55:10,400 --> 00:55:14,880
so we created 1024 buckets and then we

00:55:13,200 --> 00:55:15,440
counted how many things ended up in each

00:55:14,880 --> 00:55:16,799
bucket

00:55:15,440 --> 00:55:20,000
and you can see the utilization is a

00:55:16,799 --> 00:55:21,599
catastrophe um it's 2.3

00:55:20,000 --> 00:55:23,359
most of the buckets are empty and a

00:55:21,599 --> 00:55:25,760
bunch of them have like a hundred

00:55:23,359 --> 00:55:26,480
and it turns out the reason is that in

00:55:25,760 --> 00:55:28,559
effect

00:55:26,480 --> 00:55:29,839
uh there was a normal distribution

00:55:28,559 --> 00:55:32,319
because it just added

00:55:29,839 --> 00:55:34,240
values taken from these images and the

00:55:32,319 --> 00:55:36,079
images are effectively random

00:55:34,240 --> 00:55:38,079
and so you get the central limit theorem

00:55:36,079 --> 00:55:39,280
and you get a normal distribution

00:55:38,079 --> 00:55:40,960
but you do not want a normal

00:55:39,280 --> 00:55:42,640
distribution for your hash function you

00:55:40,960 --> 00:55:44,880
want a uniform distribution for your

00:55:42,640 --> 00:55:48,160
hash function that spread things evenly

00:55:44,880 --> 00:55:50,880
so um my student actually changed

00:55:48,160 --> 00:55:51,520
in probably the greatest uh optimization

00:55:50,880 --> 00:55:54,240
per

00:55:51,520 --> 00:55:55,280
effort uh ever changed one character in

00:55:54,240 --> 00:55:59,119
the hash function

00:55:55,280 --> 00:56:02,319
from a plus to xor

00:55:59,119 --> 00:56:04,400
and it became 82 utilization

00:56:02,319 --> 00:56:06,160
so it's not a huge speed up this led to

00:56:04,400 --> 00:56:09,040
a 9 overall speed up

00:56:06,160 --> 00:56:10,640
uh which is not nothing uh but it is uh

00:56:09,040 --> 00:56:12,400
it's definitely a big bang for one

00:56:10,640 --> 00:56:14,319
character of change

00:56:12,400 --> 00:56:16,480
and so it turns out we can actually see

00:56:14,319 --> 00:56:18,480
what cause predicted and how closely its

00:56:16,480 --> 00:56:21,760
prediction cue to the result

00:56:18,480 --> 00:56:24,079
so the blocks per bucket determines

00:56:21,760 --> 00:56:24,799
the number of iterations to go through

00:56:24,079 --> 00:56:27,480
this list

00:56:24,799 --> 00:56:29,040
obviously and on average before it was

00:56:27,480 --> 00:56:32,000
76.7

00:56:29,040 --> 00:56:32,559
afterwards it was 2.09 so that's a big

00:56:32,000 --> 00:56:35,359
improvement

00:56:32,559 --> 00:56:36,720
right so an average of two instead of 76

00:56:35,359 --> 00:56:38,319
this is a 96

00:56:36,720 --> 00:56:40,000
traversal speed up you look at that

00:56:38,319 --> 00:56:42,079
graph which i'm not going to show

00:56:40,000 --> 00:56:44,960
this gives you a 9 predicted speed up

00:56:42,079 --> 00:56:46,880
which is exactly what we observe

00:56:44,960 --> 00:56:49,359
finally i'm going to show you something

00:56:46,880 --> 00:56:51,040
that is really

00:56:49,359 --> 00:56:52,640
a kind of performance optimization

00:56:51,040 --> 00:56:55,119
opportunity you would never see

00:56:52,640 --> 00:56:56,079
any profiler ever deliver i mean cause

00:56:55,119 --> 00:56:58,480
goes beyond

00:56:56,079 --> 00:56:59,760
previous profilers in that it handles

00:56:58,480 --> 00:57:01,520
obviously predicts things

00:56:59,760 --> 00:57:03,760
it does throughput and it does latency

00:57:01,520 --> 00:57:05,119
profiling but it also finds things that

00:57:03,760 --> 00:57:06,400
you would never look for that would

00:57:05,119 --> 00:57:08,079
never show up ever

00:57:06,400 --> 00:57:09,520
so let me show you an example from

00:57:08,079 --> 00:57:12,160
sqlite so

00:57:09,520 --> 00:57:13,280
here in sqlite are some causal profiles

00:57:12,160 --> 00:57:14,400
and you can see that there's some

00:57:13,280 --> 00:57:16,400
weirdness happening

00:57:14,400 --> 00:57:18,079
we speed up some lines of code and

00:57:16,400 --> 00:57:19,920
things drop

00:57:18,079 --> 00:57:21,280
and this usually indicates some sort of

00:57:19,920 --> 00:57:23,359
a contention problem

00:57:21,280 --> 00:57:24,720
um so it's either false sharing or a

00:57:23,359 --> 00:57:27,440
lock

00:57:24,720 --> 00:57:29,119
so sqlite for those of you don't know uh

00:57:27,440 --> 00:57:32,079
it's a simple sql database

00:57:29,119 --> 00:57:32,480
it's crazy it compiles to one big c file

00:57:32,079 --> 00:57:34,400
um

00:57:32,480 --> 00:57:35,920
it's in everything it's in your browser

00:57:34,400 --> 00:57:38,000
it's on your phone it's in there's

00:57:35,920 --> 00:57:40,799
probably 10 instances of sqlite

00:57:38,000 --> 00:57:42,160
running on every device you own um and

00:57:40,799 --> 00:57:44,799
it has this

00:57:42,160 --> 00:57:45,839
super hacky uh so the thing is written

00:57:44,799 --> 00:57:48,480
in c and not c

00:57:45,839 --> 00:57:49,119
class and so they made they rolled their

00:57:48,480 --> 00:57:52,400
own v

00:57:49,119 --> 00:57:54,480
tables so uh they have this thing

00:57:52,400 --> 00:57:56,000
where it's defined at compile time they

00:57:54,480 --> 00:57:59,040
have this global config

00:57:56,000 --> 00:58:02,880
if it is thread safe um and

00:57:59,040 --> 00:58:04,880
it has uh members where it uses a lock

00:58:02,880 --> 00:58:06,079
like it does a wheel unlock when you do

00:58:04,880 --> 00:58:08,640
unlock it does

00:58:06,079 --> 00:58:10,960
this thread safe get size it does a

00:58:08,640 --> 00:58:13,119
bunch of stuff that is thread safe

00:58:10,960 --> 00:58:14,720
if it is not compiled with thread safe

00:58:13,119 --> 00:58:16,799
then the unlock is a null

00:58:14,720 --> 00:58:18,000
right it's a no op the the lock is in no

00:58:16,799 --> 00:58:20,160
op and

00:58:18,000 --> 00:58:22,000
it uses things that don't acquire locks

00:58:20,160 --> 00:58:25,520
seems like a reasonable optimization

00:58:22,000 --> 00:58:27,119
fine um it's a little odd that they

00:58:25,520 --> 00:58:29,440
would do this dynamically

00:58:27,119 --> 00:58:31,040
in a v table but anyway be that as it

00:58:29,440 --> 00:58:34,079
may that's the way it works

00:58:31,040 --> 00:58:35,920
so um the way that sql light unlock

00:58:34,079 --> 00:58:37,839
works is there's a level of indirection

00:58:35,920 --> 00:58:39,359
right so rather than calling something

00:58:37,839 --> 00:58:40,160
directly it indirects through global

00:58:39,359 --> 00:58:41,760
config

00:58:40,160 --> 00:58:43,280
and then it makes this function call

00:58:41,760 --> 00:58:44,880
this isn't a direct call

00:58:43,280 --> 00:58:46,720
uh and i think you know most people in

00:58:44,880 --> 00:58:48,160
the audience here would be like well

00:58:46,720 --> 00:58:50,000
indirect calls are not that expensive

00:58:48,160 --> 00:58:52,559
and some people in c plus bus land

00:58:50,000 --> 00:58:53,440
really hate the idea of using virtual uh

00:58:52,559 --> 00:58:55,040
dispatch

00:58:53,440 --> 00:58:58,079
um i think it's a subject of some

00:58:55,040 --> 00:59:00,720
contention uh it's usually pretty fast

00:58:58,079 --> 00:59:02,799
the the problem is that pthread mutex

00:59:00,720 --> 00:59:04,960
unlock is also pretty fast

00:59:02,799 --> 00:59:05,839
and this is preceding p thread mutex

00:59:04,960 --> 00:59:08,079
unlock

00:59:05,839 --> 00:59:10,160
right so every single time this is

00:59:08,079 --> 00:59:10,880
happening right and it happens multiple

00:59:10,160 --> 00:59:12,400
times

00:59:10,880 --> 00:59:14,799
these are all the lines that causes

00:59:12,400 --> 00:59:17,920
highlighting it's actually increasing

00:59:14,799 --> 00:59:19,680
the critical section on all of this code

00:59:17,920 --> 00:59:22,079
and the critical section is not much

00:59:19,680 --> 00:59:23,200
but it's it's enough it's like doubled

00:59:22,079 --> 00:59:25,280
so by doubling

00:59:23,200 --> 00:59:27,200
this uh these critical section lengths

00:59:25,280 --> 00:59:28,480
you actually have a big impact when you

00:59:27,200 --> 00:59:31,119
increase the number of threads

00:59:28,480 --> 00:59:32,000
because you get a ton of contention so

00:59:31,119 --> 00:59:33,680
in some

00:59:32,000 --> 00:59:35,599
uh so we we did something where we

00:59:33,680 --> 00:59:36,640
stripped out the the virtual dispatch

00:59:35,599 --> 00:59:38,720
from sqlite

00:59:36,640 --> 00:59:40,559
sped it up by 25 you've already seen

00:59:38,720 --> 00:59:42,319
these other performance improvements

00:59:40,559 --> 00:59:44,480
um we applied it to a whole bunch of

00:59:42,319 --> 00:59:46,240
other things we were able very quickly

00:59:44,480 --> 00:59:48,720
this code we had never seen before

00:59:46,240 --> 00:59:49,280
i should add uh this code that in

00:59:48,720 --> 00:59:51,200
general

00:59:49,280 --> 00:59:53,040
it was like a question of spend no more

00:59:51,200 --> 00:59:54,000
than 20 or 30 minutes trying to optimize

00:59:53,040 --> 00:59:56,640
these programs

00:59:54,000 --> 00:59:58,079
and we were able to quickly basically

00:59:56,640 --> 01:00:00,400
place progress points

00:59:58,079 --> 01:00:01,440
run cause and get shocking improvements

01:00:00,400 --> 01:00:03,680
in some cases

01:00:01,440 --> 01:00:05,680
my favorite is stream cluster uh and

01:00:03,680 --> 01:00:08,640
fluid animate we got 38

01:00:05,680 --> 01:00:09,359
and 68 improvements by removing a custom

01:00:08,640 --> 01:00:12,160
barrier

01:00:09,359 --> 01:00:13,520
and using the standard barrier uh so

01:00:12,160 --> 01:00:14,640
this is something that you probably

01:00:13,520 --> 01:00:18,160
would not have found with

01:00:14,640 --> 01:00:20,400
a regular a regular profiler

01:00:18,160 --> 01:00:23,200
so um i think that it's getting near my

01:00:20,400 --> 01:00:25,359
time so i'm going to conclude

01:00:23,200 --> 01:00:26,400
so i presented sound performance

01:00:25,359 --> 01:00:28,880
analysis

01:00:26,400 --> 01:00:30,240
argued that performance analysis or the

01:00:28,880 --> 01:00:31,280
performance optimizations have kind of

01:00:30,240 --> 01:00:32,559
run out of steam

01:00:31,280 --> 01:00:34,240
so you really need to be using a

01:00:32,559 --> 01:00:36,400
different profiler that existing

01:00:34,240 --> 01:00:39,520
profilers don't get the job done

01:00:36,400 --> 01:00:42,000
uh you should go and use the cause

01:00:39,520 --> 01:00:42,720
um you can install it yourself on linux

01:00:42,000 --> 01:00:44,640
and

01:00:42,720 --> 01:00:47,040
with that i would be happy to take any

01:00:44,640 --> 01:00:47,040
questions

01:00:47,280 --> 01:00:57,839
thanks for your attention

01:01:08,079 --> 01:01:10,160

YouTube URL: https://www.youtube.com/watch?v=koTf7u0v41o


