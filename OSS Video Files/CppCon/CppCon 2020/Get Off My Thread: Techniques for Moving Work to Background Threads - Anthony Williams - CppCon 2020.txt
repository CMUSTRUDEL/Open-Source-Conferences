Title: Get Off My Thread: Techniques for Moving Work to Background Threads - Anthony Williams - CppCon 2020
Publication date: 2020-09-30
Playlist: CppCon 2020
Description: 
	https://cppcon.org/
https://github.com/CppCon/CppCon2020/blob/main/Presentations/get_off_my_thread/get_off_my_thread__anthony_williams__cppcon_2020.pdf
---
If you're writing a GUI application and you want the interface to feel "responsive" to the user then you need the code that response to UI events to be short and fast. Similarly, if you are handling network I/O you may not want the processing of one request to prevent the system receiving further input.

If the work to be done in response to an event is complex and time consuming then you can maintain the "responsiveness" of the system by passing the work off to a background thread.

This talk will look at the ways of doing this, including managing ongoing work, providing progress updates, and cancelling work if it is no longer needed.

---
Anthony Williams
Just Software Solutions Ltd
Anthony Williams is the author of C++ Concurrency in Action.

---
Streamed & Edited by Digital Medium Ltd - events.digital-medium.co.uk
events@digital-medium.co.uk
Captions: 
	00:00:08,480 --> 00:00:10,720
so

00:00:11,599 --> 00:00:18,960
get off my thread and really

00:00:15,440 --> 00:00:18,960
if we just want to

00:00:19,439 --> 00:00:24,160
move stuff you know off the current

00:00:22,720 --> 00:00:25,760
thread

00:00:24,160 --> 00:00:27,279
onto something back onto the background

00:00:25,760 --> 00:00:28,080
thread and so obviously obviously we're

00:00:27,279 --> 00:00:29,920
going to talk about

00:00:28,080 --> 00:00:31,199
why we might want to do that then we're

00:00:29,920 --> 00:00:32,880
going to look at how we

00:00:31,199 --> 00:00:34,320
might do that and then we're going to

00:00:32,880 --> 00:00:38,000
have some

00:00:34,320 --> 00:00:42,840
final guidelines and questions

00:00:38,000 --> 00:00:44,000
you know um to like to wrap everything

00:00:42,840 --> 00:00:47,280
up

00:00:44,000 --> 00:00:48,879
so yes why do we need to move work off

00:00:47,280 --> 00:00:51,920
the current thread

00:00:48,879 --> 00:00:55,440
well fundamentally

00:00:51,920 --> 00:00:56,239
then lots of us live in and work in

00:00:55,440 --> 00:00:59,199
environments

00:00:56,239 --> 00:01:00,079
where there is some thread that is

00:00:59,199 --> 00:01:02,320
dedicated

00:01:00,079 --> 00:01:03,920
to processing external events now that

00:01:02,320 --> 00:01:06,560
might be a gui

00:01:03,920 --> 00:01:08,720
where you have a message handling thread

00:01:06,560 --> 00:01:10,000
the os is passing you messages or the

00:01:08,720 --> 00:01:11,520
windowing environment is passing you

00:01:10,000 --> 00:01:12,880
messages and they have to be handled on

00:01:11,520 --> 00:01:15,920
that thread

00:01:12,880 --> 00:01:15,920
or you might be

00:01:18,320 --> 00:01:23,840
running some form

00:01:21,439 --> 00:01:23,840
of

00:01:25,280 --> 00:01:29,439
um

00:01:26,540 --> 00:01:31,600
[Music]

00:01:29,439 --> 00:01:34,000
you might be running some form of client

00:01:31,600 --> 00:01:37,360
server or network application

00:01:34,000 --> 00:01:40,240
where the uh

00:01:37,360 --> 00:01:41,680
the network handling is is running on a

00:01:40,240 --> 00:01:44,960
specific thread

00:01:41,680 --> 00:01:47,360
so you have the

00:01:44,960 --> 00:01:48,720
you know the um socket notifications

00:01:47,360 --> 00:01:50,640
come in yes there's some data on the

00:01:48,720 --> 00:01:52,799
socket so then i'm going to process that

00:01:50,640 --> 00:01:55,119
i'm going to respond to that and then i

00:01:52,799 --> 00:01:58,399
will go back and you know

00:01:55,119 --> 00:01:58,399
call select as appropriate

00:02:00,479 --> 00:02:05,280
and then whatever the reason why you

00:02:03,759 --> 00:02:06,159
have to have your events handled on a

00:02:05,280 --> 00:02:08,160
specific thread

00:02:06,159 --> 00:02:11,280
if you then perform extensive processing

00:02:08,160 --> 00:02:13,760
in response to the response those events

00:02:11,280 --> 00:02:14,800
then that then blocks that thread it

00:02:13,760 --> 00:02:19,040
prevents you from

00:02:14,800 --> 00:02:23,840
handling any further messages so

00:02:19,040 --> 00:02:23,840
we want to get our work off that thread

00:02:27,680 --> 00:02:34,480
so now that because delaying these

00:02:30,640 --> 00:02:36,560
responses to external events can have

00:02:34,480 --> 00:02:38,800
consequences that are disastrous only

00:02:36,560 --> 00:02:42,879
they might be unpleasant for our users

00:02:38,800 --> 00:02:46,480
they might actually have genuine

00:02:42,879 --> 00:02:47,920
um no

00:02:46,480 --> 00:02:50,080
things that are actually going to cost

00:02:47,920 --> 00:02:51,040
things money but there are going to be

00:02:50,080 --> 00:02:52,319
consequences

00:02:51,040 --> 00:02:54,640
now if you're running a windows

00:02:52,319 --> 00:02:55,840
application and you don't respond to

00:02:54,640 --> 00:02:59,200
your events then you're going to bring

00:02:55,840 --> 00:03:00,640
out the entire application window and

00:02:59,200 --> 00:03:02,800
users are going to notice that they're

00:03:00,640 --> 00:03:04,400
going to complain and potentially not

00:03:02,800 --> 00:03:07,519
use your application

00:03:04,400 --> 00:03:09,360
the application window won't respond

00:03:07,519 --> 00:03:10,879
you will get support problems and then

00:03:09,360 --> 00:03:12,400
people might yes they will switch to

00:03:10,879 --> 00:03:14,800
your competitors if the competitors

00:03:12,400 --> 00:03:18,319
don't have that problem

00:03:14,800 --> 00:03:20,959
if you're running a web server and

00:03:18,319 --> 00:03:22,319
the web browser sends its request and

00:03:20,959 --> 00:03:25,200
you don't respond

00:03:22,319 --> 00:03:25,760
then at some point the web browser is

00:03:25,200 --> 00:03:27,120
going to give up

00:03:25,760 --> 00:03:29,440
it will give you a timed out

00:03:27,120 --> 00:03:31,360
notification your user won't see a nice

00:03:29,440 --> 00:03:32,720
your nice web application they'll see a

00:03:31,360 --> 00:03:36,959
nasty

00:03:32,720 --> 00:03:36,959
no error message from firefox or chrome

00:03:37,040 --> 00:03:40,159
and like and if you're not running

00:03:39,040 --> 00:03:41,840
within

00:03:40,159 --> 00:03:43,440
a browser framework but you are running

00:03:41,840 --> 00:03:46,000
other network applications

00:03:43,440 --> 00:03:47,760
then most systems we're going to have

00:03:46,000 --> 00:03:49,120
have a timeout on an operation

00:03:47,760 --> 00:03:50,159
and if you don't get a response within

00:03:49,120 --> 00:03:52,239
the timeout then they're going to do

00:03:50,159 --> 00:03:54,239
something else that might be

00:03:52,239 --> 00:03:56,720
they treat it as a failed request and

00:03:54,239 --> 00:03:56,720
cancel it

00:03:57,519 --> 00:04:04,159
or it might be that there is

00:04:01,120 --> 00:04:06,480
a um no that the application

00:04:04,159 --> 00:04:08,080
repeats the request and so now your

00:04:06,480 --> 00:04:10,959
messages are doubled up

00:04:08,080 --> 00:04:11,519
but any which way happens if you don't

00:04:10,959 --> 00:04:14,959
respond

00:04:11,519 --> 00:04:17,040
to your rents on the in a timely fashion

00:04:14,959 --> 00:04:19,040
there are undesirable consequences and

00:04:17,040 --> 00:04:22,239
so we want to move that work

00:04:19,040 --> 00:04:22,239
off the event handling threat

00:04:23,360 --> 00:04:27,280
and we don't just need to move to work

00:04:25,680 --> 00:04:28,479
we need to prevent any blocking on our

00:04:27,280 --> 00:04:29,120
event handling threads it's all very

00:04:28,479 --> 00:04:31,040
well saying

00:04:29,120 --> 00:04:32,960
our event handler is going to spawn some

00:04:31,040 --> 00:04:35,280
background tasks but if we then wait for

00:04:32,960 --> 00:04:36,800
the background task to finish

00:04:35,280 --> 00:04:38,639
even if we've done some other processing

00:04:36,800 --> 00:04:41,680
in between then that weight

00:04:38,639 --> 00:04:43,440
there no this would

00:04:41,680 --> 00:04:45,759
know throws out all the benefit that

00:04:43,440 --> 00:04:48,479
we've gained

00:04:45,759 --> 00:04:49,919
from you know actually doing that work

00:04:48,479 --> 00:04:50,639
on the background on the background

00:04:49,919 --> 00:04:53,040
thread

00:04:50,639 --> 00:04:53,759
because the event handler is still

00:04:53,040 --> 00:04:56,800
blocked

00:04:53,759 --> 00:05:00,160
and still can't process events so we

00:04:56,800 --> 00:05:00,160
need to prevent that blocking

00:05:03,759 --> 00:05:06,960
so i just want to have a quick aside

00:05:05,520 --> 00:05:10,000
here about

00:05:06,960 --> 00:05:11,840
preventing blocking and say well then in

00:05:10,000 --> 00:05:12,160
lots of cases then short term blocking

00:05:11,840 --> 00:05:15,440
like

00:05:12,160 --> 00:05:17,039
you know looking a mutex is okay if

00:05:15,440 --> 00:05:18,320
we know that other thread though if

00:05:17,039 --> 00:05:19,280
you're looking at mutex if the other

00:05:18,320 --> 00:05:21,120
threads

00:05:19,280 --> 00:05:23,280
are not going to hold the mutex not for

00:05:21,120 --> 00:05:24,639
long for very long at all

00:05:23,280 --> 00:05:26,479
then it's just a little new text

00:05:24,639 --> 00:05:26,960
background around the boolean flag for

00:05:26,479 --> 00:05:29,280
example

00:05:26,960 --> 00:05:31,600
and the other thread locks the locks

00:05:29,280 --> 00:05:34,320
mutex sets the flag unlocks the mutex

00:05:31,600 --> 00:05:34,800
if that's the case then in many cases

00:05:34,320 --> 00:05:37,280
that

00:05:34,800 --> 00:05:41,039
might be acceptable no the the worst

00:05:37,280 --> 00:05:41,039
case blocking time is really short

00:05:41,120 --> 00:05:47,759
and there isn't a problem and in no

00:05:44,160 --> 00:05:51,360
so particularly in user interface based

00:05:47,759 --> 00:05:52,960
scenarios then what we really want is

00:05:51,360 --> 00:05:55,360
not to be waiting for a lengthy period

00:05:52,960 --> 00:05:57,600
of time we're not waiting

00:05:55,360 --> 00:05:59,840
for a lengthy task to run and so that's

00:05:57,600 --> 00:06:02,960
what we mean by non-blocking

00:05:59,840 --> 00:06:05,440
but in other cases it's really really

00:06:02,960 --> 00:06:09,039
important that we genuinely do not block

00:06:05,440 --> 00:06:11,199
we mean obstruction free if you suspend

00:06:09,039 --> 00:06:12,560
all the other threads but the event

00:06:11,199 --> 00:06:14,800
handling thread the event handling

00:06:12,560 --> 00:06:17,120
thread will complete its task

00:06:14,800 --> 00:06:18,880
and that means that you can't use things

00:06:17,120 --> 00:06:20,400
like mutexes because if another thread

00:06:18,880 --> 00:06:22,880
is not the mutex

00:06:20,400 --> 00:06:23,520
then your event handling thread now will

00:06:22,880 --> 00:06:25,039
have to

00:06:23,520 --> 00:06:27,520
wait for it and if the other threads are

00:06:25,039 --> 00:06:31,600
all suspended then it will wait forever

00:06:27,520 --> 00:06:31,600
and you need to then be using lottery's

00:06:32,400 --> 00:06:35,840
implementations of just about everything

00:06:34,000 --> 00:06:37,600
around around your event handling thread

00:06:35,840 --> 00:06:39,199
that means not free allocators it means

00:06:37,600 --> 00:06:42,400
message queues that are a lot free

00:06:39,199 --> 00:06:43,680
and everything that goes with that so in

00:06:42,400 --> 00:06:47,039
some cases

00:06:43,680 --> 00:06:48,000
you really really need that and in other

00:06:47,039 --> 00:06:51,599
cases

00:06:48,000 --> 00:06:53,280
we just mean no long-term waiting

00:06:51,599 --> 00:06:57,120
no waiting with an indefinite timeout

00:06:53,280 --> 00:07:00,080
but short-term mutex box is okay

00:06:57,120 --> 00:07:00,560
so just now bear in mind in if you're

00:07:00,080 --> 00:07:02,800
thinking

00:07:00,560 --> 00:07:04,639
about this in your application which of

00:07:02,800 --> 00:07:06,880
those cases do you fit in

00:07:04,639 --> 00:07:08,080
have you got a hard real-time

00:07:06,880 --> 00:07:10,080
performance

00:07:08,080 --> 00:07:11,680
you know critical scenario where you

00:07:10,080 --> 00:07:14,160
need obstruction free

00:07:11,680 --> 00:07:17,840
or is it just the long-term blocking

00:07:14,160 --> 00:07:17,840
that you need to avoid

00:07:22,080 --> 00:07:29,360
so that was no

00:07:26,319 --> 00:07:32,000
a quick detour intact

00:07:29,360 --> 00:07:33,840
why we might move to work off the thread

00:07:32,000 --> 00:07:37,039
but obviously the meat of this is

00:07:33,840 --> 00:07:37,039
how are we going to do it

00:07:39,199 --> 00:07:47,680
so there's a myriad of possible ways

00:07:43,360 --> 00:07:49,039
the in some ways the simplest possible

00:07:47,680 --> 00:07:50,479
thing we could do is we could just say

00:07:49,039 --> 00:07:51,680
well let's spawn a new thread for each

00:07:50,479 --> 00:07:53,599
event handle

00:07:51,680 --> 00:07:55,280
every time you want an event spawn a new

00:07:53,599 --> 00:07:57,440
thread then it will do its task then it

00:07:55,280 --> 00:07:59,680
will finish it's not going to

00:07:57,440 --> 00:08:02,000
do that alternatively you can have a

00:07:59,680 --> 00:08:05,919
dedicated background thread

00:08:02,000 --> 00:08:07,120
and you can pass data to that by some

00:08:05,919 --> 00:08:08,639
pre-arranged mechanism

00:08:07,120 --> 00:08:10,319
whether that is there is a block of

00:08:08,639 --> 00:08:11,759
shared memory and you lock a mutex and

00:08:10,319 --> 00:08:14,879
stick some data in there

00:08:11,759 --> 00:08:19,199
and then unlock the mutex

00:08:14,879 --> 00:08:22,560
or is it on the other hand

00:08:19,199 --> 00:08:23,759
that there is um no you are

00:08:22,560 --> 00:08:26,080
your background thread is having a

00:08:23,759 --> 00:08:29,120
message queue and you

00:08:26,080 --> 00:08:29,680
are you know that is obviously a special

00:08:29,120 --> 00:08:32,240
case of

00:08:29,680 --> 00:08:32,800
a of a shared data memory is it's a very

00:08:32,240 --> 00:08:34,959
focused

00:08:32,800 --> 00:08:37,839
message queue and you just and you pass

00:08:34,959 --> 00:08:39,919
messages onto it

00:08:37,839 --> 00:08:41,200
and so there are cases where such a

00:08:39,919 --> 00:08:43,440
dedicated background thread might be

00:08:41,200 --> 00:08:45,279
useful

00:08:43,440 --> 00:08:47,279
alternatively you might not have a

00:08:45,279 --> 00:08:49,920
dedicated thread but have a thread pool

00:08:47,279 --> 00:08:51,839
and so when you when your event comes in

00:08:49,920 --> 00:08:53,279
your event handler

00:08:51,839 --> 00:08:54,800
needs to deal with it it knows there's a

00:08:53,279 --> 00:08:57,839
lengthy chance to do it submits that

00:08:54,800 --> 00:08:57,839
task to the thread pool

00:08:59,839 --> 00:09:04,000
and then finally there might be not just

00:09:02,240 --> 00:09:05,519
a generic threadful but various special

00:09:04,000 --> 00:09:06,959
purpose executives that you might be

00:09:05,519 --> 00:09:09,040
able to use

00:09:06,959 --> 00:09:10,320
know if it's a number crunching task you

00:09:09,040 --> 00:09:13,360
might delegate it

00:09:10,320 --> 00:09:14,080
to a gpu executive for example if

00:09:13,360 --> 00:09:16,959
there's

00:09:14,080 --> 00:09:20,560
if you if your system has a gpu that

00:09:16,959 --> 00:09:20,560
that you can use for for that purpose

00:09:20,839 --> 00:09:26,399
so again the common factor

00:09:24,320 --> 00:09:27,680
of all these things is that we are

00:09:26,399 --> 00:09:30,880
moving the

00:09:27,680 --> 00:09:32,560
work off the current thread so that

00:09:30,880 --> 00:09:34,560
the event handling thread can get back

00:09:32,560 --> 00:09:37,200
to doing what's really important

00:09:34,560 --> 00:09:38,480
which is handling the events from the

00:09:37,200 --> 00:09:43,120
external

00:09:38,480 --> 00:09:44,240
systems so that the

00:09:43,120 --> 00:09:45,519
thing whatever it is that you're

00:09:44,240 --> 00:09:46,640
interacting with whether it's the

00:09:45,519 --> 00:09:50,800
operating system

00:09:46,640 --> 00:09:53,839
with the ui or network clients

00:09:50,800 --> 00:09:57,200
they are seeing timely responses

00:09:53,839 --> 00:10:00,240
and and

00:09:57,200 --> 00:10:00,640
making sure that you will respond no you

00:10:00,240 --> 00:10:05,839
are

00:10:00,640 --> 00:10:05,839
processing the events as they come in

00:10:09,040 --> 00:10:12,560
so if you're spawning new threads

00:10:11,200 --> 00:10:14,320
there's loads of ways you can do it

00:10:12,560 --> 00:10:15,600
no standard ways we've got standard

00:10:14,320 --> 00:10:18,480
thread we've got in c

00:10:15,600 --> 00:10:20,640
plus 20 we've got standard j thread

00:10:18,480 --> 00:10:22,640
we've got

00:10:20,640 --> 00:10:24,480
standard async and actually there's a

00:10:22,640 --> 00:10:25,920
typo though if you can standard launch

00:10:24,480 --> 00:10:28,399
sync then it really really

00:10:25,920 --> 00:10:30,160
isn't isn't the thread but if you um

00:10:28,399 --> 00:10:32,959
watch async

00:10:30,160 --> 00:10:34,720
for starting a new a new thread and then

00:10:32,959 --> 00:10:36,640
platform specific apis

00:10:34,720 --> 00:10:38,240
you could use the windows you know begin

00:10:36,640 --> 00:10:41,200
thread or create thread

00:10:38,240 --> 00:10:42,480
apis you could use um posix pthread

00:10:41,200 --> 00:10:44,399
create or

00:10:42,480 --> 00:10:47,839
anything again relating to whatever

00:10:44,399 --> 00:10:47,839
platform you're happy to be working on

00:10:48,720 --> 00:10:53,040
but they all share the same the same

00:10:51,519 --> 00:10:57,680
fundamental problem

00:10:53,040 --> 00:11:00,959
is that you are spawning a new thread

00:10:57,680 --> 00:11:04,000
and if you detach the thread

00:11:00,959 --> 00:11:04,000
then you now have

00:11:04,079 --> 00:11:13,839
no there's nothing there that's going to

00:11:08,800 --> 00:11:16,079
directly relate

00:11:13,839 --> 00:11:17,200
know when it's going to finish how long

00:11:16,079 --> 00:11:19,839
it's going to be running

00:11:17,200 --> 00:11:20,480
no your your event handler now has has

00:11:19,839 --> 00:11:22,240
nothing

00:11:20,480 --> 00:11:25,040
to tie it back unless you put something

00:11:22,240 --> 00:11:25,040
specific in there

00:11:25,600 --> 00:11:29,040
on the other hand if you try and join

00:11:27,279 --> 00:11:31,440
the thread then somehow you've got to

00:11:29,040 --> 00:11:34,880
keep the thread handle around

00:11:31,440 --> 00:11:34,880
and know when to join

00:11:39,920 --> 00:11:44,480
from that perspective then standard

00:11:42,160 --> 00:11:46,000
thread and standard j threads

00:11:44,480 --> 00:11:47,600
they don't give you an there's not no

00:11:46,000 --> 00:11:51,040
difference there really a j thread just

00:11:47,600 --> 00:11:54,800
provides a slightly nicer interface

00:11:51,040 --> 00:11:57,680
so if you're going to join with it then

00:11:54,800 --> 00:12:00,000
you construct your j thread to process

00:11:57,680 --> 00:12:02,720
the events and then you

00:12:00,000 --> 00:12:04,399
push your thread back on onto onto this

00:12:02,720 --> 00:12:05,040
list of pending threads threads i've

00:12:04,399 --> 00:12:10,079
started

00:12:05,040 --> 00:12:13,120
but i need to join with at some point

00:12:10,079 --> 00:12:17,839
the fundamental issue around that

00:12:13,120 --> 00:12:20,399
is you know at what point

00:12:17,839 --> 00:12:24,880
are you going to join how are you going

00:12:20,399 --> 00:12:26,720
to know when to join

00:12:24,880 --> 00:12:28,399
because there is no reasonable way to

00:12:26,720 --> 00:12:30,079
test if any of the pending

00:12:28,399 --> 00:12:31,600
and entries impending threads can be

00:12:30,079 --> 00:12:34,880
joined

00:12:31,600 --> 00:12:36,800
so now if you com

00:12:34,880 --> 00:12:38,480
if your if your event handler thread

00:12:36,800 --> 00:12:40,639
definitely can't then

00:12:38,480 --> 00:12:41,920
at any point you can't call join on any

00:12:40,639 --> 00:12:43,040
of your threads unless you've put

00:12:41,920 --> 00:12:45,760
something ex

00:12:43,040 --> 00:12:47,839
explicit an external event that you're

00:12:45,760 --> 00:12:52,399
then passing back to say yes this thread

00:12:47,839 --> 00:12:54,480
has now finished

00:12:52,399 --> 00:12:56,160
and if you but on the other hand if you

00:12:54,480 --> 00:12:57,120
leave it to the end of your application

00:12:56,160 --> 00:13:00,000
then you've just

00:12:57,120 --> 00:13:01,440
got all these fast numbers or threads

00:13:00,000 --> 00:13:02,800
because there's going to be no presume

00:13:01,440 --> 00:13:03,519
your application is long running and

00:13:02,800 --> 00:13:05,519
it's going to have

00:13:03,519 --> 00:13:08,880
handle a lot of events in its lifetime

00:13:05,519 --> 00:13:08,880
then spawning all these threads

00:13:09,920 --> 00:13:13,120
then they're just going to accumulate

00:13:11,839 --> 00:13:15,600
and eventually run out of system

00:13:13,120 --> 00:13:15,600
resources

00:13:17,279 --> 00:13:22,959
so you really don't no

00:13:21,279 --> 00:13:24,720
there's a there's a lot of danger there

00:13:22,959 --> 00:13:25,360
if what do you do with these pending

00:13:24,720 --> 00:13:26,959
threads

00:13:25,360 --> 00:13:29,200
how do we gather them up how do we join

00:13:26,959 --> 00:13:29,200
with them

00:13:30,959 --> 00:13:38,079
so if we use async then

00:13:35,279 --> 00:13:39,440
it's a little bit better because we can

00:13:38,079 --> 00:13:41,600
actually check to see whether the

00:13:39,440 --> 00:13:44,639
futures are ready

00:13:41,600 --> 00:13:47,839
so again on our handle event

00:13:44,639 --> 00:13:50,720
task we can do our launch our new thread

00:13:47,839 --> 00:13:54,079
with standalating launch async

00:13:50,720 --> 00:13:55,839
and we can put that future on our

00:13:54,079 --> 00:13:57,279
pending threads list which they're now

00:13:55,839 --> 00:14:00,000
not just raw thread handles their

00:13:57,279 --> 00:14:00,000
standard features

00:14:01,440 --> 00:14:05,279
and so on that front it's exactly the

00:14:03,040 --> 00:14:05,279
same

00:14:05,519 --> 00:14:09,360
but on the other hand we can we now have

00:14:08,560 --> 00:14:11,680
the ability

00:14:09,360 --> 00:14:13,440
to check whether these are ready we

00:14:11,680 --> 00:14:16,480
can't can iterate through

00:14:13,440 --> 00:14:19,760
our pending threads list and we can

00:14:16,480 --> 00:14:22,880
poll each future to see if it's ready

00:14:19,760 --> 00:14:25,440
and if it is then we can erase it from

00:14:22,880 --> 00:14:25,440
from the list

00:14:27,360 --> 00:14:32,639
now obviously if you accumulate large

00:14:31,199 --> 00:14:35,040
numbers of events

00:14:32,639 --> 00:14:35,920
and not then you have large numbers of

00:14:35,040 --> 00:14:39,600
threads

00:14:35,920 --> 00:14:41,440
and so yes you can do this polling

00:14:39,600 --> 00:14:42,800
but somebody's got to do it and it's

00:14:41,440 --> 00:14:44,079
going to be a time consuming thing

00:14:42,800 --> 00:14:45,440
because you know if you end up with

00:14:44,079 --> 00:14:48,000
hundreds of features there

00:14:45,440 --> 00:14:49,199
checking them all well how often are you

00:14:48,000 --> 00:14:51,120
going to check them and

00:14:49,199 --> 00:14:52,240
know how how it's going to take a while

00:14:51,120 --> 00:14:53,519
for them to

00:14:52,240 --> 00:14:55,360
scan through them all to see if they've

00:14:53,519 --> 00:14:56,720
all done and if if

00:14:55,360 --> 00:14:58,320
most of the time they're not going to be

00:14:56,720 --> 00:14:59,360
done then you're just wasting a lot of

00:14:58,320 --> 00:15:00,800
time checking

00:14:59,360 --> 00:15:02,480
so what you really want is some form of

00:15:00,800 --> 00:15:07,040
notification

00:15:02,480 --> 00:15:12,720
and we just don't have that with

00:15:07,040 --> 00:15:15,760
these facilities and so this is still

00:15:12,720 --> 00:15:19,839
nasty if you have a lot of events

00:15:15,760 --> 00:15:22,720
you know you didn't still end up

00:15:19,839 --> 00:15:23,600
um spoiling a lot of threads and the

00:15:22,720 --> 00:15:27,839
list

00:15:23,600 --> 00:15:27,839
just gets launched

00:15:28,720 --> 00:15:32,959
so fundamentally i wanted to introduce

00:15:31,440 --> 00:15:34,560
it because

00:15:32,959 --> 00:15:36,000
it's something that in some sense it

00:15:34,560 --> 00:15:37,600
seems simple

00:15:36,000 --> 00:15:40,000
getting the work off my thread but

00:15:37,600 --> 00:15:55,839
really spawning a new thread for every

00:15:40,000 --> 00:15:55,839
task is fundamentally a bad idea

00:15:58,160 --> 00:16:03,920
a dedicated thread on the other hand can

00:16:00,800 --> 00:16:03,920
be a reasonable idea

00:16:04,880 --> 00:16:08,639
so the work flow that you might go

00:16:07,120 --> 00:16:11,839
through is that at some points you're

00:16:08,639 --> 00:16:15,440
going to start your dedicated threat

00:16:11,839 --> 00:16:19,120
this might be in response to an event no

00:16:15,440 --> 00:16:20,480
we are we have an event that something

00:16:19,120 --> 00:16:22,240
somebody clicks a button that says we're

00:16:20,480 --> 00:16:24,160
going to start this operation and then

00:16:22,240 --> 00:16:25,519
there will be things to follow and now a

00:16:24,160 --> 00:16:26,639
new window in your application it's got

00:16:25,519 --> 00:16:29,199
new events to handle

00:16:26,639 --> 00:16:30,560
new things it's going to do and so we

00:16:29,199 --> 00:16:33,519
create our

00:16:30,560 --> 00:16:33,519
dedicated thread

00:16:34,000 --> 00:16:37,680
having once the events the thread is

00:16:36,079 --> 00:16:39,440
created at some point your event handler

00:16:37,680 --> 00:16:42,000
is going to receive an event

00:16:39,440 --> 00:16:42,880
and rather than processing itself it

00:16:42,000 --> 00:16:46,399
then

00:16:42,880 --> 00:16:49,040
repost that event as as a message

00:16:46,399 --> 00:16:50,399
you know in some you know to the

00:16:49,040 --> 00:16:52,720
dedicated thread

00:16:50,399 --> 00:16:54,240
either directly using a message cube for

00:16:52,720 --> 00:16:57,680
that form of structure

00:16:54,240 --> 00:17:00,800
or alternatively

00:16:57,680 --> 00:17:04,160
for um

00:17:00,800 --> 00:17:05,839
by locking at mutex and modifying some

00:17:04,160 --> 00:17:08,240
shared data or something like that

00:17:05,839 --> 00:17:09,839
but whichever way does it somehow it

00:17:08,240 --> 00:17:10,559
passes the data that the event has

00:17:09,839 --> 00:17:13,679
happened

00:17:10,559 --> 00:17:14,720
onto the background thread and the event

00:17:13,679 --> 00:17:18,720
handler

00:17:14,720 --> 00:17:22,240
is then done it can return to his caller

00:17:18,720 --> 00:17:22,240
ready to receive a new event

00:17:23,120 --> 00:17:27,120
and then that that little cycle steps

00:17:26,319 --> 00:17:30,079
two three four

00:17:27,120 --> 00:17:30,079
because then gonna repeat

00:17:30,160 --> 00:17:34,960
but the crucial part then is that while

00:17:32,000 --> 00:17:37,039
that is repeating at some point later

00:17:34,960 --> 00:17:38,559
hopefully not too much later the

00:17:37,039 --> 00:17:39,440
dedicated thread is going to receive

00:17:38,559 --> 00:17:41,360
this message and

00:17:39,440 --> 00:17:42,559
that in turn is going to process it now

00:17:41,360 --> 00:17:44,640
at this point

00:17:42,559 --> 00:17:47,039
then provided that overall our system

00:17:44,640 --> 00:17:48,000
does have enough computing resources to

00:17:47,039 --> 00:17:49,600
deal with

00:17:48,000 --> 00:17:51,039
the background processing and the event

00:17:49,600 --> 00:17:52,600
handling

00:17:51,039 --> 00:17:54,799
then the

00:17:52,600 --> 00:17:57,760
[Music]

00:17:54,799 --> 00:17:58,480
time it takes to process it is so much

00:17:57,760 --> 00:18:01,200
less

00:17:58,480 --> 00:18:03,120
of an issue obviously we want things to

00:18:01,200 --> 00:18:05,600
be processed as fast as possible

00:18:03,120 --> 00:18:08,080
but we don't need to complete our

00:18:05,600 --> 00:18:08,080
processing

00:18:10,799 --> 00:18:15,840
any no in any particular time frame

00:18:18,480 --> 00:18:21,120
and so yes

00:18:22,320 --> 00:18:28,000
you might need to somehow pass the

00:18:25,200 --> 00:18:31,039
response back from your dedicated thread

00:18:28,000 --> 00:18:32,960
to the event handler and that is

00:18:31,039 --> 00:18:34,400
something that we are going to look at

00:18:32,960 --> 00:18:38,880
later

00:18:34,400 --> 00:18:40,720
um but

00:18:38,880 --> 00:18:42,320
from this point at this point we're just

00:18:40,720 --> 00:18:44,080
looking at how we get the data

00:18:42,320 --> 00:18:47,280
to our dedicated threat so we post that

00:18:44,080 --> 00:18:48,480
message and sometimes process it

00:18:47,280 --> 00:18:50,000
and then when it's done it's a little

00:18:48,480 --> 00:18:53,520
bit processing for that message it's

00:18:50,000 --> 00:18:53,520
then going to wait for more messages to

00:18:54,840 --> 00:18:57,840
process

00:18:58,240 --> 00:19:01,600
and and then eventually you know when

00:19:01,039 --> 00:19:03,520
it's done

00:19:01,600 --> 00:19:04,640
then the dedicated thread is going to be

00:19:03,520 --> 00:19:06,480
destroyed at the end

00:19:04,640 --> 00:19:07,919
maybe you close the window maybe you've

00:19:06,480 --> 00:19:09,919
finished the long running

00:19:07,919 --> 00:19:11,039
operation that is that it's done but

00:19:09,919 --> 00:19:14,000
whatever

00:19:11,039 --> 00:19:15,679
eventually it will come for a natural

00:19:14,000 --> 00:19:18,000
conclusion and we will destroy the

00:19:15,679 --> 00:19:18,000
thread

00:19:23,280 --> 00:19:30,160
so there are some downsides to this

00:19:26,400 --> 00:19:32,400
it's not an outright bad idea like

00:19:30,160 --> 00:19:34,880
having just spawning new threads every

00:19:32,400 --> 00:19:34,880
other minute

00:19:34,960 --> 00:19:38,559
every other millisecond there's quite

00:19:36,400 --> 00:19:39,679
possibly likely if you've got a lot of

00:19:38,559 --> 00:19:42,080
incoming messages

00:19:39,679 --> 00:19:43,360
well so the first downside is that it is

00:19:42,080 --> 00:19:44,799
a long list thread and it's going to

00:19:43,360 --> 00:19:46,320
consume resources

00:19:44,799 --> 00:19:48,080
just in terms of memory in terms of

00:19:46,320 --> 00:19:51,840
processing

00:19:48,080 --> 00:19:54,960
and it consumes those resources

00:19:51,840 --> 00:19:56,799
even when it's not actually doing any

00:19:54,960 --> 00:19:58,080
no there's no current events coming in

00:19:56,799 --> 00:19:58,640
to process it it's still going to sit

00:19:58,080 --> 00:20:02,080
there

00:19:58,640 --> 00:20:03,679
how the the memory for the thread stack

00:20:02,080 --> 00:20:05,440
and the thread local data structures and

00:20:03,679 --> 00:20:06,080
whatever else is just fixed and

00:20:05,440 --> 00:20:09,280
allocated

00:20:06,080 --> 00:20:11,440
and it's going to sit there and so

00:20:09,280 --> 00:20:13,760
that might be an issue it might not you

00:20:11,440 --> 00:20:17,360
might have loads of memory

00:20:13,760 --> 00:20:20,240
and the and so that

00:20:17,360 --> 00:20:21,600
and the the number of threads in your

00:20:20,240 --> 00:20:22,799
application is small enough that you

00:20:21,600 --> 00:20:23,360
don't have to worry about running out of

00:20:22,799 --> 00:20:25,200
thread

00:20:23,360 --> 00:20:27,280
or thread handles you don't and that

00:20:25,200 --> 00:20:28,960
sort of thing and so

00:20:27,280 --> 00:20:31,840
you might have to worry but it's there

00:20:28,960 --> 00:20:35,600
there is a persistent cost for the whole

00:20:31,840 --> 00:20:39,039
time the dedicated threat exists

00:20:35,600 --> 00:20:41,600
and then the handling of the event is

00:20:39,039 --> 00:20:45,200
now disconnected from the event itself

00:20:41,600 --> 00:20:47,679
and so depending on how easily

00:20:45,200 --> 00:20:48,480
you know and how quickly the background

00:20:47,679 --> 00:20:51,039
thread

00:20:48,480 --> 00:20:53,520
checks its message queue and how timely

00:20:51,039 --> 00:20:56,720
it is then you might find that the

00:20:53,520 --> 00:20:59,200
the time between the incoming messages

00:20:56,720 --> 00:21:01,360
being processed you know is there might

00:20:59,200 --> 00:21:01,360
be

00:21:01,520 --> 00:21:04,480
there might be several milliseconds

00:21:02,799 --> 00:21:05,200
between the incoming event being

00:21:04,480 --> 00:21:06,799
processed

00:21:05,200 --> 00:21:10,240
being received by the event handling

00:21:06,799 --> 00:21:14,000
thread and then being processed by the

00:21:10,240 --> 00:21:17,280
dedicated background thread and

00:21:14,000 --> 00:21:19,360
depending on your application that might

00:21:17,280 --> 00:21:21,039
be an issue

00:21:19,360 --> 00:21:22,480
but it's something that you need to be

00:21:21,039 --> 00:21:26,640
aware of

00:21:22,480 --> 00:21:26,640
just because there is going to be that

00:21:28,840 --> 00:21:32,480
disconnect

00:21:30,480 --> 00:21:33,840
and then by its very nature we've got a

00:21:32,480 --> 00:21:35,520
dedicated single thread

00:21:33,840 --> 00:21:37,600
and so therefore there is no parallel

00:21:35,520 --> 00:21:38,320
processing it's all very well if you've

00:21:37,600 --> 00:21:42,799
got a nice

00:21:38,320 --> 00:21:45,200
name hefty server with 128 core cpu

00:21:42,799 --> 00:21:47,520
but you've got one event thread and then

00:21:45,200 --> 00:21:49,120
one dedicated processing thread

00:21:47,520 --> 00:21:52,159
then that's not going to do you any good

00:21:49,120 --> 00:21:55,840
and the other 126 threads are

00:21:52,159 --> 00:21:55,840
just left to the os to decide what to do

00:21:56,240 --> 00:22:00,400
so you need to if you're wanting

00:21:58,799 --> 00:22:03,760
parallel processing you need to do more

00:22:00,400 --> 00:22:03,760
than just have a dedicated thread

00:22:06,640 --> 00:22:13,280
it's not all downside but there are

00:22:10,000 --> 00:22:16,799
upsides and the first of which is a nice

00:22:13,280 --> 00:22:19,120
and very simple upside

00:22:16,799 --> 00:22:20,320
is that the events are handled in the

00:22:19,120 --> 00:22:21,760
same order

00:22:20,320 --> 00:22:24,080
as they arrive at the initial event

00:22:21,760 --> 00:22:24,080
handle

00:22:25,039 --> 00:22:30,400
you and then the event comes in

00:22:28,880 --> 00:22:32,480
the event handler passes puts it on the

00:22:30,400 --> 00:22:35,039
message queue

00:22:32,480 --> 00:22:36,240
and then and then second event comes in

00:22:35,039 --> 00:22:37,440
and then handler puts that on the back

00:22:36,240 --> 00:22:39,440
of the message queue the message here

00:22:37,440 --> 00:22:41,280
now has two

00:22:39,440 --> 00:22:43,520
two messages and they get processed in

00:22:41,280 --> 00:22:45,760
order by your background thread

00:22:43,520 --> 00:22:47,679
this can be of huge benefit from the

00:22:45,760 --> 00:22:50,320
point of view of analyzing how your

00:22:47,679 --> 00:22:55,760
system is going to respond

00:22:50,320 --> 00:22:59,600
having events processed out of order

00:22:55,760 --> 00:23:02,880
now there's has a very large scope

00:22:59,600 --> 00:23:02,880
for making things go wrong

00:23:04,400 --> 00:23:09,919
even you know little things so

00:23:08,320 --> 00:23:12,159
i'm sure we've all experienced

00:23:09,919 --> 00:23:14,480
applications where

00:23:12,159 --> 00:23:15,919
you click on a button and then and

00:23:14,480 --> 00:23:16,320
nothing happens and then you click on a

00:23:15,919 --> 00:23:17,919
button

00:23:16,320 --> 00:23:20,080
and the second button or maybe the same

00:23:17,919 --> 00:23:20,480
button again then the window gets popped

00:23:20,080 --> 00:23:22,559
up

00:23:20,480 --> 00:23:24,400
and then your button click now gets

00:23:22,559 --> 00:23:26,720
redirected to the new window

00:23:24,400 --> 00:23:28,480
and even even though the window wasn't

00:23:26,720 --> 00:23:30,880
shown at the point where you clicked

00:23:28,480 --> 00:23:33,440
you know then so the handling the

00:23:30,880 --> 00:23:35,360
ordering of the window display and the

00:23:33,440 --> 00:23:37,120
event and the handling of the button

00:23:35,360 --> 00:23:40,320
event isn't is not

00:23:37,120 --> 00:23:41,679
maintained and so you need to be

00:23:40,320 --> 00:23:43,360
you know make sure that that sort of

00:23:41,679 --> 00:23:46,480
thing is happening in order

00:23:43,360 --> 00:23:48,000
and the

00:23:46,480 --> 00:23:50,000
you know you you wouldn't be want to be

00:23:48,000 --> 00:23:51,520
typing and find that they know the

00:23:50,000 --> 00:23:53,760
letters come out in a different order so

00:23:51,520 --> 00:23:55,919
you press your keys and then they need

00:23:53,760 --> 00:23:57,440
to be processed in order in many

00:23:55,919 --> 00:24:00,559
applications

00:23:57,440 --> 00:24:03,840
otherwise everything just get confused

00:24:00,559 --> 00:24:08,799
and so having a single dedicated

00:24:03,840 --> 00:24:08,799
by its very nature tends to enforce that

00:24:10,080 --> 00:24:13,279
and then if we say that the dedicated

00:24:11,760 --> 00:24:14,960
thread only communicates with the

00:24:13,279 --> 00:24:17,440
outside world via the messages

00:24:14,960 --> 00:24:18,000
so it receives messages from our event

00:24:17,440 --> 00:24:19,679
right

00:24:18,000 --> 00:24:21,200
and then potentially passes messages out

00:24:19,679 --> 00:24:24,000
again

00:24:21,200 --> 00:24:24,720
then it becomes very very easy to design

00:24:24,000 --> 00:24:27,600
and test

00:24:24,720 --> 00:24:29,120
comparatively in the sense that a whole

00:24:27,600 --> 00:24:32,480
application is multi-threaded

00:24:29,120 --> 00:24:36,240
but this is a single thread with

00:24:32,480 --> 00:24:37,840
a message queue so you can design it

00:24:36,240 --> 00:24:40,640
the same way you would anything else

00:24:37,840 --> 00:24:44,640
that's got a single thread

00:24:40,640 --> 00:24:47,679
you have you can use state machines

00:24:44,640 --> 00:24:50,159
and so so your incoming messages

00:24:47,679 --> 00:24:51,520
trigger state transitions if you find

00:24:50,159 --> 00:24:53,760
that is an easy way of structuring

00:24:51,520 --> 00:24:53,760
things

00:24:53,840 --> 00:25:00,480
alternatively you could you don't have

00:24:57,200 --> 00:25:02,640
to use a state machine but you can like

00:25:00,480 --> 00:25:05,360
you can build your little parts of the

00:25:02,640 --> 00:25:07,679
system and you can

00:25:05,360 --> 00:25:09,919
you know fire in a sequence of messages

00:25:07,679 --> 00:25:12,480
and then check that the appropriate

00:25:09,919 --> 00:25:14,400
no side effects actually from the from

00:25:12,480 --> 00:25:16,080
the thread itself in terms of whatever

00:25:14,400 --> 00:25:17,760
other processing it does and then any

00:25:16,080 --> 00:25:19,679
other messages that it sends out

00:25:17,760 --> 00:25:20,880
and verify that those are all correct

00:25:19,679 --> 00:25:23,360
and it

00:25:20,880 --> 00:25:25,279
in the whole system your test can now

00:25:23,360 --> 00:25:26,080
consist of just the single one dedicated

00:25:25,279 --> 00:25:27,520
thread

00:25:26,080 --> 00:25:29,679
and this message key which you can

00:25:27,520 --> 00:25:32,799
pre-pa pre-load with messages

00:25:29,679 --> 00:25:32,799
from from your tests

00:25:33,039 --> 00:25:37,279
so that does make it substantially

00:25:35,520 --> 00:25:40,640
easier

00:25:37,279 --> 00:25:41,440
and then if you have when you're closing

00:25:40,640 --> 00:25:44,400
your application

00:25:41,440 --> 00:25:45,039
somebody closes the window the web

00:25:44,400 --> 00:25:47,520
browser

00:25:45,039 --> 00:25:49,440
closes the connection or whatever then

00:25:47,520 --> 00:25:50,559
if you have outstanding tasks then it's

00:25:49,440 --> 00:25:53,440
that easy to

00:25:50,559 --> 00:25:54,320
to clean them all up you just shut down

00:25:53,440 --> 00:25:56,240
the threads and

00:25:54,320 --> 00:25:57,919
abandon anything left in the message

00:25:56,240 --> 00:25:59,679
queue

00:25:57,919 --> 00:26:02,799
so that can be a very easy thing you

00:25:59,679 --> 00:26:02,799
know from the point of view of

00:26:03,440 --> 00:26:11,840
finish cancelling an incomplete task

00:26:23,440 --> 00:26:27,520
but if dedicated processing isn't an

00:26:25,600 --> 00:26:30,400
ideal fit for our application

00:26:27,520 --> 00:26:31,120
then an alternative is to use a thread

00:26:30,400 --> 00:26:32,720
pool

00:26:31,120 --> 00:26:35,200
and so we don't have just one thread we

00:26:32,720 --> 00:26:35,200
have many

00:26:35,840 --> 00:26:40,080
and then the system of processing at the

00:26:38,799 --> 00:26:41,679
thread go after

00:26:40,080 --> 00:26:43,440
events goes very much the same you

00:26:41,679 --> 00:26:44,080
create the thread pool you receive an

00:26:43,440 --> 00:26:46,640
event

00:26:44,080 --> 00:26:47,279
you post as a task to the thread pool

00:26:46,640 --> 00:26:49,600
whereas

00:26:47,279 --> 00:26:51,360
with a dedicated thread then we would

00:26:49,600 --> 00:26:52,880
tend to have some form of message

00:26:51,360 --> 00:26:54,720
and then the thread itself would know

00:26:52,880 --> 00:26:55,360
what to do with that message when you're

00:26:54,720 --> 00:26:57,679
posting

00:26:55,360 --> 00:26:58,880
posting through a thread call a thread

00:26:57,679 --> 00:26:59,360
pool doesn't know what to do with

00:26:58,880 --> 00:27:00,640
anything so

00:26:59,360 --> 00:27:02,880
instead of giving a message you give it

00:27:00,640 --> 00:27:04,880
a task this is what i want you to do

00:27:02,880 --> 00:27:06,720
here not only here is the data but here

00:27:04,880 --> 00:27:08,880
is a function that i'm actually going to

00:27:06,720 --> 00:27:08,880
run

00:27:10,159 --> 00:27:15,360
and then the event handler returns back

00:27:12,880 --> 00:27:17,360
ready for receiving new events

00:27:15,360 --> 00:27:18,960
so the structure here is very much the

00:27:17,360 --> 00:27:22,080
same

00:27:18,960 --> 00:27:23,760
no but not just

00:27:22,080 --> 00:27:25,279
the dedicated thread but one of the

00:27:23,760 --> 00:27:25,760
threads from the thread will pick up our

00:27:25,279 --> 00:27:28,720
task

00:27:25,760 --> 00:27:28,720
we don't know which one

00:27:29,120 --> 00:27:34,320
and that thread will then wait for a new

00:27:30,480 --> 00:27:36,000
task of course

00:27:34,320 --> 00:27:37,039
if we've got a thread pull it's got the

00:27:36,000 --> 00:27:38,480
reason we've got a thread pull is

00:27:37,039 --> 00:27:42,000
because it's got multiple threads

00:27:38,480 --> 00:27:43,360
and so now the event handlers might be

00:27:42,000 --> 00:27:45,039
posting multiple tasks

00:27:43,360 --> 00:27:49,039
and then we they might all be picked up

00:27:45,039 --> 00:27:50,559
and now we're running simultaneously

00:27:49,039 --> 00:27:53,600
and then of course eventually the thread

00:27:50,559 --> 00:27:53,600
pool is going to be destroyed

00:27:54,240 --> 00:27:59,440
so it's a very similar overview but with

00:27:56,480 --> 00:27:59,440
some crucial differences

00:28:00,159 --> 00:28:07,200
well i'll see they are

00:28:03,360 --> 00:28:08,640
upside to thread pools is that our tasks

00:28:07,200 --> 00:28:11,840
are small

00:28:08,640 --> 00:28:13,840
now you've written your tiny little

00:28:11,840 --> 00:28:16,799
tasks

00:28:13,840 --> 00:28:18,320
and you make them self-contained this is

00:28:16,799 --> 00:28:19,600
what i want to do here is a little bit

00:28:18,320 --> 00:28:22,320
of data i got from the event

00:28:19,600 --> 00:28:23,200
this is the processing i want to do this

00:28:22,320 --> 00:28:25,520
is the state

00:28:23,200 --> 00:28:26,799
of the rest of the application that i'm

00:28:25,520 --> 00:28:29,760
going to work in

00:28:26,799 --> 00:28:30,000
and so you can design your task and test

00:28:29,760 --> 00:28:33,120
it

00:28:30,000 --> 00:28:33,120
and it's quite straightforward

00:28:33,679 --> 00:28:38,480
and the natural aspect of thread pools

00:28:37,360 --> 00:28:39,679
is that the number of threads is

00:28:38,480 --> 00:28:41,279
scalable

00:28:39,679 --> 00:28:43,760
you you're running on a four core

00:28:41,279 --> 00:28:44,640
machine then mostly you're going to run

00:28:43,760 --> 00:28:46,480
you know

00:28:44,640 --> 00:28:48,480
approximately four threads you might run

00:28:46,480 --> 00:28:50,720
a bit more or a bit less

00:28:48,480 --> 00:28:51,600
just depending what else is going on in

00:28:50,720 --> 00:28:52,960
your system

00:28:51,600 --> 00:28:55,440
but you're going to be approximately

00:28:52,960 --> 00:28:56,080
that when you if you start moving to 128

00:28:55,440 --> 00:29:00,960
cores

00:28:56,080 --> 00:29:02,960
or a serious server with 1024 cores

00:29:00,960 --> 00:29:05,440
then you scale up the number of threads

00:29:02,960 --> 00:29:08,640
in your thread pool

00:29:05,440 --> 00:29:12,640
and it just naturally expands

00:29:08,640 --> 00:29:16,159
to divide the work up between

00:29:12,640 --> 00:29:16,159
the event with the available hardware

00:29:18,480 --> 00:29:23,520
and then the threads are not dedicated

00:29:21,919 --> 00:29:25,360
it's just a generic thread pool you can

00:29:23,520 --> 00:29:26,480
now use this share it with the rest of

00:29:25,360 --> 00:29:29,039
your application

00:29:26,480 --> 00:29:29,919
and so every part of your application

00:29:29,039 --> 00:29:33,039
can post

00:29:29,919 --> 00:29:33,760
tasks onto the thread pool and the

00:29:33,039 --> 00:29:36,000
thread pool

00:29:33,760 --> 00:29:38,840
deals with allocating those tasks to

00:29:36,000 --> 00:29:41,840
threads and making sure that everything

00:29:38,840 --> 00:29:41,840
runs

00:29:43,200 --> 00:29:47,039
see they're not all upsides there's

00:29:44,799 --> 00:29:48,559
downsides to thread rules

00:29:47,039 --> 00:29:50,559
and the first of which is that your

00:29:48,559 --> 00:29:53,440
tasks are run in an arbitrary order

00:29:50,559 --> 00:29:55,360
as they are picked up by the thread pool

00:29:53,440 --> 00:29:58,880
there is

00:29:55,360 --> 00:29:58,880
nothing that you know

00:29:59,039 --> 00:30:02,880
nothing inherent in the way that thread

00:30:00,960 --> 00:30:06,320
pools work that are going to specify

00:30:02,880 --> 00:30:09,200
your tasks running in a defined order

00:30:06,320 --> 00:30:10,000
unless you put in something specific

00:30:09,200 --> 00:30:13,520
mechanism

00:30:10,000 --> 00:30:14,640
to fully enforce that so you post three

00:30:13,520 --> 00:30:17,520
messages

00:30:14,640 --> 00:30:18,480
no post three tasks on your thread pool

00:30:17,520 --> 00:30:20,320
task queue

00:30:18,480 --> 00:30:22,559
and then they might all be picked up all

00:30:20,320 --> 00:30:24,320
three by separate threads

00:30:22,559 --> 00:30:25,679
alternatively you might find that one of

00:30:24,320 --> 00:30:27,039
them goes to a thread that's currently

00:30:25,679 --> 00:30:29,520
busy and the other and then

00:30:27,039 --> 00:30:32,480
second and third get picked up by by

00:30:29,520 --> 00:30:34,159
another thread and they get run first

00:30:32,480 --> 00:30:36,159
and then the first one gets delayed so

00:30:34,159 --> 00:30:38,480
there's there's a lot of scope for how

00:30:36,159 --> 00:30:40,880
the the ordering and if you gin and it's

00:30:38,480 --> 00:30:42,399
a general thing if you just submit tasks

00:30:40,880 --> 00:30:45,039
to a thread pool without anything

00:30:42,399 --> 00:30:50,000
specific in there to constrain or drink

00:30:45,039 --> 00:30:52,000
they will be run in an arch order

00:30:50,000 --> 00:30:53,360
our event handling is still disconnected

00:30:52,000 --> 00:30:55,679
from the event

00:30:53,360 --> 00:30:58,159
fundamentally there's not a lot we can

00:30:55,679 --> 00:31:01,360
do about this as a problem

00:30:58,159 --> 00:31:02,000
because that's by getting it off the

00:31:01,360 --> 00:31:04,000
main

00:31:02,000 --> 00:31:05,200
main event thread onto the background

00:31:04,000 --> 00:31:08,320
thread we've

00:31:05,200 --> 00:31:08,320
enforced that disconnect

00:31:11,360 --> 00:31:14,480
and not only a task to run an arbitrary

00:31:13,360 --> 00:31:17,039
order

00:31:14,480 --> 00:31:18,640
but if our thread pool is going to live

00:31:17,039 --> 00:31:20,399
up to its name and have multiple threads

00:31:18,640 --> 00:31:22,000
then our tasks may indeed run

00:31:20,399 --> 00:31:25,200
concurrently

00:31:22,000 --> 00:31:27,120
and that means that if they operate on

00:31:25,200 --> 00:31:28,799
any form of shared state

00:31:27,120 --> 00:31:31,200
we need to verify that their

00:31:28,799 --> 00:31:34,240
interactions

00:31:31,200 --> 00:31:37,679
actually work as intended so

00:31:34,240 --> 00:31:39,200
our our testing though we might have

00:31:37,679 --> 00:31:42,320
thought that our testing could be done

00:31:39,200 --> 00:31:43,760
on purely simple individual tasks we do

00:31:42,320 --> 00:31:46,159
have to make sure

00:31:43,760 --> 00:31:47,679
that if those tasks interact with shared

00:31:46,159 --> 00:31:49,440
state then

00:31:47,679 --> 00:31:51,519
their synchronization with that shared

00:31:49,440 --> 00:31:53,760
state is done correctly

00:31:51,519 --> 00:31:57,039
and think about how they might interact

00:31:53,760 --> 00:31:57,039
with each other if they are indeed run

00:31:58,840 --> 00:32:03,200
concurrently

00:32:01,600 --> 00:32:05,120
and then there's a very specific thing

00:32:03,200 --> 00:32:06,399
about thread pools if you're sharing

00:32:05,120 --> 00:32:10,000
your thread pool with

00:32:06,399 --> 00:32:12,399
other parts of the application then

00:32:10,000 --> 00:32:14,240
if another part of the application

00:32:12,399 --> 00:32:15,679
submits a whole bunch of tasks onto the

00:32:14,240 --> 00:32:17,440
thread onto the thread pool

00:32:15,679 --> 00:32:19,279
then the event handling tasks might be

00:32:17,440 --> 00:32:20,720
arbitrarily delayed

00:32:19,279 --> 00:32:23,760
because they end up further back in the

00:32:20,720 --> 00:32:25,760
queue somebody's just submitted 100

00:32:23,760 --> 00:32:26,960
tasks and you've only got four threads

00:32:25,760 --> 00:32:27,600
it's going to take a while for the

00:32:26,960 --> 00:32:31,679
thread

00:32:27,600 --> 00:32:33,919
threadball to process them all so

00:32:31,679 --> 00:32:37,600
that's can be a very real issue whereas

00:32:33,919 --> 00:32:37,600
at least if you have a dedicated thread

00:32:39,440 --> 00:32:45,760
then the um

00:32:44,320 --> 00:32:48,080
you know if you have yes if you have if

00:32:45,760 --> 00:32:50,799
you have a dedicated thread

00:32:48,080 --> 00:32:51,360
then the os will preempt your threads

00:32:50,799 --> 00:32:52,399
and

00:32:51,360 --> 00:32:55,039
if you have other threads in the

00:32:52,399 --> 00:32:57,039
application running but generally

00:32:55,039 --> 00:32:58,720
your thread will be keep processing in a

00:32:57,039 --> 00:32:59,279
relatively timely fashion and it won't

00:32:58,720 --> 00:33:02,399
have

00:32:59,279 --> 00:33:03,440
won't have big pauses where

00:33:02,399 --> 00:33:04,559
you know other threads in the

00:33:03,440 --> 00:33:06,640
applications on the air well i'm just

00:33:04,559 --> 00:33:08,480
going to run for three seconds

00:33:06,640 --> 00:33:10,240
and that thread is going to be paused

00:33:08,480 --> 00:33:12,399
they tend to be you know

00:33:10,240 --> 00:33:14,799
incremental interleaving rather than big

00:33:12,399 --> 00:33:14,799
pauses

00:33:16,880 --> 00:33:22,799
and yes it is a

00:33:20,240 --> 00:33:23,600
strong recommendation that you want to

00:33:22,799 --> 00:33:25,519
minimize

00:33:23,600 --> 00:33:27,120
the interactions between your tasks and

00:33:25,519 --> 00:33:28,880
make sure that they

00:33:27,120 --> 00:33:30,399
you know they are as self-contained as

00:33:28,880 --> 00:33:32,080
possible

00:33:30,399 --> 00:33:33,679
depending on your application structure

00:33:32,080 --> 00:33:38,480
that might be harder

00:33:33,679 --> 00:33:43,679
harder or easier to do but that is the

00:33:38,480 --> 00:33:46,480
the strong recommendation is that

00:33:43,679 --> 00:33:46,480
you do indeed

00:33:47,760 --> 00:33:53,840
make sure that your tasks are

00:33:51,279 --> 00:33:53,840
independent

00:33:56,720 --> 00:33:59,679
and again as a

00:34:00,480 --> 00:34:04,159
if you're sharing your thread pool with

00:34:02,399 --> 00:34:06,159
other parts of the application

00:34:04,159 --> 00:34:08,000
then it becomes very hard to cancel just

00:34:06,159 --> 00:34:09,520
your tasks

00:34:08,000 --> 00:34:11,359
if you've got a dedicated thread you can

00:34:09,520 --> 00:34:13,599
shut down the thread and

00:34:11,359 --> 00:34:15,040
destroy everything in the in the message

00:34:13,599 --> 00:34:16,240
queue

00:34:15,040 --> 00:34:17,440
if you're sharing your thread pull with

00:34:16,240 --> 00:34:18,960
yesterday application you don't

00:34:17,440 --> 00:34:20,800
necessarily want to shut down

00:34:18,960 --> 00:34:22,720
the whole thread pool and everything in

00:34:20,800 --> 00:34:24,480
the application so cancelling just the

00:34:22,720 --> 00:34:26,800
tasks associated with

00:34:24,480 --> 00:34:29,200
a particular google window or a patek

00:34:26,800 --> 00:34:32,720
particular client connection

00:34:29,200 --> 00:34:37,599
can be though actually quite hard

00:34:32,720 --> 00:34:37,599
you need to think about how to do that

00:34:40,720 --> 00:34:49,839
and that sort of thing and so that can

00:34:43,280 --> 00:34:49,839
be an important thing

00:34:58,880 --> 00:35:02,079
so i only think that the biggest

00:35:00,400 --> 00:35:05,280
downside from tread pools is the

00:35:02,079 --> 00:35:05,280
unpredictable ordering

00:35:06,160 --> 00:35:12,960
but we can solve that

00:35:09,680 --> 00:35:12,960
with continuations

00:35:13,520 --> 00:35:17,599
the idea is fundamentally that if task b

00:35:15,760 --> 00:35:20,640
is a continuation of task a

00:35:17,599 --> 00:35:22,640
it cannot run concurrently

00:35:20,640 --> 00:35:24,560
the thread pull will not even attempt to

00:35:22,640 --> 00:35:27,280
run it so

00:35:24,560 --> 00:35:27,599
if you spawn if you submit both tasks a

00:35:27,280 --> 00:35:29,440
and b

00:35:27,599 --> 00:35:31,680
into the thread pool and mark that task

00:35:29,440 --> 00:35:35,599
b is a continuation of task a

00:35:31,680 --> 00:35:37,839
then even if you have 15 idle threads

00:35:35,599 --> 00:35:39,280
when task a is running none of the other

00:35:37,839 --> 00:35:42,079
threads are going to pick up

00:35:39,280 --> 00:35:43,440
task b until task a is finished and so

00:35:42,079 --> 00:35:47,200
now we have our

00:35:43,440 --> 00:35:48,240
ordering that guarantees that things

00:35:47,200 --> 00:35:52,000
happen in the right

00:35:48,240 --> 00:35:54,480
order and so

00:35:52,000 --> 00:35:55,280
we can do we can enforce that then on

00:35:54,480 --> 00:35:58,480
our

00:35:55,280 --> 00:35:59,359
from our event queue we can keep track

00:35:58,480 --> 00:36:01,200
of which

00:35:59,359 --> 00:36:03,359
what the last task that we submitted to

00:36:01,200 --> 00:36:07,280
the thread pool was

00:36:03,359 --> 00:36:10,320
and then we can

00:36:07,280 --> 00:36:11,359
chain our event handler as a

00:36:10,320 --> 00:36:15,200
continuation

00:36:11,359 --> 00:36:16,400
of that task rather than submitting a

00:36:15,200 --> 00:36:18,960
fresh task

00:36:16,400 --> 00:36:18,960
every time

00:36:21,520 --> 00:36:24,880
and obviously if we haven't got an

00:36:23,040 --> 00:36:27,440
existing task then we can submit a fresh

00:36:24,880 --> 00:36:30,640
one

00:36:27,440 --> 00:36:32,880
if you know that the

00:36:30,640 --> 00:36:34,079
events are unrelated then obviously you

00:36:32,880 --> 00:36:35,839
don't have to

00:36:34,079 --> 00:36:37,839
you know you can only you can submit

00:36:35,839 --> 00:36:40,000
things as continuations where it matters

00:36:37,839 --> 00:36:41,760
and have them as not continuations where

00:36:40,000 --> 00:36:44,480
they're not

00:36:41,760 --> 00:36:45,359
and based on your appropriate business

00:36:44,480 --> 00:36:48,720
logic

00:36:45,359 --> 00:36:52,480
but fundamentally we can do with that

00:36:48,720 --> 00:36:53,440
this way if you did this for all your

00:36:52,480 --> 00:36:55,280
events

00:36:53,440 --> 00:36:57,520
then you are losing some of the benefit

00:36:55,280 --> 00:36:59,520
of the thread pool because you are now

00:36:57,520 --> 00:37:01,119
putting an ordering on your tasks and

00:36:59,520 --> 00:37:02,720
that then only provides a benefit if

00:37:01,119 --> 00:37:09,839
you're sharing the thread pool with

00:37:02,720 --> 00:37:09,839
the rest of your system

00:37:13,359 --> 00:37:18,800
so upsides you know it's the

00:37:16,640 --> 00:37:20,240
big upside our rents are now handled in

00:37:18,800 --> 00:37:22,320
the order they arrive

00:37:20,240 --> 00:37:24,240
and they'll not handle concurrently now

00:37:22,320 --> 00:37:25,760
these are obviously

00:37:24,240 --> 00:37:27,200
tightly related if they were handled

00:37:25,760 --> 00:37:27,920
concurrently they would not be strictly

00:37:27,200 --> 00:37:31,119
in order

00:37:27,920 --> 00:37:33,359
but both of them are important because

00:37:31,119 --> 00:37:34,960
again your top

00:37:33,359 --> 00:37:36,480
those tasks that are handled as

00:37:34,960 --> 00:37:39,520
continuations now are

00:37:36,480 --> 00:37:41,359
essentially single threaded and so

00:37:39,520 --> 00:37:44,480
we don't have to worry about

00:37:41,359 --> 00:37:44,480
synchronization issues

00:37:45,920 --> 00:37:50,079
okay but we've eliminated the

00:37:48,800 --> 00:37:52,320
concurrency of

00:37:50,079 --> 00:37:52,320
our

00:37:54,800 --> 00:37:59,920
processing so we can delay in subsequent

00:37:57,200 --> 00:37:59,920
event processing

00:38:03,599 --> 00:38:09,280
so okay that is clearly a downside

00:38:07,280 --> 00:38:11,359
but it still doesn't fix our other

00:38:09,280 --> 00:38:12,320
problems no we still have to deal with

00:38:11,359 --> 00:38:14,480
cancellation

00:38:12,320 --> 00:38:16,960
we still need to now we still have that

00:38:14,480 --> 00:38:18,480
disconnect from the event

00:38:16,960 --> 00:38:20,480
in the event itself and then the

00:38:18,480 --> 00:38:22,560
processing so

00:38:20,480 --> 00:38:33,839
continuations are good for some aspects

00:38:22,560 --> 00:38:33,839
but they don't solve all our problems

00:38:35,839 --> 00:38:40,000
so one of the big outstanding problems

00:38:37,760 --> 00:38:40,000
which

00:38:40,400 --> 00:38:46,320
people are asking questions about as

00:38:42,079 --> 00:38:48,800
well is how do we deal with cancellation

00:38:46,320 --> 00:38:49,599
and you might need to cancel tasks

00:38:48,800 --> 00:38:52,560
submitted

00:38:49,599 --> 00:38:53,680
you know so you've submitted a task you

00:38:52,560 --> 00:38:56,720
somebody clicked

00:38:53,680 --> 00:38:58,800
download that big file or process that

00:38:56,720 --> 00:39:02,000
huge image

00:38:58,800 --> 00:39:04,240
or any other sort of

00:39:02,000 --> 00:39:06,240
long-running task and then they click

00:39:04,240 --> 00:39:09,599
cancel i don't want to do that anymore

00:39:06,240 --> 00:39:10,880
so somehow you need to stop the tasks

00:39:09,599 --> 00:39:14,000
that have been submitted

00:39:10,880 --> 00:39:15,599
that in response to earlier events so

00:39:14,000 --> 00:39:17,599
particularly if you've got long-running

00:39:15,599 --> 00:39:19,040
tasks but also

00:39:17,599 --> 00:39:20,800
even if there were a series of

00:39:19,040 --> 00:39:22,240
short-running tasks but actually now we

00:39:20,800 --> 00:39:23,680
just close the whole application we want

00:39:22,240 --> 00:39:24,720
everything to tighten to tidy up and go

00:39:23,680 --> 00:39:26,560
away

00:39:24,720 --> 00:39:28,240
so we need to avoid having dangling

00:39:26,560 --> 00:39:30,480
tasks where

00:39:28,240 --> 00:39:31,839
the task itself keeps running even

00:39:30,480 --> 00:39:33,599
though we no longer

00:39:31,839 --> 00:39:35,920
have any need for it we want it to go

00:39:33,599 --> 00:39:35,920
away

00:39:37,680 --> 00:39:40,880
so we want some means of cancelling

00:39:39,680 --> 00:39:44,240
tasks

00:39:40,880 --> 00:39:44,240
in a nice timely fashion

00:39:44,800 --> 00:39:48,560
if you've got a nice shiny c plus plus

00:39:46,960 --> 00:39:50,480
20 compiler

00:39:48,560 --> 00:39:52,640
then i would recommend the standard stop

00:39:50,480 --> 00:39:57,760
token is the

00:39:52,640 --> 00:39:59,440
the um the tool for the job

00:39:57,760 --> 00:40:01,839
you pass your stop token to every task

00:39:59,440 --> 00:40:05,119
that might need to be cancelled

00:40:01,839 --> 00:40:07,280
and then that task can then use it it

00:40:05,119 --> 00:40:10,720
can use it with

00:40:07,280 --> 00:40:11,440
condition variables and you can use it

00:40:10,720 --> 00:40:14,319
in a coach

00:40:11,440 --> 00:40:15,359
association with a stop callback to

00:40:14,319 --> 00:40:17,839
handle

00:40:15,359 --> 00:40:19,200
blocking system calls and anything else

00:40:17,839 --> 00:40:22,160
provided that

00:40:19,200 --> 00:40:26,000
your api does provide some means of

00:40:22,160 --> 00:40:29,280
cancelling those tasks so if you have

00:40:26,000 --> 00:40:30,319
a blocking i o call but you have another

00:40:29,280 --> 00:40:32,240
a

00:40:30,319 --> 00:40:34,880
cancel i o function of some description

00:40:32,240 --> 00:40:36,400
that you can call to interrupt that

00:40:34,880 --> 00:40:38,240
blocking i o you can use that with a

00:40:36,400 --> 00:40:40,480
stop callback

00:40:38,240 --> 00:40:41,839
in conjunction with your stock token and

00:40:40,480 --> 00:40:45,040
then

00:40:41,839 --> 00:40:48,800
when the cancel request comes through

00:40:45,040 --> 00:40:53,839
your counseling function will be invoked

00:40:48,800 --> 00:40:53,839
and the task interrupted

00:40:54,079 --> 00:40:57,839
you keep the stop source in the event

00:40:55,680 --> 00:40:58,480
handler and then you call request stop

00:40:57,839 --> 00:41:00,079
when

00:40:58,480 --> 00:41:02,560
the appropriate set of tasks need to be

00:41:00,079 --> 00:41:03,680
stopped so you can keep multiple stop

00:41:02,560 --> 00:41:07,200
sources around

00:41:03,680 --> 00:41:08,960
if you have if your event some tasks

00:41:07,200 --> 00:41:10,960
divvy up into little portions well

00:41:08,960 --> 00:41:12,400
there's this set of tasks that relate to

00:41:10,960 --> 00:41:13,760
downloading that file there's this set

00:41:12,400 --> 00:41:16,800
of tasks that relate to

00:41:13,760 --> 00:41:17,680
animating that window and then when

00:41:16,800 --> 00:41:19,280
somebody

00:41:17,680 --> 00:41:21,599
clicks the cancel button for the file or

00:41:19,280 --> 00:41:24,079
they say click on stop on the animation

00:41:21,599 --> 00:41:24,640
then you can trigger the appropriate

00:41:24,079 --> 00:41:26,400
source

00:41:24,640 --> 00:41:28,240
and call the appropriate request stop

00:41:26,400 --> 00:41:29,760
function

00:41:28,240 --> 00:41:34,880
to make sure that the appropriate things

00:41:29,760 --> 00:41:37,040
get stopped

00:41:34,880 --> 00:41:38,480
so you need to be aware that just

00:41:37,040 --> 00:41:40,640
because you asked the task to stop

00:41:38,480 --> 00:41:44,160
doesn't mean it stops immediately

00:41:40,640 --> 00:41:47,280
no the stop token mechanism is

00:41:44,160 --> 00:41:50,400
purely cooperative and general

00:41:47,280 --> 00:41:51,920
generally that's what you want you even

00:41:50,400 --> 00:41:52,960
if you don't have stock token you use

00:41:51,920 --> 00:41:53,680
something else that you've built

00:41:52,960 --> 00:41:56,000
yourself

00:41:53,680 --> 00:41:56,960
or some other facility that you're using

00:41:56,000 --> 00:41:59,119
from

00:41:56,960 --> 00:42:00,800
the libraries you've got then most

00:41:59,119 --> 00:42:04,319
things are

00:42:00,800 --> 00:42:04,880
not instantaneous um there is some form

00:42:04,319 --> 00:42:07,760
of

00:42:04,880 --> 00:42:08,720
cooperation and delay and so you need to

00:42:07,760 --> 00:42:12,000
actually then

00:42:08,720 --> 00:42:13,359
ensure that the tasks have been stopped

00:42:12,000 --> 00:42:16,640
before you try and clean up any data

00:42:13,359 --> 00:42:20,000
they might be operating on

00:42:16,640 --> 00:42:21,359
the simplest way to do that is just to

00:42:20,000 --> 00:42:23,680
keep a count of how many tasks you've

00:42:21,359 --> 00:42:25,599
got and you have

00:42:23,680 --> 00:42:27,280
an unsigned count number of pending

00:42:25,599 --> 00:42:28,880
tasks

00:42:27,280 --> 00:42:30,480
and when you handle events you increase

00:42:28,880 --> 00:42:31,760
the number of tasks

00:42:30,480 --> 00:42:34,000
because you're submitting one to the

00:42:31,760 --> 00:42:34,000
queue

00:42:34,079 --> 00:42:42,160
then when it is done

00:42:38,960 --> 00:42:44,720
then whether it was completed or whether

00:42:42,160 --> 00:42:46,800
it was interrupted

00:42:44,720 --> 00:42:48,640
then it decreases the number of pending

00:42:46,800 --> 00:42:51,839
tasks and notifies

00:42:48,640 --> 00:42:53,599
so if i was the last task

00:42:51,839 --> 00:42:55,760
assuming when it hit zero i was the last

00:42:53,599 --> 00:42:58,640
task no please be awaited

00:42:55,760 --> 00:43:00,640
no take note this is using the new c

00:42:58,640 --> 00:43:02,480
plus plus 20 weighting feature from

00:43:00,640 --> 00:43:04,240
for the atomic obviously if you don't

00:43:02,480 --> 00:43:05,200
have a c plus plus 20 compiler then you

00:43:04,240 --> 00:43:08,640
can

00:43:05,200 --> 00:43:10,640
um use something else so on linux you

00:43:08,640 --> 00:43:12,720
might use a futex on windows you might

00:43:10,640 --> 00:43:15,760
use weight on address both of these are

00:43:12,720 --> 00:43:18,880
fundamental things that

00:43:15,760 --> 00:43:19,680
are built underneath the atomic

00:43:18,880 --> 00:43:21,040
weighting

00:43:19,680 --> 00:43:22,480
or you might use something higher level

00:43:21,040 --> 00:43:24,000
you might use a condition variable or

00:43:22,480 --> 00:43:26,480
you might use a

00:43:24,000 --> 00:43:27,359
windows event or something but either

00:43:26,480 --> 00:43:29,599
way round

00:43:27,359 --> 00:43:32,960
you can decrement the count and then

00:43:29,599 --> 00:43:32,960
notify if it is zero

00:43:34,640 --> 00:43:39,359
when you're trying to cancel things you

00:43:36,000 --> 00:43:42,640
just know you cancel the tasks

00:43:39,359 --> 00:43:43,680
um i should say request stop not stop

00:43:42,640 --> 00:43:46,240
token

00:43:43,680 --> 00:43:47,359
um and then when you're waiting for them

00:43:46,240 --> 00:43:50,400
to clean up

00:43:47,359 --> 00:43:51,599
then make sure obviously you don't do

00:43:50,400 --> 00:43:52,880
this in an event handler

00:43:51,599 --> 00:43:55,280
you should not be blocking doing a

00:43:52,880 --> 00:43:57,119
blocking waiting event handler

00:43:55,280 --> 00:43:59,440
somebody's going to wait for the tasks

00:43:57,119 --> 00:44:01,839
and you

00:43:59,440 --> 00:44:04,480
read the count if it's not zero you wait

00:44:01,839 --> 00:44:08,079
for it to be notified

00:44:04,480 --> 00:44:09,930
and then you look round again and

00:44:08,079 --> 00:44:11,440
no the

00:44:09,930 --> 00:44:14,480
[Music]

00:44:11,440 --> 00:44:17,200
this will only um

00:44:14,480 --> 00:44:18,160
this will be a blocking weight it it

00:44:17,200 --> 00:44:19,680
will only

00:44:18,160 --> 00:44:21,119
loop around when either it's been

00:44:19,680 --> 00:44:22,400
notified which will be when the count

00:44:21,119 --> 00:44:24,000
was zero

00:44:22,400 --> 00:44:25,920
because that's what we did with our

00:44:24,000 --> 00:44:26,800
event handler or when there's a spurious

00:44:25,920 --> 00:44:28,319
wake

00:44:26,800 --> 00:44:29,920
and which and the os will look at the

00:44:28,319 --> 00:44:33,119
count and say well it has changed

00:44:29,920 --> 00:44:34,319
so maybe you want to check it again

00:44:33,119 --> 00:44:36,160
so that's why we put the while loop

00:44:34,319 --> 00:44:37,680
there but

00:44:36,160 --> 00:44:39,200
fundamentally this is like this is a

00:44:37,680 --> 00:44:40,240
blocking weight and the os will actually

00:44:39,200 --> 00:44:43,119
suspend your thread for

00:44:40,240 --> 00:44:44,240
most of the processing here so you

00:44:43,119 --> 00:44:45,280
really don't want to do this in your

00:44:44,240 --> 00:44:47,280
event handler

00:44:45,280 --> 00:44:51,680
but you can do it say in the destructor

00:44:47,280 --> 00:44:54,640
or if for a class

00:44:51,680 --> 00:44:57,040
i was you created or done all the

00:44:54,640 --> 00:44:59,839
processing

00:44:57,040 --> 00:45:01,040
then you finished finished everything so

00:44:59,839 --> 00:45:03,119
you're shutting down

00:45:01,040 --> 00:45:04,079
you stick this weight for tasks in the

00:45:03,119 --> 00:45:05,599
destructor

00:45:04,079 --> 00:45:07,040
and make sure that all the tasks are

00:45:05,599 --> 00:45:08,319
drained through from the thread pool

00:45:07,040 --> 00:45:11,359
that relates to this

00:45:08,319 --> 00:45:11,359
this particular aspect

00:45:11,440 --> 00:45:19,839
before we move on

00:45:24,560 --> 00:45:28,800
so what about progress updates what how

00:45:26,880 --> 00:45:30,480
does the background task in our thread

00:45:28,800 --> 00:45:31,440
pool or the dedicated thread how do they

00:45:30,480 --> 00:45:34,880
talk back to

00:45:31,440 --> 00:45:35,599
our um event handler now maybe there's

00:45:34,880 --> 00:45:37,839
got a res

00:45:35,599 --> 00:45:38,800
response they've got to send over back

00:45:37,839 --> 00:45:42,720
over the network

00:45:38,800 --> 00:45:44,560
maybe there's a no change to the ui that

00:45:42,720 --> 00:45:46,160
needs to happen

00:45:44,560 --> 00:45:48,400
even if it's just literally moving the

00:45:46,160 --> 00:45:50,079
progress bar

00:45:48,400 --> 00:45:51,760
now fundamentally we might need to

00:45:50,079 --> 00:45:53,680
update the event thread

00:45:51,760 --> 00:45:55,839
with new information from the background

00:45:53,680 --> 00:45:57,920
threads

00:45:55,839 --> 00:46:00,319
there might be progress updates might be

00:45:57,920 --> 00:46:01,920
other updates in the ui we might

00:46:00,319 --> 00:46:04,720
need to change change the window we

00:46:01,920 --> 00:46:09,200
might need to stick readily

00:46:04,720 --> 00:46:09,200
red wiggly lines under misspelled words

00:46:09,520 --> 00:46:16,000
no or other

00:46:13,040 --> 00:46:17,920
actually you know draw a graph of the

00:46:16,000 --> 00:46:19,200
relative frequencies of

00:46:17,920 --> 00:46:20,560
different data items that have been

00:46:19,200 --> 00:46:21,920
being calculated in the background

00:46:20,560 --> 00:46:24,800
thread the task is finished here is the

00:46:21,920 --> 00:46:24,800
data please draw it

00:46:25,040 --> 00:46:27,839
whatever somehow you've got we've got

00:46:26,560 --> 00:46:28,800
all these information coming back to the

00:46:27,839 --> 00:46:30,400
ui

00:46:28,800 --> 00:46:32,240
might be some i o that needs to happen

00:46:30,400 --> 00:46:33,040
and of course it has to happen on the io

00:46:32,240 --> 00:46:36,000
loop if that's

00:46:33,040 --> 00:46:37,040
the way your application is built but

00:46:36,000 --> 00:46:39,920
either way

00:46:37,040 --> 00:46:40,720
somehow you need to trigger some form of

00:46:39,920 --> 00:46:44,000
event

00:46:40,720 --> 00:46:45,040
on the event thread and usually it has

00:46:44,000 --> 00:46:46,800
to be the same

00:46:45,040 --> 00:46:49,839
sort of thing that the event thread is

00:46:46,800 --> 00:46:52,000
waiting for if your event thread is a

00:46:49,839 --> 00:46:53,520
gui thread waiting for messages from the

00:46:52,000 --> 00:46:55,520
windowing system

00:46:53,520 --> 00:46:57,200
then you need to send it a windows

00:46:55,520 --> 00:47:00,079
system message

00:46:57,200 --> 00:47:00,880
probably you know a custom message type

00:47:00,079 --> 00:47:02,640
but it

00:47:00,880 --> 00:47:04,240
acknowledged registered with the

00:47:02,640 --> 00:47:06,400
windowing system

00:47:04,240 --> 00:47:08,000
if it's an i o loop then you might be

00:47:06,400 --> 00:47:10,319
able to use something like event fd

00:47:08,000 --> 00:47:11,280
to give you a file handle which you can

00:47:10,319 --> 00:47:13,680
use to trigger

00:47:11,280 --> 00:47:14,400
here is an event you know on my file

00:47:13,680 --> 00:47:16,480
handle

00:47:14,400 --> 00:47:17,440
and then you can then your event thread

00:47:16,480 --> 00:47:20,720
can say ah

00:47:17,440 --> 00:47:22,800
that's an event on my special

00:47:20,720 --> 00:47:24,000
event file handle which therefore i know

00:47:22,800 --> 00:47:27,200
means that i've got some message

00:47:24,000 --> 00:47:27,200
coming from my background thread

00:47:28,000 --> 00:47:31,920
or there might be other similar

00:47:29,440 --> 00:47:33,839
mechanisms for other platforms

00:47:31,920 --> 00:47:38,000
but fundamentally you're probably going

00:47:33,839 --> 00:47:40,400
to have to package

00:47:38,000 --> 00:47:41,680
the message from the background thread

00:47:40,400 --> 00:47:44,400
has something that the event

00:47:41,680 --> 00:47:45,280
thread is going to look for without

00:47:44,400 --> 00:47:49,760
interrupting its

00:47:45,280 --> 00:47:51,599
normal processing processing flow

00:47:49,760 --> 00:47:52,960
it might be that all the only

00:47:51,599 --> 00:47:54,240
information that it actually that the

00:47:52,960 --> 00:47:56,240
message

00:47:54,240 --> 00:47:58,000
tells it is look in this message queue

00:47:56,240 --> 00:47:59,680
over here but

00:47:58,000 --> 00:48:01,200
which can then be a custom application

00:47:59,680 --> 00:48:04,400
specific message queue but

00:48:01,200 --> 00:48:06,400
you need to break it out of its um

00:48:04,400 --> 00:48:07,359
normal message loop and say actually

00:48:06,400 --> 00:48:10,079
there's something coming in from the

00:48:07,359 --> 00:48:10,079
background thread

00:48:13,200 --> 00:48:16,319
so then now your background thread it's

00:48:15,359 --> 00:48:18,960
got some progress

00:48:16,319 --> 00:48:20,079
you know i'm 99 done and i'm going to

00:48:18,960 --> 00:48:23,440
post a progress event

00:48:20,079 --> 00:48:25,680
onto the event loop

00:48:23,440 --> 00:48:26,880
onto the event queue that the event loop

00:48:25,680 --> 00:48:29,920
is processing

00:48:26,880 --> 00:48:31,599
and then in your event loop you receive

00:48:29,920 --> 00:48:33,520
a specific progress event

00:48:31,599 --> 00:48:34,880
on which you can then use to update the

00:48:33,520 --> 00:48:37,680
ui with

00:48:34,880 --> 00:48:39,839
the new progressor or whatever else it

00:48:37,680 --> 00:48:49,839
is that needs to have that is

00:48:39,839 --> 00:48:49,839
actually being affected

00:48:56,160 --> 00:49:01,599
so coat routines lots of people

00:48:59,839 --> 00:49:04,079
love co-routines and they like to use

00:49:01,599 --> 00:49:08,720
them for this sort of task

00:49:04,079 --> 00:49:10,559
but they are not a magical solution

00:49:08,720 --> 00:49:12,559
you can't just say yeah let's use

00:49:10,559 --> 00:49:13,200
co-routines it's all marvelous problem

00:49:12,559 --> 00:49:16,400
solved

00:49:13,200 --> 00:49:19,920
no but they can make

00:49:16,400 --> 00:49:21,040
your code simpler looking and aside from

00:49:19,920 --> 00:49:24,000
the co-routine

00:49:21,040 --> 00:49:24,480
library itself your code can actually be

00:49:24,000 --> 00:49:26,160
you know

00:49:24,480 --> 00:49:28,079
it's not just simpler looking it's it's

00:49:26,160 --> 00:49:29,839
simpler easier to maintain

00:49:28,079 --> 00:49:32,240
now if your co-routine library is well

00:49:29,839 --> 00:49:37,839
written then

00:49:32,240 --> 00:49:37,839
your code can be simple

00:49:38,960 --> 00:49:42,079
when you handle the event you can call

00:49:40,800 --> 00:49:45,119
your co-routine library say

00:49:42,079 --> 00:49:46,240
schedule on the thread pool no disco

00:49:45,119 --> 00:49:49,119
routine that's going to process the

00:49:46,240 --> 00:49:53,040
details from this event

00:49:49,119 --> 00:49:55,440
in our processing function

00:49:53,040 --> 00:49:57,520
then which is now it's a task for the

00:49:55,440 --> 00:49:59,920
code which the co routine

00:49:57,520 --> 00:50:01,440
you're using knows about then you can

00:49:59,920 --> 00:50:05,440
just know you can

00:50:01,440 --> 00:50:07,200
say step one and wait for that step one

00:50:05,440 --> 00:50:08,640
then i'm going to schedule an update on

00:50:07,200 --> 00:50:09,200
the gui thread to say the progress has

00:50:08,640 --> 00:50:11,760
happened

00:50:09,200 --> 00:50:13,359
i'm gonna do step wait for step two to

00:50:11,760 --> 00:50:15,200
complete and then schedule again

00:50:13,359 --> 00:50:16,480
something on the gui thread for progress

00:50:15,200 --> 00:50:18,800
to happen and

00:50:16,480 --> 00:50:19,599
all this is very simple straightforward

00:50:18,800 --> 00:50:21,839
okay

00:50:19,599 --> 00:50:23,440
lines of code this processing can be a

00:50:21,839 --> 00:50:24,640
long running task but every time there's

00:50:23,440 --> 00:50:26,800
a curl weight there

00:50:24,640 --> 00:50:29,359
then it schedules it as a continuation

00:50:26,800 --> 00:50:31,280
and so it allows other things

00:50:29,359 --> 00:50:33,839
from your application to interleave on

00:50:31,280 --> 00:50:33,839
the thread pool

00:50:34,160 --> 00:50:37,280
but it's simple from the point of view

00:50:36,880 --> 00:50:39,599
of

00:50:37,280 --> 00:50:41,200
you writing the code everything looks

00:50:39,599 --> 00:50:43,200
nice and sequential

00:50:41,200 --> 00:50:44,800
you can see clearly that step one

00:50:43,200 --> 00:50:47,359
happens before step two that there's

00:50:44,800 --> 00:50:47,839
no update for the progress in between

00:50:47,359 --> 00:50:51,119
but

00:50:47,839 --> 00:50:52,960
you'd and your code isn't

00:50:51,119 --> 00:50:54,160
you know doesn't have to deal with the

00:50:52,960 --> 00:50:56,640
complexities

00:50:54,160 --> 00:50:58,319
of scheduling continuations and writing

00:50:56,640 --> 00:51:00,000
it in a continuation style

00:50:58,319 --> 00:51:01,680
and making sure that all the data stays

00:51:00,000 --> 00:51:05,040
alive for all the continuations

00:51:01,680 --> 00:51:08,079
because the your co-routine

00:51:05,040 --> 00:51:09,119
library along with the c plus 20 co

00:51:08,079 --> 00:51:12,559
routine

00:51:09,119 --> 00:51:14,000
infrastructure deals with all that for

00:51:12,559 --> 00:51:16,000
you

00:51:14,000 --> 00:51:17,760
obviously you need a co-routine library

00:51:16,000 --> 00:51:18,480
c plus plus 20 doesn't provide us with

00:51:17,760 --> 00:51:21,359
one

00:51:18,480 --> 00:51:21,760
um you might want to use something like

00:51:21,359 --> 00:51:26,000
the

00:51:21,760 --> 00:51:29,440
cppcoro co-routine library

00:51:26,000 --> 00:51:30,800
and there's no but or you might want to

00:51:29,440 --> 00:51:34,079
write your own

00:51:30,800 --> 00:51:36,800
but either way you can simplify

00:51:34,079 --> 00:51:38,000
the end user code now the application

00:51:36,800 --> 00:51:41,599
level code

00:51:38,000 --> 00:51:45,440
with care routines i can

00:51:41,599 --> 00:51:45,440
make the overall

00:51:45,760 --> 00:51:49,200
application level code look lots a lot

00:51:48,400 --> 00:51:52,079
simpler

00:51:49,200 --> 00:51:53,359
while simultaneously using a thread pool

00:51:52,079 --> 00:51:56,640
under under the hood

00:51:53,359 --> 00:51:58,079
and dealing with the interactions and

00:51:56,640 --> 00:52:01,200
the continuations

00:51:58,079 --> 00:52:03,440
and making sure that then the

00:52:01,200 --> 00:52:05,119
that integrates nicely with other other

00:52:03,440 --> 00:52:08,480
parts of the application

00:52:05,119 --> 00:52:10,559
and seamlessly scheduling the tasks that

00:52:08,480 --> 00:52:13,599
need to run back on the gui thread

00:52:10,559 --> 00:52:16,800
get seamlessly scheduled though no you

00:52:13,599 --> 00:52:18,400
the library is abstracting posting those

00:52:16,800 --> 00:52:20,000
applications specific

00:52:18,400 --> 00:52:21,920
the messages like the progress event

00:52:20,000 --> 00:52:25,280
message that was specific

00:52:21,920 --> 00:52:26,559
to the event loop it was then seamlessly

00:52:25,280 --> 00:52:28,880
wrapped in our schedule on the gui

00:52:26,559 --> 00:52:31,200
thread function

00:52:28,880 --> 00:52:32,000
we don't need to worry about the details

00:52:31,200 --> 00:52:35,359
that's

00:52:32,000 --> 00:52:36,880
just wrapped up in the library so you

00:52:35,359 --> 00:52:38,079
can write this it doesn't have to be co

00:52:36,880 --> 00:52:39,040
routines you can write this sort of

00:52:38,079 --> 00:52:42,160
infrastructure with

00:52:39,040 --> 00:52:42,160
anything but

00:52:42,240 --> 00:52:47,839
they certainly do provide one way of

00:52:43,920 --> 00:52:47,839
making things look simple

00:52:51,359 --> 00:52:54,400
so some final guidelines obviously the

00:52:53,520 --> 00:52:57,520
first one

00:52:54,400 --> 00:53:01,359
is that the reason we're doing this is

00:52:57,520 --> 00:53:04,079
we want our threads to be responsive so

00:53:01,359 --> 00:53:06,720
if you have a time consuming task you

00:53:04,079 --> 00:53:08,480
really really must not run it

00:53:06,720 --> 00:53:11,520
on the thread that needs to be

00:53:08,480 --> 00:53:13,440
responsive and that includes

00:53:11,520 --> 00:53:14,960
you know waiting for tasks to finish

00:53:13,440 --> 00:53:18,400
once you've submitted them to your

00:53:14,960 --> 00:53:21,280
background threads because waiting

00:53:18,400 --> 00:53:21,760
blocks for an unspecified length of time

00:53:21,280 --> 00:53:25,520
and

00:53:21,760 --> 00:53:28,480
therefore interrupts your ability to

00:53:25,520 --> 00:53:29,839
deal with messages and be responsive to

00:53:28,480 --> 00:53:32,240
messages and events coming in from

00:53:29,839 --> 00:53:32,240
outside

00:53:32,800 --> 00:53:37,040
if you have a very long running task

00:53:35,200 --> 00:53:39,359
then a dedicated thread really makes

00:53:37,040 --> 00:53:39,359
sense

00:53:39,520 --> 00:53:43,359
because it's there it can just process

00:53:42,960 --> 00:53:45,119
it

00:53:43,359 --> 00:53:46,720
you know it's long-running task in

00:53:45,119 --> 00:53:49,040
sequence and

00:53:46,720 --> 00:53:50,240
it can periodically check for new

00:53:49,040 --> 00:53:52,640
messages or send things

00:53:50,240 --> 00:53:54,240
back to the event but but it doesn't

00:53:52,640 --> 00:53:55,520
have to worry about things being out of

00:53:54,240 --> 00:53:59,200
order or interleaved with

00:53:55,520 --> 00:54:02,559
other tasks but

00:53:59,200 --> 00:54:03,839
if your individual the individual parts

00:54:02,559 --> 00:54:04,640
can be small then you might want to use

00:54:03,839 --> 00:54:06,880
a thread pool

00:54:04,640 --> 00:54:08,480
and then you can submit lots of tiny

00:54:06,880 --> 00:54:12,240
tasks to your thread pool

00:54:08,480 --> 00:54:14,960
and that scales nicely as your app

00:54:12,240 --> 00:54:16,800
as your hardware you know as your

00:54:14,960 --> 00:54:18,480
hardware scales gets more calls

00:54:16,800 --> 00:54:21,599
then your application will scale if you

00:54:18,480 --> 00:54:21,599
use something like a thread pool

00:54:22,640 --> 00:54:29,599
if you need to cancel then stop token is

00:54:25,680 --> 00:54:31,680
really nice api and it's really flexible

00:54:29,599 --> 00:54:33,359
if you don't have it with your compiler

00:54:31,680 --> 00:54:35,839
then have a look at

00:54:33,359 --> 00:54:37,440
how it works and see whether you can

00:54:35,839 --> 00:54:40,160
construct something similar

00:54:37,440 --> 00:54:43,040
for your system that uses the libraries

00:54:40,160 --> 00:54:43,040
you do have available

00:54:45,839 --> 00:54:49,680
obviously we don't want dangling

00:54:47,839 --> 00:54:51,200
pointers so we need to make sure that

00:54:49,680 --> 00:54:52,960
our tasks are finished before we try and

00:54:51,200 --> 00:54:54,559
destroy any day-to-day reference

00:54:52,960 --> 00:54:56,480
the simplest way to do that is just to

00:54:54,559 --> 00:54:59,040
count how many tasks there are

00:54:56,480 --> 00:55:00,640
you if you could you do that counting

00:54:59,040 --> 00:55:02,799
with a reference count like in shared

00:55:00,640 --> 00:55:06,400
pointer

00:55:02,799 --> 00:55:08,799
but it's that's a very simple thing

00:55:06,400 --> 00:55:11,520
is count tasks and then you can clear up

00:55:08,799 --> 00:55:14,079
when everything's done

00:55:11,520 --> 00:55:15,599
and make sure you know whether you're in

00:55:14,079 --> 00:55:17,280
the scenario where

00:55:15,599 --> 00:55:19,200
you really really really need to avoid

00:55:17,280 --> 00:55:22,160
all blocking you need genuine

00:55:19,200 --> 00:55:24,079
lot free obstruction free code or

00:55:22,160 --> 00:55:27,280
whether you just need short lived locks

00:55:24,079 --> 00:55:28,880
and you need to you have a as long as

00:55:27,280 --> 00:55:30,079
it's done in a reasonable timely fashion

00:55:28,880 --> 00:55:31,359
and

00:55:30,079 --> 00:55:33,440
we know that our locks are only held for

00:55:31,359 --> 00:55:35,760
a short period of time so that's okay

00:55:33,440 --> 00:55:37,200
then that's once it whereas if you need

00:55:35,760 --> 00:55:39,280
the hard guarantee

00:55:37,200 --> 00:55:40,960
that this code is obstruction free then

00:55:39,280 --> 00:55:43,040
that makes things a lot more complicated

00:55:40,960 --> 00:55:45,680
and you really need to pay attention to

00:55:43,040 --> 00:55:49,839
all aspects of anything that interacts

00:55:45,680 --> 00:55:49,839
with that threat

00:55:52,640 --> 00:56:00,839
and so that is the

00:55:56,640 --> 00:56:02,000
the end of end of my talk so time for

00:56:00,839 --> 00:56:06,160
questions

00:56:02,000 --> 00:56:06,160
now i believe that

00:56:06,559 --> 00:56:11,119
i would like to think that i've dealt

00:56:08,000 --> 00:56:11,119
with the questions we've got

00:56:11,520 --> 00:56:17,839
so i'm not sure whether any any good any

00:56:14,480 --> 00:56:17,839
threads we've got out here

00:56:17,920 --> 00:56:21,040
there are any good examples canceling a

00:56:19,839 --> 00:56:24,880
thread

00:56:21,040 --> 00:56:29,040
or killing malfunctioning threads

00:56:24,880 --> 00:56:31,760
no if you have a malfunctioning thread

00:56:29,040 --> 00:56:35,680
that is spinning in the background

00:56:31,760 --> 00:56:38,319
then you could kill it with something

00:56:35,680 --> 00:56:39,839
hard hard and brutal like windows

00:56:38,319 --> 00:56:44,000
terminate thread

00:56:39,839 --> 00:56:46,480
but i would not recommend it

00:56:44,000 --> 00:56:47,200
because if you do then you do know do

00:56:46,480 --> 00:56:48,880
not know

00:56:47,200 --> 00:56:50,400
what state that thread has left the rest

00:56:48,880 --> 00:56:53,440
of your sits your

00:56:50,400 --> 00:56:55,520
application if you're wanting to have

00:56:53,440 --> 00:56:58,480
brute force killing in your system then

00:56:55,520 --> 00:57:00,720
i would recommend you don't use threads

00:56:58,480 --> 00:57:02,160
for your concurrency you use processes

00:57:00,720 --> 00:57:02,480
and then you can have a watchdog process

00:57:02,160 --> 00:57:05,280
that

00:57:02,480 --> 00:57:07,200
kills and restarts individual processes

00:57:05,280 --> 00:57:10,079
and that way

00:57:07,200 --> 00:57:10,880
you don't have the the shared memory

00:57:10,079 --> 00:57:12,720
infrastructure

00:57:10,880 --> 00:57:14,480
you know that any mutex is held by that

00:57:12,720 --> 00:57:15,520
crate no it's not mutexes that you're

00:57:14,480 --> 00:57:16,880
wrote about

00:57:15,520 --> 00:57:19,200
whereas if you kill a thread and it

00:57:16,880 --> 00:57:22,000
holds a mutex there's no guarantee

00:57:19,200 --> 00:57:23,040
what state the data was locked it was

00:57:22,000 --> 00:57:24,640
protecting was

00:57:23,040 --> 00:57:26,079
whether or not the os is necessarily

00:57:24,640 --> 00:57:27,440
going to allow somebody else to help get

00:57:26,079 --> 00:57:29,839
the new text lock

00:57:27,440 --> 00:57:31,119
and all sorts of things like that so

00:57:29,839 --> 00:57:34,079
hard killing of

00:57:31,119 --> 00:57:34,640
a malfunctioning thread is a bad idea if

00:57:34,079 --> 00:57:37,359
you

00:57:34,640 --> 00:57:38,319
system needs to do that sort of thing i

00:57:37,359 --> 00:57:42,559
would say

00:57:38,319 --> 00:57:42,559
use processes rather than threads

00:57:44,880 --> 00:57:48,160
and yeah so

00:57:48,640 --> 00:57:55,040
i think that comes to the end of the

00:57:52,400 --> 00:57:56,960
questions that are actually there at the

00:57:55,040 --> 00:58:01,359
moment

00:57:56,960 --> 00:58:03,680
if anybody has anything else

00:58:01,359 --> 00:58:07,200
so new questions come up recommended

00:58:03,680 --> 00:58:10,640
architectures for graph-based talent

00:58:07,200 --> 00:58:10,640
um so

00:58:12,160 --> 00:58:17,599
yes so i'm thinking in terms

00:58:15,440 --> 00:58:17,599
of

00:58:19,200 --> 00:58:27,359
um you have an initial task that then

00:58:23,920 --> 00:58:28,799
spawns you know some some subsets of

00:58:27,359 --> 00:58:30,240
tasks but then

00:58:28,799 --> 00:58:33,119
the data from each of those so we've got

00:58:30,240 --> 00:58:36,799
some form of pipeline infrastructure

00:58:33,119 --> 00:58:39,119
that um

00:58:36,799 --> 00:58:41,760
that you can pass data through whether

00:58:39,119 --> 00:58:43,280
it's just the once or in the series

00:58:41,760 --> 00:58:45,119
i think if you've got a system that

00:58:43,280 --> 00:58:45,839
allows continuations then that works

00:58:45,119 --> 00:58:47,920
really well

00:58:45,839 --> 00:58:49,599
um there's a lot of discussion with the

00:58:47,920 --> 00:58:50,720
standardization committee at the moment

00:58:49,599 --> 00:58:52,559
for

00:58:50,720 --> 00:58:54,960
ways of building such a pipeline that

00:58:52,559 --> 00:58:58,480
looks easy to use

00:58:54,960 --> 00:59:02,000
and the standard the standard ranges

00:58:58,480 --> 00:59:03,359
sort of structure i know seems to work

00:59:02,000 --> 00:59:05,119
quite well

00:59:03,359 --> 00:59:06,720
certainly but obviously that's primarily

00:59:05,119 --> 00:59:10,079
within a single thread

00:59:06,720 --> 00:59:12,640
um that's there's a lot of

00:59:10,079 --> 00:59:14,160
there's there are quite a few pipelining

00:59:12,640 --> 00:59:16,839
style application um

00:59:14,160 --> 00:59:18,319
libraries that you can use for building

00:59:16,839 --> 00:59:21,040
stuff

00:59:18,319 --> 00:59:22,079
and things like that but i i certainly

00:59:21,040 --> 00:59:24,079
haven't got a

00:59:22,079 --> 00:59:26,720
short and pithy answer for recommended

00:59:24,079 --> 00:59:26,720
architectures

00:59:28,799 --> 00:59:35,680
i'm not currently planning on a

00:59:32,079 --> 00:59:40,000
c plus 20 edition of my book

00:59:35,680 --> 00:59:42,559
the um the c plus plus 17

00:59:40,000 --> 00:59:44,480
edition also covers lots of things that

00:59:42,559 --> 00:59:49,280
are in the concurrent cts

00:59:44,480 --> 00:59:49,280
the new additions to c plus plus 20 are

00:59:49,680 --> 00:59:53,200
largely essentially discussed already

00:59:52,079 --> 00:59:55,280
the

00:59:53,200 --> 00:59:56,880
big thing that's missing well there's

00:59:55,280 --> 00:59:59,920
semaphores are not covered

00:59:56,880 --> 01:00:00,559
but semaphores really are quite low

00:59:59,920 --> 01:00:04,000
level

01:00:00,559 --> 01:00:05,040
um and using it so and so you're

01:00:04,000 --> 01:00:07,280
using them correctly you're probably

01:00:05,040 --> 01:00:08,000
going to want to look outside of what i

01:00:07,280 --> 01:00:10,480
would have

01:00:08,000 --> 01:00:12,240
talked about anyway um and then of

01:00:10,480 --> 01:00:13,920
course co-routines but actually

01:00:12,240 --> 01:00:15,920
with c plus plus 20 co routines

01:00:13,920 --> 01:00:17,280
themselves is just a pure infrastructure

01:00:15,920 --> 01:00:20,720
there's no library there

01:00:17,280 --> 01:00:22,720
so i i i don't

01:00:20,720 --> 01:00:24,240
feel that there's too much missing from

01:00:22,720 --> 01:00:27,359
c plus plus 12

01:00:24,240 --> 01:00:29,520
from from the c plus plus 17 edition

01:00:27,359 --> 01:00:31,520
that you would have wanted in to cover

01:00:29,520 --> 01:00:33,359
class plus 20

01:00:31,520 --> 01:00:35,839
so hopefully everything in there is

01:00:33,359 --> 01:00:35,839
still valid

01:00:36,720 --> 01:00:38,960
and

01:00:39,839 --> 01:00:45,119
how does overhead co-routines compare

01:00:41,680 --> 01:00:48,960
with ace income future and job q

01:00:45,119 --> 01:00:52,400
well that really really depends

01:00:48,960 --> 01:00:56,799
on the co routine library

01:00:52,400 --> 01:01:00,480
if you um

01:00:56,799 --> 01:01:02,640
you know and in the in the extreme case

01:01:00,480 --> 01:01:05,680
the co-routine library can have

01:01:02,640 --> 01:01:07,680
no overhead potentially even know what

01:01:05,680 --> 01:01:09,680
amounts to negative overhead because

01:01:07,680 --> 01:01:10,720
the compiler can inline things and

01:01:09,680 --> 01:01:14,319
eliminate some

01:01:10,720 --> 01:01:15,359
some shed something some overhead that

01:01:14,319 --> 01:01:17,280
would have been shed

01:01:15,359 --> 01:01:19,200
on the other hand if your co-routine

01:01:17,280 --> 01:01:21,920
library has been

01:01:19,200 --> 01:01:21,920
designed

01:01:22,799 --> 01:01:28,799
um you know in a less ideal fashion

01:01:26,720 --> 01:01:30,640
and then and there's got lots and lots

01:01:28,799 --> 01:01:33,359
of memory allocation and

01:01:30,640 --> 01:01:34,160
then locking overhead then that might

01:01:33,359 --> 01:01:37,040
end up being

01:01:34,160 --> 01:01:40,319
quite a lot more ahead than would be

01:01:37,040 --> 01:01:44,319
comparable asyncs and futures

01:01:40,319 --> 01:01:47,200
so at the moment then

01:01:44,319 --> 01:01:48,960
i'm not sure that there's any really

01:01:47,200 --> 01:01:49,760
bulletproof co-routine libraries that i

01:01:48,960 --> 01:01:52,079
can

01:01:49,760 --> 01:01:53,359
look at and say yes well if you use

01:01:52,079 --> 01:01:55,839
library xyz

01:01:53,359 --> 01:01:57,760
then i know what the overhead is going

01:01:55,839 --> 01:01:59,920
to be and how that compares

01:01:57,760 --> 01:02:01,440
but really it does depend on how you

01:01:59,920 --> 01:02:04,000
write your library

01:02:01,440 --> 01:02:04,480
obviously if you write it yourself which

01:02:04,000 --> 01:02:07,280
is

01:02:04,480 --> 01:02:08,400
a strong contender at the moment then

01:02:07,280 --> 01:02:10,079
you're in full control

01:02:08,400 --> 01:02:12,000
and you can see quite where all their

01:02:10,079 --> 01:02:14,160
headlights but

01:02:12,000 --> 01:02:15,839
be warned if you try and do that it is

01:02:14,160 --> 01:02:17,760
hard it is

01:02:15,839 --> 01:02:18,880
non-trivial task writing a proper clear

01:02:17,760 --> 01:02:21,839
routine library for

01:02:18,880 --> 01:02:21,839
multi-threading

01:02:22,960 --> 01:02:28,799
okay so i'm going to stop

01:02:26,000 --> 01:02:29,680
taking questions here now and i'm going

01:02:28,799 --> 01:02:35,119
to

01:02:29,680 --> 01:02:38,160
move to just the tables in remo

01:02:35,119 --> 01:02:39,119
so i gonna sit i'm gonna sit on floor

01:02:38,160 --> 01:02:41,839
eight

01:02:39,119 --> 01:02:49,839
in the embedded room and see if anyone's

01:02:41,839 --> 01:02:49,839
got any questions

01:03:03,440 --> 01:03:05,520

YouTube URL: https://www.youtube.com/watch?v=iUKxvEg0zdk


