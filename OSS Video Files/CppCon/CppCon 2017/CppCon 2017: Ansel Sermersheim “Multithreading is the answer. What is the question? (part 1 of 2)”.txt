Title: CppCon 2017: Ansel Sermersheim “Multithreading is the answer. What is the question? (part 1 of 2)”
Publication date: 2017-10-13
Playlist: CppCon 2017
Description: 
	http://CppCon.org
—
Presentation Slides, PDFs, Source Code and other presenter materials are available at: https://github.com/CppCon/CppCon2017
—
The main focus of this talk will be about the importance of lockless containers and RCU technology. The value of this approach will be explained and why it was added to libGuarded. I will also cover recent changes made to the RCU containers. 

I will explain the importance of libGuarded and how it was used in the CsSignal library to prevent deadlocks. 

Either basic familiarity with multithreading or attendance in Part I of this talk is suggested.
— 
Ansel Sermersheim: CopperSpice, Co Founder

I have been working as a programmer for nearly twenty years. My degree is in Computer Science from Cal Poly San Luis  Obispo. I have transitioned to independent consulting and I am currently working on a project for RealtyShares in San Francisco. 

Co-founder of CopperSpice, a C++ GUI library.
Co-founder of DoxyPress, a C++ application for generating documentation. 
Developer of the open source libraries: libGuarded, CsSignal and CsString. 

I have programmed in C++, C, Lisp, Java, and Perl, with extensive knowledge in TCP/IP and mutilthreaded design. I am an  avid follower of the C++ standard. Speaker at CppCon 2015, CppNow 2016, CppNow 2017, and several ACCU Bay Area meetings.
—
Videos Filmed & Edited by Bash Films: http://www.BashFilms.com
Captions: 
	00:00:00,060 --> 00:00:04,440
well welcome everybody and thank you so

00:00:02,580 --> 00:00:06,480
much for being here for multi-threading

00:00:04,440 --> 00:00:08,460
is the answer what is the question a

00:00:06,480 --> 00:00:10,860
title which I wish I could take credit

00:00:08,460 --> 00:00:14,940
for but my co-founder Barbara is the one

00:00:10,860 --> 00:00:17,039
that came up with that one like to take

00:00:14,940 --> 00:00:18,900
a second to set the stage and talk a

00:00:17,039 --> 00:00:21,660
little bit about where we're going to go

00:00:18,900 --> 00:00:23,670
and as we explore what multi-threading

00:00:21,660 --> 00:00:26,010
is we're going to discuss some of the

00:00:23,670 --> 00:00:27,900
terminology that's involved in the

00:00:26,010 --> 00:00:29,340
practice of multi-threading talk about

00:00:27,900 --> 00:00:30,869
the problems you can solve with it and

00:00:29,340 --> 00:00:32,550
the problems that you shouldn't try to

00:00:30,869 --> 00:00:34,860
solve with it which i think is a topic

00:00:32,550 --> 00:00:37,680
that is often overlooked when we discuss

00:00:34,860 --> 00:00:39,629
multi-threading and then I'm going to

00:00:37,680 --> 00:00:41,850
talk about how to review multi-threaded

00:00:39,629 --> 00:00:44,370
code and share with you a better way for

00:00:41,850 --> 00:00:46,950
implementing a multi-threaded design a

00:00:44,370 --> 00:00:49,110
better abstraction for dealing with

00:00:46,950 --> 00:00:53,879
shared data in a multi-threaded program

00:00:49,110 --> 00:00:55,710
a lot of people will say oh

00:00:53,879 --> 00:00:58,649
multi-threading that's that's really

00:00:55,710 --> 00:01:00,390
complicated well it isn't it isn't but

00:00:58,649 --> 00:01:02,640
part of the reason why it can be

00:01:00,390 --> 00:01:05,580
complicated is because it's difficult to

00:01:02,640 --> 00:01:07,140
talk about and when Barbara and I were

00:01:05,580 --> 00:01:09,000
working on copper spice which were the

00:01:07,140 --> 00:01:10,650
cofounders of the copper spice project

00:01:09,000 --> 00:01:14,340
which is an open-source cross-platform

00:01:10,650 --> 00:01:16,830
GUI library we had a section where we

00:01:14,340 --> 00:01:19,470
needed to design some code that would be

00:01:16,830 --> 00:01:21,240
thread safe and we weren't in control of

00:01:19,470 --> 00:01:22,920
how it would be called externally

00:01:21,240 --> 00:01:25,470
because we're in a library so we don't

00:01:22,920 --> 00:01:27,780
know what the user will do and we

00:01:25,470 --> 00:01:29,490
discovered that communicating about a

00:01:27,780 --> 00:01:32,280
multi-threaded piece of code was very

00:01:29,490 --> 00:01:34,170
challenging because for one thing the

00:01:32,280 --> 00:01:36,479
terminology can be confusing and people

00:01:34,170 --> 00:01:38,790
can disagree on what it means and this

00:01:36,479 --> 00:01:40,200
is what happened in our case was we had

00:01:38,790 --> 00:01:42,450
both done a great deal of concurrent

00:01:40,200 --> 00:01:44,280
programming mine had been more on the

00:01:42,450 --> 00:01:46,649
multi-threading side of the equation

00:01:44,280 --> 00:01:50,640
hers had been more on the multi-user

00:01:46,649 --> 00:01:52,770
database context of the equation and in

00:01:50,640 --> 00:01:54,630
a multi-user environment you deal with

00:01:52,770 --> 00:01:56,520
locks and in a multi-threading

00:01:54,630 --> 00:01:58,680
environment you deal with locks and they

00:01:56,520 --> 00:02:01,439
are completely different but we use the

00:01:58,680 --> 00:02:05,850
same word so it's really important to

00:02:01,439 --> 00:02:07,250
get your terminology straight so let's

00:02:05,850 --> 00:02:09,479
start there

00:02:07,250 --> 00:02:12,420
no offense to anyone in the room named

00:02:09,479 --> 00:02:13,360
Bob but the generic C++ programmer named

00:02:12,420 --> 00:02:15,430
Bob

00:02:13,360 --> 00:02:17,020
I have something that I'd like to do and

00:02:15,430 --> 00:02:19,360
I'd like to solve this problem using

00:02:17,020 --> 00:02:22,870
multi-threading there's your first

00:02:19,360 --> 00:02:26,260
mistake if you choose multi-threading as

00:02:22,870 --> 00:02:30,160
the solution before you decide that you

00:02:26,260 --> 00:02:32,560
must you're making a mistake because you

00:02:30,160 --> 00:02:35,230
have more opportunities to shoot

00:02:32,560 --> 00:02:37,630
yourself in the foot because every

00:02:35,230 --> 00:02:40,230
multi-threaded program can be reduced to

00:02:37,630 --> 00:02:42,520
one race condition which crashes and

00:02:40,230 --> 00:02:44,800
you'll have a few memory leaks here and

00:02:42,520 --> 00:02:48,340
there and you will have a high profile

00:02:44,800 --> 00:02:55,120
customer find the bug you didn't unless

00:02:48,340 --> 00:02:57,460
your extraordinarily careful however it

00:02:55,120 --> 00:02:59,650
really helps to be working on a problem

00:02:57,460 --> 00:03:01,870
that is naturally solvable with

00:02:59,650 --> 00:03:03,760
multi-threading because if you try to

00:03:01,870 --> 00:03:06,130
fit multi-threading into an environment

00:03:03,760 --> 00:03:07,720
where it doesn't fit you'll discover

00:03:06,130 --> 00:03:09,460
that it doesn't make sense and you're

00:03:07,720 --> 00:03:13,060
working at cross-purposes with the

00:03:09,460 --> 00:03:15,490
mechanism so really really ask yourself

00:03:13,060 --> 00:03:17,590
is this a problem that I actually want

00:03:15,490 --> 00:03:21,180
to solve with threads is there some

00:03:17,590 --> 00:03:23,620
better way and often the answer is yes

00:03:21,180 --> 00:03:25,150
now in order to have a proper definition

00:03:23,620 --> 00:03:27,040
of all these terms I'm gonna start by

00:03:25,150 --> 00:03:29,110
defining multi-threading itself which

00:03:27,040 --> 00:03:31,239
for our purposes is the ability of a

00:03:29,110 --> 00:03:35,380
program to execute multiple instructions

00:03:31,239 --> 00:03:38,650
at the same time sometimes you might be

00:03:35,380 --> 00:03:40,780
sharing time on a single CPU with other

00:03:38,650 --> 00:03:42,820
threads but the real complexity doesn't

00:03:40,780 --> 00:03:45,550
come in until you have multiple cores

00:03:42,820 --> 00:03:47,680
all processing different stages of

00:03:45,550 --> 00:03:49,840
execution simultaneously and having

00:03:47,680 --> 00:03:53,140
effects on the state of the entire

00:03:49,840 --> 00:03:54,790
program sometimes people like to

00:03:53,140 --> 00:03:57,610
distinguish between concurrency and

00:03:54,790 --> 00:03:59,320
parallelism because concurrency has a

00:03:57,610 --> 00:04:01,239
connotation that threads are working

00:03:59,320 --> 00:04:04,120
together to solve a particular problem

00:04:01,239 --> 00:04:06,459
and parallelism is when the threads

00:04:04,120 --> 00:04:07,900
don't have to work together if you can

00:04:06,459 --> 00:04:10,120
end up in that situation it's great

00:04:07,900 --> 00:04:12,340
because as we all know working solo is

00:04:10,120 --> 00:04:16,590
simpler than working with someone else

00:04:12,340 --> 00:04:16,590
although the solution may not be as good

00:04:18,650 --> 00:04:22,760
there's also multitasking just really

00:04:21,139 --> 00:04:24,580
common in most operating systems any

00:04:22,760 --> 00:04:26,990
operating system worth its salt is a

00:04:24,580 --> 00:04:28,669
multitasking environment these days and

00:04:26,990 --> 00:04:30,350
this is where you get into things like

00:04:28,669 --> 00:04:31,940
I'm slicing I'm not going to go too much

00:04:30,350 --> 00:04:33,500
into that but it's important to

00:04:31,940 --> 00:04:38,060
understand that multitasking is not

00:04:33,500 --> 00:04:40,880
multi-threaded so let's have a quick

00:04:38,060 --> 00:04:46,449
little quiz who here thinks that

00:04:40,880 --> 00:04:51,710
threading makes a program faster anybody

00:04:46,449 --> 00:04:55,610
okay not necessarily it can but it

00:04:51,710 --> 00:04:56,990
doesn't always who wants to write a

00:04:55,610 --> 00:05:00,010
multi-threaded program so it can be

00:04:56,990 --> 00:05:00,010
really stable and reliable

00:05:00,340 --> 00:05:05,449
I'm not saying too many hands and I'm

00:05:02,810 --> 00:05:09,050
seeing some Snickers I'm on the side of

00:05:05,449 --> 00:05:12,350
the Snickers here if you're smart enough

00:05:09,050 --> 00:05:13,910
then multi-threading will be easy I'm

00:05:12,350 --> 00:05:16,580
gonna bash that one right out of the

00:05:13,910 --> 00:05:18,410
gate there is no sufficient level of

00:05:16,580 --> 00:05:22,310
intelligence that makes multi-threading

00:05:18,410 --> 00:05:25,190
trivial and threading might be useful

00:05:22,310 --> 00:05:27,500
for error recovery well it turns out

00:05:25,190 --> 00:05:29,300
it's not threading is actually can be

00:05:27,500 --> 00:05:30,470
more complex for error recovery because

00:05:29,300 --> 00:05:32,479
now you don't know what the state of

00:05:30,470 --> 00:05:33,760
something is if one thread has had a

00:05:32,479 --> 00:05:36,530
problem

00:05:33,760 --> 00:05:38,539
but neither of the last two are true

00:05:36,530 --> 00:05:41,030
either multi-threading is not hard and

00:05:38,539 --> 00:05:43,400
it is not easy it is just a different

00:05:41,030 --> 00:05:45,050
discipline with its own set of

00:05:43,400 --> 00:05:48,849
constraints and requirements and you

00:05:45,050 --> 00:05:48,849
need to be fluent in its language a

00:05:49,599 --> 00:05:55,940
thread is nothing more than work that

00:05:53,300 --> 00:05:58,370
can run on one core at a time a threat

00:05:55,940 --> 00:06:00,139
is part of a process a process consists

00:05:58,370 --> 00:06:03,349
of multiple threads potentially and each

00:06:00,139 --> 00:06:05,870
thread has its own stack so in C++ all

00:06:03,349 --> 00:06:07,610
the state of the stack is local to your

00:06:05,870 --> 00:06:11,410
thread and all this pretty much the

00:06:07,610 --> 00:06:14,030
entire global state of memory is shared

00:06:11,410 --> 00:06:15,440
this is contrasted with a process which

00:06:14,030 --> 00:06:17,720
is really a separate program it's a

00:06:15,440 --> 00:06:20,810
separate memory space it has its own

00:06:17,720 --> 00:06:22,550
copy of everything and we deal with

00:06:20,810 --> 00:06:25,220
processes all the time in our build

00:06:22,550 --> 00:06:26,740
systems make runs a separate process to

00:06:25,220 --> 00:06:29,060
run the compiler things like that

00:06:26,740 --> 00:06:30,520
threads in the same process share a lot

00:06:29,060 --> 00:06:34,389
of resources

00:06:30,520 --> 00:06:36,129
a core a lot of people have sort of an

00:06:34,389 --> 00:06:38,199
intuitive understanding of what a core

00:06:36,129 --> 00:06:39,310
is it's the number of cores is really

00:06:38,199 --> 00:06:41,740
just the number of things that can be

00:06:39,310 --> 00:06:45,789
happening simultaneously in a processor

00:06:41,740 --> 00:06:48,580
to a reasonable approximation and not

00:06:45,789 --> 00:06:50,680
all cores are equal in some environments

00:06:48,580 --> 00:06:52,509
I'll be talking in this session about

00:06:50,680 --> 00:06:54,430
places where all the cores are equal but

00:06:52,509 --> 00:06:56,409
there are cases where they're not and

00:06:54,430 --> 00:06:58,210
things like Numa and a symmetric

00:06:56,409 --> 00:07:03,759
multiprocessing those are more

00:06:58,210 --> 00:07:07,389
specialized topics more cores does not

00:07:03,759 --> 00:07:09,759
mean faster our CI system has six cores

00:07:07,389 --> 00:07:12,280
because it's faster than the eight core

00:07:09,759 --> 00:07:14,199
version of the same chip because when

00:07:12,280 --> 00:07:15,970
they added two extra cores there was

00:07:14,199 --> 00:07:17,919
more heat generated and so they had to

00:07:15,970 --> 00:07:19,780
slow down all of the cores to compensate

00:07:17,919 --> 00:07:21,669
so it turns out the six core machine is

00:07:19,780 --> 00:07:25,080
actually capable of processing things

00:07:21,669 --> 00:07:25,080
much faster than the eight core machine

00:07:27,509 --> 00:07:32,530
the tricky bit if there can be said to

00:07:30,940 --> 00:07:34,539
be only one tricky bit in

00:07:32,530 --> 00:07:38,400
multi-threading is dealing with

00:07:34,539 --> 00:07:41,199
resources correctly a resource is in

00:07:38,400 --> 00:07:43,930
generic terms something which you don't

00:07:41,199 --> 00:07:46,180
want to threads to access simultaneously

00:07:43,930 --> 00:07:49,779
and in common things are a location in

00:07:46,180 --> 00:07:52,389
memory we're fortunate in C++ since C++

00:07:49,779 --> 00:07:54,009
11 we have a well-defined memory model

00:07:52,389 --> 00:07:56,460
so we can actually reason about the

00:07:54,009 --> 00:07:59,669
behavior of the memory in the process

00:07:56,460 --> 00:08:02,529
file handles are not usually thread safe

00:07:59,669 --> 00:08:05,169
and you may have objects that were

00:08:02,529 --> 00:08:07,569
written in your code that are not thread

00:08:05,169 --> 00:08:08,500
safe you must make sure not to access

00:08:07,569 --> 00:08:12,819
them from multiple threads

00:08:08,500 --> 00:08:15,969
simultaneously if you do you have a race

00:08:12,819 --> 00:08:19,330
condition and the exact definition of a

00:08:15,969 --> 00:08:20,979
race condition is contained in C++ is in

00:08:19,330 --> 00:08:23,949
order for a race condition to occur you

00:08:20,979 --> 00:08:26,440
have two accesses to the same location

00:08:23,949 --> 00:08:29,050
in memory and at least one of them is a

00:08:26,440 --> 00:08:31,539
write and it's important to understand

00:08:29,050 --> 00:08:34,690
that constraint because multiple reads

00:08:31,539 --> 00:08:37,329
are okay but if there is a single write

00:08:34,690 --> 00:08:38,860
all other simultaneous access is

00:08:37,329 --> 00:08:40,779
forbidden and if you have two

00:08:38,860 --> 00:08:44,290
simultaneous accesses and one of them is

00:08:40,779 --> 00:08:47,139
a write you will have undefined behavior

00:08:44,290 --> 00:08:49,690
I cannot stress this enough it's not a

00:08:47,139 --> 00:08:52,120
you might get the wrong answer it's not

00:08:49,690 --> 00:08:53,680
a oh well if two threads increment the

00:08:52,120 --> 00:08:55,660
same value at the same time it might

00:08:53,680 --> 00:08:57,639
increment it twice no it is undefined

00:08:55,660 --> 00:08:59,940
behavior pure and simple and there are

00:08:57,639 --> 00:09:02,920
architectures where you can get truly

00:08:59,940 --> 00:09:05,110
bizarre behavior if you have a race

00:09:02,920 --> 00:09:06,970
condition in your program so it is of

00:09:05,110 --> 00:09:09,100
the utmost importance to prevent race

00:09:06,970 --> 00:09:14,380
conditions it's not simply a nice

00:09:09,100 --> 00:09:17,050
property as I mentioned the stack

00:09:14,380 --> 00:09:19,480
belongs to a single thread it's the area

00:09:17,050 --> 00:09:21,550
of memory we use for fixed size objects

00:09:19,480 --> 00:09:26,949
and the heap is shared among all the

00:09:21,550 --> 00:09:30,550
threads fibers are another thing that

00:09:26,949 --> 00:09:32,259
we've used in various dialects of some

00:09:30,550 --> 00:09:34,810
programs there are more of a lightweight

00:09:32,259 --> 00:09:36,730
thread we don't we have these in boost

00:09:34,810 --> 00:09:38,139
fibre they're not that commonly used

00:09:36,730 --> 00:09:40,839
they haven't been standardized into the

00:09:38,139 --> 00:09:43,209
language yet and given the fact that

00:09:40,839 --> 00:09:46,300
co-routines are in the works

00:09:43,209 --> 00:09:48,850
fibers may not make it too far into the

00:09:46,300 --> 00:09:52,540
standardization process at any point I'm

00:09:48,850 --> 00:09:53,800
not quite sure about that you'll also in

00:09:52,540 --> 00:09:56,380
a few languages run into what are called

00:09:53,800 --> 00:09:59,380
green threads for reasons that should be

00:09:56,380 --> 00:10:01,360
lost in the mists of time but these are

00:09:59,380 --> 00:10:03,130
threads that are implemented in user

00:10:01,360 --> 00:10:04,560
space rather than by the operating

00:10:03,130 --> 00:10:07,660
system and they have a lot of

00:10:04,560 --> 00:10:08,949
consequences when your environment uses

00:10:07,660 --> 00:10:10,810
green threads you have to be very

00:10:08,949 --> 00:10:13,449
careful about how you interact because

00:10:10,810 --> 00:10:15,459
if you block you may be potentially

00:10:13,449 --> 00:10:18,760
blocking a large number of other threads

00:10:15,459 --> 00:10:21,010
simultaneously this one is not that

00:10:18,760 --> 00:10:22,899
relevant to C++ but it's good to be

00:10:21,010 --> 00:10:25,449
aware of if you're interpreting with

00:10:22,899 --> 00:10:27,130
other systems in your environment that

00:10:25,449 --> 00:10:30,449
they may have constraints on threading

00:10:27,130 --> 00:10:30,449
that we don't have to work under

00:10:32,820 --> 00:10:37,800
so given all that what do we actually

00:10:35,910 --> 00:10:41,600
want to do with multi-threading now that

00:10:37,800 --> 00:10:41,600
we've defined some of the basic terms

00:10:42,680 --> 00:10:48,150
when do you reach for multi-threading in

00:10:45,690 --> 00:10:51,030
your toolbox well the things I look for

00:10:48,150 --> 00:10:54,420
are if you have a task that can easily

00:10:51,030 --> 00:10:56,130
be split into independent steps this is

00:10:54,420 --> 00:10:58,170
a nice property to have in any problem

00:10:56,130 --> 00:11:00,560
but it also makes it tractable to work

00:10:58,170 --> 00:11:02,940
with in a multi-threaded implementation

00:11:00,560 --> 00:11:05,190
because you might be able to split up

00:11:02,940 --> 00:11:07,920
split it up into independent processes

00:11:05,190 --> 00:11:09,780
that can run it simultaneously it really

00:11:07,920 --> 00:11:14,040
helps if each step has a very clear

00:11:09,780 --> 00:11:16,530
input and output or you have you know

00:11:14,040 --> 00:11:17,790
for a fact that you're extremely CPU

00:11:16,530 --> 00:11:19,440
bound then you're going to be using the

00:11:17,790 --> 00:11:23,850
entire CPU and you would like to use

00:11:19,440 --> 00:11:26,160
more than one CPU it also can be very

00:11:23,850 --> 00:11:28,710
nice for a process that has a large

00:11:26,160 --> 00:11:30,540
read-only data set that never changes

00:11:28,710 --> 00:11:34,740
but it has to be manipulated in various

00:11:30,540 --> 00:11:37,740
ways this is a very natural place to use

00:11:34,740 --> 00:11:39,540
a multi-threaded solution or stream

00:11:37,740 --> 00:11:41,370
processing it's quite common that if you

00:11:39,540 --> 00:11:43,410
have if you can set up your program as

00:11:41,370 --> 00:11:46,170
sort of a data flow diagram where you

00:11:43,410 --> 00:11:47,850
have data streaming in one side passing

00:11:46,170 --> 00:11:50,100
through a set of transformations and

00:11:47,850 --> 00:11:52,080
streaming out the other side it can be

00:11:50,100 --> 00:11:54,360
very natural to set up each of those

00:11:52,080 --> 00:11:57,390
paths along the stream graph or each of

00:11:54,360 --> 00:11:59,160
those nodes along the stream graph as a

00:11:57,390 --> 00:12:01,280
separate thread and you can increase

00:11:59,160 --> 00:12:04,020
your performance considerably there

00:12:01,280 --> 00:12:05,540
these are the problems where you look at

00:12:04,020 --> 00:12:07,740
them and you say ah awesome

00:12:05,540 --> 00:12:12,420
multi-threading will fit I can solve

00:12:07,740 --> 00:12:14,760
this using threads it will be great then

00:12:12,420 --> 00:12:16,890
there are the problems where you have to

00:12:14,760 --> 00:12:19,680
use multi-threading and you wish you

00:12:16,890 --> 00:12:22,170
didn't and these are the ones that

00:12:19,680 --> 00:12:26,310
create interest and complexity in your

00:12:22,170 --> 00:12:28,050
code if you have a task where the

00:12:26,310 --> 00:12:29,760
performance would just be completely

00:12:28,050 --> 00:12:32,970
unacceptable as a single thread if you

00:12:29,760 --> 00:12:34,980
have to use more than one core and you

00:12:32,970 --> 00:12:37,410
have a large data set and it has to be

00:12:34,980 --> 00:12:40,590
maintained synchronously between all of

00:12:37,410 --> 00:12:42,480
the tasks in your program you need to

00:12:40,590 --> 00:12:46,110
consider multi-threading even if it's

00:12:42,480 --> 00:12:46,620
awkward it's also very common that this

00:12:46,110 --> 00:12:48,660
shows up in

00:12:46,620 --> 00:12:50,910
places where you don't know the workload

00:12:48,660 --> 00:12:53,250
ahead of time and in an independent

00:12:50,910 --> 00:12:55,980
array of workers all of which are

00:12:53,250 --> 00:12:59,580
capable of doing whichever task comes

00:12:55,980 --> 00:13:02,190
along at a given time if you have a lot

00:12:59,580 --> 00:13:03,840
of resources like you're an operating

00:13:02,190 --> 00:13:05,790
system you have disk drives you have

00:13:03,840 --> 00:13:08,040
network sockets you have all sorts of

00:13:05,790 --> 00:13:11,280
things that you're managing concurrent

00:13:08,040 --> 00:13:13,230
access to you must be multi-threaded a

00:13:11,280 --> 00:13:16,440
non multi-threaded operating system is

00:13:13,230 --> 00:13:18,150
completely useless at this point and

00:13:16,440 --> 00:13:19,860
it's hard because you have a large

00:13:18,150 --> 00:13:22,440
number of resources to manage and you

00:13:19,860 --> 00:13:23,940
you can't allow contention or you can't

00:13:22,440 --> 00:13:26,720
allow race conditions on the resources

00:13:23,940 --> 00:13:29,070
you have to manage contention and

00:13:26,720 --> 00:13:32,220
there's not a lot of tools for managing

00:13:29,070 --> 00:13:34,980
the complexity there this is another

00:13:32,220 --> 00:13:36,870
case of if you have external clients

00:13:34,980 --> 00:13:39,540
making requests to you or a web server a

00:13:36,870 --> 00:13:41,820
database server anything like that you

00:13:39,540 --> 00:13:44,250
need to handle whatever comes your way

00:13:41,820 --> 00:13:46,350
as quickly as possible and get it out of

00:13:44,250 --> 00:13:47,820
the way for the next request and you

00:13:46,350 --> 00:13:49,020
really probably ought to be looking at a

00:13:47,820 --> 00:13:56,610
multi-threaded solution

00:13:49,020 --> 00:13:59,280
I had a prior job that I had I had a

00:13:56,610 --> 00:14:02,370
real life example of this I was writing

00:13:59,280 --> 00:14:05,190
a streaming video server as a web server

00:14:02,370 --> 00:14:07,770
and the prototype had really bad

00:14:05,190 --> 00:14:09,350
performance it was unable to serve the

00:14:07,770 --> 00:14:11,520
traffic that we needed and for

00:14:09,350 --> 00:14:14,250
production we said okay well let's make

00:14:11,520 --> 00:14:16,980
it as fast as possible and I said well

00:14:14,250 --> 00:14:20,730
how fast as possible well let me make

00:14:16,980 --> 00:14:23,040
this multi-threaded No let me check if I

00:14:20,730 --> 00:14:26,340
can meet my performance goals without

00:14:23,040 --> 00:14:28,590
making this multi-threaded and I simply

00:14:26,340 --> 00:14:30,960
optimized the code and refactor some of

00:14:28,590 --> 00:14:32,700
the internal data structures and all of

00:14:30,960 --> 00:14:34,860
a sudden I was able to saturate the

00:14:32,700 --> 00:14:39,240
network bandwidth that was available to

00:14:34,860 --> 00:14:42,990
us with 12% of one core my job's done

00:14:39,240 --> 00:14:45,690
I'm a UH bound I will get no benefit out

00:14:42,990 --> 00:14:48,450
of multi-threading this code because I'm

00:14:45,690 --> 00:14:50,760
able to serve bits as fast as the

00:14:48,450 --> 00:14:52,320
network can take them away so what

00:14:50,760 --> 00:14:54,819
difference does it make how many cores

00:14:52,320 --> 00:14:58,339
I'm running on to do this

00:14:54,819 --> 00:15:03,399
look for this when you find this be glad

00:14:58,339 --> 00:15:03,399
and avoid multi-threading if you can't

00:15:05,350 --> 00:15:11,839
what I'm going to be talking about here

00:15:07,730 --> 00:15:13,549
is sort of the sweet spot of the generic

00:15:11,839 --> 00:15:15,889
multi-threading environment as I

00:15:13,549 --> 00:15:18,769
mentioned there are some other areas

00:15:15,889 --> 00:15:23,149
that multi-threading is used but this is

00:15:18,769 --> 00:15:25,939
sort of the desktop / mobile / cloud

00:15:23,149 --> 00:15:27,730
typical environment where we have some

00:15:25,939 --> 00:15:30,670
number of cores that you can count

00:15:27,730 --> 00:15:33,529
possibly with taking your shoes off and

00:15:30,670 --> 00:15:35,179
you have you know they're all similar

00:15:33,529 --> 00:15:36,739
cores the memory is fairly close

00:15:35,179 --> 00:15:38,509
together we're not dealing with a

00:15:36,739 --> 00:15:41,149
supercomputer with the memory over in

00:15:38,509 --> 00:15:42,649
the other building so if you have that

00:15:41,149 --> 00:15:48,589
situation you may need additional

00:15:42,649 --> 00:15:50,569
complexity in your design but in order

00:15:48,589 --> 00:15:53,299
to talk about multi-threading I'd like

00:15:50,569 --> 00:15:56,119
to bring in an example and the example

00:15:53,299 --> 00:16:00,079
is a restaurant kitchen and we have a

00:15:56,119 --> 00:16:02,350
couple of chefs and each chef is a

00:16:00,079 --> 00:16:04,759
threat it can do work independently and

00:16:02,350 --> 00:16:06,889
we have two knives each chef has their

00:16:04,759 --> 00:16:09,230
own knife so they can work with the

00:16:06,889 --> 00:16:11,929
knife as needed and do whatever they

00:16:09,230 --> 00:16:15,670
want to do and we say okay we have a big

00:16:11,929 --> 00:16:18,439
order came in we need 50 fruit salads so

00:16:15,670 --> 00:16:23,389
let's have each chef make 25 fruit

00:16:18,439 --> 00:16:25,429
salads now as an aside I really enjoy

00:16:23,389 --> 00:16:27,230
questions I enjoy an interactive

00:16:25,429 --> 00:16:28,850
discussion as we go through this so if

00:16:27,230 --> 00:16:29,990
anybody has questions as I'm going

00:16:28,850 --> 00:16:37,699
through this please feel free to raise

00:16:29,990 --> 00:16:40,669
your hand and the great thing about C++

00:16:37,699 --> 00:16:42,319
and C++ 11 the threading library that

00:16:40,669 --> 00:16:45,259
came in there is the code actually fits

00:16:42,319 --> 00:16:48,319
on a slide because we have a simple

00:16:45,259 --> 00:16:50,449
enough threading system and the library

00:16:48,319 --> 00:16:54,169
is concise enough that this isn't fake

00:16:50,449 --> 00:16:56,809
code this is real code on a slide so I

00:16:54,169 --> 00:16:58,790
set up a thread I name it

00:16:56,809 --> 00:17:00,379
chef 1 that's the name of the variable

00:16:58,790 --> 00:17:03,139
that's going to represent this thread

00:17:00,379 --> 00:17:05,569
and I just pass a lambda to the

00:17:03,139 --> 00:17:08,340
constructor of STD thread I say this is

00:17:05,569 --> 00:17:10,830
the work you will do when you start

00:17:08,340 --> 00:17:15,720
and I'm going to count to 25 and make a

00:17:10,830 --> 00:17:18,540
fruit salad and we do the same thing for

00:17:15,720 --> 00:17:20,970
chef too and then at the end we join

00:17:18,540 --> 00:17:23,460
both and what that means is we're going

00:17:20,970 --> 00:17:26,070
to wait in the main thread until both

00:17:23,460 --> 00:17:27,480
chefs have finished their work and then

00:17:26,070 --> 00:17:29,130
we know that they've completed all the

00:17:27,480 --> 00:17:33,180
fruit salads already and we can serve

00:17:29,130 --> 00:17:38,400
them any optimization that anybody can

00:17:33,180 --> 00:17:43,830
see here does it seem reasonable yeah

00:17:38,400 --> 00:17:46,040
seem to be an agreement on this one I'm

00:17:43,830 --> 00:17:46,040
sorry

00:17:46,580 --> 00:17:51,990
the chef's might work at different

00:17:48,870 --> 00:17:53,700
speeds that is true that is very true

00:17:51,990 --> 00:17:56,310
now in this case since they're doing

00:17:53,700 --> 00:17:59,640
exactly the same work it'll probably be

00:17:56,310 --> 00:18:01,170
roughly the same speed but it's a

00:17:59,640 --> 00:18:03,570
consideration that we need to take into

00:18:01,170 --> 00:18:06,270
account in this case it won't really

00:18:03,570 --> 00:18:08,370
affect anything what it will mean is we

00:18:06,270 --> 00:18:09,780
still get the same result but if one

00:18:08,370 --> 00:18:11,070
chef works at half the speed of the

00:18:09,780 --> 00:18:13,770
other we're not really getting that much

00:18:11,070 --> 00:18:17,460
advantage for multi-threading because

00:18:13,770 --> 00:18:20,780
the slower chef will stall everything so

00:18:17,460 --> 00:18:20,780
that's a good point thank you for that

00:18:21,860 --> 00:18:29,300
so now let's make fifty apple pies now

00:18:26,760 --> 00:18:32,430
we need an oven we have a resource and

00:18:29,300 --> 00:18:34,650
remember you can't use the same resource

00:18:32,430 --> 00:18:36,720
for multiple threads simultaneously at

00:18:34,650 --> 00:18:40,140
least in the definition of resource I'm

00:18:36,720 --> 00:18:42,480
using in this presentation so let's say

00:18:40,140 --> 00:18:50,160
ok let's have each chef make 50 apple

00:18:42,480 --> 00:18:53,280
pies so we set up an oven this is a

00:18:50,160 --> 00:18:57,900
global resource and we set up a mutex to

00:18:53,280 --> 00:19:01,590
protect this oven and each chef is going

00:18:57,900 --> 00:19:03,390
to 25 times make a pie make the crust

00:19:01,590 --> 00:19:04,320
put the apples in the pie get it ready

00:19:03,390 --> 00:19:06,720
to go in the oven

00:19:04,320 --> 00:19:09,510
then lock the mutex so that they know

00:19:06,720 --> 00:19:13,470
that they're the only access or of the

00:19:09,510 --> 00:19:15,800
oven bake the pie any problems with this

00:19:13,470 --> 00:19:15,800
design

00:19:20,730 --> 00:19:25,809
excellent observation you could be

00:19:23,290 --> 00:19:26,980
preparing a more some more crust while

00:19:25,809 --> 00:19:29,559
you're waiting for the oven to be

00:19:26,980 --> 00:19:31,690
available so this is an example of will

00:19:29,559 --> 00:19:34,570
this is a fairly simple example we have

00:19:31,690 --> 00:19:36,580
one resource and two threads and already

00:19:34,570 --> 00:19:39,220
we're getting into issues of we're going

00:19:36,580 --> 00:19:40,900
to be blocking waiting for this resource

00:19:39,220 --> 00:19:48,030
to become available we have contention

00:19:40,900 --> 00:19:48,030
yes sir I'm sorry I couldn't hear that

00:19:49,140 --> 00:19:56,290
he has an oven which allows handles to

00:19:52,300 --> 00:19:59,530
pies simultaneously that would certainly

00:19:56,290 --> 00:20:01,750
be in addition to this some resources

00:19:59,530 --> 00:20:04,360
can be used by some finite number of

00:20:01,750 --> 00:20:06,130
threads simultaneously it's not common

00:20:04,360 --> 00:20:08,650
but it does occur you'd have a slightly

00:20:06,130 --> 00:20:15,490
different design and and behavior here

00:20:08,650 --> 00:20:19,030
but that's a good example so let's make

00:20:15,490 --> 00:20:20,950
things even a little more complex so

00:20:19,030 --> 00:20:23,110
let's take the idea that you could be

00:20:20,950 --> 00:20:24,640
making a crust while the pie is baking

00:20:23,110 --> 00:20:27,760
and let's say instead of having both

00:20:24,640 --> 00:20:30,100
chefs do exactly the same work let's

00:20:27,760 --> 00:20:33,760
have one chef make the pies and the

00:20:30,100 --> 00:20:36,160
other chef put them in the oven now why

00:20:33,760 --> 00:20:40,080
would this be useful does anybody care

00:20:36,160 --> 00:20:40,080
to guess as to why this would be helpful

00:20:42,270 --> 00:20:58,240
yes if they take about the same amount

00:20:55,150 --> 00:20:59,530
of time then that max that minimizes the

00:20:58,240 --> 00:21:01,900
amount of time that somebody's sitting

00:20:59,530 --> 00:21:04,630
and waiting and doing nothing that could

00:21:01,900 --> 00:21:07,230
that could absolutely be true another

00:21:04,630 --> 00:21:07,230
yes

00:21:15,640 --> 00:21:19,160
excellent you're getting it where I was

00:21:17,570 --> 00:21:21,620
going specialization

00:21:19,160 --> 00:21:23,600
one chef might be better at making pies

00:21:21,620 --> 00:21:25,370
the other chef might be better at baking

00:21:23,600 --> 00:21:37,040
them that's a good point I'll come back

00:21:25,370 --> 00:21:40,190
to that yes it'll prevent deadlock

00:21:37,040 --> 00:21:43,250
because you only have one chef trying to

00:21:40,190 --> 00:21:47,480
put a pie in the oven that's that's well

00:21:43,250 --> 00:21:50,990
stated but in this example since we only

00:21:47,480 --> 00:21:53,690
have one resource and each chef locks

00:21:50,990 --> 00:21:57,340
the mutex and then uses the resource and

00:21:53,690 --> 00:21:57,340
unlocks the mutex can we have a deadlock

00:21:57,700 --> 00:22:16,880
and there may be blocking that's true

00:22:14,750 --> 00:22:18,230
that's not a deadlock because it's a

00:22:16,880 --> 00:22:21,620
different situation you'll still

00:22:18,230 --> 00:22:23,420
eventually make progress you just may

00:22:21,620 --> 00:22:26,090
have to wait for the other chef to be

00:22:23,420 --> 00:22:27,710
done with the oven livelock yes you can

00:22:26,090 --> 00:22:29,330
get into a livelock situation if you

00:22:27,710 --> 00:22:31,280
have enough threads all working on this

00:22:29,330 --> 00:22:34,250
simultaneously that is true you can hit

00:22:31,280 --> 00:22:36,740
a live luck there's no deadlock here now

00:22:34,250 --> 00:22:51,200
like I said terminology is exceedingly

00:22:36,740 --> 00:22:53,539
important in this area yes

00:22:51,200 --> 00:22:54,500
yes that is so thank you for for

00:22:53,539 --> 00:22:55,940
bringing in a term that I actually

00:22:54,500 --> 00:22:59,360
didn't have in my slide deck that's

00:22:55,940 --> 00:23:01,309
helpful in this example if one chef is

00:22:59,360 --> 00:23:04,490
fast enough at making pies that they're

00:23:01,309 --> 00:23:06,440
always locking acquiring the lock on the

00:23:04,490 --> 00:23:08,630
oven before the other chef can get their

00:23:06,440 --> 00:23:10,730
pie in the oven then you have starvation

00:23:08,630 --> 00:23:12,110
so one chef could end up completing

00:23:10,730 --> 00:23:14,210
their work much faster than the other

00:23:12,110 --> 00:23:16,039
one because they have better access to

00:23:14,210 --> 00:23:18,380
the shared resource so that's a great

00:23:16,039 --> 00:23:19,880
example in this case since both of them

00:23:18,380 --> 00:23:22,340
are doing a fixed amount of work you

00:23:19,880 --> 00:23:24,169
can't have starvation for an indefinite

00:23:22,340 --> 00:23:26,360
amount of time but it can definitely

00:23:24,169 --> 00:23:28,460
make it so that one thread will complete

00:23:26,360 --> 00:23:30,529
much faster than the other and that can

00:23:28,460 --> 00:23:32,090
be a property that you don't want in

00:23:30,529 --> 00:23:39,139
your system so thank you for bringing

00:23:32,090 --> 00:23:42,110
that up so getting back to the the next

00:23:39,139 --> 00:23:46,490
idea of one chef prepares pies and the

00:23:42,110 --> 00:23:48,019
second chef is going to bake them so in

00:23:46,490 --> 00:23:51,230
order to do this we're going to need

00:23:48,019 --> 00:23:54,590
some way to move the pies from one chef

00:23:51,230 --> 00:23:56,240
to the other so I'm going to for sake of

00:23:54,590 --> 00:23:58,279
argument say that we have a thread-safe

00:23:56,240 --> 00:24:00,529
queue there are plenty of talks that you

00:23:58,279 --> 00:24:02,450
can go to about how to implement a

00:24:00,529 --> 00:24:05,120
thread-safe queue I'm talking more

00:24:02,450 --> 00:24:06,889
abstractly about the way to plug

00:24:05,120 --> 00:24:09,590
together these multi-threading concepts

00:24:06,889 --> 00:24:11,330
into a working solution so we have a

00:24:09,590 --> 00:24:14,269
conveyor belt that will take the pies

00:24:11,330 --> 00:24:16,340
from one chef to the other so now our

00:24:14,269 --> 00:24:20,000
two chefs do completely different things

00:24:16,340 --> 00:24:21,409
chef one in instantiates a pie does

00:24:20,000 --> 00:24:22,909
everything that needs to be done to get

00:24:21,409 --> 00:24:23,779
it ready for the oven and puts it on the

00:24:22,909 --> 00:24:27,740
conveyor belt

00:24:23,779 --> 00:24:29,360
they give the pie away and this is a key

00:24:27,740 --> 00:24:32,059
attribute to look for if you can design

00:24:29,360 --> 00:24:34,309
your code so that you can give away

00:24:32,059 --> 00:24:37,760
ownership of something once you're done

00:24:34,309 --> 00:24:38,690
working on it it is much much easier to

00:24:37,760 --> 00:24:41,179
work with in a multi-threaded

00:24:38,690 --> 00:24:43,279
environment because whenever you have

00:24:41,179 --> 00:24:45,799
shared data remember you can have a race

00:24:43,279 --> 00:24:47,899
condition we don't want to process these

00:24:45,799 --> 00:24:50,840
two threads accessing the same data at

00:24:47,899 --> 00:24:53,059
the same time well if one thread creates

00:24:50,840 --> 00:24:54,799
something does all of the work on it it

00:24:53,059 --> 00:24:56,990
needs to do and then gives it away to

00:24:54,799 --> 00:25:02,450
another thread you can never have shared

00:24:56,990 --> 00:25:04,309
data so in this case we're using move to

00:25:02,450 --> 00:25:06,049
give away our ownership of this pie to

00:25:04,309 --> 00:25:08,460
the conveyor

00:25:06,049 --> 00:25:10,169
and the other chef just stands there

00:25:08,460 --> 00:25:13,830
waiting for a pie to come off the

00:25:10,169 --> 00:25:15,570
conveyor belt pulls it off the belt puts

00:25:13,830 --> 00:25:19,380
it in the oven waits for the oven to

00:25:15,570 --> 00:25:23,520
finish puts another pie in any questions

00:25:19,380 --> 00:25:26,100
on this phrasing of the problem and why

00:25:23,520 --> 00:25:41,370
this is potentially an improvement over

00:25:26,100 --> 00:25:43,080
the previous solution right there I've

00:25:41,370 --> 00:25:45,330
moved the work of synchronizing the

00:25:43,080 --> 00:25:48,500
resource from the pie to the conveyor

00:25:45,330 --> 00:25:52,679
belt very well spotted that's true

00:25:48,500 --> 00:25:55,860
however there is no way that I can allow

00:25:52,679 --> 00:25:57,120
in my universe of this restaurant

00:25:55,860 --> 00:26:00,840
kitchen there's no way I can allow two

00:25:57,120 --> 00:26:02,190
chefs to use the oven simultaneously but

00:26:00,840 --> 00:26:04,140
there might be ways that I could allow

00:26:02,190 --> 00:26:05,730
them one to put a pie on the conveyor

00:26:04,140 --> 00:26:08,309
belt and the other to take it off at the

00:26:05,730 --> 00:26:10,559
same time there are certainly lock less

00:26:08,309 --> 00:26:12,870
queues where we can move data between

00:26:10,559 --> 00:26:16,409
threads without either thread having to

00:26:12,870 --> 00:26:19,710
wait so I may have improved my solution

00:26:16,409 --> 00:26:21,539
by giving myself access to more tools to

00:26:19,710 --> 00:26:25,500
apply to this problem does that address

00:26:21,539 --> 00:26:33,750
your question thank you any other

00:26:25,500 --> 00:26:35,640
comments on that I'm sorry you might

00:26:33,750 --> 00:26:38,520
make too many pies for the conveyor belt

00:26:35,640 --> 00:26:41,490
to hold yes so that's the opposite of

00:26:38,520 --> 00:26:44,250
starvation where one thread gets ahead

00:26:41,490 --> 00:26:46,559
of the process and you might have have

00:26:44,250 --> 00:26:49,559
to have some way to throttle the first

00:26:46,559 --> 00:26:52,669
thread or allow an arbitrary size buffer

00:26:49,559 --> 00:26:55,860
so that it can grow to consume this this

00:26:52,669 --> 00:26:58,909
work backlog that the second thread has

00:26:55,860 --> 00:26:58,909
incurred yes

00:27:00,760 --> 00:27:06,110
the data sharing is still here it's just

00:27:03,470 --> 00:27:07,790
hidden inside the queue which brings up

00:27:06,110 --> 00:27:09,260
a great point about multi-threading in

00:27:07,790 --> 00:27:12,470
general if you can make it somebody

00:27:09,260 --> 00:27:14,270
else's problem do it you know you got a

00:27:12,470 --> 00:27:16,730
thread safe you from somebody maybe a

00:27:14,270 --> 00:27:19,190
lock freak you good for you you don't

00:27:16,730 --> 00:27:21,770
see data sharing anymore yes that that's

00:27:19,190 --> 00:27:23,330
very well stated and in general the best

00:27:21,770 --> 00:27:25,010
strategy for writing a safe

00:27:23,330 --> 00:27:26,960
multi-threaded data structures get it

00:27:25,010 --> 00:27:28,850
from someone else because they've

00:27:26,960 --> 00:27:32,840
probably broken it in at least the ways

00:27:28,850 --> 00:27:36,440
they could discover so you have a better

00:27:32,840 --> 00:27:38,840
chance yes if you acquire a a known safe

00:27:36,440 --> 00:27:41,990
thread safe queue from someone else then

00:27:38,840 --> 00:27:44,630
by all means find a place to use it in

00:27:41,990 --> 00:27:46,940
your program to reduce your larger

00:27:44,630 --> 00:27:48,740
problem to using somebody else's

00:27:46,940 --> 00:27:52,750
solution to an already solved problem is

00:27:48,740 --> 00:27:52,750
very helpful so thank you for that

00:27:53,290 --> 00:28:00,800
so can we hit a deadlock in this case

00:27:58,690 --> 00:28:02,630
not if our thread safe queue is

00:28:00,800 --> 00:28:04,450
implemented correctly because it's the

00:28:02,630 --> 00:28:07,550
only place where both threads are

00:28:04,450 --> 00:28:09,800
operating on simultaneously can we make

00:28:07,550 --> 00:28:11,720
this more optimal well we've talked

00:28:09,800 --> 00:28:14,060
about several ways in which it could be

00:28:11,720 --> 00:28:15,950
better or worse than the preceding

00:28:14,060 --> 00:28:17,990
design depending upon your constraints

00:28:15,950 --> 00:28:19,490
what the costs are for the various

00:28:17,990 --> 00:28:22,610
resources what the costs are for

00:28:19,490 --> 00:28:26,990
synchronization are there any race

00:28:22,610 --> 00:28:29,540
conditions notice this design is correct

00:28:26,990 --> 00:28:31,190
again assuming the code you got from

00:28:29,540 --> 00:28:38,060
somebody else to implement a thread safe

00:28:31,190 --> 00:28:39,620
queue works properly you're done now

00:28:38,060 --> 00:28:42,170
let's deal with the complexity of a real

00:28:39,620 --> 00:28:44,780
commercial kitchen and this is what you

00:28:42,170 --> 00:28:46,970
have you have orders coming in all the

00:28:44,780 --> 00:28:49,550
time for random things you have

00:28:46,970 --> 00:28:51,200
resources you haven't I'm sorry

00:28:49,550 --> 00:28:53,420
let me get slightly ahead of myself

00:28:51,200 --> 00:28:55,490
let's deal with a slightly less complex

00:28:53,420 --> 00:28:57,170
commercial kitchen first where we have

00:28:55,490 --> 00:29:01,640
two things that we need to do the more a

00:28:57,170 --> 00:29:05,110
catering set up so we need 25 fruit

00:29:01,640 --> 00:29:07,570
salads and 25 chicken salads

00:29:05,110 --> 00:29:10,570
which of these strategies sounds like a

00:29:07,570 --> 00:29:12,850
better option we could have each chef

00:29:10,570 --> 00:29:15,309
make a fruit salad clean up his

00:29:12,850 --> 00:29:17,020
workstation make his chicken salad clean

00:29:15,309 --> 00:29:19,450
up his workstation again and do that 25

00:29:17,020 --> 00:29:24,520
times does that sound like a good use of

00:29:19,450 --> 00:29:26,559
time what about one chef makes 25 fruit

00:29:24,520 --> 00:29:27,540
salads the other chef makes 25 chicken

00:29:26,559 --> 00:29:29,830
salads

00:29:27,540 --> 00:29:32,679
does that sound advantageous I get a

00:29:29,830 --> 00:29:35,970
thumbs up would you care to venture a

00:29:32,679 --> 00:29:35,970
reason why this would be a good solution

00:29:38,280 --> 00:29:42,370
we don't spend any time cleaning the

00:29:40,570 --> 00:29:44,410
kitchen well maybe once at the end but

00:29:42,370 --> 00:29:53,020
we save a lot of time during the middle

00:29:44,410 --> 00:29:55,210
absolutely it's a good solution a very

00:29:53,020 --> 00:29:57,370
very good it's a good solution if they

00:29:55,210 --> 00:29:59,260
take about the same time if a fruit

00:29:57,370 --> 00:30:00,910
salad is much faster to make than a

00:29:59,260 --> 00:30:03,760
chicken salad it may not be the best

00:30:00,910 --> 00:30:05,950
solution it might be depending upon what

00:30:03,760 --> 00:30:08,440
you're optimizing for if what you want

00:30:05,950 --> 00:30:10,000
to do is to get the most work done in a

00:30:08,440 --> 00:30:11,830
particular amount of time it might be a

00:30:10,000 --> 00:30:14,320
good solution even though the chicken

00:30:11,830 --> 00:30:18,340
salads will take longer to come out they

00:30:14,320 --> 00:30:19,780
can be reasonable or we can do what we

00:30:18,340 --> 00:30:21,760
don't want to have to do in a

00:30:19,780 --> 00:30:25,660
multi-threaded program and contain some

00:30:21,760 --> 00:30:27,190
shared state where both chefs start out

00:30:25,660 --> 00:30:29,169
working on one thing and then they

00:30:27,190 --> 00:30:31,480
switch over to the other once enough has

00:30:29,169 --> 00:30:32,919
been made this way if one chef works

00:30:31,480 --> 00:30:34,120
slightly faster than the other at the

00:30:32,919 --> 00:30:35,919
beginning we'll still end up with the

00:30:34,120 --> 00:30:38,500
right number and we'll have the lowest

00:30:35,919 --> 00:30:42,990
latency to having all 50 salads

00:30:38,500 --> 00:30:42,990
available does that seem reasonable

00:30:43,169 --> 00:30:48,070
again there's no right answer here these

00:30:46,419 --> 00:30:51,840
are trade-offs it depends on what you're

00:30:48,070 --> 00:30:51,840
optimizing for in your particular case

00:30:53,520 --> 00:31:01,570
now let's talk about a real kitchen we

00:30:59,860 --> 00:31:03,040
have a lot of resources they all do

00:31:01,570 --> 00:31:05,020
different things they're all unique

00:31:03,040 --> 00:31:07,990
they can't be substituted for one

00:31:05,020 --> 00:31:10,059
another and anybody can just walk up to

00:31:07,990 --> 00:31:13,990
the corner and the counter and order

00:31:10,059 --> 00:31:16,419
whatever they would like at any time how

00:31:13,990 --> 00:31:18,490
do you optimize for this you don't know

00:31:16,419 --> 00:31:19,660
the workload you don't know

00:31:18,490 --> 00:31:21,340
how long your chefs are going to take

00:31:19,660 --> 00:31:23,559
you don't know what's gonna be busy when

00:31:21,340 --> 00:31:24,210
you go to try to fill an order what do

00:31:23,559 --> 00:31:27,840
you do

00:31:24,210 --> 00:31:31,390
this is the real multi-threading problem

00:31:27,840 --> 00:31:33,250
this is not the simple one that you like

00:31:31,390 --> 00:31:34,600
to solve with multi-threading this is

00:31:33,250 --> 00:31:38,530
the one you have when you have no other

00:31:34,600 --> 00:31:40,720
choice so let's start working through

00:31:38,530 --> 00:31:44,200
this and develop this example and see

00:31:40,720 --> 00:31:47,080
how we can apply the tools in C++ 11 to

00:31:44,200 --> 00:31:49,270
this so that we can make some sense of

00:31:47,080 --> 00:31:50,890
it and then in the next section I'll

00:31:49,270 --> 00:31:52,750
show you some additional tools that we

00:31:50,890 --> 00:31:54,640
can build on top of the language to

00:31:52,750 --> 00:31:59,290
reduce the complexity of this solution

00:31:54,640 --> 00:32:01,480
and make it more tractable so first

00:31:59,290 --> 00:32:05,350
let's set up our resources so we have an

00:32:01,480 --> 00:32:07,600
oven and we have now - because we need

00:32:05,350 --> 00:32:10,860
the Viking oven for baking pies and we

00:32:07,600 --> 00:32:13,059
need the brick oven for baking pizza and

00:32:10,860 --> 00:32:14,890
the brick oven will be used for both the

00:32:13,059 --> 00:32:16,330
pizza and the garlic knots so now I have

00:32:14,890 --> 00:32:18,550
a resource that's shared among multiple

00:32:16,330 --> 00:32:20,800
different things that I might be working

00:32:18,550 --> 00:32:23,380
on as well and I have an ice cream maker

00:32:20,800 --> 00:32:26,650
and we declare mutexes for each one of

00:32:23,380 --> 00:32:29,470
these so that we can make an manage the

00:32:26,650 --> 00:32:31,720
resource contention and enforce that

00:32:29,470 --> 00:32:34,360
only one chef will use them at a given

00:32:31,720 --> 00:32:36,370
time I have a bunch of classes I have a

00:32:34,360 --> 00:32:42,730
class hierarchy of the various foods

00:32:36,370 --> 00:32:43,950
that people might want to eat and what I

00:32:42,730 --> 00:32:46,090
really want to do is eat some food

00:32:43,950 --> 00:32:47,890
that's the ultimate goal of this

00:32:46,090 --> 00:32:51,490
exercise everything else is just

00:32:47,890 --> 00:32:53,170
machinery always identify the output in

00:32:51,490 --> 00:32:55,240
a multi-threaded program and try to work

00:32:53,170 --> 00:32:59,080
back from there to see what machinery

00:32:55,240 --> 00:33:00,760
you need underlying the solution so in

00:32:59,080 --> 00:33:02,590
order to eat something I need to consume

00:33:00,760 --> 00:33:05,050
food so I'm gonna consume it by our

00:33:02,590 --> 00:33:09,070
value reference because once I'm done

00:33:05,050 --> 00:33:10,660
with it it's no longer edible so I'm

00:33:09,070 --> 00:33:13,890
just going to print a message that says

00:33:10,660 --> 00:33:16,350
I was successfully served my food and

00:33:13,890 --> 00:33:19,750
I'm going to set up a couple of tickets

00:33:16,350 --> 00:33:23,770
so we're going to use the future and

00:33:19,750 --> 00:33:25,630
promise system in C++ 11 and I look at

00:33:23,770 --> 00:33:27,910
the future and promise system as the

00:33:25,630 --> 00:33:29,500
equivalent of the ticket you get when

00:33:27,910 --> 00:33:31,690
you order a sandwich is a sandwich shop

00:33:29,500 --> 00:33:33,670
it gets split in the two half

00:33:31,690 --> 00:33:35,920
one half goes to the chef it tells the

00:33:33,670 --> 00:33:38,140
chef what work I would like you to do

00:33:35,920 --> 00:33:40,630
this is the sandwich I want I get the

00:33:38,140 --> 00:33:42,700
other half later on when the work is

00:33:40,630 --> 00:33:45,940
done we can pair them up I get my result

00:33:42,700 --> 00:33:47,940
I get my food so this is the future

00:33:45,940 --> 00:33:50,260
promise system and this is the value of

00:33:47,940 --> 00:33:52,840
doing this rather than some other

00:33:50,260 --> 00:33:58,179
mechanism for getting data back from

00:33:52,840 --> 00:34:00,780
another thread and you'll note that

00:33:58,179 --> 00:34:03,760
these are working with unique pointers

00:34:00,780 --> 00:34:06,370
the the T inside the future and promise

00:34:03,760 --> 00:34:09,429
are unique pointers unique pointer is

00:34:06,370 --> 00:34:12,820
the best feature that they added to the

00:34:09,429 --> 00:34:14,590
threading library in C++ 11 because

00:34:12,820 --> 00:34:17,669
unique pointer is a fantastic tool for

00:34:14,590 --> 00:34:23,649
preventing shared data and if you can

00:34:17,669 --> 00:34:25,210
prevent shared data so I've got a couple

00:34:23,649 --> 00:34:26,649
of patrons and they're going to come up

00:34:25,210 --> 00:34:31,440
and they're going to order random things

00:34:26,649 --> 00:34:35,050
in a random order and then eat them and

00:34:31,440 --> 00:34:37,300
note that when we call eat we're passing

00:34:35,050 --> 00:34:39,909
it we're using the the ticket that we

00:34:37,300 --> 00:34:42,490
got back we're using the future and

00:34:39,909 --> 00:34:44,320
we're calling get and when we call get

00:34:42,490 --> 00:34:46,690
the patron is going to sit at their

00:34:44,320 --> 00:34:48,609
table and wait until that particular

00:34:46,690 --> 00:34:50,169
food is available and then it will

00:34:48,609 --> 00:34:53,679
become available it will show up in your

00:34:50,169 --> 00:34:56,020
local thread and you can eat it or if

00:34:53,679 --> 00:34:57,970
the chef gave up and there was a problem

00:34:56,020 --> 00:35:00,580
like the oven caught on fire and it

00:34:57,970 --> 00:35:02,440
couldn't finish making the food when you

00:35:00,580 --> 00:35:05,170
sit to try to eat the food what you eat

00:35:02,440 --> 00:35:06,430
instead will be an exception and you can

00:35:05,170 --> 00:35:08,560
catch that exception and do whatever

00:35:06,430 --> 00:35:10,180
you'd like with it at that point but

00:35:08,560 --> 00:35:12,430
this is a very useful tool because it

00:35:10,180 --> 00:35:14,290
means that remember I was mentioning

00:35:12,430 --> 00:35:17,170
multi-threading does not always make

00:35:14,290 --> 00:35:18,460
your program more reliable well at least

00:35:17,170 --> 00:35:20,770
we have a way to manage the

00:35:18,460 --> 00:35:22,660
unreliability because we will get an

00:35:20,770 --> 00:35:25,710
exception if the other thread fails to

00:35:22,660 --> 00:35:25,710
complete its promise

00:35:28,230 --> 00:35:33,610
we're going to set up an order that is a

00:35:31,750 --> 00:35:37,420
thing that can be passed around so that

00:35:33,610 --> 00:35:39,100
we know what to work on and we set up a

00:35:37,420 --> 00:35:40,600
flag that says is the restaurant still

00:35:39,100 --> 00:35:43,150
open because we need to know when to

00:35:40,600 --> 00:35:45,070
send the chef's home and since we can't

00:35:43,150 --> 00:35:46,810
send the chef's home we need to set a

00:35:45,070 --> 00:35:48,340
flag in a place that they can see it

00:35:46,810 --> 00:35:50,500
when they're done working on an order

00:35:48,340 --> 00:35:53,530
and leave and go home of their own

00:35:50,500 --> 00:35:57,340
accord and the chef's actually become

00:35:53,530 --> 00:36:01,360
very simple we just take another order

00:35:57,340 --> 00:36:04,450
off the queue and we work on it this

00:36:01,360 --> 00:36:09,160
looks fairly straightforward well what

00:36:04,450 --> 00:36:12,070
does it order actually do well an order

00:36:09,160 --> 00:36:14,380
is nothing more than a wrapper for work

00:36:12,070 --> 00:36:16,270
that is to be done this is also

00:36:14,380 --> 00:36:20,530
sometimes called a work unit in a

00:36:16,270 --> 00:36:24,610
threading system so when I want to order

00:36:20,530 --> 00:36:27,700
some pizza I'm going to set up a future

00:36:24,610 --> 00:36:31,180
promise pair to set up this chef's

00:36:27,700 --> 00:36:33,970
ticket that I have and then I'm going to

00:36:31,180 --> 00:36:36,430
encode in the order all the work that I

00:36:33,970 --> 00:36:39,040
want done by the chef so I want the

00:36:36,430 --> 00:36:41,710
chef's to go make a new pizza add the

00:36:39,040 --> 00:36:44,440
sauce add the cheese go acquire the lock

00:36:41,710 --> 00:36:48,490
on the brick oven bake the pizza and

00:36:44,440 --> 00:36:50,740
then give the pizza back to me this

00:36:48,490 --> 00:36:52,180
whole setup returns immediately because

00:36:50,740 --> 00:36:54,850
I'm not actually asking the work to be

00:36:52,180 --> 00:36:57,490
done I'm just saying this is the work I

00:36:54,850 --> 00:37:00,940
would like to have done later by someone

00:36:57,490 --> 00:37:03,550
else so this order pizza method returns

00:37:00,940 --> 00:37:06,310
immediately and returns the future that

00:37:03,550 --> 00:37:07,660
says at some point in the future when

00:37:06,310 --> 00:37:09,880
the chef gets around to it and all of

00:37:07,660 --> 00:37:15,720
this work is done you will have a pizza

00:37:09,880 --> 00:37:19,360
in front of you that's our promise if

00:37:15,720 --> 00:37:24,340
you're in C++ 14 you can capture by move

00:37:19,360 --> 00:37:26,520
of the the promise which means you don't

00:37:24,340 --> 00:37:29,140
need a shared pointer to do this

00:37:26,520 --> 00:37:32,610
asou plus + 11 lambdas didn't quite have

00:37:29,140 --> 00:37:32,610
all this functionality available

00:37:34,880 --> 00:37:43,350
so one of the consequences of this well

00:37:39,840 --> 00:37:47,240
okay we have a single queue so we might

00:37:43,350 --> 00:37:50,580
have contention on the queue of orders

00:37:47,240 --> 00:37:52,620
so what could we do about that well if

00:37:50,580 --> 00:37:54,990
we split it up into multiple queues one

00:37:52,620 --> 00:37:56,760
for each chef then it can potentially be

00:37:54,990 --> 00:37:59,310
much faster because each chef has to

00:37:56,760 --> 00:38:00,750
only check one queue but then what if

00:37:59,310 --> 00:38:02,910
the chef is sitting there waiting for

00:38:00,750 --> 00:38:04,950
work and there's stuff to do in another

00:38:02,910 --> 00:38:06,480
chef's queue so now you go look at the

00:38:04,950 --> 00:38:08,640
other chefs queue and steal the work

00:38:06,480 --> 00:38:11,880
from them this is work stealing it's a

00:38:08,640 --> 00:38:14,130
very common attribute in thread pools so

00:38:11,880 --> 00:38:16,710
in order to implement correctly and

00:38:14,130 --> 00:38:18,810
efficiently a work queue there's a lot

00:38:16,710 --> 00:38:21,780
of complexity that goes into this again

00:38:18,810 --> 00:38:23,550
try to get one don't write it yourself

00:38:21,780 --> 00:38:27,210
there's a lot of tricks to doing this

00:38:23,550 --> 00:38:28,500
properly a chef really shouldn't be

00:38:27,210 --> 00:38:30,960
sitting there waiting for a pizza to

00:38:28,500 --> 00:38:32,430
bake because we're wasting an entire

00:38:30,960 --> 00:38:34,680
thread just sitting there doing nothing

00:38:32,430 --> 00:38:42,380
staring in an oven waiting for it to be

00:38:34,680 --> 00:38:42,380
done and if you go back a little bit

00:38:43,160 --> 00:38:48,660
this locking it's kind of arbitrary

00:38:46,520 --> 00:38:51,240
there's a thing called a brick oven

00:38:48,660 --> 00:38:55,410
mutex and there's a thing called a brick

00:38:51,240 --> 00:38:58,050
oven and you have to lock one before you

00:38:55,410 --> 00:39:02,540
use the other there ought to be a better

00:38:58,050 --> 00:39:02,540
way so think on that

00:39:08,660 --> 00:39:13,559
now before I move on to the second part

00:39:12,119 --> 00:39:17,190
I'll take a few minutes to talk about

00:39:13,559 --> 00:39:19,799
some miscellaneous advice for how

00:39:17,190 --> 00:39:22,349
threads should be pulled together in a

00:39:19,799 --> 00:39:25,859
program and what to look for when you're

00:39:22,349 --> 00:39:29,130
writing multi-threading code this is a

00:39:25,859 --> 00:39:32,369
really common mistake if you have too

00:39:29,130 --> 00:39:34,049
many threads runnable at a given time it

00:39:32,369 --> 00:39:36,450
can be very slow in the operating system

00:39:34,049 --> 00:39:37,799
this is usually not what you want when

00:39:36,450 --> 00:39:39,900
people start working with threads to

00:39:37,799 --> 00:39:41,450
think okay I have 500 things I want to

00:39:39,900 --> 00:39:44,279
do so I'll start a thread for each one

00:39:41,450 --> 00:39:47,069
and that's not what you want what you

00:39:44,279 --> 00:39:48,839
want is some number of threads roughly

00:39:47,069 --> 00:39:51,059
proportional to the number of cores on

00:39:48,839 --> 00:39:52,589
your system depending upon your design

00:39:51,059 --> 00:39:54,569
it might be one to one or it might be

00:39:52,589 --> 00:39:57,569
two to one I've seen some cases where

00:39:54,569 --> 00:40:00,089
that's useful where you have one set of

00:39:57,569 --> 00:40:02,519
threads that's doing a very complex CPU

00:40:00,089 --> 00:40:03,690
bound operation and you have another set

00:40:02,519 --> 00:40:06,329
of threads that handles all the i/o

00:40:03,690 --> 00:40:08,759
bound operations and each of those

00:40:06,329 --> 00:40:10,469
should be represented on a single core

00:40:08,759 --> 00:40:16,200
so you need two threads for each core

00:40:10,469 --> 00:40:19,109
and the total system so you really want

00:40:16,200 --> 00:40:22,529
to aim for one or two active cores the

00:40:19,109 --> 00:40:27,210
active threads per core Moore is not

00:40:22,529 --> 00:40:30,089
really a great thing we want to really

00:40:27,210 --> 00:40:32,160
move the blocking calls out to ancillary

00:40:30,089 --> 00:40:35,519
threads so you really want to see if you

00:40:32,160 --> 00:40:38,789
can partition your work into CPU bound

00:40:35,519 --> 00:40:40,859
and i/o bound components and then split

00:40:38,789 --> 00:40:43,140
this apart into separate pools of

00:40:40,859 --> 00:40:45,269
threads this can really improve your

00:40:43,140 --> 00:40:47,219
performance in areas like network

00:40:45,269 --> 00:40:51,769
servers that are doing a lot of

00:40:47,219 --> 00:40:51,769
processing but also doing a lot of i/o

00:40:54,289 --> 00:40:59,460
too much shared data I know I've said

00:40:57,239 --> 00:41:02,400
this a few times I can't repeat it

00:40:59,460 --> 00:41:04,079
enough times if you have shared data you

00:41:02,400 --> 00:41:06,450
have the potential for a race condition

00:41:04,079 --> 00:41:07,950
the less potential you have for a race

00:41:06,450 --> 00:41:12,150
condition the more correct your code

00:41:07,950 --> 00:41:14,789
will be so really try hard when

00:41:12,150 --> 00:41:16,499
formulating your problem to reduce the

00:41:14,789 --> 00:41:19,529
set of shared data that you have to work

00:41:16,499 --> 00:41:20,420
with reduce the size of the shared data

00:41:19,529 --> 00:41:22,880
that you have to work

00:41:20,420 --> 00:41:24,860
with maybe even compute some values

00:41:22,880 --> 00:41:26,990
individually in each thread rather than

00:41:24,860 --> 00:41:29,870
fetching it from a common location it

00:41:26,990 --> 00:41:31,640
will often be an improvement reduce the

00:41:29,870 --> 00:41:34,150
number of threads that need shared data

00:41:31,640 --> 00:41:36,290
if you do have some need for sharing

00:41:34,150 --> 00:41:38,030
it's really the same idea as

00:41:36,290 --> 00:41:40,220
encapsulation that we've all been doing

00:41:38,030 --> 00:41:42,590
as object-oriented programmers for many

00:41:40,220 --> 00:41:45,770
years for those of you that actually use

00:41:42,590 --> 00:41:48,800
the object-oriented part of C++ trying

00:41:45,770 --> 00:41:51,650
to compartmentalize your systems so that

00:41:48,800 --> 00:41:53,090
the number of parts of the system that

00:41:51,650 --> 00:41:58,270
have access to shared data

00:41:53,090 --> 00:41:58,270
simultaneously is the minimum feasible

00:42:00,220 --> 00:42:10,250
and this should be your main design goal

00:42:05,140 --> 00:42:14,320
it is often more efficient to reduce the

00:42:10,250 --> 00:42:14,320
amount of shared data and duplicate work

00:42:14,380 --> 00:42:23,030
and if you do have shared data and you

00:42:19,670 --> 00:42:25,790
can make it read-only huge win read-only

00:42:23,030 --> 00:42:27,650
data is better for caching it's also

00:42:25,790 --> 00:42:30,080
better for reasoning about the behavior

00:42:27,650 --> 00:42:32,840
of the system oftentimes you can set up

00:42:30,080 --> 00:42:35,960
a system where you create a large shared

00:42:32,840 --> 00:42:37,640
data structure initially but then once

00:42:35,960 --> 00:42:39,770
the process is up and running the

00:42:37,640 --> 00:42:42,710
individual threads only need read access

00:42:39,770 --> 00:42:46,070
to the shared data structure if you can

00:42:42,710 --> 00:42:48,740
do this do so market Const make it very

00:42:46,070 --> 00:42:51,290
explicit that this data is read-only and

00:42:48,740 --> 00:42:52,940
you will know that once you've reached

00:42:51,290 --> 00:42:55,820
that point in your program where the

00:42:52,940 --> 00:42:59,780
data is no longer written to your code

00:42:55,820 --> 00:43:01,370
is race condition free and we aim for an

00:42:59,780 --> 00:43:04,580
environment where you can look at a

00:43:01,370 --> 00:43:06,860
piece of code and say I know a priori

00:43:04,580 --> 00:43:08,600
that piece of code is race condition

00:43:06,860 --> 00:43:11,090
free because I can reason about its

00:43:08,600 --> 00:43:13,670
behavior and I know what it's doing when

00:43:11,090 --> 00:43:16,310
it accesses shared data if you don't

00:43:13,670 --> 00:43:18,470
have that property then you have to work

00:43:16,310 --> 00:43:21,970
through each example separately and I'll

00:43:18,470 --> 00:43:21,970
talk more about that in the second half

00:43:22,840 --> 00:43:29,390
so as I just said the property that

00:43:26,780 --> 00:43:32,420
we're aiming for is as little shared

00:43:29,390 --> 00:43:34,580
writable data as possible

00:43:32,420 --> 00:43:37,520
that is the number one concern that

00:43:34,580 --> 00:43:43,070
should drive your your data structure

00:43:37,520 --> 00:43:45,710
design in your program now when you're

00:43:43,070 --> 00:43:48,980
reviewing multi-threaded code there are

00:43:45,710 --> 00:43:52,700
many things to look for and there are

00:43:48,980 --> 00:43:58,330
better ways to arrange your code your

00:43:52,700 --> 00:43:58,330
data and your access to the data and

00:43:59,080 --> 00:44:09,260
stick around for part two if any of this

00:44:06,650 --> 00:44:11,000
interests you or if you're interested in

00:44:09,260 --> 00:44:13,850
any of the other projects that we've

00:44:11,000 --> 00:44:16,100
worked on you can definitely come find

00:44:13,850 --> 00:44:18,170
us on YouTube please do subscribe to our

00:44:16,100 --> 00:44:20,710
YouTube channel we have content coming

00:44:18,170 --> 00:44:22,970
out every two weeks about C++

00:44:20,710 --> 00:44:24,790
multi-threading copper spice and the

00:44:22,970 --> 00:44:27,680
various other projects that we work on

00:44:24,790 --> 00:44:29,450
it's of general interest to the C++

00:44:27,680 --> 00:44:34,700
community even if you're not using our

00:44:29,450 --> 00:44:37,190
libraries some of the things that we've

00:44:34,700 --> 00:44:39,380
worked on include copper spice as I

00:44:37,190 --> 00:44:43,100
mentioned it's a library cross-platform

00:44:39,380 --> 00:44:45,440
GUI library we've also refactored out of

00:44:43,100 --> 00:44:49,390
that the cs signal library which is a

00:44:45,440 --> 00:44:51,950
thread aware signal delivery mechanism

00:44:49,390 --> 00:44:54,680
this is actually a large part of what

00:44:51,950 --> 00:44:57,200
drove this talk was developing the CS

00:44:54,680 --> 00:45:01,130
signal library and encountering some of

00:44:57,200 --> 00:45:02,510
the challenges in working with a library

00:45:01,130 --> 00:45:04,970
that needs to be thread safe in this

00:45:02,510 --> 00:45:07,340
context there's also the CS string

00:45:04,970 --> 00:45:11,060
library which is our standalone Unicode

00:45:07,340 --> 00:45:13,730
aware both utf-8 and utf-16 support

00:45:11,060 --> 00:45:15,170
string library and Lib guarded which

00:45:13,730 --> 00:45:19,430
will be the subject of the second half

00:45:15,170 --> 00:45:21,530
of this talk and some additional

00:45:19,430 --> 00:45:23,180
programs that we've worked on kitchen

00:45:21,530 --> 00:45:24,890
sink is a demo application if you're

00:45:23,180 --> 00:45:25,720
interested in copper spice and how it

00:45:24,890 --> 00:45:28,370
works

00:45:25,720 --> 00:45:30,260
Diamond which is a programmers editor

00:45:28,370 --> 00:45:32,380
written in copper spice very lightweight

00:45:30,260 --> 00:45:34,970
cross-platform programmers editor and

00:45:32,380 --> 00:45:37,460
doc C press which is a documentation

00:45:34,970 --> 00:45:41,480
generator that uses clang on the front

00:45:37,460 --> 00:45:43,960
end for correct documentation of C++

00:45:41,480 --> 00:45:43,960
source code

00:45:45,090 --> 00:45:51,390
our information is available all online

00:45:47,400 --> 00:45:53,970
and you can contact us through email we

00:45:51,390 --> 00:45:55,680
welcome comments and questions and now

00:45:53,970 --> 00:46:08,570
I'll turn the floor open to questions

00:45:55,680 --> 00:46:08,570
here in the room comments observations

00:46:10,070 --> 00:46:17,670
all right well in the next session I'll

00:46:15,090 --> 00:46:20,910
be going over the entire design of Lib

00:46:17,670 --> 00:46:23,310
guarded which is a system for managing

00:46:20,910 --> 00:46:25,110
access to shared data in a

00:46:23,310 --> 00:46:27,240
multi-threaded environment without

00:46:25,110 --> 00:46:30,840
losing your mind and without invoking

00:46:27,240 --> 00:46:32,820
race conditions and I hope you stick

00:46:30,840 --> 00:46:34,890
around for that because I'll be going

00:46:32,820 --> 00:46:37,050
much deeper into this example and

00:46:34,890 --> 00:46:40,170
showing you how to reduce the complexity

00:46:37,050 --> 00:46:45,050
of what we've developed in our

00:46:40,170 --> 00:46:45,050
multi-threading vocabulary at this point

00:46:45,860 --> 00:46:53,090
thank you

00:46:47,100 --> 00:46:53,090

YouTube URL: https://www.youtube.com/watch?v=GNw3RXr-VJk


