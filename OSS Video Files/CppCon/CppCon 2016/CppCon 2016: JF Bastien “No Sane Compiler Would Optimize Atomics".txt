Title: CppCon 2016: JF Bastien “No Sane Compiler Would Optimize Atomics"
Publication date: 2016-09-30
Playlist: CppCon 2016
Description: 
	http://CppCon.org
—
Presentation Slides, PDFs, Source Code and other presenter materials are available at: https://github.com/cppcon/cppcon2016
—
False. 

Compilers do optimize atomics, memory accesses around atomics, and utilize architecture-specific knowledge. My hobby is to encourage compilers to do more of this, programmers to rely on it, and hardware vendors to give us new atomic toys to optimize with. Oh, and standardize yet more close-to-the-metal concurrency and parallelism tools. 

But, you say, surely volatile always means volatile, there’s nothing wrong with my benign races, nothing could even go wrong with non-temporal accesses, and who needs 6 memory orderings anyways‽ I’m glad you asked, let me tell you about my hobby…
— 
JF Bastien
Jest-in-Time Compiler, template
JF Bastien is a compiler engineer, currently focusing on performance and security to bring portable, fast and secure code to the Web. JF is a member of the C++ standards committee, where his mechanical engineering degree serves little purpose. He’s worked on startup incubators, business jets, flight simulators, CPUs, dynamic binary translation, systems, and compilers.
—
Videos Filmed & Edited by Bash Films: http://www.BashFilms.com
Captions: 
	00:00:00,030 --> 00:00:04,470
hi everyone thanks for coming my name is

00:00:01,860 --> 00:00:06,359
Jeff Passan I'm a compiler engineer and

00:00:04,470 --> 00:00:08,670
also a member of the super stands

00:00:06,359 --> 00:00:11,610
committee so today I'm going to talk

00:00:08,670 --> 00:00:14,009
about an interesting topic Atomics and

00:00:11,610 --> 00:00:16,500
specifically no single compiler would

00:00:14,009 --> 00:00:18,600
optimize Atomics now this is a very

00:00:16,500 --> 00:00:21,240
clickbait title with a clickbait

00:00:18,600 --> 00:00:22,980
abstract false so the premise that I

00:00:21,240 --> 00:00:25,140
have is that compilers do optimize

00:00:22,980 --> 00:00:26,820
Atomics and it's not a silly thing right

00:00:25,140 --> 00:00:28,769
they don't just talk to my stomach's

00:00:26,820 --> 00:00:30,000
they've optimized around the tonics they

00:00:28,769 --> 00:00:32,040
use a bunch of architecture specific

00:00:30,000 --> 00:00:33,450
knowledge to optimize things and it's

00:00:32,040 --> 00:00:36,270
kind of fun to optimize things when it

00:00:33,450 --> 00:00:37,500
gives you a performance win and

00:00:36,270 --> 00:00:39,480
furthermore I think that hardware

00:00:37,500 --> 00:00:41,219
vendors should give us no atomic toys

00:00:39,480 --> 00:00:43,050
taught to my stuff better so we can you

00:00:41,219 --> 00:00:46,320
use multiple cores in an interesting way

00:00:43,050 --> 00:00:47,520
and the standard should also get better

00:00:46,320 --> 00:00:49,500
when it exposes

00:00:47,520 --> 00:00:51,780
Atomics right so I try to convince you

00:00:49,500 --> 00:00:54,059
today that that's actually a good thing

00:00:51,780 --> 00:00:58,199
all right now a quick disclaimer here

00:00:54,059 --> 00:01:04,049
the this is this is my mental model of

00:00:58,199 --> 00:01:06,450
lottery code right so my goal today is

00:01:04,049 --> 00:01:08,760
not to convince you to use Atomics right

00:01:06,450 --> 00:01:10,950
my goal today is maybe to dissuade you

00:01:08,760 --> 00:01:13,560
from doing so because it's actually kind

00:01:10,950 --> 00:01:14,430
of hard and I recommend that you watch a

00:01:13,560 --> 00:01:15,750
fatalist

00:01:14,430 --> 00:01:17,009
talk that he gave maybe Monday or

00:01:15,750 --> 00:01:19,530
something like that and the talk that

00:01:17,009 --> 00:01:21,119
Hans gave yesterday because they dive

00:01:19,530 --> 00:01:23,790
into how do you actually decide whether

00:01:21,119 --> 00:01:25,439
do it or not and how it actually works

00:01:23,790 --> 00:01:27,360
right what the the technical framework

00:01:25,439 --> 00:01:29,460
is around it what I'm trying to do today

00:01:27,360 --> 00:01:31,259
is just show you assembly right and I

00:01:29,460 --> 00:01:34,049
think my talk will have the distinction

00:01:31,259 --> 00:01:35,880
of having the most different types of is

00:01:34,049 --> 00:01:38,070
a assemblies in this whole conference by

00:01:35,880 --> 00:01:40,259
like two or three X so it'll be fun

00:01:38,070 --> 00:01:42,329
alright so I think you should instead

00:01:40,259 --> 00:01:44,009
probably just use like the pals in TS or

00:01:42,329 --> 00:01:45,540
mutexes or something like that right and

00:01:44,009 --> 00:01:47,939
again the standard should get better in

00:01:45,540 --> 00:01:49,860
what it exposes to you now I'm gonna

00:01:47,939 --> 00:01:52,979
steal for it freely from faders taught

00:01:49,860 --> 00:01:54,869
yesterday and show you you know when do

00:01:52,979 --> 00:01:56,790
you want to use Lots free Atomics right

00:01:54,869 --> 00:01:59,189
there's he had a nice decision diagram

00:01:56,790 --> 00:02:02,640
and the really hilarious thing is the

00:01:59,189 --> 00:02:04,829
node that says does it work right now

00:02:02,640 --> 00:02:07,200
now I asked him afterwards and that was

00:02:04,829 --> 00:02:09,360
actually a mistake right so he made a

00:02:07,200 --> 00:02:11,790
snarky flag without realizing it it's

00:02:09,360 --> 00:02:15,350
hilarious right but it really describes

00:02:11,790 --> 00:02:20,640
really well when you should go a lot

00:02:15,350 --> 00:02:22,170
right so what I'm gonna do first is just

00:02:20,640 --> 00:02:24,450
do a quick review and I'm gonna go

00:02:22,170 --> 00:02:26,280
really fast through this review just to

00:02:24,450 --> 00:02:28,080
kind of show you what's in C++ what our

00:02:26,280 --> 00:02:31,020
tools are and what we do with it

00:02:28,080 --> 00:02:33,030
so in general C++ 11 added a few things

00:02:31,020 --> 00:02:35,670
to the language ad first a memory model

00:02:33,030 --> 00:02:37,530
and threads in added classes to

00:02:35,670 --> 00:02:39,650
communicate between threads right so the

00:02:37,530 --> 00:02:44,130
thing to remember is before C++ 11

00:02:39,650 --> 00:02:45,540
threads did not exist right now you know

00:02:44,130 --> 00:02:47,070
that's the standardized view that there

00:02:45,540 --> 00:02:48,780
was something that existed and some of

00:02:47,070 --> 00:02:52,440
what was exposed had to kind of take

00:02:48,780 --> 00:02:55,050
that into account now what's interesting

00:02:52,440 --> 00:02:56,490
when we usually do like free programming

00:02:55,050 --> 00:02:59,760
or just you know multi-core programming

00:02:56,490 --> 00:03:01,830
in general is is that the mental model

00:02:59,760 --> 00:03:03,690
that we have is actually not super

00:03:01,830 --> 00:03:06,290
related to how hardware actually works

00:03:03,690 --> 00:03:09,570
right so the way we like to think about

00:03:06,290 --> 00:03:10,890
about how the hardware should work right

00:03:09,570 --> 00:03:14,040
is in terms of sequential consistency

00:03:10,890 --> 00:03:16,800
right and that's a pretty naive model

00:03:14,040 --> 00:03:18,720
right but the model the mental model is

00:03:16,800 --> 00:03:20,970
really easy to understand it's a zipper

00:03:18,720 --> 00:03:22,590
right like you have stores that happens

00:03:20,970 --> 00:03:24,090
and and they just kind of zip together

00:03:22,590 --> 00:03:26,220
and neatly right now sequential

00:03:24,090 --> 00:03:27,930
consistency is that thing it's real easy

00:03:26,220 --> 00:03:31,290
understand that's not actually how

00:03:27,930 --> 00:03:33,780
Hardware works and if you try to use it

00:03:31,290 --> 00:03:35,400
this way it would be kind of slow right

00:03:33,780 --> 00:03:36,930
so C++ has sequential consistent

00:03:35,400 --> 00:03:38,670
accesses and they happen to not be the

00:03:36,930 --> 00:03:42,240
best thing at that point you may as well

00:03:38,670 --> 00:03:44,040
not use Atomics long and and it's really

00:03:42,240 --> 00:03:45,120
overly restrictive and expressing what

00:03:44,040 --> 00:03:47,340
you want to do and I'll try to give you

00:03:45,120 --> 00:03:49,020
a few examples later and phaidor in his

00:03:47,340 --> 00:03:50,490
talk also had a few examples of you know

00:03:49,020 --> 00:03:53,310
not sequentially consistent but that's

00:03:50,490 --> 00:03:54,750
close to what you want and the reason

00:03:53,310 --> 00:03:57,450
it's slow is because it really limits

00:03:54,750 --> 00:04:00,990
what the hardware can reorder and limits

00:03:57,450 --> 00:04:02,670
with the optimizer can do alright and in

00:04:00,990 --> 00:04:04,500
a lot of architectures and ups ends up

00:04:02,670 --> 00:04:06,600
adding fences and fences depending on

00:04:04,500 --> 00:04:08,580
the architecture cause from 2 to 200

00:04:06,600 --> 00:04:09,750
cycles right that's a ginormous cost for

00:04:08,580 --> 00:04:13,410
something that were you're trying to be

00:04:09,750 --> 00:04:15,420
fast and so the way c++ fixes that is by

00:04:13,410 --> 00:04:17,489
exposing a model called sequential

00:04:15,420 --> 00:04:20,250
consistent for data arrays free programs

00:04:17,489 --> 00:04:22,049
right so that means is if your program

00:04:20,250 --> 00:04:23,400
doesn't have a data race then you get

00:04:22,049 --> 00:04:25,080
sequential consistency just kind of

00:04:23,400 --> 00:04:27,840
magically all right now that it's about

00:04:25,080 --> 00:04:30,120
a bit so what's a data race well a vaper

00:04:27,840 --> 00:04:32,280
is what happens when two accesses the

00:04:30,120 --> 00:04:34,740
same memory location by different

00:04:32,280 --> 00:04:37,470
threads aren't ordered now that's really

00:04:34,740 --> 00:04:39,660
technical and at least one of them

00:04:37,470 --> 00:04:40,860
stores the memory location and at least

00:04:39,660 --> 00:04:44,070
one of them is not a synchronization

00:04:40,860 --> 00:04:46,800
action now that's taken from the from

00:04:44,070 --> 00:04:48,450
the standard itself right I won't

00:04:46,800 --> 00:04:49,710
explain what that means in details and

00:04:48,450 --> 00:04:51,990
why that is because that would be a

00:04:49,710 --> 00:04:54,900
wallet text right the key takeaway to

00:04:51,990 --> 00:04:57,210
get here is that data races are

00:04:54,900 --> 00:04:58,800
undefined behavior if you don't have

00:04:57,210 --> 00:05:01,080
data races then you effectively have

00:04:58,800 --> 00:05:03,330
sequential consistency for your data

00:05:01,080 --> 00:05:04,590
race free program right so the standard

00:05:03,330 --> 00:05:07,260
defines this in the section called

00:05:04,590 --> 00:05:08,790
interval multi-threading it's 1.10 if

00:05:07,260 --> 00:05:10,350
you go there it's beautiful right I

00:05:08,790 --> 00:05:12,120
really recommend you watching hunts at

00:05:10,350 --> 00:05:16,440
the same recommendation yesterday in his

00:05:12,120 --> 00:05:18,419
presentation now atomic operations and

00:05:16,440 --> 00:05:20,430
Tomic operation is indivisible with

00:05:18,419 --> 00:05:22,530
respect to all other atomic access to

00:05:20,430 --> 00:05:24,630
the object and we have a bunch of memory

00:05:22,530 --> 00:05:26,270
orders in c plus plus we have relaxed

00:05:24,630 --> 00:05:28,229
relaxed is actually kind of interesting

00:05:26,270 --> 00:05:30,630
so I mentioned you know sequential

00:05:28,229 --> 00:05:34,050
consistency relaxed kind of breaks that

00:05:30,630 --> 00:05:36,120
models mount model a bit so relaxed

00:05:34,050 --> 00:05:38,340
allows you to have racing accesses so

00:05:36,120 --> 00:05:41,400
one race one relax access the same

00:05:38,340 --> 00:05:43,800
location is another one can't can't be

00:05:41,400 --> 00:05:45,360
reordered but relax essa sees the

00:05:43,800 --> 00:05:47,880
different locations can be reordered

00:05:45,360 --> 00:05:50,100
with respect to each other now at the

00:05:47,880 --> 00:05:52,200
same time the property of relaxed is

00:05:50,100 --> 00:05:54,330
that it is still indivisible right so

00:05:52,200 --> 00:05:55,770
you you can't see word tarry you won't

00:05:54,330 --> 00:05:57,090
see half of a right or something like

00:05:55,770 --> 00:05:59,400
that or your right won't just have

00:05:57,090 --> 00:06:01,080
succeed through relax and that that's

00:05:59,400 --> 00:06:03,000
usually the fundamental property people

00:06:01,080 --> 00:06:04,979
think about when they say atomic they

00:06:03,000 --> 00:06:06,539
usually think about indivisibility but

00:06:04,979 --> 00:06:09,419
there's a bunch more stuff that actually

00:06:06,539 --> 00:06:10,889
means and relax doesn't force cache

00:06:09,419 --> 00:06:13,410
coherency

00:06:10,889 --> 00:06:16,350
the thing about relaxed though is that

00:06:13,410 --> 00:06:17,580
it doesn't guarantee visibility right so

00:06:16,350 --> 00:06:19,169
hardware usually it's kind of

00:06:17,580 --> 00:06:20,820
well-behaved where like you'll have a

00:06:19,169 --> 00:06:23,010
cache and it'll become visible pretty

00:06:20,820 --> 00:06:25,710
quickly but you could actually have an

00:06:23,010 --> 00:06:28,380
implementation of c++ and hardware where

00:06:25,710 --> 00:06:30,270
the cache doesn't really make the the

00:06:28,380 --> 00:06:31,650
story that you do visible until you tell

00:06:30,270 --> 00:06:34,110
it like hey okay maybe you should make

00:06:31,650 --> 00:06:36,409
that visible and we'll see implications

00:06:34,110 --> 00:06:41,310
of that a bit later

00:06:36,409 --> 00:06:44,520
so hunts had had an interesting quote

00:06:41,310 --> 00:06:47,070
relaxed in his talk yesterday he said

00:06:44,520 --> 00:06:48,720
that C++ 14 replaced the offensive

00:06:47,070 --> 00:06:50,520
wording about relaxed with hand waving

00:06:48,720 --> 00:06:52,500
now that that's kind of an interesting

00:06:50,520 --> 00:06:54,270
quote coming from someone who like was

00:06:52,500 --> 00:06:57,930
heavily involved in creating a language

00:06:54,270 --> 00:07:00,450
he also said something else when you use

00:06:57,930 --> 00:07:03,750
relaxed well it's probably incorrect if

00:07:00,450 --> 00:07:05,520
you care about the result right

00:07:03,750 --> 00:07:07,230
so the it's kind of interesting but

00:07:05,520 --> 00:07:08,970
there are valid uses of relaxed and his

00:07:07,230 --> 00:07:12,300
basically his entire talk was about that

00:07:08,970 --> 00:07:15,510
yesterday so the basic tools that we

00:07:12,300 --> 00:07:18,540
have in C++ for doing atomicity are the

00:07:15,510 --> 00:07:20,280
atomic objects right so there's basic

00:07:18,540 --> 00:07:22,170
overloads right so it's just the class T

00:07:20,280 --> 00:07:24,180
that takes just whatever and then

00:07:22,170 --> 00:07:26,160
there's an integral overload there's a

00:07:24,180 --> 00:07:28,140
pointer overload and maybe in the future

00:07:26,160 --> 00:07:31,770
we'll have floating-point overloads as

00:07:28,140 --> 00:07:34,500
well right and the idea in C++ is that

00:07:31,770 --> 00:07:36,150
whenever you access things atomically

00:07:34,500 --> 00:07:39,690
you always do so through an atomic

00:07:36,150 --> 00:07:43,890
object right so atomicity and c++ is

00:07:39,690 --> 00:07:46,110
based on the memory location object

00:07:43,890 --> 00:07:48,030
being atomic it is always atomic it's

00:07:46,110 --> 00:07:49,440
not in this part of the code i'm yeah

00:07:48,030 --> 00:07:50,640
i'm using this atomic li in this other

00:07:49,440 --> 00:07:52,650
part of the code i'm using the same

00:07:50,640 --> 00:07:54,840
memory location non-atomic li and that

00:07:52,650 --> 00:07:56,460
has pretty deep implications to the

00:07:54,840 --> 00:07:58,500
programming model they you either use it

00:07:56,460 --> 00:08:00,630
and other systems have different

00:07:58,500 --> 00:08:03,630
programming models for example the Linux

00:08:00,630 --> 00:08:05,280
the programming model is based on the

00:08:03,630 --> 00:08:06,420
accesses themselves or it's a one part

00:08:05,280 --> 00:08:07,980
of the code could be atomic the other

00:08:06,420 --> 00:08:09,570
part could not be a ton and that's a

00:08:07,980 --> 00:08:14,820
fundamentally different way of

00:08:09,570 --> 00:08:18,060
expressing things now atomic T has a

00:08:14,820 --> 00:08:19,380
bunch of operations on it and they're

00:08:18,060 --> 00:08:21,360
actually kind of simple right you can do

00:08:19,380 --> 00:08:22,440
load store exchange compare exchange you

00:08:21,360 --> 00:08:23,430
can see if things are a lot for you or

00:08:22,440 --> 00:08:25,440
whatever

00:08:23,430 --> 00:08:28,740
atomic integral has a few more things

00:08:25,440 --> 00:08:30,480
add subtract or whatever T star can add

00:08:28,740 --> 00:08:32,220
and subtract only and then floating

00:08:30,480 --> 00:08:33,780
point maybe can do and and subtract

00:08:32,220 --> 00:08:35,430
we'll see maybe we can do more maybe

00:08:33,780 --> 00:08:37,470
we'll have like atomic FMA that'd be

00:08:35,430 --> 00:08:38,700
kind of interesting but weird maybe we'd

00:08:37,470 --> 00:08:39,990
have comp exchange or something like

00:08:38,700 --> 00:08:44,480
that otherwise you'd have to copy it

00:08:39,990 --> 00:08:47,460
into integer side into the competent so

00:08:44,480 --> 00:08:51,000
after that you have fences and hunters

00:08:47,460 --> 00:08:53,430
make and model fences is just don't use

00:08:51,000 --> 00:08:54,730
them right the the usual recommendation

00:08:53,430 --> 00:08:56,380
is that there's not really

00:08:54,730 --> 00:08:57,940
good way to use fences or a good reason

00:08:56,380 --> 00:09:00,130
to use fences there's one explanation

00:08:57,940 --> 00:09:01,899
for where it is valid is when you use

00:09:00,130 --> 00:09:03,010
sec locks now there's big disagreement

00:09:01,899 --> 00:09:04,540
around there but I'll give you the

00:09:03,010 --> 00:09:06,130
example later where that's valid and

00:09:04,540 --> 00:09:08,500
then there's signal fence which isn't

00:09:06,130 --> 00:09:10,839
really about parallelism but it's more

00:09:08,500 --> 00:09:12,339
about preventing ordering when there's a

00:09:10,839 --> 00:09:13,779
signal that happens all right so a

00:09:12,339 --> 00:09:17,110
single that interrupts your current

00:09:13,779 --> 00:09:18,940
thread and then there's a whole concept

00:09:17,110 --> 00:09:21,459
of lock freedom if you remember atomic T

00:09:18,940 --> 00:09:23,920
can take just any T right so any T could

00:09:21,459 --> 00:09:25,630
be ginormous now there must be deep

00:09:23,920 --> 00:09:28,060
magic if you can take a struck that's

00:09:25,630 --> 00:09:29,620
like a page wide and just make that

00:09:28,060 --> 00:09:32,260
atomic right just do the right and one

00:09:29,620 --> 00:09:34,449
go and what C++ does is it says well the

00:09:32,260 --> 00:09:36,579
hardware supports one single operation

00:09:34,449 --> 00:09:38,500
they'll make that right happen

00:09:36,579 --> 00:09:40,540
atomically so indivisibly and that's

00:09:38,500 --> 00:09:43,149
cool right then the access is a lot free

00:09:40,540 --> 00:09:44,500
but if if there's no instruction they'll

00:09:43,149 --> 00:09:46,329
do that and most architectures just

00:09:44,500 --> 00:09:48,459
don't have a wave barring transactional

00:09:46,329 --> 00:09:51,070
memory of making a whole ginormous right

00:09:48,459 --> 00:09:52,959
to be visible in one go then what c++

00:09:51,070 --> 00:09:55,000
does is behind the covers it has a bunch

00:09:52,959 --> 00:09:57,040
of locks hidden right and so if you

00:09:55,000 --> 00:10:00,040
access Atomics objects are way too big

00:09:57,040 --> 00:10:01,480
to happen in one shot the atomic object

00:10:00,040 --> 00:10:04,360
actually has a lock behind the covers

00:10:01,480 --> 00:10:05,680
now that's kind of silly I'm just not

00:10:04,360 --> 00:10:07,269
really going to talk about non lock

00:10:05,680 --> 00:10:09,279
three Atomics it's kind of a weird thing

00:10:07,269 --> 00:10:12,010
to even try to make it work but that's

00:10:09,279 --> 00:10:14,079
what the language does now lock freedom

00:10:12,010 --> 00:10:15,760
is only guaranteed for one type in C++

00:10:14,079 --> 00:10:17,380
and that type is atomic flag and it's

00:10:15,760 --> 00:10:18,819
really not that useful it does a few

00:10:17,380 --> 00:10:20,680
things but all the operations I showed

00:10:18,819 --> 00:10:24,100
earlier not not all of them are

00:10:20,680 --> 00:10:26,110
available on that type and and the way I

00:10:24,100 --> 00:10:27,550
see it and I may be wrong right but the

00:10:26,110 --> 00:10:29,290
way I see lock freedom is the other

00:10:27,550 --> 00:10:31,269
context change on your architecture that

00:10:29,290 --> 00:10:32,649
I'll do you know that sighs all right

00:10:31,269 --> 00:10:34,899
it's on x86 you'll have like up to

00:10:32,649 --> 00:10:36,370
complex chained 16 B now that that still

00:10:34,899 --> 00:10:37,990
doesn't mean it's fast right can't be

00:10:36,370 --> 00:10:42,430
changed 16 B in some cases is kind of

00:10:37,990 --> 00:10:45,399
slow and then then yes so I'm really

00:10:42,430 --> 00:10:51,040
gonna focus on on lock 3 things for this

00:10:45,399 --> 00:10:52,600
is this stuck and yeah so I just kind of

00:10:51,040 --> 00:10:54,579
well show you a quick example of what

00:10:52,600 --> 00:10:56,560
lottery code looks like it's a horrible

00:10:54,579 --> 00:10:58,360
example don't write this it's not good

00:10:56,560 --> 00:11:00,850
code right but the basic idea is that

00:10:58,360 --> 00:11:02,139
you you have like a publish/subscribe

00:11:00,850 --> 00:11:03,430
thing in this case right so you have a

00:11:02,139 --> 00:11:04,990
writer that writes a bunch of data

00:11:03,430 --> 00:11:07,300
notice that none of the rights of data

00:11:04,990 --> 00:11:08,740
are atomic the only thing that's atomic

00:11:07,300 --> 00:11:10,240
is the flag that we have

00:11:08,740 --> 00:11:11,920
toys right so the writer writes his

00:11:10,240 --> 00:11:14,140
stuff says all right here's the thing

00:11:11,920 --> 00:11:16,540
I'm done release all the the things and

00:11:14,140 --> 00:11:18,399
the reader says oh hey I'm just gonna

00:11:16,540 --> 00:11:19,660
wait until that flag is set and

00:11:18,399 --> 00:11:21,880
afterwards it can read all the data

00:11:19,660 --> 00:11:24,310
right so spam bacon and eggs only get

00:11:21,880 --> 00:11:25,990
read once the flag is set and you will

00:11:24,310 --> 00:11:27,190
your if you use that protocol you're

00:11:25,990 --> 00:11:29,380
guaranteed to have the results you want

00:11:27,190 --> 00:11:31,930
now the idea here is that you run this

00:11:29,380 --> 00:11:33,610
into two threads and there's a there's a

00:11:31,930 --> 00:11:36,459
synchronization between the two threads

00:11:33,610 --> 00:11:38,709
between the the store release and the

00:11:36,459 --> 00:11:40,750
load acquire right and so it means that

00:11:38,709 --> 00:11:43,600
the write that happened before in the

00:11:40,750 --> 00:11:46,690
the writer thread are seen by the reads

00:11:43,600 --> 00:11:49,750
that that succeed the the load acquire

00:11:46,690 --> 00:11:52,180
okay it's fairly simple right so that's

00:11:49,750 --> 00:11:54,490
all the tools we have within C++ to do

00:11:52,180 --> 00:11:57,459
atomicity all right so we have our tools

00:11:54,490 --> 00:12:01,209
but why is the language set up that way

00:11:57,459 --> 00:12:02,500
well it happens that it makes it easy to

00:12:01,209 --> 00:12:04,570
prove certain properties about the

00:12:02,500 --> 00:12:06,850
language and about like what can happen

00:12:04,570 --> 00:12:08,980
right and so someone actually spent a

00:12:06,850 --> 00:12:11,140
bunch of time writing a PhD to to create

00:12:08,980 --> 00:12:12,850
math to represent that memory model and

00:12:11,140 --> 00:12:15,250
proved a bunch of interesting properties

00:12:12,850 --> 00:12:16,690
about them remodel and and found a bunch

00:12:15,250 --> 00:12:18,670
of failings in the memory model that God

00:12:16,690 --> 00:12:21,610
addressed before C++ a lot right and

00:12:18,670 --> 00:12:23,740
it's actually kind of rare in designs

00:12:21,610 --> 00:12:25,600
like this that you can use maths to like

00:12:23,740 --> 00:12:26,950
prove that something works in a certain

00:12:25,600 --> 00:12:31,149
way so I think that's actually kind of

00:12:26,950 --> 00:12:32,860
cool now the other idea is that like C++

00:12:31,149 --> 00:12:34,420
doesn't get to dictate how Hardware

00:12:32,860 --> 00:12:36,550
works right it is it's an important

00:12:34,420 --> 00:12:37,990
language but it just kind of does stuff

00:12:36,550 --> 00:12:40,450
right it kind of has to follow what

00:12:37,990 --> 00:12:42,459
hardware is able to do right so the

00:12:40,450 --> 00:12:43,899
abstraction was designed with the goal

00:12:42,459 --> 00:12:46,300
in mind that like you can write your

00:12:43,899 --> 00:12:48,190
code and it'll work pretty much the same

00:12:46,300 --> 00:12:49,930
on all the architectures if you fall if

00:12:48,190 --> 00:12:52,750
you don't fall into undefined behavior

00:12:49,930 --> 00:12:54,279
right and then the idea is well if it

00:12:52,750 --> 00:12:56,230
doesn't work correctly you should use

00:12:54,279 --> 00:12:59,070
tooling like the sanitizers or something

00:12:56,230 --> 00:13:01,240
like that to try to find the bugs right

00:12:59,070 --> 00:13:03,579
now what I'm going to do is I'm going to

00:13:01,240 --> 00:13:05,560
go through a few architectures and try

00:13:03,579 --> 00:13:08,380
to show you how they implement Atomics

00:13:05,560 --> 00:13:11,200
all right so on x86 64 it's actually

00:13:08,380 --> 00:13:13,480
kind of straightforward load is just

00:13:11,200 --> 00:13:14,890
move basically and then store can be a

00:13:13,480 --> 00:13:17,440
lock unit or something like that and

00:13:14,890 --> 00:13:19,270
then fences are usually nothing write

00:13:17,440 --> 00:13:21,579
fences are effectively the way I see a

00:13:19,270 --> 00:13:22,300
just compiler barrier the next 36 unless

00:13:21,579 --> 00:13:23,980
it's the sequential

00:13:22,300 --> 00:13:25,900
consistent offense so compiler doesn't

00:13:23,980 --> 00:13:27,700
move loads or store around and what that

00:13:25,900 --> 00:13:29,470
means is that the hardware just kind of

00:13:27,700 --> 00:13:30,940
executes things in the order that they

00:13:29,470 --> 00:13:33,420
are in the program because they don't

00:13:30,940 --> 00:13:35,230
move around in the actual assembly and

00:13:33,420 --> 00:13:36,520
afterwards they get observed in that

00:13:35,230 --> 00:13:38,800
order there's just kind of a magical

00:13:36,520 --> 00:13:42,010
property of x86 64 that's what makes

00:13:38,800 --> 00:13:43,690
writing a kind of tight code like that

00:13:42,010 --> 00:13:45,880
and exit assist and a nice because it

00:13:43,690 --> 00:13:47,050
kind of kind of does what you expect at

00:13:45,880 --> 00:13:48,700
the same time it means that if you wrote

00:13:47,050 --> 00:13:50,230
code for x86 and then the line assembly

00:13:48,700 --> 00:13:52,210
translating it to another architecture

00:13:50,230 --> 00:13:55,450
is kind of a headache right so having a

00:13:52,210 --> 00:13:57,700
high level language like C++ makes it

00:13:55,450 --> 00:14:01,060
easy to to you know translate code to

00:13:57,700 --> 00:14:02,500
another architecture now notice that I'm

00:14:01,060 --> 00:14:04,840
not talking about comp exchange or some

00:14:02,500 --> 00:14:06,730
stuff like that but cop exchanges is

00:14:04,840 --> 00:14:08,110
directly an instruction on x86 it's

00:14:06,730 --> 00:14:11,590
literally like one instruction that does

00:14:08,110 --> 00:14:13,890
contain exchange now on power it's kind

00:14:11,590 --> 00:14:17,560
of different like power is kind of a

00:14:13,890 --> 00:14:19,270
weaker architecture and so you kind of

00:14:17,560 --> 00:14:22,120
have to say when you synchronize to the

00:14:19,270 --> 00:14:24,310
hardware right and you also have to

00:14:22,120 --> 00:14:25,690
instead of using a comp exchange there's

00:14:24,310 --> 00:14:27,670
these load linked and store conditional

00:14:25,690 --> 00:14:30,270
instructions all right so it looks like

00:14:27,670 --> 00:14:32,440
this and it's kind of complicated and

00:14:30,270 --> 00:14:34,720
when you do a complex change you end up

00:14:32,440 --> 00:14:37,420
having a loop or round things right so

00:14:34,720 --> 00:14:38,920
it means they'll do a load it'll acquire

00:14:37,420 --> 00:14:40,450
a reservation station or something like

00:14:38,920 --> 00:14:43,030
that and then I'll try to do the store

00:14:40,450 --> 00:14:44,860
that fails the store the the loop goes

00:14:43,030 --> 00:14:47,770
around and tries again and again right

00:14:44,860 --> 00:14:50,410
now I'm not showing 64 bits because

00:14:47,770 --> 00:14:52,060
that's even more complicated now on an

00:14:50,410 --> 00:14:54,130
arm v7 it's actually kind of similar to

00:14:52,060 --> 00:14:56,380
power right and MIPS is actually really

00:14:54,130 --> 00:14:57,550
similar to that as well it you know you

00:14:56,380 --> 00:15:00,220
look at that it kind of looks the same

00:14:57,550 --> 00:15:01,630
now arm has kind of extra interesting

00:15:00,220 --> 00:15:02,890
things where it has a bunch of fences

00:15:01,630 --> 00:15:05,050
there's like a bunch of different types

00:15:02,890 --> 00:15:07,060
of fences so DMV at the bottom is the

00:15:05,050 --> 00:15:08,770
basic type of fence that happens to be a

00:15:07,060 --> 00:15:10,840
system-wide stance that like tells the

00:15:08,770 --> 00:15:12,250
entire machine including hardware that

00:15:10,840 --> 00:15:14,140
C++ doesn't know about like hey

00:15:12,250 --> 00:15:15,460
something could have changed there's

00:15:14,140 --> 00:15:18,040
actually a bunch of other offenses they

00:15:15,460 --> 00:15:20,260
exist an arm like DMV ish if sound

00:15:18,040 --> 00:15:23,710
stands for inner shareability not like

00:15:20,260 --> 00:15:24,760
try defense and in in you know there's a

00:15:23,710 --> 00:15:25,960
bunch of the defenses they exist and

00:15:24,760 --> 00:15:27,430
then they also have like instruction

00:15:25,960 --> 00:15:30,250
synchronization barriers if you know

00:15:27,430 --> 00:15:32,380
touching the the instruction you know

00:15:30,250 --> 00:15:33,940
that I cache and stuff like that and so

00:15:32,380 --> 00:15:34,760
it's actually more complicated to

00:15:33,940 --> 00:15:37,910
program in these are

00:15:34,760 --> 00:15:40,940
chirps now rv-8 tried to make things a

00:15:37,910 --> 00:15:43,550
bit simpler our v8 was designed with the

00:15:40,940 --> 00:15:45,620
upcoming C++ memory model in mind and so

00:15:43,550 --> 00:15:47,840
it actually is kind of interesting right

00:15:45,620 --> 00:15:49,790
like it has these load acquire and store

00:15:47,840 --> 00:15:52,430
release instructions and so it's kind of

00:15:49,790 --> 00:15:53,780
like the life imitating the standard all

00:15:52,430 --> 00:15:55,580
right so the standard did a thing and

00:15:53,780 --> 00:15:56,600
armed v8 kind of did the same thing and

00:15:55,580 --> 00:15:57,860
so it means that it's kind of a

00:15:56,600 --> 00:16:01,610
straightforward mapping in a lot of

00:15:57,860 --> 00:16:02,780
cases from D now Itanium is another

00:16:01,610 --> 00:16:05,000
architecture that's actually kind of

00:16:02,780 --> 00:16:06,380
interesting and the mapping and i Taemin

00:16:05,000 --> 00:16:08,600
was actually kind of straight forward as

00:16:06,380 --> 00:16:10,790
well so that's kind of interesting now

00:16:08,600 --> 00:16:12,920
the last the last set of assembly I want

00:16:10,790 --> 00:16:16,280
to show you is alpha so who's familiar

00:16:12,920 --> 00:16:18,800
with alpha here and a few people so what

00:16:16,280 --> 00:16:20,960
do you expect for alpha as a mapping

00:16:18,800 --> 00:16:25,670
from you know suppose was Atomics 2 to

00:16:20,960 --> 00:16:27,170
the I say not straightforward yeah not

00:16:25,670 --> 00:16:28,790
at all right it has a reputation of

00:16:27,170 --> 00:16:30,230
being kind of complicated so what I did

00:16:28,790 --> 00:16:34,220
instead of trying to do that lowering

00:16:30,230 --> 00:16:36,020
right is is I took an email from from of

00:16:34,220 --> 00:16:38,150
all people linus torvalds explaining how

00:16:36,020 --> 00:16:40,490
alpha works now what's interesting is

00:16:38,150 --> 00:16:42,020
that email has no profanities and it's

00:16:40,490 --> 00:16:45,980
actually super informative

00:16:42,020 --> 00:16:48,800
all right oh I just missed it that

00:16:45,980 --> 00:16:50,150
jumped around there we go so I won't let

00:16:48,800 --> 00:16:52,070
you read that email it's really long but

00:16:50,150 --> 00:16:53,870
it's super informative right he actually

00:16:52,070 --> 00:16:57,140
explains how it works in the Linux

00:16:53,870 --> 00:16:58,970
memory model now alpha happens to be

00:16:57,140 --> 00:17:01,720
kind of hard to implement for C++ and

00:16:58,970 --> 00:17:03,980
the the C++ design kind of abandoned

00:17:01,720 --> 00:17:06,290
targeting alpha efficiently right

00:17:03,980 --> 00:17:08,150
because alpha just wasn't really gonna

00:17:06,290 --> 00:17:09,440
be a thing and so they were like yeah we

00:17:08,150 --> 00:17:10,910
don't really care all right but it does

00:17:09,440 --> 00:17:12,650
mean that some hardware can't actually

00:17:10,910 --> 00:17:14,990
handle the C++ memory model very well

00:17:12,650 --> 00:17:16,790
right so I guess that's the one

00:17:14,990 --> 00:17:19,670
exception that proves the rule that CFOs

00:17:16,790 --> 00:17:21,410
bus is wonderful now if you remember

00:17:19,670 --> 00:17:23,900
like in the six memory organs that we

00:17:21,410 --> 00:17:26,180
have there's this consume thing right so

00:17:23,900 --> 00:17:31,760
who's heard about consume all right so

00:17:26,180 --> 00:17:34,100
this consume worked well yes now I just

00:17:31,760 --> 00:17:36,230
feel after now okay so it consumes kind

00:17:34,100 --> 00:17:39,440
of the butt of all jokes in C++ I'm

00:17:36,230 --> 00:17:41,810
sorry Paul if here in the room but it it

00:17:39,440 --> 00:17:43,820
was really well intended and and the

00:17:41,810 --> 00:17:45,950
idea that consume had when it was

00:17:43,820 --> 00:17:47,420
standardized was look there's this thing

00:17:45,950 --> 00:17:48,410
called the address dependency rule and

00:17:47,420 --> 00:17:49,550
Alice traders for

00:17:48,410 --> 00:17:50,900
because that's the one I know better but

00:17:49,550 --> 00:17:54,140
it's similar in other architectures and

00:17:50,900 --> 00:17:57,110
and the idea there is that you have a

00:17:54,140 --> 00:18:00,440
load right so you load from R 0 into R 1

00:17:57,110 --> 00:18:03,200
and then you load from r1 into r2 right

00:18:00,440 --> 00:18:05,450
so if you look here R 1 is a dependency

00:18:03,200 --> 00:18:07,160
right that the address of the second

00:18:05,450 --> 00:18:09,650
load depends on the result of the first

00:18:07,160 --> 00:18:09,980
load and that's consumed that's all it

00:18:09,650 --> 00:18:12,290
is

00:18:09,980 --> 00:18:14,060
right so the idea of consume is you look

00:18:12,290 --> 00:18:16,220
at that and you say hey the hardware

00:18:14,060 --> 00:18:17,540
can't reorder things at least in some

00:18:16,220 --> 00:18:19,820
architectures right that's not true in

00:18:17,540 --> 00:18:21,830
alpha but when there's a dependency the

00:18:19,820 --> 00:18:25,700
the is a explicitly said there's a

00:18:21,830 --> 00:18:28,610
dependency there for the the loads will

00:18:25,700 --> 00:18:30,980
or will observe the stores in the order

00:18:28,610 --> 00:18:32,450
that they occurred right and that's kind

00:18:30,980 --> 00:18:34,100
of interesting it means that you don't

00:18:32,450 --> 00:18:36,140
need a fence between them like you would

00:18:34,100 --> 00:18:38,270
in other circumstances and it's not

00:18:36,140 --> 00:18:40,940
quite true what it does is it orders

00:18:38,270 --> 00:18:42,380
those to load with those two loads which

00:18:40,940 --> 00:18:45,080
with with respect to each other it

00:18:42,380 --> 00:18:46,490
doesn't order any other loads so if you

00:18:45,080 --> 00:18:48,170
had a fence that would order all the

00:18:46,490 --> 00:18:51,890
loads but without the fence it only

00:18:48,170 --> 00:18:53,960
orders the dependent ones right now the

00:18:51,890 --> 00:18:55,730
problem with that is that C++ doesn't

00:18:53,960 --> 00:18:57,230
actually work that way right at the very

00:18:55,730 --> 00:18:59,300
high level you could write code that

00:18:57,230 --> 00:19:01,490
looks like this the compiler will not

00:18:59,300 --> 00:19:03,530
generate code that looks like this right

00:19:01,490 --> 00:19:05,000
if your code is a bit more complex is

00:19:03,530 --> 00:19:06,350
never try to optimize around things

00:19:05,000 --> 00:19:08,480
because it doesn't know that you're

00:19:06,350 --> 00:19:11,930
trying to express a dependency way down

00:19:08,480 --> 00:19:14,450
in the the back end in assembly right

00:19:11,930 --> 00:19:15,860
now there's even more complex

00:19:14,450 --> 00:19:17,420
dependencies that you can use in certain

00:19:15,860 --> 00:19:18,440
architectures for example an arm this

00:19:17,420 --> 00:19:20,510
works right

00:19:18,440 --> 00:19:23,900
still no offense but what's interesting

00:19:20,510 --> 00:19:26,120
is you're doing a load to r1 and then

00:19:23,900 --> 00:19:29,180
you're creating a magical 0 you're

00:19:26,120 --> 00:19:30,950
ending R 1 with 0 right and this is a 0

00:19:29,180 --> 00:19:33,380
value and then you you're doing a

00:19:30,950 --> 00:19:35,450
register register load the bases R is R

00:19:33,380 --> 00:19:37,790
3 and you're adding R 1 to it RR 1

00:19:35,450 --> 00:19:39,590
happens to be 0 now right

00:19:37,790 --> 00:19:41,510
but that still maintains the dependency

00:19:39,590 --> 00:19:44,210
between two dependent loads right

00:19:41,510 --> 00:19:46,940
without having the Bary now we're gonna

00:19:44,210 --> 00:19:48,830
try to fix consume in the standard but

00:19:46,940 --> 00:19:51,260
but right now it just kind of lowers to

00:19:48,830 --> 00:19:51,950
to load acquires instead so it has kind

00:19:51,260 --> 00:19:54,140
of the barrier

00:19:51,950 --> 00:19:56,750
instead in basically every compiler

00:19:54,140 --> 00:19:59,090
right now I'm going to show you

00:19:56,750 --> 00:20:00,380
something really horrible where I was

00:19:59,090 --> 00:20:01,790
working on code recently and I kind of

00:20:00,380 --> 00:20:02,190
wanted to have consumed because it

00:20:01,790 --> 00:20:03,389
turned

00:20:02,190 --> 00:20:05,879
doubt that in the code that I was

00:20:03,389 --> 00:20:07,440
working on we had a barrier that was

00:20:05,879 --> 00:20:10,500
really slow and I was just trying to

00:20:07,440 --> 00:20:11,879
order reads between two flags barely

00:20:10,500 --> 00:20:14,399
ever changed right

00:20:11,879 --> 00:20:15,809
so what I did is I actually implemented

00:20:14,399 --> 00:20:17,700
consuming the most horrible way I can

00:20:15,809 --> 00:20:21,500
think of and I didn't even clean it up

00:20:17,700 --> 00:20:24,929
to convince you that it's horrible so

00:20:21,500 --> 00:20:27,870
and don't do this at home it's really

00:20:24,929 --> 00:20:29,970
really horrible right it's really

00:20:27,870 --> 00:20:31,529
objectionable now what's interesting is

00:20:29,970 --> 00:20:33,929
I talk to people are like oh yeah it

00:20:31,529 --> 00:20:36,360
looks like it'll probably work right

00:20:33,929 --> 00:20:38,100
right Richard now the problem is he also

00:20:36,360 --> 00:20:39,240
said well except like the aliasing

00:20:38,100 --> 00:20:41,070
violation that you have but whatever

00:20:39,240 --> 00:20:42,750
right there happens to work it's

00:20:41,070 --> 00:20:45,659
actually kind of fast like I benchmark

00:20:42,750 --> 00:20:47,549
the GC I was touching and some specific

00:20:45,659 --> 00:20:49,049
benchmark in that GC got faster so

00:20:47,549 --> 00:20:50,610
that's kind of interesting but don't do

00:20:49,049 --> 00:20:52,110
this at home but we'll try to fix it in

00:20:50,610 --> 00:20:53,909
language at some point and we actually

00:20:52,110 --> 00:20:55,440
added some some wording to the language

00:20:53,909 --> 00:20:57,690
it says maybe don't use consume right

00:20:55,440 --> 00:20:59,070
now but we didn't fully deprecated it

00:20:57,690 --> 00:21:03,330
yet so you know we'll see maybe I'll

00:20:59,070 --> 00:21:05,070
come back now I'm gonna jump in into you

00:21:03,330 --> 00:21:08,789
know some architectures specific stuff

00:21:05,070 --> 00:21:10,529
right so in general you know you program

00:21:08,789 --> 00:21:13,110
it at your high level in C++ and then

00:21:10,529 --> 00:21:15,000
then you're on your when you compile you

00:21:13,110 --> 00:21:16,919
can tell your compiler like Caleb I have

00:21:15,000 --> 00:21:19,200
this specific architecture all right so

00:21:16,919 --> 00:21:20,730
if you're targeting say x86 or arm or

00:21:19,200 --> 00:21:22,320
something like that you can tell it's

00:21:20,730 --> 00:21:24,840
this version right there where it's

00:21:22,320 --> 00:21:26,399
exactly this CPU what's interesting is

00:21:24,840 --> 00:21:28,110
that the compiler can be smart and say

00:21:26,399 --> 00:21:29,820
like oh hey look I had this instruction

00:21:28,110 --> 00:21:33,059
that does exactly what you want so I'll

00:21:29,820 --> 00:21:35,490
give you an example on arm 32 bits when

00:21:33,059 --> 00:21:37,019
you do a load of a 64-bit value right so

00:21:35,490 --> 00:21:39,480
it's a 32-bit architecture you can do

00:21:37,019 --> 00:21:41,549
loads of 64-bit values but what it does

00:21:39,480 --> 00:21:42,779
is it loads it into two registers all

00:21:41,549 --> 00:21:46,019
right so there's this instruction called

00:21:42,779 --> 00:21:47,429
LDR D log two things now if you want to

00:21:46,019 --> 00:21:49,320
do that atomically writes if you don't

00:21:47,429 --> 00:21:52,409
want the load to tear you have to

00:21:49,320 --> 00:21:53,100
usually use LDR e ex LDR de ex or

00:21:52,409 --> 00:21:54,450
something like that

00:21:53,100 --> 00:21:57,240
right because you tell it do an

00:21:54,450 --> 00:21:58,980
exclusive load and don't care now if you

00:21:57,240 --> 00:22:03,090
if you happen to know that your

00:21:58,980 --> 00:22:04,710
architecture has a long pointer address

00:22:03,090 --> 00:22:06,389
extension I don't know why it's tied to

00:22:04,710 --> 00:22:09,870
that but that's what it is then you

00:22:06,389 --> 00:22:11,519
don't need LD LD Rd X you can just use

00:22:09,870 --> 00:22:13,139
the regular LDR ID right so if you

00:22:11,519 --> 00:22:15,360
compiler smart there's a bunch of

00:22:13,139 --> 00:22:17,549
interesting things you can do by

00:22:15,360 --> 00:22:18,990
getting your specific architecture and

00:22:17,549 --> 00:22:20,460
even gets more interesting right some

00:22:18,990 --> 00:22:22,470
architectures have like transactional

00:22:20,460 --> 00:22:24,330
memory or something like that some some

00:22:22,470 --> 00:22:25,920
processors don't actually implement the

00:22:24,330 --> 00:22:26,880
ISA the way it's specified they

00:22:25,920 --> 00:22:29,250
implements something that's much

00:22:26,880 --> 00:22:30,600
stricter because they wanted to write so

00:22:29,250 --> 00:22:33,059
you go to your hardware people and you

00:22:30,600 --> 00:22:34,890
say hey I put a barrier here is that the

00:22:33,059 --> 00:22:36,270
best thing and say no actually like we

00:22:34,890 --> 00:22:37,770
lied and we didn't follow the spec and

00:22:36,270 --> 00:22:39,179
we made this thing much more strict than

00:22:37,770 --> 00:22:40,620
other things that'll be faster if you do

00:22:39,179 --> 00:22:43,020
this others thing all right so I've

00:22:40,620 --> 00:22:44,670
worked on an architecture before that

00:22:43,020 --> 00:22:46,770
was supposed to be a super like weak

00:22:44,670 --> 00:22:48,780
memory model but it happened to be like

00:22:46,770 --> 00:22:50,220
super like it was actually sequentially

00:22:48,780 --> 00:22:53,429
consistent when it executed just

00:22:50,220 --> 00:22:55,260
magically right and so so it meant that

00:22:53,429 --> 00:22:57,030
like if I wrote code with architecture I

00:22:55,260 --> 00:22:58,890
didn't basically need barriers anywhere

00:22:57,030 --> 00:23:00,660
I didn't need any special instructions I

00:22:58,890 --> 00:23:02,640
could just like use regular instructions

00:23:00,660 --> 00:23:04,350
right as long as the compiler didn't

00:23:02,640 --> 00:23:06,990
reordered them everything was fine in

00:23:04,350 --> 00:23:08,429
that specific architecture and then

00:23:06,990 --> 00:23:09,750
there's interesting stuff so when I used

00:23:08,429 --> 00:23:11,100
to work on Chrome at some point I was

00:23:09,750 --> 00:23:12,870
looking at the the way chrome used

00:23:11,100 --> 00:23:16,940
Atomics and there happened to be a

00:23:12,870 --> 00:23:19,679
really old CPU bug in old AMD versions

00:23:16,940 --> 00:23:22,320
147 or something like that so the really

00:23:19,679 --> 00:23:24,299
old Opterons and that's like point zero

00:23:22,320 --> 00:23:26,370
zero two percent of all the the chrome

00:23:24,299 --> 00:23:28,950
users and it had to have a workaround

00:23:26,370 --> 00:23:30,840
for a specific bug in the way Atomics

00:23:28,950 --> 00:23:32,940
work so in that case what chrome needed

00:23:30,840 --> 00:23:34,559
to do is that needed to add an extra

00:23:32,940 --> 00:23:36,720
fence in places where the architecture

00:23:34,559 --> 00:23:38,250
said you don't need a fence right now

00:23:36,720 --> 00:23:41,730
that's unfortunate because it makes all

00:23:38,250 --> 00:23:43,169
the other users of chrome slow right but

00:23:41,730 --> 00:23:44,490
but it's kind of like your compiler

00:23:43,169 --> 00:23:47,040
should know better in a lot of cases

00:23:44,490 --> 00:23:48,330
right and so so basically you know

00:23:47,040 --> 00:23:50,640
sometimes you have special instructions

00:23:48,330 --> 00:23:52,380
and sometimes it's even more tricky

00:23:50,640 --> 00:23:53,940
right you want to write a spindle for

00:23:52,380 --> 00:23:55,169
example what's the best way to write a

00:23:53,940 --> 00:23:56,790
spin loop for your architecture it

00:23:55,169 --> 00:23:59,160
really depends on the architecture and

00:23:56,790 --> 00:24:01,260
the specific version of art the

00:23:59,160 --> 00:24:02,490
architecture you're in and then yeah as

00:24:01,260 --> 00:24:04,470
I was saying sometimes you can write

00:24:02,490 --> 00:24:05,880
code that's nominally incorrect that

00:24:04,470 --> 00:24:07,710
happens to work in that specific

00:24:05,880 --> 00:24:09,179
architecture it's guaranteed to work in

00:24:07,710 --> 00:24:11,160
that specific architecture but not in

00:24:09,179 --> 00:24:13,860
another version all right so different

00:24:11,160 --> 00:24:15,600
arm versions or something like that and

00:24:13,860 --> 00:24:15,990
then you know I'm working around CPU

00:24:15,600 --> 00:24:17,130
books

00:24:15,990 --> 00:24:20,309
all right so what's the takeaway from

00:24:17,130 --> 00:24:22,830
this well C++ exposes things in a

00:24:20,309 --> 00:24:24,480
portable manner but the hardware changes

00:24:22,830 --> 00:24:26,790
over time right you'll have bugs and old

00:24:24,480 --> 00:24:28,320
versions they'll be out later or you

00:24:26,790 --> 00:24:28,970
know you'll have kind of emergent

00:24:28,320 --> 00:24:31,789
patterns and

00:24:28,970 --> 00:24:32,900
people write code that mean that you

00:24:31,789 --> 00:24:35,000
used to write code a certain way

00:24:32,900 --> 00:24:37,159
Hardware adapted to that way now that's

00:24:35,000 --> 00:24:39,049
fast or something like that or you do

00:24:37,159 --> 00:24:40,789
things and it's super inefficient so

00:24:39,049 --> 00:24:42,679
hardware five years later or something

00:24:40,789 --> 00:24:43,909
like that gets faster right so you can

00:24:42,679 --> 00:24:46,429
actually go to hardware vendors

00:24:43,909 --> 00:24:48,470
sometimes and say hey like I do this

00:24:46,429 --> 00:24:50,179
it's slow and I don't have a way to make

00:24:48,470 --> 00:24:51,500
it fast and then they're like oh let me

00:24:50,179 --> 00:24:52,730
think about that and five to ten years

00:24:51,500 --> 00:24:54,409
later you get an instruction for your

00:24:52,730 --> 00:24:56,179
thing you've probably forgotten about it

00:24:54,409 --> 00:25:00,400
by then but someone else gets a profit

00:24:56,179 --> 00:25:03,460
from your foresight and then you know I

00:25:00,400 --> 00:25:05,990
have no clue with that it's whatever and

00:25:03,460 --> 00:25:08,059
you know C++ in general just kind of

00:25:05,990 --> 00:25:09,470
works on on on data structures which

00:25:08,059 --> 00:25:10,940
kind of need compared to like the a

00:25:09,470 --> 00:25:13,580
horrible assembly that I had earlier

00:25:10,940 --> 00:25:15,320
right so so it's kind of nice to program

00:25:13,580 --> 00:25:17,270
in that that model and also means that

00:25:15,320 --> 00:25:19,250
you can target what I call virtual

00:25:17,270 --> 00:25:21,799
assets right so I used to work on this

00:25:19,250 --> 00:25:24,080
thing called web assembly where we would

00:25:21,799 --> 00:25:25,730
execute C++ code on the web now the web

00:25:24,080 --> 00:25:27,830
happens to work on a bunch of hardware's

00:25:25,730 --> 00:25:30,440
right I think that v8 compiler targets

00:25:27,830 --> 00:25:32,750
nine platforms so right nine individual

00:25:30,440 --> 00:25:34,880
is a is there different so it has arm

00:25:32,750 --> 00:25:36,440
and x86 and a bunch of other stuff and

00:25:34,880 --> 00:25:38,090
there's no way assembly is going to work

00:25:36,440 --> 00:25:40,490
in that platform but what does work is

00:25:38,090 --> 00:25:42,860
very high level things like the C++

00:25:40,490 --> 00:25:45,799
memory model right so if you take code

00:25:42,860 --> 00:25:47,390
that's compiled for C++ then it kind of

00:25:45,799 --> 00:25:50,630
just works in the virtual I say like

00:25:47,390 --> 00:25:53,360
this which is kind of neat now how do we

00:25:50,630 --> 00:25:54,890
actually optimize Atomics right I gave

00:25:53,360 --> 00:25:57,110
you like a bunch of individual tricks

00:25:54,890 --> 00:25:59,659
but a very high level how does that work

00:25:57,110 --> 00:26:02,360
well the C++ standard has this thing

00:25:59,659 --> 00:26:05,150
called the as if rule right and so so

00:26:02,360 --> 00:26:08,390
the high-level rules of data race

00:26:05,150 --> 00:26:11,059
freedom gives you sequential consistency

00:26:08,390 --> 00:26:14,179
is basically what we kind of hinge on to

00:26:11,059 --> 00:26:16,250
to do optimizations and the basic idea

00:26:14,179 --> 00:26:18,500
is that you're allowed to make things

00:26:16,250 --> 00:26:21,559
more atomic if it won't violate forward

00:26:18,500 --> 00:26:23,179
progress right that's one one kind of

00:26:21,559 --> 00:26:25,580
benchmark for whether the optimization

00:26:23,179 --> 00:26:26,929
is worthwhile or not and at the same

00:26:25,580 --> 00:26:29,299
time we're allowed to make things less

00:26:26,929 --> 00:26:31,640
atomic if it doesn't add non benign

00:26:29,299 --> 00:26:33,230
races which weren't already there all

00:26:31,640 --> 00:26:35,450
right so I'm gonna assume your code

00:26:33,230 --> 00:26:37,490
doesn't have races and then I'm not

00:26:35,450 --> 00:26:39,320
gonna add more races basically that's

00:26:37,490 --> 00:26:41,900
the the yardstick for the

00:26:39,320 --> 00:26:43,790
now at the same time this is all

00:26:41,900 --> 00:26:45,530
beautiful in theory right but the

00:26:43,790 --> 00:26:47,030
compulsion just go in and optimize

00:26:45,530 --> 00:26:48,980
things because it can without actually

00:26:47,030 --> 00:26:51,620
giving you any benefits right the point

00:26:48,980 --> 00:26:53,300
of saying I will add any benign races if

00:26:51,620 --> 00:26:55,820
you don't already have any isn't like

00:26:53,300 --> 00:26:57,680
I'll catch you if you do right the point

00:26:55,820 --> 00:27:00,410
is it should be actually useful to

00:26:57,680 --> 00:27:01,670
optimize things right and so I think

00:27:00,410 --> 00:27:02,990
that's another kind of common

00:27:01,670 --> 00:27:04,820
misunderstanding like the compiler just

00:27:02,990 --> 00:27:06,500
doesn't just go in and try to optimize

00:27:04,820 --> 00:27:08,540
your code into being incorrect or

00:27:06,500 --> 00:27:10,280
performing the wrong thing right the

00:27:08,540 --> 00:27:12,800
compiler tries to optimize things cuz

00:27:10,280 --> 00:27:14,510
it's faster and useful ways right and

00:27:12,800 --> 00:27:16,040
again like tooling is there to try to

00:27:14,510 --> 00:27:17,690
help you catch ways where you make

00:27:16,040 --> 00:27:19,490
mistakes right so thread sanitizer or

00:27:17,690 --> 00:27:22,100
something like that should allow you to

00:27:19,490 --> 00:27:25,370
catch races in your code now put another

00:27:22,100 --> 00:27:26,960
way programs should just continue

00:27:25,370 --> 00:27:29,210
working if they were correct before

00:27:26,960 --> 00:27:31,070
after we've optimized them right first

00:27:29,210 --> 00:27:33,230
put correct before should be it should

00:27:31,070 --> 00:27:37,070
continue to be correct afterwards now

00:27:33,230 --> 00:27:38,870
another way that I see it is is is that

00:27:37,070 --> 00:27:41,990
really the the compiler should only be

00:27:38,870 --> 00:27:44,210
able to optimize what the hardware can

00:27:41,990 --> 00:27:46,430
do in a certain way right so if the

00:27:44,210 --> 00:27:48,410
hardware could reorder your instructions

00:27:46,430 --> 00:27:49,700
despite you know whatever you do then

00:27:48,410 --> 00:27:51,770
the compiler should be able to do that

00:27:49,700 --> 00:27:53,360
as well right and so if you have say a

00:27:51,770 --> 00:27:55,580
loop that has a bunch of non-atomic

00:27:53,360 --> 00:27:57,410
things nothing atomic in that loop then

00:27:55,580 --> 00:27:59,060
that loop should be optimizable loads

00:27:57,410 --> 00:28:00,980
and stores should be optimizable as long

00:27:59,060 --> 00:28:03,410
as it doesn't create extra races and

00:28:00,980 --> 00:28:04,520
pretty early on when the C++ memory

00:28:03,410 --> 00:28:06,530
model was being standardized they

00:28:04,520 --> 00:28:08,570
actually found a bug and I think GCC

00:28:06,530 --> 00:28:10,430
where GC would kind of speculate that

00:28:08,570 --> 00:28:12,830
the loop would execute at least once

00:28:10,430 --> 00:28:15,200
right and so what it would do is it

00:28:12,830 --> 00:28:17,690
would perform one iteration of the loop

00:28:15,200 --> 00:28:19,820
right because it was like oh I'm gonna

00:28:17,690 --> 00:28:21,170
guess this will execute once it happened

00:28:19,820 --> 00:28:22,760
that the loop could execute zero times

00:28:21,170 --> 00:28:24,410
and so what it would do afterwards after

00:28:22,760 --> 00:28:26,270
the loop executed it would check did

00:28:24,410 --> 00:28:28,280
that did this execute at least once if

00:28:26,270 --> 00:28:30,800
not it would undo the first iteration

00:28:28,280 --> 00:28:33,170
right now that happened to make the code

00:28:30,800 --> 00:28:35,240
faster but it also happened to make it

00:28:33,170 --> 00:28:38,450
incorrect right so that's not a good

00:28:35,240 --> 00:28:40,100
optimization and so just see how to fix

00:28:38,450 --> 00:28:41,810
that optimization which is it's a bit

00:28:40,100 --> 00:28:46,310
unfortunate but it's better to have

00:28:41,810 --> 00:28:50,360
correct code than fast code all right

00:28:46,310 --> 00:28:51,590
now let's go a bit into what the

00:28:50,360 --> 00:28:52,880
compiler can actually do and I'll try to

00:28:51,590 --> 00:28:56,990
show you a bit more code here

00:28:52,880 --> 00:28:59,600
all right now as I said I see it as like

00:28:56,990 --> 00:29:01,760
what can the hardware do one thing that

00:28:59,600 --> 00:29:03,680
you'll remember is I said well-armed v8

00:29:01,760 --> 00:29:06,170
was kind of designed with a similar

00:29:03,680 --> 00:29:09,470
memory model in mind is what C++ has

00:29:06,170 --> 00:29:11,870
isn't that a bit circular right like the

00:29:09,470 --> 00:29:13,070
hardware is falling with C++ does C++

00:29:11,870 --> 00:29:14,450
pause well the hardware does and I'm

00:29:13,070 --> 00:29:15,680
saying the compiler can do whatever the

00:29:14,450 --> 00:29:17,510
hardware can do right that's kind of

00:29:15,680 --> 00:29:22,250
circular that's kind of neat also I

00:29:17,510 --> 00:29:24,140
think now you know yeah maybe we can do

00:29:22,250 --> 00:29:25,610
more than what hard work can do and I'll

00:29:24,140 --> 00:29:28,100
give you a few examples of that

00:29:25,610 --> 00:29:29,810
afterwards now

00:29:28,100 --> 00:29:32,660
I'm sorry few examples and I'll show you

00:29:29,810 --> 00:29:33,980
a very simple thing here I have a bit of

00:29:32,660 --> 00:29:35,750
code that just doesn't increment adds

00:29:33,980 --> 00:29:37,550
one to a location and I have another one

00:29:35,750 --> 00:29:39,740
to this two increments right now the

00:29:37,550 --> 00:29:43,640
obvious optimization for this is to just

00:29:39,740 --> 00:29:45,710
plus two and step right so that's kind

00:29:43,640 --> 00:29:47,060
of straightforward right like wouldn't

00:29:45,710 --> 00:29:48,890
you be mad if your compiler didn't do

00:29:47,060 --> 00:29:51,020
that right this it whether it's atomic

00:29:48,890 --> 00:29:53,930
or not doesn't really matter like this

00:29:51,020 --> 00:29:56,510
isn't adding a race right like it adds

00:29:53,930 --> 00:29:58,070
at on this city but it can't hinder a

00:29:56,510 --> 00:30:00,410
forward progress so it must be correct

00:29:58,070 --> 00:30:03,250
and in this case like you know one fewer

00:30:00,410 --> 00:30:05,420
instruction and there's no way that a

00:30:03,250 --> 00:30:07,850
valid code could have could have

00:30:05,420 --> 00:30:10,490
observed that you added one and then

00:30:07,850 --> 00:30:12,500
added one right so that's why I think

00:30:10,490 --> 00:30:14,780
two is fine right the only racy code

00:30:12,500 --> 00:30:17,180
could have observed plus one plus one

00:30:14,780 --> 00:30:18,890
right and so what the compiler says is

00:30:17,180 --> 00:30:20,570
I'll just but assume you don't have

00:30:18,890 --> 00:30:22,760
races there is therefore no way you

00:30:20,570 --> 00:30:25,430
could observe plus one plus one right

00:30:22,760 --> 00:30:28,190
therefore I'll just do plus T right

00:30:25,430 --> 00:30:31,310
straightforward right now here's a

00:30:28,190 --> 00:30:32,810
similar example right I have one version

00:30:31,310 --> 00:30:35,510
that adds one and I have one version

00:30:32,810 --> 00:30:37,640
that adds just a value right now I'm

00:30:35,510 --> 00:30:39,890
gonna lower that to x86 it's going to

00:30:37,640 --> 00:30:41,660
look like this right one of them doesn't

00:30:39,890 --> 00:30:43,370
Inc there's an instruction for adding

00:30:41,660 --> 00:30:45,800
one to a thing and the other one doesn't

00:30:43,370 --> 00:30:47,360
add now this is interesting right those

00:30:45,800 --> 00:30:49,850
of you that know x86 right now should be

00:30:47,360 --> 00:30:51,140
shaking your heads right first we're not

00:30:49,850 --> 00:30:52,190
going to win the Turing award for doing

00:30:51,140 --> 00:30:55,220
this because it's kind of a dumb

00:30:52,190 --> 00:30:57,440
optimization but at the same time okay

00:30:55,220 --> 00:31:00,070
they have a lot prefix both instructions

00:30:57,440 --> 00:31:02,900
happen to be three bytes that's cool but

00:31:00,070 --> 00:31:04,730
it may not actually be a good idea to do

00:31:02,900 --> 00:31:06,290
an ink instead of doing an app right and

00:31:04,730 --> 00:31:07,670
naively you look at x86 and

00:31:06,290 --> 00:31:09,230
say you have an instruction to add one

00:31:07,670 --> 00:31:11,960
that must be a good instruction to use

00:31:09,230 --> 00:31:14,900
well not really because it happens that

00:31:11,960 --> 00:31:17,420
ok it uses one less register but it also

00:31:14,900 --> 00:31:19,220
kind of partially writes the flags at so

00:31:17,420 --> 00:31:20,780
x86 has a bunch of flag registers and it

00:31:19,220 --> 00:31:23,090
just partially writes one of them and so

00:31:20,780 --> 00:31:24,770
it happens in a lot of cases add could

00:31:23,090 --> 00:31:26,060
be faster than ink all right and so you

00:31:24,770 --> 00:31:29,720
can't have to benchmark those things

00:31:26,060 --> 00:31:31,130
before implementing them so yeah maybe

00:31:29,720 --> 00:31:32,180
the compiler knows better maybe it

00:31:31,130 --> 00:31:33,140
doesn't right but you would hope that

00:31:32,180 --> 00:31:35,930
your compiler vendors

00:31:33,140 --> 00:31:39,860
Tunes tune their thing to try out to see

00:31:35,930 --> 00:31:42,050
whether that makes sense or not now one

00:31:39,860 --> 00:31:44,180
thing that happens pretty often is is

00:31:42,050 --> 00:31:45,800
inlining right and even with really

00:31:44,180 --> 00:31:48,470
tight atomic code inlining is really

00:31:45,800 --> 00:31:49,910
really important right and so so that

00:31:48,470 --> 00:31:51,530
exposes certain optimization

00:31:49,910 --> 00:31:53,090
opportunities sometimes right so here's

00:31:51,530 --> 00:31:55,280
an example of code that does a compare

00:31:53,090 --> 00:31:57,020
exchange and then sees whether the

00:31:55,280 --> 00:31:59,600
expected result is the same as the

00:31:57,020 --> 00:32:00,890
desired result right and imagine that

00:31:59,600 --> 00:32:02,660
happens through inlining right so yeah

00:32:00,890 --> 00:32:04,430
right dump code it just happened to be

00:32:02,660 --> 00:32:06,500
done because you in lined it right that

00:32:04,430 --> 00:32:08,480
happens really really often in in just

00:32:06,500 --> 00:32:10,760
general code doesn't hat it's nothing

00:32:08,480 --> 00:32:12,620
specific to act on the city well that

00:32:10,760 --> 00:32:13,940
code could be changed to a compare same

00:32:12,620 --> 00:32:15,230
shrunk that just returns the result

00:32:13,940 --> 00:32:17,750
because it happens that instruction

00:32:15,230 --> 00:32:18,980
already does what you want right and on

00:32:17,750 --> 00:32:21,770
certain architectures what's interesting

00:32:18,980 --> 00:32:25,430
is that so for example on x86 comp

00:32:21,770 --> 00:32:27,620
exchange returns both both the value

00:32:25,430 --> 00:32:29,060
that are loaded and it returns a flag of

00:32:27,620 --> 00:32:30,500
whether that was the thing you wanted or

00:32:29,060 --> 00:32:32,510
not right so if the compiler is really

00:32:30,500 --> 00:32:34,250
smart it can have both of these at the

00:32:32,510 --> 00:32:36,260
same time and it happens that some

00:32:34,250 --> 00:32:37,640
compilers don't really represent such

00:32:36,260 --> 00:32:40,430
things very well so it's actually kind

00:32:37,640 --> 00:32:41,870
of hard talk two months right but that's

00:32:40,430 --> 00:32:45,890
another problem the compilers can get

00:32:41,870 --> 00:32:47,810
better at now here's a tricky one it'll

00:32:45,890 --> 00:32:49,820
work for any memory order but release

00:32:47,810 --> 00:32:52,610
and acquire release right so what I'm

00:32:49,820 --> 00:32:54,800
doing is I'm doing something where the

00:32:52,610 --> 00:32:58,340
desired value is the expected value and

00:32:54,800 --> 00:32:59,630
I do a context change with just whatever

00:32:58,340 --> 00:33:02,450
memory order I wanted to put in there

00:32:59,630 --> 00:33:04,850
right now that happens to be the same as

00:33:02,450 --> 00:33:05,960
doing this thing well is it actually the

00:33:04,850 --> 00:33:09,350
same because I have this little dagger

00:33:05,960 --> 00:33:11,300
here right not quite the compiler has to

00:33:09,350 --> 00:33:13,490
like transform this and what it calls

00:33:11,300 --> 00:33:14,900
quote unquote a release sequence now

00:33:13,490 --> 00:33:18,620
release sequences are this magical thing

00:33:14,900 --> 00:33:19,820
back in 1.10 and it also has loops sorry

00:33:18,620 --> 00:33:22,970
1 bits too

00:33:19,820 --> 00:33:25,280
and and and yeah so anyways it actually

00:33:22,970 --> 00:33:26,990
has to kind of do a bit more work to do

00:33:25,280 --> 00:33:28,460
this properly right so I don't think any

00:33:26,990 --> 00:33:31,670
compiler actually does this optimization

00:33:28,460 --> 00:33:34,670
even though it could now here's another

00:33:31,670 --> 00:33:38,090
example I have a load and I have a store

00:33:34,670 --> 00:33:41,330
what does that look like any other

00:33:38,090 --> 00:33:43,010
instruction you would use instead no

00:33:41,330 --> 00:33:44,300
there's this exchange thing that you can

00:33:43,010 --> 00:33:45,920
do instead right so you have a memory

00:33:44,300 --> 00:33:47,390
location you do a load and you do a

00:33:45,920 --> 00:33:49,970
store what you're doing is swapping two

00:33:47,390 --> 00:33:51,980
things what i'm doing here is i'm adding

00:33:49,970 --> 00:33:53,330
atomicity right remember there's no way

00:33:51,980 --> 00:33:54,500
this could have synced the first one

00:33:53,330 --> 00:33:58,130
could have synchronized with anything

00:33:54,500 --> 00:34:01,220
right little loan in the store but by

00:33:58,130 --> 00:34:03,350
making this more atomic and going from

00:34:01,220 --> 00:34:05,870
one into two instructions right one that

00:34:03,350 --> 00:34:08,120
was a pure load instruction whether it

00:34:05,870 --> 00:34:10,520
was a pure store instruction to having

00:34:08,120 --> 00:34:12,169
an instruction that is both read and

00:34:10,520 --> 00:34:13,850
write at the same time and in some

00:34:12,169 --> 00:34:16,040
architecture it happens to be better to

00:34:13,850 --> 00:34:17,300
have a write after read than it is to

00:34:16,040 --> 00:34:19,460
have an exchange instruction that does

00:34:17,300 --> 00:34:23,090
both at the same time right so that that

00:34:19,460 --> 00:34:26,030
doesn't necessarily pay off right now

00:34:23,090 --> 00:34:28,490
okay if you want to write like deep down

00:34:26,030 --> 00:34:30,050
the assembly code maybe you can do that

00:34:28,490 --> 00:34:32,000
maybe you know the fact that this isn't

00:34:30,050 --> 00:34:34,130
faster or not right but I'm gonna say

00:34:32,000 --> 00:34:36,110
this like this takes a lot of work to

00:34:34,130 --> 00:34:38,270
prove if every programmer from writes

00:34:36,110 --> 00:34:39,740
inline assembly has to figure this out

00:34:38,270 --> 00:34:41,750
whether it's faster or not and in which

00:34:39,740 --> 00:34:44,210
architecture which architecture in which

00:34:41,750 --> 00:34:45,830
version of an architecture then we're

00:34:44,210 --> 00:34:47,360
kind of wasting our time collectively as

00:34:45,830 --> 00:34:49,070
an industry right where's the compiler

00:34:47,360 --> 00:34:50,720
could just get it correct one so just

00:34:49,070 --> 00:34:52,460
get it wrong and then get a bug file and

00:34:50,720 --> 00:34:54,560
then get it correct afterwards then like

00:34:52,460 --> 00:34:55,970
everyone having to do that work right

00:34:54,560 --> 00:34:57,470
Hey just to be quick

00:34:55,970 --> 00:34:59,420
compilers get this wrong all the time

00:34:57,470 --> 00:35:00,650
right so you should just file above if

00:34:59,420 --> 00:35:02,180
it's wrong right you figure out that

00:35:00,650 --> 00:35:03,440
it's wrong you just like final button

00:35:02,180 --> 00:35:06,470
and eventually it'll get fixed or you

00:35:03,440 --> 00:35:08,930
fix it yourself that's also cool okay so

00:35:06,470 --> 00:35:10,460
so far I've had kind of just toy

00:35:08,930 --> 00:35:14,440
problems but I'll try to go into a more

00:35:10,460 --> 00:35:17,390
interesting problem so I had a co-worker

00:35:14,440 --> 00:35:18,590
maybe a year ago or something send an

00:35:17,390 --> 00:35:21,130
email to a mailing this and saying I

00:35:18,590 --> 00:35:23,570
have this interesting problem right and

00:35:21,130 --> 00:35:24,920
and the reaction you should have when

00:35:23,570 --> 00:35:26,270
someone says this and it's like you know

00:35:24,920 --> 00:35:27,740
people interested in current currency

00:35:26,270 --> 00:35:29,750
and compilers and stuff like that that

00:35:27,740 --> 00:35:33,080
this is the reaction I have

00:35:29,750 --> 00:35:36,740
right yes tell me more

00:35:33,080 --> 00:35:40,880
and we he said is well we had this code

00:35:36,740 --> 00:35:42,619
and it does this thing and and it uses

00:35:40,880 --> 00:35:46,250
Atomics but not really it's like it's

00:35:42,619 --> 00:35:48,500
like using multiple cores but it it the

00:35:46,250 --> 00:35:51,320
code doesn't use the tommix at all right

00:35:48,500 --> 00:35:53,570
and so he explained his problem my code

00:35:51,320 --> 00:35:55,340
doesn't read then it doesn't modify and

00:35:53,570 --> 00:35:56,690
then I was right it was based on this

00:35:55,340 --> 00:36:00,619
paper that got published awhile to go a

00:35:56,690 --> 00:36:03,740
while ago called hagwa and the idea is

00:36:00,619 --> 00:36:05,750
that you have a bunch of threads and the

00:36:03,740 --> 00:36:07,130
huge data structure right and so hugely

00:36:05,750 --> 00:36:09,590
the structure of floating-point values

00:36:07,130 --> 00:36:11,990
and what they do is they just kind of do

00:36:09,590 --> 00:36:13,730
racy reads and writes alright so they do

00:36:11,990 --> 00:36:15,440
a bunch of computations and then that's

00:36:13,730 --> 00:36:18,730
very big data structure they have very

00:36:15,440 --> 00:36:21,260
sparse updates and statistically it's

00:36:18,730 --> 00:36:22,790
really really really unlikely that

00:36:21,260 --> 00:36:24,890
multiple threads will try to update the

00:36:22,790 --> 00:36:27,020
same location at the same time in their

00:36:24,890 --> 00:36:29,000
specific application and that paper

00:36:27,020 --> 00:36:30,830
actually went out and proved that that

00:36:29,000 --> 00:36:32,869
was really statistically unlikely and

00:36:30,830 --> 00:36:34,970
that if it happened that you did a read

00:36:32,869 --> 00:36:36,560
then I modify and then I write right so

00:36:34,970 --> 00:36:38,210
not in the atomic operation but you did

00:36:36,560 --> 00:36:40,880
these things separately then

00:36:38,210 --> 00:36:43,940
statistically losing one update out of

00:36:40,880 --> 00:36:46,010
so many doesn't actually matter right

00:36:43,940 --> 00:36:48,200
that's interesting right now we're not

00:36:46,010 --> 00:36:50,480
in sequentially consistency land anymore

00:36:48,200 --> 00:36:52,310
very different right but it's an

00:36:50,480 --> 00:36:54,589
interesting property of that specific

00:36:52,310 --> 00:36:57,380
code now the problem is the code that

00:36:54,589 --> 00:37:03,050
they had looked like this who sees the

00:36:57,380 --> 00:37:04,849
but no one there are no Atomics in this

00:37:03,050 --> 00:37:06,560
code head-on I said multiple threads

00:37:04,849 --> 00:37:09,260
updating this data structure

00:37:06,560 --> 00:37:11,720
totally not atomically that happens to

00:37:09,260 --> 00:37:13,430
be a race it happens to be okay for

00:37:11,720 --> 00:37:16,280
their code but it's still undefined

00:37:13,430 --> 00:37:18,800
behavior right and but what's

00:37:16,280 --> 00:37:21,290
interesting is that on x86 the code that

00:37:18,800 --> 00:37:24,500
gets generated is this right like that's

00:37:21,290 --> 00:37:26,570
pretty sweet code right now it's it's

00:37:24,500 --> 00:37:29,060
not a read modify write it's a read

00:37:26,570 --> 00:37:31,820
semicolon modify semicolon right those

00:37:29,060 --> 00:37:35,230
are two distinct instructions right but

00:37:31,820 --> 00:37:37,670
it happens to be really really fast so

00:37:35,230 --> 00:37:40,339
so they're like well we'd like to you

00:37:37,670 --> 00:37:42,770
know be standards compliant but the

00:37:40,339 --> 00:37:43,770
problem is when we do that it's really

00:37:42,770 --> 00:37:45,420
slow

00:37:43,770 --> 00:37:47,190
right it's the first thing they tried

00:37:45,420 --> 00:37:51,590
what do you try when you do this well

00:37:47,190 --> 00:37:54,840
you add volatile of course right and

00:37:51,590 --> 00:37:58,230
they did that and and the code that got

00:37:54,840 --> 00:38:01,110
generated was the same they're like

00:37:58,230 --> 00:38:04,860
sweep we're good and we were like what

00:38:01,110 --> 00:38:06,270
but not do Paula told I gave this big

00:38:04,860 --> 00:38:08,400
array and it's all volatile things and

00:38:06,270 --> 00:38:11,119
like volatile doesn't really do what you

00:38:08,400 --> 00:38:14,040
want and we'll go into that a bit later

00:38:11,119 --> 00:38:16,500
but then they were like all right well

00:38:14,040 --> 00:38:18,990
if we instead do this is that correct

00:38:16,500 --> 00:38:21,000
right so we have this atomic float or

00:38:18,990 --> 00:38:23,430
this big array of atomic float and we do

00:38:21,000 --> 00:38:25,920
a load that's relaxed and then if we do

00:38:23,430 --> 00:38:29,310
the modification and we do the store is

00:38:25,920 --> 00:38:31,230
that is that correct well kind of right

00:38:29,310 --> 00:38:33,060
so if you remember when we were talking

00:38:31,230 --> 00:38:34,890
earlier relax doesn't you doesn't really

00:38:33,060 --> 00:38:37,140
guarantee that things will propagate

00:38:34,890 --> 00:38:39,360
right this isn't guarantee observability

00:38:37,140 --> 00:38:41,100
right but it happens that on the

00:38:39,360 --> 00:38:42,990
platform they were on say x86 or

00:38:41,100 --> 00:38:44,790
whatever well it happens to hold the

00:38:42,990 --> 00:38:47,070
property that like once uses store it

00:38:44,790 --> 00:38:50,010
gets its visible pretty much there and

00:38:47,070 --> 00:38:53,760
then right so it happens to be correct I

00:38:50,010 --> 00:38:55,230
guess right and the idea was well we do

00:38:53,760 --> 00:38:56,760
this thing and that should generate

00:38:55,230 --> 00:38:59,700
exactly the same code as we had before

00:38:56,760 --> 00:39:02,369
and now we'll have fast code and will be

00:38:59,700 --> 00:39:04,109
standard pedants compliant right that's

00:39:02,369 --> 00:39:06,420
awesome that's a great property right

00:39:04,109 --> 00:39:08,100
they they wanted that right and the

00:39:06,420 --> 00:39:11,100
problem is they did that and then they

00:39:08,100 --> 00:39:14,010
got this code right and that's three

00:39:11,100 --> 00:39:15,750
times slower like what the hell right

00:39:14,010 --> 00:39:17,310
like we wanted to be all standards and

00:39:15,750 --> 00:39:19,680
stuff and that doesn't like what do you

00:39:17,310 --> 00:39:21,570
what right so that's when they decided

00:39:19,680 --> 00:39:23,190
send email the mailing list and then I

00:39:21,570 --> 00:39:26,070
had the face that I showed earlier

00:39:23,190 --> 00:39:27,869
gene Wilder face earlier and I said let

00:39:26,070 --> 00:39:29,910
me try to optimize this right so I went

00:39:27,869 --> 00:39:30,930
in and got my hands dirty Intel VM and I

00:39:29,910 --> 00:39:34,230
don't really know that part of the code

00:39:30,930 --> 00:39:37,140
base I just made it faster weight

00:39:34,230 --> 00:39:38,730
optimization for the win now the part of

00:39:37,140 --> 00:39:40,320
this story that I don't usually tell now

00:39:38,730 --> 00:39:42,450
tell it to you guys just you know for

00:39:40,320 --> 00:39:44,580
true shits and giggles is that I did

00:39:42,450 --> 00:39:46,770
that and I think how long was there like

00:39:44,580 --> 00:39:48,660
two months later there's actually a bug

00:39:46,770 --> 00:39:52,650
caused by an opposition because I forgot

00:39:48,660 --> 00:39:54,300
to do one thing right and then that guy

00:39:52,650 --> 00:39:56,400
fixed it it was awesome

00:39:54,300 --> 00:39:57,490
took forever to debug it was awesome

00:39:56,400 --> 00:40:01,270
right Chandler

00:39:57,490 --> 00:40:03,760
yeah awesome right so like there was a

00:40:01,270 --> 00:40:05,109
bud sorry but like the rest of the code

00:40:03,760 --> 00:40:06,460
optimizer really well it's like if you

00:40:05,109 --> 00:40:08,050
some really complicated thing in the

00:40:06,460 --> 00:40:09,520
completely different context that the

00:40:08,050 --> 00:40:12,400
optimization didn't work out so well

00:40:09,520 --> 00:40:13,780
right but but what I want to get to is

00:40:12,400 --> 00:40:15,040
that you can actually write correct code

00:40:13,780 --> 00:40:17,080
that would be fast if you look at the

00:40:15,040 --> 00:40:19,119
code if it's not fast then you're like

00:40:17,080 --> 00:40:21,130
kind of file a bug or like try to stick

00:40:19,119 --> 00:40:23,650
the compiler that's possible right now

00:40:21,130 --> 00:40:25,089
let's look at a few other things the

00:40:23,650 --> 00:40:26,589
compiler can do a bunch of other stuff

00:40:25,089 --> 00:40:28,119
right it's just usually when it sees

00:40:26,589 --> 00:40:29,800
atomic or it sees vault or whatever just

00:40:28,119 --> 00:40:31,180
compiler throws its hand in the air and

00:40:29,800 --> 00:40:33,220
it says well I'm not gonna touch

00:40:31,180 --> 00:40:34,900
anything but if it were bits my looks

00:40:33,220 --> 00:40:37,690
smarter it can do a bunch of stuff it

00:40:34,900 --> 00:40:39,070
can do inlining constant propagation it

00:40:37,690 --> 00:40:41,290
can do a bunch of interesting tricks

00:40:39,070 --> 00:40:43,150
right where like if you you know do all

00:40:41,290 --> 00:40:45,040
ones and you do an end and that's kind

00:40:43,150 --> 00:40:47,650
of like a load right it can do a bunch

00:40:45,040 --> 00:40:48,910
of interesting stuff like this right now

00:40:47,650 --> 00:40:50,560
those are all kind of really

00:40:48,910 --> 00:40:51,790
straightforward compiler transformations

00:40:50,560 --> 00:40:53,830
and some of them are actually

00:40:51,790 --> 00:40:57,520
implemented in compilers not all right

00:40:53,830 --> 00:40:59,200
so what's the takeaway here well if

00:40:57,520 --> 00:41:00,280
simple things are hard right like some

00:40:59,200 --> 00:41:02,080
of the stuff I showed you is kind of

00:41:00,280 --> 00:41:03,640
hard then like your assembly codes

00:41:02,080 --> 00:41:05,800
probably not correct anyways there's

00:41:03,640 --> 00:41:07,720
probably not that fast and it probably

00:41:05,800 --> 00:41:08,950
won't remain correct or as fast as it

00:41:07,720 --> 00:41:10,510
could be right because as you upgrade

00:41:08,950 --> 00:41:12,310
your architectures it won't wear as your

00:41:10,510 --> 00:41:14,290
video compiler and your architectures

00:41:12,310 --> 00:41:17,140
things usually tend to get faster for

00:41:14,290 --> 00:41:19,420
that new architecture right and usually

00:41:17,140 --> 00:41:20,950
the the push bag that we get is compiler

00:41:19,420 --> 00:41:23,619
writers and there's like people who give

00:41:20,950 --> 00:41:25,869
thoughts is oh well I don't trust my

00:41:23,619 --> 00:41:27,310
compiler well I'm sorry to break it to

00:41:25,869 --> 00:41:29,740
you but you are already trusting your

00:41:27,310 --> 00:41:34,750
compiler right like you kind of have to

00:41:29,740 --> 00:41:36,400
it's compiling your code right you don't

00:41:34,750 --> 00:41:37,750
trust it to generate fast code but you

00:41:36,400 --> 00:41:38,320
trust it for everything else it's kind

00:41:37,750 --> 00:41:40,180
of silly

00:41:38,320 --> 00:41:44,050
right it's you're really kind of

00:41:40,180 --> 00:41:46,750
deluding yourself Niki's and really like

00:41:44,050 --> 00:41:48,550
you know that's the question we get what

00:41:46,750 --> 00:41:53,589
is the compiler image suboptimal code

00:41:48,550 --> 00:41:55,450
what do you do file a bug all right or

00:41:53,589 --> 00:41:56,800
complain on a hacker news that's also

00:41:55,450 --> 00:41:59,620
good

00:41:56,800 --> 00:42:01,180
right but not on the comments for this

00:41:59,620 --> 00:42:05,320
YouTube video don't I just don't look at

00:42:01,180 --> 00:42:06,760
the comments now at this point of the

00:42:05,320 --> 00:42:08,260
talk as I'm going to talk about sequence

00:42:06,760 --> 00:42:10,180
locks they're a really cool little

00:42:08,260 --> 00:42:11,500
atomic optimization the problem is Hans

00:42:10,180 --> 00:42:13,030
talked about it in his talk yesterday so

00:42:11,500 --> 00:42:14,710
I'll just refer you to the YouTube video

00:42:13,030 --> 00:42:16,630
because he did a much better job than I

00:42:14,710 --> 00:42:18,610
did because like all these slides are

00:42:16,630 --> 00:42:20,110
kind of taken from his paper right so

00:42:18,610 --> 00:42:21,430
I'll just skip over that right it's a

00:42:20,110 --> 00:42:22,690
really cool data structure if you don't

00:42:21,430 --> 00:42:26,410
know about it you should check it out

00:42:22,690 --> 00:42:27,970
it's a thing aimed at just read mostly

00:42:26,410 --> 00:42:29,680
data structure it's things that like a

00:42:27,970 --> 00:42:31,570
bunch of threads just read all the time

00:42:29,680 --> 00:42:33,190
but you update it every only every so

00:42:31,570 --> 00:42:34,300
often I mean the code looks kind of

00:42:33,190 --> 00:42:36,580
tricky and it has a bunch of different

00:42:34,300 --> 00:42:38,440
things well the me the really

00:42:36,580 --> 00:42:39,910
interesting thing here is that we kind

00:42:38,440 --> 00:42:41,740
of want a release store and there is no

00:42:39,910 --> 00:42:44,380
really store in the language right and

00:42:41,740 --> 00:42:46,300
so Hans came up with this really cool

00:42:44,380 --> 00:42:48,760
thing called reads don't modify right

00:42:46,300 --> 00:42:50,680
it's the cool optimization the compiler

00:42:48,760 --> 00:42:52,300
can also do and what it does is do a

00:42:50,680 --> 00:42:54,820
fetch ad with zero so what does the

00:42:52,300 --> 00:42:56,380
fetch add with zero does what does is it

00:42:54,820 --> 00:42:58,630
just kind of add zero to a location

00:42:56,380 --> 00:43:00,760
which does nothing right and that's the

00:42:58,630 --> 00:43:02,650
way to tell the compiler well hey I want

00:43:00,760 --> 00:43:05,470
to have a load but I want this load to

00:43:02,650 --> 00:43:08,320
be release right now that's kind of a

00:43:05,470 --> 00:43:09,670
ugly hat but it happens to generate kind

00:43:08,320 --> 00:43:11,410
of interesting code or if the compiler

00:43:09,670 --> 00:43:12,730
was smart it would write so there's

00:43:11,410 --> 00:43:14,410
different types of code that get

00:43:12,730 --> 00:43:16,540
generated in different circumstances for

00:43:14,410 --> 00:43:18,130
that if whether you use the fence

00:43:16,540 --> 00:43:20,200
manually or whether you use the read

00:43:18,130 --> 00:43:22,030
don't modify right and the interesting

00:43:20,200 --> 00:43:24,970
takeaway here is that if the compiler

00:43:22,030 --> 00:43:26,860
does its job well you get nice speed ups

00:43:24,970 --> 00:43:28,600
right so I'll refer you to the paper

00:43:26,860 --> 00:43:30,070
it's a really interesting thing but like

00:43:28,600 --> 00:43:31,600
in different cases you write different

00:43:30,070 --> 00:43:33,310
code the compiler optimizes it

00:43:31,600 --> 00:43:34,930
differently and then things get faster

00:43:33,310 --> 00:43:37,540
or slower and what's really interesting

00:43:34,930 --> 00:43:39,610
in this case and that is that for SEC

00:43:37,540 --> 00:43:41,290
Lots it's not just that things get

00:43:39,610 --> 00:43:42,280
faster depending on the compiler doesn't

00:43:41,290 --> 00:43:44,200
what code you wrote

00:43:42,280 --> 00:43:45,820
it's that it'll depend on the

00:43:44,200 --> 00:43:48,910
architecture you're on and it'll depend

00:43:45,820 --> 00:43:51,640
on how many cores you have right so in

00:43:48,910 --> 00:43:55,060
this case it's it's the read don't

00:43:51,640 --> 00:43:56,950
modify write instruction it's it doesn't

00:43:55,060 --> 00:43:58,360
really scale with the number of threads

00:43:56,950 --> 00:43:59,710
that you have so that's kind of another

00:43:58,360 --> 00:44:00,970
thing to keep in mind when you try it

00:43:59,710 --> 00:44:04,270
out to my stuff and you know when the

00:44:00,970 --> 00:44:06,610
compiler in its code is is that the code

00:44:04,270 --> 00:44:07,900
that you generate also highly depends on

00:44:06,610 --> 00:44:09,819
how many people are going to try to

00:44:07,900 --> 00:44:13,479
access the location at the same time

00:44:09,819 --> 00:44:15,160
right now as I was saying you can do a

00:44:13,479 --> 00:44:17,289
bunch of other compiler optimizations on

00:44:15,160 --> 00:44:19,239
Atomics you can you know maybe do dead

00:44:17,289 --> 00:44:20,949
storm Latian right if I do two stores

00:44:19,239 --> 00:44:23,619
back to back to the exact same location

00:44:20,949 --> 00:44:25,630
right and it's back to back I don't do

00:44:23,619 --> 00:44:27,369
anything in the middle then the compiler

00:44:25,630 --> 00:44:29,019
can go and say look you did two stores

00:44:27,369 --> 00:44:31,209
in the same location you're kind of dumb

00:44:29,019 --> 00:44:32,559
right like I'm gonna remove the first

00:44:31,209 --> 00:44:34,209
store and keep the second one because

00:44:32,559 --> 00:44:36,249
you know what unless you had a race

00:44:34,209 --> 00:44:39,999
nobody could have observed the first

00:44:36,249 --> 00:44:41,019
store or yeah yeah so you can do a bunch

00:44:39,999 --> 00:44:42,880
of other stuff you can do strength

00:44:41,019 --> 00:44:45,579
reduction and things like that and you

00:44:42,880 --> 00:44:48,279
cannot even optimize relaxed accesses

00:44:45,579 --> 00:44:50,799
right so here's an example where you

00:44:48,279 --> 00:44:54,039
have to read kind of this tricky code I

00:44:50,799 --> 00:44:54,729
stored 2x and wide but interleaved right

00:44:54,039 --> 00:44:56,619
now

00:44:54,729 --> 00:44:58,959
relax doesn't guarantee ordering between

00:44:56,619 --> 00:45:00,849
relaxed stores so what I'm allowed to do

00:44:58,959 --> 00:45:03,039
in this case is I'm allowed to call less

00:45:00,849 --> 00:45:04,989
than even though x and y were separate

00:45:03,039 --> 00:45:06,549
right they were kind of interleaved like

00:45:04,989 --> 00:45:08,410
this and I moved them together and then

00:45:06,549 --> 00:45:09,940
collapse them and compiler should do

00:45:08,410 --> 00:45:14,199
this I think LLVM does I'm not sure if

00:45:09,940 --> 00:45:15,459
Jesus he does yet now that leads to a

00:45:14,199 --> 00:45:16,900
kind of interesting question when I

00:45:15,459 --> 00:45:20,079
initially wrote to the paper that

00:45:16,900 --> 00:45:21,759
created the stock Hans Hans Baum kind of

00:45:20,079 --> 00:45:24,549
flipped that he was like whoa

00:45:21,759 --> 00:45:26,949
compilers do what like I can't just

00:45:24,549 --> 00:45:28,569
write a proper S bar like this that's

00:45:26,949 --> 00:45:31,949
what it means right so what I'm trying

00:45:28,569 --> 00:45:34,239
to do here and sorry I started had

00:45:31,949 --> 00:45:35,799
relaxed updates but I'm trying to do a

00:45:34,239 --> 00:45:36,940
bunch of really heavy work right so I

00:45:35,799 --> 00:45:38,979
have this loop that does heavy

00:45:36,940 --> 00:45:41,499
computation and then I just increment

00:45:38,979 --> 00:45:43,239
progress right now now what's

00:45:41,499 --> 00:45:45,339
interesting here is that I don't have

00:45:43,239 --> 00:45:47,589
any other atomic operations in that

00:45:45,339 --> 00:45:49,209
heavy amount of work right all I'm doing

00:45:47,589 --> 00:45:51,190
is I'm doing heavy work and I'm telling

00:45:49,209 --> 00:45:53,829
the progress bar oh another thread hey I

00:45:51,190 --> 00:45:55,359
did one more work right so the idea here

00:45:53,829 --> 00:45:57,039
is the compiler should be able to unroll

00:45:55,359 --> 00:45:58,329
the loop and do a bunch of optimizations

00:45:57,039 --> 00:46:01,239
to the code because none of that is

00:45:58,329 --> 00:46:04,390
atomic except the the progress thing

00:46:01,239 --> 00:46:06,069
right now the problems here is that the

00:46:04,390 --> 00:46:08,259
compiler in a lot of cases is allowed to

00:46:06,069 --> 00:46:09,999
do this optimization right so create a

00:46:08,259 --> 00:46:11,380
local copy of the progress thing that

00:46:09,999 --> 00:46:12,670
will just increment a local copy a

00:46:11,380 --> 00:46:14,079
million times or something like that and

00:46:12,670 --> 00:46:15,819
then just do the final updates your

00:46:14,079 --> 00:46:17,799
progress bar looks like most progress

00:46:15,819 --> 00:46:19,120
bars do they go from 0 to 100 in one

00:46:17,799 --> 00:46:24,110
shot

00:46:19,120 --> 00:46:26,660
right now that's not really what you

00:46:24,110 --> 00:46:30,410
wanted right but that's what you've said

00:46:26,660 --> 00:46:32,840
in this code and and so so we added some

00:46:30,410 --> 00:46:34,610
wording to C++ 17 to discourage this

00:46:32,840 --> 00:46:36,440
kind of optimization now it's super hand

00:46:34,610 --> 00:46:38,180
wavy wording it's in a note it's totally

00:46:36,440 --> 00:46:39,850
not normal it and says compiler really

00:46:38,180 --> 00:46:42,590
shouldn't do that in like weird cases

00:46:39,850 --> 00:46:43,970
right but but in most cases like you're

00:46:42,590 --> 00:46:45,710
actually doing synchronization you're

00:46:43,970 --> 00:46:47,660
not just like fire and forgetting writes

00:46:45,710 --> 00:46:49,490
and so in most cases that doesn't happen

00:46:47,660 --> 00:46:51,950
right it's just kind of an interesting

00:46:49,490 --> 00:46:54,110
corner case or like you know this this

00:46:51,950 --> 00:46:55,850
is same code right you really will

00:46:54,110 --> 00:46:57,800
people expect this to work and it

00:46:55,850 --> 00:46:59,900
happens that standard says that this is

00:46:57,800 --> 00:47:01,580
doesn't necessarily work now I don't

00:46:59,900 --> 00:47:04,250
know if compilers that optimize this

00:47:01,580 --> 00:47:05,870
specifically but as we start like adding

00:47:04,250 --> 00:47:07,490
new optimizations we'll have to be

00:47:05,870 --> 00:47:11,600
really careful and not break real-world

00:47:07,490 --> 00:47:13,520
code right now how do you disable the

00:47:11,600 --> 00:47:15,860
reader reordering or fusing that we saw

00:47:13,520 --> 00:47:19,430
earlier well there's a few ways to do it

00:47:15,860 --> 00:47:21,230
right now this is super objectionable

00:47:19,430 --> 00:47:23,660
right don't do that

00:47:21,230 --> 00:47:25,190
like I just don't write I say don't do

00:47:23,660 --> 00:47:27,200
that and I showed you code when I did

00:47:25,190 --> 00:47:32,810
consume that did exactly this right

00:47:27,200 --> 00:47:34,550
that's leadership now you could do

00:47:32,810 --> 00:47:36,230
signal fences but you're like what is

00:47:34,550 --> 00:47:37,490
the signal fence anyway right and signal

00:47:36,230 --> 00:47:39,110
fence was kind of put in there to kind

00:47:37,490 --> 00:47:40,640
of help like prevent this from happening

00:47:39,110 --> 00:47:42,170
because if a signal happened in the

00:47:40,640 --> 00:47:44,330
middle and whatever but it's kind of

00:47:42,170 --> 00:47:46,430
weird right like has anyone ever used

00:47:44,330 --> 00:47:48,770
single fence or seen in code like when

00:47:46,430 --> 00:47:51,770
you see it you're like what what is that

00:47:48,770 --> 00:47:53,870
right that's kind of weird you could use

00:47:51,770 --> 00:47:55,730
volatile now that won't work either

00:47:53,870 --> 00:47:58,040
that's just a dumb idea it won't work

00:47:55,730 --> 00:47:59,540
and then you know just don't use relax

00:47:58,040 --> 00:48:01,220
maybe but then like you're making this

00:47:59,540 --> 00:48:02,720
heavy computation like a tiny bit slower

00:48:01,220 --> 00:48:04,190
or something like that or you could

00:48:02,720 --> 00:48:05,690
synchronize with your progress bar right

00:48:04,190 --> 00:48:07,100
like increment and then the progress bar

00:48:05,690 --> 00:48:08,480
decrements and you look at the amount

00:48:07,100 --> 00:48:09,680
and whatever it's kind of weird there's

00:48:08,480 --> 00:48:12,170
a bunch of stuff you can do but it's

00:48:09,680 --> 00:48:13,550
weird so let's look at a bit more of

00:48:12,170 --> 00:48:15,500
what you can do those are all kind of

00:48:13,550 --> 00:48:17,030
like regular low-level optimizations but

00:48:15,500 --> 00:48:19,310
you can do higher level stuff as well

00:48:17,030 --> 00:48:21,200
right so compiler could go in and that's

00:48:19,310 --> 00:48:22,610
all kind of blue sky thinking or

00:48:21,200 --> 00:48:24,410
whatever but the compiler could go in

00:48:22,610 --> 00:48:26,630
and tag non-atomic functions and

00:48:24,410 --> 00:48:29,000
optimize around right so the compiler

00:48:26,630 --> 00:48:30,950
has already mark things as not doing

00:48:29,000 --> 00:48:32,130
agrees or not doing any rights or

00:48:30,950 --> 00:48:33,540
something like that it marks a

00:48:32,130 --> 00:48:35,580
thing other stuff like that it could

00:48:33,540 --> 00:48:36,990
mark functions as whether they have

00:48:35,580 --> 00:48:38,460
Atomics or not enough to Mai's around

00:48:36,990 --> 00:48:40,170
that that'd be kind of interesting right

00:48:38,460 --> 00:48:41,700
because usually functions kind of act as

00:48:40,170 --> 00:48:44,100
a barrier optimization unless you're

00:48:41,700 --> 00:48:45,480
doing interprocedural stuff that's kind

00:48:44,100 --> 00:48:46,230
of a basic kind of low lying through

00:48:45,480 --> 00:48:47,970
that we could do that's kind of

00:48:46,230 --> 00:48:49,740
interesting it could do something more

00:48:47,970 --> 00:48:51,690
interesting where it proves time to cook

00:48:49,740 --> 00:48:53,370
regions that don't interfere between

00:48:51,690 --> 00:48:55,020
each other and kind of optimizes around

00:48:53,370 --> 00:48:56,640
and that's not just about atomic sauce

00:48:55,020 --> 00:48:58,200
about the non Atomics there are under

00:48:56,640 --> 00:49:00,180
them right so you could have optimized

00:48:58,200 --> 00:49:02,580
things by proving that things don't just

00:49:00,180 --> 00:49:04,430
kind of touch each other then you could

00:49:02,580 --> 00:49:06,420
also optimize fencepost positioning

00:49:04,430 --> 00:49:09,030
especially in in languages that have

00:49:06,420 --> 00:49:10,440
like right barriers or something like if

00:49:09,030 --> 00:49:12,420
you have a GC running concurrently and

00:49:10,440 --> 00:49:14,280
something like that you end up having a

00:49:12,420 --> 00:49:16,020
lot of fences everywhere and the fences

00:49:14,280 --> 00:49:17,340
aren't always positioned optimally you

00:49:16,020 --> 00:49:19,080
have a big control flow and you have

00:49:17,340 --> 00:49:21,930
fences everywhere you could kind of

00:49:19,080 --> 00:49:23,580
prove that this the slope ad has yeah

00:49:21,930 --> 00:49:25,740
you'll put fences and slow paths and

00:49:23,580 --> 00:49:28,590
remove fences from the the harder path

00:49:25,740 --> 00:49:30,180
without removing correctness right so

00:49:28,590 --> 00:49:32,640
it's basically like just balancing the

00:49:30,180 --> 00:49:35,670
the fences in the control flow graph you

00:49:32,640 --> 00:49:37,350
could do that then you could prove

00:49:35,670 --> 00:49:39,000
things like oh this doesn't escape it's

00:49:37,350 --> 00:49:40,620
on the stack so there's no way you could

00:49:39,000 --> 00:49:42,270
be sharing it with everyone else or this

00:49:40,620 --> 00:49:44,340
isn't TLS or something like that right

00:49:42,270 --> 00:49:47,970
so there's a bunch of interesting stuff

00:49:44,340 --> 00:49:49,500
that we can do here now at this point

00:49:47,970 --> 00:49:50,820
you're all like okay well Atomics are

00:49:49,500 --> 00:49:52,500
really complex and like I'm not trying

00:49:50,820 --> 00:49:57,660
when you use them anymore I'm just gonna

00:49:52,500 --> 00:49:58,980
stick to stood mutex for sanity right is

00:49:57,660 --> 00:50:00,870
that a good idea well I think it is a

00:49:58,980 --> 00:50:05,010
good idea right it's easier to use

00:50:00,870 --> 00:50:07,620
correctly in theory right but but but

00:50:05,010 --> 00:50:09,270
the thing is you could still optimize

00:50:07,620 --> 00:50:11,940
stood mutex whether the compiler could

00:50:09,270 --> 00:50:13,620
do this because basically the way I see

00:50:11,940 --> 00:50:15,660
mutex and I may be slightly wrong but

00:50:13,620 --> 00:50:17,640
the way I see it is when you lock you

00:50:15,660 --> 00:50:19,530
create an acquire and when you release

00:50:17,640 --> 00:50:21,900
you when you unlock you create a release

00:50:19,530 --> 00:50:24,420
right that's kind of what mutex is do

00:50:21,900 --> 00:50:26,220
now the problem is from the compilers

00:50:24,420 --> 00:50:28,680
point of view it doesn't actually know

00:50:26,220 --> 00:50:30,150
about stood new text right like in in in

00:50:28,680 --> 00:50:32,130
in the standard library there's two

00:50:30,150 --> 00:50:34,230
mutex but then the compiler parses that

00:50:32,130 --> 00:50:35,670
just like anything else and then just

00:50:34,230 --> 00:50:37,560
generates code it doesn't really know

00:50:35,670 --> 00:50:38,940
that stimutex it kind of lies to itself

00:50:37,560 --> 00:50:40,830
it doesn't look at the name and say this

00:50:38,940 --> 00:50:43,380
is stood mutex right there look right

00:50:40,830 --> 00:50:45,090
and the thing is a good stood mutex

00:50:43,380 --> 00:50:45,660
doesn't just have like a spin loop

00:50:45,090 --> 00:50:48,000
that's

00:50:45,660 --> 00:50:49,829
stupids - new tax right a good student

00:50:48,000 --> 00:50:51,539
new text has things like calls to

00:50:49,829 --> 00:50:53,069
pthread and or colonel calls or

00:50:51,539 --> 00:50:54,839
something like that to make the mutex

00:50:53,069 --> 00:50:56,190
faster in the case where you can't get

00:50:54,839 --> 00:50:59,690
the lot in a reasonable amount of time

00:50:56,190 --> 00:51:01,950
right and any time you touch the colonel

00:50:59,690 --> 00:51:03,569
compiler just throws its hand in the air

00:51:01,950 --> 00:51:04,859
and said the colonel can do whatever so

00:51:03,569 --> 00:51:07,380
I'm not I'm gonna assume you did

00:51:04,859 --> 00:51:08,400
whatever right so so reasonably I can

00:51:07,380 --> 00:51:10,470
think well stewed meat eggs doesn't

00:51:08,400 --> 00:51:12,030
optimize anything but we're trying to

00:51:10,470 --> 00:51:14,010
add this thing called synchronic to the

00:51:12,030 --> 00:51:15,390
language and that may change this this

00:51:14,010 --> 00:51:17,460
this thing and we could actually start

00:51:15,390 --> 00:51:18,900
optimizing around stimutex and that's

00:51:17,460 --> 00:51:20,490
kind of interesting because there's a

00:51:18,900 --> 00:51:22,890
bunch of interesting optimizations we

00:51:20,490 --> 00:51:24,510
can do kind of a parallel to that if you

00:51:22,890 --> 00:51:26,160
have a shared pointer for example and

00:51:24,510 --> 00:51:27,329
the shirt pointer you know you pass

00:51:26,160 --> 00:51:28,920
there around so it does a bunch of

00:51:27,329 --> 00:51:30,599
increment and a bunch of decrements it'd

00:51:28,920 --> 00:51:32,130
be kind of interesting that the compiler

00:51:30,599 --> 00:51:33,299
could optimize these because if you

00:51:32,130 --> 00:51:35,010
think about it

00:51:33,299 --> 00:51:37,170
shirt pointer the only thing actually

00:51:35,010 --> 00:51:39,240
matters is going from one to more than

00:51:37,170 --> 00:51:41,190
one and then back to one all right

00:51:39,240 --> 00:51:43,170
everything above one just doesn't matter

00:51:41,190 --> 00:51:45,119
for a shared pointer right it's just a

00:51:43,170 --> 00:51:48,000
ref count it like doesn't matter right

00:51:45,119 --> 00:51:49,410
and so so and the compiler can look and

00:51:48,000 --> 00:51:51,299
say look I did want increments so it's

00:51:49,410 --> 00:51:52,740
above one and after that I can call s

00:51:51,299 --> 00:51:54,779
all the increments and all the

00:51:52,740 --> 00:51:56,069
decrements and it's kind of difficult to

00:51:54,779 --> 00:51:57,809
do that an interesting way for the

00:51:56,069 --> 00:52:00,119
compiler because it has to look at the

00:51:57,809 --> 00:52:00,450
decrement side and say oh I'm you know

00:52:00,119 --> 00:52:02,549
going

00:52:00,450 --> 00:52:04,140
I am decrementing and you there's always

00:52:02,549 --> 00:52:05,789
a branch that says like hey are you

00:52:04,140 --> 00:52:07,109
going unders 1 or something like that

00:52:05,789 --> 00:52:09,930
right so that's kind of hard to optimize

00:52:07,109 --> 00:52:14,130
but a high level that's kind of

00:52:09,930 --> 00:52:15,750
interesting optimization right now we we

00:52:14,130 --> 00:52:17,910
know how to do better than still new

00:52:15,750 --> 00:52:20,220
texts right the stimutex just knows

00:52:17,910 --> 00:52:21,510
better than you do usually now I'm going

00:52:20,220 --> 00:52:23,490
to skip over this really rapidly because

00:52:21,510 --> 00:52:25,260
it's objectionable but we could talk

00:52:23,490 --> 00:52:26,700
about volatile right and the basic idea

00:52:25,260 --> 00:52:28,829
of volatile is like memory mapped i/o

00:52:26,700 --> 00:52:30,630
and whatever and it's kind of selling

00:52:28,829 --> 00:52:32,279
isn't really mapped to what C++ does

00:52:30,630 --> 00:52:34,380
anymore right it doesn't really mean

00:52:32,279 --> 00:52:36,029
anything that's very coherent right so

00:52:34,380 --> 00:52:37,770
it prevents those store motion does it

00:52:36,029 --> 00:52:40,349
do arithmetic or whatever it's just it's

00:52:37,770 --> 00:52:42,240
really weird to do a volatile and and

00:52:40,349 --> 00:52:43,920
does it allow you to just share memory I

00:52:42,240 --> 00:52:45,930
don't know because it gets better all

00:52:43,920 --> 00:52:47,160
compilers model volatile differently or

00:52:45,930 --> 00:52:49,529
a lot of them do all right

00:52:47,160 --> 00:52:50,849
this version GC there's one thing MSB

00:52:49,529 --> 00:52:53,190
see there's another thing and what it

00:52:50,849 --> 00:52:54,660
does is just really crazy right like it

00:52:53,190 --> 00:52:56,039
gives you a bunch of guarantees unless

00:52:54,660 --> 00:52:59,460
you break a rule and in that case this

00:52:56,039 --> 00:53:01,350
just doesn't do anything right so so

00:52:59,460 --> 00:53:03,630
actually emulates that weirdo behavior

00:53:01,350 --> 00:53:05,040
them SVC has right and that's like an

00:53:03,630 --> 00:53:06,570
old and mistake that they made and they

00:53:05,040 --> 00:53:08,430
try to fix it when in did the arm

00:53:06,570 --> 00:53:09,810
version of isn't and then SVC but like

00:53:08,430 --> 00:53:11,520
it can't really fix it because people

00:53:09,810 --> 00:53:13,890
currently rely on the behavior of

00:53:11,520 --> 00:53:16,560
volatile right what does it really mean

00:53:13,890 --> 00:53:19,140
I don't know like I have no clue with

00:53:16,560 --> 00:53:22,260
volatile means right it has a few things

00:53:19,140 --> 00:53:23,760
that it says that it does but like it

00:53:22,260 --> 00:53:25,230
really depends on the implementation and

00:53:23,760 --> 00:53:26,760
then there's a bunch of weirdo questions

00:53:25,230 --> 00:53:29,100
that can it be lock free I don't know

00:53:26,760 --> 00:53:29,520
can it do read-modify-write no not

00:53:29,100 --> 00:53:31,440
really

00:53:29,520 --> 00:53:33,510
and then are there portable uses of all

00:53:31,440 --> 00:53:35,730
well I would say that maybe there are

00:53:33,510 --> 00:53:38,580
right maybe these three uses are valid

00:53:35,730 --> 00:53:41,640
some other people would object but

00:53:38,580 --> 00:53:43,380
whatever right and then there's also

00:53:41,640 --> 00:53:47,040
volatile atomic that's kind of weird

00:53:43,380 --> 00:53:52,890
right and and what what do compilers

00:53:47,040 --> 00:53:54,150
really do it's weird its weak so what a

00:53:52,890 --> 00:53:56,400
compilers really do well the standard

00:53:54,150 --> 00:53:58,770
library looks like this it has C atomic

00:53:56,400 --> 00:54:01,350
or stood atomic and then it kind of

00:53:58,770 --> 00:54:03,090
lowers to instructions that do built-ins

00:54:01,350 --> 00:54:04,680
right so the compiler looks at this and

00:54:03,090 --> 00:54:06,060
it's like okay well I'm gonna like kind

00:54:04,680 --> 00:54:07,650
of just generate those built-ins and

00:54:06,060 --> 00:54:09,000
I'll optimize a few things in the front

00:54:07,650 --> 00:54:10,800
10 but it's really with the middle land

00:54:09,000 --> 00:54:13,230
where things happen right so it has

00:54:10,800 --> 00:54:15,030
these instructions in the Nolan LVN

00:54:13,230 --> 00:54:17,250
knows about loads and stores and it tags

00:54:15,030 --> 00:54:18,900
those loads and stores as atomic right

00:54:17,250 --> 00:54:20,250
and so as soon as you see it sees the

00:54:18,900 --> 00:54:21,570
Tomica know like is it just gives up

00:54:20,250 --> 00:54:23,700
it's like nope not going to touch it

00:54:21,570 --> 00:54:25,170
right there has other operations for

00:54:23,700 --> 00:54:26,670
read modify write and complex change and

00:54:25,170 --> 00:54:29,550
stuff like that and it has pencils and

00:54:26,670 --> 00:54:31,230
then in the IR it says like oh is this

00:54:29,550 --> 00:54:32,610
simple is the volatile is it atomic and

00:54:31,230 --> 00:54:33,660
then just don't really touch it alright

00:54:32,610 --> 00:54:35,190
so what we've been doing is adding

00:54:33,660 --> 00:54:37,200
things where it actually touches stuff

00:54:35,190 --> 00:54:39,000
in very tricky ways like it we actually

00:54:37,200 --> 00:54:41,640
think a lot about the patches before

00:54:39,000 --> 00:54:43,110
touching things and then the machine ir

00:54:41,640 --> 00:54:44,550
to remember the example i gave you

00:54:43,110 --> 00:54:47,340
earlier about hog-wild that's where i

00:54:44,550 --> 00:54:49,950
modified what the x86 operations do

00:54:47,340 --> 00:54:53,120
right so it's really similar so in

00:54:49,950 --> 00:54:55,410
general conclusion i'm almost done

00:54:53,120 --> 00:54:57,270
what's the takeaway from my top well I

00:54:55,410 --> 00:54:59,370
kind of want the Standards Committee to

00:54:57,270 --> 00:55:01,200
assume optimizations occur and actually

00:54:59,370 --> 00:55:02,430
encourage them right like not everyone

00:55:01,200 --> 00:55:05,640
the committee assumes that that's the

00:55:02,430 --> 00:55:07,650
case for Atomics and and I want us to

00:55:05,640 --> 00:55:09,390
standardize existing practice right like

00:55:07,650 --> 00:55:11,040
as I was saying not everything that we

00:55:09,390 --> 00:55:13,240
have actually makes sense for everyone

00:55:11,040 --> 00:55:15,310
right the goal is that

00:55:13,240 --> 00:55:17,290
C++ allows you to express things as

00:55:15,310 --> 00:55:18,670
close to the metal as possible right I

00:55:17,290 --> 00:55:21,880
would like the language to do that

00:55:18,670 --> 00:55:23,290
better and then this is madness to use

00:55:21,880 --> 00:55:25,210
in a lot of cases right so I'd really

00:55:23,290 --> 00:55:27,760
like the libraries to get better at

00:55:25,210 --> 00:55:29,619
making it trivial to use these things

00:55:27,760 --> 00:55:31,180
right like kind of higher level stuff

00:55:29,619 --> 00:55:32,560
that allowed me they'll allow me to

00:55:31,180 --> 00:55:35,260
express then current same perils and

00:55:32,560 --> 00:55:37,960
really well write the goal is to make it

00:55:35,260 --> 00:55:39,369
hard to get that wrong right Atomics are

00:55:37,960 --> 00:55:42,070
easy to use the wrong way especially

00:55:39,369 --> 00:55:44,380
relaxed but if the library exposes

00:55:42,070 --> 00:55:46,270
something then that should make it

00:55:44,380 --> 00:55:50,619
easier than not to use it correctly

00:55:46,270 --> 00:55:53,320
right now most of you in the room are

00:55:50,619 --> 00:55:55,060
developers what should you get out of

00:55:53,320 --> 00:55:56,890
this talk well you should really drop

00:55:55,060 --> 00:55:58,900
inline assembly except when like the

00:55:56,890 --> 00:56:00,580
language fails you write if the language

00:55:58,900 --> 00:56:02,650
fails you sure go friend line assembly

00:56:00,580 --> 00:56:06,160
it's cool but at the end of the day like

00:56:02,650 --> 00:56:07,600
it'd be great if everyone used a Atomics

00:56:06,160 --> 00:56:10,390
in the higher levels of the language has

00:56:07,600 --> 00:56:12,640
and then if it's wrong just file a bud

00:56:10,390 --> 00:56:14,530
right it's not this there's committee

00:56:12,640 --> 00:56:17,110
like in a lot of cases will do things

00:56:14,530 --> 00:56:18,820
without having any clue of how people

00:56:17,110 --> 00:56:20,470
actually use it right we'll have one use

00:56:18,820 --> 00:56:21,820
case for a thing and we may just get it

00:56:20,470 --> 00:56:23,710
wrong so it'd be great it's like you

00:56:21,820 --> 00:56:25,480
know people gave us more feedback and

00:56:23,710 --> 00:56:26,890
there's all this tooling that you should

00:56:25,480 --> 00:56:28,660
use right like thread sanitizer and

00:56:26,890 --> 00:56:30,400
stuff like that that would be great now

00:56:28,660 --> 00:56:32,140
I don't know if there are any hardware

00:56:30,400 --> 00:56:34,030
vendors in the room I saw a few like

00:56:32,140 --> 00:56:36,250
Intel people earlier but like it'd be

00:56:34,030 --> 00:56:38,560
cool if like we could use more stuff

00:56:36,250 --> 00:56:40,210
right like showcase what you have and

00:56:38,560 --> 00:56:41,440
like make it useful and in the stands

00:56:40,210 --> 00:56:42,760
committee we've actually been trying to

00:56:41,440 --> 00:56:44,260
do that alright so one of the things

00:56:42,760 --> 00:56:46,450
we're trying to add from next version is

00:56:44,260 --> 00:56:48,400
indie support right and we're having

00:56:46,450 --> 00:56:49,630
kind of hot debates on how to do Sindhi

00:56:48,400 --> 00:56:52,840
properly in the language because it's

00:56:49,630 --> 00:56:54,730
actually not that easy and then then the

00:56:52,840 --> 00:56:57,310
last takeaways for compiler writers like

00:56:54,730 --> 00:56:59,200
you know get back to work

00:56:57,310 --> 00:57:00,790
because there's a lot of stuff that we

00:56:59,200 --> 00:57:02,710
can do and obviously like there's stuff

00:57:00,790 --> 00:57:04,150
that we can do we should focus on the

00:57:02,710 --> 00:57:06,220
ones that are useful there's all these

00:57:04,150 --> 00:57:08,080
optimizations that we can do a lot of

00:57:06,220 --> 00:57:09,460
them just aren't that useful right so we

00:57:08,080 --> 00:57:14,890
should find interesting code and make it

00:57:09,460 --> 00:57:16,690
faster alright so that's it I I have a

00:57:14,890 --> 00:57:17,800
bunch of references on github if you

00:57:16,690 --> 00:57:19,450
want to check out like I have a

00:57:17,800 --> 00:57:20,650
bajillion papers and other stuff if you

00:57:19,450 --> 00:57:22,359
want to read more about this because I

00:57:20,650 --> 00:57:24,369
know I went kind of fast over a lot of

00:57:22,359 --> 00:57:25,160
stuff but if you go to github right now

00:57:24,369 --> 00:57:26,780
in the readme

00:57:25,160 --> 00:57:28,250
I have a bunch of references at the end

00:57:26,780 --> 00:57:29,599
some of them are C++ tyrants committee

00:57:28,250 --> 00:57:31,670
papers some of them are just kind of

00:57:29,599 --> 00:57:33,470
regular publications or like you know

00:57:31,670 --> 00:57:35,299
the the references to what different

00:57:33,470 --> 00:57:39,770
compilers do and stuff like that right

00:57:35,299 --> 00:57:42,280
so any questions all right 100 percent

00:57:39,770 --> 00:57:42,280

YouTube URL: https://www.youtube.com/watch?v=IB57wIf9W1k


