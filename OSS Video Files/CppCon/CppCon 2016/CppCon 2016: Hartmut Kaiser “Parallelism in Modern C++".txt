Title: CppCon 2016: Hartmut Kaiser “Parallelism in Modern C++"
Publication date: 2016-10-01
Playlist: CppCon 2016
Description: 
	http://CppCon.org
—
Presentation Slides, PDFs, Source Code and other presenter materials are available at: https://github.com/cppcon/cppcon2016
—
The traditionally used and well established parallel programming models OpenMP and MPI are both targeting lower level parallelism and are meant to be as language agnostic as possible. For a long time, those models were the only widely available portable options for developing parallel C++ applications beyond using plain threads. This has strongly limited the optimization capabilities of compilers, has inhibited extensibility and genericity, and has restricted the use of those models together with other, modern higher level abstractions introduced by the C++11 and C++14 standards. 
The recent revival of interest in the industry and wider community for the C++ language has also spurred a remarkable amount of standardization proposals and technical specifications being developed. Those efforts however have so far failed to build a vision on how to seamlessly integrate various types of parallelism, such as iterative parallel execution, task-based parallelism, asynchronous many-task execution flows, continuation style computation, or explicit fork-join control flow of independent and non-homogeneous code paths. 

In this talk we present the results of developing higher level parallelization facilities in HPX, a general purpose C++ runtime system for applications of any scale. The developed higher-level parallelization APIs have been designed aiming at overcoming the limitations of today's prevalently used programming models in C++ codes. 
HPX exposes a uniform higher-level API which gives the application programmer syntactic and semantic equivalence of various types of on-node and off-node parallelism, all of which are well integrated into the C++ type system. We show that these higher level facilities are fully aligned with modern C++ programming concepts, they are easily extensible, fully generic, and enable highly efficient parallelization on par with or better than what existing equivalent applications based on OpenMP and/or MPI can achieve. 
— 
Hartmut Kaiser
Hartmut is a member of the faculty at the CS department at Louisiana State University (LSU) and a senior research scientist at LSU's Center for Computation and Technology (CCT). He received his doctorate from the Technical University of Chemnitz (Germany) in 1988. He is probably best known through his involvement in open source software projects, mainly as the author of several C++ libraries he has contributed to Boost, which are in use by thousands of developers worldwide. His current research is focused on leading the STE||AR group at CCT working on the practical design and implementation of future execution models and programming methods. His research interests are focused on the complex interaction of compiler technologies, runtime systems, active libraries, and modern system's architectures. His goal is to enable the creation of a new generation of scientific applications in powerful, though complex environments, such as high performance computing, distributed and grid computing, spatial information systems, and compiler technologies.

Website: https://www.cct.lsu.edu/~hkaiser/
—
Videos Filmed & Edited by Bash Films: http://www.BashFilms.com
YouTube URL: https://www.youtube.com/watch?v=6Z3_qaFYF84


