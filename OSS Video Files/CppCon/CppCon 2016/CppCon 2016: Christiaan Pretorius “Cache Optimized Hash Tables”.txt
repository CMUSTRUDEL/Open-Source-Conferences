Title: CppCon 2016: Christiaan Pretorius “Cache Optimized Hash Tables”
Publication date: 2016-09-29
Playlist: CppCon 2016
Description: 
	http://CppCon.org
—
Presentation Slides, PDFs, Source Code and other presenter materials are available at: https://github.com/cppcon/cppcon2016
—
Hashes and caches, why another hash library ? 
Problems,shortcomings and advantages of current open source hash libraries. Includes split between open and closed addressing methods and how these can be combined to give a better solution without much trade off by exploiting the strengths of each. 

Benchmarks 
Benchmarks of the library with high and medium entropy data, mostly pictures. 

Analogies 
A short description of the algorithms employed and why they work. This will include a short history of the library and why certain design decisions where made. Use of the birthday problem to model the low memory use evident from the benchmarks. 

Practical uses 
Demonstrate use cases of the library in treestore MySQL storage engine. Uses include concurrent version control algorithms and a mostly lock free allocation pool. This will include a short session with facebook link bench to illuminate possible advantages.
— 
Christiaan Pretorius
Technical Lead, Retro Rabbit
Writer maintainer of treestore MySQL storage Engine and Rabbit hash table library. https://github.com/tjizep/treestore \rabbit
—
Videos Filmed & Edited by Bash Films: http://www.BashFilms.com
Captions: 
	00:00:00,110 --> 00:00:07,830
okay hi everyone I'm Christian I'm from

00:00:06,060 --> 00:00:10,500
South Africa and I work for company

00:00:07,830 --> 00:00:13,740
called Rachel rabbit today we're going

00:00:10,500 --> 00:00:18,570
to speak a bit about cash optimized hash

00:00:13,740 --> 00:00:24,980
tables basically just the unordered map

00:00:18,570 --> 00:00:29,720
in C++ terms so basically we start why

00:00:24,980 --> 00:00:38,579
optimize the CPU catch I mean why

00:00:29,720 --> 00:00:42,390
basically since the 30 mm the despite

00:00:38,579 --> 00:00:44,610
the disparity between the world the

00:00:42,390 --> 00:00:48,539
lightning she of accessing mine memory

00:00:44,610 --> 00:00:52,250
and the actual amount of instructions

00:00:48,539 --> 00:00:56,610
you can retire within that time frame is

00:00:52,250 --> 00:00:59,489
has become very large and parted that

00:00:56,610 --> 00:01:02,460
you can probably retire about fifty

00:00:59,489 --> 00:01:06,420
instructions for a single my memory

00:01:02,460 --> 00:01:09,540
access and why the CPU manufacturers has

00:01:06,420 --> 00:01:16,409
tried to mitigate this problem is with

00:01:09,540 --> 00:01:19,259
cache memory so basically if CPU cache

00:01:16,409 --> 00:01:25,310
memory increases well as you can see me

00:01:19,259 --> 00:01:33,479
if you're eat right which is basically a

00:01:25,310 --> 00:01:36,420
percentage defined as okay it's like it

00:01:33,479 --> 00:01:38,900
from this expanding hundred accesses and

00:01:36,420 --> 00:01:41,750
96 of those comes from the cache and

00:01:38,900 --> 00:01:44,899
four of the the other four comes from

00:01:41,750 --> 00:01:49,590
from my mind memory it will spend

00:01:44,899 --> 00:01:51,890
roughly about 96 milliseconds on

00:01:49,590 --> 00:01:54,930
accessing the cache and in the other

00:01:51,890 --> 00:01:58,409
four thing that is missing it was

00:01:54,930 --> 00:02:03,630
spinned 200 milliseconds accessing my

00:01:58,409 --> 00:02:08,970
memory so if I add just one percent to

00:02:03,630 --> 00:02:12,510
that he tried my overall time that it

00:02:08,970 --> 00:02:15,900
typed it took to do the hundred accesses

00:02:12,510 --> 00:02:20,610
or drop from around about 200-300 to

00:02:15,900 --> 00:02:24,870
about 250 busy slide and so on 25% just

00:02:20,610 --> 00:02:29,879
because my efficiency has increased by

00:02:24,870 --> 00:02:31,739
1% also the CPU doesn't do much

00:02:29,879 --> 00:02:33,360
while it's writing for me maybe because

00:02:31,739 --> 00:02:36,900
it doesn't know that doesn't have

00:02:33,360 --> 00:02:41,010
instructions to retire and of course in

00:02:36,900 --> 00:02:45,510
multi-core and concurrent program

00:02:41,010 --> 00:02:48,720
programming really sort of straights

00:02:45,510 --> 00:02:53,129
axis in the CPU there's only one memory

00:02:48,720 --> 00:02:56,190
bus sending one little sentence true so

00:02:53,129 --> 00:03:03,299
basically the city is trying to get some

00:02:56,190 --> 00:03:04,920
air so this is why we would like to you

00:03:03,299 --> 00:03:10,109
know just get that want the same one or

00:03:04,920 --> 00:03:16,910
two percent extra so I'm just going to

00:03:10,109 --> 00:03:20,880
talk a bit further about our caches look

00:03:16,910 --> 00:03:25,079
basically it's written in memory is

00:03:20,880 --> 00:03:26,700
called a cache line and then no more no

00:03:25,079 --> 00:03:32,579
more terms so you can call it a block or

00:03:26,700 --> 00:03:37,410
a page or whatever basically the normal

00:03:32,579 --> 00:03:38,910
cycle is CPU ask so some memory it talks

00:03:37,410 --> 00:03:42,180
to the cache controller the cache

00:03:38,910 --> 00:03:44,160
controller says yes I asked tomatoes or

00:03:42,180 --> 00:03:50,959
if it doesn't and it's full it needs to

00:03:44,160 --> 00:03:54,209
be some other page cached inside so it's

00:03:50,959 --> 00:03:56,280
it is just the least recently used

00:03:54,209 --> 00:04:01,790
algorithm we can assess the scene which

00:03:56,280 --> 00:04:04,379
jesus least recently used algorithm and

00:04:01,790 --> 00:04:08,970
the associate we're just going to see

00:04:04,379 --> 00:04:13,230
you also that associativity which is how

00:04:08,970 --> 00:04:17,579
well it actually can access the data

00:04:13,230 --> 00:04:20,070
blocks or all the addresses that it

00:04:17,579 --> 00:04:22,060
needs is associated with the blocks is a

00:04:20,070 --> 00:04:28,000
full fully associative cache

00:04:22,060 --> 00:04:29,950
we're not gonna worry about a 2x4 yo6

00:04:28,000 --> 00:04:36,580
invite associativity or anything like

00:04:29,950 --> 00:04:40,780
that so some of the techniques we can

00:04:36,580 --> 00:04:44,290
use to actually make sure that title we

00:04:40,780 --> 00:04:48,970
want at that point in time actually sits

00:04:44,290 --> 00:04:52,270
in cache is to firstly make sure that

00:04:48,970 --> 00:04:54,760
when the cache creates a block that most

00:04:52,270 --> 00:04:57,550
of that data that retrieves is actually

00:04:54,760 --> 00:05:01,870
stuff that we're interested in doesn't

00:04:57,550 --> 00:05:04,780
help I in the pickup guys who achieve

00:05:01,870 --> 00:05:07,780
the cache line is about 64 bytes so I'm

00:05:04,780 --> 00:05:09,250
only interested in 4 bytes so it falls

00:05:07,780 --> 00:05:11,590
out the rest of the cache of memory

00:05:09,250 --> 00:05:13,300
which I'm never gonna use and it's going

00:05:11,590 --> 00:05:18,180
to cause other stuff to be victims which

00:05:13,300 --> 00:05:23,050
I don't want to use obviously another

00:05:18,180 --> 00:05:26,290
sort of often overlooked thing I can do

00:05:23,050 --> 00:05:28,479
is to just reduce memories because the

00:05:26,290 --> 00:05:31,000
less memory you have the better the

00:05:28,479 --> 00:05:34,390
chances that cache will actually contain

00:05:31,000 --> 00:05:38,890
the memory or the title that you're

00:05:34,390 --> 00:05:42,720
interested in also there's some mention

00:05:38,890 --> 00:05:46,470
I'm not going to get too deeply into the

00:05:42,720 --> 00:05:49,780
particular instruction caches but

00:05:46,470 --> 00:05:52,360
obviously if the compiler in lines code

00:05:49,780 --> 00:05:55,600
with other card that also gets called

00:05:52,360 --> 00:05:59,169
frequently the layer that is frequently

00:05:55,600 --> 00:06:02,740
called card will actually wipe some of

00:05:59,169 --> 00:06:05,970
the functions in instruction cache as

00:06:02,740 --> 00:06:13,419
well I mean then there's other you

00:06:05,970 --> 00:06:16,330
callate of reference so when I'm

00:06:13,419 --> 00:06:19,240
accessing memory in the cache and it

00:06:16,330 --> 00:06:21,190
needs to big stuff I need to make sure

00:06:19,240 --> 00:06:26,320
that the stuff is fix stuff are not

00:06:21,190 --> 00:06:29,410
going to use in the near future so

00:06:26,320 --> 00:06:33,270
that's basically if I was fancy word

00:06:29,410 --> 00:06:37,680
called temporal locality of reference

00:06:33,270 --> 00:06:40,620
but also all things being equal when

00:06:37,680 --> 00:06:43,310
you're accessing memory they're likely

00:06:40,620 --> 00:06:50,370
to access the mirror around that memory

00:06:43,310 --> 00:06:52,410
again very soon all right so hang a

00:06:50,370 --> 00:06:58,590
little bit deeper into blocks and pages

00:06:52,410 --> 00:07:01,230
this is this little picture the black or

00:06:58,590 --> 00:07:05,100
the gray ports or the memory that I'm

00:07:01,230 --> 00:07:09,060
interested in reports or memory that I'm

00:07:05,100 --> 00:07:12,030
not interested in so obviously if you

00:07:09,060 --> 00:07:14,370
have some it's better to put all the

00:07:12,030 --> 00:07:19,220
stuff you need in to continue contiguous

00:07:14,370 --> 00:07:27,180
box as you can see there the top part

00:07:19,220 --> 00:07:32,310
pointer here okay you can see there the

00:07:27,180 --> 00:07:36,150
red spots or interleaving with the cry

00:07:32,310 --> 00:07:37,770
box and there obviously I'm retrieving a

00:07:36,150 --> 00:07:40,560
lot of memory data that I don't need

00:07:37,770 --> 00:07:42,330
where is this one is a bit better it's a

00:07:40,560 --> 00:07:45,630
lot less memory that I don't need you

00:07:42,330 --> 00:07:48,270
know putting stuff into the cache but

00:07:45,630 --> 00:07:54,650
it's up to you I mean each workload has

00:07:48,270 --> 00:07:59,730
its own what you call it it's a little

00:07:54,650 --> 00:08:02,190
profile of memory that it once in memory

00:07:59,730 --> 00:08:03,870
doesn't that it doesn't want and

00:08:02,190 --> 00:08:07,020
sometimes this is a bit difficult to

00:08:03,870 --> 00:08:09,390
actually decide in which which memory

00:08:07,020 --> 00:08:12,830
you're going to choose as a algorithm

00:08:09,390 --> 00:08:17,310
designer or data structure coder

00:08:12,830 --> 00:08:23,040
you know which which memory you gonna

00:08:17,310 --> 00:08:28,919
prefer right so obviously reducing

00:08:23,040 --> 00:08:32,510
memory use is always better so you can

00:08:28,919 --> 00:08:32,510
see there on the first

00:08:32,770 --> 00:08:39,770
in the first in the worst axis in audio

00:08:37,330 --> 00:08:42,849
there's some memory extra day that

00:08:39,770 --> 00:08:45,589
doesn't fit into the cache line and

00:08:42,849 --> 00:08:48,440
obviously that's going to cause another

00:08:45,589 --> 00:08:51,610
cache at another moment memory access

00:08:48,440 --> 00:08:57,370
and where is the one at the bottom here

00:08:51,610 --> 00:09:00,500
might not cause another memory access so

00:08:57,370 --> 00:09:03,230
in the worst one we actually waiting the

00:09:00,500 --> 00:09:08,260
CPUs doing nothing again so I think for

00:09:03,230 --> 00:09:19,820
more memory to be loaded from from Ram

00:09:08,260 --> 00:09:23,770
alright so this one if it's possible

00:09:19,820 --> 00:09:26,750
this in your little cash algorithm or

00:09:23,770 --> 00:09:30,980
data structure or algorithm or whatever

00:09:26,750 --> 00:09:35,510
memory access pattern if there are parts

00:09:30,980 --> 00:09:39,040
of the memory that you need a lot it

00:09:35,510 --> 00:09:44,170
would be click to put all that stuff in

00:09:39,040 --> 00:09:46,970
in a contiguous block that will ensure

00:09:44,170 --> 00:09:50,870
sure that we will make the likely bit

00:09:46,970 --> 00:09:54,140
higher that you're going to be able to

00:09:50,870 --> 00:09:58,959
access that bits of memory again but it

00:09:54,140 --> 00:10:03,110
all depends on how you what kind of

00:09:58,959 --> 00:10:07,459
memory profile you have and how you can

00:10:03,110 --> 00:10:13,490
access it so you're sort of a

00:10:07,459 --> 00:10:15,709
complicated diagram so we're talking

00:10:13,490 --> 00:10:20,870
about a concept of specific optimality

00:10:15,709 --> 00:10:24,440
and optimization generality now my

00:10:20,870 --> 00:10:26,779
specific optimality I mean it's in some

00:10:24,440 --> 00:10:30,339
situations you actually just need a

00:10:26,779 --> 00:10:34,540
little bit of memory to fully optimize

00:10:30,339 --> 00:10:40,480
that algorithm or loop or whatever

00:10:34,540 --> 00:10:44,390
whereas in general the more general your

00:10:40,480 --> 00:10:47,030
solution is or algorithm

00:10:44,390 --> 00:10:50,960
I can probably contrast that with

00:10:47,030 --> 00:10:55,430
iteration souveneir a versus random axis

00:10:50,960 --> 00:10:58,060
or binary search on an array the binary

00:10:55,430 --> 00:11:01,430
search on an array is a more general

00:10:58,060 --> 00:11:04,520
algorithm while the iteration through

00:11:01,430 --> 00:11:11,930
the array is a very specific and it

00:11:04,520 --> 00:11:15,080
requires less code basically so while

00:11:11,930 --> 00:11:17,750
you may not be able to optimize every

00:11:15,080 --> 00:11:20,240
little thing in general it doesn't stop

00:11:17,750 --> 00:11:25,010
you from actually optimizing the

00:11:20,240 --> 00:11:31,280
specific cases for a specific memory

00:11:25,010 --> 00:11:34,400
also the cache hierarchy on CPUs as we

00:11:31,280 --> 00:11:38,650
know them today if we store those

00:11:34,400 --> 00:11:38,650
registers type at the fastest I can

00:11:39,940 --> 00:11:47,900
basically keep pace with the CPU with

00:11:44,120 --> 00:11:52,460
the full instruction retire right to the

00:11:47,900 --> 00:11:54,500
CPU the l1 is a bit larger but it's

00:11:52,460 --> 00:11:59,380
about four times slower and so on and so

00:11:54,500 --> 00:12:02,300
on and when you get to the LV it's about

00:11:59,380 --> 00:12:06,350
ten times slower which is still five

00:12:02,300 --> 00:12:10,730
times faster than my memory all right so

00:12:06,350 --> 00:12:12,830
hash tables you be so if it might need

00:12:10,730 --> 00:12:16,690
to do toxic it open addressing and close

00:12:12,830 --> 00:12:19,670
the dressing there's some examples of

00:12:16,690 --> 00:12:23,030
algorithms that a useless linear probing

00:12:19,670 --> 00:12:24,710
robbing attacking quadratic program

00:12:23,030 --> 00:12:30,080
probing is one of the other ones

00:12:24,710 --> 00:12:32,660
quadratic program probing is the one

00:12:30,080 --> 00:12:35,870
that used in Google sports hash and

00:12:32,660 --> 00:12:41,420
Google Dane sighs isn't really open

00:12:35,870 --> 00:12:44,450
source that use pure linear probing

00:12:41,420 --> 00:12:47,780
because of the requirements for a

00:12:44,450 --> 00:12:52,010
uniform distribution of the keys is very

00:12:47,780 --> 00:12:55,310
strict but I'll show you why later and

00:12:52,010 --> 00:12:56,900
in our post addressing which is its

00:12:55,310 --> 00:13:01,220
opposite that is typically

00:12:56,900 --> 00:13:05,090
actually I stables you using the STL you

00:13:01,220 --> 00:13:09,920
can see that with the chaining and lip

00:13:05,090 --> 00:13:12,980
lists we need looking up a specific key

00:13:09,920 --> 00:13:16,190
or value very likely to actually do do

00:13:12,980 --> 00:13:18,890
lookups or at least to address to memory

00:13:16,190 --> 00:13:22,780
loads because of the linked lists that's

00:13:18,890 --> 00:13:30,320
associate that was each bucket in there

00:13:22,780 --> 00:13:33,980
in the hash table all right so one of

00:13:30,320 --> 00:13:37,010
the techniques that people use it's

00:13:33,980 --> 00:13:41,060
quite a common one is to basically just

00:13:37,010 --> 00:13:43,250
like the so okay before without the I'm

00:13:41,060 --> 00:13:46,430
just going to be specifically talking

00:13:43,250 --> 00:13:50,800
about linear program probably and linear

00:13:46,430 --> 00:13:54,620
probing tiebacks tables because they are

00:13:50,800 --> 00:13:56,510
afternoon to be much more cash friendly

00:13:54,620 --> 00:14:00,740
than data algorithms so we won't really

00:13:56,510 --> 00:14:03,110
look at all the other algorithms in the

00:14:00,740 --> 00:14:06,230
close decreasing things except that

00:14:03,110 --> 00:14:10,720
there's a bucket because we'll be using

00:14:06,230 --> 00:14:14,270
a bucket at a bit later on so the first

00:14:10,720 --> 00:14:15,710
first thing after that is looking at so

00:14:14,270 --> 00:14:17,480
you're looking at linear probing hash

00:14:15,710 --> 00:14:21,490
tables you know it's not any a nice

00:14:17,480 --> 00:14:26,630
table is a open addressing type scheme

00:14:21,490 --> 00:14:36,620
so the first thing that people can do

00:14:26,630 --> 00:14:40,010
which which helps with keeping that you

00:14:36,620 --> 00:14:43,010
know improving that cache performance or

00:14:40,010 --> 00:14:45,740
the cache efficiency is to use it so

00:14:43,010 --> 00:14:52,010
separate keys and values during the

00:14:45,740 --> 00:14:53,750
normal ADT type operations you're

00:14:52,010 --> 00:14:56,090
accessing the key is a lot more than

00:14:53,750 --> 00:15:01,970
actually accessing values if you think

00:14:56,090 --> 00:15:04,910
about it so ways to take for instance if

00:15:01,970 --> 00:15:06,620
something is in stable only going to use

00:15:04,910 --> 00:15:09,480
keys

00:15:06,620 --> 00:15:12,550
if you check to see

00:15:09,480 --> 00:15:15,970
if you can you raise something all that

00:15:12,550 --> 00:15:19,540
stuff are you gonna use keys for the

00:15:15,970 --> 00:15:22,360
normal goosey a bit lighter normal

00:15:19,540 --> 00:15:24,760
linear programming algorithm there is a

00:15:22,360 --> 00:15:27,960
sort of scan sometimes when the ice

00:15:24,760 --> 00:15:32,290
table becomes full which I mean

00:15:27,960 --> 00:15:34,150
accesskey so it's better to separate the

00:15:32,290 --> 00:15:39,310
keys from the values cuz then you know

00:15:34,150 --> 00:15:43,120
that if you load something or if the

00:15:39,310 --> 00:15:46,240
cash as a medicine it likes a cache line

00:15:43,120 --> 00:15:48,970
from my memory the stuff that you're

00:15:46,240 --> 00:15:53,890
loading is King stuff that you're

00:15:48,970 --> 00:16:16,740
actually interested in right so yes like

00:15:53,890 --> 00:16:16,740
yeah that's a good question to put it

00:16:18,270 --> 00:16:26,770
this the main thing there is to actually

00:16:22,690 --> 00:16:28,690
not the mind you see in that's funny you

00:16:26,770 --> 00:16:32,200
always I have one cache nice actually

00:16:28,690 --> 00:16:36,820
because it's like a sort of idealized

00:16:32,200 --> 00:16:40,570
case where the key is all in one side

00:16:36,820 --> 00:16:42,190
and the values are no other side and we

00:16:40,570 --> 00:16:49,360
sort of assume that the keys are in the

00:16:42,190 --> 00:16:51,190
cache already then you gotta miss only

00:16:49,360 --> 00:16:54,970
once when you access the value because

00:16:51,190 --> 00:17:00,339
the key is already in the cache but the

00:16:54,970 --> 00:17:02,890
thing here is that you're not putting

00:17:00,339 --> 00:17:04,959
large values in the cache when they're

00:17:02,890 --> 00:17:07,410
all going to cause a lot of cache misses

00:17:04,959 --> 00:17:10,380
a spy oh sorry

00:17:07,410 --> 00:17:12,520
when I kind of caused it cash to fall up

00:17:10,380 --> 00:17:14,410
because it's just extra stuff that

00:17:12,520 --> 00:17:15,459
you're putting in the cache Stettin not

00:17:14,410 --> 00:17:18,520
really gonna use

00:17:15,459 --> 00:17:19,430
look.we any less looking for that 1% of

00:17:18,520 --> 00:17:23,600
improvement

00:17:19,430 --> 00:17:25,370
not looking for trying to get everything

00:17:23,600 --> 00:17:30,250
in the cache we're looking for a small

00:17:25,370 --> 00:17:34,040
movement here okay I'm just gonna

00:17:30,250 --> 00:17:38,390
explain a bit what happens with linear

00:17:34,040 --> 00:17:47,020
probing so you can see that the green

00:17:38,390 --> 00:17:51,920
keys or the green box or occupied keys

00:17:47,020 --> 00:17:56,050
the blue ones are empty and the other

00:17:51,920 --> 00:17:59,450
ones are deleted keys so the little keys

00:17:56,050 --> 00:18:02,780
as you can see you have to sign some

00:17:59,450 --> 00:18:05,870
states do to each the first problem sort

00:18:02,780 --> 00:18:07,520
of on superficially is you have to have

00:18:05,870 --> 00:18:11,750
something that keeps the Stipe for each

00:18:07,520 --> 00:18:14,960
of those keys the common way of doing

00:18:11,750 --> 00:18:21,890
that is just actually using your key

00:18:14,960 --> 00:18:24,890
space itself to to set the stage for

00:18:21,890 --> 00:18:26,990
those key so you would have deleted key

00:18:24,890 --> 00:18:30,350
key so let's say you have a lot of

00:18:26,990 --> 00:18:36,160
integers you would typically assign

00:18:30,350 --> 00:18:37,370
minus 1 as the deleted key and -2 is

00:18:36,160 --> 00:18:41,570
intiki

00:18:37,370 --> 00:18:44,390
the occupied keys can be enough anything

00:18:41,570 --> 00:18:48,410
that isn't empty or deleted this is

00:18:44,390 --> 00:18:52,190
basically our golden sash work so it's a

00:18:48,410 --> 00:18:53,870
bit irritating you have to actually look

00:18:52,190 --> 00:18:59,050
at what you're gonna do with it

00:18:53,870 --> 00:19:03,590
and in sign keys according to that which

00:18:59,050 --> 00:19:06,560
is a bit of a pain sometimes now looking

00:19:03,590 --> 00:19:10,430
at the linear program probing algorithm

00:19:06,560 --> 00:19:14,510
itself you can see there we need to lead

00:19:10,430 --> 00:19:16,400
keys that actually get removed from the

00:19:14,510 --> 00:19:20,440
problems because if there was a

00:19:16,400 --> 00:19:20,440
collision let's say at the beginning

00:19:22,960 --> 00:19:30,730
they were two beginning let's say that

00:19:25,220 --> 00:19:30,730
key had a collision so that means

00:19:31,670 --> 00:19:42,600
so collisions means that if I insert a

00:19:38,610 --> 00:19:45,240
key let's take stable of links right and

00:19:42,600 --> 00:19:50,000
I want to insert the values of for and

00:19:45,240 --> 00:19:50,000
trade off so four and twelve will both

00:19:50,030 --> 00:19:59,100
map to the same position in this science

00:19:55,500 --> 00:20:03,810
table let's swings for just for our

00:19:59,100 --> 00:20:08,640
example and say it's that one that means

00:20:03,810 --> 00:20:11,550
that we have to put so we've restored

00:20:08,640 --> 00:20:15,210
for we have to put twelve somewhere so

00:20:11,550 --> 00:20:19,440
the linear programming problem chooses

00:20:15,210 --> 00:20:27,380
the next one and if I add I'd so that

00:20:19,440 --> 00:20:31,550
will be that's 20 so so in this example

00:20:27,380 --> 00:20:34,980
there was a number of keys which mapped

00:20:31,550 --> 00:20:37,410
to a position somewhere here and then a

00:20:34,980 --> 00:20:43,920
little bit lighter on the deleted thing

00:20:37,410 --> 00:20:52,440
again but this leaves a whole block here

00:20:43,920 --> 00:20:55,350
which is so anytime I'm looking for a

00:20:52,440 --> 00:20:58,290
key that falls in this book is going to

00:20:55,350 --> 00:21:00,870
do a lot of iterations here it's very

00:20:58,290 --> 00:21:03,330
costly obviously and also those

00:21:00,870 --> 00:21:06,120
iterations has to actually iterate

00:21:03,330 --> 00:21:08,490
through that memory and it falls up the

00:21:06,120 --> 00:21:13,710
cache was even more stuff that you don't

00:21:08,490 --> 00:21:19,860
need and or might not need but it keeps

00:21:13,710 --> 00:21:27,590
the CPU very busy so we want to prove

00:21:19,860 --> 00:21:27,590
that a bit so this is basically just

00:21:31,500 --> 00:21:41,760
so you can see from this diagram we need

00:21:36,990 --> 00:21:43,799
to have a very strongly randomized hash

00:21:41,760 --> 00:21:46,740
function so that you have enough spices

00:21:43,799 --> 00:21:48,419
between the keys so the dose iterations

00:21:46,740 --> 00:21:51,750
don't carry on for too long

00:21:48,419 --> 00:21:54,450
sorry so we're sort of forced to to make

00:21:51,750 --> 00:21:59,370
that stable a bit bigger so that we can

00:21:54,450 --> 00:22:03,240
add little spices in and then that

00:21:59,370 --> 00:22:07,950
obviously causes worse locality of

00:22:03,240 --> 00:22:12,389
reference and makes the tile bigger than

00:22:07,950 --> 00:22:15,500
it really needs to be there are some

00:22:12,389 --> 00:22:23,639
solutions to some of those problems

00:22:15,500 --> 00:22:26,250
especially the I call this clustering

00:22:23,639 --> 00:22:29,460
this clustering some of them or

00:22:26,250 --> 00:22:32,970
quadratic programming aspera quadratic

00:22:29,460 --> 00:22:35,850
programming using Google DHS and there's

00:22:32,970 --> 00:22:43,070
also something like Robin the dashing

00:22:35,850 --> 00:22:43,070
which helps with that but with quadratic

00:22:43,429 --> 00:22:56,429
probing this each time you stop robbing

00:22:52,350 --> 00:22:59,639
you increasing to increasing the probing

00:22:56,429 --> 00:23:05,419
links quadratically so that's also bad

00:22:59,639 --> 00:23:08,519
so the cash because now is also making

00:23:05,419 --> 00:23:11,429
large leaps in reading stuff I don't

00:23:08,519 --> 00:23:14,299
necessarily need right now

00:23:11,429 --> 00:23:17,309
so the locality of reference of

00:23:14,299 --> 00:23:20,429
quadratic burn probing is a bit worst

00:23:17,309 --> 00:23:22,200
and especially if you want to keep the

00:23:20,429 --> 00:23:28,799
type of small and you want to have our

00:23:22,200 --> 00:23:30,750
load factor right so here we have some

00:23:28,799 --> 00:23:35,760
examples of flow and a height a factor

00:23:30,750 --> 00:23:40,300
so that you can see load load factor it

00:23:35,760 --> 00:23:44,800
is a few keys per empty space

00:23:40,300 --> 00:23:47,860
factor a lot of TNT spice and you can

00:23:44,800 --> 00:23:50,800
see it quickly starts generating long

00:23:47,860 --> 00:23:55,330
runs or broad clusters which is a bad

00:23:50,800 --> 00:23:58,720
thing so to improve that we're gonna

00:23:55,330 --> 00:24:07,240
change the actual sites that gets

00:23:58,720 --> 00:24:10,870
thought per perky the one is to exchange

00:24:07,240 --> 00:24:13,780
the deleted key with the thing called

00:24:10,870 --> 00:24:16,780
the collided key and that's basically

00:24:13,780 --> 00:24:20,820
where we have this word called collision

00:24:16,780 --> 00:24:28,030
factor so collision factor just means

00:24:20,820 --> 00:24:30,760
the amount of keys of the table size not

00:24:28,030 --> 00:24:35,680
the total size I will just type out of

00:24:30,760 --> 00:24:39,580
keys per total keys which are actually

00:24:35,680 --> 00:24:42,670
inner kaleidos type when sorry in other

00:24:39,580 --> 00:24:45,880
words if I if I've inserted something on

00:24:42,670 --> 00:24:48,180
that key and then later on greater -

00:24:45,880 --> 00:24:52,540
value which maps to the same key and

00:24:48,180 --> 00:25:00,250
inserted somewhere else there may ever

00:24:52,540 --> 00:25:05,110
there was a spice it will be counted as

00:25:00,250 --> 00:25:10,270
a collision so you can see they were the

00:25:05,110 --> 00:25:12,610
collided flags so firstly I actually

00:25:10,270 --> 00:25:17,680
just point out that this table is

00:25:12,610 --> 00:25:21,760
equivalent to that point so we don't

00:25:17,680 --> 00:25:24,330
have deleted easy anymore set of spices

00:25:21,760 --> 00:25:24,330
cut open

00:25:24,780 --> 00:25:31,030
here is the yellow one so we're gonna

00:25:27,670 --> 00:25:34,180
say that one was collided and that one

00:25:31,030 --> 00:25:37,480
as well so you can see just by changing

00:25:34,180 --> 00:25:40,410
the deleted flag into a collided state

00:25:37,480 --> 00:25:45,510
that it's tied into a collided State

00:25:40,410 --> 00:25:48,490
we've reduced a bit of the clustering

00:25:45,510 --> 00:25:52,720
but of course neither you don't have a

00:25:48,490 --> 00:25:53,800
delete key which means how do you stop

00:25:52,720 --> 00:26:01,060
searching when she

00:25:53,800 --> 00:26:04,870
something is collided and seeing elected

00:26:01,060 --> 00:26:09,370
to do is you just make sure all runs or

00:26:04,870 --> 00:26:11,620
all probes or of equal lengths so if

00:26:09,370 --> 00:26:18,240
there is a collided key it will probe

00:26:11,620 --> 00:26:26,110
for pset links but into that a bit later

00:26:18,240 --> 00:26:28,570
but basically this improves two things

00:26:26,110 --> 00:26:31,090
first you've got a lot more space to put

00:26:28,570 --> 00:26:34,630
other stuff in so your iced I will grow

00:26:31,090 --> 00:26:36,930
slower and secondly because you're

00:26:34,630 --> 00:26:41,950
limiting the runs here that you can scan

00:26:36,930 --> 00:26:44,980
the clusters will obviously not exceed

00:26:41,950 --> 00:26:47,470
the size of that constant run day where

00:26:44,980 --> 00:26:55,290
is that crime is really long there's so

00:26:47,470 --> 00:26:55,290
much much softer okay so any questions

00:26:57,180 --> 00:27:01,960
but that is not enough we want to

00:26:59,560 --> 00:27:03,970
actually improve the memory use a bit

00:27:01,960 --> 00:27:08,080
more services where the pocket at the

00:27:03,970 --> 00:27:11,230
end of the timer comes from so if I

00:27:08,080 --> 00:27:14,290
store a key and I forget that the

00:27:11,230 --> 00:27:17,080
previous one year if I store Ricky

00:27:14,290 --> 00:27:19,120
they're telling it falls of that spot

00:27:17,080 --> 00:27:23,530
but if I store another key that map's to

00:27:19,120 --> 00:27:26,160
somewhere there it has to go somewhere

00:27:23,530 --> 00:27:29,830
so at that point

00:27:26,160 --> 00:27:32,470
usually you would just call a rehash but

00:27:29,830 --> 00:27:36,700
we can actually do a bit better and we

00:27:32,470 --> 00:27:41,020
can put a little bucket at the end

00:27:36,700 --> 00:27:48,700
so whenever those probes are exhausted

00:27:41,020 --> 00:27:53,490
we just put a key in the bucket and as

00:27:48,700 --> 00:27:57,850
it turns out the the probability of

00:27:53,490 --> 00:28:01,750
these things getting full it's really

00:27:57,850 --> 00:28:05,700
love so I sort of think you sink for

00:28:01,750 --> 00:28:05,700
yourself that

00:28:07,169 --> 00:28:14,260
if I insert the key into a into the

00:28:11,110 --> 00:28:18,190
position where these eight other cons

00:28:14,260 --> 00:28:21,460
for chi other consecutive keys that the

00:28:18,190 --> 00:28:25,570
probability of that event occurring is

00:28:21,460 --> 00:28:28,659
fairly low that's why this bucket

00:28:25,570 --> 00:28:31,630
basically works and then the next thing

00:28:28,659 --> 00:28:33,789
we do is to actually take all the states

00:28:31,630 --> 00:28:36,270
and instead of using the keys themself

00:28:33,789 --> 00:28:41,590
to store the the colors of the states

00:28:36,270 --> 00:28:45,490
which would be occupied empty and

00:28:41,590 --> 00:28:50,740
collided States we use a separate bitmap

00:28:45,490 --> 00:28:53,110
to don't store it in so that but map

00:28:50,740 --> 00:28:57,580
becomes sticky in cash because it's

00:28:53,110 --> 00:29:04,000
quite small it's like for iPod keys it's

00:28:57,580 --> 00:29:06,340
like 32 times smaller and the title

00:29:04,000 --> 00:29:08,830
Ashta also the likelihood of that thing

00:29:06,340 --> 00:29:11,710
being in cash is a lot although it does

00:29:08,830 --> 00:29:14,320
incur a couple of extra processing

00:29:11,710 --> 00:29:19,270
cycles to actually do a shift and a load

00:29:14,320 --> 00:29:25,899
year before you can actually actually

00:29:19,270 --> 00:29:28,140
access a key all right so this the

00:29:25,899 --> 00:29:34,000
birthday paradox or the birthday attack

00:29:28,140 --> 00:29:40,330
is it is a problem with almost all mesh

00:29:34,000 --> 00:29:44,559
titles where the probabilities of T is

00:29:40,330 --> 00:29:49,809
colliding becomes quickly very very high

00:29:44,559 --> 00:29:54,130
very quickly and possibly a wall on the

00:29:49,809 --> 00:29:57,909
side here is that yard it's a good

00:29:54,130 --> 00:30:02,710
article to read the Google the birthday

00:29:57,909 --> 00:30:05,049
attack article on Wikipedia and then we

00:30:02,710 --> 00:30:06,909
can basically just model collisions on a

00:30:05,049 --> 00:30:11,880
nice type of the same WiDi model

00:30:06,909 --> 00:30:13,840
collisions in security algorithms the

00:30:11,880 --> 00:30:16,950
probabilities and stuff is almost the

00:30:13,840 --> 00:30:21,000
same or not the same but tile

00:30:16,950 --> 00:30:23,190
of area and it makes it easier to reason

00:30:21,000 --> 00:30:29,490
about from a functional point of view

00:30:23,190 --> 00:30:32,100
than to try and go and look at the

00:30:29,490 --> 00:30:36,470
probabilities of linear probing and with

00:30:32,100 --> 00:30:43,669
dreaded problem - tables okay it is some

00:30:36,470 --> 00:30:48,600
benchmarks so I can see their discards

00:30:43,669 --> 00:30:51,990
the in size map - map in blue and that's

00:30:48,600 --> 00:30:54,690
the Google wine the false Google wine my

00:30:51,990 --> 00:31:00,360
red one is the rabbit services for Fitch

00:30:54,690 --> 00:31:04,580
random fits times in nanoseconds in the

00:31:00,360 --> 00:31:09,720
sports hash map which is the Google app

00:31:04,580 --> 00:31:12,419
it's basically a type of hash map that

00:31:09,720 --> 00:31:15,029
is a lot a lot few spices between keys

00:31:12,419 --> 00:31:18,090
that's what I call it sports because it

00:31:15,029 --> 00:31:20,039
doesn't have a lot of spice wasted so it

00:31:18,090 --> 00:31:22,350
actually uses less memory and in the

00:31:20,039 --> 00:31:27,450
normal an audit map that's part of this

00:31:22,350 --> 00:31:33,539
they all distributions so there you can

00:31:27,450 --> 00:31:36,090
see I think the time series is that's a

00:31:33,539 --> 00:31:42,240
couple of about 20% or so faster than

00:31:36,090 --> 00:31:45,139
the forces one-state million keys but

00:31:42,240 --> 00:31:48,330
it's a few can you see the same pattern

00:31:45,139 --> 00:31:52,320
reoccur with hundred millions doesn't

00:31:48,330 --> 00:31:58,919
matter it just obviously fifteen hundred

00:31:52,320 --> 00:32:00,870
million all of that the racial status

00:31:58,919 --> 00:32:03,210
times obviously just took two actual

00:32:00,870 --> 00:32:08,070
times which comes a bit higher because

00:32:03,210 --> 00:32:13,710
you've got more cache misses so this is

00:32:08,070 --> 00:32:17,250
just for random access format graphs you

00:32:13,710 --> 00:32:20,220
can see the job you've got more like a

00:32:17,250 --> 00:32:24,059
50 years even on recent improvement in

00:32:20,220 --> 00:32:24,929
my purse and that's my only because of

00:32:24,059 --> 00:32:27,570
the

00:32:24,929 --> 00:32:29,669
little bit map that we use we don't

00:32:27,570 --> 00:32:33,179
actually need to compare our baby keys

00:32:29,669 --> 00:32:35,720
we need to very resize of the hashmap

00:32:33,179 --> 00:32:40,650
and obviously because it's much smaller

00:32:35,720 --> 00:32:42,720
you resize much less because of the

00:32:40,650 --> 00:32:47,309
higher light factor that it can

00:32:42,720 --> 00:32:50,820
withstand and you can also use more gas

00:32:47,309 --> 00:32:56,390
friendly distributions so you don't have

00:32:50,820 --> 00:32:58,770
to strongly randomize ologies together

00:32:56,390 --> 00:33:00,690
cause you don't really need a try

00:32:58,770 --> 00:33:04,230
dispersed focus you've got a collision

00:33:00,690 --> 00:33:10,980
but which avoids the scanning of the

00:33:04,230 --> 00:33:12,169
keys that okay this is way gets much

00:33:10,980 --> 00:33:16,039
better actually

00:33:12,169 --> 00:33:20,460
so if you look at cream there that's the

00:33:16,039 --> 00:33:23,820
size of our timbering keys in the HDL

00:33:20,460 --> 00:33:29,100
map the bluest will go to any size map

00:33:23,820 --> 00:33:31,230
and then the Google's porous hash map as

00:33:29,100 --> 00:33:33,720
well as rapid eases about assignment

00:33:31,230 --> 00:33:37,590
amount of memory a rabbit is little less

00:33:33,720 --> 00:33:39,240
even but it's basically the same I just

00:33:37,590 --> 00:33:45,899
have to sort of sign that they are some

00:33:39,240 --> 00:33:49,279
cranks it's because gravity's a variant

00:33:45,899 --> 00:33:52,860
on linear programming it doesn't have to

00:33:49,279 --> 00:33:54,840
resize - map from time to time that

00:33:52,860 --> 00:33:56,970
means you have to make a copy of -

00:33:54,840 --> 00:33:59,220
badminton set all the keys from the old

00:33:56,970 --> 00:34:02,700
version and then delete the old version

00:33:59,220 --> 00:34:05,159
CF drones in spark so it's not quite as

00:34:02,700 --> 00:34:08,639
low even though it looks like a year

00:34:05,159 --> 00:34:11,190
it's not quite as low as that Google's

00:34:08,639 --> 00:34:14,460
pore size map but it's much better than

00:34:11,190 --> 00:34:20,220
all the other ones anyway while it's

00:34:14,460 --> 00:34:25,379
actually Foster and everything else okay

00:34:20,220 --> 00:34:32,879
so that was that for the sort of give me

00:34:25,379 --> 00:34:35,849
an overview of the algorithms so now I

00:34:32,879 --> 00:34:37,810
would like to share a bit about out of

00:34:35,849 --> 00:34:42,020
there

00:34:37,810 --> 00:34:47,900
- my other thing actually works with

00:34:42,020 --> 00:34:55,490
your soul so you have some profiling

00:34:47,900 --> 00:34:58,250
information did a bit earlier and this

00:34:55,490 --> 00:35:04,130
is basically the workload is linked page

00:34:58,250 --> 00:35:05,630
from Facebook so you can see there is a

00:35:04,130 --> 00:35:14,660
lot of stuff happening here if you look

00:35:05,630 --> 00:35:18,350
at vegetative functions see what's going

00:35:14,660 --> 00:35:23,150
on here so you've got a lot of logging

00:35:18,350 --> 00:35:39,530
is a lot of compression and stuff like

00:35:23,150 --> 00:35:43,670
that is so dissipate okay but here is so

00:35:39,530 --> 00:35:50,090
that's just some card within the Africa

00:35:43,670 --> 00:35:57,170
it is basically in the alligator so

00:35:50,090 --> 00:36:02,090
sister a cattle that we write for for

00:35:57,170 --> 00:36:04,880
doing some improving a concurrent

00:36:02,090 --> 00:36:08,750
performance of existing I with

00:36:04,880 --> 00:36:12,050
alligators and basic ass it's sort of

00:36:08,750 --> 00:36:18,860
like the my local one of those anyways

00:36:12,050 --> 00:36:24,170
but be but basically this a lot of code

00:36:18,860 --> 00:36:26,690
be that we can see find mister it's

00:36:24,170 --> 00:36:29,360
called a lot so obviously random axis

00:36:26,690 --> 00:36:36,470
random read axis is quite important

00:36:29,360 --> 00:36:40,500
Network lied and again we can see here

00:36:36,470 --> 00:36:47,290
it does some strange things

00:36:40,500 --> 00:36:52,690
when we look at code here it's basically

00:36:47,290 --> 00:36:59,640
all cache misses so even though we try

00:36:52,690 --> 00:36:59,640
to optimize the ice table for for the

00:37:01,860 --> 00:37:09,100
cache efficiency due to all the other

00:37:06,310 --> 00:37:12,040
things happening memory allocation stuff

00:37:09,100 --> 00:37:15,460
being encoded from one buffer to another

00:37:12,040 --> 00:37:20,070
one cache misses so quite predominant

00:37:15,460 --> 00:37:27,490
anyway so that's basically that port

00:37:20,070 --> 00:37:32,410
okay I think I'm sort of finished if

00:37:27,490 --> 00:37:35,740
there's any questions that any questions

00:37:32,410 --> 00:37:41,640
anything that it's unclear to you I'd

00:37:35,740 --> 00:37:49,120
like to maybe a little bit just if I can

00:37:41,640 --> 00:38:02,680
get back to this oh you just talk about

00:37:49,120 --> 00:38:05,590
deletes you can see that the leads and

00:38:02,680 --> 00:38:11,500
replacements also gonna be much faster

00:38:05,590 --> 00:38:14,980
in this case cause we are sitting but

00:38:11,500 --> 00:38:22,420
we're not actually overwriting the whole

00:38:14,980 --> 00:38:25,000
key to signal that thing is missing all

00:38:22,420 --> 00:38:30,490
the and but it depends on how you use

00:38:25,000 --> 00:38:42,730
dice table and so on okay right any

00:38:30,490 --> 00:38:47,650
questions yeah it actually does it has

00:38:42,730 --> 00:38:52,480
the normal iterators and other like find

00:38:47,650 --> 00:38:55,080
add or insert constitute a riders

00:38:52,480 --> 00:38:59,410
all that kind of stuff it supports the

00:38:55,080 --> 00:39:01,930
only thing is with the key bears like I

00:38:59,410 --> 00:39:06,850
think it's called the value type isn't

00:39:01,930 --> 00:39:18,900
quite the same because because of that

00:39:06,850 --> 00:39:23,430
split here oh yeah because of that split

00:39:18,900 --> 00:39:28,420
he's invited haunting the same memory so

00:39:23,430 --> 00:39:30,670
the actual value table is a proxy to the

00:39:28,420 --> 00:39:32,470
actual keys but it works in the same way

00:39:30,670 --> 00:39:34,150
I just think if you do type inference

00:39:32,470 --> 00:39:38,320
and that kind of thing it will actually

00:39:34,150 --> 00:39:40,950
not retain what you expect so in that in

00:39:38,320 --> 00:39:45,700
that case it's it's not quite

00:39:40,950 --> 00:39:49,420
conformant but I'm pretty sure if you

00:39:45,700 --> 00:39:52,710
use it in a sort of real system and

00:39:49,420 --> 00:39:58,109
we're not gonna have that problem a lot

00:39:52,710 --> 00:40:02,230
the thing is that it's also much more

00:39:58,109 --> 00:40:04,810
robust against non-uniform distribution

00:40:02,230 --> 00:40:39,450
of teeth because what I explained

00:40:04,810 --> 00:40:39,450
earlier so it's probably yeah

00:40:46,960 --> 00:40:56,890
so so I guess that is why it's not

00:40:51,830 --> 00:40:56,890
impossible to guess it's impossible -

00:41:45,520 --> 00:41:59,360
yes that's right

00:41:47,420 --> 00:42:03,410
that's quick so so I just want to beat

00:41:59,360 --> 00:42:08,330
for for the audience future audience so

00:42:03,410 --> 00:42:10,370
your question is that if what is the

00:42:08,330 --> 00:42:15,490
performance of the hash table with

00:42:10,370 --> 00:42:18,770
Visual Studio as function as opposed to

00:42:15,490 --> 00:42:22,340
as opposed to just using integers

00:42:18,770 --> 00:42:25,370
directly so what I do for this thing is

00:42:22,340 --> 00:42:27,310
to just not use the standard - for

00:42:25,370 --> 00:42:30,380
integers

00:42:27,310 --> 00:42:33,440
I've rewritten the but it's all about

00:42:30,380 --> 00:42:38,060
with strings we have a high probability

00:42:33,440 --> 00:42:40,580
of birthday attacks usefully the

00:42:38,060 --> 00:42:45,410
randomization hash function that comes

00:42:40,580 --> 00:42:48,010
with the compiler will stay of the

00:42:45,410 --> 00:42:53,120
vision Avesta or whichever one you using

00:42:48,010 --> 00:42:57,680
so forth okay so ask you the others one

00:42:53,120 --> 00:42:58,460
is a bit complicated to explain so these

00:42:57,680 --> 00:43:00,800
two files

00:42:58,460 --> 00:43:03,530
- the algorithm is the first phase we

00:43:00,800 --> 00:43:05,900
even set a key and there's no collision

00:43:03,530 --> 00:43:11,210
the next phase is if there is a

00:43:05,900 --> 00:43:16,160
collision it must probe for a new for a

00:43:11,210 --> 00:43:20,990
new spice so what it does in that case

00:43:16,160 --> 00:43:26,330
is to take the size of the hash table

00:43:20,990 --> 00:43:30,500
say say did the - value divided by the

00:43:26,330 --> 00:43:32,420
size of that hash table and the negative

00:43:30,500 --> 00:43:35,630
number for instance if it's ten times

00:43:32,420 --> 00:43:38,830
larger than a nice table in 1811 and so

00:43:35,630 --> 00:43:43,099
on but before I I don't use that number

00:43:38,830 --> 00:43:46,520
directly as the offset for the probe

00:43:43,099 --> 00:43:49,910
with a probable scored because you can't

00:43:46,520 --> 00:43:52,070
do that but then you still have a lord -

00:43:49,910 --> 00:43:54,619
Dre spice which in a potential attacker

00:43:52,070 --> 00:44:01,520
can use to actually try and follow his

00:43:54,619 --> 00:44:03,890
buckets up so it we square so that port

00:44:01,520 --> 00:44:06,830
is actually like a quadratic Esther ball

00:44:03,890 --> 00:44:11,260
so that means that the total address

00:44:06,830 --> 00:44:15,490
space that the attacker has to actually

00:44:11,260 --> 00:44:21,320
cause you a stable to file or expand

00:44:15,490 --> 00:44:23,750
beyond available memory is a square root

00:44:21,320 --> 00:44:26,300
of the type of spice so it's a bit

00:44:23,750 --> 00:44:31,660
thinner inside instead if you're using

00:44:26,300 --> 00:44:34,369
64-bit Keys title address by stocker can

00:44:31,660 --> 00:44:38,109
exploit all the funny distribution or

00:44:34,369 --> 00:44:43,070
whatever is then 32 bits cuz it's almost

00:44:38,109 --> 00:44:46,820
of the total address space which is sort

00:44:43,070 --> 00:44:53,300
of the same strategy that they using the

00:44:46,820 --> 00:45:11,240
team size map as well okay but also two

00:44:53,300 --> 00:45:17,260
questions okay so rabbit doesn't have a

00:45:11,240 --> 00:45:17,260
fixed load factor and what it does is -

00:45:17,290 --> 00:45:23,480
at the end here

00:45:19,880 --> 00:45:25,580
if that little box at the end is

00:45:23,480 --> 00:45:29,390
exhausted that's the trigger for

00:45:25,580 --> 00:45:32,060
reaction so we don't I know in Google

00:45:29,390 --> 00:45:35,900
the large factories off because that's

00:45:32,060 --> 00:45:38,900
sort of optimal value for linear product

00:45:35,900 --> 00:45:40,490
having applied racing tires tables but

00:45:38,900 --> 00:45:57,890
for this one it will actually adapt to

00:45:40,490 --> 00:46:04,190
your specific distribution okay so in

00:45:57,890 --> 00:46:08,869
the library is a it depends again in the

00:46:04,190 --> 00:46:09,980
library there's a there's a function

00:46:08,869 --> 00:46:13,730
which calculated

00:46:09,980 --> 00:46:19,010
calculate the size of the bucket and

00:46:13,730 --> 00:46:21,460
that function basically nice tumors it's

00:46:19,010 --> 00:46:24,530
got a logarithmic mode and it's got a

00:46:21,460 --> 00:46:26,869
constant word so there's a function

00:46:24,530 --> 00:46:29,630
called set logarithmic ages say it to

00:46:26,869 --> 00:46:32,180
one then you take the logarithm of the

00:46:29,630 --> 00:46:34,670
this all ice double sided tape for a

00:46:32,180 --> 00:46:37,220
bucket and make that the size of the

00:46:34,670 --> 00:46:38,960
bucket and then you can say I said

00:46:37,220 --> 00:46:45,880
logarithm one two three four five

00:46:38,960 --> 00:46:45,880
whatever to make the ice table

00:46:46,990 --> 00:46:51,290
resize the lighter and lighter and

00:46:49,609 --> 00:46:53,089
lighter obviously making that bucket

00:46:51,290 --> 00:47:00,980
larger and larger as a performance

00:46:53,089 --> 00:47:04,490
penalty but with like these states said

00:47:00,980 --> 00:47:09,320
we had logarithmic factor say two one so

00:47:04,490 --> 00:47:14,880
that's about the fastest and and for

00:47:09,320 --> 00:47:19,900
that specific benchmark

00:47:14,880 --> 00:47:24,130
inputs it in other words basically I

00:47:19,900 --> 00:47:30,490
took a goof actual timing card and it

00:47:24,130 --> 00:47:32,590
just added a rabbit to it and then the

00:47:30,490 --> 00:47:36,340
keys that generate there the random keys

00:47:32,590 --> 00:47:39,810
on really that random it's about 20 bits

00:47:36,340 --> 00:47:43,180
of random place so it's not a lot but

00:47:39,810 --> 00:47:45,160
with some other taste soft time which I

00:47:43,180 --> 00:47:48,550
wanted to show you but I don't know

00:47:45,160 --> 00:47:52,810
seems like we're not gonna have time we

00:47:48,550 --> 00:47:54,250
use a full 60 64 bit of randomness it

00:47:52,810 --> 00:47:57,660
still performs really well

00:47:54,250 --> 00:48:02,830
much better than thin sash wall using

00:47:57,660 --> 00:48:09,460
also approximately after memory but you

00:48:02,830 --> 00:48:12,030
the idea is about the amount of multiply

00:48:09,460 --> 00:48:15,070
then it's the bucket size at the end by

00:48:12,030 --> 00:48:17,140
the logarithm times two times for

00:48:15,070 --> 00:48:19,660
something like that it's not just so

00:48:17,140 --> 00:48:24,970
it's a bit larger but it doesn't us

00:48:19,660 --> 00:48:26,830
because yeah it's just to to make sure

00:48:24,970 --> 00:48:30,340
you don't have that lost fiesh which

00:48:26,830 --> 00:49:04,930
something like so much bigger anyway

00:48:30,340 --> 00:49:15,760
okay okay sort of okay yeah oh okay oh

00:49:04,930 --> 00:49:17,680
that's a fair observation all right so I

00:49:15,760 --> 00:49:24,580
just wanna repeat for the audience that

00:49:17,680 --> 00:49:28,570
that you did some investigation in -

00:49:24,580 --> 00:49:31,990
Maps and you found that deletion isn't a

00:49:28,570 --> 00:49:36,630
very popular operational to do an ice

00:49:31,990 --> 00:49:44,100
table but for those people where is that

00:49:36,630 --> 00:49:47,650
for instance in this in the link page

00:49:44,100 --> 00:49:50,920
called we asked about in this koala of

00:49:47,650 --> 00:49:53,830
species alligators obviously using the

00:49:50,920 --> 00:49:55,930
ice table in alligators the others kind

00:49:53,830 --> 00:49:58,660
of a lot of delete especially for on the

00:49:55,930 --> 00:50:01,990
path because the why that alligator

00:49:58,660 --> 00:50:04,060
works is that it has a mind sort of

00:50:01,990 --> 00:50:06,640
trouble allocating which is lot and any

00:50:04,060 --> 00:50:10,270
for every thread is another little small

00:50:06,640 --> 00:50:14,860
alligator which if it's least recently

00:50:10,270 --> 00:50:18,670
used allocation sizes back to the main

00:50:14,860 --> 00:50:21,670
the main alligator and obviously when a

00:50:18,670 --> 00:50:24,880
victim or deleting we were uh

00:50:21,670 --> 00:50:29,190
negotiating from that side that guy sure

00:50:24,880 --> 00:50:31,570
it isn't he using deleting but for that

00:50:29,190 --> 00:50:37,330
in the short

00:50:31,570 --> 00:50:39,340
concurrent algorithms we check the stove

00:50:37,330 --> 00:50:41,980
versions per page and that kind of thing

00:50:39,340 --> 00:50:46,780
you're just creating like you say

00:50:41,980 --> 00:50:49,330
requiring all new eyes function is some

00:50:46,780 --> 00:50:52,210
other global ice table that contains the

00:50:49,330 --> 00:50:54,880
original versions and that per

00:50:52,210 --> 00:50:56,500
transaction tribal just gets discarded

00:50:54,880 --> 00:51:00,010
when it's finished doesn't actually

00:50:56,500 --> 00:51:06,670
delete anything okay any other questions

00:51:00,010 --> 00:51:09,810
okay that's fine okay

00:51:06,670 --> 00:51:09,810
I think I'm finished

00:51:12,180 --> 00:51:14,750

YouTube URL: https://www.youtube.com/watch?v=aXj_DsIx1xs


