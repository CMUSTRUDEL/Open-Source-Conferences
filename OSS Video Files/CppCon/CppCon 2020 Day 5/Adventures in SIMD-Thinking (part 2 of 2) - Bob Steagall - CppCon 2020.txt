Title: Adventures in SIMD-Thinking (part 2 of 2) - Bob Steagall - CppCon 2020
Publication date: 2020-10-06
Playlist: CppCon 2020 Day 5
Description: 
	https://cppcon.org/
https://github.com/CppCon/CppCon2020/blob/main/Presentations/adventures_in_simd_thinking_part_2/adventures_in_simd_thinking_part_2__bob_steagall__cppcon_2020.pdf
---
SIMD capabilities are virtually ubiquitous in modern computing hardware, and yet much of that computing capacity often goes unused. This talk will provide a high-level overview of the SSE, AVX, and AVX-512 instruction set architecture provided by Intel microprocessors, and provide some specific examples of real-world problems where additional performance can be gained by thinking "vertically".

We'll begin with a quick, high-level description of the features provided by the SSE, AVX, and AVX-512 instruction sets. We'll then use C++ to compose a simple API employing various compiler intrinsics implementing those instruction sets. At the lowest level, the API will wrap some primitive operations, and then build some very useful basic operations (like multi-register shift) upon those primitives. We'll then build some facilities for comparison and arithmetic, and finally round out the API with functions for load and store. During all of this, we'll use C++ to provide type safety, reduce complexity, and maximize performance.

Next, we'll take a look at how this simple API can be used to improve performance for a handful of interesting problems, like sorting the values stored in a register to create a very fast 1-D median filter, or high-speed convolution and correlation with kernels that fit within a single register. Finally, we'll revisit the UTF-8 to UTF-32 conversion techniques presented at CppCon two years ago to see whether using AVX can make an already fast conversion algorithm even faster.

---
Bob Steagall
KEWB Computing
Chief Cook and Bottle Washer
Maryland

---
Streamed & Edited by Digital Medium Ltd - events.digital-medium.co.uk
events@digital-medium.co.uk
Captions: 
	00:00:09,760 --> 00:00:12,559
hello everyone

00:00:10,559 --> 00:00:13,840
thanks for coming uh my name is bob

00:00:12,559 --> 00:00:15,679
stegall

00:00:13,840 --> 00:00:17,920
and this is the second top second part

00:00:15,679 --> 00:00:20,240
of my talk entitled adventures in

00:00:17,920 --> 00:00:22,560
simdi thinking in the first part of the

00:00:20,240 --> 00:00:24,880
talk uh i covered some

00:00:22,560 --> 00:00:27,599
primitives that we built around the

00:00:24,880 --> 00:00:29,359
intel's avx 512 intrinsic some simple

00:00:27,599 --> 00:00:30,720
functions for manipulating data in

00:00:29,359 --> 00:00:32,320
registers

00:00:30,720 --> 00:00:33,840
and then we looked at a couple of

00:00:32,320 --> 00:00:36,160
interesting problems

00:00:33,840 --> 00:00:38,559
how to do intra-register sorting of

00:00:36,160 --> 00:00:40,160
values in an avx-512 register

00:00:38,559 --> 00:00:42,320
and we looked at how we could apply that

00:00:40,160 --> 00:00:42,719
to creating a fast linear median of

00:00:42,320 --> 00:00:44,879
seven

00:00:42,719 --> 00:00:46,640
filter i promise to look at four

00:00:44,879 --> 00:00:49,280
problems then the other two problems

00:00:46,640 --> 00:00:50,640
are fast small kernel convolution the

00:00:49,280 --> 00:00:53,520
first thing we'll look at

00:00:50,640 --> 00:00:55,120
and the second is i will revisit a

00:00:53,520 --> 00:00:56,559
little bit of the talk i did two years

00:00:55,120 --> 00:00:59,239
ago at cppcon

00:00:56,559 --> 00:01:00,719
related to fast conversion from utf-8 to

00:00:59,239 --> 00:01:03,920
utf-32

00:01:00,719 --> 00:01:07,040
in that talk i did work using a dfa and

00:01:03,920 --> 00:01:09,280
ssc intrinsics to zero extend zero pad

00:01:07,040 --> 00:01:10,880
bytes to write them out more quickly

00:01:09,280 --> 00:01:12,799
and i attempted to squeeze a little bit

00:01:10,880 --> 00:01:14,880
more performance out of that technique

00:01:12,799 --> 00:01:18,720
with some mixed results

00:01:14,880 --> 00:01:22,400
so let's get started and move on to the

00:01:18,720 --> 00:01:22,400
fast small kernel convolution

00:01:22,799 --> 00:01:29,280
so what is convolution is a mathematical

00:01:26,640 --> 00:01:32,640
operation where a given signal

00:01:29,280 --> 00:01:33,280
in this case f is filtered uh by another

00:01:32,640 --> 00:01:36,799
signal

00:01:33,280 --> 00:01:39,439
g to great to create a different signal

00:01:36,799 --> 00:01:41,759
uh usually marked f star g and the star

00:01:39,439 --> 00:01:44,960
meaning convolution

00:01:41,759 --> 00:01:46,640
so f is a signal and g

00:01:44,960 --> 00:01:48,479
is something that we typically call a

00:01:46,640 --> 00:01:52,840
kernel

00:01:48,479 --> 00:01:54,720
and f star g is what we call the

00:01:52,840 --> 00:01:57,520
convolution

00:01:54,720 --> 00:01:59,360
every point of the result and the point

00:01:57,520 --> 00:02:00,000
of convolution is that every point of

00:01:59,360 --> 00:02:03,200
the result

00:02:00,000 --> 00:02:06,240
f star g is f weighted

00:02:03,200 --> 00:02:08,319
by every point of g

00:02:06,240 --> 00:02:10,560
it's useful for smoothing signals and

00:02:08,319 --> 00:02:13,840
for denoising

00:02:10,560 --> 00:02:17,760
so let's look at a small example

00:02:13,840 --> 00:02:21,360
in this case i have a signal a discrete

00:02:17,760 --> 00:02:22,000
signal s and it is represented by some

00:02:21,360 --> 00:02:25,840
sequence of

00:02:22,000 --> 00:02:27,360
samples s naught continuing

00:02:25,840 --> 00:02:29,040
and for the sake of argument and because

00:02:27,360 --> 00:02:30,560
there's limited space on the screen

00:02:29,040 --> 00:02:32,400
let's assume that i have a small

00:02:30,560 --> 00:02:34,080
discrete convolution kernel

00:02:32,400 --> 00:02:36,560
that has three elements and i'll call

00:02:34,080 --> 00:02:38,160
the kernel k it has elements k naught k1

00:02:36,560 --> 00:02:40,560
and k2

00:02:38,160 --> 00:02:41,840
i'm going to ignore the value of r1 at

00:02:40,560 --> 00:02:42,800
the moment because it's a boundary

00:02:41,840 --> 00:02:45,519
condition

00:02:42,800 --> 00:02:47,599
i'm going to start for r1 because there

00:02:45,519 --> 00:02:52,560
are no boundary conditions that apply

00:02:47,599 --> 00:02:56,160
so what is r1 r1 is equal to the signal

00:02:52,560 --> 00:02:59,519
at s0 times k0 plus the signal

00:02:56,160 --> 00:03:03,599
s1 times k1 plus a signal s2

00:02:59,519 --> 00:03:06,400
times k2 in other words it's s1 times k1

00:03:03,599 --> 00:03:08,640
plus the corresponding product of its

00:03:06,400 --> 00:03:10,959
two nearest neighbors left and right

00:03:08,640 --> 00:03:13,920
and that's the value of r1 the one index

00:03:10,959 --> 00:03:16,879
here corresponds to the one column

00:03:13,920 --> 00:03:18,000
and for r2 it's similar logic the value

00:03:16,879 --> 00:03:21,040
for r2

00:03:18,000 --> 00:03:22,640
is s2 times k1 because i've moved the

00:03:21,040 --> 00:03:26,720
convolution kernel over

00:03:22,640 --> 00:03:29,680
s1 times k naught s3 times k2

00:03:26,720 --> 00:03:30,959
and you follow this pattern and

00:03:29,680 --> 00:03:34,400
effectively what you're doing

00:03:30,959 --> 00:03:38,159
is you are waiting in your result

00:03:34,400 --> 00:03:42,000
for example r2 the value of r2

00:03:38,159 --> 00:03:44,560
is s2 s1 and s3

00:03:42,000 --> 00:03:46,720
weighted by the convolution kernel if

00:03:44,560 --> 00:03:48,400
this is a continuous infinite signal you

00:03:46,720 --> 00:03:50,319
know it would be integrals and

00:03:48,400 --> 00:03:52,560
it would be a little bit messier looking

00:03:50,319 --> 00:03:54,319
but for discrete convolution

00:03:52,560 --> 00:03:55,760
it's pretty straightforward and you can

00:03:54,319 --> 00:03:58,560
imagine implementing this

00:03:55,760 --> 00:03:59,200
as a nested loop an outer loop that

00:03:58,560 --> 00:04:01,680
moves

00:03:59,200 --> 00:04:03,439
along the signal and an inner loop that

00:04:01,680 --> 00:04:05,280
does this computation

00:04:03,439 --> 00:04:06,799
for each value of the kernel at each

00:04:05,280 --> 00:04:10,400
point in the signal

00:04:06,799 --> 00:04:12,319
so in this case if we had n if we had n

00:04:10,400 --> 00:04:13,760
discrete points in our sample

00:04:12,319 --> 00:04:16,079
and we have three elements in our

00:04:13,760 --> 00:04:17,199
convolution we can expect to do on the

00:04:16,079 --> 00:04:19,680
order of three n

00:04:17,199 --> 00:04:22,720
multiplications and three n additions or

00:04:19,680 --> 00:04:25,440
two n additions perhaps

00:04:22,720 --> 00:04:26,720
so this process continues until you run

00:04:25,440 --> 00:04:29,840
out of discrete signal

00:04:26,720 --> 00:04:29,840
uh to be sampled

00:04:30,560 --> 00:04:34,479
now here's another way of looking at it

00:04:32,160 --> 00:04:36,720
a graphical way

00:04:34,479 --> 00:04:38,639
here we have our our input signal and

00:04:36,720 --> 00:04:39,759
again i'm ignoring r0 because it's a

00:04:38,639 --> 00:04:41,360
boundary condition and those are a

00:04:39,759 --> 00:04:44,720
little more complicated

00:04:41,360 --> 00:04:47,520
and i've got my kernel k and

00:04:44,720 --> 00:04:49,199
i slide k along the signal and for each

00:04:47,520 --> 00:04:51,759
stop along the way

00:04:49,199 --> 00:04:53,040
i compute the product in the columns add

00:04:51,759 --> 00:04:55,199
it all together

00:04:53,040 --> 00:04:57,199
and that's what my result is for that

00:04:55,199 --> 00:05:02,000
corresponding element

00:04:57,199 --> 00:05:02,000
so it's a sliding window computation

00:05:03,919 --> 00:05:09,600
well we can rewrite the equations

00:05:07,120 --> 00:05:10,639
in a slightly different way remember

00:05:09,600 --> 00:05:12,560
before

00:05:10,639 --> 00:05:14,880
i wrote them as though there was some

00:05:12,560 --> 00:05:18,240
like a diagonal matrix all right

00:05:14,880 --> 00:05:21,039
almost but let's rewrite them

00:05:18,240 --> 00:05:22,320
let's just stack all of the terms up

00:05:21,039 --> 00:05:25,919
along the left

00:05:22,320 --> 00:05:27,360
for r1 r2 through r5 and ignore are not

00:05:25,919 --> 00:05:30,320
for now

00:05:27,360 --> 00:05:31,840
well when i was trying to make this fast

00:05:30,320 --> 00:05:32,960
it took me a while to come to the point

00:05:31,840 --> 00:05:34,880
where i figured out

00:05:32,960 --> 00:05:38,160
what if i stacked what if i wrote the

00:05:34,880 --> 00:05:39,840
equations this way

00:05:38,160 --> 00:05:42,400
well when i did it this way i noticed

00:05:39,840 --> 00:05:45,600
something very interesting

00:05:42,400 --> 00:05:48,639
i noticed that

00:05:45,600 --> 00:05:52,080
there was a limited number

00:05:48,639 --> 00:05:54,240
of columns but one of the

00:05:52,080 --> 00:05:56,000
one of the factors in each column was an

00:05:54,240 --> 00:05:58,240
element from the kernel

00:05:56,000 --> 00:05:59,280
and i started looking at thinking well

00:05:58,240 --> 00:06:01,680
wait a minute

00:05:59,280 --> 00:06:03,039
i could put that in a register i could

00:06:01,680 --> 00:06:05,280
put this in a register

00:06:03,039 --> 00:06:06,960
i could put this in a register then if i

00:06:05,280 --> 00:06:10,160
was somehow able to

00:06:06,960 --> 00:06:14,319
multiply against these guys i would be

00:06:10,160 --> 00:06:14,319
able to do this in a vectorized fashion

00:06:14,800 --> 00:06:19,440
so thinking about it i said well all

00:06:18,000 --> 00:06:20,479
right let's think about it in terms of

00:06:19,440 --> 00:06:25,440
registers

00:06:20,479 --> 00:06:25,440
let's take this diagram

00:06:26,319 --> 00:06:30,160
and let's do a transpose let's transpose

00:06:28,319 --> 00:06:33,520
it around the major axis

00:06:30,160 --> 00:06:35,680
so here we've got our signal

00:06:33,520 --> 00:06:37,759
and we've got the values of the first

00:06:35,680 --> 00:06:40,080
convolution kernel element

00:06:37,759 --> 00:06:41,680
and we've shifted the signal and we've

00:06:40,080 --> 00:06:43,840
got the values of the

00:06:41,680 --> 00:06:46,080
second convolution kernel and the same

00:06:43,840 --> 00:06:47,919
thing for the third kernel element

00:06:46,080 --> 00:06:50,240
well if you look at what the value is

00:06:47,919 --> 00:06:53,280
supposed to be for r1

00:06:50,240 --> 00:06:53,759
it is s naught times k naught s1 times

00:06:53,280 --> 00:06:56,880
k1

00:06:53,759 --> 00:06:58,479
s2 times k2 that's r1 so if i could

00:06:56,880 --> 00:07:01,280
somehow contrive

00:06:58,479 --> 00:07:02,560
to load up some registers in this

00:07:01,280 --> 00:07:04,720
fashion

00:07:02,560 --> 00:07:06,000
i could do this using my fused multiply

00:07:04,720 --> 00:07:09,759
and add function

00:07:06,000 --> 00:07:12,720
that i described in the previous talk

00:07:09,759 --> 00:07:13,440
so in fact that's what i did and so i'd

00:07:12,720 --> 00:07:16,479
like to

00:07:13,440 --> 00:07:18,160
take a look at that function now

00:07:16,479 --> 00:07:19,919
this is a function template and it's

00:07:18,160 --> 00:07:20,800
parameterized in terms of the kernel

00:07:19,919 --> 00:07:23,280
size

00:07:20,800 --> 00:07:24,240
and the center of the kernel and the

00:07:23,280 --> 00:07:26,160
center of the kernel

00:07:24,240 --> 00:07:28,880
basically is what point of the kernel do

00:07:26,160 --> 00:07:30,720
you want to call the middle

00:07:28,880 --> 00:07:32,080
so because this has to fit into a

00:07:30,720 --> 00:07:35,360
register

00:07:32,080 --> 00:07:38,080
uh the kernel size has to be

00:07:35,360 --> 00:07:41,680
16 or less it has to be greater than one

00:07:38,080 --> 00:07:44,240
it has to be less than or equal to 16.

00:07:41,680 --> 00:07:45,360
and the index of the center of the

00:07:44,240 --> 00:07:48,319
kernel

00:07:45,360 --> 00:07:50,479
also has to be in that in that number

00:07:48,319 --> 00:07:52,960
range greater than or equal to zero

00:07:50,479 --> 00:07:54,400
and it has to be less than the kernel

00:07:52,960 --> 00:07:56,560
size

00:07:54,400 --> 00:07:58,560
and because i was using median of seven

00:07:56,560 --> 00:07:59,520
in my previous slides and i'm somewhat

00:07:58,560 --> 00:08:01,440
lazy

00:07:59,520 --> 00:08:04,000
i'm in the examples i'm going to give

00:08:01,440 --> 00:08:06,160
you i'm assuming that our convolution

00:08:04,000 --> 00:08:08,240
kernel has seven elements in it

00:08:06,160 --> 00:08:09,759
and later on when i you see the tests

00:08:08,240 --> 00:08:13,039
that i run you'll see that i

00:08:09,759 --> 00:08:16,319
ran tests for 3 5 7 9 11

00:08:13,039 --> 00:08:18,639
13 and 15 elements in the convolution

00:08:16,319 --> 00:08:18,639
kernel

00:08:18,879 --> 00:08:22,479
so we validate that our kernel size is

00:08:21,919 --> 00:08:24,840
correct

00:08:22,479 --> 00:08:26,800
we validate that the kernel center is

00:08:24,840 --> 00:08:30,560
reasonable

00:08:26,800 --> 00:08:32,320
oh sorry and we compute uh the window

00:08:30,560 --> 00:08:34,880
center based on the kernel center

00:08:32,320 --> 00:08:35,680
now convolution has this weird property

00:08:34,880 --> 00:08:37,519
where

00:08:35,680 --> 00:08:39,680
when you take the kernel signal in the

00:08:37,519 --> 00:08:41,200
kernel before you apply it you actually

00:08:39,680 --> 00:08:43,279
have to reverse it

00:08:41,200 --> 00:08:45,279
and if you leave the orientation as it

00:08:43,279 --> 00:08:48,240
is originally that's correlation

00:08:45,279 --> 00:08:49,360
when you turn it the other way it is

00:08:48,240 --> 00:08:51,360
convolution

00:08:49,360 --> 00:08:52,959
if you have a kernel that's symmetric

00:08:51,360 --> 00:08:55,279
then convolution and correlation will

00:08:52,959 --> 00:08:58,240
give you the same answer

00:08:55,279 --> 00:08:59,360
so like before uh with the median of of

00:08:58,240 --> 00:09:01,360
seven

00:08:59,360 --> 00:09:03,680
we have some work registers that use

00:09:01,360 --> 00:09:06,320
similar names to do similar things

00:09:03,680 --> 00:09:08,320
we have registers preoccur and next

00:09:06,320 --> 00:09:11,279
previous current and next registers

00:09:08,320 --> 00:09:14,399
which represent the data input window of

00:09:11,279 --> 00:09:16,880
the data that we've read from memory

00:09:14,399 --> 00:09:19,040
we have two work registers low and high

00:09:16,880 --> 00:09:21,120
where a lot of the dirty work gets done

00:09:19,040 --> 00:09:23,040
we have a register called sum which is

00:09:21,120 --> 00:09:24,560
the accumulated value as

00:09:23,040 --> 00:09:27,519
you go through the sequence of fuse

00:09:24,560 --> 00:09:27,519
multiply ads

00:09:28,640 --> 00:09:36,160
i have an array of registers

00:09:33,519 --> 00:09:37,920
equal to the kernel size that are going

00:09:36,160 --> 00:09:40,399
to hold the coefficients of my

00:09:37,920 --> 00:09:43,760
convolution chrome

00:09:40,399 --> 00:09:45,279
so this can't be this can't be static

00:09:43,760 --> 00:09:48,480
and it can't be const x

00:09:45,279 --> 00:09:50,320
because my convolution kernel is

00:09:48,480 --> 00:09:54,000
provided at run time

00:09:50,320 --> 00:09:56,560
so this this array

00:09:54,000 --> 00:09:58,480
and this loop are all runtime constructs

00:09:56,560 --> 00:10:01,839
they can't be const expert

00:09:58,480 --> 00:10:04,880
but what i am going to do is for each

00:10:01,839 --> 00:10:07,360
element in my array of registers

00:10:04,880 --> 00:10:08,720
that are going to hold cur convolution

00:10:07,360 --> 00:10:10,959
kernel elements

00:10:08,720 --> 00:10:12,240
i'm going to broadcast the value of each

00:10:10,959 --> 00:10:16,160
kernel element

00:10:12,240 --> 00:10:18,480
into that array so k coefficient 0

00:10:16,160 --> 00:10:19,279
will have the will have the broadcasted

00:10:18,480 --> 00:10:23,279
value of

00:10:19,279 --> 00:10:23,279
kernel zero and so on and so forth

00:10:23,600 --> 00:10:27,120
the next thing i'm going to do is i'm

00:10:25,440 --> 00:10:29,279
going to pull some data out of memory

00:10:27,120 --> 00:10:31,600
and load it into registers my previous

00:10:29,279 --> 00:10:33,120
current and next registers

00:10:31,600 --> 00:10:34,640
my previous register i'm going to load

00:10:33,120 --> 00:10:35,839
with 0 is to handle the boundary

00:10:34,640 --> 00:10:37,519
condition

00:10:35,839 --> 00:10:39,200
my current register i'm going to read

00:10:37,519 --> 00:10:41,360
from the beginning of my memory buffer

00:10:39,200 --> 00:10:43,680
where i want to perform the convolution

00:10:41,360 --> 00:10:45,279
in my next register i'm going to read

00:10:43,680 --> 00:10:46,000
that from the next register's worth of

00:10:45,279 --> 00:10:49,839
data

00:10:46,000 --> 00:10:49,839
past the first read

00:10:50,320 --> 00:10:55,680
so at the end of those functions

00:10:53,360 --> 00:10:57,680
here are my three work registers this is

00:10:55,680 --> 00:10:59,519
my my zeros

00:10:57,680 --> 00:11:00,800
this is my first register's worth of

00:10:59,519 --> 00:11:02,560
float values

00:11:00,800 --> 00:11:05,279
this is my second register worth of

00:11:02,560 --> 00:11:05,279
float values

00:11:06,640 --> 00:11:10,079
now i'm going to take my accumulator and

00:11:08,720 --> 00:11:11,760
i'm going to zero it because i'm going

00:11:10,079 --> 00:11:15,040
to reuse it so i need to zero it before

00:11:11,760 --> 00:11:16,800
i begin the calculations

00:11:15,040 --> 00:11:18,079
next i'm going to do this crazy

00:11:16,800 --> 00:11:20,320
operation i told you before

00:11:18,079 --> 00:11:21,519
shift up with carry and what shift up

00:11:20,320 --> 00:11:23,920
carry is going to do

00:11:21,519 --> 00:11:24,640
is it's going to take our work registers

00:11:23,920 --> 00:11:27,839
and it's going to

00:11:24,640 --> 00:11:29,600
load them with values taken from some

00:11:27,839 --> 00:11:32,320
combination of prev

00:11:29,600 --> 00:11:33,680
and cur in effect what we're going to do

00:11:32,320 --> 00:11:35,680
is we're going to take

00:11:33,680 --> 00:11:36,800
we're going to treat prevent ker as if

00:11:35,680 --> 00:11:41,440
they were one

00:11:36,800 --> 00:11:44,240
large register that had 32 values in it

00:11:41,440 --> 00:11:46,240
we're going to shift it up by the value

00:11:44,240 --> 00:11:47,920
that's the center of the window

00:11:46,240 --> 00:11:50,240
and we're going to load the top of that

00:11:47,920 --> 00:11:52,880
register those top 16 values

00:11:50,240 --> 00:11:54,160
into low for this combination we're

00:11:52,880 --> 00:11:57,200
going to do the same thing

00:11:54,160 --> 00:12:00,880
for high so when we're done

00:11:57,200 --> 00:12:00,880
we get a picture that looks like this

00:12:03,120 --> 00:12:06,639
so we've taken pre-even cur we've

00:12:05,200 --> 00:12:08,720
shifted it to the right by three

00:12:06,639 --> 00:12:11,040
elements which is half the kernel size

00:12:08,720 --> 00:12:11,920
and we've loaded that into the low work

00:12:11,040 --> 00:12:14,160
register

00:12:11,920 --> 00:12:15,600
as i described and the same thing for

00:12:14,160 --> 00:12:18,399
the high work register

00:12:15,600 --> 00:12:19,920
we've taken ker and next we've shifted

00:12:18,399 --> 00:12:22,160
them up by three elements

00:12:19,920 --> 00:12:23,600
and we've loaded them directly down into

00:12:22,160 --> 00:12:25,360
the high register

00:12:23,600 --> 00:12:27,120
and from this point forward for the rest

00:12:25,360 --> 00:12:28,639
of the loop we don't really touch

00:12:27,120 --> 00:12:30,639
prevent current next

00:12:28,639 --> 00:12:31,680
we've got everything that we need to do

00:12:30,639 --> 00:12:34,639
our work now

00:12:31,680 --> 00:12:34,639
in low and high

00:12:34,880 --> 00:12:39,839
so i'm going to take the pre-current

00:12:38,160 --> 00:12:42,880
next register

00:12:39,839 --> 00:12:44,880
i'm going to load them and

00:12:42,880 --> 00:12:45,920
with another value and so they've all

00:12:44,880 --> 00:12:47,279
shifted to the left

00:12:45,920 --> 00:12:49,839
and now we're going to ignore them for

00:12:47,279 --> 00:12:51,200
the rest of the loop

00:12:49,839 --> 00:12:53,120
now is when i actually do the

00:12:51,200 --> 00:12:55,600
interesting work that

00:12:53,120 --> 00:12:56,240
makes the convolution work so what i'm

00:12:55,600 --> 00:12:59,920
going to do

00:12:56,240 --> 00:13:01,040
is for each coefficient in my kernel

00:12:59,920 --> 00:13:03,680
which is stored

00:13:01,040 --> 00:13:06,160
in this array of coefficient registers

00:13:03,680 --> 00:13:07,839
i'm going to do a fused multiply add

00:13:06,160 --> 00:13:10,639
of that coefficient stored in that

00:13:07,839 --> 00:13:12,320
register with the corresponding values

00:13:10,639 --> 00:13:14,160
in low because low is going to be my

00:13:12,320 --> 00:13:17,040
primary work register

00:13:14,160 --> 00:13:18,639
and i'm going to do the multiply and i'm

00:13:17,040 --> 00:13:20,480
going to add

00:13:18,639 --> 00:13:22,079
what's in the accumulator already in the

00:13:20,480 --> 00:13:23,760
accumulator so i'm going to multiply the

00:13:22,079 --> 00:13:25,920
coefficient times low

00:13:23,760 --> 00:13:27,839
i'm going to add it to sum and then i'm

00:13:25,920 --> 00:13:31,519
going to store the result back in sum

00:13:27,839 --> 00:13:34,639
so sum accumulates the result

00:13:31,519 --> 00:13:36,639
so i have low and i have high i have my

00:13:34,639 --> 00:13:37,360
coefficient zero the first one that i'm

00:13:36,639 --> 00:13:39,680
doing

00:13:37,360 --> 00:13:40,880
i'm doing a fused multiply and add of

00:13:39,680 --> 00:13:44,560
coefficient zero

00:13:40,880 --> 00:13:45,839
and low i add it to sum and it goes into

00:13:44,560 --> 00:13:49,279
here

00:13:45,839 --> 00:13:52,320
it's that easy

00:13:49,279 --> 00:13:53,199
i go down and do another shift this time

00:13:52,320 --> 00:13:55,199
i'm going to shift

00:13:53,199 --> 00:13:56,480
i'm going to take the combination of low

00:13:55,199 --> 00:13:58,160
and high

00:13:56,480 --> 00:14:00,639
and i'm going to shift them to the left

00:13:58,160 --> 00:14:02,000
by one and that is effectively the same

00:14:00,639 --> 00:14:04,320
thing as taking that window

00:14:02,000 --> 00:14:07,440
that represents my kernel and shifting

00:14:04,320 --> 00:14:09,839
it upward by one or to the right by one

00:14:07,440 --> 00:14:12,480
so i shift it down by one and i do the

00:14:09,839 --> 00:14:14,560
fuse multiply add operations again

00:14:12,480 --> 00:14:17,040
and here's what that looks like so now

00:14:14,560 --> 00:14:19,760
i've got coefficient number one loaded

00:14:17,040 --> 00:14:21,839
and you can see that i've shifted i've

00:14:19,760 --> 00:14:23,519
shifted downward low and high and i've

00:14:21,839 --> 00:14:25,199
filled because it's a shift i filled the

00:14:23,519 --> 00:14:26,800
top end of high with a zero which i

00:14:25,199 --> 00:14:30,240
represent by white

00:14:26,800 --> 00:14:33,360
i do the fused multiply add i multiply

00:14:30,240 --> 00:14:35,360
i add i accumulate in sum

00:14:33,360 --> 00:14:36,480
and i will continue this a few more

00:14:35,360 --> 00:14:39,519
times

00:14:36,480 --> 00:14:42,639
for coefficient number two

00:14:39,519 --> 00:14:45,519
for coefficient number three

00:14:42,639 --> 00:14:48,079
for coefficient number four for

00:14:45,519 --> 00:14:50,480
coefficient number five

00:14:48,079 --> 00:14:52,240
coefficient number six and notice how

00:14:50,480 --> 00:14:55,040
the values in high

00:14:52,240 --> 00:14:56,880
have been shifting down into low which

00:14:55,040 --> 00:14:58,959
is effectively the same thing as

00:14:56,880 --> 00:15:00,320
taking the coefficient register and

00:14:58,959 --> 00:15:02,240
shifting it upward

00:15:00,320 --> 00:15:04,079
and every time i do this single step

00:15:02,240 --> 00:15:06,880
multiplication and add

00:15:04,079 --> 00:15:08,720
i accumulate the result in sum so

00:15:06,880 --> 00:15:08,959
because my kernel has seven elements in

00:15:08,720 --> 00:15:10,800
it

00:15:08,959 --> 00:15:12,320
and i've done the fuse multiply add with

00:15:10,800 --> 00:15:14,240
seven coefficients

00:15:12,320 --> 00:15:15,920
at the end of this loop where i've done

00:15:14,240 --> 00:15:19,199
these seven operations

00:15:15,920 --> 00:15:22,240
sum now has the value of the convolution

00:15:19,199 --> 00:15:26,480
for every element that was that was uh

00:15:22,240 --> 00:15:29,040
originally part of of curve

00:15:26,480 --> 00:15:29,920
so when i'm done i will store that out

00:15:29,040 --> 00:15:32,880
to memory

00:15:29,920 --> 00:15:33,920
blast it out to memory i'll loop back up

00:15:32,880 --> 00:15:36,079
to the top

00:15:33,920 --> 00:15:37,519
and do the whole thing again and i've

00:15:36,079 --> 00:15:39,040
already done my shifting

00:15:37,519 --> 00:15:40,720
in the previous iteration of the loop

00:15:39,040 --> 00:15:42,880
i've already shifted my data

00:15:40,720 --> 00:15:44,959
a register's worth of data i've already

00:15:42,880 --> 00:15:46,160
read that so at the top of the loop i'll

00:15:44,959 --> 00:15:49,519
actually do my shift

00:15:46,160 --> 00:15:50,240
shift up with carry and you know load

00:15:49,519 --> 00:15:52,320
for the next

00:15:50,240 --> 00:15:54,000
iteration and then go through those

00:15:52,320 --> 00:15:56,720
operations again for the next register's

00:15:54,000 --> 00:15:56,720
worth of data

00:15:57,600 --> 00:16:03,600
so i wrote some tests to test this

00:16:02,079 --> 00:16:05,120
because i wanted to compare it i wanted

00:16:03,600 --> 00:16:06,959
to see how fast it was

00:16:05,120 --> 00:16:09,360
and the benchmark i used was comparing

00:16:06,959 --> 00:16:11,600
it to intel's math kernel library

00:16:09,360 --> 00:16:13,440
which has its own very fast convolution

00:16:11,600 --> 00:16:16,240
algorithm as well and

00:16:13,440 --> 00:16:17,360
um people sort of think of that at least

00:16:16,240 --> 00:16:19,279
in my world as being

00:16:17,360 --> 00:16:20,639
you know a good benchmark they're sort

00:16:19,279 --> 00:16:22,160
of the you know

00:16:20,639 --> 00:16:25,360
thought of as being the best performers

00:16:22,160 --> 00:16:27,360
there so

00:16:25,360 --> 00:16:29,440
because i'm using avx 512 intrinsics

00:16:27,360 --> 00:16:32,320
just like the median of 7 filter

00:16:29,440 --> 00:16:32,959
i ran these on an avx 512 compatible

00:16:32,320 --> 00:16:36,000
system

00:16:32,959 --> 00:16:36,480
or capable system which either sky lake

00:16:36,000 --> 00:16:38,800
or

00:16:36,480 --> 00:16:40,639
cascade lake systems will are now

00:16:38,800 --> 00:16:42,240
capable of avx-512

00:16:40,639 --> 00:16:43,759
this happened to be a cascade lake

00:16:42,240 --> 00:16:46,959
system i

00:16:43,759 --> 00:16:48,160
tested i built with gcc 10 2 and clang

00:16:46,959 --> 00:16:51,440
00:16:48,160 --> 00:16:54,720
and again as before i compile with -03

00:16:51,440 --> 00:16:56,720
and flags telling gcc and clang

00:16:54,720 --> 00:17:00,160
uh this these are the intrinsics i would

00:16:56,720 --> 00:17:00,160
like you to consider emitting

00:17:00,959 --> 00:17:07,959
i tested my results i tested my

00:17:03,759 --> 00:17:10,559
algorithm against that of intel's mkl

00:17:07,959 --> 00:17:11,919
2020.1.217 which i obtained earlier in

00:17:10,559 --> 00:17:14,880
the year i think there are probably one

00:17:11,919 --> 00:17:17,439
or two newer ones since then

00:17:14,880 --> 00:17:19,360
and as i mentioned before i compared my

00:17:17,439 --> 00:17:21,199
algorithm against intel's convolution

00:17:19,360 --> 00:17:23,120
algorithm

00:17:21,199 --> 00:17:24,720
for kernel sizes odd numbered kernel

00:17:23,120 --> 00:17:26,240
sizes from 3 to 15

00:17:24,720 --> 00:17:30,240
because remember the kernel has to fit

00:17:26,240 --> 00:17:33,120
within a single register of 16 elements

00:17:30,240 --> 00:17:34,160
this i did for element counts of 1 000

00:17:33,120 --> 00:17:36,720
through 10 million

00:17:34,160 --> 00:17:39,520
again multiplying each kernel size by a

00:17:36,720 --> 00:17:39,520
factor of 10.

00:17:40,000 --> 00:17:43,679
and i collect timings for each

00:17:41,840 --> 00:17:45,679
combination using the

00:17:43,679 --> 00:17:46,799
for each of those combinations so there

00:17:45,679 --> 00:17:50,160
are

00:17:46,799 --> 00:17:52,400
uh ten or so combinations of kernel uh

00:17:50,160 --> 00:17:54,000
well let's see there are seven seven i

00:17:52,400 --> 00:17:56,960
think combinations of kernel

00:17:54,000 --> 00:17:58,320
uh times five combinations of size so i

00:17:56,960 --> 00:18:00,080
collected all the timings for those

00:17:58,320 --> 00:18:02,480
using the mkl based

00:18:00,080 --> 00:18:05,200
convolution and my small kernel avx

00:18:02,480 --> 00:18:06,799
based convolution

00:18:05,200 --> 00:18:08,799
and so here are some of the results that

00:18:06,799 --> 00:18:12,160
i got starting with clang

00:18:08,799 --> 00:18:16,240
so kernel sizes 3 5 7 9 11

00:18:12,160 --> 00:18:17,200
13 and 15. and this is the factor speed

00:18:16,240 --> 00:18:20,960
up

00:18:17,200 --> 00:18:24,480
of the avx based approach relative to

00:18:20,960 --> 00:18:26,640
mkl so for a very small kernel

00:18:24,480 --> 00:18:28,799
of well for any kernel size for a

00:18:26,640 --> 00:18:31,760
thousand elements

00:18:28,799 --> 00:18:33,520
the avx based approach was was

00:18:31,760 --> 00:18:36,320
significantly faster

00:18:33,520 --> 00:18:38,080
and it was very fast for small kernel

00:18:36,320 --> 00:18:40,160
sizes you can see

00:18:38,080 --> 00:18:42,799
for small kernel sizes and small amounts

00:18:40,160 --> 00:18:44,640
of data it was significantly faster

00:18:42,799 --> 00:18:46,559
the performance tended to converge as

00:18:44,640 --> 00:18:48,400
you got to more elements and i expect

00:18:46,559 --> 00:18:49,919
probably a lot of the behavior that

00:18:48,400 --> 00:18:52,240
we're seeing here

00:18:49,919 --> 00:18:54,640
is memory being or elements being

00:18:52,240 --> 00:18:56,480
contained wholly inside of cash

00:18:54,640 --> 00:18:58,080
and once we got to a million elements or

00:18:56,480 --> 00:19:01,520
more we could no longer have everything

00:18:58,080 --> 00:19:03,760
in cash and cash uh memory latency

00:19:01,520 --> 00:19:05,600
started to affect the calculations and

00:19:03,760 --> 00:19:07,200
started to affect the avx calculations

00:19:05,600 --> 00:19:10,320
perhaps more than the

00:19:07,200 --> 00:19:14,000
the uh mkl calculations

00:19:10,320 --> 00:19:16,720
uh but in any event um

00:19:14,000 --> 00:19:18,400
even for a kernel size of 15 and for 10

00:19:16,720 --> 00:19:19,919
million elements

00:19:18,400 --> 00:19:22,160
uh and the performance here for kernel

00:19:19,919 --> 00:19:24,080
size of 15 was pretty flat

00:19:22,160 --> 00:19:25,200
all across the board here the kernel

00:19:24,080 --> 00:19:27,760
size of 15

00:19:25,200 --> 00:19:28,559
was on the order of about eight times

00:19:27,760 --> 00:19:31,919
faster

00:19:28,559 --> 00:19:32,480
than mkl well i was pretty pleased with

00:19:31,919 --> 00:19:36,640
that

00:19:32,480 --> 00:19:38,559
so this was clang for gcc it was

00:19:36,640 --> 00:19:40,240
it was a little bit better and i'm not

00:19:38,559 --> 00:19:42,400
sure i mean the

00:19:40,240 --> 00:19:43,919
the mkl library comes as object code so

00:19:42,400 --> 00:19:46,000
there's no changing that that just gets

00:19:43,919 --> 00:19:47,919
linked into the program

00:19:46,000 --> 00:19:49,440
so i can only explain this by thinking

00:19:47,919 --> 00:19:52,400
this was the same machine

00:19:49,440 --> 00:19:53,360
uh same day same hour running these

00:19:52,400 --> 00:19:54,720
things

00:19:53,360 --> 00:19:57,120
i can only assume that in this

00:19:54,720 --> 00:20:00,080
particular instance gcc is perhaps

00:19:57,120 --> 00:20:03,280
emitting more efficient

00:20:00,080 --> 00:20:05,600
machine instructions than climb was

00:20:03,280 --> 00:20:07,520
but in any event there's more of a

00:20:05,600 --> 00:20:09,679
pronounced lien

00:20:07,520 --> 00:20:10,799
asymptotically with larger data sizes

00:20:09,679 --> 00:20:13,039
but even so

00:20:10,799 --> 00:20:14,880
everything tended to converge for all

00:20:13,039 --> 00:20:15,840
kernel sizes the performance tend to

00:20:14,880 --> 00:20:18,559
converge

00:20:15,840 --> 00:20:21,360
between 12 and 15 times faster at 10

00:20:18,559 --> 00:20:24,480
million elements for the avx approach

00:20:21,360 --> 00:20:26,240
versus the mkl approach so

00:20:24,480 --> 00:20:28,000
i thought that that was some pretty

00:20:26,240 --> 00:20:30,480
reasonable results

00:20:28,000 --> 00:20:31,600
in the code that i showed you i actually

00:20:30,480 --> 00:20:33,440
did not

00:20:31,600 --> 00:20:35,440
include the code in the slides that

00:20:33,440 --> 00:20:37,120
accounts for the boundary conditions

00:20:35,440 --> 00:20:38,720
but even with the boundary condition

00:20:37,120 --> 00:20:41,280
code which

00:20:38,720 --> 00:20:42,960
is actually factored into these these

00:20:41,280 --> 00:20:43,440
performance times that you see you still

00:20:42,960 --> 00:20:46,320
get

00:20:43,440 --> 00:20:47,200
these results so i was pretty pleased

00:20:46,320 --> 00:20:49,360
with that

00:20:47,200 --> 00:20:51,200
i expect someone will come along and see

00:20:49,360 --> 00:20:52,960
what i've done and make it even faster

00:20:51,200 --> 00:20:55,120
and i hope they do and i hope they share

00:20:52,960 --> 00:20:55,120
it

00:20:55,440 --> 00:21:04,080
okay so that's it for small element to

00:20:58,960 --> 00:21:06,720
convolution a small kernel convolution

00:21:04,080 --> 00:21:09,280
um now i'd like to move on to revisit

00:21:06,720 --> 00:21:12,880
this topic that i've discussed before

00:21:09,280 --> 00:21:16,000
utf-8 utf-32 conversion algorithm

00:21:12,880 --> 00:21:18,559
and i've included a fairly

00:21:16,000 --> 00:21:20,400
extensive portion although not all of it

00:21:18,559 --> 00:21:21,600
from the talk that i gave two years ago

00:21:20,400 --> 00:21:23,520
because

00:21:21,600 --> 00:21:25,679
in order to describe the improvements

00:21:23,520 --> 00:21:26,400
that i made i felt that it was necessary

00:21:25,679 --> 00:21:29,200
to include

00:21:26,400 --> 00:21:30,880
some context so that the improvements i

00:21:29,200 --> 00:21:32,640
was just not i wasn't just showing you

00:21:30,880 --> 00:21:35,200
code that came out of nowhere

00:21:32,640 --> 00:21:36,480
to provide some context for for what you

00:21:35,200 --> 00:21:38,480
saw

00:21:36,480 --> 00:21:40,640
so i want to briefly sort of walk

00:21:38,480 --> 00:21:42,159
through how the conversion works

00:21:40,640 --> 00:21:44,320
and look at the four different

00:21:42,159 --> 00:21:47,840
algorithms that i implemented

00:21:44,320 --> 00:21:50,960
a basic algorithm a a simple

00:21:47,840 --> 00:21:53,280
ascii optimized algorithm an

00:21:50,960 --> 00:21:54,960
algorithm that's optimized for ascii but

00:21:53,280 --> 00:21:58,640
uses sse intrinsics

00:21:54,960 --> 00:22:00,880
sse2 intrinsics to be exact and

00:21:58,640 --> 00:22:02,559
an algorithm that's optimized for ascii

00:22:00,880 --> 00:22:06,159
that uses avx

00:22:02,559 --> 00:22:10,320
2 intrinsics so i'm going to

00:22:06,159 --> 00:22:11,919
jump into that so

00:22:10,320 --> 00:22:13,520
without much ado and without really

00:22:11,919 --> 00:22:16,240
talking about unicode the way the

00:22:13,520 --> 00:22:18,880
algorithm works is it works by

00:22:16,240 --> 00:22:19,679
feeding a sequence of input bytes

00:22:18,880 --> 00:22:23,600
through

00:22:19,679 --> 00:22:25,440
a dfa and the dfa has

00:22:23,600 --> 00:22:27,360
is basically divided into character

00:22:25,440 --> 00:22:28,400
classes which are represented by each of

00:22:27,360 --> 00:22:32,000
these ranges of

00:22:28,400 --> 00:22:34,799
octet remember utf-8

00:22:32,000 --> 00:22:35,039
is un is at a minimum or it is exactly

00:22:34,799 --> 00:22:38,480
an

00:22:35,039 --> 00:22:40,159
8-bit unsigned integer so data comes in

00:22:38,480 --> 00:22:43,919
as a stream of octets

00:22:40,159 --> 00:22:44,960
they call them so there are 256 possible

00:22:43,919 --> 00:22:48,960
values

00:22:44,960 --> 00:22:51,600
and these ranges correspond to state

00:22:48,960 --> 00:22:53,840
transitions that occur in the dfa

00:22:51,600 --> 00:22:56,320
when you encounter an octet that has a

00:22:53,840 --> 00:22:58,320
value that lies in that range

00:22:56,320 --> 00:23:00,480
the transitions in the dfa that you see

00:22:58,320 --> 00:23:01,760
in this diagram are only for legal

00:23:00,480 --> 00:23:04,559
transitions

00:23:01,760 --> 00:23:04,960
any transition that that causes an error

00:23:04,559 --> 00:23:06,960
or

00:23:04,960 --> 00:23:08,159
is an encounter of an illegal byte or an

00:23:06,960 --> 00:23:11,280
illegal trans

00:23:08,159 --> 00:23:12,880
uh transition goes to the error state

00:23:11,280 --> 00:23:16,400
and there are too many arrows to draw

00:23:12,880 --> 00:23:20,320
that so they are there implicitly

00:23:16,400 --> 00:23:20,320
so how does this work

00:23:20,880 --> 00:23:25,679
well first let's take a brief glance at

00:23:23,760 --> 00:23:27,520
the basic algorithm just to have some

00:23:25,679 --> 00:23:31,360
context

00:23:27,520 --> 00:23:33,360
basically we get

00:23:31,360 --> 00:23:34,720
pointers to the beginningless stream of

00:23:33,360 --> 00:23:36,400
octet

00:23:34,720 --> 00:23:39,440
a pointer to the end of the stream of

00:23:36,400 --> 00:23:41,760
octet and we get a pointer to char 32

00:23:39,440 --> 00:23:44,480
and char 32 is what we use to represent

00:23:41,760 --> 00:23:47,360
the utf-32 code points

00:23:44,480 --> 00:23:47,840
so the stream of octets is called code

00:23:47,360 --> 00:23:51,919
units

00:23:47,840 --> 00:23:54,480
in utf-lango and the

00:23:51,919 --> 00:23:56,159
char 32 is the representation of the

00:23:54,480 --> 00:24:00,000
code points which are

00:23:56,159 --> 00:24:01,840
uh the actual the actual uh

00:24:00,000 --> 00:24:03,600
character values if you will that's not

00:24:01,840 --> 00:24:05,120
the right definition but that's the best

00:24:03,600 --> 00:24:07,919
i can do at the moment without

00:24:05,120 --> 00:24:09,679
doing the rest of the presentation so

00:24:07,919 --> 00:24:11,919
it's very basic algorithm

00:24:09,679 --> 00:24:13,120
we scan from beginning to end and we

00:24:11,919 --> 00:24:15,120
advance

00:24:13,120 --> 00:24:16,799
and assuming that we don't get an error

00:24:15,120 --> 00:24:19,440
we asse we assign a code

00:24:16,799 --> 00:24:20,960
the code point that we get that we

00:24:19,440 --> 00:24:23,360
return here we assign the code point

00:24:20,960 --> 00:24:25,039
into a destination array

00:24:23,360 --> 00:24:27,520
and we return the count of how many we

00:24:25,039 --> 00:24:29,840
decoded

00:24:27,520 --> 00:24:31,679
so advance looks like this and we'll

00:24:29,840 --> 00:24:33,360
actually step through it in a moment

00:24:31,679 --> 00:24:34,559
but advance is the thing that actually

00:24:33,360 --> 00:24:36,240
works its way through the state

00:24:34,559 --> 00:24:39,200
transition table and i have an example

00:24:36,240 --> 00:24:39,200
in a couple of slides

00:24:39,679 --> 00:24:45,440
so let's assume

00:24:43,760 --> 00:24:47,679
that we have we're going to do an

00:24:45,440 --> 00:24:48,159
example and we're going to decode this

00:24:47,679 --> 00:24:52,320
three

00:24:48,159 --> 00:24:55,600
octet sequence e2 888 and 85

00:24:52,320 --> 00:24:56,159
so we're in the begin state and we have

00:24:55,600 --> 00:24:59,279
our first

00:24:56,159 --> 00:25:00,080
octet e2 so you look at all the outgoing

00:24:59,279 --> 00:25:03,520
transitions

00:25:00,080 --> 00:25:05,440
and we see that e2 fits into

00:25:03,520 --> 00:25:08,559
these two character classes it's

00:25:05,440 --> 00:25:11,840
actually sits in this range

00:25:08,559 --> 00:25:13,360
okay so we've read e2 so how do we do

00:25:11,840 --> 00:25:15,840
the transition while we're going to

00:25:13,360 --> 00:25:20,000
advance

00:25:15,840 --> 00:25:21,679
so we're calling advance which means

00:25:20,000 --> 00:25:22,640
this is the beginning of an octet

00:25:21,679 --> 00:25:24,320
sequence

00:25:22,640 --> 00:25:26,799
and without showing you the rest of the

00:25:24,320 --> 00:25:29,120
implementation i'll ask you to trust me

00:25:26,799 --> 00:25:30,960
that there is a table for the first

00:25:29,120 --> 00:25:34,240
octet for any sequence that tells you

00:25:30,960 --> 00:25:37,279
exactly what the code point is

00:25:34,240 --> 00:25:40,480
and so uh

00:25:37,279 --> 00:25:43,039
you look into the table it tells you

00:25:40,480 --> 00:25:44,320
it returns a value that has two elements

00:25:43,039 --> 00:25:47,039
in it one

00:25:44,320 --> 00:25:47,919
is the first octet and it tells you what

00:25:47,039 --> 00:25:50,320
the code

00:25:47,919 --> 00:25:52,240
point the beginning code point is and

00:25:50,320 --> 00:25:54,960
then it tells you what the next state

00:25:52,240 --> 00:25:55,440
in the transition is going to be so the

00:25:54,960 --> 00:25:57,840
first

00:25:55,440 --> 00:25:59,440
state transition is special the the

00:25:57,840 --> 00:26:02,400
legal values of octets

00:25:59,440 --> 00:26:03,120
for the first octet in a sequence are

00:26:02,400 --> 00:26:05,120
different

00:26:03,120 --> 00:26:06,640
than the legal values for the second

00:26:05,120 --> 00:26:08,840
octet in a sequence

00:26:06,640 --> 00:26:10,000
second third and fourth octets in a

00:26:08,840 --> 00:26:15,039
sequence

00:26:10,000 --> 00:26:18,480
so in this particular case we've got e2

00:26:15,039 --> 00:26:20,960
and we are going to because uh the first

00:26:18,480 --> 00:26:23,440
three bits are one followed by zero

00:26:20,960 --> 00:26:24,000
we use the next set of bits to begin the

00:26:23,440 --> 00:26:26,480
code point

00:26:24,000 --> 00:26:28,799
so those we take that set of bits we put

00:26:26,480 --> 00:26:32,480
them in the low order bits of code point

00:26:28,799 --> 00:26:34,240
and we move on and we're now at eight

00:26:32,480 --> 00:26:37,279
eight by the way we've advanced to eight

00:26:34,240 --> 00:26:38,880
eight okay

00:26:37,279 --> 00:26:40,400
so we've gone through this state

00:26:38,880 --> 00:26:43,520
transition we're now in

00:26:40,400 --> 00:26:45,760
in continuation state two

00:26:43,520 --> 00:26:47,039
our input byte our look ahead token is

00:26:45,760 --> 00:26:50,320
eight eight

00:26:47,039 --> 00:26:52,640
and lo and behold a8 fits into

00:26:50,320 --> 00:26:54,880
the outgoing transition to continuation

00:26:52,640 --> 00:26:58,320
state one

00:26:54,880 --> 00:27:00,799
well we're still in advance

00:26:58,320 --> 00:27:02,000
so we haven't encountered an error yet

00:27:00,799 --> 00:27:05,120
and we still have

00:27:02,000 --> 00:27:07,279
input weighting so

00:27:05,120 --> 00:27:08,640
we're going to create a temporary code

00:27:07,279 --> 00:27:12,000
point

00:27:08,640 --> 00:27:13,760
which i just assigned which you just saw

00:27:12,000 --> 00:27:16,640
i'm going to take that code point and

00:27:13,760 --> 00:27:19,360
i'm going to shift it upward by 16 bits

00:27:16,640 --> 00:27:20,000
and then i'm sorry the unit is the code

00:27:19,360 --> 00:27:21,600
unit that i just

00:27:20,000 --> 00:27:23,520
read it's 88 so i'm going to take my

00:27:21,600 --> 00:27:24,080
existing code point shift it up by eight

00:27:23,520 --> 00:27:26,880
minute

00:27:24,080 --> 00:27:28,960
by six bits i'm going to mask off the

00:27:26,880 --> 00:27:32,880
lower six bits of my code unit

00:27:28,960 --> 00:27:34,960
and mask them into my code point

00:27:32,880 --> 00:27:36,559
then i'm going to effectively use the

00:27:34,960 --> 00:27:38,320
next two tables

00:27:36,559 --> 00:27:40,159
i'll use the next table to look up the

00:27:38,320 --> 00:27:41,039
type of the octet what is its character

00:27:40,159 --> 00:27:43,679
class

00:27:41,039 --> 00:27:44,960
and given the character class given the

00:27:43,679 --> 00:27:47,360
character class

00:27:44,960 --> 00:27:51,120
and the current value i can compute the

00:27:47,360 --> 00:27:51,120
state transition to the next state

00:27:51,600 --> 00:27:58,480
so i've taken my original code point

00:27:56,399 --> 00:28:00,080
i've shifted it up by six bits i've

00:27:58,480 --> 00:28:01,600
taken the lower six bits of my

00:28:00,080 --> 00:28:03,919
continuation octet

00:28:01,600 --> 00:28:06,720
and mask them into the lower six bits of

00:28:03,919 --> 00:28:06,720
my code point

00:28:07,360 --> 00:28:11,200
so i've moved into continuation state

00:28:09,520 --> 00:28:13,440
one

00:28:11,200 --> 00:28:14,640
my look ahead token the next octet is

00:28:13,440 --> 00:28:16,720
eight five

00:28:14,640 --> 00:28:18,399
and i have a transition out of that that

00:28:16,720 --> 00:28:20,640
takes me back to the begin state which

00:28:18,399 --> 00:28:24,640
is also the done state

00:28:20,640 --> 00:28:27,200
the valid done state so

00:28:24,640 --> 00:28:28,480
i do the same thing i get a value i

00:28:27,200 --> 00:28:31,279
extract the code unit

00:28:28,480 --> 00:28:33,039
from the array i take my current code

00:28:31,279 --> 00:28:35,039
point shift it up by 6

00:28:33,039 --> 00:28:37,760
mask in the lower 6 bits from my code

00:28:35,039 --> 00:28:39,200
unit i look up the character class

00:28:37,760 --> 00:28:41,360
add it to the current value and look

00:28:39,200 --> 00:28:41,840
that up in an array to tell me what the

00:28:41,360 --> 00:28:45,120
next

00:28:41,840 --> 00:28:46,960
state is and

00:28:45,120 --> 00:28:49,120
this is the result of that arithmetic

00:28:46,960 --> 00:28:50,159
i've now shifted my original four bits

00:28:49,120 --> 00:28:53,120
up by

00:28:50,159 --> 00:28:54,399
a total of 12. i've masked in the lower

00:28:53,120 --> 00:28:56,640
six bits from my next

00:28:54,399 --> 00:28:57,840
my first continuation byte and i've

00:28:56,640 --> 00:29:01,120
masked in the lower six

00:28:57,840 --> 00:29:02,559
bits from my third continuation byte

00:29:01,120 --> 00:29:04,880
and i'm back in the i'm back in the

00:29:02,559 --> 00:29:08,320
begin state which is also the done state

00:29:04,880 --> 00:29:11,679
so i return

00:29:08,320 --> 00:29:14,080
i return the value of the code point

00:29:11,679 --> 00:29:15,919
and in this case the code point is

00:29:14,080 --> 00:29:16,799
unicode they don't use hex they use

00:29:15,919 --> 00:29:19,200
unicode

00:29:16,799 --> 00:29:21,520
2205 which corresponds to the symbol for

00:29:19,200 --> 00:29:23,200
the empty set

00:29:21,520 --> 00:29:24,640
i assign my code point into my

00:29:23,200 --> 00:29:29,120
destination array

00:29:24,640 --> 00:29:30,880
and i go so when i was developing this

00:29:29,120 --> 00:29:32,559
i was looking at advance and i looked at

00:29:30,880 --> 00:29:35,279
this and i realized

00:29:32,559 --> 00:29:36,880
hey this first set of operations i need

00:29:35,279 --> 00:29:38,320
to do what if that what if the first

00:29:36,880 --> 00:29:40,480
octet is ascii

00:29:38,320 --> 00:29:42,080
this is an awful lot of work to do if i

00:29:40,480 --> 00:29:44,240
have an ascii octet

00:29:42,080 --> 00:29:45,120
to decode it through the table to run

00:29:44,240 --> 00:29:47,840
through this branch

00:29:45,120 --> 00:29:49,600
and then return if i don't know if i

00:29:47,840 --> 00:29:52,240
already know it's ascii if it's already

00:29:49,600 --> 00:29:55,840
asking why am i doing all this work

00:29:52,240 --> 00:29:59,120
so i changed the i changed the algorithm

00:29:55,840 --> 00:30:01,520
to check if the if the current octet the

00:29:59,120 --> 00:30:04,240
first octet in the sequence is ascii

00:30:01,520 --> 00:30:05,200
if it is ascii i just go ahead and

00:30:04,240 --> 00:30:06,640
assign it

00:30:05,200 --> 00:30:08,399
from the source array into the

00:30:06,640 --> 00:30:10,399
destination array of course this is 8

00:30:08,399 --> 00:30:11,360
byte unsigned and this is 32 byte

00:30:10,399 --> 00:30:14,880
unsigned

00:30:11,360 --> 00:30:16,399
so there is a unsigned integer promotion

00:30:14,880 --> 00:30:19,520
going on here

00:30:16,399 --> 00:30:21,600
but i've bypassed all of those lookups

00:30:19,520 --> 00:30:22,960
and just simply done an assignment i

00:30:21,600 --> 00:30:25,279
would have had to do a branch

00:30:22,960 --> 00:30:26,880
anyways in the previous uh in the

00:30:25,279 --> 00:30:28,480
previous implementation

00:30:26,880 --> 00:30:30,559
but i didn't have to do any table look

00:30:28,480 --> 00:30:32,799
up so this branch that i'm doing here is

00:30:30,559 --> 00:30:34,640
is not actually costing me anything and

00:30:32,799 --> 00:30:34,960
i'm saving the lookups in those tables

00:30:34,640 --> 00:30:37,840
and

00:30:34,960 --> 00:30:37,840
the point are arithmetic

00:30:38,480 --> 00:30:45,919
okay so

00:30:42,640 --> 00:30:46,480
the reason i did that is i was looking

00:30:45,919 --> 00:30:49,919
at

00:30:46,480 --> 00:30:52,799
several source files from uh

00:30:49,919 --> 00:30:54,960
wikipedia i had i had this notion that i

00:30:52,799 --> 00:30:55,840
wanted to write a json parser and to

00:30:54,960 --> 00:30:59,440
write js a

00:30:55,840 --> 00:31:00,799
valid json parser it has to it has to

00:30:59,440 --> 00:31:02,960
everything that it takes and it has to

00:31:00,799 --> 00:31:04,720
accept utf-8 and it works in terms of

00:31:02,960 --> 00:31:06,320
utf-32 and i thought well if i'm going

00:31:04,720 --> 00:31:07,440
to write a json parser i better learn

00:31:06,320 --> 00:31:10,799
how to do this

00:31:07,440 --> 00:31:14,399
utf-8 to utf-32 computation

00:31:10,799 --> 00:31:16,000
okay well where can i get some

00:31:14,399 --> 00:31:17,679
some things that have non-english

00:31:16,000 --> 00:31:19,519
characters in them the first thing that

00:31:17,679 --> 00:31:21,360
came to mind was wikipedia

00:31:19,519 --> 00:31:22,960
so i visited a bunch of wikipedia pages

00:31:21,360 --> 00:31:25,440
and i'll give you a list later

00:31:22,960 --> 00:31:26,880
that described various languages in

00:31:25,440 --> 00:31:28,240
those languages

00:31:26,880 --> 00:31:30,960
and i thought all right this would be a

00:31:28,240 --> 00:31:32,640
good source for testing utf decoder

00:31:30,960 --> 00:31:34,320
one of the things i noticed however when

00:31:32,640 --> 00:31:35,440
i was actually looking at the bytes in

00:31:34,320 --> 00:31:39,120
the file

00:31:35,440 --> 00:31:42,240
was that even for languages like korean

00:31:39,120 --> 00:31:43,840
or japanese or chinese which are

00:31:42,240 --> 00:31:45,360
have a lot of three bite sequences in

00:31:43,840 --> 00:31:47,679
them or

00:31:45,360 --> 00:31:49,440
eastern european languages that have two

00:31:47,679 --> 00:31:51,919
a lot of two-byte sequences in them

00:31:49,440 --> 00:31:53,360
there are still large runs of ascii

00:31:51,919 --> 00:31:55,200
character where you have a contiguous

00:31:53,360 --> 00:31:58,080
run of ascii characters

00:31:55,200 --> 00:31:58,960
uh in the html code and i thought well

00:31:58,080 --> 00:32:00,720
you know

00:31:58,960 --> 00:32:03,200
this is maybe i could optimize that and

00:32:00,720 --> 00:32:05,840
that led to the idea of the

00:32:03,200 --> 00:32:07,840
optimized ascii algorithm you just saw

00:32:05,840 --> 00:32:09,519
but realizing that there were so many

00:32:07,840 --> 00:32:11,519
opportunities for more optimization i

00:32:09,519 --> 00:32:14,000
thought well maybe i can do better with

00:32:11,519 --> 00:32:16,240
sse so that's what the next section is

00:32:14,000 --> 00:32:20,000
about

00:32:16,240 --> 00:32:20,000
so let's look at this case

00:32:20,640 --> 00:32:23,760
this is the algorithm that i mentioned

00:32:22,240 --> 00:32:29,840
before the improved

00:32:23,760 --> 00:32:29,840
ascii algorithm but can we do better

00:32:30,960 --> 00:32:34,320
well let's assume that we're going to

00:32:33,440 --> 00:32:36,399
read data

00:32:34,320 --> 00:32:38,000
one chunk at a time and for the sake of

00:32:36,399 --> 00:32:39,360
argument and for this this algorithm

00:32:38,000 --> 00:32:40,320
let's assume that we've got plenty of

00:32:39,360 --> 00:32:41,679
data

00:32:40,320 --> 00:32:44,080
in the destination array because we're

00:32:41,679 --> 00:32:46,559
not checking its bounds for now

00:32:44,080 --> 00:32:48,240
well if i've determined that the first

00:32:46,559 --> 00:32:50,559
byte in this sequence

00:32:48,240 --> 00:32:52,240
at the top of the loop is an ascii bite

00:32:50,559 --> 00:32:54,000
there's a good chance there's more ascii

00:32:52,240 --> 00:32:56,640
bytes that are coming after it

00:32:54,000 --> 00:32:58,960
if so why don't i try to convert those

00:32:56,640 --> 00:33:00,399
ascii bytes using ssc intrinsics

00:32:58,960 --> 00:33:03,039
so instead of just doing the direct

00:33:00,399 --> 00:33:05,519
assignment as before i'm going to try to

00:33:03,039 --> 00:33:07,200
do some work with intrinsics so i pass

00:33:05,519 --> 00:33:09,279
this inline function

00:33:07,200 --> 00:33:10,559
a pointer to the current pointer to the

00:33:09,279 --> 00:33:14,080
source and a

00:33:10,559 --> 00:33:17,919
pointer to the current destination

00:33:14,080 --> 00:33:19,360
and so this is an overview of what that

00:33:17,919 --> 00:33:22,399
function looks like and we'll go through

00:33:19,360 --> 00:33:22,399
it piece by piece

00:33:22,640 --> 00:33:30,159
so let's assume that i have this

00:33:25,760 --> 00:33:33,440
uh this input sequence

00:33:30,159 --> 00:33:34,000
greek word cause me i'm told that's how

00:33:33,440 --> 00:33:37,679
that's

00:33:34,000 --> 00:33:42,240
pronounced so when you

00:33:37,679 --> 00:33:45,919
take this these unicode

00:33:42,240 --> 00:33:46,480
utf sequences these code points that

00:33:45,919 --> 00:33:50,000
make this

00:33:46,480 --> 00:33:50,640
up and you unpack them into a utf-8

00:33:50,000 --> 00:33:53,600
stream

00:33:50,640 --> 00:33:55,200
this is what you get so the first 11

00:33:53,600 --> 00:33:58,240
characters here

00:33:55,200 --> 00:33:59,039
are all ascii so they all map to a

00:33:58,240 --> 00:34:02,240
single

00:33:59,039 --> 00:34:03,919
to a single byte or single octet but

00:34:02,240 --> 00:34:08,480
these greek characters

00:34:03,919 --> 00:34:13,040
map most of them mapped to 2 but

00:34:08,480 --> 00:34:17,119
this character maps to a 3 byte sequence

00:34:13,040 --> 00:34:20,320
so i've got 16

00:34:17,119 --> 00:34:23,520
i've got 16 different code points

00:34:20,320 --> 00:34:28,079
but they're actually mapped into 22

00:34:23,520 --> 00:34:30,800
code units 22 octets or is it more

00:34:28,079 --> 00:34:32,079
no it's more than that okay anyway it's

00:34:30,800 --> 00:34:34,000
not a one-to-one mapping

00:34:32,079 --> 00:34:35,280
so what we're going to do is see if we

00:34:34,000 --> 00:34:38,399
can snag these

00:34:35,280 --> 00:34:41,040
first 11 ascii characters and as

00:34:38,399 --> 00:34:42,879
again as i mentioned before uh my

00:34:41,040 --> 00:34:44,399
convention is least significant

00:34:42,879 --> 00:34:48,800
bite or bit on the left and most

00:34:44,399 --> 00:34:51,520
significant bite or bit on the right

00:34:48,800 --> 00:34:54,639
so here are some sse registers except

00:34:51,520 --> 00:34:56,159
these are 128 bits and not 512.

00:34:54,639 --> 00:34:59,680
i've got a couple of variables that i'm

00:34:56,159 --> 00:34:59,680
going to use to hold some data

00:34:59,839 --> 00:35:02,880
one is a bit mask and one measures how

00:35:02,240 --> 00:35:04,480
far to

00:35:02,880 --> 00:35:06,079
increment how far to advance the

00:35:04,480 --> 00:35:07,599
destination pointer

00:35:06,079 --> 00:35:09,359
so the first thing i'm going to do is i

00:35:07,599 --> 00:35:11,440
have this zero register which i'm going

00:35:09,359 --> 00:35:14,720
to use for interleaving data

00:35:11,440 --> 00:35:18,880
i'm going to fill that with zeros

00:35:14,720 --> 00:35:21,839
now i'm going to load 128 bits

00:35:18,880 --> 00:35:24,720
16 bytes into this register that i call

00:35:21,839 --> 00:35:27,680
chunk it's a chunk of data

00:35:24,720 --> 00:35:28,800
so there i've taken memory here

00:35:27,680 --> 00:35:30,800
represented in gray

00:35:28,800 --> 00:35:34,400
i've called the load intrinsic and i've

00:35:30,800 --> 00:35:35,599
loaded into my chunk register

00:35:34,400 --> 00:35:37,839
now i'm going to call this weird

00:35:35,599 --> 00:35:41,200
function called move mask

00:35:37,839 --> 00:35:43,760
to find which bits in the

00:35:41,200 --> 00:35:45,520
which octets in this register have their

00:35:43,760 --> 00:35:47,760
highest bit set

00:35:45,520 --> 00:35:49,359
if the highest bit in an octet is set it

00:35:47,760 --> 00:35:51,520
is not an ascii bit

00:35:49,359 --> 00:35:53,920
to be ascii it has to be less than eight

00:35:51,520 --> 00:35:57,119
zero

00:35:53,920 --> 00:35:57,680
so when i call move mask what it does is

00:35:57,119 --> 00:36:00,240
it looks

00:35:57,680 --> 00:36:01,040
and it says all right well these first

00:36:00,240 --> 00:36:04,800
these first

00:36:01,040 --> 00:36:08,079
11 values are all less than

00:36:04,800 --> 00:36:10,880
eight zero they're ascii whereas

00:36:08,079 --> 00:36:11,520
the next five values all have the next

00:36:10,880 --> 00:36:13,839
five

00:36:11,520 --> 00:36:16,160
uh octets all have values that are

00:36:13,839 --> 00:36:18,720
greater than or equal to eight zero

00:36:16,160 --> 00:36:21,280
so here i get a sequence of eleven zeros

00:36:18,720 --> 00:36:24,880
in my bit mask followed by five ones

00:36:21,280 --> 00:36:28,240
indicating 11 ascii octets and

00:36:24,880 --> 00:36:31,680
five non-ascii octets so this mask is

00:36:28,240 --> 00:36:31,680
important we'll use it later

00:36:32,240 --> 00:36:36,800
so what i do then is there are these

00:36:34,079 --> 00:36:40,079
instructions called unpack low and high

00:36:36,800 --> 00:36:44,079
uh to unpack eight

00:36:40,079 --> 00:36:47,520
eight bytes or eight bits into sixteen

00:36:44,079 --> 00:36:48,400
so what i do is i'm taking the the lower

00:36:47,520 --> 00:36:51,119
eight bytes

00:36:48,400 --> 00:36:52,720
of my chunk register i'm unpacking and

00:36:51,119 --> 00:36:55,280
interleaving it with values from the

00:36:52,720 --> 00:36:57,680
zero register and i call this half

00:36:55,280 --> 00:36:59,680
because i'm halfway there so i've

00:36:57,680 --> 00:37:00,960
effectively zero padded each of these

00:36:59,680 --> 00:37:03,839
ascii bytes

00:37:00,960 --> 00:37:05,359
so these are now 16 bits wide or two

00:37:03,839 --> 00:37:07,119
bytes

00:37:05,359 --> 00:37:10,720
the next thing i do is i do the same

00:37:07,119 --> 00:37:10,720
thing again i unpack

00:37:10,800 --> 00:37:13,599
the lower half

00:37:13,839 --> 00:37:20,160
of what i had before and

00:37:17,920 --> 00:37:22,400
i fill in what it does is it fills in

00:37:20,160 --> 00:37:23,520
zeros in the second part of that so here

00:37:22,400 --> 00:37:26,800
i'm taking

00:37:23,520 --> 00:37:30,400
the lower four units these four

00:37:26,800 --> 00:37:32,160
and i'm unpacking these into 16 bit

00:37:30,400 --> 00:37:34,000
16 bit units and interleaving those

00:37:32,160 --> 00:37:35,920
zeros so i get to quarter

00:37:34,000 --> 00:37:37,839
i'm a quarter of the way done and now i

00:37:35,920 --> 00:37:39,680
have 32-bit

00:37:37,839 --> 00:37:41,119
unsigned 32-bit quantities that

00:37:39,680 --> 00:37:44,400
represent ascii numbers

00:37:41,119 --> 00:37:46,000
that are correctly zero padded then i'm

00:37:44,400 --> 00:37:49,119
going to write that out to data

00:37:46,000 --> 00:37:50,960
pdest so i write my first four code

00:37:49,119 --> 00:37:52,480
units

00:37:50,960 --> 00:37:54,400
i'm going to go through the unpacking

00:37:52,480 --> 00:37:56,079
exercise again except i'm going to start

00:37:54,400 --> 00:37:59,839
with the high

00:37:56,079 --> 00:38:01,599
eight units of half and i unpack them

00:37:59,839 --> 00:38:05,040
and interleave them with zeros

00:38:01,599 --> 00:38:06,320
and i get the next four code points

00:38:05,040 --> 00:38:08,560
and i'm going to write those out to

00:38:06,320 --> 00:38:11,680
memory so i wrote those write those out

00:38:08,560 --> 00:38:14,160
to p desk plus 4.

00:38:11,680 --> 00:38:16,720
then i go through the sequence again of

00:38:14,160 --> 00:38:20,160
unpacking

00:38:16,720 --> 00:38:21,839
the upper half of chunk

00:38:20,160 --> 00:38:23,520
so here's the upper half of chunk i'm

00:38:21,839 --> 00:38:28,240
unpacking high

00:38:23,520 --> 00:38:30,880
i unpack and interleave zeros with that

00:38:28,240 --> 00:38:34,720
i do it again to get the first the next

00:38:30,880 --> 00:38:37,280
four code units in the register quarter

00:38:34,720 --> 00:38:38,079
i store those out to p desk plus eight

00:38:37,280 --> 00:38:40,880
so

00:38:38,079 --> 00:38:43,359
i've now i've stored 12 code points in

00:38:40,880 --> 00:38:46,400
my destination array

00:38:43,359 --> 00:38:49,440
i do the final unpacking from the

00:38:46,400 --> 00:38:51,599
upper half of the register i call half

00:38:49,440 --> 00:38:52,880
unpack it into my quarter register again

00:38:51,599 --> 00:38:56,079
interleaving zeros

00:38:52,880 --> 00:38:59,599
to zero extend the last four octets into

00:38:56,079 --> 00:39:03,040
four code units i write that out

00:38:59,599 --> 00:39:03,760
and now i've written 16 code units to

00:39:03,040 --> 00:39:05,839
memory

00:39:03,760 --> 00:39:07,280
and this is underlying assumption that

00:39:05,839 --> 00:39:10,000
there's enough memory to do this that

00:39:07,280 --> 00:39:12,880
i'm not going past the end

00:39:10,000 --> 00:39:14,640
all right great well i've written 16 but

00:39:12,880 --> 00:39:18,240
i know that only 11 of them

00:39:14,640 --> 00:39:19,280
11 of them are actually valid uh ascii

00:39:18,240 --> 00:39:21,040
characters

00:39:19,280 --> 00:39:22,960
how do i figure out how to do how do i

00:39:21,040 --> 00:39:26,240
figure out how to adjust my

00:39:22,960 --> 00:39:26,720
destination pointer well the next thing

00:39:26,240 --> 00:39:28,160
you do

00:39:26,720 --> 00:39:29,839
is i look at that mask that we

00:39:28,160 --> 00:39:32,480
calculated before

00:39:29,839 --> 00:39:34,079
and if the mask was zero that meant that

00:39:32,480 --> 00:39:36,480
no bits were set in the mask

00:39:34,079 --> 00:39:38,640
and all code units were ascii and i can

00:39:36,480 --> 00:39:40,800
just advance my source and destination

00:39:38,640 --> 00:39:43,920
pointers by 16 and move on

00:39:40,800 --> 00:39:46,480
but in this case the mask was not zero

00:39:43,920 --> 00:39:47,680
the mask had some ones in it so we call

00:39:46,480 --> 00:39:49,359
another intrinsic

00:39:47,680 --> 00:39:50,720
a function i wrap called get trailing

00:39:49,359 --> 00:39:52,480
zeros that

00:39:50,720 --> 00:39:53,920
calls different built-ins on different

00:39:52,480 --> 00:39:56,480
compilers uh

00:39:53,920 --> 00:39:57,760
on linux it's and with clang and gcc

00:39:56,480 --> 00:40:00,800
it's built in

00:39:57,760 --> 00:40:03,839
uh count trailing zeros

00:40:00,800 --> 00:40:05,520
and on windows it's bit scan forward but

00:40:03,839 --> 00:40:06,880
basically what these things do is they

00:40:05,520 --> 00:40:08,640
start at the lower bit

00:40:06,880 --> 00:40:11,839
and they count the number of zeros until

00:40:08,640 --> 00:40:11,839
they come to a one

00:40:12,000 --> 00:40:15,839
so in this case it's going to count

00:40:14,000 --> 00:40:17,839
eleven zeros

00:40:15,839 --> 00:40:19,760
so this increment value that i mentioned

00:40:17,839 --> 00:40:22,400
before is eleven

00:40:19,760 --> 00:40:23,599
so that means that i can increment my

00:40:22,400 --> 00:40:26,079
source pointer

00:40:23,599 --> 00:40:26,640
by 11 to get to the next the first

00:40:26,079 --> 00:40:28,319
offset

00:40:26,640 --> 00:40:29,760
the first octet in the next sequence

00:40:28,319 --> 00:40:32,480
that's not ascii

00:40:29,760 --> 00:40:34,480
and i can adjust my destination pointer

00:40:32,480 --> 00:40:36,000
add 11 to it so now i'm pointing at the

00:40:34,480 --> 00:40:38,720
next location in memory

00:40:36,000 --> 00:40:41,280
to which i will write more code points

00:40:38,720 --> 00:40:41,280
in the future

00:40:41,599 --> 00:40:46,240
so i'm done converting and at that point

00:40:43,680 --> 00:40:49,440
i drop into the advance

00:40:46,240 --> 00:40:50,319
i come back out of the loop i know that

00:40:49,440 --> 00:40:52,400
my next

00:40:50,319 --> 00:40:53,440
octet is not ascii so i'm going to fall

00:40:52,400 --> 00:40:54,640
into advance

00:40:53,440 --> 00:40:56,240
and then i'll walk through the state

00:40:54,640 --> 00:40:59,280
machine in the same way that i did when

00:40:56,240 --> 00:41:03,680
i showed you the basic algorithm

00:40:59,280 --> 00:41:05,359
okay so that works pretty well

00:41:03,680 --> 00:41:10,000
so i started thinking can i make it even

00:41:05,359 --> 00:41:10,000
faster with avx-2 or avx-512

00:41:10,079 --> 00:41:17,280
so now i'm going to i'm going to write

00:41:13,359 --> 00:41:18,720
this function convert ascii with avx

00:41:17,280 --> 00:41:20,640
and this for me turned out to be one of

00:41:18,720 --> 00:41:24,000
those rare cases where

00:41:20,640 --> 00:41:25,760
i made the function inline but i got

00:41:24,000 --> 00:41:26,880
better performance by actually putting

00:41:25,760 --> 00:41:29,200
the code itself

00:41:26,880 --> 00:41:30,160
in line where i would have called the

00:41:29,200 --> 00:41:32,000
function

00:41:30,160 --> 00:41:33,920
so i'm effectively treating this like

00:41:32,000 --> 00:41:36,800
it's a macro so i'm going to show you

00:41:33,920 --> 00:41:36,800
what that looks like

00:41:37,680 --> 00:41:42,400
so here's my p source all right now i'm

00:41:40,240 --> 00:41:45,839
going to expand this macro

00:41:42,400 --> 00:41:48,079
here's p source and here's the code

00:41:45,839 --> 00:41:49,839
i've got the mask in the increment again

00:41:48,079 --> 00:41:51,520
i've got my chunk register

00:41:49,839 --> 00:41:53,440
i've got another register that i call

00:41:51,520 --> 00:41:56,319
half but this register

00:41:53,440 --> 00:41:58,160
is an avx avx2 register it's twice as

00:41:56,319 --> 00:42:01,359
wide

00:41:58,160 --> 00:42:04,560
so i'm going to

00:42:01,359 --> 00:42:05,760
load the same 16 bytes of data into

00:42:04,560 --> 00:42:08,079
chunk

00:42:05,760 --> 00:42:10,240
so there's my memory location i'm

00:42:08,079 --> 00:42:13,440
loading it into chunk

00:42:10,240 --> 00:42:14,640
and now i'm going to zero extend in one

00:42:13,440 --> 00:42:17,920
instruction

00:42:14,640 --> 00:42:21,359
the lower eight octets in chunk

00:42:17,920 --> 00:42:23,280
and this uh instruction from uh

00:42:21,359 --> 00:42:25,520
the avx two and transits will do that in

00:42:23,280 --> 00:42:29,520
one shot there's no need to unpack an

00:42:25,520 --> 00:42:32,880
interleave you just do it in one shot

00:42:29,520 --> 00:42:35,520
so i call that with the

00:42:32,880 --> 00:42:36,560
uh with chunk it takes the lower eight

00:42:35,520 --> 00:42:38,960
bytes

00:42:36,560 --> 00:42:39,599
and it unpacks them in one shot into

00:42:38,960 --> 00:42:41,040
half

00:42:39,599 --> 00:42:43,359
and here because i didn't have room on

00:42:41,040 --> 00:42:46,000
the screen i've i've drawn half

00:42:43,359 --> 00:42:47,839
which is which is 32 bytes wide in the

00:42:46,000 --> 00:42:50,400
rows of two so this is

00:42:47,839 --> 00:42:52,160
this is the least significant byte and

00:42:50,400 --> 00:42:54,079
this is the most significant byte but if

00:42:52,160 --> 00:42:56,560
you look at the pattern here

00:42:54,079 --> 00:42:59,119
you can see that they've been uh they've

00:42:56,560 --> 00:43:03,040
been zero padded

00:42:59,119 --> 00:43:05,920
then i store that to memory

00:43:03,040 --> 00:43:07,680
so i write that out so i'm writing out

00:43:05,920 --> 00:43:09,200
and here i'm drawing the whole buffer

00:43:07,680 --> 00:43:11,680
so i'm writing out the first eight

00:43:09,200 --> 00:43:13,359
octets

00:43:11,680 --> 00:43:15,200
and at this point i found that it was

00:43:13,359 --> 00:43:18,400
fastest to compute that mask

00:43:15,200 --> 00:43:22,800
move mask at this point so

00:43:18,400 --> 00:43:24,640
i do it i compute the mask

00:43:22,800 --> 00:43:26,000
and now i'm going to shuffle the bytes

00:43:24,640 --> 00:43:28,720
that are in chunk

00:43:26,000 --> 00:43:30,400
i'm going to swap the lower eight bytes

00:43:28,720 --> 00:43:32,480
with the upper eight bytes

00:43:30,400 --> 00:43:34,319
so there's a macro which creates a bit

00:43:32,480 --> 00:43:36,640
mask which you can passes and try

00:43:34,319 --> 00:43:38,319
intrinsic which will do that shuffling

00:43:36,640 --> 00:43:39,680
so here i've done the shuffling

00:43:38,319 --> 00:43:41,040
you can see i've taken the upper eight

00:43:39,680 --> 00:43:43,839
bytes and moved them down here in the

00:43:41,040 --> 00:43:46,640
lower eight bytes and moved them up here

00:43:43,839 --> 00:43:47,760
i'm going to do the same zero extension

00:43:46,640 --> 00:43:50,000
that i did before

00:43:47,760 --> 00:43:51,440
into the half register except now it's

00:43:50,000 --> 00:43:53,200
with the bytes that were originally in

00:43:51,440 --> 00:43:55,839
the upper half

00:43:53,200 --> 00:43:57,839
and i'm going to store in the next

00:43:55,839 --> 00:44:01,280
locations

00:43:57,839 --> 00:44:04,480
so i've written the same 18 or the same

00:44:01,280 --> 00:44:06,160
16 code points to memory as i did before

00:44:04,480 --> 00:44:07,599
but i've used fewer intrinsic

00:44:06,160 --> 00:44:09,119
instructions to do it

00:44:07,599 --> 00:44:10,720
and the question is will i get better

00:44:09,119 --> 00:44:13,680
performance if i'm not doing as much

00:44:10,720 --> 00:44:16,079
work with registers

00:44:13,680 --> 00:44:18,160
once again i use the mask to get the

00:44:16,079 --> 00:44:21,359
trailing zero count

00:44:18,160 --> 00:44:25,280
which is 11 and i adjust my input

00:44:21,359 --> 00:44:26,560
and my output pointers accordingly

00:44:25,280 --> 00:44:28,640
and then i go back to the top of the

00:44:26,560 --> 00:44:31,200
loop i know that it's not an ascii byte

00:44:28,640 --> 00:44:35,680
next and i drop into advanced to do the

00:44:31,200 --> 00:44:38,480
dfa based computation

00:44:35,680 --> 00:44:39,920
so how fast is this that i get any

00:44:38,480 --> 00:44:41,760
performance benefit

00:44:39,920 --> 00:44:43,040
well let's look at some testing and i

00:44:41,760 --> 00:44:46,480
actually end up just extending the

00:44:43,040 --> 00:44:46,480
testing that i did two years ago

00:44:47,440 --> 00:44:50,560
i've improved the compilers though i

00:44:49,920 --> 00:44:53,040
actually

00:44:50,560 --> 00:44:55,119
did the most of this work before i built

00:44:53,040 --> 00:44:57,280
uh gcc 10 for myself so i did it with

00:44:55,119 --> 00:45:00,640
gcc 93

00:44:57,280 --> 00:45:03,680
and these were all built on ubuntu 1804

00:45:00,640 --> 00:45:05,040
on a core i9 a machine that i have that

00:45:03,680 --> 00:45:07,920
i own

00:45:05,040 --> 00:45:08,400
and all the code was compiled -03 with

00:45:07,920 --> 00:45:12,240
the

00:45:08,400 --> 00:45:15,599
uh with the avx-2 intrinsics enabled

00:45:12,240 --> 00:45:18,880
and uh curiously uh

00:45:15,599 --> 00:45:20,960
and i'm not an expert at gcc flags but

00:45:18,880 --> 00:45:23,040
the lowest architecture i could find in

00:45:20,960 --> 00:45:25,839
the gcc man page that supported

00:45:23,040 --> 00:45:28,880
machine type of avx-2 was skylink so i

00:45:25,839 --> 00:45:28,880
turned on skylake

00:45:29,040 --> 00:45:33,040
i also ran it on the same same machine

00:45:32,000 --> 00:45:35,599
running windows

00:45:33,040 --> 00:45:37,119
using visual studio a very recent

00:45:35,599 --> 00:45:39,760
version of visual studio to do the

00:45:37,119 --> 00:45:39,760
compilation

00:45:40,640 --> 00:45:45,040
so i mentioned before that i had

00:45:43,520 --> 00:45:46,640
gathered these input data files and

00:45:45,040 --> 00:45:48,000
these are the same files that i used two

00:45:46,640 --> 00:45:50,560
years ago

00:45:48,000 --> 00:45:52,400
i have a wikipedia entry in english a

00:45:50,560 --> 00:45:55,839
wikipedia entry in chinese

00:45:52,400 --> 00:45:56,480
in chinese a wikipedia entry about hindi

00:45:55,839 --> 00:45:58,160
in hindi

00:45:56,480 --> 00:46:01,200
portuguese and portuguese russian and

00:45:58,160 --> 00:46:03,760
russian and so forth

00:46:01,200 --> 00:46:05,680
i also have three stress tests stress

00:46:03,760 --> 00:46:06,480
test zero one and two the first stress

00:46:05,680 --> 00:46:08,800
test

00:46:06,480 --> 00:46:10,160
has a hundred thousand ascii code points

00:46:08,800 --> 00:46:12,000
in it that's all

00:46:10,160 --> 00:46:13,839
it's effectively a no stress test

00:46:12,000 --> 00:46:15,599
because there are no multibyte sequences

00:46:13,839 --> 00:46:19,040
yet

00:46:15,599 --> 00:46:22,560
the second stress test is one where

00:46:19,040 --> 00:46:23,440
every uh every sequence is a three byte

00:46:22,560 --> 00:46:25,920
sequence

00:46:23,440 --> 00:46:27,599
so there's a hundred thousand chinese

00:46:25,920 --> 00:46:29,760
code points from chinese

00:46:27,599 --> 00:46:30,800
there are three code units per code

00:46:29,760 --> 00:46:33,839
point so there are

00:46:30,800 --> 00:46:36,720
300 000 code units 300 kilobytes

00:46:33,839 --> 00:46:38,880
and finally stress test 2 where i had 50

00:46:36,720 --> 00:46:40,000
000 chinese code points interleaved with

00:46:38,880 --> 00:46:41,920
50 000

00:46:40,000 --> 00:46:43,359
ascii code points so there would be a

00:46:41,920 --> 00:46:45,520
three point chinese code

00:46:43,359 --> 00:46:46,560
a three unit chinese code point followed

00:46:45,520 --> 00:46:49,119
by an ascii

00:46:46,560 --> 00:46:50,640
code point followed by the same thing

00:46:49,119 --> 00:46:54,240
repeating over and over again

00:46:50,640 --> 00:46:54,240
and this is really a torture test

00:46:55,040 --> 00:46:59,680
so i wanted to compare my conversion

00:46:58,000 --> 00:47:03,359
against other libraries so i

00:46:59,680 --> 00:47:04,720
used icon from the gnu library which

00:47:03,359 --> 00:47:06,079
i consider to be the gold standard

00:47:04,720 --> 00:47:08,160
because everybody seems to refer to it

00:47:06,079 --> 00:47:09,760
and it seems to get things right

00:47:08,160 --> 00:47:11,599
i'm sure perhaps some utf and

00:47:09,760 --> 00:47:13,440
internationalization experts would

00:47:11,599 --> 00:47:16,079
would disagree with me but seemed like a

00:47:13,440 --> 00:47:17,839
reasonable choice

00:47:16,079 --> 00:47:19,920
there were utf conversion functions that

00:47:17,839 --> 00:47:21,760
were part of the llvm distribution that

00:47:19,920 --> 00:47:24,160
go into clang

00:47:21,760 --> 00:47:25,760
there was a an implementation by a

00:47:24,160 --> 00:47:28,559
gentleman named alexi pachenko that

00:47:25,760 --> 00:47:30,640
converted utf-8 to 32

00:47:28,559 --> 00:47:32,559
i used stood code convert from the

00:47:30,640 --> 00:47:33,920
standard libraries utf implementation

00:47:32,559 --> 00:47:38,720
which will also do this

00:47:33,920 --> 00:47:40,240
albeit very slowly i use boost.text

00:47:38,720 --> 00:47:43,200
although this is the same version of

00:47:40,240 --> 00:47:45,920
boost.text that i used two years ago

00:47:43,200 --> 00:47:48,079
uh zach lane has recently greatly

00:47:45,920 --> 00:47:48,640
improved the performance of boost.text

00:47:48,079 --> 00:47:51,040
so

00:47:48,640 --> 00:47:52,800
don't pay much attention to that column

00:47:51,040 --> 00:47:54,720
in this presentation

00:47:52,800 --> 00:47:56,079
didn't have time to integrate his code

00:47:54,720 --> 00:47:58,640
and make it work

00:47:56,079 --> 00:48:00,079
but because i used it previously i

00:47:58,640 --> 00:48:04,240
decided to include it

00:48:00,079 --> 00:48:06,800
in this one there's an alternative

00:48:04,240 --> 00:48:08,079
dfa implementation by a gentleman named

00:48:06,800 --> 00:48:09,359
jiren hermann

00:48:08,079 --> 00:48:12,160
and this was part of my original

00:48:09,359 --> 00:48:14,800
presentation and he actually derived

00:48:12,160 --> 00:48:17,200
uh we derived the dfa independently but

00:48:14,800 --> 00:48:18,800
he did it 10 years before i did

00:48:17,200 --> 00:48:20,400
and i found it after i'd already done

00:48:18,800 --> 00:48:23,599
all the work and sort of hit myself in

00:48:20,400 --> 00:48:25,599
the head for wasting so much time

00:48:23,599 --> 00:48:27,440
so the timings are what you might expect

00:48:25,599 --> 00:48:29,520
i read the input file i create the

00:48:27,440 --> 00:48:30,559
output buffer i start a timer i enter

00:48:29,520 --> 00:48:32,400
loop

00:48:30,559 --> 00:48:34,000
i perform the conversion on the buffer

00:48:32,400 --> 00:48:37,200
multiple times the idea

00:48:34,000 --> 00:48:38,720
is the number of repetitions regardless

00:48:37,200 --> 00:48:39,359
of the size of the buffer should be

00:48:38,720 --> 00:48:41,760
about

00:48:39,359 --> 00:48:43,040
one gigabyte of input text that's what i

00:48:41,760 --> 00:48:45,280
was going for

00:48:43,040 --> 00:48:47,599
exit the timing loop stop the timer

00:48:45,280 --> 00:48:50,480
collect and collate the results

00:48:47,599 --> 00:48:53,599
to pass every library had to agree with

00:48:50,480 --> 00:48:56,160
icon that in fact they did

00:48:53,599 --> 00:48:58,559
so let's look at some timings here i've

00:48:56,160 --> 00:49:01,599
got the timings for gcc 93 on

00:48:58,559 --> 00:49:03,680
ubuntu 1804 and

00:49:01,599 --> 00:49:04,800
uh along the bottom here are the color

00:49:03,680 --> 00:49:08,000
codings

00:49:04,800 --> 00:49:11,040
uh i you've got icom llvm

00:49:08,000 --> 00:49:13,440
alexi vichenkos stood code convert

00:49:11,040 --> 00:49:14,720
you've got boost.text you've got bjorn

00:49:13,440 --> 00:49:17,200
hermann's

00:49:14,720 --> 00:49:19,280
implementation and then you've got my4

00:49:17,200 --> 00:49:22,480
the basic ascii

00:49:19,280 --> 00:49:23,520
the improved ascii the ascii improved

00:49:22,480 --> 00:49:26,559
with sse

00:49:23,520 --> 00:49:28,400
and the ascii improved with avx2

00:49:26,559 --> 00:49:30,880
so you can see in the case of english

00:49:28,400 --> 00:49:32,400
where it was all ascii code points

00:49:30,880 --> 00:49:35,359
it was quite a bit faster it was

00:49:32,400 --> 00:49:39,280
probably you know it ran in about

00:49:35,359 --> 00:49:41,839
62 percent of the time of the sse

00:49:39,280 --> 00:49:44,160
based solution however when you start

00:49:41,839 --> 00:49:45,440
getting to large multi-byte sequences on

00:49:44,160 --> 00:49:48,880
gcc

00:49:45,440 --> 00:49:52,160
the performance delta is it goes

00:49:48,880 --> 00:49:54,880
very close the delta is almost zero

00:49:52,160 --> 00:49:56,640
and here for chinese and hindi there's

00:49:54,880 --> 00:49:58,319
effectively no difference in performance

00:49:56,640 --> 00:50:01,760
and in fact with hindi the avx-2

00:49:58,319 --> 00:50:04,240
implementation was a little bit worse

00:50:01,760 --> 00:50:04,880
if we look at portuguese russian and

00:50:04,240 --> 00:50:07,119
swedish

00:50:04,880 --> 00:50:08,720
portuguese and swedish have a lot of two

00:50:07,119 --> 00:50:10,480
byte sequences russian has a lot of

00:50:08,720 --> 00:50:12,240
three byte sequences in it

00:50:10,480 --> 00:50:13,280
so for the two byte sequences we see a

00:50:12,240 --> 00:50:15,040
little bit of improvement with

00:50:13,280 --> 00:50:16,800
portuguese and swedish

00:50:15,040 --> 00:50:20,400
we see worse performance actually with

00:50:16,800 --> 00:50:22,480
russian with three byte sequences

00:50:20,400 --> 00:50:25,119
for our torture tests i think this is

00:50:22,480 --> 00:50:28,240
very interesting for the torture test

00:50:25,119 --> 00:50:30,160
the performance with the sse and avx for

00:50:28,240 --> 00:50:32,400
a hundred thousand ascii bytes was

00:50:30,160 --> 00:50:34,559
exactly identical it never differed on

00:50:32,400 --> 00:50:38,079
gcc

00:50:34,559 --> 00:50:40,319
however when it came to the

00:50:38,079 --> 00:50:42,480
when it came to stress test one which is

00:50:40,319 --> 00:50:44,880
all chinese code points

00:50:42,480 --> 00:50:46,960
both the ssc and the avx based

00:50:44,880 --> 00:50:49,680
approaches were faster

00:50:46,960 --> 00:50:51,440
uh than the improved ascii approach but

00:50:49,680 --> 00:50:52,960
they were still not as fast as the basic

00:50:51,440 --> 00:50:55,040
approach remember the basic approach

00:50:52,960 --> 00:50:55,599
just went into the dfa every time it was

00:50:55,040 --> 00:50:57,200
not

00:50:55,599 --> 00:50:59,200
doing that extra branch to check for

00:50:57,200 --> 00:51:00,319
ascii so in the case where there was no

00:50:59,200 --> 00:51:03,119
ascii

00:51:00,319 --> 00:51:05,200
it was always fastest but avx was

00:51:03,119 --> 00:51:07,280
actually worse than ssc

00:51:05,200 --> 00:51:08,480
and then on the case of the interleave

00:51:07,280 --> 00:51:10,640
chinese and

00:51:08,480 --> 00:51:14,319
ascii code points there was effectively

00:51:10,640 --> 00:51:16,960
no difference between the avx and

00:51:14,319 --> 00:51:19,040
ssc implementations so this was the

00:51:16,960 --> 00:51:20,880
behavior on gcc

00:51:19,040 --> 00:51:22,400
and it's very strange i think relative

00:51:20,880 --> 00:51:27,599
to the behavior that i observed

00:51:22,400 --> 00:51:30,800
with clang and with microsoft's compiler

00:51:27,599 --> 00:51:35,119
now here are the same graphs same data

00:51:30,800 --> 00:51:37,839
same machine run on the same day

00:51:35,119 --> 00:51:39,359
and here the performance improvement

00:51:37,839 --> 00:51:42,880
when going to the avx

00:51:39,359 --> 00:51:45,119
based implementation is

00:51:42,880 --> 00:51:48,079
is actually significant for all

00:51:45,119 --> 00:51:51,680
languages in fact you can see here

00:51:48,079 --> 00:51:52,240
for the english wiki that the avx-based

00:51:51,680 --> 00:51:55,119
approach

00:51:52,240 --> 00:51:56,480
on clang is almost exactly as fast as

00:51:55,119 --> 00:52:00,240
the avx-based approach

00:51:56,480 --> 00:52:01,760
with gcc uh but the important thing is

00:52:00,240 --> 00:52:04,079
that if you're using clang there is a

00:52:01,760 --> 00:52:06,800
performance benefit here we see it for

00:52:04,079 --> 00:52:08,880
english for three bite units for chinese

00:52:06,800 --> 00:52:10,800
three bite sequences for chinese and

00:52:08,880 --> 00:52:12,960
hindi

00:52:10,800 --> 00:52:14,559
we see a big speed up for portuguese we

00:52:12,960 --> 00:52:15,839
see a big speed up for swedish with

00:52:14,559 --> 00:52:18,000
their two bite sequences

00:52:15,839 --> 00:52:20,480
we still see a reasonable speed up for

00:52:18,000 --> 00:52:22,880
russian with its three bite sequences

00:52:20,480 --> 00:52:24,720
and we go to the torture tests well of

00:52:22,880 --> 00:52:27,440
course with the ascii torture test we do

00:52:24,720 --> 00:52:29,680
better we do twice as fast

00:52:27,440 --> 00:52:31,520
there is really no difference here at

00:52:29,680 --> 00:52:33,920
all between avx and

00:52:31,520 --> 00:52:34,880
sse with the fully chinese and the

00:52:33,920 --> 00:52:38,640
chinese

00:52:34,880 --> 00:52:40,640
ascii interleave i don't understand

00:52:38,640 --> 00:52:42,079
why i have this performance difference

00:52:40,640 --> 00:52:45,440
here for the

00:52:42,079 --> 00:52:46,880
improved basic approach i have to go

00:52:45,440 --> 00:52:49,280
back and dig into that that's

00:52:46,880 --> 00:52:51,680
one inconsistency i found with compiling

00:52:49,280 --> 00:52:53,920
with clang

00:52:51,680 --> 00:52:55,359
i saw similar sorts of results not quite

00:52:53,920 --> 00:52:58,160
as big of improvement but with

00:52:55,359 --> 00:52:59,680
visual studio so here running on visual

00:52:58,160 --> 00:53:02,960
studio i see about

00:52:59,680 --> 00:53:03,520
a 10 difference in everything so about a

00:53:02,960 --> 00:53:06,000
00:53:03,520 --> 00:53:07,280
difference here for english about 10 for

00:53:06,000 --> 00:53:11,520
chinese

00:53:07,280 --> 00:53:11,520
about 10 for hindi

00:53:11,920 --> 00:53:16,480
and again for portuguese about 10 now

00:53:15,040 --> 00:53:18,160
for russian

00:53:16,480 --> 00:53:20,000
not as much for russia i don't

00:53:18,160 --> 00:53:21,680
understand that russian is a tough

00:53:20,000 --> 00:53:22,240
language to translate or maybe it's just

00:53:21,680 --> 00:53:25,599
the

00:53:22,240 --> 00:53:27,680
russian wiki page that i was using uh

00:53:25,599 --> 00:53:30,720
and swedish curiously there wasn't much

00:53:27,680 --> 00:53:32,800
difference in that either

00:53:30,720 --> 00:53:35,920
when i looked at the torture tests i did

00:53:32,800 --> 00:53:39,520
a little bit better with avx versus ssc

00:53:35,920 --> 00:53:43,119
uh for for for the uh all ascii

00:53:39,520 --> 00:53:46,640
for all chinese code points again i did

00:53:43,119 --> 00:53:48,800
quite a bit better actually more than 10

00:53:46,640 --> 00:53:50,000
and then for the alternating chinese and

00:53:48,800 --> 00:53:52,640
ascii code points

00:53:50,000 --> 00:53:54,559
i did a little bit better but the thing

00:53:52,640 --> 00:53:57,760
that i find interesting

00:53:54,559 --> 00:53:59,760
is that first of all

00:53:57,760 --> 00:54:01,760
that i'm happy that i saw these

00:53:59,760 --> 00:54:04,319
improvements in performance with clang

00:54:01,760 --> 00:54:05,040
and visual studio i'm a little bit

00:54:04,319 --> 00:54:06,720
curious

00:54:05,040 --> 00:54:08,640
about why i didn't see the performance

00:54:06,720 --> 00:54:11,920
improvements with gcc

00:54:08,640 --> 00:54:14,720
if i look at the absolute timings gcc

00:54:11,920 --> 00:54:18,480
tends to have the best absolute timings

00:54:14,720 --> 00:54:20,480
so perhaps gcc has already figured out

00:54:18,480 --> 00:54:22,559
how to optimize the sequence of machine

00:54:20,480 --> 00:54:25,040
instructions in optimal way

00:54:22,559 --> 00:54:26,160
in a way that perhaps clang and visual

00:54:25,040 --> 00:54:28,160
studio have not yet

00:54:26,160 --> 00:54:29,920
implemented although i'm sure they

00:54:28,160 --> 00:54:32,640
probably will

00:54:29,920 --> 00:54:34,640
so sort of mixed results uh two out of

00:54:32,640 --> 00:54:36,480
three compilers i got

00:54:34,640 --> 00:54:38,079
reasonable i would consider acceptable

00:54:36,480 --> 00:54:40,079
performance improvements for

00:54:38,079 --> 00:54:42,000
especially if you use those compilers

00:54:40,079 --> 00:54:42,880
for gcc i would say there's effectively

00:54:42,000 --> 00:54:44,240
no difference

00:54:42,880 --> 00:54:46,880
and you'll get good performance either

00:54:44,240 --> 00:54:48,960
way so

00:54:46,880 --> 00:54:50,720
that is the end of my presentation the

00:54:48,960 --> 00:54:53,920
second half there's my

00:54:50,720 --> 00:54:55,359
github and my blog these slides will be

00:54:53,920 --> 00:54:58,240
up on the blog today

00:54:55,359 --> 00:54:59,680
for today's talks the code that you saw

00:54:58,240 --> 00:55:01,200
i'm going to do a little bit of cleanup

00:54:59,680 --> 00:55:03,680
and commenting so it's

00:55:01,200 --> 00:55:05,119
decipherable and the code will be up and

00:55:03,680 --> 00:55:07,839
included in the blog

00:55:05,119 --> 00:55:09,520
before you get to work monday morning so

00:55:07,839 --> 00:55:11,200
thank you everyone for coming

00:55:09,520 --> 00:55:13,040
i've got three minutes left and i see

00:55:11,200 --> 00:55:15,520
some questions on remo and i'm going to

00:55:13,040 --> 00:55:18,079
attempt to answer them

00:55:15,520 --> 00:55:20,640
so the first question is is there a

00:55:18,079 --> 00:55:22,480
drawback to have 16 registers used for

00:55:20,640 --> 00:55:25,280
kernel coefficients when the register

00:55:22,480 --> 00:55:25,280
count is limited

00:55:26,319 --> 00:55:30,799
i don't think so the change in

00:55:29,440 --> 00:55:33,520
performance from going

00:55:30,799 --> 00:55:34,640
from i actually tried convolutions for

00:55:33,520 --> 00:55:38,000
just for the

00:55:34,640 --> 00:55:41,680
fun of it for all values from 1 to 16.

00:55:38,000 --> 00:55:44,319
and the change in behavior uh

00:55:41,680 --> 00:55:45,520
did not it didn't seem to make a

00:55:44,319 --> 00:55:46,960
difference

00:55:45,520 --> 00:55:48,640
even with the limited number of

00:55:46,960 --> 00:55:51,839
registers and i suspect

00:55:48,640 --> 00:55:54,000
when the optimizer works its magic

00:55:51,839 --> 00:55:54,559
behind the scenes it's not actually

00:55:54,000 --> 00:55:58,960
loading

00:55:54,559 --> 00:56:01,920
all of those all of those things into

00:55:58,960 --> 00:56:03,760
into an array i suspect well i know that

00:56:01,920 --> 00:56:05,760
it's unrolling the main loop

00:56:03,760 --> 00:56:07,200
and since it's unrolling the main loop

00:56:05,760 --> 00:56:09,359
it may have looked at the initial loop

00:56:07,200 --> 00:56:11,359
where the kernel coefficients are stored

00:56:09,359 --> 00:56:12,880
and just simply written those things out

00:56:11,359 --> 00:56:16,000
to memory somewhere

00:56:12,880 --> 00:56:18,160
and then in the unrolled loop it

00:56:16,000 --> 00:56:20,000
just pulls those things out as it needs

00:56:18,160 --> 00:56:20,799
them from memory loading them into a

00:56:20,000 --> 00:56:22,400
register

00:56:20,799 --> 00:56:24,880
rather than keeping them always in a

00:56:22,400 --> 00:56:24,880
register

00:56:25,520 --> 00:56:29,680
what is the impact of passing cmd

00:56:27,440 --> 00:56:32,559
register values to function by value or

00:56:29,680 --> 00:56:35,119
reference in the impact of using lambdas

00:56:32,559 --> 00:56:36,000
well i haven't tried any of this code

00:56:35,119 --> 00:56:38,000
using lambdas

00:56:36,000 --> 00:56:39,119
it's intentionally designed to be very

00:56:38,000 --> 00:56:41,119
simple

00:56:39,119 --> 00:56:42,799
in fact i was really intending to use

00:56:41,119 --> 00:56:44,640
operator overloading to give me a

00:56:42,799 --> 00:56:47,280
consistent interface

00:56:44,640 --> 00:56:48,960
a consistent forced inline interface so

00:56:47,280 --> 00:56:52,319
that i could overload a single name

00:56:48,960 --> 00:56:56,000
function for ins and floats and doubles

00:56:52,319 --> 00:56:57,599
and chars in terms of performance

00:56:56,000 --> 00:56:59,359
between passing a value

00:56:57,599 --> 00:57:01,200
a register by value and passing a

00:56:59,359 --> 00:57:04,079
register by reference

00:57:01,200 --> 00:57:06,400
i'm able to detect no difference i try

00:57:04,079 --> 00:57:08,160
to use a form where

00:57:06,400 --> 00:57:11,280
registers are passed by value and you

00:57:08,160 --> 00:57:13,920
get a return you use the return value

00:57:11,280 --> 00:57:15,440
sort of a functional style however there

00:57:13,920 --> 00:57:17,440
was the one function

00:57:15,440 --> 00:57:20,079
in place shift up by with carry where i

00:57:17,440 --> 00:57:22,960
used i used

00:57:20,079 --> 00:57:24,559
i used references because i didn't want

00:57:22,960 --> 00:57:27,520
to deal with returning a tuple

00:57:24,559 --> 00:57:28,640
and possible performance degradation

00:57:27,520 --> 00:57:32,480
from that

00:57:28,640 --> 00:57:32,480
it was just easier to use references

00:57:32,640 --> 00:57:37,680
next question could you put the code on

00:57:36,240 --> 00:57:39,680
compiler explorer and see what the

00:57:37,680 --> 00:57:42,880
difference is between gcc and clang

00:57:39,680 --> 00:57:45,119
yes i absolutely could do that

00:57:42,880 --> 00:57:47,200
and as i was developing it i actually

00:57:45,119 --> 00:57:48,640
had hard-coded

00:57:47,200 --> 00:57:50,880
instead of having the template when i

00:57:48,640 --> 00:57:53,440
was originally developing the code

00:57:50,880 --> 00:57:55,040
i actually hard-coded the parameters

00:57:53,440 --> 00:57:56,400
into the function rather than making

00:57:55,040 --> 00:57:58,160
them template parameters

00:57:56,400 --> 00:57:59,839
and once i got it working for a couple

00:57:58,160 --> 00:58:02,880
of different values

00:57:59,839 --> 00:58:04,400
you know 5 and 11 i think then i went

00:58:02,880 --> 00:58:05,760
back and turned it into a template and

00:58:04,400 --> 00:58:08,799
then checked it for

00:58:05,760 --> 00:58:10,000
3 through 15 odd numbers and while i was

00:58:08,799 --> 00:58:11,680
doing that

00:58:10,000 --> 00:58:13,680
i was actually taking those and dropping

00:58:11,680 --> 00:58:14,559
them into explorer to see what was being

00:58:13,680 --> 00:58:17,760
generated

00:58:14,559 --> 00:58:19,040
but to be honest i didn't try actually

00:58:17,760 --> 00:58:20,799
looking at the op codes

00:58:19,040 --> 00:58:23,359
the difference in the instructions

00:58:20,799 --> 00:58:25,200
between gcc and clang

00:58:23,359 --> 00:58:26,720
you know in my copious free time that's

00:58:25,200 --> 00:58:28,400
something i hope to get to someday and

00:58:26,720 --> 00:58:30,640
see what the difference is

00:58:28,400 --> 00:58:32,720
but even if there was a difference i'm

00:58:30,640 --> 00:58:33,119
not enough of an assembler expert and i

00:58:32,720 --> 00:58:35,760
don't

00:58:33,119 --> 00:58:36,799
know really enough of the deep details

00:58:35,760 --> 00:58:38,720
of how

00:58:36,799 --> 00:58:40,319
the intel architecture works to look at

00:58:38,720 --> 00:58:43,040
the instructions and say

00:58:40,319 --> 00:58:46,480
aha here's the reason why this thing is

00:58:43,040 --> 00:58:46,480
slower than this other thing

00:58:47,599 --> 00:58:51,440
are you aware of cmd implementations for

00:58:49,839 --> 00:58:53,440
mathematical special functions

00:58:51,440 --> 00:58:55,280
gaussian error function for example that

00:58:53,440 --> 00:58:57,680
are publicly available

00:58:55,280 --> 00:58:58,559
no i am not it's not something i was

00:58:57,680 --> 00:59:00,799
looking for

00:58:58,559 --> 00:59:02,640
when i did this work as i said i was

00:59:00,799 --> 00:59:04,720
trying i was playing around with some

00:59:02,640 --> 00:59:06,799
signal processing on an audio signal

00:59:04,720 --> 00:59:08,480
that led me down this rabbit hole and

00:59:06,799 --> 00:59:11,520
since i had had the experience

00:59:08,480 --> 00:59:13,200
two years ago with the sse i thought hey

00:59:11,520 --> 00:59:15,359
maybe i can use intrinsics to make this

00:59:13,200 --> 00:59:18,079
audio processing faster

00:59:15,359 --> 00:59:19,200
that being said i think taking an avx

00:59:18,079 --> 00:59:21,119
based approach

00:59:19,200 --> 00:59:23,119
and turning it into a publicly available

00:59:21,119 --> 00:59:23,760
library is a great idea and something i

00:59:23,119 --> 00:59:25,680
would

00:59:23,760 --> 00:59:27,280
like to either initiate or participate

00:59:25,680 --> 00:59:29,839
in but i'm not aware of anything like

00:59:27,280 --> 00:59:31,680
that right now

00:59:29,839 --> 00:59:33,920
how did i mix ascii and chinese

00:59:31,680 --> 00:59:36,160
characters in stress test two

00:59:33,920 --> 00:59:37,760
so basically what i did is i create

00:59:36,160 --> 00:59:39,680
created a sequence of one hundred

00:59:37,760 --> 00:59:41,839
thousand code points and remember a code

00:59:39,680 --> 00:59:45,200
point is a four byte integer

00:59:41,839 --> 00:59:46,000
and every and the code points in that

00:59:45,200 --> 00:59:48,559
array

00:59:46,000 --> 00:59:50,880
began with a chinese character followed

00:59:48,559 --> 00:59:53,599
by an ascii character code point

00:59:50,880 --> 00:59:55,920
and that pattern followed so there were

00:59:53,599 --> 00:59:57,440
50 000 chinese code points interleaved

00:59:55,920 --> 01:00:00,480
with 50 000

00:59:57,440 --> 01:00:02,000
ascii code points chinese ascii chinese

01:00:00,480 --> 01:00:05,680
ascii chinese ascii

01:00:02,000 --> 01:00:07,280
so i had the code points in utf-32

01:00:05,680 --> 01:00:09,599
then what i did is i just wrote a

01:00:07,280 --> 01:00:12,799
function to convert the utf-32

01:00:09,599 --> 01:00:13,760
code point back into a sequence of utf-8

01:00:12,799 --> 01:00:17,520
octets

01:00:13,760 --> 01:00:20,720
and that's how i got the utf-8

01:00:17,520 --> 01:00:23,839
the utf-8 input for stress test 2.

01:00:20,720 --> 01:00:26,960
and of course part of stress test 2 is

01:00:23,839 --> 01:00:28,960
taking the utf-8 that i convert

01:00:26,960 --> 01:00:30,640
and comparing it to the original the

01:00:28,960 --> 01:00:32,720
original code points to make sure that

01:00:30,640 --> 01:00:36,480
they match and they should and they did

01:00:32,720 --> 01:00:37,839
but that's how they were generated so

01:00:36,480 --> 01:00:40,000
all right well i see that i'm out of

01:00:37,839 --> 01:00:41,119
questions and i'm out of time i ran two

01:00:40,000 --> 01:00:42,559
minutes over

01:00:41,119 --> 01:00:44,720
thank you everyone for coming to this

01:00:42,559 --> 01:00:47,119
talk as i said slides will be up on

01:00:44,720 --> 01:00:48,559
github tonight in the code this weekend

01:00:47,119 --> 01:00:57,839
thank you very much have a good rest of

01:00:48,559 --> 01:00:57,839
the conference and take care

01:01:09,760 --> 01:01:11,839

YouTube URL: https://www.youtube.com/watch?v=qXleSwCCEvY


