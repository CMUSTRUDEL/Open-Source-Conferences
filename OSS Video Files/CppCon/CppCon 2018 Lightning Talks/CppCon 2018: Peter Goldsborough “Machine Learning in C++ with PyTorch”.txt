Title: CppCon 2018: Peter Goldsborough “Machine Learning in C++ with PyTorch”
Publication date: 2018-11-11
Playlist: CppCon 2018 Lightning Talks
Description: 
	http://CppCon.org
—
Presentation Slides, PDFs, Source Code and other presenter materials are available at: https://github.com/CppCon/CppCon2018
—
Lightning Talk
— 
Videos Filmed & Edited by Bash Films: http://www.BashFilms.com
Captions: 
	00:00:00,030 --> 00:00:09,929
I know Peter and myself started another

00:00:07,740 --> 00:00:12,719
proposition for the name was Facebook

00:00:09,929 --> 00:00:15,420
EIU lab that was not a very good idea at

00:00:12,719 --> 00:00:17,699
all anyway

00:00:15,420 --> 00:00:19,560
exactly 364 days ago I gave a talk

00:00:17,699 --> 00:00:21,539
seeking pecan on the topic of Keith

00:00:19,560 --> 00:00:22,859
learning was supposed to us and as you

00:00:21,539 --> 00:00:25,410
can see I had really well done slides

00:00:22,859 --> 00:00:27,480
and but the conclusion of my talk was

00:00:25,410 --> 00:00:28,800
that while and most masculine learning

00:00:27,480 --> 00:00:30,750
frameworks out there were implemented

00:00:28,800 --> 00:00:33,660
under the hood none of them really

00:00:30,750 --> 00:00:37,350
provided a first-class nice universe for

00:00:33,660 --> 00:00:39,210
research directly title on the Lua or

00:00:37,350 --> 00:00:40,829
not the scripting language like that and

00:00:39,210 --> 00:00:42,450
so after my talk I end up running

00:00:40,829 --> 00:00:43,860
Facebook and end up joining a team there

00:00:42,450 --> 00:00:45,930
that works on tight core from the most

00:00:43,860 --> 00:00:48,480
popular machine learning frameworks and

00:00:45,930 --> 00:00:50,399
then actually exactly this library that

00:00:48,480 --> 00:00:52,170
I contain about non-existing one year

00:00:50,399 --> 00:00:53,489
ago and that's what the slightly talked

00:00:52,170 --> 00:00:55,350
about so let me tell you a bit more

00:00:53,489 --> 00:00:56,460
about pi course hi Kirk is a Michigan

00:00:55,350 --> 00:00:58,680
learning framework for a number of

00:00:56,460 --> 00:01:00,870
domains like the division and palang

00:00:58,680 --> 00:01:03,239
which processing gaming I or pretty much

00:01:00,870 --> 00:01:04,920
any other kind of ml or scientific

00:01:03,239 --> 00:01:06,570
computing you want to do and it's

00:01:04,920 --> 00:01:08,640
usually programmed to a Python front-end

00:01:06,570 --> 00:01:10,560
of what's good for purposes of that this

00:01:08,640 --> 00:01:13,170
Python content sits on top of a really

00:01:10,560 --> 00:01:15,479
rich and extensive was lacking and the

00:01:13,170 --> 00:01:17,909
C++ back can provide things like a type

00:01:15,479 --> 00:01:20,850
of for intensive library through the

00:01:17,909 --> 00:01:22,049
support since in I care more about CUDA

00:01:20,850 --> 00:01:23,880
than we do about CPUs

00:01:22,049 --> 00:01:26,040
and also provides automatic

00:01:23,880 --> 00:01:27,869
presentations and most modern machine

00:01:26,040 --> 00:01:30,689
learning methods require gradients in

00:01:27,869 --> 00:01:32,700
one way or another and so my work of the

00:01:30,689 --> 00:01:34,829
past six months has been to essentially

00:01:32,700 --> 00:01:36,740
add a new sequel post content based in

00:01:34,829 --> 00:01:39,270
top of the exact same C++ back-end

00:01:36,740 --> 00:01:41,159
allows you to do Emily research directly

00:01:39,270 --> 00:01:42,960
in C++ without any Python in the loop at

00:01:41,159 --> 00:01:44,850
all so let's see what this looks like

00:01:42,960 --> 00:01:46,920
I'm here an example so we include the

00:01:44,850 --> 00:01:48,960
torch header we have a model which is

00:01:46,920 --> 00:01:51,060
the linear layer which just makes

00:01:48,960 --> 00:01:52,560
multiplication we have an optimizer

00:01:51,060 --> 00:01:54,720
which is a stochastic gradient descent

00:01:52,560 --> 00:01:55,829
optimizer here we give it the parameters

00:01:54,720 --> 00:01:58,200
of the model that we want to optimize

00:01:55,829 --> 00:01:59,610
you have a multi-threaded a synchronous

00:01:58,200 --> 00:02:02,340
feed of odor which is for our data

00:01:59,610 --> 00:02:04,680
pipelines and then for 1080 parks we

00:02:02,340 --> 00:02:06,360
either a 2d data loader and we run our

00:02:04,680 --> 00:02:08,640
example through the model get a

00:02:06,360 --> 00:02:10,770
prediction consider lost between your

00:02:08,640 --> 00:02:13,020
prediction in the label compute the

00:02:10,770 --> 00:02:14,120
gradients of the loss will respect for

00:02:13,020 --> 00:02:16,250
each mole of grammar

00:02:14,120 --> 00:02:17,840
and then our optimizer will update the

00:02:16,250 --> 00:02:19,610
weights of the model based on those

00:02:17,840 --> 00:02:21,530
gradients and what's exciting is that

00:02:19,610 --> 00:02:23,989
this C++ code looks almost exactly

00:02:21,530 --> 00:02:25,909
identical to the Piatt the Python

00:02:23,989 --> 00:02:27,970
content code which means that we can do

00:02:25,909 --> 00:02:30,409
machine land research directly in C++

00:02:27,970 --> 00:02:32,720
without any loss of flexibility or

00:02:30,409 --> 00:02:35,659
aesthetics that you might be used to

00:02:32,720 --> 00:02:37,549
from Python and so that's very exciting

00:02:35,659 --> 00:02:40,370
but why would you even care like at all

00:02:37,549 --> 00:02:42,379
so I think there's we can abuse cases

00:02:40,370 --> 00:02:43,909
for the fiery the first is if you want

00:02:42,379 --> 00:02:46,040
to do an ml research in high performance

00:02:43,909 --> 00:02:47,359
environments so the biggest use of this

00:02:46,040 --> 00:02:49,310
Brunton right now the group of

00:02:47,359 --> 00:02:51,760
scientists out there that does research

00:02:49,310 --> 00:02:54,290
in StarCraft so you can imagine how the

00:02:51,760 --> 00:02:56,299
high performance low latency game engine

00:02:54,290 --> 00:02:58,579
instance plus you want to predict

00:02:56,299 --> 00:02:59,780
actions for agents and of course Python

00:02:58,579 --> 00:03:02,480
will be way too slow for that said he

00:02:59,780 --> 00:03:04,700
actually used this content to the

00:03:02,480 --> 00:03:06,409
research inside the game engine and the

00:03:04,700 --> 00:03:08,030
second use case would be more for I

00:03:06,409 --> 00:03:09,920
think I'm irrelevant to you guys I'm

00:03:08,030 --> 00:03:11,959
sure y'all work on some kind of C++

00:03:09,920 --> 00:03:14,569
application you might want to explore

00:03:11,959 --> 00:03:15,980
just explore using if you're learning in

00:03:14,569 --> 00:03:18,049
that application so for example you

00:03:15,980 --> 00:03:20,389
might be working on a load balancer for

00:03:18,049 --> 00:03:22,010
a network application and you want to

00:03:20,389 --> 00:03:23,930
see if having a neural net what you

00:03:22,010 --> 00:03:25,549
predict what Java schedule might be

00:03:23,930 --> 00:03:27,290
prove something then I think having a

00:03:25,549 --> 00:03:28,760
crucible close buddy like this will be a

00:03:27,290 --> 00:03:30,769
lot easier than having to figure out how

00:03:28,760 --> 00:03:32,450
to bind a fit Python them back and the

00:03:30,769 --> 00:03:34,340
last use case is just maybe you want to

00:03:32,450 --> 00:03:36,260
learn about machine learning can I see a

00:03:34,340 --> 00:03:37,730
show of hands who in the last few years

00:03:36,260 --> 00:03:39,849
as vaguely wanted to learn about the

00:03:37,730 --> 00:03:42,290
field name because it seems cool and

00:03:39,849 --> 00:03:44,720
super hands that we could rather do that

00:03:42,290 --> 00:03:46,329
is because Python in Python right and I

00:03:44,720 --> 00:03:49,579
guess the cyber is also called you guys

00:03:46,329 --> 00:03:51,620
and that's all I really have so please

00:03:49,579 --> 00:03:52,879
try it out um the first link is the dogs

00:03:51,620 --> 00:03:56,329
that are finished writing at 4:00 in the

00:03:52,879 --> 00:03:58,639
morning today the second link is the

00:03:56,329 --> 00:04:01,069
apply towards repels all everything we

00:03:58,639 --> 00:04:03,139
do is super duper open-source and the

00:04:01,069 --> 00:04:04,849
last link is my you know if you want to

00:04:03,139 --> 00:04:06,470
reach out and talk about your missing on

00:04:04,849 --> 00:04:08,870
use case or a supervisor will work for

00:04:06,470 --> 00:04:14,400
you and yeah thankful

00:04:08,870 --> 00:04:14,400

YouTube URL: https://www.youtube.com/watch?v=auRPXMMHJzc


