Title: Managarm: A Fully Asynchronous OS Based on Modern C++ - Alexander van der Grinten - CppCon 2020
Publication date: 2020-10-04
Playlist: CppCon 2020 Day 4
Description: 
	https://cppcon.org/
https://github.com/CppCon/CppCon2020/blob/main/Presentations/managarm_a_fully_asynchronous_operating_system_powered_by_modern_cpp/managarm_a_fully_asynchronous_operating_system_powered_by_modern_cpp__alexander_van_der_grinten__cppcon_2020.pdf
---
C++20 and future C++ standards are expected to massively improve the ergonomics of asynchronous I/O within the C++ ecosystem. Yet, the vast majority of current operating systems (OSes) were designed without considering asynchronous I/O to be a first-class citizen. For example, Linux is only able to perform general-purpose asynchronous I/O since the recent addition of io_uring. Even with this new asynchronous mechanism in place, many I/O operations still have to fall back to a thread-based emulation within the kernel.

In this talk, we present Managarm, an OS designed around C++20 coroutines and the upcoming C++ sender/receiver model. Its main goal is to fully support asynchronous I/O through the entire system. All I/O operations are asynchronous in Managarm, with a single blocking system call to wait for their completion. The OS implements primitive asynchronous operations using (a variant of) the C++ sender/receiver model. These primitives comprise the system call layer and basic asynchronous data structures. We discuss how this low-level functionality can be integrated into high-level C++ code that is based on coroutines. High-level coroutine code constitutes the majority of the system and enables fully asynchronous drivers and servers. This approach enables high programmer productivity and excellent performance at the same time. At the end of the talk, we discuss open challenges for system programming that C++20 does not solve yet and give a perspective on vital future work in this area.

---
Alexander van der Grinten is a postdoctoral researcher at Humboldt-University of Berlin. He is also a founder of Managarm, a fully asynchronous operating system that is written in modern C++.

Alexander obtained his PhD in computer science from University of Cologne in 2018. He is professionally interested in the engineering of scalable algorithms that are often implemented in C++. His main research focus is on parallel graph algorithms, shared-memory parallelism, high-performance computing and hard combinatorial problems.

---
Streamed & Edited by Digital Medium Ltd - events.digital-medium.co.uk
events@digital-medium.co.uk
Captions: 
	00:00:10,080 --> 00:00:14,240
hello

00:00:10,880 --> 00:00:16,560
and welcome to my talk about managam

00:00:14,240 --> 00:00:17,760
a fully asynchronous operating system

00:00:16,560 --> 00:00:21,119
powered by modern c

00:00:17,760 --> 00:00:24,160
plus plus so

00:00:21,119 --> 00:00:26,720
um i'm alexander van grenten

00:00:24,160 --> 00:00:28,880
first a bit of info about myself so i'm

00:00:26,720 --> 00:00:31,279
a postdoctoral researcher in computer

00:00:28,880 --> 00:00:32,559
science i'm currently working in berlin

00:00:31,279 --> 00:00:35,600
in germany

00:00:32,559 --> 00:00:39,360
and i've obtained my phd in 2018

00:00:35,600 --> 00:00:40,399
but well this is not really about

00:00:39,360 --> 00:00:42,879
research

00:00:40,399 --> 00:00:44,960
my research focuses more on parallel

00:00:42,879 --> 00:00:47,360
algorithms graph algorithms and hard

00:00:44,960 --> 00:00:47,840
combinatorial problems but in this talk

00:00:47,360 --> 00:00:49,360
i'm

00:00:47,840 --> 00:00:51,440
actually talking about something

00:00:49,360 --> 00:00:53,680
entirely different

00:00:51,440 --> 00:00:56,000
namely i'm talking about managam which

00:00:53,680 --> 00:00:59,359
is a pragmatic operating system

00:00:56,000 --> 00:01:01,760
with fully asynchronous io and by

00:00:59,359 --> 00:01:04,000
pragmatic i mean that this is not really

00:01:01,760 --> 00:01:05,360
bleeding edge research or so but this is

00:01:04,000 --> 00:01:09,200
really something

00:01:05,360 --> 00:01:12,400
uh that we that we aim

00:01:09,200 --> 00:01:15,520
to uh well provide a usable

00:01:12,400 --> 00:01:17,360
product um

00:01:15,520 --> 00:01:20,159
it's an open source project it's not

00:01:17,360 --> 00:01:24,880
actually funded by my employer

00:01:20,159 --> 00:01:26,080
um it's founded 2014 and it has a few

00:01:24,880 --> 00:01:29,040
active contributors

00:01:26,080 --> 00:01:31,360
so this is not only my work but for the

00:01:29,040 --> 00:01:34,560
the work of others too

00:01:31,360 --> 00:01:36,880
but now let's get into the topic so

00:01:34,560 --> 00:01:38,040
what will we cover in this talk first i

00:01:36,880 --> 00:01:40,560
will discuss why

00:01:38,040 --> 00:01:43,360
asynchronicity matters in operating

00:01:40,560 --> 00:01:46,479
systems and also in applications

00:01:43,360 --> 00:01:48,079
um i will give a brief overview of

00:01:46,479 --> 00:01:51,520
managam

00:01:48,079 --> 00:01:52,240
i will discuss how async can be done in

00:01:51,520 --> 00:01:54,079
c plus

00:01:52,240 --> 00:01:56,000
20 and we will see that there are

00:01:54,079 --> 00:01:57,600
different mechanisms that should be used

00:01:56,000 --> 00:01:59,439
for high level code and for building

00:01:57,600 --> 00:02:00,719
blocks

00:01:59,439 --> 00:02:02,960
then i will go through the

00:02:00,719 --> 00:02:04,399
implementation of async syscalls so

00:02:02,960 --> 00:02:08,160
these are

00:02:04,399 --> 00:02:09,759
the basis of the entire operating system

00:02:08,160 --> 00:02:11,200
and we will see how they can be

00:02:09,759 --> 00:02:14,239
implemented in c plus

00:02:11,200 --> 00:02:17,520
20 and how c plus plus especially

00:02:14,239 --> 00:02:19,040
is a very powerful tool in this context

00:02:17,520 --> 00:02:20,879
at the end of the talk we will discuss

00:02:19,040 --> 00:02:24,400
some open challenges

00:02:20,879 --> 00:02:27,120
and make some conclusions good so

00:02:24,400 --> 00:02:29,360
now let's get to the first point why

00:02:27,120 --> 00:02:32,239
does asynchronicity matter

00:02:29,360 --> 00:02:32,720
and to understand that i'm actually

00:02:32,239 --> 00:02:35,840
going to

00:02:32,720 --> 00:02:37,760
make an example of synchronous io we

00:02:35,840 --> 00:02:40,959
look at posix files that's

00:02:37,760 --> 00:02:43,360
uh well-known technology and opengl

00:02:40,959 --> 00:02:44,319
i just picked this example because many

00:02:43,360 --> 00:02:46,400
probably

00:02:44,319 --> 00:02:47,360
know these technologies or at least have

00:02:46,400 --> 00:02:48,879
heard of them

00:02:47,360 --> 00:02:50,879
they are straightforward they are well

00:02:48,879 --> 00:02:53,360
understood and for example

00:02:50,879 --> 00:02:54,400
if we want to upload a texture from the

00:02:53,360 --> 00:02:58,159
file system

00:02:54,400 --> 00:03:00,879
to the gpu using posix and opengl

00:02:58,159 --> 00:03:01,840
we can do it like this we have a

00:03:00,879 --> 00:03:05,040
function that

00:03:01,840 --> 00:03:05,760
just takes a path it allocates a

00:03:05,040 --> 00:03:09,440
constant

00:03:05,760 --> 00:03:12,080
size buffer so it allocates 400 or 4 000

00:03:09,440 --> 00:03:13,599
bytes here on the stack and then it

00:03:12,080 --> 00:03:16,640
opens the file it reads

00:03:13,599 --> 00:03:18,640
a chunk of data and uploads that data to

00:03:16,640 --> 00:03:21,840
the gpu there's nothing

00:03:18,640 --> 00:03:25,680
spectacular here this is pretty

00:03:21,840 --> 00:03:28,879
standard code i'm also abstracting a way

00:03:25,680 --> 00:03:31,680
over things like file formats that would

00:03:28,879 --> 00:03:33,599
play a role in real code here

00:03:31,680 --> 00:03:34,720
and i just assume that everything is a

00:03:33,599 --> 00:03:37,920
bitmap and

00:03:34,720 --> 00:03:39,760
that this works so if you look at that

00:03:37,920 --> 00:03:42,000
code it's really easy to understand what

00:03:39,760 --> 00:03:44,959
it does right it's synchronous we can

00:03:42,000 --> 00:03:46,640
easily reason about all the things that

00:03:44,959 --> 00:03:49,760
this code does

00:03:46,640 --> 00:03:53,360
but it does not really scale well

00:03:49,760 --> 00:03:56,480
why not well these system calls

00:03:53,360 --> 00:03:57,760
open read and whatever gl text sub image

00:03:56,480 --> 00:04:00,400
2d

00:03:57,760 --> 00:04:02,720
uses internally they all block the

00:04:00,400 --> 00:04:05,840
current thread

00:04:02,720 --> 00:04:06,319
and you might think okay that's maybe

00:04:05,840 --> 00:04:08,640
not an

00:04:06,319 --> 00:04:09,360
issue for this code but it becomes an

00:04:08,640 --> 00:04:12,159
issue

00:04:09,360 --> 00:04:12,720
if we suddenly want to read a thousand

00:04:12,159 --> 00:04:16,320
files

00:04:12,720 --> 00:04:19,440
and upload a thousand files to the gpu

00:04:16,320 --> 00:04:22,800
so we cannot just start a thousand

00:04:19,440 --> 00:04:24,560
threads and uh call this function once

00:04:22,800 --> 00:04:25,840
per thread that's really inefficient

00:04:24,560 --> 00:04:29,360
that just won't work and

00:04:25,840 --> 00:04:32,000
won't scale well and i also claim

00:04:29,360 --> 00:04:32,639
that these abstractions that we see in

00:04:32,000 --> 00:04:34,880
this code

00:04:32,639 --> 00:04:36,960
they do not really map well to modern

00:04:34,880 --> 00:04:40,960
hardware

00:04:36,960 --> 00:04:42,720
so why why is that

00:04:40,960 --> 00:04:44,160
i claim that modern hardware is highly

00:04:42,720 --> 00:04:45,759
asynchronous and

00:04:44,160 --> 00:04:48,639
to understand that we just need to look

00:04:45,759 --> 00:04:52,720
at the evolution of storage technology

00:04:48,639 --> 00:04:56,720
um 15 years ago in 2004 there was sata

00:04:52,720 --> 00:04:58,960
or by its technical name ahci

00:04:56,720 --> 00:05:01,840
it has one request queue which means it

00:04:58,960 --> 00:05:04,560
can process one request at a time

00:05:01,840 --> 00:05:04,960
and answer one one for example read or

00:05:04,560 --> 00:05:08,560
write

00:05:04,960 --> 00:05:11,120
request at a time and the os can

00:05:08,560 --> 00:05:13,199
post 32 requests to this queue

00:05:11,120 --> 00:05:15,759
afterwards the queue is full and the

00:05:13,199 --> 00:05:17,759
os needs to wait until the queue is

00:05:15,759 --> 00:05:20,400
drained again

00:05:17,759 --> 00:05:21,520
so far so good now what happened 10

00:05:20,400 --> 00:05:24,400
years later

00:05:21,520 --> 00:05:27,039
well modern devices which are called

00:05:24,400 --> 00:05:28,560
nvme devices they support many more

00:05:27,039 --> 00:05:30,880
concurrent requests

00:05:28,560 --> 00:05:32,880
they support thousands of concurrent

00:05:30,880 --> 00:05:36,560
requests at least at the higher

00:05:32,880 --> 00:05:38,400
end of the uh

00:05:36,560 --> 00:05:40,320
at least the higher-end products to do

00:05:38,400 --> 00:05:42,400
that and

00:05:40,320 --> 00:05:44,800
well they can also store many more

00:05:42,400 --> 00:05:45,600
requests per queue before the os needs

00:05:44,800 --> 00:05:49,840
to

00:05:45,600 --> 00:05:52,400
uh wait until i always finished again

00:05:49,840 --> 00:05:53,199
so the crucial point now is that if

00:05:52,400 --> 00:05:56,479
you're writing

00:05:53,199 --> 00:05:58,080
i uh oh in a synchronous way so if

00:05:56,479 --> 00:06:01,199
you're writing it

00:05:58,080 --> 00:06:03,120
like we've seen before then your thread

00:06:01,199 --> 00:06:05,600
can only post one such request

00:06:03,120 --> 00:06:06,639
and only to one such queue and it will

00:06:05,600 --> 00:06:08,800
never post

00:06:06,639 --> 00:06:09,840
many requests so many cues at the same

00:06:08,800 --> 00:06:12,720
time

00:06:09,840 --> 00:06:14,000
and that's a huge bottleneck you cannot

00:06:12,720 --> 00:06:17,440
really utilize

00:06:14,000 --> 00:06:18,960
this modern storage technology using

00:06:17,440 --> 00:06:23,199
only one thread

00:06:18,960 --> 00:06:27,520
at least not if you're not using async

00:06:23,199 --> 00:06:30,639
good and the story is similar for other

00:06:27,520 --> 00:06:33,680
devices for example for gpus

00:06:30,639 --> 00:06:36,240
for network working devices

00:06:33,680 --> 00:06:38,319
at the low end so if we look at wi-fi

00:06:36,240 --> 00:06:39,360
but also at the higher end if we look at

00:06:38,319 --> 00:06:42,319
infiniband

00:06:39,360 --> 00:06:44,160
they are all asynchronous they support

00:06:42,319 --> 00:06:47,919
many concurrent requests and

00:06:44,160 --> 00:06:48,880
infiniband even supports very deep cues

00:06:47,919 --> 00:06:50,560
where the

00:06:48,880 --> 00:06:54,800
kernel the operating system kernel is

00:06:50,560 --> 00:06:54,800
not even involved in moving data around

00:06:55,440 --> 00:06:59,680
similar story holds for accelerators

00:06:57,440 --> 00:07:02,479
these will become more important in the

00:06:59,680 --> 00:07:05,759
future for example ai accelerator script

00:07:02,479 --> 00:07:05,759
accelerators and so on

00:07:05,840 --> 00:07:08,960
and also other well-known technologies

00:07:08,000 --> 00:07:12,400
let's say audio

00:07:08,960 --> 00:07:14,240
or connectivity technologies like usb

00:07:12,400 --> 00:07:15,919
and if you sum that up well that's

00:07:14,240 --> 00:07:18,960
almost all device

00:07:15,919 --> 00:07:19,680
that covers almost all device that you

00:07:18,960 --> 00:07:23,039
find

00:07:19,680 --> 00:07:25,039
in your pc or in your server depending

00:07:23,039 --> 00:07:29,360
on what you're looking at

00:07:25,039 --> 00:07:31,520
so well if we need asynchronous

00:07:29,360 --> 00:07:32,960
code to exploit these devices what can

00:07:31,520 --> 00:07:35,280
we do

00:07:32,960 --> 00:07:37,680
um let's ask the question what can we do

00:07:35,280 --> 00:07:38,240
in c plus plus 20 right c plus plus 20

00:07:37,680 --> 00:07:41,280
is

00:07:38,240 --> 00:07:42,479
our new technology here so how can we

00:07:41,280 --> 00:07:45,599
adapt the code

00:07:42,479 --> 00:07:49,120
to well perform better

00:07:45,599 --> 00:07:52,160
in an asynchronous environment

00:07:49,120 --> 00:07:54,080
and ideally we want to do this

00:07:52,160 --> 00:07:55,440
we just want to replace the void

00:07:54,080 --> 00:07:58,879
returning function by

00:07:55,440 --> 00:08:02,240
a function that returns some future some

00:07:58,879 --> 00:08:06,080
asynchronous result so i call that

00:08:02,240 --> 00:08:08,639
here asynctask void

00:08:06,080 --> 00:08:10,639
and then we replace the synchronous

00:08:08,639 --> 00:08:13,680
calls by just co aways

00:08:10,639 --> 00:08:15,919
so we co-await the result of the open

00:08:13,680 --> 00:08:16,879
call we co-await the result of the read

00:08:15,919 --> 00:08:20,160
call

00:08:16,879 --> 00:08:21,199
um and we go away the result of the

00:08:20,160 --> 00:08:24,800
texture upload

00:08:21,199 --> 00:08:27,120
so that's that's our ideal scenario that

00:08:24,800 --> 00:08:29,919
we can do everything in the quality

00:08:27,120 --> 00:08:31,520
and due to the nature of this code it's

00:08:29,919 --> 00:08:34,719
equally easy to read

00:08:31,520 --> 00:08:39,120
as the blocking synchronous

00:08:34,719 --> 00:08:42,159
code but it can now actually scale to

00:08:39,120 --> 00:08:44,159
a large number of threads

00:08:42,159 --> 00:08:46,480
or a large number of current requests

00:08:44,159 --> 00:08:48,720
because you can

00:08:46,480 --> 00:08:49,680
launch multiple core routines per thread

00:08:48,720 --> 00:08:51,600
we can easily

00:08:49,680 --> 00:08:54,560
launch thousands of such core routines

00:08:51,600 --> 00:08:57,519
without any noticeable overhead

00:08:54,560 --> 00:08:59,360
but now some of you might claim hey that

00:08:57,519 --> 00:09:02,399
just doesn't work that way right

00:08:59,360 --> 00:09:03,279
these abstractions don't exist the posix

00:09:02,399 --> 00:09:05,440
functions

00:09:03,279 --> 00:09:07,680
do not support asynchronous behavior

00:09:05,440 --> 00:09:10,959
opengl does not support

00:09:07,680 --> 00:09:13,279
asynchronous behavior so it's not that

00:09:10,959 --> 00:09:15,680
easy

00:09:13,279 --> 00:09:16,320
but well why is it not that easy because

00:09:15,680 --> 00:09:18,640
the

00:09:16,320 --> 00:09:19,839
infrastructure is not there but we can

00:09:18,640 --> 00:09:23,040
try to well

00:09:19,839 --> 00:09:24,160
build this infrastructure and as a site

00:09:23,040 --> 00:09:27,519
remark

00:09:24,160 --> 00:09:29,600
there are technologies like linux iou

00:09:27,519 --> 00:09:32,560
ring or vulcan

00:09:29,600 --> 00:09:34,399
and they can do these operations on this

00:09:32,560 --> 00:09:36,720
slide here asynchronously

00:09:34,399 --> 00:09:37,519
but they are not a general solution for

00:09:36,720 --> 00:09:40,640
example

00:09:37,519 --> 00:09:43,200
i o urine often has to fall back to

00:09:40,640 --> 00:09:45,760
threats in certain cases where the linux

00:09:43,200 --> 00:09:48,480
kernel is just not able to perform a

00:09:45,760 --> 00:09:50,560
operation in an asynchronous way because

00:09:48,480 --> 00:09:54,480
it was coded in a synchronous way

00:09:50,560 --> 00:09:54,480
so that there's no free lunch here

00:09:55,680 --> 00:10:02,720
good um now let's get to manager

00:09:59,839 --> 00:10:03,680
which tries to avoid these issues by

00:10:02,720 --> 00:10:06,560
just

00:10:03,680 --> 00:10:07,440
building on asynchronicity from the

00:10:06,560 --> 00:10:10,560
ground up

00:10:07,440 --> 00:10:13,519
so in managum everything is asynchronous

00:10:10,560 --> 00:10:16,000
so we do a file i o asynchronously

00:10:13,519 --> 00:10:17,279
that includes metadata updates which is

00:10:16,000 --> 00:10:19,600
a

00:10:17,279 --> 00:10:21,440
problem for existing operating systems

00:10:19,600 --> 00:10:24,800
that were

00:10:21,440 --> 00:10:27,279
coded with synchronous io in mind

00:10:24,800 --> 00:10:28,560
so they often have to do metadata

00:10:27,279 --> 00:10:32,000
updates in a synchronous

00:10:28,560 --> 00:10:35,120
fashion our drivers

00:10:32,000 --> 00:10:37,120
are fully asynchronous so uh internal

00:10:35,120 --> 00:10:38,399
weekly we can often use score teams

00:10:37,120 --> 00:10:40,880
instead of callbacks

00:10:38,399 --> 00:10:43,200
uh interrupt processing becomes a lot

00:10:40,880 --> 00:10:46,240
easier that's something that we'll see

00:10:43,200 --> 00:10:49,839
uh later during this talk

00:10:46,240 --> 00:10:52,959
and also stuff like device operations

00:10:49,839 --> 00:10:53,680
i o control and unix are asynchronous

00:10:52,959 --> 00:10:56,880
and managum

00:10:53,680 --> 00:10:59,920
so there's no restriction for

00:10:56,880 --> 00:11:01,519
asynchronous code here it also affects

00:10:59,920 --> 00:11:04,079
memory management but i don't really

00:11:01,519 --> 00:11:07,120
want to go into detail here but

00:11:04,079 --> 00:11:09,279
uh if you think about mem map and linux

00:11:07,120 --> 00:11:10,399
that can block in certain circumstances

00:11:09,279 --> 00:11:12,839
and it cannot block

00:11:10,399 --> 00:11:15,839
a nanogun because it's also implemented

00:11:12,839 --> 00:11:15,839
asynchronously

00:11:16,720 --> 00:11:20,640
good and all the other stuff that you

00:11:18,800 --> 00:11:22,160
know already for example networking

00:11:20,640 --> 00:11:23,120
that's a well-understood problem of

00:11:22,160 --> 00:11:25,200
course

00:11:23,120 --> 00:11:29,360
that can also be done asynchronously in

00:11:25,200 --> 00:11:32,240
our new os

00:11:29,360 --> 00:11:33,760
i'll give a high level overview so in

00:11:32,240 --> 00:11:36,720
contrast to existing

00:11:33,760 --> 00:11:38,079
operating systems like windows or linux

00:11:36,720 --> 00:11:42,000
managum employs a

00:11:38,079 --> 00:11:44,160
microkernel so um

00:11:42,000 --> 00:11:45,760
these of you who don't really know

00:11:44,160 --> 00:11:47,519
anything about kernel design or

00:11:45,760 --> 00:11:49,680
operating system design

00:11:47,519 --> 00:11:52,240
an operating system is usually split

00:11:49,680 --> 00:11:55,120
into two parts which is the kernel

00:11:52,240 --> 00:11:56,160
that's a privileged program that

00:11:55,120 --> 00:11:58,720
implements hardware

00:11:56,160 --> 00:11:59,200
access and provides this access over

00:11:58,720 --> 00:12:02,399
some

00:11:59,200 --> 00:12:04,800
safe interface to applications and then

00:12:02,399 --> 00:12:07,040
there are user mode applications that

00:12:04,800 --> 00:12:08,720
will run on this kernel and use system

00:12:07,040 --> 00:12:10,800
calls to call into it

00:12:08,720 --> 00:12:12,160
and these system calls follow a

00:12:10,800 --> 00:12:16,560
well-defined api

00:12:12,160 --> 00:12:20,480
so that there are no security issues or

00:12:16,560 --> 00:12:23,519
permission issues but in maragam

00:12:20,480 --> 00:12:26,480
our drivers also run as normal c plus

00:12:23,519 --> 00:12:28,079
program they don't have a supervisor

00:12:26,480 --> 00:12:30,959
privileges they

00:12:28,079 --> 00:12:33,839
basically cannot do everything the

00:12:30,959 --> 00:12:33,839
kernel can do

00:12:34,160 --> 00:12:38,880
yeah and therefore they are also much

00:12:36,880 --> 00:12:41,519
more easier to write

00:12:38,880 --> 00:12:42,240
we'll see that in a minute what does our

00:12:41,519 --> 00:12:43,839
kernel do

00:12:42,240 --> 00:12:45,920
well it still has to do memory

00:12:43,839 --> 00:12:46,639
management it has to do scheduling and

00:12:45,920 --> 00:12:49,040
it has to

00:12:46,639 --> 00:12:51,600
do ipc that's just there's just no way

00:12:49,040 --> 00:12:51,600
around that

00:12:51,680 --> 00:12:58,560
and because of these special constraints

00:12:55,600 --> 00:13:00,000
that uh well it has to do with custom

00:12:58,560 --> 00:13:03,200
memory allocation

00:13:00,000 --> 00:13:05,040
uh it cannot really use full c plus 20

00:13:03,200 --> 00:13:07,519
at least it cannot use the stl

00:13:05,040 --> 00:13:08,720
so it's written in a freestanding subset

00:13:07,519 --> 00:13:10,959
whereas the

00:13:08,720 --> 00:13:11,920
user model applications are written in

00:13:10,959 --> 00:13:15,040
just standard c

00:13:11,920 --> 00:13:16,000
plus we're using an stl like support

00:13:15,040 --> 00:13:19,040
library here

00:13:16,000 --> 00:13:21,519
which means that

00:13:19,040 --> 00:13:23,360
many things are actually available in

00:13:21,519 --> 00:13:26,639
slightly different form but it's not

00:13:23,360 --> 00:13:26,639
exactly the stl

00:13:26,720 --> 00:13:32,720
um luckily that part is small because

00:13:29,760 --> 00:13:34,480
user mod contains almost everything and

00:13:32,720 --> 00:13:36,320
that's hardware drivers

00:13:34,480 --> 00:13:38,240
all the posix code so we provide the

00:13:36,320 --> 00:13:41,760
posix emulation

00:13:38,240 --> 00:13:44,880
uh upon on top of our um

00:13:41,760 --> 00:13:45,279
native interface and our applications of

00:13:44,880 --> 00:13:48,800
course

00:13:45,279 --> 00:13:52,000
also run in user mode

00:13:48,800 --> 00:13:54,399
so um yeah

00:13:52,000 --> 00:13:56,240
the user mode things are written in

00:13:54,399 --> 00:13:59,199
fully compliant c plus

00:13:56,240 --> 00:14:01,440
20 and have access to the full stl so

00:13:59,199 --> 00:14:04,480
even when writing drivers we can use

00:14:01,440 --> 00:14:06,880
standard vectors or whatever classes we

00:14:04,480 --> 00:14:09,120
want to use from the standard library

00:14:06,880 --> 00:14:10,720
with uh well certain exceptions for

00:14:09,120 --> 00:14:12,240
example you cannot use a file system

00:14:10,720 --> 00:14:12,800
when you're writing a file system driver

00:14:12,240 --> 00:14:17,519
but

00:14:12,800 --> 00:14:20,000
let's not not get into this um

00:14:17,519 --> 00:14:21,199
what are other features of the os so we

00:14:20,000 --> 00:14:23,279
have some linux

00:14:21,199 --> 00:14:25,600
source compatibility which means we can

00:14:23,279 --> 00:14:29,199
recompile linux programs

00:14:25,600 --> 00:14:29,760
uh to run on our os we cannot really

00:14:29,199 --> 00:14:32,480
provide

00:14:29,760 --> 00:14:33,440
abi compatibility and that's not a goal

00:14:32,480 --> 00:14:36,959
because it would

00:14:33,440 --> 00:14:40,720
just be a lot of work for little gain

00:14:36,959 --> 00:14:42,720
um so for example we can also support

00:14:40,720 --> 00:14:46,160
e-pull we can support event fd

00:14:42,720 --> 00:14:48,079
timer fdo and signalfd there's a mistake

00:14:46,160 --> 00:14:50,560
on that slide

00:14:48,079 --> 00:14:51,120
we have file systems like dev proc and

00:14:50,560 --> 00:14:53,519
cis

00:14:51,120 --> 00:14:54,320
that have a similar layout as linux and

00:14:53,519 --> 00:14:57,920
we can run

00:14:54,320 --> 00:15:03,360
programs like wayland and x11

00:14:57,920 --> 00:15:03,360
desktop programs uh yeah and so on

00:15:03,760 --> 00:15:08,639
uh when i say we can do that of course

00:15:06,720 --> 00:15:12,000
we need to translate between our

00:15:08,639 --> 00:15:14,800
asynchronous api to linux

00:15:12,000 --> 00:15:16,880
blocking api and that has to happen

00:15:14,800 --> 00:15:19,199
somewhere and in our case it happens

00:15:16,880 --> 00:15:20,160
in a c library so the c library

00:15:19,199 --> 00:15:22,320
sometimes

00:15:20,160 --> 00:15:25,040
does an asynchronous request and then

00:15:22,320 --> 00:15:27,279
just blocks for its completion

00:15:25,040 --> 00:15:29,839
that's basically the cost of using the

00:15:27,279 --> 00:15:33,120
emulation layout

00:15:29,839 --> 00:15:35,360
for applications that use our native api

00:15:33,120 --> 00:15:37,120
uh this translation obviously doesn't

00:15:35,360 --> 00:15:38,399
happen otherwise there would be no

00:15:37,120 --> 00:15:40,560
benefit

00:15:38,399 --> 00:15:43,279
by the way our lipsy is also written in

00:15:40,560 --> 00:15:47,040
c plus plus which might be a nice

00:15:43,279 --> 00:15:49,440
nice insight okay

00:15:47,040 --> 00:15:51,360
what do we support as hardware uh we

00:15:49,440 --> 00:15:53,120
support most virtualized hardware

00:15:51,360 --> 00:15:54,079
virtualization is of course important

00:15:53,120 --> 00:15:56,480
today

00:15:54,079 --> 00:15:58,639
and real hardware is work in progress we

00:15:56,480 --> 00:16:00,560
support many modern devices but not

00:15:58,639 --> 00:16:01,680
nearly all legislative devices that's

00:16:00,560 --> 00:16:04,959
just too much to

00:16:01,680 --> 00:16:05,360
support um the current status is that

00:16:04,959 --> 00:16:07,920
it's

00:16:05,360 --> 00:16:09,519
functional and the os is functional but

00:16:07,920 --> 00:16:10,320
it's not really stable so it's easy to

00:16:09,519 --> 00:16:14,000
crash it

00:16:10,320 --> 00:16:15,040
or easy to yeah invoke functions that

00:16:14,000 --> 00:16:18,000
are not

00:16:15,040 --> 00:16:19,839
implemented 100 correctly for example if

00:16:18,000 --> 00:16:22,000
you look at proc it does not have all

00:16:19,839 --> 00:16:25,120
the proc files that linux has but it

00:16:22,000 --> 00:16:29,519
has only a small fraction

00:16:25,120 --> 00:16:29,519
good um

00:16:29,920 --> 00:16:36,079
yeah i'm going to do a case study here

00:16:34,079 --> 00:16:40,240
in this talk so i'm going to look at

00:16:36,079 --> 00:16:42,959
how async helps in low-level driver code

00:16:40,240 --> 00:16:45,440
um and for that i'm going to explain how

00:16:42,959 --> 00:16:48,000
low-level driver code often works

00:16:45,440 --> 00:16:48,959
so we've already seen that hardware is

00:16:48,000 --> 00:16:52,000
asynchronous

00:16:48,959 --> 00:16:52,959
is highly asynchronous and how does a

00:16:52,000 --> 00:16:54,959
driver for such

00:16:52,959 --> 00:16:57,120
asynchronous hardware work let's imagine

00:16:54,959 --> 00:17:00,399
we want to read something from disk

00:16:57,120 --> 00:17:02,399
okay then what usually happens is that a

00:17:00,399 --> 00:17:04,240
driver writes some commands to a buffer

00:17:02,399 --> 00:17:06,480
in ram

00:17:04,240 --> 00:17:10,000
the commands the layout of the commands

00:17:06,480 --> 00:17:13,360
of course specific to the device

00:17:10,000 --> 00:17:16,319
and i'm not going to go into detail here

00:17:13,360 --> 00:17:17,520
but then we notify the device using some

00:17:16,319 --> 00:17:20,240
mechanism that

00:17:17,520 --> 00:17:22,000
commands are available and the device

00:17:20,240 --> 00:17:24,079
starts reading these commands and it

00:17:22,000 --> 00:17:27,280
performs work

00:17:24,079 --> 00:17:30,880
and at the end the driver

00:17:27,280 --> 00:17:32,960
the device notifies the driver again

00:17:30,880 --> 00:17:33,919
and that happens you should usually

00:17:32,960 --> 00:17:35,760
using an

00:17:33,919 --> 00:17:38,400
interrupt so what's an interrupt that's

00:17:35,760 --> 00:17:40,080
something like a signal handler it's

00:17:38,400 --> 00:17:41,760
really just the same as the signal

00:17:40,080 --> 00:17:45,120
handler so wherever

00:17:41,760 --> 00:17:47,600
the cpu currently is it just starts

00:17:45,120 --> 00:17:48,960
executing at a different place it jumps

00:17:47,600 --> 00:17:51,360
to different function

00:17:48,960 --> 00:17:52,240
and that has all the bad implications

00:17:51,360 --> 00:17:55,280
that true

00:17:52,240 --> 00:17:57,679
signal handlers also have right

00:17:55,280 --> 00:18:00,799
um they have to be very careful about

00:17:57,679 --> 00:18:02,720
what they do because for example if they

00:18:00,799 --> 00:18:04,240
take a lock they must make sure that it

00:18:02,720 --> 00:18:06,559
just

00:18:04,240 --> 00:18:07,840
didn't interrupt code that already has

00:18:06,559 --> 00:18:10,240
the lock

00:18:07,840 --> 00:18:11,919
otherwise you get a deadlock and stuff

00:18:10,240 --> 00:18:13,360
like that you cannot just allocate

00:18:11,919 --> 00:18:14,960
memory at least not

00:18:13,360 --> 00:18:16,960
without ensuring that the memory

00:18:14,960 --> 00:18:19,360
allocator is not running concurrently in

00:18:16,960 --> 00:18:22,799
the non-interrupted code

00:18:19,360 --> 00:18:25,280
that's all tedious to deal with um

00:18:22,799 --> 00:18:26,799
yeah and that's where asynchronicity

00:18:25,280 --> 00:18:28,240
comes into play because

00:18:26,799 --> 00:18:30,240
if we can handle the interrupt

00:18:28,240 --> 00:18:32,640
asynchronously everything becomes much

00:18:30,240 --> 00:18:34,640
easier

00:18:32,640 --> 00:18:36,960
traditionally these are handled by

00:18:34,640 --> 00:18:39,360
signal handlers or callbacks

00:18:36,960 --> 00:18:40,160
but we can use code teams more or less

00:18:39,360 --> 00:18:43,200
to handle them

00:18:40,160 --> 00:18:46,000
and we'll see more on that later

00:18:43,200 --> 00:18:47,760
um and because we can use code genes it

00:18:46,000 --> 00:18:49,440
becomes easy to write correct and

00:18:47,760 --> 00:18:53,440
concurrent drivers

00:18:49,440 --> 00:18:55,200
so we don't necessarily have to write

00:18:53,440 --> 00:18:57,600
parallel drivers here

00:18:55,200 --> 00:18:58,720
um if we have the right abstractions it

00:18:57,600 --> 00:19:00,480
turns out that we can

00:18:58,720 --> 00:19:02,000
write drivers that can handle many

00:19:00,480 --> 00:19:05,520
concurrent requests

00:19:02,000 --> 00:19:07,840
without being parallel and that's

00:19:05,520 --> 00:19:10,559
that takes away a lot of the complexity

00:19:07,840 --> 00:19:12,559
of traditional drivers

00:19:10,559 --> 00:19:14,480
but to illustrate that maybe let's look

00:19:12,559 --> 00:19:17,679
at a

00:19:14,480 --> 00:19:19,600
traditional interrupt code

00:19:17,679 --> 00:19:21,280
yeah let's give a brief overview over

00:19:19,600 --> 00:19:25,120
that

00:19:21,280 --> 00:19:26,559
so this is already written in c plus

00:19:25,120 --> 00:19:28,480
plus way so if you're

00:19:26,559 --> 00:19:30,720
uh trying to find that in the linux

00:19:28,480 --> 00:19:33,200
kernel then you're out of luck

00:19:30,720 --> 00:19:34,720
the c code is obviously quite a bit more

00:19:33,200 --> 00:19:36,880
ugly here

00:19:34,720 --> 00:19:39,919
but let's assume that we have a standard

00:19:36,880 --> 00:19:42,240
standard mutex and a standard deck

00:19:39,919 --> 00:19:43,440
that we can use to communicate between

00:19:42,240 --> 00:19:46,559
an interrupt handler

00:19:43,440 --> 00:19:46,559
and some other code

00:19:47,039 --> 00:19:52,240
let's imagine this is a drivers for some

00:19:49,520 --> 00:19:55,280
device let's say a mouse or a keyboard

00:19:52,240 --> 00:19:56,720
or whatever whenever you press a key you

00:19:55,280 --> 00:19:58,480
get such an interrupt and

00:19:56,720 --> 00:20:00,640
we need to read certain data from the

00:19:58,480 --> 00:20:03,039
device and we need to process it

00:20:00,640 --> 00:20:04,080
and already here we have to make some

00:20:03,039 --> 00:20:05,520
assumption and that

00:20:04,080 --> 00:20:07,200
assumption is that this interrupt

00:20:05,520 --> 00:20:10,320
callback this interrupt handler

00:20:07,200 --> 00:20:12,240
is not called re-entrantly so while

00:20:10,320 --> 00:20:14,080
advanced we already assume that it

00:20:12,240 --> 00:20:17,120
cannot be started again

00:20:14,080 --> 00:20:19,360
which is something that the cpu actually

00:20:17,120 --> 00:20:22,559
needs to ensure first so that's

00:20:19,360 --> 00:20:26,400
not given for free in reality

00:20:22,559 --> 00:20:29,039
um but now we automatically have to log

00:20:26,400 --> 00:20:29,919
at least if you have a multicore cpu we

00:20:29,039 --> 00:20:32,480
do not know which

00:20:29,919 --> 00:20:33,919
threat we interrupted so we have to log

00:20:32,480 --> 00:20:36,480
because

00:20:33,919 --> 00:20:39,840
well we have to synchronize against code

00:20:36,480 --> 00:20:39,840
that runs on the different core

00:20:39,919 --> 00:20:43,520
after we've done that we can read some

00:20:41,919 --> 00:20:46,720
data from the device

00:20:43,520 --> 00:20:49,440
let's say that's done by this def dot

00:20:46,720 --> 00:20:51,360
get byte function here and we push the

00:20:49,440 --> 00:20:55,360
data into the queue

00:20:51,360 --> 00:20:58,320
um why do we do that well

00:20:55,360 --> 00:21:00,480
um we do not want to work in this signal

00:20:58,320 --> 00:21:02,000
context in this interrupt context but we

00:21:00,480 --> 00:21:04,240
want to do our main

00:21:02,000 --> 00:21:06,240
the main body of our work outside of

00:21:04,240 --> 00:21:07,200
this interrupt context so we use the

00:21:06,240 --> 00:21:10,080
queue to push

00:21:07,200 --> 00:21:11,840
data from the inter context to some

00:21:10,080 --> 00:21:13,840
context where

00:21:11,840 --> 00:21:16,000
it's easier to write correct code where

00:21:13,840 --> 00:21:19,440
we don't have to deal with complex

00:21:16,000 --> 00:21:19,440
reentrancy issues

00:21:20,240 --> 00:21:24,080
and in our toy example let's assume that

00:21:22,799 --> 00:21:27,039
we need to parse

00:21:24,080 --> 00:21:27,679
un16s right so the device gives us you

00:21:27,039 --> 00:21:30,880
and eights

00:21:27,679 --> 00:21:33,200
and we need to pass you in 16. sounds

00:21:30,880 --> 00:21:33,200
simple

00:21:34,640 --> 00:21:38,960
first thing that we need to do is we

00:21:36,159 --> 00:21:41,360
need to disable interrupts

00:21:38,960 --> 00:21:43,600
why is that because we need to ensure

00:21:41,360 --> 00:21:44,880
that we do not call into the interrupt

00:21:43,600 --> 00:21:47,360
callback

00:21:44,880 --> 00:21:47,919
again while while we're accessing the

00:21:47,360 --> 00:21:51,039
mutex

00:21:47,919 --> 00:21:52,159
otherwise we can get that deadlocks so

00:21:51,039 --> 00:21:54,080
then we have to

00:21:52,159 --> 00:21:56,000
add an implicit state machine here

00:21:54,080 --> 00:21:56,960
because we do not know the size of the

00:21:56,000 --> 00:22:00,159
queue

00:21:56,960 --> 00:22:02,080
if this there are more than two bytes or

00:22:00,159 --> 00:22:04,000
two or more bytes then we are fine and

00:22:02,080 --> 00:22:07,600
we just retry

00:22:04,000 --> 00:22:10,400
uh the operation if that's not the case

00:22:07,600 --> 00:22:11,520
uh yeah how that works is uh out of the

00:22:10,400 --> 00:22:15,200
scope here but

00:22:11,520 --> 00:22:17,919
this is not so far from a real example

00:22:15,200 --> 00:22:18,880
once that's done we can do real work we

00:22:17,919 --> 00:22:21,039
can

00:22:18,880 --> 00:22:22,400
get data from the queue we compose it to

00:22:21,039 --> 00:22:26,320
a word by just

00:22:22,400 --> 00:22:28,080
well using bit shifts and then

00:22:26,320 --> 00:22:30,000
we process the data in some device

00:22:28,080 --> 00:22:32,559
specific way right

00:22:30,000 --> 00:22:33,600
and at the end we re-enable interrupts

00:22:32,559 --> 00:22:35,679
which means that

00:22:33,600 --> 00:22:37,600
the interrupt callback can now be called

00:22:35,679 --> 00:22:40,640
again and we

00:22:37,600 --> 00:22:43,919
can finally yeah continue

00:22:40,640 --> 00:22:46,640
with other code so that's

00:22:43,919 --> 00:22:48,480
what we see here is that as soon as you

00:22:46,640 --> 00:22:50,159
have signal handlers or in this case

00:22:48,480 --> 00:22:51,360
interrupt handlers you automatically get

00:22:50,159 --> 00:22:54,640
complex locking

00:22:51,360 --> 00:22:56,720
which is really annoying so

00:22:54,640 --> 00:22:58,320
let's look at how this works if we can

00:22:56,720 --> 00:23:01,360
use async

00:22:58,320 --> 00:23:02,000
actually becomes much easier so we

00:23:01,360 --> 00:23:04,960
replace

00:23:02,000 --> 00:23:08,320
everything by async data structure so we

00:23:04,960 --> 00:23:11,200
use an async queue here

00:23:08,320 --> 00:23:12,559
we have now a co-routine which handles

00:23:11,200 --> 00:23:15,840
interrupts

00:23:12,559 --> 00:23:17,840
and that just awaits until

00:23:15,840 --> 00:23:19,520
an interrupt happens we have a sequence

00:23:17,840 --> 00:23:22,480
number that just counts how many

00:23:19,520 --> 00:23:26,240
interrupts occurred so far

00:23:22,480 --> 00:23:27,760
and now this is more or less real code

00:23:26,240 --> 00:23:31,120
for manager

00:23:27,760 --> 00:23:33,039
um our syscall api is called helix so

00:23:31,120 --> 00:23:34,720
there's a function helix the weight

00:23:33,039 --> 00:23:38,080
event and it just waits until

00:23:34,720 --> 00:23:41,200
interrupt happens um

00:23:38,080 --> 00:23:42,080
it when that hap indeed happens then we

00:23:41,200 --> 00:23:44,159
get a byte

00:23:42,080 --> 00:23:46,000
like before and push it into our async

00:23:44,159 --> 00:23:50,320
cue

00:23:46,000 --> 00:23:51,679
and well we

00:23:50,320 --> 00:23:53,919
take the sequence number of the

00:23:51,679 --> 00:23:55,600
interrupt uh to just count how many

00:23:53,919 --> 00:23:58,240
interrupts occurred so far

00:23:55,600 --> 00:24:00,320
and then the consumer becomes also much

00:23:58,240 --> 00:24:02,720
easier because the queue is now async we

00:24:00,320 --> 00:24:05,200
can consume it in a co routine

00:24:02,720 --> 00:24:06,320
um by just popping data from the queue

00:24:05,200 --> 00:24:08,480
we don't need to

00:24:06,320 --> 00:24:10,080
code our state machine explicitly here

00:24:08,480 --> 00:24:11,440
we don't need to care if the queue is

00:24:10,080 --> 00:24:14,559
empty or not

00:24:11,440 --> 00:24:16,799
because we can just wait until uh

00:24:14,559 --> 00:24:19,600
the queue is non-empty and that's how we

00:24:16,799 --> 00:24:23,840
can process data from the device here

00:24:19,600 --> 00:24:25,840
so if we compare the examples here

00:24:23,840 --> 00:24:27,200
first of all the code's more concise

00:24:25,840 --> 00:24:29,679
okay

00:24:27,200 --> 00:24:30,240
um there's no explicit state machine

00:24:29,679 --> 00:24:32,320
here the

00:24:30,240 --> 00:24:34,720
code outside of the interrupt handler

00:24:32,320 --> 00:24:38,960
does not have to

00:24:34,720 --> 00:24:41,200
um have to care about the

00:24:38,960 --> 00:24:43,440
state of the queue here because it just

00:24:41,200 --> 00:24:46,720
uses the right abstraction to just

00:24:43,440 --> 00:24:48,720
pop data and we remove the need for

00:24:46,720 --> 00:24:51,679
complex locking because

00:24:48,720 --> 00:24:52,720
uh we don't have a signal handling uh

00:24:51,679 --> 00:24:55,039
thing anymore

00:24:52,720 --> 00:24:56,960
but we can really handle interrupts in a

00:24:55,039 --> 00:24:58,720
loop because we can wait for the next

00:24:56,960 --> 00:25:02,400
interrupt to happen that's just much

00:24:58,720 --> 00:25:05,919
easier than having a signal handler

00:25:02,400 --> 00:25:08,720
okay yeah questions

00:25:05,919 --> 00:25:10,559
um there are a few questions in the chat

00:25:08,720 --> 00:25:12,840
so what compilers are available on

00:25:10,559 --> 00:25:16,240
managom

00:25:12,840 --> 00:25:17,919
um so as cross compilers gcc and clang

00:25:16,240 --> 00:25:21,200
are available

00:25:17,919 --> 00:25:23,360
um working on management i think is only

00:25:21,200 --> 00:25:25,919
gcc so far

00:25:23,360 --> 00:25:26,720
uh what sdl library are we using we are

00:25:25,919 --> 00:25:30,159
using

00:25:26,720 --> 00:25:31,120
lib std c plus plus so gcc's one the

00:25:30,159 --> 00:25:35,360
gcc's

00:25:31,120 --> 00:25:38,540
standard library the license is mit

00:25:35,360 --> 00:25:40,480
do you have a performance comparison um

00:25:38,540 --> 00:25:43,760
[Music]

00:25:40,480 --> 00:25:45,120
of what well i can say something about

00:25:43,760 --> 00:25:47,919
performance later

00:25:45,120 --> 00:25:47,919
on in the talk

00:25:49,760 --> 00:25:52,080
okay

00:25:55,360 --> 00:26:00,559
good let's continue um

00:25:58,720 --> 00:26:02,240
and what i'm going to do in the main

00:26:00,559 --> 00:26:04,640
remainder of the talk is i'm going to

00:26:02,240 --> 00:26:06,799
look at how these async syscalls

00:26:04,640 --> 00:26:08,880
actually work so i said that we have

00:26:06,799 --> 00:26:10,720
this line helix await event

00:26:08,880 --> 00:26:12,640
and it takes an interrupt it takes a

00:26:10,720 --> 00:26:15,679
sequence number so basically

00:26:12,640 --> 00:26:18,640
uh a number

00:26:15,679 --> 00:26:19,039
of an interrupt that we're looking for

00:26:18,640 --> 00:26:22,480
and

00:26:19,039 --> 00:26:23,039
it waits until until the interrupt

00:26:22,480 --> 00:26:26,320
happens

00:26:23,039 --> 00:26:29,279
in an asynchronous way and that's

00:26:26,320 --> 00:26:29,840
in nanogram an asynchronous syscall

00:26:29,279 --> 00:26:32,320
remember

00:26:29,840 --> 00:26:33,679
syscall is just something like open read

00:26:32,320 --> 00:26:39,600
write

00:26:33,679 --> 00:26:42,799
in linux and um nanogram cisco

00:26:39,600 --> 00:26:44,400
are almost all asynchronous and so how

00:26:42,799 --> 00:26:47,600
does that work

00:26:44,400 --> 00:26:50,400
um well

00:26:47,600 --> 00:26:51,360
okay also asynchronous systems exist for

00:26:50,400 --> 00:26:53,200
other stuff

00:26:51,360 --> 00:26:55,039
like ipc task management memory

00:26:53,200 --> 00:26:57,440
management and so on i'm not going to go

00:26:55,039 --> 00:27:00,559
into detail here

00:26:57,440 --> 00:27:03,679
um but i want to take a closer

00:27:00,559 --> 00:27:07,840
look at this mechanism how the

00:27:03,679 --> 00:27:07,840
asynchronous ciscos are implemented so

00:27:07,919 --> 00:27:13,600
the syscall is invoked by user mode and

00:27:10,720 --> 00:27:16,000
remember that all our drivers and so on

00:27:13,600 --> 00:27:17,840
they are invoked by user or they run in

00:27:16,000 --> 00:27:20,799
user mode

00:27:17,840 --> 00:27:22,640
and there is a step function which is

00:27:20,799 --> 00:27:23,360
now called here hell submit the weight

00:27:22,640 --> 00:27:25,600
event

00:27:23,360 --> 00:27:26,399
which initiates the asynchronous

00:27:25,600 --> 00:27:28,159
operation

00:27:26,399 --> 00:27:30,640
now remember that the asynchronous

00:27:28,159 --> 00:27:31,279
operation is initiated at some point and

00:27:30,640 --> 00:27:34,480
completes

00:27:31,279 --> 00:27:37,679
at the later point

00:27:34,480 --> 00:27:39,600
good um

00:27:37,679 --> 00:27:42,480
it takes the handle to the interrupt as

00:27:39,600 --> 00:27:45,600
input it takes a sequence that's just

00:27:42,480 --> 00:27:48,559
the sequence from the await event call

00:27:45,600 --> 00:27:48,880
and it also takes a ring buffer we'll

00:27:48,559 --> 00:27:51,120
get

00:27:48,880 --> 00:27:52,000
into that later and a context pointer

00:27:51,120 --> 00:27:55,200
which is just

00:27:52,000 --> 00:27:57,360
an opaque uh value for the kernel

00:27:55,200 --> 00:27:59,120
the color doesn't look at this at all it

00:27:57,360 --> 00:28:02,799
just passes it

00:27:59,120 --> 00:28:06,720
through the stack and earth through the

00:28:02,799 --> 00:28:09,840
well syscall mechanism and we'll see

00:28:06,720 --> 00:28:09,840
how it's used later

00:28:10,399 --> 00:28:16,000
good then okay the cisco has to perform

00:28:13,840 --> 00:28:18,159
some async work in the kernel

00:28:16,000 --> 00:28:20,480
right in this case it has to wait until

00:28:18,159 --> 00:28:22,399
an interrupt happens

00:28:20,480 --> 00:28:24,960
but it could wait for other things like

00:28:22,399 --> 00:28:27,520
it could wait until an ipc message is

00:28:24,960 --> 00:28:30,080
sent successfully or it could wait until

00:28:27,520 --> 00:28:33,279
enough memory for something is available

00:28:30,080 --> 00:28:37,039
or it could wait until a task

00:28:33,279 --> 00:28:37,039
is in a certain state or so

00:28:37,600 --> 00:28:40,960
and then the girl needs to notify user

00:28:40,000 --> 00:28:44,080
mode again

00:28:40,960 --> 00:28:46,640
after the completion of the syscall so

00:28:44,080 --> 00:28:47,279
um the girl needs to notify user mode

00:28:46,640 --> 00:28:49,679
that the

00:28:47,279 --> 00:28:51,200
work is now done obviously that has to

00:28:49,679 --> 00:28:54,240
happen somehow

00:28:51,200 --> 00:28:54,799
and in this process there are two layers

00:28:54,240 --> 00:28:56,559
involved

00:28:54,799 --> 00:28:59,520
there's the operating system and there's

00:28:56,559 --> 00:29:03,600
c plus plus and i'm going to explain in

00:28:59,520 --> 00:29:06,640
both layer how both layers how the

00:29:03,600 --> 00:29:06,640
mechanism works

00:29:06,880 --> 00:29:10,720
so let's look at the last step maybe

00:29:09,440 --> 00:29:13,919
first

00:29:10,720 --> 00:29:15,919
the notification so the kernel has some

00:29:13,919 --> 00:29:17,679
has done some work and it wants to

00:29:15,919 --> 00:29:20,960
notify user mode again

00:29:17,679 --> 00:29:22,640
that the work is done and there are

00:29:20,960 --> 00:29:24,399
different ways to do that for example on

00:29:22,640 --> 00:29:28,960
linux there's ebol

00:29:24,399 --> 00:29:30,640
uh a new mechanism on linux is io urine

00:29:28,960 --> 00:29:32,240
and windows has for example io

00:29:30,640 --> 00:29:34,159
completion ports um

00:29:32,240 --> 00:29:36,720
if you've done some async programming

00:29:34,159 --> 00:29:40,960
you probably know at least one of these

00:29:36,720 --> 00:29:41,600
technologies and what we do in nanogram

00:29:40,960 --> 00:29:44,799
is something

00:29:41,600 --> 00:29:46,960
similar to io urine we use a log-free

00:29:44,799 --> 00:29:51,360
ring buffer

00:29:46,960 --> 00:29:53,840
um so the girl needs to send something

00:29:51,360 --> 00:29:55,360
to user mode but it cannot directly call

00:29:53,840 --> 00:29:57,360
into user mode

00:29:55,360 --> 00:29:59,679
you cannot directly for example pass a

00:29:57,360 --> 00:30:02,399
pointer to user mode that would not

00:29:59,679 --> 00:30:04,159
be helpful because kernel pointers live

00:30:02,399 --> 00:30:06,640
in a different space than user mode

00:30:04,159 --> 00:30:06,640
pointers

00:30:06,720 --> 00:30:13,360
so what it does it is it uh puts

00:30:10,880 --> 00:30:14,880
an element into a ring buffer and

00:30:13,360 --> 00:30:18,000
notifies user space

00:30:14,880 --> 00:30:22,159
using this ring buffer and that's also

00:30:18,000 --> 00:30:24,240
similar to how io urine works

00:30:22,159 --> 00:30:26,240
in the best case that means that we have

00:30:24,240 --> 00:30:27,520
zero switches between the kernel and

00:30:26,240 --> 00:30:30,480
user mode

00:30:27,520 --> 00:30:32,240
to get these notifications because if

00:30:30,480 --> 00:30:33,440
there's already a notification in the

00:30:32,240 --> 00:30:35,200
ring buffer

00:30:33,440 --> 00:30:37,440
then user mode doesn't have to block at

00:30:35,200 --> 00:30:38,080
all user mod doesn't have to enter the

00:30:37,440 --> 00:30:40,640
kernel at

00:30:38,080 --> 00:30:41,919
all if there's no notification and user

00:30:40,640 --> 00:30:45,120
mode wants to block

00:30:41,919 --> 00:30:47,440
for a notification to appear

00:30:45,120 --> 00:30:48,159
well then it just does that and that

00:30:47,440 --> 00:30:50,880
costs us

00:30:48,159 --> 00:30:53,279
one entry in the kernel and that's

00:30:50,880 --> 00:30:56,720
actually our only blocking syscall

00:30:53,279 --> 00:30:59,760
more or less we block

00:30:56,720 --> 00:31:02,320
on an atomic variable we block until an

00:30:59,760 --> 00:31:05,519
atomic variable changes

00:31:02,320 --> 00:31:08,880
and uh if you've read the c plus

00:31:05,519 --> 00:31:10,880
20 papers this has been accepted

00:31:08,880 --> 00:31:12,320
into the standard as a standard

00:31:10,880 --> 00:31:14,799
operation so

00:31:12,320 --> 00:31:17,120
it was already available on linux as a

00:31:14,799 --> 00:31:17,679
futex or as the function weight on

00:31:17,120 --> 00:31:20,880
address

00:31:17,679 --> 00:31:22,159
in windows and now it's also available

00:31:20,880 --> 00:31:25,279
as a method of

00:31:22,159 --> 00:31:27,200
standard atomic data types

00:31:25,279 --> 00:31:30,000
so that's basically our only blocking

00:31:27,200 --> 00:31:33,120
operation that we ever need

00:31:30,000 --> 00:31:36,640
and i'm going to illustrate how it works

00:31:33,120 --> 00:31:38,240
um this is our wing buffer so in reality

00:31:36,640 --> 00:31:39,039
the ring buffer consists of different

00:31:38,240 --> 00:31:40,880
chunks but i'm

00:31:39,039 --> 00:31:43,279
only going to display a single chunk

00:31:40,880 --> 00:31:46,159
here the chunk mechanism is just

00:31:43,279 --> 00:31:47,279
necessary to prevent overflows so once

00:31:46,159 --> 00:31:51,679
one trunk is

00:31:47,279 --> 00:31:53,120
fully utilized then the next track needs

00:31:51,679 --> 00:31:56,159
to be used

00:31:53,120 --> 00:31:58,480
so within such a chunk of the ring

00:31:56,159 --> 00:32:00,200
buffer there are elements

00:31:58,480 --> 00:32:02,320
let's just call them elements these are

00:32:00,200 --> 00:32:04,799
notifications right

00:32:02,320 --> 00:32:06,000
these are notifications from the kernel

00:32:04,799 --> 00:32:10,399
to user space

00:32:06,000 --> 00:32:12,640
that some kind of work has been finished

00:32:10,399 --> 00:32:14,080
and how do the kernel end user space

00:32:12,640 --> 00:32:17,840
communicate here

00:32:14,080 --> 00:32:21,440
will both store a pointer

00:32:17,840 --> 00:32:24,640
and because the kernels the producer it

00:32:21,440 --> 00:32:26,640
stores a pointer that points to the

00:32:24,640 --> 00:32:28,320
that points past the last element that

00:32:26,640 --> 00:32:32,159
it wrote

00:32:28,320 --> 00:32:34,799
whereas user mode is the consumer

00:32:32,159 --> 00:32:36,159
and it stores a pointer past the last

00:32:34,799 --> 00:32:39,200
element that it

00:32:36,159 --> 00:32:42,720
consumed already okay

00:32:39,200 --> 00:32:43,679
which means that both pointers always go

00:32:42,720 --> 00:32:46,000
to the right

00:32:43,679 --> 00:32:47,120
because the kernel keeps producing more

00:32:46,000 --> 00:32:50,480
elements

00:32:47,120 --> 00:32:54,159
and the user mode

00:32:50,480 --> 00:32:56,399
keeps consuming more elements

00:32:54,159 --> 00:32:57,360
and how's that done in c plus well

00:32:56,399 --> 00:33:00,480
that's uh

00:32:57,360 --> 00:33:02,080
there's a bit of a a bit of log free

00:33:00,480 --> 00:33:03,919
programming necessary but it's not

00:33:02,080 --> 00:33:06,000
actually too hard

00:33:03,919 --> 00:33:07,840
and i'm not going to show the code but

00:33:06,000 --> 00:33:09,039
i'm going to show the data structures

00:33:07,840 --> 00:33:11,840
here

00:33:09,039 --> 00:33:13,360
so first of all the chunk needs to be

00:33:11,840 --> 00:33:17,519
represented by

00:33:13,360 --> 00:33:20,399
well just an atomic integer more or less

00:33:17,519 --> 00:33:22,240
and that into that atomic integer the

00:33:20,399 --> 00:33:25,360
kernel stores

00:33:22,240 --> 00:33:29,039
the uh it's right pointer just the

00:33:25,360 --> 00:33:29,039
pointer that's visualize the path

00:33:29,120 --> 00:33:34,799
and then user mode uses the weight

00:33:32,320 --> 00:33:35,440
function on this atomic variable to wait

00:33:34,799 --> 00:33:38,960
until

00:33:35,440 --> 00:33:42,559
the kernel more data into the

00:33:38,960 --> 00:33:44,399
chunk and then it can update its own

00:33:42,559 --> 00:33:48,559
pointers and tweak the data from the

00:33:44,399 --> 00:33:50,880
ring buffer each element is delimited by

00:33:48,559 --> 00:33:54,000
a length

00:33:50,880 --> 00:33:56,159
and now here

00:33:54,000 --> 00:33:58,080
we see that this void pointer this

00:33:56,159 --> 00:34:01,120
context reappears where

00:33:58,080 --> 00:34:03,519
this opec value uh

00:34:01,120 --> 00:34:06,240
that i mentioned before so when we

00:34:03,519 --> 00:34:09,280
initiate the async syscall

00:34:06,240 --> 00:34:11,359
we pass a user-defined value to the

00:34:09,280 --> 00:34:14,480
syscall

00:34:11,359 --> 00:34:16,720
and then when the kernel informs us that

00:34:14,480 --> 00:34:18,240
the score is done we get back this

00:34:16,720 --> 00:34:21,119
user-defined value

00:34:18,240 --> 00:34:22,960
and we can use that for example to point

00:34:21,119 --> 00:34:26,159
to some c plus plus class

00:34:22,960 --> 00:34:29,599
with some c plus plus object um

00:34:26,159 --> 00:34:33,280
and uh yeah we'll use that

00:34:29,599 --> 00:34:36,159
to uh continue our asynchronous code so

00:34:33,280 --> 00:34:39,280
for example to resume some coating or to

00:34:36,159 --> 00:34:42,159
yeah resume some asynchronous algorithm

00:34:39,280 --> 00:34:42,800
and okay each element also has to store

00:34:42,159 --> 00:34:45,040
some

00:34:42,800 --> 00:34:46,480
cisco specific results for example error

00:34:45,040 --> 00:34:49,119
codes or

00:34:46,480 --> 00:34:52,639
yeah number of transferred bytes and ipc

00:34:49,119 --> 00:34:52,639
messages or whatever

00:34:52,720 --> 00:34:58,960
all right that's the os

00:34:56,079 --> 00:34:59,359
layer and i'm not going to explain that

00:34:58,960 --> 00:35:02,560
in

00:34:59,359 --> 00:35:03,520
more detail here so now i'm going to

00:35:02,560 --> 00:35:05,119
look at the c

00:35:03,520 --> 00:35:06,560
plus layer because this is the c plus

00:35:05,119 --> 00:35:09,599
plus conference and you're more

00:35:06,560 --> 00:35:14,400
interested in the c plus plus probably

00:35:09,599 --> 00:35:14,400
so how does it work on the c plus layer

00:35:14,839 --> 00:35:20,240
um we need some

00:35:17,280 --> 00:35:21,599
representation for async primitives in c

00:35:20,240 --> 00:35:24,160
plus plus

00:35:21,599 --> 00:35:24,640
um and such an async primitives for

00:35:24,160 --> 00:35:27,920
example

00:35:24,640 --> 00:35:27,920
helix the way to end

00:35:29,599 --> 00:35:33,280
yeah so maybe the obvious choice is

00:35:32,560 --> 00:35:36,320
available

00:35:33,280 --> 00:35:39,599
so awaitable is this concept here

00:35:36,320 --> 00:35:42,160
it makes a type co-awaitable

00:35:39,599 --> 00:35:43,520
and to do that we have some available

00:35:42,160 --> 00:35:46,480
object a

00:35:43,520 --> 00:35:49,680
and uh there are three operations await

00:35:46,480 --> 00:35:51,599
ready a way to spend and await with you

00:35:49,680 --> 00:35:53,440
it's not actually so important what they

00:35:51,599 --> 00:35:55,200
do and i'm not going to explain it

00:35:53,440 --> 00:35:56,880
because they are probably better talks

00:35:55,200 --> 00:36:00,079
on how co-routines work

00:35:56,880 --> 00:36:02,960
but the crucial point is that a weight

00:36:00,079 --> 00:36:04,000
suspend needs a coating handle that's

00:36:02,960 --> 00:36:08,000
basically

00:36:04,000 --> 00:36:10,480
just a protein and that means that

00:36:08,000 --> 00:36:12,160
if we use this available concept as our

00:36:10,480 --> 00:36:14,480
building block then

00:36:12,160 --> 00:36:16,480
we need to be in a code team to wait for

00:36:14,480 --> 00:36:19,599
the completion

00:36:16,480 --> 00:36:21,040
of awaitable operations okay

00:36:19,599 --> 00:36:23,760
because otherwise you cannot get a

00:36:21,040 --> 00:36:27,200
coating handle

00:36:23,760 --> 00:36:30,400
and uh yeah let's see if that is an

00:36:27,200 --> 00:36:32,560
issue or not um

00:36:30,400 --> 00:36:35,040
but in any case it means that every

00:36:32,560 --> 00:36:36,079
consumer of async operations needs to be

00:36:35,040 --> 00:36:40,720
a co-routine

00:36:36,079 --> 00:36:42,640
and yeah we'll see why this is an issue

00:36:40,720 --> 00:36:44,400
first of all i'm not going to bash core

00:36:42,640 --> 00:36:46,079
routines here so core teams are great

00:36:44,400 --> 00:36:47,920
you want to write almost all of your

00:36:46,079 --> 00:36:50,160
async code and core routines

00:36:47,920 --> 00:36:51,839
my rule of thumb this year that 90

00:36:50,160 --> 00:36:53,440
percent of your async code should be

00:36:51,839 --> 00:36:56,800
coroutines otherwise

00:36:53,440 --> 00:36:58,400
you're likely doing something strange

00:36:56,800 --> 00:37:00,320
and they work really well for high level

00:36:58,400 --> 00:37:00,880
logic but i'm claiming that they do not

00:37:00,320 --> 00:37:04,480
work

00:37:00,880 --> 00:37:04,480
that well for low level logic

00:37:05,440 --> 00:37:09,040
and that's because scorpions have some

00:37:07,200 --> 00:37:11,520
overheads so

00:37:09,040 --> 00:37:12,960
now i'm looking at an example of an

00:37:11,520 --> 00:37:15,200
async cue

00:37:12,960 --> 00:37:16,160
remember that we've used an async queue

00:37:15,200 --> 00:37:20,079
before in

00:37:16,160 --> 00:37:22,400
an example and now i'm going to look at

00:37:20,079 --> 00:37:23,599
how we can implement such a pop back

00:37:22,400 --> 00:37:25,680
operation

00:37:23,599 --> 00:37:26,800
of an async queue and actually i'm going

00:37:25,680 --> 00:37:28,880
to cheat

00:37:26,800 --> 00:37:30,960
because i'm going to assume that i

00:37:28,880 --> 00:37:33,839
already have a pop back

00:37:30,960 --> 00:37:36,320
operation that can be cancelled and all

00:37:33,839 --> 00:37:40,160
that i want to do is construct a public

00:37:36,320 --> 00:37:40,160
operation that cannot be cancelled

00:37:40,480 --> 00:37:44,320
my cancer table operation should return

00:37:43,200 --> 00:37:46,640
an optional t

00:37:44,320 --> 00:37:50,079
because well in case it is cancelled it

00:37:46,640 --> 00:37:52,880
just returns nothing

00:37:50,079 --> 00:37:53,440
my non-cancerable operation should

00:37:52,880 --> 00:37:57,280
return

00:37:53,440 --> 00:37:59,040
a t a task t so an asynchronous result

00:37:57,280 --> 00:38:02,400
of type t

00:37:59,040 --> 00:38:05,200
and how we're going to do that is um

00:38:02,400 --> 00:38:06,880
we have this cancellation token which

00:38:05,200 --> 00:38:09,040
somehow controls when

00:38:06,880 --> 00:38:10,640
the operation is cancelled and we're

00:38:09,040 --> 00:38:11,839
going to pass a cancellation token that

00:38:10,640 --> 00:38:15,200
just does nothing

00:38:11,839 --> 00:38:18,320
to the original function

00:38:15,200 --> 00:38:20,400
um we're going to co-await the result oh

00:38:18,320 --> 00:38:22,160
that's something that is broken on this

00:38:20,400 --> 00:38:24,079
slide so we want to co-await the

00:38:22,160 --> 00:38:27,440
pop-back operation

00:38:24,079 --> 00:38:30,839
and then we want to move out

00:38:27,440 --> 00:38:34,400
the result out of this optional r

00:38:30,839 --> 00:38:37,839
here we know that there is a optional

00:38:34,400 --> 00:38:39,760
value available because well the

00:38:37,839 --> 00:38:41,040
cancellation token is never cancelled

00:38:39,760 --> 00:38:43,599
here

00:38:41,040 --> 00:38:46,160
so that works and it looks quite simple

00:38:43,599 --> 00:38:48,880
but there's an obvious drawback

00:38:46,160 --> 00:38:49,839
if you dive a bit more into how code

00:38:48,880 --> 00:38:52,079
genes work

00:38:49,839 --> 00:38:53,280
because code genes potentially allocate

00:38:52,079 --> 00:38:56,240
protein frames

00:38:53,280 --> 00:38:58,839
not in all cases so there are great

00:38:56,240 --> 00:39:01,839
optimizations that can avoid this

00:38:58,839 --> 00:39:03,760
but um

00:39:01,839 --> 00:39:05,040
it can happen in certain cases that we

00:39:03,760 --> 00:39:07,119
want that we need

00:39:05,040 --> 00:39:09,040
to allocate a coordinating frame so we

00:39:07,119 --> 00:39:10,640
need to heap allocate something

00:39:09,040 --> 00:39:14,000
and there are certainly situations where

00:39:10,640 --> 00:39:16,160
we don't want to hip allocate

00:39:14,000 --> 00:39:17,839
example if we have async algorithms and

00:39:16,160 --> 00:39:20,000
we'll take a look at async

00:39:17,839 --> 00:39:21,920
algorithms in a few minutes then it's

00:39:20,000 --> 00:39:26,400
not desirable to

00:39:21,920 --> 00:39:28,640
make every async algorithm allocatable

00:39:26,400 --> 00:39:31,760
so i'm claiming that awaitable is not

00:39:28,640 --> 00:39:34,800
the right primitive here

00:39:31,760 --> 00:39:35,760
um and what we're going to do instead in

00:39:34,800 --> 00:39:38,720
our os

00:39:35,760 --> 00:39:41,440
or what we do in our ios is we borrow

00:39:38,720 --> 00:39:43,520
stuff from the executor's proposal

00:39:41,440 --> 00:39:45,040
we borrow senders and receivers these

00:39:43,520 --> 00:39:47,599
are concepts and

00:39:45,040 --> 00:39:48,880
i'll give a brief overview in on the

00:39:47,599 --> 00:39:50,320
next two slides

00:39:48,880 --> 00:39:52,240
they are not related to networking

00:39:50,320 --> 00:39:54,839
despite the name so please don't be

00:39:52,240 --> 00:39:57,440
confused about that

00:39:54,839 --> 00:39:57,839
um and i have to post a disclaimer so

00:39:57,440 --> 00:39:59,599
what

00:39:57,839 --> 00:40:01,040
what we do here is an independent

00:39:59,599 --> 00:40:02,720
implementation it's

00:40:01,040 --> 00:40:04,079
not a standards proposal so there are

00:40:02,720 --> 00:40:06,640
certain differences

00:40:04,079 --> 00:40:08,640
but yet the credit of these ideas is

00:40:06,640 --> 00:40:12,160
certainly

00:40:08,640 --> 00:40:14,000
certainly goes to sg1 and not 12 plus

00:40:12,160 --> 00:40:16,160
but of course the credit to buck for

00:40:14,000 --> 00:40:19,680
bucks still goes to us

00:40:16,160 --> 00:40:21,920
um yeah so what are senders and

00:40:19,680 --> 00:40:24,880
receivers

00:40:21,920 --> 00:40:26,640
we have two concepts per async operation

00:40:24,880 --> 00:40:28,319
in this context and i'm going to give

00:40:26,640 --> 00:40:31,839
the informal definition so a

00:40:28,319 --> 00:40:31,839
sender is the first concept

00:40:33,520 --> 00:40:37,440
a sender is a class that knows how to

00:40:35,440 --> 00:40:38,000
initiate an async operation so it's

00:40:37,440 --> 00:40:41,200
something like

00:40:38,000 --> 00:40:42,800
a pre-baked function call think of it as

00:40:41,200 --> 00:40:45,040
a tuple of arguments so

00:40:42,800 --> 00:40:46,960
nothing really special it's just a

00:40:45,040 --> 00:40:49,440
function and i know how to invoke the

00:40:46,960 --> 00:40:49,440
function

00:40:50,000 --> 00:40:54,079
then i have some operation object and

00:40:51,920 --> 00:40:54,640
that's just a class that represents the

00:40:54,079 --> 00:40:58,000
state

00:40:54,640 --> 00:40:58,000
of an async operation

00:40:58,720 --> 00:41:02,960
okay and that's something i need to

00:41:00,160 --> 00:41:06,000
implement for each primitive

00:41:02,960 --> 00:41:09,119
async operation and then for

00:41:06,000 --> 00:41:11,200
each consumer of async operations i need

00:41:09,119 --> 00:41:12,720
to implement a receiver

00:41:11,200 --> 00:41:14,960
and that's a class that knows how to

00:41:12,720 --> 00:41:16,880
resume after an async operation

00:41:14,960 --> 00:41:20,480
completes so it's

00:41:16,880 --> 00:41:22,880
basically a callback on steroids

00:41:20,480 --> 00:41:26,720
and nothing more so all these three

00:41:22,880 --> 00:41:29,280
things are really simple conceptually

00:41:26,720 --> 00:41:30,079
they just have names that makes make

00:41:29,280 --> 00:41:32,880
them

00:41:30,079 --> 00:41:34,640
sound like well make them sound more

00:41:32,880 --> 00:41:37,760
complicated

00:41:34,640 --> 00:41:40,960
uh at least if you uh haven't uh

00:41:37,760 --> 00:41:43,680
looked at them deeply yet so more

00:41:40,960 --> 00:41:46,000
details can be found in david holman's

00:41:43,680 --> 00:41:47,599
and eric nieble's talk from last year's

00:41:46,000 --> 00:41:49,280
cppcon

00:41:47,599 --> 00:41:50,960
if you're interested in these topics i

00:41:49,280 --> 00:41:53,920
really advise you to

00:41:50,960 --> 00:41:53,920
watch that talk

00:41:54,160 --> 00:41:57,440
good i'm going to explain sanders and

00:41:56,079 --> 00:42:00,880
receivers now in

00:41:57,440 --> 00:42:03,839
in one slide and hopefully that works

00:42:00,880 --> 00:42:05,920
so we have a center s and we have a

00:42:03,839 --> 00:42:09,119
receiver r

00:42:05,920 --> 00:42:10,560
and we proceed in three steps

00:42:09,119 --> 00:42:12,480
first of all we need to construct the

00:42:10,560 --> 00:42:16,079
operation object

00:42:12,480 --> 00:42:18,640
and that happens by calling a method

00:42:16,079 --> 00:42:20,880
called connect so it connects a sender

00:42:18,640 --> 00:42:22,480
and a receiver so it takes these two

00:42:20,880 --> 00:42:25,839
objects as input

00:42:22,480 --> 00:42:26,560
and outputs in operation object wise

00:42:25,839 --> 00:42:28,960
that's

00:42:26,560 --> 00:42:30,079
interesting usually the sender and

00:42:28,960 --> 00:42:32,800
receiver are just

00:42:30,079 --> 00:42:34,720
movable objects they they store some

00:42:32,800 --> 00:42:36,720
data and they can be moved around but

00:42:34,720 --> 00:42:40,319
the operation

00:42:36,720 --> 00:42:42,880
is something that cannot be moved and

00:42:40,319 --> 00:42:45,280
why can't it be moved because at some

00:42:42,880 --> 00:42:47,440
point the operation needs to complete

00:42:45,280 --> 00:42:49,920
and for that we usually need a pointer

00:42:47,440 --> 00:42:50,560
to the operation so the pointer must not

00:42:49,920 --> 00:42:54,400
change

00:42:50,560 --> 00:42:54,400
otherwise we run into problems

00:42:55,040 --> 00:42:58,400
okay then this does not really start the

00:42:57,680 --> 00:43:02,720
operation

00:42:58,400 --> 00:43:03,920
yet um to start the operation we call a

00:43:02,720 --> 00:43:07,520
function called start

00:43:03,920 --> 00:43:09,440
that's not really uh surprising either

00:43:07,520 --> 00:43:10,960
and now the operation does some async

00:43:09,440 --> 00:43:13,440
work and

00:43:10,960 --> 00:43:15,760
when it's done it calls a function

00:43:13,440 --> 00:43:19,119
called set value on the receiver

00:43:15,760 --> 00:43:21,599
and passes some value uh potentially

00:43:19,119 --> 00:43:23,599
passes some value to the receiver that's

00:43:21,599 --> 00:43:26,480
how our callback works and that's our

00:43:23,599 --> 00:43:29,839
third step

00:43:26,480 --> 00:43:31,760
good um yeah you see this is really

00:43:29,839 --> 00:43:33,839
simple there are a lot of objects

00:43:31,760 --> 00:43:36,079
involved and

00:43:33,839 --> 00:43:38,560
without taking a close look it might

00:43:36,079 --> 00:43:43,520
seem a bit complicated but

00:43:38,560 --> 00:43:45,359
if you well if you

00:43:43,520 --> 00:43:48,720
consider these concepts more deeply they

00:43:45,359 --> 00:43:48,720
really make a lot of sense

00:43:50,240 --> 00:43:53,280
and what does this allow us to do first

00:43:52,560 --> 00:43:56,319
of all it

00:43:53,280 --> 00:43:57,520
allows us to write zero overhead async

00:43:56,319 --> 00:43:59,680
algorithms

00:43:57,520 --> 00:44:01,839
so if we go back to the example of the

00:43:59,680 --> 00:44:06,480
non-cancelable

00:44:01,839 --> 00:44:08,800
pop-back what we can do now is we can

00:44:06,480 --> 00:44:10,880
write a generic algorithm let's call it

00:44:08,800 --> 00:44:13,760
async transform

00:44:10,880 --> 00:44:16,240
and what it does it it takes a another

00:44:13,760 --> 00:44:19,599
async operation so the result of

00:44:16,240 --> 00:44:19,839
pop back of the cancelable pop back is

00:44:19,599 --> 00:44:23,200
an

00:44:19,839 --> 00:44:24,240
async operation and it just applies a

00:44:23,200 --> 00:44:28,400
function to

00:44:24,240 --> 00:44:31,599
its result so we take the optional t

00:44:28,400 --> 00:44:33,520
and we move out the value and that's

00:44:31,599 --> 00:44:34,720
equivalent to the code that i've shown

00:44:33,520 --> 00:44:36,720
before

00:44:34,720 --> 00:44:39,680
only that it uses an async algorithm

00:44:36,720 --> 00:44:43,359
namely async transform instead of

00:44:39,680 --> 00:44:45,760
a coroutine examples for such algorithms

00:44:43,359 --> 00:44:47,760
are the transformer algorithm above

00:44:45,760 --> 00:44:50,079
a sequence algorithm that just calls

00:44:47,760 --> 00:44:53,359
different async steps

00:44:50,079 --> 00:44:54,160
one after the other or in operation race

00:44:53,359 --> 00:44:57,200
and cancel

00:44:54,160 --> 00:44:59,440
which i call race and cancel and

00:44:57,200 --> 00:45:01,040
that's that basically invokes a lot of

00:44:59,440 --> 00:45:03,040
async operations

00:45:01,040 --> 00:45:04,800
waits until the first one finishes and

00:45:03,040 --> 00:45:08,560
then cancels all others

00:45:04,800 --> 00:45:11,119
now these are useful building blocks and

00:45:08,560 --> 00:45:13,359
um we've also all seen that we can make

00:45:11,119 --> 00:45:15,599
use of async data structures

00:45:13,359 --> 00:45:17,359
these can also be implemented on top of

00:45:15,599 --> 00:45:21,520
standards receivers

00:45:17,359 --> 00:45:23,839
and yeah for example async queue or

00:45:21,520 --> 00:45:25,440
what is often really useful is async

00:45:23,839 --> 00:45:28,160
recurring event

00:45:25,440 --> 00:45:29,440
so that's basically an event that you

00:45:28,160 --> 00:45:32,000
can trigger and wait for

00:45:29,440 --> 00:45:33,040
multiple times it turns out that this is

00:45:32,000 --> 00:45:35,359
a really powerful

00:45:33,040 --> 00:45:38,000
abstraction similar to a condition

00:45:35,359 --> 00:45:38,000
variable

00:45:38,800 --> 00:45:42,079
so i'm going to take more questions from

00:45:41,760 --> 00:45:45,280
the

00:45:42,079 --> 00:45:46,640
chat at this point how do we install

00:45:45,280 --> 00:45:48,720
nanogun well

00:45:46,640 --> 00:45:50,960
at the end of the talk i will have a

00:45:48,720 --> 00:45:52,800
link to a github repository and

00:45:50,960 --> 00:45:55,040
we have some installation instructions

00:45:52,800 --> 00:45:56,880
there you should probably not install it

00:45:55,040 --> 00:45:58,839
on your hard drive at this point but

00:45:56,880 --> 00:46:00,240
feel free to try it out in a virtual

00:45:58,839 --> 00:46:03,680
machine

00:46:00,240 --> 00:46:05,520
um how easy would it be to write

00:46:03,680 --> 00:46:08,400
non-c plus plus applications based on

00:46:05,520 --> 00:46:12,160
this kernel api

00:46:08,400 --> 00:46:15,119
and well the kernel api is not

00:46:12,160 --> 00:46:16,160
written in c plus plus we cannot pass c

00:46:15,119 --> 00:46:20,319
plus plus

00:46:16,160 --> 00:46:20,319
objects over the kernel boundary

00:46:20,560 --> 00:46:25,520
but it's abstracted on uh well the

00:46:24,079 --> 00:46:27,920
abstractions on both sides

00:46:25,520 --> 00:46:29,599
in the kernel side on and on the user

00:46:27,920 --> 00:46:30,560
mod side they are witnessing plus plus

00:46:29,599 --> 00:46:32,319
so

00:46:30,560 --> 00:46:34,400
you would have to rewrite these

00:46:32,319 --> 00:46:36,480
abstractions you would have to rewrite

00:46:34,400 --> 00:46:39,760
for example these senders and receivers

00:46:36,480 --> 00:46:43,119
here that implement our async syscalls

00:46:39,760 --> 00:46:44,880
um yeah how easy that is i guess it

00:46:43,119 --> 00:46:45,280
depends on your language i wouldn't try

00:46:44,880 --> 00:46:48,560
to

00:46:45,280 --> 00:46:50,319
write um

00:46:48,560 --> 00:46:52,480
applications for that in a language that

00:46:50,319 --> 00:46:53,680
does not support async very well because

00:46:52,480 --> 00:46:57,119
then

00:46:53,680 --> 00:46:58,720
you're just going to well run into

00:46:57,119 --> 00:46:59,760
callback hell because everything is

00:46:58,720 --> 00:47:01,040
async and

00:46:59,760 --> 00:47:02,800
if you don't have the right tools to

00:47:01,040 --> 00:47:03,839
deal with it then it becomes really

00:47:02,800 --> 00:47:06,230
annoying to

00:47:03,839 --> 00:47:07,599
uh yeah to do that

00:47:06,230 --> 00:47:11,440
[Music]

00:47:07,599 --> 00:47:15,119
good very briefly i'm going to look

00:47:11,440 --> 00:47:15,119
uh take a look how

00:47:15,760 --> 00:47:19,280
we can actually write centers and

00:47:17,280 --> 00:47:22,240
receivers

00:47:19,280 --> 00:47:22,800
um so so far i've unexplained how they

00:47:22,240 --> 00:47:25,520
work

00:47:22,800 --> 00:47:27,359
let's look at how this looks in practice

00:47:25,520 --> 00:47:29,280
hopefully i can convince you that it's

00:47:27,359 --> 00:47:32,240
not too hard

00:47:29,280 --> 00:47:36,079
even though a bit of annoying

00:47:32,240 --> 00:47:37,920
boilerplate is required let's say

00:47:36,079 --> 00:47:39,920
let's re-implement this function helix

00:47:37,920 --> 00:47:44,000
away to end

00:47:39,920 --> 00:47:46,960
um we have some general boilerplate here

00:47:44,000 --> 00:47:48,800
and that's the implementation of the

00:47:46,960 --> 00:47:50,160
ring buffer

00:47:48,800 --> 00:47:52,480
well it's not the implementation of the

00:47:50,160 --> 00:47:53,440
ring buffer but it's how the ring buffer

00:47:52,480 --> 00:47:56,079
notifies

00:47:53,440 --> 00:47:57,440
us that some work has been done it's

00:47:56,079 --> 00:48:01,200
basically

00:47:57,440 --> 00:48:04,400
uh an unmovable class async system

00:48:01,200 --> 00:48:07,200
here and

00:48:04,400 --> 00:48:11,119
well the first two lines just delete the

00:48:07,200 --> 00:48:11,119
move operators and copy operators

00:48:11,920 --> 00:48:15,599
and then there's only a single virtual

00:48:13,760 --> 00:48:18,800
function called notify

00:48:15,599 --> 00:48:20,000
and um we assume that the ring buffer

00:48:18,800 --> 00:48:24,079
code calls this

00:48:20,000 --> 00:48:27,119
function when it's uh

00:48:24,079 --> 00:48:28,160
well when it sees a new element in the

00:48:27,119 --> 00:48:30,880
ring buffer

00:48:28,160 --> 00:48:33,119
yeah that's just how our notification

00:48:30,880 --> 00:48:35,440
mechanism works

00:48:33,119 --> 00:48:36,640
and then we need to need to code some

00:48:35,440 --> 00:48:39,680
struct

00:48:36,640 --> 00:48:42,800
to represent the result of

00:48:39,680 --> 00:48:44,640
our weight event function and how that's

00:48:42,800 --> 00:48:45,359
done is not really important but it

00:48:44,640 --> 00:48:47,440
should

00:48:45,359 --> 00:48:48,480
probably look at the data from the ring

00:48:47,440 --> 00:48:52,000
buffer

00:48:48,480 --> 00:48:55,359
for example at errors or whatever

00:48:52,000 --> 00:48:57,599
sequence numbers that are stored in this

00:48:55,359 --> 00:48:59,200
ring buffer element

00:48:57,599 --> 00:49:01,839
and it should somehow make them

00:48:59,200 --> 00:49:06,720
accessible to idiomatic c plus

00:49:01,839 --> 00:49:10,319
code okay let's assume that we have that

00:49:06,720 --> 00:49:12,640
um now we want to implement the

00:49:10,319 --> 00:49:15,200
operation object

00:49:12,640 --> 00:49:18,960
okay first of all the operational object

00:49:15,200 --> 00:49:18,960
is templated on the receiver

00:49:19,040 --> 00:49:23,760
because there's no type erasure here the

00:49:21,119 --> 00:49:26,480
receiver is just some concrete object

00:49:23,760 --> 00:49:28,160
our operation inherits from this async

00:49:26,480 --> 00:49:30,880
syscall class

00:49:28,160 --> 00:49:33,280
because uh that's how our ring buffer

00:49:30,880 --> 00:49:36,960
code will call into this operation

00:49:33,280 --> 00:49:41,440
when the ring buffer well uh

00:49:36,960 --> 00:49:44,240
notices a new element we also store

00:49:41,440 --> 00:49:45,760
um the data that we need to start the

00:49:44,240 --> 00:49:48,240
operation so we store

00:49:45,760 --> 00:49:49,119
a handle to the interrupt that we are

00:49:48,240 --> 00:49:51,680
awaiting

00:49:49,119 --> 00:49:53,520
we stored a sequence number because that

00:49:51,680 --> 00:49:55,920
was part of the previous code

00:49:53,520 --> 00:49:57,680
too and we store a handle to the ring

00:49:55,920 --> 00:49:59,119
buffer

00:49:57,680 --> 00:50:00,880
these handles are just in our

00:49:59,119 --> 00:50:03,760
implementation they are just

00:50:00,880 --> 00:50:04,800
integers so nothing special here and we

00:50:03,760 --> 00:50:06,720
store the receiver

00:50:04,800 --> 00:50:09,520
and the receiver okay we don't know what

00:50:06,720 --> 00:50:12,559
kind of type that is

00:50:09,520 --> 00:50:14,000
um yeah

00:50:12,559 --> 00:50:16,240
and now we need to implement the start

00:50:14,000 --> 00:50:17,359
function okay the start function is

00:50:16,240 --> 00:50:20,160
really simple

00:50:17,359 --> 00:50:22,400
it just calls the native system call and

00:50:20,160 --> 00:50:23,760
uh

00:50:22,400 --> 00:50:25,440
yeah a few minutes ago we had the

00:50:23,760 --> 00:50:26,880
question what about non-c plus plus code

00:50:25,440 --> 00:50:30,480
well non-c

00:50:26,880 --> 00:50:32,530
could use this raw system call but

00:50:30,480 --> 00:50:34,880
without the notification mechanism

00:50:32,530 --> 00:50:37,040
[Music]

00:50:34,880 --> 00:50:38,800
in place it will become really annoying

00:50:37,040 --> 00:50:40,960
to to use it because

00:50:38,800 --> 00:50:42,319
you can start the operation easily but

00:50:40,960 --> 00:50:44,160
you cannot easily wait for its

00:50:42,319 --> 00:50:48,000
completion

00:50:44,160 --> 00:50:51,440
and what we pass as this opec

00:50:48,000 --> 00:50:55,680
void pointer to the raw system call is

00:50:51,440 --> 00:50:58,720
this object um and we will arrange

00:50:55,680 --> 00:50:59,040
the ring buffer codes so that it uses

00:50:58,720 --> 00:51:03,520
the

00:50:59,040 --> 00:51:03,520
sys the this object

00:51:04,000 --> 00:51:12,000
to invoke our notify function okay so

00:51:09,599 --> 00:51:12,640
remember that this opaque pointer is

00:51:12,000 --> 00:51:15,119
passed

00:51:12,640 --> 00:51:16,240
into the ring buffer and then the ring

00:51:15,119 --> 00:51:19,359
buffer

00:51:16,240 --> 00:51:19,760
sees this object and just calls notify

00:51:19,359 --> 00:51:22,400
on it

00:51:19,760 --> 00:51:24,240
it casts it to a async syscall pointer

00:51:22,400 --> 00:51:27,280
and calls notify on it

00:51:24,240 --> 00:51:28,720
and that's how our execution proceeds

00:51:27,280 --> 00:51:30,960
here

00:51:28,720 --> 00:51:32,160
we invoke the setvalue function on the

00:51:30,960 --> 00:51:34,160
receiver

00:51:32,160 --> 00:51:35,680
this looks a bit different than in the

00:51:34,160 --> 00:51:37,280
diagram

00:51:35,680 --> 00:51:39,599
that i had before because we're not

00:51:37,280 --> 00:51:41,040
calling receiver.set value but we're

00:51:39,599 --> 00:51:45,119
using some

00:51:41,040 --> 00:51:48,319
um some library function here

00:51:45,119 --> 00:51:51,040
but that's just the minor detail it

00:51:48,319 --> 00:51:52,960
will invoke receiver.set value in the

00:51:51,040 --> 00:51:54,800
end

00:51:52,960 --> 00:51:56,400
good and we construct the result we

00:51:54,800 --> 00:51:59,760
construct the result and as an

00:51:56,400 --> 00:52:02,079
ingredient we just need the

00:51:59,760 --> 00:52:04,160
element of the ring buffer and we assume

00:52:02,079 --> 00:52:06,480
that the result class just takes out all

00:52:04,160 --> 00:52:08,640
data out of this element

00:52:06,480 --> 00:52:09,839
all data that it needs and that's how it

00:52:08,640 --> 00:52:13,119
works

00:52:09,839 --> 00:52:13,839
good so this operation is not really

00:52:13,119 --> 00:52:18,000
hard to

00:52:13,839 --> 00:52:20,960
code the sender is even easier the

00:52:18,000 --> 00:52:24,079
sender only stores some of that data

00:52:20,960 --> 00:52:24,880
it has a connect function a connect

00:52:24,079 --> 00:52:27,200
function is again

00:52:24,880 --> 00:52:28,240
templated on the receiver and it

00:52:27,200 --> 00:52:31,119
constructs

00:52:28,240 --> 00:52:32,559
an operation object and they await event

00:52:31,119 --> 00:52:34,240
operation

00:52:32,559 --> 00:52:36,400
which should also be templated on the

00:52:34,240 --> 00:52:39,520
receiver actually i forgot the

00:52:36,400 --> 00:52:41,599
r here um

00:52:39,520 --> 00:52:42,960
and then it just passes everything into

00:52:41,599 --> 00:52:47,040
this operation object

00:52:42,960 --> 00:52:50,240
that we've seen before good

00:52:47,040 --> 00:52:51,440
and finally the function that we

00:52:50,240 --> 00:52:53,760
actually want to call

00:52:51,440 --> 00:52:55,599
is just this evade event function here

00:52:53,760 --> 00:52:57,920
and it constructs a sender so that's

00:52:55,599 --> 00:52:59,680
just boilerplate to construct the sender

00:52:57,920 --> 00:53:01,119
as i said there's some annoying

00:52:59,680 --> 00:53:04,559
boilerplate

00:53:01,119 --> 00:53:08,880
but um yeah there's

00:53:04,559 --> 00:53:12,079
no good way around that i think

00:53:08,880 --> 00:53:13,839
in the end we have these two classes we

00:53:12,079 --> 00:53:15,839
have the operation class and we have the

00:53:13,839 --> 00:53:19,200
sender class and they're

00:53:15,839 --> 00:53:22,240
more straightforward to implement

00:53:19,200 --> 00:53:24,160
yeah and that

00:53:22,240 --> 00:53:26,559
is how our asynchronous course i

00:53:24,160 --> 00:53:29,119
implemented

00:53:26,559 --> 00:53:31,119
very quickly the full picture again so

00:53:29,119 --> 00:53:33,920
the high-level application code

00:53:31,119 --> 00:53:35,520
calls into the async syscall wrapper

00:53:33,920 --> 00:53:38,240
which is the sender

00:53:35,520 --> 00:53:41,040
which enters the kernel the kernel side

00:53:38,240 --> 00:53:41,040
of the syscall

00:53:41,119 --> 00:53:47,760
the kernel does some work and at the end

00:53:44,160 --> 00:53:53,359
posts an element to the ring buffer

00:53:47,760 --> 00:53:53,359
now the kernel wakes user space

00:53:53,599 --> 00:54:01,119
makes the ring buffer code in user space

00:53:57,680 --> 00:54:03,119
and well that completes the sender that

00:54:01,119 --> 00:54:05,520
completes the async syscall

00:54:03,119 --> 00:54:07,200
and resumes the high level core routine

00:54:05,520 --> 00:54:10,880
that's basically how it works

00:54:07,200 --> 00:54:11,359
and in all layers of the stack we're

00:54:10,880 --> 00:54:14,480
using c

00:54:11,359 --> 00:54:18,720
plus plus here

00:54:14,480 --> 00:54:22,400
at the kernel boundary we have to well

00:54:18,720 --> 00:54:23,520
somehow uh translate to raw pointers

00:54:22,400 --> 00:54:27,520
because you can pass

00:54:23,520 --> 00:54:30,160
objects to the kernel but yeah

00:54:27,520 --> 00:54:33,599
in all other layers we just use c plus

00:54:30,160 --> 00:54:35,920
plus 20 chord genes and centers

00:54:33,599 --> 00:54:35,920
good

00:54:36,960 --> 00:54:40,640
uh i'm going to talk a bit about

00:54:38,880 --> 00:54:43,040
challenges for one minute

00:54:40,640 --> 00:54:44,720
and then we'll get to some final

00:54:43,040 --> 00:54:48,240
questions

00:54:44,720 --> 00:54:51,040
so what are challenges in this model

00:54:48,240 --> 00:54:52,000
so i said that we have to modify our

00:54:51,040 --> 00:54:55,520
sender's receiver

00:54:52,000 --> 00:54:57,680
somehow our main modification is that we

00:54:55,520 --> 00:54:59,359
need synchronous fast paths we noticed

00:54:57,680 --> 00:55:01,680
that many operations only need to

00:54:59,359 --> 00:55:03,359
perform i o and slow paths

00:55:01,680 --> 00:55:06,319
for example a cache that fetches from

00:55:03,359 --> 00:55:07,440
disk it only needs to perform i o in the

00:55:06,319 --> 00:55:09,599
slow path

00:55:07,440 --> 00:55:11,200
and if we do that with centers and

00:55:09,599 --> 00:55:13,839
receivers

00:55:11,200 --> 00:55:16,559
then we invoke chains of callbacks we

00:55:13,839 --> 00:55:17,119
always invoke set value start set value

00:55:16,559 --> 00:55:19,280
start

00:55:17,119 --> 00:55:20,400
and so on and that quickly accumulates

00:55:19,280 --> 00:55:23,040
stack frames and

00:55:20,400 --> 00:55:24,079
runs out of stacks place especially if

00:55:23,040 --> 00:55:26,319
you do that in loops

00:55:24,079 --> 00:55:27,920
if you call such an async operation in a

00:55:26,319 --> 00:55:30,240
loop

00:55:27,920 --> 00:55:32,960
and it actually invokes its callback

00:55:30,240 --> 00:55:35,119
synchronously that's a huge problem

00:55:32,960 --> 00:55:37,040
so what we do is we have some additional

00:55:35,119 --> 00:55:39,440
function that does not cause the

00:55:37,040 --> 00:55:41,920
receiver to resume control flow

00:55:39,440 --> 00:55:43,599
but it just passes a value to it let's

00:55:41,920 --> 00:55:46,880
call that test value

00:55:43,599 --> 00:55:50,480
it's not really so such a

00:55:46,880 --> 00:55:52,559
innovative idea but it would be great if

00:55:50,480 --> 00:55:53,520
somehow the executor's proposal could

00:55:52,559 --> 00:55:57,440
deal with that

00:55:53,520 --> 00:56:00,480
and right now it really cannot that this

00:55:57,440 --> 00:56:04,960
is the problem if we were to adapt the

00:56:00,480 --> 00:56:04,960
standards proposal to our code

00:56:07,280 --> 00:56:11,520
so another pain point is error handling

00:56:09,839 --> 00:56:13,760
well c plus plus solves our

00:56:11,520 --> 00:56:14,640
async problems but it didn't really

00:56:13,760 --> 00:56:17,040
solve our

00:56:14,640 --> 00:56:19,200
error handling problems so we would like

00:56:17,040 --> 00:56:20,400
to use exceptions but that's not really

00:56:19,200 --> 00:56:23,440
possible

00:56:20,400 --> 00:56:27,520
uh we're using a standard or

00:56:23,440 --> 00:56:29,440
yeah we're using an expected t class

00:56:27,520 --> 00:56:30,880
or at least we want to use it and we're

00:56:29,440 --> 00:56:32,240
switching to it from the current

00:56:30,880 --> 00:56:34,720
handling code

00:56:32,240 --> 00:56:36,640
um we cannot use exceptions because

00:56:34,720 --> 00:56:37,280
exceptions are non-deterministic and

00:56:36,640 --> 00:56:39,200
that

00:56:37,280 --> 00:56:41,599
has a lot of problems if you look at

00:56:39,200 --> 00:56:44,880
side channels or real time latencies and

00:56:41,599 --> 00:56:47,119
drivers we cannot afford that

00:56:44,880 --> 00:56:48,319
run path is just so much slower than the

00:56:47,119 --> 00:56:50,160
other path so

00:56:48,319 --> 00:56:52,400
performance is not the problem uh

00:56:50,160 --> 00:56:54,480
predictability is really the problem why

00:56:52,400 --> 00:56:56,400
we cannot use exception so i'm really

00:56:54,480 --> 00:56:58,400
hoping for a solution

00:56:56,400 --> 00:56:59,520
of this problem in future c plus plus

00:56:58,400 --> 00:57:01,440
versions

00:56:59,520 --> 00:57:03,040
of course deterministic exceptions would

00:57:01,440 --> 00:57:03,920
solve this issue and that would be great

00:57:03,040 --> 00:57:07,040
but

00:57:03,920 --> 00:57:08,160
it doesn't seem so clear if they will

00:57:07,040 --> 00:57:11,359
actually

00:57:08,160 --> 00:57:12,720
uh well be integrated in a standard or

00:57:11,359 --> 00:57:17,520
not

00:57:12,720 --> 00:57:20,000
good some conclusions um

00:57:17,520 --> 00:57:21,520
mainstream os's don't handle async very

00:57:20,000 --> 00:57:24,720
well

00:57:21,520 --> 00:57:26,559
very few operations are entirely async

00:57:24,720 --> 00:57:27,680
and common fallbacks to blocking code

00:57:26,559 --> 00:57:31,040
exists in

00:57:27,680 --> 00:57:32,880
oss and designing for async from the

00:57:31,040 --> 00:57:35,680
ground up is necessary to

00:57:32,880 --> 00:57:37,359
utilize modern hardware because well

00:57:35,680 --> 00:57:40,400
we've seen that these

00:57:37,359 --> 00:57:42,000
hardware devices can handle many

00:57:40,400 --> 00:57:42,960
concurrent requests so we need some

00:57:42,000 --> 00:57:46,319
technology

00:57:42,960 --> 00:57:46,319
to exploit that

00:57:46,720 --> 00:57:50,480
yeah c plus 20 on the other hand is well

00:57:49,599 --> 00:57:53,200
suited for this

00:57:50,480 --> 00:57:54,079
async low level code our main tools are

00:57:53,200 --> 00:57:56,480
co routines

00:57:54,079 --> 00:57:57,200
for high level code for application

00:57:56,480 --> 00:57:59,920
logic for

00:57:57,200 --> 00:58:01,440
driver law j kernel logic and so on

00:57:59,920 --> 00:58:03,359
sanders and receivers as

00:58:01,440 --> 00:58:04,559
building blocks as zero overhead

00:58:03,359 --> 00:58:07,839
abstractions

00:58:04,559 --> 00:58:08,400
and async algorithms to compose them in

00:58:07,839 --> 00:58:11,599
a

00:58:08,400 --> 00:58:13,920
zero overhead way

00:58:11,599 --> 00:58:16,000
then given these tools it becomes really

00:58:13,920 --> 00:58:17,200
easy to write async code by default

00:58:16,000 --> 00:58:20,480
which is great

00:58:17,200 --> 00:58:22,559
async code is now not harder to write

00:58:20,480 --> 00:58:24,319
anymore than synchronous code and

00:58:22,559 --> 00:58:26,640
there's basically no

00:58:24,319 --> 00:58:28,720
point to write synchronous code for this

00:58:26,640 --> 00:58:32,480
os

00:58:28,720 --> 00:58:34,640
um as a huge benefit

00:58:32,480 --> 00:58:36,480
writing correct and concurrent drivers

00:58:34,640 --> 00:58:39,200
becomes much easier

00:58:36,480 --> 00:58:41,359
and that's really a good takeaway

00:58:39,200 --> 00:58:44,160
message here

00:58:41,359 --> 00:58:45,920
good we have a website i don't want to

00:58:44,160 --> 00:58:46,480
spend too much words on that and i want

00:58:45,920 --> 00:58:48,480
to thank

00:58:46,480 --> 00:58:50,160
all our contributors which still fit on

00:58:48,480 --> 00:58:53,359
the slide um

00:58:50,160 --> 00:58:57,200
probably hopefully not

00:58:53,359 --> 00:59:01,119
yeah hopefully

00:58:57,200 --> 00:59:03,680
yeah good

00:59:01,119 --> 00:59:05,119
finally let's look at the last question

00:59:03,680 --> 00:59:07,280
so

00:59:05,119 --> 00:59:09,200
does every application effectively have

00:59:07,280 --> 00:59:12,480
to be c plus plus

00:59:09,200 --> 00:59:14,079
uh say i want to or need to use python

00:59:12,480 --> 00:59:15,680
or c or whatever in user space and

00:59:14,079 --> 00:59:20,640
perform io

00:59:15,680 --> 00:59:22,400
well we have an emulation of blocking io

00:59:20,640 --> 00:59:24,400
and you can use that but of course

00:59:22,400 --> 00:59:28,480
you're not going to get the benefit of

00:59:24,400 --> 00:59:30,799
of async io so

00:59:28,480 --> 00:59:32,400
the emulation works but of course for

00:59:30,799 --> 00:59:34,160
example if you're running a database

00:59:32,400 --> 00:59:35,599
server or a web server and you want to

00:59:34,160 --> 00:59:38,319
take advantage of these highly

00:59:35,599 --> 00:59:40,880
concurrent async io

00:59:38,319 --> 00:59:41,760
operations then you need to write that

00:59:40,880 --> 00:59:46,480
in an async

00:59:41,760 --> 00:59:50,480
language what's the goal is it mostly

00:59:46,480 --> 00:59:51,359
academic uh or to replace mainstream oss

00:59:50,480 --> 00:59:54,799
so

00:59:51,359 --> 00:59:56,960
um it's pragmatic so it's not academic

00:59:54,799 --> 00:59:57,920
the goal is not to do some leaning edge

00:59:56,960 --> 01:00:01,040
research but it's

00:59:57,920 --> 01:00:03,599
uh meant to be a pragmatic project

01:00:01,040 --> 01:00:05,760
for example for servers that need these

01:00:03,599 --> 01:00:09,599
async operations

01:00:05,760 --> 01:00:13,040
um yeah and that's basically its goal

01:00:09,599 --> 01:00:17,040
good i think we've run out of time for

01:00:13,040 --> 01:00:20,240
questions so yeah thank you all

01:00:17,040 --> 01:00:29,839
for listening and all right that

01:00:20,240 --> 01:00:29,839
concludes the talk

01:00:42,640 --> 01:00:44,720

YouTube URL: https://www.youtube.com/watch?v=BzwpdOpNFpQ


