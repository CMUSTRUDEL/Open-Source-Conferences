Title: Neo4J and Python Playing with graph data
Publication date: 2014-10-13
Playlist: PyCon India 2014
Description: 
	
Captions: 
	00:00:00,000 --> 00:00:16,490
I by audible

00:00:18,960 --> 00:00:24,720
so hi guys i am solo and i am going to

00:00:22,169 --> 00:00:28,050
talk about neo4j and graph databases in

00:00:24,720 --> 00:00:30,109
general so before we start let's have a

00:00:28,050 --> 00:00:33,120
show of hands how many of us here have

00:00:30,109 --> 00:00:38,040
speed with working with graph databases

00:00:33,120 --> 00:00:41,610
or neo4j in particular okay quite a few

00:00:38,040 --> 00:00:44,940
and how many of draft databases in the

00:00:41,610 --> 00:00:49,589
future rate I think that is the whole

00:00:44,940 --> 00:00:57,929
audience so rest because this stock will

00:00:49,589 --> 00:01:01,260
have some each one of us here start with

00:00:57,929 --> 00:01:09,210
basics of neo4j and we'll be moving on a

00:01:01,260 --> 00:01:11,009
little advanced concepts so so the plan

00:01:09,210 --> 00:01:12,780
of the talk for today would be something

00:01:11,009 --> 00:01:16,320
like this we'll start with we'll start

00:01:12,780 --> 00:01:18,330
with graphs and no sequel databases will

00:01:16,320 --> 00:01:19,830
move on to new for J and cipher a bit of

00:01:18,330 --> 00:01:22,619
explanation for those of us who are new

00:01:19,830 --> 00:01:25,860
to neo4j will then take a look at pi/2

00:01:22,619 --> 00:01:28,470
new and the rest api that neo4j exposes

00:01:25,860 --> 00:01:31,290
and finally we look at use cases and

00:01:28,470 --> 00:01:35,490
demos to what cool stuff we can do with

00:01:31,290 --> 00:01:40,590
neo4j at the back end so how did this

00:01:35,490 --> 00:01:44,719
all start about decades back relational

00:01:40,590 --> 00:01:47,100
data Tilly ruled the database world and

00:01:44,719 --> 00:01:50,549
pre-new was to store data in the form of

00:01:47,100 --> 00:01:55,079
columns rows tables and when you

00:01:50,549 --> 00:01:56,969
encountered highly complex when you

00:01:55,079 --> 00:02:01,500
encountered highly complex data highly

00:01:56,969 --> 00:02:04,460
connected data since that you had what

00:02:01,500 --> 00:02:04,460
to use primary key

00:02:12,130 --> 00:02:18,410
hello yeah yes so you had to use a lot

00:02:16,130 --> 00:02:21,740
of joints and that was all that you

00:02:18,410 --> 00:02:24,110
could do with relational data plus he

00:02:21,740 --> 00:02:26,180
added disadvantage was if your data

00:02:24,110 --> 00:02:27,710
structure change at some time there was

00:02:26,180 --> 00:02:30,770
no option to include that in your

00:02:27,710 --> 00:02:32,570
database you had to completely reinstate

00:02:30,770 --> 00:02:34,750
a new database migrate your data to it

00:02:32,570 --> 00:02:37,370
and then you could change the structure

00:02:34,750 --> 00:02:40,940
so that's really horrible for

00:02:37,370 --> 00:02:42,860
interconnected data right so the

00:02:40,940 --> 00:02:45,980
universe balances itself as it said as I

00:02:42,860 --> 00:02:47,780
said the new SQL world came into

00:02:45,980 --> 00:02:51,080
existence to encounter these problems

00:02:47,780 --> 00:02:54,140
and it was not not just a single

00:02:51,080 --> 00:02:57,170
database no sequel addressed problems of

00:02:54,140 --> 00:02:58,970
all existing data types so whenever you

00:02:57,170 --> 00:03:01,120
see a different type of data springing

00:02:58,970 --> 00:03:03,680
up a new database came into existence

00:03:01,120 --> 00:03:05,920
today no sequel databases are divided

00:03:03,680 --> 00:03:09,020
into four types we have key value stores

00:03:05,920 --> 00:03:11,720
they store what they say in the form of

00:03:09,020 --> 00:03:13,430
keys and values then you have column

00:03:11,720 --> 00:03:14,630
family when your values are divided into

00:03:13,430 --> 00:03:17,269
multiple when you can have multiple

00:03:14,630 --> 00:03:19,730
values for a single key you have to we

00:03:17,269 --> 00:03:22,010
can separate them into columns then you

00:03:19,730 --> 00:03:23,570
have document stores when one entity has

00:03:22,010 --> 00:03:25,760
a lot of key values associated with it

00:03:23,570 --> 00:03:28,660
that's called a document and you can

00:03:25,760 --> 00:03:32,000
associate it with a relative key and

00:03:28,660 --> 00:03:34,970
finally you have graph databases you

00:03:32,000 --> 00:03:37,160
must be wondering where in this graph no

00:03:34,970 --> 00:03:40,940
sequel later my sequel databases would

00:03:37,160 --> 00:03:43,070
lie so this is where you lie now what

00:03:40,940 --> 00:03:46,610
this graph depicts is a comparison of

00:03:43,070 --> 00:03:48,860
data size and data complexity so key

00:03:46,610 --> 00:03:51,530
value stores can handle a huge amount of

00:03:48,860 --> 00:03:53,150
data but the relative complexity of data

00:03:51,530 --> 00:03:56,150
that you can process there is quite low

00:03:53,150 --> 00:03:57,920
whereas graph databases the high the

00:03:56,150 --> 00:04:01,310
handle of very high complex complexity

00:03:57,920 --> 00:04:02,690
of data but the amount of data is that

00:04:01,310 --> 00:04:04,220
you can handle there is why it quite low

00:04:02,690 --> 00:04:06,080
this is because there is a trade-off

00:04:04,220 --> 00:04:07,760
between the traversals that you perform

00:04:06,080 --> 00:04:12,049
on a graph database and the amount of

00:04:07,760 --> 00:04:14,239
data that you have so why do we actually

00:04:12,049 --> 00:04:15,890
use no sequel databases first thing is

00:04:14,239 --> 00:04:17,630
elastic scaling so if you had a

00:04:15,890 --> 00:04:20,030
relational database with you and you and

00:04:17,630 --> 00:04:21,979
suddenly your traffic increased and you

00:04:20,030 --> 00:04:23,710
started collecting a lot of data the

00:04:21,979 --> 00:04:26,949
only way you could scale initially

00:04:23,710 --> 00:04:29,199
was to scale up that means you throw a

00:04:26,949 --> 00:04:31,840
lot of RAM you threw in more disk space

00:04:29,199 --> 00:04:33,970
you're you shifted your code should your

00:04:31,840 --> 00:04:35,620
code database to a larger server and

00:04:33,970 --> 00:04:38,860
that probably should have solved your

00:04:35,620 --> 00:04:41,139
problems but then elastic scaling deals

00:04:38,860 --> 00:04:43,889
with not just scaling up but scaling out

00:04:41,139 --> 00:04:46,120
and that's what no sequel databases do

00:04:43,889 --> 00:04:48,340
so when you have to scale a no sequel

00:04:46,120 --> 00:04:51,340
database you can add more nodes where

00:04:48,340 --> 00:04:52,900
your data gets distributed over them so

00:04:51,340 --> 00:04:54,430
you don't have to worry about what

00:04:52,900 --> 00:04:55,720
happens to the existing data you can

00:04:54,430 --> 00:05:00,940
just keep adding nodes to your cluster

00:04:55,720 --> 00:05:03,910
and they scale out very well plus the

00:05:00,940 --> 00:05:05,410
new Finder called big data I don't know

00:05:03,910 --> 00:05:07,930
actually what people understand by it

00:05:05,410 --> 00:05:10,509
but big data is not just storing and

00:05:07,930 --> 00:05:12,190
handling large amounts of data it's also

00:05:10,509 --> 00:05:15,340
about efficiently processing large

00:05:12,190 --> 00:05:17,199
amounts of data so we have something

00:05:15,340 --> 00:05:18,970
called transactions which are small

00:05:17,199 --> 00:05:21,280
units of computation that you perform on

00:05:18,970 --> 00:05:23,199
a data set and that's what no sequel

00:05:21,280 --> 00:05:25,240
database is handled really well on very

00:05:23,199 --> 00:05:26,530
large data sets you know you not only

00:05:25,240 --> 00:05:29,530
can store large data sets you can

00:05:26,530 --> 00:05:31,060
process them really well plus it's

00:05:29,530 --> 00:05:32,740
economical you don't need specialized

00:05:31,060 --> 00:05:35,139
servers and specialized firmware to run

00:05:32,740 --> 00:05:37,570
such databases you can add a cluster of

00:05:35,139 --> 00:05:39,580
personal computers old machines Pentium

00:05:37,570 --> 00:05:42,610
machines and then set up a very

00:05:39,580 --> 00:05:44,020
efficient data cluster plus you don't

00:05:42,610 --> 00:05:46,360
need database administrators people

00:05:44,020 --> 00:05:49,110
specially trained in handling databases

00:05:46,360 --> 00:05:52,240
anybody can handle a no sequel database

00:05:49,110 --> 00:05:55,169
then there are flexible data models will

00:05:52,240 --> 00:05:58,240
come to data models later in this talk

00:05:55,169 --> 00:06:00,310
so for people here who have less

00:05:58,240 --> 00:06:03,130
exposure to graphs let's introduce and

00:06:00,310 --> 00:06:04,810
brush up a few concepts of graphs so

00:06:03,130 --> 00:06:06,130
where do we see graphs graphs are

00:06:04,810 --> 00:06:08,259
basically existent all around us

00:06:06,130 --> 00:06:12,070
wherever any scenario you take there's a

00:06:08,259 --> 00:06:13,719
graph that you can visualize there so

00:06:12,070 --> 00:06:18,219
anything which you here with the word

00:06:13,719 --> 00:06:21,490
social is a graph scenario so web sites

00:06:18,219 --> 00:06:24,699
like Twitter Facebook LinkedIn even once

00:06:21,490 --> 00:06:26,500
like SlideShare group on foursquare so

00:06:24,699 --> 00:06:29,440
all that's mentioned in this graph are

00:06:26,500 --> 00:06:30,969
actually graph scenarios it may they may

00:06:29,440 --> 00:06:33,810
or may not be using graph data based at

00:06:30,969 --> 00:06:35,970
the end but they are graph scenarios

00:06:33,810 --> 00:06:38,080
maps

00:06:35,970 --> 00:06:42,520
how many of us have done projects on

00:06:38,080 --> 00:06:45,250
maps great so personally I have done a

00:06:42,520 --> 00:06:49,150
project on maps where I had to divert an

00:06:45,250 --> 00:06:52,000
ambulance through bangalore traffic yeah

00:06:49,150 --> 00:06:54,280
so in that case it is really difficult

00:06:52,000 --> 00:06:56,350
if you have your map data stored in

00:06:54,280 --> 00:06:58,180
relational databases you have to have a

00:06:56,350 --> 00:07:00,730
graph which will efficiently process

00:06:58,180 --> 00:07:03,389
paths and routes and shortest distances

00:07:00,730 --> 00:07:06,250
so maps is a very good example where

00:07:03,389 --> 00:07:07,810
graph databases can be used I'll be

00:07:06,250 --> 00:07:09,729
talking about a graph database example

00:07:07,810 --> 00:07:13,540
at the end and we see how queries can be

00:07:09,729 --> 00:07:16,030
performed on that logistics that's

00:07:13,540 --> 00:07:19,150
another division that uses graph

00:07:16,030 --> 00:07:21,370
databases very in on a large scale so

00:07:19,150 --> 00:07:23,350
when you have to route your packages

00:07:21,370 --> 00:07:26,200
from one place to the other you have to

00:07:23,350 --> 00:07:28,900
think about the economy of it and the

00:07:26,200 --> 00:07:31,210
time about it so your your package has

00:07:28,900 --> 00:07:32,919
to reach your customer in the minimum

00:07:31,210 --> 00:07:35,020
possible time and the shortest possible

00:07:32,919 --> 00:07:37,690
package shortest possible route so that

00:07:35,020 --> 00:07:40,240
you you bear less expenses right so

00:07:37,690 --> 00:07:42,220
companies like FedEx and UPS they have

00:07:40,240 --> 00:07:45,700
integrated graph databases for

00:07:42,220 --> 00:07:47,820
calculating shortest distances and they

00:07:45,700 --> 00:07:51,700
are really successful as you know

00:07:47,820 --> 00:07:53,530
Airlines follow the same concept in the

00:07:51,700 --> 00:07:55,960
same tradition they need to find the

00:07:53,530 --> 00:07:59,590
shortest distances because expenses are

00:07:55,960 --> 00:08:00,970
huge and Airlines companies there are

00:07:59,590 --> 00:08:02,800
some graphs that we come across every

00:08:00,970 --> 00:08:04,840
day but we tend to overlook them as

00:08:02,800 --> 00:08:08,020
graph scenarios so when you open a

00:08:04,840 --> 00:08:10,570
linkedin page there are topics which

00:08:08,020 --> 00:08:12,760
show you lie which recommend to you news

00:08:10,570 --> 00:08:14,860
that you would probably like reading so

00:08:12,760 --> 00:08:16,030
as you can see this is on my page I

00:08:14,860 --> 00:08:18,550
don't know why I would like to read this

00:08:16,030 --> 00:08:22,150
news but yes it recommended me that I

00:08:18,550 --> 00:08:23,860
just got fired so these are places where

00:08:22,150 --> 00:08:26,889
graphs are used extensively in the back

00:08:23,860 --> 00:08:28,389
end plus there are columns which you can

00:08:26,889 --> 00:08:30,970
see in a lot of sites like Facebook

00:08:28,389 --> 00:08:32,409
LinkedIn Twitter where people are

00:08:30,970 --> 00:08:34,150
recommended to you friends are

00:08:32,409 --> 00:08:36,430
recommended to you to follow to add as

00:08:34,150 --> 00:08:38,380
friends so these are also a prime

00:08:36,430 --> 00:08:39,940
example of graphs where you are

00:08:38,380 --> 00:08:42,969
connected to a lot of other people and

00:08:39,940 --> 00:08:44,140
algorithms are used to find out who are

00:08:42,969 --> 00:08:46,510
the people that you would like to

00:08:44,140 --> 00:08:48,970
interact with so we'll also see a

00:08:46,510 --> 00:08:50,889
example of a dating site in the end

00:08:48,970 --> 00:08:52,899
if you enter a name you get possible

00:08:50,889 --> 00:08:56,529
matches of people who you can you would

00:08:52,899 --> 00:08:59,920
like to date when you visit video sites

00:08:56,529 --> 00:09:02,649
like IMDb or Netflix there you get

00:08:59,920 --> 00:09:04,389
movies or series or video

00:09:02,649 --> 00:09:06,490
recommendations based on what you have

00:09:04,389 --> 00:09:08,350
what you have already watched or what

00:09:06,490 --> 00:09:10,870
your friends or people like you have

00:09:08,350 --> 00:09:12,910
watched so these are if you think about

00:09:10,870 --> 00:09:15,550
it the graph scale they are a lot of

00:09:12,910 --> 00:09:17,439
complex traversals are going on relating

00:09:15,550 --> 00:09:19,389
you to the content you've watched

00:09:17,439 --> 00:09:21,160
relating you to other people and the

00:09:19,389 --> 00:09:23,019
content they have watched and that's a

00:09:21,160 --> 00:09:26,370
big problem when you try to solve these

00:09:23,019 --> 00:09:29,350
through joins on a relational database

00:09:26,370 --> 00:09:30,879
apart from that graph scenarios there

00:09:29,350 --> 00:09:34,060
are a few others like recommendation

00:09:30,879 --> 00:09:37,720
engines fraud analysis you can analyze

00:09:34,060 --> 00:09:39,939
impact on networks plus security firms

00:09:37,720 --> 00:09:42,220
like JP Morgan and all they analyze

00:09:39,939 --> 00:09:44,560
debts and investments through graph

00:09:42,220 --> 00:09:47,439
databases also there's this file

00:09:44,560 --> 00:09:49,750
permissions and signify permissions on

00:09:47,439 --> 00:09:53,769
servers and file systems which can be

00:09:49,750 --> 00:09:57,100
implemented using graphs so why do we

00:09:53,769 --> 00:09:58,750
prefer graphs today because graphs have

00:09:57,100 --> 00:10:00,610
been around for a long time but graph

00:09:58,750 --> 00:10:03,309
databases are coming into existence a

00:10:00,610 --> 00:10:05,019
lot in the past four to five years so

00:10:03,309 --> 00:10:08,649
this is because data is becoming highly

00:10:05,019 --> 00:10:11,110
complex most of us spend today I use I

00:10:08,649 --> 00:10:12,730
heard about a group who are making an

00:10:11,110 --> 00:10:15,490
app that can find how much time you're

00:10:12,730 --> 00:10:17,259
spending on a social network so if

00:10:15,490 --> 00:10:18,610
that's going to be a business that means

00:10:17,259 --> 00:10:21,339
we are really spending a lot of time on

00:10:18,610 --> 00:10:23,019
social networks and think about them the

00:10:21,339 --> 00:10:24,519
data that we are generating every click

00:10:23,019 --> 00:10:27,129
every like every comment that we are

00:10:24,519 --> 00:10:31,120
making we are actually creating a part

00:10:27,129 --> 00:10:32,889
in the graph and multiply that by 365 so

00:10:31,120 --> 00:10:35,410
how much graph data we generating in a

00:10:32,889 --> 00:10:37,000
year and the companies they have to

00:10:35,410 --> 00:10:39,699
process this they have to find out

00:10:37,000 --> 00:10:42,790
information about you for you for others

00:10:39,699 --> 00:10:45,040
from that data so connectivity of data

00:10:42,790 --> 00:10:47,050
is highly increasing and and that is

00:10:45,040 --> 00:10:49,870
making it more and more complex plus

00:10:47,050 --> 00:10:51,279
it's semi structured there's not a fixed

00:10:49,870 --> 00:10:53,790
set of operations that are you do every

00:10:51,279 --> 00:10:56,199
day it can be anything you could like

00:10:53,790 --> 00:10:58,449
earlier used to have forms that Hadassah

00:10:56,199 --> 00:11:00,699
fixed set of fields now you can have a

00:10:58,449 --> 00:11:02,620
text box which can be passed at the back

00:11:00,699 --> 00:11:04,720
end so the data it's not

00:11:02,620 --> 00:11:06,580
mandatory to have fixed columns or fixed

00:11:04,720 --> 00:11:10,060
fields in your data anymore because they

00:11:06,580 --> 00:11:12,430
are semi structured so the concept of

00:11:10,060 --> 00:11:15,760
graphs actually dates back to 1735 where

00:11:12,430 --> 00:11:16,900
did this all start why graphs so how

00:11:15,760 --> 00:11:19,930
many of us have heard about seven

00:11:16,900 --> 00:11:22,330
bridges of königsberg problem okay so

00:11:19,930 --> 00:11:24,880
everybody is for those who haven't heard

00:11:22,330 --> 00:11:26,830
just a brief so the anecdote goes that

00:11:24,880 --> 00:11:29,770
there's a place called königsberg in

00:11:26,830 --> 00:11:32,110
russia and it is separated into two

00:11:29,770 --> 00:11:35,230
parts by a river and there are two

00:11:32,110 --> 00:11:36,670
islands in the river and these islands

00:11:35,230 --> 00:11:40,300
are connected to each other and the

00:11:36,670 --> 00:11:41,890
mainland through seven bridges so they

00:11:40,300 --> 00:11:43,980
came up with a weird problem that you

00:11:41,890 --> 00:11:47,170
had to work walk through the entire land

00:11:43,980 --> 00:11:48,880
by crossing these bridges covering the

00:11:47,170 --> 00:11:50,860
two islands and the two mainland paths

00:11:48,880 --> 00:11:53,650
but you have to cross every bridge

00:11:50,860 --> 00:11:56,080
exactly once and this problem caught the

00:11:53,650 --> 00:11:59,200
attention of the genius Leonhard Euler

00:11:56,080 --> 00:12:02,110
and what he did was he proved by

00:11:59,200 --> 00:12:04,600
contradiction that this was exactly not

00:12:02,110 --> 00:12:07,060
possible if you have seven bridges you

00:12:04,600 --> 00:12:10,000
cannot cross every bridge exactly once

00:12:07,060 --> 00:12:12,100
and cover the entire land so he did it

00:12:10,000 --> 00:12:13,900
with the help of graphs the solution

00:12:12,100 --> 00:12:17,290
that he proposed was with the help of

00:12:13,900 --> 00:12:19,990
nodes and relationships and that was how

00:12:17,290 --> 00:12:22,510
graph started so for around two hundred

00:12:19,990 --> 00:12:24,460
and eighty years we just had concepts of

00:12:22,510 --> 00:12:27,060
graphs we pondered over what can we do

00:12:24,460 --> 00:12:30,580
with graphs and recent decades have seen

00:12:27,060 --> 00:12:32,650
like people have thought about let's

00:12:30,580 --> 00:12:34,750
store data in the form of graphs and

00:12:32,650 --> 00:12:37,480
that's how graph databases came into the

00:12:34,750 --> 00:12:40,030
existence so we've just been wondering

00:12:37,480 --> 00:12:42,540
for 280 years wherever we could have

00:12:40,030 --> 00:12:46,720
done the graph database part so long ago

00:12:42,540 --> 00:12:48,130
so okay so most graph databases today is

00:12:46,720 --> 00:12:51,490
store data in the form of property

00:12:48,130 --> 00:12:54,580
graphs property graph is very simple it

00:12:51,490 --> 00:12:56,140
has nodes these nodes have properties of

00:12:54,580 --> 00:12:59,620
their own the properties are nothing but

00:12:56,140 --> 00:13:01,390
key value pairs it has relationships and

00:12:59,620 --> 00:13:03,880
the relationships have properties of

00:13:01,390 --> 00:13:05,700
their own that essentially is what the

00:13:03,880 --> 00:13:08,290
entire graph database space is all about

00:13:05,700 --> 00:13:10,090
so the major building blocks of graphs

00:13:08,290 --> 00:13:11,980
were nodes relationships and properties

00:13:10,090 --> 00:13:14,470
and in recent years there's something

00:13:11,980 --> 00:13:16,420
called labels so labels were made to

00:13:14,470 --> 00:13:20,200
facilitate faster traversal of graph

00:13:16,420 --> 00:13:21,730
a label is a group of similar nodes or

00:13:20,200 --> 00:13:23,350
similar relationships so you can group a

00:13:21,730 --> 00:13:25,240
lot of entities together as a single

00:13:23,350 --> 00:13:29,139
node so your graph can have a lot of

00:13:25,240 --> 00:13:30,279
nodes which can represent people a lot

00:13:29,139 --> 00:13:32,500
of nodes which can represent companies

00:13:30,279 --> 00:13:35,130
think about a linkedin graph it can have

00:13:32,500 --> 00:13:37,630
nodes with people nodes with companies

00:13:35,130 --> 00:13:39,430
nodes with recruiters nodes with job

00:13:37,630 --> 00:13:41,920
seekers and how do you distinguish these

00:13:39,430 --> 00:13:43,570
nodes from each other you label them so

00:13:41,920 --> 00:13:46,510
when you query a particular type of node

00:13:43,570 --> 00:13:47,920
you use that label to traverse only

00:13:46,510 --> 00:13:52,209
those nodes instead of traversing the

00:13:47,920 --> 00:13:53,860
entire graph so data models for graph

00:13:52,209 --> 00:13:56,649
databases are classified into two types

00:13:53,860 --> 00:13:59,230
first is a native graph so a native

00:13:56,649 --> 00:14:01,089
graph has the data structures which

00:13:59,230 --> 00:14:05,470
inherently store data in the form of

00:14:01,089 --> 00:14:07,540
nodes and relationships whereas all the

00:14:05,470 --> 00:14:09,760
other graph databases that are not

00:14:07,540 --> 00:14:12,399
native crafts they store data in the

00:14:09,760 --> 00:14:14,980
form of tables the old SQL type tables

00:14:12,399 --> 00:14:16,990
and they use joints they use a layer of

00:14:14,980 --> 00:14:18,820
joints and aggregates to simulate graph

00:14:16,990 --> 00:14:20,170
operations so when you are actually

00:14:18,820 --> 00:14:22,240
thinking of a Trevor that you are doing

00:14:20,170 --> 00:14:24,279
a traversal on the graph at the back end

00:14:22,240 --> 00:14:28,180
somebody is already written a code to

00:14:24,279 --> 00:14:30,670
perform joins and aggregates near for j

00:14:28,180 --> 00:14:32,560
is actually a native graph so there are

00:14:30,670 --> 00:14:35,860
a lot of popular graph databases around

00:14:32,560 --> 00:14:38,290
you have Titan which is a another major

00:14:35,860 --> 00:14:40,930
player in the graph space but we'll talk

00:14:38,290 --> 00:14:44,230
about why we want to use neo4j first new

00:14:40,930 --> 00:14:46,750
for Jesus kima less property graph so

00:14:44,230 --> 00:14:49,390
just it's the same with Titan it's also

00:14:46,750 --> 00:14:51,990
no it's also a property graph it can

00:14:49,390 --> 00:14:55,180
hardly connected data very efficiently

00:14:51,990 --> 00:14:56,980
when you want to use graph databases in

00:14:55,180 --> 00:14:58,779
scenarios that have critical data like

00:14:56,980 --> 00:15:00,880
financial operations banks and other

00:14:58,779 --> 00:15:02,560
sectors you have to have fully acid

00:15:00,880 --> 00:15:04,839
transactions you cannot afford mistakes

00:15:02,560 --> 00:15:08,079
so like the scenarios we described where

00:15:04,839 --> 00:15:10,810
JP Morgan and other companies use graph

00:15:08,079 --> 00:15:13,420
databases to process financial data we

00:15:10,810 --> 00:15:16,120
cannot have non acid transactions it's

00:15:13,420 --> 00:15:18,010
fully scalable and in recent versions of

00:15:16,120 --> 00:15:19,779
neo4j we have high availability clusters

00:15:18,010 --> 00:15:22,600
we'll talk about how your ability

00:15:19,779 --> 00:15:25,480
clusters in the end it has a REST API

00:15:22,600 --> 00:15:27,490
for servers so it's easy to query an ear

00:15:25,480 --> 00:15:29,920
for Chase server at the back end you can

00:15:27,490 --> 00:15:31,510
embed your application within a JVM

00:15:29,920 --> 00:15:34,959
so new for j is basically written in

00:15:31,510 --> 00:15:37,510
java and its core API is in java so any

00:15:34,959 --> 00:15:39,579
JVM based application can use it but

00:15:37,510 --> 00:15:41,290
since python wrappers are available for

00:15:39,579 --> 00:15:46,029
it your python applications can as well

00:15:41,290 --> 00:15:48,029
use it the main advantage that neo4j has

00:15:46,029 --> 00:15:50,079
over other graph databases a cipher

00:15:48,029 --> 00:15:54,370
cipher is a query language that was

00:15:50,079 --> 00:15:56,139
designed specifically for neo4j plus new

00:15:54,370 --> 00:15:58,420
4g is a graph DB which has extensive

00:15:56,139 --> 00:16:02,230
python bindings we have to talk about

00:15:58,420 --> 00:16:04,149
Python we are at PyCon so other graph

00:16:02,230 --> 00:16:06,870
databases lack this functionality of

00:16:04,149 --> 00:16:10,120
integrating with languages like Python

00:16:06,870 --> 00:16:11,560
so let's see cipher in action we have

00:16:10,120 --> 00:16:14,709
highly cypher is a highly expressive

00:16:11,560 --> 00:16:17,260
query language it's actually a pattern

00:16:14,709 --> 00:16:18,639
matching language which reflects what

00:16:17,260 --> 00:16:20,199
you are thinking about the graph if

00:16:18,639 --> 00:16:21,699
you're thinking of matching a particular

00:16:20,199 --> 00:16:25,360
pattern you can represent that pattern

00:16:21,699 --> 00:16:27,220
in the form of a pattern so it cares

00:16:25,360 --> 00:16:31,389
about what you do rather than how you do

00:16:27,220 --> 00:16:33,250
it a basic cipher query is mentioned

00:16:31,389 --> 00:16:35,410
here so if you have two nodes and a

00:16:33,250 --> 00:16:38,680
connecting relationship you represent a

00:16:35,410 --> 00:16:40,480
cipher denoting this as one label to

00:16:38,680 --> 00:16:42,490
wear label is the label of the

00:16:40,480 --> 00:16:45,519
relationship that you are using a little

00:16:42,490 --> 00:16:46,750
more complex when you want to match a

00:16:45,519 --> 00:16:49,720
particular relationship from the graph

00:16:46,750 --> 00:16:52,720
you can define your first node as node

00:16:49,720 --> 00:16:55,149
of one ms node of two so what one and

00:16:52,720 --> 00:16:57,490
two here are when you store a node or a

00:16:55,149 --> 00:17:00,040
relationship in neo4j it internally

00:16:57,490 --> 00:17:03,550
assigns indices to that so these are the

00:17:00,040 --> 00:17:05,230
ids that neo4j provides for as you add a

00:17:03,550 --> 00:17:09,189
node or a relationship to the database

00:17:05,230 --> 00:17:14,169
it's automatically generated so you just

00:17:09,189 --> 00:17:16,270
have to say match n R M node 1 node 2

00:17:14,169 --> 00:17:18,339
and the relationship it will find your

00:17:16,270 --> 00:17:19,569
node 1 it will find your node 2 and get

00:17:18,339 --> 00:17:21,850
all the relationships that is the

00:17:19,569 --> 00:17:24,189
existing between these two nodes and it

00:17:21,850 --> 00:17:29,190
will return that relationship do you see

00:17:24,189 --> 00:17:33,070
something similar to SQL here so to make

00:17:29,190 --> 00:17:36,040
people's life's easier this syntax is

00:17:33,070 --> 00:17:41,169
inspired by SQL so you have commands

00:17:36,040 --> 00:17:43,180
like match return so I have briefly

00:17:41,169 --> 00:17:44,770
outlined the crud operations in

00:17:43,180 --> 00:17:47,560
Seifer how to create read update and

00:17:44,770 --> 00:17:49,000
delete your data so we not go into much

00:17:47,560 --> 00:17:52,060
detail of it but it's on the slide you

00:17:49,000 --> 00:17:56,080
can have a look later so like the first

00:17:52,060 --> 00:17:58,750
query here you define a / an ode n which

00:17:56,080 --> 00:18:01,840
you want the person that is the that is

00:17:58,750 --> 00:18:04,360
the label of that node you define the

00:18:01,840 --> 00:18:08,050
properties that you want name is Chuck

00:18:04,360 --> 00:18:09,850
Norris title is analyst and you return

00:18:08,050 --> 00:18:12,490
that so what it basically does it

00:18:09,850 --> 00:18:14,740
creates this entire node creates its

00:18:12,490 --> 00:18:16,900
properties and returns you the reference

00:18:14,740 --> 00:18:19,000
to that node you can also perform

00:18:16,900 --> 00:18:20,880
operations like match where you get a

00:18:19,000 --> 00:18:23,680
person which we have seen in the last

00:18:20,880 --> 00:18:25,240
node you can compare its properties so

00:18:23,680 --> 00:18:27,340
where is a clause that you used to

00:18:25,240 --> 00:18:28,570
compare properties a node name is equal

00:18:27,340 --> 00:18:31,060
to Chuck and be not name is equal to

00:18:28,570 --> 00:18:44,170
rationing and you compare them so a

00:18:31,060 --> 00:18:46,600
cannot find be sorry yeah so the update

00:18:44,170 --> 00:18:48,970
operations you start with a match where

00:18:46,600 --> 00:18:50,590
you find the node that you want to

00:18:48,970 --> 00:18:52,300
update or the relationship where you

00:18:50,590 --> 00:18:55,750
want to update and use the set command

00:18:52,300 --> 00:18:58,540
to update it for delete you just have to

00:18:55,750 --> 00:19:01,030
specify remove it's as simple as that it

00:18:58,540 --> 00:19:03,970
also has a REST API I have also outlined

00:19:01,030 --> 00:19:07,030
the rest crud operations so we use post

00:19:03,970 --> 00:19:08,860
to create a request that can create that

00:19:07,030 --> 00:19:12,220
can make nodes and relationships in your

00:19:08,860 --> 00:19:13,600
graph the it's provided as a JSON

00:19:12,220 --> 00:19:18,430
document the properties are provided

00:19:13,600 --> 00:19:20,590
this JSON document the reed is used the

00:19:18,430 --> 00:19:22,420
gate is used for read operations boot is

00:19:20,590 --> 00:19:23,980
used for update operations and delete is

00:19:22,420 --> 00:19:26,590
used for removing up for remove

00:19:23,980 --> 00:19:28,990
operations but we are here to talk about

00:19:26,590 --> 00:19:31,810
PI 2 neo today spy tonio is actually a

00:19:28,990 --> 00:19:34,590
wrapper around the rest api of neo4j

00:19:31,810 --> 00:19:37,930
it's a small library that was created by

00:19:34,590 --> 00:19:41,290
Nigel small he works at neo technologies

00:19:37,930 --> 00:19:42,940
and over the years it has grown into an

00:19:41,290 --> 00:19:45,970
amazing library that most people in the

00:19:42,940 --> 00:19:48,160
Python community use so what it actually

00:19:45,970 --> 00:19:50,080
does is you can use Python your Python

00:19:48,160 --> 00:19:52,450
powered application which is running

00:19:50,080 --> 00:19:54,190
with newer by tonio to interface with

00:19:52,450 --> 00:19:56,470
the REST API that's running atop the

00:19:54,190 --> 00:19:59,230
neo4j so you can

00:19:56,470 --> 00:20:01,510
initiate queries in Python but which are

00:19:59,230 --> 00:20:04,030
internally trans transfer transformed

00:20:01,510 --> 00:20:06,940
into rest requests and the response that

00:20:04,030 --> 00:20:08,919
you get back is again transformed by PI

00:20:06,940 --> 00:20:13,030
tonio into a format that you can read in

00:20:08,919 --> 00:20:17,350
Python so let's look at a bit of messy

00:20:13,030 --> 00:20:22,299
code so you define an instance of the

00:20:17,350 --> 00:20:24,610
graph data database service and we

00:20:22,299 --> 00:20:26,559
specify the location of our database

00:20:24,610 --> 00:20:28,720
server if you do not give anything it

00:20:26,559 --> 00:20:31,780
will by default connect to local host

00:20:28,720 --> 00:20:34,539
7474 which is the default host and port

00:20:31,780 --> 00:20:39,010
of neo4j but you can specify where your

00:20:34,539 --> 00:20:40,990
remote addresses you have opera you can

00:20:39,010 --> 00:20:44,409
use node and relationship defined in PI

00:20:40,990 --> 00:20:46,600
tonio to create a graph simultaneously

00:20:44,409 --> 00:20:49,570
so here we are actually creating five

00:20:46,600 --> 00:20:51,070
nodes and linking them together and when

00:20:49,570 --> 00:20:53,200
you execute this query a single

00:20:51,070 --> 00:20:56,380
statement that can create your entire

00:20:53,200 --> 00:20:58,179
graph if you have a larger graph and a

00:20:56,380 --> 00:20:59,740
data set with you you can write a simple

00:20:58,179 --> 00:21:01,840
Python script that can append these

00:20:59,740 --> 00:21:03,549
things together from the query and then

00:21:01,840 --> 00:21:07,990
execute it but there are even better

00:21:03,549 --> 00:21:09,490
ways to create graphs which will see the

00:21:07,990 --> 00:21:12,070
graph database object that we created

00:21:09,490 --> 00:21:14,679
before can be used for a lot of other

00:21:12,070 --> 00:21:16,780
operations it has inbuilt methods like

00:21:14,679 --> 00:21:19,780
clear which you can use to clear your

00:21:16,780 --> 00:21:22,830
entire database so try to run it on your

00:21:19,780 --> 00:21:25,600
own database and not on others databases

00:21:22,830 --> 00:21:28,030
you have to use create and delete with

00:21:25,600 --> 00:21:29,950
different types of parameters for

00:21:28,030 --> 00:21:33,280
creating and deleting notes they're also

00:21:29,950 --> 00:21:35,380
properties like delete index and find a

00:21:33,280 --> 00:21:37,210
way to find a note or a relationship you

00:21:35,380 --> 00:21:38,500
can get an index you can get an index

00:21:37,210 --> 00:21:41,110
node even perform more complex

00:21:38,500 --> 00:21:44,770
operations like getting indexed

00:21:41,110 --> 00:21:47,200
relationships you can use the inbuilt

00:21:44,770 --> 00:21:48,850
match method so you can retrieve nodes

00:21:47,200 --> 00:21:50,559
and relationships and sets of

00:21:48,850 --> 00:21:52,690
relationships so this basically returns

00:21:50,559 --> 00:21:54,039
a list when you map something it runs a

00:21:52,690 --> 00:21:57,400
list of all the matched nodes or

00:21:54,039 --> 00:22:00,730
relationships but the most used methods

00:21:57,400 --> 00:22:06,100
are get or create index get or create

00:22:00,730 --> 00:22:07,840
index nodes why this is because a neo4j

00:22:06,100 --> 00:22:10,240
when you're creating a node if you're

00:22:07,840 --> 00:22:12,970
creating nodes for two people

00:22:10,240 --> 00:22:15,160
and a node is already existing in the

00:22:12,970 --> 00:22:18,130
database for that person and you're not

00:22:15,160 --> 00:22:19,960
using illnesses so what do you think

00:22:18,130 --> 00:22:22,840
will happen it will definitely create

00:22:19,960 --> 00:22:24,670
the node again already raise an

00:22:22,840 --> 00:22:26,260
exception because if it cannot create

00:22:24,670 --> 00:22:28,630
that same node with the same properties

00:22:26,260 --> 00:22:31,270
if we create an exception so to avoid

00:22:28,630 --> 00:22:33,280
that nice and small has created a method

00:22:31,270 --> 00:22:36,309
these methods can't get or create index

00:22:33,280 --> 00:22:38,050
so if your index is not present it will

00:22:36,309 --> 00:22:42,220
be created otherwise it will be

00:22:38,050 --> 00:22:43,720
retrieved and given a pointer to but

00:22:42,220 --> 00:22:46,420
this is all about storing data in your

00:22:43,720 --> 00:22:48,130
graphs and reading from it but if graph

00:22:46,420 --> 00:22:50,020
databases were meant just to store and

00:22:48,130 --> 00:22:52,090
read from then there would be just a

00:22:50,020 --> 00:22:53,350
persistent graphs and there's no use of

00:22:52,090 --> 00:22:56,290
storing you could have just used a

00:22:53,350 --> 00:22:57,429
sequel database at the back end so one

00:22:56,290 --> 00:23:00,280
of the advanced things that we can do

00:22:57,429 --> 00:23:02,110
you can create paths when you have

00:23:00,280 --> 00:23:05,260
graphs in mind paths is what comes to

00:23:02,110 --> 00:23:09,570
you right so directly you can create a

00:23:05,260 --> 00:23:12,820
graph path by defining the nodes node

00:23:09,570 --> 00:23:15,550
named Alice Bob and Carol here and you

00:23:12,820 --> 00:23:16,990
can create a path where a nose binos see

00:23:15,550 --> 00:23:18,640
so essentially you're creating three

00:23:16,990 --> 00:23:21,730
nodes and you're joining them with two

00:23:18,640 --> 00:23:24,100
relationships direct path you can also

00:23:21,730 --> 00:23:26,500
join two parts using the inbuilt join

00:23:24,100 --> 00:23:31,540
method you can also get or create a

00:23:26,500 --> 00:23:33,550
graph database by committing it there's

00:23:31,540 --> 00:23:36,070
also advanced features like indices so

00:23:33,550 --> 00:23:38,590
internally what neo4j uses is leucine

00:23:36,070 --> 00:23:41,679
and that is a very effective in the

00:23:38,590 --> 00:23:45,040
index leucine has its own format of

00:23:41,679 --> 00:23:48,100
querying in the indices in the native

00:23:45,040 --> 00:23:51,250
graph API that neo4j provides you cannot

00:23:48,100 --> 00:23:53,770
run leucine illnesses but pi/2 new has a

00:23:51,250 --> 00:23:56,290
wrapper around leucine as well so if you

00:23:53,770 --> 00:23:59,950
see in the last part of this you can use

00:23:56,290 --> 00:24:03,820
a direct you seen query in the parameter

00:23:59,950 --> 00:24:10,660
and query your index so this is a

00:24:03,820 --> 00:24:11,679
leucine format of writing a query so we

00:24:10,660 --> 00:24:14,679
come to something called property

00:24:11,679 --> 00:24:16,870
containers most of us who have exposed

00:24:14,679 --> 00:24:18,640
who have been exposed to Python we know

00:24:16,870 --> 00:24:20,800
about containers that exist in the

00:24:18,640 --> 00:24:22,750
Python language right so these

00:24:20,800 --> 00:24:23,830
containers or you can call them

00:24:22,750 --> 00:24:27,940
collections are you

00:24:23,830 --> 00:24:31,360
used in neo4j in petronio to create

00:24:27,940 --> 00:24:32,860
nodes and relationships so what is the

00:24:31,360 --> 00:24:35,019
use of using perverts the benefit of

00:24:32,860 --> 00:24:37,450
using property containers firstly you

00:24:35,019 --> 00:24:39,399
can create advanced methods like get

00:24:37,450 --> 00:24:41,919
relationships where you can where you

00:24:39,399 --> 00:24:44,769
can encapsulate an entire traversal to

00:24:41,919 --> 00:24:48,340
give you a specific entity you can get

00:24:44,769 --> 00:24:49,960
related nodes of a given node plus you

00:24:48,340 --> 00:24:52,120
can perform boolean operations for

00:24:49,960 --> 00:24:54,940
checks there are methods like has

00:24:52,120 --> 00:24:56,649
relationship or is related to which is

00:24:54,940 --> 00:24:58,419
quite helpful when you are looping

00:24:56,649 --> 00:25:01,889
through a particular set of nodes that

00:24:58,419 --> 00:25:03,789
is returned for the relationship

00:25:01,889 --> 00:25:05,380
parameters it is defined in New

00:25:03,789 --> 00:25:08,080
fortunate relationship this is the class

00:25:05,380 --> 00:25:09,909
that holds the property container for

00:25:08,080 --> 00:25:11,860
relationships and you can have

00:25:09,909 --> 00:25:13,419
properties like start node n nodes so

00:25:11,860 --> 00:25:15,460
when it returns a relationship to you

00:25:13,419 --> 00:25:17,860
you can directly refer to the start node

00:25:15,460 --> 00:25:19,269
as dot start node similarly the type of

00:25:17,860 --> 00:25:25,149
the relationship that is present can be

00:25:19,269 --> 00:25:31,049
referred to directly but writing my

00:25:25,149 --> 00:25:33,190
tonio code in Python API poses a lot of

00:25:31,049 --> 00:25:35,639
its a lot of code to write you know

00:25:33,190 --> 00:25:39,789
we'll see an example where a small query

00:25:35,639 --> 00:25:41,710
takes about 15 to 20 lines so it's a lot

00:25:39,789 --> 00:25:44,289
Python is the language is designed for

00:25:41,710 --> 00:25:46,179
reduction of code size but we are riding

00:25:44,289 --> 00:25:49,029
a to execute a single line query we are

00:25:46,179 --> 00:25:51,279
writing 15 lines of code that's huge so

00:25:49,029 --> 00:25:55,750
recent versions of pi 2 neo have come

00:25:51,279 --> 00:25:58,450
with interface with the cipher engine so

00:25:55,750 --> 00:26:00,990
you can directly run cipher queries on

00:25:58,450 --> 00:26:03,340
top of the graph database using pi 2 neo

00:26:00,990 --> 00:26:06,549
so you must be wondering about the

00:26:03,340 --> 00:26:08,889
performance of pi 2 neo so since it's a

00:26:06,549 --> 00:26:11,620
wrapper around the rest api it is a bit

00:26:08,889 --> 00:26:14,970
slower than the native java api that is

00:26:11,620 --> 00:26:18,100
obvious so we have to do something which

00:26:14,970 --> 00:26:21,220
compensates for this delay in time that

00:26:18,100 --> 00:26:22,960
is why the pi 2 neo creators develop the

00:26:21,220 --> 00:26:24,669
interfacing with cipher cipher is

00:26:22,960 --> 00:26:26,799
extremely fast compared to the native

00:26:24,669 --> 00:26:29,440
rest api so when you integrate that with

00:26:26,799 --> 00:26:34,840
the PI to new API you can perform very

00:26:29,440 --> 00:26:36,860
fast reversals so there's a you can

00:26:34,840 --> 00:26:38,780
create transactions as well

00:26:36,860 --> 00:26:40,640
so there are two methods in which you

00:26:38,780 --> 00:26:43,010
can execute cypher queries one is by

00:26:40,640 --> 00:26:45,650
using the normal graph database service

00:26:43,010 --> 00:26:47,870
that we used in the previous code or you

00:26:45,650 --> 00:26:49,549
can directly import cipher so what

00:26:47,870 --> 00:26:52,850
cipher does is it creates a session and

00:26:49,549 --> 00:26:54,470
then starts a transaction you can append

00:26:52,850 --> 00:26:57,830
as many queries as you want here and

00:26:54,470 --> 00:26:59,780
then execute them whenever you want but

00:26:57,830 --> 00:27:02,120
it's not committed to the graph the

00:26:59,780 --> 00:27:03,799
queries are simply executed in the end

00:27:02,120 --> 00:27:06,200
when your transaction is committed you

00:27:03,799 --> 00:27:07,670
have to mention TxDOT's commit if you

00:27:06,200 --> 00:27:10,760
don't do that your transaction is rolled

00:27:07,670 --> 00:27:14,030
back so that's the beauty of it it's

00:27:10,760 --> 00:27:16,010
acid there's a classical way of doing it

00:27:14,030 --> 00:27:17,990
also you can use the graph database

00:27:16,010 --> 00:27:20,270
surface and the function called cipher

00:27:17,990 --> 00:27:22,190
query where you provide the instance of

00:27:20,270 --> 00:27:24,470
your graph database and your query and

00:27:22,190 --> 00:27:27,799
it directly execute it but this does not

00:27:24,470 --> 00:27:29,809
guarantee an acid transaction so when

00:27:27,799 --> 00:27:31,220
it's when it's critical data it's

00:27:29,809 --> 00:27:34,730
advisable to use the transaction

00:27:31,220 --> 00:27:37,130
properties when you install PI 2 neo on

00:27:34,730 --> 00:27:39,169
your systems if it's a Windows system

00:27:37,130 --> 00:27:42,049
you can directly use the PI tuner or

00:27:39,169 --> 00:27:43,280
tool through the command line and any

00:27:42,049 --> 00:27:46,490
terminal you do not need a specific

00:27:43,280 --> 00:27:48,620
shell or a interface to write queries

00:27:46,490 --> 00:27:52,640
you can directly use the Python minus M

00:27:48,620 --> 00:27:57,500
PI tuner or tool if you are on a Linux

00:27:52,640 --> 00:27:59,360
or Mac that new tool is a very good

00:27:57,500 --> 00:28:01,700
option it's a it's essentially the same

00:27:59,360 --> 00:28:03,740
thing as pi to new or tool but it's a

00:28:01,700 --> 00:28:06,590
shell script and you can directly use it

00:28:03,740 --> 00:28:08,600
to run your cipher you can export your

00:28:06,590 --> 00:28:11,809
data from that in the form of a cipher

00:28:08,600 --> 00:28:14,299
CSV or a cipher tab-separated values you

00:28:11,809 --> 00:28:18,169
can also import and export using G off

00:28:14,299 --> 00:28:21,260
which is a very good option for handling

00:28:18,169 --> 00:28:25,780
graph data plus you can run the shell of

00:28:21,260 --> 00:28:25,780
cipher directly using new tool shell

00:28:26,200 --> 00:28:31,669
neo4j has adapted a lot over the years

00:28:29,809 --> 00:28:34,190
and there are very advanced tools

00:28:31,669 --> 00:28:36,730
available with the neo4j package you

00:28:34,190 --> 00:28:39,559
have a batch inserter so when you're

00:28:36,730 --> 00:28:42,530
porting data from one database to the to

00:28:39,559 --> 00:28:44,960
neo4j and you want to do that quite fast

00:28:42,530 --> 00:28:46,780
instead of just manually typing in the

00:28:44,960 --> 00:28:49,640
batch inserter can be configured to

00:28:46,780 --> 00:28:50,630
export your entire data set to neo4j in

00:28:49,640 --> 00:28:53,090
an automated way

00:28:50,630 --> 00:28:54,740
there is high availability which has

00:28:53,090 --> 00:28:57,410
been introduced recent in recent

00:28:54,740 --> 00:28:59,260
versions so your data set your new forge

00:28:57,410 --> 00:29:02,930
a database is replicated across many

00:28:59,260 --> 00:29:07,100
machines in the cluster and each machine

00:29:02,930 --> 00:29:09,170
has its own hot cash so when you set up

00:29:07,100 --> 00:29:11,360
a new 4G in production it is advice to

00:29:09,170 --> 00:29:15,620
initially test it on a data set so that

00:29:11,360 --> 00:29:17,900
the hot caches are formed and these hot

00:29:15,620 --> 00:29:19,010
caches are like depending on where when

00:29:17,900 --> 00:29:21,890
you strike your heart cash the

00:29:19,010 --> 00:29:23,840
transactions are fast or slow so what

00:29:21,890 --> 00:29:25,880
new version restricts you from is you

00:29:23,840 --> 00:29:27,710
cannot distribute parts of your graph on

00:29:25,880 --> 00:29:29,180
two different machines you cannot store

00:29:27,710 --> 00:29:31,280
half of your graph in one and half you

00:29:29,180 --> 00:29:33,740
graph in the other you could do that

00:29:31,280 --> 00:29:35,600
theoretically but the whole point of a

00:29:33,740 --> 00:29:38,330
graph database is to perform traversals

00:29:35,600 --> 00:29:40,070
easier and faster and if you store data

00:29:38,330 --> 00:29:43,070
databases in parts across multiple

00:29:40,070 --> 00:29:44,420
servers you need to have intersection

00:29:43,070 --> 00:29:46,910
right you have to have something like I

00:29:44,420 --> 00:29:48,290
pcs to communicate between the two

00:29:46,910 --> 00:29:49,790
graphs so if you're traversing from a

00:29:48,290 --> 00:29:52,550
node on one machine to note on the other

00:29:49,790 --> 00:29:54,770
machine that takes a hell out of time so

00:29:52,550 --> 00:29:56,990
the new for high-availability cluster

00:29:54,770 --> 00:29:58,430
does is it replicates your data set

00:29:56,990 --> 00:30:00,440
across multiple machines you have the

00:29:58,430 --> 00:30:02,750
same database but different parts of the

00:30:00,440 --> 00:30:05,450
database are loaded into the memory into

00:30:02,750 --> 00:30:07,070
the cache of different machines so and

00:30:05,450 --> 00:30:09,050
there's a record kept of this so

00:30:07,070 --> 00:30:11,660
whenever you pass in a query to the

00:30:09,050 --> 00:30:14,750
system it finds out those parts of the

00:30:11,660 --> 00:30:17,900
database where the required component is

00:30:14,750 --> 00:30:20,810
in the cash and you can traverse that

00:30:17,900 --> 00:30:22,760
very fast plus there are built-in online

00:30:20,810 --> 00:30:24,530
backup tools so most new fuzzy clusters

00:30:22,760 --> 00:30:27,020
today have a separate server in which

00:30:24,530 --> 00:30:28,430
real-time backup happens so whenever a

00:30:27,020 --> 00:30:29,810
node is updated our relationship is

00:30:28,430 --> 00:30:32,390
updated it is reflected across in the

00:30:29,810 --> 00:30:37,010
back of node the back of node is not

00:30:32,390 --> 00:30:38,510
used for queries plus it has HTTPS

00:30:37,010 --> 00:30:43,970
support so when you are using a REST API

00:30:38,510 --> 00:30:45,260
you can use HTTPS when you deploy new

00:30:43,970 --> 00:30:47,420
for gene production there are a lot more

00:30:45,260 --> 00:30:49,790
required than just basic traversals or

00:30:47,420 --> 00:30:51,440
storage of data so a company called

00:30:49,790 --> 00:30:53,570
graph aware has developed a neo4j

00:30:51,440 --> 00:30:55,880
framework where there are additional

00:30:53,570 --> 00:30:58,430
tools and modifications to make neo4j

00:30:55,880 --> 00:31:00,920
even more faster so you have a library

00:30:58,430 --> 00:31:02,900
called graph unit it is used for unit

00:31:00,920 --> 00:31:04,500
testing new 4G applications you have

00:31:02,900 --> 00:31:06,930
libraries for performance testing

00:31:04,500 --> 00:31:09,210
an api testing so how well is your api

00:31:06,930 --> 00:31:11,520
connected with neo4j you can test that

00:31:09,210 --> 00:31:13,620
you have batch transaction tools and

00:31:11,520 --> 00:31:17,490
transaction event tools plus some other

00:31:13,620 --> 00:31:21,480
goodies in that let us look at a few

00:31:17,490 --> 00:31:22,770
examples of neo4j let us run so first

00:31:21,480 --> 00:31:25,190
example that i will show you is a dating

00:31:22,770 --> 00:31:28,560
site and a few queries that we can

00:31:25,190 --> 00:31:31,100
perform on this dating site and next we

00:31:28,560 --> 00:31:31,100
will go to a map

00:31:40,930 --> 00:31:52,920
is it visible to is it visible to

00:31:42,700 --> 00:31:52,920
everybody now

00:31:58,179 --> 00:32:03,220
okay so this is what the neo4j interface

00:32:01,149 --> 00:32:05,490
looks like this is a relatively new

00:32:03,220 --> 00:32:08,679
interface earlier they used to use the

00:32:05,490 --> 00:32:10,509
legacy interface so this was actually

00:32:08,679 --> 00:32:13,809
pretty good I personally like it there

00:32:10,509 --> 00:32:16,119
are tools here which can reflect your

00:32:13,809 --> 00:32:17,789
notes properties relationships and it

00:32:16,119 --> 00:32:20,590
gives you a beautiful demonstration of

00:32:17,789 --> 00:32:21,549
notes and relationships with time when

00:32:20,590 --> 00:32:23,470
you're creating them when you're

00:32:21,549 --> 00:32:25,419
deleting them it also gives you a pretty

00:32:23,470 --> 00:32:33,159
good idea about the database space that

00:32:25,419 --> 00:32:36,580
you are using so since we are short on

00:32:33,159 --> 00:32:40,299
time I'll explain the parts that I have

00:32:36,580 --> 00:32:41,830
put in the neo4j notebook so initially

00:32:40,299 --> 00:32:46,840
just like I said you create a new

00:32:41,830 --> 00:32:48,070
photograph database object let us look

00:32:46,840 --> 00:32:51,480
at the cipher first before we look at

00:32:48,070 --> 00:32:51,480
the PI 2 neo code

00:32:57,360 --> 00:33:03,000
so what are we trying to do in this

00:32:59,160 --> 00:33:06,360
cipher code we have a node where you

00:33:03,000 --> 00:33:08,220
specify a name and we try to match a

00:33:06,360 --> 00:33:13,140
given pattern to find the people who you

00:33:08,220 --> 00:33:15,299
are likely to date so every person has

00:33:13,140 --> 00:33:17,070
some interests and every person is

00:33:15,299 --> 00:33:18,770
looking for some qualities in the other

00:33:17,070 --> 00:33:20,880
person the person who he wants to date

00:33:18,770 --> 00:33:22,260
so we are looking for common

00:33:20,880 --> 00:33:24,750
intersection between these two

00:33:22,260 --> 00:33:27,990
properties so we define a node n which

00:33:24,750 --> 00:33:31,110
can be any person we see what interests

00:33:27,990 --> 00:33:34,500
does n have so n has some interests and

00:33:31,110 --> 00:33:38,000
we also see that the someone that we are

00:33:34,500 --> 00:33:40,080
looking for has the same interests so

00:33:38,000 --> 00:33:41,690
essentially this line is matching the

00:33:40,080 --> 00:33:45,169
common interest between two people and

00:33:41,690 --> 00:33:47,700
this is extended over the entire graph

00:33:45,169 --> 00:33:50,010
apart from that to make it a little more

00:33:47,700 --> 00:33:52,590
complex we also see in the same pattern

00:33:50,010 --> 00:33:55,710
that the someone should live in the same

00:33:52,590 --> 00:33:59,130
city as n lives in so this is a single

00:33:55,710 --> 00:34:09,899
line query right when you execute this

00:33:59,130 --> 00:34:13,020
on the database you get a visualization

00:34:09,899 --> 00:34:18,780
so the analysts who are using it must be

00:34:13,020 --> 00:34:20,760
really happy you also get a tabular

00:34:18,780 --> 00:34:22,679
representation where you can check out

00:34:20,760 --> 00:34:25,230
the name of the city and the person and

00:34:22,679 --> 00:34:28,940
the information about the person that is

00:34:25,230 --> 00:34:28,940
that who you are likely to date right

00:34:30,500 --> 00:34:38,369
the same query let's see what how my two

00:34:33,690 --> 00:34:40,919
new handles it so you create initially

00:34:38,369 --> 00:34:42,330
the database instance you get the graph

00:34:40,919 --> 00:34:46,260
node of the person you're looking for

00:34:42,330 --> 00:34:49,950
this is the n then you get all the

00:34:46,260 --> 00:34:52,530
relationships so you list and match the

00:34:49,950 --> 00:34:55,200
nodes that start with n and half the

00:34:52,530 --> 00:34:56,609
relationship typist has so you can see

00:34:55,200 --> 00:35:00,720
that we are doing everything in parts

00:34:56,609 --> 00:35:02,580
you cannot do it in a single query so

00:35:00,720 --> 00:35:04,080
this will return and I'm just printing

00:35:02,580 --> 00:35:07,650
the top five year you this will return

00:35:04,080 --> 00:35:09,500
in the form of relationships and this is

00:35:07,650 --> 00:35:12,660
a rest

00:35:09,500 --> 00:35:14,880
addressed response as you can see so

00:35:12,660 --> 00:35:16,880
this is clearly evident that pie to neo

00:35:14,880 --> 00:35:19,950
is a wrapper around the rest interface

00:35:16,880 --> 00:35:23,160
then you calculate the interests out of

00:35:19,950 --> 00:35:25,050
all these relationships you create a

00:35:23,160 --> 00:35:27,570
loop that checks one of the common

00:35:25,050 --> 00:35:32,910
interests between me and the person I am

00:35:27,570 --> 00:35:36,630
looking for so you get the same interest

00:35:32,910 --> 00:35:39,150
to people these are nodes you again

00:35:36,630 --> 00:35:42,450
check for the city separately where they

00:35:39,150 --> 00:35:44,340
live in and you find an intersection

00:35:42,450 --> 00:35:46,430
between the city that I live in and the

00:35:44,340 --> 00:35:49,500
city that the other person lives in and

00:35:46,430 --> 00:35:51,780
finally you transform them into sets and

00:35:49,500 --> 00:35:54,780
get a common list the intersection of

00:35:51,780 --> 00:35:56,310
these two when you print them you get

00:35:54,780 --> 00:36:00,570
the names of all the people that you are

00:35:56,310 --> 00:36:01,980
likely to date so you can see the amount

00:36:00,570 --> 00:36:06,720
of effort that you put into just

00:36:01,980 --> 00:36:08,010
simulate a single cipher query now if

00:36:06,720 --> 00:36:09,869
you were to execute this in the form of

00:36:08,010 --> 00:36:11,850
cipher it just takes a single

00:36:09,869 --> 00:36:14,460
transaction event you take the

00:36:11,850 --> 00:36:17,190
transaction perform the cipher query and

00:36:14,460 --> 00:36:18,990
execute it and you get the records this

00:36:17,190 --> 00:36:20,580
is returned in the former record where

00:36:18,990 --> 00:36:23,270
each record contains all the information

00:36:20,580 --> 00:36:25,470
about the person that you're looking for

00:36:23,270 --> 00:36:32,760
you see the name you see the city they

00:36:25,470 --> 00:36:34,820
belong to similarly the other method

00:36:32,760 --> 00:36:38,430
that we mentioned of non-transactional

00:36:34,820 --> 00:36:40,500
execution of cipher queries so you just

00:36:38,430 --> 00:36:41,970
form a query string this can be

00:36:40,500 --> 00:36:45,570
dynamically found four different types

00:36:41,970 --> 00:36:47,520
of queries you can just execute it using

00:36:45,570 --> 00:36:50,430
query not execute so I've just printed

00:36:47,520 --> 00:36:53,280
the type here so that you can see what

00:36:50,430 --> 00:36:56,310
type of variables it returns so when you

00:36:53,280 --> 00:36:58,050
form the query it's a new for J dot

00:36:56,310 --> 00:37:01,260
cipher query just forms a query does not

00:36:58,050 --> 00:37:04,040
execute it it is of the form of cipher

00:37:01,260 --> 00:37:06,840
query so they have a class cipher query

00:37:04,040 --> 00:37:09,810
when you execute it it returns as cipher

00:37:06,840 --> 00:37:11,810
results and to iterate over that results

00:37:09,810 --> 00:37:14,970
you have to use a method called stream

00:37:11,810 --> 00:37:16,770
where for each record in the stream you

00:37:14,970 --> 00:37:18,210
process and find out the relative

00:37:16,770 --> 00:37:19,890
position so record of zero will give you

00:37:18,210 --> 00:37:23,359
the name record of one will give you any

00:37:19,890 --> 00:37:23,359
other property that exists in that node

00:37:23,430 --> 00:37:31,990
so this is the list of all the

00:37:25,630 --> 00:37:35,190
properties that it has returned so this

00:37:31,990 --> 00:37:35,190
is another query that I'm running here

00:37:36,930 --> 00:37:44,589
so this is actually a complex a little

00:37:42,400 --> 00:37:48,579
more complex and this is in the line of

00:37:44,589 --> 00:37:51,670
a recommendation so what we are doing

00:37:48,579 --> 00:37:55,150
here is it starts in the same way as the

00:37:51,670 --> 00:37:58,270
previous query you take the node any

00:37:55,150 --> 00:38:00,040
node of a person you check with city he

00:37:58,270 --> 00:38:01,540
lives in and find all the people who

00:38:00,040 --> 00:38:04,540
live in the same city you check the

00:38:01,540 --> 00:38:07,390
orientation of the person person who we

00:38:04,540 --> 00:38:13,060
likes to date he must not be of the same

00:38:07,390 --> 00:38:15,520
gender and you also check that the

00:38:13,060 --> 00:38:18,040
person has once the properties that the

00:38:15,520 --> 00:38:19,300
other person has and the person has the

00:38:18,040 --> 00:38:21,700
properties of that the other person

00:38:19,300 --> 00:38:24,970
wants so you are actually checking for

00:38:21,700 --> 00:38:26,890
compatibility then you return the

00:38:24,970 --> 00:38:31,510
distinct names of the cities and the

00:38:26,890 --> 00:38:34,089
name of the person you collect them and

00:38:31,510 --> 00:38:35,200
you return the top pin so you count all

00:38:34,089 --> 00:38:36,970
the attributes you count all the

00:38:35,200 --> 00:38:38,319
requirements and check the degree so if

00:38:36,970 --> 00:38:40,450
there are four properties matching

00:38:38,319 --> 00:38:43,359
between you and me then we can date so

00:38:40,450 --> 00:38:45,160
that's a thing that you're calculating

00:38:43,359 --> 00:38:50,910
in this return statement and you limit

00:38:45,160 --> 00:38:50,910
it by 10 if you execute the square here

00:38:59,900 --> 00:39:05,400
so you can see all the you can define

00:39:03,570 --> 00:39:07,500
the format you want it to be returned in

00:39:05,400 --> 00:39:09,660
so the name of the city from which the

00:39:07,500 --> 00:39:11,670
person is the name of the person in the

00:39:09,660 --> 00:39:13,440
name of the interests that I have and

00:39:11,670 --> 00:39:15,330
the person likes and the name of the

00:39:13,440 --> 00:39:19,560
interests that the person has then I

00:39:15,330 --> 00:39:21,840
like the number of matching

00:39:19,560 --> 00:39:23,220
characteristics and the number of the

00:39:21,840 --> 00:39:24,330
number of matching characteristics that

00:39:23,220 --> 00:39:28,050
I want and the number of magic

00:39:24,330 --> 00:39:34,230
characteristics that are present so this

00:39:28,050 --> 00:39:36,060
is just random data so don't judge it so

00:39:34,230 --> 00:39:38,160
these are the kind of recommendation so

00:39:36,060 --> 00:39:39,630
you can use it for product catalogs if

00:39:38,160 --> 00:39:42,090
you are if you're running an e-commerce

00:39:39,630 --> 00:39:44,190
website you can traverse the previous

00:39:42,090 --> 00:39:45,960
history graph of the person and check

00:39:44,190 --> 00:39:48,650
for products that the person would like

00:39:45,960 --> 00:39:50,970
and display them on your website in life

00:39:48,650 --> 00:39:56,820
let us also take an example of a map

00:39:50,970 --> 00:39:59,570
data so we have a map database we just

00:39:56,820 --> 00:39:59,570
need to connect to it

00:40:13,519 --> 00:40:18,049
so let's see what type of operations you

00:40:15,739 --> 00:40:21,019
can map we can perform when your map

00:40:18,049 --> 00:40:22,729
data is stored in the home of a graph so

00:40:21,019 --> 00:40:25,939
suppose you wanted to travel from a

00:40:22,729 --> 00:40:27,140
given this is a random postal code if

00:40:25,939 --> 00:40:30,079
you wanted to travel from a random

00:40:27,140 --> 00:40:31,699
postal code to a random postal code what

00:40:30,079 --> 00:40:35,449
are the places that you have an option

00:40:31,699 --> 00:40:37,130
of visiting in that place so the query

00:40:35,449 --> 00:40:40,429
is as simple as this you need to match a

00:40:37,130 --> 00:40:43,069
location where you have the same postal

00:40:40,429 --> 00:40:47,119
code or a similar postal code this is

00:40:43,069 --> 00:40:49,880
just to check the case and all so you

00:40:47,119 --> 00:40:51,859
return the number this house number the

00:40:49,880 --> 00:41:01,789
street number the local address and the

00:40:51,859 --> 00:41:04,069
postal code of that place so we just

00:41:01,789 --> 00:41:06,640
refresh this page so that the data

00:41:04,069 --> 00:41:06,640
clears off

00:41:15,010 --> 00:41:20,420
so you see if you go to if you wanted to

00:41:17,750 --> 00:41:22,250
go to a place with a postal code of this

00:41:20,420 --> 00:41:26,030
number these are the places that you

00:41:22,250 --> 00:41:27,590
have an option of visiting when you

00:41:26,030 --> 00:41:29,510
implement that in the form of cipher

00:41:27,590 --> 00:41:33,350
it's better to go for a transaction

00:41:29,510 --> 00:41:36,230
because you know it makes your acid

00:41:33,350 --> 00:41:38,180
properties to use you can also query

00:41:36,230 --> 00:41:42,230
like from which junctions can I get to a

00:41:38,180 --> 00:41:43,790
place called chertsey so the unknown

00:41:42,230 --> 00:41:49,580
here is the junction that I am going to

00:41:43,790 --> 00:41:52,460
the depth you mentioning here you also

00:41:49,580 --> 00:41:54,230
check you also check the properties that

00:41:52,460 --> 00:42:02,890
the name of the place should be chertsey

00:41:54,230 --> 00:42:06,320
and then you are you can use the j-stop

00:42:02,890 --> 00:42:08,150
yeah you can use the J that is returned

00:42:06,320 --> 00:42:10,730
from here the junction and calculate the

00:42:08,150 --> 00:42:16,790
properties and return them so if you

00:42:10,730 --> 00:42:19,550
execute this query in the interface this

00:42:16,790 --> 00:42:21,470
is what we get so there's a place called

00:42:19,550 --> 00:42:25,790
hatch farm roundabout and this is the

00:42:21,470 --> 00:42:32,510
place where you will reach this is the

00:42:25,790 --> 00:42:34,310
way you implement that in Python so

00:42:32,510 --> 00:42:36,680
another problem that is very easily

00:42:34,310 --> 00:42:39,590
solved using graph databases is shortest

00:42:36,680 --> 00:42:42,200
path there are inbuilt methods that

00:42:39,590 --> 00:42:44,300
cipher as well as by 2 neo have devised

00:42:42,200 --> 00:42:46,640
which we can easily get you to use

00:42:44,300 --> 00:42:49,550
shortest path problems there's one point

00:42:46,640 --> 00:42:52,130
to note that cipher supports a lot of

00:42:49,550 --> 00:42:54,560
existing algorithms like a star and die

00:42:52,130 --> 00:42:56,630
strasse which are already there you do

00:42:54,560 --> 00:42:58,820
not need to define them but there are no

00:42:56,630 --> 00:43:00,560
existing wrappers for pipe to know which

00:42:58,820 --> 00:43:02,450
i think is in progress as the last issue

00:43:00,560 --> 00:43:05,200
on jet up showed they are developing

00:43:02,450 --> 00:43:08,090
wrappers for existing algorithms as well

00:43:05,200 --> 00:43:12,320
so even take a look at contribute to the

00:43:08,090 --> 00:43:15,800
code if you want let's see how a

00:43:12,320 --> 00:43:17,870
shortest path works so what it does is

00:43:15,800 --> 00:43:19,850
you take a location you find all

00:43:17,870 --> 00:43:22,520
locations that are related to that

00:43:19,850 --> 00:43:24,110
location get the postal code of one

00:43:22,520 --> 00:43:25,900
location get the postal code of the

00:43:24,110 --> 00:43:28,020
second location

00:43:25,900 --> 00:43:31,240
and find the length of the relationships

00:43:28,020 --> 00:43:33,010
so it acts it it actually finds all

00:43:31,240 --> 00:43:34,990
relationships between two existing nodes

00:43:33,010 --> 00:43:36,670
in a graph find the lengths of those

00:43:34,990 --> 00:43:44,800
relationships and gives you a list of

00:43:36,670 --> 00:43:46,210
the shortest ones so instead of getting

00:43:44,800 --> 00:43:48,310
a list of instead of getting the

00:43:46,210 --> 00:43:50,590
shortest path you get to know the exact

00:43:48,310 --> 00:43:51,640
path where where you have to go do you

00:43:50,590 --> 00:43:55,680
think it's something like Google Maps

00:43:51,640 --> 00:44:01,870
does you can create your own google maps

00:43:55,680 --> 00:44:04,600
duplicate this is one more query that's

00:44:01,870 --> 00:44:06,310
good like if your nodes are already

00:44:04,600 --> 00:44:08,170
storing the average speed that is

00:44:06,310 --> 00:44:10,660
required to go through a particular area

00:44:08,170 --> 00:44:12,520
you can calculate the time that is

00:44:10,660 --> 00:44:13,930
required so when you search on google

00:44:12,520 --> 00:44:15,940
maps that you go from one place to the

00:44:13,930 --> 00:44:17,770
other place it gives you it is the

00:44:15,940 --> 00:44:19,330
estimate of time according to a given

00:44:17,770 --> 00:44:21,040
situation right in p cards that will

00:44:19,330 --> 00:44:23,170
give you a different time in a normal

00:44:21,040 --> 00:44:28,090
time it will give you a different

00:44:23,170 --> 00:44:34,150
estimate of the time so let's see what

00:44:28,090 --> 00:44:36,310
this query does so here we are using an

00:44:34,150 --> 00:44:38,830
operation called reduce where you

00:44:36,310 --> 00:44:40,890
calculate the total kilometers that is

00:44:38,830 --> 00:44:44,380
traveled and reduce them by the weights

00:44:40,890 --> 00:44:45,850
so each node here like if you in the

00:44:44,380 --> 00:44:49,810
previous example that we ran let's see

00:44:45,850 --> 00:44:52,120
what each node has this is the number of

00:44:49,810 --> 00:44:53,830
the node this is the number of the

00:44:52,120 --> 00:44:56,470
property so in the property it is

00:44:53,830 --> 00:44:59,110
defined the speed at the peak time the

00:44:56,470 --> 00:45:02,650
speed in a normal time the type of the

00:44:59,110 --> 00:45:06,340
node and the distance that is there in

00:45:02,650 --> 00:45:09,070
that road so when you execute this query

00:45:06,340 --> 00:45:11,320
it will give you an example of the

00:45:09,070 --> 00:45:14,260
average km/h or the miles per hour that

00:45:11,320 --> 00:45:20,560
you need to travel in in the path that

00:45:14,260 --> 00:45:23,500
you have selected between two nodes it

00:45:20,560 --> 00:45:26,200
can also match a little more complex

00:45:23,500 --> 00:45:29,920
queries where shortest path is used

00:45:26,200 --> 00:45:32,620
along with reduce so how long would it

00:45:29,920 --> 00:45:35,590
take to drive from a place called 48

00:45:32,620 --> 00:45:37,570
rylstone move in London Road to 123

00:45:35,590 --> 00:45:38,940
stains road this is exactly another

00:45:37,570 --> 00:45:41,530
situation of the

00:45:38,940 --> 00:45:47,410
graph database problem which you can

00:45:41,530 --> 00:45:49,240
relate to google maps right so they are

00:45:47,410 --> 00:45:51,990
pretty simple use cases where you can

00:45:49,240 --> 00:45:54,190
use social network data you can use

00:45:51,990 --> 00:45:57,850
recommendation data you can use map data

00:45:54,190 --> 00:45:59,730
to perform complex operations so in a

00:45:57,850 --> 00:46:01,930
pose that Nigel posted a few days ago

00:45:59,730 --> 00:46:03,880
there are there's a lot of hope for pie

00:46:01,930 --> 00:46:06,640
to new in the future there will be

00:46:03,880 --> 00:46:08,860
support for fast HTTP Python 3 support

00:46:06,640 --> 00:46:10,180
is already there it's probably not

00:46:08,860 --> 00:46:12,160
released yet but it's already done

00:46:10,180 --> 00:46:14,920
there's multithreading support available

00:46:12,160 --> 00:46:18,100
there are more command lines tools tools

00:46:14,920 --> 00:46:20,050
coming up there will be new methods to

00:46:18,100 --> 00:46:21,670
easier process of communicating with the

00:46:20,050 --> 00:46:23,470
database there we get paths to each so

00:46:21,670 --> 00:46:25,210
you just have to special i specify a

00:46:23,470 --> 00:46:27,310
given node and you can get all the paths

00:46:25,210 --> 00:46:30,040
that are existing in that database to

00:46:27,310 --> 00:46:31,810
that node there are a lot of other

00:46:30,040 --> 00:46:34,600
relatives in the Python family 4 PI 2

00:46:31,810 --> 00:46:37,540
neo there's a framework called bulb flow

00:46:34,600 --> 00:46:39,190
which is a separate framework devised

00:46:37,540 --> 00:46:42,370
for communicating with all types of

00:46:39,190 --> 00:46:46,180
graph databases including neo4j we have

00:46:42,370 --> 00:46:48,730
a object graph mapping for neo4j gorneo

00:46:46,180 --> 00:46:50,650
model we also have new for django which

00:46:48,730 --> 00:46:51,940
makes it easy to integrate new version

00:46:50,650 --> 00:46:56,620
as a back-end for any Django application

00:46:51,940 --> 00:46:57,820
that you are building so like since

00:46:56,620 --> 00:47:00,460
you're running short of time that sort

00:46:57,820 --> 00:47:11,920
that's it for today we open to questions

00:47:00,460 --> 00:47:13,090
if anyone has well don't be stopped by

00:47:11,920 --> 00:47:23,140
neo he is not trying to stop your

00:47:13,090 --> 00:47:26,560
questions hi yeah so a new photo has a

00:47:23,140 --> 00:47:27,880
notion of notes in our relationship so I

00:47:26,560 --> 00:47:30,100
want to ask that the relationship

00:47:27,880 --> 00:47:32,350
between two notes is a unidirectional or

00:47:30,100 --> 00:47:35,410
bi-directional or there is no such thing

00:47:32,350 --> 00:47:37,390
in neo4j know there is you can specify

00:47:35,410 --> 00:47:38,860
what direction you want you can have a

00:47:37,390 --> 00:47:41,290
bidirectional relationship you can have

00:47:38,860 --> 00:47:43,090
a unidirectional relationship as well so

00:47:41,290 --> 00:47:44,590
the concept behind is it to relate one

00:47:43,090 --> 00:47:47,380
thing to do to the other so you can

00:47:44,590 --> 00:47:48,970
specify two relationships as well so

00:47:47,380 --> 00:47:51,880
there's an optional a separate

00:47:48,970 --> 00:47:53,520
specifying the direction i think i saw a

00:47:51,880 --> 00:48:03,850
question here

00:47:53,520 --> 00:48:05,380
okay we come to you yeah so new for jay

00:48:03,850 --> 00:48:07,330
is you know like it is not a replacement

00:48:05,380 --> 00:48:08,920
for relational databases it is going to

00:48:07,330 --> 00:48:11,020
more argument or complement their

00:48:08,920 --> 00:48:12,580
relational devices so there is a need to

00:48:11,020 --> 00:48:15,010
transfer the data from relational

00:48:12,580 --> 00:48:16,240
databases to the new forte and models

00:48:15,010 --> 00:48:17,680
are quite different as you mentioned

00:48:16,240 --> 00:48:20,260
this is you know completely on this one

00:48:17,680 --> 00:48:21,490
so do you have any suggestions or

00:48:20,260 --> 00:48:23,140
another what kind of clothes that we can

00:48:21,490 --> 00:48:25,630
really use they have developed a batch

00:48:23,140 --> 00:48:28,450
inserter for it so like when you have a

00:48:25,630 --> 00:48:30,430
very large my sequel database at the

00:48:28,450 --> 00:48:32,860
back end you cannot transfer the entire

00:48:30,430 --> 00:48:34,690
data to and you have neo4j instance

00:48:32,860 --> 00:48:36,850
right so there are special techniques

00:48:34,690 --> 00:48:39,370
where this new 4g is basically used for

00:48:36,850 --> 00:48:40,720
analytics so when you have a part of a

00:48:39,370 --> 00:48:42,580
data that you want to use final it

00:48:40,720 --> 00:48:44,470
expands fir that analytics is not

00:48:42,580 --> 00:48:46,660
something which you do on the fly it is

00:48:44,470 --> 00:48:48,910
done once in a while so on warehouse

00:48:46,660 --> 00:48:50,980
data probably so what you can do is you

00:48:48,910 --> 00:48:52,990
can take that part of the data inserted

00:48:50,980 --> 00:48:55,450
into neo4j perform your operations and

00:48:52,990 --> 00:48:56,710
then do away with the data so these kind

00:48:55,450 --> 00:48:58,270
of operations are much simpler instead

00:48:56,710 --> 00:49:00,510
of replacing your entire database with

00:48:58,270 --> 00:49:03,250
neo4j you can use your entire database

00:49:00,510 --> 00:49:05,200
part of your database to transfer the

00:49:03,250 --> 00:49:07,840
data to new forge a process it get your

00:49:05,200 --> 00:49:10,270
results and then remove the data from

00:49:07,840 --> 00:49:12,010
the new version so basically what you

00:49:10,270 --> 00:49:14,200
are doing is you're making the complex

00:49:12,010 --> 00:49:25,030
operations simpler with neo4j by a

00:49:14,200 --> 00:49:26,770
little overhead of data transfer he's

00:49:25,030 --> 00:49:28,800
been waiting for a long while now okay

00:49:26,770 --> 00:49:32,950
will come to you if you want to go fast

00:49:28,800 --> 00:49:34,960
yeah sure yeah so you mention about

00:49:32,950 --> 00:49:37,420
cipher following more of a saint acts

00:49:34,960 --> 00:49:39,460
like a sequel and then we had pie to

00:49:37,420 --> 00:49:41,140
near which is more closer to rest base

00:49:39,460 --> 00:49:43,810
will how we use for elasticsearch kind

00:49:41,140 --> 00:49:45,790
of syntax so now you have pie to near

00:49:43,810 --> 00:49:47,980
where we can import cipher and you

00:49:45,790 --> 00:49:49,690
cipher queries inside so don't you think

00:49:47,980 --> 00:49:51,160
like when we are using cipher and pie

00:49:49,690 --> 00:49:52,900
tune your board together it become more

00:49:51,160 --> 00:49:54,970
cluttered of a code where you have one

00:49:52,900 --> 00:49:58,540
syntax in one format an underling other

00:49:54,970 --> 00:50:00,070
one a cluttered of a code I think if you

00:49:58,540 --> 00:50:02,470
are not using cipher your code is more

00:50:00,070 --> 00:50:03,579
cluttered so as you know pi/2 new is

00:50:02,470 --> 00:50:05,859
actually a rest

00:50:03,579 --> 00:50:08,440
rapper right so a rest request is slower

00:50:05,859 --> 00:50:10,630
if you think about it it was a necessary

00:50:08,440 --> 00:50:12,400
step that was taken to include cypher in

00:50:10,630 --> 00:50:14,619
my two new cipher queries are much

00:50:12,400 --> 00:50:17,319
faster than rest queries they have the

00:50:14,619 --> 00:50:21,459
less over time overhead of data transfer

00:50:17,319 --> 00:50:23,289
through Jason documents you don't need

00:50:21,459 --> 00:50:24,579
that was this is legacy you know it was

00:50:23,289 --> 00:50:27,009
it began white when you began

00:50:24,579 --> 00:50:30,309
development as a rest wrapper and then

00:50:27,009 --> 00:50:32,680
moved on to this plus rest provides you

00:50:30,309 --> 00:50:35,170
flexibility like a lot of options are

00:50:32,680 --> 00:50:37,119
there which you can do with rest over a

00:50:35,170 --> 00:50:41,940
server interface but yeah they have been

00:50:37,119 --> 00:50:45,549
incorporated into cipher lately finally

00:50:41,940 --> 00:50:48,489
this neo for Django how is that what

00:50:45,549 --> 00:50:50,709
exactly does it use behind same it's a

00:50:48,489 --> 00:50:54,609
wrapper around the new foreign PI 2 neo

00:50:50,709 --> 00:50:56,440
so it is a REST API interface it's

00:50:54,609 --> 00:50:58,359
implemented with rest at the back end

00:50:56,440 --> 00:50:59,170
but it's it has specific methods which

00:50:58,359 --> 00:51:02,039
you can direct which are directly

00:50:59,170 --> 00:51:04,630
callable from your django functions and

00:51:02,039 --> 00:51:07,989
rest so it would be easy to integrate

00:51:04,630 --> 00:51:10,269
with MongoDB user because if I have the

00:51:07,989 --> 00:51:12,549
whole website on number TV and I want to

00:51:10,269 --> 00:51:14,170
use this for basically finding

00:51:12,549 --> 00:51:16,630
relationships yeah it would be much

00:51:14,170 --> 00:51:18,729
faster with hoja right yeah of course so

00:51:16,630 --> 00:51:20,829
if you have related data then it's much

00:51:18,729 --> 00:51:22,029
faster an earful j plus there's also one

00:51:20,829 --> 00:51:25,359
point i would like to mention like you

00:51:22,029 --> 00:51:27,069
know if you have a lot of data so i

00:51:25,359 --> 00:51:29,709
wouldn't say new for j is a good option

00:51:27,069 --> 00:51:33,039
for that day so it's around a huge data

00:51:29,709 --> 00:51:36,549
set new 4 g's does in-memory traversals

00:51:33,039 --> 00:51:38,229
that is why it's fast so in memory or in

00:51:36,549 --> 00:51:40,449
cash traversals are fast when you have

00:51:38,229 --> 00:51:43,329
relatively good amounts of data but not

00:51:40,449 --> 00:51:45,190
very huge so like you see Facebook has

00:51:43,329 --> 00:51:47,890
implemented graph search you can you

00:51:45,190 --> 00:51:50,019
can't you just be such specific stuff so

00:51:47,890 --> 00:51:51,789
maybe grab at the back end view we don't

00:51:50,019 --> 00:51:54,489
know but maybe at the graph back end

00:51:51,789 --> 00:51:56,259
it's only implemented on the names of

00:51:54,489 --> 00:51:57,789
the people the nodes are the people

00:51:56,259 --> 00:51:59,019
themselves you can search people you

00:51:57,789 --> 00:52:02,529
cannot search which company they work

00:51:59,019 --> 00:52:03,729
for right so that's the problem that

00:52:02,529 --> 00:52:05,349
they are trying to solve with gravity

00:52:03,729 --> 00:52:07,150
devices you cannot transfer the entire

00:52:05,349 --> 00:52:08,559
routed facebook cannot operate on a

00:52:07,150 --> 00:52:12,430
graph database the at the scale that

00:52:08,559 --> 00:52:14,979
they are working on special cases of

00:52:12,430 --> 00:52:16,410
that data which you can traverse using

00:52:14,979 --> 00:52:19,860
graph databases

00:52:16,410 --> 00:52:22,710
hey I want to know like i was using

00:52:19,860 --> 00:52:25,290
gremlin for wearing new footage actually

00:52:22,710 --> 00:52:27,360
gremlin had supper ramblin gamblin was

00:52:25,290 --> 00:52:31,800
supported till the last version

00:52:27,360 --> 00:52:34,830
officially I feel gremlin is rambling

00:52:31,800 --> 00:52:36,510
yeah I lose that gremlin is a generic

00:52:34,830 --> 00:52:38,790
language for all graph traversals for

00:52:36,510 --> 00:52:42,480
any graph database so i'm using Burrell

00:52:38,790 --> 00:52:46,350
for you know ORM layer okay so Kremlin

00:52:42,480 --> 00:52:50,610
is the enforcement it before so does it

00:52:46,350 --> 00:52:52,170
in like do i deduce lot of you know not

00:52:50,610 --> 00:52:53,760
much I feel cipher has been quite

00:52:52,170 --> 00:52:56,490
optimized to work at the level of

00:52:53,760 --> 00:52:58,560
Kremlin probably for neo4j cipher works

00:52:56,490 --> 00:52:59,790
faster than gremlin this is from

00:52:58,560 --> 00:53:03,150
personal experience haven't tested it

00:52:59,790 --> 00:53:04,770
out yet but yeah I feel that so like you

00:53:03,150 --> 00:53:08,280
see in this this is the old new fuji

00:53:04,770 --> 00:53:10,650
console where you had a shell for new

00:53:08,280 --> 00:53:12,360
for cipher queries and HTTP this is a

00:53:10,650 --> 00:53:15,750
new version in the previous version we

00:53:12,360 --> 00:53:20,990
also had a tab for gremlin so you could

00:53:15,750 --> 00:53:27,330
perform some inquiries from you thank ya

00:53:20,990 --> 00:53:37,680
anybody else I guess that's it yeah

00:53:27,330 --> 00:53:43,580
thank you guys Thank You sunol for the

00:53:37,680 --> 00:53:43,580

YouTube URL: https://www.youtube.com/watch?v=sqwQV5hldD8


