Title: Making Of NextGen Fintech: Insights From Visible Alpha Tech Stack
Publication date: 2018-01-31
Playlist: PyCon India 2017
Description: 
	Making Of NextGen Fintech: Insights From Visible Alpha Tech Stack (Sponsored Talk)

Visible Alpha is a fintech firm at the intersection of finance and analytics. The financial analytics we provide is one of a kind because the we have 'first' access to analyst's data and that's something very unique on the street. We also provide a lot of technology infrastructure that makes the buy and sell side firms work together. Our stack is built on top of micro services architecture, with high availability at the core of the system. This is sprinkled with a liberal dose NLP, computation algorithms etc. There is a constant push towards designing and implementing components with the best available technology while keeping in mind scalability and maintainability. One of the challenges we continuously face is dealing with an ever increasing data and still keeping latency within acceptable limits.
Prerequisites:
Developers/Practitioners with a keen interest on industrial use case studies of Python with a keen interest in analytics and modern cloud infrastructure.
Speakers: 1. Abhijeet Gorhe
Abhijeet works as a Lead Engineer with Visible Alpha. He leads a team of python programmers who are responsible for performance sensitive analytics computation and data distribution services.
His Linkedin profile link - https://www.linkedin.com/in/abhijeet-gorhe-87046711/
2. Milind Walke
Milind works as a Lead Engineer with Visible Alpha. He heads the engineering team responsible for Visible Alpha's core infrastructure and API development, and is in many ways responsible for a smooth resilient client experience. He enjoys getting his hands dirty on microservices development using a Python-Consul-Docker stack. His Linkedin profile link - https://www.linkedin.com/in/milind-walke/
Captions: 
	00:00:16,970 --> 00:00:24,869
sometime in early 2017 we acquired of

00:00:20,939 --> 00:00:27,720
product me one axis acquisition made a

00:00:24,869 --> 00:00:30,900
lot of business sense but we faced a lot

00:00:27,720 --> 00:00:32,850
of technical challenges why if you look

00:00:30,900 --> 00:00:34,200
at the technical stacks for visible

00:00:32,850 --> 00:00:37,579
alpha and one axis you'll see that

00:00:34,200 --> 00:00:40,410
visible alpha is primarily using Python

00:00:37,579 --> 00:00:43,829
one axis was built on Microsoft

00:00:40,410 --> 00:00:46,170
technologies one axis were also very

00:00:43,829 --> 00:00:50,280
heavy on using the database for stored

00:00:46,170 --> 00:00:52,260
procedures for computations and the way

00:00:50,280 --> 00:00:54,719
one axis grew it grew very rapidly and

00:00:52,260 --> 00:00:57,629
the at the pace at which it on modern

00:00:54,719 --> 00:00:59,640
new brokers Illume short up

00:00:57,629 --> 00:01:01,320
significantly and we knew that very soon

00:00:59,640 --> 00:01:05,220
we would not be able to scale this

00:01:01,320 --> 00:01:07,439
product the third thing that was

00:01:05,220 --> 00:01:09,180
challenging was that the way the system

00:01:07,439 --> 00:01:11,070
had evolved it was a fairly monolithic

00:01:09,180 --> 00:01:13,229
architecture so it was very difficult to

00:01:11,070 --> 00:01:16,830
integrate these two into a single

00:01:13,229 --> 00:01:19,080
unified solution hence the decision was

00:01:16,830 --> 00:01:22,040
taken to break down the architecture

00:01:19,080 --> 00:01:28,470
into a micro services based architecture

00:01:22,040 --> 00:01:30,600
next okay so micro services well what

00:01:28,470 --> 00:01:32,520
does micro services really mean so in a

00:01:30,600 --> 00:01:34,470
micro services world each business

00:01:32,520 --> 00:01:37,530
functionality becomes its own

00:01:34,470 --> 00:01:40,049
independent service these services

00:01:37,530 --> 00:01:43,049
expose a set of well-defined rest api is

00:01:40,049 --> 00:01:44,280
to the external world and the services

00:01:43,049 --> 00:01:47,970
communicate with each other through

00:01:44,280 --> 00:01:51,149
these rest api is how do you build these

00:01:47,970 --> 00:01:54,299
so we've used the Falcon framework in

00:01:51,149 --> 00:01:56,130
case you haven't looked at it it's a Web

00:01:54,299 --> 00:01:58,590
API framework for building mic reserves

00:01:56,130 --> 00:02:00,719
in Python it's a very small and

00:01:58,590 --> 00:02:02,790
minimalistic framework it doesn't do too

00:02:00,719 --> 00:02:04,530
much under the hood but at the same time

00:02:02,790 --> 00:02:06,890
it gives you flexibility to plug in

00:02:04,530 --> 00:02:09,660
stuff which you can use to you know

00:02:06,890 --> 00:02:11,879
expand it and it encourages the rest

00:02:09,660 --> 00:02:13,510
architectural style so hence it was very

00:02:11,879 --> 00:02:16,750
well suited for

00:02:13,510 --> 00:02:19,060
style of work once the Falcon

00:02:16,750 --> 00:02:22,090
application was built we used G unicorn

00:02:19,060 --> 00:02:25,480
to run this application so essentially

00:02:22,090 --> 00:02:28,689
each service is essentially a unicorn

00:02:25,480 --> 00:02:30,610
application running Falcon what this

00:02:28,689 --> 00:02:32,079
does is it gives us a lot of flexibility

00:02:30,610 --> 00:02:33,519
because you can have multiple G unique

00:02:32,079 --> 00:02:36,730
on processes running on multiple

00:02:33,519 --> 00:02:40,930
machines and you can just scale up to

00:02:36,730 --> 00:02:43,359
whatever number you want micro services

00:02:40,930 --> 00:02:45,670
don't work in isolation they need data

00:02:43,359 --> 00:02:48,700
to work with so that's where we use

00:02:45,670 --> 00:02:50,609
sequel alchemy sequel alchemy abstracts

00:02:48,700 --> 00:02:52,900
out the whole data access layer and

00:02:50,609 --> 00:02:54,790
maybe there's a service that's very

00:02:52,900 --> 00:02:56,379
light on memory footprint on data

00:02:54,790 --> 00:02:58,659
footprint so it could just do it a

00:02:56,379 --> 00:02:59,829
sequel light DB whereas there may be

00:02:58,659 --> 00:03:01,690
some services that are very

00:02:59,829 --> 00:03:04,209
transactional nature hence you need a

00:03:01,690 --> 00:03:05,920
sequel server to handle them sequel

00:03:04,209 --> 00:03:07,480
alchemy allows us to abstract out the

00:03:05,920 --> 00:03:10,659
data layer so that different services

00:03:07,480 --> 00:03:12,489
can maintain their own databases and you

00:03:10,659 --> 00:03:16,900
don't have to worry about whom you're

00:03:12,489 --> 00:03:18,879
working with well all this sounds very

00:03:16,900 --> 00:03:20,799
good but there are obvious trade-offs

00:03:18,879 --> 00:03:23,230
that come with this and that trade-off

00:03:20,799 --> 00:03:25,359
is monitoring you have services running

00:03:23,230 --> 00:03:28,060
all over the place if you don't do a

00:03:25,359 --> 00:03:29,470
good good job of monitoring it's not

00:03:28,060 --> 00:03:32,020
going to work

00:03:29,470 --> 00:03:35,890
so what do you use for monitoring we

00:03:32,020 --> 00:03:37,990
have things like Nigeria we used the ALK

00:03:35,890 --> 00:03:40,840
stack that's elastic logstash Cabana

00:03:37,990 --> 00:03:43,180
right these things help us to monitor

00:03:40,840 --> 00:03:49,720
the health of these services which we

00:03:43,180 --> 00:03:51,400
can explain in more detail I know we're

00:03:49,720 --> 00:03:53,800
running out of time so I'll just quickly

00:03:51,400 --> 00:03:55,990
go through the slide you know if any of

00:03:53,800 --> 00:03:57,820
you feel that you want to get into the

00:03:55,990 --> 00:04:02,310
code a little more please do visit us at

00:03:57,820 --> 00:04:02,310
the booth I can kind of hero show this

00:05:49,080 --> 00:06:07,509
hello as the services come up they

00:06:05,860 --> 00:06:09,250
register themselves with console console

00:06:07,509 --> 00:06:11,680
agents are running on each load in your

00:06:09,250 --> 00:06:14,199
network and these control agents talk to

00:06:11,680 --> 00:06:16,780
each other using this the build up a

00:06:14,199 --> 00:06:18,460
service registry so any any service that

00:06:16,780 --> 00:06:20,080
ones so if research service wants to

00:06:18,460 --> 00:06:21,970
know okay where is model service running

00:06:20,080 --> 00:06:24,370
it can look up its console registry

00:06:21,970 --> 00:06:26,259
figure out the IP port where the model

00:06:24,370 --> 00:06:30,490
service is running and get the data from

00:06:26,259 --> 00:06:31,840
there and lastly what we've used is kind

00:06:30,490 --> 00:06:33,370
of control is something that we are

00:06:31,840 --> 00:06:34,870
currently piloting and the last thing

00:06:33,370 --> 00:06:36,970
that we are piloting on right now is the

00:06:34,870 --> 00:06:40,180
use of talker so what we want to do is

00:06:36,970 --> 00:06:41,979
each service that comes up gets deployed

00:06:40,180 --> 00:06:43,690
into its old docker container so it

00:06:41,979 --> 00:06:45,759
gives us the flexibility of you know

00:06:43,690 --> 00:06:47,860
deploying it on any data center we don't

00:06:45,759 --> 00:06:49,720
have dependencies on where we want to

00:06:47,860 --> 00:06:51,310
deploy this service development

00:06:49,720 --> 00:06:54,639
framework also kind of you know gets

00:06:51,310 --> 00:06:56,020
significantly simplified so yep I think

00:06:54,639 --> 00:06:59,560
that's that's pretty much you know all

00:06:56,020 --> 00:07:02,320
we wanted to say I have a slide that

00:06:59,560 --> 00:07:03,820
talks about how this is done but again I

00:07:02,320 --> 00:07:07,030
think in the interest of time I'll just

00:07:03,820 --> 00:07:08,530
move over and we can we can take this up

00:07:07,030 --> 00:07:10,659
at the booth so you're all welcome to

00:07:08,530 --> 00:07:12,310
kind of you know reach out to us at the

00:07:10,659 --> 00:07:16,080
booth and you know we'll be glad to

00:07:12,310 --> 00:07:16,080
address any queries that you have

00:07:27,030 --> 00:07:47,680
thank you so we'll start with the

00:07:32,680 --> 00:07:49,919
questions any questions please yeah what

00:07:47,680 --> 00:07:52,150
was your number one most challenging

00:07:49,919 --> 00:07:53,710
like thing that you encountered when you

00:07:52,150 --> 00:07:55,270
scaled what was the number one

00:07:53,710 --> 00:08:01,240
challenging thing was it monitoring was

00:07:55,270 --> 00:08:07,630
it anything else the number one thing

00:08:01,240 --> 00:08:09,550
which we had to one axis we had it

00:08:07,630 --> 00:08:12,130
heavily dependent on stored procedures

00:08:09,550 --> 00:08:14,050
to do computations now what happens with

00:08:12,130 --> 00:08:16,840
that is every all your computations are

00:08:14,050 --> 00:08:19,930
kind of you know going down into one

00:08:16,840 --> 00:08:22,539
database box and as your volume scale up

00:08:19,930 --> 00:08:24,940
you really cannot have one box through

00:08:22,539 --> 00:08:26,199
it so that's where the whole kind of you

00:08:24,940 --> 00:08:28,150
know we are collecting gave me the

00:08:26,199 --> 00:08:30,240
picture where instead of doing the

00:08:28,150 --> 00:08:32,589
computation within the stored procedures

00:08:30,240 --> 00:08:35,620
we move it out of the stored procedures

00:08:32,589 --> 00:08:42,130
build services that do it and scale the

00:08:35,620 --> 00:08:45,180
services okay thank you everyone

00:08:42,130 --> 00:08:45,180

YouTube URL: https://www.youtube.com/watch?v=to78eaSyaGM


