Title: Talk: Building production ready distributed task queue management system with celery - Vishrut Kohli
Publication date: 2020-12-03
Playlist: PyCon India 2020
Description: 
	This talk was presented at PyCon India 2020 Online.

PyCon India is the largest gathering of Pythonistas in India for the Python programming language. The 12th edition of PyCon India took place online from 2nd October to 5th October 2020.

Talk Detail: https://in.pycon.org/cfp/2020/proposals/how-to-build-a-production-ready-distributed-task-queue-management-system-with-celery~e5qYe/

Click here to subscribe to the PyCon India channel: https://www.youtube.com/user/inpycon?sub_confirmation=1
Follow PyCon India on Twitter: https://twitter.com/pyconindia
Follow PyCon India on Facebook: https://www.facebook.com/PyConIndia/
Captions: 
	                              next speaker                               is going to be vishruth and vishwath is                               going to talk about                               um how to build a production ready                               distributed task queue management system                               with celery but                               you know like a little bit to say about                               vishwath uh he makes                               he's going to make a lot of bad jokes                                apparently but                                um when he's not making that he is a                                software engineer at graphics                                provers and is working as a data science                                lead                                at a vc funded edutech startup called                                leverage edu                                he embarked on his python journey from                                the start of his college                                but he's always learning a lot more he                                was also a meti japan                                internship scholar and he's won a lot of                                hackathons and stuff he's highly                                enthusiastic at teaching                                and we're going to see a little bit of                                that now um so vishud i'm going to                                welcome you to the stage                                please                                okay so                                hi everyone i'm vishwa kohli first of                                all i would like to thank all of you for                                attending this talk and i'm really                                excited to be here                                so i started working with python uh or                                should i say fell in love in python                                in my early days of college and now i am                                using it as my primary tech stack at                                work                                where we use it at tremendous scale i am                                working as a software engineer at                                growfors                                uh if you do not know about grofers it                                is one of the most popular grocery                                e-commerce in india                                uh if you want to chat about anything                                else or about this talk you can reach me                                from my linkedin                                or through my personal portfolio so                                without any further ado                                let's dive into the good stuff                                so uh today we are going to see how to                                build                                a production ready distributed task                                management system                                with salary so when i say production                                ready                                i mean which is highly efficient which                                is scalable                                which is transparent and which is                                resilient                                so in this talk we are going to cover                                what are task queues                                and why we need them what is and why                                salary building a distributed task                                viewing system                                tuning it to get maximum performance uh                                adding resiliency or self-healing                                capabilities to the system                                uh what to do in times of sos                                or emergencies uh monitoring the system                                we built                                and most importantly bad jokes                                so i've tried to make this talk as                                descriptive                                as possible but still there are some                                basic prerequisites                                like some basic knowledge of python some                                basic knowledge of web development                                worked or even heard about celery before                                and most important one is                                a sense of humor and love for gifts                                because there are a lot of chess in this                                so ah let's start by taskies                                so let's assume i own a mall and i want                                to keep track of how many people are                                entering in my mall                                so i installed a small iot sensor at my                                entrance                                and whenever someone enters my mod it                                shoots an api request to my web server                                then the request goes to the database                                and increments the counter                                and at the end of the day i can just                                check my database and see the count                                this system was working pretty well for                                me so one day                                i thought i'd stream a football match in                                my mall so                                a lot of people came to the mall and i                                was really excited to see the numbers in                                 my database                                 but when i check my database the numbers                                 i observed                                 were relatively low and i knew something                                 was not right                                 so i investigated and figured out uh                                 when a lot of people                                 entered my mall for each person an api                                 request was raised to my web server                                 and there were a lot of concurrent                                 requests trying to talk to the database                                 and due to the atomicity and locking at                                 my database                                 many requests were timed out and that's                                 why the low count in the tv                                 so there's got to be a better way                                 and there is task queues come to rescue                                 so                                 let's see what our task use so uh if                                 someone asked me this question                                 when i was giving my university                                 examinations uh i would have answered                                 task queue is a queue of tasks and that                                 is                                 exactly what it is i don't know why                                 teachers don't like those answers                                 uh but yeah it fits perfectly here so                                 now                                 in the new architecture whenever we get                                 request from a web server                                 instead of going and trying to increment                                 the counter in the database                                 it puts it into the task queue and                                 returns a                                              and now the database can consume the                                 request from the task queue at its own                                 pace                                 so now we moved from a more real-time                                 approach                                 to a more eventually consistent type of                                 approach                                 and that is okay for us because i only                                 needed to see the count                                 at the end of the day                                 okay so what is and why                                 salary so you must have heard about task                                 queues                                 there are a bunch of them available like                                 amazon amazon if                                 amazon sqs amazon mq red is rabbit                                 enqueue                                 but building and building a consumption                                 and publishing mechanism for those task                                 queues uh is not that straightforward                                 uh to help us with that celery gives us                                 a plug-in plate task view management                                 framework                                 which uh with which we can manage our                                 tasks our distributed task queues                                 with ease so in this talk we are going                                 to use some keywords                                 so let's just iterate over them once uh                                 we already know what task queues are                                 from our previous example                                 uh but we'll just say it again task                                 queue is a queue of tasks                                 then there is task a task is the basic                                 unit of work                                 of a task view and a task queue can                                 contain                                 n number of tasks then here comes the                                 worker                                 worker is the basic unit of computation                                 which lies outside your application                                 and where a task is processed then in                                 line                                 there is broker broker in layman                                 language helps us with picking an                                 offloaded task                                 putting it into a task queue and                                 delivering the task to the worker from                                 the task queue whenever the worker wants                                 to process it                                 and the last one is result back-end it                                 is a highly available database which is                                 used by salary to keep track of all the                                 tasks                                 and their results along with storing all                                 kinds of metadata for salary                                 uh some examples for reserve backend can                                 be read is mean cash                                 etc so okay so                                 before we start building the system one                                 question arises                                 which broker to choose there are a bunch                                 of brokers available like rabbit mq                                 redis etc they all are great pieces of                                 software                                 what works best for their own specific                                 use cases so for example i'll cover the                                 most common ones                                 rabbit mq and redis so if you are                                 looking for a highly efficient broker                                 uh which supports several workers                                 consuming from different queues                                 and also offers some kind of persistence                                 of task when it touched down                                 then no doubt rabbit mq is the way to go                                 but                                 rabbitmq is a little more time consuming                                 to set up                                 and maintain on the other hand if you                                 just want to use your broker as a quick                                 messaging system                                 redis is the way to go as it works                                 really well for quick task                                 and is very easy to set up too                                 okay so let's start building the system                                 so let's think of an e-commerce                                 warehouse to build and there                                 are going to be mainly three things                                 which happen there picking of the                                 products                                 uh packing of the products and delivery                                 of the order                                 so uh the most basic kind of                                 architecture of for my warehouse would                                 be                                 something like this uh i have one boy                                 who picks up the products                                 packs the products and delivers them and                                 this worked for me for some time                                 uh but now the orders are increasing and                                 i want to scale my setup                                 so i employed another girl in the                                 warehouse                                 so now they both are parallely picking                                 packing and delivering the products and                                 this is fine                                 this is fine as when more orders will                                 start coming in                                 i'll just add more people in the                                 warehouse but i think i can improve it a                                 bit                                 further because as i know that these two                                 people                                 are really good at picking but they are                                 lousy at packing and they don't even                                 have delivery bikes to deliver                                 so what if we break this work into                                 smaller fragments                                 and get specialized people to do what                                 they do best                                 so let's see this so now those two                                 people                                 are just doing the picking because they                                 were good at it uh                                 i added an experienced packer who has                                 its own packaging station and everything                                 and i added people with delivery bikes                                 to deliver more efficiently                                 so now this way we had one big task                                 we broke it into smaller tasks and                                 executed them in order                                 and now in further slides we will call                                 this our pipeline                                 so why should we even use pipelines so                                 there are a bunch of advantages we get                                 while using pipelines so let's go by                                 them                                 one by one first uh it gives us the                                 ability to see bottlenecks                                 and scale smaller components of the                                 system instead of the whole system                                 so for example so now if i see that                                 there are a lot of orders pending to be                                 packed                                 so i can just add more people in the                                 packing worker and scale the packing                                 operations                                 instead of scaling the whole pipeline                                 like we did earlier with the girl                                 so second this will give i                                 give the ability to give different kind                                 of machines to different tasks                                 so as per in our example we can see that                                 the packing worker needs a packaging                                 station                                 but a delivery worker needs a delivery                                 bike uh the same thing happens in our                                 tech system                                 different tasks need different kinds of                                 infrastructure                                 some might need more cpu others might                                 need more memory                                 third it helps us keep track of status                                 of tasks                                 and will add some kind of resiliency to                                 the system                                 by enabling retries at every step so now                                 if a task fails uh it will not retry                                 from the beginning                                 uh but will get read right from the last                                 checkpoint or the last succeeded task in                                 the pipeline                                 okay so now let's assume we have a sale                                 going on                                 and we have we have a lot of orders                                 pouring in and                                 our warehouse is already full and we                                 can't even add more people to the                                 warehouse                                 ah so we got two ways first thing we can                                 do is buy a bigger warehouse                                 move all the operations from the smaller                                 warehouse to the bigger warehouse                                 and add more people in it in tech terms                                 we call it vertical scaling                                 on the other hand we can purchase                                 another makeshift warehouse                                 of the same size add more people there                                 and run this warehouse uh run these two                                 warehouses in parallel                                 whilst the operations inside them are                                 concurrent                                 so in tech terms we call it horizontal                                 scaling                                 uh in my case horizontal scrolling makes                                 more sense                                 as the number of orders are variable and                                 after the sealants                                 one warehouse would be able to get all                                 the orders alone and then i can just                                 shut down                                 the my new makeshift warehouse                                 so uh the code for our application would                                 look something like this                                 uh we have an order receiver api which                                 receives an order                                 offloads it to the picking worker uh                                 which is the entry point in our pipeline                                 and the code in our pipeline is                                 something like this                                 uh it starts with the picking worker                                 which picks up stuff from the aisle                                 and passes it to the packing worker                                 the packing worker packs the stuff and                                 passes it to the delivery worker                                 and in the last the delivery worker                                 delivers the stuff                                 in time and makes the customer happy                                 okay so now we have built our system                                 but we don't know how well it performs                                 so first things first                                 it is always better to benchmark before                                 moving to any                                 further optimization because in my                                 experience                                 i have seen if we go by intuition either                                 we end up over optimizing the system                                 or optimizing wrong parts of the                                 architecture                                 so for example in our pipeline when i                                 ran a load test                                 i saw the number of tasks queued at the                                 picking worker                                 were much higher uh than any other                                 worker                                 so i knew uh from where i have to start                                 optimizing                                 so let's ask this question to ourselves                                 can we use                                 batching so let's assume what happens in                                 the picking task                                 uh here in the picking task a person is                                 assigned an order                                 it goes to the aisle picks up that order                                 and passes it to the packing worker                                 uh now assume you have a lot of orders                                 coming in                                 it's a sale and to cater them you added                                 a lot of people in the picking worker                                 and everyone is trying to get something                                 from the aisle                                 as lots of people will be crowding the                                 aisle there will be some kind of wait                                 time for every picker                                 to pick their order uh the exact same                                 thing                                 happens in our concurrent systems the                                 aisle acts as our database                                 and the people act as our concurrent                                 threads                                 so to solve this problem we can                                 introduce batching                                 so instead of one person picking up one                                 order                                 we can make one person pick up                                           this way                                 we are decreasing our trips to the aisle                                 and our database by                                                                                                          also comes with a trade-off so now your                                 rate rise and failures                                 also happen at batch level so if the                                 ninth order failed for some reason in a                                 batch of                                    still the whole batch of                                            retried so                                 if you are okay with this trade-off this                                 can definitely decrease the load at your                                 database and increase                                 our performance so                                 uh there is not much change in the code                                 for our application                                 but instead of offloading it to the                                 picking worker like before                                 we will now offload it to the order                                 aggregator worker                                 and the code is also pretty much the                                 same just one more task named order                                 aggregator is added                                 which contains the order chunking logic                                 and instead of path                                 instead of passing just one order to the                                 picking worker                                 it passes a chunk of orders to the                                 picking worker                                 so next optimization would be always                                 split                                 tasks into io bound and cpu bound tasks                                 so i o bomb tasks are tasks in which                                 thread blocks the cpu and waits until                                 an input or output is received this                                 makes the cpu unusable for the time it's                                 just waiting                                 these kinds of tasks can be optimized                                 with the help of                                 g vent or event lit pool which helps us                                 enable a non-blocking i o approach                                 in which the thread goes to the cpu                                 registers its request                                 does not blocks the cpu and whenever its                                 input and output is ready                                 the cpu raises a callback and the thread                                 goes and collects it                                 this way our cpu is never blocked by                                 concurrent io processes                                 on the other hand a cpu bound task is a                                 task                                 which uses the cpu for crunching numbers                                 or doing cpu intensive tasks                                 uh for these kinds of tasks we should                                 use a preferred pool                                 as it is based on python's                                 multi-processing module and helps                                 running                                 parallel processes on multiple codes                                 and all this is very easy to set up to                                 you just need to pass the cool name and                                 the desired concurrency needed                                 in the following command and you will                                 spin up a new worker with the provided                                 configuration                                 okay use of optimization                                 when possible so this is quite                                 interesting                                 uh the default approach in salary uses a                                 round-robin approach to distribute tasks                                 among distributed systems                                 so if you have a set of tasks that take                                 varying amount of time to complete                                 either deliberately or due to                                 unpredictable network conditions                                 uh this will cause unexpected delays in                                 total execution time for tasks                                 in the queue so you might end up having                                 some tasks                                 queued at some workers whilst some                                 workers are ideal                                 uh to solve this problem you can use                                 offer optimization                                 uh which distributes the task according                                 to the availability of the workers                                 instead of the workers available this                                 option                                 comes with a coordination cost penalty                                 but                                 results in a much more predictable                                 behavior if your task is having varying                                 execution times                                 as most io bound tasks will                                 [Music]                                 so keeping track of results only if you                                 need them                                 so as i told you about result back end                                 in the beginning                                 which stores all the metadata statuses                                 and results of salary                                 if you know you are not going to use                                 them anywhere in your application                                 you can decrease the amount of network                                 calls to your highly available database                                 and it can give you some amount of                                 optimization                                 okay uh so now                                 we ah so now we will see how to add some                                 kind of                                 resiliency or self-healing capabilities                                 to the system                                 so i think we all agree what sentry that                                 ios tagline is                                 software errors are inevitable but chaos                                 is not                                 and that is so true so the most basic                                 version of resiliency is to enable                                 auto retries in times of failures so                                 and you can also add a circuit circuit                                 breaking element for example i've added                                 five                                 as a max number of retries and if a task                                 is retried five times                                 and still failed it will be ignored so                                 that we don't fall into an infinite loop                                 to make it more resilient you can add                                 exponential backup                                 so for example your task is dependent on                                 another service                                 and that service is down and let's                                 assume the time between consecutive                                 retries                                 is                                                                      my first retry will happen at                                            the second one                                 at                                                                   seconds                                 the fourth one at                                                    last one at                                            so in this case i gave                                            breathing time to the other service to                                 come back up                                 so that i don't lose my task to increase                                 that amount                                 the amount of breathing room we have we                                 can use exponential                                 back off which means the first retry                                 will happen at                                            on the second one at                                                    before                                 uh but the third one at                                                fourth one at                                                                                                     seconds                                 so now the breathing time is increased                                 from                                                                     to                                             and if you want more breathing room uh                                 you can just change the exponential back                                 off                                 so next up is acts late is equal to true                                 this means as per the name suggest late                                 acknowledgement                                 uh so by default a broker marks a task                                 as acknowledged                                 when it is delivered to the worker but                                 if our worker goes down                                 and restarts we lose that task so to                                 make your system resilient towards                                 worker failures or infrastructure                                 failures                                 uh we can use actually is equal to true                                 which means uh until and unless                                 uh a task is processed by a worker it                                 will not be marked acknowledged                                 so even if the worker goes down the                                 broker delivers the same task to it as                                 it was still stored in the worker                                 and was marked unacknowledged                                 okay and the last argument is retry                                 jitter                                 is equal to true ah this param is used                                 to add                                 some kind of randomness to the system so                                 let's assume we have a concurrent system                                 and there are chances that two tasks are                                 trying to access the same database                                 resource and when they execute they will                                 form a deadlock                                 and fail because they are trying to                                 access the same database a database                                 resource                                 so we have an automatic retries enabled                                 from before                                 so they'll get retried again but at the                                 same time                                 they will form a deadlock and fail again                                 and this will be                                 uh this will be repeated till the                                 circuit breaks so                                 in situations like these we would want                                 some kind of randomness to the retries                                 so that they do not get retried again                                 and again at the same time                                 and that is why retry jitter is helpful                                 and if you want to keep track of your                                 circuit break failures                                 uh you can use a dlq or a dead liter                                 cube                                 to store your failed tasks                                 okay so when your system is down and the                                 first thing you should do is                                 check your cpu and memory utilization                                 uh if your cpu utilization is high then                                 maybe horizontally and vertically                                 scaling according to your infrastructure                                 can help but if your memory utilization                                 is high                                 and you know for a fact that your code                                 is not using that kind of memory                                 there are chances there is some memory                                 leak in your code                                 uh so i know what you're wondering you                                 might be wondering memory leak in python                                 that is impossible uh and i am with you                                 if you are working with core python                                 that is impossible but when many of the                                 libraries you are using are built using                                 c python                                 or uh even the python interpreter you                                 are using has some kind of memory leak                                 then there are chances there will be                                 some kind of memory leak happening                                 under the hood which is not in your                                 hands so so                                 to solve that problem salary provides                                 two thresholds max memory per child                                 and max tasks per child so with the help                                 of these commands                                 you can set a threshold either on number                                 of tasks executed by the process                                 or the amount of memory being used by                                 the process                                 and when any of the threshold is reached                                 it rotates the process                                 and clears out the stagnant memory so                                 that we do not get                                 oom killed errors or out of memory                                 errors                                 so so when we are running something in                                 production                                 we should have the capability to keep an                                 eye on it and                                 flower works really well with just                                 running one command                                 you can set up a full fledged monitoring                                 tool for your salary setup                                 so it gives you the capabilities like uh                                 purging queues                                 view acknowledgement rates view and                                 modify queue worker instances                                 view scheduled tasks it has an http api                                 for almost all the data                                 data points available so that you can                                 integrate it in your                                 own monitoring dashboards as well and                                 also using those endpoints to configure                                 alerts                                 so that you know if your system is going                                 down beforehand                                 uh if you're using rabbit mq as your                                 broker                                 uh and you are more comfortable with                                 rabbit enqueue instead of flower                                 uh you can use the rabbit mq admin panel                                 too to monitor your system                                 at the broker level itself so it also                                 gives features such as                                 purging deleting monitoring queues etc                                 just like flower before                                 so to conclude in this talk we                                 understood                                 why pipelines are better uh how to tune                                 salary configuration to get maximum                                 performance                                 uh how to make your salary set up                                 resilient                                 or self-healing uh what to do                                 when unknown things are hogging up on                                 memory resources                                 and how to keep an eye on our system                                 so if we follow all these steps while                                 building our system                                 we will be facing a lot less issues and                                 our system will be production ready                                 and we will sleep soundly                                 so that is it from me                                 so if you have any questions or feedback                                 as it was my first talk                                 i'd be happy to work on it uh also if                                 you didn't like the presentation i'm                                 also open to take virtual tomatoes                                 so yeah that is it for me and over to                                 you                                 sure first of all let me begin by saying                                 that you have cured this                                 pretty perfectly in terms of time so                                 thank you for that                                 uh and you know you have                                 you're in a very safe spot with respect                                 to tomatoes you won't be receiving them                                 i suppose because it's virtual but                                 i don't think there will be the there                                 are uh we have                                 three more minutes three four more                                 minutes for our question answers because                                 the next thing is a break anyway                                 so and there are a bunch of questions                                 actually um                                 yeah let's get that show like                                 i you know there are too many questions                                 to be answered so we'll take                                 uh maybe the last few but the rest of                                 them                                 we will make it available to you so that                                 you can answer them on this you look                                 chat                                 and you know like we also if you can                                 provide your                                 contact information we'll get in touch                                 with you as an                                 email id or you know twitter handle                                 similar to how we did it with wesley                                 chan                                 right so i think we'll take a couple of                                 questions now so i think one of the                                 questions is                                 uh can how can i put a delay in a queue                                 so that every task inside a queue will                                 be picked by worker                                 with a predefined delay so                                 let's put that up on scale yeah so                                 basically                                 if you are using salary uh celery                                 provides a feature                                 such as countdown so countdown means                                 that if you want to have some kind of                                 delay before your task is picked                                 uh you can use that feature and if i put                                 a countdown of                                               it will pick up the broker will deliver                                 the task to the worker it will put that                                 in its memory                                 and whenever the countdown is finished                                 it will get executed                                 so it has one drawback that if you have                                 a lot of things countdowning                                 so uh it will it might                                 uh have some kind of memory constraints                                 on your worker                                 but yeah you can use countdown if you're                                 if the tasks are not very much                                 okay uh i think we have time for                                 two more questions again what kind of                                 data can we send to salary i think                                 that's a generic question and i'm                                 sure everyone any kind of data which can                                 be serialized in json                                 or xml or even pickle you can send it                                 so if your data is serializable in any                                 of these formats you can send it over                                 cell                                 so one more question was uh is it                                 possible to schedule tasks using salary                                 and there were a lot of answers for that                                 like                                 mentioning salary beat and crown and air                                 flow but if you have any more                                 suggestions uh                                 in your arsenal you can mention them                                 yeah i think                                 people have answered already in the chat                                 but yeah if you want to use salary only                                 there is celery beat which is a very                                 neat piece of software so                                 you can use it to schedule tasks it just                                 takes one                                 uh it just take one instance and your                                 whole distributed task                                 system can be uh it can you can use it                                 to schedule tasks so yeah                                 um okay                                 so omkar says but countdown means it'll                                 be executed                                 late but not picked up late right yeah                                 it will be executed late but                                 it will be delivered to the worker but                                 if you want it to be executed after some                                 kind of delay in terms of time then yeah                                 it will be executed after that time but                                 it will be picked up from the broker and                                 delivered to the worker                                 but it will be unacknowledged until it                                 gets processed                                 um i hope you got your answer uh um                                 and um yeah i think there's a lot more                                 comments but then                                 can you provide some contact information                                 so                                 wait i'll just share that screen again                                 so that                                 uh where i had all my contact                                 information                                 i should have added it in the end but                                 sorry about that                                 uh you can contact me through linkedin                                 actually i just watched                                 social dilemma so i'm having my aversion                                 towards social media                                 so but yeah you can contact me through                                 linkedin i'm pretty much available there                                 or you can email me my email id i'll put                                 it in the stage                                 chat also but my email id is                                 gmail.com                                 great i think there's a mild delay                                 before i can                                 take a screenshot of the contact                                 information to be provided later                                 okay after they talk i can just go to                                 the stage link and                                 i'll add the information there also                                 great                                 okay so um again folks thank you so much                                 for being such a participative audience                                 thank you                                 vishwud for an awesome talk it was very                                 clear                                 and you know participation is uh i mean                                 even if it is online it's a great                                 indicator of how much of the talk                                 can have been and i think it has been                                 great uh and i know it's a tough act to                                 follow wesley but you've done an                                 awesome job thank you um thank you thank                                 you so much
YouTube URL: https://www.youtube.com/watch?v=rk8RE8HYecg


