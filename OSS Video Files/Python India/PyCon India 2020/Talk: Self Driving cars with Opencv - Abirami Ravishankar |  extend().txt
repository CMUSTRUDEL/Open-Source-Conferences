Title: Talk: Self Driving cars with Opencv - Abirami Ravishankar |  extend()
Publication date: 2020-12-03
Playlist: PyCon India 2020
Description: 
	This talk was presented at PyCon India 2020 Online.

PyCon India is the largest gathering of Pythonistas in India for the Python programming language. The 12th edition of PyCon India took place online from 2nd October to 5th October 2020.

Talk Details: https://in.pycon.org/cfp/2020/proposals/self-driving-cars-using-opencv~dJGge/

Click here to subscribe to the PyCon India channel: https://www.youtube.com/user/inpycon?sub_confirmation=1
Follow PyCon India on Twitter: https://twitter.com/pyconindia
Follow PyCon India on Facebook: https://www.facebook.com/PyConIndia/
Captions: 
	                              hey                               good evening everyone welcome back to                               the evening session                               so for the evening talk you know we're                               going to start with abhirami                               ravishankar who's gonna talk about                               self-driving cars using opencv                               so i know there are a lot of curious                               listeners specifically for this talk                                because                                uh it's about opencv and that's uh you                                know really up in the market at this                                point                                so over to you all right thank you so                                much                                so good evening everyone my name is                                abhiyani and i am from bangalore                                and we all know the traffic situation                                here and the number of accidents that                                happen on a daily basis during the peak                                hours                                well at least before the pandemic began                                life would be a lot simpler with                                self-driving cars and i was always keen                                to work on it                                i got introduced to opencv in my first                                year of engineering                                and it has a wide range of applications                                for both human                                and non-human detection i began this                                project                                as a step closer to innovating what                                already exists today                                and started it as a weekend project so                                today i'm going to be talking about                                self-driving cars using opencv                                so the objective here is to basically                                understand the use of opencv                                for self-driving cars and to understand                                the nature of the obstacle                                present in front of it and uh time it                                takes to basically move away from the                                obstacle and the nature of path that                                needs to be taken                                after encountering the obstacle                                so first what is a self-driving car a                                self-driving car is                                also known as an automatic vehicle or a                                robotic car                                which is basically a vehicle that is                                capable of sensing its environment                                and moving safely with little to no                                human input                                self-driving cars combine a variety of                                sensors to perceive their surroundings                                like radar lidar sonar gps and other                                inertial                                measurement units advanced control                                systems                                interpret sensory information to                                identify appropriate navigation paths                                as well as obstacles and relevant                                signage                                so the concept of self-driving cars has                                actually been around for a few decades                                now                                scientists in the beginning were                                actually brainstorming through a few                                ideas                                and faced problems one wouldn't be able                                to figure out without implementing it in                                the real world                                i would like to walk you through a small                                introduction into the history of                                self-driving cars                                problems faced using certain techniques                                and what we know as a self-driving car                                today                                so a few things that have been here                                since the                                      are basically hybrid navigation                                homogenization and decoupling                                vehicle communication systems                                reprogrammability                                and digital traces now a lot of these                                terms might seem unfamiliar                                and are no longer used but i would like                                to explain them in this particular                                context                                to understand the evolution of                                self-driving cars today                                so firstly hybrid navigation now                                there are different systems that help                                control the car                                systems that need improvement include                                car navigation systems                                control systems location systems knowing                                the environment                                vehicle control knowing the speed of the                                 vehicle the direction and other control                                 methods                                 next homogenization and decoupling                                 homogenization indicates the fact that                                 all digital information                                 assumes the same form the concept of                                 homogenization                                 also applies to autonomous vehicles in                                 order for autonomous vehicles to                                 perceive their surroundings                                 they have to have different techniques                                 each of their own accompanying digital                                 information                                 that is from like radar gps motion                                 sensors or using computer vision                                 homogenization requires that digital                                 information                                 in these in these forms are transmitted                                 and stored in the same form                                 this means that their differences are                                 decoupled and digital information                                 can be transmitted stored and computed                                 in a way                                 that vehicles and their operating                                 systems can understand                                 and act upon it homogenization also                                 helps to take advantage of the                                 exponential increase                                 in computing power of both hardware and                                 software                                 which is basically the moore's law and                                 also supports autonomous vehicles                                 to understand and act upon digital                                 information                                 in a more cost effective way and                                 therefore lowering the marginal costs of                                 the vehicle                                 next vehicle communication systems                                 individual vehicles may benefit from                                 information obtained from other vehicles                                 in the                                 in the vicinity especially information                                 relating to traffic congestion                                 and safety hazards regular communication                                 systems                                 use vehicles on the roadside and other                                 roadside units                                 communicating nodes from a peer-to-peer                                 network                                 providing each other with information                                 this is rather ineffective and ideal for                                 a world only with connected vehicles                                 and no people involved another useful                                 factor is reprogrammability                                 another characteristic of autonomous                                 vehicles is that the core product will                                 have greater emphasis                                 on software and its possibilities                                 instead of the chassis and the engine                                 which are basically mechanical parts                                 this is because autonomous vehicles have                                 software systems                                 that drive the vehicle meaning that                                 updates through reprogramming or editing                                 the software                                 can enhance the benefits of the owner                                 that is update a better distinguishing                                 between a blind person and a non-blind                                 person                                 so that the vehicle can take extra                                 caution while approaching the blind                                 person                                 by recognizing a stick along with the                                 person which also                                 works in the case of other differently                                 abled individuals                                 a characteristic of this programmable                                 part of the autonomous vehicle                                 is that updates don't need to come only                                 from the supplier                                 because through machine learning smart                                 autonomous vehicles can                                 learn certain updates and install them                                 accordingly                                 like new navigation maps and                                 intersection computer systems                                 these reprogrammable characteristics of                                 digital technology and the possibility                                 of smart machine learning                                 gives the manufacturer of automobiles an                                 opportunity to differentiate themselves                                 on software                                 this also implies that autonomous                                 vehicles would never be finished because                                 the product can continuously be improved                                 next digital traces now autonomous                                 vehicles are equipped with different                                 sorts of sensors and errors                                 and as said this allows them to connect                                 and interpolate with computers                                 from other autonomous vehicles and                                 roadside units                                 this implies that autonomous vehicles                                 have digital traces when they are                                 connected                                 and the data that comes from these                                 traces can be allowed to develop                                 new products or updates to enhance                                 autonomous vehicles                                 driving safety and you know its ability                                 to actually perform well                                 so what are the challenges faced well                                 also scientists somehow forgot that in                                 the real world                                 especially in busy urban areas there                                 would be hundreds of people walking                                 across the street                                 even for an ideal first world country                                 there where people you know usually                                 follow                                 traffic rules perfectly it is impossible                                 to eliminate a scenario where there are                                 no                                 people or pets on the street now coming                                 to a very important factor where opencv                                 plays a crucial role that is the human                                 factor                                 self-driving cars already are already                                 exploring the field                                 of difficulties in determining the                                 intentions of pedestrians bicyclists                                 and people owning pets and the model and                                 models the behavior                                 that must be programmed into the driving                                 algorithm                                 human road users also have the challenge                                 of determining the intentions of                                 autonomous vehicles                                 where there is no driver to which you                                 can make eye contact or exchange hand                                 signals                                 drive dot ai is testing a solution to                                 this problem                                 that basically involves led boards                                 mounted outside the vehicle                                 announcing like going slow do not cross                                 or waiting for you to cross this is                                 rather counterproductive                                 and makes the whole process much slower                                 than if a human were to actually drive                                 now the handoff from automated driving                                 to manual driving                                 which can become necessary because of                                 unforeseeable road conditions                                 or if the vehicle has limited                                 capabilities now a sudden hand off could                                 leave the human driver                                 dangerously unprepared for the moment                                 and in the long term                                 humans would have less practice at                                 driving and might have a lower skill                                 level and thus be more dangerous in the                                 manual mode                                 semi-automated cars have shown to suffer                                 from this very problem                                 for example tesla autopilot ignoring the                                 and people usually ignore the road and                                 use their phones and                                 perform other activities inside you know                                 their car                                 against the advice of the company as the                                 car is not capable of being completely                                 autonomous                                 in the near future pedestrians and                                 bicyclists                                 may travel in the street in a much                                 riskier fashion                                 when because they would believe that                                 self-driving cars are capable of                                 avoiding them                                 in order for people to buy self-driving                                 cars and allow them on the road                                 the technology must be trusted as safe                                 and as an engineering student i also                                 came across                                 waymo and uber's uh incident and um                                 it actually got me thinking how hard can                                 it be well                                 it turns out a lot anyway this is how                                 i built the primary prototype                                 so the plan of action here was to                                 basically find the depth of the                                 obstacle present in front of it                                 calculating the total time the object                                 spends in front of the camera                                 detecting the nature of obstacle present                                 in front of it                                 whether it's a moving object or if it's                                 a stationary object                                 and the movement of the car based on                                 this data received by the computer                                 and works real time and mostly using                                 data fed into it                                 over a period of time so the solution                                 here                                 is to basically use opencv now what is                                 opencv                                 and why do we use it opencv is basically                                 an open source library which is aimed at                                 real-time computer vision                                 the library was developed by intel and                                 its cross-platform                                 it would support basically python c plus                                 java                                 and other programming languages computer                                 vision is a cutting-edge field of                                 computer science that aims to enable                                 computers to understand                                 what is being seen in front of the image                                 opencv                                 is one of the most widely used libraries                                 for computer vision tasks                                 like face recognition motion recognition                                 object detection etc                                 several people have been working on this                                 for a few decades now                                 but only for specific applications and                                 more to do                                 with their software than software and                                 hardware integration                                 so i decided to attempt a combination of                                 these applications                                 like lane detection traffic light and                                 signal detection                                 pedestrian detection into one prototype                                 and also keeping in mind                                 only the software point of view and                                 trying to perfect it and later plan                                 on scaling it into hardware if it's okay                                 i take a little water break                                 um so one of the first things i did                                 was basically traffic light detection                                 so three things must be kept in mind                                 identifying the regions of interest                                 training a classifier tracking and                                 optimization                                 so images from urban areas usually have                                 a lot of things going on                                 there are cars pedestrians traffic                                 lights and a lot of information                                 that needs to be processed at a quick                                 rate                                 the detection limits the amount of time                                 basically the amount of information                                 that needs to be analyzed into much                                 smaller regions of interest                                 now the regions of interest presents a                                 list of potential traffic light                                 candidates                                 and if it is implemented correctly the                                 detection should improve the system                                 speed                                 and performance i would also like to                                 talk about a few methods that i tried                                 and also explain why i wouldn't                                 recommend it                                 so a lot of you might have heard about                                 sliding windows                                 now i will explain why i did not use it                                 so sliding windows is basically a box                                 or also known as slides across the image                                 at                                 every interval and the classifier checks                                 if the contents                                 inside the window is the traffic light                                 or if it is something else                                 sliding windows are simple intuitive and                                 easy to implement                                 the purpose of the region of interest is                                 to limit the work that the classifier                                 has to do                                 if we were to use this approach we would                                 need                                 relatively small windows to capture                                 traffic light                                 to handle the range of traffic light                                 sizes we would have to run the sliding                                 window approach                                 multiple times using different window                                 sizes or can and construct a pyramid                                 an image pyramid so this would basically                                 be                                 an extremely complicated task                                 now color thresholding is also extremely                                 popular                                 uh traffic lights emit one of the three                                 colors basically red yellow and green                                 or green um the basic idea behind color                                 thresholding                                 is basically to limit to where these                                 three colors are present                                 anywhere where the image is not red                                 yellow or green                                 is set to basically black to effectively                                 isolate the colors we are interested in                                 a few considerations need to be covered                                 like color space                                 threshold cut-off and variation in                                 illumination                                 typically images are present in the rgb                                 color space                                 however rgb mixes the color and                                 intensity information                                 through its channels this makes the rgb                                 format sensitive to changes in lighting                                 to detect the traffic lights we can't                                 have variation in lighting depending on                                 whether                                 the uh weather what stops the threshold                                 from picking out the right colors                                 so to compare this many opt to convert                                 color spaces that separate color                                 from image intensity now some of the                                 more viable options                                 are like spotlight detection so a                                 spotlight is basically                                 a bright area in an image surrounded by                                 a darker area                                 the idea behind this detection method is                                 that traffic lights will appear brighter                                 than their immediate surroundings the                                 image is transformed into gray scale                                 and a white top hat filter is applied                                 now the white top hat filter                                 highlights the areas that are brighter                                 than their surroundings                                 the stop light detection method is                                 robust to variations in illumination                                 because of the structuring element which                                 is basically the kernel                                 is applied locally meaning uneven                                 background illumination                                 would not be a problem we can find blob                                 in the image and filter them by shape or                                 size                                 unlike before we do not rely on color                                 information                                 now another very advanced method is                                 block analysis and morphological filters                                 a block basically stands for binary                                 large object                                 and refers to a group of connected                                 pixels in an image                                 so the image shown here basically a dart                                 connected region                                 known as blob and another example is a                                 red thresholding image basically shown                                 here                                 and so every red object is basically an                                 image                                 and can be viewed as a block with                                 important properties                                 like shape and size so the color and                                 blob based methods customly use                                 morphological filters                                 to refine the information in the scene                                 so morphology is a broad set                                 of image processing and basically                                 processes the                                 images based on its shape so the erosion                                 and dilation are two fundamental                                 morphological operations                                 so in dilation the object is in the                                 foreground                                 is enlarged while the erosion erodes                                 away the boundary of the foreground                                 foreground object so dilation is                                 basically great for joining                                 broken paths of an object and erosion                                 comes in handy                                 at like later stages to remove noise                                 block analysis can also help filter                                 non-traffic lights by comparing it to                                 the blocks property of                                 what we expect our traffic lights                                 properties should be                                 so the traffic light should be circular                                 with the                                 exception of like turn signals because                                 they are also circular in shape                                 and would not take up a large part of                                 the image                                 so we select blobs that are somewhat                                 circular but not too large                                 and the final product is a set of                                 traffic light candidates                                 that meet the shape and size criteria                                 so next traffic sign detection road sign                                 recognition                                 is a significant and essential part in                                 intelligent vehicle navigation systems                                 so the text and logo embedded in a road                                 sign                                 usually contains a lot of information uh                                 such as guided direction                                 and current traffic conditions of you                                 know that particular role                                 however it is a hard task to find and                                 extract road signs                                 exactly from a single natural image due                                 to complex backgrounds                                 variable light condition appearance                                 degeneration                                 perspective effects caused by the camera                                 and the recognition                                 of road signs is a challenging problem                                 that has engaged the attention of the                                 computer vision community                                 for more than                                                         sign                                 is normally highly contrasted in their                                 backgrounds and rectangles are often                                 designed                                 for road signs previously the approaches                                 were divided into two categories                                 that is color-based and shape-based                                 methods                                 the system recognizes and interprets                                 various                                 signs using vision only information                                 and therefore science must be obscured                                 by signs which may be                                 basically obscured is like blocked by                                 other vehicles                                 or trees will not be recognized                                 here the algorithm is based on its core                                 competence                                 in vehicles and pedestrian detection the                                 algorithm shares the attention                                 classification and tracking framework of                                 these modules                                 and uses robust classifiers developed in                                 these applications                                 trained on different examples so the                                 algorithm                                 used to detect the hsv is for an image                                 extraction gaussian filter                                 is used the traffic sign is detected                                 using the hsv and the hsp representation                                 of colors                                 basically the hue determines the color                                 that you want                                 saturation determines how intense the                                 color                                 and value determines the light lightness                                 of the image                                 high variance in sign appearance has                                 made the detection                                 and recognition of road science or                                 computer vision problem                                 over which many studies have recently                                 been performed                                 road signs use particular colors and                                 geometric shapes to attract the drivers                                 attention                                 however the difficulty in recognizing                                 road signs                                 are largely because the colors might                                 fade or peel off                                 uh because of long duration of exposure                                 to the sun                                 and basically they can get damaged                                 uh air pollution and the condition can                                 decrease the visibility of road signs                                 outdoor lighting conditions may vary                                 from day to night                                 and affect the colors being perceived by                                 the camera                                 obstacles like trees pools buildings and                                 pedestrians                                 or vehicles that are present in front                                 can                                 basically block the signs from being                                 viewed by the camera                                 also video images of road signs                                 basically suffer from blurring in the                                 view that the camcorder is mounted on                                 top of                                 a moving vehicle so a solution to this                                 is basically the images                                 could be pre-processed in stages with an                                 image processing technique like a                                 threshold technique gaussian filter                                 canny edge detection contour or fit                                 ellipse                                 and these stages are performed to                                 recognize                                 the traffic sign patterns and the main                                 reason to select this method                                 is to reduce the computational cost in                                 order to facilitate real-time                                 implementation                                 so the first strategy is to reduce the                                 number of mlp                                 also known as multi-layer perception                                 inputs                                 by pre-processing traffic sign image and                                 the second strategy                                 is to search for the best network                                 architecture which reduces the                                 complexity                                 by selecting a suitable error criteria                                 for training                                 the system was trained using the                                 training data set                                 validated with a validating data set to                                 find the best network architecture                                 so the cross variation technique is                                 implemented with a training data set                                 validating data set as well as a                                 training as well as a test data set                                 so recent experiments show consistent                                 results                                 with accurate classifications of traffic                                 sign patterns                                 with complex background images                                 now moving on to pedestrian detection                                 pedestrian detection is a very important                                 area of research                                 because it can enhance the functionality                                 of pedestrian protection system                                 in a self-driving car we can extract                                 features                                 like one head two arms and two legs from                                 the image of a human body and pass it                                 into a machine learning model to train                                 it                                 and after training the model can be used                                 to detect                                 and track humans in images and video                                 streams                                 but lucky for us opencv has a built-in                                 method                                 to detect pedestrians and it has a                                 pre-trained hog                                 hog is basically a histogram of oriented                                 gradients                                 and a linear svm model to detect                                 pedestrians                                 in images and video streams so                                 um what is an hog or a histogram of                                 oriented gradients                                 so the algorithm basically checks                                 directly surrounding pixels of every                                 single pixel                                 and the goal is to check how darker the                                 current pixel is                                 compared to the surrounding pixels so                                 the algorithm                                 draws and arrows each of the                                 adjoining uh pixels with a which are                                 basically darker                                 and it repeats the process for each and                                 every pixel                                 in the image at last every pixel                                 is b is now replaced by an arrow and                                 these arrows are called                                 gradients and these gradients show the                                 flow of light                                 from you know a lighter region to a dark                                 region                                 and by using these gradients uh further                                 analysis can be performed                                 uh now lane detection there are multiple                                 ways                                 we can perform lane detection we can use                                 a learning based approach                                 like training a deep learning model or                                 an                                 on an annotated video data set or by                                 using a pre-trained model                                 capturing and decoding the video file is                                 the first step                                 we can capture the video using video                                 capture object                                 and after the capturing has been                                 initialized every video frame                                 is decoded that is converted into a                                 sequence of images                                 the second step is grayscale conversion                                 of the image                                 so the video frames that are in rgb                                 format that is red green and blue                                 ah rgb is converted to a gray scale                                 because processing                                 a single channel image is faster than                                 processing                                 a three color image then the third step                                 is to reduce noise                                 noise can create false edges and                                 therefore before going further it is                                 extremely                                 important to perform immediate                                 smoothening                                 a vertical filter is used to perform                                 this process                                 next canny edge detector it computes the                                 gradients                                 in all directions of our blurred image                                 and traces the edges with large changes                                 in                                 intensity then region of interest                                 this step takes into account only the                                 regions covered by the road lane                                 a mask is created which is of the same                                 dimension                                 as as the road image further a bit wise                                 operator is performed between each pixel                                 of the candy image                                 and this mask it ultimately masks the                                 candy image                                 and shows the region of interest traced                                 by polygonal contour of the mask                                 then the hue line transform the humanoid                                 transform is a transform used to detect                                 straight lines                                 and the parabolistic hue line transform                                 used here                                 gives an output as the extremes of the                                 lines are detected                                 so the library is used for this task and                                 basically across opencv                                 matplotlib and numpy                                 so to conclude i would like to say it is                                 extremely important to keep in mind the                                 human behavioral aspect of self-driving                                 cars before venturing into it                                 i hope you learned quite a bit from my                                 talk if you have any questions                                 or would like to know more please feel                                 free to contact me                                 and also i did a good amount of research                                 into this topic for a few months before                                 dipping my feet into                                 it and i made it a point to learn from                                 articles about                                 field projects and why it didn't work                                 and why it has taken about                                          for people since people started working                                 on it to achieve a small amount of                                 autonomy                                 that these you know cars have                                 thank you hey great great talk abhirani                                 so i know there are a lot of questions                                 actually and                                 uh we've asked them to you know reach                                 out to you on zulip                                 all right yeah so thanks a lot                                 again
YouTube URL: https://www.youtube.com/watch?v=wESdQB8EyhY


