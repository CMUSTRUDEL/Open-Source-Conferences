Title: LPC2018 - eBPF   XDP Based Firewall and Packet Filtering
Publication date: 2018-12-04
Playlist: LPC2018 - Networking Track
Description: 
	url:  https://linuxplumbersconf.org/event/2/contributions/100/
speaker:  Anant Deepak (Facebook),  Puneet Mehra (Facebook),  Richard Huang (Facebook)

iptables have been the typical tool to create firewall for linux hosts. We have used them at Facebook for setting up host firewalls on our servers across a variety of tiers. In this proposal, we introduce a eBPF / XDP based firewall solution which we use for packet filtering and has parity to our iptables implementation. We discuss various aspects of this. Following is a brief summary of these aspects, which we will detail further in the paper / presentation.

Design and Implementation:

We use BPF Tables (maps, lpm tries, and arrays) to match for appropriate packet header contents
The heart of a firewall is a eBPF filter which parses a packet and does lookups against all relevant maps collecting the matching values. A logical rule set is applied to these collected values. This logical set reads similar to a human-readable high level firewall policy. With iptable rules, amidst all the verbose matching criteria inline every rule, such a policy level representation is hard to infer.
Performance benefits and comparisons with iptables

iptables does packet matching linearly against each rule until a match is found. In our proposal, we use BPF Tables (maps) containing keys for all rules, making packet matching highly efficient. We then apply the policy using the collected results, which results in a considerable speedup over iptables.
Ease of policy / config updates and maintenance

The network administrator owns the firewall while the app developers typically require opening ports for their applications to work. With our approach of using a eBPF filter, we create a logical separation between the filter which enforces the policy and the contents of the associated maps which represent the specific ports and prefixes that need to be filtered. The policy is owned by the network administrator (Example: ports open to the internet, ports open from within specific prefixes, drop everything else). The data (port numbers, prefixes, etc) can now belong to a separate logical section which presents application developers a predetermined destination to update their data (Example: File containing port opened to internal subnets, etc). This reduces friction between the 2 different functions and reduces human errors.
Deployment experience:

We deploy this solution in our edge infrastructure to implement our firewall policy.
We update configuration, reload filters and contents of the various maps containing keys and values for filtering
BPF Program array

We use the power of BPF program array to chain different programs like rate limiter, firewall, load balancers, etc. These are building blocks to create a rich, high performant networking solution
Proposal for a completely generic firewall solution to migrate existing iptables rules to eBPF / XDP based filtering

We present a proposal which can translate existing iptables rules to a better performant eBPF program with mostly user space processing and validation.
Captions: 
	00:00:06,069 --> 00:00:12,049
hi guys as well as you know my name is

00:00:09,889 --> 00:00:16,160
Anand Deepak and I'll be talking to you

00:00:12,049 --> 00:00:20,540
about our X TP or EB PF base firewall

00:00:16,160 --> 00:00:22,369
implementation at Facebook so a little

00:00:20,540 --> 00:00:25,399
primer of what we'll be you know talking

00:00:22,369 --> 00:00:28,520
about in today's session I'll give you a

00:00:25,399 --> 00:00:30,919
background about IP tables because that

00:00:28,520 --> 00:00:34,239
was the motivation for us to implement

00:00:30,919 --> 00:00:37,130
our firewall policy in XTP so we will

00:00:34,239 --> 00:00:40,490
visit that background and discuss what

00:00:37,130 --> 00:00:43,100
were the motivating factors then we will

00:00:40,490 --> 00:00:45,380
discuss in details about our firewall

00:00:43,100 --> 00:00:50,000
implementation I'll go into specifics

00:00:45,380 --> 00:00:53,360
share some deployment lessons that we

00:00:50,000 --> 00:00:55,190
learned talk about the performance that

00:00:53,360 --> 00:00:59,500
we see between an IP tables based

00:00:55,190 --> 00:01:02,900
implementation versus the SDP based and

00:00:59,500 --> 00:01:05,210
lastly you'll touch upon a prototype

00:01:02,900 --> 00:01:07,840
that we built having learnt from our

00:01:05,210 --> 00:01:13,460
experience of building a firewall in xdp

00:01:07,840 --> 00:01:15,680
as a generic way to to configure a

00:01:13,460 --> 00:01:19,130
firewall using IP tables but

00:01:15,680 --> 00:01:23,479
implementing it in vpf and that effort

00:01:19,130 --> 00:01:25,729
sort of Maps into the BP filter project

00:01:23,479 --> 00:01:29,720
or initiative that the community is

00:01:25,729 --> 00:01:32,840
trying to take on and hopefully we can

00:01:29,720 --> 00:01:37,070
share some of our lessons and influence

00:01:32,840 --> 00:01:39,970
that direction so IP tables so IP tables

00:01:37,070 --> 00:01:43,940
has existed since a long time it's the

00:01:39,970 --> 00:01:46,690
de-facto host filtering mechanism in

00:01:43,940 --> 00:01:50,330
Linux it's extremely intuitive to use

00:01:46,690 --> 00:01:51,710
people know how to configure it and it's

00:01:50,330 --> 00:01:55,240
straightforward and people like it for

00:01:51,710 --> 00:01:58,520
its simplicity its implementation

00:01:55,240 --> 00:02:01,400
reflects that simplicity so in essence

00:01:58,520 --> 00:02:06,290
what it is is a list of ordered rules

00:02:01,400 --> 00:02:08,000
and each incoming packet is trying to go

00:02:06,290 --> 00:02:10,849
through the list of rules and find the

00:02:08,000 --> 00:02:14,450
first rule that it can match and then

00:02:10,849 --> 00:02:16,790
take action or you know a car which is

00:02:14,450 --> 00:02:18,349
configured for that specific rule and if

00:02:16,790 --> 00:02:19,470
no rule is matched you take the default

00:02:18,349 --> 00:02:23,610
policy which in most

00:02:19,470 --> 00:02:25,620
is just dropping the packet so here's

00:02:23,610 --> 00:02:28,080
what an input chain would look like in

00:02:25,620 --> 00:02:30,000
iptables you essentially have a table

00:02:28,080 --> 00:02:32,100
which is your opening some ports to the

00:02:30,000 --> 00:02:34,530
internet then you start sort of

00:02:32,100 --> 00:02:36,690
specifying more specific rules you may

00:02:34,530 --> 00:02:39,600
want to open specific ports to some

00:02:36,690 --> 00:02:41,280
specific destinations so on and so forth

00:02:39,600 --> 00:02:48,960
and then you have a drop policy in the

00:02:41,280 --> 00:02:52,020
end now this looks nice simple great but

00:02:48,960 --> 00:02:55,320
if you start to look carefully

00:02:52,020 --> 00:02:58,800
imagine a packet that happens to match a

00:02:55,320 --> 00:03:01,350
lower order rule in there now what that

00:02:58,800 --> 00:03:03,420
packet has done is it has spent a bunch

00:03:01,350 --> 00:03:06,240
of CPU cycles trying to match against

00:03:03,420 --> 00:03:09,000
all these previous rules only to have

00:03:06,240 --> 00:03:11,070
arrived at that ends rule and then take

00:03:09,000 --> 00:03:15,209
some action which could be permit in

00:03:11,070 --> 00:03:17,220
this case even worse if it were to be

00:03:15,209 --> 00:03:19,370
dropped it would spend like a few more

00:03:17,220 --> 00:03:21,720
cycles matching against a few more rules

00:03:19,370 --> 00:03:23,970
now if it's ten or fifteen rules this

00:03:21,720 --> 00:03:28,830
isn't a problem but in fact you may have

00:03:23,970 --> 00:03:30,630
like hundreds of rules you notice and we

00:03:28,830 --> 00:03:34,850
could notice it that you know if you

00:03:30,630 --> 00:03:37,920
compare a high-performance packet stream

00:03:34,850 --> 00:03:41,790
against a room that matches the first

00:03:37,920 --> 00:03:43,290
order rule versus something which

00:03:41,790 --> 00:03:45,330
matches our much lower order rule you'll

00:03:43,290 --> 00:03:48,600
see a lot of variance and the CP

00:03:45,330 --> 00:03:52,290
utilization varies dramatically now when

00:03:48,600 --> 00:03:55,080
you're operating a large network the

00:03:52,290 --> 00:03:58,350
last thing you want is variance in the

00:03:55,080 --> 00:03:59,640
CP utilization are based on incoming

00:03:58,350 --> 00:04:03,510
traffic stream that's an extremely

00:03:59,640 --> 00:04:06,180
undesirable characteristic when managing

00:04:03,510 --> 00:04:09,650
a large T row so we wanted to focus on

00:04:06,180 --> 00:04:09,650
that and see what we could do about it

00:04:10,580 --> 00:04:14,220
so Before we jump onto our

00:04:12,570 --> 00:04:20,959
implementation I wanted to again take a

00:04:14,220 --> 00:04:23,850
step back and try to explain or rather

00:04:20,959 --> 00:04:26,040
describe that even though this IP tables

00:04:23,850 --> 00:04:28,169
looks like one monolithic table which

00:04:26,040 --> 00:04:30,870
has a bunch of rules it has much of port

00:04:28,169 --> 00:04:33,800
numbers and some IP addresses and

00:04:30,870 --> 00:04:37,610
prefixes it really is

00:04:33,800 --> 00:04:41,879
two things it's a policy that some

00:04:37,610 --> 00:04:43,520
security person has defined and then

00:04:41,879 --> 00:04:45,479
it's filled with a bunch of

00:04:43,520 --> 00:04:47,759
characteristics of that specific

00:04:45,479 --> 00:04:50,939
topology port numbers and network

00:04:47,759 --> 00:04:53,490
prefixes so on and so forth and just

00:04:50,939 --> 00:04:55,949
hold on to that card because this was

00:04:53,490 --> 00:04:58,439
also one of the motivation that we had

00:04:55,949 --> 00:05:01,680
when we won't be re-implemented or

00:04:58,439 --> 00:05:04,139
rather implemented our firewall policy

00:05:01,680 --> 00:05:07,310
in xdp is that we wanted to focus on

00:05:04,139 --> 00:05:10,620
this logical separation of a policy

00:05:07,310 --> 00:05:14,789
versus data representing that network

00:05:10,620 --> 00:05:18,509
topology also there are features like IP

00:05:14,789 --> 00:05:20,879
set in the kernel that can address some

00:05:18,509 --> 00:05:23,819
of these concerns that are raised in the

00:05:20,879 --> 00:05:27,659
earlier slide about matching packets so

00:05:23,819 --> 00:05:32,370
you know just keep that in mind all

00:05:27,659 --> 00:05:34,819
right so let's talk about firewall in

00:05:32,370 --> 00:05:38,219
XDP that we have implemented at Facebook

00:05:34,819 --> 00:05:39,539
first let's talk about why did you want

00:05:38,219 --> 00:05:43,409
to do this in the first place

00:05:39,539 --> 00:05:46,490
so as I described earlier one of the

00:05:43,409 --> 00:05:48,539
motivation was we wanted our

00:05:46,490 --> 00:05:49,889
infrastructure specifically our edge

00:05:48,539 --> 00:05:53,279
infrastructure where we are doing this

00:05:49,889 --> 00:05:57,240
packet filtering to have a pretty

00:05:53,279 --> 00:06:00,180
uniform behavior irrespective of the

00:05:57,240 --> 00:06:02,819
nature of packets being received so this

00:06:00,180 --> 00:06:06,449
could be a high PPS packet stream

00:06:02,819 --> 00:06:09,120
targeted at a closed port or could be a

00:06:06,449 --> 00:06:11,580
high VPS packet stream targeted to

00:06:09,120 --> 00:06:13,319
destination port 443 which is you know

00:06:11,580 --> 00:06:16,529
they're very listening to all for all

00:06:13,319 --> 00:06:18,629
our applications we wanted our CPU

00:06:16,529 --> 00:06:21,300
utilization to fail look fairly uniform

00:06:18,629 --> 00:06:26,159
irrespective of the incoming packet

00:06:21,300 --> 00:06:28,439
streams the other thing is Facebook has

00:06:26,159 --> 00:06:30,330
a bunch of networking solutions in xtp

00:06:28,439 --> 00:06:33,449
so we have now a pretty rich networking

00:06:30,330 --> 00:06:36,870
stack in xtp and you'll hear from one of

00:06:33,449 --> 00:06:39,240
my colleagues tomorrow about our l4 load

00:06:36,870 --> 00:06:42,659
balancer called Catron which is also an

00:06:39,240 --> 00:06:43,229
open source project that is implemented

00:06:42,659 --> 00:06:46,229
in xtb

00:06:43,229 --> 00:06:47,190
so it only made sense that if you are

00:06:46,229 --> 00:06:50,210
going to start but load

00:06:47,190 --> 00:06:52,680
balancing packets in XDP we also end up

00:06:50,210 --> 00:06:54,810
putting a firewall before that otherwise

00:06:52,680 --> 00:06:56,970
we're just wasting cycles load balancing

00:06:54,810 --> 00:07:00,570
traffic that eventually will not even be

00:06:56,970 --> 00:07:02,370
admitted into our infrastructure and the

00:07:00,570 --> 00:07:05,520
manageability aspect so I touched upon

00:07:02,370 --> 00:07:09,150
this by trying to illustrate in that in

00:07:05,520 --> 00:07:12,800
that in the table over there there is a

00:07:09,150 --> 00:07:15,810
policy that the security folks want to

00:07:12,800 --> 00:07:18,780
create define have control over and

00:07:15,810 --> 00:07:21,030
there's a network aspect to it which

00:07:18,780 --> 00:07:22,590
means application owners love to write

00:07:21,030 --> 00:07:24,090
new applications especially in a place

00:07:22,590 --> 00:07:26,250
like Facebook which is you know

00:07:24,090 --> 00:07:28,500
extremely software oriented organization

00:07:26,250 --> 00:07:31,680
people write lots of new apps they

00:07:28,500 --> 00:07:35,640
constantly want to open these ports for

00:07:31,680 --> 00:07:38,370
these apps within our intranet and so

00:07:35,640 --> 00:07:40,260
one of the motivation was we wanted to

00:07:38,370 --> 00:07:44,430
create an extremely low frictional

00:07:40,260 --> 00:07:48,900
process where application owners could

00:07:44,430 --> 00:07:51,690
open a port by themselves on our edge

00:07:48,900 --> 00:07:54,620
infrastructure without having to involve

00:07:51,690 --> 00:08:00,810
a bunch of security folks and make it a

00:07:54,620 --> 00:08:03,780
pretty daunting process so let's revisit

00:08:00,810 --> 00:08:05,520
that that representation again so we

00:08:03,780 --> 00:08:06,240
have a policy and a network and in

00:08:05,520 --> 00:08:09,620
iptables

00:08:06,240 --> 00:08:15,870
it looked pretty monolithic in this way

00:08:09,620 --> 00:08:18,900
now imagine if you could express that

00:08:15,870 --> 00:08:21,750
policy in a c program and that's what it

00:08:18,900 --> 00:08:23,640
would look like and we worked this

00:08:21,750 --> 00:08:26,580
implementation backward in the sense

00:08:23,640 --> 00:08:29,280
that you know we wanted this c program

00:08:26,580 --> 00:08:30,810
to be human readable so that just like

00:08:29,280 --> 00:08:32,580
in IP tables which is extremely

00:08:30,810 --> 00:08:34,560
intuitive to read we wanted an

00:08:32,580 --> 00:08:37,760
implementation which over time is also

00:08:34,560 --> 00:08:41,729
maintainable and the security or

00:08:37,760 --> 00:08:43,950
intention can be easily expressed so we

00:08:41,729 --> 00:08:47,490
had a C program which reads something

00:08:43,950 --> 00:08:50,370
like this so how do we bring this all

00:08:47,490 --> 00:08:54,060
together and achieve all those factors

00:08:50,370 --> 00:08:58,980
that we spoke about earlier so the C

00:08:54,060 --> 00:09:00,879
program starts off by doing a lookup for

00:08:58,980 --> 00:09:03,819
each of these

00:09:00,879 --> 00:09:05,769
tuples in our case it's 5-tuple so the

00:09:03,819 --> 00:09:08,470
source address destination address or

00:09:05,769 --> 00:09:12,999
suppose destination port protocol and we

00:09:08,470 --> 00:09:15,939
also have lookups on prefixes and we

00:09:12,999 --> 00:09:17,559
collect all these results for each tuple

00:09:15,939 --> 00:09:23,109
of a packet and this is done for each

00:09:17,559 --> 00:09:25,959
and every packet that comes in the VP of

00:09:23,109 --> 00:09:28,179
map itself for each of these tuples is

00:09:25,959 --> 00:09:31,539
loaded with obviously a key and a value

00:09:28,179 --> 00:09:34,959
that key being the specific attribute so

00:09:31,539 --> 00:09:37,959
let's say port 443 for a TCP port but

00:09:34,959 --> 00:09:40,359
the value here is an identifier and that

00:09:37,959 --> 00:09:43,809
identifier is a logical representation

00:09:40,359 --> 00:09:48,129
of what logical group does that port

00:09:43,809 --> 00:09:51,999
belong to and herein lies the

00:09:48,129 --> 00:09:55,779
manageability whim so what we have is a

00:09:51,999 --> 00:09:58,539
configuration script or a I would call a

00:09:55,779 --> 00:10:01,989
configuration system with just three

00:09:58,539 --> 00:10:04,329
things it creates these logical

00:10:01,989 --> 00:10:06,939
representations for each attribute so

00:10:04,329 --> 00:10:09,249
let me take the example of TCP port so

00:10:06,939 --> 00:10:12,069
it represents some ports calling TCP

00:10:09,249 --> 00:10:14,289
public this would be destination ports

00:10:12,069 --> 00:10:17,079
which are open to the internet it would

00:10:14,289 --> 00:10:18,669
then call some ports TCP production

00:10:17,079 --> 00:10:24,689
maybe these are open to only certain

00:10:18,669 --> 00:10:29,439
production network prefixes and that

00:10:24,689 --> 00:10:34,179
aspect gives application owners very

00:10:29,439 --> 00:10:36,879
human readable and a safe way to express

00:10:34,179 --> 00:10:38,709
if they want to open a port which

00:10:36,879 --> 00:10:40,449
category do they want to open a port in

00:10:38,709 --> 00:10:42,609
so if they really want to open a port

00:10:40,449 --> 00:10:45,039
strictly within our network they can

00:10:42,609 --> 00:10:46,929
choose something like same net say

00:10:45,039 --> 00:10:49,119
expressing that hey I'm writing this

00:10:46,929 --> 00:10:51,639
application I want this port to be open

00:10:49,119 --> 00:10:54,639
to all of Facebook internal traffic and

00:10:51,639 --> 00:10:56,679
I associate this port number with you

00:10:54,639 --> 00:10:59,189
know an identifier called saving it so

00:10:56,679 --> 00:11:02,129
that's this configuration system

00:10:59,189 --> 00:11:06,279
simplifying the ability for users to

00:11:02,129 --> 00:11:08,739
express or rather associate a port with

00:11:06,279 --> 00:11:10,239
a logical group the two other things

00:11:08,739 --> 00:11:14,710
that the configuration system will now

00:11:10,239 --> 00:11:17,520
do is it will generate ahead of

00:11:14,710 --> 00:11:22,480
while that the C program can include

00:11:17,520 --> 00:11:26,500
which is nothing but enums and as you

00:11:22,480 --> 00:11:28,960
can see it's the capitalized identifier

00:11:26,500 --> 00:11:31,630
in the C program so this makes sure that

00:11:28,960 --> 00:11:34,780
the data plane is now consistently

00:11:31,630 --> 00:11:35,830
represented with our policy and the

00:11:34,780 --> 00:11:39,430
third thing that the configuration

00:11:35,830 --> 00:11:42,460
system will do is when we load these BPF

00:11:39,430 --> 00:11:46,540
maps it will make sure that the value

00:11:42,460 --> 00:11:49,900
loaded in these BPF maps have again the

00:11:46,540 --> 00:11:54,640
right enum value so in this case if TCP

00:11:49,900 --> 00:11:56,260
public happens to be a flag hex for this

00:11:54,640 --> 00:11:58,180
configuration system we'll make sure

00:11:56,260 --> 00:12:01,810
that the data plane and how we load the

00:11:58,180 --> 00:12:03,820
map remains consistent now the exact

00:12:01,810 --> 00:12:05,860
value of food is internal to our system

00:12:03,820 --> 00:12:08,620
because from a human point of view we

00:12:05,860 --> 00:12:10,300
have created an identifier called human

00:12:08,620 --> 00:12:17,260
readable identifier called TCP public

00:12:10,300 --> 00:12:19,420
and that gives us a manageability win so

00:12:17,260 --> 00:12:22,450
haven't spoken about like core of the

00:12:19,420 --> 00:12:25,630
program let's talk about what does this

00:12:22,450 --> 00:12:27,490
firewall really do and you know a few

00:12:25,630 --> 00:12:30,540
more details about it so it's stateless

00:12:27,490 --> 00:12:33,100
now that's a design choice we have made

00:12:30,540 --> 00:12:35,140
having said that you know connection

00:12:33,100 --> 00:12:36,370
tracking is as you've heard in various

00:12:35,140 --> 00:12:37,690
talks to the connection tracking is

00:12:36,370 --> 00:12:40,030
possible and something that could be

00:12:37,690 --> 00:12:43,060
doable it's in our implementation we

00:12:40,030 --> 00:12:47,020
have a stateless firewall it's deployed

00:12:43,060 --> 00:12:48,430
all across our edge infrastructure as I

00:12:47,020 --> 00:12:50,440
mentioned earlier because we have a rich

00:12:48,430 --> 00:12:54,790
networking stack in xtp we run this

00:12:50,440 --> 00:12:56,680
before our firewall in fact any packet

00:12:54,790 --> 00:12:58,780
that is deemed to pass this firewall is

00:12:56,680 --> 00:13:02,140
actually a tail cost to our load

00:12:58,780 --> 00:13:04,690
balancer we have some really good

00:13:02,140 --> 00:13:07,710
tooling which will periodically scrub

00:13:04,690 --> 00:13:11,110
these DPF maps and check for consistency

00:13:07,710 --> 00:13:16,440
with our configuration systems as a way

00:13:11,110 --> 00:13:20,640
to indicate that our configuration is

00:13:16,440 --> 00:13:20,640
consistent coherent and as expected

00:13:21,320 --> 00:13:29,060
just like iptables restore which allows

00:13:24,110 --> 00:13:32,270
you to atomically swap a given policy we

00:13:29,060 --> 00:13:35,990
can atomically swap our firewall and

00:13:32,270 --> 00:13:38,690
this is thanks to the way BPF reference

00:13:35,990 --> 00:13:40,790
counting mechanism works what we do is

00:13:38,690 --> 00:13:42,650
whenever there is a change in our

00:13:40,790 --> 00:13:44,840
firewall policy because let's say

00:13:42,650 --> 00:13:47,660
somebody added a new port we simply

00:13:44,840 --> 00:13:50,480
compile a new program loaded into the

00:13:47,660 --> 00:13:53,600
kernel create all the new maps load all

00:13:50,480 --> 00:13:56,090
the new maps and attach the program to

00:13:53,600 --> 00:13:57,950
the same point and drop the reference or

00:13:56,090 --> 00:14:00,470
drop the file descriptor to the old

00:13:57,950 --> 00:14:02,660
program and there on the kernel then you

00:14:00,470 --> 00:14:04,310
know has reference counting it drops you

00:14:02,660 --> 00:14:07,040
know references to the old maps and the

00:14:04,310 --> 00:14:09,050
old programs and it vanishes and now the

00:14:07,040 --> 00:14:11,600
new program takes effect so we get

00:14:09,050 --> 00:14:15,620
similar IP table restore like behavior

00:14:11,600 --> 00:14:18,380
with this firewall we use BCC helpers

00:14:15,620 --> 00:14:22,340
just because they help us avoid some

00:14:18,380 --> 00:14:24,470
boilerplate code and our C policy as I

00:14:22,340 --> 00:14:27,470
said you know the policy for any

00:14:24,470 --> 00:14:29,180
filtering or rather a a firewall is

00:14:27,470 --> 00:14:32,960
something that rarely changes so that C

00:14:29,180 --> 00:14:34,850
program that you saw has had very few

00:14:32,960 --> 00:14:37,070
changes most of the changes that we see

00:14:34,850 --> 00:14:39,200
our folks are trying to add a port or a

00:14:37,070 --> 00:14:41,180
network prefix or removing a port

00:14:39,200 --> 00:14:45,890
because their application is you know

00:14:41,180 --> 00:14:48,350
their deprecating it one interesting

00:14:45,890 --> 00:14:50,450
thing that we did learn from this is you

00:14:48,350 --> 00:14:54,140
know when you're using the longest

00:14:50,450 --> 00:14:59,120
prefix match it is important that when

00:14:54,140 --> 00:15:02,240
you load the the LPM try that you look

00:14:59,120 --> 00:15:04,490
for overlapping prefixes and this can

00:15:02,240 --> 00:15:07,100
cause some interesting result and this

00:15:04,490 --> 00:15:09,560
is something that we learned while doing

00:15:07,100 --> 00:15:11,240
some tests is that you know the in the

00:15:09,560 --> 00:15:14,300
data plane as the name suggests is going

00:15:11,240 --> 00:15:16,730
to return to you the value of the

00:15:14,300 --> 00:15:20,180
longest prefix when it's looking up up

00:15:16,730 --> 00:15:21,440
you know a particular IP prefix and so

00:15:20,180 --> 00:15:24,370
if you happen to have overlapping

00:15:21,440 --> 00:15:27,290
prefixes make sure you use flags and

00:15:24,370 --> 00:15:30,050
logically or bitwise are those values so

00:15:27,290 --> 00:15:34,930
that in the data plane now when you get

00:15:30,050 --> 00:15:38,290
a result that result can be indicated of

00:15:34,930 --> 00:15:41,350
having matched both those identifiers so

00:15:38,290 --> 00:15:46,150
that your decision-making engine can

00:15:41,350 --> 00:15:48,970
take the appropriate action just like

00:15:46,150 --> 00:15:53,260
iptables where you know pretty often

00:15:48,970 --> 00:15:56,140
people will log packets drop packets for

00:15:53,260 --> 00:15:58,570
you know analysis we do something

00:15:56,140 --> 00:16:00,820
similar we sample packets at a certain

00:15:58,570 --> 00:16:02,920
rate which sample drop packets at a

00:16:00,820 --> 00:16:06,370
certain rate and write them to a b PF /

00:16:02,920 --> 00:16:09,610
pi / phi which are user space demon will

00:16:06,370 --> 00:16:11,320
you know read it's in essence what we're

00:16:09,610 --> 00:16:13,390
doing in XDP mode is just taking the

00:16:11,320 --> 00:16:15,670
first n bytes of a packet and writing it

00:16:13,390 --> 00:16:17,529
on to the power 5 I use this PS daemon

00:16:15,670 --> 00:16:20,020
reads it parses it and writes to a

00:16:17,529 --> 00:16:23,500
logging infrastructure same thing for

00:16:20,020 --> 00:16:25,900
statistics and a few specific things for

00:16:23,500 --> 00:16:28,900
our infrastructure because now that we

00:16:25,900 --> 00:16:32,350
can write AC program we can do a few

00:16:28,900 --> 00:16:34,420
custom own things so for example we do

00:16:32,350 --> 00:16:36,610
see tunneled headers inside our

00:16:34,420 --> 00:16:43,529
infrastructure and we can go look beyond

00:16:36,610 --> 00:16:45,940
that basically passed on with headers so

00:16:43,529 --> 00:16:47,529
one thing that I would like to call out

00:16:45,940 --> 00:16:48,850
of the difference is in IP tables you

00:16:47,529 --> 00:16:51,700
would have seen that you know you get

00:16:48,850 --> 00:16:54,190
per rule granularity statistics we lose

00:16:51,700 --> 00:16:56,620
that and this is because now we

00:16:54,190 --> 00:16:58,750
represent statistics on a a granade

00:16:56,620 --> 00:17:01,480
policy level so we can say how many

00:16:58,750 --> 00:17:05,020
packets were received towards the

00:17:01,480 --> 00:17:07,120
logical group of destination TCP ports

00:17:05,020 --> 00:17:09,760
open to the Internet but we cannot

00:17:07,120 --> 00:17:12,910
distinguish packets received on port 80

00:17:09,760 --> 00:17:15,699
versus port 443 and in our logging

00:17:12,910 --> 00:17:17,189
infrastructure or you know this is not a

00:17:15,699 --> 00:17:19,780
problem

00:17:17,189 --> 00:17:22,120
we keep things simple so we have accept

00:17:19,780 --> 00:17:25,260
and drop as the two sort of actions we

00:17:22,120 --> 00:17:27,850
support rejects can be possible with BPF

00:17:25,260 --> 00:17:30,070
we don't do that you can do custom

00:17:27,850 --> 00:17:34,650
chains with tail call call into another

00:17:30,070 --> 00:17:34,650
program again that's not something we do

00:17:36,000 --> 00:17:41,950
so assign your own performance so this

00:17:39,520 --> 00:17:43,630
graph is slightly contrived to make the

00:17:41,950 --> 00:17:45,820
point but what it's trying to indicate

00:17:43,630 --> 00:17:48,040
here is that little blue line that

00:17:45,820 --> 00:17:48,520
you'll see is that uniform distribution

00:17:48,040 --> 00:17:52,000
of

00:17:48,520 --> 00:17:54,670
traffic are there are xdb based

00:17:52,000 --> 00:17:57,130
implementation which remains a fairly

00:17:54,670 --> 00:17:59,110
constant constant irrespective of the

00:17:57,130 --> 00:18:01,960
nature of the traffic so in that blue

00:17:59,110 --> 00:18:04,750
line is that in that span was traffic

00:18:01,960 --> 00:18:07,270
sent to quote encode the first rule and

00:18:04,750 --> 00:18:13,240
also a block port the CPU performance

00:18:07,270 --> 00:18:14,590
remained fairly fairly even with IP

00:18:13,240 --> 00:18:15,670
tables as you can see from the yellow

00:18:14,590 --> 00:18:18,010
line it was an order of magnitude

00:18:15,670 --> 00:18:21,310
different again it's a contrived example

00:18:18,010 --> 00:18:23,470
to sort of highlight the point you know

00:18:21,310 --> 00:18:26,590
in practical networks this is not

00:18:23,470 --> 00:18:28,450
exactly how it'll manifest so just bear

00:18:26,590 --> 00:18:33,280
that in mind it not end of the world for

00:18:28,450 --> 00:18:35,500
people using IP tables all right so this

00:18:33,280 --> 00:18:37,200
was great you know we implemented a

00:18:35,500 --> 00:18:39,460
firewall we wrote our C program

00:18:37,200 --> 00:18:43,560
everybody was happy we got some solid

00:18:39,460 --> 00:18:49,030
manageability wins and you know we got

00:18:43,560 --> 00:18:51,690
good performance didn't Facebook then we

00:18:49,030 --> 00:18:54,270
started you know having different teams

00:18:51,690 --> 00:18:58,140
talk about hey we are doing some

00:18:54,270 --> 00:19:03,100
filtering maybe on a container maybe on

00:18:58,140 --> 00:19:04,960
you know in TC mode and each team would

00:19:03,100 --> 00:19:07,330
wonder alright you guys did this for

00:19:04,960 --> 00:19:09,250
your edge infrastructure how did you do

00:19:07,330 --> 00:19:12,340
this and is there something we could

00:19:09,250 --> 00:19:14,770
leverage and that's an event like yeah

00:19:12,340 --> 00:19:16,540
we wrote a C program custom to our logic

00:19:14,770 --> 00:19:18,190
so if you want to write another C

00:19:16,540 --> 00:19:20,290
program we could give you all our

00:19:18,190 --> 00:19:21,880
configuration system and that's when

00:19:20,290 --> 00:19:23,440
sort of things started to like how well

00:19:21,880 --> 00:19:25,990
you're writing custom code so you know

00:19:23,440 --> 00:19:29,140
let's go do our own thing you know let's

00:19:25,990 --> 00:19:31,870
write our own software and that's when

00:19:29,140 --> 00:19:35,400
we realized that okay what if we could

00:19:31,870 --> 00:19:41,400
take the same specification of iptables

00:19:35,400 --> 00:19:45,160
but get all the performance winds of BBF

00:19:41,400 --> 00:19:47,380
so the idea is create like a drop-in

00:19:45,160 --> 00:19:49,540
replacement for IP tables so you have IP

00:19:47,380 --> 00:19:52,210
tables you configure the rules in that

00:19:49,540 --> 00:19:55,750
language but you create a BPF program

00:19:52,210 --> 00:19:58,990
and you associate it at maybe some

00:19:55,750 --> 00:20:01,180
customizable attach point it could be

00:19:58,990 --> 00:20:02,059
xdp mode it could be TC more it could be

00:20:01,180 --> 00:20:06,379
a container

00:20:02,059 --> 00:20:08,570
and the idea is let the user space

00:20:06,379 --> 00:20:11,719
module do most of the work which is load

00:20:08,570 --> 00:20:14,570
the BPF maps verify your consistency in

00:20:11,719 --> 00:20:17,090
configuration and how a BPF program do

00:20:14,570 --> 00:20:20,539
the minimal work so what is this BPF

00:20:17,090 --> 00:20:24,859
program going to look like so this is

00:20:20,539 --> 00:20:27,080
revisiting our implementation or in BBF

00:20:24,859 --> 00:20:31,070
so there was a c program we looked up

00:20:27,080 --> 00:20:33,229
all the tuples and our BPF maps were key

00:20:31,070 --> 00:20:39,259
values where the values were logical

00:20:33,229 --> 00:20:40,969
representation on of a group now let's

00:20:39,259 --> 00:20:44,089
talk about our prototype which does

00:20:40,969 --> 00:20:46,940
generic iptables implementation so here

00:20:44,089 --> 00:20:49,009
the overall scheme remains similar that

00:20:46,940 --> 00:20:53,919
is each packet goes and does a lookup

00:20:49,009 --> 00:20:58,489
for each tuple in a pre-configured map

00:20:53,919 --> 00:21:02,359
but the maps value now is essentially a

00:20:58,489 --> 00:21:03,739
large bitmap and the number of bits is

00:21:02,359 --> 00:21:06,529
equal to the number of rules so let's

00:21:03,739 --> 00:21:10,159
say you have thousand rules you have 128

00:21:06,529 --> 00:21:15,289
bits sorry 1000 bits which is like you

00:21:10,159 --> 00:21:21,440
know 128 bytes worth of a an array of

00:21:15,289 --> 00:21:23,960
you would since you and 64 and what the

00:21:21,440 --> 00:21:26,269
value is now representing is a 1 or a 0

00:21:23,960 --> 00:21:27,919
which means it's either a match which

00:21:26,269 --> 00:21:30,229
means you happen to have specified

00:21:27,919 --> 00:21:34,580
explicitly the criteria in that specific

00:21:30,229 --> 00:21:37,190
rule to match that tuple or it could be

00:21:34,580 --> 00:21:40,849
a wild-card which again would be a match

00:21:37,190 --> 00:21:43,969
or it could be 0 because maybe somebody

00:21:40,849 --> 00:21:46,789
else had another criteria in there for

00:21:43,969 --> 00:21:49,580
that specific tuple so the idea is we

00:21:46,789 --> 00:21:53,629
collect all these results so if you are

00:21:49,580 --> 00:21:58,639
doing 5 tuples you'll have 5 such huge

00:21:53,629 --> 00:22:00,859
bitmaps and now what we try to do is we

00:21:58,639 --> 00:22:03,979
do a logical and of these 5 bitmaps

00:22:00,859 --> 00:22:08,320
which represents the intersection of all

00:22:03,979 --> 00:22:11,299
these tuples and the first bit set

00:22:08,320 --> 00:22:15,980
indicates the highest order rule that

00:22:11,299 --> 00:22:18,350
matches your the the IP table rules

00:22:15,980 --> 00:22:20,480
so what the BPF program does is in

00:22:18,350 --> 00:22:22,539
addition to having issued the lookups

00:22:20,480 --> 00:22:25,909
for each of the maps is essentially

00:22:22,539 --> 00:22:28,610
going through each word the length of

00:22:25,909 --> 00:22:32,600
the words being reflective of the number

00:22:28,610 --> 00:22:34,610
of rules that you have doing a logical

00:22:32,600 --> 00:22:36,169
and of these words and trying to find

00:22:34,610 --> 00:22:39,440
the first bit set so it's a fairly

00:22:36,169 --> 00:22:41,779
straightforward BPF program but now it

00:22:39,440 --> 00:22:48,740
gives you the ability to translate

00:22:41,779 --> 00:22:50,809
generic IP tables into a BPF program so

00:22:48,740 --> 00:22:55,220
from a performance point of view this

00:22:50,809 --> 00:22:57,529
was very similar to our custom vpf

00:22:55,220 --> 00:22:59,000
program we didn't notice any difference

00:22:57,529 --> 00:23:01,519
which is again obvious because if you

00:22:59,000 --> 00:23:04,539
see both the programs are doing map

00:23:01,519 --> 00:23:07,210
lookups for the same number of tuples

00:23:04,539 --> 00:23:12,019
once you get the results you are

00:23:07,210 --> 00:23:13,580
essentially doing BPF instructions which

00:23:12,019 --> 00:23:16,460
is now you're playing just within

00:23:13,580 --> 00:23:19,399
branching instructions and by definition

00:23:16,460 --> 00:23:21,799
a BPF prog program is limited to only X

00:23:19,399 --> 00:23:23,990
instructions so one can argue that you

00:23:21,799 --> 00:23:25,760
can only have so much variance given two

00:23:23,990 --> 00:23:28,460
different packet streams so we saw a

00:23:25,760 --> 00:23:30,769
pretty even line in terms of our CPU

00:23:28,460 --> 00:23:36,799
utilization irrespective of the packet

00:23:30,769 --> 00:23:38,659
stream some specifics about this

00:23:36,799 --> 00:23:41,059
prototype implementation so we use the

00:23:38,659 --> 00:23:44,299
output of IP tables save which is a

00:23:41,059 --> 00:23:47,809
pretty human readable expression of IP

00:23:44,299 --> 00:23:50,299
tables and used a Python loader with BCC

00:23:47,809 --> 00:23:53,029
helpers to populate all our maps and

00:23:50,299 --> 00:23:55,220
these were / - pull maps so it was

00:23:53,029 --> 00:23:58,490
simple parser for input chains we had

00:23:55,220 --> 00:24:00,320
five tuples and TCP flags we did not

00:23:58,490 --> 00:24:02,029
subject support reject rules again we

00:24:00,320 --> 00:24:05,529
kept kept it simple with accept and drop

00:24:02,029 --> 00:24:08,299
and it was a stateless firewall

00:24:05,529 --> 00:24:11,240
so what are the lessons learned from

00:24:08,299 --> 00:24:14,120
this so you know we heard about the BP

00:24:11,240 --> 00:24:17,570
filter initiative and we were like this

00:24:14,120 --> 00:24:20,990
is great like what if we go back in time

00:24:17,570 --> 00:24:23,330
and we had a way to transparently map

00:24:20,990 --> 00:24:25,700
all these IP table rules into a BPF

00:24:23,330 --> 00:24:28,519
program it would have certainly taken a

00:24:25,700 --> 00:24:29,160
lot of arm solved a lot of the problems

00:24:28,519 --> 00:24:31,809
which

00:24:29,160 --> 00:24:34,030
probably make us reflect harder on the

00:24:31,809 --> 00:24:37,840
choice to write a custom C program and a

00:24:34,030 --> 00:24:41,080
custom firewall implementation and so

00:24:37,840 --> 00:24:46,360
going back at it I think we would love

00:24:41,080 --> 00:24:50,440
to see a a B P filter implementation

00:24:46,360 --> 00:24:54,850
which can transparently map IP table

00:24:50,440 --> 00:24:58,480
rules into a b PF program and i think

00:24:54,850 --> 00:25:00,610
there are two ways to go about it one

00:24:58,480 --> 00:25:03,309
could be an implicit rather or a

00:25:00,610 --> 00:25:06,220
transparent way where you know the

00:25:03,309 --> 00:25:08,049
kernel could internally decide that you

00:25:06,220 --> 00:25:10,090
know these IP table rules can be

00:25:08,049 --> 00:25:13,150
implemented in b PF and i can attach it

00:25:10,090 --> 00:25:15,910
to wherever the you know the user have

00:25:13,150 --> 00:25:17,559
asked me to in which in most cases in

00:25:15,910 --> 00:25:21,870
the is in the ingress packet processing

00:25:17,559 --> 00:25:26,650
part or you could make it a more

00:25:21,870 --> 00:25:30,700
voluntary adoption by creating be p

00:25:26,650 --> 00:25:34,570
filter options to the IP tables family

00:25:30,700 --> 00:25:37,870
of tools basically save restore and IP

00:25:34,570 --> 00:25:43,260
tables wherein you drive adoption but in

00:25:37,870 --> 00:25:45,880
a more voluntary way i don't have the

00:25:43,260 --> 00:25:49,510
foresight or rather the context to

00:25:45,880 --> 00:25:54,429
influence that decision but i think

00:25:49,510 --> 00:25:59,070
given the nature of this feature its

00:25:54,429 --> 00:26:04,770
wide usage we do believe that it is a

00:25:59,070 --> 00:26:06,970
great way to drive adoption for BPF

00:26:04,770 --> 00:26:11,590
within the community

00:26:06,970 --> 00:26:13,570
the winds are obvious and if we could

00:26:11,590 --> 00:26:15,880
gain more communal forks in the

00:26:13,570 --> 00:26:18,940
community to use BPF and generate more

00:26:15,880 --> 00:26:22,690
interest that could be a setting stage

00:26:18,940 --> 00:26:25,900
to maybe create more features for

00:26:22,690 --> 00:26:29,200
filtering mechanism and allow for more

00:26:25,900 --> 00:26:32,169
customizations beyond what IP tables can

00:26:29,200 --> 00:26:34,600
offer today so the pitch is basically

00:26:32,169 --> 00:26:37,530
you know you get your IP table see the

00:26:34,600 --> 00:26:40,660
same specificity specification language

00:26:37,530 --> 00:26:42,500
but a much more performant version of it

00:26:40,660 --> 00:26:44,810
and it can come with

00:26:42,500 --> 00:26:47,270
restrictions because I do believe that

00:26:44,810 --> 00:26:50,480
most of the folks you know who use IP

00:26:47,270 --> 00:26:52,940
tables out there use a certain

00:26:50,480 --> 00:26:54,560
restricted set of features and you know

00:26:52,940 --> 00:26:57,200
supporting all the possible options

00:26:54,560 --> 00:27:02,480
might be an arduous task if we were to

00:26:57,200 --> 00:27:04,130
ever support this in BPF so here are a

00:27:02,480 --> 00:27:06,410
few references to some of the things I

00:27:04,130 --> 00:27:09,200
had mentioned um interestingly one of

00:27:06,410 --> 00:27:11,270
her colleagues attended sigcomm earlier

00:27:09,200 --> 00:27:13,970
this year and there was a very

00:27:11,270 --> 00:27:16,210
interesting paper on accelerating Linux

00:27:13,970 --> 00:27:19,580
security with EB PF which had very

00:27:16,210 --> 00:27:21,200
similar design ideas about implementing

00:27:19,580 --> 00:27:25,760
a high performance firewall

00:27:21,200 --> 00:27:28,810
so you know it great coincidence that

00:27:25,760 --> 00:27:32,780
this is happening and we hope you know

00:27:28,810 --> 00:27:35,420
this takes off and one day we can get

00:27:32,780 --> 00:27:40,870
rid of our C program and just rely on VP

00:27:35,420 --> 00:27:40,870
filter any questions

00:27:49,519 --> 00:27:56,549
thank you did did you open-source this

00:27:53,399 --> 00:27:59,460
work uh no so we had so our

00:27:56,549 --> 00:28:01,980
implementation for the one that we are

00:27:59,460 --> 00:28:05,789
running in production is fairly specific

00:28:01,980 --> 00:28:08,340
to our infrastructure so as I sure it's

00:28:05,789 --> 00:28:10,379
an expression of a policy so there's not

00:28:08,340 --> 00:28:12,360
much value in open sourcing that as is I

00:28:10,379 --> 00:28:13,950
mean anybody could write and come up

00:28:12,360 --> 00:28:17,100
with come up with that policy for their

00:28:13,950 --> 00:28:19,679
network definitely the the prototype

00:28:17,100 --> 00:28:22,909
that we wrote you know we are in touch

00:28:19,679 --> 00:28:25,620
with you know Alexi and Daniel here and

00:28:22,909 --> 00:28:27,629
we haven't really open sourced it yet

00:28:25,620 --> 00:28:30,629
but you know depending on the feedback

00:28:27,629 --> 00:28:33,210
if it's about driving it or you know

00:28:30,629 --> 00:28:35,519
putting up the patches on your github

00:28:33,210 --> 00:28:39,029
that's certainly something we could look

00:28:35,519 --> 00:28:44,509
into but our interest here at this point

00:28:39,029 --> 00:28:47,820
is long term in the in the sense that we

00:28:44,509 --> 00:28:50,639
hope that we're the evolution of pp

00:28:47,820 --> 00:28:53,039
filter can help us remove some of these

00:28:50,639 --> 00:28:58,919
custom codes that we have in our case

00:28:53,039 --> 00:29:00,990
this custom C program without statistics

00:28:58,919 --> 00:29:03,659
how do you do attack vector

00:29:00,990 --> 00:29:08,610
identification so we have statistics but

00:29:03,659 --> 00:29:12,990
what we don't have is a Perl sort of

00:29:08,610 --> 00:29:15,450
rule or per port statistics but as I

00:29:12,990 --> 00:29:18,840
expressed you know typically when we

00:29:15,450 --> 00:29:21,649
look at our our incoming network data

00:29:18,840 --> 00:29:24,809
what we are interested is in looking at

00:29:21,649 --> 00:29:27,269
metrics of how many packets did we

00:29:24,809 --> 00:29:28,590
receive from the internet on a bunch of

00:29:27,269 --> 00:29:30,690
these ports that are open to the

00:29:28,590 --> 00:29:34,830
Internet or how many packets are flowing

00:29:30,690 --> 00:29:37,830
between our internal ports that we open

00:29:34,830 --> 00:29:40,110
only within our network while we do lose

00:29:37,830 --> 00:29:42,779
the granularity of you know ambiguous

00:29:40,110 --> 00:29:45,419
disambiguating between as in my example

00:29:42,779 --> 00:29:48,750
as I said port 80 and 443 we haven't

00:29:45,419 --> 00:29:51,389
found that to be a concern because you

00:29:48,750 --> 00:29:53,580
know we also have other visibility into

00:29:51,389 --> 00:29:55,590
incoming traffic to our infrastructure

00:29:53,580 --> 00:29:59,159
with you know net flow and other kind of

00:29:55,590 --> 00:29:59,600
sampling so this has not come up yet but

00:29:59,159 --> 00:30:01,400
I

00:29:59,600 --> 00:30:04,130
as I did call out you're right that you

00:30:01,400 --> 00:30:06,410
know we are losing some fine grain stats

00:30:04,130 --> 00:30:08,360
interestingly even though we had those

00:30:06,410 --> 00:30:10,549
stats it was the problem of too much

00:30:08,360 --> 00:30:12,890
data like fine we had all these stats

00:30:10,549 --> 00:30:20,020
and iptables but what are we doing with

00:30:12,890 --> 00:30:21,980
it so so one thing I want to say is that

00:30:20,020 --> 00:30:25,760
one thing that's really difficult with a

00:30:21,980 --> 00:30:28,120
project like BP filter is you always

00:30:25,760 --> 00:30:30,730
have to create a certain amount of

00:30:28,120 --> 00:30:34,039
infrastructure and basic functionality

00:30:30,730 --> 00:30:35,270
before you get that big wave of people

00:30:34,039 --> 00:30:37,490
jumping onto the project and

00:30:35,270 --> 00:30:39,530
contributing and I thought we had we put

00:30:37,490 --> 00:30:43,490
enough in there initially to do that and

00:30:39,530 --> 00:30:44,840
it wasn't so people could keep asking

00:30:43,490 --> 00:30:47,600
what's what's going on VP filter or

00:30:44,840 --> 00:30:49,700
whatever and I know that all we need to

00:30:47,600 --> 00:30:50,870
do is add more basic functionality so

00:30:49,700 --> 00:30:53,780
that the framework is there for people

00:30:50,870 --> 00:30:55,789
to add their use cases to and I think

00:30:53,780 --> 00:30:57,890
maybe one of the ways to kind of get

00:30:55,789 --> 00:31:00,049
around that limitation and get more

00:30:57,890 --> 00:31:05,000
effort into it is to take the approach

00:31:00,049 --> 00:31:06,590
you guys did which is to you know have

00:31:05,000 --> 00:31:08,390
this optional thing with iptables

00:31:06,590 --> 00:31:13,010
command line that does the BPF code

00:31:08,390 --> 00:31:14,809
generator and then we have the code that

00:31:13,010 --> 00:31:17,120
we need we would need in the BP filter

00:31:14,809 --> 00:31:19,850
user mode helper to do the different

00:31:17,120 --> 00:31:21,500
kinds of iptables features it's just

00:31:19,850 --> 00:31:26,289
sitting somewhere else temporarily until

00:31:21,500 --> 00:31:29,240
we integrate it into the kernel side so

00:31:26,289 --> 00:31:32,450
so I guess what I'm trying to say is the

00:31:29,240 --> 00:31:36,169
more people who write iptables imitators

00:31:32,450 --> 00:31:37,730
that generate BPF code the better and I

00:31:36,169 --> 00:31:40,309
don't care where it ends up in the end

00:31:37,730 --> 00:31:41,780
and I'm really encouraged by the work

00:31:40,309 --> 00:31:45,289
that you guys are doing in that area all

00:31:41,780 --> 00:31:48,470
right and the point is you know the the

00:31:45,289 --> 00:31:50,740
direction forward is part technical and

00:31:48,470 --> 00:31:53,480
part philosophical and you know how we

00:31:50,740 --> 00:31:55,909
encourage the community and what are the

00:31:53,480 --> 00:31:59,780
ways that we nudge them to use it as you

00:31:55,909 --> 00:32:03,169
said it it is open to discussion and I

00:31:59,780 --> 00:32:05,059
like that approach here in your

00:32:03,169 --> 00:32:06,850
presentation you said it was all your

00:32:05,059 --> 00:32:10,400
stateless what did you do - like

00:32:06,850 --> 00:32:13,540
stateful traffic like did you know how

00:32:10,400 --> 00:32:15,980
many stateful firewall priorities

00:32:13,540 --> 00:32:19,130
so in our as I said in our

00:32:15,980 --> 00:32:21,530
implementation you know given our

00:32:19,130 --> 00:32:25,790
overall scheme of the network

00:32:21,530 --> 00:32:27,770
you know stateful firewalls work given

00:32:25,790 --> 00:32:29,810
what we wanted to achieve with the

00:32:27,770 --> 00:32:30,980
firewall in our networking start you

00:32:29,810 --> 00:32:33,230
will hear tomorrow from one of our

00:32:30,980 --> 00:32:35,570
colleagues will talk about load balancer

00:32:33,230 --> 00:32:39,950
and you know how we do stateful tracking

00:32:35,570 --> 00:32:43,240
there and given them the entire stack it

00:32:39,950 --> 00:32:46,250
didn't seem for us necessary to do

00:32:43,240 --> 00:32:48,050
stateful firewalls but as I as I

00:32:46,250 --> 00:32:49,400
indicated I do believe that you know

00:32:48,050 --> 00:32:52,100
there are multiple projects out there

00:32:49,400 --> 00:32:56,050
there do connection tracking and so if

00:32:52,100 --> 00:32:58,490
you believe this was helpful I don't let

00:32:56,050 --> 00:33:01,780
the statelessness of this implementation

00:32:58,490 --> 00:33:05,630
hold you back adding being stateful is a

00:33:01,780 --> 00:33:14,660
fairly straightforward enhancement to

00:33:05,630 --> 00:33:16,340
what I just promised you anyone else do

00:33:14,660 --> 00:33:17,810
you use this to deploy automatic rules

00:33:16,340 --> 00:33:19,400
for example to mitigate DDoS attacks in

00:33:17,810 --> 00:33:25,300
any way or these all manual kind of

00:33:19,400 --> 00:33:30,020
handcrafted rules so this is more of a

00:33:25,300 --> 00:33:32,510
static policy we have some dynamic

00:33:30,020 --> 00:33:36,740
controls in a networking stack that we

00:33:32,510 --> 00:33:39,350
use for various purposes one of our

00:33:36,740 --> 00:33:41,630
engineers actually presented I believe a

00:33:39,350 --> 00:33:45,470
year ago a project called droplet

00:33:41,630 --> 00:33:47,690
droplet sorry and that is more in line

00:33:45,470 --> 00:33:49,790
with with what you just discussed but it

00:33:47,690 --> 00:33:52,460
all fits into a very similar ecosystem

00:33:49,790 --> 00:33:57,890
but this specific project we only focus

00:33:52,460 --> 00:34:00,620
on please static configuration also

00:33:57,890 --> 00:34:02,330
because it's a pretty uniform deployment

00:34:00,620 --> 00:34:05,270
across all of our Facebook edge

00:34:02,330 --> 00:34:10,790
infrastructure so yeah we don't want to

00:34:05,270 --> 00:34:14,380
keep too many moving pieces here all

00:34:10,790 --> 00:34:14,380
right thank you Anna oh hey

00:34:15,169 --> 00:34:24,389
okay so for the iptables conversion how

00:34:21,000 --> 00:34:27,389
long the corrosion program from the from

00:34:24,389 --> 00:34:29,550
the iptables roof - to the VP program

00:34:27,389 --> 00:34:32,580
how long it runs how efficient it is

00:34:29,550 --> 00:34:35,399
because I think that it must be kind of

00:34:32,580 --> 00:34:39,300
slow right sorry what do you mean how

00:34:35,399 --> 00:34:43,050
long the conversion from iptables rules

00:34:39,300 --> 00:34:44,820
to the BPF maps and program Oh the top

00:34:43,050 --> 00:34:47,190
rows and so that's it could be quite

00:34:44,820 --> 00:34:50,700
costly right uh but it's control plane

00:34:47,190 --> 00:34:52,950
right I mean yeah actually we didn't

00:34:50,700 --> 00:34:54,570
profiler I think we were in a you know

00:34:52,950 --> 00:34:56,180
one of the engineers will help us with

00:34:54,570 --> 00:34:59,460
our Shankaran is is sitting right here

00:34:56,180 --> 00:35:01,020
we did he profile it we were more in a

00:34:59,460 --> 00:35:04,859
prototype phase we wanted to flesh out

00:35:01,020 --> 00:35:06,660
the concept and yeah this was never a

00:35:04,859 --> 00:35:08,130
concern so we didn't really profile it

00:35:06,660 --> 00:35:13,050
but if you're interested we could follow

00:35:08,130 --> 00:35:14,730
up help the one we have at clubs fair

00:35:13,050 --> 00:35:16,530
takes about a second counting the claim

00:35:14,730 --> 00:35:19,250
compilation to produce about if we have

00:35:16,530 --> 00:35:25,020
a hundred or two hundred girls yeah

00:35:19,250 --> 00:35:26,640
about a second yes we had a bob yeah I I

00:35:25,020 --> 00:35:27,930
mean I would be pulling them without my

00:35:26,640 --> 00:35:29,760
hand so I want to give you some numbers

00:35:27,930 --> 00:35:31,890
but it was never a problem like I wasn't

00:35:29,760 --> 00:35:35,849
like going for my coffee when when I was

00:35:31,890 --> 00:35:37,680
running the script so alright thank you

00:35:35,849 --> 00:35:42,130
very much thank you

00:35:37,680 --> 00:35:42,130

YouTube URL: https://www.youtube.com/watch?v=XpBzEq1MwI8


