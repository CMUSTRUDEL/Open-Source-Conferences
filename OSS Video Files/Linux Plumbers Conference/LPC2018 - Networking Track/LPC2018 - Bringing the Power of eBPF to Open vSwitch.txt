Title: LPC2018 - Bringing the Power of eBPF to Open vSwitch
Publication date: 2018-12-04
Playlist: LPC2018 - Networking Track
Description: 
	url:  https://linuxplumbersconf.org/event/2/contributions/107/
speaker:  William Tu (VMware),  Joe Stringer (Isovalent),  Yi-Hung Wei (VMware),  Yifeng Sun (VMware)


Among the various ways of using eBPF, OVS has been exploring the power
of eBPF in three: (1) attaching eBPF to TC, (2) offloading a subset of
processing to XDP, and (3) by-passing the kernel using AF_XDP.
Unfortunately, as of today, none of the three approaches satisfies the
requirements of OVS. In this presentation, weâ€™d like to share the
challenges we faced, experience learned, and seek for feedbacks from
the community for future direction.

Attaching eBPF to TC started first with the most aggressive goal: we
planned to re-implement the entire features of OVS kernel datapath
under net/openvswitch/* into eBPF code. We worked around a couple of
limitations, for example, the lack of TLV support led us to redefine a
binary kernel-user API using a fixed-length array; and without a
dedicated way to execute a packet, we created a dedicated device for
user to kernel packet transmission, with a different BPF program
attached to handle packet execute logic. Currently, we are working on
connection tracking. Although a simple eBPF map can achieve basic
operations of conntrack table lookup and commit, how to handle NAT,
(de)fragmentation, and ALG are still under discussion.

Moving one layer below TC is called XDP (eXpress Data Path), a much
faster layer for packet processing, but with almost no extra packet
metadata and limited BPF helpers support. Depending on the complexity
of flows, OVS can offload a subset of its flow processing to XDP when
feasible. However, the fact that XDP has fewer helper function support
implies that either 1) only very limited number of flows are eligible
for offload, or 2) more flow processing logic needed to be done in
native eBPF.

AF_XDP represents another form of XDP, with a socket interface for
control plane and a shared memory API for accessing packets from
userspace applications. OVS today has another full-fledged datapath
implementation in userspace, called dpif-netdev, used by DPDK
community. By treating the AF_XDP as a fast packet-I/O channel, the
OVS dpif-netdev can satisfy almost all existing features. We are
working on building the prototype and evaluating its performance.

RFC patch:
OVS eBPF datapath.
https://www.mail-archive.com/iovisor-dev@lists.iovisor.org/msg01105.html
Captions: 
	00:00:08,059 --> 00:00:11,059
okay

00:00:12,200 --> 00:00:17,510
William is one of the crazy people

00:00:14,699 --> 00:00:21,449
trying to involved in multiple

00:00:17,510 --> 00:00:24,419
presentations these last two days and in

00:00:21,449 --> 00:00:26,250
particular he's involved in the space

00:00:24,419 --> 00:00:30,300
that I think is really important for the

00:00:26,250 --> 00:00:32,220
evolution and forward progress for EBP F

00:00:30,300 --> 00:00:33,750
and X DP which is people actually

00:00:32,220 --> 00:00:35,640
building cool stuff using this

00:00:33,750 --> 00:00:38,250
technology so we know what the problems

00:00:35,640 --> 00:00:40,530
are what the needs are what we need to

00:00:38,250 --> 00:00:42,120
change what we need to redesign and how

00:00:40,530 --> 00:00:43,890
to remove things forward for other

00:00:42,120 --> 00:00:48,359
people who want to build cool stuff with

00:00:43,890 --> 00:00:52,800
these technologies so here we go thank

00:00:48,359 --> 00:00:58,730
you thank you okay so this is a talk

00:00:52,800 --> 00:01:01,649
about EBP F XTP and open V switch so

00:00:58,730 --> 00:01:04,970
this is doing work with Joe stranger

00:01:01,649 --> 00:01:10,640
from Cillian Ephraim's a long way from

00:01:04,970 --> 00:01:12,750
VMware so I've spent a couple of slides

00:01:10,640 --> 00:01:17,070
explaining why we are doing this work

00:01:12,750 --> 00:01:20,010
and then we have two projects one is

00:01:17,070 --> 00:01:23,700
obvious IPP a project which we started

00:01:20,010 --> 00:01:25,650
about two years ago and then we until we

00:01:23,700 --> 00:01:31,650
start to work on the second project

00:01:25,650 --> 00:01:35,220
called obvious AF xdp project so at a

00:01:31,650 --> 00:01:38,430
high level what is obvious so obvious is

00:01:35,220 --> 00:01:41,400
a software switch implementation running

00:01:38,430 --> 00:01:43,770
the hypervisor so allow you to create

00:01:41,400 --> 00:01:46,560
allow users to create multiple ports and

00:01:43,770 --> 00:01:49,920
these ports can connect multiple virtual

00:01:46,560 --> 00:01:52,650
machines and obvious is a programmable

00:01:49,920 --> 00:01:55,350
post switch meaning that it doesn't know

00:01:52,650 --> 00:01:59,160
how to process the package until you

00:01:55,350 --> 00:02:02,220
have a Sdn controller and programs your

00:01:59,160 --> 00:02:05,610
network policy or never flows in this

00:02:02,220 --> 00:02:08,610
case we are using OpenFlow protocol into

00:02:05,610 --> 00:02:10,979
this switch so for example you can say

00:02:08,610 --> 00:02:11,790
okay forwarding from you can install you

00:02:10,979 --> 00:02:13,590
or saying that

00:02:11,790 --> 00:02:16,349
forwarding from this port to another

00:02:13,590 --> 00:02:16,959
pour or we can drop a packet by saying

00:02:16,349 --> 00:02:20,459
okay

00:02:16,959 --> 00:02:22,890
if the packing match these kind of

00:02:20,459 --> 00:02:26,890
headers then drop it

00:02:22,890 --> 00:02:30,129
and so today mostly obvious consists of

00:02:26,890 --> 00:02:33,790
two component one in slope has Co

00:02:30,129 --> 00:02:37,900
obvious VHD and ER the other is a fast

00:02:33,790 --> 00:02:40,870
path called data paths so when first

00:02:37,900 --> 00:02:43,689
packet comes to obvious it always go to

00:02:40,870 --> 00:02:46,000
the slope s and slope s has more

00:02:43,689 --> 00:02:48,939
complicated stuff like open flow has so

00:02:46,000 --> 00:02:51,129
many tables so many different fields to

00:02:48,939 --> 00:02:54,700
match on the packet and different type

00:02:51,129 --> 00:02:58,329
of actions and after the slope has doing

00:02:54,700 --> 00:03:01,120
the other complicated things it will

00:02:58,329 --> 00:03:04,299
install of row a single flow into the

00:03:01,120 --> 00:03:07,419
data path which is a fast path so that

00:03:04,299 --> 00:03:10,450
substitute subsequent packet will hit

00:03:07,419 --> 00:03:14,769
the fast pass which shows a much better

00:03:10,450 --> 00:03:17,469
performance in this case so most of the

00:03:14,769 --> 00:03:20,650
user use case today for all years we

00:03:17,469 --> 00:03:24,010
have a kernel module obvious openness

00:03:20,650 --> 00:03:27,879
which takeo inside the binney's kernel

00:03:24,010 --> 00:03:31,359
and obviously switch daemon running at a

00:03:27,879 --> 00:03:35,079
user space so the kernel module just

00:03:31,359 --> 00:03:38,829
registered receive packet hook point and

00:03:35,079 --> 00:03:45,159
then do the rest of the processing in

00:03:38,829 --> 00:03:48,579
this kernel module so our motivation for

00:03:45,159 --> 00:03:50,889
the first project is that for the long

00:03:48,579 --> 00:03:53,319
time we want to add a new feature to the

00:03:50,889 --> 00:03:55,780
obvious Colonel the hopheads the kernel

00:03:53,319 --> 00:03:59,079
module first we have to implement this

00:03:55,780 --> 00:04:02,229
feature and then because customer always

00:03:59,079 --> 00:04:04,449
runs older version of the kernel then we

00:04:02,229 --> 00:04:07,359
back power to the older version of the

00:04:04,449 --> 00:04:10,720
kernel and then because kernel keep

00:04:07,359 --> 00:04:14,109
changing a new version so we also need

00:04:10,720 --> 00:04:16,359
to make sure that our new feature indeed

00:04:14,109 --> 00:04:19,690
work correctly in the newer version of

00:04:16,359 --> 00:04:21,669
the kernel and sometimes our customer

00:04:19,690 --> 00:04:24,610
runs the non-standard her know like

00:04:21,669 --> 00:04:27,070
where he has their own bad port over a

00:04:24,610 --> 00:04:29,770
customer strong these do a security

00:04:27,070 --> 00:04:33,490
patch so that we also need to

00:04:29,770 --> 00:04:36,640
change a repeat of our code so in the

00:04:33,490 --> 00:04:40,000
end our kernel module ends up having a

00:04:36,640 --> 00:04:42,550
lot of like if define a also in

00:04:40,000 --> 00:04:45,790
sometimes nested define a O's so it's

00:04:42,550 --> 00:04:50,230
very hard to read and the bugs are very

00:04:45,790 --> 00:04:54,210
hard to find out so that's the why we

00:04:50,230 --> 00:04:57,100
are thinking about using EBP F so

00:04:54,210 --> 00:05:01,150
because the PPF have much more stable

00:04:57,100 --> 00:05:03,940
API and it's guaranteed to run in the

00:05:01,150 --> 00:05:06,400
new kernel so if we increment everything

00:05:03,940 --> 00:05:08,800
today in this kernel I can imagine that

00:05:06,400 --> 00:05:12,520
for later for the newer version we

00:05:08,800 --> 00:05:16,390
shouldn't need to do anything and also

00:05:12,520 --> 00:05:18,610
most importantly in this model we put

00:05:16,390 --> 00:05:20,550
all the feature in EBP F then it

00:05:18,610 --> 00:05:23,500
encourages people to do more

00:05:20,550 --> 00:05:26,110
experimental stuff or do to try

00:05:23,500 --> 00:05:29,200
something crazy because they only need

00:05:26,110 --> 00:05:32,410
to write a PP eko and this code will be

00:05:29,200 --> 00:05:35,440
push from the obvious user space to the

00:05:32,410 --> 00:05:39,370
kernel so without a company to going

00:05:35,440 --> 00:05:41,500
through the mailing list so discuss with

00:05:39,370 --> 00:05:45,940
others they can try things try new

00:05:41,500 --> 00:05:49,450
things by their by themselves so if you

00:05:45,940 --> 00:05:52,240
have I guess everyone relief million

00:05:49,450 --> 00:05:55,990
Colonel Burton virtual machine it allows

00:05:52,240 --> 00:05:58,960
users to run a C program and then attach

00:05:55,990 --> 00:06:00,910
to a book point and then your program

00:05:58,960 --> 00:06:04,180
will be triggered to wrong when this

00:06:00,910 --> 00:06:07,630
event happened it's guaranteed to be

00:06:04,180 --> 00:06:09,400
safe because by the PPF verifier so it

00:06:07,630 --> 00:06:12,400
won't crush the kernel and it's

00:06:09,400 --> 00:06:14,650
guaranteed to be terminated

00:06:12,400 --> 00:06:17,350
it has map which allows you to

00:06:14,650 --> 00:06:20,860
communicate with different epp a program

00:06:17,350 --> 00:06:24,310
and also the user space program and it

00:06:20,860 --> 00:06:29,080
has helper function to help you push or

00:06:24,310 --> 00:06:32,290
retrieve data from the kernel so the

00:06:29,080 --> 00:06:37,120
obvious tvvf projects start by writing

00:06:32,290 --> 00:06:41,110
the star by looking at the kernel module

00:06:37,120 --> 00:06:42,729
the file under net open V switch so all

00:06:41,110 --> 00:06:45,520
the implementations there and

00:06:42,729 --> 00:06:51,279
see if we can implement the same feature

00:06:45,520 --> 00:06:53,949
in EVF Co so we start by picking TC who

00:06:51,279 --> 00:06:57,759
point and then we hook our Appa program

00:06:53,949 --> 00:07:00,610
there and then we start to implement the

00:06:57,759 --> 00:07:03,069
parts lookup and actions in this

00:07:00,610 --> 00:07:06,189
basically this is what we do in the

00:07:03,069 --> 00:07:13,059
kernel module and then for communication

00:07:06,189 --> 00:07:15,009
with user space we we use EPF Maps so of

00:07:13,059 --> 00:07:15,819
course the first stage is to do header

00:07:15,009 --> 00:07:17,740
parsing

00:07:15,819 --> 00:07:20,169
so we're not going to we are not passing

00:07:17,740 --> 00:07:23,499
all the protocol so we only pass the

00:07:20,169 --> 00:07:26,529
whatever protocols is implementing the

00:07:23,499 --> 00:07:30,580
kernel module today and we define a very

00:07:26,529 --> 00:07:33,309
similar floki structure extra SW floki

00:07:30,580 --> 00:07:36,909
this is what open V switch can module

00:07:33,309 --> 00:07:40,120
use and we pass followed data and we

00:07:36,909 --> 00:07:43,270
press measure data and then we Indian

00:07:40,120 --> 00:07:47,560
place this floki in the procedure you a

00:07:43,270 --> 00:07:49,389
PDF map so in this stage there are some

00:07:47,560 --> 00:07:53,919
difficulties for example stack is

00:07:49,389 --> 00:07:58,930
heavily used for example the software

00:07:53,919 --> 00:08:02,020
soft flow key is 4464 byte and it's

00:07:58,930 --> 00:08:04,680
getting close to the maximum and also

00:08:02,020 --> 00:08:07,919
this program is pretty crunchy so

00:08:04,680 --> 00:08:10,449
basically after the parsing we have to

00:08:07,919 --> 00:08:12,999
create another ppl program because

00:08:10,449 --> 00:08:19,389
everything we do next probably increase

00:08:12,999 --> 00:08:21,909
the programs complexity a lot so after

00:08:19,389 --> 00:08:26,709
passing then second stage is called

00:08:21,909 --> 00:08:29,800
match in action as match so this is what

00:08:26,709 --> 00:08:32,319
we're doing Linux kernel module today so

00:08:29,800 --> 00:08:36,839
after passing the pepper we take this

00:08:32,319 --> 00:08:39,459
packet and we do a flow table lookup and

00:08:36,839 --> 00:08:43,599
first packet always meets because the

00:08:39,459 --> 00:08:46,120
table is empty so in that case in kernel

00:08:43,599 --> 00:08:48,670
module we create we take this pack here

00:08:46,120 --> 00:08:51,899
we create an ailing API and then we send

00:08:48,670 --> 00:08:54,939
to the user space and then obviously

00:08:51,899 --> 00:08:56,290
does all the complicated stuff look up

00:08:54,939 --> 00:08:59,220
multiple tables

00:08:56,290 --> 00:09:03,040
and then get the result and then it will

00:08:59,220 --> 00:09:06,930
again call flow installation which

00:09:03,040 --> 00:09:10,209
create another nailing socket and then

00:09:06,930 --> 00:09:13,839
write this a flow entry into the flow

00:09:10,209 --> 00:09:20,410
table so we want to implement this logic

00:09:13,839 --> 00:09:24,130
in EBP F so first we need a flow table

00:09:20,410 --> 00:09:28,149
in Colonel so we use a GP PF hash table

00:09:24,130 --> 00:09:30,490
and then after the passing stage we want

00:09:28,149 --> 00:09:33,100
to pass it in the packet to first pack

00:09:30,490 --> 00:09:36,519
and we'll miss the hash table lookup and

00:09:33,100 --> 00:09:39,069
then we want to pass it to user space so

00:09:36,519 --> 00:09:42,040
we use a perfect buffer the helper

00:09:39,069 --> 00:09:45,699
function which allows us to put packet

00:09:42,040 --> 00:09:47,920
and then to the user space and then in

00:09:45,699 --> 00:09:51,009
the user space which again converting

00:09:47,920 --> 00:09:54,339
this package into the nailing API so

00:09:51,009 --> 00:09:59,440
that the rest of the obvious user space

00:09:54,339 --> 00:10:02,769
call can be reused and then when obvious

00:09:59,440 --> 00:10:07,240
finished processing it will use the

00:10:02,769 --> 00:10:10,420
netting API to do floor installation in

00:10:07,240 --> 00:10:13,420
this case obvious put package into a tea

00:10:10,420 --> 00:10:16,389
or before men but how so it which means

00:10:13,420 --> 00:10:18,910
each time the lens might be different so

00:10:16,389 --> 00:10:22,420
because EVP F in the beginning we have

00:10:18,910 --> 00:10:24,670
to the size of the map need to be fixed

00:10:22,420 --> 00:10:27,699
at the loading time so we have to

00:10:24,670 --> 00:10:30,670
convert in this tier V nanning tier V

00:10:27,699 --> 00:10:32,519
into a fixed length array and then put

00:10:30,670 --> 00:10:35,920
into the EBP of meth

00:10:32,519 --> 00:10:38,680
so after this installation the second

00:10:35,920 --> 00:10:42,389
packet or the subsequent packet can hit

00:10:38,680 --> 00:10:45,760
the flow in this EBP of hash map and

00:10:42,389 --> 00:10:49,449
converting the nailing tier being to fix

00:10:45,760 --> 00:10:55,529
a fixed length of a world wasting space

00:10:49,449 --> 00:11:00,220
and that's the cost we pay so after we

00:10:55,529 --> 00:11:04,329
find after lookup stage then it's a net

00:11:00,220 --> 00:11:08,319
next stage is the action so for example

00:11:04,329 --> 00:11:09,970
this is how kernel module does today if

00:11:08,319 --> 00:11:13,389
we were if we wanted to

00:11:09,970 --> 00:11:16,360
flooding then obvious we'll say okay

00:11:13,389 --> 00:11:19,180
actions equals to Abu Dis output is

00:11:16,360 --> 00:11:22,839
pakka tuned for 9 / 5 or 10 basically

00:11:19,180 --> 00:11:26,560
all your port or if you want to do a

00:11:22,839 --> 00:11:29,620
mirror and push me then then your lookup

00:11:26,560 --> 00:11:33,339
resolved the action will be output to 3

00:11:29,620 --> 00:11:36,519
which is your original port and then you

00:11:33,339 --> 00:11:40,360
push a VLAN tag then output to the port

00:11:36,519 --> 00:11:42,279
number 2 which is a port that's ended

00:11:40,360 --> 00:11:45,910
you want to mirror you want to send a

00:11:42,279 --> 00:11:54,310
mirror packet to so ok we want to

00:11:45,910 --> 00:11:56,529
implement this in EB PF so ideally in

00:11:54,310 --> 00:11:58,870
this case we have a interaction

00:11:56,529 --> 00:12:01,779
execution we have a packet as an input

00:11:58,870 --> 00:12:04,259
and then we have a for loop and we run

00:12:01,779 --> 00:12:07,240
this follow through to implement to

00:12:04,259 --> 00:12:09,610
implement or action from action 1 to the

00:12:07,240 --> 00:12:13,449
end of action however there are some

00:12:09,610 --> 00:12:16,779
challenges for example today we don't

00:12:13,449 --> 00:12:20,759
support an emic for loop so that we have

00:12:16,779 --> 00:12:24,730
to break this for loop using tail call

00:12:20,759 --> 00:12:28,149
so even so first first time I try I just

00:12:24,730 --> 00:12:28,860
use a maximum of static upper bum of the

00:12:28,149 --> 00:12:33,639
for loop

00:12:28,860 --> 00:12:37,089
like I always ask you 3-2 or 64 but then

00:12:33,639 --> 00:12:40,480
we hit another limitation that EBP a

00:12:37,089 --> 00:12:44,110
program has maximum size of 4 K so for

00:12:40,480 --> 00:12:46,569
example if you are and if you have an

00:12:44,110 --> 00:12:48,610
action list that has many element like

00:12:46,569 --> 00:12:51,819
many actions to do then you might hit

00:12:48,610 --> 00:12:56,740
the limitation so we end up breaking

00:12:51,819 --> 00:12:59,620
each action into an independent Appa

00:12:56,740 --> 00:13:02,290
program and then at the end of the EPP a

00:12:59,620 --> 00:13:04,750
program we have to map look up to see

00:13:02,290 --> 00:13:09,329
what's the next next action to execute

00:13:04,750 --> 00:13:13,329
and then exclude another actions

00:13:09,329 --> 00:13:15,129
so with that implementation we can get

00:13:13,329 --> 00:13:18,370
something working so we set up two

00:13:15,129 --> 00:13:21,790
machines using tankini car connected

00:13:18,370 --> 00:13:24,010
them back-to-back the machine on the

00:13:21,790 --> 00:13:27,529
left is a traffic generator

00:13:24,010 --> 00:13:29,930
14 million packet per second 64 PI you

00:13:27,529 --> 00:13:32,630
need to pee packet on the right hand

00:13:29,930 --> 00:13:36,160
side would run obvious kernel module and

00:13:32,630 --> 00:13:41,500
compared with obvious EPF implementation

00:13:36,160 --> 00:13:41,500
we measure using single flow single corn

00:13:43,120 --> 00:13:50,060
so the blue table shows the kernel

00:13:47,450 --> 00:13:52,790
module obvious kernel module today so

00:13:50,060 --> 00:13:55,130
output means that actually cost up to

00:13:52,790 --> 00:13:58,279
output so it means that you take the

00:13:55,130 --> 00:14:01,390
package from one port and then you do

00:13:58,279 --> 00:14:03,830
parse lookup and actions equal to

00:14:01,390 --> 00:14:05,480
another port so basically we are taking

00:14:03,830 --> 00:14:07,490
packet from one port do some processing

00:14:05,480 --> 00:14:11,180
and send it to another port

00:14:07,490 --> 00:14:13,220
so it shows 1.3 million if you do

00:14:11,180 --> 00:14:16,760
something extra for example receive a

00:14:13,220 --> 00:14:20,240
packet and then modify the destination

00:14:16,760 --> 00:14:23,480
MAC address then output so it drops a

00:14:20,240 --> 00:14:26,510
little bit and then if you do a tunnel

00:14:23,480 --> 00:14:28,880
for example you set hanno pick something

00:14:26,510 --> 00:14:31,700
and then you push GI tahno and then you

00:14:28,880 --> 00:14:34,610
are go to another port then because it

00:14:31,700 --> 00:14:37,510
traverses the linux deck another time so

00:14:34,610 --> 00:14:40,370
it dropped to 0.5

00:14:37,510 --> 00:14:44,570
so compared with the EP PFD high pass

00:14:40,370 --> 00:14:47,690
action first we did something called

00:14:44,570 --> 00:14:49,790
redirect so Rita ray is at the TC layer

00:14:47,690 --> 00:14:52,190
we don't do anything so it's just no

00:14:49,790 --> 00:14:55,220
parser take the packet and from one pole

00:14:52,190 --> 00:14:58,870
and just forwarded to another port so it

00:14:55,220 --> 00:15:01,910
just it shows 1.9 million and then the

00:14:58,870 --> 00:15:05,150
second one output is with our obvious

00:15:01,910 --> 00:15:08,750
EPF implementation having parser lookup

00:15:05,150 --> 00:15:12,140
in actions it's just one point two I was

00:15:08,750 --> 00:15:15,080
31 point 1 and then we set the session

00:15:12,140 --> 00:15:19,339
mech output and Gia eternal output it's

00:15:15,080 --> 00:15:22,870
just 1 point 1 and 0 point 4 so we see

00:15:19,339 --> 00:15:26,180
around 10 to 20% performance overhead

00:15:22,870 --> 00:15:29,660
it's not because of the EPF but because

00:15:26,180 --> 00:15:31,400
of the limitation of the EBP so that we

00:15:29,660 --> 00:15:33,890
have to change some design for example

00:15:31,400 --> 00:15:36,000
we have to break the action into

00:15:33,890 --> 00:15:39,060
multiple telco and then

00:15:36,000 --> 00:15:44,690
two extra look up so I guess that's the

00:15:39,060 --> 00:15:48,090
reason it shows a little bit slow so

00:15:44,690 --> 00:15:50,340
right now we are working on a couple

00:15:48,090 --> 00:15:54,540
features for example mega flow support

00:15:50,340 --> 00:15:56,100
and basic combination tracking for more

00:15:54,540 --> 00:15:58,950
difficult one like packet if

00:15:56,100 --> 00:16:00,930
fragmentation and energy we still don't

00:15:58,950 --> 00:16:04,800
know how to do so this is the under

00:16:00,930 --> 00:16:08,880
discussion so the lesson learned from

00:16:04,800 --> 00:16:12,030
this project is that taking the existing

00:16:08,880 --> 00:16:14,910
features like kernel module code obvious

00:16:12,030 --> 00:16:18,120
kernel module code and converted into EP

00:16:14,910 --> 00:16:21,060
PF is a little bit hard although they

00:16:18,120 --> 00:16:23,580
are post C code and and then you cannot

00:16:21,060 --> 00:16:25,890
click copy this 10 line of code 20 lines

00:16:23,580 --> 00:16:29,250
of code from your kernel module and then

00:16:25,890 --> 00:16:30,870
to EBV echo I guess is because 4 is more

00:16:29,250 --> 00:16:33,060
for loop have to

00:16:30,870 --> 00:16:35,370
there's no for loops at all so we have

00:16:33,060 --> 00:16:39,420
to break our program or this limit is

00:16:35,370 --> 00:16:41,580
deck size or there is no dynamic memory

00:16:39,420 --> 00:16:46,140
location there so we have to do a lot of

00:16:41,580 --> 00:16:49,530
conversion so its ends up that when you

00:16:46,140 --> 00:16:51,140
want someone to do this work they should

00:16:49,530 --> 00:16:53,850
actually they have to change their

00:16:51,140 --> 00:16:56,700
myself a lot like it's not although it's

00:16:53,850 --> 00:17:01,290
all psycho but it's totally this totally

00:16:56,700 --> 00:17:04,790
different so then we start to think

00:17:01,290 --> 00:17:09,300
about this AF xdp work

00:17:04,790 --> 00:17:14,640
so if pushing all that obviously F has

00:17:09,300 --> 00:17:17,730
feature in to EBP of code is difficult

00:17:14,640 --> 00:17:20,310
then maybe we can try retrieve the

00:17:17,730 --> 00:17:22,620
package from the kernel as fast as

00:17:20,310 --> 00:17:25,380
possible and then do the rest of

00:17:22,620 --> 00:17:27,780
processing the first local tunnel

00:17:25,380 --> 00:17:33,510
implementation whatever in the user

00:17:27,780 --> 00:17:36,270
space so it has two concerns here so

00:17:33,510 --> 00:17:39,390
first once we take the packet to the

00:17:36,270 --> 00:17:42,780
user space then we lose all the chance

00:17:39,390 --> 00:17:45,060
of using the kernels code for example

00:17:42,780 --> 00:17:47,800
today obvious kernel module use a lot of

00:17:45,060 --> 00:17:52,960
tunnel implementation we excellent

00:17:47,800 --> 00:17:57,190
genÃ¨ve ger spam all right we use QoS the

00:17:52,960 --> 00:18:00,910
TC curious and we also use the data

00:17:57,190 --> 00:18:02,440
structure there we use net filter

00:18:00,910 --> 00:18:05,110
combination tracking feature in our

00:18:02,440 --> 00:18:07,660
kernel module so bring packet to user

00:18:05,110 --> 00:18:10,720
space means that we have to do

00:18:07,660 --> 00:18:13,360
everything there in use of the space and

00:18:10,720 --> 00:18:17,080
second is the performance so usually

00:18:13,360 --> 00:18:20,170
taking packet to user spaces has extra

00:18:17,080 --> 00:18:25,120
overhead like context switch and packet

00:18:20,170 --> 00:18:29,470
copy so luckily for the first problem we

00:18:25,120 --> 00:18:32,110
have this another user space they have

00:18:29,470 --> 00:18:35,710
has implementation called DPF

00:18:32,110 --> 00:18:38,920
native so today it's similar in

00:18:35,710 --> 00:18:42,340
contention then to our kernel module by

00:18:38,920 --> 00:18:44,440
mainly used by the DPD community so in

00:18:42,340 --> 00:18:46,780
the DVD can work they take the packet

00:18:44,440 --> 00:18:50,200
from the hardware and then send it to

00:18:46,780 --> 00:18:53,670
the user space of yes to the this user

00:18:50,200 --> 00:18:58,270
space data path and then it has another

00:18:53,670 --> 00:19:02,710
implementation of of the obvious there

00:18:58,270 --> 00:19:05,410
are paths so the second problem about

00:19:02,710 --> 00:19:10,810
performance so luckily we have this x TP

00:19:05,410 --> 00:19:15,160
and a FX DP so x DB means express that

00:19:10,810 --> 00:19:17,890
hop has it's a PPP a book point that can

00:19:15,160 --> 00:19:22,780
SS pack it as a very low level at a

00:19:17,890 --> 00:19:25,540
device driver level and with a FX TP is

00:19:22,780 --> 00:19:27,580
allow us to create a socket type that

00:19:25,540 --> 00:19:33,850
receive and send packet friend from at a

00:19:27,580 --> 00:19:36,250
very high speed so that so that the only

00:19:33,850 --> 00:19:37,780
thing we need to do the holistic thing

00:19:36,250 --> 00:19:40,930
different from the socket is that we

00:19:37,780 --> 00:19:44,110
have to do this extra programming of

00:19:40,930 --> 00:19:49,710
maintenance of these arcs ring the X

00:19:44,110 --> 00:19:53,410
ring and completion ring and theory so

00:19:49,710 --> 00:19:56,980
the this project obvious mfdp is about

00:19:53,410 --> 00:19:57,830
taking the packet from the driver XDP

00:19:56,980 --> 00:20:01,249
layer and

00:19:57,830 --> 00:20:03,679
creating a FX DP sake as a user space

00:20:01,249 --> 00:20:10,159
and then reusing that they have has

00:20:03,679 --> 00:20:13,730
today used by the DP TK community then

00:20:10,159 --> 00:20:17,090
what what obvious should do in this case

00:20:13,730 --> 00:20:19,879
is that so FX DP introduced something

00:20:17,090 --> 00:20:22,999
called you men so human is a user space

00:20:19,879 --> 00:20:24,950
memory allocated by the user space

00:20:22,999 --> 00:20:28,999
program in this case is obviously

00:20:24,950 --> 00:20:32,090
sweetie demon and then you Manuel so you

00:20:28,999 --> 00:20:36,619
means a chunk of memory in our case we

00:20:32,090 --> 00:20:39,379
allocate 2 KP chunk and then we'll have

00:20:36,619 --> 00:20:41,869
to map this human to the Linux kernel so

00:20:39,379 --> 00:20:44,720
that it becomes a shimmery between the

00:20:41,869 --> 00:20:47,899
user space program and kernel it has

00:20:44,720 --> 00:20:50,989
feeling and completion ring so fearing

00:20:47,899 --> 00:20:55,009
allows kernel to receive packet and then

00:20:50,989 --> 00:20:58,100
put it into one of the human airman your

00:20:55,009 --> 00:21:01,609
packet data their completion ring is a

00:20:58,100 --> 00:21:05,830
way to from kernel to letter obvious

00:21:01,609 --> 00:21:10,639
know that you already send your packet

00:21:05,830 --> 00:21:13,369
and then for the arcs ring is for users

00:21:10,639 --> 00:21:16,309
to receive packet that received by the

00:21:13,369 --> 00:21:20,419
Linux kernel and for TX ring is

00:21:16,309 --> 00:21:23,029
something obvious for obvious to put the

00:21:20,419 --> 00:21:27,619
package into TX ring and then ask the

00:21:23,029 --> 00:21:29,419
Linux kernel FX DP to send it out and

00:21:27,619 --> 00:21:32,570
also it wasn't to mention that the

00:21:29,419 --> 00:21:35,119
component in this ring is a descriptor

00:21:32,570 --> 00:21:37,070
so pointing to the one of the human

00:21:35,119 --> 00:21:39,710
element so there is no data copying

00:21:37,070 --> 00:21:43,850
between them so it's just a dress for

00:21:39,710 --> 00:21:46,580
address point to the location data in

00:21:43,850 --> 00:21:48,830
human and your your your pack is always

00:21:46,580 --> 00:21:53,539
there when you are doing transmission

00:21:48,830 --> 00:21:55,850
receiving user space and kernel so to

00:21:53,539 --> 00:21:59,869
receive a package we need to program act

00:21:55,850 --> 00:22:02,389
ring and theory and to transmit packet

00:21:59,869 --> 00:22:05,389
we have to program he x-ray and

00:22:02,389 --> 00:22:07,730
completion rate so I'm going to go

00:22:05,389 --> 00:22:11,630
through an example how obvious to

00:22:07,730 --> 00:22:14,030
reception for sympathy

00:22:11,630 --> 00:22:16,850
four simple case if we only have eight

00:22:14,030 --> 00:22:19,850
human airman in the beginning and then

00:22:16,850 --> 00:22:21,920
we have fill ring and artery and we also

00:22:19,850 --> 00:22:25,490
need an extra data structure called

00:22:21,920 --> 00:22:28,190
human man pool which kept track of which

00:22:25,490 --> 00:22:32,900
is a free list keep track of available

00:22:28,190 --> 00:22:35,690
human element so in the beginning we

00:22:32,900 --> 00:22:38,480
obvious will get four available human

00:22:35,690 --> 00:22:45,730
airman and put it into the field ring so

00:22:38,480 --> 00:22:48,230
that and mark then in use so once we put

00:22:45,730 --> 00:22:50,810
distributor in the field ring kono can

00:22:48,230 --> 00:22:53,540
receive this for packet and once the

00:22:50,810 --> 00:22:55,880
receive is done Colonel will transfer

00:22:53,540 --> 00:23:00,320
the ownership from the field ring so

00:22:55,880 --> 00:23:04,490
from this one two three four into the

00:23:00,320 --> 00:23:06,860
artery and we at this time we want

00:23:04,490 --> 00:23:11,150
Colonel to be able to keep receiving

00:23:06,860 --> 00:23:14,390
package so we have to get another four

00:23:11,150 --> 00:23:16,960
packet for you available humane airman

00:23:14,390 --> 00:23:20,480
and put it into a fuel ring so that

00:23:16,960 --> 00:23:23,570
Colonel can keep receiving and put it

00:23:20,480 --> 00:23:26,960
into the field ring after this stage

00:23:23,570 --> 00:23:30,680
obvious start to process the package on

00:23:26,960 --> 00:23:32,690
the rx ring so this is then this is just

00:23:30,680 --> 00:23:36,980
tender obvious code which does past

00:23:32,690 --> 00:23:39,610
lookup and actions and not right now we

00:23:36,980 --> 00:23:43,370
don't have any available human element

00:23:39,610 --> 00:23:46,280
so once obvious finish finish processing

00:23:43,370 --> 00:23:49,100
this for a package then we can recycle

00:23:46,280 --> 00:23:53,930
this for T three or four you may never

00:23:49,100 --> 00:23:59,390
back to the human poor so that next

00:23:53,930 --> 00:24:02,270
package or can can use that there's a

00:23:59,390 --> 00:24:05,720
similar logic for the same things I put

00:24:02,270 --> 00:24:08,330
in the papers so we can take a look so

00:24:05,720 --> 00:24:11,260
our initial implementation the

00:24:08,330 --> 00:24:16,190
performance is not so good so I have to

00:24:11,260 --> 00:24:21,290
apply this optimization so first one is

00:24:16,190 --> 00:24:24,440
called poor more driver mode so without

00:24:21,290 --> 00:24:25,370
homo driver obvious obvious use poor

00:24:24,440 --> 00:24:27,410
system :

00:24:25,370 --> 00:24:29,450
than well for new i/o this turned out to

00:24:27,410 --> 00:24:32,180
be pretty slow because every time I go

00:24:29,450 --> 00:24:35,870
to the Linux kernel and contest which

00:24:32,180 --> 00:24:38,420
Bay it takes couple of microseconds so I

00:24:35,870 --> 00:24:43,550
have to use this dedicated thread to

00:24:38,420 --> 00:24:46,370
keep pouring the rx-3 also we mentioned

00:24:43,550 --> 00:24:48,110
this a human memory poor design every

00:24:46,370 --> 00:24:51,710
time we want to get some free element

00:24:48,110 --> 00:24:53,809
from the human list and sometimes we

00:24:51,710 --> 00:24:57,530
want to put it back recycled back when

00:24:53,809 --> 00:25:00,890
we finish so we're on the fasted heart

00:24:57,530 --> 00:25:02,740
structure to do this after operation and

00:25:00,890 --> 00:25:05,240
there are some standard things like

00:25:02,740 --> 00:25:07,580
create locations so we don't want to err

00:25:05,240 --> 00:25:10,550
ok any men had a camp when we receive

00:25:07,580 --> 00:25:12,890
packet we want to me ok L okay in the

00:25:10,550 --> 00:25:15,650
beginning and preset up pretty

00:25:12,890 --> 00:25:21,410
initialize some songs they are structure

00:25:15,650 --> 00:25:23,960
and also some system Co patching so

00:25:21,410 --> 00:25:26,480
about the human design so actually it

00:25:23,960 --> 00:25:30,440
has only two operations of first run

00:25:26,480 --> 00:25:33,230
first is get so it says get for for

00:25:30,440 --> 00:25:36,290
example for free you maintenance from

00:25:33,230 --> 00:25:40,220
the human poor or after obvious

00:25:36,290 --> 00:25:44,809
processes we say put for admin back to

00:25:40,220 --> 00:25:48,290
the list so that's it then I increment

00:25:44,809 --> 00:25:51,590
three they have structure first one

00:25:48,290 --> 00:25:54,890
slide o list head so second one is five

00:25:51,590 --> 00:25:58,280
four point three the last one is life

00:25:54,890 --> 00:26:00,200
4.0 right so it turned out the last one

00:25:58,280 --> 00:26:05,200
shows the better performance

00:26:00,200 --> 00:26:07,850
so LIFO is basically a push pop style so

00:26:05,200 --> 00:26:11,360
because I guess because we have a ring

00:26:07,850 --> 00:26:15,340
and every time if we do push pop on the

00:26:11,360 --> 00:26:20,780
top of the stack then we kind of always

00:26:15,340 --> 00:26:23,660
reusing the first for example first 200

00:26:20,780 --> 00:26:27,170
human instead of if we have a ring with

00:26:23,660 --> 00:26:30,980
tail and head and tail we'll end up

00:26:27,170 --> 00:26:34,130
using all the your human element in the

00:26:30,980 --> 00:26:37,520
in the memory so I guess this is more

00:26:34,130 --> 00:26:41,220
cash friendly and

00:26:37,520 --> 00:26:44,940
so maybe this smoke this is no clear so

00:26:41,220 --> 00:26:47,130
point then we allocate all the pointer

00:26:44,940 --> 00:26:49,890
in this pointer array so this pointer

00:26:47,130 --> 00:26:53,960
array were pointing to the unused

00:26:49,890 --> 00:26:59,280
element in the human so putting all the

00:26:53,960 --> 00:27:01,530
all the addressing an array is also more

00:26:59,280 --> 00:27:06,059
cash friendly because that you can do

00:27:01,530 --> 00:27:11,970
patching I take 32 or take 16 pointer in

00:27:06,059 --> 00:27:15,510
one operation then once we receive

00:27:11,970 --> 00:27:18,720
packet from a FX DP we need to allocate

00:27:15,510 --> 00:27:21,690
the metadata so in the case of obvious

00:27:18,720 --> 00:27:24,960
is called TPI packet again we have to

00:27:21,690 --> 00:27:28,320
design one is to use single chunk of

00:27:24,960 --> 00:27:30,750
memory for post data in metadata so this

00:27:28,320 --> 00:27:34,470
is similar to DVD case and buff T design

00:27:30,750 --> 00:27:37,289
basically you reserve probably 500 bytes

00:27:34,470 --> 00:27:39,690
in front of your packet data and then

00:27:37,289 --> 00:27:42,960
every time you SS you can just do an

00:27:39,690 --> 00:27:46,159
offset or the second design is you have

00:27:42,960 --> 00:27:49,890
a separate dedicated buffer for all your

00:27:46,159 --> 00:27:52,830
or your metadata and then we found out

00:27:49,890 --> 00:27:56,039
the second one this one is shows better

00:27:52,830 --> 00:27:58,490
performance so in this design we'd

00:27:56,039 --> 00:28:03,600
actually either be anyway we are okay

00:27:58,490 --> 00:28:06,600
the same amount of metadata as the

00:28:03,600 --> 00:28:09,840
number of human chunk and then to

00:28:06,600 --> 00:28:11,789
one-to-one mapping and then one packet

00:28:09,840 --> 00:28:14,070
comes we can do patching more easily

00:28:11,789 --> 00:28:18,000
because we can say process batch of

00:28:14,070 --> 00:28:20,940
packet by assessing this memory and also

00:28:18,000 --> 00:28:27,480
the packet data memory so I guess this

00:28:20,940 --> 00:28:29,970
reduces the cache miss a lot so again we

00:28:27,480 --> 00:28:33,720
measure this performance this time we

00:28:29,970 --> 00:28:37,530
upgrade our hardware by using 40 kidney

00:28:33,720 --> 00:28:41,809
car thanks for name Eleanor Skype so

00:28:37,530 --> 00:28:44,460
right now we use a for ticket on FB 4000

00:28:41,809 --> 00:28:47,400
running the PDK to send

00:28:44,460 --> 00:28:50,340
19 million packet per second to the

00:28:47,400 --> 00:28:54,510
server on the right which we use Intel

00:28:50,340 --> 00:28:58,170
exhales 710 and then we run obvious with

00:28:54,510 --> 00:29:02,040
AF XDP there so again this is also

00:28:58,170 --> 00:29:08,100
single flow single corn 64 PI packet

00:29:02,040 --> 00:29:10,850
with a FX DP 0 copy more and I disabled

00:29:08,100 --> 00:29:15,600
I disabled the spectrum and Milltown

00:29:10,850 --> 00:29:20,190
patch so we compare the performance with

00:29:15,600 --> 00:29:22,560
the XTP style micro benchmark program in

00:29:20,190 --> 00:29:27,480
the kernel source so there are two

00:29:22,560 --> 00:29:30,030
applications one is called extra so in

00:29:27,480 --> 00:29:32,580
the obvious extra does parts lookup and

00:29:30,030 --> 00:29:36,060
actually includes to drop in the case of

00:29:32,580 --> 00:29:38,790
XTP sock it doesn't touch packet for the

00:29:36,060 --> 00:29:41,700
a or to forward obvious does pass lookup

00:29:38,790 --> 00:29:44,460
and action equals to change the Mac

00:29:41,700 --> 00:29:48,840
edges and then output to the same port a

00:29:44,460 --> 00:29:52,440
seed receive so we compare the

00:29:48,840 --> 00:29:55,140
performance so for the receive side it's

00:29:52,440 --> 00:29:57,900
the same we can get 19 million packet

00:29:55,140 --> 00:30:01,760
per second for the i/o two for it's a

00:29:57,900 --> 00:30:04,500
little bit slow I think song of the same

00:30:01,760 --> 00:30:10,290
system Co has over here I have to

00:30:04,500 --> 00:30:13,470
optimize it so in terms of future work

00:30:10,290 --> 00:30:15,840
right now it's all forwarding packet

00:30:13,470 --> 00:30:17,880
from physical port to physical port so

00:30:15,840 --> 00:30:20,610
next time next thing I want to try is to

00:30:17,880 --> 00:30:23,610
try forwarding packet to virtual machine

00:30:20,610 --> 00:30:26,490
I will explain well be much slower

00:30:23,610 --> 00:30:28,830
because for example for virtual machine

00:30:26,490 --> 00:30:32,760
oil container we have to create tab

00:30:28,830 --> 00:30:35,280
device or this peer device and then from

00:30:32,760 --> 00:30:38,370
obvious to from right because right now

00:30:35,280 --> 00:30:42,180
peg is already in user space right so to

00:30:38,370 --> 00:30:45,180
send a packet to we sort have device we

00:30:42,180 --> 00:30:48,660
have to push that packet pay inside the

00:30:45,180 --> 00:30:53,460
kernel so I guess it's performance work

00:30:48,660 --> 00:30:57,630
job so either we can support a a flex TP

00:30:53,460 --> 00:31:02,910
for the vSphere or tap device or another

00:30:57,630 --> 00:31:03,990
option is to use a V host user user mode

00:31:02,910 --> 00:31:08,670
so the pack

00:31:03,990 --> 00:31:12,350
userspace can directly creative of the

00:31:08,670 --> 00:31:18,030
Verdi all form a packet and send it to

00:31:12,350 --> 00:31:21,780
the Verdi or wrong in either in virtual

00:31:18,030 --> 00:31:23,280
machine or in container also the second

00:31:21,780 --> 00:31:25,440
way is we want to bring the feature

00:31:23,280 --> 00:31:28,080
parity between the user space and kernel

00:31:25,440 --> 00:31:30,330
therapies so today our kernel module has

00:31:28,080 --> 00:31:33,150
more features than our user space called

00:31:30,330 --> 00:31:36,450
for for example current incarnation

00:31:33,150 --> 00:31:41,910
tracking they are still kono is still

00:31:36,450 --> 00:31:43,800
more complete than user space so in

00:31:41,910 --> 00:31:49,559
terms of discussion right now obvious is

00:31:43,800 --> 00:31:51,929
always using 100% CPU actually to CP or

00:31:49,559 --> 00:31:54,780
shoham group is same one is the case of

00:31:51,929 --> 00:31:57,990
a irq demon and the other is a poor

00:31:54,780 --> 00:32:00,330
driver of the obvious created by obvious

00:31:57,990 --> 00:32:02,840
so we're asking about how to balance

00:32:00,330 --> 00:32:06,600
this PMD when the traffic is not so

00:32:02,840 --> 00:32:09,990
traffic race not so high and also we

00:32:06,600 --> 00:32:12,120
want to compare with DP DK not because

00:32:09,990 --> 00:32:15,210
of the now in terms of performance but

00:32:12,120 --> 00:32:22,559
in terms of the deployment difficulty or

00:32:15,210 --> 00:32:26,700
how to ease of the management so finally

00:32:22,559 --> 00:32:30,050
in comparison of this three so first one

00:32:26,700 --> 00:32:34,080
I think in terms of maintenance cost

00:32:30,050 --> 00:32:36,300
obvious EPF I see it's low if we have

00:32:34,080 --> 00:32:39,300
everything there because if we have

00:32:36,300 --> 00:32:40,980
everything EVP F then we basically can

00:32:39,300 --> 00:32:44,790
do whatever we want and push all the

00:32:40,980 --> 00:32:47,580
feature from the user space for the AF x

00:32:44,790 --> 00:32:49,679
TP is also low but it's because right

00:32:47,580 --> 00:32:52,110
now we increment everything user space

00:32:49,679 --> 00:32:54,480
and then we changed everything in there

00:32:52,110 --> 00:32:57,840
chrono module is high because the ABI

00:32:54,480 --> 00:33:01,530
change end and some other and some song

00:32:57,840 --> 00:33:06,390
on the stage for performance areas o AF

00:33:01,530 --> 00:33:11,010
x GP is high because of this fast FX DP

00:33:06,390 --> 00:33:14,400
to the user space in terms of developer

00:33:11,010 --> 00:33:16,440
burn effort obviously PPF is still or

00:33:14,400 --> 00:33:17,430
you'll be difficult if I want someone

00:33:16,440 --> 00:33:20,090
song Experion

00:33:17,430 --> 00:33:23,900
see program to implement a feature in

00:33:20,090 --> 00:33:28,080
IPPF then it still takes some time

00:33:23,900 --> 00:33:31,140
FX DP is easier because it's the user

00:33:28,080 --> 00:33:35,190
space easier to debug easier to call

00:33:31,140 --> 00:33:37,440
into other library in terms of new

00:33:35,190 --> 00:33:39,920
feature deployment I would say

00:33:37,440 --> 00:33:43,320
immediately is easier to deploy because

00:33:39,920 --> 00:33:47,490
right now customer today runs were many

00:33:43,320 --> 00:33:50,790
different a kernel version and then if

00:33:47,490 --> 00:33:52,950
we can have this in EBP F then once we

00:33:50,790 --> 00:33:58,200
know the version support then we can t

00:33:52,950 --> 00:34:01,020
provide it and so so does a FX DP but in

00:33:58,200 --> 00:34:02,910
terms of safety I think obvious EPP F is

00:34:01,020 --> 00:34:05,910
much higher because the verified

00:34:02,910 --> 00:34:07,620
guarantee and the code is safe then in

00:34:05,910 --> 00:34:12,030
terms of another two is actually

00:34:07,620 --> 00:34:21,360
depending on the reviewer okay let's

00:34:12,030 --> 00:34:25,080
thank you so I want to address like a

00:34:21,360 --> 00:34:27,200
couple points so since you're going

00:34:25,080 --> 00:34:30,230
through the classifier to do the EBP F

00:34:27,200 --> 00:34:33,260
implementation of the OBS data path

00:34:30,230 --> 00:34:37,290
you're not getting the benefits of xdp

00:34:33,260 --> 00:34:39,360
wherein we had to make an S KB we had to

00:34:37,290 --> 00:34:41,340
traverse into the packet scheduler layer

00:34:39,360 --> 00:34:44,130
and then get to your EVP F program so do

00:34:41,340 --> 00:34:45,720
some fixed overhead there so if you went

00:34:44,130 --> 00:34:48,330
to an x DP based solution you could

00:34:45,720 --> 00:34:50,280
eliminate some of that overhead another

00:34:48,330 --> 00:34:52,140
thing to take in consideration is you

00:34:50,280 --> 00:34:55,590
talked about virtualization and pushing

00:34:52,140 --> 00:34:57,720
in and out of guests and with the AF x

00:34:55,590 --> 00:34:59,760
DP situation you have the same problem

00:34:57,720 --> 00:35:01,320
DP TK has where that you have to cross

00:34:59,760 --> 00:35:02,700
the protection boundary again to push

00:35:01,320 --> 00:35:05,220
the packet back incident virtualization

00:35:02,700 --> 00:35:08,250
layer yes if you are able to get feature

00:35:05,220 --> 00:35:12,330
parity with the BPF solution with x DP

00:35:08,250 --> 00:35:13,620
as you get with a FX DP you would be in

00:35:12,330 --> 00:35:15,120
the kernel already and you wouldn't have

00:35:13,620 --> 00:35:17,310
to cross this protection boundary again

00:35:15,120 --> 00:35:19,320
so there is a huge incentive to somehow

00:35:17,310 --> 00:35:21,540
make the BPF implementation performance

00:35:19,320 --> 00:35:23,280
mm-hmm so I just I think those are all

00:35:21,540 --> 00:35:25,140
the things you need to consider as you

00:35:23,280 --> 00:35:27,870
move forward and decide how to attack

00:35:25,140 --> 00:35:30,740
different approaches any questions

00:35:27,870 --> 00:35:30,740
for William

00:35:35,140 --> 00:35:39,790
one of the pain points you should

00:35:37,599 --> 00:35:43,330
consider OVS with TC offloading is that

00:35:39,790 --> 00:35:47,080
the flow rate can be quite low have you

00:35:43,330 --> 00:35:48,359
considered this one when doing this

00:35:47,080 --> 00:35:52,119
project

00:35:48,359 --> 00:35:55,000
sorry your question is a TC what is very

00:35:52,119 --> 00:35:59,410
low TC of low yeah this you're floating

00:35:55,000 --> 00:36:02,260
can be quite low price lower yeah and if

00:35:59,410 --> 00:36:04,599
you try to insert like 1,000 flows in

00:36:02,260 --> 00:36:07,450
the data path they can get even slower

00:36:04,599 --> 00:36:10,510
and slower as the amount piles up and

00:36:07,450 --> 00:36:13,510
have you considered how fast or how slow

00:36:10,510 --> 00:36:18,790
it can be to add a new flow in the data

00:36:13,510 --> 00:36:21,640
path while using a BBF right now the we

00:36:18,790 --> 00:36:23,500
implement flow in a PDF map so every

00:36:21,640 --> 00:36:27,880
time we install flow is basically

00:36:23,500 --> 00:36:31,270
updating the a PDF map so we're now

00:36:27,880 --> 00:36:33,220
using TC of low today so another way to

00:36:31,270 --> 00:36:34,960
think about this and so OBS has a

00:36:33,220 --> 00:36:38,410
back-end for the data plane which is

00:36:34,960 --> 00:36:40,570
make TC flower rule and offload that on

00:36:38,410 --> 00:36:43,119
to the hardware okay what if you

00:36:40,570 --> 00:36:45,580
generated your BPF program in the flour

00:36:43,119 --> 00:36:47,770
classifier taking all these goals into

00:36:45,580 --> 00:36:50,530
consideration oh okay so you're saying

00:36:47,770 --> 00:36:54,010
so that's another idea we people talk

00:36:50,530 --> 00:36:57,010
about so if we had a BPF program

00:36:54,010 --> 00:36:59,320
generated from the TC flower rules you

00:36:57,010 --> 00:37:03,520
know you can yes okay okay that's a

00:36:59,320 --> 00:37:07,810
third approach there's many different

00:37:03,520 --> 00:37:09,700
avenues to attack and again the EBP F

00:37:07,810 --> 00:37:11,410
based solution would be superior for the

00:37:09,700 --> 00:37:13,720
virtualization case as we discussed

00:37:11,410 --> 00:37:16,030
earlier since it's very lot of things to

00:37:13,720 --> 00:37:21,070
think about okay there's another hand

00:37:16,030 --> 00:37:23,430
that was up over here yeah do you have

00:37:21,070 --> 00:37:28,859
numbers comparing the performance of

00:37:23,430 --> 00:37:32,500
obvious AF x DP to obvious DP decay I

00:37:28,859 --> 00:37:34,810
don't but obviously people do the

00:37:32,500 --> 00:37:38,050
performance comparison of obviously PDK

00:37:34,810 --> 00:37:39,670
a lot so right now I think our

00:37:38,050 --> 00:37:41,760
implementation is slower than all this

00:37:39,670 --> 00:37:43,560
obviously PDK because

00:37:41,760 --> 00:37:47,400
I think they asked us armed my vision I

00:37:43,560 --> 00:37:51,510
have to do yeah but basically I would

00:37:47,400 --> 00:37:54,090
say as obvious the top has layers they

00:37:51,510 --> 00:37:57,120
are we are using almost the same code so

00:37:54,090 --> 00:37:59,700
if there's extra overhead or obvious FX

00:37:57,120 --> 00:38:02,010
TP is slower there is probably because

00:37:59,700 --> 00:38:04,440
of the interface

00:38:02,010 --> 00:38:07,260
I try to receive the packet for my FX TP

00:38:04,440 --> 00:38:09,900
create some overhead once we get a

00:38:07,260 --> 00:38:13,940
packet then it's the same with the BTK

00:38:09,900 --> 00:38:16,380
that is the same cause obviously BTK

00:38:13,940 --> 00:38:19,500
what so the one thing I need to mention

00:38:16,380 --> 00:38:21,450
is that right now if we kept packet from

00:38:19,500 --> 00:38:24,240
obvious DVD case then it already has

00:38:21,450 --> 00:38:31,260
this rx hash there but in the case of a

00:38:24,240 --> 00:38:35,640
FX DP we have to calculate rx - another

00:38:31,260 --> 00:38:38,550
thing with you you mentioned that you're

00:38:35,640 --> 00:38:41,100
using facilities in the kernel like

00:38:38,550 --> 00:38:43,140
connection tracking and VLAN or floats

00:38:41,100 --> 00:38:46,020
and so on so let's expand what Dave was

00:38:43,140 --> 00:38:48,150
saying if you go the route of like right

00:38:46,020 --> 00:38:50,370
now you're implementing eb PF but not

00:38:48,150 --> 00:38:52,440
getting the AFA the HTTP speed up

00:38:50,370 --> 00:38:54,060
because you stood on to the stack so one

00:38:52,440 --> 00:38:57,630
thing you could think about is which

00:38:54,060 --> 00:39:00,180
features from the kernel do you need if

00:38:57,630 --> 00:39:02,610
you were to implemented it in HTTP and

00:39:00,180 --> 00:39:05,610
which helpers would be useful to try to

00:39:02,610 --> 00:39:07,860
hook into some of these features even

00:39:05,610 --> 00:39:09,960
from an HTTP context so that you can get

00:39:07,860 --> 00:39:12,990
the speed up but still use what you need

00:39:09,960 --> 00:39:17,100
to do from the rest of the problem so do

00:39:12,990 --> 00:39:20,070
you so you say that to compare this to

00:39:17,100 --> 00:39:22,350
performance I can basically see what the

00:39:20,070 --> 00:39:25,260
overhead right now in obvious EPP F and

00:39:22,350 --> 00:39:28,230
then increment song of the next EP layer

00:39:25,260 --> 00:39:31,860
so that the - project will have full or

00:39:28,230 --> 00:39:34,680
if you move the whole data path into XDP

00:39:31,860 --> 00:39:37,230
okay what subsystems would need to be

00:39:34,680 --> 00:39:39,180
able to handle skb list packets that

00:39:37,230 --> 00:39:42,750
cannot currently do so connection

00:39:39,180 --> 00:39:47,150
tracker would be one of those and

00:39:42,750 --> 00:39:47,150
probably the QoS yes

00:39:55,150 --> 00:40:03,050
so in obvious when you insert flows into

00:40:00,080 --> 00:40:09,430
a full table how do you evict stale flow

00:40:03,050 --> 00:40:12,890
Keys how do i addicted how do you okay

00:40:09,430 --> 00:40:15,230
yes oh yes has another thread Quarry

00:40:12,890 --> 00:40:18,380
validation so from time to time I think

00:40:15,230 --> 00:40:20,750
one second on the eve well check whether

00:40:18,380 --> 00:40:23,480
we need to remove all whether the entry

00:40:20,750 --> 00:40:27,020
in the data path is up to day so if not

00:40:23,480 --> 00:40:30,950
then we'll chore diveded so in the case

00:40:27,020 --> 00:40:43,130
of obviousiy PPF we'll just to remove

00:40:30,950 --> 00:40:44,330
this entry from the EBP map okay so it's

00:40:43,130 --> 00:40:46,370
on that note it's actually quite

00:40:44,330 --> 00:40:48,650
interesting that like we've got some

00:40:46,370 --> 00:40:49,820
stuff in psyllium which is doing we've

00:40:48,650 --> 00:40:51,410
got a connection tracker and we're

00:40:49,820 --> 00:40:53,660
trying to timeout entries there as well

00:40:51,410 --> 00:40:55,730
and if you have a large number of these

00:40:53,660 --> 00:40:56,990
injuries like you're doing like if you

00:40:55,730 --> 00:40:59,300
want to delete it your vessel is to

00:40:56,990 --> 00:41:00,740
syscalls per entry in your map and it's

00:40:59,300 --> 00:41:02,240
a hundred thousand of these or something

00:41:00,740 --> 00:41:04,220
you guys we burn a whole bunch of cpu

00:41:02,240 --> 00:41:06,830
just trying to like timeout entries in

00:41:04,220 --> 00:41:09,530
these in these maps so I think that'll

00:41:06,830 --> 00:41:11,690
be an interesting sort of area for the

00:41:09,530 --> 00:41:13,820
summon bro another thing is that people

00:41:11,690 --> 00:41:15,740
can figure they people want to

00:41:13,820 --> 00:41:17,810
transparently configure OBS and the

00:41:15,740 --> 00:41:19,550
connection tracker and then this xdp

00:41:17,810 --> 00:41:20,900
thing just does the data path and then I

00:41:19,550 --> 00:41:22,130
can still dump my connection tracking

00:41:20,900 --> 00:41:25,280
table and see all the things that are

00:41:22,130 --> 00:41:26,420
happening maybe you get less of that

00:41:25,280 --> 00:41:28,910
because you're controlling the whole

00:41:26,420 --> 00:41:30,140
scenario with cilium and that's like you

00:41:28,910 --> 00:41:31,640
can provide some other interface to

00:41:30,140 --> 00:41:34,280
dumped a connection tracking table or to

00:41:31,640 --> 00:41:36,110
state whereas people using OBS have a

00:41:34,280 --> 00:41:38,750
different set of expectations so yeah

00:41:36,110 --> 00:41:40,640
it's--that's-- and traditionally

00:41:38,750 --> 00:41:43,700
connection tracking has been known to be

00:41:40,640 --> 00:41:45,740
an easy way to overload a system with

00:41:43,700 --> 00:41:51,700
the recycling of the entry so there's

00:41:45,740 --> 00:41:55,250
very serious concern anyone else

00:41:51,700 --> 00:42:00,690
all right you're free to go to lunch

00:41:55,250 --> 00:42:00,690

YouTube URL: https://www.youtube.com/watch?v=lHcUC_AXyio


