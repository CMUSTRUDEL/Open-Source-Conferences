Title: LPC2018 - TC SW Datapath: A Performance Analysis
Publication date: 2018-12-04
Playlist: LPC2018 - Networking Track
Description: 
	url:  https://linuxplumbersconf.org/event/2/contributions/111/
speaker:  Paolo Abeni (Red Hat),  Davide Caratti (Red Hat),  Eelco Chaudron (Red Hat),  Marcelo Ricardo Leitner (Red Hat)


Currently the Linux kernel implements two distinct datapaths for Open
vSwitch: the ovskdp and the TC DP. The latter has been added recently
mainly to allow HW offload, while the former is usually preferred for
SW based forwarding due to functional and performance reasons.

We evaluate both datapaths in a typical forwarding scenario - the PVP
test - using the perf tool to identify bottlenecks in the TC SW dp.
While similar steps usually incur in similar costs, the TC SW DP
requires an additional, per packet, skb_clone, due to a TC actions
constraint.

We propose to extend the existing act infrastructure, leveraging the
ACT_REDIRECT action and the bpf redirect code, to allow clone-free
forwarding from the mirred action and then re-evaluate the datapaths
performances: the gap is then almost already closed.

Nevertheless, TC SW performance can be further improved by completing
the RCU-ification of the TC actions and expanding the recent
listification infrastructure to the TC (ingress) hook. We plan also to
compare the TC/SW datapath with an custom eBPF program implementing the
equivalent flow set to tag a reference value for the target
performances.
Captions: 
	00:00:05,990 --> 00:00:12,690
our next speaker hello I find his

00:00:10,650 --> 00:00:16,590
history a little bit interesting from my

00:00:12,690 --> 00:00:18,390
perspective all of a sudden I saw

00:00:16,590 --> 00:00:21,810
someone posting all these interesting

00:00:18,390 --> 00:00:25,370
UDP optimizations for socket lookup and

00:00:21,810 --> 00:00:28,680
SK be handling who's this guy

00:00:25,370 --> 00:00:30,869
and over time his performance

00:00:28,680 --> 00:00:32,070
improvements as a percentage and various

00:00:30,869 --> 00:00:34,410
different tests were extremely

00:00:32,070 --> 00:00:38,309
impressive and his knowledge of the

00:00:34,410 --> 00:00:40,019
stack in this area was a really show

00:00:38,309 --> 00:00:41,399
that he knew what he was doing and he

00:00:40,019 --> 00:00:45,929
knew how to achieve the goals that he

00:00:41,399 --> 00:00:47,670
was looking after and so be prepared if

00:00:45,929 --> 00:00:49,859
he attacks another subsystem that he's

00:00:47,670 --> 00:00:52,019
gonna do similar awesome work with

00:00:49,859 --> 00:00:53,670
performance improvement and that's what

00:00:52,019 --> 00:00:57,089
he's going to talk about here hello

00:00:53,670 --> 00:00:59,729
thank you I'm Paolo a penny I work for

00:00:57,089 --> 00:01:06,150
adapt and I'm not going to talk you

00:00:59,729 --> 00:01:12,920
about xcp work we made with fellow

00:01:06,150 --> 00:01:16,649
colleagues marcelo really presented : so

00:01:12,920 --> 00:01:19,469
we see like we currently have two

00:01:16,649 --> 00:01:22,259
distinct obvious data paths inside the

00:01:19,469 --> 00:01:24,210
carbonyl and since this is about

00:01:22,259 --> 00:01:27,689
performances we will discuss our

00:01:24,210 --> 00:01:31,350
reference testing scenario can I throw a

00:01:27,689 --> 00:01:35,549
bunch of numbers and figures and yes

00:01:31,350 --> 00:01:40,549
it's not about to be pf+ we will see if

00:01:35,549 --> 00:01:45,710
we have changes a lot I think the veneer

00:01:40,549 --> 00:01:49,799
so why we have two different obvious can

00:01:45,710 --> 00:01:53,700
obvious lotta parties that happen

00:01:49,799 --> 00:01:58,820
thanks to Winnie until presentation a

00:01:53,700 --> 00:02:02,609
radial you know about obvious and the

00:01:58,820 --> 00:02:07,020
old obvious cannot about has been added

00:02:02,609 --> 00:02:09,929
a long time ago is considered to be the

00:02:07,020 --> 00:02:16,370
faster implementation available and it's

00:02:09,929 --> 00:02:19,230
officially complete recently to support

00:02:16,370 --> 00:02:21,900
Hardware offloaded

00:02:19,230 --> 00:02:24,540
another data pot has been implicit we

00:02:21,900 --> 00:02:28,200
added the DC software data but because

00:02:24,540 --> 00:02:33,659
we use dc/dt silk to offload flows to

00:02:28,200 --> 00:02:35,519
the upper and two features to support an

00:02:33,659 --> 00:02:40,200
upper Fischer we need to support also

00:02:35,519 --> 00:02:43,829
the same picture in the TC software

00:02:40,200 --> 00:02:47,819
infrastructure and that can be to

00:02:43,829 --> 00:02:50,489
another candidate patent side obvious

00:02:47,819 --> 00:02:54,269
data pÃ¢tisserie comment date it is

00:02:50,489 --> 00:02:57,689
considered slower and lat still lacks

00:02:54,269 --> 00:02:59,939
some of fish some features that are

00:02:57,689 --> 00:03:08,639
required for example connection tracking

00:02:59,939 --> 00:03:12,349
even if this is in the world so this is

00:03:08,639 --> 00:03:14,730
about reference testing scenario the p2p

00:03:12,349 --> 00:03:18,239
dictionary will be P stands for physical

00:03:14,730 --> 00:03:20,879
to be able to physical the device under

00:03:18,239 --> 00:03:25,019
test is back to back to connected with

00:03:20,879 --> 00:03:27,090
the traffic generator and they have the

00:03:25,019 --> 00:03:29,459
NIC receiving the traffic for the route

00:03:27,090 --> 00:03:33,750
invader is enslaved to an obvious switch

00:03:29,459 --> 00:03:37,430
which also comprised a term device which

00:03:33,750 --> 00:03:40,530
use it to give network connectivity to

00:03:37,430 --> 00:03:45,419
virtual machines that receive the

00:03:40,530 --> 00:03:48,659
traffic net device inside the VM and the

00:03:45,419 --> 00:03:51,959
PDK application is running test BMD such

00:03:48,659 --> 00:03:57,019
application read the packet from the

00:03:51,959 --> 00:04:00,419
virtual devices loop them back the

00:03:57,019 --> 00:04:02,510
obvious which inside the obvious which

00:04:00,419 --> 00:04:05,699
we have configured at the number of

00:04:02,510 --> 00:04:07,470
symmetric flows so that each packet

00:04:05,699 --> 00:04:12,209
received on the physical NIC is

00:04:07,470 --> 00:04:15,150
forwarded to the to device to the VM the

00:04:12,209 --> 00:04:17,280
VM loop them back and another flow in

00:04:15,150 --> 00:04:21,209
the obvious for what the packet received

00:04:17,280 --> 00:04:23,000
from the turn device to the same

00:04:21,209 --> 00:04:27,719
physical device where the packet were

00:04:23,000 --> 00:04:30,440
originally signal well does not every

00:04:27,719 --> 00:04:34,110
real let's say

00:04:30,440 --> 00:04:37,830
application in any real-world scenario

00:04:34,110 --> 00:04:40,320
but it's used to stress as much as

00:04:37,830 --> 00:04:44,730
possible therefore whopping capabilities

00:04:40,320 --> 00:04:48,870
or obvious and this is why we use this

00:04:44,730 --> 00:04:55,710
that DTK application to avoid both

00:04:48,870 --> 00:04:59,430
bottlenecks inside DBM so let's see the

00:04:55,710 --> 00:05:06,180
figures these are collected on top of

00:04:59,430 --> 00:05:08,640
limos Linux 417 the purple columns show

00:05:06,180 --> 00:05:10,950
the performances for the obvious

00:05:08,640 --> 00:05:14,280
candidate apart the other for the thesis

00:05:10,950 --> 00:05:16,050
of the data bar we made several

00:05:14,280 --> 00:05:19,920
different tests changing the number of

00:05:16,050 --> 00:05:23,490
conquer and flaws we can see that they

00:05:19,920 --> 00:05:31,230
can be plain old obvious can that apart

00:05:23,490 --> 00:05:35,760
is like did you see yeah performance not

00:05:31,230 --> 00:05:38,580
that bad because with roughly 800,000

00:05:35,760 --> 00:05:42,980
packet per seconds we can cope with a 10

00:05:38,580 --> 00:05:42,980
gigabit flows using max and two packets

00:05:44,000 --> 00:05:52,320
we are actually using a small packets in

00:05:49,080 --> 00:05:56,790
this test 64 byte packet just to stress

00:05:52,320 --> 00:06:00,750
the foot working more but distances

00:05:56,790 --> 00:06:06,000
perhaps bit misleading because we are

00:06:00,750 --> 00:06:09,600
using a single receive cue inside the

00:06:06,000 --> 00:06:13,370
panic which is not a usual default so

00:06:09,600 --> 00:06:19,470
let's see how things change when we use

00:06:13,370 --> 00:06:22,770
multiple receive cue in our tonic in

00:06:19,470 --> 00:06:24,990
this case we are using sixteen receive

00:06:22,770 --> 00:06:29,460
cues which is the default for the

00:06:24,990 --> 00:06:31,860
artwork we add a tolerance and we can

00:06:29,460 --> 00:06:35,550
see that the obvious caneta part is

00:06:31,860 --> 00:06:40,110
still miserably faster than the TCS

00:06:35,550 --> 00:06:41,030
often one but performances dropped a lot

00:06:40,110 --> 00:06:46,640
when

00:06:41,030 --> 00:06:50,690
we had multiple cook continent flows in

00:06:46,640 --> 00:06:55,970
our tests we use at l3 flows meaning

00:06:50,690 --> 00:07:00,070
that each flows the different source IP

00:06:55,970 --> 00:07:02,960
destination IP address meaning that

00:07:00,070 --> 00:07:05,710
different flows with default RSS

00:07:02,960 --> 00:07:10,430
configuration landed two different

00:07:05,710 --> 00:07:13,510
received queue two different England two

00:07:10,430 --> 00:07:17,870
different meat receive queue so it is

00:07:13,510 --> 00:07:21,890
very bad slowdown could less let us

00:07:17,870 --> 00:07:25,940
think about some contention problem we

00:07:21,890 --> 00:07:30,530
can try to inspect with path if there is

00:07:25,940 --> 00:07:35,870
really some contention on the Left we

00:07:30,530 --> 00:07:38,840
see the top step back in our scenario

00:07:35,870 --> 00:07:41,570
the bottleneck was in the viewers

00:07:38,840 --> 00:07:46,340
process which is a common thread in

00:07:41,570 --> 00:07:49,400
charge of passing the graph where they

00:07:46,340 --> 00:07:54,140
can a buffer out to the user space and

00:07:49,400 --> 00:07:55,820
vice versa on the Left we see the top

00:07:54,140 --> 00:07:59,120
most powerful fender for the vias

00:07:55,820 --> 00:08:02,930
process when we had one single receive

00:07:59,120 --> 00:08:07,250
queue and there are when we had sixteen

00:08:02,930 --> 00:08:09,890
receive queue this with the Oviatt open

00:08:07,250 --> 00:08:11,810
with which kernel data path similar

00:08:09,890 --> 00:08:15,650
result with the thesis of the water

00:08:11,810 --> 00:08:18,919
while the offenders list change quite a

00:08:15,650 --> 00:08:23,510
bit there is no clear sign of contention

00:08:18,919 --> 00:08:27,620
and it's quite an obvious at least to me

00:08:23,510 --> 00:08:32,690
to find out why we are so slow with

00:08:27,620 --> 00:08:36,740
sixteen queues so we can use some more

00:08:32,690 --> 00:08:39,700
help from path looking at the call graph

00:08:36,740 --> 00:08:44,720
accounting still for the abuse process

00:08:39,700 --> 00:08:47,900
and we can see that the end all our X

00:08:44,720 --> 00:08:50,780
function is taking in most of the CPU

00:08:47,900 --> 00:08:51,800
time while the end of ticks function is

00:08:50,780 --> 00:08:54,620
taking only a little

00:08:51,800 --> 00:08:56,990
of the our CPU time the another ethics

00:08:54,620 --> 00:09:01,370
faction is responsible for processing

00:08:56,990 --> 00:09:05,570
the packets sent by the kernel we are

00:09:01,370 --> 00:09:09,529
there to device up to the user space and

00:09:05,570 --> 00:09:11,990
we meeting that function is really

00:09:09,529 --> 00:09:18,680
radius lower than the opposite direction

00:09:11,990 --> 00:09:23,690
but it's not if we look at the two

00:09:18,680 --> 00:09:26,000
device stats we see the views processes

00:09:23,690 --> 00:09:28,370
processing much more packets in the

00:09:26,000 --> 00:09:32,959
iraq's direction that the opposite one

00:09:28,370 --> 00:09:36,079
and we may wonder why this is due to

00:09:32,959 --> 00:09:39,040
some limits that are our code inside the

00:09:36,079 --> 00:09:42,310
vos process itself because process is

00:09:39,040 --> 00:09:45,980
responsible for scheduling the

00:09:42,310 --> 00:09:49,579
processing of the true direction that is

00:09:45,980 --> 00:09:54,410
for deceiving when processing I expect

00:09:49,579 --> 00:10:00,260
when processing expire and it has coded

00:09:54,410 --> 00:10:05,050
a byte base at a limit for what

00:10:00,260 --> 00:10:08,570
direction but up to 470 it also had the

00:10:05,050 --> 00:10:12,529
packet base limit only for the tEEX

00:10:08,570 --> 00:10:14,959
direction it pocket at limited a lot the

00:10:12,529 --> 00:10:17,540
amount of work we will do data x

00:10:14,959 --> 00:10:21,350
direction and was the cause of TC

00:10:17,540 --> 00:10:23,930
balance once that we have C which was

00:10:21,350 --> 00:10:28,910
the root cause the fix was trivial and

00:10:23,930 --> 00:10:31,720
was implementing the same limits in both

00:10:28,910 --> 00:10:37,160
direction and that has been done in the

00:10:31,720 --> 00:10:48,410
418 release cycle and we can see how

00:10:37,160 --> 00:10:51,709
that changed in respect to 417 the

00:10:48,410 --> 00:10:52,850
performance for multi flows scenarios

00:10:51,709 --> 00:10:57,620
has improved a lot

00:10:52,850 --> 00:11:02,390
it's about four six times more and we

00:10:57,620 --> 00:11:04,740
can see that a open V switch can another

00:11:02,390 --> 00:11:08,430
party still miss is miserable

00:11:04,740 --> 00:11:16,940
faster than theta-c softer wampie and

00:11:08,430 --> 00:11:21,830
now we can try to investigate why still

00:11:16,940 --> 00:11:21,830
please don't look at the last two lights

00:11:22,459 --> 00:11:32,430
not so not least still we are using some

00:11:26,700 --> 00:11:35,209
helpful from path looking at the top

00:11:32,430 --> 00:11:38,220
most powerful fender on the left for the

00:11:35,209 --> 00:11:42,510
obvious karna left pad on the right with

00:11:38,220 --> 00:11:44,970
the TC soft apart again the two lists

00:11:42,510 --> 00:11:48,170
are quite different but at least to me

00:11:44,970 --> 00:11:53,040
it's not entirely obvious understand why

00:11:48,170 --> 00:11:55,920
TC was lower just looking at them after

00:11:53,040 --> 00:11:58,730
you can see that they look up is a

00:11:55,920 --> 00:12:03,029
little more efficient we did you see

00:11:58,730 --> 00:12:06,570
compare it to the obvious with obvious

00:12:03,029 --> 00:12:10,100
the first offender is Muscat floor

00:12:06,570 --> 00:12:13,829
lookup that is a function performing a

00:12:10,100 --> 00:12:17,310
fluke up in DC we have a little bit

00:12:13,829 --> 00:12:19,579
faster because we use the programmable

00:12:17,310 --> 00:12:25,310
flow the second infrastructure

00:12:19,579 --> 00:12:28,709
anyhow we are slower we need to look

00:12:25,310 --> 00:12:32,279
some symbol more down the list for data

00:12:28,709 --> 00:12:34,860
series of the weekend and specifically

00:12:32,279 --> 00:12:38,430
you can found this SK big long function

00:12:34,860 --> 00:12:40,680
then we don't have with obvious per se

00:12:38,430 --> 00:12:43,440
is not very expensive but it adds

00:12:40,680 --> 00:12:50,100
overhead all along stack spiria

00:12:43,440 --> 00:12:57,750
specially for to the sk b memory life

00:12:50,100 --> 00:13:02,070
cycle so why do we have to clone a

00:12:57,750 --> 00:13:06,990
pocket with the C this is due to the TC

00:13:02,070 --> 00:13:09,779
infrastructure that requires that the

00:13:06,990 --> 00:13:14,430
color of the tea silk retain ownership

00:13:09,779 --> 00:13:17,139
of the sk b so in action like drop in

00:13:14,430 --> 00:13:22,329
the packet should be done by the

00:13:17,139 --> 00:13:24,579
of the TCO the piece of this

00:13:22,329 --> 00:13:29,339
infrastructure that does the forwarding

00:13:24,579 --> 00:13:33,999
is the active mirror action module and

00:13:29,339 --> 00:13:37,829
to keep with this constraint it has to

00:13:33,999 --> 00:13:41,649
clone the skb packet forward to digress

00:13:37,829 --> 00:13:43,029
interface the commit packet and return

00:13:41,649 --> 00:13:47,199
to the corner

00:13:43,029 --> 00:13:50,350
the original one and in the obvious

00:13:47,199 --> 00:13:54,609
context it applied to that packet called

00:13:50,350 --> 00:13:57,609
running action that say that tell the

00:13:54,609 --> 00:14:02,279
code the DC caller to just drop the

00:13:57,609 --> 00:14:05,379
bucket so we could avoid the clone

00:14:02,279 --> 00:14:08,139
introducing a new control in action for

00:14:05,379 --> 00:14:12,549
the central structure that implemented

00:14:08,139 --> 00:14:14,730
the forwarding capabilities and use it

00:14:12,549 --> 00:14:18,100
that controller action inside the

00:14:14,730 --> 00:14:24,689
admitted module and that has been done

00:14:18,100 --> 00:14:27,730
in the 419 release cycle and we can look

00:14:24,689 --> 00:14:32,079
the performance on top of that changing

00:14:27,730 --> 00:14:35,829
I'm not here we didn't use for nineteen

00:14:32,079 --> 00:14:38,110
Familia because it was not yet out at

00:14:35,829 --> 00:14:46,239
the time when we collected the data it's

00:14:38,110 --> 00:14:49,419
for nineteen c6 here we compare the

00:14:46,239 --> 00:14:52,389
obvious kernel data path that version

00:14:49,419 --> 00:14:54,850
with issues of the data path and also to

00:14:52,389 --> 00:14:55,480
teaches of the data path on the previous

00:14:54,850 --> 00:14:58,480
camera

00:14:55,480 --> 00:15:00,970
Narsha and we can issue a roughly 10%

00:14:58,480 --> 00:15:03,869
perform improvement but this is after

00:15:00,970 --> 00:15:09,029
that part that is now a little bit

00:15:03,869 --> 00:15:09,029
faster than the obvious corner lot

00:15:10,860 --> 00:15:23,980
so so far I tension emitted some points

00:15:19,319 --> 00:15:29,740
one is that they teach is softer data

00:15:23,980 --> 00:15:33,970
path due to TCC infrastructure you use a

00:15:29,740 --> 00:15:37,030
indirect call for each action present in

00:15:33,970 --> 00:15:40,320
the flaws in our exemplar we had a

00:15:37,030 --> 00:15:43,390
single action were flown and that give a

00:15:40,320 --> 00:15:46,120
reasonable low read in the rare case

00:15:43,390 --> 00:15:49,090
scenario we had multiple action per

00:15:46,120 --> 00:15:52,180
flaws in that case red line overhead

00:15:49,090 --> 00:15:57,780
adapts and will slow down the tissues of

00:15:52,180 --> 00:16:04,030
the pod we look a little bit to apply

00:15:57,780 --> 00:16:08,410
mystification here which is the idea

00:16:04,030 --> 00:16:10,330
introduced by edward cree to pass along

00:16:08,410 --> 00:16:16,560
the network restock instead of a single

00:16:10,330 --> 00:16:19,270
sk be a list of sk that receive similar

00:16:16,560 --> 00:16:22,480
threatening the networking stuff stuck

00:16:19,270 --> 00:16:28,450
itself but it's very difficult to apply

00:16:22,480 --> 00:16:33,450
here because this years a lot of Nesta

00:16:28,450 --> 00:16:33,450
books and this change will be very

00:16:36,240 --> 00:16:46,540
another point of tension is that several

00:16:40,710 --> 00:16:49,480
TC action do not do not scale well when

00:16:46,540 --> 00:16:53,010
multiple queues are involved because

00:16:49,480 --> 00:16:56,680
they use spin alone to synchronize the

00:16:53,010 --> 00:16:59,380
data part with the controlling part here

00:16:56,680 --> 00:17:02,500
the solution relative was simple and

00:16:59,380 --> 00:17:05,410
this migrating such such action to use

00:17:02,500 --> 00:17:10,240
SEO and this is working progress

00:17:05,410 --> 00:17:13,450
currently I think only PID is a toggle

00:17:10,240 --> 00:17:16,020
between the action user by the pieces of

00:17:13,450 --> 00:17:16,020
the data path

00:17:16,270 --> 00:17:24,130
another thing that cool he could have

00:17:19,990 --> 00:17:28,069
use it and prove performance is using

00:17:24,130 --> 00:17:31,280
two separate thread to process

00:17:28,069 --> 00:17:34,070
packet packet well want Red Cross

00:17:31,280 --> 00:17:36,590
packing the era x-direction in another

00:17:34,070 --> 00:17:42,559
thread to process packet with the X

00:17:36,590 --> 00:17:45,410
direction and that would most almost

00:17:42,559 --> 00:17:48,260
double their performances but it will

00:17:45,410 --> 00:17:54,610
that be similar to just adding more

00:17:48,260 --> 00:17:58,670
visual cue to the vista your device

00:17:54,610 --> 00:18:05,500
since we have it would have traded more

00:17:58,670 --> 00:18:08,120
CPU power for more bandwidth final

00:18:05,500 --> 00:18:14,929
consideration but the number we have

00:18:08,120 --> 00:18:17,570
seen we are still quite far from it's a

00:18:14,929 --> 00:18:20,840
carrier grade requirements which ask for

00:18:17,570 --> 00:18:24,920
the usual fourteen million packets per

00:18:20,840 --> 00:18:28,520
second and we are still also quite far

00:18:24,920 --> 00:18:30,559
from the performance women issue from

00:18:28,520 --> 00:18:34,790
this kind of artwork with bypass

00:18:30,559 --> 00:18:38,120
solutions like decay for example in this

00:18:34,790 --> 00:18:39,950
test we duplicate issued around two

00:18:38,120 --> 00:18:46,100
million and half packet per seconds with

00:18:39,950 --> 00:18:50,090
ten thousand concurrent flows so since

00:18:46,100 --> 00:18:53,270
we spoke a lot performances and the only

00:18:50,090 --> 00:18:57,500
girl for resolving performance provinces

00:18:53,270 --> 00:19:02,870
xdp we have wonder if actually we will

00:18:57,500 --> 00:19:06,950
will save us here if we could fill the

00:19:02,870 --> 00:19:13,280
gap between the candidate patton bypass

00:19:06,950 --> 00:19:18,650
solutions we've seen that a b PF began

00:19:13,280 --> 00:19:23,300
for obvious is currently in the work we

00:19:18,650 --> 00:19:26,929
choose not to use that instead we use a

00:19:23,300 --> 00:19:29,000
simple x DP v PF program that was in

00:19:26,929 --> 00:19:31,270
charge of forwarding the packet between

00:19:29,000 --> 00:19:31,270
the

00:19:31,340 --> 00:19:36,800
physical Nick and tune device and visa

00:19:35,270 --> 00:19:40,370
versa

00:19:36,800 --> 00:19:43,100
we did the choice for two reasons

00:19:40,370 --> 00:19:47,330
the first one is that we wanted to avoid

00:19:43,100 --> 00:19:49,640
a mental bottleneck present in the ABP f

00:19:47,330 --> 00:19:52,640
obvious implementation at this early

00:19:49,640 --> 00:19:55,400
stage and the other a more relevant one

00:19:52,640 --> 00:20:00,770
was that we needed to somehow experiment

00:19:55,400 --> 00:20:03,830
to stand with xt p so we are not with

00:20:00,770 --> 00:20:05,120
this very trivial implementation that is

00:20:03,830 --> 00:20:10,660
a problem

00:20:05,120 --> 00:20:16,150
it just passed a packet up to the layer

00:20:10,660 --> 00:20:19,160
look up the IP addresses in a use of the

00:20:16,150 --> 00:20:20,270
user control that map and forward the

00:20:19,160 --> 00:20:24,620
packet yeah

00:20:20,270 --> 00:20:28,700
ready net map to the device specify into

00:20:24,620 --> 00:20:33,410
the mata entry it's very far from being

00:20:28,700 --> 00:20:36,500
a complete solution after he serves only

00:20:33,410 --> 00:20:40,070
to T's purpose but gives a reasonable

00:20:36,500 --> 00:20:43,490
upper bound of what we can see we can

00:20:40,070 --> 00:20:46,220
obtain with x DP and the BPF since we do

00:20:43,490 --> 00:20:49,630
exactly what to look up and as it's

00:20:46,220 --> 00:20:54,620
needed for example status accounting and

00:20:49,630 --> 00:20:59,720
director so yeah

00:20:54,620 --> 00:21:06,700
the fuse and we can see that with X dpi

00:20:59,720 --> 00:21:09,430
BPF we reach almost 1 million and

00:21:06,700 --> 00:21:12,680
200,000 packets per second the single

00:21:09,430 --> 00:21:18,020
flow scenario little less with multiple

00:21:12,680 --> 00:21:22,310
flows which is roughly 50% more than the

00:21:18,020 --> 00:21:24,680
ATC software figures it's quite good

00:21:22,310 --> 00:21:28,490
it's little that probably a little less

00:21:24,680 --> 00:21:34,090
than expected this is with the default

00:21:28,490 --> 00:21:41,840
default configuration if that is with

00:21:34,090 --> 00:21:45,160
zero copy in enabled in the BIOS driver

00:21:41,840 --> 00:21:49,130
if we disable zero copy the a tourniquet

00:21:45,160 --> 00:21:52,100
miserable speed up and we reach around 1

00:21:49,130 --> 00:21:55,640
million packet 1 million and our packet

00:21:52,100 --> 00:21:58,250
per second this is why in the non zero

00:21:55,640 --> 00:22:02,930
copy case there is a sort of first part

00:21:58,250 --> 00:22:06,200
between V Austin the tone device that -

00:22:02,930 --> 00:22:10,190
barking of packets and give a good gives

00:22:06,200 --> 00:22:13,370
a good speed up but still we are a

00:22:10,190 --> 00:22:18,580
little bit far from the same bypass

00:22:13,370 --> 00:22:21,380
solution and we get similar improvement

00:22:18,580 --> 00:22:24,290
similar proportion improving when

00:22:21,380 --> 00:22:31,820
disabled disabling zero copy even for

00:22:24,290 --> 00:22:33,260
the thesis of the data path so we can

00:22:31,820 --> 00:22:37,910
expect from the future

00:22:33,260 --> 00:22:41,120
you've seen that XDP sorry that a BPF

00:22:37,910 --> 00:22:44,840
they can t seem to work for open we

00:22:41,120 --> 00:22:46,580
switch and also in a FX DP this in the

00:22:44,840 --> 00:22:50,300
world for yes

00:22:46,580 --> 00:22:54,230
I personally think that from from a

00:22:50,300 --> 00:22:59,660
person the sorry from a performance

00:22:54,230 --> 00:23:01,840
perspective only point of view i x DP is

00:22:59,660 --> 00:23:08,270
probably the most provides in approach

00:23:01,840 --> 00:23:14,230
because in our testing we meet this

00:23:08,270 --> 00:23:18,140
bottleneck in the views process and

00:23:14,230 --> 00:23:20,540
specifically in the function in charge

00:23:18,140 --> 00:23:26,600
of translating the buffer descriptor

00:23:20,540 --> 00:23:30,980
from Colonel to user space this to

00:23:26,600 --> 00:23:34,070
function here and count for roughly

00:23:30,980 --> 00:23:38,630
eight percent when using the thesis of

00:23:34,070 --> 00:23:42,170
the data path then using the x DPI BPF

00:23:38,630 --> 00:23:45,410
program they weight grow we've caused a

00:23:42,170 --> 00:23:49,940
packet rate Grosso or so and it's about

00:23:45,410 --> 00:23:53,870
20% or more with I effects do P we

00:23:49,940 --> 00:23:58,070
probably such cost we go to zero and

00:23:53,870 --> 00:24:02,029
so I should if improvement another

00:23:58,070 --> 00:24:06,740
things that we possibly have something

00:24:02,029 --> 00:24:11,150
said economy up get sorry that could

00:24:06,740 --> 00:24:18,710
help us is a huge new DP 0 for what a

00:24:11,150 --> 00:24:21,830
pocket that could help only in the Asian

00:24:18,710 --> 00:24:24,260
area that are using a limited number of

00:24:21,830 --> 00:24:28,220
laws because when the number of laws

00:24:24,260 --> 00:24:49,039
grows a lot we will not be able to

00:24:28,220 --> 00:24:51,169
perform aggregation so you mentioned

00:24:49,039 --> 00:24:54,429
some difference between that classifier

00:24:51,169 --> 00:24:57,740
in TC and obvious like in the purview of

00:24:54,429 --> 00:25:01,010
obvious we always see the mask flow loca

00:24:57,740 --> 00:25:04,970
showing the top and so I wonder what's

00:25:01,010 --> 00:25:11,120
the the weight is he does classification

00:25:04,970 --> 00:25:13,370
and why it's a faster yes TC the thesis

00:25:11,120 --> 00:25:19,159
of the datapath uses the programmable

00:25:13,370 --> 00:25:23,830
floaty sector to perform the part they

00:25:19,159 --> 00:25:23,830
look after the flow steady flow table

00:25:25,610 --> 00:25:34,549
let me see oh we can see some function

00:25:31,730 --> 00:25:37,490
related to touch this SKB flow this

00:25:34,549 --> 00:25:41,809
sector performed a passing and this main

00:25:37,490 --> 00:25:45,860
compare is actually the comparison

00:25:41,809 --> 00:25:49,100
function for the flows it's quite costly

00:25:45,860 --> 00:25:51,470
because as you know that the key is

00:25:49,100 --> 00:25:54,590
quite large for obvious and this is

00:25:51,470 --> 00:26:01,279
beginning probably a custom

00:25:54,590 --> 00:26:05,010
implementation using long word instead

00:26:01,279 --> 00:26:08,650
that that single bite could be faster

00:26:05,010 --> 00:26:18,780
yeah instead open with which he uses his

00:26:08,650 --> 00:26:18,780
own custom lookup function anyone else

00:26:22,240 --> 00:26:26,710
yep I'd and there's a couple of things

00:26:25,180 --> 00:26:29,500
that I think would be maybe more

00:26:26,710 --> 00:26:31,030
interesting to also work on choice so

00:26:29,500 --> 00:26:36,580
one thing is the number of unique masks

00:26:31,030 --> 00:26:38,350
you have can affect this so like that

00:26:36,580 --> 00:26:40,090
that's fundamentally something about the

00:26:38,350 --> 00:26:43,330
way that the lookup works that would

00:26:40,090 --> 00:26:51,040
would change the way the numbers that

00:26:43,330 --> 00:26:53,980
you're actually gonna get cuz like it's

00:26:51,040 --> 00:26:56,260
kind of the idea behind obvious he's got

00:26:53,980 --> 00:26:57,370
like fairly high-level perhaps like

00:26:56,260 --> 00:26:58,660
hundreds of thousands of these open

00:26:57,370 --> 00:27:02,050
floor rules and you can sort of compile

00:26:58,660 --> 00:27:03,930
that down into a smaller set but the

00:27:02,050 --> 00:27:06,850
smaller set is based on like different

00:27:03,930 --> 00:27:09,280
bid mosques against different flows and

00:27:06,850 --> 00:27:12,070
so depending on how complex your overall

00:27:09,280 --> 00:27:15,370
higher level pipeline is that pushes

00:27:12,070 --> 00:27:17,140
down different numbers of masks so I'd

00:27:15,370 --> 00:27:18,840
be curious to see what this looks like

00:27:17,140 --> 00:27:21,130
with maybe a slightly more realistic

00:27:18,840 --> 00:27:23,310
benchmark like maybe setup ovn or

00:27:21,130 --> 00:27:25,660
something like that and just like see

00:27:23,310 --> 00:27:32,320
now you might have to turn off a couple

00:27:25,660 --> 00:27:34,390
yeah you're right meaning that the flow

00:27:32,320 --> 00:27:37,300
set use at the year is completely

00:27:34,390 --> 00:27:43,120
synthetic and is quite different from

00:27:37,300 --> 00:27:49,540
whatever OpenStack or whatever tools

00:27:43,120 --> 00:27:52,660
installs but I I don't have numbers or

00:27:49,540 --> 00:27:55,240
figures or graphs I believe that over

00:27:52,660 --> 00:27:58,570
all that let's say they'll look up cost

00:27:55,240 --> 00:28:03,340
should not change much I think what we

00:27:58,570 --> 00:28:09,030
change more looking at we are obvious

00:28:03,340 --> 00:28:12,550
number OpenStack number is that this

00:28:09,030 --> 00:28:17,220
histogram will sink a lot because just

00:28:12,550 --> 00:28:20,340
because the rosette is much more complex

00:28:17,220 --> 00:28:22,350
usually require several receipt

00:28:20,340 --> 00:28:26,850
quotation meaning that on the same

00:28:22,350 --> 00:28:31,350
packet we compute several times the ash

00:28:26,850 --> 00:28:34,170
and we do several cuts per packet and in

00:28:31,350 --> 00:28:40,890
that sense YouTube

00:28:34,170 --> 00:28:51,720
jierou even for a limited range of

00:28:40,890 --> 00:28:55,290
scenarios could give good improvement so

00:28:51,720 --> 00:28:57,960
for for the HTTP redirect did you use

00:28:55,290 --> 00:29:02,430
the map variant of yes I just want to

00:28:57,960 --> 00:29:11,130
make sure I look at that the comments

00:29:02,430 --> 00:29:12,210
inside either five it was politically EQ

00:29:11,130 --> 00:29:17,609
Paulo

00:29:12,210 --> 00:29:17,609

YouTube URL: https://www.youtube.com/watch?v=W1AhODsNTQc


