Title: LPC2018 - Combining kTLS and BPF for Introspection and Policy Enforcement
Publication date: 2018-12-04
Playlist: LPC2018 - Networking Track
Description: 
	url:  https://linuxplumbersconf.org/event/2/contributions/105/
speaker:  Daniel Borkmann (Cilium), John Fastabend (Cilium)


This talk is divided into two parts, first we present on kTLS, the current kernel's
sockmap BPF architecture for L7 policy enforcement, as well as the kernel's ULP and
strparser framework which is utilized by both in order to hook into socket callbacks
and determine message boundaries for subsequent processing.

We further elaborate on the challenges we face when trying to combine kTLS with the
power of BPF for the eventual goal of allowing in-kernel introspection and policy
enforcement of application data before encryption. Besides others, this includes a
discussion on various approaches to address the shortcomings of the current ULP layer,
optimizations for strparser, and the consolidation of scatter/gather processing for
kTLS and sockmap as well as future work on top of that.
Captions: 
	00:00:05,680 --> 00:00:17,840
okay moving right along in addition to

00:00:14,080 --> 00:00:25,670
being a co maintainer of the BPF with

00:00:17,840 --> 00:00:29,360
Alexia and preparing the BPF tract for

00:00:25,670 --> 00:00:31,280
Thursday he was helping me with the

00:00:29,360 --> 00:00:33,020
networking track as well and he brought

00:00:31,280 --> 00:00:35,539
his laptop to help with this

00:00:33,020 --> 00:00:38,300
so Daniels contributions are numerous

00:00:35,539 --> 00:00:39,860
and valuable and I really appreciate all

00:00:38,300 --> 00:00:41,420
the effort he's put into helping make

00:00:39,860 --> 00:00:42,680
everything great analytics networking

00:00:41,420 --> 00:00:46,040
new BPF subsystems

00:00:42,680 --> 00:00:48,050
today he's gonna talk about KT LS and

00:00:46,040 --> 00:00:49,579
layering and all the issues that were

00:00:48,050 --> 00:00:51,620
have to fight with that and how we're

00:00:49,579 --> 00:00:53,930
gonna resolve it and he's gonna get some

00:00:51,620 --> 00:00:58,489
help from John fast defense so should be

00:00:53,930 --> 00:01:01,160
interesting thank you very much so today

00:00:58,489 --> 00:01:03,460
I would like to talk about the work that

00:01:01,160 --> 00:01:07,880
John and myself have been doing over

00:01:03,460 --> 00:01:10,460
recently on combining Katie Ellis with

00:01:07,880 --> 00:01:14,740
PPF so that we can do policy enforcement

00:01:10,460 --> 00:01:18,020
there first a little bit of background

00:01:14,740 --> 00:01:21,310
what why all this so basically right now

00:01:18,020 --> 00:01:24,229
in the industry we see a shift where

00:01:21,310 --> 00:01:27,140
enterprises split their monolithic

00:01:24,229 --> 00:01:29,720
application into so-called micro

00:01:27,140 --> 00:01:32,600
services in the distributed level what

00:01:29,720 --> 00:01:35,150
is the Micro Service that's basically a

00:01:32,600 --> 00:01:37,159
service that does one simple thing well

00:01:35,150 --> 00:01:39,920
it communicates over the network and

00:01:37,159 --> 00:01:42,170
it's built and managed independently by

00:01:39,920 --> 00:01:44,950
independent teams basically like the old

00:01:42,170 --> 00:01:49,130
UNIX philosophy just brought into

00:01:44,950 --> 00:01:52,130
enterprise service world and whatnot the

00:01:49,130 --> 00:01:54,320
key motivation why this is so popular

00:01:52,130 --> 00:01:56,150
right now this design pattern is

00:01:54,320 --> 00:02:00,110
basically that it allows enterprise is

00:01:56,150 --> 00:02:02,560
city can to have basically more speed

00:02:00,110 --> 00:02:05,119
scale and the guilty so that they can

00:02:02,560 --> 00:02:07,700
react faster to the market because of

00:02:05,119 --> 00:02:09,019
that and those micro services that can

00:02:07,700 --> 00:02:11,250
be implemented in whatever language you

00:02:09,019 --> 00:02:13,540
like but they have one lowest common

00:02:11,250 --> 00:02:15,530
[Music]

00:02:13,540 --> 00:02:17,530
denominator to communicate with each

00:02:15,530 --> 00:02:21,010
other and that is an API

00:02:17,530 --> 00:02:23,260
and that's typically REST API over HTTP

00:02:21,010 --> 00:02:24,580
and it also allows them to outsource

00:02:23,260 --> 00:02:28,840
various things for example you have

00:02:24,580 --> 00:02:31,870
stripe for payment processing and Twilio

00:02:28,840 --> 00:02:34,810
for messaging and so on you can see some

00:02:31,870 --> 00:02:36,490
examples of those api's and the basic

00:02:34,810 --> 00:02:39,790
idea is that the microservice itself

00:02:36,490 --> 00:02:43,030
becomes easier to develop the bark and

00:02:39,790 --> 00:02:46,350
deploys we just have test cases against

00:02:43,030 --> 00:02:49,810
the API and see what the outcome is but

00:02:46,350 --> 00:02:51,840
the big downside or like a big challenge

00:02:49,810 --> 00:02:54,670
in that sense is that you have a higher

00:02:51,840 --> 00:02:56,380
operational complexity because you need

00:02:54,670 --> 00:02:59,650
to take care of all the security

00:02:56,380 --> 00:03:02,110
policies load balancing scaling policies

00:02:59,650 --> 00:03:06,060
and all of that and there's a platform

00:03:02,110 --> 00:03:08,440
that helps basically in deploying

00:03:06,060 --> 00:03:11,110
scaling and operating all of this which

00:03:08,440 --> 00:03:13,770
is called kubernetes at the heart of all

00:03:11,110 --> 00:03:18,160
of this is of course the Linux kernel

00:03:13,770 --> 00:03:20,140
and in coupon edits you have some some

00:03:18,160 --> 00:03:23,470
entities which are called parts those

00:03:20,140 --> 00:03:27,400
are basically a combination of C groups

00:03:23,470 --> 00:03:30,100
and namespaces that can contain one or

00:03:27,400 --> 00:03:32,080
multiple containers and basically they

00:03:30,100 --> 00:03:34,510
share a common policy for example

00:03:32,080 --> 00:03:39,070
security policy or policy how you roll

00:03:34,510 --> 00:03:39,930
out a particular service and while we've

00:03:39,070 --> 00:03:44,049
talked a lot about

00:03:39,930 --> 00:03:45,870
xtp here at networking track if you

00:03:44,049 --> 00:03:48,549
shouldn't forget that the DCPI stack

00:03:45,870 --> 00:03:52,150
tcp/ip stack and the whole socket layer

00:03:48,549 --> 00:03:54,040
is a fundamental thing and it's the

00:03:52,150 --> 00:04:00,070
communication pass for the micro

00:03:54,040 --> 00:04:02,470
services in terms of network policy what

00:04:00,070 --> 00:04:05,799
what is used in communities by default

00:04:02,470 --> 00:04:07,860
is IP tables the good thing is this is

00:04:05,799 --> 00:04:12,370
available on all the kernels of course

00:04:07,860 --> 00:04:15,850
and more or less well understood here's

00:04:12,370 --> 00:04:17,590
a fun quote from one of the earlier quad

00:04:15,850 --> 00:04:22,020
docker maintainer that you heard at some

00:04:17,590 --> 00:04:25,419
conference but the big problem with that

00:04:22,020 --> 00:04:27,820
is that in an in a world where you only

00:04:25,419 --> 00:04:30,620
communicate through api's basically

00:04:27,820 --> 00:04:32,240
Deportes the l3 l4

00:04:30,620 --> 00:04:35,420
more or less become meaningless because

00:04:32,240 --> 00:04:36,950
you either have to open up everything or

00:04:35,420 --> 00:04:39,950
you have to expose everything from that

00:04:36,950 --> 00:04:41,390
particular part or you just don't but

00:04:39,950 --> 00:04:45,530
usually you want to have some more

00:04:41,390 --> 00:04:48,020
fine-grained policy for accessing parts

00:04:45,530 --> 00:04:52,580
of the API so as a consequence of that

00:04:48,020 --> 00:04:55,790
is that there are now several proxies or

00:04:52,580 --> 00:04:57,980
seven proxies that manage the API

00:04:55,790 --> 00:05:01,640
communication and they are typically

00:04:57,980 --> 00:05:04,970
injected as a transparent citecar into

00:05:01,640 --> 00:05:07,580
every part so as you can see from there

00:05:04,970 --> 00:05:12,260
from the picture here you have a service

00:05:07,580 --> 00:05:16,070
inside a kubernetes part and an instance

00:05:12,260 --> 00:05:18,980
of a proxy here it's an invoice proxy as

00:05:16,070 --> 00:05:20,540
one example and if one service wants to

00:05:18,980 --> 00:05:22,970
talk to another they basically have to

00:05:20,540 --> 00:05:25,940
traverse the networking stack six times

00:05:22,970 --> 00:05:29,140
and that that is what is used and

00:05:25,940 --> 00:05:32,170
deployed today so I'm not making it up

00:05:29,140 --> 00:05:34,670
and that is of course a huge cost

00:05:32,170 --> 00:05:36,410
because well your packet first goes to

00:05:34,670 --> 00:05:38,060
the proxy it and turned it a remote

00:05:36,410 --> 00:05:41,480
proxy from the remote part and that

00:05:38,060 --> 00:05:43,490
proxy once again pushes the message to

00:05:41,480 --> 00:05:45,670
the actual service you want to talk to

00:05:43,490 --> 00:05:48,500
and of course sometimes where you have

00:05:45,670 --> 00:05:50,690
Colonel page table isolation and read

00:05:48,500 --> 00:05:53,200
pooling mitigations and everything this

00:05:50,690 --> 00:05:53,200
is quite bad

00:05:54,100 --> 00:06:00,170
those title proxies such as envoi they

00:05:57,950 --> 00:06:02,270
also provide additional features on top

00:06:00,170 --> 00:06:05,210
of that for example health checks

00:06:02,270 --> 00:06:07,600
service discovery load balancing or a

00:06:05,210 --> 00:06:09,740
mutual TLS which is quite nice because

00:06:07,600 --> 00:06:11,210
and I think that's one reason why

00:06:09,740 --> 00:06:12,740
they're also so popular because you

00:06:11,210 --> 00:06:15,070
don't have to change your application

00:06:12,740 --> 00:06:18,380
you get this feature automatically

00:06:15,070 --> 00:06:21,110
because all the traffic goes through

00:06:18,380 --> 00:06:22,490
that particular proxy so for example you

00:06:21,110 --> 00:06:25,010
don't have to care about encryption they

00:06:22,490 --> 00:06:30,740
just proxy to proxy communicates over

00:06:25,010 --> 00:06:35,390
TLS but we think that it makes of course

00:06:30,740 --> 00:06:38,660
sense to speed up that fast path and for

00:06:35,390 --> 00:06:42,160
example to augment it with PPF support

00:06:38,660 --> 00:06:44,120
in terms of policy enforcement

00:06:42,160 --> 00:06:46,280
introspection redirections we don't

00:06:44,120 --> 00:06:49,970
have to traverse networking stack six

00:06:46,280 --> 00:06:53,660
times but only actually two times and

00:06:49,970 --> 00:06:58,370
and how are we doing that so one option

00:06:53,660 --> 00:07:02,870
is to have PPF at the socket layer so

00:06:58,370 --> 00:07:05,449
basically you have a special BPF map

00:07:02,870 --> 00:07:08,030
which is called sock map and then an

00:07:05,449 --> 00:07:10,190
orchestration daemon can can use that

00:07:08,030 --> 00:07:13,220
and can put a socket into that map and

00:07:10,190 --> 00:07:16,760
basically then the socket callbacks are

00:07:13,220 --> 00:07:19,220
replaced and a so-called p sock is

00:07:16,760 --> 00:07:22,699
attached on top of that which holds

00:07:19,220 --> 00:07:26,449
additional metadata that is relevant in

00:07:22,699 --> 00:07:30,039
order to execute BPF at that layer for

00:07:26,449 --> 00:07:33,430
example if you look at the ingress path

00:07:30,039 --> 00:07:35,930
when such a socket is in that mode

00:07:33,430 --> 00:07:39,169
basically the packet goes normally to

00:07:35,930 --> 00:07:43,460
the TCP stack and then it passes through

00:07:39,169 --> 00:07:47,720
a stream parser in the stream car so we

00:07:43,460 --> 00:07:49,789
have two BPF programs one is SPP parse

00:07:47,720 --> 00:07:52,610
another one is actually B verdict they

00:07:49,789 --> 00:07:58,010
were basically inherited from the BPF

00:07:52,610 --> 00:08:03,380
map and the sqp parser is basically

00:07:58,010 --> 00:08:05,570
there so that the PPF program can make a

00:08:03,380 --> 00:08:08,870
decision on how much data has to be

00:08:05,570 --> 00:08:10,729
queued in order to reach a verdict and

00:08:08,870 --> 00:08:12,530
then the second program the verdict is

00:08:10,729 --> 00:08:16,580
there to actual actually make that

00:08:12,530 --> 00:08:18,860
action action can be a drop or pass

00:08:16,580 --> 00:08:28,370
action and once it pass it's basically

00:08:18,860 --> 00:08:31,340
put into a backlog worker into a backlog

00:08:28,370 --> 00:08:37,599
worker so you have that's basically one

00:08:31,340 --> 00:08:43,330
of the cues from the thank you from the

00:08:37,599 --> 00:08:43,330
is it off all right

00:08:44,680 --> 00:08:49,500
so that's basically put into a ingress

00:08:46,960 --> 00:08:53,790
skb Q which is attached on the P sock

00:08:49,500 --> 00:08:56,470
and that worker will then internally

00:08:53,790 --> 00:08:58,990
convert that into a so called sock

00:08:56,470 --> 00:09:03,820
message what it exactly is we will hear

00:08:58,990 --> 00:09:07,780
later we will hear later on and once the

00:09:03,820 --> 00:09:09,970
application calls the receive message

00:09:07,780 --> 00:09:15,150
then it will basically get picked up the

00:09:09,970 --> 00:09:17,500
sock message from that ingress queue and

00:09:15,150 --> 00:09:22,120
basically in internally in that sock

00:09:17,500 --> 00:09:24,160
message you have a catalyst ring and we

00:09:22,120 --> 00:09:25,690
have like some start and end pointers

00:09:24,160 --> 00:09:28,750
and then basically copy the data to use

00:09:25,690 --> 00:09:31,980
this base depending on where they are

00:09:28,750 --> 00:09:35,110
located the egress path is quite similar

00:09:31,980 --> 00:09:37,990
whenever an application does a sent

00:09:35,110 --> 00:09:41,380
message sent page is more or less

00:09:37,990 --> 00:09:44,440
similar to that either you have already

00:09:41,380 --> 00:09:46,210
a short message that is corked on that

00:09:44,440 --> 00:09:53,080
particular piece Ock or you create a new

00:09:46,210 --> 00:09:54,820
one you would zero copy those pages when

00:09:53,080 --> 00:09:56,560
when whenever possible or if not then

00:09:54,820 --> 00:09:59,560
you have to allocate some buffer from

00:09:56,560 --> 00:10:02,440
the socket in order to later on mem copy

00:09:59,560 --> 00:10:07,030
that data over and then in the end you

00:10:02,440 --> 00:10:09,970
call the you call a BPF verdict program

00:10:07,030 --> 00:10:12,490
which will then decide that either the

00:10:09,970 --> 00:10:13,210
packet is dropped or it's passed on

00:10:12,490 --> 00:10:15,430
words

00:10:13,210 --> 00:10:17,110
- for transmission to the TCP stack or

00:10:15,430 --> 00:10:19,660
it will decide okay I don't have enough

00:10:17,110 --> 00:10:22,390
data I have to work that short message

00:10:19,660 --> 00:10:24,970
so for the next sent message call maybe

00:10:22,390 --> 00:10:27,070
then I can enforce a policy and then the

00:10:24,970 --> 00:10:31,300
PPF program for that is called MSG

00:10:27,070 --> 00:10:36,700
parser it's also inherited from the sock

00:10:31,300 --> 00:10:39,880
map and yeah and now we make a switch to

00:10:36,700 --> 00:10:42,990
KT LS and UOP and later on go and how

00:10:39,880 --> 00:10:45,250
these two connect to each other

00:10:42,990 --> 00:10:48,070
basically

00:10:45,250 --> 00:10:51,310
kernel TLS how it operates it basically

00:10:48,070 --> 00:10:52,930
does the TLS handshake in userspace and

00:10:51,310 --> 00:10:55,780
then the remaining work is transferred

00:10:52,930 --> 00:10:56,960
into the kernel the nice thing is that

00:10:55,780 --> 00:10:59,000
you can have

00:10:56,960 --> 00:11:03,260
copy that you don't need on cent page

00:10:59,000 --> 00:11:05,270
for example a bounce buffer it goes back

00:11:03,260 --> 00:11:07,430
and forth to user space just to do an

00:11:05,270 --> 00:11:10,160
encryption there are a couple of modes

00:11:07,430 --> 00:11:12,280
in kernel TOS I'd software based or

00:11:10,160 --> 00:11:15,290
hardware based when you have the

00:11:12,280 --> 00:11:17,510
software based mode then the encryption

00:11:15,290 --> 00:11:20,240
and decryption goes to the normal kernel

00:11:17,510 --> 00:11:23,210
crypto layer you can have it on RX and

00:11:20,240 --> 00:11:26,480
TX and for the hardware I think there's

00:11:23,210 --> 00:11:30,620
no one ik from Mellanox which does the

00:11:26,480 --> 00:11:33,170
offloading on Rx and TX as well right

00:11:30,620 --> 00:11:37,790
now the most common setup is supported

00:11:33,170 --> 00:11:41,510
which is TLS 1.2 in yes GCM mode and

00:11:37,790 --> 00:11:44,450
128-bit key size and haw

00:11:41,510 --> 00:11:46,670
k TLS operates basically transparent to

00:11:44,450 --> 00:11:50,630
the application in the sense that in SSL

00:11:46,670 --> 00:11:54,380
library such as mrs. L will just do all

00:11:50,630 --> 00:11:58,640
the setup in the background and soon

00:11:54,380 --> 00:12:01,190
since TLS 1.3 finished standardization I

00:11:58,640 --> 00:12:03,740
believe you've also be supported in the

00:12:01,190 --> 00:12:06,230
kernel as well as other key sizes larger

00:12:03,740 --> 00:12:08,410
than 28 bits so that is a work in

00:12:06,230 --> 00:12:08,410
progress

00:12:08,740 --> 00:12:15,790
basically the upper layer protocol like

00:12:11,990 --> 00:12:19,700
how this is glued on to a socket

00:12:15,790 --> 00:12:22,100
provides such a selector so that it's

00:12:19,700 --> 00:12:24,620
basically a very thin layer where you

00:12:22,100 --> 00:12:28,880
can have a module that registers to the

00:12:24,620 --> 00:12:32,630
ULP and then replace this a couple of

00:12:28,880 --> 00:12:35,120
callbacks in in the case for K TLS the

00:12:32,630 --> 00:12:37,580
way you would set it up can be seen here

00:12:35,120 --> 00:12:40,100
so first you register for your socket

00:12:37,580 --> 00:12:42,830
that you want to use k TLS with it and

00:12:40,100 --> 00:12:44,780
then you have some control data

00:12:42,830 --> 00:12:47,630
structure which is filled out by

00:12:44,780 --> 00:12:50,720
libraries such as open ssl once the

00:12:47,630 --> 00:12:54,560
handshake completed where you can define

00:12:50,720 --> 00:12:56,750
the TLS version the key size the actual

00:12:54,560 --> 00:13:00,110
key and various other information then

00:12:56,750 --> 00:13:05,290
you can enable it on transmission or

00:13:00,110 --> 00:13:08,690
receive or in both at the same time so

00:13:05,290 --> 00:13:10,910
before our work got merged basically

00:13:08,690 --> 00:13:14,090
both the kts but

00:13:10,910 --> 00:13:17,630
also the PPF which was operating in the

00:13:14,090 --> 00:13:19,820
socket layer we're both using ULP which

00:13:17,630 --> 00:13:21,620
was a problem because you can only pick

00:13:19,820 --> 00:13:25,220
one of those two but you cannot use

00:13:21,620 --> 00:13:27,920
those two in combination so we are

00:13:25,220 --> 00:13:29,690
thinking whether stacking would make

00:13:27,920 --> 00:13:31,880
sense but on the other hand you have

00:13:29,690 --> 00:13:33,560
even more layers of indirection and more

00:13:31,880 --> 00:13:36,710
complexity if you want to make it really

00:13:33,560 --> 00:13:40,550
generic so it wasn't an optimal path so

00:13:36,710 --> 00:13:44,060
we basically decided to refactor and

00:13:40,550 --> 00:13:47,390
tear the old PPF sofmap code apart

00:13:44,060 --> 00:13:51,380
basically into three things so one is a

00:13:47,390 --> 00:13:55,400
generic SK message API in order to

00:13:51,380 --> 00:13:58,640
manage the data disk at a gathering that

00:13:55,400 --> 00:14:02,270
you get from user space or push to user

00:13:58,640 --> 00:14:05,150
space and another one was the P sock

00:14:02,270 --> 00:14:08,690
framework itself where TCP is one

00:14:05,150 --> 00:14:11,720
implementation of it it works of course

00:14:08,690 --> 00:14:14,390
on top of SK messages and the other one

00:14:11,720 --> 00:14:18,260
which can be completely isolated is the

00:14:14,390 --> 00:14:20,240
actual PPF map so right right now we

00:14:18,260 --> 00:14:23,750
have an aryan hash map for that where

00:14:20,240 --> 00:14:25,910
sockets are attached to you so basically

00:14:23,750 --> 00:14:27,710
the idea is that the SK message and the

00:14:25,910 --> 00:14:31,550
P sub framework works across

00:14:27,710 --> 00:14:37,520
ULP it's not an individual u P it works

00:14:31,550 --> 00:14:40,430
across in the whole layer and before the

00:14:37,520 --> 00:14:44,450
sock message the old sock message code

00:14:40,430 --> 00:14:47,090
was using ULP the european layer it was

00:14:44,450 --> 00:14:49,700
basically using it in a little bit of a

00:14:47,090 --> 00:14:51,680
hacker's way that it's only in kernel so

00:14:49,700 --> 00:14:53,480
it's you could not select it from user

00:14:51,680 --> 00:14:56,720
space but only from inside the kernel

00:14:53,480 --> 00:15:00,770
and right now it's like keeping the LP

00:14:56,720 --> 00:15:04,900
layer as it was originally intended to

00:15:00,770 --> 00:15:09,050
and with that we have basically have

00:15:04,900 --> 00:15:13,430
with that were refactoring we could also

00:15:09,050 --> 00:15:15,800
put the SK message handling into KT LS

00:15:13,430 --> 00:15:19,850
which was not using it before and so now

00:15:15,800 --> 00:15:22,130
both operate on the same context which

00:15:19,850 --> 00:15:23,820
is really good for PPF because you can

00:15:22,130 --> 00:15:27,090
unable to you

00:15:23,820 --> 00:15:29,850
there it also helped to remove a bunch

00:15:27,090 --> 00:15:32,250
of open chord code and dig indicate us

00:15:29,850 --> 00:15:35,220
lair for transmission because the

00:15:32,250 --> 00:15:39,320
plaintext in the encryption handling was

00:15:35,220 --> 00:15:41,340
also working on s Sheila's basically and

00:15:39,320 --> 00:15:47,250
how it operates

00:15:41,340 --> 00:15:51,090
will Tran will continue on that okay

00:15:47,250 --> 00:15:53,400
working alright great okay so thanks

00:15:51,090 --> 00:15:57,360
Daniel all that talk about how the Katie

00:15:53,400 --> 00:15:59,820
Ellis works with EPF so this is sort of

00:15:57,360 --> 00:16:02,100
a flow through the transmit side and you

00:15:59,820 --> 00:16:04,080
can see at the top is we hook into the

00:16:02,100 --> 00:16:05,580
syn message call which is the TLS

00:16:04,080 --> 00:16:09,720
software send message so this is how the

00:16:05,580 --> 00:16:10,950
the actual you LPS plug into the into

00:16:09,720 --> 00:16:12,930
the socket layer so every time you do a

00:16:10,950 --> 00:16:15,090
send message from your user space

00:16:12,930 --> 00:16:16,770
application you'll then now call the TLS

00:16:15,090 --> 00:16:20,340
software send message hook and not the

00:16:16,770 --> 00:16:21,960
generic tcp hook we show the same

00:16:20,340 --> 00:16:23,400
messages kiss here and it's very similar

00:16:21,960 --> 00:16:25,280
but we also do the same page hook so if

00:16:23,400 --> 00:16:27,840
you call send file well we have the same

00:16:25,280 --> 00:16:29,820
introspection with one detail that i'll

00:16:27,840 --> 00:16:31,080
get to in just a second so what what the

00:16:29,820 --> 00:16:34,500
first thing that the TLS will do is

00:16:31,080 --> 00:16:36,150
it'll build a record of the TLS they're

00:16:34,500 --> 00:16:39,620
just going to keep the context and the

00:16:36,150 --> 00:16:41,790
reason it has to have a sort of a

00:16:39,620 --> 00:16:43,500
context that it keeps is because of this

00:16:41,790 --> 00:16:46,980
encryption layer so it's going to

00:16:43,500 --> 00:16:48,840
encrypt it and then it might keep it

00:16:46,980 --> 00:16:51,420
across system pulse and i'll explain why

00:16:48,840 --> 00:16:53,250
that is possible but we need to have

00:16:51,420 --> 00:16:55,290
something that stays even after the

00:16:53,250 --> 00:16:57,420
system call returns and we'll talk about

00:16:55,290 --> 00:17:00,750
that in a second the next thing it'll do

00:16:57,420 --> 00:17:01,830
is it'll allocate a encrypted message

00:17:00,750 --> 00:17:04,860
and so this is just where it's gonna

00:17:01,830 --> 00:17:06,839
encrypt the plaintext into the encrypted

00:17:04,860 --> 00:17:09,990
text so you get a block of memory for

00:17:06,839 --> 00:17:11,220
that and then the next couple points are

00:17:09,990 --> 00:17:13,290
sort of interesting there's third block

00:17:11,220 --> 00:17:16,140
here that sk message 0 copy from it ur

00:17:13,290 --> 00:17:17,400
so because we already have a block of

00:17:16,140 --> 00:17:19,170
memory in kernel that we're going to

00:17:17,400 --> 00:17:20,790
copy the plaintext into when we do the

00:17:19,170 --> 00:17:23,100
encryption or as we're doing the

00:17:20,790 --> 00:17:25,560
encryption we don't need to do a copy

00:17:23,100 --> 00:17:27,270
right away from user space into the

00:17:25,560 --> 00:17:28,740
kernel into the kernel into the

00:17:27,270 --> 00:17:30,480
encrypted block and have two copies

00:17:28,740 --> 00:17:33,180
there so the TLS layer tries to do a

00:17:30,480 --> 00:17:34,860
zero copy so we just fill out the sk

00:17:33,180 --> 00:17:36,810
message which is the standardized

00:17:34,860 --> 00:17:39,180
structure that we built across the EP

00:17:36,810 --> 00:17:41,760
so opcode and the K TLS code so now we

00:17:39,180 --> 00:17:43,770
have this common layer but if that can't

00:17:41,760 --> 00:17:45,360
be done for some reason and this tends

00:17:43,770 --> 00:17:48,660
to be because the there's not enough

00:17:45,360 --> 00:17:50,370
room in in the scatter gather list that

00:17:48,660 --> 00:17:52,650
we're building or there's a couple other

00:17:50,370 --> 00:17:54,900
air cases that this happens so then you

00:17:52,650 --> 00:17:57,530
may need to actually do this copy which

00:17:54,900 --> 00:18:00,630
is the SK message mem copy from it or

00:17:57,530 --> 00:18:02,250
two blocks down and this will actually

00:18:00,630 --> 00:18:03,810
copy it from user space and if you hit

00:18:02,250 --> 00:18:05,100
this case you actually do two copies in

00:18:03,810 --> 00:18:06,990
this path you'll do a copy from user

00:18:05,100 --> 00:18:09,600
space to kernel kernel to the encrypted

00:18:06,990 --> 00:18:10,830
block we really try to avoid this at all

00:18:09,600 --> 00:18:12,390
costs but this is sort of the you know

00:18:10,830 --> 00:18:13,380
edge cases in ear cases when you're

00:18:12,390 --> 00:18:17,520
under memory pressure you'll actually

00:18:13,380 --> 00:18:20,880
will hit this and there's also one case

00:18:17,520 --> 00:18:22,590
that we can fire this off from from the

00:18:20,880 --> 00:18:26,640
BPS site as well I'll talk about that

00:18:22,590 --> 00:18:28,140
just second so once you have this SK

00:18:26,640 --> 00:18:30,300
message structure which I'll give you

00:18:28,140 --> 00:18:32,160
the sort of deep deep details of it in

00:18:30,300 --> 00:18:34,350
the next slide but basically you have a

00:18:32,160 --> 00:18:35,910
scatter gather list of memory that came

00:18:34,350 --> 00:18:37,440
from user so the user will say here's a

00:18:35,910 --> 00:18:38,550
list of blocks just like the eye effect

00:18:37,440 --> 00:18:40,890
that you pass down through the send

00:18:38,550 --> 00:18:43,890
message call or in that if it's a sin

00:18:40,890 --> 00:18:47,220
page call or sin file you'll have the

00:18:43,890 --> 00:18:49,470
page and they they offset in the length

00:18:47,220 --> 00:18:52,140
which will just be kind of represented

00:18:49,470 --> 00:18:53,790
in this sky regather list as well so

00:18:52,140 --> 00:18:56,640
once that goes in that goes into this

00:18:53,790 --> 00:18:59,040
skp sock message verdict block and

00:18:56,640 --> 00:19:00,750
what's really nice about this work that

00:18:59,040 --> 00:19:02,970
don't know what I did at this point is

00:19:00,750 --> 00:19:05,040
that this block is sort of the same

00:19:02,970 --> 00:19:07,440
whether or not the SK message came from

00:19:05,040 --> 00:19:09,330
K TLS or it came from the just normal

00:19:07,440 --> 00:19:10,800
sin message so we've sort of unified all

00:19:09,330 --> 00:19:12,090
this kind of pieces and as daniel noted

00:19:10,800 --> 00:19:13,230
we tore apart into three pieces and we

00:19:12,090 --> 00:19:14,940
can just kind of call directly into this

00:19:13,230 --> 00:19:17,400
because kick Els now uses this sort of

00:19:14,940 --> 00:19:18,840
standardized format so if you happen to

00:19:17,400 --> 00:19:20,520
be writing new ul B's and you use the

00:19:18,840 --> 00:19:22,110
same format you can get all these same

00:19:20,520 --> 00:19:23,670
benefits all the helper calls are

00:19:22,110 --> 00:19:26,220
available to you and you can also plumb

00:19:23,670 --> 00:19:29,220
into BPF straight using the helper calls

00:19:26,220 --> 00:19:30,900
that we have so interestingly if the

00:19:29,220 --> 00:19:32,910
socket is a VPS socket it's been

00:19:30,900 --> 00:19:34,590
attached to a sock map and the map would

00:19:32,910 --> 00:19:36,120
self will have IPPF program attached to

00:19:34,590 --> 00:19:38,790
it and this BPI program here is the

00:19:36,120 --> 00:19:40,470
message parser that program will be run

00:19:38,790 --> 00:19:44,400
and that program can have a set of

00:19:40,470 --> 00:19:45,630
verdicts drop or pass and a leave work

00:19:44,400 --> 00:19:47,790
out for right now and we'll cover that

00:19:45,630 --> 00:19:50,170
in the next couple slides if it's

00:19:47,790 --> 00:19:53,740
dropped we just return to the user

00:19:50,170 --> 00:19:56,910
err code access at the moment there's a

00:19:53,740 --> 00:19:59,860
bit of an interesting case where the and

00:19:56,910 --> 00:20:01,330
you can drops only part of the message

00:19:59,860 --> 00:20:03,430
you may send the first half and then

00:20:01,330 --> 00:20:06,910
drop the next half and the reason we do

00:20:03,430 --> 00:20:09,790
this is because a user may at the API

00:20:06,910 --> 00:20:11,470
level say I have four API calls pack

00:20:09,790 --> 00:20:13,180
them all into one send message call and

00:20:11,470 --> 00:20:15,280
send the whole block down and from a

00:20:13,180 --> 00:20:16,960
policy perspective you know two of those

00:20:15,280 --> 00:20:20,200
may be okay and then the next two may be

00:20:16,960 --> 00:20:23,170
bad and so when this happens the verdict

00:20:20,200 --> 00:20:24,850
can say two of these first two are good

00:20:23,170 --> 00:20:26,830
the third one is bad I'm throwing an

00:20:24,850 --> 00:20:29,560
error on the third one and what happens

00:20:26,830 --> 00:20:32,680
then is we will send the first two out

00:20:29,560 --> 00:20:34,270
and we will return the correct return

00:20:32,680 --> 00:20:36,640
value to the user indicating that we

00:20:34,270 --> 00:20:39,100
sent you know five of the ten bytes and

00:20:36,640 --> 00:20:40,630
then the user can try to resend and then

00:20:39,100 --> 00:20:41,980
at that point we'll give any access

00:20:40,630 --> 00:20:44,350
because there'll be no more valid data

00:20:41,980 --> 00:20:45,970
to send on our side and and this this

00:20:44,350 --> 00:20:47,440
happens actually quite frequently most

00:20:45,970 --> 00:20:49,960
applications are trying to pack as much

00:20:47,440 --> 00:20:52,150
as they can into a send message call at

00:20:49,960 --> 00:20:55,390
a time to get multiple API calls going

00:20:52,150 --> 00:20:57,430
it you know in at once if we do a pass

00:20:55,390 --> 00:20:58,840
at that point you know the policy leader

00:20:57,430 --> 00:21:01,090
has said this is good this is a good

00:20:58,840 --> 00:21:03,250
packet to send a good message to send

00:21:01,090 --> 00:21:04,630
and we'll push it down to the crypto

00:21:03,250 --> 00:21:06,100
layer and this is sort of the unique

00:21:04,630 --> 00:21:07,660
part about Katie Ellis with VP F is that

00:21:06,100 --> 00:21:11,080
we have this crypto layer underneath if

00:21:07,660 --> 00:21:12,850
this was a just the soft map BPF normal

00:21:11,080 --> 00:21:15,160
send message without Katie LS this would

00:21:12,850 --> 00:21:20,110
then send to send message the normal TCP

00:21:15,160 --> 00:21:23,800
stack at that point okay so this is the

00:21:20,110 --> 00:21:25,570
sort of the guts of how this works this

00:21:23,800 --> 00:21:29,110
is our kind of common structure we have

00:21:25,570 --> 00:21:30,550
two pieces of it we have the SK MSS

00:21:29,110 --> 00:21:32,830
scatter gather this which is the list of

00:21:30,550 --> 00:21:34,750
all the data and then we have the

00:21:32,830 --> 00:21:37,180
higher-level structure with it which is

00:21:34,750 --> 00:21:38,620
the SK message inside the scouter gather

00:21:37,180 --> 00:21:40,750
list we have sort of what you would

00:21:38,620 --> 00:21:43,600
expect from a ring of scatter gather

00:21:40,750 --> 00:21:45,130
elements we have the ring which itself

00:21:43,600 --> 00:21:47,380
which is the struck scatter list here

00:21:45,130 --> 00:21:50,440
and we have a math.max message frags at

00:21:47,380 --> 00:21:52,300
this point we have a start and end in a

00:21:50,440 --> 00:21:53,320
current so the current is sort of

00:21:52,300 --> 00:21:55,870
interesting because it's keeping track

00:21:53,320 --> 00:21:59,680
of how far you've processed in the

00:21:55,870 --> 00:22:02,080
message and the reason that this is

00:21:59,680 --> 00:22:02,750
there is because of the quark behavior

00:22:02,080 --> 00:22:06,740
and

00:22:02,750 --> 00:22:07,970
get to that next slide we have a size so

00:22:06,740 --> 00:22:09,380
that we keep track of the overall size

00:22:07,970 --> 00:22:10,760
and this is just mostly from memory

00:22:09,380 --> 00:22:13,040
accounting so we know how much to free

00:22:10,760 --> 00:22:16,390
how much debt how much memory allocated

00:22:13,040 --> 00:22:20,780
through the process and then we have a a

00:22:16,390 --> 00:22:22,310
copy a copy pool here boolean this is

00:22:20,780 --> 00:22:25,070
interesting because in the zero copy

00:22:22,310 --> 00:22:26,540
case coming either from sin page or

00:22:25,070 --> 00:22:28,760
because we've optimized the send message

00:22:26,540 --> 00:22:30,500
and we're running on the policy we need

00:22:28,760 --> 00:22:32,300
to ensure that the users we don't have a

00:22:30,500 --> 00:22:34,130
race with the user if you're running

00:22:32,300 --> 00:22:35,870
policy and as long as it'll copy page

00:22:34,130 --> 00:22:38,000
there's nothing to stop the user from

00:22:35,870 --> 00:22:40,400
modifying the message as you're doing

00:22:38,000 --> 00:22:41,840
the policy and so from a strict policy

00:22:40,400 --> 00:22:44,120
point of view you have a race here where

00:22:41,840 --> 00:22:46,610
you might you be in the person who wrote

00:22:44,120 --> 00:22:48,650
the BPF program might agree that this

00:22:46,610 --> 00:22:50,300
message is a valid message to send but

00:22:48,650 --> 00:22:52,460
it's still an owned by the application

00:22:50,300 --> 00:22:54,710
and at that point the application can

00:22:52,460 --> 00:22:57,470
change data and get it back after it's

00:22:54,710 --> 00:22:59,510
gone through the policy so if your

00:22:57,470 --> 00:23:03,650
policy will touch certain bytes or read

00:22:59,510 --> 00:23:05,570
certain bytes in the in the message we

00:23:03,650 --> 00:23:07,580
have a helper call that will then pull

00:23:05,570 --> 00:23:10,280
the data in and copy it and this is

00:23:07,580 --> 00:23:12,350
works quite well compared to the sort of

00:23:10,280 --> 00:23:14,690
the very initial version one of this I

00:23:12,350 --> 00:23:16,370
just copied all of the data in right and

00:23:14,690 --> 00:23:18,440
this is this is a huge performance it

00:23:16,370 --> 00:23:20,660
because we're tucking all of the

00:23:18,440 --> 00:23:22,490
messages copying them twice versus now

00:23:20,660 --> 00:23:24,770
we just copy the very specific sections

00:23:22,490 --> 00:23:27,410
that you need to read or write to so if

00:23:24,770 --> 00:23:28,880
you have a header on a 4k message you

00:23:27,410 --> 00:23:31,550
can copy the header in read the header

00:23:28,880 --> 00:23:33,080
say the next 4k is good and it'll all go

00:23:31,550 --> 00:23:37,120
through without ever doing this double

00:23:33,080 --> 00:23:39,470
copy buffer so that's that's quite nice

00:23:37,120 --> 00:23:42,980
down here in the actual structure we

00:23:39,470 --> 00:23:46,100
have these two interesting links called

00:23:42,980 --> 00:23:49,130
apply bytes and quark bytes and the

00:23:46,100 --> 00:23:51,110
reason we need these is for two reasons

00:23:49,130 --> 00:23:53,660
the first case apply bytes is perhaps

00:23:51,110 --> 00:23:54,950
the easier to understand we go back to

00:23:53,660 --> 00:23:56,480
the header case so you have a header

00:23:54,950 --> 00:23:58,760
with a 4k message you actually don't

00:23:56,480 --> 00:24:01,130
care how many cin meshes calls that 4k

00:23:58,760 --> 00:24:02,540
header takes so if you have a message

00:24:01,130 --> 00:24:04,580
that has a header a whole bunch of data

00:24:02,540 --> 00:24:06,650
you may not want to ever have BPF

00:24:04,580 --> 00:24:09,200
touched the payload just the headers and

00:24:06,650 --> 00:24:11,150
so we have this apply bytes for the BPF

00:24:09,200 --> 00:24:12,350
program can specify how many bytes to

00:24:11,150 --> 00:24:14,120
send through the system without ever

00:24:12,350 --> 00:24:16,070
calling the BPF verdict machine again

00:24:14,120 --> 00:24:19,550
and in this way we can kind

00:24:16,070 --> 00:24:21,830
do a fishing large transfers without

00:24:19,550 --> 00:24:24,380
having to continuously call BPM it also

00:24:21,830 --> 00:24:25,820
stops sort of some bad application

00:24:24,380 --> 00:24:27,590
behavior where maybe they send one byte

00:24:25,820 --> 00:24:29,240
at a time like in the worst no

00:24:27,590 --> 00:24:31,190
application would ever should ever do

00:24:29,240 --> 00:24:32,810
this probably but you know we have to

00:24:31,190 --> 00:24:34,070
handle this at the API level and we

00:24:32,810 --> 00:24:36,140
don't want a user to be able to force

00:24:34,070 --> 00:24:37,790
the BPF execution on every byte of a

00:24:36,140 --> 00:24:41,410
packet because it just it's quite it's

00:24:37,790 --> 00:24:44,060
kind of expensive in terms of system

00:24:41,410 --> 00:24:46,940
clerk bytes is almost the opposite case

00:24:44,060 --> 00:24:48,470
so this sort of user might not send the

00:24:46,940 --> 00:24:50,570
entire header that you need to read in

00:24:48,470 --> 00:24:53,660
the pack and that's for initial send

00:24:50,570 --> 00:24:56,840
message so if if the application and we

00:24:53,660 --> 00:24:59,630
actually see this in practice where it's

00:24:56,840 --> 00:25:01,580
like a proxy that's collecting a bunch

00:24:59,630 --> 00:25:03,230
of API calls and it might do one big

00:25:01,580 --> 00:25:05,780
send message when it reaches it's sort

00:25:03,230 --> 00:25:07,850
of whatever its limited of kind of

00:25:05,780 --> 00:25:11,270
buffer spaces it'll send it out and you

00:25:07,850 --> 00:25:12,680
might have half a header which you can't

00:25:11,270 --> 00:25:13,910
make a policy decision on but you don't

00:25:12,680 --> 00:25:15,230
want to pass it along because you don't

00:25:13,910 --> 00:25:17,330
know it's good yet from your policy

00:25:15,230 --> 00:25:22,040
perspective so what we do is we have an

00:25:17,330 --> 00:25:24,650
API BPF helper that says please um do

00:25:22,040 --> 00:25:26,690
not do not forward this data until I

00:25:24,650 --> 00:25:28,130
received the next in bytes and in this

00:25:26,690 --> 00:25:29,870
way you can say I have a 10 by Ted or I

00:25:28,130 --> 00:25:32,060
only have 5 bytes of it please give me

00:25:29,870 --> 00:25:33,470
the next 5 bytes I'm not going to send

00:25:32,060 --> 00:25:36,130
any of this data until I see the entire

00:25:33,470 --> 00:25:37,910
header and okay the based on the policy

00:25:36,130 --> 00:25:41,120
and so those are the kind of the main

00:25:37,910 --> 00:25:42,620
things there we also allow redirects

00:25:41,120 --> 00:25:45,920
from there and this kind of comes from

00:25:42,620 --> 00:25:50,510
the CLS layer a similar idea where at

00:25:45,920 --> 00:25:51,980
the GC CLS layer which is the the skb

00:25:50,510 --> 00:25:53,390
kind of implementation of this not the

00:25:51,980 --> 00:25:55,610
stock map we have the ability to

00:25:53,390 --> 00:25:57,080
redirect to other interfaces at the

00:25:55,610 --> 00:25:58,850
socket lever layer we wanted a very

00:25:57,080 --> 00:26:01,760
similar thing where we could redirect to

00:25:58,850 --> 00:26:03,230
other sockets and so that we have a

00:26:01,760 --> 00:26:04,490
helper call this as okay redirect yeah

00:26:03,230 --> 00:26:05,960
there's all keys and then we stash all

00:26:04,490 --> 00:26:07,430
this stuff in the these kind of struck

00:26:05,960 --> 00:26:09,800
socks at the bottom of the SKA message

00:26:07,430 --> 00:26:11,060
here so that when we pass it down we can

00:26:09,800 --> 00:26:12,800
find the right sock that we want to

00:26:11,060 --> 00:26:14,060
redirect to and put it in the received

00:26:12,800 --> 00:26:18,080
queue where the transmit queue of that

00:26:14,060 --> 00:26:20,540
Salkin this is how we sort accelerate

00:26:18,080 --> 00:26:23,850
this three passes or six passes through

00:26:20,540 --> 00:26:27,630
the TCP stack through down to one or two

00:26:23,850 --> 00:26:30,360
all right so here's the list of the

00:26:27,630 --> 00:26:31,620
helpers this is this user-facing size so

00:26:30,360 --> 00:26:33,270
if you're writing BPF programs these are

00:26:31,620 --> 00:26:34,410
the helpers that you have used these

00:26:33,270 --> 00:26:36,030
will then be translated into that

00:26:34,410 --> 00:26:37,950
structure in the right light places so

00:26:36,030 --> 00:26:39,900
as we talked about we have a BPF message

00:26:37,950 --> 00:26:41,669
apply bytes this is how like we said we

00:26:39,900 --> 00:26:44,309
can say we want in bytes before we make

00:26:41,669 --> 00:26:46,590
them without making any BPF verdict on

00:26:44,309 --> 00:26:47,789
it we just already have okayed it we

00:26:46,590 --> 00:26:49,919
have this quark bytes which will allow

00:26:47,789 --> 00:26:53,700
you to as we say get more data before

00:26:49,919 --> 00:26:55,830
you get called back into the BPF program

00:26:53,700 --> 00:26:58,230
we have a redirect

00:26:55,830 --> 00:26:59,850
map very similar to how we did the XD

00:26:58,230 --> 00:27:02,909
PDF reader to redirect map which I think

00:26:59,850 --> 00:27:04,440
we talked about yesterday basically you

00:27:02,909 --> 00:27:06,030
have a map full of sockets you do a

00:27:04,440 --> 00:27:07,860
redirect you give it an index or a hash

00:27:06,030 --> 00:27:10,260
into that map it'll look up whatever

00:27:07,860 --> 00:27:12,510
socket happens to be in that slot and

00:27:10,260 --> 00:27:14,340
it'll do a redirect either to the TX or

00:27:12,510 --> 00:27:17,370
the either the egress or the ingress

00:27:14,340 --> 00:27:19,110
based on the flags provided so it's it's

00:27:17,370 --> 00:27:21,600
very very similar to the api's that we

00:27:19,110 --> 00:27:24,450
already have in XP layer TC layer and

00:27:21,600 --> 00:27:28,440
now in the socket layer so pull and push

00:27:24,450 --> 00:27:30,780
data is as interesting the pull data is

00:27:28,440 --> 00:27:32,190
for the 0 copy case so if you want to

00:27:30,780 --> 00:27:34,110
read or write data and you want to and

00:27:32,190 --> 00:27:36,590
you need to ensure that it's actually

00:27:34,110 --> 00:27:40,860
copied you can do a pull data on bytes a

00:27:36,590 --> 00:27:43,169
through B it can be sort of it doesn't

00:27:40,860 --> 00:27:45,150
have to be from the head onward it can

00:27:43,169 --> 00:27:47,429
be in the middle so you could do 4 by 4

00:27:45,150 --> 00:27:51,809
through 6 for example and it'll pull

00:27:47,429 --> 00:27:54,870
just those 2 bytes in in that case if

00:27:51,809 --> 00:27:57,210
the data is already been copied the API

00:27:54,870 --> 00:27:59,130
is smart enough not to recopy it so it's

00:27:57,210 --> 00:28:00,240
like it doesn't it tries to be

00:27:59,130 --> 00:28:02,100
intelligent so if you're writing your

00:28:00,240 --> 00:28:03,120
program for sort of ease of use and you

00:28:02,100 --> 00:28:04,260
know you're always gonna copy this you

00:28:03,120 --> 00:28:06,210
don't have to check to see if it's copy

00:28:04,260 --> 00:28:07,559
just make this call it'll jump out to

00:28:06,210 --> 00:28:08,909
the helper the helper will then say oh

00:28:07,559 --> 00:28:10,610
that data's already there I don't need

00:28:08,909 --> 00:28:13,080
to do anything and give you back control

00:28:10,610 --> 00:28:14,730
push data is an interesting one so this

00:28:13,080 --> 00:28:16,110
is I think we talked about this going

00:28:14,730 --> 00:28:18,390
the other way again from the XDP side

00:28:16,110 --> 00:28:19,740
what you want to be able to push stuff

00:28:18,390 --> 00:28:21,270
into the metadata header so that you can

00:28:19,740 --> 00:28:22,770
read it in further up the stack this is

00:28:21,270 --> 00:28:24,270
similar but going the other way so now

00:28:22,770 --> 00:28:26,429
instead of coming from the wire we're

00:28:24,270 --> 00:28:28,049
coming from the application you may want

00:28:26,429 --> 00:28:31,080
to push some metadata that you're going

00:28:28,049 --> 00:28:33,090
to read later in the stack so you have a

00:28:31,080 --> 00:28:35,810
push data which lets you put some

00:28:33,090 --> 00:28:38,570
arbitrary number of bytes in the

00:28:35,810 --> 00:28:42,320
the message at some location interesting

00:28:38,570 --> 00:28:44,360
slight interesting case here which is

00:28:42,320 --> 00:28:46,850
different from XD P so XD p always has

00:28:44,360 --> 00:28:48,620
the data at the head here we can insert

00:28:46,850 --> 00:28:50,240
data sort of arbitrarily in the packet

00:28:48,620 --> 00:28:52,400
because we have a scatter gather list

00:28:50,240 --> 00:28:54,770
it's pretty easy to tear it apart and

00:28:52,400 --> 00:28:56,570
insert data in the middle this lets you

00:28:54,770 --> 00:28:58,430
do sort interesting things like maybe

00:28:56,570 --> 00:29:00,470
you want to add an option into the

00:28:58,430 --> 00:29:02,060
header or a flag or field or something

00:29:00,470 --> 00:29:03,500
so a lot of headers will have optional

00:29:02,060 --> 00:29:06,830
fields you could stick something in

00:29:03,500 --> 00:29:08,810
there if you wanted to and then we have

00:29:06,830 --> 00:29:11,780
all of the normal BPF base helpers as

00:29:08,810 --> 00:29:14,660
well so these are all should say all the

00:29:11,780 --> 00:29:16,490
ones that apply to this not the skp ones

00:29:14,660 --> 00:29:21,770
obviously because we have no skb and not

00:29:16,490 --> 00:29:23,600
the XDP ones could be xdp here so that's

00:29:21,770 --> 00:29:25,160
fun that's all the low-level details so

00:29:23,600 --> 00:29:28,160
the question now is how does this all

00:29:25,160 --> 00:29:29,870
work Daniel and I both work on a project

00:29:28,160 --> 00:29:33,890
called psyllium and I'll talked about it

00:29:29,870 --> 00:29:36,050
kind of earlier the behind so what this

00:29:33,890 --> 00:29:37,340
will do then is it provides a kind of

00:29:36,050 --> 00:29:40,160
high level integration with the

00:29:37,340 --> 00:29:43,010
orchestration layer and under the covers

00:29:40,160 --> 00:29:44,930
will use all of the BPF layers and what

00:29:43,010 --> 00:29:46,370
sort of really interesting about this I

00:29:44,930 --> 00:29:48,530
think in my opinion is that we're using

00:29:46,370 --> 00:29:50,480
basically all of the DPF hooks on the

00:29:48,530 --> 00:29:51,650
networking side all the way from xdp

00:29:50,480 --> 00:29:54,230
which will get you your low level

00:29:51,650 --> 00:29:56,420
networking up to the socket layer now so

00:29:54,230 --> 00:29:58,280
we have elf you know basically l2 at the

00:29:56,420 --> 00:29:59,600
bottom we have the TC hooks and now we

00:29:58,280 --> 00:30:02,840
have the socket layer hooks so we can

00:29:59,600 --> 00:30:04,940
get very you know insert insert our

00:30:02,840 --> 00:30:08,630
policy either at the socket side or at

00:30:04,940 --> 00:30:12,590
the NIC side or at the interface side as

00:30:08,630 --> 00:30:15,380
well and now we have this additional

00:30:12,590 --> 00:30:17,990
piece where with Kay TLS running we can

00:30:15,380 --> 00:30:21,620
run our policy then do the crypto and

00:30:17,990 --> 00:30:25,310
have a full kind of que TLS encryption

00:30:21,620 --> 00:30:28,520
with policy which is I think interesting

00:30:25,310 --> 00:30:30,020
to note because it hasn't been it hasn't

00:30:28,520 --> 00:30:32,240
been possible and tell this before if

00:30:30,020 --> 00:30:34,430
something was encrypted to us in user

00:30:32,240 --> 00:30:37,570
space there's no way to do policy at the

00:30:34,430 --> 00:30:37,570
microservice API level

00:30:38,149 --> 00:30:43,309
so we although still have a bunch of

00:30:41,460 --> 00:30:45,510
work to do

00:30:43,309 --> 00:30:47,159
we've managed to get this first point

00:30:45,510 --> 00:30:50,070
here what we can now do enforcement with

00:30:47,159 --> 00:30:53,100
TLS we have a bunch of things on our

00:30:50,070 --> 00:30:55,769
list to do we'll have a github page with

00:30:53,100 --> 00:31:00,240
lots of issues and things to fictive

00:30:55,769 --> 00:31:02,159
features mostly at this point some

00:31:00,240 --> 00:31:03,809
helpers would be useful some things like

00:31:02,159 --> 00:31:05,789
being able to figure out what C group

00:31:03,809 --> 00:31:07,799
the salk it belongs to without walking

00:31:05,789 --> 00:31:09,840
prague structures and things to figure

00:31:07,799 --> 00:31:12,750
this out would be really great there's

00:31:09,840 --> 00:31:14,880
actually exist in other BPF folks just

00:31:12,750 --> 00:31:18,659
not in you know we haven't added them to

00:31:14,880 --> 00:31:20,820
map yet mister the string parser which

00:31:18,659 --> 00:31:24,149
is the ingress site of this piece is

00:31:20,820 --> 00:31:26,159
currently needs some optimization it's a

00:31:24,149 --> 00:31:27,120
little bit slower than the TX ID so we

00:31:26,159 --> 00:31:30,120
spent a fair amount of time optimizing

00:31:27,120 --> 00:31:32,190
the egress path because a lot of our

00:31:30,120 --> 00:31:34,190
policies are built on egress but we also

00:31:32,190 --> 00:31:38,039
have policies on ingress as well and

00:31:34,190 --> 00:31:39,409
they're sort of not optimized yet so

00:31:38,039 --> 00:31:42,870
there's some work to do there

00:31:39,409 --> 00:31:45,389
as Daniel noted that Katie Ellis right

00:31:42,870 --> 00:31:47,519
now works with this one specific set of

00:31:45,389 --> 00:31:48,960
keys fortunately this is kind of a very

00:31:47,519 --> 00:31:54,059
this is a very common one

00:31:48,960 --> 00:31:58,110
most of the sort of exposed api's that

00:31:54,059 --> 00:32:00,809
I've tested Twitter and some of the u.s.

00:31:58,110 --> 00:32:03,149
stuff and some of the Facebook API seem

00:32:00,809 --> 00:32:06,029
to all negotiate to this version so

00:32:03,149 --> 00:32:07,500
that's okay but you know that we still

00:32:06,029 --> 00:32:12,389
have room to get the rest of the keys

00:32:07,500 --> 00:32:16,380
and TLS 1.3 so on interestingly the open

00:32:12,389 --> 00:32:18,179
SSL PR is out now and I've hopefully

00:32:16,380 --> 00:32:20,429
winding up we're getting close I think

00:32:18,179 --> 00:32:21,570
to having it all resolved there's a few

00:32:20,429 --> 00:32:23,549
more comments that need to be there but

00:32:21,570 --> 00:32:26,279
once that's in it'll be a part of the

00:32:23,549 --> 00:32:29,519
standard open SSL live to use the key

00:32:26,279 --> 00:32:34,070
TLS support and the other piece to note

00:32:29,519 --> 00:32:36,659
is as we'll talk about tomorrow at the

00:32:34,070 --> 00:32:39,450
at the mica conference yeah the PPF

00:32:36,659 --> 00:32:41,549
micro comments thanks is bounded loops

00:32:39,450 --> 00:32:44,070
so we've gone through some effort to

00:32:41,549 --> 00:32:46,019
avoid loops in cilium as well and also

00:32:44,070 --> 00:32:48,380
more specifically in the saw in the sock

00:32:46,019 --> 00:32:50,700
them out kind of

00:32:48,380 --> 00:32:52,230
and we make do and we're able to get

00:32:50,700 --> 00:32:54,090
around it but it would be really nice if

00:32:52,230 --> 00:32:56,190
we could kind of make more complex

00:32:54,090 --> 00:32:57,330
programs and if you look at the cilium

00:32:56,190 --> 00:32:59,250
code you'll see some of these cases

00:32:57,330 --> 00:33:00,809
where we have macros that try to ensure

00:32:59,250 --> 00:33:03,870
that we don't optimize him to loop some

00:33:00,809 --> 00:33:07,170
things in the code and be nice to just

00:33:03,870 --> 00:33:10,679
clean all that up and get in and kind of

00:33:07,170 --> 00:33:20,100
have a support for loops oops all right

00:33:10,679 --> 00:33:21,660
great thank you guys so basically the

00:33:20,100 --> 00:33:23,130
whole point is that you get to see the

00:33:21,660 --> 00:33:25,380
clear text and then you call into the

00:33:23,130 --> 00:33:26,970
TLS UOP to do all its whatever it does

00:33:25,380 --> 00:33:28,140
and its operating understand key message

00:33:26,970 --> 00:33:29,640
structures that you're using to pass

00:33:28,140 --> 00:33:31,230
into the BPI program so that's

00:33:29,640 --> 00:33:33,750
completely integrated with the same

00:33:31,230 --> 00:33:36,299
infrastructure yeah that's great cool

00:33:33,750 --> 00:33:38,309
any questions out there it's a pretty

00:33:36,299 --> 00:33:40,500
interesting piece of technology in

00:33:38,309 --> 00:33:42,360
talking integrating many different

00:33:40,500 --> 00:33:44,340
diverse areas of the networking stack

00:33:42,360 --> 00:33:46,890
from the actual stack itself to decay

00:33:44,340 --> 00:33:51,570
TLS layer to our friend vpf which we

00:33:46,890 --> 00:33:53,610
don't talk about enough so someone's got

00:33:51,570 --> 00:33:55,620
to be curious about the implications or

00:33:53,610 --> 00:33:59,970
whatever moving forward what we can do

00:33:55,620 --> 00:34:01,549
with this you're just so blown away that

00:33:59,970 --> 00:34:11,790
you can't come up with anything to ask

00:34:01,549 --> 00:34:13,080
okay so uh any ideas about how this

00:34:11,790 --> 00:34:14,580
stuff integrates with any kind of

00:34:13,080 --> 00:34:16,320
hardware offload support lookaside

00:34:14,580 --> 00:34:18,389
support in the kernel lookaside api's

00:34:16,320 --> 00:34:21,300
there's already off loaders they can do

00:34:18,389 --> 00:34:23,330
this the encryption for you is it better

00:34:21,300 --> 00:34:27,510
just to do it on a CPU what do you think

00:34:23,330 --> 00:34:28,800
um there's there's maybe like the raw

00:34:27,510 --> 00:34:30,540
performance question about what is it

00:34:28,800 --> 00:34:32,460
like is the CPU faster than the hardware

00:34:30,540 --> 00:34:34,889
offload in moving the data around but

00:34:32,460 --> 00:34:39,060
from our perspective we're doing a lot

00:34:34,889 --> 00:34:40,639
of policy enforcement written in BPF so

00:34:39,060 --> 00:34:43,560
the question would be how does the

00:34:40,639 --> 00:34:45,359
hardware know how to do the policy you

00:34:43,560 --> 00:34:48,210
that's written in BPF before the

00:34:45,359 --> 00:34:51,419
encryption but to clarify what you push

00:34:48,210 --> 00:34:53,669
it to the KT last GOP it would do the

00:34:51,419 --> 00:34:56,700
offloading stuff that that came to us

00:34:53,669 --> 00:34:59,490
there would do already so I guess if we

00:34:56,700 --> 00:34:59,830
if it's okay to do the policy first and

00:34:59,490 --> 00:35:01,570
then

00:34:59,830 --> 00:35:04,330
we push it to the the TLS record down

00:35:01,570 --> 00:35:06,460
and we do offloading at that point yes

00:35:04,330 --> 00:35:08,080
it's sort of hello awesome good I mean

00:35:06,460 --> 00:35:10,900
for the transmission that would write

00:35:08,080 --> 00:35:12,430
for the ingress I'd probably not yeah

00:35:10,900 --> 00:35:15,490
receive the problems you need to see the

00:35:12,430 --> 00:35:20,260
plaintext and that you the card is

00:35:15,490 --> 00:35:21,820
before the horse so to speak so yeah we

00:35:20,260 --> 00:35:24,040
have my yes we haven't tried it

00:35:21,820 --> 00:35:25,330
maybe I'm TX it just works though if we

00:35:24,040 --> 00:35:27,040
had a really interesting piece of

00:35:25,330 --> 00:35:29,350
hardware that could run the policy

00:35:27,040 --> 00:35:37,990
enforcement and then do the keyless and

00:35:29,350 --> 00:35:44,800
yeah that would be cool mind blown any

00:35:37,990 --> 00:35:46,960
other questions well this might be a

00:35:44,800 --> 00:35:49,660
very basic question that everyone else

00:35:46,960 --> 00:35:55,000
understands I see that the like this six

00:35:49,660 --> 00:35:58,180
stack path is kind of crazy there's

00:35:55,000 --> 00:36:00,610
there's basically data that goes out the

00:35:58,180 --> 00:36:02,770
machine host to another host and there's

00:36:00,610 --> 00:36:06,940
data that basically stays within the

00:36:02,770 --> 00:36:08,530
host I see with KT LS and this is the

00:36:06,940 --> 00:36:10,810
part that I just don't fully understand

00:36:08,530 --> 00:36:11,950
yet are you doing all the policy

00:36:10,810 --> 00:36:13,990
enforcement that you would normally do

00:36:11,950 --> 00:36:16,800
an envoy in the kernel and send it out

00:36:13,990 --> 00:36:20,530
right away so it's one transmission and

00:36:16,800 --> 00:36:25,330
or are you forwarding between Sokka says

00:36:20,530 --> 00:36:26,740
nope TCP friends which was like a long

00:36:25,330 --> 00:36:29,590
time ago a proposal to basically

00:36:26,740 --> 00:36:30,790
short-circuit to a stack but still

00:36:29,590 --> 00:36:34,030
deliver it locally and do all the

00:36:30,790 --> 00:36:36,730
enforcement in user space right so so

00:36:34,030 --> 00:36:39,460
the implementation in cilium leverages

00:36:36,730 --> 00:36:40,900
envoy so they work it works every oh if

00:36:39,460 --> 00:36:42,460
we have a layer seven policy like an

00:36:40,900 --> 00:36:46,950
HTTP policy that's throwing through

00:36:42,460 --> 00:36:51,180
envoy we will then do the socket

00:36:46,950 --> 00:36:51,180
redirect directly to the Envoy proxy

00:36:51,430 --> 00:36:55,460
and then the encryption happens from

00:36:53,720 --> 00:36:56,930
that point onwards and then the

00:36:55,460 --> 00:37:03,200
encryption happens in a point envoy on

00:36:56,930 --> 00:37:05,300
Marzia so so that piece is already in

00:37:03,200 --> 00:37:09,530
cilium and the cilium itself doesn't do

00:37:05,300 --> 00:37:11,600
any sort of HTTP parsing for example

00:37:09,530 --> 00:37:13,010
which would be done by envoy so the idea

00:37:11,600 --> 00:37:15,680
would be the accelerate envoy and not

00:37:13,010 --> 00:37:16,880
try to somehow do what it's doing the

00:37:15,680 --> 00:37:18,950
other trouble is one rate is a lot more

00:37:16,880 --> 00:37:20,960
than just parsing it'll do routing and

00:37:18,950 --> 00:37:22,970
keep alive in these kinds of things that

00:37:20,960 --> 00:37:26,330
we saw so that's what circuit is the

00:37:22,970 --> 00:37:28,970
decay TLS part from an envoy out on the

00:37:26,330 --> 00:37:31,430
network and is the socket forwarding

00:37:28,970 --> 00:37:33,230
between the surface and an envoy which

00:37:31,430 --> 00:37:35,020
is intercepting traffic that the service

00:37:33,230 --> 00:37:37,220
is not aware it's being intercepted

00:37:35,020 --> 00:37:38,570
right so there's two ways to do it with

00:37:37,220 --> 00:37:41,180
Katie Ellis one is via the Katie Ellis

00:37:38,570 --> 00:37:43,700
does it on the Envoy envoy to network

00:37:41,180 --> 00:37:46,370
side mm-hmm right and then the other one

00:37:43,700 --> 00:37:46,910
would be to do it from the service side

00:37:46,370 --> 00:37:48,380
as well

00:37:46,910 --> 00:37:49,850
and in that case we have to take the

00:37:48,380 --> 00:37:52,880
packet back from envoy and put it back

00:37:49,850 --> 00:37:55,870
in the TLS I take it back to be

00:37:52,880 --> 00:37:55,870
encrypted and it's okay

00:37:57,940 --> 00:38:09,249
Thanks maybe a whiteboard would help try

00:38:00,410 --> 00:38:11,059
to drive here oh there's a yeah so I

00:38:09,249 --> 00:38:29,690
said that and there's a white boy

00:38:11,059 --> 00:38:31,039
climbing all right yeah so the I guess

00:38:29,690 --> 00:38:32,390
the main point is that the song if the

00:38:31,039 --> 00:38:33,859
if you do a send message from a service

00:38:32,390 --> 00:38:35,599
and you have Katie Ellis on it'll go to

00:38:33,859 --> 00:38:37,640
the policy if the policy needs to

00:38:35,599 --> 00:38:39,650
redirect to a proxy it can do that and

00:38:37,640 --> 00:38:41,890
then when the proxy sends it we can send

00:38:39,650 --> 00:38:44,779
it back to do 2k TLS on that's okay

00:38:41,890 --> 00:38:47,180
and then this way we get the users the

00:38:44,779 --> 00:38:49,759
policy and envoy and we do this end with

00:38:47,180 --> 00:38:52,880
Katie Ellis so sort of transparent at

00:38:49,759 --> 00:38:54,589
that point we avoid the in the other way

00:38:52,880 --> 00:38:56,059
to do it which could be done today is

00:38:54,589 --> 00:38:58,160
you can encrypt it from the service then

00:38:56,059 --> 00:39:00,170
decrypt it on envoy and then re encrypt

00:38:58,160 --> 00:39:01,789
it and this is even worse than using you

00:39:00,170 --> 00:39:05,470
know six TCP stacks because now you

00:39:01,789 --> 00:39:05,470
encrypt or decrypt it encrypted

00:39:13,690 --> 00:39:24,180
all right thanks let's see so the

00:39:20,920 --> 00:39:26,980
question is can you do something like

00:39:24,180 --> 00:39:30,280
transparent encryption was this like

00:39:26,980 --> 00:39:33,280
when the application was not using gel

00:39:30,280 --> 00:39:38,260
as before but was this redirect to

00:39:33,280 --> 00:39:40,660
direct into socket that doing K TLS yes

00:39:38,260 --> 00:39:44,380
so you wait one way to think of that

00:39:40,660 --> 00:39:46,119
would be if every node has a TLS to

00:39:44,380 --> 00:39:49,299
every other node so you have like a TLS

00:39:46,119 --> 00:39:50,799
mesh basically we can take the service

00:39:49,299 --> 00:39:52,900
will send packets normally unencrypted

00:39:50,799 --> 00:39:55,089
and we can do a redirect to that once we

00:39:52,900 --> 00:39:57,460
know where it descendant we can say put

00:39:55,089 --> 00:39:59,319
it on the which you'll know because we

00:39:57,460 --> 00:40:00,630
have the whole sock destruct there we

00:39:59,319 --> 00:40:03,280
can put it on the right

00:40:00,630 --> 00:40:05,980
egress socket that has TLS to the

00:40:03,280 --> 00:40:09,450
wherever notice in Unit two and do sort

00:40:05,980 --> 00:40:15,190
of a full kind of transparent key TLS

00:40:09,450 --> 00:40:18,839
mesh I think the other thing I've made

00:40:15,190 --> 00:40:21,400
also be interesting is to have internal

00:40:18,839 --> 00:40:24,670
TLS termination or something like that

00:40:21,400 --> 00:40:30,359
for example from from XDP potentially or

00:40:24,670 --> 00:40:30,359
you know I might also look into that

00:40:32,090 --> 00:40:41,769
anyone else thank you very much guys

00:40:36,750 --> 00:40:41,769

YouTube URL: https://www.youtube.com/watch?v=NnibidVRtWY


