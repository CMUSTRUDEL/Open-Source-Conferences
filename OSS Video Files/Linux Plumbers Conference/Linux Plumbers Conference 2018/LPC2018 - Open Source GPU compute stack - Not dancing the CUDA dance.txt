Title: LPC2018 - Open Source GPU compute stack - Not dancing the CUDA dance
Publication date: 2018-11-28
Playlist: Linux Plumbers Conference 2018
Description: 
	url:  https://linuxplumbersconf.org/event/2/contributions/63/
speaker:  David Airlie (RedHat)

Using graphics cards for compute acceleration has been a major shift in technology lately, especially around AI/ML and HPC.

Until now the clear market leader has been the CUDA stack from NVIDIA, which is a closed source solution that runs on Linux. Open source applications like tensorflow (AI/ML) rely on this closed stack to utilise GPUs for acceleration.

Vendor aligned stacks such as AMD's ROCm and Intel's OpenCL NEO are emerging that try to fill the gap for their specific hardware platforms. These stacks are very large, and don't share much if any code. There are also efforts inside groups like Khronos with their OpenCL, SPIR-V and SYCL standards being made to produce something that can work as a useful standardised alternative.

This talk will discuss the possibility of creating a vendor neutral reference compute stack based around open source technologies and open source development models that could execute compute tasks across multiple vendor GPUs. Using SYCL/OpenCL/Vulkan and the open-source Mesa stack, as the basis for a future task that development of tools and features on top of as part of a desktop OS.

This talk doesn't have all the answers, but it wants to get people considering what we can produce in the area.
Captions: 
	00:00:05,540 --> 00:00:13,190
hi good morning my name is David Ellie I

00:00:10,070 --> 00:00:14,769
work at Red Hat the kernel maintainer

00:00:13,190 --> 00:00:20,060
for a long time

00:00:14,769 --> 00:00:22,250
graphics and I recently started becoming

00:00:20,060 --> 00:00:25,310
more involved in compute and that side

00:00:22,250 --> 00:00:29,570
of the world so my talk today is pretty

00:00:25,310 --> 00:00:32,230
much what's the status of GPU compute

00:00:29,570 --> 00:00:36,559
everyone like knows what a coup de but

00:00:32,230 --> 00:00:38,540
we're open source people I am I looking

00:00:36,559 --> 00:00:40,040
at CUDA is like okay I'm not touching it

00:00:38,540 --> 00:00:41,890
cuz it's not open source I don't care

00:00:40,040 --> 00:00:44,510
what a how great or brilliant it is but

00:00:41,890 --> 00:00:47,030
where where's the alternate why haven't

00:00:44,510 --> 00:00:48,500
we got an open source thing for this

00:00:47,030 --> 00:00:50,840
already everyone loves CUDA

00:00:48,500 --> 00:00:53,510
but that loads but everyone has no

00:00:50,840 --> 00:00:55,100
choice but to love CUDA why have we not

00:00:53,510 --> 00:00:56,960
managed to do this what's what's going

00:00:55,100 --> 00:01:00,980
wrong yeah so I'm just going to give you

00:00:56,960 --> 00:01:03,770
a quick sort of introduction over new

00:01:00,980 --> 00:01:05,329
cases what what what computes for what

00:01:03,770 --> 00:01:08,360
ap eyes are out there what are the

00:01:05,329 --> 00:01:10,220
components in a GPU compute stack what

00:01:08,360 --> 00:01:12,650
stacks are supporting these and how are

00:01:10,220 --> 00:01:15,200
they developed and packaged and possible

00:01:12,650 --> 00:01:17,630
futures there this is a very hand wavy

00:01:15,200 --> 00:01:19,220
vague possible futures talk I have have

00:01:17,630 --> 00:01:21,770
to say up front I have not really done

00:01:19,220 --> 00:01:24,650
anything on this red hats not this is

00:01:21,770 --> 00:01:27,610
not a red hat committed strategy this is

00:01:24,650 --> 00:01:30,979
not a red hat you know this is just me

00:01:27,610 --> 00:01:32,330
drawing ideas out there and trying to

00:01:30,979 --> 00:01:34,490
see if anything will stick I'm seeing if

00:01:32,330 --> 00:01:37,400
there's any sort of I suppose trying to

00:01:34,490 --> 00:01:39,200
find some upstream people to you know

00:01:37,400 --> 00:01:40,580
try and move this stuff along and figure

00:01:39,200 --> 00:01:41,780
out a better way of doing it rather than

00:01:40,580 --> 00:01:45,350
just saying well right that's gonna

00:01:41,780 --> 00:01:46,640
solve this or so I'm just the basics are

00:01:45,350 --> 00:01:49,340
the use cases that people come up with

00:01:46,640 --> 00:01:50,750
compute for sort of a IML area so

00:01:49,340 --> 00:01:52,670
machine learning is pretty big

00:01:50,750 --> 00:01:55,040
ai is pretty big tensorflow seems to be

00:01:52,670 --> 00:01:57,020
the common thing that everyone started

00:01:55,040 --> 00:01:59,810
uses that's then based on a stack of

00:01:57,020 --> 00:02:04,250
other stuff so you go build tensor flow

00:01:59,810 --> 00:02:07,250
and then tree dies later you've oh it's

00:02:04,250 --> 00:02:09,649
built Augen it's built uses blasts it's

00:02:07,250 --> 00:02:11,390
using with NVIDIA got the Cu DN n

00:02:09,649 --> 00:02:13,189
libraries there's just all a lot of

00:02:11,390 --> 00:02:17,239
stuff that you need to do to get this

00:02:13,189 --> 00:02:19,340
system in place HPC is another big area

00:02:17,239 --> 00:02:22,190
HPC is a lot more custom application

00:02:19,340 --> 00:02:24,170
for built on the stack but you don't

00:02:22,190 --> 00:02:25,459
have these sort of you still use the

00:02:24,170 --> 00:02:27,470
common libraries that blasting stuff

00:02:25,459 --> 00:02:29,330
will be used like linear algebra stuff

00:02:27,470 --> 00:02:30,920
and but there's not as much of a common

00:02:29,330 --> 00:02:34,069
application as tensorflow tential is

00:02:30,920 --> 00:02:35,840
quite you know it's a focal point and

00:02:34,069 --> 00:02:37,849
then scientific applications again using

00:02:35,840 --> 00:02:39,260
similar sort of stuff but it's yeah

00:02:37,849 --> 00:02:40,970
there's a good few use cases as all

00:02:39,260 --> 00:02:42,530
stuff out there people want to do this

00:02:40,970 --> 00:02:44,360
stuff and they want to do it on GPUs

00:02:42,530 --> 00:02:46,010
because GPUs do it so much faster than

00:02:44,360 --> 00:02:51,530
CPUs

00:02:46,010 --> 00:02:54,500
so first up api's so CUDA is the leader

00:02:51,530 --> 00:02:57,049
it's the it's Nvidia defined there's not

00:02:54,500 --> 00:02:58,340
there's no specification process as far

00:02:57,049 --> 00:03:00,799
as I know it's Nvidia come out with a

00:02:58,340 --> 00:03:06,440
new API this is what you get it's

00:03:00,799 --> 00:03:09,860
unfortunately closed source it's the way

00:03:06,440 --> 00:03:12,500
you use CUDA is pretty much called a C++

00:03:09,860 --> 00:03:14,810
based resort options but C++ based but

00:03:12,500 --> 00:03:17,870
it's single source and this is a big

00:03:14,810 --> 00:03:20,780
differentiator between how you write

00:03:17,870 --> 00:03:24,440
using these API is you have a choice of

00:03:20,780 --> 00:03:25,820
single source or I suppose non single

00:03:24,440 --> 00:03:29,690
but single source pretty much beat Brian

00:03:25,820 --> 00:03:31,459
you write code in C++ and you sort of

00:03:29,690 --> 00:03:33,109
describe a chunk of that code and that

00:03:31,459 --> 00:03:35,840
sudden that code will end up running on

00:03:33,109 --> 00:03:38,420
your GPU whereas non single source is

00:03:35,840 --> 00:03:39,950
you write a code chunk of code for the

00:03:38,420 --> 00:03:43,130
host and your rather obvious chunk of

00:03:39,950 --> 00:03:44,630
code to run on the GPU and that's

00:03:43,130 --> 00:03:46,549
compare compiled separately and they're

00:03:44,630 --> 00:03:48,739
all just there's a set of calls but the

00:03:46,549 --> 00:03:50,810
the code the codes well the control flow

00:03:48,739 --> 00:03:53,000
of single source is a lot more obvious

00:03:50,810 --> 00:03:54,920
it's a lot more the programming model

00:03:53,000 --> 00:03:57,829
people want people don't really want the

00:03:54,920 --> 00:03:59,989
other model but there is cases where

00:03:57,829 --> 00:04:01,940
it's it's used but so just but CUDA is

00:03:59,989 --> 00:04:03,709
pretty much based around C++ based

00:04:01,940 --> 00:04:05,209
single source there's a lot of support

00:04:03,709 --> 00:04:07,069
libraries that come and CUDA they've got

00:04:05,209 --> 00:04:08,269
their own last they've got CD and n

00:04:07,069 --> 00:04:09,220
which is a pretty important part of

00:04:08,269 --> 00:04:11,780
tensorflow

00:04:09,220 --> 00:04:14,930
but that's like the industry standard

00:04:11,780 --> 00:04:18,410
api at the moment as I say people love

00:04:14,930 --> 00:04:20,239
it but some don't but what else is hat

00:04:18,410 --> 00:04:22,940
sort of happening out there there's hip

00:04:20,239 --> 00:04:26,060
which is the AMD I can't believe it's

00:04:22,940 --> 00:04:27,979
not CUDA hat genius computing a face

00:04:26,060 --> 00:04:30,430
report ability to name just pretty much

00:04:27,979 --> 00:04:32,390
rolls off the tongue

00:04:30,430 --> 00:04:33,950
it's got

00:04:32,390 --> 00:04:36,970
it has its source code released on

00:04:33,950 --> 00:04:39,410
github I'll get into this a bit later

00:04:36,970 --> 00:04:41,440
it's on earth it's under an open source

00:04:39,410 --> 00:04:45,740
compatible license it's it's fine

00:04:41,440 --> 00:04:47,480
it also c++ based single source again it

00:04:45,740 --> 00:04:51,140
has some support libraries hip plus hip

00:04:47,480 --> 00:04:55,120
tienen it pretty much is sort of a good

00:04:51,140 --> 00:04:58,250
at trying to recreate the cooler style

00:04:55,120 --> 00:05:01,070
we have open CL so open CL is the old

00:04:58,250 --> 00:05:03,730
reliable came from Apple via Kronos it's

00:05:01,070 --> 00:05:05,240
a Cronus standard there's open

00:05:03,730 --> 00:05:08,150
implementation there's closed

00:05:05,240 --> 00:05:10,160
implementations there's the open CL

00:05:08,150 --> 00:05:12,020
standard hard at 1.2 seems to be what

00:05:10,160 --> 00:05:14,060
everyone implemented and then 2.0 was a

00:05:12,020 --> 00:05:15,680
bit more pie-in-the-sky futuristic and

00:05:14,060 --> 00:05:17,950
we didn't have implementations for and

00:05:15,680 --> 00:05:20,360
they're slowly catching up but again

00:05:17,950 --> 00:05:22,460
certain vendors don't want to do a CL

00:05:20,360 --> 00:05:24,740
2.0 annotation or have no motivation

00:05:22,460 --> 00:05:27,110
because they have cuda why would you

00:05:24,740 --> 00:05:30,080
care about doing this so also somebody

00:05:27,110 --> 00:05:31,850
dan added c++ to open CL so open CL

00:05:30,080 --> 00:05:34,610
apart from being just like a standard

00:05:31,850 --> 00:05:38,480
for running things it has its own sort

00:05:34,610 --> 00:05:41,660
of C and C++ implementations that you

00:05:38,480 --> 00:05:43,310
write code for like in separate source

00:05:41,660 --> 00:05:45,260
file so it's not single source you don't

00:05:43,310 --> 00:05:46,610
get the nice control flow it's it's kind

00:05:45,260 --> 00:05:49,040
of messy

00:05:46,610 --> 00:05:52,910
it also offers online and offline

00:05:49,040 --> 00:05:56,270
compilation so you can take that GPU

00:05:52,910 --> 00:05:58,910
code that you've built build up and have

00:05:56,270 --> 00:06:00,950
it built up when you're executing so not

00:05:58,910 --> 00:06:03,290
when you're we are before you do it

00:06:00,950 --> 00:06:04,910
offline you just build while you're

00:06:03,290 --> 00:06:06,800
actually running your app but that means

00:06:04,910 --> 00:06:09,640
you then have to have a full C or C++

00:06:06,800 --> 00:06:12,770
compiler inside your open CL stack which

00:06:09,640 --> 00:06:14,720
gets kind of messy it's yeah it's it has

00:06:12,770 --> 00:06:17,240
some issues in there how the design but

00:06:14,720 --> 00:06:18,410
they're trying to get rid of improve

00:06:17,240 --> 00:06:20,740
that and one of the ways we're trying to

00:06:18,410 --> 00:06:22,790
improve that is spear V which is this

00:06:20,740 --> 00:06:24,890
intermediate representation I'll get to

00:06:22,790 --> 00:06:26,660
later and they can accept these kernels

00:06:24,890 --> 00:06:28,580
so that they don't just have this you

00:06:26,660 --> 00:06:30,170
can have it a source or a binary you can

00:06:28,580 --> 00:06:32,180
have this other representation then use

00:06:30,170 --> 00:06:34,370
that then to build your final binary but

00:06:32,180 --> 00:06:36,890
it's a lot lower level you don't need to

00:06:34,370 --> 00:06:40,460
be having your full C and C++ compiler

00:06:36,890 --> 00:06:42,740
sitting in your stack another sort of

00:06:40,460 --> 00:06:44,240
standard that's being it's just started

00:06:42,740 --> 00:06:45,020
up it's been around for a little while

00:06:44,240 --> 00:06:46,639
but it's not

00:06:45,020 --> 00:06:48,080
got a huge amount of traction yet but

00:06:46,639 --> 00:06:51,710
it's a another Cronus standard called

00:06:48,080 --> 00:06:56,509
cycle cycle attempts to bring the sort

00:06:51,710 --> 00:07:00,620
of single source solution to OpenCL in a

00:06:56,509 --> 00:07:02,690
nicer fashion you again have your single

00:07:00,620 --> 00:07:04,250
source code it can run on your CPU it

00:07:02,690 --> 00:07:06,139
can run your GPU if you want to run on

00:07:04,250 --> 00:07:08,300
the implementation then can decide you

00:07:06,139 --> 00:07:11,479
say open MP to execute this code on your

00:07:08,300 --> 00:07:13,669
CPU or I can use OpenCL to launch the

00:07:11,479 --> 00:07:15,259
same code on your GPU so it's it's sort

00:07:13,669 --> 00:07:17,419
of a layer of bubbled and CL it doesn't

00:07:15,259 --> 00:07:18,710
actually require open CL you could make

00:07:17,419 --> 00:07:20,240
a cycle implementation on top of

00:07:18,710 --> 00:07:22,550
something else so it has that

00:07:20,240 --> 00:07:24,319
flexibility but at the moment

00:07:22,550 --> 00:07:26,780
nearly all cycle implementations are

00:07:24,319 --> 00:07:29,449
using open CL for launching on the

00:07:26,780 --> 00:07:31,430
device there's a closed source

00:07:29,449 --> 00:07:33,560
implementation of cycle from coldplay

00:07:31,430 --> 00:07:35,990
pretty much code play is a compiler

00:07:33,560 --> 00:07:38,180
company and they pretty much drive this

00:07:35,990 --> 00:07:40,250
standard at the moment they're doing a

00:07:38,180 --> 00:07:42,229
lot of the work there is an open source

00:07:40,250 --> 00:07:45,590
implementation on github called tricycle

00:07:42,229 --> 00:07:48,530
which Xilinx a guy who used to work for

00:07:45,590 --> 00:07:49,580
AMD and now works with Xilinx started it

00:07:48,530 --> 00:07:51,259
was sort of being used as an

00:07:49,580 --> 00:07:52,880
experimental ground who's like I want to

00:07:51,259 --> 00:07:53,840
try something new this is easy easy way

00:07:52,880 --> 00:07:56,360
to do it with his open-source

00:07:53,840 --> 00:07:57,530
implementation I've been picking up on

00:07:56,360 --> 00:07:59,719
it for the last few months and just

00:07:57,530 --> 00:08:01,279
hammering it but they have a conformance

00:07:59,719 --> 00:08:03,650
suite internally at Chronos and I've

00:08:01,279 --> 00:08:05,779
been just trying to hammer I'm starting

00:08:03,650 --> 00:08:07,849
combining my ability to learn C++ and

00:08:05,779 --> 00:08:09,349
implement the standard at the same time

00:08:07,849 --> 00:08:12,800
it just seemed like a good way to learn

00:08:09,349 --> 00:08:15,620
because it relies on C++ 17 it relies on

00:08:12,800 --> 00:08:16,699
you know a lot of templating and I'm

00:08:15,620 --> 00:08:18,469
starting to find out all these

00:08:16,699 --> 00:08:21,949
interesting terminology but Stack

00:08:18,469 --> 00:08:25,250
Overflow is really good for learning but

00:08:21,949 --> 00:08:27,380
DC threes so cycle is kind of a the idea

00:08:25,250 --> 00:08:29,360
at least is we have a standardized

00:08:27,380 --> 00:08:30,889
version of that sort of we can do what

00:08:29,360 --> 00:08:32,839
CUDA can do we can do a single source

00:08:30,889 --> 00:08:36,140
implementation for all of these

00:08:32,839 --> 00:08:38,270
applications there are other api's out

00:08:36,140 --> 00:08:41,570
there that I haven't dug too far into

00:08:38,270 --> 00:08:45,130
because it's endless so there's C++ a MP

00:08:41,570 --> 00:08:47,750
from Microsoft which yes sorry to say

00:08:45,130 --> 00:08:49,730
yeah Computers Linux there is no

00:08:47,750 --> 00:08:52,670
computer on Windows really that battle

00:08:49,730 --> 00:08:54,470
is not worth even thinking about Windows

00:08:52,670 --> 00:08:56,270
computers not a feature of the

00:08:54,470 --> 00:08:57,500
marketplace no one wants to deploy a

00:08:56,270 --> 00:08:59,900
workload on Windows

00:08:57,500 --> 00:09:02,080
it's not out there so that's that's a

00:08:59,900 --> 00:09:04,610
dead end as far as I'm concerned

00:09:02,080 --> 00:09:06,860
openmp there's a lot of we could make

00:09:04,610 --> 00:09:10,640
OpenMP better make we can do more GPU

00:09:06,860 --> 00:09:12,890
still open MP again there's a lot hand

00:09:10,640 --> 00:09:16,370
waving in that area about how possible

00:09:12,890 --> 00:09:18,470
to make the API better but it's it's a

00:09:16,370 --> 00:09:21,260
difficult things like you get a lot all

00:09:18,470 --> 00:09:22,580
we could describe the data sets and a

00:09:21,260 --> 00:09:24,650
set of rules and we can make these

00:09:22,580 --> 00:09:27,380
really interesting and that the compiler

00:09:24,650 --> 00:09:28,880
figure it out and ever somebody ever

00:09:27,380 --> 00:09:31,850
says to me will let the compiler figure

00:09:28,880 --> 00:09:34,220
it out I'd get bad flashbacks titanium

00:09:31,850 --> 00:09:36,170
and some of the old very long

00:09:34,220 --> 00:09:37,430
instruction work GPUs where nobody ever

00:09:36,170 --> 00:09:39,890
figured out how to make the compiler

00:09:37,430 --> 00:09:41,690
work it out because sometimes the

00:09:39,890 --> 00:09:43,460
compiler you can you know you can't just

00:09:41,690 --> 00:09:44,900
punt things and say magic compiler you

00:09:43,460 --> 00:09:47,500
figure it all out because magic compiler

00:09:44,900 --> 00:09:50,240
never shows up you're waiting for use

00:09:47,500 --> 00:09:52,880
open ACC's another standard in the same

00:09:50,240 --> 00:09:56,240
area again I haven't done too much into

00:09:52,880 --> 00:09:57,680
it it's been used but it doesn't really

00:09:56,240 --> 00:10:00,500
interest me in terms of what we can do

00:09:57,680 --> 00:10:02,900
here one things are kind of interesting

00:10:00,500 --> 00:10:06,650
is Vulcan the new low-level graphics API

00:10:02,900 --> 00:10:09,200
has a compute interface and what's great

00:10:06,650 --> 00:10:11,630
about is its low-level your submission

00:10:09,200 --> 00:10:12,890
API is not a whole lot of extra features

00:10:11,630 --> 00:10:17,030
you don't need it's just pretty much

00:10:12,890 --> 00:10:21,050
take this kernel code and give it to the

00:10:17,030 --> 00:10:24,410
graphics card currently the Vulcan can't

00:10:21,050 --> 00:10:26,390
support the feature set of OpenCL that's

00:10:24,410 --> 00:10:28,460
where it's it's missing it's there's

00:10:26,390 --> 00:10:30,380
some work and trying to make Vulcan

00:10:28,460 --> 00:10:32,710
computer add more features and but the

00:10:30,380 --> 00:10:35,090
Vulcan standardization guys are very

00:10:32,710 --> 00:10:37,070
strict on what they will accept they're

00:10:35,090 --> 00:10:38,870
very you must have two implementations

00:10:37,070 --> 00:10:40,940
you must have a full test set of tests

00:10:38,870 --> 00:10:42,200
or a test suite we will not give you you

00:10:40,940 --> 00:10:44,720
will not put the extensions in without

00:10:42,200 --> 00:10:46,100
this work and this is good because open

00:10:44,720 --> 00:10:47,240
see how shut it on that because that's

00:10:46,100 --> 00:10:49,190
one of the mistakes I feel open sale

00:10:47,240 --> 00:10:50,480
made was they were like oh yeah we'll

00:10:49,190 --> 00:10:51,860
put that in the standard and it'll

00:10:50,480 --> 00:10:53,600
magically appear in the future whereas

00:10:51,860 --> 00:10:55,270
it should have been we've got two

00:10:53,600 --> 00:10:57,500
implementations we know how it works

00:10:55,270 --> 00:10:59,690
it's here now we'll put it in the

00:10:57,500 --> 00:11:01,220
standard so I feel Vulcan is doing the

00:10:59,690 --> 00:11:02,360
right thing they are not saying no we're

00:11:01,220 --> 00:11:04,100
not just going to throw the kitchen sink

00:11:02,360 --> 00:11:05,660
in here because you asked for it we want

00:11:04,100 --> 00:11:07,340
to wait around and see see it's actually

00:11:05,660 --> 00:11:09,980
useful for people in the real world so

00:11:07,340 --> 00:11:11,180
it may actually develop they're

00:11:09,980 --> 00:11:12,650
currently focused on graphics

00:11:11,180 --> 00:11:14,600
there's a bit of push to try and add

00:11:12,650 --> 00:11:18,200
compute features so we may get that end

00:11:14,600 --> 00:11:19,790
or ending up being the end goal and more

00:11:18,200 --> 00:11:23,210
high-level there's a lot of future API

00:11:19,790 --> 00:11:24,640
work in C++ standardization the C++

00:11:23,210 --> 00:11:26,840
standards body

00:11:24,640 --> 00:11:28,970
everyone says they're contributing to

00:11:26,840 --> 00:11:30,590
the standards body so I can't tell who's

00:11:28,970 --> 00:11:32,210
actually winning you know it's like the

00:11:30,590 --> 00:11:33,500
cycle guys are like we're interesting

00:11:32,210 --> 00:11:35,120
we're contributing our stuff to the

00:11:33,500 --> 00:11:36,950
standards body and cooler people are

00:11:35,120 --> 00:11:38,390
talking to standards body and open ACC

00:11:36,950 --> 00:11:40,130
you know MP and everyone's talking to

00:11:38,390 --> 00:11:42,320
standards body and my feeling with the

00:11:40,130 --> 00:11:43,820
standards body is whoever you talk to

00:11:42,320 --> 00:11:45,590
says their implementations gonna be the

00:11:43,820 --> 00:11:47,780
one that gets accepted but nobody

00:11:45,590 --> 00:11:50,000
actually knows yes and it's future it's

00:11:47,780 --> 00:11:53,000
gonna be C++ 20 or something at this

00:11:50,000 --> 00:11:54,050
point only have these sort of things one

00:11:53,000 --> 00:11:55,720
of the things I've been told about the

00:11:54,050 --> 00:11:58,160
super standards at least they want

00:11:55,720 --> 00:11:59,540
tested implementations so the cycle guys

00:11:58,160 --> 00:12:00,890
were like well we got this cycle

00:11:59,540 --> 00:12:03,620
standard we should be up to getting

00:12:00,890 --> 00:12:04,910
those like we need to implement it can't

00:12:03,620 --> 00:12:06,350
just say it's going to work we need to

00:12:04,910 --> 00:12:08,180
be able to see that what you've done is

00:12:06,350 --> 00:12:10,370
working and even if you have a high

00:12:08,180 --> 00:12:12,170
level C++ standard you still need some

00:12:10,370 --> 00:12:14,450
sort of execution environment underneath

00:12:12,170 --> 00:12:16,460
it to run it it's not like just because

00:12:14,450 --> 00:12:18,050
it's in C++ that's your problem is

00:12:16,460 --> 00:12:20,720
solved the compiler has to have some

00:12:18,050 --> 00:12:22,430
sort of runtimes and all that so I'll

00:12:20,720 --> 00:12:26,110
just give a quick overview of what a

00:12:22,430 --> 00:12:29,480
stack compute stack looks like so

00:12:26,110 --> 00:12:32,210
there's two sort of parts to how at

00:12:29,480 --> 00:12:35,210
least with a non OpenCL sax so we'll see

00:12:32,210 --> 00:12:38,290
what a single source stack there's two

00:12:35,210 --> 00:12:40,760
kind of parts the first is building your

00:12:38,290 --> 00:12:42,560
application so you take your source code

00:12:40,760 --> 00:12:45,590
at the top which is your C++ sort of

00:12:42,560 --> 00:12:46,850
stuff it then has to go into the

00:12:45,590 --> 00:12:49,280
compiler front-end the compiler

00:12:46,850 --> 00:12:54,260
front-end has to then separate what's

00:12:49,280 --> 00:12:57,560
host code and wants device code and then

00:12:54,260 --> 00:12:59,330
it has to side build code on the host

00:12:57,560 --> 00:13:02,810
compiler and build code with the device

00:12:59,330 --> 00:13:04,310
compiler they then have to spit out as

00:13:02,810 --> 00:13:06,740
normal the host compiler will spit out

00:13:04,310 --> 00:13:10,670
native object code but the device

00:13:06,740 --> 00:13:13,670
compiler will spit out something magical

00:13:10,670 --> 00:13:16,880
in that it's not like x86 code but it's

00:13:13,670 --> 00:13:19,070
not it could be GPU assembly or sorry

00:13:16,880 --> 00:13:21,170
GPU binary it could be intermediate

00:13:19,070 --> 00:13:22,700
representation it could be multiple of

00:13:21,170 --> 00:13:24,380
these you can actually you know it could

00:13:22,700 --> 00:13:24,740
go okay I'm gonna give you a generic

00:13:24,380 --> 00:13:26,330
thing

00:13:24,740 --> 00:13:28,580
I'm gonna give you four specific things

00:13:26,330 --> 00:13:30,830
and then that all gets stuck together

00:13:28,580 --> 00:13:32,810
into your elf file just like normal and

00:13:30,830 --> 00:13:35,240
then the elf file is your application

00:13:32,810 --> 00:13:38,000
executable or library or whatever and

00:13:35,240 --> 00:13:40,490
then so here's a picture of that is that

00:13:38,000 --> 00:13:43,399
the CPU object code on the GPU IR code

00:13:40,490 --> 00:13:45,200
stuck all-in-one as it executes you'll

00:13:43,399 --> 00:13:46,640
be able to CPU over oh I need to call

00:13:45,200 --> 00:13:48,529
this function or that's in the GPU thing

00:13:46,640 --> 00:13:51,410
I'll launch that kernel using some sort

00:13:48,529 --> 00:13:52,730
of launch platform and that's the

00:13:51,410 --> 00:13:53,899
execution environment so you need an

00:13:52,730 --> 00:13:56,300
execution environment you want to run

00:13:53,899 --> 00:13:58,070
your application it needs to sit on top

00:13:56,300 --> 00:13:59,839
of a few layers there's some support

00:13:58,070 --> 00:14:01,220
libraries there's a runtime that that's

00:13:59,839 --> 00:14:03,200
that's like I want to actually execute

00:14:01,220 --> 00:14:06,140
this code on the GPU please make it

00:14:03,200 --> 00:14:07,520
happen and so I want a CPU code when it

00:14:06,140 --> 00:14:09,830
reaches a function that it knows needs

00:14:07,520 --> 00:14:12,740
to be run on the GPU will trampoline

00:14:09,830 --> 00:14:15,170
itself sort of answer it kick into

00:14:12,740 --> 00:14:17,630
OpenCL or kick into the CUDA runtime and

00:14:15,170 --> 00:14:18,560
say hey launch this bunch of current

00:14:17,630 --> 00:14:19,940
code and get back to me when you're

00:14:18,560 --> 00:14:23,810
finished with executing it on all this

00:14:19,940 --> 00:14:24,860
data so the support libraries is a bunch

00:14:23,810 --> 00:14:26,810
of things in there depending on your

00:14:24,860 --> 00:14:28,790
application user spaces runtime

00:14:26,810 --> 00:14:30,620
libraries and then on the bottom there's

00:14:28,790 --> 00:14:32,050
some sort of graphics caralyn driver or

00:14:30,620 --> 00:14:35,899
sitting over on top of the hardware

00:14:32,050 --> 00:14:39,050
again so that's that's pretty much the

00:14:35,899 --> 00:14:41,240
generic stack look it's not hand waving

00:14:39,050 --> 00:14:42,459
a few things but it's pretty much the ll

00:14:41,240 --> 00:14:45,560
end up looking something like that

00:14:42,459 --> 00:14:47,690
OpenCL is a bit different because OpenCL

00:14:45,560 --> 00:14:51,200
also allows you to X to build that

00:14:47,690 --> 00:14:52,880
execution plan so when you have OpenCL

00:14:51,200 --> 00:14:54,800
you have to have a follow up in CL

00:14:52,880 --> 00:14:56,270
front-end compiler and then you have to

00:14:54,800 --> 00:14:57,680
have an intermediate compiler because

00:14:56,270 --> 00:14:59,480
you can also accept other things that

00:14:57,680 --> 00:15:01,279
aren't C in C++ you have the Spear be

00:14:59,480 --> 00:15:04,760
stuff not again I'll get into that in a

00:15:01,279 --> 00:15:06,770
second and then you get your GPU code on

00:15:04,760 --> 00:15:07,970
your hardware so yeah so it's slightly

00:15:06,770 --> 00:15:11,930
different but again most of the

00:15:07,970 --> 00:15:13,670
components are in a similar sort of it's

00:15:11,930 --> 00:15:16,160
not a huge difference so I just have a

00:15:13,670 --> 00:15:17,750
quick word on what ir's are because IRAs

00:15:16,160 --> 00:15:20,540
are very important when you talk about

00:15:17,750 --> 00:15:22,870
this stuff so I ours are intermediate

00:15:20,540 --> 00:15:26,149
representations they're a big compiler

00:15:22,870 --> 00:15:28,430
in that area and they're pretty much you

00:15:26,149 --> 00:15:30,740
take your C or C++ you Paris at all and

00:15:28,430 --> 00:15:32,000
then you don't want to come go straight

00:15:30,740 --> 00:15:34,430
to binary you need something that

00:15:32,000 --> 00:15:36,380
represents it in between the fully

00:15:34,430 --> 00:15:37,640
source code state on the fully binary

00:15:36,380 --> 00:15:38,180
state that's called an intermediate

00:15:37,640 --> 00:15:40,400
reference

00:15:38,180 --> 00:15:42,200
tation the common intermediate represent

00:15:40,400 --> 00:15:43,490
there are some two types of intermediate

00:15:42,200 --> 00:15:45,410
stations there's the type of

00:15:43,490 --> 00:15:48,020
intermediate representation you want to

00:15:45,410 --> 00:15:51,260
give to an other part of the stack to

00:15:48,020 --> 00:15:53,000
use and they're usually more sort of

00:15:51,260 --> 00:15:54,290
formalized and try to be standardized

00:15:53,000 --> 00:15:56,480
and then there's a type of intermediate

00:15:54,290 --> 00:15:58,730
representing parlor system we'll use

00:15:56,480 --> 00:16:01,820
internally and those are usually a lot

00:15:58,730 --> 00:16:04,700
more changeable mutable you just you

00:16:01,820 --> 00:16:06,170
need to add things them quickly so in

00:16:04,700 --> 00:16:07,400
terms of intermediate representations

00:16:06,170 --> 00:16:10,460
that you want to give to other people

00:16:07,400 --> 00:16:12,650
you've got the cooler one is Nvidia PTX

00:16:10,460 --> 00:16:16,390
so they've got there is no level PTX

00:16:12,650 --> 00:16:19,400
sort of it's like an assembly level I or

00:16:16,390 --> 00:16:22,250
the AMD stack currently doesn't really

00:16:19,400 --> 00:16:24,590
have an IR at that level it gives ends

00:16:22,250 --> 00:16:26,210
up giving the binary to the other person

00:16:24,590 --> 00:16:28,520
on GCM which is unfortunate it's not a

00:16:26,210 --> 00:16:29,930
it's a bit frustrating but that's yeah

00:16:28,520 --> 00:16:34,070
that's that they've decided they want to

00:16:29,930 --> 00:16:36,320
do Chronos spear fee as well spear Vee

00:16:34,070 --> 00:16:40,370
is an intimate representation defined by

00:16:36,320 --> 00:16:42,920
Chronos for fully open CL on Vulcan but

00:16:40,370 --> 00:16:45,680
when you say the words spear Vee you

00:16:42,920 --> 00:16:48,110
should always qualify a with Colonel or

00:16:45,680 --> 00:16:49,790
shader because okay they look the same

00:16:48,110 --> 00:16:53,690
and they use the same building blocks

00:16:49,790 --> 00:16:55,400
but how they are actually like what the

00:16:53,690 --> 00:16:56,840
code can do is completely different

00:16:55,400 --> 00:16:58,040
depending upon execution environments

00:16:56,840 --> 00:17:00,680
you want to run it in so you have to

00:16:58,040 --> 00:17:03,980
target your spirit V at either an open

00:17:00,680 --> 00:17:07,250
CL or a Vulcan implementation so you it

00:17:03,980 --> 00:17:11,030
is two different IRS hiding in the one

00:17:07,250 --> 00:17:12,740
like standardized format and then also

00:17:11,030 --> 00:17:13,850
internally insert in your compiler

00:17:12,740 --> 00:17:15,080
stacks you've got intermediate

00:17:13,850 --> 00:17:16,610
representations and the two don't sort

00:17:15,080 --> 00:17:21,620
of matter for the purposes of this talk

00:17:16,610 --> 00:17:22,280
is Mesa which is the Linux opens OpenGL

00:17:21,620 --> 00:17:24,520
and

00:17:22,280 --> 00:17:28,730
Vulcan stack has a thing called near and

00:17:24,520 --> 00:17:32,540
it it's but what it uses for most of its

00:17:28,730 --> 00:17:35,350
GPU code and then LVM has the LLVM ir

00:17:32,540 --> 00:17:37,730
which is a purely internal thing to LLVM

00:17:35,350 --> 00:17:39,230
people have tried to standardize that

00:17:37,730 --> 00:17:41,120
there was an effort but Kronos thing

00:17:39,230 --> 00:17:43,700
called spear which was a precursor to

00:17:41,120 --> 00:17:44,930
spear V and that just sort of took LLVM

00:17:43,700 --> 00:17:47,660
ire and then some went this thing's

00:17:44,930 --> 00:17:49,910
really unstable we can't just go making

00:17:47,660 --> 00:17:52,000
the standard just copy what they do so

00:17:49,910 --> 00:17:54,340
that's that's actually why spear

00:17:52,000 --> 00:17:55,510
came about and became a lot you know

00:17:54,340 --> 00:17:56,950
it's a it's a lot more thought about

00:17:55,510 --> 00:18:02,350
they've actually sort of think well we

00:17:56,950 --> 00:18:04,270
have to keep this thing stable and just

00:18:02,350 --> 00:18:06,160
quit but OpenCL stacks there's lots of

00:18:04,270 --> 00:18:09,010
them out there is a very vendor-specific

00:18:06,160 --> 00:18:11,380
AMD has more has to I think I think

00:18:09,010 --> 00:18:13,300
everyone's got to people have have

00:18:11,380 --> 00:18:15,790
traders and videos OpenCL people are and

00:18:13,300 --> 00:18:18,670
we heard in Tolliver's neo open CL stack

00:18:15,790 --> 00:18:20,590
that's come out recently these are all

00:18:18,670 --> 00:18:22,510
some of our open source similar close

00:18:20,590 --> 00:18:25,330
source but a lot of them have forked

00:18:22,510 --> 00:18:27,040
LLVM for si Lang's they've got pieces of

00:18:25,330 --> 00:18:28,330
code you know they're not up streaming

00:18:27,040 --> 00:18:32,010
those sort of things they're just like

00:18:28,330 --> 00:18:32,010
big chunks of new Ceylon code that's

00:18:32,040 --> 00:18:36,760
there they're difficult to work with to

00:18:35,200 --> 00:18:38,230
deploy those sort of things you have to

00:18:36,760 --> 00:18:40,900
pick which one you want to deploy and

00:18:38,230 --> 00:18:42,700
you have to spend your time making that

00:18:40,900 --> 00:18:44,200
being the one thing on your system but I

00:18:42,700 --> 00:18:46,030
just wanted to give it a list at this

00:18:44,200 --> 00:18:48,910
point because I'll see why in a minute

00:18:46,030 --> 00:18:50,710
so what did the vendor stack sort of

00:18:48,910 --> 00:18:53,080
look like so from kouddous point of view

00:18:50,710 --> 00:18:55,290
the same picture had earlier but just

00:18:53,080 --> 00:18:57,520
filled in with more of a cool specific

00:18:55,290 --> 00:18:59,500
tangent to it is that yeah so you got

00:18:57,520 --> 00:19:01,240
your C++ CUDA at the application source

00:18:59,500 --> 00:19:03,460
you got your cout the compiler front-end

00:19:01,240 --> 00:19:05,830
I'm sure John tell me this is perfectly

00:19:03,460 --> 00:19:08,650
not right but it's a hand wavy graph

00:19:05,830 --> 00:19:10,120
picture it splits it does host

00:19:08,650 --> 00:19:12,190
compilation into native object code it

00:19:10,120 --> 00:19:13,900
does device compilation it spits out PTX

00:19:12,190 --> 00:19:16,420
it may also spit out other things

00:19:13,900 --> 00:19:18,790
alongside that but at the base level it

00:19:16,420 --> 00:19:20,350
will spit out this IR and they will put

00:19:18,790 --> 00:19:23,730
that into the object file so your object

00:19:20,350 --> 00:19:27,160
file will end up having PTX code and

00:19:23,730 --> 00:19:29,260
object code and then in the execution

00:19:27,160 --> 00:19:31,780
environment your application will run

00:19:29,260 --> 00:19:36,640
the cooler runtime will take the PTX

00:19:31,780 --> 00:19:38,800
code and create the low-level assembly

00:19:36,640 --> 00:19:40,420
or a binary code so it will it will

00:19:38,800 --> 00:19:41,620
actually in the being a compiler as well

00:19:40,420 --> 00:19:42,820
so there is a compiler in there to

00:19:41,620 --> 00:19:47,890
compose the PTX

00:19:42,820 --> 00:19:50,770
down to the binary that runs on your GPU

00:19:47,890 --> 00:19:52,720
again different GPUs the ISAs or GPUs

00:19:50,770 --> 00:19:55,210
are not like x86 they haven't been sort

00:19:52,720 --> 00:19:57,010
of stuck in one place they move quite

00:19:55,210 --> 00:19:58,540
regularly every new generation of GPU

00:19:57,010 --> 00:20:01,270
will either add a few instructions takes

00:19:58,540 --> 00:20:03,790
them away modified a look so they're not

00:20:01,270 --> 00:20:05,120
they're not stable at that level so they

00:20:03,790 --> 00:20:07,340
that's why they end up needing this

00:20:05,120 --> 00:20:09,650
finalizer thing that will take the PTX

00:20:07,340 --> 00:20:14,690
and make it into the IR or sorry to the

00:20:09,650 --> 00:20:16,160
binary and I will execute it that's the

00:20:14,690 --> 00:20:18,260
pretty much the basics of just the

00:20:16,160 --> 00:20:21,350
coolest act in terms of where it's IR is

00:20:18,260 --> 00:20:23,380
used and that's where PBX contain so aim

00:20:21,350 --> 00:20:26,960
these vendor stack is called Rock'em I

00:20:23,380 --> 00:20:28,190
can't remember what rock stands for it

00:20:26,960 --> 00:20:32,330
probably rolls off the tongue like a

00:20:28,190 --> 00:20:33,770
true genius something else so they

00:20:32,330 --> 00:20:36,860
actually have taken this thing so they

00:20:33,770 --> 00:20:40,429
they will let you use CUDA and then they

00:20:36,860 --> 00:20:43,070
will slice both said slash Perl slash

00:20:40,429 --> 00:20:45,860
something older file off the CUDA slash

00:20:43,070 --> 00:20:48,350
hip and they will translate the cooler

00:20:45,860 --> 00:20:50,240
API into hip API and ill translate Cudas

00:20:48,350 --> 00:20:51,679
source code it to hip source code and

00:20:50,240 --> 00:20:54,230
then they will you then have an

00:20:51,679 --> 00:20:56,480
application that C++ hip and then you

00:20:54,230 --> 00:20:58,550
run that trigger hip front-end on the

00:20:56,480 --> 00:20:59,960
same thing there the vise compiler and

00:20:58,550 --> 00:21:00,740
then they've got the assembly but they

00:20:59,960 --> 00:21:03,280
don't have an intermediate

00:21:00,740 --> 00:21:06,710
representation they actually put

00:21:03,280 --> 00:21:10,520
targeted binary code into the elf object

00:21:06,710 --> 00:21:12,710
file which it's like okay I don't want

00:21:10,520 --> 00:21:14,690
ever change my GPU I'm good here but if

00:21:12,710 --> 00:21:18,290
you want to change the GPU you you are

00:21:14,690 --> 00:21:21,260
not good see any execution environment

00:21:18,290 --> 00:21:23,630
is again slightly similar language

00:21:21,260 --> 00:21:25,670
runtime rockem runtime they don't really

00:21:23,630 --> 00:21:27,230
have to finalize as much there may be an

00:21:25,670 --> 00:21:28,400
option for certain cases but generally

00:21:27,230 --> 00:21:30,800
they've got the binary did not do

00:21:28,400 --> 00:21:32,179
finalization at all does just yeah throw

00:21:30,800 --> 00:21:34,790
that binary into the hardware I'm

00:21:32,179 --> 00:21:37,400
running so yeah they've made this bit

00:21:34,790 --> 00:21:39,140
simpler at the expense of making this

00:21:37,400 --> 00:21:43,700
bit more complex and having the elf file

00:21:39,140 --> 00:21:46,880
being a lot more targeted there's sort

00:21:43,700 --> 00:21:49,970
of two competing single source stacks

00:21:46,880 --> 00:21:52,160
and execution environments again back to

00:21:49,970 --> 00:21:53,660
the vendor so intel has a neo stack this

00:21:52,160 --> 00:21:56,840
is an open CL stack that they recently

00:21:53,660 --> 00:21:58,730
released open source it doesn't do CUDA

00:21:56,840 --> 00:22:03,020
our hip level things it's pretty much

00:21:58,730 --> 00:22:06,830
just a C++ open CL C and C++ and I think

00:22:03,020 --> 00:22:08,420
it can execute spare vir as well so it's

00:22:06,830 --> 00:22:11,720
not on the same playing field as the

00:22:08,420 --> 00:22:14,800
other two stacks but it's a building

00:22:11,720 --> 00:22:17,960
block to add or to get you towards that

00:22:14,800 --> 00:22:18,730
there's also an open stack for open CL

00:22:17,960 --> 00:22:21,800
so Mesa

00:22:18,730 --> 00:22:26,540
implementation of the CL called clover

00:22:21,800 --> 00:22:28,910
it it hasn't received that dedication is

00:22:26,540 --> 00:22:30,800
required for it to be what we needed to

00:22:28,910 --> 00:22:33,830
be so far it's got obviously at one

00:22:30,800 --> 00:22:35,540
point one opencl 1.2 is getting there I

00:22:33,830 --> 00:22:37,370
think there's only one feature missing

00:22:35,540 --> 00:22:38,960
it's like printf or something and printf

00:22:37,370 --> 00:22:40,190
makes I mean you think about print test

00:22:38,960 --> 00:22:43,040
actually kind of messy when you want to

00:22:40,190 --> 00:22:44,180
run on your GPU it's based on the

00:22:43,040 --> 00:22:45,770
gallium architecture which is an

00:22:44,180 --> 00:22:47,510
internal Mesa architecture that we use

00:22:45,770 --> 00:22:49,610
for running the graphics drivers role or

00:22:47,510 --> 00:22:51,050
nearly all the graphics drivers are

00:22:49,610 --> 00:22:54,080
written on top of this architecture at

00:22:51,050 --> 00:22:58,570
this stage spear Vee support is

00:22:54,080 --> 00:23:01,490
currently being finalized it works and

00:22:58,570 --> 00:23:04,760
the backends are what exit can execute

00:23:01,490 --> 00:23:06,500
on AMD Nvidia freed reno's arm again

00:23:04,760 --> 00:23:08,300
this brings in a whole world of arm

00:23:06,500 --> 00:23:09,590
devices as well this opens up a

00:23:08,300 --> 00:23:12,350
possibility that we can execute this

00:23:09,590 --> 00:23:16,880
stuff on you know non x86 platforms as

00:23:12,350 --> 00:23:18,860
well a lot better there is a chance of

00:23:16,880 --> 00:23:21,050
this running would Intel gallium drivers

00:23:18,860 --> 00:23:25,220
ball so that possibility exists in the

00:23:21,050 --> 00:23:27,830
future as well so that's kind of sort of

00:23:25,220 --> 00:23:30,230
what the state of play is currently in

00:23:27,830 --> 00:23:33,020
terms of what stats are out there it's

00:23:30,230 --> 00:23:36,020
like it had been with development model

00:23:33,020 --> 00:23:38,870
so when somebody tells you oh it's fine

00:23:36,020 --> 00:23:40,760
my stock is open-source what does it

00:23:38,870 --> 00:23:44,720
mean to them and what does it sure that

00:23:40,760 --> 00:23:46,400
mean to you is people in this area have

00:23:44,720 --> 00:23:48,260
been say oh we've open-sourced our stack

00:23:46,400 --> 00:23:50,210
and what they mean is they've taken that

00:23:48,260 --> 00:23:54,050
as a release model not as a development

00:23:50,210 --> 00:23:55,220
model and my my opinion from the stuff I

00:23:54,050 --> 00:23:57,310
want to work on I want open-source

00:23:55,220 --> 00:24:02,330
development model I want to be able to

00:23:57,310 --> 00:24:03,620
have the project I'm working on in be

00:24:02,330 --> 00:24:05,750
able to interact with that project at

00:24:03,620 --> 00:24:08,690
the same level as somebody working at a

00:24:05,750 --> 00:24:11,420
vendor or you know in the company you

00:24:08,690 --> 00:24:12,740
can't just release it by throwing it

00:24:11,420 --> 00:24:14,060
over the wall every three months and

00:24:12,740 --> 00:24:15,560
saying it's open source it's like

00:24:14,060 --> 00:24:17,390
Android has done that in a lot of ways

00:24:15,560 --> 00:24:21,320
but it's some areas it's it's moving

00:24:17,390 --> 00:24:24,010
towards being better but as as someone

00:24:21,320 --> 00:24:27,110
that's not aligned with the vendors you

00:24:24,010 --> 00:24:29,540
don't want to be on you know you don't

00:24:27,110 --> 00:24:30,730
want to be outside of the project and

00:24:29,540 --> 00:24:33,669
trying to push too

00:24:30,730 --> 00:24:35,950
and then relying on you know processes

00:24:33,669 --> 00:24:38,080
you can't see and internal meetings and

00:24:35,950 --> 00:24:41,049
all this stuff that they've built up it

00:24:38,080 --> 00:24:43,929
the the current model that they the

00:24:41,049 --> 00:24:46,840
OpenCL Intel dome CL and the Rock'em are

00:24:43,929 --> 00:24:49,240
done on is vendor controlled the vendor

00:24:46,840 --> 00:24:51,940
does all the development in-house does

00:24:49,240 --> 00:24:53,429
all the design in-house and kicks it out

00:24:51,940 --> 00:24:55,990
over the wall every three months and say

00:24:53,429 --> 00:24:58,179
you guys just yeah that's what you want

00:24:55,990 --> 00:24:59,620
it's like I think you missed you know

00:24:58,179 --> 00:25:04,200
you miss the memo on how this works but

00:24:59,620 --> 00:25:06,400
it it comes down to then how do I a

00:25:04,200 --> 00:25:09,580
support something like that how do I put

00:25:06,400 --> 00:25:11,740
this into a distribution and move

00:25:09,580 --> 00:25:14,860
forward wit and support it because if

00:25:11,740 --> 00:25:16,570
it's buggy how do I get fixes in how do

00:25:14,860 --> 00:25:18,610
I make sure I'm not Reba can i rebased

00:25:16,570 --> 00:25:20,320
this every six months when they kick it

00:25:18,610 --> 00:25:22,000
over the wall that it's not broken or it

00:25:20,320 --> 00:25:23,830
hasn't regressed in a horrible way that

00:25:22,000 --> 00:25:28,330
they don't care about that affects the

00:25:23,830 --> 00:25:29,830
applications I'm running so it may have

00:25:28,330 --> 00:25:31,660
been knows some messaging in this it

00:25:29,830 --> 00:25:33,250
because you know they they probably just

00:25:31,660 --> 00:25:34,840
heard all well once we open source stuff

00:25:33,250 --> 00:25:36,400
all the Linux distributions will just

00:25:34,840 --> 00:25:38,410
magically take it because that's all

00:25:36,400 --> 00:25:40,870
they cared about but it was like no open

00:25:38,410 --> 00:25:43,120
sourcing it was like the zero step that

00:25:40,870 --> 00:25:44,799
was the I can now talk to you it once

00:25:43,120 --> 00:25:46,390
you've open sourced it it's not the oh

00:25:44,799 --> 00:25:48,309
you've got them source that now it's in

00:25:46,390 --> 00:25:49,840
my distribution two weeks later it's

00:25:48,309 --> 00:25:52,570
like there's a big disconnect between

00:25:49,840 --> 00:25:54,460
what they think open sourcing it is and

00:25:52,570 --> 00:25:56,830
what we think open sourcing something is

00:25:54,460 --> 00:26:00,400
and for me that's that's a problem

00:25:56,830 --> 00:26:02,260
because like we have the Linux kernel we

00:26:00,400 --> 00:26:04,510
already have a model of open source

00:26:02,260 --> 00:26:06,429
development and how to build things and

00:26:04,510 --> 00:26:09,160
how to get vendors to put stuff into a

00:26:06,429 --> 00:26:10,540
common area and we have in the graphics

00:26:09,160 --> 00:26:12,640
base we have the Mesa project and again

00:26:10,540 --> 00:26:14,110
the Mesa project has a model of vendors

00:26:12,640 --> 00:26:15,820
cooperating and vendors there's no

00:26:14,110 --> 00:26:18,250
vendor controller there's nobody you

00:26:15,820 --> 00:26:19,780
know I own this I can drive it it's like

00:26:18,250 --> 00:26:24,100
everyone has to cooperate it works

00:26:19,780 --> 00:26:25,780
pretty well so why do i why would I want

00:26:24,100 --> 00:26:28,440
to go back to having these vendor

00:26:25,780 --> 00:26:31,150
control stacks that don't let me

00:26:28,440 --> 00:26:33,160
contribute and don't let me like how

00:26:31,150 --> 00:26:36,220
could I port AMD's Rock'em to Intel how

00:26:33,160 --> 00:26:39,850
can I port Intel stack to AMD and NVIDIA

00:26:36,220 --> 00:26:42,790
you know there's a lot of challenges in

00:26:39,850 --> 00:26:43,870
this area for someone that at the end

00:26:42,790 --> 00:26:46,240
some that's like

00:26:43,870 --> 00:26:48,100
tributing is code it's like there are

00:26:46,240 --> 00:26:51,010
very large bodies of code these things

00:26:48,100 --> 00:26:54,220
take a lot of time to get into the

00:26:51,010 --> 00:26:56,590
common code is not massive there's

00:26:54,220 --> 00:27:00,130
everyone loves to fork LLVM and si lang

00:26:56,590 --> 00:27:02,950
and like LLVM si lang don't have the

00:27:00,130 --> 00:27:06,430
greatest to develop model challenging

00:27:02,950 --> 00:27:07,990
but the forking of them is impossible

00:27:06,430 --> 00:27:10,240
for a distributor to keep up with

00:27:07,990 --> 00:27:12,840
because right even from like a fedora

00:27:10,240 --> 00:27:15,490
point of view right i for i think i

00:27:12,840 --> 00:27:18,520
packaged LLVM si Lang for about three

00:27:15,490 --> 00:27:20,110
years and doing that was enough to make

00:27:18,520 --> 00:27:22,000
me not want to do it I can't imagine

00:27:20,110 --> 00:27:23,440
something going well I've got a fork of

00:27:22,000 --> 00:27:24,820
L of yam and I've got another fork if

00:27:23,440 --> 00:27:27,010
you package all three of these Forks or

00:27:24,820 --> 00:27:29,890
four forks like you you'd go insane so

00:27:27,010 --> 00:27:31,570
you need to have at least baseline all

00:27:29,890 --> 00:27:33,490
of this stuff needs to be upstream din

00:27:31,570 --> 00:27:34,929
LLVM so if you're going and doing crazy

00:27:33,490 --> 00:27:36,429
stuff you need to make sure that you've

00:27:34,929 --> 00:27:38,320
figured it out upstream before you come

00:27:36,429 --> 00:27:41,320
back and say here's my cool stack up

00:27:38,320 --> 00:27:44,170
there load so it there's there's

00:27:41,320 --> 00:27:47,970
challenges in this area and with the

00:27:44,170 --> 00:27:50,470
current stack so kind of question is

00:27:47,970 --> 00:27:52,650
anything we can do about this alright it

00:27:50,470 --> 00:27:55,990
should be I just get the feeling that

00:27:52,650 --> 00:27:58,240
like we have said we have Linux we know

00:27:55,990 --> 00:28:01,059
how to do it it's very late at the

00:27:58,240 --> 00:28:03,000
moment we also have the Linux experience

00:28:01,059 --> 00:28:05,740
of dealing with vendors which is

00:28:03,000 --> 00:28:07,630
generally it never ends well or it it

00:28:05,740 --> 00:28:09,580
takes a long time to get vendors around

00:28:07,630 --> 00:28:11,080
to the way of doing things so it

00:28:09,580 --> 00:28:13,210
involves pushing the right people into

00:28:11,080 --> 00:28:15,150
the vendor and getting them to align

00:28:13,210 --> 00:28:17,440
their goals not with their own internal

00:28:15,150 --> 00:28:19,360
view of the world but with an external

00:28:17,440 --> 00:28:21,610
toward a more holistic Linux view of the

00:28:19,360 --> 00:28:23,260
world and you know they still have a lot

00:28:21,610 --> 00:28:24,820
of because a lot of this stuff comes

00:28:23,260 --> 00:28:27,670
from a graphics point of view and

00:28:24,820 --> 00:28:29,950
graphics from a Linux point of view is

00:28:27,670 --> 00:28:32,140
not really wasn't really a primary focus

00:28:29,950 --> 00:28:34,000
we were very your enterprise doesn't

00:28:32,140 --> 00:28:35,620
need graphics so why do we care about it

00:28:34,000 --> 00:28:37,150
that kill its desktop it's that stuff

00:28:35,620 --> 00:28:39,250
like that all of a sudden it's like Oh

00:28:37,150 --> 00:28:41,140
enterprise new traffic oh but how do we

00:28:39,250 --> 00:28:42,490
do this and it's like well we should

00:28:41,140 --> 00:28:43,720
have started five years ago when we had

00:28:42,490 --> 00:28:47,350
graphics and we didn't have this problem

00:28:43,720 --> 00:28:48,670
but you know we've done it now so this

00:28:47,350 --> 00:28:50,770
is where I get bit hand-wavy this is

00:28:48,670 --> 00:28:54,070
kind of like well what would I do if I

00:28:50,770 --> 00:28:54,970
had either time resources or cared

00:28:54,070 --> 00:28:57,309
enough

00:28:54,970 --> 00:28:58,419
sort of and maybe I will start caring

00:28:57,309 --> 00:29:00,070
enough I'm getting there

00:28:58,419 --> 00:29:04,059
and but it's sort of like a proposed

00:29:00,070 --> 00:29:06,280
stack for this sort of thing so first

00:29:04,059 --> 00:29:08,669
thing I believe it least need a baseline

00:29:06,280 --> 00:29:13,090
reference implementation something that

00:29:08,669 --> 00:29:15,520
we can ship in a distro that developers

00:29:13,090 --> 00:29:18,190
can pick up and just use and play around

00:29:15,520 --> 00:29:21,850
with and it's just there it might not be

00:29:18,190 --> 00:29:23,950
as super optimized for every case but

00:29:21,850 --> 00:29:26,080
it's there and it's open source it's in

00:29:23,950 --> 00:29:28,030
front of them it's not defined by the

00:29:26,080 --> 00:29:30,130
vendor it's neutral like the vendor the

00:29:28,030 --> 00:29:33,220
the contribution model will would be a

00:29:30,130 --> 00:29:36,760
common set of code bases because you

00:29:33,220 --> 00:29:39,880
don't want to be held to this single

00:29:36,760 --> 00:29:41,830
vendor problem you want to share as much

00:29:39,880 --> 00:29:44,830
of the code as possible because support

00:29:41,830 --> 00:29:47,200
costs go down if you support share as

00:29:44,830 --> 00:29:48,820
much of the code as possible look like

00:29:47,200 --> 00:29:50,830
from a point of view of oh I fixed a bug

00:29:48,820 --> 00:29:52,360
in this and it's got the same bug over

00:29:50,830 --> 00:29:53,890
here and it's got the same bug over here

00:29:52,360 --> 00:29:55,929
and he's just copied the code it's like

00:29:53,890 --> 00:29:58,720
it doesn't scale out you need to

00:29:55,929 --> 00:30:00,520
minimize the vendor specific code as

00:29:58,720 --> 00:30:03,100
much as possible same as we do in the

00:30:00,520 --> 00:30:05,289
kernel you know we try to we don't we

00:30:03,100 --> 00:30:07,480
don't invite everyone to put their own

00:30:05,289 --> 00:30:10,510
ate or 2.11 stack into the kernel like

00:30:07,480 --> 00:30:12,429
you know they wanted to ten years ago we

00:30:10,510 --> 00:30:15,190
go no you write your driver for the soft

00:30:12,429 --> 00:30:17,320
there it you know you your commonality

00:30:15,190 --> 00:30:19,510
as much as possible so I I believe that

00:30:17,320 --> 00:30:22,929
we need to try and get the same sort of

00:30:19,510 --> 00:30:26,110
level we need to define what we believe

00:30:22,929 --> 00:30:27,970
to be the Linux compute stack and tell

00:30:26,110 --> 00:30:30,850
the vendors this is what you should be

00:30:27,970 --> 00:30:32,110
at least aiming for as a baseline yeah

00:30:30,850 --> 00:30:34,000
if you want to keep going with your

00:30:32,110 --> 00:30:36,100
private stacks and on your bestest you

00:30:34,000 --> 00:30:37,600
know your well tuned things and you want

00:30:36,100 --> 00:30:39,159
to share my windows that's fine they do

00:30:37,600 --> 00:30:41,020
that with graphics drivers now they'll

00:30:39,159 --> 00:30:42,220
have an open source work that's actually

00:30:41,020 --> 00:30:44,350
in the distros and then they may have

00:30:42,220 --> 00:30:47,380
their own open source or closed source

00:30:44,350 --> 00:30:48,669
or vendor specific code that nobody has

00:30:47,380 --> 00:30:50,169
to care about unless they have a some

00:30:48,669 --> 00:30:53,440
you know business relationship with them

00:30:50,169 --> 00:30:57,480
so I think it has to be standards-based

00:30:53,440 --> 00:30:59,860
I can't really say we just take CUDA and

00:30:57,480 --> 00:31:01,900
it reimplemented it as an open source

00:30:59,860 --> 00:31:04,380
project because you can't control

00:31:01,900 --> 00:31:07,390
something that's led by a single vendor

00:31:04,380 --> 00:31:10,360
doing things are controlled by Kronos

00:31:07,390 --> 00:31:12,040
it's still not open source but there's a

00:31:10,360 --> 00:31:15,070
lot more input from vendors and

00:31:12,040 --> 00:31:17,260
distributions and you know there's a lot

00:31:15,070 --> 00:31:19,060
more areas you can get control over how

00:31:17,260 --> 00:31:21,580
things are going out

00:31:19,060 --> 00:31:22,570
I believe the API is need to be common I

00:31:21,580 --> 00:31:24,040
don't think we should you know there

00:31:22,570 --> 00:31:26,320
should be a the execution environment

00:31:24,040 --> 00:31:29,680
needs to be as common as possible the IR

00:31:26,320 --> 00:31:33,280
needs to be common we can't the elf

00:31:29,680 --> 00:31:37,600
objects can't go having NVIDIA code and

00:31:33,280 --> 00:31:39,850
M decode Intel codes you need one thing

00:31:37,600 --> 00:31:41,680
in the in the elf object and the object

00:31:39,850 --> 00:31:44,710
end should be portable across vendors

00:31:41,680 --> 00:31:46,450
and we need tooling in the end that's

00:31:44,710 --> 00:31:49,360
common because one area that I haven't

00:31:46,450 --> 00:31:52,090
really dug into here is okay all you've

00:31:49,360 --> 00:31:54,700
you run this but how do you debug it how

00:31:52,090 --> 00:31:56,920
do you profile it oh there's a vendor

00:31:54,700 --> 00:31:59,200
tool for us well I don't want to learn

00:31:56,920 --> 00:32:01,300
every vendors tools it's not like I want

00:31:59,200 --> 00:32:05,440
to be able to use gdb I want to be able

00:32:01,300 --> 00:32:07,570
to use perf you know there's the range

00:32:05,440 --> 00:32:09,370
of tools that we linux already has and

00:32:07,570 --> 00:32:11,140
people are familiar with you want to be

00:32:09,370 --> 00:32:13,120
able to use those tools you don't want

00:32:11,140 --> 00:32:14,710
to be oh I've gotta learn a whole new

00:32:13,120 --> 00:32:16,690
vendor stack every time you switch

00:32:14,710 --> 00:32:21,970
graphics card it's like that would just

00:32:16,690 --> 00:32:23,910
be draining so like my currently isn't

00:32:21,970 --> 00:32:27,190
like a bit of a proposed stack picture I

00:32:23,910 --> 00:32:30,730
kind of feel cycles the only thing in

00:32:27,190 --> 00:32:32,350
the right place right now I may be in

00:32:30,730 --> 00:32:34,180
five years C++ will be in the right

00:32:32,350 --> 00:32:37,420
place but right now I think cycles the

00:32:34,180 --> 00:32:40,390
only thing that's at least a standard

00:32:37,420 --> 00:32:41,800
implementation there is a standard but

00:32:40,390 --> 00:32:44,080
maybe too much in the standard but at

00:32:41,800 --> 00:32:47,350
least it exists and it's possible to do

00:32:44,080 --> 00:32:49,630
it you plug it into an upstream C line

00:32:47,350 --> 00:32:52,450
cycle for a min so you write a common

00:32:49,630 --> 00:32:55,740
cycle front end at upstream and C line

00:32:52,450 --> 00:33:01,600
and all the vendors contribute to that

00:32:55,740 --> 00:33:06,070
you're the LLVM device compilers device

00:33:01,600 --> 00:33:09,340
compiler for the cycle code is upstream

00:33:06,070 --> 00:33:13,330
LVM as well so no Forks no crazy stuff

00:33:09,340 --> 00:33:17,110
and it will spit out spear V and I mean

00:33:13,330 --> 00:33:18,160
open CL spear V right now focus parity

00:33:17,110 --> 00:33:20,470
could be an option in the future but

00:33:18,160 --> 00:33:21,159
right now it's not you dentro that

00:33:20,470 --> 00:33:22,809
interior

00:33:21,159 --> 00:33:25,599
thought you didn't have an elf object

00:33:22,809 --> 00:33:27,340
file you want in your execution

00:33:25,599 --> 00:33:29,109
environment you want to have your cycle

00:33:27,340 --> 00:33:31,690
library so you're gonna have one area

00:33:29,109 --> 00:33:35,739
that's kind of again I'm hand-waving a

00:33:31,690 --> 00:33:38,649
lot in this area is how to do vendor

00:33:35,739 --> 00:33:40,989
specific library I sort of feel you

00:33:38,649 --> 00:33:42,729
should still have so for things like

00:33:40,989 --> 00:33:44,919
glassware they've got linear algebra

00:33:42,729 --> 00:33:46,570
stuff there's must be I'm gonna gas

00:33:44,919 --> 00:33:48,340
there's at least fifteen glass

00:33:46,570 --> 00:33:50,200
implementations existing in the moment

00:33:48,340 --> 00:33:52,239
why is there fifteen glass

00:33:50,200 --> 00:33:54,940
implementations and everyone targeting

00:33:52,239 --> 00:33:56,919
different things it's like well couldn't

00:33:54,940 --> 00:33:58,899
you just have one blast project with

00:33:56,919 --> 00:34:01,239
fifteen implementations in silent that's

00:33:58,899 --> 00:34:02,919
not everyone forking it like how do i

00:34:01,239 --> 00:34:05,320
distribute fifteen blossom plantations

00:34:02,919 --> 00:34:08,200
I'm not going it's just too much people

00:34:05,320 --> 00:34:09,520
are only thinking of very small problems

00:34:08,200 --> 00:34:10,899
of like how do I get something it's like

00:34:09,520 --> 00:34:14,679
how do i distribute this how do i get

00:34:10,899 --> 00:34:15,700
other people into this area so and

00:34:14,679 --> 00:34:16,899
that's the definitely area it needs a

00:34:15,700 --> 00:34:18,669
lot more research especially around

00:34:16,899 --> 00:34:20,799
things like the DNN library the tensor

00:34:18,669 --> 00:34:23,619
fill users from cuda and the hip one

00:34:20,799 --> 00:34:25,569
because that there are some really tuned

00:34:23,619 --> 00:34:28,510
implementations of things just to make

00:34:25,569 --> 00:34:30,069
tensor flow that much faster on that GPU

00:34:28,510 --> 00:34:31,659
and getting that stuff open-source and

00:34:30,069 --> 00:34:36,220
having someone invest in that is

00:34:31,659 --> 00:34:38,500
possibly a very you know i've done

00:34:36,220 --> 00:34:40,690
stupider things we'll see what happens

00:34:38,500 --> 00:34:42,579
at the wrong time i would believe would

00:34:40,690 --> 00:34:46,779
need to be based on mesa at this point

00:34:42,579 --> 00:34:49,240
using the mesas OpenCL I don't really

00:34:46,779 --> 00:34:50,859
care to make the OpenCL in Mesa

00:34:49,240 --> 00:34:52,359
standards-compliant

00:34:50,859 --> 00:34:55,659
as such I don't want people to be using

00:34:52,359 --> 00:34:58,599
open Co other than to launch things that

00:34:55,659 --> 00:35:00,130
came out of cycle it's I don't feel the

00:34:58,599 --> 00:35:02,829
need that we need to have the full C and

00:35:00,130 --> 00:35:04,779
C++ implementations in OpenCL I actually

00:35:02,829 --> 00:35:07,329
would like it to be Vulcan I take Vulcan

00:35:04,779 --> 00:35:09,279
is the right level of API for a launcher

00:35:07,329 --> 00:35:12,309
it doesn't do anything that you don't

00:35:09,279 --> 00:35:14,349
want it doesn't have a compiler but I

00:35:12,309 --> 00:35:16,000
just don't think it's right yet but I'm

00:35:14,349 --> 00:35:17,829
going to do some experimenting someone

00:35:16,000 --> 00:35:20,859
has actually started doing a cycle over

00:35:17,829 --> 00:35:23,049
Vulcan experiment already so we'll see

00:35:20,859 --> 00:35:24,730
it might be useful book and also doesn't

00:35:23,049 --> 00:35:25,930
really have some of the more modern

00:35:24,730 --> 00:35:28,059
things you want like virtual memory

00:35:25,930 --> 00:35:29,640
shared virtual memory things like Jerome

00:35:28,059 --> 00:35:32,160
was talking about yesterday and

00:35:29,640 --> 00:35:33,510
memory management volcans not really

00:35:32,160 --> 00:35:36,210
ready for that yet

00:35:33,510 --> 00:35:37,319
OpenCL is not it hasn't in the standard

00:35:36,210 --> 00:35:39,119
but I don't think anyone ever

00:35:37,319 --> 00:35:41,910
implemented it before about a few months

00:35:39,119 --> 00:35:44,819
ago it has some issues but I want at the

00:35:41,910 --> 00:35:45,779
end to be able to run this on all three

00:35:44,819 --> 00:35:49,440
vendors hardware

00:35:45,779 --> 00:35:52,289
I want one binary that I build that can

00:35:49,440 --> 00:35:54,150
then run across the tree hardware so

00:35:52,289 --> 00:35:58,369
we'll have a the Mesa runtime will be a

00:35:54,150 --> 00:35:58,369
finalizar it will take the Spear VI are

00:36:01,880 --> 00:36:06,630
actually better details on the OPC are

00:36:03,930 --> 00:36:08,309
so the runtime would be you'd minimize

00:36:06,630 --> 00:36:11,160
your GPU specific code as much as

00:36:08,309 --> 00:36:12,900
possible the abstract the runtime api

00:36:11,160 --> 00:36:15,150
which would be open CL but it could be

00:36:12,900 --> 00:36:16,589
Vulcan will use the existing graphics

00:36:15,150 --> 00:36:18,779
gallium drivers to actually run the

00:36:16,589 --> 00:36:23,299
hardware or Volcom drivers will forget

00:36:18,779 --> 00:36:27,029
their and there will be a spear vv2 near

00:36:23,299 --> 00:36:28,049
to hardware finalizar of code compile

00:36:27,029 --> 00:36:29,519
it's pretty much a compiler

00:36:28,049 --> 00:36:31,140
I call it come finalizer but they they

00:36:29,519 --> 00:36:34,049
use that just to stop you confusing it

00:36:31,140 --> 00:36:36,539
with the other compiler currently like

00:36:34,049 --> 00:36:39,930
in Mesa the near backends we have an

00:36:36,539 --> 00:36:43,230
Intel near back-end which is in Mesa we

00:36:39,930 --> 00:36:45,119
have an AMD LLVM back-end that we the

00:36:43,230 --> 00:36:46,230
near it back and plugs into so but we're

00:36:45,119 --> 00:36:48,210
actually there's discussions that are

00:36:46,230 --> 00:36:50,519
actually making getting rid of that in

00:36:48,210 --> 00:36:52,650
some areas and just having an AMD near

00:36:50,519 --> 00:36:56,789
back-end that we can control and there's

00:36:52,650 --> 00:36:59,160
an Evo back-end for near as well so we

00:36:56,789 --> 00:37:03,059
have coverage of the tree vendors so the

00:36:59,160 --> 00:37:05,880
LLVM bitten there is kind of optional so

00:37:03,059 --> 00:37:07,740
yeah that's that's pretty much the

00:37:05,880 --> 00:37:12,119
picture like just some problems in the a

00:37:07,740 --> 00:37:15,390
like for instance very specific sort of

00:37:12,119 --> 00:37:17,339
problem and this is just for John so the

00:37:15,390 --> 00:37:19,740
Nvidia Hardware we can't currently make

00:37:17,339 --> 00:37:23,099
the vram go fast so you could build a

00:37:19,740 --> 00:37:25,019
computer TAC but practically you can't

00:37:23,099 --> 00:37:27,720
use a computer stack with open source

00:37:25,019 --> 00:37:30,299
drivers because the vram is being

00:37:27,720 --> 00:37:32,279
clocked at whatever it booted up and to

00:37:30,299 --> 00:37:33,809
actually make things run no point in

00:37:32,279 --> 00:37:35,220
putting stuff on to the GPU is to do it

00:37:33,809 --> 00:37:37,950
faster than the CPU and if you can't

00:37:35,220 --> 00:37:39,240
make the vram run at full speed so well

00:37:37,950 --> 00:37:40,710
but those things are all in discussion

00:37:39,240 --> 00:37:42,930
on how we could move forward and open

00:37:40,710 --> 00:37:43,230
get sort of you know drivers that let us

00:37:42,930 --> 00:37:44,580
do

00:37:43,230 --> 00:37:46,440
all that stuff for now that will

00:37:44,580 --> 00:37:49,170
actually open up a lot of possibility I

00:37:46,440 --> 00:37:52,230
think if we can get the nouveau stack

00:37:49,170 --> 00:37:53,850
into a space where all Cameron's Italy

00:37:52,230 --> 00:37:56,160
can at least have the possibility of

00:37:53,850 --> 00:37:57,810
running code at the same speed then it's

00:37:56,160 --> 00:38:00,780
then it's a software problem and it's a

00:37:57,810 --> 00:38:03,000
compiler guys we can the community can

00:38:00,780 --> 00:38:04,680
actually move on it as opposed to we're

00:38:03,000 --> 00:38:06,060
stalling we're stalling I think that's

00:38:04,680 --> 00:38:08,609
you know that sort of thing it's in aim

00:38:06,060 --> 00:38:10,650
be is pretty good the drivers should be

00:38:08,609 --> 00:38:11,880
everything and same with Intel their

00:38:10,650 --> 00:38:15,950
drivers should be able to execute things

00:38:11,880 --> 00:38:15,950
that yeah at Intel speeds

00:38:18,800 --> 00:38:30,990
that's my any questions or so you mean

00:38:29,700 --> 00:38:33,270
shoot a few times

00:38:30,990 --> 00:38:35,670
machine learning like I mean just for

00:38:33,270 --> 00:38:39,869
the workload but the solution is for

00:38:35,670 --> 00:38:42,420
generic compute and so it offers much

00:38:39,869 --> 00:38:43,859
more and it would be a lot of work and I

00:38:42,420 --> 00:38:46,050
was wondering if you have considered

00:38:43,859 --> 00:38:48,840
targeting much smaller API like for

00:38:46,050 --> 00:38:51,690
example Excel a potential flow is moving

00:38:48,840 --> 00:38:54,470
towards that instead of a I can cycle in

00:38:51,690 --> 00:38:58,260
this case so so for example you could

00:38:54,470 --> 00:39:03,030
implement Excel a back-end which would

00:38:58,260 --> 00:39:06,510
be a galleys mistake tracker drivers

00:39:03,030 --> 00:39:08,790
like that and it could be and maybe you

00:39:06,510 --> 00:39:12,500
get a better because Excel is much more

00:39:08,790 --> 00:39:18,420
closer to what machine learning needs

00:39:12,500 --> 00:39:22,260
yeah we talked about doing a sort of

00:39:18,420 --> 00:39:25,040
machine learning a smaller surface API

00:39:22,260 --> 00:39:25,040
specifically

00:39:26,480 --> 00:39:31,680
it's tempting but I also get the feeling

00:39:29,100 --> 00:39:34,440
that there's a lot more out there that

00:39:31,680 --> 00:39:36,210
people want to run even though it tends

00:39:34,440 --> 00:39:38,490
to flow and you know we were starting

00:39:36,210 --> 00:39:40,230
down and also the cycle stuff I haven't

00:39:38,490 --> 00:39:42,090
really mentioned Xilinx are like big

00:39:40,230 --> 00:39:43,470
into it's a big FPGA area again so

00:39:42,090 --> 00:39:46,950
there's a lot of research going on and

00:39:43,470 --> 00:39:48,570
what we could do with this ABI API yeah

00:39:46,950 --> 00:39:50,460
I feel about if we try to limit

00:39:48,570 --> 00:39:52,230
ourselves to one area that we could that

00:39:50,460 --> 00:39:54,030
area could get grown out of pretty quick

00:39:52,230 --> 00:39:56,010
or it would change direction and you'd

00:39:54,030 --> 00:39:59,820
be left holding a bag of something

00:39:56,010 --> 00:40:01,770
you've no other use for so I'm trying to

00:39:59,820 --> 00:40:03,150
keep it generic enough to be useful

00:40:01,770 --> 00:40:04,620
across industries because that's how

00:40:03,150 --> 00:40:08,160
you're gonna get a bit more investment

00:40:04,620 --> 00:40:11,250
or get people involved but not you know

00:40:08,160 --> 00:40:13,470
- I don't want the hey I've got a great

00:40:11,250 --> 00:40:15,300
idea trow it in there and then nobody

00:40:13,470 --> 00:40:18,960
implements it so it's yeah it's a

00:40:15,300 --> 00:40:21,060
balancing act I suppose consume because

00:40:18,960 --> 00:40:23,220
if you see the machine learning

00:40:21,060 --> 00:40:26,640
frameworks they're ones that have an

00:40:23,220 --> 00:40:29,250
opens your back-end it's not in the main

00:40:26,640 --> 00:40:31,890
branch no no I'm not that is some fork

00:40:29,250 --> 00:40:34,260
yeah the problem with mobile or having

00:40:31,890 --> 00:40:37,140
an open CL back-end is pointless it's

00:40:34,260 --> 00:40:39,360
the wrong solution MCL is not the way to

00:40:37,140 --> 00:40:42,360
do machine learning on computer cycle

00:40:39,360 --> 00:40:44,790
back end is actually upstream but

00:40:42,360 --> 00:40:46,500
doesn't work so tension flow has a cycle

00:40:44,790 --> 00:40:49,860
back end in an eigen has a cycle back

00:40:46,500 --> 00:40:52,080
end in it and there are the problems

00:40:49,860 --> 00:40:55,290
with tends to blow an eigen and those

00:40:52,080 --> 00:40:57,090
projects with cycle isn't data that they

00:40:55,290 --> 00:40:58,980
don't run on them it's that you can't

00:40:57,090 --> 00:41:01,380
get code upstream to tensorflow like

00:40:58,980 --> 00:41:03,750
I've had a C string include for it a

00:41:01,380 --> 00:41:05,610
patch that just includes tree C strings

00:41:03,750 --> 00:41:06,900
or hechas because they don't then the

00:41:05,610 --> 00:41:07,950
CUDA drivers are pulling those in and

00:41:06,900 --> 00:41:09,780
when you don't be Lakota they're not

00:41:07,950 --> 00:41:13,200
there it's been sitting there for four

00:41:09,780 --> 00:41:14,880
months it's like yeah how do you get

00:41:13,200 --> 00:41:16,530
like and then that's not required how do

00:41:14,880 --> 00:41:18,960
we like we need to engage those people

00:41:16,530 --> 00:41:21,600
in in terms of how do we get them to

00:41:18,960 --> 00:41:22,650
benefit to them that mean that they're

00:41:21,600 --> 00:41:25,500
suddenly interested they can get

00:41:22,650 --> 00:41:26,310
interested in because those guys do want

00:41:25,500 --> 00:41:28,860
to run tensorflow

00:41:26,310 --> 00:41:30,990
on more platforms they're not all we

00:41:28,860 --> 00:41:33,030
love coded that much but we haven't

00:41:30,990 --> 00:41:35,580
given them the benefits to them yet and

00:41:33,030 --> 00:41:37,170
you need to we need to give them this

00:41:35,580 --> 00:41:39,720
thing that says oh look you could

00:41:37,170 --> 00:41:41,940
suddenly do your your regression testing

00:41:39,720 --> 00:41:43,320
on other eight machines and other you

00:41:41,940 --> 00:41:45,360
can branch up what you're doing I think

00:41:43,320 --> 00:41:47,580
we have to sell that to the tensorflow

00:41:45,360 --> 00:41:50,550
and eigen and those sort of communities

00:41:47,580 --> 00:41:51,720
more than we have to you know hope that

00:41:50,550 --> 00:41:53,130
they're just going to accept what we do

00:41:51,720 --> 00:41:54,390
it needs a bit more a lot more

00:41:53,130 --> 00:42:00,300
interaction with those communities to

00:41:54,390 --> 00:42:01,680
try and well just I guess we yeah so I

00:42:00,300 --> 00:42:03,180
just want to make the observation that

00:42:01,680 --> 00:42:03,360
the you had a slide were you talking

00:42:03,180 --> 00:42:05,130
about

00:42:03,360 --> 00:42:06,450
development and release being open

00:42:05,130 --> 00:42:06,920
source sort of separate things and

00:42:06,450 --> 00:42:08,750
that's

00:42:06,920 --> 00:42:10,460
I can summarize that in one sentence

00:42:08,750 --> 00:42:11,599
that is open sources they process not a

00:42:10,460 --> 00:42:12,859
product and I've been telling you

00:42:11,599 --> 00:42:14,720
vendors that for about 15 years already

00:42:12,859 --> 00:42:16,069
yeah well we have a we've a statement in

00:42:14,720 --> 00:42:17,480
Red Hat that yeah we actually we have a

00:42:16,069 --> 00:42:19,460
it's a project

00:42:17,480 --> 00:42:21,079
not a product statement as a time you

00:42:19,460 --> 00:42:22,369
when you're doing it's yeah we have you

00:42:21,079 --> 00:42:23,750
have to have an open source project and

00:42:22,369 --> 00:42:25,760
then you have to have your product and

00:42:23,750 --> 00:42:28,089
they can't be the same thing yeah and

00:42:25,760 --> 00:42:29,869
you mentioned you got me thinking about

00:42:28,089 --> 00:42:31,730
performance monitoring when you

00:42:29,869 --> 00:42:33,619
mentioned I can and it's compiler and

00:42:31,730 --> 00:42:34,880
how you had this magic compiler well

00:42:33,619 --> 00:42:36,230
that depended a lot on performance

00:42:34,880 --> 00:42:38,150
monitoring to make that compiler work

00:42:36,230 --> 00:42:40,099
and if you had feedback loops in that to

00:42:38,150 --> 00:42:42,710
make it work more efficiently do those

00:42:40,099 --> 00:42:43,579
the there's two sir questions I have

00:42:42,710 --> 00:42:46,130
about because I don't know much about

00:42:43,579 --> 00:42:47,750
GPUs is is one of them is there that

00:42:46,130 --> 00:42:49,250
same sort of feedback loop available for

00:42:47,750 --> 00:42:51,680
DP you and GPU performance and their

00:42:49,250 --> 00:42:53,270
tools and the second one is do you have

00:42:51,680 --> 00:42:55,670
to understand as much about a specific

00:42:53,270 --> 00:42:57,650
implementation of the hardware as you do

00:42:55,670 --> 00:42:59,329
for I as we did for Itanium and for

00:42:57,650 --> 00:43:02,030
Intel and for anything else that has a

00:42:59,329 --> 00:43:05,059
PM you yeah I I didn't that's maybe

00:43:02,030 --> 00:43:07,520
memory a kind of sort of had like even

00:43:05,059 --> 00:43:09,829
if you get this stack you are going to

00:43:07,520 --> 00:43:12,200
have to tune it per GPU yes I guess my

00:43:09,829 --> 00:43:14,000
question is are those vendors gonna

00:43:12,200 --> 00:43:15,020
release enough documentation for people

00:43:14,000 --> 00:43:17,680
to understand what the hell they're

00:43:15,020 --> 00:43:20,359
tuning yeah the the performance counters

00:43:17,680 --> 00:43:22,099
used to be this we cannot tell you

00:43:20,359 --> 00:43:23,960
anything and they're now getting to

00:43:22,099 --> 00:43:25,790
being performance counters will tell you

00:43:23,960 --> 00:43:27,020
what they do and then you know some of

00:43:25,790 --> 00:43:28,849
them are still a bit vague on what they

00:43:27,020 --> 00:43:30,440
do but they are yeah they're definitely

00:43:28,849 --> 00:43:33,619
coming around to realizing that you

00:43:30,440 --> 00:43:34,970
can't just have this one tool that hides

00:43:33,619 --> 00:43:36,740
all your performance counting stuff

00:43:34,970 --> 00:43:39,799
inside it and then nobody needs anything

00:43:36,740 --> 00:43:42,200
else that's we are getting standards at

00:43:39,799 --> 00:43:44,059
least OpenGL and Vulcan and those are

00:43:42,200 --> 00:43:45,650
open C I was starting to get performance

00:43:44,059 --> 00:43:50,349
counters standard so the hope is that

00:43:45,650 --> 00:43:50,349
yes the feedback loop will be possible

00:43:57,010 --> 00:44:05,060
so open ACCC has the openness is the

00:44:02,570 --> 00:44:08,090
implementation GCC has an Nvidia

00:44:05,060 --> 00:44:10,700
back-end currently and I think there's

00:44:08,090 --> 00:44:13,400
an AMD GCN vacuum in the works as well

00:44:10,700 --> 00:44:15,470
so how does that measure up as a stack

00:44:13,400 --> 00:44:17,870
compared to what you have because it

00:44:15,470 --> 00:44:20,420
basically has a standard API which is

00:44:17,870 --> 00:44:22,670
open ACC open MP which is increasingly

00:44:20,420 --> 00:44:25,160
converging and then you have like the

00:44:22,670 --> 00:44:29,330
entire stack which is essentially open

00:44:25,160 --> 00:44:31,940
source I'm just I'm just gonna say I

00:44:29,330 --> 00:44:32,360
meant I didn't mention GCC for a few

00:44:31,940 --> 00:44:36,950
reasons

00:44:32,360 --> 00:44:40,010
a it's LVM is not a great compiler for

00:44:36,950 --> 00:44:42,020
graphics cards and you can extrapolate

00:44:40,010 --> 00:44:43,550
from that how good I think GCC is going

00:44:42,020 --> 00:44:47,150
to be as a compiler for graphics cards

00:44:43,550 --> 00:44:49,910
and it's not the good way it's it's not

00:44:47,150 --> 00:44:51,230
designed for this LVM is already causing

00:44:49,910 --> 00:44:54,500
us problems that we're willing to drop

00:44:51,230 --> 00:44:58,970
it at the finalizar stage I don't think

00:44:54,500 --> 00:45:01,700
having GCC spit out GCN binaries are PR

00:44:58,970 --> 00:45:03,320
Nvidia non-avian people PTX I'm okay

00:45:01,700 --> 00:45:06,290
with naming spear V I'd be okay with but

00:45:03,320 --> 00:45:07,970
barring our actual GPU target opponents

00:45:06,290 --> 00:45:12,530
right right so but what it does

00:45:07,970 --> 00:45:15,590
currently is it it spits out n vp DX and

00:45:12,530 --> 00:45:18,650
then mep DX is fed into the cuda

00:45:15,590 --> 00:45:22,790
libraries yes nvidia and for AMD if i

00:45:18,650 --> 00:45:27,640
remember correctly you it uses I'm gonna

00:45:22,790 --> 00:45:31,220
say the LLVM assembler for now and maybe

00:45:27,640 --> 00:45:35,420
generate that but then what if what if

00:45:31,220 --> 00:45:39,320
we could do something like have the open

00:45:35,420 --> 00:45:43,100
SEC open MP kind of front-end generate

00:45:39,320 --> 00:45:44,300
open CL speery yeah for all the compute

00:45:43,100 --> 00:45:47,240
parts and then you

00:45:44,300 --> 00:45:49,460
I think in this picture if you if you

00:45:47,240 --> 00:45:51,650
were to take that ceiling cycle and LLVM

00:45:49,460 --> 00:45:53,660
device compiler bits and make GCC do

00:45:51,650 --> 00:45:56,200
that and spit out spear V I don't think

00:45:53,660 --> 00:45:58,160
that would be an insane solution Einar I

00:45:56,200 --> 00:46:00,110
don't think it's going to get as much

00:45:58,160 --> 00:46:03,970
traction because LVM is already a known

00:46:00,110 --> 00:46:06,290
quantity in that area but yeah I do feel

00:46:03,970 --> 00:46:07,940
anything that's not spitting out an IR

00:46:06,290 --> 00:46:09,800
that you can retarget at runtime

00:46:07,940 --> 00:46:11,900
is doing you at this favor because you

00:46:09,800 --> 00:46:15,530
now have a binary you can only run them

00:46:11,900 --> 00:46:17,030
on GPU and GPUs aren't like CPUs you

00:46:15,530 --> 00:46:21,770
know you don't want to be building your

00:46:17,030 --> 00:46:22,880
district for x86 Nvidia x86 AMD x86 you

00:46:21,770 --> 00:46:24,320
know you don't want to suddenly have

00:46:22,880 --> 00:46:28,040
that common area that's become very

00:46:24,320 --> 00:46:31,850
explosion of cpu vendor - GPU vendor in

00:46:28,040 --> 00:46:34,070
your distribution Taner is even you know

00:46:31,850 --> 00:46:35,930
it's just it gets unmanageable pretty

00:46:34,070 --> 00:46:39,710
quickly especially if each one of those

00:46:35,930 --> 00:46:43,040
is a separate stack you know you know so

00:46:39,710 --> 00:46:45,200
much millions of your time so yeah IIIi

00:46:43,040 --> 00:46:47,420
feel GCC is not a great answer for this

00:46:45,200 --> 00:46:48,830
solution but I also know that people are

00:46:47,420 --> 00:46:50,450
looking into and it's possibly you know

00:46:48,830 --> 00:46:52,160
it may be a good have a place in it as

00:46:50,450 --> 00:46:53,690
well and then again you need the

00:46:52,160 --> 00:46:55,610
execution environment and I think that's

00:46:53,690 --> 00:46:57,190
the area we need to get a good execution

00:46:55,610 --> 00:47:03,650
environment and then we can worry about

00:46:57,190 --> 00:47:06,970
yeah yeah that's a secondary project all

00:47:03,650 --> 00:47:06,970
right thank you

00:47:07,120 --> 00:47:11,780

YouTube URL: https://www.youtube.com/watch?v=d94N2Lu4x9s


