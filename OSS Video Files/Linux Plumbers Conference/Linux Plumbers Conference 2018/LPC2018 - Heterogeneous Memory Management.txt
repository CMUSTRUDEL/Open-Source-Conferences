Title: LPC2018 - Heterogeneous Memory Management
Publication date: 2018-11-28
Playlist: Linux Plumbers Conference 2018
Description: 
	url:  https://linuxplumbersconf.org/event/2/contributions/70/
speaker:  Jerome Glisse (Red Hat)


Heterogeneous computing use massively parallel devices, such as GPU, to crunch through huge data-set. This talks intends to present the issues, challenges and problems related to memory management and heterogeneous computing. Issues and problems from one address space per device which makes exchanging or sharing data-set between devices and CPUs hard, complex and error prone.

Solutions involve a unified address space between devices and CPU often call SVM (Share Virtual Memory) or SVA (Share Virtual Address). In those unified address space a virtual address valid on CPUs is also valid on the devices. Talk will address both hardware and software solutions to this problem. Moreover it will consider ways to preserve the ability to use the device memory in those scheme.

Ultimately this talks is an opportunity to discuss memory placement, like for NUMA architecture, in a world where we not only have to worry about CPU but also about devices like GPU and their associated memory.

If it were not enough, we now also have to worry about memory hierarchy for each CPU or device. Memory hierarchy going from fast High Bandwidth Memory (HBM) to main memory (DDR DIMM) which can be order of magnitude slower, and finally to persistent memory which is large in size but slower and with higher latency.
Captions: 
	00:00:05,860 --> 00:00:11,690
I'm here to talk about eternal memory

00:00:08,660 --> 00:00:13,460
system what it is what it means what it

00:00:11,690 --> 00:00:17,780
is about

00:00:13,460 --> 00:00:19,880
so it's first I want to get a few basics

00:00:17,780 --> 00:00:22,880
make sure that we all understand what

00:00:19,880 --> 00:00:24,320
we're talking about when you talk about

00:00:22,880 --> 00:00:26,539
computer and when you talk about

00:00:24,320 --> 00:00:28,160
programming and everything's all the

00:00:26,539 --> 00:00:30,050
data structures rely on pointers

00:00:28,160 --> 00:00:32,419
it's either explicit or implicit

00:00:30,050 --> 00:00:34,160
depending on the language you use so you

00:00:32,419 --> 00:00:38,420
know when you're using a language like C

00:00:34,160 --> 00:00:39,829
or C++ and depending on you C++ to you

00:00:38,420 --> 00:00:40,969
cannot explicit pointers you know

00:00:39,829 --> 00:00:42,920
pointers and you can do pointer

00:00:40,969 --> 00:00:45,260
arithmetic sand you can do you can work

00:00:42,920 --> 00:00:47,719
with my dramatically and you have also

00:00:45,260 --> 00:00:50,840
other kind of languages like Python Java

00:00:47,719 --> 00:00:52,550
and whatnot that have implicit pointers

00:00:50,840 --> 00:00:54,590
it's either an under knees from the

00:00:52,550 --> 00:00:56,449
programmer but very still pointers the

00:00:54,590 --> 00:00:58,940
bottom line here is really that every

00:00:56,449 --> 00:01:00,829
data structure you use is actually

00:00:58,940 --> 00:01:03,199
relying on pointers in one form or the

00:01:00,829 --> 00:01:05,750
others you know when you have a graph

00:01:03,199 --> 00:01:08,270
for instance it's gonna be every arrow

00:01:05,750 --> 00:01:10,759
inside your graph gonna be pointers and

00:01:08,270 --> 00:01:14,360
graph is one of the most complex trees

00:01:10,759 --> 00:01:16,189
you can think of and then you have other

00:01:14,360 --> 00:01:19,130
data structures that use less pointers

00:01:16,189 --> 00:01:21,439
like tree for instance which is a kind

00:01:19,130 --> 00:01:23,810
of a graph and you know in the tree is

00:01:21,439 --> 00:01:25,280
really it's a you talk about balanced

00:01:23,810 --> 00:01:26,600
tree usually you have two children and

00:01:25,280 --> 00:01:29,780
stuff like that so you only have two

00:01:26,600 --> 00:01:33,020
pointers per node you have a thing like

00:01:29,780 --> 00:01:35,899
a stable it's an array of pointers you

00:01:33,020 --> 00:01:37,520
have the usual list obviously depending

00:01:35,899 --> 00:01:39,979
if it's edible lace or single lists you

00:01:37,520 --> 00:01:43,270
can have one or two pointers and re

00:01:39,979 --> 00:01:47,509
which is a simplest thing really of so

00:01:43,270 --> 00:01:48,770
pointers is what you rely on for all

00:01:47,509 --> 00:01:50,240
your data structure inside your

00:01:48,770 --> 00:01:52,780
programming language whatever it is in

00:01:50,240 --> 00:01:55,070
the end various pointers somewhere and

00:01:52,780 --> 00:01:57,350
what are pointers really

00:01:55,070 --> 00:01:59,780
pointer of our our virtual addresses

00:01:57,350 --> 00:02:01,100
because you don't actually from your

00:01:59,780 --> 00:02:02,450
program point of view you don't actually

00:02:01,100 --> 00:02:04,909
access the physical memory you use

00:02:02,450 --> 00:02:08,270
virtual addresses and virtual addresses

00:02:04,909 --> 00:02:10,220
are are translated to physical memory to

00:02:08,270 --> 00:02:11,930
the help of the CPU page table and the

00:02:10,220 --> 00:02:16,420
CPU vegetables simply Maps

00:02:11,930 --> 00:02:18,830
the virtual address to physical memory

00:02:16,420 --> 00:02:21,440
the way you look at virtual either

00:02:18,830 --> 00:02:23,810
usually with a map but you know when

00:02:21,440 --> 00:02:25,460
using a programming language like C or

00:02:23,810 --> 00:02:27,410
C++ is going to be Malik it's gonna be

00:02:25,460 --> 00:02:30,230
new it's gonna be whatever the language

00:02:27,410 --> 00:02:31,910
is actually exposing to you but

00:02:30,230 --> 00:02:34,130
underneath it's gonna be using users

00:02:31,910 --> 00:02:35,990
leap C or something else that does your

00:02:34,130 --> 00:02:40,220
M map in the end this is called to via a

00:02:35,990 --> 00:02:42,230
Linux kernel so all memory management

00:02:40,220 --> 00:02:44,750
inside user space is really relying on

00:02:42,230 --> 00:02:46,370
the virtual address thing and most of it

00:02:44,750 --> 00:02:50,600
is done by the programming languages

00:02:46,370 --> 00:02:52,700
like C++ or Java Script or Java and

00:02:50,600 --> 00:02:54,620
verse few interesting thing to to to

00:02:52,700 --> 00:02:56,390
keep in mind is that at any point in

00:02:54,620 --> 00:02:58,190
time the mapping between a virtual

00:02:56,390 --> 00:03:00,170
address and the physical memory can

00:02:58,190 --> 00:03:02,150
change you can immigrate you can use

00:03:00,170 --> 00:03:03,500
different physical memory to back the

00:03:02,150 --> 00:03:05,570
same virtual address

00:03:03,500 --> 00:03:07,160
there is nothing blocking you from that

00:03:05,570 --> 00:03:09,260
a actually quite common actually inside

00:03:07,160 --> 00:03:11,540
an external for that to happen

00:03:09,260 --> 00:03:13,730
so all these give us like the definition

00:03:11,540 --> 00:03:14,930
on what is an address space an address

00:03:13,730 --> 00:03:17,660
space is a mapping between virtual

00:03:14,930 --> 00:03:19,670
address and physical memory and it's

00:03:17,660 --> 00:03:23,989
what you share among thread inside a

00:03:19,670 --> 00:03:26,450
process and it's unique to a process

00:03:23,989 --> 00:03:28,340
that's how you have isolation between

00:03:26,450 --> 00:03:30,519
your process you know you your process

00:03:28,340 --> 00:03:34,370
of your own address space and we don't

00:03:30,519 --> 00:03:36,380
see each other's address space and so

00:03:34,370 --> 00:03:39,170
the end result is really that all

00:03:36,380 --> 00:03:40,910
pointers are interpreted against an

00:03:39,170 --> 00:03:42,650
address space a pointer doesn't mean

00:03:40,910 --> 00:03:44,239
anything if you don't have the mapping

00:03:42,650 --> 00:03:46,580
between the virtual address and the

00:03:44,239 --> 00:03:49,360
physical address so that's what pointer

00:03:46,580 --> 00:03:49,360
are about

00:03:53,640 --> 00:04:01,300
now there is an issue when you have

00:03:59,470 --> 00:04:05,200
multiple addresses based inside a single

00:04:01,300 --> 00:04:07,240
process and that's what is what you what

00:04:05,200 --> 00:04:09,780
is the most common thing today still

00:04:07,240 --> 00:04:12,070
when you use device like GPU or FPGA

00:04:09,780 --> 00:04:13,270
they have their own page table they are

00:04:12,070 --> 00:04:15,700
their own address space

00:04:13,270 --> 00:04:18,100
that does mean that pointers for GPU on

00:04:15,700 --> 00:04:20,110
FPGA is not the same thing as a partner

00:04:18,100 --> 00:04:23,110
you have on your CPU it doesn't mean the

00:04:20,110 --> 00:04:25,270
same thing simply because the virtual

00:04:23,110 --> 00:04:27,160
address on your device will point to

00:04:25,270 --> 00:04:31,890
different physical memory than the one

00:04:27,160 --> 00:04:36,730
you use on your on your CPU and you know

00:04:31,890 --> 00:04:39,300
this one other states per device is kind

00:04:36,730 --> 00:04:42,010
of becoming a bigger issue when it was

00:04:39,300 --> 00:04:43,570
ETR like OpenGL and stuff like that it's

00:04:42,010 --> 00:04:44,980
not much an issue because most of the

00:04:43,570 --> 00:04:46,390
time the area space is actually idn't

00:04:44,980 --> 00:04:47,920
from the application point of view and

00:04:46,390 --> 00:04:50,110
we don't really rely on point you're

00:04:47,920 --> 00:04:51,400
relying on higher higher up construct

00:04:50,110 --> 00:04:55,690
and so we don't really see the point of

00:04:51,400 --> 00:04:58,570
things and so nowadays we compute

00:04:55,690 --> 00:05:01,180
becoming really big things you can't see

00:04:58,570 --> 00:05:03,580
the address space the GPU physical

00:05:01,180 --> 00:05:06,370
address space actually a tricking down

00:05:03,580 --> 00:05:08,470
inside the programming application to

00:05:06,370 --> 00:05:10,060
things like OpenGL or CUDA where you

00:05:08,470 --> 00:05:11,590
actually expose the address space to the

00:05:10,060 --> 00:05:13,750
application itself so that the

00:05:11,590 --> 00:05:16,750
application becomes aware that yes GPRS

00:05:13,750 --> 00:05:18,490
based CPU airspace may be gff's path and

00:05:16,750 --> 00:05:20,080
so on and so forth

00:05:18,490 --> 00:05:22,720
and what it means really is that data

00:05:20,080 --> 00:05:24,040
structure you create actually are only

00:05:22,720 --> 00:05:25,419
meaningful against one of the address

00:05:24,040 --> 00:05:27,730
space so if you created a structure on

00:05:25,419 --> 00:05:29,560
your GPU that structure it can only be

00:05:27,730 --> 00:05:31,450
actually used by the GPU you cannot use

00:05:29,560 --> 00:05:33,490
it on the CPU because the virtual

00:05:31,450 --> 00:05:34,990
pointer all the all the pointer inside

00:05:33,490 --> 00:05:37,060
where that structure are only meaningful

00:05:34,990 --> 00:05:39,760
for the virtual address at which you are

00:05:37,060 --> 00:05:41,200
actually using and what it means it's

00:05:39,760 --> 00:05:42,960
really that sharing data structure

00:05:41,200 --> 00:05:45,070
between your CPU and your device is

00:05:42,960 --> 00:05:45,520
becoming really tedious and really

00:05:45,070 --> 00:05:47,530
complex

00:05:45,520 --> 00:05:50,530
you need special handling you need to

00:05:47,530 --> 00:05:55,510
use a library or you need to do really

00:05:50,530 --> 00:05:58,270
crazy things and to give you an ID this

00:05:55,510 --> 00:06:00,190
is an example of a double linked list at

00:05:58,270 --> 00:06:02,380
the top you have the one outer space via

00:06:00,190 --> 00:06:04,840
CPU thing you know the thing you really

00:06:02,380 --> 00:06:07,060
used to what you expect basically when

00:06:04,840 --> 00:06:09,430
I'm not Ritu released you just update

00:06:07,060 --> 00:06:17,080
the next pointer the previous pointer

00:06:09,430 --> 00:06:18,460
and you get the so - or - that way but

00:06:17,080 --> 00:06:21,699
when you have to aerospace

00:06:18,460 --> 00:06:23,500
I'd say for instance a GPU it's becoming

00:06:21,699 --> 00:06:26,650
much more complex no you need a pointer

00:06:23,500 --> 00:06:28,120
for the GPU two pointers for GPU because

00:06:26,650 --> 00:06:31,360
it's doubly linked list so you need a

00:06:28,120 --> 00:06:33,610
GPU preb and a GPU next water and this

00:06:31,360 --> 00:06:35,229
is what becomes the same function

00:06:33,610 --> 00:06:37,960
becomes much more complex and VC's only

00:06:35,229 --> 00:06:41,650
with one device one GPU nobody we're

00:06:37,960 --> 00:06:43,240
saying a computer with 32 GPU I'll take

00:06:41,650 --> 00:06:45,460
linky you can get away with only using

00:06:43,240 --> 00:06:47,350
one address space for 32 GPU but in some

00:06:45,460 --> 00:06:48,669
cases you will have 32 different idea

00:06:47,350 --> 00:06:51,490
space so that doesn't mean you will need

00:06:48,669 --> 00:06:54,070
to repeat that 42 times obviously it's

00:06:51,490 --> 00:06:56,229
you know it's it's making people crazy

00:06:54,070 --> 00:07:05,370
really we don't want to do that it's

00:06:56,229 --> 00:07:07,510
it's really cumbersome and basically

00:07:05,370 --> 00:07:11,169
adding this pointer for every address

00:07:07,510 --> 00:07:12,940
space and I think also to use different

00:07:11,169 --> 00:07:16,300
API so you know you will have to use

00:07:12,940 --> 00:07:17,860
OpenCL cuda or whatever you using to

00:07:16,300 --> 00:07:19,150
allocate memory for each of your writing

00:07:17,860 --> 00:07:22,120
space it's really becoming really really

00:07:19,150 --> 00:07:24,880
tedious we see people developing library

00:07:22,120 --> 00:07:26,440
we see people developing a simple first

00:07:24,880 --> 00:07:29,110
class wrapper and stuff like that a

00:07:26,440 --> 00:07:30,760
smart pointer for GPU and all that it's

00:07:29,110 --> 00:07:34,870
a lot of instrument a lot of engineering

00:07:30,760 --> 00:07:36,690
time it's really really something where

00:07:34,870 --> 00:07:39,910
we'll be wasting their time doing that

00:07:36,690 --> 00:07:41,590
and you have so you have to wait you do

00:07:39,910 --> 00:07:43,360
that the first one is the one I just

00:07:41,590 --> 00:07:44,830
show you you just grow the data

00:07:43,360 --> 00:07:47,080
structure to add pointers for every

00:07:44,830 --> 00:07:49,349
other space you care about so if you

00:07:47,080 --> 00:07:52,270
have to address space you're gonna have

00:07:49,349 --> 00:07:56,560
you're gonna have two pointers one for

00:07:52,270 --> 00:07:58,210
each other space obviously you kind of

00:07:56,560 --> 00:07:59,889
wasting memory here because you are you

00:07:58,210 --> 00:08:03,160
are adding more fuel to your that up

00:07:59,889 --> 00:08:06,400
structures to be able to catch to have

00:08:03,160 --> 00:08:08,169
all this array space build ways to

00:08:06,400 --> 00:08:09,610
duplicate the data structure on each

00:08:08,169 --> 00:08:12,250
other a space so every time you have a

00:08:09,610 --> 00:08:13,719
list you just copy the list to the GTRs

00:08:12,250 --> 00:08:16,680
space and that means you duplicate the

00:08:13,719 --> 00:08:18,660
list on the GPRA space and

00:08:16,680 --> 00:08:20,700
the advantages a zero is like you can

00:08:18,660 --> 00:08:23,190
have one set of function that does that

00:08:20,700 --> 00:08:24,840
and you can do only use the extra memory

00:08:23,190 --> 00:08:27,830
only when you're actually actively using

00:08:24,840 --> 00:08:29,790
the dot structure on your GPU but

00:08:27,830 --> 00:08:31,200
obviously the drawback is that you have

00:08:29,790 --> 00:08:33,210
to keep all copy synchronized between

00:08:31,200 --> 00:08:35,850
each of them and its really argh and

00:08:33,210 --> 00:08:40,110
tedious and you wasting memory of memory

00:08:35,850 --> 00:08:41,370
boundaries and all that so I think at

00:08:40,110 --> 00:08:42,600
this point it's pretty clear for

00:08:41,370 --> 00:08:45,300
everybody in the industry that it's

00:08:42,600 --> 00:08:48,360
really a very rough run ultimately and

00:08:45,300 --> 00:08:49,890
after debug people you know wasting time

00:08:48,360 --> 00:08:51,090
and spending a lot of time just trying

00:08:49,890 --> 00:08:53,490
to debug something that goes wrong

00:08:51,090 --> 00:08:55,080
because we just forget you've got one

00:08:53,490 --> 00:08:56,790
pointer somewhere in their data

00:08:55,080 --> 00:08:58,050
structure and so similarly everything

00:08:56,790 --> 00:08:59,970
goes awry because you're just accessing

00:08:58,050 --> 00:09:03,170
motors are invalid in one address space

00:08:59,970 --> 00:09:08,880
but that not in user address space so

00:09:03,170 --> 00:09:11,760
let's work I mean the the sure which

00:09:08,880 --> 00:09:14,130
will address space ID really the idea is

00:09:11,760 --> 00:09:16,500
you want to share the same processor a

00:09:14,130 --> 00:09:18,450
space with the device which means you

00:09:16,500 --> 00:09:19,980
want to use the CPU page table as kind

00:09:18,450 --> 00:09:23,100
of a canonical area space for everybody

00:09:19,980 --> 00:09:25,290
every device and so that device like GPU

00:09:23,100 --> 00:09:28,500
or FPGA will use the same airspace and

00:09:25,290 --> 00:09:30,000
share the same useful address that will

00:09:28,500 --> 00:09:31,920
map to the same physical memory

00:09:30,000 --> 00:09:34,260
underneath that does mean that any

00:09:31,920 --> 00:09:35,700
pointers will be valid on GPU or on CPU

00:09:34,260 --> 00:09:37,650
and it will always point to the same

00:09:35,700 --> 00:09:39,540
memory in the end because it's the same

00:09:37,650 --> 00:09:42,060
physical memory that points for each

00:09:39,540 --> 00:09:44,670
virtual address and where it's two-way

00:09:42,060 --> 00:09:47,910
to do that you can do it in app where

00:09:44,670 --> 00:09:50,340
for instance with iommu and HTS PSID and

00:09:47,910 --> 00:09:52,740
i will go over what it is and you can

00:09:50,340 --> 00:09:54,390
also do it in software with

00:09:52,740 --> 00:09:56,130
mirroring the CPU vegetable into the

00:09:54,390 --> 00:10:00,120
device vegetable and keeping both

00:09:56,130 --> 00:10:01,650
synchronized at every point in time and

00:10:00,120 --> 00:10:03,810
you can mix and match actually both

00:10:01,650 --> 00:10:05,430
solution if you want and we'll see why

00:10:03,810 --> 00:10:08,580
it's actually an idea that some people

00:10:05,430 --> 00:10:12,230
actually interested in a point of

00:10:08,580 --> 00:10:14,310
terminology now you will see SVA or SVM

00:10:12,230 --> 00:10:16,650
depending on where you're talking to

00:10:14,310 --> 00:10:18,330
it's exactly the same thing so one is a

00:10:16,650 --> 00:10:20,490
sure virtual address and we'll show

00:10:18,330 --> 00:10:23,430
virtual memory it's really the same idea

00:10:20,490 --> 00:10:25,110
really beyond it to just you know we

00:10:23,430 --> 00:10:28,760
always use different name for the same

00:10:25,110 --> 00:10:33,780
thing so

00:10:28,760 --> 00:10:35,310
SVA without where is using iommu and you

00:10:33,780 --> 00:10:37,710
have to thing really you have the

00:10:35,310 --> 00:10:42,840
address translation service and you have

00:10:37,710 --> 00:10:46,530
the process address space ID the Evenflo

00:10:42,840 --> 00:10:48,360
is pretty simple the device request a

00:10:46,530 --> 00:10:50,970
virtual address translation be ats

00:10:48,360 --> 00:10:55,350
against a given psi D I guess in a given

00:10:50,970 --> 00:10:58,620
process ID Pio menu Maps V psi D to a

00:10:55,350 --> 00:11:00,720
given CPU page table the iommu then

00:10:58,620 --> 00:11:03,120
we'll walk down the cpu page table and

00:11:00,720 --> 00:11:05,280
we look up what is the physical address

00:11:03,120 --> 00:11:06,870
for the virtual address exactly as your

00:11:05,280 --> 00:11:09,150
CPU is doing when it's walking down the

00:11:06,870 --> 00:11:11,130
page table on the CPU it's exact

00:11:09,150 --> 00:11:12,690
sometime often most on most cpu at

00:11:11,130 --> 00:11:14,910
existing CPU it's actually the exact

00:11:12,690 --> 00:11:17,720
same silicon underneath Eric is actually

00:11:14,910 --> 00:11:20,280
used for boss for a iommu and the CPU

00:11:17,720 --> 00:11:23,000
then the iron were applied to the device

00:11:20,280 --> 00:11:24,570
giving the device of physical address

00:11:23,000 --> 00:11:26,250
corresponding to the virtual address

00:11:24,570 --> 00:11:28,230
that was requested at first step and

00:11:26,250 --> 00:11:30,000
then you use the device directly use the

00:11:28,230 --> 00:11:33,390
physical address for any more memory

00:11:30,000 --> 00:11:35,760
access obviously like CPU device and

00:11:33,390 --> 00:11:37,500
climb on TLB to Kashani any request we

00:11:35,760 --> 00:11:41,580
have done so far so that we don't always

00:11:37,500 --> 00:11:43,050
have to again request the same mapping

00:11:41,580 --> 00:11:44,670
between here virtual address and the

00:11:43,050 --> 00:11:46,800
physical memory we try to catch that so

00:11:44,670 --> 00:11:48,930
they don't have to constantly ask the

00:11:46,800 --> 00:11:56,700
same thing to the iron so this is how

00:11:48,930 --> 00:11:58,800
you do it in our where in software it's

00:11:56,700 --> 00:12:00,870
not that much different really you are

00:11:58,800 --> 00:12:04,200
copying the CPU page table into the

00:12:00,870 --> 00:12:05,550
device page level and then you keep the

00:12:04,200 --> 00:12:06,900
CPU and the VAS spaceship will

00:12:05,550 --> 00:12:09,450
synchronize at all time

00:12:06,900 --> 00:12:10,650
you don't want adding any point in time

00:12:09,450 --> 00:12:12,000
you don't want to have a mismatch

00:12:10,650 --> 00:12:15,090
between the two because otherwise it

00:12:12,000 --> 00:12:16,200
means that the CPU or GPU or FPGA we'll

00:12:15,090 --> 00:12:18,060
look at different data

00:12:16,200 --> 00:12:19,770
physical data because it pointing to a

00:12:18,060 --> 00:12:23,340
different physical memory it's something

00:12:19,770 --> 00:12:26,310
you want to avoid at all point so yeah

00:12:23,340 --> 00:12:27,570
the cornerstone is having at any time at

00:12:26,310 --> 00:12:28,860
any point in time you want to have the

00:12:27,570 --> 00:12:31,320
same way always point to the same

00:12:28,860 --> 00:12:33,390
physical memory so the event flow at

00:12:31,320 --> 00:12:34,860
this time is selecting the same really

00:12:33,390 --> 00:12:36,690
the device fault

00:12:34,860 --> 00:12:38,280
so like the device doesn't have enough

00:12:36,690 --> 00:12:41,760
inside its page table so we take a fault

00:12:38,280 --> 00:12:44,250
and it goes a trigger interrupt yeah

00:12:41,760 --> 00:12:45,959
is taken by the device driver inside the

00:12:44,250 --> 00:12:48,240
kernel the device drivers and requests -

00:12:45,959 --> 00:12:50,940
for instance hmm - mural the faulting

00:12:48,240 --> 00:12:52,050
ritual address and then hmm what what I

00:12:50,940 --> 00:12:54,120
shouldn't does he's going to take a

00:12:52,050 --> 00:12:57,149
snapshot of the CPU page table you're

00:12:54,120 --> 00:12:59,070
gonna map the page for you inside the

00:12:57,149 --> 00:13:01,800
iommu so that the device can directly

00:12:59,070 --> 00:13:03,600
access right the right memory and then

00:13:01,800 --> 00:13:05,519
the device driver will get the answer

00:13:03,600 --> 00:13:07,440
from from me hmm snapshot and will

00:13:05,519 --> 00:13:09,060
populate the device page table and then

00:13:07,440 --> 00:13:10,850
we resume the device so that the device

00:13:09,060 --> 00:13:14,220
can come doing whatever it was doing

00:13:10,850 --> 00:13:15,810
it's exactly as the CPU page fault it

00:13:14,220 --> 00:13:17,279
just this time you're not trying to

00:13:15,810 --> 00:13:19,740
populate the CPU vegetable trying to

00:13:17,279 --> 00:13:21,360
pour it a device vegetable so it's exact

00:13:19,740 --> 00:13:23,250
same thing as you see when you when you

00:13:21,360 --> 00:13:25,440
take a CPU page fault really

00:13:23,250 --> 00:13:27,209
we only whoops and go cha here is that

00:13:25,440 --> 00:13:29,610
you need to make sure that there is no

00:13:27,209 --> 00:13:30,930
change to the CPU vegetable between the

00:13:29,610 --> 00:13:32,490
time you start doing the snapshot and a

00:13:30,930 --> 00:13:33,810
time program the device page table you

00:13:32,490 --> 00:13:34,949
want to make sure that it's always going

00:13:33,810 --> 00:13:38,130
to be the same physical address

00:13:34,949 --> 00:13:40,079
underneath the same virtual address so

00:13:38,130 --> 00:13:42,029
what we do right now is always hmm it's

00:13:40,079 --> 00:13:46,800
mostly using you know the MM unity fire

00:13:42,029 --> 00:13:48,600
inside the kernel and yeah so you we

00:13:46,800 --> 00:13:50,459
have to constantly monitor any chance to

00:13:48,600 --> 00:13:52,319
the CPU page table and by the Linux

00:13:50,459 --> 00:13:54,319
kernel so that we can all constantly get

00:13:52,319 --> 00:13:59,010
the device page table at the same time

00:13:54,319 --> 00:14:00,630
bit of tedious but it does work so then

00:13:59,010 --> 00:14:02,160
the question becomes you know what is

00:14:00,630 --> 00:14:03,750
the best you know if I tell you there's

00:14:02,160 --> 00:14:06,510
two solution maybe varies one is better

00:14:03,750 --> 00:14:08,699
than the others and there is point cons

00:14:06,510 --> 00:14:11,370
to both of them so I just want to go

00:14:08,699 --> 00:14:13,260
over some some of it and see why you

00:14:11,370 --> 00:14:15,690
will want to pick one or the other

00:14:13,260 --> 00:14:17,310
so we with our the good thing is you

00:14:15,690 --> 00:14:20,310
only have one page table a CPU page

00:14:17,310 --> 00:14:22,139
table in it does mean that you don't

00:14:20,310 --> 00:14:23,760
waste more memory it also means that at

00:14:22,139 --> 00:14:25,019
any point in time you sure that you have

00:14:23,760 --> 00:14:26,130
the same year so otherwise that point to

00:14:25,019 --> 00:14:27,420
the same physical address because you

00:14:26,130 --> 00:14:32,910
only have one place where that

00:14:27,420 --> 00:14:34,310
information is you also don't need to

00:14:32,910 --> 00:14:37,980
have too much code inside a kernel

00:14:34,310 --> 00:14:39,600
enabling our hardware solution only

00:14:37,980 --> 00:14:43,290
takes about 20 line of code inside a

00:14:39,600 --> 00:14:44,639
driver assuming you obviously you device

00:14:43,290 --> 00:14:46,260
need to be able to export all these

00:14:44,639 --> 00:14:48,060
because it's all up where so you know

00:14:46,260 --> 00:14:52,019
it's new PCI Express protocol it's a new

00:14:48,060 --> 00:14:53,530
copy with CCI X or whatnot there is a

00:14:52,019 --> 00:14:57,160
steal couple things that

00:14:53,530 --> 00:14:59,890
kind of a kind of an issue yeah you can

00:14:57,160 --> 00:15:05,140
only access memory that is accessible by

00:14:59,890 --> 00:15:07,360
the CPU and on some platform you also

00:15:05,140 --> 00:15:10,270
have a limit on the number of active

00:15:07,360 --> 00:15:12,400
PSID active process ID so you know it

00:15:10,270 --> 00:15:14,380
used to be eight process IDs and go to

00:15:12,400 --> 00:15:17,860
16 I think though most of the platform

00:15:14,380 --> 00:15:19,930
are 256 process ID often what you do you

00:15:17,860 --> 00:15:21,730
recycle the base ID so you know when a

00:15:19,930 --> 00:15:23,530
process is not active actually so you

00:15:21,730 --> 00:15:27,370
swap out the process and you associate

00:15:23,530 --> 00:15:30,580
the process with a new PS ID but you

00:15:27,370 --> 00:15:32,590
know it still kind of a can can become a

00:15:30,580 --> 00:15:34,300
limit in some cases when you have a user

00:15:32,590 --> 00:15:37,960
whose lot of process running the same

00:15:34,300 --> 00:15:38,890
time with via software solution the good

00:15:37,960 --> 00:15:42,220
thing is that you can use actually

00:15:38,890 --> 00:15:44,560
device memory and just a footnote here a

00:15:42,220 --> 00:15:46,750
PCI Express is not cache go around which

00:15:44,560 --> 00:15:49,810
means that CPU access to device memory

00:15:46,750 --> 00:15:51,160
through the PCI Express bar is actually

00:15:49,810 --> 00:15:52,840
undefined inside the PCI Express

00:15:51,160 --> 00:15:56,980
specification so what happened is

00:15:52,840 --> 00:15:59,350
undefined you can access it as I hope

00:15:56,980 --> 00:16:01,030
and so it will depend on the platform

00:15:59,350 --> 00:16:04,690
and how I was defined and most of the

00:16:01,030 --> 00:16:06,910
time this is very loose our CPU do what

00:16:04,690 --> 00:16:09,310
we define inside the platform so there's

00:16:06,910 --> 00:16:10,630
no notes on our way we specially

00:16:09,310 --> 00:16:12,850
expressed and and I will get back to

00:16:10,630 --> 00:16:15,850
that there's no limit on the number of

00:16:12,850 --> 00:16:17,380
process but but the issuer that you have

00:16:15,850 --> 00:16:18,580
multiple page table you have the CPU

00:16:17,380 --> 00:16:20,260
vegetable and you will have a vegetable

00:16:18,580 --> 00:16:22,390
for every your signal device you have so

00:16:20,260 --> 00:16:23,830
you can have you know if you have 32 GPU

00:16:22,390 --> 00:16:27,670
you're gonna have 32 page-level

00:16:23,830 --> 00:16:29,140
please CPU 1 sacré nation can become

00:16:27,670 --> 00:16:31,330
first owned it's a lot of water played

00:16:29,140 --> 00:16:33,040
card so it's done by shamim so the count

00:16:31,330 --> 00:16:34,510
is doing most of the thing and and

00:16:33,040 --> 00:16:37,780
private only have to provide a couple

00:16:34,510 --> 00:16:39,250
callbacks so that to keep fingering but

00:16:37,780 --> 00:16:42,870
you still need quite a lot of bits of

00:16:39,250 --> 00:16:42,870
driver code to to achieve all that

00:16:44,990 --> 00:16:52,100
so I can say at one point you don't have

00:16:49,700 --> 00:16:53,840
you can share the boss solution at the

00:16:52,100 --> 00:16:54,380
same time you can mix Yahoo and software

00:16:53,840 --> 00:16:56,600
solution

00:16:54,380 --> 00:17:02,630
assuming you or Albert can actually do

00:16:56,600 --> 00:17:06,620
that so you can have the device use the

00:17:02,630 --> 00:17:09,500
r-word solution for for a for the same

00:17:06,620 --> 00:17:11,390
range of virtual address and and simply

00:17:09,500 --> 00:17:12,980
because you actually use a device page

00:17:11,390 --> 00:17:14,720
table inside the device page table for

00:17:12,980 --> 00:17:17,870
every entry you say use the app

00:17:14,720 --> 00:17:20,089
resolution or use the device vegetable

00:17:17,870 --> 00:17:23,990
country so it's like a flag inside the

00:17:20,089 --> 00:17:25,550
device device page table you need our

00:17:23,990 --> 00:17:28,100
support for that but but you know it's

00:17:25,550 --> 00:17:30,050
it's something you can do and in couple

00:17:28,100 --> 00:17:33,170
device actually can do that what we can

00:17:30,050 --> 00:17:34,580
do it or not is a question one of the

00:17:33,170 --> 00:17:35,690
nice thing when you mix and match best

00:17:34,580 --> 00:17:38,120
thing is that you can actually use a

00:17:35,690 --> 00:17:41,540
device memory so you can have both you

00:17:38,120 --> 00:17:43,130
know the best of both world by Lee you

00:17:41,540 --> 00:17:45,500
can also do few things that are kind of

00:17:43,130 --> 00:17:47,030
interesting you can reserve some range

00:17:45,500 --> 00:17:49,130
of your virtual address space for

00:17:47,030 --> 00:17:50,600
devices only for instance if you have a

00:17:49,130 --> 00:17:52,010
computer application that also have

00:17:50,600 --> 00:17:53,750
Vulcan or Penny shell running on the

00:17:52,010 --> 00:17:55,250
side you want to reserve some some

00:17:53,750 --> 00:17:58,190
shrink of address space virtual address

00:17:55,250 --> 00:17:59,600
space for Vulcan OpenGL and it was right

00:17:58,190 --> 00:18:04,130
here you have that actually it doesn't

00:17:59,600 --> 00:18:06,260
expose every space and yeah and you only

00:18:04,130 --> 00:18:09,560
need to to to populate the device page

00:18:06,260 --> 00:18:11,330
table for for virtual addresses that you

00:18:09,560 --> 00:18:17,590
want to use on the device when you want

00:18:11,330 --> 00:18:19,910
to use device memory so device memory

00:18:17,590 --> 00:18:22,190
why I'm making such a big deal about

00:18:19,910 --> 00:18:25,790
device memory it's it's kind of

00:18:22,190 --> 00:18:29,020
mind-blowing so the I am bandwidth on

00:18:25,790 --> 00:18:31,580
device memory is 800 gigabyte its bite

00:18:29,020 --> 00:18:33,200
you haven't seen our days I think we

00:18:31,580 --> 00:18:36,680
just announced next generation that we

00:18:33,200 --> 00:18:38,030
want to rob ight and you have to in

00:18:36,680 --> 00:18:43,400
corporation you have to think that PCI

00:18:38,030 --> 00:18:47,060
Express 369 is 30 30 gigabyte and 60

00:18:43,400 --> 00:18:51,290
goodbye to you peace Express for so you

00:18:47,060 --> 00:18:52,940
know it's 10 times slower and someone

00:18:51,290 --> 00:18:55,400
wasn't that if you look at about latency

00:18:52,940 --> 00:18:57,020
actual add-ons he's also a player and

00:18:55,400 --> 00:18:58,250
you know when I tell you eight hundred

00:18:57,020 --> 00:18:58,400
gigabyte you say well there is no way

00:18:58,250 --> 00:19:00,410
you

00:18:58,400 --> 00:19:04,640
I actually saturated that and it exactly

00:19:00,410 --> 00:19:07,340
very easy on GPU to to reach 80% 90% of

00:19:04,640 --> 00:19:08,870
our memory bandwidth was that too much

00:19:07,340 --> 00:19:10,370
effort actually really easily with

00:19:08,870 --> 00:19:12,050
simple program without trying to do

00:19:10,370 --> 00:19:13,940
anything tricky and people actually

00:19:12,050 --> 00:19:15,680
spend time to optimize for programming

00:19:13,940 --> 00:19:17,450
the GPU they can actually reach in 99%

00:19:15,680 --> 00:19:20,270
of the other theoretical bandwidth

00:19:17,450 --> 00:19:22,670
really easily so it's a this kind of man

00:19:20,270 --> 00:19:25,940
who is exactly actually put to use on

00:19:22,670 --> 00:19:27,200
GPU and it really works and also when

00:19:25,940 --> 00:19:29,810
you use device memory of you so you are

00:19:27,200 --> 00:19:31,040
freeing the PCI Express bandwidth and

00:19:29,810 --> 00:19:32,240
you can do all the stuff in the

00:19:31,040 --> 00:19:34,340
background you can use the PCI Express

00:19:32,240 --> 00:19:36,200
boundaries you have to do DMA and stuff

00:19:34,340 --> 00:19:38,510
like that you know to do janitorial

00:19:36,200 --> 00:19:44,150
tasks basically and move stuff around

00:19:38,510 --> 00:19:45,740
while the active computer is running but

00:19:44,150 --> 00:19:49,220
very couple issue would be a device

00:19:45,740 --> 00:19:51,050
memory first the CPU might not be able

00:19:49,220 --> 00:19:52,970
to access it at home because you have

00:19:51,050 --> 00:19:55,430
inside PCI Express once you have what

00:19:52,970 --> 00:19:57,980
they call the bar which is a region of

00:19:55,430 --> 00:19:59,810
memory that is actually windows inside

00:19:57,980 --> 00:20:02,180
the inside your device memory so if your

00:19:59,810 --> 00:20:04,660
device min or a 16 gigabyte by default

00:20:02,180 --> 00:20:07,340
for a long time the bar window size was

00:20:04,660 --> 00:20:10,070
256 megabytes so you know you can only

00:20:07,340 --> 00:20:13,730
see 256 megabytes of your 16 gigabyte of

00:20:10,070 --> 00:20:15,050
memory which is really bad it's no

00:20:13,730 --> 00:20:17,030
longer so much an issue there have been

00:20:15,050 --> 00:20:19,610
a lot of patches co-op ashes up

00:20:17,030 --> 00:20:22,040
streaming last last few months to make

00:20:19,610 --> 00:20:23,150
so that we can recite the bar on most

00:20:22,040 --> 00:20:24,740
platform and something that does work

00:20:23,150 --> 00:20:27,470
probably so you can actually map the

00:20:24,740 --> 00:20:29,720
sitting gigabyte or more obviously you

00:20:27,470 --> 00:20:32,030
kind of rely on you know 64-bit

00:20:29,720 --> 00:20:34,760
architecture because 142 bit you really

00:20:32,030 --> 00:20:37,190
you don't have much space for that and

00:20:34,760 --> 00:20:38,930
the biggest issue of all is really that

00:20:37,190 --> 00:20:40,310
PCI spreads on support cache memory like

00:20:38,930 --> 00:20:42,530
I say if you look at the PCI Express

00:20:40,310 --> 00:20:45,590
specification they will tell you that

00:20:42,530 --> 00:20:48,050
any atomic access or any any atomic

00:20:45,590 --> 00:20:51,260
access by CPU is actually undefined and

00:20:48,050 --> 00:20:53,930
if you look at Intel or AMD

00:20:51,260 --> 00:20:55,400
platform specification and they also say

00:20:53,930 --> 00:20:56,780
it's on the phone and we don't we don't

00:20:55,400 --> 00:20:58,550
commit to anything they don't say what's

00:20:56,780 --> 00:21:00,320
gonna happen we know you know they don't

00:20:58,550 --> 00:21:02,480
give you any guarantee about anything so

00:21:00,320 --> 00:21:03,980
it's just what's gonna happen can change

00:21:02,480 --> 00:21:06,590
from one platform to be next and from

00:21:03,980 --> 00:21:08,030
once if you to be next and that's a

00:21:06,590 --> 00:21:11,080
reason what you have seen in lately

00:21:08,030 --> 00:21:11,080
things like

00:21:11,149 --> 00:21:21,200
and not only is it is undefined the

00:21:17,480 --> 00:21:24,110
results actually are undefined yeah yeah

00:21:21,200 --> 00:21:25,690
thank you you know I tried to do it

00:21:24,110 --> 00:21:27,649
actually so on some platform you like we

00:21:25,690 --> 00:21:29,120
something happens the right goes through

00:21:27,649 --> 00:21:30,679
but very similar to me CD at all so very

00:21:29,120 --> 00:21:32,269
it's like so it's not a to me but

00:21:30,679 --> 00:21:33,710
something did happen you know the

00:21:32,269 --> 00:21:35,179
platform likely there was a bunch of

00:21:33,710 --> 00:21:36,139
oops and suddenly the carnival started

00:21:35,179 --> 00:21:38,179
to freak out and I don't know why

00:21:36,139 --> 00:21:39,379
exactly was acting hours so I like okay

00:21:38,179 --> 00:21:41,659
so it's really not a good idea to do it

00:21:39,379 --> 00:21:43,340
but yet it's on the fun and you don't

00:21:41,659 --> 00:21:45,980
want to try to define it because it's

00:21:43,340 --> 00:21:47,059
really only fine so yeah so that's one

00:21:45,980 --> 00:21:51,190
of the reason you've been saying lately

00:21:47,059 --> 00:21:54,259
things like open Kathy from IBM CCI X

00:21:51,190 --> 00:21:58,039
any link egg GM I and bunch of other

00:21:54,259 --> 00:22:00,080
stuff all these are easier building on

00:21:58,039 --> 00:22:01,850
top of PCI Express or defining a new bus

00:22:00,080 --> 00:22:03,289
where you have cash currency so that is

00:22:01,850 --> 00:22:06,499
if you can access cash currently is a

00:22:03,289 --> 00:22:08,749
device memory but you know it's it's a

00:22:06,499 --> 00:22:10,220
long long time in the making is taking a

00:22:08,749 --> 00:22:12,379
lot of time we don't know when you're

00:22:10,220 --> 00:22:13,850
gonna actually see except Cappy Cappy is

00:22:12,379 --> 00:22:15,230
really a Kathy and Lincoln are really

00:22:13,850 --> 00:22:17,029
the two thing you can buy today but it's

00:22:15,230 --> 00:22:19,249
not really a community thing you know

00:22:17,029 --> 00:22:24,710
it's a on one platform and so it's not

00:22:19,249 --> 00:22:26,779
not generate to everybody so let's go

00:22:24,710 --> 00:22:28,460
back to memory you know like I say at

00:22:26,779 --> 00:22:30,259
the beginning you can mean great memory

00:22:28,460 --> 00:22:32,720
the virtual address to physical address

00:22:30,259 --> 00:22:34,820
can change over time and it's pretty

00:22:32,720 --> 00:22:36,440
common actually on Linux it's been you

00:22:34,820 --> 00:22:38,330
know it's been a very common thing on

00:22:36,440 --> 00:22:40,159
new March teacher when you actually you

00:22:38,330 --> 00:22:42,200
want to try to put everything on the

00:22:40,159 --> 00:22:44,899
same note I just also recommend when you

00:22:42,200 --> 00:22:46,970
do memory reclaim or when you do some

00:22:44,899 --> 00:22:47,929
other stuff some of the memory activity

00:22:46,970 --> 00:22:50,119
happening in southern scale will

00:22:47,929 --> 00:22:51,740
actually try to migrate a page around

00:22:50,119 --> 00:22:53,090
when you do I don't know continuous

00:22:51,740 --> 00:22:55,759
being a relocation I want to try to

00:22:53,090 --> 00:22:57,519
compaction or raise many things I don't

00:22:55,759 --> 00:22:59,720
external it can actually trigger

00:22:57,519 --> 00:23:03,320
exchange between the virtual address and

00:22:59,720 --> 00:23:05,509
the physical address underneath so you

00:23:03,320 --> 00:23:06,679
can immigrate virtual address from one

00:23:05,509 --> 00:23:12,169
physical memory to another physical

00:23:06,679 --> 00:23:14,029
memory and most of the time you know

00:23:12,169 --> 00:23:16,399
like you you have when you can do that

00:23:14,029 --> 00:23:18,019
you have already to you're facing to

00:23:16,399 --> 00:23:20,000
choice you can either do it explicitly

00:23:18,019 --> 00:23:21,830
have the applications say I want to move

00:23:20,000 --> 00:23:22,320
memory on that node I want to move

00:23:21,830 --> 00:23:23,549
memory

00:23:22,320 --> 00:23:25,380
and varan want to use that kind of

00:23:23,549 --> 00:23:26,940
physical memory and you have also the

00:23:25,380 --> 00:23:28,980
automatic thing and you can have a mix

00:23:26,940 --> 00:23:31,799
of two you know it's not black and white

00:23:28,980 --> 00:23:34,049
it's it can be a share of other two and

00:23:31,799 --> 00:23:35,970
right now the two things the most common

00:23:34,049 --> 00:23:38,340
thing is M bind for explicit memory

00:23:35,970 --> 00:23:40,169
selection on Numa and you can also use

00:23:38,340 --> 00:23:42,360
memory security in some way to try to

00:23:40,169 --> 00:23:45,210
limit the process to some kind of

00:23:42,360 --> 00:23:46,820
physical memory or to make stuff is the

00:23:45,210 --> 00:23:50,279
most common one is autónoma obviously

00:23:46,820 --> 00:23:56,610
it's all about CPU memory it's all about

00:23:50,279 --> 00:23:58,799
new mind stuff like that so if you can

00:23:56,610 --> 00:24:00,539
move memory around obviously what you if

00:23:58,799 --> 00:24:03,570
you do that it's obviously because you

00:24:00,539 --> 00:24:05,580
want to use the best memory for what it

00:24:03,570 --> 00:24:07,019
is you're doing and so when you when

00:24:05,580 --> 00:24:08,789
you're working on some data structure on

00:24:07,019 --> 00:24:10,230
the GPU you want to use the GPU memory

00:24:08,789 --> 00:24:12,149
because it's where you're gonna get the

00:24:10,230 --> 00:24:14,549
most performance most performance for

00:24:12,149 --> 00:24:16,500
the bugs so it will change over time

00:24:14,549 --> 00:24:18,539
depending on what happened so you know

00:24:16,500 --> 00:24:20,159
if you're working on a CPU then you

00:24:18,539 --> 00:24:21,870
probably want to have your memory inside

00:24:20,159 --> 00:24:24,179
the CPU memory inside the fastest CPU

00:24:21,870 --> 00:24:25,649
where you can have and if you're working

00:24:24,179 --> 00:24:29,039
on the device you want to use a device

00:24:25,649 --> 00:24:30,570
memory sometimes same data structure can

00:24:29,039 --> 00:24:33,690
be used concurrently by both CPU and

00:24:30,570 --> 00:24:35,429
device you know you never can can tell

00:24:33,690 --> 00:24:38,580
what you know you can do anything wrong

00:24:35,429 --> 00:24:40,860
so new also kind of complicate things

00:24:38,580 --> 00:24:42,809
because most of the time the device is

00:24:40,860 --> 00:24:45,210
actually linked to an am I not so you

00:24:42,809 --> 00:24:47,279
know the devices are also tied I also

00:24:45,210 --> 00:24:54,750
play inside the new minority topology

00:24:47,279 --> 00:24:56,279
but I will get back to that then you can

00:24:54,750 --> 00:24:59,250
also have multiple device so like I say

00:24:56,279 --> 00:25:02,149
42 GPU on a note it's something you're

00:24:59,250 --> 00:25:04,799
gonna see so it's kind of a lot advice

00:25:02,149 --> 00:25:07,080
you cannot expect also to have all your

00:25:04,799 --> 00:25:09,330
application provide int and do explicit

00:25:07,080 --> 00:25:11,220
basement sometimes you know it all

00:25:09,330 --> 00:25:12,840
depends on how much time the programmers

00:25:11,220 --> 00:25:17,070
plan on optimizing things for your

00:25:12,840 --> 00:25:18,600
platform if you want to do automatic

00:25:17,070 --> 00:25:20,879
placements you know if you want to try

00:25:18,600 --> 00:25:22,470
to do that if you not then it does mean

00:25:20,879 --> 00:25:24,720
enough to monitor access so you have to

00:25:22,470 --> 00:25:26,490
monitor okay this program is accessing

00:25:24,720 --> 00:25:27,960
that part and that device acts in that

00:25:26,490 --> 00:25:30,059
part of the memory so it does mean you

00:25:27,960 --> 00:25:31,559
have to actually use processes to do

00:25:30,059 --> 00:25:33,480
that to that tracking need to use

00:25:31,559 --> 00:25:35,670
memories if you are work under s and all

00:25:33,480 --> 00:25:37,740
that so automate place

00:25:35,670 --> 00:25:39,660
is also something that actually takes

00:25:37,740 --> 00:25:41,790
time and what sauce is away from your

00:25:39,660 --> 00:25:45,720
program but it can be a it can be a win

00:25:41,790 --> 00:25:48,090
overall and very the whole issue also

00:25:45,720 --> 00:25:49,140
with automatic placement like lag for

00:25:48,090 --> 00:25:51,390
instance you know you saw you're

00:25:49,140 --> 00:25:52,680
monitoring the access and you take time

00:25:51,390 --> 00:25:54,390
you mature and you see okay this is

00:25:52,680 --> 00:25:56,220
accessing the device memory the device

00:25:54,390 --> 00:25:58,050
and so on and so forth and you then you

00:25:56,220 --> 00:25:59,850
decide to make a decision okay I'm gonna

00:25:58,050 --> 00:26:01,350
move the memory because really it's

00:25:59,850 --> 00:26:03,180
really accessing that ring a lot so I

00:26:01,350 --> 00:26:04,820
want to move it but by the time you

00:26:03,180 --> 00:26:07,200
actually make the decision and move it

00:26:04,820 --> 00:26:08,940
the access pattern can change

00:26:07,200 --> 00:26:10,740
drastically and be completely different

00:26:08,940 --> 00:26:15,480
from from the thing that actually made

00:26:10,740 --> 00:26:16,710
you make that decision but nonetheless I

00:26:15,480 --> 00:26:18,330
believe that we're going to want to have

00:26:16,710 --> 00:26:20,790
these two things we're going to want to

00:26:18,330 --> 00:26:23,550
have explicit memory placement so what

00:26:20,790 --> 00:26:24,930
we're going to want to have API for view

00:26:23,550 --> 00:26:26,010
space to be able to say okay I want to

00:26:24,930 --> 00:26:28,050
use that memory I want to use that

00:26:26,010 --> 00:26:29,850
memory and so on and so forth but I

00:26:28,050 --> 00:26:32,250
think long-term also probably want to

00:26:29,850 --> 00:26:33,900
have this kind of a kind of autonomy but

00:26:32,250 --> 00:26:37,950
also for device memory so that you can

00:26:33,900 --> 00:26:39,600
have things working more working better

00:26:37,950 --> 00:26:41,340
for application that don't spend too

00:26:39,600 --> 00:26:43,650
much time optimizing for for this kind

00:26:41,340 --> 00:26:45,750
of thing so yeah bottom line we're gonna

00:26:43,650 --> 00:26:51,240
need a new API for all these kind of

00:26:45,750 --> 00:26:54,090
thing and instantly it's it's not

00:26:51,240 --> 00:26:55,950
getting any easier really we have all

00:26:54,090 --> 00:26:57,510
this new technology popping up and

00:26:55,950 --> 00:27:01,050
pulling up on top of that you have the

00:26:57,510 --> 00:27:03,750
HBM ID man who is memory for CPU you

00:27:01,050 --> 00:27:05,820
have the main memory you have the

00:27:03,750 --> 00:27:08,580
personal memory you have the new memory

00:27:05,820 --> 00:27:11,970
technology also down the road with

00:27:08,580 --> 00:27:15,210
gigantic size but a lot slower latency

00:27:11,970 --> 00:27:17,940
and the smaller man weighs Numa abuse

00:27:15,210 --> 00:27:20,310
Lee so breaking all this mean that the

00:27:17,940 --> 00:27:21,750
system topology in the end it's becoming

00:27:20,310 --> 00:27:23,130
more like a network topology you know

00:27:21,750 --> 00:27:24,600
it's no longer you have two CPU and

00:27:23,130 --> 00:27:25,980
memory and everything is on Perry

00:27:24,600 --> 00:27:27,090
working at the same bandwidth and

00:27:25,980 --> 00:27:29,370
everything all the same I don't see and

00:27:27,090 --> 00:27:31,710
everybody is on the same same level no

00:27:29,370 --> 00:27:33,600
you have fast link slowly different

00:27:31,710 --> 00:27:35,910
paths and you can you can access really

00:27:33,600 --> 00:27:38,490
you have to thinks about your computer

00:27:35,910 --> 00:27:40,890
single computer as a network with

00:27:38,490 --> 00:27:43,200
multiple CPU or device accessing

00:27:40,890 --> 00:27:45,000
different memory and they have you know

00:27:43,200 --> 00:27:47,450
bottleneck on some link and better link

00:27:45,000 --> 00:27:50,269
on the other way

00:27:47,450 --> 00:27:51,799
and and things also you have to take it

00:27:50,269 --> 00:27:53,869
to things like India League or HDMI

00:27:51,799 --> 00:27:57,169
which is like GPU link and I just want

00:27:53,869 --> 00:27:58,489
to show you an example or it looks so

00:27:57,169 --> 00:28:01,999
this is a kind of a two circuit

00:27:58,489 --> 00:28:03,529
architecture with two GPU so you know on

00:28:01,999 --> 00:28:06,859
each circuit you have the PCI Express

00:28:03,529 --> 00:28:08,419
Woodbridge and then it's GPU is

00:28:06,859 --> 00:28:10,219
connected to the root bridge on H so ket

00:28:08,419 --> 00:28:12,289
and you have be seeping interconnect

00:28:10,219 --> 00:28:14,419
between the two circuit and then you

00:28:12,289 --> 00:28:16,489
have also a GPU link that links all the

00:28:14,419 --> 00:28:18,320
GPU together so you know you can have

00:28:16,489 --> 00:28:20,509
the GPU link that four hundred gigabyte

00:28:18,320 --> 00:28:22,579
per second and the PCI Express link have

00:28:20,509 --> 00:28:24,409
only thirty thirty gigabyte per second

00:28:22,579 --> 00:28:26,509
so beautifully when you have a GPU

00:28:24,409 --> 00:28:28,269
working on the same thing they want you

00:28:26,509 --> 00:28:30,799
want to use the GPU link and not use the

00:28:28,269 --> 00:28:32,690
PCR woodbridge and then CPU interconnect

00:28:30,799 --> 00:28:34,820
and go to VP celos or a root bridge and

00:28:32,690 --> 00:28:36,079
then go to the GPU you want to use the

00:28:34,820 --> 00:28:38,089
jeep hearing instead of using V other

00:28:36,079 --> 00:28:39,649
paths so it does mean that you have you

00:28:38,089 --> 00:28:41,570
have to select which path you want to

00:28:39,649 --> 00:28:43,249
use and you want to select the best path

00:28:41,570 --> 00:28:45,079
for whatever you're doing and you can

00:28:43,249 --> 00:28:47,899
use vo slow pass for doing janitorial

00:28:45,079 --> 00:28:49,700
tasks or background things and this is a

00:28:47,899 --> 00:28:52,820
simple example you have to think about

00:28:49,700 --> 00:28:54,589
thirty-two GPU and GPU connected not you

00:28:52,820 --> 00:28:57,789
know not on par with each other but with

00:28:54,589 --> 00:29:03,049
more complex graphically than this one

00:28:57,789 --> 00:29:06,229
so where we are really at this point we

00:29:03,049 --> 00:29:09,169
have iommu we say tsps ID it's on old

00:29:06,229 --> 00:29:12,349
platform really you can see up arm AMD

00:29:09,169 --> 00:29:15,169
and TL for PC we have hmm for a software

00:29:12,349 --> 00:29:18,289
solution we also a fisherman that does

00:29:15,169 --> 00:29:19,999
allow you to use device memory and you

00:29:18,289 --> 00:29:22,849
have really helps you to make read

00:29:19,999 --> 00:29:25,279
memory around we have few thing missing

00:29:22,849 --> 00:29:27,619
like I say we need a new API for memory

00:29:25,279 --> 00:29:28,999
placement and bind just doesn't cut it

00:29:27,619 --> 00:29:31,369
because you cannot really support the

00:29:28,999 --> 00:29:33,049
Vice Monroe's it we need a new way to

00:29:31,369 --> 00:29:34,369
expose the system topology to us base

00:29:33,049 --> 00:29:36,139
because the system to place is becoming

00:29:34,369 --> 00:29:38,659
much much more complex than what it is

00:29:36,139 --> 00:29:43,219
it's a graph no really and a graph with

00:29:38,659 --> 00:29:44,749
link that of different poverty and yeah

00:29:43,219 --> 00:29:45,679
you want also to follow device to access

00:29:44,749 --> 00:29:47,779
user memory

00:29:45,679 --> 00:29:50,899
peer-to-peer between device ready

00:29:47,779 --> 00:29:52,849
session about that later this week and

00:29:50,899 --> 00:29:55,459
you want stuff like you automatic memory

00:29:52,849 --> 00:29:57,499
or placement really the bottom line

00:29:55,459 --> 00:30:00,100
years that we're trying to grow the the

00:29:57,499 --> 00:30:02,169
the boundary between a CPU and device

00:30:00,100 --> 00:30:03,489
we want obviously it's a training

00:30:02,169 --> 00:30:06,519
cycling industry you want to be able to

00:30:03,489 --> 00:30:08,470
your GPU or FPGA or whatever to use it

00:30:06,519 --> 00:30:09,489
for what it's good at so you have one

00:30:08,470 --> 00:30:11,109
part of your application they're gonna

00:30:09,489 --> 00:30:12,850
use a CPU because the CPU is good for

00:30:11,109 --> 00:30:14,049
doing that thing and for another part of

00:30:12,850 --> 00:30:17,080
your application you're going to use a

00:30:14,049 --> 00:30:19,269
GT u1n FPGA or whatnot or or a DSP

00:30:17,080 --> 00:30:21,940
because it's a lot faster and you get

00:30:19,269 --> 00:30:23,289
better performance alright so that's

00:30:21,940 --> 00:30:37,690
pretty much it that's a status of

00:30:23,289 --> 00:30:39,639
everything does you frankly right now I

00:30:37,690 --> 00:30:48,580
would say 90% of industries include up

00:30:39,639 --> 00:30:51,399
if you talk about GPU yes but the issue

00:30:48,580 --> 00:30:53,679
is could i right now with a period

00:30:51,399 --> 00:30:55,840
version of CUDA is you have to use

00:30:53,679 --> 00:30:57,429
cudamalloc so you cannot use matter for

00:30:55,840 --> 00:30:59,739
new memory or you cannot use a map

00:30:57,429 --> 00:31:01,840
memory if you have a device

00:30:59,739 --> 00:31:06,519
rubberization man and let's say you have

00:31:01,840 --> 00:31:08,349
hmm and hula next a future version of

00:31:06,519 --> 00:31:09,789
could I don't want it like I'm not

00:31:08,349 --> 00:31:13,149
invidious so I don't want to talk to it

00:31:09,789 --> 00:31:15,759
but like at some point the switch is

00:31:13,149 --> 00:31:18,039
very CLE you switch away from cudamalloc

00:31:15,759 --> 00:31:21,009
to malappuram app and you have this new

00:31:18,039 --> 00:31:23,409
API Cisco API that is kind of in bind

00:31:21,009 --> 00:31:25,509
and and replace in mind and you just do

00:31:23,409 --> 00:31:26,859
binding my memory to GPU memory bind

00:31:25,509 --> 00:31:30,909
that branch of your progress to GPU

00:31:26,859 --> 00:31:33,220
memory but you're right now inside

00:31:30,909 --> 00:31:35,320
inside CUDA or been CL to have the same

00:31:33,220 --> 00:31:36,849
thing inside open CL we can say I want

00:31:35,320 --> 00:31:38,590
to use that memory or I want to use

00:31:36,849 --> 00:31:40,749
whistles remembering for a range or

00:31:38,590 --> 00:31:42,970
virtual address are actually allocated

00:31:40,749 --> 00:31:47,950
by OpenGL or CUDA depending on what

00:31:42,970 --> 00:31:50,049
whatever you use okay I'm just trying to

00:31:47,950 --> 00:31:51,789
avoid the pot this situation where we're

00:31:50,049 --> 00:32:02,259
construction API that we think is good

00:31:51,789 --> 00:32:06,190
but is hard for users to use it yeah

00:32:02,259 --> 00:32:09,369
yeah no and so I would patch it about

00:32:06,190 --> 00:32:12,580
this um bind thing I'm gonna post soon

00:32:09,369 --> 00:32:13,720
anything it's using the best whatever

00:32:12,580 --> 00:32:18,670
will be to be the best of

00:32:13,720 --> 00:32:20,260
a good iti so it's like squeeze down

00:32:18,670 --> 00:32:21,760
version of could ITI because if we could

00:32:20,260 --> 00:32:23,980
IP i also have a lot of you know you had

00:32:21,760 --> 00:32:25,810
kuda v could i could put an iron put i

00:32:23,980 --> 00:32:28,360
10 so on and so forth and every time we

00:32:25,810 --> 00:32:30,370
do slight modification in the way the

00:32:28,360 --> 00:32:32,170
nvidia cuda things work is kind of I

00:32:30,370 --> 00:32:34,450
won't say like bad but it's kind of you

00:32:32,170 --> 00:32:37,480
know they pile up stuff on top of each

00:32:34,450 --> 00:32:46,690
other and we don't we don't evolve they

00:32:37,480 --> 00:32:48,670
replace what's your I guess our solution

00:32:46,690 --> 00:32:50,920
for virtualization I mean for the

00:32:48,670 --> 00:32:53,410
hardware solution iommu has two levels

00:32:50,920 --> 00:32:55,750
of page tables right you can still use

00:32:53,410 --> 00:32:58,000
the you know the first level bind to the

00:32:55,750 --> 00:33:00,730
guest process space and then the second

00:32:58,000 --> 00:33:02,980
level to translate the guy's physical

00:33:00,730 --> 00:33:03,810
host physical but for software solution

00:33:02,980 --> 00:33:06,460
can you do the same

00:33:03,810 --> 00:33:10,120
so for virtualization again you have the

00:33:06,460 --> 00:33:11,710
two things so you have the ATS PSID that

00:33:10,120 --> 00:33:15,610
does support virtualization so this time

00:33:11,710 --> 00:33:17,860
you are virtual tpsid and so so that you

00:33:15,610 --> 00:33:19,780
get ATS against a virtual BS ID and the

00:33:17,860 --> 00:33:23,650
virtual base ideas and bind by the

00:33:19,780 --> 00:33:25,720
operating system to a virtual guest page

00:33:23,650 --> 00:33:27,280
table and you also have the software

00:33:25,720 --> 00:33:29,050
solution that you can implement directly

00:33:27,280 --> 00:33:32,470
inside the guest without having to do

00:33:29,050 --> 00:33:33,940
anything inside Aust so you can you can

00:33:32,470 --> 00:33:38,250
again do the same thing inside

00:33:33,940 --> 00:33:38,250
virtualization virtual change anything

00:33:48,670 --> 00:33:53,860
so it depends oh you're so it depends

00:33:52,060 --> 00:33:55,690
how you you passed on your drive you

00:33:53,860 --> 00:33:57,370
device to the guest you know you can do

00:33:55,690 --> 00:33:59,440
PCI Express pass through to the guest

00:33:57,370 --> 00:34:01,390
and in that in that case you have a real

00:33:59,440 --> 00:34:03,820
hardware device driver inside the guest

00:34:01,390 --> 00:34:05,980
and that the one that are not programmed

00:34:03,820 --> 00:34:08,470
the device vegetable or you can do

00:34:05,980 --> 00:34:10,450
virtual device so it does mean that the

00:34:08,470 --> 00:34:12,580
driver exactly inside the O's kernel and

00:34:10,450 --> 00:34:13,480
so you have a virtual device driver

00:34:12,580 --> 00:34:15,370
inside the gas can now

00:34:13,480 --> 00:34:16,930
and the virtual device water inside the

00:34:15,370 --> 00:34:17,980
gas can gonna talk to the driver inside

00:34:16,930 --> 00:34:20,560
Oscar now to

00:34:17,980 --> 00:34:22,390
I did get linked in the to vir tile

00:34:20,560 --> 00:34:23,380
vertically and then the you know the

00:34:22,390 --> 00:34:24,820
aust

00:34:23,380 --> 00:34:26,680
caramel device what we're going to

00:34:24,820 --> 00:34:27,490
program things on behalf of the device

00:34:26,680 --> 00:34:44,440
guest come on

00:34:27,490 --> 00:34:48,389
so it depends on what kind of the

00:34:44,440 --> 00:34:51,730
chicken nations came to use for the

00:34:48,389 --> 00:34:54,520
synchronization of the page tables to

00:34:51,730 --> 00:34:58,200
use Oscar lucky will find great locking

00:34:54,520 --> 00:35:01,900
was something Adam s so to test

00:34:58,200 --> 00:35:03,910
sterilization in a server solution you

00:35:01,900 --> 00:35:07,690
know you just basically run your program

00:35:03,910 --> 00:35:09,640
and constantly access the memory by the

00:35:07,690 --> 00:35:11,349
device so you make the device access all

00:35:09,640 --> 00:35:13,390
the memory inside your process and a

00:35:11,349 --> 00:35:17,410
same time you create condition that will

00:35:13,390 --> 00:35:19,450
force update to the process page table

00:35:17,410 --> 00:35:23,140
for a sound you set limit on the memory

00:35:19,450 --> 00:35:24,790
C group so that you say this process not

00:35:23,140 --> 00:35:26,560
use more than one gigabyte of memory and

00:35:24,790 --> 00:35:28,330
then there will be a reclamation going

00:35:26,560 --> 00:35:30,520
on so there will be compaction going on

00:35:28,330 --> 00:35:33,760
so there will be a validation you can

00:35:30,520 --> 00:35:35,800
also also have some time kernel modules

00:35:33,760 --> 00:35:38,140
that I use at just vertically is mean to

00:35:35,800 --> 00:35:39,940
other process so I'll give you PID and

00:35:38,140 --> 00:35:42,790
you got a trigger migration for that

00:35:39,940 --> 00:35:44,349
process randomly so that it can test

00:35:42,790 --> 00:35:45,820
against my main process and see if it

00:35:44,349 --> 00:35:48,369
keep growing and keep doing the thing it

00:35:45,820 --> 00:35:52,210
does I supposed to do so you know it's

00:35:48,369 --> 00:35:54,460
it's a mix and match of custom-made and

00:35:52,210 --> 00:35:57,580
thorough made solution to test this and

00:35:54,460 --> 00:35:59,920
and using existing things like memory C

00:35:57,580 --> 00:36:01,420
group or memory C group is probably the

00:35:59,920 --> 00:36:03,070
best one I use it's really like I set a

00:36:01,420 --> 00:36:05,200
limit on the number of memory the

00:36:03,070 --> 00:36:06,760
process can use and I'm gonna look at 16

00:36:05,200 --> 00:36:08,740
gigabyte I set the limit to one gigabyte

00:36:06,760 --> 00:36:11,140
and I constantly access memory and then

00:36:08,740 --> 00:36:13,480
I'm going to be a compaction reclamation

00:36:11,140 --> 00:36:15,010
swap and all that going on and that will

00:36:13,480 --> 00:36:16,300
change the CPU Peshtigo constantly

00:36:15,010 --> 00:36:19,800
because I'm costly accessing different

00:36:16,300 --> 00:36:19,800
memory thank you

00:36:24,760 --> 00:36:29,260

YouTube URL: https://www.youtube.com/watch?v=GlKB9EB5sAw


