Title: LPC2019 - An Evaluation of Host Bandwidth Manager
Publication date: 2019-09-20
Playlist: Linux Plumbers Conference 2019
Description: 
	An Evaluation of Host Bandwidth Manager

Speaker
 Lawrence Brakmo (Facebook)

Description
Host Bandwidth Manager (HBM) is a BPF based framework for managing per-cgroupv2 egress and ingress bandwidths in order to provide a better experience to workloads/services coexisting within a host. In particular, HBM allows us to divide a host's egress and ingress bandwidth among workloads residing in different v2 cgroups. Note that although sample BPF programs are included in the BPF patches, one can easily use different algorithms for managing bandwidth.

This talk presents an evaluation of HBM and associated BPF programs. It explores the performance of various approaches to bandwidth management for TCP flows that use Cubic, Cubic with ECN or DCTCP for their congestion control. For evaluating performance, we consider how well flows can utilize the allocated bandwidth, how many packets are dropped by HBM, increases to RTTs due to queueing, RPC size fairness, as well as RPC latencies. This evaluation is done independently for egress and ingress. In addition, we explore the use of HBM for protecting against incast congestion by also using HBM on the root v2 cgroup.

Our testing shows that HBM, with the appropriate BPF program, is very effective at managing egress bandwidths regardless of which TCP congestion control algorithm is used, preventing flows from exceeding the allocated bandwidth while allowing them to use most of their allocation. Not surprisingly, effectively managing ingress bandwidth requires ECN, and preferably DCTCP. Finally, we show that using HBM is very effective at preventing packet losses due to incast congestion, as long as we are willing to sacrifice some ingress bandwidth.
Captions: 
	00:00:00,180 --> 00:00:02,480
- Moving right along, we now have

00:00:02,480 --> 00:00:04,620
a presentation by Lawrence Brakmo.

00:00:04,620 --> 00:00:05,890
He is the father of

00:00:05,890 --> 00:00:08,320
the TCP Vegas Congestion Control Algorithm

00:00:08,320 --> 00:00:09,830
and more recently, he's been doing lots

00:00:09,830 --> 00:00:13,740
of interesting things with VPF at Facebook, including TCPDF,

00:00:13,740 --> 00:00:15,320
and what he's talking about today,

00:00:15,320 --> 00:00:16,660
the Host Bandwidth Manager.

00:00:16,660 --> 00:00:18,988
So please give him a warm welcome.

00:00:18,988 --> 00:00:21,738
(crowd applauds)

00:00:22,600 --> 00:00:25,120
- Thank you for the introduction.

00:00:25,120 --> 00:00:25,953
So today, I'm going to talk about

00:00:25,953 --> 00:00:28,320
evaluation of Host Bandwidth Manager.

00:00:28,320 --> 00:00:32,690
Last year, I talked about Network Resource Manager,

00:00:32,690 --> 00:00:35,970
so this is the same thing, except that we're

00:00:35,970 --> 00:00:38,913
not doing the evaluation based on the actual patches.

00:00:41,050 --> 00:00:45,770
And to recap, what we had last year,

00:00:45,770 --> 00:00:49,890
is an idea about how to do management,

00:00:49,890 --> 00:00:52,720
initially for cgroups, for the bandwidth,

00:00:52,720 --> 00:00:54,250
both ingress and egress

00:00:54,250 --> 00:00:59,250
and we created some test patches to evaluation the idea.

00:01:00,530 --> 00:01:02,760
When we submitted it later on,

00:01:02,760 --> 00:01:05,740
we realized that we needed to make quite a few changes

00:01:05,740 --> 00:01:08,530
and at that time, we also changed the name

00:01:08,530 --> 00:01:09,650
to Host Bandwidth Manager

00:01:09,650 --> 00:01:10,730
because we were just focusing,

00:01:10,730 --> 00:01:13,170
at that time, on the host bandwidth.

00:01:13,170 --> 00:01:17,860
The concept of NRM was to manage bandwidths also,

00:01:17,860 --> 00:01:19,800
on different areas of our network

00:01:19,800 --> 00:01:21,700
but this is just about the host.

00:01:21,700 --> 00:01:24,220
So to recap, Host Bandwidth Manager is

00:01:24,220 --> 00:01:27,980
a VPF based framework for managing egress

00:01:27,980 --> 00:01:32,150
and ingress bandwidth at the host.

00:01:32,150 --> 00:01:35,610
It uses the ingress and egress cgroup SKD hooks

00:01:36,530 --> 00:01:38,980
and you know, Linux server, it supports locating

00:01:38,980 --> 00:01:42,910
and managing many system resources, such as CPU and memory,

00:01:42,910 --> 00:01:45,270
but I think there's more to be done

00:01:45,270 --> 00:01:49,373
for bandwidth management, so that was the goal of this work.

00:01:52,120 --> 00:01:54,570
So, in particular, what are the difference

00:01:54,570 --> 00:01:55,510
from the previous talk?

00:01:55,510 --> 00:01:58,350
So, first of all, there are some code changes.

00:01:58,350 --> 00:02:01,210
Previously we didn't have any spinlocks for VPF

00:02:01,210 --> 00:02:03,660
so we used a global lock to do it,

00:02:03,660 --> 00:02:06,917
so now the code is implementing the spinlocks.

00:02:08,210 --> 00:02:10,160
Also, turns out that initially we wanted

00:02:10,160 --> 00:02:13,573
to call from the VPF program,

00:02:15,260 --> 00:02:19,000
make calls to effect the TCP socket.

00:02:19,000 --> 00:02:22,790
For example, tell it to enter a congestion window reduction.

00:02:22,790 --> 00:02:24,713
Turns out that where we had the hooks,

00:02:26,160 --> 00:02:27,830
Eric correctly pointed out,

00:02:27,830 --> 00:02:31,420
there are some code paths we do not own the socket lock,

00:02:31,420 --> 00:02:35,410
so rather than calling, for example, enter cwr directly,

00:02:35,410 --> 00:02:38,020
what we did is, the framework already supports

00:02:38,020 --> 00:02:41,760
for the queues to be able to return

00:02:41,760 --> 00:02:44,250
congestion notification, right,

00:02:44,250 --> 00:02:47,573
so the TCP then can call itself enter cwr

00:02:47,573 --> 00:02:50,170
and what we did is add support

00:02:50,170 --> 00:02:52,470
so that we can do the same thing from the VPF program.

00:02:52,470 --> 00:02:55,580
We can notify the TCP on the return path

00:02:55,580 --> 00:02:57,130
that there's congestion

00:02:57,130 --> 00:03:02,130
and then TCP itself will call tcp enter cwr.

00:03:02,260 --> 00:03:06,080
Also, we're getting to some issues sometimes

00:03:06,080 --> 00:03:08,890
where when we're trying to limit the bandwidth,

00:03:08,890 --> 00:03:11,180
sometimes we had to drop packets

00:03:11,180 --> 00:03:13,600
and if we drop all of the packets for a flow,

00:03:13,600 --> 00:03:15,410
we're gonna get a situation where we need

00:03:15,410 --> 00:03:18,360
to depend the probe timer to start sending again

00:03:18,360 --> 00:03:21,360
so this would introduce 40 millisecond delays

00:03:21,360 --> 00:03:22,370
at some stages.

00:03:22,370 --> 00:03:24,210
So, what we do now, is that

00:03:24,210 --> 00:03:26,840
we have access to the TCP socket state,

00:03:26,840 --> 00:03:30,860
we can figure out how many packets are out for this flow

00:03:30,860 --> 00:03:33,490
and if it's less than one, then we will not drop it,

00:03:33,490 --> 00:03:38,490
just to prevent forcing the code to probe timer.

00:03:41,220 --> 00:03:42,590
Also, the evaluation is different.

00:03:42,590 --> 00:03:45,080
First of all, we're using the actual upstream patches

00:03:45,080 --> 00:03:47,470
as opposed to our experimental code

00:03:47,470 --> 00:03:49,690
and we're also doing tests with multiple cgroups,

00:03:49,690 --> 00:03:51,370
instead of just one, which is

00:03:51,370 --> 00:03:53,420
the ultimate goal of this work.

00:03:53,420 --> 00:03:58,020
And we also have some tests of using the ingress

00:03:58,020 --> 00:03:59,930
to prevent incast congestion

00:03:59,930 --> 00:04:01,963
and losses due to incast congestion.

00:04:03,310 --> 00:04:06,540
And we also introduce support for using fair queueing,

00:04:06,540 --> 00:04:09,370
support for earlier departure time.

00:04:09,370 --> 00:04:12,760
So the idea is that you can write a time into the SKB

00:04:12,760 --> 00:04:15,151
and fq will ensure that the packet

00:04:15,151 --> 00:04:18,510
is not send before that time.

00:04:18,510 --> 00:04:21,240
And you can use that then to do shaping

00:04:22,840 --> 00:04:24,340
as opposed to just publishing.

00:04:25,420 --> 00:04:28,800
So what other options are there to manage bandwidths?

00:04:28,800 --> 00:04:31,020
You know, obviously traffic control

00:04:31,020 --> 00:04:34,290
allows us to use QinQ disciplines to shape

00:04:34,290 --> 00:04:36,270
and police outgoing traffic

00:04:36,270 --> 00:04:39,540
and typically, HTBs, what is used for this purpose

00:04:41,080 --> 00:04:44,221
but one of the problems is, if you're trained to do it

00:04:44,221 --> 00:04:47,920
for a lot of things, you can have performance issues

00:04:47,920 --> 00:04:52,920
due to the log and we've used that in the past at Facebook

00:04:53,528 --> 00:04:57,240
and typically we'll end up with every now and then,

00:04:57,240 --> 00:04:59,390
there would be issues that we would need to solve

00:04:59,390 --> 00:05:01,813
related to using HTB for this purpose.

00:05:03,350 --> 00:05:06,100
There's also ways to use BPF to do similar things,

00:05:06,100 --> 00:05:10,460
for example, Google uses the hook clsact TC

00:05:11,670 --> 00:05:15,800
in order to manage a flat HTB

00:05:15,800 --> 00:05:20,190
for them to do for their bandwidth manager.

00:05:20,190 --> 00:05:25,190
And one can use also, fq with EDT at different points,

00:05:25,440 --> 00:05:28,350
different types of hooks for BPF to do it.

00:05:28,350 --> 00:05:31,193
So, this is not the only solution to defer egress.

00:05:33,960 --> 00:05:35,940
So a quick overview of HBM,

00:05:35,940 --> 00:05:38,422
so there is a way, like I mentioned before,

00:05:38,422 --> 00:05:42,350
we use existing ingress and egress cgroup skb hooks,

00:05:42,350 --> 00:05:45,055
the policing and shaping is done

00:05:45,055 --> 00:05:48,770
by the BPF program through ECN marking,

00:05:48,770 --> 00:05:52,163
return code to trigger TCPs congestion window reduction.

00:05:53,220 --> 00:05:57,710
We can also use Earliest Departure Time with fq

00:05:57,710 --> 00:05:59,800
and of course, you know, packet drops.

00:05:59,800 --> 00:06:04,330
For in this policy we are more limited from we can do.

00:06:04,330 --> 00:06:08,183
We can only do ECN marking or we can drop packets.

00:06:09,780 --> 00:06:12,650
We need to tell the sender to slow down

00:06:12,650 --> 00:06:15,440
and unless we wanted to use another mechanism,

00:06:15,440 --> 00:06:17,953
those are the only two ways that we can do it.

00:06:21,696 --> 00:06:22,750
The policy algorithm obviously's

00:06:22,750 --> 00:06:24,450
implemented in a BPF program

00:06:24,450 --> 00:06:27,520
and can also use the TCP state to improve that behavior.

00:06:27,520 --> 00:06:29,700
For example, looking at packets out

00:06:29,700 --> 00:06:31,430
or looking at the rtt

00:06:31,430 --> 00:06:33,823
or the connection to make a different decision.

00:06:38,308 --> 00:06:41,580
In particular, the code that I used that is based

00:06:43,030 --> 00:06:46,770
on the code that was upstream with HPN patches,

00:06:46,770 --> 00:06:48,630
uses a virtual queue.

00:06:48,630 --> 00:06:51,450
That behavior that includes the spinlock

00:06:51,450 --> 00:06:53,123
to protect access to this queue,

00:06:54,030 --> 00:06:59,030
includes the last time that a packet was egress,

00:07:05,220 --> 00:07:07,090
came to our hook point.

00:07:07,090 --> 00:07:11,100
We keep track of the credit in bytes

00:07:11,100 --> 00:07:13,180
and then we also have a rate

00:07:13,180 --> 00:07:15,813
that that's what we're trying to enforce.

00:07:16,900 --> 00:07:19,060
Then when we send a packet, the first thing we do

00:07:19,060 --> 00:07:22,340
is the credit is increased by the last time,

00:07:22,340 --> 00:07:23,970
you know, the delay between the last time

00:07:23,970 --> 00:07:26,177
we went to send in a packet and right now.

00:07:26,177 --> 00:07:30,180
Last time we didn't send anything, so comes as credit.

00:07:30,180 --> 00:07:32,320
And then, the credit then would be reduced,

00:07:32,320 --> 00:07:37,320
based on the length, the wire length of the skb, right,

00:07:37,768 --> 00:07:40,500
so you had to possibly take into account

00:07:40,500 --> 00:07:44,763
the multiple headers of TSO packet, et cetera.

00:07:45,700 --> 00:07:46,710
And then we make a decision

00:07:46,710 --> 00:07:49,150
based on the credit and the packet info.

00:07:49,150 --> 00:07:51,960
When we're using EDT, it's a little bit different.

00:07:51,960 --> 00:07:55,400
The structure is the same, but all we use is the last,

00:07:55,400 --> 00:07:58,241
we don't use the credit, we use the last time.

00:07:58,241 --> 00:07:59,650
For EDT, we're keeping track

00:07:59,650 --> 00:08:02,120
of when should the next packet be sent

00:08:02,120 --> 00:08:07,120
for this particular cgroup and that time between

00:08:09,003 --> 00:08:12,130
tends to be in the future if we are behind,

00:08:12,130 --> 00:08:15,900
and the difference between that and the present

00:08:15,900 --> 00:08:20,470
is the credit, in some ways, you know, how big our queue is.

00:08:20,470 --> 00:08:21,950
So we wouldn't need to use the credit,

00:08:21,950 --> 00:08:26,143
so it's a little bit simpler managing for that case.

00:08:27,830 --> 00:08:31,990
And so, the idea is, you know, we have this virtual queue

00:08:31,990 --> 00:08:34,023
and in this case, I've got negative,

00:08:34,910 --> 00:08:37,340
shifted to the right, and it will be the positive,

00:08:37,340 --> 00:08:40,780
but the idea is that if the credit's so low,

00:08:40,780 --> 00:08:45,440
like we run below and we hit the packet,

00:08:45,440 --> 00:08:48,200
it should be the packet drop threshold on the left,

00:08:48,200 --> 00:08:50,147
as opposed to there's no packet drop threshold.

00:08:50,147 --> 00:08:51,630
You hit the drop threshold,

00:08:51,630 --> 00:08:52,970
we're gonna drop the packet, right.

00:08:52,970 --> 00:08:55,240
And obviously we're trying to prevent that

00:08:55,240 --> 00:08:57,090
when we use ECN marking and all that.

00:08:59,222 --> 00:09:03,000
We have a large packet threshold that is smaller

00:09:03,000 --> 00:09:04,300
and the idea is that we are

00:09:04,300 --> 00:09:06,630
willing to drop large packets sooner

00:09:06,630 --> 00:09:09,470
so that we have some buffer that we can use

00:09:09,470 --> 00:09:12,320
to give priority to smaller packets

00:09:12,320 --> 00:09:14,240
and this helps to prevent, you know,

00:09:14,240 --> 00:09:16,733
like, semi-starvation and things like that.

00:09:17,840 --> 00:09:19,480
And then we have a mark threshold,

00:09:19,480 --> 00:09:24,480
if our credit is negative enough, we do marking.

00:09:25,830 --> 00:09:28,390
And the marking, you know, in quotes,

00:09:28,390 --> 00:09:31,021
means different things based on

00:09:31,021 --> 00:09:33,170
what type of packet connection we have.

00:09:33,170 --> 00:09:34,980
So, for example, if the packet

00:09:34,980 --> 00:09:38,069
supports ECN, we will mark it,

00:09:38,069 --> 00:09:41,380
if it's TCP and does not support ECN,

00:09:41,380 --> 00:09:46,280
what we'll do is we're gonna return congestion to TCPs

00:09:46,280 --> 00:09:49,440
so they call cwr based on a linear probability.

00:09:49,440 --> 00:09:53,140
So, the bigger the queue is, the virtual queue is,

00:09:53,140 --> 00:09:56,393
the more likely that we will mark congestion, right.

00:09:57,334 --> 00:10:00,480
So it's kind of like an implementation of WRED in our code.

00:10:05,880 --> 00:10:09,350
And of course, if we were using EDT,

00:10:09,350 --> 00:10:12,620
this, rather then them being credits, would be delays

00:10:12,620 --> 00:10:17,240
and then we would use that time to timestamp that packet.

00:10:17,240 --> 00:10:20,260
And also, you know, to do ECN marking and all that,

00:10:20,260 --> 00:10:22,823
but the behavior is quite similar in the code.

00:10:24,760 --> 00:10:27,840
Once again, this just rehashes what I said.

00:10:27,840 --> 00:10:29,540
When we hit the marking threshold,

00:10:30,526 --> 00:10:32,580
between that and the doctoral threshold,

00:10:32,580 --> 00:10:34,900
we have our linear probability

00:10:34,900 --> 00:10:36,870
of marking the packet with congestion

00:10:36,870 --> 00:10:39,369
so that the sender will reduce

00:10:39,369 --> 00:10:43,003
his congestion window and it's right.

00:10:44,240 --> 00:10:45,363
So, evaluation.

00:10:46,350 --> 00:10:51,350
So, for evaluation, we did couple different things.

00:10:53,030 --> 00:10:56,500
We redid some of the cgroup egress

00:10:56,500 --> 00:10:58,460
for a single cgroup that we did before,

00:10:58,460 --> 00:10:59,850
because the code is actually different,

00:10:59,850 --> 00:11:03,190
so we wanted to see what is the behavior

00:11:03,190 --> 00:11:05,480
and then we also tested with multiple cgroups

00:11:06,453 --> 00:11:10,370
to demonstrate how it can actually manage the bandwidth

00:11:10,370 --> 00:11:12,200
and what kind of behaviors we have

00:11:12,200 --> 00:11:15,020
when we're using all the different mechanisms, right.

00:11:15,020 --> 00:11:17,710
Like, in some cases, we use EDT,

00:11:17,710 --> 00:11:20,004
some cases we use DCTCP, other times is for

00:11:20,004 --> 00:11:24,310
flows that do not support either one so we're just dropping

00:11:24,310 --> 00:11:26,973
and we wanted to see how it would perform in those cases.

00:11:27,972 --> 00:11:30,120
We did it for multiple cgroups for egress

00:11:31,690 --> 00:11:33,360
so that we can divide the bandwidth,

00:11:33,360 --> 00:11:35,070
the girth bandwidth of the host,

00:11:35,070 --> 00:11:39,050
and finally, so we did it for ingress

00:11:39,050 --> 00:11:41,190
and the test we're demonstrating right now

00:11:41,190 --> 00:11:43,600
is for a single cgroup

00:11:43,600 --> 00:11:44,810
and it was just demonstrating

00:11:44,810 --> 00:11:47,040
how it can be used to prevent incast

00:11:47,040 --> 00:11:49,673
or decrease the probability of incast packet drops.

00:11:53,965 --> 00:11:54,798
So, single group egress, right,

00:11:54,798 --> 00:11:57,370
so these an example where we have

00:11:57,370 --> 00:11:59,760
one gigabit per second limit

00:11:59,760 --> 00:12:03,163
and the different things we tested were just cubic,

00:12:03,163 --> 00:12:07,350
with RDCN, so all we can do is tell the sender to, you know,

00:12:07,350 --> 00:12:10,080
reduce the congestion window or drop the packet.

00:12:10,080 --> 00:12:12,308
We have cubic with EDT, so we can

00:12:12,308 --> 00:12:16,760
actually do some shaping in addition.

00:12:16,760 --> 00:12:19,307
We have DCTCP so we can use ECN marking

00:12:20,146 --> 00:12:22,808
and we have DCTCP, also with EDT,

00:12:22,808 --> 00:12:25,790
because I wanted to see if there were any advantages

00:12:25,790 --> 00:12:28,533
of combining both of those together.

00:12:29,400 --> 00:12:34,210
So, other than the cubic, that I choose a little less

00:12:34,210 --> 00:12:38,220
than the limit, you know, like, 960 megabits per second,

00:12:41,280 --> 00:12:44,950
all the other ones can reach the limit quite nicely

00:12:44,950 --> 00:12:46,250
of one gigabit per second.

00:12:47,280 --> 00:12:48,580
Typically, in this experiment,

00:12:48,580 --> 00:12:52,130
we would do this multiple RPCs, than kilobytes

00:12:52,130 --> 00:12:54,320
and one megabyte and the reason for me

00:12:54,320 --> 00:12:57,740
is always I'm very interested in how flows

00:12:58,694 --> 00:13:01,400
affect my floats and inter latency

00:13:01,400 --> 00:13:02,750
so I did really all my experiments,

00:13:02,750 --> 00:13:06,270
I always do a combination of large RPCs,

00:13:06,270 --> 00:13:08,520
small RPCs and in some cases, also streaming.

00:13:09,980 --> 00:13:12,360
So in this case, we can see

00:13:12,360 --> 00:13:14,630
that they all behaved quite similar,

00:13:14,630 --> 00:13:18,950
which in some ways is surprising that just pure cubic,

00:13:18,950 --> 00:13:21,350
you know, where I didn't condition notification,

00:13:22,581 --> 00:13:27,573
we're doing quite well, which is nice to see.

00:13:28,670 --> 00:13:31,810
Of course, when were just running cubic without ECN,

00:13:31,810 --> 00:13:33,830
we're dropping more packets

00:13:33,830 --> 00:13:36,310
than when we have ECN notification

00:13:36,310 --> 00:13:37,330
but they were not too bad.

00:13:37,330 --> 00:13:40,473
This is .06% of the packets were being dropped.

00:13:41,870 --> 00:13:45,700
For cubic and DCTCP, we had some drops, .01%

00:13:45,700 --> 00:13:50,700
and this case it was typically due to doing the slow start.

00:13:52,150 --> 00:13:55,750
It takes for DCTCP, it takes a little bit too long

00:13:59,846 --> 00:14:01,740
for the sender to slow down

00:14:01,740 --> 00:14:03,970
and we have some packet loss due to that.

00:14:03,970 --> 00:14:05,530
When we combine DCTCP with EDT,

00:14:05,530 --> 00:14:07,440
we didn't see any packet losses, right.

00:14:07,440 --> 00:14:09,840
In particular, probably is because our threshold

00:14:11,212 --> 00:14:12,260
turn out to be a little bit different

00:14:12,260 --> 00:14:15,420
than when were using the credit base

00:14:15,420 --> 00:14:17,483
as opposed to delayed base.

00:14:21,220 --> 00:14:26,120
And, the latencies are quite similar.

00:14:26,120 --> 00:14:27,620
The cubic itself did a little bit better

00:14:27,620 --> 00:14:30,600
because they RTTs were a little smaller with the cubic,

00:14:30,600 --> 00:14:34,040
you know, it didn't reach to 1G rate per second

00:14:34,040 --> 00:14:35,650
so there was less queueing due to that,

00:14:35,650 --> 00:14:39,043
so that thinking about RPC, which is the orange,

00:14:40,340 --> 00:14:42,690
it's a little bit lower than for the other ones

00:14:44,260 --> 00:14:48,010
but the cast is then and 1 megabyte is larger latency

00:14:48,010 --> 00:14:49,833
than the other ones.

00:14:50,900 --> 00:14:52,260
And in this case, the things we're seeing,

00:14:52,260 --> 00:14:56,847
this is a logarithm scales so watching some RTOs

00:14:58,380 --> 00:15:02,973
and some delays were like 200 milliseconds for the cubic.

00:15:06,770 --> 00:15:10,040
So, this one is now with the 9G limit,

00:15:10,040 --> 00:15:13,370
trying to enforce a nine gigabit per second limit.

00:15:13,370 --> 00:15:18,370
Once again, DCTCP they get close to the 9G limit.

00:15:21,043 --> 00:15:24,100
And the throughputs are similar for all of them

00:15:25,090 --> 00:15:27,294
but with most of these cases, we had to do it last,

00:15:27,294 --> 00:15:29,670
it's easy to see the throughput,

00:15:29,670 --> 00:15:32,518
they impact many times, based on the algorithm

00:15:32,518 --> 00:15:33,840
and will be in the latencies.

00:15:33,840 --> 00:15:36,283
And this shows the latencies for those, too.

00:15:37,654 --> 00:15:41,930
And, you know, once again I think DCTCP

00:15:41,930 --> 00:15:46,010
has the lower latencies, which is, I think, typical of DCTCP

00:15:46,867 --> 00:15:48,230
and this is again, a large scale,

00:15:48,230 --> 00:15:51,610
so there's more differences between DCTCP and cubic,

00:15:51,610 --> 00:15:52,830
even though they look small there,

00:15:52,830 --> 00:15:54,393
you know, they are significant.

00:16:00,790 --> 00:16:04,120
And, another test I did is that I like to do

00:16:04,120 --> 00:16:06,180
a 200 megabit per second limit,

00:16:06,180 --> 00:16:08,570
because that's a really big stress test

00:16:08,570 --> 00:16:11,070
for this experimental setup

00:16:11,070 --> 00:16:12,720
because the RTPs are so small,

00:16:12,720 --> 00:16:16,520
that in order to enforce the 200 megabit per second limit,

00:16:16,520 --> 00:16:20,370
sometimes, you know, your congestion window

00:16:20,370 --> 00:16:22,570
needs to be very, very, very, very small, right.

00:16:22,570 --> 00:16:25,570
Sometimes, less than one, depend how many flows you have,

00:16:25,570 --> 00:16:28,793
could easily be less than one packet for RTP.

00:16:30,230 --> 00:16:34,360
We should obviously get into these losses and other things.

00:16:34,360 --> 00:16:39,360
So, for this setup, typically EDT is very nice, right,

00:16:39,480 --> 00:16:44,480
because you get to do shaping as opposed to just policing,

00:16:44,830 --> 00:16:46,620
so you don't have to drop the packet,

00:16:46,620 --> 00:16:49,718
you can ensure that you have a couple packets for each flow

00:16:49,718 --> 00:16:54,718
to make sure you're not hit by delayed ax in some cases

00:16:56,190 --> 00:17:01,190
or by the probe timer that I mentioned earlier.

00:17:05,859 --> 00:17:06,692
- [Audience Member] Can you go through that?

00:17:06,692 --> 00:17:07,525
- Yes, of course.

00:17:15,550 --> 00:17:16,383
- [Audience Member] Can you explain

00:17:16,383 --> 00:17:18,640
what's in this picture exactly?

00:17:18,640 --> 00:17:21,470
- Yeah, so I'm doing multiple flows at the same time

00:17:21,470 --> 00:17:24,630
and we have the aggregate rates

00:17:24,630 --> 00:17:27,980
and then we have the 10K and the one megabyte rates,

00:17:27,980 --> 00:17:30,553
right, so I measured them individually

00:17:30,553 --> 00:17:32,920
just to see the whole behavior.

00:17:32,920 --> 00:17:35,123
So, obviously, with just pure cubic,

00:17:35,975 --> 00:17:38,683
I'm only doing like, 160 megabits per second.

00:17:40,460 --> 00:17:42,861
I cannot get close enough to that 200

00:17:42,861 --> 00:17:44,680
because I'm having to drop too many packets

00:17:44,680 --> 00:17:47,910
and the cwr is very coarse, right,

00:17:47,910 --> 00:17:51,717
as opposed to DCTCP, that can reduce

00:17:51,717 --> 00:17:53,663
the congestion window more gracefully.

00:17:54,590 --> 00:17:57,300
With cubic, you know, it's a bigger reduction

00:17:57,300 --> 00:17:59,490
when I trigger it, either through losses

00:17:59,490 --> 00:18:01,483
or through calling cwr.

00:18:02,701 --> 00:18:04,165
Did that answer your question?

00:18:04,165 --> 00:18:06,910
- That's okay, thank you.

00:18:13,340 --> 00:18:15,190
- And let's see, in the previous one,

00:18:17,130 --> 00:18:20,433
so these are the latencies for the 10 kilobyte,

00:18:23,050 --> 00:18:25,450
and obviously the cubic has very large latencies

00:18:26,298 --> 00:18:28,080
as opposed to the other ones

00:18:28,080 --> 00:18:30,623
because it has more drops.

00:18:37,150 --> 00:18:38,880
And this is the 1 megabyte RPC latency

00:18:38,880 --> 00:18:43,880
and here, DTCTP was hit with hard latencies

00:18:44,150 --> 00:18:47,270
and one of the reasons is that I realized just today,

00:18:47,270 --> 00:18:51,105
that I mentioned before that we can look at the TCP state

00:18:51,105 --> 00:18:52,720
and we can look that if we only have like,

00:18:52,720 --> 00:18:56,830
how many packets that we have to try to get better behavior

00:18:57,740 --> 00:18:59,430
but I'm not using it with DTCTP

00:19:00,380 --> 00:19:02,030
so that probably would have helped

00:19:02,030 --> 00:19:04,911
but if we use DTCTP with EDT, a combination of both,

00:19:04,911 --> 00:19:08,810
we do shaping but we use the DTCTP mechanism

00:19:08,810 --> 00:19:10,940
to reduce the congestion window more gracefully

00:19:10,940 --> 00:19:13,750
than just cubic you're seeing.

00:19:13,750 --> 00:19:16,300
We'll get the best latency.

00:19:16,300 --> 00:19:18,080
- One question, in your previous slide,

00:19:18,080 --> 00:19:22,453
how can we change to a 90% latency instead of 99%?

00:19:23,430 --> 00:19:25,220
- [Lawrence] I'm sorry, oh, it's a type, sorry.

00:19:25,220 --> 00:19:26,210
It should be 99%.

00:19:26,210 --> 00:19:27,460
- Oh, okay.

00:19:27,460 --> 00:19:28,710
- I'm sorry, it's a typo.

00:19:31,790 --> 00:19:33,340
Yes.

00:19:33,340 --> 00:19:34,173
- When you're measuring RPCs,

00:19:34,173 --> 00:19:36,200
are you doing a whole new connection for RPC

00:19:36,200 --> 00:19:38,697
or do have an established one for RPC?

00:19:39,990 --> 00:19:40,823
- [Lawrence] I'm sorry?

00:19:40,823 --> 00:19:42,651
- So, you're going through a syn, synack--

00:19:42,651 --> 00:19:44,072
- [Lawrence] No, no, no. - RPC.

00:19:44,072 --> 00:19:46,599
- [Lawrence] So I did this at back to back RPCs.

00:19:46,599 --> 00:19:48,123
- Okay, so you have established connections for it?

00:19:48,123 --> 00:19:48,956
- Yes, I have.

00:19:48,956 --> 00:19:50,890
It starts and then it's just back to back.

00:19:50,890 --> 00:19:52,297
- [Audience Member] Great, thank you.

00:19:52,297 --> 00:19:55,220
- So it produces a lot more load than it would.

00:19:55,220 --> 00:19:58,320
Or I would need a lot more flows to congest.

00:20:01,850 --> 00:20:04,493
Okay, so the next test is for example,

00:20:05,750 --> 00:20:07,960
1G, two limits, right, so where we have

00:20:07,960 --> 00:20:10,510
a low priority cgroup that we're gonna post

00:20:10,510 --> 00:20:12,320
a one gigabit per second limit

00:20:12,320 --> 00:20:14,846
and we have a high priority cgroup

00:20:14,846 --> 00:20:18,590
where we're giving it nine gigabits per second of bandwidth.

00:20:18,590 --> 00:20:21,707
So now, we're testing the framework

00:20:21,707 --> 00:20:23,560
to see how it behaves

00:20:23,560 --> 00:20:28,560
and for the 1G limit, you know, it reaches it.

00:20:29,540 --> 00:20:32,713
For the 9G, it falls a little behind.

00:20:35,540 --> 00:20:37,750
I'm not 100% sure why that is.

00:20:37,750 --> 00:20:40,520
It could be because when I doing marking,

00:20:40,520 --> 00:20:42,890
for example, for DTCTP, maybe too low,

00:20:42,890 --> 00:20:46,990
and we know for DTCTP if the marking,

00:20:46,990 --> 00:20:49,860
the buffer is too small for the threshold,

00:20:49,860 --> 00:20:51,863
then you cannot fully utilize the link.

00:20:56,837 --> 00:20:59,050
And in particular, this was with only,

00:20:59,050 --> 00:21:01,400
I believe it was with four flows in particular.

00:21:03,110 --> 00:21:05,887
I did some tests with more flows later on,

00:21:05,887 --> 00:21:06,870
I did not do the slides,

00:21:06,870 --> 00:21:10,040
and I was able to get closer to the nine gigabit per second

00:21:10,040 --> 00:21:12,383
by increasing the number of flows.

00:21:19,490 --> 00:21:23,030
For this one, we were just looking at

00:21:23,030 --> 00:21:27,290
the rates for all the different ones,

00:21:27,290 --> 00:21:30,263
and they all, again, behaved more or less similarly.

00:21:32,396 --> 00:21:36,760
I say once again, typically, it's easier to shoot the rates,

00:21:36,760 --> 00:21:40,113
that the bigger issues are the latencies, right.

00:21:40,113 --> 00:21:41,720
So if, for the latencies, we're looking at

00:21:41,720 --> 00:21:46,253
the 10K and the one megabyte for the two different cgroups,

00:21:47,840 --> 00:21:50,240
so one is for the one gigabit,

00:21:50,240 --> 00:21:54,990
two is for the 10 gigabit and we can see here that...

00:22:00,530 --> 00:22:02,710
They are more or less the same, but not exactly.

00:22:02,710 --> 00:22:04,400
This is again logarithm

00:22:04,400 --> 00:22:06,710
and it thinks that DTCTP, again,

00:22:06,710 --> 00:22:09,743
seems to have the lower latencies for all of this.

00:22:15,140 --> 00:22:20,140
So, our preference has been to use DTCTP

00:22:21,670 --> 00:22:23,803
when doing this kind of work.

00:22:26,050 --> 00:22:27,430
So, the next thing we're gonna talk,

00:22:27,430 --> 00:22:31,830
is about using this mechanism for ingress,

00:22:31,830 --> 00:22:35,260
to also try to limit losses due to incast, right.

00:22:35,260 --> 00:22:38,290
So, the experimental setup was to have four senders

00:22:39,440 --> 00:22:40,990
that are sending to one receiver.

00:22:40,990 --> 00:22:45,710
And each sender is doing three flows,

00:22:45,710 --> 00:22:48,340
one 10K back to back RPC,

00:22:48,340 --> 00:22:49,790
1MB back to back RPCs

00:22:49,790 --> 00:22:51,680
and 8MG back to back RPCs.

00:22:51,680 --> 00:22:54,080
I want you to be in megabyte to put more stress.

00:22:54,940 --> 00:22:55,773
Go ahead.

00:22:58,960 --> 00:23:01,220
- My immediate gut instinct is that RSS

00:23:01,220 --> 00:23:03,283
is gonna be saving your tailbone here.

00:23:04,650 --> 00:23:06,720
We see side steering.

00:23:06,720 --> 00:23:07,553
- [Lawrence] What do you mean?

00:23:07,553 --> 00:23:08,386
- Just keep going.

00:23:08,386 --> 00:23:09,593
- Okay, sure.

00:23:09,593 --> 00:23:10,426
(audience laughs)

00:23:10,426 --> 00:23:12,590
Not a problem.

00:23:12,590 --> 00:23:14,150
So, we apply the limit,

00:23:14,150 --> 00:23:15,760
whatever we want to use in the condition

00:23:15,760 --> 00:23:20,430
to prevent incast losses, we apply the limit

00:23:20,430 --> 00:23:23,400
to the root cgroup as opposed to different cgroups,

00:23:23,400 --> 00:23:27,543
it would apply to the aggregate traffic coming in.

00:23:29,221 --> 00:23:33,163
And we need to post a limit below the bandwidth of the link.

00:23:34,250 --> 00:23:37,670
First of all, you know, we need to go above it

00:23:37,670 --> 00:23:41,470
so that we start running out of credits.

00:23:41,470 --> 00:23:44,520
Secondly, also, is because that

00:23:44,520 --> 00:23:47,250
gives us some headroom, right.

00:23:47,250 --> 00:23:50,885
If I impose a limit, let's say that I have a 10G limit,

00:23:50,885 --> 00:23:52,390
and I post a limit of 9G

00:23:52,390 --> 00:23:54,053
but I would not drop that packet, right,

00:23:54,053 --> 00:23:57,260
it's just for marking and to notify the sender to slow down,

00:23:57,260 --> 00:23:59,600
if imposing the limit on 9G,

00:23:59,600 --> 00:24:02,220
it means I have a lot more headroom

00:24:02,220 --> 00:24:07,140
to deal with bursts before that switch

00:24:07,140 --> 00:24:08,400
above me needs to drop them.

00:24:08,400 --> 00:24:11,550
So, I can use the buffers

00:24:11,550 --> 00:24:13,640
in the screens above me to get the drops

00:24:13,640 --> 00:24:15,290
and I can also use the extra bandwidth

00:24:15,290 --> 00:24:19,230
that the 1G in this case, where I can go over

00:24:19,230 --> 00:24:24,230
and give me some time to react before packets are dropped.

00:24:26,880 --> 00:24:27,713
Okay.

00:24:30,270 --> 00:24:33,713
So what we did is we posed a 9G per second limit.

00:24:35,290 --> 00:24:38,040
The baseline is, we're not doing anything.

00:24:38,040 --> 00:24:42,160
We're just sending to the receiver,

00:24:42,160 --> 00:24:43,963
we're not imposing any limits right.

00:24:46,350 --> 00:24:49,314
On the next one, we doing cubic, cubic-ECN,

00:24:49,314 --> 00:24:50,973
and DTCTP to the limit.

00:24:53,420 --> 00:24:54,863
To try to prevent losses.

00:24:56,600 --> 00:25:00,380
So obviously, we're trying to post a 9G limit,

00:25:00,380 --> 00:25:01,922
by the way, these are the throughputs

00:25:01,922 --> 00:25:05,760
for the different flows, right.

00:25:05,760 --> 00:25:08,340
So, this is not the aggregate bandwidth

00:25:09,822 --> 00:25:11,920
and the yeah, the baseline has higher

00:25:11,920 --> 00:25:13,661
for one megabyte and then megabyte

00:25:13,661 --> 00:25:17,450
but has a lot smaller for the 10 kilobyte, as you can see.

00:25:17,450 --> 00:25:19,770
And I will talk later more about that in the next slide.

00:25:19,770 --> 00:25:21,070
Do you have any questions?

00:25:22,310 --> 00:25:23,840
- [Audience Member] This slide doesn't make any sense to me.

00:25:23,840 --> 00:25:28,230
- Okay, so what I'm printing here

00:25:28,230 --> 00:25:32,887
is the average bandwidth for the 1K, 10K, RPC,

00:25:34,500 --> 00:25:37,740
the one megabyte and the eight megabyte, right.

00:25:37,740 --> 00:25:40,150
And we wanted to see how that is different

00:25:40,150 --> 00:25:42,650
so when you can see that whenever we're using HBM,

00:25:44,920 --> 00:25:47,700
the smaller transfer, the 10 kilobytes,

00:25:47,700 --> 00:25:49,130
gets a lot more bandwidth, right.

00:25:49,130 --> 00:25:52,203
So, it's more fair across transfer sizes.

00:25:55,020 --> 00:25:58,423
That's the main message of this slide.

00:26:02,720 --> 00:26:04,823
So now let's look at the 99% latencies.

00:26:07,640 --> 00:26:10,803
That's a baseline, DTCTP, cubic ECN.

00:26:13,320 --> 00:26:16,090
So they show here, that obviously

00:26:16,090 --> 00:26:19,090
because the 10 kilobyte gets a bigger rate,

00:26:19,090 --> 00:26:20,603
it's latency's much smaller.

00:26:22,700 --> 00:26:25,500
With DTCTP, the latency is actually smaller

00:26:25,500 --> 00:26:30,303
for the eight megabyte and the one megabyte RPCs.

00:26:31,180 --> 00:26:34,597
The cubic-ECN is not at it's worst and also for--

00:26:35,455 --> 00:26:36,288
- [Audience Member] And this--

00:26:36,288 --> 00:26:37,121
- [Lawrence] The activity is dropping

00:26:37,121 --> 00:26:38,910
so it's like, horrible thing to do, right.

00:26:38,910 --> 00:26:39,743
- [Audience Member] So this effect is

00:26:39,743 --> 00:26:42,850
because DTCTPs more graceful back off?

00:26:42,850 --> 00:26:44,640
- [Lawrence] Yes, so cubic-ECN is losing

00:26:44,640 --> 00:26:46,702
some bandwidth in some ways,

00:26:46,702 --> 00:26:51,702
and yeah, the DTCTP can fully utilize more of the bandwidth.

00:26:53,600 --> 00:26:54,433
There.

00:26:58,790 --> 00:26:59,980
- [Audience Member] For your best slide,

00:26:59,980 --> 00:27:02,720
what congestion control protocol is that running?

00:27:02,720 --> 00:27:04,583
- [Lawrence] Off of the biller, it's just cubic.

00:27:06,590 --> 00:27:08,930
- [Audience Member] Cubic with no HBM, right?

00:27:08,930 --> 00:27:09,763
- [Lawrence] I'm sorry.

00:27:09,763 --> 00:27:11,632
- Cubic with no HBM, right?

00:27:11,632 --> 00:27:13,235
- Correct, cubic code, no HBM,

00:27:13,235 --> 00:27:15,340
that's the best, uh huh, correct.

00:27:15,340 --> 00:27:17,220
Now, we cannot see very much

00:27:17,220 --> 00:27:19,230
between the 10 kilobyte RPC differences

00:27:19,230 --> 00:27:22,560
so on the next slide, I try it on it's own scale, right,

00:27:22,560 --> 00:27:27,560
and the DTCTP, it's six times lower than for baseline.

00:27:30,720 --> 00:27:35,280
So one of the advantages of this mechanism, once again,

00:27:35,280 --> 00:27:38,530
is to get furnished for smaller transfers, right.

00:27:38,530 --> 00:27:42,640
Which, typically, tend to suffer

00:27:42,640 --> 00:27:46,123
all the time in data centers.

00:27:47,370 --> 00:27:50,370
This last slide, shows retransmissions.

00:27:50,370 --> 00:27:54,170
So, cubic is here and DTCTP had zero retransmissions

00:27:54,170 --> 00:27:57,530
and obviously, that also effects the latencies.

00:27:57,530 --> 00:28:00,810
Cubic has horrible because the only thing we can do is drop

00:28:00,810 --> 00:28:02,660
and I'm just trying it there, like...

00:28:04,980 --> 00:28:06,790
For completeness, not for...

00:28:08,040 --> 00:28:10,530
I would not recommend anybody using that, honestly,

00:28:10,530 --> 00:28:11,930
it's not a sane thing to do.

00:28:13,010 --> 00:28:15,739
If you're gonna drop, you may as well drop

00:28:15,739 --> 00:28:17,490
when the buffers in the three get full,

00:28:17,490 --> 00:28:19,483
are supposed to do it ahead of time.

00:28:22,220 --> 00:28:23,400
That's it.

00:28:23,400 --> 00:28:24,930
So, the idea is that we can

00:28:24,930 --> 00:28:26,820
allocate bandwidth within cgroups

00:28:27,750 --> 00:28:29,470
and we can divide it effectively.

00:28:29,470 --> 00:28:34,470
We can utilize the bandwidth we have allocated

00:28:34,650 --> 00:28:37,320
and we can also achieve fairness

00:28:37,320 --> 00:28:40,320
between different transfer sizes.

00:28:40,320 --> 00:28:43,310
And we can also use it for ingress limiting,

00:28:43,310 --> 00:28:46,300
to try to reduce the likelihood of losses

00:28:46,300 --> 00:28:49,043
and effect on latency for incast congestion.

00:28:52,660 --> 00:28:54,273
- [Host] Any questions?

00:28:56,984 --> 00:28:58,770
(crowd murmurs softly)

00:28:58,770 --> 00:29:02,738
- So you're doing ingress limiting primarily on the host.

00:29:02,738 --> 00:29:03,571
- [Lawrence] Yes.

00:29:03,571 --> 00:29:06,320
- You're not engaging ECN on the switches at all.

00:29:06,320 --> 00:29:07,153
- [Lawrence] No.

00:29:08,130 --> 00:29:13,130
But there are some environments where you cannot do that.

00:29:13,630 --> 00:29:14,690
Also, there are environments

00:29:14,690 --> 00:29:17,229
where you have multi-call switch

00:29:17,229 --> 00:29:18,490
so that the switch my have support

00:29:18,490 --> 00:29:22,080
and maybe the host does not have support for ECN marking,

00:29:22,080 --> 00:29:25,920
and this way is one way to achieve that behavior, right,

00:29:25,920 --> 00:29:30,670
at the cost of some bandwidth losses, right,

00:29:30,670 --> 00:29:33,730
because you had to use less than--

00:29:33,730 --> 00:29:35,890
- Less bandwidth, with 1/6 the latency

00:29:35,890 --> 00:29:37,823
is kinda nice sometimes.

00:29:39,080 --> 00:29:41,120
The related question was,

00:29:41,120 --> 00:29:43,610
and I mentioned it earlier in your talk,

00:29:43,610 --> 00:29:46,150
to me, receive side steering

00:29:46,150 --> 00:29:48,990
would have taken care of some of your issues

00:29:48,990 --> 00:29:53,140
with having small RPCs versus large RPCs,

00:29:53,140 --> 00:29:55,280
so are you feeding this through a single queue,

00:29:55,280 --> 00:29:56,970
all these RPCs are going through

00:29:56,970 --> 00:29:58,730
a single queue at this level?

00:29:58,730 --> 00:30:02,340
- So this were going to a single queue on the switch, yes.

00:30:02,340 --> 00:30:06,200
- Okay, but on the policer side, on the ingress side,

00:30:06,200 --> 00:30:09,570
ideally you could have as many queues

00:30:09,570 --> 00:30:11,170
as you wanted coming in.

00:30:11,170 --> 00:30:13,390
- [Lawrence] Are you talking about the receiving host?

00:30:13,390 --> 00:30:14,380
- Yeah, that one that's trying that--

00:30:14,380 --> 00:30:18,450
- I think the delays are not due on the receiving side,

00:30:18,450 --> 00:30:22,410
they're rightly due on queueing elsewhere in the network.

00:30:22,410 --> 00:30:23,640
- Okay, I'd love to talk to you later.

00:30:23,640 --> 00:30:24,473
Thank you.

00:30:32,182 --> 00:30:33,015
- [Audience Member] Now I'm confused,

00:30:33,015 --> 00:30:35,130
I thought you were doing the ingress stuff

00:30:35,130 --> 00:30:36,663
in the host itself, on the--

00:30:36,663 --> 00:30:37,713
- It is on the host.

00:30:37,713 --> 00:30:40,570
- Okay, so because you mentioned that HTB

00:30:40,570 --> 00:30:43,821
had a big cost because of single spinlock, but then--

00:30:43,821 --> 00:30:45,070
- [Lawrence] No, no, no, that's--

00:30:45,070 --> 00:30:49,430
- That's on egress, but now, on ingress you add some stuff?

00:30:51,730 --> 00:30:53,630
With a central rating meter,

00:30:53,630 --> 00:30:57,440
why, you probably have multi-queue device, right?

00:30:57,440 --> 00:30:59,420
The 10 gig device you're using

00:30:59,420 --> 00:31:02,540
are probably used with multi-queue.

00:31:02,540 --> 00:31:03,920
- What, I'm sorry?

00:31:03,920 --> 00:31:05,848
- [Audience Member] Multiple queues.

00:31:05,848 --> 00:31:07,160
- Yes.

00:31:07,160 --> 00:31:09,170
- So you still need the spinlock

00:31:09,170 --> 00:31:12,580
to protect this central rating meter for the ingress--

00:31:12,580 --> 00:31:13,675
- So is it - No, no, no.

00:31:13,675 --> 00:31:15,530
We're using the spinlock on both, ingress and egress.

00:31:15,530 --> 00:31:19,060
- Yeah, so you have a centralized locking regimen

00:31:19,060 --> 00:31:21,790
for the cgroup BPF program that's doing all this logic.

00:31:21,790 --> 00:31:22,623
- [Lawrence] Yes, correct, correct.

00:31:22,623 --> 00:31:27,623
- So that kinda fights against the RSS, that's the point.

00:31:27,893 --> 00:31:28,759
- [Lawrence] That's a good point.

00:31:28,759 --> 00:31:30,560
- That's probably have a heavy cost.

00:31:30,560 --> 00:31:35,263
Do you have an idea what this heavy cost has,

00:31:36,210 --> 00:31:39,110
what effect has this heavy cost on all your measurement

00:31:39,110 --> 00:31:41,370
because you don't really show

00:31:41,370 --> 00:31:43,863
what the cost of all these stuff.

00:31:45,490 --> 00:31:47,780
- No, I don't have the numbers with me right now, sorry.

00:31:47,780 --> 00:31:49,730
- Yeah, it should definitely run perf top

00:31:49,730 --> 00:31:52,110
while only your test is running and see if it shows up.

00:31:52,110 --> 00:31:53,010
That would be interesting.

00:31:53,010 --> 00:31:56,680
- I usually collect the stuff, I just didn't have time to

00:31:57,680 --> 00:31:59,430
because I had to rerun some tests first.

00:31:59,430 --> 00:32:00,810
- [Host] Okay, it's definitely something to look into.

00:32:00,810 --> 00:32:01,643
- Yeah, thank you.

00:32:01,643 --> 00:32:03,680
- [Host] Any other questions?

00:32:03,680 --> 00:32:04,820
Thank you very much Lawrence.

00:32:04,820 --> 00:32:05,878
- Okay, thank you.

00:32:05,878 --> 00:32:08,297

YouTube URL: https://www.youtube.com/watch?v=wIWpqkdGrEM


