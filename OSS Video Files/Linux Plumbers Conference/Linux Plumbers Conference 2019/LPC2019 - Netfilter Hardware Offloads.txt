Title: LPC2019 - Netfilter Hardware Offloads
Publication date: 2019-09-17
Playlist: Linux Plumbers Conference 2019
Description: 
	netfilter hardware offloads

Speaker
Mr Pablo Neira
Description
With the advent of the the flow rule and flow block API, ethtool_rx, netfilter and tc can share the same infrastructure to represent hardware offloads.
Captions: 
	00:00:00,380 --> 00:00:02,263
- All right we're gonna get started.

00:00:05,990 --> 00:00:07,943
Quick announcement.

00:00:09,370 --> 00:00:11,250
I've been asked that when people ask questions,

00:00:11,250 --> 00:00:14,070
please stand up because it helps with taking the video,

00:00:14,070 --> 00:00:17,060
otherwise you can't be seen and your mouth can't be seen.

00:00:17,060 --> 00:00:18,840
It's easier to understand what you're saying.

00:00:18,840 --> 00:00:22,470
So, please stand up when you wanna make a question, okay?

00:00:22,470 --> 00:00:27,330
Our next talk is about netfilter hardware offloads by Pablo.

00:00:27,330 --> 00:00:28,740
Pablo's been a netfilter maintainer

00:00:28,740 --> 00:00:31,670
for a very, very long time, doing a great job there

00:00:31,670 --> 00:00:33,110
and he's been doing work lately

00:00:33,110 --> 00:00:38,010
to more abstract the TC offloading infrastructure

00:00:38,010 --> 00:00:40,100
so that subsystems such as netfilter

00:00:40,100 --> 00:00:41,860
can take advantage of it, as well.

00:00:41,860 --> 00:00:43,766
Please give him a warm welcome.

00:00:43,766 --> 00:00:46,766
(audience applauds)

00:00:48,490 --> 00:00:49,573
- Hi everyone.

00:00:52,324 --> 00:00:55,317
So, I'm going to talk a bit about the developments

00:00:56,500 --> 00:00:59,000
that have happened on the netfilter domain,

00:00:59,000 --> 00:01:03,203
in terms of hardware offloads, in the last month.

00:01:05,960 --> 00:01:08,350
I forgot to say, I'm very glad to be here.

00:01:08,350 --> 00:01:13,270
So, basically, this talk is going to be focused

00:01:13,270 --> 00:01:15,500
on two use cases that are, basically,

00:01:15,500 --> 00:01:18,250
the hardware policy offload,

00:01:18,250 --> 00:01:20,150
and there is a different use case,

00:01:20,150 --> 00:01:21,950
that is, basically, the flowtable,

00:01:21,950 --> 00:01:24,950
the contract flowtable bypass.

00:01:24,950 --> 00:01:29,410
So, at the end of the presentation, I will propose

00:01:29,410 --> 00:01:33,117
a way to use the same infrastructure for both use cases.

00:01:36,440 --> 00:01:37,510
And also, I will explain a bit

00:01:37,510 --> 00:01:40,123
on the particularities of both of them.

00:01:41,439 --> 00:01:45,173
So, I'm going to start with the flow offload API,

00:01:46,990 --> 00:01:50,014
which is going to be used by these two main clients.

00:01:50,014 --> 00:01:52,950
So, basically, the idea is,

00:01:52,950 --> 00:01:56,033
that in order to avoid duplicated code,

00:01:59,700 --> 00:02:01,710
I mean, basically, on the table we've found

00:02:01,710 --> 00:02:04,140
before the path side that got matched

00:02:04,140 --> 00:02:08,900
is that some drivers have start to duplicate code

00:02:08,900 --> 00:02:13,390
to configure the offloads via the ethtool

00:02:13,390 --> 00:02:14,823
and also, tc flower.

00:02:19,470 --> 00:02:21,470
Basically, the idea was to try to find

00:02:21,470 --> 00:02:24,748
a unified representation for the driver

00:02:24,748 --> 00:02:29,748
to expose the rule that is going to be

00:02:29,880 --> 00:02:32,610
pushed into the hardware for the packet classification.

00:02:32,610 --> 00:02:35,660
So, if there is a common representation,

00:02:35,660 --> 00:02:40,660
both for ethtool and also for tc, the drivers could take,

00:02:42,347 --> 00:02:43,947
then code could be consolidated.

00:02:45,522 --> 00:02:48,620
And then, at the same, we would open up for more offloads,

00:02:49,770 --> 00:02:52,110
in this case, for netfilter.

00:02:52,110 --> 00:02:56,920
So, it will be just, productively easy just to

00:02:56,920 --> 00:03:00,580
make the front end to transform the native representation

00:03:00,580 --> 00:03:03,230
and use these intermediate representation

00:03:03,230 --> 00:03:04,850
and then push it to the driver.

00:03:04,850 --> 00:03:07,900
The driver would actually not distinguish

00:03:07,900 --> 00:03:10,530
where this representation is coming from,

00:03:10,530 --> 00:03:12,380
actually this is going to change on time

00:03:12,380 --> 00:03:15,510
because we want to have, as I would explain,

00:03:15,510 --> 00:03:18,400
we will have blocks for each subsystem

00:03:18,400 --> 00:03:22,030
and every offload will be in a pipeline,

00:03:22,030 --> 00:03:27,030
so the same processing in software will be happening

00:03:27,500 --> 00:03:31,130
but so far, it's a bit like,

00:03:31,130 --> 00:03:33,210
no matter from one front then this is coming,

00:03:33,210 --> 00:03:35,480
this flow rule representation is coming,

00:03:35,480 --> 00:03:40,480
the drivers are going to place it into the hardware.

00:03:44,673 --> 00:03:48,230
So, the flow off of the API is basically composed

00:03:48,230 --> 00:03:52,297
of two main objects that are the flow rule API,

00:03:53,400 --> 00:03:54,630
the flow rule object.

00:03:54,630 --> 00:03:58,900
This flow rule object is composed of two fields,

00:03:58,900 --> 00:04:00,960
it's one object is the flow match

00:04:00,960 --> 00:04:02,240
and another is the flow action.

00:04:02,240 --> 00:04:05,150
The flow match allows you to express

00:04:05,150 --> 00:04:07,090
what you want to match on the rule

00:04:07,090 --> 00:04:09,930
and the flow action allows you to specify what actions

00:04:09,930 --> 00:04:12,230
are going to be applying, in case of matching.

00:04:17,670 --> 00:04:21,150
To express the matching side of the rule,

00:04:21,150 --> 00:04:23,760
there was a representation already in place

00:04:23,760 --> 00:04:27,520
that wasn't being used by tc flower,

00:04:27,520 --> 00:04:30,943
so for tc flower, this is going to be the native.

00:04:32,375 --> 00:04:35,470
So, we are just taking the flow dissector representation

00:04:35,470 --> 00:04:38,770
that flower is using to express the matching side

00:04:38,770 --> 00:04:41,770
and for the action side, this is based on the tc action.

00:04:41,770 --> 00:04:45,990
So, because the initial actions

00:04:45,990 --> 00:04:48,710
have been offloading to hardware

00:04:48,710 --> 00:04:52,480
has been done through the tc action API,

00:04:52,480 --> 00:04:55,580
the idea has been just to, basically,

00:04:55,580 --> 00:04:58,590
start by adding an API that looks

00:04:58,590 --> 00:05:02,080
very much similar to the tc action API,

00:05:02,080 --> 00:05:04,670
but a long time, the plan is probably,

00:05:04,670 --> 00:05:06,650
these two APIs, they will diverge

00:05:06,650 --> 00:05:10,280
because, basically, the tc action API is a front end API,

00:05:10,280 --> 00:05:11,970
it's a software front end API,

00:05:11,970 --> 00:05:13,310
and also at the same time,

00:05:13,310 --> 00:05:16,400
while it's good to avoid duplicated code,

00:05:16,400 --> 00:05:17,850
in my opinion, it's also good if

00:05:17,850 --> 00:05:20,790
the software front end gets decoupled

00:05:20,790 --> 00:05:24,090
from the flow rule representation,

00:05:24,090 --> 00:05:27,680
in particular, because if a software developer

00:05:27,680 --> 00:05:30,580
wants to introduce a new feature in the front end,

00:05:30,580 --> 00:05:35,580
it won't be good if he ends up updating code

00:05:36,450 --> 00:05:38,690
all over the place in the drivers

00:05:38,690 --> 00:05:43,690
that are referencing data structures that are part of tc.

00:05:43,940 --> 00:05:46,393
So, it's also, in terms of maintenance,

00:05:47,250 --> 00:05:49,140
I think it's a good idea that we have

00:05:49,140 --> 00:05:50,740
this intermediate representation.

00:05:50,740 --> 00:05:52,920
It's basically blue code between the driver

00:05:52,920 --> 00:05:54,493
and the front end side.

00:05:55,920 --> 00:05:58,980
And the other main object is the flow block,

00:05:58,980 --> 00:06:00,830
I will talk, also, about this one.

00:06:00,830 --> 00:06:03,680
So, this has been more of the tales of

00:06:03,680 --> 00:06:08,560
what I've been talking is, it's basically, this flow match.

00:06:08,560 --> 00:06:10,930
It's using these flow dissector object

00:06:10,930 --> 00:06:14,063
and that to point us to opaque structures,

00:06:15,197 --> 00:06:18,380
the opaque structures are the mask and the key.

00:06:18,380 --> 00:06:22,360
So, they are just using the flow dissector API,

00:06:22,360 --> 00:06:27,360
which is basically has use keys field

00:06:30,757 --> 00:06:33,400
that you can use to set flags

00:06:33,400 --> 00:06:36,240
and these flags tell what fields

00:06:36,240 --> 00:06:39,720
in the flow dissector are being used

00:06:39,720 --> 00:06:43,560
and then, the offset is basically initialized to point to,

00:06:43,560 --> 00:06:47,503
because these opaque objects are per subsystem,

00:06:49,300 --> 00:06:51,650
these offsets are initialized to the fields

00:06:51,650 --> 00:06:56,172
of these key and mask, depending on tc

00:06:56,172 --> 00:06:58,790
or ethtool or on netfilter.

00:06:58,790 --> 00:07:01,740
They are not the same, that could be changed at that point.

00:07:03,614 --> 00:07:05,770
As things are looking today,

00:07:05,770 --> 00:07:07,700
it's basically using the flow dissector API

00:07:07,700 --> 00:07:10,523
to represent the match inside of the rule.

00:07:11,810 --> 00:07:16,810
So, one example is this flow dissector key ethernet address.

00:07:17,650 --> 00:07:20,880
So, this allows you to match on the destination

00:07:20,880 --> 00:07:22,743
and source ethernet address.

00:07:24,690 --> 00:07:26,270
You have both the mask and the key,

00:07:26,270 --> 00:07:27,740
so you can specify if you only want

00:07:27,740 --> 00:07:30,293
to match the source or the destination or both.

00:07:32,760 --> 00:07:37,440
So, this is basically how you can express

00:07:37,440 --> 00:07:38,940
the matching side of the rule.

00:07:40,976 --> 00:07:42,710
And then, the actions they are, as I said,

00:07:42,710 --> 00:07:45,220
they are based on the tc action API,

00:07:45,220 --> 00:07:48,090
so there is a flow action object

00:07:48,090 --> 00:07:52,590
that contains a number of entries using an array of entries

00:07:52,590 --> 00:07:56,310
and then each entry has an id

00:07:56,310 --> 00:07:58,490
that identifies the type of actions

00:07:58,490 --> 00:07:59,410
and then you have a union

00:07:59,410 --> 00:08:02,097
that contains all of the options there are,

00:08:03,631 --> 00:08:05,950
all of the parameters that these action,

00:08:05,950 --> 00:08:07,000
in particular, needs.

00:08:10,460 --> 00:08:12,540
So,me of the actions that are available,

00:08:12,540 --> 00:08:14,670
one of the good things that I would say

00:08:14,670 --> 00:08:18,220
that are a part of this flow rule API, is that now,

00:08:18,220 --> 00:08:20,990
before this flow rule API, you have to read

00:08:22,116 --> 00:08:25,410
all drivers in the tree to guess what actions

00:08:25,410 --> 00:08:29,410
were actually available or being offload.

00:08:29,410 --> 00:08:30,970
Now there is a clear API

00:08:30,970 --> 00:08:34,630
and if there is some of the actions that is missing,

00:08:34,630 --> 00:08:36,200
you can just add in.

00:08:36,200 --> 00:08:39,460
So, there is a number of actions,

00:08:39,460 --> 00:08:43,290
this is just a bit of them, not all of them,

00:08:43,290 --> 00:08:44,840
but you can just express

00:08:44,840 --> 00:08:46,660
if you want to accept or drop the packet,

00:08:46,660 --> 00:08:50,263
if you want to redirect it or mirror it to a net device,

00:08:51,610 --> 00:08:56,610
you could also push a VLAN encapsulation, pop it, mangle it.

00:08:59,860 --> 00:09:00,693
There is also similar action

00:09:00,693 --> 00:09:03,390
for NPLAN that has been added quite recently.

00:09:03,390 --> 00:09:06,600
There is also an action for payload mangling.

00:09:06,600 --> 00:09:09,050
There is another action for updating the checksum

00:09:12,310 --> 00:09:14,550
that usually comes together with the mangling action.

00:09:14,550 --> 00:09:19,550
So, there is another action that is the tunnel action,

00:09:21,138 --> 00:09:25,440
it is generic, it's basically, it's actually rather generic

00:09:25,440 --> 00:09:28,743
but it's being used by VXLAN and GENEVE these days,

00:09:29,790 --> 00:09:32,230
which is what I've seen in the drivers so far.

00:09:32,230 --> 00:09:35,170
And then there is a couple of actions that were added

00:09:36,350 --> 00:09:38,440
because they were needed for ethtool,

00:09:38,440 --> 00:09:41,420
that are the wake up LAN action

00:09:41,420 --> 00:09:45,290
and also the packet steering action,

00:09:45,290 --> 00:09:47,240
just basically, for packet steering

00:09:47,240 --> 00:09:51,733
just to place the packet in the right queue.

00:09:52,844 --> 00:09:54,170
So, those are a bit of them.

00:09:54,170 --> 00:09:59,170
So, all these API comes with a few of helpers.

00:10:02,960 --> 00:10:05,050
There is one for tc,

00:10:05,050 --> 00:10:09,460
since this API is using flower, match is native

00:10:09,460 --> 00:10:12,670
because flower uses the flow dissector API already,

00:10:12,670 --> 00:10:16,560
and then there is a helper that is tc setup flow action

00:10:16,560 --> 00:10:21,490
that translate the tc action to the flow action API.

00:10:21,490 --> 00:10:25,230
And then for ethtool, there is a helper function

00:10:25,230 --> 00:10:28,687
that takes, basically, the ethtool rx flow inspect layout

00:10:32,300 --> 00:10:37,300
and it translate that layout to the flow rule object.

00:10:43,120 --> 00:10:46,970
So, in terms of code, you can find the header file

00:10:46,970 --> 00:10:51,687
it's under include net flow offload.h

00:10:52,710 --> 00:10:55,500
and then basically the core

00:10:55,500 --> 00:10:57,930
is placed at net core flow offload.c.

00:10:57,930 --> 00:11:00,683
There is a number of drivers already using this,

00:11:01,820 --> 00:11:04,910
either for flower, now also for netfilter,

00:11:04,910 --> 00:11:08,830
and some of them, they are also using it for ethtool,

00:11:08,830 --> 00:11:12,993
that are the Qlogic and also the Broadcom and StarFighter.

00:11:17,499 --> 00:11:18,730
What introduces this API,

00:11:18,730 --> 00:11:21,293
all these driver were translated to use it.

00:11:22,290 --> 00:11:26,110
The flow block API, that is basically, the other objects,

00:11:26,110 --> 00:11:30,970
that we now have this flow rule object to express

00:11:30,970 --> 00:11:34,150
the rule that is going to be placed into the hardware,

00:11:34,150 --> 00:11:37,480
so there is another API for this flow block,

00:11:37,480 --> 00:11:40,703
but basically, the idea of the block was introduced

00:11:40,703 --> 00:11:44,310
to have a way to share policies

00:11:44,310 --> 00:11:48,543
between different tc ingress qdiscs.

00:11:50,630 --> 00:11:55,630
One tc block could be used by multiple ingress qdiscs

00:11:56,926 --> 00:12:00,410
so you don't have to duplicate the policy

00:12:00,410 --> 00:12:01,560
among different qdiscs.

00:12:03,900 --> 00:12:06,783
The front end has to set up this block object.

00:12:08,588 --> 00:12:09,421
There are two operations that are

00:12:09,421 --> 00:12:12,190
this flow block bind and unbind.

00:12:12,190 --> 00:12:16,080
This flow block bind happens when,

00:12:16,080 --> 00:12:20,950
in the case of tc, when the block is set up,

00:12:20,950 --> 00:12:22,680
and in case of netfilter,

00:12:22,680 --> 00:12:26,193
it happens when the basechain is created.

00:12:27,350 --> 00:12:31,530
So far, in netfilter, there is only one flow block,

00:12:31,530 --> 00:12:35,020
that should read as one flow block, not tc block.

00:12:35,020 --> 00:12:37,743
That's mistaken on the third item.

00:12:38,720 --> 00:12:43,660
So, it's one flow block and one netfilter basechain, so far.

00:12:43,660 --> 00:12:47,300
It should be possible to support more than one flow block.

00:12:47,300 --> 00:12:49,320
The idea would be to, basically,

00:12:49,320 --> 00:12:53,650
to allow for netfilter basechains on the ingress hook,

00:12:53,650 --> 00:12:56,080
the idea would be to allow to specify

00:12:56,080 --> 00:12:58,220
more than one single device, something like

00:12:58,220 --> 00:13:01,230
specify array of devices in the basechain,

00:13:01,230 --> 00:13:06,230
so all these devices could share the same policy.

00:13:07,130 --> 00:13:10,070
So, no need to explicitly expose any object

00:13:10,070 --> 00:13:14,240
in netfilter for this, as it happens in tc.

00:13:14,240 --> 00:13:18,270
So, so far, only one of the subsystem

00:13:18,270 --> 00:13:23,270
can bind to the flow block.

00:13:24,500 --> 00:13:27,810
This means that at this point, you have to either choose

00:13:27,810 --> 00:13:30,593
between tc or netfilter, which is not good for anyone.

00:13:32,040 --> 00:13:34,890
But there are plans to, or at least I was told,

00:13:34,890 --> 00:13:37,400
front driver developers that would be code

00:13:37,400 --> 00:13:41,760
landing in the street soon to basically to allow

00:13:41,760 --> 00:13:45,630
to create multiple blocks, one for each subsystem

00:13:45,630 --> 00:13:50,630
and so you could offload any subsystem.

00:13:53,120 --> 00:13:58,120
Also, there should be room to add a block for ethtool, too.

00:14:01,140 --> 00:14:03,460
There has been discussions on where to set up the block

00:14:03,460 --> 00:14:07,160
because there is no explicit, in the ethtool,

00:14:07,160 --> 00:14:10,397
there is no explicit way to indicate this,

00:14:10,397 --> 00:14:12,300
you set up a block.

00:14:12,300 --> 00:14:14,590
In tc ingress, you set up a block,

00:14:14,590 --> 00:14:17,130
in netfilter, you set up a basechain,

00:14:17,130 --> 00:14:18,640
in ethtool, that does not exist,

00:14:18,640 --> 00:14:21,607
you just directly other rule to the nic.

00:14:29,250 --> 00:14:33,300
How the flow block API is used for netfilter is basically,

00:14:33,300 --> 00:14:38,300
there is a hardware offload flag for basechains

00:14:40,450 --> 00:14:43,330
that is, basically, telling that this,

00:14:43,330 --> 00:14:45,530
all the policies that are contained,

00:14:45,530 --> 00:14:48,870
all the rules that are contained in these basechain

00:14:49,860 --> 00:14:52,170
should be placed in hardware.

00:14:52,170 --> 00:14:57,170
So, it's a toggle that the user can enable, disable.

00:14:57,640 --> 00:14:59,270
Obviously if the card cannot do it,

00:14:59,270 --> 00:15:01,813
the user would just get I don't support this.

00:15:03,070 --> 00:15:06,203
So, by when the netfilter basechain is created,

00:15:07,460 --> 00:15:12,460
the NDO set up tc with the flow block setup at action time

00:15:15,116 --> 00:15:20,116
and the flow block bind time will be specified

00:15:21,460 --> 00:15:24,470
and then, basically, the driver

00:15:24,470 --> 00:15:28,423
will create this flow block object, configure it,

00:15:29,340 --> 00:15:34,340
and then pass it back to netfilter already ready to be used.

00:15:37,000 --> 00:15:41,442
Then, every time you add a rule,

00:15:41,442 --> 00:15:44,270
netfilter iterates over the list of blocks

00:15:44,270 --> 00:15:46,980
that have been registered

00:15:50,015 --> 00:15:54,210
and then when the user removes the netfilter basechain,

00:15:54,210 --> 00:15:56,500
what happens is that netfilter first

00:15:56,500 --> 00:15:58,820
has to iterate over the list of blocks

00:15:58,820 --> 00:16:03,240
and tell them to remove all the rules

00:16:03,240 --> 00:16:06,363
and then, release the flow block.

00:16:09,550 --> 00:16:11,660
So, this picture shows a bit how it looks,

00:16:11,660 --> 00:16:14,053
so either from netfilter or tc,

00:16:19,300 --> 00:16:22,320
the idea is that via the NDO stop tc,

00:16:27,070 --> 00:16:29,640
they'd request the driver to stop the flow block

00:16:30,590 --> 00:16:33,940
and then they get back this block

00:16:33,940 --> 00:16:37,657
and they keep the basechain or the qdisc.

00:16:42,003 --> 00:16:43,170
The tc qdisc ingress is going to keep

00:16:43,170 --> 00:16:45,820
a list of blocks that is available

00:16:45,820 --> 00:16:50,820
so once the user push a rule into the hardware,

00:16:51,470 --> 00:16:53,970
what had happens is that either netfilter or tc,

00:16:53,970 --> 00:16:57,770
they are going to transform the native representation

00:16:57,770 --> 00:17:00,253
to the flow rule API and then they are going to

00:17:00,253 --> 00:17:03,283
iterate over the list of blocks that have been set up,

00:17:05,230 --> 00:17:07,773
that basically just drive the object to the driver.

00:17:16,100 --> 00:17:19,670
So, what is important right now in netfilter

00:17:19,670 --> 00:17:22,160
through these new flow offload APIs,

00:17:22,160 --> 00:17:27,160
so basically, you can offload

00:17:27,260 --> 00:17:31,470
only basechains on the ingress hook,

00:17:31,470 --> 00:17:34,013
where you can enable this offload flag.

00:17:35,748 --> 00:17:39,400
So, far priorities are supported for this basechains

00:17:39,400 --> 00:17:43,583
are from one to Cobalt 16.

00:17:45,670 --> 00:17:47,930
And this is just because this is the priorities

00:17:47,930 --> 00:17:51,160
that has been, that are, these days supported by drivers

00:17:51,160 --> 00:17:54,200
because this is what tc has been supporting,

00:17:54,200 --> 00:17:58,743
has been exposing through the pref option.

00:18:02,150 --> 00:18:07,150
And then, so far, only support for the accept policy,

00:18:07,740 --> 00:18:12,420
you can match on traffic using payload matching.

00:18:12,420 --> 00:18:15,000
You could also accept drop traffic.

00:18:15,000 --> 00:18:19,440
There is also a netmask matching that is

00:18:19,440 --> 00:18:22,050
going to come in the next release.

00:18:22,050 --> 00:18:26,350
And also, a couple of actions, just basically to mirror

00:18:26,350 --> 00:18:29,760
and also to redirect traffic, that is this forward action

00:18:29,760 --> 00:18:31,850
and duplicate action that will

00:18:31,850 --> 00:18:33,420
come also in the next release.

00:18:33,420 --> 00:18:35,850
Those are basically the actions that are supported,

00:18:35,850 --> 00:18:39,453
which is still behind of what tc can do,

00:18:40,480 --> 00:18:43,960
but the idea is that, as time passes by,

00:18:43,960 --> 00:18:45,473
the plan is to catch up.

00:18:48,420 --> 00:18:50,580
For the payload mangling,

00:18:50,580 --> 00:18:53,910
there is also a bounce set on the table

00:18:53,910 --> 00:18:56,210
and there's some ongoing discussions going on.

00:18:57,060 --> 00:19:00,760
So, basically, the flow action mangle representation

00:19:01,752 --> 00:19:06,752
uses the native TCP packet edit representation,

00:19:07,490 --> 00:19:10,620
so because the flow action API

00:19:10,620 --> 00:19:15,620
has been modeled from the tc action API,

00:19:16,590 --> 00:19:21,590
it's basically, taking what tc was using

00:19:22,300 --> 00:19:26,240
to represent packet mangling and there was p edit.

00:19:26,240 --> 00:19:29,770
And then p edit has a number of specificities,

00:19:34,543 --> 00:19:36,477
such as p edit works with words of 32-bits

00:19:40,150 --> 00:19:43,583
so always offsets are aligned to 32-bits,

00:19:44,780 --> 00:19:48,990
so the driver needs to look at the mask

00:19:48,990 --> 00:19:51,900
to infer what part of the mangle, what is going to happen.

00:19:51,900 --> 00:19:55,190
So, that is expressed in network by order,

00:19:55,190 --> 00:19:59,356
so in case you want to match source port or deport,

00:19:59,356 --> 00:20:01,220
playing with a mask, you know,

00:20:01,220 --> 00:20:05,180
the driver knows if you want to mangle the source port

00:20:07,220 --> 00:20:08,990
or the destination port,

00:20:08,990 --> 00:20:13,990
which might be, depending on the driver,

00:20:14,760 --> 00:20:17,191
it might result in extra complexity.

00:20:17,191 --> 00:20:20,020
And also, you need up to four actions

00:20:20,020 --> 00:20:24,480
to mangle one IPv6 address, so it's a bit off,

00:20:24,480 --> 00:20:26,730
go backs and forths, so it's like,

00:20:26,730 --> 00:20:29,593
one part of the 32-bits of the IP address,

00:20:29,593 --> 00:20:31,210
and then you get the action, the driver's configured

00:20:31,210 --> 00:20:33,430
but then another action follows up

00:20:33,430 --> 00:20:35,880
and then another one, so it's four times the same thing

00:20:35,880 --> 00:20:39,000
but it could be only one single rule.

00:20:39,000 --> 00:20:41,040
So, there is a patchset available, basically,

00:20:41,040 --> 00:20:44,810
just to change offset alignment to 8-bits

00:20:46,370 --> 00:20:50,180
so the driver gets offset at byte level

00:20:50,180 --> 00:20:54,940
and also, this code adjust the offset

00:20:54,940 --> 00:20:56,640
and the length, based on the mask.

00:20:58,530 --> 00:21:01,460
So far, there is one problem with that patchset,

00:21:01,460 --> 00:21:06,460
at least there was one developer on the main list,

00:21:08,110 --> 00:21:12,720
basically, telling that with the approach I was following,

00:21:12,720 --> 00:21:14,650
it's not possible anymore to mangle one single byte

00:21:14,650 --> 00:21:18,550
of the TCP port, either source or destination.

00:21:18,550 --> 00:21:19,860
So, I have to fix that.

00:21:19,860 --> 00:21:22,099
I don't know the use case for that

00:21:22,099 --> 00:21:25,349
but he has one, so I'm going to fix it.

00:21:28,761 --> 00:21:32,600
And then, the other use case for this flow offload APIs

00:21:32,600 --> 00:21:34,250
is the contract flowtable bypass.

00:21:36,394 --> 00:21:40,250
The idea of this infrastructure

00:21:40,250 --> 00:21:42,350
is to provide an alternative fast path

00:21:42,350 --> 00:21:44,430
to the classic forwarding path.

00:21:44,430 --> 00:21:46,190
So, there is a software plane

00:21:47,910 --> 00:21:50,793
that implements this new flowtable object.

00:21:52,110 --> 00:21:56,220
So, this representation is independent from hardware

00:21:56,220 --> 00:22:00,043
so you could use it to speed up forwarding,

00:22:01,550 --> 00:22:02,910
purely in software.

00:22:02,910 --> 00:22:07,243
So, basically, the idea is once a packet gets in to ingress,

00:22:09,300 --> 00:22:12,060
there is a lookup in the flowtable,

00:22:12,060 --> 00:22:13,670
it's basically a hash table to check

00:22:13,670 --> 00:22:15,660
if there is a 5-tuple matching,

00:22:15,660 --> 00:22:19,630
exact 5-tuple matching in the hash table.

00:22:19,630 --> 00:22:21,640
If there is one, then we know already

00:22:21,640 --> 00:22:22,590
what to do with the packet,

00:22:22,590 --> 00:22:26,490
we know the destination port, the destination device,

00:22:26,490 --> 00:22:28,330
so we just basically, take the packet

00:22:28,330 --> 00:22:33,330
and also take command TTL, apply mangling and so on,

00:22:33,520 --> 00:22:37,503
and then packet is placed in the right net device.

00:22:43,010 --> 00:22:45,499
And then, for the forward netfilter chain,

00:22:45,499 --> 00:22:47,530
the idea is that you have an action that is flow, off flow,

00:22:47,530 --> 00:22:49,860
that allows you to tell what traffic is going to

00:22:49,860 --> 00:22:54,860
be placed into these contract flowtable at the ingress hook.

00:22:58,060 --> 00:23:03,060
So, this is basically, what I've been describing

00:23:03,970 --> 00:23:07,720
is for each packet, the idea is to extract the tuple

00:23:07,720 --> 00:23:09,490
and then perform the look at the flowtable.

00:23:09,490 --> 00:23:11,500
If there is a miss, the packet follows

00:23:11,500 --> 00:23:13,050
the classic forwarding path.

00:23:13,050 --> 00:23:15,320
If there is a hit, attach the route,

00:23:15,320 --> 00:23:20,020
apply NAT, decrement TTL, and then send via neigh xmit.

00:23:20,020 --> 00:23:21,410
There is a few exceptions,

00:23:21,410 --> 00:23:25,780
in case the packet is over MTU or IP options available,

00:23:25,780 --> 00:23:27,080
in that case, the packet needs

00:23:27,080 --> 00:23:29,773
to follow the classic forwarding path.

00:23:31,118 --> 00:23:33,420
There is a tear down state that is basically,

00:23:33,420 --> 00:23:38,420
if the flowtable sees a TCP reset or fin packet,

00:23:38,450 --> 00:23:43,450
the entry is scheduled to be removed from the flowtable

00:23:44,562 --> 00:23:48,910
and the packets, after reset, basically,

00:23:48,910 --> 00:23:51,993
the connection tracking takes over control on the entry.

00:23:52,944 --> 00:23:55,620
It's basically, a way to release

00:23:55,620 --> 00:23:59,102
any resources from the flowtable.

00:23:59,102 --> 00:24:00,090
And there is also a garbage collector,

00:24:00,090 --> 00:24:04,180
in case the flowtable doesn't see a packet after N seconds.

00:24:04,180 --> 00:24:06,420
Currently is quite aggressive, it's only 30 seconds,

00:24:06,420 --> 00:24:07,450
but that can be changed

00:24:07,450 --> 00:24:09,900
and also, the timeout can be disposed.

00:24:09,900 --> 00:24:13,330
So, the idea is that, if after N seconds,

00:24:13,330 --> 00:24:18,330
you don't see any packet matching an entry in the flowtable

00:24:20,289 --> 00:24:22,720
what happens is that the entry expires

00:24:22,720 --> 00:24:24,930
and is removed from the flowtable

00:24:24,930 --> 00:24:26,810
but it is basically, hand over,

00:24:26,810 --> 00:24:28,840
back to the connection tracking.

00:24:28,840 --> 00:24:33,200
So, there is a pickup timeout that kicks in,

00:24:33,200 --> 00:24:36,120
and the entry is set to establish state

00:24:36,120 --> 00:24:39,950
and after that timeout, then the entry expires

00:24:39,950 --> 00:24:41,300
in the connection tracking.

00:24:44,690 --> 00:24:47,410
So, the way to configure this is with one single rule,

00:24:47,410 --> 00:24:49,757
just specify the devices that

00:24:52,620 --> 00:24:55,860
are part of the contract flowtable

00:24:55,860 --> 00:24:58,350
and then there is an action from the forward chain

00:24:58,350 --> 00:25:00,580
that allows you to specify what flows

00:25:00,580 --> 00:25:03,790
are going to be placed into the flowtable.

00:25:03,790 --> 00:25:06,480
Another change that happened in the contract flowtable

00:25:06,480 --> 00:25:11,480
is that before, in the initial approach,

00:25:17,360 --> 00:25:19,610
the flowtable action needed

00:25:21,923 --> 00:25:23,190
to see packets in both directions

00:25:23,190 --> 00:25:25,050
but that doesn't work for EDB flows

00:25:25,050 --> 00:25:26,830
going one single direction, so it's basically,

00:25:26,830 --> 00:25:29,863
once the connection tracking entry is confirmed,

00:25:30,718 --> 00:25:31,707
so once the first packet has

00:25:31,707 --> 00:25:36,707
fully went through the networking stack,

00:25:37,890 --> 00:25:42,120
then after that, the next packet then follows the fast path.

00:25:42,120 --> 00:25:47,120
So, once one packet follows the

00:25:47,763 --> 00:25:51,650
entire classic forwarding path,

00:25:51,650 --> 00:25:55,333
then the flowtable path kicks in.

00:25:57,830 --> 00:25:59,520
But, anyway, this is configurable

00:25:59,520 --> 00:26:01,370
so it's through policy you specify

00:26:01,370 --> 00:26:04,190
when you add the entry to the flowtable,

00:26:04,190 --> 00:26:06,360
so it could be after it's 10 seconds,

00:26:06,360 --> 00:26:08,560
after inspecting the payload,

00:26:08,560 --> 00:26:13,560
once the TCB flow has been established

00:26:13,710 --> 00:26:15,960
and you see some traffic on the payload.

00:26:15,960 --> 00:26:20,960
So, it's whenever you want, whenever the user decides to,

00:26:23,510 --> 00:26:26,500
the entry is added to the flowtable.

00:26:26,500 --> 00:26:30,300
So, there is no predefined behavior.

00:26:30,300 --> 00:26:32,360
- [Host] When you instantiate the flowtable,

00:26:32,360 --> 00:26:33,890
like in this rule, is that where

00:26:33,890 --> 00:26:36,320
you can specify the timeout being shorter?

00:26:36,320 --> 00:26:38,453
- Yeah, exactly, it will be an option.

00:26:44,570 --> 00:26:48,280
So, the contract flowtable bypass in hardware,

00:26:48,280 --> 00:26:52,820
basically, the idea is to,

00:26:52,820 --> 00:26:55,640
so because all this flow rule API

00:26:55,640 --> 00:26:57,400
and flow block infrastructure,

00:26:57,400 --> 00:27:01,323
all these flow offload API that it not available,

00:27:02,260 --> 00:27:05,810
the idea is to avoid, basically, to consolidate the code,

00:27:05,810 --> 00:27:08,270
provide one single unified representation to the driver.

00:27:08,270 --> 00:27:11,730
It would make no sense to use it for the contract flowtable

00:27:11,730 --> 00:27:16,040
so the idea is that, basically, contract entry is,

00:27:16,040 --> 00:27:20,250
basically, represented by an exact double matching

00:27:20,250 --> 00:27:22,790
and then you could use the SD action,

00:27:22,790 --> 00:27:26,190
redirect to specify what this nation port,

00:27:26,190 --> 00:27:30,000
so it's like a rule but the difference is

00:27:30,000 --> 00:27:35,000
that rule is added from the packet path via workqueue.

00:27:35,870 --> 00:27:37,670
So, just to make sure that the

00:27:37,670 --> 00:27:39,860
configuration happens from user context,

00:27:39,860 --> 00:27:42,180
we need these to happen from the workqueue.

00:27:42,180 --> 00:27:45,140
The flowtable software plane,

00:27:45,140 --> 00:27:48,480
make sure that this looks consistent to the user

00:27:48,480 --> 00:27:51,630
because the workqueue takes time to kick in

00:27:52,788 --> 00:27:56,090
and to configure the hardware.

00:27:56,090 --> 00:27:57,930
That is a little bit of time

00:27:57,930 --> 00:28:01,090
that packets are already offload,

00:28:01,090 --> 00:28:04,190
will still be seen by software,

00:28:04,190 --> 00:28:07,850
but they will follow the software flowtable path

00:28:07,850 --> 00:28:11,380
and then once the hardware is configured,

00:28:11,380 --> 00:28:15,717
then the host CPU stops seeing packets

00:28:15,717 --> 00:28:17,783
and they basically, follow the hardware path.

00:28:22,760 --> 00:28:24,362
- [Audience Member] If using this software--

00:28:24,362 --> 00:28:25,289
- [Host] Please stand up.

00:28:25,289 --> 00:28:26,457
- [Audience Member] Oh, sorry.

00:28:26,457 --> 00:28:28,280
When using this software auto path

00:28:28,280 --> 00:28:30,970
the statistics can show on still, correct?

00:28:30,970 --> 00:28:32,016
- Sorry?

00:28:32,016 --> 00:28:33,495
- [Audience Member] Statistics, are they correct?

00:28:33,495 --> 00:28:34,537
- [Host] Statistics.

00:28:34,537 --> 00:28:35,620
- Statistics?

00:28:36,760 --> 00:28:37,760
- [Audience Member] Packet counter.

00:28:37,760 --> 00:28:38,810
- Yeah, packet counter.

00:28:38,810 --> 00:28:39,880
- [Audience Member] Are they maintained

00:28:39,880 --> 00:28:40,713
when using your software?

00:28:40,713 --> 00:28:42,310
- No, they are not currently maintained.

00:28:42,310 --> 00:28:43,250
No, they are not.

00:28:43,250 --> 00:28:45,723
And if, so basically, no.

00:28:48,275 --> 00:28:50,720
No, the idea, once the hardware offload is in place,

00:28:50,720 --> 00:28:52,940
so far, what has been discussed is that

00:28:52,940 --> 00:28:55,210
because the hardware can keep counters on that,

00:28:55,210 --> 00:28:58,080
would be to synchronize the contract counters

00:29:00,710 --> 00:29:04,690
because the entries is exposed with

00:29:04,690 --> 00:29:07,090
a offload label in the connection tracking,

00:29:07,090 --> 00:29:09,390
we could just synchronize those counters

00:29:09,390 --> 00:29:10,490
to the contract entry.

00:29:13,150 --> 00:29:14,555
- You kind of assume--

00:29:14,555 --> 00:29:15,738
- [Host] Stand up please.

00:29:15,738 --> 00:29:19,060
- (laughs) You're kind of assuming a very smart switch.

00:29:19,060 --> 00:29:21,050
If you look at the little ones in tsohost,

00:29:21,050 --> 00:29:23,380
which is they don't have counters per flow.

00:29:23,380 --> 00:29:24,710
- They don't have counter per flow?

00:29:24,710 --> 00:29:27,975
We can expose all these features that the hardware has,

00:29:27,975 --> 00:29:31,990
depending on what they offer, so it's not like...

00:29:32,890 --> 00:29:35,170
- [Host] So, one thing you usually see

00:29:35,170 --> 00:29:37,303
in this kind of situation is,

00:29:38,520 --> 00:29:41,360
make the default be the least common denominator,

00:29:41,360 --> 00:29:44,150
which would be not supporting the counters, right.

00:29:44,150 --> 00:29:46,383
And then in the rule, the user could say,

00:29:47,300 --> 00:29:49,200
I want counter synchronization

00:29:49,200 --> 00:29:51,830
and then you could fail the rule insertion

00:29:51,830 --> 00:29:54,010
if you had a device like that, otherwise you just--

00:29:54,010 --> 00:29:56,265
- Exactly, all this is going to happen

00:29:56,265 --> 00:29:58,570
from the control plane so the user can specify

00:29:58,570 --> 00:30:00,180
I want counters and then you can say,

00:30:00,180 --> 00:30:02,110
no I don't support counters, I'm sorry.

00:30:02,110 --> 00:30:03,350
Or you could even say,

00:30:03,350 --> 00:30:06,580
oh please describe what this flowtable can do

00:30:06,580 --> 00:30:08,970
and then the hardware will provide

00:30:08,970 --> 00:30:11,000
some description of what is available,

00:30:11,000 --> 00:30:15,430
so I can do this things, so the user doesn't even know,

00:30:15,430 --> 00:30:20,270
knows what to do and doesn't need to be trying,

00:30:20,270 --> 00:30:21,723
picking what is available.

00:30:28,560 --> 00:30:32,070
- Isn't the counter something necessary

00:30:32,070 --> 00:30:33,020
for connection tracking?

00:30:33,020 --> 00:30:34,750
Without the counter you won't be able to know

00:30:34,750 --> 00:30:36,690
if the connection is live or not.

00:30:36,690 --> 00:30:38,380
- Yeah, exactly.

00:30:38,380 --> 00:30:41,600
That's a point when you get things to the hardware,

00:30:41,600 --> 00:30:43,930
it's a bit like you are a bit blind,

00:30:43,930 --> 00:30:44,850
so you have no information

00:30:44,850 --> 00:30:46,260
on what is going on with the flow,

00:30:46,260 --> 00:30:47,840
so having the counters will help,

00:30:47,840 --> 00:30:51,037
but if there are hardware that don't support this, just--

00:30:52,003 --> 00:30:53,360
- [Audience Member] Wait, in the case of

00:30:53,360 --> 00:30:55,320
the less sophisticated devices,

00:30:55,320 --> 00:30:56,730
do they have like, an access bit

00:30:56,730 --> 00:30:58,700
that gets cleared occasionally or something like this

00:30:58,700 --> 00:31:02,523
so you can tell if it's alive, it's been recently touched?

00:31:05,960 --> 00:31:08,150
- So, for example on the marvel switches,

00:31:08,150 --> 00:31:09,950
you didn't command this in the T count

00:31:09,950 --> 00:31:13,023
and you'd see a T count rule has been hit recently.

00:31:14,112 --> 00:31:14,945
- And you can see that?

00:31:15,860 --> 00:31:17,710
- So, we could do something, even without the counters,

00:31:17,710 --> 00:31:19,868
to keep the entry alive.

00:31:19,868 --> 00:31:22,700
- Yeah, so then it could be exposed that way, too,

00:31:22,700 --> 00:31:24,513
to give a hint to the user.

00:31:26,120 --> 00:31:26,953
Thanks.

00:31:37,730 --> 00:31:39,330
I have been a bit fast.

00:31:39,330 --> 00:31:40,380
- [Host] That's okay.

00:31:45,990 --> 00:31:48,280
- So, if you have any more questions?

00:31:48,280 --> 00:31:49,200
Otherwise...

00:31:54,600 --> 00:31:55,850
- [Host] Please stand up.

00:31:56,900 --> 00:32:00,140
- Is there any order associated with calling these APIs,

00:32:00,140 --> 00:32:05,140
like, you're better off having CPU process the package

00:32:05,330 --> 00:32:07,253
other than offloading it to hardware?

00:32:09,320 --> 00:32:11,386
- So, you mean, if it would be

00:32:11,386 --> 00:32:13,323
better to do in software, right?

00:32:14,550 --> 00:32:17,900
It depends, there are devices

00:32:19,627 --> 00:32:23,940
that are not designed to go with the CPU they have.

00:32:23,940 --> 00:32:27,770
They are not designed to go with a bit rate

00:32:27,770 --> 00:32:30,380
that they can achieve with the net devices

00:32:30,380 --> 00:32:34,010
so there are awful big switches, for torque switches,

00:32:34,010 --> 00:32:37,510
they have very small CPU, just to deal,

00:32:37,510 --> 00:32:39,640
basically, with control plane traffic.

00:32:39,640 --> 00:32:40,583
So, in that case,

00:32:41,430 --> 00:32:43,260
because the way the device has been designed,

00:32:43,260 --> 00:32:46,918
there is no way they can cope with that bit rate.

00:32:46,918 --> 00:32:50,770
And it also happen with smaller switches that I have seen,

00:32:50,770 --> 00:32:53,350
so, they have CPU that can only cope with 100 megabits

00:32:53,350 --> 00:32:55,633
but they have 1 gigabit ports.

00:32:57,120 --> 00:32:59,090
- [Host] The other situation is where your time

00:32:59,090 --> 00:33:02,870
is dominated by cycling entries in and out of the hardware,

00:33:02,870 --> 00:33:06,380
programming and inserting, adding and deleting,

00:33:06,380 --> 00:33:07,930
but that's the dominant operation.

00:33:07,930 --> 00:33:10,870
It can be expensive compared to just software.

00:33:10,870 --> 00:33:11,970
It depends.

00:33:11,970 --> 00:33:12,803
- Yeah.

00:33:15,900 --> 00:33:17,200
Yeah, but definitely software

00:33:17,200 --> 00:33:19,480
is always more flexible than hardware is,

00:33:19,480 --> 00:33:22,840
so at some point, it's basically,

00:33:22,840 --> 00:33:25,240
in a situation where you don't have these kind of devices,

00:33:25,240 --> 00:33:26,540
it's a bit like a trade off, right.

00:33:26,540 --> 00:33:29,270
So, you could just decide to push a few,

00:33:29,270 --> 00:33:33,220
a number of flows to hardware to speed process

00:33:33,220 --> 00:33:38,220
and then if you want to make more inspection on those flows,

00:33:38,720 --> 00:33:41,920
you can keep doing that, or for example, in contract,

00:33:41,920 --> 00:33:46,237
you have full validation of the TCP sequence, right,

00:33:47,327 --> 00:33:49,840
the TCP flow, so in that case,

00:33:49,840 --> 00:33:52,353
you want to keep that in software.

00:33:53,330 --> 00:33:58,250
And if you want just to reduce security a bit,

00:33:58,250 --> 00:34:00,520
while speeding up forwarding,

00:34:00,520 --> 00:34:02,580
you can just place some of those flows into hardware,

00:34:02,580 --> 00:34:04,020
so it's a bit like...

00:34:06,650 --> 00:34:08,103
- [Host] Any other questions?

00:34:09,530 --> 00:34:11,250
All right, thank you very much, Pablo.

00:34:11,250 --> 00:34:12,083
- Thank you.

00:34:12,083 --> 00:34:13,406

YouTube URL: https://www.youtube.com/watch?v=Fh5qWz-ePXU


