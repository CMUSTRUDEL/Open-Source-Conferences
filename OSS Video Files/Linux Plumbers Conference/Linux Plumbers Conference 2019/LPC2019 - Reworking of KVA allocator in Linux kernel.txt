Title: LPC2019 - Reworking of KVA allocator in Linux kernel
Publication date: 2019-09-17
Playlist: Linux Plumbers Conference 2019
Description: 
	Reworking of KVA allocator in Linux kernel

Speaker
Mr Uladzislau Rezki

Description
Hello.

I would like to give a talk about KVA allocator in the kernel and about
improvements i have done.

See below the presentation:

ftp://vps418301.ovh.net/incoming/Reworking_of_KVA_allocator_in_Linux_kernel.pdf

Thank you in advance!

--
Vlad Rezki
Captions: 
	00:00:00,388 --> 00:00:04,230
(speaking faintly off mic)

00:00:04,230 --> 00:00:07,620
- Alright, I have 10 o' clock and sounds like

00:00:07,620 --> 00:00:09,530
there are a lot of people still in the hall,

00:00:09,530 --> 00:00:11,153
but we should get started.

00:00:12,360 --> 00:00:14,910
First of all, welcome to Linux Plumbers Conference.

00:00:14,910 --> 00:00:16,680
We don't have an opening plenary,

00:00:16,680 --> 00:00:18,760
so I've been asked to make a couple

00:00:18,760 --> 00:00:21,200
of quick announcements so that everybody

00:00:21,200 --> 00:00:22,800
and all the tracks will hear it.

00:00:22,800 --> 00:00:24,560
I guess, people who are still talking out

00:00:24,560 --> 00:00:27,275
in the hallways won't, but so it goes.

00:00:27,275 --> 00:00:28,433
The next slide, please?

00:00:30,470 --> 00:00:32,190
So, first of all, I'd like to thank

00:00:32,190 --> 00:00:35,520
all of our sponsors, especially, our major diamond

00:00:35,520 --> 00:00:36,990
and platinum sponsors.

00:00:36,990 --> 00:00:40,210
Facebook, Intel, Google, NetApp.

00:00:40,210 --> 00:00:41,690
And, as you can see, there's a host

00:00:41,690 --> 00:00:44,400
of other sponsors, as well,

00:00:44,400 --> 00:00:47,130
that are the companies that actually make

00:00:47,130 --> 00:00:48,700
this event possible.

00:00:48,700 --> 00:00:51,040
So thanks to all those companies.

00:00:51,040 --> 00:00:53,210
Some of them may be your employers.

00:00:53,210 --> 00:00:55,370
Please let them know what a great job they do

00:00:55,370 --> 00:00:57,910
in terms of making this event something

00:00:57,910 --> 00:00:59,540
that happens every year.

00:00:59,540 --> 00:01:00,573
Next slide, please.

00:01:01,542 --> 00:01:04,170
So just some quick information.

00:01:04,170 --> 00:01:07,000
First of all, if you haven't gotten the WIFI yet,

00:01:07,000 --> 00:01:11,920
it's lfevents, with the password, linux1991.

00:01:11,920 --> 00:01:13,880
I think it's been that same WIFI

00:01:13,880 --> 00:01:15,520
for a couple of years now,

00:01:15,520 --> 00:01:18,223
so it may already be in your laptops.

00:01:19,870 --> 00:01:23,160
Also, I have to remind everyone

00:01:23,160 --> 00:01:24,970
about the code of conduct,

00:01:24,970 --> 00:01:26,890
which you can see on the link there,

00:01:26,890 --> 00:01:29,752
and which you agreed to when you registered.

00:01:29,752 --> 00:01:33,440
If there are any issues that you find,

00:01:33,440 --> 00:01:35,470
please inform one of the members

00:01:35,470 --> 00:01:36,950
of the planning committee.

00:01:36,950 --> 00:01:41,273
They're gonna be the people that have a green badge ribbon

00:01:42,420 --> 00:01:44,670
so you can spot them easily.

00:01:44,670 --> 00:01:45,693
Next slide, please.

00:01:47,810 --> 00:01:50,060
The overall schedule is on the website.

00:01:50,060 --> 00:01:52,944
If you just go to linuxplumbersconf.org

00:01:52,944 --> 00:01:54,880
and click on the hamburger menu,

00:01:54,880 --> 00:01:56,750
you'll see the overall schedule,

00:01:56,750 --> 00:01:58,880
and then, the detailed schedule.

00:01:58,880 --> 00:02:00,410
Everything in this room is going

00:02:00,410 --> 00:02:02,873
to be on the Kernel Summit page.

00:02:03,720 --> 00:02:06,500
We start at 10 a.m. each morning,

00:02:06,500 --> 00:02:07,540
which is a little bit late,

00:02:07,540 --> 00:02:11,250
but that's also because dinners go very late

00:02:11,250 --> 00:02:13,193
into the night because it's Europe.

00:02:14,369 --> 00:02:15,610
(audience laughing)

00:02:15,610 --> 00:02:19,940
Lunch will be at the Sete Colinas restaurant at 1:30.

00:02:19,940 --> 00:02:22,593
There will be an evening event tonight,

00:02:23,698 --> 00:02:25,500
which is a welcoming reception

00:02:25,500 --> 00:02:27,773
at that same restaurant at seven.

00:02:28,990 --> 00:02:31,340
Wednesday night is their closing party.

00:02:31,340 --> 00:02:33,980
The buses will be leaving at 7:30.

00:02:33,980 --> 00:02:36,400
And Tuesday night is on your own.

00:02:36,400 --> 00:02:37,550
The next slide, please.

00:02:38,760 --> 00:02:41,581
So for everyone who's gonna be presenting,

00:02:41,581 --> 00:02:43,770
please upload your slides

00:02:43,770 --> 00:02:46,810
to the Linux Plumbers Conf website.

00:02:46,810 --> 00:02:49,060
For some of the presenters who,

00:02:49,060 --> 00:02:53,900
who had their talks submitted via email,

00:02:53,900 --> 00:02:56,120
as opposed to on the website,

00:02:56,120 --> 00:03:00,060
you may not be able to upload the slides.

00:03:00,060 --> 00:03:01,000
And, if that's the case,

00:03:01,000 --> 00:03:02,240
send it to me and I'll make sure

00:03:02,240 --> 00:03:05,093
it gets uploaded on your behalf.

00:03:07,259 --> 00:03:10,210
Yeah, one thing I'll add about the Kernel Summit,

00:03:10,210 --> 00:03:12,640
in particular, is we always design

00:03:12,640 --> 00:03:15,550
the Kernel Summit to have some extra space

00:03:15,550 --> 00:03:19,390
for any sort of ad hoc talks

00:03:19,390 --> 00:03:20,600
that people wanna have,

00:03:20,600 --> 00:03:22,670
or discussions that start in the hallway

00:03:22,670 --> 00:03:24,950
and you wanna turn them into something bigger

00:03:24,950 --> 00:03:28,130
without having to do a late night BoF session.

00:03:28,130 --> 00:03:29,980
We do have a handful of slots,

00:03:29,980 --> 00:03:32,779
mostly, on Tuesday and Wednesday.

00:03:32,779 --> 00:03:35,720
Again, if you're interested in using

00:03:35,720 --> 00:03:37,620
one of those empty slots which you can see

00:03:37,620 --> 00:03:42,500
on the schedule, let me know what the name

00:03:42,500 --> 00:03:45,413
of the talk would be or, you know, discussion,

00:03:45,413 --> 00:03:48,240
who absolutely needs to be there, and,

00:03:48,240 --> 00:03:50,880
if you have a preferred slot, let me know.

00:03:50,880 --> 00:03:55,430
Slots will be made available on an as-available, and,

00:03:55,430 --> 00:03:56,440
if there are conflicts,

00:03:56,440 --> 00:04:00,428
what seems to be more of general interest.

00:04:00,428 --> 00:04:02,470
So we do have some spare slots

00:04:02,470 --> 00:04:04,930
that are specifically designed for things

00:04:04,930 --> 00:04:06,890
that come up during this week.

00:04:06,890 --> 00:04:08,730
Maybe here, maybe there isn't time

00:04:08,730 --> 00:04:10,550
at one of the mini confs.

00:04:10,550 --> 00:04:14,860
We do have those sort of un-conference-style slots

00:04:14,860 --> 00:04:17,240
available for people to schedule against.

00:04:17,240 --> 00:04:19,490
Alright, now, I think that's the last slide?

00:04:19,490 --> 00:04:20,596
Ah, yes.

00:04:20,596 --> 00:04:22,440
So, again, the planning committee

00:04:22,440 --> 00:04:24,580
are the people with the green lanyards.

00:04:24,580 --> 00:04:25,423
Thanks to these people.

00:04:25,423 --> 00:04:27,920
They are the ones who do all the hard work

00:04:27,920 --> 00:04:30,130
planning this conference.

00:04:30,130 --> 00:04:32,610
And, with that, I'll turn it over

00:04:32,610 --> 00:04:33,640
for our first talk.

00:04:33,640 --> 00:04:35,460
Thank you. - Yes, thank you.

00:04:35,460 --> 00:04:36,980
So my name is Uladzislau Rezki.

00:04:36,980 --> 00:04:39,270
I have been working in Sony Mobile.

00:04:39,270 --> 00:04:42,140
So today, I would like to talk about the reworking

00:04:42,140 --> 00:04:44,980
of KVA allocator in Linux Kernel.

00:04:44,980 --> 00:04:49,640
So, basically, here you see the topics

00:04:49,640 --> 00:04:51,190
of my presentation.

00:04:51,190 --> 00:04:53,670
First, it will be kind of on a high level

00:04:53,670 --> 00:04:55,470
because I don't want to go into details

00:04:55,470 --> 00:04:57,210
because it will take a lot of time.

00:04:57,210 --> 00:04:59,083
So first one is motivation.

00:05:00,080 --> 00:05:01,360
I will talk about motivations.

00:05:01,360 --> 00:05:03,550
Then, I will talk about special requirements

00:05:03,550 --> 00:05:06,354
for the KVA allocator.

00:05:06,354 --> 00:05:08,820
Then, I will talk about the current allocation scheme,

00:05:08,820 --> 00:05:10,470
what is not current anymore,

00:05:10,470 --> 00:05:12,150
the previous allocation scheme.

00:05:12,150 --> 00:05:15,995
Because it has been merged into the 5.2 kernel.

00:05:15,995 --> 00:05:20,870
Then, we talk about current allocation scheme drawbacks.

00:05:20,870 --> 00:05:23,980
Then, I will the new allocation scheme.

00:05:23,980 --> 00:05:26,420
I will talk about performance analysis,

00:05:26,420 --> 00:05:28,740
performance test results, contributions.

00:05:28,740 --> 00:05:32,340
And, the last one, I will talk about wishlist,

00:05:32,340 --> 00:05:34,823
or to-do list, what I would like to do.

00:05:36,310 --> 00:05:37,660
So first one, first of all,

00:05:38,600 --> 00:05:41,220
as you know, today, we are dealing with metadata.

00:05:41,220 --> 00:05:42,840
We do video recording.

00:05:42,840 --> 00:05:44,240
We do video streaming.

00:05:44,240 --> 00:05:46,140
We send, we take pictures,

00:05:46,140 --> 00:05:48,520
we send them between different kinds of points

00:05:48,520 --> 00:05:49,353
between each other.

00:05:49,353 --> 00:05:53,930
So there's a big demand in big data,

00:05:53,930 --> 00:05:55,483
or a high demand in big data.

00:05:56,455 --> 00:06:00,520
So, for example, if we take look at the mobile segment,

00:06:00,520 --> 00:06:01,950
we will see that we have audio,

00:06:01,950 --> 00:06:05,610
we have video, we have 8K high resolution.

00:06:05,610 --> 00:06:08,970
We have 5G areas, and so on.

00:06:08,970 --> 00:06:12,200
Second one, it's workloads which are critical

00:06:12,200 --> 00:06:13,520
to time and latency.

00:06:13,520 --> 00:06:17,540
So, basically, it means that have some systems,

00:06:17,540 --> 00:06:19,790
realtime systems, then it will affect you

00:06:19,790 --> 00:06:23,873
if you use, for example, vmalloc, or something like that.

00:06:23,873 --> 00:06:26,160
Apart from that, we know that KVA

00:06:26,160 --> 00:06:28,200
is getting more and more used nowadays.

00:06:28,200 --> 00:06:32,700
So if you, if we have a look at the Linux source tree,

00:06:32,700 --> 00:06:33,940
we will see filesystem,

00:06:33,940 --> 00:06:35,180
we will see kernel stacks,

00:06:35,180 --> 00:06:39,480
we will see BPF, percpu, fork paths, drivers, et cetera.

00:06:39,480 --> 00:06:41,950
Apart from that, we know that there was

00:06:41,950 --> 00:06:44,730
a new interface introduced in 2017,

00:06:44,730 --> 00:06:49,120
and the name is kvmalloc()kvfree() interface.

00:06:49,120 --> 00:06:53,600
So, basically, when the regular slab allocator gets failed,

00:06:53,600 --> 00:06:55,260
for example, due to big size requests,

00:06:55,260 --> 00:06:59,540
we fall back to vmalloc allocator and bypass,

00:06:59,540 --> 00:07:01,290
try to bypass out of memory killer.

00:07:02,900 --> 00:07:03,733
So...

00:07:07,320 --> 00:07:10,540
And last motivation, it's about, basically,

00:07:10,540 --> 00:07:14,140
we've had a lot of issues related to allocation time.

00:07:14,140 --> 00:07:17,160
So, sometimes, it was really, really terribly slow and,

00:07:17,160 --> 00:07:22,160
as a result, workloads such as high resolution audio

00:07:22,860 --> 00:07:27,470
and Bluetooth, we had many audio drops, glitches,

00:07:27,470 --> 00:07:29,910
and so on due to the problems.

00:07:29,910 --> 00:07:32,290
Also, we have frame drops in UI.

00:07:32,290 --> 00:07:34,550
I'm talking about, actually, Android,

00:07:34,550 --> 00:07:36,490
because I have been working in Sony Mobile.

00:07:36,490 --> 00:07:41,390
So all that's related to, basically, maybe,

00:07:41,390 --> 00:07:43,060
Android devices or something like that.

00:07:43,060 --> 00:07:46,843
So frame drops, UI video playback, and so on.

00:07:47,900 --> 00:07:49,708
So when you start to develop something,

00:07:49,708 --> 00:07:54,708
you do, you base your work on some special requirements.

00:07:55,230 --> 00:07:57,390
So the same here.

00:07:57,390 --> 00:08:00,290
I had three main requirements.

00:08:00,290 --> 00:08:03,230
First of all, we have to support zone allocation

00:08:03,230 --> 00:08:04,510
in KVA space.

00:08:04,510 --> 00:08:06,140
Then, we have to be sequential

00:08:07,260 --> 00:08:08,870
to maximize locality.

00:08:08,870 --> 00:08:11,820
And then, we would like to minimize external fragmentation.

00:08:12,950 --> 00:08:16,620
So on this slide, you see that we have three main zones,

00:08:16,620 --> 00:08:18,680
Zone_A, Zone_B, Zone_C.

00:08:18,680 --> 00:08:20,350
And this is just an example.

00:08:20,350 --> 00:08:23,370
For example, you see that vmalloc address space

00:08:23,370 --> 00:08:24,270
belongs to Zone_B.

00:08:25,208 --> 00:08:28,770
So it means that all the vmalloc allocation happens there

00:08:28,770 --> 00:08:30,020
in that zone.

00:08:30,020 --> 00:08:31,250
It means that you have start address,

00:08:31,250 --> 00:08:34,993
you have end address and allocate in such range.

00:08:38,270 --> 00:08:39,103
Yeah, on the bottom,

00:08:39,103 --> 00:08:40,910
you see continuous virtual address space.

00:08:40,910 --> 00:08:43,793
It spans from one until unsigned long max or from zero.

00:08:47,640 --> 00:08:51,853
So sequential allocation, why it is important.

00:08:52,710 --> 00:08:54,490
So it's important because we would like

00:08:54,490 --> 00:08:55,323
to maximize locality.

00:08:55,323 --> 00:08:56,156
What does it mean?

00:08:56,156 --> 00:08:57,830
It means that, if you have, for example,

00:08:57,830 --> 00:08:59,710
if you see two different pictures,

00:08:59,710 --> 00:09:01,390
Picture A and Picture B,

00:09:01,390 --> 00:09:03,270
on Picture A, you see sequential allocation.

00:09:03,270 --> 00:09:04,103
So it's easy.

00:09:04,103 --> 00:09:06,220
You allocate step by step if you can.

00:09:06,220 --> 00:09:08,940
If you can do that, we would like to do that.

00:09:08,940 --> 00:09:12,220
And, for example, we have Zone_0 and we have Zone_1,

00:09:12,220 --> 00:09:14,513
because that is included in Zone_0.

00:09:16,460 --> 00:09:18,230
In case of sequential allocation,

00:09:18,230 --> 00:09:22,670
you see that we waste space sequentially, one by one.

00:09:22,670 --> 00:09:24,080
So it's on a high level.

00:09:24,080 --> 00:09:27,530
But, basically, it is like that.

00:09:27,530 --> 00:09:29,020
And, in case of random allocation,

00:09:29,020 --> 00:09:33,760
you see that we can waste space from Zone_0,

00:09:33,760 --> 00:09:37,030
and also, we can waste space from Zone_1.

00:09:37,030 --> 00:09:38,370
And why it is bad?

00:09:38,370 --> 00:09:41,510
It is bad due to many aspects.

00:09:41,510 --> 00:09:44,146
But, for example, the main aspect is that,

00:09:44,146 --> 00:09:47,880
if we waste space that belongs to Zone_1,

00:09:47,880 --> 00:09:50,820
it means that users which allocate

00:09:50,820 --> 00:09:55,800
from Zone_1 may fight, may get nasty.

00:09:55,800 --> 00:09:58,490
Also, it's important from our TLB location

00:09:58,490 --> 00:10:00,150
point of view flushing.

00:10:00,150 --> 00:10:03,503
So the full sequential allocation is implemented.

00:10:05,471 --> 00:10:08,200
Then, minimize external fragmentation,

00:10:08,200 --> 00:10:10,580
and why that is important, as well.

00:10:10,580 --> 00:10:13,990
First of all, we'd like to reduce implementation overhead.

00:10:13,990 --> 00:10:18,810
It means that there's less memory objects inside.

00:10:18,810 --> 00:10:20,900
We have less memory we need.

00:10:20,900 --> 00:10:23,723
So for bookkeeping our data structures

00:10:23,723 --> 00:10:28,040
to implement implementation overhead, bookkeeping,

00:10:28,040 --> 00:10:29,634
and so on.

00:10:29,634 --> 00:10:31,247
The second one, we would like to satisfy

00:10:31,247 --> 00:10:32,483
and allocation request.

00:10:33,690 --> 00:10:37,579
It means that, if you have many free blocks,

00:10:37,579 --> 00:10:42,323
but they are too small to complete allocation requests.

00:10:43,980 --> 00:10:46,730
And the last one, it's about improving allocation time.

00:10:48,356 --> 00:10:51,294
Basically, if we have a lot of fragments,

00:10:51,294 --> 00:10:53,740
usually, it means an allocation,

00:10:53,740 --> 00:10:55,853
our allocation time gets increased.

00:10:59,650 --> 00:11:02,740
So, now, I will talk about current,

00:11:02,740 --> 00:11:04,320
our current allocation scheme.

00:11:04,320 --> 00:11:07,620
So it's on a high level and,

00:11:07,620 --> 00:11:12,060
on a high level, we have two main data structures.

00:11:12,060 --> 00:11:14,574
So we have a red-black tree.

00:11:14,574 --> 00:11:17,460
We have a linked, a regular linked list.

00:11:17,460 --> 00:11:21,883
And we allocate from gaps, using gaps, or holes.

00:11:23,900 --> 00:11:26,913
All busy blocks are sorted in ascended order.

00:11:28,176 --> 00:11:31,780
So, basically, the same happens with a linked list.

00:11:31,780 --> 00:11:35,850
So all blocks are sorted in order of increasing addresses.

00:11:35,850 --> 00:11:37,730
So this is the same like red-black trees.

00:11:37,730 --> 00:11:38,950
So we duplicate.

00:11:38,950 --> 00:11:41,496
But, actually, to maintain the linked list,

00:11:41,496 --> 00:11:44,913
it's not, there is no, there is no OI, I would say.

00:11:46,211 --> 00:11:50,470
Alright, so also, I need to mention that,

00:11:50,470 --> 00:11:52,730
each time you allocate,

00:11:52,730 --> 00:11:55,223
you place a new fragment to all data structures.

00:12:02,826 --> 00:12:04,980
So here, you see a small example.

00:12:04,980 --> 00:12:07,130
We have five busy blocks,

00:12:07,130 --> 00:12:09,410
and we allocate based on gaps,

00:12:09,410 --> 00:12:10,243
or based on holes.

00:12:10,243 --> 00:12:11,533
You see three holes.

00:12:12,930 --> 00:12:15,480
So, on a high level, if we want to allocate,

00:12:15,480 --> 00:12:19,850
we just, we should iterate over the blocks

00:12:19,850 --> 00:12:23,480
and try to find a fitting base, the first fitting base.

00:12:23,480 --> 00:12:27,255
So in this picture, you see that,

00:12:27,255 --> 00:12:28,860
on top of this linked list,

00:12:28,860 --> 00:12:31,204
we've got a red-black tree

00:12:31,204 --> 00:12:36,204
that is used to find the busy blocks

00:12:36,450 --> 00:12:38,420
when we want to de-allocate it.

00:12:38,420 --> 00:12:41,710
So for all at login time.

00:12:41,710 --> 00:12:46,710
So you see the two first gaps, or holes.

00:12:47,030 --> 00:12:48,350
They didn't fit.

00:12:48,350 --> 00:12:51,360
But we found sorted ones that fit.

00:12:51,360 --> 00:12:52,830
So what we need to do,

00:12:52,830 --> 00:12:56,430
we need to create a fragment and place it to data,

00:12:56,430 --> 00:12:57,950
our data structures.

00:12:57,950 --> 00:13:00,363
And you see that B6, it starts from 12.

00:13:01,206 --> 00:13:03,490
So I hope it's clear.

00:13:03,490 --> 00:13:05,453
So it's pretty easy.

00:13:07,610 --> 00:13:09,856
And, of course, drawbacks.

00:13:09,856 --> 00:13:13,783
Drawbacks, so it's over-fragmented.

00:13:14,970 --> 00:13:17,040
So if we have a lot of allocations

00:13:17,040 --> 00:13:19,410
and it's terribly fragmented.

00:13:19,410 --> 00:13:21,200
And to do some search

00:13:21,200 --> 00:13:24,090
in that fragmented area's data structure

00:13:24,090 --> 00:13:26,050
is really, really complicated.

00:13:26,050 --> 00:13:27,873
So the full complexity is O(N),

00:13:28,910 --> 00:13:32,663
which is not acceptable, I would say.

00:13:34,750 --> 00:13:36,200
So our new allocation scheme.

00:13:37,800 --> 00:13:42,200
First of all, we allocate from free blocks.

00:13:42,200 --> 00:13:47,000
So we build a memory layout during boot-up phase.

00:13:47,000 --> 00:13:50,420
So the new allocation method uses

00:13:50,420 --> 00:13:52,003
an augmented red-black tree.

00:13:53,120 --> 00:13:56,410
So all free blocks are sorted in ascending order

00:13:56,410 --> 00:13:57,510
by that tree.

00:13:57,510 --> 00:13:59,660
Also, we use a linked list

00:14:00,640 --> 00:14:04,690
and we need it when we de-allocate.

00:14:04,690 --> 00:14:06,440
So, basically, when we de-allocate,

00:14:06,440 --> 00:14:07,960
we find a free spot,

00:14:07,960 --> 00:14:10,260
we find a spot in the tree,

00:14:10,260 --> 00:14:12,800
knowing the parent and direction, left or right.

00:14:12,800 --> 00:14:16,380
We can identify the next element, future next element,

00:14:16,380 --> 00:14:17,940
and then, we can access the previous.

00:14:17,940 --> 00:14:20,390
And then, we can check if we can merge it or not.

00:14:21,540 --> 00:14:24,830
So nodes are augmented with the size of maximum

00:14:24,830 --> 00:14:27,820
available block in left or right subtree.

00:14:27,820 --> 00:14:31,560
So we have a node, and we have maximum subtree size.

00:14:31,560 --> 00:14:34,593
It can be on the right or left subtree.

00:14:35,680 --> 00:14:36,770
Complexity.

00:14:36,770 --> 00:14:38,917
So as a result, it becomes ~O(log(N)).

00:14:43,915 --> 00:14:45,840
So this is just an example.

00:14:45,840 --> 00:14:48,360
We built a new memory,

00:14:48,360 --> 00:14:51,240
we built a memory layout during boot-up phase.

00:14:51,240 --> 00:14:53,540
So you see, it consists of five blocks.

00:14:53,540 --> 00:14:54,373
Free blocks.

00:14:54,373 --> 00:14:57,150
We don't like it from gaps or from busy blocks,

00:14:57,150 --> 00:14:58,143
or from holes.

00:14:59,420 --> 00:15:03,223
So KVA space spans from one until unsigned long max.

00:15:04,130 --> 00:15:05,720
So, and that's it, and that's it.

00:15:05,720 --> 00:15:08,030
And also, it depends on ARCH, of course.

00:15:08,030 --> 00:15:11,960
So it can be one big solid space during boot-up.

00:15:11,960 --> 00:15:14,500
But, of course, afterwards, it will be split,

00:15:14,500 --> 00:15:15,363
when we allocate.

00:15:17,490 --> 00:15:22,060
So the new model consists of two main data structures,

00:15:22,060 --> 00:15:24,390
it's red-black tree, as I mentioned before,

00:15:24,390 --> 00:15:26,600
augmented, augmented red-black tree

00:15:26,600 --> 00:15:28,110
so that we have a linked list.

00:15:28,110 --> 00:15:30,653
Each node consists of three main parameters.

00:15:31,562 --> 00:15:33,180
The first one, it's a start address.

00:15:33,180 --> 00:15:36,613
For example, N2 starts from, N1 starts from two.

00:15:37,680 --> 00:15:40,853
It has size two, and maximum subtree size, it has two.

00:15:42,230 --> 00:15:44,360
So it is the most-left node.

00:15:44,360 --> 00:15:45,193
It's a leaf.

00:15:46,580 --> 00:15:51,580
So I hope it's clear, and move to next.

00:15:52,660 --> 00:15:53,673
How we allocate.

00:15:54,650 --> 00:15:56,010
Basically, we start from,

00:15:56,010 --> 00:15:58,193
we start tree traversal from the root node.

00:15:59,690 --> 00:16:02,960
Then, we try to check left subtree max size,

00:16:02,960 --> 00:16:04,320
and we would like to follow the left

00:16:04,320 --> 00:16:05,636
as much as possible because,

00:16:05,636 --> 00:16:07,700
on the left subtree, we have the lowest address.

00:16:07,700 --> 00:16:11,060
And since we would like to be sequential,

00:16:11,060 --> 00:16:12,880
like to be sequential, we must,

00:16:12,880 --> 00:16:14,890
or we have to follow the left subtree

00:16:14,890 --> 00:16:16,580
as much as we can.

00:16:16,580 --> 00:16:20,670
So follow the left subtree if request is less

00:16:20,670 --> 00:16:22,400
or equal available size.

00:16:22,400 --> 00:16:26,490
And then, we try to go towards the blocks that fit.

00:16:26,490 --> 00:16:29,763
Once a block is found, we split it and it must remain gated.

00:16:31,110 --> 00:16:32,560
I will talk about that later.

00:16:34,510 --> 00:16:38,270
So this is block diagram of the search algorithm.

00:16:38,270 --> 00:16:43,020
It's a bit not correct, actually.

00:16:43,020 --> 00:16:47,110
There are some mistakes, but I hope it will be clear.

00:16:47,110 --> 00:16:48,793
So we start the search from N4.

00:16:49,930 --> 00:16:54,930
Then, we try to get_left_subtree_max_size for N4.

00:16:55,250 --> 00:16:58,790
For example, if N2, it's 12.

00:16:58,790 --> 00:17:02,430
Then, if we know that it's enough for our needs,

00:17:02,430 --> 00:17:04,123
we follow left to N2.

00:17:05,180 --> 00:17:06,953
Go yes to it, yes.

00:17:07,800 --> 00:17:12,250
And then, we try to check N1, as well.

00:17:12,250 --> 00:17:14,776
So left subtree and this N1.

00:17:14,776 --> 00:17:17,920
If there is no, any free space there,

00:17:17,920 --> 00:17:20,590
we stop and we should check N2

00:17:20,590 --> 00:17:21,710
before going to right.

00:17:21,710 --> 00:17:25,800
Because N2 has lower, a lower address than N3.

00:17:25,800 --> 00:17:28,220
Because N3 goes to right

00:17:28,220 --> 00:17:31,103
and the block are sorted in ascending order.

00:17:34,160 --> 00:17:37,470
Yeah, basically, and then, if N2 doesn't fit,

00:17:37,470 --> 00:17:40,460
then, we go to N3, check N3 because it's,

00:17:40,460 --> 00:17:41,700
if it fits, okay.

00:17:41,700 --> 00:17:43,830
If it's not, then we are not,

00:17:43,830 --> 00:17:45,580
we didn't find anything.

00:17:45,580 --> 00:17:49,630
But I will talk about here on the monitor.

00:17:49,630 --> 00:17:53,493
So here, you see two pictures.

00:18:00,356 --> 00:18:01,189
A and B.

00:18:02,560 --> 00:18:04,160
On A, we allocate one page.

00:18:04,160 --> 00:18:06,090
On B, we allocate four pages.

00:18:06,090 --> 00:18:10,100
So, first of all, please keep in mind

00:18:10,100 --> 00:18:12,530
that we have a node and the node consists

00:18:12,530 --> 00:18:14,780
of three main parameters, as I mentioned before.

00:18:14,780 --> 00:18:16,490
It's a block start address, block size,

00:18:16,490 --> 00:18:17,870
and subtree max size.

00:18:17,870 --> 00:18:20,770
And we populate our tree,

00:18:20,770 --> 00:18:24,620
or fix our tree by subtree max size.

00:18:24,620 --> 00:18:26,570
It should be correctly updated because,

00:18:26,570 --> 00:18:29,020
knowing that, we know direction, where to follow.

00:18:29,880 --> 00:18:34,880
So A, first of all, we need to find the block, free blocks.

00:18:35,730 --> 00:18:36,653
We start from N4.

00:18:37,670 --> 00:18:40,180
We get left subtree size,

00:18:40,180 --> 00:18:42,220
check N2, and I test 12.

00:18:42,220 --> 00:18:43,880
If you see, it has 12.

00:18:43,880 --> 00:18:45,230
What is enough for our need?

00:18:45,230 --> 00:18:46,750
We need only one page.

00:18:46,750 --> 00:18:47,760
So we follow left.

00:18:47,760 --> 00:18:51,070
Then, we check N1, because we would like

00:18:51,070 --> 00:18:52,860
to follow left as much as we can.

00:18:52,860 --> 00:18:53,693
Check N1.

00:18:54,940 --> 00:18:58,503
It's the same because the maximum subtree size has two.

00:18:59,650 --> 00:19:03,020
And, eventually, it has size two

00:19:03,020 --> 00:19:05,370
because it's a left, sorry, it's a leaf.

00:19:05,370 --> 00:19:06,813
So we go to N1.

00:19:07,795 --> 00:19:08,882
It's a leaf.

00:19:08,882 --> 00:19:10,323
We can't follow.

00:19:11,170 --> 00:19:12,360
We are on the bottom.

00:19:12,360 --> 00:19:15,080
So, next step, splitting them.

00:19:15,080 --> 00:19:18,133
And what we do, you see it becomes 1/1.

00:19:19,770 --> 00:19:22,280
So, and then, why 1/1?

00:19:22,280 --> 00:19:24,280
Because we split the block.

00:19:24,280 --> 00:19:25,780
It was two.

00:19:25,780 --> 00:19:26,613
We need one page.

00:19:26,613 --> 00:19:27,446
It becomes one.

00:19:27,446 --> 00:19:29,800
And then, we update the maximum subtree size for N1,

00:19:29,800 --> 00:19:32,223
and it becomes one because it's a leaf.

00:19:34,220 --> 00:19:37,043
Then, let's have a look how we allocate four pages.

00:19:37,990 --> 00:19:40,083
We start from N4 as the same.

00:19:41,060 --> 00:19:43,270
We check N2 maximum subtree size.

00:19:43,270 --> 00:19:44,974
It has 12 pages.

00:19:44,974 --> 00:19:46,460
Then, we go to N2.

00:19:46,460 --> 00:19:47,920
We are in N2.

00:19:47,920 --> 00:19:49,373
After that, we check N1.

00:19:51,279 --> 00:19:55,520
And we see that it has two pages only,

00:19:55,520 --> 00:19:57,210
and as a maximum.

00:19:57,210 --> 00:20:00,463
So that is not acceptable for us.

00:20:01,767 --> 00:20:03,898
We can't follow left subtree.

00:20:03,898 --> 00:20:06,940
So, therefore, we have to check N2

00:20:06,940 --> 00:20:08,940
before going to the right subtree,

00:20:08,940 --> 00:20:11,243
because N2 has a lower address,

00:20:12,670 --> 00:20:15,773
start address of free blocks.

00:20:17,270 --> 00:20:19,430
It has three pages, which is not enough.

00:20:19,430 --> 00:20:20,350
We need four.

00:20:20,350 --> 00:20:22,773
So, therefore, we follow right subtree.

00:20:24,380 --> 00:20:26,560
It has 12 pages and it's a leaf.

00:20:26,560 --> 00:20:29,900
It's our last chance to have a look

00:20:29,900 --> 00:20:31,320
if it fits or not.

00:20:31,320 --> 00:20:33,760
So it fits because it has 12 pages.

00:20:33,760 --> 00:20:35,060
After that, when we find,

00:20:35,060 --> 00:20:36,900
we have to split it.

00:20:36,900 --> 00:20:39,010
And you see how we split it.

00:20:39,010 --> 00:20:42,080
So, basically, when we split it,

00:20:44,830 --> 00:20:48,330
it becomes eight as a size of free blocks.

00:20:48,330 --> 00:20:49,323
It used to be 12.

00:20:50,260 --> 00:20:51,360
After that, when we split,

00:20:51,360 --> 00:20:55,550
we have to fix the tree to upper levels,

00:20:55,550 --> 00:20:57,513
because the tree is augmented.

00:20:58,460 --> 00:21:00,987
And what do we do?

00:21:00,987 --> 00:21:02,553
The last step is updated.

00:21:05,570 --> 00:21:07,590
It's better here.

00:21:07,590 --> 00:21:12,590
So we update N3, trying to calculate maximum

00:21:14,840 --> 00:21:18,800
subtree size for N3, and it becomes eight.

00:21:18,800 --> 00:21:20,250
It used to be 12.

00:21:20,250 --> 00:21:21,360
It becomes eight.

00:21:21,360 --> 00:21:24,830
Then, we follow upstairs to upper levels

00:21:24,830 --> 00:21:27,320
and we check N2 as a parent node.

00:21:27,320 --> 00:21:30,750
We calculate the maximum subtree for the parent node.

00:21:30,750 --> 00:21:32,170
We have two and eight.

00:21:32,170 --> 00:21:35,260
Maximum is eight, allocated in a right subtree.

00:21:35,260 --> 00:21:36,153
Set it to eight.

00:21:37,640 --> 00:21:41,250
After that, we follow to N4.

00:21:41,250 --> 00:21:42,850
It's a parent node of N2.

00:21:42,850 --> 00:21:45,673
And then, we calculate the maximum subtree size for N4.

00:21:46,898 --> 00:21:49,953
And we take the maximum between N2 and N5,

00:21:51,170 --> 00:21:52,113
and it's 11.

00:21:53,440 --> 00:21:57,670
So, therefore, we set the maximum subtree size to 11,

00:21:57,670 --> 00:21:59,570
and it's allocated in a right subtree.

00:22:00,526 --> 00:22:04,701
So, after that, it's done.

00:22:04,701 --> 00:22:06,380
The tree is correctly updated

00:22:06,380 --> 00:22:08,253
and we can use it further.

00:22:11,100 --> 00:22:13,380
So there are three main cases,

00:22:13,380 --> 00:22:14,640
when the block is found,

00:22:14,640 --> 00:22:16,320
there are three main cases how we split it.

00:22:16,320 --> 00:22:17,450
It's like a brick.

00:22:17,450 --> 00:22:19,590
We can split left page, we can split right page,

00:22:19,590 --> 00:22:21,500
we can split somewhere in the middle.

00:22:21,500 --> 00:22:24,454
So on this picture, you see that we have found the block,

00:22:24,454 --> 00:22:25,750
and this is F3.

00:22:25,750 --> 00:22:28,620
It implies that F1, F2, didn't fit,

00:22:28,620 --> 00:22:31,440
even though it looks like on the picture,

00:22:31,440 --> 00:22:33,490
it should fit, too, in F2.

00:22:33,490 --> 00:22:37,324
But it's just a picture.

00:22:37,324 --> 00:22:39,530
(speaking faintly)

00:22:39,530 --> 00:22:44,530
So we shrink F3 and give that part to the user, give back.

00:22:45,410 --> 00:22:46,273
So that's it.

00:22:47,483 --> 00:22:49,530
Our next step, sorry, second case,

00:22:49,530 --> 00:22:53,440
it's about when the block fully fits, it's F3.

00:22:53,440 --> 00:22:56,640
We just remove it from our internal data structures

00:22:56,640 --> 00:22:57,710
and give it back to the user.

00:22:57,710 --> 00:22:59,423
That's it, easy.

00:22:59,423 --> 00:23:03,780
The last one, it's about when the free block

00:23:05,470 --> 00:23:07,310
is placed somewhere in the middle.

00:23:07,310 --> 00:23:12,090
It happens because of an alignment request,

00:23:12,090 --> 00:23:14,400
because we can, different primitive parameters

00:23:14,400 --> 00:23:15,233
when we allocate.

00:23:15,233 --> 00:23:17,480
We have size, we have alignment, we have restart,

00:23:17,480 --> 00:23:21,560
and we have, yeah, probably, that's it.

00:23:21,560 --> 00:23:22,550
Three main.

00:23:22,550 --> 00:23:26,870
So it happens because of alignment.

00:23:26,870 --> 00:23:29,453
We split it, and you see that we shrink F3.

00:23:30,300 --> 00:23:32,190
Middle part, we give back to the user,

00:23:32,190 --> 00:23:33,670
and the remaining part, N,

00:23:33,670 --> 00:23:37,023
we place back to our data structures internally.

00:23:40,220 --> 00:23:41,053
Summarizing.

00:23:42,390 --> 00:23:46,540
So since the tree is augmented, augmented red-black tree,

00:23:46,540 --> 00:23:50,530
we have to operate and maintain subtree-max-size

00:23:50,530 --> 00:23:51,473
for each node.

00:23:52,440 --> 00:23:55,770
And it happens in three cases when we update the tree.

00:23:55,770 --> 00:23:58,340
One way, when the block is split,

00:23:58,340 --> 00:24:00,020
its an allocation path.

00:24:00,020 --> 00:24:03,240
When the block is inserted to the tree,

00:24:03,240 --> 00:24:04,820
it's a free path.

00:24:04,820 --> 00:24:07,690
And, last one, when the block is merged.

00:24:07,690 --> 00:24:08,723
It's a merging path.

00:24:10,310 --> 00:24:12,590
So please know that it doesn't mean

00:24:12,590 --> 00:24:17,590
that we operate or propagate maximum subtree size

00:24:17,690 --> 00:24:19,320
up to the root node.

00:24:19,320 --> 00:24:22,560
Basically, we calculate parent nodes and,

00:24:22,560 --> 00:24:24,869
if we see if it's correctly normalized,

00:24:24,869 --> 00:24:25,760
we give up and we stop.

00:24:25,760 --> 00:24:28,624
Because it doesn't make sense to go further because,

00:24:28,624 --> 00:24:33,017
further, everything will be updated correctly.

00:24:33,017 --> 00:24:34,760
The allocation, it's on a high level

00:24:34,760 --> 00:24:38,290
because I don't want to go into details

00:24:38,290 --> 00:24:41,110
because it will be maybe complicated,

00:24:41,110 --> 00:24:44,070
and maybe, not so easy to understand.

00:24:44,070 --> 00:24:48,790
So, therefore, on a high level, what we do.

00:24:48,790 --> 00:24:50,580
Basically, we have free blocks.

00:24:50,580 --> 00:24:54,340
We have red-black trees that keeps free blocks.

00:24:54,340 --> 00:24:55,960
Before, when we de-allocate,

00:24:55,960 --> 00:24:58,350
we find a spot in that tree.

00:24:58,350 --> 00:24:59,220
So what does it mean?

00:24:59,220 --> 00:25:01,000
It means we find a parent node,

00:25:01,000 --> 00:25:05,650
and then, we find the direction, link direction.

00:25:05,650 --> 00:25:07,113
It can be right or left.

00:25:08,480 --> 00:25:11,750
So, based on that, we can identify the next node,

00:25:11,750 --> 00:25:14,720
or next element, future next element and know,

00:25:14,720 --> 00:25:17,890
in the future, we can identify a previous element.

00:25:17,890 --> 00:25:21,610
So for all at one time.

00:25:21,610 --> 00:25:22,620
It's fast.

00:25:22,620 --> 00:25:25,380
So you see our full allocated blocks.

00:25:25,380 --> 00:25:27,730
What we do when we de-allocate,

00:25:27,730 --> 00:25:30,190
we just insert it to our data structures.

00:25:30,190 --> 00:25:31,870
So we can merge it with the previous element

00:25:31,870 --> 00:25:33,270
or with the next one.

00:25:33,270 --> 00:25:36,567
So here, on the third row,

00:25:36,567 --> 00:25:38,870
you see that we do the same

00:25:38,870 --> 00:25:40,920
with the most-right one.

00:25:40,920 --> 00:25:41,790
So we can't merge it.

00:25:41,790 --> 00:25:42,883
We just insert it.

00:25:44,400 --> 00:25:46,670
Next, you see that we can merge

00:25:46,670 --> 00:25:49,160
with the previous and next element.

00:25:49,160 --> 00:25:50,820
And then, we do that.

00:25:50,820 --> 00:25:53,530
And, as a result, we get a bigger block.

00:25:53,530 --> 00:25:56,931
And, last one, it's when the most-left one is freed,

00:25:56,931 --> 00:26:00,630
we get one big solid space.

00:26:00,630 --> 00:26:02,733
So it's easy.

00:26:04,150 --> 00:26:05,610
So performance analysis.

00:26:05,610 --> 00:26:08,630
When I started to do the work,

00:26:08,630 --> 00:26:10,590
I had to base it on something

00:26:10,590 --> 00:26:13,070
to analyze performance impact.

00:26:13,070 --> 00:26:16,170
So therefore, because of that reason,

00:26:16,170 --> 00:26:19,061
I developed a special microbenchmark

00:26:19,061 --> 00:26:23,250
to analyze the performance impact of vmalloc allocator.

00:26:23,250 --> 00:26:26,333
So it is available since the 5.1 kernel.

00:26:27,584 --> 00:26:31,280
It has been integrated with kernel self-tests suite.

00:26:31,280 --> 00:26:35,100
It is available under tools/testing/selftests/vm/.

00:26:35,100 --> 00:26:37,560
The name is test_vmalloc.sh.

00:26:37,560 --> 00:26:41,110
It's a kernel module so you can use it

00:26:41,110 --> 00:26:44,900
to simulate different kinds of workloads.

00:26:44,900 --> 00:26:48,020
Like random workloads, allocation workloads,

00:26:48,020 --> 00:26:51,460
on a single CPU, or on many CPUs, and so on.

00:26:51,460 --> 00:26:53,880
So two modes on the high level:

00:26:53,880 --> 00:26:56,130
performance analysis mode and stressing mode.

00:26:58,640 --> 00:27:02,960
So if we have a look at this, sorry,

00:27:02,960 --> 00:27:06,840
on this simple slide,

00:27:06,840 --> 00:27:09,480
I have my computer, this one.

00:27:09,480 --> 00:27:13,244
If I wanted, I use test_vmalloc.sh.

00:27:13,244 --> 00:27:16,353
I have an i5-3320M machine.

00:27:17,400 --> 00:27:20,770
And, if we have a look at taken time

00:27:20,770 --> 00:27:23,040
to complete a test, we will see that,

00:27:23,040 --> 00:27:25,270
in the first, the default configuration,

00:27:25,270 --> 00:27:27,480
it takes 160 minutes.

00:27:27,480 --> 00:27:29,170
In case of Rework, it takes three minutes.

00:27:29,170 --> 00:27:31,173
So maybe 30 times faster.

00:27:32,666 --> 00:27:33,499
(speaking faintly)

00:27:33,499 --> 00:27:34,533
I think it's more.

00:27:35,780 --> 00:27:36,920
It's good.

00:27:36,920 --> 00:27:40,503
So on this plot, you see,

00:27:42,010 --> 00:27:44,090
on the right side, you see all CPUs.

00:27:44,090 --> 00:27:47,860
It's a random allocation on all CPUs simultaneously.

00:27:47,860 --> 00:27:50,850
And this is, on the bottom,

00:27:50,850 --> 00:27:52,460
we have number of samples.

00:27:52,460 --> 00:27:54,193
We have one per second.

00:27:54,193 --> 00:27:56,776
So test version is 120 seconds.

00:27:57,678 --> 00:28:01,478
And here, we see allocation time in nanoseconds,

00:28:01,478 --> 00:28:03,690
average per sample.

00:28:03,690 --> 00:28:05,950
So what we can say?

00:28:05,950 --> 00:28:08,550
We can see that we have a big deviation

00:28:08,550 --> 00:28:10,450
between the minimum and maximum.

00:28:10,450 --> 00:28:14,380
So if we, the minimum ratio here

00:28:14,380 --> 00:28:16,700
is approximately 25 microseconds.

00:28:16,700 --> 00:28:20,793
So it is the minimum time that is needed per one allocation.

00:28:22,910 --> 00:28:24,297
Then, we have a maximum.

00:28:24,297 --> 00:28:27,780
Our maximum is, maybe, four milliseconds,

00:28:27,780 --> 00:28:30,543
can be what is really, really, really long.

00:28:32,300 --> 00:28:35,019
And I would say it's not acceptable

00:28:35,019 --> 00:28:38,720
for many reasons, and for many, in many areas

00:28:38,720 --> 00:28:40,885
like realtime systems and so on.

00:28:40,885 --> 00:28:43,350
And this is on my laptop that has, I don't know,

00:28:43,350 --> 00:28:44,443
maybe, two gigahertz.

00:28:45,830 --> 00:28:50,593
And average is approximately 400 microseconds.

00:28:52,123 --> 00:28:55,551
- [Man] So are these all the same size allocations--

00:28:55,551 --> 00:28:57,109
- No, no, no, it's different.

00:28:57,109 --> 00:28:58,200
It's different.

00:28:58,200 --> 00:28:59,163
Not the same.

00:29:01,470 --> 00:29:03,940
It's a random allocation and different test cases,

00:29:03,940 --> 00:29:07,460
and each CPU tried to run a different test case.

00:29:08,927 --> 00:29:10,510
And each test case has a special allocation modeled

00:29:14,710 --> 00:29:15,543
and so on.

00:29:15,543 --> 00:29:16,880
But it's random allocation,

00:29:16,880 --> 00:29:19,100
and randomly sized, and random,

00:29:19,100 --> 00:29:20,830
different alignment, and so on.

00:29:20,830 --> 00:29:24,750
It's not just one page allocation.

00:29:26,270 --> 00:29:28,933
And here, we see what happens in the case of Rework.

00:29:30,262 --> 00:29:31,095
It's the same.

00:29:31,095 --> 00:29:31,928
We have four CPUs.

00:29:31,928 --> 00:29:33,070
We have a number of samples.

00:29:33,070 --> 00:29:35,220
We have the allocation time in nanoseconds.

00:29:36,930 --> 00:29:39,610
It's a random allocation simulation.

00:29:39,610 --> 00:29:41,430
Here, we see that we need,

00:29:41,430 --> 00:29:43,530
so the division is smaller.

00:29:43,530 --> 00:29:45,260
We have maybe seven microseconds

00:29:45,260 --> 00:29:47,683
against 25 microseconds.

00:29:49,040 --> 00:29:50,320
And, on the next plot,

00:29:50,320 --> 00:29:52,410
it will be more easy to understand.

00:29:52,410 --> 00:29:53,823
And, on the next plot,

00:29:56,390 --> 00:29:58,880
the red line you see is Rework.

00:29:58,880 --> 00:30:01,403
Default is the blue line and,

00:30:02,749 --> 00:30:05,943
in the case of Default, it kind of zigzags.

00:30:10,065 --> 00:30:12,700
You see that the maximum can be four milliseconds.

00:30:12,700 --> 00:30:16,990
And average, it's approximately 400 microseconds.

00:30:16,990 --> 00:30:21,150
In the case of Rework, we have maybe 10 microseconds,

00:30:21,150 --> 00:30:22,163
as an average.

00:30:23,410 --> 00:30:28,410
So I hope that there is a difference, actually,

00:30:28,580 --> 00:30:29,613
and big difference.

00:30:30,770 --> 00:30:31,623
Contribution.

00:30:35,070 --> 00:30:37,570
Vmalloc benchmark and stress-test suite.

00:30:37,570 --> 00:30:41,930
So I contributed it in 5.1 kernel.

00:30:41,930 --> 00:30:43,003
Some links.

00:30:43,003 --> 00:30:45,710
Not all of them, just some links.

00:30:45,710 --> 00:30:49,410
Stability fixes, which I found in the test driver

00:30:50,270 --> 00:30:53,200
during analysis of the re-allocator.

00:30:53,200 --> 00:30:54,983
I found many issues with that.

00:30:57,690 --> 00:31:01,793
Yeah, they were also merged into the 5.1 kernel.

00:31:03,260 --> 00:31:06,190
Then, we have Rework,

00:31:06,190 --> 00:31:08,520
and we got it in the 5.2 kernel.

00:31:08,520 --> 00:31:09,353
Some links.

00:31:09,353 --> 00:31:11,783
Not all of them, but some basic links.

00:31:13,630 --> 00:31:14,910
And, last one.

00:31:14,910 --> 00:31:17,623
I would like to talk about what I would like to do.

00:31:18,720 --> 00:31:23,300
So, first of all, it's lock contention.

00:31:23,300 --> 00:31:25,850
Because, nowadays, we have systems

00:31:25,850 --> 00:31:28,513
which consist of many CPUs, not only one.

00:31:29,830 --> 00:31:32,683
If we take a look at this picture,

00:31:34,110 --> 00:31:38,710
so this is my computer, Intel Xeon.

00:31:38,710 --> 00:31:40,151
I have 3.7 gigahertz.

00:31:40,151 --> 00:31:42,393
I have 12 CPUs.

00:31:43,580 --> 00:31:48,580
If I simulate different kinds of workloads

00:31:48,880 --> 00:31:51,423
on all of them simultaneously, on all CPUs,

00:31:52,660 --> 00:31:54,650
and, on both, we will see that we have

00:31:54,650 --> 00:31:58,690
a high lock contention in the, yeah,

00:31:58,690 --> 00:32:01,040
in native_queued_spin-lock_slowpath.

00:32:01,040 --> 00:32:03,520
And if we try to annotate that symbol,

00:32:03,520 --> 00:32:08,520
we will see that we spent 72% in pause instruction, waiting.

00:32:13,260 --> 00:32:17,780
So, therefore, I would like to get rid

00:32:17,780 --> 00:32:19,343
of one global spin lock.

00:32:20,480 --> 00:32:23,290
So how we can do that?

00:32:23,290 --> 00:32:24,550
We can split it.

00:32:24,550 --> 00:32:26,603
So, according to our new scheme,

00:32:27,530 --> 00:32:29,080
new allocation method,

00:32:29,080 --> 00:32:31,570
we can split it easily because we have

00:32:31,570 --> 00:32:36,570
three independent states for our vmap_area internal object.

00:32:37,170 --> 00:32:39,520
So it can be in three different states.

00:32:39,520 --> 00:32:41,410
In A, B, C.

00:32:41,410 --> 00:32:44,820
It can be in busy tree only.

00:32:44,820 --> 00:32:47,073
So we can protect busy tree by,

00:32:50,210 --> 00:32:51,603
by any lock primitive.

00:32:52,820 --> 00:32:55,293
Then, we can protect free tree,

00:32:56,320 --> 00:32:59,220
which is used for allocation.

00:32:59,220 --> 00:33:01,700
We can protect it, it's the same,

00:33:01,700 --> 00:33:03,990
using any lock primitive.

00:33:03,990 --> 00:33:07,070
And then, we have lazily-freed errors.

00:33:07,070 --> 00:33:12,070
So we also can protect it by another spin lock or whatever.

00:33:12,930 --> 00:33:14,193
Read lock or write lock.

00:33:16,710 --> 00:33:20,860
So, therefore, the first thing I would like

00:33:20,860 --> 00:33:21,820
to do is splitting.

00:33:21,820 --> 00:33:26,003
I think it will help when it comes to high lock contentions.

00:33:30,560 --> 00:33:34,343
But, of course, there will be other work

00:33:34,343 --> 00:33:37,360
that has to be done in order to improve

00:33:37,360 --> 00:33:39,470
and reduce lock contention.

00:33:39,470 --> 00:33:40,513
Not only this one.

00:33:41,870 --> 00:33:45,720
And this one is more about more research and development.

00:33:45,720 --> 00:33:47,123
It's more about analysis,

00:33:48,540 --> 00:33:51,133
how we can actually improve our model,

00:33:52,400 --> 00:33:57,220
and how we can build a new model

00:33:57,220 --> 00:33:59,950
for vmalloc allocator.

00:33:59,950 --> 00:34:03,670
So, first of all, maybe, it makes sense

00:34:03,670 --> 00:34:06,403
to use a more efficient data structure.

00:34:07,260 --> 00:34:11,160
So I'm thinking about, to use B-Tree for organizing

00:34:11,160 --> 00:34:12,327
free memory layout.

00:34:14,470 --> 00:34:17,803
Maybe, it's a bit complicated for many reasons.

00:34:19,460 --> 00:34:23,730
First of all, we don't have any particular

00:34:23,730 --> 00:34:25,670
B-Tree implementation in Linux Kernel.

00:34:25,670 --> 00:34:27,290
We have many B-Tree implementations

00:34:27,290 --> 00:34:28,800
in filesystem and so on.

00:34:28,800 --> 00:34:30,860
But it will be kind of special.

00:34:30,860 --> 00:34:32,943
We need to adopt it for our model,

00:34:34,060 --> 00:34:35,390
for our memory model.

00:34:35,390 --> 00:34:38,590
So, therefore, it will be definitely different.

00:34:38,590 --> 00:34:39,933
And why B-Tree?

00:34:41,210 --> 00:34:43,230
First of all, and on a high level,

00:34:43,230 --> 00:34:47,413
it's because of, I would like to utilize cache performance,

00:34:48,980 --> 00:34:50,640
as much as we can.

00:34:50,640 --> 00:34:55,640
So, therefore, then, a splay tree also can be chosen.

00:34:57,050 --> 00:35:02,050
For example, I know that, in a BSD operating system,

00:35:02,560 --> 00:35:05,380
or Microsoft, they use splay tree

00:35:06,380 --> 00:35:09,763
to manage allocations.

00:35:10,920 --> 00:35:14,943
But, unfortunately, I don't have any results.

00:35:15,820 --> 00:35:17,920
I have results but I haven't composed them

00:35:18,820 --> 00:35:20,400
to this presentation.

00:35:20,400 --> 00:35:24,670
But I need to say that using splay tree

00:35:25,540 --> 00:35:27,903
is not a way forward.

00:35:32,106 --> 00:35:33,540
But this is on a high level.

00:35:33,540 --> 00:35:34,840
I don't have details here.

00:35:37,390 --> 00:35:41,900
Then, to implement lazy tree fix-ups.

00:35:41,900 --> 00:35:45,230
I think it's easy to implement.

00:35:45,230 --> 00:35:46,883
What we need is just,

00:35:48,300 --> 00:35:51,490
when we find a block we allocate from,

00:35:51,490 --> 00:35:55,060
we don't need to populate each time we allocate,

00:35:55,060 --> 00:35:59,980
because we need to do it only once when we switch

00:35:59,980 --> 00:36:01,520
to another block.

00:36:01,520 --> 00:36:03,640
So when we switch, we'll just populate previous,

00:36:03,640 --> 00:36:04,951
and that's it.

00:36:04,951 --> 00:36:05,784
We're done.

00:36:05,784 --> 00:36:06,617
We'll just update the paths.

00:36:06,617 --> 00:36:09,530
Because, if we allocate from one and the same block,

00:36:09,530 --> 00:36:10,773
the path is the same.

00:36:12,060 --> 00:36:15,930
So it's easy to implement but I'm not sure

00:36:17,810 --> 00:36:22,010
how much we will gain, I mean, when it comes to performance.

00:36:22,010 --> 00:36:24,600
We will gain, but I'm not sure how much.

00:36:24,600 --> 00:36:26,080
Last one.

00:36:26,080 --> 00:36:29,420
It's about to cache last accessed node

00:36:29,420 --> 00:36:31,240
to optimize traversal.

00:36:31,240 --> 00:36:36,240
Basically, we can cache the last accessed node and,

00:36:38,240 --> 00:36:40,810
if we have the same permissive parameters

00:36:40,810 --> 00:36:44,290
on the next allocation, so the same parameters,

00:36:44,290 --> 00:36:49,290
so it means that we check the same or previous node fast-ly.

00:36:50,250 --> 00:36:52,140
If it's okay, if it feeds,

00:36:52,140 --> 00:36:54,253
we'll just allocate and that's it.

00:36:55,503 --> 00:37:00,100
And why it is important or, yeah,

00:37:00,100 --> 00:37:00,933
more or less important,

00:37:00,933 --> 00:37:04,400
because we would like to optimize traversal.

00:37:04,400 --> 00:37:05,863
We don't want traversal.

00:37:07,110 --> 00:37:09,603
So I hope it's clear.

00:37:11,000 --> 00:37:13,720
I think I don't have anything more.

00:37:13,720 --> 00:37:15,573
So thank you for your attention.

00:37:17,150 --> 00:37:18,450
Yeah?

00:37:18,450 --> 00:37:19,962
- So...

00:37:19,962 --> 00:37:23,129
(audience applauding)

00:37:25,145 --> 00:37:28,460
Are your test cases random allocations?

00:37:28,460 --> 00:37:31,350
- [Uladzislau] Yeah, you can simulate random

00:37:31,350 --> 00:37:33,280
or you can simulate sequential.

00:37:33,280 --> 00:37:34,113
Whatever you want.

00:37:34,113 --> 00:37:34,946
- So...

00:37:39,440 --> 00:37:44,440
Anyways, so I'm wondering, and, of course,

00:37:44,490 --> 00:37:45,490
that's very interesting.

00:37:45,490 --> 00:37:48,100
In some ways, it might be the hardest thing,

00:37:48,100 --> 00:37:50,173
but it might not be the most interesting.

00:37:51,410 --> 00:37:53,070
More interesting might be, you know,

00:37:53,070 --> 00:37:56,060
if we had a trace of a particular workload.

00:37:56,060 --> 00:38:01,060
Like, for example, apropos your last optimization,

00:38:02,200 --> 00:38:03,540
it might be very interesting to have

00:38:03,540 --> 00:38:06,840
a lot of allocations that are the same size

00:38:06,840 --> 00:38:09,610
at the same time because that might be

00:38:09,610 --> 00:38:11,957
how the system's used in real life.

00:38:11,957 --> 00:38:14,220
And random might actually be making us

00:38:14,220 --> 00:38:16,310
solve a problem that we might now really have.

00:38:16,310 --> 00:38:17,600
- Yeah, I see your point.

00:38:17,600 --> 00:38:21,600
Actually, I provide that plot just

00:38:21,600 --> 00:38:23,570
to show you the difference,

00:38:23,570 --> 00:38:24,620
and that's it.

00:38:24,620 --> 00:38:27,160
I haven't provided you real workloads.

00:38:27,160 --> 00:38:28,220
Even so, I have it.

00:38:28,220 --> 00:38:30,706
I can provide it and, as an example,

00:38:30,706 --> 00:38:35,706
it's high resolution audio and audio loops.

00:38:36,000 --> 00:38:38,773
So you can hear glitches.

00:38:41,200 --> 00:38:45,303
And, actually, when they send me this patch,

00:38:46,240 --> 00:38:47,620
all these patches to our kernel,

00:38:47,620 --> 00:38:52,620
I provided exactly a particular workload

00:38:52,760 --> 00:38:55,810
related to high resolution playing audio

00:38:55,810 --> 00:38:59,650
in a way you can take your headphones and hear glitches.

00:38:59,650 --> 00:39:02,463
And this is a real workload.

00:39:04,330 --> 00:39:09,270
So we have real workloads even though I didn't show you.

00:39:09,270 --> 00:39:14,120
I wanted to play it, but I'm not sure if I'd have it

00:39:14,120 --> 00:39:14,970
on sound speaker.

00:39:16,030 --> 00:39:17,871
I'm not sure that this,

00:39:17,871 --> 00:39:20,520
I think that showing that random allocation,

00:39:20,520 --> 00:39:22,230
there was a big difference.

00:39:22,230 --> 00:39:24,070
So I thought that it's enough.

00:39:24,070 --> 00:39:27,473
But there are, yeah, real workloads.

00:39:34,890 --> 00:39:38,280
- So I was wondering just as you checked,

00:39:38,280 --> 00:39:40,050
so if you have, for example,

00:39:40,050 --> 00:39:42,380
your regular workload of playing audio,

00:39:42,380 --> 00:39:46,910
so what is the workload on the virtual memory allocator

00:39:46,910 --> 00:39:48,340
you have when you are playing audio?

00:39:48,340 --> 00:39:50,140
So what is the frequency of allocations?

00:39:50,140 --> 00:39:51,830
Do you have some numbers about that?

00:39:51,830 --> 00:39:53,544
I was just interested by what--

00:39:53,544 --> 00:39:57,830
- The problem is, the problem is that

00:39:57,830 --> 00:39:59,620
it shouldn't be frequent.

00:39:59,620 --> 00:40:01,770
It really doesn't matter.

00:40:01,770 --> 00:40:05,597
It can be as frequent, and it can be as not-frequent.

00:40:05,597 --> 00:40:09,464
The problem is that, if it becomes over-fragmented--

00:40:09,464 --> 00:40:11,870
- Oh, I understand that the latency

00:40:11,870 --> 00:40:13,670
of the individual allocation gets high

00:40:13,670 --> 00:40:15,400
with the old allocator.

00:40:15,400 --> 00:40:19,360
So it's good that you implemented the, like RB3,

00:40:19,360 --> 00:40:21,760
so that the latency of the allocation goes down.

00:40:21,760 --> 00:40:24,380
That random space gets fragmented.

00:40:24,380 --> 00:40:25,620
That's good.

00:40:25,620 --> 00:40:26,680
But then, for example,

00:40:26,680 --> 00:40:29,450
you speak about scalability improvements,

00:40:29,450 --> 00:40:31,960
those really make sense only if the frequency

00:40:31,960 --> 00:40:33,330
of allocation is really high.

00:40:33,330 --> 00:40:34,670
Because, if the frequency is low,

00:40:34,670 --> 00:40:36,620
then you don't care about scalability, basically.

00:40:36,620 --> 00:40:38,430
- Yeah, but, of course, it depends on how much

00:40:38,430 --> 00:40:39,340
you allocate, of course.

00:40:39,340 --> 00:40:40,712
It's like--

00:40:40,712 --> 00:40:41,940
- So that's why I was asking--

00:40:41,940 --> 00:40:46,940
- Yeah, for example, if you have servers,

00:40:47,100 --> 00:40:49,040
web servers, where you would, for example,

00:40:49,040 --> 00:40:51,070
do a lot of forks, and, as you know,

00:40:51,070 --> 00:40:55,390
for example, fork paths make use of vmalloc allocator for,

00:40:55,390 --> 00:40:59,471
to keep a task stack in a vmalloc space.

00:40:59,471 --> 00:41:00,304
- [Man] Yeah, sure.

00:41:00,304 --> 00:41:01,880
- So, therefore, of course, it depends.

00:41:01,880 --> 00:41:04,313
But I haven't analyze, for example,

00:41:04,313 --> 00:41:06,000
what servers, and so on.

00:41:06,000 --> 00:41:08,990
But it will affect, of course, allocation time.

00:41:08,990 --> 00:41:12,610
- And even if the web server has maybe hundreds

00:41:12,610 --> 00:41:14,410
of forks per second,

00:41:14,410 --> 00:41:16,910
which is still a very low load

00:41:16,910 --> 00:41:19,950
to the allocator, like hundreds,

00:41:19,950 --> 00:41:20,910
even if you have lots of--

00:41:20,910 --> 00:41:22,266
- [Uladzislau] If you have a--

00:41:22,266 --> 00:41:24,180
- But, yeah, just that I wanted to point out that,

00:41:24,180 --> 00:41:27,420
probably, you should look into whether it will actually,

00:41:27,420 --> 00:41:29,170
so, of course, you can create a bench,

00:41:29,170 --> 00:41:31,540
like your kernel, your benchmark,

00:41:31,540 --> 00:41:32,810
which will stress the code enough

00:41:32,810 --> 00:41:35,230
that the scalability improvements will be visible.

00:41:35,230 --> 00:41:37,640
There's a question about if any real life workload

00:41:37,640 --> 00:41:39,470
will actually benefit from that.

00:41:39,470 --> 00:41:41,610
- Yeah, in real life, as I mentioned before,

00:41:41,610 --> 00:41:43,720
we had problems with high resolution audio.

00:41:43,720 --> 00:41:47,600
We had problems with frame drops in UI in Android--

00:41:47,600 --> 00:41:49,420
- [Man] Yeah, but that's programmed fragmentation

00:41:49,420 --> 00:41:50,670
and allocation frequency.

00:41:51,950 --> 00:41:54,890
That's not a problem with scalability.

00:41:54,890 --> 00:41:57,003
- Ah, no, no, no, yeah, of course,, yeah.

00:41:58,690 --> 00:42:01,397
- [Announcer] Alright, one last question?

00:42:01,397 --> 00:42:04,360
(speaking faintly)

00:42:04,360 --> 00:42:06,900
- Firstly, thank you for the vmalloc test module.

00:42:06,900 --> 00:42:08,140
It's been very helpful for,

00:42:08,140 --> 00:42:10,630
I've been doing on Kasan on vmalloc.

00:42:10,630 --> 00:42:13,050
I wanted to ask you about the lock changes

00:42:13,050 --> 00:42:14,150
that you want to make.

00:42:15,810 --> 00:42:20,540
What, how does it work now with lazy freeing,

00:42:20,540 --> 00:42:22,520
what happens if you have lazy freeing happening

00:42:22,520 --> 00:42:25,660
and allocation happening at the same time?

00:42:25,660 --> 00:42:26,493
How is that--

00:42:26,493 --> 00:42:30,050
- So, at the same time, we had one global spin lock,

00:42:30,050 --> 00:42:30,900
and that is bad.

00:42:30,900 --> 00:42:33,410
So if we lazily free pages and try

00:42:33,410 --> 00:42:34,630
to allocate at the same time,

00:42:34,630 --> 00:42:38,110
we just sit and smoke.

00:42:38,110 --> 00:42:41,470
So, therefore, with the new module,

00:42:41,470 --> 00:42:44,680
we can split to three main data structures.

00:42:44,680 --> 00:42:47,587
So you can simultaneously free and allocate.

00:42:47,587 --> 00:42:52,587
And, yeah, free, allocate, and lazily free.

00:42:53,210 --> 00:42:55,100
So it will be important.

00:42:55,100 --> 00:42:56,863
But it's not implemented yet.

00:42:56,863 --> 00:42:59,677
I will not be hard to implement because the module

00:43:00,860 --> 00:43:02,740
actually allows us to do that.

00:43:02,740 --> 00:43:04,310
In the previous module, for example,

00:43:04,310 --> 00:43:08,434
when we used gap-based allocator,

00:43:08,434 --> 00:43:11,230
so the program is, first of all,

00:43:11,230 --> 00:43:12,600
it's all fragmented.

00:43:12,600 --> 00:43:15,913
Second, we have a problem that, if we allocate from a gap,

00:43:17,290 --> 00:43:21,820
there are two main hidden things inside the tree.

00:43:21,820 --> 00:43:24,940
First one, it's gaps, free gaps.

00:43:24,940 --> 00:43:27,790
And, second one, it's mapped areas.

00:43:27,790 --> 00:43:30,890
And we can't actually split it.

00:43:30,890 --> 00:43:33,950
Because we have one item,

00:43:33,950 --> 00:43:36,390
or one entity.

00:43:36,390 --> 00:43:38,650
So, therefore, since we have now three,

00:43:38,650 --> 00:43:39,483
we can split it.

00:43:40,670 --> 00:43:42,443
I hope I answered your question.

00:43:44,283 --> 00:43:45,116
(speaking faintly off mic)

00:43:45,116 --> 00:43:45,949
Yeah.

00:43:47,650 --> 00:43:49,330
- [Announcer] So I think we're out of time.

00:43:49,330 --> 00:43:51,010
We need time for our next speaker

00:43:51,010 --> 00:43:52,640
to come up.

00:43:52,640 --> 00:43:54,210
So thank you very much.

00:43:54,210 --> 00:43:55,043
- [Uladzislau] You're welcome.

00:43:55,043 --> 00:43:58,194

YouTube URL: https://www.youtube.com/watch?v=qfqRPgBZ9Sk


