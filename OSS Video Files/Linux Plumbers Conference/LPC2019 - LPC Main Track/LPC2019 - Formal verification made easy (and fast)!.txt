Title: LPC2019 - Formal verification made easy (and fast)!
Publication date: 2019-11-18
Playlist: LPC2019 - LPC Main Track
Description: 
	Formal verification made easy (and fast)!

Speaker
 Daniel Bristot de Oliveira (Red Hat, Inc.)

Description
Linux is complex, and formal verification has been gaining more and more attention because independent "asserts" in the code can be ambiguous and not cover all the desired points. Formal models aim to avoid such problems of natural language, but the problem is that "formal modeling and verification" sound complex. Things have been changing.

What if I say it is possible to verify Linux behavior using a formal method?

Yes! We already have some models; people have been talking about it, but they seem to be very specific (Memory, Real-time...).
What if I say it is possible to model many Linux subsystems, to auto-generate code from the model, to run the model on-the-fly, and that this can be as efficient as just tracing?

No way!
Yes! It is! It is hard to believe, I know.

In this talk, the author will present a methodology based on events and state (automata), and how to model Linux' complex behaviors with small and intuitive models. Then, how to transform the model into efficient C code, that can be loaded into the kernel on-the-fly to verify Linux! Experiments have also shown that this can be as efficient as tracing (sometimes even better)!

This methodology can be applied on many the kernel subsystems, and the idea of this talk is also to discuss how to proceed towards a more formally verified Linux!
Captions: 
	00:00:00,290 --> 00:00:02,883
- So, good afternoon.

00:00:03,780 --> 00:00:08,230
I am Daniel, and I'm here to talk about

00:00:08,230 --> 00:00:13,230
formal verification made easy and fast, for sure fast.

00:00:14,740 --> 00:00:18,020
And this is an academic subject,

00:00:18,020 --> 00:00:20,430
because I'm trying to stay in the university

00:00:20,430 --> 00:00:23,360
because that's my excuse for my girlfriend.

00:00:23,360 --> 00:00:24,650
So, while I stay studying,

00:00:24,650 --> 00:00:27,890
I don't need to ask more compromises.

00:00:27,890 --> 00:00:32,890
So, that's why I try to feed Linux as is

00:00:33,010 --> 00:00:36,683
and the academic stuff, try to improve both situations.

00:00:37,660 --> 00:00:41,930
Mainly because, Linux is complex, right?

00:00:41,930 --> 00:00:45,110
We know a little bit about a part of the kernel.

00:00:45,110 --> 00:00:47,110
For example, I worked with the scheduling,

00:00:47,110 --> 00:00:50,320
but I have to be fair and say that I don't know

00:00:50,320 --> 00:00:52,710
about the Fair Scheduler, right?

00:00:52,710 --> 00:00:54,840
Things are complex, we have an integration

00:00:54,840 --> 00:00:56,340
of many sub systems.

00:00:56,340 --> 00:00:59,260
We have locking in the file system.

00:00:59,260 --> 00:01:01,330
Nobody knows all the picture,

00:01:01,330 --> 00:01:04,400
and describing the behavior of all the picture

00:01:04,400 --> 00:01:06,023
is hard, right?

00:01:09,960 --> 00:01:13,570
Linux is critical, and it's more critical than ever

00:01:13,570 --> 00:01:15,590
because there are people like BMW

00:01:15,590 --> 00:01:18,910
that are thinking to use Linux on cars,

00:01:18,910 --> 00:01:22,670
on Cyber-Physical Systems, for example.

00:01:22,670 --> 00:01:26,670
So, the more and more we need to be sure

00:01:26,670 --> 00:01:31,050
that Linux behaves as expected, right?

00:01:31,050 --> 00:01:35,543
But what do we expect from Linux?

00:01:36,670 --> 00:01:38,790
So, we have a lot of documentation

00:01:38,790 --> 00:01:41,550
saying what we expect from Linux.

00:01:41,550 --> 00:01:43,300
In many different languages.

00:01:43,300 --> 00:01:45,810
I learned Linux in Portuguese.

00:01:45,810 --> 00:01:48,850
And we have a lot of ifs inside the kernel saying,

00:01:48,850 --> 00:01:50,620
okay, this should not happen,

00:01:50,620 --> 00:01:53,470
or this specifically should not happen.

00:01:53,470 --> 00:01:57,920
And we have a lot of test case

00:01:57,920 --> 00:02:00,743
that try to check if Linux is behaving.

00:02:02,570 --> 00:02:06,290
And these all are good things, right?

00:02:06,290 --> 00:02:09,353
But how can I check if the reasoning

00:02:09,353 --> 00:02:14,353
behind the documentation, behind the test, is coherent?

00:02:14,880 --> 00:02:19,880
How do you check if all asserts are not contradictory

00:02:20,450 --> 00:02:23,330
or leading to explanations that bring us

00:02:23,330 --> 00:02:26,420
to a deadlock, or to a a livelock,

00:02:26,420 --> 00:02:28,730
in the reasoning of how things work,

00:02:28,730 --> 00:02:30,400
or should work at least.

00:02:30,400 --> 00:02:35,400
And how do you check that verification is

00:02:35,640 --> 00:02:37,690
including all the possible cases,

00:02:37,690 --> 00:02:39,920
that we are not forgetting anything?

00:02:39,920 --> 00:02:41,983
How do we control this though?

00:02:45,397 --> 00:02:48,840
So, what do we need for trying to achieve,

00:02:48,840 --> 00:02:50,670
or to resolve these problems?

00:02:50,670 --> 00:02:54,130
We need to find an intuitive way

00:02:54,130 --> 00:02:57,361
to describe what we expect from Linux,

00:02:57,361 --> 00:03:01,907
using methods that enable the verification of our reasoning,

00:03:01,907 --> 00:03:04,000
and the verification of our explanation

00:03:04,000 --> 00:03:07,980
of how the system should actually works,

00:03:07,980 --> 00:03:11,940
and that allow us to get all the cases

00:03:11,940 --> 00:03:16,410
without forgetting a specific test,

00:03:16,410 --> 00:03:21,410
or a case we wanted to verify.

00:03:21,880 --> 00:03:25,310
And this all should scale well, right?

00:03:25,310 --> 00:03:27,880
Because a test would not be useful

00:03:27,880 --> 00:03:31,460
if it takes like two years to complete, right?

00:03:31,460 --> 00:03:34,503
We need to deliver kernel faster than two years.

00:03:36,020 --> 00:03:40,730
So, there is, I'm just already jumping

00:03:40,730 --> 00:03:43,050
to saying that we need formal models

00:03:43,050 --> 00:03:45,790
because we already have some formal models in the kernel,

00:03:45,790 --> 00:03:48,380
and we are seeing the benefits of it.

00:03:48,380 --> 00:03:52,760
Catalin has some of applying formal methods

00:03:52,760 --> 00:03:55,660
for the spinlocks and found bugs.

00:03:55,660 --> 00:03:57,800
We have the memory model.

00:03:57,800 --> 00:04:00,860
I have that PREEMPT_RT model that I am working myself.

00:04:00,860 --> 00:04:04,450
So, it's not something new that we need

00:04:04,450 --> 00:04:07,420
formal methods from our models modeling the Linux kernel.

00:04:07,420 --> 00:04:10,283
We already have very good examples, right?

00:04:13,440 --> 00:04:16,683
But we need a more generic,

00:04:17,600 --> 00:04:20,230
or we need one generic and intuitive way

00:04:20,230 --> 00:04:22,090
for modeling the behavior

00:04:22,090 --> 00:04:24,240
that applies for other parts of the kernel.

00:04:26,560 --> 00:04:29,610
So, how can we turn modeling,

00:04:29,610 --> 00:04:31,820
which is something we have on our minds

00:04:31,820 --> 00:04:34,750
as something complex, right?

00:04:34,750 --> 00:04:37,800
We do our university, and we pass on exams,

00:04:37,800 --> 00:04:39,913
and forget about it, because it's complex.

00:04:43,050 --> 00:04:45,853
So, how can we turn that complex thing

00:04:45,853 --> 00:04:48,533
a little bit easier for us?

00:04:50,300 --> 00:04:53,413
We need to find a formal method that looks natural for us.

00:04:57,020 --> 00:05:01,323
That we can express ourselves in a more easy way.

00:05:02,350 --> 00:05:05,180
And thinking about the runtime verification of Linux,

00:05:05,180 --> 00:05:06,983
or when it's running,

00:05:07,860 --> 00:05:11,343
how do we observe the Linux dynamics nowadays?

00:05:13,770 --> 00:05:15,423
Trace of events, right?

00:05:16,290 --> 00:05:18,680
We have a lot of tracing tools.

00:05:18,680 --> 00:05:22,350
We have ftrace and BPF, and all that kind of stuff.

00:05:22,350 --> 00:05:27,100
And we are generally reading those traces

00:05:27,100 --> 00:05:32,100
and inside of our minds, we are drawing state machines.

00:05:32,510 --> 00:05:33,990
We're thinking on state machines,

00:05:33,990 --> 00:05:36,360
we are not necessarily putting in the paper.

00:05:36,360 --> 00:05:39,040
But the wake up of a task brings us to a state

00:05:39,040 --> 00:05:43,840
in which, okay, the task is ready to run.

00:05:43,840 --> 00:05:47,110
And then we will need to wait for this cad switch

00:05:47,110 --> 00:05:48,500
for it to start actually running.

00:05:48,500 --> 00:05:52,810
So, that's a somehow natural way of thinking for us.

00:05:52,810 --> 00:05:55,290
And also because all the operating system books

00:05:55,290 --> 00:05:57,830
have the state machines explain the states

00:05:57,830 --> 00:06:00,383
of processors and things like that.

00:06:01,270 --> 00:06:03,307
This seems to be one possible,

00:06:03,307 --> 00:06:06,080
and there should be more, for sure, there are more.

00:06:06,080 --> 00:06:11,080
But this seems to be one way to go, one possible way to go.

00:06:11,830 --> 00:06:16,830
So, state machines are used to model event-driven systems.

00:06:19,970 --> 00:06:22,860
And event-driven systems are described

00:06:22,860 --> 00:06:27,860
as a sequence of events, or a sequence of traces.

00:06:28,690 --> 00:06:32,460
And, as I explained before, we do this inside of our mind.

00:06:32,460 --> 00:06:35,510
But this, actually, is one example

00:06:35,510 --> 00:06:39,080
of a state-machine that I used to report a bug.

00:06:39,080 --> 00:06:40,910
To, this bug...

00:06:44,240 --> 00:06:45,073
Here.

00:06:47,180 --> 00:06:48,080
It's in the model.

00:06:51,770 --> 00:06:56,770
And here is the example of the model I submitted,

00:06:58,450 --> 00:07:01,063
and this is part of the work I'm presenting now, so.

00:07:02,728 --> 00:07:05,719
- [Audience Member] LKML.org is good, (muffled speaking).

00:07:05,719 --> 00:07:07,052
- [Daniel] Okay.

00:07:09,150 --> 00:07:14,150
But, if you are a friend of mine,

00:07:14,390 --> 00:07:18,420
and were here last year, you might recall that,

00:07:21,880 --> 00:07:24,273
okay, I talked about it last year.

00:07:25,460 --> 00:07:26,840
I was talking about the idea

00:07:26,840 --> 00:07:29,750
of using state-machines and automata

00:07:29,750 --> 00:07:34,090
to describe the behavior of the tasks on PREEMPT_RT.

00:07:34,090 --> 00:07:36,330
And at the time, I was thinking to use it

00:07:36,330 --> 00:07:41,330
for trying to extract variables from the behavior of Linux

00:07:42,980 --> 00:07:46,340
to use on the realtime mathematics part.

00:07:46,340 --> 00:07:49,010
But at the end of the presentation,

00:07:49,010 --> 00:07:50,780
Masami came to talk to me,

00:07:50,780 --> 00:07:54,280
and Peter and Arnaldo came to talk to me,

00:07:54,280 --> 00:07:56,630
that they should try to move those things

00:07:56,630 --> 00:07:59,240
to model in a more generic way.

00:07:59,240 --> 00:08:01,890
So, apply to other sub systems, do you remember that?

00:08:02,870 --> 00:08:04,405
Yeah, okay, so I'm not lying.

00:08:04,405 --> 00:08:06,380
(crowd laughing)

00:08:06,380 --> 00:08:09,260
And they came, and also Clark Williams,

00:08:09,260 --> 00:08:11,790
my lovely manager also came saying,

00:08:11,790 --> 00:08:13,640
oh, you should put more time on this.

00:08:16,681 --> 00:08:18,400
And we continued working on that.

00:08:18,400 --> 00:08:20,453
But just recalling a little bit,

00:08:22,070 --> 00:08:25,428
this seems to be something that was drawn.

00:08:25,428 --> 00:08:28,660
I have some balls and some points

00:08:31,560 --> 00:08:33,063
connection one to the other.

00:08:34,030 --> 00:08:38,010
But this is the good thing about automata.

00:08:38,010 --> 00:08:40,400
It's a very simple format that we can understand.

00:08:40,400 --> 00:08:42,030
This is the initial state,

00:08:42,030 --> 00:08:44,940
this is the safe state, or the final state.

00:08:44,940 --> 00:08:49,560
And we can see that we can open here,

00:08:49,560 --> 00:08:51,810
can be a socket, and we can close the socket.

00:08:51,810 --> 00:08:55,370
And when the socket's open we can send a request

00:08:55,370 --> 00:08:57,440
and read the request, and send a request,

00:08:57,440 --> 00:08:59,433
read the request until we close it.

00:09:00,720 --> 00:09:05,530
It's very forward to understand, but in the back,

00:09:05,530 --> 00:09:09,320
we have a formal definition of those states.

00:09:09,320 --> 00:09:12,747
So, one automata is a finite set of states.

00:09:14,694 --> 00:09:16,697
A finite set of events, a set of transitions that say that

00:09:19,090 --> 00:09:21,760
okay, if I am on the state, in one of the states

00:09:21,760 --> 00:09:25,610
and receive these events, I will go to the next state.

00:09:25,610 --> 00:09:26,573
It clearly says, okay,

00:09:26,573 --> 00:09:29,843
this is my initial state, these are my final states.

00:09:30,910 --> 00:09:34,620
And the possible chain of events

00:09:34,620 --> 00:09:39,490
that are recognized by the automata

00:09:39,490 --> 00:09:42,890
is the language recognized by the automata.

00:09:42,890 --> 00:09:45,850
And the idea was that when we have

00:09:47,640 --> 00:09:51,340
one trace that is not recognized by the automata,

00:09:51,340 --> 00:09:53,070
we are seeing one event

00:09:53,070 --> 00:09:55,310
that should not happen at that point.

00:09:55,310 --> 00:10:00,310
For example, I could not want to have a close here

00:10:00,550 --> 00:10:01,950
returning to the initial state

00:10:01,950 --> 00:10:03,973
because then I would not wait to read.

00:10:04,990 --> 00:10:07,520
So, we can model what we want,

00:10:07,520 --> 00:10:10,480
and explicitly here what we don't want.

00:10:10,480 --> 00:10:12,080
And when we hit what we don't want,

00:10:12,080 --> 00:10:13,137
we can complain, and say,

00:10:13,137 --> 00:10:16,127
"Okay, the system is not behaving as expected."

00:10:17,190 --> 00:10:22,190
But why use the automata?

00:10:23,510 --> 00:10:25,280
The good thing about using a formal method

00:10:25,280 --> 00:10:28,870
is that you can apply other methods on top of it.

00:10:28,870 --> 00:10:31,720
Like, you can use formal methods to verify

00:10:31,720 --> 00:10:36,720
if my model is deadlock free, or livelock free,

00:10:36,910 --> 00:10:39,730
using tlaplus like Catalin Marinas's

00:10:39,730 --> 00:10:41,753
last year presentation showed you.

00:10:41,753 --> 00:10:44,640
You present this year about the same topic again,

00:10:44,640 --> 00:10:46,094
don't you, Catalin?

00:10:46,094 --> 00:10:48,120
(muffled speaking)

00:10:48,120 --> 00:10:51,280
Oh, yeah, but that's one of the cases

00:10:51,280 --> 00:10:54,160
where you can use the way that he was testing

00:10:54,160 --> 00:10:55,160
using a formal method.

00:10:55,160 --> 00:10:58,570
So, we can integrate with other kinds of verification

00:10:58,570 --> 00:11:02,490
to check our reasoning, or if the kernel is behaving.

00:11:02,490 --> 00:11:07,490
And also, it enables the modular development of a system.

00:11:09,680 --> 00:11:14,410
For example, I can draw myself these,

00:11:14,410 --> 00:11:18,870
but I can do a more constructive way to reach the state,

00:11:18,870 --> 00:11:21,320
to reach the description of the system.

00:11:21,320 --> 00:11:25,520
For example, this technique says that,

00:11:25,520 --> 00:11:28,450
first I develop the simple models

00:11:28,450 --> 00:11:33,450
as more as possible for the operations that are independent.

00:11:34,130 --> 00:11:39,080
So, that model, I can say that I can open and close a socket

00:11:39,080 --> 00:11:41,293
and then I can read and write a socket.

00:11:42,560 --> 00:11:44,073
This is a dumb example, right?

00:11:45,280 --> 00:11:50,150
If you want better examples, watch the last year's talk.

00:11:50,150 --> 00:11:52,323
There is a useful example here, there.

00:11:54,410 --> 00:11:58,400
And so, if I synchronize these two models,

00:11:58,400 --> 00:12:03,140
I have all the possible chains of events.

00:12:03,140 --> 00:12:07,360
Those that are expected, and those that are not expected

00:12:07,360 --> 00:12:09,620
like closing a socket and then reopening it

00:12:09,620 --> 00:12:12,550
to wait for the read, for example.

00:12:12,550 --> 00:12:16,390
Or reading and writing while the sockets are closed.

00:12:16,390 --> 00:12:19,820
So, we first draw out all the possibilities,

00:12:19,820 --> 00:12:24,290
and then work to cutting off the cases we don't want.

00:12:24,290 --> 00:12:26,860
And these are the restrictions imposed to the model.

00:12:26,860 --> 00:12:30,960
Like I can say that I can only close the socket

00:12:30,960 --> 00:12:33,870
when I'm not in the middle of an operation.

00:12:33,870 --> 00:12:37,130
So, if one close happens here,

00:12:37,130 --> 00:12:39,330
this is not expected, and this is a problem.

00:12:40,300 --> 00:12:42,090
At same time I can say that okay,

00:12:42,090 --> 00:12:47,090
I will only start reading and write after doing a open.

00:12:48,740 --> 00:12:53,440
And then I can synchronize these, and do the verifications.

00:12:53,440 --> 00:12:56,580
And here I am using a tool that does this,

00:12:56,580 --> 00:12:57,730
there are many of them,

00:12:57,730 --> 00:13:00,780
but here it's say that system is blocking.

00:13:00,780 --> 00:13:03,280
It's saying that I cannot return to the initial state.

00:13:03,280 --> 00:13:06,633
So, I have a livelock or a deadlock on my reasoning there.

00:13:09,230 --> 00:13:12,090
That's because I didn't say

00:13:12,090 --> 00:13:14,010
that I cannot close and write here,

00:13:14,010 --> 00:13:17,263
it was missing this part.

00:13:19,620 --> 00:13:21,390
It's not the case that I only need

00:13:21,390 --> 00:13:23,150
to read and write after opening.

00:13:23,150 --> 00:13:27,393
It's after opening, and before closing.

00:13:28,650 --> 00:13:31,417
And so, synchronizing those generators,

00:13:31,417 --> 00:13:33,830
and these specifications bring me back

00:13:33,830 --> 00:13:36,133
to the case we know it's correct.

00:13:37,260 --> 00:13:38,883
Why not just draw it, Daniel?

00:13:39,796 --> 00:13:43,663
Okay, this was just an example to show the approach.

00:13:45,330 --> 00:13:48,750
But last year, I presented the PREEMPT_RT model

00:13:48,750 --> 00:13:51,720
that generated a state machine

00:13:51,720 --> 00:13:56,720
with 9,000 states, and 23,000 transitions.

00:13:56,890 --> 00:14:01,890
So, it's impossible to draw it, right?

00:14:01,901 --> 00:14:04,283
At least during my PhD time.

00:14:06,170 --> 00:14:10,770
And all this reasoning, the way that they construct it

00:14:10,770 --> 00:14:13,200
using generators and specifications,

00:14:13,200 --> 00:14:17,320
and the verification of my reasoning show that my model here

00:14:17,320 --> 00:14:20,840
doesn't have something obviously wrong.

00:14:20,840 --> 00:14:23,030
Like it doesn't have a deadlock

00:14:23,030 --> 00:14:26,320
and doesn't have a livelock inside it.

00:14:26,320 --> 00:14:28,360
And during the development of the model,

00:14:28,360 --> 00:14:30,610
we found three bugs that would not

00:14:30,610 --> 00:14:32,063
be detected by other tools.

00:14:35,860 --> 00:14:39,840
This idea of modeling the behavior of Linux

00:14:39,840 --> 00:14:44,520
ended up being accepted on three different papers

00:14:44,520 --> 00:14:49,520
that covers this story of modeling the PREEMPT_RT behavior.

00:14:51,310 --> 00:14:55,283
So, this means that I'm speaking

00:14:56,940 --> 00:14:58,930
about academic stuff applied to Linux

00:14:58,930 --> 00:15:03,930
and the academy is accepting this as something useful.

00:15:04,290 --> 00:15:09,290
I'm not just talking to myself, and this is good.

00:15:11,780 --> 00:15:16,780
Okay, so I was explaining how to model

00:15:18,690 --> 00:15:22,220
how the Linux behaves, what we expected from Linux.

00:15:22,220 --> 00:15:25,430
But how to verify that the system

00:15:25,430 --> 00:15:29,363
is actually behaving as we expect, right?

00:15:30,960 --> 00:15:34,433
Is comparing the system execution against the model.

00:15:37,970 --> 00:15:42,890
And last year, it was a read BOSS/BODE doing it.

00:15:42,890 --> 00:15:46,143
I was doing with perf, I was recording all the events,

00:15:47,000 --> 00:15:49,730
bringing them to the user space,

00:15:49,730 --> 00:15:51,923
and then later doing the post-processing.

00:15:52,910 --> 00:15:57,277
Here it was already running the comparison part,

00:15:57,277 --> 00:15:59,560
the verification part it was, you know, of one,

00:15:59,560 --> 00:16:00,700
and they had good properties.

00:16:00,700 --> 00:16:03,630
But we have the problem of that,

00:16:03,630 --> 00:16:05,990
for example, on a single core box,

00:16:05,990 --> 00:16:09,250
in 30 seconds I generated two gigs of data.

00:16:09,250 --> 00:16:12,273
So, this wasn't that practical, right?

00:16:14,340 --> 00:16:16,750
But things changed since these slides.

00:16:16,750 --> 00:16:18,340
Like Red Hat changed the symbol,

00:16:18,340 --> 00:16:20,590
and it's more red than before.

00:16:20,590 --> 00:16:23,794
So, no jokes about switching our color to blue.

00:16:23,794 --> 00:16:25,690
(crowd laughing)

00:16:25,690 --> 00:16:30,077
But other than that, I developed a new approach.

00:16:33,070 --> 00:16:38,070
That is, rather than tracing and verifying

00:16:40,020 --> 00:16:43,220
user space and requiring all the transfer of data

00:16:43,220 --> 00:16:45,040
from the kernel to user space

00:16:45,040 --> 00:16:48,390
and all that huge storage that it requires,

00:16:48,390 --> 00:16:53,390
I'm getting the model and I'm using Python

00:16:53,470 --> 00:16:56,893
to translate that model to see data structures.

00:16:57,980 --> 00:17:01,870
And then I use that, using that data structures

00:17:01,870 --> 00:17:06,460
I connect the verification code

00:17:07,390 --> 00:17:11,600
with the tracing functions of the kernel,

00:17:11,600 --> 00:17:15,740
the tracing features, like, I get the code generated,

00:17:15,740 --> 00:17:20,740
and I hook the handler of one event to one kernel event,

00:17:21,640 --> 00:17:24,436
and then I do the comparison runtime.

00:17:24,436 --> 00:17:28,090
As long as my system is accepting,

00:17:28,090 --> 00:17:30,750
or the model is accepting the events that are coming,

00:17:30,750 --> 00:17:31,583
it's okay.

00:17:31,583 --> 00:17:35,020
If not, it generates a dump to the trace.

00:17:35,020 --> 00:17:36,614
And I can get the chain of events

00:17:36,614 --> 00:17:39,750
that brought me to the undesired step.

00:17:43,350 --> 00:17:45,390
- So, how do you generate the model

00:17:45,390 --> 00:17:46,830
in the first place?

00:17:46,830 --> 00:17:51,683
The first stage, right, how did you get that dot file?

00:17:53,190 --> 00:17:56,480
- Oh, I'm using one tool which is Supremica.

00:17:56,480 --> 00:17:59,100
That allows me to do the modeling,

00:17:59,100 --> 00:18:01,457
and the synchronization, the verification,

00:18:01,457 --> 00:18:03,800
and it exports in this format.

00:18:03,800 --> 00:18:07,770
But one can use the graphics to export it.

00:18:07,770 --> 00:18:09,270
Can use any format,

00:18:09,270 --> 00:18:11,620
any tool that exports the resulting

00:18:12,764 --> 00:18:14,960
in the graphics format, which is the dot.

00:18:14,960 --> 00:18:18,170
- So, you did this for the PREEMPT_RT patch that...

00:18:19,154 --> 00:18:21,120
- Well, I did on the previous work,

00:18:21,120 --> 00:18:23,190
I did the model for the PREEMPT_RT,

00:18:23,190 --> 00:18:26,653
but you can model anything, and translate into code.

00:18:27,770 --> 00:18:30,263
Yeah, you can model RSU and translate into code.

00:18:33,660 --> 00:18:34,493
So...

00:18:36,950 --> 00:18:38,970
- Daniel, the question is like,

00:18:38,970 --> 00:18:43,970
if you are suggesting everyone trying to use your approach,

00:18:44,250 --> 00:18:46,650
we need to have a common language

00:18:46,650 --> 00:18:48,630
of describing these automata.

00:18:48,630 --> 00:18:49,893
- [Daniel] Yes. - So you will (mumbles)

00:18:49,893 --> 00:18:51,920
- And that's the dot format.

00:18:51,920 --> 00:18:54,520
- Well, the dot format is not a thing

00:18:54,520 --> 00:18:57,443
that you would check in into the repository, right?

00:18:58,420 --> 00:19:01,120
- You can use the dot format.

00:19:01,120 --> 00:19:02,790
It's a text, yeah, it's a text format.

00:19:02,790 --> 00:19:05,730
- But this is already the generated part, right?

00:19:05,730 --> 00:19:10,240
Or is it just this is the full automata.

00:19:10,240 --> 00:19:11,490
- It can be the full automata,

00:19:11,490 --> 00:19:14,140
it can be just each model,

00:19:14,140 --> 00:19:15,820
but I'm using forward verification,

00:19:15,820 --> 00:19:18,600
I'm using the entire model, the runtime.

00:19:18,600 --> 00:19:20,363
Because this turns the operations out, O of one.

00:19:20,363 --> 00:19:22,220
- [Audience Member] But it's not the generator

00:19:22,220 --> 00:19:23,520
in the constraints, right?

00:19:24,360 --> 00:19:25,193
- Yes.

00:19:25,193 --> 00:19:26,270
- [Audience Member] It is, okay.

00:19:26,270 --> 00:19:29,150
- Yeah, you model everything,

00:19:29,150 --> 00:19:32,650
and then you could run each automata for each event.

00:19:32,650 --> 00:19:35,550
But this would be O of an operation.

00:19:35,550 --> 00:19:38,130
When you have all the models synchronized

00:19:38,130 --> 00:19:40,120
the operation becomes O of one.

00:19:40,120 --> 00:19:43,260
That's why I'm using the full model to do this part.

00:19:43,260 --> 00:19:46,500
But the idea is dot format is a text format,

00:19:46,500 --> 00:19:49,750
is an open format, and is provided by the graphics library,

00:19:49,750 --> 00:19:51,233
which is open too.

00:19:52,590 --> 00:19:55,140
- And you think that's the right approach,

00:19:55,140 --> 00:19:56,487
the right language for modeling that?

00:19:56,487 --> 00:20:00,623
- I think it's one language, one possible language.

00:20:01,709 --> 00:20:04,626
(muffled speaking)

00:20:06,400 --> 00:20:08,730
- So, how hard it is to write those models?

00:20:08,730 --> 00:20:11,060
Have you tried to write models for something else?

00:20:11,060 --> 00:20:12,720
And what parts of the kernels

00:20:12,720 --> 00:20:13,553
may be good candidates for such models?

00:20:13,553 --> 00:20:16,460
- Yes, it was the last year's presentation.

00:20:16,460 --> 00:20:18,660
I modeled how the synchronization primitives

00:20:21,329 --> 00:20:25,620
of the PREEMPT_RT are correlated and how they describe

00:20:25,620 --> 00:20:29,040
the execution of the realtime test on the PREEMPT_RT.

00:20:29,040 --> 00:20:31,283
And that is the model I'm mentioning here.

00:20:32,455 --> 00:20:34,204
Oops, wait, wait, backwards.

00:20:34,204 --> 00:20:36,070
- [Audience Member] Wrong direction.

00:20:36,070 --> 00:20:37,883
- Yeah, this model for example.

00:20:39,080 --> 00:20:42,440
That describes the behavior of the PREEMPT_RT.

00:20:42,440 --> 00:20:43,760
And these are the publications

00:20:43,760 --> 00:20:45,440
where you can read more about it.

00:20:45,440 --> 00:20:48,380
- But this is all the same area.

00:20:48,380 --> 00:20:49,520
Have you tried to apply it to other things?

00:20:49,520 --> 00:20:51,850
Say, you know, circuits, files, systems?

00:20:51,850 --> 00:20:52,790
What other parts?

00:20:52,790 --> 00:20:55,390
- That's what I'm trying to convincing people to do.

00:20:57,025 --> 00:20:57,858
(crowd laughing)

00:20:57,858 --> 00:21:00,950
Do you have any indication that it will be

00:21:00,950 --> 00:21:03,320
suitable for other parts of the kernel?

00:21:03,320 --> 00:21:08,320
- How do you check the behavior of the system nowadays,

00:21:10,850 --> 00:21:12,880
the connections of traces,

00:21:12,880 --> 00:21:15,193
the connection that are happening?

00:21:16,850 --> 00:21:20,200
The point is that you can observe these using trace.

00:21:20,200 --> 00:21:22,670
And you have tracepoints, and you have function traces.

00:21:22,670 --> 00:21:24,780
So, that's why I explained before

00:21:24,780 --> 00:21:26,320
that this would be suitable

00:21:26,320 --> 00:21:30,030
for other areas of the kernel.

00:21:30,030 --> 00:21:31,640
- Let's say for file systems,

00:21:31,640 --> 00:21:33,260
you probably want to want to just tracepoint.

00:21:33,260 --> 00:21:37,460
But tracking this contents of the files,

00:21:37,460 --> 00:21:39,320
or I don't know, some other data?

00:21:40,450 --> 00:21:42,720
- Okay, it depends on what, okay,

00:21:42,720 --> 00:21:46,050
this is for run-time verification based on event.

00:21:46,050 --> 00:21:47,520
If you apply for all the things

00:21:47,520 --> 00:21:50,820
that you can actually verify using trace,

00:21:50,820 --> 00:21:52,170
and there are many subsystems

00:21:52,170 --> 00:21:54,680
that people observe using trace,

00:21:54,680 --> 00:21:57,390
for this case, this would be a possibility.

00:21:57,390 --> 00:22:00,420
But I'm not trying to resolve all the problems of the world.

00:22:00,420 --> 00:22:03,490
If you want to do an instructional-level verification,

00:22:03,490 --> 00:22:05,410
you can use other methods to describe.

00:22:05,410 --> 00:22:07,940
Like Catalin uses for the spinlocks.

00:22:12,040 --> 00:22:13,080
There is another.

00:22:13,080 --> 00:22:14,980
- [Audience Member] Just to see if I understand correctly,

00:22:14,980 --> 00:22:19,090
so if you go back to the previous slide with the PREEMPT_RT.

00:22:19,090 --> 00:22:22,400
No, with the model saying, yes.

00:22:22,400 --> 00:22:24,480
So, just to understand.

00:22:24,480 --> 00:22:27,060
So, you didn't generate all those states

00:22:27,060 --> 00:22:28,300
and all those transitions by hand.

00:22:28,300 --> 00:22:30,077
You have a method for that, an automated tool for that?

00:22:30,077 --> 00:22:33,270
- No, okay, I generated, by hand,

00:22:33,270 --> 00:22:36,892
I created 12 generators and 33 specifications

00:22:36,892 --> 00:22:40,363
and the more complex one has just nine states.

00:22:41,570 --> 00:22:44,430
And then I synchronized them all

00:22:44,430 --> 00:22:47,500
and generate a model with 9,000 states.

00:22:47,500 --> 00:22:50,270
So, we broke the reasoning

00:22:50,270 --> 00:22:54,150
to have as most states to generate the big one.

00:22:54,150 --> 00:22:59,150
One could try to auto-generate this model using the trace.

00:23:00,130 --> 00:23:02,760
But if your system has a bug,

00:23:02,760 --> 00:23:05,970
the bug will be translated into the code as well.

00:23:05,970 --> 00:23:09,750
And that's why it's better to do the manual thing

00:23:09,750 --> 00:23:12,340
than doing manual things step-by-step

00:23:12,340 --> 00:23:15,120
and trying to break down all the restrictions

00:23:15,120 --> 00:23:18,210
than doing an automatic one, but it's possible.

00:23:18,210 --> 00:23:19,245
- [Audience Member] It's best to describe

00:23:19,245 --> 00:23:22,130
what you're expecting (muffled speaking)

00:23:22,130 --> 00:23:24,670
- But when you merge the simple models,

00:23:24,670 --> 00:23:27,532
you have some sites that are not valid, right?

00:23:27,532 --> 00:23:30,722
- When I generated all the generators,

00:23:30,722 --> 00:23:32,700
I have a lot of states that are not valid.

00:23:32,700 --> 00:23:34,965
And then the specifications say

00:23:34,965 --> 00:23:37,990
what are the states I don't expect?

00:23:37,990 --> 00:23:40,950
And then you cut down these states I don't expect

00:23:40,950 --> 00:23:43,735
and reduce to the ones I expect.

00:23:43,735 --> 00:23:44,568
- [Audience Member] Okay, thank you.

00:23:44,568 --> 00:23:46,550
- That's why when there's one event that is not expected,

00:23:46,550 --> 00:23:47,383
it's a problem.

00:23:48,520 --> 00:23:51,220
- So, maybe a little follow up to the question before.

00:23:52,720 --> 00:23:55,120
It's obvious that you cannot describe everything

00:23:56,012 --> 00:23:57,767
you can describe and see with automata.

00:23:57,767 --> 00:24:00,470
So, there must be portions of the kernel

00:24:00,470 --> 00:24:01,380
that do not fit to this approach.

00:24:01,380 --> 00:24:05,480
Sort of, think about where this approach applies

00:24:05,480 --> 00:24:09,020
and where it's limited.

00:24:09,020 --> 00:24:12,020
- Anything that we can describe using state machines,

00:24:12,020 --> 00:24:16,950
like state of connections on TCPs, states of firewalls.

00:24:16,950 --> 00:24:20,090
Anything that's states and events we can model.

00:24:20,090 --> 00:24:22,091
- Of course, but if I have, for example,

00:24:22,091 --> 00:24:26,200
some random decision somewhere like in the crypto code

00:24:26,200 --> 00:24:28,350
that wouldn't apply then anymore, would it?

00:24:29,238 --> 00:24:31,350
I'm just curious where the limitations are.

00:24:31,350 --> 00:24:34,900
- Yeah, yeah, that's better for determinist,

00:24:34,900 --> 00:24:38,204
there are automata for non-determinist cases,

00:24:38,204 --> 00:24:41,689
but this is better for the deterministic cases.

00:24:41,689 --> 00:24:42,610
- But, I mean, you can make

00:24:42,610 --> 00:24:44,690
non-deterministic automata deterministic.

00:24:44,690 --> 00:24:49,690
So, would your approaches work with, like, Markov chains?

00:24:52,140 --> 00:24:55,800
Or could you generalize that from automata to Markov chains?

00:24:55,800 --> 00:24:56,633
- I don't know.

00:24:59,020 --> 00:25:00,611
We need to think about it.

00:25:00,611 --> 00:25:02,330
(muffled speaking)

00:25:02,330 --> 00:25:07,330
- So, Daniel, so, you created this specification last year.

00:25:09,280 --> 00:25:12,403
And I assume you have it on your laptop, right?

00:25:13,810 --> 00:25:15,650
Does it still hold this year?

00:25:15,650 --> 00:25:16,483
- [Daniel] Sure.

00:25:17,430 --> 00:25:19,940
- So, this means that the changes that happened

00:25:19,940 --> 00:25:21,853
happened in the scheduler in the last year?

00:25:21,853 --> 00:25:26,510
- I am not modeling, yeah, I took care of modeling things

00:25:26,510 --> 00:25:30,560
that don't change that often.

00:25:30,560 --> 00:25:32,880
I discussed all these questions last year

00:25:32,880 --> 00:25:35,150
and they are writing in the paper.

00:25:35,150 --> 00:25:39,800
The point is that the things I described on that model,

00:25:39,800 --> 00:25:41,570
didn't change in the last 10 years.

00:25:41,570 --> 00:25:44,100
They changed when we added SMP support

00:25:44,100 --> 00:25:46,800
or when we created the PREEMPT_RT model.

00:25:46,800 --> 00:25:50,950
But, yeah, on that case I took care of these decisions.

00:25:50,950 --> 00:25:52,620
On other models that might change,

00:25:52,620 --> 00:25:54,550
and people might follow the code, and try to--

00:25:54,550 --> 00:25:57,423
- So, at the moment, you actually don't know if,

00:25:59,250 --> 00:26:01,640
let's say, some other scheduler developer

00:26:01,640 --> 00:26:04,190
could actually change the model

00:26:04,190 --> 00:26:05,900
that you have written the first time.

00:26:05,900 --> 00:26:07,964
Because you actually don't know

00:26:07,964 --> 00:26:09,740
if it's understandable to-- - [Daniel] No, no.

00:26:09,740 --> 00:26:12,810
I'm not, on that case specifically,

00:26:12,810 --> 00:26:15,360
I'm not modeling strictly the code,

00:26:15,360 --> 00:26:17,670
but abstractions that we use.

00:26:17,670 --> 00:26:20,449
Preempt is disabled, yet nobody touch it.

00:26:20,449 --> 00:26:22,520
IRQ disabled, nobody touch it.

00:26:22,520 --> 00:26:24,970
The way that the restrictions should take rt lock,

00:26:24,970 --> 00:26:26,560
mutex didn't work.

00:26:26,560 --> 00:26:30,170
The restrictions supposed to take spinlock didn't work.

00:26:30,170 --> 00:26:32,140
So I'm working on a level of abstraction

00:26:32,140 --> 00:26:34,760
that doesn't actually change every day.

00:26:34,760 --> 00:26:36,680
It's not one code of line that you change.

00:26:36,680 --> 00:26:38,380
It will break entirely PREEMPT_RT.

00:26:42,340 --> 00:26:46,090
- So, question I have, so from the dot file,

00:26:46,090 --> 00:26:48,773
you generate that code that you plug into Linux

00:26:48,773 --> 00:26:53,773
and you verify that the behavior of the Linux kernel

00:26:54,210 --> 00:26:55,613
matches your model.

00:26:57,400 --> 00:27:02,400
How do you verify that your model has certain properties?

00:27:05,617 --> 00:27:07,923
So, before you actually get to the kernel,

00:27:08,870 --> 00:27:09,907
kernel matches the model.

00:27:09,907 --> 00:27:13,890
Does your model satisfy certain properties?

00:27:13,890 --> 00:27:14,723
Use this in the--

00:27:14,723 --> 00:27:17,490
- Which properties, like saying if it's deadlock free,

00:27:17,490 --> 00:27:18,323
or if there's--

00:27:18,323 --> 00:27:21,390
- Dead or liveness, or, for example, one thing is,

00:27:21,390 --> 00:27:25,060
let's say, floating-point state saving and restoring.

00:27:25,060 --> 00:27:26,810
I can draw some state machine about one init

00:27:26,810 --> 00:27:30,930
to where I could have the kernel, you know,

00:27:30,930 --> 00:27:33,513
some tracepoints that match, it matches my model.

00:27:33,513 --> 00:27:35,793
Well, what if my model is wrong?

00:27:36,700 --> 00:27:38,510
So how can I prove that my,

00:27:38,510 --> 00:27:40,660
how do you do this in this step?

00:27:40,660 --> 00:27:43,400
I know how to do it in tlaplus, I have a model,

00:27:43,400 --> 00:27:46,790
and too I can write some properties, like, okay,

00:27:46,790 --> 00:27:48,876
something eventually happens, like, you know--

00:27:48,876 --> 00:27:53,660
- Yeah, you can check if something eventually happens

00:27:53,660 --> 00:27:56,290
in the model using tlaplus for automata.

00:27:56,290 --> 00:27:58,610
There are tools that make it.

00:27:58,610 --> 00:28:01,640
In the kernel, we need to compare one each other,

00:28:01,640 --> 00:28:05,250
and see if there is, during the development of the model,

00:28:05,250 --> 00:28:09,610
you need to see if your model is generating problem.

00:28:09,610 --> 00:28:12,330
When one problem happens, you need to check first if

00:28:12,330 --> 00:28:15,490
the problem is in your model or if it's in the kernel.

00:28:15,490 --> 00:28:17,810
But the problem is that on runtime

00:28:17,810 --> 00:28:19,630
we have no current way to say

00:28:19,630 --> 00:28:23,350
that we exercised all the paths inside the Linux, right?

00:28:23,350 --> 00:28:25,160
That's a problem of runtime verification.

00:28:25,160 --> 00:28:27,060
I cannot exercise all the paths

00:28:27,060 --> 00:28:29,560
and see that we are covering all the cases.

00:28:29,560 --> 00:28:33,670
So for the modeling, you end up going this way, like,

00:28:33,670 --> 00:28:37,800
you cut the events you don't expect,

00:28:37,800 --> 00:28:40,770
and try to run the Linux, and see if it's matching,

00:28:40,770 --> 00:28:45,020
matching, and try to get it to converge in a model

00:28:45,020 --> 00:28:48,973
that actually stabilizes, is it?

00:28:50,210 --> 00:28:51,980
- [Audience Member] Yeah, thank you.

00:28:51,980 --> 00:28:53,780
- So I'm gonna say, Andres,

00:28:53,780 --> 00:28:56,560
this will be the last question for a little while,

00:28:56,560 --> 00:28:59,140
we'll let Daniel do a bit more of his talk, and,

00:28:59,140 --> 00:29:00,270
cause otherwise we're just gonna

00:29:00,270 --> 00:29:01,693
cycle around asking questions--

00:29:01,693 --> 00:29:02,530
- No, no, no problem, no, the--

00:29:02,530 --> 00:29:03,550
- [Moderator] Oh, okay, all right, sure.

00:29:03,550 --> 00:29:04,383
- Yeah, no, it's okay.

00:29:04,383 --> 00:29:05,216
- [Moderator] If you're okay with it.

00:29:05,216 --> 00:29:06,051
- The questions are good.

00:29:06,051 --> 00:29:06,884
- [Moderator] I just wanted to make sure

00:29:06,884 --> 00:29:08,100
you didn't get completely derailed.

00:29:08,100 --> 00:29:09,630
Um, you go.

00:29:09,630 --> 00:29:10,700
- So yeah, I wanted to follow up

00:29:10,700 --> 00:29:12,440
on two aspects that came up here.

00:29:12,440 --> 00:29:14,890
So one was about this dot file

00:29:14,890 --> 00:29:17,223
possibly being committed to the repository?

00:29:18,380 --> 00:29:20,470
And yes, that of course begs the question

00:29:20,470 --> 00:29:21,590
that Lukas already brought up

00:29:21,590 --> 00:29:24,800
of actually making sure that we do not have a stale file

00:29:24,800 --> 00:29:27,780
that is actually lying around and describing something

00:29:27,780 --> 00:29:29,470
that may have been a state in the past

00:29:29,470 --> 00:29:30,956
but is no longer current.

00:29:30,956 --> 00:29:35,956
So for one, isn't the solution of that going to be

00:29:36,000 --> 00:29:38,180
the same as with documentation,

00:29:38,180 --> 00:29:40,790
that you need to break it down to a level

00:29:40,790 --> 00:29:43,850
and require that the individual stakeholders

00:29:43,850 --> 00:29:47,400
that are working on the code also update this abstraction

00:29:47,400 --> 00:29:49,290
as they make changes to the code?

00:29:49,290 --> 00:29:51,550
And also, do you have any tooling,

00:29:51,550 --> 00:29:53,470
you mentioned those generators,

00:29:53,470 --> 00:29:57,970
to keep the model and the code in sync in both directions?

00:29:57,970 --> 00:30:00,790
- Okay, that would be a development process.

00:30:00,790 --> 00:30:02,900
Developing the model, you should develop

00:30:02,900 --> 00:30:03,973
along with the code.

00:30:05,260 --> 00:30:06,843
- [Audience Member] Yeah, but you can't, you know,

00:30:06,843 --> 00:30:10,073
tell random people to use some Java, whatever tool,

00:30:10,073 --> 00:30:12,810
to model things, you know, with (muffled speaking)

00:30:12,810 --> 00:30:16,340
- Yeah, you need to have a person taking care of it, sure.

00:30:16,340 --> 00:30:18,410
It's like code, you are trying to,

00:30:18,410 --> 00:30:20,900
you are re-describing something that exists.

00:30:20,900 --> 00:30:23,860
You need to take care, a human needs to take care,

00:30:23,860 --> 00:30:28,370
and if the problem happens, you need to update the model.

00:30:28,370 --> 00:30:29,430
Right.

00:30:29,430 --> 00:30:30,350
- [Dmitry] So I think we,

00:30:30,350 --> 00:30:31,800
if we want to keep them in sync,

00:30:31,800 --> 00:30:34,270
we need some kind of debug and config

00:30:34,270 --> 00:30:36,690
that will actually enable this checking at runtime--

00:30:36,690 --> 00:30:37,562
- We will arrive there, yeah.

00:30:37,562 --> 00:30:38,395
- And this should be enabled

00:30:38,395 --> 00:30:40,980
on all of the CI and all of the tests.

00:30:40,980 --> 00:30:45,390
And then the singular one thing that we would like, so,

00:30:45,390 --> 00:30:47,810
one thing we considered doing with syzkaller,

00:30:47,810 --> 00:30:51,280
which is a kernel fuzzer, is having some kind of a model,

00:30:51,280 --> 00:30:52,180
and actually doing the--

00:30:52,180 --> 00:30:54,306
- [Daniel] That's the part I will make questions. This is--

00:30:54,306 --> 00:30:55,739
- We could potentially enable it

00:30:55,739 --> 00:30:57,319
during fuzzing all the time, and--

00:30:57,319 --> 00:31:02,319
- Going to the end, if we were arrived there, right,

00:31:02,560 --> 00:31:04,680
when arriving here you say the question is, okay,

00:31:04,680 --> 00:31:09,680
I'm loading this prototype, it works,

00:31:09,810 --> 00:31:14,810
people at the academic world accepted this

00:31:16,400 --> 00:31:21,400
as reasonable thing, so I'm just not talking to myself,

00:31:24,440 --> 00:31:26,890
so it was verified by experts on the area,

00:31:26,890 --> 00:31:29,070
I will present this work next week

00:31:29,070 --> 00:31:34,070
at the Software Engineering and Formal Methods conference,

00:31:34,150 --> 00:31:37,490
which is very formal methods people,

00:31:37,490 --> 00:31:40,310
so I'm not just talking to myself, right,

00:31:40,310 --> 00:31:42,093
just let's set it clear.

00:31:47,815 --> 00:31:50,330
- I was just thinking from an implementation standpoint,

00:31:50,330 --> 00:31:51,999
you said that you had to collect

00:31:51,999 --> 00:31:53,950
two gigabytes of data or something.

00:31:53,950 --> 00:31:58,950
So something like this could be perfect for doing in-kernel,

00:32:00,330 --> 00:32:02,070
because you really don't need the data

00:32:02,070 --> 00:32:03,997
once you transition the state.

00:32:03,997 --> 00:32:05,820
You can throw away the trace record, right?

00:32:05,820 --> 00:32:08,220
- Okay, now we are making questions

00:32:08,220 --> 00:32:10,220
that I will wait for in the next slides.

00:32:11,520 --> 00:32:12,353
- [Audience Member] Does it also answer

00:32:12,353 --> 00:32:14,010
how long you are measuring?

00:32:14,010 --> 00:32:14,843
- Sorry?

00:32:14,843 --> 00:32:16,570
- Does it also answer how long you are measuring?

00:32:16,570 --> 00:32:19,570
Because otherwise I'd quickly put that question.

00:32:19,570 --> 00:32:22,053
How long do you measure to achieve something?

00:32:23,000 --> 00:32:26,107
- Okay, on the PREEMPT_RT which is the model,

00:32:26,107 --> 00:32:29,290
I'm running it full, it's running,

00:32:29,290 --> 00:32:31,680
and they come trying to find bugs on the kernel

00:32:31,680 --> 00:32:35,193
since two years, one year, it's more than one year.

00:32:36,130 --> 00:32:39,930
But wait, let me finish the...

00:32:39,930 --> 00:32:40,887
- [Audience Member] But wait, there's more!

00:32:40,887 --> 00:32:43,637
(crowd laughing)

00:32:49,454 --> 00:32:53,430
- So, this one simple example,

00:32:53,430 --> 00:32:56,120
this is not a full model, it's just a small model,

00:32:56,120 --> 00:32:58,100
it can be used to describe test cases,

00:32:58,100 --> 00:33:01,940
and this is one test case that I show here the code

00:33:01,940 --> 00:33:04,310
that it ends up translating.

00:33:04,310 --> 00:33:09,310
So, I have one enum that says the states that I have.

00:33:09,340 --> 00:33:12,563
Okay, this is actually automatically generated code, right?

00:33:14,080 --> 00:33:16,890
I have the number of, the set of states,

00:33:16,890 --> 00:33:19,853
and the set of events, like the definition of the automata.

00:33:21,300 --> 00:33:25,830
And here this is used for the bug to translate the enum

00:33:25,830 --> 00:33:28,350
into the name of the states for the bug,

00:33:28,350 --> 00:33:30,290
and this is a matrix that connected,

00:33:30,290 --> 00:33:34,320
that says "Okay, I put all the state transitions here."

00:33:34,320 --> 00:33:36,523
So it's the next byte state and byte event,

00:33:37,770 --> 00:33:40,980
the initial state, and the final state,

00:33:40,980 --> 00:33:43,683
and then it translates to something like this, right?

00:33:44,640 --> 00:33:47,950
So this is the state zero,

00:33:47,950 --> 00:33:50,593
and these are the transitions that I can have.

00:33:52,380 --> 00:33:55,680
So when I get, when I'm processing one event

00:33:55,680 --> 00:33:59,560
that comes from the, I hook it to one event in the kernel,

00:33:59,560 --> 00:34:03,350
and then it passes me the event I am dealing now.

00:34:03,350 --> 00:34:08,280
So, I get the current state and I try to set the next state.

00:34:08,280 --> 00:34:11,260
If the next state is possible, is a valid state,

00:34:11,260 --> 00:34:14,840
like more than zero, I go to the next state and it's done.

00:34:14,840 --> 00:34:17,203
I can print some the bug and it's done.

00:34:18,470 --> 00:34:20,580
And if these are error,

00:34:20,580 --> 00:34:23,890
I can print the error to the trace buffer

00:34:23,890 --> 00:34:25,740
and put the stack trace, for example.

00:34:28,740 --> 00:34:32,320
All that operations that I mentioned are O of one.

00:34:32,320 --> 00:34:37,320
So this is a vector lookup, vector lookup, matrix lookup,

00:34:40,310 --> 00:34:43,020
returning the current state, and setting the next state.

00:34:43,020 --> 00:34:45,460
So all the operations are O of one,

00:34:45,460 --> 00:34:48,770
and that's why we could scale well

00:34:48,770 --> 00:34:50,680
using these kind of abstractions

00:34:50,680 --> 00:34:52,680
for these kind of use cases, right?

00:34:52,680 --> 00:34:54,330
I'm not trying to save the world.

00:34:57,310 --> 00:34:59,563
So, wow, okay, there is no free meal.

00:35:00,530 --> 00:35:04,293
So, I'm using a vector and matrix that are not compact.

00:35:06,140 --> 00:35:10,700
But I tried to use other methods, and in the end,

00:35:11,880 --> 00:35:15,070
even for that model, the PREEMPT_RT model,

00:35:15,070 --> 00:35:17,673
which is a big model, tried to model many things,

00:35:20,410 --> 00:35:23,930
the model compiled was like eight kbytes of data,

00:35:23,930 --> 00:35:25,520
which seems to be acceptable

00:35:26,510 --> 00:35:28,513
for the gains in the performance.

00:35:30,860 --> 00:35:34,470
So how efficient is this idea comparing to other things?

00:35:34,470 --> 00:35:38,053
How much does it affect the system execution, right?

00:35:40,300 --> 00:35:42,460
So I did two benchmarks,

00:35:42,460 --> 00:35:44,780
one about throughput and one about latency.

00:35:44,780 --> 00:35:47,140
I used the Phoronix Test Suite for throughput,

00:35:47,140 --> 00:35:50,270
and cyclictest, which is the PREEMPT_RT testing tool

00:35:50,270 --> 00:35:53,010
that we used to measure the latency, our main metric,

00:35:53,010 --> 00:35:55,740
to see how much it affects the...

00:35:57,510 --> 00:35:59,770
or, our metric, which is very precise,

00:35:59,770 --> 00:36:02,823
it's only a microseconds scale.

00:36:03,660 --> 00:36:06,300
I compared with the kernel as is, doing nothing,

00:36:06,300 --> 00:36:09,400
just running, without any verification or tracing,

00:36:09,400 --> 00:36:12,550
and I did the same experiment with the model,

00:36:12,550 --> 00:36:15,750
one model, and tracing the system.

00:36:15,750 --> 00:36:19,650
Just using tracepoint and ftrace,

00:36:19,650 --> 00:36:22,990
tracing the same events of interest of the model.

00:36:22,990 --> 00:36:24,570
And the good thing about ftrace

00:36:24,570 --> 00:36:26,520
is that we know it performs very well

00:36:26,520 --> 00:36:28,120
and we can use it in production.

00:36:28,120 --> 00:36:29,840
So it's a sample we, even in production,

00:36:29,840 --> 00:36:32,270
the overhead of ftrace,

00:36:32,270 --> 00:36:34,700
when you are doing some kind of verification.

00:36:34,700 --> 00:36:36,930
And I'm just talking about tracing here,

00:36:36,930 --> 00:36:39,230
I'm not doing the verification step,

00:36:39,230 --> 00:36:41,563
just recording the event, same event.

00:36:43,920 --> 00:36:48,920
So, I'm using a simple model here just to illustrate,

00:36:49,680 --> 00:36:53,090
and it explains one case of the PREEMPT_RT

00:36:53,090 --> 00:36:54,860
in which we have a lot of functions

00:36:54,860 --> 00:36:58,220
that might eventually sleep, and that's a problem,

00:36:58,220 --> 00:37:02,020
the scheduling while in atomic problem in the PREEMPT_RT,

00:37:02,020 --> 00:37:06,723
and we cannot call them if we are, what,

00:37:07,750 --> 00:37:12,290
with either preempt or local_irq disabled,

00:37:12,290 --> 00:37:15,390
or with both disabled, right?

00:37:15,390 --> 00:37:17,250
Just an example to take the metrics.

00:37:17,250 --> 00:37:21,650
What matter here is not the size of the model,

00:37:21,650 --> 00:37:24,970
but the set of events, because I go one,

00:37:24,970 --> 00:37:27,513
O of one, per event, right?

00:37:28,820 --> 00:37:32,160
And it was good because I'm using both a hook

00:37:32,160 --> 00:37:34,770
into the function tracer here, to set the functions,

00:37:34,770 --> 00:37:36,270
and hook into tracepoints,

00:37:36,270 --> 00:37:38,570
so I try to exercise two parts of the tracing.

00:37:40,058 --> 00:37:45,058
For low kernel activation benchmarks,

00:37:46,260 --> 00:37:49,450
both the results of the tracing verification are,

00:37:49,450 --> 00:37:52,710
we can see them but they are not that much.

00:37:52,710 --> 00:37:55,790
It sometimes looks like just noise in the experiment,

00:37:55,790 --> 00:37:57,360
which is expected.

00:37:57,360 --> 00:37:59,100
But when we try, obviously,

00:37:59,100 --> 00:38:00,920
when you try to exercise kernel functions,

00:38:00,920 --> 00:38:02,160
we will see more then,

00:38:02,160 --> 00:38:05,040
mainly because the preempt_disable and the local_irq_disable

00:38:05,040 --> 00:38:07,860
are operations they take very often in PREEMPT_RT.

00:38:07,860 --> 00:38:11,840
And we, obviously, we will see some performance draw here.

00:38:11,840 --> 00:38:16,840
But the model, because of the efficiency,

00:38:17,320 --> 00:38:21,530
is using, is adding less overhead than just tracing.

00:38:21,530 --> 00:38:22,940
An the explanation is that tracing,

00:38:22,940 --> 00:38:27,430
we need to save more data to trace buffers,

00:38:27,430 --> 00:38:29,900
and we need to do more operations than just looking up,

00:38:29,900 --> 00:38:33,140
you know, matrix and setting next state,

00:38:33,140 --> 00:38:37,203
and saving it to one char or one integer.

00:38:38,490 --> 00:38:42,620
So, for runtime monitoring

00:38:42,620 --> 00:38:46,630
of the properties that we modeled,

00:38:46,630 --> 00:38:51,630
this is efficient enough to run in production, right?

00:38:51,810 --> 00:38:53,863
As we can enable ftrace in production.

00:38:56,834 --> 00:39:00,040
And another good thing regarding

00:39:00,040 --> 00:39:03,890
using O of one operations and storing low data

00:39:03,890 --> 00:39:08,723
is that here is the cyclictest output, right?

00:39:09,970 --> 00:39:14,360
This is the baseline, the darker blue.

00:39:16,544 --> 00:39:17,973
And this is verification.

00:39:18,860 --> 00:39:20,950
You see that even though we have a shift here,

00:39:20,950 --> 00:39:25,620
which is expected, the line it draws in almost the same way.

00:39:25,620 --> 00:39:28,030
So it actually doesn't change that much

00:39:28,030 --> 00:39:30,340
the behavior of the system.

00:39:30,340 --> 00:39:35,340
So we have, we have the same, almost the same behavior.

00:39:36,555 --> 00:39:41,290
While doing ftrace we can have some changes in the behavior.

00:39:41,290 --> 00:39:42,562
- [Moderator] That was the timer.

00:39:42,562 --> 00:39:43,395
- For?

00:39:43,395 --> 00:39:44,228
- [Moderator] Five minutes remaining.

00:39:44,228 --> 00:39:45,478
- Okay, thanks.

00:39:49,350 --> 00:39:54,040
And as I said, I'm not just talking to myself about it.

00:39:54,040 --> 00:39:55,660
I send this to one of the best

00:39:55,660 --> 00:39:57,920
conference on formal verification,

00:39:57,920 --> 00:40:00,200
the junctions of formal verifications

00:40:00,200 --> 00:40:01,660
and software engineering,

00:40:01,660 --> 00:40:03,960
and it was accepted, I will present next week.

00:40:05,520 --> 00:40:08,330
This added some grains of sorting

00:40:08,330 --> 00:40:09,890
in the model I'm developing.

00:40:09,890 --> 00:40:13,050
But I'm not trying to solve all the problems,

00:40:13,050 --> 00:40:14,250
and that's clear, right?

00:40:16,230 --> 00:40:18,763
So, we have everything here in this page?

00:40:21,000 --> 00:40:23,250
So, what can be next?

00:40:23,250 --> 00:40:25,160
Obviously, what I did so far,

00:40:25,160 --> 00:40:26,700
and that's why I'm on all Plumbers,

00:40:26,700 --> 00:40:29,180
I'm not presenting on product here.

00:40:29,180 --> 00:40:32,470
I'm present an idea that is under development,

00:40:32,470 --> 00:40:34,670
and that's why I'm here asking for feedback.

00:40:36,490 --> 00:40:40,565
So loading a module and trying to do things more manually,

00:40:40,565 --> 00:40:44,683
in practice, if it becomes practical someday,

00:40:45,610 --> 00:40:49,410
it's not that easy, and loading, and keeping things.

00:40:49,410 --> 00:40:54,410
So the idea I talked to Thomas and Peter last year would be

00:40:54,960 --> 00:40:59,740
that to having these models up to date with the kernel,

00:40:59,740 --> 00:41:04,470
we need to use them as test cases for the kernel, right?

00:41:04,470 --> 00:41:07,220
And so while we are changing the kernel,

00:41:07,220 --> 00:41:09,310
we are observing that things are still

00:41:09,310 --> 00:41:11,880
in the way that we desired,

00:41:11,880 --> 00:41:13,680
and then if there is some change in the kernel

00:41:13,680 --> 00:41:16,317
we check if this is a bug or an actual change

00:41:16,317 --> 00:41:19,090
in the model that Linux behaves.

00:41:19,090 --> 00:41:24,090
And now the things that behaves in our older specifications

00:41:24,200 --> 00:41:26,650
needs to be adapted to the new model.

00:41:26,650 --> 00:41:31,650
For example, if I have a deadline scheduler

00:41:31,710 --> 00:41:35,460
that represents all the cases of the PREEMPT_RT,

00:41:35,460 --> 00:41:37,980
and the model changes, and the kernel changes,

00:41:37,980 --> 00:41:39,680
the synchronization changes,

00:41:39,680 --> 00:41:43,280
we would have to change also the model that we used,

00:41:43,280 --> 00:41:47,480
and also the things that depends on that model,

00:41:47,480 --> 00:41:49,670
like when the scheduler implementation.

00:41:49,670 --> 00:41:51,270
So, yes, the idea is

00:41:51,270 --> 00:41:53,800
that the models will adapt with the kernel,

00:41:53,800 --> 00:41:55,770
and that's one of the reasons why we would like

00:41:55,770 --> 00:41:58,513
to have this closer in the same blob of the kernel.

00:42:00,280 --> 00:42:05,280
So, what would be the interface

00:42:05,340 --> 00:42:08,140
that would be better to integrate this,

00:42:08,140 --> 00:42:09,170
would be with perf?

00:42:09,170 --> 00:42:12,633
Would be like a directory into the ftrace, Steven?

00:42:13,830 --> 00:42:18,640
Like, we could generate these models, translate into code,

00:42:18,640 --> 00:42:22,560
and have one interface like we do with a function tracer.

00:42:22,560 --> 00:42:26,350
Would we enable this tracer that verifies or not?

00:42:26,350 --> 00:42:30,830
Or should I use a more perf-like interface using BPF?

00:42:38,510 --> 00:42:42,490
- I would say see how easy it would be,

00:42:42,490 --> 00:42:45,460
or difficult it would be, to use eBPF in perf,

00:42:45,460 --> 00:42:47,090
but basically don't modify anything.

00:42:47,090 --> 00:42:49,230
If you can do everything with that, might as well use it.

00:42:49,230 --> 00:42:53,030
If it becomes too complex, then we can start looking

00:42:53,030 --> 00:42:56,600
at saying maybe we have something custom built

00:42:56,600 --> 00:42:57,680
that could help you do this.

00:42:57,680 --> 00:43:01,030
So I would say first, start to see the complexity

00:43:01,030 --> 00:43:06,030
of using eBPF in perf, but then if you find issues,

00:43:06,370 --> 00:43:08,763
then you have an argument for why.

00:43:09,780 --> 00:43:13,250
If you do the verification interface first,

00:43:13,250 --> 00:43:14,277
the first question someone's gonna ask is

00:43:14,277 --> 00:43:15,640
"Why don't you use eBPF?"

00:43:15,640 --> 00:43:16,473
So do that first.

00:43:16,473 --> 00:43:20,063
- That was my concern as well.

00:43:22,970 --> 00:43:27,640
And the other thing which was the question that were raised,

00:43:27,640 --> 00:43:32,550
is there any other thing that we can model

00:43:32,550 --> 00:43:34,260
and try to take advantage of this.

00:43:34,260 --> 00:43:36,695
For example, we have lockdep,

00:43:36,695 --> 00:43:39,030
but lockdep's not enabled by default

00:43:39,030 --> 00:43:43,640
because it's very heavy, and you cannot,

00:43:43,640 --> 00:43:47,740
even with lockdep enabled, you don't have a way

00:43:47,740 --> 00:43:49,510
to enable and disable it in runtime

00:43:49,510 --> 00:43:51,253
and have it compile in the kernel.

00:43:52,540 --> 00:43:54,840
With the idea of using the trace infrastructure,

00:43:54,840 --> 00:43:57,500
we can have all the modeling outside of the code,

00:43:57,500 --> 00:44:00,140
and only hook our test cases

00:44:00,140 --> 00:44:02,730
into the already existing tracepoints,

00:44:02,730 --> 00:44:04,220
and some tracepoints for this case

00:44:04,220 --> 00:44:07,710
would be even easy to justify, right,

00:44:07,710 --> 00:44:10,883
to enable this kind of verification.

00:44:12,610 --> 00:44:17,310
So this part of my project is trying

00:44:17,310 --> 00:44:20,380
to convince other people to model other parts of the kernel,

00:44:20,380 --> 00:44:24,883
even to justify that my idea that this is good holds, right?

00:44:27,640 --> 00:44:31,380
- So I was wondering why, instead of eBPF or something,

00:44:31,380 --> 00:44:35,190
why not just have the model as a part of the kernel itself?

00:44:35,190 --> 00:44:36,890
Like, I don't know what that'll take,

00:44:36,890 --> 00:44:41,563
but assuming it's an automata state machine kind of thing,

00:44:42,480 --> 00:44:45,280
you can just somehow hard-code

00:44:45,280 --> 00:44:48,470
what that state machine looks like in the kernel itself,

00:44:48,470 --> 00:44:52,210
and then using a config option or something at load time,

00:44:52,210 --> 00:44:53,043
you know, just--

00:44:53,043 --> 00:44:56,360
- But the good thing about having the model as a tracer

00:44:56,360 --> 00:44:58,926
is that you can enable and disable it,

00:44:58,926 --> 00:45:02,676
and not have any overhead of having it there,

00:45:03,614 --> 00:45:06,610
and not having to recompile your kernel

00:45:06,610 --> 00:45:08,160
to enable and disable.

00:45:08,160 --> 00:45:09,210
- [Audience Member] Yeah, that's fine.

00:45:09,210 --> 00:45:11,940
- Yeah, it's more because it gets more dynamic

00:45:11,940 --> 00:45:14,600
if we hook to the trace of things

00:45:14,600 --> 00:45:17,610
than actually having it hard-coded in the kernel.

00:45:17,610 --> 00:45:20,593
And we could update things more easily.

00:45:25,230 --> 00:45:27,710
- Just a comment, an idea,

00:45:27,710 --> 00:45:31,620
maybe some kind of hands-on session or a demo,

00:45:31,620 --> 00:45:35,170
especially for the part where you actually build a model,

00:45:35,170 --> 00:45:37,387
because I think most of the questions were

00:45:37,387 --> 00:45:39,980
"Okay, how hard is it to actually come up with a model?"

00:45:39,980 --> 00:45:43,450
So I guess in my head, maybe convince people to try it.

00:45:43,450 --> 00:45:46,880
- Yeah, I was thinking too, I still didn't have time,

00:45:46,880 --> 00:45:50,930
but one idea was making a set of how-to

00:45:50,930 --> 00:45:55,133
to put on LWN with videos.

00:45:56,140 --> 00:45:58,850
- I was wondering if, and if so how,

00:45:58,850 --> 00:46:01,220
you contextualize your automata.

00:46:01,220 --> 00:46:05,440
For example, you had the open, write, read, close stuff.

00:46:05,440 --> 00:46:09,610
How do you contextualize that for FD, or things like that?

00:46:09,610 --> 00:46:11,330
- Oh, that's a good question, yeah.

00:46:11,330 --> 00:46:14,220
You can have these states associated, just,

00:46:14,220 --> 00:46:16,692
no, wait, wait, wait, wait, just to--

00:46:16,692 --> 00:46:17,770
(crowd laughing)

00:46:17,770 --> 00:46:19,760
Just to see if I got the question, right?

00:46:19,760 --> 00:46:22,400
Yes, a model has a context,

00:46:22,400 --> 00:46:26,200
like the PREEMPT_RT model was for, per one task,

00:46:26,200 --> 00:46:28,030
each task would follow the model.

00:46:28,030 --> 00:46:30,600
Actually, I'm translating it now to be per CPU,

00:46:30,600 --> 00:46:32,660
to check the states of the CPU,

00:46:32,660 --> 00:46:36,560
because it would be more efficient, would be better.

00:46:36,560 --> 00:46:38,180
But there should be cases

00:46:38,180 --> 00:46:39,660
in which the model would represent

00:46:39,660 --> 00:46:42,160
the state of one file descriptor.

00:46:42,160 --> 00:46:43,850
Then you would have to have

00:46:43,850 --> 00:46:46,980
each file descriptor its own model,

00:46:46,980 --> 00:46:49,110
and then you need to find a way to store it,

00:46:49,110 --> 00:46:52,481
you can store this in a kernel module,

00:46:52,481 --> 00:46:54,200
do not confuse with model,

00:46:54,200 --> 00:46:58,100
and have a hash table of file descriptor and try to find it,

00:46:58,100 --> 00:47:00,860
or if this get good enough you might convince someone

00:47:00,860 --> 00:47:05,860
to have on entry in the definition of the file descriptor.

00:47:07,290 --> 00:47:11,200
But yes, you have, we have different levels of,

00:47:11,200 --> 00:47:14,520
we can have different levels of object that we are modeling.

00:47:14,520 --> 00:47:16,520
And it can be a file descriptor,

00:47:16,520 --> 00:47:19,393
a lock, or a CPU, or a task.

00:47:22,850 --> 00:47:24,580
- [Moderator] So, you've gone past 6:30,

00:47:24,580 --> 00:47:27,440
but feel free to keep asking questions, if anyone has them,

00:47:27,440 --> 00:47:31,123
but if you wanted to go to another talk in another,

00:47:32,530 --> 00:47:34,520
there's like one or two mini-confs still going,

00:47:34,520 --> 00:47:36,530
so just be aware that it's past 6:30,

00:47:36,530 --> 00:47:39,010
otherwise if anyone has any more questions,

00:47:39,010 --> 00:47:41,200
I will throw you the, ah, you've got one there.

00:47:41,200 --> 00:47:44,900
- Yeah, I was just wondering, kind of goes with the context.

00:47:44,900 --> 00:47:48,400
So you're running, you're loading the modules

00:47:48,400 --> 00:47:51,350
on the running system, so how do you know

00:47:51,350 --> 00:47:55,310
when you can reach an initial state of the automata?

00:47:55,310 --> 00:47:58,163
- Yeah, you need to wait for the initial state, okay,

00:47:59,140 --> 00:48:02,320
but then you need to watch the events, and try to see,

00:48:02,320 --> 00:48:05,830
for example, these here, oops...

00:48:15,840 --> 00:48:17,750
These here I was waiting

00:48:17,750 --> 00:48:22,250
for the preemption and IRQs to be enabled,

00:48:22,250 --> 00:48:25,730
and then I can hook both cases,

00:48:25,730 --> 00:48:29,030
and saw "Okay, is it disabled and is it disabled?"

00:48:29,030 --> 00:48:30,770
And I wait for this condition,

00:48:30,770 --> 00:48:33,730
and then I was sure that I was in initial state,

00:48:33,730 --> 00:48:35,460
and then starting to trace.

00:48:35,460 --> 00:48:37,710
Yes, but you need to wait for this condition.

00:48:39,910 --> 00:48:41,540
- [Audience Member] Now that you mentioned initial state,

00:48:41,540 --> 00:48:44,090
does the acceptance state have any special meaning?

00:48:46,492 --> 00:48:48,580
- Is the, I mean, could you...

00:48:48,580 --> 00:48:51,283
- Does the accepting state have any special meaning?

00:48:53,280 --> 00:48:55,970
Like the one with the two circles

00:48:55,970 --> 00:48:56,803
compared to the ones with the single circle.

00:48:56,803 --> 00:48:58,530
- Oh, yeah, yeah, yeah, this is the final state.

00:48:58,530 --> 00:49:00,670
- [Audience Member] Yeah, but what meaning does it have?

00:49:00,670 --> 00:49:02,850
- It means that is a safe state,

00:49:02,850 --> 00:49:04,943
where you can restart the system.

00:49:06,640 --> 00:49:08,390
And then you can conclude that

00:49:08,390 --> 00:49:10,873
if you cannot return to the initial state,

00:49:11,710 --> 00:49:14,220
you have a deadlock or a livelock in your,

00:49:14,220 --> 00:49:16,290
these are the kind of conclusions you can derive

00:49:16,290 --> 00:49:17,720
from such a condition.

00:49:17,720 --> 00:49:18,900
If it's live,

00:49:18,900 --> 00:49:22,980
from each state it can return to the initial state,

00:49:22,980 --> 00:49:26,038
and then you don't have livelocks.

00:49:26,038 --> 00:49:29,300
(muffled speaking)

00:49:29,300 --> 00:49:30,133
- [Audience Member] Sometimes you don't know

00:49:30,133 --> 00:49:32,400
how much to wait, right, depends on the algorithm?

00:49:32,400 --> 00:49:34,280
- Yeah, you need to find, this is a problem,

00:49:34,280 --> 00:49:37,510
you need to wait for the initial condition, you need to...

00:49:41,231 --> 00:49:43,981
(crowd laughing)

00:49:44,860 --> 00:49:49,000
- Yeah, so, just to be sure, right, on the,

00:49:49,000 --> 00:49:52,300
because you are at the formal conference,

00:49:52,300 --> 00:49:54,740
Formal Methods conference next week,

00:49:54,740 --> 00:49:56,820
if you have this kind of case where you say

00:49:56,820 --> 00:49:59,440
you have to return to a certain state,

00:49:59,440 --> 00:50:02,070
then it's actually not finite automata

00:50:02,070 --> 00:50:04,120
but it's discrete automata.

00:50:04,120 --> 00:50:08,230
So there are automata types on infinite words,

00:50:08,230 --> 00:50:12,527
and there you have an acceptance condition where you say

00:50:12,527 --> 00:50:16,150
"I have to always, in an infinite word,

00:50:16,150 --> 00:50:20,117
I have to be finitely often in a certain state."

00:50:21,370 --> 00:50:22,690
So just that you know, right,

00:50:22,690 --> 00:50:24,327
because it's not a finite automata you're talking about--

00:50:24,327 --> 00:50:26,483
- That's the basis for automata, yeah.

00:50:27,780 --> 00:50:28,613
Good, thanks.

00:50:33,353 --> 00:50:36,270
(muffled speaking)

00:50:39,350 --> 00:50:42,450
- So, you said if you do not make it back

00:50:42,450 --> 00:50:45,350
to the start state at some point, then you can conclude

00:50:45,350 --> 00:50:47,210
that you have a deadlock or a livelock?

00:50:47,210 --> 00:50:49,970
- Okay, in the reasoning in the model.

00:50:49,970 --> 00:50:51,390
- [Audience Member] Right.

00:50:51,390 --> 00:50:52,223
- Oh, yeah, and then most of--

00:50:52,223 --> 00:50:53,688
- For a livelock, isn't there a temporal

00:50:53,688 --> 00:50:56,900
or iteration count component?

00:50:56,900 --> 00:50:57,950
Is that how you decide?

00:50:57,950 --> 00:51:01,160
- Okay, that would be an extension

00:51:01,160 --> 00:51:04,490
to the type of automata that I'm using.

00:51:04,490 --> 00:51:06,390
Now I'm using the automata doesn't count,

00:51:06,390 --> 00:51:09,510
which is the more simple automata,

00:51:09,510 --> 00:51:12,310
which is the one that blocks me less

00:51:12,310 --> 00:51:15,480
for using other extensions of automatas.

00:51:15,480 --> 00:51:16,960
But there are parametric automata

00:51:16,960 --> 00:51:19,180
where you can put counters.

00:51:19,180 --> 00:51:21,407
- So at that point you could classify something

00:51:21,407 --> 00:51:25,594
"Yes, this is a livelock, we've been here this many times."

00:51:25,594 --> 00:51:26,710
- Yeah, and then you have

00:51:26,710 --> 00:51:29,963
more ways to express our conditions.

00:51:30,865 --> 00:51:33,521
But I decided to use more simple automatas

00:51:33,521 --> 00:51:35,510
at the beginning of the modeling,

00:51:35,510 --> 00:51:39,560
because I can then use the more specific cases.

00:51:39,560 --> 00:51:41,860
In the other way a round loop would be harder.

00:51:43,830 --> 00:51:45,900
- [Audience Member] So if you introduce counters,

00:51:45,900 --> 00:51:49,030
can you still apply your formal verification techniques

00:51:49,030 --> 00:51:50,740
done on this extended automata?

00:51:50,740 --> 00:51:52,133
- That's a future work.

00:51:53,270 --> 00:51:55,940
- [Audience Member] And does the accepting state always need

00:51:55,940 --> 00:51:57,910
to coincide with the initial state?

00:51:57,910 --> 00:51:58,743
- Not necessarily.

00:51:58,743 --> 00:51:59,810
- [Audience Member] Or can be different state,

00:51:59,810 --> 00:52:01,890
can have more than one acceptor?

00:52:01,890 --> 00:52:02,760
- Yes, there can be.

00:52:02,760 --> 00:52:06,250
Depends on the thing that you're model, but it's possible.

00:52:06,250 --> 00:52:10,100
There is just one initial state in the automata definition,

00:52:10,100 --> 00:52:11,490
but there can be more than one

00:52:11,490 --> 00:52:14,170
and that's why it's a set of initial states,

00:52:14,170 --> 00:52:15,520
set of final states, sorry.

00:52:19,265 --> 00:52:21,270
Like, for example, here, it's a set of final states,

00:52:21,270 --> 00:52:22,103
do the first--

00:52:22,103 --> 00:52:23,580
- [Audience Member] Like in the standard definition.

00:52:23,580 --> 00:52:24,413
- Yeah.

00:52:26,190 --> 00:52:27,023
- Have you thought about

00:52:27,023 --> 00:52:28,763
how you might be able to extend this

00:52:28,763 --> 00:52:31,540
for situations where you have multiple state machines,

00:52:31,540 --> 00:52:32,373
and you need to reason

00:52:32,373 --> 00:52:34,520
about their concurrent interactions between them?

00:52:34,520 --> 00:52:37,170
So for example, if one has to synchronize with another,

00:52:37,170 --> 00:52:38,180
then you probably can't just rely

00:52:38,180 --> 00:52:40,130
on things like timestamps for that.

00:52:40,130 --> 00:52:44,120
- Okay. The idea here is that you have

00:52:44,120 --> 00:52:46,070
all the interactions in a single model.

00:52:48,630 --> 00:52:51,660
Even if, you need to be able to express

00:52:51,660 --> 00:52:54,020
even the concurrence in a single model.

00:52:54,020 --> 00:52:55,120
- How would you get that,

00:52:55,120 --> 00:52:59,700
how would you verify that with the task tracepoints though?

00:52:59,700 --> 00:53:01,320
You'd need sort of concurrent tracepoints

00:53:01,320 --> 00:53:03,873
to assert concurrent assertions.

00:53:04,730 --> 00:53:05,985
Like, for example, you'd need to know

00:53:05,985 --> 00:53:06,970
when certain synchronized,

00:53:06,970 --> 00:53:08,390
I don't know how you would do that, that was all.

00:53:08,390 --> 00:53:11,540
- Okay. In these crit event systems,

00:53:11,540 --> 00:53:16,540
it assumes that the events are take one after the other

00:53:17,200 --> 00:53:19,100
in this crit time.

00:53:19,100 --> 00:53:23,070
So the automata cannot describe two

00:53:23,070 --> 00:53:28,010
that occurred exactly at the same nanosecond.

00:53:28,010 --> 00:53:32,250
But you can describe before or after, right?

00:53:32,250 --> 00:53:37,250
But when you are thinking about the concurrence of one task,

00:53:37,560 --> 00:53:40,700
and the states of one task, you'd hardly have,

00:53:40,700 --> 00:53:42,893
you not have one are after the other.

00:53:45,960 --> 00:53:47,020
And exactly the same time,

00:53:47,020 --> 00:53:49,280
you need to find out maybe other abstractions

00:53:49,280 --> 00:53:54,023
or try to assume all the cases, even before or after.

00:53:54,934 --> 00:53:57,640
In the end, if you have such interaction in kernel,

00:53:57,640 --> 00:54:01,420
you need some kind of synchronization mechanism to do it.

00:54:01,420 --> 00:54:03,200
- I mean, there are some cases,

00:54:03,200 --> 00:54:05,190
for example, where, and it's quite unusual,

00:54:05,190 --> 00:54:07,710
I think Paul McKenney's responsible for most of it, that,

00:54:07,710 --> 00:54:09,990
where you may have two threads storing to the same variable,

00:54:09,990 --> 00:54:11,930
and one of them will overwrite the other variable,

00:54:11,930 --> 00:54:14,040
and neither of them know which one won,

00:54:14,040 --> 00:54:16,150
but you can use that property

00:54:16,150 --> 00:54:19,290
to assert something happens later on.

00:54:19,290 --> 00:54:21,994
- But if one wrote after the other,

00:54:21,994 --> 00:54:24,133
they didn't happen at same time.

00:54:25,400 --> 00:54:26,830
- My point is more that

00:54:26,830 --> 00:54:28,750
you can't tell which order they wrote in

00:54:28,750 --> 00:54:30,080
unless you read the thing back,

00:54:30,080 --> 00:54:31,170
and then you're gonna be introducing

00:54:31,170 --> 00:54:33,434
quite a lot of overhead to your tracepoints.

00:54:33,434 --> 00:54:37,030
- But then if you wanted to, okay, this is one point.

00:54:37,030 --> 00:54:40,340
If you wanted to do this kind of analysis,

00:54:40,340 --> 00:54:42,770
you need to trace the operation of the two,

00:54:42,770 --> 00:54:46,513
and so you would see them taking place, right?

00:54:47,920 --> 00:54:49,070
- Right, but the order in the trace

00:54:49,070 --> 00:54:51,030
might not be the order of the writes, that's the problem.

00:54:51,030 --> 00:54:52,040
So you need to somehow,

00:54:52,040 --> 00:54:54,800
you somehow need to relate the trace to the memory model,

00:54:54,800 --> 00:54:56,192
I think that's what I'm trying to say.

00:54:56,192 --> 00:54:57,826
And that's really exciting,

00:54:57,826 --> 00:55:00,101
but I don't know how you'd do it.

00:55:00,101 --> 00:55:02,177
- Yeah, we reached to this point,

00:55:02,177 --> 00:55:03,510
and these are advanced points

00:55:03,510 --> 00:55:05,913
that we might find problems and, yeah.

00:55:10,831 --> 00:55:13,650
- Yeah, so I was, as I understand it,

00:55:13,650 --> 00:55:17,560
all these events between the states are all function calls?

00:55:17,560 --> 00:55:20,560
But, I presume, you could get into bad states

00:55:20,560 --> 00:55:24,030
by assigning variables to, you know.

00:55:24,030 --> 00:55:27,300
- Yeah, but then then, these, that's why these work,

00:55:27,300 --> 00:55:31,890
this kind of modeling works only when you can,

00:55:31,890 --> 00:55:34,520
when you have the event you want to observe.

00:55:34,520 --> 00:55:36,083
This is not for other cases.

00:55:37,000 --> 00:55:37,940
- Yeah, I was just wondering

00:55:37,940 --> 00:55:39,400
if you'd thought about that at all,

00:55:39,400 --> 00:55:42,780
how you could possibly model other things

00:55:42,780 --> 00:55:43,613
other than function calls.

00:55:43,613 --> 00:55:44,970
- You would have to put a tracepoint write

00:55:44,970 --> 00:55:48,330
into that place to be able to monitor.

00:55:48,330 --> 00:55:51,670
So this is for the event that we can have on the kernel.

00:55:51,670 --> 00:55:53,077
Yeah, you would have to added

00:55:53,077 --> 00:55:56,667
the one event writing to that memory,

00:55:58,660 --> 00:56:00,693
and then to monitor it.

00:56:03,090 --> 00:56:03,923
Yeah.

00:56:06,180 --> 00:56:07,860
- I have a question.

00:56:07,860 --> 00:56:11,300
So, all the state diagram you're describing

00:56:11,300 --> 00:56:15,100
is just for one CPU, right?

00:56:15,100 --> 00:56:16,970
- No, you, you-- - You have multiple CPU,

00:56:16,970 --> 00:56:19,790
you have different CPU at different state,

00:56:19,790 --> 00:56:20,633
and there will be interaction between them.

00:56:20,633 --> 00:56:23,110
- Yeah, and then you can have,

00:56:23,110 --> 00:56:28,110
you need to have a global model that would hook to the,

00:56:29,000 --> 00:56:31,930
that's the question that he asked,

00:56:31,930 --> 00:56:33,830
you can have a per CPU model,

00:56:33,830 --> 00:56:35,380
and then you can have a global model.

00:56:35,380 --> 00:56:36,980
The difference between the per CPU model

00:56:36,980 --> 00:56:39,950
is that I will only try to move the states

00:56:39,950 --> 00:56:41,800
if I'm taking place on the CPU.

00:56:41,800 --> 00:56:43,420
If I have a global model,

00:56:43,420 --> 00:56:46,490
I will try to move the automata

00:56:47,680 --> 00:56:51,560
with the events from all the models.

00:56:51,560 --> 00:56:55,030
If I have a per file, only the events from that file.

00:56:55,030 --> 00:56:56,880
And then we need to filter this case.

00:56:58,430 --> 00:57:02,220
But it's possible to express global models

00:57:02,220 --> 00:57:03,893
using the automata.

00:57:05,890 --> 00:57:09,873
- It only changes the way that you model your system.

00:57:13,730 --> 00:57:17,470
- Have you considered or tested

00:57:17,470 --> 00:57:19,810
whether expressing your generators

00:57:19,810 --> 00:57:22,810
in temporal logics, LTL, whatever,

00:57:22,810 --> 00:57:25,500
works maybe better for some of the,

00:57:25,500 --> 00:57:29,040
especially for programmers who maybe don't know

00:57:29,040 --> 00:57:31,120
how to write dot files?

00:57:31,120 --> 00:57:32,210
- [Daniel] Well, could you--

00:57:32,210 --> 00:57:36,920
- Like, temporal logics is a way to express

00:57:36,920 --> 00:57:39,590
simple automata that you can test against other automata,

00:57:39,590 --> 00:57:41,660
and you could maybe use those

00:57:41,660 --> 00:57:44,470
in place of your graphical automata

00:57:44,470 --> 00:57:49,000
in order to write the expectations against the system.

00:57:49,000 --> 00:57:49,833
- Yes, yes.

00:57:49,833 --> 00:57:51,438
- [Audience Member] And use that for generating your--

00:57:51,438 --> 00:57:53,347
- Yeah, specifications, yeah.

00:57:53,347 --> 00:57:54,940
But there should be a way

00:57:54,940 --> 00:57:57,200
to express the same thing with the generators,

00:57:57,200 --> 00:57:59,760
because if you can translate that idea to automata,

00:57:59,760 --> 00:58:03,000
you can translate to the graphical format.

00:58:03,000 --> 00:58:04,700
But it doesn't matter if you write

00:58:04,700 --> 00:58:08,180
in the graphical format or in the automata format

00:58:08,180 --> 00:58:10,920
because they are interchangeable, right?

00:58:10,920 --> 00:58:13,810
- My proposal is to use maybe, well,

00:58:13,810 --> 00:58:17,950
my question was whether you assessed if temporal logics

00:58:17,950 --> 00:58:22,080
were a suitable representation for your generators

00:58:22,080 --> 00:58:23,330
that might have more acceptance with your community.

00:58:23,330 --> 00:58:24,660
- No, I didn't.

00:58:24,660 --> 00:58:27,920
We need to sit down and try to understand the temporal,

00:58:27,920 --> 00:58:30,513
how do you model things in temporal logic.

00:58:35,910 --> 00:58:40,470
- So if you augmented your states with timing information

00:58:40,470 --> 00:58:43,270
so that you can measure the distance,

00:58:43,270 --> 00:58:44,500
the temporal distance between events,

00:58:44,500 --> 00:58:46,390
would you say that's a good idea then

00:58:46,390 --> 00:58:49,750
to come up with a worst case execution time estimates

00:58:49,750 --> 00:58:50,583
by calculating longest pause?

00:58:50,583 --> 00:58:52,450
- Okay, that's often, it is very used

00:58:52,450 --> 00:58:54,080
in the realtime academic world,

00:58:54,080 --> 00:58:57,830
which is representing the system as a timed automata.

00:58:57,830 --> 00:58:59,640
Yeah, that's why I use

00:58:59,640 --> 00:59:02,110
the most simple case of automata first,

00:59:02,110 --> 00:59:06,360
because later it can extend to use other kind of automatas,

00:59:06,360 --> 00:59:09,800
which are the timed automata, the parametric automata,

00:59:09,800 --> 00:59:12,600
but these are all things that we still need to develop.

00:59:12,600 --> 00:59:14,030
It's in the early stage,

00:59:14,030 --> 00:59:16,580
but I tried to take care of using the tools

00:59:16,580 --> 00:59:19,930
that would allow me to go forward.

00:59:19,930 --> 00:59:22,410
Cause sometimes if you do timed automata first, you cannot,

00:59:22,410 --> 00:59:25,133
it's hard to get backwards and try other things.

00:59:26,050 --> 00:59:29,480
- Well, this is not a question, but a comment.

00:59:29,480 --> 00:59:33,260
Arnaldo, today, in his presentation about eBPF and perf,

00:59:33,260 --> 00:59:38,260
he was talking about the plans to use the Intel PT,

00:59:38,690 --> 00:59:42,480
the hardware tracers, and the interaction,

00:59:42,480 --> 00:59:44,620
to create the events for perf.

00:59:44,620 --> 00:59:49,620
So the amount of events that you can use in your automata

00:59:50,810 --> 00:59:54,970
will grow significantly, and it maybe help you to do things

00:59:54,970 --> 00:59:58,960
that you wanted to do, that maybe related to memory address

00:59:58,960 --> 01:00:02,040
or to access to assess a certain variable.

01:00:02,040 --> 01:00:06,200
So that is something that soon may be possible.

01:00:06,200 --> 01:00:09,440
- Yeah, that's why it's good to rely on the trace things,

01:00:09,440 --> 01:00:12,240
because they are evolving and we will have

01:00:12,240 --> 01:00:15,483
more and more and more possibilities of tracing things.

01:00:19,340 --> 01:00:23,200
- Have you thought about whether there could be things

01:00:23,200 --> 01:00:26,985
that we as contributors and maintainers could do

01:00:26,985 --> 01:00:31,160
in the Linux kernel source code to facilitate, for one,

01:00:31,160 --> 01:00:34,390
generation of models, or verification of models?

01:00:34,390 --> 01:00:38,040
Like, have you thought about any form of macros

01:00:38,040 --> 01:00:41,400
to annotate state variables or anything like that?

01:00:41,400 --> 01:00:46,400
- Yeah, I think that the demand for new events

01:00:46,600 --> 01:00:48,873
or to know that something happened,

01:00:49,900 --> 01:00:53,030
they will take place during the development of the model.

01:00:53,030 --> 01:00:58,030
And then we have one very specific case of a maintainer

01:00:59,670 --> 01:01:02,580
that doesn't likes tracepoints, for example,

01:01:02,580 --> 01:01:04,330
which is something that we hook,

01:01:04,330 --> 01:01:06,383
and this person is Peter Zijlstra.

01:01:10,250 --> 01:01:12,840
- [Audience Member] Well actually that's changing, now it's,

01:01:12,840 --> 01:01:14,970
he hates trace events, not tracepoints.

01:01:14,970 --> 01:01:19,100
- Yeah, that's where we will arrive.

01:01:19,100 --> 01:01:23,040
So I had a long time discussion with Peter

01:01:23,040 --> 01:01:27,710
for having traces for these cat deadline, right,

01:01:27,710 --> 01:01:32,427
and last year I think it was in the LPC,

01:01:33,345 --> 01:01:35,710
we got him the acceptance

01:01:35,710 --> 01:01:40,710
that we can add the trace events to the kernel,

01:01:40,820 --> 01:01:41,880
but not tracepoints.

01:01:41,880 --> 01:01:44,868
The difference that trace event--

01:01:44,868 --> 01:01:45,701
- [Audience Member] The other way.

01:01:45,701 --> 01:01:47,380
- Oh, the other way around, okay.

01:01:47,380 --> 01:01:50,267
We can have tracepoints as long as we don't export

01:01:50,267 --> 01:01:53,340
the trace event interface for userspace.

01:01:53,340 --> 01:01:57,490
So, the idea is that if we don't export userspace

01:01:57,490 --> 01:02:00,560
we can get rid of it when we don't need it anymore,

01:02:00,560 --> 01:02:05,223
so we can add the tracepoints to the kernel as,

01:02:06,860 --> 01:02:09,360
on demand, when we need it,

01:02:09,360 --> 01:02:12,193
and try to convince the maintainer with this argument.

01:02:13,340 --> 01:02:16,010
- [Audience Member] Daniel, I have a question, so--

01:02:16,010 --> 01:02:17,200
- [Audience Member] Um--

01:02:17,200 --> 01:02:18,040
- Yeah--

01:02:18,040 --> 01:02:18,873
- Sorry.

01:02:19,870 --> 01:02:24,470
So that are a trace event after we record

01:02:24,470 --> 01:02:28,180
that some are passed some argument,

01:02:28,180 --> 01:02:31,330
but the tracepoint does not, so that I doubted,

01:02:31,330 --> 01:02:36,050
I think that's a big difference, which one would you need?

01:02:36,050 --> 01:02:39,760
It seems that just using that tracepoint,

01:02:39,760 --> 01:02:42,503
or trace event you need?

01:02:43,400 --> 01:02:45,713
- Okay, I'm hooking to the tracepoint,

01:02:47,090 --> 01:02:50,040
to the tracepoint and not--

01:02:50,040 --> 01:02:54,261
- So that are just are the, let's see, are the passed,

01:02:54,261 --> 01:02:57,630
execution pass seeds or the materials for--

01:02:57,630 --> 01:02:59,950
- [Daniel] Just wait, give me one, close the door,

01:02:59,950 --> 01:03:02,400
because there is come in the noise and I'm not...

01:03:04,050 --> 01:03:08,513
- So that are the event point, you know, are the other,

01:03:09,720 --> 01:03:12,733
what happened is are the materials?

01:03:15,000 --> 01:03:17,120
- I didn't, sorry, didn't get the--

01:03:17,120 --> 01:03:22,120
- So that are, I think that that one is there just using,

01:03:22,656 --> 01:03:26,875
changing that are the state machine, machine state,

01:03:26,875 --> 01:03:31,013
by your, what's it, by the event,

01:03:31,960 --> 01:03:33,520
so those are tracepoint,

01:03:34,709 --> 01:03:39,709
and it doesn't check that the event was a argument,

01:03:41,980 --> 01:03:43,563
or something--

01:03:43,563 --> 01:03:47,249
(muffled speaking)

01:03:47,249 --> 01:03:50,577
- Okay, I'm just using one event to,

01:03:50,577 --> 01:03:52,207
I'm just analyzing one event,

01:03:52,207 --> 01:03:55,010
and not the content of that event, right?

01:03:55,010 --> 01:03:56,380
Is that the point?

01:03:56,380 --> 01:04:01,290
Okay, so, if we had parametric automata,

01:04:01,290 --> 01:04:03,523
we could do the checks in the automata.

01:04:04,890 --> 01:04:07,650
In the current mode of automata I'm doing,

01:04:07,650 --> 01:04:11,830
I need to decide which automata event fire

01:04:11,830 --> 01:04:16,830
based on the data that I can get in the tracepoint, right?

01:04:18,930 --> 01:04:21,890
And then I move to plexing one possible kernel event

01:04:21,890 --> 01:04:26,350
into different automata events in the code there.

01:04:26,350 --> 01:04:31,350
But, and if when, if all these idea justifies

01:04:32,610 --> 01:04:35,080
continuing developing this,

01:04:35,080 --> 01:04:37,910
and if we need to use the timed automata,

01:04:37,910 --> 01:04:40,490
we could decide it in the automata itself

01:04:40,490 --> 01:04:42,770
by passing the parameters, and passing the data

01:04:42,770 --> 01:04:43,753
of the tracepoint, tracepoint, yeah.

01:04:50,649 --> 01:04:54,190
(muffled speaking)

01:04:54,190 --> 01:04:57,640
- About tracepoints, so you can actually passed arguments,

01:04:57,640 --> 01:05:00,130
as you would do with a simple function call.

01:05:00,130 --> 01:05:01,383
So you can pass data.

01:05:01,383 --> 01:05:05,890
It's just that it is not exposed to userspace

01:05:05,890 --> 01:05:08,000
in a fixed layout, so this is the only difference,

01:05:08,000 --> 01:05:09,220
but you can pass arguments.

01:05:09,220 --> 01:05:12,100
- Yeah, yeah, the other, when we hook to a tracepoint

01:05:12,100 --> 01:05:13,670
you need to make a function

01:05:13,670 --> 01:05:16,770
that receives the same arguments of the tracepoint.

01:05:16,770 --> 01:05:20,480
So I receive the same thing that the tracer would receive,

01:05:20,480 --> 01:05:22,070
and then I can do the same manipulations

01:05:22,070 --> 01:05:24,870
that the trace would, could do.

01:05:24,870 --> 01:05:28,430
Yeah, the information is available for me inside as well.

01:05:28,430 --> 01:05:30,790
The only point is that it's not exposed to userspace,

01:05:30,790 --> 01:05:33,983
so no user can use it, just a module.

01:05:35,810 --> 01:05:37,740
- Can I ask a question?

01:05:37,740 --> 01:05:40,810
So I was wondering how hard, how weird,

01:05:40,810 --> 01:05:43,767
would a model look that actually had events

01:05:43,767 --> 01:05:48,767
and like, interrupts, and non-interrupt contexts,

01:05:48,830 --> 01:05:51,970
so you have like, A and B in process contexts,

01:05:51,970 --> 01:05:55,000
and then interrupt, have other events,

01:05:55,000 --> 01:05:57,210
and so you have to somehow join all of them.

01:05:57,210 --> 01:06:02,210
So, then you'll have back-and-forth between all the states,

01:06:02,670 --> 01:06:05,263
between the two contexts, is that gonna be hard?

01:06:05,263 --> 01:06:07,800
Because something like, for example, RCU,

01:06:07,800 --> 01:06:09,780
that's very common to have.

01:06:09,780 --> 01:06:12,280
- Yeah, that is actually the case

01:06:12,280 --> 01:06:15,227
that we got a problem in the ftrace,

01:06:17,095 --> 01:06:22,095
in the tracepoints code, on the preempt_disable tracepoint.

01:06:24,610 --> 01:06:28,230
Because, okay, when we are running,

01:06:28,230 --> 01:06:30,583
we assume that the event took place,

01:06:33,990 --> 01:06:37,870
but actually the hit of the event and the event itself,

01:06:37,870 --> 01:06:40,100
they take place on different timings.

01:06:40,100 --> 01:06:43,160
And so we need to synchronize both.

01:06:43,160 --> 01:06:47,440
So to create the idea that this was one atomic operation,

01:06:47,440 --> 01:06:51,820
the real event and the event we are tracing itself.

01:06:51,820 --> 01:06:54,410
Generally, and this is one case

01:06:54,410 --> 01:06:57,100
where the interrupts can add noise,

01:06:57,100 --> 01:07:01,240
because I disabled the preemption counter,

01:07:01,240 --> 01:07:03,640
and then I would bring to the tracepoint.

01:07:03,640 --> 01:07:06,110
I can have an interrupt here,

01:07:06,110 --> 01:07:08,540
and this can, and in my next tracepoint

01:07:08,540 --> 01:07:12,530
that can disable interrupt here, will not fire.

01:07:12,530 --> 01:07:17,210
That's actually this case here, right?

01:07:17,210 --> 01:07:21,893
This is one case in which the interrupt messed up the event.

01:07:23,610 --> 01:07:28,610
So yes, but this is not a problem of the way I'm checking,

01:07:28,680 --> 01:07:32,290
but the consistency in the trace subsystem,

01:07:32,290 --> 01:07:36,920
that we need to have the real event, and the trace event,

01:07:36,920 --> 01:07:40,280
or trace point of that event, synchronized.

01:07:40,280 --> 01:07:43,590
They are generally synchronized already,

01:07:43,590 --> 01:07:47,510
because, for example, when you're dealing with a scheduler,

01:07:47,510 --> 01:07:50,900
you need to take the locks of the scheduler,

01:07:50,900 --> 01:07:55,150
and then for example, you will not have a reentrance

01:07:55,150 --> 01:07:57,890
in the scheduler code to mess up with the event.

01:07:57,890 --> 01:08:02,707
And as the scheduler data can be manipulated in interrupt,

01:08:03,850 --> 01:08:06,850
interrupts are disabled, so generally there is

01:08:06,850 --> 01:08:10,200
a natural synchronization between both events.

01:08:10,200 --> 01:08:13,550
But there are cases in which we need to enforce this.

01:08:13,550 --> 01:08:15,900
And that's the case that we had in this problem

01:08:17,522 --> 01:08:22,057
with the tracepoints, that we had to enforce here the...

01:08:24,020 --> 01:08:25,630
- Yeah, so it's not as cash hot

01:08:25,630 --> 01:08:28,180
as it was when I wanted to reply, just,

01:08:28,180 --> 01:08:30,600
back on the tracepoint versus trace event thing,

01:08:30,600 --> 01:08:32,010
the problem is not necessarily as

01:08:32,010 --> 01:08:33,033
having that exposed to userspace,

01:08:33,033 --> 01:08:35,790
it's just not having the format of the event

01:08:35,790 --> 01:08:37,360
committed in the kernel.

01:08:37,360 --> 01:08:39,130
By having just a tracepoint you force people

01:08:39,130 --> 01:08:40,537
who want to have the trace events

01:08:40,537 --> 01:08:43,210
to write their own modules, but then it's not API,

01:08:43,210 --> 01:08:45,467
it's their modules, and just, yeah.

01:08:50,760 --> 01:08:52,760
- [Moderator] Okay, any more questions?

01:08:52,760 --> 01:08:56,657
Going once, going twice, thank you very much to Daniel!

01:08:56,657 --> 01:08:58,907

YouTube URL: https://www.youtube.com/watch?v=5ZPVPkR-aW4


