Title: LPC2019 - Utilizing tools made for "Big Data" to analyse Ftrace data - making it fast and easy
Publication date: 2019-11-18
Playlist: LPC2019 - LPC Main Track
Description: 
	Utilizing tools made for "Big Data" to analyse Ftrace data - making it fast and easy

Speaker
 Yordan Karadzhov (VMware)

Description
Tools based on low level tracing tend to generate large amounts of data, typically outputted in some kind of text or binary format. On the other hand the predefined data analysis features of those tools are often useless when it comes to solving a nontrivial or very user-specific problem. This is when the possibility to make sophisticated analysis via scripting can be extremely useful.

Fast and easy scripting inside the tracing data is possible if we take advantage of the already existing infrastructure, originally developed for the purposes of the "Big Data" and ML industries. A PoC interface for accessing Ftrace data in Python (via NumPy arrays) will be demonstrated, together with few examples of analysis scripts. Currently the prototype of the interface is implemented as an extension of KernelShark. This is a work in progress, and we hope to receive advice from experts in the field to make sure the end result works seamlessly for them.
Captions: 
	00:00:01,110 --> 00:00:02,730
- So, hello, everybody.

00:00:02,730 --> 00:00:04,720
My name is Yordan Karadzhov.

00:00:04,720 --> 00:00:09,360
I'm working for KernelShark Open Source Technology Center.

00:00:09,360 --> 00:00:11,680
And in this talk, I'm going to tell you

00:00:11,680 --> 00:00:14,730
about how you can use tools which have

00:00:14,730 --> 00:00:18,380
been originally developed for doing Big Data

00:00:18,380 --> 00:00:20,023
to look into the Ftrace data.

00:00:21,840 --> 00:00:24,480
That's my first time speaking at Plumbers,

00:00:24,480 --> 00:00:27,056
so maybe I have to introduce myself.

00:00:27,056 --> 00:00:27,930
The interesting about me is that

00:00:27,930 --> 00:00:31,630
before joining VMware's Open Source team,

00:00:31,630 --> 00:00:34,120
I used to be experimental physicist,

00:00:34,120 --> 00:00:35,820
so maybe this is not going to be

00:00:35,820 --> 00:00:39,310
the typical presentation of a software engineer.

00:00:39,310 --> 00:00:40,523
I hope you like it.

00:00:42,240 --> 00:00:46,040
Okay, so just, before starting, let's say a few words

00:00:46,040 --> 00:00:48,731
about the motivation for doing this work.

00:00:48,731 --> 00:00:51,260
So first, Ftrace, that's the official trace

00:00:51,260 --> 00:00:52,137
of the Linux kernel.

00:00:52,137 --> 00:00:54,790
I'm not going to explain this.

00:00:54,790 --> 00:00:58,520
The question is, is the Ftrace data Big Data?

00:00:58,520 --> 00:01:01,020
Well, not necessarily.

00:01:01,020 --> 00:01:03,220
In most of the cases, no.

00:01:03,220 --> 00:01:07,467
If you know very well what you are doing

00:01:07,467 --> 00:01:10,482
and if you have a well-defined question,

00:01:10,482 --> 00:01:13,150
actually, Ftrace can give you a very short answer

00:01:13,150 --> 00:01:14,803
and it's not a Big Data at all.

00:01:15,790 --> 00:01:18,100
But it's a sophisticated instrument.

00:01:18,100 --> 00:01:21,280
There is a large variety of ways you can use it.

00:01:21,280 --> 00:01:25,280
So, let's say that you have some non-trivial,

00:01:25,280 --> 00:01:29,330
or maybe a very specific for you problem,

00:01:29,330 --> 00:01:32,070
and you don't know exactly what's going on.

00:01:32,070 --> 00:01:34,780
You have recorded a lot of tracing data,

00:01:34,780 --> 00:01:36,963
so the question is what to do now.

00:01:38,052 --> 00:01:42,710
So far we've been answering, just use KernelShark

00:01:42,710 --> 00:01:45,524
to look into this data and to understand

00:01:45,524 --> 00:01:46,663
what is going on.

00:01:47,500 --> 00:01:50,450
So, I'm not going to explain KernelShark here.

00:01:50,450 --> 00:01:52,280
If you want to know more about KernelShark,

00:01:52,280 --> 00:01:54,790
Steven gave a very good presentation

00:01:54,790 --> 00:01:56,900
at Open Source Summit North America

00:01:56,900 --> 00:01:58,320
just a month ago.

00:01:58,320 --> 00:02:00,570
There is a video, I believe.

00:02:00,570 --> 00:02:03,130
There are many videos on YouTube about KernelShark,

00:02:03,130 --> 00:02:05,219
so I'm not explaining this thing.

00:02:05,219 --> 00:02:08,865
But in this talk I will actually,

00:02:08,865 --> 00:02:11,580
sorry, just to step back,

00:02:11,580 --> 00:02:13,600
I'm the of maintainer of KernelShark.

00:02:13,600 --> 00:02:16,320
I'm actually the main developer right now.

00:02:16,320 --> 00:02:18,360
But in this talk, I will tell you that

00:02:18,360 --> 00:02:21,530
the KernelShark GUI actually has some weaknesses,

00:02:21,530 --> 00:02:25,630
and actually you can do much more if you go

00:02:25,630 --> 00:02:27,080
behind this GUI thing.

00:02:27,080 --> 00:02:31,060
So, this one slide which I took from Steven's presentation

00:02:33,778 --> 00:02:35,890
from Open Source Summit North America.

00:02:35,890 --> 00:02:38,050
In this place in his presentation,

00:02:38,050 --> 00:02:41,390
he explains how he can actually see what's going on

00:02:43,130 --> 00:02:45,556
with the real-time system.

00:02:45,556 --> 00:02:50,330
This real-time system is supposed to run FT tasks

00:02:50,330 --> 00:02:52,960
with high priority for 95% of the time.

00:02:52,960 --> 00:02:55,630
And then for 5% of the time, give a chance

00:02:55,630 --> 00:02:59,230
for a low-priority tasks to run during it.

00:02:59,230 --> 00:03:04,230
So here, he clicks at the end of this period,

00:03:06,700 --> 00:03:08,623
with marker A of the GUI.

00:03:09,490 --> 00:03:10,820
I don't know if you can see the marker.

00:03:10,820 --> 00:03:14,480
So, he clicks here, then he selects and right-clicks here,

00:03:14,480 --> 00:03:18,570
then switches to marker B, selecting the right event here.

00:03:18,570 --> 00:03:20,050
He measures the time interval,

00:03:20,050 --> 00:03:23,710
then he measures the time duration of the void,

00:03:23,710 --> 00:03:24,840
of the small gap,

00:03:24,840 --> 00:03:27,350
and he computes that everything is okay

00:03:27,350 --> 00:03:30,430
because you have, exactly 95% of the time,

00:03:30,430 --> 00:03:33,693
the expand running all these tasks.

00:03:33,693 --> 00:03:36,767
But the point is, this is a lot of clicking.

00:03:36,767 --> 00:03:40,120
And at the same time, is this really enough

00:03:40,120 --> 00:03:41,920
to make any conclusions?

00:03:41,920 --> 00:03:44,380
Because we just randomly zoomed in

00:03:44,380 --> 00:03:47,080
very deep in the data, in one particular place

00:03:47,080 --> 00:03:49,450
which was very randomly selected.

00:03:49,450 --> 00:03:50,997
We saw that everything is okay here,

00:03:50,997 --> 00:03:53,510
but is this really enough to make conclusions

00:03:53,510 --> 00:03:55,570
that the system is operating as it should,

00:03:55,570 --> 00:03:57,770
that everything is okay everywhere,

00:03:57,770 --> 00:03:59,030
all the time?

00:03:59,030 --> 00:04:00,380
Oh, I would say no.

00:04:00,380 --> 00:04:05,380
So, now imagine doing the same thing 10 thousand times.

00:04:05,720 --> 00:04:09,030
Well, this is just not doable.

00:04:09,030 --> 00:04:11,657
You cannot approach a problem like this with the GUI.

00:04:11,657 --> 00:04:13,720
You're just not supposed to do it.

00:04:13,720 --> 00:04:17,370
There must be a better way of getting this job done.

00:04:17,370 --> 00:04:20,060
And, yes, I think there is a better way

00:04:20,060 --> 00:04:21,850
which is a complimentary,

00:04:21,850 --> 00:04:24,220
and imagine having something like this.

00:04:24,220 --> 00:04:28,417
So you load a Python module, in Python, ksharkpy.

00:04:30,289 --> 00:04:32,990
Then you open your data file,

00:04:32,990 --> 00:04:35,860
then you load your data, and then you look on there.

00:04:35,860 --> 00:04:38,137
So, that's not a real code, of course.

00:04:38,137 --> 00:04:40,370
I'm just trying to fix the idea.

00:04:40,370 --> 00:04:42,580
But, so, you select your Event A,

00:04:42,580 --> 00:04:44,080
you select your Event B,

00:04:44,080 --> 00:04:46,730
you measure the duration between those two events.

00:04:46,730 --> 00:04:50,590
You store this information when you finish

00:04:50,590 --> 00:04:51,910
looping over the data.

00:04:51,910 --> 00:04:54,542
You do some calculations that you may need

00:04:54,542 --> 00:04:58,750
for your analysis, you plot some summary

00:04:58,750 --> 00:05:01,905
of the results, and eventually you can even

00:05:01,905 --> 00:05:04,930
draw some cool histograms, some graphs,

00:05:04,930 --> 00:05:07,440
which can be put in your presentation.

00:05:07,440 --> 00:05:10,880
This can be by far more useful,

00:05:10,880 --> 00:05:15,230
in this particular case, which Steven was showing me

00:05:15,230 --> 00:05:17,072
in his pressentation.

00:05:17,072 --> 00:05:21,770
So that's another stolen slide.

00:05:21,770 --> 00:05:25,260
That's a typical slide of people using

00:05:25,260 --> 00:05:30,170
when they explain NumPy and how it's a great,

00:05:30,170 --> 00:05:32,323
powerful, and shiny instrument.

00:05:33,215 --> 00:05:37,000
So, typically, the typical slide is,

00:05:37,000 --> 00:05:39,660
the languages are given in the opposite order.

00:05:39,660 --> 00:05:41,940
They usually put the Numerical

00:05:41,940 --> 00:05:45,040
or Scientific programming languages first.

00:05:45,040 --> 00:05:48,670
So, my contribution to this slide was to change it

00:05:48,670 --> 00:05:49,503
a little bit.

00:05:50,534 --> 00:05:52,578
So my point is, you have some languages

00:05:52,578 --> 00:05:54,660
like R, MATLAB, Fortran, maybe,

00:05:54,660 --> 00:05:58,080
which are designed to do mathematical calculations.

00:05:58,080 --> 00:05:59,980
They are very optimized.

00:05:59,980 --> 00:06:04,930
But they're not very useful outside of this code.

00:06:04,930 --> 00:06:06,990
And you have the general purpose language, of course.

00:06:06,990 --> 00:06:08,320
And when you combine the two,

00:06:08,320 --> 00:06:11,446
the general purpose language like Python

00:06:11,446 --> 00:06:14,240
with the scientific computing, you get NumPy.

00:06:14,240 --> 00:06:16,803
That's the idea behind developing NumPy.

00:06:17,842 --> 00:06:20,190
What's the important thing here?

00:06:20,190 --> 00:06:23,400
So, NumPy is not a part of the Python language.

00:06:23,400 --> 00:06:25,430
It's just a library.

00:06:25,430 --> 00:06:29,269
It provides N-dimensional arrays

00:06:29,269 --> 00:06:30,890
of homogeneous types.

00:06:30,890 --> 00:06:33,670
So, you have strong typing of your data,

00:06:33,670 --> 00:06:36,310
which makes everything run fast.

00:06:36,310 --> 00:06:40,600
NumPy also provides you with a large collection

00:06:40,600 --> 00:06:43,380
of mathematical functions, which are operating

00:06:43,380 --> 00:06:47,290
on top of these arrays, so you can do many different things.

00:06:47,290 --> 00:06:50,440
The other nice things is if you have a C

00:06:50,440 --> 00:06:53,930
or C++ or Fortran code, you can easily integrate this

00:06:53,930 --> 00:06:57,003
with NumPy and just use it.

00:06:58,140 --> 00:07:02,060
Also, you have some complimentary packages like Matplotlib,

00:07:02,060 --> 00:07:06,480
which you'll see how we use this to plot histograms.

00:07:06,480 --> 00:07:10,290
We have SciPy library which adds things

00:07:10,290 --> 00:07:14,380
like optimization, for example,

00:07:14,380 --> 00:07:17,830
linear algebra, integration, fast area transformations

00:07:17,830 --> 00:07:21,023
and things if you need this.

00:07:22,600 --> 00:07:26,290
So, many NumPy operations are actually implemented

00:07:26,290 --> 00:07:27,653
in C, which is good.

00:07:28,540 --> 00:07:31,800
In fact, the NumPy erase, the way they are defined

00:07:31,800 --> 00:07:36,600
is very similar to the way we know the arrays in C.

00:07:36,600 --> 00:07:39,920
And the cool thing is, if you have a C code

00:07:39,920 --> 00:07:42,750
which allocates a memory for an array and fills

00:07:42,750 --> 00:07:44,340
this array with data,

00:07:44,340 --> 00:07:46,490
then you can just wrap this thing

00:07:46,490 --> 00:07:47,740
into a NumPy array.

00:07:47,740 --> 00:07:50,460
You don't need to copy any data, and you create

00:07:50,460 --> 00:07:54,170
your NumPy array directly from your C array.

00:07:54,170 --> 00:07:58,650
So, let's see how we can take advantage

00:07:58,650 --> 00:08:03,540
of all these things, and eventually get our tracing data

00:08:03,540 --> 00:08:07,010
in Python, and start analyzing there.

00:08:07,010 --> 00:08:09,135
So, we'll take advantage with something

00:08:09,135 --> 00:08:13,724
which I'll say almost exists already.

00:08:13,724 --> 00:08:18,320
Even with KernelShark 1.0, if you take the code

00:08:18,320 --> 00:08:20,820
and build it, you get a library

00:08:20,820 --> 00:08:22,413
which is called libkshark.

00:08:23,570 --> 00:08:27,750
We don't call this an official library because the API

00:08:27,750 --> 00:08:30,420
is still not completed.

00:08:30,420 --> 00:08:32,240
We tried to get a good API

00:08:32,240 --> 00:08:36,100
from the first attempt, but we are still changing

00:08:36,100 --> 00:08:40,076
a few things, so, the library became officially available

00:08:40,076 --> 00:08:44,233
with KernelShark 2.1, which is--

00:08:44,233 --> 00:08:45,500
- [Audience Member] 2.1, or 2.0?

00:08:45,500 --> 00:08:47,630
- 2.0, yeah, sorry, 2.0.

00:08:49,240 --> 00:08:51,960
Which is under development right now.

00:08:51,960 --> 00:08:55,780
I'll be giving a demo talk at Open Source Europe

00:08:55,780 --> 00:08:58,860
in Lisbon, so if you're interested, come to see this talk.

00:08:58,860 --> 00:09:02,369
It will be particular for KernelShark 2.

00:09:02,369 --> 00:09:07,320
But, so, KernelShark 2, we'll include the final version,

00:09:07,320 --> 00:09:09,060
or not final, but the official version

00:09:09,060 --> 00:09:11,300
of the library, but the library is still there

00:09:11,300 --> 00:09:14,250
even with version 1,

00:09:14,250 --> 00:09:18,643
and for a proof of concept like this one can be used.

00:09:18,643 --> 00:09:23,643
So, together with the version 1, if you get the code

00:09:25,100 --> 00:09:29,330
from kernel.org inside the KernelShark directory,

00:09:29,330 --> 00:09:32,160
there is another tree code examples.

00:09:32,160 --> 00:09:36,710
And in this example directory we have a collection

00:09:36,710 --> 00:09:40,980
of very simple C programs which are there

00:09:40,980 --> 00:09:43,970
to demonstrate how to use the library.

00:09:43,970 --> 00:09:46,150
And that's one of these examples.

00:09:46,150 --> 00:09:48,240
Actually, it's not the full example,

00:09:48,240 --> 00:09:51,050
but I wanted to somehow get the code shown

00:09:51,050 --> 00:09:54,412
on two slides, so I moved over from the code.

00:09:54,412 --> 00:09:57,719
But the idea is, as you can see,

00:09:57,719 --> 00:10:02,656
it follows the same sequence of the instructions

00:10:02,656 --> 00:10:07,656
that we saw in our Python code, which we would like to have.

00:10:10,270 --> 00:10:13,700
So, you basically just, each slide's a session.

00:10:13,700 --> 00:10:16,200
You load the file, and you load the data,

00:10:16,200 --> 00:10:19,320
again, this part here is not the real code.

00:10:19,320 --> 00:10:21,143
That's just to fix the idea that you look

00:10:21,143 --> 00:10:23,220
for all the data.

00:10:23,220 --> 00:10:25,760
The difference compared to Python is,

00:10:25,760 --> 00:10:27,440
first of all, you have to cleanup.

00:10:27,440 --> 00:10:28,840
That's your responsibility.

00:10:28,840 --> 00:10:32,750
Here in C you can print the summary

00:10:32,750 --> 00:10:34,920
of your results, but unfortunately there is

00:10:34,920 --> 00:10:38,800
no easy way to draw histograms or graphs

00:10:38,800 --> 00:10:40,142
or things like this.

00:10:40,142 --> 00:10:42,393
That's a weakness.

00:10:45,050 --> 00:10:49,780
So, just to summarize, this proof of concept

00:10:49,780 --> 00:10:53,280
NumPy interface, to access the Ftrade data

00:10:53,280 --> 00:10:57,100
in Python via NumPy arrays is nothing more

00:10:57,100 --> 00:11:01,170
than just a tiny wrapper around this library

00:11:01,170 --> 00:11:02,720
which KernelShark provides,

00:11:02,720 --> 00:11:06,283
or will provide with version 2.0.

00:11:07,620 --> 00:11:12,620
And so, enough for explaining, let's see some examples.

00:11:13,860 --> 00:11:15,090
- So, one question. - Yes.

00:11:15,090 --> 00:11:18,140
- So, could you do something,

00:11:18,140 --> 00:11:21,460
hook into print dot, graph this

00:11:21,460 --> 00:11:25,610
with the printing statements from the new program?

00:11:25,610 --> 00:11:27,280
- In C, you mean. - Yeah.

00:11:27,280 --> 00:11:29,019
You could do that. - You could do this,

00:11:29,019 --> 00:11:32,760
but you haven't, far more sophisticated,

00:11:32,760 --> 00:11:35,950
user-friendly instruments for drawing histograms

00:11:35,950 --> 00:11:38,893
in Python then, you can do much more.

00:11:40,848 --> 00:11:42,790
- I think what, I mean, preferably, I'm a C programmer.

00:11:42,790 --> 00:11:46,240
Yordan likes Python.

00:11:46,240 --> 00:11:48,600
But a lot of people it's like, anything

00:11:48,600 --> 00:11:52,123
with the simplicity of Python is there, it's just,

00:11:52,123 --> 00:11:54,350
you've got a lot of tools, so--

00:11:54,350 --> 00:11:55,960
- I think when you see the example

00:11:55,960 --> 00:11:59,470
you would understand why we want to use Python.

00:11:59,470 --> 00:12:00,349
- [Woman] Yeah, that's fine.

00:12:00,349 --> 00:12:01,608
I thought you were trying to use,

00:12:01,608 --> 00:12:04,758
you have a C program to begin with.

00:12:04,758 --> 00:12:06,290
- [Man With Glasses] Well, basically, I think

00:12:06,290 --> 00:12:08,410
what you're saying is we have the Lib,

00:12:08,410 --> 00:12:10,180
the code that we have is written in C.

00:12:10,180 --> 00:12:13,366
- Yeah, so, under the hood everything is written in C.

00:12:13,366 --> 00:12:14,800
I mean, the Python is just a tiny wrapper

00:12:14,800 --> 00:12:16,623
around the C library.

00:12:21,260 --> 00:12:22,453
So, the first example.

00:12:23,299 --> 00:12:25,020
And here with this example, I'm trying to reproduce

00:12:25,020 --> 00:12:29,890
the original study done by Wolfgang and Daniel.

00:12:29,890 --> 00:12:32,380
They presented this at Open Source Summit

00:12:32,380 --> 00:12:34,849
in Japan, this year.

00:12:34,849 --> 00:12:38,620
So, the goal is just to reproduce the study

00:12:38,620 --> 00:12:42,094
that they did for the real-time,

00:12:42,094 --> 00:12:46,156
for the latency of the real-time system

00:12:46,156 --> 00:12:49,230
with the instrument and eventually show you

00:12:49,230 --> 00:12:51,670
or convince you that the new instrument

00:12:51,670 --> 00:12:54,100
can give you more opportunities,

00:12:54,100 --> 00:12:56,480
and eventually it's more powerful

00:12:58,520 --> 00:13:01,573
and can help you understand deeper what's going on.

00:13:02,408 --> 00:13:03,670
- Actually I think they did a talk

00:13:03,670 --> 00:13:06,090
here on Kernel Summit on the first day.

00:13:06,090 --> 00:13:07,933
- Ah. - Maybe, okay.

00:13:11,247 --> 00:13:12,650
- So, the goal of this now is to get

00:13:12,650 --> 00:13:15,102
a statistical estimate of the probability

00:13:15,102 --> 00:13:18,630
of exceeding the Worst Case Execution Time,

00:13:18,630 --> 00:13:21,050
or, to expand it here,

00:13:21,050 --> 00:13:24,930
what is the probability of having a very large latency

00:13:24,930 --> 00:13:27,490
when you run your application?

00:13:27,490 --> 00:13:30,430
And once again I want to remind that this is just

00:13:30,430 --> 00:13:32,265
a demonstration of the instrument.

00:13:32,265 --> 00:13:34,410
The core credit for the analysis itself

00:13:34,410 --> 00:13:36,913
and the idea itself goes to Wolfgang and Daniel.

00:13:39,150 --> 00:13:44,150
So, they are using jitterdebugger to study the latencies.

00:13:44,230 --> 00:13:48,560
It's just an implementation of a so-called side code test,

00:13:48,560 --> 00:13:50,880
or, side code test, yes.

00:13:50,880 --> 00:13:55,880
The idea is you have a task which runs on each CPU

00:13:56,189 --> 00:13:58,930
which is doing a very simple thing.

00:13:58,930 --> 00:14:01,390
It initializes the high-resolution flow,

00:14:01,390 --> 00:14:05,170
resets it to zero, and then goes to sleep

00:14:05,170 --> 00:14:07,130
for one millisecond.

00:14:07,130 --> 00:14:10,550
When it wakes up, it gets the time of the clock,

00:14:10,550 --> 00:14:13,640
resets the clock again, and goes through it again,

00:14:13,640 --> 00:14:15,710
and you repeat this--

00:14:15,710 --> 00:14:17,170
- It doesn't actually reset the clock.

00:14:17,170 --> 00:14:22,088
It just wakes up at every millisecond, it's like--

00:14:22,088 --> 00:14:25,014
- [Yordan] But you have this high resolution, this start.

00:14:25,014 --> 00:14:26,550
- But the reset there you see is just,

00:14:26,550 --> 00:14:28,020
that's a kernel insight code.

00:14:28,020 --> 00:14:30,270
That's actually the kernel reset timer.

00:14:30,270 --> 00:14:31,680
It's slightly different

00:14:31,680 --> 00:14:34,160
than what the actual application is doing.

00:14:34,160 --> 00:14:34,993
You're looking at the kernel now.

00:14:34,993 --> 00:14:37,930
- Yeah, but the point is we don't use this clock anyway

00:14:37,930 --> 00:14:40,320
because we use the timestamps of the events,

00:14:40,320 --> 00:14:42,900
so you can't see this thing here

00:14:42,900 --> 00:14:46,392
because you have to zoom so this is the next slide,

00:14:46,392 --> 00:14:48,740
which is just zooming in

00:14:48,740 --> 00:14:52,189
in one of the executions of this cycle.

00:14:52,189 --> 00:14:56,130
Here, in the beginning, you see the scheduling

00:14:56,130 --> 00:14:58,690
when the task gets scheduled.

00:14:58,690 --> 00:15:01,271
The first thing is this print event,

00:15:01,271 --> 00:15:04,730
which we just used to get the timestamp

00:15:04,730 --> 00:15:08,190
when the execution of the task starts.

00:15:08,190 --> 00:15:11,590
Then you have this unit start,

00:15:11,590 --> 00:15:14,750
and basically from the start we want to go

00:15:14,750 --> 00:15:18,320
to the print event in the next execution

00:15:18,320 --> 00:15:20,550
and measure this duration.

00:15:20,550 --> 00:15:23,730
So, it's expected to be one millisecond,

00:15:23,730 --> 00:15:27,040
so everything that is more than a millisecond

00:15:27,040 --> 00:15:30,490
is latency in this experiment.

00:15:30,490 --> 00:15:35,210
And going back here, so here, with the GUI we've measured

00:15:35,210 --> 00:15:39,483
that the latency is around three hundred nanoseconds,

00:15:41,130 --> 00:15:43,160
so very small latency.

00:15:43,160 --> 00:15:45,440
Looks great, but the problem is,

00:15:45,440 --> 00:15:47,900
is it the same everywhere?

00:15:47,900 --> 00:15:50,350
So, we would do a statistical analysis

00:15:50,350 --> 00:15:52,580
and we will try to estimate the probability

00:15:52,580 --> 00:15:54,963
of actually having much larger latencies.

00:15:56,024 --> 00:15:59,150
And to make it more interesting,

00:15:59,150 --> 00:16:03,100
together with jitterdebugger we will run Hackbench,

00:16:03,100 --> 00:16:05,948
which is a stress test for the scheduler.

00:16:05,948 --> 00:16:10,217
So, the system will be really heavily loaded

00:16:10,217 --> 00:16:12,458
when we run this.

00:16:12,458 --> 00:16:16,040
So, how we are going to estimate the probability

00:16:16,040 --> 00:16:17,700
of having a large latency.

00:16:17,700 --> 00:16:19,930
There is a special tier in here which is part

00:16:19,930 --> 00:16:23,465
of the statistics, which is called extreme value theory.

00:16:23,465 --> 00:16:27,300
Usually, in the textbooks, when people are introducing

00:16:27,300 --> 00:16:31,560
the theory they use examples with precipitation

00:16:31,560 --> 00:16:34,600
or water levels of the rivers,

00:16:34,600 --> 00:16:37,080
because when the theory was developed

00:16:37,080 --> 00:16:40,270
back in the 19th century, the motivation

00:16:40,270 --> 00:16:43,030
for developing this was to develop infrastructure

00:16:43,030 --> 00:16:44,370
for preventing floods,

00:16:44,370 --> 00:16:47,320
for protecting the population from floods.

00:16:47,320 --> 00:16:51,153
And in many books that's the way, actually,

00:16:51,153 --> 00:16:52,730
that the math gets introduced, so I will

00:16:52,730 --> 00:16:54,240
follow this tradition.

00:16:54,240 --> 00:16:58,888
Here you see data series of precipitations per day.

00:16:58,888 --> 00:17:03,447
Like, in millimeters per day.

00:17:05,140 --> 00:17:08,010
And you see you have some extreme values,

00:17:08,010 --> 00:17:09,710
but most of the case you have rain

00:17:11,550 --> 00:17:14,741
which is around 20 millimeters per day.

00:17:14,741 --> 00:17:18,370
So the way this peak over Threshold approach

00:17:18,370 --> 00:17:22,990
to the problem works is you just ignore all the data

00:17:22,990 --> 00:17:24,970
that is below the threshold.

00:17:24,970 --> 00:17:26,580
You don't care about this data.

00:17:26,580 --> 00:17:29,420
You take only the data which is above this threshold.

00:17:29,420 --> 00:17:32,720
And now imagine projecting all these red points here

00:17:32,720 --> 00:17:34,770
that you see on the diagram,

00:17:34,770 --> 00:17:35,940
on the y-axis.

00:17:35,940 --> 00:17:38,200
This will follow a histogram for you.

00:17:38,200 --> 00:17:42,190
And here in this bit of the histogram you have

00:17:42,190 --> 00:17:45,960
a lot of points, a relatively big number.

00:17:45,960 --> 00:17:49,330
And when you go to the higher, more and more extreme values

00:17:49,330 --> 00:17:51,443
you have less and less data, okay?

00:17:55,180 --> 00:17:58,400
So, how can you view the model on top of this thing?

00:17:58,400 --> 00:18:02,290
That's the so-called Generalized Pareto Distribution.

00:18:02,290 --> 00:18:05,870
It's just a function which is very flexible.

00:18:05,870 --> 00:18:09,560
It has the three free parameters which you can tune,

00:18:09,560 --> 00:18:11,410
and with those parameters we can get

00:18:11,410 --> 00:18:15,490
very different shapes, on the right side

00:18:15,490 --> 00:18:20,490
of the slide, you can see how this function

00:18:21,720 --> 00:18:25,363
looks for different values of the parameters.

00:18:26,290 --> 00:18:29,310
Just to explain it a bit more, so

00:18:29,310 --> 00:18:32,673
if this function has a private probability

00:18:32,673 --> 00:18:37,673
then all the area that is below the curve is equal to one,

00:18:38,420 --> 00:18:41,080
because the total probability of having any value

00:18:41,080 --> 00:18:42,850
for the latency or any value

00:18:42,850 --> 00:18:46,240
for the precipitation should be one, yes?

00:18:46,240 --> 00:18:47,720
Make sense?

00:18:47,720 --> 00:18:52,366
But you may ask yourself, I clear see that the red line

00:18:52,366 --> 00:18:57,040
covers a much bigger area than the blue one?

00:18:57,040 --> 00:18:58,490
How they can be equal?

00:18:58,490 --> 00:19:01,540
Well, it's very simple, because this large tail

00:19:01,540 --> 00:19:05,640
which goes outside of my slide here continues

00:19:05,640 --> 00:19:09,797
almost to infinity, eventually, and the tail of the red line

00:19:13,250 --> 00:19:15,910
vanishes very quickly and becomes negligible

00:19:15,910 --> 00:19:20,191
while the blue line has a tail which goes much father.

00:19:20,191 --> 00:19:22,740
And then, the two areas will be the same.

00:19:22,740 --> 00:19:26,380
Going back here, so we have data for just,

00:19:26,380 --> 00:19:29,350
what is this, eleven years.

00:19:29,350 --> 00:19:33,150
Imagine having the data for the entire history

00:19:33,150 --> 00:19:34,570
of the planet Earth.

00:19:34,570 --> 00:19:37,050
Well, maybe then you see a precipitation

00:19:37,050 --> 00:19:38,950
which goes to infinity.

00:19:38,950 --> 00:19:43,950
I mean, if you have an infinite amount of data

00:19:44,186 --> 00:19:48,120
your data must be described by some distribution

00:19:48,120 --> 00:19:49,717
like this one.

00:19:49,717 --> 00:19:52,900
So, going back to the problem that we are trying to solve

00:19:52,900 --> 00:19:57,160
here are the latencies that we observe in our test.

00:19:57,160 --> 00:20:02,160
Here on my top-left plot you see the histogram

00:20:04,410 --> 00:20:07,780
of the latency, so the y-axis is lower.

00:20:07,780 --> 00:20:09,690
It's good just being able to see better,

00:20:09,690 --> 00:20:13,467
we have two latencies which are around 30 microseconds,

00:20:15,060 --> 00:20:17,530
so significant latencies around the example

00:20:17,530 --> 00:20:18,810
which we saw with the GUI,

00:20:18,810 --> 00:20:20,970
we saw 300 nanoseconds.

00:20:20,970 --> 00:20:24,170
And here we see 30 microseconds.

00:20:24,170 --> 00:20:26,543
So, it's a significantly larger latency.

00:20:28,920 --> 00:20:31,820
Below, you see how this histogram gets fitted

00:20:31,820 --> 00:20:35,250
with the theoretical distribution.

00:20:35,250 --> 00:20:38,010
See, the curve of the distribution falls

00:20:38,010 --> 00:20:40,450
to the histogram more or less correctly.

00:20:40,450 --> 00:20:43,180
That's the result of the fit,

00:20:44,324 --> 00:20:48,221
your estimate of the parameters of the distribution.

00:20:48,221 --> 00:20:51,270
This one has a 15% error.

00:20:51,270 --> 00:20:53,140
This one just has 3% error.

00:20:53,140 --> 00:20:56,201
This one is fixed because we know that we are cutting

00:20:56,201 --> 00:21:00,910
10 microseconds, and the goodness of the fit

00:21:00,910 --> 00:21:02,870
is more or less correct.

00:21:02,870 --> 00:21:04,583
Perfect fit will give you one.

00:21:04,583 --> 00:21:07,220
Anything that's much smaller than one

00:21:07,220 --> 00:21:08,240
is very suspicious.

00:21:08,240 --> 00:21:09,940
You probably have a bug in your code

00:21:09,940 --> 00:21:11,543
if you get such a value.

00:21:12,470 --> 00:21:15,154
1.8 is a decent fit.

00:21:15,154 --> 00:21:18,760
So, having this thing we can now

00:21:18,760 --> 00:21:21,030
recalculate the probability.

00:21:21,030 --> 00:21:23,658
And the probability is calculated with this

00:21:23,658 --> 00:21:26,990
so-called return plot.

00:21:26,990 --> 00:21:29,500
So, let's say you're asking yourself,

00:21:29,500 --> 00:21:32,570
what is the probability, so, how often should I

00:21:32,570 --> 00:21:35,080
actually observe in my data a latency

00:21:35,080 --> 00:21:39,403
which is around three, thirty microseconds.

00:21:41,770 --> 00:21:45,920
So, you just take this red line,

00:21:45,920 --> 00:21:49,500
then you find here that you should expect

00:21:49,500 --> 00:21:53,426
to observe such a latency more or less

00:21:53,426 --> 00:21:58,426
1.5 times 10 to the sixth, which is one and a half million,

00:22:00,166 --> 00:22:02,760
171 and a half millionth iteration

00:22:02,760 --> 00:22:04,694
of your cycle test.

00:22:04,694 --> 00:22:07,750
And this is more or less what you see here, actually,

00:22:07,750 --> 00:22:11,880
because the entire number of cycles that we have

00:22:11,880 --> 00:22:16,880
in the data is 2.5 millions, and we see two latencies

00:22:18,170 --> 00:22:19,270
like this one.

00:22:19,270 --> 00:22:20,630
Well, you may ask yourself,

00:22:20,630 --> 00:22:22,292
it's not exactly correct.

00:22:22,292 --> 00:22:27,292
It gives me a number which is kinda less than what I see.

00:22:28,230 --> 00:22:32,790
That's because the model is actually trying to see

00:22:32,790 --> 00:22:34,970
the entire picture, not just looking

00:22:34,970 --> 00:22:39,970
for the 30 microsecond latencies.

00:22:40,090 --> 00:22:44,400
He also takes into account the part that is here,

00:22:44,400 --> 00:22:46,786
and because you actually don't have a lot of events

00:22:46,786 --> 00:22:49,940
in this case, it kinda just thinks

00:22:49,940 --> 00:22:54,103
maybe I'm kind of unlucky to have 13 microsecond latencies

00:22:56,650 --> 00:22:57,903
in my data sample.

00:23:00,390 --> 00:23:02,913
Okay, if you compare the performance

00:23:02,913 --> 00:23:06,597
between the case when you run Hackbench,

00:23:06,597 --> 00:23:09,870
and the case when you run an idle machine,

00:23:09,870 --> 00:23:12,940
you see there's a very significant decrease

00:23:13,790 --> 00:23:15,000
in the performance.

00:23:15,000 --> 00:23:18,660
This thing on top is your probability estimate

00:23:18,660 --> 00:23:21,557
for when you run Hackbench and this below

00:23:21,557 --> 00:23:25,530
is your probability estimate for when you run

00:23:25,530 --> 00:23:27,470
jitterdebugger on an idle machine.

00:23:27,470 --> 00:23:32,040
So really, running Hackbench results

00:23:32,040 --> 00:23:35,333
in a significant decrease in the performance of the system.

00:23:39,111 --> 00:23:40,090
- [Man With Glasses] Actually, it's not performance,

00:23:40,090 --> 00:23:41,460
but more like, it's jitter.

00:23:41,460 --> 00:23:42,383
- Yeah, okay.

00:23:45,670 --> 00:23:48,130
Okay, so let's see how this thing was done,

00:23:48,130 --> 00:23:49,913
actually, in this Python code.

00:23:54,949 --> 00:23:56,399
Oh, that's my second example.

00:24:00,323 --> 00:24:02,850
So, the entire script is, let's see,

00:24:02,850 --> 00:24:07,850
it's 300 lines of code but I have a lot of comments.

00:24:09,598 --> 00:24:12,248
So, it's a very simple script, that's all this thing.

00:24:15,468 --> 00:24:16,710
So it starts here.

00:24:16,710 --> 00:24:20,580
We open the file, we're loading one plugin.

00:24:20,580 --> 00:24:22,400
Here, I didn't explain anything

00:24:22,400 --> 00:24:24,070
about plugins but, yeah,

00:24:24,070 --> 00:24:24,903
we load one plugin.

00:24:24,903 --> 00:24:26,780
Then we load the data.

00:24:26,780 --> 00:24:31,780
We find the ID of the high-resolution timer start event.

00:24:33,310 --> 00:24:35,727
We find the ID of the print event.

00:24:35,727 --> 00:24:40,727
Then we find the PADs of the old threads,

00:24:41,720 --> 00:24:44,388
of the jitterdebugger program.

00:24:44,388 --> 00:24:47,790
Then, we iterate over each task.

00:24:47,790 --> 00:24:51,493
So, this is basically for CPU data.

00:24:53,650 --> 00:24:56,240
Here we calculate the total probability

00:24:56,240 --> 00:25:00,190
in the place where we actually fit the histogram

00:25:00,190 --> 00:25:04,203
with the curve, is here.

00:25:06,250 --> 00:25:07,423
It's this part.

00:25:09,100 --> 00:25:13,120
Here we plug the legend that we used on the plot,

00:25:13,120 --> 00:25:16,460
and here we're just doing some plotting.

00:25:16,460 --> 00:25:17,833
I mean, this creates, this plot.

00:25:27,237 --> 00:25:28,832
- [Man With Glasses] Is that example anywhere

00:25:28,832 --> 00:25:30,900
you can post, where people can actually download

00:25:30,900 --> 00:25:32,110
and take a look at it?

00:25:32,110 --> 00:25:35,480
- Well, it's not posted right now.

00:25:35,480 --> 00:25:37,090
The code development goes

00:25:37,090 --> 00:25:40,240
on the Linux Trace Development list

00:25:40,240 --> 00:25:44,920
on some previous versions of the NumPy interface,

00:25:44,920 --> 00:25:46,718
having posted there.

00:25:46,718 --> 00:25:51,120
This one will be probably available

00:25:51,120 --> 00:25:54,230
in maybe a week, because I still have to clean some final--

00:25:54,230 --> 00:25:55,930
- I'm not talking about the NumPy interface.

00:25:55,930 --> 00:25:57,880
I'm talking about the script you used, yeah.

00:25:57,880 --> 00:25:59,730
- Well, the examples will be part of the interface.

00:25:59,730 --> 00:26:02,941
I mean, they will come together with the interface, yeah.

00:26:02,941 --> 00:26:04,803
All the examples.

00:26:09,370 --> 00:26:12,250
Okay, so so far this basically just reproduces

00:26:12,250 --> 00:26:14,417
what Wolfgang and Daniel did.

00:26:14,417 --> 00:26:16,760
So, what is the complimentary thing

00:26:16,760 --> 00:26:19,350
that our instrument can give you?

00:26:19,350 --> 00:26:23,700
If we go back to the code, the example,

00:26:25,870 --> 00:26:30,870
at some point we have this here.

00:26:31,060 --> 00:26:34,870
We are creating a JSON file which actually gives

00:26:34,870 --> 00:26:37,000
the description of the KernelShark session.

00:26:37,000 --> 00:26:39,400
It's a very simple file.

00:26:39,400 --> 00:26:42,280
Here, we just put the PAD of the process

00:26:42,280 --> 00:26:46,060
that we want to see, the CPU it runs here.

00:26:46,060 --> 00:26:48,140
So, we take the start event,

00:26:48,140 --> 00:26:51,330
we take the stop event, we just add a little bit

00:26:51,330 --> 00:26:54,040
of a margin to the two sides of this time window

00:26:54,040 --> 00:26:57,090
and so we set the same to the module of the KernelShark.

00:26:57,090 --> 00:26:59,070
Okay, visualize for me this time window.

00:26:59,070 --> 00:27:01,740
Just zoom around this very large latency

00:27:01,740 --> 00:27:04,610
which we discovered and make me a session

00:27:04,610 --> 00:27:07,165
that will show me this thing.

00:27:07,165 --> 00:27:10,550
So, a session file looks like this.

00:27:10,550 --> 00:27:14,160
It's a very simple, human-readable JSON file.

00:27:20,376 --> 00:27:21,530
You have a description of your models,

00:27:21,530 --> 00:27:24,080
so it starts from this time.

00:27:24,080 --> 00:27:26,600
This is the timestamp of the first event

00:27:26,600 --> 00:27:27,550
that will be shown.

00:27:27,550 --> 00:27:32,490
Go to the end, your time window with this timestamp.

00:27:32,490 --> 00:27:37,260
Make me one thousand bins, set the markB

00:27:37,260 --> 00:27:40,877
to be at the start, set markA, it's the opposite.

00:27:42,918 --> 00:27:43,947
Set MarkA to be at the start.

00:27:43,947 --> 00:27:47,593
Set markB to be at the end of this big latency.

00:27:49,862 --> 00:27:51,353
- [Man With Glasses] Can you explain what a bin is?

00:27:52,229 --> 00:27:53,640
- Explain it? - Explain what a bin is.

00:27:53,640 --> 00:27:58,640
- Bin, well, that's, okay, I can explain that right here.

00:28:12,087 --> 00:28:17,087
So, the model that we use to visualize the tracing data

00:28:17,190 --> 00:28:20,110
is based on this concept of binning.

00:28:20,110 --> 00:28:21,430
So because there is no,

00:28:21,430 --> 00:28:25,900
if you have, like in the case of this jitterdebugger test

00:28:25,900 --> 00:28:29,290
we have hundreds of millions of trace records.

00:28:29,290 --> 00:28:30,710
There is no way to visualize this

00:28:30,710 --> 00:28:32,770
with the limited amount of pixels that you have

00:28:32,770 --> 00:28:35,540
on your screen, so everything that,

00:28:35,540 --> 00:28:40,540
so we just separate the whole duration of the data, in time,

00:28:41,060 --> 00:28:43,880
into small, sub-intervals,

00:28:43,880 --> 00:28:46,640
time intervals, which are uniform in size.

00:28:46,640 --> 00:28:49,620
And everything that goes into one of the sub intervals

00:28:49,620 --> 00:28:53,560
or bins gets visualized by a single graphical element

00:28:54,473 --> 00:28:57,360
which is like a tick here in this graph.

00:28:57,360 --> 00:28:59,080
- Or one pixel. - Yeah.

00:28:59,080 --> 00:29:01,620
- One pixel is one bin, essentially,

00:29:01,620 --> 00:29:04,810
but the point is the way we define the bin

00:29:04,810 --> 00:29:07,773
is just the time interval inside your tracing data.

00:29:12,188 --> 00:29:15,640
Okay, so we have our session descriptor file

00:29:15,640 --> 00:29:18,300
which has been generated by the python script,

00:29:18,300 --> 00:29:22,070
which analyzes the data, and now we can just do

00:29:22,070 --> 00:29:25,430
this KernelShark -s your JSON file,

00:29:25,430 --> 00:29:29,040
and it will directly zoom and show you the place

00:29:29,040 --> 00:29:32,850
where this very big latency is happening.

00:29:32,850 --> 00:29:37,850
And strangely, you see that the task is waiting

00:29:38,020 --> 00:29:42,903
for like, 37 microseconds without doing anything

00:29:45,660 --> 00:29:48,260
so our current explanation for this

00:29:48,260 --> 00:29:52,034
is that there's an SMI going on right now,

00:29:52,034 --> 00:29:54,680
but we are investigating this thing.

00:29:54,680 --> 00:29:59,290
But the point is you can really connect the script

00:29:59,290 --> 00:30:03,180
with the GUI, and what has been discovered by the script

00:30:03,180 --> 00:30:07,950
can eventually be seen in the GUI.

00:30:07,950 --> 00:30:11,399
You can then investigate what's going on.

00:30:11,399 --> 00:30:14,230
You can get a deeper understanding.

00:30:14,230 --> 00:30:17,520
So, the two instruments are made to be complimentary,

00:30:17,520 --> 00:30:20,963
not to stand alone, but together.

00:30:22,980 --> 00:30:25,410
Okay, this example is not very good

00:30:25,410 --> 00:30:29,870
for making demo because, I mean, to curate a statistic

00:30:29,870 --> 00:30:31,010
you need a very large file.

00:30:31,010 --> 00:30:33,693
In this case, the file is like 10 gigabytes

00:30:33,693 --> 00:30:36,800
and running the script takes several minutes

00:30:36,800 --> 00:30:38,280
so it's not useful for a demo.

00:30:38,280 --> 00:30:40,952
I will show you something which goes quickly

00:30:40,952 --> 00:30:43,183
for my demo.

00:31:02,350 --> 00:31:05,257
Okay, so I have a hello world executable here

00:31:05,257 --> 00:31:08,010
and I'm going to record the tracing data

00:31:08,010 --> 00:31:08,843
for this executable.

00:31:08,843 --> 00:31:11,470
In particular, I'm interested in page faults.

00:31:11,470 --> 00:31:15,530
So, I want to record all page faults which are happening

00:31:15,530 --> 00:31:18,518
when I run this hello world program.

00:31:18,518 --> 00:31:22,710
I will need to map the memory of the process,

00:31:22,710 --> 00:31:26,788
so I need to know the address space of the executable.

00:31:26,788 --> 00:31:28,293
And basically, that's it.

00:31:29,236 --> 00:31:30,069
So here, there's a very simple comment.

00:31:30,069 --> 00:31:31,990
I am saying, trace and record,

00:31:31,990 --> 00:31:34,480
minus, so I want to exceptional events,

00:31:34,480 --> 00:31:36,870
that's where the page fault events are.

00:31:36,870 --> 00:31:40,830
I want to map them, to get the address space

00:31:41,673 --> 00:31:43,290
in the process, and the output will be traced

00:31:43,290 --> 00:31:45,430
in the core PX

00:31:45,430 --> 00:31:48,483
and I'm running hello world executable.

00:31:57,683 --> 00:31:58,516
Okay, hello world.

00:32:00,045 --> 00:32:01,711
And here's my data.

00:32:01,711 --> 00:32:06,307
So now I will run a script, which looks like this.

00:32:08,350 --> 00:32:12,560
Basically I'm doing the same iteration

00:32:12,560 --> 00:32:17,560
over the data, looking for page fault user events.

00:32:18,730 --> 00:32:22,960
For each event I'm getting the offset and the IP,

00:32:22,960 --> 00:32:26,098
and then I'll use GDB to tell me what's actually

00:32:26,098 --> 00:32:27,890
at this address.

00:32:27,890 --> 00:32:29,963
And I'm doing this thing here.

00:32:30,930 --> 00:32:35,823
I'm just running GDB in badge mode with this comment here,

00:32:36,690 --> 00:32:39,320
and then I'm parsing there with the output

00:32:39,320 --> 00:32:42,660
and I'm putting it in a table,

00:32:42,660 --> 00:32:44,250
which is like a chart,

00:32:44,250 --> 00:32:46,923
the places where you get the most page faults.

00:32:48,573 --> 00:32:49,943
Okay, so let's run this.

00:33:12,080 --> 00:33:13,650
So, it's a very simple program,

00:33:13,650 --> 00:33:16,750
so you apparently don't get a lot of page faults,

00:33:16,750 --> 00:33:19,940
but, yeah, you have three page faults from here,

00:33:19,940 --> 00:33:23,120
so that's in the LD.

00:33:23,120 --> 00:33:24,500
What else?

00:33:24,500 --> 00:33:26,150
Oh, page faults are basically here.

00:33:26,150 --> 00:33:29,010
So, let's do something a bit more interesting.

00:33:29,010 --> 00:33:30,300
So, instead of running

00:33:30,300 --> 00:33:34,923
with this Hello World program, we will start Firefox.

00:33:42,930 --> 00:33:47,480
Yeah, so we have to do a little bit of more so -f.

00:33:47,480 --> 00:33:51,600
I don't want to run Firefox as root but if I just do this

00:33:51,600 --> 00:33:54,280
it will attempt to run Firefox as root,

00:33:54,280 --> 00:33:56,540
and Firefox doesn't want to run as root.

00:33:56,540 --> 00:34:00,357
so I will say --user Yordan.

00:34:03,520 --> 00:34:06,810
Okay, it's no magic here,

00:34:06,810 --> 00:34:08,820
I'm just running Firefox

00:34:08,820 --> 00:34:10,600
with my normal user, not as root.

00:34:10,600 --> 00:34:13,387
- Just FYI, the option is the proc map,

00:34:13,387 --> 00:34:16,180
and the desktop user, that's still in,

00:34:16,180 --> 00:34:18,259
I don't think I've merged that upstream yet.

00:34:18,259 --> 00:34:19,092
The patches are out there, albeit--

00:34:19,092 --> 00:34:21,024
- Yeah, the patches are there, they're not--

00:34:21,024 --> 00:34:21,857
- [Man With Glasses] I delayed into merging that.

00:34:21,857 --> 00:34:23,232
That will be--

00:34:23,232 --> 00:34:24,740
- So, Firefox is starting.

00:34:24,740 --> 00:34:25,730
I don't know why I'm getting

00:34:25,730 --> 00:34:28,110
these warning messages.

00:34:28,110 --> 00:34:31,180
If I just start Firefox, I don't get these.

00:34:31,180 --> 00:34:33,003
It only shows up when I'm tracing.

00:34:36,410 --> 00:34:37,610
- I'm wondering if that dcash

00:34:37,610 --> 00:34:40,053
somehow created it as roots or something.

00:34:41,650 --> 00:34:42,483
- Maybe.

00:34:43,348 --> 00:34:45,237
And so now, running the same script

00:34:45,237 --> 00:34:49,363
on the new data file,

00:34:58,420 --> 00:35:03,390
well, see, so you have, like, 11 hundred page faults

00:35:03,390 --> 00:35:07,622
from my original location here, which is just,

00:35:07,622 --> 00:35:08,720
something is tied to libseed.

00:35:08,720 --> 00:35:12,780
And then you have 600 page faults from here.

00:35:12,780 --> 00:35:14,580
I mean, yeah, apparently Firefox

00:35:14,580 --> 00:35:17,013
creates those page faults when it starts.

00:35:18,570 --> 00:35:19,987
Okay, that's all.

00:35:19,987 --> 00:35:21,737
If you have questions--

00:35:23,810 --> 00:35:25,660
- [Woman] Nine minutes for questions.

00:35:29,350 --> 00:35:31,097
- Alright, not necessarily a question,

00:35:31,097 --> 00:35:32,810
but more of a comment.

00:35:32,810 --> 00:35:35,180
So, I'm one of the maintainers of a tool called Lisa,

00:35:35,180 --> 00:35:37,100
which is doing exactly that

00:35:37,100 --> 00:35:41,023
in terms of using Python to analyze trace outputs,

00:35:41,980 --> 00:35:42,940
and we actually use that

00:35:42,940 --> 00:35:44,280
to mostly verify what's going on

00:35:44,280 --> 00:35:45,756
on the shallow.

00:35:45,756 --> 00:35:47,510
So, I work for ARM, so we can have stuff like big.LITTLE

00:35:47,510 --> 00:35:49,690
and placing during, we have that placement

00:35:49,690 --> 00:35:52,059
because we have architecture.

00:35:52,059 --> 00:35:54,270
But seeing what we're really using

00:35:54,270 --> 00:35:57,418
is what you're introducing which is a nice interface

00:35:57,418 --> 00:36:02,190
in Python to access data from the recorded traces.

00:36:02,190 --> 00:36:04,720
Because right now what we're doing is quite ugly,

00:36:04,720 --> 00:36:06,990
is we're pass a good bit of tracing

00:36:06,990 --> 00:36:09,810
in index format, which is human-readable,

00:36:09,810 --> 00:36:11,770
so it's not made for machines, but just,

00:36:11,770 --> 00:36:15,620
someone wrote that, and we're carrying that over, there.

00:36:15,620 --> 00:36:18,590
So reading something using a data interface.

00:36:18,590 --> 00:36:22,370
But for the analysis part, maybe I can give you a demo

00:36:22,370 --> 00:36:24,530
at the break, but we have a lot of interesting

00:36:24,530 --> 00:36:27,470
and edgy stuff like wake-up legends, or see heat maps,

00:36:27,470 --> 00:36:30,440
we've been building a library for the last six years.

00:36:30,440 --> 00:36:31,570
So we have a lot of that.

00:36:31,570 --> 00:36:34,147
- Could you please join Linux Kernel,

00:36:34,147 --> 00:36:35,757
sorry, I meant to say,

00:36:35,757 --> 00:36:38,440
LinuxTraceDevel@Beager.Kernel.Org, and--

00:36:38,440 --> 00:36:41,619
- I saw that saying on that list, so.

00:36:41,619 --> 00:36:42,710
- Yeah, so please send me where,

00:36:42,710 --> 00:36:45,070
this is all in development, we could use,

00:36:45,070 --> 00:36:46,490
we want to make-- - It's in a very early stage

00:36:46,490 --> 00:36:48,180
of development right now.

00:36:48,180 --> 00:36:49,050
- Yes. - So, any help,

00:36:49,050 --> 00:36:51,823
any advice, anything is more welcome.

00:36:52,720 --> 00:36:56,250
- I also, a bit like, yeah, public service announcement.

00:36:56,250 --> 00:36:58,244
I have some issues with some people

00:36:58,244 --> 00:37:00,750
who are saying because we are doing this in Python,

00:37:00,750 --> 00:37:02,490
performance is going to be horrible.

00:37:02,490 --> 00:37:05,800
NumPy is mostly done in C and if you do it right

00:37:05,800 --> 00:37:07,150
you will get decent performance.

00:37:07,150 --> 00:37:08,710
So, for an example, I had some complaining like,

00:37:08,710 --> 00:37:11,810
oh, I had this trouble with trace, and I'm using

00:37:11,810 --> 00:37:13,610
this analysis function.

00:37:13,610 --> 00:37:17,040
The library's taking 45 seconds to process.

00:37:17,040 --> 00:37:19,841
I give up, I'm going to rewrite your thing in C++.

00:37:19,841 --> 00:37:20,674
It's going to be much better.

00:37:20,674 --> 00:37:21,630
I took an afternoon to rewrite the thing

00:37:21,630 --> 00:37:24,660
and he parses it in 500 milliseconds, so.

00:37:24,660 --> 00:37:26,780
You can have decent performance with Python

00:37:26,780 --> 00:37:29,466
if under the hood you don't have Python,

00:37:29,466 --> 00:37:30,569
which is why NumPy is all about, so.

00:37:30,569 --> 00:37:33,250
- Yeah, you have to have certain awareness

00:37:33,250 --> 00:37:35,450
of what you are doing, because even if you use

00:37:35,450 --> 00:37:40,450
NumPy erase, just try to stick with strong typing.

00:37:42,780 --> 00:37:46,280
Don't add your own lists, I mean, for example,

00:37:46,280 --> 00:37:48,380
when you loop over the data you record

00:37:48,380 --> 00:37:50,350
into some list, if you expect more

00:37:50,350 --> 00:37:53,990
than a thousand, and just this list,

00:37:53,990 --> 00:37:56,370
just switch to NumPy already.

00:37:56,370 --> 00:37:58,970
Just keep in mind what is, what has a strong type

00:37:58,970 --> 00:38:00,130
and what doesn't.

00:38:00,130 --> 00:38:04,590
I mean, that's what makes Python slow.

00:38:04,590 --> 00:38:09,590
I mean, even if you use NumPy,

00:38:10,015 --> 00:38:13,610
if you are not careful you may still have a script

00:38:13,610 --> 00:38:14,443
which is very slow.

00:38:14,443 --> 00:38:16,790
- Yeah, that's why I stripped over the data.

00:38:16,790 --> 00:38:18,939
But, we need to have this good documentation--

00:38:18,939 --> 00:38:19,833
(Yordan coughs)

00:38:19,833 --> 00:38:20,706
- [Yordan] Sorry.

00:38:20,706 --> 00:38:21,579
- If you're not doing this,

00:38:21,579 --> 00:38:22,454
if you're capable of performance.

00:38:22,454 --> 00:38:25,787
- [Yordan] I really have something here.

00:38:28,480 --> 00:38:31,220
- Just to get my head around use cases.

00:38:31,220 --> 00:38:33,730
So, imagine I used ftrace to record,

00:38:33,730 --> 00:38:36,970
tracing data to record much of different events,

00:38:36,970 --> 00:38:41,970
could I use this to then have tools that work

00:38:42,030 --> 00:38:43,730
on that capture file?

00:38:43,730 --> 00:38:45,520
For example, could I re-implement VMstat,

00:38:45,520 --> 00:38:48,750
so you run VMstat on the capture file so I can see

00:38:48,750 --> 00:38:52,430
similar metrics, things like that.

00:38:52,430 --> 00:38:54,780
- I mean, this is all a library, so, yes,

00:38:54,780 --> 00:38:56,440
you have all the access, and you may,

00:38:56,440 --> 00:38:57,620
I don't know how much you have to work on it

00:38:57,620 --> 00:38:59,900
but this is all becoming a library.

00:38:59,900 --> 00:39:04,050
The libkshark.io, everything you saw in Python,

00:39:04,050 --> 00:39:06,920
I believe there's a C interface as well.

00:39:06,920 --> 00:39:09,140
- Yeah, so-- - Actually, the C interface

00:39:09,140 --> 00:39:11,450
is recharge, I mean, the Python is just

00:39:11,450 --> 00:39:14,697
a minimum useful thing.

00:39:14,697 --> 00:39:18,425
You have much more options in the CPU directory

00:39:18,425 --> 00:39:19,964
of the C interface.

00:39:19,964 --> 00:39:20,890
- So I mean, exactly what you're looking for.

00:39:20,890 --> 00:39:23,660
You could do basically any data analysis.

00:39:23,660 --> 00:39:25,300
- It's the use case where you wanna do

00:39:25,300 --> 00:39:27,760
a black box recording, and then afterwards

00:39:27,760 --> 00:39:30,520
create a bunch of tools to analyze it in different ways

00:39:30,520 --> 00:39:31,950
you didn't think of at the time.

00:39:31,950 --> 00:39:34,600
With BPF real time tracing that I do,

00:39:34,600 --> 00:39:37,280
if I don't think of tracing something, it's gone.

00:39:37,280 --> 00:39:39,530
But with black box recording I trace

00:39:39,530 --> 00:39:41,990
a bunch of events and then afterwards I can think

00:39:41,990 --> 00:39:45,170
of a new tool or a new analysis technique.

00:39:45,170 --> 00:39:47,450
- Yes, I mean if you have the data in there

00:39:47,450 --> 00:39:48,750
and just the trace.dat file in there,

00:39:48,750 --> 00:39:49,810
because that's actually,

00:39:49,810 --> 00:39:51,100
actually something that happened was

00:39:51,100 --> 00:39:52,920
I had trace.dat file and I went,

00:39:52,920 --> 00:39:56,190
wait, if I look for these things,

00:39:56,190 --> 00:39:57,023
I didn't even think about it

00:39:57,023 --> 00:39:58,496
while I did the recording.

00:39:58,496 --> 00:39:59,730
I just recorded a bunch of events and everything.

00:39:59,730 --> 00:40:02,433
And later I said, wait, I need to analyze something,

00:40:02,433 --> 00:40:06,410
that was like a wake up, or some path of, I wanted to follow

00:40:06,410 --> 00:40:07,410
like, inner ups going up

00:40:07,410 --> 00:40:11,020
and saying, where was this happening?

00:40:11,020 --> 00:40:13,150
I just wrote a script that, well,

00:40:13,150 --> 00:40:16,280
I used libtrace event to just attach everything

00:40:16,280 --> 00:40:18,540
and read the data and just do my analysis

00:40:18,540 --> 00:40:20,323
at a later time, so.

00:40:20,323 --> 00:40:22,680
The data's there.

00:40:22,680 --> 00:40:23,730
You can do whatever you want with it

00:40:23,730 --> 00:40:24,563
once you have the data.

00:40:24,563 --> 00:40:27,190
But you can't go back and, say, add more data to it,

00:40:27,190 --> 00:40:28,340
after you've recorded it.

00:40:28,340 --> 00:40:29,590
- Okay, that makes sense.

00:40:34,664 --> 00:40:35,530
- This is all-- - Maybe if I

00:40:35,530 --> 00:40:37,340
can add something.

00:40:37,340 --> 00:40:39,860
Basically, you have two different approaches.

00:40:39,860 --> 00:40:41,830
And the first thing is,

00:40:41,830 --> 00:40:44,060
I know what I'm looking for.

00:40:44,060 --> 00:40:46,360
I'm very confident that I understand what's going on.

00:40:46,360 --> 00:40:49,000
So I will record the minimum amount of data

00:40:49,000 --> 00:40:50,500
that will answer my question.

00:40:50,500 --> 00:40:53,440
And this includes, you can do, I mean,

00:40:53,440 --> 00:40:55,040
online processing via data

00:40:55,040 --> 00:40:58,260
like the processing code in Ftrace is doing, so,

00:40:58,260 --> 00:41:00,400
you directly calculate your,

00:41:00,400 --> 00:41:02,710
fill your histograms when you record.

00:41:02,710 --> 00:41:04,170
And everything that is not related

00:41:04,170 --> 00:41:06,000
to your histogram, this data is just lost.

00:41:06,000 --> 00:41:08,010
But because you are confident

00:41:08,010 --> 00:41:09,490
that you know what you are doing,

00:41:09,490 --> 00:41:10,590
you don't care.

00:41:10,590 --> 00:41:12,520
But if you don't know what you're doing,

00:41:12,520 --> 00:41:14,815
that approach, just record as much as you can

00:41:14,815 --> 00:41:17,640
and then you figure out what's going on

00:41:17,640 --> 00:41:18,880
with all this data.

00:41:18,880 --> 00:41:21,910
Of course, in this case it's not

00:41:21,910 --> 00:41:23,480
that efficient, first of all.

00:41:23,480 --> 00:41:26,880
You get a lot of data which most probably

00:41:26,880 --> 00:41:28,641
is just useless for you.

00:41:28,641 --> 00:41:32,960
Also, you have this Heisenberg Programme which, I mean,

00:41:32,960 --> 00:41:35,710
because you do a lot, you actually change the thing

00:41:35,710 --> 00:41:37,952
that you are trying to observe.

00:41:37,952 --> 00:41:41,090
Maybe, I think that this approach

00:41:41,090 --> 00:41:42,370
is good for prototyping,

00:41:42,370 --> 00:41:44,270
just to understand what's going on,

00:41:44,270 --> 00:41:46,780
to get an idea, and then you probably go

00:41:46,780 --> 00:41:49,320
to another code for you to record less

00:41:49,320 --> 00:41:50,970
and more efficiently.

00:41:50,970 --> 00:41:51,803
- I mean, you do, you record,

00:41:51,803 --> 00:41:53,823
what I usually do is I'll record everything

00:41:53,823 --> 00:41:56,570
and then say, oh, there's a lot of this stuff

00:41:56,570 --> 00:41:58,600
I don't care about, and then just turn all those off

00:41:58,600 --> 00:42:00,159
and do the recording.

00:42:00,159 --> 00:42:02,070
That's all.

00:42:02,070 --> 00:42:04,493
- So, we have, last question.

00:42:07,830 --> 00:42:09,440
- Regarding the libkshark,

00:42:09,440 --> 00:42:12,400
have you considered making an input plugin

00:42:13,473 --> 00:42:14,306
for the bubble trace?

00:42:14,306 --> 00:42:17,623
Because we're talking about unifying the trace format

00:42:17,623 --> 00:42:21,631
instead of adding to create yet another trace API

00:42:21,631 --> 00:42:23,921
and, have you looked at that?

00:42:23,921 --> 00:42:24,754
- Well, yes, absolutely.

00:42:24,754 --> 00:42:26,719
Actually, that's one of the reasons why

00:42:26,719 --> 00:42:30,100
the library is not officially called the library yet.

00:42:30,100 --> 00:42:33,900
That's one of the weaknesses of our original API.

00:42:33,900 --> 00:42:38,580
Because we wanted to have the input data abstracted.

00:42:38,580 --> 00:42:43,020
So we can actually fill the model with just

00:42:43,020 --> 00:42:45,881
arbitrary data format.

00:42:45,881 --> 00:42:48,400
But it turns out that the first version

00:42:48,400 --> 00:42:50,530
of the API that we implemented,

00:42:50,530 --> 00:42:53,057
there are problems in there, so that's one

00:42:53,057 --> 00:42:56,560
of the reasons why we are modifying the API right now.

00:42:56,560 --> 00:42:58,840
But yeah, with the new version of the API

00:42:58,840 --> 00:43:01,760
which will be in KernelShark 2, the input

00:43:01,760 --> 00:43:02,890
is completely abstracted.

00:43:02,890 --> 00:43:04,870
And you can merge different inputs.

00:43:04,870 --> 00:43:09,470
So you can have one trace CMD, trace.dat file,

00:43:10,850 --> 00:43:12,135
you can merge this thing

00:43:12,135 --> 00:43:16,170
with a bow tracer data file.

00:43:16,170 --> 00:43:19,290
Actually, because VMware has a,

00:43:19,290 --> 00:43:21,730
they have their own tracer for the hypervisor

00:43:21,730 --> 00:43:24,102
which records in a different format

00:43:24,102 --> 00:43:27,880
and we want to merge the format from the hypervisor

00:43:27,880 --> 00:43:31,220
and the guess together, and I'll be demonstrating

00:43:31,220 --> 00:43:33,020
this in Lisbon.

00:43:33,020 --> 00:43:35,952
So, yeah, we have to merge different data formats

00:43:35,952 --> 00:43:36,860
in this one.

00:43:36,860 --> 00:43:41,337
- Real quick, real quick, one question.

00:43:41,337 --> 00:43:42,170
Once you've got the universal tracing API,

00:43:42,170 --> 00:43:43,010
how long 'till you have

00:43:43,010 --> 00:43:44,760
the universal tracing library done?

00:43:45,959 --> 00:43:48,376
(Yordan laughs)

00:43:48,376 --> 00:43:49,520
- [Bald Man] It's the full one.

00:43:49,520 --> 00:43:51,780
- [Woman] That's all the time we have.

00:43:52,892 --> 00:43:55,136

YouTube URL: https://www.youtube.com/watch?v=u4UQw7vu1i8


