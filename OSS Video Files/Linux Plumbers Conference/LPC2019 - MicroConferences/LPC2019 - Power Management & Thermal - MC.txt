Title: LPC2019 - Power Management & Thermal - MC
Publication date: 2019-11-18
Playlist: LPC2019 - MicroConferences
Description: 
	Power Management & Thermal - MC
Captions: 
	00:00:00,330 --> 00:00:04,970
- This micro conference is about thermal zones hierarchy.

00:00:07,330 --> 00:00:10,620
So this topic was already addressed last time,

00:00:10,620 --> 00:00:15,080
we discussed but we don't reach a consensus.

00:00:15,080 --> 00:00:18,020
We don't agree on something

00:00:18,020 --> 00:00:21,220
and I wanted to discuss again about that

00:00:21,220 --> 00:00:23,290
so we can have some progress,

00:00:23,290 --> 00:00:25,140
on how we can represent the thermal zone.

00:00:25,140 --> 00:00:28,980
So it's not about dealing with all the thermal zone

00:00:28,980 --> 00:00:32,710
and taking decision, but just hope we can organize that,

00:00:32,710 --> 00:00:37,710
to have in the resulting code to be clean.

00:00:40,467 --> 00:00:45,467
So why do we need to to make this more order?

00:00:45,780 --> 00:00:49,010
Is because yesterday if we look at the code,

00:00:49,010 --> 00:00:52,412
we have upstream, I'm not talking about out stream

00:00:52,412 --> 00:00:57,412
out of tree Linux connect but just the upstream connect,

00:00:58,040 --> 00:01:02,820
we have one or two thermal zones defined,

00:01:02,820 --> 00:01:05,710
and now we have boards coming with more than,

00:01:05,710 --> 00:01:10,710
the biggest number I saw is 21 thermal zones.

00:01:11,740 --> 00:01:14,570
So it's a lot of sensors and we have

00:01:14,570 --> 00:01:16,180
to deal with all the sensor list

00:01:16,180 --> 00:01:19,500
and then same time and take some decisions.

00:01:19,500 --> 00:01:23,750
So what we want to do with all these sensors

00:01:23,750 --> 00:01:27,720
is first we want to have some kind of a description

00:01:27,720 --> 00:01:32,720
giving a topology which is, even if it's not perfect,

00:01:33,020 --> 00:01:34,920
at least it gives us an indication

00:01:36,510 --> 00:01:39,530
which is close to the reality.

00:01:39,530 --> 00:01:42,690
Also by giving this relationship

00:01:42,690 --> 00:01:46,260
between all we build a new hierarchy,

00:01:46,260 --> 00:01:50,670
we can also organize the thermal zone

00:01:50,670 --> 00:01:53,130
and detect where are the hot spots

00:01:53,130 --> 00:01:56,650
and if there is a relationship between the different nodes

00:01:56,650 --> 00:02:00,170
and if they can interact with the temperature.

00:02:01,700 --> 00:02:04,980
Also by grouping the thermal zone with this hierarchy,

00:02:04,980 --> 00:02:09,980
we can, they have one governor using one node,

00:02:11,400 --> 00:02:16,400
while beginning to, under all the descendant of this node

00:02:17,337 --> 00:02:21,950
it's not representing a thermal zone and deal with them.

00:02:21,950 --> 00:02:25,105
And also it's a way to represent what we have,

00:02:25,105 --> 00:02:28,720
legacy system where we have a spanning sensors.

00:02:28,720 --> 00:02:32,900
So if we want to extend the current framework,

00:02:34,670 --> 00:02:37,960
we need to create a tree representation

00:02:40,050 --> 00:02:43,980
so that the good thing is,

00:02:43,980 --> 00:02:46,560
it's compatible with the current representation

00:02:46,560 --> 00:02:48,310
which is a flat representation.

00:02:49,750 --> 00:02:52,310
This representation give us a good indication,

00:02:52,310 --> 00:02:56,990
about the topology and also it's a way

00:02:56,990 --> 00:03:00,160
to give a centralized view to a specific governor.

00:03:01,270 --> 00:03:06,270
We said, we will be able to act on all the nodes,

00:03:06,748 --> 00:03:08,590
we dug into this tree.

00:03:09,990 --> 00:03:14,020
That means for a current framework,

00:03:14,020 --> 00:03:16,890
we have the thermal zones

00:03:16,890 --> 00:03:19,300
and this thermal zone can be without sensors.

00:03:20,380 --> 00:03:24,230
So we break this paradigm saying,

00:03:24,230 --> 00:03:25,830
we have a thermal zone, a sensor

00:03:28,689 --> 00:03:31,940
and also a cooling device assigned to it or a governor.

00:03:31,940 --> 00:03:35,390
So that means that this entity is alone

00:03:38,824 --> 00:03:40,410
and we can add a sensor

00:03:42,157 --> 00:03:44,130
or cooling device or governor, but it's optional.

00:03:44,130 --> 00:03:48,400
And also we cannot give a weight to the nodes

00:03:50,000 --> 00:03:53,780
of the thermal zone saying how much they contribute.

00:03:53,780 --> 00:03:54,800
Yes?

00:03:54,800 --> 00:03:57,290
- [Attendant] So, you know we discussed this many times.

00:03:57,290 --> 00:03:58,759
- Yes.

00:03:58,759 --> 00:04:00,650
- Why you want to call thermal zone,

00:04:00,650 --> 00:04:02,550
you should call thermal sensor.

00:04:02,550 --> 00:04:04,340
And let Zone B you know.

00:04:04,340 --> 00:04:05,530
- [John] What is the sensor?

00:04:05,530 --> 00:04:08,130
- A sensor, a thermal zone without sensor,

00:04:08,130 --> 00:04:09,350
it doesn't make sense right?

00:04:09,350 --> 00:04:12,120
Thermal zone is basically its own with many sensors.

00:04:13,710 --> 00:04:14,800
Like you know.

00:04:14,800 --> 00:04:15,633
- [John] No.

00:04:15,633 --> 00:04:17,140
- Because if zone is that you know like an ACPI

00:04:17,140 --> 00:04:19,310
if you define like, a zone is a part of like

00:04:19,310 --> 00:04:21,270
it's a surface is a zone, right.

00:04:21,270 --> 00:04:22,342
- [John] Yeah.

00:04:22,342 --> 00:04:23,830
- That surface can have five sensors.

00:04:23,830 --> 00:04:27,760
- Yeah but we keep the relationship one to one,

00:04:27,760 --> 00:04:30,540
that means one thermal zone is ones and so--

00:04:30,540 --> 00:04:32,320
- [Attendee] But that's the--

00:04:32,320 --> 00:04:37,320
- I agree we can, we can say okay to sensor

00:04:37,740 --> 00:04:39,610
but in this, in this representation

00:04:39,610 --> 00:04:43,000
is the thermal zone as one sensor and we build a tree.

00:04:44,334 --> 00:04:47,550
- So the question, maybe one of the

00:04:47,550 --> 00:04:50,870
primary questions that I have with this approach is,

00:04:50,870 --> 00:04:53,540
why do you need to represent the topology?

00:04:55,320 --> 00:04:57,550
I mean let's step back and go on

00:04:57,550 --> 00:05:00,420
problem statement first, right.

00:05:00,420 --> 00:05:02,679
Why do you need to represent that

00:05:02,679 --> 00:05:04,770
the topology of sensors here?

00:05:04,770 --> 00:05:06,680
What you are gonna do with that information?

00:05:08,192 --> 00:05:12,250
- So if we can have give a weight to thermal zones

00:05:12,250 --> 00:05:14,260
and you present, you represent

00:05:15,260 --> 00:05:19,710
the different thermal zones with this hierarchy

00:05:19,710 --> 00:05:23,190
then you can have a representation

00:05:23,190 --> 00:05:27,430
of how the different sensor

00:05:28,460 --> 00:05:31,710
are grouped for a single entity

00:05:31,710 --> 00:05:35,050
like cluster zero which in turn

00:05:35,050 --> 00:05:37,370
can be grouped the odd cluster for CPU.

00:05:39,260 --> 00:05:40,540
Let me give an example.

00:05:45,420 --> 00:05:50,420
So let's imagine we have one sensor on each course

00:05:52,260 --> 00:05:54,960
but we don't have a sensor for the cluster

00:05:54,960 --> 00:05:57,090
and we want a way to group them,

00:05:57,090 --> 00:06:00,260
we can do a virtual sensor also, but see--

00:06:00,260 --> 00:06:01,093
- That's the point.

00:06:01,093 --> 00:06:02,400
That's why we were saying if you

00:06:02,400 --> 00:06:04,440
do present those bottom circles

00:06:04,440 --> 00:06:07,290
as a sensor and thermal zone has weight

00:06:07,290 --> 00:06:09,510
of dependency on sensors,

00:06:09,510 --> 00:06:11,620
you can define individual weights of each sensor

00:06:11,620 --> 00:06:14,860
and you can have a virtual sensor a pair clustered.

00:06:14,860 --> 00:06:17,060
- Yes, but at the end we end up

00:06:17,060 --> 00:06:18,860
with a new hierarchy, right.

00:06:18,860 --> 00:06:22,433
- [Attendee] Yeah, yeah, you will have a new hierarchy.

00:06:22,433 --> 00:06:23,390
- So you mean it's a hierarchy of sensor

00:06:23,390 --> 00:06:25,280
or it's a hierarchy of thermal zones?

00:06:25,280 --> 00:06:26,980
- A hierarchy of sensor and zones.

00:06:27,830 --> 00:06:31,340
The sensor is like thermal zone, can't have optional,

00:06:31,340 --> 00:06:34,176
like as I said before, don't have to have temperature.

00:06:34,176 --> 00:06:35,570
- [John] Don't, I'm sorry.

00:06:35,570 --> 00:06:38,920
- Don't have to have temperature, right.

00:06:38,920 --> 00:06:42,420
So thermal zone is a combination of sensors.

00:06:42,420 --> 00:06:44,120
So each sensor will have a definitely

00:06:44,120 --> 00:06:46,630
have must have a set temperature

00:06:46,630 --> 00:06:48,480
and the cluster can be virtual, John.

00:06:49,620 --> 00:06:50,453
- Yes. - Right.

00:06:51,573 --> 00:06:53,400
- Yeah, I mean the way that he is going

00:06:53,400 --> 00:06:55,470
is a little bit simpler than what you're proposing.

00:06:55,470 --> 00:06:58,840
I still don't see why, you may depend on

00:06:58,840 --> 00:07:00,650
what's the post that you want to build over there

00:07:00,650 --> 00:07:03,170
but if you have a hot spot on the plus zero

00:07:03,170 --> 00:07:04,830
and you want to represent that, you can just

00:07:04,830 --> 00:07:08,130
have a little sensor that is say set, I mean,

00:07:08,130 --> 00:07:11,630
it's based off of a set of the sensors that he has here.

00:07:11,630 --> 00:07:13,320
I mean it doesn't need to be limited

00:07:13,320 --> 00:07:15,930
to the sensors that are on the cluster though.

00:07:15,930 --> 00:07:17,170
Even if you have like something

00:07:17,170 --> 00:07:19,460
which represents the hot spot which is even outside,

00:07:19,460 --> 00:07:21,580
some I have seen that weird stuff already.

00:07:22,810 --> 00:07:27,090
People put like a thermistor close to the chip

00:07:28,030 --> 00:07:33,030
that represents better the hot spot than the internal ones.

00:07:33,550 --> 00:07:37,040
So I mean it's not necessarily that you have to

00:07:37,040 --> 00:07:39,910
build like a hierarchy to represent the hot spot.

00:07:41,490 --> 00:07:44,580
I still don't see why you want to build in a hierarchal way.

00:07:46,160 --> 00:07:49,590
I see that, yeah, it does represent how the system is built.

00:07:49,590 --> 00:07:51,570
But what you're gonna do with it?

00:07:51,570 --> 00:07:54,707
- So now if you want to have a governor dealing with

00:07:54,707 --> 00:07:57,950
all this sensors, thermal zone, whatever,

00:07:59,710 --> 00:08:02,920
because of all these design the current framework.

00:08:02,920 --> 00:08:04,650
We have at thermal zone, we have a sensor,

00:08:04,650 --> 00:08:06,240
we have a governor.

00:08:06,240 --> 00:08:10,180
By using the thermal zone hierarchy,

00:08:10,180 --> 00:08:11,970
which is a representation,

00:08:11,970 --> 00:08:15,320
it's the encapsulation of the sensor.

00:08:17,450 --> 00:08:20,090
- Yeah, today we have a one one bad representation.

00:08:20,090 --> 00:08:20,923
- Yes.

00:08:20,923 --> 00:08:24,063
So the idea is we we keep the thermal zone

00:08:24,063 --> 00:08:28,510
which is virtual and it aggregates thermal zone

00:08:28,510 --> 00:08:32,266
having one sensor, and that's the example.

00:08:32,266 --> 00:08:35,920
For example, here.

00:08:35,920 --> 00:08:37,880
- So one clarifying question for

00:08:37,880 --> 00:08:41,119
the notes that I'm trying to take.

00:08:41,119 --> 00:08:46,119
Do you mean, do you want to have one sensor per zone?

00:08:47,270 --> 00:08:48,970
Is this what you are proposing?

00:08:48,970 --> 00:08:49,803
- [John] Yes.

00:08:49,803 --> 00:08:53,423
- One sensor per zone and then have a hierarchy of zones?

00:08:53,423 --> 00:08:54,510
- [John] Yes.

00:08:54,510 --> 00:08:55,550
- That's what you are saying?

00:08:55,550 --> 00:08:56,900
- Okay. - Yes.

00:08:56,900 --> 00:09:01,410
And for example here, you can have all the course

00:09:01,410 --> 00:09:06,410
having a sensor and then cluster zero does not have a sensor

00:09:06,530 --> 00:09:09,150
but when you read the temperature of cluster zero,

00:09:09,150 --> 00:09:11,900
it aggregates so that the temperature of all the other.

00:09:13,190 --> 00:09:17,270
We can, of course, we can create a virtual sensor

00:09:17,270 --> 00:09:21,530
inside this thermal zone, aggregating the sensor

00:09:21,530 --> 00:09:23,650
of the child zone, if you just--

00:09:24,507 --> 00:09:26,486
- There are even like drivers that do that already.

00:09:26,486 --> 00:09:27,319
- Sorry.

00:09:27,319 --> 00:09:29,670
- There is drivers that do that.

00:09:29,670 --> 00:09:31,600
- There are drivers doing that

00:09:31,600 --> 00:09:34,070
but if you look at the code of its design,

00:09:34,070 --> 00:09:36,580
it's about design because it's the same,

00:09:36,580 --> 00:09:38,590
at the end is the same how we represent that.

00:09:38,590 --> 00:09:39,423
- Right.

00:09:39,423 --> 00:09:42,650
- But if we look at all the thermal zone,

00:09:42,650 --> 00:09:46,330
the thermal zone can be built in hierarchy

00:09:46,330 --> 00:09:49,410
and when you call get thermal zone temperature,

00:09:50,560 --> 00:09:53,850
it's much more the impact on the code

00:09:53,850 --> 00:09:58,850
in the core framework is less than having a virtual sensor

00:09:59,460 --> 00:10:01,780
and trying to do or get temperature

00:10:01,780 --> 00:10:03,620
from one sensor to other sensors,

00:10:03,620 --> 00:10:05,520
to a virtual sensor to other sensors.

00:10:05,520 --> 00:10:08,660
It's much simpler to write a thermal zone

00:10:09,650 --> 00:10:14,040
saying when I asked to get me the temperature,

00:10:14,040 --> 00:10:17,880
it will ask the older child thermal zone temperature

00:10:17,880 --> 00:10:20,640
and do the aggregation without having a virtual sensor.

00:10:22,066 --> 00:10:25,320
- Like a comment, if you say that something is easier

00:10:25,320 --> 00:10:26,790
than something else it would be good

00:10:26,790 --> 00:10:31,510
to give an example of when it takes place.

00:10:31,510 --> 00:10:34,280
Like do you have a specific example in mind,

00:10:34,280 --> 00:10:37,950
like when an implementation of a zone may be simpler

00:10:37,950 --> 00:10:41,300
than an implementation of a visual sensor?

00:10:41,300 --> 00:10:45,310
- [John] I think it's about code, so I have a patch.

00:10:45,310 --> 00:10:48,240
I can send the patch but.

00:10:48,240 --> 00:10:49,800
- Okay, so.

00:10:49,800 --> 00:10:51,610
- So let me get example, like for example

00:10:51,610 --> 00:10:54,010
in your cluster zero with one sensor.

00:10:54,010 --> 00:10:55,980
Also, you know like in your case cluster,

00:10:55,980 --> 00:10:58,110
like in our case example, I give you,

00:10:58,110 --> 00:11:00,190
we have it like same temperature sensor

00:11:00,190 --> 00:11:03,130
on a CPU but that temperature sensor

00:11:03,130 --> 00:11:06,370
also affects like a surface skin.

00:11:07,221 --> 00:11:09,380
So same sensor will be in cluster one

00:11:09,380 --> 00:11:11,630
and cluster zero in your example.

00:11:12,580 --> 00:11:14,810
How do you, how do you replicate here or?

00:11:15,980 --> 00:11:17,330
So suppose one sensor here--

00:11:17,330 --> 00:11:19,300
- [John] Something like that?

00:11:19,300 --> 00:11:20,840
So you have a sensor on cluster zero

00:11:20,840 --> 00:11:21,830
and sensor on cluster one.

00:11:21,830 --> 00:11:26,069
- Same sensor is used in multiple, in the middle.

00:11:26,069 --> 00:11:27,140
- [John] It's the same.

00:11:27,140 --> 00:11:28,900
- So you would have an arrow also, for example,

00:11:28,900 --> 00:11:31,325
from cluster one to two-- - Also on the cluster one.

00:11:31,325 --> 00:11:32,158
It's here.

00:11:32,158 --> 00:11:34,150
- No, from cluster one, you will have an arrow

00:11:34,150 --> 00:11:36,950
from cluster one to one of the children of cluster zero.

00:11:39,870 --> 00:11:41,110
So across--

00:11:41,110 --> 00:11:42,147
- [Attendee] No.

00:11:42,147 --> 00:11:42,980
- Cross reference, sorry.

00:11:42,980 --> 00:11:44,278
- [Attendee] Yeah, from here.

00:11:44,278 --> 00:11:45,111
- Either way?

00:11:45,111 --> 00:11:46,528
- [Attendee] Yes.

00:11:47,540 --> 00:11:50,570
So if you represent them as a sensor

00:11:50,570 --> 00:11:52,850
and then the zone as a formula of sensors,

00:11:52,850 --> 00:11:54,550
then you can, it's logical.

00:11:54,550 --> 00:11:56,130
- [Attendee] It's more logical, yeah.

00:11:56,130 --> 00:11:57,780
- Right.

00:11:57,780 --> 00:11:58,850
- [Attendee] I mean I think the--

00:11:58,850 --> 00:12:00,730
- You'll achieve the same purpose.

00:12:00,730 --> 00:12:04,710
- The 101 representation, it kind of limits us, right,

00:12:05,617 --> 00:12:08,680
and drives us to do these kind of weird hacks of,

00:12:08,680 --> 00:12:12,029
okay, let's have multiple zones on top of each other.

00:12:12,029 --> 00:12:15,240
But if we split the zone from sensor concept,

00:12:16,750 --> 00:12:18,860
I think evenly makes easier, for example,

00:12:18,860 --> 00:12:23,860
to aggregate or to connect with half or more, for example,

00:12:24,460 --> 00:12:26,560
if we have a better representation

00:12:26,560 --> 00:12:29,570
of a set thermal sensor that's using in thermal zone.

00:12:29,570 --> 00:12:31,960
- [Attendee] And you will achieve the same purpose, right.

00:12:31,960 --> 00:12:34,010
- I think we've reached the same goal.

00:12:34,010 --> 00:12:35,760
- [Attendee] Yeah, same goal, yeah.

00:12:37,998 --> 00:12:39,490
- So instead of calling that

00:12:39,490 --> 00:12:40,420
thermal zone. - Thermal zone.

00:12:40,420 --> 00:12:41,550
- You want to call that

00:12:41,550 --> 00:12:43,200
sensors? - Thermal sensors, yeah.

00:12:43,200 --> 00:12:45,580
Which has only temperature with no thresholds,

00:12:45,580 --> 00:12:48,680
no, what's the called, trip points, no trip points.

00:12:48,680 --> 00:12:50,626
- Trip points finish and so on.

00:12:50,626 --> 00:12:52,045
- Yeah.

00:12:52,045 --> 00:12:55,730
You can have a temperature notification limit.

00:12:55,730 --> 00:12:57,120
That's fine, but not the,

00:12:58,020 --> 00:13:01,090
the trip point set as at the zone there.

00:13:01,090 --> 00:13:04,510
- So basically your suggestion will be to define sensors

00:13:04,510 --> 00:13:06,230
as something that measures temperature

00:13:06,230 --> 00:13:10,350
and zones, that something that applies certain limits

00:13:10,350 --> 00:13:11,910
or trip points on those thing.

00:13:13,188 --> 00:13:14,021
- Sensors, combination of sensors.

00:13:15,096 --> 00:13:17,010
- On the combination of sensors, okay.

00:13:17,010 --> 00:13:17,890
- Right.

00:13:17,890 --> 00:13:21,284
- If we take the example of, we have--

00:13:21,284 --> 00:13:24,700
- And then again, I mean, you can plug in

00:13:24,700 --> 00:13:29,660
a sensor on multiple zones as well.

00:13:29,660 --> 00:13:32,084
- So doing spanning sensors.

00:13:32,084 --> 00:13:34,330
- Yeah, that's a lanoff.

00:13:34,330 --> 00:13:36,750
- Sensors are expensive, right, people need to pay money,

00:13:36,750 --> 00:13:39,330
in the virtual is free so they can,

00:13:39,330 --> 00:13:42,990
so that's what they've tried to do, same sensor, use, reuse.

00:13:44,260 --> 00:13:49,260
- So from the program programming okay,

00:13:50,110 --> 00:13:51,720
recording inside the kernel.

00:13:51,720 --> 00:13:52,553
- Yes.

00:13:52,553 --> 00:13:55,820
- So let's imagine you have cluster zero.

00:13:55,820 --> 00:13:57,520
Cluster zero is aggregating.

00:13:57,520 --> 00:14:00,360
You have a virtual sensor there, okay.

00:14:00,360 --> 00:14:04,847
And then you ask the temperature of this thermal zone.

00:14:04,847 --> 00:14:07,990
It will call the temperature of the sensor,

00:14:07,990 --> 00:14:09,840
which is a virtual sensor.

00:14:09,840 --> 00:14:14,310
And this virtual sensor, what will it call?

00:14:14,310 --> 00:14:16,670
The directly the sensor will get temperature call back,

00:14:16,670 --> 00:14:21,090
or will we call to get temperature from the thermal zone?

00:14:21,090 --> 00:14:25,310
- So essentially my kind of vision at this point

00:14:25,310 --> 00:14:27,850
would be that, you have a zone

00:14:27,850 --> 00:14:32,180
that has a list of sensors and then there is a function.

00:14:32,180 --> 00:14:33,013
- Right.

00:14:33,013 --> 00:14:34,700
- Which you have to apply to those sensors

00:14:34,700 --> 00:14:35,850
to get the temperature.

00:14:38,340 --> 00:14:40,310
- And that function can be you know polynomial

00:14:40,310 --> 00:14:42,130
or set off the sensors.

00:14:43,120 --> 00:14:46,620
- [John] So you, the paradigm of having one sensor,

00:14:46,620 --> 00:14:50,257
one thermal zone, you break this this paradigm.

00:14:50,257 --> 00:14:51,610
- You can have it.

00:14:51,610 --> 00:14:52,620
This can still represent.

00:14:52,620 --> 00:14:54,750
- I mean you would have like one thermal zone

00:14:54,750 --> 00:14:58,490
has one aggregated value at the moment, right,

00:14:58,490 --> 00:15:00,855
which is the output of that function.

00:15:00,855 --> 00:15:03,990
- Yeah if you want you can have one doing two.

00:15:03,990 --> 00:15:07,370
- But it's not the one thermal zone to one sensor anymore.

00:15:12,190 --> 00:15:15,590
- And do you represent the physically

00:15:15,590 --> 00:15:19,340
the meaning of the thermal zones, the sensors?

00:15:19,340 --> 00:15:20,860
- Then that's back to my first question,

00:15:20,860 --> 00:15:22,560
why do you want to represent that?

00:15:23,850 --> 00:15:27,890
- Conceptually I find it's a better representation.

00:15:27,890 --> 00:15:30,960
- I mean unless, I mean, yeah I kind of agree with that

00:15:30,960 --> 00:15:34,260
but if you are not solving any problem, why brother?

00:15:35,780 --> 00:15:38,550
What's the problem that you're solving, right?

00:15:38,550 --> 00:15:40,860
You have like, what, at the end of the day

00:15:40,860 --> 00:15:43,560
what you want to do here, is like represent hot spots.

00:15:44,410 --> 00:15:45,478
- Okay.

00:15:45,478 --> 00:15:46,625
- And then take control of that.

00:15:46,625 --> 00:15:50,090
- So if we have a governor and we want this governor

00:15:50,090 --> 00:15:54,700
to deal with different thermal zone or different sensors.

00:15:54,700 --> 00:15:56,870
- Right, then I think then that question

00:15:56,870 --> 00:16:00,130
becomes a similar question of,

00:16:00,130 --> 00:16:05,130
how do we aggregate to a governor, multiple zones, right.

00:16:06,550 --> 00:16:09,360
Then I think to get to the point where you want to solve

00:16:09,360 --> 00:16:11,260
the problems that you are proposing here,

00:16:11,260 --> 00:16:13,380
then we would have like a thermal zone,

00:16:13,380 --> 00:16:15,870
can have aggregation of multiple sensors,

00:16:15,870 --> 00:16:19,110
and a governor should have access to multiple thermal zones.

00:16:21,820 --> 00:16:22,653
Then you don't need

00:16:22,653 --> 00:16:26,340
the physical representation of the hierarchy.

00:16:34,750 --> 00:16:39,290
- So now you have to apply some cooling effect.

00:16:39,290 --> 00:16:41,850
An example, how do you split that, I mean,

00:16:41,850 --> 00:16:44,450
you say that you want lead the cluster zero

00:16:44,450 --> 00:16:49,110
to all the CPU to only consume a number of what?

00:16:49,110 --> 00:16:50,440
And then you will have to split that.

00:16:50,440 --> 00:16:52,530
If you don't know how is the hierarchy,

00:16:52,530 --> 00:16:55,410
how you can split them in this barber jet

00:16:55,410 --> 00:16:59,170
in smaller barber jet for each zone, a sensor,

00:16:59,170 --> 00:17:00,700
if you don't have the hierarchy?

00:17:01,927 --> 00:17:05,420
(faintly speaking)

00:17:05,420 --> 00:17:06,780
No, it's not across the zone.

00:17:06,780 --> 00:17:08,250
- Mic, mic.

00:17:08,250 --> 00:17:10,030
- So the power locator governor,

00:17:10,030 --> 00:17:12,580
you already have a different one budget

00:17:12,580 --> 00:17:17,100
with many zones, right.

00:17:17,100 --> 00:17:19,480
Like yeah like CPU, CPU you're already doing.

00:17:19,480 --> 00:17:22,630
- No, I agree for that but then between the CPU

00:17:22,630 --> 00:17:25,980
are you split the CPU budget between cluster zero

00:17:25,980 --> 00:17:30,340
and cluster one, between CPU zero and one, up to eight.

00:17:30,340 --> 00:17:32,970
At the point, if you don't have the dependency

00:17:32,970 --> 00:17:36,050
between the CPU sensor to the cluster,

00:17:36,910 --> 00:17:38,060
how you can split that?

00:17:39,560 --> 00:17:40,600
I mean what you have right now,

00:17:40,600 --> 00:17:42,660
you have three independent thermal zone

00:17:42,660 --> 00:17:45,010
which are CPU graphic and peripherals,

00:17:45,010 --> 00:17:46,900
and you split that quite easily.

00:17:46,900 --> 00:17:50,808
But then if you go, if you want to go one more level below,

00:17:50,808 --> 00:17:53,330
I mean for all the CPU, how do you,

00:17:53,330 --> 00:17:56,720
how can you split the budget between all the CPU?

00:17:56,720 --> 00:17:59,480
Because maybe one is operating more than another one,

00:17:59,480 --> 00:18:01,630
so maybe the power budget can be different.

00:18:02,630 --> 00:18:05,630
If you don't have the topology, you don't have any,

00:18:05,630 --> 00:18:07,530
you can't make any decision like that.

00:18:10,290 --> 00:18:14,380
- I mean, the way that I see this, you would have,

00:18:15,810 --> 00:18:19,180
once again back to your example right, so you would have

00:18:19,180 --> 00:18:24,180
like multiple thermal zones, one per cluster, can you,

00:18:27,790 --> 00:18:30,140
one per cluster and then you would have like a,

00:18:32,549 --> 00:18:34,096
as a Shunua was saying, right,

00:18:34,096 --> 00:18:38,120
on the power locator we have the power consumption entity

00:18:38,120 --> 00:18:42,260
that represents the consumption of each zone.

00:18:44,850 --> 00:18:48,860
It doesn't, I mean, I don't think you would need to have

00:18:48,860 --> 00:18:51,800
the aggregation or the contribution of each sensor,

00:18:51,800 --> 00:18:55,260
but you would need to have the power consumption

00:18:55,260 --> 00:18:58,050
for each zone and then that's it

00:18:58,050 --> 00:18:59,550
at the level of the zone.

00:19:01,298 --> 00:19:04,830
(faintly speaking)

00:19:04,830 --> 00:19:06,078
Right.

00:19:06,078 --> 00:19:09,590
- Yeah, we can't hear you.

00:19:09,590 --> 00:19:14,170
- At the level one your whatever your power locator governor

00:19:14,170 --> 00:19:17,130
will divide in CPU graphics and peripherals,

00:19:17,130 --> 00:19:19,590
and the second level power budget of CPU

00:19:19,590 --> 00:19:21,280
will be divided among them, right.

00:19:21,280 --> 00:19:23,150
So there you have, governor is doing

00:19:23,150 --> 00:19:27,160
multiple level basically with the hierarchy, right.

00:19:29,270 --> 00:19:31,240
- So basically I think the problem is that

00:19:31,240 --> 00:19:35,340
the hierarchy of the sensors doesn't have to reflect

00:19:35,340 --> 00:19:38,500
the hierarchy of devices that you want to control.

00:19:38,500 --> 00:19:40,570
- [Attendee] That's my point.

00:19:40,570 --> 00:19:43,900
- And then so you basically end up

00:19:43,900 --> 00:19:45,630
with two hierarchies to represent,

00:19:47,350 --> 00:19:52,130
and that, I'm not sure it's the model for applying

00:19:52,130 --> 00:19:54,970
constraints in the inner case that you

00:19:54,970 --> 00:19:57,540
and a string of us were proposing

00:19:57,540 --> 00:19:59,920
like when with the roof thermal zones

00:19:59,920 --> 00:20:01,510
having multiple sensors in them,

00:20:01,510 --> 00:20:04,550
so each zone will also have a list of devices

00:20:04,550 --> 00:20:06,550
that it controls or something like that.

00:20:07,600 --> 00:20:10,890
- Each zone will have sensors to which is multiple device,

00:20:10,890 --> 00:20:13,940
its cooling devices are part of different,

00:20:13,940 --> 00:20:15,806
right, cooling devices are different.

00:20:15,806 --> 00:20:16,639
- Yes but they are important too right,

00:20:16,639 --> 00:20:20,580
so you have to represent so in each zone

00:20:20,580 --> 00:20:23,540
there will be a list of devices to control

00:20:23,540 --> 00:20:25,970
and a list of sensors to read from,

00:20:25,970 --> 00:20:27,270
something like that, okay.

00:20:29,470 --> 00:20:32,700
- Which is true now, with the device.

00:20:32,700 --> 00:20:36,360
- It's not the best representation, I agree,

00:20:36,360 --> 00:20:41,360
it doesn't reflect the hierarchy of the the hardware

00:20:42,590 --> 00:20:47,050
but maybe I'm just failing to see what would be the benefit.

00:20:47,050 --> 00:20:49,440
I mean, if you guys are really thinking of having like

00:20:49,440 --> 00:20:53,400
multiple hierarchies here and you guys are really using that

00:20:53,400 --> 00:20:55,500
like the contribution of which hierarchy

00:20:55,500 --> 00:20:57,390
up to the top hierarchies.

00:20:57,390 --> 00:21:00,810
But I mean, at the end of the day as I said,

00:21:00,810 --> 00:21:02,760
what you want to do is like you have a hot spot

00:21:02,760 --> 00:21:04,720
you want to control that, right.

00:21:05,830 --> 00:21:09,680
- It's not that you really want to control the hot spot,

00:21:09,680 --> 00:21:11,864
you just, you want to split the power budget

00:21:11,864 --> 00:21:14,680
and according, I mean, because--

00:21:14,680 --> 00:21:17,570
- No, I mean, that's from the perspective

00:21:17,570 --> 00:21:20,440
of how you are solving the problem, right.

00:21:20,440 --> 00:21:23,560
But the problem statement is you have a hot spot,

00:21:23,560 --> 00:21:26,460
you want to remove that hot spot from your silicon, right.

00:21:27,340 --> 00:21:30,140
I mean, that from from a thermal management

00:21:30,140 --> 00:21:31,270
perspective, that's what we have got.

00:21:31,270 --> 00:21:33,500
- We can't afford to keep the hotspot.

00:21:33,500 --> 00:21:36,620
- Right, that's the whole point, I mean you have to,

00:21:36,620 --> 00:21:40,600
you know you do your thermal simulation,

00:21:40,600 --> 00:21:41,780
your thermal characterization,

00:21:41,780 --> 00:21:43,650
you find where your hot spots are,

00:21:43,650 --> 00:21:46,940
and you do representations of, as Shunua was saying,

00:21:46,940 --> 00:21:49,680
you have like sensors who are expensive.

00:21:49,680 --> 00:21:50,850
Then you place sensors around

00:21:50,850 --> 00:21:53,100
that hot spot to represent them.

00:21:53,100 --> 00:21:54,610
And at that point you already know

00:21:54,610 --> 00:21:56,630
what's the contribution of those sensors

00:21:56,630 --> 00:21:57,980
to represent that hot spot,

00:22:01,110 --> 00:22:03,960
right, depending on on the workload that you are running.

00:22:06,140 --> 00:22:09,100
- I'm not sure to follow what you want to mean.

00:22:09,100 --> 00:22:11,200
My point is just that having this hierarchy,

00:22:11,200 --> 00:22:13,088
just that when you have several cooling

00:22:13,088 --> 00:22:16,090
device of different way to cool.

00:22:16,090 --> 00:22:18,630
For example, if you take a cluster of CPU

00:22:19,515 --> 00:22:22,390
you can either scale down the frequency of all the CPU

00:22:22,390 --> 00:22:25,960
or you can inject idle on only one CPU

00:22:25,960 --> 00:22:28,000
to get the same power budget.

00:22:28,000 --> 00:22:29,300
How you make the decision?

00:22:31,700 --> 00:22:33,880
I mean, at some point you must know that you have

00:22:33,880 --> 00:22:36,280
a power budget for this cluster and then decide.

00:22:37,890 --> 00:22:40,660
- Yeah but with one hierarchy is not enough for that.

00:22:42,492 --> 00:22:43,910
Is it?

00:22:43,910 --> 00:22:44,743
- Sorry?

00:22:44,743 --> 00:22:47,810
- One hierarchy is not enough for that because you need

00:22:47,810 --> 00:22:52,610
to know what sensors to contribute to your measurement,

00:22:52,610 --> 00:22:56,480
and what devices you can control anyway.

00:23:02,230 --> 00:23:04,500
- Well we'd say that I am not shocked to see

00:23:04,500 --> 00:23:07,660
why you need, it's not enough, one hierarchy,

00:23:07,660 --> 00:23:09,130
because in each thermal zone you will

00:23:09,130 --> 00:23:11,450
have some cooling device attached.

00:23:11,450 --> 00:23:13,330
That's the cooling device represent

00:23:13,330 --> 00:23:15,820
how you can cool this thermal zone.

00:23:15,820 --> 00:23:17,890
- Well it depends on how you define

00:23:17,890 --> 00:23:20,570
the thermal zone but we are running out of time

00:23:20,570 --> 00:23:23,210
for this topic, so let's just pencil it

00:23:23,210 --> 00:23:28,210
for the buff slot and let's just move on to the next one.

00:23:30,140 --> 00:23:33,621
- You mean you've run already out of time, or?

00:23:33,621 --> 00:23:36,115
(applause)

00:23:36,115 --> 00:23:39,032
(faintly speaking)

00:23:39,982 --> 00:23:41,674
- Yeah, okay.

00:23:41,674 --> 00:23:43,680
- I mean, I agree that we need to move on.

00:23:44,783 --> 00:23:46,040
(faintly speaking)

00:23:46,040 --> 00:23:49,000
- Yeah we need to move on.

00:23:50,032 --> 00:23:51,610
(faintly speaking)

00:23:51,610 --> 00:23:53,060
- Let's get something, yeah.

00:23:54,187 --> 00:23:57,104
(speaking faintly)

00:23:58,401 --> 00:24:03,401
- Let's go back to this one.

00:24:05,401 --> 00:24:10,401
- Oh sorry.

00:24:17,786 --> 00:24:21,755
- Hello, microphone working, no.

00:24:21,755 --> 00:24:22,960
- Now yes it is.

00:24:22,960 --> 00:24:24,210
- Working now, okay good.

00:24:26,828 --> 00:24:28,940
I'm Morten, I work for ARM,

00:24:28,940 --> 00:24:33,230
and I have a couple of slightly more open-ended problems

00:24:33,230 --> 00:24:35,630
that I haven't actually done any work on or anything.

00:24:35,630 --> 00:24:38,370
But the first one we actually started

00:24:38,370 --> 00:24:40,880
a little bit at OSPM summit in Pisa,

00:24:40,880 --> 00:24:43,910
and Rafael and I discussed that it might be a good idea

00:24:43,910 --> 00:24:46,090
to bring it up in this audience.

00:24:46,090 --> 00:24:51,090
So the thought we've been having with regards

00:24:51,220 --> 00:24:55,010
to thermal and, well most systems today,

00:24:56,128 --> 00:24:58,200
when you run stuff on them, they get hot,

00:24:58,200 --> 00:25:00,330
you can't sustain a high level of performance,

00:25:00,330 --> 00:25:02,160
you need to scale things back.

00:25:02,160 --> 00:25:05,210
And I think that applies both to mobile and to laptops

00:25:05,210 --> 00:25:08,721
and well most systems today, you can't just assume

00:25:08,721 --> 00:25:11,630
that a CPU is something that just runs flat out

00:25:11,630 --> 00:25:13,580
and you can just put busy loops everywhere,

00:25:13,580 --> 00:25:14,660
and it will just keep running

00:25:14,660 --> 00:25:15,930
at a high level of performance.

00:25:15,930 --> 00:25:18,080
So I think performance will be capped.

00:25:20,200 --> 00:25:21,200
Is that a problem?

00:25:23,000 --> 00:25:25,360
It depends on what you're doing I think.

00:25:27,920 --> 00:25:29,640
We'll try this one.

00:25:31,350 --> 00:25:33,120
So what you effectively have is

00:25:33,120 --> 00:25:35,960
unpredictable compute bandwidth,

00:25:35,960 --> 00:25:39,500
and that might be fine for some things but

00:25:41,430 --> 00:25:45,740
user-space today has no idea that this capping is happening

00:25:45,740 --> 00:25:50,050
and we have at least one thing in the kernel where we

00:25:50,050 --> 00:25:54,010
imply a certain level of performance with what user-space

00:25:57,887 --> 00:25:59,510
or we're having an interface where you can basically

00:25:59,510 --> 00:26:01,260
request a certain performance level,

00:26:01,260 --> 00:26:02,460
a notice SCHED_DEADLINE.

00:26:03,520 --> 00:26:07,340
In SCHED_DEADLINE you can request a reservation

00:26:07,340 --> 00:26:11,726
in terms of compute bandwidth, where you specify a period

00:26:11,726 --> 00:26:15,850
and an amount of compute for each period, right.

00:26:15,850 --> 00:26:18,750
And I think the implicit assumption at the moment is that

00:26:18,750 --> 00:26:22,550
the, well the period this is not scaled

00:26:22,550 --> 00:26:24,120
according to how fast you're running

00:26:24,120 --> 00:26:26,850
but the amount of busy time is assumed

00:26:26,850 --> 00:26:29,560
to be the busy time at the highest performance level.

00:26:29,560 --> 00:26:31,051
Am I right, Yuri?

00:26:31,051 --> 00:26:33,968
(speaking faintly)

00:26:37,930 --> 00:26:40,050
- Yeah, you're right but then a run-time

00:26:40,050 --> 00:26:41,870
it is actually scale considering.

00:26:41,870 --> 00:26:44,560
- Yeah sure, so if you book a reservation

00:26:44,560 --> 00:26:46,770
which gives you five milliseconds every ten

00:26:47,680 --> 00:26:49,010
and you run at half the speed,

00:26:49,010 --> 00:26:50,260
it basically means that you would be

00:26:50,260 --> 00:26:53,740
running all the time, right, at that frequency.

00:26:53,740 --> 00:26:54,573
- [Yuri] Yeah.

00:26:54,573 --> 00:26:55,406
- Yeah.

00:26:56,520 --> 00:27:00,421
So given that we have systems where

00:27:00,421 --> 00:27:04,290
the budget you have to spend on CPUs

00:27:04,290 --> 00:27:07,900
and running a certain OPP can change at any point in time.

00:27:08,820 --> 00:27:10,800
Is it a good idea to have an interface

00:27:10,800 --> 00:27:15,800
where you can sort of lure the user space into thinking,

00:27:15,870 --> 00:27:18,390
"Oh I can make this reservation and it's all good,

00:27:18,390 --> 00:27:21,790
and I'm going to get this performance level forever.

00:27:21,790 --> 00:27:23,110
Is that a good idea?

00:27:23,110 --> 00:27:27,260
Or should we start thinking about exposing

00:27:27,260 --> 00:27:30,110
what level of performance user-space can actually expect?

00:27:31,805 --> 00:27:33,480
I don't know if there are other examples

00:27:33,480 --> 00:27:35,680
in the kernel where we make,

00:27:35,680 --> 00:27:37,230
where there are these implicit,

00:27:38,975 --> 00:27:41,594
or well, explicit requirements about how fast

00:27:41,594 --> 00:27:44,760
what level of performance you'll be getting,

00:27:44,760 --> 00:27:46,980
but at least for that line, we do have it.

00:27:46,980 --> 00:27:48,930
I think we have it a little bit with util clamp

00:27:48,930 --> 00:27:51,270
that Patrick just up streamed as well.

00:27:53,470 --> 00:27:56,530
Your clamp level does have implications

00:27:56,530 --> 00:27:58,410
for the OPP you are choosing

00:27:58,410 --> 00:28:00,120
but it's not a hard guarantee.

00:28:00,120 --> 00:28:02,720
I think it's like worse for SCHED_DEADLINE

00:28:02,720 --> 00:28:03,980
where you might be thinking,

00:28:03,980 --> 00:28:05,580
"Oh I can make this reservation,

00:28:05,580 --> 00:28:08,230
"I'm always going to get this performance level."

00:28:09,640 --> 00:28:12,000
So what do we do with SCHED_DEADLINE?

00:28:12,000 --> 00:28:14,690
Is it fine that you make a reservation

00:28:14,690 --> 00:28:16,950
and then if the system can't deliver it,

00:28:16,950 --> 00:28:19,280
it put silent, it just ignore your reservation

00:28:19,280 --> 00:28:21,490
and you don't get the performance level you need?

00:28:24,245 --> 00:28:25,078
- So what's this notification,

00:28:25,078 --> 00:28:28,350
whether you are constrained, right,

00:28:28,350 --> 00:28:29,373
that is missing.

00:28:29,373 --> 00:28:31,030
- [Morten] Yeah.

00:28:31,030 --> 00:28:32,650
- So first of all, yeah, like you requested,

00:28:32,650 --> 00:28:34,709
you may not get that performance,

00:28:34,709 --> 00:28:36,030
so you need to notify, you need to know

00:28:36,030 --> 00:28:37,380
that you are not getting it.

00:28:37,380 --> 00:28:38,800
- [Morten] Exactly, and that's not there today.

00:28:38,800 --> 00:28:39,633
- And that's not there.

00:28:39,633 --> 00:28:42,090
We have in, you know, we expose it in,

00:28:43,430 --> 00:28:45,890
we bring it to the kernel but we never use it.

00:28:45,890 --> 00:28:47,500
At least in for X36.

00:28:48,770 --> 00:28:51,510
- Yeah, and the way you use SCHED_DEADLINE today,

00:28:51,510 --> 00:28:53,490
you make a reservation and then you assume

00:28:53,490 --> 00:28:57,330
that it's there forever, or is that just a false assumption?

00:28:57,330 --> 00:28:59,210
Should we just say that SCHED_DEADLINE,

00:28:59,210 --> 00:29:01,770
you have a reservation until it can't be honored.

00:29:01,770 --> 00:29:03,390
- Yeah once you get interrupter,

00:29:04,867 --> 00:29:08,171
till you get constrained interrupt, you are done.

00:29:08,171 --> 00:29:12,440
- What happens to SCHED_DEADLINE when we cap it,

00:29:12,440 --> 00:29:13,790
for example due to thermos?

00:29:18,828 --> 00:29:21,630
- Yeah currently we don't react to that.

00:29:21,630 --> 00:29:26,320
My way of thinking about this is that if you know

00:29:26,320 --> 00:29:28,260
that you can actually be capped,

00:29:28,260 --> 00:29:30,760
you shouldn't meet stuff that you know

00:29:30,760 --> 00:29:32,340
that you cannot guarantee, right.

00:29:32,340 --> 00:29:35,330
So it's something that happens before.

00:29:35,330 --> 00:29:40,080
Or if you know that the, if you can, I mean,

00:29:41,002 --> 00:29:44,700
problem is that, as you say, once you emitted something

00:29:44,700 --> 00:29:47,240
then there is this contract going on with user-space

00:29:47,240 --> 00:29:49,560
and then, if your then your capped,

00:29:49,560 --> 00:29:51,430
you're basically not respecting that.

00:29:51,430 --> 00:29:53,622
So I guess what you can do if you want

00:29:53,622 --> 00:29:57,270
to actually guarantee performance, is to admit less,

00:29:57,270 --> 00:30:00,030
and with Dettol you can do it.

00:30:00,030 --> 00:30:01,640
- That's what I'm getting at.

00:30:01,640 --> 00:30:04,850
Do we want to have that?

00:30:04,850 --> 00:30:07,139
Because at the moment it's not clear.

00:30:07,139 --> 00:30:09,880
The SCHED_DEADLINE user can't be tricked

00:30:09,880 --> 00:30:11,830
into thinking that it is actually a contract

00:30:11,830 --> 00:30:14,010
with the kernel where it's not today.

00:30:14,010 --> 00:30:15,010
So should we fix it?

00:30:16,420 --> 00:30:20,120
- So on the one hand we need to reintroduce

00:30:20,120 --> 00:30:23,780
the signal for for missing deadlines.

00:30:24,971 --> 00:30:25,804
(faintly speaking)

00:30:25,804 --> 00:30:26,637
Step back in?

00:30:26,637 --> 00:30:28,250
Okay so that's at least one hint

00:30:28,250 --> 00:30:30,660
that stuff has gone to bits.

00:30:35,630 --> 00:30:40,630
We could add information to the signal that says why.

00:30:42,318 --> 00:30:47,318
And then, I mean, for a variable system like that

00:30:49,833 --> 00:30:54,470
you can of course a priori configure things

00:30:54,470 --> 00:30:57,160
to not hand out the highest of the high.

00:30:57,160 --> 00:30:59,370
I mean but of course if you put it,

00:30:59,370 --> 00:31:02,934
if you put your phone in bright sunlight in your car,

00:31:02,934 --> 00:31:06,623
it, yeah, at some point you have to just say, DM.

00:31:11,850 --> 00:31:15,170
So when the thermals really kick in,

00:31:15,170 --> 00:31:19,060
we should probably tell user-space about it.

00:31:19,956 --> 00:31:22,750
(faintly speaking)

00:31:22,750 --> 00:31:25,150
- Yeah I guess we can have probably both things.

00:31:26,175 --> 00:31:30,050
So it also depends on how bad it is, if you are actually

00:31:30,050 --> 00:31:33,610
breaking that this contract with some of your tasks.

00:31:33,610 --> 00:31:37,420
So if you have a task that you cannot, I mean,

00:31:37,420 --> 00:31:40,660
it has to run always, even when you're capped,

00:31:40,660 --> 00:31:44,660
I think we for that you actually need to have,

00:31:44,660 --> 00:31:48,540
I mean, the sustainable cap must be present

00:31:48,540 --> 00:31:50,840
before you are meet that does to the system,

00:31:50,840 --> 00:31:55,840
so that one it is in, you will always be guaranteed,

00:31:55,880 --> 00:31:57,140
if that's possible.

00:31:57,140 --> 00:32:00,020
And for the others that can actually maybe be stopped

00:32:00,020 --> 00:32:03,680
or behave worse when the system is capped,

00:32:03,680 --> 00:32:07,520
we can have a signal and then user-space can actually,

00:32:07,520 --> 00:32:11,240
so for example if you have a video that is playing back,

00:32:11,240 --> 00:32:13,710
and when you're capped you cannot try to reduce

00:32:13,710 --> 00:32:18,270
the frame rate or anything but you can get the signal back.

00:32:19,160 --> 00:32:22,170
- So are you proposing to have sort of two kinds of tasks,

00:32:22,170 --> 00:32:25,370
ones that requires almost like a hard guarantee,

00:32:25,370 --> 00:32:28,620
saying it will never ever take away your reservation,

00:32:28,620 --> 00:32:31,130
and then you can allow other tasks to actually

00:32:31,130 --> 00:32:34,670
oversubscribe the CPU, go above the sustained level

00:32:34,670 --> 00:32:37,280
and then when it can't deliver that any more,

00:32:37,280 --> 00:32:38,620
then just notified and say,

00:32:38,620 --> 00:32:41,290
"Well your reservation is no longer on it."

00:32:41,290 --> 00:32:46,040
- This just sounds like ooM and we're awfully at that.

00:32:50,150 --> 00:32:53,710
I don't know, I'd start by just sending signals

00:32:53,710 --> 00:32:57,530
when programs run and they completely fail,

00:32:58,990 --> 00:33:02,710
mostly due to stuff changing and then

00:33:02,710 --> 00:33:05,500
let user-space figure out what to do.

00:33:05,500 --> 00:33:07,970
For Android that should probably be enough,

00:33:07,970 --> 00:33:10,070
and then user-space can figure out which task

00:33:10,070 --> 00:33:12,290
to knock on the head.

00:33:15,410 --> 00:33:17,830
- [Morten] So we don't want to try to put in like a bar

00:33:17,830 --> 00:33:19,820
saying, you should not make reservations

00:33:19,820 --> 00:33:22,610
above, I don't know, 50%.

00:33:22,610 --> 00:33:26,240
- We already have this bar and it's configurable.

00:33:26,240 --> 00:33:27,980
- It's at 95% now, isn't it.

00:33:27,980 --> 00:33:29,341
- But you can lower it.

00:33:29,341 --> 00:33:30,440
- [Morten] True.

00:33:30,440 --> 00:33:32,670
- And that's, it's the administrator.

00:33:32,670 --> 00:33:35,690
I mean, we as kernel developers have no friggin clue.

00:33:37,700 --> 00:33:39,360
It's the SOC.

00:33:39,360 --> 00:33:41,040
- But is that entirely true?

00:33:41,040 --> 00:33:43,520
You do have information in ACPI for example.

00:33:45,256 --> 00:33:50,256
- Didn't I earlier, it was yesterday, right, yeah.

00:33:50,421 --> 00:33:55,312
So if we have to rely on ACPI it's a sad, sad world.

00:33:55,312 --> 00:33:57,030
(speaking faintly)

00:33:57,030 --> 00:34:01,310
- So saying rely to ACPI is like saying rely on

00:34:01,310 --> 00:34:04,110
English language, it's basically a communication means.

00:34:04,110 --> 00:34:08,780
So what you are really saying is we can't rely

00:34:08,780 --> 00:34:12,220
on firmware to provide actual information

00:34:12,220 --> 00:34:14,880
which is very true, I mean, in practice.

00:34:15,861 --> 00:34:18,800
(laughing)

00:34:18,800 --> 00:34:20,100
- [Morten] Well we do rely on

00:34:20,100 --> 00:34:22,253
some information coming from firmware.

00:34:22,253 --> 00:34:23,980
- I mean if there is ACPI, we can of course

00:34:23,980 --> 00:34:26,970
use it and set a number, it's just, I

00:34:27,840 --> 00:34:30,400
let me say I am not full of faith that this number

00:34:30,400 --> 00:34:34,040
will be as useful as it could be.

00:34:34,040 --> 00:34:35,680
- But is it better or worse than nothing?

00:34:35,680 --> 00:34:38,350
I mean the default is 95% which is above

00:34:38,350 --> 00:34:43,350
your turbo arranged level on most of your parts at Intel.

00:34:44,740 --> 00:34:47,770
And on arm I think that's probably true for many,

00:34:47,770 --> 00:34:49,130
at least for the bigger cores that

00:34:49,130 --> 00:34:51,290
you can't sustain a 95% frequency.

00:34:53,170 --> 00:34:55,310
- So like once we had in thermal limits,

00:34:55,310 --> 00:34:58,330
those guarantees don't hold, in none of

00:34:58,330 --> 00:35:00,240
the guarantees hold, basically.

00:35:00,240 --> 00:35:01,073
- That's how we do it.

00:35:01,073 --> 00:35:03,940
- LFM, the the lowest frequency, even that's not guaranteed

00:35:03,940 --> 00:35:05,861
because we can even have a duty cycle

00:35:05,861 --> 00:35:07,970
eight steps inside that.

00:35:08,943 --> 00:35:11,820
So 1800 megahertz divided by 8, 100 megahertz.

00:35:11,820 --> 00:35:14,190
So 100 megahertz is the guarantee.

00:35:14,190 --> 00:35:15,900
- So what you're is that SCHED_DEADLINE

00:35:15,900 --> 00:35:17,960
and things like that is completely useless on a--

00:35:17,960 --> 00:35:19,490
(speaking faintly)

00:35:19,490 --> 00:35:21,060
- Yeah, it's very rare.

00:35:21,060 --> 00:35:23,480
- It's not aware of any of those deadlines

00:35:23,480 --> 00:35:27,470
and if you prioritize controlling the temperatures,

00:35:27,470 --> 00:35:32,020
getting our way of the hot spots, as I was telling before.

00:35:32,020 --> 00:35:34,210
That's how it's actually done today.

00:35:34,210 --> 00:35:37,100
I mean if we can maybe have like from thermal,

00:35:37,100 --> 00:35:38,710
from the thermal subsystem likes,

00:35:38,710 --> 00:35:42,560
and is it even possible today for the system administrator

00:35:42,560 --> 00:35:46,150
to actually define or the from AC guy to define

00:35:46,150 --> 00:35:48,650
tree points where if the thermal subsystem

00:35:49,935 --> 00:35:51,302
could notify the user-space, for example,

00:35:51,302 --> 00:35:54,150
okay we are getting hot but we are not hammering it yet.

00:35:54,150 --> 00:35:55,960
I mean yeah, that's possible you could do that

00:35:55,960 --> 00:35:59,200
but you know, at the end of the day

00:35:59,200 --> 00:36:02,840
when we get to the point where thermals are theme,

00:36:02,840 --> 00:36:05,390
we need to reduce the performance.

00:36:05,390 --> 00:36:10,390
- So yeah I'm all for changing the 95% in a sensible way

00:36:11,330 --> 00:36:13,290
if we have sensible information.

00:36:13,290 --> 00:36:14,330
That's not a problem.

00:36:14,330 --> 00:36:16,840
- Yeah that's where I'm going, I mean, if we have

00:36:17,911 --> 00:36:18,744
information from firmware, why don't we

00:36:18,744 --> 00:36:21,440
use that to set a more sensible limit.

00:36:21,440 --> 00:36:25,340
I totally agree that will be different for different devices

00:36:25,340 --> 00:36:28,860
and each vendor might choose to have a different level

00:36:28,860 --> 00:36:31,920
depending on what level of guarantees they need.

00:36:31,920 --> 00:36:34,390
- What do we do in extreme thermal events,

00:36:34,390 --> 00:36:36,060
that's another story.

00:36:36,060 --> 00:36:37,030
- [Morten] I mean if you're at the point

00:36:37,030 --> 00:36:38,160
where the only thing you can do

00:36:38,160 --> 00:36:40,185
is to shut down, then you're screwed anyway.

00:36:40,185 --> 00:36:41,018
- Right.

00:36:41,018 --> 00:36:43,500
- Then everybody's screwed up, right, including

00:36:43,500 --> 00:36:46,500
system integrators because they didn't foresee that working.

00:36:49,410 --> 00:36:50,370
- True.

00:36:50,370 --> 00:36:52,760
There's a question here or a comment.

00:36:56,859 --> 00:36:59,230
- So I was wondering, is your assumption here

00:36:59,230 --> 00:37:01,780
that you've gotten multiple tasks running SCHED_DEADLINE

00:37:01,780 --> 00:37:05,090
or are you a single task scenario because you could,

00:37:05,090 --> 00:37:07,160
if you're hitting that limit you're gonna get

00:37:07,160 --> 00:37:09,840
like three signals if there's a signal there,

00:37:09,840 --> 00:37:11,470
and you're just gonna get confused

00:37:11,470 --> 00:37:12,420
with all that information.

00:37:12,420 --> 00:37:13,990
I mean I don't know how that's necessarily

00:37:13,990 --> 00:37:15,810
going to help you other than, you know,

00:37:15,810 --> 00:37:18,450
the fire alarm that's going off, right, you know.

00:37:19,730 --> 00:37:22,690
So some of it's more about the system's architecture too,

00:37:22,690 --> 00:37:25,290
understanding your limits and understanding

00:37:25,290 --> 00:37:27,570
what the predicted behavior of some of these workloads are

00:37:27,570 --> 00:37:31,260
and how to distribute the workload across the course.

00:37:31,260 --> 00:37:35,090
But I do agree, if we had meaningful information

00:37:35,090 --> 00:37:36,820
than people trying to schedule these workloads

00:37:36,820 --> 00:37:38,800
and meet some deadlines, you know,

00:37:38,800 --> 00:37:41,591
maybe we could make better choices, right.

00:37:41,591 --> 00:37:44,800
But I think that as you start to add more to the workload

00:37:44,800 --> 00:37:47,640
and consolidate your workload on your multi-core systems,

00:37:47,640 --> 00:37:49,740
I think then it's just noise at that point.

00:37:49,740 --> 00:37:52,120
You've got all these fires going off because nobody's

00:37:52,120 --> 00:37:55,240
hitting their deadlines on that core and then you've got it.

00:37:55,240 --> 00:37:57,570
That gets back to just understanding,

00:37:57,570 --> 00:37:59,690
what are my priority tasks, right.

00:37:59,690 --> 00:38:02,340
And then, and in architecting maybe setting affinity

00:38:02,340 --> 00:38:03,830
for specific things, you know.

00:38:03,830 --> 00:38:05,660
I don't know what your use case is

00:38:05,660 --> 00:38:07,860
and sometimes the use case will define this.

00:38:09,710 --> 00:38:11,682
- But for us, it's getting the information

00:38:11,682 --> 00:38:15,286
out to user-space.

00:38:15,286 --> 00:38:19,850
- My worry is that if you want to architect everything now

00:38:19,850 --> 00:38:21,960
you need to know how are the platform behaves.

00:38:21,960 --> 00:38:24,592
I mean, if an end user picks up a dashboard or a device

00:38:24,592 --> 00:38:27,010
and want your SCHED_DEADLINE on that,

00:38:27,010 --> 00:38:28,340
then we're screwed, right.

00:38:28,340 --> 00:38:29,870
- We'd like to have meaningful data

00:38:29,870 --> 00:38:31,570
that we could provide the user-space.

00:38:31,570 --> 00:38:32,403
- [Morten] Yeah.

00:38:32,403 --> 00:38:33,236
- I agree.

00:38:34,950 --> 00:38:36,742
- Yeah, I mean, unless you are foreseeing to say

00:38:36,742 --> 00:38:41,540
play on the gray area where only one core is having

00:38:41,540 --> 00:38:44,380
like a thermal event like a real fire alarm,

00:38:45,250 --> 00:38:47,350
and then you want to move your workload out of it

00:38:47,350 --> 00:38:49,920
so that it can cool off, but I mean,

00:38:49,920 --> 00:38:52,880
it starts to be a little slightly bit complicated

00:38:52,880 --> 00:38:53,980
but I don't know.

00:38:53,980 --> 00:38:56,920
- Yeah that's probably not what I had in mind.

00:38:56,920 --> 00:38:59,550
I was more after like providing

00:38:59,550 --> 00:39:04,550
like some level of guarantee where if you use SCHED_DEADLINE

00:39:04,690 --> 00:39:07,700
then you would be stopped before you can actually

00:39:07,700 --> 00:39:10,920
make a reservation, that you would be almost sure

00:39:10,920 --> 00:39:12,220
it would, wouldn't be met.

00:39:13,506 --> 00:39:14,632
- Well the the thing is is that,

00:39:14,632 --> 00:39:15,610
let's say you had some information

00:39:15,610 --> 00:39:17,490
and you've got forecasts running on that core

00:39:17,490 --> 00:39:18,610
and you thought you had everything

00:39:18,610 --> 00:39:21,480
precisely managed as far as your deadlines.

00:39:21,480 --> 00:39:23,730
But all of a sudden the fire alarms go off, right,

00:39:23,730 --> 00:39:26,190
and so you do have that information to tweak it

00:39:26,190 --> 00:39:28,930
from 95% to something a little more,

00:39:28,930 --> 00:39:31,228
and fire alarms are still going off,

00:39:31,228 --> 00:39:32,800
then do you just get the bucket

00:39:32,800 --> 00:39:34,140
and then throw one of the tasks off

00:39:34,140 --> 00:39:35,200
and move it to another core?

00:39:35,200 --> 00:39:36,700
You know, yeah, you need more.

00:39:39,669 --> 00:39:41,640
- The thermal is not the core, I think.

00:39:41,640 --> 00:39:46,640
- Yeah well it depends on your time frame,

00:39:46,650 --> 00:39:48,890
but I don't know if it's actually feasible

00:39:48,890 --> 00:39:51,300
to try and to shift, I mean, the hot spot

00:39:51,300 --> 00:39:53,040
from one core to the next or the whole thing

00:39:53,040 --> 00:39:56,220
heats up so fast that it's just a global problem anyway.

00:39:56,220 --> 00:39:58,980
- Yeah, if you have some idol CPUs, I don't know.

00:40:03,980 --> 00:40:05,830
- Yeah so with deadline, you of course

00:40:05,830 --> 00:40:09,310
have the period of the task and mostly

00:40:09,310 --> 00:40:11,280
this would be like the 60 hertz

00:40:11,280 --> 00:40:14,760
of your rendering pipeline or whatever is convenient

00:40:14,760 --> 00:40:17,715
for your audio pipeline or something like that.

00:40:17,715 --> 00:40:22,715
It's the core thermal versus packaged thermal

00:40:24,040 --> 00:40:26,160
anywhere near that range of time?

00:40:27,200 --> 00:40:29,530
I mean does it make sense to shift

00:40:29,530 --> 00:40:31,470
to another core in those time frames?

00:40:34,450 --> 00:40:38,478
- Yeah, it can happen fast.

00:40:38,478 --> 00:40:41,566
- It can be microseconds.

00:40:41,566 --> 00:40:45,924
- But you can't mic radio task that fast.

00:40:45,924 --> 00:40:47,974
So you can't do anything about it anyway.

00:40:47,974 --> 00:40:51,306
- And if they're in a BM, then, you know.

00:40:51,306 --> 00:40:52,139
- Yeah.

00:40:56,521 --> 00:41:00,080
- So if we plan to use the knobs that are available

00:41:00,080 --> 00:41:04,230
to define the reservation we can use for deadline

00:41:04,230 --> 00:41:06,060
with that note that we already have,

00:41:06,060 --> 00:41:10,540
is not that knob affecting both deadline and RT tasks.

00:41:10,540 --> 00:41:13,770
So does that mean that if we are under thermal pressure

00:41:13,770 --> 00:41:16,390
we have only deadline tasks, we basically keel out

00:41:16,390 --> 00:41:20,193
also the RT tasks in our system, so.

00:41:24,020 --> 00:41:28,220
- So RT doesn't have admission control.

00:41:28,220 --> 00:41:29,053
- No, exactly.

00:41:29,053 --> 00:41:32,713
- RT is basically basically a failed scheduling policy.

00:41:35,820 --> 00:41:38,587
There is nothing you can really do for them.

00:41:38,587 --> 00:41:39,420
- So when it says that--

00:41:39,420 --> 00:41:42,170
- Basically, so you only have then deadline,

00:41:42,170 --> 00:41:45,679
all the RT will won't be scheduled because it's a total

00:41:45,679 --> 00:41:47,370
when deadline basically finishes in doing its work.

00:41:47,370 --> 00:41:50,250
So they are emitted they will never run.

00:41:51,887 --> 00:41:53,630
- If it's worth at least to try to distinguish

00:41:53,630 --> 00:41:58,630
what we can allocate with deadline and what is left for RT

00:41:58,870 --> 00:42:02,120
still within the sustainable performance capacity.

00:42:04,950 --> 00:42:07,190
Which goes back to what Morten was proposing

00:42:07,190 --> 00:42:11,300
so we have to define a deadline granted capacity

00:42:11,300 --> 00:42:14,240
that leave some space for RT for example

00:42:14,240 --> 00:42:16,560
and other stuff under thermal conditions also.

00:42:20,840 --> 00:42:23,750
- So this comes back to U clamp of course

00:42:23,750 --> 00:42:28,310
because that's the only thing that RT has to.

00:42:29,250 --> 00:42:32,580
- Yeah but U clamp is not really enforcing anything.

00:42:32,580 --> 00:42:35,380
It has to be an extension on that eventually.

00:42:35,380 --> 00:42:39,670
- So I'd hate to add bandwidth to RT, it's just.

00:42:41,436 --> 00:42:44,940
- Well okay, so there are different categories

00:42:44,940 --> 00:42:48,770
of thermal events, different time frames, and there are such

00:42:48,770 --> 00:42:51,870
that you can't do anything about it because they,

00:42:51,870 --> 00:42:55,010
it will just happen in a matter of microseconds

00:42:55,010 --> 00:42:57,571
and then the hardware will decided.

00:42:57,571 --> 00:43:00,780
You will get less power and that's it.

00:43:01,850 --> 00:43:05,670
And you can't do anything except for getting,

00:43:05,670 --> 00:43:07,910
possibly getting notified about that.

00:43:07,910 --> 00:43:11,030
- Yeah but for those, the workload

00:43:11,030 --> 00:43:13,290
should already take that into account.

00:43:13,290 --> 00:43:16,740
Those will always happen and then, I mean,

00:43:16,740 --> 00:43:21,510
if you have a work that is like four milliseconds long

00:43:23,156 --> 00:43:25,170
and the event happens on microsecond scale,

00:43:26,040 --> 00:43:29,010
it will always happen and therefore the workload

00:43:29,010 --> 00:43:31,930
should take this into account anyway,

00:43:32,880 --> 00:43:36,180
because it's just nothing we can do about it.

00:43:36,180 --> 00:43:41,180
- Well so the work, there is a difference between a workload

00:43:41,290 --> 00:43:46,290
and a, how the kernel allows to happen

00:43:48,860 --> 00:43:50,520
because the workload is just, you know,

00:43:50,520 --> 00:43:52,760
a bunch of tasks that will run,

00:43:52,760 --> 00:43:55,360
and a kernel decides how fast they will run,

00:43:55,360 --> 00:43:56,430
right, and that is--

00:43:56,430 --> 00:43:57,480
- Sure, sure, but so,

00:43:59,880 --> 00:44:01,420
this is for admission control

00:44:04,594 --> 00:44:07,550
and we should allow so much work that it is possible

00:44:11,930 --> 00:44:16,930
and suppose we do a while 1 loop

00:44:19,200 --> 00:44:24,130
and load the CPU up and then it throws us down

00:44:24,130 --> 00:44:27,470
and then we see we cannot ever load this machine up

00:44:27,470 --> 00:44:32,470
more than now 60%, maybe 40% depending on the platform.

00:44:34,940 --> 00:44:37,590
And that's where we should set our admission control.

00:44:38,910 --> 00:44:43,140
That means that admission control should be

00:44:43,140 --> 00:44:46,609
like tuned to the, to what's going on, right.

00:44:46,609 --> 00:44:49,526
(faintly speaking)

00:44:52,152 --> 00:44:54,620
- So then emission control control will disallow new tasks

00:44:54,620 --> 00:44:57,990
and then the existing tasks, if you put it in the sun

00:44:57,990 --> 00:45:00,400
or if something bad happens, your fan breaks

00:45:00,400 --> 00:45:03,180
or thermal glue dried up, I don't know.

00:45:05,800 --> 00:45:07,190
Weird stuff happens, I know.

00:45:07,190 --> 00:45:09,530
- Yeah, I mean, I think just maybe circle back

00:45:09,530 --> 00:45:11,280
on the same thing that you are saying,

00:45:12,200 --> 00:45:14,450
two aspects here, right, if you are designing

00:45:15,333 --> 00:45:20,170
your admission control assuming your maximum CPU frequency

00:45:20,170 --> 00:45:24,560
or your turbo, you already started doing it wrong, right.

00:45:24,560 --> 00:45:25,790
So there is that.

00:45:25,790 --> 00:45:28,630
And the other thing is also that I think Peter mentioned

00:45:28,630 --> 00:45:32,660
is like or maybe say in a different way is that

00:45:32,660 --> 00:45:34,640
it's not only about thermals at least,

00:45:34,640 --> 00:45:37,250
it's not only about the admission control

00:45:37,250 --> 00:45:39,720
of a SCHED_DEADLINE doesn't know about that, right.

00:45:39,720 --> 00:45:41,810
So if you have you as your high priority tasks

00:45:41,810 --> 00:45:45,860
which had the endmies admitted on on a SCHED_DEADLINE,

00:45:45,860 --> 00:45:48,460
and maybe you can even admit more,

00:45:48,460 --> 00:45:51,450
but if you have like a noisy workload

00:45:51,450 --> 00:45:56,450
which is consuming power like a while 1 over there,

00:45:56,630 --> 00:45:58,700
it's also going to contribute to the thermals.

00:45:58,700 --> 00:46:01,260
- It will.

00:46:01,260 --> 00:46:04,680
- Right, it has nothing to do with the admission control

00:46:04,680 --> 00:46:06,740
maybe, right, is not part of SCHED_DEADLINE,

00:46:06,740 --> 00:46:10,130
it's just like a CFS task, but if you produce power

00:46:10,130 --> 00:46:11,370
if you heat the--

00:46:11,370 --> 00:46:14,870
- Yeah but its contribution will eventually be reduced to 5%

00:46:14,870 --> 00:46:17,200
because if you start capping because of thermal,

00:46:17,200 --> 00:46:19,030
then in the end, it's only your deadline task

00:46:19,030 --> 00:46:21,110
that will end up running minus the 5%

00:46:21,110 --> 00:46:22,710
that will reserve further stuff.

00:46:22,710 --> 00:46:24,830
- And so the history of the 95,

00:46:24,830 --> 00:46:29,647
the 95 was set way before we ever did any DVFS smarts.

00:46:32,604 --> 00:46:36,513
The moment we started scaling work for SCHED_DEADLINE,

00:46:40,090 --> 00:46:43,960
for DVFS, the whole 95% thing when went out the window,

00:46:43,960 --> 00:46:47,260
and this is basically an overlooked thing.

00:46:47,260 --> 00:46:51,250
So I'm absolutely okay with changing the 95

00:46:51,250 --> 00:46:54,590
to a sensible number and even doing it

00:46:54,590 --> 00:46:58,170
dynamically if we have the information.

00:47:00,650 --> 00:47:03,700
- [Morten] Okay, fair enough.

00:47:03,700 --> 00:47:05,710
- But maybe one point is also that

00:47:05,710 --> 00:47:07,670
yes we can do ismar stuff here

00:47:07,670 --> 00:47:10,200
but in the end of the day, is also part of the job

00:47:10,200 --> 00:47:12,740
to design the system that fits

00:47:12,740 --> 00:47:15,740
on your thermals envelope, right.

00:47:15,740 --> 00:47:16,881
- Yeah.

00:47:16,881 --> 00:47:18,280
- So we have one more minute for this topic,

00:47:18,280 --> 00:47:20,630
so last thoughts and then we need to.

00:47:26,078 --> 00:47:27,340
- I think I agree with your point

00:47:27,340 --> 00:47:29,830
but I still think we can do slightly more

00:47:29,830 --> 00:47:31,940
than just say it's up to the user

00:47:31,940 --> 00:47:33,730
if we do have a little bit of information

00:47:33,730 --> 00:47:37,200
to not let people put in deadlines

00:47:37,200 --> 00:47:40,190
after use in 90% of the CPU capacity.

00:47:42,480 --> 00:47:44,920
- So what kind of exact information are you looking for,

00:47:44,920 --> 00:47:47,400
like from the thermal subsystem for example

00:47:47,400 --> 00:47:51,480
or some notification through that, or?

00:47:51,480 --> 00:47:56,480
- I think, well you can subscribe to notifications, can you,

00:47:56,810 --> 00:48:01,670
I mean if you want to know when the system gets hot.

00:48:01,670 --> 00:48:03,570
- Right, you already can do that.

00:48:03,570 --> 00:48:04,403
- Yeah.

00:48:04,403 --> 00:48:05,236
- From user-space.

00:48:05,236 --> 00:48:06,069
- Yeah.

00:48:07,250 --> 00:48:11,380
So yeah, maybe just lower the 95% to something derived

00:48:11,380 --> 00:48:14,700
from whatever information will have the firmware table.

00:48:14,700 --> 00:48:16,843
- Basically the sustained rate.

00:48:16,843 --> 00:48:17,676
- Yeah.

00:48:17,676 --> 00:48:19,790
- I think there's an ACPI thing or whatever we have,

00:48:19,790 --> 00:48:22,450
but a sustained rate and set it to that.

00:48:22,450 --> 00:48:23,903
- [Morten] And we can probably

00:48:23,903 --> 00:48:24,736
find something similar for DT.

00:48:24,736 --> 00:48:26,740
- But if you lower this dynamically then what do you do

00:48:26,740 --> 00:48:29,250
with all the tasks which are already subscribed to.

00:48:29,250 --> 00:48:32,170
- [Morten] It's not dynamic, it's a static table.

00:48:32,170 --> 00:48:33,667
- They get a signal.

00:48:33,667 --> 00:48:35,917
(laughing)

00:48:37,119 --> 00:48:40,345
(faintly speaking)

00:48:40,345 --> 00:48:42,640
- Or maybe you can also start on server 3.

00:48:42,640 --> 00:48:45,830
So you first start with a really low cap

00:48:45,830 --> 00:48:48,170
and see if you actually need to increase it

00:48:48,170 --> 00:48:51,680
if you actually have more tasks that tries

00:48:51,680 --> 00:48:55,197
to enter a system, I guess can monitor the thing.

00:48:55,197 --> 00:48:57,290
- Right, okay, good.

00:48:59,530 --> 00:49:00,860
I think that's it for this topic.

00:49:00,860 --> 00:49:05,860
So I have one more topic which is sort of related.

00:49:06,190 --> 00:49:08,430
Let me see if I can work this out again.

00:49:08,430 --> 00:49:10,030
Oh no, I messed it up, didn't I.

00:49:17,291 --> 00:49:19,970
I think we're here and can I realign it somehow.

00:49:26,010 --> 00:49:27,730
Especially when they're not your own.

00:49:29,309 --> 00:49:32,360
Right, so this is a little bit related

00:49:32,360 --> 00:49:33,950
and it actually came out of the discussion

00:49:33,950 --> 00:49:36,840
again from OSPM Summit in Pisa.

00:49:36,840 --> 00:49:40,436
So the way we do with thermal management today in Linux

00:49:40,436 --> 00:49:44,470
is very much focused on what devices do we have

00:49:44,470 --> 00:49:45,960
and how can we control them.

00:49:45,960 --> 00:49:48,050
And if we're in a thermal situation,

00:49:48,050 --> 00:49:50,960
we decide a set of caps and we apply them to each device

00:49:50,960 --> 00:49:53,060
and say you can't go any faster than this.

00:49:59,212 --> 00:50:00,380
But when you have a thermal situation,

00:50:00,380 --> 00:50:01,670
what you really need to do is to,

00:50:01,670 --> 00:50:04,050
you need to lower the amount of work you need to do,

00:50:04,050 --> 00:50:06,970
lower the amount of compute, you need to reduce it somehow.

00:50:06,970 --> 00:50:09,780
And one way is just to slow everything down.

00:50:09,780 --> 00:50:13,320
But what if the set of caps that our current

00:50:13,320 --> 00:50:15,970
device centric thermal management governor

00:50:17,522 --> 00:50:20,320
decides is not the most optimum one for your use case.

00:50:21,480 --> 00:50:23,700
You could have a use case where

00:50:23,700 --> 00:50:26,175
there is a task you might want to run really fast

00:50:26,175 --> 00:50:29,770
because it's absolutely essential for the performance

00:50:29,770 --> 00:50:32,220
and there are some other tasks you can sacrifice,

00:50:35,130 --> 00:50:36,690
that you can't really handle today

00:50:36,690 --> 00:50:38,690
in the way power management works.

00:50:39,550 --> 00:50:44,550
So should we consider changing the way we look

00:50:45,070 --> 00:50:50,070
at a thermal management, and make it task centric instead

00:50:51,520 --> 00:50:56,520
because as we have today, we don't have any any information

00:50:57,920 --> 00:51:00,350
about the importance of tasks,

00:51:00,350 --> 00:51:03,620
we don't know how to best spent the thermal budget

00:51:03,620 --> 00:51:06,100
and if we try to do clever things in the scheduler

00:51:06,100 --> 00:51:08,472
we might actually make things worse.

00:51:08,472 --> 00:51:11,310
I mean we can have task placement trying to escape

00:51:11,310 --> 00:51:14,170
thermal caps, if you cap one set of CPUs,

00:51:14,170 --> 00:51:16,550
the scheduler says, oh these CPUs are not capped as hard,

00:51:16,550 --> 00:51:18,120
then you move more load over there

00:51:18,120 --> 00:51:20,370
and then you have to cap them a moment later.

00:51:21,450 --> 00:51:23,860
So it doesn't really work that well

00:51:23,860 --> 00:51:25,260
I think, for some scenarios.

00:51:27,520 --> 00:51:31,960
So in an ideal world, if you have a thermal situation,

00:51:31,960 --> 00:51:34,250
you want to lower the amount of compute

00:51:34,250 --> 00:51:38,790
but I think the application is actually better place

00:51:38,790 --> 00:51:41,600
at deciding how to lower the amount of compute

00:51:41,600 --> 00:51:43,870
rather than kernel firmware stepping units,

00:51:43,870 --> 00:51:46,230
say you can't go any faster than this,

00:51:46,230 --> 00:51:47,970
all your CPUs are capped at this level,

00:51:47,970 --> 00:51:49,670
your GPU is capped at that level,

00:51:49,670 --> 00:51:52,430
and you just have to live inside those constraints.

00:51:53,420 --> 00:51:55,580
What if you had a workload, the new,

00:51:55,580 --> 00:51:58,130
I actually want the few CPUs that run really fast

00:51:58,130 --> 00:51:59,810
but I'm okay with the other ones

00:51:59,810 --> 00:52:02,680
being being capped at very low OPP

00:52:02,680 --> 00:52:05,930
or I can sacrifice my GPU completely.

00:52:05,930 --> 00:52:08,090
There is no room to do that with the way

00:52:08,090 --> 00:52:09,740
we currently do power management.

00:52:10,930 --> 00:52:14,320
- Okay, thank you, so one thought about this.

00:52:14,320 --> 00:52:18,503
So we still need to cut the kernel to be the last boundary,

00:52:19,770 --> 00:52:22,480
like for you know, because we can we can be nice

00:52:22,480 --> 00:52:27,380
to applications but then when they still don't, you know.

00:52:27,380 --> 00:52:28,710
- Exactly.

00:52:28,710 --> 00:52:30,860
- So this is not about just shifting

00:52:30,860 --> 00:52:32,740
a whole problem up into the application

00:52:32,740 --> 00:52:35,040
because we can't trust them in the end.

00:52:35,040 --> 00:52:36,890
This is about enabling the applications

00:52:36,890 --> 00:52:39,500
to do better if they behave.

00:52:39,500 --> 00:52:41,160
And I don't think the kernel is going to

00:52:41,160 --> 00:52:42,800
be the last line of defense anyway,

00:52:42,800 --> 00:52:43,950
you have something in firmware.

00:52:43,950 --> 00:52:45,710
So you sort of have a number of layers

00:52:45,710 --> 00:52:47,980
starting from the bottom where you have firmware,

00:52:47,980 --> 00:52:50,089
then you have kernel, you might have middleware

00:52:50,089 --> 00:52:52,500
having an opinion in there, and then

00:52:52,500 --> 00:52:55,713
at the very top you have the application.

00:53:03,020 --> 00:53:04,860
- But these applications don't have deadlines

00:53:04,860 --> 00:53:06,710
because they're kind of contradicting things here

00:53:06,710 --> 00:53:08,670
is because if they have a deadline and you want

00:53:08,670 --> 00:53:10,820
some sort of user space notification that

00:53:10,820 --> 00:53:12,470
hey I should slow things down,

00:53:13,380 --> 00:53:15,930
if the applications aware that it's deadline centered,

00:53:15,930 --> 00:53:17,380
I guess it could reject that.

00:53:19,970 --> 00:53:21,790
- Well the application can choose to ignore

00:53:21,790 --> 00:53:24,290
whatever we tell it, and if that happens

00:53:24,290 --> 00:53:26,160
and at some point you have you will,

00:53:26,160 --> 00:53:29,420
it oversteps some boundaries, the kernel will step in

00:53:29,420 --> 00:53:30,830
or the firmware will step in and say,

00:53:30,830 --> 00:53:33,780
well you still exceed the power budget now and need to--

00:53:33,780 --> 00:53:34,900
- Yeah, now I need to clamp.

00:53:34,900 --> 00:53:38,670
- Boundaries, but this is around trying to enable

00:53:38,670 --> 00:53:42,740
the application to stay away from those boundaries

00:53:42,740 --> 00:53:44,540
so they actually don't get enforced.

00:53:45,510 --> 00:53:49,310
So letting the application itself manage

00:53:49,310 --> 00:53:51,510
how much compute it's requiring.

00:53:52,360 --> 00:53:55,340
There are a few examples out there.

00:53:55,340 --> 00:53:58,240
I came across a blog post where some graphics people

00:53:58,240 --> 00:54:02,110
had worked with a specific phone vendor to try to

00:54:04,528 --> 00:54:05,430
basically self-adapt the amount of detail

00:54:05,430 --> 00:54:07,880
you were rendering in the graphics engine

00:54:07,880 --> 00:54:09,850
depending on the thermal pressure.

00:54:09,850 --> 00:54:12,030
So if you're overheating, they basically adapted

00:54:12,030 --> 00:54:14,950
the workload to become less by reducing the complexity

00:54:14,950 --> 00:54:16,560
of what you are rendering, and thereby you could

00:54:16,560 --> 00:54:18,230
stay within the thermal budget, but you still

00:54:18,230 --> 00:54:22,350
had a nice frame rate because the graphics really sucks

00:54:22,350 --> 00:54:23,910
if you cap your system so hard

00:54:23,910 --> 00:54:26,680
that you can't meet 30 or 60 FPS.

00:54:26,680 --> 00:54:29,981
You might be better off only being able to see

00:54:29,981 --> 00:54:32,390
half a mile ahead instead of one mile

00:54:33,850 --> 00:54:36,390
in your render distance or whatever,

00:54:36,390 --> 00:54:37,690
I'm not a graphics expert.

00:54:39,430 --> 00:54:44,050
For applications like that, where you might be interested in

00:54:44,050 --> 00:54:48,060
in investing into making them self-adapting.

00:54:48,060 --> 00:54:51,060
Could we come up with a way to enable them to do that?

00:54:51,060 --> 00:54:53,190
I know that in Android, I think they recently introduced

00:54:53,190 --> 00:54:56,310
an interface where you can get notifications,

00:54:56,310 --> 00:54:59,090
I think they have four different notifications going

00:54:59,090 --> 00:55:03,680
from mildly critical up to severe for thermal.

00:55:04,870 --> 00:55:06,460
But as far as I know, it doesn't use,

00:55:06,460 --> 00:55:09,328
we don't have a standardized kernel interface

00:55:09,328 --> 00:55:11,700
for user-space to subscribe to or read,

00:55:11,700 --> 00:55:14,771
saying what is the current thermal situation.

00:55:14,771 --> 00:55:16,570
And what should that interface actually be?

00:55:16,570 --> 00:55:19,860
Can we come up with a metric that they can use to say

00:55:19,860 --> 00:55:22,490
how far away am i from from hitting that boundary

00:55:22,490 --> 00:55:26,160
where firmware will step in and hard cap the frequency?

00:55:26,160 --> 00:55:28,950
- Right, so just like from a graphic side of things,

00:55:28,950 --> 00:55:32,080
like you're saying, if I'm starting to see some,

00:55:32,080 --> 00:55:36,960
I'm dropping frames, then I start to make some adjustments,

00:55:36,960 --> 00:55:38,810
and then you had that feedback loop.

00:55:38,810 --> 00:55:40,450
And I think what you're looking for is that,

00:55:40,450 --> 00:55:43,020
also that feedback, it's not a one-time thing,

00:55:43,020 --> 00:55:46,050
it's sort of like the application makes some adjustments,

00:55:46,050 --> 00:55:47,610
gets additional feedback somehow.

00:55:47,610 --> 00:55:48,750
- Right, yes.

00:55:48,750 --> 00:55:52,420
And I want to enable the application to do the adjustments

00:55:52,420 --> 00:55:55,320
before you have kernel firmware kicking in

00:55:55,320 --> 00:55:58,020
and making hard caps, so you actually drop the frames.

00:56:02,001 --> 00:56:03,800
Well you could of course see that you exceed

00:56:03,800 --> 00:56:06,980
the thermal budget if you start to see frames dropping

00:56:06,980 --> 00:56:08,800
and then you can start thinking about doing something.

00:56:08,800 --> 00:56:11,570
But if we told it beforehand and now you're actually

00:56:11,570 --> 00:56:16,390
approaching whatever limit you have in terms of thermal

00:56:16,390 --> 00:56:19,040
and then do something about it proactively,

00:56:19,040 --> 00:56:20,970
I think you can end up with a better user experience.

00:56:20,970 --> 00:56:25,470
- So just to, maybe I mentioned that on the other topic

00:56:25,470 --> 00:56:29,150
is the way that assist integrator would do it,

00:56:29,150 --> 00:56:31,770
you would like create bands on the temperature domains,

00:56:31,770 --> 00:56:34,334
right, and have tree points defined

00:56:34,334 --> 00:56:37,468
on this temperature domain.

00:56:37,468 --> 00:56:40,100
It's very common for people to say,

00:56:40,100 --> 00:56:43,860
hey yeah, on this band we are fully okay,

00:56:43,860 --> 00:56:46,500
and then on the next band we are in a warm zone

00:56:46,500 --> 00:56:50,070
and then on the next band, we would be on a throttling zone,

00:56:50,070 --> 00:56:51,440
and then the last band would be,

00:56:51,440 --> 00:56:53,490
okay at this point, you are screwed,

00:56:53,490 --> 00:56:55,280
you are gonna be shut down right,

00:56:55,280 --> 00:56:57,327
that's a very typical design.

00:56:57,327 --> 00:57:01,500
And the thermal subsystem actually sends notifications

00:57:01,500 --> 00:57:03,700
to user-space when you cross the tree points,

00:57:03,700 --> 00:57:05,050
when you cross up and down.

00:57:06,040 --> 00:57:09,830
That would be one way of, obviously I mean,

00:57:09,830 --> 00:57:12,920
out of tree policies that people do,

00:57:12,920 --> 00:57:14,848
it's a whole different ballgame,

00:57:14,848 --> 00:57:17,880
but that's at least how it is recommended today.

00:57:17,880 --> 00:57:19,720
You don't need to necessarily throttle

00:57:19,720 --> 00:57:21,850
on all the tree points, you can just define tree points

00:57:21,850 --> 00:57:23,660
that are just for notification.

00:57:27,980 --> 00:57:29,910
- So you're saying it is, somewhat there

00:57:29,910 --> 00:57:31,860
already but it's out of tree.

00:57:31,860 --> 00:57:33,980
- No, it's there, it's not out of tree.

00:57:35,479 --> 00:57:36,391
- The notifications for that.

00:57:36,391 --> 00:57:40,330
- It's probably not even used by auto tree systems,

00:57:40,330 --> 00:57:42,040
but yeah, it's actually there.

00:57:44,400 --> 00:57:46,030
So can you get those notifications?

00:57:46,030 --> 00:57:48,610
Are they per thermal zone or?

00:57:48,610 --> 00:57:49,740
- On the thermal zone.

00:57:49,740 --> 00:57:50,573
- Okay.

00:57:51,860 --> 00:57:53,453
So maybe they're--

00:57:53,453 --> 00:57:56,236
- And you define those on the by-street as well for example.

00:57:56,236 --> 00:58:00,710
There's no standardized way of saying what are the bands

00:58:00,710 --> 00:58:02,620
these are left for the system integrator

00:58:02,620 --> 00:58:05,580
because some people think, okay, two bands are fine,

00:58:05,580 --> 00:58:06,710
three bands are fine, some people,

00:58:06,710 --> 00:58:09,730
okay I want to have six bands.

00:58:09,730 --> 00:58:12,270
- Yeah so but that would need to be

00:58:12,270 --> 00:58:15,180
like defined by the system integrator.

00:58:15,180 --> 00:58:16,013
- Right.

00:58:16,013 --> 00:58:19,000
- Somehow like more, to add more trip points

00:58:19,000 --> 00:58:21,120
for this kind of work.

00:58:21,120 --> 00:58:26,120
So that would require some input from like the

00:58:26,180 --> 00:58:29,165
firmware people as well as--

00:58:29,165 --> 00:58:30,660
- I mean, yeah, if you have like something in ACPI

00:58:30,660 --> 00:58:32,160
for example, then yeah.

00:58:32,160 --> 00:58:34,090
- Well yeah that's what I mean.

00:58:34,090 --> 00:58:38,631
So somebody needs to tell us what what are those,

00:58:38,631 --> 00:58:41,170
what the bands are essentially.

00:58:43,359 --> 00:58:45,030
- So to better understand, we can define tree points

00:58:45,030 --> 00:58:47,760
already but we also have support to get signals

00:58:47,760 --> 00:58:49,290
when we cross tree points?

00:58:49,290 --> 00:58:52,150
- To the user-space we have Caesar fast notifications,

00:58:52,150 --> 00:58:54,410
Caesar fast notifies that there are sent out.

00:58:57,450 --> 00:59:00,310
If that's enough that's a whole different story, but yeah.

00:59:00,310 --> 00:59:03,060
Yeah that would be easy if it's already there.

00:59:03,060 --> 00:59:07,400
I was thinking maybe have some continuous signal

00:59:07,400 --> 00:59:08,764
or something that you could use

00:59:08,764 --> 00:59:12,160
if you want to basically create a feedback loop

00:59:12,160 --> 00:59:15,584
in your application saying, okay I've got this much spare

00:59:15,584 --> 00:59:19,040
of thermal, I mean, you could almost get there

00:59:19,040 --> 00:59:21,420
if you define a lot of thread points I guess.

00:59:22,950 --> 00:59:24,860
- It's like a concept of thermal capacity,

00:59:24,860 --> 00:59:29,530
this thermal capacity we have crossing the next tree point.

00:59:29,530 --> 00:59:31,240
Or maybe defining, okay I'm interested

00:59:31,240 --> 00:59:34,450
to these specific level, can you notify me

00:59:34,450 --> 00:59:35,580
when I'm crossing these levels,

00:59:35,580 --> 00:59:37,410
some kind of programmable interface

00:59:37,410 --> 00:59:39,180
where the application can actually require

00:59:39,180 --> 00:59:42,850
to be notified on certain specific tree points.

00:59:44,690 --> 00:59:46,460
- Yeah I think Shuima was at some point

00:59:46,460 --> 00:59:51,460
was proposing something similar, right.

00:59:54,630 --> 00:59:57,490
- Dell based notifications, to the,

00:59:57,490 --> 00:59:58,740
the current is very slow.

00:59:59,981 --> 01:00:01,910
Current mechanism is net link based

01:00:01,910 --> 01:00:05,206
and it goes to Udev and then it distributes.

01:00:05,206 --> 01:00:10,206
So it's a Dell based device and directing notification

01:00:10,515 --> 01:00:11,348
that will be faster on that node.

01:00:13,080 --> 01:00:14,840
- I mean that's the Dell nodes not existing,

01:00:14,840 --> 01:00:16,405
he was proposing to have that.

01:00:16,405 --> 01:00:19,800
Would that be more helpful?

01:00:21,200 --> 01:00:22,190
- Potentially, yeah.

01:00:22,190 --> 01:00:24,370
So what we did in turn is just a mock of things.

01:00:24,370 --> 01:00:26,990
We basically took the power allocator governor

01:00:26,990 --> 01:00:29,990
and it has like an error feedback in the feedback loop

01:00:29,990 --> 01:00:32,260
it has, and we basically just exposed that

01:00:32,260 --> 01:00:34,990
to user-space and trying to let user-space adapt

01:00:34,990 --> 01:00:37,720
itself based on that information.

01:00:37,720 --> 01:00:39,998
And that worked reasonably well.

01:00:39,998 --> 01:00:40,831
- Yeah, I think he contrited that.

01:00:40,831 --> 01:00:41,960
The other thing I was thinking about is

01:00:41,960 --> 01:00:46,350
depends on how many gradients of information that you have

01:00:46,350 --> 01:00:49,640
and like was mentioned earlier, a systems integrator

01:00:49,640 --> 01:00:52,860
or something could actually tune it and if the gradients

01:00:52,860 --> 01:00:55,800
are reliable and predictable, then the applications

01:00:55,800 --> 01:00:58,050
could be tuned ahead of time that when they hit

01:00:58,050 --> 01:01:01,291
a certain gradient, then the application goes into another

01:01:01,291 --> 01:01:03,720
like a lower performance mode.

01:01:10,443 --> 01:01:13,526
- There's a question at the far back.

01:01:21,240 --> 01:01:23,550
- Does it need to be signals or could it just look like

01:01:23,550 --> 01:01:26,940
the CPU freak interface where I've got a base temperature

01:01:26,940 --> 01:01:31,000
and a min and a max that I can deal with and then

01:01:31,000 --> 01:01:34,710
the applications can do whatever they wish at that point.

01:01:35,860 --> 01:01:38,610
- Yeah, I'm not sure if it needs to be signals, I mean,

01:01:41,922 --> 01:01:43,140
we probably can't react that fast anyway,

01:01:43,140 --> 01:01:47,300
I mean, it's frame by frame so if it's just something

01:01:47,300 --> 01:01:52,300
we could Paul or Reed, yeah, maybe that's sufficient.

01:01:52,510 --> 01:01:54,120
- Yeah but maybe you don't want to be

01:01:54,120 --> 01:01:57,200
like reacting frame by frame, maybe you wanted to find

01:01:57,200 --> 01:02:01,310
a specific notification entry point where you just

01:02:01,310 --> 01:02:03,700
do the switch from the application perspective, right.

01:02:03,700 --> 01:02:08,040
So when we cross that tree point then

01:02:08,040 --> 01:02:11,300
I would switch to another mode where I would

01:02:11,300 --> 01:02:14,740
have less of a rendering requirement.

01:02:16,607 --> 01:02:17,500
I mean it doesn't need to be frame by frame.

01:02:17,500 --> 01:02:19,870
You would glitch a little bit when you cross it.

01:02:19,870 --> 01:02:21,990
- You'll fixed it in a few frames.

01:02:22,919 --> 01:02:23,815
- But you wouldn't be like

01:02:23,815 --> 01:02:24,910
a frame by frame kind of adaptation.

01:02:27,896 --> 01:02:29,596
- That's going to be a long throw.

01:02:36,640 --> 01:02:41,100
- So but then we'll need user-space to subscribe to those.

01:02:42,663 --> 01:02:43,496
- [Morten] Right.

01:02:43,496 --> 01:02:45,820
- Not notification mechanisms, whatever they are,

01:02:45,820 --> 01:02:48,230
so it will have to either open a dev

01:02:48,230 --> 01:02:50,570
or listen to something, right.

01:02:53,795 --> 01:02:55,706
- Yeah, they will need to listen to that.

01:02:55,706 --> 01:02:57,360
- Yeah, okay.

01:02:57,360 --> 01:03:00,260
- But that's fair enough, I mean, if I wants information

01:03:00,260 --> 01:03:02,130
it needs to get it from somewhere.

01:03:03,090 --> 01:03:03,923
- Yeah, okay.

01:03:07,395 --> 01:03:09,074
- Fair enough.

01:03:09,074 --> 01:03:10,930
- Where are we on time?

01:03:10,930 --> 01:03:12,600
- We are fine, so we are five minutes

01:03:12,600 --> 01:03:14,960
ahead of time, actually even ten minutes.

01:03:14,960 --> 01:03:19,606
So are there any more thoughts on this particular topic

01:03:19,606 --> 01:03:22,880
or we can switch over to the next one and then.

01:03:22,880 --> 01:03:23,760
- [Morten] No I think that's it,

01:03:23,760 --> 01:03:24,960
it sounds like we have something--

01:03:24,960 --> 01:03:27,740
- I have one question related to this.

01:03:27,740 --> 01:03:30,400
Last year they were talking about thermal capacity govern

01:03:30,400 --> 01:03:31,880
and thermal capacity end scheduler.

01:03:31,880 --> 01:03:34,539
Is that patches upstream or is it like?

01:03:34,539 --> 01:03:36,739
- [Morten] You should ask Vason in the back.

01:03:38,710 --> 01:03:40,530
- They're actually still working on that.

01:03:40,530 --> 01:03:42,830
She is running some tests, she has been a bit sidetracked

01:03:42,830 --> 01:03:45,380
on that activity, but it's ongoing.

01:03:45,380 --> 01:03:48,550
We'll make sure that this will go outside in coming weeks.

01:03:54,260 --> 01:03:56,510
- So I think for this topic this summer,

01:03:56,510 --> 01:03:59,810
yes there is some Caesar fast notification going on

01:03:59,810 --> 01:04:01,760
that you can already subscribe

01:04:01,760 --> 01:04:03,630
and you would require the syst integrator

01:04:03,630 --> 01:04:07,330
to define your bands but either way if you have

01:04:07,330 --> 01:04:09,040
the syst integrator defining your bands,

01:04:09,040 --> 01:04:12,596
reliable bands, I think there's still a question

01:04:12,596 --> 01:04:15,680
to answer is if this is the Caesar fast notifications

01:04:15,680 --> 01:04:18,962
is enough or we need a dev node for example

01:04:18,962 --> 01:04:22,250
to be at the right time scale that you need.

01:04:22,250 --> 01:04:24,550
- Yeah, okay that makes sense.

01:04:24,550 --> 01:04:26,500
I'll have a look at that patch and see.

01:04:28,300 --> 01:04:29,550
It's on the list already.

01:04:31,340 --> 01:04:33,360
There was a patch for you in dev node.

01:04:33,360 --> 01:04:35,910
- Is your dev node patches already on my list?

01:04:35,910 --> 01:04:38,000
I think that we were supposed to send it.

01:04:38,000 --> 01:04:39,160
- Yeah, I'll send a mailing list.

01:04:39,160 --> 01:04:39,993
- Okay.

01:04:39,993 --> 01:04:43,520
- Okay, cool, that's it, more questions?

01:04:46,240 --> 01:04:47,230
No, next.

01:04:49,825 --> 01:04:52,075
(applause)

01:04:56,281 --> 01:04:58,169
- Sorry about that meddling stuff,

01:04:58,169 --> 01:05:00,533
it was the latest thing when we put it in.

01:05:20,590 --> 01:05:22,860
- So I have a problem but I don't

01:05:22,860 --> 01:05:24,530
have a good solutions beforehand.

01:05:28,146 --> 01:05:32,190
So we have Per Core P-States in Intel platform

01:05:33,060 --> 01:05:37,220
for really long but previously the power was not

01:05:37,220 --> 01:05:38,860
a consideration on this platform.

01:05:38,860 --> 01:05:42,450
I mean, it was okay too but we have power sensitive

01:05:42,450 --> 01:05:45,360
platforms now with Per Core P-States.

01:05:45,360 --> 01:05:50,360
It's great for power, it significantly improves

01:05:50,860 --> 01:05:53,010
the power savings and active power savings,

01:05:53,940 --> 01:05:57,303
and but they will have some small performance loss

01:05:57,303 --> 01:06:01,250
with some producer-consumer type workloads.

01:06:02,610 --> 01:06:05,730
And good part, good news is that it's not that bad

01:06:05,730 --> 01:06:08,560
because our hardware P algorithms

01:06:08,560 --> 01:06:10,820
already has built-in optimization for that,

01:06:11,990 --> 01:06:16,883
but there are still some cases where seams are required.

01:06:18,663 --> 01:06:21,790
So it's very typical example in this is

01:06:21,790 --> 01:06:23,800
one of the thread is continuously pushing

01:06:23,800 --> 01:06:26,290
data and producing some new data,

01:06:26,290 --> 01:06:29,850
and trying to ask some consumers stretch to do things,

01:06:29,850 --> 01:06:32,150
like rendering or an audio playback

01:06:32,150 --> 01:06:34,350
or some type of you know situations.

01:06:35,260 --> 01:06:38,980
And in that case, the compared to the,

01:06:38,980 --> 01:06:41,080
it's nothing to do with, I know it's in a core

01:06:41,080 --> 01:06:42,940
but compared to the older generations,

01:06:42,940 --> 01:06:46,333
we have some performance loss.

01:06:46,333 --> 01:06:51,010
You can see simply do with schbench type workload,

01:06:51,010 --> 01:06:54,360
with sleep option, like if you look at,

01:06:54,360 --> 01:06:57,920
the PCPS means the old style and that's a new style

01:06:57,920 --> 01:06:59,710
the Per Core P-States and SPD means

01:07:01,030 --> 01:07:03,430
we don't have Per Core P-State here.

01:07:03,430 --> 01:07:07,240
And if you look at this you know CPU in the case,

01:07:07,240 --> 01:07:12,240
in the Per Core P case case, the CPU at two

01:07:13,030 --> 01:07:18,030
which was in previously was planning at much higher

01:07:18,270 --> 01:07:22,140
frequency because of the other core is running high

01:07:22,140 --> 01:07:25,110
so it also gets a boost because of others.

01:07:25,110 --> 01:07:27,970
But when you run Per Core P-State you won't get that boost.

01:07:27,970 --> 01:07:31,340
It's good for power obviously but we don't get that boost

01:07:31,340 --> 01:07:35,910
and then you lose some performance.

01:07:35,910 --> 01:07:39,770
And it's not all workloads, it's very isolated workloads

01:07:40,693 --> 01:07:42,780
but you won't see much impact but

01:07:42,780 --> 01:07:45,230
we still need to solve this thing.

01:07:46,820 --> 01:07:49,830
So I then I try to look at this,

01:07:49,830 --> 01:07:52,430
the average CFS utilization.

01:07:52,430 --> 01:07:55,070
So like in this that example which I was giving you

01:07:55,070 --> 01:07:58,460
the one other CPU, one is basically is fully busy

01:07:58,460 --> 01:08:01,720
with full capacity and the other CPU2

01:08:01,720 --> 01:08:04,620
is the actual CFS utilization is almost

01:08:04,620 --> 01:08:08,680
and very low because it sleeps most of the time, wakes up,

01:08:08,680 --> 01:08:11,680
do something, again dump to some hardware again go to sleep.

01:08:11,680 --> 01:08:13,130
So it doesn't ever build

01:08:13,130 --> 01:08:15,710
a utilization enough to do anything.

01:08:18,260 --> 01:08:21,430
And I see that you on the, had this similar problem

01:08:21,430 --> 01:08:24,050
but they, it's not same problem but similar,

01:08:24,050 --> 01:08:25,810
where do you have some utilization clamps

01:08:25,810 --> 01:08:28,100
and other things, right, I think you did some

01:08:28,100 --> 01:08:31,350
lot of work on because it's long sleeping tasks.

01:08:31,350 --> 01:08:34,340
But it doesn't help because I know if we cannot really

01:08:34,340 --> 01:08:36,810
define clamps, it's like x86 system,

01:08:36,810 --> 01:08:40,410
anybody can run any workload, it's not tuned vertically,

01:08:40,410 --> 01:08:45,130
so we don't have option.

01:08:47,821 --> 01:08:48,654
So we don't have--

01:08:48,654 --> 01:08:51,700
- There's a worst case, the worst case is when,

01:08:51,700 --> 01:08:54,780
instead of, you've got 99% and 5%,

01:08:54,780 --> 01:08:56,950
when they're 50/50 then they both run slow.

01:08:58,090 --> 01:09:00,440
- Yeah, that is the worst.

01:09:03,560 --> 01:09:08,250
So I did simple experiment, may not be the great one

01:09:08,250 --> 01:09:10,710
but if I know that like in this case,

01:09:10,710 --> 01:09:13,410
if the current task which is basically waking up

01:09:13,410 --> 01:09:18,410
the consumer in this case and its utilization is

01:09:19,760 --> 01:09:23,540
and the current one is like half of the full CPU capacity,

01:09:23,540 --> 01:09:28,540
then you just give an indication to the CPU freq update

01:09:30,399 --> 01:09:35,399
to sched util and current because to reduce the impact

01:09:35,540 --> 01:09:38,800
the sched util governor can totally ignore that signal,

01:09:38,800 --> 01:09:40,750
but like an Intel P-state case,

01:09:40,750 --> 01:09:43,480
we have mechanism where we can somehow relate

01:09:43,480 --> 01:09:46,210
between different processes, we know that they are related.

01:09:47,210 --> 01:09:49,920
We can tell the hardware that they are related then it will

01:09:49,920 --> 01:09:52,620
know that let me push this also at the same time.

01:09:53,960 --> 01:09:56,910
But I don't know how how good is that,

01:09:56,910 --> 01:10:00,180
what's the impact, so that's what I have questions.

01:10:00,180 --> 01:10:02,740
What's that, what will happen if I put this change?

01:10:09,290 --> 01:10:11,670
So we don't want back and forth

01:10:11,670 --> 01:10:15,050
like didn't want a cyclic positive feedback loop,

01:10:15,050 --> 01:10:17,560
it's gonna keep the frequency high, right,

01:10:17,560 --> 01:10:19,520
if one is waking up another and then that's waking

01:10:19,520 --> 01:10:23,030
it back up, I don't I mean it's just the core snippets,

01:10:23,030 --> 01:10:24,650
I don't know how he implemented it,

01:10:24,650 --> 01:10:26,640
but would that cause both CPUs to be stay

01:10:26,640 --> 01:10:30,390
at a higher frequency because the other one needs you.

01:10:30,390 --> 01:10:31,350
- Yeah, yeah.

01:10:31,350 --> 01:10:32,850
- Is that a potential issue?

01:10:32,850 --> 01:10:35,420
- Yeah, as long as both are related they will be high,

01:10:35,420 --> 01:10:37,720
and that's what we want, if they're both are related,

01:10:37,720 --> 01:10:41,230
If two CPUS are related, if two to CPS running a workload

01:10:41,230 --> 01:10:43,680
which are related, they need to be high

01:10:43,680 --> 01:10:46,360
otherwise it will cause the power distribution

01:10:46,360 --> 01:10:48,090
an uneven distribution of the power.

01:10:48,090 --> 01:10:50,960
- So if they're sharing a CPU, this happens naturally.

01:10:50,960 --> 01:10:51,793
- Yeah.

01:10:51,793 --> 01:10:52,761
- Yeah.

01:10:52,761 --> 01:10:53,862
- But if their on separate CPUs

01:10:53,862 --> 01:10:54,772
that's when we run into this.

01:10:54,772 --> 01:10:55,605
- Yeah.

01:10:59,780 --> 01:11:02,740
- So maybe I don't understand the case but it looks like

01:11:02,740 --> 01:11:05,960
that if you know the tasks now with U clamp

01:11:05,960 --> 01:11:09,770
you should be able to take those tasks and keep the

01:11:09,770 --> 01:11:14,260
frequency to whatever minimum you define as a clamp value.

01:11:14,260 --> 01:11:16,820
- So I need to know the task ahead.

01:11:16,820 --> 01:11:19,770
- That's true, I mean, what we do for example

01:11:19,770 --> 01:11:22,680
Android is the tasks are usually in C groups

01:11:22,680 --> 01:11:25,060
and we know that those are the tasks most important

01:11:25,060 --> 01:11:27,622
right now, so always keep the frequency at this level

01:11:27,622 --> 01:11:30,640
whenever tasks are runnable independent

01:11:30,640 --> 01:11:32,690
from their utility structure, if it is issue

01:11:32,690 --> 01:11:34,830
is above the clamp value you follow the utilization

01:11:34,830 --> 01:11:37,588
but if there are small tasks you still keep these.

01:11:37,588 --> 01:11:42,588
- Yeah, that I understand, the problem is tuning

01:11:42,980 --> 01:11:45,160
some waiting to clear, but if I like, if you are using

01:11:45,160 --> 01:11:50,045
x86 system, like ten generation, and you don't know

01:11:50,045 --> 01:11:52,900
unless you are expert user you don't nearly know

01:11:52,900 --> 01:11:55,170
how to chain to C group and tie this.

01:11:55,170 --> 01:11:58,050
He will just run a graphics work, something.

01:11:58,050 --> 01:12:00,400
- There is per tasks API so with a Cisco

01:12:00,400 --> 01:12:01,910
but you you need to know the task,

01:12:01,910 --> 01:12:02,920
so if you need all these--

01:12:02,920 --> 01:12:03,810
- Yeah, something which is--

01:12:03,810 --> 01:12:05,720
- I get the point is ideally though it was configured out

01:12:05,720 --> 01:12:07,914
itself and not force the end user to do it.

01:12:07,914 --> 01:12:10,870
- Not every user can do that.

01:12:10,870 --> 01:12:12,200
And very special because you know

01:12:12,200 --> 01:12:15,270
somebody's tuning for you before, right.

01:12:15,270 --> 01:12:17,610
- Is this a server workload or what kind of workload is it?

01:12:17,610 --> 01:12:18,820
- It's a client workload.

01:12:21,703 --> 01:12:22,580
(faintly speaking)

01:12:22,580 --> 01:12:23,413
No, a client.

01:12:26,270 --> 01:12:29,890
- I'm wondering if this, in this kind of workload

01:12:29,890 --> 01:12:34,390
you could identify as sort of wake or wakey pattern

01:12:34,390 --> 01:12:39,390
and it happens that one of those two process wakes up

01:12:41,050 --> 01:12:44,910
there's a wakey wakey, in that case shouldn't the scheduler

01:12:44,910 --> 01:12:47,640
already realize that there is this relationship

01:12:47,640 --> 01:12:52,640
and put the two tasks close together so on the same core?

01:12:53,660 --> 01:12:57,630
When you describe this problem, I would say,

01:12:57,630 --> 01:12:59,670
doesn't the scheduler already solve this?

01:12:59,670 --> 01:13:00,503
- No, no.

01:13:00,503 --> 01:13:02,150
- Because they recognized that they are waking each other up

01:13:02,150 --> 01:13:03,510
and put them on the same core.

01:13:03,510 --> 01:13:06,510
I don't know if this is the case, I'm just asking it.

01:13:06,510 --> 01:13:10,100
- It won't happen because the other core is hopefully busy,

01:13:10,100 --> 01:13:11,430
it's running continuously, right,

01:13:11,430 --> 01:13:15,060
it's occupying full hundred capacity of the CPU, it's not.

01:13:17,150 --> 01:13:22,150
- So the thing you just mentioned just a fine wake up

01:13:22,188 --> 01:13:27,188
and that only works for if there's idle time.

01:13:30,760 --> 01:13:33,160
- Another question is, another question I had is

01:13:33,160 --> 01:13:35,550
in this case are each of the CPUs running

01:13:35,550 --> 01:13:37,280
in a completely independent power supply?

01:13:37,280 --> 01:13:38,473
- Yes, yeah.

01:13:38,473 --> 01:13:39,997
- They are, okay.

01:13:39,997 --> 01:13:40,830
(laughing)

01:13:40,830 --> 01:13:42,300
- Because sometimes the frequency, you can get the power

01:13:42,300 --> 01:13:45,280
sings by frequency savings and I've done some analysis

01:13:45,280 --> 01:13:48,580
on that before and it was like not worth it.

01:13:48,580 --> 01:13:49,450
- Yeah yeah yeah.

01:13:50,424 --> 01:13:52,657
- SPD stands for single power.

01:13:52,657 --> 01:13:54,023
(speaking faintly)

01:13:54,023 --> 01:13:54,856
- A power, okay, not P-state.

01:13:58,420 --> 01:14:01,480
- I might have missed this earlier on, so you mentioned

01:14:01,480 --> 01:14:04,270
this is actually running slower but do you have any kind

01:14:04,270 --> 01:14:07,660
of data to show how much slower the total task is running?

01:14:07,660 --> 01:14:10,240
It sounds like it's kind of working as intended

01:14:10,240 --> 01:14:13,280
based on my interpretation because the other--

01:14:13,280 --> 01:14:15,668
- It is working as intended but the--

01:14:15,668 --> 01:14:18,931
(speaking faintly)

01:14:18,931 --> 01:14:21,181
(laughing)

01:14:22,786 --> 01:14:23,710
- I guess what, because--

01:14:23,710 --> 01:14:28,210
- No, this is working as designed, I would say,

01:14:28,210 --> 01:14:32,370
but it has it has the some disadvantage

01:14:32,370 --> 01:14:35,660
if you compare with the old style with the new style, right.

01:14:35,660 --> 01:14:36,752
- Right.

01:14:36,752 --> 01:14:37,695
- What's the performance of all time?

01:14:37,695 --> 01:14:39,830
- I mean you're at 100% on one CPU guaranteed,

01:14:39,830 --> 01:14:41,890
the other CPU you're at 5%, right,

01:14:41,890 --> 01:14:45,610
so if you run that second core faster

01:14:45,610 --> 01:14:47,817
then maybe you get down to like 2%.

01:14:47,817 --> 01:14:48,972
Is that the?

01:14:48,972 --> 01:14:52,390
- No, you won't get because of whenever we try

01:14:52,390 --> 01:14:54,930
to associate tasks we have overhead to some

01:14:54,930 --> 01:14:58,122
in firm hardware, so that's not going to be hundred equal

01:14:58,122 --> 01:15:01,190
but it will be like with so base this change,

01:15:01,190 --> 01:15:03,170
I could all get performance very similar.

01:15:03,170 --> 01:15:04,720
You'll never get similar, same.

01:15:07,008 --> 01:15:10,410
- So it's look like you want the two CPU

01:15:10,410 --> 01:15:12,450
to share the same frequency domain.

01:15:12,450 --> 01:15:13,283
- [Lecturer] Yeah.

01:15:13,283 --> 01:15:16,160
- So why don't you, I mean, instead because they have some

01:15:16,160 --> 01:15:18,160
dedicated frequency control that you

01:15:18,160 --> 01:15:20,690
can't have a shared frequency domain.

01:15:20,690 --> 01:15:23,650
- No, they have dedicated strict control on each,

01:15:23,650 --> 01:15:25,840
so hardware does doesn't know each other.

01:15:25,840 --> 01:15:27,300
- Yeah but from a software point of view

01:15:27,300 --> 01:15:28,850
we already have something like that.

01:15:28,850 --> 01:15:32,290
- No, we cannot tell hardware that they are,

01:15:32,290 --> 01:15:33,720
we have to tell them they are together.

01:15:33,720 --> 01:15:36,550
- Not from an another but in an

01:15:38,210 --> 01:15:41,310
ARM platform we have one frequency domain

01:15:41,310 --> 01:15:43,280
for all the CPU and we are looking,

01:15:43,280 --> 01:15:45,910
we are selecting the highest utilization

01:15:45,910 --> 01:15:49,530
of all the CPU in the in the frequency domain.

01:15:49,530 --> 01:15:51,380
So can't you create something similar?

01:15:51,380 --> 01:15:52,213
- Yeah but--

01:15:52,213 --> 01:15:53,860
- Looking at the utilization of all the CPU.

01:15:53,860 --> 01:15:56,700
- Yeah but then I did defeat the purpose of

01:15:56,700 --> 01:15:58,592
Per Core P-States if I do it.

01:15:58,592 --> 01:15:59,540
(speaking faintly)

01:15:59,540 --> 01:16:01,980
- Yeah it's like, it's very, that's what I said initially,

01:16:01,980 --> 01:16:04,770
it's very isolated case, it's not a panic situation,

01:16:07,082 --> 01:16:10,270
very, yeah, it's outliers, not really a mainstream.

01:16:15,032 --> 01:16:15,865
- So IOA is exactly the same except we have to hack for IOA.

01:16:19,820 --> 01:16:22,737
(speaking faintly)

01:16:27,780 --> 01:16:30,750
- Can't we repurpose the IOA 'cause this,

01:16:30,750 --> 01:16:32,190
so what I said just for the record,

01:16:32,190 --> 01:16:34,590
this is the exact same problem we have with IOA.

01:16:35,530 --> 01:16:39,410
IOA it is for block devices, this just happens to be

01:16:39,410 --> 01:16:42,630
not a block device but it's the exact same problem.

01:16:44,376 --> 01:16:45,800
- Yes, yes, it is the exact same problem,

01:16:45,800 --> 01:16:48,315
I just didn't want to because IOA is set

01:16:48,315 --> 01:16:51,790
by the drivers in the only thing is.

01:16:53,347 --> 01:16:56,264
(faintly speaking)

01:16:58,860 --> 01:17:00,430
- So in this case you would have the consumer

01:17:00,430 --> 01:17:02,980
do the IOA on the supplier?

01:17:02,980 --> 01:17:05,390
- Yeah but I need to identify consumer, how do I.

01:17:05,390 --> 01:17:07,338
- I know, it's a question for Peter.

01:17:07,338 --> 01:17:11,540
So in this case you would have the consumer do the IOA

01:17:11,540 --> 01:17:14,700
on the producer, is that what you would want?

01:17:14,700 --> 01:17:16,750
- So it's the consumer that is waiting,

01:17:16,750 --> 01:17:18,390
it's waiting on a device that just happens

01:17:18,390 --> 01:17:19,640
to not be a block device.

01:17:20,580 --> 01:17:22,660
- Well it's not, okay, it might be talking to device

01:17:22,660 --> 01:17:24,674
but I think his problem was not that,

01:17:24,674 --> 01:17:26,770
waiting on a device right.

01:17:26,770 --> 01:17:29,870
He was in a sense is waiting on the producer.

01:17:29,870 --> 01:17:32,710
- It's waiting on Hutex basically yet in this example.

01:17:32,710 --> 01:17:36,409
We are in a futex on that one.

01:17:36,409 --> 01:17:40,990
So we have to simulate IOA, like I'm simulating

01:17:40,990 --> 01:17:44,130
a remote wake, it's basically nothing.

01:17:44,130 --> 01:17:47,400
- So you kinda want to include the producers utilization

01:17:47,400 --> 01:17:50,115
as part of your utilization so that you can run fast.

01:17:50,115 --> 01:17:50,948
- [Lecturer] Yeah.

01:17:50,948 --> 01:17:53,010
- In a sense, I'm not sure that's the right thing to do

01:17:53,010 --> 01:17:54,540
but that would solve your issue.

01:17:54,540 --> 01:17:56,940
- [Lecturer] Yeah that's why question is.

01:17:58,260 --> 01:17:59,880
- I was also thinking of a similar scenario

01:17:59,880 --> 01:18:02,660
with Chromebooks, and how we'd have a scenario

01:18:02,660 --> 01:18:04,670
where we would have a shared handle and the handle

01:18:04,670 --> 01:18:07,220
would be open, right, but when the handle was open

01:18:07,220 --> 01:18:09,390
for the display what would happen is

01:18:09,390 --> 01:18:12,490
is the GPU processor would be pegged at that frequency.

01:18:12,490 --> 01:18:14,750
It was actually a bug because we needed to let go

01:18:14,750 --> 01:18:16,230
of the handle at a better time

01:18:16,230 --> 01:18:17,990
and it was a power management issue.

01:18:17,990 --> 01:18:19,980
But if there is some way like with IOA

01:18:19,980 --> 01:18:23,440
or some other mechanism, they could signal or notify

01:18:23,440 --> 01:18:28,170
that while this is held, keep it up, right,

01:18:28,170 --> 01:18:31,180
you wouldn't necessarily need to know specifically,

01:18:31,180 --> 01:18:35,070
that the consumer producer wouldn't have to know who is who.

01:18:35,070 --> 01:18:38,380
(speaking faintly)

01:18:38,380 --> 01:18:43,380
- This kind of resembles this thing that Yuri

01:18:43,440 --> 01:18:46,460
was talking about yesterday in a scheduler

01:18:46,460 --> 01:18:48,210
proxy execution problem, right.

01:18:50,640 --> 01:18:54,358
Pretty much it is very similar to that one

01:18:54,358 --> 01:18:59,358
because this is just pretty much like

01:19:00,330 --> 01:19:02,130
the same problem in different terms.

01:19:07,650 --> 01:19:10,763
- So with proxy there is a clear and unambiguous

01:19:10,763 --> 01:19:15,763
blocked on relation and this might not have that.

01:19:19,170 --> 01:19:22,600
- Right, that's correct, but maybe the,

01:19:22,600 --> 01:19:27,460
so my point is that maybe somebody should know that

01:19:27,460 --> 01:19:29,430
those two things are related, right.

01:19:30,291 --> 01:19:32,239
(speaking faintly)

01:19:32,239 --> 01:19:37,239
- Yeah, yes.

01:19:38,550 --> 01:19:41,650
- So if you use a mute, a few tags in two threads

01:19:41,650 --> 01:19:46,640
in application that they obviously are correlated.

01:19:50,550 --> 01:19:51,383
- Maybe.

01:19:51,383 --> 01:19:53,330
- Well no, they are because they use

01:19:53,330 --> 01:19:56,280
the same lock so there is at least

01:19:56,280 --> 01:19:58,460
one memory location they want to access.

01:20:01,160 --> 01:20:04,290
- Yeah but so the few tags,

01:20:04,290 --> 01:20:06,240
you don't know who will wake the futex.

01:20:07,250 --> 01:20:09,470
The futex is just a wait operation.

01:20:09,470 --> 01:20:12,118
It's futex wait and it'll sit there until

01:20:12,118 --> 01:20:15,200
somebody in that address space flips the bit

01:20:15,200 --> 01:20:17,520
and tells it, hey wake up now.

01:20:20,350 --> 01:20:22,310
So you don't know who of the many

01:20:22,310 --> 01:20:24,370
possible tasks that might be.

01:20:25,260 --> 01:20:28,200
- No but my point was that if you are

01:20:28,200 --> 01:20:32,730
a user-space programmer and if you put that few code

01:20:32,730 --> 01:20:34,460
then you kind of know that your threads

01:20:34,460 --> 01:20:36,610
are going to be working together.

01:20:37,610 --> 01:20:39,540
So you in principle, you could also

01:20:39,540 --> 01:20:41,990
do something else and say, hey these two threads

01:20:41,990 --> 01:20:45,870
are really correlated because XYZ, right.

01:20:50,150 --> 01:20:53,210
- So then you have a multi-threaded program

01:20:54,050 --> 01:20:56,730
that has a gazillion threads that do absolutely

01:20:56,730 --> 01:21:01,233
nothing important and two that actually do something.

01:21:01,233 --> 01:21:03,483
(laughing)

01:21:06,293 --> 01:21:08,210
- And I kind of had two similar issues in the

01:21:08,210 --> 01:21:09,830
embedded space, when you're talking about

01:21:09,830 --> 01:21:12,990
say display pipeline, we may have two threads working on it

01:21:12,990 --> 01:21:15,180
but if you are double buffering, you don't want

01:21:15,180 --> 01:21:17,630
to treat them as one combined load

01:21:17,630 --> 01:21:20,230
because they're not going to really delay each other.

01:21:20,230 --> 01:21:21,540
And then there are sometimes you're not doing

01:21:21,540 --> 01:21:23,250
double buffering, in which case you do

01:21:23,250 --> 01:21:25,470
want to consider them as one workload.

01:21:25,470 --> 01:21:27,340
This is going by wake or wakey doesn't

01:21:27,340 --> 01:21:28,990
really give you that information.

01:21:29,970 --> 01:21:32,530
So if you're single buffered, you want to run

01:21:32,530 --> 01:21:36,360
both of the CPUs really fast so that you can meet your needs

01:21:36,360 --> 01:21:40,700
but if you're double buffered you can take your own time.

01:21:40,700 --> 01:21:42,380
So it's pretty complicated.

01:21:42,380 --> 01:21:45,140
- Yes I know that, that's why there's no good solution,

01:21:45,140 --> 01:21:48,000
so that's, this is the best I could think about

01:21:48,000 --> 01:21:52,710
but I know it may impact some of those mobile.

01:21:54,127 --> 01:21:55,730
- I guess, I mean, would it be right to say

01:21:55,730 --> 01:21:58,890
we need some amount of input from those two threads

01:21:58,890 --> 01:22:00,840
I think to make useful decision.

01:22:00,840 --> 01:22:03,068
- Yeah but then somebody--

01:22:03,068 --> 01:22:05,166
- That is not forthcoming.

01:22:05,166 --> 01:22:05,999
- There's not be tuning or util clamping

01:22:05,999 --> 01:22:07,840
on a per app or per basis but.

01:22:09,090 --> 01:22:11,017
- That's not going to happen.

01:22:11,017 --> 01:22:12,710
(speaking faintly)

01:22:12,710 --> 01:22:15,784
Okay so if you know if you have better suggestion,

01:22:15,784 --> 01:22:19,990
let me know, or I'll just send a spanner patch,

01:22:19,990 --> 01:22:22,290
you can just do it as a record and just maybe comment

01:22:22,290 --> 01:22:24,840
and leave it if there's a solution you can suggest.

01:22:27,200 --> 01:22:30,990
- One more consideration, so if you can identify the tasks

01:22:30,990 --> 01:22:33,450
from user-space so without changing the application

01:22:33,450 --> 01:22:35,810
but you can still have some kind of monitoring mechanism

01:22:35,810 --> 01:22:39,700
to identify those misbehaviors, then using the pair task

01:22:39,700 --> 01:22:41,530
API can still set the output use.

01:22:41,530 --> 01:22:44,230
- Yes, if I have an user-space which is smart enough

01:22:44,230 --> 01:22:47,090
to identify the relationship, you can do it, yes.

01:22:47,090 --> 01:22:48,590
- Without changing the application, I mean,

01:22:48,590 --> 01:22:50,166
it can be a third party.

01:22:50,166 --> 01:22:51,020
- Yes, without changing the application.

01:22:52,810 --> 01:22:57,220
- Question, which Intel generation has this

01:22:57,220 --> 01:23:00,600
per core capability, normag Xeon like Skylake,

01:23:00,600 --> 01:23:02,660
Broadwell, do they have it?

01:23:02,660 --> 01:23:03,493
- Yes.

01:23:03,493 --> 01:23:04,780
- Okay so it's not like a latest

01:23:04,780 --> 01:23:06,990
I mean it was a while, okay.

01:23:06,990 --> 01:23:09,680
So in order to reproduce we send that if it's something

01:23:09,680 --> 01:23:11,396
that we don't have the other four.

01:23:11,396 --> 01:23:12,229
- (Lecturer) Yeah you need ten generation

01:23:12,229 --> 01:23:13,510
now you probably.

01:23:13,510 --> 01:23:14,880
- What do I need?

01:23:14,880 --> 01:23:16,130
- Tenth generation cores.

01:23:18,360 --> 01:23:20,550
- So for a client it is like what?

01:23:20,550 --> 01:23:22,038
- The Ice Lake.

01:23:22,038 --> 01:23:22,871
- The latest one, Ice Lake, yeah.

01:23:22,871 --> 01:23:25,510
So for the client, in the client space you need the latest.

01:23:25,510 --> 01:23:26,880
- But you can reproduce this on

01:23:26,880 --> 01:23:29,940
the servers, in any of the servers, yes.

01:23:29,940 --> 01:23:32,960
Yeah just run Schedule schedbench with sleep,

01:23:33,920 --> 01:23:34,753
you will see it.

01:23:34,753 --> 01:23:37,780
- Yeah and it's just that the ranges get bigger every.

01:23:37,780 --> 01:23:42,330
- Yeah, fine, sure.

01:23:42,330 --> 01:23:45,110
- Can you say again what you do in case

01:23:45,110 --> 01:23:48,460
your governor receives a shed CPU freq wake remote?

01:23:48,460 --> 01:23:53,460
- I, we have the, we have a boost, we know that

01:23:56,070 --> 01:23:59,090
we just increase the, we have something called EPP knob

01:23:59,090 --> 01:24:02,567
which all the minimum frequency, we can just increase it.

01:24:02,567 --> 01:24:03,690
So it it will--

01:24:04,760 --> 01:24:06,310
- The knob is expensive, right.

01:24:07,470 --> 01:24:10,310
- In Ice Lake, not, yeah, it's the that,

01:24:10,310 --> 01:24:12,010
it takes hundred cycles, it's not.

01:24:14,148 --> 01:24:15,877
- Too bright not to take affect.

01:24:15,877 --> 01:24:17,517
- At the ah sure.

01:24:17,517 --> 01:24:18,350
- Yeah.

01:24:18,350 --> 01:24:19,630
- As long as we don't have to wait.

01:24:19,630 --> 01:24:22,428
- Yeah, no, you don't wait, yeah.

01:24:22,428 --> 01:24:25,610
Okay so yeah if commented, let's test it

01:24:25,610 --> 01:24:29,270
and if you, I'm sure there are better approaches

01:24:29,270 --> 01:24:31,710
and one approach is I was thinking about doing in

01:24:31,710 --> 01:24:33,400
user-space write some smart app

01:24:33,400 --> 01:24:37,990
and to identify this relationship but it's not that,

01:24:37,990 --> 01:24:38,823
it's not immediately.

01:24:38,823 --> 01:24:39,660
- It's not easy.

01:24:40,717 --> 01:24:43,340
- It's not easy because that's has to be very smart, yeah.

01:24:49,474 --> 01:24:53,410
No question.

01:24:55,170 --> 01:24:58,227
- We are we are pretty much in a break time for, yeah,

01:24:59,905 --> 01:25:01,720
for the official break, so let's just do a break

01:25:01,720 --> 01:25:03,890
and then we will resume after it.

01:25:05,081 --> 01:25:07,331
(applause)

01:25:08,270 --> 01:25:09,270
- Thank you.

01:25:10,962 --> 01:25:13,957
- Hi, I'm Sudeep from Linux kernel team at ARM.

01:25:15,415 --> 01:25:17,600
So today I'm going to talk about

01:25:17,600 --> 01:25:20,690
device power management based on platform firmware.

01:25:20,690 --> 01:25:24,940
It's not just device, could be anything in the system.

01:25:24,940 --> 01:25:28,475
So basically the idea is using platform firmware

01:25:28,475 --> 01:25:31,610
instead of driving everything from OS.

01:25:32,480 --> 01:25:37,480
Lots of people are not happy with that idea,

01:25:37,540 --> 01:25:39,640
everybody wants this, can't also do it.

01:25:39,640 --> 01:25:43,320
Has been controversial topic but there are use cases

01:25:43,320 --> 01:25:46,259
and requirements that we just can't address,

01:25:46,259 --> 01:25:49,900
having everything all the control in Linux.

01:25:49,900 --> 01:25:54,900
So the idea here is, I'm just trying to standardize

01:25:57,380 --> 01:26:02,380
the interface and does achieve to some extent and like

01:26:05,390 --> 01:26:08,250
this is mostly getting used on quite complex systems

01:26:08,250 --> 01:26:11,840
like the high end mobile phones you would see

01:26:11,840 --> 01:26:14,790
which have a dedicated controller to do

01:26:14,790 --> 01:26:17,020
all the power management on your system,

01:26:17,020 --> 01:26:20,750
and every vendor trying to invent

01:26:20,750 --> 01:26:23,380
their own way to talk to this controller.

01:26:23,380 --> 01:26:27,970
So this interface is about standardizing that

01:26:27,970 --> 01:26:32,580
and we did start initially standardizing everything

01:26:32,580 --> 01:26:36,250
just to keep the changes minimal.

01:26:36,250 --> 01:26:39,040
The way we approach the solution is like,

01:26:39,040 --> 01:26:42,650
okay we have device, it needs some power domain,

01:26:42,650 --> 01:26:46,170
some performance domain or reset domain,

01:26:46,170 --> 01:26:48,150
clock domains, just hook them.

01:26:48,150 --> 01:26:51,770
And the sharing information is today

01:26:51,770 --> 01:26:53,750
given through the device tree,

01:26:53,750 --> 01:26:56,330
so you need to know for the device X,

01:26:56,330 --> 01:26:58,830
what do my power domain it's attached to

01:26:59,796 --> 01:27:03,370
say the domain Z power, performance domain Y.

01:27:03,370 --> 01:27:05,910
So all this information is needed.

01:27:05,910 --> 01:27:08,750
So we are just thinking about how we can

01:27:12,918 --> 01:27:14,670
move to like making a device centric

01:27:14,670 --> 01:27:17,950
and see, like it's most likely the way

01:27:17,950 --> 01:27:20,880
ACPI works today, like it's all device centric.

01:27:20,880 --> 01:27:23,420
Turn on the device, set to this state,

01:27:23,420 --> 01:27:26,520
it doesn't bother about what domains

01:27:26,520 --> 01:27:28,940
or where it is in the system.

01:27:28,940 --> 01:27:32,470
So the approach is more like that.

01:27:32,470 --> 01:27:35,740
So just to give a background on what

01:27:35,740 --> 01:27:40,320
most of the immediate systems had in the past,

01:27:40,320 --> 01:27:43,140
this shows how everything is in the operating system

01:27:43,140 --> 01:27:46,170
trying to deal with all the clocks, reset

01:27:46,170 --> 01:27:49,130
power domains, everything in the OS.

01:27:49,130 --> 01:27:54,130
So now it's migrating to this with some standard interface

01:27:57,080 --> 01:28:01,100
talking a standard protocol over anything

01:28:01,100 --> 01:28:02,940
can be the transport but you have

01:28:04,199 --> 01:28:05,390
a dedicated controller that talks.

01:28:05,390 --> 01:28:08,260
But you need not have a dedicated controller

01:28:08,260 --> 01:28:11,490
on your system, it could be just a service

01:28:11,490 --> 01:28:13,870
which is running somewhere remotely,

01:28:13,870 --> 01:28:16,170
it could be as a secure service on your

01:28:17,686 --> 01:28:20,450
like application processor itself.

01:28:20,450 --> 01:28:23,620
It's just abstracted and moved away

01:28:26,696 --> 01:28:27,860
so that the operating system need not know

01:28:27,860 --> 01:28:31,830
all those details about where which register to book

01:28:31,830 --> 01:28:35,300
and how to change for each and everything.

01:28:44,945 --> 01:28:47,596
- If you are saying that it could just be a service running

01:28:47,596 --> 01:28:50,640
either entrusted side or some other core processor

01:28:51,740 --> 01:28:56,370
and then you're also trying to standardize the protocol,

01:28:56,370 --> 01:28:57,650
wouldn't it be just simpler to just have

01:28:57,650 --> 01:28:59,530
a standardized ops and let them implement it?

01:28:59,530 --> 01:29:02,060
Like what is the benefit of doing this?

01:29:02,060 --> 01:29:03,470
Like there's already an abstraction layer

01:29:03,470 --> 01:29:05,640
by allowing people to implement ops

01:29:05,640 --> 01:29:07,390
and drivers can plug in and implement ops.

01:29:07,390 --> 01:29:12,390
- So I agree, I just gave that as the initial motivation

01:29:13,040 --> 01:29:16,520
with which we started this, but the requirements,

01:29:16,520 --> 01:29:18,770
as more and more requirements come,

01:29:18,770 --> 01:29:20,430
so we see the real lean.

01:29:20,430 --> 01:29:24,370
So just to get into the next requirement,

01:29:24,370 --> 01:29:28,400
so how would you do if you had two virtual machines

01:29:28,400 --> 01:29:30,190
one probably running some other OS

01:29:30,190 --> 01:29:31,810
and one running Linux?

01:29:31,810 --> 01:29:35,080
So do you go and implement custom interfaces

01:29:35,080 --> 01:29:38,900
in each of those and try to solve the problem

01:29:38,900 --> 01:29:41,740
or just have this standard interface

01:29:41,740 --> 01:29:46,740
and each virtual machines talk over the same interface.

01:29:47,100 --> 01:29:52,100
So this is becoming increasingly like high requirement,

01:29:52,630 --> 01:29:56,290
even in mobile platforms people want to run

01:29:56,290 --> 01:29:58,860
in the virtualized environment isolating

01:29:58,860 --> 01:30:01,940
the like partitioning the system

01:30:01,940 --> 01:30:06,160
and giving some parts isolated to a virtual machine

01:30:06,160 --> 01:30:11,000
and it deals with all the controls and power management

01:30:11,000 --> 01:30:14,070
or whatnot for that part of the, so.

01:30:14,070 --> 01:30:17,240
So that's one of like another motivation,

01:30:17,240 --> 01:30:20,680
why we need this more than ever.

01:30:23,150 --> 01:30:26,940
So what we have today is, as I said like

01:30:26,940 --> 01:30:30,580
when we started initially, it was all like

01:30:30,580 --> 01:30:32,520
just keep the changes minimal,

01:30:32,520 --> 01:30:36,230
let's just hook into existing frameworks

01:30:36,230 --> 01:30:40,410
we have in kernel, like we have devfs for performance,

01:30:40,410 --> 01:30:45,410
reset clock power domains, sensors, all those things.

01:30:45,960 --> 01:30:49,600
So it's all fine, it hooks up perfectly well

01:30:49,600 --> 01:30:54,310
and it's all fine but as I said,

01:30:54,310 --> 01:30:55,810
one of the motivation for this

01:30:55,810 --> 01:30:58,140
is also the virtualized environment.

01:30:58,140 --> 01:31:02,110
Do we want the virtual machine configuration manager

01:31:02,110 --> 01:31:04,340
to have each of these information

01:31:04,340 --> 01:31:06,970
like it has to know which clock domain

01:31:06,970 --> 01:31:10,010
it belongs to reset, so on and so.

01:31:10,010 --> 01:31:15,010
So the idea is can we make everything device centric.

01:31:15,700 --> 01:31:20,180
We just say, set this device to something

01:31:20,180 --> 01:31:25,140
and all the arbitration happens in the platform firmware.

01:31:27,574 --> 01:31:31,180
And also we have with this interface

01:31:31,180 --> 01:31:34,070
as we are dealing with virtual machines

01:31:34,070 --> 01:31:37,150
like the device isolation and giving permission

01:31:37,150 --> 01:31:41,020
for each of these devices and the controls

01:31:41,020 --> 01:31:44,820
they can have with this.

01:31:47,600 --> 01:31:51,590
So as I was telling, so this is a use case

01:31:51,590 --> 01:31:54,670
where we have these two resources here

01:31:54,670 --> 01:31:57,530
can be one of these power clock.

01:31:58,460 --> 01:32:03,250
So we are just saying this is one VM which is isolated

01:32:03,250 --> 01:32:08,250
on its own, it talks over this transport and controls this.

01:32:08,250 --> 01:32:10,840
Whereas another virtual machine can be having

01:32:10,840 --> 01:32:13,860
and your mean virtual machine

01:32:13,860 --> 01:32:18,580
manager can control what each of those domain

01:32:18,580 --> 01:32:21,610
can actually have control over.

01:32:21,610 --> 01:32:25,410
So the permissions and are all set here.

01:32:25,410 --> 01:32:30,410
So that's the idea but again like if we have to describe

01:32:35,030 --> 01:32:40,030
the entire topology, like what clock what power

01:32:40,400 --> 01:32:44,040
what performance, that is not going to scale

01:32:44,040 --> 01:32:47,910
because there is also requirements say that have to change.

01:32:51,210 --> 01:32:53,720
- Don't you need to describe that somewhere anyway?

01:32:55,185 --> 01:32:57,080
- Yeah, the idea what I am trying to say is like,

01:32:57,080 --> 01:33:00,370
do we need that or do we let platform, deal with it,

01:33:00,370 --> 01:33:02,982
because that's never going to end,

01:33:02,982 --> 01:33:05,770
as I was about to say like GPIO pin marks.

01:33:05,770 --> 01:33:08,960
So for this device to work, I have to do all these

01:33:08,960 --> 01:33:12,560
and to keep increasing this controls.

01:33:18,029 --> 01:33:19,460
- So basically you are saying that

01:33:20,400 --> 01:33:24,550
that it could in principle be done in the OS

01:33:24,550 --> 01:33:29,550
but that would require more and more complicated code

01:33:32,830 --> 01:33:37,670
in going forward, and which may not be scalable enough.

01:33:37,670 --> 01:33:41,160
And then it will be hard to address the case

01:33:41,160 --> 01:33:44,350
in which different OS is run in different VMs

01:33:44,350 --> 01:33:47,450
and have to control the same resources, right.

01:33:47,450 --> 01:33:50,650
- Yeah, it may be possible but not always true.

01:33:50,650 --> 01:33:53,670
So because of, as I said, like they want to isolate

01:33:53,670 --> 01:33:57,300
the system, so yeah, it's possible

01:33:57,300 --> 01:34:01,710
but if there is another VM running and it's sharing,

01:34:01,710 --> 01:34:05,280
if you have Linux running, taking control over all,

01:34:06,360 --> 01:34:08,120
that's just like stepping on each other.

01:34:08,120 --> 01:34:12,820
So yeah you could probably do but we want it to be isolated

01:34:12,820 --> 01:34:17,820
and put, left complete to the platform to solve this

01:34:18,320 --> 01:34:21,430
for you because you just don't know what

01:34:21,430 --> 01:34:23,110
other domains are actually running

01:34:23,110 --> 01:34:26,730
or VMs are running and what they are managing.

01:34:33,900 --> 01:34:35,920
- So one thing I see here, and like understand

01:34:35,920 --> 01:34:38,560
the value of what you're bringing forward.

01:34:38,560 --> 01:34:41,180
On a flip side, it pushes the complexity

01:34:41,180 --> 01:34:44,550
down into the firmware, and I fear that

01:34:44,550 --> 01:34:46,650
the complexity that we currently have

01:34:46,650 --> 01:34:48,980
and have to manage in any operating system,

01:34:49,930 --> 01:34:52,750
are just going to be coming back in a few years time

01:34:52,750 --> 01:34:55,443
when we see that there's more dependencies

01:34:55,443 --> 01:34:57,020
that cannot be accommodated in the firmware.

01:34:57,020 --> 01:34:59,790
So we're gonna, in my, I fear that we will

01:34:59,790 --> 01:35:04,260
have to revisit this again in the future.

01:35:04,260 --> 01:35:06,410
The complexity is just going to creep up again

01:35:06,410 --> 01:35:07,850
because we are going to see that there are things

01:35:07,850 --> 01:35:09,020
that we can't do in firmware

01:35:09,020 --> 01:35:10,940
that we're going to have to start doing

01:35:10,940 --> 01:35:12,480
in the operating system again.

01:35:13,615 --> 01:35:15,750
(faintly speaking)

01:35:15,750 --> 01:35:17,750
And then there will be battles between firmware

01:35:17,750 --> 01:35:21,170
and operating systems, and it will beget very complex.

01:35:21,170 --> 01:35:23,480
- Yep but like if you have a solution

01:35:23,480 --> 01:35:26,450
that we can solve this problem, you know is today,

01:35:26,450 --> 01:35:29,070
yeah like happy, but do we have

01:35:29,070 --> 01:35:33,300
any other better solution today to deal with this?

01:35:33,300 --> 01:35:38,300
- So you were saying something about you didn't want to,

01:35:39,930 --> 01:35:42,060
I completely didn't understand one of points

01:35:42,060 --> 01:35:44,430
you were trying to make about letting,

01:35:44,430 --> 01:35:46,690
doing this on a device level instead of a resource level.

01:35:46,690 --> 01:35:49,827
I'm not sure what you're, can you explain that more?

01:35:49,827 --> 01:35:52,850
- Yeah, just building up the case why we need.

01:35:52,850 --> 01:35:54,390
I'll just come to that soon.

01:35:56,187 --> 01:35:59,580
So this is just just two different,

01:35:59,580 --> 01:36:03,040
like it could be your application processor

01:36:03,040 --> 01:36:05,930
modem controlling shared resources.

01:36:05,930 --> 01:36:10,010
So what I was trying to tell is like,

01:36:10,010 --> 01:36:12,660
instead of having all this information,

01:36:12,660 --> 01:36:15,420
can we just make it device centric

01:36:15,420 --> 01:36:18,790
and say, I operate everything over the device.

01:36:18,790 --> 01:36:22,600
Like you just get a device ID and you just say,

01:36:22,600 --> 01:36:26,490
okay, I want to power on or whatever state,

01:36:26,490 --> 01:36:30,890
I want this performance level or I just want to reset.

01:36:30,890 --> 01:36:35,320
So just drive everything because the resource

01:36:35,320 --> 01:36:39,380
in the previous slide as I showed, the VMs have to

01:36:40,335 --> 01:36:43,550
like they just isolate the devices

01:36:43,550 --> 01:36:47,610
and having to give all the information around that device

01:36:47,610 --> 01:36:50,150
to each, is adds more complexity

01:36:50,150 --> 01:36:53,390
than just make it everything device centric and then say

01:36:53,390 --> 01:36:56,160
this is isolated and then deal with it, and if--

01:36:56,160 --> 01:36:58,900
- So okay, one second, when you're saying device

01:36:58,900 --> 01:37:01,778
here, in what context are you defining that?

01:37:01,778 --> 01:37:04,230
Are you talking about it as like a device

01:37:04,230 --> 01:37:06,350
as in the driver from driver core,

01:37:06,350 --> 01:37:08,870
we're talking about a device that?

01:37:08,870 --> 01:37:10,062
- Yes--

01:37:10,062 --> 01:37:11,320
- Because for everything listed here

01:37:11,320 --> 01:37:13,310
you have a corresponding thing on the right side,

01:37:13,310 --> 01:37:14,800
so I'm like not sure what the point

01:37:14,800 --> 01:37:16,870
you're trying to simplify here, I don't see it.

01:37:16,870 --> 01:37:19,240
- This device as I said, it could be even a CPU

01:37:19,240 --> 01:37:24,240
or your, some IP block, which it could be

01:37:24,580 --> 01:37:26,280
a security engine or it could be

01:37:26,280 --> 01:37:29,780
a random number generating, whatever it could be.

01:37:29,780 --> 01:37:31,640
- Okay maybe let me rephrase it

01:37:31,640 --> 01:37:33,310
and tell me if this is what you're trying to say.

01:37:33,310 --> 01:37:36,740
Are you trying to say instead of SCMI exporting,

01:37:36,740 --> 01:37:39,180
here are the ten clocks that you could use

01:37:39,180 --> 01:37:41,650
and here are the ten research states you could use.

01:37:41,650 --> 01:37:43,960
Are trying to say, here are the 10 devices

01:37:43,960 --> 01:37:45,590
you could use and out of these 10 devices,

01:37:45,590 --> 01:37:48,240
some of them have clocks, some of them have control.

01:37:48,240 --> 01:37:49,200
Is that what you are trying to say, or?

01:37:49,200 --> 01:37:50,380
- Yeah, those are--

01:37:51,370 --> 01:37:53,210
- Are you trying to like encapsulate the clocks

01:37:53,210 --> 01:37:56,540
and performance like as a subset of each device?

01:37:57,637 --> 01:37:58,470
Is that what you're trying to say?

01:37:58,470 --> 01:37:59,470
- Not each device, it's like,

01:38:00,510 --> 01:38:03,490
instead of having all this operate on the device

01:38:03,490 --> 01:38:08,490
and let the firmware or the platform deal with what is

01:38:09,990 --> 01:38:12,400
the clock it's connected to power domain connected to--

01:38:12,400 --> 01:38:14,610
- But it still won't ask the frequency for the device.

01:38:14,610 --> 01:38:15,443
- Yes.

01:38:17,470 --> 01:38:20,230
- So the idea is that for each device

01:38:22,530 --> 01:38:23,890
you have a certain

01:38:23,890 --> 01:38:27,160
number of resources related to it,

01:38:27,160 --> 01:38:31,624
and then you can either control all these resources directly

01:38:31,624 --> 01:38:35,730
or you can define power states say for the device,

01:38:35,730 --> 01:38:40,250
and define those power States in terms of those resources.

01:38:40,250 --> 01:38:42,070
So you say you say for example

01:38:42,070 --> 01:38:45,380
power state one is this clock is gated.

01:38:46,590 --> 01:38:49,870
Power state two is this clock is gated

01:38:49,870 --> 01:38:54,760
and that regulator is in this state, right.

01:38:55,643 --> 01:38:56,480
- Is it what he's trying to say then?

01:38:56,480 --> 01:38:57,827
- Yeah I think so.

01:38:57,827 --> 01:39:02,827
- So making it device specific or device centric--

01:39:03,550 --> 01:39:07,950
- So the Linux or any hose running under the VM

01:39:07,950 --> 01:39:09,690
would never actually specifically try

01:39:09,690 --> 01:39:12,520
to change a clock or a power domain.

01:39:12,520 --> 01:39:16,500
- They may not have that information if I'm trying to,

01:39:16,500 --> 01:39:18,750
the question I have is that like,

01:39:18,750 --> 01:39:21,650
in Linux how do we drive this?

01:39:21,650 --> 01:39:25,050
So this is how we would like to drive

01:39:25,050 --> 01:39:28,420
the specification towards because this removes

01:39:28,420 --> 01:39:32,820
a lot of complexity but how do we drive this inland access?

01:39:32,820 --> 01:39:35,720
My open question here, like do we just you reuse

01:39:35,720 --> 01:39:37,770
the power gen pd power domain?

01:39:37,770 --> 01:39:40,640
And since it already have this performance level

01:39:40,640 --> 01:39:43,278
do we extend it or do we come up with some

01:39:43,278 --> 01:39:46,390
different solution to all together?

01:39:46,390 --> 01:39:49,140
I'm just opening that.

01:39:49,140 --> 01:39:53,990
- Doesn't it just hook in, right in, into the structure?

01:39:53,990 --> 01:39:55,780
All you have to do is specify the domain

01:39:55,780 --> 01:39:59,640
and then you can do whatever you want on the back end part.

01:39:59,640 --> 01:40:02,680
- Yeah, I'm just asking the question here,

01:40:02,680 --> 01:40:06,516
so I'm fine it before we get into there,

01:40:06,516 --> 01:40:09,570
I just want to get the opinion of how would we look this,

01:40:09,570 --> 01:40:11,920
how do we want to solve this in Linux.

01:40:11,920 --> 01:40:13,750
- So essentially, depending on the granularity

01:40:13,750 --> 01:40:18,750
you want to kind of control things.

01:40:20,450 --> 01:40:24,205
You can either define a PM domain like ACPI does,

01:40:24,205 --> 01:40:29,205
with a set of operations in there

01:40:29,229 --> 01:40:34,229
and that could be called like ACMI PM domain,

01:40:34,260 --> 01:40:36,960
and then work pretty much the same way

01:40:36,960 --> 01:40:39,620
as the ACPI PM domain does.

01:40:39,620 --> 01:40:43,220
Or you hook up with Gen PD at a kind of lower level

01:40:43,220 --> 01:40:48,220
but then you have to expose the power domain hierarchy

01:40:49,727 --> 01:40:54,490
through the device tree, right, for that to work actually.

01:40:55,730 --> 01:40:59,130
- In the idealistic world we want just the leaf node

01:40:59,130 --> 01:41:02,030
not the hierarchy, leave the hierarchy to the firmware.

01:41:03,060 --> 01:41:04,047
- Well yeah, something.

01:41:04,047 --> 01:41:05,915
- But something to see if, I agree.

01:41:05,915 --> 01:41:07,403
- A part of it, right, so it depends on

01:41:07,403 --> 01:41:11,631
that you want to, where you want

01:41:11,631 --> 01:41:16,631
to have your control plane essentially, right.

01:41:21,777 --> 01:41:24,430
- So the idea is to have something either connect to

01:41:24,430 --> 01:41:28,650
Gen PD or create this IC on my power domain

01:41:28,650 --> 01:41:31,009
and create one for each device.

01:41:31,009 --> 01:41:32,688
- Have you tried anything?

01:41:32,688 --> 01:41:35,970
It's already-- - No, it's just new idea,

01:41:35,970 --> 01:41:37,560
so I'm just trying to.

01:41:37,560 --> 01:41:42,560
- So I guess, okay, so I guess my advice would be

01:41:43,640 --> 01:41:46,750
to try to do it in this way and that way

01:41:46,750 --> 01:41:49,000
and compare and then have an idea

01:41:49,000 --> 01:41:51,070
what's simpler, what works for you

01:41:51,070 --> 01:41:54,080
because at this point it's like we,

01:41:54,080 --> 01:41:55,500
yeah, you can do you can do this,

01:41:55,500 --> 01:41:58,570
you can do that, you can do something else.

01:41:58,570 --> 01:42:03,010
It would be good to have like an example to look at, right.

01:42:04,637 --> 01:42:09,130
- So another question that is kind of like my pet peeve

01:42:09,130 --> 01:42:11,430
with the CMI, I just want to call it out here.

01:42:13,710 --> 01:42:17,300
If ACMI is going to be adopted his arms position

01:42:17,300 --> 01:42:19,140
or upstream position gonna be,

01:42:19,140 --> 01:42:21,980
every former needs to follow ACMI going forward?

01:42:21,980 --> 01:42:25,940
- Like at least for the solution space

01:42:25,940 --> 01:42:28,090
we are addressing here, they should not come up

01:42:28,090 --> 01:42:31,620
with something which is just a,

01:42:31,620 --> 01:42:34,180
which makes no sense but no add on,

01:42:34,180 --> 01:42:36,140
so that would, what I would say like--

01:42:36,140 --> 01:42:37,570
- Because I see that the answer is--

01:42:38,627 --> 01:42:39,976
- If it's just another protocol trying

01:42:39,976 --> 01:42:41,620
to solve the same problem, I would say no,

01:42:41,620 --> 01:42:44,990
but if it's addressing something out of there--

01:42:44,990 --> 01:42:47,230
- Then I'm, okay, that's an okay pushing tab

01:42:47,230 --> 01:42:49,930
but just one thing that I noticed was that

01:42:49,930 --> 01:42:52,320
with all of these things ASCMI effectively makes

01:42:52,320 --> 01:42:54,900
fast switching impossible on ARM for CPU frequency scaling.

01:42:54,900 --> 01:42:57,370
- We do have that today, or in the latest.

01:42:59,570 --> 01:43:02,320
- So we are having a separate protocol for CP frequency?

01:43:02,320 --> 01:43:06,823
- No, we discovered that this has a fast transport

01:43:07,670 --> 01:43:10,210
where it just says, this is the registers,

01:43:10,210 --> 01:43:12,350
you can just write and it's--

01:43:12,350 --> 01:43:15,120
- Okay, part of the pet peeve is gone, thank you.

01:43:15,120 --> 01:43:15,953
- Yeah.

01:43:19,740 --> 01:43:20,740
Any other questions?

01:43:24,690 --> 01:43:25,810
No, nothing, okay.

01:43:29,942 --> 01:43:32,192
(applause)

01:44:05,220 --> 01:44:06,510
- Yeah, yeah it's a Windows laptop,

01:44:06,510 --> 01:44:07,760
boo hiss, get used to it.

01:44:12,150 --> 01:44:14,530
See if it wakes up, that would be funny, wouldn't it?

01:44:15,690 --> 01:44:17,840
We're about to do a talk on suspend resume.

01:44:18,990 --> 01:44:22,250
See how the other guys do.

01:44:22,250 --> 01:44:25,730
It may not wake up, that would be freaking hysterical.

01:44:30,118 --> 01:44:31,534
All right.

01:44:31,534 --> 01:44:32,367
- It's waking up.

01:44:32,367 --> 01:44:33,568
- Yeah, I can hear it.

01:44:33,568 --> 01:44:35,680
(laughing)

01:44:35,680 --> 01:44:37,670
- Yeah, I have a bunch of data on here that

01:44:39,600 --> 01:44:41,100
can't really get to otherwise.

01:44:41,990 --> 01:44:43,500
So my name's Lynn Brown.

01:44:43,500 --> 01:44:45,540
It's not this, I don't really have slides,

01:44:45,540 --> 01:44:47,300
I'm just going to show you some stuff.

01:44:48,496 --> 01:44:51,310
I work at Intel Open Source Technology Center

01:44:51,310 --> 01:44:52,810
along with a couple of guys in this room

01:44:52,810 --> 01:44:56,200
if you don't know me, and today we're going to talk

01:44:56,200 --> 01:44:59,210
about suspend resume quality in Linux.

01:45:03,724 --> 01:45:06,783
So five years ago, who was at Linux plumbers in Seattle?

01:45:11,010 --> 01:45:12,840
Okay, well then you may recognize some of this

01:45:12,840 --> 01:45:15,390
because that's when we introduced this tool called,

01:45:16,629 --> 01:45:19,050
at that time it was called Analyze Suspend.

01:45:19,050 --> 01:45:21,850
And now the way we ship it is in

01:45:21,850 --> 01:45:24,600
a part of this project called PM-Graph.

01:45:25,819 --> 01:45:27,320
It also has bootgraph in it but today we're going

01:45:27,320 --> 01:45:31,530
to talk just about the suspend graph part.

01:45:33,050 --> 01:45:35,070
So what I'm going to do right now is actually go to

01:45:35,070 --> 01:45:38,414
a web page that you can get to, it's 01.org PM-graph,

01:45:38,414 --> 01:45:40,970
and I'm just going to highlight some stuff

01:45:40,970 --> 01:45:42,870
from the getting started for those of you

01:45:42,870 --> 01:45:45,760
that weren't in that session 5 years ago.

01:45:47,850 --> 01:45:52,140
Very simple, oh good, you can actually see.

01:45:52,140 --> 01:45:56,990
You can clone this, it's open source, make install run it,

01:45:56,990 --> 01:45:58,990
run it as root, it's really that simple.

01:46:00,070 --> 01:46:01,820
Does have some, this tool does have

01:46:03,090 --> 01:46:07,250
some kernel dependencies, most distros have

01:46:07,250 --> 01:46:09,670
all of these in there already,

01:46:10,970 --> 01:46:12,410
and if you don't have all of them

01:46:12,410 --> 01:46:14,990
and some pieces of functionality work

01:46:14,990 --> 01:46:16,790
and some do not, I'll talk about that

01:46:16,790 --> 01:46:18,580
a little bit more when we go through

01:46:18,580 --> 01:46:20,130
examples of how the tool works.

01:46:23,110 --> 01:46:27,870
And then basic usage, it'd be sort of like this,

01:46:29,532 --> 01:46:32,350
you say sleepgraph - m mem would be for a suspend to mem.

01:46:32,350 --> 01:46:36,480
If you do a freeze it would do a suspend to idle.

01:46:36,480 --> 01:46:38,530
RTC wake says, after you've been,

01:46:39,591 --> 01:46:40,660
actually right before you suspend ARM

01:46:40,660 --> 01:46:42,790
the RTC to wake up in 15 seconds,

01:46:42,790 --> 01:46:44,280
it can be whatever number you like,

01:46:44,280 --> 01:46:46,170
that's how we usually run it.

01:46:46,170 --> 01:46:48,380
You could run it without that for testing

01:46:48,380 --> 01:46:53,080
other wake up sources, but for automated testing

01:46:53,080 --> 01:46:54,960
that's what we use because we don't have

01:46:54,960 --> 01:46:56,610
somebody there to press a button.

01:46:58,350 --> 01:46:59,390
There's a bunch of options,

01:46:59,390 --> 01:47:01,250
you can stick them into config files,

01:47:02,360 --> 01:47:05,300
and I think now I'm going to show you some,

01:47:05,300 --> 01:47:07,610
oh a couple of things we can do with it,

01:47:07,610 --> 01:47:09,890
this is an example output, but you know what,

01:47:09,890 --> 01:47:12,120
I'm going to go to a real webpage.

01:47:12,120 --> 01:47:13,770
So it's a HTML page like this.

01:47:16,300 --> 01:47:19,420
On the top it says, you know what it is,

01:47:19,420 --> 01:47:22,210
this is run on a 9360 which there's probably some

01:47:22,210 --> 01:47:26,150
in this room, it's a pretty good Linux laptop from Dell.

01:47:26,150 --> 01:47:31,150
And suspend time was 247 milliseconds,

01:47:32,310 --> 01:47:35,040
resume time was 3/4 of a second.

01:47:36,700 --> 01:47:38,970
In purple it reports, it self-reports

01:47:38,970 --> 01:47:41,080
how long it was in firmware.

01:47:41,080 --> 01:47:43,250
I don't believe what it's reporting here, it's saying

01:47:43,250 --> 01:47:46,790
one millisecond, but some of them are actually accurate.

01:47:49,070 --> 01:47:50,700
So that's sort of informational.

01:47:50,700 --> 01:47:52,410
And then what you're seeing on the screen

01:47:52,410 --> 01:47:55,950
is a graph from left to right in time.

01:47:55,950 --> 01:47:58,000
We initiated the suspend here about

01:47:58,000 --> 01:48:00,510
a quarter second before the actual suspend,

01:48:00,510 --> 01:48:03,400
SR this is the line between suspend resume.

01:48:03,400 --> 01:48:05,840
And then all of this to the right

01:48:05,840 --> 01:48:08,050
is how long it took us to wake up,

01:48:08,050 --> 01:48:10,950
and this basically says where the time went, okay.

01:48:12,374 --> 01:48:15,320
This is a suspend to mem.

01:48:16,790 --> 01:48:21,540
In mem, which commonly is a set up to do an ACPI S3

01:48:21,540 --> 01:48:24,440
but it could be a suspend to idle on another machine,

01:48:24,440 --> 01:48:25,970
but what you'll see on the suspend to mem

01:48:25,970 --> 01:48:29,240
is this blue and red, is the low level suspend

01:48:29,240 --> 01:48:30,820
and resume, that you don't see was to see

01:48:30,820 --> 01:48:32,730
with suspend to mem where you're offlining

01:48:32,730 --> 01:48:34,180
your processors and so forth.

01:48:35,950 --> 01:48:38,850
This is actually a pretty common scenario

01:48:38,850 --> 01:48:43,850
right here, where you're big guy might be

01:48:44,027 --> 01:48:49,027
nvme on suspend side, and USB is our nemesis

01:48:50,130 --> 01:48:53,200
on the resume side for a typical system.

01:48:55,960 --> 01:49:00,900
HD audio, not as much of a problem as it used to be,

01:49:00,900 --> 01:49:03,400
and often graphics, I don't know if

01:49:03,400 --> 01:49:07,770
this example right here has graphics on or off.

01:49:07,770 --> 01:49:09,490
If the graphics was off when you suspended

01:49:09,490 --> 01:49:10,890
then it will look different.

01:49:12,260 --> 01:49:14,970
You can zoom in, you can zoom out, you can,

01:49:14,970 --> 01:49:19,290
if we wanted to go look at our RS CPUs off lines,

01:49:19,290 --> 01:49:20,790
they'd be in here for example.

01:49:24,170 --> 01:49:26,720
Here's our machine suspend, machine resume,

01:49:26,720 --> 01:49:29,000
calls into the BIOS, it's all here.

01:49:31,310 --> 01:49:32,980
There's just a couple of other things

01:49:32,980 --> 01:49:34,340
that I'd like to point out with this tool,

01:49:34,340 --> 01:49:35,700
and then I'm going to talk about

01:49:35,700 --> 01:49:38,140
why I'm talking about this tool today,

01:49:38,140 --> 01:49:40,280
which is what we want to do with it.

01:49:41,190 --> 01:49:42,910
Actually there's, I think there's an example

01:49:42,910 --> 01:49:46,110
on the web page, at one point we were very concerned

01:49:46,110 --> 01:49:49,620
about back to back suspend resume, so then an X two.

01:49:50,660 --> 01:49:55,060
Sometimes there, to make suspend go faster, some things

01:49:55,060 --> 01:49:58,760
got deferred to the right side of that yellow bar,

01:49:58,760 --> 01:50:00,310
and you can't resume until those things

01:50:00,310 --> 01:50:02,450
have finished, you can't suspend again til

01:50:02,450 --> 01:50:03,730
those things have finished resuming.

01:50:03,730 --> 01:50:08,610
So this can be interesting, particularly in the case

01:50:08,610 --> 01:50:11,230
where you have a low latency, you wake up

01:50:11,230 --> 01:50:15,570
from Network, you want to wake up, wake up, wake up,

01:50:15,570 --> 01:50:17,990
well if you're still, you can't come back to sleep,

01:50:17,990 --> 01:50:19,940
you can't, if you're spending all your time

01:50:19,940 --> 01:50:23,810
suspend resuming, then you can't get any work done,

01:50:23,810 --> 01:50:25,250
you're basically on all the time.

01:50:25,250 --> 01:50:29,530
So we need fast suspend and resume and nothing deferred

01:50:29,530 --> 01:50:31,990
in between them that delays the next one.

01:50:34,110 --> 01:50:36,010
That's pretty important on some machines.

01:50:36,010 --> 01:50:39,540
On a laptop, if something takes under a second

01:50:39,540 --> 01:50:40,990
most people are pretty happy.

01:50:42,550 --> 01:50:45,100
But I'm showing you sort of the success cases here.

01:50:46,070 --> 01:50:47,890
There are a lot of non-success cases.

01:50:47,890 --> 01:50:50,610
And with that, I'm going to go to a summary.

01:50:50,610 --> 01:50:55,610
So first I have to apologize, we usually put our summary

01:50:56,790 --> 01:50:59,110
into Google sheet and this has been exported

01:50:59,110 --> 01:51:01,010
so that I could show it on this kind of laptop

01:51:01,010 --> 01:51:03,520
and I'm really pretty bad at Windows.

01:51:05,470 --> 01:51:07,760
But what this is, is a list of machines

01:51:10,664 --> 01:51:13,890
and it's the output of a number of tests.

01:51:13,890 --> 01:51:16,240
So say there's a Dell 9380 at the top,

01:51:18,536 --> 01:51:21,930
and line 2 is, we ran freeze for 24 hours

01:51:23,030 --> 01:51:28,030
and it suspended and resumed 2500 times,

01:51:28,250 --> 01:51:31,920
similarly with mem, 2700 times.

01:51:31,920 --> 01:51:34,460
This particular test setup we run for 24 hours

01:51:34,460 --> 01:51:36,310
and however many we fit in there.

01:51:36,310 --> 01:51:39,140
Another test lab we have we run

01:51:39,140 --> 01:51:40,930
generally around 2,000 cycles.

01:51:44,060 --> 01:51:48,020
Let's see, this health, we have a summary where we

01:51:49,220 --> 01:51:51,270
sort of wait different things, like if it crashed,

01:51:51,270 --> 01:51:53,104
that would be that would really

01:51:53,104 --> 01:51:55,454
impact this health, so we could sort by health.

01:51:56,770 --> 01:51:58,810
I do have machines which are 100% healthy,

01:51:58,810 --> 01:52:00,090
they're just not on here.

01:52:04,496 --> 01:52:07,538
And let's see, pass fail and hang,

01:52:07,538 --> 01:52:11,530
so one way you can run the tool is

01:52:11,530 --> 01:52:14,590
when we run the tool is, we would run it say

01:52:14,590 --> 01:52:19,590
for 24 hours on a system which has no state, and so on disk,

01:52:19,980 --> 01:52:22,720
and so when it resumes then we pull the data off.

01:52:22,720 --> 01:52:26,560
Well if it failed to resume, then we've lost the results.

01:52:27,899 --> 01:52:31,140
And so from our point of view, that's a hang

01:52:31,140 --> 01:52:33,140
and there's no result to look at,

01:52:33,140 --> 01:52:36,140
which is pretty annoying whereas on the ones we have

01:52:36,140 --> 01:52:39,220
with the disk, you can go back, you can reboot the machine,

01:52:39,220 --> 01:52:42,720
you still have your your system results there.

01:52:44,540 --> 01:52:47,360
Back of C 10, is this LPIR, so some details.

01:52:47,360 --> 01:52:49,730
This, probably a graphic is better for this.

01:52:49,730 --> 01:52:54,150
So this is suspend max medium and min time.

01:52:54,150 --> 01:52:58,840
So this first one, the maximum suspend time was 5.8 seconds,

01:52:58,840 --> 01:53:00,340
these are all in milliseconds.

01:53:01,290 --> 01:53:06,290
Resume, 7 seconds, usually 2 seconds and a 1/2 a second

01:53:07,280 --> 01:53:08,830
for resume, for that particular machine.

01:53:08,830 --> 01:53:12,370
It's sort of a new machine which still has some quirks.

01:53:13,850 --> 01:53:16,380
All right, so what do we do with this?

01:53:16,380 --> 01:53:18,530
We have this whole huge list of machines,

01:53:18,530 --> 01:53:20,890
actually we have a list a lot longer than this,

01:53:20,890 --> 01:53:22,600
I only have public machines here.

01:53:23,800 --> 01:53:26,340
So there's a, we happen to have in our lab,

01:53:26,340 --> 01:53:29,230
this is an organ lab we, have a couple of Dells,

01:53:29,230 --> 01:53:34,230
thank you Dell, and I think a Galaxy Book is a Samsung,

01:53:34,630 --> 01:53:39,500
thanks Samsung, and some HPs, there's a MacBook in there,

01:53:41,500 --> 01:53:43,600
and then a couple of Lenovo machines.

01:53:47,636 --> 01:53:49,770
And we've scrubbed all of these results

01:53:49,770 --> 01:53:52,060
which have been running for 24 hours a day.

01:53:52,060 --> 01:53:56,570
And in priority order, the first thing we do is

01:53:56,570 --> 01:53:59,100
grep for bad things in D message,

01:53:59,100 --> 01:54:03,270
and so say on this 9360, this DMAR,

01:54:04,360 --> 01:54:08,620
this happened 2800 times out of 28 tests, so.

01:54:09,960 --> 01:54:12,530
What we're trying to do when we are casting this net

01:54:12,530 --> 01:54:15,040
and looking for failures, is to find out

01:54:15,040 --> 01:54:17,390
what happens all the time, what's intermittent.

01:54:18,650 --> 01:54:21,350
If I wanted to bug something, where do I go to bug it.

01:54:23,250 --> 01:54:25,530
If I ran more tests on this machine

01:54:25,530 --> 01:54:27,230
would I learn any more, or is it better

01:54:27,230 --> 01:54:29,640
to run on that machine over there, okay.

01:54:30,520 --> 01:54:35,360
And what we're learning is that after around 2000 tests

01:54:35,360 --> 01:54:36,590
you pretty much got a good idea

01:54:36,590 --> 01:54:38,882
what this machine is going to do.

01:54:38,882 --> 01:54:42,830
I remember the day when I was,

01:54:42,830 --> 01:54:44,630
actually it was wasn't too long ago,

01:54:44,630 --> 01:54:46,940
where doing two suspend resumes on Linux

01:54:46,940 --> 01:54:49,310
was a big freaking deal, like if you could do it

01:54:49,310 --> 01:54:52,190
and then you did it again, you're like yes.

01:54:52,190 --> 01:54:55,670
Now it's like 2000 and oh, somebody else

01:54:55,670 --> 01:54:58,900
wants the machine for something else, 'cause.

01:54:58,900 --> 01:55:01,940
So really what we want to do now is

01:55:01,940 --> 01:55:03,690
find more faults from more machines.

01:55:03,690 --> 01:55:07,610
But let me scroll down, so these happen 100% of the time,

01:55:07,610 --> 01:55:11,950
but down here you'll get, sorry,

01:55:11,950 --> 01:55:13,410
like I said I'm bad at this,

01:55:15,310 --> 01:55:18,190
you'll get a lot of things that out of say

01:55:21,650 --> 01:55:25,740
1.08% of the time, we got some error message

01:55:25,740 --> 01:55:30,330
on say this Dell, okay, so the BIOS basically freaked out.

01:55:30,330 --> 01:55:32,220
We have no idea, it looks like a fan

01:55:32,220 --> 01:55:34,860
tried to turn itself off at some point,

01:55:34,860 --> 01:55:39,860
but it only happened 0.08% of the time, and that's

01:55:40,430 --> 01:55:44,690
a tough one, that's a tough path to follow to debug that.

01:55:44,690 --> 01:55:49,690
So we cast this net and we filed a bunch of Bugzillas.

01:55:50,720 --> 01:55:52,130
This is an example of one.

01:55:52,130 --> 01:55:53,100
By the way, I should say about

01:55:53,100 --> 01:55:55,100
all the stuff in this spreadsheet, Paul?

01:55:56,636 --> 01:55:59,639
- I'm just curious, is there some way

01:55:59,639 --> 01:56:01,199
you to accelerate the failure rate?

01:56:01,199 --> 01:56:02,767
For example, you mentioned the fan.

01:56:02,767 --> 01:56:05,308
Is it possible just to force a fan on and off at odd times

01:56:05,308 --> 01:56:06,749
while you're suspending or resuming?

01:56:06,749 --> 01:56:08,116
- Yeah, so that's a good question.

01:56:08,116 --> 01:56:11,202
So when you have a bug that's difficult to reproduce,

01:56:11,202 --> 01:56:14,214
how do you force it to happen more often?

01:56:14,214 --> 01:56:15,402
(speaking faintly)

01:56:15,402 --> 01:56:17,790
In that case, yeah, in that case, so for the fan

01:56:17,790 --> 01:56:19,300
if you were debugging that one in particular,

01:56:19,300 --> 01:56:22,010
which we do have some work going on in that,

01:56:22,010 --> 01:56:23,760
on that particular thing right now.

01:56:25,830 --> 01:56:28,320
Yeah, we could perhaps provoke that failure

01:56:28,320 --> 01:56:29,860
without even suspending and resuming,

01:56:29,860 --> 01:56:31,450
just by turning the device on and off,

01:56:31,450 --> 01:56:34,900
and with runtime device power management we can do that.

01:56:36,190 --> 01:56:39,790
This is one that actually, I like this example

01:56:39,790 --> 01:56:41,840
the best because it's something that's,

01:56:41,840 --> 01:56:44,207
it's on a bunch of different machines.

01:56:44,207 --> 01:56:45,850
So basically you may see in some of our bugzillas

01:56:45,850 --> 01:56:48,960
we suck a cookie, basically we have a script,

01:56:48,960 --> 01:56:51,080
it goes up to bugzilla and says,

01:56:51,080 --> 01:56:54,850
oh do I see that bug in this test results, okay.

01:56:54,850 --> 01:56:57,150
And so say I were looking for this bug I'd say,

01:56:57,150 --> 01:57:00,650
well on this Dell 9370 which is a cab u leik refresh

01:57:00,650 --> 01:57:04,240
I saw it 400 times, which is 17% of the time,

01:57:04,240 --> 01:57:07,530
that's a good machine to debug this problem, okay.

01:57:07,530 --> 01:57:09,790
But it's, this is the sound one,

01:57:10,810 --> 01:57:13,350
very intermittent but you see all these other machines,

01:57:13,350 --> 01:57:14,570
it's like whoa, okay this thing

01:57:14,570 --> 01:57:18,250
is happening .07 times on this, on say the 9360.

01:57:20,620 --> 01:57:24,720
And we have, we really had no idea.

01:57:24,720 --> 01:57:26,590
This one is actually a 5.0 result,

01:57:26,590 --> 01:57:28,650
we've actually fixed this.

01:57:28,650 --> 01:57:32,050
But then there's other bugs where it disappeared,

01:57:32,050 --> 01:57:33,640
like on these particular machines,

01:57:33,640 --> 01:57:36,540
this bug we found none of the test results,

01:57:36,540 --> 01:57:39,230
all 0% of the time found this failure.

01:57:41,117 --> 01:57:43,410
And these are just what we have happened to have documented,

01:57:43,410 --> 01:57:48,410
and then over here, this PCEI port device bug,

01:57:48,470 --> 01:57:51,460
this happens 100% of the time on the 9380.

01:57:55,470 --> 01:57:57,730
So one thing that we can do is

01:57:57,730 --> 01:58:01,113
we can look and see, okay if I want to,

01:58:01,113 --> 01:58:05,220
that's the kernel issue, so we've got,

01:58:05,220 --> 01:58:06,930
so we're scraping for kernel issues,

01:58:06,930 --> 01:58:09,660
we're scraping for file bugs, and now

01:58:09,660 --> 01:58:11,660
we're looking for slow devices.

01:58:11,660 --> 01:58:14,500
I didn't really show except for USB

01:58:14,500 --> 01:58:16,410
that some devices sometimes are very slow.

01:58:16,410 --> 01:58:18,606
I think there's an example in here

01:58:18,606 --> 01:58:20,550
where something took 50 seconds, in that amount of time

01:58:20,550 --> 01:58:22,724
somebody's going to press the button,

01:58:22,724 --> 01:58:24,274
right, so catastrophic failure.

01:58:25,250 --> 01:58:28,480
And here in fact we have sorted the worst suspend devices.

01:58:28,480 --> 01:58:32,220
Here's one, 32 seconds for this device

01:58:32,220 --> 01:58:35,810
on a MacBook Pro and it's the nouveau driver,

01:58:39,062 --> 01:58:40,430
so not sure what to say about that.

01:58:40,430 --> 01:58:45,430
But the interesting thing is that the average time,

01:58:46,640 --> 01:58:48,650
so the average time was one second

01:58:48,650 --> 01:58:51,180
but one, one time, it took 32 seconds

01:58:52,030 --> 01:58:55,540
out of 6,000 times that it was the worst device.

01:58:56,380 --> 01:58:58,070
And you can go all the way down.

01:58:58,070 --> 01:59:00,710
This is, we can sort all of our devices

01:59:00,710 --> 01:59:03,890
to I think, where we'd do the cut off at very low

01:59:06,410 --> 01:59:10,120
for some of these other, like CPU on and off,

01:59:10,120 --> 01:59:12,080
for some reason they're very slow on the Mac.

01:59:12,080 --> 01:59:15,230
I think they've got their MTRS set up wrong.

01:59:15,230 --> 01:59:19,560
Or this is a Browsewell, that's an old slow machine.

01:59:19,560 --> 01:59:24,010
So we can say, okay from the population of failures

01:59:24,010 --> 01:59:25,830
which ones are the most dramatic.

01:59:27,360 --> 01:59:29,220
We can see how often they happen.

01:59:30,830 --> 01:59:32,820
And say I go to worst resume devices,

01:59:32,820 --> 01:59:35,760
and then we can say, here's the 915,

01:59:35,760 --> 01:59:38,520
I could say, well for all the results I have,

01:59:38,520 --> 01:59:40,710
for the million results I have,

01:59:40,710 --> 01:59:43,510
on what machines is the 915 the slowest device.

01:59:43,510 --> 01:59:48,510
Oh okay, so I can scroll over and say, oh well it's great.

01:59:48,780 --> 01:59:52,010
This one right here is the machine I want to debug

01:59:52,010 --> 01:59:57,010
to 915 on because basically 3,000 times

01:59:57,460 --> 01:59:58,700
that's the slowest device.

01:59:58,700 --> 02:00:03,360
So if I want to work on that device, it's easy to sort them.

02:00:03,360 --> 02:00:07,850
So anyway, so what we have is we have this capability.

02:00:07,850 --> 02:00:09,540
A, you should be running it, particularly

02:00:09,540 --> 02:00:12,540
if you're concerned about suspend resume performance,

02:00:12,540 --> 02:00:14,450
particularly if you're concerned about it

02:00:14,450 --> 02:00:16,430
on a particular laptop you may have.

02:00:16,430 --> 02:00:17,930
B, you should be filing bugs.

02:00:21,690 --> 02:00:23,800
C, we are doing this automatically

02:00:23,800 --> 02:00:27,080
and we are we have moved from the,

02:00:27,080 --> 02:00:30,140
does it work and to how fast it is

02:00:30,140 --> 02:00:33,130
into the how reliable is it stage.

02:00:33,130 --> 02:00:35,380
We still have problems where it fails,

02:00:35,380 --> 02:00:37,920
we still have problems where it's slow,

02:00:37,920 --> 02:00:41,400
but now we're, gee does it run all night stage.

02:00:41,400 --> 02:00:43,110
And for the most part it does.

02:00:44,960 --> 02:00:48,780
And now the thing that we've discovered is

02:00:48,780 --> 02:00:50,840
we have 30 machines but what we need

02:00:50,840 --> 02:00:55,830
is 3500 machines, and my lab has a budget

02:00:55,830 --> 02:00:59,070
but it's not going to have 3500 machines.

02:00:59,070 --> 02:01:02,800
So what I'd really like is, I'd really like this test

02:01:02,800 --> 02:01:05,940
run by say Ubuntu, like opt in,

02:01:05,940 --> 02:01:09,160
send interesting information back to Ubuntu

02:01:09,160 --> 02:01:12,700
and have these results squirreled away

02:01:12,700 --> 02:01:14,750
when I, when your random Ubuntu user

02:01:14,750 --> 02:01:17,450
does their a suspend resume somewhere

02:01:17,450 --> 02:01:20,290
where somebody can debug them and have their finger

02:01:20,290 --> 02:01:23,000
on the pulse of how is Linux suspend resume

02:01:23,000 --> 02:01:24,280
working out in the wild.

02:01:25,290 --> 02:01:26,930
We can observe that and not only that,

02:01:26,930 --> 02:01:28,300
maybe even have enough information

02:01:28,300 --> 02:01:31,710
that we can go debug it and attack it.

02:01:31,710 --> 02:01:33,640
So I'm interested to know if anybody

02:01:33,640 --> 02:01:36,700
has any insight into public telemetry

02:01:37,990 --> 02:01:39,390
because that's what I really want.

02:01:39,390 --> 02:01:41,540
We're really good on the private telemetry.

02:01:42,652 --> 02:01:45,830
- Are you publishing this data already?

02:01:45,830 --> 02:01:48,300
- Not until today am i publishing this data.

02:01:48,300 --> 02:01:53,300
So say like if I were looking at this,

02:01:56,990 --> 02:01:59,724
say this bug report, right, so yeah.

02:01:59,724 --> 02:02:03,833
We let people know that we have this

02:02:03,833 --> 02:02:08,110
and particularly in the bug reports that we find,

02:02:08,110 --> 02:02:10,650
yes, I'm seeing this on the following 18 machines

02:02:10,650 --> 02:02:13,350
or I'm seeing this on this one weird machine over there.

02:02:15,550 --> 02:02:20,090
But it's not in some public place where say

02:02:20,090 --> 02:02:22,170
I got run over by a bus, somebody else could say,

02:02:22,170 --> 02:02:24,570
oh yeah and let's go work on the number one bug.

02:02:26,777 --> 02:02:28,220
If we weren't pushing this, I don't know if we,

02:02:28,220 --> 02:02:29,860
we don't really have a lot of community,

02:02:29,860 --> 02:02:32,210
we have a bunch, a couple of people at Intel working

02:02:32,210 --> 02:02:36,680
at this but I'd like to to be broader than that.

02:02:36,680 --> 02:02:38,730
I'd like to leverage the diversity

02:02:38,730 --> 02:02:42,760
of the community for a number of reasons, one is

02:02:42,760 --> 02:02:45,490
because the community has a lot more laptops than I have.

02:02:47,530 --> 02:02:49,730
Even if all the community did was report bugs,

02:02:49,730 --> 02:02:51,580
that would be a huge boon to us

02:02:51,580 --> 02:02:53,870
because we could say, oh my gosh, look at

02:02:53,870 --> 02:02:56,770
all these bugs that are appearing on this class of machine.

02:02:59,164 --> 02:03:01,100
So any ideas, thoughts?

02:03:01,100 --> 02:03:03,079
- There is the kernel CI thing, right,

02:03:03,079 --> 02:03:06,902
that they have like a distributed way of doing tests.

02:03:06,902 --> 02:03:11,333
I've seen that, I mean it's not power management specific,

02:03:11,333 --> 02:03:14,846
but they have some sort of testing.

02:03:14,846 --> 02:03:18,570
- So I mean I've talked about this with a couple of people,

02:03:18,570 --> 02:03:22,960
and say in Seattle, I said, hey we have this tool

02:03:22,960 --> 02:03:24,620
and the guys in this room, the people that care

02:03:24,620 --> 02:03:26,695
about power management, go run it.

02:03:26,695 --> 02:03:27,528
And some people said, sure.

02:03:27,528 --> 02:03:29,130
I mean you could all have downloaded it and run it

02:03:29,130 --> 02:03:31,570
in the time I've been talking, nobody has.

02:03:33,150 --> 02:03:36,980
And very few people have sent the results back to me

02:03:36,980 --> 02:03:39,960
or anybody that can debug them.

02:03:41,520 --> 02:03:44,870
So I think we're now past the stage where,

02:03:44,870 --> 02:03:47,176
hey we'll get the community, I'm going to

02:03:47,176 --> 02:03:48,009
volunteer my system for testing.

02:03:48,009 --> 02:03:51,100
No, what we really want is, during the day

02:03:51,100 --> 02:03:53,330
I've suspended and resumed eight times today,

02:03:53,330 --> 02:03:55,460
I could have sent eight results back, right.

02:03:55,460 --> 02:03:56,805
- Oh I see.

02:03:56,805 --> 02:03:59,440
- Yeah, automatically by opting in, right,

02:03:59,440 --> 02:04:01,740
by opting in, or maybe 1/8 of them

02:04:01,740 --> 02:04:05,900
or some sampling, some number larger than zero

02:04:05,900 --> 02:04:07,820
and that would be really useful

02:04:07,820 --> 02:04:10,810
because this is just a table of the 15 machines

02:04:10,810 --> 02:04:12,600
that we have right here and we've found

02:04:12,600 --> 02:04:16,340
some really interesting issues

02:04:16,340 --> 02:04:18,150
that you would never, you'd say,

02:04:19,210 --> 02:04:22,010
in your own laptop, if it didn't work 100% of the time,

02:04:22,010 --> 02:04:23,440
you're like, I must have done something wrong

02:04:23,440 --> 02:04:26,280
or maybe I sat on my laptop, whatever, reset it, but no.

02:04:26,280 --> 02:04:30,040
If it recorded it, we'll see one out of 2,000,

02:04:30,040 --> 02:04:33,190
we'll see that, oh wait, that's a real failure.

02:04:33,190 --> 02:04:35,020
And if we can nail that one out of 2,000

02:04:35,020 --> 02:04:37,330
then people will really start to trust

02:04:38,250 --> 02:04:39,590
Suspend Resume even more.

02:04:41,676 --> 02:04:44,370
So I want to have more machines with a 100% health

02:04:44,370 --> 02:04:46,370
for 2,000 tests, that's my goal.

02:04:47,770 --> 02:04:51,070
I have some but it's a very short list.

02:04:51,070 --> 02:04:53,580
Everyone has some blemish of some minute,

02:04:54,910 --> 02:04:58,130
100% perfect is a high bar.

02:04:58,130 --> 02:05:00,730
So yeah, I'm thinking opt in,

02:05:03,370 --> 02:05:04,700
and where does the results get stored,

02:05:04,700 --> 02:05:07,010
I should say that the results are like about,

02:05:07,010 --> 02:05:09,730
it's about 100K for one of these webpages.

02:05:09,730 --> 02:05:13,630
Yes, it's compressible, we can save the data

02:05:13,630 --> 02:05:16,270
without generating HTML to squeeze it down.

02:05:17,250 --> 02:05:19,720
Or we could just send the summaries.

02:05:19,720 --> 02:05:21,850
We have a script that will generate

02:05:21,850 --> 02:05:25,130
a Google Doc of a Google sheet of a summary

02:05:25,130 --> 02:05:29,020
of an entire directory of thousands of results.

02:05:29,020 --> 02:05:31,710
So if we could even just upload them somewhere

02:05:31,710 --> 02:05:33,650
and then you could run your favorite scraping tool

02:05:33,650 --> 02:05:35,520
to go look for problems, that would work,

02:05:35,520 --> 02:05:37,644
but we need a repository and we need

02:05:37,644 --> 02:05:41,930
community uploading those results.

02:05:41,930 --> 02:05:44,010
- I mean, I think it's a great idea,

02:05:44,010 --> 02:05:47,690
it's just that, how do you think

02:05:48,770 --> 02:05:50,790
you're gonna solve the problem

02:05:50,790 --> 02:05:54,860
having tests done on distro kernels?

02:05:56,030 --> 02:05:58,730
- On distro kernels, this will run on a distro kernel.

02:05:59,970 --> 02:06:02,650
- No, I meant like, you may see a problem

02:06:02,650 --> 02:06:04,930
that's only reproducible on kernels.

02:06:05,969 --> 02:06:07,960
- Okay, yeah, so most of the time it doesn't matter.

02:06:07,960 --> 02:06:10,100
I mean at this point, there was a time

02:06:10,100 --> 02:06:12,910
when it was pretty frantic, getting suspend resume running,

02:06:12,910 --> 02:06:17,910
now it's usually a device, like there's a couple of,

02:06:18,770 --> 02:06:20,410
I won't make fun of them, but there's a couple of

02:06:20,410 --> 02:06:22,810
choice devices that our OEMs choose

02:06:22,810 --> 02:06:27,510
to save like 10 cents, and yeah.

02:06:28,790 --> 02:06:33,000
So usually it's a device, and that's a device driver,

02:06:33,000 --> 02:06:35,980
and the distros, the same driver upstream has, so yeah.

02:06:35,980 --> 02:06:38,000
It's more information.

02:06:38,000 --> 02:06:40,180
Did I just turn myself off?

02:06:40,180 --> 02:06:41,013
- You did.

02:06:41,883 --> 02:06:46,883
- How did I do that, sorry.

02:06:47,062 --> 02:06:50,690
(speaking faintly)

02:06:50,690 --> 02:06:52,590
- She is coming.

02:06:52,590 --> 02:06:53,820
- My phone just talked to me too.

02:06:53,820 --> 02:06:56,412
Everything's malfunctioning up here.

02:06:56,412 --> 02:06:59,610
(speaking faintly)

02:06:59,610 --> 02:07:00,510
- Is that on, yes.

02:07:02,077 --> 02:07:03,010
- It's always the battery, it's the first.

02:07:03,010 --> 02:07:05,930
- I wanted to comment, this is inspiring,

02:07:05,930 --> 02:07:09,180
that's a good, I'm impressed by this project.

02:07:09,180 --> 02:07:12,270
I didn't think about this and it's a great idea.

02:07:12,270 --> 02:07:15,660
You obviously may want to talk to distro people,

02:07:15,660 --> 02:07:19,170
this has to go into the default images

02:07:19,170 --> 02:07:23,600
of the most popular distribution.

02:07:23,600 --> 02:07:26,190
This is one thing that I can think of.

02:07:26,190 --> 02:07:30,350
Obviously there is this, should I send back

02:07:30,350 --> 02:07:32,810
the bug report, to somebody is more sensitive

02:07:32,810 --> 02:07:34,500
to this than others, but I don't know,

02:07:34,500 --> 02:07:38,750
Firefox sent on telemetry back home and people accept that.

02:07:38,750 --> 02:07:43,390
I was thinking that a privileged venu

02:07:43,390 --> 02:07:47,480
to advertise this kind of work is the FOSDEM Conference

02:07:47,480 --> 02:07:52,480
in Brussels in Europe, it's a, stands for

02:07:52,500 --> 02:07:55,500
Free and Open Source Developer European Meeting,

02:07:55,500 --> 02:07:57,460
and it's a place where this kind of stuff

02:07:57,460 --> 02:07:59,990
is really taken to heart,

02:07:59,990 --> 02:08:02,010
like you would have people cheering for you

02:08:02,010 --> 02:08:03,550
if you show them this because they say,

02:08:03,550 --> 02:08:06,770
yes this is something I can really contribute to just,

02:08:06,770 --> 02:08:10,300
and the suspend resume affects everybody

02:08:10,300 --> 02:08:11,220
and everybody hates it.

02:08:11,220 --> 02:08:13,097
Like when I don't see my laptop coming back,

02:08:13,097 --> 02:08:15,040
it's not something like,

02:08:15,040 --> 02:08:17,270
I don't know, my network doesn't do IPV6,

02:08:17,270 --> 02:08:19,550
yeah I mean, I am I on the--

02:08:19,550 --> 02:08:21,500
- [Lynn] Very visible, right, some people think

02:08:21,500 --> 02:08:23,350
suspend resume and PM are synonymous.

02:08:24,618 --> 02:08:25,475
- But suspend resume, it's really

02:08:25,475 --> 02:08:26,877
something like, it's mission critical.

02:08:26,877 --> 02:08:28,609
So people are going to be enthusiastic about this

02:08:28,609 --> 02:08:30,640
if you or some of your collaborators

02:08:30,640 --> 02:08:32,435
can go and present there and have,

02:08:32,435 --> 02:08:35,780
and also you will meet a lot of distro people there.

02:08:35,780 --> 02:08:39,380
Like so you will have people approaching you saying,

02:08:40,250 --> 02:08:42,110
we should do this for fedora,

02:08:42,110 --> 02:08:43,580
we should do this for openSUSE,

02:08:43,580 --> 02:08:45,190
we should do this for Ubuntu.

02:08:46,670 --> 02:08:48,820
- Basdom, okay, good suggestion, thank you.

02:08:50,670 --> 02:08:53,990
Yeah so if any, does any, first of all I should,

02:08:55,060 --> 02:08:57,560
does anybody have any questions about the tool itself

02:08:57,560 --> 02:09:00,628
or its results, because I just sort of

02:09:00,628 --> 02:09:02,370
skipped through that a little bit,

02:09:02,370 --> 02:09:04,380
but you can all look at that,

02:09:04,380 --> 02:09:06,120
you can run it and look at your own results.

02:09:06,120 --> 02:09:08,460
It creates an HTML file, you open the file

02:09:08,460 --> 02:09:10,350
and you have what's run the screen right, here so.

02:09:10,350 --> 02:09:11,560
- I think you mentioned already

02:09:11,560 --> 02:09:14,470
but does it have an option to output

02:09:14,470 --> 02:09:17,520
a computer readable format?

02:09:18,850 --> 02:09:20,387
- Well it's--

02:09:20,387 --> 02:09:21,840
- Or is it only HTML?

02:09:21,840 --> 02:09:26,840
- It creates, it saves the D message in an F trace log

02:09:27,410 --> 02:09:31,010
and a tool specific log, and then a separate program

02:09:31,010 --> 02:09:32,660
comes and renders this from that.

02:09:33,690 --> 02:09:35,980
So you could grep through it, if you wanted

02:09:35,980 --> 02:09:38,080
another tool, you could do that too, yeah.

02:09:42,040 --> 02:09:43,690
A couple, get the mic back there.

02:09:51,230 --> 02:09:53,570
- I think that there's some privacy implications

02:09:53,570 --> 02:09:55,970
for this of course, so have you thought about

02:09:55,970 --> 02:09:57,720
what sort of things you'd be filtering

02:09:58,971 --> 02:10:01,010
from D message that would be sent up with this yet?

02:10:01,010 --> 02:10:06,010
- So yes, so like if, like we save the D message here,

02:10:06,930 --> 02:10:09,030
I guess maybe, how can I make that bigger,

02:10:10,440 --> 02:10:12,750
we save the D message from when you start to suspend

02:10:12,750 --> 02:10:15,724
to when your resume to see if something jumps out.

02:10:15,724 --> 02:10:18,530
We have some other logs involved,

02:10:18,530 --> 02:10:22,290
a tool specific log that grabs some stuff

02:10:22,290 --> 02:10:23,790
from the system that's useful.

02:10:25,170 --> 02:10:28,750
There is an option to trace processes

02:10:28,750 --> 02:10:30,840
that are to show what's running

02:10:30,840 --> 02:10:33,740
because sometimes a process will be doing something

02:10:33,740 --> 02:10:35,580
and we'll hang up a device and then

02:10:35,580 --> 02:10:38,770
the device hangs up suspend, like you're, I don't know,

02:10:38,770 --> 02:10:42,190
you're reading something out on Thunderbolt or something.

02:10:43,760 --> 02:10:47,120
And so, but that's an option, that's not on by default.

02:10:49,550 --> 02:10:51,290
This bit here, like where we can see,

02:10:51,290 --> 02:10:52,630
actually the one in front of us this,

02:10:52,630 --> 02:10:55,670
is an M sleep, this is, yeah.

02:10:55,670 --> 02:10:57,030
So a couple vendors have this,

02:10:57,030 --> 02:10:58,340
I think it's a bug workaround,

02:10:58,340 --> 02:11:00,170
that's hard-coded into the BIOS.

02:11:00,170 --> 02:11:03,280
It's sort of embarrassing but that's a, yeah,

02:11:03,280 --> 02:11:05,360
it is what it looks like,

02:11:05,360 --> 02:11:07,500
it's a two seconds sleep in the BIOS.

02:11:07,500 --> 02:11:10,091
There's really nothing we can do about it, you're like--

02:11:10,091 --> 02:11:11,670
(speaking faintly)

02:11:11,670 --> 02:11:13,550
- Yeah it's, I think it's an off method

02:11:13,550 --> 02:11:16,000
for maybe it's a fan or something, I forgot what.

02:11:17,380 --> 02:11:22,220
Yeah, so it's, this isn't the, HP has this one too.

02:11:22,220 --> 02:11:25,860
- Yeah so there are systems in which

02:11:25,860 --> 02:11:28,250
there are things like that in AML,

02:11:28,250 --> 02:11:33,090
essentially they wake, they wait for a certain fixed time.

02:11:33,090 --> 02:11:34,430
- [Lynn] Yes, it's bad.

02:11:34,430 --> 02:11:35,810
- Because to work around some issues.

02:11:35,810 --> 02:11:37,970
- And I believe this one, the workaround

02:11:37,970 --> 02:11:40,090
is only for resume, so the suspense side

02:11:40,090 --> 02:11:42,710
is completely bogus but yeah.

02:11:42,710 --> 02:11:44,980
I mean, you can really, closer you look at a BIOS

02:11:44,980 --> 02:11:46,280
the more you can embarrass a BIOS guy

02:11:46,280 --> 02:11:47,660
and we could do that all day long

02:11:47,660 --> 02:11:49,900
but that's really not what I want to talk about today.

02:11:50,893 --> 02:11:51,726
- That's not the main goal here.

02:11:51,726 --> 02:11:53,720
- Yeah, so we have, for me--

02:11:53,720 --> 02:11:54,760
- I should show a different one,

02:11:54,760 --> 02:11:55,810
I'll show a happier one.

02:11:55,810 --> 02:11:58,140
- Lynn, so we have two minutes left for this topic, so.

02:11:58,140 --> 02:11:59,450
- Well I'm just asking questions

02:11:59,450 --> 02:12:03,280
so I really had nothing to, I think one.

02:12:04,910 --> 02:12:06,452
- So there are two things there.

02:12:06,452 --> 02:12:10,030
Actually the packaging that stuff was easy

02:12:10,030 --> 02:12:12,240
and I actually did for the openSUSE

02:12:12,240 --> 02:12:15,110
and I want to try to push up to the factory

02:12:15,110 --> 02:12:18,780
and but the question is, how to,

02:12:18,780 --> 02:12:20,720
so where to gather the data?

02:12:20,720 --> 02:12:22,240
So where to upload?

02:12:22,240 --> 02:12:23,790
That's not defined yet, right.

02:12:23,790 --> 02:12:25,930
- Right, right, so if, say Google stepped forward

02:12:25,930 --> 02:12:28,280
and said hey, you can stick this on our Google drive

02:12:28,280 --> 02:12:30,990
with some credentials, we'd all be really happy about that

02:12:30,990 --> 02:12:33,360
because we know how to do, how to get to that.

02:12:33,360 --> 02:12:36,190
- Yeah that's, I'm not sure how this will work.

02:12:36,190 --> 02:12:39,760
- There's, so this spreadsheet here had a,

02:12:39,760 --> 02:12:43,050
say I ran 2000, we save all 2,000 results

02:12:43,050 --> 02:12:46,400
but we also say, we can also just reduce

02:12:46,400 --> 02:12:49,020
this down to save, like say, these.

02:12:49,020 --> 02:12:50,710
Like this, each one of these is a link

02:12:50,710 --> 02:12:53,760
to the fastest slowest and median, and it's a real result.

02:12:53,760 --> 02:12:55,810
I can open any of these, at least,

02:12:55,810 --> 02:12:58,140
I should be able to open any of those.

02:12:58,140 --> 02:13:00,560
And that's the median for this machine.

02:13:00,560 --> 02:13:03,071
So instead of all 2000, there's like

02:13:03,071 --> 02:13:05,440
about a dozen interesting ones, like the slowest device,

02:13:05,440 --> 02:13:09,100
the fastest device, anything with an oops

02:13:09,100 --> 02:13:13,340
or a kernel message in it, we grab those.

02:13:14,200 --> 02:13:15,760
And then a lot of them are just repeats,

02:13:15,760 --> 02:13:17,210
so we don't really have to store that.

02:13:17,210 --> 02:13:22,210
But yeah, I'd ballpark about 100K per result.

02:13:22,490 --> 02:13:25,610
We have to store that someplace, yeah.

02:13:25,610 --> 02:13:28,530
- Yeah and a weighted question is,

02:13:28,530 --> 02:13:30,480
so suppose that we get a data

02:13:30,480 --> 02:13:32,970
and we had a bug report for that

02:13:32,970 --> 02:13:36,800
and we fixed that, but how to verify the fix?

02:13:38,150 --> 02:13:41,220
- Well I mean, we run this every RC actually,

02:13:41,220 --> 02:13:43,340
and so the 5.0, of the bug I showed you

02:13:44,400 --> 02:13:46,006
with the audio is gone.

02:13:46,006 --> 02:13:47,810
- Yeah in that case, you guys have the machines

02:13:47,810 --> 02:13:50,310
but in the case the supposed access,

02:13:50,310 --> 02:13:52,160
we get we get a data from the pub,

02:13:52,160 --> 02:13:56,760
someone else publicly, and how to verify that?

02:13:57,653 --> 02:13:59,616
- I don't know, like any other bug,

02:13:59,616 --> 02:14:00,449
you debug it, you make it go away

02:14:00,449 --> 02:14:02,470
on what's in front of you and hopefully

02:14:02,470 --> 02:14:05,609
it goes away for everybody else, sometimes that works.

02:14:05,609 --> 02:14:08,490
But if they run it again and we get a result

02:14:08,490 --> 02:14:10,510
for that machine and it's clean, then we know it worked.

02:14:10,510 --> 02:14:14,600
So this also happens for regular bugs, like bugzilla,

02:14:14,600 --> 02:14:18,670
somebody files the bug, you see it,

02:14:18,670 --> 02:14:21,250
you fix it and then there's no response.

02:14:21,250 --> 02:14:24,436
You have to assume that it has been fixed, right, kind of.

02:14:24,436 --> 02:14:29,090
- The case of bugzilla is clear that there is a bug reporter

02:14:29,090 --> 02:14:32,930
but in that saboratory we get, we gather the data

02:14:32,930 --> 02:14:37,930
for improvement and, but we yeah,

02:14:38,150 --> 02:14:40,960
don't know exactly who submitted that data

02:14:40,960 --> 02:14:43,440
and we can verify that and improve it.

02:14:45,350 --> 02:14:46,730
- So say for this one, what we did was,

02:14:47,867 --> 02:14:49,090
we put a little attachment in the bug report,

02:14:49,090 --> 02:14:52,350
which sort of has a profile, this issue.def

02:14:52,350 --> 02:14:55,840
so that our tool will go out and say, okay, here's a result.

02:14:55,840 --> 02:14:59,580
And then we could see that that thing I showed you,

02:14:59,580 --> 02:15:02,940
with the audio bug, that was all done automatically

02:15:02,940 --> 02:15:07,940
by comparing this bug report with those test results

02:15:08,080 --> 02:15:11,290
and we could see that it was on all these machines in 5.0.

02:15:11,290 --> 02:15:15,700
It's gone and 5.0 RC, whatever it was, 5.1 RC6.

02:15:16,940 --> 02:15:18,950
So yeah, Bugzilla is good, if we can get

02:15:18,950 --> 02:15:20,750
into Bugzilla, we're in pretty good shape.

02:15:20,750 --> 02:15:22,800
- So what, just to clarify, what's your idea right now?

02:15:22,800 --> 02:15:24,880
Do you want people to send the reports to you,

02:15:24,880 --> 02:15:25,970
or do you want--

02:15:25,970 --> 02:15:28,870
- First of all, filing bugs we're all good with that,

02:15:28,870 --> 02:15:30,654
but yeah, what we really want,

02:15:30,654 --> 02:15:35,540
what the grand strategy is, we want to get data

02:15:35,540 --> 02:15:37,180
stuff running on all kinds of machines,

02:15:37,180 --> 02:15:40,230
that's what we really want is, we want to cast a broad net.

02:15:40,230 --> 02:15:42,750
We can run 24 hours a day on a machine

02:15:42,750 --> 02:15:47,011
we have in front of us, but I need 3,000 machines.

02:15:47,011 --> 02:15:48,420
That's really the message.

02:15:48,420 --> 02:15:49,340
I think this one last.

02:15:49,340 --> 02:15:54,210
- Yep, hello, I'm Victor Ruiz, I work in Red Hat.

02:15:54,210 --> 02:15:56,110
I own suspend resume, I work on

02:15:56,110 --> 02:15:58,805
the current hardware team QE.

02:15:58,805 --> 02:16:02,550
You have a pull request for me on Github

02:16:02,550 --> 02:16:06,010
from two years ago, so I'm very interested in in your work.

02:16:07,770 --> 02:16:11,800
I have a question about the tool itself,

02:16:11,800 --> 02:16:15,860
whether you are thinking about doing a client,

02:16:17,530 --> 02:16:21,040
client-server architecture to be able to get that

02:16:21,040 --> 02:16:25,110
when something growth run because if the machine

02:16:25,110 --> 02:16:29,820
doesn't resume then you are losing data.

02:16:29,820 --> 02:16:31,070
- Yeah that's a good question,

02:16:31,070 --> 02:16:34,140
so we basically have been running it

02:16:34,140 --> 02:16:36,880
via SSH on it when we have that situation.

02:16:38,700 --> 02:16:43,150
But that hasn't been a priority yet anyway.

02:16:43,150 --> 02:16:44,560
- Okay but let's talk.

02:16:45,699 --> 02:16:47,980
- Yeah okay, thank you, thanks.

02:16:47,980 --> 02:16:49,110
- [Moderator] All right, thank you.

02:16:51,584 --> 02:16:53,834
(applause)

02:16:55,853 --> 02:16:58,770
(faintly speaking)

02:17:18,856 --> 02:17:20,272
- Just press it to turn it on.

02:17:20,272 --> 02:17:23,189
(faintly speaking)

02:17:50,029 --> 02:17:52,820
- Okay, hi everyone thanks for having me.

02:17:53,830 --> 02:17:58,310
My name is Artem I worked for Intel from Finland.

02:17:58,310 --> 02:18:00,090
The subject of my talk is the

02:18:00,090 --> 02:18:02,310
C-state latency measurement infrastructure.

02:18:03,910 --> 02:18:07,410
Brief introduction, so in Intel

02:18:07,410 --> 02:18:10,580
we've developed a tool for measuring C-state latency,

02:18:10,580 --> 02:18:14,950
we call it WULT which stands for Wake Up Latency Tracer.

02:18:17,260 --> 02:18:18,390
Right now we are going through

02:18:18,390 --> 02:18:21,670
the process of open sourcing it.

02:18:21,670 --> 02:18:23,760
Unfortunately we are not done yet

02:18:24,760 --> 02:18:28,390
but as soon as we get the company approval

02:18:28,390 --> 02:18:31,880
we will publish it on Github under the GPL license.

02:18:33,270 --> 02:18:37,480
This tool has user space components and a kernel driver,

02:18:39,300 --> 02:18:41,860
and the plan is to upstream the kernel driver.

02:18:43,290 --> 02:18:45,310
So the reason I'm here is to get

02:18:45,310 --> 02:18:48,410
early feedback on the WULT kernel drivers

02:18:48,410 --> 02:18:51,500
and how do we transform them into something up streamable.

02:18:53,200 --> 02:18:55,590
Okay so let's talk about what exactly

02:18:55,590 --> 02:18:57,460
we measure and how we do this.

02:18:59,774 --> 02:19:03,830
I'll walk you through a simplified version

02:19:03,830 --> 02:19:06,430
of one single measurement cycle.

02:19:07,440 --> 02:19:10,070
So we start with Arm in a delayed interrupt.

02:19:11,160 --> 02:19:13,200
I'll talk a little bit more about what it is

02:19:13,200 --> 02:19:16,510
but just assume for now that the measured platform

02:19:16,510 --> 02:19:19,850
has a capability of generating an interrupt

02:19:19,850 --> 02:19:22,540
at a precise pre-programmed time in the future,

02:19:22,540 --> 02:19:25,610
sort of like a timer but there are some nuances there.

02:19:27,120 --> 02:19:28,940
So we armed the delayed interrupt

02:19:28,940 --> 02:19:31,680
so that it should happen at launch time in the future

02:19:33,140 --> 02:19:36,210
and then since we are measuring an idle system,

02:19:36,210 --> 02:19:38,160
it will at some point go to a C-state.

02:19:39,230 --> 02:19:44,230
On Intel platforms the CPU instruction that we execute

02:19:44,240 --> 02:19:45,950
to enter a C-state is mwait.

02:19:46,910 --> 02:19:49,000
I think on arms it's something like wfi.

02:19:49,945 --> 02:19:51,110
- Wfi, yeah.

02:19:51,110 --> 02:19:54,880
- Yeah, so okay, so the measured CPU executes mwait,

02:19:54,880 --> 02:19:56,900
it stops executing further instructions.

02:19:57,960 --> 02:20:02,020
It enters the C-state, sits there saving power

02:20:02,020 --> 02:20:04,980
and waiting for an event like an interrupt to happen.

02:20:06,790 --> 02:20:09,770
Then when it's launch time the delayed interrupt

02:20:09,770 --> 02:20:13,165
actually happens, it gets delivered to the mirrored CPU

02:20:13,165 --> 02:20:15,930
and kicks off the process of exiting the C-state.

02:20:17,830 --> 02:20:20,250
This process will take some time.

02:20:20,250 --> 02:20:22,520
When it's finished, the CPU will

02:20:22,520 --> 02:20:24,620
start executing the instructions

02:20:24,620 --> 02:20:26,970
after the end wait, and that's the point

02:20:26,970 --> 02:20:29,360
where we take the time after idle timestamp.

02:20:32,230 --> 02:20:36,080
So the C-state exit latency is the period of time

02:20:36,080 --> 02:20:39,660
between launch time and time after idle.

02:20:39,660 --> 02:20:43,700
In other words, it's a time between the moment we

02:20:43,700 --> 02:20:46,410
the delayed interrupt happens until the moment

02:20:46,410 --> 02:20:48,310
the CPU starts executing instructions.

02:20:50,240 --> 02:20:53,670
So the C-state latency is this difference.

02:20:54,630 --> 02:20:56,460
And that's basically what we measure

02:20:56,460 --> 02:21:00,450
and how we do it in a in a nutshell, the principle.

02:21:03,120 --> 02:21:04,380
Any questions so far?

02:21:07,170 --> 02:21:08,900
I assume that if there are questions,

02:21:08,900 --> 02:21:13,480
you can just interrupt me, I mean, you don't need to wait.

02:21:13,480 --> 02:21:15,180
Okay, few words, why is it useful.

02:21:17,900 --> 02:21:20,868
Okay, so the C-state latency information

02:21:20,868 --> 02:21:23,580
is today, is the foundation for

02:21:24,537 --> 02:21:26,550
the power management quality of service subsystem.

02:21:26,550 --> 02:21:29,790
On Intel platforms, we get this information

02:21:29,790 --> 02:21:33,550
either from the firmware through the ACPI tables

02:21:33,550 --> 02:21:37,550
or from the driver from intel_idle driver,

02:21:37,550 --> 02:21:39,200
they are just hard coded there.

02:21:39,200 --> 02:21:41,120
Now the truth is that these numbers

02:21:41,120 --> 02:21:43,010
are not always 100% correct.

02:21:45,280 --> 02:21:48,040
And they also may depend on platform configuration.

02:21:48,040 --> 02:21:53,040
So if we have a tool that is easy to use

02:21:53,380 --> 02:21:55,340
and that can measure these latencies,

02:21:55,340 --> 02:21:57,190
we will open lots of opportunities

02:21:57,190 --> 02:21:58,540
for improving this subsystem.

02:21:58,540 --> 02:22:01,180
For example we can improve numbers in intel_driver.

02:22:02,686 --> 02:22:04,850
Other point is that if you are someone

02:22:04,850 --> 02:22:07,690
who is building real time-ish product

02:22:07,690 --> 02:22:10,580
and for some reasons you are going to use C-states,

02:22:11,792 --> 02:22:13,800
maybe some of them, then measuring their latency

02:22:13,800 --> 02:22:15,650
is probably crucial for your product.

02:22:17,050 --> 02:22:18,790
And with this tool you wouldn't need

02:22:18,790 --> 02:22:21,120
expensive lab equipment to do so.

02:22:23,727 --> 02:22:24,560
- So can you just repeat again,

02:22:24,560 --> 02:22:28,640
what were the requirements from your hardware

02:22:28,640 --> 02:22:30,390
to use your tool or your driver?

02:22:30,390 --> 02:22:33,410
- Yeah so the question is, what are the requirements

02:22:33,410 --> 02:22:34,970
from the hardware to use the tool?

02:22:34,970 --> 02:22:37,120
So the requirement is to be able to

02:22:38,120 --> 02:22:39,840
generate a delay interrupt and I said

02:22:39,840 --> 02:22:41,550
I would talk a little bit later

02:22:41,550 --> 02:22:42,890
and I will very soon.

02:22:42,890 --> 02:22:43,990
- Okay.

02:22:43,990 --> 02:22:47,520
- Yeah, but before I will talk about that,

02:22:47,520 --> 02:22:49,710
I'll just very briefly show a quick,

02:22:49,710 --> 02:22:51,310
a visual example, just you know.

02:22:51,310 --> 02:22:52,230
- Sure.

02:22:52,230 --> 02:22:56,400
- So this talk is not about talking about the results

02:22:56,400 --> 02:22:59,560
and all that and user-space, it's about drivers,

02:22:59,560 --> 02:23:02,400
but I thought just showing an example of,

02:23:02,400 --> 02:23:05,850
this example will help understanding what we are doing.

02:23:05,850 --> 02:23:09,780
So this is a snapshot from a report,

02:23:09,780 --> 02:23:11,840
in this case it's the scatterplot,

02:23:11,840 --> 02:23:14,791
every dot is one single measurement,

02:23:14,791 --> 02:23:17,230
on the X we have the amount of time

02:23:17,230 --> 02:23:19,980
was spent in the end wait before the interrupt happened.

02:23:19,980 --> 02:23:22,280
We call it silent time, it's in milliseconds.

02:23:22,280 --> 02:23:25,380
On the y-axis we have the C-state latency,

02:23:25,380 --> 02:23:27,010
it's in microseconds.

02:23:27,010 --> 02:23:30,700
Now so in HTML, you can hover your mouse over a dot

02:23:30,700 --> 02:23:32,630
and then you get this little pop-up menu

02:23:32,630 --> 02:23:35,130
that tells details about the C-state.

02:23:35,130 --> 02:23:38,950
In this specific case, what do we have here,

02:23:38,950 --> 02:23:43,840
it says that we spend 2.5 milliseconds in end wait

02:23:43,840 --> 02:23:45,400
before the interrupt happened,

02:23:45,400 --> 02:23:49,110
and it took us 94 microseconds to wake up.

02:23:49,110 --> 02:23:51,880
And then the Linux request, it says six,

02:23:51,880 --> 02:23:54,370
but you know the C-state counters tells us

02:23:54,370 --> 02:23:57,686
that we were around 1% in CC zero course E0,

02:23:57,686 --> 02:24:00,810
like 13% in course E1 and so on.

02:24:03,478 --> 02:24:06,090
We had 73% in PC6 that's, yeah.

02:24:09,290 --> 02:24:11,710
So yeah, it's not it's not my goal to talk

02:24:11,710 --> 02:24:16,440
about the results, it's just a quick example.

02:24:16,440 --> 02:24:20,000
Okay, now let's talk about implementation details.

02:24:20,000 --> 02:24:23,840
Now if you have like rotten tomatoes prepared,

02:24:23,840 --> 02:24:27,870
don't throw it let me immediately, do hesitate.

02:24:27,870 --> 02:24:30,662
It's how it's implemented, right,

02:24:30,662 --> 02:24:34,674
it's not necessarily what we need to do in upstream, okay.

02:24:34,674 --> 02:24:38,550
Okay, delayed interrupts, so on your question.

02:24:38,550 --> 02:24:40,910
So today, in how we implemented it now,

02:24:40,910 --> 02:24:45,450
we use the I210 network card to generate delayed interrupts.

02:24:46,480 --> 02:24:51,270
So it's a Gigabit Ethernet card PCI Express device

02:24:51,270 --> 02:24:53,670
that you can buy in many shops around the globe.

02:24:55,250 --> 02:24:58,800
Now the nice thing about it, it has a built-in clock,

02:24:59,830 --> 02:25:02,600
high precision clock that host can read,

02:25:02,600 --> 02:25:04,750
and it also can generate an interrupt,

02:25:04,750 --> 02:25:06,864
a delayed interrupt for you.

02:25:06,864 --> 02:25:08,450
So basically what we do, we read the clock from the card,

02:25:09,334 --> 02:25:10,790
add a delay, write it back, tell the card

02:25:10,790 --> 02:25:12,270
generate interrupt at that point,

02:25:12,270 --> 02:25:14,530
and then we can go in into end wait.

02:25:14,530 --> 02:25:18,227
Now is this the only device that can do this?

02:25:18,227 --> 02:25:21,180
(faintly speaking)

02:25:21,180 --> 02:25:22,500
Yes, the question is,

02:25:22,500 --> 02:25:24,890
do we affinitize the interrupt to CPU, yes.

02:25:24,890 --> 02:25:26,700
So we select a CPU that we measure,

02:25:26,700 --> 02:25:28,868
affinitize the interrupted to that CPU, that's right.

02:25:28,868 --> 02:25:31,490
Now, yeah, it's not the only device

02:25:31,490 --> 02:25:33,790
that can do this, is what we use.

02:25:33,790 --> 02:25:37,120
I know other NICs can do this and there are

02:25:37,120 --> 02:25:39,820
other types of devices that can do this.

02:25:39,820 --> 02:25:42,450
For example, you can use display controller for that.

02:25:43,470 --> 02:25:44,930
Okay, so now the question is,

02:25:44,930 --> 02:25:46,500
why not using the timers, right,

02:25:46,500 --> 02:25:48,930
they are a perfect source of delayed interrupt,

02:25:48,930 --> 02:25:50,230
they're designed for that.

02:25:51,120 --> 02:25:54,180
The answer is that on Intel platforms they are too perfect,

02:25:55,100 --> 02:25:56,840
they are so perfect that they

02:25:56,840 --> 02:25:59,240
make C-state latency invisible.

02:25:59,240 --> 02:26:01,870
So the problem is that the P you need the microchip

02:26:01,870 --> 02:26:06,870
inside this Intel chip or PMC, it is aware of timers.

02:26:07,280 --> 02:26:10,620
So it will pre-wake the system, the core,

02:26:10,620 --> 02:26:14,170
and hide this latency and make it

02:26:14,170 --> 02:26:16,450
disappear or drop substantially.

02:26:16,450 --> 02:26:19,950
So in Intel platforms, we need to use something external,

02:26:19,950 --> 02:26:21,810
that's what why we use the network card.

02:26:21,810 --> 02:26:23,640
But probably there are platforms out there

02:26:23,640 --> 02:26:25,040
where timer's could be used.

02:26:27,210 --> 02:26:29,110
So yeah, that's on delayed interrupts.

02:26:29,950 --> 02:26:32,720
Now, high-level design, how we did it,

02:26:32,720 --> 02:26:34,030
how we implemented this.

02:26:34,880 --> 02:26:39,750
Okay so today we have two kernel components,

02:26:39,750 --> 02:26:42,280
and I will be talking just about the kernel.

02:26:42,280 --> 02:26:45,040
Everything I show is are kernel components.

02:26:45,040 --> 02:26:47,980
So we have two models, we implement this as models.

02:26:47,980 --> 02:26:51,090
One is called wult, one is called, the other is wult_igb.

02:26:52,130 --> 02:26:55,740
So the main logic of measurement is implemented in wult.

02:26:56,860 --> 02:27:00,040
And wult_igb is a simple driver

02:27:00,040 --> 02:27:03,850
that knows how to talk to the network card, okay.

02:27:03,850 --> 02:27:08,367
So wult implements in API and wult defines

02:27:09,690 --> 02:27:11,200
the API wult_igb implements it.

02:27:11,200 --> 02:27:12,870
So from wult point of view, wult_igb

02:27:12,870 --> 02:27:14,890
is just a delayed interrupts provider.

02:27:14,890 --> 02:27:17,367
It could be some other device, something else,

02:27:17,367 --> 02:27:18,800
so it's a small layer of abstraction.

02:27:20,415 --> 02:27:22,580
Now in Linux today, there is a standard driver

02:27:22,580 --> 02:27:25,840
for these network cards, it's called igb, Intel gigabit.

02:27:28,230 --> 02:27:33,230
So what we do, we unbind the NIC from this driver,

02:27:33,720 --> 02:27:35,530
and then bind it to wult.

02:27:35,530 --> 02:27:37,710
So igb doesn't own it anymore.

02:27:38,670 --> 02:27:41,880
Wult_igb driver is very small comparing to igb.

02:27:41,880 --> 02:27:46,530
All we do, reset the card, we do few instilization steps

02:27:46,530 --> 02:27:48,970
and then it's ready to be used as delayed interrupt source.

02:27:48,970 --> 02:27:52,300
We don't initialize the fi, we don't need to allocate rings

02:27:52,300 --> 02:27:55,610
and deal with these descriptors, no complexity.

02:27:55,610 --> 02:27:57,210
It's very tiny comparing to igb.

02:27:59,340 --> 02:28:03,230
Okay, now one of the components in the wult driver

02:28:03,230 --> 02:28:06,140
is what we call Armer kernel thread.

02:28:06,140 --> 02:28:08,920
It's a kernel thread and the mission of this thread

02:28:08,920 --> 02:28:11,690
is to continuously arm delayed interrupts.

02:28:11,690 --> 02:28:14,149
So all it does, it will pick a delay

02:28:14,149 --> 02:28:18,600
arm the interrupt, wait for it to happen,

02:28:18,600 --> 02:28:21,084
and continue this again and again and again.

02:28:21,084 --> 02:28:22,360
That's all it does.

02:28:23,370 --> 02:28:26,170
Then we have a debugging, debug fs interface

02:28:26,170 --> 02:28:28,150
for configuring this stuff, for example

02:28:28,150 --> 02:28:30,430
you can enable disable measurements,

02:28:30,430 --> 02:28:32,890
you have this delay min and max knobs

02:28:32,890 --> 02:28:36,850
where you can set the interrupt delay range.

02:28:36,850 --> 02:28:40,170
So the thread will pick a random number in this range

02:28:40,170 --> 02:28:43,590
and arm the interrupt that far away.

02:28:45,544 --> 02:28:46,680
Okay I'm just zooming the out components,

02:28:46,680 --> 02:28:48,650
so just to recap what we have,

02:28:48,650 --> 02:28:50,080
is the driver with a thread,

02:28:50,080 --> 02:28:52,710
it arms interrupts and waits for them to happen,

02:28:52,710 --> 02:28:54,420
otherwise the system is idle.

02:28:54,420 --> 02:28:56,230
The mirrored CPU has plenty of time

02:28:56,230 --> 02:28:58,920
to go to a C-state, so what happens, it will go

02:28:58,920 --> 02:29:02,850
to in a C-state, the interrupt will wake it up.

02:29:02,850 --> 02:29:05,070
Then it goes into a C-state again and we repeat this.

02:29:05,070 --> 02:29:07,500
So now how do we actually measure the latency?

02:29:09,100 --> 02:29:13,313
Okay, let's briefly talk about the current Intel idle flow.

02:29:13,313 --> 02:29:16,853
So we have the idle task, we have the CPU idle subsystem.

02:29:16,853 --> 02:29:19,940
So the subsystem will choose a C-state

02:29:19,940 --> 02:29:23,620
and then will enter it by calling the inter call back.

02:29:23,620 --> 02:29:26,340
This will go into the idle driver,

02:29:26,340 --> 02:29:30,340
in our case it's Intel idle driver, and Intel idle driver

02:29:30,340 --> 02:29:33,320
will ultimately call the end wait instruction.

02:29:33,320 --> 02:29:35,830
So here I assume that the mirrored CPU

02:29:35,830 --> 02:29:37,560
CPU is zero, but it can be anything else.

02:29:37,560 --> 02:29:41,460
And yes, the delayed interrupts are affinities to the CPU.

02:29:42,970 --> 02:29:46,310
Okay, so we have another component in wult,

02:29:46,310 --> 02:29:47,740
we call it interposer.

02:29:50,535 --> 02:29:52,535
So it basically puts itself right there.

02:29:55,410 --> 02:29:56,310
Right there, just.

02:29:58,780 --> 02:30:01,480
Now with interposer, the flow looks like this.

02:30:02,460 --> 02:30:05,800
So CPU idle tries to call the idle driver

02:30:05,800 --> 02:30:08,820
but it actually goes to the interposer

02:30:08,820 --> 02:30:12,990
so we have chance to take some stuff like time before idle.

02:30:12,990 --> 02:30:16,070
Then we go back to intel_idle, go to end wait.

02:30:16,070 --> 02:30:17,750
From end wait we go to Intel idle

02:30:18,643 --> 02:30:21,670
and back to interposer, we can measure stuff after idle,

02:30:21,670 --> 02:30:23,470
and then it will return to CPU idle.

02:30:27,851 --> 02:30:29,550
So now a few points here, important points,

02:30:29,550 --> 02:30:33,580
one important point is that CPU idle disables interrupts

02:30:33,580 --> 02:30:36,400
and preemption right before calling to idle driver.

02:30:36,400 --> 02:30:39,080
So in interposer we have this disabled.

02:30:40,540 --> 02:30:43,060
Other point is that in current implementation,

02:30:43,060 --> 02:30:45,890
we don't modify CPU idle, we don't modify Intel idle.

02:30:45,890 --> 02:30:50,580
What we do is we use Kiel sims to find the address

02:30:50,580 --> 02:30:53,360
of the function and then we use F trace

02:30:53,360 --> 02:30:56,380
to hook to it and interpose it.

02:30:56,380 --> 02:30:58,460
So no need to modify these subsystems.

02:31:00,620 --> 02:31:03,380
Okay, few words about what we do in interposer.

02:31:03,380 --> 02:31:08,380
So basically when CPU idle calls enter, we take,

02:31:08,582 --> 02:31:12,000
we can remember launch time, we take time before idle,

02:31:12,000 --> 02:31:15,170
we take snapshots of C-state counters.

02:31:15,170 --> 02:31:18,410
Then we go run until idle which goes to end weight.

02:31:18,410 --> 02:31:21,856
We sleep, we wake up, we go back to interposer.

02:31:21,856 --> 02:31:24,510
We take statistics after idle,

02:31:24,510 --> 02:31:27,080
like time after idle, C-states counter after idle.

02:31:28,053 --> 02:31:29,472
Linus?

02:31:29,472 --> 02:31:30,305
- So why don't you just call end wait.

02:31:31,422 --> 02:31:34,339
(speaking faintly)

02:31:35,364 --> 02:31:37,750
There must be some reason obviously.

02:31:37,750 --> 02:31:40,745
- Why don't we just call end wait our cells?

02:31:40,745 --> 02:31:42,869
- Intel idle does a suggestion.

02:31:42,869 --> 02:31:45,850
(speaking faintly)

02:31:45,850 --> 02:31:47,906
- Yes but I mean, like you would to

02:31:47,906 --> 02:31:51,779
iterate over all the suggestions,

02:31:51,779 --> 02:31:56,779
and iterate over all the different distances,

02:31:57,205 --> 02:32:02,061
time distances and get a scatter plot of that one, maybe.

02:32:02,061 --> 02:32:03,639
- Yeah we could do something like this,

02:32:03,639 --> 02:32:07,843
it's just, there is lots of knowledge

02:32:07,843 --> 02:32:12,146
about C-states in end wait, oh sorry, in the intel idle.

02:32:12,146 --> 02:32:15,730
We didn't want to duplicate it,

02:32:15,730 --> 02:32:17,590
but that's a right point, we want to be as close

02:32:17,590 --> 02:32:19,780
to this way as possible from both ends.

02:32:19,780 --> 02:32:22,710
And right now we are we're a little bit further away.

02:32:24,492 --> 02:32:26,220
I think it doesn't really matter.

02:32:26,220 --> 02:32:27,830
So we are talking about like hundreds of

02:32:27,830 --> 02:32:32,760
nano seconds versus microseconds here, but we could do this.

02:32:32,760 --> 02:32:36,020
The other point is that, with this sort of architecture

02:32:36,020 --> 02:32:40,853
we could actually also hook to ACPI idle.

02:32:40,853 --> 02:32:43,590
But yeah, that's an option, yeah.

02:32:44,940 --> 02:32:47,040
I don't know if this answers the question.

02:32:48,370 --> 02:32:50,690
Yeah so the other thing we do,

02:32:50,690 --> 02:32:52,090
I just wanted to mention is that

02:32:52,090 --> 02:32:53,820
we try to check the wake reason.

02:32:53,820 --> 02:32:55,860
So if we think we woke up because of something else

02:32:55,860 --> 02:32:58,620
not our interrupt, we just ignore all this data.

02:32:58,620 --> 02:33:00,570
But if we do think we woke up from interrupt,

02:33:00,570 --> 02:33:02,610
we send the data to user-space

02:33:02,610 --> 02:33:04,970
and how we do this, we use trace print K.

02:33:05,900 --> 02:33:10,370
So that's where I hope rotten tomatoes don't fly at me.

02:33:10,370 --> 02:33:13,740
I know that this is like not a way to go in upstream

02:33:13,740 --> 02:33:16,310
but that was a quick shortcut.

02:33:16,310 --> 02:33:18,610
So it ends up in the trace buffer,

02:33:18,610 --> 02:33:22,104
so user-space picks it from the trace of S.

02:33:22,104 --> 02:33:25,070
And yeah, that's basically the current design,

02:33:25,070 --> 02:33:26,140
that's how it works.

02:33:28,790 --> 02:33:32,810
So I have a list of challenges that I see.

02:33:34,190 --> 02:33:36,490
I can go to them and unless someone

02:33:36,490 --> 02:33:40,040
has comments or questions or suggestions.

02:33:42,760 --> 02:33:47,680
Okay so again, now I need high-level feedback,

02:33:47,680 --> 02:33:48,980
there are lots of details.

02:33:50,253 --> 02:33:51,860
Let's see, on high level first,

02:33:51,860 --> 02:33:54,410
kind of first thing is, where,

02:33:54,410 --> 02:33:56,970
if we to upstream this stuff, where would it leave?

02:33:56,970 --> 02:34:00,850
I drivers, idle wult, something like that.

02:34:02,171 --> 02:34:05,140
That's what comes to mind.

02:34:05,140 --> 02:34:07,220
Any other ideas?

02:34:08,190 --> 02:34:09,980
- [Lynn] All those in favor, say aye.

02:34:09,980 --> 02:34:12,135
- [Group] Aye.

02:34:12,135 --> 02:34:13,304
(laughing)

02:34:13,304 --> 02:34:15,690
- I mean, yeah, if no one comments

02:34:15,690 --> 02:34:18,120
then probably it's this or we'll see.

02:34:19,650 --> 02:34:22,080
Okay the other thing is the measurement data.

02:34:23,030 --> 02:34:26,440
So what do we send now to upstream?

02:34:26,440 --> 02:34:28,450
Well first of all we send the launch time,

02:34:28,450 --> 02:34:30,910
the time before time are after idle,

02:34:30,910 --> 02:34:35,340
then we calculate delta TSC, delta APERF MPERF,

02:34:35,340 --> 02:34:37,890
and then we get statistics before and after idle

02:34:37,890 --> 02:34:41,320
for C-states, and we send those, the deltas, to upstream.

02:34:41,320 --> 02:34:44,880
So is basically ends up right now being in one CSV line,

02:34:45,820 --> 02:34:48,720
comma separated line with of numbers.

02:34:48,720 --> 02:34:51,750
And but the for a very first line will be CSV header

02:34:51,750 --> 02:34:54,230
with a short name for those things.

02:34:54,230 --> 02:34:56,310
So what are the issues here?

02:34:56,310 --> 02:34:59,510
First of all, obviously is architecture dependent, right,

02:34:59,510 --> 02:35:03,980
but more than that, it also depends

02:35:03,980 --> 02:35:06,960
on which specific Intel platform we measure.

02:35:06,960 --> 02:35:11,483
C-states are different on add amps, on Kleins, on Xeons.

02:35:13,320 --> 02:35:17,510
Also, even MSR registers to read those C-states

02:35:17,510 --> 02:35:19,360
are different on different platforms,

02:35:20,300 --> 02:35:23,810
and we need to somehow read them.

02:35:23,810 --> 02:35:26,330
So what we do today, we just read all the possible MSRs

02:35:26,330 --> 02:35:28,460
for all the possible C-states we know

02:35:28,460 --> 02:35:31,340
for all the Intel platforms, right, and send lots of data.

02:35:31,340 --> 02:35:36,340
Now luckily, in most cases if we read C-state counter

02:35:36,760 --> 02:35:38,670
for a C-state that doesn't exist on this platform,

02:35:38,670 --> 02:35:40,970
we just zeros and we send zeros.

02:35:40,970 --> 02:35:43,410
In other cases we have an exception

02:35:43,410 --> 02:35:44,450
and then we just handle it,

02:35:44,450 --> 02:35:45,850
we remember we had an exception,

02:35:45,850 --> 02:35:48,860
never read again, and just always put zeros.

02:35:48,860 --> 02:35:51,680
So the user-space recognizes that,

02:35:51,680 --> 02:35:54,910
okay, for this C-state there are always zeros

02:35:54,910 --> 02:35:56,460
then it either it doesn't exist

02:35:57,532 --> 02:35:59,430
or it just disabled, then just ignore it.

02:35:59,430 --> 02:36:01,030
That's how we do it but obviously

02:36:01,030 --> 02:36:03,860
it's not like nice and cool.

02:36:03,860 --> 02:36:07,770
Ideally we need to put knowledge to kernel

02:36:07,770 --> 02:36:12,490
about hardware C-states on all the Intel platforms.

02:36:12,490 --> 02:36:15,250
Now we have all this knowledge in the Turbostar tool,

02:36:15,250 --> 02:36:18,250
which is part of the kernel tree but it's a user-space tool.

02:36:19,460 --> 02:36:21,740
It's there, so it would be cool

02:36:21,740 --> 02:36:25,050
to have this knowledge inside the kernel instead.

02:36:25,050 --> 02:36:28,040
Now, so Lynn Brown is here, I talked to him,

02:36:28,040 --> 02:36:30,840
he says that he would also like to have this too

02:36:30,840 --> 02:36:33,660
in Turbostat because it's a problem for turbostat.

02:36:33,660 --> 02:36:35,640
Now Turbostat uses, they have MSR

02:36:35,640 --> 02:36:38,030
and it reads these counters like one after another

02:36:38,030 --> 02:36:40,340
so there is a big time gap between them.

02:36:40,340 --> 02:36:44,010
Also the security people don't like dev MSR, they want

02:36:44,010 --> 02:36:47,290
to disable it, so Turbostat would also benefit from this.

02:36:47,290 --> 02:36:50,700
So probably we need something, some sort of function

02:36:50,700 --> 02:36:52,770
that would disable interrupts preemption

02:36:52,770 --> 02:36:55,310
and read all those counters, it would know

02:36:55,310 --> 02:36:58,182
all those counters for this platform, read them it

02:36:58,182 --> 02:37:02,847
in one go and then kernel consumers

02:37:02,847 --> 02:37:07,210
could run this function and somehow we could use,

02:37:07,210 --> 02:37:10,730
we could send it to user-space if Turbostat wants it.

02:37:10,730 --> 02:37:15,200
- What exactly do you mean by more C-state in the kernel?

02:37:16,210 --> 02:37:19,790
- Ah okay, so yeah when I say C-state syllable confusion

02:37:19,790 --> 02:37:22,450
there are, so I like to, this terminology,

02:37:22,450 --> 02:37:25,320
there are requested C-states, that's those,

02:37:25,320 --> 02:37:28,190
those that see that Linux can request,

02:37:28,190 --> 02:37:31,530
like arguments of the mwait instruction, right,

02:37:31,530 --> 02:37:34,260
but under the hood in the hardware,

02:37:34,260 --> 02:37:36,279
there are more C-states than this.

02:37:36,279 --> 02:37:38,750
I call them hardware C-states.

02:37:38,750 --> 02:37:41,950
So now Linux is aware of those requested C-states

02:37:41,950 --> 02:37:45,890
but Linux kernel is not aware of the hardware C-states.

02:37:45,890 --> 02:37:49,700
- Oh I see, so you are pretty much talking about,

02:37:49,700 --> 02:37:52,310
about the residency counters.

02:37:52,310 --> 02:37:53,143
- Exactly, yeah.

02:37:53,143 --> 02:37:54,690
- Yeah, okay.

02:37:54,690 --> 02:37:57,510
- So all this knowledge is in Turbostat today.

02:37:59,310 --> 02:38:03,830
Yeah so, any ideas, suggestions

02:38:03,830 --> 02:38:06,070
how to do this sort of stuff?

02:38:07,010 --> 02:38:10,590
- I guess maybe it's a question too,

02:38:10,590 --> 02:38:14,230
why the hardware C-states are not in the kernel yet?

02:38:15,970 --> 02:38:17,760
- [Moderator] You mean residency counters?

02:38:19,900 --> 02:38:20,733
- Or to Lynn.

02:38:22,713 --> 02:38:27,668
- So yeah, so I've shown a couple people this patch

02:38:27,668 --> 02:38:29,610
but what we're thinking of doing

02:38:29,610 --> 02:38:31,790
is moving the counters into perf

02:38:31,790 --> 02:38:34,850
where they'll be explicitly advertised by name,

02:38:34,850 --> 02:38:37,600
and so that a tool could look at them by name.

02:38:37,600 --> 02:38:39,840
What Artem wants them, I want them in user-space,

02:38:39,840 --> 02:38:41,980
he wants them in the kernel space.

02:38:41,980 --> 02:38:44,040
So right now we're using just an offset

02:38:44,040 --> 02:38:46,670
that we know from the data book into dev MSR

02:38:46,670 --> 02:38:50,250
and that's convenient but it has downsides,

02:38:50,250 --> 02:38:53,028
multiple system calls is one of them.

02:38:53,028 --> 02:38:54,450
So we want to be able to, we have to update perf

02:38:54,450 --> 02:38:56,679
to do this because you can't read

02:38:56,679 --> 02:38:58,240
multiple counters in one system call now.

02:38:59,080 --> 02:39:01,580
And we want to be able to name them with a vector.

02:39:02,820 --> 02:39:05,910
So that's I think the solution of that problem.

02:39:05,910 --> 02:39:09,920
- So maybe, to circle back on the question,

02:39:09,920 --> 02:39:14,390
the kernel cannot request for those specific states then,

02:39:14,390 --> 02:39:16,020
so that's why it doesn't make sense to have it.

02:39:16,020 --> 02:39:18,364
- [Lynn] And it just doesn't know.

02:39:18,364 --> 02:39:19,197
(speaking faintly)

02:39:19,197 --> 02:39:24,197
- So I think it hasn't been needed in the kernel so far,

02:39:24,690 --> 02:39:26,490
okay, so that's why it's not there.

02:39:27,780 --> 02:39:29,700
- So I have a different question

02:39:29,700 --> 02:39:31,390
from an architectural point of view,

02:39:32,720 --> 02:39:34,300
I say this with no love for BPF

02:39:36,514 --> 02:39:37,347
but this seems actually like quite a natural thing

02:39:37,347 --> 02:39:39,990
to try and solve with BPF because we could have

02:39:39,990 --> 02:39:42,410
arch dependent compilation with the right MSRs.

02:39:43,470 --> 02:39:45,290
You can do a much better export path

02:39:45,290 --> 02:39:48,070
relative versus trace print K.

02:39:48,070 --> 02:39:51,240
You could, there is BPF and puff interaction.

02:39:53,050 --> 02:39:54,870
It seems to solve a lot of problems.

02:39:54,870 --> 02:39:56,614
Has it been considered?

02:39:56,614 --> 02:39:57,890
- [Lynn] Can we access the read MSR?

02:39:57,890 --> 02:40:00,090
- You would have to extend the BPF program

02:40:00,090 --> 02:40:02,560
to give you the access to do that, right.

02:40:02,560 --> 02:40:04,985
There are a few things you could do that.

02:40:04,985 --> 02:40:05,920
You could either have it be something

02:40:07,130 --> 02:40:08,740
that side loads from like,

02:40:08,740 --> 02:40:10,370
I'm not saying it works out the box,

02:40:10,370 --> 02:40:12,770
I'm just saying whether you extended

02:40:12,770 --> 02:40:15,780
the BPF instruction set or you have side load

02:40:15,780 --> 02:40:20,040
prior to the BPF program in CPU idle, right,

02:40:20,040 --> 02:40:21,750
both of those things would work.

02:40:21,750 --> 02:40:23,600
But both of those things seem much simpler

02:40:23,600 --> 02:40:26,780
than what's been outlined with respect to

02:40:26,780 --> 02:40:29,800
both the arc concerns and getting data in and out

02:40:29,800 --> 02:40:31,350
and doing some of the analysis.

02:40:35,270 --> 02:40:36,960
So that's a kind of a general question.

02:40:36,960 --> 02:40:39,470
- [Lynn] Yeah no, we hadn't thought of that, thanks.

02:40:39,470 --> 02:40:42,170
- Yeah thanks, that's interesting suggestion.

02:40:47,200 --> 02:40:51,780
Okay another thing set of challenges

02:40:51,780 --> 02:40:53,470
are user-space interfaces.

02:40:54,540 --> 02:40:56,540
Let's see, so first of all, debugfs

02:40:56,540 --> 02:41:00,620
I feel like for upstream we, if we were in upstream

02:41:00,620 --> 02:41:04,360
it would need to be cisFS rather than the bugfs

02:41:04,360 --> 02:41:05,830
and I would imagine it would be

02:41:05,830 --> 02:41:07,460
something like sys class wult

02:41:08,401 --> 02:41:11,380
or any suggestions here or?

02:41:12,413 --> 02:41:14,963
- [Attendant] But if you, yeah, if you go BPF.

02:41:14,963 --> 02:41:18,010
- Yeah, if we go BPF, if I guess.

02:41:18,010 --> 02:41:21,190
Okay, so for, so these are more like

02:41:21,190 --> 02:41:22,790
configure the measurement themselves,

02:41:22,790 --> 02:41:24,510
like what are those delays.

02:41:24,510 --> 02:41:26,630
Oh they would be in the BPF program, you mean.

02:41:26,630 --> 02:41:29,880
- [Attendant] Right, it would simplify things.

02:41:32,440 --> 02:41:34,430
- Yeah but also we would need enough

02:41:34,430 --> 02:41:36,010
to just switch it on and off.

02:41:36,950 --> 02:41:38,110
- [Attendant] Load and unload.

02:41:39,000 --> 02:41:44,000
- Okay but if it's not BPF then something like this

02:41:46,653 --> 02:41:48,240
would probably make sense to start with.

02:41:50,396 --> 02:41:52,290
- [Attendant] So just trying BPF.

02:41:52,290 --> 02:41:55,850
- Yeah yeah, I understand but let's assume we tried

02:41:55,850 --> 02:41:58,540
and something didn't work, let's just assume.

02:41:58,540 --> 02:42:01,374
- [Attendant] Then you get worried.

02:42:01,374 --> 02:42:03,780
- I would make the meta suggestion

02:42:03,780 --> 02:42:05,230
building on the meta suggestion,

02:42:05,230 --> 02:42:07,460
that if you tried BPF and it didn't work,

02:42:07,460 --> 02:42:09,840
what didn't work in BPF might give you guidance

02:42:09,840 --> 02:42:12,608
as to what this interface should look like.

02:42:12,608 --> 02:42:15,030
- Right.

02:42:15,030 --> 02:42:18,670
- So in BPF, how would it look like?

02:42:18,670 --> 02:42:22,690
Is it like I write a program in some,

02:42:22,690 --> 02:42:25,800
I don't know much about, in some like language,

02:42:25,800 --> 02:42:27,860
special language and then I put it to the kernel

02:42:27,860 --> 02:42:31,180
and it's compiled and kernel execute it.

02:42:31,180 --> 02:42:33,533
- It compiles to native code.

02:42:39,498 --> 02:42:40,900
It compiles to native code but obviously you have some

02:42:40,900 --> 02:42:44,590
specific like read MSR dependency for your arch bits here.

02:42:44,590 --> 02:42:46,690
So it would be a combination of that

02:42:46,690 --> 02:42:49,300
plus either some extension to your program

02:42:49,300 --> 02:42:51,140
to allow it to make those reads,

02:42:51,140 --> 02:42:53,320
or an extension to read and hand it off

02:42:53,320 --> 02:42:55,550
to the BPF program if it's activated.

02:42:55,550 --> 02:42:58,950
But both of those, I'm not suggesting

02:42:58,950 --> 02:43:00,360
either of those is the answer, I'm saying

02:43:00,360 --> 02:43:04,770
those with two possibilities, yeah.

02:43:06,777 --> 02:43:11,777
- Okay, then yeah, this slide was

02:43:12,310 --> 02:43:16,840
about trace print K and my thinking about this.

02:43:16,840 --> 02:43:20,540
Yeah so I, what I want to, my vision here is that

02:43:20,540 --> 02:43:22,920
first of all the, by nature this data

02:43:22,920 --> 02:43:25,420
that we sent to upstream kind of belongs to tracing,

02:43:25,420 --> 02:43:29,310
it just feels like tracing is right, is the right fit.

02:43:30,580 --> 02:43:32,710
Now of course we shouldn't use trace print K.

02:43:32,710 --> 02:43:37,383
So I was thinking that if we,

02:43:38,298 --> 02:43:43,298
if we can use F trace anyway, so we can,

02:43:44,450 --> 02:43:48,250
CPU idle in CPU idle, when we call the enter function,

02:43:48,250 --> 02:43:51,705
we already have a pair of trace events,

02:43:51,705 --> 02:43:54,860
trace points around the enter invocation.

02:43:54,860 --> 02:43:57,918
So if we could hook to them so we can

02:43:57,918 --> 02:44:01,810
take measurements before in idle and after idle, that's one.

02:44:01,810 --> 02:44:04,760
And then if we could create a dynamically from the model,

02:44:04,760 --> 02:44:08,690
created a trace point, trace event that we can trigger,

02:44:08,690 --> 02:44:11,357
right, because the problem now is that

02:44:11,357 --> 02:44:12,750
trace points are, they are kind of static.

02:44:12,750 --> 02:44:14,740
You need to define the arguments

02:44:14,740 --> 02:44:17,310
in advance and like in compile time.

02:44:17,310 --> 02:44:19,400
In this case if we don't know in advance

02:44:19,400 --> 02:44:22,220
what are our C-states, what going to be our arguments,

02:44:22,220 --> 02:44:25,410
we need to create a trace point,

02:44:25,410 --> 02:44:28,220
trace event on the fly, right,

02:44:28,220 --> 02:44:30,820
and like dynamically from within the model.

02:44:30,820 --> 02:44:35,020
So if we had a way to dynamically create trace points.

02:44:35,020 --> 02:44:38,750
Okay Steven taught us yesterday the trace points

02:44:38,750 --> 02:44:40,010
and trace events are different things,

02:44:40,010 --> 02:44:43,090
that's why I kind of get confusing, but yeah.

02:44:43,090 --> 02:44:45,970
So if we could dynamically define a trace event

02:44:45,970 --> 02:44:48,610
from within the model, that would help us.

02:44:48,610 --> 02:44:49,900
We could take the measurement,

02:44:49,900 --> 02:44:53,550
trigger this trace event, it goes to the F trace

02:44:53,550 --> 02:44:55,710
and then perf can also consume it.

02:44:55,710 --> 02:44:58,300
I have patches in my mailbox from Thomson Lucy.

02:44:58,300 --> 02:45:00,320
I'm not sure if he sent them upstream or not

02:45:00,320 --> 02:45:02,810
but these patches implement exactly that

02:45:02,810 --> 02:45:06,160
you can create a trace event from within the model

02:45:06,160 --> 02:45:10,120
by calling several functions within the kernel.

02:45:10,120 --> 02:45:13,500
So that looks very promising, I didn't try them.

02:45:13,500 --> 02:45:14,950
So yeah that's my thinking.

02:45:14,950 --> 02:45:17,490
Any suggestions, comments here?

02:45:23,220 --> 02:45:27,660
- So with BPF you can hook up to existing trace points

02:45:27,660 --> 02:45:31,010
or you can use new trace points by,

02:45:32,639 --> 02:45:35,633
you could add trace points for that

02:45:35,633 --> 02:45:39,930
and hook up to them from the BPF program,

02:45:39,930 --> 02:45:43,490
and then you can define what information

02:45:43,490 --> 02:45:46,180
you will export from that.

02:45:46,180 --> 02:45:49,390
- Yeah right, so there, we have two tasks, right.

02:45:49,390 --> 02:45:52,110
One is to hook to before an after idle,

02:45:52,110 --> 02:45:53,300
that's task number one.

02:45:53,300 --> 02:45:54,920
So we have those trace points.

02:45:54,920 --> 02:45:57,360
- Yeah, so you just add trace points as you,

02:45:57,360 --> 02:46:00,080
defined as places to hook up to.

02:46:00,080 --> 02:46:04,750
- Right, and now we hook up, we collect data,

02:46:04,750 --> 02:46:06,630
now we have something to deliver to user-space.

02:46:06,630 --> 02:46:09,600
How do we deliver through which interface?

02:46:09,600 --> 02:46:11,520
So my thinking was to deliver,

02:46:11,520 --> 02:46:15,920
we dynamically create another trace event,

02:46:15,920 --> 02:46:18,560
let's call it wult trace event, sorry.

02:46:19,643 --> 02:46:20,480
- [Moderator] Well so I don't really

02:46:20,480 --> 02:46:22,080
have an answer ready for that,

02:46:22,080 --> 02:46:24,400
so we, let's just talk about it later.

02:46:24,400 --> 02:46:29,400
- For the eBPF, it can hook to the trace point

02:46:29,610 --> 02:46:34,070
like the idle entry or idle exit.

02:46:35,193 --> 02:46:39,020
This had been existed in the coder side.

02:46:39,020 --> 02:46:41,200
- Right right, I hooked, I have this hooked.

02:46:41,200 --> 02:46:44,150
I run my interposer it before and after, fine.

02:46:44,150 --> 02:46:45,730
I have data now.

02:46:45,730 --> 02:46:48,302
How do I deliver this data to user-space?

02:46:48,302 --> 02:46:50,500
- The eBPF where they have the map

02:46:50,500 --> 02:46:53,480
so they can communicate the data from the color side

02:46:53,480 --> 02:46:56,192
to the user side, so you can.

02:46:56,192 --> 02:46:58,630
But for the eBPF, I follow up one question

02:47:00,331 --> 02:47:02,560
that difficult to see in that,

02:47:02,560 --> 02:47:07,560
how you can create the map or to create eBPF program

02:47:09,760 --> 02:47:11,970
based on the different the CPU topology

02:47:11,970 --> 02:47:15,770
and the CPU idle states.

02:47:15,770 --> 02:47:20,400
So before that I write to the program

02:47:20,400 --> 02:47:21,600
like a hot code to that.

02:47:22,520 --> 02:47:25,080
I'm going to show how how to do that.

02:47:25,080 --> 02:47:29,860
I just to bring up maybe you need to resolve this.

02:47:32,050 --> 02:47:32,883
So you if you have that

02:47:32,883 --> 02:47:35,630
and you need to know the CPUs,

02:47:35,630 --> 02:47:40,397
how many CPU numbers and know what's the CPU idle states,

02:47:41,680 --> 02:47:44,280
then you need to create the eBPF of the program.

02:47:47,440 --> 02:47:49,300
This me might be issue.

02:47:49,300 --> 02:47:51,300
- Okay, so basically what I hear is that

02:47:52,340 --> 02:47:56,000
BPF has mechanisms, so you go figure out

02:47:56,000 --> 02:47:58,370
how to do it through BPF, okay.

02:47:58,370 --> 02:47:59,650
(faintly speaking)

02:47:59,650 --> 02:48:00,600
- Right, okay.

02:48:03,130 --> 02:48:05,290
- [Basdom] You said you want to hook

02:48:06,433 --> 02:48:07,630
before and after something, right?

02:48:07,630 --> 02:48:08,463
- [Artem] Yeah.

02:48:09,513 --> 02:48:11,332
- I am not sure I understand that part

02:48:11,332 --> 02:48:14,920
cause this event that you have is something that

02:48:14,920 --> 02:48:18,500
after you woke up from an idle residency

02:48:18,500 --> 02:48:20,920
you have a number which is the exit latency, right?

02:48:20,920 --> 02:48:21,753
- Yes.

02:48:21,753 --> 02:48:24,250
- So why do you want to hook up before and after?

02:48:24,250 --> 02:48:27,790
I mean you have the number, you just want to be after.

02:48:27,790 --> 02:48:28,970
- [Artem] Yes.

02:48:28,970 --> 02:48:31,400
- Like when you're after the residency completed

02:48:31,400 --> 02:48:34,580
then you have a number which is the exit latency.

02:48:34,580 --> 02:48:36,096
- [Artem] Exactly, yeah.

02:48:36,096 --> 02:48:37,610
- But I understand this being before and after something,

02:48:37,610 --> 02:48:40,295
like if you want to compute a difference, you have

02:48:40,295 --> 02:48:43,240
the difference, it's the knick who is computing that.

02:48:43,240 --> 02:48:46,070
So there's no before and after anything, just after.

02:48:46,070 --> 02:48:50,460
- So if for every data point, we need only a single number

02:48:50,460 --> 02:48:52,930
and this is the latency, that that's enough.

02:48:52,930 --> 02:48:55,630
Now we need more data than that.

02:48:55,630 --> 02:48:57,340
We need several other things.

02:48:57,340 --> 02:49:00,930
First of all is the C-state residency.

02:49:00,930 --> 02:49:04,710
So in x86 we have counters, that just count

02:49:04,710 --> 02:49:07,448
amount of cycles you spent in this C-state.

02:49:07,448 --> 02:49:09,570
I'm talking about hardware C-states now.

02:49:09,570 --> 02:49:11,490
In these hardware C-states, like let's say

02:49:11,490 --> 02:49:15,070
core C1 core C6 package C2 package C6,

02:49:15,070 --> 02:49:16,760
these are absolute numbers.

02:49:16,760 --> 02:49:19,530
So we need to take snapshot of them before idle,

02:49:19,530 --> 02:49:22,750
before M wait and after M wait, and then have the delta.

02:49:23,740 --> 02:49:26,890
Then we know that out of 100%,

02:49:26,890 --> 02:49:29,410
how much we spent in this and that and that

02:49:29,410 --> 02:49:30,980
because that is very helpful when

02:49:30,980 --> 02:49:32,710
you actually start analyzing the data

02:49:32,710 --> 02:49:35,580
and figuring out why it goes down here always

02:49:35,580 --> 02:49:39,170
because you don't have package C6 here.

02:49:39,170 --> 02:49:40,870
And there are there are so many things

02:49:42,475 --> 02:49:44,520
actually you can learn from that, that's why.

02:49:44,520 --> 02:49:45,520
- I have a question.

02:49:47,487 --> 02:49:49,130
So when you imagine the new latency,

02:49:49,130 --> 02:49:52,100
how do you change the system to use a new number?

02:49:54,770 --> 02:49:57,730
- Okay, so right now we didn't change anything.

02:49:57,730 --> 02:50:00,830
So I didn't even finish open source in this tool

02:50:00,830 --> 02:50:02,440
so it's too early to say but

02:50:04,850 --> 02:50:07,650
yeah that's a good for one forward-looking question.

02:50:07,650 --> 02:50:10,882
I don't know if I have good answers right now.

02:50:10,882 --> 02:50:14,390
But I would imagine that others could also try this

02:50:14,390 --> 02:50:18,580
and we could figure it out, yeah.

02:50:21,930 --> 02:50:25,370
- So we have like two minutes to go and then

02:50:25,370 --> 02:50:27,800
the session recording is going to stop at that point.

02:50:27,800 --> 02:50:31,540
So if you want your question recorded, ask it now

02:50:32,560 --> 02:50:37,560
and then yeah, there is, give the mic to them.

02:50:41,380 --> 02:50:43,440
- Yeah it's something related.

02:50:43,440 --> 02:50:47,580
So you mentioned there's a pre wake up CPU timers

02:50:48,560 --> 02:50:51,550
and I'm not sure if manual governor has already been fixed

02:50:52,603 --> 02:50:55,920
because there's a lot, there's a few heuristics

02:50:55,920 --> 02:51:00,160
based on the timer so they can decide to inter C6 or not.

02:51:01,848 --> 02:51:04,270
So if you have this feature, you can just

02:51:05,140 --> 02:51:06,550
for any platform supporting this feature,

02:51:06,550 --> 02:51:09,740
we need to turn off this in the menu governor.

02:51:09,740 --> 02:51:11,940
- Yeah I don't think they are related.

02:51:11,940 --> 02:51:14,580
So menu governor, when you select the C-state to enter,

02:51:14,580 --> 02:51:18,200
right, it's a different thing,

02:51:18,200 --> 02:51:19,370
it's not see state latency.

02:51:19,370 --> 02:51:20,380
It's the break even.

02:51:20,380 --> 02:51:22,030
- It's not orse thing but it's something

02:51:22,030 --> 02:51:24,470
you might need to be fixed in menu governor

02:51:24,470 --> 02:51:26,290
because you have this feature.

02:51:26,290 --> 02:51:28,760
- No, I don't think they are related.

02:51:28,760 --> 02:51:30,530
In menu governor when you select the C-state

02:51:30,530 --> 02:51:32,860
and you know you have to be in this C-state

02:51:32,860 --> 02:51:36,300
at least let's say 200 microseconds

02:51:36,300 --> 02:51:38,720
for it to make sense to save any power

02:51:38,720 --> 02:51:43,350
and you know the next interrupt is 100 microseconds away,

02:51:43,350 --> 02:51:45,440
doesn't make sense to request these deep C-state,

02:51:45,440 --> 02:51:46,740
you request more shallow.

02:51:46,740 --> 02:51:48,490
So it's about power break even,

02:51:48,490 --> 02:51:50,660
it's not about C-state exit latency.

02:51:50,660 --> 02:51:52,280
Although, okay.

02:51:52,280 --> 02:51:55,320
- It's all based on the estimation of future recaps

02:51:55,320 --> 02:51:58,480
but one of the input of how long it's going to

02:51:58,480 --> 02:52:00,980
wake up is actual timer expiration.

02:52:00,980 --> 02:52:03,650
So actually with only that, if you have already have.

02:52:05,980 --> 02:52:08,100
- Okay yeah, we don't have time I think

02:52:09,051 --> 02:52:12,060
but I suggest to talk about this to Rafael.

02:52:12,060 --> 02:52:13,700
He knows everything about that.

02:52:14,550 --> 02:52:16,870
Yeah but my personal opinion, these are not,

02:52:16,870 --> 02:52:18,670
these are kind of orthogonal things.

02:52:18,670 --> 02:52:21,270
- So the short answer is, this is a different timer.

02:52:24,290 --> 02:52:26,620
This is a different timer, it's not the timer he's using.

02:52:26,620 --> 02:52:28,263
It's a different timer.

02:52:28,263 --> 02:52:29,540
- [Attendant] Yeah I'm not talking about different,

02:52:29,540 --> 02:52:34,020
maybe computated, totally independent now his work

02:52:34,020 --> 02:52:36,730
but something like somewhat related.

02:52:36,730 --> 02:52:39,120
- Okay, let's talk about that later.

02:52:39,120 --> 02:52:42,370
Now we need to finish the session at this point.

02:52:43,938 --> 02:52:45,170
Of course we can continue the discussion.

02:52:45,170 --> 02:52:48,490
We have the room for the rest of the evening today.

02:52:48,490 --> 02:52:51,440
But the recording as I said is going to finish

02:52:51,440 --> 02:52:54,500
pretty much right now, so thanks a lot everybody for.

02:52:54,500 --> 02:52:56,410
- [Lynn] Everything else is off the record.

02:52:56,410 --> 02:52:59,090
- Everything else is off the, record, yeah.

02:52:59,090 --> 02:53:01,265
(laughing)

02:53:01,265 --> 02:53:03,090
So yeah, so thanks a lot for participating

02:53:03,090 --> 02:53:04,640

YouTube URL: https://www.youtube.com/watch?v=Opk92aQyvt0


