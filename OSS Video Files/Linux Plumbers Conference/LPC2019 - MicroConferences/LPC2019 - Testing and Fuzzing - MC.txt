Title: LPC2019 - Testing and Fuzzing - MC
Publication date: 2019-12-09
Playlist: LPC2019 - MicroConferences
Description: 
	The Linux Plumbers 2019 Testing and Fuzzing track focuses on advancing the current state of testing of the Linux Kernel.

Videos of the Topics:

[kernelCI: testing a broad variety of hardware (00:00)](https://youtu.be/0JMUlgT1AmQ?t=1949)
Kevin Hillman and Guillaume Tucker

[Dealing with complex test suites (32:29)](https://youtu.be/0JMUlgT1AmQ?t=1949)
Guillaume Tucker

[GWP-ASAN (52:42)](https://youtu.be/0JMUlgT1AmQ?t=3162)
Dmitry Vyukov

[Fighting uninitialized memory in the kernel (1:13:06)](https://youtu.be/0JMUlgT1AmQ?t=4386)
Alexander Potapenko

[syzbot (1:26:53)](https://youtu.be/0JMUlgT1AmQ?t=5213)
Dmitry Vuykov

[Collabora/unification around unit testing frameworks (1:48:49)](https://youtu.be/0JMUlgT1AmQ?t=6519)
Knut Omang - Sorry for the very low audio at the start. Microphone problem

[All about Kselftest (2:19:25)](https://youtu.be/0JMUlgT1AmQ?t=8365)
Shuah Khan
Captions: 
	00:00:00,150 --> 00:00:03,360
We'll get started with discuss Kelsey, I'm a little bit, um,

00:00:03,540 --> 00:00:08,250
and the focus being on how to do testing on a wide variety of hardware.

00:00:09,090 --> 00:00:09,923
So

00:00:10,130 --> 00:00:11,360
I don't have to be in this crowd.

00:00:11,361 --> 00:00:14,870
I don't have to do the light bulbs to smartwatches, to servers,

00:00:14,880 --> 00:00:17,660
the supercomputers thing. Everybody here knows Linux runs day.

00:00:18,720 --> 00:00:21,580
You'd love that slide. But [inaudible]

00:00:21,640 --> 00:00:23,560
what about testing? Where does the next testing,

00:00:23,590 --> 00:00:28,420
right. There we go.

00:00:29,320 --> 00:00:34,320
So Linux testing runs slightly fewer places than Linux itself runs as we know.

00:00:35,711 --> 00:00:36,544
Well.

00:00:36,760 --> 00:00:40,120
So what we want to discuss is a little bit about why that is and what do we want

00:00:40,190 --> 00:00:41,023
to do

00:00:41,690 --> 00:00:46,580
that. So let's talk a little bit about kind of the landscape, um,

00:00:46,640 --> 00:00:51,560
of kinda testing. So, uh, how have you ever took up,

00:00:52,550 --> 00:00:56,930
so there's a couple of slides here showing current events, Cape boots,

00:00:57,680 --> 00:01:00,080
Michael Covel testing, especially upstream cause of testing.

00:01:00,410 --> 00:01:04,000
So we have different tastes, suites and frameworks. I mean,

00:01:04,010 --> 00:01:06,320
I think we've been discussing them already in all the talks,

00:01:06,321 --> 00:01:10,010
but that's just like you never opened the new one could have testified work,

00:01:10,100 --> 00:01:12,140
which I haven't moved. You mentioned to indicated.

00:01:13,790 --> 00:01:15,620
Well we're going to have a talk on that later today.

00:01:15,621 --> 00:01:19,160
So I didn't put too much on here cause [inaudible]

00:01:20,720 --> 00:01:24,280
um, so these things cause health test, these being used in intubation code,

00:01:24,800 --> 00:01:29,800
OCI and CIS both in community and KTF on adult potentially things we could be

00:01:30,530 --> 00:01:32,840
uh, using. Um,

00:01:32,870 --> 00:01:37,730
but now let's do here to show that why do we have such a variety of tests?

00:01:38,940 --> 00:01:43,310
So we'll goes through the old year different tanks. So Intel has zero today. Uh,

00:01:44,270 --> 00:01:48,440
and, and also there's always multiple venues, cuddle, performance, probate. Uh,

00:01:48,530 --> 00:01:52,070
but that is mostly told to an Intel [inaudible]

00:01:55,410 --> 00:02:00,120
what about maybe and [inaudible] in our cuddle essential tests that we should be

00:02:00,121 --> 00:02:00,954
running on the

00:02:03,410 --> 00:02:06,240
[inaudible] and CQI of all the bread hedges,

00:02:06,241 --> 00:02:08,880
mostly running home [inaudible] all of

00:02:11,010 --> 00:02:13,500
this Sunday now to a stable approach is that, that's why you stopped it.

00:02:13,830 --> 00:02:18,660
So only in all these cases, some people have argued running Linux on some six,

00:02:18,930 --> 00:02:22,920
seven, have a [inaudible] something that solves their problem.

00:02:23,640 --> 00:02:25,980
So that's why there's such a variety of tests and it,

00:02:25,981 --> 00:02:28,590
because there's cases where the news is being rough.

00:02:30,180 --> 00:02:33,750
And then you have other types of testing. Do you have fin girdle calls?

00:02:33,751 --> 00:02:36,750
You have developers. So people who contribute to the code,

00:02:36,751 --> 00:02:40,500
they have tested it to some extent. Um,

00:02:40,740 --> 00:02:41,820
and then this Crow

00:03:04,150 --> 00:03:08,950
[inaudible]. So basically, uh, the current always tested only where you know,

00:03:09,010 --> 00:03:10,990
where it's being the most used the most.

00:03:12,000 --> 00:03:13,670
- [Guillaume] So, there's a lot of bugs everywhere

00:03:13,670 --> 00:03:16,930
that I think pushed under the carpet in a way, I suppose.

00:03:18,017 --> 00:03:22,580
And now, I'll hand it over to Kevin for this one.

00:03:23,890 --> 00:03:27,510
- [Kevin] Yeah, so this gets to the story behind KernelCI

00:03:27,510 --> 00:03:29,300
a little bit and the goal of KernelCI

00:03:29,300 --> 00:03:32,420
is to actually try and test Linux on the variety

00:03:32,420 --> 00:03:34,510
of hardware where it actually runs.

00:03:34,510 --> 00:03:37,350
So, like we said, most of the testing

00:03:37,350 --> 00:03:39,270
is happening on kind of the common architectures

00:03:39,270 --> 00:03:40,390
or the common distros.

00:03:41,330 --> 00:03:43,820
But, as we all know, there's lots of places

00:03:43,820 --> 00:03:45,570
where Linux runs, lots of architectures

00:03:45,570 --> 00:03:50,230
that are not tested very often or not tested at all,

00:03:50,230 --> 00:03:52,620
except for the one or two people that are actually

00:03:52,620 --> 00:03:54,600
hacking on that kernel.

00:03:54,600 --> 00:03:57,510
So with KernelCI the goal is to extend that

00:03:57,510 --> 00:03:58,600
as much as possible.

00:03:58,600 --> 00:04:01,740
So this is the architectures that we're doing today

00:04:01,740 --> 00:04:04,050
and this has almost entirely been donation-based

00:04:04,050 --> 00:04:06,890
so when people send us hardware we add it to the labs

00:04:06,890 --> 00:04:09,700
and that's how things have been growing up til now.

00:04:09,700 --> 00:04:12,430
So we have, and this grew, a little bit of history

00:04:12,430 --> 00:04:14,416
for those who don't know anything about KernelCI.

00:04:14,416 --> 00:04:17,710
The project's about four or five years old now, I guess.

00:04:17,710 --> 00:04:20,320
And it grew initially out of the ARM kernel community

00:04:20,320 --> 00:04:22,620
because the hardware variety in the ARM community

00:04:22,620 --> 00:04:25,420
is so diverse, right.

00:04:25,420 --> 00:04:27,720
Here we have 35 different SoC vendors

00:04:27,720 --> 00:04:30,240
that have chips or boards in the labs right now

00:04:30,240 --> 00:04:32,720
and so there's about 200 plus unique pieces

00:04:32,720 --> 00:04:34,460
of hardware in the lab right now and that's growing

00:04:34,460 --> 00:04:37,620
as people add their own labs or send us hardware.

00:04:38,960 --> 00:04:41,960
So this is just to show how the variety

00:04:41,960 --> 00:04:43,690
of hardware in the kernel is growing,

00:04:43,690 --> 00:04:46,510
and this is just for ARM and ARM64.

00:04:46,510 --> 00:04:48,870
So the blue line is the number of unique platforms

00:04:48,870 --> 00:04:50,090
that the kernel supports.

00:04:50,090 --> 00:04:53,560
Just upstream, obviously out of tree,

00:04:53,560 --> 00:04:55,250
there's tons more of platform support.

00:04:55,250 --> 00:04:59,060
But just in upstream ARM plus ARM64

00:04:59,060 --> 00:05:01,310
we're approaching 2,000 unique platforms,

00:05:01,310 --> 00:05:02,850
support in the kernel.

00:05:04,000 --> 00:05:06,710
Right, so the yellow line is 32-bit platforms,

00:05:06,710 --> 00:05:09,080
the green line is the 64-bit platforms

00:05:09,080 --> 00:05:11,840
which are obviously the newer ones that are growing.

00:05:11,840 --> 00:05:13,900
So this is just since 3.0.

00:05:19,295 --> 00:05:20,450
- So what's the Legacy machine?

00:05:20,450 --> 00:05:22,040
- So the Legacy machines was kind of

00:05:22,040 --> 00:05:23,250
that predates Device Tree,

00:05:23,250 --> 00:05:25,730
so in ARM there was these board files that you would,

00:05:25,730 --> 00:05:27,959
to do board support in ARM before Device Tree,

00:05:27,959 --> 00:05:30,340
you'd do stuff in a board file,

00:05:30,340 --> 00:05:33,040
so that's the legacy support, it's the board files that

00:05:33,040 --> 00:05:34,540
you can see at the beginning of this timeframe

00:05:34,540 --> 00:05:35,950
that's all there was.

00:05:35,950 --> 00:05:39,110
And since then all the growth is happening in Device Tree.

00:05:39,110 --> 00:05:40,370
- Kevin, I have another question for you.

00:05:40,370 --> 00:05:42,320
Earlier, you talked about how,

00:05:43,710 --> 00:05:46,080
not everything was equally well tested.

00:05:47,030 --> 00:05:50,620
Are we happy about the testing of those that are well-used?

00:05:53,792 --> 00:05:54,625
- [Kevin] I don't think so.

00:05:54,625 --> 00:05:58,260
I think, based on the proliferation of CI frameworks

00:05:58,260 --> 00:05:59,780
and testing stuff going on now,

00:05:59,780 --> 00:06:02,050
I think that's an indication that people aren't super happy

00:06:02,050 --> 00:06:03,760
with the testing that's happening.

00:06:03,760 --> 00:06:05,400
- Given the limited resources we have,

00:06:05,400 --> 00:06:10,360
shouldn't we be focusing more on banging away at platforms

00:06:10,360 --> 00:06:12,130
that are more widely used?

00:06:12,130 --> 00:06:15,560
- [Kevin] I think the point here is there's already,

00:06:15,560 --> 00:06:18,290
the focus of the current testing is those platforms,

00:06:18,290 --> 00:06:21,924
but we also wanna be able to test all the platforms.

00:06:21,924 --> 00:06:24,370
I still think the majority of the testing

00:06:24,370 --> 00:06:26,020
is going to be on the common platforms,

00:06:26,020 --> 00:06:29,180
because more people have them and the distros

00:06:29,180 --> 00:06:30,550
and things are gonna be focusing still,

00:06:30,550 --> 00:06:32,500
on those hardware platforms.

00:06:32,500 --> 00:06:34,890
But the point of KernelCI, at least from the beginning

00:06:34,890 --> 00:06:37,660
of KernelCI, was to make sure that other platforms

00:06:37,660 --> 00:06:38,520
are also represented.

00:06:38,520 --> 00:06:40,090
And we're still not getting anywhere near all,

00:06:40,090 --> 00:06:43,560
so this slide also shows just on all the architectures

00:06:43,560 --> 00:06:44,393
that are out there.

00:06:44,393 --> 00:06:46,470
This tries to capture a little bit of the variety

00:06:46,470 --> 00:06:49,300
of platforms in all the other architectures.

00:06:49,300 --> 00:06:53,210
So, again, and this is just, only one way of looking

00:06:53,210 --> 00:06:54,810
at the unique pieces of hardware out there.

00:06:54,810 --> 00:06:56,890
Obviously, this isn't quite fair to x86,

00:06:56,890 --> 00:06:59,210
'cause x86 supports all this hardware

00:06:59,210 --> 00:07:01,400
with one, essentially, platform support

00:07:01,400 --> 00:07:02,600
because of the firmware.

00:07:03,790 --> 00:07:06,370
But this also shows all the other architectures

00:07:06,370 --> 00:07:08,460
that have multiple platform support.

00:07:08,460 --> 00:07:09,980
- Kevin? - Yes?

00:07:09,980 --> 00:07:12,110
- Sorry, Don Zigus here.

00:07:12,110 --> 00:07:13,250
Kind of further up to your point,

00:07:13,250 --> 00:07:15,080
the gentleman in the front there was saying,

00:07:15,080 --> 00:07:16,510
wouldn't it also make sense for KernelCI

00:07:16,510 --> 00:07:18,270
to kinda expand its scope a little bit,

00:07:18,270 --> 00:07:20,310
saying hey, not knowing, we're gonna focus on testing

00:07:20,310 --> 00:07:21,800
but focusing on technologies

00:07:21,800 --> 00:07:24,450
that allowed other people to bring in their platforms,

00:07:24,450 --> 00:07:27,270
like that to integrate their testing and make it easier.

00:07:27,270 --> 00:07:30,440
So that way, not all the burden is on the CI systems

00:07:30,440 --> 00:07:31,820
to test all the platforms.

00:07:31,820 --> 00:07:32,840
- [Kevin] That's right, yeah.

00:07:32,840 --> 00:07:34,760
- But make it easy for other hardware vendors to say,

00:07:34,760 --> 00:07:36,390
"Hey, I can plug into this system pretty soon."

00:07:36,390 --> 00:07:38,150
- [Kevin] Yeah, that is the goal and we'll get to that.

00:07:38,150 --> 00:07:40,140
But the goal of the project is to kind

00:07:40,140 --> 00:07:44,260
of make it easier so people don't have to send hardware

00:07:44,260 --> 00:07:46,460
all around, you can set up a lab,

00:07:46,460 --> 00:07:48,600
plug into these kinda frameworks that we're using

00:07:48,600 --> 00:07:50,940
and we can do testing on a more and more,

00:07:50,940 --> 00:07:52,370
just increase the variety of hardware

00:07:52,370 --> 00:07:55,190
without having to send hardware all over the place.

00:07:55,190 --> 00:07:56,590
You got a question? - Yeah.

00:07:58,560 --> 00:08:00,200
Mic working, oh there you go, thank you.

00:08:00,200 --> 00:08:02,130
So, the previous graph is a little bit deceiving

00:08:02,130 --> 00:08:04,770
because I mean you have dts files as definitive.

00:08:04,770 --> 00:08:06,720
It doesn't mean, you guys have any measure of how much

00:08:06,720 --> 00:08:08,730
of it actually still works as part of the testing

00:08:08,730 --> 00:08:10,440
that you have done so far?

00:08:10,440 --> 00:08:11,438
'Cause I mean we, I work on the ChromeOS team

00:08:11,438 --> 00:08:15,140
and we support some ARM boards and they're very subject

00:08:15,140 --> 00:08:15,973
to bit rot.

00:08:15,973 --> 00:08:18,220
- [Kevin] Yeah, so that's a good point.

00:08:18,220 --> 00:08:19,790
So these are the number of platforms

00:08:19,790 --> 00:08:20,900
that actually are upstream.

00:08:20,900 --> 00:08:23,329
Whether they actually work or not, we only test,

00:08:23,329 --> 00:08:26,120
like in the previous slide, we test about 200

00:08:26,120 --> 00:08:27,710
of these in KernelCI.

00:08:27,710 --> 00:08:30,390
But before KernelCI, the number was even lower.

00:08:31,540 --> 00:08:33,830
And the testing that we're able to do in KernelCI,

00:08:33,830 --> 00:08:37,200
as we'll get to, it's not extensive.

00:08:37,200 --> 00:08:39,260
A lot of the testing we're doing for the variety

00:08:39,260 --> 00:08:41,570
of hardware is just does it actually boot to a shell?

00:08:41,570 --> 00:08:45,130
Does it boot to a shell, does it boot to a RAM disk shell,

00:08:45,130 --> 00:08:46,880
and that's considered a pass.

00:08:46,880 --> 00:08:49,010
And even the amount of failures you get with that,

00:08:49,010 --> 00:08:50,750
in mainline is actually pretty.

00:08:50,750 --> 00:08:52,360
So you're right, I mean a lot of these platforms,

00:08:52,360 --> 00:08:55,220
I guarantee that a lot of them are not booting in mainline,

00:08:55,220 --> 00:08:59,470
just 'cause nobody is actually testing them.

00:08:59,470 --> 00:09:00,860
- So one of the problems,

00:09:00,860 --> 00:09:02,360
do you see this as a problem too

00:09:02,360 --> 00:09:06,540
that a lot of these ARM boards, they tend to have,

00:09:06,540 --> 00:09:08,460
you need special gits in some cases,

00:09:08,460 --> 00:09:11,980
they have a lot of out of tree stuff

00:09:11,980 --> 00:09:13,850
that it's hard for a...

00:09:15,580 --> 00:09:17,670
to get a wide range of testing,

00:09:17,670 --> 00:09:20,180
like some of the common platforms.

00:09:20,180 --> 00:09:22,750
X86 does get a lot of testing, right,

00:09:22,750 --> 00:09:25,630
because even stable releases, when they come out,

00:09:25,630 --> 00:09:29,860
a lot of people do test and I test routinely on my x86.

00:09:29,860 --> 00:09:33,640
But that's not the case for ARM, and do you have,

00:09:34,600 --> 00:09:37,190
I have kind of some ideas in my head

00:09:37,190 --> 00:09:39,600
that why that is the case.

00:09:39,600 --> 00:09:44,160
Having distros not having good support for these things

00:09:44,160 --> 00:09:47,520
is the main being, is that your perception as well

00:09:47,520 --> 00:09:49,280
or how do we solve that problem?

00:09:49,280 --> 00:09:50,750
- [Kevin] I would say it's only partly that.

00:09:50,750 --> 00:09:52,280
I'd say that maybe the bigger problem

00:09:52,280 --> 00:09:55,170
is the ARM vendors take a snapshot

00:09:55,170 --> 00:09:57,080
of whatever they release when Android comes out

00:09:57,080 --> 00:09:58,850
or something and they get it upstream

00:09:58,850 --> 00:10:00,560
and then they kind of, that stays

00:10:00,560 --> 00:10:02,170
and it evolves out of tree for while

00:10:02,170 --> 00:10:04,180
and then at some point later they'll sync up again.

00:10:04,180 --> 00:10:05,630
But in the meantime there's gonna be lots

00:10:05,630 --> 00:10:10,430
of potential time for bit rot and for failure and so.

00:10:10,430 --> 00:10:12,680
But now with KernelCI we've actually caught a lot of

00:10:12,680 --> 00:10:15,230
that stuff so when a platform stops working upstream,

00:10:15,230 --> 00:10:16,540
at least we can report it and say,

00:10:16,540 --> 00:10:19,440
either we're gonna disable it or fix the Device Tree type.

00:10:23,740 --> 00:10:26,060
- So vendor is fixing the problems, or do you?

00:10:26,060 --> 00:10:26,893
- Yeah. - Okay.

00:10:26,893 --> 00:10:27,726
- [Kevin] Not all of them. I mean,

00:10:27,726 --> 00:10:30,390
some are more responsive, but,

00:10:30,390 --> 00:10:32,080
the ones that have actually sent us hardware

00:10:32,080 --> 00:10:35,060
to include in KernelCI they're, if they send,

00:10:35,060 --> 00:10:36,000
that's one of the things we say,

00:10:36,000 --> 00:10:37,870
if we're gonna include your boards,

00:10:37,870 --> 00:10:38,840
we'd like you to...

00:10:38,840 --> 00:10:41,870
'Cause we can't do all the fixing ourselves, either.

00:10:41,870 --> 00:10:45,620
- So how much of the function of bit rotting is,

00:10:45,620 --> 00:10:47,330
can be directly correlated to the fact

00:10:47,330 --> 00:10:51,230
that the platform's no longer of interest,

00:10:51,230 --> 00:10:52,230
whatever that means.

00:10:53,640 --> 00:10:56,224
- [Kevin] I would say there's definitely some of that.

00:10:56,224 --> 00:10:58,590
I guess I haven't done the numbers on that

00:10:58,590 --> 00:11:00,730
to see who no longer cares.

00:11:00,730 --> 00:11:02,940
There are some platforms there that, I mean I've had some

00:11:02,940 --> 00:11:04,680
of these boards in my lab for many years,

00:11:04,680 --> 00:11:06,600
and sometimes I just realize that nobody,

00:11:06,600 --> 00:11:08,380
you can't buy it, nobody cares about it,

00:11:08,380 --> 00:11:10,470
the maintainers long gone, I'll just,

00:11:10,470 --> 00:11:12,490
if I can't fix it simply, I'll just unplug it.

00:11:12,490 --> 00:11:14,940
So there's definitely some of the don't-care factor.

00:11:14,940 --> 00:11:17,150
- Right, so the follow-up for that point is,

00:11:17,150 --> 00:11:19,390
do we really need that breadth of testing,

00:11:19,390 --> 00:11:21,660
if nobody is using that platform?

00:11:21,660 --> 00:11:24,970
- [Kevin] Yep, probably not, not to the same extent.

00:11:26,350 --> 00:11:28,510
But my philosophy has always been,

00:11:28,510 --> 00:11:29,820
if it's easy to keep it working,

00:11:29,820 --> 00:11:31,801
I'll keep it working, if it's not,

00:11:31,801 --> 00:11:33,780
I'm not gonna spend my own time.

00:11:33,780 --> 00:11:36,210
And I think most of the lab owners are that way.

00:11:36,210 --> 00:11:38,150
It's up to the people that maintain the labs,

00:11:38,150 --> 00:11:40,040
if you don't wanna mess around with the hardware,

00:11:40,040 --> 00:11:41,240
you don't have to.

00:11:43,080 --> 00:11:44,870
- I see two aspects of this testing, right?

00:11:44,870 --> 00:11:47,860
One is to obviously to make sure the board works,

00:11:49,770 --> 00:11:52,550
is it functional, that's one aspect of testing,

00:11:52,550 --> 00:11:55,150
and of course if nobody uses the board anymore,

00:11:55,150 --> 00:11:58,160
and nobody's manufacturing the board anymore,

00:11:58,160 --> 00:12:01,580
it's less important that the board be validated.

00:12:01,580 --> 00:12:04,790
That said, each device hardware that comes

00:12:04,790 --> 00:12:08,310
to the table also validates the promise that Linux has

00:12:08,310 --> 00:12:11,470
that it can run on a variety of platforms,

00:12:11,470 --> 00:12:12,860
and to that extent the way,

00:12:12,860 --> 00:12:15,250
we have put the architecture specific

00:12:15,250 --> 00:12:17,990
and the board specific code from the rest,

00:12:17,990 --> 00:12:22,220
whether that contract is still as well-defined

00:12:22,220 --> 00:12:24,160
and as broad as it needs to be,

00:12:25,230 --> 00:12:28,030
that testing of some obscure board

00:12:28,030 --> 00:12:31,130
can bring up some changes that have occurred.

00:12:31,130 --> 00:12:33,700
And the code that is no longer as broad

00:12:33,700 --> 00:12:34,570
as the product was.

00:12:34,570 --> 00:12:38,100
So in that sense, some such testing is interesting

00:12:38,100 --> 00:12:38,933
but not considered--

00:12:38,933 --> 00:12:39,930
- [Kevin] Yeah, and that was a little bit

00:12:39,930 --> 00:12:42,290
of the origin story, too, because is in the ARM community,

00:12:42,290 --> 00:12:45,150
it's actually, especially at the time it was much easier

00:12:45,150 --> 00:12:47,110
to break other platforms unintentionally

00:12:47,110 --> 00:12:48,700
by doing something on a new platform,

00:12:48,700 --> 00:12:50,630
and that's the type of stuff that we were not catching

00:12:50,630 --> 00:12:52,370
initially, but now that type of thing

00:12:52,370 --> 00:12:55,056
is much easier to catch.

00:12:55,056 --> 00:12:57,056
- Kevin, there's a question. - Yep, I can't see the mic,

00:12:57,056 --> 00:13:00,920
so just speak up. - Yeah, it's me.

00:13:05,180 --> 00:13:07,942
So going back to, in terms of the platform.

00:13:07,942 --> 00:13:10,690
(microphone squealing)

00:13:10,690 --> 00:13:12,596
Sorry, I got preempted a bit,

00:13:12,596 --> 00:13:14,890
so, I forgot my question a bit.

00:13:14,890 --> 00:13:16,270
In terms of platform support,

00:13:16,270 --> 00:13:18,710
there are ARM vendors who really care about upstream

00:13:18,710 --> 00:13:20,450
and basically only ship upstream.

00:13:21,340 --> 00:13:23,060
So the people who don't care about upstream,

00:13:23,060 --> 00:13:25,880
are mostly focused on the mobile,

00:13:25,880 --> 00:13:27,900
high-volume consumer stuff.

00:13:27,900 --> 00:13:31,100
The people who care about upstream,

00:13:31,100 --> 00:13:36,100
are focused on small-volume, catalog stuff,

00:13:36,650 --> 00:13:37,970
and enterprise.

00:13:39,970 --> 00:13:42,290
So you can't just say that universally,

00:13:42,290 --> 00:13:45,920
ARM is not supported upstream and platforms are all broken,

00:13:45,920 --> 00:13:48,930
there's this huge pre-patch set,

00:13:48,930 --> 00:13:51,515
if that's true for some of the ones you've heard of,

00:13:51,515 --> 00:13:56,515
the atinals of this world, the SDs of this world

00:13:56,680 --> 00:14:00,130
have tiny BSPs, they're smaller than the Android patch set.

00:14:01,250 --> 00:14:02,540
- [Guillaume] Also, some chips are supported

00:14:02,540 --> 00:14:04,170
for a long time, like for automotive,

00:14:04,170 --> 00:14:06,280
you know when the product needs to be supported

00:14:06,280 --> 00:14:07,113
for a long time.

00:14:07,113 --> 00:14:08,450
So these are typically platforms

00:14:08,450 --> 00:14:10,360
that make more sense to add.

00:14:10,360 --> 00:14:12,940
- Yes, and the mobile ones, people are happy

00:14:12,940 --> 00:14:15,730
to let them bit rot because they have no value,

00:14:15,730 --> 00:14:18,360
after about a year or two years, or something,

00:14:18,360 --> 00:14:21,730
you can't sell them, so nobody cares.

00:14:21,730 --> 00:14:23,200
- [Kevin] And I think the point--

00:14:23,200 --> 00:14:24,960
- [Guillaume] Sorry, on the enterprise side,

00:14:24,960 --> 00:14:27,790
also we are starting to test on ARM64 servers.

00:14:27,790 --> 00:14:30,390
So that's also something that probably we need to,

00:14:30,390 --> 00:14:32,090
it's closer to the x86 model.

00:14:32,090 --> 00:14:34,050
- It's the same as the x86 model.

00:14:38,950 --> 00:14:40,280
- That doesn't necessarily mean

00:14:40,280 --> 00:14:42,720
that one of these platforms won't be broken.

00:14:42,720 --> 00:14:44,490
Even if you're testing on ARM64.

00:14:46,460 --> 00:14:48,040
- [Kevin] Yeah, the other point of this slide is

00:14:48,040 --> 00:14:49,650
to show that the variety of hardware

00:14:49,650 --> 00:14:52,190
that we have supporting in Linux is not shrinking,

00:14:52,190 --> 00:14:53,970
it's growing, right, which I think we all know,

00:14:53,970 --> 00:14:57,530
but it's pretty obvious that the supporting

00:14:57,530 --> 00:15:00,710
variety of hardware is a growing problem,

00:15:00,710 --> 00:15:02,730
not a shrinking problem.

00:15:06,753 --> 00:15:07,730
Yeah, go ahead. - I have a question.

00:15:07,730 --> 00:15:11,090
I know that QEMU can emulate some of the ARM boards.

00:15:11,090 --> 00:15:13,540
So what percent of bugs do they think,

00:15:13,540 --> 00:15:15,710
could have been caught in QEMU or instances

00:15:15,710 --> 00:15:18,770
that are much scalable or reliable

00:15:18,770 --> 00:15:19,890
that can provide test?

00:15:19,890 --> 00:15:21,160
- [Kevin] There are quite a few things

00:15:21,160 --> 00:15:22,100
we can catch in QEMU,

00:15:22,100 --> 00:15:24,630
especially the early boot breakage stuff,

00:15:24,630 --> 00:15:28,040
where if the thing just crashes before it even boots up,

00:15:28,040 --> 00:15:29,600
those types of things are caught on QEMU.

00:15:29,600 --> 00:15:31,960
But there's a lot of stuff that QEMU doesn't emulate,

00:15:31,960 --> 00:15:35,330
especially the obviously the variety of drivers and stuff.

00:15:35,330 --> 00:15:37,980
But, again, I don't really have the numbers,

00:15:37,980 --> 00:15:40,970
on what we've caught on QEMU versus what we've caught

00:15:40,970 --> 00:15:42,530
on actual hardware.

00:15:42,530 --> 00:15:44,900
- How many breakages affect loss of the boards,

00:15:44,900 --> 00:15:48,230
rather than say just one specific driver?

00:15:49,950 --> 00:15:52,840
- [Man] It's mostly specific boards.

00:15:52,840 --> 00:15:56,490
Maybe you might get like, UMMAP might die or something,

00:15:56,490 --> 00:15:58,610
you might get a platform that dies.

00:15:58,610 --> 00:16:01,250
But it's mostly an individual board.

00:16:01,250 --> 00:16:04,600
And if it's a wide breakage, it's very brief.

00:16:05,490 --> 00:16:06,630
- [Guillaume] There was one breakage like,

00:16:06,630 --> 00:16:08,650
a year and a half ago that broke all the ARM platforms.

00:16:08,650 --> 00:16:10,890
- [Man] Yeah, it does happen.

00:16:11,900 --> 00:16:14,660
And unfortunately, QEMU is mostly useful for those,

00:16:14,660 --> 00:16:17,030
because a lot of the individual platform breakages

00:16:17,030 --> 00:16:18,430
are driver breakages.

00:16:20,910 --> 00:16:23,380
And QEMU will emulate things working,

00:16:23,380 --> 00:16:25,020
but it won't emulate if you write

00:16:25,020 --> 00:16:26,280
to this register slightly wrong,

00:16:26,280 --> 00:16:28,820
then the system will explode, obviously.

00:16:28,820 --> 00:16:30,870
So QEMU doesn't catch that sort of stuff.

00:16:33,120 --> 00:16:37,370
It's rare that, or it's relatively rare that

00:16:37,370 --> 00:16:38,670
you'll see a QEMU failure.

00:16:39,590 --> 00:16:40,423
It's much more common

00:16:40,423 --> 00:16:43,530
that you'll see a failure on actual hardware,

00:16:43,530 --> 00:16:47,440
from doing something rude to some device.

00:16:47,440 --> 00:16:50,330
- [Man] So overall, how useful would you consider,

00:16:50,330 --> 00:16:53,270
using QEMU, as kind of a first layer?

00:16:53,270 --> 00:16:54,510
- I think it's good as a first layer

00:16:54,510 --> 00:16:56,900
because it can also run quickly.

00:16:56,900 --> 00:16:59,000
You can run it in the cloud, essentially,

00:16:59,000 --> 00:17:01,880
you don't have to dispatch these jobs off

00:17:01,880 --> 00:17:02,713
to actual hardware.

00:17:02,713 --> 00:17:05,410
So as a first check, I think it's quite useful.

00:17:05,410 --> 00:17:07,460
- It's useful for testing frameworks in the kernel,

00:17:07,460 --> 00:17:10,740
like for media subsystem, there's the vivid driver,

00:17:10,740 --> 00:17:13,520
so you can test the common parts, the frameworks,

00:17:13,520 --> 00:17:15,010
without testing individual drivers.

00:17:15,010 --> 00:17:17,060
And that's good as a first test,

00:17:17,060 --> 00:17:18,060
because you know if that fails,

00:17:18,060 --> 00:17:19,950
you know that all the drivers are also gonna fail

00:17:19,950 --> 00:17:22,180
because of the framework problem.

00:17:22,180 --> 00:17:25,360
So it's good to narrow down problems.

00:17:25,360 --> 00:17:26,840
- [Man] And it's super cheap to run as well,

00:17:26,840 --> 00:17:31,610
so if it provides any benefit at all, it's valuable.

00:17:31,610 --> 00:17:33,510
It's not like it's costing us anything.

00:17:36,290 --> 00:17:37,707
- [Kevin] So just a little bit more about,

00:17:37,707 --> 00:17:40,880
how we're actually testing the variety,

00:17:40,880 --> 00:17:43,000
of not just of hardware but the variety of kernels

00:17:43,000 --> 00:17:44,588
that are out there.

00:17:44,588 --> 00:17:47,930
So right now, we're doing all these tests on mainline,

00:17:47,930 --> 00:17:50,180
next, stable and the stable queues,

00:17:51,070 --> 00:17:52,860
a bunch of different subsystem trees,

00:17:52,860 --> 00:17:55,480
the subsystem maintainers, we track their trees

00:17:55,480 --> 00:17:56,530
as well as some individual.

00:17:56,530 --> 00:17:57,363
Yeah, go ahead.

00:17:57,363 --> 00:18:00,450
- So you're picking mainline, next, stable, stable RC.

00:18:00,450 --> 00:18:03,080
Isn't LTS maybe a better choice,

00:18:03,080 --> 00:18:06,780
because so many of the board vendors are on LTS

00:18:06,780 --> 00:18:07,980
and LTS is-- - Yeah,

00:18:07,980 --> 00:18:10,980
that's the stable tree. - Oh, so, it does include LTS.

00:18:12,704 --> 00:18:13,920
- Yeah, so it's the stable tree,

00:18:13,920 --> 00:18:16,240
for each kernel version they track all the latest stable.

00:18:16,240 --> 00:18:18,320
So we're testing all those, yeah.

00:18:18,320 --> 00:18:20,020
And the stable RC, for those who don't know,

00:18:20,020 --> 00:18:22,770
that's before actually a new stable is released,

00:18:23,630 --> 00:18:26,070
the patches are pushed up there.

00:18:26,070 --> 00:18:27,670
Greg's actually looking at KernelCI,

00:18:27,670 --> 00:18:30,370
before he decides whether it's actually stable or not.

00:18:33,480 --> 00:18:36,870
Yeah, so several maintainer trees and developer trees

00:18:36,870 --> 00:18:39,800
we track, for people that have asked us to add their tree.

00:18:41,240 --> 00:18:43,390
And so we're also doing GCC,

00:18:43,390 --> 00:18:45,590
and we've just recently added Clang support.

00:18:46,520 --> 00:18:51,520
So Clang works on x86 and ARM64 but not much else,

00:18:51,540 --> 00:18:53,670
in terms of actual booting.

00:18:53,670 --> 00:18:56,140
- [Man] X86 will be there will Clang 9,

00:18:56,140 --> 00:18:57,810
but they haven't released that yet.

00:18:57,810 --> 00:18:59,850
- Ah, okay. So that's not even upstream yet.

00:18:59,850 --> 00:19:03,160
- Yeah, it mostly works on 32-bit ARM.

00:19:03,160 --> 00:19:06,080
And it definitely works on ARM64.

00:19:07,353 --> 00:19:09,703
And the next version of Clang will work on x86.

00:19:11,360 --> 00:19:14,360
- So we've been trying the released versions of those,

00:19:14,360 --> 00:19:17,540
but also the latest versions of those to test.

00:19:17,540 --> 00:19:19,810
- So the reason you want Clang

00:19:19,810 --> 00:19:22,620
is BPF tests depend on Clang, right?

00:19:22,620 --> 00:19:24,650
That case of tests at least.

00:19:24,650 --> 00:19:26,900
BPF requires Clang.

00:19:26,900 --> 00:19:30,520
So you get a coverage for, is that a consideration for you?

00:19:30,520 --> 00:19:32,840
- [Kevin] I wasn't even aware that that required Clang,

00:19:32,840 --> 00:19:34,660
so the requests have just become,

00:19:34,660 --> 00:19:36,250
more people want to actually build their kernels

00:19:36,250 --> 00:19:37,990
with Clang, like Android is doing all their

00:19:37,990 --> 00:19:38,823
kernel work with Clang.

00:19:38,823 --> 00:19:40,020
- I see, but, yeah.

00:19:40,020 --> 00:19:42,350
If you're running case self-tests then you want

00:19:42,350 --> 00:19:45,150
to exercise the BPF, you need Clang.

00:19:45,150 --> 00:19:46,950
- [Kevin] Okay, that's good to know.

00:19:48,540 --> 00:19:51,240
And then obviously we're doing any def configuration

00:19:51,240 --> 00:19:53,330
that's actually checked in upstream for an architecture,

00:19:53,330 --> 00:19:55,340
we're building that, so we're able

00:19:55,340 --> 00:19:56,750
to at least report build failures

00:19:56,750 --> 00:19:58,570
for several different defconfigs.

00:19:59,530 --> 00:20:02,710
Some big-endian stuff and some other things.

00:20:02,710 --> 00:20:04,310
There's a whole bunch of these different fragments

00:20:04,310 --> 00:20:06,260
that we can build, and we can add more.

00:20:11,840 --> 00:20:14,610
- So as you know, KernelCI is doing a lot of boot testing,

00:20:14,610 --> 00:20:17,180
but we are actively working on it,

00:20:17,180 --> 00:20:18,950
improving functional testing as well,

00:20:18,950 --> 00:20:22,030
so we've been running IGT on some platforms,

00:20:22,030 --> 00:20:24,150
only on the DRM KMS side.

00:20:24,150 --> 00:20:26,920
We've just started doing a few things on GPUs

00:20:26,920 --> 00:20:30,870
with i915 and some Mali GPUs as well,

00:20:30,870 --> 00:20:31,940
with Panfrost driver.

00:20:33,472 --> 00:20:35,480
But we're not really pushing the results for that yet

00:20:35,480 --> 00:20:37,800
because there are still some things that we need

00:20:37,800 --> 00:20:41,350
to improve with the reporting and dealing with test results.

00:20:41,350 --> 00:20:45,280
But, we've started reporting the v412 compliance results

00:20:45,280 --> 00:20:47,280
to the media mailing list,

00:20:47,280 --> 00:20:49,500
from the media tree and from next,

00:20:51,460 --> 00:20:52,490
and that's working pretty well,

00:20:52,490 --> 00:20:54,340
I mean, we caught a couple of issues.

00:20:55,834 --> 00:20:57,050
And we're running things like suspend

00:20:57,050 --> 00:20:59,590
and resume on the virtual platforms,

00:20:59,590 --> 00:21:01,040
that fails a lot of the time.

00:21:03,350 --> 00:21:06,390
But, again, we're not really reporting the results too well,

00:21:06,390 --> 00:21:09,870
so sometimes we would forward something to one key person

00:21:09,870 --> 00:21:11,030
to try to get it fixed.

00:21:12,040 --> 00:21:13,930
But we're ramping up the test suite, basically,

00:21:13,930 --> 00:21:16,410
and at some point we'll get a better way

00:21:16,410 --> 00:21:18,420
of reporting results and bisecting as well,

00:21:18,420 --> 00:21:21,740
which is something I'll be talking about a bit later.

00:21:21,740 --> 00:21:25,160
And USB smoke test, that's another test we have made

00:21:25,160 --> 00:21:27,820
to verify that USB subsystem is working.

00:21:28,750 --> 00:21:31,090
And we have a few more on the list.

00:21:32,200 --> 00:21:34,820
Especially we are adding a baseline test,

00:21:34,820 --> 00:21:38,980
which looks at kernel log error messages,

00:21:38,980 --> 00:21:40,110
based on the level.

00:21:41,700 --> 00:21:44,890
And that's something we want to run on all platforms,

00:21:44,890 --> 00:21:47,020
to improve, you know the current boot test basically

00:21:47,020 --> 00:21:50,370
realize just being able to log in.

00:21:50,370 --> 00:21:52,230
But it's all based on Lava, you know.

00:21:52,230 --> 00:21:55,320
If Lava says, yeah, you managed to log in,

00:21:55,320 --> 00:21:56,420
then it's considered a pass,

00:21:56,420 --> 00:21:58,660
even if there were kernel errors and everything.

00:21:58,660 --> 00:22:01,080
As long as you managed to get to a login,

00:22:01,080 --> 00:22:02,230
considers it as a pass.

00:22:03,230 --> 00:22:06,650
So we want to improve that to have more positive test

00:22:06,650 --> 00:22:09,150
to say yes, it actually booted without any errors.

00:22:10,720 --> 00:22:13,270
So that should be rolled out pretty soon,

00:22:13,270 --> 00:22:15,410
because it's something we can run on any platform.

00:22:18,320 --> 00:22:20,510
Data is growing, I guess I'll hand it over to Kevin.

00:22:20,510 --> 00:22:23,840
- Yeah, so this is, as Guillaume just said,

00:22:24,690 --> 00:22:27,110
all this matrix is expanding.

00:22:27,110 --> 00:22:31,060
We have compiler versions, tree, multiple trees,

00:22:31,060 --> 00:22:34,120
multiple defconfigs, multiple architectures.

00:22:34,120 --> 00:22:36,200
The dimensions on our matrix just keep growing.

00:22:36,200 --> 00:22:38,550
So we're actually collecting quite a bit of data,

00:22:38,550 --> 00:22:40,960
but we're not actually doing a whole lot useful.

00:22:40,960 --> 00:22:42,540
We have a few targeted email reports

00:22:42,540 --> 00:22:44,720
for some subsystems and so on.

00:22:44,720 --> 00:22:46,200
So one of the things we're trying to work on

00:22:46,200 --> 00:22:48,780
and we're looking for collaboration as the project

00:22:48,780 --> 00:22:51,630
is growing, is this is an area where we really need help.

00:22:52,810 --> 00:22:54,170
This really the next step.

00:22:54,170 --> 00:22:57,110
We've been collecting this data for years,

00:22:57,110 --> 00:22:59,440
how do we actually do a better job of analyzing it

00:22:59,440 --> 00:23:01,720
and doing reporting on it, detecting things.

00:23:01,720 --> 00:23:04,190
Something detecting things prematurely,

00:23:05,745 --> 00:23:06,860
there's several different things we could do,

00:23:06,860 --> 00:23:08,470
all sorts of trends.

00:23:08,470 --> 00:23:10,780
We've been collecting data on the kernel size

00:23:10,780 --> 00:23:13,648
and boot times and all these types of things,

00:23:13,648 --> 00:23:15,560
we have all this data, we're not doing stuff with it,

00:23:15,560 --> 00:23:17,830
so that's one of the areas of collaboration

00:23:17,830 --> 00:23:20,170
that we're, you know.

00:23:20,170 --> 00:23:22,010
Most of us that have been working on this project

00:23:22,010 --> 00:23:23,530
are kind of kernel people,

00:23:23,530 --> 00:23:25,900
not necessarily data analytics people.

00:23:25,900 --> 00:23:28,290
So this is an area where we would love

00:23:28,290 --> 00:23:30,150
to have some collaboration.

00:23:31,463 --> 00:23:33,513
So that's one of the areas going forward.

00:23:34,560 --> 00:23:36,615
Sorry for the bad joke here on this slide.

00:23:36,615 --> 00:23:37,448
(laughing)

00:23:37,448 --> 00:23:38,390
I couldn't resist.

00:23:38,390 --> 00:23:40,500
- So one of the problems with collecting lots of data,

00:23:40,500 --> 00:23:43,340
including logs, especially logs are not structured.

00:23:43,340 --> 00:23:45,970
So you have no idea really what errors you're looking for.

00:23:45,970 --> 00:23:49,090
And one of the ways I've attempted to approach this

00:23:49,090 --> 00:23:51,590
is by looking at 10,000 logs,

00:23:52,750 --> 00:23:54,050
sorting all of the messages

00:23:54,050 --> 00:23:56,690
and getting a count of how often every message shows up.

00:23:57,815 --> 00:23:58,648
And then I can sort of categorize them,

00:23:58,648 --> 00:24:00,980
so there's the oddball ones that you find,

00:24:00,980 --> 00:24:03,100
and then there's a bunch that get repeated often.

00:24:03,100 --> 00:24:05,470
Based on the number of times that you've booted.

00:24:05,470 --> 00:24:06,770
So that might be one way of looking at it,

00:24:06,770 --> 00:24:08,430
but again, the fact that it's not structured,

00:24:08,430 --> 00:24:11,110
and then you have these quirks, and hardware doesn't

00:24:11,110 --> 00:24:13,210
come up quite right that one time,

00:24:13,210 --> 00:24:16,220
you end up with a lot of weirdness that you can't explain.

00:24:18,200 --> 00:24:19,310
- [Kevin] Especially with the variety

00:24:19,310 --> 00:24:20,320
of hardware we're tracking.

00:24:20,320 --> 00:24:22,600
One of the really interesting things is I got this new,

00:24:22,600 --> 00:24:24,570
kind of obscure log, has it actually,

00:24:24,570 --> 00:24:27,875
have I seen this on any other platform at any other time?

00:24:27,875 --> 00:24:29,120
That type of stuff is actually quite interesting

00:24:29,120 --> 00:24:30,320
to be able to query.

00:24:30,320 --> 00:24:32,490
- That's an evolution of what I said about checking

00:24:32,490 --> 00:24:34,330
for error messages in the kernel log.

00:24:34,330 --> 00:24:36,050
So right now we're like counting,

00:24:36,050 --> 00:24:38,050
are there any warnings, critical things.

00:24:39,968 --> 00:24:44,830
A good next step would be to store the log line

00:24:44,830 --> 00:24:47,070
as a kind of error signature basically,

00:24:47,070 --> 00:24:48,780
and try to see if it comes back again.

00:24:48,780 --> 00:24:50,820
Like store it as an error that was seen,

00:24:50,820 --> 00:24:52,870
and then when you get a new test that comes,

00:24:52,870 --> 00:24:55,910
you can see if that happened before or not.

00:24:55,910 --> 00:24:58,100
Like then I am uniquely creating a list of errors.

00:24:58,100 --> 00:24:59,610
- But the problem with the log lines of the app,

00:24:59,610 --> 00:25:00,910
is that they're only showing you a symptom,

00:25:00,910 --> 00:25:02,150
not the cause. - Right.

00:25:02,150 --> 00:25:04,710
- Right, so, the symptom is good to report,

00:25:04,710 --> 00:25:06,260
you're just trying to report it.

00:25:06,260 --> 00:25:07,920
But ultimately if you want to try to fix it,

00:25:07,920 --> 00:25:09,180
you have to figure out what the cause was.

00:25:09,180 --> 00:25:13,645
And I find that the logs are generally hit and miss on that.

00:25:13,645 --> 00:25:14,970
It's not that useful.

00:25:14,970 --> 00:25:16,410
- So if the problem always shows the log,

00:25:16,410 --> 00:25:18,330
then we can bisect it, but of course if it doesn't,

00:25:18,330 --> 00:25:20,380
then that's a problem.

00:25:20,380 --> 00:25:21,550
- How much automation do you have here,

00:25:21,550 --> 00:25:23,580
in terms of what's processing the data?

00:25:23,580 --> 00:25:27,210
If something boots, you declare that has passed,

00:25:27,210 --> 00:25:28,043
that's the easy part.

00:25:28,043 --> 00:25:30,260
If it doesn't boot, what do you do then?

00:25:30,260 --> 00:25:33,270
What kind of back end infrastructure do you have

00:25:33,270 --> 00:25:37,080
for dealing with whatever logs or stack traces

00:25:37,080 --> 00:25:39,780
and things like that that may show up?

00:25:39,780 --> 00:25:41,180
- [Kevin] Yeah, so you can talk about bisecting,

00:25:41,180 --> 00:25:43,150
'cause that's the main thing that we're doing, I guess.

00:25:43,150 --> 00:25:45,420
- I have a question about logs, is that okay?

00:25:46,610 --> 00:25:47,870
- Stick to logs.

00:25:47,870 --> 00:25:51,670
- So from what you said, it sounded like currently,

00:25:51,670 --> 00:25:54,460
you just boot and don't actually look at the logs,

00:25:54,460 --> 00:25:55,470
don't gather logs?

00:25:55,470 --> 00:25:58,680
- [Kevin] No, we gather the logs and with the reporting,

00:25:58,680 --> 00:26:00,840
if it's a failure you can go and find the logs,

00:26:00,840 --> 00:26:02,030
or we report the logs with it.

00:26:02,030 --> 00:26:03,910
- That's what I remember seeing of logs.

00:26:03,910 --> 00:26:05,660
- The logs are all there, we're just not,

00:26:05,660 --> 00:26:07,890
we're collecting them, we're not doing anything

00:26:07,890 --> 00:26:10,180
super intelligent with them. - Right.

00:26:10,180 --> 00:26:12,380
- You know, automatic parsing or that stuff.

00:26:13,290 --> 00:26:17,280
But we're storing them all for hopefully future use.

00:26:17,280 --> 00:26:20,530
'Cause we know that there's lots of useful things in there,

00:26:20,530 --> 00:26:22,380
that we could do, we just haven't done it yet.

00:26:22,380 --> 00:26:24,980
- Right, so I do that when I'm,

00:26:24,980 --> 00:26:26,600
my process doesn't scale of course,

00:26:26,600 --> 00:26:28,960
I test a few things on one system

00:26:28,960 --> 00:26:30,460
and then I do look at logs.

00:26:30,460 --> 00:26:34,640
I look for criticals, and those manual checks.

00:26:35,670 --> 00:26:40,400
And then also, do you guys enable some of the options,

00:26:40,400 --> 00:26:43,580
like KASAN and debug options,

00:26:44,490 --> 00:26:47,720
lock, dependency checks and all of those?

00:26:47,720 --> 00:26:50,090
- [Kevin] Yeah, we have one of the, not KASAN yet,

00:26:50,090 --> 00:26:53,990
but we do, there's a debug option that turns on a handful

00:26:53,990 --> 00:26:56,730
of debug things like lock checking and so on.

00:26:56,730 --> 00:27:00,230
That's one of the fragments that we built.

00:27:00,230 --> 00:27:01,550
Actually I think we turned that off,

00:27:01,550 --> 00:27:03,220
because that was actually catching a lot of things,

00:27:03,220 --> 00:27:05,870
it was catching more things than we had the ability

00:27:05,870 --> 00:27:07,650
to actually fix at the time.

00:27:07,650 --> 00:27:09,660
- So that would be very important.

00:27:09,660 --> 00:27:13,730
I mean, that's what I do on my manual testing

00:27:13,730 --> 00:27:14,580
that I do.

00:27:14,580 --> 00:27:16,630
I have all of them turned on.

00:27:16,630 --> 00:27:19,890
It does, that means that you are catching problems.

00:27:19,890 --> 00:27:22,290
But that's the whole idea of testing, right?

00:27:22,290 --> 00:27:23,380
To be able to do that.

00:27:23,380 --> 00:27:27,060
So that would be something I would say would be important.

00:27:27,060 --> 00:27:28,730
- [Kevin] It actually that problem leads

00:27:28,730 --> 00:27:29,670
to an interesting challenge

00:27:29,670 --> 00:27:33,100
because if you are generating more errors and more bugs

00:27:33,100 --> 00:27:35,210
and stuff than the capacity to fix them,

00:27:35,210 --> 00:27:37,200
then people start ignoring results

00:27:37,200 --> 00:27:38,990
because it's just failures,

00:27:38,990 --> 00:27:40,420
the same failures over and over again.

00:27:40,420 --> 00:27:44,430
So you've gotta be pretty selective

00:27:44,430 --> 00:27:45,720
about the types of things that you know,

00:27:45,720 --> 00:27:47,170
you have the capacity to fix.

00:27:47,170 --> 00:27:49,380
Until the capacity to actually fix these things grows,

00:27:49,380 --> 00:27:51,850
you can't actually report everything.

00:27:51,850 --> 00:27:55,420
There's a lot more things we can turn on and find as well.

00:27:55,420 --> 00:27:57,640
I think this is part of the whole,

00:27:57,640 --> 00:27:59,760
part of this discussion hopefully we can have today

00:27:59,760 --> 00:28:02,450
and over the conference is just how we're scaling up

00:28:02,450 --> 00:28:03,283
this kernel testing.

00:28:03,283 --> 00:28:05,330
'Cause we are reaching a point where we're generating

00:28:05,330 --> 00:28:09,600
lots more issues than the community has the capacity

00:28:09,600 --> 00:28:11,010
to fix manually.

00:28:11,010 --> 00:28:13,760
- So there is a small subset of debug options

00:28:13,760 --> 00:28:15,210
that would be very important.

00:28:16,190 --> 00:28:18,510
Which is, I find a lot of problems,

00:28:18,510 --> 00:28:20,700
when I turn on KASAN, for example.

00:28:20,700 --> 00:28:24,030
And also lock dep analysis.

00:28:25,315 --> 00:28:26,410
- One thing that Karina said about,

00:28:26,410 --> 00:28:27,490
when there's a lot of failures,

00:28:27,490 --> 00:28:28,680
I think the first thing to do is

00:28:28,680 --> 00:28:30,400
to start reporting new failures.

00:28:30,400 --> 00:28:32,440
So you start, and the first time you run the test,

00:28:32,440 --> 00:28:33,700
you see all these things are failing.

00:28:33,700 --> 00:28:36,310
And if new things are failing then you report them actively.

00:28:36,310 --> 00:28:39,540
- [Man] The trouble with lock dep is it's very,

00:28:39,540 --> 00:28:41,850
very difficult to get anybody to care.

00:28:41,850 --> 00:28:45,060
Some people will care, but it's very, very difficult

00:28:45,060 --> 00:28:47,150
to get a lot of those issues fixed,

00:28:47,150 --> 00:28:48,630
just nobody's interested.

00:28:51,450 --> 00:28:54,316
They're legit, they're legit, we should report them.

00:28:54,316 --> 00:28:56,500
I'm just saying, as one of the people who sends a lot

00:28:56,500 --> 00:29:00,320
of these emails, eventually you get fed up

00:29:00,320 --> 00:29:03,280
and go yeah, can we turn this build off, it's annoying.

00:29:03,280 --> 00:29:05,430
- [Kevin] So back to the question of what happens

00:29:05,430 --> 00:29:07,530
when a boot actually fails.

00:29:08,640 --> 00:29:10,470
The primary thing we're doing right now is,

00:29:10,470 --> 00:29:11,580
we can report the failure,

00:29:11,580 --> 00:29:14,700
but we can actually bisect these boot failures.

00:29:14,700 --> 00:29:16,750
We actually have an automated process

00:29:16,750 --> 00:29:20,210
that can go back to the lab and do builds

00:29:20,210 --> 00:29:23,030
and resend the jobs until we find the commit that failed.

00:29:23,030 --> 00:29:24,690
So that's the primary thing we're doing right now

00:29:24,690 --> 00:29:25,880
with those.

00:29:25,880 --> 00:29:28,870
- So now that we're all one big happy family

00:29:28,870 --> 00:29:30,590
with Microsoft in the fold,

00:29:30,590 --> 00:29:34,540
there's a lot of art that Microsoft has in terms

00:29:34,540 --> 00:29:37,100
of dealing with large amounts of data

00:29:37,100 --> 00:29:39,660
that's coming back from all the Windows endpoints,

00:29:39,660 --> 00:29:43,130
and the way we process the bugs and problems

00:29:43,130 --> 00:29:46,690
that we have in terms of putting new Windows.

00:29:47,850 --> 00:29:49,920
Speaking to the Windows folks, they're very happy

00:29:49,920 --> 00:29:54,440
to share that technology within the next group,

00:29:54,440 --> 00:29:56,670
if your interested you could talk about,

00:29:56,670 --> 00:29:58,882
what's being done in the back end in terms

00:29:58,882 --> 00:30:03,882
of visualizing the data and making sense of the data.

00:30:05,820 --> 00:30:07,140
- [Kevin] Yeah, we're definitely interested,

00:30:07,140 --> 00:30:09,000
in any help on that. - Yeah, that's good.

00:30:09,000 --> 00:30:11,920
I'd love to work with you guys on that.

00:30:11,920 --> 00:30:14,460
- There is another side of not enabling some debug config,

00:30:14,460 --> 00:30:16,720
for example if you get silent memory corruption,

00:30:16,720 --> 00:30:19,490
then you get assorted failures that you can't explain,

00:30:19,490 --> 00:30:21,150
and you can't really bisect them as well,

00:30:21,150 --> 00:30:23,190
because they are very flaky.

00:30:23,190 --> 00:30:25,690
And the same maybe for deadlocks as well.

00:30:27,550 --> 00:30:28,887
- Can't, is that what you said?

00:30:28,887 --> 00:30:30,417
- Can't, yes. - You can't bisect, yeah.

00:30:30,417 --> 00:30:31,820
- So then you have something

00:30:31,820 --> 00:30:34,170
but it's much more expensive to fix.

00:30:35,910 --> 00:30:37,080
- [Guillaume] In order to bisect, you need

00:30:37,080 --> 00:30:38,890
to run several tests and do some stats

00:30:38,890 --> 00:30:40,440
to see how often it comes back.

00:30:48,494 --> 00:30:50,020
- Yeah so I think we're...

00:30:50,020 --> 00:30:51,140
So this is just a little bit,

00:30:51,140 --> 00:30:52,460
some of this stuff we've already talked about.

00:30:52,460 --> 00:30:54,700
So in terms of what's next for the project,

00:30:55,650 --> 00:30:57,320
the big thing that's next is the project

00:30:57,320 --> 00:30:59,440
is becoming a Linux Foundation project,

00:31:01,820 --> 00:31:03,660
I know for those of you who were at Palmers last year,

00:31:03,660 --> 00:31:07,313
I said the same thing, this year it's actually happening,

00:31:07,313 --> 00:31:10,063
(crowd laughing)

00:31:11,001 --> 00:31:11,834
- Write it down.

00:31:13,800 --> 00:31:17,350
- So we'll announce officially in a couple months

00:31:17,350 --> 00:31:21,760
at the OSS Europe conference, so, that's the plan.

00:31:22,680 --> 00:31:25,690
But, leading up to that, the goal is basically collaboration

00:31:25,690 --> 00:31:27,100
so that's also why we're here.

00:31:27,100 --> 00:31:29,250
There's lots of CI efforts going on,

00:31:29,250 --> 00:31:32,570
we wanted just to make sure we're not duplicating effort.

00:31:32,570 --> 00:31:35,640
We want our testing to be open source and collaborative

00:31:35,640 --> 00:31:37,840
just like our kernel development.

00:31:37,840 --> 00:31:39,390
So some of this stuff I've already talked about.

00:31:39,390 --> 00:31:44,030
We've been already getting some more horsepower

00:31:44,030 --> 00:31:46,230
to be able to do more builds and to be able

00:31:46,230 --> 00:31:48,180
to do more stuff kind of server side,

00:31:48,180 --> 00:31:50,720
before we actually distribute to the targets.

00:31:50,720 --> 00:31:52,530
And then there's new developments,

00:31:52,530 --> 00:31:54,880
like the KUnit, and there's lots of work going on

00:31:54,880 --> 00:31:56,600
with fuzzing and stuff right now that we would like

00:31:56,600 --> 00:31:59,420
to start being able to run those types of tests

00:31:59,420 --> 00:32:01,570
and include more testing.

00:32:03,420 --> 00:32:07,120
So that's the gist of what we have.

00:32:07,120 --> 00:32:08,070
Any more questions?

00:32:11,570 --> 00:32:14,744
- Maybe the last question, we'll move to the next...

00:32:14,744 --> 00:32:16,499
- Well, it's a terrible question.

00:32:16,499 --> 00:32:19,249
(crowd laughing)

00:32:22,500 --> 00:32:26,720
- Is there any other way to catch some errors so that,

00:32:26,720 --> 00:32:30,690
I guess that you just check only whether it boot up or not,

00:32:30,690 --> 00:32:32,010
or something like that.

00:32:32,010 --> 00:32:35,050
But in many cases the driver shows some errors,

00:32:35,050 --> 00:32:37,970
but so we ignore that.

00:32:37,970 --> 00:32:39,780
- [Kevin] Well, we don't ignore it now.

00:32:39,780 --> 00:32:42,020
So if the driver's actually reporting errors

00:32:42,020 --> 00:32:43,790
in the kernel log, we can catch those things.

00:32:43,790 --> 00:32:45,700
We're actually capturing logs,

00:32:45,700 --> 00:32:48,750
and the kernel log has different levels,

00:32:49,921 --> 00:32:50,754
so we can catch things.

00:32:50,754 --> 00:32:52,950
If it's actually logged as an error, we'll catch that.

00:32:52,950 --> 00:32:54,930
But right now, we're basically just counting those things

00:32:54,930 --> 00:32:57,340
and we can say that the platform booted

00:32:57,340 --> 00:32:59,980
but it's got 20 errors, error messages.

00:32:59,980 --> 00:33:02,020
So that's the type of thing we can capture and report.

00:33:02,020 --> 00:33:04,150
We're not actually,

00:33:04,150 --> 00:33:06,910
we're not doing clever analyzing of the logs

00:33:06,910 --> 00:33:09,000
to detect exactly what happened.

00:33:09,000 --> 00:33:11,510
- Yeah, so that makes me wonder,

00:33:11,510 --> 00:33:15,370
whether we should define the common practice

00:33:16,810 --> 00:33:19,780
that's at least this kernel warning,

00:33:19,780 --> 00:33:23,650
or some enable should have been, must have been

00:33:23,650 --> 00:33:25,790
searched for critical errors.

00:33:26,820 --> 00:33:28,910
- [Kevin] Yeah, there's definitely, we've noticed

00:33:28,910 --> 00:33:30,780
already there's definitely inconsistent use

00:33:30,780 --> 00:33:32,293
of kernel log levels.

00:33:32,293 --> 00:33:35,678
(crowd laughing)

00:33:35,678 --> 00:33:37,480
For the first point, even when you boot the kernel,

00:33:37,480 --> 00:33:39,280
you can't actually see the log levels.

00:33:39,280 --> 00:33:41,830
So it all just comes out together.

00:33:41,830 --> 00:33:44,140
So most people don't look at log levels,

00:33:44,140 --> 00:33:45,830
they just do a printk and they're happy,

00:33:45,830 --> 00:33:47,380
or a dev_printk or whatever.

00:33:48,900 --> 00:33:51,840
There's definitely, I think as more automation comes along,

00:33:51,840 --> 00:33:54,050
we're definitely gonna need to be a little more structured

00:33:54,050 --> 00:33:56,990
in how we decide to log and at what levels and why

00:33:56,990 --> 00:33:57,823
and so on.

00:33:57,823 --> 00:33:59,550
- Drivers are getting better.

00:33:59,550 --> 00:34:00,940
- Drivers are getting better, yeah.

00:34:00,940 --> 00:34:02,930
With some of the helper macros and stuff.

00:34:02,930 --> 00:34:04,760
- One example is for deferred pros,

00:34:04,760 --> 00:34:07,460
I've see things from Info to Critical. I mean, it's...

00:34:08,460 --> 00:34:10,486
- [Man] The level itself might be wrong,

00:34:10,486 --> 00:34:13,389
but a using structure, like...

00:34:13,389 --> 00:34:16,790
- [Moderator] I think we need to get off to the next topic.

00:34:16,790 --> 00:34:18,115
Thank you.

00:34:18,115 --> 00:34:21,448
(participants clapping)

00:34:25,337 --> 00:34:27,920
- The next talk is you I think.

00:35:33,256 --> 00:35:36,173
(crowd chattering)

00:35:41,290 --> 00:35:42,420
- [Guillaume] Hello, this is still related

00:35:42,420 --> 00:35:46,140
to KernelCI, this one is about dealing

00:35:46,140 --> 00:35:47,910
with complex test suites, which was something

00:35:47,910 --> 00:35:49,710
that was already talked a bit about.

00:35:50,641 --> 00:35:53,490
But I've got a small story here to tell you,

00:35:53,490 --> 00:35:56,400
why we got into this situation of dealing

00:35:56,400 --> 00:35:58,250
with complex test suites in KernelCI.

00:35:59,090 --> 00:36:00,330
So I won't spend too much time

00:36:00,330 --> 00:36:01,350
but just give some background

00:36:01,350 --> 00:36:03,150
and then we can discuss things.

00:36:03,150 --> 00:36:04,830
Because I'm more like looking for solutions

00:36:04,830 --> 00:36:06,680
and what people think here.

00:36:06,680 --> 00:36:09,320
So once upon a time, there was a little project

00:36:09,320 --> 00:36:11,880
called KernelCI, as we know, we just talked about it,

00:36:11,880 --> 00:36:14,950
but it was on the ARM ecosystem around 2015

00:36:14,950 --> 00:36:18,250
doing builds and boots and loads of boots and boots.

00:36:18,250 --> 00:36:21,430
And at some point, around 2018 we started running

00:36:21,430 --> 00:36:24,990
automated boot bisections, which was very useful

00:36:24,990 --> 00:36:28,900
at reporting issues directly to the patch authors,

00:36:28,900 --> 00:36:31,450
so even if they were not getting the KernelCI results,

00:36:31,450 --> 00:36:33,300
some things were reported to people

00:36:33,300 --> 00:36:35,140
and they were happy to see that.

00:36:35,140 --> 00:36:37,890
That would save them some debugging time.

00:36:37,890 --> 00:36:40,600
Boot failures are almost always considered

00:36:40,600 --> 00:36:41,730
as something that has to be fixed.

00:36:41,730 --> 00:36:43,930
So if someone makes a patch that breaks a platform

00:36:43,930 --> 00:36:45,790
even if they don't know about the platform,

00:36:45,790 --> 00:36:46,740
don't normally care about it,

00:36:46,740 --> 00:36:48,250
if they can't fix it themselves.

00:36:48,250 --> 00:36:50,220
Something will happen, rewrite a patch

00:36:50,220 --> 00:36:51,770
or try to get it working again.

00:36:53,440 --> 00:36:55,000
So that was good, and at the same time,

00:36:55,000 --> 00:36:56,710
we started doing more test suites,

00:36:56,710 --> 00:37:00,840
like explained in previous slides.

00:37:02,456 --> 00:37:04,430
But then what do we do with these results?

00:37:04,430 --> 00:37:07,810
Things like igt can produce a lot of results,

00:37:07,810 --> 00:37:09,640
and suspend, suspend and resume,

00:37:09,640 --> 00:37:11,040
if we do that in all the platforms

00:37:11,040 --> 00:37:12,790
that's hundreds of results as well.

00:37:13,650 --> 00:37:16,326
So that's where we needed some help.

00:37:16,326 --> 00:37:19,190
I mean we started looking at the problem space

00:37:19,190 --> 00:37:20,090
and how to fix it,

00:37:23,648 --> 00:37:25,190
but so these are basically the issues,

00:37:25,190 --> 00:37:28,260
and like I said, there's a lot of commits

00:37:28,260 --> 00:37:31,470
and why we need to bisect is because in linux-next,

00:37:31,470 --> 00:37:34,730
you have of course, every time there's a new linux-next tag,

00:37:34,730 --> 00:37:38,100
it's completely re-based and you get a lot of merges.

00:37:38,100 --> 00:37:39,760
You can't test every commit in that

00:37:39,760 --> 00:37:44,000
so from mailing list or maintainer tree,

00:37:44,000 --> 00:37:46,810
you could look at every patch on the mailing list

00:37:46,810 --> 00:37:48,180
or look at every commit on a git branch

00:37:48,180 --> 00:37:50,050
because the volume is quite low,

00:37:50,050 --> 00:37:52,620
but for linux-next, sometimes you have issues

00:37:52,620 --> 00:37:54,020
that only show up in linux-next,

00:37:54,020 --> 00:37:55,260
when you merge two things together,

00:37:55,260 --> 00:37:57,190
that's the point of linux-next.

00:37:57,190 --> 00:37:58,160
And if that happens, the only way

00:37:58,160 --> 00:38:00,390
to find a commit is really bisection.

00:38:02,060 --> 00:38:07,060
So, git bisect only tracks one result per revision,

00:38:07,560 --> 00:38:08,800
so when you do git bisect,

00:38:08,800 --> 00:38:10,910
you tell it whether it was good or bad, all or new,

00:38:10,910 --> 00:38:14,370
but you can't say, test case one did 2.5

00:38:14,370 --> 00:38:17,710
as a score and test case three did 3.4

00:38:17,710 --> 00:38:20,180
and then compare and all that kind of things.

00:38:20,180 --> 00:38:21,780
So it's not good for like performance,

00:38:21,780 --> 00:38:24,090
unless you manage your own threshold

00:38:24,090 --> 00:38:25,840
and you try to determine whether it's good or bad.

00:38:25,840 --> 00:38:28,760
But you need to run a separate bisection for each test case.

00:38:28,760 --> 00:38:32,570
It can become very complicated when on each revision,

00:38:32,570 --> 00:38:35,870
some test cases were all start passing or failing,

00:38:35,870 --> 00:38:37,710
and if you're dealing with performance, you know,

00:38:37,710 --> 00:38:40,240
it's a curve, and when do you decide if it's a pass or fail?

00:38:40,240 --> 00:38:43,810
So that's where it gets really complicated to report.

00:38:43,810 --> 00:38:46,230
First of all there's what actually started failing,

00:38:46,230 --> 00:38:50,050
and then to bisect to find which commit actually broke.

00:38:50,050 --> 00:38:52,360
'Cause if you just say, yesterday's next performance

00:38:52,360 --> 00:38:54,950
was that, and today it's that.

00:38:54,950 --> 00:38:57,060
If there was a drop, it's gonna be really hard

00:38:57,060 --> 00:38:58,600
to find where the drop is coming from.

00:38:58,600 --> 00:39:00,490
Sometimes it might be obvious, if some people

00:39:00,490 --> 00:39:01,370
know the code really well

00:39:01,370 --> 00:39:05,770
and they can correlate it instinctively, but it's not easy.

00:39:07,150 --> 00:39:08,700
So meanwhile at Intel,

00:39:09,600 --> 00:39:14,010
around 2015 the EzBench project was started by Martin Peres,

00:39:14,010 --> 00:39:16,960
and that's kind of the origin of what is gfx-ci now.

00:39:19,463 --> 00:39:24,350
That was used in automated testing between 2016 and 2018

00:39:24,350 --> 00:39:29,130
and now I think gfx-ci is mostly using ci buglog,

00:39:29,130 --> 00:39:30,940
which is pretty good at, you know, tracking bugs,

00:39:30,940 --> 00:39:32,320
but it's not doing bisections.

00:39:32,320 --> 00:39:35,640
So some people are running EzBench

00:39:35,640 --> 00:39:39,510
to deal with their results and narrow down,

00:39:39,510 --> 00:39:42,880
'cause it does some bisection for complex test suites,

00:39:42,880 --> 00:39:45,870
but people are doing this more like on the manual basis.

00:39:45,870 --> 00:39:49,200
However it has some very powerful features,

00:39:49,200 --> 00:39:52,510
it can schedule tests like we do in KernelCI

00:39:52,510 --> 00:39:54,950
and generate some reports like we do in KernelCI,

00:39:54,950 --> 00:39:57,800
but also bisect test suites like I've just explained

00:39:57,800 --> 00:40:00,140
with floating point values and multiple numbers

00:40:00,140 --> 00:40:02,580
of test cases that pass or fail at different points in time.

00:40:02,580 --> 00:40:05,530
And that's something we don't have in KernelCI

00:40:05,530 --> 00:40:07,400
and we really care about.

00:40:07,400 --> 00:40:11,420
So actually I did a presentation at Fosdem in February,

00:40:12,450 --> 00:40:14,120
about when I explained the problem,

00:40:14,120 --> 00:40:15,350
and Martin Peres was in the room

00:40:15,350 --> 00:40:16,890
and we talked about the presentation

00:40:16,890 --> 00:40:19,368
and he explained that he had a solution for that.

00:40:19,368 --> 00:40:24,368
So then I, the challenge was clear.

00:40:24,510 --> 00:40:26,520
There's a solution in EzBench for the problem,

00:40:26,520 --> 00:40:30,226
we're having in KernelCI and well, it's only typing, right?

00:40:30,226 --> 00:40:31,160
(laughing)

00:40:31,160 --> 00:40:32,800
So many keystrokes later,

00:40:34,475 --> 00:40:36,600
I made this dangerous tool called scalpel

00:40:36,600 --> 00:40:38,400
and it's a proof of concept project.

00:40:41,502 --> 00:40:43,630
And basically I took some bits of EzBench

00:40:43,630 --> 00:40:46,970
that just do the bisection, so it's a compressed version.

00:40:46,970 --> 00:40:49,230
And there's a git tree here.

00:40:49,230 --> 00:40:51,420
But it's a proof of concept that has,

00:40:52,805 --> 00:40:55,800
I've only tested it on some artificial git trees

00:40:55,800 --> 00:40:58,320
but I've shown that it can work

00:40:58,320 --> 00:41:00,030
with floating point values and tests

00:41:00,030 --> 00:41:02,820
that change at different rates.

00:41:04,380 --> 00:41:06,630
And we've agreed that Martin, that it was a good idea

00:41:06,630 --> 00:41:09,940
to have this tool maybe as a separate python package,

00:41:09,940 --> 00:41:10,780
it's written in python,

00:41:10,780 --> 00:41:14,520
that you could use both in gfx-ci for Intel and KernelCI

00:41:14,520 --> 00:41:16,380
and maybe other people could use that

00:41:16,380 --> 00:41:20,540
to bisect other test suites like a generic tool

00:41:20,540 --> 00:41:23,240
that can be more powerful than git bisect.

00:41:25,060 --> 00:41:28,180
There are probably things that git bisect would do better

00:41:28,180 --> 00:41:29,980
because it's part of git

00:41:29,980 --> 00:41:32,510
but that's a separate class of issues.

00:41:32,510 --> 00:41:35,630
So here we have, not a real demo,

00:41:35,630 --> 00:41:36,970
it's kind of an exercise for the reader,

00:41:36,970 --> 00:41:37,880
the slides are available

00:41:37,880 --> 00:41:39,350
so I'm not gonna spend too much time looking

00:41:39,350 --> 00:41:41,830
at it right now.

00:41:41,830 --> 00:41:45,320
But basically you start with like an artificial history

00:41:45,320 --> 00:41:49,210
of things here and you only report these three commits.

00:41:49,210 --> 00:41:52,020
There's foo and bar, our two test results,

00:41:52,020 --> 00:41:54,540
giving some floating point numbers,

00:41:54,540 --> 00:41:56,410
and they're run three times to give you some idea

00:41:56,410 --> 00:41:57,920
of the variance of the test.

00:41:58,810 --> 00:42:02,290
So you can see that this test went up and down

00:42:02,290 --> 00:42:05,840
and it went up on that branch, they got merged later.

00:42:06,880 --> 00:42:08,240
So you give these three inputs,

00:42:08,240 --> 00:42:11,520
you need to test this version with this test

00:42:11,520 --> 00:42:13,680
and you need to test this one because it's a merge base.

00:42:13,680 --> 00:42:15,370
It will detect when there's a merge base,

00:42:15,370 --> 00:42:16,540
speaking of the git tree.

00:42:16,540 --> 00:42:19,570
It imports the git objects using the git

00:42:20,520 --> 00:42:22,310
with the python wrapper.

00:42:22,310 --> 00:42:24,640
And then so you run tests and it finds more results

00:42:24,640 --> 00:42:27,020
and then it says, oh, this is the one commit

00:42:27,020 --> 00:42:29,690
for that test case that failed.

00:42:29,690 --> 00:42:32,050
And it finds that this one went up here

00:42:32,050 --> 00:42:34,430
and down here so that's the whole history.

00:42:34,430 --> 00:42:36,180
I mean you can look at the detail of that.

00:42:36,180 --> 00:42:38,740
You can also run it yourself, there's a demo script,

00:42:38,740 --> 00:42:43,640
in the project, there was a link in a previous slide.

00:42:43,640 --> 00:42:45,770
So that's how I proved that it could work

00:42:45,770 --> 00:42:48,300
and it was written as a command line

00:42:48,300 --> 00:42:51,110
that can be used in KernelCI.

00:42:51,110 --> 00:42:55,980
So while we have a set of good and bad test results,

00:42:55,980 --> 00:42:58,830
we can feed that into the program as it currently stands.

00:43:00,200 --> 00:43:03,580
It's not running now, but we have a test instance

00:43:03,580 --> 00:43:05,860
for KernelCI where we can try new things

00:43:05,860 --> 00:43:07,380
and I'm planning to get that tested.

00:43:07,380 --> 00:43:09,800
I mean, I did this work like a month ago,

00:43:09,800 --> 00:43:12,000
so maybe later this year it will be good

00:43:12,000 --> 00:43:13,780
to have this started to be tested.

00:43:15,420 --> 00:43:18,836
And we can also do it with maybe igt test results

00:43:18,836 --> 00:43:21,600
and see if that's something that

00:43:21,600 --> 00:43:24,370
Intel would be interested to help with.

00:43:25,280 --> 00:43:27,570
But this is not the end, so what should we do with this?

00:43:27,570 --> 00:43:30,270
Like I said, we can try to integrated it in KernelCI.

00:43:30,270 --> 00:43:32,610
We would like make a generic python package,

00:43:33,560 --> 00:43:35,860
like pybisect or whatever you want to call it.

00:43:37,640 --> 00:43:39,880
And in KernelCI, also KernelCI,

00:43:40,990 --> 00:43:42,820
all the steps to build and generate

00:43:42,820 --> 00:43:45,469
some jobs and submit them.

00:43:45,469 --> 00:43:48,990
They were all like hard-coded in Jenkins jobs,

00:43:48,990 --> 00:43:51,150
but now we're moving all that to command line

00:43:51,150 --> 00:43:53,790
so you can run them in shell and the Jenkins automation,

00:43:53,790 --> 00:43:55,570
will just be calling these things

00:43:55,570 --> 00:43:57,430
so you don't have to use Jenkins

00:43:57,430 --> 00:44:00,210
or you could run it in something else if you want to.

00:44:00,210 --> 00:44:03,380
As you write pipeline or gitlapCI or whatever you call it,

00:44:03,380 --> 00:44:05,070
as long as you can call these things

00:44:05,070 --> 00:44:07,370
and solve the problems of managing resources

00:44:07,370 --> 00:44:10,150
and running stacks in parallel and stuff like that.

00:44:10,150 --> 00:44:12,730
So anyway, there's gonna be a new command for KernelCI

00:44:12,730 --> 00:44:15,600
called kci_bisect to run these things.

00:44:15,600 --> 00:44:17,780
So you could also rerun a bisection locally,

00:44:17,780 --> 00:44:19,130
if you want to do the same thing

00:44:19,130 --> 00:44:21,430
with more debug options turned on for example.

00:44:22,430 --> 00:44:24,120
So every time there's a pass or fail,

00:44:24,120 --> 00:44:28,510
you can have more information about what's going on.

00:44:29,382 --> 00:44:31,290
So having a generic tool

00:44:31,290 --> 00:44:33,010
that can be used across different projects,

00:44:33,010 --> 00:44:35,170
maybe that's something we would want to do again

00:44:35,170 --> 00:44:36,680
for other things.

00:44:36,680 --> 00:44:41,680
For example, there are loads of steps in a CI system,

00:44:43,800 --> 00:44:48,490
like this where you need to detect the source code changes.

00:44:48,490 --> 00:44:52,200
You need to schedule some tests

00:44:52,200 --> 00:44:54,280
and get the results and then bisect them.

00:44:54,280 --> 00:44:56,780
So here, if we have a tool for bisection,

00:44:56,780 --> 00:44:59,170
that's good, and then maybe we could also have tools

00:44:59,170 --> 00:45:00,003
for all the other things

00:45:00,003 --> 00:45:03,220
that could be used across different CI systems.

00:45:05,680 --> 00:45:09,570
So maybe having a toolbox, where we have other tools,

00:45:09,570 --> 00:45:11,720
like scissors and hammers maybe

00:45:11,720 --> 00:45:14,540
could be used to solve the other issues.

00:45:15,650 --> 00:45:17,790
And then also needed, so here we need

00:45:17,790 --> 00:45:20,100
to improve the email reports and all that.

00:45:20,100 --> 00:45:22,600
It's about finding the right balance between

00:45:22,600 --> 00:45:24,620
giving enough detail so that it's useful,

00:45:24,620 --> 00:45:26,770
but not having too much noise so it's lost in the noise.

00:45:26,770 --> 00:45:28,150
That's all, it's very subjective

00:45:28,150 --> 00:45:30,800
and depends on the workflows of different subsystems.

00:45:33,305 --> 00:45:34,280
And yeah, there's a lot of things we need

00:45:34,280 --> 00:45:37,870
to improve on that, but at least if we can bisect,

00:45:37,870 --> 00:45:40,460
based on the experience we have from boots,

00:45:40,460 --> 00:45:42,990
being able to bisect and find the commit

00:45:42,990 --> 00:45:43,850
that caused the problems,

00:45:43,850 --> 00:45:47,700
that's already like 80% of the work done

00:45:47,700 --> 00:45:50,700
to incentivize people to fix the problem.

00:45:53,940 --> 00:45:56,270
So yeah, stay tuned, there's more things coming.

00:45:57,980 --> 00:45:59,230
So, some people I've mentioned dealing with

00:45:59,230 --> 00:46:01,820
large test suites, like Microsoft,

00:46:01,820 --> 00:46:03,650
I know you're dealing with a lot of data.

00:46:03,650 --> 00:46:07,580
Is that something that you've solved as well in some way?

00:46:07,580 --> 00:46:09,730
Like, how do you detect if you have long...

00:46:11,390 --> 00:46:12,510
You know, huge number of changes,

00:46:12,510 --> 00:46:14,896
how do you find where the problem is?

00:46:14,896 --> 00:46:16,720
- That's what I was asking earlier,

00:46:16,720 --> 00:46:20,095
like what kind of automation do you have in place for this?

00:46:20,095 --> 00:46:24,484
Microsoft has invested a lot in automating the back end

00:46:24,484 --> 00:46:27,150
of the telemetry data that they get

00:46:27,150 --> 00:46:28,550
from every Windows endpoint.

00:46:33,220 --> 00:46:34,490
And speaking to the Windows guys,

00:46:34,490 --> 00:46:38,040
they're willing to share all the technology if you will,

00:46:39,049 --> 00:46:41,770
with open source projects like what you have here.

00:46:42,746 --> 00:46:44,770
We'd would like to get together with Kevin and Hoark

00:46:44,770 --> 00:46:47,040
and come to Redmond and get a meeting going,

00:46:47,040 --> 00:46:48,950
in terms of what you have on the Windows side

00:46:48,950 --> 00:46:53,240
and see what's applicable to Linux platforms

00:46:53,240 --> 00:46:56,720
in terms of gathering the data

00:46:56,720 --> 00:46:59,010
and making the data useful down the road.

00:47:02,280 --> 00:47:04,670
It's not something I can talk in a few minutes here,

00:47:04,670 --> 00:47:07,090
but certainly I think it's worth a discussion.

00:47:07,090 --> 00:47:09,160
- Yeah, I'm curious if other people than

00:47:09,160 --> 00:47:11,270
EzBench and KernelCI have hit the problem

00:47:11,270 --> 00:47:12,520
and then maybe solved it.

00:47:13,530 --> 00:47:16,190
- Well to me this looks like a places,

00:47:16,190 --> 00:47:17,660
where you generate the data

00:47:19,210 --> 00:47:22,200
and there's really a large amount of backend processing

00:47:22,200 --> 00:47:25,700
that you would need to put this data through

00:47:25,700 --> 00:47:28,080
to make the data useful in terms

00:47:28,080 --> 00:47:31,030
of gating new commits going in for instance

00:47:31,030 --> 00:47:34,680
as well as the least processes you might have.

00:47:35,860 --> 00:47:37,670
At Microsoft, they actually use this data

00:47:37,670 --> 00:47:41,360
to stop Windows updates going out for instance.

00:47:45,690 --> 00:47:48,870
So there's also a large body of internal users

00:47:48,870 --> 00:47:53,870
of internal built for Windows that also generate this data,

00:47:54,110 --> 00:47:55,490
which also allows us to control,

00:47:55,490 --> 00:48:00,280
how the internal testing of Windows goes on.

00:48:00,280 --> 00:48:03,720
So we could do something like that on the next one as well.

00:48:03,720 --> 00:48:05,750
- How much of your tooling is open source?

00:48:05,750 --> 00:48:06,583
- I'm sorry.

00:48:06,583 --> 00:48:08,010
- How much of your tooling is open source?

00:48:08,010 --> 00:48:10,380
- Zero. - Zero, alright, thank you.

00:48:10,380 --> 00:48:12,630
- That's where we are, but we want to

00:48:12,630 --> 00:48:13,980
actually look at ways of...

00:48:15,400 --> 00:48:18,640
As more and more Linux workloads run on Azure, right?

00:48:18,640 --> 00:48:21,460
So I am pretty blind in terms

00:48:21,460 --> 00:48:26,310
of Linux telemetry coming back from our cloud,

00:48:26,310 --> 00:48:27,420
but on the Windows side,

00:48:27,420 --> 00:48:29,610
they have rich telemetry that tells them

00:48:29,610 --> 00:48:31,970
what kind of things are going on.

00:48:31,970 --> 00:48:34,260
So we're interested in looking at what we can do

00:48:34,260 --> 00:48:39,030
to collect more information and be able to use that

00:48:39,030 --> 00:48:41,230
to control how things get deployed.

00:48:45,590 --> 00:48:48,530
- I'm curious to know if there are other Google folks,

00:48:48,530 --> 00:48:51,280
what sort of telemetry are you getting from your cloud?

00:48:57,560 --> 00:48:58,999
- Silence.

00:48:58,999 --> 00:48:59,832
Amazon?

00:49:02,370 --> 00:49:05,076
Okay, it was worth a shot.

00:49:05,076 --> 00:49:07,326
(laughing)

00:49:10,385 --> 00:49:11,302
- Facebook.

00:49:14,460 --> 00:49:16,520
- I know Facebook's using, they've talked about,

00:49:16,520 --> 00:49:18,660
bsi in the past to collect data,

00:49:19,910 --> 00:49:22,120
but I don't know how much of this is really

00:49:22,120 --> 00:49:24,990
to catch errors versus, hey, some system's slowing down,

00:49:26,770 --> 00:49:28,570
and you know, we needed to fix that.

00:49:34,360 --> 00:49:37,770
- So, for Sony Mobile for a while,

00:49:37,770 --> 00:49:41,430
Sony has a lot of telemetry data from their phones,

00:49:41,430 --> 00:49:43,340
I would assume that the other phone manufacturers

00:49:43,340 --> 00:49:46,790
also have a lot of data that they get.

00:49:46,790 --> 00:49:49,890
- Oh, another interesting group I guess would be Tesla.

00:49:51,240 --> 00:49:53,490
Those guys must collect a lot of information.

00:49:57,598 --> 00:49:58,797
- They're not gonna share it.

00:49:58,797 --> 00:50:00,120
(laughing)

00:50:00,120 --> 00:50:04,980
- You can ask.

00:50:04,980 --> 00:50:09,980
- Speaking of end to end use of the telemetry data,

00:50:10,610 --> 00:50:13,770
if somebody is sitting and coding in a file,

00:50:13,770 --> 00:50:16,400
let's say there's a third in that particular function,

00:50:17,270 --> 00:50:20,530
you could actually get information about how many times,

00:50:20,530 --> 00:50:22,790
in the field, that a third triggered.

00:50:24,020 --> 00:50:28,690
So the developer know where the problems are coming in.

00:50:29,990 --> 00:50:33,810
That kind of end to end solution

00:50:33,810 --> 00:50:36,650
is what Microsoft has on their Windows platforms.

00:50:41,120 --> 00:50:42,920
- So I can try to answer.

00:50:42,920 --> 00:50:46,203
Sir, I think your question is a little too general, Duvall.

00:50:46,203 --> 00:50:47,940
I mean, 'cause Google does collect a lot of information,

00:50:47,940 --> 00:50:51,080
obviously right, from browser, for ChromeOS in particular.

00:50:51,080 --> 00:50:52,670
- So let me be more specific.

00:50:52,670 --> 00:50:55,810
- I can't speak for Android, but in both cases

00:50:55,810 --> 00:50:58,600
we do collect user stats when people opt in to it.

00:50:58,600 --> 00:51:01,352
There are usage information that we do collect about it

00:51:01,352 --> 00:51:02,880
and we also get crash reports,

00:51:02,880 --> 00:51:03,920
which is something I want to talk

00:51:03,920 --> 00:51:06,370
to Kevin about later and looking at that.

00:51:06,370 --> 00:51:08,150
- Do we have time to talk about this right now?

00:51:08,150 --> 00:51:08,983
No.

00:51:10,560 --> 00:51:11,810
- My point is that there's a lot

00:51:11,810 --> 00:51:14,710
of information and I don't think I have

00:51:14,710 --> 00:51:17,430
the liberty to speak publicly about it.

00:51:17,430 --> 00:51:19,060
- Let me make it a bit more specific.

00:51:19,060 --> 00:51:22,840
Let's talk about the telemetry information

00:51:22,840 --> 00:51:24,860
for example, what these guys are getting

00:51:24,860 --> 00:51:27,200
from their Windows system in Azure.

00:51:28,420 --> 00:51:31,140
Are you getting similar amount of telemetry

00:51:31,140 --> 00:51:33,390
from say GCE as an example.

00:51:34,330 --> 00:51:35,420
- I don't know anything about Azure,

00:51:35,420 --> 00:51:36,340
and I'm not working on the cloud,

00:51:36,340 --> 00:51:41,070
so I can't answer any of that.

00:51:41,070 --> 00:51:42,840
I can hardly imagine why not.

00:51:42,840 --> 00:51:44,370
I mean, why wouldn't they collect it?

00:51:45,780 --> 00:51:49,950
- I think, I mean, we're talking now about a lot of data,

00:51:49,950 --> 00:51:52,610
but I think maybe the most challenging problem

00:51:52,610 --> 00:51:54,530
is to figure out what data to use

00:51:54,530 --> 00:51:56,930
to test what commits because right now,

00:51:56,930 --> 00:51:59,240
we are talking about testing entire kernel

00:52:00,430 --> 00:52:03,630
or random commits in the kernel to which,

00:52:05,250 --> 00:52:08,500
and what test do you actually need to test on.

00:52:08,500 --> 00:52:11,110
If you know what subsystem a commit is about,

00:52:11,110 --> 00:52:14,420
you could maybe limit the test to kind of certain--

00:52:15,540 --> 00:52:16,373
- Yeah that's true.

00:52:16,373 --> 00:52:18,770
That's why we were running the v4l2 compliance

00:52:18,770 --> 00:52:21,030
for the media subsystem in the same way,

00:52:21,030 --> 00:52:23,730
we could run igt on the drm tree.

00:52:24,580 --> 00:52:27,150
But then our thing is, like I said about Linux-next,

00:52:27,150 --> 00:52:29,760
you know sometimes one person makes a change in one tree

00:52:29,760 --> 00:52:31,530
and it's all fine and there's another change

00:52:31,530 --> 00:52:32,550
in another tree and it's all fine,

00:52:32,550 --> 00:52:34,400
and when you merge the two together, then there's a problem.

00:52:34,400 --> 00:52:36,850
So in linux-next we need to, ideally

00:52:36,850 --> 00:52:38,400
to be running all the things.

00:52:38,400 --> 00:52:40,360
- Yes, definitely, but at least

00:52:40,360 --> 00:52:42,980
that's the first kind of first iteration,

00:52:44,769 --> 00:52:46,790
and then maybe add on in some way.

00:52:46,790 --> 00:52:47,970
- I'm sorry to interrupt here,

00:52:47,970 --> 00:52:49,250
but we're going to run out of time,

00:52:49,250 --> 00:52:50,660
so maybe one more question.

00:52:52,000 --> 00:52:54,002
Only one more answer.

00:52:54,002 --> 00:52:56,760
(laughing)

00:52:56,760 --> 00:52:58,400
- Did you say you were testing,

00:52:58,400 --> 00:53:00,160
the gate for commits going in?

00:53:02,180 --> 00:53:04,961
So the testing that you have going here,

00:53:04,961 --> 00:53:07,400
do you see that being the gate

00:53:08,390 --> 00:53:10,600
for the maintainers to come in to code?

00:53:10,600 --> 00:53:11,930
So they would wait for you to say,

00:53:11,930 --> 00:53:14,700
"Yeah, this thing doesn't regress anything,

00:53:14,700 --> 00:53:17,270
"doesn't break anything or hurt anything."

00:53:17,270 --> 00:53:20,600
- I don't think the workflow ever changed.

00:53:20,600 --> 00:53:22,910
Maybe for stable branches, like it's only the case,

00:53:22,910 --> 00:53:27,090
on stable releases that there's a report sent actively

00:53:27,090 --> 00:53:30,850
by KernelCI replying to stable queue review.

00:53:32,040 --> 00:53:33,500
Maybe if we have more things,

00:53:33,500 --> 00:53:35,310
if there's an error reported there,

00:53:35,310 --> 00:53:37,310
maybe the stable release will wait,

00:53:37,310 --> 00:53:39,110
until there's something that comes back.

00:53:39,110 --> 00:53:41,298
But it depends, you know,

00:53:41,298 --> 00:53:44,300
maybe some subsystems will be willing to do that.

00:53:44,300 --> 00:53:46,950
It depends at which pace they're going.

00:53:46,950 --> 00:53:48,290
- So yeah, I don't see that.

00:53:48,290 --> 00:53:52,000
Stable, yes, because the commit goes into the main line,

00:53:52,000 --> 00:53:54,485
that's how it flows so that makes sense.

00:53:54,485 --> 00:53:57,520
We do the work, some cases depending on the fail

00:53:57,520 --> 00:53:59,100
or failure of the cases,

00:53:59,100 --> 00:54:01,470
but that's not how the development model works.

00:54:01,470 --> 00:54:03,820
- [Man] So it depends on the turn around time.

00:54:07,414 --> 00:54:08,860
- Let's continue this discussion later.

00:54:09,866 --> 00:54:11,140
- It also depends how long it takes.

00:54:11,140 --> 00:54:12,840
If it takes 12 hours then--

00:54:12,840 --> 00:54:15,610
- That's the thing, if it's not just a small amount.

00:54:18,720 --> 00:54:19,780
- While this discussion goes on,

00:54:19,780 --> 00:54:21,180
I guess Dmitry can step out.

00:54:27,650 --> 00:54:29,690
- I would just add that it's not officially part

00:54:29,690 --> 00:54:30,910
of the development process,

00:54:30,910 --> 00:54:33,230
but there are maintainers that actually look at it,

00:54:33,230 --> 00:54:36,310
before they make decisions, but it's not a hard gate.

00:54:53,966 --> 00:54:55,788
- Thank you very much.

00:54:55,788 --> 00:54:59,121
(participants clapping)

00:55:09,832 --> 00:55:13,249
(low indistinct chatter)

00:55:51,800 --> 00:55:53,810
- I'm starting?

00:55:53,810 --> 00:55:55,660
So hello, my name is Dmitry Vyukov

00:55:55,660 --> 00:55:59,180
and I wanted to introduce an idea called GWP-ASAN.

00:55:59,180 --> 00:56:01,480
So this idea is implemented for user space

00:56:01,480 --> 00:56:02,550
but not yet for kernel,

00:56:02,550 --> 00:56:05,060
so for kernel it's just something we can't do.

00:56:06,560 --> 00:56:09,040
Right, so we all want to find more bugs.

00:56:09,040 --> 00:56:11,220
And we could ask, but why?

00:56:11,220 --> 00:56:13,760
You have that killing machine by you in more bugs

00:56:13,760 --> 00:56:15,850
and the thing is that not all bugs are equal, right?

00:56:15,850 --> 00:56:17,730
There are logged up warnings in the code

00:56:17,730 --> 00:56:18,870
that you don't care about,

00:56:18,870 --> 00:56:22,510
and then there are bad bugs in your actual production code.

00:56:23,530 --> 00:56:25,240
And the GWP-ASAN is the answer for this.

00:56:25,240 --> 00:56:26,870
And the good thing is that you will not need

00:56:26,870 --> 00:56:31,180
to write tests and do CI and even do fuzzing.

00:56:34,190 --> 00:56:36,690
So, first of all, KASAN crash course.

00:56:36,690 --> 00:56:40,130
So KASAN finds use-after-free, out-of-bounds, double-free.

00:56:41,130 --> 00:56:43,100
It uses compiler instrumentation,

00:56:43,100 --> 00:56:45,010
so that before each memory access,

00:56:45,010 --> 00:56:47,090
the compiler instrumentation checks,

00:56:47,090 --> 00:56:49,150
if this memory access is legit or not.

00:56:50,040 --> 00:56:53,090
And we have one-eighths shadow memory,

00:56:53,090 --> 00:56:56,630
which keeps track of the state of the actual kernel memory.

00:56:56,630 --> 00:56:59,230
And we have red-zones around heap objects

00:56:59,230 --> 00:57:01,400
and we have quarantine for freed objects.

00:57:02,460 --> 00:57:04,120
And the problem is that these seem

00:57:04,120 --> 00:57:06,980
to use significant slowdown and memory overhead,

00:57:06,980 --> 00:57:09,810
so there's no way you would use this in production.

00:57:11,210 --> 00:57:13,470
And there's an idea called electric fence,

00:57:13,470 --> 00:57:15,560
also known as page heap or page guard.

00:57:15,560 --> 00:57:17,510
It's when we allocate a heap object.

00:57:17,510 --> 00:57:19,880
What we do actually allocate three pages

00:57:19,880 --> 00:57:22,210
and we protect two of the pages

00:57:22,210 --> 00:57:25,240
and place object in the middle page.

00:57:25,240 --> 00:57:27,260
We can also place it at the end,

00:57:27,260 --> 00:57:29,490
and those protected pages help us

00:57:29,490 --> 00:57:31,440
to catch out of bounds access.

00:57:32,600 --> 00:57:34,150
Right then, when we free the object,

00:57:34,150 --> 00:57:35,920
we also protect the page itself.

00:57:36,900 --> 00:57:39,230
This allows us to catch each of the frees.

00:57:39,230 --> 00:57:41,450
So this is great because this detect bugs

00:57:41,450 --> 00:57:43,500
and this doesn't need any instrumentation

00:57:44,720 --> 00:57:46,440
and can be enabled at runtime.

00:57:46,440 --> 00:57:49,760
But the problem is that it's really expensive, right,

00:57:49,760 --> 00:57:53,590
because for memory we allocate a whole page

00:57:53,590 --> 00:57:57,260
for each heap object and it's also slow

00:57:57,260 --> 00:58:00,970
because we need to do those and protect our DTLB flushes

00:58:00,970 --> 00:58:03,180
or something for each heap allocation free.

00:58:04,990 --> 00:58:06,540
Yeah, so this also can't work,

00:58:06,540 --> 00:58:08,790
it's actually even slower than KASAN,

00:58:11,250 --> 00:58:13,250
but what if we use sampling.

00:58:13,250 --> 00:58:15,720
So if we combine the electric fence with the sampling,

00:58:15,720 --> 00:58:18,620
so what we do, we just choose one of the allocations

00:58:18,620 --> 00:58:22,150
and allocate it this way with the surrounding pages.

00:58:24,300 --> 00:58:26,610
And we can choose the sampling rate.

00:58:27,740 --> 00:58:30,090
Low, as low as we need

00:58:30,090 --> 00:58:34,360
to get the CPU overhead to the level that we need,

00:58:34,360 --> 00:58:36,840
to the level that actually doesn't matter for us.

00:58:36,840 --> 00:58:39,850
And we can also limit the number

00:58:39,850 --> 00:58:43,040
of heap objects to control the memory overhead.

00:58:43,940 --> 00:58:45,960
But the caveat here is that then you want

00:58:45,960 --> 00:58:48,650
to apply this to a really large set of machines, right?

00:58:48,650 --> 00:58:50,470
Because if you use example one

00:58:50,470 --> 00:58:52,240
of million objects in one machine,

00:58:52,240 --> 00:58:54,020
it's like you do not really test anything,

00:58:54,020 --> 00:58:56,830
but if you apply it then to millions of machines,

00:58:56,830 --> 00:58:59,120
then kind of get back your precision.

00:59:01,230 --> 00:59:03,160
And for the memory layout we can do,

00:59:03,160 --> 00:59:04,290
actually an interesting thing,

00:59:04,290 --> 00:59:08,910
we can pre-allocate on boot a fixed number of pages

00:59:08,910 --> 00:59:10,920
and protect each other page.

00:59:10,920 --> 00:59:13,650
And then only kind of use that fixed number,

00:59:13,650 --> 00:59:17,190
so we don't have even the lower half left fixed,

00:59:17,190 --> 00:59:18,960
completely fixed memory overhead,

00:59:18,960 --> 00:59:21,920
so if you can dedicate one megabyte of memory,

00:59:21,920 --> 00:59:26,260
this gives you 128 such protected objects.

00:59:28,460 --> 00:59:30,300
We are also using metainformation

00:59:30,300 --> 00:59:34,460
to store the allocation free stacks, maybe PIDs,

00:59:34,460 --> 00:59:36,820
to provide actionable back reports,

00:59:36,820 --> 00:59:40,590
but this doesn't affect performance

00:59:40,590 --> 00:59:42,640
or memory consumption so it's easy to do.

00:59:44,040 --> 00:59:45,000
So the current use.

00:59:45,000 --> 00:59:48,600
We have it implemented in user space in LLVM

00:59:48,600 --> 00:59:51,670
and it's enabled for the SCUDO hardened memory allocator.

00:59:52,880 --> 00:59:54,820
And internally at Google we enable it

00:59:54,820 --> 00:59:57,100
for all of the tests and for the tests,

00:59:57,100 --> 01:00:01,130
we use a slightly more aggressive sampling rate,

01:00:01,130 --> 01:00:03,270
so there is actually some effect on the CPU,

01:00:03,270 --> 01:00:04,800
but for testing it's fine.

01:00:06,630 --> 01:00:09,010
And we also enable it, it's also enabled,

01:00:09,010 --> 01:00:11,320
in the production by default and in production,

01:00:11,320 --> 01:00:13,430
we actually use a much lower sampling rate

01:00:13,430 --> 01:00:16,050
so that we get CPU overhead effectively zero.

01:00:16,950 --> 01:00:20,130
Like it's not measurable by any means.

01:00:20,130 --> 01:00:23,100
And this already found hundreds of bugs

01:00:23,100 --> 01:00:24,600
that are kind of super-critical

01:00:24,600 --> 01:00:26,320
that actually happen in production,

01:00:26,320 --> 01:00:28,860
in our actual production workloads

01:00:28,860 --> 01:00:31,400
and the bugs are auto-filed and so on,

01:00:31,400 --> 01:00:34,400
so this kind of applied pipeline of finding bugs.

01:00:35,530 --> 01:00:37,640
For the Chrome it's now being rolled out

01:00:37,640 --> 01:00:39,260
and at this point I think it's enabled,

01:00:39,260 --> 01:00:41,570
in some of the actual end user builds,

01:00:41,570 --> 01:00:44,480
so in some operating systems you actually get

01:00:44,480 --> 01:00:46,430
Chrome build with this feature enabled.

01:00:48,460 --> 01:00:50,110
And it's also finding lots of bugs

01:00:50,110 --> 01:00:52,850
that are very important and critical,

01:00:52,850 --> 01:00:54,710
especially for security.

01:00:54,710 --> 01:00:56,340
And finally, this work in progress,

01:00:56,340 --> 01:00:59,330
we will also want it deployed for Android devices.

01:01:00,780 --> 01:01:04,440
Some potential kernel users, so I see lots.

01:01:04,440 --> 01:01:07,370
For example, the distribution could enable it

01:01:07,370 --> 01:01:10,610
for just everybody on all builds

01:01:10,610 --> 01:01:15,420
and all of the cloud and data centers could enable it,

01:01:15,420 --> 01:01:18,350
on all servers for all kernels and if you have lots

01:01:18,350 --> 01:01:20,460
of consumer devices, large base,

01:01:20,460 --> 01:01:22,610
you could enable it on all of the devices.

01:01:24,357 --> 01:01:25,730
I see no reason to not do this.

01:01:25,730 --> 01:01:30,730
So there's like no overhead and no downsides at all.

01:01:30,900 --> 01:01:35,403
We just get really critical, important backs from the field.

01:01:37,420 --> 01:01:40,030
There are several interesting implementation aspects.

01:01:40,030 --> 01:01:42,670
For example, when we do allocation,

01:01:42,670 --> 01:01:44,610
we can do some quick check and then go

01:01:44,610 --> 01:01:47,500
to slow-path actually and allocate the protected page,

01:01:47,500 --> 01:01:51,460
but this check slows down the kmalloc fast-path.

01:01:51,460 --> 01:01:53,320
So the question is, "Can we implement it

01:01:53,320 --> 01:01:56,000
"without slowing down kmalloc at all?"

01:01:56,000 --> 01:01:57,410
And I think it's possible,

01:01:57,410 --> 01:01:59,330
we probably could piggyback on some

01:01:59,330 --> 01:02:00,770
of the existing slow-paths,

01:02:00,770 --> 01:02:03,280
for example when we refill SBU cache

01:02:03,280 --> 01:02:08,280
we could only then, kind of do a lower rate checking.

01:02:10,240 --> 01:02:13,000
Then it may need some potential tunables.

01:02:13,000 --> 01:02:16,240
Maybe you want to enable and disable it at runtime,

01:02:16,240 --> 01:02:19,470
maybe you want it to panic or not at runtime

01:02:19,470 --> 01:02:21,970
and obviously want to tune the memory overhead

01:02:21,970 --> 01:02:23,860
and sampling rate, but the good news is,

01:02:23,860 --> 01:02:27,850
those can be runtime tunables, I mean boot time tunables.

01:02:29,680 --> 01:02:31,450
The question is for small devices,

01:02:31,450 --> 01:02:33,890
how can it be used in small devices?

01:02:33,890 --> 01:02:37,450
How small a device can still use it?

01:02:37,450 --> 01:02:42,450
And I think even if you can permit several pages,

01:02:42,790 --> 01:02:44,380
maybe, I don't know, two or four,

01:02:44,380 --> 01:02:47,230
that still can be useful because the thing is that,

01:02:47,230 --> 01:02:50,610
if you have less code and smaller workload,

01:02:50,610 --> 01:02:53,640
you also have fewer allocation sites,

01:02:53,640 --> 01:02:57,710
so you actually need kind of slower rate sampling is fine

01:02:57,710 --> 01:03:01,920
because you just have to fix kind of hundreds of kmallocs.

01:03:04,900 --> 01:03:07,860
Sampling strategy for kernel may need some tuning

01:03:07,860 --> 01:03:11,260
and there's no answer what is the right thing to do

01:03:11,260 --> 01:03:13,960
because the problem is that if you have

01:03:13,960 --> 01:03:17,860
any persistent allocations, they deplete this pool, right?

01:03:17,860 --> 01:03:19,670
Allocate something, now never free

01:03:19,670 --> 01:03:21,560
and now we have less one object

01:03:21,560 --> 01:03:23,870
and if we have just a hundred of them,

01:03:23,870 --> 01:03:27,110
we can soon just deplete all of them.

01:03:27,110 --> 01:03:32,030
And some of the kernels, they see very infrequent reboots,

01:03:32,030 --> 01:03:33,370
so the question, what do we do?

01:03:33,370 --> 01:03:35,700
Maybe we don't sample at boot at all

01:03:35,700 --> 01:03:38,921
or maybe we just do very low probability,

01:03:38,921 --> 01:03:41,340
during boot for example, just one object.

01:03:42,820 --> 01:03:46,460
Or we can start sampling after X uptime only.

01:03:47,950 --> 01:03:50,840
Or maybe we can deplete some of the slaps

01:03:50,840 --> 01:03:54,730
because we know that they have long-leafed objects.

01:03:54,730 --> 01:03:56,060
Maybe it's actually not that bad

01:03:56,060 --> 01:03:58,080
because if you have a given router

01:03:58,080 --> 01:04:01,580
and you're rebooting frequently but still big left.

01:04:01,580 --> 01:04:05,060
And you have say, hundreds of thousands of devices still,

01:04:05,060 --> 01:04:08,390
like people have power outages which reboot them.

01:04:08,390 --> 01:04:10,780
Sometimes they plug them into different sockets

01:04:10,780 --> 01:04:12,320
so again it reboots and so on,

01:04:12,320 --> 01:04:15,610
so maybe it's actually not that bad in practice.

01:04:17,060 --> 01:04:18,590
Yes, and volunteers.

01:04:18,590 --> 01:04:21,130
If anybody's interested, that would be cool.

01:04:21,130 --> 01:04:23,340
So we do not have immediate plans,

01:04:23,340 --> 01:04:25,090
right now if nobody does this.

01:04:25,090 --> 01:04:29,900
We may do it in the future but it's not in our plans.

01:04:29,900 --> 01:04:32,500
I think it should be relatively easy and fun

01:04:32,500 --> 01:04:36,780
for anybody experienced in the MM subsystem.

01:04:36,780 --> 01:04:38,130
Yeah, that's it, thank you.

01:04:40,170 --> 01:04:41,610
- Sorry.

01:04:41,610 --> 01:04:46,610
Backing up two slides, do you have a way to...

01:04:46,660 --> 01:04:49,860
So you said your persistent objects deplete the pool.

01:04:49,860 --> 01:04:51,760
Seemed like the only persistent object you had

01:04:51,760 --> 01:04:53,380
was your use-after-free,

01:04:55,641 --> 01:04:56,750
or do you have other persistent objects?

01:04:56,750 --> 01:04:58,630
- No, if it's still allocated.

01:04:58,630 --> 01:05:01,220
So object allocated assembly events are freed,

01:05:01,220 --> 01:05:03,750
so now we're gonna start with checking this object

01:05:03,750 --> 01:05:05,930
and we don't check anything else.

01:05:05,930 --> 01:05:06,880
That's the problem.

01:05:08,130 --> 01:05:10,810
For you, you're protected for some time,

01:05:10,810 --> 01:05:13,610
and then after some time you can decide to go protected.

01:05:18,790 --> 01:05:20,240
- So where does it live right now,

01:05:20,240 --> 01:05:22,570
the user space side of things?

01:05:22,570 --> 01:05:24,200
- In LLVM.

01:05:24,200 --> 01:05:27,450
- So it's a compiler flag or how does it work?

01:05:27,450 --> 01:05:31,940
- So, it's kind of a thing

01:05:31,940 --> 01:05:35,480
that you can plug in to your memory allocator.

01:05:35,480 --> 01:05:38,520
So internally we plugged it into tcmalloc

01:05:38,520 --> 01:05:41,270
and LBM we have a library which gives you hoops

01:05:41,270 --> 01:05:43,230
that you can insert into your malloc

01:05:43,230 --> 01:05:46,460
and we inserted them into SCUDA memory allocator,

01:05:46,460 --> 01:05:48,190
which is also part of LLVM.

01:05:49,730 --> 01:05:53,440
So if you use SCUDA, it may be enabled by default

01:05:53,440 --> 01:05:55,390
or you need to flip something for that.

01:06:01,120 --> 01:06:03,680
- I'll just say that I think it's a brilliant idea

01:06:03,680 --> 01:06:07,340
to use probability like that

01:06:07,340 --> 01:06:09,390
to be able to test on live systems.

01:06:10,960 --> 01:06:14,770
- Thank you, all ideas trend well in hindsight.

01:06:22,230 --> 01:06:23,063
Thank you.

01:06:29,940 --> 01:06:32,800
- I think that, a good way forward this just

01:06:32,800 --> 01:06:36,040
to plug something into MM right now,

01:06:36,040 --> 01:06:37,660
even if it's not optimal, even if you have

01:06:37,660 --> 01:06:40,810
to kill the fast-path just to get the ball rolling.

01:06:40,810 --> 01:06:43,500
'Cause I don't think that just throwing it out there will...

01:06:43,500 --> 01:06:45,140
I don't think anyone will pick it up,

01:06:45,140 --> 01:06:47,900
it's a big project to do, especially with the MM folks,

01:06:47,900 --> 01:06:50,920
who don't have time for anything, apparently.

01:06:50,920 --> 01:06:52,560
So maybe the way forward would be,

01:06:52,560 --> 01:06:55,433
just to plug it in and make the performance hit,

01:06:55,433 --> 01:06:59,080
much worse than it should be, and then work from there.

01:06:59,080 --> 01:07:01,180
And I'm wondering if that's something you're sort

01:07:01,180 --> 01:07:03,620
of willing to work with someone to do that.

01:07:05,290 --> 01:07:06,970
- Yes, so initially we could just,

01:07:06,970 --> 01:07:09,090
penalize the fast-paths and some graphics

01:07:09,090 --> 01:07:12,410
and use very simple sampling strategy.

01:07:12,410 --> 01:07:13,660
So what do you mean by if we...

01:07:13,660 --> 01:07:14,590
So, I...

01:07:16,760 --> 01:07:19,830
I don't want to get into this right now

01:07:19,830 --> 01:07:23,170
because this also implies some deployment, right?

01:07:24,290 --> 01:07:27,080
Just implementing it doesn't make sense.

01:07:27,080 --> 01:07:28,660
We will need to use it somewhere

01:07:28,660 --> 01:07:31,540
and I don't have time for that mainly,

01:07:31,540 --> 01:07:36,540
but if someone's willing to send the patch,

01:07:37,050 --> 01:07:39,110
I'm willing to review it for example.

01:07:39,110 --> 01:07:40,510
- So I'm just thinking that,

01:07:42,643 --> 01:07:43,540
start by keeping the patches simple.

01:07:43,540 --> 01:07:44,750
I mean I'm sure we could find someone

01:07:44,750 --> 01:07:46,440
to do that, I could do that.

01:07:46,440 --> 01:07:47,830
But start by keeping it simple

01:07:47,830 --> 01:07:50,750
and then build the tempo over time,

01:07:50,750 --> 01:07:51,800
rather than trying to come up

01:07:51,800 --> 01:07:54,170
with this perfect solution from day one.

01:07:54,170 --> 01:07:56,000
- Yeah, we don't need perfect solution,

01:07:56,000 --> 01:07:58,250
but still it's some amount of work

01:07:58,250 --> 01:08:02,820
and somebody needs a plan for to actually use it as well.

01:08:04,330 --> 01:08:06,110
- I mean, people use KASAN now.

01:08:06,110 --> 01:08:07,880
It could be like a dependent option of that,

01:08:07,880 --> 01:08:09,390
if you enable KASAN, you enable that--

01:08:09,390 --> 01:08:12,150
- No, no, it doesn't make sense to enable KASAN.

01:08:12,150 --> 01:08:15,660
- It doesn't make sense, but it's a testing story,

01:08:15,660 --> 01:08:16,820
just to test those fast.

01:08:16,820 --> 01:08:19,880
So you enable that with always going,

01:08:19,880 --> 01:08:22,310
like sampling rate of always basically,

01:08:22,310 --> 01:08:24,000
and then when you see that working fine,

01:08:24,000 --> 01:08:26,970
you make the sampling rate configurable

01:08:26,970 --> 01:08:29,430
and users can start dropping the...

01:08:29,430 --> 01:08:30,880
But just to get people using it

01:08:30,880 --> 01:08:33,100
sort of as a replacement to KASAN.

01:08:33,100 --> 01:08:34,460
Because this is basically KASAN

01:08:34,460 --> 01:08:37,960
with a sampling rate of 100%.

01:08:37,960 --> 01:08:39,900
- KASAN with some knobs.

01:08:39,900 --> 01:08:43,280
- KASAN is this with 100% sampling rate, right?

01:08:45,020 --> 01:08:45,853
Basically?

01:08:45,853 --> 01:08:50,060
- Yeah, I'm sure you consume too much memory.

01:08:50,060 --> 01:08:52,170
I'm sure you can't do this.

01:08:52,170 --> 01:08:54,940
You should at least put two pages per heap object.

01:08:57,300 --> 01:09:00,200
- Yeah, let's talk about it.

01:09:03,520 --> 01:09:05,426
- There's all kinds of knobs in the kernel now

01:09:05,426 --> 01:09:10,426
that are used only in debugging circumstances

01:09:10,520 --> 01:09:12,140
and are horrible on performance

01:09:12,140 --> 01:09:14,776
so don't be afraid to add another one.

01:09:14,776 --> 01:09:16,930
- No, this is not a debugging feature,

01:09:16,930 --> 01:09:20,270
this is what you enable in all of your devices.

01:09:20,270 --> 01:09:23,530
- Well yeah, so don't pitch it that way.

01:09:24,560 --> 01:09:26,160
- Not at first.

01:09:26,160 --> 01:09:27,710
- Pitch it as a debugging tool.

01:09:34,250 --> 01:09:38,470
- One way to think about it is like advertising.

01:09:38,470 --> 01:09:40,840
If you pay for some service and you have advertising,

01:09:40,840 --> 01:09:45,190
you could have kind of a slight KASAN

01:09:45,190 --> 01:09:48,940
that gives you the product first, like the least cost or...

01:09:55,617 --> 01:09:57,784
- Okay, question way back.

01:09:58,840 --> 01:10:00,630
- Who's got a good arm?

01:10:00,630 --> 01:10:01,463
- I'll walk.

01:10:03,530 --> 01:10:08,505
I'll come half-way, here it comes.

01:10:08,505 --> 01:10:10,400
- I've got a couple of questions.

01:10:10,400 --> 01:10:13,860
One is, you talked about an allocation pool,

01:10:15,160 --> 01:10:20,160
what is the benefit of just having,

01:10:20,650 --> 01:10:22,030
the allocations come out of the pool?

01:10:22,030 --> 01:10:26,910
Is it just to stop it consuming

01:10:26,910 --> 01:10:29,130
an unlimited amount of memory?

01:10:29,130 --> 01:10:31,060
Is that the motivation for that idea?

01:10:32,990 --> 01:10:35,170
- It's not necessary.

01:10:35,170 --> 01:10:36,300
Yeah, it's not the only way.

01:10:36,300 --> 01:10:39,180
We can just call the page allocator.

01:10:39,180 --> 01:10:42,810
So the nice thing if they're allocated consequently,

01:10:42,810 --> 01:10:45,360
is that they share guard pages, because otherwise,

01:10:45,360 --> 01:10:50,360
you need three, and here you need two per object.

01:10:50,540 --> 01:10:52,200
I would expect in most contexts,

01:10:53,449 --> 01:10:54,970
having fixed memory overhead

01:10:54,970 --> 01:10:57,610
is a nice property for production.

01:10:57,610 --> 01:10:59,450
You can say like, this metric receives

01:10:59,450 --> 01:11:01,320
one megabyte at boot, that's it.

01:11:02,730 --> 01:11:04,350
Yeah, but this can be done perfectly

01:11:04,350 --> 01:11:07,540
with page allocator or virtual memory.

01:11:07,540 --> 01:11:12,030
- My other question was, is there a way

01:11:12,030 --> 01:11:16,520
that this could be made to work with the cache pools?

01:11:16,520 --> 01:11:18,580
So, a whole bunch of interesting allocations,

01:11:18,580 --> 01:11:20,420
are gonna to come out of cache pools,

01:11:20,420 --> 01:11:23,700
where we're not going to necessarily easily

01:11:23,700 --> 01:11:27,030
be able to pull it out of a different pool.

01:11:30,290 --> 01:11:31,760
- I don't have an answer to this.

01:11:31,760 --> 01:11:33,420
It depends if the code,

01:11:33,420 --> 01:11:36,040
like if you suddenly give an object

01:11:36,040 --> 01:11:39,690
from different memory range, will it break or...

01:11:40,820 --> 01:11:41,900
- Yeah, I'm not sure either.

01:11:41,900 --> 01:11:44,480
I haven't looked at the cache pool code, I just know--

01:11:44,480 --> 01:11:46,410
- Generally code should not care, right,

01:11:46,410 --> 01:11:50,180
it's just object in a different page.

01:11:50,180 --> 01:11:53,010
Rather than on the same slap page.

01:11:53,010 --> 01:11:54,410
So, probably it should work.

01:12:00,236 --> 01:12:03,736
(drowned out by coughing)

01:12:04,840 --> 01:12:05,880
- I don't know what you asked,

01:12:05,880 --> 01:12:07,580
I don't want to throw it randomly.

01:12:10,650 --> 01:12:12,720
- So, with cache pools the problem is that

01:12:12,720 --> 01:12:15,160
if you have to destroy the whole pool,

01:12:15,160 --> 01:12:18,350
you'll have to deal with all the alien objects as well.

01:12:18,350 --> 01:12:21,201
With slow-path you could probably do that,

01:12:21,201 --> 01:12:26,201
but still, if you get these alien objects

01:12:26,480 --> 01:12:29,220
on the free list maybe something will break.

01:12:33,604 --> 01:12:34,510
- Well, I think it should be possible

01:12:34,510 --> 01:12:36,130
to implement it so it doesn't break,

01:12:36,130 --> 01:12:38,310
because by that time our object should be freed.

01:12:38,310 --> 01:12:41,020
So let's say they're protected

01:12:42,170 --> 01:12:43,720
and just unprotect them later.

01:12:45,120 --> 01:12:47,650
So freeing the kmem cache should not,

01:12:48,490 --> 01:12:49,890
directly affect it, I think.

01:12:53,990 --> 01:12:57,070
- That's just another example of abstraction.

01:12:57,070 --> 01:12:59,960
It's just an abstraction on memory allocation.

01:12:59,960 --> 01:13:04,960
As long as you can implement that, it should be fine.

01:13:05,507 --> 01:13:10,507
To free up...

01:13:12,428 --> 01:13:14,990
The question that he asked, I agree with you,

01:13:14,990 --> 01:13:17,160
it's just a matter of having an abstraction layer,

01:13:17,160 --> 01:13:18,920
on top of the allocation.

01:13:18,920 --> 01:13:23,920
- Well yes, definitely overall it should be fixable,

01:13:24,020 --> 01:13:24,853
we can do this.

01:13:30,550 --> 01:13:32,020
Okay, thank you again.

01:13:32,020 --> 01:13:33,670
- Thank you very much.

01:13:33,670 --> 01:13:37,003
(participants clapping)

01:16:20,120 --> 01:16:22,760
- Potapenko, I'm gonna talk a little about,

01:16:22,760 --> 01:16:25,272
uninitialized memory in the Linux kernel.

01:16:25,272 --> 01:16:29,440
Two years ago I presented KernelMemorySanitizer,

01:16:29,440 --> 01:16:33,130
which is a tool to detect uses of uninitialized memory.

01:16:33,130 --> 01:16:36,470
Just to remind you, it contains a runtime library

01:16:36,470 --> 01:16:41,470
that maintains the metadata, the state of every bit,

01:16:42,110 --> 01:16:45,720
in the kernel whether it's initialized or not.

01:16:45,720 --> 01:16:49,240
And we also use Clang instrumentation to propagate

01:16:49,240 --> 01:16:50,620
this uninitialized data

01:16:52,677 --> 01:16:56,530
and detect users of uninitialized data in conditions,

01:16:56,530 --> 01:16:58,930
pointer dereferencing and if the init

01:16:58,930 --> 01:17:01,950
is copied to user space or hardware, whatever,

01:17:01,950 --> 01:17:04,280
then we're also reporting this as an error.

01:17:06,070 --> 01:17:11,070
So since then, Sasha has removed kmemcheck

01:17:11,340 --> 01:17:14,902
from the kernel but KMSAN isn't there yet.

01:17:14,902 --> 01:17:18,720
The last 20% of the work took a little longer,

01:17:18,720 --> 01:17:20,590
than I expected.

01:17:20,590 --> 01:17:24,390
Right now the kernel supports Clang builds

01:17:24,390 --> 01:17:28,390
and Clang itself supports KMSAN

01:17:28,390 --> 01:17:30,720
as stabilized compiler interfaces

01:17:30,720 --> 01:17:33,270
and have done quite a bit of work

01:17:33,270 --> 01:17:37,870
in the shadow memory layout getting all the crashes,

01:17:37,870 --> 01:17:40,420
adding some interesting features,

01:17:40,420 --> 01:17:42,120
but there's still some work to do.

01:17:43,330 --> 01:17:46,710
So right now we're fully integrated with syzkaller.

01:17:46,710 --> 01:17:48,400
All the new reports are pre-moderated

01:17:48,400 --> 01:17:50,940
which means we only report true positives

01:17:50,940 --> 01:17:53,150
to the upstream developers

01:17:53,150 --> 01:17:57,120
unless people at Google beat us at fixing them.

01:17:57,120 --> 01:17:59,990
Like Eric did for maybe half of the reports

01:17:59,990 --> 01:18:01,150
that KMSAN found.

01:18:02,460 --> 01:18:06,050
We found around 150 reports so far.

01:18:06,050 --> 01:18:08,520
The code is at github and I'm trying

01:18:08,520 --> 01:18:10,750
to revise it at least once a month.

01:18:11,700 --> 01:18:13,590
So, still not upstream.

01:18:14,893 --> 01:18:16,230
A fun fact is that NetBSD,

01:18:16,230 --> 01:18:18,420
has a working KMSAN implementation.

01:18:19,270 --> 01:18:24,270
It turned out to be really easy.

01:18:24,533 --> 01:18:29,533
I've put up a Gerrit code review for KMSAN,

01:18:29,720 --> 01:18:31,850
I just need more eyes on it

01:18:31,850 --> 01:18:34,470
because it's a big chunk of code.

01:18:35,520 --> 01:18:37,750
Most certainly there are ways

01:18:37,750 --> 01:18:41,120
to do the things I'm doing a lot easier.

01:18:41,120 --> 01:18:43,240
Like organizing the shadow memory

01:18:43,240 --> 01:18:46,170
or interacting with printk and kmalloc locks.

01:18:46,170 --> 01:18:48,750
There is a lot of opportunities to deadlock

01:18:48,750 --> 01:18:51,200
and a lot of debug configs are also broken

01:18:51,200 --> 01:18:56,200
for the same reason 'cause we get into deadlocks.

01:18:56,500 --> 01:19:01,500
And we may also benefit from subsystem maintainers,

01:19:02,830 --> 01:19:05,550
domain specific knowledge about where we want

01:19:05,550 --> 01:19:09,630
to put our checks for our initialized memory.

01:19:09,630 --> 01:19:12,450
Maybe DMA devices and file I/O or whatever.

01:19:14,660 --> 01:19:18,480
So, I wanted to shock you with some CVE information here,

01:19:18,480 --> 01:19:21,070
but it turns out no one is really,

01:19:21,070 --> 01:19:23,400
filing CVEs for initialized memory.

01:19:24,380 --> 01:19:27,280
We have some syzbot stats for the past two years.

01:19:29,170 --> 01:19:31,080
Right now there are 42 open bugs

01:19:31,080 --> 01:19:36,080
and 108 fixed bugs, of which there is 21 information leak.

01:19:36,770 --> 01:19:39,330
Two of them to the USB subsystem.

01:19:39,330 --> 01:19:42,330
There were five KVM bugs and most of the bugs,

01:19:42,330 --> 01:19:44,280
are in the network subsystem just

01:19:44,280 --> 01:19:48,880
because syzbot is really good at finding those.

01:19:51,760 --> 01:19:55,200
The top antipatterns are copying some...

01:19:55,200 --> 01:19:56,033
Yeah.

01:20:00,940 --> 01:20:02,560
- Previous slide you said,

01:20:02,560 --> 01:20:06,420
there aren't very many CVEs being requested.

01:20:06,420 --> 01:20:09,280
I guess with the information leaks you should have CVEs.

01:20:10,270 --> 01:20:14,010
- Well, yeah, no, we try not

01:20:14,010 --> 01:20:15,800
to request CVEs for kernel stuff.

01:20:20,910 --> 01:20:22,660
- So some distros and some companies do it

01:20:22,660 --> 01:20:24,800
so that the patch will actually be back ported

01:20:24,800 --> 01:20:28,500
so it's more like a way to pressure the management

01:20:28,500 --> 01:20:31,330
to make them dedicate resources for back porting stuff,

01:20:31,330 --> 01:20:33,450
and we're trying not to fall into that.

01:20:33,450 --> 01:20:35,880
There's really no clear policy

01:20:35,880 --> 01:20:38,250
of requesting CVEs for kernel stuff.

01:20:39,470 --> 01:20:41,350
Greg is working on an alternative,

01:20:41,350 --> 01:20:43,080
hopefully towards the end of the year,

01:20:43,080 --> 01:20:45,630
but we don't want to dig ourselves into the CVE.

01:20:45,630 --> 01:20:47,810
Just for example, people start requesting CVEs

01:20:47,810 --> 01:20:50,160
for stuff that are just jokes and it's hard to go back

01:20:50,160 --> 01:20:52,830
and revoke them and it's just a whole mess

01:20:52,830 --> 01:20:54,730
and it doesn't work well for a kernel.

01:20:55,800 --> 01:20:56,633
Not a thing.

01:20:59,270 --> 01:21:00,990
- You said you're feeling good about,

01:21:00,990 --> 01:21:03,890
memory corruptions and use of the frees and out of bounds.

01:21:05,380 --> 01:21:08,501
So if you can allocate about ten people full time,

01:21:08,501 --> 01:21:11,220
doing this, full security assessment

01:21:11,220 --> 01:21:13,120
and all of this trash and filing CVEs,

01:21:14,269 --> 01:21:15,260
then you're welcome to do so.

01:21:17,036 --> 01:21:17,869
And this will be no, this will not increase

01:21:17,869 --> 01:21:19,730
number of bugs, number of bug fixes,

01:21:19,730 --> 01:21:23,770
just the keeping track of things and filing CVEs.

01:21:25,040 --> 01:21:26,740
- And that keeping track of things

01:21:27,657 --> 01:21:28,810
is actually fairly important.

01:21:28,810 --> 01:21:30,210
- Is it incredibly important

01:21:30,210 --> 01:21:32,380
so your employer would allocate ten people?

01:21:37,025 --> 01:21:39,923
So for that answer is that, it's not that important.

01:21:41,440 --> 01:21:42,273
Unfortunately.

01:21:43,853 --> 01:21:46,060
- The problem is that one needs to do some analysis

01:21:46,060 --> 01:21:48,620
of whether the bug is exploitable,

01:21:48,620 --> 01:21:53,061
whether it's interesting for the developers.

01:21:53,061 --> 01:21:56,510
And actually we're finding the bugs earlier,

01:21:56,510 --> 01:21:58,840
than they hit in the distros.

01:21:58,840 --> 01:22:00,430
Some of the bugs, at least.

01:22:00,430 --> 01:22:04,850
So maybe we should invest in earlier testing

01:22:04,850 --> 01:22:07,330
and earlier detection of those bugs,

01:22:07,330 --> 01:22:10,370
instead of investing into CVEs.

01:22:15,360 --> 01:22:19,180
- So I guess the question that I should ask is,

01:22:20,260 --> 01:22:23,110
how often are you finding bugs

01:22:23,110 --> 01:22:27,270
in pre-released code versus already released code?

01:22:28,130 --> 01:22:30,610
- Well I can get to it in a moment.

01:22:32,870 --> 01:22:35,910
So here are the top antipatterns.

01:22:37,010 --> 01:22:39,660
A lot of people like copying things like,

01:22:39,660 --> 01:22:42,110
struct sockadddr from the user space

01:22:43,030 --> 01:22:47,690
but it can be shorter than expected

01:22:47,690 --> 01:22:50,660
and then some of the fields get uninitialized

01:22:50,660 --> 01:22:53,580
and people treat them as a whole subcategory.

01:22:55,150 --> 01:22:57,570
The most common one is just allocating a structure

01:22:57,570 --> 01:23:00,361
and forgetting to fill something

01:23:00,361 --> 01:23:01,700
and copy it into the user space.

01:23:01,700 --> 01:23:03,200
This also includes the padding

01:23:04,432 --> 01:23:08,040
'cause padding always contains some uninitialized data.

01:23:09,092 --> 01:23:13,770
A lot of people do not check for reading from USB devices,

01:23:13,770 --> 01:23:16,060
whether the read succeeds or not.

01:23:16,060 --> 01:23:18,650
So this also leaves uninitialized data.

01:23:21,110 --> 01:23:25,210
This graph can give you an idea about the bug lifetime.

01:23:25,210 --> 01:23:30,210
We only have this many bugfixes with the fixes tags

01:23:31,770 --> 01:23:34,720
but there are some really old reports

01:23:34,720 --> 01:23:39,100
and there are also a lot of newly introduced bugs.

01:23:39,100 --> 01:23:43,550
So we sometimes see the bugs being reintroduced

01:23:44,388 --> 01:23:49,330
or we sometimes see the bugs in very fresh code.

01:23:52,180 --> 01:23:54,250
- What was the average lifetime?

01:23:57,468 --> 01:24:00,120
Sorry, let me rephrase, when was the 2005 bug fixed,

01:24:00,120 --> 01:24:02,000
2017 or 2019?

01:24:03,390 --> 01:24:05,190
- Doesn't really matter.

01:24:05,190 --> 01:24:08,300
It's like two years versus ten years.

01:24:10,680 --> 01:24:11,880
I don't really remember.

01:24:13,100 --> 01:24:14,050
I can look that up.

01:24:18,400 --> 01:24:20,500
Most of the bugs are still there.

01:24:22,280 --> 01:24:25,000
Right now syzbot only covers maybe 11%

01:24:25,000 --> 01:24:28,410
of the x86 kernel code and most

01:24:28,410 --> 01:24:31,650
of the attack vectors are not covered.

01:24:31,650 --> 01:24:34,710
So I expect, for example, the remaining networking code

01:24:34,710 --> 01:24:38,620
to have maybe 200s of bugs that we haven't seen.

01:24:39,910 --> 01:24:42,523
Most certainly the wireless stack

01:24:42,523 --> 01:24:45,140
has a real information leak,

01:24:45,140 --> 01:24:47,700
so don't require any local code to be run.

01:24:50,700 --> 01:24:54,850
So what do we do with all those bugs piling up?

01:24:54,850 --> 01:24:58,400
Although initializing everything sounds a bit crazy,

01:24:58,400 --> 01:25:02,100
this is probably doable and at least we can try to do that.

01:25:04,790 --> 01:25:06,510
This serves two purposes,

01:25:06,510 --> 01:25:10,480
first we kill all the information leaks, if we initialize

01:25:10,480 --> 01:25:13,290
with zero there is nothing to leak.

01:25:13,290 --> 01:25:17,900
And if any code depends on uninitialized data,

01:25:17,900 --> 01:25:21,860
then it will execute deterministically.

01:25:21,860 --> 01:25:24,150
By the way, Microsoft has started experimenting

01:25:24,150 --> 01:25:27,130
with this already and it ships kernels

01:25:27,130 --> 01:25:30,100
with initialized PODs since last year.

01:25:32,300 --> 01:25:36,730
So for local variables there is a bunch of kernel configs

01:25:36,730 --> 01:25:41,730
that Case Cook has handily put up under a common umbrella.

01:25:44,400 --> 01:25:47,460
And the most interesting one is init_stack_all,

01:25:47,460 --> 01:25:50,420
which is right now only available in Clang.

01:25:50,420 --> 01:25:53,780
This is something that we want to change in the future,

01:25:54,740 --> 01:25:56,790
and Linus also wants this to change.

01:25:58,960 --> 01:26:02,900
So, any takers for just to see who will be willing to help?

01:26:06,410 --> 01:26:09,090
We made some performance measurements

01:26:09,090 --> 01:26:12,080
of initializing of the local data.

01:26:13,870 --> 01:26:17,550
There are pretty good results but also some outliers.

01:26:19,419 --> 01:26:22,050
And I want to emphasize that benchmarking is hard

01:26:22,050 --> 01:26:26,690
and for example the netperf can perform quite good,

01:26:26,690 --> 01:26:30,580
but it doesn't show you how the rest of the kernel,

01:26:30,580 --> 01:26:35,580
how the user space applications work with this mitigation.

01:26:36,920 --> 01:26:38,910
And on the other hand there are some

01:26:38,910 --> 01:26:43,383
Android benchmarks for example, for which we see

01:26:45,270 --> 01:26:48,620
a very big variance because it's just hard

01:26:48,620 --> 01:26:50,680
to write a reliable benchmark.

01:26:51,550 --> 01:26:54,910
Ideas on how to benchmark the whole system

01:26:54,910 --> 01:26:55,810
are still welcome.

01:27:00,360 --> 01:27:03,470
- So you have a line for 0xAA initialization

01:27:03,470 --> 01:27:06,420
and line for 0x00 initialization.

01:27:06,420 --> 01:27:08,630
Why would the value make a difference,

01:27:08,630 --> 01:27:09,960
in terms of performance?

01:27:09,960 --> 01:27:14,670
- Okay, so there are two options right now.

01:27:14,670 --> 01:27:19,670
We only use this one, the initialization with 0xAA

01:27:20,300 --> 01:27:24,550
because the other one is hidden behind a Clang flag

01:27:24,550 --> 01:27:29,490
with a really heavy name that no one wants to use.

01:27:29,490 --> 01:27:32,210
The difference is that obviously,

01:27:32,210 --> 01:27:37,090
it's easier to encode a zero constant in ARM and x86.

01:27:37,942 --> 01:27:40,692
For example ARM has a dedicated zero register for that.

01:27:42,020 --> 01:27:44,450
- In the case of zero, do you pre-allocate all memory,

01:27:44,450 --> 01:27:47,760
fully zeroed out or only specific fields are zeroed out.

01:27:47,760 --> 01:27:51,100
- That's about the stack, so we insert some code

01:27:51,100 --> 01:27:56,100
that initializes all the stack objects

01:27:56,690 --> 01:27:58,390
at the beginning of every function

01:27:59,500 --> 01:28:04,160
and of course we take advantage

01:28:04,160 --> 01:28:08,030
of the dead store elimination but Clang is very bad at it

01:28:08,030 --> 01:28:13,030
so there is a lot of opportunities to improve the speed up

01:28:13,600 --> 01:28:17,190
and we are already doing something to fix that.

01:28:20,360 --> 01:28:24,699
So another thing that's landing in 5.3 already

01:28:24,699 --> 01:28:29,699
is the init_on_alloc and init_on_free boot time options.

01:28:30,340 --> 01:28:33,530
They're basically initializing, zero initializing,

01:28:33,530 --> 01:28:37,610
all the allocated or all the freed memory objects

01:28:37,610 --> 01:28:40,960
in page_alloc and in the heap.

01:28:40,960 --> 01:28:45,160
The difference is small so init_on_alloc

01:28:45,160 --> 01:28:48,400
is the more cache friendly and init_on_free

01:28:48,400 --> 01:28:51,740
minimizes the lifetime of the sensitive data.

01:28:51,740 --> 01:28:55,590
This is somewhat similar to PAX_MEMORY_SANITIZE.

01:28:55,590 --> 01:28:59,710
But PAX_MEMORY_SANITIZE disables initialization

01:28:59,710 --> 01:29:02,360
for certain memory caches and we don't know,

01:29:02,360 --> 01:29:05,340
whether it's good or bad for performance

01:29:05,340 --> 01:29:07,640
and for security so we haven't tried this yet.

01:29:09,690 --> 01:29:14,129
And I also believe that we're a little faster

01:29:14,129 --> 01:29:15,929
than PAX_MEMORY_SANITIZE, maybe not.

01:29:18,550 --> 01:29:21,070
So here are the performance costs.

01:29:21,070 --> 01:29:22,580
Initializing all the heap objects

01:29:22,580 --> 01:29:27,580
is obviously more costly than for the stack,

01:29:27,580 --> 01:29:31,382
but still we can choose to skip some,

01:29:31,382 --> 01:29:33,820
certain memory caches for example.

01:29:35,440 --> 01:29:37,210
We just need a better understanding

01:29:37,210 --> 01:29:39,330
of which workflows are important

01:29:40,224 --> 01:29:44,223
and which one we can trade security for speed.

01:29:46,130 --> 01:29:48,560
So here is another quote by Linus

01:29:48,560 --> 01:29:50,330
regarding heap initialization.

01:29:51,630 --> 01:29:52,463
Enough said.

01:29:53,860 --> 01:29:55,500
So that's basically it.

01:29:57,470 --> 01:29:58,910
Thank you for your attention.

01:30:00,754 --> 01:30:04,087
(participants clapping)

01:30:05,200 --> 01:30:08,570
- Hello, it's me again and I wanted to give a short update,

01:30:08,570 --> 01:30:11,870
on various things related to syzkaller and sysbot

01:30:11,870 --> 01:30:13,370
that happened since last year.

01:30:14,660 --> 01:30:17,480
So syzkaller is the present system kernel fuzzer

01:30:17,480 --> 01:30:20,280
that is coverage guided, input structure aware,

01:30:20,280 --> 01:30:24,050
multiple operating system, it was focused on automation

01:30:24,050 --> 01:30:27,250
and then syzbot is the automation on top of syzkaller

01:30:27,250 --> 01:30:29,610
which can do continuous kernel build

01:30:29,610 --> 01:30:32,622
and that does bug reporting, bug tracking

01:30:32,622 --> 01:30:33,590
and has web dashboard.

01:30:35,480 --> 01:30:39,687
So far it reported about 2,300 bugs

01:30:41,070 --> 01:30:44,970
and of which 1,500 are fixed

01:30:44,970 --> 01:30:48,980
and approximately 750 are still open

01:30:48,980 --> 01:30:51,050
and when I looked several weeks ago,

01:30:51,050 --> 01:30:55,580
fixed bugs were precisely two-thirds of the reported bugs

01:30:56,458 --> 01:30:57,980
so it makes it three bugs per day,

01:30:57,980 --> 01:30:59,830
two of which are fixed for two years.

01:31:01,630 --> 01:31:03,980
And some people ask, "Is it getting better?"

01:31:03,980 --> 01:31:05,860
"Is there any positive dynamics?"

01:31:05,860 --> 01:31:09,590
On the graph you can see number of bugs reported per month

01:31:09,590 --> 01:31:13,020
for the last year and on the graph you can see,

01:31:13,020 --> 01:31:14,933
actually I'm not sure what you can see.

01:31:14,933 --> 01:31:16,670
There's nothing.

01:31:16,670 --> 01:31:18,590
I can't say that there are any dynamics.

01:31:18,590 --> 01:31:21,930
The spikes are probably related to either merge windows

01:31:21,930 --> 01:31:24,640
or that we deployed some bug finding capabilities.

01:31:25,480 --> 01:31:27,080
But no, it's not getting better.

01:31:28,790 --> 01:31:31,020
And there's still lots of open bugs

01:31:31,020 --> 01:31:33,810
and bed bugs, bugs as reproducers,

01:31:33,810 --> 01:31:36,350
bugs that still happen that were reported,

01:31:36,350 --> 01:31:37,700
a year ago or more.

01:31:40,660 --> 01:31:42,300
So what happened?

01:31:42,300 --> 01:31:44,250
So first of all, we deployed kmemleak.

01:31:44,250 --> 01:31:46,220
Kmemleak finds memory leaks.

01:31:48,150 --> 01:31:51,330
In three months it found 82 leaks,

01:31:51,330 --> 01:31:53,260
44 of which are now fixed.

01:31:54,380 --> 01:31:56,700
And we had some challenges, so first of all,

01:31:56,700 --> 01:32:00,190
kmemleak is slow because it scans all of the memory

01:32:01,200 --> 01:32:03,630
and it also has some false positives.

01:32:03,630 --> 01:32:05,350
Maybe it related the fact

01:32:05,350 --> 01:32:08,170
that it doesn't do atomic scan maybe it's something else,

01:32:08,170 --> 01:32:09,720
nobody actually looked.

01:32:09,720 --> 01:32:11,480
And some of the reports are very frequent

01:32:11,480 --> 01:32:14,390
and some of them seem to be false positives.

01:32:15,420 --> 01:32:16,640
And also there is a question

01:32:16,640 --> 01:32:20,420
of how do you provide reproducers to developers

01:32:20,420 --> 01:32:22,380
because memory leaks are completely silent.

01:32:22,380 --> 01:32:24,510
It's not like you get some splash

01:32:24,510 --> 01:32:25,910
on the console or something.

01:32:31,170 --> 01:32:32,580
So what do we do?

01:32:32,580 --> 01:32:36,300
First of all, we do a scan only after a batch of tests.

01:32:36,300 --> 01:32:39,150
We run several tests and then run scanning

01:32:39,150 --> 01:32:42,610
and if there is any leak then we try to understand

01:32:42,610 --> 01:32:45,260
which of the tests actually caused the memory leak

01:32:45,260 --> 01:32:47,280
so this makes it a bit faster.

01:32:48,530 --> 01:32:52,050
Then we report memory leaks only if they're reproducible.

01:32:52,050 --> 01:32:54,240
So this is not true for other types of bugs

01:32:54,240 --> 01:32:55,790
but for leaks what you get

01:32:55,790 --> 01:32:59,290
is only get one stacktrace which is the allocation stack,

01:32:59,290 --> 01:33:01,870
so it's even the stack where the object

01:33:01,870 --> 01:33:03,300
was forgotten to be freed.

01:33:05,520 --> 01:33:10,050
So it may not be very actionable without a reproducer.

01:33:10,050 --> 01:33:13,520
Then we have scanning and the code that talks to kmemleakm

01:33:13,520 --> 01:33:17,140
but in the C reproducer so you can actually run them

01:33:17,140 --> 01:33:21,020
and see the kmemleak report and you can, say, test your fix.

01:33:22,740 --> 01:33:25,800
And then, so how the syzkaller was designed,

01:33:26,760 --> 01:33:28,930
if it hits any crash, any bug,

01:33:28,930 --> 01:33:32,610
then it immediately kills the machine and reboots it.

01:33:32,610 --> 01:33:35,450
So it always works on a clean, on a good state.

01:33:36,520 --> 01:33:40,340
And this doesn't work well with frequent bugs,

01:33:40,340 --> 01:33:42,340
especially with false positives.

01:33:42,340 --> 01:33:45,060
So what we do if we hit a particular leak,

01:33:45,060 --> 01:33:48,030
we again kill the machine this time, reboot it,

01:33:48,030 --> 01:33:50,870
but we later, in the later runs

01:33:50,870 --> 01:33:53,260
we start ignoring this particular leak.

01:33:53,260 --> 01:33:55,900
So the idea is that we've hit all of the

01:33:55,900 --> 01:33:57,800
frequent one initially and then later

01:33:57,800 --> 01:34:02,690
we start discovering the more interesting ones.

01:34:04,450 --> 01:34:05,840
And for the scanning we had

01:34:05,840 --> 01:34:09,780
to do a quite tricky dance to fight false positives.

01:34:09,780 --> 01:34:11,820
So what we do, it will scan and then it will sleep

01:34:11,820 --> 01:34:14,980
for four seconds, then we scan again.

01:34:14,980 --> 01:34:16,990
Then if we see leaks at that point,

01:34:16,990 --> 01:34:19,320
we sleep for one more second, then scan again.

01:34:20,180 --> 01:34:24,100
And this tends to reduce false positive rate

01:34:24,100 --> 01:34:26,090
and there's actually some science behind this.

01:34:26,090 --> 01:34:29,520
So each of the sleeps and the scans is kind

01:34:29,520 --> 01:34:32,580
of tied to what the kmemleak does and how it works.

01:34:35,630 --> 01:34:38,040
Yes and all testing should use kmemleak

01:34:38,040 --> 01:34:39,720
because some people have been saying that leaks

01:34:39,720 --> 01:34:42,320
are the worst kernel bugs, especially for servers

01:34:42,320 --> 01:34:45,870
because they just slowly drain capacity

01:34:45,870 --> 01:34:49,190
of your servers completely silently.

01:34:49,190 --> 01:34:50,023
Nothing happens.

01:34:52,630 --> 01:34:56,880
Yeah, the next thing is called systematic fault injection.

01:34:56,880 --> 01:34:59,780
So we have a special mode to fault injection

01:35:01,170 --> 01:35:02,830
which works as follows.

01:35:02,830 --> 01:35:05,880
We have a per thread, per task file

01:35:05,880 --> 01:35:09,084
and you can write a particular number to that file.

01:35:09,084 --> 01:35:10,750
So you write three and what this does

01:35:10,750 --> 01:35:14,690
is this will fault the third allocation,

01:35:14,690 --> 01:35:17,430
third fault site in this thread

01:35:19,510 --> 01:35:22,150
after you write this number in this particular task.

01:35:23,050 --> 01:35:25,170
And then you can read from that file

01:35:25,170 --> 01:35:27,170
to understand if the fault was injected.

01:35:28,044 --> 01:35:32,010
If the task has reached that third fault site

01:35:33,160 --> 01:35:35,260
or it hasn't reached it yet.

01:35:36,720 --> 01:35:38,690
And what you can do is this.

01:35:38,690 --> 01:35:40,060
You do the following, so let's say

01:35:40,060 --> 01:35:41,860
that I have a system code.

01:35:41,860 --> 01:35:45,210
First of all you inject failure into the first full site,

01:35:45,210 --> 01:35:46,350
say first kmalloc.

01:35:48,560 --> 01:35:51,650
Then next time you execute the same test

01:35:51,650 --> 01:35:55,000
and you inject the fault into the second fault site.

01:35:55,000 --> 01:35:58,000
Then into third and so on until you reach the state

01:35:58,000 --> 01:36:00,330
when the fault wasn't injected.

01:36:00,330 --> 01:36:01,450
So at that point you know

01:36:01,450 --> 01:36:04,240
that you tried all the fault sites one by one

01:36:04,240 --> 01:36:07,780
and now you kind of tested all of them.

01:36:09,920 --> 01:36:13,490
So the traditional mode was kind of randomized.

01:36:13,490 --> 01:36:16,450
So you just fail X percent of mallocs a

01:36:16,450 --> 01:36:20,350
and this doesn't necessarily test all of the sites

01:36:20,350 --> 01:36:23,510
and it requires running the test for a long time

01:36:23,510 --> 01:36:27,900
and this mode allows the test to fail each site once

01:36:27,900 --> 01:36:29,930
with the minimum number of tests.

01:36:29,930 --> 01:36:30,980
Which is pretty cool.

01:36:34,110 --> 01:36:36,560
All of the tests should also use fault injection.

01:36:38,170 --> 01:36:41,020
And this is particularly useful with kmemleak especially

01:36:41,020 --> 01:36:44,770
because most common bugs in the error handling bus,

01:36:44,770 --> 01:36:47,440
are double frees and memory leaks.

01:36:47,440 --> 01:36:49,570
And I think it should be possible with speedtrace

01:36:49,570 --> 01:36:52,910
for in the testing context so say you run a test,

01:36:52,910 --> 01:36:56,647
you check the exit status and it's zero

01:36:56,647 --> 01:36:59,410
so the test succeeded and then you run the same test

01:36:59,410 --> 01:37:03,380
with this fault injection mode using say, btrace

01:37:03,380 --> 01:37:07,200
and you systematically fail each malloc,

01:37:07,200 --> 01:37:09,200
in each of the system calls in the test.

01:37:10,690 --> 01:37:13,737
Right but in this mode you'd know the exit status

01:37:13,737 --> 01:37:15,110
because the test will probably fail but it doesn't matter,

01:37:15,110 --> 01:37:17,060
we're just looking for the kernel bugs.

01:37:17,970 --> 01:37:21,300
Yes and if the kernel code is kind

01:37:21,300 --> 01:37:26,190
of poorly tested and error paths are just virgin lands.

01:37:27,720 --> 01:37:31,160
I'm not sure what testing they got, if at all.

01:37:34,790 --> 01:37:37,870
So the next tool was KMSAN was already mentioned.

01:37:37,870 --> 01:37:39,740
It detects uses of uninitialized values.

01:37:39,740 --> 01:37:44,740
It found about 220 bugs at this point, 100 is fixed.

01:37:44,880 --> 01:37:47,510
And we're finding infoleaks to the user space,

01:37:47,510 --> 01:37:51,350
including say, 100 bytes infoleak in the wait system poll

01:37:51,350 --> 01:37:53,930
which is reachable by any user

01:37:53,930 --> 01:37:57,260
for infoleaks to the USB cables

01:37:57,260 --> 01:38:00,330
or use of initialized values in the networking pass

01:38:00,330 --> 01:38:01,680
or in the security modules.

01:38:05,520 --> 01:38:07,690
Then we started doing USB fuzzing.

01:38:07,690 --> 01:38:09,490
And the idea is to stress the kernel

01:38:10,342 --> 01:38:13,320
from the external side, from the side of the USB cable.

01:38:13,320 --> 01:38:15,683
Actually from both sides so the same test,

01:38:15,683 --> 01:38:19,620
can both kind of do the external workload

01:38:19,620 --> 01:38:22,310
and call some of my autos, so actually

01:38:22,310 --> 01:38:23,980
stress kernel from both sides.

01:38:25,900 --> 01:38:28,850
For this we added a special debugger fuzz interface

01:38:28,850 --> 01:38:32,130
which kind of allows us to inject USB packets

01:38:32,130 --> 01:38:34,470
in a way that is suitable for fuzzing.

01:38:36,370 --> 01:38:39,860
And so far we've found about 250 bugs, 100 is fixed

01:38:39,860 --> 01:38:43,350
but we know that we're just barely scratching the surface

01:38:43,350 --> 01:38:48,350
because just for the USB IDs we have 8,400 of them

01:38:48,630 --> 01:38:51,740
and their interfaces are generic interfaces.

01:38:51,740 --> 01:38:54,570
There are also interfaces per device class

01:38:54,570 --> 01:38:57,160
and there are interfaces per device driver.

01:38:58,195 --> 01:39:00,327
So there's just tremendous amounts of--

01:39:00,327 --> 01:39:02,170
- Do you actually need an external USB device to test it,

01:39:02,170 --> 01:39:03,360
or can you just emulate one?

01:39:03,360 --> 01:39:04,520
Is there software?

01:39:04,520 --> 01:39:05,950
- This is all emulated and stuff

01:39:05,950 --> 01:39:08,910
using this debugger fuzz interface.

01:39:08,910 --> 01:39:10,890
Yes, it's all driven from a test basically.

01:39:10,890 --> 01:39:12,540
It will write the particular file

01:39:13,415 --> 01:39:15,000
or packet and it's injected.

01:39:15,000 --> 01:39:19,910
It's just like a tuning device for USB.

01:39:19,910 --> 01:39:22,320
And then we deployed bisection which is, "Yay!"

01:39:22,320 --> 01:39:23,610
Lots of people asked for it

01:39:23,610 --> 01:39:26,810
but unfortunately the success rate is about 50%

01:39:28,010 --> 01:39:30,540
and when I worked in the bisection,

01:39:30,540 --> 01:39:33,430
I discovered lots of interesting things.

01:39:33,430 --> 01:39:36,000
So going back in time is where I'm using.

01:39:36,000 --> 01:39:39,110
So first of all your compiler starts breaking,

01:39:39,110 --> 01:39:40,690
then you take an older one,

01:39:40,690 --> 01:39:42,680
it's also start breaking with something,

01:39:42,680 --> 01:39:45,570
then the other one breaks as well.

01:39:45,570 --> 01:39:47,220
At some point your perl breaks.

01:39:47,220 --> 01:39:49,110
At some point your make breaks.

01:39:49,110 --> 01:39:52,770
At some point your binutils break.

01:39:52,770 --> 01:39:55,020
At some point there were no olddefconfig

01:39:55,020 --> 01:39:57,900
so if you natively used it in your bisection screen,

01:39:57,900 --> 01:39:59,130
sorry it doesn't exist.

01:40:01,480 --> 01:40:03,310
Yes and it's not that you can just,

01:40:03,310 --> 01:40:05,420
take the older versions and they will

01:40:05,420 --> 01:40:06,990
be the new kernel of this.

01:40:06,990 --> 01:40:09,350
So what you need is for each tool,

01:40:09,350 --> 01:40:12,050
you need kind of some range of kernels

01:40:12,914 --> 01:40:14,610
where this particular version works,

01:40:14,610 --> 01:40:18,780
and then you need to combine like right version of gcc make,

01:40:18,780 --> 01:40:23,350
perl, binutils to kind of to something

01:40:23,350 --> 01:40:25,250
to build this particular version.

01:40:25,250 --> 01:40:26,420
And obviously this will not work

01:40:26,420 --> 01:40:28,390
with just any glibc as well.

01:40:28,390 --> 01:40:30,270
- So maybe an option for that is to use something like

01:40:30,270 --> 01:40:32,840
yocto which sort of builds its own environment.

01:40:32,840 --> 01:40:34,770
And you can go back in time with yocto

01:40:34,770 --> 01:40:38,500
to like sort of junk all the kernels with that.

01:40:38,500 --> 01:40:40,510
'Cause it does build everything like

01:40:40,510 --> 01:40:43,340
all the dependencies and it did work back at the time.

01:40:44,760 --> 01:40:46,470
- Have you tried it?

01:40:46,470 --> 01:40:49,730
- Not for this purpose, but I mean,

01:40:49,730 --> 01:40:51,350
I don't see why it wouldn't work

01:40:51,350 --> 01:40:53,890
because it does build gcc, it builds perl,

01:40:53,890 --> 01:40:57,140
it builds all of that to work with the--

01:40:57,140 --> 01:41:00,400
- For now actually, we stopped at a pretty recent

01:41:00,400 --> 01:41:05,260
gcc version, which is 4.1 because of those reasons

01:41:05,260 --> 01:41:07,700
and a number of other reasons as well.

01:41:07,700 --> 01:41:10,520
So and for that we just need three gcc versions,

01:41:10,520 --> 01:41:15,520
so we just switch the gccs again, according to some ranges.

01:41:17,460 --> 01:41:21,680
Then as we go back, say there's no KASAN, no LOCKDEP

01:41:21,680 --> 01:41:24,620
or KASAN loses some of its abilities.

01:41:24,620 --> 01:41:26,700
So you're tracking KASAN back,

01:41:26,700 --> 01:41:29,940
like you can bisect it to basically

01:41:29,940 --> 01:41:34,460
addition of KASAN for example.

01:41:34,460 --> 01:41:38,830
And then we see lots of build breakages, boot breakages

01:41:38,830 --> 01:41:41,900
and runtime breakages, even under release stacks.

01:41:41,900 --> 01:41:44,500
So what we do first of all, we check the releases

01:41:45,620 --> 01:41:47,850
to find the initial range for bisection

01:41:47,850 --> 01:41:49,790
and it happens that lots of them actually,

01:41:49,790 --> 01:41:51,610
build broken or boot broken.

01:41:53,560 --> 01:41:54,520
So what we have to do,

01:41:54,520 --> 01:41:56,680
we have to as we go back on a particular release,

01:41:56,680 --> 01:41:59,053
we have to disable particular config

01:41:59,053 --> 01:42:00,880
and we have lots of those rules,

01:42:00,880 --> 01:42:03,030
just to fix major breakages

01:42:03,030 --> 01:42:05,250
because otherwise there's just no way,

01:42:05,250 --> 01:42:09,330
you can do any bisection beyond that release.

01:42:09,330 --> 01:42:12,340
It actually starts from very recent kernels.

01:42:13,670 --> 01:42:18,420
So when we deployed and started reporting results,

01:42:18,420 --> 01:42:21,360
people started complaining and so I had

01:42:21,360 --> 01:42:23,790
to analyze kind of initial results,

01:42:23,790 --> 01:42:25,460
just to understand what happens,

01:42:26,348 --> 01:42:28,100
whether the root causes if we can do anything.

01:42:28,100 --> 01:42:31,040
So analyzed looked at 118 bisections.

01:42:32,280 --> 01:42:35,020
As I said, success rate was about 50%.

01:42:35,970 --> 01:42:40,050
And it turned out that 46% of those were affected

01:42:40,050 --> 01:42:42,700
by the fact that the bug is racy, flaky

01:42:42,700 --> 01:42:44,410
or hard to reproduce.

01:42:44,410 --> 01:42:45,700
And the thing with bisection is

01:42:45,700 --> 01:42:48,400
that if you need to answer yes or no 15 times

01:42:48,400 --> 01:42:50,560
and if you answer it once wrong,

01:42:50,560 --> 01:42:52,360
like everything is totally wrong.

01:42:52,360 --> 01:42:55,270
It's not that you can be like 90% correct.

01:42:55,270 --> 01:42:58,650
You're either 100% or you are 0% correct.

01:43:00,610 --> 01:43:02,840
Also actually, this is the major cause,

01:43:02,840 --> 01:43:05,750
66% were affected by the other bugs.

01:43:05,750 --> 01:43:09,660
So we're just chasing one bug but then we hit another one.

01:43:09,660 --> 01:43:12,434
It's not, some people asked like if you can say,

01:43:12,434 --> 01:43:15,350
if it's the same bug or not, but it's not really possible.

01:43:15,350 --> 01:43:18,390
Partially because more than half of the bug,

01:43:18,390 --> 01:43:20,830
the bug itself has multiple manifestations,

01:43:20,830 --> 01:43:23,400
either in space or in time.

01:43:23,400 --> 01:43:28,400
And then even if you can say that this is a different bug,

01:43:28,400 --> 01:43:29,370
still what does it mean?

01:43:29,370 --> 01:43:31,560
Does it mean that the original bug is not there,

01:43:31,560 --> 01:43:34,560
or it's still there but you just hit another one earlier?

01:43:36,073 --> 01:43:38,073
Like you still can't do anything useful.

01:43:38,930 --> 01:43:41,960
And 14% were build or boot broken.

01:43:41,960 --> 01:43:45,660
We actually reduced it but those 14% were kind

01:43:45,660 --> 01:43:49,710
of bisected to the broken range so we couldn't even,

01:43:51,230 --> 01:43:52,720
Git_bisect_skip didn't help.

01:43:54,220 --> 01:43:57,910
And 8% were bisected to those two release stacks

01:43:57,910 --> 01:44:00,080
because we disabled configs.

01:44:00,080 --> 01:44:02,010
So that was actually a bug in the config

01:44:02,010 --> 01:44:03,160
that we had to disable.

01:44:05,050 --> 01:44:06,990
But the light at the end of the tunnel is

01:44:06,990 --> 01:44:09,970
that when I looked at just at the four latest releases,

01:44:09,970 --> 01:44:12,650
it turned out that the success rate is 70%

01:44:12,650 --> 01:44:15,340
so if you just bisect in a smaller recent range,

01:44:15,340 --> 01:44:18,370
it seems to be that there's strong correlation

01:44:18,370 --> 01:44:19,970
with correct results.

01:44:24,220 --> 01:44:25,932
Before we did it lots of people asked,

01:44:25,932 --> 01:44:28,290
"Why didn't you just bisect it?"

01:44:28,290 --> 01:44:32,200
To say, give us the commit that introduced it

01:44:32,200 --> 01:44:33,470
or cc the right people,

01:44:33,470 --> 01:44:36,200
so please never use the word just

01:44:36,200 --> 01:44:38,734
and bisect in the kernel context, okay?

01:44:38,734 --> 01:44:40,029
(laughing)

01:44:40,029 --> 01:44:41,028
Thank you.

01:44:41,028 --> 01:44:42,490
So this is far from being just.

01:44:44,410 --> 01:44:46,980
And the next thing we are working on now is fix bisection,

01:44:46,980 --> 01:44:48,790
it's a work in progress, so what we want to do,

01:44:48,790 --> 01:44:53,000
if we have a crash that didn't happen for X days,

01:44:53,000 --> 01:44:54,270
maybe it's fixed already.

01:44:54,270 --> 01:44:57,420
So what we want to do, we want to test it in head,

01:44:57,420 --> 01:45:00,630
and then if the crash still happens we want to,

01:45:00,630 --> 01:45:03,650
so if it doesn't happen we want to try to bisect

01:45:03,650 --> 01:45:08,400
to find the fixing commit and then say to the developers,

01:45:08,400 --> 01:45:10,420
"Hey, this is probably fixed by this commit"

01:45:10,420 --> 01:45:13,600
and if it can make sense then please close the bug.

01:45:14,440 --> 01:45:16,500
Or if the crash actually happens in the head,

01:45:16,500 --> 01:45:18,590
then this may be a right time

01:45:18,590 --> 01:45:23,097
to send the ping with the new report and the latest commit.

01:45:23,097 --> 01:45:26,550
Initial results that we see lots of cases,

01:45:26,550 --> 01:45:30,820
where we had a reproducer that stopped happening say,

01:45:30,820 --> 01:45:34,040
one and a half years ago and then we tested in head

01:45:34,040 --> 01:45:37,260
and it still happened, like it causes the same crash.

01:45:37,260 --> 01:45:39,300
So for some reason the system kind

01:45:39,300 --> 01:45:41,620
of unlearned how to trigger it

01:45:41,620 --> 01:45:44,153
but the bug is very much there.

01:45:47,280 --> 01:45:48,620
Also lots of other work which

01:45:48,620 --> 01:45:50,890
is probably not very interesting.

01:45:50,890 --> 01:45:53,840
Coverage, so lots of people asked "What is the coverage?"

01:45:53,840 --> 01:45:56,680
Like, how good is this for my subsystem?

01:45:56,680 --> 01:45:58,260
Is it testing my subsystem?

01:45:58,260 --> 01:46:00,060
If it's not finding bugs is it

01:46:00,060 --> 01:46:03,410
because we are good or are we just not testing it?

01:46:03,410 --> 01:46:06,700
So if you go to dashboard you will see the coverage link

01:46:06,700 --> 01:46:08,760
which leads you to the coverage report,

01:46:09,800 --> 01:46:11,210
and if you click it you will see

01:46:11,210 --> 01:46:13,730
the kernel file directory structure

01:46:13,730 --> 01:46:17,180
and for each directory have the kind of percent of coverage.

01:46:17,180 --> 01:46:20,550
And this is kind of this number of basic blocks,

01:46:20,550 --> 01:46:22,890
which is some substitute for lines of code.

01:46:24,790 --> 01:46:26,910
So basically how much of this directory.

01:46:28,304 --> 01:46:29,230
You can expand the directory.

01:46:29,230 --> 01:46:30,270
You can go deeper.

01:46:30,270 --> 01:46:32,030
You can expand other directories

01:46:32,030 --> 01:46:34,940
and kind of see coverage for particular files.

01:46:34,940 --> 01:46:36,790
And if you click on the file you will see,

01:46:36,790 --> 01:46:38,010
coverage on this file.

01:46:38,010 --> 01:46:41,810
So, here black is covered and red is not covered.

01:46:41,810 --> 01:46:44,190
So in this case for example, it's obvious

01:46:44,190 --> 01:46:46,470
that the fuzzer cannot progress

01:46:46,470 --> 01:46:49,213
through this first check in the function.

01:46:49,213 --> 01:46:51,790
And if you know about this subsystem,

01:46:51,790 --> 01:46:53,450
maybe you know about what's required

01:46:53,450 --> 01:46:56,230
for the fuzzer to what needs to be improved

01:46:56,230 --> 01:47:00,300
to actually cover this function.

01:47:00,300 --> 01:47:02,520
You can also see those yellow lines

01:47:02,520 --> 01:47:04,190
which means partially covered.

01:47:04,190 --> 01:47:06,980
So here it's like, I think it's a logical end,

01:47:06,980 --> 01:47:08,900
one part is covered, another is not.

01:47:09,780 --> 01:47:11,800
And you also see those numbers which means,

01:47:11,800 --> 01:47:14,470
how many tests cover a particular line.

01:47:14,470 --> 01:47:17,283
And this may be useful for some analysis.

01:47:19,840 --> 01:47:22,800
There are some caveats, so we collect coverage

01:47:22,800 --> 01:47:24,600
only from the system call itself

01:47:24,600 --> 01:47:26,580
only from this particular task.

01:47:26,580 --> 01:47:28,320
So we don't collect coverage from say,

01:47:28,320 --> 01:47:31,030
interrupts, background threats, init code,

01:47:31,030 --> 01:47:34,070
we only can collect coverage on

01:47:34,070 --> 01:47:36,120
what's reachable from system call.

01:47:39,130 --> 01:47:41,120
Yeah, and the number you all were waiting

01:47:41,120 --> 01:47:42,520
for is total coverage.

01:47:42,520 --> 01:47:47,520
So we cover 250,000 basic blocks out of three million,

01:47:49,980 --> 01:47:52,140
three and a half million,

01:47:52,140 --> 01:47:55,930
which gives us approximately 7% of the kernel code.

01:47:57,356 --> 01:47:59,700
I think this is for x86.

01:47:59,700 --> 01:48:03,270
And then some variance, but yeah, which is not very large.

01:48:03,270 --> 01:48:06,070
So for kind of, if you cover everything,

01:48:06,070 --> 01:48:09,410
you need to multiply back numbers say by 14.

01:48:10,940 --> 01:48:13,150
But then some very unsound math,

01:48:13,150 --> 01:48:15,410
I converted it to lines of code and this gives us

01:48:15,410 --> 01:48:18,020
pretty cool 1.8 million lines of code.

01:48:18,020 --> 01:48:22,390
So we maybe have the largest kind of test case base

01:48:22,390 --> 01:48:26,520
for Linux that allows us to really quickly cover

01:48:26,520 --> 01:48:28,690
almost two million lines of code

01:48:28,690 --> 01:48:30,860
in a virtual machine without any hardware.

01:48:32,570 --> 01:48:34,080
Yeah, but those are not really tests

01:48:34,080 --> 01:48:36,780
so they don't test anything, they just cover the code.

01:48:40,310 --> 01:48:42,920
And so we still need more descriptions.

01:48:44,030 --> 01:48:47,070
Since color interface are rare

01:48:47,070 --> 01:48:50,270
and it needs descriptions of the interfaces

01:48:50,270 --> 01:48:53,290
that test the kernel and we can't add all of them

01:48:53,290 --> 01:48:56,100
because it requires some expertise in the subsystem.

01:48:57,980 --> 01:49:01,460
So all kernel developers are welcome to add more.

01:49:01,460 --> 01:49:04,100
And I just show you brief example

01:49:04,100 --> 01:49:07,150
so that you're not too scared of this.

01:49:07,150 --> 01:49:08,910
So let's say this for floppy drive.

01:49:09,860 --> 01:49:11,730
Yeah, and this is a description actually,

01:49:11,730 --> 01:49:13,520
the reason for the recent events

01:49:13,520 --> 01:49:17,150
that happened with the floppy drive in the Linux kernel.

01:49:17,150 --> 01:49:19,220
So let's say we want to add descriptions,

01:49:19,220 --> 01:49:22,040
so first of all we say that there is a special type of fd

01:49:22,040 --> 01:49:25,050
which is, we call fd_floppy and then we say

01:49:25,050 --> 01:49:28,170
that if you open this particular file,

01:49:28,170 --> 01:49:31,890
you'll get instances of this floppy descriptor

01:49:31,890 --> 01:49:35,580
and then we say that there is an ioctl on this fd_floppy

01:49:35,580 --> 01:49:39,530
with this constant which doesn't accept any argument

01:49:39,530 --> 01:49:41,680
and there's another one which accepts pointer

01:49:41,680 --> 01:49:43,220
to this structure.

01:49:43,220 --> 01:49:46,160
And here is a description of this structure.

01:49:46,160 --> 01:49:48,670
So you can think of this more or less

01:49:48,670 --> 01:49:52,810
as a see function and structure declaration,

01:49:52,810 --> 01:49:55,190
just with slightly more semantic information.

01:49:58,460 --> 01:50:00,310
And the last thing is stub devices.

01:50:00,310 --> 01:50:03,560
So we have tun, we have some others

01:50:04,465 --> 01:50:06,710
and they're super useful in covering code

01:50:06,710 --> 01:50:10,330
that is not normally reachable from the user space.

01:50:11,420 --> 01:50:13,050
So we absolutely need more of them.

01:50:13,050 --> 01:50:14,930
They're not useful not just for fuzzing,

01:50:14,930 --> 01:50:17,390
also for unit tests, for example tun allows you

01:50:17,390 --> 01:50:20,830
to write very kind of handy abstract unit tests

01:50:20,830 --> 01:50:23,590
that can test incoming network pass

01:50:25,360 --> 01:50:27,950
and if that can be unit tested

01:50:27,950 --> 01:50:30,290
from user space then it can also be fuzzed.

01:50:31,860 --> 01:50:33,080
Yes, and that's it.

01:50:33,080 --> 01:50:34,680
Thank you.

01:50:34,680 --> 01:50:37,080
- And unfortunately you are out of time for Q&A.

01:50:39,810 --> 01:50:40,643
Thank you.

01:50:41,928 --> 01:50:45,261
(participants clapping)

01:51:36,166 --> 01:51:36,999
- Okay.

01:51:50,459 --> 01:51:51,292
Okay.

01:51:57,185 --> 01:52:00,685
The title is collaboration and unification

01:52:02,032 --> 01:52:05,623
around unit testing frameworks and hopefully

01:52:05,623 --> 01:52:08,719
we can get some discussion around

01:52:08,719 --> 01:52:11,719
what's important around unit testing

01:52:13,031 --> 01:52:17,049
and unit testing frameworks for the kernel.

01:52:17,049 --> 01:52:21,692
That's the goal, but since I think people

01:52:21,692 --> 01:52:26,692
also maybe don't know about where we come from

01:52:31,619 --> 01:52:36,619
and myself in particular.

01:52:36,846 --> 01:52:39,351
And, oh, thanks.

01:52:39,351 --> 01:52:43,601
Turn it on, that's all.

01:52:43,601 --> 01:52:48,601
So I've been working pragmatically test driven

01:52:48,960 --> 01:52:53,750
since 2001 and once I started to,

01:52:53,750 --> 01:52:55,750
and I call it pragmatically test driven,

01:52:56,907 --> 01:53:00,280
that means test driven whenever it's actually possible

01:53:00,280 --> 01:53:03,620
to do it within the timeframe given by management.

01:53:03,620 --> 01:53:05,570
Because there's always a time limit,

01:53:05,570 --> 01:53:08,120
you have to do deliver something within a certain time.

01:53:08,120 --> 01:53:13,060
And it's a trade-off between time and quality.

01:53:16,070 --> 01:53:20,310
And once I kind of started there I never have gone back,

01:53:20,310 --> 01:53:21,940
so I always wanted to do that,

01:53:23,020 --> 01:53:25,990
to continue to be able to work relatively test driven.

01:53:26,910 --> 01:53:31,110
So on KTF, as I call it, kernel test framework.

01:53:33,381 --> 01:53:36,010
It was originally conceived as ktest

01:53:36,860 --> 01:53:40,290
from testing needs that we had with the Infiniband driver

01:53:40,290 --> 01:53:45,290
that we did a lot at Oracle for a couple of years.

01:53:48,380 --> 01:53:52,050
But since the ktest name was already taken,

01:53:52,050 --> 01:53:55,070
we had to come up with something new.

01:53:57,130 --> 01:54:02,070
Initially we did this with Qemu and hardware simulation

01:54:02,070 --> 01:54:04,300
and we needed to have really focused tests

01:54:04,300 --> 01:54:09,050
because if you run something in the simulated hardware,

01:54:09,050 --> 01:54:12,530
it takes forever to run even a small piece of code,

01:54:12,530 --> 01:54:15,240
so we needed to have really focused tests

01:54:15,240 --> 01:54:18,150
so unit tests became important in that sense.

01:54:19,930 --> 01:54:22,770
When that project got canceled unfortunately,

01:54:26,994 --> 01:54:29,080
then I was actually requested to look into

01:54:29,080 --> 01:54:31,870
what can we salvage from that project

01:54:31,870 --> 01:54:36,870
in terms of tools and that's how KTF became what it is.

01:54:38,840 --> 01:54:43,840
So then I kind of rebranded and refactored it in early 2017

01:54:44,880 --> 01:54:48,280
and then I got excellent help from Alan here in the front,

01:54:49,150 --> 01:54:51,530
who has added cool features to it

01:54:51,530 --> 01:54:54,730
and he really kind of enhanced it

01:54:54,730 --> 01:54:59,730
and got it further on to my great pleasure.

01:55:00,770 --> 01:55:04,257
And we actually considered the word Kunit as well

01:55:06,770 --> 01:55:09,220
but since ku in Norwegian means cow,

01:55:10,130 --> 01:55:14,080
so cow-nit doesn't really sound that well so I skipped that.

01:55:17,950 --> 01:55:19,670
And I also think it's important to know

01:55:19,670 --> 01:55:24,670
that unit testing plus continuous integration equals true.

01:55:25,250 --> 01:55:26,650
You need to really have it

01:55:26,650 --> 01:55:28,990
to get the full benefit out of unit tests,

01:55:28,990 --> 01:55:31,555
you also need to have a continuous integration system

01:55:31,555 --> 01:55:35,130
that can make sure that you don't have to fix all the bugs

01:55:35,130 --> 01:55:40,130
that other people introduce that causes your tests to fail.

01:55:44,100 --> 01:55:48,020
And we have...

01:55:49,670 --> 01:55:52,610
Alan's written an excellent blog entry,

01:55:52,610 --> 01:55:55,810
on the oracle blog that shows you an example

01:55:55,810 --> 01:55:59,260
of how to do it and all of his development

01:55:59,260 --> 01:56:02,609
of our unit test that covers an interesting,

01:56:02,609 --> 01:56:07,290
kind of simple example of how KTF can be used.

01:56:08,190 --> 01:56:10,310
So, to the real topic of today.

01:56:11,210 --> 01:56:15,110
What are we really trying to achieve with unit tests?

01:56:15,110 --> 01:56:19,940
Well, in my view we want to achieve a more

01:56:19,940 --> 01:56:22,400
test driven culture for kernel development

01:56:23,380 --> 01:56:27,070
and the main challenge with test driven development

01:56:27,070 --> 01:56:30,850
is that it is to some extent a change of mindset

01:56:31,800 --> 01:56:36,800
and that means that for those of us

01:56:37,640 --> 01:56:41,080
who have already seen the light, we just need

01:56:41,080 --> 01:56:45,690
to make it easy to continue to work test driven.

01:56:45,690 --> 01:56:49,410
While for the rest of the world, we basically need

01:56:49,410 --> 01:56:54,410
to make it as so easy to use that it's kind of unresistible.

01:56:57,220 --> 01:56:59,980
So like the drug dealer approach

01:56:59,980 --> 01:57:02,110
where you give the first doses for free

01:57:02,110 --> 01:57:03,870
and then people get hooked

01:57:03,870 --> 01:57:06,030
and then they start continuing to do it.

01:57:06,030 --> 01:57:09,614
So that's kind of the idea here, I think.

01:57:09,614 --> 01:57:12,183
Isn't it?

01:57:12,183 --> 01:57:17,183
So, I think it's about scalability

01:57:19,390 --> 01:57:21,490
of the kernel development process

01:57:21,490 --> 01:57:24,930
because not all of us are geniuses.

01:57:24,930 --> 01:57:28,630
We make mistakes and we might not understand

01:57:28,630 --> 01:57:31,052
the code in the kernel that well,

01:57:31,052 --> 01:57:34,810
so if we can kind of get to a point

01:57:34,810 --> 01:57:37,380
where we get a lot of unit tests

01:57:37,380 --> 01:57:39,030
in various areas of the kernel,

01:57:39,030 --> 01:57:42,060
it will be much easier for people

01:57:42,060 --> 01:57:45,150
getting into this because these tests can serve

01:57:45,150 --> 01:57:47,140
as kind of assertions on the code

01:57:47,140 --> 01:57:49,930
to make it possible to understand,

01:57:49,930 --> 01:57:52,440
more easily possible for people to understand

01:57:52,440 --> 01:57:55,720
how the code works, or how it's supposed to work.

01:57:55,720 --> 01:57:59,300
Or even, you can have an assumption about the code

01:57:59,300 --> 01:58:03,110
and introduce it and see if it passes

01:58:03,110 --> 01:58:05,340
and it might fail and then you gain

01:58:05,340 --> 01:58:07,150
some knowledge from that as well.

01:58:08,080 --> 01:58:11,053
So it's also kind of a safety net to entry.

01:58:15,890 --> 01:58:19,520
Now this is kind of the preacher preaching to the community,

01:58:19,520 --> 01:58:22,560
I suppose because all of you are obviously interested

01:58:22,560 --> 01:58:25,545
in testing and that's probably some of the problem too,

01:58:25,545 --> 01:58:30,060
that those who really would need it,

01:58:30,060 --> 01:58:34,080
they wouldn't bother to come anyway.

01:58:34,080 --> 01:58:36,650
But I thought it would be useful to just have

01:58:36,650 --> 01:58:39,820
kind of a hands up and see if everyone

01:58:39,820 --> 01:58:43,300
agrees on some basic ideas here.

01:58:48,519 --> 01:58:51,770
For instance, how many of you would agree

01:58:51,770 --> 01:58:55,580
that what I describe now as pragmatic form

01:58:55,580 --> 01:58:57,980
of test driven development should be encouraged.

01:58:59,120 --> 01:58:59,953
Hands up.

01:59:00,940 --> 01:59:05,070
So, yeah, some 30% almost.

01:59:05,070 --> 01:59:06,190
Okay.

01:59:06,190 --> 01:59:07,930
That's interesting.

01:59:07,930 --> 01:59:10,850
I thought that was kind of 100%, but okay,

01:59:10,850 --> 01:59:11,850
that's good to know.

01:59:13,560 --> 01:59:17,110
How about the fact that testing tools need

01:59:17,110 --> 01:59:21,700
to be intuitive and concise and rewarding to use.

01:59:21,700 --> 01:59:23,880
How many of you would agree to that?

01:59:23,880 --> 01:59:25,620
Oh, slightly more but not all.

01:59:28,932 --> 01:59:31,182
It would be interesting to know why not, but.

01:59:32,315 --> 01:59:37,315
Okay, with the unit test framework,

01:59:39,520 --> 01:59:43,240
do we want to cover all types of uses classes

01:59:43,240 --> 01:59:48,007
or can we introduce the API with only covering

01:59:50,450 --> 01:59:54,880
parts of the problems, part of the kernel for instance.

01:59:57,630 --> 01:59:58,750
- Can you elaborate?

02:00:00,367 --> 02:00:03,740
- So to try to elaborate, is it okay to have unit tests

02:00:06,240 --> 02:00:09,950
that can only be applied to certain parts of the kernel

02:00:09,950 --> 02:00:13,370
or does it need to be applied to all parts of the kernel?

02:00:13,370 --> 02:00:18,370
- Do you mean right away or in the future?

02:00:19,460 --> 02:00:23,970
- For instance, drivers, is it okay,

02:00:23,970 --> 02:00:25,760
should drivers be supported?

02:00:25,760 --> 02:00:27,520
Driver testing or hardware testing?

02:00:38,990 --> 02:00:42,350
- So, I feel like this is kind of a loaded question.

02:00:42,350 --> 02:00:44,080
- It is, of course. - Yeah.

02:00:44,080 --> 02:00:45,280
- That's the whole idea.

02:00:46,340 --> 02:00:48,130
- I think it's fine to.

02:00:48,130 --> 02:00:52,310
So like, it's fine to have a unit testing suite

02:00:52,310 --> 02:00:54,060
that doesn't do end to end testing, right?

02:00:54,060 --> 02:00:56,320
Like those are very different use cases.

02:00:57,540 --> 02:00:59,580
Like I don't think there's really any point

02:00:59,580 --> 02:01:02,050
in trying to cover end to end testing for example

02:01:02,050 --> 02:01:07,020
'cause kselftest already does a good job doing that.

02:01:07,020 --> 02:01:09,820
- Okay, so how many of you would disagree with him?

02:01:12,500 --> 02:01:14,010
Oh, some.

02:01:14,010 --> 02:01:15,650
Thanks.

02:01:15,650 --> 02:01:17,851
- [Man] I disagree with the last part.

02:01:17,851 --> 02:01:20,193
Kselftest is scratching the surface,

02:01:20,193 --> 02:01:23,300
as are most test systems, so.

02:01:23,300 --> 02:01:25,330
- Any other comments to that?

02:01:25,330 --> 02:01:27,980
We'll move on because otherwise we won't be finished.

02:01:31,550 --> 02:01:33,640
Do we agree that drivers and hardware

02:01:33,640 --> 02:01:36,570
are big pain point in the kernel with respect to testing?

02:01:37,790 --> 02:01:38,930
How many?

02:01:38,930 --> 02:01:39,900
Oh, quite a few.

02:01:45,770 --> 02:01:48,330
Do you think it would be good to have a test framework

02:01:48,330 --> 02:01:52,730
that supports the tests that cross the kernel

02:01:52,730 --> 02:01:53,580
and use the boundaries,

02:01:53,580 --> 02:01:55,360
or that you can have part of the testing

02:01:55,360 --> 02:01:57,660
in the user line and parts in the kernel line?

02:01:59,840 --> 02:02:02,110
Yeah, hands up again.

02:02:02,110 --> 02:02:04,431
I didn't look properly.

02:02:04,431 --> 02:02:07,650
Good, so 50% or something, maybe.

02:02:10,084 --> 02:02:15,084
And I think also, I'll claim that one particular class

02:02:17,050 --> 02:02:20,660
of tests that's not particularly good covered today

02:02:20,660 --> 02:02:23,840
but we need covered is tests

02:02:23,840 --> 02:02:27,420
that cannot be done easily with just one kernel.

02:02:28,870 --> 02:02:30,800
Network tests for instance.

02:02:30,800 --> 02:02:33,710
How many of you would agree to that?

02:02:34,550 --> 02:02:35,450
Very few actually.

02:02:37,111 --> 02:02:37,944
That's interesting.

02:02:39,085 --> 02:02:42,090
- [Man] Just because we never do that type of testing.

02:02:42,090 --> 02:02:43,487
These people aren't familiar with it

02:02:43,487 --> 02:02:47,020
so they don't know how to use it.

02:02:47,937 --> 02:02:50,780
- So the second kernel would be like a hardware.

02:02:50,780 --> 02:02:53,250
If our goal is marking out hardware,

02:02:53,250 --> 02:02:55,640
you can also mark out the second kernel.

02:02:55,640 --> 02:02:58,029
- Yeah, we could to some extent mark,

02:02:58,029 --> 02:02:59,630
some mark could compensate maybe

02:02:59,630 --> 02:03:03,090
but some tests would probably need two kernels.

02:03:03,090 --> 02:03:05,840
If you have a network test, two...

02:03:14,444 --> 02:03:18,130
- I think you're biasing it by phrasing it as single kernel.

02:03:18,130 --> 02:03:20,470
It's a kernel plus other stuff.

02:03:20,470 --> 02:03:22,100
Like there's a whole bunch of tests you could run

02:03:22,100 --> 02:03:25,230
if you had a video analyzer or a USB,

02:03:26,260 --> 02:03:28,390
something that can control USB hardware

02:03:28,390 --> 02:03:32,050
or something that does power measurement off-board.

02:03:33,220 --> 02:03:35,510
So there's all kinds of tests,

02:03:37,620 --> 02:03:40,500
probably an infinite number of tests that you can do

02:03:40,500 --> 02:03:42,270
if you have additional things besides

02:03:42,270 --> 02:03:43,800
just the software and the test.

02:03:43,800 --> 02:03:45,540
- Right, that's probably a better.

02:03:47,020 --> 02:03:49,190
Should kind of generalize it to that.

02:03:50,170 --> 02:03:51,307
Good point, thanks.

02:03:55,970 --> 02:04:00,120
The last bullet, how many of you would agree

02:04:00,120 --> 02:04:05,120
that if there are good user land tools for things,

02:04:05,750 --> 02:04:07,800
that it doesn't necessarily need

02:04:07,800 --> 02:04:09,690
to be reinvented in the kernel,

02:04:09,690 --> 02:04:12,030
or do we want to have everything in the kernel?

02:04:12,030 --> 02:04:13,950
So let's say how many of you think

02:04:13,950 --> 02:04:16,540
that user land tools in general,

02:04:18,530 --> 02:04:20,230
if we have good user land tools,

02:04:20,230 --> 02:04:24,960
should we then use them as dependencies to the kernel?

02:04:28,160 --> 02:04:30,110
Or dependencies to testing or whatever.

02:04:34,397 --> 02:04:36,670
- I would say it depends on how well it feeds,

02:04:36,670 --> 02:04:39,589
into the kernel and how much it actually provides.

02:04:39,589 --> 02:04:40,540
So putting in dependency to just get,

02:04:40,540 --> 02:04:43,930
some small beat maybe not worth it.

02:04:43,930 --> 02:04:46,550
- Yes, I agree with you on that.

02:04:47,504 --> 02:04:49,750
I think when there are good tools

02:04:49,750 --> 02:04:52,060
that already are maintained outside the kernel,

02:04:52,060 --> 02:04:56,730
we agree that it's good to keep it that way.

02:04:56,730 --> 02:05:00,180
How many of you would agree with that?

02:05:00,180 --> 02:05:01,900
Not that many.

02:05:01,900 --> 02:05:03,200
Interesting.

02:05:03,200 --> 02:05:05,510
Okay, so let's move to the discussion areas.

02:05:12,800 --> 02:05:17,800
I think, there's something called religion

02:05:18,360 --> 02:05:22,110
that plays in some of these topics I think.

02:05:22,110 --> 02:05:24,310
And what is really a religion?

02:05:24,310 --> 02:05:27,770
Well it's something that's based on dogmas which is,

02:05:27,770 --> 02:05:32,230
a dogma is something that which one think is true.

02:05:32,230 --> 02:05:34,830
Which we kind of assume it's true,

02:05:34,830 --> 02:05:36,580
but we don't have any proof, right?

02:05:39,120 --> 02:05:42,220
So I'm trying to be a little bit provocative here now,

02:05:42,220 --> 02:05:43,470
I don't know if it works.

02:05:49,080 --> 02:05:53,930
We have the neat factor, I think

02:05:53,930 --> 02:05:55,430
that's a really important one.

02:05:56,550 --> 02:06:00,050
That if someone's going to use some program,

02:06:00,050 --> 02:06:02,780
it needs to feel good to use it.

02:06:02,780 --> 02:06:07,240
Or if it's a device, think about an iPod or something,

02:06:07,240 --> 02:06:12,240
how it became what it became because it was so neat to use,

02:06:12,800 --> 02:06:15,420
so easy to use that anyone could use it

02:06:15,420 --> 02:06:16,900
without any documentation.

02:06:20,870 --> 02:06:25,070
I think that's what we need in the testing space

02:06:25,070 --> 02:06:30,070
is a way of making it so easy to get started with tests

02:06:32,903 --> 02:06:37,010
that it's no excuse not to do it.

02:06:37,010 --> 02:06:41,710
And we also need to make sure that the input

02:06:41,710 --> 02:06:44,539
is similar for all tests so that it could

02:06:44,539 --> 02:06:46,620
take example tests, look at them

02:06:46,620 --> 02:06:50,130
and redeploy them in other areas easily

02:06:51,270 --> 02:06:54,000
and also the output needs to be configured.

02:06:59,470 --> 02:07:01,800
- So I'm gonna go back and say that unified input

02:07:01,800 --> 02:07:06,080
might be a dream because a lot of subsystems

02:07:06,080 --> 02:07:08,530
are very different, they rely on different things

02:07:10,220 --> 02:07:12,240
and I don't see that happening.

02:07:12,240 --> 02:07:14,360
Unified output, yes that's certainly very useful

02:07:14,360 --> 02:07:15,810
but unified input, maybe not.

02:07:16,880 --> 02:07:19,150
- To some extent maybe, I mean,

02:07:19,150 --> 02:07:21,180
what I'm thinking about with unified input

02:07:21,180 --> 02:07:24,870
is that the primitives to check things

02:07:24,870 --> 02:07:26,170
are similar for instance.

02:07:27,240 --> 02:07:30,150
That you have a similar--

02:07:30,150 --> 02:07:32,810
- But if you're talking about unit testing here,

02:07:32,810 --> 02:07:36,070
then the unit can have different things as input,

02:07:36,070 --> 02:07:38,900
it's very hard to come up with commonalities--

02:07:38,900 --> 02:07:40,970
- I think maybe input is the wrong word,

02:07:40,970 --> 02:07:43,040
I think input to the tests.

02:07:43,040 --> 02:07:47,180
So in the assertion language, like

02:07:47,180 --> 02:07:50,580
the language that we use to devise the tests.

02:07:50,580 --> 02:07:54,660
If we look at the kernel today, we have tests in /lib,

02:07:55,550 --> 02:07:57,960
we have some tests in kselftest,

02:07:57,960 --> 02:08:02,960
we have tests spread out in some user land modules and so on

02:08:03,270 --> 02:08:06,450
and they have very different languages,

02:08:06,450 --> 02:08:10,100
in how to express assertions about what to test.

02:08:10,100 --> 02:08:12,660
If we can kind of unify and own.

02:08:15,200 --> 02:08:17,500
We are moving on to the next one here.

02:08:17,500 --> 02:08:22,500
That is to take ownership of the unit test name space.

02:08:23,410 --> 02:08:27,700
I know Brandon was trying to have a search

02:08:27,700 --> 02:08:32,080
equals and expect equals, which is kind of the standard

02:08:32,080 --> 02:08:35,830
unit test primitives as primitives in kunit,

02:08:35,830 --> 02:08:40,320
but he was told to rewrite it to kunit_assert_

02:08:41,970 --> 02:08:46,970
and kunit_expect_ which I think kind

02:08:47,563 --> 02:08:51,680
of didn't really mean serious that we want

02:08:51,680 --> 02:08:56,360
to have unit testing, in which case maybe it could be

02:08:56,360 --> 02:08:59,020
promoted to maybe the same level as let's say beg

02:08:59,948 --> 02:09:03,370
or one or some other short primitive so that it's easy to.

02:09:04,640 --> 02:09:07,380
For those of us who kind of have

02:09:07,380 --> 02:09:10,280
a limited amount of key clicks to make

02:09:10,280 --> 02:09:12,660
before our arms are dead,

02:09:12,660 --> 02:09:15,670
that we don't have to type more than necessary.

02:09:17,470 --> 02:09:18,520
Any comments on that?

02:09:20,770 --> 02:09:21,920
The names based issue.

02:09:27,460 --> 02:09:29,910
- I agree that unit tests should be easy to write

02:09:29,910 --> 02:09:34,910
and they should be concise and doesn't have too much typing.

02:09:36,380 --> 02:09:37,580
Boilerplate typing.

02:09:39,560 --> 02:09:44,560
- And also I think the second point, moving tests from,

02:09:44,610 --> 02:09:48,810
or taking the work of unifying the tests

02:09:48,810 --> 02:09:52,630
is something that I think is useful

02:09:52,630 --> 02:09:54,600
and I've actually had a Master's student

02:09:54,600 --> 02:09:56,900
working for me while doing a Master's thesis,

02:09:56,900 --> 02:09:59,260
where he looked at how he could convert KTF

02:10:00,446 --> 02:10:03,320
for some of the existing tests such as the xarray tests

02:10:04,570 --> 02:10:07,830
or hash table tests and a few other small tests

02:10:07,830 --> 02:10:10,870
that already are existing kernel tests

02:10:10,870 --> 02:10:13,660
and he kind of converted them to KTF

02:10:13,660 --> 02:10:17,360
to kind of show that it's possible to do that.

02:10:18,520 --> 02:10:22,960
That there's enough expressivity in the code,

02:10:22,960 --> 02:10:26,960
and I think doing that work, while it might seem like,

02:10:26,960 --> 02:10:29,810
kind of elaborate, unnecessary work,

02:10:29,810 --> 02:10:34,810
it is important because then people start looking

02:10:35,880 --> 02:10:38,010
at some area, they will take examples

02:10:38,010 --> 02:10:41,310
from existing code and it's important that that code

02:10:41,310 --> 02:10:46,310
is kind of consistently doing it,

02:10:46,790 --> 02:10:49,600
in the right way, or kind of the intended way.

02:10:52,360 --> 02:10:53,610
How much time do I have?

02:10:59,320 --> 02:11:00,420
10 more minutes, good.

02:11:01,687 --> 02:11:06,620
Okay, so what I've found when I tried

02:11:06,620 --> 02:11:09,640
to integrate KTF into the kernel,

02:11:10,520 --> 02:11:13,340
I found that what I call,

02:11:13,340 --> 02:11:18,340
inadequate support in the kernel build system.

02:11:19,130 --> 02:11:23,380
I know that kselftest, if we look at kselftest,

02:11:23,380 --> 02:11:25,513
it had done quite some work to try

02:11:25,513 --> 02:11:30,513
to make it possible to even build user level

02:11:32,840 --> 02:11:37,290
or target architecture programs

02:11:37,290 --> 02:11:40,393
and that distinction wasn't clear enough to me

02:11:40,393 --> 02:11:42,560
until I posted the patch, that there's actually

02:11:42,560 --> 02:11:46,190
a big difference between host and target

02:11:46,190 --> 02:11:49,645
in some circumstances for us coming from the server side.

02:11:49,645 --> 02:11:54,420
But there's no rules in the generic build system

02:11:54,420 --> 02:11:58,900
in the kernel to build user level applications

02:11:58,900 --> 02:12:02,100
together with kernel modules for testing

02:12:02,100 --> 02:12:07,100
because they naturally belong together in a test sense

02:12:07,310 --> 02:12:11,780
and there's no good way today, in my view

02:12:13,508 --> 02:12:18,037
to support and having kind of similar rules

02:12:20,870 --> 02:12:24,310
in the kernel as we have for object-y.

02:12:24,310 --> 02:12:28,870
We should have similar rules for host programs.

02:12:28,870 --> 02:12:33,200
Or there is for host programs, and libs,

02:12:33,200 --> 02:12:36,860
but there's nothing for target programs.

02:12:38,050 --> 02:12:41,520
Because we really, if we change,

02:12:41,520 --> 02:12:46,193
I'll postulate that if we change the config to a kernel,

02:12:49,530 --> 02:12:51,600
it's no longer the same kernel.

02:12:51,600 --> 02:12:56,460
So if we depend upon changing the configuration

02:12:57,710 --> 02:13:00,350
to build the test framework, we are

02:13:00,350 --> 02:13:02,050
no longer testing the same kernel.

02:13:02,930 --> 02:13:06,720
So really, configuration should not be needed.

02:13:06,720 --> 02:13:10,423
We might need configuration for building the...

02:13:12,580 --> 02:13:15,910
Because it requires some features for the testing itself.

02:13:15,910 --> 02:13:18,580
But in general it should be possible

02:13:19,468 --> 02:13:22,900
to have an existing production kernel

02:13:22,900 --> 02:13:25,950
and then deploy a test framework

02:13:25,950 --> 02:13:29,130
towards that production kernel without

02:13:30,370 --> 02:13:32,120
having to make conflict changes

02:13:33,189 --> 02:13:35,320
because if we have to, then we are

02:13:35,320 --> 02:13:37,170
no longer looking at the same kernel.

02:13:41,580 --> 02:13:44,100
- Yeah, so it's actually one of the reasons that,

02:13:44,100 --> 02:13:47,560
for example the distro kind of doesn't the kselftest,

02:13:48,980 --> 02:13:53,940
because kselftest needs to have the extra kconfigs

02:13:53,940 --> 02:13:58,560
enabling all the back options and so on and that's...

02:13:58,560 --> 02:14:01,700
So it would be oh so good if we have a kselftest

02:14:02,760 --> 02:14:07,020
without any extra kind of configuration enablement

02:14:07,020 --> 02:14:12,020
so that can test the distro kernel as is with test case.

02:14:15,630 --> 02:14:17,897
- So you mean if you have...

02:14:20,120 --> 02:14:21,690
Are you actually planning to build

02:14:21,690 --> 02:14:24,750
the kselftest on the entire system

02:14:24,750 --> 02:14:27,120
or do you want executable shipped?

02:14:29,943 --> 02:14:31,428
What are you looking at?

02:14:31,428 --> 02:14:32,710
- It depends. - It depends.

02:14:32,710 --> 02:14:35,550
So you don't have to...

02:14:37,139 --> 02:14:40,800
In the mode where you have a distro kernel running, right,

02:14:40,800 --> 02:14:45,180
and then you are building a self test on there to run.

02:14:45,180 --> 02:14:48,700
You have the git repo, whatever.

02:14:48,700 --> 02:14:52,446
So then you don't have to, you can use your old

02:14:52,446 --> 02:14:56,600
current config and then build self test.

02:14:56,600 --> 02:14:58,930
You could do that, there is nobody

02:14:58,930 --> 02:15:00,830
stopping you from doing that.

02:15:00,830 --> 02:15:03,790
Config fragments came in partly because

02:15:05,540 --> 02:15:10,540
in CI environments they have variations on configurations.

02:15:13,720 --> 02:15:17,446
I think it makes sense to enable configurations

02:15:17,446 --> 02:15:21,100
and giving some control over configuration options.

02:15:21,100 --> 02:15:23,530
That's how fragments came about.

02:15:23,530 --> 02:15:28,316
To be able to have some control over the config drivers.

02:15:28,316 --> 02:15:30,770
Is that correct, Dan?

02:15:30,770 --> 02:15:34,063
Right, so that's why we...

02:15:34,063 --> 02:15:38,600
That's a tweak to support some of the CI environments,

02:15:38,600 --> 02:15:42,840
but you could build a default with the current config.

02:15:48,499 --> 02:15:51,210
- Then what's the necessity of having

02:15:51,210 --> 02:15:54,110
a separate kconfig for each test?

02:15:55,170 --> 02:16:00,170
Can we have just one I built, kselftetst

02:16:00,170 --> 02:16:03,840
and forward all the modules for the

02:16:03,840 --> 02:16:05,680
built in drivers that I built?

02:16:09,780 --> 02:16:10,810
- You can do that.

02:16:12,770 --> 02:16:15,500
- So I want separate config fragments per tests

02:16:15,500 --> 02:16:17,400
because I want to use config fragments

02:16:17,400 --> 02:16:21,040
not to shape the software under test,

02:16:21,040 --> 02:16:24,960
but as information for the test scheduler.

02:16:26,211 --> 02:16:27,430
- Yes, so that's why maybe it needs

02:16:27,430 --> 02:16:28,850
to be a separate dimension.

02:16:30,075 --> 02:16:31,680
- Right, it's a separate operation.

02:16:31,680 --> 02:16:34,630
So I'm doing mostly product testing

02:16:34,630 --> 02:16:37,860
so I never change my kernel config,

02:16:37,860 --> 02:16:41,160
well I use the kernel config that the product guys chose.

02:16:41,160 --> 02:16:42,800
So I'm not in a position to go

02:16:42,800 --> 02:16:44,500
modifying my kernel configuration.

02:16:46,460 --> 02:16:49,050
So I'm only interested, what I would use it for

02:16:49,050 --> 02:16:52,130
is finding the tests that apply to my kernel

02:16:52,130 --> 02:16:54,130
that have those options enabled already.

02:16:55,794 --> 02:16:57,584
So I assume that that--

02:16:57,584 --> 02:16:59,331
- Yeah, that's exactly the same use case

02:16:59,331 --> 02:17:00,781
that I'm kind of thinking of.

02:17:05,740 --> 02:17:06,600
Box, box.

02:17:09,140 --> 02:17:11,170
- I was just suggesting, we only have a couple minutes left,

02:17:11,170 --> 02:17:12,970
I'd like to hear about the proposed,

02:17:14,212 --> 02:17:18,200
like collaboration integration thing.

02:17:18,200 --> 02:17:20,750
- It's more of the same here, so it's not really...

02:17:23,025 --> 02:17:26,560
I mean, I feel that this is collaboration, unification.

02:17:26,560 --> 02:17:29,810
How should the ideal unit test system look?

02:17:29,810 --> 02:17:34,810
That's what I'm kind of trying to get at.

02:17:38,160 --> 02:17:39,950
So we've been touching up on that.

02:17:42,580 --> 02:17:47,580
I think tests really are different from production code.

02:17:50,460 --> 02:17:54,820
That's what I've alluded to with dimensions,

02:17:54,820 --> 02:17:58,270
that we need to have proper support

02:17:58,270 --> 02:18:01,940
from the kernel build system to the test space

02:18:01,940 --> 02:18:04,550
and that's going to be different from production code.

02:18:04,550 --> 02:18:09,400
Right now if we look at, if I want to run the xarray tests,

02:18:09,400 --> 02:18:12,647
I have to change the configuration for that tests code

02:18:14,770 --> 02:18:18,520
to be built and it's also positioned inside the kernel tree,

02:18:18,520 --> 02:18:21,210
below kind of one of the paths

02:18:21,210 --> 02:18:26,210
where other actual kernel production kernel code is

02:18:26,250 --> 02:18:29,150
and it shouldn't be, it should be located

02:18:29,150 --> 02:18:31,650
under tools for testing on hardware.

02:18:31,650 --> 02:18:36,650
Maybe everything could be under self tests.

02:18:38,010 --> 02:18:39,950
The test frameworks, everything that has to do

02:18:39,950 --> 02:18:42,530
with tests and it should be made kind

02:18:43,573 --> 02:18:47,230
of octagonal to the code itself.

02:18:49,868 --> 02:18:51,040
So more than one dimension.

02:18:51,040 --> 02:18:55,177
And also I think one important aspect of testing

02:18:56,070 --> 02:18:58,490
that's not covered by having everything

02:18:58,490 --> 02:19:00,990
into the same kernel, but that could be covered

02:19:00,990 --> 02:19:05,753
by kind of the same approach as compiling modules is.

02:19:12,451 --> 02:19:16,250
It's possible to, even though everything

02:19:16,250 --> 02:19:18,530
might be in one kernel repository,

02:19:18,530 --> 02:19:22,590
that it's possible to take that whole shebang

02:19:22,590 --> 02:19:26,100
and compile it against another kernel

02:19:26,100 --> 02:19:28,730
so that it can still be used to test an older kernel

02:19:28,730 --> 02:19:32,550
because one important test case is,

02:19:33,582 --> 02:19:35,260
let's say we have developed a lot of tests,

02:19:35,260 --> 02:19:37,700
fixed a lot of bugs in the recent kernel

02:19:37,700 --> 02:19:40,000
and then someone has a production kernel

02:19:40,000 --> 02:19:42,410
and they would like to see what bugs

02:19:42,410 --> 02:19:45,350
are we exposed to in that production kernel.

02:19:45,350 --> 02:19:47,250
Then it should be easy to take

02:19:47,250 --> 02:19:50,240
whatever test logic exists in the kernel,

02:19:50,240 --> 02:19:52,580
recompile it against that kernel

02:19:52,580 --> 02:19:56,150
and run the test against that production kernel

02:19:56,150 --> 02:19:57,500
without changing anything.

02:19:58,780 --> 02:20:02,360
Maybe you might not be able to run all the tests,

02:20:02,360 --> 02:20:05,400
but at least the tests that would work

02:20:05,400 --> 02:20:08,880
with the support that is in that kernel.

02:20:08,880 --> 02:20:09,713
We out?

02:20:09,713 --> 02:20:11,640
Okay, that's all I've got to do, so thank you.

02:20:12,973 --> 02:20:16,306
(participants clapping)

02:20:30,730 --> 02:20:33,510
- In the meantime, if someone could help with the notes.

02:20:33,510 --> 02:20:36,260
It's been one person doing a really really hurried job.

02:20:38,870 --> 02:20:41,313
Should I just start picking people out,

02:20:41,313 --> 02:20:42,770
from the audience at random?

02:20:42,770 --> 02:20:43,635
- I'll do it.

02:20:43,635 --> 02:20:48,635
- Thank you.

02:22:53,064 --> 02:22:56,930
- So thanks for having me, this is the usual talk

02:22:56,930 --> 02:22:58,500
that I do once a year,

02:22:58,500 --> 02:23:00,630
talking about the state of kernelselftest

02:23:00,630 --> 02:23:02,840
and find out what we want to do

02:23:04,300 --> 02:23:06,990
and what we can do to improve it.

02:23:08,970 --> 02:23:13,950
So, 3.17, that's when we started kernelselftest.

02:23:13,950 --> 02:23:15,590
That's five years ago.

02:23:15,590 --> 02:23:20,590
We have 15 targets in the make file.

02:23:20,860 --> 02:23:22,340
The way kernelselftest works

02:23:22,340 --> 02:23:24,230
is you have a bunch of directories.

02:23:25,260 --> 02:23:30,260
This is written by developers primarily for their main use.

02:23:30,480 --> 02:23:33,034
We are stretching it to use it,

02:23:33,034 --> 02:23:35,220
run it into user space by users.

02:23:35,220 --> 02:23:37,930
So there are some challenges but I will...

02:23:37,930 --> 02:23:41,040
Some of the challenges that you're bringing up.

02:23:41,040 --> 02:23:45,460
Since we started 15 targets, now we're up to 70,

02:23:45,460 --> 02:23:48,600
I just counted how many directories we have.

02:23:48,600 --> 02:23:53,600
Usually directories means that each subsystem type test,

02:23:54,090 --> 02:23:56,450
and then under that you'll have multiple tests.

02:23:56,450 --> 02:24:01,450
So you're looking at, you have a major target

02:24:02,760 --> 02:24:05,680
and then under that, multiple test suites.

02:24:05,680 --> 02:24:07,910
So you might be looking at probably

02:24:07,910 --> 02:24:10,050
upwards of a thousand tests.

02:24:12,470 --> 02:24:14,020
So these are the...

02:24:14,020 --> 02:24:18,810
I'm not going into too much detail on kselftest itself,

02:24:18,810 --> 02:24:21,130
partly because I want to use this session

02:24:21,130 --> 02:24:26,130
to talk about some of the CI related improvements,

02:24:27,980 --> 02:24:32,660
we could do and clarify how

02:24:32,660 --> 02:24:35,330
to improve some of the CI experiences.

02:24:35,330 --> 02:24:37,470
So I'm not going into too much detail.

02:24:38,640 --> 02:24:40,890
So there are three different kinds

02:24:40,890 --> 02:24:44,060
of use cases for kernelselftest.

02:24:44,060 --> 02:24:46,140
One is rev matched.

02:24:46,140 --> 02:24:48,950
That means you have a development system.

02:24:48,950 --> 02:24:52,130
You are running tests on your development system,

02:24:52,130 --> 02:24:55,840
while you are doing kernel development, essentially.

02:24:55,840 --> 02:25:00,840
So you're testing your kernel, you might be testing,

02:25:01,000 --> 02:25:03,960
just running a subset of tests even,

02:25:03,960 --> 02:25:06,100
so you'll build kernelselftest

02:25:06,100 --> 02:25:09,430
from the same repo and then run tests on that.

02:25:09,430 --> 02:25:12,940
So that's the one I'm showing on the top left.

02:25:13,910 --> 02:25:17,200
The second one is stable release testing.

02:25:17,200 --> 02:25:20,104
Stable release testing you can have

02:25:20,104 --> 02:25:21,520
a couple different modes.

02:25:21,520 --> 02:25:25,250
You can use the main line latest on stable releases

02:25:25,250 --> 02:25:26,570
or we'll get into more of

02:25:26,570 --> 02:25:28,990
that discussion a little bit later,

02:25:28,990 --> 02:25:32,420
or you can rev match it similarly.

02:25:32,420 --> 02:25:34,300
So the third variation is,

02:25:35,960 --> 02:25:40,923
a lot of the CI folks do that, KernelCI.

02:25:42,988 --> 02:25:45,910
They will compile and then, okay

02:25:45,910 --> 02:25:49,460
they have a development system that they will build

02:25:49,460 --> 02:25:51,210
and then they have a target system.

02:25:58,650 --> 02:26:03,650
So kind of give a current picture of results from...

02:26:13,030 --> 02:26:15,230
Do you want to do your tables at this point.

02:26:16,670 --> 02:26:18,250
Show your tables and then we'll

02:26:18,250 --> 02:26:20,050
talk about some of the other issues.

02:26:21,570 --> 02:26:25,790
So at this point if you want more information

02:26:25,790 --> 02:26:28,330
on kselftest I can go into it.

02:26:28,330 --> 02:26:30,370
I don't have slides, but I can go into it,

02:26:30,370 --> 02:26:31,670
if you have any questions.

02:26:36,150 --> 02:26:37,450
You have one, right?

02:26:37,450 --> 02:26:39,033
You have a question, go ahead.

02:26:52,905 --> 02:26:54,500
- Just like in the previous talk,

02:26:54,500 --> 02:26:59,410
how can we encourage that including

02:26:59,410 --> 02:27:01,960
kselftest enablement on distro kernels?

02:27:09,520 --> 02:27:11,490
- How do we want to include them?

02:27:11,490 --> 02:27:12,890
I guess that's the question.

02:27:14,000 --> 02:27:16,954
- One of the things, as I mentioned,

02:27:16,954 --> 02:27:18,930
that the kernel configurations.

02:27:18,930 --> 02:27:21,620
We do not explode the kernel configuration.

02:27:30,300 --> 02:27:35,300
If kselftest works always with distro kernel configuration

02:27:37,830 --> 02:27:41,100
for their drivers or their base configuration,

02:27:41,100 --> 02:27:44,880
then we can just enable each end shape

02:27:44,880 --> 02:27:49,440
or just build and get some people using that

02:27:49,440 --> 02:27:53,270
or testing in the build infrastructure and so on.

02:27:53,270 --> 02:27:56,100
But currently we do not do that

02:27:56,100 --> 02:28:01,100
because we fear that we will hit a kind

02:28:01,550 --> 02:28:02,910
of config mess somehow.

02:28:04,410 --> 02:28:05,243
- So it's...

02:28:06,220 --> 02:28:11,220
I do this on my development system and I use distro,

02:28:13,170 --> 02:28:15,590
whichever distro I'm running on it.

02:28:15,590 --> 02:28:20,590
I use the distro kernel and then make kselftest

02:28:21,380 --> 02:28:24,820
and it will use the distro, your configuration.

02:28:25,900 --> 02:28:30,380
- I think Takashi, your issue is

02:28:30,380 --> 02:28:33,940
that kselftest needs some configs turned on

02:28:33,940 --> 02:28:35,740
that the distro kernel hasn't enabled.

02:28:35,740 --> 02:28:40,310
So to run kselftest, kselftest requires,

02:28:40,310 --> 02:28:43,980
is set up to require options to be turned on

02:28:45,020 --> 02:28:45,870
and it doesn't...

02:28:46,720 --> 02:28:48,570
Takashi wants to test his distro kernel

02:28:48,570 --> 02:28:50,630
which does not have those options on,

02:28:50,630 --> 02:28:54,080
so he needs kselftest to run cleanly.

02:28:54,080 --> 02:28:56,680
It's not about building, it's about the target system.

02:28:56,680 --> 02:29:00,020
Getting kselftest to run cleanly on a system

02:29:00,020 --> 02:29:03,700
where the configs are disabled, if I understand correctly.

02:29:03,700 --> 02:29:05,290
- So is that what you're saying?

02:29:05,290 --> 02:29:08,540
- Yeah, that's one of the concerns.

02:29:09,530 --> 02:29:12,580
That kselftest is guaranteed to work,

02:29:12,580 --> 02:29:15,200
even even ways that imitate kernel configurations.

02:29:16,320 --> 02:29:18,250
- That is the goal.

02:29:18,250 --> 02:29:20,890
That's what we keep working towards.

02:29:24,670 --> 02:29:27,800
That's why if the feature is not supported,

02:29:27,800 --> 02:29:30,470
our tests are supposed to do one or two things.

02:29:31,680 --> 02:29:35,660
Unsupported, which is usually a skip, they do skips.

02:29:35,660 --> 02:29:37,580
So we have gotten there.

02:29:37,580 --> 02:29:40,840
I can't say that all 100% of the tests

02:29:40,840 --> 02:29:43,040
that should skip do skip.

02:29:43,040 --> 02:29:45,170
That's not reality.

02:29:45,170 --> 02:29:49,190
Partly because we keep adding tests every single release

02:29:50,380 --> 02:29:53,310
and some subsystems add more tests than others.

02:29:53,310 --> 02:29:56,960
Our networking adds tons of tests every time.

02:29:56,960 --> 02:29:59,870
So we do miss some things on occasion.

02:30:04,823 --> 02:30:07,570
- I have a follow up question on that for you.

02:30:07,570 --> 02:30:09,470
Do tests skip for configuration missing?

02:30:09,470 --> 02:30:11,220
Do they do configuration detection?

02:30:12,500 --> 02:30:13,870
- The configuration...

02:30:14,740 --> 02:30:18,240
The feature detection sometimes.

02:30:18,240 --> 02:30:23,173
So it depends what kind of test it is.

02:30:24,040 --> 02:30:27,710
We have a mix of binaries and we have mix of shell scripts.

02:30:28,938 --> 02:30:33,080
Shell scripts go in some cases try to load a module to test.

02:30:34,260 --> 02:30:39,260
If the module isn't built in, they will skip the test.

02:30:39,690 --> 02:30:41,190
So that's one variation.

02:30:41,190 --> 02:30:44,750
The second variation is, they do go and look for,

02:30:44,750 --> 02:30:46,530
if it's a shell script it goes

02:30:46,530 --> 02:30:48,480
and looks for a config option.

02:30:48,480 --> 02:30:51,650
So if it's not enabled, it will say

02:30:51,650 --> 02:30:54,980
config option is not enabled, it will skip, right?

02:30:54,980 --> 02:30:57,850
The third variation is system calls.

02:30:58,830 --> 02:31:02,150
I saw your hand up, I will get to it, let me just finish.

02:31:04,100 --> 02:31:07,540
So the third variation is the feature itself.

02:31:07,540 --> 02:31:10,410
For example you might have a...

02:31:10,410 --> 02:31:12,210
I'm just going to say a system call.

02:31:13,910 --> 02:31:18,910
So you have a new system call, new flags are introduced.

02:31:19,600 --> 02:31:23,240
You make a support for the new flags got added.

02:31:23,240 --> 02:31:26,130
So this will be a runtime determination,

02:31:26,130 --> 02:31:29,300
meaning you actually make the system call

02:31:29,300 --> 02:31:31,480
and you either get invalid org

02:31:31,480 --> 02:31:34,520
or unsupported whatever return value.

02:31:34,520 --> 02:31:37,850
That return value is interpreted and then it'll say

02:31:37,850 --> 02:31:39,140
the kernel doesn't support it.

02:31:39,140 --> 02:31:40,340
It says skip.

02:31:40,340 --> 02:31:43,470
So there's multiple variations of these skips,

02:31:43,470 --> 02:31:47,680
so the one you are interested in is...

02:31:47,680 --> 02:31:49,300
I guess that's the thing.

02:31:49,300 --> 02:31:52,850
So it's a complex set of checks

02:31:52,850 --> 02:31:54,350
that are made on the features.

02:31:56,800 --> 02:32:00,990
So some of the shell scripts do check

02:32:00,990 --> 02:32:05,010
config options and binaries don't always.

02:32:05,010 --> 02:32:07,030
They work in a different way.

02:32:07,030 --> 02:32:10,280
'Cause we have bunch of things that we load.

02:32:10,280 --> 02:32:13,400
Modules get loaded, test modules need to be loaded also.

02:32:16,775 --> 02:32:19,270
I think my goal is...

02:32:19,270 --> 02:32:21,120
This is why I do these sessions.

02:32:21,960 --> 02:32:24,760
As people come up and say, "We want to run those tests."

02:32:28,780 --> 02:32:31,400
I want to be able to make that happen.

02:32:31,400 --> 02:32:32,510
Obviously with your help,

02:32:32,510 --> 02:32:34,710
because I won't be writing all the code,

02:32:34,710 --> 02:32:36,570
so you'll be helping me,

02:32:36,570 --> 02:32:38,503
helping kselftest get there.

02:32:45,350 --> 02:32:47,060
So do you have a follow up question?

02:32:52,670 --> 02:32:55,250
- It's kind of multiple questions,

02:32:55,250 --> 02:32:58,960
are distributions packaging self test

02:32:58,960 --> 02:33:01,757
and installing on other systems today?

02:33:01,757 --> 02:33:06,757
- I don't believe so.

02:33:07,244 --> 02:33:08,744
You're not, right?

02:33:12,490 --> 02:33:15,672
- And if distributions did do this,

02:33:15,672 --> 02:33:20,672
do you think use of kselftest would become more prominent?

02:33:21,030 --> 02:33:22,420
Is that what you're trying to push?

02:33:23,450 --> 02:33:26,550
- Yes and no, we are using it in primarily,

02:33:26,550 --> 02:33:31,360
in our integration test cycles currently, right?

02:33:35,856 --> 02:33:39,890
I think you are interested in having that tested in distros.

02:33:39,890 --> 02:33:40,723
- Yes.

02:33:41,830 --> 02:33:45,700
Part of my problem is, I'm kind of leading an effort,

02:33:45,700 --> 02:33:49,380
inside of Red Hat to get developers to write more tests

02:33:49,380 --> 02:33:52,074
and a lot of the questions I have is,

02:33:52,074 --> 02:33:54,700
"I have a shell script right in my hand,

02:33:54,700 --> 02:33:56,800
"but I don't have a framework to wrap it around."

02:33:56,800 --> 02:33:59,804
So they're always asking, "What framework do I use?"

02:33:59,804 --> 02:34:01,878
A lot of times we push it to LTP.

02:34:01,878 --> 02:34:02,711
It's a good, stable framework,

02:34:02,711 --> 02:34:04,560
a lot of people can help you with that.

02:34:05,987 --> 02:34:08,510
A lot of times, lately people have been looking

02:34:08,510 --> 02:34:10,410
at self test like, well is this a better option?

02:34:10,410 --> 02:34:12,610
It's got a framework that's inside the kernel.

02:34:13,560 --> 02:34:14,560
How do you use that?

02:34:15,668 --> 02:34:17,386
And I thought about if we packaged that

02:34:17,386 --> 02:34:21,620
and pushed it out and wrap our test harness around it,

02:34:21,620 --> 02:34:24,360
would that be useful to push?

02:34:24,360 --> 02:34:26,890
I'm just trying to wrap my head around...

02:34:26,890 --> 02:34:28,910
- So I think it would be useful

02:34:28,910 --> 02:34:33,850
because the pros of the kernelselftest is

02:34:33,850 --> 02:34:36,130
the reason we kept it with the kernel sources

02:34:36,130 --> 02:34:40,650
is because that we can ship the kernel

02:34:40,650 --> 02:34:43,910
with the tests that test the kernel.

02:34:43,910 --> 02:34:47,340
As we add new features, we add tests as well.

02:34:47,340 --> 02:34:48,620
Which is what we do.

02:34:50,079 --> 02:34:52,550
- More important is, my more concern is for

02:34:52,550 --> 02:34:55,424
the rel kernel a lot of times we push things out,

02:34:55,424 --> 02:34:56,257
things are broken, you have to revert it.

02:34:56,257 --> 02:34:59,000
So reverting the patch, that causes a problem

02:34:59,000 --> 02:35:01,790
along with the test case is usually a big one too.

02:35:02,870 --> 02:35:04,470
So that's why I like your model.

02:35:05,800 --> 02:35:08,690
- Right, but having both in the kernel

02:35:08,690 --> 02:35:11,730
helps you with that model, that's what you're saying?

02:35:11,730 --> 02:35:16,420
So that is the plus point of that,

02:35:16,420 --> 02:35:21,243
and then the negative with having,

02:35:22,590 --> 02:35:26,010
because we're actually moving, moving tests

02:35:26,010 --> 02:35:28,440
and the kernel at the same time.

02:35:28,440 --> 02:35:30,940
So tests are going to be broken.

02:35:30,940 --> 02:35:33,650
It's an expected thing because they are c7.

02:35:33,650 --> 02:35:35,290
So you are going to see that.

02:35:35,290 --> 02:35:39,270
So you will have probably kernel bugs

02:35:39,270 --> 02:35:41,867
and as well as test bugs.

02:35:41,867 --> 02:35:45,170
Those need to be fixed as well.

02:35:46,240 --> 02:35:47,490
That's the reality of it.

02:35:49,816 --> 02:35:51,640
- So who would own those broken tests?

02:35:51,640 --> 02:35:53,720
Would it be the subsystem maintainer,

02:35:53,720 --> 02:35:55,260
would it be somebody else?

02:35:59,600 --> 02:36:02,390
- Well it's the same kernel development process

02:36:02,390 --> 02:36:03,390
that happens, right?

02:36:04,900 --> 02:36:07,780
So whoever writes the task fixes it.

02:36:07,780 --> 02:36:11,400
- What I'm trying to get to is if you are sending a patch in

02:36:11,400 --> 02:36:14,800
that's breaking the self test for that subsystem,

02:36:14,800 --> 02:36:18,130
you probably want to be fixing that self test

02:36:18,130 --> 02:36:20,250
at that point in time and therefore,

02:36:23,608 --> 02:36:28,153
if there is a bug in the test, the test is broken,

02:36:28,153 --> 02:36:32,180
that means the process is broken.

02:36:32,180 --> 02:36:35,420
- So let's address that in a bit.

02:36:36,728 --> 02:36:38,190
Just hang on.

02:36:38,190 --> 02:36:40,687
So to answer your question, I think it would...

02:36:45,260 --> 02:36:50,260
Running kselftest in distros will,

02:36:50,400 --> 02:36:54,070
I think that kselftest enhancements will happen.

02:36:54,070 --> 02:36:56,650
Like for example you might have.

02:36:56,650 --> 02:37:00,370
We have pulled in a lot of tests the same way.

02:37:00,370 --> 02:37:03,420
Several developers had tests sitting in the gits

02:37:03,420 --> 02:37:05,150
and then we included them in the kernel

02:37:05,150 --> 02:37:06,550
and we are running them now.

02:37:07,443 --> 02:37:10,580
BPF came in that way, futex just came in that way,

02:37:10,580 --> 02:37:13,560
timer just came in that way, so we have...

02:37:15,621 --> 02:37:17,900
Kernel developers, if they had their tests

02:37:17,900 --> 02:37:20,320
sitting in their private gits,

02:37:20,320 --> 02:37:22,940
they brought them in, which is good, right?

02:37:24,040 --> 02:37:27,580
I think that if distros get involved,

02:37:27,580 --> 02:37:32,340
I think kselftest all of a sudden will have more tests.

02:37:33,520 --> 02:37:34,580
I want to see that.

02:37:35,890 --> 02:37:39,740
What I'm saying is there are some pain points

02:37:39,740 --> 02:37:42,620
with that approach as well, meaning

02:37:42,620 --> 02:37:45,710
when you are coming in, you do have to expect

02:37:46,710 --> 02:37:49,250
because developers are writing new tests

02:37:49,250 --> 02:37:52,430
and those tests might not always behave.

02:37:52,430 --> 02:37:55,900
I mean, there aren't test bugs, but expectation right.

02:37:55,900 --> 02:37:58,080
Dan will get into this in a little bit.

02:37:58,080 --> 02:38:00,190
Dan has more experience on that.

02:38:01,350 --> 02:38:06,350
What happens is we expect tests to skip gracefully.

02:38:11,400 --> 02:38:13,260
Those are the kinds of bugs I'm talking about.

02:38:13,260 --> 02:38:14,910
So they might not happen.

02:38:14,910 --> 02:38:17,230
We find them in linux-next,

02:38:17,230 --> 02:38:20,370
just like in every other kernel bug we find.

02:38:20,370 --> 02:38:22,200
Integration cycle, we do find them.

02:38:24,330 --> 02:38:26,330
And some tests, depending on the cycles

02:38:26,330 --> 02:38:27,930
of when maintainers choose to...

02:38:31,090 --> 02:38:33,420
Self tests flow a little bit differently.

02:38:33,420 --> 02:38:36,510
I maintain the framework, I maintain the tests,

02:38:36,510 --> 02:38:39,150
however individual tests go through

02:38:39,150 --> 02:38:42,390
maintainers tree sometimes, if they have dependencies.

02:38:42,390 --> 02:38:44,340
For example there is a new feature

02:38:44,340 --> 02:38:47,970
that went into a MM area for example.

02:38:47,970 --> 02:38:50,970
So those tests, new tests, they go in,

02:38:50,970 --> 02:38:54,170
they go through MM trees.

02:38:54,170 --> 02:38:55,220
For good reason, see.

02:38:56,499 --> 02:38:58,220
'Cause if we try to...

02:38:58,220 --> 02:39:01,360
So that's how it's working right now.

02:39:01,360 --> 02:39:03,450
Because we're encouraging...

02:39:03,450 --> 02:39:06,350
I want to kind of say, "Hey, let the tests get in."

02:39:07,310 --> 02:39:09,670
If there are dependencies between trees,

02:39:09,670 --> 02:39:10,820
let's work it that way.

02:39:11,928 --> 02:39:13,850
And we work these things out in linux-next.

02:39:14,760 --> 02:39:19,760
So as a result what happens is close to the merge window,

02:39:19,910 --> 02:39:24,520
depending on when the content gets into linux-next,

02:39:25,770 --> 02:39:28,130
sometimes we don't find them soon enough,

02:39:28,130 --> 02:39:30,990
so it might be that we're finding them

02:39:30,990 --> 02:39:34,520
after release comes out and then just like,

02:39:34,520 --> 02:39:36,610
last minute bugs that get found.

02:39:36,610 --> 02:39:39,590
So they end up going into .1 release of this table.

02:39:42,490 --> 02:39:46,160
I'm thinking you have a question, right?

02:39:48,329 --> 02:39:51,870
- Kind of a comment, so I'm a kernel maintainer for Ubuntu.

02:39:51,870 --> 02:39:54,190
We run a subset of the self test

02:39:54,190 --> 02:39:56,100
as part of our release testing

02:39:57,100 --> 02:40:01,300
and one of the things related to what you were saying

02:40:01,300 --> 02:40:04,790
is the more that the tests can remain,

02:40:04,790 --> 02:40:08,900
coupled to the commits that have the changes

02:40:08,900 --> 02:40:10,570
they're testing, that's a big help

02:40:10,570 --> 02:40:15,570
because one thing that we run into is with stable updates,

02:40:17,090 --> 02:40:20,180
they might back-port a fix but the test needs to change too

02:40:20,180 --> 02:40:21,430
and that doesn't get back-ported

02:40:21,430 --> 02:40:22,930
and now our tests are failing.

02:40:23,910 --> 02:40:28,090
So, you know, the more we can keep those things together,

02:40:28,090 --> 02:40:30,390
that's a big help to distributions I think

02:40:30,390 --> 02:40:32,120
to being able to use these tests.

02:40:33,610 --> 02:40:37,630
And the other thing is like with the...

02:40:37,630 --> 02:40:41,010
I guess what I would like to see is if we could have,

02:40:41,010 --> 02:40:45,980
more of a CI type of testing per kselftest in linux-next

02:40:45,980 --> 02:40:49,010
so that when we get to rc1 hopefully we don't have,

02:40:49,910 --> 02:40:53,300
kselftest failures that are just because you know,

02:40:53,300 --> 02:40:54,610
the test didn't get updated

02:40:54,610 --> 02:40:56,550
or somebody actually introduced a regression

02:40:56,550 --> 02:40:59,550
and they would have caught it if they had run the kselftest.

02:41:01,390 --> 02:41:03,370
- So that's a pain point for me as well.

02:41:03,370 --> 02:41:05,940
So I am actually furiously by,

02:41:05,940 --> 02:41:07,870
after the merge window sometimes

02:41:07,870 --> 02:41:12,753
and once the rc7 or rc8 comes out I do find

02:41:15,700 --> 02:41:20,190
kselftest problems and I'm looking to fix them.

02:41:20,190 --> 02:41:24,340
- From a maintainers perspective, if I do self tests,

02:41:25,464 --> 02:41:27,510
well, not if I do, I do self test

02:41:27,510 --> 02:41:30,430
and it's a requirement that if something goes to the tree

02:41:30,430 --> 02:41:32,360
there is self test attached to it,

02:41:33,720 --> 02:41:35,790
but it requires me right now, and this is related

02:41:35,790 --> 02:41:38,780
to what Seth has been saying, requires me right now,

02:41:38,780 --> 02:41:40,460
before I accept something into my tree,

02:41:40,460 --> 02:41:41,310
which I obviously do.

02:41:41,310 --> 02:41:43,570
Then I compile all of the tests

02:41:43,570 --> 02:41:46,048
that I have added before and I run them

02:41:46,048 --> 02:41:48,140
and I check if everything still succeeds, right?

02:41:48,140 --> 02:41:50,230
But this is only for my tree,

02:41:50,230 --> 02:41:53,555
I'm not cross checking what other trees are going in,

02:41:53,555 --> 02:41:55,530
so if linux-next would, for example tell me,

02:41:55,530 --> 02:41:58,440
"By the way, one of your tasks is failing."

02:41:58,440 --> 02:42:00,762
That would be really valuable.

02:42:00,762 --> 02:42:04,020
- Okay, so that would be something we can look into adding.

02:42:04,020 --> 02:42:05,430
Definitely if that helps.

02:42:13,255 --> 02:42:14,755
Go ahead.

02:42:14,755 --> 02:42:18,420
- I was just wondering, you know how we have the convention

02:42:18,420 --> 02:42:20,380
when you fix a bug, you have that fixes tag

02:42:20,380 --> 02:42:23,270
that refers to where the bug was introduced?

02:42:23,270 --> 02:42:26,770
If you add a tests tag that referred

02:42:26,770 --> 02:42:29,960
to when the feature was added, that would be a way

02:42:29,960 --> 02:42:32,268
to build a relationship between when you add the test

02:42:32,268 --> 02:42:34,950
and you have that test tag which references,

02:42:34,950 --> 02:42:37,130
the git commit with that feature,

02:42:37,130 --> 02:42:39,290
and then you could use that to figure out

02:42:39,290 --> 02:42:41,280
which tests to run and you could also

02:42:43,210 --> 02:42:44,700
understand much better what that relationship

02:42:44,700 --> 02:42:45,880
is between when the tests are added

02:42:45,880 --> 02:42:46,960
and when the features were.

02:42:46,960 --> 02:42:48,930
Even if the feature was added a long time ago,

02:42:48,930 --> 02:42:50,040
you could have that relationship

02:42:50,040 --> 02:42:51,580
and that would help people figure out,

02:42:51,580 --> 02:42:56,044
okay this feature is here and you know,

02:42:56,044 --> 02:42:56,877
that might be useful.

02:42:56,877 --> 02:42:58,460
- We'll have to look into that.

02:42:58,460 --> 02:43:02,100
The test files, and Dan is trying to...

02:43:02,100 --> 02:43:06,990
So to answer your question about linus-next testing,

02:43:06,990 --> 02:43:10,060
CI folks do that, Leonardo, they have been doing that.

02:43:10,060 --> 02:43:11,030
They do report.

02:43:11,030 --> 02:43:13,650
They send it to kselftest.

02:43:13,650 --> 02:43:16,160
So I'm going to have Dan talk.

02:43:17,680 --> 02:43:20,340
- So I have kind of a user experience here.

02:43:20,340 --> 02:43:24,530
I work at Linaro, my name is Dan Rue and I work with LKFT.

02:43:24,530 --> 02:43:27,280
We do continuous integration of Linux trees,

02:43:27,280 --> 02:43:29,110
especially upstream Linux trees, mainline,

02:43:29,110 --> 02:43:31,570
next and stable and LTS branches

02:43:32,480 --> 02:43:35,690
and we've been running kselftest since we started,

02:43:35,690 --> 02:43:37,090
about two years ago.

02:43:37,090 --> 02:43:38,310
And so we have a lot of experience trying

02:43:38,310 --> 02:43:40,180
to kind of get kselftest results

02:43:40,180 --> 02:43:44,060
and I'm here for feedback on how we're running it

02:43:44,060 --> 02:43:47,160
because in some cases we're running it wrong.

02:43:48,060 --> 02:43:50,790
And I'm here to get feedback in terms

02:43:50,790 --> 02:43:54,360
of how things that we think would improve kselftest

02:43:54,360 --> 02:43:55,510
to make it more approachable

02:43:55,510 --> 02:43:58,740
for like the distro concerns are one of the main ones.

02:44:00,060 --> 02:44:04,470
So we have approximately 10 different boards that we run on.

02:44:04,470 --> 02:44:05,990
We run a variety of tests in addition

02:44:05,990 --> 02:44:08,710
to kselftest so this is just background on KFT slide.

02:44:10,580 --> 02:44:13,260
This is the aggregate number of tests

02:44:13,260 --> 02:44:14,093
that we've run over time.

02:44:14,093 --> 02:44:15,150
So we started about two years ago.

02:44:15,150 --> 02:44:16,350
You can see we've run...

02:44:17,400 --> 02:44:20,360
I guess you can't see, it's 60 some million tests in

02:44:20,360 --> 02:44:23,240
that time on the stable trees, mainline and next.

02:44:25,760 --> 02:44:27,490
So this is kind of the meat of it.

02:44:29,100 --> 02:44:31,890
This is a snapshot of our results of kselftest.

02:44:33,831 --> 02:44:35,750
On next and mainline we run the entry version

02:44:35,750 --> 02:44:38,050
of kselftest so it matches.

02:44:38,050 --> 02:44:43,050
On stable and LTS branches we try to run the latest version,

02:44:44,340 --> 02:44:46,650
the latest stable release of kselftest.

02:44:46,650 --> 02:44:50,270
So today that would be something like 5.2.11

02:44:50,270 --> 02:44:51,870
or maybe 12 now as of this week.

02:44:53,410 --> 02:44:55,530
We don't rev that automatically

02:44:55,530 --> 02:44:57,790
so some of the results don't actually show that,

02:44:57,790 --> 02:44:59,480
if you go into our database and look at our results.

02:44:59,480 --> 02:45:00,313
But that's our policy,

02:45:00,313 --> 02:45:02,210
we try to run the latest stable,

02:45:02,210 --> 02:45:03,490
against all the older branches.

02:45:03,490 --> 02:45:05,040
This is one of the more controversial parts

02:45:05,040 --> 02:45:06,640
of what we're doing.

02:45:06,640 --> 02:45:08,540
A lot of kernel engineers think that's the right way.

02:45:08,540 --> 02:45:11,220
A lot of kernel engineers decidedly don't.

02:45:13,209 --> 02:45:17,460
We kind of like it because we get a lot more tests run.

02:45:17,460 --> 02:45:18,450
The experience isn't as good

02:45:18,450 --> 02:45:20,200
because we get a lot more failures.

02:45:21,800 --> 02:45:23,470
So let me just describe this graph

02:45:23,470 --> 02:45:25,910
and then we can talk about it a little bit.

02:45:25,910 --> 02:45:30,680
So this set here, the first set is 5.3-rc7,

02:45:30,680 --> 02:45:32,620
so this is recent data from the last week

02:45:32,620 --> 02:45:34,710
and you can see the numbers of...

02:45:34,710 --> 02:45:36,630
The rows here are the different environments we run in

02:45:36,630 --> 02:45:39,650
and you can see the numbers of passes we get.

02:45:39,650 --> 02:45:42,370
These skips are kselftest admitted skips,

02:45:42,370 --> 02:45:45,190
so a test decides that it can't run for some reason.

02:45:45,190 --> 02:45:46,740
Skips are awesome.

02:45:46,740 --> 02:45:50,140
Failures, and you can see the failure counts.

02:45:50,140 --> 02:45:52,240
And then the second set of data there

02:45:52,240 --> 02:45:57,240
is 4.9.190 running kselftest from 5.1 release.

02:45:58,660 --> 02:46:00,240
That just happened to be the data I had.

02:46:00,240 --> 02:46:02,600
And then the last column, the last set of data there

02:46:02,600 --> 02:46:06,090
is 4.9.190, the same kernel

02:46:06,090 --> 02:46:08,090
but using the in-kernel version of kselftest.

02:46:08,090 --> 02:46:10,760
And so you can see the difference in quantity

02:46:10,760 --> 02:46:12,770
of passes and failures.

02:46:12,770 --> 02:46:16,110
We get about twice as many tests running successfully,

02:46:16,110 --> 02:46:18,850
if we use the latest version of kselftest,

02:46:18,850 --> 02:46:21,750
but we also get about 10x the number of failures as we do,

02:46:22,750 --> 02:46:23,810
because all of the new tests

02:46:23,810 --> 02:46:25,110
that have been written since then

02:46:25,110 --> 02:46:26,330
that don't apply to the kernel.

02:46:26,330 --> 02:46:27,230
Most of them fail.

02:46:28,767 --> 02:46:30,000
It would be nice if they skipped.

02:46:32,199 --> 02:46:34,070
- I have a quick question about the fail counts,

02:46:34,070 --> 02:46:35,820
one thing I notice when looking at kselftest

02:46:35,820 --> 02:46:37,360
and this has come up when I've been,

02:46:37,360 --> 02:46:38,890
writing my own self test,

02:46:38,890 --> 02:46:41,440
is that a lot of self tests abort early whenever.

02:46:41,440 --> 02:46:43,350
So for instance you have one suite,

02:46:43,350 --> 02:46:45,830
you have one binary that is doing 50 tests.

02:46:45,830 --> 02:46:47,450
If one of them fails it'll abort early

02:46:47,450 --> 02:46:49,660
and it won't do the rest of the tests.

02:46:49,660 --> 02:46:52,692
This happens in quite a few, there's the one for MFD

02:46:52,692 --> 02:46:53,830
and a bunch of others, they do this.

02:46:53,830 --> 02:46:55,310
The question I wanted to ask was

02:46:55,310 --> 02:46:57,920
is there a plan to sort of push for doing it,

02:46:57,920 --> 02:47:00,640
in a more traditional way for instance

02:47:00,640 --> 02:47:03,260
with other TAP based frameworks they usually,

02:47:03,260 --> 02:47:05,410
you run all of the tests and you just output

02:47:05,410 --> 02:47:06,430
which ones failed rather than,

02:47:06,430 --> 02:47:08,700
having the first failure causing an error.

02:47:08,700 --> 02:47:09,540
And I guess the question is,

02:47:09,540 --> 02:47:12,540
is the failure number actually an underestimate?

02:47:12,540 --> 02:47:15,210
Given that in many cases the test will fail early.

02:47:18,150 --> 02:47:19,620
- So I believe our parsing, Anders,

02:47:19,620 --> 02:47:20,680
maybe you can correct me if I'm wrong,

02:47:20,680 --> 02:47:25,360
rolls up the results so each set of tests shows up

02:47:25,360 --> 02:47:27,208
as a pass or a fail for us.

02:47:27,208 --> 02:47:28,041
Is that right?

02:47:28,041 --> 02:47:28,874
Yeah, I'm getting a nod.

02:47:32,860 --> 02:47:35,570
- So to answer your specific question,

02:47:35,570 --> 02:47:40,570
it depends on what the test author decides to do.

02:47:42,570 --> 02:47:44,780
If that is something we can look into,

02:47:44,780 --> 02:47:46,630
improving the framework.

02:47:46,630 --> 02:47:51,630
So to Dan and Anders, they have done a lot

02:47:51,840 --> 02:47:56,840
of work helping improve the skip parts actually.

02:47:56,990 --> 02:47:59,130
They either gave me feedback so I went

02:47:59,130 --> 02:48:04,130
and did framework enhancements to make their life easier

02:48:05,040 --> 02:48:09,680
so we have done, with the collaboration that I have

02:48:09,680 --> 02:48:13,280
with the Linado folks we have done a lot of improvements.

02:48:13,280 --> 02:48:15,870
So we keep talking about it,

02:48:15,870 --> 02:48:18,840
as I understand their pain points, we keep improving.

02:48:18,840 --> 02:48:20,780
So if that is something we can do...

02:48:22,850 --> 02:48:24,560
It is up to the test developers.

02:48:24,560 --> 02:48:26,550
The way you're writing tests, right?

02:48:26,550 --> 02:48:29,560
You're actually, I'm seeing your pat series.

02:48:29,560 --> 02:48:32,750
So sometimes what happens is,

02:48:32,750 --> 02:48:34,420
developers are doing two things.

02:48:34,420 --> 02:48:36,110
They are doing their kernel feature

02:48:36,110 --> 02:48:38,280
and they're also writing tests.

02:48:38,280 --> 02:48:41,490
And then in some cases I'm trying to fix this as well.

02:48:41,490 --> 02:48:46,490
Some cases by the time I come and comment on the framework,

02:48:47,460 --> 02:48:50,310
I have to do that myself.

02:48:51,230 --> 02:48:53,750
I might be late giving comments also.

02:48:53,750 --> 02:48:56,480
So there is all of that happening too.

02:48:56,480 --> 02:49:01,480
So I think the goal is really when you write a test,

02:49:03,540 --> 02:49:07,280
send a test, the test should skip gracefully,

02:49:07,280 --> 02:49:09,090
fail gracefully and power.

02:49:09,090 --> 02:49:11,490
It's also kselftest document, if you look at it,

02:49:12,380 --> 02:49:16,640
it clearly says run as many tests as possible,

02:49:16,640 --> 02:49:20,830
before skipping or exiting.

02:49:20,830 --> 02:49:22,700
You keep skip and keep going,

02:49:22,700 --> 02:49:24,860
but run as many tests as possible.

02:49:24,860 --> 02:49:29,830
You have 90 tests to run and only 10 can not be run,

02:49:31,180 --> 02:49:33,120
don't abort early.

02:49:33,120 --> 02:49:35,310
So the only exception to that would be,

02:49:36,457 --> 02:49:39,330
even the rootkits, some tests require root access,

02:49:39,330 --> 02:49:44,150
so my recommendation is write the test such

02:49:44,150 --> 02:49:46,870
that you are still going ahead

02:49:46,870 --> 02:49:49,560
and running the rest of the test,

02:49:49,560 --> 02:49:52,480
but just skip the ones that need a specific feature.

02:49:52,480 --> 02:49:53,490
So that's the recommendation.

02:49:53,490 --> 02:49:54,750
- I have some suggestions,

02:49:54,750 --> 02:49:56,600
but we can talk about it later because it's a bit technical.

02:49:56,600 --> 02:49:59,970
But yeah, I agree with your general point.

02:50:03,484 --> 02:50:05,101
- The question was that--

02:50:05,101 --> 02:50:05,934
- The question is, is it on the white radar?

02:50:05,934 --> 02:50:07,304
- I'm sorry?

02:50:07,304 --> 02:50:08,780
- I'm sorry, mine or his?

02:50:08,780 --> 02:50:09,613
- Mine.

02:50:09,613 --> 02:50:10,770
It was, is it on your radar effectively

02:50:10,770 --> 02:50:12,790
because if a test fails early,

02:50:13,780 --> 02:50:16,650
the fail count you have there will be an underestimate.

02:50:17,810 --> 02:50:19,380
As in are you aware of that and is there a plan

02:50:19,380 --> 02:50:22,030
to work on that was the general question.

02:50:22,030 --> 02:50:24,260
- Why do you say that skips are awesome?

02:50:24,260 --> 02:50:25,810
So consider all tests are skips

02:50:26,730 --> 02:50:29,060
and LKFT will say that everything is good,

02:50:29,060 --> 02:50:30,800
but they actually didn't test everything.

02:50:30,800 --> 02:50:32,960
So what I'm getting at is that the CI actually need

02:50:32,960 --> 02:50:35,400
to solve the reverse problem of distros.

02:50:35,400 --> 02:50:37,660
So you have a set of tests and you need to figure out

02:50:37,660 --> 02:50:40,650
what is the configs, what are the user space packages,

02:50:40,650 --> 02:50:42,772
you need to run all of the tests?

02:50:42,772 --> 02:50:46,390
This seems to be one of the major missing features,

02:50:46,390 --> 02:50:48,300
in the case of this.

02:50:48,300 --> 02:50:51,340
And the CI's kind of the main use case for any test suite.

02:50:51,340 --> 02:50:54,400
- I like skips because it usually means the test...

02:50:54,400 --> 02:50:56,520
A good skip means that the test is inappropriate to run.

02:50:56,520 --> 02:50:59,950
We're running on a lot of small boards with limited memory,

02:50:59,950 --> 02:51:02,760
limited capacity or an architecture

02:51:02,760 --> 02:51:04,170
that isn't supported by the test

02:51:04,170 --> 02:51:08,340
and so in my mind a lot of times those fail.

02:51:08,340 --> 02:51:10,340
A config doesn't exist, a config wasn't built in

02:51:10,340 --> 02:51:12,150
because sometimes a config fragment

02:51:12,150 --> 02:51:14,160
is missing from kselftest.

02:51:14,160 --> 02:51:17,350
The test will fail, it would be better if it skipped.

02:51:17,350 --> 02:51:19,780
- Well it would be better if you will have the config

02:51:19,780 --> 02:51:22,150
that this needed to run this test.

02:51:22,150 --> 02:51:24,710
- Right, but if it's not possible,

02:51:24,710 --> 02:51:26,060
there are tests that aren't possible,

02:51:26,060 --> 02:51:28,290
I mean there's an x86 test and I'm on an ARM board

02:51:28,290 --> 02:51:29,230
and I'm running all the tests.

02:51:29,230 --> 02:51:31,950
So the way we run is we use the generated,

02:51:31,950 --> 02:51:34,260
Kselftest generates a runfile for you

02:51:34,260 --> 02:51:37,970
that is like a script that iterates through all the tests

02:51:37,970 --> 02:51:39,030
and that's how we run it.

02:51:39,030 --> 02:51:41,260
So we run all the tests together.

02:51:41,260 --> 02:51:45,740
It's not sophisticated enough to deal

02:51:45,740 --> 02:51:48,600
with the board at the time of the build,

02:51:48,600 --> 02:51:50,620
in terms of the environment that it's running in.

02:51:51,690 --> 02:51:52,810
- So all the skips are kind

02:51:52,810 --> 02:51:55,780
of inherently can run on this hardware.

02:51:55,780 --> 02:51:56,613
- I doubt it.

02:51:57,810 --> 02:52:00,190
- So there's still skips that can--

02:52:00,190 --> 02:52:05,190
- So the skip means that if the kernel,

02:52:05,540 --> 02:52:07,230
the test is running on,

02:52:09,040 --> 02:52:12,102
the kernel doesn't have the support for that test to run.

02:52:12,102 --> 02:52:14,270
So that means...

02:52:15,230 --> 02:52:18,830
Dan, his point of view, he's looking at it from the point

02:52:18,830 --> 02:52:22,070
of view of his test systems, right?

02:52:22,070 --> 02:52:26,880
And they don't have, not all of the kselftests run on those.

02:52:26,880 --> 02:52:28,720
He knows that.

02:52:28,720 --> 02:52:31,580
So he's saying skips are good from his perspective

02:52:32,820 --> 02:52:35,820
that they are not reporting false failures.

02:52:37,060 --> 02:52:39,720
From that perspective it's a good thing.

02:52:39,720 --> 02:52:42,820
However, skips aren't coverage.

02:52:42,820 --> 02:52:44,870
If you're looking at the coverage angle,

02:52:44,870 --> 02:52:48,100
skips aren't doing any coverage.

02:52:48,100 --> 02:52:51,590
I mean, having 75 skips

02:52:51,590 --> 02:52:56,590
and 25 passes says either two things.

02:52:57,800 --> 02:53:02,640
One is your test system can only run 25 and it ran them

02:53:03,980 --> 02:53:08,980
and the rest 75 are skips because it couldn't run,

02:53:09,330 --> 02:53:10,880
so it correctly reported skips.

02:53:14,640 --> 02:53:16,190
- In the case of running a newer version

02:53:16,190 --> 02:53:17,820
of kselftest against an older kernel though,

02:53:17,820 --> 02:53:21,800
I would expect a lot of skips because we run this on 4.4,

02:53:21,800 --> 02:53:24,010
so if you're running kselftest from 5.2

02:53:24,010 --> 02:53:26,440
against a 4.4 kernel, there's a lot of features

02:53:26,440 --> 02:53:28,560
that it's testing for that don't exist in the kernel.

02:53:28,560 --> 02:53:30,430
- Classic examples are syscall,

02:53:30,430 --> 02:53:32,910
that are not implemented for example on some architectures

02:53:32,910 --> 02:53:36,250
where we skip self tests.

02:53:36,250 --> 02:53:37,083
- Exactly.

02:53:37,083 --> 02:53:38,330
- So I'm a little concerned now

02:53:38,330 --> 02:53:42,120
that we are just talking about tests that,

02:53:42,120 --> 02:53:43,890
or running a large set of tests

02:53:43,890 --> 02:53:45,020
and some of them will fail

02:53:45,020 --> 02:53:48,860
and not really thinking about what tests did pass,

02:53:48,860 --> 02:53:52,230
before a change and what did pass afterwards,

02:53:52,230 --> 02:53:53,680
which is kind of the CI idea.

02:53:56,400 --> 02:53:57,233
- So there's a couple of things.

02:53:57,233 --> 02:53:59,110
I wanted to address the point earlier about running,

02:53:59,110 --> 02:54:01,310
about our reports on next.

02:54:01,310 --> 02:54:04,790
We do send a report to the kselftest mailing list

02:54:04,790 --> 02:54:07,350
that iterates all of our failures that we get.

02:54:07,350 --> 02:54:09,470
It's not like sophisticated enough

02:54:09,470 --> 02:54:13,210
to figure out whose failures they are or anything like that

02:54:13,210 --> 02:54:15,920
but there is a report going out to the kselftest list

02:54:15,920 --> 02:54:17,160
and we'd love feedback on it

02:54:17,160 --> 02:54:18,720
'cause I don't know if it's useful

02:54:19,756 --> 02:54:20,589
and I don't have an example here,

02:54:20,589 --> 02:54:21,970
but you can see that on the list.

02:54:21,970 --> 02:54:23,930
- So I wonder for example, for files

02:54:23,930 --> 02:54:27,920
that have a dedicated maintainers entry for example,

02:54:27,920 --> 02:54:30,510
so that show up in a maintainers file and it's like,

02:54:30,510 --> 02:54:34,260
"This self test is maintained by this guy, send him a mail."

02:54:35,589 --> 02:54:36,970
- Yeah, we don't do that yet.

02:54:39,930 --> 02:54:44,540
- What's missing is metadata associating the test

02:54:44,540 --> 02:54:46,190
with the code.

02:54:47,400 --> 02:54:48,860
And that's something interesting

02:54:48,860 --> 02:54:50,870
that the CKI guys apparently have.

02:54:51,850 --> 02:54:54,130
CKI project has something like that.

02:54:54,130 --> 02:54:55,730
So that's something to consider.

02:55:01,250 --> 02:55:04,660
- Well I mean, can't we like, within the maintainers file,

02:55:04,660 --> 02:55:09,660
like the maintainer for whatever area of the kernel,

02:55:09,830 --> 02:55:12,620
put the self test for that area of the kernel,

02:55:12,620 --> 02:55:14,630
under their entry in the maintainers file.

02:55:14,630 --> 02:55:15,970
- We do that, yeah.

02:55:18,025 --> 02:55:19,940
- This is exactly what I did.

02:55:19,940 --> 02:55:24,940
So I have everything that's under a specific keyword,

02:55:24,960 --> 02:55:27,410
in the self tools testing self test,

02:55:28,371 --> 02:55:31,140
that directory has an entry

02:55:31,140 --> 02:55:33,820
and that's basically how it should be

02:55:33,820 --> 02:55:35,480
because then it's also guaranteed

02:55:35,480 --> 02:55:40,480
that the maintainer sees additions to the self test.

02:55:41,480 --> 02:55:43,650
So if you randomly get maintainers,

02:55:43,650 --> 02:55:46,270
he or she would be CC'd as well.

02:55:47,170 --> 02:55:49,130
And then it's also a good thing,

02:55:49,130 --> 02:55:51,860
if a maintainer can take it through their tree.

02:55:51,860 --> 02:55:53,160
- So that's what we do, right?

02:55:53,160 --> 02:55:55,320
I mean that's how we.

02:55:55,320 --> 02:55:56,460
- Yeah, this is what I do.

02:55:56,460 --> 02:55:58,280
I never knew, but for example,

02:55:58,280 --> 02:56:00,090
I don't know if it's documented anywhere,

02:56:00,090 --> 02:56:02,550
but I wasn't sure if I'm stepping for example on your foot

02:56:02,550 --> 02:56:05,010
because I just sent all of the self tests directly.

02:56:05,010 --> 02:56:07,930
- Right, so the way I would like to know about it,

02:56:07,930 --> 02:56:09,540
that you're sending the tests,

02:56:09,540 --> 02:56:11,330
because then I can look at the framework

02:56:11,330 --> 02:56:12,930
and then avoid these kinds of things,

02:56:12,930 --> 02:56:16,160
like should it skip, or, I do review those.

02:56:16,160 --> 02:56:20,650
So one of the reasons I let patches flow.

02:56:20,650 --> 02:56:25,010
I have a slide somewhere that I show how the patches flow.

02:56:25,010 --> 02:56:28,190
The reason is that I want to test in there.

02:56:28,190 --> 02:56:33,190
I don't want to be the blocker for, block the flow of tests.

02:56:34,280 --> 02:56:36,460
So that's okay, what you're doing is fine.

02:56:37,970 --> 02:56:41,130
One thing I would like to know is if you're sending tests,

02:56:41,130 --> 02:56:42,270
I would like to know about them

02:56:42,270 --> 02:56:46,040
because then I can review the framework to avoid it.

02:56:46,040 --> 02:56:47,340
And the second point is...

02:56:49,180 --> 02:56:52,450
Dan, one thing you guys can do is key off

02:56:52,450 --> 02:56:56,090
of the maintainers, get maintainers data and cc them all.

02:56:56,090 --> 02:56:58,420
Then we could run into spam too, so...

02:57:00,174 --> 02:57:01,007
- Based on what he was saying,

02:57:01,007 --> 02:57:03,440
can't you just add an entry into the maintainers file

02:57:03,440 --> 02:57:07,900
for kselftest saying we do get maintainers whatever,

02:57:07,900 --> 02:57:09,370
it automatically CC's you

02:57:09,370 --> 02:57:10,680
and it makes it a little bit easier

02:57:10,680 --> 02:57:14,540
so you don't have to ask people to cc you.

02:57:14,540 --> 02:57:19,380
- Well actually, that's how it works but in some cases,

02:57:20,738 --> 02:57:23,800
some things aren't working right,

02:57:23,800 --> 02:57:25,200
so I don't see some patches.

02:57:33,812 --> 02:57:34,920
- I believe, correct me if I'm wrong,

02:57:34,920 --> 02:57:36,040
I believe that maintainers will,

02:57:36,040 --> 02:57:38,290
if there is a more strict match

02:57:38,290 --> 02:57:40,100
of a file it will give you that maintainer,

02:57:40,100 --> 02:57:41,850
rather than the directory one.

02:57:41,850 --> 02:57:46,397
- No, it gives you everything because git maintainers,

02:57:46,397 --> 02:57:48,680
will copy in the world half the time.

02:57:48,680 --> 02:57:53,070
People will often do a manual filter on it.

02:57:53,070 --> 02:57:56,910
So for example if you got the thing

02:57:56,910 --> 02:57:58,120
that looks at the git log turned on,

02:57:58,120 --> 02:57:59,900
you'll often find you're CC'ing people who do lots

02:57:59,900 --> 02:58:01,380
of spelling fixes or whatever

02:58:01,380 --> 02:58:03,230
and they don't need that noise.

02:58:03,230 --> 02:58:05,080
So people do filter it by hand.

02:58:05,080 --> 02:58:06,620
You shouldn't really trust git maintainers

02:58:06,620 --> 02:58:07,970
to do things automatically.

02:58:11,100 --> 02:58:12,620
- That's actually why it's important

02:58:12,620 --> 02:58:15,740
that a self test associated with specific subsystem

02:58:15,740 --> 02:58:17,630
or whatever has a dedicated entry

02:58:17,630 --> 02:58:20,410
because then it will show up in git maintainers output

02:58:20,410 --> 02:58:24,900
as maintainer and then people will usually cc those I think.

02:58:24,900 --> 02:58:27,160
- So that's kind of what we have.

02:58:27,160 --> 02:58:29,150
Most new tests that get added,

02:58:30,957 --> 02:58:32,880
test maintainers add their test.

02:58:34,100 --> 02:58:35,900
But we seem to have...

02:58:35,900 --> 02:58:40,320
So reporting, I have been asking Dan reporting

02:58:40,320 --> 02:58:41,610
to be improved a bit too,

02:58:41,610 --> 02:58:45,910
so we'll figure something out in reporting for sure.

02:58:48,413 --> 02:58:51,310
- And one of the things we found with KernelCI

02:58:51,310 --> 02:58:54,550
which I suspect is also true for LKFT is

02:58:54,550 --> 02:58:57,600
that having a manual step where you go

02:58:57,600 --> 02:59:00,230
and a human goes and tells the person

02:59:00,230 --> 02:59:03,930
that they broke the thing helps a lot

02:59:03,930 --> 02:59:06,308
with people actually paying attention to the results.

02:59:06,308 --> 02:59:09,230
If you've got something like a bisect,

02:59:09,230 --> 02:59:13,930
it's real easy to get people like him implemented for boots.

02:59:13,930 --> 02:59:15,490
It's really easy to get somebody to pay attention

02:59:15,490 --> 02:59:17,640
but if you just send a mail saying,

02:59:17,640 --> 02:59:19,420
or if an automated system sends somebody a mail,

02:59:19,420 --> 02:59:21,320
saying there's a breakage somewhere,

02:59:21,320 --> 02:59:23,660
it's a lot harder to get a response than it is,

02:59:23,660 --> 02:59:26,860
if you've got a human going, there is a breakage somewhere.

02:59:26,860 --> 02:59:29,720
There is still a breakage here that's been here for a week.

02:59:29,720 --> 02:59:33,110
- Right, so that's what I told Dan and Anders.

02:59:33,110 --> 02:59:36,660
Flag me, I will go figure out how to get that happen.

02:59:36,660 --> 02:59:38,020
Because I am not...

02:59:38,020 --> 02:59:39,620
Some of these failures...

02:59:39,620 --> 02:59:40,990
We talked about it.

02:59:40,990 --> 02:59:42,100
We had a meeting.

02:59:43,170 --> 02:59:44,490
We sync sometimes.

02:59:45,770 --> 02:59:47,530
Yes that's exactly what I told him.

02:59:47,530 --> 02:59:50,480
Because what happens is these automated reports come in

02:59:50,480 --> 02:59:52,500
and they get ignored for the most part

02:59:52,500 --> 02:59:56,290
and also even if we did go to picking up git maintainers

02:59:56,290 --> 02:59:59,760
and reporting problems, it could be viewed as...

03:00:01,980 --> 03:00:03,870
There is too much volume to get ignored.

03:00:03,870 --> 03:00:05,490
So that's...

03:00:17,470 --> 03:00:22,410
So the caution, I have another session in the kernel summit.

03:00:25,910 --> 03:00:28,490
I am looking to make a recommendation

03:00:28,490 --> 03:00:30,100
because it's becoming difficult

03:00:30,100 --> 03:00:34,720
for Dan and Anders and Linado test farm.

03:00:34,720 --> 03:00:37,510
When they run the test they're trying

03:00:37,510 --> 03:00:40,100
to figure out what's the best recipe.

03:00:40,100 --> 03:00:41,800
Do they want to rev match?

03:00:41,800 --> 03:00:42,740
I'm going to make this quick.

03:00:42,740 --> 03:00:44,710
That's the outstanding question,

03:00:44,710 --> 03:00:47,870
do you rev match the kernel and self tests

03:00:47,870 --> 03:00:52,870
or do they run latest stable on older stables?

03:00:53,800 --> 03:00:56,120
There are pros and cons to both approaches

03:00:56,120 --> 03:00:58,710
so we have been talking about it.

03:00:58,710 --> 03:01:03,710
And I have said for better coverage, use latest stable.

03:01:03,850 --> 03:01:07,520
And now I'm beginning to think based on the pain...

03:01:11,881 --> 03:01:12,714
It's been painful.

03:01:12,714 --> 03:01:15,800
So I'm saying use your judgment,

03:01:15,800 --> 03:01:19,510
on how much pain you want to take.

03:01:19,510 --> 03:01:20,850
- We definitely rev match

03:01:20,850 --> 03:01:23,300
because we've had too many problems.

03:01:23,300 --> 03:01:27,750
Like even if you take 1.5.2 and you know,

03:01:27,750 --> 03:01:32,050
a newer update to 5.2, you can have breakage just between

03:01:32,050 --> 03:01:34,400
that skew so we definitely have found

03:01:34,400 --> 03:01:36,370
that rev matching is the only thing

03:01:36,370 --> 03:01:37,710
that seems to be reliable.

03:01:37,710 --> 03:01:40,430
- Right, so that's what I'm coming to.

03:01:40,430 --> 03:01:45,130
At one point it made sense because the graph I showed you,

03:01:45,130 --> 03:01:47,340
3.17, we didn't have any tests.

03:01:47,340 --> 03:01:50,730
Between 3.17 and 4.4 obviously we have more tests.

03:01:50,730 --> 03:01:54,180
It would make more sense to run 4.4 tests on 3.18

03:01:54,180 --> 03:01:58,450
but when you are coming closer to between 5.2 and 5.4

03:01:59,290 --> 03:02:01,120
you have diminishing results.

03:02:01,990 --> 03:02:03,300
Your coverage doesn't go up.

03:02:03,300 --> 03:02:04,550
You might have more skips

03:02:06,204 --> 03:02:07,630
but looks like we're out of time.

03:02:09,060 --> 03:02:11,390
Please come get me in the hallway.

03:02:16,363 --> 03:02:17,687
- All right, thanks everyone for coming.

03:02:17,687 --> 03:02:21,020
(participants clapping)

03:02:23,070 --> 03:02:25,080
- I want to say a special thank you

03:02:25,080 --> 03:02:27,450
to Major for doing all the notes.

03:02:27,450 --> 03:02:29,886
Thank you for sticking up for us.

03:02:29,886 --> 03:02:31,783

YouTube URL: https://www.youtube.com/watch?v=V0aC59xtw90


