Title: LPC2018 - When eBPF meets FUSE: Improving Performance of User File Systems
Publication date: 2018-12-04
Playlist: LPC2018 - Kernel Summit Track
Description: 
	url:  https://linuxplumbersconf.org/event/2/contributions/249/
speaker:  Ashish Bijlani (Georgia Institute of Technology)
Captions: 
	00:00:05,620 --> 00:00:12,850
good afternoon everyone and welcome can

00:00:08,710 --> 00:00:15,639
everybody hear me okay all right yeah so

00:00:12,850 --> 00:00:18,400
I'm I'm Ashish I am a PhD student at

00:00:15,639 --> 00:00:20,740
Georgia Tech and today I'll be talking

00:00:18,400 --> 00:00:23,050
about or presenting my doctoral or part

00:00:20,740 --> 00:00:25,030
of my daughter on research that focuses

00:00:23,050 --> 00:00:28,330
on improving the performance of user

00:00:25,030 --> 00:00:32,110
file systems specifically I'll be

00:00:28,330 --> 00:00:33,790
talking about how you can use EBP F to

00:00:32,110 --> 00:00:37,809
improve the performance of few file

00:00:33,790 --> 00:00:39,489
systems and before I start I just want

00:00:37,809 --> 00:00:41,710
to say that the reason I'm presenting

00:00:39,489 --> 00:00:43,510
this is you know this way is so that the

00:00:41,710 --> 00:00:46,149
camera captures me and not my laptop

00:00:43,510 --> 00:00:50,069
this is not my presentation style all

00:00:46,149 --> 00:00:53,109
right so let's get started

00:00:50,069 --> 00:00:56,199
unfortunately the world we live in is

00:00:53,109 --> 00:00:59,620
divided and it's divided into kernel and

00:00:56,199 --> 00:01:04,180
user file systems and each has its own

00:00:59,620 --> 00:01:07,090
pros and cons for example kernel file

00:01:04,180 --> 00:01:09,880
system give you native performance but

00:01:07,090 --> 00:01:13,450
they are not easy to develop they are

00:01:09,880 --> 00:01:17,619
not easy to debug in maintain an example

00:01:13,450 --> 00:01:20,439
would be exe 4 on contrast there are

00:01:17,619 --> 00:01:22,810
user file systems that provide improved

00:01:20,439 --> 00:01:25,149
reliability security they are easy to

00:01:22,810 --> 00:01:28,450
develop debug maintained but they offer

00:01:25,149 --> 00:01:33,039
poor performance an example would be

00:01:28,450 --> 00:01:34,960
Gluster quite popular and Inc FS so poor

00:01:33,039 --> 00:01:38,350
performance is going to be that the

00:01:34,960 --> 00:01:41,700
focus of my talk today so with that

00:01:38,350 --> 00:01:45,549
let's get into details and talk about

00:01:41,700 --> 00:01:48,119
fuse so what is fuse fuse is a

00:01:45,549 --> 00:01:51,549
state-of-the-art framework for creating

00:01:48,119 --> 00:01:54,219
developing user file systems all file

00:01:51,549 --> 00:01:57,490
system requests are served in the user

00:01:54,219 --> 00:01:59,859
space by a fuse demon that has

00:01:57,490 --> 00:02:04,060
corresponding handlers for example look

00:01:59,859 --> 00:02:06,179
up open read write etc over hundred fuse

00:02:04,060 --> 00:02:09,570
file systems have been implemented and

00:02:06,179 --> 00:02:12,790
they spend across our two categories

00:02:09,570 --> 00:02:15,159
stackable and networked file systems so

00:02:12,790 --> 00:02:16,989
stackable file systems as the name

00:02:15,159 --> 00:02:19,270
servant it adds incremental

00:02:16,989 --> 00:02:21,600
functionality on top of

00:02:19,270 --> 00:02:25,660
underlying hosts file system for example

00:02:21,600 --> 00:02:28,270
Android SD card FS add custom security

00:02:25,660 --> 00:02:31,390
permission checks on top of ext4 file

00:02:28,270 --> 00:02:35,440
system on the other hand there are

00:02:31,390 --> 00:02:37,750
Network fuse file system that serve file

00:02:35,440 --> 00:02:42,550
system requests by talking to a remote

00:02:37,750 --> 00:02:46,260
server so further further for this talk

00:02:42,550 --> 00:02:49,960
will restrict ourselves to just the

00:02:46,260 --> 00:02:53,440
stackable fuse file system so let's look

00:02:49,960 --> 00:02:55,120
at the architecture of fuse so the most

00:02:53,440 --> 00:02:57,610
important component here is the fuse

00:02:55,120 --> 00:03:00,730
driver it's in the kernel it's a thin

00:02:57,610 --> 00:03:04,720
interposition layer that interfaces with

00:03:00,730 --> 00:03:06,370
the VFS and the second component is the

00:03:04,720 --> 00:03:09,490
fuse daemon which is in the user space

00:03:06,370 --> 00:03:13,480
it implements all file system handlers

00:03:09,490 --> 00:03:17,500
to serve requests in the user space so

00:03:13,480 --> 00:03:20,530
as applications make as applications

00:03:17,500 --> 00:03:23,740
make system calls the VFS will deliver

00:03:20,530 --> 00:03:25,840
the request to the fuse driver the fuse

00:03:23,740 --> 00:03:28,959
driver would simply forward the request

00:03:25,840 --> 00:03:35,410
to the fuse daemon which is in the user

00:03:28,959 --> 00:03:38,110
space and if the fuse file system is

00:03:35,410 --> 00:03:40,990
stackable then it would talk to the

00:03:38,110 --> 00:03:43,390
underlying filesystem lower filesystem

00:03:40,990 --> 00:03:45,340
to serve these requests on the other

00:03:43,390 --> 00:03:47,140
hand if the filesystem is over the

00:03:45,340 --> 00:03:47,620
network then it will talk over the

00:03:47,140 --> 00:03:49,360
network

00:03:47,620 --> 00:03:50,709
but for that like I said for the disk

00:03:49,360 --> 00:03:53,020
talk we'll we'll just take ourselves to

00:03:50,709 --> 00:03:57,790
stack above file systems all right so

00:03:53,020 --> 00:04:01,630
let's look at the performance of fuse so

00:03:57,790 --> 00:04:03,970
here the the benchmark that I'm using is

00:04:01,630 --> 00:04:07,120
Linux completion benchmark I'm using I'm

00:04:03,970 --> 00:04:09,220
trying to compile la Linux force 17 the

00:04:07,120 --> 00:04:13,180
Machine I'm using is quad-core Intel

00:04:09,220 --> 00:04:14,950
machine and I'm using SSD and there's a

00:04:13,180 --> 00:04:18,760
particular version of lip fuse that I'm

00:04:14,950 --> 00:04:19,540
using so x-axis compares native which is

00:04:18,760 --> 00:04:22,540
ext4

00:04:19,540 --> 00:04:24,970
and fuse performance y-axis shows the

00:04:22,540 --> 00:04:27,490
time in seconds and it's the build time

00:04:24,970 --> 00:04:32,050
time taken to compile the Linux kernel

00:04:27,490 --> 00:04:33,040
and as seen there is about 17.5 for you

00:04:32,050 --> 00:04:36,790
know overhead percentage

00:04:33,040 --> 00:04:42,940
overhead with Sue's so let's understand

00:04:36,790 --> 00:04:45,790
why so for that I think the main cause

00:04:42,940 --> 00:04:48,250
of the performance overhead infused is

00:04:45,790 --> 00:04:52,930
the context switch that occurs for every

00:04:48,250 --> 00:04:55,420
request and what happens is that when

00:04:52,930 --> 00:04:58,930
the application is making a file system

00:04:55,420 --> 00:05:01,540
call for example open so the application

00:04:58,930 --> 00:05:03,630
will do open on Mount is where fuse is

00:05:01,540 --> 00:05:07,540
mounted so application would do mount

00:05:03,630 --> 00:05:11,370
open on some file then the the request

00:05:07,540 --> 00:05:13,810
will be delivered to the fuse driver and

00:05:11,370 --> 00:05:17,200
but the requests that are delivered are

00:05:13,810 --> 00:05:19,660
for example in case of open the internal

00:05:17,200 --> 00:05:22,870
request is delivered by VFS which says

00:05:19,660 --> 00:05:25,210
ok this is the path component and give

00:05:22,870 --> 00:05:27,940
me the inode 4 for this that will be the

00:05:25,210 --> 00:05:31,120
lookup operation and similarly lookup

00:05:27,940 --> 00:05:34,120
operation lookup requests will be issued

00:05:31,120 --> 00:05:35,710
for all path components so for foo one

00:05:34,120 --> 00:05:36,850
for foo one for bar and if there are

00:05:35,710 --> 00:05:40,240
more than you know

00:05:36,850 --> 00:05:42,670
additional lookup requests such liquid

00:05:40,240 --> 00:05:46,270
lookup requests go to the fuse driver

00:05:42,670 --> 00:05:48,010
and then there's this context switch

00:05:46,270 --> 00:05:51,850
that happens the requests are simply

00:05:48,010 --> 00:05:55,120
forwarded to the fuse daemon where the

00:05:51,850 --> 00:05:58,120
fuse demon would talk to the lower FS to

00:05:55,120 --> 00:06:00,460
serve these requests so as you see there

00:05:58,120 --> 00:06:05,440
are multiple contexts which is for one

00:06:00,460 --> 00:06:07,780
open request so let's look at let's look

00:06:05,440 --> 00:06:10,840
at the the number of requests that is

00:06:07,780 --> 00:06:14,830
delivered to the fuse demon in case of

00:06:10,840 --> 00:06:18,430
Linux completion benchmark so again I'm

00:06:14,830 --> 00:06:21,520
compiling Linux for 17 and this graph

00:06:18,430 --> 00:06:23,820
shows the number of requests so x-axis

00:06:21,520 --> 00:06:26,830
will show the type of each request and

00:06:23,820 --> 00:06:29,800
y-axis is showing the number of requests

00:06:26,830 --> 00:06:32,230
in thousands so as you can see this

00:06:29,800 --> 00:06:32,950
benchmark is very heavy on metadata

00:06:32,230 --> 00:06:35,770
requests

00:06:32,950 --> 00:06:39,250
so there are lookup requests there are

00:06:35,770 --> 00:06:42,490
get attribute requests also get extended

00:06:39,250 --> 00:06:46,240
attribute requests apart from the

00:06:42,490 --> 00:06:50,860
regular I or II Drive request

00:06:46,240 --> 00:06:53,560
so what do we how can we how can we

00:06:50,860 --> 00:06:56,500
reduce the number of requests to the

00:06:53,560 --> 00:06:58,860
fuse demon which will in turn reduce the

00:06:56,500 --> 00:07:06,610
number of context switches well

00:06:58,860 --> 00:07:08,740
fortunately fuse has some Wow okay

00:07:06,610 --> 00:07:12,130
so fortunately fuse has some bra

00:07:08,740 --> 00:07:17,860
optimization parameters and then you

00:07:12,130 --> 00:07:21,190
could use for example you can use entry

00:07:17,860 --> 00:07:23,280
time out in attribute timeout to ask the

00:07:21,190 --> 00:07:27,580
fuse driver to cash some of the get

00:07:23,280 --> 00:07:30,009
attribute requests and get an lookup

00:07:27,580 --> 00:07:32,020
request in the corner so if the colonel

00:07:30,009 --> 00:07:33,940
is cashing a lot of these requests then

00:07:32,020 --> 00:07:35,440
you would assume you would think the

00:07:33,940 --> 00:07:38,070
number of requests being delivered to

00:07:35,440 --> 00:07:41,409
the to the fuse team would reduce

00:07:38,070 --> 00:07:43,270
similarly because the requests are being

00:07:41,409 --> 00:07:45,389
simply forwarded to the user space where

00:07:43,270 --> 00:07:48,099
they are served there is a lot of i/o

00:07:45,389 --> 00:07:51,220
there's a lot of data copying for i/o

00:07:48,099 --> 00:07:53,699
you can use splice read write move to

00:07:51,220 --> 00:07:56,710
reduce the number of copies

00:07:53,699 --> 00:07:58,389
so let's look what let's look at the

00:07:56,710 --> 00:08:01,599
performance and you know see what

00:07:58,389 --> 00:08:04,509
happens when you when you enable these

00:08:01,599 --> 00:08:07,150
optimizations so I've enabled these

00:08:04,509 --> 00:08:10,419
optimizations here so I've enabled

00:08:07,150 --> 00:08:12,820
splice I've enabled I've specified a

00:08:10,419 --> 00:08:15,820
nonzero entry timeout which would say

00:08:12,820 --> 00:08:18,880
okay if there are lookup requests cache

00:08:15,820 --> 00:08:21,580
them in the kernel similarly if if there

00:08:18,880 --> 00:08:23,560
is get attribute request because of this

00:08:21,580 --> 00:08:25,509
non zero attribute timeout these

00:08:23,560 --> 00:08:28,330
requests will be cached in the or these

00:08:25,509 --> 00:08:30,490
replies will be cached in the kernel and

00:08:28,330 --> 00:08:33,550
again the benchmark is the same this

00:08:30,490 --> 00:08:36,310
shows the x-axis will compare Native

00:08:33,550 --> 00:08:38,529
regular optimized fuse performance and

00:08:36,310 --> 00:08:41,440
this is again the build time in seconds

00:08:38,529 --> 00:08:47,200
in Y on y-axis so as you can see the

00:08:41,440 --> 00:08:51,190
optimizations do not help much why is

00:08:47,200 --> 00:08:53,529
that okay so to understand why let's

00:08:51,190 --> 00:08:55,060
look at the number of requests that are

00:08:53,529 --> 00:08:57,730
being you know that is being delivered

00:08:55,060 --> 00:09:00,190
to the fuse daemon in each of these

00:08:57,730 --> 00:09:03,190
cases so

00:09:00,190 --> 00:09:06,579
again x-axis shows the type of request

00:09:03,190 --> 00:09:08,889
y-axis shows the number of requests in

00:09:06,579 --> 00:09:13,629
thousands and I'm comparing regular fuse

00:09:08,889 --> 00:09:15,940
and optimized fuse as you can see there

00:09:13,629 --> 00:09:20,290
are four times fewer lookups which is

00:09:15,940 --> 00:09:26,860
good because we enable our nonzero entry

00:09:20,290 --> 00:09:29,850
timer right but the number of get

00:09:26,860 --> 00:09:32,410
attribute requests actually increases

00:09:29,850 --> 00:09:34,839
also the number of get extended

00:09:32,410 --> 00:09:39,310
attribute requests it's the same so

00:09:34,839 --> 00:09:42,399
what's going on well what happens is

00:09:39,310 --> 00:09:45,310
that when a file is read in the kernel

00:09:42,399 --> 00:09:47,769
the a time changes the fewest rival will

00:09:45,310 --> 00:09:51,310
change the a type which will invalidate

00:09:47,769 --> 00:09:54,879
the cached attribute so next time the

00:09:51,310 --> 00:09:56,470
requests get attribute request or get

00:09:54,879 --> 00:09:59,980
extended get attribute request will be

00:09:56,470 --> 00:10:02,050
will be sent to the user space hence the

00:09:59,980 --> 00:10:04,300
number does not really decrease it

00:10:02,050 --> 00:10:06,850
actually increases because it's trying

00:10:04,300 --> 00:10:12,670
to flush out the stale attributes from

00:10:06,850 --> 00:10:16,029
the kernel and because there is a

00:10:12,670 --> 00:10:18,370
extended attribute handler implemented

00:10:16,029 --> 00:10:21,519
in the in the user space by the few

00:10:18,370 --> 00:10:24,639
steamin for every write request just

00:10:21,519 --> 00:10:28,180
like the VFS issues lookup request for

00:10:24,639 --> 00:10:30,639
every open system call for every write

00:10:28,180 --> 00:10:33,310
system called there's an internal get at

00:10:30,639 --> 00:10:35,139
get extended attribute request issued to

00:10:33,310 --> 00:10:38,230
the fuse driver by the VFS to read

00:10:35,139 --> 00:10:39,939
security labels so you can see the

00:10:38,230 --> 00:10:41,319
number is almost the same the number of

00:10:39,939 --> 00:10:44,639
write requests and the number of guests

00:10:41,319 --> 00:10:48,699
get extended attribute request the same

00:10:44,639 --> 00:10:50,290
and there is no caching of extended

00:10:48,699 --> 00:10:54,009
attributes in the kernel right now the

00:10:50,290 --> 00:10:56,410
fuse driver so what can we do how can we

00:10:54,009 --> 00:10:58,839
reduce the number of requests in the

00:10:56,410 --> 00:11:00,819
user space and you know thereby reducing

00:10:58,839 --> 00:11:06,000
content number of contexts which is an

00:11:00,819 --> 00:11:09,189
increase in performance entery BPF so

00:11:06,000 --> 00:11:12,100
BPF is a it's berkeley packet filter

00:11:09,189 --> 00:11:14,140
it's a pseudo machine architecture that

00:11:12,100 --> 00:11:18,460
was introduced a while back

00:11:14,140 --> 00:11:21,640
recently a BPF extends that the BPF

00:11:18,460 --> 00:11:25,260
virtual machine architecture and it's it

00:11:21,640 --> 00:11:28,720
actually introduces multiple

00:11:25,260 --> 00:11:30,940
improvements over over BPF and it has

00:11:28,720 --> 00:11:32,920
now evolved as a generic kernel

00:11:30,940 --> 00:11:35,080
extension framework it's being used by

00:11:32,920 --> 00:11:39,790
tracing perf and network subsystems

00:11:35,080 --> 00:11:45,370
currently so let's start with a little

00:11:39,790 --> 00:11:46,930
overview of a BBF so like I said it's a

00:11:45,370 --> 00:11:49,300
pseudo machine architecture so the

00:11:46,930 --> 00:11:51,100
extensions are written in C you can

00:11:49,300 --> 00:11:52,660
extend the functionality of the kernel

00:11:51,100 --> 00:11:55,420
at runtime the extensions will be

00:11:52,660 --> 00:11:58,060
written in C and user space there'll be

00:11:55,420 --> 00:12:01,450
a C program you compile the C program

00:11:58,060 --> 00:12:03,310
using LLVM you know toolchain will be a

00:12:01,450 --> 00:12:06,040
bytecode that is produced the bytecode

00:12:03,310 --> 00:12:09,040
is inserted into the kernel using a

00:12:06,040 --> 00:12:11,110
system call before that there's a

00:12:09,040 --> 00:12:13,420
verifier that kicks in it checks the

00:12:11,110 --> 00:12:15,550
integrity it takes the sanity of the of

00:12:13,420 --> 00:12:19,089
the bytecode you know making sure there

00:12:15,550 --> 00:12:21,430
are no you know buffer overflows there

00:12:19,089 --> 00:12:24,520
are no loops because it's severely

00:12:21,430 --> 00:12:27,459
restricted and the bytecode is executed

00:12:24,520 --> 00:12:30,010
as part of a virtual machine runtime its

00:12:27,459 --> 00:12:33,700
BPF virtual machine and the virtual

00:12:30,010 --> 00:12:35,380
machine can also access a certain you

00:12:33,700 --> 00:12:38,170
know whitelisted criminal functions

00:12:35,380 --> 00:12:40,870
helper functions if you will to

00:12:38,170 --> 00:12:44,920
implement that functionality at the same

00:12:40,870 --> 00:12:47,350
time there is a key value data structure

00:12:44,920 --> 00:12:50,320
called BPF map that is provided to these

00:12:47,350 --> 00:12:53,050
to these extensions in the kernel space

00:12:50,320 --> 00:12:55,930
and at the same time the map is also

00:12:53,050 --> 00:12:58,720
available to the c program to the to the

00:12:55,930 --> 00:13:01,810
user space actually we are a system call

00:12:58,720 --> 00:13:04,029
so the user space and the and the and

00:13:01,810 --> 00:13:09,910
the the bytecode can communicate with

00:13:04,029 --> 00:13:13,600
each other using a b PF map let's look

00:13:09,910 --> 00:13:16,540
at an example of ebps how you can use it

00:13:13,600 --> 00:13:20,620
so here what I'm doing is I'm counting

00:13:16,540 --> 00:13:23,770
the number of open system calls so this

00:13:20,620 --> 00:13:26,829
as I said e BPF framework is being used

00:13:23,770 --> 00:13:27,640
by tracing subsystem in kernel so there

00:13:26,829 --> 00:13:31,540
are hooks

00:13:27,640 --> 00:13:35,800
I I you know just would add this hook to

00:13:31,540 --> 00:13:38,530
sis enter open so my this is the C

00:13:35,800 --> 00:13:40,750
program that will execute inside the

00:13:38,530 --> 00:13:44,940
corner and what's going to happen is

00:13:40,750 --> 00:13:48,250
that we are going to register a map of

00:13:44,940 --> 00:13:51,210
type array because we want to just count

00:13:48,250 --> 00:13:56,290
the number of open system calls just one

00:13:51,210 --> 00:14:00,430
entry is enough the size of this counter

00:13:56,290 --> 00:14:04,150
would be you know since there is only

00:14:00,430 --> 00:14:07,240
one entry just 32 is enough to

00:14:04,150 --> 00:14:12,280
locate the entry in the map and you need

00:14:07,240 --> 00:14:14,140
a 64 bit counter value so when when the

00:14:12,280 --> 00:14:16,210
open system call is made the hook is

00:14:14,140 --> 00:14:19,630
executed what I'm doing here is I'm just

00:14:16,210 --> 00:14:22,990
looking up in the map to get this entry

00:14:19,630 --> 00:14:26,170
using the key which is just because

00:14:22,990 --> 00:14:28,300
there's only single element and and I'm

00:14:26,170 --> 00:14:30,160
in cream implementing the value for

00:14:28,300 --> 00:14:32,290
every open system call and that's how

00:14:30,160 --> 00:14:35,590
I'm keeping track of number of open

00:14:32,290 --> 00:14:38,200
system calls so far so good so how can

00:14:35,590 --> 00:14:44,320
we use a BPF to improve performance of

00:14:38,200 --> 00:14:45,940
fuse file systems all right so this is

00:14:44,320 --> 00:14:48,490
what I developed as a part of my

00:14:45,940 --> 00:14:52,330
doctoral research at Georgia Tech it's

00:14:48,490 --> 00:14:54,280
called extended fuse it's extension

00:14:52,330 --> 00:14:56,710
framework for fuse file systems what it

00:14:54,280 --> 00:14:59,410
does is it basically allows developers

00:14:56,710 --> 00:15:02,350
the fuse file system our developers to

00:14:59,410 --> 00:15:04,390
also register thin extensions in the

00:15:02,350 --> 00:15:06,280
kernel so it will have the same

00:15:04,390 --> 00:15:08,380
interface just like you your regular

00:15:06,280 --> 00:15:10,090
fuse operations if the interface will be

00:15:08,380 --> 00:15:12,760
the same the parameters will be the same

00:15:10,090 --> 00:15:15,160
you will register the extensions that

00:15:12,760 --> 00:15:17,320
you need and those will be registered in

00:15:15,160 --> 00:15:19,180
the corner and will be handled will be

00:15:17,320 --> 00:15:26,340
executed in the kernel thereby avoiding

00:15:19,180 --> 00:15:26,340
any context switch to user space and

00:15:26,610 --> 00:15:33,730
additional thing that we we do is I

00:15:30,150 --> 00:15:36,100
provide a special type of BPF maps that

00:15:33,730 --> 00:15:38,470
are only accessible to the fuse daemon

00:15:36,100 --> 00:15:41,139
and they serve as a communication

00:15:38,470 --> 00:15:44,410
channel between these extensions in the

00:15:41,139 --> 00:15:47,139
and the fuse demon in the user space and

00:15:44,410 --> 00:15:49,329
what I'm doing here is I'm trying to

00:15:47,139 --> 00:15:51,129
cache metadata because what the

00:15:49,329 --> 00:15:53,439
benchmark we saw was heavy on metadata

00:15:51,129 --> 00:15:56,079
operations a lot of metadata so what if

00:15:53,439 --> 00:16:00,669
we could use the VP of maps to cache

00:15:56,079 --> 00:16:03,369
that metadata and the extensions will be

00:16:00,669 --> 00:16:05,559
will be will be serving from these cache

00:16:03,369 --> 00:16:08,999
in the kernel and still be no or very

00:16:05,559 --> 00:16:12,970
few contexts which is to use the space

00:16:08,999 --> 00:16:21,089
so let's look at the architecture of ext

00:16:12,970 --> 00:16:25,269
fuse so there are two new components now

00:16:21,089 --> 00:16:26,919
so first is the the Lib extended fuse

00:16:25,269 --> 00:16:29,709
similar to lip fuse

00:16:26,919 --> 00:16:31,749
I provided a helper library so that

00:16:29,709 --> 00:16:33,459
developers that basically it will hide

00:16:31,749 --> 00:16:34,929
all the you know details and provide

00:16:33,459 --> 00:16:37,720
nice abstractions so that developers

00:16:34,929 --> 00:16:40,209
have the same interface and can write

00:16:37,720 --> 00:16:43,089
you know easily write their extensions

00:16:40,209 --> 00:16:46,660
in you know in C language which will be

00:16:43,089 --> 00:16:49,029
which will be compiled and inserted into

00:16:46,660 --> 00:16:52,470
the kernel obviously it'll be verified

00:16:49,029 --> 00:16:56,559
as part of the BPF IPPF framework

00:16:52,470 --> 00:17:00,249
verifier and this will be done during

00:16:56,559 --> 00:17:02,049
mount time so at Mount time so the fuse

00:17:00,249 --> 00:17:06,100
file system will have to kind of

00:17:02,049 --> 00:17:08,380
handlers one would be the fuse daemon

00:17:06,100 --> 00:17:10,360
handlers regular handlers which exist

00:17:08,380 --> 00:17:12,279
you know even today and those are you

00:17:10,360 --> 00:17:15,610
know that's actually the slow path and

00:17:12,279 --> 00:17:18,130
then there's the second type of handlers

00:17:15,610 --> 00:17:22,000
which are extensions now registered into

00:17:18,130 --> 00:17:24,699
the kernel so what happens is when the

00:17:22,000 --> 00:17:26,889
application makes is a filesystem call

00:17:24,699 --> 00:17:29,950
the the requests are delivered to the

00:17:26,889 --> 00:17:31,779
fuse driver so now the fast path will be

00:17:29,950 --> 00:17:33,669
taken as opposed to the regular slow

00:17:31,779 --> 00:17:37,240
path which is going back to the user

00:17:33,669 --> 00:17:38,590
space since we have registered we have

00:17:37,240 --> 00:17:41,019
modified fuse Drive where we have

00:17:38,590 --> 00:17:43,210
registered extensions the fast path will

00:17:41,019 --> 00:17:46,299
be taken where the the corresponding

00:17:43,210 --> 00:17:49,379
handler will be executed for example if

00:17:46,299 --> 00:17:51,760
it's fused open requests then open

00:17:49,379 --> 00:17:53,289
handler will be executed if it's fused

00:17:51,760 --> 00:17:54,490
look up and look up handler will be

00:17:53,289 --> 00:17:59,289
executed

00:17:54,490 --> 00:18:02,499
and so that will be the first path that

00:17:59,289 --> 00:18:05,559
taken inside the kernel and that's when

00:18:02,499 --> 00:18:07,629
the handler that has been implemented by

00:18:05,559 --> 00:18:11,080
these you know or developers file system

00:18:07,629 --> 00:18:12,850
developers will check if if the if the

00:18:11,080 --> 00:18:15,009
entry that you're trying to look up is

00:18:12,850 --> 00:18:17,769
already available is you know in EBP of

00:18:15,009 --> 00:18:20,320
map is already cached if it is then it

00:18:17,769 --> 00:18:22,299
will serve from the cache similarly if

00:18:20,320 --> 00:18:24,999
there are attributes that are already

00:18:22,299 --> 00:18:28,029
cached in e BPF map then those will be

00:18:24,999 --> 00:18:30,490
served from the map and if they are not

00:18:28,029 --> 00:18:33,279
then the regular slow path will be taken

00:18:30,490 --> 00:18:36,429
where the control will again go to fuse

00:18:33,279 --> 00:18:39,100
daemon and at that point since the

00:18:36,429 --> 00:18:41,139
control is to you know given to fuse

00:18:39,100 --> 00:18:42,789
daemon that means that the attributes

00:18:41,139 --> 00:18:45,820
were not cached the entries were you

00:18:42,789 --> 00:18:48,999
know not cached and that time the fuse

00:18:45,820 --> 00:18:51,220
daemon can using system calls since it

00:18:48,999 --> 00:18:54,909
can interact with the EBP F map can

00:18:51,220 --> 00:18:56,799
insert or cache metadata in EBP of map

00:18:54,909 --> 00:19:01,960
so that the future feature requests are

00:18:56,799 --> 00:19:06,669
served right in the kernel so let's look

00:19:01,960 --> 00:19:10,179
at example of exd fuse so what I'm doing

00:19:06,669 --> 00:19:13,299
here is I'm have there's a handler for

00:19:10,179 --> 00:19:15,820
get a gate attribute kernel kernel

00:19:13,299 --> 00:19:18,039
extension which will really serve cached

00:19:15,820 --> 00:19:20,379
attributes so for that we need to first

00:19:18,039 --> 00:19:23,950
cache attributes you know from fuse team

00:19:20,379 --> 00:19:27,119
so we define a map it's of type hash now

00:19:23,950 --> 00:19:29,320
because for each node ID you know file

00:19:27,119 --> 00:19:31,809
directory we need to find the

00:19:29,320 --> 00:19:33,940
corresponding attributes so the key size

00:19:31,809 --> 00:19:36,220
is the inode of the identifier of the

00:19:33,940 --> 00:19:38,049
file or directory and the value would be

00:19:36,220 --> 00:19:41,350
really what is expected by the fuse

00:19:38,049 --> 00:19:44,019
driver what is it so that it's it it

00:19:41,350 --> 00:19:46,210
returns it populates additional you know

00:19:44,019 --> 00:19:47,559
data structures and returns the final

00:19:46,210 --> 00:19:49,809
value to VFS and it goes to the

00:19:47,559 --> 00:19:54,070
application so fuse attribute out is

00:19:49,809 --> 00:19:56,220
expected by the fuse driver and so what

00:19:54,070 --> 00:20:01,720
I've done here is I've created a map of

00:19:56,220 --> 00:20:04,990
so many entries to raise to 16 and when

00:20:01,720 --> 00:20:07,900
when the request is delivered to the

00:20:04,990 --> 00:20:09,550
fuse driver the get extended request the

00:20:07,900 --> 00:20:12,640
first parts that is taken is the fast

00:20:09,550 --> 00:20:14,410
part so the get extended kernel

00:20:12,640 --> 00:20:16,690
extension here will be executed

00:20:14,410 --> 00:20:19,480
what I'm doing here is I'm first reading

00:20:16,690 --> 00:20:21,790
the parameters like just allow you just

00:20:19,480 --> 00:20:25,540
how you know you read the parameters in

00:20:21,790 --> 00:20:28,780
userspace in few steamin you would read

00:20:25,540 --> 00:20:31,840
parameters here to basically find out

00:20:28,780 --> 00:20:34,810
what what the inode number is right

00:20:31,840 --> 00:20:37,750
which is the key into this map so based

00:20:34,810 --> 00:20:40,330
on the key you would find if the value

00:20:37,750 --> 00:20:43,530
is cached or not in the map if it is

00:20:40,330 --> 00:20:46,120
cache then you would simply write the

00:20:43,530 --> 00:20:49,720
value here which is really what is

00:20:46,120 --> 00:20:52,300
expected by the fuse driver hence this

00:20:49,720 --> 00:20:54,190
if what you what you're looking for is

00:20:52,300 --> 00:20:55,390
is cache then then this will be served

00:20:54,190 --> 00:21:04,510
from the kernel and there'll be no

00:20:55,390 --> 00:21:06,820
context switches ok so now we are we are

00:21:04,510 --> 00:21:09,640
caching you know in the kernel it's all

00:21:06,820 --> 00:21:12,220
good but what about stale entries what

00:21:09,640 --> 00:21:13,990
about invalidations so it's really the

00:21:12,220 --> 00:21:16,300
responsibility of the developer to

00:21:13,990 --> 00:21:19,300
provide the right handler right

00:21:16,300 --> 00:21:21,460
extensions in the kernel so that the

00:21:19,300 --> 00:21:25,270
cached still attributes are are

00:21:21,460 --> 00:21:27,640
invalidated for example if so what's

00:21:25,270 --> 00:21:30,790
going to invalidate a cache attribute

00:21:27,640 --> 00:21:33,100
it'll be maybe a set attribute you know

00:21:30,790 --> 00:21:35,890
function that is or a request that is

00:21:33,100 --> 00:21:37,210
issued to to BFS that's when you know

00:21:35,890 --> 00:21:38,440
that you're trying to change one of

00:21:37,210 --> 00:21:40,240
these attributes and it doesn't make

00:21:38,440 --> 00:21:42,280
sense to cache those attributes anymore

00:21:40,240 --> 00:21:45,280
in the corner so the developer would

00:21:42,280 --> 00:21:47,680
register set attribute handler or the

00:21:45,280 --> 00:21:49,740
kernel extension again what I'm doing

00:21:47,680 --> 00:21:52,480
here is I'm just reading the inode

00:21:49,740 --> 00:21:54,340
number from the from you know the

00:21:52,480 --> 00:21:56,860
parameters that fuse driver provided to

00:21:54,340 --> 00:21:59,100
this extension Handler and I'm just

00:21:56,860 --> 00:22:01,930
deleting the element from the map and

00:21:59,100 --> 00:22:04,060
because it's the it's because the first

00:22:01,930 --> 00:22:06,340
part is the first part that is taken

00:22:04,060 --> 00:22:10,360
inside the kernel now there are no race

00:22:06,340 --> 00:22:13,000
conditions because because the the

00:22:10,360 --> 00:22:15,160
future request will go to the user space

00:22:13,000 --> 00:22:17,110
only after going through this so if you

00:22:15,160 --> 00:22:18,490
have invalidated the stale attributes

00:22:17,110 --> 00:22:20,940
here there will be no more race

00:22:18,490 --> 00:22:20,940
conditions

00:22:20,980 --> 00:22:26,090
so similarly you can so this was an

00:22:24,290 --> 00:22:29,600
example of how you can cache and

00:22:26,090 --> 00:22:32,390
invalidate attributes but you can also

00:22:29,600 --> 00:22:37,010
cache look up replies in extended

00:22:32,390 --> 00:22:39,080
attributes and even siblings alright so

00:22:37,010 --> 00:22:41,090
let's look at the performance of

00:22:39,080 --> 00:22:43,880
extended views and compare it to regular

00:22:41,090 --> 00:22:45,770
and optimized views so you I'm using the

00:22:43,880 --> 00:22:49,490
same kernel composition benchmarks a

00:22:45,770 --> 00:22:51,560
machine same version of diffuse and this

00:22:49,490 --> 00:22:53,740
graph compares native regular optimized

00:22:51,560 --> 00:22:58,010
the extended fuse on x-axis y-axis

00:22:53,740 --> 00:23:02,300
reproach the build time and as you can

00:22:58,010 --> 00:23:08,180
see there is the the the overhead

00:23:02,300 --> 00:23:12,140
reduces from 17.5 4% to 5.7 1% which is

00:23:08,180 --> 00:23:15,620
good however because we are caching

00:23:12,140 --> 00:23:18,800
replies in the kernel and I really used

00:23:15,620 --> 00:23:21,500
a large map so I used to raise to 16

00:23:18,800 --> 00:23:24,970
entries but if you were to use a smaller

00:23:21,500 --> 00:23:27,980
map and efficiently maintain the cache

00:23:24,970 --> 00:23:29,930
then you know depending upon your you

00:23:27,980 --> 00:23:31,630
know cache caching algorithm you would

00:23:29,930 --> 00:23:34,630
see the overhead being you know

00:23:31,630 --> 00:23:37,660
increasing we basically increase from

00:23:34,630 --> 00:23:40,490
5.71 to you know something like 7 or 8

00:23:37,660 --> 00:23:42,560
so if you really use a large cache or

00:23:40,490 --> 00:23:45,130
maintain it efficiently only then you

00:23:42,560 --> 00:23:48,020
will see performance improvement and

00:23:45,130 --> 00:23:51,070
here because I'm using a large cache

00:23:48,020 --> 00:23:55,360
there will be worst case 50 MB of memory

00:23:51,070 --> 00:23:58,250
consumption because I'm I'm I'm caching

00:23:55,360 --> 00:24:05,000
lookup requests attribute attribute

00:23:58,250 --> 00:24:07,450
replies and also extended attributes so

00:24:05,000 --> 00:24:11,260
why do we see this improvement so to

00:24:07,450 --> 00:24:14,480
understand that let's again look at the

00:24:11,260 --> 00:24:18,110
number of requests that are delivered to

00:24:14,480 --> 00:24:20,870
fuse daemon in each of these cases so

00:24:18,110 --> 00:24:23,600
I've compared regular optimized and

00:24:20,870 --> 00:24:25,580
extended fuse x-axis shows the number

00:24:23,600 --> 00:24:28,340
the type of request and y-axis shows the

00:24:25,580 --> 00:24:30,440
number of requests in thousands as you

00:24:28,340 --> 00:24:32,270
can see in case of extended fuse there

00:24:30,440 --> 00:24:34,520
are very few get attribute requests

00:24:32,270 --> 00:24:38,390
because we were able to successfully

00:24:34,520 --> 00:24:41,960
- them and in timely invalidate them by

00:24:38,390 --> 00:24:45,140
the way because the the read because the

00:24:41,960 --> 00:24:47,660
the read request invalidates a time what

00:24:45,140 --> 00:24:50,540
needs to happen to be able to

00:24:47,660 --> 00:24:52,880
successfully cash and serve attribution

00:24:50,540 --> 00:24:55,610
the kernel is the read handler in the

00:24:52,880 --> 00:24:58,820
user space after the read is done needs

00:24:55,610 --> 00:25:01,580
to insert those new attributes again in

00:24:58,820 --> 00:25:03,170
the cache so that the future requests

00:25:01,580 --> 00:25:07,460
are served from the from the cache from

00:25:03,170 --> 00:25:11,750
the map and similarly there are very few

00:25:07,460 --> 00:25:14,000
extended attribute requests for example

00:25:11,750 --> 00:25:16,370
if if the file system does not implement

00:25:14,000 --> 00:25:18,320
it doesn't have security you know labels

00:25:16,370 --> 00:25:22,750
then it will be as simple as you know

00:25:18,320 --> 00:25:27,170
caching the you know II know data reply

00:25:22,750 --> 00:25:30,380
all right so okay so what can be used

00:25:27,170 --> 00:25:32,030
this for so like I you know in this

00:25:30,380 --> 00:25:33,980
presentation I give an example how you

00:25:32,030 --> 00:25:35,780
can cache and invalidate metadata in the

00:25:33,980 --> 00:25:38,870
in the kernel and hence reduce the

00:25:35,780 --> 00:25:41,600
number of context switches this actually

00:25:38,870 --> 00:25:43,520
applies to all fused file system and

00:25:41,600 --> 00:25:48,320
could be you know potentially a part of

00:25:43,520 --> 00:25:50,330
the lip fuse similarly we can I'm this

00:25:48,320 --> 00:25:54,110
is something I'm exploring can you also

00:25:50,330 --> 00:25:55,460
cache read the results that you know

00:25:54,110 --> 00:25:58,760
that happens in in Gluster

00:25:55,460 --> 00:26:01,340
so we you you would cache those replies

00:25:58,760 --> 00:26:05,590
in the in the kernel you know as sort as

00:26:01,340 --> 00:26:08,560
an optimization in future read directly

00:26:05,590 --> 00:26:11,390
requests are served from the kernel

00:26:08,560 --> 00:26:13,760
another example or use case of this

00:26:11,390 --> 00:26:16,370
would be to perform custom filtering or

00:26:13,760 --> 00:26:19,400
permission chicks so I give an example

00:26:16,370 --> 00:26:21,200
of strf SS a popular fused filesystem

00:26:19,400 --> 00:26:25,340
what it does is that it implements

00:26:21,200 --> 00:26:27,560
custom security checks on top of ext4

00:26:25,340 --> 00:26:29,870
filesystem and those checks are

00:26:27,560 --> 00:26:32,030
primarily UID based so they will check

00:26:29,870 --> 00:26:34,130
the app ID they'll compare you know or

00:26:32,030 --> 00:26:36,350
they'll be so it maintains a list of all

00:26:34,130 --> 00:26:39,740
the apps installed in a packages lot

00:26:36,350 --> 00:26:43,100
list file which is really kept as a hash

00:26:39,740 --> 00:26:47,090
table and because we have this a BBF map

00:26:43,100 --> 00:26:48,110
here you can insert all those app ID app

00:26:47,090 --> 00:26:52,100
name in the EPP

00:26:48,110 --> 00:26:55,909
map and and enforced UID based checks in

00:26:52,100 --> 00:26:59,240
lookup and and open so you can also have

00:26:55,909 --> 00:27:03,620
you can also add you can also basically

00:26:59,240 --> 00:27:06,769
add you can use kernel helper functions

00:27:03,620 --> 00:27:08,299
so that you can get UID from the kernel

00:27:06,769 --> 00:27:13,340
you can get the name of the application

00:27:08,299 --> 00:27:15,620
in the kernel finally this is again a

00:27:13,340 --> 00:27:19,460
work-in-progress what I'm exploring is

00:27:15,620 --> 00:27:23,600
can you use BPF code to directly to

00:27:19,460 --> 00:27:25,580
bypass the to bypass the fuse daemon and

00:27:23,600 --> 00:27:29,059
directly go to the lower file system is

00:27:25,580 --> 00:27:31,909
the file system is stackable so can you

00:27:29,059 --> 00:27:34,850
install once you open the file in in

00:27:31,909 --> 00:27:38,710
userspace can you install the FD in the

00:27:34,850 --> 00:27:41,870
kernel using the e BPF in a safe manner

00:27:38,710 --> 00:27:43,399
so that the future read/write requests

00:27:41,870 --> 00:27:46,370
are directly sent to the lower file

00:27:43,399 --> 00:27:51,620
system as opposed to sending back to the

00:27:46,370 --> 00:27:54,019
user space so like I said this is a work

00:27:51,620 --> 00:27:56,450
in progress at Georgia Tech we are

00:27:54,019 --> 00:27:59,389
applying this to Android lustre and even

00:27:56,450 --> 00:28:01,309
in caphis there's a project page it's

00:27:59,389 --> 00:28:03,590
not it's not populated now I've

00:28:01,309 --> 00:28:06,260
submitted an academic paper this is what

00:28:03,590 --> 00:28:08,059
I was working on but in maybe next

00:28:06,260 --> 00:28:09,980
couple of weeks I will be I'll be

00:28:08,059 --> 00:28:11,330
populating this page you know just

00:28:09,980 --> 00:28:13,010
adding all the code and you know

00:28:11,330 --> 00:28:15,620
everything that I have so what I'm

00:28:13,010 --> 00:28:17,149
looking for from you guys is it's you

00:28:15,620 --> 00:28:19,549
know any feedbacks any suggestions that

00:28:17,149 --> 00:28:21,320
may have and I think this will be this

00:28:19,549 --> 00:28:27,980
will potentially help lot of fuse file

00:28:21,320 --> 00:28:28,710
systems thank you it will be happy to

00:28:27,980 --> 00:28:32,910
take any questions

00:28:28,710 --> 00:28:32,910
[Applause]

00:28:36,190 --> 00:28:43,490
so you said that requests are clearing

00:28:41,929 --> 00:28:46,640
the cache from the colonel have you

00:28:43,490 --> 00:28:49,610
trusted with no no access time no our

00:28:46,640 --> 00:28:51,650
time for the mount options so it yes I

00:28:49,610 --> 00:28:53,960
did and it turns out that fuse does not

00:28:51,650 --> 00:28:57,380
honor know a time and they have their

00:28:53,960 --> 00:28:59,840
own reasons I forgot why but if you

00:28:57,380 --> 00:29:02,630
specify if you amount using no wait time

00:28:59,840 --> 00:29:05,690
it doesn't really honor them general

00:29:02,630 --> 00:29:09,500
question is have you drop the caches

00:29:05,690 --> 00:29:10,460
between the tests can I drop caches

00:29:09,500 --> 00:29:13,640
between the tests

00:29:10,460 --> 00:29:16,070
yes if you test it with dropping caches

00:29:13,640 --> 00:29:18,679
know what I've tested is with the

00:29:16,070 --> 00:29:20,929
smaller BPF map size so as opposed to -

00:29:18,679 --> 00:29:22,820
this is 16 maybe you know just 512

00:29:20,929 --> 00:29:24,919
entries and I did not really see a lot

00:29:22,820 --> 00:29:26,990
of improvement and I was just there was

00:29:24,919 --> 00:29:29,540
no efficient algorithm to manage the

00:29:26,990 --> 00:29:31,730
cash but I I I believe that if there was

00:29:29,540 --> 00:29:33,169
an algorithm - you know even if you have

00:29:31,730 --> 00:29:35,059
a smaller cache and a better and

00:29:33,169 --> 00:29:36,620
efficient algorithm to manage that cache

00:29:35,059 --> 00:29:39,200
you would still see performance

00:29:36,620 --> 00:29:42,710
improvements ok ask question have you

00:29:39,200 --> 00:29:47,330
tested to the corner with kpti colonel

00:29:42,710 --> 00:29:50,390
it colonel page tables relation oh yes

00:29:47,330 --> 00:29:52,070
you from yeah so this is something you

00:29:50,390 --> 00:29:55,160
know that I plan to do I haven't tested

00:29:52,070 --> 00:29:58,070
that but III think you you're bang on I

00:29:55,160 --> 00:30:00,110
think you would because now there are

00:29:58,070 --> 00:30:02,240
you know more context switches you would

00:30:00,110 --> 00:30:03,860
expect something different and I'll post

00:30:02,240 --> 00:30:06,520
the results soon this is something I

00:30:03,860 --> 00:30:06,520
want to do yes

00:30:11,870 --> 00:30:22,710
hello - what kind of synchronization and

00:30:19,140 --> 00:30:25,410
even you used in this world and how it's

00:30:22,710 --> 00:30:31,410
bearable in terms of number of CPU cores

00:30:25,410 --> 00:30:33,060
how it works if you have - of course not

00:30:31,410 --> 00:30:45,690
I'm not sure I'm understanding did you

00:30:33,060 --> 00:30:47,700
use global so I really did not use any

00:30:45,690 --> 00:30:49,590
any locking it was part of the EBP a

00:30:47,700 --> 00:30:51,840
framework so when you are about to

00:30:49,590 --> 00:30:54,810
execute the handler or one of those

00:30:51,840 --> 00:30:57,360
extensions in the kernel the the

00:30:54,810 --> 00:30:59,580
framework takes RC lock and that's how

00:30:57,360 --> 00:31:02,970
it protects so I'd really did not have

00:30:59,580 --> 00:31:04,950
to just do that I just I so whatever was

00:31:02,970 --> 00:31:07,470
being used for tracing and network

00:31:04,950 --> 00:31:10,320
subsystem I was you know you I used that

00:31:07,470 --> 00:31:13,110
as an inspiration and just added so you

00:31:10,320 --> 00:31:21,540
start serial or no no global locks are

00:31:13,110 --> 00:31:25,410
taken so have you considered like other

00:31:21,540 --> 00:31:27,510
cases in PPF other than caching because

00:31:25,410 --> 00:31:30,750
PPF you can implement a very complicated

00:31:27,510 --> 00:31:33,270
or maybe not very complicated use cases

00:31:30,750 --> 00:31:35,730
and maybe you like in the extreme case

00:31:33,270 --> 00:31:38,640
you probably can implement a huge amount

00:31:35,730 --> 00:31:46,590
of your like a file system just all in

00:31:38,640 --> 00:31:48,180
BPF so you're right so so what I'm what

00:31:46,590 --> 00:31:49,980
I'm proposing here is a framework so

00:31:48,180 --> 00:31:51,630
it's up to the developer and there you

00:31:49,980 --> 00:31:53,190
know effort and their imagination to

00:31:51,630 --> 00:31:54,960
really come up with a complicated case

00:31:53,190 --> 00:31:57,600
but you're absolutely right

00:31:54,960 --> 00:31:59,700
so depending on how you know improved

00:31:57,600 --> 00:32:01,740
EVP have gates over the time it's you

00:31:59,700 --> 00:32:04,320
know started with you know restricted

00:32:01,740 --> 00:32:06,930
now it is evolving so you perhaps could

00:32:04,320 --> 00:32:08,820
have a full you know maybe I'll just

00:32:06,930 --> 00:32:10,260
active file system functionality in the

00:32:08,820 --> 00:32:12,420
kernel without anything in the user

00:32:10,260 --> 00:32:16,380
space in fact this is something that I'm

00:32:12,420 --> 00:32:18,240
trying with with Android if it is it

00:32:16,380 --> 00:32:20,640
possible to push all the Android you

00:32:18,240 --> 00:32:22,659
know custom checks in the kernel as part

00:32:20,640 --> 00:32:24,009
of a BPF as opposed to

00:32:22,659 --> 00:32:27,720
but I'm not I'm not sure at this point

00:32:24,009 --> 00:32:27,720
yeah thank you

00:32:33,590 --> 00:32:42,050
hi say with your library add-on does the

00:32:39,260 --> 00:32:44,300
author of the fuse file system have to

00:32:42,050 --> 00:32:46,580
do anything special or do they just use

00:32:44,300 --> 00:32:55,460
your library and it's automatic they get

00:32:46,580 --> 00:32:59,290
this caching so they're so there will be

00:32:55,460 --> 00:33:05,210
a flag that says okay now the fuse

00:32:59,290 --> 00:33:08,450
driver supports supports at the extended

00:33:05,210 --> 00:33:10,820
fuse framework but I believe law and and

00:33:08,450 --> 00:33:13,310
since the the handlers are written by

00:33:10,820 --> 00:33:16,340
developers it can be an external library

00:33:13,310 --> 00:33:18,920
and the flag can also be moved into in

00:33:16,340 --> 00:33:21,320
it where the the init function of the

00:33:18,920 --> 00:33:23,270
fuse file system or the fuse daemon can

00:33:21,320 --> 00:33:24,890
really test if the functionality is

00:33:23,270 --> 00:33:27,740
present in the kernel enable that and

00:33:24,890 --> 00:33:32,000
then insert those extensions so I would

00:33:27,740 --> 00:33:33,980
suspect very few we I mean I think less

00:33:32,000 --> 00:33:36,340
than maybe you know 50 lines of code if

00:33:33,980 --> 00:33:36,340
anything

00:33:44,510 --> 00:33:52,220
so I have a very specific question so

00:33:47,000 --> 00:33:56,690
for your example you use the PPF map as

00:33:52,220 --> 00:33:58,910
a cache but it's a fixed side storage so

00:33:56,690 --> 00:34:02,120
what is your caching strategy and like

00:33:58,910 --> 00:34:05,000
just vpf side controls like the eviction

00:34:02,120 --> 00:34:07,940
or the user side controls caching

00:34:05,000 --> 00:34:10,880
strategy so I really did not get time to

00:34:07,940 --> 00:34:12,350
come up with a very efficient you know

00:34:10,880 --> 00:34:16,010
caching mechanism I really haven't

00:34:12,350 --> 00:34:18,110
evaluated that you know deeply but but I

00:34:16,010 --> 00:34:19,640
just use a fixed size but it is

00:34:18,110 --> 00:34:21,860
something that I want to do just for

00:34:19,640 --> 00:34:23,900
every you know different sizes how does

00:34:21,860 --> 00:34:26,420
the performance change I tested the

00:34:23,900 --> 00:34:28,910
completion benchmark you know briefly

00:34:26,420 --> 00:34:30,910
but with a smaller cache but I did not

00:34:28,910 --> 00:34:32,870
come up with an efficient way of

00:34:30,910 --> 00:34:35,150
invalidating and maintaining the cache

00:34:32,870 --> 00:34:44,960
but if you do that I think it's improve

00:34:35,150 --> 00:34:50,120
it I want to understand how profit

00:34:44,960 --> 00:34:55,340
happen as I understood you get profit

00:34:50,120 --> 00:34:58,270
because you caches fuse under user get

00:34:55,340 --> 00:34:58,270
other requests

00:34:58,570 --> 00:35:09,890
comment when you first read I note you

00:35:06,410 --> 00:35:14,030
read you story team struck structure I

00:35:09,890 --> 00:35:21,110
not we just which is in container

00:35:14,030 --> 00:35:24,290
refused I not it's already a shot why

00:35:21,110 --> 00:35:31,040
what is the reason it's not enough and

00:35:24,290 --> 00:35:35,990
in plain we use what you request you do

00:35:31,040 --> 00:35:38,870
use that a request again why it's not

00:35:35,990 --> 00:35:40,310
enough that's a very good question and

00:35:38,870 --> 00:35:42,320
thank you for asking this question this

00:35:40,310 --> 00:35:46,460
gives me an opportunity to highlight why

00:35:42,320 --> 00:35:50,510
you need you know custom checks so there

00:35:46,460 --> 00:35:52,850
was a kiss some time back where it was

00:35:50,510 --> 00:35:54,650
identified that the the right absolutely

00:35:52,850 --> 00:35:56,780
right the I nodes and the entries are

00:35:54,650 --> 00:35:57,240
cash in the corner right but it's it

00:35:56,780 --> 00:35:59,430
what

00:35:57,240 --> 00:36:02,400
what's happening is it's done for the

00:35:59,430 --> 00:36:06,030
first user it's really there is no UID

00:36:02,400 --> 00:36:08,700
based checks so if the if you want to

00:36:06,030 --> 00:36:11,370
implement custom permission checks it

00:36:08,700 --> 00:36:13,260
really cannot happen because the the I

00:36:11,370 --> 00:36:16,680
note that is now cached by the kernel

00:36:13,260 --> 00:36:19,080
was tested for first user and you really

00:36:16,680 --> 00:36:20,910
cannot invalidate for next user so only

00:36:19,080 --> 00:36:23,600
with this sort of framework where

00:36:20,910 --> 00:36:27,440
developers can add their custom logic

00:36:23,600 --> 00:36:30,860
can they really implement custom checks

00:36:27,440 --> 00:36:30,860
that does make sense

00:36:31,550 --> 00:36:38,510
you mean additional chips which happen

00:36:34,890 --> 00:36:40,680
which occur at open time or something

00:36:38,510 --> 00:36:43,350
lookup time open time there could be

00:36:40,680 --> 00:36:47,580
additional permission checks I mean that

00:36:43,350 --> 00:36:52,400
you say not is not being invalidated at

00:36:47,580 --> 00:37:02,100
close time it's still living for a while

00:36:52,400 --> 00:37:07,740
till required time when you first time

00:37:02,100 --> 00:37:11,630
get I note you do all the checks isn't

00:37:07,740 --> 00:37:17,430
this so when you do the second open and

00:37:11,630 --> 00:37:22,320
you can perform the checks again and if

00:37:17,430 --> 00:37:26,250
it's impossible you won't believe the

00:37:22,320 --> 00:37:29,700
casual tie not so what I'm saying is

00:37:26,250 --> 00:37:31,440
that so the fuse model currently with

00:37:29,700 --> 00:37:33,390
the driver does it you know if you

00:37:31,440 --> 00:37:35,670
enable the you know if you specified no

00:37:33,390 --> 00:37:38,160
nonzero entry time out there in cash

00:37:35,670 --> 00:37:40,350
entries based on you know the first user

00:37:38,160 --> 00:37:42,840
that is using and using the permissions

00:37:40,350 --> 00:37:46,470
for that user if the user were to change

00:37:42,840 --> 00:37:49,470
right so that's one way one example

00:37:46,470 --> 00:37:52,680
where the the cached model does not you

00:37:49,470 --> 00:37:54,660
know suffice another example where so

00:37:52,680 --> 00:37:57,120
the current model that kernel has it all

00:37:54,660 --> 00:37:58,770
reactive caching so you your first

00:37:57,120 --> 00:38:00,330
request you know it goes through the

00:37:58,770 --> 00:38:00,900
slow part you cache it and now it's in

00:38:00,330 --> 00:38:02,940
the Karma

00:38:00,900 --> 00:38:05,580
so this can have proactive caching so

00:38:02,940 --> 00:38:08,180
for example you can before you so

00:38:05,580 --> 00:38:10,620
developers know what what you know

00:38:08,180 --> 00:38:11,040
attributes what entries will be accessed

00:38:10,620 --> 00:38:13,230
so they can

00:38:11,040 --> 00:38:20,070
- before him for example the Gloucester

00:38:13,230 --> 00:38:21,630
reader I had requests me maybe we can

00:38:20,070 --> 00:38:23,040
take that offline if I'm missing

00:38:21,630 --> 00:38:29,430
something yeah thank you so much for

00:38:23,040 --> 00:38:31,140
that any other questions thank you very

00:38:29,430 --> 00:38:33,710
much okay thank you so much the audience

00:38:31,140 --> 00:38:33,710

YouTube URL: https://www.youtube.com/watch?v=XmoJCHNEp2w


