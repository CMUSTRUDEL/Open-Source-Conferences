Title: LPC 2020 - Refereed Track - Day 5
Publication date: 2020-08-28
Playlist: LPC2020 - Live Streams
Description: 
	Linux Plumbers Conference 2020
Captions: 
	00:00:00,000 --> 00:00:03,280
otherwise contributed to the conference

00:00:02,960 --> 00:00:08,160
and

00:00:03,280 --> 00:00:08,160
uh it's uh

00:00:09,679 --> 00:00:12,719
good to have so many people i think that

00:00:11,519 --> 00:00:15,599
might not have otherwise been able to

00:00:12,719 --> 00:00:18,960
attend attend so that's certainly one

00:00:15,599 --> 00:00:19,600
um silver lining in the dark cloud that

00:00:18,960 --> 00:00:21,920
is the

00:00:19,600 --> 00:00:23,119
current uh travel situation for many

00:00:21,920 --> 00:00:26,240
people

00:00:23,119 --> 00:00:26,960
so uh one way or another whether you

00:00:26,240 --> 00:00:28,840
could have made it

00:00:26,960 --> 00:00:30,800
in first or not glad to see everybody

00:00:28,840 --> 00:00:33,040
here

00:00:30,800 --> 00:00:34,719
and again we'll give another minute or

00:00:33,040 --> 00:00:45,840
so and

00:00:34,719 --> 00:00:45,840
let daniel take it away

00:01:04,159 --> 00:01:13,840
can you all hear me fine

00:01:07,600 --> 00:01:13,840
it's a very hot day visa today

00:01:17,360 --> 00:01:21,680
does that improve or degrade response

00:01:19,040 --> 00:01:21,680
time the heat

00:01:22,159 --> 00:01:26,320
yeah it's uh i have a cooling system so

00:01:25,200 --> 00:01:41,840
i

00:01:26,320 --> 00:01:41,840
put a stable frequency all right

00:01:45,680 --> 00:01:48,880
and steven just showed up in time to

00:01:47,280 --> 00:01:51,280
give you a hard time so here you are go

00:01:48,880 --> 00:01:54,320
ahead daniel you're all yours

00:01:51,280 --> 00:01:55,119
okay here we go so hello humans uh i'm

00:01:54,320 --> 00:01:57,439
daniel

00:01:55,119 --> 00:01:59,280
i work for red hat and the this is the

00:01:57,439 --> 00:02:02,240
work i did in collaboration with some

00:01:59,280 --> 00:02:03,439
folks at uh scuanlos pero de santana

00:02:02,240 --> 00:02:07,520
here in pisa

00:02:03,439 --> 00:02:12,959
and uh in brazil

00:02:07,520 --> 00:02:12,959
right and uh today you talk about

00:02:13,200 --> 00:02:16,560
guess what real time

00:02:17,680 --> 00:02:21,280
and uh for those who attended the

00:02:19,440 --> 00:02:23,440
plumbers last years

00:02:21,280 --> 00:02:25,120
i would say that this is the episode 3

00:02:23,440 --> 00:02:28,000
showing a math talk

00:02:25,120 --> 00:02:28,959
and uh we'll talk more about this during

00:02:28,000 --> 00:02:32,400
the

00:02:28,959 --> 00:02:33,920
presentation right so

00:02:32,400 --> 00:02:35,599
yeah i'm from the real time linux

00:02:33,920 --> 00:02:38,400
community

00:02:35,599 --> 00:02:40,480
and uh but sometimes we need to say

00:02:38,400 --> 00:02:42,160
real-time lands mainly when we are in

00:02:40,480 --> 00:02:45,680
front of

00:02:42,160 --> 00:02:47,200
academic people who who have another or

00:02:45,680 --> 00:02:50,480
a different

00:02:47,200 --> 00:02:52,580
let's say different but yeah a different

00:02:50,480 --> 00:02:54,640
point of view about real time

00:02:52,580 --> 00:02:57,360
[Music]

00:02:54,640 --> 00:02:59,599
that's because on the on the real-time

00:02:57,360 --> 00:03:02,480
linux side of the fence

00:02:59,599 --> 00:03:03,599
we we took a more uh experimental

00:03:02,480 --> 00:03:05,840
approach

00:03:03,599 --> 00:03:06,959
while in the math in the real-time

00:03:05,840 --> 00:03:09,920
theory they

00:03:06,959 --> 00:03:10,640
we have also there so they have a more

00:03:09,920 --> 00:03:15,200
uh

00:03:10,640 --> 00:03:17,599
analytical approach right for example

00:03:15,200 --> 00:03:18,560
linux was adapted to become a real-time

00:03:17,599 --> 00:03:21,840
operating system

00:03:18,560 --> 00:03:24,720
the prime turkey is the de facto

00:03:21,840 --> 00:03:25,599
standard for it and we have many people

00:03:24,720 --> 00:03:27,120
running this

00:03:25,599 --> 00:03:29,200
production as a real-time operating

00:03:27,120 --> 00:03:31,040
system and then

00:03:29,200 --> 00:03:32,400
the main tool that we use to evaluate

00:03:31,040 --> 00:03:35,360
the prem turkey

00:03:32,400 --> 00:03:37,120
is actually the cyclic test that analyze

00:03:35,360 --> 00:03:40,799
the kernel somehow like a

00:03:37,120 --> 00:03:44,840
a closed box and uh

00:03:40,799 --> 00:03:48,080
these bring some critters to how linux

00:03:44,840 --> 00:03:50,480
performs because uh

00:03:48,080 --> 00:03:51,440
uh despite the fact that psychic tests

00:03:50,480 --> 00:03:53,599
help

00:03:51,440 --> 00:03:55,519
a lot it doesn't give the demonstration

00:03:53,599 --> 00:03:56,239
of worst case which are common in the

00:03:55,519 --> 00:03:59,599
real-time

00:03:56,239 --> 00:04:02,239
literature and does not yeah there's a

00:03:59,599 --> 00:04:04,159
demonstration in evidences that

00:04:02,239 --> 00:04:06,159
the worst case was found while running

00:04:04,159 --> 00:04:09,599
the system right you never know if you

00:04:06,159 --> 00:04:13,040
hit the max latest or not

00:04:09,599 --> 00:04:16,639
um on the other side of the fence

00:04:13,040 --> 00:04:20,079
in a real-time theory the

00:04:16,639 --> 00:04:22,160
these studies are made on top of a very

00:04:20,079 --> 00:04:23,199
precise description of the system that

00:04:22,160 --> 00:04:26,240
tries to capture

00:04:23,199 --> 00:04:29,190
all the behaviors they precisely define

00:04:26,240 --> 00:04:30,720
the the worst case and uh

00:04:29,190 --> 00:04:32,720
[Music]

00:04:30,720 --> 00:04:34,880
and then they can say like more strong

00:04:32,720 --> 00:04:38,240
arguments about finding diversity

00:04:34,880 --> 00:04:39,759
right i'm not just trying but sometimes

00:04:38,240 --> 00:04:42,000
it's overly simplified

00:04:39,759 --> 00:04:43,199
because to be able to do the math they

00:04:42,000 --> 00:04:46,080
use

00:04:43,199 --> 00:04:47,120
models that are not necessarily

00:04:46,080 --> 00:04:48,800
connected to the

00:04:47,120 --> 00:04:51,199
things that we see on linux for example

00:04:48,800 --> 00:04:53,440
they say that dots are now independent

00:04:51,199 --> 00:04:54,639
that operations are atomic and such

00:04:53,440 --> 00:04:57,840
simplifications

00:04:54,639 --> 00:04:59,120
make sometimes hard to defeat linux and

00:04:57,840 --> 00:05:04,080
real-time

00:04:59,120 --> 00:05:04,080
theory in same same room

00:05:04,160 --> 00:05:08,960
but the point is i like both i like

00:05:06,880 --> 00:05:10,320
real-time lyrics i like to focus in the

00:05:08,960 --> 00:05:12,000
real time news community

00:05:10,320 --> 00:05:13,680
and then i also like folks in the

00:05:12,000 --> 00:05:15,360
academic side they have good friends on

00:05:13,680 --> 00:05:18,880
the both side of the fence

00:05:15,360 --> 00:05:21,280
fest and uh yeah i try to

00:05:18,880 --> 00:05:23,440
to put them all together and make

00:05:21,280 --> 00:05:27,039
everybody happy

00:05:23,440 --> 00:05:29,120
so and uh

00:05:27,039 --> 00:05:30,560
this presentation actually is based on a

00:05:29,120 --> 00:05:34,000
paper published

00:05:30,560 --> 00:05:36,840
on the ecrts there are three main uh

00:05:34,000 --> 00:05:39,199
conferences on real-time theory defense

00:05:36,840 --> 00:05:42,639
systems which are the rtss

00:05:39,199 --> 00:05:45,280
dcrks and rks and this was

00:05:42,639 --> 00:05:48,320
uh published one of those conferences

00:05:45,280 --> 00:05:48,320
the ec rts

00:05:49,280 --> 00:05:56,400
so why this is the aim tree because

00:05:52,560 --> 00:05:59,600
two years ago we get the episode one

00:05:56,400 --> 00:06:03,199
in which i showed my idea that

00:05:59,600 --> 00:06:04,800
okay uh try and say that the linux

00:06:03,199 --> 00:06:06,319
works in real time is cheap we need to

00:06:04,800 --> 00:06:09,120
show the map and

00:06:06,319 --> 00:06:10,000
uh on that talk i explained that i was

00:06:09,120 --> 00:06:13,120
trying to

00:06:10,000 --> 00:06:17,039
specify the behavior of the gram turkey

00:06:13,120 --> 00:06:19,919
using the the automata theory

00:06:17,039 --> 00:06:20,800
right trying to reduce the complexity of

00:06:19,919 --> 00:06:24,319
linux

00:06:20,800 --> 00:06:27,919
using a model and actually

00:06:24,319 --> 00:06:28,800
that work is the base from this paper

00:06:27,919 --> 00:06:32,080
that i presented

00:06:28,800 --> 00:06:32,960
in the stock right so the approach here

00:06:32,080 --> 00:06:35,840
was

00:06:32,960 --> 00:06:36,800
we analyzed that form of specification

00:06:35,840 --> 00:06:40,479
we

00:06:36,800 --> 00:06:41,280
did we produced a a scheduling latency

00:06:40,479 --> 00:06:44,240
bound

00:06:41,280 --> 00:06:45,759
explanation following the kind of the

00:06:44,240 --> 00:06:48,240
methodology used

00:06:45,759 --> 00:06:49,599
commonly used in real-time theory and

00:06:48,240 --> 00:06:50,720
then we made some measurement and

00:06:49,599 --> 00:06:53,840
analysis to see

00:06:50,720 --> 00:06:58,960
okay how bad linux is using those

00:06:53,840 --> 00:06:58,960
pessimism and uh those were bridge

00:07:00,840 --> 00:07:06,720
analysis

00:07:02,639 --> 00:07:08,479
and uh okay from the talk i explained

00:07:06,720 --> 00:07:10,000
that i'm modeling using a set of

00:07:08,479 --> 00:07:12,240
generators which are where the

00:07:10,000 --> 00:07:16,639
independent behavior of the system

00:07:12,240 --> 00:07:18,479
and then in the paper the approach to

00:07:16,639 --> 00:07:20,960
to demystify the real time we've been

00:07:18,479 --> 00:07:23,599
translated to reach the ethereum

00:07:20,960 --> 00:07:25,520
we translated those generators into a

00:07:23,599 --> 00:07:28,319
set of operations

00:07:25,520 --> 00:07:28,639
right on a natural language explanations

00:07:28,319 --> 00:07:31,199
of

00:07:28,639 --> 00:07:32,639
operations afterwards and then we got

00:07:31,199 --> 00:07:34,560
specifications

00:07:32,639 --> 00:07:37,120
and the specifications are the

00:07:34,560 --> 00:07:39,280
coordinated behavior of these generators

00:07:37,120 --> 00:07:40,720
an example of a generator is i can call

00:07:39,280 --> 00:07:41,520
the scheduler and return from the

00:07:40,720 --> 00:07:43,520
scheduler

00:07:41,520 --> 00:07:44,639
and i can disable interrupts and enable

00:07:43,520 --> 00:07:48,000
interrupts and

00:07:44,639 --> 00:07:50,080
specifications like uh i cannot

00:07:48,000 --> 00:07:52,080
call the scheduler with interrupts

00:07:50,080 --> 00:07:56,479
disabled

00:07:52,080 --> 00:07:56,479
and these are are some kind of rules of

00:07:56,840 --> 00:08:00,479
synchronism

00:07:58,400 --> 00:08:02,160
and that we use this word like we

00:08:00,479 --> 00:08:05,440
explain this as the rules

00:08:02,160 --> 00:08:08,879
of synchronization of the system

00:08:05,440 --> 00:08:12,000
okay from that base operations and

00:08:08,879 --> 00:08:14,879
specifications we define what could be

00:08:12,000 --> 00:08:15,919
uh the scheduling latest okay we want to

00:08:14,879 --> 00:08:18,400
show

00:08:15,919 --> 00:08:20,080
the the timing behavior of the

00:08:18,400 --> 00:08:23,360
scheduling latest

00:08:20,080 --> 00:08:26,479
and we defined it as the longest time

00:08:23,360 --> 00:08:27,199
elapsed between the time a in which a

00:08:26,479 --> 00:08:29,199
threat

00:08:27,199 --> 00:08:30,560
right here is a job but it's a threat

00:08:29,199 --> 00:08:33,839
only externality

00:08:30,560 --> 00:08:36,479
which attract becomes ready and with the

00:08:33,839 --> 00:08:40,719
highest priority

00:08:36,479 --> 00:08:44,399
right until the time in which

00:08:40,719 --> 00:08:47,680
these tasks starts to execute right

00:08:44,399 --> 00:08:48,399
and it's important to to mention to you

00:08:47,680 --> 00:08:51,120
here that

00:08:48,399 --> 00:08:53,040
ready and with highest priority are two

00:08:51,120 --> 00:08:56,000
different actions

00:08:53,040 --> 00:08:56,959
right i'm gonna explain it uh better in

00:08:56,000 --> 00:08:59,600
a

00:08:56,959 --> 00:08:59,600
next slide

00:09:00,399 --> 00:09:05,760
um so okay i want to

00:09:03,600 --> 00:09:07,200
i want to define this ladies delay

00:09:05,760 --> 00:09:10,080
between the test being

00:09:07,200 --> 00:09:10,640
ready and with the highest priority up

00:09:10,080 --> 00:09:13,519
to

00:09:10,640 --> 00:09:14,720
the time in which it starts to run and

00:09:13,519 --> 00:09:17,040
uh

00:09:14,720 --> 00:09:18,480
to break down a little bit more this

00:09:17,040 --> 00:09:22,800
problem

00:09:18,480 --> 00:09:24,800
uh we separated two kinds of abstraction

00:09:22,800 --> 00:09:26,560
we have the trend running the current

00:09:24,800 --> 00:09:28,399
straight running and these new highest

00:09:26,560 --> 00:09:31,839
parts thread who just arrived

00:09:28,399 --> 00:09:32,640
right and then we break down this delay

00:09:31,839 --> 00:09:34,800
into

00:09:32,640 --> 00:09:37,440
the delay caused by blocking and the

00:09:34,800 --> 00:09:39,920
delay caused by the interference

00:09:37,440 --> 00:09:41,440
blocking is a terminology used in the

00:09:39,920 --> 00:09:44,320
real-time theory

00:09:41,440 --> 00:09:44,800
for the case in which a lower priority

00:09:44,320 --> 00:09:47,760
task

00:09:44,800 --> 00:09:49,040
delays a highest priority one or higher

00:09:47,760 --> 00:09:51,360
priority one

00:09:49,040 --> 00:09:52,800
and interference means when we have a

00:09:51,360 --> 00:09:55,440
higher priority

00:09:52,800 --> 00:09:56,720
test interfering in a lower priority

00:09:55,440 --> 00:09:58,560
test

00:09:56,720 --> 00:10:00,560
for the case of linux we use the

00:09:58,560 --> 00:10:03,839
blocking to define the delay

00:10:00,560 --> 00:10:08,320
of the lower priority thread

00:10:03,839 --> 00:10:11,680
into this new highest priority one

00:10:08,320 --> 00:10:15,279
an interference we use for the irqs that

00:10:11,680 --> 00:10:15,279
happen during this time window

00:10:16,839 --> 00:10:22,000
so from the bottom of the

00:10:20,399 --> 00:10:23,839
blocking and the bond of the

00:10:22,000 --> 00:10:27,760
interference we started

00:10:23,839 --> 00:10:31,040
bounding the blocking time right

00:10:27,760 --> 00:10:32,880
and to do this we used uh the

00:10:31,040 --> 00:10:36,240
specification of the system

00:10:32,880 --> 00:10:38,880
used in the formal model and

00:10:36,240 --> 00:10:39,680
we got an auxiliary image which is a

00:10:38,880 --> 00:10:42,160
timeline

00:10:39,680 --> 00:10:43,760
which is used in the real-time theory

00:10:42,160 --> 00:10:47,519
and i'll explain it better

00:10:43,760 --> 00:10:50,000
right so okay blocking the bond

00:10:47,519 --> 00:10:50,640
when does the scheduling latency start

00:10:50,000 --> 00:10:54,000
right

00:10:50,640 --> 00:10:54,800
it's again it's in the instant of time

00:10:54,000 --> 00:10:58,320
in which

00:10:54,800 --> 00:11:00,560
uh a thread becomes ready and with the

00:10:58,320 --> 00:11:03,760
highest priority

00:11:00,560 --> 00:11:05,680
the event that better uh notifies that

00:11:03,760 --> 00:11:09,519
there is a new highest priority

00:11:05,680 --> 00:11:12,720
threat in linux is the sadness cat

00:11:09,519 --> 00:11:15,440
right and so we have this

00:11:12,720 --> 00:11:18,000
net setting this cat that works for all

00:11:15,440 --> 00:11:20,160
schedulers and all conditions

00:11:18,000 --> 00:11:21,440
and this set me very scary it has two

00:11:20,160 --> 00:11:24,640
necessary conditions

00:11:21,440 --> 00:11:27,360
preemption and erection it's able so

00:11:24,640 --> 00:11:28,480
we bounded back the starting of this

00:11:27,360 --> 00:11:31,600
scheduled latency

00:11:28,480 --> 00:11:35,120
to the instead of time in which

00:11:31,600 --> 00:11:37,839
uh this amount of time in which

00:11:35,120 --> 00:11:38,320
the prevention req became disabled this

00:11:37,839 --> 00:11:42,640
is the

00:11:38,320 --> 00:11:46,320
the furthest back that we could see

00:11:42,640 --> 00:11:48,959
then the end of the latency

00:11:46,320 --> 00:11:50,720
on the blocking is the time which the

00:11:48,959 --> 00:11:52,800
scheduler returns

00:11:50,720 --> 00:11:55,760
and allows the execution of the new

00:11:52,800 --> 00:11:59,440
highest priority thread uncle

00:11:55,760 --> 00:12:01,760
we generalize this uh instant of time

00:11:59,440 --> 00:12:03,360
to the point in which the schedule the

00:12:01,760 --> 00:12:05,760
scheduler returns

00:12:03,360 --> 00:12:07,279
and the permissions get enabled after

00:12:05,760 --> 00:12:10,480
scheduling

00:12:07,279 --> 00:12:13,040
so it's important to note here

00:12:10,480 --> 00:12:13,600
that this implies that the context

00:12:13,040 --> 00:12:16,639
switch

00:12:13,600 --> 00:12:18,560
will cross it by the context switch and

00:12:16,639 --> 00:12:20,560
the context switch

00:12:18,560 --> 00:12:23,440
also implies doing the schedule so they

00:12:20,560 --> 00:12:24,800
are indirectional

00:12:23,440 --> 00:12:26,639
and it's important here for the

00:12:24,800 --> 00:12:27,200
demonstration that the contact switch

00:12:26,639 --> 00:12:29,279
needs

00:12:27,200 --> 00:12:30,320
preemption is able to scan and i are

00:12:29,279 --> 00:12:34,000
accused

00:12:30,320 --> 00:12:36,639
and we will reach them so just recalling

00:12:34,000 --> 00:12:37,279
the scheduling latency so for the thread

00:12:36,639 --> 00:12:40,880
arguments

00:12:37,279 --> 00:12:41,360
is in the first is starts when we first

00:12:40,880 --> 00:12:44,320
see

00:12:41,360 --> 00:12:46,079
either our cues or prevention being

00:12:44,320 --> 00:12:50,800
disabled

00:12:46,079 --> 00:12:54,240
and then calls me chris cat and

00:12:50,800 --> 00:12:56,959
the time in which we have the

00:12:54,240 --> 00:12:58,480
the highest part trend already scheduled

00:12:56,959 --> 00:13:00,800
and the scheduler

00:12:58,480 --> 00:13:01,760
finished running enable preemption and

00:13:00,800 --> 00:13:04,800
then it's uh

00:13:01,760 --> 00:13:04,800
the unfriend code

00:13:05,600 --> 00:13:11,360
so and how do i bound these two events

00:13:09,040 --> 00:13:13,279
right disabling prevention to to cause

00:13:11,360 --> 00:13:15,040
the preferred q2 cause

00:13:13,279 --> 00:13:18,560
they need your scan and the return from

00:13:15,040 --> 00:13:21,760
the scheduler enabling the branch

00:13:18,560 --> 00:13:24,800
there in the formal model there was

00:13:21,760 --> 00:13:26,240
one specifications that says that the

00:13:24,800 --> 00:13:30,000
set need risk add

00:13:26,240 --> 00:13:33,120
is a sufficient condition for a

00:13:30,000 --> 00:13:37,200
contact switch in of a new thread

00:13:33,120 --> 00:13:39,839
anytime i have uh setting your scan

00:13:37,200 --> 00:13:41,920
i will only return to the initial state

00:13:39,839 --> 00:13:45,440
after having

00:13:41,920 --> 00:13:48,560
a context switch a of another thread

00:13:45,440 --> 00:13:51,040
or just just these two types

00:13:48,560 --> 00:13:51,760
then here inside we have all the

00:13:51,040 --> 00:13:54,399
possible

00:13:51,760 --> 00:13:56,320
paths in the synchronization level right

00:13:54,399 --> 00:13:58,639
perhaps an enable prediction disable

00:13:56,320 --> 00:14:00,399
calling scheduler

00:13:58,639 --> 00:14:02,480
so in the synchronization level we have

00:14:00,399 --> 00:14:06,160
all the possible bets

00:14:02,480 --> 00:14:09,279
that we can face here by the current

00:14:06,160 --> 00:14:12,480
and from these paths we distinguished

00:14:09,279 --> 00:14:14,720
five possible cases

00:14:12,480 --> 00:14:17,760
so and then we use the timeline to

00:14:14,720 --> 00:14:19,519
explain it here because it's easier

00:14:17,760 --> 00:14:21,279
and that's normal right when we are

00:14:19,519 --> 00:14:23,839
doing this recommendation on paper we

00:14:21,279 --> 00:14:26,720
can use this lcdr in formats to help in

00:14:23,839 --> 00:14:26,720
the demonstration

00:14:28,560 --> 00:14:35,920
so uh think of this on that task

00:14:32,480 --> 00:14:38,240
running right on the cpu

00:14:35,920 --> 00:14:40,079
this is the scheduler context right this

00:14:38,240 --> 00:14:42,000
is disable the permission to call the

00:14:40,079 --> 00:14:44,399
scheduler the scheduler runs

00:14:42,000 --> 00:14:46,160
we have the context switch and the

00:14:44,399 --> 00:14:49,920
schedule returns and we have another

00:14:46,160 --> 00:14:53,040
test burning and here is the previous

00:14:49,920 --> 00:14:53,040
task that was working

00:14:54,320 --> 00:14:57,839
we can have the arrival of the new high

00:14:57,519 --> 00:15:01,680
gas

00:14:57,839 --> 00:15:04,560
priority threat in any time here

00:15:01,680 --> 00:15:05,600
and from this this specification let me

00:15:04,560 --> 00:15:09,920
see if it's in the next

00:15:05,600 --> 00:15:13,040
slide from the analysis of this path

00:15:09,920 --> 00:15:15,120
we found the situation in which let's

00:15:13,040 --> 00:15:15,680
come from the most optimistic to the

00:15:15,120 --> 00:15:19,120
most

00:15:15,680 --> 00:15:21,600
pessimistic we could have a new highest

00:15:19,120 --> 00:15:23,839
priority friday being very lucky

00:15:21,600 --> 00:15:25,519
in the case in which the farmer the

00:15:23,839 --> 00:15:27,839
lower priority threat

00:15:25,519 --> 00:15:28,880
was calling the scheduler to suspend to

00:15:27,839 --> 00:15:30,560
go to sleep

00:15:28,880 --> 00:15:32,720
and it was already on the path to call

00:15:30,560 --> 00:15:35,839
the schedule so

00:15:32,720 --> 00:15:38,079
if my new task is uh

00:15:35,839 --> 00:15:39,519
lucky enough if we were right here while

00:15:38,079 --> 00:15:43,040
the scheduler is already

00:15:39,519 --> 00:15:45,759
running right or

00:15:43,040 --> 00:15:47,920
there is a case that that doesn't

00:15:45,759 --> 00:15:49,360
actually exist in reality but it would

00:15:47,920 --> 00:15:51,199
not break the model in which this

00:15:49,360 --> 00:15:55,199
scheduler code would

00:15:51,199 --> 00:15:57,120
wake up a trend as well so if the thread

00:15:55,199 --> 00:15:59,519
the new highest part thread is lucky

00:15:57,120 --> 00:16:03,120
enough we'll have this case one a

00:15:59,519 --> 00:16:06,079
and one b over here one a

00:16:03,120 --> 00:16:06,720
and one b the farmer thread was already

00:16:06,079 --> 00:16:09,040
uh

00:16:06,720 --> 00:16:10,480
calling the scheduler and all the good

00:16:09,040 --> 00:16:13,279
conditions right there

00:16:10,480 --> 00:16:15,120
okay good lucky but this doesn't always

00:16:13,279 --> 00:16:18,320
happen

00:16:15,120 --> 00:16:21,120
there is one unlucky case in which

00:16:18,320 --> 00:16:21,680
let's say we have a timer interrupt and

00:16:21,120 --> 00:16:25,040
it would

00:16:21,680 --> 00:16:26,480
arrive right here when irequeues get

00:16:25,040 --> 00:16:28,480
disabled to call the

00:16:26,480 --> 00:16:29,839
caused contact switch because i request

00:16:28,480 --> 00:16:33,040
disabled

00:16:29,839 --> 00:16:35,600
uh direct sample

00:16:33,040 --> 00:16:37,440
has this necessary condition of having

00:16:35,600 --> 00:16:41,759
hierarchies disabled

00:16:37,440 --> 00:16:44,639
contextually so if my timer arrives here

00:16:41,759 --> 00:16:45,680
hierarchy will be disabled and then it

00:16:44,639 --> 00:16:49,279
will all be served

00:16:45,680 --> 00:16:54,000
here and then we will have to go

00:16:49,279 --> 00:16:56,959
this path again and in then we have this

00:16:54,000 --> 00:16:57,519
is here right this timeline here the

00:16:56,959 --> 00:17:02,079
case

00:16:57,519 --> 00:17:04,880
three and we have the more common case

00:17:02,079 --> 00:17:05,280
or the most unlucky case in which the

00:17:04,880 --> 00:17:08,000
current

00:17:05,280 --> 00:17:09,120
thread was not wishing to go away it was

00:17:08,000 --> 00:17:11,760
just running

00:17:09,120 --> 00:17:12,559
it could have the same preemption and or

00:17:11,760 --> 00:17:14,640
it could be

00:17:12,559 --> 00:17:16,160
running on user space and then it code

00:17:14,640 --> 00:17:18,319
is running and we have the branching

00:17:16,160 --> 00:17:20,720
disabled either by the thread or

00:17:18,319 --> 00:17:22,000
as a side effect of this the arrival

00:17:20,720 --> 00:17:25,199
from the thread

00:17:22,000 --> 00:17:27,760
or to cause the chronic risk head

00:17:25,199 --> 00:17:29,600
or to cause the universe can and then we

00:17:27,760 --> 00:17:33,520
have all this delay which is

00:17:29,600 --> 00:17:35,679
which are the cases one a and one b

00:17:33,520 --> 00:17:37,919
and then we in this timeline we covered

00:17:35,679 --> 00:17:39,520
all the possible cases here

00:17:37,919 --> 00:17:43,120
and this gives us the assurance that

00:17:39,520 --> 00:17:43,120
we're not forgetting any path

00:17:43,520 --> 00:17:47,600
so we demonstrated all the possible

00:17:46,400 --> 00:17:49,440
cases

00:17:47,600 --> 00:17:51,520
and showed that the latency will be

00:17:49,440 --> 00:17:55,200
found by ear

00:17:51,520 --> 00:17:58,320
uh this case here like

00:17:55,200 --> 00:18:01,840
these are getting here

00:17:58,320 --> 00:18:01,840
so for us to

00:18:02,240 --> 00:18:06,640
to make a computation okay i have the

00:18:04,240 --> 00:18:08,320
behavior how can i distract these into

00:18:06,640 --> 00:18:11,919
mathematical variables

00:18:08,320 --> 00:18:15,280
that i can use on a on an equation right

00:18:11,919 --> 00:18:17,520
so we found that the most practical

00:18:15,280 --> 00:18:19,919
variables to explain these dynamics

00:18:17,520 --> 00:18:24,720
would be this

00:18:19,919 --> 00:18:27,360
sorry we have this variable that

00:18:24,720 --> 00:18:28,559
accounts the branch on our interrupts

00:18:27,360 --> 00:18:30,559
disabled

00:18:28,559 --> 00:18:32,080
to postpone the scheduler which is the

00:18:30,559 --> 00:18:33,840
classical case in which a thread is

00:18:32,080 --> 00:18:36,240
running disabling permission

00:18:33,840 --> 00:18:37,120
to something and enable the parameter

00:18:36,240 --> 00:18:40,320
for example

00:18:37,120 --> 00:18:43,520
but not called sketch we have

00:18:40,320 --> 00:18:46,320
the time window in which the impression

00:18:43,520 --> 00:18:47,840
are disabled to call the scheduler

00:18:46,320 --> 00:18:50,559
because the scanner is called with

00:18:47,840 --> 00:18:53,840
fractions disabled

00:18:50,559 --> 00:18:57,440
we have this window here which is after

00:18:53,840 --> 00:18:58,160
disabling interrupts during the

00:18:57,440 --> 00:19:02,080
scheduler

00:18:58,160 --> 00:19:04,960
to cause the contact switch and we have

00:19:02,080 --> 00:19:07,120
this this transient state here that

00:19:04,960 --> 00:19:09,840
happens inside the prep enable

00:19:07,120 --> 00:19:10,559
or inside the return from my erq which

00:19:09,840 --> 00:19:14,080
is

00:19:10,559 --> 00:19:16,880
uh my i have to need risquet

00:19:14,080 --> 00:19:17,760
the system is enabling the prediction in

00:19:16,880 --> 00:19:19,280
nirq

00:19:17,760 --> 00:19:21,200
because there are necessary conditions

00:19:19,280 --> 00:19:23,360
for neutral scan and then when

00:19:21,200 --> 00:19:25,360
both are enabled we check for need

00:19:23,360 --> 00:19:26,640
rescan if there is the need for risk ad

00:19:25,360 --> 00:19:28,799
we call the scheduler

00:19:26,640 --> 00:19:29,919
and we have this transient state in

00:19:28,799 --> 00:19:32,320
which the preemption

00:19:29,919 --> 00:19:35,840
and our queue are enabled but then we

00:19:32,320 --> 00:19:38,240
strict connect with the next example

00:19:35,840 --> 00:19:39,600
okay returning to the this variables to

00:19:38,240 --> 00:19:44,320
the timeline because it's easier

00:19:39,600 --> 00:19:44,320
so we have the scatter latency

00:19:44,960 --> 00:19:49,039
the depression the sketch is able to

00:19:48,559 --> 00:19:53,280
predict

00:19:49,039 --> 00:19:53,280
to cause the scavenger the preemption

00:19:55,919 --> 00:20:00,880
we have this window here uh we have

00:19:59,280 --> 00:20:01,919
given off preps and then our queue

00:20:00,880 --> 00:20:05,120
disabled

00:20:01,919 --> 00:20:07,600
to post on the scheduler and this

00:20:05,120 --> 00:20:09,919
tiny boy here which is just a transient

00:20:07,600 --> 00:20:09,919
state

00:20:11,520 --> 00:20:17,200
and uh okay and here we start

00:20:14,960 --> 00:20:18,240
editing the delay caused by the

00:20:17,200 --> 00:20:20,559
interference

00:20:18,240 --> 00:20:21,760
from error cues we said that our keys

00:20:20,559 --> 00:20:24,880
are interference because

00:20:21,760 --> 00:20:27,520
uh they behave like if they had

00:20:24,880 --> 00:20:29,760
a priority higher than all the threads

00:20:27,520 --> 00:20:29,760
right

00:20:30,000 --> 00:20:35,600
we can cause block to be to the irq's

00:20:34,720 --> 00:20:37,440
because we can

00:20:35,600 --> 00:20:39,679
disable our queues and make them to

00:20:37,440 --> 00:20:43,120
delay but those they are allowed to run

00:20:39,679 --> 00:20:46,240
but they cause interference okay

00:20:43,120 --> 00:20:50,480
yes at the end of the scheduler

00:20:46,240 --> 00:20:53,600
we will return with interrupts enabled

00:20:50,480 --> 00:20:56,400
even if these all were interrupts

00:20:53,600 --> 00:20:58,480
uh disabled all the interrupts will be

00:20:56,400 --> 00:21:02,480
served here

00:20:58,480 --> 00:21:05,440
so we need to account the

00:21:02,480 --> 00:21:06,480
how much interrupts we could have in the

00:21:05,440 --> 00:21:09,600
entire

00:21:06,480 --> 00:21:11,440
uh window of time from from the first

00:21:09,600 --> 00:21:14,480
conditions constantly scan

00:21:11,440 --> 00:21:16,640
up to the point in which we return

00:21:14,480 --> 00:21:18,960
the control to the new highest priority

00:21:16,640 --> 00:21:18,960
threat

00:21:20,080 --> 00:21:23,760
with that explained right here i'm not

00:21:22,240 --> 00:21:25,679
showing the audio details of the

00:21:23,760 --> 00:21:26,240
argumentation that we have in the paper

00:21:25,679 --> 00:21:28,000
go there

00:21:26,240 --> 00:21:29,440
it's not that hard after seeing the

00:21:28,000 --> 00:21:31,520
explanation

00:21:29,440 --> 00:21:33,520
and here we say that the latency the

00:21:31,520 --> 00:21:34,559
theorem says that the latency is bound

00:21:33,520 --> 00:21:37,840
by

00:21:34,559 --> 00:21:38,960
the maximum value between the scheduled

00:21:37,840 --> 00:21:40,880
delay

00:21:38,960 --> 00:21:42,400
and the preemption ranking disabled

00:21:40,880 --> 00:21:45,520
which whichever

00:21:42,400 --> 00:21:48,080
is one of these is higher we will pick

00:21:45,520 --> 00:21:50,240
the highest one the maximum one then

00:21:48,080 --> 00:21:53,440
that transient state

00:21:50,240 --> 00:21:56,840
then the the time to call the

00:21:53,440 --> 00:21:59,600
dash dash schedule function inside the

00:21:56,840 --> 00:22:02,799
parentheses

00:21:59,600 --> 00:22:04,559
plus the function that returns me how

00:22:02,799 --> 00:22:07,039
much interference i can have

00:22:04,559 --> 00:22:08,320
during the latency from nmis and the

00:22:07,039 --> 00:22:10,000
function that

00:22:08,320 --> 00:22:12,640
say how much interference i can have

00:22:10,000 --> 00:22:14,400
from irqs inside that l

00:22:12,640 --> 00:22:17,039
and as you can see the l is in both

00:22:14,400 --> 00:22:18,640
sides of the formula

00:22:17,039 --> 00:22:20,320
and that's common in the real time

00:22:18,640 --> 00:22:22,799
period it's based on the real

00:22:20,320 --> 00:22:23,520
response time analysis here in which

00:22:22,799 --> 00:22:25,600
when we have

00:22:23,520 --> 00:22:27,200
these two cases let's say that i have a

00:22:25,600 --> 00:22:29,520
maximum here of five

00:22:27,200 --> 00:22:31,039
then i add nmi it goes to six then i

00:22:29,520 --> 00:22:33,840
have nmit goes to seven

00:22:31,039 --> 00:22:34,559
then i recompute these with seven right

00:22:33,840 --> 00:22:37,280
and then

00:22:34,559 --> 00:22:38,400
if your cages doesn't increase anymore

00:22:37,280 --> 00:22:40,559
after seven

00:22:38,400 --> 00:22:41,520
then we have the uh stable latency

00:22:40,559 --> 00:22:44,240
stable l

00:22:41,520 --> 00:22:44,240
and that's the l

00:22:45,520 --> 00:22:50,159
okay looking back here with the timeline

00:22:48,480 --> 00:22:52,400
it's easier to understand it so

00:22:50,159 --> 00:22:53,440
it's the maximum between this delay that

00:22:52,400 --> 00:22:56,480
we

00:22:53,440 --> 00:22:57,760
the behavior here parties delay that

00:22:56,480 --> 00:23:08,640
will cause the behavior

00:22:57,760 --> 00:23:11,039
here plus the interference

00:23:08,640 --> 00:23:13,120
okay daniel but so far you haven't

00:23:11,039 --> 00:23:15,200
talked about these functions that define

00:23:13,120 --> 00:23:17,600
the

00:23:15,200 --> 00:23:18,640
that they find interferes from ir2's and

00:23:17,600 --> 00:23:22,400
nmis right

00:23:18,640 --> 00:23:24,960
what are you hiding yeah

00:23:22,400 --> 00:23:26,400
last year at lumbers we discussed this i

00:23:24,960 --> 00:23:29,520
i gave some uh

00:23:26,400 --> 00:23:30,159
brief ideas of what i was talking and uh

00:23:29,520 --> 00:23:32,320
and actually

00:23:30,159 --> 00:23:33,840
these diagrams that i'm using today were

00:23:32,320 --> 00:23:37,520
designed for last years

00:23:33,840 --> 00:23:40,720
and we used them at the paper

00:23:37,520 --> 00:23:44,080
uh so the puts that

00:23:40,720 --> 00:23:46,720
there is no best way to characterize how

00:23:44,080 --> 00:23:48,880
much interrupts you can have on a system

00:23:46,720 --> 00:23:50,320
and it will depend on the design of your

00:23:48,880 --> 00:23:53,039
own system right

00:23:50,320 --> 00:23:54,559
you can have a cpu isolated or you can

00:23:53,039 --> 00:23:57,360
have the skew handling

00:23:54,559 --> 00:23:58,080
your mouse and you can go like this and

00:23:57,360 --> 00:24:00,880
cause a lot of

00:23:58,080 --> 00:24:02,159
bursts of interrupts so there's no

00:24:00,880 --> 00:24:04,960
single way to define

00:24:02,159 --> 00:24:06,799
the characterization of hierarchies or

00:24:04,960 --> 00:24:09,919
there's no single past way

00:24:06,799 --> 00:24:11,039
so instead of trying to convince about a

00:24:09,919 --> 00:24:12,640
way

00:24:11,039 --> 00:24:14,240
that could be pessimistic that could be

00:24:12,640 --> 00:24:17,760
optimistic we

00:24:14,240 --> 00:24:20,480
did the analysis considering well no

00:24:17,760 --> 00:24:21,679
characterizations for the irqs the

00:24:20,480 --> 00:24:24,240
experiment

00:24:21,679 --> 00:24:25,840
and that's why we we put the ir q's in

00:24:24,240 --> 00:24:27,760
the in a formula

00:24:25,840 --> 00:24:29,039
this will get easier when we reach the

00:24:27,760 --> 00:24:31,360
the tooling part

00:24:29,039 --> 00:24:32,240
i'll explain and uh we will analyze some

00:24:31,360 --> 00:24:34,559
uh

00:24:32,240 --> 00:24:37,279
and latest channels using these

00:24:34,559 --> 00:24:37,279
different curves

00:24:38,480 --> 00:24:43,039
okay episode two getting practical so

00:24:41,200 --> 00:24:46,000
two years ago i explained the model

00:24:43,039 --> 00:24:48,080
but it was a little bit hard to process

00:24:46,000 --> 00:24:51,600
all those events in user space and then

00:24:48,080 --> 00:24:53,840
last year i came with the idea of doing

00:24:51,600 --> 00:24:54,640
real-time verification inside the kernel

00:24:53,840 --> 00:24:57,360
and showing that

00:24:54,640 --> 00:24:58,320
that idea of processing uh events in

00:24:57,360 --> 00:25:00,960
cardo

00:24:58,320 --> 00:25:02,799
was good enough to be used in production

00:25:00,960 --> 00:25:05,840
and uh

00:25:02,799 --> 00:25:08,480
that allows us to reach here with the

00:25:05,840 --> 00:25:11,760
tooling part of this paper

00:25:08,480 --> 00:25:14,159
so okay it's nice to have a formula

00:25:11,760 --> 00:25:16,080
it's cool i can show to my friends in

00:25:14,159 --> 00:25:18,480
the academia and they would say

00:25:16,080 --> 00:25:19,440
like i like it but when you go to the

00:25:18,480 --> 00:25:22,080
practice

00:25:19,440 --> 00:25:24,559
when i came to this side of defense if i

00:25:22,080 --> 00:25:28,000
don't show a tool that can actually

00:25:24,559 --> 00:25:30,559
pop me out some some numbers it could be

00:25:28,000 --> 00:25:32,799
just a piece of paper right so

00:25:30,559 --> 00:25:35,039
and here we get in the get back to the

00:25:32,799 --> 00:25:38,400
linux side of the fence

00:25:35,039 --> 00:25:40,840
so i created that tool

00:25:38,400 --> 00:25:42,000
based on the latest found explain it

00:25:40,840 --> 00:25:43,679
there

00:25:42,000 --> 00:25:45,440
and the latest one was based in the

00:25:43,679 --> 00:25:47,440
model that i presented two years ago and

00:25:45,440 --> 00:25:50,400
then model calls

00:25:47,440 --> 00:25:52,320
a lot of data hundreds of megabytes per

00:25:50,400 --> 00:25:54,640
cpu per second

00:25:52,320 --> 00:25:55,679
and uh that would not be practical right

00:25:54,640 --> 00:25:58,000
to email users

00:25:55,679 --> 00:26:00,240
so the challenge here was to minimize

00:25:58,000 --> 00:26:01,360
the runtime overhead and to make it work

00:26:00,240 --> 00:26:02,570
somehow

00:26:01,360 --> 00:26:04,880
out of the box the tool

00:26:02,570 --> 00:26:07,520
[Music]

00:26:04,880 --> 00:26:08,320
and uh here's the structure of the tool

00:26:07,520 --> 00:26:11,360
that

00:26:08,320 --> 00:26:13,120
we created to do the latest measurements

00:26:11,360 --> 00:26:15,200
actually this structure is already

00:26:13,120 --> 00:26:15,840
updated structure it's already different

00:26:15,200 --> 00:26:18,000
from the paper

00:26:15,840 --> 00:26:19,760
published this would probably be the

00:26:18,000 --> 00:26:23,600
version that we've sent on an

00:26:19,760 --> 00:26:24,159
extension of that paper and it has these

00:26:23,600 --> 00:26:27,039
uh

00:26:24,159 --> 00:26:29,440
four let's say components it's two

00:26:27,039 --> 00:26:31,600
components one in kernel

00:26:29,440 --> 00:26:33,840
and one in user space and this user

00:26:31,600 --> 00:26:36,799
space has three subcomments

00:26:33,840 --> 00:26:37,760
and we will get more detail more details

00:26:36,799 --> 00:26:41,520
yeah

00:26:37,760 --> 00:26:45,279
so in the kernel side

00:26:41,520 --> 00:26:47,360
uh we did an internal trace parser

00:26:45,279 --> 00:26:49,600
in which i hooked to the kernel events

00:26:47,360 --> 00:26:52,240
that i need to look at

00:26:49,600 --> 00:26:54,400
and they are mostly the prime and rq

00:26:52,240 --> 00:26:57,679
disabled which happen on a

00:26:54,400 --> 00:27:00,799
very huge frequency on the prem 30

00:26:57,679 --> 00:27:06,400
and also in the iqs that start and

00:27:00,799 --> 00:27:08,480
goes away in the schedule

00:27:06,400 --> 00:27:10,880
as these events happen too often i

00:27:08,480 --> 00:27:11,200
cannot export outstated user space i can

00:27:10,880 --> 00:27:13,520
do

00:27:11,200 --> 00:27:14,320
i need to do the filter here and that's

00:27:13,520 --> 00:27:17,440
what

00:27:14,320 --> 00:27:19,679
these rtsl events do instead of

00:27:17,440 --> 00:27:22,000
exporting all the trace it exports the

00:27:19,679 --> 00:27:25,039
value for the variables that i use

00:27:22,000 --> 00:27:28,799
in the equation so i exported value for

00:27:25,039 --> 00:27:31,679
poid for the psd

00:27:28,799 --> 00:27:33,440
uh here alright process trying to lower

00:27:31,679 --> 00:27:38,080
down the number of events to put for

00:27:33,440 --> 00:27:38,080
user space or to be consumed by the pdf

00:27:40,240 --> 00:27:44,799
and so the point is that this uh this

00:27:43,279 --> 00:27:47,520
internal

00:27:44,799 --> 00:27:48,720
filter it requires some change in the

00:27:47,520 --> 00:27:52,080
kernel

00:27:48,720 --> 00:27:53,679
the measure let's say major thing here

00:27:52,080 --> 00:27:54,880
is that i depend on the primary key

00:27:53,679 --> 00:27:58,559
trace points

00:27:54,880 --> 00:28:00,799
that can cause some overhead uh and so

00:27:58,559 --> 00:28:02,080
this tool won't work for kernels

00:28:00,799 --> 00:28:04,480
compiled to

00:28:02,080 --> 00:28:05,840
have support for this it will not like

00:28:04,480 --> 00:28:09,039
run on any kernel it

00:28:05,840 --> 00:28:11,679
needs these trace points enable the

00:28:09,039 --> 00:28:14,480
completion time but life finds a way we

00:28:11,679 --> 00:28:16,399
can always improve that

00:28:14,480 --> 00:28:18,000
and it also adds some annotation to the

00:28:16,399 --> 00:28:20,480
breadth it's able to notify

00:28:18,000 --> 00:28:21,360
when the preference it was was called

00:28:20,480 --> 00:28:24,799
actually to

00:28:21,360 --> 00:28:26,960
run the scheduler but these are no

00:28:24,799 --> 00:28:28,880
functional chains

00:28:26,960 --> 00:28:30,480
all these things here are no functional

00:28:28,880 --> 00:28:31,919
chains i'm not changing the behavior to

00:28:30,480 --> 00:28:35,919
make the tool to work

00:28:31,919 --> 00:28:38,640
i'm just putting editing annotations

00:28:35,919 --> 00:28:39,679
to to get more information from the

00:28:38,640 --> 00:28:41,760
trace points

00:28:39,679 --> 00:28:43,360
but no functional change that it would

00:28:41,760 --> 00:28:44,480
not make sense to change the kernel to

00:28:43,360 --> 00:28:46,960
to fit

00:28:44,480 --> 00:28:49,200
the tooling right so no functional

00:28:46,960 --> 00:28:52,880
chains

00:28:49,200 --> 00:28:56,000
then i have user space side

00:28:52,880 --> 00:28:57,200
i have the record the rgsl which is a

00:28:56,000 --> 00:28:59,360
command line

00:28:57,200 --> 00:29:01,600
is a tool it was made in python because

00:28:59,360 --> 00:29:02,720
python is easy to make proof of concepts

00:29:01,600 --> 00:29:05,919
right

00:29:02,720 --> 00:29:07,279
so when trying to measure the latency

00:29:05,919 --> 00:29:10,240
using this idea

00:29:07,279 --> 00:29:11,520
the first thing that i do is do an rtsl

00:29:10,240 --> 00:29:13,600
record

00:29:11,520 --> 00:29:14,799
it will enable these events if you hook

00:29:13,600 --> 00:29:16,559
to these events

00:29:14,799 --> 00:29:17,840
and you trace the events that i would

00:29:16,559 --> 00:29:21,919
that i want

00:29:17,840 --> 00:29:24,159
and save it a g r g a cell here

00:29:21,919 --> 00:29:26,000
is a python script that's patched either

00:29:24,159 --> 00:29:28,880
perf or trace command

00:29:26,000 --> 00:29:30,480
and saves the trace data it will get

00:29:28,880 --> 00:29:34,000
easier when i show the demo right

00:29:30,480 --> 00:29:37,200
just explain it here in the bottom uh

00:29:34,000 --> 00:29:38,799
then after doing the record i can do the

00:29:37,200 --> 00:29:42,000
parse of the stress data and the

00:29:38,799 --> 00:29:43,840
analysis of the data that shows me the

00:29:42,000 --> 00:29:45,679
what would be my scheduling latency on

00:29:43,840 --> 00:29:48,799
that system

00:29:45,679 --> 00:29:51,679
so i get the trace file

00:29:48,799 --> 00:29:54,640
and i parse it in parallel per cpu like

00:29:51,679 --> 00:29:57,760
for each cpu i expect one per for one

00:29:54,640 --> 00:30:01,760
uh or one trace command

00:29:57,760 --> 00:30:04,000
and i convert the the trace data into a

00:30:01,760 --> 00:30:08,000
perceptual database

00:30:04,000 --> 00:30:09,679
and the reason for that is because for

00:30:08,000 --> 00:30:11,440
for me to do the analysis of

00:30:09,679 --> 00:30:13,600
interference from my rqs

00:30:11,440 --> 00:30:16,159
i need to go back and forth in the data

00:30:13,600 --> 00:30:18,720
i analyze all the iq's final

00:30:16,159 --> 00:30:19,760
worst case then i using this worst case

00:30:18,720 --> 00:30:21,360
as parameter

00:30:19,760 --> 00:30:22,960
is there any worst case that could be

00:30:21,360 --> 00:30:25,039
even worse because now we

00:30:22,960 --> 00:30:26,080
turn the window a little bit higher than

00:30:25,039 --> 00:30:28,640
barcelona

00:30:26,080 --> 00:30:30,240
so i could do this in memory in the

00:30:28,640 --> 00:30:31,840
first person it was a memory but

00:30:30,240 --> 00:30:34,240
one day of trace generates like

00:30:31,840 --> 00:30:36,640
gigabytes of of data so

00:30:34,240 --> 00:30:37,520
it was not practical that's why i use

00:30:36,640 --> 00:30:40,880
the

00:30:37,520 --> 00:30:44,559
the databases again then

00:30:40,880 --> 00:30:46,480
i dispatch one track per cpu here

00:30:44,559 --> 00:30:47,760
and do the analysis of the latency

00:30:46,480 --> 00:30:49,679
persevere

00:30:47,760 --> 00:30:50,960
and then in the analysis i print a

00:30:49,679 --> 00:30:55,440
analogy in a

00:30:50,960 --> 00:30:55,440
text format and also plot some charts

00:30:58,080 --> 00:31:02,159
[Music]

00:31:00,000 --> 00:31:04,880
okay here i was continuing the

00:31:02,159 --> 00:31:06,880
discussion in our the explanations

00:31:04,880 --> 00:31:08,559
here's one example of the output of the

00:31:06,880 --> 00:31:12,720
two i will show a demo

00:31:08,559 --> 00:31:16,559
soon so but for example here

00:31:12,720 --> 00:31:20,080
i get the maximum values for those trend

00:31:16,559 --> 00:31:22,799
variables the maximum observed value

00:31:20,080 --> 00:31:23,679
and i say okay if i consider no

00:31:22,799 --> 00:31:26,799
interrupts

00:31:23,679 --> 00:31:30,480
my latest would be 42 microseconds

00:31:26,799 --> 00:31:33,120
the time here is in nanosecond

00:31:30,480 --> 00:31:34,720
but at that same time on cyclic test

00:31:33,120 --> 00:31:37,120
running on that cpu

00:31:34,720 --> 00:31:38,000
at the same time frame in parallel it

00:31:37,120 --> 00:31:42,559
just found

00:31:38,000 --> 00:31:45,760
47 and the reason for that

00:31:42,559 --> 00:31:49,039
is that cyclic tests just get one

00:31:45,760 --> 00:31:51,360
it set the timer and it measures

00:31:49,039 --> 00:31:53,200
but we have no evidence that we found

00:31:51,360 --> 00:31:55,360
the worst conditions of

00:31:53,200 --> 00:31:57,039
this case here the worst condition of a

00:31:55,360 --> 00:32:01,200
scheduling delayed worst condition

00:31:57,039 --> 00:32:04,320
of peripheral disable on that set

00:32:01,200 --> 00:32:05,519
and uh here instead of getting like just

00:32:04,320 --> 00:32:08,240
the combination the worst

00:32:05,519 --> 00:32:09,360
scheduling or the worst irq symbol that

00:32:08,240 --> 00:32:12,480
stick together

00:32:09,360 --> 00:32:15,600
i got those separated so i've notes it

00:32:12,480 --> 00:32:16,240
is premature argue disabled in the

00:32:15,600 --> 00:32:19,039
system

00:32:16,240 --> 00:32:20,480
and i know it's this psd and as they are

00:32:19,039 --> 00:32:22,799
independent variables

00:32:20,480 --> 00:32:24,640
i can sum them up and there is the

00:32:22,799 --> 00:32:25,120
background real time here that shows

00:32:24,640 --> 00:32:29,039
that it's

00:32:25,120 --> 00:32:32,159
possible right and then

00:32:29,039 --> 00:32:33,919
okay considering no no uh interrupts i

00:32:32,159 --> 00:32:36,399
can also find already

00:32:33,919 --> 00:32:38,480
uh some some ladies that are higher than

00:32:36,399 --> 00:32:41,279
um

00:32:38,480 --> 00:32:42,880
and psychopaths but then i can use some

00:32:41,279 --> 00:32:44,720
well-known uh ir

00:32:42,880 --> 00:32:46,640
some well well-known irq

00:32:44,720 --> 00:32:49,919
characterizations

00:32:46,640 --> 00:32:53,279
to add also delay caused by rqs

00:32:49,919 --> 00:32:55,600
and uh one common characterization from

00:32:53,279 --> 00:32:56,159
the real-time theory are the periodic

00:32:55,600 --> 00:32:59,360
tests

00:32:56,159 --> 00:33:01,840
like that we use the minimal

00:32:59,360 --> 00:33:03,360
inter-arrival time between two instances

00:33:01,840 --> 00:33:06,559
of the same irq

00:33:03,360 --> 00:33:09,679
or tests of the irq tests and

00:33:06,559 --> 00:33:14,480
the worst case execution time

00:33:09,679 --> 00:33:16,480
of that irq and this is prompt to be

00:33:14,480 --> 00:33:17,679
pessimistic and we discussed at this

00:33:16,480 --> 00:33:20,720
last year and

00:33:17,679 --> 00:33:22,720
in that it is because very often

00:33:20,720 --> 00:33:24,399
the minimum arrival time between two

00:33:22,720 --> 00:33:27,440
instances of an rq

00:33:24,399 --> 00:33:30,240
is even lower than the maximum execution

00:33:27,440 --> 00:33:34,159
time of those error keys

00:33:30,240 --> 00:33:36,960
so yeah sporadic is too pessimistic

00:33:34,159 --> 00:33:38,640
no interrupt is too optimistic and here

00:33:36,960 --> 00:33:39,200
we have the sliding window which is the

00:33:38,640 --> 00:33:42,320
one i

00:33:39,200 --> 00:33:45,919
prefer most that gets this it gets

00:33:42,320 --> 00:33:49,679
it gets the latency the block latency

00:33:45,919 --> 00:33:51,679
and then for each irq it scans all the

00:33:49,679 --> 00:33:55,519
vectors and say okay

00:33:51,679 --> 00:33:56,240
40 is 42 microseconds my req 33 could

00:33:55,519 --> 00:33:59,679
increase it

00:33:56,240 --> 00:34:03,519
in 16 microseconds then

00:33:59,679 --> 00:34:06,399
i get this drq35 and i see that it could

00:34:03,519 --> 00:34:07,519
put up plus 40 microseconds on top of

00:34:06,399 --> 00:34:10,720
this level

00:34:07,519 --> 00:34:13,200
and so on then i i reach

00:34:10,720 --> 00:34:14,960
a latency right using these parameters

00:34:13,200 --> 00:34:16,079
but then i need to go back to our cues

00:34:14,960 --> 00:34:18,399
to say okay

00:34:16,079 --> 00:34:22,480
considering this time we know could i

00:34:18,399 --> 00:34:24,720
feed any more uh interrupts from the 33

00:34:22,480 --> 00:34:26,159
vector and so on and here for the case

00:34:24,720 --> 00:34:28,720
in which the timer

00:34:26,159 --> 00:34:30,240
found could put yet more interrupts in

00:34:28,720 --> 00:34:33,280
this type of window

00:34:30,240 --> 00:34:35,679
and we reach a stable value of 98

00:34:33,280 --> 00:34:37,919
microseconds

00:34:35,679 --> 00:34:37,919
uh

00:34:39,679 --> 00:34:44,079
and then based on that i can also plot

00:34:42,159 --> 00:34:46,159
some charts comparing

00:34:44,079 --> 00:34:48,079
and uh i will do the experiments

00:34:46,159 --> 00:34:50,240
explaining later but

00:34:48,079 --> 00:34:52,560
here are on a system in the same system

00:34:50,240 --> 00:34:55,919
running with the same conditions

00:34:52,560 --> 00:35:00,480
uh yes i probably say uh 47

00:34:55,919 --> 00:35:04,000
when i and when i have to say 27 steven

00:35:00,480 --> 00:35:04,560
uh so here i compared the system with

00:35:04,000 --> 00:35:07,680
eight

00:35:04,560 --> 00:35:09,920
if not 12 cpus here

00:35:07,680 --> 00:35:11,200
these were the values found by cyclic

00:35:09,920 --> 00:35:13,599
test

00:35:11,200 --> 00:35:15,200
and at the same time frame the cycle

00:35:13,599 --> 00:35:18,000
test could not get

00:35:15,200 --> 00:35:18,960
catch these cases in which i'm not even

00:35:18,000 --> 00:35:22,880
considering

00:35:18,960 --> 00:35:23,680
interrupts that got worse then if i just

00:35:22,880 --> 00:35:26,640
added one

00:35:23,680 --> 00:35:28,560
interrupt the worst of them all i could

00:35:26,640 --> 00:35:31,280
even have higher latencies

00:35:28,560 --> 00:35:32,000
and getting one of each interrupt vector

00:35:31,280 --> 00:35:34,000
even higher

00:35:32,000 --> 00:35:35,040
using the slider window and using the

00:35:34,000 --> 00:35:37,359
overlapping

00:35:35,040 --> 00:35:38,079
things so depending on the rq we can

00:35:37,359 --> 00:35:41,839
estimate

00:35:38,079 --> 00:35:43,520
a different uh latency but

00:35:41,839 --> 00:35:45,760
it's hard to define which one is the

00:35:43,520 --> 00:35:46,640
worst and the users of the system should

00:35:45,760 --> 00:35:50,560
say that

00:35:46,640 --> 00:35:50,560
but personally i like this

00:35:51,599 --> 00:35:56,880
so another tool that we can have here is

00:35:54,880 --> 00:36:00,400
the rtsl stocks

00:35:56,880 --> 00:36:03,119
inside the rtsl we have a subcomma that

00:36:00,400 --> 00:36:04,560
it monitors the value of these variables

00:36:03,119 --> 00:36:07,599
the blocking variables

00:36:04,560 --> 00:36:10,000
in kernel using the bpf and i

00:36:07,599 --> 00:36:11,280
save the histograms inside the kernel

00:36:10,000 --> 00:36:14,079
and periodically

00:36:11,280 --> 00:36:15,760
the user space side using python and pcc

00:36:14,079 --> 00:36:17,680
i collect the histograms

00:36:15,760 --> 00:36:20,720
and i show these values there like

00:36:17,680 --> 00:36:23,200
showing i'll show it in the demo

00:36:20,720 --> 00:36:25,119
and it will be more to be more uh

00:36:23,200 --> 00:36:27,839
intuitive

00:36:25,119 --> 00:36:28,160
so i'll show you how the demo now from

00:36:27,839 --> 00:36:33,520
the

00:36:28,160 --> 00:36:33,520
tooling work just a second getting the

00:36:38,839 --> 00:36:44,720
youtube

00:36:41,280 --> 00:36:48,560
so here i

00:36:44,720 --> 00:36:51,040
recorded 10 minutes of the trace and uh

00:36:48,560 --> 00:36:52,560
i did it this yesterday and here is the

00:36:51,040 --> 00:36:56,240
trace data it was with

00:36:52,560 --> 00:36:59,599
f trace it was uh 176

00:36:56,240 --> 00:37:02,160
megabytes of data in the 10 minutes

00:36:59,599 --> 00:37:04,800
you can see it's not it's not too much

00:37:02,160 --> 00:37:07,040
but still considerable amount

00:37:04,800 --> 00:37:09,280
and then i do the report i'm trying to

00:37:07,040 --> 00:37:10,480
make the analysis of the latency with

00:37:09,280 --> 00:37:13,680
these two

00:37:10,480 --> 00:37:15,520
as you see here in the top uh

00:37:13,680 --> 00:37:17,760
it first does some analysis in the trace

00:37:15,520 --> 00:37:19,359
and then i dispatch a tracer perfect

00:37:17,760 --> 00:37:24,640
parallel converting the

00:37:19,359 --> 00:37:27,200
trace into a sql file

00:37:24,640 --> 00:37:28,480
and you see they use all the cpu because

00:37:27,200 --> 00:37:30,240
they're running fully parallel and then

00:37:28,480 --> 00:37:33,359
when it's python is doing the analysis

00:37:30,240 --> 00:37:37,040
you see the analysis is actually fast

00:37:33,359 --> 00:37:38,560
and uh here we can see i'll show some

00:37:37,040 --> 00:37:40,240
values like i have the

00:37:38,560 --> 00:37:43,119
header that i explain what are these

00:37:40,240 --> 00:37:45,920
values and then i show the latest

00:37:43,119 --> 00:37:46,480
analysis of c20 with the actual values

00:37:45,920 --> 00:37:48,000
from the

00:37:46,480 --> 00:37:50,480
system running this is not a very

00:37:48,000 --> 00:37:53,119
optimized system so it'll be large

00:37:50,480 --> 00:37:54,800
and i showed the interrupts how much

00:37:53,119 --> 00:37:56,640
dirt i could have

00:37:54,800 --> 00:37:58,560
and these are the latest analysis i will

00:37:56,640 --> 00:38:01,680
show later in the experiments

00:37:58,560 --> 00:38:04,000
uh some typical values so

00:38:01,680 --> 00:38:05,599
if i run it on the report again i will

00:38:04,000 --> 00:38:07,200
not parse again the traces so the

00:38:05,599 --> 00:38:08,720
analysis will be faster so the vast

00:38:07,200 --> 00:38:10,320
majority of time i'm just converting

00:38:08,720 --> 00:38:13,599
trace into the database

00:38:10,320 --> 00:38:15,680
then as the database is not that slow

00:38:13,599 --> 00:38:16,720
and here are the database files

00:38:15,680 --> 00:38:19,599
generated

00:38:16,720 --> 00:38:21,920
and this in this technical pause here

00:38:19,599 --> 00:38:25,680
and it's good to have these files in

00:38:21,920 --> 00:38:26,960
sql databases because later

00:38:25,680 --> 00:38:28,640
all the researchers that are not

00:38:26,960 --> 00:38:30,320
familiar with linux they could use this

00:38:28,640 --> 00:38:32,560
data to do more

00:38:30,320 --> 00:38:33,440
more sophisticated analysis on iraq for

00:38:32,560 --> 00:38:36,480
example

00:38:33,440 --> 00:38:40,320
and it's straightforward to use a python

00:38:36,480 --> 00:38:41,839
and uh okay steve i was i would later

00:38:40,320 --> 00:38:43,839
these slides

00:38:41,839 --> 00:38:45,359
i forgot to put the double these slices

00:38:43,839 --> 00:38:47,520
down

00:38:45,359 --> 00:38:49,200
anyway these are all available already

00:38:47,520 --> 00:38:52,320
on the site

00:38:49,200 --> 00:38:55,839
but i can put it so uh

00:38:52,320 --> 00:38:56,240
here are the okay this dot rtsl files

00:38:55,839 --> 00:39:01,359
are

00:38:56,240 --> 00:39:05,200
sql pre database

00:39:01,359 --> 00:39:05,200
and now i use the

00:39:06,400 --> 00:39:12,320
the stats to show the values

00:39:09,599 --> 00:39:13,200
that are actually happening on my system

00:39:12,320 --> 00:39:16,800
for the

00:39:13,200 --> 00:39:18,880
poid uh variable

00:39:16,800 --> 00:39:22,000
and here i'm using the bcc to collect

00:39:18,880 --> 00:39:23,760
these variables and show the histograms

00:39:22,000 --> 00:39:25,760
and i can also plot things with matte

00:39:23,760 --> 00:39:29,520
block linear and that's why

00:39:25,760 --> 00:39:33,119
it is scheduled to work with python

00:39:29,520 --> 00:39:36,400
and also i can find where in the system

00:39:33,119 --> 00:39:37,839
uh those like larger point numbers

00:39:36,400 --> 00:39:39,599
happen using the

00:39:37,839 --> 00:39:40,960
using power for example and i can also

00:39:39,599 --> 00:39:43,839
extend rtsl to use

00:39:40,960 --> 00:39:44,800
to make this using the pdf so here for

00:39:43,839 --> 00:39:47,680
example

00:39:44,800 --> 00:39:48,560
uh i can show the trace that i collected

00:39:47,680 --> 00:39:50,480
in which the

00:39:48,560 --> 00:39:52,000
potential iq is able to more than 50

00:39:50,480 --> 00:39:54,839
microseconds

00:39:52,000 --> 00:39:56,240
and that's good for debugging the system

00:39:54,839 --> 00:39:58,400
right

00:39:56,240 --> 00:39:58,400
and

00:39:59,760 --> 00:40:02,640
yeah that's it

00:40:03,200 --> 00:40:08,880
okay thanks thanks uh for posting the

00:40:06,640 --> 00:40:08,880
link

00:40:09,599 --> 00:40:15,599
and uh okay stop

00:40:12,800 --> 00:40:16,640
going fast now i run uh some kind of

00:40:15,599 --> 00:40:19,359
experiment showing

00:40:16,640 --> 00:40:19,760
how how pessimistic we are to using

00:40:19,359 --> 00:40:23,040
these

00:40:19,760 --> 00:40:25,599
uh using this technique

00:40:23,040 --> 00:40:26,800
and here's a single car this is the

00:40:25,599 --> 00:40:29,119
cyclic test

00:40:26,800 --> 00:40:29,920
and this is the latest only considering

00:40:29,119 --> 00:40:32,560
block

00:40:29,920 --> 00:40:33,680
and considering some arrival curves and

00:40:32,560 --> 00:40:36,079
we can see that

00:40:33,680 --> 00:40:37,200
okay i'm getting pessimists for some

00:40:36,079 --> 00:40:39,760
arrival boards

00:40:37,200 --> 00:40:41,680
but still the values are not bad even

00:40:39,760 --> 00:40:42,319
getting the worst conditions that we

00:40:41,680 --> 00:40:45,839
observed

00:40:42,319 --> 00:40:47,839
during a long during a trace

00:40:45,839 --> 00:40:49,440
even put all the worst cases all

00:40:47,839 --> 00:40:51,760
together

00:40:49,440 --> 00:40:53,920
unless we use like a very pessimistic

00:40:51,760 --> 00:40:56,800
arrival curve fire queues

00:40:53,920 --> 00:40:57,440
the values for the req the printer

00:40:56,800 --> 00:41:00,720
latest

00:40:57,440 --> 00:41:03,599
are still good they are still in 100 and

00:41:00,720 --> 00:41:06,720
something here for the supermarket

00:41:03,599 --> 00:41:10,640
and even if i go for the

00:41:06,720 --> 00:41:12,880
for a a case with multiple cpus

00:41:10,640 --> 00:41:15,200
now the experiments i'm running back

00:41:12,880 --> 00:41:16,000
background workload to try to find bad

00:41:15,200 --> 00:41:18,000
case

00:41:16,000 --> 00:41:20,000
you see with the sliding window which is

00:41:18,000 --> 00:41:22,560
the most practical in my opinion

00:41:20,000 --> 00:41:24,319
we are still getting like 250

00:41:22,560 --> 00:41:28,880
microseconds latency

00:41:24,319 --> 00:41:29,520
or here less than 350 microseconds

00:41:28,880 --> 00:41:31,920
latest

00:41:29,520 --> 00:41:34,160
even with pessimism and even with the

00:41:31,920 --> 00:41:37,280
overhead added by these two so

00:41:34,160 --> 00:41:39,760
yeah the printer t does very well even

00:41:37,280 --> 00:41:41,680
when we do some pessimistic analysis

00:41:39,760 --> 00:41:41,920
with all the pessimism that we get from

00:41:41,680 --> 00:41:45,440
the

00:41:41,920 --> 00:41:50,079
the theoretical analysis and that's good

00:41:45,440 --> 00:41:52,480
that's impressive so some remarks here

00:41:50,079 --> 00:41:54,319
the prime party model is the firmness

00:41:52,480 --> 00:41:56,480
can have showing is

00:41:54,319 --> 00:41:59,119
no need to put these around the

00:41:56,480 --> 00:42:02,079
determinism

00:41:59,119 --> 00:42:02,079
oh okay

00:42:07,839 --> 00:42:12,640
it has a potential model that is the

00:42:10,160 --> 00:42:14,800
terminus can we show with the model

00:42:12,640 --> 00:42:16,319
the approach presented for this paper is

00:42:14,800 --> 00:42:18,800
not the end of the line

00:42:16,319 --> 00:42:21,280
instead it is the beginning of a more

00:42:18,800 --> 00:42:25,040
sophisticated analysis that can be done

00:42:21,280 --> 00:42:27,200
by the researchers in a researcher level

00:42:25,040 --> 00:42:28,720
and even though the rtsl finds higher

00:42:27,200 --> 00:42:31,599
latency it's still

00:42:28,720 --> 00:42:33,920
not large enough to to make lyrics not

00:42:31,599 --> 00:42:37,520
usable for the user case that they have

00:42:33,920 --> 00:42:39,520
instead it just fly the usage of printer

00:42:37,520 --> 00:42:41,040
key and even more critical scenarios

00:42:39,520 --> 00:42:43,680
because now we have a more strong gave

00:42:41,040 --> 00:42:47,440
this of the latency

00:42:43,680 --> 00:42:51,119
jrtsl is practical okay we need for now

00:42:47,440 --> 00:42:54,079
to enable some uh some some

00:42:51,119 --> 00:42:55,839
things at compilation time but still

00:42:54,079 --> 00:42:58,960
it's practical because it doesn't add

00:42:55,839 --> 00:43:02,000
enough overhead to turn it on practical

00:42:58,960 --> 00:43:04,560
arcgis versus psychic tests

00:43:02,000 --> 00:43:05,520
they are not rival they do they help the

00:43:04,560 --> 00:43:08,160
same people

00:43:05,520 --> 00:43:10,240
but the rtsl is a more specific tool it

00:43:08,160 --> 00:43:13,040
covers worst cases

00:43:10,240 --> 00:43:14,000
uh but it depends on kernel features and

00:43:13,040 --> 00:43:15,680
it does a

00:43:14,000 --> 00:43:18,000
worst case scenario it doesn't it's not

00:43:15,680 --> 00:43:21,040
shown yet like a minimum in an

00:43:18,000 --> 00:43:22,480
average case i think that has another

00:43:21,040 --> 00:43:26,560
purpose

00:43:22,480 --> 00:43:29,839
and capture other things uh and uh

00:43:26,560 --> 00:43:32,480
curiosity whenever an air can sell

00:43:29,839 --> 00:43:34,400
to get a recycling test it's added in

00:43:32,480 --> 00:43:37,280
for each microseconds overhead

00:43:34,400 --> 00:43:39,119
over psychic test so as you can see the

00:43:37,280 --> 00:43:41,119
rtsl is not adding

00:43:39,119 --> 00:43:43,359
too much overhead instead it's it's

00:43:41,119 --> 00:43:44,960
impressive to see just four microseconds

00:43:43,359 --> 00:43:46,640
giving the amount of trace that we need

00:43:44,960 --> 00:43:49,680
to use

00:43:46,640 --> 00:43:50,880
the code is on my github i was planning

00:43:49,680 --> 00:43:54,319
to send it today

00:43:50,880 --> 00:43:55,280
it's based on 5.6 that was the latest

00:43:54,319 --> 00:43:58,640
art internal

00:43:55,280 --> 00:43:58,640
up to earlier this week

00:43:59,119 --> 00:44:04,800
oh yeah no i said i said here that

00:44:02,160 --> 00:44:06,480
the cyclic test could run on a potato

00:44:04,800 --> 00:44:08,160
that from linux and it says that

00:44:06,480 --> 00:44:10,240
if limits run on a potato you can run

00:44:08,160 --> 00:44:13,280
second test but that's not the

00:44:10,240 --> 00:44:16,640
rtsl case because it meets the printer t

00:44:13,280 --> 00:44:18,160
with some tweaks so

00:44:16,640 --> 00:44:20,880
i was planning to send today the kernel

00:44:18,160 --> 00:44:23,920
patches but there is a newer rng version

00:44:20,880 --> 00:44:24,599
should i send it with 5.6 or should i

00:44:23,920 --> 00:44:29,200
update it

00:44:24,599 --> 00:44:33,680
5.96 that should i send it to 65.6 or

00:44:29,200 --> 00:44:36,400
updates six to five nine

00:44:33,680 --> 00:44:37,359
and um yeah that's it i'm open for

00:44:36,400 --> 00:44:39,760
questioning

00:44:37,359 --> 00:44:39,760
and uh

00:44:45,920 --> 00:44:53,839
i'm making time

00:44:51,200 --> 00:44:53,839
don't be shy

00:45:00,560 --> 00:45:05,839
no questions that's bad

00:45:06,960 --> 00:45:13,440
if primit rt is

00:45:10,160 --> 00:45:17,760
disabled u2 keys

00:45:13,440 --> 00:45:21,200
is still could be used in

00:45:17,760 --> 00:45:24,880
analyze the system latency

00:45:21,200 --> 00:45:28,880
okay i didn't get the question could you

00:45:24,880 --> 00:45:32,000
i mean if the pre uh premature

00:45:28,880 --> 00:45:34,640
preemption preemptor rt

00:45:32,000 --> 00:45:36,079
disabled the macro of the preview

00:45:34,640 --> 00:45:39,839
preemptor

00:45:36,079 --> 00:45:39,839
rt disabled

00:45:40,079 --> 00:45:45,280
u2 keys could still analyze the system

00:45:42,880 --> 00:45:48,640
lengthy

00:45:45,280 --> 00:45:52,240
if i don't have like the yeah

00:45:48,640 --> 00:45:56,400
if we don't have the primitive rt you

00:45:52,240 --> 00:45:56,400
ui rttl

00:45:56,640 --> 00:46:02,960
okay is you mean if i don't have the

00:46:00,640 --> 00:46:06,640
trace points enabled do you mean

00:46:02,960 --> 00:46:09,839
if i could yeah yeah yeah i mean we just

00:46:06,640 --> 00:46:14,319
utilized the current trace point

00:46:09,839 --> 00:46:14,720
and uh and but we didn't uh uh enable

00:46:14,319 --> 00:46:17,760
the

00:46:14,720 --> 00:46:21,359
primitive rt uh so you you

00:46:17,760 --> 00:46:25,280
if the two keys you have mentioned

00:46:21,359 --> 00:46:25,280
could be utilized the uh uh

00:46:26,319 --> 00:46:29,440
look let me let me try to state the

00:46:28,400 --> 00:46:32,319
question and see if i

00:46:29,440 --> 00:46:33,119
get the right thing would your analysis

00:46:32,319 --> 00:46:37,040
tools

00:46:33,119 --> 00:46:39,280
work on a normal non-pre non-rt kernel

00:46:37,040 --> 00:46:40,839
is that what you're asking yeah yeah

00:46:39,280 --> 00:46:43,760
that is

00:46:40,839 --> 00:46:45,920
okay now because it's based on

00:46:43,760 --> 00:46:48,319
the precise specification of the model

00:46:45,920 --> 00:46:51,200
for the primary key

00:46:48,319 --> 00:46:53,680
for for us to extend it for the no for

00:46:51,200 --> 00:46:57,520
the preemptive but not rt

00:46:53,680 --> 00:46:57,839
i need to analyze this the the software

00:46:57,520 --> 00:47:01,119
queue

00:46:57,839 --> 00:47:04,400
how the software queue behaves on the

00:47:01,119 --> 00:47:06,240
on the primitive but not rt

00:47:04,400 --> 00:47:08,240
if they still have a higher priority

00:47:06,240 --> 00:47:08,960
then threads then i would have to edit

00:47:08,240 --> 00:47:10,880
it

00:47:08,960 --> 00:47:12,079
on the bound that delay caused by

00:47:10,880 --> 00:47:14,880
software accused

00:47:12,079 --> 00:47:16,560
it would not be that hard for the

00:47:14,880 --> 00:47:18,720
non-primitive kernel

00:47:16,560 --> 00:47:20,559
then we need a different analysis

00:47:18,720 --> 00:47:25,839
because the premise model is different

00:47:20,559 --> 00:47:25,839
and this is restricted to the primitive

00:47:27,040 --> 00:47:30,800
that's why it's very specific thing

00:47:34,400 --> 00:47:41,680
here mute or oh it's tough to me

00:47:39,119 --> 00:47:42,960
oh actually i just want to jump in i was

00:47:41,680 --> 00:47:45,040
i kind of missed a little bit because my

00:47:42,960 --> 00:47:48,000
microphone went dead i had a log

00:47:45,040 --> 00:47:50,240
i hang up and so by the way one thing

00:47:48,000 --> 00:47:53,119
about if you do it without preempt rt

00:47:50,240 --> 00:47:56,880
you there is you have unbounded latency

00:47:53,119 --> 00:47:56,880
so the worst case scenario is infinite

00:47:58,160 --> 00:48:04,079
yeah yeah yeah you can write it

00:48:01,760 --> 00:48:05,680
and see what the system would be but the

00:48:04,079 --> 00:48:06,960
analysis should probably come up with an

00:48:05,680 --> 00:48:08,800
infinite scenario

00:48:06,960 --> 00:48:10,319
well is that really true i mean that

00:48:08,800 --> 00:48:12,240
depends on your restrictions on

00:48:10,319 --> 00:48:14,800
interrupts and other things right

00:48:12,240 --> 00:48:16,960
no actually i could set i could actually

00:48:14,800 --> 00:48:20,480
set up a system where you will i will

00:48:16,960 --> 00:48:23,119
um if i were not to use pi

00:48:20,480 --> 00:48:25,599
futexes and such or whatever i mean if i

00:48:23,119 --> 00:48:27,520
were to set up a system where

00:48:25,599 --> 00:48:29,520
i could inside the kernel i think i

00:48:27,520 --> 00:48:31,920
could probably pin things up so i could

00:48:29,520 --> 00:48:33,520
preempt something i i did this before

00:48:31,920 --> 00:48:35,119
i was able to hang attac hang the

00:48:33,520 --> 00:48:37,599
highest priority tasks

00:48:35,119 --> 00:48:38,720
that shared a resource deadlocked or

00:48:37,599 --> 00:48:41,119
live lock it

00:48:38,720 --> 00:48:42,960
but well no it wasn't deadlocked it was

00:48:41,119 --> 00:48:45,680
what happened was

00:48:42,960 --> 00:48:48,960
no it was the simple pre-iron priority

00:48:45,680 --> 00:48:48,960
inversion i had three tasks

00:48:49,119 --> 00:48:52,720
the same resource had it so that the

00:48:51,119 --> 00:48:54,000
high would block on the low and then the

00:48:52,720 --> 00:48:55,520
middle one would run

00:48:54,000 --> 00:48:57,760
never letting the low one release the

00:48:55,520 --> 00:48:58,640
lock and the high wind would stay there

00:48:57,760 --> 00:49:01,119
forever

00:48:58,640 --> 00:49:03,839
okay that's the that's the pi test

00:49:01,119 --> 00:49:06,000
that's in rt tests

00:49:03,839 --> 00:49:08,079
well you can we test that you can look

00:49:06,000 --> 00:49:10,000
that up from a if you don't use pi mu

00:49:08,079 --> 00:49:11,599
texas in the real case you could lock up

00:49:10,000 --> 00:49:12,240
a normal rt curl i'm saying i did this

00:49:11,599 --> 00:49:14,800
in the kernel

00:49:12,240 --> 00:49:15,440
i had the kernel is able to trigger this

00:49:14,800 --> 00:49:17,200
interesting

00:49:15,440 --> 00:49:18,720
we should probably let clark ask this

00:49:17,200 --> 00:49:19,200
question and we're kind of at the end of

00:49:18,720 --> 00:49:22,240
time

00:49:19,200 --> 00:49:23,760
um afterwards well i guess it was just i

00:49:22,240 --> 00:49:27,040
guess i was just observing that

00:49:23,760 --> 00:49:30,400
uh it since the model the current model

00:49:27,040 --> 00:49:31,839
is is kind of uh built around preempt rt

00:49:30,400 --> 00:49:33,839
doesn't that imply that any time we

00:49:31,839 --> 00:49:34,240
change that scheduler parameter we have

00:49:33,839 --> 00:49:37,280
to

00:49:34,240 --> 00:49:41,280
you have to generate a new model

00:49:37,280 --> 00:49:44,720
the analysis is all done it's a model

00:49:41,280 --> 00:49:45,359
it's a scheduler agnostic i'm not using

00:49:44,720 --> 00:49:47,839
any

00:49:45,359 --> 00:49:48,800
abstraction that is for one specific

00:49:47,839 --> 00:49:50,960
scheduler

00:49:48,800 --> 00:49:52,800
i i guess what i'm saying though is if

00:49:50,960 --> 00:49:54,400
you switch from using a preempt rt

00:49:52,800 --> 00:49:55,119
kernel to say just a plain preempt

00:49:54,400 --> 00:49:57,760
kernel

00:49:55,119 --> 00:49:57,760
or volunteer

00:50:00,240 --> 00:50:03,760
i need to create another model that

00:50:01,760 --> 00:50:05,680
represents that preemption model

00:50:03,760 --> 00:50:06,960
and then i should do the analysis on

00:50:05,680 --> 00:50:10,559
that breakthrough

00:50:06,960 --> 00:50:11,920
right it's first b6413 i have a question

00:50:10,559 --> 00:50:13,920
i'm curious would your model actually

00:50:11,920 --> 00:50:15,359
catch the priority inversion

00:50:13,920 --> 00:50:17,680
or is it just assume that there's

00:50:15,359 --> 00:50:21,359
priority inheritance

00:50:17,680 --> 00:50:24,400
uh the model didn't model the

00:50:21,359 --> 00:50:26,480
the status of the

00:50:24,400 --> 00:50:27,760
of the locking we can create a model for

00:50:26,480 --> 00:50:30,640
this but the model is not

00:50:27,760 --> 00:50:31,839
capturing oh that's right so so actually

00:50:30,640 --> 00:50:34,079
we could have longer

00:50:31,839 --> 00:50:35,839
um a high priority price that's just to

00:50:34,079 --> 00:50:36,640
schedule a wake up so basically assuming

00:50:35,839 --> 00:50:38,400
that the

00:50:36,640 --> 00:50:40,000
the guy that's not holding any resources

00:50:38,400 --> 00:50:42,240
is just waking up that's what you're

00:50:40,000 --> 00:50:44,480
basically modeling

00:50:42,240 --> 00:50:47,280
yeah yeah so that might work on a

00:50:44,480 --> 00:50:50,800
non-preempt kernel

00:50:47,280 --> 00:50:53,200
the point is the is the

00:50:50,800 --> 00:50:54,559
software cues is the software queues

00:50:53,200 --> 00:50:56,559
behaving in the same way

00:50:54,559 --> 00:50:57,839
that in the predictor key are they not

00:50:56,559 --> 00:51:00,400
on the thread context

00:50:57,839 --> 00:51:02,000
yeah that's the difference if then we

00:51:00,400 --> 00:51:04,880
need to add the abstraction of

00:51:02,000 --> 00:51:06,839
the software key if software can wear on

00:51:04,880 --> 00:51:09,760
threads it would work

00:51:06,839 --> 00:51:11,280
probably okay we're out of time but

00:51:09,760 --> 00:51:13,040
there's nothing after us

00:51:11,280 --> 00:51:14,880
uh people that need to go to another

00:51:13,040 --> 00:51:16,079
talk go to their talk i i have to go

00:51:14,880 --> 00:51:17,599
somewhere else but

00:51:16,079 --> 00:51:19,280
i don't see any reason not to continue

00:51:17,599 --> 00:51:20,880
the conversation right here right but i

00:51:19,280 --> 00:51:22,000
want to take a time out to thank daniel

00:51:20,880 --> 00:51:23,440
and thank everybody for the questions

00:51:22,000 --> 00:51:25,280
and everything and

00:51:23,440 --> 00:51:27,119
uh you know great start to the last day

00:51:25,280 --> 00:51:30,000
of plumbers thank you very much

00:51:27,119 --> 00:51:31,920
thanks i'm off to ctf so talk to you

00:51:30,000 --> 00:51:34,079
guys later okay

00:51:31,920 --> 00:51:35,520
i have a question i have a question

00:51:34,079 --> 00:51:37,599
about the

00:51:35,520 --> 00:51:39,920
because in most of the charts we see

00:51:37,599 --> 00:51:41,280
cyclic test as a lower latency than most

00:51:39,920 --> 00:51:44,160
of the models

00:51:41,280 --> 00:51:44,720
i'm curious if there is a way to tune

00:51:44,160 --> 00:51:47,920
the model

00:51:44,720 --> 00:51:49,520
so it shows the same data as the one you

00:51:47,920 --> 00:51:52,079
get from the experiment we

00:51:49,520 --> 00:51:52,079
psychic test

00:51:53,119 --> 00:51:59,040
well i could ignore that i could just

00:51:56,480 --> 00:52:01,680
capture the case in which the

00:51:59,040 --> 00:52:02,960
twix up that it said before scan is

00:52:01,680 --> 00:52:06,160
actually

00:52:02,960 --> 00:52:08,720
being called to being called

00:52:06,160 --> 00:52:09,920
being heated because of cyclic tests

00:52:08,720 --> 00:52:11,839
trying to run

00:52:09,920 --> 00:52:15,440
but that would not make much sense from

00:52:11,839 --> 00:52:15,440
the real-time scheduling theory

00:52:15,839 --> 00:52:20,000
i'm just curious if it's because cyclic

00:52:18,480 --> 00:52:25,040
test is so active

00:52:20,000 --> 00:52:28,319
and it makes a difference in the latency

00:52:25,040 --> 00:52:29,599
compared to the other models out here

00:52:28,319 --> 00:52:32,960
are running at the same time

00:52:29,599 --> 00:52:35,760
i'm running in parallel i expect a test

00:52:32,960 --> 00:52:37,280
a test which is i'm tracing to get these

00:52:35,760 --> 00:52:40,000
values

00:52:37,280 --> 00:52:43,599
while cyclic test is running so i'm

00:52:40,000 --> 00:52:43,599
capturing the same scenario here

00:52:44,400 --> 00:52:50,240
and analyze said same uh same system at

00:52:46,960 --> 00:52:50,240
the same time with same workload

00:52:50,960 --> 00:52:57,119
and yeah it's getting it's getting uh

00:52:55,680 --> 00:53:00,480
lower because it doesn't capture the

00:52:57,119 --> 00:53:02,240
worst scenarios

00:53:00,480 --> 00:53:03,920
and actually it doesn't mean here that

00:53:02,240 --> 00:53:05,040
the worst scenarios took place all

00:53:03,920 --> 00:53:08,480
together

00:53:05,040 --> 00:53:08,800
right the formula allows us to post late

00:53:08,480 --> 00:53:11,760
that

00:53:08,800 --> 00:53:12,800
uh this could be the latest the higher

00:53:11,760 --> 00:53:17,200
latency but it

00:53:12,800 --> 00:53:17,200
actually might not have happened in this

00:53:26,839 --> 00:53:30,880
sequence

00:53:29,200 --> 00:53:33,520
question should i send the pet set based

00:53:30,880 --> 00:53:37,200
on 5.6 as it is now or should i

00:53:33,520 --> 00:53:42,640
update for 509 and send it to

00:53:37,200 --> 00:53:46,160
next week what do you think

00:53:42,640 --> 00:53:48,319
um i said we just set it up for the next

00:53:46,160 --> 00:53:48,319
one

00:53:49,920 --> 00:53:53,040
it was a good talk though daniel

00:53:54,319 --> 00:53:59,920
yeah it's a little bit heavy yeah that's

00:53:57,040 --> 00:54:01,599
no it's not that bad

00:53:59,920 --> 00:54:03,119
okay well i'm gonna have to go to

00:54:01,599 --> 00:54:06,400
another meeting so

00:54:03,119 --> 00:54:08,720
anyway thank you sir thank you all

00:54:06,400 --> 00:54:08,720
thank you

00:54:09,440 --> 00:54:13,200
yeah sir you all uh i don't have a beer

00:54:11,760 --> 00:54:16,000
because i'm tired

00:54:13,200 --> 00:54:18,800
and it's late here it's time to go home

00:54:16,000 --> 00:54:18,800
i'm actually home

00:54:19,599 --> 00:54:25,839
thank you congrats daniel

00:54:36,839 --> 00:54:39,839
thanks

01:03:58,799 --> 01:04:13,839
you are currently the only person in

01:04:00,400 --> 01:04:13,839
this conference

02:40:16,880 --> 02:40:18,960

YouTube URL: https://www.youtube.com/watch?v=_aQ29PrQ86M


