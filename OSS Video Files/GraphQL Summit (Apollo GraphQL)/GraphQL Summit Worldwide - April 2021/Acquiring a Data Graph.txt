Title: Acquiring a Data Graph
Publication date: 2021-04-13
Playlist: GraphQL Summit Worldwide - April 2021
Description: 
	Merger and acquisition consulting is common in the business world, but how does one accommodate this in a technical sense? 

Taz will take you on the journey of his team solving this problem, by leveraging sophisticated GraphQL simulation on top of Federation.

Key takeaways:
* How GraphQL helped a company unify data from multiple acquisitions
* Why aligning on naming is so important
* How Apollo Federation eased this process

Resources:
Learn more about Summit - https://summit.graphql.com/
Explore the GraphQL FAQs - https://www.apollographql.com/docs/resources/faq
Checkout the Apollo docs - https://www.apollographql.com/docs/
Learn GraphQL using Apollo's Tutorials: https://odyssey.apollographql.com/
Captions: 
	00:00:00,740 --> 00:00:12,970
[Music]

00:00:14,400 --> 00:00:17,119
hey everyone

00:00:15,200 --> 00:00:18,480
i'm taz singh and this is a picture of

00:00:17,119 --> 00:00:20,160
me from a prior summit

00:00:18,480 --> 00:00:22,320
back when i was younger but still quite

00:00:20,160 --> 00:00:23,840
foolish since that summit i've gained a

00:00:22,320 --> 00:00:25,599
bit of a reputation for being able to

00:00:23,840 --> 00:00:26,400
take perceivably insurmountable

00:00:25,599 --> 00:00:27,599
challenges

00:00:26,400 --> 00:00:29,039
and breaking them down to be

00:00:27,599 --> 00:00:30,560
understandable enough for an elegant

00:00:29,039 --> 00:00:32,079
solution to be applied

00:00:30,560 --> 00:00:34,079
today i'm here to tell you about one of

00:00:32,079 --> 00:00:36,320
such stories which has been my team's

00:00:34,079 --> 00:00:38,320
area of focus for the past two years

00:00:36,320 --> 00:00:40,000
you see we've been contracted by a large

00:00:38,320 --> 00:00:41,520
publicly traded corporation to assist

00:00:40,000 --> 00:00:43,360
with their data architecture

00:00:41,520 --> 00:00:44,480
and well this is actually the very first

00:00:43,360 --> 00:00:46,079
engineering presentation that

00:00:44,480 --> 00:00:47,840
corporation's ever given

00:00:46,079 --> 00:00:49,120
so without further ado i'd like to tell

00:00:47,840 --> 00:00:51,680
you more about our story

00:00:49,120 --> 00:00:53,360
at residio don't recognize that name

00:00:51,680 --> 00:00:56,079
well maybe you've seen this slide at

00:00:53,360 --> 00:00:57,840
apple's wwdc keynote last year

00:00:56,079 --> 00:01:00,000
and over here you'll see that residue

00:00:57,840 --> 00:01:01,280
name once again alongside other industry

00:01:00,000 --> 00:01:04,000
members such as google

00:01:01,280 --> 00:01:05,280
amazon apple of course ikea smartthings

00:01:04,000 --> 00:01:07,119
and so on

00:01:05,280 --> 00:01:08,720
you've likely clued in by now that it's

00:01:07,119 --> 00:01:10,000
an internet of things company but why is

00:01:08,720 --> 00:01:11,680
the name so foreign

00:01:10,000 --> 00:01:14,000
especially given the companies keeping

00:01:11,680 --> 00:01:15,520
on the slide well what if i told you is

00:01:14,000 --> 00:01:16,479
actually a fortune 100 company in

00:01:15,520 --> 00:01:18,720
disguise

00:01:16,479 --> 00:01:21,600
that's right it's really honeywell in

00:01:18,720 --> 00:01:23,360
disguise because you see back in 2019

00:01:21,600 --> 00:01:24,640
honeywell spun off its home division to

00:01:23,360 --> 00:01:26,400
form residio

00:01:24,640 --> 00:01:28,320
and with that spin-off resulted in

00:01:26,400 --> 00:01:29,200
residio taking on the large data

00:01:28,320 --> 00:01:31,920
heritage that

00:01:29,200 --> 00:01:33,360
that honeywell had including well now

00:01:31,920 --> 00:01:35,200
taking over the honeywell home app

00:01:33,360 --> 00:01:37,680
itself it's now called honeywell home

00:01:35,200 --> 00:01:38,320
by residio along with that app came a

00:01:37,680 --> 00:01:40,000
few more

00:01:38,320 --> 00:01:41,759
including all of these that we can see

00:01:40,000 --> 00:01:43,200
from the apple app store

00:01:41,759 --> 00:01:44,640
of course these are just the apple apps

00:01:43,200 --> 00:01:46,240
it doesn't include all the web apps and

00:01:44,640 --> 00:01:46,799
android apps that presidio also took

00:01:46,240 --> 00:01:48,479
over

00:01:46,799 --> 00:01:50,640
but anyway just to name a few on this

00:01:48,479 --> 00:01:52,079
screen we have total connect comfort

00:01:50,640 --> 00:01:54,479
that honeywell home app i mentioned

00:01:52,079 --> 00:01:56,640
before total connect 2.0

00:01:54,479 --> 00:01:59,759
w box and i don't even know what that is

00:01:56,640 --> 00:02:01,360
um alarmnet360 and so on

00:01:59,759 --> 00:02:02,880
the thing about each of these apps is

00:02:01,360 --> 00:02:03,759
that they all have different user

00:02:02,880 --> 00:02:05,520
account systems

00:02:03,759 --> 00:02:06,960
because they have different back back

00:02:05,520 --> 00:02:09,039
ends entirely as well

00:02:06,960 --> 00:02:10,080
with very few of those components shared

00:02:09,039 --> 00:02:11,440
amongst each other

00:02:10,080 --> 00:02:13,040
so because they have different user

00:02:11,440 --> 00:02:14,319
account systems if you have a user

00:02:13,040 --> 00:02:15,520
account on one

00:02:14,319 --> 00:02:16,959
that doesn't mean that you'll be able to

00:02:15,520 --> 00:02:17,520
log in with the same user account on

00:02:16,959 --> 00:02:19,520
another

00:02:17,520 --> 00:02:21,120
they're basically incredibly fragmented

00:02:19,520 --> 00:02:23,120
systems

00:02:21,120 --> 00:02:24,800
and on top of that they're all at

00:02:23,120 --> 00:02:26,400
they're all at immense load

00:02:24,800 --> 00:02:28,319
i'm actually told that one of these

00:02:26,400 --> 00:02:30,959
back-end systems has an ingress volume

00:02:28,319 --> 00:02:33,280
of around 13 billion requests per day

00:02:30,959 --> 00:02:35,200
by comparison i'm told that twitter only

00:02:33,280 --> 00:02:37,040
has an ingress volume of 9 billion

00:02:35,200 --> 00:02:39,040
requests per day

00:02:37,040 --> 00:02:40,560
each of these even has their own

00:02:39,040 --> 00:02:42,160
business their own product their own

00:02:40,560 --> 00:02:43,840
development their own design and their

00:02:42,160 --> 00:02:45,680
own marketing teams they basically

00:02:43,840 --> 00:02:47,280
operate as independent companies under a

00:02:45,680 --> 00:02:49,280
residual umbrella

00:02:47,280 --> 00:02:50,640
now on top of that residio has made a

00:02:49,280 --> 00:02:52,640
few acquisitions

00:02:50,640 --> 00:02:54,000
of course all of these systems are

00:02:52,640 --> 00:02:55,200
entirely different to residues because

00:02:54,000 --> 00:02:56,640
they're built by entirely different

00:02:55,200 --> 00:02:57,599
teams of course they have different user

00:02:56,640 --> 00:02:58,800
account systems

00:02:57,599 --> 00:03:01,040
of course they have entirely different

00:02:58,800 --> 00:03:03,120
backends because they're acquisitions

00:03:01,040 --> 00:03:05,280
now how would we even go about

00:03:03,120 --> 00:03:06,800
integrating these acquisitions into even

00:03:05,280 --> 00:03:08,080
just the first row of apple apps i

00:03:06,800 --> 00:03:09,360
mentioned before

00:03:08,080 --> 00:03:10,640
each of those are different user

00:03:09,360 --> 00:03:11,920
accounts each each of those are

00:03:10,640 --> 00:03:13,280
different backing systems

00:03:11,920 --> 00:03:14,720
what's the effort to effectively

00:03:13,280 --> 00:03:16,080
integrate any of those does it look

00:03:14,720 --> 00:03:18,080
something like this

00:03:16,080 --> 00:03:19,200
is it a custom integration for each app

00:03:18,080 --> 00:03:21,280
for each acquisition

00:03:19,200 --> 00:03:22,879
that's a bit crazy and furthermore what

00:03:21,280 --> 00:03:24,239
happens when residio acquires yet

00:03:22,879 --> 00:03:25,680
another company like this one that i

00:03:24,239 --> 00:03:26,640
found out about while researching this

00:03:25,680 --> 00:03:28,319
talk

00:03:26,640 --> 00:03:30,000
like does that become a set of custom

00:03:28,319 --> 00:03:31,680
integrations all over again

00:03:30,000 --> 00:03:33,760
how do we effectively scale and maintain

00:03:31,680 --> 00:03:35,599
this with a limited group of engineers

00:03:33,760 --> 00:03:37,840
fundamentally how do we go about

00:03:35,599 --> 00:03:39,920
acquiring a data graph

00:03:37,840 --> 00:03:41,599
well this was the exact problem that my

00:03:39,920 --> 00:03:43,599
team was contracted to solve

00:03:41,599 --> 00:03:45,360
because what we truly want is to get rid

00:03:43,599 --> 00:03:48,720
of all this garbage

00:03:45,360 --> 00:03:51,840
and instead what we want is we want one

00:03:48,720 --> 00:03:53,760
single data graph for all of residio

00:03:51,840 --> 00:03:56,239
we want all of the data providers to

00:03:53,760 --> 00:03:57,920
report into that consolidated data graph

00:03:56,239 --> 00:04:00,000
and we want the data consumers to be

00:03:57,920 --> 00:04:02,159
able to operate on top of it

00:04:00,000 --> 00:04:03,599
okay so we have a general action plan

00:04:02,159 --> 00:04:04,959
moving forward but where do we even

00:04:03,599 --> 00:04:07,439
start with this well

00:04:04,959 --> 00:04:10,799
given it's a graphql talk let's go ahead

00:04:07,439 --> 00:04:10,799
by applying some graph thinking

00:04:11,200 --> 00:04:15,120
typically when when looking at new data

00:04:13,519 --> 00:04:17,120
systems i like to think about how i

00:04:15,120 --> 00:04:17,519
relate to the data system so let's start

00:04:17,120 --> 00:04:20,479
with

00:04:17,519 --> 00:04:22,000
me and one node which represents me so

00:04:20,479 --> 00:04:24,400
how do i relate to the residual

00:04:22,000 --> 00:04:25,520
ecosystem well inside residio i would

00:04:24,400 --> 00:04:27,120
have a house

00:04:25,520 --> 00:04:29,280
and that house would have a bunch of

00:04:27,120 --> 00:04:30,960
smart devices inside of them

00:04:29,280 --> 00:04:32,800
but of course this isn't quite how we

00:04:30,960 --> 00:04:34,400
model things inside graphql we wouldn't

00:04:32,800 --> 00:04:36,080
model things quite literally by the

00:04:34,400 --> 00:04:38,240
things that are represented in the world

00:04:36,080 --> 00:04:39,759
we'd instead group these entities by the

00:04:38,240 --> 00:04:42,720
types that they represent

00:04:39,759 --> 00:04:44,800
so instead i would become a user the

00:04:42,720 --> 00:04:46,320
house would become a location

00:04:44,800 --> 00:04:48,400
and the devices well they would just be

00:04:46,320 --> 00:04:51,120
devices of course so we can simplify

00:04:48,400 --> 00:04:53,919
that object graph into an entity graph

00:04:51,120 --> 00:04:54,840
by just saying a user has a location

00:04:53,919 --> 00:04:57,360
that has

00:04:54,840 --> 00:04:59,600
devices okay so i have a pretty

00:04:57,360 --> 00:05:00,960
simplistic model of how i could relate

00:04:59,600 --> 00:05:03,039
to a device within the residual

00:05:00,960 --> 00:05:03,919
ecosystem now let's check if that

00:05:03,039 --> 00:05:05,680
hypothesis

00:05:03,919 --> 00:05:07,199
actually holds true across the systems

00:05:05,680 --> 00:05:10,240
that we're evaluating

00:05:07,199 --> 00:05:12,000
so thankfully a user that has many

00:05:10,240 --> 00:05:13,120
locations that has many devices does

00:05:12,000 --> 00:05:14,960
seem to hold true

00:05:13,120 --> 00:05:16,720
in quite a few with the residue and it's

00:05:14,960 --> 00:05:18,479
quite a few of the residual systems

00:05:16,720 --> 00:05:20,720
however when we start evaluating more

00:05:18,479 --> 00:05:21,919
systems there's an account that has a

00:05:20,720 --> 00:05:23,440
home that has

00:05:21,919 --> 00:05:25,280
the same definition of device that we

00:05:23,440 --> 00:05:27,120
had in the first in the first system

00:05:25,280 --> 00:05:28,720
and if we were to look at another system

00:05:27,120 --> 00:05:30,800
it's a customer that has a service

00:05:28,720 --> 00:05:32,560
account that has a security alarm panel

00:05:30,800 --> 00:05:33,919
and actually while evaluating that third

00:05:32,560 --> 00:05:35,759
system we found out that

00:05:33,919 --> 00:05:37,039
the first system doesn't hold all types

00:05:35,759 --> 00:05:40,320
of devices only holds

00:05:37,039 --> 00:05:42,320
thermostats in fact okay well this level

00:05:40,320 --> 00:05:44,800
of fragmentation makes it incredibly

00:05:42,320 --> 00:05:48,240
difficult to answer very basic questions

00:05:44,800 --> 00:05:50,639
such as how many users are do we have

00:05:48,240 --> 00:05:52,240
how many devices does a user have all of

00:05:50,639 --> 00:05:54,160
these types of questions are incredibly

00:05:52,240 --> 00:05:55,840
difficult because no system can even

00:05:54,160 --> 00:05:57,759
agree on what a user is

00:05:55,840 --> 00:05:59,440
the system don't even call a user a user

00:05:57,759 --> 00:06:00,800
in the first place they don't even agree

00:05:59,440 --> 00:06:02,720
on what a device is because they don't

00:06:00,800 --> 00:06:03,919
even have a common definition of what a

00:06:02,720 --> 00:06:05,759
device is

00:06:03,919 --> 00:06:07,520
so going back to my original question

00:06:05,759 --> 00:06:09,280
does the hypothesis hold

00:06:07,520 --> 00:06:10,960
it doesn't seem like it does it seems

00:06:09,280 --> 00:06:12,880
like the systems are are way too

00:06:10,960 --> 00:06:14,000
fragmented for that hypothesis to hold

00:06:12,880 --> 00:06:15,919
true

00:06:14,000 --> 00:06:17,120
so where do we start our data

00:06:15,919 --> 00:06:18,960
unification effort

00:06:17,120 --> 00:06:20,479
given this fragmented like fragmented

00:06:18,960 --> 00:06:22,639
data landscape

00:06:20,479 --> 00:06:23,680
well first things first we should align

00:06:22,639 --> 00:06:25,520
on naming

00:06:23,680 --> 00:06:27,039
it doesn't help that every system calls

00:06:25,520 --> 00:06:28,960
everything by different names

00:06:27,039 --> 00:06:30,160
let's first start by applying the same

00:06:28,960 --> 00:06:32,400
name everywhere

00:06:30,160 --> 00:06:33,840
so we started out with this entity graph

00:06:32,400 --> 00:06:35,520
let's just start by calling everything

00:06:33,840 --> 00:06:36,960
that could be a user a user

00:06:35,520 --> 00:06:38,319
all other than that could be a location

00:06:36,960 --> 00:06:39,600
a location and everything that could be

00:06:38,319 --> 00:06:40,560
a device a device

00:06:39,600 --> 00:06:42,319
now of course it's a bit more

00:06:40,560 --> 00:06:43,680
complicated than this in reality than

00:06:42,319 --> 00:06:45,600
just changing the names

00:06:43,680 --> 00:06:47,199
but um you kind of get where i'm going

00:06:45,600 --> 00:06:49,120
we have to align on the naming

00:06:47,199 --> 00:06:51,520
first of all across teams and across

00:06:49,120 --> 00:06:52,880
systems in order to start to try to chip

00:06:51,520 --> 00:06:54,639
away at the problem

00:06:52,880 --> 00:06:56,319
so at the very least now we're all

00:06:54,639 --> 00:06:57,840
talking in the same terms

00:06:56,319 --> 00:07:00,000
so instead of this being a

00:06:57,840 --> 00:07:02,240
representation of terms it's now a

00:07:00,000 --> 00:07:04,080
better representation of which entities

00:07:02,240 --> 00:07:06,720
are held within each system

00:07:04,080 --> 00:07:08,400
and so how do we go about describing

00:07:06,720 --> 00:07:10,080
these systems now

00:07:08,400 --> 00:07:11,919
well thankfully around the same time we

00:07:10,080 --> 00:07:13,680
were exploring this problem was around

00:07:11,919 --> 00:07:16,160
the same time that apollo federation

00:07:13,680 --> 00:07:17,840
started picking up in popularity

00:07:16,160 --> 00:07:19,280
and through that through that through

00:07:17,840 --> 00:07:20,880
that same time i often

00:07:19,280 --> 00:07:22,639
learn quite a bit more about apollo

00:07:20,880 --> 00:07:24,400
federation and one of the things that i

00:07:22,639 --> 00:07:26,240
really like about apollo federation

00:07:24,400 --> 00:07:28,080
is a principled graphql site that was

00:07:26,240 --> 00:07:30,639
marketed alongside it

00:07:28,080 --> 00:07:31,919
you see it very directly aligns with

00:07:30,639 --> 00:07:34,240
what we want

00:07:31,919 --> 00:07:36,319
um we want one data graph which which

00:07:34,240 --> 00:07:37,680
catalogs the entire data offering

00:07:36,319 --> 00:07:40,000
we want it to represent the different

00:07:37,680 --> 00:07:42,160
systems in a federated implementation

00:07:40,000 --> 00:07:43,360
we want to track schemas and registry as

00:07:42,160 --> 00:07:45,039
a single source of truth

00:07:43,360 --> 00:07:46,800
of what should be within that one data

00:07:45,039 --> 00:07:48,240
graph and i'll talk a little bit more

00:07:46,800 --> 00:07:49,599
about those agility principles in the

00:07:48,240 --> 00:07:51,520
later part of this talk but

00:07:49,599 --> 00:07:53,360
so far i mean it aligns pretty well with

00:07:51,520 --> 00:07:55,199
exactly what we want

00:07:53,360 --> 00:07:56,800
but um let's talk a little bit more

00:07:55,199 --> 00:07:58,800
about the technology itself and things

00:07:56,800 --> 00:08:01,360
that i like about that

00:07:58,800 --> 00:08:03,360
specifically apollo federation defines a

00:08:01,360 --> 00:08:04,800
common protocol for federated graphs to

00:08:03,360 --> 00:08:07,039
combine into one data

00:08:04,800 --> 00:08:08,479
offering it comes with a query planner

00:08:07,039 --> 00:08:09,360
that looks at the various data graph

00:08:08,479 --> 00:08:10,800
definitions

00:08:09,360 --> 00:08:12,960
and determines how to execute any

00:08:10,800 --> 00:08:14,160
graphql operation across a federated

00:08:12,960 --> 00:08:15,599
cluster

00:08:14,160 --> 00:08:17,680
this is a little bit different than

00:08:15,599 --> 00:08:19,039
other graphql schema merging tools

00:08:17,680 --> 00:08:21,199
where you may have to define your own

00:08:19,039 --> 00:08:23,039
protocol but of course as with

00:08:21,199 --> 00:08:24,879
as with all things they all have their

00:08:23,039 --> 00:08:26,639
trade-offs at the end of the day

00:08:24,879 --> 00:08:28,240
okay so taking the entity graph that

00:08:26,639 --> 00:08:30,160
we've been working on uh

00:08:28,240 --> 00:08:32,880
let's assign a few labels to them a b

00:08:30,160 --> 00:08:34,479
and c so system a system b and system c

00:08:32,880 --> 00:08:36,080
and let's actually start writing it out

00:08:34,479 --> 00:08:38,719
in graphql

00:08:36,080 --> 00:08:40,479
so um i could define a system a user as

00:08:38,719 --> 00:08:41,279
such and i could define a system b user

00:08:40,479 --> 00:08:44,399
and such

00:08:41,279 --> 00:08:46,080
and i can add both of those to the top

00:08:44,399 --> 00:08:46,959
level query entry point of our data

00:08:46,080 --> 00:08:48,880
graph

00:08:46,959 --> 00:08:50,480
so now if we were to execute a query

00:08:48,880 --> 00:08:51,600
against a data graph a query could look

00:08:50,480 --> 00:08:53,120
like this where we want

00:08:51,600 --> 00:08:55,519
a first name from system a we want a

00:08:53,120 --> 00:08:57,440
first name from system b

00:08:55,519 --> 00:08:58,800
and if we were to execute that operation

00:08:57,440 --> 00:08:59,200
we could get a response that looks like

00:08:58,800 --> 00:09:01,120
this

00:08:59,200 --> 00:09:03,760
where system a responds with a first

00:09:01,120 --> 00:09:04,399
name we could also get a response that

00:09:03,760 --> 00:09:06,080
looks like this

00:09:04,399 --> 00:09:08,800
where system b responds with the first

00:09:06,080 --> 00:09:10,320
name or we could get a response that

00:09:08,800 --> 00:09:11,360
looks like this where no system responds

00:09:10,320 --> 00:09:12,880
with anything

00:09:11,360 --> 00:09:15,040
perhaps we aren't authenticated yet to

00:09:12,880 --> 00:09:17,360
try to to get that type of data

00:09:15,040 --> 00:09:18,959
and fundamentally in every single case

00:09:17,360 --> 00:09:20,560
it's up to the data consumer to

00:09:18,959 --> 00:09:22,240
implement logic to reconcile

00:09:20,560 --> 00:09:24,800
all the different permutations of data

00:09:22,240 --> 00:09:26,399
that the schema technically allows

00:09:24,800 --> 00:09:28,000
because what would happen to a data

00:09:26,399 --> 00:09:30,720
consumer if they got something like this

00:09:28,000 --> 00:09:32,480
where both systems respond

00:09:30,720 --> 00:09:34,160
like thankfully the data in this case

00:09:32,480 --> 00:09:34,959
are equivalent but what if they're

00:09:34,160 --> 00:09:36,480
different

00:09:34,959 --> 00:09:38,000
does the data consumer now need to start

00:09:36,480 --> 00:09:40,480
writing precedence logic to determine

00:09:38,000 --> 00:09:42,320
which system it prefers the data from

00:09:40,480 --> 00:09:43,839
let what happens if we were to introduce

00:09:42,320 --> 00:09:45,600
system c into the mix

00:09:43,839 --> 00:09:47,440
would we then have to update every

00:09:45,600 --> 00:09:49,680
single query for every single data

00:09:47,440 --> 00:09:51,360
consumer to start considering system c

00:09:49,680 --> 00:09:52,800
and then determine precedence logic on

00:09:51,360 --> 00:09:54,480
top of that for all of the new

00:09:52,800 --> 00:09:55,519
permutations responses that are possible

00:09:54,480 --> 00:09:58,240
now

00:09:55,519 --> 00:10:00,000
well this is a valid approach when it

00:09:58,240 --> 00:10:01,120
comes to data unification and we

00:10:00,000 --> 00:10:04,079
actually call this approach

00:10:01,120 --> 00:10:05,200
branching branching is when we expose

00:10:04,079 --> 00:10:07,279
the data literally

00:10:05,200 --> 00:10:09,120
through different data graph branches in

00:10:07,279 --> 00:10:10,880
order to better rationalize the data

00:10:09,120 --> 00:10:12,399
dimensions at play

00:10:10,880 --> 00:10:13,680
fundamentally this allows us to see the

00:10:12,399 --> 00:10:15,600
data which allows us to better

00:10:13,680 --> 00:10:17,360
understand how it's interacted with

00:10:15,600 --> 00:10:19,040
fundamentally leading towards more

00:10:17,360 --> 00:10:20,079
optimal data unification strategies in

00:10:19,040 --> 00:10:23,200
the future

00:10:20,079 --> 00:10:24,640
this is a learning step this gets us to

00:10:23,200 --> 00:10:25,120
a point where we can rationalize the

00:10:24,640 --> 00:10:29,040
data

00:10:25,120 --> 00:10:31,200
much more effectively okay so

00:10:29,040 --> 00:10:32,320
branching enables enables us to model

00:10:31,200 --> 00:10:34,640
this entity graph

00:10:32,320 --> 00:10:35,600
very literally with all the trade-offs

00:10:34,640 --> 00:10:37,839
that come with that

00:10:35,600 --> 00:10:38,640
but what if we can do better what if we

00:10:37,839 --> 00:10:41,120
can model

00:10:38,640 --> 00:10:43,040
the entity graph in a manner that's as

00:10:41,120 --> 00:10:45,839
simple as this

00:10:43,040 --> 00:10:47,519
but is still extended with the unique

00:10:45,839 --> 00:10:48,880
attributes that are present within each

00:10:47,519 --> 00:10:51,519
system

00:10:48,880 --> 00:10:53,760
thankfully this is where graphql data

00:10:51,519 --> 00:10:55,600
expressivity really shines

00:10:53,760 --> 00:10:57,760
graphql sophisticated type system

00:10:55,600 --> 00:10:59,680
enables us to express a variety of data

00:10:57,760 --> 00:11:01,920
architectures in a manner that's simple

00:10:59,680 --> 00:11:04,320
for data consumers

00:11:01,920 --> 00:11:06,079
okay so let's take the graph the graphql

00:11:04,320 --> 00:11:07,760
schema that we had before

00:11:06,079 --> 00:11:09,600
and let's go ahead and introduce an

00:11:07,760 --> 00:11:11,360
interface of the mix

00:11:09,600 --> 00:11:13,120
now we can compose that interface onto

00:11:11,360 --> 00:11:15,120
the types that we had before

00:11:13,120 --> 00:11:17,040
and we can update the top level query

00:11:15,120 --> 00:11:18,000
entry point to simply have a field

00:11:17,040 --> 00:11:20,800
called viewer

00:11:18,000 --> 00:11:22,480
that resolves to that interface now we

00:11:20,800 --> 00:11:24,320
can go ahead and update our query so

00:11:22,480 --> 00:11:25,360
instead of having a list of every single

00:11:24,320 --> 00:11:27,360
system

00:11:25,360 --> 00:11:29,040
in a query we can just say get me the

00:11:27,360 --> 00:11:30,640
viewer's first name

00:11:29,040 --> 00:11:31,760
immediately you can see how much cleaner

00:11:30,640 --> 00:11:33,760
and how much more predictable this

00:11:31,760 --> 00:11:36,079
operation becomes for data consumers

00:11:33,760 --> 00:11:37,519
while still enabling data producers to

00:11:36,079 --> 00:11:39,120
express themselves with a level of

00:11:37,519 --> 00:11:40,800
sophistication

00:11:39,120 --> 00:11:42,560
so now the response to that to that

00:11:40,800 --> 00:11:45,760
operation can simply be

00:11:42,560 --> 00:11:48,640
the first name of tas or it can be null

00:11:45,760 --> 00:11:50,399
it's that easy and that's it it's

00:11:48,640 --> 00:11:51,360
dramatically more predictable for the

00:11:50,399 --> 00:11:53,680
data consumer

00:11:51,360 --> 00:11:56,160
to to to reason about the permutations

00:11:53,680 --> 00:11:57,760
of data that they're getting

00:11:56,160 --> 00:11:59,360
and if we did happen to care about which

00:11:57,760 --> 00:12:01,040
system is responding with data we can

00:11:59,360 --> 00:12:02,800
simply ask for a type name and we can

00:12:01,040 --> 00:12:03,920
ask for more information only present a

00:12:02,800 --> 00:12:05,920
particular type

00:12:03,920 --> 00:12:07,519
in this case system b user has a name

00:12:05,920 --> 00:12:10,480
prefix that we could be interested in

00:12:07,519 --> 00:12:12,240
so we can grab that as well we could get

00:12:10,480 --> 00:12:15,279
a response like this if system b

00:12:12,240 --> 00:12:18,240
was a source of truth for this data

00:12:15,279 --> 00:12:19,360
so we call this approach core entity

00:12:18,240 --> 00:12:21,519
normalization

00:12:19,360 --> 00:12:23,519
where we leverage graphql interfaces to

00:12:21,519 --> 00:12:26,160
expose common data fields as if they

00:12:23,519 --> 00:12:28,880
were being provided by a singular source

00:12:26,160 --> 00:12:31,200
this approach is best for data consumers

00:12:28,880 --> 00:12:32,880
but may require us to gap fill pieces of

00:12:31,200 --> 00:12:33,920
the schema that differ between interface

00:12:32,880 --> 00:12:35,760
implementers

00:12:33,920 --> 00:12:37,680
for example we need to provide a resolve

00:12:35,760 --> 00:12:39,200
type at the very least in order to in

00:12:37,680 --> 00:12:40,800
order for our federated implementation

00:12:39,200 --> 00:12:41,680
to figure out which system to pull data

00:12:40,800 --> 00:12:44,000
from

00:12:41,680 --> 00:12:45,200
and of course this only we can only get

00:12:44,000 --> 00:12:46,000
to this stage once we have an

00:12:45,200 --> 00:12:47,600
understanding

00:12:46,000 --> 00:12:49,680
of what commonalities are within the

00:12:47,600 --> 00:12:51,360
data architecture which we can only

00:12:49,680 --> 00:12:53,839
achieve through the branching approach

00:12:51,360 --> 00:12:56,000
from before

00:12:53,839 --> 00:12:57,120
okay well uh this is all pretty cool

00:12:56,000 --> 00:12:58,959
right we've gone through a few different

00:12:57,120 --> 00:13:00,480
strategies of data unification

00:12:58,959 --> 00:13:02,160
like like now we can hopefully just

00:13:00,480 --> 00:13:02,959
build it right that's as easy as that

00:13:02,160 --> 00:13:05,760
right

00:13:02,959 --> 00:13:06,000
well not really all we've really done so

00:13:05,760 --> 00:13:07,839
far

00:13:06,000 --> 00:13:09,920
is talk about the general shape of what

00:13:07,839 --> 00:13:12,079
we of what we want to build

00:13:09,920 --> 00:13:14,079
actually building a fully executable

00:13:12,079 --> 00:13:15,120
federated cluster of services is a whole

00:13:14,079 --> 00:13:16,720
different story

00:13:15,120 --> 00:13:18,480
and there's a whole lot of other data

00:13:16,720 --> 00:13:20,079
dimensions at play

00:13:18,480 --> 00:13:21,920
so far we've only really talked about

00:13:20,079 --> 00:13:23,680
schema shape which is provided by the

00:13:21,920 --> 00:13:25,360
graphql schema definition language

00:13:23,680 --> 00:13:26,800
and we've talked about federated schema

00:13:25,360 --> 00:13:28,160
ownership which is a which is supplied

00:13:26,800 --> 00:13:29,839
by apollo federation

00:13:28,160 --> 00:13:30,959
but what about entity relationships

00:13:29,839 --> 00:13:33,360
which are the bi-directional

00:13:30,959 --> 00:13:35,680
associations in our case between a user

00:13:33,360 --> 00:13:38,000
their locations and their devices

00:13:35,680 --> 00:13:40,240
what about referential integrity if i

00:13:38,000 --> 00:13:42,240
refer to a given user i want it to be

00:13:40,240 --> 00:13:44,160
that exact same user

00:13:42,240 --> 00:13:45,680
reference throughout the myriad of ways

00:13:44,160 --> 00:13:46,959
that i can access that user throughout

00:13:45,680 --> 00:13:50,079
the data graph

00:13:46,959 --> 00:13:51,040
data pertinence my name is taz it's not

00:13:50,079 --> 00:13:53,199
some random

00:13:51,040 --> 00:13:54,639
characters that formulate a string it is

00:13:53,199 --> 00:13:56,800
taz

00:13:54,639 --> 00:13:58,240
data mutation what are the rules around

00:13:56,800 --> 00:14:00,320
how i can change the data how am i

00:13:58,240 --> 00:14:03,600
allowed to operate on on every field

00:14:00,320 --> 00:14:04,720
are certain fields required data

00:14:03,600 --> 00:14:06,480
authorization

00:14:04,720 --> 00:14:07,839
what governs the data interactions that

00:14:06,480 --> 00:14:09,760
i'm allowed to perform

00:14:07,839 --> 00:14:11,440
and last but certainly not least data

00:14:09,760 --> 00:14:13,440
persistence

00:14:11,440 --> 00:14:15,040
even then this is not an exhaustive or

00:14:13,440 --> 00:14:15,760
academic list this is just whatever i

00:14:15,040 --> 00:14:17,279
thought of

00:14:15,760 --> 00:14:18,560
i'm sure there are other data dimensions

00:14:17,279 --> 00:14:20,000
i play that i haven't explicitly

00:14:18,560 --> 00:14:22,160
mentioned here

00:14:20,000 --> 00:14:23,279
but if we were to wait for teams to

00:14:22,160 --> 00:14:24,880
determine and build

00:14:23,279 --> 00:14:26,959
all of these different various data

00:14:24,880 --> 00:14:28,800
dimensions into their federated services

00:14:26,959 --> 00:14:30,399
we'd probably be waiting for a long time

00:14:28,800 --> 00:14:32,240
before data consumers were actually

00:14:30,399 --> 00:14:34,000
given anything usable

00:14:32,240 --> 00:14:35,360
and even when they were given something

00:14:34,000 --> 00:14:36,320
usable if they didn't like it what

00:14:35,360 --> 00:14:37,920
happens then

00:14:36,320 --> 00:14:39,839
the data producer has to go back and

00:14:37,920 --> 00:14:41,680
redo their database tables migrate their

00:14:39,839 --> 00:14:43,279
data rebuild another executable

00:14:41,680 --> 00:14:44,880
executable schema for yet another round

00:14:43,279 --> 00:14:46,560
of evaluation

00:14:44,880 --> 00:14:48,560
this is where we fundamentally needed a

00:14:46,560 --> 00:14:50,160
solution to continually deliver business

00:14:48,560 --> 00:14:52,079
value while working through the myriad

00:14:50,160 --> 00:14:52,720
of data realities that exist at large

00:14:52,079 --> 00:14:54,320
companies

00:14:52,720 --> 00:14:55,839
with the sort of data heritage that

00:14:54,320 --> 00:14:58,480
residio has

00:14:55,839 --> 00:14:59,199
so what our team came up with was very

00:14:58,480 --> 00:15:02,320
unique

00:14:59,199 --> 00:15:06,320
for our our problem space that is

00:15:02,320 --> 00:15:07,360
graphql simulation this enables a data

00:15:06,320 --> 00:15:09,040
consuming teams

00:15:07,360 --> 00:15:11,199
to rapidly iterate on product

00:15:09,040 --> 00:15:12,000
requirements while data producing teams

00:15:11,199 --> 00:15:15,440
can currently

00:15:12,000 --> 00:15:17,519
turn that schema contract into reality

00:15:15,440 --> 00:15:20,079
we ended up calling our solution giraffe

00:15:17,519 --> 00:15:21,120
ql and i'd like to demo it publicly for

00:15:20,079 --> 00:15:23,360
the very first time

00:15:21,120 --> 00:15:24,639
just for you awesome so let's take a

00:15:23,360 --> 00:15:26,320
look at giraffe ql

00:15:24,639 --> 00:15:27,920
i don't have enough time to go over the

00:15:26,320 --> 00:15:29,920
schema in a lot of depth

00:15:27,920 --> 00:15:31,279
but i'll touch on critical high level

00:15:29,920 --> 00:15:32,639
points that i want to i want to

00:15:31,279 --> 00:15:33,839
highlight for you

00:15:32,639 --> 00:15:35,920
first things first you'll probably

00:15:33,839 --> 00:15:38,639
notice that this is not using

00:15:35,920 --> 00:15:40,000
a schema first style of of graphql

00:15:38,639 --> 00:15:42,079
definition this is using a code

00:15:40,000 --> 00:15:44,079
first style and the reason we do that is

00:15:42,079 --> 00:15:45,680
because it allows us to co-locate

00:15:44,079 --> 00:15:48,079
the definition of all different data

00:15:45,680 --> 00:15:51,040
dimensions on the same type

00:15:48,079 --> 00:15:52,000
we also follow a relay schema

00:15:51,040 --> 00:15:53,759
specification

00:15:52,000 --> 00:15:55,360
which means that we have interfaces such

00:15:53,759 --> 00:15:57,600
as node and so on so forth

00:15:55,360 --> 00:15:59,360
but anyway moving forward um we can see

00:15:57,600 --> 00:16:01,360
this is the same core user interface

00:15:59,360 --> 00:16:03,759
that we had defined before

00:16:01,360 --> 00:16:04,959
we have that uh first name field we have

00:16:03,759 --> 00:16:06,959
that last name field

00:16:04,959 --> 00:16:08,000
we have data pertinent so basically what

00:16:06,959 --> 00:16:10,160
this will this will

00:16:08,000 --> 00:16:11,759
say is that for the first name field we

00:16:10,160 --> 00:16:13,839
want it to look like a first name

00:16:11,759 --> 00:16:15,279
it's pertinent to to that field

00:16:13,839 --> 00:16:17,120
definition itself

00:16:15,279 --> 00:16:18,800
we also i've also gone ahead and defined

00:16:17,120 --> 00:16:20,560
locations on this demo

00:16:18,800 --> 00:16:22,079
so here we can see we have a paginated

00:16:20,560 --> 00:16:24,560
list of locations it is

00:16:22,079 --> 00:16:25,519
a core location interface type and

00:16:24,560 --> 00:16:29,040
critically

00:16:25,519 --> 00:16:31,920
the inverse of this location relation

00:16:29,040 --> 00:16:32,880
is the owner of relation on the location

00:16:31,920 --> 00:16:36,000
itself so

00:16:32,880 --> 00:16:38,079
basically for a given user they have

00:16:36,000 --> 00:16:39,360
a list of locations and from a

00:16:38,079 --> 00:16:41,279
location's perspective

00:16:39,360 --> 00:16:42,720
it's the owner that relates back to the

00:16:41,279 --> 00:16:44,320
same core user

00:16:42,720 --> 00:16:46,160
so if we were to look at the definition

00:16:44,320 --> 00:16:48,720
of a core location interface

00:16:46,160 --> 00:16:51,199
we can see that an owner here has an

00:16:48,720 --> 00:16:52,720
inverse of locations as the relation

00:16:51,199 --> 00:16:54,639
that relates it back to the list of

00:16:52,720 --> 00:16:56,079
locations for a user i hope that makes

00:16:54,639 --> 00:16:58,320
sense and i hope i hope it makes a bit

00:16:56,079 --> 00:17:00,079
more sense if we start executing queries

00:16:58,320 --> 00:17:02,079
so we have a viewer we want to grab the

00:17:00,079 --> 00:17:04,480
first name last name and id

00:17:02,079 --> 00:17:05,520
we can see we we got some data here we

00:17:04,480 --> 00:17:08,319
got a clemmy

00:17:05,520 --> 00:17:10,400
cremin this time um and down here we can

00:17:08,319 --> 00:17:12,880
see the federated query plan to

00:17:10,400 --> 00:17:14,240
to let you know that it is executing a

00:17:12,880 --> 00:17:17,120
fully functional

00:17:14,240 --> 00:17:18,559
uh federated simulated cluster and oh in

00:17:17,120 --> 00:17:20,799
fact we have a system b

00:17:18,559 --> 00:17:23,039
definition over here um again i won't go

00:17:20,799 --> 00:17:24,480
into into this in a lot of detail but

00:17:23,039 --> 00:17:26,319
simply know that it does it does

00:17:24,480 --> 00:17:29,120
physically exist but okay

00:17:26,319 --> 00:17:30,480
let's take a look at this id over here

00:17:29,120 --> 00:17:33,520
and let's execute that

00:17:30,480 --> 00:17:36,880
on a node query

00:17:33,520 --> 00:17:40,000
um at the top level here on core

00:17:36,880 --> 00:17:42,480
user let's grab the id again let's grab

00:17:40,000 --> 00:17:44,480
the first name and last name

00:17:42,480 --> 00:17:46,640
um so we can see that we get

00:17:44,480 --> 00:17:46,880
chlamycruming again so we have some sort

00:17:46,640 --> 00:17:48,960
of

00:17:46,880 --> 00:17:50,400
level of referential integrity across

00:17:48,960 --> 00:17:51,280
these two tabs we're getting the same

00:17:50,400 --> 00:17:54,320
type of data

00:17:51,280 --> 00:17:55,440
for the same user again but okay i think

00:17:54,320 --> 00:17:57,280
we can do better than that let's go

00:17:55,440 --> 00:17:58,720
ahead and grab a location let's grab the

00:17:57,280 --> 00:18:02,559
first location

00:17:58,720 --> 00:18:06,559
and let's grab the edges node

00:18:02,559 --> 00:18:09,679
um id and name of that

00:18:06,559 --> 00:18:12,880
location so um this is

00:18:09,679 --> 00:18:15,919
clemmy's second home and let's

00:18:12,880 --> 00:18:16,880
by grabbing that id there let's pull it

00:18:15,919 --> 00:18:20,640
up inside

00:18:16,880 --> 00:18:24,240
node over here uh on

00:18:20,640 --> 00:18:26,000
core location um grab the idea grin grab

00:18:24,240 --> 00:18:27,280
the name again

00:18:26,000 --> 00:18:29,200
and we should hopefully get the second

00:18:27,280 --> 00:18:31,120
home bam there it is

00:18:29,200 --> 00:18:32,960
but we can go even further than that

00:18:31,120 --> 00:18:34,640
let's take a look at this

00:18:32,960 --> 00:18:36,640
field definition here and how we can

00:18:34,640 --> 00:18:38,640
relate back to a list of locations

00:18:36,640 --> 00:18:39,760
let's grab the owner and let's grab

00:18:38,640 --> 00:18:43,600
their id

00:18:39,760 --> 00:18:46,000
and first name last name once again

00:18:43,600 --> 00:18:47,280
and there we can see that the owner of

00:18:46,000 --> 00:18:50,559
this location

00:18:47,280 --> 00:18:52,240
is clemmy kremen the same clemmy kremen

00:18:50,559 --> 00:18:53,600
as in the first example that's a funny

00:18:52,240 --> 00:18:56,960
name um

00:18:53,600 --> 00:18:58,799
i mean funny for faker anyway

00:18:56,960 --> 00:19:00,960
i hope i've demonstrated that with a

00:18:58,799 --> 00:19:01,840
very declarative style of defining

00:19:00,960 --> 00:19:04,160
schemas

00:19:01,840 --> 00:19:05,600
we can co-locate all the data dimensions

00:19:04,160 --> 00:19:07,840
through simulation

00:19:05,600 --> 00:19:08,799
to make sure that we've provided data

00:19:07,840 --> 00:19:10,880
consumers

00:19:08,799 --> 00:19:12,480
with a path forward on iterating on

00:19:10,880 --> 00:19:14,880
their product requirements

00:19:12,480 --> 00:19:16,160
while concurrently a data producer can

00:19:14,880 --> 00:19:19,440
go ahead and fulfill

00:19:16,160 --> 00:19:20,240
the schema contract perfect i hope you

00:19:19,440 --> 00:19:21,840
enjoyed that

00:19:20,240 --> 00:19:24,880
well let's talk a little bit about the

00:19:21,840 --> 00:19:26,640
future of graphql at residio

00:19:24,880 --> 00:19:29,280
we want to continue working on real-time

00:19:26,640 --> 00:19:30,880
graphql the nature of the data residual

00:19:29,280 --> 00:19:32,320
is inherently real time

00:19:30,880 --> 00:19:33,600
your thermostat could report different

00:19:32,320 --> 00:19:35,280
temperature measurements and you want to

00:19:33,600 --> 00:19:36,960
get all of that in real time

00:19:35,280 --> 00:19:39,840
you want to work on server on client

00:19:36,960 --> 00:19:41,520
graphql so graphql in my opinion is a

00:19:39,840 --> 00:19:43,440
technology that best describes data

00:19:41,520 --> 00:19:44,880
dependencies that are external to the

00:19:43,440 --> 00:19:45,600
system that you're currently operating

00:19:44,880 --> 00:19:47,280
on

00:19:45,600 --> 00:19:49,039
for example if you're a mobile app

00:19:47,280 --> 00:19:49,919
developer interacting with a device over

00:19:49,039 --> 00:19:52,240
bluetooth

00:19:49,919 --> 00:19:53,200
that device's data is external to their

00:19:52,240 --> 00:19:56,160
mobile app that you're

00:19:53,200 --> 00:19:57,440
working on what if we were to extend the

00:19:56,160 --> 00:20:00,960
graphql schema

00:19:57,440 --> 00:20:03,760
on that mobile device to apply a schema

00:20:00,960 --> 00:20:04,880
to the to the actual data from your

00:20:03,760 --> 00:20:06,240
thermostat

00:20:04,880 --> 00:20:08,080
thus making it easy for mobile

00:20:06,240 --> 00:20:09,440
developers to pull in any sort of data

00:20:08,080 --> 00:20:11,360
expressed through graphql

00:20:09,440 --> 00:20:13,039
without caring about where that data

00:20:11,360 --> 00:20:14,960
physically lives

00:20:13,039 --> 00:20:16,400
i want to work on graphql for embedded

00:20:14,960 --> 00:20:18,320
systems of course

00:20:16,400 --> 00:20:19,679
being an iot company we have plenty of

00:20:18,320 --> 00:20:21,360
embedded systems that could

00:20:19,679 --> 00:20:23,520
benefit from graph technology i

00:20:21,360 --> 00:20:25,440
mentioned before that we have that

00:20:23,520 --> 00:20:26,559
large ingress point about 13 billion

00:20:25,440 --> 00:20:28,480
requests per day

00:20:26,559 --> 00:20:30,240
what if that reported directly into

00:20:28,480 --> 00:20:31,440
graphql and reported directly into our

00:20:30,240 --> 00:20:33,760
federated data graph

00:20:31,440 --> 00:20:35,200
what benefits could we see there and

00:20:33,760 --> 00:20:36,640
fundamentally if you're interested in

00:20:35,200 --> 00:20:37,360
working on any of these challenges

00:20:36,640 --> 00:20:39,679
residio

00:20:37,360 --> 00:20:41,679
is hiring please check out the careers

00:20:39,679 --> 00:20:42,960
page and for more info and i'm actually

00:20:41,679 --> 00:20:43,919
told that there will be a graphql

00:20:42,960 --> 00:20:45,760
specific role

00:20:43,919 --> 00:20:47,280
being added on there shortly if you

00:20:45,760 --> 00:20:48,559
follow me on twitter i'm more than happy

00:20:47,280 --> 00:20:50,400
to tweet her to link directly to that

00:20:48,559 --> 00:20:52,559
role whenever it's added

00:20:50,400 --> 00:20:54,799
but if you enjoyed this talk i it

00:20:52,559 --> 00:20:56,400
wouldn't be here without my team so

00:20:54,799 --> 00:20:57,679
thank you so much to everyone that

00:20:56,400 --> 00:21:00,080
worked on this

00:20:57,679 --> 00:21:00,720
thank you brian thank you imran jordan

00:21:00,080 --> 00:21:02,960
marcel

00:21:00,720 --> 00:21:04,480
and shane these are their twitter or

00:21:02,960 --> 00:21:05,840
githubs if you want to follow them more

00:21:04,480 --> 00:21:07,919
and thank you to everyone else that i

00:21:05,840 --> 00:21:11,039
haven't had a moment to explicitly thank

00:21:07,919 --> 00:21:12,240
in this talk but fundamentally thank you

00:21:11,039 --> 00:21:17,840
so much for listening

00:21:12,240 --> 00:21:17,840
i hope you enjoyed it bye for now

00:21:20,500 --> 00:21:28,009
[Music]

00:21:28,960 --> 00:21:31,039

YouTube URL: https://www.youtube.com/watch?v=pfJ0APRrRNQ


