Title: GraphQL at Brigade (Steve Rice)
Publication date: 2018-06-05
Playlist: Apollo Day SF 2018
Description: 
	Talk from Apollo Day SF (May 31, 2018)

Brigade is a venture-backed civic engagement platform that is using Apollo GraphQL in production to power their web and mobile apps. 

* Learn more at https://www.apollographql.com (https://www.apollographql.com/)

* Read our technical blog: https://dev-blog.apollodata.com (https://dev-blog.apollodata.com/)

* Join Apollo's Community Slack group: https://www.apollographql.com/slack

* Register for the 3rd annual GraphQL Summit 2018, the world's largest GraphQL developer conference: https://summit.graphql.com/
Captions: 
	00:00:02,150 --> 00:00:07,640
I'm gonna give you a little bit of an

00:00:04,130 --> 00:00:09,260
overview of graph QL at Brigade and what

00:00:07,640 --> 00:00:11,299
it's done for us what our experience has

00:00:09,260 --> 00:00:12,320
been like adopting it and some of the

00:00:11,299 --> 00:00:14,840
things that we've learned along the way

00:00:12,320 --> 00:00:17,810
so we've been using graph QL in

00:00:14,840 --> 00:00:20,480
production for a year or so we're using

00:00:17,810 --> 00:00:22,730
it across our web apps our Android apps

00:00:20,480 --> 00:00:24,859
and our iOS clients and it serves a

00:00:22,730 --> 00:00:27,140
hundred percent of our data requests we

00:00:24,859 --> 00:00:29,570
don't have a huge team so the benefits

00:00:27,140 --> 00:00:31,099
that graph QL has given us have really

00:00:29,570 --> 00:00:34,010
made a big difference in our ability to

00:00:31,099 --> 00:00:35,510
move quickly and execute well we've

00:00:34,010 --> 00:00:38,240
learned a lot I'm excited to share some

00:00:35,510 --> 00:00:40,190
of that with you today so I'm Steve rice

00:00:38,240 --> 00:00:42,680
I'm a software engineer brigade I'm

00:00:40,190 --> 00:00:45,500
focused on back end and our api's and

00:00:42,680 --> 00:00:48,110
I've been there from before we had graph

00:00:45,500 --> 00:00:50,210
QL all the way through starting at

00:00:48,110 --> 00:00:53,180
bringing in production so I've seen a

00:00:50,210 --> 00:00:55,400
lot of how its evolved over time I'm

00:00:53,180 --> 00:00:57,230
gonna cover most of brigades journey

00:00:55,400 --> 00:00:59,870
with graph QL and there's a lot going on

00:00:57,230 --> 00:01:01,940
there so if something is of interest to

00:00:59,870 --> 00:01:03,920
you please come talk to me after the

00:01:01,940 --> 00:01:05,509
break or anything efforts like that and

00:01:03,920 --> 00:01:07,820
I'd love to talk more about any of this

00:01:05,509 --> 00:01:11,300
in depth I'll start with what brigade is

00:01:07,820 --> 00:01:13,430
how we came to use graph QL how graph QL

00:01:11,300 --> 00:01:15,470
has impacted our development workflow

00:01:13,430 --> 00:01:18,050
and tools discuss what we deal with

00:01:15,470 --> 00:01:19,400
running graph QL in production and end

00:01:18,050 --> 00:01:23,150
up with some of our kind of key

00:01:19,400 --> 00:01:24,980
takeaways from this journey so brigades

00:01:23,150 --> 00:01:27,740
vision is a highly participatory

00:01:24,980 --> 00:01:30,530
democracy in which voters instead of

00:01:27,740 --> 00:01:31,700
donors hold the true source of power so

00:01:30,530 --> 00:01:33,770
we're a company that's focused on

00:01:31,700 --> 00:01:35,870
restoring the feedback loop that exists

00:01:33,770 --> 00:01:37,850
in a healthy democracy between

00:01:35,870 --> 00:01:40,700
representatives and their constituents

00:01:37,850 --> 00:01:42,890
by getting more voters to be engaged so

00:01:40,700 --> 00:01:45,500
that we combat sort of the influence of

00:01:42,890 --> 00:01:47,960
money and politics with direct

00:01:45,500 --> 00:01:50,330
engagement from constituents to their

00:01:47,960 --> 00:01:52,549
politicians so we do this through a

00:01:50,330 --> 00:01:54,650
variety of features things that are kind

00:01:52,549 --> 00:01:57,620
of aimed at being a companion for a

00:01:54,650 --> 00:02:00,470
users civic life a brigade user can use

00:01:57,620 --> 00:02:02,720
the platform to take action directed at

00:02:00,470 --> 00:02:05,000
their representatives she can organize

00:02:02,720 --> 00:02:07,310
with other like-minded voters and hold

00:02:05,000 --> 00:02:09,379
her representatives accountable so you

00:02:07,310 --> 00:02:10,819
can see three of example features here

00:02:09,379 --> 00:02:12,139
or petition experience where

00:02:10,819 --> 00:02:13,630
constituents can tell their

00:02:12,139 --> 00:02:16,570
representatives what they wanted to do

00:02:13,630 --> 00:02:18,460
ooh brigades where organizers can kind

00:02:16,570 --> 00:02:20,890
of recruit others and organize them

00:02:18,460 --> 00:02:23,110
around a political cause and the rep

00:02:20,890 --> 00:02:24,610
tracker which allows users to follow up

00:02:23,110 --> 00:02:26,320
on what their representatives are

00:02:24,610 --> 00:02:28,090
actually doing so they can go to the

00:02:26,320 --> 00:02:30,040
ballot box making an informed decision

00:02:28,090 --> 00:02:32,680
about whether their representatives are

00:02:30,040 --> 00:02:35,620
actually representing them so all of

00:02:32,680 --> 00:02:38,320
these features are drawing from a lot of

00:02:35,620 --> 00:02:40,270
different data sources and what we want

00:02:38,320 --> 00:02:41,920
to do is just provide our users with a

00:02:40,270 --> 00:02:44,290
pretty straight forward and hopefully

00:02:41,920 --> 00:02:45,760
delightful experience so we have an

00:02:44,290 --> 00:02:48,280
architecture to do that that looks a

00:02:45,760 --> 00:02:50,170
little bit something like this we have a

00:02:48,280 --> 00:02:52,660
few different clients so web client

00:02:50,170 --> 00:02:53,920
Android iOS as I mentioned even a web

00:02:52,660 --> 00:02:56,440
server that's doing some of our

00:02:53,920 --> 00:02:58,300
server-side stuff and they all

00:02:56,440 --> 00:03:00,370
communicate with a fleet of different

00:02:58,300 --> 00:03:02,650
micro services and this is managed by

00:03:00,370 --> 00:03:04,620
our graph QL layer so our requests come

00:03:02,650 --> 00:03:08,140
in through Kong which does

00:03:04,620 --> 00:03:10,810
authentication attachment other HTTP

00:03:08,140 --> 00:03:12,340
level like normalization concerns but

00:03:10,810 --> 00:03:14,530
then it performs the network level

00:03:12,340 --> 00:03:16,270
recount routing and hands everything off

00:03:14,530 --> 00:03:18,850
to graph QL to do all the data

00:03:16,270 --> 00:03:20,830
management graph QL is then providing

00:03:18,850 --> 00:03:23,020
everything with a single consistent

00:03:20,830 --> 00:03:25,570
interface in such a way that clients

00:03:23,020 --> 00:03:27,490
don't have to worry about which API am I

00:03:25,570 --> 00:03:29,620
talking to what is this book protocol

00:03:27,490 --> 00:03:31,900
does this service speak how does this

00:03:29,620 --> 00:03:33,670
service differ from other services but

00:03:31,900 --> 00:03:37,420
first it wasn't always this way

00:03:33,670 --> 00:03:39,100
so in 2016 as the election season was

00:03:37,420 --> 00:03:40,300
kind of picking up it was really

00:03:39,100 --> 00:03:42,850
highlighting some of the issues that

00:03:40,300 --> 00:03:45,070
we've been seeing previously supporting

00:03:42,850 --> 00:03:47,500
multiple clients that show different

00:03:45,070 --> 00:03:50,200
experiences of a lot of these like data

00:03:47,500 --> 00:03:52,480
rich kind of product features so we had

00:03:50,200 --> 00:03:56,350
a monolithic application that was

00:03:52,480 --> 00:03:59,770
serving our single internal rails API

00:03:56,350 --> 00:04:00,790
pretty standard tech we're doing restful

00:03:59,770 --> 00:04:04,120
api calls

00:04:00,790 --> 00:04:06,250
we're serving JSON over HTTP we're using

00:04:04,120 --> 00:04:08,050
active model serializers which some

00:04:06,250 --> 00:04:11,350
people may be familiar with to actually

00:04:08,050 --> 00:04:13,690
turn our data into JSON and what we were

00:04:11,350 --> 00:04:17,500
finding is we were doing a lot of

00:04:13,690 --> 00:04:21,609
expensive stuff to serialize our API

00:04:17,500 --> 00:04:23,650
responses so like if we want to have a

00:04:21,609 --> 00:04:25,540
single response for our client which we

00:04:23,650 --> 00:04:27,430
do so they're not making expensive round

00:04:25,540 --> 00:04:29,710
trips we have to provide

00:04:27,430 --> 00:04:32,139
everything that they need inside the

00:04:29,710 --> 00:04:34,750
payload and so this means a lot of like

00:04:32,139 --> 00:04:38,080
nesting of objects kind of arbitrarily

00:04:34,750 --> 00:04:40,509
deeply in our JSON payloads so for

00:04:38,080 --> 00:04:42,970
instance we have positions that users

00:04:40,509 --> 00:04:44,949
can take those users have profiles they

00:04:42,970 --> 00:04:47,530
can be responded to by other users who

00:04:44,949 --> 00:04:50,139
also have profiles then users can

00:04:47,530 --> 00:04:52,180
explain those responses and those users

00:04:50,139 --> 00:04:53,470
also have profiles and then comments

00:04:52,180 --> 00:04:55,750
that also have profiles you can see

00:04:53,470 --> 00:04:58,389
where I'm going and so like an object

00:04:55,750 --> 00:05:00,550
like profile is just all over the place

00:04:58,389 --> 00:05:02,349
in our response not only is this a big

00:05:00,550 --> 00:05:04,660
response but we're duplicating the data

00:05:02,349 --> 00:05:07,090
kind of all over the place and this gets

00:05:04,660 --> 00:05:09,009
expensive for us to even just take what

00:05:07,090 --> 00:05:12,880
we've built up as a query response and

00:05:09,009 --> 00:05:14,320
convert it to a JSON string so we have

00:05:12,880 --> 00:05:17,080
to do things to mitigate this

00:05:14,320 --> 00:05:19,180
so we'll do things like once we get to a

00:05:17,080 --> 00:05:19,720
certain point a certain depth in this

00:05:19,180 --> 00:05:21,610
response

00:05:19,720 --> 00:05:23,349
just stop serializing things that have

00:05:21,610 --> 00:05:25,599
already been serialized you know ten

00:05:23,349 --> 00:05:26,919
times already but now clients have to

00:05:25,599 --> 00:05:28,840
worry about well when I look at a

00:05:26,919 --> 00:05:30,460
profile is it going to look like a

00:05:28,840 --> 00:05:31,630
profile or is it going to look like

00:05:30,460 --> 00:05:33,610
something that has a bunch of null

00:05:31,630 --> 00:05:35,440
fields because we didn't serialize all

00:05:33,610 --> 00:05:38,050
of it so now we're doing null checks

00:05:35,440 --> 00:05:40,210
everywhere in our clients not great and

00:05:38,050 --> 00:05:42,180
of course we have versions and our API

00:05:40,210 --> 00:05:45,250
so that we can support multiple

00:05:42,180 --> 00:05:47,169
backwards compatible versions but that's

00:05:45,250 --> 00:05:48,460
really tough to maintain especially if

00:05:47,169 --> 00:05:50,800
you're trying to do something internal

00:05:48,460 --> 00:05:53,050
we just want to kind of move fast so we

00:05:50,800 --> 00:05:55,030
have an edge version or sort of like our

00:05:53,050 --> 00:05:57,340
own infinite version and now we're back

00:05:55,030 --> 00:05:59,199
to ok every time we make a little API

00:05:57,340 --> 00:06:01,000
change to support a new feature it

00:05:59,199 --> 00:06:04,180
breaks a different client that we didn't

00:06:01,000 --> 00:06:06,099
realize would break with many problems

00:06:04,180 --> 00:06:09,220
comes plenty of bike shedding about how

00:06:06,099 --> 00:06:10,870
to fix them and so we have to kind of go

00:06:09,220 --> 00:06:12,639
through this whole API proposal every

00:06:10,870 --> 00:06:14,470
time we want to make a change get

00:06:12,639 --> 00:06:16,690
sign-off from all the key stakeholders

00:06:14,470 --> 00:06:18,520
and really becomes this process heavy

00:06:16,690 --> 00:06:21,970
thing just to like build a new feature

00:06:18,520 --> 00:06:24,400
on our API so to address sort of the

00:06:21,970 --> 00:06:26,409
serialization needs we looked at kind of

00:06:24,400 --> 00:06:28,720
just flattening our API responses where

00:06:26,409 --> 00:06:31,120
we could reference things somewhere

00:06:28,720 --> 00:06:34,240
within the API response and then just

00:06:31,120 --> 00:06:35,529
kind of provide that object later so

00:06:34,240 --> 00:06:37,840
clients still don't have to make more

00:06:35,529 --> 00:06:40,380
than one request but there's no like

00:06:37,840 --> 00:06:41,670
tooling for us to use to put this

00:06:40,380 --> 00:06:43,440
of thing together we'd have to build it

00:06:41,670 --> 00:06:45,360
ourselves and clients are still gonna

00:06:43,440 --> 00:06:46,830
need to go through and figure out okay

00:06:45,360 --> 00:06:48,870
now that I have this profile object

00:06:46,830 --> 00:06:51,150
where am I going to put it in this tree

00:06:48,870 --> 00:06:53,850
of data so we kind of gave open this

00:06:51,150 --> 00:06:56,130
strategy we looked at JSON API as a

00:06:53,850 --> 00:06:58,230
solution nice thing about that is

00:06:56,130 --> 00:06:59,760
clients can kind of just query for

00:06:58,230 --> 00:07:01,890
exactly what they want since everything

00:06:59,760 --> 00:07:03,840
has a an endpoint that you can hit to

00:07:01,890 --> 00:07:06,930
just get the data and of course we also

00:07:03,840 --> 00:07:08,940
looked at graphical so clients wanted to

00:07:06,930 --> 00:07:11,280
just be able to define here's what I

00:07:08,940 --> 00:07:13,290
want from the backend JSON API gives

00:07:11,280 --> 00:07:16,440
them one way to do that but graph QL

00:07:13,290 --> 00:07:18,900
even more so when we were comparing the

00:07:16,440 --> 00:07:21,420
two graph QL just kind of gave us more

00:07:18,900 --> 00:07:23,400
of everything we were looking for so we

00:07:21,420 --> 00:07:25,800
could completely eliminate over fetching

00:07:23,400 --> 00:07:28,410
we could stay with just a single client

00:07:25,800 --> 00:07:30,240
request and we have a real type system

00:07:28,410 --> 00:07:32,610
so we could do all the schema validation

00:07:30,240 --> 00:07:33,990
all the kinds of great tooling that we

00:07:32,610 --> 00:07:36,540
can build around something that has that

00:07:33,990 --> 00:07:39,120
sort of structure not only that but like

00:07:36,540 --> 00:07:41,070
the clear laundry list of benefits made

00:07:39,120 --> 00:07:43,380
it easy for us to sell this to our

00:07:41,070 --> 00:07:45,540
client teams our server teams and of

00:07:43,380 --> 00:07:48,570
course management who had to give us the

00:07:45,540 --> 00:07:51,080
leeway to build this so how do we

00:07:48,570 --> 00:07:53,850
actually start on a project like this

00:07:51,080 --> 00:07:54,600
for us it was key to just sort of start

00:07:53,850 --> 00:07:57,810
off small

00:07:54,600 --> 00:07:59,880
we chose a single page in our admin

00:07:57,810 --> 00:08:02,310
interface to move over to graph QL

00:07:59,880 --> 00:08:04,650
something that users aren't going to see

00:08:02,310 --> 00:08:06,030
if it goes down or there's some problem

00:08:04,650 --> 00:08:08,190
with it we have some kind of fallback

00:08:06,030 --> 00:08:10,170
for it just get something deployed that

00:08:08,190 --> 00:08:12,870
we could get a feel for how graph QL was

00:08:10,170 --> 00:08:15,600
working in production since we had this

00:08:12,870 --> 00:08:17,100
Rails monolith the temptation was okay

00:08:15,600 --> 00:08:19,500
well we've got a bunch of Ruby engineers

00:08:17,100 --> 00:08:21,630
let's write this in Ruby but the Ruby

00:08:19,500 --> 00:08:23,190
library we found didn't really map to

00:08:21,630 --> 00:08:25,680
the way that we thought about data in

00:08:23,190 --> 00:08:27,900
that it wanted types to kind of map

00:08:25,680 --> 00:08:30,240
directly to active record models and we

00:08:27,900 --> 00:08:32,130
had a lot of logic in like service

00:08:30,240 --> 00:08:33,599
classes or in our controllers that were

00:08:32,130 --> 00:08:35,550
doing more than just here's the row in

00:08:33,599 --> 00:08:36,870
the database we also have things that

00:08:35,550 --> 00:08:39,510
aren't backed by a row in the database

00:08:36,870 --> 00:08:42,060
so it's hard to kind of build that kind

00:08:39,510 --> 00:08:43,680
of abstraction around them at the same

00:08:42,060 --> 00:08:46,110
time we're building a lot more micro

00:08:43,680 --> 00:08:48,570
services so we need some sort of

00:08:46,110 --> 00:08:50,550
coordinator that can handle the

00:08:48,570 --> 00:08:52,260
communication between the services and

00:08:50,550 --> 00:08:53,390
also between our clients and services

00:08:52,260 --> 00:08:55,490
themselves

00:08:53,390 --> 00:08:57,500
so graph QL seemed to really fit this

00:08:55,490 --> 00:08:59,930
bill well if it was a new lightweight

00:08:57,500 --> 00:09:03,890
service then it would be able to handle

00:08:59,930 --> 00:09:06,860
all these responsibilities node was what

00:09:03,890 --> 00:09:09,350
we chose because the tooling is the most

00:09:06,860 --> 00:09:11,270
mature in the graph QL space it's the

00:09:09,350 --> 00:09:14,630
quickest way to get started the

00:09:11,270 --> 00:09:16,670
event-driven execution model where some

00:09:14,630 --> 00:09:17,570
request gets fired off and we don't have

00:09:16,670 --> 00:09:19,460
to do anything about it

00:09:17,570 --> 00:09:22,010
until it comes back really works well

00:09:19,460 --> 00:09:23,870
for graph QL and if you had to pick a

00:09:22,010 --> 00:09:25,400
language that everybody in your

00:09:23,870 --> 00:09:27,620
organization is gonna be familiar with

00:09:25,400 --> 00:09:31,040
you might not find one but Java scripts

00:09:27,620 --> 00:09:32,450
going to be the closest thing so we set

00:09:31,040 --> 00:09:35,180
up this structure where our clients

00:09:32,450 --> 00:09:38,690
could start talking to graph QL continue

00:09:35,180 --> 00:09:41,360
talking to our HTTP API and sort of just

00:09:38,690 --> 00:09:43,580
go to both depending on what data they

00:09:41,360 --> 00:09:47,210
needed and we'd slowly transition things

00:09:43,580 --> 00:09:48,740
over from our REST API into graph QL and

00:09:47,210 --> 00:09:50,870
as we add more and more things to graph

00:09:48,740 --> 00:09:53,000
QL it's more and more valuable for

00:09:50,870 --> 00:09:54,980
clients to be pulling data from there so

00:09:53,000 --> 00:09:57,320
we can sort of move from 100% of data

00:09:54,980 --> 00:09:59,480
coming from the monolith to 100% of the

00:09:57,320 --> 00:10:02,000
data coming from graph QL slowly over

00:09:59,480 --> 00:10:03,320
time even if this meant what graph QL

00:10:02,000 --> 00:10:05,090
was doing is just forwarding that

00:10:03,320 --> 00:10:08,090
request on to the monolith and still

00:10:05,090 --> 00:10:09,380
pulling it from the REST API on the

00:10:08,090 --> 00:10:11,270
client side as I mentioned we've got

00:10:09,380 --> 00:10:14,360
multiple client types that we need to

00:10:11,270 --> 00:10:16,010
support but our web client was the most

00:10:14,360 --> 00:10:18,590
like well defined in terms of

00:10:16,010 --> 00:10:21,560
architecture using react in a homegrown

00:10:18,590 --> 00:10:23,330
flux architecture so we wanted to find

00:10:21,560 --> 00:10:25,670
something that would fit best in web

00:10:23,330 --> 00:10:28,280
first Apollo client was pretty new at

00:10:25,670 --> 00:10:30,700
the time relay was a more popular choice

00:10:28,280 --> 00:10:33,620
than it is today so we went with relay

00:10:30,700 --> 00:10:35,810
but it also brought along a lot of like

00:10:33,620 --> 00:10:38,150
opinions about schema design which we

00:10:35,810 --> 00:10:40,820
figured were important I guess we want

00:10:38,150 --> 00:10:42,290
to have opinions and graph QL the spec

00:10:40,820 --> 00:10:45,260
doesn't really tell you how to describe

00:10:42,290 --> 00:10:47,390
your schema or anything like that while

00:10:45,260 --> 00:10:48,830
it gave us some things it also kind of

00:10:47,390 --> 00:10:51,380
gave us a lot of baggage that we had to

00:10:48,830 --> 00:10:54,230
deal with later things like relay IDs

00:10:51,380 --> 00:10:56,270
this concept of a node interface and a

00:10:54,230 --> 00:10:58,880
viewer type these are things that we

00:10:56,270 --> 00:11:00,890
sort of debated endlessly about sort of

00:10:58,880 --> 00:11:03,320
what they mean and how we use them in

00:11:00,890 --> 00:11:05,450
our schema and in large part those

00:11:03,320 --> 00:11:06,700
discussions sort of led to well we don't

00:11:05,450 --> 00:11:09,460
need those things but we're

00:11:06,700 --> 00:11:11,710
kind of stuck with them at this point it

00:11:09,460 --> 00:11:14,020
also made like this learning curve that

00:11:11,710 --> 00:11:15,820
we already had getting up to graph QL a

00:11:14,020 --> 00:11:18,280
little bit more tough because it was

00:11:15,820 --> 00:11:19,780
hard to tell where does graph QL end and

00:11:18,280 --> 00:11:21,820
where does really begin since it's

00:11:19,780 --> 00:11:24,610
trying to like abstract all those

00:11:21,820 --> 00:11:26,740
differences away from you on our native

00:11:24,610 --> 00:11:28,630
clients we were lucky enough that Apollo

00:11:26,740 --> 00:11:30,460
client was out for iOS there was a beta

00:11:28,630 --> 00:11:32,440
version for Android this almost

00:11:30,460 --> 00:11:34,990
immediately saved us a ton of work over

00:11:32,440 --> 00:11:36,940
our HTTP stack where we were writing

00:11:34,990 --> 00:11:39,130
custom serializers for everything and

00:11:36,940 --> 00:11:43,120
now we could just do code gen and it's

00:11:39,130 --> 00:11:44,860
all there for us out of the box so once

00:11:43,120 --> 00:11:46,780
we have everything we're working with

00:11:44,860 --> 00:11:48,310
graph QL and production what's it

00:11:46,780 --> 00:11:50,680
actually like to build product in this

00:11:48,310 --> 00:11:52,060
graph QL world let's take a look at what

00:11:50,680 --> 00:11:54,640
we were doing before

00:11:52,060 --> 00:11:57,580
so traditionally our clients kind of

00:11:54,640 --> 00:11:59,260
need a full API to build against in

00:11:57,580 --> 00:12:01,810
order to make significant progress on

00:11:59,260 --> 00:12:03,790
finishing their features so this

00:12:01,810 --> 00:12:06,280
involves like this proposal of what the

00:12:03,790 --> 00:12:07,840
API is gonna look like it involves kind

00:12:06,280 --> 00:12:09,430
of sign off and deciding that that's

00:12:07,840 --> 00:12:11,950
okay that it's gonna do the right things

00:12:09,430 --> 00:12:14,500
then our server teams go and build the

00:12:11,950 --> 00:12:16,660
actual API endpoint at that point the

00:12:14,500 --> 00:12:18,100
client can build something and then when

00:12:16,660 --> 00:12:20,380
we go to integrate the two almost

00:12:18,100 --> 00:12:21,880
inevitably there's a bug that we find or

00:12:20,380 --> 00:12:23,410
an edge case we didn't think about or

00:12:21,880 --> 00:12:25,270
somebody misinterpreted the spec or

00:12:23,410 --> 00:12:28,210
something like that so we end up doing a

00:12:25,270 --> 00:12:30,640
little bit of rework in a graph QL and

00:12:28,210 --> 00:12:32,680
that agreement that we come to early on

00:12:30,640 --> 00:12:35,320
about how is this gonna work is the

00:12:32,680 --> 00:12:37,750
schema and not only is it way easier

00:12:35,320 --> 00:12:40,030
right you just open up a pull request as

00:12:37,750 --> 00:12:42,370
we've seen it immediately is kind of

00:12:40,030 --> 00:12:43,780
this unambiguous technical agreement

00:12:42,370 --> 00:12:46,240
that's actually part of the functional

00:12:43,780 --> 00:12:49,240
stack so we can't accidentally like

00:12:46,240 --> 00:12:52,210
overlook it do the wrong thing at this

00:12:49,240 --> 00:12:54,160
point we have client and server work

00:12:52,210 --> 00:12:55,180
totally decoupled because they're just

00:12:54,160 --> 00:12:57,520
they've already agreed on what the

00:12:55,180 --> 00:12:59,350
schema looks like so our server side

00:12:57,520 --> 00:13:01,120
teams can build the api's that are gonna

00:12:59,350 --> 00:13:03,310
back it our clients can build the

00:13:01,120 --> 00:13:06,100
feature and we can even provide stub

00:13:03,310 --> 00:13:08,380
data for that schema so we can actually

00:13:06,100 --> 00:13:10,630
test out the feature see is working and

00:13:08,380 --> 00:13:14,770
do some QA before the server is even

00:13:10,630 --> 00:13:17,290
ready now we found that like having

00:13:14,770 --> 00:13:19,480
clients actually define that schema has

00:13:17,290 --> 00:13:21,240
been super useful to us because they

00:13:19,480 --> 00:13:23,730
know what they need but in

00:13:21,240 --> 00:13:26,190
teams do and all the server teams need

00:13:23,730 --> 00:13:27,600
to be concerned about is just well is

00:13:26,190 --> 00:13:31,950
this something that we're gonna be able

00:13:27,600 --> 00:13:34,260
to deliver we kind of started off

00:13:31,950 --> 00:13:37,080
thinking that well like our previous

00:13:34,260 --> 00:13:39,660
api's there'd be an API team this is

00:13:37,080 --> 00:13:41,130
kind of a back-end team that manages the

00:13:39,660 --> 00:13:43,700
schema you know make sure it's

00:13:41,130 --> 00:13:46,620
performant and everything like that but

00:13:43,700 --> 00:13:48,480
sort of tying like what our data model

00:13:46,620 --> 00:13:51,930
look like to what our schema looked like

00:13:48,480 --> 00:13:54,270
was this difficult conceptual problem

00:13:51,930 --> 00:13:55,980
like how do we think about graphs and

00:13:54,270 --> 00:13:58,830
what does a data model look like as a

00:13:55,980 --> 00:14:00,180
graph but we realized that like we were

00:13:58,830 --> 00:14:02,190
kind of missing the point

00:14:00,180 --> 00:14:04,320
that one of the key advantages of graph

00:14:02,190 --> 00:14:06,270
QL is that you can have your schema for

00:14:04,320 --> 00:14:07,950
your clients you can have your services

00:14:06,270 --> 00:14:10,170
with their own api's and you have this

00:14:07,950 --> 00:14:11,820
resolver layer where everything can kind

00:14:10,170 --> 00:14:14,160
of work out and you can tie those two

00:14:11,820 --> 00:14:16,680
things together however you want so by

00:14:14,160 --> 00:14:18,240
mirroring client needs directly we give

00:14:16,680 --> 00:14:20,220
clients what they want and they're not

00:14:18,240 --> 00:14:23,280
performing all their own logic to try to

00:14:20,220 --> 00:14:26,100
turn that into something they can use so

00:14:23,280 --> 00:14:29,450
a simple example if a client is trying

00:14:26,100 --> 00:14:32,850
to do something like have a brigade user

00:14:29,450 --> 00:14:35,070
join a group on the platform because

00:14:32,850 --> 00:14:36,900
they've been invited to it or if the

00:14:35,070 --> 00:14:39,330
leader of that group is trying to add

00:14:36,900 --> 00:14:41,850
that same user we know on the backend

00:14:39,330 --> 00:14:43,860
that these are actually pretty much

00:14:41,850 --> 00:14:45,810
doing the same thing or creating like a

00:14:43,860 --> 00:14:48,710
group membership record in order to

00:14:45,810 --> 00:14:51,750
represent that but if we put different

00:14:48,710 --> 00:14:53,820
mutations in the schema they represent

00:14:51,750 --> 00:14:56,820
that then now we have the flexibility to

00:14:53,820 --> 00:14:59,400
do things that are context specific like

00:14:56,820 --> 00:15:01,230
if we're trying to have a leader add

00:14:59,400 --> 00:15:02,880
somebody to their group but they're not

00:15:01,230 --> 00:15:04,860
actually a leader we can do something

00:15:02,880 --> 00:15:06,630
different with authorization we can show

00:15:04,860 --> 00:15:07,890
them different error messages if there's

00:15:06,630 --> 00:15:09,870
anything else that we want to have

00:15:07,890 --> 00:15:11,490
behave differently between those two

00:15:09,870 --> 00:15:14,640
experiences that's mirrored in our

00:15:11,490 --> 00:15:16,590
schema and with clients working on graph

00:15:14,640 --> 00:15:18,960
QL with our server teams working on

00:15:16,590 --> 00:15:21,000
graph qo with operations working on it

00:15:18,960 --> 00:15:23,580
it's kind of this big shared asset for

00:15:21,000 --> 00:15:25,560
us so there's a lot going on within that

00:15:23,580 --> 00:15:27,090
graph QL server of course we want

00:15:25,560 --> 00:15:29,720
everything to be fast and we want it to

00:15:27,090 --> 00:15:31,740
be understandable so having some

00:15:29,720 --> 00:15:33,080
structure around this has really helped

00:15:31,740 --> 00:15:35,330
us and I'll go through that quickly

00:15:33,080 --> 00:15:37,459
so we've got the schema layer which

00:15:35,330 --> 00:15:40,010
simply says okay what do things look

00:15:37,459 --> 00:15:42,140
like what can i query for we've got our

00:15:40,010 --> 00:15:44,330
resolvers that then figure out how do i

00:15:42,140 --> 00:15:46,760
turn the fields that were requested in

00:15:44,330 --> 00:15:49,850
the schema into a request that I can

00:15:46,760 --> 00:15:52,190
make to my back-end services and then

00:15:49,850 --> 00:15:55,220
we've got our model layer and here we're

00:15:52,190 --> 00:15:57,320
kind of abstracting away the details of

00:15:55,220 --> 00:15:59,600
this particular API endpoint or this

00:15:57,320 --> 00:16:02,329
particular RPC call and just turning it

00:15:59,600 --> 00:16:05,269
all into a standard JavaScript interface

00:16:02,329 --> 00:16:06,800
that anything can call the resolver

00:16:05,269 --> 00:16:09,320
doesn't need to worry about whether it's

00:16:06,800 --> 00:16:12,490
a micro service written in Ruby or a

00:16:09,320 --> 00:16:15,680
node or Scala or anything like that

00:16:12,490 --> 00:16:17,959
backing those are our services this is

00:16:15,680 --> 00:16:20,269
kind of like the data sources that Jake

00:16:17,959 --> 00:16:21,769
was talking about where we kind of have

00:16:20,269 --> 00:16:24,200
a one-to-one mapping between that and

00:16:21,769 --> 00:16:25,910
one of our micro services sort of knows

00:16:24,200 --> 00:16:28,670
about the universe of what that service

00:16:25,910 --> 00:16:31,610
does and then the transport layer is

00:16:28,670 --> 00:16:35,000
just the actual nuts and bolts of how do

00:16:31,610 --> 00:16:36,950
we talk to those services HTTP is it

00:16:35,000 --> 00:16:39,320
thrift how do we manage those kinds of

00:16:36,950 --> 00:16:40,730
connections it doesn't know the meaning

00:16:39,320 --> 00:16:42,560
about what's going over the wire but

00:16:40,730 --> 00:16:45,440
just how do we send it how do we receive

00:16:42,560 --> 00:16:47,899
it how do we handle that data so having

00:16:45,440 --> 00:16:50,510
these sort of discrete layers makes unit

00:16:47,899 --> 00:16:52,520
testing a lot easier because they all

00:16:50,510 --> 00:16:54,020
have a defined responsibility we can

00:16:52,520 --> 00:16:56,270
mock out the things that we don't care

00:16:54,020 --> 00:16:59,089
to test and just test the things that we

00:16:56,270 --> 00:17:01,760
do we also do some sort of like more

00:16:59,089 --> 00:17:04,069
end-to-end query testing where we've

00:17:01,760 --> 00:17:07,640
built a testing framework where we can

00:17:04,069 --> 00:17:09,980
specify a schema a query some variables

00:17:07,640 --> 00:17:11,390
we want to send to it and what we expect

00:17:09,980 --> 00:17:13,280
it to look like and what we expect it to

00:17:11,390 --> 00:17:15,110
happen and by doing that we're kind of

00:17:13,280 --> 00:17:17,900
validating continuously that we haven't

00:17:15,110 --> 00:17:20,270
broken any of those things so in

00:17:17,900 --> 00:17:22,790
production what's it actually like to

00:17:20,270 --> 00:17:24,530
run this service well

00:17:22,790 --> 00:17:27,079
production is going to throw all sorts

00:17:24,530 --> 00:17:29,360
of challenges at you so it's important

00:17:27,079 --> 00:17:32,080
that when you see a symptom you can

00:17:29,360 --> 00:17:35,030
actually figure out what's going on

00:17:32,080 --> 00:17:37,460
because graph QL is kind of asynchronous

00:17:35,030 --> 00:17:39,290
by nature this can be tricky because you

00:17:37,460 --> 00:17:40,370
can't just follow a code path and see

00:17:39,290 --> 00:17:42,530
everything that's going on

00:17:40,370 --> 00:17:44,870
but the structure that it provides lends

00:17:42,530 --> 00:17:46,170
itself well to tooling that helps you

00:17:44,870 --> 00:17:48,080
sort through things

00:17:46,170 --> 00:17:50,700
so three key pieces to this puzzle

00:17:48,080 --> 00:17:52,110
metrics logs and tracing if you have all

00:17:50,700 --> 00:17:54,600
of these that can help out with your

00:17:52,110 --> 00:17:57,060
visibility a lot so we track metrics

00:17:54,600 --> 00:17:59,550
that we sent a data dog via stats tea

00:17:57,060 --> 00:18:02,910
with counters every time a field is

00:17:59,550 --> 00:18:04,560
resolved we call out to a service we

00:18:02,910 --> 00:18:07,320
access a data loader

00:18:04,560 --> 00:18:09,450
we also gauge things like how expensive

00:18:07,320 --> 00:18:11,760
do we expect this query to be via just

00:18:09,450 --> 00:18:13,470
static analysis before it gets run how

00:18:11,760 --> 00:18:15,210
long did it take for the HTTP request to

00:18:13,470 --> 00:18:17,810
finish how long did it take for the

00:18:15,210 --> 00:18:20,010
actual graph QL execution take place and

00:18:17,810 --> 00:18:22,470
then by putting all this data together

00:18:20,010 --> 00:18:24,780
we can look at things like for instance

00:18:22,470 --> 00:18:27,120
what fields in our schema are actually

00:18:24,780 --> 00:18:29,160
being used by clients what deprecated

00:18:27,120 --> 00:18:30,660
fields are being used by clients which

00:18:29,160 --> 00:18:33,000
clients are the ones that are doing that

00:18:30,660 --> 00:18:36,330
so we can identify those and resolve

00:18:33,000 --> 00:18:39,480
those issues we also log every request

00:18:36,330 --> 00:18:41,670
every error we attach tracing identifier

00:18:39,480 --> 00:18:43,770
so these logs that we can follow them

00:18:41,670 --> 00:18:46,440
through our system we make sure that all

00:18:43,770 --> 00:18:47,790
of our user data uses graph QL variables

00:18:46,440 --> 00:18:49,500
so we can tell the difference between a

00:18:47,790 --> 00:18:53,490
query and user data and make sure we're

00:18:49,500 --> 00:18:56,160
not logging that and on the errors front

00:18:53,490 --> 00:18:58,380
it's a little bit trickier graph QL

00:18:56,160 --> 00:19:00,930
because it's kind of sitting in between

00:18:58,380 --> 00:19:02,880
everything it's really a focal point for

00:19:00,930 --> 00:19:05,160
errors errors coming from upstream

00:19:02,880 --> 00:19:06,960
services air is coming from clients

00:19:05,160 --> 00:19:10,260
errors in the code that we wrote and

00:19:06,960 --> 00:19:12,900
graph QL itself and so things that are

00:19:10,260 --> 00:19:14,640
like an error of the same type can mean

00:19:12,900 --> 00:19:17,130
very different things depending on where

00:19:14,640 --> 00:19:19,200
they came from so we try to attach as

00:19:17,130 --> 00:19:21,420
much context about what's going on in

00:19:19,200 --> 00:19:24,270
the state of that execution as we can

00:19:21,420 --> 00:19:26,790
and we're using graph QL context to to

00:19:24,270 --> 00:19:29,160
kind of pass that stuff around so stuff

00:19:26,790 --> 00:19:31,440
like what client is making this call

00:19:29,160 --> 00:19:33,630
what service are we talking to what

00:19:31,440 --> 00:19:36,180
operation are we performing and then we

00:19:33,630 --> 00:19:37,740
try to make a guess as to whether that

00:19:36,180 --> 00:19:40,230
error type is something that comes from

00:19:37,740 --> 00:19:42,300
a client like the query syntax was

00:19:40,230 --> 00:19:44,340
invalid or whether it's something that

00:19:42,300 --> 00:19:47,250
came from a server like we got a 500 or

00:19:44,340 --> 00:19:49,290
we got a 400 or something like that now

00:19:47,250 --> 00:19:50,250
Apollo engine gives us a lot of this

00:19:49,290 --> 00:19:52,050
kind of stuff that I've just been

00:19:50,250 --> 00:19:54,360
talking about and I wish we had had

00:19:52,050 --> 00:19:57,240
Apollo engine a year ago it's a great

00:19:54,360 --> 00:20:00,090
place to get like high level metrics see

00:19:57,240 --> 00:20:02,159
traces of requests see where errors

00:20:00,090 --> 00:20:03,990
are trending over time we have daily

00:20:02,159 --> 00:20:06,179
reports that our on-call engineers can

00:20:03,990 --> 00:20:07,679
look at to kind of look for any latent

00:20:06,179 --> 00:20:10,710
issues that we haven't noticed yet and

00:20:07,679 --> 00:20:12,450
it's also pushing its own metrics into

00:20:10,710 --> 00:20:14,970
data dog which we can then correlate

00:20:12,450 --> 00:20:17,250
with our own stats t stuff it's also

00:20:14,970 --> 00:20:20,700
nice if we break our own instrumentation

00:20:17,250 --> 00:20:22,590
that this stuff still works one thing we

00:20:20,700 --> 00:20:24,840
look at a lot is query patterns so

00:20:22,590 --> 00:20:26,789
because graph QL is mostly just a simple

00:20:24,840 --> 00:20:29,580
Orchestrator it's not running a bunch of

00:20:26,789 --> 00:20:31,110
expensive code on its own if we have any

00:20:29,580 --> 00:20:34,320
performance or load issues they're

00:20:31,110 --> 00:20:36,000
usually because we're making a requests

00:20:34,320 --> 00:20:37,860
in an inefficient way this could be that

00:20:36,000 --> 00:20:39,480
we have a request to a service that's

00:20:37,860 --> 00:20:42,179
really slow it could be that we're

00:20:39,480 --> 00:20:44,309
making a bunch of small fast but just

00:20:42,179 --> 00:20:46,620
numerous requests in order to fetch a

00:20:44,309 --> 00:20:49,110
set of data or because the way that our

00:20:46,620 --> 00:20:51,240
request is going through is sort of

00:20:49,110 --> 00:20:53,610
misconfigured in terms of its fan-out

00:20:51,240 --> 00:20:56,130
depth and what I'm talking about there

00:20:53,610 --> 00:20:58,409
is that on the fan-out side we're kind

00:20:56,130 --> 00:20:59,880
of talking about a service moving the

00:20:58,409 --> 00:21:02,279
request to a bunch of other adjacent

00:20:59,880 --> 00:21:05,159
services and then sort of waiting for

00:21:02,279 --> 00:21:07,020
them to come back whereas the requests

00:21:05,159 --> 00:21:09,240
depth is more of we talked to service a

00:21:07,020 --> 00:21:11,370
it talks a service B that talked to

00:21:09,240 --> 00:21:14,159
service C maybe if we're really unlucky

00:21:11,370 --> 00:21:17,010
that talks to service a again and that

00:21:14,159 --> 00:21:18,510
kind of introduces some uncertainty into

00:21:17,010 --> 00:21:20,640
how long our request is going to take

00:21:18,510 --> 00:21:22,409
and also we can run into the situation

00:21:20,640 --> 00:21:24,240
where because the client is now

00:21:22,409 --> 00:21:26,159
specifying exactly what data it needs

00:21:24,240 --> 00:21:27,960
maybe we didn't need the data from

00:21:26,159 --> 00:21:29,640
service B maybe we didn't need the data

00:21:27,960 --> 00:21:30,899
from service C but service a doesn't

00:21:29,640 --> 00:21:32,610
know that and so we're performing

00:21:30,899 --> 00:21:35,820
expensive operations to figure that out

00:21:32,610 --> 00:21:38,159
so it Brigade we've kind of stuck to

00:21:35,820 --> 00:21:39,870
this design principle where we limit our

00:21:38,159 --> 00:21:41,760
depth to just one and we don't have our

00:21:39,870 --> 00:21:43,440
micro services talk to each other of

00:21:41,760 --> 00:21:46,140
course they do need to share some data

00:21:43,440 --> 00:21:48,570
but they can do that asynchronously via

00:21:46,140 --> 00:21:49,950
our cued event bus all of our

00:21:48,570 --> 00:21:52,260
synchronous communication is just

00:21:49,950 --> 00:21:54,179
orchestrated through graph QL so it

00:21:52,260 --> 00:21:56,070
fetches what's needed it doesn't fetch

00:21:54,179 --> 00:21:58,980
anything else that we don't need and we

00:21:56,070 --> 00:22:01,200
avoid recreating kind of the problem of

00:21:58,980 --> 00:22:03,840
nested objects of arbitrary depth and

00:22:01,200 --> 00:22:05,250
just have it be nested services of

00:22:03,840 --> 00:22:07,770
arbitrary depth

00:22:05,250 --> 00:22:09,299
maybe this is a bit extreme and we

00:22:07,770 --> 00:22:10,919
definitely face challenged in this

00:22:09,299 --> 00:22:12,929
approach sometimes it's tough to figure

00:22:10,919 --> 00:22:13,740
out like if service a really needs to

00:22:12,929 --> 00:22:15,720
get something from serve

00:22:13,740 --> 00:22:17,580
be how do we make that work but it has

00:22:15,720 --> 00:22:19,679
kept kind of us from having any

00:22:17,580 --> 00:22:22,800
bottlenecks in graph QL and given us

00:22:19,679 --> 00:22:24,750
predictable response times so I want

00:22:22,800 --> 00:22:27,030
quickly at how we can pull kind of our

00:22:24,750 --> 00:22:28,620
monitoring together to investigate a

00:22:27,030 --> 00:22:31,890
production issue that we might see in

00:22:28,620 --> 00:22:33,929
graphic UL so we start with an alert we

00:22:31,890 --> 00:22:37,800
try to set our alerts to kind of cover

00:22:33,929 --> 00:22:40,230
any sort of novel or unexpected behavior

00:22:37,800 --> 00:22:43,290
in our system so in this case we got an

00:22:40,230 --> 00:22:46,110
alert that graph QL is making a bunch of

00:22:43,290 --> 00:22:48,059
RPC request to one of our micro services

00:22:46,110 --> 00:22:50,640
that we'd never expect it to make that

00:22:48,059 --> 00:22:53,910
many if we look in our overall metrics

00:22:50,640 --> 00:22:55,590
we can see that the call volume has this

00:22:53,910 --> 00:22:57,990
spike eNOS that we weren't seeing before

00:22:55,590 --> 00:23:00,240
and that it is the RPC we were alerted

00:22:57,990 --> 00:23:03,179
about when we come into engine we can

00:23:00,240 --> 00:23:05,610
take the field that's resolving that RPC

00:23:03,179 --> 00:23:08,520
find out what operations are actually

00:23:05,610 --> 00:23:09,900
resolving that field and then pull out a

00:23:08,520 --> 00:23:13,110
trace from one of them

00:23:09,900 --> 00:23:15,059
grab a request identifier from it and go

00:23:13,110 --> 00:23:16,679
over to our logs where we can look at

00:23:15,059 --> 00:23:19,170
what's going on with that request and

00:23:16,679 --> 00:23:21,570
see that we're actually making 24 calls

00:23:19,170 --> 00:23:22,140
on the same RPC just to resolve that one

00:23:21,570 --> 00:23:25,730
graphical

00:23:22,140 --> 00:23:28,860
request more than we've expected or like

00:23:25,730 --> 00:23:30,780
finally having a client information and

00:23:28,860 --> 00:23:33,270
data dog lets us kind of zoom back out

00:23:30,780 --> 00:23:36,660
and see that this is being used by our

00:23:33,270 --> 00:23:38,640
newest Android and iOS versions and also

00:23:36,660 --> 00:23:42,630
it seems to map pretty nicely to when we

00:23:38,640 --> 00:23:45,540
release those to the app store so what

00:23:42,630 --> 00:23:48,570
would I like to tell 2016 Brigade about

00:23:45,540 --> 00:23:50,760
what we know now in 2018 about graph QL

00:23:48,570 --> 00:23:54,480
well I think we did the right thing by

00:23:50,760 --> 00:23:56,429
starting simple not trying to like come

00:23:54,480 --> 00:23:59,220
up with a grand solution that would

00:23:56,429 --> 00:24:01,590
solve all our problems but just start

00:23:59,220 --> 00:24:04,350
and build something small and figure out

00:24:01,590 --> 00:24:06,210
what more we needed later later we were

00:24:04,350 --> 00:24:08,880
building out a lot of schema early on

00:24:06,210 --> 00:24:10,380
sort of speculatively either because it

00:24:08,880 --> 00:24:13,290
was something that was in our REST API

00:24:10,380 --> 00:24:14,820
or even had like plans to build products

00:24:13,290 --> 00:24:16,650
that would use something like that and

00:24:14,820 --> 00:24:20,010
we ended up throwing a lot of that away

00:24:16,650 --> 00:24:22,530
it's so easy to like add things into

00:24:20,010 --> 00:24:24,330
graph QL because you just add a field

00:24:22,530 --> 00:24:26,400
and it's there and you add a resolver

00:24:24,330 --> 00:24:27,630
and it's there and there's no like

00:24:26,400 --> 00:24:29,430
versioning or other

00:24:27,630 --> 00:24:31,050
things you have to worry about so it

00:24:29,430 --> 00:24:32,850
works super well with a continuous

00:24:31,050 --> 00:24:34,920
delivery model where as soon as you need

00:24:32,850 --> 00:24:36,600
something you add it and you don't worry

00:24:34,920 --> 00:24:40,560
about sort of figuring that all out

00:24:36,600 --> 00:24:42,390
beforehand graph you all's structure you

00:24:40,560 --> 00:24:45,060
know has a lot of opinions about types

00:24:42,390 --> 00:24:46,770
and like fields versus resolvers and

00:24:45,060 --> 00:24:48,960
queries and all this thing can make

00:24:46,770 --> 00:24:50,880
automation work super well we've seen

00:24:48,960 --> 00:24:52,680
some of those tools already but it's

00:24:50,880 --> 00:24:55,350
easy to figure out if your schema is

00:24:52,680 --> 00:24:57,240
going to break we've written our own

00:24:55,350 --> 00:25:00,480
tools but I wish we had the github thing

00:24:57,240 --> 00:25:02,310
before and humans can easily describe

00:25:00,480 --> 00:25:05,400
things in the schema definition language

00:25:02,310 --> 00:25:07,680
we can pull that in we can leverage that

00:25:05,400 --> 00:25:09,720
part of graph QL and the self

00:25:07,680 --> 00:25:12,030
documentation is super awesome so like

00:25:09,720 --> 00:25:13,860
early on we even implemented a rule that

00:25:12,030 --> 00:25:16,410
every time you add a new field it has to

00:25:13,860 --> 00:25:17,850
have a description or won't pass CI so

00:25:16,410 --> 00:25:19,800
now we have this wonderfully documented

00:25:17,850 --> 00:25:21,980
schema that our clients can just look

00:25:19,800 --> 00:25:24,690
through and figure out what they need

00:25:21,980 --> 00:25:27,020
semantic scaler types so graph QL gives

00:25:24,690 --> 00:25:29,160
us like custom types that we can use and

00:25:27,020 --> 00:25:31,080
attaching things to those even if we

00:25:29,160 --> 00:25:32,970
don't expect them to look necessarily

00:25:31,080 --> 00:25:35,490
different from just like a regular

00:25:32,970 --> 00:25:38,160
string or something like that gives us

00:25:35,490 --> 00:25:38,810
other benefits like we can validate them

00:25:38,160 --> 00:25:41,520
in different ways

00:25:38,810 --> 00:25:43,890
we can even do non-functional behavior

00:25:41,520 --> 00:25:46,290
so for instance if we have a password

00:25:43,890 --> 00:25:48,240
type even though it's just a string we

00:25:46,290 --> 00:25:49,890
know that we can look for that type and

00:25:48,240 --> 00:25:53,490
handle it a little bit more sensitively

00:25:49,890 --> 00:25:55,020
than we would just any other user one of

00:25:53,490 --> 00:25:57,390
the most common reasons that we've

00:25:55,020 --> 00:26:00,360
needed to deprecated fields or remove

00:25:57,390 --> 00:26:02,790
them entirely is because we ambitiously

00:26:00,360 --> 00:26:05,040
marked them as non null but there was

00:26:02,790 --> 00:26:07,050
some like gamma ray that came down from

00:26:05,040 --> 00:26:09,360
the sky and prevented that field from

00:26:07,050 --> 00:26:10,920
being resolved and now clients can't

00:26:09,360 --> 00:26:12,600
access the a fields that they actually

00:26:10,920 --> 00:26:15,240
did need because of this field that they

00:26:12,600 --> 00:26:17,220
don't really need so like every object

00:26:15,240 --> 00:26:20,160
is probably gonna have a resolver make

00:26:17,220 --> 00:26:22,980
it null this is the graph QL default for

00:26:20,160 --> 00:26:24,630
a very good reason and more and more

00:26:22,980 --> 00:26:28,290
we're shying away from adding those

00:26:24,630 --> 00:26:31,410
kinds of fields now we don't talk to any

00:26:28,290 --> 00:26:34,500
databases directly through graph QL so

00:26:31,410 --> 00:26:36,240
this is like oh okay well we can't like

00:26:34,500 --> 00:26:38,160
write queries that have database

00:26:36,240 --> 00:26:41,010
optimizations and isn't that not so

00:26:38,160 --> 00:26:45,150
great but in fact having that makes it a

00:26:41,010 --> 00:26:47,010
lot simpler to manage we it's going to

00:26:45,150 --> 00:26:49,200
be that graph QL is kind of in the hot

00:26:47,010 --> 00:26:51,360
path of all of your clients API requests

00:26:49,200 --> 00:26:53,610
so you don't want to put anything in it

00:26:51,360 --> 00:26:55,890
that makes it slow that makes it

00:26:53,610 --> 00:26:58,380
blocking that makes it like take a lock

00:26:55,890 --> 00:27:01,320
on something so let other services do

00:26:58,380 --> 00:27:04,080
the heavy lifting if you just kind of

00:27:01,320 --> 00:27:06,450
like fire off requests get them going

00:27:04,080 --> 00:27:08,910
wait for them to come back that scales

00:27:06,450 --> 00:27:10,590
better than trying to like figure out

00:27:08,910 --> 00:27:12,150
the perfect query pattern that you're

00:27:10,590 --> 00:27:14,340
going to be sending out before you send

00:27:12,150 --> 00:27:17,520
it because your graph QL server can't be

00:27:14,340 --> 00:27:19,500
doing other things at the same time now

00:27:17,520 --> 00:27:21,360
the tendency especially for back-end

00:27:19,500 --> 00:27:23,070
teams is to try to like lock everything

00:27:21,360 --> 00:27:25,680
down right because we're we're used to

00:27:23,070 --> 00:27:27,150
this world of an API that's managed by

00:27:25,680 --> 00:27:31,140
the server the request and the response

00:27:27,150 --> 00:27:33,120
is this like defined payload and we want

00:27:31,140 --> 00:27:35,850
to optimize those queries as much as

00:27:33,120 --> 00:27:37,740
possible but there's a lot more in a

00:27:35,850 --> 00:27:38,940
graph QL world where clients are gonna

00:27:37,740 --> 00:27:39,930
make their own queries and we don't

00:27:38,940 --> 00:27:42,810
necessarily know what they're gonna look

00:27:39,930 --> 00:27:44,250
like so if you're just focusing on

00:27:42,810 --> 00:27:47,430
specific things you're kind of losing

00:27:44,250 --> 00:27:49,140
the key advantage of graph QL if you use

00:27:47,430 --> 00:27:51,630
tools and patterns that kind of make

00:27:49,140 --> 00:27:54,240
everything better together like that

00:27:51,630 --> 00:27:56,460
kind of partial query caching or using

00:27:54,240 --> 00:27:59,490
data loader which for us Maps well to

00:27:56,460 --> 00:28:02,070
how our RPC is work you can turn things

00:27:59,490 --> 00:28:03,780
like a single request or a series of

00:28:02,070 --> 00:28:05,730
single requests no matter what kind of

00:28:03,780 --> 00:28:08,450
query they're coming from into something

00:28:05,730 --> 00:28:11,700
that works a lot more performant lis and

00:28:08,450 --> 00:28:14,000
graph QL is providing client and server

00:28:11,700 --> 00:28:16,170
a place to kind of meet in the middle

00:28:14,000 --> 00:28:18,330
where hopefully they're not fighting out

00:28:16,170 --> 00:28:19,950
too much but the differences are

00:28:18,330 --> 00:28:22,290
actually going to be written in code and

00:28:19,950 --> 00:28:24,750
everybody can see them and that's a good

00:28:22,290 --> 00:28:26,610
thing so service engineers can see where

00:28:24,750 --> 00:28:28,740
clients are having a tough time fetching

00:28:26,610 --> 00:28:30,510
data client engineers can figure out

00:28:28,740 --> 00:28:32,880
like maybe where they can fetch some of

00:28:30,510 --> 00:28:34,980
that data themselves and that resolver

00:28:32,880 --> 00:28:37,260
layer serves as not just like here's

00:28:34,980 --> 00:28:39,960
visible on the page exactly what we're

00:28:37,260 --> 00:28:41,640
doing but there's no two-sided interface

00:28:39,960 --> 00:28:44,820
there that has to stay in sync all the

00:28:41,640 --> 00:28:47,040
time so we can evolve it to fix bugs to

00:28:44,820 --> 00:28:49,950
improve performance to improve logic

00:28:47,040 --> 00:28:51,810
which is a huge asset when you know you

00:28:49,950 --> 00:28:53,790
want your clients and servers to be able

00:28:51,810 --> 00:28:56,430
to talk to each other

00:28:53,790 --> 00:28:59,160
so at the end of the day we started a

00:28:56,430 --> 00:29:01,920
year ago with some mounting performance

00:28:59,160 --> 00:29:03,630
problems inconsistent response formats a

00:29:01,920 --> 00:29:05,970
lot of different API versions that we

00:29:03,630 --> 00:29:07,950
had to maintain this sort of difficult

00:29:05,970 --> 00:29:09,090
sequential development flow that was

00:29:07,950 --> 00:29:10,860
really slowing us down

00:29:09,090 --> 00:29:14,190
and we maybe didn't even realize it

00:29:10,860 --> 00:29:15,720
could be better and kind of not super

00:29:14,190 --> 00:29:18,540
clear path forward to how we're gonna

00:29:15,720 --> 00:29:21,270
solve these issues but with graph QL we

00:29:18,540 --> 00:29:23,220
can do prototyping with our schema we

00:29:21,270 --> 00:29:25,440
can use our type guarantees so clients

00:29:23,220 --> 00:29:27,150
know exactly what they're getting we can

00:29:25,440 --> 00:29:29,010
focus on building better services

00:29:27,150 --> 00:29:31,740
instead of just building better JSON

00:29:29,010 --> 00:29:34,020
payloads we can collaborate across the

00:29:31,740 --> 00:29:35,760
engineering organization on the API so

00:29:34,020 --> 00:29:38,760
that everybody has a voice and we can

00:29:35,760 --> 00:29:41,280
build better api's together and it

00:29:38,760 --> 00:29:44,010
cleanly addresses client and server

00:29:41,280 --> 00:29:46,080
needs separately in the the layered

00:29:44,010 --> 00:29:48,240
approach where we have schema that's

00:29:46,080 --> 00:29:49,920
doing what the client needs and we have

00:29:48,240 --> 00:29:51,330
our services and our transports which

00:29:49,920 --> 00:29:54,690
are handling what the the back-end

00:29:51,330 --> 00:29:56,310
services need to do it's way easier for

00:29:54,690 --> 00:30:00,060
us now to integrate new services and

00:29:56,310 --> 00:30:01,560
features and you can do it so there are

00:30:00,060 --> 00:30:03,210
some challenges along the way but if you

00:30:01,560 --> 00:30:05,760
stick to a few basic things that'll help

00:30:03,210 --> 00:30:07,620
you succeed just start off simple get

00:30:05,760 --> 00:30:09,360
something working get a feel for how it

00:30:07,620 --> 00:30:11,160
does you can always optimize later

00:30:09,360 --> 00:30:13,980
there's tons of great stuff that you can

00:30:11,160 --> 00:30:14,790
add in the graph QL ecosystem if you

00:30:13,980 --> 00:30:16,920
integrate it with your existing

00:30:14,790 --> 00:30:18,840
infrastructure then you're right off the

00:30:16,920 --> 00:30:21,000
bat gonna understand how it works not

00:30:18,840 --> 00:30:23,250
just as a toy or not just as a demo but

00:30:21,000 --> 00:30:25,980
really in production or live with your

00:30:23,250 --> 00:30:28,350
application if you embrace that graph QL

00:30:25,980 --> 00:30:30,510
workflow of doing schema first and

00:30:28,350 --> 00:30:33,270
having development follow you'll get a

00:30:30,510 --> 00:30:35,460
lot of productivity benefits and just

00:30:33,270 --> 00:30:38,070
iterate as you need like don't try to

00:30:35,460 --> 00:30:40,620
solve the world upfront when you need

00:30:38,070 --> 00:30:42,270
something implement it of course just

00:30:40,620 --> 00:30:44,670
measure everything you're doing so you

00:30:42,270 --> 00:30:46,980
know where to improve if you're using a

00:30:44,670 --> 00:30:48,510
pollo engine and you can see kind of

00:30:46,980 --> 00:30:50,460
these are our slowest things this is

00:30:48,510 --> 00:30:53,070
what we should focus on that's time much

00:30:50,460 --> 00:30:56,760
better spent than tackling theoretical

00:30:53,070 --> 00:30:58,290
problems so if you're interested in

00:30:56,760 --> 00:31:00,390
helping us solve technical problems or

00:30:58,290 --> 00:31:02,220
you know anybody who is we're interested

00:31:00,390 --> 00:31:04,110
in solving our countries civic problems

00:31:02,220 --> 00:31:05,640
so we have open positions and

00:31:04,110 --> 00:31:06,509
engineering teams feel free to reach out

00:31:05,640 --> 00:31:08,459
about those

00:31:06,509 --> 00:31:10,589
I also hope you found something useful

00:31:08,459 --> 00:31:13,259
in this that can apply to your own

00:31:10,589 --> 00:31:14,879
experience with graph QL I'll be around

00:31:13,259 --> 00:31:16,709
during the break and throughout the day

00:31:14,879 --> 00:31:18,320
so if you want to talk to me about any

00:31:16,709 --> 00:31:21,089
of this stuff I would love to chat more

00:31:18,320 --> 00:31:23,419
you can also find me on the Apollo slack

00:31:21,089 --> 00:31:25,979
or on github and I'll post these slides

00:31:23,419 --> 00:31:27,990
in the coming days if you want to review

00:31:25,979 --> 00:31:34,539
anything so thanks

00:31:27,990 --> 00:31:34,539

YouTube URL: https://www.youtube.com/watch?v=_-yt1iawGPc


