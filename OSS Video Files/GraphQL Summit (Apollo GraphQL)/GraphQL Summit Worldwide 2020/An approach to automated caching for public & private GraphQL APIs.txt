Title: An approach to automated caching for public & private GraphQL APIs
Publication date: 2020-08-05
Playlist: GraphQL Summit Worldwide 2020
Description: 
	Explore an approach to automated caching for public & private GraphQL APIs with Tanmai Gopal, CEO, co-founder at Hasura

Resources:
Learn more about Summit - https://summit.graphql.com/
Explore the GraphQL FAQs - https://www.apollographql.com/docs/resources/faq
Learn GraphQL using Apollo's Tutorials: https://odyssey.apollographql.com/
Captions: 
	00:00:00,240 --> 00:00:03,600
hi folks i'm tanmay i'm the co-founder

00:00:02,159 --> 00:00:04,799
ceo at hasura

00:00:03,600 --> 00:00:06,960
and i'm going to talk to you a little

00:00:04,799 --> 00:00:10,559
bit today about strategies to

00:00:06,960 --> 00:00:12,080
automate caching with graphql hi folks

00:00:10,559 --> 00:00:14,480
i'm going to talk about approaches to

00:00:12,080 --> 00:00:16,080
automating uh data caching with graphql

00:00:14,480 --> 00:00:18,880
i'm tanmay i'm the co-founder

00:00:16,080 --> 00:00:20,640
at hussuro hustla is a graphql engine

00:00:18,880 --> 00:00:22,160
and a lot of our learnings on caching

00:00:20,640 --> 00:00:24,880
have been based on interactions

00:00:22,160 --> 00:00:25,760
uh with asura users and at building

00:00:24,880 --> 00:00:27,599
asura

00:00:25,760 --> 00:00:29,599
hasura gives you an instant real-time

00:00:27,599 --> 00:00:31,199
graphql api on postgres and other

00:00:29,599 --> 00:00:32,800
databases are coming soon

00:00:31,199 --> 00:00:34,960
that means graphql queries mutations and

00:00:32,800 --> 00:00:36,399
subscriptions uh which are secured with

00:00:34,960 --> 00:00:37,920
authorization rules

00:00:36,399 --> 00:00:39,760
you can also bring in other services

00:00:37,920 --> 00:00:41,520
like graphqlrs services and connect them

00:00:39,760 --> 00:00:43,360
to get a unified graphql api

00:00:41,520 --> 00:00:44,879
you can run hasura as a docker container

00:00:43,360 --> 00:00:45,600
on your own infrastructure or use house

00:00:44,879 --> 00:00:48,320
or cloud

00:00:45,600 --> 00:00:49,760
um open source checked it out on uh

00:00:48,320 --> 00:00:52,640
github

00:00:49,760 --> 00:00:54,239
all right onwards to caching so query

00:00:52,640 --> 00:00:55,199
caching and data caching right so

00:00:54,239 --> 00:00:56,960
caching queries

00:00:55,199 --> 00:00:58,640
is the idea of caching the query

00:00:56,960 --> 00:00:59,920
execution plan so that whenever a new

00:00:58,640 --> 00:01:01,600
graphql query comes in

00:00:59,920 --> 00:01:02,879
you don't have to figure out what to do

00:01:01,600 --> 00:01:04,320
the server doesn't have to parse it

00:01:02,879 --> 00:01:05,920
validate it and figure out what to do

00:01:04,320 --> 00:01:07,119
every single time

00:01:05,920 --> 00:01:09,360
same query maybe with different

00:01:07,119 --> 00:01:11,280
variables comes in caching data on the

00:01:09,360 --> 00:01:13,439
other hand is that you basically want to

00:01:11,280 --> 00:01:14,880
avoid hitting the upstream data source

00:01:13,439 --> 00:01:16,479
for queries that are expensive and you

00:01:14,880 --> 00:01:19,040
want to reduce your load on

00:01:16,479 --> 00:01:19,840
the upstream uh for example database

00:01:19,040 --> 00:01:20,960
right

00:01:19,840 --> 00:01:22,880
so first i'm going to talk a little bit

00:01:20,960 --> 00:01:25,119
about query caching right so

00:01:22,880 --> 00:01:26,159
query caching is fairly straightforward

00:01:25,119 --> 00:01:29,840
or i mean

00:01:26,159 --> 00:01:31,040
um the the way you would implement it is

00:01:29,840 --> 00:01:32,640
so query caching is fairly

00:01:31,040 --> 00:01:34,320
straightforward uh what you would do is

00:01:32,640 --> 00:01:35,759
for every incoming graphical query you

00:01:34,320 --> 00:01:38,560
would normalize it you know

00:01:35,759 --> 00:01:40,320
validate it step out fragments uh do

00:01:38,560 --> 00:01:41,680
fields and stuff like that then you can

00:01:40,320 --> 00:01:44,640
hash the graphql query

00:01:41,680 --> 00:01:46,560
um and uh store the fact that this kind

00:01:44,640 --> 00:01:48,320
of normalized graphql query

00:01:46,560 --> 00:01:50,320
and the plan that is going to come the

00:01:48,320 --> 00:01:51,360
sequence of execution you can store that

00:01:50,320 --> 00:01:52,720
plan in a map

00:01:51,360 --> 00:01:54,479
uh and then every time this graphql

00:01:52,720 --> 00:01:56,640
query comes in you can

00:01:54,479 --> 00:01:58,479
fetch that from a cache fetch the plan

00:01:56,640 --> 00:01:59,680
from a cache and then run that plan

00:01:58,479 --> 00:02:00,799
right and you can use something like an

00:01:59,680 --> 00:02:03,840
lru strategy

00:02:00,799 --> 00:02:06,719
to bound the size of the cache right

00:02:03,840 --> 00:02:08,319
and and that's kind of how graphql query

00:02:06,719 --> 00:02:09,520
caching will work uh

00:02:08,319 --> 00:02:11,280
the nice thing is that if you have

00:02:09,520 --> 00:02:12,959
something like an allow list or your

00:02:11,280 --> 00:02:14,480
graphql client can support making a

00:02:12,959 --> 00:02:16,080
query using that hash directly

00:02:14,480 --> 00:02:17,599
you won't even need to send a graphql

00:02:16,080 --> 00:02:19,760
query in the first place

00:02:17,599 --> 00:02:21,520
um you can check out approaches like uh

00:02:19,760 --> 00:02:23,040
with what graphql jit and fastify

00:02:21,520 --> 00:02:25,280
graphql are doing to understand

00:02:23,040 --> 00:02:27,760
different flavors of query caching and

00:02:25,280 --> 00:02:31,120
of optimizing execution plans

00:02:27,760 --> 00:02:31,920
for executing a graphql query graphql

00:02:31,120 --> 00:02:34,319
query caching

00:02:31,920 --> 00:02:35,840
is a 10x win when you pair it with

00:02:34,319 --> 00:02:38,080
database query caching

00:02:35,840 --> 00:02:39,519
and so databases which provide a query

00:02:38,080 --> 00:02:41,920
language to query the database

00:02:39,519 --> 00:02:43,360
also offer the same idea of being able

00:02:41,920 --> 00:02:45,360
to cache a query

00:02:43,360 --> 00:02:47,120
instead of parsing and figuring out how

00:02:45,360 --> 00:02:48,720
to run and execute that query for every

00:02:47,120 --> 00:02:49,840
new query that comes in

00:02:48,720 --> 00:02:51,760
and these are often called prepared

00:02:49,840 --> 00:02:53,680
statements um so what you can do

00:02:51,760 --> 00:02:55,120
if if so so one approach that works

00:02:53,680 --> 00:02:56,560
really well here is that instead of a

00:02:55,120 --> 00:02:58,400
pure resolver approach

00:02:56,560 --> 00:02:59,840
uh that you have to graphql uh if you

00:02:58,400 --> 00:03:01,440
think about a pushdown approach where

00:02:59,840 --> 00:03:02,959
you take a part of the graphql query or

00:03:01,440 --> 00:03:03,920
maybe even the entire graphql query and

00:03:02,959 --> 00:03:07,040
you're able to con

00:03:03,920 --> 00:03:08,800
compile that into a database query what

00:03:07,040 --> 00:03:11,120
you can do is you can send the database

00:03:08,800 --> 00:03:13,360
the entire query and that way what the

00:03:11,120 --> 00:03:16,000
database can do

00:03:13,360 --> 00:03:17,360
is it can cache that query plan as well

00:03:16,000 --> 00:03:18,080
right and these are called prepared

00:03:17,360 --> 00:03:21,440
statements

00:03:18,080 --> 00:03:22,080
um the the nice thing here is that

00:03:21,440 --> 00:03:23,760
whenever

00:03:22,080 --> 00:03:25,440
this graphql query now comes in what

00:03:23,760 --> 00:03:27,120
happens is that the graphql query which

00:03:25,440 --> 00:03:29,200
has maybe query variables and session

00:03:27,120 --> 00:03:32,560
variables like you know the user id or

00:03:29,200 --> 00:03:35,680
like the cookie or the resolved cookie

00:03:32,560 --> 00:03:37,760
this information is processed by

00:03:35,680 --> 00:03:39,599
zooming the session variables and the

00:03:37,760 --> 00:03:40,879
query variables directly through

00:03:39,599 --> 00:03:42,640
to the database right because what

00:03:40,879 --> 00:03:44,640
happens is the graphql query

00:03:42,640 --> 00:03:47,040
uh is not really processed only these

00:03:44,640 --> 00:03:49,040
variables are taken uh the graphql

00:03:47,040 --> 00:03:50,480
query plan the cache the graphql query

00:03:49,040 --> 00:03:52,239
cache is looked up

00:03:50,480 --> 00:03:53,599
and then you get the sql query and in

00:03:52,239 --> 00:03:55,120
fact you don't even have the full sql

00:03:53,599 --> 00:03:57,120
query you can look up the

00:03:55,120 --> 00:03:58,560
sql query identifier if you're using a

00:03:57,120 --> 00:04:00,400
sql database

00:03:58,560 --> 00:04:02,000
and then uh you can now query that

00:04:00,400 --> 00:04:03,840
database with that query id

00:04:02,000 --> 00:04:05,599
right so in both places that is your

00:04:03,840 --> 00:04:07,519
graphql server in a database server

00:04:05,599 --> 00:04:08,720
the query is not being processed only

00:04:07,519 --> 00:04:10,799
the right variables

00:04:08,720 --> 00:04:11,840
are sent through from the client all the

00:04:10,799 --> 00:04:14,239
way to the database

00:04:11,840 --> 00:04:16,239
um the way this looks like would be you

00:04:14,239 --> 00:04:18,000
have a client the client makes a graphql

00:04:16,239 --> 00:04:19,440
request the server right so it sends a

00:04:18,000 --> 00:04:21,519
query id and variables

00:04:19,440 --> 00:04:24,160
or the query and the graphql server does

00:04:21,519 --> 00:04:25,680
a lookup which then becomes a sql query

00:04:24,160 --> 00:04:27,919
and uh variables if it's sent to

00:04:25,680 --> 00:04:28,560
postgres um and then that json can be

00:04:27,919 --> 00:04:31,680
zoomed back

00:04:28,560 --> 00:04:32,080
to the client right um if you don't need

00:04:31,680 --> 00:04:33,840
to

00:04:32,080 --> 00:04:35,759
enrich that json at the graphql server

00:04:33,840 --> 00:04:38,160
again you can actually send that json

00:04:35,759 --> 00:04:39,919
directly back from the postgres avoiding

00:04:38,160 --> 00:04:40,479
uh serialization deserialization

00:04:39,919 --> 00:04:42,240
overhead

00:04:40,479 --> 00:04:44,479
at the graphql server as well so this

00:04:42,240 --> 00:04:44,880
this often results in a phenomenal speed

00:04:44,479 --> 00:04:46,800
up

00:04:44,880 --> 00:04:48,240
uh when paired with uh you know

00:04:46,800 --> 00:04:49,440
graphical query caching plus database

00:04:48,240 --> 00:04:51,360
query caching plus

00:04:49,440 --> 00:04:52,800
uh the pushdown approach results in a

00:04:51,360 --> 00:04:55,680
pretty pretty uh

00:04:52,800 --> 00:04:57,360
pretty phenomenal speed up all right

00:04:55,680 --> 00:05:00,000
next let's talk about data caching

00:04:57,360 --> 00:05:01,600
so um with data caching the idea is to

00:05:00,000 --> 00:05:03,600
reduce your load on upstream services so

00:05:01,600 --> 00:05:05,600
if you see 10k requests from the client

00:05:03,600 --> 00:05:06,880
uh these are usually 10k requests to the

00:05:05,600 --> 00:05:08,160
database if you're fetching this data

00:05:06,880 --> 00:05:09,199
from a database but the idea is to

00:05:08,160 --> 00:05:10,400
reduce that to

00:05:09,199 --> 00:05:12,320
maybe just a thousand requests to the

00:05:10,400 --> 00:05:13,039
database right and effectively reduce

00:05:12,320 --> 00:05:14,720
your database

00:05:13,039 --> 00:05:16,800
um and this works well when you kind of

00:05:14,720 --> 00:05:18,960
identify hot queries or queries that are

00:05:16,800 --> 00:05:20,160
uh the most kind of popular and are

00:05:18,960 --> 00:05:22,160
straining the system

00:05:20,160 --> 00:05:23,680
and what you can do is cache the results

00:05:22,160 --> 00:05:24,960
instead of hitting the upstream system

00:05:23,680 --> 00:05:26,720
to compute those results

00:05:24,960 --> 00:05:28,320
the trade-off here is that you have

00:05:26,720 --> 00:05:29,120
consistency problems and you might have

00:05:28,320 --> 00:05:30,880
still results

00:05:29,120 --> 00:05:32,479
right because you're caching that data

00:05:30,880 --> 00:05:33,759
outside the database caching that

00:05:32,479 --> 00:05:34,880
outside a system that understands

00:05:33,759 --> 00:05:36,320
consistency

00:05:34,880 --> 00:05:38,160
what that means is that you are going to

00:05:36,320 --> 00:05:39,919
have for a brief period of time while

00:05:38,160 --> 00:05:41,440
the data is cached your data might be

00:05:39,919 --> 00:05:43,840
out of date

00:05:41,440 --> 00:05:45,280
data caching unsurprisingly is hard and

00:05:43,840 --> 00:05:48,080
this is hard with graphql

00:05:45,280 --> 00:05:49,840
this is hard for rest apis as well and

00:05:48,080 --> 00:05:51,120
automatically caching data that changes

00:05:49,840 --> 00:05:53,280
dynamically

00:05:51,120 --> 00:05:54,639
is painful for two reasons right the

00:05:53,280 --> 00:05:56,479
first problem that you want to solve is

00:05:54,639 --> 00:05:59,360
you need to understand what to cache

00:05:56,479 --> 00:06:00,080
right how do you cache data how do you

00:05:59,360 --> 00:06:02,720
know

00:06:00,080 --> 00:06:03,919
what data to cache this is for example

00:06:02,720 --> 00:06:05,280
you know we

00:06:03,919 --> 00:06:07,039
let's say there are two users user one

00:06:05,280 --> 00:06:08,160
user two and they both make an api call

00:06:07,039 --> 00:06:10,000
to fetch their profile

00:06:08,160 --> 00:06:11,520
now the api call might be the same if

00:06:10,000 --> 00:06:12,720
it's rest it might be slash profile if

00:06:11,520 --> 00:06:13,520
the graphql query it might be query

00:06:12,720 --> 00:06:15,360
profile

00:06:13,520 --> 00:06:16,960
but the result that is fetched is

00:06:15,360 --> 00:06:18,400
entirely different because it depends on

00:06:16,960 --> 00:06:21,039
the identity of the user

00:06:18,400 --> 00:06:21,600
so in this case this api call can't be

00:06:21,039 --> 00:06:23,520
cached

00:06:21,600 --> 00:06:25,840
because the data set that is fetched is

00:06:23,520 --> 00:06:27,600
different so knowing what to cache

00:06:25,840 --> 00:06:28,880
is hard because it depends on the

00:06:27,600 --> 00:06:30,880
identity of the user

00:06:28,880 --> 00:06:32,240
the second problem is how do you update

00:06:30,880 --> 00:06:34,160
or invalidate the cache

00:06:32,240 --> 00:06:35,600
right which is uh because it's a dynamic

00:06:34,160 --> 00:06:37,039
data how are you going to decide

00:06:35,600 --> 00:06:39,360
when you invalidate the cache and say

00:06:37,039 --> 00:06:41,600
that these results are stale let's fresh

00:06:39,360 --> 00:06:43,120
let's fetch fresh results from the

00:06:41,600 --> 00:06:45,280
upstream data source

00:06:43,120 --> 00:06:46,639
um let's take an example that we're

00:06:45,280 --> 00:06:48,000
going to use through

00:06:46,639 --> 00:06:50,400
understanding these various flavors of

00:06:48,000 --> 00:06:51,599
data caching so let's say for example we

00:06:50,400 --> 00:06:53,759
have an api called

00:06:51,599 --> 00:06:55,759
uh that fetches restaurants right so i'm

00:06:53,759 --> 00:06:56,479
i'm using a url path here called slash

00:06:55,759 --> 00:06:57,680
restaurants

00:06:56,479 --> 00:06:59,440
uh and you know that turns out to be a

00:06:57,680 --> 00:07:00,160
surprising win for rest right it's like

00:06:59,440 --> 00:07:02,000
with the rest

00:07:00,160 --> 00:07:03,680
i can compress the information i need to

00:07:02,000 --> 00:07:05,199
show on a slide with the graphql i would

00:07:03,680 --> 00:07:08,560
have had to show you the full query

00:07:05,199 --> 00:07:11,039
uh rest one graphql zero i'm joking but

00:07:08,560 --> 00:07:11,840
but if you have a restaurants api call

00:07:11,039 --> 00:07:14,000
and you're and

00:07:11,840 --> 00:07:15,360
user one is making this this this api

00:07:14,000 --> 00:07:16,080
call to fetch restaurants on a

00:07:15,360 --> 00:07:19,039
restaurant listing

00:07:16,080 --> 00:07:20,319
app and and then you might have user id2

00:07:19,039 --> 00:07:22,000
and then you might have user id3 right

00:07:20,319 --> 00:07:23,440
so they're all kind of on their apps and

00:07:22,000 --> 00:07:24,639
they're fetching this restaurant data

00:07:23,440 --> 00:07:26,639
now when you're trying to fetch this

00:07:24,639 --> 00:07:27,120
list the the code that you're executing

00:07:26,639 --> 00:07:28,880
is

00:07:27,120 --> 00:07:30,720
you first want to understand who user id

00:07:28,880 --> 00:07:32,319
is who this user is

00:07:30,720 --> 00:07:34,080
where they're based and if they're based

00:07:32,319 --> 00:07:35,840
in a particular city like san francisco

00:07:34,080 --> 00:07:36,880
you want to load the restaurant list for

00:07:35,840 --> 00:07:38,960
san francisco

00:07:36,880 --> 00:07:41,120
right and so what you're probably going

00:07:38,960 --> 00:07:42,560
to do is go to a cache and fetch that

00:07:41,120 --> 00:07:44,080
list from a cache right

00:07:42,560 --> 00:07:45,599
similarly when user id 2 comes in you

00:07:44,080 --> 00:07:47,360
realize user id 2 is in dublin

00:07:45,599 --> 00:07:49,120
and so you need to load the restaurant

00:07:47,360 --> 00:07:50,240
list from dublin and so maybe you have

00:07:49,120 --> 00:07:52,560
that entry in a cache

00:07:50,240 --> 00:07:54,080
and so you fetch that data right user

00:07:52,560 --> 00:07:55,840
id3 is in san francisco

00:07:54,080 --> 00:07:57,520
once you figure that out you can now

00:07:55,840 --> 00:07:58,080
load that from the cache right so this

00:07:57,520 --> 00:07:59,759
information

00:07:58,080 --> 00:08:01,360
even though the api call is the same

00:07:59,759 --> 00:08:02,960
because these users are different

00:08:01,360 --> 00:08:05,199
and because there's a property of this

00:08:02,960 --> 00:08:06,800
user and a property of the data

00:08:05,199 --> 00:08:08,720
you're going to use a cache in an

00:08:06,800 --> 00:08:11,039
appropriate way to fetch that data

00:08:08,720 --> 00:08:12,400
right the trick here is understanding

00:08:11,039 --> 00:08:13,759
how we're going to do this

00:08:12,400 --> 00:08:16,000
with graphql and how we're going to try

00:08:13,759 --> 00:08:17,440
to automate this so let's

00:08:16,000 --> 00:08:19,120
uh talk about the second problem which

00:08:17,440 --> 00:08:19,520
is how do we invalidate the cache the

00:08:19,120 --> 00:08:21,440
first

00:08:19,520 --> 00:08:22,800
example the first simple way of doing it

00:08:21,440 --> 00:08:24,000
is that you base it on time

00:08:22,800 --> 00:08:25,840
and you say you know what we're going to

00:08:24,000 --> 00:08:27,520
maintain this cache for 60 seconds

00:08:25,840 --> 00:08:28,000
because within 60 seconds if there's an

00:08:27,520 --> 00:08:30,160
update

00:08:28,000 --> 00:08:31,759
we don't care it's fine you can look at

00:08:30,160 --> 00:08:33,680
data that is stale by a minute

00:08:31,759 --> 00:08:35,440
and it's not going to destroy our users

00:08:33,680 --> 00:08:37,360
right and this is simple because you

00:08:35,440 --> 00:08:39,039
just have a ttl-based cache right

00:08:37,360 --> 00:08:40,800
the other is kind of a more significant

00:08:39,039 --> 00:08:42,240
problem which is that you track all of

00:08:40,800 --> 00:08:43,120
these update events that are happening

00:08:42,240 --> 00:08:44,640
to the system

00:08:43,120 --> 00:08:46,160
you say you know if there's let's say

00:08:44,640 --> 00:08:47,680
for example there's a restaurant update

00:08:46,160 --> 00:08:48,480
operation that happens on restaurant one

00:08:47,680 --> 00:08:50,880
two three

00:08:48,480 --> 00:08:51,600
um you need to figure out if it is a

00:08:50,880 --> 00:08:53,200
restaurant

00:08:51,600 --> 00:08:55,279
uh if it is an update event that is

00:08:53,200 --> 00:08:56,240
going to impact your cash so is this

00:08:55,279 --> 00:08:58,560
restaurant also

00:08:56,240 --> 00:09:00,399
sf restaurant is it going to impact this

00:08:58,560 --> 00:09:01,360
cash this cash that i was using for the

00:09:00,399 --> 00:09:03,200
restaurant query

00:09:01,360 --> 00:09:04,480
and if it is what you do is you then go

00:09:03,200 --> 00:09:06,480
and validate the cash

00:09:04,480 --> 00:09:08,160
this is an extremely hard problem in the

00:09:06,480 --> 00:09:10,000
database world this is often called the

00:09:08,160 --> 00:09:11,920
materialized view update problem

00:09:10,000 --> 00:09:14,320
right and updating a materialized view

00:09:11,920 --> 00:09:16,240
and doing this is non-trivial

00:09:14,320 --> 00:09:18,000
it's in fact so hard that people often

00:09:16,240 --> 00:09:19,360
don't do this at all and just stick to

00:09:18,000 --> 00:09:21,120
time-based caching

00:09:19,360 --> 00:09:22,959
and what they do is have maybe very

00:09:21,120 --> 00:09:24,160
specific cases where they have very

00:09:22,959 --> 00:09:26,640
specific events

00:09:24,160 --> 00:09:27,200
that can go update the cache right um

00:09:26,640 --> 00:09:29,920
but it's

00:09:27,200 --> 00:09:31,440
very hard and almost impossible to do uh

00:09:29,920 --> 00:09:33,760
uh with reasonable effort

00:09:31,440 --> 00:09:35,200
in a generic way right so those are kind

00:09:33,760 --> 00:09:37,200
of the two problems with caching

00:09:35,200 --> 00:09:39,680
right now let's talk about three ways to

00:09:37,200 --> 00:09:42,000
cache data with graphql right so

00:09:39,680 --> 00:09:43,440
the first example is or the first method

00:09:42,000 --> 00:09:45,200
is that we can say that we're going to

00:09:43,440 --> 00:09:46,160
cache data before it even hits our

00:09:45,200 --> 00:09:48,160
graphql server

00:09:46,160 --> 00:09:49,200
or before it hits the graphql query

00:09:48,160 --> 00:09:51,600
processing pipeline

00:09:49,200 --> 00:09:52,880
right and so you can cache the data here

00:09:51,600 --> 00:09:53,600
or you can cache the data inside

00:09:52,880 --> 00:09:55,839
resolvers

00:09:53,600 --> 00:09:57,279
right where those particular bits of the

00:09:55,839 --> 00:10:01,040
graphql query are being processed

00:09:57,279 --> 00:10:02,560
and third is that you can integrate

00:10:01,040 --> 00:10:04,079
or automate caching so that the caching

00:10:02,560 --> 00:10:05,600
mechanism hooks in

00:10:04,079 --> 00:10:07,519
to the model level logic which is

00:10:05,600 --> 00:10:09,360
integrated with the data fetching logic

00:10:07,519 --> 00:10:10,720
of that particular model and so we look

00:10:09,360 --> 00:10:12,399
at all of these three approaches

00:10:10,720 --> 00:10:13,839
so the first approach is we're going to

00:10:12,399 --> 00:10:14,880
cache it before it hits the graphql

00:10:13,839 --> 00:10:16,160
pipeline

00:10:14,880 --> 00:10:18,240
not necessarily before the graphql

00:10:16,160 --> 00:10:19,120
server it might be in the same technical

00:10:18,240 --> 00:10:20,880
server but

00:10:19,120 --> 00:10:22,959
what i mean here is before the graphql

00:10:20,880 --> 00:10:24,560
query is processed this is kind of very

00:10:22,959 --> 00:10:26,720
similar to caching get request for the

00:10:24,560 --> 00:10:28,560
cdn right it's like saying

00:10:26,720 --> 00:10:30,399
you have an http call it makes a get api

00:10:28,560 --> 00:10:31,839
call and then you have a cdn that can

00:10:30,399 --> 00:10:33,040
cache that for some amount of time with

00:10:31,839 --> 00:10:35,839
a cache control header

00:10:33,040 --> 00:10:36,560
or something like that right um and in

00:10:35,839 --> 00:10:38,720
this case the

00:10:36,560 --> 00:10:40,240
the the server that is doing the caching

00:10:38,720 --> 00:10:41,839
or or the bits of the server that is

00:10:40,240 --> 00:10:44,800
doing the caching does not really

00:10:41,839 --> 00:10:46,320
uh uh uh does the caching entirely

00:10:44,800 --> 00:10:48,640
automatically right it doesn't

00:10:46,320 --> 00:10:49,920
the the the api server the graphql api

00:10:48,640 --> 00:10:51,040
server doesn't really know anything

00:10:49,920 --> 00:10:53,279
about caching

00:10:51,040 --> 00:10:54,560
um so it's uh the caching happens

00:10:53,279 --> 00:10:57,600
entirely before that

00:10:54,560 --> 00:10:58,880
api logic runs right um in this case a

00:10:57,600 --> 00:11:00,160
rough algorithm just to give you a sense

00:10:58,880 --> 00:11:01,680
of what this would look like is

00:11:00,160 --> 00:11:03,200
something like saying that here there's

00:11:01,680 --> 00:11:05,120
an incoming graphql query

00:11:03,200 --> 00:11:06,560
uh you look at the queries identifier

00:11:05,120 --> 00:11:07,519
right um you see if this query is

00:11:06,560 --> 00:11:09,040
cacheable or not

00:11:07,519 --> 00:11:10,480
uh some queries are cacheable or not

00:11:09,040 --> 00:11:12,160
like for example if you know that it's a

00:11:10,480 --> 00:11:14,560
query that's fetching public data

00:11:12,160 --> 00:11:16,320
it's it's it's a graphql query that is

00:11:14,560 --> 00:11:19,040
fetching data from uh

00:11:16,320 --> 00:11:21,120
uh uh is fetching data in a way that

00:11:19,040 --> 00:11:21,600
will not depend on the user's identity

00:11:21,120 --> 00:11:22,880
right

00:11:21,600 --> 00:11:24,880
you don't have to solve the what to

00:11:22,880 --> 00:11:26,160
cache problem um and then what you do is

00:11:24,880 --> 00:11:27,440
you load that data

00:11:26,160 --> 00:11:29,360
from a cache instead of running those

00:11:27,440 --> 00:11:30,560
resolvers uh and of course if you don't

00:11:29,360 --> 00:11:32,240
have the data in the cache

00:11:30,560 --> 00:11:34,640
uh you populate the cache by running

00:11:32,240 --> 00:11:36,720
that query right the caveats here as are

00:11:34,640 --> 00:11:38,800
obvious is that this only works

00:11:36,720 --> 00:11:41,200
if the graphql query result doesn't

00:11:38,800 --> 00:11:43,839
depend on the identity of the user

00:11:41,200 --> 00:11:44,480
or an ident or a dynamic property of the

00:11:43,839 --> 00:11:46,160
request

00:11:44,480 --> 00:11:48,000
uh it only depends on that on the

00:11:46,160 --> 00:11:49,360
graphql query that is coming in

00:11:48,000 --> 00:11:51,519
and this works for example for public

00:11:49,360 --> 00:11:54,480
apis or unauthenticated apis

00:11:51,519 --> 00:11:55,519
or perhaps more accurately unauthorized

00:11:54,480 --> 00:11:58,240
apis right where

00:11:55,519 --> 00:11:59,680
apis don't have authorization so um just

00:11:58,240 --> 00:12:01,279
kind of taking a look at how this could

00:11:59,680 --> 00:12:03,680
work in our restaurant scenario

00:12:01,279 --> 00:12:05,440
and again apologies for using the rest

00:12:03,680 --> 00:12:07,279
um

00:12:05,440 --> 00:12:08,480
a way of displaying things it's it's

00:12:07,279 --> 00:12:11,360
just a little bit easier

00:12:08,480 --> 00:12:11,839
so if i have a restaurant and instead of

00:12:11,360 --> 00:12:13,920
now

00:12:11,839 --> 00:12:15,760
making that making the list of

00:12:13,920 --> 00:12:17,040
restaurants that are fetched a property

00:12:15,760 --> 00:12:18,720
of the logic

00:12:17,040 --> 00:12:20,399
what we can do is make it a property of

00:12:18,720 --> 00:12:22,160
the api call itself

00:12:20,399 --> 00:12:23,440
and now what happens is that each of

00:12:22,160 --> 00:12:25,920
these api calls

00:12:23,440 --> 00:12:27,680
are cacheable by a system that's outside

00:12:25,920 --> 00:12:29,360
our graphql server because it doesn't

00:12:27,680 --> 00:12:29,920
depend on the user identity anymore

00:12:29,360 --> 00:12:32,639
right

00:12:29,920 --> 00:12:33,360
so we can say hey this is from the sf

00:12:32,639 --> 00:12:34,560
list

00:12:33,360 --> 00:12:37,200
fetch from the cache this is from the

00:12:34,560 --> 00:12:38,639
dublin list fetch from the dublin cache

00:12:37,200 --> 00:12:40,399
this is from the sf list again fetch

00:12:38,639 --> 00:12:43,279
from the sf list right

00:12:40,399 --> 00:12:43,920
so our graphql system doesn't really

00:12:43,279 --> 00:12:46,399
have to

00:12:43,920 --> 00:12:47,600
do anything to process the graphql query

00:12:46,399 --> 00:12:48,079
we know that we can just load it from

00:12:47,600 --> 00:12:50,240
the cache

00:12:48,079 --> 00:12:51,920
right let's look at the second example

00:12:50,240 --> 00:12:52,320
which is caching at the graphql resolver

00:12:51,920 --> 00:12:54,720
level

00:12:52,320 --> 00:12:56,079
um and this is kind of more similar to

00:12:54,720 --> 00:12:57,680
if you were building your own api

00:12:56,079 --> 00:12:59,920
controllers with the rest apis

00:12:57,680 --> 00:13:00,880
uh you know how you would cache uh how

00:12:59,920 --> 00:13:02,320
you would cache them

00:13:00,880 --> 00:13:03,920
right or how you would implement caching

00:13:02,320 --> 00:13:05,120
in that scenario so here a rough

00:13:03,920 --> 00:13:08,079
algorithm would be that

00:13:05,120 --> 00:13:09,279
inside every resolver depending on the

00:13:08,079 --> 00:13:10,880
logic right depending on

00:13:09,279 --> 00:13:12,399
you know is this public data does this

00:13:10,880 --> 00:13:13,200
depend on the user does this not depend

00:13:12,399 --> 00:13:15,120
on the user

00:13:13,200 --> 00:13:16,560
uh you make that call as a developer

00:13:15,120 --> 00:13:17,839
because you have that information as a

00:13:16,560 --> 00:13:19,839
developer inside your mind

00:13:17,839 --> 00:13:20,959
and you decide whether you can create a

00:13:19,839 --> 00:13:22,720
cache key

00:13:20,959 --> 00:13:24,079
and whether you can put this in a cache

00:13:22,720 --> 00:13:25,360
or whether you just have to query the

00:13:24,079 --> 00:13:27,680
upstream database right

00:13:25,360 --> 00:13:29,120
so you can make that call as the author

00:13:27,680 --> 00:13:31,440
of that resolver

00:13:29,120 --> 00:13:32,320
and so whenever that you need to fetch

00:13:31,440 --> 00:13:34,000
that data

00:13:32,320 --> 00:13:35,760
if you know that it's cacheable you use

00:13:34,000 --> 00:13:36,480
the cache key and you load that data

00:13:35,760 --> 00:13:38,160
from a cache

00:13:36,480 --> 00:13:39,519
uh instead of loading it from the data

00:13:38,160 --> 00:13:40,480
source and of course you populate the

00:13:39,519 --> 00:13:42,160
cache if there's a miss

00:13:40,480 --> 00:13:43,360
right in this case the caveat is that

00:13:42,160 --> 00:13:44,720
you have to hit the cache for every

00:13:43,360 --> 00:13:46,240
resolver which means that you

00:13:44,720 --> 00:13:47,920
run into an n plus one kind of problem

00:13:46,240 --> 00:13:49,839
potentially again that means your

00:13:47,920 --> 00:13:52,079
caching system also needs a data loader

00:13:49,839 --> 00:13:53,440
and now you're just like ah this is this

00:13:52,079 --> 00:13:56,639
is there's a lot of work

00:13:53,440 --> 00:13:57,760
right and and especially if you realize

00:13:56,639 --> 00:14:00,160
that these resolvers

00:13:57,760 --> 00:14:01,040
are multiple resolvers are fetching data

00:14:00,160 --> 00:14:03,920
from the same

00:14:01,040 --> 00:14:05,440
model right uh you know maybe you have a

00:14:03,920 --> 00:14:06,399
for example with relay you have a top

00:14:05,440 --> 00:14:08,079
level node

00:14:06,399 --> 00:14:10,000
interface right uh and you can you can

00:14:08,079 --> 00:14:11,839
query for any node using a gyd

00:14:10,000 --> 00:14:13,760
now in this case uh so there is some

00:14:11,839 --> 00:14:15,440
logic that is fetching that data

00:14:13,760 --> 00:14:17,600
for a node but at the same time you

00:14:15,440 --> 00:14:19,199
might have a graphql query which

00:14:17,600 --> 00:14:20,639
somewhere deep inside the query

00:14:19,199 --> 00:14:23,360
is also fetching the same data from the

00:14:20,639 --> 00:14:24,800
node so the the data fetch logic for at

00:14:23,360 --> 00:14:26,480
the top level node and the data fetch

00:14:24,800 --> 00:14:27,279
logic for a resolver that is deep inside

00:14:26,480 --> 00:14:29,519
the query

00:14:27,279 --> 00:14:31,120
they are acting on the same model but

00:14:29,519 --> 00:14:32,480
they're both implementing their own data

00:14:31,120 --> 00:14:33,279
fetching logic and their own caching

00:14:32,480 --> 00:14:35,360
logic right

00:14:33,279 --> 00:14:36,399
and so that that that that code has to

00:14:35,360 --> 00:14:37,279
be duplicated enough to

00:14:36,399 --> 00:14:38,800
you have to make sure that you're

00:14:37,279 --> 00:14:40,079
keeping both of those in sync as a

00:14:38,800 --> 00:14:41,680
developer as well

00:14:40,079 --> 00:14:43,440
it's also hard to automate because this

00:14:41,680 --> 00:14:45,839
information is inside your mind

00:14:43,440 --> 00:14:47,600
right only you know what can be cached

00:14:45,839 --> 00:14:49,120
the system itself cannot kind of

00:14:47,600 --> 00:14:51,040
automatically cache it right

00:14:49,120 --> 00:14:52,639
um at least in the previous system we

00:14:51,040 --> 00:14:53,040
can identify that certain queries are

00:14:52,639 --> 00:14:55,279
just

00:14:53,040 --> 00:14:56,240
you know public apis and so we can just

00:14:55,279 --> 00:14:58,480
cache a bunch of them

00:14:56,240 --> 00:14:59,600
right but in this case all of that that

00:14:58,480 --> 00:15:02,240
burden is kind of

00:14:59,600 --> 00:15:03,519
on your shoulders as a developer let's

00:15:02,240 --> 00:15:05,440
take a look at what this looks like if

00:15:03,519 --> 00:15:07,440
you have a restaurant example right so

00:15:05,440 --> 00:15:08,800
uh in our in a restaurant example we

00:15:07,440 --> 00:15:09,920
have you know you make a query to

00:15:08,800 --> 00:15:10,639
restaurants you run the restaurant

00:15:09,920 --> 00:15:13,040
resolver

00:15:10,639 --> 00:15:13,680
the restaurant resolver knows that uh oh

00:15:13,040 --> 00:15:17,040
you know this

00:15:13,680 --> 00:15:17,680
is uh this data set is dependent only on

00:15:17,040 --> 00:15:19,600
location

00:15:17,680 --> 00:15:21,440
so it creates a cache key based on the

00:15:19,600 --> 00:15:23,519
location right which is san francisco

00:15:21,440 --> 00:15:24,880
and so it loads the san francisco list

00:15:23,519 --> 00:15:26,800
right so you have that cache key

00:15:24,880 --> 00:15:28,079
information here you use that cache key

00:15:26,800 --> 00:15:29,759
to load that from the cache

00:15:28,079 --> 00:15:31,120
similarly for dublin and similarly again

00:15:29,759 --> 00:15:31,759
for san francisco you load it from the

00:15:31,120 --> 00:15:34,000
same cache

00:15:31,759 --> 00:15:34,959
so this resolver has the information

00:15:34,000 --> 00:15:37,279
about knowing

00:15:34,959 --> 00:15:38,160
what to cache and what that cache key is

00:15:37,279 --> 00:15:41,279
so that it can load

00:15:38,160 --> 00:15:42,320
from the cache right the third example

00:15:41,279 --> 00:15:44,480
that we're going to look at

00:15:42,320 --> 00:15:45,680
is caching using mod level rules so in

00:15:44,480 --> 00:15:46,560
this case the first thing that we would

00:15:45,680 --> 00:15:48,399
do is that each

00:15:46,560 --> 00:15:50,399
model should have declarative

00:15:48,399 --> 00:15:51,199
authorization and relationship rules so

00:15:50,399 --> 00:15:53,920
what you want to do

00:15:51,199 --> 00:15:55,839
is you don't want to write the code for

00:15:53,920 --> 00:15:58,639
understanding

00:15:55,839 --> 00:16:00,240
how to fetch data for a particular user

00:15:58,639 --> 00:16:03,279
instead of you writing that code

00:16:00,240 --> 00:16:05,040
you load that from a internal kind of a

00:16:03,279 --> 00:16:06,480
configuration that you maintain right so

00:16:05,040 --> 00:16:09,199
you have maybe you have

00:16:06,480 --> 00:16:10,800
these rules as javascript objects that

00:16:09,199 --> 00:16:11,920
is json objects that you specify and

00:16:10,800 --> 00:16:13,920
attach to each

00:16:11,920 --> 00:16:15,440
model and so you know for example that

00:16:13,920 --> 00:16:17,519
when i'm fetching restaurants

00:16:15,440 --> 00:16:19,360
the rule here is to fetch the restaurant

00:16:17,519 --> 00:16:21,519
by user.location

00:16:19,360 --> 00:16:22,959
right so if you can represent that

00:16:21,519 --> 00:16:24,959
particular rule

00:16:22,959 --> 00:16:26,000
as a declarative configuration as a

00:16:24,959 --> 00:16:28,880
piece of data

00:16:26,000 --> 00:16:30,560
and not as a piece of code that becomes

00:16:28,880 --> 00:16:31,519
very useful because now you can use it

00:16:30,560 --> 00:16:33,040
to automate

00:16:31,519 --> 00:16:34,639
your caching logic so the first

00:16:33,040 --> 00:16:35,600
requirement is that your rules that

00:16:34,639 --> 00:16:37,759
determine

00:16:35,600 --> 00:16:39,680
how a particular query or how a

00:16:37,759 --> 00:16:42,240
particular data fetch

00:16:39,680 --> 00:16:43,920
depends on the user that is kind of

00:16:42,240 --> 00:16:45,519
making that query

00:16:43,920 --> 00:16:47,040
then you are able to convert that to

00:16:45,519 --> 00:16:47,600
data and now we can use that in the

00:16:47,040 --> 00:16:50,480
future

00:16:47,600 --> 00:16:52,399
for automating caching so now your

00:16:50,480 --> 00:16:53,759
resolvers that are fetching data

00:16:52,399 --> 00:16:55,199
don't actually fetch data directly from

00:16:53,759 --> 00:16:55,600
the data source they fetch data from

00:16:55,199 --> 00:16:57,839
this

00:16:55,600 --> 00:16:59,040
this kind of generic data fetching layer

00:16:57,839 --> 00:17:01,040
right

00:16:59,040 --> 00:17:02,079
and and this this this data fetching

00:17:01,040 --> 00:17:04,000
layer that you have

00:17:02,079 --> 00:17:05,919
is automatically combining those

00:17:04,000 --> 00:17:07,839
declarative rules that you have

00:17:05,919 --> 00:17:10,079
uh when it's making the query so now

00:17:07,839 --> 00:17:11,280
because you have a set of rules that are

00:17:10,079 --> 00:17:13,439
attached to the model

00:17:11,280 --> 00:17:14,319
when your data fetch code is running the

00:17:13,439 --> 00:17:16,400
code to

00:17:14,319 --> 00:17:17,600
fetch the restaurant list it's not just

00:17:16,400 --> 00:17:19,039
fetching the restaurant list it's

00:17:17,600 --> 00:17:20,959
fetching the restaurant list and

00:17:19,039 --> 00:17:22,880
applying that rule that fetch restaurant

00:17:20,959 --> 00:17:25,039
list where restaurant dot location

00:17:22,880 --> 00:17:26,400
equal to current user dot location right

00:17:25,039 --> 00:17:28,319
so you're able to

00:17:26,400 --> 00:17:30,559
the data fetching logic can add that

00:17:28,319 --> 00:17:31,280
rule from that declarative map right you

00:17:30,559 --> 00:17:33,840
can do a lookup

00:17:31,280 --> 00:17:34,480
on the authorization rule list and apply

00:17:33,840 --> 00:17:36,480
that rule

00:17:34,480 --> 00:17:38,080
the nice thing now here is that this

00:17:36,480 --> 00:17:40,160
knowing this information of what to

00:17:38,080 --> 00:17:42,000
cache and whether the data set

00:17:40,160 --> 00:17:43,919
depends and whether the data fetch

00:17:42,000 --> 00:17:46,320
depends on the user identity or not

00:17:43,919 --> 00:17:47,360
is not at the resolver level but it is

00:17:46,320 --> 00:17:49,200
in fact there in

00:17:47,360 --> 00:17:51,440
a piece of data right so before you run

00:17:49,200 --> 00:17:52,000
the resolver you can you automatically

00:17:51,440 --> 00:17:53,760
know

00:17:52,000 --> 00:17:55,600
that this particular data fetch is not

00:17:53,760 --> 00:17:56,000
going to depend on the user identity at

00:17:55,600 --> 00:17:57,919
all

00:17:56,000 --> 00:17:59,520
or if it depends on the user identity

00:17:57,919 --> 00:18:00,240
you know how it depends on the user

00:17:59,520 --> 00:18:03,360
identity

00:18:00,240 --> 00:18:04,799
right um and and so now if you want to

00:18:03,360 --> 00:18:05,200
think about how to cache it what you can

00:18:04,799 --> 00:18:08,080
do is

00:18:05,200 --> 00:18:08,559
when the graphql query comes in you uh

00:18:08,080 --> 00:18:10,559
you

00:18:08,559 --> 00:18:11,919
you already know what the the various

00:18:10,559 --> 00:18:13,919
models that are going to be hit

00:18:11,919 --> 00:18:15,440
are right once you know all of the

00:18:13,919 --> 00:18:17,200
models that you can hit and this is

00:18:15,440 --> 00:18:18,640
because you have the query cache right

00:18:17,200 --> 00:18:20,240
which you have the execution plan

00:18:18,640 --> 00:18:21,200
the execution plan can tell you what are

00:18:20,240 --> 00:18:22,000
the different models that you're going

00:18:21,200 --> 00:18:23,039
to fetch from

00:18:22,000 --> 00:18:24,480
now that you know what the different

00:18:23,039 --> 00:18:26,080
models that you're going to fetch from

00:18:24,480 --> 00:18:29,200
you know whether this

00:18:26,080 --> 00:18:31,039
this entire fetch will require

00:18:29,200 --> 00:18:32,640
the user identity or will not require

00:18:31,039 --> 00:18:34,480
the user identity if it doesn't require

00:18:32,640 --> 00:18:35,679
the user identity it's like public data

00:18:34,480 --> 00:18:36,720
you can load it from the cache without

00:18:35,679 --> 00:18:38,960
even thinking about it

00:18:36,720 --> 00:18:39,760
if it does require user identity you can

00:18:38,960 --> 00:18:42,160
determine

00:18:39,760 --> 00:18:43,280
if there is a key that can be extracted

00:18:42,160 --> 00:18:45,360
for example is it

00:18:43,280 --> 00:18:47,120
location is it a group right is it an

00:18:45,360 --> 00:18:47,679
organization is there a property of this

00:18:47,120 --> 00:18:49,600
user

00:18:47,679 --> 00:18:50,880
that you can use as a cache key because

00:18:49,600 --> 00:18:53,200
you will notice that that

00:18:50,880 --> 00:18:55,039
that that property is going to be in

00:18:53,200 --> 00:18:57,840
your declarative authorization rules

00:18:55,039 --> 00:18:59,520
right and so if the same query comes in

00:18:57,840 --> 00:19:01,520
for multiple user identities

00:18:59,520 --> 00:19:02,960
you can see that those multiple user

00:19:01,520 --> 00:19:03,679
identities in fact have the same

00:19:02,960 --> 00:19:05,600
property

00:19:03,679 --> 00:19:07,520
which will result in fetching the same

00:19:05,600 --> 00:19:09,039
data right so if you know that multiple

00:19:07,520 --> 00:19:10,559
users are coming in and it all depends

00:19:09,039 --> 00:19:12,880
on the user.location

00:19:10,559 --> 00:19:14,240
then what you can say is that well i can

00:19:12,880 --> 00:19:15,679
use uh

00:19:14,240 --> 00:19:17,440
i can i can now in fact instead of

00:19:15,679 --> 00:19:19,440
making a 10 000 request these might just

00:19:17,440 --> 00:19:22,240
be 500 requests to the database

00:19:19,440 --> 00:19:24,880
or 500 unique fetches because i know

00:19:22,240 --> 00:19:27,919
that it's only 500 unique locations

00:19:24,880 --> 00:19:29,600
across these 10 000 users right so let's

00:19:27,919 --> 00:19:30,559
take a look at our restaurants example

00:19:29,600 --> 00:19:33,520
in this case

00:19:30,559 --> 00:19:34,960
uh what we're going to do is uh when

00:19:33,520 --> 00:19:36,960
when this query comes in

00:19:34,960 --> 00:19:38,400
uh we're going to before we run this

00:19:36,960 --> 00:19:40,000
query before we start kind of making

00:19:38,400 --> 00:19:40,559
those data fetches what we can do is we

00:19:40,000 --> 00:19:42,400
know

00:19:40,559 --> 00:19:43,840
what property these data fetches are

00:19:42,400 --> 00:19:44,960
going to depend on right and we know

00:19:43,840 --> 00:19:45,600
that this property is going to be

00:19:44,960 --> 00:19:47,760
location

00:19:45,600 --> 00:19:49,280
because we can process the authorization

00:19:47,760 --> 00:19:50,799
rules that we have which are just

00:19:49,280 --> 00:19:52,559
data we can go through those

00:19:50,799 --> 00:19:54,080
authorization rules we know that

00:19:52,559 --> 00:19:55,840
this entire data fetch is going to

00:19:54,080 --> 00:19:57,840
depend only on location

00:19:55,840 --> 00:19:59,679
so now you can take that location and

00:19:57,840 --> 00:20:01,280
make it a cache key so that location and

00:19:59,679 --> 00:20:02,640
the query location comma query

00:20:01,280 --> 00:20:04,159
uh becomes our location comma

00:20:02,640 --> 00:20:04,559
restaurants query that becomes the cache

00:20:04,159 --> 00:20:06,080
key

00:20:04,559 --> 00:20:07,520
and now you load it from the cache right

00:20:06,080 --> 00:20:08,480
or you populate the cache and then you

00:20:07,520 --> 00:20:10,240
load it from the cache

00:20:08,480 --> 00:20:11,520
um and similarly when the query comes in

00:20:10,240 --> 00:20:13,200
and the same query comes in

00:20:11,520 --> 00:20:14,960
for a user that's now in dublin you

00:20:13,200 --> 00:20:17,280
create a new cache key that is

00:20:14,960 --> 00:20:18,000
the new location which is dublin and

00:20:17,280 --> 00:20:19,440
then load it

00:20:18,000 --> 00:20:20,880
uh populate the doubling cache and load

00:20:19,440 --> 00:20:22,159
from the dublin cache and now when a

00:20:20,880 --> 00:20:24,000
repeated query comes in

00:20:22,159 --> 00:20:25,520
from a completely different user that

00:20:24,000 --> 00:20:27,520
happens to be in the same location

00:20:25,520 --> 00:20:29,120
because you're going to use the same uh

00:20:27,520 --> 00:20:31,679
sf comma query or location

00:20:29,120 --> 00:20:32,799
comma query as as the cache key when you

00:20:31,679 --> 00:20:33,520
hit the cache you're going to get a

00:20:32,799 --> 00:20:34,960
cache hit

00:20:33,520 --> 00:20:36,720
and you're going to be able to load it

00:20:34,960 --> 00:20:37,840
from this previously populated cache

00:20:36,720 --> 00:20:40,880
that you already had

00:20:37,840 --> 00:20:43,039
right um so the cache key is kind of

00:20:40,880 --> 00:20:43,679
automatically able to include the user's

00:20:43,039 --> 00:20:45,919
group

00:20:43,679 --> 00:20:48,000
and we got this ability right we could

00:20:45,919 --> 00:20:50,640
we got this ability to automate

00:20:48,000 --> 00:20:51,840
things because we made the rules of how

00:20:50,640 --> 00:20:54,000
that data fetch happen

00:20:51,840 --> 00:20:55,360
declarative and that allows us to we can

00:20:54,000 --> 00:20:57,520
cache the entire query

00:20:55,360 --> 00:20:59,120
right so this is in fact the approach

00:20:57,520 --> 00:21:02,640
that we use on our cloud

00:20:59,120 --> 00:21:04,159
um and we have an lru cache that

00:21:02,640 --> 00:21:06,240
caches the most popular queries and

00:21:04,159 --> 00:21:08,400
evicts older queries

00:21:06,240 --> 00:21:09,360
we use a cache directive and so that

00:21:08,400 --> 00:21:11,200
means that the

00:21:09,360 --> 00:21:12,960
client can control the tolerance for the

00:21:11,200 --> 00:21:14,880
stale data and of course you can use an

00:21:12,960 --> 00:21:16,080
allow list as well to make sure

00:21:14,880 --> 00:21:17,520
that clients just don't decide to

00:21:16,080 --> 00:21:18,240
arbitrarily cache all the data that they

00:21:17,520 --> 00:21:20,159
receive

00:21:18,240 --> 00:21:21,919
um and and historical cloud then uses a

00:21:20,159 --> 00:21:22,720
combination of that first strategy of

00:21:21,919 --> 00:21:24,000
knowing that

00:21:22,720 --> 00:21:26,159
you know if the query is independent of

00:21:24,000 --> 00:21:27,760
the user identity uh that

00:21:26,159 --> 00:21:29,120
that it can just load that from a cache

00:21:27,760 --> 00:21:30,080
and if it is dependent on the user

00:21:29,120 --> 00:21:31,039
identity

00:21:30,080 --> 00:21:33,120
and the data is coming in from a

00:21:31,039 --> 00:21:33,760
database uh cloud can determine what

00:21:33,120 --> 00:21:35,520
that unique

00:21:33,760 --> 00:21:37,039
group is and whether there is a unique

00:21:35,520 --> 00:21:39,840
group across these queries

00:21:37,039 --> 00:21:40,559
and then use that group as a cache key

00:21:39,840 --> 00:21:41,840
right

00:21:40,559 --> 00:21:43,919
and all of this obviously happens

00:21:41,840 --> 00:21:44,799
because uh while you're using hustler

00:21:43,919 --> 00:21:46,720
you're able to

00:21:44,799 --> 00:21:48,080
represent all of these data fetching

00:21:46,720 --> 00:21:50,799
authorization rules

00:21:48,080 --> 00:21:51,760
right uh declaratively and that is the

00:21:50,799 --> 00:21:54,240
reason why this

00:21:51,760 --> 00:21:55,039
this uh automation can be unlocked all

00:21:54,240 --> 00:21:57,760
right so do

00:21:55,039 --> 00:21:58,960
uh do check it out on australia cloud

00:21:57,760 --> 00:22:01,440
let me know what you think

00:21:58,960 --> 00:22:03,520
uh and uh happy to discuss caching

00:22:01,440 --> 00:22:05,120
please feel free to hit me up on twitter

00:22:03,520 --> 00:22:06,640
uh or reach to me on linkedin or twitter

00:22:05,120 --> 00:22:08,559
and we can talk about all things caching

00:22:06,640 --> 00:22:11,039
graphql and

00:22:08,559 --> 00:22:12,400
have a fun graphql summit conference see

00:22:11,039 --> 00:22:15,440
you in the conference and see you

00:22:12,400 --> 00:22:18,000
in discord hey folks uh

00:22:15,440 --> 00:22:19,280
hope you enjoyed the talk i'm going to

00:22:18,000 --> 00:22:22,720
be taking some questions now

00:22:19,280 --> 00:22:25,039
uh feel free to pop in on the discord

00:22:22,720 --> 00:22:26,960
channel that says questions for uh

00:22:25,039 --> 00:22:28,080
speaker and feel free to post your

00:22:26,960 --> 00:22:31,360
questions there

00:22:28,080 --> 00:22:31,840
and we can talk about them um i think

00:22:31,360 --> 00:22:34,480
i'll

00:22:31,840 --> 00:22:35,200
i'll take the first question um which

00:22:34,480 --> 00:22:37,280
was

00:22:35,200 --> 00:22:39,120
uh what are the biggest uh what are the

00:22:37,280 --> 00:22:40,000
biggest differences between caching

00:22:39,120 --> 00:22:43,280
public and

00:22:40,000 --> 00:22:44,480
private apis um no it's it's part of

00:22:43,280 --> 00:22:46,480
kind of you know what i talked about

00:22:44,480 --> 00:22:50,880
which is i think the idea of

00:22:46,480 --> 00:22:52,080
um whether you can share data or not

00:22:50,880 --> 00:22:54,000
right that's kind of really where

00:22:52,080 --> 00:22:56,640
caching becomes effective across

00:22:54,000 --> 00:22:58,240
requests right is can can for this for

00:22:56,640 --> 00:22:58,960
the same request can i serve the same

00:22:58,240 --> 00:23:01,600
page

00:22:58,960 --> 00:23:02,960
um or serve the same data right if you

00:23:01,600 --> 00:23:03,679
think about a static website it's like

00:23:02,960 --> 00:23:04,720
the same

00:23:03,679 --> 00:23:06,880
web page that you're serving for

00:23:04,720 --> 00:23:08,720
multiple people if it's an api call

00:23:06,880 --> 00:23:09,919
you're serving the same data for many

00:23:08,720 --> 00:23:11,679
people right so especially if it's like

00:23:09,919 --> 00:23:13,039
a public data set kind of an app like

00:23:11,679 --> 00:23:15,840
you have public data that you're

00:23:13,039 --> 00:23:17,679
giving to people uh then then that is

00:23:15,840 --> 00:23:19,120
what i would call kind of a public api

00:23:17,679 --> 00:23:21,840
and a private api is something that

00:23:19,120 --> 00:23:23,679
depends uniquely on the property of it

00:23:21,840 --> 00:23:26,480
depends on some property of the user

00:23:23,679 --> 00:23:28,320
right um and and and then private apis

00:23:26,480 --> 00:23:29,600
can also kind of deal with shared data

00:23:28,320 --> 00:23:31,200
and so this is when you have a user

00:23:29,600 --> 00:23:32,640
group and a group of users share the

00:23:31,200 --> 00:23:34,080
same data in the example i was talking

00:23:32,640 --> 00:23:35,600
about like with restaurants or

00:23:34,080 --> 00:23:37,360
you know location is kind of their

00:23:35,600 --> 00:23:39,600
shared group um if you like

00:23:37,360 --> 00:23:40,960
maybe it's the google doc it's like your

00:23:39,600 --> 00:23:43,600
organization or your

00:23:40,960 --> 00:23:44,799
uh the document editor group is the

00:23:43,600 --> 00:23:47,279
shared group right

00:23:44,799 --> 00:23:48,960
um and so um so that's kind of what

00:23:47,279 --> 00:23:51,600
private apis but private apis can also

00:23:48,960 --> 00:23:53,360
kind of be sometimes transactional apis

00:23:51,600 --> 00:23:55,120
and transactional apis for example can't

00:23:53,360 --> 00:23:58,240
be cash because it's it depends

00:23:55,120 --> 00:23:59,919
on uh it it depends uh the

00:23:58,240 --> 00:24:01,600
it depends not only on the property of

00:23:59,919 --> 00:24:03,600
the user but it depends on a property of

00:24:01,600 --> 00:24:05,840
the variable that will never be the same

00:24:03,600 --> 00:24:07,440
for anybody else right so it's like i'm

00:24:05,840 --> 00:24:08,640
making a payment transaction but that

00:24:07,440 --> 00:24:09,600
transaction id is different for

00:24:08,640 --> 00:24:11,120
everybody

00:24:09,600 --> 00:24:13,919
and so we can even though it's a private

00:24:11,120 --> 00:24:16,400
api we can we can never cache this data

00:24:13,919 --> 00:24:17,440
this point is caching this data um so

00:24:16,400 --> 00:24:19,200
that's kind of the

00:24:17,440 --> 00:24:20,640
main main difference between our public

00:24:19,200 --> 00:24:21,120
and private apis and i was talking about

00:24:20,640 --> 00:24:24,799
that

00:24:21,120 --> 00:24:27,919
um are there ways to define time frames

00:24:24,799 --> 00:24:28,240
for um automating caching uh example you

00:24:27,919 --> 00:24:30,080
have

00:24:28,240 --> 00:24:31,600
of this question from kurt uh you know

00:24:30,080 --> 00:24:33,120
other time frames to define

00:24:31,600 --> 00:24:34,400
automated caching for example i have

00:24:33,120 --> 00:24:35,120
some things that you need to update

00:24:34,400 --> 00:24:37,200
quickly

00:24:35,120 --> 00:24:39,279
and other data points that won't change

00:24:37,200 --> 00:24:40,880
much um so that's a good question it

00:24:39,279 --> 00:24:42,159
depends on your caching implementation

00:24:40,880 --> 00:24:43,520
right so for example

00:24:42,159 --> 00:24:45,440
for each kind of query that you're

00:24:43,520 --> 00:24:47,279
caching you can define uh

00:24:45,440 --> 00:24:48,480
you can define your ttl right and again

00:24:47,279 --> 00:24:49,279
it depends on what kind of caching

00:24:48,480 --> 00:24:52,799
you're doing

00:24:49,279 --> 00:24:55,039
uh so for example uh so for example

00:24:52,799 --> 00:24:56,320
uh you know if you're if if you're

00:24:55,039 --> 00:24:57,120
caching if you're building your own

00:24:56,320 --> 00:24:58,559
cache layer

00:24:57,120 --> 00:25:02,159
and you're going to be able you're going

00:24:58,559 --> 00:25:05,679
to cache certain queries or resolvers or

00:25:02,159 --> 00:25:07,840
or or entire data fetches in a cache

00:25:05,679 --> 00:25:09,760
then what you want to do is uh you know

00:25:07,840 --> 00:25:12,320
you you want to define

00:25:09,760 --> 00:25:13,760
a ttl there right for that and that kind

00:25:12,320 --> 00:25:15,120
of depends on

00:25:13,760 --> 00:25:17,039
that kind of depends on you right you

00:25:15,120 --> 00:25:18,960
can decide to you can decide to make

00:25:17,039 --> 00:25:20,559
that call yourself as the person that's

00:25:18,960 --> 00:25:22,159
implementing the graphql api

00:25:20,559 --> 00:25:23,600
or you can also decide to give that

00:25:22,159 --> 00:25:25,440
control to the client

00:25:23,600 --> 00:25:26,799
uh and let them deal with the fact that

00:25:25,440 --> 00:25:28,080
you know they can decide whether this

00:25:26,799 --> 00:25:30,400
data is fast changing

00:25:28,080 --> 00:25:31,919
or this or the data or the user end user

00:25:30,400 --> 00:25:33,039
can tolerate uh

00:25:31,919 --> 00:25:35,600
the amount of stateless that they can

00:25:33,039 --> 00:25:36,720
tolerate um and i'm going to answer

00:25:35,600 --> 00:25:38,880
another question from kurt that came in

00:25:36,720 --> 00:25:41,120
a little bit later

00:25:38,880 --> 00:25:42,000
how should i configure relationships and

00:25:41,120 --> 00:25:43,200
off on models

00:25:42,000 --> 00:25:45,600
is this something i do with detectives

00:25:43,200 --> 00:25:48,400
or in a ui so uh actually

00:25:45,600 --> 00:25:49,440
i think i think this question might have

00:25:48,400 --> 00:25:50,799
i think there are two elements to this

00:25:49,440 --> 00:25:52,320
question right it depends on like what

00:25:50,799 --> 00:25:54,320
you do with hasura versus

00:25:52,320 --> 00:25:55,760
what you would do yourself so so if

00:25:54,320 --> 00:25:58,320
you're doing if you're building this

00:25:55,760 --> 00:25:59,440
yourself and and my kind of intention

00:25:58,320 --> 00:26:00,400
behind this talk was to share kind of

00:25:59,440 --> 00:26:01,520
some of the strategies that we've been

00:26:00,400 --> 00:26:03,679
using at huro

00:26:01,520 --> 00:26:05,679
that you can also build yourself up you

00:26:03,679 --> 00:26:07,120
would have to set up your own system

00:26:05,679 --> 00:26:08,799
like you would have to set up your own

00:26:07,120 --> 00:26:10,400
way of when the way that you're building

00:26:08,799 --> 00:26:11,679
your graphql server itself the way

00:26:10,400 --> 00:26:13,120
you're setting up your

00:26:11,679 --> 00:26:15,039
models and the data fetching of the

00:26:13,120 --> 00:26:17,840
models and stuff like that if you are

00:26:15,039 --> 00:26:19,360
able to do that in a way that is as

00:26:17,840 --> 00:26:21,360
declarative as possible

00:26:19,360 --> 00:26:22,400
right the models that you are defining

00:26:21,360 --> 00:26:23,520
and the relationships that you're

00:26:22,400 --> 00:26:25,520
defining

00:26:23,520 --> 00:26:26,640
and and it's basically code for you

00:26:25,520 --> 00:26:27,919
right like imagine that you're able to

00:26:26,640 --> 00:26:29,840
define it in json

00:26:27,919 --> 00:26:31,120
uh if you're able to define that in json

00:26:29,840 --> 00:26:33,120
and then use that

00:26:31,120 --> 00:26:34,480
to build the graphql server then what

00:26:33,120 --> 00:26:35,279
you can do is you can introspect that

00:26:34,480 --> 00:26:36,880
json

00:26:35,279 --> 00:26:38,320
right you can query that json to get

00:26:36,880 --> 00:26:39,440
information out of the json then and

00:26:38,320 --> 00:26:40,720
then use that for

00:26:39,440 --> 00:26:42,480
whatever you want to use it for whether

00:26:40,720 --> 00:26:43,840
it's a uh whether it's coming up with a

00:26:42,480 --> 00:26:45,120
cache plan or whether it's deciding what

00:26:43,840 --> 00:26:47,120
to cache and stuff like that

00:26:45,120 --> 00:26:48,720
on hasura this is what we do internally

00:26:47,120 --> 00:26:50,080
and so on hustler you see that

00:26:48,720 --> 00:26:51,679
everything is declarative

00:26:50,080 --> 00:26:54,159
you use a ui for doing it you can write

00:26:51,679 --> 00:26:57,440
a json configuration for doing it

00:26:54,159 --> 00:26:59,120
but but but but that that information

00:26:57,440 --> 00:26:59,840
being introspectible that information

00:26:59,120 --> 00:27:02,480
about

00:26:59,840 --> 00:27:03,840
authorization and relationships being

00:27:02,480 --> 00:27:04,320
something that you can analyze is very

00:27:03,840 --> 00:27:05,840
important

00:27:04,320 --> 00:27:07,520
because because then you can start

00:27:05,840 --> 00:27:08,480
thinking about automating it or creating

00:27:07,520 --> 00:27:11,279
a framework

00:27:08,480 --> 00:27:12,400
of automation for the developers right

00:27:11,279 --> 00:27:14,159
um

00:27:12,400 --> 00:27:16,400
i'll move to the next question which is

00:27:14,159 --> 00:27:16,400
should

00:27:17,360 --> 00:27:20,640
is it possible to build purely

00:27:18,720 --> 00:27:23,919
declarative caching rules uh

00:27:20,640 --> 00:27:24,799
even for uh cyclical data sources do we

00:27:23,919 --> 00:27:27,440
almost end up

00:27:24,799 --> 00:27:29,440
needing some non-declarative escape

00:27:27,440 --> 00:27:33,600
hacks is a question from sean

00:27:29,440 --> 00:27:34,000
um i think i think it's a i think it's a

00:27:33,600 --> 00:27:36,799
good

00:27:34,000 --> 00:27:38,159
question uh i'm i'm not sure it's a very

00:27:36,799 --> 00:27:39,919
good question i'm not sure how to answer

00:27:38,159 --> 00:27:42,320
it i think

00:27:39,919 --> 00:27:44,720
i i'm not i'm not sure i understand why

00:27:42,320 --> 00:27:47,440
even if you have a cyclical data source

00:27:44,720 --> 00:27:49,039
uh a declarative um a declarative

00:27:47,440 --> 00:27:50,960
caching rule wouldn't suffice

00:27:49,039 --> 00:27:52,240
but i have to think about that i think

00:27:50,960 --> 00:27:54,559
uh yeah i i think

00:27:52,240 --> 00:27:55,760
i think for uh i think if you need i

00:27:54,559 --> 00:27:56,320
think if you're looking at automating

00:27:55,760 --> 00:27:58,640
things or

00:27:56,320 --> 00:28:00,399
providing some kind of automation uh to

00:27:58,640 --> 00:28:01,600
developers or building their server or

00:28:00,399 --> 00:28:03,360
using the services

00:28:01,600 --> 00:28:04,880
it has to be some element of of being

00:28:03,360 --> 00:28:06,960
declarative because

00:28:04,880 --> 00:28:08,080
um only then is it easy for for

00:28:06,960 --> 00:28:10,159
automation to kick in but

00:28:08,080 --> 00:28:11,440
you know that's a good uh it's a it's a

00:28:10,159 --> 00:28:13,520
good question um

00:28:11,440 --> 00:28:13,520
i

00:28:15,279 --> 00:28:18,640
i apologize um some two other quick

00:28:17,840 --> 00:28:20,320
questions

00:28:18,640 --> 00:28:21,679
if uh most of your data is depend on the

00:28:20,320 --> 00:28:22,960
user identity what's a good place to

00:28:21,679 --> 00:28:24,000
start with server side caching in

00:28:22,960 --> 00:28:25,600
graphql

00:28:24,000 --> 00:28:26,799
very good question basically you have to

00:28:25,600 --> 00:28:27,679
kind of set up this declarative

00:28:26,799 --> 00:28:30,240
framework

00:28:27,679 --> 00:28:31,840
uh uh yourself uh of course if you're

00:28:30,240 --> 00:28:32,880
using something like postgres or a

00:28:31,840 --> 00:28:35,039
database and you have a

00:28:32,880 --> 00:28:36,240
existing data source then uh you should

00:28:35,039 --> 00:28:38,240
check customer out and see

00:28:36,240 --> 00:28:39,360
uh what that experience feels like and

00:28:38,240 --> 00:28:40,720
see if that's something that you can

00:28:39,360 --> 00:28:42,720
take some ideas from there

00:28:40,720 --> 00:28:44,000
uh and and and bring that to your

00:28:42,720 --> 00:28:45,520
graphql servers the last

00:28:44,000 --> 00:28:47,360
quick question i will answer is how does

00:28:45,520 --> 00:28:48,559
cqrs help simplify caching with graphql

00:28:47,360 --> 00:28:49,760
that's a question from khalid that's a

00:28:48,559 --> 00:28:52,080
really good question

00:28:49,760 --> 00:28:54,480
i think cqrs drastically helps us

00:28:52,080 --> 00:28:55,919
simplify caching with graphql because it

00:28:54,480 --> 00:28:57,440
because it's a mental model that forces

00:28:55,919 --> 00:28:58,159
you to separate your rights from your

00:28:57,440 --> 00:29:00,240
reads

00:28:58,159 --> 00:29:01,200
right and so in in a cqrs style you're

00:29:00,240 --> 00:29:04,240
thinking of like

00:29:01,200 --> 00:29:05,360
commands or events or mutations or query

00:29:04,240 --> 00:29:07,760
commands that are

00:29:05,360 --> 00:29:08,720
operating on data that go and update

00:29:07,760 --> 00:29:10,320
read models

00:29:08,720 --> 00:29:12,000
and read models are things that you're

00:29:10,320 --> 00:29:13,600
reading from now when you start

00:29:12,000 --> 00:29:15,279
thinking of your world as read models or

00:29:13,600 --> 00:29:17,520
as projected models right

00:29:15,279 --> 00:29:19,120
what you start doing is you you stop you

00:29:17,520 --> 00:29:21,600
you try to reduce the amount of

00:29:19,120 --> 00:29:25,360
transformation that you do while reading

00:29:21,600 --> 00:29:26,720
you you try to increase so you try

00:29:25,360 --> 00:29:29,120
the amount of code that you have that's

00:29:26,720 --> 00:29:30,960
transforming data after it is being read

00:29:29,120 --> 00:29:32,320
is reduced because the data is already

00:29:30,960 --> 00:29:34,720
projected and

00:29:32,320 --> 00:29:36,480
that makes it much easier to specify

00:29:34,720 --> 00:29:38,320
declarative rules for caching

00:29:36,480 --> 00:29:39,679
that depend on even user identity and

00:29:38,320 --> 00:29:41,039
stuff like that uh

00:29:39,679 --> 00:29:42,720
if you're reading from the from these

00:29:41,039 --> 00:29:45,039
projected models so if

00:29:42,720 --> 00:29:47,039
if you start thinking about your back

00:29:45,039 --> 00:29:49,520
end as a cqrs kind of back end

00:29:47,039 --> 00:29:51,120
um the the ability to kind of cache and

00:29:49,520 --> 00:29:52,320
the ability to create a framework to say

00:29:51,120 --> 00:29:53,200
this is how we're going to deal with our

00:29:52,320 --> 00:29:54,640
projected models

00:29:53,200 --> 00:29:56,640
and your ability to start making things

00:29:54,640 --> 00:29:58,399
more declarative right

00:29:56,640 --> 00:30:00,240
becomes becomes greater so you can

00:29:58,399 --> 00:30:01,840
create an internal library or an api or

00:30:00,240 --> 00:30:03,919
a declarative rule system

00:30:01,840 --> 00:30:05,440
uh that you can give to your developers

00:30:03,919 --> 00:30:06,640
because now you have a projected model

00:30:05,440 --> 00:30:09,039
that you're going to use right

00:30:06,640 --> 00:30:09,679
uh so so cqrs does actually help

00:30:09,039 --> 00:30:10,960
simplify

00:30:09,679 --> 00:30:12,240
caching with graphql a lot that's a

00:30:10,960 --> 00:30:13,520
that's a great question there are a

00:30:12,240 --> 00:30:14,880
bunch bunch of

00:30:13,520 --> 00:30:16,559
a bunch of other questions which we can

00:30:14,880 --> 00:30:17,840
take later but thank you so much folks

00:30:16,559 --> 00:30:19,279
i'll be hanging around on the discord

00:30:17,840 --> 00:30:21,520
channels for caching and graphql

00:30:19,279 --> 00:30:23,840
so see you folks there for more

00:30:21,520 --> 00:30:23,840
questions

00:30:23,970 --> 00:30:30,710
[Music]

00:30:31,880 --> 00:30:34,880

YouTube URL: https://www.youtube.com/watch?v=HJPYnUT5unw


