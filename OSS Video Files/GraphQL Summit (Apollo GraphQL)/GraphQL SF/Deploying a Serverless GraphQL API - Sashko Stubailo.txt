Title: Deploying a Serverless GraphQL API - Sashko Stubailo
Publication date: 2018-02-21
Playlist: GraphQL SF
Description: 
	At GraphQL SF 2/15/18, Sashko Stubailo from Apollo speaks about deploying a serverless GraphQL API with AWS Lambda and Apollo Engine.

Follow us on Twitter to get notified about future meetups: https://twitter.com/apollographql

ðŸ‘‰Full Description

More and more, we find that GraphQL APIs are being developed by product developers that don't want to worry about operating backend services. The serverless function model of deployment has a lot of benefits for APIs, but isn't as well suited when you need some stateful features such as caching or performance metrics aggregation. In this talk, Sashko presents a solution that combines the best of both worlds: A stateless GraphQL API running in AWS Lambda for ease of deployment with Apollo Engine in front to handle stateful concerns.

ðŸ‘‰Slides


https://www.slideshare.net/sashko1/production-ready-serverless-graphql-with-aws-lambda-apollo-engine

ðŸ‘‰Interested in Speaking?

We'd love to hear from you! Please message https://twitter.com/evanshauser
Captions: 
	00:00:02,689 --> 00:00:06,769
so I'm here to talk to you about real

00:00:05,059 --> 00:00:08,679
cool way to deploy graph kill servers

00:00:06,769 --> 00:00:13,610
but I've been really excited about for

00:00:08,679 --> 00:00:15,830
at least last week you know as you may

00:00:13,610 --> 00:00:18,170
know we've spent a lot of time thinking

00:00:15,830 --> 00:00:19,609
about graphical clients specifically and

00:00:18,170 --> 00:00:23,569
graph kill steam management with the

00:00:19,609 --> 00:00:26,480
react on the Apollo team but now the eye

00:00:23,569 --> 00:00:28,130
is is shifting to graph kill servers and

00:00:26,480 --> 00:00:30,349
server deployment so it's gonna be a

00:00:28,130 --> 00:00:30,919
very exciting year and and that's where

00:00:30,349 --> 00:00:33,649
this comes in

00:00:30,919 --> 00:00:35,540
so in the next ten minutes I want to

00:00:33,649 --> 00:00:36,980
show you first of all what is the

00:00:35,540 --> 00:00:38,450
fastest way to get graphical going at

00:00:36,980 --> 00:00:41,660
your company if you don't have any graph

00:00:38,450 --> 00:00:43,400
QL second why server list is a great

00:00:41,660 --> 00:00:44,840
option to deploy your graph kill server

00:00:43,400 --> 00:00:47,390
if you're looking for a simple way to do

00:00:44,840 --> 00:00:48,770
that and why Apollo engine the tool we

00:00:47,390 --> 00:00:50,750
built is a good way to fill in the gaps

00:00:48,770 --> 00:00:52,460
of that architecture and the third is

00:00:50,750 --> 00:00:54,320
just walk through how you might set up

00:00:52,460 --> 00:00:57,140
that production-ready architecture in

00:00:54,320 --> 00:00:58,640
just a few minutes and I learned my

00:00:57,140 --> 00:01:00,739
lesson over the last couple of talks

00:00:58,640 --> 00:01:02,420
that I've done to never actually do real

00:01:00,739 --> 00:01:04,460
live demos so I just screenshotted it

00:01:02,420 --> 00:01:06,049
when I did it earlier today and it

00:01:04,460 --> 00:01:10,340
totally worked

00:01:06,049 --> 00:01:11,840
so that was great all right so you know

00:01:10,340 --> 00:01:13,909
it's great that John was just talking

00:01:11,840 --> 00:01:16,490
about putting graphical api's on top of

00:01:13,909 --> 00:01:19,189
rest because I think that's actually an

00:01:16,490 --> 00:01:20,929
often overlooked but extremely critical

00:01:19,189 --> 00:01:23,439
way that graph QL I think should be used

00:01:20,929 --> 00:01:25,399
in a lot of different places because

00:01:23,439 --> 00:01:27,170
what we've heard from people is that

00:01:25,399 --> 00:01:28,310
almost every single time you're trying

00:01:27,170 --> 00:01:30,380
to build a new front-end or a new

00:01:28,310 --> 00:01:31,969
feature inside an organization with a

00:01:30,380 --> 00:01:33,649
lot of data the api's you have are

00:01:31,969 --> 00:01:35,270
almost never exactly what you're looking

00:01:33,649 --> 00:01:36,469
for so either you're forced to call

00:01:35,270 --> 00:01:38,539
api's that return you a bunch of data

00:01:36,469 --> 00:01:40,670
you don't need or often you have to wait

00:01:38,539 --> 00:01:42,380
for new IPIN points to be constructed or

00:01:40,670 --> 00:01:44,149
there's some sort of problem and when we

00:01:42,380 --> 00:01:45,529
were talking to people maybe two years

00:01:44,149 --> 00:01:47,539
ago one thing we heard is some people

00:01:45,529 --> 00:01:49,759
even actually build a new API back in

00:01:47,539 --> 00:01:53,869
for like every single feature which

00:01:49,759 --> 00:01:55,039
seems real intense so graph geo might be

00:01:53,869 --> 00:01:57,259
able to help you there because it might

00:01:55,039 --> 00:01:58,969
help you build those applications a lot

00:01:57,259 --> 00:02:01,849
more quickly and have great tooling and

00:01:58,969 --> 00:02:04,310
not have to deal with the rigid api have

00:02:01,849 --> 00:02:05,539
you had before but at the same time if

00:02:04,310 --> 00:02:07,369
you want to get graphical going in your

00:02:05,539 --> 00:02:08,539
company as fast as possible you don't

00:02:07,369 --> 00:02:10,160
want to worry about complicated

00:02:08,539 --> 00:02:11,420
infrastructure you don't want to worry

00:02:10,160 --> 00:02:12,050
about rewriting your whole back-end or

00:02:11,420 --> 00:02:14,750
anything like that

00:02:12,050 --> 00:02:16,010
and so I think if we could have a really

00:02:14,750 --> 00:02:17,330
lightweight way

00:02:16,010 --> 00:02:20,120
a really simple way to deploy a graph

00:02:17,330 --> 00:02:23,420
QAPI on top of our existing backends I

00:02:20,120 --> 00:02:24,920
think that would be super sweet so I

00:02:23,420 --> 00:02:26,450
think a great solution this problem is

00:02:24,920 --> 00:02:28,640
to put graph QL directly over your

00:02:26,450 --> 00:02:29,750
existing api's so there's been a lot of

00:02:28,640 --> 00:02:31,099
different discussion out there

00:02:29,750 --> 00:02:32,480
especially as graph kills getting

00:02:31,099 --> 00:02:34,010
started about putting graph kill

00:02:32,480 --> 00:02:35,810
directly over your database or starting

00:02:34,010 --> 00:02:38,209
a new application using a tool like

00:02:35,810 --> 00:02:39,890
graph cool or something like that but I

00:02:38,209 --> 00:02:42,530
think this is really the killer use case

00:02:39,890 --> 00:02:44,329
for graph QL is putting it on top of

00:02:42,530 --> 00:02:47,150
existing backends that you already have

00:02:44,329 --> 00:02:48,470
that you want to make better even if

00:02:47,150 --> 00:02:49,879
you're not talking directly to your

00:02:48,470 --> 00:02:51,260
back-end if you're just talking to REST

00:02:49,879 --> 00:02:53,180
API eyes you already get a whole ton of

00:02:51,260 --> 00:02:54,530
benefits you're definitely gonna get a

00:02:53,180 --> 00:02:55,970
better developer experience because your

00:02:54,530 --> 00:02:57,500
API is now gonna be self documenting

00:02:55,970 --> 00:02:59,000
it's gonna be much easier to write

00:02:57,500 --> 00:03:01,040
queries you don't have to do multiple

00:02:59,000 --> 00:03:02,780
requests on the client I'm drinking out

00:03:01,040 --> 00:03:04,489
much smaller payloads because if you've

00:03:02,780 --> 00:03:06,530
ever called like the get abreast API and

00:03:04,489 --> 00:03:07,849
gotten like 20 kilobytes of data when

00:03:06,530 --> 00:03:10,609
you were looking for like three fields

00:03:07,849 --> 00:03:12,769
now you can do that on the back end in

00:03:10,609 --> 00:03:14,900
your graph QL API instead of all the way

00:03:12,769 --> 00:03:16,790
from your clients and also I think you

00:03:14,900 --> 00:03:18,709
might get a lot better insight into how

00:03:16,790 --> 00:03:20,480
your client is performing because when

00:03:18,709 --> 00:03:23,449
you send that graph QL query actually is

00:03:20,480 --> 00:03:25,010
one unit to the server that graph kill

00:03:23,449 --> 00:03:26,540
Server can actually know all the data

00:03:25,010 --> 00:03:28,699
that's required for a particular view

00:03:26,540 --> 00:03:30,139
and track what it took to actually

00:03:28,699 --> 00:03:31,519
execute that which we'll see in a second

00:03:30,139 --> 00:03:33,230
which is something that's actually a lot

00:03:31,519 --> 00:03:36,980
harder to do if you're making all those

00:03:33,230 --> 00:03:38,629
requests individually from your UI so my

00:03:36,980 --> 00:03:40,579
point here is even if you're not hyper

00:03:38,629 --> 00:03:42,410
optimizing your graph QL API to do like

00:03:40,579 --> 00:03:43,879
the absolute smallest number of requests

00:03:42,410 --> 00:03:45,049
and it's just the same request you're

00:03:43,879 --> 00:03:46,849
doing from the client but now you're

00:03:45,049 --> 00:03:50,299
doing them inside a server you already

00:03:46,849 --> 00:03:52,040
get a lot of benefits so how do we make

00:03:50,299 --> 00:03:54,319
that graph kill layer that we're

00:03:52,040 --> 00:03:55,220
throwing into our infrastructure feel

00:03:54,319 --> 00:03:56,419
less like another piece of

00:03:55,220 --> 00:03:59,500
infrastructure you have to manage

00:03:56,419 --> 00:04:02,510
another server that you've got a deploy

00:03:59,500 --> 00:04:03,980
and make it feel like just a thin thing

00:04:02,510 --> 00:04:05,840
that just translates from one thing to

00:04:03,980 --> 00:04:08,859
another well if you want to avoid having

00:04:05,840 --> 00:04:11,959
a server clearly you want serverless

00:04:08,859 --> 00:04:13,549
because that's that's the whole point so

00:04:11,959 --> 00:04:15,620
if you use serverless functions like

00:04:13,549 --> 00:04:17,239
something like lambda or Google Cloud

00:04:15,620 --> 00:04:19,909
mostly just lambda that's the only thing

00:04:17,239 --> 00:04:21,650
that I think people use you don't have

00:04:19,909 --> 00:04:23,690
to do any manual scaling at all because

00:04:21,650 --> 00:04:25,400
you just get a new function whenever you

00:04:23,690 --> 00:04:26,450
make a new request you don't have to

00:04:25,400 --> 00:04:28,250
worry about how many containers you're

00:04:26,450 --> 00:04:30,020
running what their CPU is whether

00:04:28,250 --> 00:04:31,430
they're crashing you can really easily

00:04:30,020 --> 00:04:32,750
deploy new versions and have new

00:04:31,430 --> 00:04:35,630
requests go to those versions right away

00:04:32,750 --> 00:04:36,979
if you have an error it's not a big deal

00:04:35,630 --> 00:04:39,080
you just get a new function the next

00:04:36,979 --> 00:04:40,780
time so I think actually server list is

00:04:39,080 --> 00:04:42,830
a really great way to go with graph QL

00:04:40,780 --> 00:04:44,450
especially if you want it to feel like

00:04:42,830 --> 00:04:46,279
that really thin translation layer and

00:04:44,450 --> 00:04:48,110
not like a whole other service or back

00:04:46,279 --> 00:04:49,940
in that you have to manage and that's

00:04:48,110 --> 00:04:51,020
especially because I think that the

00:04:49,940 --> 00:04:53,360
people that are best equipped to manage

00:04:51,020 --> 00:04:55,190
that graph kill server are the front end

00:04:53,360 --> 00:04:57,169
developers or product developers that

00:04:55,190 --> 00:04:59,060
need that API not the people at your

00:04:57,169 --> 00:05:01,159
company that normally run those back-end

00:04:59,060 --> 00:05:02,840
services which is something that I

00:05:01,159 --> 00:05:04,370
didn't initially think a couple of years

00:05:02,840 --> 00:05:06,560
ago but as we've been talking to more

00:05:04,370 --> 00:05:08,570
and more teams we've often seen the

00:05:06,560 --> 00:05:09,860
teams be the most successful where it's

00:05:08,570 --> 00:05:15,229
the Fronde developers who are in charge

00:05:09,860 --> 00:05:16,400
of that particular API layer so another

00:05:15,229 --> 00:05:18,020
thing that I'm really excited about is

00:05:16,400 --> 00:05:19,940
Apollo engine which is this tool that

00:05:18,020 --> 00:05:20,960
we've been developing and the thing that

00:05:19,940 --> 00:05:23,090
I've been really excited about over the

00:05:20,960 --> 00:05:25,849
last week is that it specifically really

00:05:23,090 --> 00:05:28,520
well complements this function mentality

00:05:25,849 --> 00:05:30,110
so there's a lot of things that are

00:05:28,520 --> 00:05:32,180
pretty hard to do when you've got this

00:05:30,110 --> 00:05:33,620
service set up where every time you you

00:05:32,180 --> 00:05:35,389
throw away your entire environment every

00:05:33,620 --> 00:05:36,919
time you do in the request it can be

00:05:35,389 --> 00:05:38,450
hard to do performance tracing because

00:05:36,919 --> 00:05:41,029
that often requires aggregating data

00:05:38,450 --> 00:05:43,010
over some period of time it can be hard

00:05:41,029 --> 00:05:45,380
to track errors because if that function

00:05:43,010 --> 00:05:47,000
crashes how are you gonna get that error

00:05:45,380 --> 00:05:48,560
and aggregated into a single place it

00:05:47,000 --> 00:05:50,900
also be hard to do stuff like caching

00:05:48,560 --> 00:05:53,000
across those requests because inside a

00:05:50,900 --> 00:05:55,460
container or a long-lived server you can

00:05:53,000 --> 00:05:57,950
memorize stuff you can like use e tags

00:05:55,460 --> 00:05:59,810
whatever with your back-end but it's a

00:05:57,950 --> 00:06:01,669
lot harder to do that lambda and so I

00:05:59,810 --> 00:06:04,219
was wondering if we could get a lot of

00:06:01,669 --> 00:06:06,229
the best of both worlds by adding engine

00:06:04,219 --> 00:06:07,669
on top of it and that's what I'm gonna

00:06:06,229 --> 00:06:11,300
show you how to do in the rest of the

00:06:07,669 --> 00:06:13,490
talk so first we're gonna see how easy

00:06:11,300 --> 00:06:15,289
it is to deploy a JavaScript graphical

00:06:13,490 --> 00:06:17,680
server to lambda using this tool called

00:06:15,289 --> 00:06:20,150
up that my coworker James told me about

00:06:17,680 --> 00:06:21,800
and then we're gonna see how easy it is

00:06:20,150 --> 00:06:24,110
to deploy engine which is a stateful

00:06:21,800 --> 00:06:26,000
thing using Fargate which is a new

00:06:24,110 --> 00:06:28,250
technology that AWS released just a

00:06:26,000 --> 00:06:30,740
month ago to deploy containers just as

00:06:28,250 --> 00:06:32,779
easily as you can deploy lambdas and if

00:06:30,740 --> 00:06:33,890
you want more complete directions about

00:06:32,779 --> 00:06:34,459
how to do this you can go to this

00:06:33,890 --> 00:06:36,620
repository

00:06:34,459 --> 00:06:38,630
made by James that I just follow to make

00:06:36,620 --> 00:06:42,270
this talk so let's see what it looks

00:06:38,630 --> 00:06:44,640
like okay so first we've

00:06:42,270 --> 00:06:46,050
to write a graph QL API so this is where

00:06:44,640 --> 00:06:49,530
you would apply all those tips that you

00:06:46,050 --> 00:06:51,720
learn from from John we've got a great

00:06:49,530 --> 00:06:53,490
example online you can find that uses

00:06:51,720 --> 00:06:55,620
the Ticketmaster API to retrieve some

00:06:53,490 --> 00:06:58,770
information about upcoming concerts in

00:06:55,620 --> 00:07:00,420
your area but it's actually not too hard

00:06:58,770 --> 00:07:02,670
you just write a couple of resolvers you

00:07:00,420 --> 00:07:03,810
call fetch in there and you hit that

00:07:02,670 --> 00:07:06,180
rest endpoint there you're trying to hit

00:07:03,810 --> 00:07:09,600
and then you can really easily use that

00:07:06,180 --> 00:07:11,850
data then you just really easily take

00:07:09,600 --> 00:07:13,530
that schema that you wrote you bind it

00:07:11,850 --> 00:07:15,360
to an HTTP server the same way that you

00:07:13,530 --> 00:07:16,890
would do it without lambda um you know

00:07:15,360 --> 00:07:18,060
we're just using Express here because it

00:07:16,890 --> 00:07:19,860
turns out the tool we're about to use

00:07:18,060 --> 00:07:21,420
doesn't require you to write any lambda

00:07:19,860 --> 00:07:23,640
specific code at all it's just like

00:07:21,420 --> 00:07:24,840
writing an Express web server the same

00:07:23,640 --> 00:07:27,180
way you would write it any other way and

00:07:24,840 --> 00:07:30,480
this is actually the entire file that

00:07:27,180 --> 00:07:32,280
that does that part and then the last

00:07:30,480 --> 00:07:34,110
thing we do is we just write a couple of

00:07:32,280 --> 00:07:35,760
lines of configuration that you don't

00:07:34,110 --> 00:07:38,660
even have to look at you can just get it

00:07:35,760 --> 00:07:40,950
if you download that repository and then

00:07:38,660 --> 00:07:45,660
you literally just type one command

00:07:40,950 --> 00:07:47,880
which is just up and then you get your

00:07:45,660 --> 00:07:50,970
server on lambda and then you type up

00:07:47,880 --> 00:07:54,990
URL and you have a URL to your server

00:07:50,970 --> 00:07:56,490
that is running so okay so before we

00:07:54,990 --> 00:08:01,170
move on let's see if that actually works

00:07:56,490 --> 00:08:05,400
so we've got a server running on lambda

00:08:01,170 --> 00:08:08,520
we can indeed oh my god this keyboard

00:08:05,400 --> 00:08:10,590
there we go we can get a list of some of

00:08:08,520 --> 00:08:14,880
my favorite artists which I think

00:08:10,590 --> 00:08:18,540
includes Kansas Lily octi and Jason

00:08:14,880 --> 00:08:21,420
brass and all of these artists have

00:08:18,540 --> 00:08:26,460
upcoming concerts in my area I check

00:08:21,420 --> 00:08:29,820
that so for example there are concerts

00:08:26,460 --> 00:08:32,520
at these time stamps and you can also

00:08:29,820 --> 00:08:35,900
get nice images so for example things

00:08:32,520 --> 00:08:37,830
gave me an image of the band Kansas

00:08:35,900 --> 00:08:38,940
there you go

00:08:37,830 --> 00:08:40,860
and so these are all coming from that

00:08:38,940 --> 00:08:41,790
Ticketmaster API that we wrapped with

00:08:40,860 --> 00:08:43,500
that code that I was telling you about

00:08:41,790 --> 00:08:44,700
and in a second I'll show you how easy

00:08:43,500 --> 00:08:47,400
it is to actually redeploy and you

00:08:44,700 --> 00:08:51,110
version of that API where'd I put my

00:08:47,400 --> 00:08:52,970
presentation over here perfect

00:08:51,110 --> 00:08:54,350
all right and one thing you can see over

00:08:52,970 --> 00:08:56,720
there is there's this little extensions

00:08:54,350 --> 00:08:57,709
bit at the bottom of the response and

00:08:56,720 --> 00:08:59,480
that's going to come into play

00:08:57,709 --> 00:09:00,560
when we set up this engine thing so

00:08:59,480 --> 00:09:02,660
right now we're hitting the lamda

00:09:00,560 --> 00:09:05,149
directly but what benefits do we get if

00:09:02,660 --> 00:09:07,399
we head it through another thing so

00:09:05,149 --> 00:09:09,290
we'll see in a bit so it turns out

00:09:07,399 --> 00:09:11,089
deploying engine engine is this thing

00:09:09,290 --> 00:09:12,920
that's kind of like a graphical proxy

00:09:11,089 --> 00:09:15,230
that you can get just in the form of a

00:09:12,920 --> 00:09:16,610
container and with Fargate it's super

00:09:15,230 --> 00:09:19,730
easy you just go to this URL

00:09:16,610 --> 00:09:21,850
you basically just type in the URL to

00:09:19,730 --> 00:09:24,740
that container on the docker registry

00:09:21,850 --> 00:09:26,990
and then you put in some configuration

00:09:24,740 --> 00:09:30,200
directly into the AWS console and then

00:09:26,990 --> 00:09:31,850
you hit like a create button and then

00:09:30,200 --> 00:09:35,450
it's pretty great you get a whole lot of

00:09:31,850 --> 00:09:37,130
green check boxes on your screen that

00:09:35,450 --> 00:09:38,480
set up all this kind of stuff that you

00:09:37,130 --> 00:09:40,100
would normally have to set up on AWS

00:09:38,480 --> 00:09:41,750
yourself remember there you might not

00:09:40,100 --> 00:09:43,160
see but the check boxes are all over

00:09:41,750 --> 00:09:45,260
here

00:09:43,160 --> 00:09:47,839
it sets up all kinds of stuff it sets up

00:09:45,260 --> 00:09:51,160
load balancing if that's a B pcs subnets

00:09:47,839 --> 00:09:53,240
tasks definition and services clusters

00:09:51,160 --> 00:09:54,410
really just with one button click so I

00:09:53,240 --> 00:09:55,910
think this new product that they

00:09:54,410 --> 00:09:58,610
released a month ago makes a whole lot

00:09:55,910 --> 00:10:02,029
of stuff a lot easier so this is super

00:09:58,610 --> 00:10:03,709
sweet and then you're up and running

00:10:02,029 --> 00:10:06,230
after you click through some dialogues

00:10:03,709 --> 00:10:08,680
because AWS is maybe a few more

00:10:06,230 --> 00:10:10,790
dialogues than you would hope for but

00:10:08,680 --> 00:10:12,500
but you basically just click Next on all

00:10:10,790 --> 00:10:16,459
of them ok so now let's see what happens

00:10:12,500 --> 00:10:19,390
when we hit the same end point through

00:10:16,459 --> 00:10:22,970
that thing and I think I've prepared a

00:10:19,390 --> 00:10:25,459
query so I've type it in again so you

00:10:22,970 --> 00:10:27,440
can see that we get also the data that

00:10:25,459 --> 00:10:28,699
we were looking for and when we scroll

00:10:27,440 --> 00:10:30,670
back down to the bottom we don't have

00:10:28,699 --> 00:10:32,660
those extensions anymore because now

00:10:30,670 --> 00:10:34,370
engine is running in front of our server

00:10:32,660 --> 00:10:36,260
and it's actually consuming that data

00:10:34,370 --> 00:10:40,540
for us so let's see what we get I'm

00:10:36,260 --> 00:10:44,120
gonna hit this a couple more times okay

00:10:40,540 --> 00:10:48,050
so this is the engine UI here and I

00:10:44,120 --> 00:10:49,880
think if we refresh this we will indeed

00:10:48,050 --> 00:10:51,680
see okay we will see that we did a

00:10:49,880 --> 00:10:53,779
couple of requests this app is very

00:10:51,680 --> 00:10:55,730
unpopular because I'm the only one who

00:10:53,779 --> 00:10:57,560
uses it so they've only been nine

00:10:55,730 --> 00:10:59,360
requests in the last hour but one really

00:10:57,560 --> 00:11:01,490
neat thing that we can do right away is

00:10:59,360 --> 00:11:03,830
we can start to get traces of how our

00:11:01,490 --> 00:11:06,410
graph QL

00:11:03,830 --> 00:11:08,870
executed so we can see that the my

00:11:06,410 --> 00:11:10,700
favorite artist field took 55

00:11:08,870 --> 00:11:12,350
milliseconds that the events field took

00:11:10,700 --> 00:11:13,520
hundred and twenty-six milliseconds this

00:11:12,350 --> 00:11:15,710
is how long it took to actually hit that

00:11:13,520 --> 00:11:17,600
Ticketmaster API to get that data back

00:11:15,710 --> 00:11:19,670
that we were looking for and so that's

00:11:17,600 --> 00:11:20,990
why it consumes that extension data that

00:11:19,670 --> 00:11:22,820
comes from the graph jewel server and

00:11:20,990 --> 00:11:24,950
gives you more insight into how your

00:11:22,820 --> 00:11:27,580
server works and is able to actually

00:11:24,950 --> 00:11:29,630
aggregate that over time to give you

00:11:27,580 --> 00:11:31,940
histograms of your performance and

00:11:29,630 --> 00:11:33,560
because it's all based on the queries

00:11:31,940 --> 00:11:35,900
that you're doing based on the different

00:11:33,560 --> 00:11:37,040
UI queries you're doing in your UI you

00:11:35,900 --> 00:11:39,410
can see how different parts of your app

00:11:37,040 --> 00:11:41,840
are performing one thing that I think is

00:11:39,410 --> 00:11:44,330
really cool here is you can actually see

00:11:41,840 --> 00:11:46,160
some of the overhead that lamda adds to

00:11:44,330 --> 00:11:48,440
your request which is basically the time

00:11:46,160 --> 00:11:51,740
in between engine actually invoking that

00:11:48,440 --> 00:11:53,840
lamda request and the requests actually

00:11:51,740 --> 00:11:56,960
starting to execute there's like at

00:11:53,840 --> 00:11:59,480
least 50 or 60 60 milliseconds there so

00:11:56,960 --> 00:12:02,330
this request the screenshot here in

00:11:59,480 --> 00:12:05,180
total took 250 milliseconds that's like

00:12:02,330 --> 00:12:06,890
okay I think that's just like part of

00:12:05,180 --> 00:12:08,990
the part of the deal of using server

00:12:06,890 --> 00:12:10,130
lists a little bit is that because

00:12:08,990 --> 00:12:12,050
you're cleaning everything up right

00:12:10,130 --> 00:12:13,240
every time it sometimes takes a little

00:12:12,050 --> 00:12:17,480
bit longer than having that request

00:12:13,240 --> 00:12:18,710
running or that server running but this

00:12:17,480 --> 00:12:20,720
is what I got really excited about in

00:12:18,710 --> 00:12:22,190
last week is that because engine has

00:12:20,720 --> 00:12:24,700
that stateful thing going on it can

00:12:22,190 --> 00:12:25,910
actually solve that for you with caching

00:12:24,700 --> 00:12:27,770
okay

00:12:25,910 --> 00:12:30,680
so this is where it's actually a live

00:12:27,770 --> 00:12:33,250
demo so in order to turn on caching I

00:12:30,680 --> 00:12:36,980
think it's pretty easy we will find out

00:12:33,250 --> 00:12:40,070
the only thing we have to do is add some

00:12:36,980 --> 00:12:43,730
directives to our schema where we can

00:12:40,070 --> 00:12:45,020
say we would like to cash this data for

00:12:43,730 --> 00:12:46,190
10 seconds and I'm getting real nervous

00:12:45,020 --> 00:12:49,130
now because I'm about to deploy some

00:12:46,190 --> 00:12:50,810
code so yeah so we added some directives

00:12:49,130 --> 00:12:52,940
here that say we want to cache these

00:12:50,810 --> 00:12:54,500
types for 10 seconds and once we deploy

00:12:52,940 --> 00:12:57,890
and we're going to see how easy it is to

00:12:54,500 --> 00:13:00,310
deploy to lamda using this tool we just

00:12:57,890 --> 00:13:00,310
type up

00:13:07,490 --> 00:13:12,800
sweet alright so we just deployed a new

00:13:10,279 --> 00:13:14,000
version of our code to lamda I think the

00:13:12,800 --> 00:13:17,270
fact that it finished means it's already

00:13:14,000 --> 00:13:19,430
running and now we're gonna go here and

00:13:17,270 --> 00:13:23,300
we're gonna click this button again I

00:13:19,430 --> 00:13:25,880
think it's a lambda cold start okay now

00:13:23,300 --> 00:13:28,100
I don't know if you can tell it's a

00:13:25,880 --> 00:13:29,660
little bit faster but I will show you

00:13:28,100 --> 00:13:31,070
the data and it's a little bit slower

00:13:29,660 --> 00:13:33,920
every 10 seconds because it's only cache

00:13:31,070 --> 00:13:35,720
for 10 seconds okay but when we go to

00:13:33,920 --> 00:13:38,420
this UI we can really see what's going

00:13:35,720 --> 00:13:40,010
on I think it only updates like every

00:13:38,420 --> 00:13:42,830
once in a while so if you want to go to

00:13:40,010 --> 00:13:45,440
the USTA okay so we can see that from a

00:13:42,830 --> 00:13:47,540
lambda cold start when the lambdas just

00:13:45,440 --> 00:13:48,740
deploy it took three seconds when we

00:13:47,540 --> 00:13:51,080
were actually hitting the API it took

00:13:48,740 --> 00:13:54,820
300 milliseconds and then with the

00:13:51,080 --> 00:13:57,459
engine cache it took 500 microseconds so

00:13:54,820 --> 00:13:59,300
you can see that it's much faster and

00:13:57,459 --> 00:14:01,070
you know this cache doesn't do

00:13:59,300 --> 00:14:02,600
everything that you might want to do in

00:14:01,070 --> 00:14:04,339
the world with a cache yet but if you've

00:14:02,600 --> 00:14:05,540
got an app that has a lot of public

00:14:04,339 --> 00:14:07,459
facing data like you're displaying

00:14:05,540 --> 00:14:09,170
concert information you don't need new

00:14:07,459 --> 00:14:11,120
data every microsecond you could catch

00:14:09,170 --> 00:14:13,820
that stuff for 10 seconds no problem at

00:14:11,120 --> 00:14:16,459
all and that's where I think using

00:14:13,820 --> 00:14:18,170
lambda together with engine both of them

00:14:16,459 --> 00:14:20,209
are super easy to deploy because of this

00:14:18,170 --> 00:14:21,589
to call tool called up and because of

00:14:20,209 --> 00:14:23,450
Fargate which lets you run that

00:14:21,589 --> 00:14:25,579
container in an auto scaling way you

00:14:23,450 --> 00:14:27,680
don't have to worry about it I think

00:14:25,579 --> 00:14:31,640
they really work super well together and

00:14:27,680 --> 00:14:35,600
that's what I'm excited about alright so

00:14:31,640 --> 00:14:37,940
looks like it worked so there's a

00:14:35,600 --> 00:14:41,000
screenshot of that chart just in case we

00:14:37,940 --> 00:14:42,529
couldn't get it actually working but

00:14:41,000 --> 00:14:43,730
basically yeah you can actually even

00:14:42,529 --> 00:14:45,170
feel the difference when you click that

00:14:43,730 --> 00:14:46,820
button in graphical that instead of

00:14:45,170 --> 00:14:48,800
taking 100 or 200 milliseconds it takes

00:14:46,820 --> 00:14:50,720
like no milliseconds at all so that's

00:14:48,800 --> 00:14:53,000
pretty sweet and you're actually saving

00:14:50,720 --> 00:14:53,870
that performance on your back-end as

00:14:53,000 --> 00:14:57,550
well because you're not even hitting

00:14:53,870 --> 00:15:00,110
that REST API which is also super sweet

00:14:57,550 --> 00:15:02,120
so basically I'm really excited about

00:15:00,110 --> 00:15:03,560
this architecture right now it's kind of

00:15:02,120 --> 00:15:04,970
a new thing enabled by a couple of

00:15:03,560 --> 00:15:06,200
different new products including engine

00:15:04,970 --> 00:15:07,820
and Fargate and a bunch of other stuff

00:15:06,200 --> 00:15:10,220
you get a whole bunch of stuff including

00:15:07,820 --> 00:15:12,770
some things that didn't show like if

00:15:10,220 --> 00:15:15,770
your lambda actually crashes and returns

00:15:12,770 --> 00:15:16,850
like you know basically an error you'll

00:15:15,770 --> 00:15:18,260
actually be able to see that an engine

00:15:16,850 --> 00:15:20,410
as well because even though the lambda

00:15:18,260 --> 00:15:22,360
is crashed the container hasn't crashed

00:15:20,410 --> 00:15:25,540
because they're separated part of the

00:15:22,360 --> 00:15:26,800
wonder of the cloud so I'm really

00:15:25,540 --> 00:15:28,660
excited about this architecture that I

00:15:26,800 --> 00:15:30,670
think is going to bring people some of

00:15:28,660 --> 00:15:31,990
the main benefits of service deployment

00:15:30,670 --> 00:15:33,520
as well as some of the benefits of

00:15:31,990 --> 00:15:36,700
actually having a server and having that

00:15:33,520 --> 00:15:37,660
stateful architecture and I'm so excited

00:15:36,700 --> 00:15:39,400
about it I'm definitely gonna put

00:15:37,660 --> 00:15:41,170
together a blog post next week that

00:15:39,400 --> 00:15:43,170
outlines how to do this but if you guys

00:15:41,170 --> 00:15:46,120
want to dive in into the nitty-gritty

00:15:43,170 --> 00:15:48,340
there's a great read me on this repo

00:15:46,120 --> 00:15:48,970
that you can check out and I think

00:15:48,340 --> 00:15:57,760
that's all I've got

00:15:48,970 --> 00:15:59,290
thank you very much thank you sashko we

00:15:57,760 --> 00:16:07,570
can take a couple questions if there are

00:15:59,290 --> 00:16:09,670
any any questions please yeah um so if

00:16:07,570 --> 00:16:11,830
you go to the the question is how easy

00:16:09,670 --> 00:16:13,570
it is it to deploy my graphical API here

00:16:11,830 --> 00:16:15,160
so I think they're a couple things they

00:16:13,570 --> 00:16:17,350
make it really easy the first thing is

00:16:15,160 --> 00:16:19,570
that this up tool is super simple

00:16:17,350 --> 00:16:21,490
because you don't have to when you're

00:16:19,570 --> 00:16:22,990
usually deploying a node app to lambda

00:16:21,490 --> 00:16:24,610
you have to write some lambda specific

00:16:22,990 --> 00:16:26,380
code but because it just takes a regular

00:16:24,610 --> 00:16:28,600
Express server you basically don't have

00:16:26,380 --> 00:16:30,070
to do anything at all so it's super easy

00:16:28,600 --> 00:16:31,470
you could probably just deploy your

00:16:30,070 --> 00:16:33,670
server that you already have to there

00:16:31,470 --> 00:16:35,380
and like I said you can find the

00:16:33,670 --> 00:16:37,990
directions to do that on this repository

00:16:35,380 --> 00:16:41,020
but if you want to wait a little bit I'm

00:16:37,990 --> 00:16:42,580
also gonna put up more detailed easy to

00:16:41,020 --> 00:16:43,900
follow directions well these are the

00:16:42,580 --> 00:16:46,770
directions I followed and it worked but

00:16:43,900 --> 00:16:49,090
I'm gonna try even harder next week

00:16:46,770 --> 00:16:50,680
that's very true follow up answer if you

00:16:49,090 --> 00:16:52,750
want that caching but you don't want to

00:16:50,680 --> 00:16:57,940
use lambda you can also still use engine

00:16:52,750 --> 00:16:59,380
and you can even use Fargate but yes

00:16:57,940 --> 00:17:01,450
that's correct this talk is about a

00:16:59,380 --> 00:17:04,030
specific architecture but you can use

00:17:01,450 --> 00:17:06,550
engine by itself with like Heroku with

00:17:04,030 --> 00:17:08,140
your AWS server with ECS with like

00:17:06,550 --> 00:17:09,310
basically any with kubernetes like

00:17:08,140 --> 00:17:12,510
anything you want that can deploy a

00:17:09,310 --> 00:17:14,079
container suite any other questions

00:17:12,510 --> 00:17:17,339
thank you very much

00:17:14,079 --> 00:17:17,339
really a lot of Monica

00:17:17,370 --> 00:17:19,430

YouTube URL: https://www.youtube.com/watch?v=aNbxH9KQqiA


