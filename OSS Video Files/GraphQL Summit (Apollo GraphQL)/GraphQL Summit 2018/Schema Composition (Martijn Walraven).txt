Title: Schema Composition (Martijn Walraven)
Publication date: 2018-12-05
Playlist: GraphQL Summit 2018
Description: 
	Talk from GraphQL Summit 2018 - Nov 8, 2018

Martijn Walraven, a Tech Lead at Apollo, shares schema composition strategies that range from techniques for achieving modularity within a single codebase, to tools and workflows that help teams collaborate on a shared data graph distributed across multiple services.

Learn more about Apollo:  https://www.apollographql.com/

Join Apollo's community Slack group:  https://www.apollographql.com/slack/

Resources:
Learn more about Summit - https://summit.graphql.com/
Explore the GraphQL FAQs - https://www.apollographql.com/docs/resources/faq
Checkout the Apollo docs - https://www.apollographql.com/docs/
Learn GraphQL using Apollo's Tutorials: https://odyssey.apollographql.com/
Captions: 
	00:00:03,640 --> 00:00:11,929
all right really glad to be here and

00:00:09,700 --> 00:00:15,589
excited to share some of the things

00:00:11,929 --> 00:00:18,019
we've been working on for a while my

00:00:15,589 --> 00:00:23,779
name is Martin Lauren I'm tech lead add

00:00:18,019 --> 00:00:26,269
a polo and maybe we just start by sort

00:00:23,779 --> 00:00:30,679
of reminding ourselves how lucky we are

00:00:26,269 --> 00:00:34,160
that we get to use graph QL that we get

00:00:30,679 --> 00:00:37,910
to write a query like this imagine

00:00:34,160 --> 00:00:40,520
you're writing a front-end for an

00:00:37,910 --> 00:00:42,739
e-commerce site you have a page where

00:00:40,520 --> 00:00:46,280
you want to show the top reviews for

00:00:42,739 --> 00:00:48,350
products you want to show who wrote the

00:00:46,280 --> 00:00:49,879
review and you want to include some

00:00:48,350 --> 00:00:52,100
information about the product name the

00:00:49,879 --> 00:00:55,609
price and you also want to know whether

00:00:52,100 --> 00:00:58,129
the product is currently in stock this

00:00:55,609 --> 00:01:03,940
is what you need and this is what you

00:00:58,129 --> 00:01:06,890
write and this is all made possible by

00:01:03,940 --> 00:01:09,830
this amazing concept of having a data

00:01:06,890 --> 00:01:11,150
graph a graph that describes all the

00:01:09,830 --> 00:01:13,549
data that's available to you as a

00:01:11,150 --> 00:01:17,570
developer and then you write queries

00:01:13,549 --> 00:01:20,000
against this graph one thing to keep in

00:01:17,570 --> 00:01:23,509
mind there is that as soon as you sort

00:01:20,000 --> 00:01:28,070
of break up this one graph into smaller

00:01:23,509 --> 00:01:29,990
graphs as soon as you have multiple

00:01:28,070 --> 00:01:32,840
teams sort of coming up with their own

00:01:29,990 --> 00:01:37,009
graph QL api's you're losing a large

00:01:32,840 --> 00:01:38,600
part of the benefit of that one graph on

00:01:37,009 --> 00:01:40,939
the other hand there are good reasons

00:01:38,600 --> 00:01:47,960
for actually wanting to break up your

00:01:40,939 --> 00:01:49,430
schema having one graph making one graph

00:01:47,960 --> 00:01:51,439
available to your clients

00:01:49,430 --> 00:01:56,619
doesn't mean that you need to write one

00:01:51,439 --> 00:01:59,090
monolithic schema so they're often

00:01:56,619 --> 00:02:01,189
really good reasons not to write your

00:01:59,090 --> 00:02:06,820
whole schema in one file or in one

00:02:01,189 --> 00:02:10,460
repository or in one NPM package and

00:02:06,820 --> 00:02:14,260
especially if you

00:02:10,460 --> 00:02:16,760
if your graph starts growing

00:02:14,260 --> 00:02:21,200
you'll be working together with multiple

00:02:16,760 --> 00:02:23,030
teams on this single graph so you need

00:02:21,200 --> 00:02:26,000
to start thinking about ways to break up

00:02:23,030 --> 00:02:31,370
your your schema while still exposing a

00:02:26,000 --> 00:02:34,130
single graph and your initial

00:02:31,370 --> 00:02:37,610
inclination might be to just take the

00:02:34,130 --> 00:02:40,460
types of your schema and use those as

00:02:37,610 --> 00:02:44,720
your module boundaries and this seems

00:02:40,460 --> 00:02:46,160
very natural so this is part of part of

00:02:44,720 --> 00:02:49,790
that ecommerce schema that that query

00:02:46,160 --> 00:02:51,910
run against we have a type user we have

00:02:49,790 --> 00:02:55,510
a type product we have a type review

00:02:51,910 --> 00:02:59,750
these can live in separate files

00:02:55,510 --> 00:03:01,840
seems to make a lot of sense there are

00:02:59,750 --> 00:03:06,110
some serious problems with this however

00:03:01,840 --> 00:03:08,960
if you look at these types if you look

00:03:06,110 --> 00:03:13,790
at the fields in these types they mix

00:03:08,960 --> 00:03:16,100
concerns so type user for instance has a

00:03:13,790 --> 00:03:17,540
name that seems to make sense a user

00:03:16,100 --> 00:03:21,200
name is something that's really

00:03:17,540 --> 00:03:23,240
fundamental to to the base user type but

00:03:21,200 --> 00:03:26,480
we also see a field reviews and a field

00:03:23,240 --> 00:03:29,180
recent purchases these are not actually

00:03:26,480 --> 00:03:32,660
concerns of the user type itself they

00:03:29,180 --> 00:03:34,250
are not concerns of your accounts

00:03:32,660 --> 00:03:35,720
back-end for instance that might be

00:03:34,250 --> 00:03:42,460
underlying the implementation of this

00:03:35,720 --> 00:03:44,930
type similarly your type product may

00:03:42,460 --> 00:03:47,840
represent information living in your

00:03:44,930 --> 00:03:51,440
product database or a back-end system

00:03:47,840 --> 00:03:53,270
managing the product in your store it

00:03:51,440 --> 00:03:55,490
makes sense for that information to

00:03:53,270 --> 00:03:57,280
include the name and the price but

00:03:55,490 --> 00:04:00,920
reviews seems like something that

00:03:57,280 --> 00:04:04,640
doesn't really belong there

00:04:00,920 --> 00:04:07,370
and one way of looking at this is in

00:04:04,640 --> 00:04:11,000
terms of feature development so as teams

00:04:07,370 --> 00:04:13,160
start developing individual features on

00:04:11,000 --> 00:04:15,500
top of this one graph extending the

00:04:13,160 --> 00:04:18,040
graph in the process there's often a

00:04:15,500 --> 00:04:20,270
need to touch multiple types and

00:04:18,040 --> 00:04:22,970
fortunately graph QL has a great

00:04:20,270 --> 00:04:24,050
built-in mechanism for this and some of

00:04:22,970 --> 00:04:25,849
you may be familiar

00:04:24,050 --> 00:04:29,270
with this especially if you've seen

00:04:25,849 --> 00:04:31,729
Peggy's talk from yesterday on client

00:04:29,270 --> 00:04:34,370
side state graph Gale has this notion of

00:04:31,729 --> 00:04:37,460
type extension and that allows you to

00:04:34,370 --> 00:04:39,470
move these concerns to their proper

00:04:37,460 --> 00:04:41,750
place so instead of breaking up your

00:04:39,470 --> 00:04:45,409
schema by types you can now break up

00:04:41,750 --> 00:04:47,830
your schema by concerns your user type

00:04:45,409 --> 00:04:51,409
now just represents your account system

00:04:47,830 --> 00:04:54,139
your product type is part of your

00:04:51,409 --> 00:04:56,840
product system but the extension on type

00:04:54,139 --> 00:04:58,940
user a way of navigating from a user to

00:04:56,840 --> 00:05:02,240
your recent purchases is just as much

00:04:58,940 --> 00:05:05,500
part of the product module of your of

00:05:02,240 --> 00:05:10,330
your schema as the product type itself

00:05:05,500 --> 00:05:14,900
and their reviews module is now a

00:05:10,330 --> 00:05:16,370
self-contained module that contains all

00:05:14,900 --> 00:05:18,680
the type information that needed to

00:05:16,370 --> 00:05:20,419
implement this reviews feature so you

00:05:18,680 --> 00:05:22,639
can have a separate team working on

00:05:20,419 --> 00:05:24,830
implementing reviews of course they need

00:05:22,639 --> 00:05:26,990
a review type but they also need

00:05:24,830 --> 00:05:29,210
extensions to other types they need

00:05:26,990 --> 00:05:31,550
fields that allow client developers to

00:05:29,210 --> 00:05:37,219
navigate to these reviews for instance

00:05:31,550 --> 00:05:41,690
from users and and end products so

00:05:37,219 --> 00:05:45,969
really the main message here is that you

00:05:41,690 --> 00:05:49,430
want to break up your schema not by type

00:05:45,969 --> 00:05:51,349
because that really mixes concerns and

00:05:49,430 --> 00:05:56,110
it makes it hard to read the benefits of

00:05:51,349 --> 00:05:58,909
modular development if you really want

00:05:56,110 --> 00:06:00,860
individual teams to work productively

00:05:58,909 --> 00:06:07,250
together you want to make sure that the

00:06:00,860 --> 00:06:10,039
module boundaries make sense and I'm I'm

00:06:07,250 --> 00:06:15,800
happy to announce that schema modularity

00:06:10,039 --> 00:06:19,419
is now part of Apollo server 2.2 and let

00:06:15,800 --> 00:06:19,419
me show you what that means

00:06:23,909 --> 00:06:30,729
if you're familiar with the current

00:06:26,439 --> 00:06:32,949
Apollo server 2 API you'll know that you

00:06:30,729 --> 00:06:37,840
construct an Apollo server by passing in

00:06:32,949 --> 00:06:39,550
type definitions and resolvers what this

00:06:37,840 --> 00:06:43,330
allows you to do is instead of passing

00:06:39,550 --> 00:06:45,849
in a list of type definitions and a list

00:06:43,330 --> 00:06:49,900
of resolvers you can pass in a list of

00:06:45,849 --> 00:06:51,939
modules and these modules are ordinary

00:06:49,900 --> 00:06:53,860
JavaScript modules they can live within

00:06:51,939 --> 00:06:55,569
the same repository they can come from

00:06:53,860 --> 00:06:58,900
an NPM package that you install in your

00:06:55,569 --> 00:07:03,819
project and the basic structure should

00:06:58,900 --> 00:07:05,289
look very familiar to anyone who has who

00:07:03,819 --> 00:07:07,900
has attempted to break up their schema

00:07:05,289 --> 00:07:10,060
into modules it's a JavaScript module

00:07:07,900 --> 00:07:14,590
that exports type definitions and

00:07:10,060 --> 00:07:21,460
resolvers looking at the type definition

00:07:14,590 --> 00:07:25,029
of course there's the review type this

00:07:21,460 --> 00:07:28,060
is the module for the reviews feature so

00:07:25,029 --> 00:07:30,940
there's a review type note that we're

00:07:28,060 --> 00:07:33,940
also extending type query the query

00:07:30,940 --> 00:07:37,990
route a way of getting with a way of

00:07:33,940 --> 00:07:40,839
getting to the top reviews and we're

00:07:37,990 --> 00:07:44,229
extending type user and type product

00:07:40,839 --> 00:07:46,960
here to give you those relationships

00:07:44,229 --> 00:07:49,449
that that you can navigate to get from a

00:07:46,960 --> 00:07:59,969
user or product to a review or a list of

00:07:49,449 --> 00:08:03,159
reviews the implementation here may

00:07:59,969 --> 00:08:06,669
require a little bit of attention one

00:08:03,159 --> 00:08:08,080
interesting feature of the schema

00:08:06,669 --> 00:08:11,199
modularity implementation in Apollo

00:08:08,080 --> 00:08:13,389
server to point to is that schema

00:08:11,199 --> 00:08:16,240
modularity is not just about breaking up

00:08:13,389 --> 00:08:19,870
your type definitions there are a few

00:08:16,240 --> 00:08:22,870
gotchas with input with composing type

00:08:19,870 --> 00:08:25,360
definitions and some of those we've we

00:08:22,870 --> 00:08:28,180
take care of care for you in Apollo

00:08:25,360 --> 00:08:30,009
server 2.2 but the larger question for

00:08:28,180 --> 00:08:33,880
many people is how do you actually break

00:08:30,009 --> 00:08:35,099
up your resolvers because if you think

00:08:33,880 --> 00:08:40,019
about it

00:08:35,099 --> 00:08:41,909
a resolver in graph QL a resolver that

00:08:40,019 --> 00:08:47,519
returns an object or a list of objects

00:08:41,909 --> 00:08:49,380
is it's mostly expected to return a more

00:08:47,519 --> 00:08:53,190
or less complete representation of the

00:08:49,380 --> 00:08:55,440
object because after you return from a

00:08:53,190 --> 00:08:58,380
resolver that represents a relationship

00:08:55,440 --> 00:09:01,560
so for instance here the author field or

00:08:58,380 --> 00:09:04,470
the product field after that the next

00:09:01,560 --> 00:09:07,529
stage in execution for graphic QL are

00:09:04,470 --> 00:09:10,550
the field resolvers so after you return

00:09:07,529 --> 00:09:13,199
an author or a product graph QL

00:09:10,550 --> 00:09:15,870
execution would call the resolvers for

00:09:13,199 --> 00:09:19,139
the name and the price of your of your

00:09:15,870 --> 00:09:23,819
product for instance the problem with

00:09:19,139 --> 00:09:26,970
that is that it forces these author and

00:09:23,819 --> 00:09:31,199
product resolvers to fetch the data for

00:09:26,970 --> 00:09:33,899
for those objects and if you do that you

00:09:31,199 --> 00:09:36,959
break modularity you're forced to do the

00:09:33,899 --> 00:09:40,439
pass around data loaders or data

00:09:36,959 --> 00:09:44,009
fetchers some way of going from your

00:09:40,439 --> 00:09:46,199
review module into for instance your

00:09:44,009 --> 00:09:47,699
product database or your product

00:09:46,199 --> 00:09:51,930
back-end service to fetch the data you

00:09:47,699 --> 00:09:55,019
need instead what we've added in the

00:09:51,930 --> 00:09:57,839
paulo server 2.2 is a way of returning a

00:09:55,019 --> 00:09:59,790
partial representation of an object in

00:09:57,839 --> 00:10:05,120
many cases the representation you return

00:09:59,790 --> 00:10:09,089
is it's just the primary key or other

00:10:05,120 --> 00:10:11,910
identifying information that the module

00:10:09,089 --> 00:10:13,860
that owns the type can use to fetch the

00:10:11,910 --> 00:10:17,339
data needed for that type so in this

00:10:13,860 --> 00:10:20,519
case we're not returning a full author a

00:10:17,339 --> 00:10:23,430
full user object but we're returning an

00:10:20,519 --> 00:10:27,360
object with just an ID and then in the

00:10:23,430 --> 00:10:31,079
accounts module we now have an extra

00:10:27,360 --> 00:10:34,529
hook on every object type resolved

00:10:31,079 --> 00:10:37,170
object an object resolver is similar to

00:10:34,529 --> 00:10:39,120
a field resolver but where field

00:10:37,170 --> 00:10:41,370
resolvers are responsible for fetching

00:10:39,120 --> 00:10:44,010
data for an individual field object

00:10:41,370 --> 00:10:46,170
resolvers run before the field resolvers

00:10:44,010 --> 00:10:47,820
for an object run so they gave you an

00:10:46,170 --> 00:10:49,910
opportunity to

00:10:47,820 --> 00:10:53,730
centralized data fetching for an object

00:10:49,910 --> 00:10:57,800
and this is very useful in general but

00:10:53,730 --> 00:10:57,800
it's extremely important for modularity

00:11:00,260 --> 00:11:03,440
all right

00:11:04,350 --> 00:11:09,660
so that's that's the first part and I

00:11:07,470 --> 00:11:12,450
mean this is something that I imagine

00:11:09,660 --> 00:11:16,470
will be very useful to people it'll

00:11:12,450 --> 00:11:19,560
really help sort of grow modularity

00:11:16,470 --> 00:11:23,300
modular construction of graphical

00:11:19,560 --> 00:11:27,030
servers but once you start breaking

00:11:23,300 --> 00:11:30,690
breaking up your schema into modules you

00:11:27,030 --> 00:11:33,870
quickly land on a need to not just run

00:11:30,690 --> 00:11:35,790
individual code modules and compose

00:11:33,870 --> 00:11:38,820
those together into a single Apollo

00:11:35,790 --> 00:11:43,170
server but I need to actually run those

00:11:38,820 --> 00:11:46,320
modules as separate services separates

00:11:43,170 --> 00:11:49,260
micro-services and all the reasons for

00:11:46,320 --> 00:11:51,420
using micro services also apply to grab

00:11:49,260 --> 00:11:53,750
your micro services so independent

00:11:51,420 --> 00:11:59,010
development independent deployment

00:11:53,750 --> 00:12:01,380
separation of failure conditions so how

00:11:59,010 --> 00:12:06,390
do you actually go from modules to micro

00:12:01,380 --> 00:12:09,210
services well you need a gateway you

00:12:06,390 --> 00:12:10,950
don't want your clients to have to talk

00:12:09,210 --> 00:12:12,450
to these individual micro services that

00:12:10,950 --> 00:12:14,940
gets you into the situation I described

00:12:12,450 --> 00:12:16,440
at the beginning where you have 30 teams

00:12:14,940 --> 00:12:18,180
in your organization and they all come

00:12:16,440 --> 00:12:19,950
up with their own graph to our API with

00:12:18,180 --> 00:12:23,070
overlapping concerns and you have to

00:12:19,950 --> 00:12:25,740
manually navigate between them what you

00:12:23,070 --> 00:12:28,530
want is from the perspective of a client

00:12:25,740 --> 00:12:30,570
there should still be one graph you want

00:12:28,530 --> 00:12:32,370
all the benefits of that one graph you

00:12:30,570 --> 00:12:35,040
want to be able to run the exact same

00:12:32,370 --> 00:12:39,390
queries you run against a single Apollo

00:12:35,040 --> 00:12:41,940
of server but you want to ask queries to

00:12:39,390 --> 00:12:43,560
be automatically broken up into sub

00:12:41,940 --> 00:12:47,400
queries that get executed against your

00:12:43,560 --> 00:12:50,340
micro services and this is something

00:12:47,400 --> 00:12:53,940
that especially over the last year a lot

00:12:50,340 --> 00:12:56,580
of people have started doing I imagine

00:12:53,940 --> 00:12:58,200
some of you may be familiar with schema

00:12:56,580 --> 00:13:01,850
stitching and the implementation of that

00:12:58,200 --> 00:13:01,850
in graphical tools

00:13:02,170 --> 00:13:08,930
that has generated an enormous amount of

00:13:05,829 --> 00:13:11,600
interest and enthusiasm a lot of people

00:13:08,930 --> 00:13:14,470
have actually adopted this they've

00:13:11,600 --> 00:13:18,649
started implementing gateways using it

00:13:14,470 --> 00:13:20,690
but in talking to two people who've done

00:13:18,649 --> 00:13:23,779
this it becomes clear that there are a

00:13:20,690 --> 00:13:28,220
number of issues that are very common

00:13:23,779 --> 00:13:29,600
between these implementations so how do

00:13:28,220 --> 00:13:33,050
you how do you how in this approach

00:13:29,600 --> 00:13:35,110
would you actually break up your your

00:13:33,050 --> 00:13:37,370
schema into these micro services well

00:13:35,110 --> 00:13:39,800
this is what we started out with this

00:13:37,370 --> 00:13:42,829
was sort of our ideal module for the

00:13:39,800 --> 00:13:45,769
reviews feature so we have a review type

00:13:42,829 --> 00:13:47,290
we have our type extensions how do you

00:13:45,769 --> 00:13:51,829
make this into a micro service

00:13:47,290 --> 00:13:54,290
well what tends to happen is there's a

00:13:51,829 --> 00:13:58,160
need to split this up into two levels

00:13:54,290 --> 00:14:01,720
the underlying microserver the reviews

00:13:58,160 --> 00:14:06,050
micro service has the base type review

00:14:01,720 --> 00:14:08,449
and the fields that it owns the fields

00:14:06,050 --> 00:14:11,000
that it knows how to fetch data for like

00:14:08,449 --> 00:14:14,170
body in this case but there are other

00:14:11,000 --> 00:14:17,360
fields which represent relationships or

00:14:14,170 --> 00:14:23,899
more generally data that lives in other

00:14:17,360 --> 00:14:25,399
parts of your graph and in these

00:14:23,899 --> 00:14:27,769
existing schema switching approaches

00:14:25,399 --> 00:14:31,100
you're sort of forced to build out your

00:14:27,769 --> 00:14:33,019
micro service schema in a unnatural way

00:14:31,100 --> 00:14:35,690
from a graphical perspective you're no

00:14:33,019 --> 00:14:38,120
longer really describing a graph what

00:14:35,690 --> 00:14:40,850
you're doing here is describing a

00:14:38,120 --> 00:14:43,819
database model you're exposing foreign

00:14:40,850 --> 00:14:47,170
keys so instead of a relationship from a

00:14:43,819 --> 00:14:49,040
review to an author I'm exposing an ID

00:14:47,170 --> 00:14:51,980
similar for product

00:14:49,040 --> 00:14:56,060
I also need entry points at the root

00:14:51,980 --> 00:14:59,000
level so instead of navigating from a

00:14:56,060 --> 00:15:02,000
user to reviews

00:14:59,000 --> 00:15:04,040
I now need a reviews for a user root

00:15:02,000 --> 00:15:08,230
field and a reviews for a product root

00:15:04,040 --> 00:15:08,230
field which takes an ID

00:15:08,910 --> 00:15:16,860
so that's obviously not the schema you

00:15:13,530 --> 00:15:19,020
want to expose to your clients so you're

00:15:16,860 --> 00:15:21,420
forced to build an additional linking

00:15:19,020 --> 00:15:23,730
layer on top of this and that is code

00:15:21,420 --> 00:15:29,400
that doesn't live in your micro service

00:15:23,730 --> 00:15:31,710
but in your gateway it's code that you

00:15:29,400 --> 00:15:34,500
have to write so the the team

00:15:31,710 --> 00:15:36,390
responsible for the reviews feature now

00:15:34,500 --> 00:15:38,400
is responsible not just for writing code

00:15:36,390 --> 00:15:39,960
that lives in their micro service but

00:15:38,400 --> 00:15:42,330
they also have to write the linking code

00:15:39,960 --> 00:15:45,090
that lives at the gateway level so the

00:15:42,330 --> 00:15:48,690
gateway level becomes a shared resource

00:15:45,090 --> 00:15:54,900
or a development bottleneck for your

00:15:48,690 --> 00:15:58,470
entire organization that code in many

00:15:54,900 --> 00:16:01,890
cases also isn't trivial so even even

00:15:58,470 --> 00:16:04,340
the most simple implementation of schema

00:16:01,890 --> 00:16:07,710
delegation contains quite a bit of code

00:16:04,340 --> 00:16:10,260
and this is called you have to write yet

00:16:07,710 --> 00:16:12,270
you have to write in many cases it's

00:16:10,260 --> 00:16:15,450
it's actually more or less write only

00:16:12,270 --> 00:16:16,770
code it becomes code that people really

00:16:15,450 --> 00:16:19,110
don't want to touch as long as it's

00:16:16,770 --> 00:16:21,120
working but if things break down that

00:16:19,110 --> 00:16:27,360
also means no one really knows how to

00:16:21,120 --> 00:16:30,600
fix it so manually writing code to link

00:16:27,360 --> 00:16:33,570
together your scheme ass is dangerous

00:16:30,600 --> 00:16:38,190
it's dangerous from a development

00:16:33,570 --> 00:16:41,520
perspective because it it means the

00:16:38,190 --> 00:16:43,140
benefits of modular development you lose

00:16:41,520 --> 00:16:45,720
the benefits of modular development at

00:16:43,140 --> 00:16:47,430
the gateway level but but it also has

00:16:45,720 --> 00:16:49,260
risks for deployment because this is

00:16:47,430 --> 00:16:52,650
user code that's running inside your

00:16:49,260 --> 00:16:54,450
gateway and this is this is like your

00:16:52,650 --> 00:16:57,150
single entry point to your data graph

00:16:54,450 --> 00:16:59,460
for your entire organization if one of

00:16:57,150 --> 00:17:01,230
your micro services or one of the teams

00:16:59,460 --> 00:17:03,420
developing one of those micro services

00:17:01,230 --> 00:17:05,280
pushes linking code to the gateway that

00:17:03,420 --> 00:17:11,400
is faulty that somehow brings down that

00:17:05,280 --> 00:17:14,640
gateway you have a huge problem so there

00:17:11,400 --> 00:17:17,010
are two takeaways here one is you really

00:17:14,640 --> 00:17:20,040
want to design your micro services not

00:17:17,010 --> 00:17:21,299
as sort of these isolated sub schemas

00:17:20,040 --> 00:17:25,889
with foreign keys

00:17:21,299 --> 00:17:30,529
and root fields that are more like

00:17:25,889 --> 00:17:35,759
database queries than graph navigation

00:17:30,529 --> 00:17:38,159
and you also don't want to write user

00:17:35,759 --> 00:17:40,320
code you don't want to write it because

00:17:38,159 --> 00:17:42,480
it's actual work to write it but you

00:17:40,320 --> 00:17:43,739
also don't want to write it because you

00:17:42,480 --> 00:17:48,090
don't want user code running in your

00:17:43,739 --> 00:17:50,700
gateway so schema composition both for

00:17:48,090 --> 00:17:52,769
the local case and for the gateway case

00:17:50,700 --> 00:18:00,619
should be driven by configuration not

00:17:52,769 --> 00:18:03,570
user code and what should that look like

00:18:00,619 --> 00:18:07,950
this is the local schema modularity

00:18:03,570 --> 00:18:11,549
model that we discussed before what if

00:18:07,950 --> 00:18:15,690
we just put this in a box and ran a

00:18:11,549 --> 00:18:18,210
gateway on top of it that to me seems to

00:18:15,690 --> 00:18:22,859
be the ideal situation so that's what we

00:18:18,210 --> 00:18:25,679
did we build a palo gateway it's part of

00:18:22,859 --> 00:18:30,169
our commercial platform it runs on top

00:18:25,679 --> 00:18:33,779
of Apollo server and it allows you to

00:18:30,169 --> 00:18:36,379
declaratively compose these graphical

00:18:33,779 --> 00:18:40,769
micro services and then run queries

00:18:36,379 --> 00:18:43,159
against them so let me show you what

00:18:40,769 --> 00:18:43,159
that looks like

00:18:47,520 --> 00:18:51,400
remember before we we're we were

00:18:49,960 --> 00:18:54,880
constructing an Apollo server and

00:18:51,400 --> 00:18:58,270
passing in a list of modules now one of

00:18:54,880 --> 00:19:01,560
the ways you can do this is you can

00:18:58,270 --> 00:19:05,770
create an Apollo gateway and pass in a

00:19:01,560 --> 00:19:08,610
list of services and these services are

00:19:05,770 --> 00:19:11,860
combination of service definitions

00:19:08,610 --> 00:19:14,320
information about the schema and related

00:19:11,860 --> 00:19:26,770
information and a way to contact that

00:19:14,320 --> 00:19:28,600
service then observe that we actually

00:19:26,770 --> 00:19:31,270
have a number of craft fuel micro

00:19:28,600 --> 00:19:34,260
services running here so these are the

00:19:31,270 --> 00:19:37,000
exact same schema modules that we were

00:19:34,260 --> 00:19:39,630
composing in a single Apollo server

00:19:37,000 --> 00:19:42,280
before but now we're running them as

00:19:39,630 --> 00:19:46,350
individual micro services so we have

00:19:42,280 --> 00:19:51,420
accounts reviews product and inventory

00:19:46,350 --> 00:19:51,420
and I can run a gateway on top of it

00:19:58,820 --> 00:20:06,090
first of all that gives us an overall

00:20:03,840 --> 00:20:08,810
schema there is no additional work

00:20:06,090 --> 00:20:11,580
needed to link together these

00:20:08,810 --> 00:20:12,870
micro-services the schema is created

00:20:11,580 --> 00:20:16,950
completely from these service

00:20:12,870 --> 00:20:21,390
definitions which means that there's no

00:20:16,950 --> 00:20:26,940
sort of central linking layer every

00:20:21,390 --> 00:20:29,340
service is self descriptive and the

00:20:26,940 --> 00:20:32,760
overall gateway knows how to compose

00:20:29,340 --> 00:20:35,970
these services into this schema which

00:20:32,760 --> 00:20:38,970
looks exactly the same as a schema you

00:20:35,970 --> 00:20:41,490
would create yourself either as a

00:20:38,970 --> 00:20:43,470
monolithic schema or as a modular schema

00:20:41,490 --> 00:20:48,390
so the distributive case is exactly

00:20:43,470 --> 00:20:54,740
similar to the local case that also goes

00:20:48,390 --> 00:20:54,740
for the queries we can run it force so

00:20:55,070 --> 00:21:06,780
let's get the top reviews a little bit

00:21:00,690 --> 00:21:10,050
of fake body text of course that's not

00:21:06,780 --> 00:21:13,860
all we want to know we also want

00:21:10,050 --> 00:21:18,170
information about the author I happen to

00:21:13,860 --> 00:21:23,520
have written all of these reviews and

00:21:18,170 --> 00:21:31,500
then there's the product some products

00:21:23,520 --> 00:21:33,600
have a name they have a price there is a

00:21:31,500 --> 00:21:37,170
single product so note that this is an

00:21:33,600 --> 00:21:39,480
actual schema validation works I get all

00:21:37,170 --> 00:21:41,370
the tooling benefits that you've heard

00:21:39,480 --> 00:21:42,780
about at length during the rest of the

00:21:41,370 --> 00:21:48,710
conference including the vs code

00:21:42,780 --> 00:21:51,630
extension and then the last service we

00:21:48,710 --> 00:21:52,950
are going to stitch together is the

00:21:51,630 --> 00:21:55,350
inventory service because we want to

00:21:52,950 --> 00:21:58,800
know whether whether these products are

00:21:55,350 --> 00:22:04,170
actually in stock and then let me show

00:21:58,800 --> 00:22:07,560
you what's going on underneath so the

00:22:04,170 --> 00:22:09,690
gateway takes in a graphical query has

00:22:07,560 --> 00:22:11,639
this internal representation of

00:22:09,690 --> 00:22:14,220
the composed schema and all the service

00:22:11,639 --> 00:22:18,509
definitions and it generates a query

00:22:14,220 --> 00:22:20,940
plan and a query plan is generated in

00:22:18,509 --> 00:22:23,580
advance before execution which means it

00:22:20,940 --> 00:22:29,429
can be cash it can be reasoned about and

00:22:23,580 --> 00:22:30,870
it knows how to fetch how to break up

00:22:29,429 --> 00:22:33,539
your queries and how to fetch these

00:22:30,870 --> 00:22:38,450
individual pieces that make up the

00:22:33,539 --> 00:22:42,509
overall query results so in this case

00:22:38,450 --> 00:22:45,419
top reviews that's the first level we're

00:22:42,509 --> 00:22:48,539
going to the review service we're

00:22:45,419 --> 00:22:51,720
getting the body text for each top for

00:22:48,539 --> 00:22:54,659
each review and then authors and

00:22:51,720 --> 00:22:57,539
products are external objects they don't

00:22:54,659 --> 00:23:00,929
live inside the review service so

00:22:57,539 --> 00:23:08,029
instead we get a reference we then pass

00:23:00,929 --> 00:23:11,070
that reference for each author to the

00:23:08,029 --> 00:23:17,039
account service and that allows us to

00:23:11,070 --> 00:23:21,440
get the author name we also pass in the

00:23:17,039 --> 00:23:25,200
product reference in parallel may I note

00:23:21,440 --> 00:23:29,490
- the product service giving us the name

00:23:25,200 --> 00:23:31,320
the price and something interesting the

00:23:29,490 --> 00:23:34,559
product ID that we didn't actually ask

00:23:31,320 --> 00:23:37,019
for so what's the reason for including

00:23:34,559 --> 00:23:39,419
this in the sub query that we execute

00:23:37,019 --> 00:23:42,120
against a product service well we have

00:23:39,419 --> 00:23:44,190
one more query to make to the inventory

00:23:42,120 --> 00:23:45,779
service and in order to know whether a

00:23:44,190 --> 00:23:49,169
product is in stock we need the Product

00:23:45,779 --> 00:23:50,730
ID so the gateway knows that that's a

00:23:49,169 --> 00:23:53,580
field that needs to be added to the sub

00:23:50,730 --> 00:23:55,529
query but it's also smart enough to

00:23:53,580 --> 00:23:57,629
filter that out of the result because

00:23:55,529 --> 00:23:59,129
you didn't actually ask for it so

00:23:57,629 --> 00:24:01,460
including it would generate an invalid

00:23:59,129 --> 00:24:01,460
response

00:24:05,290 --> 00:24:11,860
so there are a lot of benefits to

00:24:08,130 --> 00:24:16,000
distributive execution one benefit that

00:24:11,860 --> 00:24:18,210
I want to highlight is reliability so we

00:24:16,000 --> 00:24:22,710
have four micro services running here

00:24:18,210 --> 00:24:24,700
they'll contain part of our data graph

00:24:22,710 --> 00:24:29,910
let's say one of them is down

00:24:24,700 --> 00:24:35,980
so let's kill the inventory service and

00:24:29,910 --> 00:24:39,700
let's re execute this query I get all my

00:24:35,980 --> 00:24:42,550
data the exact same data except for the

00:24:39,700 --> 00:24:44,770
inventory information and this is an

00:24:42,550 --> 00:24:47,350
important property of graph QL this is a

00:24:44,770 --> 00:24:49,390
design feature of crash QL graph geo has

00:24:47,350 --> 00:24:53,110
been explicitly designed to return

00:24:49,390 --> 00:24:54,880
partial results and a combination of

00:24:53,110 --> 00:24:57,670
data and errors that's one of the

00:24:54,880 --> 00:24:59,800
reasons fields by default are nullable

00:24:57,670 --> 00:25:04,090
you need to have a really good reason to

00:24:59,800 --> 00:25:07,000
make a field non null because the

00:25:04,090 --> 00:25:08,680
ability vert for fields to be null is

00:25:07,000 --> 00:25:11,800
extremely important for failure

00:25:08,680 --> 00:25:15,610
conditions so here if our UI has been

00:25:11,800 --> 00:25:17,380
designed to deal with the instruct field

00:25:15,610 --> 00:25:21,190
like the possibility of the instruct

00:25:17,380 --> 00:25:22,570
field being null which would would they

00:25:21,190 --> 00:25:25,690
would actually be forced to do if they

00:25:22,570 --> 00:25:29,500
used code gen which would generate

00:25:25,690 --> 00:25:32,560
nullable types for these fields they

00:25:29,500 --> 00:25:34,000
they could display a list of top reviews

00:25:32,560 --> 00:25:37,720
that is still pretty useful to most

00:25:34,000 --> 00:25:39,430
users and well I mean if I were user and

00:25:37,720 --> 00:25:42,550
I have to choose between not getting any

00:25:39,430 --> 00:25:47,350
data at all or missing one piece of data

00:25:42,550 --> 00:25:50,440
I know what I would choose something

00:25:47,350 --> 00:25:54,450
else to highlight that I think is

00:25:50,440 --> 00:25:58,410
interesting is because these

00:25:54,450 --> 00:26:01,420
microservices all represent a proper

00:25:58,410 --> 00:26:03,540
part of the graph unlike the situation

00:26:01,420 --> 00:26:07,090
where we had to expose foreign keys and

00:26:03,540 --> 00:26:10,540
road fields we can actually do pretty

00:26:07,090 --> 00:26:15,850
interesting things so for instance if we

00:26:10,540 --> 00:26:19,670
asked not just for the top reviews but

00:26:15,850 --> 00:26:24,900
also for other reviews

00:26:19,670 --> 00:26:29,430
from that same product that is listed as

00:26:24,900 --> 00:26:32,790
a top review well we get data but

00:26:29,430 --> 00:26:34,380
looking at the query plan what you see

00:26:32,790 --> 00:26:36,000
is that there's actually there's only a

00:26:34,380 --> 00:26:38,580
single query to the review service

00:26:36,000 --> 00:26:39,840
there's no need to go to the product

00:26:38,580 --> 00:26:42,360
service in this case because all

00:26:39,840 --> 00:26:44,250
information about that of which products

00:26:42,360 --> 00:26:48,180
relate to which reviews it's contained

00:26:44,250 --> 00:26:50,840
in the review service so this is another

00:26:48,180 --> 00:26:54,870
important part of a reliability story

00:26:50,840 --> 00:26:57,420
the the schema design actually makes it

00:26:54,870 --> 00:27:01,200
possible to to get this partial data

00:26:57,420 --> 00:27:06,510
even relational data in cases where one

00:27:01,200 --> 00:27:12,840
of the services is down for instance all

00:27:06,510 --> 00:27:16,380
right so that's Apple Gateway I'm yeah

00:27:12,840 --> 00:27:19,080
I'm really proud and excited that we're

00:27:16,380 --> 00:27:23,360
releasing this and happy to talk to

00:27:19,080 --> 00:27:27,540
anyone about it there's one more thing

00:27:23,360 --> 00:27:30,150
that I should mention Apple Gateway is

00:27:27,540 --> 00:27:33,270
not just a gateway on top of a palo

00:27:30,150 --> 00:27:34,590
server it's built on Apollo server so if

00:27:33,270 --> 00:27:36,540
you're running a palo gateway you're

00:27:34,590 --> 00:27:39,920
running a palo server you get all the

00:27:36,540 --> 00:27:42,450
benefits of the new request pipeline

00:27:39,920 --> 00:27:45,470
you'll be able to take advantage of

00:27:42,450 --> 00:27:48,690
features like caching you get tracing

00:27:45,470 --> 00:27:51,270
but that doesn't mean you are limited to

00:27:48,690 --> 00:27:55,170
running your Gateway on top of Apollo

00:27:51,270 --> 00:27:56,880
server so there are teams that have

00:27:55,170 --> 00:28:01,050
decided to build their graphical server

00:27:56,880 --> 00:28:04,080
on Python or Ruby or Java and those can

00:28:01,050 --> 00:28:06,780
all be perfectly reasonable choices you

00:28:04,080 --> 00:28:09,510
just want to make sure that those graph

00:28:06,780 --> 00:28:11,100
gel servers can still participate in

00:28:09,510 --> 00:28:17,190
that one graph that you're creating for

00:28:11,100 --> 00:28:21,960
your ole organization and I'm I don't

00:28:17,190 --> 00:28:25,320
actually have a Java server or a Python

00:28:21,960 --> 00:28:29,610
server or a ruby server running but one

00:28:25,320 --> 00:28:31,740
thing I happen to know is github

00:28:29,610 --> 00:28:35,340
actually runs a

00:28:31,740 --> 00:28:40,200
Rubi server so let me take out our

00:28:35,340 --> 00:28:42,630
account service and plug in the get up

00:28:40,200 --> 00:28:44,790
API and see what happens

00:28:42,630 --> 00:28:48,600
our gateway is reloading it's fetching

00:28:44,790 --> 00:29:01,040
an introspection results from github and

00:28:48,600 --> 00:29:01,040
now let me get some user information

00:29:01,550 --> 00:29:10,110
that still works conveniently because I

00:29:07,010 --> 00:29:15,270
happen to have the same ID on github as

00:29:10,110 --> 00:29:16,920
I have in this demo app but what what's

00:29:15,270 --> 00:29:21,059
amazing is that this actually brings in

00:29:16,920 --> 00:29:28,950
a complete github user object so I can I

00:29:21,059 --> 00:29:31,350
now have let me reload my schema and now

00:29:28,950 --> 00:29:33,510
I have the ability to for instance get

00:29:31,350 --> 00:29:35,580
the company field that isn't part of the

00:29:33,510 --> 00:29:37,710
account service that I built that that

00:29:35,580 --> 00:29:40,410
is the first part of the github user

00:29:37,710 --> 00:29:42,500
object so this is not to say that

00:29:40,410 --> 00:29:45,179
everyone should be for the stitching in

00:29:42,500 --> 00:29:48,179
github user objects as their main event

00:29:45,179 --> 00:29:50,790
ocation method in their graph but it's a

00:29:48,179 --> 00:29:54,929
nice illustration of without any work on

00:29:50,790 --> 00:29:58,070
the part of github we can actually make

00:29:54,929 --> 00:30:00,870
our gateway run on top of their server

00:29:58,070 --> 00:30:02,700
based on a standard graph GL

00:30:00,870 --> 00:30:05,700
introspection query no further

00:30:02,700 --> 00:30:08,460
configuration data the one thing for

00:30:05,700 --> 00:30:10,230
those of you who are curious we are

00:30:08,460 --> 00:30:14,640
using the node interface here as sort of

00:30:10,230 --> 00:30:16,320
a common mechanism across across server

00:30:14,640 --> 00:30:19,710
implementations that we can utilize to

00:30:16,320 --> 00:30:26,370
to automatically get an entry point into

00:30:19,710 --> 00:30:30,470
into these servers so that's Apple

00:30:26,370 --> 00:30:32,970
Gateway it gives you the ability to

00:30:30,470 --> 00:30:35,520
expose a single graph to your

00:30:32,970 --> 00:30:40,470
organization but it's built on top of

00:30:35,520 --> 00:30:43,080
this distributive execution layer so it

00:30:40,470 --> 00:30:45,510
composes your the schemas of your micro

00:30:43,080 --> 00:30:47,030
services it generate

00:30:45,510 --> 00:30:51,960
career plans that execute queries

00:30:47,030 --> 00:30:53,400
against those services and everything

00:30:51,960 --> 00:30:55,559
else you've heard here in this

00:30:53,400 --> 00:31:00,059
conference about the amazing work flow

00:30:55,559 --> 00:31:04,370
that Bradshaw enables schema validation

00:31:00,059 --> 00:31:07,500
the schema registry the ability for

00:31:04,370 --> 00:31:10,950
clients to validate their operations

00:31:07,500 --> 00:31:14,520
against a schema that all works on top

00:31:10,950 --> 00:31:17,429
of the Gateway schema one interesting

00:31:14,520 --> 00:31:19,740
use case there is the development of the

00:31:17,429 --> 00:31:23,130
micro services themselves so as you're

00:31:19,740 --> 00:31:25,799
developing your micro services because

00:31:23,130 --> 00:31:27,750
they are meant to be composed together

00:31:25,799 --> 00:31:28,890
with other micro services you want to

00:31:27,750 --> 00:31:30,450
make sure that there are no conflicts

00:31:28,890 --> 00:31:33,960
that you're actually always developing

00:31:30,450 --> 00:31:35,790
against the recent versions of all the

00:31:33,960 --> 00:31:40,049
other micro services keeping the overall

00:31:35,790 --> 00:31:43,980
schema in mind so one way of doing this

00:31:40,049 --> 00:31:49,850
is to actually as part of your CI CD

00:31:43,980 --> 00:31:52,760
workflow always build an overall schema

00:31:49,850 --> 00:31:56,220
from your current development version of

00:31:52,760 --> 00:31:57,929
the micro service you're working on plus

00:31:56,220 --> 00:32:00,419
all the other services that make up your

00:31:57,929 --> 00:32:02,910
schema create one overall schema and

00:32:00,419 --> 00:32:04,350
apply all the same mechanisms that you

00:32:02,910 --> 00:32:06,690
can apply when you have a single server

00:32:04,350 --> 00:32:08,010
running against those so so delegating

00:32:06,690 --> 00:32:09,990
things against real production traffic

00:32:08,010 --> 00:32:15,960
for instance to see what is actually

00:32:09,990 --> 00:32:18,380
breaking I yeah I'm really happy to have

00:32:15,960 --> 00:32:21,390
been able to share this with you and I

00:32:18,380 --> 00:32:23,010
am looking forward to some stimulating

00:32:21,390 --> 00:32:26,780
conversations and a happy to to answer

00:32:23,010 --> 00:32:26,780
any questions you you might have

00:32:29,929 --> 00:32:31,990

YouTube URL: https://www.youtube.com/watch?v=OFT9bSv3aYA


