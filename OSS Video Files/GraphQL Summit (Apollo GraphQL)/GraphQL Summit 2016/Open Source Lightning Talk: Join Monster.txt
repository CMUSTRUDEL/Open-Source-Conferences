Title: Open Source Lightning Talk: Join Monster
Publication date: 2016-11-02
Playlist: GraphQL Summit 2016
Description: 
	Andrew Carlson, Stem.is

Join Monster is a JavaScript execution layer from GraphQL to SQL for batch data-fetching between the API and the database by dynamically translating GraphQL to SQL for efficient data retrieval, all in a single batch before resolution. Simply declare the data requirements of each field in you schema. Then, for each query, Join Monster will look at what was requested, find the data requirements, fetch, and shape your data.
https://github.com/stems/join-monster

Learn more about GraphQL Summit:
http://graphqlsummit.com

Join our GraphQL SF meetup to hear more about GraphQL best practices and implementations: 
http://meetup.com/GraphQL-SF/
Captions: 
	00:00:03,720 --> 00:00:09,599
hi everyone I'm I'm Andy I'm a software

00:00:07,350 --> 00:00:12,320
engineer on the contract API team at

00:00:09,599 --> 00:00:15,330
stem so stem is a platform that empowers

00:00:12,320 --> 00:00:18,630
music and video creators to distribute

00:00:15,330 --> 00:00:19,680
their content and and track their

00:00:18,630 --> 00:00:23,189
earnings so we want to make it really

00:00:19,680 --> 00:00:25,619
easy to release and get paid for your

00:00:23,189 --> 00:00:28,079
music and video but today I'm here to

00:00:25,619 --> 00:00:30,599
talk about why we chose graph QL for our

00:00:28,079 --> 00:00:32,669
API some problems that we had in using

00:00:30,599 --> 00:00:35,489
it with sequel and how we solve these

00:00:32,669 --> 00:00:37,910
problems with our with our open source

00:00:35,489 --> 00:00:44,310
and PM packaged joint monster

00:00:37,910 --> 00:00:45,870
so why graph QL well as you all know you

00:00:44,310 --> 00:00:48,980
don't want to deal with too many round

00:00:45,870 --> 00:00:50,910
trips between client and API and you

00:00:48,980 --> 00:00:52,760
don't want to get a bunch of data that

00:00:50,910 --> 00:00:54,450
you're not using from your restaurants

00:00:52,760 --> 00:00:57,000
your right you don't want to deal with

00:00:54,450 --> 00:00:59,940
over fetching and so you build a graph

00:00:57,000 --> 00:01:02,370
QL API and these problems are solved

00:00:59,940 --> 00:01:05,309
because one request gets you all the

00:01:02,370 --> 00:01:06,840
data for you view no more no less but

00:01:05,309 --> 00:01:09,180
that doesn't solve all your performance

00:01:06,840 --> 00:01:10,980
problems because you still have to make

00:01:09,180 --> 00:01:13,050
sure that graph QL executes sufficiently

00:01:10,980 --> 00:01:17,550
against your back-end and if you're

00:01:13,050 --> 00:01:19,020
using sequel like we are a naive

00:01:17,550 --> 00:01:22,229
application might end up doing too many

00:01:19,020 --> 00:01:23,030
sequel queries so let me illustrate this

00:01:22,229 --> 00:01:26,640
with an example

00:01:23,030 --> 00:01:29,130
we have this schema that has users with

00:01:26,640 --> 00:01:31,830
mini posts with many comments and say we

00:01:29,130 --> 00:01:35,540
want to get some data with a query like

00:01:31,830 --> 00:01:39,840
this so how might we resolve this query

00:01:35,540 --> 00:01:41,670
so we could get our post field so we

00:01:39,840 --> 00:01:45,420
could resolve that by doing one sequel

00:01:41,670 --> 00:01:48,659
query for all the posts and then each

00:01:45,420 --> 00:01:51,740
post could resolve its comments by doing

00:01:48,659 --> 00:01:51,740
one sequel query for all the comments

00:01:55,400 --> 00:02:02,670
times equal each that adds up to 31

00:02:00,119 --> 00:02:03,659
sequel queries all these user so it

00:02:02,670 --> 00:02:07,110
looks like we're running into a

00:02:03,659 --> 00:02:08,340
round-trip problem again so let's try a

00:02:07,110 --> 00:02:11,250
different approach let's try to do this

00:02:08,340 --> 00:02:14,040
all in one query so how do we typically

00:02:11,250 --> 00:02:17,340
get data from multiple tables in sequel

00:02:14,040 --> 00:02:17,700
well typically with a join so let's go

00:02:17,340 --> 00:02:20,940
up here

00:02:17,700 --> 00:02:21,599
to the users resolver and when we get

00:02:20,940 --> 00:02:23,370
the users

00:02:21,599 --> 00:02:26,400
let's join on the posts and on the

00:02:23,370 --> 00:02:29,069
comments so we send this query off to

00:02:26,400 --> 00:02:32,190
our database what we get is one big

00:02:29,069 --> 00:02:34,709
result set with all those data and let's

00:02:32,190 --> 00:02:37,319
assume that we can take that big flat

00:02:34,709 --> 00:02:39,959
array and nest it or hydrated that is

00:02:37,319 --> 00:02:43,140
convert it to the correct object shape

00:02:39,959 --> 00:02:47,340
that our graph QL schema is expecting so

00:02:43,140 --> 00:02:48,900
assuming we can do that well then the

00:02:47,340 --> 00:02:50,010
posts and the comments are already

00:02:48,900 --> 00:02:53,069
resolved right because the data is

00:02:50,010 --> 00:02:54,989
already there so okay it looks like we

00:02:53,069 --> 00:02:57,810
did it we solved the roundtrip problem

00:02:54,989 --> 00:03:00,810
which works great for queries like this

00:02:57,810 --> 00:03:03,299
one but what about this one they only

00:03:00,810 --> 00:03:05,730
want the users in the posts so why would

00:03:03,299 --> 00:03:08,579
we bother joining on the comments we're

00:03:05,730 --> 00:03:09,959
still what if they only want users so it

00:03:08,579 --> 00:03:13,860
looks like we're we're getting all these

00:03:09,959 --> 00:03:16,110
data and it's a waste because they just

00:03:13,860 --> 00:03:17,760
don't want that data so now we have an

00:03:16,110 --> 00:03:20,549
over fetch problem we have this

00:03:17,760 --> 00:03:23,690
one-size-fits-all sequel query that

00:03:20,549 --> 00:03:26,430
becomes wasteful for some graph queue up

00:03:23,690 --> 00:03:27,930
so this is why we built joint monster we

00:03:26,430 --> 00:03:29,910
wanted a way to do batch data fetching

00:03:27,930 --> 00:03:32,040
with sequel in a single round trip

00:03:29,910 --> 00:03:33,660
without resorting to over fetching so

00:03:32,040 --> 00:03:35,910
this is this is our solution to these

00:03:33,660 --> 00:03:38,100
problems so let me show you how this

00:03:35,910 --> 00:03:40,590
works so it's basically it's basically a

00:03:38,100 --> 00:03:43,290
a query planner where it looks at a

00:03:40,590 --> 00:03:45,480
graph QL query and automatically

00:03:43,290 --> 00:03:48,000
generates the sequel dynamically where

00:03:45,480 --> 00:03:50,250
it'll ask for the right columns and join

00:03:48,000 --> 00:03:53,609
on the right things and say I want posts

00:03:50,250 --> 00:03:55,470
and comments it joins on both but if I

00:03:53,609 --> 00:03:58,139
if I didn't want the comments will

00:03:55,470 --> 00:03:59,730
notice it won't join on the comments so

00:03:58,139 --> 00:04:02,730
in order to get a library to do this we

00:03:59,730 --> 00:04:04,799
need to make a few assumptions about how

00:04:02,730 --> 00:04:08,160
your data is modeled your sequel tables

00:04:04,799 --> 00:04:11,310
map to graph QL object types and that's

00:04:08,160 --> 00:04:13,049
done by decorating the type definition

00:04:11,310 --> 00:04:16,950
with some additional metadata like the

00:04:13,049 --> 00:04:20,070
table name and its unique key and then

00:04:16,950 --> 00:04:21,959
your fields depends on the columns so

00:04:20,070 --> 00:04:23,580
fields like these could depend on one

00:04:21,959 --> 00:04:25,919
sequel column or perhaps they could

00:04:23,580 --> 00:04:28,289
depend on multiple and resolve the value

00:04:25,919 --> 00:04:29,820
from those dependencies or you could

00:04:28,289 --> 00:04:31,710
have fields that don't depend on any and

00:04:29,820 --> 00:04:34,740
just get their data from

00:04:31,710 --> 00:04:38,370
we're sorta Joines come into this well

00:04:34,740 --> 00:04:40,560
say you have a field that is all itself

00:04:38,370 --> 00:04:43,080
another object type with another table

00:04:40,560 --> 00:04:45,450
this is assumed to come from from a

00:04:43,080 --> 00:04:47,700
joint so you can decorate that field

00:04:45,450 --> 00:04:50,490
with a function that generates your join

00:04:47,700 --> 00:04:53,100
condition and that's all you have to do

00:04:50,490 --> 00:04:54,720
to your schema now we're we can just

00:04:53,100 --> 00:04:57,060
import our function and we're back here

00:04:54,720 --> 00:04:59,190
at the users resolver so instead of

00:04:57,060 --> 00:05:02,760
doing one big query now we call join

00:04:59,190 --> 00:05:05,880
monster pass it the grab ql resolve info

00:05:02,760 --> 00:05:08,130
and it looks at the parsed query syntax

00:05:05,880 --> 00:05:10,530
tree and it looks at your decorated

00:05:08,130 --> 00:05:12,780
schema definition generates the sequel

00:05:10,530 --> 00:05:14,490
passes it to this callback which you

00:05:12,780 --> 00:05:18,960
write to query whatever database you're

00:05:14,490 --> 00:05:20,630
using and return the raw data and then

00:05:18,960 --> 00:05:23,670
once join Monster has your raw data it

00:05:20,630 --> 00:05:26,250
hydrates it or it shapes it into that of

00:05:23,670 --> 00:05:30,450
your schema so that after join monster

00:05:26,250 --> 00:05:31,800
returns all of the child resolvers they

00:05:30,450 --> 00:05:34,770
can find the data at you know the

00:05:31,800 --> 00:05:36,150
property names that it expects and after

00:05:34,770 --> 00:05:37,650
that point you don't need any sequel

00:05:36,150 --> 00:05:41,340
queries it's all resolved all the data

00:05:37,650 --> 00:05:43,890
is there so so what we've done is we've

00:05:41,340 --> 00:05:45,720
taken this picture and sort of reaped

00:05:43,890 --> 00:05:49,560
the benefits of this batch requesting

00:05:45,720 --> 00:05:51,990
all the way down to database layer some

00:05:49,560 --> 00:05:53,970
other features we have although we

00:05:51,990 --> 00:05:56,610
started to handle joint monster at the

00:05:53,970 --> 00:05:59,730
root of the schema you don't have to you

00:05:56,610 --> 00:06:02,660
can do it at any depth resolve any field

00:05:59,730 --> 00:06:04,920
as long as you decorate its object type

00:06:02,660 --> 00:06:06,600
we have functions to generate wear

00:06:04,920 --> 00:06:08,010
conditions we support many to many

00:06:06,600 --> 00:06:10,950
relations we have a couple different

00:06:08,010 --> 00:06:14,340
options for pagination and we work

00:06:10,950 --> 00:06:17,250
pretty well with graph QL relay so

00:06:14,340 --> 00:06:19,500
here's here's an example of handling the

00:06:17,250 --> 00:06:23,010
node interface and a relay connection

00:06:19,500 --> 00:06:25,430
and automatically paginating that in a

00:06:23,010 --> 00:06:25,430
sequel gray

00:06:33,100 --> 00:06:37,000
so some some benefits that we see here

00:06:34,960 --> 00:06:38,800
are the ability to get all your data in

00:06:37,000 --> 00:06:41,650
a single query without resorting to over

00:06:38,800 --> 00:06:43,060
fetching we think it's very maintainable

00:06:41,650 --> 00:06:45,040
because you're not manually writing

00:06:43,060 --> 00:06:46,390
queries that's one less thing that you

00:06:45,040 --> 00:06:49,180
have to change when your schema changes

00:06:46,390 --> 00:06:51,040
we say it's unobtrusive it does not take

00:06:49,180 --> 00:06:53,410
away your ability to define your schemas

00:06:51,040 --> 00:06:55,540
or the data types or the custom resolve

00:06:53,410 --> 00:06:58,390
functions those all coexist

00:06:55,540 --> 00:07:00,430
it's declarative you're simply defining

00:06:58,390 --> 00:07:04,330
the data requirements of your graph QL

00:07:00,430 --> 00:07:05,800
fields on your schema sequel columns and

00:07:04,330 --> 00:07:07,810
finally we say that graph QL sort of

00:07:05,800 --> 00:07:09,520
becomes your ORM so you don't even need

00:07:07,810 --> 00:07:11,500
to use one all you have to do is add

00:07:09,520 --> 00:07:13,510
some metadata to alongside your schema

00:07:11,500 --> 00:07:18,160
and it becomes not only a self

00:07:13,510 --> 00:07:20,140
documenting but also self mapping so as

00:07:18,160 --> 00:07:23,190
I mentioned we're open source check us

00:07:20,140 --> 00:07:25,120
out on github speed up or quest please

00:07:23,190 --> 00:07:27,070
you can learn more by checking out our

00:07:25,120 --> 00:07:28,420
documentation and you can find the live

00:07:27,070 --> 00:07:33,030
versions of the demos I showed you on

00:07:28,420 --> 00:07:33,030

YouTube URL: https://www.youtube.com/watch?v=Y7AdMIuXOgs


