Title: Configuration driven Data as a Service gateway with GraphQL (NORIAKI TATSUMI)
Publication date: 2019-11-02
Playlist: GraphQL Summit 2019
Description: 
	In this talk, youâ€™ll learn about techniques used to build a scalable GraphQL based data gateway with the capability to dynamically on-board various new data sources. They include runtime schema evolution and resolver wiring, abstract resolvers, auto GraphQL schema generation from other schema types, and construction of appropriate cache key-values.
Captions: 
	00:00:01,679 --> 00:00:08,170
thank you for that intro

00:00:04,390 --> 00:00:11,740
it's my mic okay so hi my name is nori

00:00:08,170 --> 00:00:14,349
and I work for Capital One and I work

00:00:11,740 --> 00:00:17,320
for the card machine learning team at

00:00:14,349 --> 00:00:19,240
Capital One one of the things that I

00:00:17,320 --> 00:00:21,370
like to brag about is that I can ride a

00:00:19,240 --> 00:00:23,680
unicycle and I thought about entering

00:00:21,370 --> 00:00:24,760
the room with my unicycle but that would

00:00:23,680 --> 00:00:30,580
have been a terrible idea

00:00:24,760 --> 00:00:32,110
so I decided not to so I what I do at

00:00:30,580 --> 00:00:35,739
Capital One in this machine learning

00:00:32,110 --> 00:00:38,079
team is I lead a team that's building

00:00:35,739 --> 00:00:40,120
the platform capabilities to further

00:00:38,079 --> 00:00:42,820
advance a machine learning agenda a

00:00:40,120 --> 00:00:45,730
Capital One we use machine learning for

00:00:42,820 --> 00:00:48,219
many different use cases including

00:00:45,730 --> 00:00:51,579
fighting the the fraudsters to catch

00:00:48,219 --> 00:00:56,440
them as well as increasing customer

00:00:51,579 --> 00:00:58,899
experience as well so today as was as I

00:00:56,440 --> 00:01:01,870
was introduced I'll be talking about how

00:00:58,899 --> 00:01:05,290
to build a graph queue based data

00:01:01,870 --> 00:01:07,960
gateway that enables you to onboard new

00:01:05,290 --> 00:01:13,479
back-end data sources without making any

00:01:07,960 --> 00:01:15,640
code changes but before we dive into

00:01:13,479 --> 00:01:17,710
that you might be thinking what does

00:01:15,640 --> 00:01:20,380
graph queue all have to do with machine

00:01:17,710 --> 00:01:23,020
learning right the fact of the matter is

00:01:20,380 --> 00:01:27,340
machine learning is learning from data

00:01:23,020 --> 00:01:29,969
and no fancy algorithm or you know math

00:01:27,340 --> 00:01:34,539
formula can replace lack of good data

00:01:29,969 --> 00:01:36,789
so essentially majority of work that we

00:01:34,539 --> 00:01:41,710
do in machine learning is working with

00:01:36,789 --> 00:01:44,409
data to prepare quality data to MPD the

00:01:41,710 --> 00:01:46,630
machine learning training exercises as

00:01:44,409 --> 00:01:51,700
well as the execution of the models in

00:01:46,630 --> 00:01:53,950
production so after conducting much

00:01:51,700 --> 00:01:55,750
research on the pain points that our

00:01:53,950 --> 00:01:58,570
machine learning engineers as well as

00:01:55,750 --> 00:02:02,170
our data scientists are experiencing in

00:01:58,570 --> 00:02:06,399
terms of finding the machine learning

00:02:02,170 --> 00:02:08,580
data inputs what we did was to decide to

00:02:06,399 --> 00:02:12,129
build this thing called the data gateway

00:02:08,580 --> 00:02:14,330
so this data gateway is not just a

00:02:12,129 --> 00:02:17,270
simple reverse proxy

00:02:14,330 --> 00:02:22,670
we want it to be a really smart endpoint

00:02:17,270 --> 00:02:26,920
that unifies the retrieval of all the

00:02:22,670 --> 00:02:30,200
machine learning inputs and it provides

00:02:26,920 --> 00:02:34,370
everything from being able to discover

00:02:30,200 --> 00:02:38,780
data to share the data that other team

00:02:34,370 --> 00:02:41,030
might have worked on and derived and not

00:02:38,780 --> 00:02:44,030
just serve them but monitor them from

00:02:41,030 --> 00:02:49,970
both operational and features

00:02:44,030 --> 00:02:52,460
characteristic point of view and graph

00:02:49,970 --> 00:02:55,190
QL is something that we found that can

00:02:52,460 --> 00:02:57,860
really help us so one of the big

00:02:55,190 --> 00:03:00,350
challenges at Capital One is a that

00:02:57,860 --> 00:03:02,380
we're a really big company and there are

00:03:00,350 --> 00:03:06,500
a lot of data producers

00:03:02,380 --> 00:03:09,430
so all these federated teams that has

00:03:06,500 --> 00:03:12,560
domain knowledge about their data

00:03:09,430 --> 00:03:15,350
produces the data and hosts their data

00:03:12,560 --> 00:03:17,480
in many different types of backends and

00:03:15,350 --> 00:03:21,920
it could be database

00:03:17,480 --> 00:03:25,790
it could be micro services a bunch of

00:03:21,920 --> 00:03:28,280
variety of interfaces and what the graph

00:03:25,790 --> 00:03:32,150
key well you know does that's really

00:03:28,280 --> 00:03:35,840
well as you guys know is to stitch all

00:03:32,150 --> 00:03:38,990
those data into a single schema exposed

00:03:35,840 --> 00:03:41,090
to make that discoverable and helps you

00:03:38,990 --> 00:03:42,860
aggregate all that data from different

00:03:41,090 --> 00:03:45,290
types of backends so that data

00:03:42,860 --> 00:03:49,310
scientists machine learning engineers

00:03:45,290 --> 00:03:51,350
can really focus on working with machine

00:03:49,310 --> 00:03:57,200
learning as opposed to do in data

00:03:51,350 --> 00:03:59,870
engineering the second important design

00:03:57,200 --> 00:04:02,780
decision we made is that our data needs

00:03:59,870 --> 00:04:05,900
to be a catalog and have standardized

00:04:02,780 --> 00:04:10,100
interface at the end of the day it's

00:04:05,900 --> 00:04:12,470
garbage Inc or garbage out so we wanted

00:04:10,100 --> 00:04:15,590
to make sure that the data that gets

00:04:12,470 --> 00:04:19,130
hooked into a gateway it has all the

00:04:15,590 --> 00:04:21,980
qualities that we need so therefore what

00:04:19,130 --> 00:04:27,800
we did was to in order to make make the

00:04:21,980 --> 00:04:32,300
gateway just work as the standardized

00:04:27,800 --> 00:04:37,900
sourcetype we preferred something that

00:04:32,300 --> 00:04:41,060
has a strong type or schema and

00:04:37,900 --> 00:04:43,430
everything all the data that gets hooked

00:04:41,060 --> 00:04:46,030
up into the Gateway needs to be

00:04:43,430 --> 00:04:50,229
registered in our enterprise registry

00:04:46,030 --> 00:04:53,900
that includes not just the data on our

00:04:50,229 --> 00:04:58,539
on our data leak but also your micro

00:04:53,900 --> 00:04:58,539
services including your rest endpoint

00:05:01,210 --> 00:05:07,220
and finally the key thing that enables

00:05:04,669 --> 00:05:11,810
the scalability of specifically my team

00:05:07,220 --> 00:05:14,659
is to support this capability is to make

00:05:11,810 --> 00:05:17,720
everything configuration driven so every

00:05:14,659 --> 00:05:19,520
time a new data source appear we don't

00:05:17,720 --> 00:05:23,080
have to start with getting the

00:05:19,520 --> 00:05:26,419
specification of how that works and

00:05:23,080 --> 00:05:33,889
start coding away and pushing that

00:05:26,419 --> 00:05:37,130
changes to a production environment so

00:05:33,889 --> 00:05:39,199
let's dive into what implementing a

00:05:37,130 --> 00:05:41,180
graph queue endpoint looks like so this

00:05:39,199 --> 00:05:44,389
is a straight out of Apollo's

00:05:41,180 --> 00:05:48,250
documentation you start you know

00:05:44,389 --> 00:05:51,380
essentially what you see is a pretty

00:05:48,250 --> 00:05:56,300
simple schema here what you start with

00:05:51,380 --> 00:05:59,620
is designing a graph QL schema so you

00:05:56,300 --> 00:06:03,529
see that there's a type codebook with

00:05:59,620 --> 00:06:07,009
fields called title and author and a

00:06:03,529 --> 00:06:08,830
nested a type called author and what's

00:06:07,009 --> 00:06:13,099
happening on the right side is

00:06:08,830 --> 00:06:16,449
essentially wiring that schema type into

00:06:13,099 --> 00:06:19,039
the resolver implementation right and

00:06:16,449 --> 00:06:22,819
this is what what it looks like on a

00:06:19,039 --> 00:06:26,479
Java stack here's an example taken from

00:06:22,819 --> 00:06:29,240
a framework called Java kickstart for

00:06:26,479 --> 00:06:32,620
graph QL and it's essentially the same

00:06:29,240 --> 00:06:35,630
you start with building the schema and

00:06:32,620 --> 00:06:38,240
creating some simple project pocho that

00:06:35,630 --> 00:06:40,850
maps to your object-oriented

00:06:38,240 --> 00:06:43,970
implementation and then you wire them

00:06:40,850 --> 00:06:48,259
and you know with the resolver

00:06:43,970 --> 00:06:50,090
implementation so this looks really

00:06:48,259 --> 00:06:51,979
simple and these frameworks are great

00:06:50,090 --> 00:06:54,320
right but how do we make this

00:06:51,979 --> 00:07:00,080
implementation so that this is all

00:06:54,320 --> 00:07:03,410
configuration driven the secret sauce is

00:07:00,080 --> 00:07:06,169
that the schema first approach as you

00:07:03,410 --> 00:07:10,400
saw in the two frameworks that you know

00:07:06,169 --> 00:07:13,520
just now these frameworks guides you to

00:07:10,400 --> 00:07:16,160
build your schema first and then the

00:07:13,520 --> 00:07:19,610
implementation and what that allows us

00:07:16,160 --> 00:07:22,130
to do is create the separation and

00:07:19,610 --> 00:07:24,620
concerns in our components of the

00:07:22,130 --> 00:07:28,610
implementation into these four blocks

00:07:24,620 --> 00:07:30,650
essentially so there is a schema there's

00:07:28,610 --> 00:07:33,320
the the resolvers that helps you

00:07:30,650 --> 00:07:33,830
aggregate the data that the client is

00:07:33,320 --> 00:07:36,500
asking

00:07:33,830 --> 00:07:39,860
there's the models that maps to the the

00:07:36,500 --> 00:07:42,530
fields of the schema the for the object

00:07:39,860 --> 00:07:44,630
oriented model implementation and then

00:07:42,530 --> 00:07:48,199
there is essentially the the connectors

00:07:44,630 --> 00:07:50,930
that actually knows how to talk to the

00:07:48,199 --> 00:07:53,050
back-end data source and retrieve the

00:07:50,930 --> 00:07:53,050
data

00:07:55,610 --> 00:08:02,810
and essentially what we from there we

00:07:59,539 --> 00:08:05,479
can do is take that scheme apart and put

00:08:02,810 --> 00:08:10,430
it into something like of a relational

00:08:05,479 --> 00:08:14,090
database and why we can then there is to

00:08:10,430 --> 00:08:16,460
do is in our permit implementation we

00:08:14,090 --> 00:08:19,939
have this thing called a configuration

00:08:16,460 --> 00:08:22,819
service that is essentially the brain of

00:08:19,939 --> 00:08:27,199
a gateway and it talks to the registry

00:08:22,819 --> 00:08:29,840
service to understand what data sources

00:08:27,199 --> 00:08:32,479
are out there grabs its business

00:08:29,840 --> 00:08:35,839
metadata as well as technical data

00:08:32,479 --> 00:08:39,940
metadata along with the schema that is

00:08:35,839 --> 00:08:43,130
registered or in rest endpoints

00:08:39,940 --> 00:08:45,410
perspective the the definition of the

00:08:43,130 --> 00:08:50,450
what the rest endpoint looks like and

00:08:45,410 --> 00:08:53,720
then convert that to fragments of graph

00:08:50,450 --> 00:08:56,089
QL types and queries and they have the

00:08:53,720 --> 00:09:02,000
data gateway stitch them up on the

00:08:56,089 --> 00:09:06,170
server side so here's an example of

00:09:02,000 --> 00:09:08,480
park' data that is that could be

00:09:06,170 --> 00:09:11,029
on-boarded onto a gateway directly

00:09:08,480 --> 00:09:14,029
without building any sort of graph queue

00:09:11,029 --> 00:09:16,970
endpoint yourself so parkade data as you

00:09:14,029 --> 00:09:19,760
might know is a columnar data format it

00:09:16,970 --> 00:09:22,310
looks like a table and it's very popular

00:09:19,760 --> 00:09:24,890
amongst data scientists and data

00:09:22,310 --> 00:09:28,550
engineers especially in the world of big

00:09:24,890 --> 00:09:31,070
data space and in this case you know I'm

00:09:28,550 --> 00:09:34,399
naming the type using the the data

00:09:31,070 --> 00:09:38,089
source name and translating the park it

00:09:34,399 --> 00:09:39,890
feels as graph QL fields and populating

00:09:38,089 --> 00:09:44,540
the schema comments using the metadata

00:09:39,890 --> 00:09:48,410
in the configuration and on the right is

00:09:44,540 --> 00:09:51,070
the what what's the output of that the

00:09:48,410 --> 00:09:51,070
translation

00:09:52,290 --> 00:09:59,710
here's an example for rs10 point capital

00:09:56,050 --> 00:10:03,010
one we use open API spec as the

00:09:59,710 --> 00:10:06,880
enterprise standard to register all of

00:10:03,010 --> 00:10:09,940
our best end points so we can take this

00:10:06,880 --> 00:10:14,170
specification and essentially do the

00:10:09,940 --> 00:10:17,260
same thing we just did on the parquet so

00:10:14,170 --> 00:10:20,649
the output here is a type called web

00:10:17,260 --> 00:10:23,200
analytics with the fields also as well

00:10:20,649 --> 00:10:30,310
as the comments that has been derived

00:10:23,200 --> 00:10:32,620
from the rest documentation and you can

00:10:30,310 --> 00:10:38,100
do the same thing with the query as well

00:10:32,620 --> 00:10:43,420
so what we're doing here is in the

00:10:38,100 --> 00:10:46,810
metadata for the park' object we know

00:10:43,420 --> 00:10:49,420
that it has partition keys and also has

00:10:46,810 --> 00:10:52,660
different fields but we have a data

00:10:49,420 --> 00:10:56,080
producers tag which fields they want to

00:10:52,660 --> 00:10:59,430
expose as the filter key so using this

00:10:56,080 --> 00:11:01,660
partition key and the filter key we're

00:10:59,430 --> 00:11:06,070
creating this compound key that's

00:11:01,660 --> 00:11:12,220
exposed as the input of the query on the

00:11:06,070 --> 00:11:15,880
graph key well side and doing exposing

00:11:12,220 --> 00:11:18,760
this quiz in this way helps you make

00:11:15,880 --> 00:11:21,610
sure that your queries will perform well

00:11:18,760 --> 00:11:24,010
because it's using the always using the

00:11:21,610 --> 00:11:27,279
partition key and then always using the

00:11:24,010 --> 00:11:29,790
filter key that the data producers want

00:11:27,279 --> 00:11:29,790
you to use

00:11:31,800 --> 00:11:37,499
again this is this is an example for the

00:11:34,350 --> 00:11:42,119
rest for the building the query there is

00:11:37,499 --> 00:11:44,730
a part of the open API definition called

00:11:42,119 --> 00:11:47,550
parameters and you can straight take

00:11:44,730 --> 00:11:54,569
that and then convert that into a graph

00:11:47,550 --> 00:11:56,699
queue or query schema fragment but in

00:11:54,569 --> 00:11:59,600
this automation one of the first things

00:11:56,699 --> 00:12:03,449
you might encounter as a problem is

00:11:59,600 --> 00:12:06,749
naming collision so in graph QL spec

00:12:03,449 --> 00:12:10,350
there's no concept of name spacing that

00:12:06,749 --> 00:12:12,600
enforces unique names so let's say

00:12:10,350 --> 00:12:16,279
multiple teams have similar names

00:12:12,600 --> 00:12:19,829
there's a high chance of you know

00:12:16,279 --> 00:12:22,079
essentially teams in creating similar

00:12:19,829 --> 00:12:25,230
names and then you end up creating this

00:12:22,079 --> 00:12:27,119
collision so what we do is again going

00:12:25,230 --> 00:12:30,209
back to the metadata that we have and

00:12:27,119 --> 00:12:35,009
we're essentially generating this pseudo

00:12:30,209 --> 00:12:37,410
namespace and in our case taking the

00:12:35,009 --> 00:12:39,540
line of business capital we're not just

00:12:37,410 --> 00:12:42,240
a credit company credit card company

00:12:39,540 --> 00:12:45,660
we're a bank we do auto loans we do all

00:12:42,240 --> 00:12:48,420
kinds of things right so line of

00:12:45,660 --> 00:12:51,269
business in my line of business is card

00:12:48,420 --> 00:12:54,449
so we can use that as the prefix one of

00:12:51,269 --> 00:12:57,689
the prefix and then for this particular

00:12:54,449 --> 00:13:00,869
call center analytics data source it is

00:12:57,689 --> 00:13:04,290
owned by the domain servicing for the

00:13:00,869 --> 00:13:07,860
customer call center division and then

00:13:04,290 --> 00:13:11,899
also we're using the diversion to create

00:13:07,860 --> 00:13:16,499
this prefix in order to make sure that

00:13:11,899 --> 00:13:19,110
the name spacing or the the types and

00:13:16,499 --> 00:13:21,379
the queries are generated with unique

00:13:19,110 --> 00:13:21,379
names

00:13:22,810 --> 00:13:28,900
and in speaking of versioning there's

00:13:25,690 --> 00:13:32,440
many many ways to you know go go about

00:13:28,900 --> 00:13:34,840
it but for us we're only versioning the

00:13:32,440 --> 00:13:37,720
types and the associated queries

00:13:34,840 --> 00:13:42,160
we're not versioning the Global like the

00:13:37,720 --> 00:13:45,630
top-level schema itself the only thing

00:13:42,160 --> 00:13:49,990
that we're versioning is when we see a

00:13:45,630 --> 00:13:54,700
field that is either deleted modified or

00:13:49,990 --> 00:13:58,000
added into the the new the change on the

00:13:54,700 --> 00:14:02,260
backend data source we increment the

00:13:58,000 --> 00:14:04,960
version type to make the change

00:14:02,260 --> 00:14:07,750
transparent to all the consumers of the

00:14:04,960 --> 00:14:09,970
gateway and one of the things that I

00:14:07,750 --> 00:14:11,830
want to call out is as you increment the

00:14:09,970 --> 00:14:14,770
versions you might want to essentially

00:14:11,830 --> 00:14:17,590
deprecated the old ones and when you

00:14:14,770 --> 00:14:19,630
delete and as you delete in different

00:14:17,590 --> 00:14:22,360
types you want to be extremely careful

00:14:19,630 --> 00:14:24,010
you know when you do so because you

00:14:22,360 --> 00:14:28,440
might have consumers that are still

00:14:24,010 --> 00:14:33,600
using the old version so things such as

00:14:28,440 --> 00:14:36,940
onboarding you know the data with

00:14:33,600 --> 00:14:39,550
updated configuration information as

00:14:36,940 --> 00:14:42,010
well as being able to monitor the

00:14:39,550 --> 00:14:45,090
activity of the usage becomes really

00:14:42,010 --> 00:14:45,090
useful and important

00:14:48,580 --> 00:14:53,320
and one of the really powerful thing

00:14:50,830 --> 00:14:57,310
about graph QL obviously is to represent

00:14:53,320 --> 00:14:59,769
your data in graph so to take advantage

00:14:57,310 --> 00:15:04,120
of this you want to define relationship

00:14:59,769 --> 00:15:10,029
between your types right and so here's

00:15:04,120 --> 00:15:12,519
an example of taking the past two types

00:15:10,029 --> 00:15:16,300
that we generated in the earlier slides

00:15:12,519 --> 00:15:18,940
once the card servicing call center

00:15:16,300 --> 00:15:23,200
analytics type and that tech digital web

00:15:18,940 --> 00:15:25,510
analytics types and we are essentially

00:15:23,200 --> 00:15:28,930
and building that into this called

00:15:25,510 --> 00:15:31,329
account type so then a card account

00:15:28,930 --> 00:15:33,640
could be queried and then from there you

00:15:31,329 --> 00:15:35,649
can drill down to the either the call

00:15:33,640 --> 00:15:37,779
center analytics or web analytics that

00:15:35,649 --> 00:15:40,750
way and then build start building this

00:15:37,779 --> 00:15:47,649
ontology of your domain data which can

00:15:40,750 --> 00:15:49,660
be extremely useful so I'd like to take

00:15:47,649 --> 00:15:51,970
a moment to get a sense of the graph QL

00:15:49,660 --> 00:15:54,910
community for a second here

00:15:51,970 --> 00:15:59,140
how many people work with graph queue on

00:15:54,910 --> 00:16:02,620
a everyday basis oh wow there's a lot of

00:15:59,140 --> 00:16:06,060
you how many of you use the JavaScript

00:16:02,620 --> 00:16:11,529
stack JavaScript

00:16:06,060 --> 00:16:15,970
how about Java oh that's the thing about

00:16:11,529 --> 00:16:22,870
how about golang okay only a few of you

00:16:15,970 --> 00:16:25,990
okay so my team is essentially a JVM

00:16:22,870 --> 00:16:28,930
tech stack shop with Python so we

00:16:25,990 --> 00:16:33,220
decided to implement ours using the java

00:16:28,930 --> 00:16:35,050
language and here's just an example over

00:16:33,220 --> 00:16:38,680
the library that we use it's called

00:16:35,050 --> 00:16:41,199
graph qo Java kickstart and it has this

00:16:38,680 --> 00:16:44,740
utility called type definition Factory

00:16:41,199 --> 00:16:50,290
and this enables you to essentially

00:16:44,740 --> 00:16:54,230
create a dynamic graph schema or graph

00:16:50,290 --> 00:16:57,210
QL schema during the application runtime

00:16:54,230 --> 00:17:00,810
so this is what we use to essentially

00:16:57,210 --> 00:17:05,540
during the execution of the data graph

00:17:00,810 --> 00:17:10,439
or the the Gateway we can dynamically

00:17:05,540 --> 00:17:12,510
take the fragments of the types and

00:17:10,439 --> 00:17:15,600
queries that we generate using the

00:17:12,510 --> 00:17:20,780
configuration translator and then expose

00:17:15,600 --> 00:17:20,780
that into our schema that we host

00:17:21,020 --> 00:17:26,010
another really cool library that we use

00:17:24,030 --> 00:17:29,040
is called bite buddy

00:17:26,010 --> 00:17:31,500
so as you know Java is a compiled

00:17:29,040 --> 00:17:33,870
language but this library what it does

00:17:31,500 --> 00:17:37,110
is it lets you during the application

00:17:33,870 --> 00:17:40,260
run time generate this dynamic code and

00:17:37,110 --> 00:17:44,880
then inject a code into your JVM through

00:17:40,260 --> 00:17:47,970
the class or loader even if you you know

00:17:44,880 --> 00:17:50,070
might think that there's no use for this

00:17:47,970 --> 00:17:52,620
EW I suggest like checking it out just

00:17:50,070 --> 00:17:56,010
because it's a really cool tool and it

00:17:52,620 --> 00:17:57,990
might spark some ideas on some some new

00:17:56,010 --> 00:17:59,429
really interesting you know features

00:17:57,990 --> 00:18:03,120
that you might want to introduce in your

00:17:59,429 --> 00:18:07,559
java application and this is essentially

00:18:03,120 --> 00:18:10,860
what I use to dynamically build the the

00:18:07,559 --> 00:18:15,530
models or the the plane object Maps to

00:18:10,860 --> 00:18:18,150
the graph QL fields and wire them to the

00:18:15,530 --> 00:18:21,050
resolver implementation during the

00:18:18,150 --> 00:18:21,050
application runtime

00:18:23,260 --> 00:18:28,090
for resolver wiring I leveraged this

00:18:26,200 --> 00:18:31,179
implementation that I have called a

00:18:28,090 --> 00:18:33,419
resolver Factory essentially it's just a

00:18:31,179 --> 00:18:36,669
typical factory pattern that returns

00:18:33,419 --> 00:18:39,130
appropriate resolver for requested query

00:18:36,669 --> 00:18:42,520
based on the the user requests with

00:18:39,130 --> 00:18:46,059
polymorphism and our configuration has

00:18:42,520 --> 00:18:48,370
the necessary information or that our

00:18:46,059 --> 00:18:51,429
configuration service has the necessary

00:18:48,370 --> 00:18:53,919
information to determine what resolver

00:18:51,429 --> 00:19:01,809
to return based on the request that we

00:18:53,919 --> 00:19:05,140
get and behind the scenes of the

00:19:01,809 --> 00:19:07,929
resolvers here are a few different tools

00:19:05,140 --> 00:19:09,820
that we use to actually get to the data

00:19:07,929 --> 00:19:12,429
and then bring them bring back the data

00:19:09,820 --> 00:19:20,799
for the resolver to aggregate the data

00:19:12,429 --> 00:19:23,380
and then present the data and in

00:19:20,799 --> 00:19:26,620
building any platform that's responsive

00:19:23,380 --> 00:19:30,400
and scale scalable you always need a

00:19:26,620 --> 00:19:33,870
very good caching mechanism right so we

00:19:30,400 --> 00:19:38,100
also have this cache building technique

00:19:33,870 --> 00:19:41,950
that essentially allows us to

00:19:38,100 --> 00:19:45,480
dynamically create these key values that

00:19:41,950 --> 00:19:48,820
is optimal for supporting the quick

00:19:45,480 --> 00:19:51,100
lookup of the data that we have on the

00:19:48,820 --> 00:19:57,160
Gateway so what we essentially do is

00:19:51,100 --> 00:20:01,450
look at the the type query and translate

00:19:57,160 --> 00:20:03,340
that into the the key that we need so

00:20:01,450 --> 00:20:05,880
that the the key could look like this

00:20:03,340 --> 00:20:11,370
and that the value would be the default

00:20:05,880 --> 00:20:11,370
that JSON response before the filtering

00:20:12,900 --> 00:20:22,070
and also I forgot to mention that in

00:20:16,110 --> 00:20:22,070
terms of the caching strategies around

00:20:22,130 --> 00:20:29,180
essentially the retention policy we use

00:20:26,670 --> 00:20:33,680
obviously use the least recently used

00:20:29,180 --> 00:20:38,430
strategy which is typically helpful for

00:20:33,680 --> 00:20:44,640
the majority of the use case but we also

00:20:38,430 --> 00:20:49,679
do some pre warming as some specific use

00:20:44,640 --> 00:20:53,040
cases are expecting to use certain

00:20:49,679 --> 00:20:57,000
subsets of data so there are cases where

00:20:53,040 --> 00:20:59,820
we can predict which data set will be

00:20:57,000 --> 00:21:08,130
accessed that day or that moment so we

00:20:59,820 --> 00:21:10,650
would pre warm those and lastly from

00:21:08,130 --> 00:21:13,950
infrastructure point of view the most

00:21:10,650 --> 00:21:16,260
important thing to design what the most

00:21:13,950 --> 00:21:19,380
important thing is to design something

00:21:16,260 --> 00:21:23,190
that is obviously scalable and is also

00:21:19,380 --> 00:21:26,370
resilient and in order to do this we

00:21:23,190 --> 00:21:29,850
chose to extract out the component that

00:21:26,370 --> 00:21:33,179
we houses the the configurations as its

00:21:29,850 --> 00:21:35,550
own micro service and we treat them as

00:21:33,179 --> 00:21:39,090
the the brain of the gate and try to

00:21:35,550 --> 00:21:42,600
give the best care so all the way to the

00:21:39,090 --> 00:21:46,350
the left there's the two configuration

00:21:42,600 --> 00:21:48,660
knows these are very stateful micro

00:21:46,350 --> 00:21:53,150
service and we don't want this to go

00:21:48,660 --> 00:21:57,540
down ever so we put a lot of care and

00:21:53,150 --> 00:21:59,880
try to make sure this this is this set

00:21:57,540 --> 00:22:04,050
of the micro services always up and

00:21:59,880 --> 00:22:04,890
running and then on the graph key well

00:22:04,050 --> 00:22:08,220
server side

00:22:04,890 --> 00:22:10,980
order order in this diagram called the

00:22:08,220 --> 00:22:15,000
gateway number one two three and four

00:22:10,980 --> 00:22:18,120
these are stateless micro services they

00:22:15,000 --> 00:22:19,220
can run out of memory because there's

00:22:18,120 --> 00:22:24,110
some really

00:22:19,220 --> 00:22:26,900
spensive query that was executed or it

00:22:24,110 --> 00:22:30,350
needs to be taken down for some

00:22:26,900 --> 00:22:32,539
maintenance because we have some bug or

00:22:30,350 --> 00:22:36,350
you know some new features that we

00:22:32,539 --> 00:22:39,590
implement in a gateway these gateways

00:22:36,350 --> 00:22:42,530
can go up and down you know for those

00:22:39,590 --> 00:22:45,140
kind of purpose or if you if we need to

00:22:42,530 --> 00:22:46,850
scale up you know up or down based on

00:22:45,140 --> 00:22:52,370
the load we can do that as well

00:22:46,850 --> 00:22:56,150
and all of this are containerized and we

00:22:52,370 --> 00:22:58,990
have a kubernetes cluster infrastructure

00:22:56,150 --> 00:23:02,659
deployed on our Amazon Web Services and

00:22:58,990 --> 00:23:06,650
that is the thing that orchestrates the

00:23:02,659 --> 00:23:08,539
the deployment and the the the

00:23:06,650 --> 00:23:13,789
resiliency of the containers that are

00:23:08,539 --> 00:23:17,169
running in our production so I went

00:23:13,789 --> 00:23:21,169
through a lot of material super quickly

00:23:17,169 --> 00:23:24,820
but here's sort of the summary of all

00:23:21,169 --> 00:23:26,929
the things that I just talked about and

00:23:24,820 --> 00:23:29,390
you know thank you very much for your

00:23:26,929 --> 00:23:33,049
time and I hope this is you know this

00:23:29,390 --> 00:23:33,980
was useful and that's it for me thank

00:23:33,049 --> 00:23:36,980
you

00:23:33,980 --> 00:23:36,980

YouTube URL: https://www.youtube.com/watch?v=9lfnMBnLdNQ


