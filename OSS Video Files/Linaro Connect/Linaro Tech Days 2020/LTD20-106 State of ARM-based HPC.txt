Title: LTD20-106 State of ARM-based HPC
Publication date: 2020-03-25
Playlist: Linaro Tech Days 2020
Description: 
	Description:
An overview of applications and infrastructure services successfully ported to Aarch64 and benefiting from scale.

Session Speakers
Paul Isaac's - Director (LDCG, HPC-SIG) (Linaro Limited)


Technical Lead for HPC-SIG within LDCG. 30+ years of international infrastructure architecture experience from Smart NICs to HPC and software development. 



You can find the presentation for this session on connect.linaro.org:
https://connect.linaro.org/resources/ltd20/ltd20-106/
Captions: 
	00:00:04,350 --> 00:00:09,809
so the aim of the talk is to highlight

00:00:07,470 --> 00:00:12,240
the evolution of the arm CPU

00:00:09,809 --> 00:00:15,570
capabilities that can be exploited

00:00:12,240 --> 00:00:18,060
within the HPC concept we're looking at

00:00:15,570 --> 00:00:22,050
the benefits of the neon sim D and the

00:00:18,060 --> 00:00:24,779
extensions of sv e but we also have a

00:00:22,050 --> 00:00:28,109
trade-off in waiting for new CPU

00:00:24,779 --> 00:00:32,400
production cycles versus potentially

00:00:28,109 --> 00:00:36,329
putting accelerators in GPU cards for

00:00:32,400 --> 00:00:42,030
example so what may happen is we end up

00:00:36,329 --> 00:00:45,899
rotating between various and so then

00:00:42,030 --> 00:00:49,260
silicon vendors rather than being able

00:00:45,899 --> 00:00:51,690
to establish a long term scenario with

00:00:49,260 --> 00:00:54,329
one particular silicon bender simply

00:00:51,690 --> 00:01:01,920
because the the way that the is a

00:00:54,329 --> 00:01:07,620
develops okay so so in sorry go back one

00:01:01,920 --> 00:01:11,580
please so in my welcome to you and like

00:01:07,620 --> 00:01:15,030
to say that the arm is a is definitely a

00:01:11,580 --> 00:01:19,049
first-class citizen with respect to the

00:01:15,030 --> 00:01:22,400
HPC environment we started out so a few

00:01:19,049 --> 00:01:26,070
years ago now with the mont blanc

00:01:22,400 --> 00:01:29,130
project which was initially a system on

00:01:26,070 --> 00:01:33,560
chip and the maya GPU configurations

00:01:29,130 --> 00:01:37,470
then there was the caveum thunder x1

00:01:33,560 --> 00:01:40,680
scenario and followed by the thunder x2

00:01:37,470 --> 00:01:45,540
and we're looking for updates with the

00:01:40,680 --> 00:01:50,640
nvidia support where we can have arm

00:01:45,540 --> 00:01:54,409
based servers with nvidia gpus so it's

00:01:50,640 --> 00:02:00,030
it's not our first radio we can say that

00:01:54,409 --> 00:02:04,409
arm as a is a benefits in the HPC

00:02:00,030 --> 00:02:10,289
community primarily on efficiency as

00:02:04,409 --> 00:02:12,510
always most noted for and if you'd like

00:02:10,289 --> 00:02:15,270
to take a look at where we are and then

00:02:12,510 --> 00:02:18,030
there are several links here and the

00:02:15,270 --> 00:02:21,510
last one being the developers site

00:02:18,030 --> 00:02:26,880
where you can see the various HPC

00:02:21,510 --> 00:02:31,850
concepts okay next slide so listen let's

00:02:26,880 --> 00:02:34,860
just review I know I may be talking to a

00:02:31,850 --> 00:02:38,100
grandma to suck eggs but it's it's

00:02:34,860 --> 00:02:41,150
always good to happen a review of what

00:02:38,100 --> 00:02:45,030
HPC actually is so we're looking for

00:02:41,150 --> 00:02:47,510
common components and typically and

00:02:45,030 --> 00:02:51,450
they're looking to be near identical

00:02:47,510 --> 00:02:54,630
configuration so it eases scalability a

00:02:51,450 --> 00:02:56,310
method of interconnecting the nodes some

00:02:54,630 --> 00:02:59,900
sort of jobs scheduler

00:02:56,310 --> 00:03:04,700
such as a slam work workload manager

00:02:59,900 --> 00:03:08,489
univariate engine and there's ways to

00:03:04,700 --> 00:03:09,959
parallelize across multiple nodes so it

00:03:08,489 --> 00:03:13,310
doesn't have to be literally a job

00:03:09,959 --> 00:03:18,570
scheduler they're just a form of

00:03:13,310 --> 00:03:21,150
parallelization so if we just say a bit

00:03:18,570 --> 00:03:23,190
of CPU bit of RAM bit of interconnection

00:03:21,150 --> 00:03:27,720
bit of storage is that enough to really

00:03:23,190 --> 00:03:33,720
call it HPC so if we go to the next

00:03:27,720 --> 00:03:37,860
slide so first of all we look at the CPU

00:03:33,720 --> 00:03:43,019
so it's we have to break again as to how

00:03:37,860 --> 00:03:47,340
relevant it is to HPC environment so we

00:03:43,019 --> 00:03:49,170
look at the number of nodes so that's a

00:03:47,340 --> 00:03:51,239
number of chassis is that were likely to

00:03:49,170 --> 00:03:55,829
be putting together the number of cores

00:03:51,239 --> 00:03:59,600
within those CPUs how many threads could

00:03:55,829 --> 00:04:03,450
actually be maintained by a single CPU

00:03:59,600 --> 00:04:06,360
is non-uniform memory access supported

00:04:03,450 --> 00:04:08,420
so can we have multiple CPUs accessing

00:04:06,360 --> 00:04:11,579
slightly different parts of the memory

00:04:08,420 --> 00:04:15,060
but fundamentally working all towards

00:04:11,579 --> 00:04:18,660
the same goal and whether those machines

00:04:15,060 --> 00:04:21,959
are cache coherence so are we in sync

00:04:18,660 --> 00:04:25,650
between each of the calls with the data

00:04:21,959 --> 00:04:27,360
that is being processed so these are

00:04:25,650 --> 00:04:32,250
elements which you don't necessarily

00:04:27,360 --> 00:04:36,390
find at the edge devices

00:04:32,250 --> 00:04:38,490
and and so what unfortunately HPC

00:04:36,390 --> 00:04:41,430
requires a lot of money it's a

00:04:38,490 --> 00:04:45,590
significant investment it's not

00:04:41,430 --> 00:04:50,220
something that a 50 $50 system-on-chip

00:04:45,590 --> 00:04:52,320
edge device is really capable of and so

00:04:50,220 --> 00:04:56,550
we're we're looking at the way that we

00:04:52,320 --> 00:05:00,330
scale so first of all the the scaling of

00:04:56,550 --> 00:05:03,660
levels of cash so within the ISA we have

00:05:00,330 --> 00:05:06,090
the macro op cash which is just

00:05:03,660 --> 00:05:08,190
collecting a few small instructions

00:05:06,090 --> 00:05:11,490
together and then running them as a

00:05:08,190 --> 00:05:15,780
simple micro and then level 1 level 2

00:05:11,490 --> 00:05:18,510
level 3 as we sounds the slides as for

00:05:15,780 --> 00:05:22,590
each core for cluster of calls and for

00:05:18,510 --> 00:05:24,630
the cluster of the CPUs so what were

00:05:22,590 --> 00:05:27,810
actually looking at is how fast can we

00:05:24,630 --> 00:05:29,730
get the data being processed and if

00:05:27,810 --> 00:05:31,500
we've got to do multiple operations on

00:05:29,730 --> 00:05:33,000
the same pieces of data we don't want to

00:05:31,500 --> 00:05:35,730
keep passing it backwards and forwards

00:05:33,000 --> 00:05:40,040
between memory he just needs to be held

00:05:35,730 --> 00:05:45,840
within the CPU area for processing so

00:05:40,040 --> 00:05:48,750
next slide so where where did we start

00:05:45,840 --> 00:05:51,630
and so I even I referred back to the

00:05:48,750 --> 00:05:55,260
Montblanc and then Thunder x1 and x2 so

00:05:51,630 --> 00:05:58,170
these are based on the arm is a so the

00:05:55,260 --> 00:06:00,180
instruction set architecture the is a

00:05:58,170 --> 00:06:05,040
doesn't stipulate how the silicon is

00:06:00,180 --> 00:06:08,250
actually laid down you can either take a

00:06:05,040 --> 00:06:11,880
reference design or build your own IP as

00:06:08,250 --> 00:06:15,180
to how the silicon is laid out and you

00:06:11,880 --> 00:06:18,230
implement the armor you say so the first

00:06:15,180 --> 00:06:21,800
version of the 64 bit was the arm b8

00:06:18,230 --> 00:06:25,440
which introduced the advanced neon

00:06:21,800 --> 00:06:29,940
Sindhi architecture so that had 32

00:06:25,440 --> 00:06:32,550
registers 128 bits and that was

00:06:29,940 --> 00:06:35,370
implemented in silicon by the ampere

00:06:32,550 --> 00:06:40,320
emag the cabby and FedEx and the

00:06:35,370 --> 00:06:43,170
Qualcomm quite when we go to the arm v81

00:06:40,320 --> 00:06:45,690
this is where we get the Thunder x2 so

00:06:43,170 --> 00:06:48,660
this is where we start to see

00:06:45,690 --> 00:06:50,970
so supercomputers you probably heard of

00:06:48,660 --> 00:06:52,980
so the Astra supercomputer at Sandia

00:06:50,970 --> 00:06:56,130
National Labs and the Isambard

00:06:52,980 --> 00:07:00,320
supercomputer at run by University of

00:06:56,130 --> 00:07:05,670
Bristol alongside the meteorology

00:07:00,320 --> 00:07:11,400
Meteorological Office of the UK Met

00:07:05,670 --> 00:07:13,710
Office in short but on v81 it's actually

00:07:11,400 --> 00:07:16,950
quite an all when I say it's a few years

00:07:13,710 --> 00:07:19,770
old now and in subsequent releases we've

00:07:16,950 --> 00:07:25,020
seen eight point two eight point three

00:07:19,770 --> 00:07:28,800
and what what we see is there's a delay

00:07:25,020 --> 00:07:32,340
between the benefits of the new AIS a

00:07:28,800 --> 00:07:35,820
and it being implemented in silicon so

00:07:32,340 --> 00:07:39,120
when we're just seeing so early

00:07:35,820 --> 00:07:44,550
deliveries of the a 64 FX from Fujitsu

00:07:39,120 --> 00:07:49,260
with the 8.2 is a but specifically the

00:07:44,550 --> 00:07:54,210
Asics for FX has the SBE extension now

00:07:49,260 --> 00:07:58,050
we use a potentially use sve for larger

00:07:54,210 --> 00:08:00,360
simpie functions as Cindy hopefully not

00:07:58,050 --> 00:08:02,970
preaching to everybody but single

00:08:00,360 --> 00:08:04,169
instruction multiple data so if you want

00:08:02,970 --> 00:08:07,320
to carry out a particular mathematical

00:08:04,169 --> 00:08:10,890
operation on a set of data you can do it

00:08:07,320 --> 00:08:13,440
with the standard neon 128 bits of data

00:08:10,890 --> 00:08:15,510
but with SBE

00:08:13,440 --> 00:08:19,950
as implemented on the ACS to Polyface

00:08:15,510 --> 00:08:23,010
you can do it with 512 bits so a

00:08:19,950 --> 00:08:25,440
significant improvement and sve extends

00:08:23,010 --> 00:08:28,190
up to 204 eight if it's implemented in

00:08:25,440 --> 00:08:31,740
silicon now

00:08:28,190 --> 00:08:35,940
so the ISA it takes time to implement so

00:08:31,740 --> 00:08:38,490
we've already had 8.3 Cindy computes now

00:08:35,940 --> 00:08:40,590
that if a mathematician and you're

00:08:38,490 --> 00:08:42,599
looking into complex numbers you want to

00:08:40,590 --> 00:08:44,850
do 90-degree rotations of complex

00:08:42,599 --> 00:08:51,300
numbers then you and you will be looking

00:08:44,850 --> 00:08:53,310
at 8.3 implemented in silicon before it

00:08:51,300 --> 00:08:56,610
will be available in hardware of course

00:08:53,310 --> 00:08:58,899
you can do complex number 90 degree

00:08:56,610 --> 00:09:00,999
rotation in software but

00:08:58,899 --> 00:09:04,509
wouldn't be accelerated until the

00:09:00,999 --> 00:09:08,860
hardware is available to do so so we're

00:09:04,509 --> 00:09:12,509
looking at the Thunder x3 and campaign

00:09:08,860 --> 00:09:15,850
930 which are likely to support these

00:09:12,509 --> 00:09:18,579
sort of details I'm not giving out any

00:09:15,850 --> 00:09:22,019
yet NDA information dole this is

00:09:18,579 --> 00:09:27,459
available for young which video and web

00:09:22,019 --> 00:09:29,249
product launching so I'm not taking the

00:09:27,459 --> 00:09:32,800
thunder at about other people's

00:09:29,249 --> 00:09:37,240
announcements but and say there is a

00:09:32,800 --> 00:09:40,300
delay and surprise surprise if you if

00:09:37,240 --> 00:09:47,470
you look at where 8.4 the logical

00:09:40,300 --> 00:09:51,879
numbering would be next slide surprise

00:09:47,470 --> 00:09:55,600
you've actually got the the later

00:09:51,879 --> 00:10:01,449
version of is a in your phone if you've

00:09:55,600 --> 00:10:05,220
got an iPhone 11 so that's in the a 13

00:10:01,449 --> 00:10:07,509
Bionic chip so currently the

00:10:05,220 --> 00:10:10,480
supercomputers of today run

00:10:07,509 --> 00:10:14,199
architectures or is a versions which are

00:10:10,480 --> 00:10:16,839
less than the version that you may have

00:10:14,199 --> 00:10:21,670
on your mobile phone that doesn't mean

00:10:16,839 --> 00:10:26,499
to say that the iPhone is more powerful

00:10:21,670 --> 00:10:28,870
than a supercomputer it's not because

00:10:26,499 --> 00:10:31,809
there's many many other components which

00:10:28,870 --> 00:10:38,769
we'll talk about reagan regarding so

00:10:31,809 --> 00:10:41,920
what makes a HPC so next slide so if we

00:10:38,769 --> 00:10:43,990
come right up to to date so the current

00:10:41,920 --> 00:10:47,290
version is 8.6

00:10:43,990 --> 00:10:50,649
and so we're expecting that the NIA

00:10:47,290 --> 00:10:52,600
verse end to reference design will be

00:10:50,649 --> 00:10:56,769
used by the European processor

00:10:52,600 --> 00:11:00,879
initiative and we then note that there

00:10:56,769 --> 00:11:05,920
is a B float16 format support in the

00:11:00,879 --> 00:11:08,740
hardware what that means is a more

00:11:05,920 --> 00:11:12,460
efficient way of handling floating-point

00:11:08,740 --> 00:11:15,160
numbers at the 16 bit level now

00:11:12,460 --> 00:11:17,380
the likes of Google and Intel I've been

00:11:15,160 --> 00:11:21,220
out support for this we're still waiting

00:11:17,380 --> 00:11:25,470
for support from Nvidia for for their

00:11:21,220 --> 00:11:28,300
support supported be float16 so there's

00:11:25,470 --> 00:11:31,330
not a huge amount of vendors at the

00:11:28,300 --> 00:11:36,550
moment at this level and so we have

00:11:31,330 --> 00:11:39,190
plenty of time to implement silicon to

00:11:36,550 --> 00:11:41,410
support reflow 16 because the

00:11:39,190 --> 00:11:44,580
alternative is you don't wait for the

00:11:41,410 --> 00:11:50,050
humane CPU you could have an accelerator

00:11:44,580 --> 00:11:52,029
and plug in to your main CPU to provide

00:11:50,050 --> 00:11:56,560
those extra functions and that's what

00:11:52,029 --> 00:12:02,070
people do so you may have an FPGA

00:11:56,560 --> 00:12:05,920
enabled accelerator or it could be a GPU

00:12:02,070 --> 00:12:08,470
from some other and design that supports

00:12:05,920 --> 00:12:12,690
the functions you need while she wait

00:12:08,470 --> 00:12:19,540
for the the silicon vendors to implement

00:12:12,690 --> 00:12:22,360
the latest is a so so these versions

00:12:19,540 --> 00:12:24,820
eight point six and that's the e to the

00:12:22,360 --> 00:12:28,810
enhancement recipe were announced last

00:12:24,820 --> 00:12:33,839
year in April and we're looking towards

00:12:28,810 --> 00:12:38,230
the end of this year where we see

00:12:33,839 --> 00:12:48,310
potential launches that support eight

00:12:38,230 --> 00:12:50,950
point six ok so next slide so this is

00:12:48,310 --> 00:12:54,910
what I was alluding to do do we look at

00:12:50,950 --> 00:12:58,420
purely what the CPU can do do we look at

00:12:54,910 --> 00:13:03,209
what the accelerators candy for the HPC

00:12:58,420 --> 00:13:06,430
benefit or do we use a combination and

00:13:03,209 --> 00:13:07,660
the technology doesn't say stand still

00:13:06,430 --> 00:13:09,459
and say we wait for different

00:13:07,660 --> 00:13:11,320
fabrication sizes whether we're going

00:13:09,459 --> 00:13:13,990
from ten nanometer to seven to

00:13:11,320 --> 00:13:19,540
potentially finally in the future to

00:13:13,990 --> 00:13:21,790
enhance the HPC environment and the end

00:13:19,540 --> 00:13:26,230
that the answer is not clear-cut if

00:13:21,790 --> 00:13:30,459
we're saying does one particular is a

00:13:26,230 --> 00:13:33,959
so outperform a another particular and

00:13:30,459 --> 00:13:38,170
saya Sisk implementation so does risk

00:13:33,959 --> 00:13:40,980
beat Sisk some cases yes some capers and

00:13:38,170 --> 00:13:44,589
maybe not it's really a case of

00:13:40,980 --> 00:13:45,940
implementation benchmarking testing does

00:13:44,589 --> 00:13:53,560
it fulfill the role that you actually

00:13:45,940 --> 00:13:57,820
wanted to do okay so next slide so

00:13:53,560 --> 00:14:00,370
beyond the CPU and the accelerators how

00:13:57,820 --> 00:14:04,000
do we actually connect these processes

00:14:00,370 --> 00:14:07,630
together to make them octal so we have

00:14:04,000 --> 00:14:11,800
our options of the internal connectivity

00:14:07,630 --> 00:14:15,220
so arm CNM 600 support 128 call into

00:14:11,800 --> 00:14:18,760
connectivity so that will be connecting

00:14:15,220 --> 00:14:20,980
with a single chassis and then between

00:14:18,760 --> 00:14:27,579
chassis is we have the options at PCIe

00:14:20,980 --> 00:14:32,199
or c6 maybe we'll see support for cxl so

00:14:27,579 --> 00:14:35,110
the alternative to c6 and then more

00:14:32,199 --> 00:14:38,680
proprietary connectivity such as Ares

00:14:35,110 --> 00:14:40,510
and tofu so Ares from the likes of creo

00:14:38,680 --> 00:14:43,209
free from packets ooh

00:14:40,510 --> 00:14:46,959
and then one we're looking at

00:14:43,209 --> 00:14:49,000
interlinking lots of chasis then we have

00:14:46,959 --> 00:14:51,070
their network options of InfiniBand

00:14:49,000 --> 00:14:55,959
which is low low latency interconnect

00:14:51,070 --> 00:14:57,610
and Ethernet but the point is again you

00:14:55,959 --> 00:15:02,140
wouldn't get these methods of

00:14:57,610 --> 00:15:04,060
interconnects on say the iPhone 11 so it

00:15:02,140 --> 00:15:10,839
didn't the iPhone unit may have the

00:15:04,060 --> 00:15:14,490
april 8.4 is a but the 8.2 solutions

00:15:10,839 --> 00:15:18,779
with these interconnects will outperform

00:15:14,490 --> 00:15:20,610
easily let the mobile phone options okay

00:15:18,779 --> 00:15:25,060
next slide

00:15:20,610 --> 00:15:26,920
hey Paul just away you've got three four

00:15:25,060 --> 00:15:29,230
no minutes you'll probably have to start

00:15:26,920 --> 00:15:34,720
wrapping up soon no problem

00:15:29,230 --> 00:15:38,410
okay so the alternative is we go FPGA in

00:15:34,720 --> 00:15:40,080
the accelerations and here's an example

00:15:38,410 --> 00:15:45,570
from Xilinx

00:15:40,080 --> 00:15:49,410
which matches cortex a 72 core with the

00:15:45,570 --> 00:15:53,000
possibility to add FPGA solutions

00:15:49,410 --> 00:15:56,820
it supports c6 and cxl it's got Ethernet

00:15:53,000 --> 00:15:59,990
but the a72 just going back to the ISA

00:15:56,820 --> 00:16:02,850
architecture is actually version 8.0

00:15:59,990 --> 00:16:07,290
and so you will then have to implement

00:16:02,850 --> 00:16:08,420
in FPGA your any extended commands next

00:16:07,290 --> 00:16:12,450
slide

00:16:08,420 --> 00:16:14,760
and then for HPC we require resilience

00:16:12,450 --> 00:16:18,450
such as error correcting code memory

00:16:14,760 --> 00:16:21,180
chill power supplies of basics and core

00:16:18,450 --> 00:16:24,660
fault sensing to see if a multi-core

00:16:21,180 --> 00:16:26,850
CPUs actually fail and then above the

00:16:24,660 --> 00:16:31,709
work containers because containers is

00:16:26,850 --> 00:16:34,339
actually quite novel if we just go to

00:16:31,709 --> 00:16:34,339
the next slide

00:16:34,910 --> 00:16:39,290
containers now give us the options that

00:16:37,200 --> 00:16:42,330
we're spending all this money on

00:16:39,290 --> 00:16:45,390
interconnects expensive interconnects

00:16:42,330 --> 00:16:48,060
the expensive Graham and I've been

00:16:45,390 --> 00:16:51,570
alluding to that HPC is far far better

00:16:48,060 --> 00:16:54,829
than your system on chips but containers

00:16:51,570 --> 00:16:58,529
give us the opportunity if you want to

00:16:54,829 --> 00:17:01,140
consider them as throwaway services that

00:16:58,529 --> 00:17:03,779
you could have your applications in

00:17:01,140 --> 00:17:07,230
containers running on system on chips

00:17:03,779 --> 00:17:10,199
across thousands of system on chips and

00:17:07,230 --> 00:17:13,410
if one fails you just restart another

00:17:10,199 --> 00:17:16,110
container and another solution and the

00:17:13,410 --> 00:17:18,809
potential of this is such that you can

00:17:16,110 --> 00:17:21,179
scale containers from the low-end system

00:17:18,809 --> 00:17:25,230
on chip all the way through to freghar

00:17:21,179 --> 00:17:27,800
code to the a 64 FX supercomputer if you

00:17:25,230 --> 00:17:32,070
saw the keynote earlier this morning and

00:17:27,800 --> 00:17:36,120
that there was mention on the HPC /ai

00:17:32,070 --> 00:17:38,220
using containers within the HPC

00:17:36,120 --> 00:17:40,910
environment which is quite interesting

00:17:38,220 --> 00:17:45,240
because it allows the total scalability

00:17:40,910 --> 00:17:47,850
okay next slide just quickly just a

00:17:45,240 --> 00:17:51,270
reminder we do need storage are quite an

00:17:47,850 --> 00:17:53,700
wrap it up a little quicker that's we're

00:17:51,270 --> 00:17:56,669
looking at distributed storage our set

00:17:53,700 --> 00:17:58,980
and parallel file systems such as lustre

00:17:56,669 --> 00:18:02,190
these are projects that we're very

00:17:58,980 --> 00:18:03,480
interested in and working on because at

00:18:02,190 --> 00:18:06,740
the end of the day you still need to

00:18:03,480 --> 00:18:09,720
store your data somewhere and next slide

00:18:06,740 --> 00:18:14,610
but one applications did we run on the

00:18:09,720 --> 00:18:16,080
HPC so there's already 292 libraries and

00:18:14,610 --> 00:18:19,500
applications that have been tested for

00:18:16,080 --> 00:18:22,169
AR 64 and they're available to view on

00:18:19,500 --> 00:18:23,700
arms website you could run weather

00:18:22,169 --> 00:18:25,830
prediction models but of course the

00:18:23,700 --> 00:18:30,600
latest algorithms suggest that you can

00:18:25,830 --> 00:18:31,860
run it on PC powered devices in the

00:18:30,600 --> 00:18:34,740
weather prediction there's a link there

00:18:31,860 --> 00:18:36,809
for a novel an algorithm and then we

00:18:34,740 --> 00:18:40,440
have molecular dynamics so we're talking

00:18:36,809 --> 00:18:44,730
about kovat 19 potentially being looked

00:18:40,440 --> 00:18:46,830
at on using grow max molecular dynamic

00:18:44,730 --> 00:18:51,570
application and then of course we have a

00:18:46,830 --> 00:18:55,679
is a potential application for HPC next

00:18:51,570 --> 00:18:59,070
slide but we're now working from home

00:18:55,679 --> 00:19:02,389
all things are in McLean old apart from

00:18:59,070 --> 00:19:07,169
latency-sensitive edge computing devices

00:19:02,389 --> 00:19:11,159
and we need to scale on demand which

00:19:07,169 --> 00:19:14,340
suggests that HP sees accessed across

00:19:11,159 --> 00:19:17,580
the cloud eventually well potentially

00:19:14,340 --> 00:19:19,409
form Cerberus computing environments and

00:19:17,580 --> 00:19:23,460
if we look at the number of chassis sold

00:19:19,409 --> 00:19:27,090
in servers worldwide it was an 11% drop

00:19:23,460 --> 00:19:29,190
last year in chassis sales and of course

00:19:27,090 --> 00:19:31,799
where the code 19 we're looking at

00:19:29,190 --> 00:19:34,049
market falls of 20 percent so we are

00:19:31,799 --> 00:19:39,000
looking at different ways of how to make

00:19:34,049 --> 00:19:41,519
HPC pricing efficient and then the next

00:19:39,000 --> 00:19:44,070
slide so I'll just skip over the next

00:19:41,519 --> 00:19:46,380
two slides which are just a promotion

00:19:44,070 --> 00:19:49,889
often in our datacenter and cloud group

00:19:46,380 --> 00:19:51,510
which I'm a director and they hate from

00:19:49,889 --> 00:19:53,549
a high-performance sync group where we

00:19:51,510 --> 00:19:56,100
actually focus specifically on the

00:19:53,549 --> 00:19:59,210
applications which are relevant to HPC

00:19:56,100 --> 00:20:01,679
but it concluded that the last slide

00:19:59,210 --> 00:20:05,010
functions as a service this is what

00:20:01,679 --> 00:20:07,950
gradually aiming for because at the end

00:20:05,010 --> 00:20:10,830
of the day everything is cloud connected

00:20:07,950 --> 00:20:12,870
whilst as engineers in the background we

00:20:10,830 --> 00:20:18,000
will need to know the island the is AE

00:20:12,870 --> 00:20:20,520
formats the GCC compiler potions the the

00:20:18,000 --> 00:20:22,320
service computer consumer the people at

00:20:20,520 --> 00:20:25,200
the end that actually use it they just

00:20:22,320 --> 00:20:29,730
want to send a request and get an answer

00:20:25,200 --> 00:20:34,350
they effectively become CPU GPU is a

00:20:29,730 --> 00:20:36,299
agnostic so our challenge is if the

00:20:34,350 --> 00:20:38,909
equipment is being billed as a per use

00:20:36,299 --> 00:20:41,850
our challenge is to ensure that the AR

00:20:38,909 --> 00:20:42,960
60 boss solution match the significant

00:20:41,850 --> 00:20:47,789
number of requests

00:20:42,960 --> 00:20:50,100
so in conclusion HPC is is moving to the

00:20:47,789 --> 00:20:52,169
cloud everybody's you know going to be

00:20:50,100 --> 00:20:54,919
wanting to use it but they don't

00:20:52,169 --> 00:20:57,600
necessarily need the technical skills to

00:20:54,919 --> 00:21:00,059
support the infrastructure instead

00:20:57,600 --> 00:21:03,179
they're looking as function as a service

00:21:00,059 --> 00:21:05,580
fire the requests get the answer this is

00:21:03,179 --> 00:21:10,850
the direction that I believe that we

00:21:05,580 --> 00:21:10,850

YouTube URL: https://www.youtube.com/watch?v=lTsdojkQ8HQ


