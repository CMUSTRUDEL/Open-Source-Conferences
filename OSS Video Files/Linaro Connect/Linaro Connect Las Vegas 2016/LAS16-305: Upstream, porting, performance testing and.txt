Title: LAS16-305: Upstream, porting, performance testing and
Publication date: 2016-09-30
Playlist: Linaro Connect Las Vegas 2016
Description: 
	LAS16-305: Smart City Big Data Visualization on 96Boards
Speakers: Naresh Bhat, Ganesh Raju
Date: September 28, 2016

★ Session Description ★
Cities are getting identified as smart cities based on what and how data are used to do predictive analytics. Smart City as a phrase can have a wide spectrum of meaning. But there are two key things (Data and Analytics) that ‘smart’ refers to in smart city. With IoT gaining so much market attention, brings in the power to drive the implementation. Data collection, Storage and Analytics provide so much potential. This talk will go over a sample use case scenario utilizing ODPi based Hadoop eco system and H20 visualizations for analytics.

★ Resources ★
Etherpad: pad.linaro.org/p/las16-305
Presentations & Videos: http://connect.linaro.org/resource/las16/las16-305/

★ Event Details ★
Linaro Connect Las Vegas 2016 – #LAS16
September 26-30, 2016
http://www.linaro.org
http://connect.linaro.org
Captions: 
	00:00:08,059 --> 00:00:14,340
good morning everyone thanks for coming

00:00:10,290 --> 00:00:16,920
for the stock I am granese Raju I'm a

00:00:14,340 --> 00:00:21,060
technical lead for the big data team and

00:00:16,920 --> 00:00:23,070
at linaro so this talk is going to have

00:00:21,060 --> 00:00:26,099
two sections the first section we are

00:00:23,070 --> 00:00:28,980
going to do a small demo basically

00:00:26,099 --> 00:00:31,349
showing how a city can use its own data

00:00:28,980 --> 00:00:35,880
and utilize it for doing some machine

00:00:31,349 --> 00:00:39,809
learning and things like that it's going

00:00:35,880 --> 00:00:44,129
to utilize use ODP i spec based native

00:00:39,809 --> 00:00:47,700
hadoop apache spark h2o and sparkling

00:00:44,129 --> 00:00:50,719
water to do the demo and then the second

00:00:47,700 --> 00:00:54,449
section will be more on the Hadoop and

00:00:50,719 --> 00:00:59,010
the Big Data benchmarks benchmarks for

00:00:54,449 --> 00:01:04,500
Hadoop spark and anything to with the

00:00:59,010 --> 00:01:08,310
big data it's over so in the first

00:01:04,500 --> 00:01:12,090
section it's a demo like I said it's

00:01:08,310 --> 00:01:14,760
going to have owed epi base Hadoop ODP I

00:01:12,090 --> 00:01:18,780
is a standards body where you have

00:01:14,760 --> 00:01:22,409
different Hadoop disclose and isvs come

00:01:18,780 --> 00:01:26,100
together to standardize Hadoop if you

00:01:22,409 --> 00:01:28,619
see today's Hadoop ecosystem you have

00:01:26,100 --> 00:01:32,159
various disclose available and each

00:01:28,619 --> 00:01:36,170
distro they package all this open source

00:01:32,159 --> 00:01:39,020
components and there's lot of them and

00:01:36,170 --> 00:01:41,970
the problem is they don't have a proper

00:01:39,020 --> 00:01:44,130
standardization now one distro goes with

00:01:41,970 --> 00:01:46,590
the particular version that and the same

00:01:44,130 --> 00:01:49,079
same kind of a tool in a different

00:01:46,590 --> 00:01:52,890
district could be a different version of

00:01:49,079 --> 00:01:56,549
it so far for an enterprise or for an

00:01:52,890 --> 00:01:59,040
end-user when they go with a particular

00:01:56,549 --> 00:02:01,890
distro they get logged in they may have

00:01:59,040 --> 00:02:05,909
problems if for say if they want to

00:02:01,890 --> 00:02:08,849
upgrade any particular component of the

00:02:05,909 --> 00:02:11,720
big data they get stuck with district

00:02:08,849 --> 00:02:14,870
provided the package

00:02:11,720 --> 00:02:19,810
so that's why Oh DPI is collaborating

00:02:14,870 --> 00:02:23,200
with companies like IBM pivotal SAS

00:02:19,810 --> 00:02:27,320
Infosys so I think there are about 30 so

00:02:23,200 --> 00:02:30,160
member companies working together to on

00:02:27,320 --> 00:02:36,730
a common goal to standardize Hadoop in

00:02:30,160 --> 00:02:40,520
our any big data platform and also since

00:02:36,730 --> 00:02:42,830
you spend less time in testing and less

00:02:40,520 --> 00:02:45,890
time and the configurations and fixing

00:02:42,830 --> 00:02:47,750
things it reduces costs and reduces the

00:02:45,890 --> 00:02:52,490
complexity for the enterprise for the

00:02:47,750 --> 00:02:56,150
end users what ODP also provides is a

00:02:52,490 --> 00:02:59,959
cross compatibility that what that means

00:02:56,150 --> 00:03:06,430
is every distro who wants to who's part

00:02:59,959 --> 00:03:10,130
of epi they can get certified from ODP I

00:03:06,430 --> 00:03:13,040
so oh do I owe DPI provides some test

00:03:10,130 --> 00:03:15,410
suites that they can run and they can

00:03:13,040 --> 00:03:17,780
certified and what that provides for the

00:03:15,410 --> 00:03:19,670
end-user enterprises you have cross

00:03:17,780 --> 00:03:22,519
compatibility they can go with one

00:03:19,670 --> 00:03:25,130
distro later on they want to switch and

00:03:22,519 --> 00:03:31,420
go switch to another distro they can do

00:03:25,130 --> 00:03:34,880
that so right now Oh DPI has two tracks

00:03:31,420 --> 00:03:36,890
it has a runtime track and operations in

00:03:34,880 --> 00:03:41,320
the run time you have the classic Hadoop

00:03:36,890 --> 00:03:44,090
components or do sdfs MapReduce and yon

00:03:41,320 --> 00:03:47,239
on the operations right now we are

00:03:44,090 --> 00:03:53,660
looking at Apache ambari we are working

00:03:47,239 --> 00:03:55,730
on version 2 of the ODP i spec and it it

00:03:53,660 --> 00:04:00,290
is in the alpha stage and it will be

00:03:55,730 --> 00:04:03,290
releasing pretty soon linaro is

00:04:00,290 --> 00:04:05,810
obviously a member of OD Pia and I am

00:04:03,290 --> 00:04:09,739
personally a member of the technical

00:04:05,810 --> 00:04:13,430
steering committee for that so for this

00:04:09,739 --> 00:04:17,000
demo we will be using native Hadoop was

00:04:13,430 --> 00:04:21,080
in 2.7 that following the ODP I

00:04:17,000 --> 00:04:23,599
specifications and we will also use

00:04:21,080 --> 00:04:25,130
apache spark apache spark is an

00:04:23,599 --> 00:04:29,110
in-memory processing

00:04:25,130 --> 00:04:33,680
data processing engine it provides

00:04:29,110 --> 00:04:37,480
development api's for you know doing

00:04:33,680 --> 00:04:42,170
sequel workloads on big data also

00:04:37,480 --> 00:04:44,330
streaming API is for big data and it

00:04:42,170 --> 00:04:49,790
also has machine learning algorithms

00:04:44,330 --> 00:04:51,680
built-in into it you know in the spark

00:04:49,790 --> 00:04:54,320
was actually created as an alternative

00:04:51,680 --> 00:04:57,110
for Hadoop MapReduce because MapReduce

00:04:54,320 --> 00:04:59,210
was a batch processing it was pretty

00:04:57,110 --> 00:05:02,330
slow so they wanted to bring an

00:04:59,210 --> 00:05:04,960
interactive processing and that's that's

00:05:02,330 --> 00:05:08,060
the main goal of Apache spark is to

00:05:04,960 --> 00:05:12,860
provide a fast and interactive

00:05:08,060 --> 00:05:17,810
processing now you can use Java Scala or

00:05:12,860 --> 00:05:20,330
Python for coding in spark so this demo

00:05:17,810 --> 00:05:24,680
will also use spark that would be

00:05:20,330 --> 00:05:29,060
running on top of UDP is based Hadoop

00:05:24,680 --> 00:05:31,160
and it will use Hadoop yan as the

00:05:29,060 --> 00:05:35,140
resource manager so we will have a

00:05:31,160 --> 00:05:38,420
cluster of three nodes for this demo and

00:05:35,140 --> 00:05:41,690
we'll have spark running on top of epi

00:05:38,420 --> 00:05:44,300
and then we will also use H to a

00:05:41,690 --> 00:05:51,700
sparkling water which will be running on

00:05:44,300 --> 00:05:57,140
top of spark h2o is been an in-memory

00:05:51,700 --> 00:05:58,970
user-friendly machine learning API it is

00:05:57,140 --> 00:06:02,650
compatible with Hadoop it can run

00:05:58,970 --> 00:06:06,590
standalone or it can run on top of spark

00:06:02,650 --> 00:06:10,370
the reason that we are using his to a

00:06:06,590 --> 00:06:12,890
sparkling water on top of sparkles spark

00:06:10,370 --> 00:06:16,280
is very good in you know fast

00:06:12,890 --> 00:06:18,560
interactive data processing and his

00:06:16,280 --> 00:06:24,670
tours very gives provides a very

00:06:18,560 --> 00:06:24,670
user-friendly machine learning api's

00:06:25,990 --> 00:06:34,810
and both spark and his 20 they work well

00:06:31,270 --> 00:06:37,780
integrated spark has this concept of

00:06:34,810 --> 00:06:40,120
oddities and data frames to have the

00:06:37,780 --> 00:06:42,820
data and their memory and his to have

00:06:40,120 --> 00:06:45,910
has something called h2o frame so you

00:06:42,820 --> 00:06:49,570
can load data into sparks are dd's or

00:06:45,910 --> 00:06:51,790
data frame and then move it to his 20

00:06:49,570 --> 00:06:55,930
frame and you can even load it to histo

00:06:51,790 --> 00:07:00,850
frame and bring it back to oddities one

00:06:55,930 --> 00:07:03,520
caveat is knows h2o uses the same memory

00:07:00,850 --> 00:07:06,730
of the spark in the same executors so if

00:07:03,520 --> 00:07:09,760
you are loading your data into a sparks

00:07:06,730 --> 00:07:12,940
r DD or a data frame and then converting

00:07:09,760 --> 00:07:14,980
into a h2o frame there is no penalty but

00:07:12,940 --> 00:07:18,430
if you are doing the other way around if

00:07:14,980 --> 00:07:20,320
you are having h2o frame the dead are

00:07:18,430 --> 00:07:24,250
loaded into histo frame and you want to

00:07:20,320 --> 00:07:26,440
convert into a spark there's a copy that

00:07:24,250 --> 00:07:34,660
is made of the memory so you may have a

00:07:26,440 --> 00:07:38,680
little bit penalty hit his 20 comes with

00:07:34,660 --> 00:07:43,840
a visual visualization you I of ebb you

00:07:38,680 --> 00:07:46,870
I it's called his 20 flow basically

00:07:43,840 --> 00:07:49,660
that's a very user-friendly wait for you

00:07:46,870 --> 00:07:52,960
to choose various machine learning

00:07:49,660 --> 00:07:55,990
algorithms and easy way for you to build

00:07:52,960 --> 00:07:58,480
models on the data and then you can

00:07:55,990 --> 00:08:02,010
apply the machine learning algorithms

00:07:58,480 --> 00:08:02,010
and do predictive analysis

00:08:04,770 --> 00:08:10,560
so with that we'll get into the demo

00:08:07,860 --> 00:08:13,860
again this demo is based it's going to

00:08:10,560 --> 00:08:18,180
be in a three node cluster I to have

00:08:13,860 --> 00:08:23,340
Hadoop 2.7 spark 1.6 built with Scala

00:08:18,180 --> 00:08:28,139
2.10 Britain's deliberately build it

00:08:23,340 --> 00:08:31,199
with 2.11 because there is a known bug

00:08:28,139 --> 00:08:35,520
in sparkling water with one of the

00:08:31,199 --> 00:08:38,250
machine learning algorithms and these a

00:08:35,520 --> 00:08:41,130
node the cluster of node is running on

00:08:38,250 --> 00:08:43,529
the developer cloud thanks to the SDI

00:08:41,130 --> 00:08:47,130
team it's all running in the arm based

00:08:43,529 --> 00:08:49,890
hardware on the developer cloud and this

00:08:47,130 --> 00:08:58,290
all has been independently built and

00:08:49,890 --> 00:09:01,860
compiled on arm and tested so we are

00:08:58,290 --> 00:09:05,130
going to get data which is pretty much

00:09:01,860 --> 00:09:06,899
open from some of the cities they are

00:09:05,130 --> 00:09:09,690
going to collect the open data that they

00:09:06,899 --> 00:09:13,140
have exposed and then it is going to be

00:09:09,690 --> 00:09:16,470
stored in HDFS and it will be read

00:09:13,140 --> 00:09:19,350
through apache spark and converted into

00:09:16,470 --> 00:09:21,570
Apache spark our DD and then hits 20

00:09:19,350 --> 00:09:24,270
will read from there and converted to

00:09:21,570 --> 00:09:28,260
h2o frame and then we will look at the

00:09:24,270 --> 00:09:30,180
h2o phlo the web UI and we'll build a

00:09:28,260 --> 00:09:33,140
model and apply some machine learning

00:09:30,180 --> 00:09:33,140
algorithm on to it

00:09:54,430 --> 00:10:02,960
so I got the Hadoop and spark and

00:09:58,970 --> 00:10:06,260
sparkling water installed into it so

00:10:02,960 --> 00:10:11,690
lack of time I have also loaded the data

00:10:06,260 --> 00:10:20,230
into the HDFS so let me go ahead and

00:10:11,690 --> 00:10:20,230
start the spark

00:10:30,360 --> 00:10:39,839
so what this has done is it has created

00:10:33,120 --> 00:10:41,640
one master node and two worker nodes the

00:10:39,839 --> 00:10:44,220
spark driver will be running on the

00:10:41,640 --> 00:10:47,089
master and the executors will be running

00:10:44,220 --> 00:10:47,089
on the worker nodes

00:10:55,130 --> 00:11:01,820
and now i'm creating the sparkling cell

00:10:58,940 --> 00:11:09,290
which is a cell where you can put in

00:11:01,820 --> 00:11:16,760
your h2o commands and while that is

00:11:09,290 --> 00:11:19,510
going on i can show you the developer

00:11:16,760 --> 00:11:23,150
cloud instances that we are using is

00:11:19,510 --> 00:11:29,410
these are the nodes big data one two and

00:11:23,150 --> 00:11:33,680
three and spark comes also comes with a

00:11:29,410 --> 00:11:37,640
web UI to see the master and worker

00:11:33,680 --> 00:11:39,380
nodes so this is the master the web UI

00:11:37,640 --> 00:11:43,750
to see that you can see that where there

00:11:39,380 --> 00:11:43,750
is one master and to vocal

00:11:47,440 --> 00:11:59,590
and by default they get exposed through

00:11:50,410 --> 00:12:03,100
8080 port 8080 and you can also while we

00:11:59,590 --> 00:12:05,920
can also see the spark jobs and how they

00:12:03,100 --> 00:12:08,980
are running and that gets exposed

00:12:05,920 --> 00:12:11,710
through a port 40 40 and here you can

00:12:08,980 --> 00:12:16,720
see that the spark is up and running and

00:12:11,710 --> 00:12:20,490
the executors are up and these are the

00:12:16,720 --> 00:12:20,490
different stages the job goes to

00:12:29,000 --> 00:12:38,980
and this is the h2o phlo webui still

00:12:34,790 --> 00:12:38,980
loading up okay

00:12:45,470 --> 00:12:50,720
so you can see here like I said no it

00:12:47,690 --> 00:12:54,800
provides a easy way for you to build

00:12:50,720 --> 00:12:56,780
models and and this model menu there now

00:12:54,800 --> 00:13:01,190
you can select machine learning

00:12:56,780 --> 00:13:03,760
algorithms on it so we will go over the

00:13:01,190 --> 00:13:03,760
data set

00:13:13,820 --> 00:13:19,190
so I am selecting a data that New York

00:13:16,370 --> 00:13:21,860
City has exposed New York City has these

00:13:19,190 --> 00:13:24,890
bikes that they have placed all around

00:13:21,860 --> 00:13:28,160
the city for the people to rent and then

00:13:24,890 --> 00:13:31,220
they can drive so this data has the rent

00:13:28,160 --> 00:13:33,410
the information about no people what

00:13:31,220 --> 00:13:36,290
time they rent how many miles they ride

00:13:33,410 --> 00:13:40,670
on the bike how frequently they write it

00:13:36,290 --> 00:13:45,680
and how long they rented for for a day

00:13:40,670 --> 00:13:49,910
or some now a week so we just imported

00:13:45,680 --> 00:13:53,210
that into H whoa and you can parse this

00:13:49,910 --> 00:13:55,760
file when you do the parse it it kicks

00:13:53,210 --> 00:13:58,390
off jobs behind the scene and that's run

00:13:55,760 --> 00:13:58,390
in this part

00:14:03,070 --> 00:14:08,050
so you can see the job that progressed

00:14:08,830 --> 00:14:15,860
and you can view the data getting parse

00:14:12,320 --> 00:14:17,630
this is the data that is parsed and if

00:14:15,860 --> 00:14:22,520
you want to see actual data you can

00:14:17,630 --> 00:14:27,350
click on the view data itself and you

00:14:22,520 --> 00:14:29,930
can see here the date and time and the

00:14:27,350 --> 00:14:33,860
tricks that they had made the in the

00:14:29,930 --> 00:14:41,720
blast 24 hours that's the total trips

00:14:33,860 --> 00:14:45,680
and the miles travel in a day and how

00:14:41,720 --> 00:14:51,760
many people are renting it so you can

00:14:45,680 --> 00:14:51,760
use this data now go and create a model

00:14:54,280 --> 00:14:59,810
to create a model what we are going to

00:14:56,660 --> 00:15:02,600
do we are going to first split the data

00:14:59,810 --> 00:15:07,820
into eighty percent and twenty percent

00:15:02,600 --> 00:15:10,960
eighty percent is to train and twenty

00:15:07,820 --> 00:15:10,960
percent is to test

00:15:15,660 --> 00:15:19,920
so we split the data now into eighty

00:15:18,360 --> 00:15:21,990
percent and fornication the whole data

00:15:19,920 --> 00:15:23,430
gets split into two sections eighty

00:15:21,990 --> 00:15:26,370
percent of the data and Tory person of

00:15:23,430 --> 00:15:32,930
the data and now you can go and build a

00:15:26,370 --> 00:15:36,230
model and you can choose an algorithm I

00:15:32,930 --> 00:15:42,900
am going to select generalized linear

00:15:36,230 --> 00:15:46,830
modeling and for this model now i will

00:15:42,900 --> 00:15:50,790
say use the data eighty percent data to

00:15:46,830 --> 00:15:53,420
train and to validate use the tony

00:15:50,790 --> 00:15:53,420
percent data

00:16:09,120 --> 00:16:14,790
so that builds the model and you can

00:16:12,690 --> 00:16:16,589
actually save this model and if you have

00:16:14,790 --> 00:16:19,890
new data you can use the same model

00:16:16,589 --> 00:16:26,430
which is already trained and you can use

00:16:19,890 --> 00:16:28,529
that to do the predictive analysis so

00:16:26,430 --> 00:16:35,160
you can see that model and you can it

00:16:28,529 --> 00:16:37,800
shows a graph also and if you want to do

00:16:35,160 --> 00:16:41,400
the product pelicula so you just click

00:16:37,800 --> 00:16:45,410
the predict and you can select the model

00:16:41,400 --> 00:16:45,410
and click on product

00:16:59,880 --> 00:17:07,650
so we at the big data team so we've been

00:17:04,740 --> 00:17:09,750
working on quite a lot of synthetic

00:17:07,650 --> 00:17:12,150
workloads and small workloads that comes

00:17:09,750 --> 00:17:14,160
with the micro benchmarking workloads

00:17:12,150 --> 00:17:15,930
that comes with the Hadoop now we are

00:17:14,160 --> 00:17:19,920
going into the next stage of know

00:17:15,930 --> 00:17:22,500
looking at real world Dara and the and

00:17:19,920 --> 00:17:26,750
even benchmarking against it so that

00:17:22,500 --> 00:17:26,750
also leads me to the next section

00:17:38,200 --> 00:17:44,169
so we're going to talk about the

00:17:42,250 --> 00:17:45,809
benchmarks why we need benchmark what

00:17:44,169 --> 00:17:49,419
are the different types of benchmarks

00:17:45,809 --> 00:17:51,460
that's out there for big data and we are

00:17:49,419 --> 00:17:54,820
going to go into each one of them and

00:17:51,460 --> 00:17:56,980
give an overview of them and we worked

00:17:54,820 --> 00:18:01,899
on quite a lot of benchmarking last few

00:17:56,980 --> 00:18:04,330
weeks and we will go over what those

00:18:01,899 --> 00:18:07,029
benchmarks are far and what what kind of

00:18:04,330 --> 00:18:09,730
metrics they give out and what are the

00:18:07,029 --> 00:18:17,289
issues that we have faced and these are

00:18:09,730 --> 00:18:20,409
specific for arm so obviously so we saw

00:18:17,289 --> 00:18:22,870
this demo so we know that there is quite

00:18:20,409 --> 00:18:26,110
a lot of potential for big data so a lot

00:18:22,870 --> 00:18:27,760
of there's a lot of interest lot of

00:18:26,110 --> 00:18:30,250
people talking about smart cities and

00:18:27,760 --> 00:18:32,260
there's lot of open data available a lot

00:18:30,250 --> 00:18:35,260
of people are starting to combine data

00:18:32,260 --> 00:18:38,019
and know like in the previous demo you

00:18:35,260 --> 00:18:40,299
could use multiple data sets and use a

00:18:38,019 --> 00:18:42,549
spark sequel then start combining and

00:18:40,299 --> 00:18:45,309
look at machine learning so there is a

00:18:42,549 --> 00:18:47,500
lot of potential so that also leads the

00:18:45,309 --> 00:18:50,620
to that there are so much variety of

00:18:47,500 --> 00:18:52,720
data right there's different types of

00:18:50,620 --> 00:18:57,750
solutions that you can come up with with

00:18:52,720 --> 00:19:02,470
the machine learning so but how do you

00:18:57,750 --> 00:19:04,210
how do you benchmark between how do you

00:19:02,470 --> 00:19:05,950
how do you differentiate between a

00:19:04,210 --> 00:19:08,350
particular solution with another

00:19:05,950 --> 00:19:10,630
solution so we definitely need some kind

00:19:08,350 --> 00:19:12,669
of benchmark from from a hardware

00:19:10,630 --> 00:19:14,850
perspective and also from a software

00:19:12,669 --> 00:19:14,850
perspective

00:19:18,400 --> 00:19:25,510
and also you know big data there's this

00:19:23,170 --> 00:19:28,090
the data is growing in a very rapid

00:19:25,510 --> 00:19:32,470
phase and the types of data that is also

00:19:28,090 --> 00:19:34,840
or you know very diverse you have data

00:19:32,470 --> 00:19:37,330
no huge petabytes of data someplace

00:19:34,840 --> 00:19:39,040
sitting and you want to analyze and you

00:19:37,330 --> 00:19:41,410
may have data for coming from search

00:19:39,040 --> 00:19:43,870
engines you want to index that you may

00:19:41,410 --> 00:19:45,880
have data that is coming through as a

00:19:43,870 --> 00:19:48,070
streaming data you may have data

00:19:45,880 --> 00:19:50,650
warehousing they're aware you may want

00:19:48,070 --> 00:19:52,960
to do a lot of reads and writes you want

00:19:50,650 --> 00:19:54,670
to do filtering of data and things like

00:19:52,960 --> 00:19:59,110
that and you may want to do machine

00:19:54,670 --> 00:20:04,750
learning so there's quite a lot of data

00:19:59,110 --> 00:20:08,040
and it's growing so it becomes more and

00:20:04,750 --> 00:20:11,890
more important why we need benchmarking

00:20:08,040 --> 00:20:13,990
so now with benchmarking there are no

00:20:11,890 --> 00:20:15,580
various types no you can have micro

00:20:13,990 --> 00:20:18,340
benchmarks that comes along with the

00:20:15,580 --> 00:20:20,800
Hadoop itself for no sorting and grab

00:20:18,340 --> 00:20:23,080
and work word count and terrace art and

00:20:20,800 --> 00:20:26,530
things like that there was also

00:20:23,080 --> 00:20:28,750
component benchmarks for each components

00:20:26,530 --> 00:20:35,050
that you can do and application level

00:20:28,750 --> 00:20:38,800
benchmarks so I'd like to ask maurice to

00:20:35,050 --> 00:20:41,920
come over and no explain over some of

00:20:38,800 --> 00:20:46,770
the benchmarks he'll go give an overview

00:20:41,920 --> 00:20:46,770
and go in tapped into each one of them

00:20:50,619 --> 00:20:57,590
okay we have actually big data team sit

00:20:55,549 --> 00:21:01,970
together and we have listed a couple of

00:20:57,590 --> 00:21:06,169
benchmarks first thing is this is my

00:21:01,970 --> 00:21:08,869
grappling point micro benchmarks so this

00:21:06,169 --> 00:21:11,299
Bank my scheduling matrix like execution

00:21:08,869 --> 00:21:17,139
time and proper resource utilization was

00:21:11,299 --> 00:21:22,759
a and the hybrid dfx I oh and a mplab

00:21:17,139 --> 00:21:27,889
this IP 3 micro benchmarks workloads are

00:21:22,759 --> 00:21:31,940
like for a high paint salt word count

00:21:27,889 --> 00:21:37,369
Terra sort and pagerank a means based

00:21:31,940 --> 00:21:41,950
classification and index and for DFS i/o

00:21:37,369 --> 00:21:46,539
is a general and the rewrite Aaron

00:21:41,950 --> 00:21:50,899
remove the data for a MapReduce jobs

00:21:46,539 --> 00:22:00,889
mplab benchmarks workloads are like part

00:21:50,899 --> 00:22:03,710
of calda workloads so this microbial was

00:22:00,889 --> 00:22:10,960
basically use of for testing a Hadoop

00:22:03,710 --> 00:22:10,960
high and disease at stax software times

00:22:11,499 --> 00:22:26,419
next one is a tpc bent once we have like

00:22:22,759 --> 00:22:34,659
consider three benchmarks tpc xhs t PCH

00:22:26,419 --> 00:22:40,820
and DP c.d.s for these workloads are

00:22:34,659 --> 00:22:45,649
like a chess generator will go in detail

00:22:40,820 --> 00:22:48,200
these benchmarks later then data errors

00:22:45,649 --> 00:22:50,960
in the operations and decision supports

00:22:48,200 --> 00:22:56,149
like this for these benchmarks matrix

00:22:50,960 --> 00:22:59,450
are like performance price of energy Oh

00:22:56,149 --> 00:23:04,399
like execution time and throughput are

00:22:59,450 --> 00:23:10,940
the for the t PCH and tpc DSBN

00:23:04,399 --> 00:23:13,970
benchmarks the software stacks are hadoo

00:23:10,940 --> 00:23:19,909
hive and pig for these testing can use

00:23:13,970 --> 00:23:28,639
this next one is like a synthetic

00:23:19,909 --> 00:23:30,679
benchmarks or swim grade next big mix mr

00:23:28,639 --> 00:23:34,279
bench are the most of these main sponsor

00:23:30,679 --> 00:23:38,629
comes with Hadoop actually when you

00:23:34,279 --> 00:23:43,960
install her dope it will be a in the

00:23:38,629 --> 00:23:43,960
examples of the part of java file

00:23:49,309 --> 00:24:00,070
so big data bench is also a in the you

00:23:56,629 --> 00:24:00,070
will get it when you installed Lijadu

00:24:00,340 --> 00:24:14,360
this matrix is throughput memory and CPU

00:24:07,580 --> 00:24:17,809
are we can use it for the benchmarking

00:24:14,360 --> 00:24:23,330
this and a software stacks are like

00:24:17,809 --> 00:24:24,799
Hadoop and HJ simple lot of things

00:24:23,330 --> 00:24:33,999
should be covered in the big data range

00:24:24,799 --> 00:24:38,029
actually heard of benchmarks and test ol

00:24:33,999 --> 00:24:39,830
like a psycho like Hadoop distribution

00:24:38,029 --> 00:24:45,799
comes with lot of danger ox number of

00:24:39,830 --> 00:24:51,350
regions test DFS I oh and then bent my

00:24:45,799 --> 00:24:55,659
range then garage terragen their assault

00:24:51,350 --> 00:24:59,029
Tara validate you can you can check the

00:24:55,659 --> 00:25:03,559
different benchmarks with a below

00:24:59,029 --> 00:25:04,940
comment actually while running these

00:25:03,559 --> 00:25:08,779
veins powers you can use the time

00:25:04,940 --> 00:25:11,950
command so that the example snapshot

00:25:08,779 --> 00:25:16,039
like output will be like that where the

00:25:11,950 --> 00:25:20,110
you will get the matter is actually this

00:25:16,039 --> 00:25:20,110
is a sample example

00:25:23,299 --> 00:25:30,860
okay pterosaur Jared terragen terrace

00:25:27,570 --> 00:25:34,530
water and Tara validate basically

00:25:30,860 --> 00:25:40,549
terragen generously data set and Tara

00:25:34,530 --> 00:25:45,090
sword Aaron's runs on the input data

00:25:40,549 --> 00:25:50,520
validate will validate the generated not

00:25:45,090 --> 00:25:55,130
actually the actually we did run this

00:25:50,520 --> 00:25:59,190
benchmark and you can have a look into

00:25:55,130 --> 00:26:01,620
wiki page how to compile and configure

00:25:59,190 --> 00:26:06,780
and then this kind of marks on I'm 64

00:26:01,620 --> 00:26:10,230
architecture high bench actually

00:26:06,780 --> 00:26:15,809
contains in line typical hadouken

00:26:10,230 --> 00:26:20,669
Sparkle clothes and salt word count

00:26:15,809 --> 00:26:23,970
Paris or at the FSI Cole etc and it uses

00:26:20,669 --> 00:26:31,020
the actually a jet live compression for

00:26:23,970 --> 00:26:33,360
input and output there are actually lack

00:26:31,020 --> 00:26:38,520
of a are 64 bits and lack of

00:26:33,360 --> 00:26:42,299
documentation how to configure build and

00:26:38,520 --> 00:26:45,090
run this benchmark actually so you can

00:26:42,299 --> 00:26:49,260
you can have a look into our wiki page

00:26:45,090 --> 00:26:57,299
what we had created how to do this stuff

00:26:49,260 --> 00:27:01,679
item yes the FSI oh it's a part of

00:26:57,299 --> 00:27:03,540
hadoop mapreduce client of job then you

00:27:01,679 --> 00:27:08,040
will get this main part when you install

00:27:03,540 --> 00:27:13,230
the hadoop on your system so basically

00:27:08,040 --> 00:27:16,340
just the name node and data node and it

00:27:13,230 --> 00:27:19,730
helps to discover the bottlenecks in

00:27:16,340 --> 00:27:19,730
your network

00:27:23,139 --> 00:27:30,429
when you run this benchmark you can use

00:27:26,509 --> 00:27:34,490
the you can first write it and then read

00:27:30,429 --> 00:27:37,460
followed by read so this is how this big

00:27:34,490 --> 00:27:41,749
mark will work actually and the results

00:27:37,460 --> 00:27:47,059
are stored in the text PDF sio results

00:27:41,749 --> 00:27:49,519
log file or you can use a arias file for

00:27:47,059 --> 00:27:58,909
the to use a different filing or

00:27:49,519 --> 00:28:06,350
something hi test bench is like based on

00:27:58,909 --> 00:28:10,129
our PPC H and T pcds benchmark from the

00:28:06,350 --> 00:28:14,659
experiment the Apache high on any data

00:28:10,129 --> 00:28:19,539
scale actually it contains the data

00:28:14,659 --> 00:28:19,539
generator and that a set of data queries

00:28:19,570 --> 00:28:29,419
just the basic high performance on large

00:28:22,759 --> 00:28:34,659
data 60 we did run this benchmark and we

00:28:29,419 --> 00:28:34,659
have created a wiki page for the same

00:28:35,740 --> 00:28:45,200
MapReduce benchmark are what it does is

00:28:39,919 --> 00:28:49,369
basically a loops a small number of like

00:28:45,200 --> 00:28:52,999
a small job number of crimes and checks

00:28:49,369 --> 00:28:55,940
with the recurrence the job runs are

00:28:52,999 --> 00:29:02,720
very responsive or not running

00:28:55,940 --> 00:29:04,820
efficiently on your on your cluster puts

00:29:02,720 --> 00:29:06,769
the focus on MapReduce layer as its

00:29:04,820 --> 00:29:15,470
impact of it DFS they are very limited

00:29:06,769 --> 00:29:19,960
okay the test command is like 250 small

00:29:15,470 --> 00:29:28,060
van and the example output is

00:29:19,960 --> 00:29:33,280
you can see NN binge and a nun bench

00:29:28,060 --> 00:29:37,270
without MapReduce a load and testing

00:29:33,280 --> 00:29:40,270
name node so continuously right rename

00:29:37,270 --> 00:29:46,690
and delete operation delete operations

00:29:40,270 --> 00:29:51,340
on small files this does actually kind

00:29:46,690 --> 00:29:54,810
of a like test test so if you run this

00:29:51,340 --> 00:29:58,440
benchmark it will check whether your

00:29:54,810 --> 00:29:58,440
name not disturb

00:30:06,080 --> 00:30:13,950
the the sample command is as below just

00:30:09,720 --> 00:30:20,310
command and if you want to run the NN

00:30:13,950 --> 00:30:25,800
range benchmark with red use you can use

00:30:20,310 --> 00:30:29,220
the option hyphen reduce and maps if you

00:30:25,800 --> 00:30:31,950
do not want to run I mean NN bench

00:30:29,220 --> 00:30:38,820
without a mark we can use you can remove

00:30:31,950 --> 00:30:44,760
all those perpetual TPC is a divisive in

00:30:38,820 --> 00:30:49,110
park UPC say as it old one body standard

00:30:44,760 --> 00:30:50,820
body we try to run the TPC a HS named

00:30:49,110 --> 00:30:56,190
mark and we are currently facing some

00:30:50,820 --> 00:31:02,700
issues with competition we didn't turn

00:30:56,190 --> 00:31:09,060
PPC edge vs and PPC Syrian pass will try

00:31:02,700 --> 00:31:13,820
to do it in upcoming days actually be

00:31:09,060 --> 00:31:17,280
PCH focus of the adults queries and the

00:31:13,820 --> 00:31:23,460
TPC des is the standard win 5-4 decision

00:31:17,280 --> 00:31:27,050
support ppcc is a online transaction or

00:31:23,460 --> 00:31:27,050
ATP benchmark actually

00:31:28,130 --> 00:31:35,980
our TPC xhs benchmark so x is for the

00:31:33,410 --> 00:31:39,950
ex-player's and it is for Hadoop and

00:31:35,980 --> 00:31:46,820
access was sort it comes with a sect it

00:31:39,950 --> 00:31:53,060
and it contains a script to execute the

00:31:46,820 --> 00:31:57,860
benchmark and Java code to execute the

00:31:53,060 --> 00:31:59,360
benchmark load today so execution this

00:31:57,860 --> 00:32:03,950
is how you need to do the execution

00:31:59,360 --> 00:32:08,840
actually a valid run consists of five

00:32:03,950 --> 00:32:11,770
separate phases actually so with all of

00:32:08,840 --> 00:32:15,680
their execution the benchmark test

00:32:11,770 --> 00:32:19,190
consists of programs are run with the

00:32:15,680 --> 00:32:26,570
lower and lung run with higher RTP CHS

00:32:19,190 --> 00:32:30,100
performance matrix and no configuration

00:32:26,570 --> 00:32:35,410
or tuning changes or rebooting of your

00:32:30,100 --> 00:32:41,570
system it is not allowed in between

00:32:35,410 --> 00:32:45,680
while doing this benchmark actually okay

00:32:41,570 --> 00:32:51,770
see the difference between PPC a and

00:32:45,680 --> 00:32:54,650
spec models TPC is actually a

00:32:51,770 --> 00:32:59,150
specification based model spec models

00:32:54,650 --> 00:33:03,320
say it bases on here actually in TBC

00:32:59,150 --> 00:33:07,910
model performance price energy in one

00:33:03,320 --> 00:33:11,090
beam path and here no inspect model the

00:33:07,910 --> 00:33:17,960
performance and energy in this separate

00:33:11,090 --> 00:33:23,360
benchmarks t pcs end to end and a spec

00:33:17,960 --> 00:33:27,350
model is a hacer web-centric TPC model

00:33:23,360 --> 00:33:32,120
execute actually multiple tears expect

00:33:27,350 --> 00:33:35,529
model execute a single diaphragm tpc

00:33:32,120 --> 00:33:38,390
model follows the independent review and

00:33:35,529 --> 00:33:46,250
spec model is a summary disclosure

00:33:38,390 --> 00:33:49,730
actually DPC is a technology conference

00:33:46,250 --> 00:34:06,620
and like spec model is a research group

00:33:49,730 --> 00:34:10,099
actually big range Ganesh this okay big

00:34:06,620 --> 00:34:14,780
bench is sweet of benchmarking sweet to

00:34:10,099 --> 00:34:18,859
a benchmarking tools it actually borrows

00:34:14,780 --> 00:34:21,770
from various other benchmarking sweet

00:34:18,859 --> 00:34:25,010
all now including TPC some of the micro

00:34:21,770 --> 00:34:27,139
benchmarking and it takes some other

00:34:25,010 --> 00:34:30,409
workloads from them and it has added its

00:34:27,139 --> 00:34:33,470
own workload so right and it is evolving

00:34:30,409 --> 00:34:36,970
quite a bit it is worked by cloudera and

00:34:33,470 --> 00:34:40,429
in tow and there is lot of academic

00:34:36,970 --> 00:34:42,950
interest in this so this is evolving a

00:34:40,429 --> 00:34:47,240
lot this one of the main standards and

00:34:42,950 --> 00:34:52,669
big data benchmarking only thing is it

00:34:47,240 --> 00:34:55,839
focuses mainly on structured data less

00:34:52,669 --> 00:34:55,839
on unstructured data

00:34:58,820 --> 00:35:04,440
so the next part bench will spark been

00:35:02,130 --> 00:35:09,750
to specific more specific to apache

00:35:04,440 --> 00:35:14,630
spark you know we currently are working

00:35:09,750 --> 00:35:17,730
on it we are having few is used in

00:35:14,630 --> 00:35:22,340
testing it running the workloads we were

00:35:17,730 --> 00:35:25,980
able to build it on arm but when we run

00:35:22,340 --> 00:35:28,380
example workloads there is a kill signal

00:35:25,980 --> 00:35:31,380
that is getting called and then it kills

00:35:28,380 --> 00:35:36,290
him so we are still debugging it trying

00:35:31,380 --> 00:35:36,290
to figure out you know how to do this

00:35:36,830 --> 00:35:40,650
obviously there is a lack of

00:35:38,790 --> 00:35:42,810
documentation there's lack of

00:35:40,650 --> 00:35:47,370
documentation with many other benchmarks

00:35:42,810 --> 00:35:49,890
in regards to a arc 64 so that's why

00:35:47,370 --> 00:35:51,840
we've been going through each benchmark

00:35:49,890 --> 00:35:55,050
and we are trying to document everything

00:35:51,840 --> 00:35:57,720
and put it in the linaro Vicki so we

00:35:55,050 --> 00:36:07,230
have length everywhere so you could go

00:35:57,720 --> 00:36:11,160
and check it out in those and grid makes

00:36:07,230 --> 00:36:15,510
and no it says bent synthetic benchmark

00:36:11,160 --> 00:36:19,770
again focused on MapReduce and his DFS

00:36:15,510 --> 00:36:23,610
performance it has load job and sleep

00:36:19,770 --> 00:36:25,890
job noid kind of for the load job it

00:36:23,610 --> 00:36:29,340
looks at the history logs and loads it

00:36:25,890 --> 00:36:32,160
I'd use Roman for that and sleep job is

00:36:29,340 --> 00:36:37,800
basically it invokes jobs and puts them

00:36:32,160 --> 00:36:40,650
into sleep you can run them in a run

00:36:37,800 --> 00:36:44,550
this job benchmarking in a stress more

00:36:40,650 --> 00:36:47,400
or you can do a replay of the previous

00:36:44,550 --> 00:36:50,090
one and check how it performs compared

00:36:47,400 --> 00:36:56,390
to the other or you can do

00:36:50,090 --> 00:36:59,390
serial of benchmarks next is pig mix

00:36:56,390 --> 00:37:01,640
this is folk this in particular to

00:36:59,390 --> 00:37:04,750
Apache pig it's more of a data

00:37:01,640 --> 00:37:07,750
warehousing kind of a performance

00:37:04,750 --> 00:37:07,750
benchmark

00:37:15,160 --> 00:37:23,890
this swim is another body which provides

00:37:18,800 --> 00:37:23,890
benchmark focused on MapReduce as well

00:37:27,700 --> 00:37:36,290
an amp lab is UC Berkeley created

00:37:32,630 --> 00:37:38,750
benchmarking sweet know it at all it

00:37:36,290 --> 00:37:45,080
focuses more on data warehousing tools

00:37:38,750 --> 00:37:47,450
like hive Impala or even days it also

00:37:45,080 --> 00:37:51,020
focuses on pipeline data pipeline

00:37:47,450 --> 00:37:56,170
creation so it know you can use that for

00:37:51,020 --> 00:37:56,170
apache spark benchmarking as well

00:38:02,070 --> 00:38:07,980
another suite of product is Big Data

00:38:04,290 --> 00:38:13,970
benchmark this is different from the big

00:38:07,980 --> 00:38:26,430
benchmark and this focuses on sequential

00:38:13,970 --> 00:38:28,950
multi-threaded workloads with that these

00:38:26,430 --> 00:38:30,600
are the links and all the effort that we

00:38:28,950 --> 00:38:33,690
have put in in running all these

00:38:30,600 --> 00:38:36,780
benchmarks and figuring out the issues

00:38:33,690 --> 00:38:39,660
and some of the places we didn't have a

00:38:36,780 --> 00:38:42,510
arvixe so we had to compile them and

00:38:39,660 --> 00:38:45,660
build the hair bits and you will have

00:38:42,510 --> 00:38:48,750
all the information and this even the AR

00:38:45,660 --> 00:38:56,820
bits the links to them will all be in

00:38:48,750 --> 00:39:00,380
here that this concludes the talk I will

00:38:56,820 --> 00:39:00,380
open it up for questions if any

00:39:10,080 --> 00:39:12,950
science

00:39:16,539 --> 00:39:24,609
we have the wiki page for the demo also

00:39:20,969 --> 00:39:27,369
including how to build the Hadoop native

00:39:24,609 --> 00:39:32,229
aduke ODP I suspect based and how to

00:39:27,369 --> 00:39:37,569
build spark his h2o sparkling water and

00:39:32,229 --> 00:39:39,759
even how to run those demos you can go

00:39:37,569 --> 00:39:47,699
and check out the wiki page for that as

00:39:39,759 --> 00:39:47,699
well thank you

00:39:55,820 --> 00:39:57,880

YouTube URL: https://www.youtube.com/watch?v=f-0QX8yTSJo


