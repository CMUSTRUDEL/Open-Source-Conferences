Title: LAS16-201: ART JIT Android N
Publication date: 2016-09-30
Playlist: Linaro Connect Las Vegas 2016
Description: 
	LAS16-201: ART JIT in Android N
Speakers: Xueliang Zhong
Date: September 27, 2016

★ Session Description ★
Android runtime (ART) has evolved from an AOT compiler (in Android L & M) to a hybrid mode runtime (in Android N) which combines fast interpreter, JIT compiler and profile guided AOT compiler. In this talk, we’ll take a look at all these important changes in Android N. For example, the design and implementation of JIT, hybrid mode, tooling support, etc. This talk is meant to help Linaro members and developers to have a deeper understanding of ART in Android N, and to help them face the challenges of the new behaviors of Android runtime.

★ Resources ★
Etherpad: pad.linaro.org/p/las16-201
Presentations & Videos: http://connect.linaro.org/resource/las16/las16-201/

★ Event Details ★
Linaro Connect Las Vegas 2016 – #LAS16
September 26-30, 2016
http://www.linaro.org
http://connect.linaro.org
Captions: 
	00:00:09,019 --> 00:00:16,139
good morning everyone my name is really

00:00:12,570 --> 00:00:21,869
I'm John I'm currently working in the

00:00:16,139 --> 00:00:25,350
narrow oMG art team so the new Android

00:00:21,869 --> 00:00:28,619
in has come in this talk I would like to

00:00:25,350 --> 00:00:33,230
share what we've learned about the new

00:00:28,619 --> 00:00:35,219
changes in the art in Android N and

00:00:33,230 --> 00:00:37,399
actually there are some quite

00:00:35,219 --> 00:00:41,790
interesting findings and behaviors in

00:00:37,399 --> 00:00:48,149
the new art did like I would like to

00:00:41,790 --> 00:00:50,940
share so I'm gonna talk about what and

00:00:48,149 --> 00:00:55,590
with Braun Tamizh and the current new

00:00:50,940 --> 00:00:58,170
challenges for the Android runtime and

00:00:55,590 --> 00:01:03,090
in my opinion these challenges actually

00:00:58,170 --> 00:01:05,909
driving the new changes in Android

00:01:03,090 --> 00:01:10,430
runtime we're gonna take a look at how

00:01:05,909 --> 00:01:14,369
the new changes in art in Android n are

00:01:10,430 --> 00:01:19,740
implemented we're gonna introduce a few

00:01:14,369 --> 00:01:22,140
tools that I think are helpful useful

00:01:19,740 --> 00:01:25,950
for the developers to analyze those new

00:01:22,140 --> 00:01:28,049
modes and new threat in Android n and

00:01:25,950 --> 00:01:31,259
we're gonna hear some performance data

00:01:28,049 --> 00:01:33,479
and findings about the new art behavior

00:01:31,259 --> 00:01:39,420
and hopefully there will be some

00:01:33,479 --> 00:01:43,350
question and answers so art stands for

00:01:39,420 --> 00:01:47,430
Android runtime it is a quite important

00:01:43,350 --> 00:01:51,299
layer in the Android software stack so

00:01:47,430 --> 00:01:54,869
most part of android framework and most

00:01:51,299 --> 00:01:59,869
of android applications are written in

00:01:54,869 --> 00:02:04,409
java and compiled into a native sorry a

00:01:59,869 --> 00:02:07,469
bytecode format file cortex bytecode

00:02:04,409 --> 00:02:12,930
file and these text byte code files are

00:02:07,469 --> 00:02:13,800
running on art so no matter what we

00:02:12,930 --> 00:02:15,960
choose to

00:02:13,800 --> 00:02:18,600
implement art you can be interpretation

00:02:15,960 --> 00:02:22,290
just-in-time compilation or head of time

00:02:18,600 --> 00:02:25,500
compilation and this art should meet or

00:02:22,290 --> 00:02:29,490
the performance requirement that I this

00:02:25,500 --> 00:02:32,220
here so we hope that our can run

00:02:29,490 --> 00:02:36,660
applications really fast and smoothly

00:02:32,220 --> 00:02:38,250
we hope art can start and launch

00:02:36,660 --> 00:02:42,290
application really fast

00:02:38,250 --> 00:02:47,010
we hope applications can install on

00:02:42,290 --> 00:02:49,290
Android really fast and we hope that no

00:02:47,010 --> 00:02:52,100
matter what internal behavior art is

00:02:49,290 --> 00:02:54,660
doing it may be a compilation

00:02:52,100 --> 00:02:57,090
interpretation memories management

00:02:54,660 --> 00:02:59,820
garbage collection no matter what

00:02:57,090 --> 00:03:02,610
behaviors in the art we hope these

00:02:59,820 --> 00:03:06,630
behaviors brings minimal impact to the

00:03:02,610 --> 00:03:09,930
whole Android system so in my opinion

00:03:06,630 --> 00:03:13,980
all of the runtime system used in

00:03:09,930 --> 00:03:16,560
previous Android versions I think none

00:03:13,980 --> 00:03:21,540
of them actually meet all the reforms

00:03:16,560 --> 00:03:24,540
requirement a list here for example in

00:03:21,540 --> 00:03:28,200
Android KitKat at that time we were

00:03:24,540 --> 00:03:32,700
using a just-in-time solution so the

00:03:28,200 --> 00:03:37,140
idea is that when the user installed app

00:03:32,700 --> 00:03:39,480
from Google Play we do not do any

00:03:37,140 --> 00:03:43,560
compilation and installation time what

00:03:39,480 --> 00:03:47,150
we do is we extract the text bytecode

00:03:43,560 --> 00:03:50,239
file from the apk file of the app and

00:03:47,150 --> 00:03:54,510
copied it on the device storage and

00:03:50,239 --> 00:03:57,660
basically the installation is done until

00:03:54,510 --> 00:04:01,260
the user start to use the app and we use

00:03:57,660 --> 00:04:04,980
dynamic compilation the JIT to

00:04:01,260 --> 00:04:11,459
dynamically compile those text byte code

00:04:04,980 --> 00:04:14,100
into our native code so the advantage of

00:04:11,459 --> 00:04:17,190
this bottle is that the user can help

00:04:14,100 --> 00:04:20,790
fast installation and because we do not

00:04:17,190 --> 00:04:25,280
cash or store any compiled to native

00:04:20,790 --> 00:04:29,270
code file device storage so we have

00:04:25,280 --> 00:04:34,840
storage consumption but the performance

00:04:29,270 --> 00:04:38,270
overhead and the drawback here is that

00:04:34,840 --> 00:04:41,570
we have JIT compilation overhead at

00:04:38,270 --> 00:04:44,060
application runtime and the dynamic

00:04:41,570 --> 00:04:47,120
compilation behavior also consumes

00:04:44,060 --> 00:04:51,820
battery so makes the battery life

00:04:47,120 --> 00:04:56,030
shorter in the rest very recent

00:04:51,820 --> 00:04:58,160
marshmallow it use a completely

00:04:56,030 --> 00:05:01,040
different approach which is ahead of

00:04:58,160 --> 00:05:04,940
time compilation so the idea here is

00:05:01,040 --> 00:05:08,630
that when the user installed the app

00:05:04,940 --> 00:05:12,110
from Google Play at installation time we

00:05:08,630 --> 00:05:15,169
will try to compile all the decks fight

00:05:12,110 --> 00:05:18,979
code into native code at installation

00:05:15,169 --> 00:05:23,210
time and store the compiled native code

00:05:18,979 --> 00:05:26,290
file into device storage and when users

00:05:23,210 --> 00:05:29,930
started user app all the bytecode

00:05:26,290 --> 00:05:33,919
already compiled into native code so we

00:05:29,930 --> 00:05:37,430
get fast application startup performance

00:05:33,919 --> 00:05:41,930
in fast application runtime performance

00:05:37,430 --> 00:05:44,240
and because we do not do any on-the-fly

00:05:41,930 --> 00:05:48,950
compilation we actually saves battery

00:05:44,240 --> 00:05:51,140
power but the drawback of this model is

00:05:48,950 --> 00:05:53,570
that because we push all the compilation

00:05:51,140 --> 00:05:56,240
behavior at application installation

00:05:53,570 --> 00:06:01,220
time actually the user may experience

00:05:56,240 --> 00:06:05,750
very long installation time and because

00:06:01,220 --> 00:06:08,630
we try to store the compiled code file

00:06:05,750 --> 00:06:13,130
into device storage actually it may take

00:06:08,630 --> 00:06:16,850
a lot of device storage especially for

00:06:13,130 --> 00:06:20,630
those big apps with a relatively big to

00:06:16,850 --> 00:06:22,880
expect code file this is particularly a

00:06:20,630 --> 00:06:28,130
challenge for entry level device with

00:06:22,880 --> 00:06:30,440
limited storage and here are a few more

00:06:28,130 --> 00:06:33,320
challenges for the ahead of time

00:06:30,440 --> 00:06:38,150
compilation model nowadays I think first

00:06:33,320 --> 00:06:38,840
is system update behavior system update

00:06:38,150 --> 00:06:42,889
is

00:06:38,840 --> 00:06:46,479
quite popular common seeing behavior

00:06:42,889 --> 00:06:50,210
nowadays it can be the user update the

00:06:46,479 --> 00:06:53,479
phone android device with OTA

00:06:50,210 --> 00:06:56,479
over-the-air update and as a developer I

00:06:53,479 --> 00:06:59,360
may also change the source code of the

00:06:56,479 --> 00:07:01,820
Android source code a little bit and

00:06:59,360 --> 00:07:05,090
recompile it and flash the system image

00:07:01,820 --> 00:07:08,600
on the device and in all these system

00:07:05,090 --> 00:07:11,900
update behaviors what happens there is

00:07:08,600 --> 00:07:14,030
that actually all the applications that

00:07:11,900 --> 00:07:17,330
has been installed on the device will be

00:07:14,030 --> 00:07:19,880
reinstalled and recompiled during system

00:07:17,330 --> 00:07:23,810
update so if we happen to have lots of

00:07:19,880 --> 00:07:25,850
applications installed on the device the

00:07:23,810 --> 00:07:29,590
user may need to wait for a very long

00:07:25,850 --> 00:07:33,320
time until the phone can be used again

00:07:29,590 --> 00:07:37,010
and like I said before the compiled a

00:07:33,320 --> 00:07:39,440
native code also takes a lot of device

00:07:37,010 --> 00:07:41,389
storage especially nowadays many

00:07:39,440 --> 00:07:44,510
applications are actually getting bigger

00:07:41,389 --> 00:07:46,639
and bigger we have paper and bigger text

00:07:44,510 --> 00:07:49,220
byte code so they're compounding native

00:07:46,639 --> 00:07:51,410
code file are also quite big so if we

00:07:49,220 --> 00:07:53,900
try to compile all the code in the

00:07:51,410 --> 00:07:59,479
native native code that you can take

00:07:53,900 --> 00:08:01,669
data for device storage we've also seen

00:07:59,479 --> 00:08:04,760
some behaviors nowadays that some

00:08:01,669 --> 00:08:09,280
applications starts to do this kind of

00:08:04,760 --> 00:08:14,150
dynamic apk or dynamic detects

00:08:09,280 --> 00:08:16,940
generation behavior which means it

00:08:14,150 --> 00:08:19,720
dynamically generate a apk or text byte

00:08:16,940 --> 00:08:24,590
code file on the fly during application

00:08:19,720 --> 00:08:26,900
execution so having a only ahead of time

00:08:24,590 --> 00:08:32,919
compiler cannot handle this scenario

00:08:26,900 --> 00:08:35,959
very well so to solve all the

00:08:32,919 --> 00:08:38,659
performance problem I listed here and

00:08:35,959 --> 00:08:41,060
try to meet all the performance

00:08:38,659 --> 00:08:44,330
requirement that are listed in previous

00:08:41,060 --> 00:08:49,280
slide Google changed the new art in

00:08:44,330 --> 00:08:52,110
Android in into something like this so

00:08:49,280 --> 00:08:56,190
what we can notice here is that

00:08:52,110 --> 00:08:59,940
just in time compiler is back to Android

00:08:56,190 --> 00:09:03,209
Walton and the head of time compiler

00:08:59,940 --> 00:09:07,170
isn't gone actually it has been enhanced

00:09:03,209 --> 00:09:10,529
in evolved into a profile guided ahead

00:09:07,170 --> 00:09:14,279
of time compilation so the idea here is

00:09:10,529 --> 00:09:16,140
that well user install the app from

00:09:14,279 --> 00:09:19,579
Google Play we no longer do any

00:09:16,140 --> 00:09:23,310
compilation during installation time

00:09:19,579 --> 00:09:25,260
just like the old KitKat days when the

00:09:23,310 --> 00:09:27,300
user won't use the app right after

00:09:25,260 --> 00:09:31,350
installation actually we will use the

00:09:27,300 --> 00:09:36,360
JIT mode to execute the app and during

00:09:31,350 --> 00:09:38,760
the JIT execution a offline profile will

00:09:36,360 --> 00:09:41,670
be generated this offline profile file

00:09:38,760 --> 00:09:45,180
records all the hot method information

00:09:41,670 --> 00:09:48,800
during the JIT execution and later at

00:09:45,180 --> 00:09:53,670
some point the android framework will

00:09:48,800 --> 00:09:57,000
start a ahead of time compilation based

00:09:53,670 --> 00:09:59,820
on the offline profile file and actually

00:09:57,000 --> 00:10:03,000
it only compiles or the hot code that

00:09:59,820 --> 00:10:07,350
has been recorded in offline profile

00:10:03,000 --> 00:10:10,230
file so hopefully the JIT phase brings

00:10:07,350 --> 00:10:14,250
fast application installation and fast

00:10:10,230 --> 00:10:15,870
system update performance and the

00:10:14,250 --> 00:10:20,339
profile guided ahead of time compilation

00:10:15,870 --> 00:10:24,120
brains fast application startup and

00:10:20,339 --> 00:10:29,000
runtime performance and we can have

00:10:24,120 --> 00:10:35,630
minimal overhead in terms of CPU usage

00:10:29,000 --> 00:10:41,370
power usage device consumption etc - the

00:10:35,630 --> 00:10:43,019
whole Android system so let's take a

00:10:41,370 --> 00:10:47,880
look at how these new modes are

00:10:43,019 --> 00:10:51,620
implemented the new jet mode includes

00:10:47,880 --> 00:10:54,720
age at runtime a JIT compiler and

00:10:51,620 --> 00:11:00,860
mechanism to generate the offline

00:10:54,720 --> 00:11:03,630
profile file the Jade runtime includes a

00:11:00,860 --> 00:11:06,060
interpreter what we call that fast

00:11:03,630 --> 00:11:11,250
interpreter it is a

00:11:06,060 --> 00:11:13,790
goto based interpreter and every hopi

00:11:11,250 --> 00:11:16,500
code handling is carefully written in

00:11:13,790 --> 00:11:18,900
assembly to make sure the interpreter

00:11:16,500 --> 00:11:22,740
have really good interpreter level

00:11:18,900 --> 00:11:24,990
performance the profiling and triggering

00:11:22,740 --> 00:11:29,030
JIT compilation is down during

00:11:24,990 --> 00:11:33,960
interpretation actually it is based on

00:11:29,030 --> 00:11:37,140
the execution count of certain method

00:11:33,960 --> 00:11:39,870
and with some heuristics to make sure

00:11:37,140 --> 00:11:43,500
that important method gets to be treated

00:11:39,870 --> 00:11:50,250
quickly so if you are interested in how

00:11:43,500 --> 00:11:53,730
this process is it's made you can have a

00:11:50,250 --> 00:11:57,210
look at how the hotness count is used in

00:11:53,730 --> 00:12:01,140
the runtime code so the chit one time

00:11:57,210 --> 00:12:04,290
also contains a cheat code cache of

00:12:01,140 --> 00:12:08,490
course the Jade calc and manages the

00:12:04,290 --> 00:12:11,720
cheated code it also provides a

00:12:08,490 --> 00:12:16,740
mechanism to allocate the hot cold hot

00:12:11,720 --> 00:12:20,850
method information in the code cache

00:12:16,740 --> 00:12:25,550
this feature is for tamping the offline

00:12:20,850 --> 00:12:31,380
code file offline profile file later

00:12:25,550 --> 00:12:34,140
okay the JIT compiler so here are a few

00:12:31,380 --> 00:12:37,560
facts about the new JIT compiler first

00:12:34,140 --> 00:12:41,730
of all the get compiler is does message

00:12:37,560 --> 00:12:45,660
granularity compilation the JIT

00:12:41,730 --> 00:12:48,270
compilation is stung in the background

00:12:45,660 --> 00:12:51,030
thread instead of application thread so

00:12:48,270 --> 00:12:53,520
that the JIT compilation does not block

00:12:51,030 --> 00:12:57,030
application threat especially it does

00:12:53,520 --> 00:13:02,130
not block the us read in cause you are

00:12:57,030 --> 00:13:06,150
junk and the new JIT compiler is based

00:13:02,130 --> 00:13:08,610
on the original optimizing compiler

00:13:06,150 --> 00:13:11,160
back-end so Google didn't introduce a

00:13:08,610 --> 00:13:11,630
whole new compiler for us to learn from

00:13:11,160 --> 00:13:14,580
scratch

00:13:11,630 --> 00:13:17,880
so if already a very familiar with

00:13:14,580 --> 00:13:19,170
original optimizing compiler so the new

00:13:17,880 --> 00:13:23,970
JIT compiler came

00:13:19,170 --> 00:13:26,040
be very familiar to you actually the JIT

00:13:23,970 --> 00:13:31,440
compiler and the äôt compiler share this

00:13:26,040 --> 00:13:34,380
exact same optimization pipeline in the

00:13:31,440 --> 00:13:40,320
compiler so the both compilers should

00:13:34,380 --> 00:13:43,670
generate very similar native code but of

00:13:40,320 --> 00:13:46,529
course in GT mode we have some dynamic

00:13:43,670 --> 00:13:50,540
compilation dynamic profiling

00:13:46,529 --> 00:13:53,040
information so actually the original

00:13:50,540 --> 00:13:57,079
optimizing compiler are enhanced a

00:13:53,040 --> 00:14:00,149
little bit to support more aggressive

00:13:57,079 --> 00:14:03,420
optimization in JIT compiler for example

00:14:00,149 --> 00:14:05,579
the JIT compiler can perform more

00:14:03,420 --> 00:14:12,930
aggressive inlining based on inline

00:14:05,579 --> 00:14:15,899
cache information the mechanism to

00:14:12,930 --> 00:14:18,570
generate offline profile file Google

00:14:15,899 --> 00:14:22,620
introduced a new thread called profiler

00:14:18,570 --> 00:14:25,320
Sabre thread in JIT runtime what the

00:14:22,620 --> 00:14:29,279
profile Silvestre does is that it keeps

00:14:25,320 --> 00:14:32,100
reading the hot measured information

00:14:29,279 --> 00:14:34,920
allocated in the JIT code cache and

00:14:32,100 --> 00:14:37,829
keeps writing such information to the

00:14:34,920 --> 00:14:40,880
device storage we noticed that Google

00:14:37,829 --> 00:14:43,529
has carefully tuned the overhead of this

00:14:40,880 --> 00:14:45,930
thread to make sure it does not bring

00:14:43,529 --> 00:14:50,070
too much overhead to the Android system

00:14:45,930 --> 00:14:56,010
for example the thread only wakes up

00:14:50,070 --> 00:15:00,690
once in like about 20 second and Google

00:14:56,010 --> 00:15:04,380
has carefully designed the format of the

00:15:00,690 --> 00:15:08,069
offline profile file to make sure the

00:15:04,380 --> 00:15:11,640
profiler service read have many more

00:15:08,069 --> 00:15:15,589
things to write to the device storage to

00:15:11,640 --> 00:15:15,589
minimize the Iowa overhead

00:15:17,320 --> 00:15:28,790
actually the JIT mode and the alt mode

00:15:22,670 --> 00:15:31,910
fit into a bigger picture of hybrid mode

00:15:28,790 --> 00:15:35,270
so the hybrid mode the idea of hybrid

00:15:31,910 --> 00:15:39,410
mode is that for some users user certain

00:15:35,270 --> 00:15:43,160
app the app may provide lots of features

00:15:39,410 --> 00:15:45,560
and lots of buttons actually user may

00:15:43,160 --> 00:15:49,310
touch some of the features some of the

00:15:45,560 --> 00:15:52,550
button and only those frequently touched

00:15:49,310 --> 00:15:55,100
and used features and the code behind

00:15:52,550 --> 00:15:59,150
these features worth compiling into

00:15:55,100 --> 00:16:03,010
native code so we can use the JIT phase

00:15:59,150 --> 00:16:08,060
as kind of a big profiler to find these

00:16:03,010 --> 00:16:11,930
frequent used code and we use the äôt

00:16:08,060 --> 00:16:14,690
compiler to do a handle on compilation

00:16:11,930 --> 00:16:18,340
and optimize to speed up the frequent

00:16:14,690 --> 00:16:24,800
and use cases and we avoid paying

00:16:18,340 --> 00:16:28,280
overhead in terms of CPU storage and the

00:16:24,800 --> 00:16:34,090
power overhead on this code which the

00:16:28,280 --> 00:16:38,240
user never touches so to implement such

00:16:34,090 --> 00:16:41,570
hybrid mode behavior we need to have a

00:16:38,240 --> 00:16:45,110
mechanism to generate a Franco profile

00:16:41,570 --> 00:16:48,260
file during JIT execution just show you

00:16:45,110 --> 00:16:51,320
the process in previous slide we'll take

00:16:48,260 --> 00:16:55,250
a look at how the file format of this

00:16:51,320 --> 00:17:00,350
offline profile file and the original

00:16:55,250 --> 00:17:02,510
ahead of an compiler is enhanced to be

00:17:00,350 --> 00:17:05,720
able to do such a profile guided a

00:17:02,510 --> 00:17:08,540
header file compilation and a new

00:17:05,720 --> 00:17:12,830
compilation daemon service is introduced

00:17:08,540 --> 00:17:15,200
in the android framework to to be in

00:17:12,830 --> 00:17:19,240
charge of when should we trigger the

00:17:15,200 --> 00:17:19,240
such a header file compilation

00:17:20,430 --> 00:17:29,160
so here is the file format of this

00:17:24,860 --> 00:17:32,430
offline profile file so each application

00:17:29,160 --> 00:17:35,000
has its own profile and the file is

00:17:32,430 --> 00:17:37,710
stored in application local storage

00:17:35,000 --> 00:17:40,740
currently this profile file is a very

00:17:37,710 --> 00:17:45,120
simple binary format basically it just

00:17:40,740 --> 00:17:49,650
records in what apk in what class which

00:17:45,120 --> 00:17:52,860
method is hot analysis of this binary

00:17:49,650 --> 00:17:57,540
file can be done through a tool called

00:17:52,860 --> 00:18:00,990
prof man I'll talk about it later so we

00:17:57,540 --> 00:18:04,230
have the profile file the question is

00:18:00,990 --> 00:18:08,820
when should we trigger such profile

00:18:04,230 --> 00:18:12,210
guided compilation so the answer is

00:18:08,820 --> 00:18:18,750
quite simple when the phone is charging

00:18:12,210 --> 00:18:21,120
and idle like this so Google introduced

00:18:18,750 --> 00:18:25,350
a new service called background tech

00:18:21,120 --> 00:18:29,190
soft service which which is in charge of

00:18:25,350 --> 00:18:31,740
the policy of when should this profile

00:18:29,190 --> 00:18:34,710
guided ahead of time compilation should

00:18:31,740 --> 00:18:36,600
be triggered so if interested in the

00:18:34,710 --> 00:18:38,430
implementation of this policy and the

00:18:36,600 --> 00:18:41,010
detail of these policy you can take a

00:18:38,430 --> 00:18:48,030
look at the source code of this service

00:18:41,010 --> 00:18:52,500
in android framework so the original

00:18:48,030 --> 00:18:56,420
text old äôt compiler is enhanced to be

00:18:52,500 --> 00:19:02,030
able to accept the new new profile file

00:18:56,420 --> 00:19:04,560
so actually it is a kind of small

00:19:02,030 --> 00:19:09,660
enhancement in the original text old

00:19:04,560 --> 00:19:13,290
compiler the compilation process didn't

00:19:09,660 --> 00:19:16,230
didn't change so the tech TextAloud

00:19:13,290 --> 00:19:20,460
compiler will try to compile all every

00:19:16,230 --> 00:19:23,250
method in the text bytecode file and now

00:19:20,460 --> 00:19:26,160
in the new Android n before compiling

00:19:23,250 --> 00:19:29,810
each method it will ask one more

00:19:26,160 --> 00:19:32,390
question does this method has record in

00:19:29,810 --> 00:19:35,390
the offline profile file

00:19:32,390 --> 00:19:37,130
if I can find this method in the profile

00:19:35,390 --> 00:19:40,370
file I'll compare I'll compile it

00:19:37,130 --> 00:19:44,390
otherwise I'll just skip it so the

00:19:40,370 --> 00:19:47,590
profile guided compilation is in my

00:19:44,390 --> 00:19:55,330
opinion is just a selective compilation

00:19:47,590 --> 00:19:59,240
well I compile it or not so after such

00:19:55,330 --> 00:20:02,180
profile guided compilation the next time

00:19:59,240 --> 00:20:07,880
user launched app again all previous hot

00:20:02,180 --> 00:20:10,610
thread are compiled into native code but

00:20:07,880 --> 00:20:13,210
the JIT compiler is still loaded in

00:20:10,610 --> 00:20:17,000
memory just in case the user wants to

00:20:13,210 --> 00:20:20,240
explore some new features and exploit

00:20:17,000 --> 00:20:22,780
features or code in the app and such

00:20:20,240 --> 00:20:25,970
process may generate new profiles and

00:20:22,780 --> 00:20:33,290
the profile guided compilation process

00:20:25,970 --> 00:20:37,670
when they start all over again so we've

00:20:33,290 --> 00:20:41,810
seen a lot of new mode and new thread

00:20:37,670 --> 00:20:44,150
introduced in the art so here are a few

00:20:41,810 --> 00:20:46,700
tools that we think can be useful for

00:20:44,150 --> 00:20:51,350
Android developers to analyze those new

00:20:46,700 --> 00:20:53,210
modes and new threads the first two is

00:20:51,350 --> 00:20:55,550
called trace view it's a very nice

00:20:53,210 --> 00:20:59,140
tracing tool which can be found in

00:20:55,550 --> 00:21:03,530
Android studio or the standalone Android

00:20:59,140 --> 00:21:06,800
SDK you can give us a very nice job

00:21:03,530 --> 00:21:10,850
method level tracing and CPU time

00:21:06,800 --> 00:21:16,360
breakdown and because in the new Android

00:21:10,850 --> 00:21:20,450
n a method can be in interpretation in

00:21:16,360 --> 00:21:22,900
JTED code or as a header from compiled

00:21:20,450 --> 00:21:26,810
code actually this tool can support

00:21:22,900 --> 00:21:31,460
analyzing the method only in different

00:21:26,810 --> 00:21:35,090
modes another really useful tool is

00:21:31,460 --> 00:21:40,660
systrace this citrus is very good to

00:21:35,090 --> 00:21:43,730
pull multi thread analysis on android so

00:21:40,660 --> 00:21:45,020
once we enable the dalvik trees we can

00:21:43,730 --> 00:21:50,410
analyze

00:21:45,020 --> 00:21:53,330
jeet behaviors in art you can show us

00:21:50,410 --> 00:21:55,910
the jet code cash behaviors profile

00:21:53,330 --> 00:21:59,150
cyber threat behaviors covered

00:21:55,910 --> 00:22:02,210
collection behavior etc actually our

00:21:59,150 --> 00:22:06,530
team also used such tool as a micro

00:22:02,210 --> 00:22:11,720
scope to measure mini second level or

00:22:06,530 --> 00:22:16,850
even micro second level events in

00:22:11,720 --> 00:22:21,220
following twist example histories shows

00:22:16,850 --> 00:22:25,670
it accurately shows that a method is

00:22:21,220 --> 00:22:28,610
invoked three times and the first invoke

00:22:25,670 --> 00:22:31,970
of that method is quite slow compared to

00:22:28,610 --> 00:22:35,210
over later invokes and it clearly shows

00:22:31,970 --> 00:22:38,390
that because of interpretation and JIT

00:22:35,210 --> 00:22:43,540
compilation all these behaviors slows

00:22:38,390 --> 00:22:46,400
down the first in bulk of that method so

00:22:43,540 --> 00:22:53,840
history is really useful in measuring

00:22:46,400 --> 00:22:57,620
such such behaviors JIT compiler level

00:22:53,840 --> 00:23:01,300
analysis first of all because the new

00:22:57,620 --> 00:23:04,130
jet compiler is based on the original

00:23:01,300 --> 00:23:07,640
optimising compiler so all techniques

00:23:04,130 --> 00:23:10,580
used to analyze the original ultimately

00:23:07,640 --> 00:23:14,840
compiler apply here for example we can

00:23:10,580 --> 00:23:18,080
ask the JIT compiler to dump CFG file to

00:23:14,840 --> 00:23:23,300
do control flow graph level analysis and

00:23:18,080 --> 00:23:29,390
HR level analysis currently art did

00:23:23,300 --> 00:23:34,610
support method level profiling of the GT

00:23:29,390 --> 00:23:37,850
decode the art G it supports stamping

00:23:34,610 --> 00:23:40,130
perf map which allows us to do method

00:23:37,850 --> 00:23:44,740
level profiling was perf our team is

00:23:40,130 --> 00:23:47,920
also looking at how to enable

00:23:44,740 --> 00:23:53,270
instruction level profiling words with

00:23:47,920 --> 00:23:56,920
perf inject actually for point X kernel

00:23:53,270 --> 00:24:01,790
on Android can be really useful here

00:23:56,920 --> 00:24:04,970
of course here are more options we can

00:24:01,790 --> 00:24:09,190
provide to our Jetta to enable more

00:24:04,970 --> 00:24:09,190
dumps and statistics

00:24:12,010 --> 00:24:19,250
Google introduced a new tool called

00:24:14,690 --> 00:24:21,680
prevent for us to do profile guided

00:24:19,250 --> 00:24:25,010
ahead of time compilation analysis so

00:24:21,680 --> 00:24:28,220
this tool can help us to analyze the

00:24:25,010 --> 00:24:31,690
contents of a binary offline profile

00:24:28,220 --> 00:24:36,310
file so it can also generate a random

00:24:31,690 --> 00:24:39,340
test profile file for us to try such

00:24:36,310 --> 00:24:43,550
profile guided compilation process

00:24:39,340 --> 00:24:47,030
textual compiler if you want to try such

00:24:43,550 --> 00:24:52,070
compare you can also enable following to

00:24:47,030 --> 00:24:54,680
debug flags to enable modems and enable

00:24:52,070 --> 00:25:01,760
the textual compiler to accept your test

00:24:54,680 --> 00:25:04,760
profile file so here are a few

00:25:01,760 --> 00:25:06,550
performance findings that we like to

00:25:04,760 --> 00:25:11,540
hear

00:25:06,550 --> 00:25:15,770
we found a relatively popular and big

00:25:11,540 --> 00:25:18,560
app the newsreader app and we tried such

00:25:15,770 --> 00:25:20,900
news reader app on the new Android N and

00:25:18,560 --> 00:25:25,730
measure the performance some of the

00:25:20,900 --> 00:25:27,400
behaviors are quite interesting so first

00:25:25,730 --> 00:25:30,830
the installation time of this

00:25:27,400 --> 00:25:35,300
application so if we still use the

00:25:30,830 --> 00:25:37,820
marshmallow full ahead of time approach

00:25:35,300 --> 00:25:41,750
the installation time is nearly 90

00:25:37,820 --> 00:25:46,250
seconds not a very good experience so in

00:25:41,750 --> 00:25:49,040
the new Android end with the hybrid mode

00:25:46,250 --> 00:25:53,390
the installation time of this app is

00:25:49,040 --> 00:25:57,290
down to only eleven point four second so

00:25:53,390 --> 00:26:01,810
it's a very good improvement in hop out

00:25:57,290 --> 00:26:04,520
application startup time so the original

00:26:01,810 --> 00:26:07,400
full ahead of time compilation approach

00:26:04,520 --> 00:26:09,830
in marshmallow the application startup

00:26:07,400 --> 00:26:14,240
time is two point four second

00:26:09,830 --> 00:26:17,179
so in the new Android n if we start up

00:26:14,240 --> 00:26:21,950
right after installation the startup

00:26:17,179 --> 00:26:27,049
time is only 2.9 seconds so there is

00:26:21,950 --> 00:26:29,960
slightly increase in in Android M with

00:26:27,049 --> 00:26:32,510
JIT mode but when the ahead of time

00:26:29,960 --> 00:26:36,380
compilation the profile guided ahead of

00:26:32,510 --> 00:26:39,279
time compilation kicks in actually the

00:26:36,380 --> 00:26:41,000
ton of time is the same as original for

00:26:39,279 --> 00:26:45,080
IOT approach

00:26:41,000 --> 00:26:49,330
I put such application launch time

00:26:45,080 --> 00:26:52,519
performance here to show that actually

00:26:49,330 --> 00:26:57,350
even we go back to the jet mode

00:26:52,519 --> 00:27:01,460
actually the performance slowdown is

00:26:57,350 --> 00:27:04,250
actually very very minimal actually it

00:27:01,460 --> 00:27:06,620
means that in application startup time

00:27:04,250 --> 00:27:09,880
not all the code will be executed and I

00:27:06,620 --> 00:27:12,139
believe in application execution runtime

00:27:09,880 --> 00:27:17,210
also not all the code will be executed

00:27:12,139 --> 00:27:19,700
so it's really not worse to compile all

00:27:17,210 --> 00:27:24,710
the application code at installation

00:27:19,700 --> 00:27:27,350
time so we measure the device storage

00:27:24,710 --> 00:27:31,070
consumption after a few days usage of

00:27:27,350 --> 00:27:33,440
that app so we to make sure that the

00:27:31,070 --> 00:27:40,850
ahead of time compilation has kicked in

00:27:33,440 --> 00:27:43,309
on Android n so we felt that the device

00:27:40,850 --> 00:27:49,190
storage consumption is also greatly

00:27:43,309 --> 00:27:52,429
reduced due to the user does not use all

00:27:49,190 --> 00:27:55,880
the features in the app and I will also

00:27:52,429 --> 00:27:58,370
like to point out that the profile file

00:27:55,880 --> 00:28:02,149
the new profile file and it in Android n

00:27:58,370 --> 00:28:08,860
is is both designed so it's kept very

00:28:02,149 --> 00:28:08,860
very small size so it's nothing

00:28:09,159 --> 00:28:15,499
another question we asked ourselves is

00:28:12,080 --> 00:28:17,779
that also we know the new JIT compiler

00:28:15,499 --> 00:28:21,049
and the IOT compiler actually share the

00:28:17,779 --> 00:28:22,850
exact same compiler back-end then how

00:28:21,049 --> 00:28:26,210
about their generated code performance

00:28:22,850 --> 00:28:30,110
does the two nuke compilers generate the

00:28:26,210 --> 00:28:35,350
exact same native code and deliver the

00:28:30,110 --> 00:28:35,350
exact same performance so we run our

00:28:35,440 --> 00:28:42,679
benchmark suite our testing which is

00:28:39,440 --> 00:28:46,129
maintained by our team we want such a

00:28:42,679 --> 00:28:48,230
benchmarks micro benchmark suite on the

00:28:46,129 --> 00:28:52,299
LT mode and the JIT mode and compare the

00:28:48,230 --> 00:28:55,820
performance and here is a performance

00:28:52,299 --> 00:28:58,600
this is normalized execution time so the

00:28:55,820 --> 00:29:02,990
lower bar means better performance and

00:28:58,600 --> 00:29:08,299
as we expect in some benchmarks like

00:29:02,990 --> 00:29:10,789
macro the LT compiler and the JIT

00:29:08,299 --> 00:29:13,639
compiler actually generate the same

00:29:10,789 --> 00:29:18,139
performance but we also noticed that

00:29:13,639 --> 00:29:21,740
there are a slight performance slowdown

00:29:18,139 --> 00:29:26,090
in the JIT mode for example in the

00:29:21,740 --> 00:29:28,820
algorithm benchmark suite and in some

00:29:26,090 --> 00:29:31,549
cases like the caffeine mark the cheat

00:29:28,820 --> 00:29:33,860
mode is much faster than a Ooty mode so

00:29:31,549 --> 00:29:38,210
we did some investigation and here are

00:29:33,860 --> 00:29:40,759
two findings I will like to share first

00:29:38,210 --> 00:29:45,379
why the JIT mode seemed to be a little

00:29:40,759 --> 00:29:46,879
bit slower than the äôt mode actually

00:29:45,379 --> 00:29:49,669
there's nothing wrong with the JIT

00:29:46,879 --> 00:29:51,919
compiler we found that our our testing

00:29:49,669 --> 00:29:54,769
benchmark has been well tuned for IOT

00:29:51,919 --> 00:29:57,019
compiler but for the new JIT compiler

00:29:54,769 --> 00:30:00,200
actually for some benchmark we didn't

00:29:57,019 --> 00:30:03,129
give them enough warmup time so we

00:30:00,200 --> 00:30:05,450
accidentally measured some

00:30:03,129 --> 00:30:10,340
interpretation and JIT compilation

00:30:05,450 --> 00:30:12,590
performance compilation time so if we

00:30:10,340 --> 00:30:17,379
are doing similar micro benchmarking

00:30:12,590 --> 00:30:20,240
make sure that you do not include such

00:30:17,379 --> 00:30:22,490
interpretation and JIT compilation phase

00:30:20,240 --> 00:30:25,490
the benchmarking unless you're actually

00:30:22,490 --> 00:30:30,260
a page marking the interpreter of

00:30:25,490 --> 00:30:34,360
performance then another finding is that

00:30:30,260 --> 00:30:37,850
why some benchmark are much faster on

00:30:34,360 --> 00:30:39,320
the JIT compiler for example the

00:30:37,850 --> 00:30:42,320
caffeine mark

00:30:39,320 --> 00:30:45,320
like I said in previous slides because

00:30:42,320 --> 00:30:48,800
in JIT mode we actually can do more

00:30:45,320 --> 00:30:52,880
aggressive optimizations based on

00:30:48,800 --> 00:30:54,620
dynamic profile profile information for

00:30:52,880 --> 00:30:57,230
example in this case actually the JIT

00:30:54,620 --> 00:31:00,020
mode does more inlining based on inline

00:30:57,230 --> 00:31:03,080
caching information than a or T compiler

00:31:00,020 --> 00:31:05,300
so the more inlining the JIT compiler

00:31:03,080 --> 00:31:07,670
performed actually delivers better

00:31:05,300 --> 00:31:11,050
performance but I will also like to

00:31:07,670 --> 00:31:13,400
point out that in real life applications

00:31:11,050 --> 00:31:16,520
the interpretation and the JIT

00:31:13,400 --> 00:31:20,570
compilation behavior also slows down the

00:31:16,520 --> 00:31:22,400
jet mode so overall I think the IOT

00:31:20,570 --> 00:31:26,270
compiler and the JIT compiler should

00:31:22,400 --> 00:31:32,450
have very similar performance and äôt

00:31:26,270 --> 00:31:36,110
compound code should be preferred last

00:31:32,450 --> 00:31:38,270
slide if you're interested in what our

00:31:36,110 --> 00:31:41,690
team the de niro our team is doing we

00:31:38,270 --> 00:31:47,440
have two more talks during this general

00:31:41,690 --> 00:31:51,320
connect these two talks are in our AOSP

00:31:47,440 --> 00:31:54,350
mini-com my colleague Anton will talk

00:31:51,320 --> 00:32:00,410
about our recent efforts to enable

00:31:54,350 --> 00:32:04,640
Victor 32 art said it our art 32

00:32:00,410 --> 00:32:08,710
back-end and my colleague autumn would

00:32:04,640 --> 00:32:13,520
share his insightful views about

00:32:08,710 --> 00:32:16,520
performance analysis Android runtime so

00:32:13,520 --> 00:32:20,360
if you're interested in more details

00:32:16,520 --> 00:32:23,870
about the implementation of this new art

00:32:20,360 --> 00:32:28,070
in Android n Google arts team has a very

00:32:23,870 --> 00:32:30,530
good talk in Google IO are they this

00:32:28,070 --> 00:32:33,150
year evolution of art this talk is

00:32:30,530 --> 00:32:36,000
available on YouTube

00:32:33,150 --> 00:32:38,010
and if you are interested in the

00:32:36,000 --> 00:32:41,510
compiler JIT compiler implementation I

00:32:38,010 --> 00:32:45,510
found there is a very good article in

00:32:41,510 --> 00:32:51,510
source.android.com you can take a look

00:32:45,510 --> 00:32:53,960
at with that ready to take your

00:32:51,510 --> 00:32:53,960
questions

00:33:55,640 --> 00:34:05,809
I think that's a good question so my

00:34:01,850 --> 00:34:08,629
idea is that my opinion is that if you

00:34:05,809 --> 00:34:10,730
do that you actually have to handle the

00:34:08,629 --> 00:34:14,119
address space layout randomization in

00:34:10,730 --> 00:34:15,919
Android so that is a problem when you

00:34:14,119 --> 00:34:20,240
when you do that because when you cash

00:34:15,919 --> 00:34:23,270
that a memory image offline the next

00:34:20,240 --> 00:34:25,700
time it is loaded in memory Android

00:34:23,270 --> 00:34:29,290
olena's cannot guarantee because we have

00:34:25,700 --> 00:34:31,669
such address space randomization

00:34:29,290 --> 00:34:35,090
behavior you cannot guarantee that is

00:34:31,669 --> 00:34:37,340
still there so it can be in a completely

00:34:35,090 --> 00:34:40,429
different address and all assumptions

00:34:37,340 --> 00:34:43,850
about address in the treated code I

00:34:40,429 --> 00:34:45,590
actually will fail so you if you want if

00:34:43,850 --> 00:34:55,550
we want to use that approach actually

00:34:45,590 --> 00:34:59,109
such this is a big problem no I don't

00:34:55,550 --> 00:35:02,480
think that has a same problem because it

00:34:59,109 --> 00:35:05,060
the compiled code the JIT compiled code

00:35:02,480 --> 00:35:09,890
may have some assumption about the

00:35:05,060 --> 00:35:12,140
address the color coding address but the

00:35:09,890 --> 00:35:16,090
ahead of time come harder compound code

00:35:12,140 --> 00:35:16,090
will not have that assumption

00:35:40,900 --> 00:35:47,470
yeah that can be also another reason

00:35:43,840 --> 00:35:50,800
because yeah in GT code we can make such

00:35:47,470 --> 00:35:54,400
assumptions that some method are already

00:35:50,800 --> 00:35:57,030
resolved during the interpretation phase

00:35:54,400 --> 00:36:00,130
so that we we because with that

00:35:57,030 --> 00:36:02,830
assumption actually we can generate some

00:36:00,130 --> 00:36:05,740
more aggressive code that we do not do

00:36:02,830 --> 00:36:09,030
dynamic resolve but in a og compiler we

00:36:05,740 --> 00:36:09,030
always do dynamic resolve

00:36:59,890 --> 00:37:03,640

YouTube URL: https://www.youtube.com/watch?v=TCJLFqhC1VE


