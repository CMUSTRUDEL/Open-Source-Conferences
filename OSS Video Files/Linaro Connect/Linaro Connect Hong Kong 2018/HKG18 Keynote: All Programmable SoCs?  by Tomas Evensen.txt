Title: HKG18 Keynote: All Programmable SoCs?  by Tomas Evensen
Publication date: 2019-05-09
Playlist: Linaro Connect Hong Kong 2018
Description: 
	HKG18 Keynote: Tomas Evensen - All Programmable SoCs? â€“ Platforms to enable the future of Embedded Machine Learning
Captions: 
	00:00:00,000 --> 00:00:04,890
mas Evanson who is the CTO for embedded

00:00:03,360 --> 00:00:06,990
at Xilinx and he's going to share all

00:00:04,890 --> 00:00:17,250
sorts of interesting insight with us

00:00:06,990 --> 00:00:19,619
about FPGAs welcome Tomas morning

00:00:17,250 --> 00:00:22,500
everyone so I'm going to talk about

00:00:19,619 --> 00:00:26,189
FPGAs just show her hands here who knows

00:00:22,500 --> 00:00:29,369
what the heck an FPGA is that's quite a

00:00:26,189 --> 00:00:32,399
few people who knows how to use it from

00:00:29,369 --> 00:00:35,309
a software point of view not as many

00:00:32,399 --> 00:00:39,050
people yeah so being a software guy at

00:00:35,309 --> 00:00:41,730
silence is obviously interesting and and

00:00:39,050 --> 00:00:43,890
what I knew about FPGAs before joining

00:00:41,730 --> 00:00:45,570
really they have today a porch or that

00:00:43,890 --> 00:00:46,950
was for the hardware guys right that was

00:00:45,570 --> 00:00:48,480
more interested in the embedded

00:00:46,950 --> 00:00:50,190
processors and we'll talk a little bit

00:00:48,480 --> 00:00:52,079
about that but mostly I will talk about

00:00:50,190 --> 00:00:54,899
the FPGA port and how we can use both

00:00:52,079 --> 00:00:57,210
together and and the really fascinating

00:00:54,899 --> 00:00:59,399
and interesting thing that's happening

00:00:57,210 --> 00:01:02,340
right now is software guys are actually

00:00:59,399 --> 00:01:07,740
programming the FPGA for accelerators

00:01:02,340 --> 00:01:09,659
and so on so I'll get into that so the

00:01:07,740 --> 00:01:11,610
reason why people are looking at their

00:01:09,659 --> 00:01:14,760
PJs of course is we all seen this before

00:01:11,610 --> 00:01:17,159
right Moore's law doesn't really apply

00:01:14,760 --> 00:01:19,799
not much anymore it's harder and harder

00:01:17,159 --> 00:01:21,960
just to add CPUs even if you had many of

00:01:19,799 --> 00:01:24,750
them you get power issues and so forth

00:01:21,960 --> 00:01:28,020
and the workloads of course at the same

00:01:24,750 --> 00:01:30,180
time are really exploding so I think a

00:01:28,020 --> 00:01:33,600
lot of people have realized that you

00:01:30,180 --> 00:01:35,159
need specialized execution engines to be

00:01:33,600 --> 00:01:37,710
able to handle all these different loads

00:01:35,159 --> 00:01:40,200
the problem of course then is well if

00:01:37,710 --> 00:01:43,110
you have one really specific execution

00:01:40,200 --> 00:01:45,180
engine for one task another one for

00:01:43,110 --> 00:01:46,950
another task well how do you do that

00:01:45,180 --> 00:01:48,930
because very often you want to have

00:01:46,950 --> 00:01:51,380
mixed loads like in the data center for

00:01:48,930 --> 00:01:53,579
example you can have one specific

00:01:51,380 --> 00:01:54,509
accelerator for each task because

00:01:53,579 --> 00:01:56,780
there's so many of them

00:01:54,509 --> 00:01:59,820
so then FPGA is has programmable

00:01:56,780 --> 00:02:02,490
Hardware is what it really is comes in

00:01:59,820 --> 00:02:04,140
because you can use the same board for a

00:02:02,490 --> 00:02:06,719
lot of different things so you can even

00:02:04,140 --> 00:02:08,970
timeslice it's you use it for some

00:02:06,719 --> 00:02:10,890
acceleration first and then you use it

00:02:08,970 --> 00:02:13,560
for other types of acceleration later on

00:02:10,890 --> 00:02:17,190
and this is this applies both in

00:02:13,560 --> 00:02:20,790
cloud so Amazon and other people they

00:02:17,190 --> 00:02:22,590
have FPGA servers basically or record by

00:02:20,790 --> 00:02:25,800
the servers there's the eft-1 from

00:02:22,590 --> 00:02:29,310
Amazon for example but then also in the

00:02:25,800 --> 00:02:31,800
edge things like drivers is it our

00:02:29,310 --> 00:02:33,720
autonomous driving embedded vision and

00:02:31,800 --> 00:02:39,980
so on lots and lots of people using FPGA

00:02:33,720 --> 00:02:42,870
is for us so today I'm talking about

00:02:39,980 --> 00:02:45,870
what we call sync ultra scale plus MP

00:02:42,870 --> 00:02:48,750
soch and that's a mouthful I did not

00:02:45,870 --> 00:02:50,730
come up with the name yeah this is a

00:02:48,750 --> 00:02:52,200
really interesting tip from a software

00:02:50,730 --> 00:02:52,860
point of view because there are lots of

00:02:52,200 --> 00:02:54,180
moving parts

00:02:52,860 --> 00:02:56,459
lots of stuff where you can put your

00:02:54,180 --> 00:02:59,430
code if you will so for example you have

00:02:56,459 --> 00:03:03,840
some 853 s so this is really more for

00:02:59,430 --> 00:03:05,790
the embedded space and a 53 s or more

00:03:03,840 --> 00:03:07,440
than well enough equipped to handle

00:03:05,790 --> 00:03:09,540
those tasks when you want to have a

00:03:07,440 --> 00:03:12,060
little bit more umph and for compute and

00:03:09,540 --> 00:03:14,130
so on we put that into the FPGA part of

00:03:12,060 --> 00:03:17,010
it right so you have four of them

00:03:14,130 --> 00:03:19,200
typically running Linux sometimes people

00:03:17,010 --> 00:03:22,170
put a hypervisor there and have multiple

00:03:19,200 --> 00:03:25,680
operating systems and so on we also have

00:03:22,170 --> 00:03:30,359
some real-time course so cortex r5

00:03:25,680 --> 00:03:32,609
Chiodos in a lot of these systems safety

00:03:30,359 --> 00:03:34,680
and security and those things are really

00:03:32,609 --> 00:03:36,120
important so these guys you can run in

00:03:34,680 --> 00:03:40,530
lockstep for example which is really

00:03:36,120 --> 00:03:42,780
important for safety also for real-time

00:03:40,530 --> 00:03:45,450
if you really want that low latency

00:03:42,780 --> 00:03:47,190
between the FPGA and the core and not

00:03:45,450 --> 00:03:49,380
have things like caches and so on get

00:03:47,190 --> 00:03:52,049
too much into the way then the or files

00:03:49,380 --> 00:03:57,480
are really good for that you have memory

00:03:52,049 --> 00:03:59,160
of course GPU peripherals a lot of the

00:03:57,480 --> 00:04:02,940
what have PDAs are really good at is

00:03:59,160 --> 00:04:04,590
really high input output but very often

00:04:02,940 --> 00:04:06,299
what people do they have something

00:04:04,590 --> 00:04:08,340
coming in maybe from an antenna or

00:04:06,299 --> 00:04:10,769
something like that or or a video stream

00:04:08,340 --> 00:04:12,450
and then you go broad in the FPGA you

00:04:10,769 --> 00:04:14,639
can you know really brought to have

00:04:12,450 --> 00:04:17,070
really wide buses since you really

00:04:14,639 --> 00:04:18,989
design your own buses in the hardware

00:04:17,070 --> 00:04:21,510
right so you can have packets coming in

00:04:18,989 --> 00:04:24,450
for example and then you go 256 bits

00:04:21,510 --> 00:04:24,820
wide and go through the the fabric while

00:04:24,450 --> 00:04:27,190
you

00:04:24,820 --> 00:04:30,820
your recognition or classification and

00:04:27,190 --> 00:04:34,960
so on on some of our chips we have a

00:04:30,820 --> 00:04:37,900
video codec we have kept log of

00:04:34,960 --> 00:04:39,970
interesting other processor units or for

00:04:37,900 --> 00:04:42,160
security and platform management so

00:04:39,970 --> 00:04:43,990
these are triple redundant processors

00:04:42,160 --> 00:04:46,570
are supposed to be up and running all

00:04:43,990 --> 00:04:49,330
the time of course right so put your

00:04:46,570 --> 00:04:52,060
both code security code and so on we can

00:04:49,330 --> 00:04:55,930
put them there if you want to but then

00:04:52,060 --> 00:04:57,220
we have the fabric so for some reason we

00:04:55,930 --> 00:05:00,010
can't even ourselves come up with one

00:04:57,220 --> 00:05:02,950
good name so FPGA programmable logic

00:05:00,010 --> 00:05:04,270
fabric it's all the same it's the stuff

00:05:02,950 --> 00:05:07,660
that the hardware you can program

00:05:04,270 --> 00:05:11,830
basically right FPGA is a pretty old

00:05:07,660 --> 00:05:14,500
term field programmable gate arrays so I

00:05:11,830 --> 00:05:16,770
don't know how that is so very often you

00:05:14,500 --> 00:05:19,720
hear these turns programmable logic

00:05:16,770 --> 00:05:22,360
fabric you know just interchange one

00:05:19,720 --> 00:05:22,630
with another so the question is then all

00:05:22,360 --> 00:05:26,320
right

00:05:22,630 --> 00:05:29,830
this fabric how do you program that and

00:05:26,320 --> 00:05:31,030
what is it really first of all so that's

00:05:29,830 --> 00:05:33,820
the interesting thing when you ask

00:05:31,030 --> 00:05:36,130
people what is an FTA you very often get

00:05:33,820 --> 00:05:37,690
really different answers depending where

00:05:36,130 --> 00:05:40,540
they come from what kind of background

00:05:37,690 --> 00:05:44,350
so it started with with FPGA is really

00:05:40,540 --> 00:05:46,240
being you know what we call the lots the

00:05:44,350 --> 00:05:49,360
look-up tables the programmable logic

00:05:46,240 --> 00:05:51,010
your nor and NAND gates and so on you

00:05:49,360 --> 00:05:52,690
can program them yourselves and then we

00:05:51,010 --> 00:05:54,490
can change that so really hardware

00:05:52,690 --> 00:05:56,350
that's that's programmable and then

00:05:54,490 --> 00:05:58,810
people came up with well we're using a

00:05:56,350 --> 00:06:00,490
lot of these guys just for memory let's

00:05:58,810 --> 00:06:03,760
put in some hardened memory I'm actually

00:06:00,490 --> 00:06:06,340
multiple types of memory with multi port

00:06:03,760 --> 00:06:08,650
accents and things like that next thing

00:06:06,340 --> 00:06:10,900
people started to use these for for

00:06:08,650 --> 00:06:11,380
things like multiply and accumulate and

00:06:10,900 --> 00:06:13,420
so on

00:06:11,380 --> 00:06:15,610
why don't we harden that and put a lot

00:06:13,420 --> 00:06:17,140
of DSP blocks so in some of these you

00:06:15,610 --> 00:06:20,860
have thousands and thousands of these

00:06:17,140 --> 00:06:22,990
DSP blocks into the fabric in various

00:06:20,860 --> 00:06:24,880
places right so that's been the trend

00:06:22,990 --> 00:06:26,740
that your hard and more and more things

00:06:24,880 --> 00:06:29,380
which means that you can use this for

00:06:26,740 --> 00:06:31,960
the global logic that's sort of what it

00:06:29,380 --> 00:06:34,270
started out so if you have your own type

00:06:31,960 --> 00:06:35,710
of bus or very often in industrial

00:06:34,270 --> 00:06:37,060
applications you have different types of

00:06:35,710 --> 00:06:39,730
buses field buses

00:06:37,060 --> 00:06:41,500
and US release tonight and so on so you

00:06:39,730 --> 00:06:43,300
can with the same trip you just

00:06:41,500 --> 00:06:44,950
reprogram how you interface with those

00:06:43,300 --> 00:06:46,870
busses all right it's just one way of

00:06:44,950 --> 00:06:50,380
doing it not to be interesting for for a

00:06:46,870 --> 00:06:52,780
software guy like myself yeah but those

00:06:50,380 --> 00:06:56,700
these PC in there if you can really

00:06:52,780 --> 00:06:58,960
paralyze your matrix multiply or your

00:06:56,700 --> 00:07:01,300
what we'll get into a little bit later

00:06:58,960 --> 00:07:04,030
neural networks and so on that gets

00:07:01,300 --> 00:07:06,220
really really interesting right other

00:07:04,030 --> 00:07:08,950
people they new affiliates from

00:07:06,220 --> 00:07:09,940
simulation or emulation so we have this

00:07:08,950 --> 00:07:11,860
really big

00:07:09,940 --> 00:07:13,510
everydays and then you put like eight of

00:07:11,860 --> 00:07:15,430
them on one board and then you can

00:07:13,510 --> 00:07:16,930
simulate new basic designs so some

00:07:15,430 --> 00:07:19,330
people that's what they do and what you

00:07:16,930 --> 00:07:20,980
use their PJs for it so that's the

00:07:19,330 --> 00:07:23,050
interesting thing you can use it for a

00:07:20,980 --> 00:07:25,210
lot of different things but since it's

00:07:23,050 --> 00:07:27,670
so programmable you can have your own

00:07:25,210 --> 00:07:30,130
buses as I mentioned your own data flow

00:07:27,670 --> 00:07:31,600
it's really good for things like machine

00:07:30,130 --> 00:07:33,490
learning where there lots of

00:07:31,600 --> 00:07:35,410
experimentation right now lots of new

00:07:33,490 --> 00:07:37,780
ways of doing stuff you can sort of have

00:07:35,410 --> 00:07:40,960
intelligent memory that's serving up or

00:07:37,780 --> 00:07:42,280
your weights in really nice ways you

00:07:40,960 --> 00:07:44,770
don't have to go out to memory all the

00:07:42,280 --> 00:07:47,710
time so lots of innovation happening

00:07:44,770 --> 00:07:49,180
right now around how to use FPGA is for

00:07:47,710 --> 00:07:55,030
for machine learning and a lot of other

00:07:49,180 --> 00:07:59,410
things so how do you program this stuff

00:07:55,030 --> 00:08:00,940
right so it used to be that really was

00:07:59,410 --> 00:08:03,580
something for the hardware guys and they

00:08:00,940 --> 00:08:06,250
had their funky languages like like very

00:08:03,580 --> 00:08:10,750
long VHDL those kind of things right

00:08:06,250 --> 00:08:12,940
interesting languages but but a little

00:08:10,750 --> 00:08:14,560
bit harder for a software guy we tend to

00:08:12,940 --> 00:08:16,840
think a little bit more in the serial

00:08:14,560 --> 00:08:18,640
fashion they are everything is happening

00:08:16,840 --> 00:08:21,550
at the same time in the right you really

00:08:18,640 --> 00:08:23,050
have to think in a different way so but

00:08:21,550 --> 00:08:26,260
if you want to program them with that

00:08:23,050 --> 00:08:28,510
that's great and for some tasks that's

00:08:26,260 --> 00:08:30,520
absolutely the way to do what we've done

00:08:28,510 --> 00:08:32,950
over the years is adding other tools on

00:08:30,520 --> 00:08:34,330
top of it so we added the C compiler in

00:08:32,950 --> 00:08:35,800
the beginning it was mostly for the

00:08:34,330 --> 00:08:38,530
hardware guys but they wanted to write

00:08:35,800 --> 00:08:39,940
it in C but still they had to connect it

00:08:38,530 --> 00:08:41,470
with other things and so I want to do

00:08:39,940 --> 00:08:42,820
all the glue and all that stuff

00:08:41,470 --> 00:08:45,250
themselves you really have to be a

00:08:42,820 --> 00:08:47,650
hardware designer to use it but you

00:08:45,250 --> 00:08:49,260
could take your city code it will unroll

00:08:47,650 --> 00:08:51,390
your loops and so on and

00:08:49,260 --> 00:08:53,700
did things like matrix operations or so

00:08:51,390 --> 00:08:56,340
on you can really go wide and you know

00:08:53,700 --> 00:08:59,430
go hundred multiply accumulates per

00:08:56,340 --> 00:09:01,800
cycle and things like that right what we

00:08:59,430 --> 00:09:03,750
done late in the last few years is then

00:09:01,800 --> 00:09:05,040
add another layer on top of it is for

00:09:03,750 --> 00:09:07,220
software guys like myself

00:09:05,040 --> 00:09:09,660
so now you can write your C code and

00:09:07,220 --> 00:09:11,250
then you can just point to function and

00:09:09,660 --> 00:09:14,070
say hey I want this one to run in

00:09:11,250 --> 00:09:15,480
hardware if you just do that the nothing

00:09:14,070 --> 00:09:17,130
else you've probably run it will

00:09:15,480 --> 00:09:18,690
probably not Brown that great if you

00:09:17,130 --> 00:09:21,240
haven't thought about things when you

00:09:18,690 --> 00:09:23,340
would never do something like parsing a

00:09:21,240 --> 00:09:25,410
linked list in an FPGA just doesn't make

00:09:23,340 --> 00:09:27,450
sense you want to have the data concise

00:09:25,410 --> 00:09:30,000
and close to each other and things like

00:09:27,450 --> 00:09:31,380
that right yeah but if you know what

00:09:30,000 --> 00:09:33,390
you're doing it's a little bit like

00:09:31,380 --> 00:09:34,890
programming this piece you have to

00:09:33,390 --> 00:09:36,990
understand a little bit all the hardware

00:09:34,890 --> 00:09:38,640
underneath but once you know that then

00:09:36,990 --> 00:09:41,130
you can apply some pragmas and things

00:09:38,640 --> 00:09:42,990
like that you can yourself specify how

00:09:41,130 --> 00:09:45,930
do I want to date the moment to happen

00:09:42,990 --> 00:09:49,890
should I use the DMA plug-in a new DMA

00:09:45,930 --> 00:09:52,140
myself and so on so forth right so an

00:09:49,890 --> 00:09:54,930
example of that so the tool that's doing

00:09:52,140 --> 00:09:59,280
that in the embedded space is called SD

00:09:54,930 --> 00:10:01,710
SOC and we have a similar tool for the

00:09:59,280 --> 00:10:03,420
data centers called SD excel kind of the

00:10:01,710 --> 00:10:05,940
same infrastructure underneath but

00:10:03,420 --> 00:10:07,650
different use cases because here we're

00:10:05,940 --> 00:10:09,750
running portal the application on the

00:10:07,650 --> 00:10:14,310
embedded arm course and part of it in

00:10:09,750 --> 00:10:16,380
the fabric so if you imagine really

00:10:14,310 --> 00:10:18,990
stupid program here that's not really

00:10:16,380 --> 00:10:21,090
that great because someone forgot to

00:10:18,990 --> 00:10:23,160
initialize the matrices here so they're

00:10:21,090 --> 00:10:25,890
doing multiply and add on something

00:10:23,160 --> 00:10:27,810
that's unknown that takes it had to fit

00:10:25,890 --> 00:10:30,630
on the slide I guess so what we're doing

00:10:27,810 --> 00:10:31,770
here is really so this is more

00:10:30,630 --> 00:10:35,550
pseudocode of course

00:10:31,770 --> 00:10:38,070
so you're doing a multiply B times D to

00:10:35,550 --> 00:10:42,390
a and this can be really big matrices of

00:10:38,070 --> 00:10:44,850
course writes and then you take it's

00:10:42,390 --> 00:10:47,010
actually a times B to D and then you

00:10:44,850 --> 00:10:50,070
take D plus C so it's just a regular

00:10:47,010 --> 00:10:53,040
multiplier and add an operation into E

00:10:50,070 --> 00:10:54,900
and then on the command line or you can

00:10:53,040 --> 00:10:57,390
do it from from the IDE you just point

00:10:54,900 --> 00:11:00,000
to these two functions here and say that

00:10:57,390 --> 00:11:01,279
I want these two guys to run in the

00:11:00,000 --> 00:11:03,499
fabric has dead

00:11:01,279 --> 00:11:04,910
what a compiler does and it looks like a

00:11:03,499 --> 00:11:06,439
regular compiler you have the same

00:11:04,910 --> 00:11:08,749
options and things like that right what

00:11:06,439 --> 00:11:11,149
it does then is under the hood it

00:11:08,749 --> 00:11:13,310
compiles the rest of the code with

00:11:11,149 --> 00:11:14,990
regular DC or what compiler you're using

00:11:13,310 --> 00:11:17,779
put that on the arm you get the nail

00:11:14,990 --> 00:11:20,120
file out of that the other stuff under

00:11:17,779 --> 00:11:22,370
the hood it pushes that stuff through or

00:11:20,120 --> 00:11:25,879
HLS compiler which is a high level

00:11:22,370 --> 00:11:30,529
synthesis it takes to see into RTL which

00:11:25,879 --> 00:11:32,749
is the sort of the language of PDA and

00:11:30,529 --> 00:11:34,430
then it builds all the different stuff

00:11:32,749 --> 00:11:37,040
all the glue in between as well

00:11:34,430 --> 00:11:39,110
so in this particular case kind of be

00:11:37,040 --> 00:11:42,259
interesting here that you have to get

00:11:39,110 --> 00:11:44,449
obviously the first two matrices into

00:11:42,259 --> 00:11:46,550
the multiplier there you can specify

00:11:44,449 --> 00:11:48,889
yourself if you want to use one DMA for

00:11:46,550 --> 00:11:50,689
those two or separate DMA sand or if you

00:11:48,889 --> 00:11:53,120
just want to copy it to the main memory

00:11:50,689 --> 00:11:55,309
lots of different ways so we have really

00:11:53,120 --> 00:11:58,100
made the data movements a first-class

00:11:55,309 --> 00:12:00,350
citizen you can really specify outside

00:11:58,100 --> 00:12:02,899
of the code itself how you want to move

00:12:00,350 --> 00:12:04,790
the data back and forth the compiler is

00:12:02,899 --> 00:12:06,620
smart enough to see that ad is the

00:12:04,790 --> 00:12:08,329
output of one of these blocks here I

00:12:06,620 --> 00:12:10,430
really don't have to go back to memory I

00:12:08,329 --> 00:12:12,889
can just stream that into the next to

00:12:10,430 --> 00:12:14,569
the other there by doing this you can

00:12:12,889 --> 00:12:16,819
imagine if you have a video pipeline and

00:12:14,569 --> 00:12:18,680
you have like a sobel filter and the

00:12:16,819 --> 00:12:20,750
corner detection that's something after

00:12:18,680 --> 00:12:23,660
another you can actually write that all

00:12:20,750 --> 00:12:25,910
in C but all the data moment everything

00:12:23,660 --> 00:12:29,540
real is actually happening in FPGA it

00:12:25,910 --> 00:12:31,490
just shuffling the data from one block

00:12:29,540 --> 00:12:32,930
to the next block so it's a really

00:12:31,490 --> 00:12:35,000
interesting way of doing it from a

00:12:32,930 --> 00:12:37,600
software point of view but they're not

00:12:35,000 --> 00:12:39,589
the hardware do all the hard work here

00:12:37,600 --> 00:12:41,660
another really interesting thing with

00:12:39,589 --> 00:12:43,519
this is it's a little bit when I started

00:12:41,660 --> 00:12:46,490
programming which was back in the 70s

00:12:43,519 --> 00:12:48,769
the compilers were not that great it's

00:12:46,490 --> 00:12:52,160
very often even if you used like C for

00:12:48,769 --> 00:12:53,420
example very often if you were in order

00:12:52,160 --> 00:12:54,980
placed you looked at the assembly code

00:12:53,420 --> 00:12:56,720
and say hey I can do better than that

00:12:54,980 --> 00:12:57,829
right you didn't do that for everything

00:12:56,720 --> 00:12:59,779
but it was something that you really

00:12:57,829 --> 00:13:02,389
wanted to to run fast you wrote your own

00:12:59,779 --> 00:13:03,679
assembly code for also six to eight

00:13:02,389 --> 00:13:06,589
thousand or something like that right

00:13:03,679 --> 00:13:08,029
but you didn't write everything and he

00:13:06,589 --> 00:13:09,889
still had a linker that linked to

00:13:08,029 --> 00:13:12,170
everything together so you can do the

00:13:09,889 --> 00:13:13,440
same thing here you can start putting a

00:13:12,170 --> 00:13:15,690
lot of stuff in

00:13:13,440 --> 00:13:17,910
see put it over there if you're not

00:13:15,690 --> 00:13:19,560
happy with the code you can then have

00:13:17,910 --> 00:13:22,740
someone or yourself if you know very

00:13:19,560 --> 00:13:24,390
longer VHDL replace that part as long as

00:13:22,740 --> 00:13:27,060
you connect to the acts the interfaces

00:13:24,390 --> 00:13:29,820
the right way and make that sort of a

00:13:27,060 --> 00:13:32,250
library that someone else can use so

00:13:29,820 --> 00:13:34,110
that way you can work together with your

00:13:32,250 --> 00:13:36,300
hardware guys that knows those kind of

00:13:34,110 --> 00:13:44,610
languages and use this tool more as a

00:13:36,300 --> 00:13:46,140
way to glue things together so then on

00:13:44,610 --> 00:13:48,180
top of that we have added other things

00:13:46,140 --> 00:13:51,780
of like for machine learning for example

00:13:48,180 --> 00:13:53,160
people not really writing all the matrix

00:13:51,780 --> 00:13:55,020
multiplying so on themselves then you

00:13:53,160 --> 00:13:56,970
think affair your tensor flower so on so

00:13:55,020 --> 00:13:59,880
we have interfaces from that that then

00:13:56,970 --> 00:14:02,700
generates either for our data center

00:13:59,880 --> 00:14:05,010
each case or are embedded use case and

00:14:02,700 --> 00:14:07,140
that way it's really nice wave because

00:14:05,010 --> 00:14:09,720
then we and our partners can work on

00:14:07,140 --> 00:14:12,210
optimize the neural networks that gets

00:14:09,720 --> 00:14:14,280
output from from Caffe for example right

00:14:12,210 --> 00:14:16,950
so as a programmer you really don't know

00:14:14,280 --> 00:14:19,080
have to know anything about about FPS at

00:14:16,950 --> 00:14:22,620
all we also have a bunch of other

00:14:19,080 --> 00:14:25,230
libraries like open severe ffmpeg and

00:14:22,620 --> 00:14:27,360
things like that weird accelerators in

00:14:25,230 --> 00:14:29,310
the fpga so from a software point of

00:14:27,360 --> 00:14:31,890
view it looks like just another

00:14:29,310 --> 00:14:33,960
accelerator just a library call and

00:14:31,890 --> 00:14:36,690
that's really where we want to get to is

00:14:33,960 --> 00:14:38,550
that for most software people they just

00:14:36,690 --> 00:14:40,440
call a library and things we run fast

00:14:38,550 --> 00:14:42,870
and then you have some other people are

00:14:40,440 --> 00:14:45,540
really good at writing those

00:14:42,870 --> 00:14:47,070
accelerators into their today and that's

00:14:45,540 --> 00:14:51,320
what the tools allows you to have that

00:14:47,070 --> 00:14:51,320
that separation between those things

00:14:53,600 --> 00:15:00,020
so here's another machine learning

00:14:56,570 --> 00:15:02,300
example from one of our partners defy so

00:15:00,020 --> 00:15:04,070
this is the interesting thing of course

00:15:02,300 --> 00:15:05,810
as you guys know about machine learning

00:15:04,070 --> 00:15:08,600
is that you have all these different

00:15:05,810 --> 00:15:13,580
kinds of neural networks and there's a

00:15:08,600 --> 00:15:14,990
lot of new innovation coming and every

00:15:13,580 --> 00:15:17,350
day's work really well with us because

00:15:14,990 --> 00:15:20,030
you can really design your own hardware

00:15:17,350 --> 00:15:22,580
so that it really fits to it in this

00:15:20,030 --> 00:15:27,800
case they have an SSD network so that's

00:15:22,580 --> 00:15:30,350
the single shot multi box network and so

00:15:27,800 --> 00:15:33,020
they're comparing that with the NVIDIA

00:15:30,350 --> 00:15:35,500
GPU and we get five times the

00:15:33,020 --> 00:15:38,300
performance per watt before performance

00:15:35,500 --> 00:15:40,160
and very often performs raw performance

00:15:38,300 --> 00:15:42,080
is really important and you can get that

00:15:40,160 --> 00:15:44,000
and you can use really big everydays for

00:15:42,080 --> 00:15:45,770
that but very often it's performance per

00:15:44,000 --> 00:15:50,150
watt all right for example if you have a

00:15:45,770 --> 00:15:52,430
a camera in a car you can only use like

00:15:50,150 --> 00:15:54,890
five watt or something like that for for

00:15:52,430 --> 00:15:57,020
the camera that's front-facing so it's

00:15:54,890 --> 00:15:58,880
really the computer to get per watt

00:15:57,020 --> 00:16:08,860
that's really really important in many

00:15:58,880 --> 00:16:11,120
cases right so as we heard two days ago

00:16:08,860 --> 00:16:13,850
what we're doing now is that we're

00:16:11,120 --> 00:16:16,970
launching one of the board called ultra

00:16:13,850 --> 00:16:19,670
96 that will sell for 249 and this is

00:16:16,970 --> 00:16:21,170
really the first time before our boards

00:16:19,670 --> 00:16:23,840
that we've been providing ourselves

00:16:21,170 --> 00:16:25,940
being bigger really showcasing the a few

00:16:23,840 --> 00:16:27,800
days with all the i/o and so on this is

00:16:25,940 --> 00:16:30,830
really meant for software guys to

00:16:27,800 --> 00:16:32,900
experiment and work on and and it's

00:16:30,830 --> 00:16:35,300
really cool I really love this part I've

00:16:32,900 --> 00:16:37,580
been using it quite a bit myself and you

00:16:35,300 --> 00:16:39,350
can use it in many different ways you

00:16:37,580 --> 00:16:41,870
can use it like a Raspberry Pi kinda

00:16:39,350 --> 00:16:44,510
like thing you just connect to it either

00:16:41,870 --> 00:16:46,910
over wireless or you can attach a

00:16:44,510 --> 00:16:49,100
monitor and a keyboard and then you just

00:16:46,910 --> 00:16:51,290
GCC and you do your make and everything

00:16:49,100 --> 00:16:54,260
on the board itself really easy to get

00:16:51,290 --> 00:16:56,060
going and lots of examples and so on or

00:16:54,260 --> 00:16:58,100
you can download our cross-compiled

00:16:56,060 --> 00:17:00,500
compilation tools across environment and

00:16:58,100 --> 00:17:02,420
then we get the full Eclipse IDE we can

00:17:00,500 --> 00:17:04,990
do debugging over JTAG and things like

00:17:02,420 --> 00:17:08,439
that and and all those those are or

00:17:04,990 --> 00:17:13,510
available for free there what we also

00:17:08,439 --> 00:17:16,270
have is the SD SOC - so that will come

00:17:13,510 --> 00:17:17,920
in a couple of months for for this

00:17:16,270 --> 00:17:21,160
particular board is not ported to this

00:17:17,920 --> 00:17:22,329
board as of yet and then but then when

00:17:21,160 --> 00:17:27,130
you get this board you will get the

00:17:22,329 --> 00:17:30,670
one-year free license for for that SDS

00:17:27,130 --> 00:17:32,710
OC toll as well yeah so so this is

00:17:30,670 --> 00:17:35,890
really fun to play around with yourself

00:17:32,710 --> 00:17:38,200
because you can say C programmer C++ or

00:17:35,890 --> 00:17:40,480
OpenGL you can write your own code and

00:17:38,200 --> 00:17:43,720
see what happens and really fun to play

00:17:40,480 --> 00:17:45,010
around with and as since it's so fun to

00:17:43,720 --> 00:17:47,800
play around with we're actually going to

00:17:45,010 --> 00:17:50,080
give away thirty of these on Friday so

00:17:47,800 --> 00:17:52,330
we're having this contest coming up so I

00:17:50,080 --> 00:17:55,270
really encourage you guys to to look

00:17:52,330 --> 00:17:58,480
into this so what we're going to do you

00:17:55,270 --> 00:18:01,510
can come to our table at on Friday come

00:17:58,480 --> 00:18:03,280
up with a proposal on hey this is what I

00:18:01,510 --> 00:18:06,429
would use the board for and they will

00:18:03,280 --> 00:18:09,640
pick the the the coolest ideas there 30

00:18:06,429 --> 00:18:11,230
of them and then you have some time to

00:18:09,640 --> 00:18:13,059
work on it right and then you can submit

00:18:11,230 --> 00:18:16,000
something later on and there will be

00:18:13,059 --> 00:18:17,559
prizes and so on for that so kind of a

00:18:16,000 --> 00:18:20,230
fun thing as well but we really want to

00:18:17,559 --> 00:18:22,870
get this board out for people to really

00:18:20,230 --> 00:18:24,280
experience the FPGAs and because it is a

00:18:22,870 --> 00:18:29,350
little bit of a new way of thinking of

00:18:24,280 --> 00:18:31,929
course so go to to end with a little

00:18:29,350 --> 00:18:34,420
demo so if you guys can get that up and

00:18:31,929 --> 00:18:36,850
it's still running you never know when

00:18:34,420 --> 00:18:39,160
you're when you're up here so what are

00:18:36,850 --> 00:18:42,220
we doing here so this is yet another

00:18:39,160 --> 00:18:45,070
type of network this type time it's a

00:18:42,220 --> 00:18:47,410
binary network binary means that all the

00:18:45,070 --> 00:18:51,370
weights and activation function or just

00:18:47,410 --> 00:18:53,530
one or minus one basically so only have

00:18:51,370 --> 00:18:56,110
the two values and as you can imagine

00:18:53,530 --> 00:18:57,580
one of the advantages within fpga is

00:18:56,110 --> 00:19:00,160
that you can have this mixed precision

00:18:57,580 --> 00:19:02,230
obviously you can do you know 32-bit

00:19:00,160 --> 00:19:05,380
stuff you can do a much bigger you can

00:19:02,230 --> 00:19:07,809
do 8 bit you can do 1 bit it just means

00:19:05,380 --> 00:19:10,780
that it uses a lot less of these lots

00:19:07,809 --> 00:19:12,610
and these pieces in there and that the

00:19:10,780 --> 00:19:14,320
power consumption goes near dramatically

00:19:12,610 --> 00:19:16,100
of course the nice thing with binary

00:19:14,320 --> 00:19:17,869
network is that you can use

00:19:16,100 --> 00:19:20,179
you know bits of operations is to

00:19:17,869 --> 00:19:22,009
multiply right to do the X ORS and stuff

00:19:20,179 --> 00:19:24,229
like that so it's kind of interesting

00:19:22,009 --> 00:19:27,559
and that way you can have deeper and

00:19:24,229 --> 00:19:29,299
bigger networks and and get a similar

00:19:27,559 --> 00:19:31,970
precision as opposed to a regular

00:19:29,299 --> 00:19:35,809
Network what we're doing here we program

00:19:31,970 --> 00:19:37,659
this with road signs for some reason

00:19:35,809 --> 00:19:41,479
German road signs because there was a

00:19:37,659 --> 00:19:45,769
database of that so so we put that

00:19:41,479 --> 00:19:48,739
through training in Amazon so people

00:19:45,769 --> 00:19:50,749
always ask so it costs seven dollars and

00:19:48,739 --> 00:19:55,039
78 cents I guess to do the training for

00:19:50,749 --> 00:19:58,519
for this thing and and then we take the

00:19:55,039 --> 00:20:00,590
output of that convert into a binary the

00:19:58,519 --> 00:20:02,659
weights and so on into binary and then

00:20:00,590 --> 00:20:04,879
we run it on this little board so this

00:20:02,659 --> 00:20:07,039
is the board that we are ultra

00:20:04,879 --> 00:20:09,019
ninety-six it's one of these small ones

00:20:07,039 --> 00:20:13,879
that's just the same it's the same four

00:20:09,019 --> 00:20:20,659
factor that's the 96 port of course yeah

00:20:13,879 --> 00:20:23,690
and the perform is pretty amazing we are

00:20:20,659 --> 00:20:25,909
actually running in parallel on the CPUs

00:20:23,690 --> 00:20:28,340
and again binary networks are not that

00:20:25,909 --> 00:20:30,710
great for CPUs right so it's a little

00:20:28,340 --> 00:20:33,799
bit of an interesting comparison here

00:20:30,710 --> 00:20:36,590
but what we actually get is like 19 or

00:20:33,799 --> 00:20:38,210
90 thousand frames per second

00:20:36,590 --> 00:20:41,119
actually right now here I say we get

00:20:38,210 --> 00:20:42,859
like 14,000 so I don't know if the

00:20:41,119 --> 00:20:45,559
electricity is a little bit weaker here

00:20:42,859 --> 00:20:52,220
in China or something going on but say

00:20:45,559 --> 00:20:56,299
15,000 here while we get 94 frames per

00:20:52,220 --> 00:20:58,519
second on on the or tiles per second 2.2

00:20:56,299 --> 00:21:01,789
tiles per second I mean which means that

00:20:58,519 --> 00:21:05,929
it's 92 seconds per frame to run it on

00:21:01,789 --> 00:21:08,629
the CPU and you can do 94 frames per

00:21:05,929 --> 00:21:11,299
seconds on the FPGA so then you do the

00:21:08,629 --> 00:21:13,460
calculation so when we ran at that time

00:21:11,299 --> 00:21:16,399
it was eight thousand six hundred times

00:21:13,460 --> 00:21:20,139
faster which is a big deal that's a

00:21:16,399 --> 00:21:22,549
pretty big deal and what's doing is is

00:21:20,139 --> 00:21:24,710
an Emmy we went out and took a bunch of

00:21:22,549 --> 00:21:27,289
photos and be running through that and

00:21:24,710 --> 00:21:28,679
I'm told that it actually has a couple

00:21:27,289 --> 00:21:30,480
of errors in here I

00:21:28,679 --> 00:21:33,419
haven't really been able to detect them

00:21:30,480 --> 00:21:35,399
but somewhere guys say that there are a

00:21:33,419 --> 00:21:38,659
couple you know how it works in Iran

00:21:35,399 --> 00:21:38,659
that / - you don't always get it right

00:21:41,210 --> 00:21:45,659
if you want to know more about the stuff

00:21:43,980 --> 00:21:47,460
I've been talking about and and

00:21:45,659 --> 00:21:49,980
interesting view a little bit deeper

00:21:47,460 --> 00:21:52,619
then Jillian is going to make a couple

00:21:49,980 --> 00:21:56,429
of presentations here so one is today at

00:21:52,619 --> 00:21:58,649
4 o'clock talking more generally about

00:21:56,429 --> 00:22:00,450
accelerating things on the Neff PDA and

00:21:58,649 --> 00:22:06,600
then more talking about the neural

00:22:00,450 --> 00:22:08,039
networks tomorrow at 11 right so I don't

00:22:06,600 --> 00:22:12,570
know do we have time for maybe a couple

00:22:08,039 --> 00:22:18,779
questions there's anybody any questions

00:22:12,570 --> 00:22:21,240
for Tomas mad dog not so much a question

00:22:18,779 --> 00:22:24,330
but one thing you didn't really point

00:22:21,240 --> 00:22:26,429
out is that the FPGA not only speeds up

00:22:24,330 --> 00:22:28,710
the calculations but all flows the main

00:22:26,429 --> 00:22:30,360
processor from having to do it so your

00:22:28,710 --> 00:22:34,350
main processor can be concentrating more

00:22:30,360 --> 00:22:36,059
on other things exactly so so one of

00:22:34,350 --> 00:22:38,279
their whole ideas and that's something

00:22:36,059 --> 00:22:40,350
you can do with these tools as well is

00:22:38,279 --> 00:22:42,149
to really make sure part of it get the

00:22:40,350 --> 00:22:45,149
speed up is to get the pipelining going

00:22:42,149 --> 00:22:47,039
so that you feel feel the PDA with doing

00:22:45,149 --> 00:22:49,139
stuff all the time but then of course

00:22:47,039 --> 00:22:51,570
you have done the processor free doing

00:22:49,139 --> 00:22:54,240
other stuff and Glenn will talk more

00:22:51,570 --> 00:23:01,019
about that in his sessions as well good

00:22:54,240 --> 00:23:02,820
comment anyone else how much time have

00:23:01,019 --> 00:23:05,190
you spent on streamlining the feature

00:23:02,820 --> 00:23:08,669
detection process before Wilde's

00:23:05,190 --> 00:23:10,889
creating model machine learning model so

00:23:08,669 --> 00:23:12,450
how much time do you spend to manage to

00:23:10,889 --> 00:23:14,279
streamline the process of feature

00:23:12,450 --> 00:23:15,749
detection when creating your machine

00:23:14,279 --> 00:23:19,950
learning model say for image

00:23:15,749 --> 00:23:21,960
classification not right how much time

00:23:19,950 --> 00:23:23,759
we spent or how much to have you and

00:23:21,960 --> 00:23:26,249
have you been able to because a lot of

00:23:23,759 --> 00:23:27,659
time usefully in part of the machine

00:23:26,249 --> 00:23:31,799
learning models a lot of effort is spent

00:23:27,659 --> 00:23:33,450
into feature detection actually defining

00:23:31,799 --> 00:23:35,100
what the fit what features were looking

00:23:33,450 --> 00:23:37,580
for so I was wondering if you have

00:23:35,100 --> 00:23:40,619
managed to streamline that process or

00:23:37,580 --> 00:23:41,910
sorry to go on - yeah I mean the

00:23:40,619 --> 00:23:44,250
interesting thing here is that the

00:23:41,910 --> 00:23:46,230
training really you do that the same as

00:23:44,250 --> 00:23:49,260
with any other right you used the cafe

00:23:46,230 --> 00:23:51,630
and so on you run it on Amazon or other

00:23:49,260 --> 00:23:53,160
servers to do that so that part we

00:23:51,630 --> 00:23:55,620
haven't really changed at all it's

00:23:53,160 --> 00:23:58,160
really the the inference the actual

00:23:55,620 --> 00:24:01,560
execution of it that we are accelerating

00:23:58,160 --> 00:24:03,450
more at the edge in this case or or in

00:24:01,560 --> 00:24:07,070
the cloud as well so but the training

00:24:03,450 --> 00:24:07,070
part we're not touching that really see

00:24:07,160 --> 00:24:18,360
anyone else when you provide all the

00:24:16,410 --> 00:24:23,700
standard acceleration libraries like the

00:24:18,360 --> 00:24:26,160
ffmpeg or other blocks do your customers

00:24:23,700 --> 00:24:27,780
have to write custom drivers for every

00:24:26,160 --> 00:24:30,030
application or is there a bunch of

00:24:27,780 --> 00:24:33,720
drivers that you provide and that you

00:24:30,030 --> 00:24:35,550
have up streamed yeah no so so what

00:24:33,720 --> 00:24:37,230
we're doing is if you're using like or

00:24:35,550 --> 00:24:40,470
OpenCV libraries or something like that

00:24:37,230 --> 00:24:42,420
right so that comes so from your point

00:24:40,470 --> 00:24:44,250
of view so those are in open source so

00:24:42,420 --> 00:24:48,270
you can go and see and they're written

00:24:44,250 --> 00:24:49,770
so for example the neural network binary

00:24:48,270 --> 00:24:51,300
Network for this is written in C

00:24:49,770 --> 00:24:54,120
actually so you can look at the code and

00:24:51,300 --> 00:24:56,040
see how that looks like and then for

00:24:54,120 --> 00:24:58,320
interfaces so one the tool will take

00:24:56,040 --> 00:24:59,970
care of the interfaces so what do you

00:24:58,320 --> 00:25:01,170
basically do is saying that I want to

00:24:59,970 --> 00:25:03,390
have this library and this library

00:25:01,170 --> 00:25:06,210
basically calling those libraries and

00:25:03,390 --> 00:25:08,430
then it will create a bit stream which

00:25:06,210 --> 00:25:10,350
is the FPGA and the interfaces will

00:25:08,430 --> 00:25:13,380
automatically created if you want to you

00:25:10,350 --> 00:25:15,840
can then go in and change the default to

00:25:13,380 --> 00:25:18,030
something different if you want to have

00:25:15,840 --> 00:25:19,800
you know a different DMA or have

00:25:18,030 --> 00:25:23,190
multiple the image can stream a little

00:25:19,800 --> 00:25:25,950
better but so typically the the flow is

00:25:23,190 --> 00:25:27,780
that you get it going first you just

00:25:25,950 --> 00:25:29,850
compile and get it going then we have

00:25:27,780 --> 00:25:32,370
tools and we'll talk about that a little

00:25:29,850 --> 00:25:34,410
bit later in the other sessions where

00:25:32,370 --> 00:25:36,060
you can see exactly where you spend your

00:25:34,410 --> 00:25:38,160
time on the buses and so on so that you

00:25:36,060 --> 00:25:39,750
can go back into your code and change a

00:25:38,160 --> 00:25:41,910
little bit so it can really streamline

00:25:39,750 --> 00:25:43,500
to overlap the transfer of data where

00:25:41,910 --> 00:25:44,670
you computed it and things like that so

00:25:43,500 --> 00:25:46,470
that's really what you spend your time

00:25:44,670 --> 00:25:52,830
on when you use these kind of tools to

00:25:46,470 --> 00:25:54,330
get it faster so sorry so your

00:25:52,830 --> 00:25:55,440
application scenario you mention a lot

00:25:54,330 --> 00:25:58,919
about neural net

00:25:55,440 --> 00:26:00,360
in furnace scenario and in today's a lot

00:25:58,919 --> 00:26:04,590
of inference changing they use a

00:26:00,360 --> 00:26:07,019
standard libraries like Jim Lowe P so

00:26:04,590 --> 00:26:10,529
the one thing I didn't quite get is do

00:26:07,019 --> 00:26:13,769
you expect us just compiled that Jim

00:26:10,529 --> 00:26:17,730
Lowe P and then your cross compiler do

00:26:13,769 --> 00:26:21,240
that or you have prepackaged some of

00:26:17,730 --> 00:26:23,490
those so now we just link yes so we have

00:26:21,240 --> 00:26:25,110
so for example for cafe and and we're

00:26:23,490 --> 00:26:28,759
coming up with tensorflow and so on if

00:26:25,110 --> 00:26:31,679
you're using those we are doing all the

00:26:28,759 --> 00:26:33,779
everything underneath so we taking the

00:26:31,679 --> 00:26:35,490
output of that and then doing all the

00:26:33,779 --> 00:26:38,730
work together any until inefficient

00:26:35,490 --> 00:26:40,620
bitstream so and then we have in a

00:26:38,730 --> 00:26:42,299
roadmap of other libraries and

00:26:40,620 --> 00:26:45,240
frameworks to be going to support coming

00:26:42,299 --> 00:26:47,519
forward so the intent is not that

00:26:45,240 --> 00:26:50,159
everyone should you know implement that

00:26:47,519 --> 00:26:51,929
by themselves but still it's fairly

00:26:50,159 --> 00:26:53,399
early on so it's just the most popular

00:26:51,929 --> 00:26:56,129
ones that we've done and then we have

00:26:53,399 --> 00:26:58,440
partners that's doing a bunch of the

00:26:56,129 --> 00:27:00,480
other ones as well so there quite a few

00:26:58,440 --> 00:27:02,370
out there already some that we are doing

00:27:00,480 --> 00:27:04,440
and but then we have some partners doing

00:27:02,370 --> 00:27:06,870
it as well or you can also of course

00:27:04,440 --> 00:27:08,879
feel free yourself to do the lower level

00:27:06,870 --> 00:27:11,279
and an experiment without as well

00:27:08,879 --> 00:27:12,990
because there are different ways of how

00:27:11,279 --> 00:27:16,529
you know how we want to get the data

00:27:12,990 --> 00:27:20,519
through the yeah let me just a little

00:27:16,529 --> 00:27:24,750
bit on the same line when I accelerate

00:27:20,519 --> 00:27:26,429
the inference I could just exert one

00:27:24,750 --> 00:27:31,620
particular operator in the network for

00:27:26,429 --> 00:27:35,039
example come to D or you know accumulate

00:27:31,620 --> 00:27:36,960
add or could really extend and make it a

00:27:35,039 --> 00:27:40,230
powerful to take for example doing

00:27:36,960 --> 00:27:42,870
inference on the whole graph do you have

00:27:40,230 --> 00:27:44,909
any I mean which approach you're

00:27:42,870 --> 00:27:48,450
thinking this is the best way of using

00:27:44,909 --> 00:27:50,340
your engine for that yes so currently

00:27:48,450 --> 00:27:52,230
what we're doing is actually you sort of

00:27:50,340 --> 00:27:55,350
design your own network and you use one

00:27:52,230 --> 00:27:57,000
of these these frameworks and then we

00:27:55,350 --> 00:27:59,220
take it take care of that we are not

00:27:57,000 --> 00:28:01,090
really at this point helping you decide

00:27:59,220 --> 00:28:03,850
if it's better with a binary network or

00:28:01,090 --> 00:28:05,290
or with a different kind of network that

00:28:03,850 --> 00:28:08,350
sort of up to you but at this point

00:28:05,290 --> 00:28:09,940
thank you okay so I'm gonna have one

00:28:08,350 --> 00:28:11,440
final question I'm curious about it and

00:28:09,940 --> 00:28:11,980
I think it's an easy one so I'm just

00:28:11,440 --> 00:28:14,440
curious

00:28:11,980 --> 00:28:16,540
our Spectre and melt down a risk factor

00:28:14,440 --> 00:28:19,150
in the world of FPGAs or they're really

00:28:16,540 --> 00:28:21,700
not a consideration now that's the nice

00:28:19,150 --> 00:28:25,900
thing with with the everydays so they

00:28:21,700 --> 00:28:30,180
are really nothing like that in there I

00:28:25,900 --> 00:28:33,940
mean if you want abilities like that

00:28:30,180 --> 00:28:35,320
really it's more more more an issue when

00:28:33,940 --> 00:28:37,150
people know when you're seeing the same

00:28:35,320 --> 00:28:39,400
thing so we have armed course in there

00:28:37,150 --> 00:28:43,780
on this one we have the 53 which vector

00:28:39,400 --> 00:28:45,460
is not an issue FPGA fabric itself you

00:28:43,780 --> 00:28:47,530
can put processors there and we have our

00:28:45,460 --> 00:28:49,450
soft course they don't have those kind

00:28:47,530 --> 00:28:51,550
of issues but the rest of the code is

00:28:49,450 --> 00:28:53,920
really your own code so if you have

00:28:51,550 --> 00:28:55,660
vulnerabilities well first of all the

00:28:53,920 --> 00:28:56,800
person trying to attack it has to know

00:28:55,660 --> 00:28:58,870
what the heck you were doing in their

00:28:56,800 --> 00:29:01,210
bit every day so that's a big big

00:28:58,870 --> 00:29:03,070
because they they can't easily get to

00:29:01,210 --> 00:29:04,930
the bit stream right right thank you

00:29:03,070 --> 00:29:11,410
all right Tomas thank you so much that

00:29:04,930 --> 00:29:13,090
was really interesting okay so we're

00:29:11,410 --> 00:29:16,380
gonna take a little break we'll start

00:29:13,090 --> 00:29:19,320
again at 10:30 in here for enterprise

00:29:16,380 --> 00:29:21,880
HPC and AI machine learning and

00:29:19,320 --> 00:29:25,060
ecosystem day and next door for

00:29:21,880 --> 00:29:27,780
automotive mobile and embedded so have a

00:29:25,060 --> 00:29:27,780

YouTube URL: https://www.youtube.com/watch?v=9BgTGuQLT4M


