Title: HKG18 Keynote: Mingfei Huang: Accelerating AI from Cloud to Edge
Publication date: 2019-05-09
Playlist: Linaro Connect Hong Kong 2018
Description: 
	Keynote: Mingfei Huang: Accelerating AI from Cloud to Edge (HKG18-200K2)
Captions: 
	00:00:05,009 --> 00:00:09,960
I'm in favor one from open-air lab thank

00:00:09,179 --> 00:00:14,670
you everyone

00:00:09,960 --> 00:00:18,869
good morning I will introduce our lab

00:00:14,670 --> 00:00:29,630
and the labs who work open I open I'd is

00:00:18,869 --> 00:00:29,630
our AI software platform okay yes okay

00:00:41,719 --> 00:00:51,140
this is a lab open air lab will initiate

00:00:46,620 --> 00:00:51,140
by arm a winner

00:00:51,390 --> 00:01:05,330
Horan robotics and Sarita in December

00:00:58,010 --> 00:01:10,100
2016 we focused on open a eyes software

00:01:05,330 --> 00:01:14,909
for each computing this age including

00:01:10,100 --> 00:01:19,080
edge gateway and device so we focus on

00:01:14,909 --> 00:01:25,400
embodied a device it's AI software

00:01:19,080 --> 00:01:30,210
platform we our headquarter in Shanghai

00:01:25,400 --> 00:01:40,380
also have division in Beijing and on the

00:01:30,210 --> 00:01:45,860
center I'm based in Beijing this general

00:01:40,380 --> 00:01:50,369
idea about AI it have it includes

00:01:45,860 --> 00:01:58,950
chilling and the inference also have

00:01:50,369 --> 00:02:01,229
cloud and aid we focus on 8 inference so

00:01:58,950 --> 00:02:06,810
far we haven't seen any requirements

00:02:01,229 --> 00:02:10,190
about each training our focus on also is

00:02:06,810 --> 00:02:13,140
based on arms solution is because our

00:02:10,190 --> 00:02:19,810
background

00:02:13,140 --> 00:02:27,400
okay this is our walk opener the deed

00:02:19,810 --> 00:02:36,010
means to destroy okay this our software

00:02:27,400 --> 00:02:41,860
platform for for AI h computing you can

00:02:36,010 --> 00:02:44,980
see in the in the middle box is open ID

00:02:41,860 --> 00:02:50,500
it has three layers I will introduce

00:02:44,980 --> 00:02:55,990
each layer above that is applications

00:02:50,500 --> 00:02:58,840
and below that is OS and the hardware

00:02:55,990 --> 00:03:05,860
platform maybe we can start from

00:02:58,840 --> 00:03:09,610
hardware platform first ISO say we think

00:03:05,860 --> 00:03:15,760
for each computing the SOC will be

00:03:09,610 --> 00:03:22,150
combined CPU class GPU + deep learning

00:03:15,760 --> 00:03:30,070
accelerator or impure a + DSP this DSP

00:03:22,150 --> 00:03:34,000
maybe is a simple vector processor maybe

00:03:30,070 --> 00:03:39,990
some part just have cpu Toa and vector

00:03:34,000 --> 00:03:45,540
processor maybe some part of CPU I mean

00:03:39,990 --> 00:03:46,710
anyways the SOC will be heterogeneous

00:03:45,540 --> 00:03:56,650
[Music]

00:03:46,710 --> 00:04:02,860
computing platform for the board we we

00:03:56,650 --> 00:04:09,700
support the six nine six boards as opens

00:04:02,860 --> 00:04:14,050
back so if we use our our open software

00:04:09,700 --> 00:04:21,280
plans this open pod that will be open a

00:04:14,050 --> 00:04:25,000
platform for software with about Oprah

00:04:21,280 --> 00:04:30,970
OS which is about angel Linux

00:04:25,000 --> 00:04:35,500
and artists about that is our open that

00:04:30,970 --> 00:04:41,290
open I'd have three layers the low layer

00:04:35,500 --> 00:04:44,680
is computer library the middle layer is

00:04:41,290 --> 00:04:47,970
a framework it's a it's a deep learning

00:04:44,680 --> 00:04:50,980
framework or machine learning framework

00:04:47,970 --> 00:04:55,050
above that is Tommy library is a

00:04:50,980 --> 00:05:01,680
application library including Algren

00:04:55,050 --> 00:05:08,260
okay for the for the taman library

00:05:01,680 --> 00:05:13,180
it is not owning deep learning algorithm

00:05:08,260 --> 00:05:15,880
it also including as like for example

00:05:13,180 --> 00:05:21,570
doesn't mean domain term means now we

00:05:15,880 --> 00:05:26,890
support vision computer vision and and

00:05:21,570 --> 00:05:31,440
speech so in the future we will support

00:05:26,890 --> 00:05:35,910
more domains related to some sensors so

00:05:31,440 --> 00:05:40,000
for the above that for the applications

00:05:35,910 --> 00:05:44,910
if your applicant user you can call the

00:05:40,000 --> 00:05:48,280
Tommy library API you don't need to know

00:05:44,910 --> 00:05:52,330
what's the tip Learning framework you

00:05:48,280 --> 00:05:55,120
are using coming API is like for example

00:05:52,330 --> 00:05:58,630
you you don't need care about what I'll

00:05:55,120 --> 00:06:02,140
grab you just need call for example face

00:05:58,630 --> 00:06:05,470
face detection it just need to call face

00:06:02,140 --> 00:06:07,930
detection API you don't need to know

00:06:05,470 --> 00:06:13,240
what exacted outbound you are using

00:06:07,930 --> 00:06:15,790
maybe it's for example maybe it's a

00:06:13,240 --> 00:06:17,979
based on MTC and this network but you

00:06:15,790 --> 00:06:20,110
don't need to know you also don't need

00:06:17,979 --> 00:06:24,010
to know what the framework you are using

00:06:20,110 --> 00:06:28,030
it so the cafe or it's a tense flow you

00:06:24,010 --> 00:06:32,260
don't need to know that that's a dummy

00:06:28,030 --> 00:06:34,740
library for the for the framework you

00:06:32,260 --> 00:06:37,139
can see we have

00:06:34,740 --> 00:06:40,710
chanting a very popular framework

00:06:37,139 --> 00:06:45,889
supported like a cafe this cafes a cafe

00:06:40,710 --> 00:06:52,430
chart he that means it's it's HRT means

00:06:45,889 --> 00:06:57,780
had here heterogeneous runtime that's

00:06:52,430 --> 00:07:04,080
optimized cafe it's easy but it's just

00:06:57,780 --> 00:07:08,960
for arms a solution a cafe HRT or I'm

00:07:04,080 --> 00:07:08,960
accident HRT or transfer or a charity or

00:07:09,229 --> 00:07:20,580
optimized framework we also have our own

00:07:16,460 --> 00:07:25,259
framework is tianjin but it is suggested

00:07:20,580 --> 00:07:28,490
for inference not supporting training we

00:07:25,259 --> 00:07:34,440
for the changing we also support more

00:07:28,490 --> 00:07:41,719
features here we name these enhanced

00:07:34,440 --> 00:07:42,930
feature like security also support

00:07:41,719 --> 00:07:46,770
heterogeneous

00:07:42,930 --> 00:07:55,490
thalamic scheduling also support some

00:07:46,770 --> 00:08:01,949
dumbing operators like that for the low

00:07:55,490 --> 00:08:04,710
low layer library with about general

00:08:01,949 --> 00:08:07,110
blast library for example open blasts or

00:08:04,710 --> 00:08:11,190
prefer class for glass is a commercial

00:08:07,110 --> 00:08:18,199
version of open blasts i'm computer

00:08:11,190 --> 00:08:22,139
library of them are opens open sourced

00:08:18,199 --> 00:08:26,370
cafe whatever cafe HRT Amex nada h RT or

00:08:22,139 --> 00:08:28,650
tensorflow HRT or our tianjin this sub

00:08:26,370 --> 00:08:32,610
they did not only support this open

00:08:28,650 --> 00:08:37,979
source library also support our own

00:08:32,610 --> 00:08:41,159
library is HCl had your genius computing

00:08:37,979 --> 00:08:44,970
library this library is based on arm

00:08:41,159 --> 00:08:46,870
computer library we focus on special

00:08:44,970 --> 00:08:54,480
micro act action

00:08:46,870 --> 00:08:58,420
architecture for example contacts a 72 a

00:08:54,480 --> 00:09:02,620
53 a7 in the future we were suffering

00:08:58,420 --> 00:09:08,649
more macro architecture in also

00:09:02,620 --> 00:09:14,680
including codex air these are general

00:09:08,649 --> 00:09:22,050
our introduct about open air ok let's

00:09:14,680 --> 00:09:28,329
jump to more details this optimized Cafe

00:09:22,050 --> 00:09:33,129
principle Oh Amex not ok way what we

00:09:28,329 --> 00:09:38,259
what we did an optimization for my team

00:09:33,129 --> 00:09:43,920
focus on improving performance so first

00:09:38,259 --> 00:09:47,709
we make a cafe to support dynamic

00:09:43,920 --> 00:09:55,600
scheduler embodied what what does that

00:09:47,709 --> 00:10:00,899
mean first cafe we make it a support

00:09:55,600 --> 00:10:04,990
tool and scheduler we turn CPU and GPU

00:10:00,899 --> 00:10:08,350
the schedule Amin means for example if

00:10:04,990 --> 00:10:10,720
you using a network you can make the

00:10:08,350 --> 00:10:14,709
network some operators running on CPU

00:10:10,720 --> 00:10:17,680
some operator running on GPU so the

00:10:14,709 --> 00:10:24,550
natural running will be pipelined like

00:10:17,680 --> 00:10:28,089
that default cafe all the networking

00:10:24,550 --> 00:10:32,970
running you need to bundle the data work

00:10:28,089 --> 00:10:42,959
to CPU or GPU is cannot the lamp

00:10:32,970 --> 00:10:48,759
scheduling second for the for the

00:10:42,959 --> 00:10:52,889
dynamic scheduling means even for CPU we

00:10:48,759 --> 00:10:52,889
still await a limited selecting

00:10:53,550 --> 00:11:03,580
operators driver from the three kind of

00:10:58,700 --> 00:11:07,910
library what's that mean that means we

00:11:03,580 --> 00:11:12,230
for Network some operator there are

00:11:07,910 --> 00:11:15,770
there there there library from HTC L

00:11:12,230 --> 00:11:20,860
some from ACL some from open blasts like

00:11:15,770 --> 00:11:26,930
that because in our developing we found

00:11:20,860 --> 00:11:29,570
no any computer library is perfect for

00:11:26,930 --> 00:11:32,540
all networks different

00:11:29,570 --> 00:11:37,190
Algrim different model or different

00:11:32,540 --> 00:11:40,610
network they use different operators

00:11:37,190 --> 00:11:43,820
even for convolution operation different

00:11:40,610 --> 00:11:48,020
parameters will you will see different

00:11:43,820 --> 00:11:52,490
performance using different library so

00:11:48,020 --> 00:11:57,370
no one earning library is perfect for

00:11:52,490 --> 00:12:04,210
all operators so we have a deal I'm

00:11:57,370 --> 00:12:10,370
scheduling select library return three

00:12:04,210 --> 00:12:15,010
libraries let's tell our scheduler we

00:12:10,370 --> 00:12:24,400
also to some tip learning operator

00:12:15,010 --> 00:12:29,500
optimizing so we also be decided besides

00:12:24,400 --> 00:12:33,080
optimization we also did some work on

00:12:29,500 --> 00:12:40,280
tools we have invited debugging and

00:12:33,080 --> 00:12:44,690
profiling tools in invited cafe that's

00:12:40,280 --> 00:12:48,560
what we did on cafe also a max not also

00:12:44,690 --> 00:12:52,570
turns flow in the future we may support

00:12:48,560 --> 00:12:58,250
a pedo pedo of Baidu's framework

00:12:52,570 --> 00:13:02,420
ok let's optimize the cafe things below

00:12:58,250 --> 00:13:06,920
and a max net these are performance

00:13:02,420 --> 00:13:10,250
I just reuse calf HRT to compare our

00:13:06,920 --> 00:13:11,310
result you can see this is a based on

00:13:10,250 --> 00:13:18,090
arm

00:13:11,310 --> 00:13:24,450
 a53 you can carry this

00:13:18,090 --> 00:13:26,190
this performance title from our project

00:13:24,450 --> 00:13:28,650
in github

00:13:26,190 --> 00:13:32,010
for this one you can see we compare

00:13:28,650 --> 00:13:38,250
single core performance between cafe and

00:13:32,010 --> 00:13:42,240
the CAF HRT and HRT with HCl a default

00:13:38,250 --> 00:13:46,200
party for configuration HR ketones about

00:13:42,240 --> 00:13:57,180
HCl Israel need to enable so we compare

00:13:46,200 --> 00:14:04,740
the H they also support quantized data

00:13:57,180 --> 00:14:07,320
for example index in the 8 so we we can

00:14:04,740 --> 00:14:10,320
see the performance whatever is a single

00:14:07,320 --> 00:14:14,940
call or for call the performance you can

00:14:10,320 --> 00:14:17,339
say whatever our next night or google

00:14:14,940 --> 00:14:21,270
night or squeeze night or mobile night

00:14:17,339 --> 00:14:24,540
the performance skew is good okay that's

00:14:21,270 --> 00:14:30,450
our performance result you can you you

00:14:24,540 --> 00:14:38,120
can get none dot 5x come compared with

00:14:30,450 --> 00:14:38,120
or regional cafe okay that's performance

00:14:38,510 --> 00:14:44,450
changing okay it's our own framework

00:14:41,430 --> 00:14:50,190
this framework just the support

00:14:44,450 --> 00:14:52,730
inference in unit in the middle block

00:14:50,190 --> 00:14:56,270
you can see teen you have a graph

00:14:52,730 --> 00:14:59,780
presentation graphics cuter scheduler

00:14:56,270 --> 00:15:05,280
device hi scooter whatever the purpose

00:14:59,780 --> 00:15:10,830
is is general a blog for earning deep

00:15:05,280 --> 00:15:15,150
learning framework the scheduler support

00:15:10,830 --> 00:15:23,970
CPU GPU ela or DSP this Telemachus

00:15:15,150 --> 00:15:25,320
scheduling as that means if we won if

00:15:23,970 --> 00:15:29,340
one night work

00:15:25,320 --> 00:15:31,740
our model it come running on see some

00:15:29,340 --> 00:15:35,100
operator can't running on CPU some

00:15:31,740 --> 00:15:38,880
Aubrey on GPU some can be um do a some

00:15:35,100 --> 00:15:42,240
will be on TSP you may you may ask you

00:15:38,880 --> 00:15:47,120
why you already have do a you still need

00:15:42,240 --> 00:15:50,840
the CPU or DSP vac the processor to

00:15:47,120 --> 00:15:55,170
running some operators that's because

00:15:50,840 --> 00:15:58,320
the do a or until they are the operator

00:15:55,170 --> 00:16:00,740
are fixed this means if you have new

00:15:58,320 --> 00:16:05,520
operator coming or your network is

00:16:00,740 --> 00:16:09,080
special not supported by this Toa you

00:16:05,520 --> 00:16:13,560
you have problem to running the whole

00:16:09,080 --> 00:16:18,360
network rounds at dar or interview so

00:16:13,560 --> 00:16:23,790
you need some extend extended operators

00:16:18,360 --> 00:16:26,880
supported by valid processor or CPU so

00:16:23,790 --> 00:16:30,020
that's why we need this dynamic

00:16:26,880 --> 00:16:36,480
scheduling for this Hardware juniors

00:16:30,020 --> 00:16:39,830
computing platform okay that's one

00:16:36,480 --> 00:16:45,600
feature for this inference engine

00:16:39,830 --> 00:16:50,120
another very important feature is if you

00:16:45,600 --> 00:16:53,430
if you are user for cafe or tensorflow

00:16:50,120 --> 00:16:57,630
you don't want to change your software

00:16:53,430 --> 00:16:59,760
from cafe framework to Tianjin but you

00:16:57,630 --> 00:17:01,130
still want to use Tianjin to get a

00:16:59,760 --> 00:17:05,700
better performance

00:17:01,130 --> 00:17:10,950
so what what we can do in fact are

00:17:05,700 --> 00:17:15,300
changing we have cafe tensorflow a max

00:17:10,950 --> 00:17:20,030
not API interface that means our in the

00:17:15,300 --> 00:17:24,150
API interface are compatible with this

00:17:20,030 --> 00:17:25,200
transitional framework so if you are

00:17:24,150 --> 00:17:27,000
using cafe

00:17:25,200 --> 00:17:29,390
you don't need changing your software

00:17:27,000 --> 00:17:33,890
you just link to these two engines

00:17:29,390 --> 00:17:36,930
library you you can you can make it run

00:17:33,890 --> 00:17:38,140
another more important is we support

00:17:36,930 --> 00:17:40,620
cafe

00:17:38,140 --> 00:17:43,810
Amyx night tenza follows models

00:17:40,620 --> 00:17:47,590
pre-trained models you don't need to

00:17:43,810 --> 00:17:50,230
translate that to another model with

00:17:47,590 --> 00:17:54,600
supported you just need to load it and

00:17:50,230 --> 00:18:00,450
run it we also support own acts this

00:17:54,600 --> 00:18:00,450
like standard model

00:18:00,910 --> 00:18:12,850
okay this Tianjin this is a performance

00:18:06,630 --> 00:18:17,590
and this just compares the CPUs

00:18:12,850 --> 00:18:21,430
performance this we compare cafe and the

00:18:17,590 --> 00:18:24,940
optimized cafe and Tianjin

00:18:21,430 --> 00:18:30,400
we compare the fruit point also compiled

00:18:24,940 --> 00:18:34,480
a contest you can see whatever are we

00:18:30,400 --> 00:18:38,010
get better performance we use the

00:18:34,480 --> 00:18:41,950
squeeze night and mobile light eyes

00:18:38,010 --> 00:18:47,640
benchmark because in the embodied device

00:18:41,950 --> 00:18:52,480
the small network is a more popular

00:18:47,640 --> 00:18:54,670
okay this engines performance so you can

00:18:52,480 --> 00:19:01,300
see we get a better performance even

00:18:54,670 --> 00:19:07,740
than our optimized cafe for this case we

00:19:01,300 --> 00:19:07,740
can get as 22.4 6x performance

00:19:08,490 --> 00:19:18,940
okay this domain library now

00:19:14,110 --> 00:19:23,400
domina blabbering we haven't really set

00:19:18,940 --> 00:19:27,940
in github we just have some open source

00:19:23,400 --> 00:19:31,500
algorithms there but Tommy library will

00:19:27,940 --> 00:19:34,990
be released in middle of this year

00:19:31,500 --> 00:19:38,860
better the album we already released the

00:19:34,990 --> 00:19:42,930
Sun that open sourced recently this is a

00:19:38,860 --> 00:19:47,680
list with some performance I haven't

00:19:42,930 --> 00:19:52,130
listed the accuracy but you can get

00:19:47,680 --> 00:19:54,830
accuracy either in github

00:19:52,130 --> 00:19:58,270
you can say we will come we have a

00:19:54,830 --> 00:20:01,580
physically touching face recognition

00:19:58,270 --> 00:20:06,110
object attracting gasps your recognition

00:20:01,580 --> 00:20:11,420
and speech regulation for this speech

00:20:06,110 --> 00:20:16,160
recognition is not the performance is

00:20:11,420 --> 00:20:17,330
running on the device especial is ARM

00:20:16,160 --> 00:20:23,450
Cortex

00:20:17,330 --> 00:20:27,860
is 72 okay this performance is running

00:20:23,450 --> 00:20:31,700
on that single cause performance for

00:20:27,860 --> 00:20:33,740
this speech rag machines it means it's

00:20:31,700 --> 00:20:38,300
the voice command

00:20:33,740 --> 00:20:42,670
that means all others requirement is

00:20:38,300 --> 00:20:47,960
from some home device or optics it need

00:20:42,670 --> 00:20:53,390
local voice to hand to handle for for a

00:20:47,960 --> 00:20:55,820
voice command this just is for 100 voice

00:20:53,390 --> 00:20:59,300
command support here we have other

00:20:55,820 --> 00:21:04,460
versions is this one is based on is

00:20:59,300 --> 00:21:10,010
caddy based reporting from caddy we make

00:21:04,460 --> 00:21:13,130
is smaller we we use G mm-hmm model or

00:21:10,010 --> 00:21:16,190
we have also other models we also we

00:21:13,130 --> 00:21:20,020
also have non catalyst speech

00:21:16,190 --> 00:21:24,560
recognition algorithm it will be up to

00:21:20,020 --> 00:21:34,250
upload to github later okay this all

00:21:24,560 --> 00:21:39,080
these awkward list except third parties

00:21:34,250 --> 00:21:41,720
Algrim all of them are in github for

00:21:39,080 --> 00:21:43,690
example face detaching we use the MTC

00:21:41,720 --> 00:21:49,960
hands is awkward

00:21:43,690 --> 00:21:55,210
okay in this just awkward in the future

00:21:49,960 --> 00:22:00,170
Domon library up streamed you will see

00:21:55,210 --> 00:22:04,160
the algorithm will be packaged into a

00:22:00,170 --> 00:22:05,389
dummy library you don't need a cause our

00:22:04,160 --> 00:22:08,149
gravity right

00:22:05,389 --> 00:22:13,069
you just need call tom elaborate a PID

00:22:08,149 --> 00:22:17,389
interface in fact for supporting this

00:22:13,069 --> 00:22:23,079
album and our framework we we have we

00:22:17,389 --> 00:22:26,449
not a widow we have more tools besides

00:22:23,079 --> 00:22:29,569
besides the to seeing the device we have

00:22:26,449 --> 00:22:32,089
also have some server tools that just

00:22:29,569 --> 00:22:38,089
means that we'll be running whatever arm

00:22:32,089 --> 00:22:42,559
server or x86 server is for each inning

00:22:38,089 --> 00:22:52,209
and quantizing we have this kind of

00:22:42,559 --> 00:23:02,509
tools to support this local framework

00:22:52,209 --> 00:23:09,889
okay this our corporate weighs 96 bars

00:23:02,509 --> 00:23:15,879
and if you use our open ad plus 9 6 bars

00:23:09,889 --> 00:23:20,559
you will get a open platform now we have

00:23:15,879 --> 00:23:22,399
open hired have runs on high K 960

00:23:20,559 --> 00:23:29,959
dragon board

00:23:22,399 --> 00:23:33,729
it's 20 C and rock 960 all the solutions

00:23:29,959 --> 00:23:39,289
are based ok

00:23:33,729 --> 00:23:44,790
this our link you can cut almost

00:23:39,289 --> 00:23:46,059
everything from this K github link ok

00:23:44,790 --> 00:23:49,609
[Music]

00:23:46,059 --> 00:23:53,749
the picture is small but anyway you can

00:23:49,609 --> 00:23:56,479
see Tianjin Cafe charity some alcohol

00:23:53,749 --> 00:24:02,269
are there yeah you can you can gather

00:23:56,479 --> 00:24:05,619
the scenes in this github ok you can

00:24:02,269 --> 00:24:08,769
care support from this email address

00:24:05,619 --> 00:24:08,769
thank you

00:24:12,100 --> 00:24:16,420

YouTube URL: https://www.youtube.com/watch?v=ugVW1ea8UY8


