Title: HKG18 Keynote: Dileep Bhandarkar - Emerging Computing Trends in the Datacenter
Publication date: 2019-05-09
Playlist: Linaro Connect Hong Kong 2018
Description: 
	HKG18 Keynote: Dileep Bhandarkar - Emerging Computing Trends in the Datacenter
Captions: 
	00:00:03,890 --> 00:00:08,760
it's great to see such a big big crowd I

00:00:06,779 --> 00:00:10,530
was worried there'd be fewer people in

00:00:08,760 --> 00:00:13,590
the room than they were on my flight

00:00:10,530 --> 00:00:14,730
last night from San Francisco but that

00:00:13,590 --> 00:00:17,760
doesn't seem to be the case

00:00:14,730 --> 00:00:21,570
okay I'm gonna over the next half hour

00:00:17,760 --> 00:00:25,470
or so share what I've served in the

00:00:21,570 --> 00:00:27,570
industry how did we get started a little

00:00:25,470 --> 00:00:30,029
bit of history and then talk about what

00:00:27,570 --> 00:00:34,309
I sees as important things for the

00:00:30,029 --> 00:00:36,809
future so with that let's let's go so a

00:00:34,309 --> 00:00:39,989
historical perspective of the first 40

00:00:36,809 --> 00:00:43,410
years of Moore's law and then what

00:00:39,989 --> 00:00:45,570
happened when Dennard scaling ended and

00:00:43,410 --> 00:00:48,800
I'll explain what Dennard scaling is and

00:00:45,570 --> 00:00:51,090
then we'll talk about how we shifted to

00:00:48,800 --> 00:00:53,190
energy-efficient multi-core designs and

00:00:51,090 --> 00:00:59,809
then end up with talking about some

00:00:53,190 --> 00:01:02,219
heterogeneous computing so the first 50

00:00:59,809 --> 00:01:06,150
Shockley invented the transistor in the

00:01:02,219 --> 00:01:08,490
early 1950s and over the first 50 years

00:01:06,150 --> 00:01:10,830
or so you could see how things to kind

00:01:08,490 --> 00:01:13,439
of transition so over the first 50 years

00:01:10,830 --> 00:01:15,960
by the time we got into the 2000s we are

00:01:13,439 --> 00:01:18,840
about half a million million transistors

00:01:15,960 --> 00:01:22,110
on a single chip so quite a lot a lot of

00:01:18,840 --> 00:01:23,549
progress but the other sort of important

00:01:22,110 --> 00:01:26,759
thing that happened along the way was

00:01:23,549 --> 00:01:30,780
the invention of the integrated circuit

00:01:26,759 --> 00:01:33,150
and Bob Noyce at Intel and Jack Kilby at

00:01:30,780 --> 00:01:35,340
Texas Instruments invented the

00:01:33,150 --> 00:01:38,310
integrated circuit at about the same

00:01:35,340 --> 00:01:41,430
same time and I was lucky enough to meet

00:01:38,310 --> 00:01:46,290
Jack Kilby when I first started working

00:01:41,430 --> 00:01:48,659
in 1973 so here's what the first 40

00:01:46,290 --> 00:01:51,509
years of Moore's law looks like starting

00:01:48,659 --> 00:01:53,820
with the 4000 you know which had about

00:01:51,509 --> 00:01:57,509
you know I forget what the number is a

00:01:53,820 --> 00:02:00,090
few thousand transistors and it slowly

00:01:57,509 --> 00:02:01,649
kept increasing until we got to over a

00:02:00,090 --> 00:02:06,390
billion transistors and I think it was

00:02:01,649 --> 00:02:08,920
either 2003 or there abouts in 2005 okay

00:02:06,390 --> 00:02:11,200
I've got it on my slide

00:02:08,920 --> 00:02:12,790
so along the way there was something

00:02:11,200 --> 00:02:15,190
called Dennard scaling Dennard was

00:02:12,790 --> 00:02:18,030
somebody who worked at IBM and what he

00:02:15,190 --> 00:02:20,590
observed was that when you go from one

00:02:18,030 --> 00:02:23,319
semiconductor node to the next one there

00:02:20,590 --> 00:02:26,200
was a constant scaling factor K and the

00:02:23,319 --> 00:02:28,690
value of K was 0.7 and what happened was

00:02:26,200 --> 00:02:31,390
all other parameters the physical and

00:02:28,690 --> 00:02:34,390
the electrical parameters scaled by that

00:02:31,390 --> 00:02:36,940
same factor of K so it was very easy to

00:02:34,390 --> 00:02:40,780
move from one node to to the other and

00:02:36,940 --> 00:02:44,470
the important thing is K squared is 0.7

00:02:40,780 --> 00:02:46,660
times 0.7 which is 0.1 so you take the

00:02:44,470 --> 00:02:51,120
inverse of that that it's 2x so what

00:02:46,660 --> 00:02:53,290
that said was with each node the density

00:02:51,120 --> 00:02:56,650
increased by a factor of two which is

00:02:53,290 --> 00:03:01,180
exactly what Moore's law said now what

00:02:56,650 --> 00:03:02,769
happened was around 2003 for Dennard

00:03:01,180 --> 00:03:05,170
scaling broke down for a variety of

00:03:02,769 --> 00:03:07,480
reasons because of device physics and

00:03:05,170 --> 00:03:10,360
things no longer scaled by that constant

00:03:07,480 --> 00:03:12,459
factor it was it was mainly because the

00:03:10,360 --> 00:03:15,760
interconnect didn't scale the same way

00:03:12,459 --> 00:03:17,530
as the transistors did so you couldn't

00:03:15,760 --> 00:03:19,570
sort of move from one node to the other

00:03:17,530 --> 00:03:21,780
without doing something more drastic

00:03:19,570 --> 00:03:24,430
like introducing new materials new

00:03:21,780 --> 00:03:26,680
process reasons and so forth but the

00:03:24,430 --> 00:03:29,440
density can continue to increase and

00:03:26,680 --> 00:03:31,720
that caused a shift in the way with the

00:03:29,440 --> 00:03:34,030
design so instead of of of pushing

00:03:31,720 --> 00:03:35,980
single thread performance at that time

00:03:34,030 --> 00:03:38,230
we had to move because we had density

00:03:35,980 --> 00:03:40,900
but the transistors weren't getting us

00:03:38,230 --> 00:03:43,390
as fast we had to move to multi-core

00:03:40,900 --> 00:03:46,660
designs so the post

00:03:43,390 --> 00:03:49,000
Dennard scaling era is about multi

00:03:46,660 --> 00:03:50,799
multi-core single threaded performance

00:03:49,000 --> 00:03:53,769
and I'll show you I've got some data I

00:03:50,799 --> 00:03:56,290
started to slow down and performance was

00:03:53,769 --> 00:03:59,890
driven by mostly by higher core core

00:03:56,290 --> 00:04:01,959
count so here's the plot that somebody

00:03:59,890 --> 00:04:05,170
had Stanford University put together

00:04:01,959 --> 00:04:07,120
which shows on the top it shows the the

00:04:05,170 --> 00:04:11,230
transistor count increasing you know

00:04:07,120 --> 00:04:12,730
doubling every every two years single

00:04:11,230 --> 00:04:16,239
thread performance which is the the blue

00:04:12,730 --> 00:04:18,549
part started to tail off you know in in

00:04:16,239 --> 00:04:21,709
the in the two thousand five six time

00:04:18,549 --> 00:04:23,870
frame frequency started to flatten

00:04:21,709 --> 00:04:26,300
but in order to get that higher

00:04:23,870 --> 00:04:27,530
performance all we could do is was

00:04:26,300 --> 00:04:30,110
increase the number of course you can

00:04:27,530 --> 00:04:31,970
see that those those red those black

00:04:30,110 --> 00:04:33,830
diamonds at the bottom showing how the

00:04:31,970 --> 00:04:35,240
core count went up and when the core

00:04:33,830 --> 00:04:37,970
crime went up we had to also increase

00:04:35,240 --> 00:04:39,860
the the power budget so in order to get

00:04:37,970 --> 00:04:41,900
higher performance we have to go to

00:04:39,860 --> 00:04:43,880
multi-core which had some software

00:04:41,900 --> 00:04:48,770
challenges and we had to figure out how

00:04:43,880 --> 00:04:51,979
to tolerate higher power so here's what

00:04:48,770 --> 00:04:55,340
I did I went and looked at the last five

00:04:51,979 --> 00:04:57,560
generations of the Intel Xeon processor

00:04:55,340 --> 00:05:00,860
standing with starting with Sandy Bridge

00:04:57,560 --> 00:05:07,910
being the one in 2012 four followed by

00:05:00,860 --> 00:05:10,940
as well no Ivy Bridge has well Broadwell

00:05:07,910 --> 00:05:12,470
and then skylake and and I picked the

00:05:10,940 --> 00:05:14,930
hundred and thirty what processors

00:05:12,470 --> 00:05:17,360
because back in the in the Sandy Bridge

00:05:14,930 --> 00:05:20,870
generation the two socket servers the

00:05:17,360 --> 00:05:22,430
highest power was 130 watts as opposed

00:05:20,870 --> 00:05:24,680
to two hundred and five watts and on

00:05:22,430 --> 00:05:26,900
skylake today so to do a comparison at

00:05:24,680 --> 00:05:29,780
the same power level I picked 130 watts

00:05:26,900 --> 00:05:33,979
and what you see is that the blue bar is

00:05:29,780 --> 00:05:36,560
the spec in 2006 which is a a speed

00:05:33,979 --> 00:05:38,690
metric where if you are just running one

00:05:36,560 --> 00:05:40,370
core and nothing else and so you have

00:05:38,690 --> 00:05:43,159
access to all of the memory bandwidth

00:05:40,370 --> 00:05:44,360
all other caches the blue bar shows what

00:05:43,159 --> 00:05:46,699
that number is and you can see it's

00:05:44,360 --> 00:05:49,370
steadily increasing but when you put

00:05:46,699 --> 00:05:51,229
that in a multi-core environment and now

00:05:49,370 --> 00:05:53,479
you calculate the specint rate per core

00:05:51,229 --> 00:05:56,050
you can't run all of those cores at that

00:05:53,479 --> 00:05:58,550
same performance and you see that that

00:05:56,050 --> 00:06:00,979
those orange bars are starting to

00:05:58,550 --> 00:06:02,960
flatten more than the the blue bars and

00:06:00,979 --> 00:06:05,300
this was primarily because you were

00:06:02,960 --> 00:06:08,719
constrained by by power so this is the

00:06:05,300 --> 00:06:12,620
power constraint chart then I said let's

00:06:08,719 --> 00:06:16,880
see what what that progression looks

00:06:12,620 --> 00:06:19,070
like if I use the highest power in each

00:06:16,880 --> 00:06:23,300
of those generations so if you see on

00:06:19,070 --> 00:06:27,710
the on the first one which is the 26 90

00:06:23,300 --> 00:06:30,380
which is a Sandy Bridge the that the TDP

00:06:27,710 --> 00:06:32,810
was again 135 watts and then to the

00:06:30,380 --> 00:06:34,420
right on the under on the red bar which

00:06:32,810 --> 00:06:37,330
is skylight the top end

00:06:34,420 --> 00:06:39,400
is a two hundred five five watts now if

00:06:37,330 --> 00:06:41,950
you calculate the other metrics that

00:06:39,400 --> 00:06:44,440
like the performance per watt and the

00:06:41,950 --> 00:06:46,840
performance per watt per core you can

00:06:44,440 --> 00:06:49,510
see that even when we increase the power

00:06:46,840 --> 00:06:52,390
envelope not we even when Intel rates

00:06:49,510 --> 00:06:54,550
the power you know now I I spent twelve

00:06:52,390 --> 00:06:55,390
years at Intel so you can't blame me for

00:06:54,550 --> 00:06:59,890
any of this

00:06:55,390 --> 00:07:02,590
III left about in 2007 so anyway what

00:06:59,890 --> 00:07:04,900
you can see is that even when you allow

00:07:02,590 --> 00:07:09,670
the power to grow that the energy

00:07:04,900 --> 00:07:11,500
efficiency isn't just quite there so in

00:07:09,670 --> 00:07:14,590
the last few years at least some

00:07:11,500 --> 00:07:16,090
companies mostly in the armed camp have

00:07:14,590 --> 00:07:19,120
kind of woken up to the fact that energy

00:07:16,090 --> 00:07:22,080
efficiency is important and we certainly

00:07:19,120 --> 00:07:26,260
at at welcome embraced that thought I

00:07:22,080 --> 00:07:28,420
pulled this slide out of Peters Hot Chip

00:07:26,260 --> 00:07:31,600
presentation last year and there are a

00:07:28,420 --> 00:07:34,630
lot of interesting messages here first

00:07:31,600 --> 00:07:36,910
is he talks about that arm is is taking

00:07:34,630 --> 00:07:39,100
their course beyond just mobiles so

00:07:36,910 --> 00:07:41,430
they're doing course that fit more

00:07:39,100 --> 00:07:44,710
nicely you know in a server platform

00:07:41,430 --> 00:07:47,170
efficiency is important and then he has

00:07:44,710 --> 00:07:49,330
a little subtitle there that future

00:07:47,170 --> 00:07:53,140
requires a new approach to CPU design

00:07:49,330 --> 00:07:57,810
and part of my talk today addresses that

00:07:53,140 --> 00:08:02,130
statement so if you look at the industry

00:07:57,810 --> 00:08:06,130
things are moving pretty rapidly from

00:08:02,130 --> 00:08:08,800
on-premise to the cloud and most of this

00:08:06,130 --> 00:08:10,360
I think is is is the public cloud but a

00:08:08,800 --> 00:08:12,190
lot of the enterprises are also moving

00:08:10,360 --> 00:08:14,860
towards apply with private cloud we're

00:08:12,190 --> 00:08:16,780
inside of a large corporation instead of

00:08:14,860 --> 00:08:18,760
each department having their their own

00:08:16,780 --> 00:08:20,470
set of sort of servers like you know

00:08:18,760 --> 00:08:22,270
finance has their own engineering has

00:08:20,470 --> 00:08:24,930
their own lot of companies are are

00:08:22,270 --> 00:08:28,660
pulling those resources into an internal

00:08:24,930 --> 00:08:31,300
service that they then parcel out

00:08:28,660 --> 00:08:33,760
compute and storage capacity to the

00:08:31,300 --> 00:08:36,310
internal business units so you can see

00:08:33,760 --> 00:08:39,610
by 2020 more than 50 percent of the

00:08:36,310 --> 00:08:46,450
server shipments will be to the cloud

00:08:39,610 --> 00:08:49,540
providers now what you see is I started

00:08:46,450 --> 00:08:53,650
in in this business working at Digital

00:08:49,540 --> 00:08:56,890
Equipment Corporation in 1977 in on many

00:08:53,650 --> 00:09:00,220
computers and what I saw over the last

00:08:56,890 --> 00:09:02,680
40 years or so is that disruptions

00:09:00,220 --> 00:09:05,610
always come from from below somebody

00:09:02,680 --> 00:09:08,920
finds something that is less expensive

00:09:05,610 --> 00:09:12,040
smaller and that comes in and eats into

00:09:08,920 --> 00:09:14,290
the the the lunch after of after of the

00:09:12,040 --> 00:09:17,340
bigger things so the RISC systems mainly

00:09:14,290 --> 00:09:21,070
from from Sun Microsystems came in and

00:09:17,340 --> 00:09:23,920
ate into the the business that that we

00:09:21,070 --> 00:09:27,220
had dec had on many computers and then

00:09:23,920 --> 00:09:28,930
the PC technology primarily driven by by

00:09:27,220 --> 00:09:31,780
by Intel and so the desktop PC

00:09:28,930 --> 00:09:35,410
technology came in and displaced a lot

00:09:31,780 --> 00:09:38,290
of those risk UNIX systems and then even

00:09:35,410 --> 00:09:40,150
in the in the PC era it moved from using

00:09:38,290 --> 00:09:44,080
desktop processors to notebook

00:09:40,150 --> 00:09:45,850
processors in 2006 Intel launched their

00:09:44,080 --> 00:09:49,060
their their core to do which was

00:09:45,850 --> 00:09:52,270
primarily designed for for notebooks and

00:09:49,060 --> 00:09:53,740
then of the multi-core instantiation of

00:09:52,270 --> 00:09:57,070
those mobile colors there worked in

00:09:53,740 --> 00:09:59,320
servers so the next technology phase is

00:09:57,070 --> 00:10:03,010
is happening now with course that would

00:09:59,320 --> 00:10:08,230
primarily design for smartphones driven

00:10:03,010 --> 00:10:11,050
by the arm community so how do we think

00:10:08,230 --> 00:10:12,850
about this at at Qualcomm and why do we

00:10:11,050 --> 00:10:15,670
believe that we can build something

00:10:12,850 --> 00:10:18,670
that's interesting set of products if

00:10:15,670 --> 00:10:20,830
you look historically one of the things

00:10:18,670 --> 00:10:22,750
that Intel has been able to do is they

00:10:20,830 --> 00:10:24,910
were because of the high wall volume

00:10:22,750 --> 00:10:28,270
economics is is what makes everything

00:10:24,910 --> 00:10:29,290
work so when the PC volumes really took

00:10:28,270 --> 00:10:32,110
off

00:10:29,290 --> 00:10:35,440
Intel was able to use the revenues from

00:10:32,110 --> 00:10:38,860
the PC segment to fund the development

00:10:35,440 --> 00:10:41,470
of new fabs for new process nodes and

00:10:38,860 --> 00:10:44,320
that drove the industry that that drove

00:10:41,470 --> 00:10:46,570
the leadership nodes so they got to 45

00:10:44,320 --> 00:10:49,240
nanometer a year and a half or two years

00:10:46,570 --> 00:10:52,300
before anybody else and that continued

00:10:49,240 --> 00:10:54,520
for a for a long time what has happened

00:10:52,300 --> 00:10:58,660
within the last three or four years is

00:10:54,520 --> 00:11:02,140
that that volume mix has shifted

00:10:58,660 --> 00:11:04,600
from PCs to the smartphone I mean you

00:11:02,140 --> 00:11:06,670
can go go do a search and see how the

00:11:04,600 --> 00:11:10,270
iPhone took off or how the Android phone

00:11:06,670 --> 00:11:13,450
and took off and that volume has has has

00:11:10,270 --> 00:11:17,920
caused a shift where the new process

00:11:13,450 --> 00:11:20,830
node is not driven by the PC usage but

00:11:17,920 --> 00:11:22,900
driven more by the smartphone usage so

00:11:20,830 --> 00:11:27,490
we were able to take advantage of that

00:11:22,900 --> 00:11:31,660
move and get to in a newer node earlier

00:11:27,490 --> 00:11:33,370
then Intel has been able to and what

00:11:31,660 --> 00:11:36,820
does the new leading leading node give

00:11:33,370 --> 00:11:38,890
you one is these transistors are smaller

00:11:36,820 --> 00:11:43,300
so you can pack more more nodes the

00:11:38,890 --> 00:11:45,730
power is lower and you do get some small

00:11:43,300 --> 00:11:47,890
amount of speed increase in the in those

00:11:45,730 --> 00:11:50,590
transistors so when you combine all of

00:11:47,890 --> 00:11:54,550
those those features you can get better

00:11:50,590 --> 00:11:56,320
performance lower power and the area is

00:11:54,550 --> 00:11:58,720
smaller because it's in a you know in a

00:11:56,320 --> 00:12:01,150
smaller node and the area is important

00:11:58,720 --> 00:12:03,430
because that determines what your cost

00:12:01,150 --> 00:12:05,980
is so now you can compete with somebody

00:12:03,430 --> 00:12:09,370
who's on an older node trying to build a

00:12:05,980 --> 00:12:12,460
a larger chip so we've been taking

00:12:09,370 --> 00:12:15,220
advantage of this shift I belong to the

00:12:12,460 --> 00:12:18,640
server business unit inside of of

00:12:15,220 --> 00:12:21,160
Qualcomm so we're able to leverage what

00:12:18,640 --> 00:12:24,540
the mobile side of of cocom has been

00:12:21,160 --> 00:12:27,220
doing to bring in these new nodes into

00:12:24,540 --> 00:12:30,460
Qualcomm we be able to use it to drive

00:12:27,220 --> 00:12:35,530
leadership products for for the server

00:12:30,460 --> 00:12:37,990
domain our server chips are designed

00:12:35,530 --> 00:12:42,040
primarily with the with the cloud in

00:12:37,990 --> 00:12:43,690
mind we don't have a desktop legacy that

00:12:42,040 --> 00:12:46,690
we have to protect so all of the

00:12:43,690 --> 00:12:48,370
trade-offs we make is based on on server

00:12:46,690 --> 00:12:51,850
workloads whereas if you look at the x86

00:12:48,370 --> 00:12:54,510
a lot of the decisions they make is that

00:12:51,850 --> 00:12:58,000
their cores are designed to run well for

00:12:54,510 --> 00:12:59,890
gaming and and then once they they have

00:12:58,000 --> 00:13:01,720
a core that works well for forget for

00:12:59,890 --> 00:13:03,490
gaming they use that in server so

00:13:01,720 --> 00:13:05,680
they're kind of designing for the top

00:13:03,490 --> 00:13:08,710
and bringing it down we are designing it

00:13:05,680 --> 00:13:10,780
for sort of the four energy efficiency

00:13:08,710 --> 00:13:11,160
and scaling that up and that's a that's

00:13:10,780 --> 00:13:13,680
a

00:13:11,160 --> 00:13:16,920
it's a dichotomy that you see in the way

00:13:13,680 --> 00:13:19,759
in which we are approaching this problem

00:13:16,920 --> 00:13:22,319
compared to the x86 vendors

00:13:19,759 --> 00:13:25,769
unfortunately some of the people in the

00:13:22,319 --> 00:13:27,209
armed community haven't kind of caught

00:13:25,769 --> 00:13:28,589
caught up with with that and they're

00:13:27,209 --> 00:13:30,449
still designing you see a hundred and

00:13:28,589 --> 00:13:33,810
eighty white parts which I don't think

00:13:30,449 --> 00:13:36,920
makes any sense well so yes the future

00:13:33,810 --> 00:13:39,750
does require a new bridge to CPU design

00:13:36,920 --> 00:13:41,850
we measure ourselves on performance per

00:13:39,750 --> 00:13:44,480
thread not just the performance of a

00:13:41,850 --> 00:13:46,949
single thread performance per watt and

00:13:44,480 --> 00:13:54,839
performance per millimeter squared

00:13:46,949 --> 00:13:59,839
I spent six years of almost six years

00:13:54,839 --> 00:14:03,079
five and a half years of my life between

00:13:59,839 --> 00:14:06,180
leaving Intel and joining Qualcomm

00:14:03,079 --> 00:14:10,439
working at Microsoft as part of their

00:14:06,180 --> 00:14:13,410
cloud infrastructure Services team and

00:14:10,439 --> 00:14:15,810
when I got there I had never walked into

00:14:13,410 --> 00:14:17,550
a data center before didn't know what

00:14:15,810 --> 00:14:19,980
was important to the data center

00:14:17,550 --> 00:14:23,459
customers and it was an amazing learning

00:14:19,980 --> 00:14:25,680
experience it's amazing how you think

00:14:23,459 --> 00:14:28,829
about things differently when you are

00:14:25,680 --> 00:14:32,100
providing silicon that you think is you

00:14:28,829 --> 00:14:33,959
know better than sliced bread and the

00:14:32,100 --> 00:14:37,110
customer is sitting there and saying why

00:14:33,959 --> 00:14:39,540
the hell should I use this so I learned

00:14:37,110 --> 00:14:41,550
that when you're collecting money from a

00:14:39,540 --> 00:14:43,470
customer versus when you're paying for

00:14:41,550 --> 00:14:45,660
what the customer what the supplier is

00:14:43,470 --> 00:14:48,480
offering it's a different point of view

00:14:45,660 --> 00:14:50,970
and and and I've learned a lot from from

00:14:48,480 --> 00:14:53,220
that experience and I'm using that in my

00:14:50,970 --> 00:14:56,130
work with the rest of my colleagues at

00:14:53,220 --> 00:14:58,680
at quite at Qualcomm so when when they

00:14:56,130 --> 00:15:01,470
look at at how they deploy servers it's

00:14:58,680 --> 00:15:04,819
all about energy efficiency and if you

00:15:01,470 --> 00:15:08,040
look at the total cost of ownership of

00:15:04,819 --> 00:15:10,220
servers in a data center it's not just

00:15:08,040 --> 00:15:12,209
what you paid for therefore the servers

00:15:10,220 --> 00:15:14,370
there's other equipment there's

00:15:12,209 --> 00:15:16,529
networking equipment but what you see is

00:15:14,370 --> 00:15:18,930
that there's two other pieces the the

00:15:16,529 --> 00:15:23,370
green and the purple the 18 percent and

00:15:18,930 --> 00:15:24,580
20 percent the the 18 the 20 percent is

00:15:23,370 --> 00:15:26,260
energy usage

00:15:24,580 --> 00:15:29,730
so what that says is that if you're

00:15:26,260 --> 00:15:34,330
running these servers for 24 hours 365

00:15:29,730 --> 00:15:36,220
days and your energy costs are 10 cents

00:15:34,330 --> 00:15:38,800
per kilowatt hour and in many many

00:15:36,220 --> 00:15:41,110
places it's much higher than that then

00:15:38,800 --> 00:15:44,200
about 20% of your three-year cost of

00:15:41,110 --> 00:15:46,660
ownership is goes towards paying your

00:15:44,200 --> 00:15:49,860
energy bill the other piece that most

00:15:46,660 --> 00:15:52,480
people miss is that 18% Green number

00:15:49,860 --> 00:15:54,700
people don't build build data centers

00:15:52,480 --> 00:15:57,130
because they look cool they build data

00:15:54,700 --> 00:15:59,500
centers because that's where they they

00:15:57,130 --> 00:16:01,899
house their servers so there's a capital

00:15:59,500 --> 00:16:04,570
expenditure roughly somewhere in from

00:16:01,899 --> 00:16:07,060
ballpark tech 10 million per per

00:16:04,570 --> 00:16:10,360
megawatt that goes into the construction

00:16:07,060 --> 00:16:12,820
of these data centers and and this is

00:16:10,360 --> 00:16:14,709
the mostly power distribution and

00:16:12,820 --> 00:16:16,990
cooling so this doesn't include any of

00:16:14,709 --> 00:16:21,220
any of the server costs or all the

00:16:16,990 --> 00:16:23,620
network equipment costs so so then if I

00:16:21,220 --> 00:16:25,839
put a server in there that is a 500 watt

00:16:23,620 --> 00:16:28,000
server I need to look at the

00:16:25,839 --> 00:16:31,600
depreciation on that capital expenditure

00:16:28,000 --> 00:16:33,940
and allocate that in proportion to the

00:16:31,600 --> 00:16:37,060
the power that's provision for that

00:16:33,940 --> 00:16:41,829
server so that that green chart the 18%

00:16:37,060 --> 00:16:43,600
is that capital cost attributable to the

00:16:41,829 --> 00:16:47,079
server that's in the data center so you

00:16:43,600 --> 00:16:50,649
can see about a 1/3 more than a third of

00:16:47,079 --> 00:16:52,510
the overall cost of ownership is energy

00:16:50,649 --> 00:16:55,200
related and that that's based on a three

00:16:52,510 --> 00:16:57,880
year life cycle many people do not

00:16:55,200 --> 00:16:59,980
update their their servers on a 3-hour

00:16:57,880 --> 00:17:02,950
life cycle if I were to do this for five

00:16:59,980 --> 00:17:04,900
years that that green and that purple

00:17:02,950 --> 00:17:06,429
bar would be even even higher and get

00:17:04,900 --> 00:17:09,880
close to about 50%

00:17:06,429 --> 00:17:13,360
so energy does matter and because of all

00:17:09,880 --> 00:17:16,390
of that in 2014 US data centers consumed

00:17:13,360 --> 00:17:18,790
about 70 billion kilowatt hours of

00:17:16,390 --> 00:17:22,240
electricity and that has stayed

00:17:18,790 --> 00:17:26,970
relatively flat for the last three years

00:17:22,240 --> 00:17:30,669
or so and the reason for that is the

00:17:26,970 --> 00:17:31,750
energy efficiency has gotten better but

00:17:30,669 --> 00:17:33,100
lately what you see with the

00:17:31,750 --> 00:17:36,220
introduction of these hundred and eighty

00:17:33,100 --> 00:17:37,040
and 200 watt processors we've lost sight

00:17:36,220 --> 00:17:40,010
of the end

00:17:37,040 --> 00:17:41,720
equation efficiency we've lost sight of

00:17:40,010 --> 00:17:43,550
the fact that we need to limit the

00:17:41,720 --> 00:17:45,950
amount of energy being consumed in our

00:17:43,550 --> 00:17:49,130
data centers and I think that's somewhat

00:17:45,950 --> 00:17:51,770
irresponsible so we need to focus more

00:17:49,130 --> 00:17:54,320
on on energy efficiency to make sure

00:17:51,770 --> 00:17:57,260
that we stay within some reasonable

00:17:54,320 --> 00:17:59,660
bounds so once again energy efficiency

00:17:57,260 --> 00:18:03,020
is important average power matters not

00:17:59,660 --> 00:18:05,150
just the the peak power so a little bit

00:18:03,020 --> 00:18:06,440
of a commercial message here so excuse

00:18:05,150 --> 00:18:07,490
me I'll run through this very very

00:18:06,440 --> 00:18:10,250
quickly

00:18:07,490 --> 00:18:12,440
somebody Qualcomm had to pay my flight

00:18:10,250 --> 00:18:14,270
bill so I had to put two slides sort of

00:18:12,440 --> 00:18:14,770
talking about our product so bear with

00:18:14,270 --> 00:18:17,270
me

00:18:14,770 --> 00:18:19,490
so our first first product we're very

00:18:17,270 --> 00:18:21,230
proud of the fact that it's a the

00:18:19,490 --> 00:18:23,630
world's first ten nanometer server

00:18:21,230 --> 00:18:26,600
processor that's a technology statement

00:18:23,630 --> 00:18:27,980
right it's 48 arm v8 coresight running

00:18:26,600 --> 00:18:30,290
at two point six gigahertz

00:18:27,980 --> 00:18:32,540
these are custom-designed course these

00:18:30,290 --> 00:18:36,140
are not licensed course from from arm

00:18:32,540 --> 00:18:38,780
they're specifically designed for for

00:18:36,140 --> 00:18:42,320
four servers there are 64-bit but only

00:18:38,780 --> 00:18:45,320
we we jettison the 32-bit part of the of

00:18:42,320 --> 00:18:47,990
the design to allow us more power and

00:18:45,320 --> 00:18:51,410
more area that could be dedicated for a

00:18:47,990 --> 00:18:53,570
64-bit server performance I won't go

00:18:51,410 --> 00:18:56,420
into a lot of the details there's a link

00:18:53,570 --> 00:18:58,580
at the bottom you can go check it out

00:18:56,420 --> 00:19:01,310
he also of like I said this I didn't

00:18:58,580 --> 00:19:03,800
mean this to be a sales pitch but if you

00:19:01,310 --> 00:19:07,070
look at the results of what we were able

00:19:03,800 --> 00:19:12,050
to achieve versus Intel skylake I think

00:19:07,070 --> 00:19:14,360
this is my last slide that shows how we

00:19:12,050 --> 00:19:16,490
do comparatively sir but it's important

00:19:14,360 --> 00:19:17,420
you know if you set your heart to being

00:19:16,490 --> 00:19:19,820
energy efficient

00:19:17,420 --> 00:19:21,140
what can you deliver it doesn't mean

00:19:19,820 --> 00:19:24,230
that you're going to sacrifice

00:19:21,140 --> 00:19:25,970
performance there's if you look at all

00:19:24,230 --> 00:19:28,670
of the Scylla excuse that Intel has

00:19:25,970 --> 00:19:30,830
there is about 30 or 40 of them there's

00:19:28,670 --> 00:19:35,210
only three of them that deliver higher

00:19:30,830 --> 00:19:38,450
performance then our centric 2,400 and

00:19:35,210 --> 00:19:40,160
our centric 2,400 is 120 what part the

00:19:38,450 --> 00:19:43,670
three Scylla excuse that have higher

00:19:40,160 --> 00:19:46,580
performance are 165 or 205 five watts

00:19:43,670 --> 00:19:49,539
but in order to make things a little

00:19:46,580 --> 00:19:52,539
interesting what I did was let's compare

00:19:49,539 --> 00:19:57,330
to the top end sky licks Q which is the

00:19:52,539 --> 00:20:00,549
Platinum 8180 with 28 course 205 watts

00:19:57,330 --> 00:20:03,940
775 a speck in prey yes you know there

00:20:00,549 --> 00:20:06,729
what does that translate to 18% the

00:20:03,940 --> 00:20:10,090
yellow bar is a spike in trade 18%

00:20:06,729 --> 00:20:13,330
higher performance and then ice but

00:20:10,090 --> 00:20:15,460
there are 205 watts we're at 120 watts

00:20:13,330 --> 00:20:18,100
but then if you go to anything like

00:20:15,460 --> 00:20:20,409
performance / what performance / / /

00:20:18,100 --> 00:20:22,570
thread performance per dollar and and

00:20:20,409 --> 00:20:24,820
the performance per dollar is based on

00:20:22,570 --> 00:20:26,349
less price and yes you know there are

00:20:24,820 --> 00:20:28,419
many people who don't pay the list price

00:20:26,349 --> 00:20:30,940
but that's the best I could do

00:20:28,419 --> 00:20:33,009
so you can modulate that number any way

00:20:30,940 --> 00:20:35,769
where you want now performance / core

00:20:33,009 --> 00:20:37,509
yes there there there 2x but nobody's

00:20:35,769 --> 00:20:39,970
going to sense you know not all the

00:20:37,509 --> 00:20:41,320
course not all 28 course on skylake are

00:20:39,970 --> 00:20:43,359
going to be running at that full

00:20:41,320 --> 00:20:45,549
frequency that's kind of a hooking

00:20:43,359 --> 00:20:48,700
number so perform so specking rate per

00:20:45,549 --> 00:20:51,009
core is a much better metric so then you

00:20:48,700 --> 00:20:53,109
take that the next one I said how do we

00:20:51,009 --> 00:20:55,359
compare if we do it at the same power

00:20:53,109 --> 00:20:56,590
level we're at 120 I picked their

00:20:55,359 --> 00:20:58,720
highest performance hundred and

00:20:56,590 --> 00:21:00,099
twenty-five white part and now you see

00:20:58,720 --> 00:21:04,210
that all of those metrics

00:21:00,099 --> 00:21:06,700
except for performance per core are very

00:21:04,210 --> 00:21:09,099
much in our favor yes they're their

00:21:06,700 --> 00:21:12,190
overall spiking rate is 4% higher which

00:21:09,099 --> 00:21:15,159
is you know close enough then I said

00:21:12,190 --> 00:21:17,739
let's take their top ePHI they used to

00:21:15,159 --> 00:21:21,249
have this e Phi e 7 e Phi was their

00:21:17,739 --> 00:21:24,039
family of two socket processors each

00:21:21,249 --> 00:21:26,349
seven was the four socket and if you

00:21:24,039 --> 00:21:29,289
took and and the e 5 the top price point

00:21:26,349 --> 00:21:32,139
was about $4,000 4700 or something like

00:21:29,289 --> 00:21:34,779
that so if you took the skew and in with

00:21:32,139 --> 00:21:37,299
with skylake they went through this to

00:21:34,779 --> 00:21:39,009
the silver gold platinum and it kind of

00:21:37,299 --> 00:21:43,059
can get very confusing so I picked the

00:21:39,009 --> 00:21:45,639
the the top skewed that sort of was at

00:21:43,059 --> 00:21:50,019
the the price point of the old ii 5

00:21:45,639 --> 00:21:51,809
which is now the 81 60 and that's 150

00:21:50,019 --> 00:21:55,929
watts

00:21:51,809 --> 00:21:59,619
$4,700 and again you can see that except

00:21:55,929 --> 00:22:02,080
for the performance / core our chip

00:21:59,619 --> 00:22:04,180
comes out looking ahead so if

00:22:02,080 --> 00:22:06,880
on performance per thread performance

00:22:04,180 --> 00:22:08,230
per what we beat all of these and then

00:22:06,880 --> 00:22:11,470
the last one I said let's do it

00:22:08,230 --> 00:22:14,770
I saw performance ours is at 657 these

00:22:11,470 --> 00:22:21,370
are by the way GCC or go to measure

00:22:14,770 --> 00:22:23,740
numbers there's is that 653 so I saw

00:22:21,370 --> 00:22:26,050
performance I saw power and at two

00:22:23,740 --> 00:22:28,240
different price points if you pay

00:22:26,050 --> 00:22:30,280
attention to energy efficiency yes you

00:22:28,240 --> 00:22:35,320
can deliver competitive performance

00:22:30,280 --> 00:22:40,210
without sacrificing power without it

00:22:35,320 --> 00:22:42,810
being a lower performance when arm

00:22:40,210 --> 00:22:45,460
service first came about people thought

00:22:42,810 --> 00:22:47,380
toss are talking about micro servers

00:22:45,460 --> 00:22:48,940
that's not where the action is that's

00:22:47,380 --> 00:22:51,640
not where the large cloud service

00:22:48,940 --> 00:22:54,550
providers are focusing their deployments

00:22:51,640 --> 00:22:58,120
so the important thing is being able to

00:22:54,550 --> 00:23:00,790
deliver top level performance compared

00:22:58,120 --> 00:23:02,610
to the the Intel products at a much

00:23:00,790 --> 00:23:04,630
lower power and that's what we're doing

00:23:02,610 --> 00:23:06,270
the other thing that matters remember I

00:23:04,630 --> 00:23:12,310
told you about the energy consumption

00:23:06,270 --> 00:23:14,740
now we measured the power running the

00:23:12,310 --> 00:23:17,290
spec in workload which has about 12

00:23:14,740 --> 00:23:20,140
different sub tests and across each of

00:23:17,290 --> 00:23:23,020
the sub tests what we notice what was

00:23:20,140 --> 00:23:27,040
that the average power consumed when

00:23:23,020 --> 00:23:30,250
running the entire test is slightly more

00:23:27,040 --> 00:23:32,200
than half the thermal design point so

00:23:30,250 --> 00:23:34,300
why is the thermal design point 120

00:23:32,200 --> 00:23:37,480
watts when when the when the average

00:23:34,300 --> 00:23:39,910
power is about 65 watts that's because a

00:23:37,480 --> 00:23:41,500
lot of these workloads are peaky so what

00:23:39,910 --> 00:23:43,660
I should wait for a very short period of

00:23:41,500 --> 00:23:47,410
time they get close to that that you

00:23:43,660 --> 00:23:49,410
know above 100 110 115 so from a thermal

00:23:47,410 --> 00:23:53,560
design you have to be able to tolerate a

00:23:49,410 --> 00:23:55,780
maximum power dissipation of 120 watts

00:23:53,560 --> 00:23:58,750
but on average in our case it's

00:23:55,780 --> 00:24:02,530
significantly lower than that maximum

00:23:58,750 --> 00:24:04,810
power so TDP is max power the average

00:24:02,530 --> 00:24:07,870
power is significantly less and then at

00:24:04,810 --> 00:24:10,450
the other thing we do is is the idle

00:24:07,870 --> 00:24:14,170
power is 8 watts which helps a lot in

00:24:10,450 --> 00:24:15,380
the energy so before we move on to them

00:24:14,170 --> 00:24:19,190
to the next phase

00:24:15,380 --> 00:24:23,150
I thought instead of giving you my

00:24:19,190 --> 00:24:25,670
opinion a lot of answers I'll put some

00:24:23,150 --> 00:24:26,900
questions up there I have my opinion but

00:24:25,670 --> 00:24:29,270
I'm not going to share that with me you

00:24:26,900 --> 00:24:30,920
can catch me after the the presentation

00:24:29,270 --> 00:24:33,470
I'll tell you what I think

00:24:30,920 --> 00:24:36,110
but top of the list is are we really

00:24:33,470 --> 00:24:39,620
serious about energy efficiency if we

00:24:36,110 --> 00:24:43,910
are why are people buying 200 watt

00:24:39,620 --> 00:24:46,370
processors that do not deliver good

00:24:43,910 --> 00:24:48,620
performance per watt the lowest

00:24:46,370 --> 00:24:50,780
performance for what on those other skis

00:24:48,620 --> 00:24:52,870
that I showed you are at the ones that

00:24:50,780 --> 00:24:54,830
I've had at 205 watts

00:24:52,870 --> 00:24:57,500
what should the cost and power

00:24:54,830 --> 00:24:59,600
constraints be for people who are who

00:24:57,500 --> 00:25:02,570
are designing these these processors

00:24:59,600 --> 00:25:06,590
how many instruction sets is too many we

00:25:02,570 --> 00:25:09,580
have x86 we have arm the you know I

00:25:06,590 --> 00:25:12,260
think nips at least in services is

00:25:09,580 --> 00:25:15,230
non-existent powers trying to make a

00:25:12,260 --> 00:25:17,030
comeback there was a Open Power Summit

00:25:15,230 --> 00:25:19,550
last week and they're talking about

00:25:17,030 --> 00:25:21,590
deployments at Google and other places

00:25:19,550 --> 00:25:24,290
and then the other one that's sort of

00:25:21,590 --> 00:25:29,000
coming on at least somewhat strong not

00:25:24,290 --> 00:25:30,260
in service quite yet is is risk five the

00:25:29,000 --> 00:25:32,450
other question is have we reached the

00:25:30,260 --> 00:25:34,580
limit of high cork out with each

00:25:32,450 --> 00:25:36,410
generation if the only way we can get

00:25:34,580 --> 00:25:40,310
through put performance is by increasing

00:25:36,410 --> 00:25:44,000
the the cork on where does it stop can

00:25:40,310 --> 00:25:45,610
the software handle 150 cores I mean

00:25:44,000 --> 00:25:48,710
does it need to be capped at some

00:25:45,610 --> 00:25:51,320
two-digit number how does the software

00:25:48,710 --> 00:25:53,540
scale when you get 200 cores on a single

00:25:51,320 --> 00:25:55,130
piece of silicon constrained by the

00:25:53,540 --> 00:25:58,760
memory bandwidth memory bandwidth isn't

00:25:55,130 --> 00:25:59,960
growing it at that faster rate that's

00:25:58,760 --> 00:26:03,110
something that I don't think we pay

00:25:59,960 --> 00:26:05,060
enough attention to do we need to

00:26:03,110 --> 00:26:07,940
improve these a single set performance

00:26:05,060 --> 00:26:09,950
for general-purpose computing or do we

00:26:07,940 --> 00:26:12,530
need to focus on new workloads like

00:26:09,950 --> 00:26:16,040
machine learning and have accelerators

00:26:12,530 --> 00:26:17,540
provide that level of performance what

00:26:16,040 --> 00:26:21,140
should be the power limit be for a

00:26:17,540 --> 00:26:23,830
single socket it wouldn't surprise me if

00:26:21,140 --> 00:26:28,730
the next generation from some companies

00:26:23,830 --> 00:26:32,090
will go from 200 to 250 watts is that

00:26:28,730 --> 00:26:35,390
right trade-off to make and lately when

00:26:32,090 --> 00:26:37,250
we talk about security I don't believe

00:26:35,390 --> 00:26:40,460
that you can have security without

00:26:37,250 --> 00:26:42,650
incurring a performance penalty the

00:26:40,460 --> 00:26:44,059
question for us as the industry is how

00:26:42,650 --> 00:26:48,230
much performance are we willing to

00:26:44,059 --> 00:26:49,520
sacrifice to get security and one of the

00:26:48,230 --> 00:26:52,850
reasons some of these security things

00:26:49,520 --> 00:26:56,299
happened was because from an economics

00:26:52,850 --> 00:26:57,860
perspective we said multi-tenancy is the

00:26:56,299 --> 00:27:01,700
way to go so when you combine

00:26:57,860 --> 00:27:06,290
multi-tenancy and some other you know a

00:27:01,700 --> 00:27:08,419
speculation we've found ourself with the

00:27:06,290 --> 00:27:10,790
problems that we have today yes these

00:27:08,419 --> 00:27:14,179
problems can be solved but it will cost

00:27:10,790 --> 00:27:16,640
maybe it will cost in a cost area it

00:27:14,179 --> 00:27:18,799
will certainly cost performance how much

00:27:16,640 --> 00:27:21,799
are we willing to sacrifice in terms of

00:27:18,799 --> 00:27:22,610
product cost and performance to get

00:27:21,799 --> 00:27:24,290
security

00:27:22,610 --> 00:27:30,169
we better be willing to answer those

00:27:24,290 --> 00:27:32,870
questions cost and convenience yes I

00:27:30,169 --> 00:27:34,700
covered that the other thing that that I

00:27:32,870 --> 00:27:38,200
think about being a semiconductor guy is

00:27:34,700 --> 00:27:43,610
when does device gaming end 7 nanometre

00:27:38,200 --> 00:27:45,710
is showing up now we haven't seen the

00:27:43,610 --> 00:27:47,419
first server processor in 7 nanometers

00:27:45,710 --> 00:27:51,200
but you'll you'll see that before the

00:27:47,419 --> 00:27:53,330
end of this this year 5 nanometer is

00:27:51,200 --> 00:27:55,549
beyond that and the next will be will be

00:27:53,330 --> 00:27:59,179
3 will three nanometers happen I don't

00:27:55,549 --> 00:28:02,960
know will there be a sub Pico nanometer

00:27:59,179 --> 00:28:04,790
will we have transistors below one

00:28:02,960 --> 00:28:08,740
nanometer I don't know the answer to

00:28:04,790 --> 00:28:12,260
these questions so these are things to

00:28:08,740 --> 00:28:17,000
think about so now let's move on to the

00:28:12,260 --> 00:28:19,130
heterogeneous computing error there are

00:28:17,000 --> 00:28:20,840
a lot of lessons we can learn from from

00:28:19,130 --> 00:28:23,240
the world of off of mobile computing

00:28:20,840 --> 00:28:26,210
first of all this is energy efficiency

00:28:23,240 --> 00:28:28,250
has to be an implicit target when when

00:28:26,210 --> 00:28:30,620
my colleagues at Qualcomm design chips

00:28:28,250 --> 00:28:32,780
for the smartphone they have a power

00:28:30,620 --> 00:28:36,169
budget you know one and a half watt to

00:28:32,780 --> 00:28:38,120
water whatever it is and in their job is

00:28:36,169 --> 00:28:40,940
to deliver maximum performance within

00:28:38,120 --> 00:28:42,070
that in in my world in servers yes it's

00:28:40,940 --> 00:28:45,360
a three-digit number

00:28:42,070 --> 00:28:48,040
we are are our marching orders are

00:28:45,360 --> 00:28:50,320
here's your power budget here is your

00:28:48,040 --> 00:28:53,770
area budget how much performance can you

00:28:50,320 --> 00:28:57,220
deliver within that if you start the

00:28:53,770 --> 00:29:00,000
desktop CPUs and scaled us to do either

00:28:57,220 --> 00:29:03,220
mobile I mean there's a reason why x86

00:29:00,000 --> 00:29:05,050
doesn't play in in smartphones if you

00:29:03,220 --> 00:29:06,370
look at the server products they're not

00:29:05,050 --> 00:29:08,890
energy efficient because they're

00:29:06,370 --> 00:29:11,800
essentially power-hungry desktop course

00:29:08,890 --> 00:29:15,100
on the other side you can't use wimpy

00:29:11,800 --> 00:29:17,830
mobile cores and winin servers so we had

00:29:15,100 --> 00:29:19,300
to sort of move away from our of our

00:29:17,830 --> 00:29:21,370
mobile cores and design a server

00:29:19,300 --> 00:29:25,060
specific core to meet the needs of

00:29:21,370 --> 00:29:27,640
servers but you can design those server

00:29:25,060 --> 00:29:29,740
processors using the same mentality that

00:29:27,640 --> 00:29:32,380
you use to design mobile cores where

00:29:29,740 --> 00:29:35,620
energy efficiency is a very explicit

00:29:32,380 --> 00:29:38,080
design goal the other thing with what we

00:29:35,620 --> 00:29:41,350
notice in the world of mobile computing

00:29:38,080 --> 00:29:43,420
is that many work workloads run better

00:29:41,350 --> 00:29:48,040
on different so we have a DSP there's a

00:29:43,420 --> 00:29:49,900
GPU and a CPU in in the mobile SLC's and

00:29:48,040 --> 00:29:53,170
depending on the workload you run those

00:29:49,900 --> 00:29:55,180
on these different energies engines why

00:29:53,170 --> 00:29:57,610
can't we do that in the server domain

00:29:55,180 --> 00:29:59,500
also and that might be a better way of

00:29:57,610 --> 00:30:04,570
pushing performance than then just

00:29:59,500 --> 00:30:07,210
adding adding more cores so we are now

00:30:04,570 --> 00:30:11,500
in the age of application specific

00:30:07,210 --> 00:30:15,190
accelerators you've started to see you

00:30:11,500 --> 00:30:17,410
know TP use Google sort of has made a

00:30:15,190 --> 00:30:19,900
big deal about 30 PU and how deploying

00:30:17,410 --> 00:30:22,170
those TPU has allowed them to reduce the

00:30:19,900 --> 00:30:26,170
number of servers that they're deploying

00:30:22,170 --> 00:30:28,630
and in general you can get an order of

00:30:26,170 --> 00:30:31,510
magnitude higher computing efficiency

00:30:28,630 --> 00:30:34,420
with a specialized engine than you would

00:30:31,510 --> 00:30:36,190
with with a general-purpose engine this

00:30:34,420 --> 00:30:39,100
has been true in the industry for a long

00:30:36,190 --> 00:30:41,260
time but back in the old days when the

00:30:39,100 --> 00:30:43,540
single thread performance was was moving

00:30:41,260 --> 00:30:47,560
at a very rapid pace what people who

00:30:43,540 --> 00:30:49,690
were doing highly specialized processors

00:30:47,560 --> 00:30:51,910
found out that the next year's

00:30:49,690 --> 00:30:54,800
general-purpose processor would catch up

00:30:51,910 --> 00:30:56,930
to what they were trying to do the

00:30:54,800 --> 00:30:59,570
wasn't there but I think things that are

00:30:56,930 --> 00:31:00,650
changing so what's important is that

00:30:59,570 --> 00:31:03,260
because you have an order of magnitude

00:31:00,650 --> 00:31:04,790
improvement you don't necessarily have

00:31:03,260 --> 00:31:06,680
to go with the most efficient

00:31:04,790 --> 00:31:09,650
implementation of these

00:31:06,680 --> 00:31:11,360
application-specific accelerators time

00:31:09,650 --> 00:31:13,430
to market is important so I would leave

00:31:11,360 --> 00:31:18,860
10% performance on the table to get to

00:31:13,430 --> 00:31:21,530
market six months sooner there are many

00:31:18,860 --> 00:31:23,750
potential applications machine learning

00:31:21,530 --> 00:31:25,150
encryption data compression video

00:31:23,750 --> 00:31:28,670
processing these are not meant to be a

00:31:25,150 --> 00:31:32,750
complete list and in order for this to

00:31:28,670 --> 00:31:34,280
be viable you need reasonable volume if

00:31:32,750 --> 00:31:36,620
you if you can sell enough chips you

00:31:34,280 --> 00:31:39,290
can't amortize the development costs of

00:31:36,620 --> 00:31:43,220
doing an accelerator what you see is is

00:31:39,290 --> 00:31:46,960
many startups now raising on the order

00:31:43,220 --> 00:31:49,550
of 50 million dollars for their first

00:31:46,960 --> 00:31:52,190
machine learning accelerator product so

00:31:49,550 --> 00:31:54,650
the rough cost of developing a

00:31:52,190 --> 00:31:56,360
specialized chip for artificial

00:31:54,650 --> 00:31:58,280
intelligence is somewhere in that fifty

00:31:56,360 --> 00:32:00,230
two hundred million dollars the other

00:31:58,280 --> 00:32:02,750
thing is the algorithms have to be

00:32:00,230 --> 00:32:05,150
stable because if the algorithms are

00:32:02,750 --> 00:32:06,710
changing I have to if I was going to

00:32:05,150 --> 00:32:09,200
build something that's application

00:32:06,710 --> 00:32:11,240
specific and I pick our algorithm today

00:32:09,200 --> 00:32:13,520
and I'm not going to ship it for two

00:32:11,240 --> 00:32:15,800
years if in that meantime the algorithm

00:32:13,520 --> 00:32:17,710
changes nobody's gonna want to buy my

00:32:15,800 --> 00:32:20,660
part so there are there are challenges

00:32:17,710 --> 00:32:23,090
and sometimes they're if they're fixed

00:32:20,660 --> 00:32:25,280
function that makes it difficult to and

00:32:23,090 --> 00:32:29,420
and that's why inside for some people

00:32:25,280 --> 00:32:31,190
the FPGAs are a better fit so how did

00:32:29,420 --> 00:32:35,450
this all get get get started I mean

00:32:31,190 --> 00:32:36,980
we've talked about machine learning for

00:32:35,450 --> 00:32:39,440
a long time and I was a graduate student

00:32:36,980 --> 00:32:43,550
at Carnegie Mellon in the 70s it was all

00:32:39,440 --> 00:32:46,700
about playing chess and go and in speech

00:32:43,550 --> 00:32:48,080
recognition and all of that but there

00:32:46,700 --> 00:32:49,700
was nothing that was large and

00:32:48,080 --> 00:32:52,130
commercial but there are three things

00:32:49,700 --> 00:32:55,430
that that sort of happened within the

00:32:52,130 --> 00:32:57,830
last five or six years there was more

00:32:55,430 --> 00:33:01,760
data available to analyze and figure out

00:32:57,830 --> 00:33:04,580
how those those workloads behaved we had

00:33:01,760 --> 00:33:06,500
better models to deal with and then it

00:33:04,580 --> 00:33:08,659
just so happened that the GPUs were

00:33:06,500 --> 00:33:12,559
there they weren't designed

00:33:08,659 --> 00:33:14,509
for machine learning but it was better

00:33:12,559 --> 00:33:16,460
than trying to develop your your own and

00:33:14,509 --> 00:33:18,320
there's a lot of excess baggage in those

00:33:16,460 --> 00:33:19,940
GPU which is not relevant for machine

00:33:18,320 --> 00:33:24,019
learning I'll talk about that a little

00:33:19,940 --> 00:33:26,419
later and that allowed people to do some

00:33:24,019 --> 00:33:29,149
very interesting things and the turning

00:33:26,419 --> 00:33:34,639
point in my belief was a presentation at

00:33:29,149 --> 00:33:36,759
the imagenet competition in 2012 that

00:33:34,639 --> 00:33:40,869
opened people's eyes and now you know

00:33:36,759 --> 00:33:43,759
everybody is doing deep neural networks

00:33:40,869 --> 00:33:46,879
now here's another chart that shows how

00:33:43,759 --> 00:33:48,409
over time the interest in in machine

00:33:46,879 --> 00:33:51,349
learning has evolved on the left hand

00:33:48,409 --> 00:33:53,960
side this chart came from Google the

00:33:51,349 --> 00:33:55,909
number of people doing search with the

00:33:53,960 --> 00:34:00,979
term deep learning you can see how that

00:33:55,909 --> 00:34:03,799
accelerated from 2010 to sometime 2015

00:34:00,979 --> 00:34:07,549
the use of deep learning inside of

00:34:03,799 --> 00:34:09,740
Google also took a big turn and that's

00:34:07,549 --> 00:34:13,010
why Google are launched their TPU and

00:34:09,740 --> 00:34:16,579
the TPU to internally designed Eric you

00:34:13,010 --> 00:34:18,730
know a captive market some devices

00:34:16,579 --> 00:34:20,869
machines and things are all becoming

00:34:18,730 --> 00:34:24,409
more intelligence so then the question

00:34:20,869 --> 00:34:27,349
is where do we put the intelligence and

00:34:24,409 --> 00:34:30,260
what are the parameters I'll skip this

00:34:27,349 --> 00:34:33,440
one in the interest of time so where do

00:34:30,260 --> 00:34:36,200
we need to to put the compute and why

00:34:33,440 --> 00:34:38,139
and this is this law general-purpose as

00:34:36,200 --> 00:34:41,359
well as a special purpose computer

00:34:38,139 --> 00:34:44,059
clearly there's this computation

00:34:41,359 --> 00:34:46,369
available in the device itself

00:34:44,059 --> 00:34:48,950
these today's smartphones are doing

00:34:46,369 --> 00:34:50,480
inference on the phone in in the past

00:34:48,950 --> 00:34:53,329
when you try to do something on your

00:34:50,480 --> 00:34:55,579
phone all what your request got sent up

00:34:53,329 --> 00:34:58,609
to a server in the cloud the results

00:34:55,579 --> 00:35:00,799
came back to the to the device but now a

00:34:58,609 --> 00:35:03,710
lot of that is happening happening on

00:35:00,799 --> 00:35:06,529
the device itself we all know about the

00:35:03,710 --> 00:35:09,230
central cloud but an emerging trend that

00:35:06,529 --> 00:35:12,230
I think often we miss is this thing in

00:35:09,230 --> 00:35:14,480
the middle the computation at the edge

00:35:12,230 --> 00:35:16,549
and I think you heard the Mark

00:35:14,480 --> 00:35:18,559
Shuttleworth talk about how the edge is

00:35:16,549 --> 00:35:20,150
going to eat eat up the cloud I'm not

00:35:18,559 --> 00:35:20,840
sure it's going to be that that drastic

00:35:20,150 --> 00:35:23,690
any time so

00:35:20,840 --> 00:35:25,190
but essentially used to see a lot of

00:35:23,690 --> 00:35:30,620
computation happening at the edge

00:35:25,190 --> 00:35:32,600
primarily because of the latency and in

00:35:30,620 --> 00:35:37,880
the availability of computer resources

00:35:32,600 --> 00:35:39,560
closer to where the devices are so what

00:35:37,880 --> 00:35:42,830
is the edge right

00:35:39,560 --> 00:35:45,260
the edge is risk essentially a bunch of

00:35:42,830 --> 00:35:49,250
servers that are closest like I said to

00:35:45,260 --> 00:35:51,470
the 2d devices the latency is maybe five

00:35:49,250 --> 00:35:54,710
or ten times lower than sending that

00:35:51,470 --> 00:35:57,290
request to a sense central cloud they're

00:35:54,710 --> 00:36:01,640
smaller fewer racks the power budgets

00:35:57,290 --> 00:36:04,040
are smaller they want server processors

00:36:01,640 --> 00:36:05,600
that are maybe less than 100 watts they

00:36:04,040 --> 00:36:09,260
can't tolerate the 200 Watts because

00:36:05,600 --> 00:36:11,330
they're severely space and in power

00:36:09,260 --> 00:36:13,790
constraint so this isn't sort of an

00:36:11,330 --> 00:36:16,580
interesting dynamic that you'll see

00:36:13,790 --> 00:36:19,340
playing out where that the telcos will

00:36:16,580 --> 00:36:21,590
will start kind of figuring out how to

00:36:19,340 --> 00:36:24,110
provide that same level of functionality

00:36:21,590 --> 00:36:26,030
at the edge that a lot of the cloud

00:36:24,110 --> 00:36:31,010
service providers are providing at the

00:36:26,030 --> 00:36:33,740
centralized level so AI is is is is

00:36:31,010 --> 00:36:36,260
everywhere and inference is happening on

00:36:33,740 --> 00:36:38,300
the device at the edge and at the

00:36:36,260 --> 00:36:40,310
centralized cloud again depending on the

00:36:38,300 --> 00:36:42,620
on the use case there isn't a single

00:36:40,310 --> 00:36:45,770
answer that everything will be done in

00:36:42,620 --> 00:36:48,110
one place or the other so what are some

00:36:45,770 --> 00:36:50,960
of the silicon alternatives for deep

00:36:48,110 --> 00:36:54,290
neural networks clearly the most most

00:36:50,960 --> 00:36:57,050
flexible is the CPU and a lot of people

00:36:54,290 --> 00:36:59,180
are doing that on the CPU to the extent

00:36:57,050 --> 00:37:01,400
that there are unused life cycles if you

00:36:59,180 --> 00:37:05,060
look at most data centers the CPU

00:37:01,400 --> 00:37:07,850
utilization is fairly low so if you got

00:37:05,060 --> 00:37:09,500
free cycles and if you can get the

00:37:07,850 --> 00:37:12,530
inference done in a reasonable amount of

00:37:09,500 --> 00:37:15,080
time not necessarily the fastest you

00:37:12,530 --> 00:37:18,980
know that's one one place to do it there

00:37:15,080 --> 00:37:21,380
are I saw enhancements arm has talked

00:37:18,980 --> 00:37:23,810
about some of those in Telus I mentioned

00:37:21,380 --> 00:37:26,810
what they're doing and you can

00:37:23,810 --> 00:37:31,040
complement the the these the servers

00:37:26,810 --> 00:37:33,630
with some accelerators like the TPU etc

00:37:31,040 --> 00:37:38,750
to make it even even even even better

00:37:33,630 --> 00:37:41,880
that GPUs have been used mainly for

00:37:38,750 --> 00:37:45,660
training for inference there are two

00:37:41,880 --> 00:37:48,000
power-hungry and too expensive the part

00:37:45,660 --> 00:37:51,690
in the middle which is FPGA has the

00:37:48,000 --> 00:37:54,720
flexibility they don't cost a lot to

00:37:51,690 --> 00:37:56,490
develop but the unit cost is is it is

00:37:54,720 --> 00:37:59,099
slightly higher and they're not easy to

00:37:56,490 --> 00:38:02,819
program on the other extreme the most

00:37:59,099 --> 00:38:04,950
efficient one is an ASIC but it takes

00:38:02,819 --> 00:38:08,460
you you know maybe a year and I have to

00:38:04,950 --> 00:38:11,099
develop it yes it is more energy and

00:38:08,460 --> 00:38:13,319
cost efficient but it cost you a lot of

00:38:11,099 --> 00:38:15,509
out of money 50 million to 100 million

00:38:13,319 --> 00:38:17,460
to develop that chip and it's a least

00:38:15,509 --> 00:38:19,170
flexible it's a damn good job for it was

00:38:17,460 --> 00:38:24,480
designed for but it can't do anything

00:38:19,170 --> 00:38:29,130
else so how do you see this and how do I

00:38:24,480 --> 00:38:32,309
see this playing out GPUs and large DP

00:38:29,130 --> 00:38:35,549
use DNN processing units higher cost

00:38:32,309 --> 00:38:37,500
will get deployed for training but but

00:38:35,549 --> 00:38:40,140
are non inference and the volume is

00:38:37,500 --> 00:38:43,140
lower so it's it's lower volume higher

00:38:40,140 --> 00:38:45,569
price versus higher volume lower price

00:38:43,140 --> 00:38:47,400
at the other extreme for inference so

00:38:45,569 --> 00:38:50,990
inference will move more and more

00:38:47,400 --> 00:38:54,589
towards smaller lower cost lower power

00:38:50,990 --> 00:38:56,910
specialized engines I think training

00:38:54,589 --> 00:38:58,470
GPUs are still at the top and there are

00:38:56,910 --> 00:39:00,390
at least couple of startups that I know

00:38:58,470 --> 00:39:03,180
after doing something specific

00:39:00,390 --> 00:39:05,039
essentially removing some of the things

00:39:03,180 --> 00:39:07,019
in the GPU that do nothing for a machine

00:39:05,039 --> 00:39:10,890
learning to essentially get more than

00:39:07,019 --> 00:39:15,930
with less silicon area so what are my my

00:39:10,890 --> 00:39:19,289
sort of final thoughts on on on silicon

00:39:15,930 --> 00:39:21,509
design for for deep learning CPUs and

00:39:19,289 --> 00:39:23,759
are not powerful enough but they have

00:39:21,509 --> 00:39:26,789
free cycles but there's an opportunity

00:39:23,759 --> 00:39:28,289
for adding accelerators instructions and

00:39:26,789 --> 00:39:32,630
set enhancements as I mentioned before

00:39:28,289 --> 00:39:36,809
will improve the performance of

00:39:32,630 --> 00:39:39,470
initially of inference on the CPUs

00:39:36,809 --> 00:39:41,880
initially it'll be through add-in cards

00:39:39,470 --> 00:39:44,160
sometime in the future you'll see

00:39:41,880 --> 00:39:46,099
multiple chips within a package so

00:39:44,160 --> 00:39:48,430
package level integration and thence

00:39:46,099 --> 00:39:50,749
years beyond that you might even see

00:39:48,430 --> 00:39:53,650
these specialized accelerators

00:39:50,749 --> 00:39:56,150
integrated on the same piece of silicon

00:39:53,650 --> 00:39:57,859
GPUs in my opinion have too much extra

00:39:56,150 --> 00:40:02,539
baggage and that creates an opportunity

00:39:57,859 --> 00:40:04,759
for domain-specific accelerators FPGAs

00:40:02,539 --> 00:40:07,220
we'll find a place because they're much

00:40:04,759 --> 00:40:09,170
more flexible and they have a faster

00:40:07,220 --> 00:40:11,960
time-to-market as long as you know how

00:40:09,170 --> 00:40:15,200
to program them so deep neural networks

00:40:11,960 --> 00:40:17,660
are really moving into many areas drug

00:40:15,200 --> 00:40:19,489
discovery medical imaging you know

00:40:17,660 --> 00:40:22,339
beyond sort of saying this is a picture

00:40:19,489 --> 00:40:24,529
of a cat you know which is how most of

00:40:22,339 --> 00:40:26,690
this stuff started but we have an

00:40:24,529 --> 00:40:29,059
opportunity to dramatically reshape the

00:40:26,690 --> 00:40:31,279
way we design our computing devices to

00:40:29,059 --> 00:40:34,309
meet the needs of these this emerging

00:40:31,279 --> 00:40:37,160
and growing growing market I expect to

00:40:34,309 --> 00:40:40,489
see lots of innovation and excitement in

00:40:37,160 --> 00:40:43,339
the in the years to come so stay tuned

00:40:40,489 --> 00:40:46,069
it's going to be a fun ride so in

00:40:43,339 --> 00:40:48,339
conclusion single-thread general

00:40:46,069 --> 00:40:52,339
performance improvement is slowing down

00:40:48,339 --> 00:40:54,890
energy efficiency is extremely important

00:40:52,339 --> 00:40:57,289
in data centers arm architecture enables

00:40:54,890 --> 00:40:59,869
energy efficient designs with good

00:40:57,289 --> 00:41:02,960
performance but that has to be a very

00:40:59,869 --> 00:41:04,789
explicit design goal typical use

00:41:02,960 --> 00:41:07,999
efficiency is becoming more important

00:41:04,789 --> 00:41:10,579
then then then peak performance at the

00:41:07,999 --> 00:41:13,430
highest levels of power idle more power

00:41:10,579 --> 00:41:15,140
will become more important smart power

00:41:13,430 --> 00:41:18,229
management is also something that will

00:41:15,140 --> 00:41:21,019
help meant you know limit the energy

00:41:18,229 --> 00:41:24,650
consumption in data centers security

00:41:21,019 --> 00:41:28,489
improvements are needed but we'll have

00:41:24,650 --> 00:41:31,009
to accept some performance loss to get

00:41:28,489 --> 00:41:33,589
that security nothing in life is nothing

00:41:31,009 --> 00:41:35,630
good in life is free there's plenty of

00:41:33,589 --> 00:41:38,390
opportunity for innovation for new

00:41:35,630 --> 00:41:40,579
application specific architectures and

00:41:38,390 --> 00:41:43,809
then not as I was thinking about this I

00:41:40,579 --> 00:41:47,960
said not just in CPU design but in life

00:41:43,809 --> 00:41:50,559
speculation can lead to a meltdown so

00:41:47,960 --> 00:41:50,559
that's all I had

00:41:53,900 --> 00:41:57,710

YouTube URL: https://www.youtube.com/watch?v=iAxy9suPYyk


