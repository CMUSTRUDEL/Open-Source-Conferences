Title: LVC20-109 Arm core: Empower networking on SmartNIC
Publication date: 2020-09-21
Playlist: Linaro Virtual Connect 2020
Description: 
	Empower networking on SmartNIC
SmartNIC becomes increasingly popular in datacenter and telco. It can achieve high performance and rich feature networking, and release CPU resources on server.


In a real deployment, OVS-DPDK on Arm based SmartNIC is one of the common networking solutions. In this presentation, we demo two different SmartNICs for OVS-DPDK, and discuss the advantages introduced by Arm CPU as follows:
1. Flexible and programmable.
2. Highly efficient implementation for complex features difficult to be done by hardware.
3. Fully offloading, include control plane and management plane
Captions: 
	00:00:10,320 --> 00:00:14,000
hi

00:00:10,719 --> 00:00:16,160
everyone today i'm going to talk about

00:00:14,000 --> 00:00:19,359
arm calls on smaniq

00:00:16,160 --> 00:00:21,920
arm calls empower networking and

00:00:19,359 --> 00:00:21,920
hispanic

00:00:23,680 --> 00:00:31,039
in my presentation i will

00:00:27,840 --> 00:00:33,200
introduce three parts one is a brief

00:00:31,039 --> 00:00:36,480
introduction to smaniq

00:00:33,200 --> 00:00:38,000
the second one is to is about network of

00:00:36,480 --> 00:00:40,800
loading models

00:00:38,000 --> 00:00:43,120
and address the value of arm calls for

00:00:40,800 --> 00:00:46,640
the offloading mode

00:00:43,120 --> 00:00:49,039
finally i'll do two full os of loading

00:00:46,640 --> 00:00:49,039
demos

00:00:53,520 --> 00:01:00,960
first of all smartnik has become

00:00:57,520 --> 00:01:04,559
increasingly popular in data center

00:01:00,960 --> 00:01:07,840
and telco field because as you can see

00:01:04,559 --> 00:01:07,840
in the right picture

00:01:08,720 --> 00:01:15,600
this money support a lot of functions

00:01:12,159 --> 00:01:19,520
such as network

00:01:15,600 --> 00:01:19,520
cryptography and storage

00:01:19,759 --> 00:01:24,560
smarnic also supports a lot of network

00:01:22,640 --> 00:01:28,400
function

00:01:24,560 --> 00:01:31,920
it supports network overlays for example

00:01:28,400 --> 00:01:36,000
the vxlan which is widely used

00:01:31,920 --> 00:01:39,439
in a uh in a public cloud

00:01:36,000 --> 00:01:42,880
package inspection on file in firewall

00:01:39,439 --> 00:01:44,799
and packet processing many of them

00:01:42,880 --> 00:01:50,240
depends on software

00:01:44,799 --> 00:01:50,240
so it depends heavily on cpu cores

00:01:50,799 --> 00:01:57,759
the target for smalling is to improve

00:01:54,560 --> 00:01:57,759
network throughput

00:01:59,600 --> 00:02:08,319
smanig can increase the network speed

00:02:04,079 --> 00:02:11,599
avoid bottleneck and even sometimes

00:02:08,319 --> 00:02:15,760
mitigates the ddos attack so

00:02:11,599 --> 00:02:15,760
it can improve the network throughput

00:02:19,520 --> 00:02:25,920
it aims to offload network functions

00:02:23,120 --> 00:02:25,920
from service

00:02:31,440 --> 00:02:38,879
then secondly we are talking about

00:02:35,440 --> 00:02:42,560
the network of loading so what is a

00:02:38,879 --> 00:02:42,560
network of loading osmonic

00:02:42,640 --> 00:02:51,120
as you can see in the right picture

00:02:47,120 --> 00:02:54,160
in a traditional implementation

00:02:51,120 --> 00:02:57,680
the traditional nic

00:02:54,160 --> 00:03:01,200
which is called dumpling will only

00:02:57,680 --> 00:03:04,319
receive the package and

00:03:01,200 --> 00:03:07,760
send out the packets it will not pause

00:03:04,319 --> 00:03:07,760
or process the packets

00:03:08,879 --> 00:03:14,800
all the software about

00:03:12,080 --> 00:03:18,000
processing the network traffic is

00:03:14,800 --> 00:03:21,440
running on the host

00:03:18,000 --> 00:03:24,640
the offloading on monique is to move

00:03:21,440 --> 00:03:27,840
the network functions such as the

00:03:24,640 --> 00:03:31,200
user space virtual waste virtuous wage

00:03:27,840 --> 00:03:34,480
choose monique and

00:03:31,200 --> 00:03:36,720
the what is going to be offloaded

00:03:34,480 --> 00:03:40,159
to smallnic depends on the difference

00:03:36,720 --> 00:03:40,159
mining implementations

00:03:42,560 --> 00:03:49,920
because we offload the network functions

00:03:46,319 --> 00:03:53,360
choose monique this monique will

00:03:49,920 --> 00:03:56,080
help help free host resources

00:03:53,360 --> 00:03:58,720
and improve performances for packet

00:03:56,080 --> 00:03:58,720
processing

00:03:59,560 --> 00:04:06,560
ovsdbtk is one of the most common

00:04:02,879 --> 00:04:06,560
network of loading solutions

00:04:11,120 --> 00:04:15,760
the network of loading models there are

00:04:13,439 --> 00:04:19,519
lots of network of loading modes

00:04:15,760 --> 00:04:22,560
but it can be classified into two uh

00:04:19,519 --> 00:04:26,840
two classification one is a data

00:04:22,560 --> 00:04:29,840
path of loading another is a full os of

00:04:26,840 --> 00:04:29,840
loading

00:04:30,800 --> 00:04:35,120
in data parts of loading the host will

00:04:34,320 --> 00:04:37,280
run

00:04:35,120 --> 00:04:39,440
the slow pass and the management

00:04:37,280 --> 00:04:42,880
software

00:04:39,440 --> 00:04:47,040
this monique only

00:04:42,880 --> 00:04:47,040
processor hardware fastpass

00:04:52,960 --> 00:04:59,120
this monique only have the hardware

00:04:56,479 --> 00:04:59,120
fastpass

00:05:06,560 --> 00:05:10,320
there are two kinds of data parts of

00:05:08,639 --> 00:05:12,880
loading what is a

00:05:10,320 --> 00:05:14,400
partial data path of loading another one

00:05:12,880 --> 00:05:18,080
is a

00:05:14,400 --> 00:05:21,600
the other is a full data path of loading

00:05:18,080 --> 00:05:25,759
in partial data parts of loading

00:05:21,600 --> 00:05:28,880
the hardware will do the package parsing

00:05:25,759 --> 00:05:29,680
analyze the analyzer package and the

00:05:28,880 --> 00:05:32,720
software

00:05:29,680 --> 00:05:33,680
on the host will do the flow table

00:05:32,720 --> 00:05:36,880
lookup

00:05:33,680 --> 00:05:38,240
and decide which actions to perform such

00:05:36,880 --> 00:05:42,400
as

00:05:38,240 --> 00:05:46,400
jobs package or forward packets

00:05:42,400 --> 00:05:46,400
in full data parts of loading

00:05:46,960 --> 00:05:50,720
only the initial first package for each

00:05:49,840 --> 00:05:53,919
flow

00:05:50,720 --> 00:05:57,680
will be will be sent up to the

00:05:53,919 --> 00:06:00,880
slow pass and after the

00:05:57,680 --> 00:06:03,199
rules and identify packets are inserted

00:06:00,880 --> 00:06:07,039
into the software

00:06:03,199 --> 00:06:10,639
the following same packets

00:06:07,039 --> 00:06:12,960
will not go off to the uh to the slow

00:06:10,639 --> 00:06:12,960
pass

00:06:13,120 --> 00:06:18,319
it can be processed more fast

00:06:18,960 --> 00:06:26,800
as you can see the software data path

00:06:23,440 --> 00:06:29,120
and the management in both

00:06:26,800 --> 00:06:30,639
partial floating and the full data path

00:06:29,120 --> 00:06:33,600
of loading

00:06:30,639 --> 00:06:34,560
those software are running on the host

00:06:33,600 --> 00:06:37,280
that means

00:06:34,560 --> 00:06:39,600
it will take up cpu resources on the

00:06:37,280 --> 00:06:39,600
host

00:06:43,520 --> 00:06:49,840
so let's see the what is the full os of

00:06:46,840 --> 00:06:49,840
loading

00:06:50,479 --> 00:06:58,160
as you can see in the uh in the picture

00:06:54,880 --> 00:07:01,759
because there the arm cores

00:06:58,160 --> 00:07:02,319
on this monique we can run both data

00:07:01,759 --> 00:07:06,960
paths

00:07:02,319 --> 00:07:11,759
and management software on this monique

00:07:06,960 --> 00:07:15,039
this monique will will through

00:07:11,759 --> 00:07:18,479
will communicate with the host will

00:07:15,039 --> 00:07:18,479
send traffic to the host

00:07:18,639 --> 00:07:23,440
through srv or words io

00:07:24,639 --> 00:07:32,800
why we need four overs of loading

00:07:28,720 --> 00:07:36,560
because the uh the the computation

00:07:32,800 --> 00:07:39,280
uh resources on the host is

00:07:36,560 --> 00:07:39,280
expensive

00:07:40,080 --> 00:07:44,720
for lower soft loading country of host

00:07:43,039 --> 00:07:47,919
cpu computation

00:07:44,720 --> 00:07:51,919
and cache resources and it supports

00:07:47,919 --> 00:07:51,919
latency sensitive services

00:07:54,000 --> 00:08:00,319
in this in the full os of loading

00:07:58,000 --> 00:08:02,720
the high performance arm cores are

00:08:00,319 --> 00:08:02,720
valuable

00:08:03,520 --> 00:08:08,160
it supports complex combination of

00:08:06,400 --> 00:08:11,360
actions when processing the

00:08:08,160 --> 00:08:13,520
network traffic and it's

00:08:11,360 --> 00:08:14,960
also supports stateful package

00:08:13,520 --> 00:08:19,919
processing

00:08:14,960 --> 00:08:19,919
for example the network states migration

00:08:20,160 --> 00:08:27,759
it can migrate the the state for tcp

00:08:24,840 --> 00:08:30,960
connections

00:08:27,759 --> 00:08:33,760
under sdn

00:08:30,960 --> 00:08:35,680
the network topology and network

00:08:33,760 --> 00:08:37,839
configuration are usually

00:08:35,680 --> 00:08:39,599
stored in the in the database in the

00:08:37,839 --> 00:08:43,599
databases

00:08:39,599 --> 00:08:46,800
when one of the databases crashed

00:08:43,599 --> 00:08:51,519
this monique supports fast

00:08:46,800 --> 00:08:55,360
database database recovery

00:08:51,519 --> 00:08:57,839
through some algorithms

00:08:55,360 --> 00:08:58,560
it also supports because so because of

00:08:57,839 --> 00:09:01,120
the

00:08:58,560 --> 00:09:01,760
uh high performance arm course it

00:09:01,120 --> 00:09:03,279
supports

00:09:01,760 --> 00:09:04,959
high concurrent connection

00:09:03,279 --> 00:09:09,360
initialization

00:09:04,959 --> 00:09:12,480
such as a web service

00:09:09,360 --> 00:09:14,560
and the as the beginning of my

00:09:12,480 --> 00:09:16,880
presentation i mentioned

00:09:14,560 --> 00:09:18,720
uh the smart needs also support other

00:09:16,880 --> 00:09:23,839
functions besides network

00:09:18,720 --> 00:09:23,839
such as net storage and the cryptography

00:09:24,959 --> 00:09:33,600
let's see the first

00:09:28,160 --> 00:09:33,600
os full os of loading deployment

00:09:34,839 --> 00:09:40,720
deployment

00:09:36,959 --> 00:09:44,240
this is uh this is we use a

00:09:40,720 --> 00:09:47,920
stingray the package generator

00:09:44,240 --> 00:09:51,200
will generate flows the flows will

00:09:47,920 --> 00:09:54,399
uh go into the smart link through the

00:09:51,200 --> 00:09:58,399
physical function when the

00:09:54,399 --> 00:10:02,320
over os process unless monique

00:09:58,399 --> 00:10:06,640
receive the packets it will

00:10:02,320 --> 00:10:06,640
according to the open flow rule

00:10:07,120 --> 00:10:13,519
the os process will forward the

00:10:10,240 --> 00:10:16,959
all the packets or the traffic to the

00:10:13,519 --> 00:10:20,320
virtual machine through sr iov

00:10:16,959 --> 00:10:22,320
interface but in this demo we will

00:10:20,320 --> 00:10:24,800
bypass the hardware acceleration

00:10:22,320 --> 00:10:28,079
function to

00:10:24,800 --> 00:10:31,120
verify the pure softwares of

00:10:28,079 --> 00:10:31,120
pure software

00:10:31,360 --> 00:10:37,279
solutions um for os of loading

00:10:37,680 --> 00:10:43,519
when the virtual machine

00:10:40,959 --> 00:10:44,720
the pro the test pmd process on the on

00:10:43,519 --> 00:10:48,399
virtual machine

00:10:44,720 --> 00:10:51,760
receive the packets

00:10:48,399 --> 00:10:54,800
it will forward back to the

00:10:51,760 --> 00:10:57,839
overs process on this monique

00:10:54,800 --> 00:11:02,320
in this way we can measure

00:10:57,839 --> 00:11:05,760
the throughput of the software solution

00:11:02,320 --> 00:11:05,760
for os of loading

00:11:06,000 --> 00:11:15,839
let's see the video

00:11:32,320 --> 00:11:35,440
first we need to bring up the physical

00:11:34,480 --> 00:11:39,680
interface

00:11:35,440 --> 00:11:39,680
and create a virtual function

00:11:40,480 --> 00:11:44,560
we can use a comma we can use this

00:11:43,200 --> 00:11:48,399
command to see

00:11:44,560 --> 00:11:48,399
the newly created virtual function

00:11:49,760 --> 00:11:53,920
and we bring up the interface

00:11:55,360 --> 00:12:00,800
for further configuration and under the

00:12:05,519 --> 00:12:10,399
and we can use the s tool to check the

00:12:08,839 --> 00:12:14,560
information

00:12:10,399 --> 00:12:16,639
for the newly created virtual interface

00:12:14,560 --> 00:12:17,600
you can see the box information which we

00:12:16,639 --> 00:12:20,959
will

00:12:17,600 --> 00:12:22,839
which we will use usually to assign

00:12:20,959 --> 00:12:25,839
the virtual function to the virtual

00:12:22,839 --> 00:12:25,839
machine

00:12:26,160 --> 00:12:39,839
then we mount the huge page load

00:12:29,200 --> 00:12:39,839
the uil driver

00:12:40,000 --> 00:12:43,440
then we will configure the stingray

00:12:42,160 --> 00:12:47,519
smanic

00:12:43,440 --> 00:12:53,839
we bring up the interface and create the

00:12:47,519 --> 00:12:57,040
virtual function with a similar command

00:12:53,839 --> 00:12:59,680
you can see the passing for pass

00:12:57,040 --> 00:13:02,000
the pci boxing for under the interface

00:12:59,680 --> 00:13:07,839
name

00:13:02,000 --> 00:13:07,839
will bring up the interface

00:13:12,959 --> 00:13:19,839
then we can use a bnx tctl

00:13:16,880 --> 00:13:20,720
to connect the virtual interface unless

00:13:19,839 --> 00:13:24,160
monique

00:13:20,720 --> 00:13:27,519
and the virtual interface on the host

00:13:24,160 --> 00:13:32,639
in this way this monique and the host

00:13:27,519 --> 00:13:32,639
can forward packets between

00:13:32,839 --> 00:13:38,800
them

00:13:34,959 --> 00:13:42,399
then we will mount the huge page and

00:13:38,800 --> 00:13:42,399
send the number of huge page

00:13:43,839 --> 00:13:50,160
similarly we

00:13:46,959 --> 00:13:54,000
load the ui igb url

00:13:50,160 --> 00:13:55,120
driver because we will use the igb url

00:13:54,000 --> 00:13:57,839
driver for the

00:13:55,120 --> 00:13:58,320
uh for the interface we need to unbind

00:13:57,839 --> 00:14:01,519
the

00:13:58,320 --> 00:14:06,000
bnxt driver

00:14:01,519 --> 00:14:06,000
for those interface we need to use

00:14:08,800 --> 00:14:17,839
then rebind the igb url driver

00:14:12,639 --> 00:14:17,839
for the in those interface

00:14:22,880 --> 00:14:27,680
then we need to create create oes

00:14:25,839 --> 00:14:31,680
process on this monique

00:14:27,680 --> 00:14:34,880
we need to to over to avoid inter

00:14:31,680 --> 00:14:39,120
interference we will

00:14:34,880 --> 00:14:42,240
exit all the existing os

00:14:39,120 --> 00:14:45,440
process then we recreate

00:14:42,240 --> 00:14:49,600
the os db

00:14:45,440 --> 00:14:49,600
and the start the ovsdb server

00:14:52,800 --> 00:14:56,399
now we do we create some

00:14:55,290 --> 00:14:59,800
[Music]

00:14:56,399 --> 00:15:03,199
interface and bind them to dptk

00:14:59,800 --> 00:15:03,199
osdpk bridge

00:15:04,160 --> 00:15:13,839
we with the interface

00:15:08,160 --> 00:15:13,839
pci box id

00:15:15,600 --> 00:15:18,079
finally

00:15:20,000 --> 00:15:27,920
we will set the open flow rules

00:15:23,680 --> 00:15:29,839
to for two forwards of the package from

00:15:27,920 --> 00:15:33,120
the pf1 to wave

00:15:29,839 --> 00:15:35,519
zero and the welfare zero back to the pf

00:15:33,120 --> 00:15:35,519
zero

00:15:39,040 --> 00:15:46,160
big uh because the cafe

00:15:42,160 --> 00:15:49,440
configuration are quite long so i

00:15:46,160 --> 00:15:55,440
uh i write all the comments

00:15:49,440 --> 00:15:58,720
to the scripts

00:15:55,440 --> 00:16:00,560
after executing the scripts we need to

00:15:58,720 --> 00:16:03,600
assign the virtual function

00:16:00,560 --> 00:16:07,279
we created on the whole host to the

00:16:03,600 --> 00:16:11,360
vm we use a

00:16:07,279 --> 00:16:14,880
leave words comment to change the

00:16:11,360 --> 00:16:22,240
net to configure the

00:16:14,880 --> 00:16:25,360
virtual interface for vm

00:16:22,240 --> 00:16:28,399
we need to fill the domain

00:16:25,360 --> 00:16:32,079
box slot and the function

00:16:28,399 --> 00:16:37,839
id according to the bus id which we have

00:16:32,079 --> 00:16:37,839
justly seen

00:16:38,800 --> 00:16:46,240
after finish configuration

00:16:42,639 --> 00:16:50,399
we can see the box info here

00:16:46,240 --> 00:16:53,199
and start the os xrv

00:16:50,399 --> 00:16:53,199
virtual machine

00:16:54,399 --> 00:16:58,560
after the virtual machine is ready we

00:16:56,959 --> 00:17:01,839
can use ls pci

00:16:58,560 --> 00:17:02,880
to see the uh commands to see the

00:17:01,839 --> 00:17:05,839
interface we

00:17:02,880 --> 00:17:05,839
just created

00:17:10,880 --> 00:17:18,000
and similarly amongst the huge page

00:17:15,600 --> 00:17:19,439
and this is the number of huge page

00:17:18,000 --> 00:17:22,480
because we will use

00:17:19,439 --> 00:17:22,480
a test pmd

00:17:22,640 --> 00:17:25,039
later

00:17:26,319 --> 00:17:33,039
and load the driver to help the test pmd

00:17:29,919 --> 00:17:35,679
process to identify the

00:17:33,039 --> 00:17:38,160
to identify the virtual interface we

00:17:35,679 --> 00:17:38,160
created

00:17:40,320 --> 00:17:51,440
and bind the interface to dptk

00:17:47,440 --> 00:17:51,440
and start the test pmd process

00:17:57,039 --> 00:18:04,400
finally we use a package generator

00:18:00,960 --> 00:18:04,400
to send some traffic

00:18:05,039 --> 00:18:09,840
we set the frame rate to 15 percent of

00:18:08,160 --> 00:18:15,840
the line rate

00:18:09,840 --> 00:18:15,840
and with a 64 bytes packet

00:18:26,480 --> 00:18:30,559
as you can see in this configuration we

00:18:30,000 --> 00:18:33,919
can

00:18:30,559 --> 00:18:42,480
achieve 5.5

00:18:33,919 --> 00:18:45,520
mega packets per second

00:18:42,480 --> 00:18:48,720
okay let's see the second

00:18:45,520 --> 00:18:48,720
uh demo video

00:18:48,880 --> 00:18:55,760
because in current uh current historic

00:18:52,720 --> 00:18:59,520
implementation there's no in play

00:18:55,760 --> 00:19:02,880
implementation includes the up-to-date

00:18:59,520 --> 00:19:06,960
um arm course neo-verse n1

00:19:02,880 --> 00:19:10,960
with the hardware acceleration function

00:19:06,960 --> 00:19:14,160
so i use and nystv stp

00:19:10,960 --> 00:19:16,320
which is which are embedded with a new

00:19:14,160 --> 00:19:20,960
version one cpu

00:19:16,320 --> 00:19:25,679
and the user sting connects five

00:19:20,960 --> 00:19:28,080
to demo the hardware acceleration

00:19:25,679 --> 00:19:28,720
as you can see the topology for this

00:19:28,080 --> 00:19:30,880
demo

00:19:28,720 --> 00:19:33,520
is quite similar to the previous

00:19:30,880 --> 00:19:35,840
previously one

00:19:33,520 --> 00:19:37,600
to the previous one and the the

00:19:35,840 --> 00:19:40,960
difference is two

00:19:37,600 --> 00:19:42,559
is in this demo we will use a hardware

00:19:40,960 --> 00:19:47,039
acceleration function

00:19:42,559 --> 00:19:53,840
uh in a in this monique

00:19:47,039 --> 00:19:53,840
okay let's see the demo video

00:20:10,240 --> 00:20:17,280
first we can use lspci

00:20:14,240 --> 00:20:20,400
to find out the

00:20:17,280 --> 00:20:22,559
pci box id for the virtual uh physical

00:20:20,400 --> 00:20:26,400
function we we need to use

00:20:22,559 --> 00:20:28,799
and reset that function

00:20:26,400 --> 00:20:30,559
because this will clear all the old

00:20:28,799 --> 00:20:35,840
configuration to avoid

00:20:30,559 --> 00:20:35,840
interface interference

00:20:38,799 --> 00:20:45,600
similarly to the previous demo

00:20:42,080 --> 00:20:51,520
we use a similar command command

00:20:45,600 --> 00:20:51,520
to create a new virtual function

00:20:51,600 --> 00:20:54,720
we can see the virtual function

00:20:53,120 --> 00:20:57,840
information the

00:20:54,720 --> 00:20:57,840
pci bus id

00:21:00,720 --> 00:21:07,360
then because we need to uh bind

00:21:03,760 --> 00:21:09,919
the other driver later so

00:21:07,360 --> 00:21:12,159
we need to unbind the kernel driver

00:21:09,919 --> 00:21:16,960
melanox 5 core

00:21:12,159 --> 00:21:20,240
for that for the virtual function

00:21:16,960 --> 00:21:21,840
then we switch the smart link to the

00:21:20,240 --> 00:21:24,400
switch tv demo

00:21:21,840 --> 00:21:30,799
which is necessary for the hardware

00:21:24,400 --> 00:21:34,480
acceleration function

00:21:30,799 --> 00:21:37,919
and we still need to start up

00:21:34,480 --> 00:21:41,280
start the os function

00:21:37,919 --> 00:21:44,960
first of all we exit

00:21:41,280 --> 00:21:47,840
all the existing over a ovs

00:21:44,960 --> 00:21:47,840
uh process

00:21:48,080 --> 00:21:51,600
to clear the tier click to clear all the

00:21:50,799 --> 00:21:54,799
old

00:21:51,600 --> 00:21:54,799
uh configurations

00:21:55,520 --> 00:22:04,000
then we use oh we use a

00:22:00,080 --> 00:22:04,880
oas database schema to recreate the os

00:22:04,000 --> 00:22:08,720
db

00:22:04,880 --> 00:22:08,720
and start osdb server

00:22:11,120 --> 00:22:15,200
you the uh attention to the hardware of

00:22:14,400 --> 00:22:19,919
load

00:22:15,200 --> 00:22:19,919
uh parameter which you set it to true

00:22:21,760 --> 00:22:28,080
and also we need to configure the dv

00:22:24,880 --> 00:22:31,760
flow parameter to

00:22:28,080 --> 00:22:34,240
1 because these two parameters are

00:22:31,760 --> 00:22:40,880
essential to enable the hardware

00:22:34,240 --> 00:22:43,919
acceleration functions

00:22:40,880 --> 00:22:47,120
to make the above tech effective

00:22:43,919 --> 00:22:51,360
immediately we need to

00:22:47,120 --> 00:22:51,360
restart the os we switch d

00:22:52,840 --> 00:22:55,840
process

00:23:00,320 --> 00:23:08,559
and then we created a three interface

00:23:04,080 --> 00:23:11,760
pfo pf1 and vm1 according to the

00:23:08,559 --> 00:23:14,960
pci box id another

00:23:11,760 --> 00:23:19,600
represented id

00:23:14,960 --> 00:23:23,200
finally we we configured the

00:23:19,600 --> 00:23:37,840
forwarding rule from pfo to vm1

00:23:23,200 --> 00:23:37,840
and from vm1 back to pf1

00:23:46,480 --> 00:23:54,240
and we need to assign

00:23:50,559 --> 00:23:56,880
the virtual interface to use the

00:23:54,240 --> 00:23:58,320
pci box id to assign the virtual

00:23:56,880 --> 00:24:01,840
interface to

00:23:58,320 --> 00:24:01,840
to the vm

00:24:02,880 --> 00:24:10,000
we configure the domain

00:24:06,480 --> 00:24:15,679
box and slow slot and function id

00:24:10,000 --> 00:24:15,679
according to the pci box id

00:24:17,440 --> 00:24:21,760
and then starts the virtual machine

00:24:27,279 --> 00:24:31,679
after the virtual machine is ready we

00:24:30,080 --> 00:24:34,400
log into the

00:24:31,679 --> 00:24:34,400
virtual machine

00:24:39,279 --> 00:24:48,080
and do the similar and we can

00:24:43,200 --> 00:24:52,480
find out the virtual interface

00:24:48,080 --> 00:25:01,840
bus id on inside of the vm

00:24:52,480 --> 00:25:01,840
similarly we mount the huge page

00:25:06,320 --> 00:25:14,720
load the driver because this is

00:25:09,919 --> 00:25:18,240
essential for test pmd to identify the

00:25:14,720 --> 00:25:20,640
virtual function we assigned to the

00:25:18,240 --> 00:25:20,640
vm

00:25:22,880 --> 00:25:29,840
and start the test pmd process

00:25:34,320 --> 00:25:42,960
and we use package generator to send

00:25:37,360 --> 00:25:46,880
some traffic

00:25:42,960 --> 00:25:46,880
uh with 64 bytes

00:25:46,960 --> 00:25:54,000
package we can achieve 25

00:25:50,480 --> 00:25:57,440
million packets per second which is

00:25:54,000 --> 00:26:00,480
four or five times compared to the

00:25:57,440 --> 00:26:00,480
stingray performance

00:26:02,240 --> 00:26:10,159
according to the two demos we have shown

00:26:06,000 --> 00:26:12,400
we can we can say that with stronger and

00:26:10,159 --> 00:26:12,880
one cpu under the hardware acceleration

00:26:12,400 --> 00:26:16,080
we can

00:26:12,880 --> 00:26:18,640
achieve high performance on

00:26:16,080 --> 00:26:18,640
throughput

00:26:20,080 --> 00:26:24,080
under in real time in real benchmarking

00:26:23,279 --> 00:26:27,360
we have

00:26:24,080 --> 00:26:30,640
uh we also verify uh the

00:26:27,360 --> 00:26:31,679
stronger m1 cpu can also achieve high

00:26:30,640 --> 00:26:34,880
performance

00:26:31,679 --> 00:26:38,000
uh when we have high concurrent

00:26:34,880 --> 00:26:41,679
uh connection app applications

00:26:38,000 --> 00:26:42,559
like the web servers but uh i will not

00:26:41,679 --> 00:26:46,080
show the

00:26:42,559 --> 00:26:49,360
uh demo here because uh the time limit

00:26:46,080 --> 00:26:50,400
because of the time limit if you have

00:26:49,360 --> 00:26:54,000
any questions

00:26:50,400 --> 00:27:00,880
you can contact me by email

00:26:54,000 --> 00:27:00,880

YouTube URL: https://www.youtube.com/watch?v=w0jvp4iC2oU


