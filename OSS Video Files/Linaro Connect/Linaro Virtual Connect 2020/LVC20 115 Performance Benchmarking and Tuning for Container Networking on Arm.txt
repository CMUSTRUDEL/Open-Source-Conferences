Title: LVC20 115 Performance Benchmarking and Tuning for Container Networking on Arm
Publication date: 2020-10-09
Playlist: Linaro Virtual Connect 2020
Description: 
	Performance Benchmarking and Tuning for Container Networking on Arm

Arm ecosystem is becoming much more popular in cloud native applications than ever before with its increasing wide use. Arm devotes to be a cloud native vendor and puts much resources to enable related projects on its platform. Container networking is the key to high performance connection for cloud native computing and there are a number of Container Networking Interface(CNI) solutions, such as Flannel, Calico, etc.

In the presentation, we would like present our recent work result on the performance benchmarking and tuning on various CNIs of arm:
1. High performance evaluation environment and tools used for benchmarking;
2. Networking models used by CNIs which actually affect the final result;
3. Benchmarking metrics(IP, TCP/UDP, HTTP) and results of the various CNIs on arm
4. Comparison between CNIs and analysis to the bottleneck factors with the graph
5. Our performance tuning to them and their improvements
from the Linux system and usage model aspects
Captions: 
	00:00:01,040 --> 00:00:06,160
uh good morning i think i should

00:00:03,120 --> 00:00:09,840
say good afternoon uh for me it's good

00:00:06,160 --> 00:00:12,080
it's evening and i will talk about

00:00:09,840 --> 00:00:13,920
our performance benchmarking and tuning

00:00:12,080 --> 00:00:16,640
for container working on arm

00:00:13,920 --> 00:00:18,160
which is about our work on the

00:00:16,640 --> 00:00:23,359
performance benchmarking

00:00:18,160 --> 00:00:26,240
issues uh for this slide i would like to

00:00:23,359 --> 00:00:28,400
uh introduce for this uh following

00:00:26,240 --> 00:00:31,119
agenda first i will briefly

00:00:28,400 --> 00:00:32,960
introduction about the topics and then i

00:00:31,119 --> 00:00:34,640
will talk about the content analog

00:00:32,960 --> 00:00:37,120
interfaces on arm

00:00:34,640 --> 00:00:39,120
and the it is the core part of the

00:00:37,120 --> 00:00:40,160
benchmarking metrics and the environment

00:00:39,120 --> 00:00:43,520
and tools

00:00:40,160 --> 00:00:44,640
and the benchmarking results actually we

00:00:43,520 --> 00:00:46,480
could like to

00:00:44,640 --> 00:00:48,879
present some initial performance

00:00:46,480 --> 00:00:52,000
analysis with the prof tools

00:00:48,879 --> 00:00:53,280
and they will talk about some uh future

00:00:52,000 --> 00:00:56,160
worker

00:00:53,280 --> 00:00:56,160
consideration

00:00:57,280 --> 00:01:01,600
firstly we would introduce a what is

00:00:59,359 --> 00:01:02,719
thing is a container networking

00:01:01,600 --> 00:01:04,879
interface

00:01:02,719 --> 00:01:06,560
uh it's a cloud native computing

00:01:04,879 --> 00:01:09,040
foundation project

00:01:06,560 --> 00:01:11,280
consists of a specification libraries

00:01:09,040 --> 00:01:13,840
for writing plugins to config network

00:01:11,280 --> 00:01:17,680
interfaces in linux containers

00:01:13,840 --> 00:01:20,560
along with a number of supported plugins

00:01:17,680 --> 00:01:21,600
and for the right part it's a thing i

00:01:20,560 --> 00:01:25,200
plugged in

00:01:21,600 --> 00:01:30,799
a single plugin

00:01:25,200 --> 00:01:30,799
graph it shows which shows as a cni

00:01:31,200 --> 00:01:36,320
part and which connects to the

00:01:34,320 --> 00:01:39,759
kubernetes runtime

00:01:36,320 --> 00:01:43,360
which is kubernetes kubernetes

00:01:39,759 --> 00:01:43,600
to create then create a new container

00:01:43,360 --> 00:01:46,560
and

00:01:43,600 --> 00:01:47,280
delete a container they can it will be a

00:01:46,560 --> 00:01:50,479
called a

00:01:47,280 --> 00:01:53,680
single plugin to create a pot or they

00:01:50,479 --> 00:01:55,280
create the container for the kubernetes

00:01:53,680 --> 00:01:58,640
networking mode

00:01:55,280 --> 00:02:02,079
we have several uh uh

00:01:58,640 --> 00:02:04,399
several assumptions first one is that

00:02:02,079 --> 00:02:05,680
all parts can communicate with other

00:02:04,399 --> 00:02:09,039
other parts

00:02:05,680 --> 00:02:11,680
without using the network address

00:02:09,039 --> 00:02:13,520
translation and the second one is all

00:02:11,680 --> 00:02:15,599
nodes can communicate with outputs

00:02:13,520 --> 00:02:18,720
without any t

00:02:15,599 --> 00:02:21,680
and the third one is ip that process

00:02:18,720 --> 00:02:22,000
itself is the same as is the same ips

00:02:21,680 --> 00:02:25,200
that

00:02:22,000 --> 00:02:27,040
others see it as so it's a

00:02:25,200 --> 00:02:29,040
uh i think kubernetes networking model

00:02:27,040 --> 00:02:32,400
is a virtual networking

00:02:29,040 --> 00:02:34,840
virtual networking environment for a

00:02:32,400 --> 00:02:37,040
virtual networking environment for the

00:02:34,840 --> 00:02:40,400
kubernetes

00:02:37,040 --> 00:02:43,280
and actually we have uh the following

00:02:40,400 --> 00:02:43,840
thing eyes as i had listed in the red

00:02:43,280 --> 00:02:46,879
part and

00:02:43,840 --> 00:02:47,760
but not limited to because there are so

00:02:46,879 --> 00:02:50,560
many things

00:02:47,760 --> 00:02:51,200
uh seeing eyes here that we could talk

00:02:50,560 --> 00:02:54,400
about

00:02:51,200 --> 00:02:56,319
but we can only attach only

00:02:54,400 --> 00:02:57,519
very small part of them because there

00:02:56,319 --> 00:03:01,519
are so many

00:02:57,519 --> 00:03:05,360
so many many complex uh cni's many many

00:03:01,519 --> 00:03:08,560
uh which uh each one provide very

00:03:05,360 --> 00:03:10,400
uh senior features very good features

00:03:08,560 --> 00:03:13,280
very very good solutions from connect

00:03:10,400 --> 00:03:19,519
networking but we can only choose a few

00:03:13,280 --> 00:03:22,640
very few of them to talk about

00:03:19,519 --> 00:03:25,599
uh uh you may interested in what

00:03:22,640 --> 00:03:26,000
we are uh what we have enabled uh for

00:03:25,599 --> 00:03:29,599
the

00:03:26,000 --> 00:03:32,879
arm on arm platform for the cni's uh

00:03:29,599 --> 00:03:35,519
actually uh we had enabled us

00:03:32,879 --> 00:03:36,560
the following one on their arm on the

00:03:35,519 --> 00:03:39,200
arm platform and

00:03:36,560 --> 00:03:40,480
integrated integrate them into the

00:03:39,200 --> 00:03:43,920
aquarium iec

00:03:40,480 --> 00:03:45,599
arm edge stack as a reference uh the

00:03:43,920 --> 00:03:47,599
first one is chemical

00:03:45,599 --> 00:03:48,879
and the cellulite is syrian and the

00:03:47,599 --> 00:03:51,760
continuous vp

00:03:48,879 --> 00:03:53,760
and alvin kubernetes and the srvc and

00:03:51,760 --> 00:03:57,920
for nano

00:03:53,760 --> 00:04:00,720
we had listed we had listed j

00:03:57,920 --> 00:04:03,760
features each one for example calico

00:04:00,720 --> 00:04:08,080
provides pure ip networking fabric

00:04:03,760 --> 00:04:10,400
which can uses uh the overlay-based

00:04:08,080 --> 00:04:11,920
solution or the direct routing based

00:04:10,400 --> 00:04:14,959
solution for their con

00:04:11,920 --> 00:04:16,880
for their container collection for cdn

00:04:14,959 --> 00:04:19,440
it is an index native api where

00:04:16,880 --> 00:04:22,960
networking and security for containers

00:04:19,440 --> 00:04:25,280
it uses the ebpf based network policy

00:04:22,960 --> 00:04:27,280
for load balance for security and all

00:04:25,280 --> 00:04:30,560
things like that

00:04:27,280 --> 00:04:33,840
another widely used uh uh

00:04:30,560 --> 00:04:34,560
uh cni is the fernando spanano is very

00:04:33,840 --> 00:04:37,120
easy to

00:04:34,560 --> 00:04:38,080
deploy and is a very simple solution for

00:04:37,120 --> 00:04:40,080
the

00:04:38,080 --> 00:04:41,680
kubernetes networking so it is widely

00:04:40,080 --> 00:04:45,919
used as a demo

00:04:41,680 --> 00:04:49,199
as a demo purpose for the demo purpose

00:04:45,919 --> 00:04:49,919
and for srv it is a physical network

00:04:49,199 --> 00:04:51,600
interface

00:04:49,919 --> 00:04:53,199
physical network interface support for

00:04:51,600 --> 00:04:56,800
the parts

00:04:53,199 --> 00:05:00,960
and for oem kubernetes it's a oes based

00:04:56,800 --> 00:05:03,440
kubernetes solution uh here we just

00:05:00,960 --> 00:05:04,479
talked about three cylinders in this uh

00:05:03,440 --> 00:05:08,000
in the

00:05:04,479 --> 00:05:10,639
in the this in the this slide the first

00:05:08,000 --> 00:05:12,639
one is for nano flannel uses

00:05:10,639 --> 00:05:13,840
an overlay solution for the particle

00:05:12,639 --> 00:05:17,120
port communication

00:05:13,840 --> 00:05:19,680
across hosts here is a top

00:05:17,120 --> 00:05:21,280
here is the architecture for the nano

00:05:19,680 --> 00:05:25,199
which uses ipip

00:05:21,280 --> 00:05:28,240
and the vx line as the back end

00:05:25,199 --> 00:05:29,280
the second one is serium cdm user uses

00:05:28,240 --> 00:05:32,320
the same

00:05:29,280 --> 00:05:35,360
almost the same overlay-based resolution

00:05:32,320 --> 00:05:38,560
for the across host communication

00:05:35,360 --> 00:05:41,360
that uses a ceiling hose to collect

00:05:38,560 --> 00:05:43,440
all the port port to the host and they

00:05:41,360 --> 00:05:46,800
use the cdmvx line to

00:05:43,440 --> 00:05:49,919
connect it to the outside world and to

00:05:46,800 --> 00:05:52,960
for the in-house communication and

00:05:49,919 --> 00:05:55,120
here's the top here is the basic uh

00:05:52,960 --> 00:05:56,400
network networking architecture for

00:05:55,120 --> 00:05:59,520
serium city ceiling

00:05:56,400 --> 00:06:03,120
also support the direct direct routing

00:05:59,520 --> 00:06:07,039
mod but we had not touched it because

00:06:03,120 --> 00:06:10,240
but we had not tested it until now

00:06:07,039 --> 00:06:11,919
and the third one is calico calico is a

00:06:10,240 --> 00:06:14,479
high performance networking solution

00:06:11,919 --> 00:06:15,600
with the eye direct ipip networking

00:06:14,479 --> 00:06:18,639
fabric

00:06:15,600 --> 00:06:21,600
and actually for the

00:06:18,639 --> 00:06:22,639
root routine based solution it it can

00:06:21,600 --> 00:06:25,120
support

00:06:22,639 --> 00:06:26,240
no incomplete encapsulation based

00:06:25,120 --> 00:06:30,319
solution

00:06:26,240 --> 00:06:33,360
for the positive part communication uh

00:06:30,319 --> 00:06:36,319
for the inter-host case

00:06:33,360 --> 00:06:37,120
and for kubernetes service uh the basic

00:06:36,319 --> 00:06:39,360
solution is

00:06:37,120 --> 00:06:40,479
for the copy is from the copy proxy

00:06:39,360 --> 00:06:44,160
which uses

00:06:40,479 --> 00:06:45,520
ib tables to support the uh usable the

00:06:44,160 --> 00:06:47,759
load balance and the

00:06:45,520 --> 00:06:50,560
also border load balance for the

00:06:47,759 --> 00:06:54,560
different back-end boards

00:06:50,560 --> 00:06:57,680
and another a recent solution is for the

00:06:54,560 --> 00:07:01,440
uh is for the uh is

00:06:57,680 --> 00:07:04,639
is from the ebbf support based solution

00:07:01,440 --> 00:07:08,000
for example cdm and the newest

00:07:04,639 --> 00:07:09,280
j current calico also supports a epf

00:07:08,000 --> 00:07:11,039
based

00:07:09,280 --> 00:07:12,960
solution which has much better

00:07:11,039 --> 00:07:17,840
performance than

00:07:12,960 --> 00:07:17,840
ib table solution

00:07:18,240 --> 00:07:22,560
uh actually we should talk about our

00:07:20,639 --> 00:07:23,199
benchmarking matrix environment at the

00:07:22,560 --> 00:07:26,720
tours

00:07:23,199 --> 00:07:28,960
here uh

00:07:26,720 --> 00:07:30,639
first one is that we want to talk about

00:07:28,960 --> 00:07:34,319
tcp and there's a

00:07:30,639 --> 00:07:36,160
layer for layer 4 performance and the

00:07:34,319 --> 00:07:37,840
layer 7 performance which is which is

00:07:36,160 --> 00:07:41,280
about http

00:07:37,840 --> 00:07:43,360
for the tcp metrics we talked about

00:07:41,280 --> 00:07:45,599
bandwidth and we talked about them

00:07:43,360 --> 00:07:48,639
within megabyte megabits

00:07:45,599 --> 00:07:51,520
per second or gigabits per second

00:07:48,639 --> 00:07:52,400
and for http performance we talk about

00:07:51,520 --> 00:07:55,599
bandwidth

00:07:52,400 --> 00:07:56,400
uh in megabits per second and gigabits

00:07:55,599 --> 00:07:59,680
per second

00:07:56,400 --> 00:08:02,960
and the cps rps but we have not really

00:07:59,680 --> 00:08:03,680
listed out the cps rps result here for

00:08:02,960 --> 00:08:05,919
the

00:08:03,680 --> 00:08:06,720
at actually we don't have too much time

00:08:05,919 --> 00:08:10,240
in this topic

00:08:06,720 --> 00:08:12,879
you uh

00:08:10,240 --> 00:08:13,840
we use this ipro for the tcp ip

00:08:12,879 --> 00:08:17,360
performance

00:08:13,840 --> 00:08:20,479
tcp throughput and we use this wrk

00:08:17,360 --> 00:08:24,800
client wrk as the http client

00:08:20,479 --> 00:08:24,800
http matrix here

00:08:24,879 --> 00:08:29,280
here we got a 10 gigabit collections for

00:08:28,000 --> 00:08:31,840
the

00:08:29,280 --> 00:08:35,120
classical inter-host communication for

00:08:31,840 --> 00:08:38,640
the part to part or notice your part

00:08:35,120 --> 00:08:40,479
actually we uh had a uses arm server

00:08:38,640 --> 00:08:43,440
here which is

00:08:40,479 --> 00:08:45,839
from malware and we don't talk about the

00:08:43,440 --> 00:08:48,480
details we want to talk about the

00:08:45,839 --> 00:08:49,040
type of this machine because of our test

00:08:48,480 --> 00:08:52,480
result

00:08:49,040 --> 00:08:54,560
is so maybe maybe some little

00:08:52,480 --> 00:08:56,560
maybe a little sensitive so we would not

00:08:54,560 --> 00:09:00,399
talk about the concrete solution

00:08:56,560 --> 00:09:03,440
concrete platform and

00:09:00,399 --> 00:09:03,440
actually uh

00:09:03,519 --> 00:09:06,800
this is a collection part collection

00:09:05,760 --> 00:09:09,120
topology

00:09:06,800 --> 00:09:13,120
collection topology for iproof test and

00:09:09,120 --> 00:09:14,959
the wrk http test http performance test

00:09:13,120 --> 00:09:17,040
and the first one will collect the

00:09:14,959 --> 00:09:17,600
iproof client to the apple server which

00:09:17,040 --> 00:09:20,720
each one

00:09:17,600 --> 00:09:25,519
runs in roms in a

00:09:20,720 --> 00:09:28,720
port the second one would be a uh

00:09:25,519 --> 00:09:31,920
that we would use ngx as a

00:09:28,720 --> 00:09:35,360
http http server and we will

00:09:31,920 --> 00:09:38,800
use wrk as the http client

00:09:35,360 --> 00:09:39,920
and for the wrk we can we use the two

00:09:38,800 --> 00:09:42,959
types of tests

00:09:39,920 --> 00:09:46,800
first one is we run wrk on the host from

00:09:42,959 --> 00:09:48,240
another host the second one we run wrk

00:09:46,800 --> 00:09:51,279
in a single port

00:09:48,240 --> 00:09:53,600
so there are two cases here uh this

00:09:51,279 --> 00:09:54,959
uh this page also gives out the

00:09:53,600 --> 00:09:57,279
collection between the

00:09:54,959 --> 00:09:58,880
particle part and for the inter-host

00:09:57,279 --> 00:10:01,920
that i introduced that can

00:09:58,880 --> 00:10:04,640
intro host the cases

00:10:01,920 --> 00:10:06,399
if the lactual a benchmarking route of

00:10:04,640 --> 00:10:09,760
tcp throughput for the same as

00:10:06,399 --> 00:10:12,000
with different back end here the first

00:10:09,760 --> 00:10:15,279
one we would like to give out is that

00:10:12,000 --> 00:10:16,320
they will give out the node to port tcp

00:10:15,279 --> 00:10:19,360
performance

00:10:16,320 --> 00:10:22,560
and say several test cases for

00:10:19,360 --> 00:10:25,760
i would like to uh listed out

00:10:22,560 --> 00:10:28,959
is the the first one is the ipip front

00:10:25,760 --> 00:10:31,519
for the chemical ipf ipip overlay

00:10:28,959 --> 00:10:32,160
solution from calico and the ipiper

00:10:31,519 --> 00:10:34,959
solution

00:10:32,160 --> 00:10:36,000
from fernando and the vx line solution

00:10:34,959 --> 00:10:39,200
from

00:10:36,000 --> 00:10:39,920
vxlan back and off nano and the vxlan

00:10:39,200 --> 00:10:43,360
solution

00:10:39,920 --> 00:10:46,640
xlam based solution for cdm and

00:10:43,360 --> 00:10:47,040
also we want to check check thing about

00:10:46,640 --> 00:10:50,160
the

00:10:47,040 --> 00:10:52,399
what what is the result to these

00:10:50,160 --> 00:10:53,760
results what is the result would be for

00:10:52,399 --> 00:10:56,640
the direct routing

00:10:53,760 --> 00:10:58,959
we just use the calico direct routing

00:10:56,640 --> 00:11:01,440
which has no tunnel

00:10:58,959 --> 00:11:02,000
for the particular part communication

00:11:01,440 --> 00:11:05,279
which should

00:11:02,000 --> 00:11:08,000
be uh directly uh

00:11:05,279 --> 00:11:08,320
if you are out uh intrinsics and we

00:11:08,000 --> 00:11:10,240
should

00:11:08,320 --> 00:11:11,839
think uh it has should have the best

00:11:10,240 --> 00:11:15,680
performance

00:11:11,839 --> 00:11:18,800
uh actually from the uh performance

00:11:15,680 --> 00:11:20,480
from these uh two graphs here

00:11:18,800 --> 00:11:22,000
the second one the first one is the node

00:11:20,480 --> 00:11:24,320
to power performance

00:11:22,000 --> 00:11:25,120
and the second the third uh the second

00:11:24,320 --> 00:11:27,360
one

00:11:25,120 --> 00:11:28,240
graph below is for the partial

00:11:27,360 --> 00:11:31,680
performance

00:11:28,240 --> 00:11:34,800
you could uh look at the look at the

00:11:31,680 --> 00:11:35,440
page here uh actually would i would like

00:11:34,800 --> 00:11:38,560
to figure

00:11:35,440 --> 00:11:40,640
out uh what what about our

00:11:38,560 --> 00:11:42,160
observation for the tcp performance over

00:11:40,640 --> 00:11:43,920
different cni's

00:11:42,160 --> 00:11:45,760
the first one is that the performance

00:11:43,920 --> 00:11:47,200
gap beating cylinders are not so

00:11:45,760 --> 00:11:50,639
explicit

00:11:47,200 --> 00:11:52,639
when the overnight hollow is used and

00:11:50,639 --> 00:11:54,560
for the calico and the nano shows a

00:11:52,639 --> 00:11:55,279
little bit better performance than cdm

00:11:54,560 --> 00:11:58,959
for most

00:11:55,279 --> 00:12:03,040
mqu's here actually we

00:11:58,959 --> 00:12:06,720
we had set different mqs for the for the

00:12:03,040 --> 00:12:09,360
physical nick and for the uh virtual

00:12:06,720 --> 00:12:11,200
interfaces to collect to the pot and the

00:12:09,360 --> 00:12:11,839
virtual interfaces for the different

00:12:11,200 --> 00:12:15,360
bridge

00:12:11,839 --> 00:12:15,839
different bridges we used so we could

00:12:15,360 --> 00:12:19,120
match

00:12:15,839 --> 00:12:23,360
them so the m2 we used is from the

00:12:19,120 --> 00:12:26,480
1500 from the 1500 to the

00:12:23,360 --> 00:12:29,680
9000 to 9000 and

00:12:26,480 --> 00:12:33,120
we could you can you can check the

00:12:29,680 --> 00:12:35,600
step we increase the mtu

00:12:33,120 --> 00:12:37,519
and the for the calico and the flannel

00:12:35,600 --> 00:12:39,760
shows a little bit bad performance and

00:12:37,519 --> 00:12:42,160
syrian for most m2 scale

00:12:39,760 --> 00:12:43,200
and there is ipip and the vxlan overlay

00:12:42,160 --> 00:12:45,600
tunnel enabled

00:12:43,200 --> 00:12:47,519
the large mto size their throughput

00:12:45,600 --> 00:12:50,079
performance is better

00:12:47,519 --> 00:12:51,200
when used directly routing and the

00:12:50,079 --> 00:12:54,079
throughput performance

00:12:51,200 --> 00:12:55,680
is not so significantly affected by the

00:12:54,079 --> 00:12:58,720
mtu size

00:12:55,680 --> 00:12:59,360
so and you can see that even with a very

00:12:58,720 --> 00:13:02,480
small

00:12:59,360 --> 00:13:04,639
mtu such as uh 1500

00:13:02,480 --> 00:13:05,680
and we still have good performance

00:13:04,639 --> 00:13:09,760
compared to the large

00:13:05,680 --> 00:13:11,279
m2 we don't lost explicit performance

00:13:09,760 --> 00:13:13,440
here

00:13:11,279 --> 00:13:14,560
and the performance of direct routing

00:13:13,440 --> 00:13:17,839
here by calico

00:13:14,560 --> 00:13:20,000
is better than ipip enabled so actually

00:13:17,839 --> 00:13:22,240
uh the director routing shows much

00:13:20,000 --> 00:13:22,480
better performance for the ipip tunnel

00:13:22,240 --> 00:13:25,680
and

00:13:22,480 --> 00:13:27,680
at the vxlan tunnel which is an issue we

00:13:25,680 --> 00:13:29,839
are investigating

00:13:27,680 --> 00:13:31,920
and the rpi b tunnel is a little bit

00:13:29,839 --> 00:13:34,240
better than the vxlan tunnel

00:13:31,920 --> 00:13:36,079
in general the node to part tcp

00:13:34,240 --> 00:13:37,360
performance is better than that of

00:13:36,079 --> 00:13:39,839
partial part

00:13:37,360 --> 00:13:40,480
which flows one more step because of the

00:13:39,839 --> 00:13:42,800
vth

00:13:40,480 --> 00:13:44,480
collection to the next canoe for the

00:13:42,800 --> 00:13:46,560
part

00:13:44,480 --> 00:13:47,600
finally compared with different

00:13:46,560 --> 00:13:51,760
scenarios it

00:13:47,600 --> 00:13:54,160
proves that ipip vx line overlay tunnel

00:13:51,760 --> 00:13:55,839
which are now implemented in the index

00:13:54,160 --> 00:13:58,160
kernel is a key fact

00:13:55,839 --> 00:13:59,839
which affects the performance of cns on

00:13:58,160 --> 00:14:02,320
arm

00:13:59,839 --> 00:14:03,040
here is a very interesting question is

00:14:02,320 --> 00:14:05,680
that why

00:14:03,040 --> 00:14:07,920
the node tube node to port performance

00:14:05,680 --> 00:14:09,839
is no better than that of partial pod

00:14:07,920 --> 00:14:13,199
case for cdm

00:14:09,839 --> 00:14:16,240
it's a little bit strange gear and

00:14:13,199 --> 00:14:17,839
you could sink it further and we still

00:14:16,240 --> 00:14:21,519
have no direct direct

00:14:17,839 --> 00:14:21,519
direct direct answer on it

00:14:22,560 --> 00:14:27,360
uh this is for the hddb for phones

00:14:24,880 --> 00:14:30,639
benchmarking for calico cni

00:14:27,360 --> 00:14:34,079
and we would just give out as a

00:14:30,639 --> 00:14:36,639
uh explain we would just explain what if

00:14:34,079 --> 00:14:39,040
what did they talk about we use these

00:14:36,639 --> 00:14:42,399
different file sizes the file size is

00:14:39,040 --> 00:14:45,920
from 600 bytes to uh

00:14:42,399 --> 00:14:46,959
500 megabytes so the if we increase the

00:14:45,920 --> 00:14:49,040
file size

00:14:46,959 --> 00:14:50,320
at the same time it also increase the

00:14:49,040 --> 00:14:54,720
mtu we used

00:14:50,320 --> 00:14:58,560
mtu we used and so the m2 is from the

00:14:54,720 --> 00:15:01,839
uh 1500 to

00:14:58,560 --> 00:15:02,160
uh nine nine thousand uh actually you

00:15:01,839 --> 00:15:05,279
see

00:15:02,160 --> 00:15:09,279
very strange values here for example the

00:15:05,279 --> 00:15:12,800
fourteen eighty which means that

00:15:09,279 --> 00:15:16,399
we are using say because ipip

00:15:12,800 --> 00:15:18,079
over payload overhead is the payload

00:15:16,399 --> 00:15:20,720
overhead is 20

00:15:18,079 --> 00:15:22,639
and for the vx line the payload overhead

00:15:20,720 --> 00:15:26,880
should be 50. so we should

00:15:22,639 --> 00:15:29,839
decrease the payload overhead

00:15:26,880 --> 00:15:30,880
decrease the payload overhead here so we

00:15:29,839 --> 00:15:33,920
got it a

00:15:30,880 --> 00:15:38,320
a very strange value here

00:15:33,920 --> 00:15:38,320
but it will not affect the result

00:15:38,480 --> 00:15:42,240
and here you know uh what we are talking

00:15:41,680 --> 00:15:44,880
about

00:15:42,240 --> 00:15:47,120
and you could give some out our initial

00:15:44,880 --> 00:15:49,680
observation here

00:15:47,120 --> 00:15:50,480
actually m2 has a rather big effect on

00:15:49,680 --> 00:15:52,959
the performance

00:15:50,480 --> 00:15:54,639
when accessing large files but when

00:15:52,959 --> 00:15:57,120
access but when

00:15:54,639 --> 00:15:58,480
to access the file size is small it has

00:15:57,120 --> 00:16:00,800
little effect

00:15:58,480 --> 00:16:03,199
to access the file size is a major

00:16:00,800 --> 00:16:04,959
factor to the http performance

00:16:03,199 --> 00:16:06,959
when there is only a small number

00:16:04,959 --> 00:16:09,680
parallel thread

00:16:06,959 --> 00:16:11,920
when the file size is big enough their

00:16:09,680 --> 00:16:15,040
performance can't be improved much even

00:16:11,920 --> 00:16:15,040
with big empty use

00:16:16,560 --> 00:16:20,720
and the second one for the http

00:16:18,720 --> 00:16:23,759
performance testing is that

00:16:20,720 --> 00:16:26,639
for the proto-port http performs is a

00:16:23,759 --> 00:16:27,920
calico non-ipip overlay for cross-course

00:16:26,639 --> 00:16:30,160
communication

00:16:27,920 --> 00:16:31,199
our initial urbanization is at almost

00:16:30,160 --> 00:16:33,920
the same as

00:16:31,199 --> 00:16:35,839
that of ipip and the file size has much

00:16:33,920 --> 00:16:37,360
more significant the performance impact

00:16:35,839 --> 00:16:40,480
than the mtu

00:16:37,360 --> 00:16:43,680
profile size is greater than 10

00:16:40,480 --> 00:16:45,440
megabytes the m2 has little effect

00:16:43,680 --> 00:16:48,000
than to the final performance the

00:16:45,440 --> 00:16:51,120
performance is much higher than those of

00:16:48,000 --> 00:16:54,320
ipi problem files as is greater than

00:16:51,120 --> 00:16:57,040
100 kilobytes you could see from the

00:16:54,320 --> 00:16:57,040
last page

00:16:57,680 --> 00:17:04,079
you could see from the last page and

00:17:00,959 --> 00:17:06,959
the http for most benchmarking here

00:17:04,079 --> 00:17:07,679
http this is for the third one third one

00:17:06,959 --> 00:17:10,640
is that the

00:17:07,679 --> 00:17:12,559
port support http performance these are

00:17:10,640 --> 00:17:16,319
calico ipip

00:17:12,559 --> 00:17:17,600
versus non-ipip cases for cross-house

00:17:16,319 --> 00:17:20,319
communication

00:17:17,600 --> 00:17:21,120
our observation here is that for file

00:17:20,319 --> 00:17:24,160
size

00:17:21,120 --> 00:17:26,240
which is greater than 10 megabytes

00:17:24,160 --> 00:17:28,079
the m2 has a little effect to the final

00:17:26,240 --> 00:17:30,640
performance and the performance much

00:17:28,079 --> 00:17:33,679
higher than those of ipip even files

00:17:30,640 --> 00:17:35,679
is greater than 100 kilobytes and

00:17:33,679 --> 00:17:37,039
when the m2 is small the performance gap

00:17:35,679 --> 00:17:40,400
between ipip and

00:17:37,039 --> 00:17:40,400
non-ipip is hyrule

00:17:41,840 --> 00:17:47,280
here is the host port and vs versus the

00:17:45,120 --> 00:17:49,840
host to service http programs with

00:17:47,280 --> 00:17:51,120
calico ipip and non-ipip for cross-host

00:17:49,840 --> 00:17:54,720
communication

00:17:51,120 --> 00:17:57,440
our observation is the performance

00:17:54,720 --> 00:17:58,720
uh the performance gap is manual when

00:17:57,440 --> 00:18:01,200
accessing small files

00:17:58,720 --> 00:18:02,400
for small file sets the host to port and

00:18:01,200 --> 00:18:04,400
host to service

00:18:02,400 --> 00:18:07,039
performance is almost the same which

00:18:04,400 --> 00:18:11,120
means that the service accessed

00:18:07,039 --> 00:18:13,760
by ip tables is not the bottleneck

00:18:11,120 --> 00:18:14,880
for the http service the performance of

00:18:13,760 --> 00:18:17,600
a non-ipip

00:18:14,880 --> 00:18:20,000
is much higher than those of ipv1 files

00:18:17,600 --> 00:18:22,240
is greater than 100 kilobytes

00:18:20,000 --> 00:18:23,760
and for large mqs large files has also

00:18:22,240 --> 00:18:24,559
both performance better than hostile

00:18:23,760 --> 00:18:26,960
service

00:18:24,559 --> 00:18:28,320
and for non-ipip the formats gap between

00:18:26,960 --> 00:18:30,799
different m2 is not so

00:18:28,320 --> 00:18:31,440
explicit so it's believe it's believed

00:18:30,799 --> 00:18:32,880
iph

00:18:31,440 --> 00:18:35,360
actually the bottleneck which is the

00:18:32,880 --> 00:18:39,200
same as previous

00:18:35,360 --> 00:18:42,559
and we'd like to compile uh

00:18:39,200 --> 00:18:45,280
different uh cni's uh i will just

00:18:42,559 --> 00:18:46,880
give out the http to service cases for

00:18:45,280 --> 00:18:50,320
different cmis

00:18:46,880 --> 00:18:52,480
and uh we you could take from this graph

00:18:50,320 --> 00:18:54,240
you can see that for this reason guys

00:18:52,480 --> 00:18:56,799
the performance gap is minor when

00:18:54,240 --> 00:18:57,600
accessing small files as pure's direct

00:18:56,799 --> 00:19:00,799
routing

00:18:57,600 --> 00:19:01,600
mod shows the best performance with any

00:19:00,799 --> 00:19:03,520
other

00:19:01,600 --> 00:19:05,600
compared with any other overlay based

00:19:03,520 --> 00:19:08,480
solution approach

00:19:05,600 --> 00:19:10,080
for file size which is greater than 100

00:19:08,480 --> 00:19:12,240
kilobytes the catechol shows

00:19:10,080 --> 00:19:13,520
explicitly the best performance over

00:19:12,240 --> 00:19:15,360
other two signals

00:19:13,520 --> 00:19:16,960
and the flyknow shows the worst hostile

00:19:15,360 --> 00:19:19,280
service performance

00:19:16,960 --> 00:19:20,559
and for large m2 and large faster cdm

00:19:19,280 --> 00:19:22,960
shows similar performance with the

00:19:20,559 --> 00:19:24,400
calico c9 for long ipip cases

00:19:22,960 --> 00:19:26,400
the performance gap between different

00:19:24,400 --> 00:19:27,919
mtu is not so explicit

00:19:26,400 --> 00:19:30,480
so it's believed that the tunnel

00:19:27,919 --> 00:19:33,520
communication is actually the bottleneck

00:19:30,480 --> 00:19:36,080
which is the same as previous

00:19:33,520 --> 00:19:37,360
uh we would like to give some initial

00:19:36,080 --> 00:19:40,480
performance in

00:19:37,360 --> 00:19:42,480
analysis for the uh uh

00:19:40,480 --> 00:19:44,559
overlay-based solutions uh for the

00:19:42,480 --> 00:19:46,559
overlay-based solutions for the

00:19:44,559 --> 00:19:47,919
autopilot communication to find out

00:19:46,559 --> 00:19:50,320
what's the bottleneck here

00:19:47,919 --> 00:19:51,039
but we only show but we only got the

00:19:50,320 --> 00:19:53,440
previous

00:19:51,039 --> 00:19:55,360
result we could have used the

00:19:53,440 --> 00:19:56,960
performance tools uh performance tools

00:19:55,360 --> 00:19:58,960
such as f trace perf

00:19:56,960 --> 00:20:00,880
trace and something like here we just

00:19:58,960 --> 00:20:03,600
give the proof

00:20:00,880 --> 00:20:05,200
we can use the proof and we say flame

00:20:03,600 --> 00:20:08,320
graph package to go to the

00:20:05,200 --> 00:20:11,919
flying graph for the eye proof test with

00:20:08,320 --> 00:20:14,320
and without the ipip tunnel here is the

00:20:11,919 --> 00:20:15,600
flame graph to the ipip tunnel case and

00:20:14,320 --> 00:20:18,400
no tunnel case

00:20:15,600 --> 00:20:19,360
you could see for the ipip tunnel case

00:20:18,400 --> 00:20:23,440
the cpu

00:20:19,360 --> 00:20:27,280
takes uh one takes two

00:20:23,440 --> 00:20:29,679
uh two tools uh takes two thirds

00:20:27,280 --> 00:20:31,200
takes two thirds of the time for the

00:20:29,679 --> 00:20:35,200
idle in the idle state

00:20:31,200 --> 00:20:37,520
it cannot uh in the host for the non

00:20:35,200 --> 00:20:38,720
for the non-tunnel cases for the

00:20:37,520 --> 00:20:41,520
non-tunnel cases

00:20:38,720 --> 00:20:43,120
the cpu can use this uh or most of the

00:20:41,520 --> 00:20:45,679
cpu are used on the trans

00:20:43,120 --> 00:20:46,840
transmission and the receiving we used

00:20:45,679 --> 00:20:50,960
on the receiving

00:20:46,840 --> 00:20:53,840
so uh we should find out the time

00:20:50,960 --> 00:20:55,360
final root cause for the problem in the

00:20:53,840 --> 00:20:59,520
late time for to

00:20:55,360 --> 00:21:02,720
to investigate why the cpu is in the id

00:20:59,520 --> 00:21:05,280
is in idle state so here

00:21:02,720 --> 00:21:06,960
we are our brief summary uh here we

00:21:05,280 --> 00:21:10,480
bring somebody we got

00:21:06,960 --> 00:21:12,960
and for the benchmarking case and

00:21:10,480 --> 00:21:14,400
we think all this reasonis utilizes the

00:21:12,960 --> 00:21:15,520
cleanest kernel overlay tunnel

00:21:14,400 --> 00:21:18,080
implementation

00:21:15,520 --> 00:21:19,600
to enable crying cross-culture plot and

00:21:18,080 --> 00:21:21,600
service communication

00:21:19,600 --> 00:21:24,000
and the tcp throughput performance gap

00:21:21,600 --> 00:21:26,720
between singers are not so explicit

00:21:24,000 --> 00:21:28,960
when overlay tunnel is used for tcp

00:21:26,720 --> 00:21:30,960
throughput calculator finance show

00:21:28,960 --> 00:21:33,039
a little bit better performance and

00:21:30,960 --> 00:21:35,840
serium for most m2 here

00:21:33,039 --> 00:21:36,640
but this ipi pvxlan overlay entirely

00:21:35,840 --> 00:21:38,640
enabled

00:21:36,640 --> 00:21:40,159
the large m2 size the throughput

00:21:38,640 --> 00:21:44,960
bandwidth their throughput

00:21:40,159 --> 00:21:47,600
performance is better uh

00:21:44,960 --> 00:21:48,799
the overlap based overly tallow

00:21:47,600 --> 00:21:50,640
approaches

00:21:48,799 --> 00:21:53,520
and actually affects the performance

00:21:50,640 --> 00:21:56,559
either tcp or http performance march

00:21:53,520 --> 00:21:58,880
compared with direct direct routing

00:21:56,559 --> 00:22:00,640
and for http performance the calico and

00:21:58,880 --> 00:22:03,760
cdm shows much better performance or

00:22:00,640 --> 00:22:03,760
work for nano cni

00:22:04,799 --> 00:22:08,480
this is about our future work and which

00:22:07,039 --> 00:22:11,520
is um provisional

00:22:08,480 --> 00:22:12,000
uh for example we do more performance

00:22:11,520 --> 00:22:13,919
testing

00:22:12,000 --> 00:22:16,080
for supporting the senior features of

00:22:13,919 --> 00:22:17,039
cnns for example there could be proxy

00:22:16,080 --> 00:22:20,720
replacement

00:22:17,039 --> 00:22:22,640
with ebpf for cdmcni and encryption

00:22:20,720 --> 00:22:24,880
added cases for broad-to-port

00:22:22,640 --> 00:22:26,000
communication and the ebbf introduced

00:22:24,880 --> 00:22:30,240
the volcanic signal

00:22:26,000 --> 00:22:30,240
all things like that and

00:22:31,039 --> 00:22:39,520
here is my uh topic for this

00:22:34,720 --> 00:22:43,200
uh my slides for this topic yes

00:22:39,520 --> 00:22:43,200

YouTube URL: https://www.youtube.com/watch?v=solRbvR4wtg


