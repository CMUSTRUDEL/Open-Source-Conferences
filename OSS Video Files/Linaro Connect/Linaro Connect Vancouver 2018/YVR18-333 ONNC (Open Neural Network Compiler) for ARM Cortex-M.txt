Title: YVR18-333 ONNC (Open Neural Network Compiler) for ARM Cortex-M
Publication date: 2018-09-28
Playlist: Linaro Connect Vancouver 2018
Description: 
	The Open Neural Network Compiler (ONNC) project aims to provide a compiler to connect Open Neural Network Exchange Format (ONNX) to every deep learning accelerator (DLA). ONNX is a standard format for representing deep learning models that enables models to be correctly transferred between frameworks, like caffe, CNTK, mxnet, pytorch and TensorFlow. ONNX guarantees interoperability between frameworks, however, the industry still needs a backer to guarantee executability between DLAs - to ensure every DLA can execute ONNX models correctly.

ONNC is such a backer for DLA vendors. It is a kind of cross compiler that transforms ONNX models into binary machine code of DLAs.
Every DLA has its own unique and delicate design in its memory for fast data movement. A compiler must provide sufficient flexibility to handle with the wide range of varieties. ONNC leverages the IR design of ONNX and provides rich and effective algorithms to eliminate overhead of data movement. And the best is that DLA vendors can easily reuse these algorithms by just describing its own unique physical cost model. Skymizer hopes DLA vendors can be free from re-inventing these intricated optimization algorithms.

In this talk, we not only introduce ONNC framework, we will dive into ONNC internals. We will explain our plan to support uTensor backend for ARM Cortex-M and discuss some technical issues.
Captions: 
	00:00:02,110 --> 00:00:07,120
[Music]

00:00:08,200 --> 00:00:15,230
I'm really pleased to welcome Luba tank

00:00:12,650 --> 00:00:17,710
from sky miser I'm sure it would be a

00:00:15,230 --> 00:00:22,340
very interesting presentation we had

00:00:17,710 --> 00:00:24,019
some presentation in a few months ago in

00:00:22,340 --> 00:00:28,160
a conference called that was really

00:00:24,019 --> 00:00:30,769
exciting so yeah please how everyone I'm

00:00:28,160 --> 00:00:33,380
so glad to be here to share our open

00:00:30,769 --> 00:00:38,120
source project over and she oh and she's

00:00:33,380 --> 00:00:41,120
open your network liberal the OCO is the

00:00:38,120 --> 00:00:44,120
project or the couple projects try to

00:00:41,120 --> 00:00:47,300
connect every to8 learning as a writer

00:00:44,120 --> 00:00:50,510
to onyx file format and here is our

00:00:47,300 --> 00:00:55,460
website if you have internet welcome to

00:00:50,510 --> 00:00:58,100
visit okay many of us there are we

00:00:55,460 --> 00:01:00,590
already have a lot of AI compiler why

00:00:58,100 --> 00:01:02,960
you guys need to reinvent the wheel why

00:01:00,590 --> 00:01:06,680
you guys need to reinvent a new company

00:01:02,960 --> 00:01:11,840
here are some reasons the biggest reason

00:01:06,680 --> 00:01:13,850
is tragic compiler like a VM or GCC they

00:01:11,840 --> 00:01:16,670
are kind of single takechiyo compiled

00:01:13,850 --> 00:01:20,480
what that means that means if you are

00:01:16,670 --> 00:01:23,690
using GCC that you see of course is only

00:01:20,480 --> 00:01:27,590
produced really ensuring say in such an

00:01:23,690 --> 00:01:30,740
instructions but in AI systems we talk

00:01:27,590 --> 00:01:33,350
it on heterogeneous system that means we

00:01:30,740 --> 00:01:37,820
have multiple processing units in the

00:01:33,350 --> 00:01:40,520
same chip here example of our target

00:01:37,820 --> 00:01:48,050
renewal system in this system you will

00:01:40,520 --> 00:01:52,159
see it we may have we may have matrix

00:01:48,050 --> 00:01:55,210
operators that can calculate like CNN or

00:01:52,159 --> 00:01:58,190
convolution and sometimes we will have

00:01:55,210 --> 00:02:01,390
ailment wide operator this functional

00:01:58,190 --> 00:02:06,320
can calculate something like I owe you

00:02:01,390 --> 00:02:08,429
like so mess of mix and of course we all

00:02:06,320 --> 00:02:11,069
have one DSP Oh

00:02:08,429 --> 00:02:14,849
at least over some season they'll have

00:02:11,069 --> 00:02:17,400
they may have about four and you lost

00:02:14,849 --> 00:02:21,180
all sense you control data flow of a

00:02:17,400 --> 00:02:25,069
system and in the outside in the other

00:02:21,180 --> 00:02:29,159
of the PAI ciphers we may have the young

00:02:25,069 --> 00:02:35,310
in some system we may have contests code

00:02:29,159 --> 00:02:38,400
has a applicant processor so as uses in

00:02:35,310 --> 00:02:40,560
this system we have at least two so

00:02:38,400 --> 00:02:42,780
we're defined a component we have the

00:02:40,560 --> 00:02:45,870
outside became processor and the inside

00:02:42,780 --> 00:02:49,980
angel and there is some systems they

00:02:45,870 --> 00:02:52,680
were there Elmen wiser profanity also so

00:02:49,980 --> 00:02:55,560
we're divided that means you can rest on

00:02:52,680 --> 00:02:59,640
so well to control the behavior of the

00:02:55,560 --> 00:03:02,250
function unit so in the system and the

00:02:59,640 --> 00:03:05,190
many of our customers they are Isis

00:03:02,250 --> 00:03:08,099
their houses so they are very good at

00:03:05,190 --> 00:03:11,129
design matrix function unit they are

00:03:08,099 --> 00:03:13,019
very good at deciding among whites and

00:03:11,129 --> 00:03:15,950
non-whites from community and they are

00:03:13,019 --> 00:03:19,260
good and CalNet each components together

00:03:15,950 --> 00:03:21,510
but they are facing to the same problem

00:03:19,260 --> 00:03:25,019
facing on the same problem they don't

00:03:21,510 --> 00:03:28,260
know how to handle somewhere because

00:03:25,019 --> 00:03:30,180
today so we have to control three

00:03:28,260 --> 00:03:32,040
different kind of at least three

00:03:30,180 --> 00:03:34,079
different kind of assistance so

00:03:32,040 --> 00:03:36,180
difficult possessing unit and each

00:03:34,079 --> 00:03:39,810
person Union has its own unique

00:03:36,180 --> 00:03:45,870
insurance a educator ok now here is our

00:03:39,810 --> 00:03:48,209
solution in OMG we single a cistern is a

00:03:45,870 --> 00:03:51,090
heterogeneous system so the first

00:03:48,209 --> 00:03:54,660
problem is where and the when

00:03:51,090 --> 00:03:57,269
which component you is killed which kind

00:03:54,660 --> 00:03:59,790
of layer so taking this system for

00:03:57,269 --> 00:04:01,739
example we are solely assisting a three

00:03:59,790 --> 00:04:06,060
component the first is the general

00:04:01,739 --> 00:04:08,609
processor CPU and we have a DSP and we

00:04:06,060 --> 00:04:11,879
also have a do a now we are trying to

00:04:08,609 --> 00:04:14,849
run the commotion layer and now some

00:04:11,879 --> 00:04:19,380
will fight let the DSP is more cost

00:04:14,849 --> 00:04:20,790
effective than the CPU so this is pet

00:04:19,380 --> 00:04:22,830
TSE is

00:04:20,790 --> 00:04:26,100
veteran ship you to calculated a

00:04:22,830 --> 00:04:31,560
convolution what we'll do we'll prepare

00:04:26,100 --> 00:04:35,070
the data for the DSP and the port on the

00:04:31,560 --> 00:04:38,580
convolution to DSP okay the same story

00:04:35,070 --> 00:04:42,000
happen again now we find last do a is

00:04:38,580 --> 00:04:44,700
more cost effective than the DSP so

00:04:42,000 --> 00:04:47,790
we'll do the single team ization will

00:04:44,700 --> 00:04:51,240
try to put down the collusion to a ripe

00:04:47,790 --> 00:04:53,340
face we call this behavior composites

00:04:51,240 --> 00:04:56,460
peel the Train is borrowed from the

00:04:53,340 --> 00:04:59,880
cache coherence polical sometimes we'll

00:04:56,460 --> 00:05:03,210
say okay we gather commercial miss yes

00:04:59,880 --> 00:05:05,970
okay then here we borrow the thing idea

00:05:03,210 --> 00:05:09,570
we say we gather composite composite

00:05:05,970 --> 00:05:12,390
spiel we have to move on a convolution

00:05:09,570 --> 00:05:17,310
to the most code effective processing

00:05:12,390 --> 00:05:20,610
unit and if you use traditional currents

00:05:17,310 --> 00:05:21,240
tradition compared to do this is not too

00:05:20,610 --> 00:05:23,880
difficult

00:05:21,240 --> 00:05:27,330
most compiler already have some basic

00:05:23,880 --> 00:05:31,260
infrastructures so you can just rewrite

00:05:27,330 --> 00:05:34,920
a ovn to suppose that can't be real and

00:05:31,260 --> 00:05:38,610
the other case is likely it now we have

00:05:34,920 --> 00:05:43,020
a new to operator one coax and the other

00:05:38,610 --> 00:05:45,450
to Kauai and now we find less we find we

00:05:43,020 --> 00:05:49,500
don't have enough memory to calculate X

00:05:45,450 --> 00:05:54,540
how do we do for this case we will try

00:05:49,500 --> 00:05:58,500
to pull up the membrane need from do a

00:05:54,540 --> 00:06:02,430
to a DSP so we'll just borrow some

00:05:58,500 --> 00:06:05,100
airspace from the DSP then now our DOA

00:06:02,430 --> 00:06:08,910
has more memory space to calculate the

00:06:05,100 --> 00:06:11,670
other operators then after do a release

00:06:08,910 --> 00:06:14,700
enough my memories now we have an

00:06:11,670 --> 00:06:16,270
immersed base to calculate the Singapore

00:06:14,700 --> 00:06:19,000
it

00:06:16,270 --> 00:06:23,169
at this time we will try to store every

00:06:19,000 --> 00:06:26,889
data from move data from do TSP to do a

00:06:23,169 --> 00:06:29,500
and recalculate the X again we call this

00:06:26,889 --> 00:06:33,039
memories Bo that means we don't have

00:06:29,500 --> 00:06:35,590
enough memory insert in one position

00:06:33,039 --> 00:06:39,729
unit then we borrow memory from the

00:06:35,590 --> 00:06:43,479
other processing unit okay and this is

00:06:39,729 --> 00:06:46,090
the source and this behavior can deviate

00:06:43,479 --> 00:06:49,360
a lot of memory consumptions by

00:06:46,090 --> 00:06:52,090
combination but in combustion time and

00:06:49,360 --> 00:06:54,880
we call it behavior spiel actually miss

00:06:52,090 --> 00:06:57,310
Bo is far already having every combating

00:06:54,880 --> 00:06:59,650
work you can just revise a member

00:06:57,310 --> 00:07:01,659
rachaelh or locating thing work and the

00:06:59,650 --> 00:07:07,599
cattle of same behavior get the same

00:07:01,659 --> 00:07:10,710
function okay let's go for now if we are

00:07:07,599 --> 00:07:15,159
trying to calculate a new operator Z and

00:07:10,710 --> 00:07:18,190
take for example a Z maybe a softmax and

00:07:15,159 --> 00:07:21,639
then we know it's masa TOA mata ethic

00:07:18,190 --> 00:07:25,810
doesn't support thousands of also makes

00:07:21,639 --> 00:07:29,710
how do we do in this case we will try to

00:07:25,810 --> 00:07:32,949
find the processing unit who can suppose

00:07:29,710 --> 00:07:36,370
so max now we find ESP can calculate a

00:07:32,949 --> 00:07:41,259
sub so max then we will prepare data for

00:07:36,370 --> 00:07:45,520
the DSP and the LAN will move the

00:07:41,259 --> 00:07:49,780
operator to a right place we call this

00:07:45,520 --> 00:07:57,280
behavior is we call it is it's an

00:07:49,780 --> 00:08:00,759
appraiser speakers and that is what new

00:07:57,280 --> 00:08:03,550
in the compiled URI Jeju compiler we

00:08:00,759 --> 00:08:05,919
just try to move data from one memory

00:08:03,550 --> 00:08:09,460
system to the other memory system but

00:08:05,919 --> 00:08:12,729
today in the AI system we have two motor

00:08:09,460 --> 00:08:16,569
operator from one operating unit to the

00:08:12,729 --> 00:08:20,319
other personally unit let pushers push

00:08:16,569 --> 00:08:24,310
our compared with guys we have to almost

00:08:20,319 --> 00:08:28,100
reinvent all the algorithms to to make

00:08:24,310 --> 00:08:30,890
sure our compiler can compare its right

00:08:28,100 --> 00:08:35,500
and the operations Pio is one of the

00:08:30,890 --> 00:08:35,500
most difficult topic in the air compiler

00:08:35,560 --> 00:08:47,920
okay so another reason why we need to

00:08:42,760 --> 00:08:47,920
reinvent a compiler even a fear is let

00:08:48,580 --> 00:08:54,980
if you give us a convolution how many

00:08:52,010 --> 00:08:57,710
cuz cuz I call the community needs not

00:08:54,980 --> 00:09:00,920
depends on it so pickle it's only

00:08:57,710 --> 00:09:03,350
depends on the input matrix but of many

00:09:00,920 --> 00:09:05,780
income an algorithm like the laryngeal

00:09:03,350 --> 00:09:08,240
analysis or like memory or rotating

00:09:05,780 --> 00:09:11,870
Eloise's they have a basic assumption

00:09:08,240 --> 00:09:15,650
they just as soon every instruction has

00:09:11,870 --> 00:09:19,010
a fixed feature fixed physical features

00:09:15,650 --> 00:09:22,130
take for example if we just give a add

00:09:19,010 --> 00:09:24,320
up add instruction then we will say okay

00:09:22,130 --> 00:09:26,860
lady in social may take about two car

00:09:24,320 --> 00:09:29,150
cycles and take about three register

00:09:26,860 --> 00:09:35,300
almost all the physical features are

00:09:29,150 --> 00:09:38,090
fixed but in AI every layer has physical

00:09:35,300 --> 00:09:41,150
features of a layer is dependent on the

00:09:38,090 --> 00:09:44,870
operon not oh we call letter pushers

00:09:41,150 --> 00:09:49,700
need to or neutering then almost or

00:09:44,870 --> 00:09:51,770
everything again okay if we try to

00:09:49,700 --> 00:09:54,740
Romania with them what we can achieve

00:09:51,770 --> 00:09:59,750
here is some is free mental result we

00:09:54,740 --> 00:10:02,990
achieve and we can we can alleviate the

00:09:59,750 --> 00:10:05,960
memory consumption about three point

00:10:02,990 --> 00:10:10,910
seven seven times on average that means

00:10:05,960 --> 00:10:14,000
if you before atomization if a model if

00:10:10,910 --> 00:10:17,240
you need about 100 megabytes to run that

00:10:14,000 --> 00:10:21,460
model but after our optimization you

00:10:17,240 --> 00:10:25,160
main is just about 200 to denier about

00:10:21,460 --> 00:10:29,930
25 megabytes to run it and the for some

00:10:25,160 --> 00:10:32,120
popular model like Yolo v1 we can save

00:10:29,930 --> 00:10:35,710
memory concern you about almost 10 times

00:10:32,120 --> 00:10:39,240
that means you can save the memory from

00:10:35,710 --> 00:10:43,440
hundred megabytes to 10 megabytes there

00:10:39,240 --> 00:10:45,630
is a significant achievement of our

00:10:43,440 --> 00:10:47,850
combination now

00:10:45,630 --> 00:10:51,350
there's a one or biggest reason why we

00:10:47,850 --> 00:10:52,529
need to reinvent a new compiler yeah

00:10:51,350 --> 00:10:55,170
okay

00:10:52,529 --> 00:10:58,290
so oh and she is a compared to the

00:10:55,170 --> 00:11:00,950
polyhedra genius system how we support

00:10:58,290 --> 00:11:05,520
variants targeted bias in the same time

00:11:00,950 --> 00:11:08,670
here's our education we have a very

00:11:05,520 --> 00:11:11,459
special representation for each passing

00:11:08,670 --> 00:11:14,160
unit we'll call it corpo the idea is

00:11:11,459 --> 00:11:16,830
parallel from a ovn in Obion there is a

00:11:14,160 --> 00:11:21,149
string representation called triple so

00:11:16,830 --> 00:11:24,209
we just give in our system we call it

00:11:21,149 --> 00:11:27,149
corporal because we can discuss not only

00:11:24,209 --> 00:11:32,370
the hardware and so where we can also

00:11:27,149 --> 00:11:34,860
describe the tool we are using so the

00:11:32,370 --> 00:11:38,820
driver likely compiler individually just

00:11:34,860 --> 00:11:40,740
give us serious of a curveball then we

00:11:38,820 --> 00:11:45,180
can build a lot of different hardware

00:11:40,740 --> 00:11:49,140
tacky hardware and we will pack all the

00:11:45,180 --> 00:11:52,110
backend into one special case we call it

00:11:49,140 --> 00:11:56,130
platform and we will use platform to

00:11:52,110 --> 00:11:59,579
general many target specific pieces so

00:11:56,130 --> 00:12:02,370
I'll come back and do a lot over target

00:11:59,579 --> 00:12:06,180
specific algorithms this is our basic

00:12:02,370 --> 00:12:09,029
eradication I think I don't have too

00:12:06,180 --> 00:12:14,070
much time so I will just quickly go

00:12:09,029 --> 00:12:17,880
through the rest slice the basic idea of

00:12:14,070 --> 00:12:21,890
our combinations followed by this is

00:12:17,880 --> 00:12:26,070
this faces okay

00:12:21,890 --> 00:12:29,130
at the beginning we will read or an onyx

00:12:26,070 --> 00:12:32,610
file and the origin is fairest and

00:12:29,130 --> 00:12:35,790
general graph and the first phase we

00:12:32,610 --> 00:12:38,970
will separate that graph into many sub

00:12:35,790 --> 00:12:42,660
graphs we call this we call this path

00:12:38,970 --> 00:12:44,850
the tensor partition phase then F change

00:12:42,660 --> 00:12:47,870
the partition world we have many sub

00:12:44,850 --> 00:12:49,459
graph then we will try to find a

00:12:47,870 --> 00:12:51,499
topology

00:12:49,459 --> 00:12:55,490
such a topological sort for each stop

00:12:51,499 --> 00:12:58,819
graph we call this tensors instruction

00:12:55,490 --> 00:13:02,980
scheduling will find a la pesto order

00:12:58,819 --> 00:13:05,449
for each sub graph and when we have the

00:13:02,980 --> 00:13:07,790
order of which the graph will try to

00:13:05,449 --> 00:13:10,639
allocate some memory to each sub graph

00:13:07,790 --> 00:13:14,600
then finally world has to commit it

00:13:10,639 --> 00:13:18,470
means we will try to turn turn onyx IR

00:13:14,600 --> 00:13:22,399
to the machine instruction and here's

00:13:18,470 --> 00:13:25,100
the definition and is the transformation

00:13:22,399 --> 00:13:28,249
of the our intermediate representation

00:13:25,100 --> 00:13:32,059
in compartment algae in that we call

00:13:28,249 --> 00:13:34,999
intermediary changing IR so error

00:13:32,059 --> 00:13:37,850
beginning the IR is the earnings format

00:13:34,999 --> 00:13:45,170
and world has already it and turn it to

00:13:37,850 --> 00:13:50,420
the onyx G ship Ava's API then then

00:13:45,170 --> 00:13:54,350
every tensor in onyx ship our API is

00:13:50,420 --> 00:13:57,049
just a simple so we'll add a pro so we

00:13:54,350 --> 00:14:00,079
will try to do a face coat insulation

00:13:57,049 --> 00:14:03,709
that means we will try to turn on its

00:14:00,079 --> 00:14:06,679
lair to target specific operators and

00:14:03,709 --> 00:14:10,970
the next words had to do memory location

00:14:06,679 --> 00:14:15,049
that means now before memory location

00:14:10,970 --> 00:14:17,420
every cancer is simple then F the memory

00:14:15,049 --> 00:14:21,529
location we will try to turn a symbol to

00:14:17,420 --> 00:14:24,049
the real virtual edges and now we have a

00:14:21,529 --> 00:14:27,829
low Pico and we have our address the

00:14:24,049 --> 00:14:30,350
less faces have to come it will just

00:14:27,829 --> 00:14:35,240
generate on Michiko for each target

00:14:30,350 --> 00:14:37,939
devices and a layer to so-called - Pat

00:14:35,240 --> 00:14:41,299
face Previn face whines coat ends up

00:14:37,939 --> 00:14:43,939
addition they will try to separate the

00:14:41,299 --> 00:14:46,220
whole graph into sub graphs and the

00:14:43,939 --> 00:14:49,040
other cooperate scheduling news editor

00:14:46,220 --> 00:14:53,119
they will try to fire a sequence for the

00:14:49,040 --> 00:14:56,059
correct timing okay here are some code

00:14:53,119 --> 00:14:58,399
if we already familiar with the ovn then

00:14:56,059 --> 00:15:01,129
you'll find our interface is very very

00:14:58,399 --> 00:15:02,870
similar of yet but we do it from scratch

00:15:01,129 --> 00:15:05,750
so if you want to

00:15:02,870 --> 00:15:10,490
at a new phase in your hardware you just

00:15:05,750 --> 00:15:16,850
need to in kill in here past class and

00:15:10,490 --> 00:15:19,250
override some virtual functions and so

00:15:16,850 --> 00:15:22,580
far oh and she asleep

00:15:19,250 --> 00:15:26,720
only when I compile who has strong who

00:15:22,580 --> 00:15:32,230
can say he has strong pest manager in

00:15:26,720 --> 00:15:36,410
Ong in compile theory many pets and

00:15:32,230 --> 00:15:39,560
every pest pest may depend on the other

00:15:36,410 --> 00:15:42,710
pests so there are dependencies between

00:15:39,560 --> 00:15:45,400
places mostly all the other combined

00:15:42,710 --> 00:15:48,830
they don't have they don't have

00:15:45,400 --> 00:15:51,590
instrument to describe these panels

00:15:48,830 --> 00:15:54,950
between cases but in Ong we just

00:15:51,590 --> 00:15:58,490
leverage the thing idea from the OVA so

00:15:54,950 --> 00:16:02,660
you can generate code like list to

00:15:58,490 --> 00:16:07,880
describe the pesty may require pass a

00:16:02,660 --> 00:16:10,190
and the pest be okay and the one of the

00:16:07,880 --> 00:16:13,940
most special things in owning oh and

00:16:10,190 --> 00:16:17,200
she's led with support vertical I'll we

00:16:13,940 --> 00:16:21,620
know TV and less about Auto tuning and

00:16:17,200 --> 00:16:24,950
the in combat theory was a letter is a

00:16:21,620 --> 00:16:28,040
kite it's ready a combination that means

00:16:24,950 --> 00:16:31,820
we compile many many times in charge

00:16:28,040 --> 00:16:35,150
change parameters in every iteration and

00:16:31,820 --> 00:16:38,000
we naturally with support it's ready

00:16:35,150 --> 00:16:39,740
combination in our pest manager about

00:16:38,000 --> 00:16:46,640
our being dozens about such kind of

00:16:39,740 --> 00:16:54,320
behavior okay so for our customers for

00:16:46,640 --> 00:16:59,060
for a new do a if if if if idea already

00:16:54,320 --> 00:17:02,150
Caribbean support then in only in Ong we

00:16:59,060 --> 00:17:06,500
can connect the device directly we also

00:17:02,150 --> 00:17:09,290
we can because we can generate our

00:17:06,500 --> 00:17:13,199
vehicle directly so if we already have a

00:17:09,290 --> 00:17:16,529
V V n you have no porting ever on

00:17:13,199 --> 00:17:19,409
she but some for some devices for take

00:17:16,529 --> 00:17:22,409
for example all customer their devices

00:17:19,409 --> 00:17:26,369
only support like camp ruching and GNN

00:17:22,409 --> 00:17:29,669
so they cannot support by ovn then they

00:17:26,369 --> 00:17:32,279
need to write a new ownership again and

00:17:29,669 --> 00:17:35,460
to cut it all and she support so we can

00:17:32,279 --> 00:17:38,999
suppose no matter your device can

00:17:35,460 --> 00:17:42,749
support VN them or not then oh and she

00:17:38,999 --> 00:17:47,669
can support both kinds of purpose or

00:17:42,749 --> 00:17:52,609
being an ASIC okay here is our target

00:17:47,669 --> 00:17:56,820
device in the next release we will have

00:17:52,609 --> 00:18:02,549
x86 support by LVN and we are going to

00:17:56,820 --> 00:18:06,029
support s uncoded n series that includes

00:18:02,549 --> 00:18:10,080
micro tangible investable and the C&C

00:18:06,029 --> 00:18:13,549
support and we are going to the park in

00:18:10,080 --> 00:18:16,320
our system we have Tooting one suppo

00:18:13,549 --> 00:18:19,739
wanting try to support and video a so

00:18:16,320 --> 00:18:22,980
we'll cut a meteor a taking the end of

00:18:19,739 --> 00:18:26,190
this arc and October and we are

00:18:22,980 --> 00:18:31,649
reducible many Toa like women's sofa and

00:18:26,190 --> 00:18:36,179
sister yeah and the history here is here

00:18:31,649 --> 00:18:40,980
is something about how ong to support

00:18:36,179 --> 00:18:43,350
causes ends courtesan in custody under

00:18:40,980 --> 00:18:45,720
is an open source project called micro

00:18:43,350 --> 00:18:48,029
tensor micro tensor is a very

00:18:45,720 --> 00:18:50,940
interesting project if we just give him

00:18:48,029 --> 00:18:53,460
a tensor flow model then it will

00:18:50,940 --> 00:18:57,690
translate attend the pro model to she

00:18:53,460 --> 00:19:01,440
and the ship apart and the ong with

00:18:57,690 --> 00:19:04,919
child we offer the other pest to micro

00:19:01,440 --> 00:19:08,700
tensor so just you just you can use just

00:19:04,919 --> 00:19:11,399
onyx format then we will use ong and

00:19:08,700 --> 00:19:13,950
micro tensor will translate it to the

00:19:11,399 --> 00:19:16,409
sea and the shipper was published

00:19:13,950 --> 00:19:20,159
program and can run on sciences and

00:19:16,409 --> 00:19:24,530
embedded and now we orient is finish all

00:19:20,159 --> 00:19:27,410
linear scan and will we put some ever

00:19:24,530 --> 00:19:30,020
help my cotton setting to refactor in

00:19:27,410 --> 00:19:32,800
the assistance so we are going to have

00:19:30,020 --> 00:19:37,100
my presence again very soon

00:19:32,800 --> 00:19:40,370
yeah orange part is open so special and

00:19:37,100 --> 00:19:42,440
the progeny sizing in this URL so if you

00:19:40,370 --> 00:19:48,770
have internet welcome to visit our

00:19:42,440 --> 00:19:52,040
project and we just release point in

00:19:48,770 --> 00:19:54,560
nine point two this week and that we are

00:19:52,040 --> 00:19:57,770
going to raise point nine point three

00:19:54,560 --> 00:19:57,770
[Applause]

00:19:58,600 --> 00:20:04,490
the first of October

00:20:01,010 --> 00:20:07,490
here are a row map of our system in the

00:20:04,490 --> 00:20:10,730
next release will release our open

00:20:07,490 --> 00:20:14,000
source version of Exodus interpreter and

00:20:10,730 --> 00:20:17,360
the perform register perform means we

00:20:14,000 --> 00:20:21,110
may we start with about 18 years perform

00:20:17,360 --> 00:20:24,170
in the open source and in the next

00:20:21,110 --> 00:20:26,690
version we were suppose is a digit in

00:20:24,170 --> 00:20:30,410
the panda Panda means the Robo purdue's

00:20:26,690 --> 00:20:33,410
it's cutable file let the file can let's

00:20:30,410 --> 00:20:35,780
see for you it's kill that file if I was

00:20:33,410 --> 00:20:39,110
wrong just like my mother

00:20:35,780 --> 00:20:43,250
yeah and we're going to have a micro

00:20:39,110 --> 00:20:47,660
tense up again in inner first of all in

00:20:43,250 --> 00:20:50,210
a 1.0 version and in the next version in

00:20:47,660 --> 00:20:53,150
the end of October we're going to

00:20:50,210 --> 00:20:58,550
support and VD up again and for

00:20:53,150 --> 00:21:02,740
heterogeneous everything's okay this is

00:20:58,550 --> 00:21:02,740
lesser slide okay

00:21:03,850 --> 00:21:10,270
on she project you can visit the project

00:21:08,470 --> 00:21:13,900
in the open source and we put over

00:21:10,270 --> 00:21:17,110
everything on the github so if you have

00:21:13,900 --> 00:21:19,960
internet please give us a star with and

00:21:17,110 --> 00:21:28,110
any kind of elaboration of welcome thank

00:21:19,960 --> 00:21:33,040
everybody thank you Thank You Lou

00:21:28,110 --> 00:21:33,760
first question reality ask the first

00:21:33,040 --> 00:21:38,410
question

00:21:33,760 --> 00:21:42,670
so for for the backend support and on on

00:21:38,410 --> 00:21:46,900
ik so I see that and for GPU support you

00:21:42,670 --> 00:21:49,810
are leveraging a VM right but in mobile

00:21:46,900 --> 00:21:53,050
space for example for Molly as I know

00:21:49,810 --> 00:21:56,260
there is no area of VM support yeah so

00:21:53,050 --> 00:22:04,210
do you have some plan to add GPU pekka's

00:21:56,260 --> 00:22:09,400
GPU specific back-end yannick okay if I

00:22:04,210 --> 00:22:12,370
can have a speck of money so you said I

00:22:09,400 --> 00:22:17,260
believe we can just write a multipack

00:22:12,370 --> 00:22:21,550
end yeah but when I was an engineer in

00:22:17,260 --> 00:22:23,440
mediatek with I never say that I never

00:22:21,550 --> 00:22:30,130
see my spec we just use these like a

00:22:23,440 --> 00:22:32,620
library so have you considered targeting

00:22:30,130 --> 00:22:35,110
some of the intermediates like spare Vee

00:22:32,620 --> 00:22:38,050
as a way to to act get access to

00:22:35,110 --> 00:22:45,610
multiple GPUs or is that not a suitable

00:22:38,050 --> 00:22:47,530
representation okay about multiple GPIO

00:22:45,610 --> 00:22:49,200
many people I assume as the same

00:22:47,530 --> 00:22:52,360
question

00:22:49,200 --> 00:22:55,570
now they almost all customer they are

00:22:52,360 --> 00:22:59,110
trying they are trying to do like the

00:22:55,570 --> 00:23:01,780
variant system or some a better system

00:22:59,110 --> 00:23:05,240
so in their system they don't have a GPU

00:23:01,780 --> 00:23:08,990
so we put this

00:23:05,240 --> 00:23:11,900
we put GPU support in lateral row map

00:23:08,990 --> 00:23:18,490
and the first in this year will try to

00:23:11,900 --> 00:23:22,400
support NGO and a video way first but

00:23:18,490 --> 00:23:24,200
supportive supportable multiple review

00:23:22,400 --> 00:23:37,940
in the same time is really a big problem

00:23:24,200 --> 00:23:42,550
and I still don't know how to do that so

00:23:37,940 --> 00:23:47,270
I have two questions the first is for

00:23:42,550 --> 00:23:52,000
compounding to ASIC actually a very

00:23:47,270 --> 00:23:56,810
challenging to arrange the pipeline so

00:23:52,000 --> 00:24:01,310
do you manage their pipeline yourself or

00:23:56,810 --> 00:24:04,610
large other third party to do that

00:24:01,310 --> 00:24:07,580
sorry the second question is that so

00:24:04,610 --> 00:24:13,130
you mentioned the heterogeneous runtime

00:24:07,580 --> 00:24:17,090
so how do you decide which part you will

00:24:13,130 --> 00:24:20,390
now which device is the rubles based or

00:24:17,090 --> 00:24:23,470
you depend on your some kind of

00:24:20,390 --> 00:24:26,690
auto-tuning to do that so thank you

00:24:23,470 --> 00:24:39,230
that's a very good question and Delta

00:24:26,690 --> 00:24:43,070
Christian compassion we call it machine

00:24:39,230 --> 00:24:45,890
descriptor yeah so in all packing we

00:24:43,070 --> 00:24:49,910
have we don't have a huge budget Eclipse

00:24:45,890 --> 00:24:52,370
we just descriptive machine by one

00:24:49,910 --> 00:24:55,010
object we call target info and the other

00:24:52,370 --> 00:24:59,450
key imported memory for indicator info

00:24:55,010 --> 00:25:01,940
so when we request one request the

00:24:59,450 --> 00:25:05,510
physical features from the Pegeen will

00:25:01,940 --> 00:25:10,370
put the operator into true traversal

00:25:05,510 --> 00:25:14,810
although simple to get the cost of the

00:25:10,370 --> 00:25:18,950
operator and the same since we have the

00:25:14,810 --> 00:25:22,310
cost of each operator each presenting

00:25:18,950 --> 00:25:25,520
unit then the next problem is easy we

00:25:22,310 --> 00:25:28,220
can try to do some Katrina heat or

00:25:25,520 --> 00:25:32,330
Junius a reason like the came a coke

00:25:28,220 --> 00:25:36,320
some cost function to cutter ring each

00:25:32,330 --> 00:25:39,350
operator together and we do the cutting

00:25:36,320 --> 00:25:40,250
at Al Fateh face we call tensor

00:25:39,350 --> 00:25:47,020
partition

00:25:40,250 --> 00:25:47,020
yeah let's how we support

00:25:51,540 --> 00:25:57,870
I we're doing the the calculations to

00:25:56,130 --> 00:26:01,080
determine the time that it will take to

00:25:57,870 --> 00:26:04,050
migrate an operation to a different IP

00:26:01,080 --> 00:26:06,870
unit yes when you support dynamic

00:26:04,050 --> 00:26:08,700
frequency and voltage scaling or when

00:26:06,870 --> 00:26:10,530
you have power management and you don't

00:26:08,700 --> 00:26:12,360
know what the how do you model those

00:26:10,530 --> 00:26:13,470
things to be able to know how long it's

00:26:12,360 --> 00:26:16,770
actually going to take to do that

00:26:13,470 --> 00:26:27,720
migration we didn't think about devfs in

00:26:16,770 --> 00:26:30,630
the assistant now because we have a

00:26:27,720 --> 00:26:33,870
communication cost of a chopper computed

00:26:30,630 --> 00:26:37,680
person you need and computation cost of

00:26:33,870 --> 00:26:39,980
each person unit so we were the only

00:26:37,680 --> 00:26:44,190
thing we need to do is give a platform

00:26:39,980 --> 00:26:46,830
cost function then he will then we can

00:26:44,190 --> 00:26:49,740
automatically decide which operators you

00:26:46,830 --> 00:26:52,830
put on which kind of processing units

00:26:49,740 --> 00:27:00,330
but now we didn't support them in devfs

00:26:52,830 --> 00:27:03,890
so so far I have to say our team has no

00:27:00,330 --> 00:27:03,890
idea about how and ologies

00:27:04,310 --> 00:27:10,710
yeah thank you

00:27:07,670 --> 00:27:13,560
so with respect to your cost function is

00:27:10,710 --> 00:27:16,170
it on per operator basis or do you do it

00:27:13,560 --> 00:27:18,780
on the collection of operators so if you

00:27:16,170 --> 00:27:22,950
have one that could run on any one of

00:27:18,780 --> 00:27:27,810
those processing units you could make a

00:27:22,950 --> 00:27:31,530
decision to move it next to one in order

00:27:27,810 --> 00:27:35,790
to avoid the transition cost yes there

00:27:31,530 --> 00:27:38,550
are two dimension one dimensions we have

00:27:35,790 --> 00:27:41,460
to run the whole model as fast as

00:27:38,550 --> 00:27:44,730
possible the other dimension is why we

00:27:41,460 --> 00:27:48,180
have to idiot delineate the number of

00:27:44,730 --> 00:27:50,700
data movement so if their movement

00:27:48,180 --> 00:27:53,760
coaster is highly and calculated the

00:27:50,700 --> 00:27:56,610
same operator in the simple we was that

00:27:53,760 --> 00:27:59,830
we was how to avoid from move data out

00:27:56,610 --> 00:28:02,620
but doing sometimes

00:27:59,830 --> 00:28:06,850
take some meds for example sometimes

00:28:02,620 --> 00:28:09,370
when we approach two operators because

00:28:06,850 --> 00:28:12,370
that means this function is a person

00:28:09,370 --> 00:28:16,210
support is layer so the Casas become in

00:28:12,370 --> 00:28:19,539
Phineas big let's in this case we will

00:28:16,210 --> 00:28:23,049
move the operator to the other pausing

00:28:19,539 --> 00:28:24,909
units do you take power into

00:28:23,049 --> 00:28:29,380
consideration for your collagen because

00:28:24,909 --> 00:28:33,100
for compiler we don't have precise poor

00:28:29,380 --> 00:28:36,370
model so but by me by your help we can

00:28:33,100 --> 00:28:40,570
present for model yeah I believe for no

00:28:36,370 --> 00:28:43,870
no compiler has has Palma doing it right

00:28:40,570 --> 00:28:45,610
but I'm thinking more about the movement

00:28:43,870 --> 00:28:48,549
of memory between the two processors

00:28:45,610 --> 00:28:51,010
because that's typically a significant

00:28:48,549 --> 00:28:55,000
cost from a parent perspective yes and

00:28:51,010 --> 00:28:57,370
by the other property is a kind of

00:28:55,000 --> 00:29:02,440
np-complete problem so it's impossible

00:28:57,370 --> 00:29:06,340
to have an optimal solution but the same

00:29:02,440 --> 00:29:09,429
problem is very well known in the EDS in

00:29:06,340 --> 00:29:13,799
the idea area so we just borrow the

00:29:09,429 --> 00:29:13,799
personality algorithm from that area

00:29:16,230 --> 00:29:20,549
okay thanks

00:29:22,070 --> 00:29:25,230
thank you very much

00:29:23,610 --> 00:29:27,950
that was a very interesting session

00:29:25,230 --> 00:29:27,950
thank you

00:29:29,920 --> 00:29:34,929

YouTube URL: https://www.youtube.com/watch?v=-FuKZFfWIXo


