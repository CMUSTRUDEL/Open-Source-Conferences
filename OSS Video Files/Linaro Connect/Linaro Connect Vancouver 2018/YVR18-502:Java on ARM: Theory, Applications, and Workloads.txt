Title: YVR18-502:Java on ARM: Theory, Applications, and Workloads
Publication date: 2018-10-22
Playlist: Linaro Connect Vancouver 2018
Description: 
	Although ARM processors are almost always viewed as having been designed for the embedded market, several vendors are making a bet and building server CPUs that contend with Intel in cloud deployments. With the presence of the Java ARM port and a wide variety of applications in the Java ecosystem able to run on ARM CPUs, the real question becomes which workloads are best suited to the ARM servers niche and which metrics can be optimized for using ARM servers.

This presentation explores the status of Java and the Java ecosystem on ARM, together with the Java ARM port features and performance of specific workloads. Some focus is on the recent changes in the Java ARM port, which the speakerâ€™s company contributes to.
Captions: 
	00:00:02,050 --> 00:00:07,110
[Music]

00:00:08,600 --> 00:00:14,580
so let's begin

00:00:10,760 --> 00:00:20,339
aunt Michiko I work at company named

00:00:14,580 --> 00:00:25,230
Belle soft today it will be one more

00:00:20,339 --> 00:00:28,079
OpenJDK talk probably more generic and

00:00:25,230 --> 00:00:34,200
also focused to the work that we do

00:00:28,079 --> 00:00:37,760
about soft but not limited to it that's

00:00:34,200 --> 00:00:40,860
me I work at Bell South to have small

00:00:37,760 --> 00:00:42,630
OpenJDK team and previously we all work

00:00:40,860 --> 00:00:45,390
the Torico I've worked a performance

00:00:42,630 --> 00:00:49,460
team so that's what I'm continued to do

00:00:45,390 --> 00:00:53,400
now and Belle soft the service company

00:00:49,460 --> 00:00:55,680
we do arm stuff and we also release our

00:00:53,400 --> 00:01:00,150
own distribution of open JDK called

00:00:55,680 --> 00:01:03,140
America it's a de sica verified bundle

00:01:00,150 --> 00:01:10,249
of open JDK which is important I believe

00:01:03,140 --> 00:01:13,960
I'll mention it today so we'll discuss

00:01:10,249 --> 00:01:15,140
contributions in OpenJDK I especially

00:01:13,960 --> 00:01:18,149
[Music]

00:01:15,140 --> 00:01:21,329
remember well what happened for past

00:01:18,149 --> 00:01:28,009
year because it was not sold for long

00:01:21,329 --> 00:01:33,420
ago and how how the process goes and

00:01:28,009 --> 00:01:40,170
what do we struggle with and how it

00:01:33,420 --> 00:01:43,350
happens so interesting statistics which

00:01:40,170 --> 00:01:45,539
is of course always tricky because you

00:01:43,350 --> 00:01:50,429
cannot compare one thing to another

00:01:45,539 --> 00:01:51,329
directly which is what's interesting on

00:01:50,429 --> 00:01:53,850
this picture

00:01:51,329 --> 00:01:57,929
it's a statistics of contributions to

00:01:53,850 --> 00:02:02,600
OpenJDK for some time period like one

00:01:57,929 --> 00:02:05,920
year till this August

00:02:02,600 --> 00:02:10,670
what's interesting is how many companies

00:02:05,920 --> 00:02:15,500
contribute OpenJDK and particularly we

00:02:10,670 --> 00:02:20,510
have strong community in our space this

00:02:15,500 --> 00:02:23,630
was really warmly accepted on JDK

00:02:20,510 --> 00:02:32,000
committers workshop this year and it is

00:02:23,630 --> 00:02:35,450
good and the other flash back here is

00:02:32,000 --> 00:02:38,060
new release cadence because this is

00:02:35,450 --> 00:02:42,440
statistics for just one year but what

00:02:38,060 --> 00:02:49,670
happened for few past years GT key 8 was

00:02:42,440 --> 00:02:55,519
released in 2014 after few years of work

00:02:49,670 --> 00:03:00,350
and then three years later was gdk9 was

00:02:55,519 --> 00:03:03,850
released and just in a year it was 10 it

00:03:00,350 --> 00:03:07,130
was last year and we already

00:03:03,850 --> 00:03:12,410
participated in that release and now it

00:03:07,130 --> 00:03:15,830
starts speeding up and we are - the new

00:03:12,410 --> 00:03:18,890
GDK cadence which is six months so six

00:03:15,830 --> 00:03:23,709
months of development six months for

00:03:18,890 --> 00:03:30,980
support from Oracle engineers in open

00:03:23,709 --> 00:03:34,310
but it should be more long lasting

00:03:30,980 --> 00:03:36,920
support in general from other companies

00:03:34,310 --> 00:03:40,610
and from maybe from Oracle to for a long

00:03:36,920 --> 00:03:46,730
term releases long term support

00:03:40,610 --> 00:03:50,690
religious so for this past year it was

00:03:46,730 --> 00:03:56,320
JDK 11 which will be released this fall

00:03:50,690 --> 00:03:56,320
it's already in release candidate phase

00:04:00,349 --> 00:04:10,409
so if it talked about applications and

00:04:06,049 --> 00:04:14,040
some platform what's typical I don't

00:04:10,409 --> 00:04:17,570
know the clear answer I have some

00:04:14,040 --> 00:04:22,440
assumptions some experience of course

00:04:17,570 --> 00:04:29,300
Java had long embedded story so

00:04:22,440 --> 00:04:36,060
different flavors of Java but it was on

00:04:29,300 --> 00:04:37,919
32-bit arm for now we have more recent

00:04:36,060 --> 00:04:42,060
more powerful so-called platform

00:04:37,919 --> 00:04:44,550
versions but you still have choice

00:04:42,060 --> 00:04:49,849
sometimes which one to use for example

00:04:44,550 --> 00:04:58,400
in raspberry you can have both ice

00:04:49,849 --> 00:05:01,349
versions anything and you have typical

00:04:58,400 --> 00:05:06,080
assumptions and I do about what

00:05:01,349 --> 00:05:12,590
applications we can find on such devices

00:05:06,080 --> 00:05:15,830
like tiny user experience devices if

00:05:12,590 --> 00:05:20,039
probably gooeys you can press on button

00:05:15,830 --> 00:05:22,560
interactive touchscreen anything or you

00:05:20,039 --> 00:05:24,960
can collect data from sensors and send

00:05:22,560 --> 00:05:27,930
them to the cloud for example and in the

00:05:24,960 --> 00:05:30,659
cloud you can have some back-end except

00:05:27,930 --> 00:05:33,300
on those data or processing them as a

00:05:30,659 --> 00:05:38,880
big sets of data like big data or

00:05:33,300 --> 00:05:43,699
databases etc so that kinds of workloads

00:05:38,880 --> 00:05:48,440
are different and it's not always clear

00:05:43,699 --> 00:05:54,590
how these tasks are mapped to

00:05:48,440 --> 00:05:59,009
architectures right so you can have a 64

00:05:54,590 --> 00:06:02,550
device which does a good job and it's

00:05:59,009 --> 00:06:04,699
fine or you can make a gateway on a 32

00:06:02,550 --> 00:06:04,699
bit

00:06:08,190 --> 00:06:16,960
so we have some preferences and some

00:06:12,880 --> 00:06:22,200
story because we worked with km so I

00:06:16,960 --> 00:06:25,660
believe what we suppose here is that

00:06:22,200 --> 00:06:28,240
64-bit architecture is most suitable for

00:06:25,660 --> 00:06:34,570
back-end applications for big data of

00:06:28,240 --> 00:06:36,820
course and again we should recall the

00:06:34,570 --> 00:06:43,770
dates so at the time that we started

00:06:36,820 --> 00:06:43,770
after JDK 9 and working on JDK 10 and 11

00:06:44,850 --> 00:06:54,070
most recent hardware was not released

00:06:47,860 --> 00:06:57,400
yet and hopefully the Thunder axe was

00:06:54,070 --> 00:06:59,670
stable at that time but still the micro

00:06:57,400 --> 00:07:04,450
tech chure microarchitectures change and

00:06:59,670 --> 00:07:08,080
well we worked with what they have now

00:07:04,450 --> 00:07:13,720
we have better option from the other

00:07:08,080 --> 00:07:17,860
hand we have some typical devices

00:07:13,720 --> 00:07:22,720
so-called like raspberry and we make our

00:07:17,860 --> 00:07:27,550
own gel distribution just to be visible

00:07:22,720 --> 00:07:32,290
in the community we're really while this

00:07:27,550 --> 00:07:36,880
is a playmate project and the

00:07:32,290 --> 00:07:39,550
distribution is itself a TCK verified

00:07:36,880 --> 00:07:42,670
Java it has some specific modules in

00:07:39,550 --> 00:07:46,890
case of the grass berry working to

00:07:42,670 --> 00:07:50,560
worked with GUI to work if device IO so

00:07:46,890 --> 00:07:52,810
that are things that distinguish one

00:07:50,560 --> 00:07:56,530
Java from another some additional

00:07:52,810 --> 00:08:03,040
sources and we also release that even

00:07:56,530 --> 00:08:09,790
for AR 64 and even for Intel and maybe

00:08:03,040 --> 00:08:11,920
for Windows just stay tuned and

00:08:09,790 --> 00:08:14,050
basically then you for example get

00:08:11,920 --> 00:08:16,900
raspberry what do you get out of the box

00:08:14,050 --> 00:08:18,669
or what do you get out of the repos you

00:08:16,900 --> 00:08:22,960
get JDK 8

00:08:18,669 --> 00:08:27,310
which is definitely not the best choice

00:08:22,960 --> 00:08:35,469
from my perspective because as I said it

00:08:27,310 --> 00:08:37,899
was released it 2014 and it's well JDK

00:08:35,469 --> 00:08:41,019
11 is on the way it will be new LTS

00:08:37,899 --> 00:08:45,370
release dedicate support will last for

00:08:41,019 --> 00:08:53,320
it maybe for long but that's not

00:08:45,370 --> 00:08:57,430
something that developers want so as I

00:08:53,320 --> 00:09:00,519
said yeah we have liberec it's all

00:08:57,430 --> 00:09:03,660
described on some pages like release

00:09:00,519 --> 00:09:09,120
notes it's open sourced by the general

00:09:03,660 --> 00:09:14,290
licenses but if like OpenGL Oh JPL - and

00:09:09,120 --> 00:09:19,500
not viral in case of Java it works with

00:09:14,290 --> 00:09:24,570
some additional sources and 4 gdk9

00:09:19,500 --> 00:09:28,690
you've got bonuses like ability to split

00:09:24,570 --> 00:09:31,870
your application depend to cut off

00:09:28,690 --> 00:09:35,920
unnecessary dependencies inside JDK to

00:09:31,870 --> 00:09:39,940
minimize your deployment and we went

00:09:35,920 --> 00:09:44,100
even further because in general open JDK

00:09:39,940 --> 00:09:47,500
has a notions of client and minimal VM

00:09:44,100 --> 00:09:51,279
which are smaller subsets of the entire

00:09:47,500 --> 00:09:56,709
runtime like you can strip off server

00:09:51,279 --> 00:09:58,510
compiler you can strip off most garbage

00:09:56,709 --> 00:10:02,440
collectors you don't need on embedded

00:09:58,510 --> 00:10:05,529
devices and to get your minimized very

00:10:02,440 --> 00:10:09,430
dense run time and the object so you can

00:10:05,529 --> 00:10:11,290
strip off the part of dependencies from

00:10:09,430 --> 00:10:18,370
the core library that you don't need

00:10:11,290 --> 00:10:21,839
again that's important sometimes and to

00:10:18,370 --> 00:10:25,779
support that it required some work in

00:10:21,839 --> 00:10:27,940
open JDK space because some things were

00:10:25,779 --> 00:10:35,330
just like broken

00:10:27,940 --> 00:10:39,530
that's essential so when they started to

00:10:35,330 --> 00:10:46,640
work we immediately started with 64-bit

00:10:39,530 --> 00:10:50,690
arm and initially we were new to the

00:10:46,640 --> 00:10:53,450
architecture so we had not just a

00:10:50,690 --> 00:10:56,870
perspective of JDK developer but also

00:10:53,450 --> 00:10:59,540
perspective of the user it was good that

00:10:56,870 --> 00:11:05,660
they had the hardware because at the

00:10:59,540 --> 00:11:08,060
times then it started JDK developers

00:11:05,660 --> 00:11:12,830
sometimes had no real hardware to test

00:11:08,060 --> 00:11:16,640
on so from a consumer perspective you

00:11:12,830 --> 00:11:19,910
can buy something from one more vendor

00:11:16,640 --> 00:11:25,400
which is not Intel North Oracle or not

00:11:19,910 --> 00:11:32,110
HP someone else who can offer probably

00:11:25,400 --> 00:11:37,090
chip a solution more power effective as

00:11:32,110 --> 00:11:42,740
performant as your current option may be

00:11:37,090 --> 00:11:48,440
so from a GDK perspective the another I

00:11:42,740 --> 00:11:52,720
say is another I see it requires a lot

00:11:48,440 --> 00:11:55,690
of work to realize what's the difference

00:11:52,720 --> 00:11:59,020
what I key points of change and things

00:11:55,690 --> 00:12:02,270
maybe sometimes that requires generic

00:11:59,020 --> 00:12:05,990
fixes to allow different behavior in

00:12:02,270 --> 00:12:08,780
certain places and it is so for all

00:12:05,990 --> 00:12:12,320
parts of open JDK and related projects

00:12:08,780 --> 00:12:16,780
like me now for garbage collection for

00:12:12,320 --> 00:12:16,780
growl that's that's true

00:12:18,440 --> 00:12:29,930
yeah and when someone chooses an option

00:12:25,819 --> 00:12:31,959
to deploy his application like it maybe

00:12:29,930 --> 00:12:36,579
a web server or something

00:12:31,959 --> 00:12:39,560
what what good is Java for here is that

00:12:36,579 --> 00:12:41,629
you can easily transfer your already

00:12:39,560 --> 00:12:45,079
made application from another platform

00:12:41,629 --> 00:12:47,689
it's just probably a jar or some other

00:12:45,079 --> 00:12:49,790
kind of archive and you just pick

00:12:47,689 --> 00:12:50,269
another JVM you may pick another

00:12:49,790 --> 00:12:52,850
platform

00:12:50,269 --> 00:12:57,259
it just works it must work because it's

00:12:52,850 --> 00:13:01,069
Java but will you do it as a customer

00:12:57,259 --> 00:13:05,360
only if it works fine if it satisfies

00:13:01,069 --> 00:13:10,810
your SLA agreements your quality tests

00:13:05,360 --> 00:13:13,759
etc and then we talk about pricing and

00:13:10,810 --> 00:13:19,970
some competition yeah the performance

00:13:13,759 --> 00:13:27,529
should be very good and we work in this

00:13:19,970 --> 00:13:35,300
area as I said we target primarily KVM

00:13:27,529 --> 00:13:41,829
course but we also really carefully test

00:13:35,300 --> 00:13:47,420
on cortex course and we have our own

00:13:41,829 --> 00:13:52,910
small web of machines maybe not as big

00:13:47,420 --> 00:13:58,250
as some one if you have what we do we

00:13:52,910 --> 00:14:00,889
also use public clouds like packet which

00:13:58,250 --> 00:14:05,120
offers bare-metal servers and they have

00:14:00,889 --> 00:14:07,269
tender machines for us so that's pretty

00:14:05,120 --> 00:14:07,269
straightforward

00:14:10,340 --> 00:14:22,290
so what is Java in general it's an

00:14:14,220 --> 00:14:26,940
ecosystem not just well formerly it's

00:14:22,290 --> 00:14:28,830
just two specifications right but at

00:14:26,940 --> 00:14:29,970
this time they have implementations

00:14:28,830 --> 00:14:35,060
different ones

00:14:29,970 --> 00:14:41,070
it may be open JDK there are others like

00:14:35,060 --> 00:14:44,640
for example IBM based

00:14:41,070 --> 00:14:55,350
j9 based versions of Java or it may be

00:14:44,640 --> 00:15:01,230
growl am growl growl images for now it's

00:14:55,350 --> 00:15:03,840
Linux but things may change and we are

00:15:01,230 --> 00:15:08,490
working in hotspot space in open JDK

00:15:03,840 --> 00:15:12,240
hotspot and it has its own Cabot's for

00:15:08,490 --> 00:15:16,010
example has ports what support is all

00:15:12,240 --> 00:15:20,100
specific for example CPU specific stuff

00:15:16,010 --> 00:15:22,980
related to one architecture in all areas

00:15:20,100 --> 00:15:29,370
like runtime garbage collection JIT

00:15:22,980 --> 00:15:31,230
compilation interpretation everything it

00:15:29,370 --> 00:15:33,960
may be separated and implemented in

00:15:31,230 --> 00:15:37,170
different ways and it is deployment it

00:15:33,960 --> 00:15:40,920
is implemented in different ways for arm

00:15:37,170 --> 00:15:44,910
for example there is unified port for

00:15:40,920 --> 00:15:49,410
arm 52 and arm 64 from Oracle open

00:15:44,910 --> 00:15:53,750
source now there is special port for

00:15:49,410 --> 00:15:57,990
hours 32 from hazel I believe existing

00:15:53,750 --> 00:16:05,210
in a separate tree and there is a are 64

00:15:57,990 --> 00:16:10,620
port in mainline and there is also growl

00:16:05,210 --> 00:16:14,870
which is a standalone one because it's

00:16:10,620 --> 00:16:19,110
not a part of open JDK as a project but

00:16:14,870 --> 00:16:20,200
it is a part of open JDK of hotspot as a

00:16:19,110 --> 00:16:23,829
source

00:16:20,200 --> 00:16:27,970
that's kind of funny but really this

00:16:23,829 --> 00:16:34,060
this way of doing things it's been

00:16:27,970 --> 00:16:38,440
imported and bundled if openjdk so as I

00:16:34,060 --> 00:16:40,899
mentioned for 64-bit arm there are

00:16:38,440 --> 00:16:43,540
currently two ports in mainline the

00:16:40,899 --> 00:16:47,310
process is going the way that the first

00:16:43,540 --> 00:16:53,889
port will be decommissioned for our 64

00:16:47,310 --> 00:16:56,620
it will stay there for our 32 but we

00:16:53,889 --> 00:17:00,910
still have to support it because someone

00:16:56,620 --> 00:17:03,510
might build top and GDK built that port

00:17:00,910 --> 00:17:10,900
and use it for example someone who wants

00:17:03,510 --> 00:17:14,230
to try I don't know Java Island if Teddy

00:17:10,900 --> 00:17:19,510
k-8 flavor like it will be the same port

00:17:14,230 --> 00:17:23,890
but with some new features at least so

00:17:19,510 --> 00:17:28,840
we also spent some resources of keeping

00:17:23,890 --> 00:17:34,030
it clean so this is JDK 8

00:17:28,840 --> 00:17:36,940
if you look for bundles that this port

00:17:34,030 --> 00:17:39,280
that will be JDK 8 and if you look for

00:17:36,940 --> 00:17:45,549
the decay AIDS you'll find bundles to

00:17:39,280 --> 00:17:49,360
this port it won't be continued but at

00:17:45,549 --> 00:17:53,049
the time we started our work the

00:17:49,360 --> 00:17:55,660
situation is was like there are two

00:17:53,049 --> 00:17:57,330
ports they both exist they both open

00:17:55,660 --> 00:18:00,190
sourced they are both in mainline and

00:17:57,330 --> 00:18:02,980
that's what we have now so we have to

00:18:00,190 --> 00:18:04,809
compare we have to choose and we have to

00:18:02,980 --> 00:18:08,559
improve something the general notion

00:18:04,809 --> 00:18:11,860
already was that er 64-bit port will be

00:18:08,559 --> 00:18:17,980
the main main line so that was the

00:18:11,860 --> 00:18:19,660
consensus but the additional port is a

00:18:17,980 --> 00:18:22,929
source of interesting findings

00:18:19,660 --> 00:18:28,210
potentially so we analyzed what we had

00:18:22,929 --> 00:18:31,409
in that port what we had at Newport in

00:18:28,210 --> 00:18:33,760
our compilers what can they improve

00:18:31,409 --> 00:18:38,350
they've done some analysis

00:18:33,760 --> 00:18:41,230
we made few tables big ones one of

00:18:38,350 --> 00:18:47,130
low-hanging fruits was improvement of

00:18:41,230 --> 00:18:50,710
intrinsics so if we want to make better

00:18:47,130 --> 00:18:58,330
openjdk in terms of performance we can

00:18:50,710 --> 00:19:01,810
improve intrinsics we also had an option

00:18:58,330 --> 00:19:05,080
to test our work on the real hardware to

00:19:01,810 --> 00:19:08,620
verify the performance and we stand it

00:19:05,080 --> 00:19:14,220
on the shoulders of giants so a lot of

00:19:08,620 --> 00:19:17,980
companies contributed to the common good

00:19:14,220 --> 00:19:21,930
so at least we had stable hardware which

00:19:17,980 --> 00:19:24,130
was not true for not so long time ago

00:19:21,930 --> 00:19:26,490
especially for multi-threaded

00:19:24,130 --> 00:19:32,350
applications

00:19:26,490 --> 00:19:35,820
well things may be crashing and we had

00:19:32,350 --> 00:19:40,090
working operating systems pretty stable

00:19:35,820 --> 00:19:43,150
modern kernels with modern features did

00:19:40,090 --> 00:19:46,450
hardware counter support so then you do

00:19:43,150 --> 00:19:47,920
performance analysis of your code you

00:19:46,450 --> 00:19:50,710
typically need to understand what

00:19:47,920 --> 00:19:52,660
happens in CPU if it's CPU bound so you

00:19:50,710 --> 00:19:59,080
need performance counters and you need

00:19:52,660 --> 00:20:01,000
to realize what's hot in terms of events

00:19:59,080 --> 00:20:07,360
happen in CPU then you run your

00:20:01,000 --> 00:20:10,620
application your workload and we had

00:20:07,360 --> 00:20:14,050
some examples of really good work

00:20:10,620 --> 00:20:19,020
already have been done in open JDK in

00:20:14,050 --> 00:20:19,020
other areas that's really helpful

00:20:21,470 --> 00:20:33,159
so from for not a long time we went to

00:20:28,179 --> 00:20:38,899
the situation with many things available

00:20:33,159 --> 00:20:42,320
like for examples kevin ships its

00:20:38,899 --> 00:20:47,269
hardware and clusters are built from

00:20:42,320 --> 00:20:52,279
that that's very good situation i was

00:20:47,269 --> 00:20:55,789
blown up by all the details of post geek

00:20:52,279 --> 00:21:02,360
super computer just because it's lots of

00:20:55,789 --> 00:21:03,860
arm course sv super interconnect i know

00:21:02,360 --> 00:21:09,529
that's that's really mind-blowing

00:21:03,860 --> 00:21:12,379
and where's java and this space of

00:21:09,529 --> 00:21:14,620
course it's possible to see it as a big

00:21:12,379 --> 00:21:17,480
data processing as database i see

00:21:14,620 --> 00:21:21,970
everywhere in clusters of course in

00:21:17,480 --> 00:21:24,830
management if you round even some super

00:21:21,970 --> 00:21:27,350
handwritten assembly and see optimized

00:21:24,830 --> 00:21:30,710
native code on your supercomputers you

00:21:27,350 --> 00:21:34,340
probably managed all the stuff how work

00:21:30,710 --> 00:21:37,100
goes and it's a good space for java

00:21:34,340 --> 00:21:41,799
there there are solutions for managing

00:21:37,100 --> 00:21:45,679
like containers resources all the things

00:21:41,799 --> 00:21:49,429
of course it all may be deployed in some

00:21:45,679 --> 00:21:52,309
cloud it should be transparent probably

00:21:49,429 --> 00:21:56,149
to the user that you have where is used

00:21:52,309 --> 00:22:00,799
but again Java is wanted here because it

00:21:56,149 --> 00:22:05,720
allows to hide even more underlying

00:22:00,799 --> 00:22:12,110
details so important to have everything

00:22:05,720 --> 00:22:13,610
working and to have good performance and

00:22:12,110 --> 00:22:18,340
there are lot of applications we all

00:22:13,610 --> 00:22:22,789
know like works on arm a lot of stuff is

00:22:18,340 --> 00:22:26,160
Java containing stuff a lot of other

00:22:22,789 --> 00:22:29,440
things but a lots of Joe

00:22:26,160 --> 00:22:36,070
so we came to introducing job

00:22:29,440 --> 00:22:40,750
enhancement proposal of for improvement

00:22:36,070 --> 00:22:45,250
of intrinsics as a some general formula

00:22:40,750 --> 00:22:47,880
of doing things because that was the

00:22:45,250 --> 00:22:53,710
visible result of our work in open JDK

00:22:47,880 --> 00:22:57,070
for this period it's a joint job of

00:22:53,710 --> 00:22:59,860
bells often a home you can find it in

00:22:57,070 --> 00:23:02,890
open JDK in public space there's an

00:22:59,860 --> 00:23:05,320
obvious motivation of improving scores

00:23:02,890 --> 00:23:09,100
at least in micro benchmarks but in

00:23:05,320 --> 00:23:12,490
general also we notice that some things

00:23:09,100 --> 00:23:15,460
were missing and that weren't important

00:23:12,490 --> 00:23:19,140
parts from our perspective and some

00:23:15,460 --> 00:23:25,540
things to improve on particular hardware

00:23:19,140 --> 00:23:30,010
but hopefully in general so you know if

00:23:25,540 --> 00:23:33,790
it's visible fine I would say of this

00:23:30,010 --> 00:23:38,770
picture with really good results speed

00:23:33,790 --> 00:23:42,790
ups etc besides of all this free from my

00:23:38,770 --> 00:23:49,570
perspective major parts in this short

00:23:42,790 --> 00:23:52,870
list of successes first is a set of

00:23:49,570 --> 00:23:58,500
operations bulk operations with data

00:23:52,870 --> 00:24:06,100
chunks like for example calculating CRC

00:23:58,500 --> 00:24:11,860
or copying or comparing memory data

00:24:06,100 --> 00:24:15,370
important tasks related group of string

00:24:11,860 --> 00:24:19,230
separation where we can compare against

00:24:15,370 --> 00:24:19,230
strings find something

00:24:20,960 --> 00:24:28,160
strengths are also represented as memory

00:24:24,200 --> 00:24:30,860
chunks in the end but some details are

00:24:28,160 --> 00:24:33,830
different like you have to take into

00:24:30,860 --> 00:24:36,100
account distinct encoding etc so

00:24:33,830 --> 00:24:40,610
something specific is present and

00:24:36,100 --> 00:24:45,110
typical string lengths a bit different

00:24:40,610 --> 00:24:49,059
from typical array lengths for some

00:24:45,110 --> 00:24:54,410
other tasks and there is one more group

00:24:49,059 --> 00:24:57,170
which looks not related to data chunk

00:24:54,410 --> 00:25:01,840
processing it's a group of math

00:24:57,170 --> 00:25:01,840
functions which we continue to work on

00:25:02,650 --> 00:25:12,370
that's scalar malfunctions calculation

00:25:06,550 --> 00:25:15,440
but the interesting future work here

00:25:12,370 --> 00:25:18,200
is the work that's similar to work the

00:25:15,440 --> 00:25:21,710
pintle does the calculation of same

00:25:18,200 --> 00:25:26,270
things in parallel I mean like vector

00:25:21,710 --> 00:25:30,920
processing so when we calculate many

00:25:26,270 --> 00:25:34,360
scenes functions at row which is really

00:25:30,920 --> 00:25:36,830
loosely coupled with a vector API work

00:25:34,360 --> 00:25:39,530
so probably we will see some interesting

00:25:36,830 --> 00:25:42,650
results here in future so not just for

00:25:39,530 --> 00:25:48,080
scalar calculations but different things

00:25:42,650 --> 00:25:50,720
for vector calculations and yeah thanks

00:25:48,080 --> 00:25:53,660
for giant work on strings string

00:25:50,720 --> 00:25:55,520
intrinsic yeah those negatives was an

00:25:53,660 --> 00:26:01,130
interesting first experience of throwing

00:25:55,520 --> 00:26:01,809
into the open JDK space of 64 and it was

00:26:01,130 --> 00:26:06,530
a success

00:26:01,809 --> 00:26:09,429
that's really a good example of doing

00:26:06,530 --> 00:26:16,490
things together maybe not very rapidly

00:26:09,429 --> 00:26:20,090
but the high quality for quality it's

00:26:16,490 --> 00:26:22,850
hard to do complex things so we still

00:26:20,090 --> 00:26:26,960
continue to fix issues and math

00:26:22,850 --> 00:26:29,950
functions and math functions this is a

00:26:26,960 --> 00:26:34,010
really complex area because it includes

00:26:29,950 --> 00:26:40,160
heavy algorithmic optimizations not

00:26:34,010 --> 00:26:45,200
oh no microarchitecture tricks and other

00:26:40,160 --> 00:26:51,140
areas are more - well good crafting

00:26:45,200 --> 00:26:54,020
assembly code handcraft in it and we

00:26:51,140 --> 00:26:56,450
double check the performance in micro

00:26:54,020 --> 00:26:59,059
benchmarks on different micro

00:26:56,450 --> 00:27:02,740
architectures and also we try to find

00:26:59,059 --> 00:27:06,470
something bigger to check our

00:27:02,740 --> 00:27:12,500
modifications I will show one example

00:27:06,470 --> 00:27:20,299
here today and we'll discuss probably so

00:27:12,500 --> 00:27:22,700
what we what we use for evaluation we

00:27:20,299 --> 00:27:26,929
need to measure some scores so you need

00:27:22,700 --> 00:27:29,570
benchmarks for micro benchmarking we

00:27:26,929 --> 00:27:32,929
worked if Java and we also worked with

00:27:29,570 --> 00:27:36,350
CPUs so sometimes we have to make native

00:27:32,929 --> 00:27:40,820
benchmarks not surprisingly to check

00:27:36,350 --> 00:27:44,230
some patterns of assembly code directly

00:27:40,820 --> 00:27:47,929
not involved in any java stuff and

00:27:44,230 --> 00:27:51,620
sometimes we are fine just differ our

00:27:47,929 --> 00:27:56,660
benchmarks as a standard we use Java

00:27:51,620 --> 00:27:59,230
micro benchmarking harness jmh we also

00:27:56,660 --> 00:28:02,000
use widely accessible benchmarks

00:27:59,230 --> 00:28:07,400
industry ones like spec benchmarks and

00:28:02,000 --> 00:28:09,710
some bigger workloads like Hadoop

00:28:07,400 --> 00:28:16,580
benchmarks not just aerosol but also

00:28:09,710 --> 00:28:20,000
others what we like to do is to work

00:28:16,580 --> 00:28:21,679
with fixed bugs so we don't want to

00:28:20,000 --> 00:28:25,400
optimize what's already have been

00:28:21,679 --> 00:28:30,030
optimized in mainline so we run latest

00:28:25,400 --> 00:28:34,950
software on latest JDK

00:28:30,030 --> 00:28:37,080
we'll see an example here today and then

00:28:34,950 --> 00:28:39,060
you've worked if something bigger than

00:28:37,080 --> 00:28:41,040
the micro benchmark or even the micro

00:28:39,060 --> 00:28:43,920
benchmark you sometimes need to profile

00:28:41,040 --> 00:28:47,880
and it's better to profile so we need

00:28:43,920 --> 00:28:51,180
profilers and we briefly discussed

00:28:47,880 --> 00:28:55,380
yesterday what do we have here as an

00:28:51,180 --> 00:28:59,990
options of course it's better to be

00:28:55,380 --> 00:29:05,220
based on low-level things we have so we

00:28:59,990 --> 00:29:10,140
wish to collect Hardware events using

00:29:05,220 --> 00:29:16,800
system mechanisms like perv or BPF as an

00:29:10,140 --> 00:29:19,620
analysis aggregation stuff Java has its

00:29:16,800 --> 00:29:21,390
own specific it's not just a program but

00:29:19,620 --> 00:29:23,880
it's a program consisting of many parts

00:29:21,390 --> 00:29:27,420
so it has its own static a compiled

00:29:23,880 --> 00:29:34,320
runtime and even not statically these

00:29:27,420 --> 00:29:38,250
days it has JIT compilers and in the end

00:29:34,320 --> 00:29:40,470
and it also has of one compiler and in

00:29:38,250 --> 00:29:44,280
the end and the heads sorry it has also

00:29:40,470 --> 00:29:47,070
interpreter so your code then you write

00:29:44,280 --> 00:29:49,470
some Java method that's for you as a

00:29:47,070 --> 00:29:54,030
developer is just a method having a name

00:29:49,470 --> 00:29:57,420
have anybody and all the stuff it can

00:29:54,030 --> 00:30:00,770
end up executing in different states in

00:29:57,420 --> 00:30:03,630
really different states so there are

00:30:00,770 --> 00:30:04,920
they may be multiple versions of this

00:30:03,630 --> 00:30:10,530
method compiled that differentiate

00:30:04,920 --> 00:30:12,540
compilers if some profiling yeah it can

00:30:10,530 --> 00:30:14,910
be executed and interpreter so we won't

00:30:12,540 --> 00:30:18,000
see the code of your method you may see

00:30:14,910 --> 00:30:21,560
multiple codes some entry points many

00:30:18,000 --> 00:30:24,990
different things so for using an

00:30:21,560 --> 00:30:28,530
attribution of reason profilers and

00:30:24,990 --> 00:30:33,260
attribute in your methods you need some

00:30:28,530 --> 00:30:37,610
clue some hints for system tools to clue

00:30:33,260 --> 00:30:40,730
that pieces of profile information into

00:30:37,610 --> 00:30:44,870
some good

00:30:40,730 --> 00:30:48,049
information about your method so I'm

00:30:44,870 --> 00:30:52,100
describing bits for so long to say that

00:30:48,049 --> 00:30:55,610
there are special profilers for Java you

00:30:52,100 --> 00:30:57,650
can profile it in a very simple way from

00:30:55,610 --> 00:31:01,280
user perspective just looking at Java

00:30:57,650 --> 00:31:03,980
stacks you can in a standard way

00:31:01,280 --> 00:31:10,070
ask Java VM periodically and make stacks

00:31:03,980 --> 00:31:13,790
sampling to get the notion of what's the

00:31:10,070 --> 00:31:19,940
virtual machine relatively is doing in

00:31:13,790 --> 00:31:22,669
some moments there will be strong bias

00:31:19,940 --> 00:31:27,890
in the data and the sampling would be a

00:31:22,669 --> 00:31:30,700
very frequent so you'll be getting their

00:31:27,890 --> 00:31:34,640
approximate profile of your application

00:31:30,700 --> 00:31:37,850
there are other means there is an

00:31:34,640 --> 00:31:41,120
internal API in open hotspot code a

00:31:37,850 --> 00:31:43,940
single trace which gives you a better

00:31:41,120 --> 00:31:50,750
sampling options and it can be compiled

00:31:43,940 --> 00:31:55,460
combined with turf events it allows for

00:31:50,750 --> 00:31:58,190
example not to use any agent the

00:31:55,460 --> 00:32:02,390
application that will tell a perf about

00:31:58,190 --> 00:32:04,490
general methods so this approach lowers

00:32:02,390 --> 00:32:06,650
the overhead of profiling which is

00:32:04,490 --> 00:32:12,590
really important then you need to look

00:32:06,650 --> 00:32:14,750
at some tiny things and remember we

00:32:12,590 --> 00:32:16,760
worked if different versions of Java

00:32:14,750 --> 00:32:18,770
even for the same for example Java

00:32:16,760 --> 00:32:23,570
version on the same microarchitecture

00:32:18,770 --> 00:32:26,929
boom but we don't want to do so as I

00:32:23,570 --> 00:32:29,390
said we want to stick to a new version

00:32:26,929 --> 00:32:33,970
so we stick to one port but also made

00:32:29,390 --> 00:32:37,820
some work for JDK 8 so basically like

00:32:33,970 --> 00:32:41,600
two profilers one is called a sink

00:32:37,820 --> 00:32:47,000
profiler that does exactly what I said

00:32:41,600 --> 00:32:50,419
it combines performance even like you

00:32:47,000 --> 00:32:54,590
know cache misses for example or page

00:32:50,419 --> 00:33:00,019
faults and basically of course CPU spent

00:32:54,590 --> 00:33:03,230
and Java information what methods were

00:33:00,019 --> 00:33:10,070
executed and the other thing is a

00:33:03,230 --> 00:33:13,580
built-in mechanism released it's been

00:33:10,070 --> 00:33:16,129
released now and JDK 11 as an open

00:33:13,580 --> 00:33:17,779
source it has been released for x86 in

00:33:16,129 --> 00:33:20,690
Java 8 and it's called Java flight

00:33:17,779 --> 00:33:22,100
recorder and there's a tool for working

00:33:20,690 --> 00:33:25,159
the search information which is called

00:33:22,100 --> 00:33:28,399
Java Mission Control so Java flight

00:33:25,159 --> 00:33:31,309
recorder records internal events from

00:33:28,399 --> 00:33:35,269
the virtual machine from some places in

00:33:31,309 --> 00:33:38,899
an efficient way with low overhead in

00:33:35,269 --> 00:33:45,679
some chunks that can be transferred over

00:33:38,899 --> 00:33:49,519
the network or store it into disk so the

00:33:45,679 --> 00:33:52,850
benefit of flat recorder is ability to

00:33:49,519 --> 00:33:56,450
use Mission Control and to use also an

00:33:52,850 --> 00:34:02,529
official API for doing stuff and a

00:33:56,450 --> 00:34:06,799
cross-platform way so we participated in

00:34:02,529 --> 00:34:12,470
fixing both for the platform for support

00:34:06,799 --> 00:34:14,869
and we wish to use them ourselves that

00:34:12,470 --> 00:34:20,629
was an important motivation for doing

00:34:14,869 --> 00:34:22,879
this so as I said icing profiler it's an

00:34:20,629 --> 00:34:29,679
open-source tool if you need sound fixes

00:34:22,879 --> 00:34:33,169
please do them it's free it's up to date

00:34:29,679 --> 00:34:37,240
so it's works it works with recent

00:34:33,169 --> 00:34:43,280
version of Java which will be Java 11

00:34:37,240 --> 00:34:47,200
and also from it works from nine up to

00:34:43,280 --> 00:34:47,200
11 and also works itself

00:34:48,080 --> 00:34:54,410
so here are fixes were made some general

00:34:51,260 --> 00:34:59,180
support and some specific cpu specific

00:34:54,410 --> 00:35:02,990
support $14.99 for thunder x2 set bill

00:34:59,180 --> 00:35:07,310
here is that this tool won't work if JDK

00:35:02,990 --> 00:35:09,320
8 you'll need something else also we

00:35:07,310 --> 00:35:13,430
discovered that currently doesn't work

00:35:09,320 --> 00:35:15,070
if you involve a UT code so then you

00:35:13,430 --> 00:35:20,410
step on energy frame your hotspot

00:35:15,070 --> 00:35:20,410
crushes which is something to fix

00:35:21,340 --> 00:35:26,840
so let's look how we improved at least

00:35:24,890 --> 00:35:32,390
something and how we measured that using

00:35:26,840 --> 00:35:37,310
the tools as an example let's look at

00:35:32,390 --> 00:35:43,490
CRC calculation the quite an essential

00:35:37,310 --> 00:35:47,180
task in Java it's declared in the

00:35:43,490 --> 00:35:52,730
standard API as an implementation of

00:35:47,180 --> 00:35:56,230
Java checksum interface there are for

00:35:52,730 --> 00:36:00,020
example two different CRC check sums

00:35:56,230 --> 00:36:03,520
available for quite a long time and

00:36:00,020 --> 00:36:07,220
there are different ways of

00:36:03,520 --> 00:36:10,580
implementation for such things in open

00:36:07,220 --> 00:36:17,390
JDK so you can stick to Java based

00:36:10,580 --> 00:36:19,640
implementation that's possible you can

00:36:17,390 --> 00:36:23,570
have class library where you have normal

00:36:19,640 --> 00:36:26,630
class and it's just it can contain Java

00:36:23,570 --> 00:36:29,210
code and it will be compiled or not

00:36:26,630 --> 00:36:37,150
compile to just execute it as any other

00:36:29,210 --> 00:36:40,490
Java code you can also have an intrinsic

00:36:37,150 --> 00:36:46,970
some native code that will replace in

00:36:40,490 --> 00:36:48,800
some cases your java method instantly so

00:36:46,970 --> 00:36:51,230
we won't need for example to JIT compile

00:36:48,800 --> 00:36:55,460
it to get better performance it will

00:36:51,230 --> 00:36:59,200
just glue some piece of native code and

00:36:55,460 --> 00:37:03,370
the hot spot of your application

00:36:59,200 --> 00:37:06,190
or make a call to stop so this native

00:37:03,370 --> 00:37:09,340
replacement can be written for example

00:37:06,190 --> 00:37:13,570
in C and there is optimized statically

00:37:09,340 --> 00:37:15,850
linked library called if dilla bam or it

00:37:13,570 --> 00:37:18,910
can be implemented in C or macro

00:37:15,850 --> 00:37:25,060
assembly inside the hotspot in the

00:37:18,910 --> 00:37:28,540
runtime part or acapella part so there

00:37:25,060 --> 00:37:33,010
are different options where we started

00:37:28,540 --> 00:37:35,620
our work the first one in a are 64 port

00:37:33,010 --> 00:37:42,520
there already was very good

00:37:35,620 --> 00:37:48,640
implementation from the narrow so we had

00:37:42,520 --> 00:37:52,330
to look at this from multiple sites even

00:37:48,640 --> 00:37:55,780
there few implementations were available

00:37:52,330 --> 00:37:58,600
and there are possible options there are

00:37:55,780 --> 00:38:02,880
algorithmic options and instruction set

00:37:58,600 --> 00:38:06,450
options so at least you have subsets of

00:38:02,880 --> 00:38:09,190
instructions like neon instructions

00:38:06,450 --> 00:38:16,270
specialized instructions what we

00:38:09,190 --> 00:38:18,300
consider available but not always so how

00:38:16,270 --> 00:38:22,660
does it works and where it's applicable

00:38:18,300 --> 00:38:28,480
as I said it's a widely well known tasks

00:38:22,660 --> 00:38:30,910
of checksum calculations and it's widely

00:38:28,480 --> 00:38:34,860
used of course it's an integrity check

00:38:30,910 --> 00:38:38,880
thing and if you look at many major

00:38:34,860 --> 00:38:42,790
products and technologies you'll see a

00:38:38,880 --> 00:38:45,160
wide adoption of this but how its

00:38:42,790 --> 00:38:46,020
implemented how it's used how to

00:38:45,160 --> 00:38:49,560
calculate it

00:38:46,020 --> 00:38:56,440
that's for example look at HDFS and

00:38:49,560 --> 00:38:58,960
Hadoop core will see that checksums

00:38:56,440 --> 00:39:01,630
typically calculated on block size of

00:38:58,960 --> 00:39:07,810
half a kilobyte that's the default and

00:39:01,630 --> 00:39:11,110
it's really rarely modified it

00:39:07,810 --> 00:39:15,100
there is already a bigger chunk from

00:39:11,110 --> 00:39:18,280
which we took pieces and calculate

00:39:15,100 --> 00:39:20,560
checks on for each piece there are some

00:39:18,280 --> 00:39:23,140
default checksum which is also important

00:39:20,560 --> 00:39:25,750
and it's important to know which default

00:39:23,140 --> 00:39:28,350
to offer on the platform because this

00:39:25,750 --> 00:39:32,490
default of course was selected for Intel

00:39:28,350 --> 00:39:36,990
which may be not true for any arm

00:39:32,490 --> 00:39:41,830
microarchitecture it's an option and

00:39:36,990 --> 00:39:43,300
surprisingly a lot of such products and

00:39:41,830 --> 00:39:45,160
technologies have their own

00:39:43,300 --> 00:39:47,710
implementation and there's a long

00:39:45,160 --> 00:39:49,510
history of modifications like we are

00:39:47,710 --> 00:39:51,910
going to implement some checks I mean

00:39:49,510 --> 00:39:55,090
okay here's the code snippet from

00:39:51,910 --> 00:39:57,760
somewhere it works okay then after a few

00:39:55,090 --> 00:40:02,110
months oh it doesn't work we'll fix it

00:39:57,760 --> 00:40:04,510
and a few months ago oh it does work

00:40:02,110 --> 00:40:07,810
well I will improve it and then again it

00:40:04,510 --> 00:40:12,940
just contains some error and again and

00:40:07,810 --> 00:40:16,960
again and of course in JDK code there is

00:40:12,940 --> 00:40:21,850
also such history but it's the one and

00:40:16,960 --> 00:40:26,170
major place of having such functions so

00:40:21,850 --> 00:40:28,750
it's better probably to use close

00:40:26,170 --> 00:40:34,180
library one but will it be the best

00:40:28,750 --> 00:40:38,170
choice so if you look again at Hadoop

00:40:34,180 --> 00:40:41,860
common it's an interesting example of

00:40:38,170 --> 00:40:47,730
technology because it's currently really

00:40:41,860 --> 00:40:53,560
heavily tied to JDK 8 I believe it will

00:40:47,730 --> 00:40:59,290
last be compatible on 8 for ages and it

00:40:53,560 --> 00:41:04,090
is true for other similar products so we

00:40:59,290 --> 00:41:06,040
have to deal with this in any case it

00:41:04,090 --> 00:41:09,310
has its own pure Java implementations

00:41:06,040 --> 00:41:14,190
and if you remember not all check sums

00:41:09,310 --> 00:41:18,180
are available at 8 now that's it

00:41:14,190 --> 00:41:24,330
but in a good case it uses for example

00:41:18,180 --> 00:41:27,090
for just crc32 nazi building classes and

00:41:24,330 --> 00:41:30,000
it also has an implementation in native

00:41:27,090 --> 00:41:34,620
library which may be loaded in case it

00:41:30,000 --> 00:41:36,360
presents Thank You Lynne ro for the

00:41:34,620 --> 00:41:40,110
native library implementation which is

00:41:36,360 --> 00:41:42,660
also good it also introduces a nice

00:41:40,110 --> 00:41:45,780
trick of independent calculations of

00:41:42,660 --> 00:41:50,240
multiple blocks so then you check your

00:41:45,780 --> 00:41:54,840
check sums you can independently load

00:41:50,240 --> 00:41:56,970
pieces of data to have better pipelining

00:41:54,840 --> 00:42:01,770
and less data dependencies so which is

00:41:56,970 --> 00:42:04,590
very good but if a user downloads like

00:42:01,770 --> 00:42:08,910
Hadoop distribution from the official

00:42:04,590 --> 00:42:12,440
site what will he get he'll get native

00:42:08,910 --> 00:42:18,270
library for x86 which won't load and

00:42:12,440 --> 00:42:23,730
he'll fall to giant annotation the only

00:42:18,270 --> 00:42:26,190
notice is there will be an output of in

00:42:23,730 --> 00:42:29,030
standard output saying that you're not

00:42:26,190 --> 00:42:31,590
using native library that that's okay

00:42:29,030 --> 00:42:36,750
but that's actually said because the

00:42:31,590 --> 00:42:44,550
performance will be bad so what

00:42:36,750 --> 00:42:47,340
benchmarked different versions for this

00:42:44,550 --> 00:42:50,060
intrinsic in open JDK we try at

00:42:47,340 --> 00:42:53,910
algorithmic optimizations the funny ones

00:42:50,060 --> 00:42:56,160
like the one similar to what Intel does

00:42:53,910 --> 00:43:03,630
like recombining

00:42:56,160 --> 00:43:06,750
parts of checksum for larger block and

00:43:03,630 --> 00:43:11,670
it's funny it's still slower than the

00:43:06,750 --> 00:43:13,770
one we cut we use J image and all the

00:43:11,670 --> 00:43:18,720
tools related to J much like peripheral

00:43:13,770 --> 00:43:21,030
filers so in Jim H you can easily write

00:43:18,720 --> 00:43:25,800
Java benchmarks like this and you have

00:43:21,030 --> 00:43:27,540
basically mesh mark method and all the

00:43:25,800 --> 00:43:31,740
other stuff harness will do for you

00:43:27,540 --> 00:43:37,080
it will trick JIT compilers in necessary

00:43:31,740 --> 00:43:40,590
places etc so basically see what's being

00:43:37,080 --> 00:43:42,840
benchmarked here it's really simple you

00:43:40,590 --> 00:43:45,110
just create a buffer and then you test

00:43:42,840 --> 00:43:48,210
the method you want to test

00:43:45,110 --> 00:43:55,790
so in this benchmark we initially

00:43:48,210 --> 00:43:58,680
applied some we initially made check

00:43:55,790 --> 00:44:02,850
about the default implementation on the

00:43:58,680 --> 00:44:05,610
interesting platforms and there are

00:44:02,850 --> 00:44:08,310
options of implementing this algorithm

00:44:05,610 --> 00:44:10,670
so specialites specialized instruction

00:44:08,310 --> 00:44:14,670
is the best option but not the only

00:44:10,670 --> 00:44:19,380
that's a mandatory check and you see how

00:44:14,670 --> 00:44:22,110
good is best option is we changed

00:44:19,380 --> 00:44:28,160
nothing for so long right we're just

00:44:22,110 --> 00:44:31,800
checking so now what about optimization

00:44:28,160 --> 00:44:34,980
our initial assumption about all that

00:44:31,800 --> 00:44:36,960
operations diff data blocks was will put

00:44:34,980 --> 00:44:39,390
prefetch in everywhere and it will help

00:44:36,960 --> 00:44:44,550
it's so good to have different kinds of

00:44:39,390 --> 00:44:47,310
prefetching unarmed it's so rich it

00:44:44,550 --> 00:44:50,280
really helps somewhere for example you

00:44:47,310 --> 00:44:54,660
see that if he put profession it helps

00:44:50,280 --> 00:44:58,020
well here but does it make sense not at

00:44:54,660 --> 00:45:00,090
all because you have to be in a

00:44:58,020 --> 00:45:05,070
situation then you calculate exam of a

00:45:00,090 --> 00:45:09,150
single melting megabytes block maybe

00:45:05,070 --> 00:45:11,340
sometimes you are but do really need to

00:45:09,150 --> 00:45:13,460
optimize it that way and lose the

00:45:11,340 --> 00:45:17,700
performance in really important cases

00:45:13,460 --> 00:45:22,050
like losing 4% in the middle of this

00:45:17,700 --> 00:45:24,780
plot so it's a speed of checksum

00:45:22,050 --> 00:45:28,790
calculation hires better and this it's a

00:45:24,780 --> 00:45:32,600
size of block and bytes on mega bytes it

00:45:28,790 --> 00:45:32,600
it's not so important

00:45:34,710 --> 00:45:41,550
and the speed of observed was only for

00:45:38,850 --> 00:45:45,870
one micro architecture which doesn't

00:45:41,550 --> 00:45:48,200
have hardware prefetcher surprised not

00:45:45,870 --> 00:45:48,200
really

00:45:48,750 --> 00:45:56,420
maybe the benchmark is wrong so we made

00:45:51,600 --> 00:46:00,000
another ones like for example we can

00:45:56,420 --> 00:46:02,610
work some larger buffer makino copying

00:46:00,000 --> 00:46:06,240
and update to check some doesn't make

00:46:02,610 --> 00:46:10,170
sense well not really it can be very

00:46:06,240 --> 00:46:12,350
good in improved but that's the wrong

00:46:10,170 --> 00:46:17,850
benchmark because it makes no sense and

00:46:12,350 --> 00:46:19,380
the sense here if you divide the larger

00:46:17,850 --> 00:46:21,630
buffer into smaller chunks then you

00:46:19,380 --> 00:46:24,150
probably do copy and then you in this

00:46:21,630 --> 00:46:26,070
situation of the first benchmark so we

00:46:24,150 --> 00:46:31,890
made additional benchmarks for copying

00:46:26,070 --> 00:46:34,650
situations anyway so what we started was

00:46:31,890 --> 00:46:37,710
a very good and nice looking look like

00:46:34,650 --> 00:46:39,980
this in the end I modified it just

00:46:37,710 --> 00:46:42,600
slightly after doing many experiments

00:46:39,980 --> 00:46:47,850
not changing the algorithm but just

00:46:42,600 --> 00:46:51,630
changing the details in the instruction

00:46:47,850 --> 00:46:55,680
instruction orchestration and then

00:46:51,630 --> 00:46:59,360
surprisingly gave good results so only

00:46:55,680 --> 00:47:03,620
well la smart microarchitectures I got

00:46:59,360 --> 00:47:06,540
good speed up immediately on more smart

00:47:03,620 --> 00:47:09,240
mark architectures the speed-up observed

00:47:06,540 --> 00:47:13,350
is well well we fully utilize your CPU

00:47:09,240 --> 00:47:17,790
but anyway and again we have to keep in

00:47:13,350 --> 00:47:21,920
mind the block size but that's not the

00:47:17,790 --> 00:47:27,110
only part then you have some native code

00:47:21,920 --> 00:47:29,880
it works only in certain scenarios and

00:47:27,110 --> 00:47:34,530
there is a scenario for big data for

00:47:29,880 --> 00:47:37,350
example when your container leaves not

00:47:34,530 --> 00:47:39,330
for so long for like seconds and the

00:47:37,350 --> 00:47:42,600
warm-up is really important there you

00:47:39,330 --> 00:47:47,160
have to get instant performance of such

00:47:42,600 --> 00:47:49,410
functions so also made fixes to like CY

00:47:47,160 --> 00:47:51,680
interpreter to use all the same code

00:47:49,410 --> 00:47:57,270
it's only it's also good for correctness

00:47:51,680 --> 00:48:01,710
but again this is not enough because

00:47:57,270 --> 00:48:05,190
openjdk has new compiler written in Java

00:48:01,710 --> 00:48:10,680
called growl and it has to use the same

00:48:05,190 --> 00:48:13,560
optimizations so the goal nowadays then

00:48:10,680 --> 00:48:16,820
you optimize something you have to

00:48:13,560 --> 00:48:19,050
optimize it in one more place in growl

00:48:16,820 --> 00:48:24,750
that's what we also do for stringing

00:48:19,050 --> 00:48:28,740
into a six and oh I see really it could

00:48:24,750 --> 00:48:32,790
work in growl right now and growl is

00:48:28,740 --> 00:48:34,890
available for x86 from Java 9 as an

00:48:32,790 --> 00:48:41,700
experimental option it's now available

00:48:34,890 --> 00:48:43,890
there just as an option in 11 and in 11

00:48:41,700 --> 00:48:47,460
it will be there for a are 64 and

00:48:43,890 --> 00:48:51,360
sometimes it even works which is really

00:48:47,460 --> 00:49:00,330
impressive also as a result of aeg work

00:48:51,360 --> 00:49:02,610
being done so some resolve to god we got

00:49:00,330 --> 00:49:05,760
an improvement released in hadoop not in

00:49:02,610 --> 00:49:09,840
java an improvement released in java so

00:49:05,760 --> 00:49:11,610
we can combine them compare the native

00:49:09,840 --> 00:49:14,190
library with pure jump limitation from

00:49:11,610 --> 00:49:17,370
hadoop and in big benchmarks like for

00:49:14,190 --> 00:49:20,970
example in terasort optionally using

00:49:17,370 --> 00:49:22,770
some harnesses like high bench and we do

00:49:20,970 --> 00:49:24,870
it on the most recent hadoop version

00:49:22,770 --> 00:49:26,910
because we change it with the most

00:49:24,870 --> 00:49:28,950
recent JDK version so we have to modify

00:49:26,910 --> 00:49:31,890
high bench to round it off and we do

00:49:28,950 --> 00:49:35,520
some young setup and we use profilers

00:49:31,890 --> 00:49:37,830
even on systems that are not CPU bound

00:49:35,520 --> 00:49:43,020
because we can get some many folders out

00:49:37,830 --> 00:49:46,500
there there are some tricks of using

00:49:43,020 --> 00:49:49,110
profilers like async profiler some brief

00:49:46,500 --> 00:49:51,350
information is here and then you get

00:49:49,110 --> 00:49:53,850
some flame graphs like this for example

00:49:51,350 --> 00:49:56,789
do you see any difference then patches

00:49:53,850 --> 00:50:00,039
apply it I don't

00:49:56,789 --> 00:50:03,640
but you can zoom and to study it more

00:50:00,039 --> 00:50:05,559
carefully so you can see the interesting

00:50:03,640 --> 00:50:09,609
method here in profiles and to find

00:50:05,559 --> 00:50:13,480
stacks that use it and even to see

00:50:09,609 --> 00:50:18,579
difference in samples and the CPU spent

00:50:13,480 --> 00:50:22,119
there there is a speculative estimate of

00:50:18,579 --> 00:50:27,400
improvement and the actual measurements

00:50:22,119 --> 00:50:31,380
that prove that it exists so then they

00:50:27,400 --> 00:50:35,470
also used of course the benchmarks that

00:50:31,380 --> 00:50:39,009
changed technology offers us so Hadoop

00:50:35,470 --> 00:50:41,200
Commons has its own benchmarking staff

00:50:39,009 --> 00:50:43,750
and they compared it on different

00:50:41,200 --> 00:50:47,589
platforms including x86 because we

00:50:43,750 --> 00:50:49,990
change common part this is also so for

00:50:47,589 --> 00:50:53,230
any optimizations made in common part

00:50:49,990 --> 00:50:56,309
for example in open JDK you have to look

00:50:53,230 --> 00:51:00,029
at x86 and backwards you have to checks

00:50:56,309 --> 00:51:03,759
x86 improvements on our platform

00:51:00,029 --> 00:51:07,509
sometimes the result is interesting like

00:51:03,759 --> 00:51:11,309
last week or two weeks ago there was an

00:51:07,509 --> 00:51:15,670
improvement for crypto staff for x86

00:51:11,309 --> 00:51:20,589
which shown the exactly same regression

00:51:15,670 --> 00:51:23,440
on arm and that seems to be a typical

00:51:20,589 --> 00:51:27,789
situation unfortunately so I have to

00:51:23,440 --> 00:51:29,289
deal with it so I made some comparisons

00:51:27,789 --> 00:51:32,200
maybe not so interesting so what's about

00:51:29,289 --> 00:51:36,519
flight recorder yes we also can use it

00:51:32,200 --> 00:51:39,269
if even such technologies as Hadoop and

00:51:36,519 --> 00:51:42,009
we can see basically the same things

00:51:39,269 --> 00:51:44,769
like then you look at the bigger

00:51:42,009 --> 00:51:46,839
perspective then you look at the

00:51:44,769 --> 00:51:48,430
processes perspective for JVM processes

00:51:46,839 --> 00:51:53,140
you see that there are processes of

00:51:48,430 --> 00:51:54,819
their lifetime and consume CPU they are

00:51:53,140 --> 00:51:58,329
mostly cold but the entire machine is

00:51:54,819 --> 00:52:02,200
pretty good utilized so you see maybe

00:51:58,329 --> 00:52:06,880
not so well the CPU utilization goes

00:52:02,200 --> 00:52:10,060
like up to 80% at some points but the

00:52:06,880 --> 00:52:12,670
lower part here not so clearly visible

00:52:10,060 --> 00:52:16,920
is the consumption of CPU for this

00:52:12,670 --> 00:52:20,020
particular process which we track so

00:52:16,920 --> 00:52:25,480
flight recorder here records information

00:52:20,020 --> 00:52:28,180
for this process we get information just

00:52:25,480 --> 00:52:30,790
from round one process and also for the

00:52:28,180 --> 00:52:36,510
entire machine so this the overall

00:52:30,790 --> 00:52:41,050
picture and we can have multi node

00:52:36,510 --> 00:52:45,430
things going on so if you look at node

00:52:41,050 --> 00:52:50,440
manager we'll see some great stripes

00:52:45,430 --> 00:52:53,110
here that correlate to south and that

00:52:50,440 --> 00:52:59,920
happens and it's managed by that node

00:52:53,110 --> 00:53:02,730
manager then you look at threads and if

00:52:59,920 --> 00:53:09,120
you look at data and other data node

00:53:02,730 --> 00:53:11,980
then will probably notice data transfers

00:53:09,120 --> 00:53:15,520
right even then we look at a single

00:53:11,980 --> 00:53:18,760
process but the interior mechanism of

00:53:15,520 --> 00:53:22,200
things going on reflects what happens

00:53:18,760 --> 00:53:27,700
with all the processes in the cluster

00:53:22,200 --> 00:53:31,110
and again if you look at just one for

00:53:27,700 --> 00:53:33,940
example MapReduce process will get

00:53:31,110 --> 00:53:39,040
basically the same information about hot

00:53:33,940 --> 00:53:41,320
methods but not the details and it's a

00:53:39,040 --> 00:53:44,170
bit shifted like here we see that it

00:53:41,320 --> 00:53:52,570
does sorting it's terasort so that's

00:53:44,170 --> 00:53:54,820
normal so what's interesting in JDK 10

00:53:52,570 --> 00:53:58,420
and then probably you hurt

00:53:54,820 --> 00:54:02,440
Stewart's talk I want overlap too much

00:53:58,420 --> 00:54:04,780
here string intrinsics allowed to

00:54:02,440 --> 00:54:05,890
complete compact strings support which

00:54:04,780 --> 00:54:07,270
is really important for business

00:54:05,890 --> 00:54:11,460
applications because they all work the

00:54:07,270 --> 00:54:16,200
strings that may be JSON XML or anything

00:54:11,460 --> 00:54:19,720
strings aut support was implemented

00:54:16,200 --> 00:54:22,630
which brought growl on the platform and

00:54:19,720 --> 00:54:25,509
also it seems to

00:54:22,630 --> 00:54:28,029
help for application startup if you use

00:54:25,509 --> 00:54:30,400
it carefully for example you cannot ad

00:54:28,029 --> 00:54:34,240
compile currently the entire Jo database

00:54:30,400 --> 00:54:38,289
module and that's not right for the r64

00:54:34,240 --> 00:54:41,109
but then you compile hot methods for

00:54:38,289 --> 00:54:46,230
Hadoop for example you can see like

00:54:41,109 --> 00:54:49,720
seven to eight percent workload speed-up

00:54:46,230 --> 00:54:54,910
in some cases which is really a good

00:54:49,720 --> 00:54:57,670
number that's what you t is for UPS it

00:54:54,910 --> 00:55:00,220
is application close data sharing it's

00:54:57,670 --> 00:55:04,539
also a good picture we participated in

00:55:00,220 --> 00:55:07,599
porting it doesn't help for workload

00:55:04,539 --> 00:55:12,549
times but it can help to say to save

00:55:07,599 --> 00:55:16,000
your footprint may be a bit for things

00:55:12,549 --> 00:55:19,210
like my produce but for other tasks like

00:55:16,000 --> 00:55:27,069
web servers this may be really critical

00:55:19,210 --> 00:55:30,430
and it also helps for startup there some

00:55:27,069 --> 00:55:36,609
bigger things we know the port is now

00:55:30,430 --> 00:55:37,990
competitive for some time if you get the

00:55:36,609 --> 00:55:43,599
latest job magazine there's an article

00:55:37,990 --> 00:55:46,809
and mentioning those numbers we tried

00:55:43,599 --> 00:55:50,650
some dummy setups for example this is

00:55:46,809 --> 00:55:53,230
page expect GBP composite and the

00:55:50,650 --> 00:55:58,049
minimal tuning was made for both

00:55:53,230 --> 00:56:02,380
machines we took into a machine that km

00:55:58,049 --> 00:56:02,859
competes to officially and just compared

00:56:02,380 --> 00:56:05,619
scores

00:56:02,859 --> 00:56:08,430
so you see both critical and Mark's

00:56:05,619 --> 00:56:16,660
operations are higher which is better

00:56:08,430 --> 00:56:19,359
and that's JDK 11 and also inspect JVM

00:56:16,660 --> 00:56:22,660
the result is about the same so you see

00:56:19,359 --> 00:56:24,510
the lines I think not so much the

00:56:22,660 --> 00:56:29,200
comment

00:56:24,510 --> 00:56:31,960
so we are continuing our work of

00:56:29,200 --> 00:56:34,840
intrinsics and other stuff and doing new

00:56:31,960 --> 00:56:39,400
things particularly bail software

00:56:34,840 --> 00:56:44,350
started value types work which should be

00:56:39,400 --> 00:56:49,540
also good for performance and stuff like

00:56:44,350 --> 00:56:53,260
Cassandra for example and we know that

00:56:49,540 --> 00:56:57,100
other things are going on like again zgc

00:56:53,260 --> 00:56:59,920
work which is a great perspective for

00:56:57,100 --> 00:57:05,190
having a low latency collector one more

00:56:59,920 --> 00:57:10,090
one and we still have stability issues

00:57:05,190 --> 00:57:12,280
we continue in Java 12 to improve entry

00:57:10,090 --> 00:57:14,800
6 which is workd which is no that's not

00:57:12,280 --> 00:57:18,130
finished and lector api is on the go

00:57:14,800 --> 00:57:22,020
because it also opens many perspectives

00:57:18,130 --> 00:57:29,140
but that's not the only Panama part

00:57:22,020 --> 00:57:38,290
because I think layouts and FFI is also

00:57:29,140 --> 00:57:41,890
important so as I said our perspective

00:57:38,290 --> 00:57:44,410
is to be focused on applications to

00:57:41,890 --> 00:57:47,040
carefully test all the changes with

00:57:44,410 --> 00:57:49,780
applications to test optimizations

00:57:47,040 --> 00:57:52,900
verify it is profiling and micro

00:57:49,780 --> 00:57:56,620
benchmarking so let's continue to

00:57:52,900 --> 00:57:59,470
contribute not only to open JDK but also

00:57:56,620 --> 00:58:03,690
surrounding technologies like profiling

00:57:59,470 --> 00:58:06,780
and frameworks based on opportunity

00:58:03,690 --> 00:58:06,780
thank you

00:58:06,890 --> 00:58:10,770
[Applause]

00:58:11,090 --> 00:58:15,410
we'll have some time for questions

00:58:16,040 --> 00:58:19,040
yeah

00:58:24,839 --> 00:58:30,420
yeah but it maybe the question is is

00:58:27,749 --> 00:58:32,249
this JFR scalable and it's a good if

00:58:30,420 --> 00:58:35,519
it's a good tool for production it's

00:58:32,249 --> 00:58:37,979
designed to be a tool for production but

00:58:35,519 --> 00:58:41,219
it's sometimes not easy to use it then

00:58:37,979 --> 00:58:45,499
you have many Gerry amps so that's a

00:58:41,219 --> 00:58:48,569
good challenge what to profile that's

00:58:45,499 --> 00:58:51,239
true not only for Jeff are but Jeff are

00:58:48,569 --> 00:58:53,690
probably slightly simpler to use them

00:58:51,239 --> 00:59:02,819
for example icing profile in this case

00:58:53,690 --> 00:59:06,390
yeah help one more question so the AB CD

00:59:02,819 --> 00:59:10,529
sorry specifically focusing on just AB

00:59:06,390 --> 00:59:14,969
series or series in general so there are

00:59:10,529 --> 00:59:16,950
two CDs parts general class data sharing

00:59:14,969 --> 00:59:21,390
that's for system classes and that's a

00:59:16,950 --> 00:59:24,479
separate or hive there is a jab for Jada

00:59:21,390 --> 00:59:27,650
k12 or just an enhancement to create it

00:59:24,479 --> 00:59:31,349
by default in some certain cases cases

00:59:27,650 --> 00:59:34,650
and there is a plus data sharing for

00:59:31,349 --> 00:59:38,400
applications AB Sidious then you can

00:59:34,650 --> 00:59:39,809
reuse loaded class data and decode it

00:59:38,400 --> 00:59:42,209
was date information for your

00:59:39,809 --> 00:59:47,039
application classes loaded certain class

00:59:42,209 --> 00:59:51,299
loaders and it worse basically we

00:59:47,039 --> 00:59:53,849
checked benchmarks similar to x86 I used

00:59:51,299 --> 00:59:55,859
to be involved in that projects so kind

00:59:53,849 --> 01:00:01,380
of realize what happens and the speed

00:59:55,859 --> 01:00:04,349
ups are similar so it works very well it

01:00:01,380 --> 01:00:09,769
can help you to save a lot of footprint

01:00:04,349 --> 01:00:09,769
then you start many similar things

01:00:17,220 --> 01:00:23,849
yep no more questions thanks again I

01:00:20,700 --> 01:00:26,030
think we'll have yeah some offline

01:00:23,849 --> 01:00:26,030
discussion

01:00:27,130 --> 01:00:35,130
[Applause]

01:00:30,130 --> 01:00:35,130

YouTube URL: https://www.youtube.com/watch?v=5m5kLU0_DH0


