Title: Wednesdays Keynotes at Linaro Connect Vancouver 2018 (YVR18)
Publication date: 2018-09-28
Playlist: Linaro Connect Vancouver 2018
Description: 
	Wednesdays Keynotes at Linaro Connect Vancouver 2018 (YVR18)
YVR18- 300K1 Keynote: Jem Davies "Enabling Machine Learning to Explode with Open Standards and Collaboration"
YVR18- 300K2 Keynote: Chris Benson "Artificial Intelligence Strategy: Digital Transformation Through Deep Learning"
YVR18- 300K3 Introduction to AI and Neural Networks on Arm Summit
Captions: 
	00:00:06,950 --> 00:00:10,980
so the video is not working on the

00:00:09,150 --> 00:00:12,620
slides normally you would see the cars

00:00:10,980 --> 00:00:16,139
moving around here on the front screen

00:00:12,620 --> 00:00:17,340
so I'm Chris Benson I am going to talk

00:00:16,139 --> 00:00:22,020
to you a little bit about deep learning

00:00:17,340 --> 00:00:25,230
and digital transformation i Ã´ll moment

00:00:22,020 --> 00:00:26,849
there so almost didn't make it today I'm

00:00:25,230 --> 00:00:28,920
from Atlanta and we had a close call

00:00:26,849 --> 00:00:30,960
with a hurricane and I had a broken foot

00:00:28,920 --> 00:00:34,430
so forgive me as I hobble around the

00:00:30,960 --> 00:00:37,649
stage here talking I have a cast futon

00:00:34,430 --> 00:00:38,730
this is me I was recently I've just left

00:00:37,649 --> 00:00:40,739
Honeywell where I was the chief

00:00:38,730 --> 00:00:42,930
scientist for AI and ml for one of their

00:00:40,739 --> 00:00:45,510
global divisions I ran I built the

00:00:42,930 --> 00:00:47,940
capability there and before that I was

00:00:45,510 --> 00:00:49,920
an Accenture and then I have some other

00:00:47,940 --> 00:00:52,620
activities around the AI world such as a

00:00:49,920 --> 00:00:54,000
podcast and deep learning group and so I

00:00:52,620 --> 00:00:57,809
do a lot of talking about these topics

00:00:54,000 --> 00:01:00,660
with different groups I had my first

00:00:57,809 --> 00:01:01,530
start quite a ways back on this for

00:01:00,660 --> 00:01:03,359
those of you who are old enough to

00:01:01,530 --> 00:01:05,040
remember it's the original IBM PC when

00:01:03,359 --> 00:01:07,530
it came out did my first hello world on

00:01:05,040 --> 00:01:11,250
that and I've been doing data science

00:01:07,530 --> 00:01:12,450
and computer science ever since so I got

00:01:11,250 --> 00:01:16,080
introduced to artificial intelligence

00:01:12,450 --> 00:01:17,939
before most people out there with it's

00:01:16,080 --> 00:01:21,330
been 26 years and people like really

00:01:17,939 --> 00:01:23,040
that far back and that's because there

00:01:21,330 --> 00:01:25,799
was this plane that was built in the

00:01:23,040 --> 00:01:27,479
Atlanta area and some of you may

00:01:25,799 --> 00:01:30,750
recognize it it's the f-22 stealth

00:01:27,479 --> 00:01:33,299
fighter it was built in the Lockheed

00:01:30,750 --> 00:01:37,799
Georgia plant just outside of Atlanta

00:01:33,299 --> 00:01:41,130
and that had a serious situation when it

00:01:37,799 --> 00:01:42,840
was still a prototype there was a test

00:01:41,130 --> 00:01:44,820
going on at Edwards Air Force Base in

00:01:42,840 --> 00:01:47,159
California and the plane was supposed to

00:01:44,820 --> 00:01:48,270
to prevent the pilot from being able to

00:01:47,159 --> 00:01:51,479
crash it so they were testing the

00:01:48,270 --> 00:01:53,909
avionics and things did not go quite as

00:01:51,479 --> 00:01:56,100
they planned um the good news is the

00:01:53,909 --> 00:01:59,040
pilot was fine and after skidding fire

00:01:56,100 --> 00:02:03,210
down the runway he got out but this

00:01:59,040 --> 00:02:07,439
somehow led to to me getting into AI and

00:02:03,210 --> 00:02:09,780
that was because this particular man was

00:02:07,439 --> 00:02:11,610
responsible as the engineer to go figure

00:02:09,780 --> 00:02:11,970
out what happened what went wrong and

00:02:11,610 --> 00:02:13,680
why the

00:02:11,970 --> 00:02:15,720
that and the reason I came into the

00:02:13,680 --> 00:02:16,140
story is this particular guy was my

00:02:15,720 --> 00:02:18,690
father

00:02:16,140 --> 00:02:19,860
and so for about a year as he was

00:02:18,690 --> 00:02:21,750
dealing with it he would come home from

00:02:19,860 --> 00:02:23,250
work and I was a college student and we

00:02:21,750 --> 00:02:24,840
talked about neural networks which was

00:02:23,250 --> 00:02:27,450
the technology he was using of the day

00:02:24,840 --> 00:02:30,600
to try to solve it and I developed a

00:02:27,450 --> 00:02:33,420
passion and thereafter it led ultimately

00:02:30,600 --> 00:02:35,250
to where we are today and so I wanted to

00:02:33,420 --> 00:02:37,470
share that in that I've had a long time

00:02:35,250 --> 00:02:39,780
as an engineer to think about how the

00:02:37,470 --> 00:02:42,090
neural networks solve the problems that

00:02:39,780 --> 00:02:43,320
we're dealing with today and so I want

00:02:42,090 --> 00:02:45,630
to talk about since we're talking about

00:02:43,320 --> 00:02:46,860
how to does deep learning affect digital

00:02:45,630 --> 00:02:47,790
transformation and what is digital

00:02:46,860 --> 00:02:50,070
transformation

00:02:47,790 --> 00:02:52,680
I want to real quick cover that it's

00:02:50,070 --> 00:02:55,200
common misconceptions there it's not a

00:02:52,680 --> 00:02:56,910
channel because people often say a

00:02:55,200 --> 00:02:59,430
digital channel that kind of thing and

00:02:56,910 --> 00:03:01,459
it's not a project it's not something

00:02:59,430 --> 00:03:04,530
you often stick a budget on and go do

00:03:01,459 --> 00:03:06,660
it's the purpose of digital

00:03:04,530 --> 00:03:08,880
transformation is to Digita is not to

00:03:06,660 --> 00:03:11,400
digitize an existing state but to

00:03:08,880 --> 00:03:13,020
completely reimagine what kind of

00:03:11,400 --> 00:03:14,400
business model is appropriate to solve

00:03:13,020 --> 00:03:16,500
your problem so if you were starting on

00:03:14,400 --> 00:03:18,030
your existing business today with the

00:03:16,500 --> 00:03:20,160
tape with the technologies that you have

00:03:18,030 --> 00:03:21,600
and you were saying how would we how

00:03:20,160 --> 00:03:23,250
would we create this today from scratch

00:03:21,600 --> 00:03:25,590
that's what it's about so what we're

00:03:23,250 --> 00:03:28,590
really saying is that it's all about

00:03:25,590 --> 00:03:30,120
innovation it's not about optimization

00:03:28,590 --> 00:03:32,130
and that's a really common misconception

00:03:30,120 --> 00:03:33,600
a lot of companies will go fund digital

00:03:32,130 --> 00:03:35,610
transformational projects stick a budget

00:03:33,600 --> 00:03:36,570
and they're trying to basically change

00:03:35,610 --> 00:03:40,560
something they already have in place

00:03:36,570 --> 00:03:42,450
with technologies so the thing about it

00:03:40,560 --> 00:03:44,700
is digital transformation is itself

00:03:42,450 --> 00:03:48,510
going through a massive transformation

00:03:44,700 --> 00:03:50,489
right now and that is because of AI and

00:03:48,510 --> 00:03:52,019
as we talked about here it's kind of led

00:03:50,489 --> 00:03:54,600
through this and that we have we've had

00:03:52,019 --> 00:03:56,840
the cognitive revolution which happened

00:03:54,600 --> 00:04:00,209
70,000 years ago agricultural revolution

00:03:56,840 --> 00:04:02,250
12,000 years ago followed by Industrial

00:04:00,209 --> 00:04:04,769
digital and now the AI revolution and

00:04:02,250 --> 00:04:06,090
they've gradually been changing society

00:04:04,769 --> 00:04:07,500
more and more but now as we're getting

00:04:06,090 --> 00:04:11,580
into AI and it's impacting everything

00:04:07,500 --> 00:04:13,860
we're talking massive changes to social

00:04:11,580 --> 00:04:15,989
cultural and economic interests all over

00:04:13,860 --> 00:04:17,970
the world and it definitely affects

00:04:15,989 --> 00:04:19,280
digital transformation that all of our

00:04:17,970 --> 00:04:22,800
businesses are going to be going through

00:04:19,280 --> 00:04:25,140
so digital transformation is at the very

00:04:22,800 --> 00:04:26,330
heart of this AI driven change going

00:04:25,140 --> 00:04:28,950
full

00:04:26,330 --> 00:04:31,410
artificial intelligence is already

00:04:28,950 --> 00:04:34,770
changing how these business models are

00:04:31,410 --> 00:04:37,560
being reimagined so you could think of

00:04:34,770 --> 00:04:41,100
it as AI is the technology we're talking

00:04:37,560 --> 00:04:44,130
about and digital transformation is that

00:04:41,100 --> 00:04:46,890
strategic process and fundamentally the

00:04:44,130 --> 00:04:48,660
technology is changing the fundamentals

00:04:46,890 --> 00:04:52,530
of how you apply the strategic process

00:04:48,660 --> 00:04:55,500
going forward so I wanted to put this in

00:04:52,530 --> 00:04:57,360
a little bit of context this lady is the

00:04:55,500 --> 00:04:59,370
essentially the CTO at the United

00:04:57,360 --> 00:05:01,590
Nations and she talks a lot about this

00:04:59,370 --> 00:05:03,630
in terms of how we should think about

00:05:01,590 --> 00:05:05,550
ourselves as technologists in this AI

00:05:03,630 --> 00:05:08,190
and digital transformation world going

00:05:05,550 --> 00:05:10,500
forward and the ramifications there good

00:05:08,190 --> 00:05:12,630
and bad that we all see in the news and

00:05:10,500 --> 00:05:13,920
what do we need to do what does our

00:05:12,630 --> 00:05:17,460
businesses need to do to transform

00:05:13,920 --> 00:05:19,350
ourselves going forward if you look at

00:05:17,460 --> 00:05:20,820
the last 20 years a lot of changes

00:05:19,350 --> 00:05:22,230
happen but that's nothing like what

00:05:20,820 --> 00:05:24,900
we're going to see in the next 20 years

00:05:22,230 --> 00:05:28,110
next 50 years 100 years we're going up

00:05:24,900 --> 00:05:30,660
an exponential curve with this so you

00:05:28,110 --> 00:05:33,090
could think of that AI might be the last

00:05:30,660 --> 00:05:34,980
major innovation that humans are

00:05:33,090 --> 00:05:37,500
creating because going forward we're

00:05:34,980 --> 00:05:41,490
gonna be using the at the AI itself to

00:05:37,500 --> 00:05:43,020
create those next innovations and so you

00:05:41,490 --> 00:05:44,550
have a question there we all have to

00:05:43,020 --> 00:05:46,380
answer those businesses of you know the

00:05:44,550 --> 00:05:47,850
obvious labor things we talk about jobs

00:05:46,380 --> 00:05:50,970
and things like that but there's amazing

00:05:47,850 --> 00:05:53,400
great side's amazing upside and some

00:05:50,970 --> 00:05:56,130
downsides to contend with so ultimately

00:05:53,400 --> 00:05:58,620
the the objective of digital

00:05:56,130 --> 00:05:59,970
transformation is going to be to try to

00:05:58,620 --> 00:06:01,800
figure out how to cope with the

00:05:59,970 --> 00:06:04,890
downsides while taking advantage of

00:06:01,800 --> 00:06:06,750
amazing upsides going forward so this is

00:06:04,890 --> 00:06:10,320
the AI enabled world of digital

00:06:06,750 --> 00:06:12,680
transformation going forward so I've

00:06:10,320 --> 00:06:15,000
been throwing around AI a lot and

00:06:12,680 --> 00:06:18,960
sometimes that can be hard to define so

00:06:15,000 --> 00:06:20,360
can we define AI well that's easier said

00:06:18,960 --> 00:06:22,860
the dud

00:06:20,360 --> 00:06:25,560
because if you ask 10 different AI

00:06:22,860 --> 00:06:27,090
experts to define AI you're gonna

00:06:25,560 --> 00:06:29,940
typically come up with ten different

00:06:27,090 --> 00:06:32,580
answers and so how do I know this well

00:06:29,940 --> 00:06:33,900
because Adobe recently did this and I

00:06:32,580 --> 00:06:36,180
was invited to be one of those AI

00:06:33,900 --> 00:06:39,270
experts that they pulled so we had a

00:06:36,180 --> 00:06:42,030
group in a think tank in New York City

00:06:39,270 --> 00:06:43,080
that was broadcast and it was funny you

00:06:42,030 --> 00:06:45,560
put all these people that are supposed

00:06:43,080 --> 00:06:49,320
to know all about AI and the thing was

00:06:45,560 --> 00:06:51,150
we were unable to define it every one of

00:06:49,320 --> 00:06:53,880
us had a completely different answer so

00:06:51,150 --> 00:06:57,450
I say I'm gonna kind of share what my

00:06:53,880 --> 00:06:59,280
definition is and it's perfectly fine to

00:06:57,450 --> 00:07:00,300
not agree with me on precisely because

00:06:59,280 --> 00:07:01,830
there were at least nine other AI

00:07:00,300 --> 00:07:02,160
experts in that room that didn't agree

00:07:01,830 --> 00:07:03,540
with me

00:07:02,160 --> 00:07:05,010
and each one of them had the same

00:07:03,540 --> 00:07:08,250
dilemma they all had nine people that

00:07:05,010 --> 00:07:11,510
didn't agree with them so I define AI in

00:07:08,250 --> 00:07:14,190
a very narrow context personally I

00:07:11,510 --> 00:07:16,710
consider AI to be a marketing buzzword

00:07:14,190 --> 00:07:18,780
and it evolves over time it was the

00:07:16,710 --> 00:07:21,450
neural networks that my father was doing

00:07:18,780 --> 00:07:22,830
in the early 90s was AI there were other

00:07:21,450 --> 00:07:24,780
things that were attached to the label

00:07:22,830 --> 00:07:26,520
and as time goes on different

00:07:24,780 --> 00:07:28,710
technologies get attached to that AI

00:07:26,520 --> 00:07:30,390
label so it evolves it'll probably my

00:07:28,710 --> 00:07:31,530
definition will evolve also from you

00:07:30,390 --> 00:07:34,320
know five ten years from now it'll

00:07:31,530 --> 00:07:37,590
probably be a bit different so these

00:07:34,320 --> 00:07:39,090
days I take the fact that AI being a

00:07:37,590 --> 00:07:40,590
marketing buzzword and obviously digital

00:07:39,090 --> 00:07:45,060
transformation is too because that's

00:07:40,590 --> 00:07:46,890
evolving and so I consider AI simply to

00:07:45,060 --> 00:07:48,720
be deep learning there are other

00:07:46,890 --> 00:07:50,160
technologies you can argue are in there

00:07:48,720 --> 00:07:52,320
and that's fine

00:07:50,160 --> 00:07:54,060
but I think this is what's really driven

00:07:52,320 --> 00:07:56,970
this massive surge over the last few

00:07:54,060 --> 00:07:58,790
years so I realized that not everybody

00:07:56,970 --> 00:08:00,630
will agree with my own definition

00:07:58,790 --> 00:08:02,340
Princess Leia is looking pretty rough

00:08:00,630 --> 00:08:05,760
there I think with the stormtroopers

00:08:02,340 --> 00:08:07,410
behind her but I did also want to share

00:08:05,760 --> 00:08:10,500
one other thing that's just an aside as

00:08:07,410 --> 00:08:12,630
we go on and that is that we did all

00:08:10,500 --> 00:08:15,570
agree on exactly one key principle in

00:08:12,630 --> 00:08:17,070
that group of 10 people we all agreed

00:08:15,570 --> 00:08:18,810
that you start with the customer no

00:08:17,070 --> 00:08:21,180
matter what industry you're in what your

00:08:18,810 --> 00:08:22,320
project is where you're applying and you

00:08:21,180 --> 00:08:24,780
work yourself backwards to the

00:08:22,320 --> 00:08:26,550
technology so we couldn't agree on what

00:08:24,780 --> 00:08:27,600
aisle it was but we could agree on what

00:08:26,550 --> 00:08:31,680
you do with it when you're trying to

00:08:27,600 --> 00:08:32,670
apply it so what is deep learning I'm

00:08:31,680 --> 00:08:34,800
going to talk about that for a moment

00:08:32,670 --> 00:08:37,980
it's really modern AI that is working

00:08:34,800 --> 00:08:39,570
today and it's an approach to machine

00:08:37,980 --> 00:08:42,050
learning that's driving the current

00:08:39,570 --> 00:08:44,130
artificial intelligence revolution and

00:08:42,050 --> 00:08:46,110
it's an approach to machine learning

00:08:44,130 --> 00:08:48,180
that draws its inspiration from the

00:08:46,110 --> 00:08:50,600
human brain statistics and applied

00:08:48,180 --> 00:08:52,940
mathematics

00:08:50,600 --> 00:08:55,400
so and by the way the quotes here from

00:08:52,940 --> 00:08:56,780
the seminal textbook in the in the field

00:08:55,400 --> 00:08:59,150
which is called the deep learning

00:08:56,780 --> 00:09:02,030
textbook just to just a note that there

00:08:59,150 --> 00:09:03,710
and they note in the textbook which is

00:09:02,030 --> 00:09:05,360
probably many of us understand here that

00:09:03,710 --> 00:09:07,220
the things that are driving this at this

00:09:05,360 --> 00:09:09,350
point are the facts that we have we have

00:09:07,220 --> 00:09:11,090
new techniques every year and right now

00:09:09,350 --> 00:09:13,760
we have new techniques almost every few

00:09:11,090 --> 00:09:15,230
months giant data sets that are just

00:09:13,760 --> 00:09:17,420
getting bigger and more available and

00:09:15,230 --> 00:09:20,270
obviously more powerful computers

00:09:17,420 --> 00:09:21,770
whether they be cloud based or NVIDIA

00:09:20,270 --> 00:09:25,250
supercomputers or whatever you want to

00:09:21,770 --> 00:09:26,300
have and so what that really means is

00:09:25,250 --> 00:09:28,580
that you're talking about the modern

00:09:26,300 --> 00:09:30,140
application of neural networks to

00:09:28,580 --> 00:09:32,930
achieve the machine learning goals that

00:09:30,140 --> 00:09:36,830
you have so you're learning from data

00:09:32,930 --> 00:09:38,690
without explicit programming and that is

00:09:36,830 --> 00:09:39,800
neural computing and this is a term

00:09:38,690 --> 00:09:40,310
you're gonna see more and more in the

00:09:39,800 --> 00:09:43,430
years ahead

00:09:40,310 --> 00:09:45,290
because I was recently at the Nvidia GT

00:09:43,430 --> 00:09:48,260
C conference back in I guess it was

00:09:45,290 --> 00:09:50,120
February now and I noticed that their

00:09:48,260 --> 00:09:52,130
CEO was talking a lot about neural

00:09:50,120 --> 00:09:53,470
computing and it's kind of a shift in

00:09:52,130 --> 00:09:56,360
the way we're thinking about programming

00:09:53,470 --> 00:09:58,580
instead of being explicit if this then

00:09:56,360 --> 00:09:59,990
that go through a loop I have to think

00:09:58,580 --> 00:10:02,210
of everything as a programmer we're now

00:09:59,990 --> 00:10:03,290
get to start having models that do a lot

00:10:02,210 --> 00:10:04,700
of that decision-making and we

00:10:03,290 --> 00:10:06,920
accommodate those models in day-to-day

00:10:04,700 --> 00:10:09,770
programming this is a huge shift in

00:10:06,920 --> 00:10:11,990
computing going forward so this is kind

00:10:09,770 --> 00:10:15,440
of how I see deep learning as AI fitting

00:10:11,990 --> 00:10:17,210
into the the space it is one type of

00:10:15,440 --> 00:10:18,380
machine learning it's not the only type

00:10:17,210 --> 00:10:20,540
of machine learning there are many other

00:10:18,380 --> 00:10:23,210
algorithms out there now some of them

00:10:20,540 --> 00:10:25,520
people are you also take part in that AI

00:10:23,210 --> 00:10:27,080
world so obviously I have the bias that

00:10:25,520 --> 00:10:28,820
I've already disclosed and then those

00:10:27,080 --> 00:10:32,870
fit into the larger combined world of

00:10:28,820 --> 00:10:34,070
data science and computer science so one

00:10:32,870 --> 00:10:35,780
of the things we tend to talk about deep

00:10:34,070 --> 00:10:37,340
learning a lot without a lot of people

00:10:35,780 --> 00:10:38,660
don't really understand why why is it

00:10:37,340 --> 00:10:40,250
this we keep talking with deep learning

00:10:38,660 --> 00:10:42,380
it's so popular you hear about it and

00:10:40,250 --> 00:10:44,450
everything what is making deep learning

00:10:42,380 --> 00:10:45,860
such an amazing tool for us or at least

00:10:44,450 --> 00:10:48,280
why are we talking about it so much I

00:10:45,860 --> 00:10:50,630
want to talk about what drives it and

00:10:48,280 --> 00:10:54,470
this guy here is excited I can tell you

00:10:50,630 --> 00:10:57,370
and that is that you can precisely

00:10:54,470 --> 00:10:59,330
approximate any continuous function so

00:10:57,370 --> 00:11:00,800
maybe not this crowd because it's a

00:10:59,330 --> 00:11:02,330
fairly technical corral but a lot of

00:11:00,800 --> 00:11:03,680
people they see that slide and they

00:11:02,330 --> 00:11:04,520
start to fall asleep and go really

00:11:03,680 --> 00:11:07,130
that's your big

00:11:04,520 --> 00:11:08,720
right there but it's a pretty powerful

00:11:07,130 --> 00:11:10,190
statement because you're basically

00:11:08,720 --> 00:11:12,050
saying that nearly any imaginable

00:11:10,190 --> 00:11:14,360
process involves computing a function

00:11:12,050 --> 00:11:16,250
and if you can approximate that function

00:11:14,360 --> 00:11:18,110
with neural networks if that's possible

00:11:16,250 --> 00:11:20,120
that means you can apply to a lot of

00:11:18,110 --> 00:11:23,060
different problems so this is huge

00:11:20,120 --> 00:11:25,209
Knowle networks are somewhat universal

00:11:23,060 --> 00:11:27,709
and that means that deep learning is a

00:11:25,209 --> 00:11:31,399
universal approach to solving complex

00:11:27,709 --> 00:11:35,959
problems so Homer is pretty happy about

00:11:31,399 --> 00:11:37,339
that but deep learning is currently as

00:11:35,959 --> 00:11:41,029
you're probably aware right at the very

00:11:37,339 --> 00:11:42,320
peak of the hype cycle every it's magic

00:11:41,029 --> 00:11:43,910
it can do anything it can solve any

00:11:42,320 --> 00:11:47,300
problem in the world I just said it was

00:11:43,910 --> 00:11:48,529
the universal toolbox didn't I but we'll

00:11:47,300 --> 00:11:50,390
talk a little bit in a few minutes about

00:11:48,529 --> 00:11:52,250
what it's good to solve and and what

00:11:50,390 --> 00:11:55,040
things are maybe not so perfect for it

00:11:52,250 --> 00:11:56,720
and having said that I would recommend

00:11:55,040 --> 00:11:59,480
that keep in mind that it's at the peak

00:11:56,720 --> 00:12:01,839
of the hype cycle ignore the hype just

00:11:59,480 --> 00:12:04,310
ignore the hype on it completely and

00:12:01,839 --> 00:12:09,020
focus entirely on the practical

00:12:04,310 --> 00:12:11,510
applications so let's talk a little bit

00:12:09,020 --> 00:12:13,459
about how this technology how deep

00:12:11,510 --> 00:12:14,990
learning in the context of digital

00:12:13,459 --> 00:12:17,720
transformation is being applied out

00:12:14,990 --> 00:12:20,360
there in industry so probably the first

00:12:17,720 --> 00:12:22,070
mainstream stuff was Google several

00:12:20,360 --> 00:12:25,459
years ago kicking off and talking about

00:12:22,070 --> 00:12:28,610
it and and that was kicked off by the

00:12:25,459 --> 00:12:30,560
idea that he noted that the last 10

00:12:28,610 --> 00:12:33,140
years have been about mobile first and

00:12:30,560 --> 00:12:34,910
we heard that so much but the next 10

00:12:33,140 --> 00:12:38,180
years oh and it's were several years

00:12:34,910 --> 00:12:40,730
into that is all about AI first and so

00:12:38,180 --> 00:12:42,050
as they look forward he's basically they

00:12:40,730 --> 00:12:43,310
have been and we've probably experienced

00:12:42,050 --> 00:12:45,260
if you have Gmail and or doing Google

00:12:43,310 --> 00:12:47,360
searches and stuff those services have

00:12:45,260 --> 00:12:48,950
been evolving very rapidly and so you

00:12:47,360 --> 00:12:52,640
are seeing them go through all their

00:12:48,950 --> 00:12:54,890
services and implement AI neural network

00:12:52,640 --> 00:12:56,600
models wherever it makes sense to help

00:12:54,890 --> 00:12:58,370
them along and that's an ongoing thing

00:12:56,600 --> 00:13:01,220
and everybody else in the world has

00:12:58,370 --> 00:13:02,510
followed suit on that it is becoming one

00:13:01,220 --> 00:13:05,750
of those things that everyone realizes

00:13:02,510 --> 00:13:08,510
they really need to do now about a year

00:13:05,750 --> 00:13:09,890
and a half ago you know close to I guess

00:13:08,510 --> 00:13:11,240
actually it's been over that spent over

00:13:09,890 --> 00:13:15,079
two years ago now

00:13:11,240 --> 00:13:17,360
the CIO was commenting that if you were

00:13:15,079 --> 00:13:18,620
looking back three years and you decided

00:13:17,360 --> 00:13:21,470
to get into deep learning then you

00:13:18,620 --> 00:13:23,210
enormous amount of money and effort and

00:13:21,470 --> 00:13:25,190
time with limited results but if you

00:13:23,210 --> 00:13:27,410
were to wait three more years you're

00:13:25,190 --> 00:13:29,420
gonna be hopelessly behind and I've had

00:13:27,410 --> 00:13:31,580
that slide for a while in various talks

00:13:29,420 --> 00:13:33,470
and I found that as we're approaching

00:13:31,580 --> 00:13:35,570
that three-year mark I think he's dead

00:13:33,470 --> 00:13:36,980
on I think I never knew if his timeline

00:13:35,570 --> 00:13:38,420
was right I agreed with the sentiment

00:13:36,980 --> 00:13:39,760
but I think its timeline is right

00:13:38,420 --> 00:13:41,750
because everyone's doing it now

00:13:39,760 --> 00:13:44,510
everybody is trying to figure out how to

00:13:41,750 --> 00:13:46,520
apply models so if your company isn't

00:13:44,510 --> 00:13:48,620
then you probably need to be thinking

00:13:46,520 --> 00:13:50,390
about that because in these years ahead

00:13:48,620 --> 00:13:52,040
we're certainly going to consume and

00:13:50,390 --> 00:13:53,480
will probably be creating artificial

00:13:52,040 --> 00:13:55,940
intelligence that companies throughout

00:13:53,480 --> 00:13:57,590
the world and machine learning in the

00:13:55,940 --> 00:13:59,690
form of micro services it'll just be

00:13:57,590 --> 00:14:01,070
normal programming API is that we're

00:13:59,690 --> 00:14:04,790
used to having it won't be anything

00:14:01,070 --> 00:14:06,260
distinct and magical so see these are

00:14:04,790 --> 00:14:10,280
some of the more common use cases and

00:14:06,260 --> 00:14:11,510
let me pop back a second I hit the wrong

00:14:10,280 --> 00:14:13,730
button there these are some of the

00:14:11,510 --> 00:14:15,380
common use cases and this doesn't even

00:14:13,730 --> 00:14:17,870
begin to cover all of them this is a

00:14:15,380 --> 00:14:21,040
tiny smattering kind of byline we're

00:14:17,870 --> 00:14:23,210
talking about kind of security marketing

00:14:21,040 --> 00:14:24,650
some of the different machine computer

00:14:23,210 --> 00:14:26,930
vision applications and speech

00:14:24,650 --> 00:14:28,790
recognition obviously transportation

00:14:26,930 --> 00:14:32,270
with us talking about automated vehicles

00:14:28,790 --> 00:14:33,800
everywhere and healthcare is huge and

00:14:32,270 --> 00:14:36,110
then financial and a matter of fact

00:14:33,800 --> 00:14:38,450
these days really everything in the

00:14:36,110 --> 00:14:41,630
securities market is is regulated by

00:14:38,450 --> 00:14:43,400
these models some of these crashes that

00:14:41,630 --> 00:14:46,490
we've had recently were you know drops

00:14:43,400 --> 00:14:47,870
hundreds of points in a few minutes and

00:14:46,490 --> 00:14:49,220
pop straight back up all of that is

00:14:47,870 --> 00:14:50,570
computer driven by these types of models

00:14:49,220 --> 00:14:53,270
as they're learning to do it better and

00:14:50,570 --> 00:14:55,460
better so androoni

00:14:53,270 --> 00:14:57,770
and Harvard Business Review also put

00:14:55,460 --> 00:15:01,070
this out as just a basic way of talking

00:14:57,770 --> 00:15:02,810
about some of the use cases that you can

00:15:01,070 --> 00:15:04,600
apply these technologies to and he did

00:15:02,810 --> 00:15:06,860
it in a very simple like I got a picture

00:15:04,600 --> 00:15:10,340
are there human faces and that's photo

00:15:06,860 --> 00:15:11,900
tagging so you can take a look at that

00:15:10,340 --> 00:15:13,760
and I'll make the slides available later

00:15:11,900 --> 00:15:18,110
on so but I really want to talk about

00:15:13,760 --> 00:15:20,390
what is today's AI good at it's really

00:15:18,110 --> 00:15:23,810
good at solving complex but very very

00:15:20,390 --> 00:15:26,250
specific problems and often times it can

00:15:23,810 --> 00:15:27,660
do that far better than

00:15:26,250 --> 00:15:30,090
humans can and that's where you're

00:15:27,660 --> 00:15:32,870
seeing giant strides and you know in in

00:15:30,090 --> 00:15:35,460
in things that we see and even on CNN

00:15:32,870 --> 00:15:36,210
about what certain systems are able to

00:15:35,460 --> 00:15:38,790
do so much better

00:15:36,210 --> 00:15:41,000
you know radiologists the last few years

00:15:38,790 --> 00:15:43,110
have been in a hard place because they

00:15:41,000 --> 00:15:44,820
CNN's of today the convolutional neural

00:15:43,110 --> 00:15:46,890
networks which we'll talk about can

00:15:44,820 --> 00:15:48,390
analyze those images so much better than

00:15:46,890 --> 00:15:52,350
human camp and that's being spread out

00:15:48,390 --> 00:15:55,170
so what is they not bad at it's really

00:15:52,350 --> 00:15:57,690
bad right now at problems that involve

00:15:55,170 --> 00:16:01,380
creativity or that change or evolve

00:15:57,690 --> 00:16:04,590
continuously and that may not always be

00:16:01,380 --> 00:16:06,810
the case but right now it is ironically

00:16:04,590 --> 00:16:09,480
it's a lot easier for a neural network

00:16:06,810 --> 00:16:11,670
to go and do the job of a radiologist

00:16:09,480 --> 00:16:14,040
which is a highly specialized field

00:16:11,670 --> 00:16:15,360
versus if you were back before the

00:16:14,040 --> 00:16:16,890
Agricultural Revolution and you were a

00:16:15,360 --> 00:16:18,360
hunter-gatherer and there were so many

00:16:16,890 --> 00:16:19,740
different things that you needed to be

00:16:18,360 --> 00:16:22,080
able to do to survive on a day to day

00:16:19,740 --> 00:16:23,400
basis neural networks would never be

00:16:22,080 --> 00:16:28,620
able to handle the complexity and

00:16:23,400 --> 00:16:30,780
diversity of all those today so the real

00:16:28,620 --> 00:16:33,060
power equation going forward is humans

00:16:30,780 --> 00:16:35,250
plus AI you have a bunch of different

00:16:33,060 --> 00:16:37,190
use cases there's a ton of as vehicles

00:16:35,250 --> 00:16:39,360
where you're essentially delegating that

00:16:37,190 --> 00:16:41,360
robotics where it's a combination of

00:16:39,360 --> 00:16:43,680
collaboration and delegation

00:16:41,360 --> 00:16:45,950
interactions interactions through either

00:16:43,680 --> 00:16:48,810
augmented reality mobile or

00:16:45,950 --> 00:16:50,160
conversational interfaces I don't know

00:16:48,810 --> 00:16:53,220
about you all but I have both Google I

00:16:50,160 --> 00:16:54,930
have both Amazon and Google in my home

00:16:53,220 --> 00:16:57,750
listening to everything I say in some

00:16:54,930 --> 00:17:00,060
cases the same device both devices are

00:16:57,750 --> 00:17:04,410
in the same room so that is the world

00:17:00,060 --> 00:17:05,850
going forward so really what AI is going

00:17:04,410 --> 00:17:08,459
to do in the near future is give us

00:17:05,850 --> 00:17:11,100
superpowers you'll you'll have the

00:17:08,459 --> 00:17:13,620
ability to to work with that AI to do

00:17:11,100 --> 00:17:14,699
your job but so much more productively

00:17:13,620 --> 00:17:18,750
than you ever could have done it before

00:17:14,699 --> 00:17:19,980
so we talked about a world transformed

00:17:18,750 --> 00:17:22,020
we're all familiar with Google's

00:17:19,980 --> 00:17:24,329
automated vehicles and the profound

00:17:22,020 --> 00:17:27,120
changes that's doing that that's

00:17:24,329 --> 00:17:30,030
creating an industry it's you know it's

00:17:27,120 --> 00:17:32,310
moving from cars to flying vehicles to

00:17:30,030 --> 00:17:35,340
trucks on the highway you name it that

00:17:32,310 --> 00:17:38,720
that entire industry is being digitally

00:17:35,340 --> 00:17:38,720
transformed through this technology

00:17:39,140 --> 00:17:42,680
this is kind of a joke of mine that I

00:17:40,670 --> 00:17:44,360
found and I like and it's that you know

00:17:42,680 --> 00:17:46,220
or are we gonna just have BOTS everyone

00:17:44,360 --> 00:17:48,200
talks about boss when I was Accenture we

00:17:46,220 --> 00:17:50,450
talked about bots all day long I got to

00:17:48,200 --> 00:17:52,640
where I couldn't stand BOTS anymore

00:17:50,450 --> 00:17:54,770
because you know so many companies were

00:17:52,640 --> 00:17:57,020
creating BOTS for anything they want to

00:17:54,770 --> 00:17:59,750
do which assists the people they're

00:17:57,020 --> 00:18:02,480
their customers their employees and as

00:17:59,750 --> 00:18:03,860
we do that going forward it's going to

00:18:02,480 --> 00:18:05,420
affect all of our lives in a profound

00:18:03,860 --> 00:18:08,510
way in the fairly near future Gardner

00:18:05,420 --> 00:18:09,920
has estimated that by 2025 half of our

00:18:08,510 --> 00:18:12,050
primary health care needs are going to

00:18:09,920 --> 00:18:13,250
be handled by bots these technologies

00:18:12,050 --> 00:18:15,770
are already out there they're getting

00:18:13,250 --> 00:18:17,450
much much better very very quickly and

00:18:15,770 --> 00:18:20,060
so you're gonna go to your iPhone or

00:18:17,450 --> 00:18:22,250
Android as your first mechanism for

00:18:20,060 --> 00:18:24,140
solving whatever your ailment of the day

00:18:22,250 --> 00:18:26,480
is and you'll only go in and see a

00:18:24,140 --> 00:18:28,040
doctor once you get passed up you'll no

00:18:26,480 --> 00:18:29,510
longer start with a primary care

00:18:28,040 --> 00:18:31,520
physician you'll start with the bot and

00:18:29,510 --> 00:18:34,100
then work your way into that and you'll

00:18:31,520 --> 00:18:36,290
get faster better service as a result so

00:18:34,100 --> 00:18:39,860
lots of BOTS we're all building chat

00:18:36,290 --> 00:18:41,540
BOTS google's deepmind is doing some

00:18:39,860 --> 00:18:44,240
amazing things in terms of cancer

00:18:41,540 --> 00:18:46,520
treatment and you're also going to find

00:18:44,240 --> 00:18:49,280
that even though things like stopping

00:18:46,520 --> 00:18:51,530
violence this is a system here that is

00:18:49,280 --> 00:18:53,890
able to through microphones placed

00:18:51,530 --> 00:18:56,630
throughout a region hear gunshots and

00:18:53,890 --> 00:18:58,160
rout police much faster than they could

00:18:56,630 --> 00:18:59,810
have before based on neural networks

00:18:58,160 --> 00:19:02,810
analyzing where crime is occurring and

00:18:59,810 --> 00:19:05,000
giving the dispatchers and early go so

00:19:02,810 --> 00:19:07,430
it's pretty amazing so we've been kind

00:19:05,000 --> 00:19:09,620
of talking about use cases and and how

00:19:07,430 --> 00:19:11,180
it affects the world and I want to do a

00:19:09,620 --> 00:19:12,800
little bit of a deep dive for those of

00:19:11,180 --> 00:19:14,570
you who may not be familiar with exactly

00:19:12,800 --> 00:19:17,420
what and I have this fellow again

00:19:14,570 --> 00:19:19,640
apologize for that and it's kind of talk

00:19:17,420 --> 00:19:21,830
about how neural networks work

00:19:19,640 --> 00:19:23,810
fundamentally so you're really talking

00:19:21,830 --> 00:19:25,880
about creating training that enables

00:19:23,810 --> 00:19:28,100
generalized predictions and using known

00:19:25,880 --> 00:19:30,290
correct results and this is called

00:19:28,100 --> 00:19:32,120
supervised learning as opposed to

00:19:30,290 --> 00:19:33,950
unsupervised learning or reinforcement

00:19:32,120 --> 00:19:35,810
learning all of which are in the space

00:19:33,950 --> 00:19:38,150
but I'm kind of starting with the basics

00:19:35,810 --> 00:19:39,530
here as you do that you have to have to

00:19:38,150 --> 00:19:41,680
for training to work yet have a lot of

00:19:39,530 --> 00:19:44,060
known correct results it can often be in

00:19:41,680 --> 00:19:46,870
easily in the thousands often in the

00:19:44,060 --> 00:19:49,400
hundreds of thousands or millions of

00:19:46,870 --> 00:19:51,890
samples that you can say this is the

00:19:49,400 --> 00:19:54,020
reality we have a historical record

00:19:51,890 --> 00:19:55,970
and by using the historical record we're

00:19:54,020 --> 00:19:57,950
gonna be able to train a neural network

00:19:55,970 --> 00:20:00,500
to do this the way it should be done

00:19:57,950 --> 00:20:02,510
based on that historical record and so

00:20:00,500 --> 00:20:04,340
once trained though from that historical

00:20:02,510 --> 00:20:08,080
record a neural network can give

00:20:04,340 --> 00:20:11,060
completely new things from from existing

00:20:08,080 --> 00:20:12,740
you can have a new input and it can give

00:20:11,060 --> 00:20:14,480
you a completely new output based on

00:20:12,740 --> 00:20:16,130
that is existing generalization and it's

00:20:14,480 --> 00:20:17,930
likely going to be right in a lot of

00:20:16,130 --> 00:20:21,590
cases it's gonna be 99 plus percent

00:20:17,930 --> 00:20:22,700
right which is incredibly powerful so

00:20:21,590 --> 00:20:25,580
you're essentially talking about

00:20:22,700 --> 00:20:28,550
learning from experience here and so

00:20:25,580 --> 00:20:30,350
this is a slide that kind of shows a toy

00:20:28,550 --> 00:20:33,380
neural network you got a couple of

00:20:30,350 --> 00:20:35,620
different nodes and basically you would

00:20:33,380 --> 00:20:38,360
start your training process by

00:20:35,620 --> 00:20:40,130
randomizing the weights each one of

00:20:38,360 --> 00:20:41,900
those nodes has a weight associated with

00:20:40,130 --> 00:20:43,610
it and it has an algorithm that you put

00:20:41,900 --> 00:20:45,650
in called an activation function that

00:20:43,610 --> 00:20:47,810
that does something with the numbers

00:20:45,650 --> 00:20:49,970
coming in so you have all your data

00:20:47,810 --> 00:20:51,910
going in is in the form of a number

00:20:49,970 --> 00:20:53,990
those numbers get pushed through

00:20:51,910 --> 00:20:55,250
processed by each a neuron and push

00:20:53,990 --> 00:20:56,990
through they're fully connected from

00:20:55,250 --> 00:20:59,180
layered layer every neuron at one layer

00:20:56,990 --> 00:21:01,910
goes to all the neurons the next and you

00:20:59,180 --> 00:21:04,340
push that through and then every neuron

00:21:01,910 --> 00:21:06,110
here accepts all the inputs coming into

00:21:04,340 --> 00:21:09,260
it has the transfer function and then

00:21:06,110 --> 00:21:11,690
activates that back out and so you could

00:21:09,260 --> 00:21:14,630
almost think of this as as trying to

00:21:11,690 --> 00:21:17,330
find the lowest error through the entire

00:21:14,630 --> 00:21:19,400
network to get to achieve your accuracy

00:21:17,330 --> 00:21:20,540
and there are different ways of

00:21:19,400 --> 00:21:21,890
approaching that so you get to the end

00:21:20,540 --> 00:21:23,660
and if you're talking about using back

00:21:21,890 --> 00:21:25,100
propagation which is probably the kind

00:21:23,660 --> 00:21:26,840
of the granddaddy of the algorithms

00:21:25,100 --> 00:21:29,540
applied in the space then it pushes

00:21:26,840 --> 00:21:31,850
those back using that known correct

00:21:29,540 --> 00:21:33,350
number pushes them all the way back

00:21:31,850 --> 00:21:35,000
through and filters into the beginning

00:21:33,350 --> 00:21:36,830
and makes adjustments to those weights

00:21:35,000 --> 00:21:38,480
and then it pushes them back through

00:21:36,830 --> 00:21:41,360
again it goes back and forth and back

00:21:38,480 --> 00:21:42,950
and forth for every row of data you have

00:21:41,360 --> 00:21:44,840
in your set which can be millions as we

00:21:42,950 --> 00:21:47,270
discussed and it's getting better and

00:21:44,840 --> 00:21:50,030
better and reducing that error down and

00:21:47,270 --> 00:21:52,070
eventually after what you're essentially

00:21:50,030 --> 00:21:54,110
doing is this search to find the right

00:21:52,070 --> 00:21:56,030
answer for that you're gonna get to a

00:21:54,110 --> 00:21:58,010
final neural network and if you notice

00:21:56,030 --> 00:21:59,810
the arrows represent the weights that

00:21:58,010 --> 00:22:01,280
are being applied and you could then

00:21:59,810 --> 00:22:02,840
take this tray neural network stick it

00:22:01,280 --> 00:22:04,280
out in the real world take a new data

00:22:02,840 --> 00:22:05,809
for that same kind of problem that the

00:22:04,280 --> 00:22:07,399
network has never seen before

00:22:05,809 --> 00:22:09,109
and it should give you a very very good

00:22:07,399 --> 00:22:11,749
answer for that and that's the

00:22:09,109 --> 00:22:14,239
fundamental way that feed-forward that

00:22:11,749 --> 00:22:17,239
propagation works which is kind of where

00:22:14,239 --> 00:22:20,659
everybody starts and so you could think

00:22:17,239 --> 00:22:23,179
of this as a way of representing all

00:22:20,659 --> 00:22:25,909
these as a set of hierarchies the layers

00:22:23,179 --> 00:22:28,309
are each taking what comes in before and

00:22:25,909 --> 00:22:30,519
creating a new node in that hierarchy

00:22:28,309 --> 00:22:32,840
and so it's really a set of hierarchies

00:22:30,519 --> 00:22:35,139
that the neural network creates they're

00:22:32,840 --> 00:22:37,999
each one conceptual at a different layer

00:22:35,139 --> 00:22:39,109
so these are the common architectures

00:22:37,999 --> 00:22:41,779
that you're going to find we just talked

00:22:39,109 --> 00:22:44,419
about feed-forward networks there's also

00:22:41,779 --> 00:22:45,919
for computer vision and for now other

00:22:44,419 --> 00:22:49,159
applications as well convolutional

00:22:45,919 --> 00:22:50,359
neural networks are amazing there's a

00:22:49,159 --> 00:22:52,279
new one that may replace them called

00:22:50,359 --> 00:22:53,509
capsule networks that a lot of us are

00:22:52,279 --> 00:22:55,309
focused on at this point

00:22:53,509 --> 00:22:57,169
recurrent is great for sequential

00:22:55,309 --> 00:22:59,960
problems that you're trying to solve and

00:22:57,169 --> 00:23:01,759
generative adversarial allow you to

00:22:59,960 --> 00:23:04,159
generate new data by having neural

00:23:01,759 --> 00:23:06,710
networks essentially kind of fight it

00:23:04,159 --> 00:23:08,539
out one creates things and the only the

00:23:06,710 --> 00:23:10,879
other one has to discriminate whether or

00:23:08,539 --> 00:23:13,700
not it's real or not and you you work

00:23:10,879 --> 00:23:15,169
your way into into new outputs through

00:23:13,700 --> 00:23:15,489
the two of those working against each

00:23:15,169 --> 00:23:17,690
other

00:23:15,489 --> 00:23:20,200
I'm gonna go pretty quick because we're

00:23:17,690 --> 00:23:22,820
short on time fundamentally a

00:23:20,200 --> 00:23:26,539
convolutional neural network takes a big

00:23:22,820 --> 00:23:28,519
picture and breaks it down into what you

00:23:26,539 --> 00:23:30,169
can think of as features and eventually

00:23:28,519 --> 00:23:33,049
it can feed that into that feed-forward

00:23:30,169 --> 00:23:35,179
Network and identify what that is going

00:23:33,049 --> 00:23:37,399
beyond that is beyond the scope of our

00:23:35,179 --> 00:23:39,859
time but fundamentally you need lots of

00:23:37,399 --> 00:23:41,629
data and you need lots of computation so

00:23:39,859 --> 00:23:45,019
if you're going to invest in deep

00:23:41,629 --> 00:23:48,559
learning you want to have all of these

00:23:45,019 --> 00:23:49,909
are kind of really startup concepts that

00:23:48,559 --> 00:23:52,129
you want to really do because deep

00:23:49,909 --> 00:23:53,929
learning is definitely an area where

00:23:52,129 --> 00:23:55,309
you're not getting just you know do this

00:23:53,929 --> 00:23:56,929
and you automatically get results you

00:23:55,309 --> 00:24:00,830
have to search your way into getting

00:23:56,929 --> 00:24:01,940
where you want to go so startups or big

00:24:00,830 --> 00:24:04,759
companies that have a start-up mentality

00:24:01,940 --> 00:24:06,589
within team tend to do better than

00:24:04,759 --> 00:24:07,940
others on getting there and there's a

00:24:06,589 --> 00:24:09,619
bunch of questions most of these are

00:24:07,940 --> 00:24:11,599
very typical data science questions that

00:24:09,619 --> 00:24:13,460
you probably have already used even if

00:24:11,599 --> 00:24:15,440
you weren't doing deep learning in terms

00:24:13,460 --> 00:24:17,389
of how you're going to get into this and

00:24:15,440 --> 00:24:19,440
what kind of things you need in place

00:24:17,389 --> 00:24:21,929
I'll let you take a look at that and

00:24:19,440 --> 00:24:23,190
move on and this comes back I mentioned

00:24:21,929 --> 00:24:26,370
earlier that we would come back to this

00:24:23,190 --> 00:24:27,840
you have to start with the fundamental

00:24:26,370 --> 00:24:29,789
problem you're trying to solve and work

00:24:27,840 --> 00:24:32,250
your way into what is the right deep

00:24:29,789 --> 00:24:34,470
learning solution that you're trying to

00:24:32,250 --> 00:24:36,809
get to so you want to analyze the

00:24:34,470 --> 00:24:38,070
problem statement can you solve the

00:24:36,809 --> 00:24:40,740
problem with simpler or less expensive

00:24:38,070 --> 00:24:41,970
tools because sometimes deep learning is

00:24:40,740 --> 00:24:43,679
not the right solution there may be

00:24:41,970 --> 00:24:45,169
other machine learning solutions that

00:24:43,679 --> 00:24:49,200
are much quicker to get to without the

00:24:45,169 --> 00:24:51,750
investment so deep learning can be

00:24:49,200 --> 00:24:53,610
expensive to scale it's if once you get

00:24:51,750 --> 00:24:56,250
into large datasets and processing on

00:24:53,610 --> 00:24:58,710
those for complex problems your training

00:24:56,250 --> 00:25:00,149
cost can quickly spiral and I know

00:24:58,710 --> 00:25:02,820
somebody who accidentally spent a

00:25:00,149 --> 00:25:03,990
hundred thousand dollars out of budget

00:25:02,820 --> 00:25:05,970
he I think he had a ten thousand dollar

00:25:03,990 --> 00:25:07,289
budget for a small project and he left

00:25:05,970 --> 00:25:08,460
something overnight and came back and

00:25:07,289 --> 00:25:11,879
you'd spend a hundred grand

00:25:08,460 --> 00:25:13,830
so that was fairly painful it really

00:25:11,879 --> 00:25:16,620
requires a strategic investment from

00:25:13,830 --> 00:25:18,389
your leadership team and you really need

00:25:16,620 --> 00:25:20,759
to recruit the very best people you can

00:25:18,389 --> 00:25:22,710
find and train the people that you have

00:25:20,759 --> 00:25:23,789
so that you can get into this that

00:25:22,710 --> 00:25:26,220
requires that you have that learning

00:25:23,789 --> 00:25:27,690
culture and you need a mixture of

00:25:26,220 --> 00:25:30,179
different skills not just data

00:25:27,690 --> 00:25:32,220
scientists the teams that I've run have

00:25:30,179 --> 00:25:34,710
had been very eclectic in terms of what

00:25:32,220 --> 00:25:36,000
their capabilities were and that means

00:25:34,710 --> 00:25:37,710
you need someone who knows deep learning

00:25:36,000 --> 00:25:40,289
not all data scientists are familiar

00:25:37,710 --> 00:25:41,309
with it so you need to make sure you

00:25:40,289 --> 00:25:44,250
have your data and have your data

00:25:41,309 --> 00:25:47,820
strategy in place you need lots of data

00:25:44,250 --> 00:25:50,190
lots of computation as I noted and then

00:25:47,820 --> 00:25:55,049
going through with the sorry about that

00:25:50,190 --> 00:25:58,080
I think I'm going you need an executable

00:25:55,049 --> 00:25:59,820
AI strategy as a prerequisite if you

00:25:58,080 --> 00:26:02,429
don't have your AI if you don't have

00:25:59,820 --> 00:26:05,549
your data strategy for your AI strategy

00:26:02,429 --> 00:26:07,259
then you are going to feel a lot of pain

00:26:05,549 --> 00:26:09,779
and if there's one thing that I've run

00:26:07,259 --> 00:26:11,789
into more often than anything else with

00:26:09,779 --> 00:26:12,870
other teams and with customers it's that

00:26:11,789 --> 00:26:14,460
they didn't figure out their data

00:26:12,870 --> 00:26:17,340
strategy ahead of time so they're a a

00:26:14,460 --> 00:26:20,669
strategy would work so that's where most

00:26:17,340 --> 00:26:23,460
organizations fail so get that in order

00:26:20,669 --> 00:26:26,149
have a process it's really no different

00:26:23,460 --> 00:26:28,919
from any other data science process

00:26:26,149 --> 00:26:32,780
feature engineering model selection

00:26:28,919 --> 00:26:35,210
model training make sure that your

00:26:32,780 --> 00:26:36,970
software and systems were able to do

00:26:35,210 --> 00:26:40,400
what it is that you need them to do and

00:26:36,970 --> 00:26:41,870
that you have a deployment strategy and

00:26:40,400 --> 00:26:44,870
this is really where I want to finish is

00:26:41,870 --> 00:26:47,900
that when we get to deployment things

00:26:44,870 --> 00:26:50,900
get difficult for me when I was at both

00:26:47,900 --> 00:26:52,940
Accenture and Honeywell we had a fairly

00:26:50,900 --> 00:26:56,860
standard environment that we were able

00:26:52,940 --> 00:26:59,150
to operate in the usual cloud providers

00:26:56,860 --> 00:27:01,910
at Honeywell we also had our own

00:26:59,150 --> 00:27:05,450
hardware that we could use and we had a

00:27:01,910 --> 00:27:07,370
bunch of great frameworks with which we

00:27:05,450 --> 00:27:11,030
could actually go and we'd use

00:27:07,370 --> 00:27:12,560
tensorflow more recently pi torch and

00:27:11,030 --> 00:27:14,510
some of the others and it really

00:27:12,560 --> 00:27:16,630
depended on who on the team wanted to do

00:27:14,510 --> 00:27:20,360
what and we could we could get there but

00:27:16,630 --> 00:27:22,130
and that was pretty amazing that those

00:27:20,360 --> 00:27:24,350
frameworks were starting off with you

00:27:22,130 --> 00:27:28,160
know doctor and kubernetes standard the

00:27:24,350 --> 00:27:31,300
usual cloud technologies but even though

00:27:28,160 --> 00:27:33,890
your open source tools are democratizing

00:27:31,300 --> 00:27:36,770
your accessibility to these technologies

00:27:33,890 --> 00:27:39,920
when you got to deployment that is where

00:27:36,770 --> 00:27:42,020
things got difficult we would get to

00:27:39,920 --> 00:27:44,180
where we were deploying to one vendors

00:27:42,020 --> 00:27:46,520
edge devices or another vendors edge

00:27:44,180 --> 00:27:48,170
devices and and I don't want to I don't

00:27:46,520 --> 00:27:51,140
want to call names out but as we move

00:27:48,170 --> 00:27:54,050
from vendor to vendor we found that we

00:27:51,140 --> 00:27:55,280
had to completely relearn or re-engineer

00:27:54,050 --> 00:27:57,290
how we were approaching it sometimes

00:27:55,280 --> 00:27:59,000
we'd actually go back and have to move

00:27:57,290 --> 00:28:01,190
our models from one open-source

00:27:59,000 --> 00:28:02,900
framework into another one because the

00:28:01,190 --> 00:28:05,750
vendor be supported it vendor a

00:28:02,900 --> 00:28:07,970
supported that one and so I think if

00:28:05,750 --> 00:28:10,130
there's one thing as we finish up that I

00:28:07,970 --> 00:28:12,500
have been hoping for for the better part

00:28:10,130 --> 00:28:14,630
of the last year maybe year and a half

00:28:12,500 --> 00:28:17,270
it's that we would get better vendor

00:28:14,630 --> 00:28:19,310
support for being able to take advantage

00:28:17,270 --> 00:28:22,250
of the optimizations that everyone's

00:28:19,310 --> 00:28:24,080
hardware could do we people are putting

00:28:22,250 --> 00:28:26,660
the acceleration in there supporting

00:28:24,080 --> 00:28:30,710
certain frameworks and not others and so

00:28:26,660 --> 00:28:33,020
my my vision as we close out of rainbows

00:28:30,710 --> 00:28:35,930
and unicorns is having a deployment

00:28:33,020 --> 00:28:38,900
environment that allows us to go through

00:28:35,930 --> 00:28:40,700
less pain and more of a common unified

00:28:38,900 --> 00:28:42,380
way so that so I wanted to finish this

00:28:40,700 --> 00:28:45,590
talk as I talked to this particular

00:28:42,380 --> 00:28:46,610
group and say I hope that you will go

00:28:45,590 --> 00:28:48,020
out and

00:28:46,610 --> 00:28:50,299
and those of us who are working in the

00:28:48,020 --> 00:28:52,040
space help us get there a little bit

00:28:50,299 --> 00:28:53,809
easier and a little bit better and we

00:28:52,040 --> 00:28:56,660
may have it have some interesting

00:28:53,809 --> 00:28:58,580
conversations today about that having

00:28:56,660 --> 00:29:00,770
said that I just want to say I welcome

00:28:58,580 --> 00:29:03,049
you to listen to my podcast there it is

00:29:00,770 --> 00:29:04,520
and if you have an interesting story see

00:29:03,049 --> 00:29:06,920
me afterwards and we'd love to get you

00:29:04,520 --> 00:29:15,140
on and that's it thank you very much for

00:29:06,920 --> 00:29:16,910
listening we we have time for a question

00:29:15,140 --> 00:29:19,549
if anyone would like to ask a question

00:29:16,910 --> 00:29:36,169
yes I'm gonna get some water as we talk

00:29:19,549 --> 00:29:40,160
yeah yeah so can you say that given a

00:29:36,169 --> 00:29:46,250
problem how would you define how wide

00:29:40,160 --> 00:29:48,169
and deep so when you go back to the the

00:29:46,250 --> 00:29:50,330
process slides and I know given the time

00:29:48,169 --> 00:29:51,950
I'll skip through very very quickly sure

00:29:50,330 --> 00:29:53,500
sure but when you're analyzing the

00:29:51,950 --> 00:29:57,549
problem and you'll you will

00:29:53,500 --> 00:29:59,660
realistically you will come up with a

00:29:57,549 --> 00:30:01,640
candidate which is probably very much

00:29:59,660 --> 00:30:03,679
like somebody else before you has we do

00:30:01,640 --> 00:30:05,480
a lot of transfer learning and so you'll

00:30:03,679 --> 00:30:07,880
you'll say HM I have a problem how

00:30:05,480 --> 00:30:09,320
people solve that before you go find a

00:30:07,880 --> 00:30:10,640
model where people live written about

00:30:09,320 --> 00:30:12,590
what they've done and do that and

00:30:10,640 --> 00:30:14,090
generally speaking if you're lucky it

00:30:12,590 --> 00:30:15,350
might work but more often than not it

00:30:14,090 --> 00:30:16,790
doesn't work quite as well as you want

00:30:15,350 --> 00:30:18,290
so you keep iterating and then you start

00:30:16,790 --> 00:30:21,320
saying what makes my problem different

00:30:18,290 --> 00:30:23,360
from theirs and you start saying okay I

00:30:21,320 --> 00:30:25,340
have these layers in this architecture

00:30:23,360 --> 00:30:27,049
that serve these purposes so it's it's

00:30:25,340 --> 00:30:27,470
it's an engineering question as what it

00:30:27,049 --> 00:30:30,110
becomes

00:30:27,470 --> 00:30:31,640
it's saying if as I separate the

00:30:30,110 --> 00:30:35,390
requirements this model that I'm

00:30:31,640 --> 00:30:36,770
transferring in to utilize did and I

00:30:35,390 --> 00:30:38,720
have this problem over here what makes

00:30:36,770 --> 00:30:40,610
it different and then I start adding or

00:30:38,720 --> 00:30:43,130
subtracting parts to the architecture

00:30:40,610 --> 00:30:44,600
that allow me to get closer to that set

00:30:43,130 --> 00:30:46,040
of requirements and then it's trial and

00:30:44,600 --> 00:30:49,000
error you go back and back and back and

00:30:46,040 --> 00:30:51,380
try until you get there that answer

00:30:49,000 --> 00:30:53,059
thank you all right thank you very much

00:30:51,380 --> 00:30:54,950
Chris thank you so much Chris is gonna

00:30:53,059 --> 00:30:56,929
be around for the rest of the day you

00:30:54,950 --> 00:30:58,130
know and try not to stand on his foot

00:30:56,929 --> 00:31:07,580
which I nearly did

00:30:58,130 --> 00:31:09,890
okay thank you very much right it is my

00:31:07,580 --> 00:31:13,640
very great privilege and honor to

00:31:09,890 --> 00:31:17,450
introduce an old chum of mine Jim Davies

00:31:13,640 --> 00:31:20,390
who has more titles than I have he's a

00:31:17,450 --> 00:31:22,370
fellow he's a VP and he's general

00:31:20,390 --> 00:31:26,270
manager of the machine learning group in

00:31:22,370 --> 00:31:30,080
on so Jim's gonna come and talk to us

00:31:26,270 --> 00:31:32,510
about well guess well stuff yes do come

00:31:30,080 --> 00:31:37,210
over here old chap I think this is still

00:31:32,510 --> 00:31:41,480
the same one this the button we need

00:31:37,210 --> 00:31:44,360
yeah that works right technology right

00:31:41,480 --> 00:31:47,030
good man nursey nursey will be along

00:31:44,360 --> 00:31:49,820
later to help you out so good morning

00:31:47,030 --> 00:31:52,970
everybody my name is Jim Davis as Dave

00:31:49,820 --> 00:31:55,880
reeling says a long long time ago in a

00:31:52,970 --> 00:31:58,580
galaxy far far away he persuaded me to

00:31:55,880 --> 00:32:00,890
join a company called arm where I was a

00:31:58,580 --> 00:32:02,390
Linux kernel hacker and and the stories

00:32:00,890 --> 00:32:05,960
that are told of those times

00:32:02,390 --> 00:32:07,880
tragically are mostly true more years

00:32:05,960 --> 00:32:08,330
have passed now than either of us cares

00:32:07,880 --> 00:32:10,370
to admit

00:32:08,330 --> 00:32:12,230
and now I'm an armed fellow and recently

00:32:10,370 --> 00:32:15,110
I took over as general manager of the

00:32:12,230 --> 00:32:16,700
arms machine learning group what am I

00:32:15,110 --> 00:32:18,320
doing here today apart from reminiscing

00:32:16,700 --> 00:32:20,150
with an old buddy and drinking too much

00:32:18,320 --> 00:32:23,330
in the bath I'm here to talk to you

00:32:20,150 --> 00:32:24,470
about steps we are taking to enable

00:32:23,330 --> 00:32:27,770
developers to use machine learning

00:32:24,470 --> 00:32:30,679
across the widest variety of ARM based

00:32:27,770 --> 00:32:33,350
platforms to enable us to take advantage

00:32:30,679 --> 00:32:36,320
of these great technology that Chris was

00:32:33,350 --> 00:32:37,820
talking about it will empower so quickly

00:32:36,320 --> 00:32:39,409
I think I agreed with several of the

00:32:37,820 --> 00:32:42,470
things he said but I'll have to think

00:32:39,409 --> 00:32:45,740
about it later to see I think he set me

00:32:42,470 --> 00:32:47,690
up rather nicely for this talk how will

00:32:45,740 --> 00:32:49,520
we do this well we're going to do this

00:32:47,690 --> 00:32:52,429
by driving the definitions of open

00:32:49,520 --> 00:32:55,460
standards in this area and collaborating

00:32:52,429 --> 00:32:56,890
with you the best in the industry in

00:32:55,460 --> 00:33:02,600
open source

00:32:56,890 --> 00:33:04,039
damn it works so what's happening

00:33:02,600 --> 00:33:05,809
machine learning changing incredibly

00:33:04,039 --> 00:33:07,610
fast as Chris was talking about it's a

00:33:05,809 --> 00:33:09,190
field of really you know many many

00:33:07,610 --> 00:33:11,590
moving parts but

00:33:09,190 --> 00:33:13,900
we believe the time is right when key

00:33:11,590 --> 00:33:16,960
areas and applications and use cases are

00:33:13,900 --> 00:33:19,810
starting to stabilize and now is the

00:33:16,960 --> 00:33:21,400
time is now right for collaboration

00:33:19,810 --> 00:33:23,770
I want to thank George for his keynotes

00:33:21,400 --> 00:33:25,660
on Monday and in that you'll have seen

00:33:23,770 --> 00:33:27,940
that the Naro announced a new machine

00:33:25,660 --> 00:33:30,220
learning intelligence initiative that

00:33:27,940 --> 00:33:33,910
Army's going to be part of and I'll talk

00:33:30,220 --> 00:33:35,560
a bit about what part means this

00:33:33,910 --> 00:33:37,420
initiative Google announced their

00:33:35,560 --> 00:33:39,220
endorsement of this with a statement and

00:33:37,420 --> 00:33:41,530
I quote the tensor phloem is a

00:33:39,220 --> 00:33:43,450
tensorflow team is excited to expand

00:33:41,530 --> 00:33:44,980
support for edge devices and we're

00:33:43,450 --> 00:33:47,410
looking forward to integrating with the

00:33:44,980 --> 00:33:49,390
Army nn library right well as it clue

00:33:47,410 --> 00:33:51,340
what are we doing we're getting involved

00:33:49,390 --> 00:33:53,410
we're collaborating with all of the

00:33:51,340 --> 00:33:56,710
companies to define these open standards

00:33:53,410 --> 00:33:58,660
to support this machine learning to be

00:33:56,710 --> 00:34:02,500
rolled out across a wide variety of

00:33:58,660 --> 00:34:05,650
platforms in addition we're donating a

00:34:02,500 --> 00:34:07,330
huge body of code to bootstrap this

00:34:05,650 --> 00:34:11,500
initiative and I'm going to talk about

00:34:07,330 --> 00:34:15,460
that body of code in this talk although

00:34:11,500 --> 00:34:17,770
we were already open source under at MIT

00:34:15,460 --> 00:34:20,860
license with donating arm an end to the

00:34:17,770 --> 00:34:23,879
learn ro machine learning initiative arm

00:34:20,860 --> 00:34:26,860
NN is an inference engine designed for

00:34:23,879 --> 00:34:29,110
efficient inference running at the edge

00:34:26,860 --> 00:34:33,460
on the sort of devices we all work on

00:34:29,110 --> 00:34:35,080
and following really quite significant

00:34:33,460 --> 00:34:37,600
pull from a number of companies working

00:34:35,080 --> 00:34:39,220
in this space and developers who wanted

00:34:37,600 --> 00:34:41,679
to get involved and contribute to this

00:34:39,220 --> 00:34:43,480
project we decided that Lennar o is the

00:34:41,679 --> 00:34:45,520
best place for that collaboration to

00:34:43,480 --> 00:34:48,550
happen so we're donating it to the

00:34:45,520 --> 00:34:50,800
initiative remains under at MIT license

00:34:48,550 --> 00:34:52,870
it's very permissive license and we

00:34:50,800 --> 00:34:56,020
encourage contributions from everybody

00:34:52,870 --> 00:34:58,420
that governance will be organized by

00:34:56,020 --> 00:35:02,500
Lynne ro we think this is the right

00:34:58,420 --> 00:35:04,270
thing to do we will continue to work on

00:35:02,500 --> 00:35:06,940
it there will be massive contributions

00:35:04,270 --> 00:35:09,460
from us continuing we are moving all of

00:35:06,940 --> 00:35:10,960
our development into the open so if you

00:35:09,460 --> 00:35:14,580
don't want to see how sausages get made

00:35:10,960 --> 00:35:14,580
I suggest you stay well away

00:35:14,740 --> 00:35:20,869
so I think by now particularly after the

00:35:19,250 --> 00:35:23,240
previous presentation nobody would doubt

00:35:20,869 --> 00:35:25,130
the effect that ml is having and will

00:35:23,240 --> 00:35:27,320
continue to have on all of the things

00:35:25,130 --> 00:35:29,930
we're working on notwithstanding the

00:35:27,320 --> 00:35:32,570
absolute massive hype and Chris you may

00:35:29,930 --> 00:35:33,830
have noticed that Gartner put machine

00:35:32,570 --> 00:35:36,440
learning at the absolute peak of

00:35:33,830 --> 00:35:38,869
inflated expectations I paid good money

00:35:36,440 --> 00:35:40,910
for Gartland come in and present the

00:35:38,869 --> 00:35:42,290
Gartner hype cycle to us and then they

00:35:40,910 --> 00:35:44,510
put machine learning at the peak of

00:35:42,290 --> 00:35:47,600
inflated expectations so imagine my

00:35:44,510 --> 00:35:49,910
disappointment but but but actually if

00:35:47,600 --> 00:35:53,510
you're right ignore all the hype if you

00:35:49,910 --> 00:35:56,570
get through it we will see that ml is

00:35:53,510 --> 00:36:01,369
enabling key new use cases and also

00:35:56,570 --> 00:36:04,460
massively improving existing ones and in

00:36:01,369 --> 00:36:07,750
something that is perhaps surprising to

00:36:04,460 --> 00:36:10,220
some of us if not all we're seeing this

00:36:07,750 --> 00:36:12,800
actually across the full spectrum of

00:36:10,220 --> 00:36:14,990
devices right from very basic cortex-m

00:36:12,800 --> 00:36:17,540
microcontrollers through codex a through

00:36:14,990 --> 00:36:21,260
GPUs and also dedicated neural network

00:36:17,540 --> 00:36:23,300
processors it is probably easier to try

00:36:21,260 --> 00:36:25,940
to list the segments that aren't using

00:36:23,300 --> 00:36:28,040
machine learning an experiment that I

00:36:25,940 --> 00:36:28,400
was recommended and I recommend it to

00:36:28,040 --> 00:36:31,660
you

00:36:28,400 --> 00:36:34,310
is think of any classical method of of

00:36:31,660 --> 00:36:36,890
processing algorithms whatever and just

00:36:34,310 --> 00:36:38,359
take them type that in and add machine

00:36:36,890 --> 00:36:40,490
learning and then put that into Google

00:36:38,359 --> 00:36:42,260
and you'll find a whole range of

00:36:40,490 --> 00:36:44,630
research papers coming out where people

00:36:42,260 --> 00:36:45,920
have tried the most bizarre topics and

00:36:44,630 --> 00:36:49,960
replace them with the machine learning

00:36:45,920 --> 00:36:52,430
implementation my personal favorite is

00:36:49,960 --> 00:36:54,500
intercontinental ballistic missiles it's

00:36:52,430 --> 00:36:56,810
actually very difficult controlled plane

00:36:54,500 --> 00:36:58,280
problem and very few countries have

00:36:56,810 --> 00:37:00,050
actually ever got it right

00:36:58,280 --> 00:37:02,720
controlling rockets by setting you know

00:37:00,050 --> 00:37:04,640
lighting a very very big fire at one end

00:37:02,720 --> 00:37:06,440
and then moving the other end of it it

00:37:04,640 --> 00:37:08,780
turns out to be remarkably hard to do

00:37:06,440 --> 00:37:11,720
all you need to do is write a model of

00:37:08,780 --> 00:37:14,359
that system crash about four trillion

00:37:11,720 --> 00:37:16,580
Rockets and then you can have a machine

00:37:14,359 --> 00:37:18,740
learning process run that for you it's

00:37:16,580 --> 00:37:21,080
just extraordinary the things you can

00:37:18,740 --> 00:37:23,510
apply this to quite successfully and get

00:37:21,080 --> 00:37:25,369
better results for many values of the

00:37:23,510 --> 00:37:26,440
word better cheaper faster more

00:37:25,369 --> 00:37:30,220
optimized

00:37:26,440 --> 00:37:32,500
you know you name it you get it I've

00:37:30,220 --> 00:37:34,240
listed a few on this slide I don't think

00:37:32,500 --> 00:37:35,829
really I need to go through and I think

00:37:34,240 --> 00:37:37,869
you all know them autonomous driving

00:37:35,829 --> 00:37:41,380
czar only ever really going to take off

00:37:37,869 --> 00:37:43,569
successfully once in technological terms

00:37:41,380 --> 00:37:44,980
there are many litigation and liability

00:37:43,569 --> 00:37:47,109
issues to celebrating technological

00:37:44,980 --> 00:37:50,290
terms once the ml advances become

00:37:47,109 --> 00:37:52,059
mainstream both in the classical sort of

00:37:50,290 --> 00:37:53,980
object detection and segmentation but

00:37:52,059 --> 00:37:56,500
also the cognition that goes into it

00:37:53,980 --> 00:37:58,569
face identification really only got

00:37:56,500 --> 00:38:01,030
critically reliable once we apply to

00:37:58,569 --> 00:38:03,490
airmailed techniques speech recognitions

00:38:01,030 --> 00:38:05,410
gone from you know isolated key word

00:38:03,490 --> 00:38:07,690
recognition through to being able to

00:38:05,410 --> 00:38:10,540
analyze continuous streams of speech

00:38:07,690 --> 00:38:12,910
using a very small percentage of the cpu

00:38:10,540 --> 00:38:15,220
budget on sort of mobile devices you

00:38:12,910 --> 00:38:17,859
know huge improvements in any existing

00:38:15,220 --> 00:38:19,510
capabilities and image processing I

00:38:17,859 --> 00:38:21,880
think is going to be a huge thing in the

00:38:19,510 --> 00:38:23,980
consumer field it's actually if you

00:38:21,880 --> 00:38:26,140
think about it it's an ideal target

00:38:23,980 --> 00:38:27,010
because what do we want we want things

00:38:26,140 --> 00:38:30,359
to look good

00:38:27,010 --> 00:38:32,799
can we actually define good in

00:38:30,359 --> 00:38:35,170
algorithms that say I'll take this pixel

00:38:32,799 --> 00:38:37,510
sharpen that bring down the gamma do

00:38:35,170 --> 00:38:40,960
this do that no we can't actually it's

00:38:37,510 --> 00:38:42,849
completely heuristic method so it's

00:38:40,960 --> 00:38:44,530
ideal for putting vast quantities of

00:38:42,849 --> 00:38:46,390
images up getting people to vote on

00:38:44,530 --> 00:38:48,640
whether they like them or not and having

00:38:46,390 --> 00:38:50,799
those images processed in a way that

00:38:48,640 --> 00:38:55,089
makes us feel oh that's nice

00:38:50,799 --> 00:38:57,099
well buy that one not that one a neat

00:38:55,089 --> 00:38:59,770
side effect is there something that I

00:38:57,099 --> 00:39:01,329
was working on before in the image

00:38:59,770 --> 00:39:03,460
processing field which is actually

00:39:01,329 --> 00:39:05,680
different groups of people have

00:39:03,460 --> 00:39:08,349
different ideas about what good looks

00:39:05,680 --> 00:39:12,069
like there's a body of work being done

00:39:08,349 --> 00:39:14,680
to look at genetic disposition towards

00:39:12,069 --> 00:39:17,319
perceiving color and image in different

00:39:14,680 --> 00:39:19,630
ways for example this just falls out

00:39:17,319 --> 00:39:23,530
yeah you just go yeah I'll have that

00:39:19,630 --> 00:39:24,790
version please it could I could go on we

00:39:23,530 --> 00:39:27,220
could be here a week with me talking

00:39:24,790 --> 00:39:29,559
about applications that are possibly

00:39:27,220 --> 00:39:31,170
slightly less exciting like logistics

00:39:29,559 --> 00:39:33,369
and distribution and things like this

00:39:31,170 --> 00:39:34,839
but one thing I bring out from all of

00:39:33,369 --> 00:39:37,299
these things is that all of these are

00:39:34,839 --> 00:39:38,180
decisions where the data is available at

00:39:37,299 --> 00:39:40,520
the edge

00:39:38,180 --> 00:39:42,049
if training is a problem which is solved

00:39:40,520 --> 00:39:45,079
where you have large quantities of

00:39:42,049 --> 00:39:47,630
example data high quality annotated data

00:39:45,079 --> 00:39:51,760
then inference is something that you

00:39:47,630 --> 00:39:53,930
want to do near the test data and

00:39:51,760 --> 00:39:57,470
generally speaking that is at the age on

00:39:53,930 --> 00:40:00,940
battery powered devices which curiously

00:39:57,470 --> 00:40:00,940
enough is something we care about a lot

00:40:05,190 --> 00:40:10,930
technology so if we look at machine

00:40:09,250 --> 00:40:12,760
learning and look at the challenges

00:40:10,930 --> 00:40:15,220
associated with it and Chris talked

00:40:12,760 --> 00:40:18,450
about some of this in his talk we have

00:40:15,220 --> 00:40:18,450
problems in different domains

00:40:18,840 --> 00:40:23,350
ok that's slightly scary please don't do

00:40:21,400 --> 00:40:26,770
that again

00:40:23,350 --> 00:40:28,930
you could be an m/l domain expert you

00:40:26,770 --> 00:40:31,210
know data scientist or somebody working

00:40:28,930 --> 00:40:33,310
in ML frameworks of researcher you could

00:40:31,210 --> 00:40:35,650
be a problem domain expert you could be

00:40:33,310 --> 00:40:37,870
a doctor you know a logistics planner

00:40:35,650 --> 00:40:40,570
you could be a computational linguist or

00:40:37,870 --> 00:40:42,130
you could be a platform expert and at

00:40:40,570 --> 00:40:43,660
the moment you've got a situation where

00:40:42,130 --> 00:40:45,250
some sort of domain experts are

00:40:43,660 --> 00:40:48,250
providing their knowledge and expertise

00:40:45,250 --> 00:40:50,290
to the Emerald researchers and to allow

00:40:48,250 --> 00:40:51,910
some experts to interpret the data but

00:40:50,290 --> 00:40:53,320
there's this sort of knowledge and

00:40:51,910 --> 00:40:55,300
expertise transfer between these

00:40:53,320 --> 00:40:57,420
different debates it's not working well

00:40:55,300 --> 00:41:00,250
and it is holding us back

00:40:57,420 --> 00:41:02,770
Lenora is obviously the meeting ground

00:41:00,250 --> 00:41:04,780
for the third pillar the third domain

00:41:02,770 --> 00:41:07,240
expertise which are the platform experts

00:41:04,780 --> 00:41:10,030
we are the ones who need to get our

00:41:07,240 --> 00:41:12,250
heads around chris's final problem which

00:41:10,030 --> 00:41:15,610
is enabling ml across the wide variety

00:41:12,250 --> 00:41:17,500
of ARM based platforms and obviously

00:41:15,610 --> 00:41:19,210
armies committed to working on this part

00:41:17,500 --> 00:41:22,800
of the problem and in fact I've been

00:41:19,210 --> 00:41:25,090
working on it for the last few years

00:41:22,800 --> 00:41:26,950
most of the use cases I talked about

00:41:25,090 --> 00:41:29,710
there and I think they yeah that is

00:41:26,950 --> 00:41:32,170
actually legible they run on CPUs and

00:41:29,710 --> 00:41:34,300
GPUs today but we're going to need to

00:41:32,170 --> 00:41:35,470
transition some of those to working on

00:41:34,300 --> 00:41:39,250
other types of processes and

00:41:35,470 --> 00:41:41,010
accelerators and those accelerators are

00:41:39,250 --> 00:41:43,090
not going to be a one-size-fits-all

00:41:41,010 --> 00:41:44,710
problem we're going to need different

00:41:43,090 --> 00:41:46,450
accelerators to solve different

00:41:44,710 --> 00:41:50,470
computational problems in different

00:41:46,450 --> 00:41:52,450
markets so naturally you know as a

00:41:50,470 --> 00:41:54,220
software engineer or at least was once a

00:41:52,450 --> 00:41:56,800
software engineer you know I reach into

00:41:54,220 --> 00:41:58,210
my toolkit of things to deal with this

00:41:56,800 --> 00:42:01,390
and I come up with a software

00:41:58,210 --> 00:42:03,040
abstraction we've got lots of machine

00:42:01,390 --> 00:42:05,110
learning being run on arm platforms

00:42:03,040 --> 00:42:07,600
today we've got lots of new use cases

00:42:05,110 --> 00:42:09,580
coming along we've got some people

00:42:07,600 --> 00:42:11,800
running perfectly happily on CPUs and

00:42:09,580 --> 00:42:13,710
GPUs today we've got some people who are

00:42:11,800 --> 00:42:15,540
never going to need

00:42:13,710 --> 00:42:18,000
a neural network accelerator and we've

00:42:15,540 --> 00:42:19,589
got some people that do and we know that

00:42:18,000 --> 00:42:21,869
we can't rely on the cloud in this

00:42:19,589 --> 00:42:24,170
situation because it's inappropriate for

00:42:21,869 --> 00:42:26,609
a bunch of reasons I'll talk about next

00:42:24,170 --> 00:42:29,430
but you're going to want to run more

00:42:26,609 --> 00:42:30,900
efficiently on future devices you're

00:42:29,430 --> 00:42:32,940
going to want to run workloads between

00:42:30,900 --> 00:42:34,470
different parts of the device you're

00:42:32,940 --> 00:42:37,260
going to want to run workloads between

00:42:34,470 --> 00:42:39,150
different devices and we need to work

00:42:37,260 --> 00:42:43,410
move workloads between the different

00:42:39,150 --> 00:42:46,200
accelerators there's a whole heap of

00:42:43,410 --> 00:42:48,930
choice here that nan experts in this

00:42:46,200 --> 00:42:51,960
field are currently failing with we need

00:42:48,930 --> 00:42:54,210
to make that easy for them if we are to

00:42:51,960 --> 00:42:56,160
get the benefit of bringing ml

00:42:54,210 --> 00:43:00,270
techniques to the sort of devices that

00:42:56,160 --> 00:43:02,430
we build and standard software inference

00:43:00,270 --> 00:43:06,420
engines is going to be part of that

00:43:02,430 --> 00:43:09,119
problem I talked about running software

00:43:06,420 --> 00:43:10,640
at the edge and why I thought the cloud

00:43:09,119 --> 00:43:12,990
wasn't the right answer for everything

00:43:10,640 --> 00:43:14,190
it's instructive perhaps to look at a

00:43:12,990 --> 00:43:17,220
little bit of history here

00:43:14,190 --> 00:43:19,410
most of the ml research has been done by

00:43:17,220 --> 00:43:22,109
people who had a hiker scale data center

00:43:19,410 --> 00:43:24,720
out the back so the obvious tool to use

00:43:22,109 --> 00:43:27,630
to solve their ml problems was the hyper

00:43:24,720 --> 00:43:31,109
scale data center but actually there are

00:43:27,630 --> 00:43:33,390
very solid reasons why that isn't gonna

00:43:31,109 --> 00:43:34,710
work for all examples clearly gonna work

00:43:33,390 --> 00:43:37,230
for some it's clear working for some

00:43:34,710 --> 00:43:40,680
today but in the future there are three

00:43:37,230 --> 00:43:43,349
primary reasons why there are pressures

00:43:40,680 --> 00:43:45,780
to move that to processing at the edge

00:43:43,349 --> 00:43:48,570
laws of physics laws of economics

00:43:45,780 --> 00:43:51,660
actually the bits of economics I believe

00:43:48,570 --> 00:43:54,750
in and the laws of the land in several

00:43:51,660 --> 00:43:57,930
jurisdictions so if we look at the laws

00:43:54,750 --> 00:44:00,330
of physics first of all bandwidth there

00:43:57,930 --> 00:44:03,300
is not enough bandwidth in the world

00:44:00,330 --> 00:44:06,420
we're talking about upwards of billions

00:44:03,300 --> 00:44:08,580
possibly a trillion my new boss Massa

00:44:06,420 --> 00:44:10,800
who runs Softbank talk meaningfully

00:44:08,580 --> 00:44:13,109
about a trillion IOT connected IOT

00:44:10,800 --> 00:44:17,040
devices I can't count that far but it's

00:44:13,109 --> 00:44:18,330
going to be a big number many of them

00:44:17,040 --> 00:44:19,770
are going to have high resolution video

00:44:18,330 --> 00:44:22,369
cameras at

00:44:19,770 --> 00:44:25,500
connecting half-trillion

00:44:22,369 --> 00:44:27,300
devices and sending continuous video

00:44:25,500 --> 00:44:30,680
stream up to a data center in Seattle

00:44:27,300 --> 00:44:33,119
having it processed there or in some

00:44:30,680 --> 00:44:35,040
data center of your choice submerged

00:44:33,119 --> 00:44:37,200
under the sea off Iceland whatever and

00:44:35,040 --> 00:44:39,030
then send it all back again it's just

00:44:37,200 --> 00:44:41,430
not going to work the internet will

00:44:39,030 --> 00:44:45,510
break there is not that much bandwidth

00:44:41,430 --> 00:44:47,040
in the world power increasingly of

00:44:45,510 --> 00:44:49,890
course as we get into modern devices

00:44:47,040 --> 00:44:51,300
it's more power expensive to transmit

00:44:49,890 --> 00:44:53,850
the data than it is to compute it

00:44:51,300 --> 00:44:55,800
locally and that's before we start

00:44:53,850 --> 00:44:58,109
looking at the power consumption of

00:44:55,800 --> 00:44:59,880
these huge data centers you know the

00:44:58,109 --> 00:45:01,350
power problem for us you know we have

00:44:59,880 --> 00:45:02,910
some power problems we understand about

00:45:01,350 --> 00:45:04,920
batteries and things like that they have

00:45:02,910 --> 00:45:06,300
similar power problems but even or not

00:45:04,920 --> 00:45:08,430
it's actually almost impossible to get

00:45:06,300 --> 00:45:10,230
more than 10 kilowatts into a rack full

00:45:08,430 --> 00:45:11,820
of computers and then take the 10

00:45:10,230 --> 00:45:13,170
kilowatts of heat out it's almost

00:45:11,820 --> 00:45:15,030
impossible to get more than a megawatt

00:45:13,170 --> 00:45:17,160
into a shipping container and get it out

00:45:15,030 --> 00:45:18,570
again you know they have serious power

00:45:17,160 --> 00:45:21,359
problems and then of course you have to

00:45:18,570 --> 00:45:23,100
buy that much power stop me later and

00:45:21,359 --> 00:45:25,859
I'll tell you about the bloke who wanted

00:45:23,100 --> 00:45:29,550
to run the human genome project and got

00:45:25,859 --> 00:45:33,260
told to build a power station so yeah

00:45:29,550 --> 00:45:35,100
the power is it is significant latency

00:45:33,260 --> 00:45:37,320
we're accustomed to talking about

00:45:35,100 --> 00:45:38,640
latency as a user experience problem you

00:45:37,320 --> 00:45:40,230
know we all hate it when the thing

00:45:38,640 --> 00:45:42,930
doesn't seem to respond to us you watch

00:45:40,230 --> 00:45:44,820
me struggling hear it but actually

00:45:42,930 --> 00:45:47,580
latency gets to a point where it's it's

00:45:44,820 --> 00:45:50,250
it's rather more than simply tedious you

00:45:47,580 --> 00:45:52,470
can imagine a car doing visual

00:45:50,250 --> 00:45:54,600
recognition of things in front of it the

00:45:52,470 --> 00:45:57,000
speed with which it recognizes a speed

00:45:54,600 --> 00:45:58,980
sign or a stop sign or a child walking

00:45:57,000 --> 00:46:01,440
out in front of it is actually

00:45:58,980 --> 00:46:04,920
singularly important to the process

00:46:01,440 --> 00:46:07,740
involved and just imagine what that says

00:46:04,920 --> 00:46:10,500
when you go oh sorry I need to

00:46:07,740 --> 00:46:13,800
retransmit that this is the 3G signals a

00:46:10,500 --> 00:46:15,300
bit weak yes 4G makes that better yes 5g

00:46:13,800 --> 00:46:16,830
makes that better but it's never going

00:46:15,300 --> 00:46:18,300
to make this problem go away there are

00:46:16,830 --> 00:46:20,880
certain classes of computation was

00:46:18,300 --> 00:46:23,270
simply going to have to do locally at

00:46:20,880 --> 00:46:23,270
the edge

00:46:23,640 --> 00:46:30,240
moving on to cost then I can do no

00:46:28,200 --> 00:46:32,100
better than quote Google who said if

00:46:30,240 --> 00:46:33,780
everybody in the world uses Android

00:46:32,100 --> 00:46:36,300
voice assistant for three minutes every

00:46:33,780 --> 00:46:40,080
day we will have to double the number of

00:46:36,300 --> 00:46:42,000
servers we own so this is not a we're

00:46:40,080 --> 00:46:45,120
not finishing a bill of materials cost

00:46:42,000 --> 00:46:48,180
here these are simply a watering sums of

00:46:45,120 --> 00:46:49,620
money that we cannot ignore it's cheaper

00:46:48,180 --> 00:46:52,530
to provide a certain number of compute

00:46:49,620 --> 00:46:54,420
cycles in a small battery-powered device

00:46:52,530 --> 00:46:57,150
than it is to provide those compute

00:46:54,420 --> 00:47:01,050
cycles in a five nines reliability data

00:46:57,150 --> 00:47:02,850
center it just is and we can also get

00:47:01,050 --> 00:47:04,380
into questions about who pays that cost

00:47:02,850 --> 00:47:07,650
of it that's that's a sort of an

00:47:04,380 --> 00:47:09,530
interesting aside reliability well I

00:47:07,650 --> 00:47:12,390
talked about the interruption to your

00:47:09,530 --> 00:47:14,250
mobile internet service there are

00:47:12,390 --> 00:47:17,640
certain things that just simply have to

00:47:14,250 --> 00:47:19,040
work we have to guarantee they're there

00:47:17,640 --> 00:47:21,990
put their performance we have to

00:47:19,040 --> 00:47:24,570
guarantee their reliability of their

00:47:21,990 --> 00:47:27,210
latency and so the only way to do that

00:47:24,570 --> 00:47:30,060
in some cases is to take ownership of

00:47:27,210 --> 00:47:31,920
that problem ourselves I'm not having a

00:47:30,060 --> 00:47:33,540
go at the cloud cloud is brilliant but

00:47:31,920 --> 00:47:35,250
we need to be thinking about using

00:47:33,540 --> 00:47:37,610
appropriate tools in appropriate places

00:47:35,250 --> 00:47:39,450
and then finally the law of the land

00:47:37,610 --> 00:47:41,460
having been through the laws of

00:47:39,450 --> 00:47:45,300
economics let's go back to the law of

00:47:41,460 --> 00:47:46,740
the land security and privacy are of

00:47:45,300 --> 00:47:49,170
course concepts that are becoming

00:47:46,740 --> 00:47:51,540
incredibly important to us and as we get

00:47:49,170 --> 00:47:53,610
into the internet of connected devices

00:47:51,540 --> 00:47:56,400
then there are significant concerns

00:47:53,610 --> 00:47:59,070
expressed in that place we're connecting

00:47:56,400 --> 00:48:00,860
very personal data if you think about

00:47:59,070 --> 00:48:04,320
the phone in your pocket its

00:48:00,860 --> 00:48:07,730
accelerometers can already work out with

00:48:04,320 --> 00:48:10,020
about 90% accuracy what gender you are

00:48:07,730 --> 00:48:11,700
it certainly knows when you're sitting

00:48:10,020 --> 00:48:13,980
down when you're walking about it can

00:48:11,700 --> 00:48:15,720
easily work out when you're asleep it

00:48:13,980 --> 00:48:17,550
knows where you are it knows whether

00:48:15,720 --> 00:48:18,840
you're in your house somebody else's

00:48:17,550 --> 00:48:22,110
house at somebody's house you shouldn't

00:48:18,840 --> 00:48:24,450
be in you know go I could go on there's

00:48:22,110 --> 00:48:26,790
very personal data here we are going to

00:48:24,450 --> 00:48:29,460
want to cook to protect this carefully

00:48:26,790 --> 00:48:33,000
and part of the story of protecting that

00:48:29,460 --> 00:48:34,170
data carefully is not sending it to

00:48:33,000 --> 00:48:37,470
other people unless you have

00:48:34,170 --> 00:48:39,510
you have to so I think I've set out you

00:48:37,470 --> 00:48:41,280
know pretty clearly why I think there

00:48:39,510 --> 00:48:42,990
are fundamental principles this isn't

00:48:41,280 --> 00:48:45,390
just me saying this is a good idea

00:48:42,990 --> 00:48:47,580
this is observing there are fundamental

00:48:45,390 --> 00:48:49,350
things laws of nature out there that are

00:48:47,580 --> 00:48:54,960
going to push as much as possible of

00:48:49,350 --> 00:48:57,390
this processing to the edge and what is

00:48:54,960 --> 00:49:00,300
that processing well at arm we see

00:48:57,390 --> 00:49:01,740
machine learning as simply and yes I

00:49:00,300 --> 00:49:05,370
deliberately put snare quotes around

00:49:01,740 --> 00:49:08,580
that simply a software problem ml is for

00:49:05,370 --> 00:49:10,500
us just a can compute workload it's of

00:49:08,580 --> 00:49:12,570
course an increasingly common workload

00:49:10,500 --> 00:49:14,610
and it's a slightly different type of

00:49:12,570 --> 00:49:16,140
compute workload to some we've seen

00:49:14,610 --> 00:49:20,310
before and that has effects on our

00:49:16,140 --> 00:49:22,410
processor design but at a high level we

00:49:20,310 --> 00:49:24,180
just need this workload run as

00:49:22,410 --> 00:49:26,100
efficiently as possible as optimized as

00:49:24,180 --> 00:49:29,220
much as possible across the widest

00:49:26,100 --> 00:49:31,350
variety of our platforms the guy at the

00:49:29,220 --> 00:49:33,570
top of this the top of this stack

00:49:31,350 --> 00:49:35,190
doesn't care what's in the hardware

00:49:33,570 --> 00:49:37,920
underneath this he just wants it to run

00:49:35,190 --> 00:49:39,570
reliably easily and for him not to have

00:49:37,920 --> 00:49:42,360
to spend all night getting it to work he

00:49:39,570 --> 00:49:44,040
likes to go home on time that was a non

00:49:42,360 --> 00:49:46,740
gender-specific use of the word

00:49:44,040 --> 00:49:49,290
obviously so we need a software platform

00:49:46,740 --> 00:49:51,930
that will support this and we need to

00:49:49,290 --> 00:49:54,480
plug into the existing ml frameworks

00:49:51,930 --> 00:49:57,090
that are already out there we've been

00:49:54,480 --> 00:50:00,240
working on parts of this solution for

00:49:57,090 --> 00:50:02,820
some years now and last year we

00:50:00,240 --> 00:50:05,070
announced project Trillium we don't have

00:50:02,820 --> 00:50:07,830
all the parts we don't intend to have

00:50:05,070 --> 00:50:10,080
all of the parts we intend to take the

00:50:07,830 --> 00:50:13,070
best of the parts from other people and

00:50:10,080 --> 00:50:15,450
build this all this platform together

00:50:13,070 --> 00:50:16,950
but by now we've got the best part of a

00:50:15,450 --> 00:50:19,140
hundred engineers working on the

00:50:16,950 --> 00:50:21,230
frameworks that are set out in this

00:50:19,140 --> 00:50:24,960
rather beautiful market Ector diagram

00:50:21,230 --> 00:50:27,660
and we have our inference engine arm and

00:50:24,960 --> 00:50:30,180
n which sits on top of our compute

00:50:27,660 --> 00:50:31,830
library which consists of code optimized

00:50:30,180 --> 00:50:34,800
to run on the wide variety of processes

00:50:31,830 --> 00:50:36,780
that you find today on your platforms

00:50:34,800 --> 00:50:39,090
and of course for different partners we

00:50:36,780 --> 00:50:41,730
find different platforms from cortex-m

00:50:39,090 --> 00:50:44,640
which is actually being used much much

00:50:41,730 --> 00:50:47,730
more than we expected for processing for

00:50:44,640 --> 00:50:50,250
keyword spotting audio phrases etc so

00:50:47,730 --> 00:50:52,890
cortex a and Mali GPUs being used for

00:50:50,250 --> 00:50:55,680
high-performance applications on mobile

00:50:52,890 --> 00:50:57,390
today you've got the applications from

00:50:55,680 --> 00:51:00,300
people like Google and Facebook there

00:50:57,390 --> 00:51:02,369
are already using ml on mobile on CPU

00:51:00,300 --> 00:51:04,080
and GPU today and finally of course

00:51:02,369 --> 00:51:06,720
we're going to need to support these new

00:51:04,080 --> 00:51:09,480
dedicated neural network processors and

00:51:06,720 --> 00:51:13,320
not just the ones produced by my group

00:51:09,480 --> 00:51:15,510
at all we need to be realistic about

00:51:13,320 --> 00:51:17,250
this this is an open field lots of

00:51:15,510 --> 00:51:19,530
people are going to come in and innovate

00:51:17,250 --> 00:51:21,210
in this base and we need to allow and

00:51:19,530 --> 00:51:24,690
more than allow we need to encourage

00:51:21,210 --> 00:51:26,940
that the performance and efficiency of

00:51:24,690 --> 00:51:28,250
these new neural network processors is

00:51:26,940 --> 00:51:30,690
so high that they're not only

00:51:28,250 --> 00:51:32,850
accelerating the top right where people

00:51:30,690 --> 00:51:34,890
want absolute absolute massive

00:51:32,850 --> 00:51:38,640
performance but it's also making

00:51:34,890 --> 00:51:41,130
possible new applications by dint of

00:51:38,640 --> 00:51:43,619
that efficiency and that capability

00:51:41,130 --> 00:51:45,900
my favorite is you know things like full

00:51:43,619 --> 00:51:47,760
frame rate full resolution scene

00:51:45,900 --> 00:51:49,980
identification being used to drive

00:51:47,760 --> 00:51:52,020
picture quality improvements in set-top

00:51:49,980 --> 00:51:53,940
boxes you know this is not a is not a

00:51:52,020 --> 00:51:55,830
mobile application this is guys going oh

00:51:53,940 --> 00:51:57,060
yeah well we used to sort of work out

00:51:55,830 --> 00:51:59,280
what was in the picture and then we

00:51:57,060 --> 00:52:01,050
lovingly hand polished all these pixels

00:51:59,280 --> 00:52:03,240
to make it look good now we're just

00:52:01,050 --> 00:52:04,619
throwing away the front nd we just do

00:52:03,240 --> 00:52:06,300
we'll put it all through a neural

00:52:04,619 --> 00:52:08,730
network we'll identify what's in the

00:52:06,300 --> 00:52:12,690
scene and then we'll polish it according

00:52:08,730 --> 00:52:14,490
to our our secret sauce so with project

00:52:12,690 --> 00:52:17,820
Trillium we've started we've got this

00:52:14,490 --> 00:52:20,420
bull road but we need your help to do

00:52:17,820 --> 00:52:20,420
the next part

00:52:22,420 --> 00:52:28,299
talk a little about experts as indeed

00:52:25,720 --> 00:52:30,160
Chris was talking about it kind of looks

00:52:28,299 --> 00:52:31,690
as though we're all it's simple you just

00:52:30,160 --> 00:52:33,720
throw everything at a neural network and

00:52:31,690 --> 00:52:35,920
it you know at the solution pops

00:52:33,720 --> 00:52:38,319
everyone knows what part of an imager

00:52:35,920 --> 00:52:40,390
cat is are indeed a hot dog

00:52:38,319 --> 00:52:43,900
even a one-year-old child can recognize

00:52:40,390 --> 00:52:45,609
a cat well it turns out there's actually

00:52:43,900 --> 00:52:47,290
some some interesting wrinkles there a

00:52:45,609 --> 00:52:50,470
one-year-old child shown a picture of a

00:52:47,290 --> 00:52:52,510
Manx cat which is a cat genetically

00:52:50,470 --> 00:52:54,880
having no title the one-year-old child

00:52:52,510 --> 00:52:57,520
says that's a cat but it's got no tail

00:52:54,880 --> 00:53:00,160
it's confused but it knows it's a cat

00:52:57,520 --> 00:53:02,859
you show it to most deep learning

00:53:00,160 --> 00:53:04,089
network systems and they go no idea what

00:53:02,859 --> 00:53:07,240
that is

00:53:04,089 --> 00:53:09,190
models have hidden problems for example

00:53:07,240 --> 00:53:10,630
it turns out you know if you're not

00:53:09,190 --> 00:53:13,329
careful

00:53:10,630 --> 00:53:13,960
snow was being used to identify pictures

00:53:13,329 --> 00:53:15,609
of wolves

00:53:13,960 --> 00:53:17,470
you thought it was identifying a wolf

00:53:15,609 --> 00:53:19,599
actually it was it was fixating on the

00:53:17,470 --> 00:53:21,609
snow you just didn't notice that until

00:53:19,599 --> 00:53:23,500
you brought a husky along and husky gets

00:53:21,609 --> 00:53:25,270
identified as a wolf because the Huskies

00:53:23,500 --> 00:53:26,650
rolling around the snow as well there

00:53:25,270 --> 00:53:28,900
was another one where tanks were at

00:53:26,650 --> 00:53:30,790
being identified by the bright

00:53:28,900 --> 00:53:33,579
conditions when the photograph was being

00:53:30,790 --> 00:53:38,020
taken it wasn't actually identifying the

00:53:33,579 --> 00:53:40,599
object itself speech recognition works

00:53:38,020 --> 00:53:44,770
well because we've now got a combination

00:53:40,599 --> 00:53:46,720
of classical approaches things like you

00:53:44,770 --> 00:53:49,359
know extracting the features via FFT

00:53:46,720 --> 00:53:51,400
working in time in the frequency domain

00:53:49,359 --> 00:53:53,410
taking out the phoneme extraction and

00:53:51,400 --> 00:53:55,750
then working on sentence probabilities

00:53:53,410 --> 00:53:57,910
and things like that well actually if we

00:53:55,750 --> 00:53:59,920
rework that and take the phoneme and the

00:53:57,910 --> 00:54:01,420
sentence probabilities together throw it

00:53:59,920 --> 00:54:04,420
into a machine learning model we get a

00:54:01,420 --> 00:54:07,299
huge improvement in accuracy of speech

00:54:04,420 --> 00:54:10,150
identification that works been achieved

00:54:07,299 --> 00:54:12,069
because you've got researchers from one

00:54:10,150 --> 00:54:14,349
field standing on the shoulders of a

00:54:12,069 --> 00:54:18,490
huge body of research already being done

00:54:14,349 --> 00:54:20,680
in other fields experts are very much

00:54:18,490 --> 00:54:22,359
still needed in this base we have a long

00:54:20,680 --> 00:54:25,690
way from making this idiot-proof

00:54:22,359 --> 00:54:27,490
worse than that we've got to provide an

00:54:25,690 --> 00:54:29,430
environment in which the experts can

00:54:27,490 --> 00:54:31,529
work with each other

00:54:29,430 --> 00:54:35,819
because we are going to need the experts

00:54:31,529 --> 00:54:37,529
to combine their expertise so there's a

00:54:35,819 --> 00:54:41,519
lot of talk about ml being the Wild West

00:54:37,529 --> 00:54:43,739
and in some ways EDA actually is but

00:54:41,519 --> 00:54:46,079
we've got a lot to work from albeit

00:54:43,739 --> 00:54:49,440
several places where there's unnecessary

00:54:46,079 --> 00:54:52,170
separate separation duplication and some

00:54:49,440 --> 00:54:53,609
religious wars clearly no field of human

00:54:52,170 --> 00:54:55,349
endeavor in computer science would be

00:54:53,609 --> 00:54:57,089
complete without some good religious

00:54:55,349 --> 00:55:00,329
wars going on and we've certainly got

00:54:57,089 --> 00:55:01,529
some of those we've reached a natural

00:55:00,329 --> 00:55:03,869
position where several companies have

00:55:01,529 --> 00:55:06,479
produced systems that understand their

00:55:03,869 --> 00:55:08,400
data and produce useful results out of

00:55:06,479 --> 00:55:10,440
their data and understanding their

00:55:08,400 --> 00:55:11,670
problems but it's now getting through

00:55:10,440 --> 00:55:14,009
stage where we want to consolidate

00:55:11,670 --> 00:55:15,539
shared interests and try and address

00:55:14,009 --> 00:55:18,239
some of this fragmentation and

00:55:15,539 --> 00:55:20,789
duplication we don't need so many

00:55:18,239 --> 00:55:22,380
intermediate forms indeed I'll argue

00:55:20,789 --> 00:55:24,690
some of the intermediate forms aren't

00:55:22,380 --> 00:55:27,869
really intermediate forms at all just F

00:55:24,690 --> 00:55:30,089
writing your your internal data format

00:55:27,869 --> 00:55:33,150
out to a file does not make it a

00:55:30,089 --> 00:55:34,380
standard you know there are several out

00:55:33,150 --> 00:55:37,019
there that are not thought through

00:55:34,380 --> 00:55:38,940
formats that we can use for multiple

00:55:37,019 --> 00:55:41,489
tools and frameworks and inference

00:55:38,940 --> 00:55:43,289
engines to use we need to embrace other

00:55:41,489 --> 00:55:47,930
people's work here we need the open

00:55:43,289 --> 00:55:50,759
standards open data representations so

00:55:47,930 --> 00:55:52,650
we need to be able to work on that in an

00:55:50,759 --> 00:55:56,309
environment where people can collaborate

00:55:52,650 --> 00:55:58,529
in an environment like the Nara we need

00:55:56,309 --> 00:56:00,539
to share the inference code bases we've

00:55:58,529 --> 00:56:03,569
already got good results with arm and

00:56:00,539 --> 00:56:06,319
Google sharing Android nn using some of

00:56:03,569 --> 00:56:08,969
our optimized codes and scheduling code

00:56:06,319 --> 00:56:11,400
we're seeing good convergence on Android

00:56:08,969 --> 00:56:13,349
with tools and frameworks Android nn

00:56:11,400 --> 00:56:15,210
absolutely the standard in this space

00:56:13,349 --> 00:56:18,150
but the same is not yet true of other

00:56:15,210 --> 00:56:21,239
variants of Linux we're seeing far more

00:56:18,150 --> 00:56:24,029
fragmentation we're seeing those

00:56:21,239 --> 00:56:26,489
inference engines often exploiting arm

00:56:24,029 --> 00:56:28,140
compute library for performance but we

00:56:26,489 --> 00:56:30,779
need to consolidate on a single

00:56:28,140 --> 00:56:33,119
inference interface there's really no

00:56:30,779 --> 00:56:35,349
need for multiple spaces at multiple

00:56:33,119 --> 00:56:37,790
places in this space

00:56:35,349 --> 00:56:39,890
with that in mind we might be able to

00:56:37,790 --> 00:56:42,920
tame some of the worst of the Wild West

00:56:39,890 --> 00:56:44,630
I talked about the three pillars of the

00:56:42,920 --> 00:56:46,609
problem earlier the domain experts the

00:56:44,630 --> 00:56:48,800
ml experts and the platform experts and

00:56:46,609 --> 00:56:51,710
and how we need to bring these pillars

00:56:48,800 --> 00:56:53,210
together to make this possible the prize

00:56:51,710 --> 00:56:55,400
at the end of this would be to allow

00:56:53,210 --> 00:56:57,530
experts in one of the areas not to have

00:56:55,400 --> 00:57:00,380
to be experts in all three because if we

00:56:57,530 --> 00:57:02,599
don't fix that this is this this simply

00:57:00,380 --> 00:57:05,150
isn't going to work nobody or very very

00:57:02,599 --> 00:57:09,140
few people can become experts in all

00:57:05,150 --> 00:57:10,940
three of these problem spaces I'm sure

00:57:09,140 --> 00:57:11,349
it is obvious to all of you that the

00:57:10,940 --> 00:57:14,660
Naro

00:57:11,349 --> 00:57:17,329
is is the place where we should be able

00:57:14,660 --> 00:57:19,280
to work together arm and yourselves to

00:57:17,329 --> 00:57:21,650
help solve the platform part of that

00:57:19,280 --> 00:57:25,220
problem and make those platforms useful

00:57:21,650 --> 00:57:27,680
and available to other developers and

00:57:25,220 --> 00:57:29,720
this isn't although I've talked about a

00:57:27,680 --> 00:57:32,329
lot of the usual suspects of arm denaro

00:57:29,720 --> 00:57:34,970
Google and Facebook this isn't just them

00:57:32,329 --> 00:57:37,310
this this is huge the ecosystem for this

00:57:34,970 --> 00:57:39,800
is pretty much everybody you might care

00:57:37,310 --> 00:57:42,910
about there are experts in data services

00:57:39,800 --> 00:57:44,810
who understand how to under

00:57:42,910 --> 00:57:47,180
interpret and understand that data

00:57:44,810 --> 00:57:49,550
they're experts in algorithms being used

00:57:47,180 --> 00:57:51,230
to solve the common problems packaged up

00:57:49,550 --> 00:57:52,910
for others to use in a way where they

00:57:51,230 --> 00:57:55,250
don't have to understand them so deeply

00:57:52,910 --> 00:57:57,829
there's companies building software

00:57:55,250 --> 00:58:00,020
services around this there are companies

00:57:57,829 --> 00:58:02,869
and developers building tools the debug

00:58:00,020 --> 00:58:04,280
and optimizer code and of course there's

00:58:02,869 --> 00:58:07,609
lots of companies working on the many

00:58:04,280 --> 00:58:10,069
platforms and IP components of those

00:58:07,609 --> 00:58:13,160
platforms being designed across all the

00:58:10,069 --> 00:58:15,470
variety of end end market segments now

00:58:13,160 --> 00:58:17,720
all of these people need to be able to

00:58:15,470 --> 00:58:21,290
speak common languages and be able to

00:58:17,720 --> 00:58:23,210
talk to each other I hope it made clear

00:58:21,290 --> 00:58:27,700
that all this requires us to come

00:58:23,210 --> 00:58:30,410
together and collaborate as developers

00:58:27,700 --> 00:58:32,050
we want you to join the work so that

00:58:30,410 --> 00:58:34,640
we've got the best minds working on this

00:58:32,050 --> 00:58:36,260
I'm an N and the compute library as I

00:58:34,640 --> 00:58:39,170
said we're already available under the

00:58:36,260 --> 00:58:41,630
MIT license but we got many requests to

00:58:39,170 --> 00:58:43,490
get to it closer and to be able to

00:58:41,630 --> 00:58:44,349
contribute and that's why we're opening

00:58:43,490 --> 00:58:45,999
up the code

00:58:44,349 --> 00:58:47,529
and getting it governed open-source

00:58:45,999 --> 00:58:49,329
governance as well as open source

00:58:47,529 --> 00:58:52,299
license in order for people to

00:58:49,329 --> 00:58:54,910
contribute we think it's it's really

00:58:52,299 --> 00:58:56,589
important that we get this right it's

00:58:54,910 --> 00:58:59,349
taken us over a hundred man years of

00:58:56,589 --> 00:59:01,749
effort already to work on our men n the

00:58:59,349 --> 00:59:03,819
compute library all the work we've done

00:59:01,749 --> 00:59:06,489
on performance analysis methodology and

00:59:03,819 --> 00:59:08,769
benchmarking and arm has been and will

00:59:06,489 --> 00:59:10,989
continue to be committed to development

00:59:08,769 --> 00:59:13,589
on rmn but now we'll do it in the open

00:59:10,989 --> 00:59:16,239
with you and all of your contributions

00:59:13,589 --> 00:59:19,150
we hope to leverage the best of Linares

00:59:16,239 --> 00:59:22,329
forte for combined development which is

00:59:19,150 --> 00:59:24,160
key because we need your methodologies

00:59:22,329 --> 00:59:26,319
for continuous integration and testing

00:59:24,160 --> 00:59:29,529
to make progress in this fast-moving

00:59:26,319 --> 00:59:31,329
space and we need inaros approach of

00:59:29,529 --> 00:59:33,549
collaborative development making this

00:59:31,329 --> 00:59:36,729
the place where the smart people want to

00:59:33,549 --> 00:59:38,589
work but let me be clear of course arm

00:59:36,729 --> 00:59:42,880
is in no way backing off this now this

00:59:38,589 --> 00:59:44,259
is this is just the start I took a

00:59:42,880 --> 00:59:46,329
little hear about what's so important

00:59:44,259 --> 00:59:48,099
about our men n what did we get for

00:59:46,329 --> 00:59:49,660
those hundred man years of effort well

00:59:48,099 --> 00:59:51,219
one of the design choices from the start

00:59:49,660 --> 00:59:53,940
was not to produce her own high level

00:59:51,219 --> 00:59:57,960
framework there enough of those already

00:59:53,940 --> 01:00:01,150
personally I would argue way too many

00:59:57,960 --> 01:00:02,950
keep going I the industry won't could

01:00:01,150 --> 01:00:05,950
continue to support 20 of these

01:00:02,950 --> 01:00:07,710
frameworks they simply won't it's also

01:00:05,950 --> 01:00:10,390
instructive to observe if you look at

01:00:07,710 --> 01:00:12,579
effort as measured by open-source

01:00:10,390 --> 01:00:14,579
commits you can see that one or two

01:00:12,579 --> 01:00:17,049
absolutely streets ahead of the others

01:00:14,579 --> 01:00:18,430
but our men n is not taking sides in

01:00:17,049 --> 01:00:19,539
this our main aim was designed from the

01:00:18,430 --> 01:00:21,729
start to plug into the existing

01:00:19,539 --> 01:00:24,880
frameworks we're not taking sides in

01:00:21,729 --> 01:00:26,619
this war in sub segments such as mobile

01:00:24,880 --> 01:00:28,450
there are existing inference engines and

01:00:26,619 --> 01:00:30,309
of course we can connect to those work

01:00:28,450 --> 01:00:31,719
efficiently with those there's simply no

01:00:30,309 --> 01:00:33,969
point in reinventing the wheel for

01:00:31,719 --> 01:00:35,499
Android but for embedded Linux systems

01:00:33,969 --> 01:00:37,779
we need to start setting some hardware

01:00:35,499 --> 01:00:40,450
standards and taming some of this world

01:00:37,779 --> 01:00:42,789
West and finally we have highly

01:00:40,450 --> 01:00:45,729
efficient backends already optimized for

01:00:42,789 --> 01:00:47,410
some of our CPUs and GPUs we spend tens

01:00:45,729 --> 01:00:49,660
of man years of effort just on that

01:00:47,410 --> 01:00:52,900
alone and we want the world to take

01:00:49,660 --> 01:00:56,589
advantage of that I said we're committed

01:00:52,900 --> 01:00:57,590
to allowing other third party IP into

01:00:56,589 --> 01:00:59,330
this we've got three

01:00:57,590 --> 01:01:01,100
serious companies working with us

01:00:59,330 --> 01:01:03,410
already looking to integrate their

01:01:01,100 --> 01:01:06,080
accelerators into our framework and and

01:01:03,410 --> 01:01:08,660
we are committing to helping that making

01:01:06,080 --> 01:01:11,330
that possible and it's also worth noting

01:01:08,660 --> 01:01:12,680
MNN is already proven in production we

01:01:11,330 --> 01:01:15,230
have already more than one deployment

01:01:12,680 --> 01:01:21,260
shipping in hyper quite valuable

01:01:15,230 --> 01:01:23,840
production devices join to a close then

01:01:21,260 --> 01:01:26,030
please make the most of this day there's

01:01:23,840 --> 01:01:27,860
a full-day session on this in this room

01:01:26,030 --> 01:01:30,110
following the keynotes and I highly

01:01:27,860 --> 01:01:32,810
recommend you make full use of this as

01:01:30,110 --> 01:01:34,970
well as grabbing people in the breaks

01:01:32,810 --> 01:01:36,980
talking to them including myself in

01:01:34,970 --> 01:01:38,690
Rob's talk he's going to give an

01:01:36,980 --> 01:01:40,700
overview of the army name design and

01:01:38,690 --> 01:01:43,250
code base he'll talk about the

01:01:40,700 --> 01:01:45,200
interfaces why they exist and what they

01:01:43,250 --> 01:01:47,960
are he'll talk about how people are

01:01:45,200 --> 01:01:49,790
using it today and also give a peek at

01:01:47,960 --> 01:01:51,350
the future of some features that are

01:01:49,790 --> 01:01:53,720
going to be contributing with the code

01:01:51,350 --> 01:01:55,670
base in future after that we've got Pete

01:01:53,720 --> 01:01:57,890
worden and Mark shalwar from Google and

01:01:55,670 --> 01:01:59,960
Qualcomm and I'm sure those are going to

01:01:57,890 --> 01:02:01,460
be great as well and these are just the

01:01:59,960 --> 01:02:03,950
morning sessions we go on in the

01:02:01,460 --> 01:02:06,700
afternoon with talks from AWS and XP

01:02:03,950 --> 01:02:09,440
Xilinx and others talk to each other

01:02:06,700 --> 01:02:11,210
let's work out between us because

01:02:09,440 --> 01:02:13,370
between us is the answer to this problem

01:02:11,210 --> 01:02:15,980
how to speed development on machine

01:02:13,370 --> 01:02:18,820
learning on more use cases across the

01:02:15,980 --> 01:02:21,190
widest variety of ARM based platforms

01:02:18,820 --> 01:02:27,929
thank you very much

01:02:21,190 --> 01:02:27,929

YouTube URL: https://www.youtube.com/watch?v=bYSwYkmQJVo


