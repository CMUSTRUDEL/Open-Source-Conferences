Title: YVR18- 330 Snapdragon in Arm NN
Publication date: 2018-10-22
Playlist: Linaro Connect Vancouver 2018
Description: 
	TBD
Captions: 
	00:00:02,110 --> 00:00:07,120
[Music]

00:00:09,299 --> 00:00:13,299
hi I'm Mark Sullivan

00:00:11,099 --> 00:00:15,820
director of engineering in the machine

00:00:13,299 --> 00:00:18,189
learning group at Qualcomm so today I

00:00:15,820 --> 00:00:22,060
want to go through a deep dive of

00:00:18,189 --> 00:00:24,849
Qualcomm's AI software actually more

00:00:22,060 --> 00:00:27,099
accurately deep learning software and

00:00:24,849 --> 00:00:29,830
talk about some of the solutions we have

00:00:27,099 --> 00:00:31,929
I give you a an architectural overview

00:00:29,830 --> 00:00:35,230
and look at how some of them have been

00:00:31,929 --> 00:00:37,059
used even by some third parties but at

00:00:35,230 --> 00:00:41,379
first I want to start and give a sort of

00:00:37,059 --> 00:00:42,850
high-level overall context we talked

00:00:41,379 --> 00:00:44,260
we've heard today in the and the

00:00:42,850 --> 00:00:46,359
keynotes this morning from Chris about

00:00:44,260 --> 00:00:48,539
the last decade has been mobile first

00:00:46,359 --> 00:00:51,850
and the next decade is going to be about

00:00:48,539 --> 00:00:54,850
AI first but really the the mobile that

00:00:51,850 --> 00:00:56,800
you have your devices is going to be the

00:00:54,850 --> 00:00:59,440
nexus of both those things it's going to

00:00:56,800 --> 00:01:00,879
still be your your view to the world and

00:00:59,440 --> 00:01:04,150
the thing that you always have with you

00:01:00,879 --> 00:01:09,119
and as a really central Nexus of AI

00:01:04,150 --> 00:01:11,020
innovation in the next four years

00:01:09,119 --> 00:01:15,220
there's going to be eight point six

00:01:11,020 --> 00:01:17,740
billion mobile phones shipped and if you

00:01:15,220 --> 00:01:20,920
look that's currently the population of

00:01:17,740 --> 00:01:26,140
the earth at least as of 7:20 this

00:01:20,920 --> 00:01:30,000
morning on the the world population

00:01:26,140 --> 00:01:32,560
calculator so the the kinds of

00:01:30,000 --> 00:01:36,130
experiences we're seeing from for my eye

00:01:32,560 --> 00:01:38,229
for camera for voice recognition for for

00:01:36,130 --> 00:01:39,700
keyword recognition is really providing

00:01:38,229 --> 00:01:41,590
a whole bunch of new experiences for

00:01:39,700 --> 00:01:43,950
people and I think you can see this

00:01:41,590 --> 00:01:46,930
every day as new features come to phones

00:01:43,950 --> 00:01:48,250
it seems to be for everybody much except

00:01:46,930 --> 00:01:51,329
unfortunately Andrea who seems

00:01:48,250 --> 00:01:51,329
impervious to voice recognition

00:01:53,710 --> 00:01:58,340
so I'll give you a brief history of the

00:01:56,690 --> 00:02:00,680
evolution of of how well we've been

00:01:58,340 --> 00:02:04,010
doing for a ion Snapdragon so he started

00:02:00,680 --> 00:02:06,920
out supporting cafe models and for some

00:02:04,010 --> 00:02:08,899
reason there we are and these were

00:02:06,920 --> 00:02:10,429
taking the proto text files and

00:02:08,899 --> 00:02:12,350
basically converting them to our own

00:02:10,429 --> 00:02:15,530
custom runtime running them on the cpu

00:02:12,350 --> 00:02:18,080
doing things like face recognition and

00:02:15,530 --> 00:02:20,959
that was done back in 2015 on the

00:02:18,080 --> 00:02:22,520
Snapdragon 820 chip the training would

00:02:20,959 --> 00:02:27,550
be done in in the cloud or on a server

00:02:22,520 --> 00:02:30,260
then deployed to the device using the

00:02:27,550 --> 00:02:35,080
converted cafe models that would then

00:02:30,260 --> 00:02:41,180
run in the runtime so in the next

00:02:35,080 --> 00:02:43,430
2016-2017 we did a lot of support for

00:02:41,180 --> 00:02:45,320
additional networks for tensorflow for

00:02:43,430 --> 00:02:46,610
cafe to creating new converters that

00:02:45,320 --> 00:02:51,190
would be able to take those portable

00:02:46,610 --> 00:02:51,190
formats and convert them to our runtimes

00:02:51,370 --> 00:02:57,380
to a new format that we call a DLC which

00:02:54,110 --> 00:02:59,480
was a deep learning container and so

00:02:57,380 --> 00:03:01,489
these would obviously have to have

00:02:59,480 --> 00:03:03,380
separate converters for each of them we

00:03:01,489 --> 00:03:06,350
go through a quantization phase that

00:03:03,380 --> 00:03:09,410
would then be allowed to support the DSP

00:03:06,350 --> 00:03:11,150
which runs quantized networks you can

00:03:09,410 --> 00:03:14,390
see the overall architecture where we

00:03:11,150 --> 00:03:16,820
have the the Qualcomm neural processing

00:03:14,390 --> 00:03:20,840
SDK which supports running networks

00:03:16,820 --> 00:03:22,220
across the CPU the GPU and the DSP we

00:03:20,840 --> 00:03:25,610
have something called QoS ml which

00:03:22,220 --> 00:03:27,799
supports accelerated operations like a

00:03:25,610 --> 00:03:32,180
blast library supports those kinds of

00:03:27,799 --> 00:03:34,670
acceleration especially using neon the

00:03:32,180 --> 00:03:36,890
GPU ops which are basically OpenCL

00:03:34,670 --> 00:03:40,100
kernels that run on the Adreno GPU and

00:03:36,890 --> 00:03:45,860
then DSP operations which are leveraging

00:03:40,100 --> 00:03:49,430
the open source hexagon n-n-no process

00:03:45,860 --> 00:03:51,500
basically set of operations that are

00:03:49,430 --> 00:03:53,690
available for accelerating machine

00:03:51,500 --> 00:03:56,120
learning operations on the DSP and it's

00:03:53,690 --> 00:03:58,930
using a newer hardware technology we

00:03:56,120 --> 00:03:58,930
have called HDX

00:04:08,989 --> 00:04:14,340
so now you can see in 2018 the the

00:04:12,330 --> 00:04:15,720
growth of the support of all of these

00:04:14,340 --> 00:04:18,720
different networks and a lot of this has

00:04:15,720 --> 00:04:23,370
come from the ability of these networks

00:04:18,720 --> 00:04:25,020
to convert their models through onyx and

00:04:23,370 --> 00:04:28,080
we now have an onyx converter that

00:04:25,020 --> 00:04:29,190
allows us to import all those models

00:04:28,080 --> 00:04:31,250
that are generated from different

00:04:29,190 --> 00:04:34,650
frameworks and run them on the runtime

00:04:31,250 --> 00:04:36,030
so you see the dlc model loader takes in

00:04:34,650 --> 00:04:38,370
those those networks that have been

00:04:36,030 --> 00:04:45,150
converted through the converter or we

00:04:38,370 --> 00:04:47,610
have yeah we have the option potentially

00:04:45,150 --> 00:04:49,500
through the android NN runtime that is

00:04:47,610 --> 00:04:52,650
also supported through the android BSP's

00:04:49,500 --> 00:04:55,289
to take in tensorflow models and run

00:04:52,650 --> 00:05:01,650
them directly through the android and an

00:04:55,289 --> 00:05:04,530
interface and again this would be so

00:05:01,650 --> 00:05:10,110
this is support as of this year was

00:05:04,530 --> 00:05:13,440
deployed on the snapdragon 845 models so

00:05:10,110 --> 00:05:15,300
the whole combination of these things we

00:05:13,440 --> 00:05:17,250
call the AI engine and that's the

00:05:15,300 --> 00:05:20,520
combination of support for the DSP the

00:05:17,250 --> 00:05:24,360
GPU the CPU using Qualcomm's neural

00:05:20,520 --> 00:05:27,210
processing SDK supported via via Android

00:05:24,360 --> 00:05:29,990
nn on Android platforms and then using

00:05:27,210 --> 00:05:32,729
the hexagon and then library as well

00:05:29,990 --> 00:05:35,520
supporting networks that were designed

00:05:32,729 --> 00:05:37,830
by Cafe cafe to tensorflow or tensorflow

00:05:35,520 --> 00:05:44,580
light or anything that can be imported

00:05:37,830 --> 00:05:46,229
through onyx here's a diagram of the

00:05:44,580 --> 00:05:47,789
software stack in general so we have

00:05:46,229 --> 00:05:51,270
mobile applications they can be written

00:05:47,789 --> 00:05:52,560
using a variety of approaches it's

00:05:51,270 --> 00:05:54,539
possible to write things that go

00:05:52,560 --> 00:05:57,150
directly to either Vulcan or OpenGL ES

00:05:54,539 --> 00:05:58,530
or use render script you can write

00:05:57,150 --> 00:06:01,860
something it directly interfaces with

00:05:58,530 --> 00:06:04,169
OpenCL on the platform or your if you're

00:06:01,860 --> 00:06:07,199
going through Android and an API you can

00:06:04,169 --> 00:06:11,610
target through the the GPU back-end

00:06:07,199 --> 00:06:14,120
using OpenCL you go through Android nn

00:06:11,610 --> 00:06:18,760
again the same way but targeting the

00:06:14,120 --> 00:06:21,020
DSP with the hexagon n n back-end and

00:06:18,760 --> 00:06:30,139
then if you're using the the neural

00:06:21,020 --> 00:06:34,280
processing engine excuse me through the

00:06:30,139 --> 00:06:37,580
DLC you can run things on the CPU the GP

00:06:34,280 --> 00:06:41,180
or the DSP as well if you're using

00:06:37,580 --> 00:06:43,520
tensor flow models there's a the TF

00:06:41,180 --> 00:06:45,949
light runtime can run directly on the

00:06:43,520 --> 00:06:48,020
CPU here or there's other frameworks and

00:06:45,949 --> 00:06:49,639
in fact I gave some patches to the T

00:06:48,020 --> 00:06:51,800
engine project that allow it to run on

00:06:49,639 --> 00:06:55,150
the 820 and so that would go directly

00:06:51,800 --> 00:07:02,180
through using the CPU back-end

00:06:55,150 --> 00:07:04,280
accelerated by neon so the SDK also

00:07:02,180 --> 00:07:07,360
comes with a bunch of tutorial samples

00:07:04,280 --> 00:07:09,710
benchmarking user reference Docs and

00:07:07,360 --> 00:07:13,060
debug tools and I'll get into more of

00:07:09,710 --> 00:07:13,060
the tools that come in the SDK in a sec

00:07:18,460 --> 00:07:26,749
all right so you can download the Torah

00:07:21,439 --> 00:07:28,909
the hexagon not the hexagon I'll get to

00:07:26,749 --> 00:07:30,770
that a little later interpretation the

00:07:28,909 --> 00:07:32,479
Qualcomm neural processing SDK from the

00:07:30,770 --> 00:07:33,050
Qualcomm developer Network there's a

00:07:32,479 --> 00:07:35,150
link there

00:07:33,050 --> 00:07:37,969
it supports several different chips in

00:07:35,150 --> 00:07:40,539
the 800 series 600 series down to the

00:07:37,969 --> 00:07:44,870
400 series it also supports the

00:07:40,539 --> 00:07:47,360
Snapdragon 820 am platform which is the

00:07:44,870 --> 00:07:52,279
automotive platform and Snapdragon

00:07:47,360 --> 00:07:53,930
flight which is a drone platform it uses

00:07:52,279 --> 00:07:56,659
for Android the Android compilers

00:07:53,930 --> 00:07:59,990
supporting GCC and clang and then for

00:07:56,659 --> 00:08:04,310
Linux it has support for our b7 our 37

00:07:59,990 --> 00:08:08,270
heart float air 64 and we'll also run on

00:08:04,310 --> 00:08:10,669
x86 64 workstations but that's mainly

00:08:08,270 --> 00:08:12,889
just for for testing and development

00:08:10,669 --> 00:08:15,219
purposes it's not fully optimized

00:08:12,889 --> 00:08:15,219
runtime

00:08:17,530 --> 00:08:21,700
the developer tools we have snapping net

00:08:20,290 --> 00:08:23,800
run which is a way to quickly run a

00:08:21,700 --> 00:08:26,470
network that's been converted into a DLC

00:08:23,800 --> 00:08:30,910
and we have the various converters that

00:08:26,470 --> 00:08:32,770
will take the native model formats do

00:08:30,910 --> 00:08:35,979
some model optimization and then can

00:08:32,770 --> 00:08:39,789
turn them into the deep learning

00:08:35,979 --> 00:08:40,960
containers we have snappy diag beyou for

00:08:39,789 --> 00:08:42,960
reviewing the dialogues that are

00:08:40,960 --> 00:08:46,180
generated while the models are being run

00:08:42,960 --> 00:08:47,740
dlc info which will print out a text

00:08:46,180 --> 00:08:51,100
form of all the different layers so you

00:08:47,740 --> 00:08:53,110
can analyze what the inputs are what the

00:08:51,100 --> 00:08:56,590
output layers are basically get a sense

00:08:53,110 --> 00:08:58,210
of the overall model snappy dlc quantize

00:08:56,590 --> 00:08:59,740
which will take a series of inputs and

00:08:58,210 --> 00:09:03,580
be able to generate the quantization

00:08:59,740 --> 00:09:07,390
parameters for the outputs that can be

00:09:03,580 --> 00:09:10,840
used to run for the DSP it snappy bench

00:09:07,390 --> 00:09:14,320
which we can give you the inference

00:09:10,840 --> 00:09:15,610
times per layer and some other metrics

00:09:14,320 --> 00:09:17,050
when you're you're analyzing your

00:09:15,610 --> 00:09:19,210
networks and testing for regressions and

00:09:17,050 --> 00:09:21,040
performance and then recently there's

00:09:19,210 --> 00:09:23,230
been a couple other additions one is the

00:09:21,040 --> 00:09:25,570
Onyx converter that can convert onyx

00:09:23,230 --> 00:09:29,380
models to DLC and then a DLC viewer

00:09:25,570 --> 00:09:31,150
which will allow you to do a nice

00:09:29,380 --> 00:09:33,310
analysis of models inside your browser

00:09:31,150 --> 00:09:39,160
and you can go into a deep dive through

00:09:33,310 --> 00:09:40,810
the various connections of the model so

00:09:39,160 --> 00:09:42,760
the general workflow is you get a model

00:09:40,810 --> 00:09:44,470
in the native format you would run it

00:09:42,760 --> 00:09:46,690
through the conversion tool for instance

00:09:44,470 --> 00:09:49,150
like the Onyx converter you get the DLC

00:09:46,690 --> 00:09:52,270
model file and then you can run that on

00:09:49,150 --> 00:09:53,980
the snappy runtime if you're doing some

00:09:52,270 --> 00:09:56,860
prototyping there's also as a facility

00:09:53,980 --> 00:09:59,470
called the user-defined layer where you

00:09:56,860 --> 00:10:01,240
can add in your own layer into the model

00:09:59,470 --> 00:10:03,130
that's not a supported operation for

00:10:01,240 --> 00:10:06,880
instance and then make that be part of

00:10:03,130 --> 00:10:08,560
the runtime so you see there's the

00:10:06,880 --> 00:10:10,480
various models as supported there's a

00:10:08,560 --> 00:10:13,930
list of a subset of some of those models

00:10:10,480 --> 00:10:16,770
there for Google net inception Alex not

00:10:13,930 --> 00:10:16,770
ResNet etc

00:10:18,770 --> 00:10:23,130
so models can be DLCs can be quantized

00:10:22,290 --> 00:10:27,420
or non quantized

00:10:23,130 --> 00:10:29,520
the quantized models run on the DSP

00:10:27,420 --> 00:10:32,250
directly if you have a non quantized

00:10:29,520 --> 00:10:35,520
model it can also run on the DLC s

00:10:32,250 --> 00:10:38,310
around the on the DSP it will auto

00:10:35,520 --> 00:10:40,320
quantize in that case if you have a

00:10:38,310 --> 00:10:43,200
quantized model it can be D quantized

00:10:40,320 --> 00:10:46,770
and then run in 32-bit float mode on the

00:10:43,200 --> 00:10:49,860
CPU or GPU it just depends what you have

00:10:46,770 --> 00:10:51,360
so it can do either but you won't go

00:10:49,860 --> 00:10:53,580
through that quantization or D

00:10:51,360 --> 00:10:55,140
quantization phase so knowing which

00:10:53,580 --> 00:11:03,240
back-end you're targeting may save you

00:10:55,140 --> 00:11:08,250
that step if you do it beforehand so for

00:11:03,240 --> 00:11:09,960
N and API support clear you C tends to

00:11:08,250 --> 00:11:12,420
full light supports the end and API back

00:11:09,960 --> 00:11:16,950
in you can also use other frameworks

00:11:12,420 --> 00:11:20,310
that can then feed into in an epi what

00:11:16,950 --> 00:11:24,900
we do is implement the the Android and

00:11:20,310 --> 00:11:28,920
then how that has the DSP runtime the

00:11:24,900 --> 00:11:33,480
open CL runtime targeting the DSP and

00:11:28,920 --> 00:11:35,670
the GPU and then the CPU is obviously

00:11:33,480 --> 00:11:38,000
provided by by Google as part of the

00:11:35,670 --> 00:11:38,000
framework

00:11:43,240 --> 00:11:50,330
so these are the the sets of operations

00:11:46,750 --> 00:11:52,250
expected for an API the ones in green

00:11:50,330 --> 00:11:54,440
there with the one are the ones that are

00:11:52,250 --> 00:11:56,210
currently supported there's a bunch of

00:11:54,440 --> 00:11:59,720
other ones that we feel are missing

00:11:56,210 --> 00:12:01,790
actually from the spec four and an API

00:11:59,720 --> 00:12:02,840
that we think are really important and

00:12:01,790 --> 00:12:05,680
there's some of the priorities that we

00:12:02,840 --> 00:12:05,680
listed with those as well

00:12:10,460 --> 00:12:15,830
all right so hexagon NN is the open

00:12:13,010 --> 00:12:19,160
source library that supports machine

00:12:15,830 --> 00:12:20,810
learning operations on the DSP there are

00:12:19,160 --> 00:12:22,870
currently already used by some other

00:12:20,810 --> 00:12:24,890
runtimes other than just snappy

00:12:22,870 --> 00:12:31,160
Snapdragon neural processing engine or

00:12:24,890 --> 00:12:33,650
the or Android nn mace has taken the

00:12:31,160 --> 00:12:35,600
code and forked a version of it it's

00:12:33,650 --> 00:12:37,340
part of their sorry Xiao Mei has done

00:12:35,600 --> 00:12:40,040
that in the context of mace which they

00:12:37,340 --> 00:12:43,850
released this year and then tensorflow

00:12:40,040 --> 00:12:45,320
has a contributor which I believe the

00:12:43,850 --> 00:12:47,450
hexagon team has been working with to

00:12:45,320 --> 00:12:50,420
provide an optimized back-end for

00:12:47,450 --> 00:12:52,750
running tensorflow so some of the

00:12:50,420 --> 00:12:55,610
Cabot's of using hexagon and n are that

00:12:52,750 --> 00:12:59,960
you have to have a test signature to run

00:12:55,610 --> 00:13:03,950
binaries on the on the DSP there is

00:12:59,960 --> 00:13:06,560
tools to do the signing but you will

00:13:03,950 --> 00:13:07,820
typically either need an OEM signature

00:13:06,560 --> 00:13:08,900
or you will have to have a test

00:13:07,820 --> 00:13:10,400
signature and if you're going to run a

00:13:08,900 --> 00:13:12,590
test signature you're using need a

00:13:10,400 --> 00:13:13,910
device that you can have rooted so if

00:13:12,590 --> 00:13:15,470
you're trying to do this on a commercial

00:13:13,910 --> 00:13:17,090
device you want to have a device that

00:13:15,470 --> 00:13:22,820
you can buy and then route in order to

00:13:17,090 --> 00:13:25,250
do your testing so the flow for the sign

00:13:22,820 --> 00:13:29,270
binaries is the you have the Libman n

00:13:25,250 --> 00:13:30,740
from hexagon and then you have tools

00:13:29,270 --> 00:13:32,510
that can get the device serial number

00:13:30,740 --> 00:13:34,790
you run it through the elf signer it can

00:13:32,510 --> 00:13:37,820
buy it generates this test signature and

00:13:34,790 --> 00:13:39,680
a version of the library which works

00:13:37,820 --> 00:13:40,940
with that those both get pushed to the

00:13:39,680 --> 00:13:45,350
device and when those things are both

00:13:40,940 --> 00:13:50,290
present and and supported then you can

00:13:45,350 --> 00:13:50,290
basically run your program on the DSP

00:13:51,690 --> 00:13:56,020
so here's the feature matrix so there's

00:13:54,010 --> 00:13:58,810
several different versions of DSPs

00:13:56,020 --> 00:14:03,150
and then there are some variants of the

00:13:58,810 --> 00:14:05,890
DSP so there's a audio DSP compute DSP

00:14:03,150 --> 00:14:08,580
sensors DSP a sensor core DSP and then

00:14:05,890 --> 00:14:11,230
the mobile DSP so the mobile DSP is a

00:14:08,580 --> 00:14:12,670
modem DSP I guess so the modem DSP

00:14:11,230 --> 00:14:14,050
clearly runs the modem most of the times

00:14:12,670 --> 00:14:15,610
but there are configurations where you

00:14:14,050 --> 00:14:17,830
have a device like a tablet that may not

00:14:15,610 --> 00:14:19,870
have a modem the processor may have a

00:14:17,830 --> 00:14:22,450
modem DSP and then it can also be used

00:14:19,870 --> 00:14:24,630
for compute so that's the last column

00:14:22,450 --> 00:14:26,890
therefore the mdsp

00:14:24,630 --> 00:14:30,730
court is the operating system that runs

00:14:26,890 --> 00:14:32,800
on the DSP and then la is linux android

00:14:30,730 --> 00:14:37,090
so there's android variants supported on

00:14:32,800 --> 00:14:38,800
the application processor in the case of

00:14:37,090 --> 00:14:40,180
820 there's the automotive variant which

00:14:38,800 --> 00:14:43,620
is not running Android it's running a

00:14:40,180 --> 00:14:50,350
Linux standard Linux in fact a GL

00:14:43,620 --> 00:14:53,980
variant so htx is supported on the v6 TV

00:14:50,350 --> 00:14:55,420
62 and v65 hexagon DSPs I had mentioned

00:14:53,980 --> 00:14:57,790
earlier the Snapdragon Flight was

00:14:55,420 --> 00:14:59,830
supported it actually has an older GSP

00:14:57,790 --> 00:15:02,500
that does not support HDX so the

00:14:59,830 --> 00:15:08,830
framework will not support the DSP on

00:15:02,500 --> 00:15:10,450
that particular platform I think and and

00:15:08,830 --> 00:15:14,430
all this stuff is inside the release

00:15:10,450 --> 00:15:14,430
notes for the hexagon SDK

00:15:17,030 --> 00:15:23,060
so sometime for the end so in general we

00:15:20,090 --> 00:15:26,120
see the opportunity to take all these

00:15:23,060 --> 00:15:27,590
mobile centric technologies and all the

00:15:26,120 --> 00:15:29,060
innovation that's going on in the mobile

00:15:27,590 --> 00:15:31,880
space and then taking that and applying

00:15:29,060 --> 00:15:34,930
it to other markets like automotive

00:15:31,880 --> 00:15:38,240
healthcare etc and we really see that

00:15:34,930 --> 00:15:43,330
it's exciting to see all the different

00:15:38,240 --> 00:15:51,500
things being able by a a today thank you

00:15:43,330 --> 00:15:54,400
thank you Morrow any question any

00:15:51,500 --> 00:15:54,400
question for mark

00:16:01,940 --> 00:16:07,920
thanks a lot do you plan any

00:16:04,710 --> 00:16:10,050
collaboration with the arm and n so that

00:16:07,920 --> 00:16:12,480
you use maybe a compute library or that

00:16:10,050 --> 00:16:15,840
you contribute some part for your cheap

00:16:12,480 --> 00:16:16,950
use or the DSP yeah we we've been

00:16:15,840 --> 00:16:18,330
exploring with them with the

00:16:16,950 --> 00:16:22,170
collaboration opportunities are

00:16:18,330 --> 00:16:24,540
certainly if you look at art the hexagon

00:16:22,170 --> 00:16:28,410
and n once there's the plug-in interface

00:16:24,540 --> 00:16:29,880
to find for our men n and it solid then

00:16:28,410 --> 00:16:33,240
there's an opportunity for us to

00:16:29,880 --> 00:16:37,830
potentially create a I plug-in using the

00:16:33,240 --> 00:16:39,930
hexagon n n api's to GPU be used we

00:16:37,830 --> 00:16:44,850
would have to create a separate plugin

00:16:39,930 --> 00:16:45,810
for the Adreno GPU because as he

00:16:44,850 --> 00:16:47,340
mentioned that could be an order of

00:16:45,810 --> 00:16:49,200
magnitude difference in performance for

00:16:47,340 --> 00:16:51,360
the the Mallee GPU kernels that are

00:16:49,200 --> 00:16:52,890
there right now but yeah it does seem

00:16:51,360 --> 00:16:54,990
like an interesting prospect and

00:16:52,890 --> 00:16:56,130
definitely we want to pursue what

00:16:54,990 --> 00:16:58,610
opportunities there might be there for

00:16:56,130 --> 00:16:58,610
collaboration

00:17:07,630 --> 00:17:14,620
okay thank you very much right I think

00:17:11,289 --> 00:17:18,309
we can have a five-minute break and at

00:17:14,620 --> 00:17:21,150
the hour we start with Tom Lane from

00:17:18,309 --> 00:17:21,150
Amazon

00:17:22,079 --> 00:17:27,088

YouTube URL: https://www.youtube.com/watch?v=MgyfmaYhtLU


