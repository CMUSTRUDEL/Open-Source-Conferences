Title: BKK19-207 -  OpenAMP Libmetal Shared Memory Cross OS Interface
Publication date: 2019-04-11
Playlist: Linaro Connect Bangkok 2019
Description: 
	Abstract
This session will describe the OpenAMP libmetal shared memory API. The talk will include the interface default backend implementation in Linux system

Wendy Liang
OpenAMP, Linux kernel, Embedded system
Captions: 
	00:00:05,509 --> 00:00:10,700
good morning everyone I'm Wendy from

00:00:07,910 --> 00:00:13,790
ceilings and I work with add on the open

00:00:10,700 --> 00:00:19,730
NP and thanks very much for the very

00:00:13,790 --> 00:00:24,290
good introduction of open amv so open

00:00:19,730 --> 00:00:27,500
AMPT current implementation it solved

00:00:24,290 --> 00:00:34,370
the lifecycle management and also the

00:00:27,500 --> 00:00:40,420
IPC issues between the computer between

00:00:34,370 --> 00:00:42,830
the CPUs in a heater jenea system and so

00:00:40,420 --> 00:00:45,710
openmp implement the our key message

00:00:42,830 --> 00:00:51,260
which is basically for the messaging and

00:00:45,710 --> 00:00:54,650
however we have CC'ing we have common

00:00:51,260 --> 00:00:59,239
resource on sharing large data between

00:00:54,650 --> 00:01:01,420
the processors and so to taste this

00:00:59,239 --> 00:01:06,350
presentation i'm going to talk about

00:01:01,420 --> 00:01:12,319
some ideas on how to solve the large

00:01:06,350 --> 00:01:17,659
data sharing with open the NP and so and

00:01:12,319 --> 00:01:21,590
we'll also as at mention we we have a

00:01:17,659 --> 00:01:25,310
metal layer for the cross OS

00:01:21,590 --> 00:01:30,259
abstractions for prime motive and we

00:01:25,310 --> 00:01:33,709
also have a shared memory abstraction to

00:01:30,259 --> 00:01:36,289
share the memory between processors and

00:01:33,709 --> 00:01:38,600
its devices and the coprocessor

00:01:36,289 --> 00:01:41,270
can also be considered as one type of

00:01:38,600 --> 00:01:49,060
devices so we will also talk about that

00:01:41,270 --> 00:01:53,200
too so today

00:01:49,060 --> 00:01:57,439
open the NP implement the IP message

00:01:53,200 --> 00:02:00,069
which is based on what i own and there

00:01:57,439 --> 00:02:03,709
is some limitation with the IP message

00:02:00,069 --> 00:02:08,750
the protocol itself is defined for

00:02:03,709 --> 00:02:11,000
message only as you can see this there

00:02:08,750 --> 00:02:14,900
is a field for the length of the payload

00:02:11,000 --> 00:02:17,500
and it is only 16-bit so in for some

00:02:14,900 --> 00:02:20,500
cases if you have

00:02:17,500 --> 00:02:24,700
multiple mac of data and RP message is

00:02:20,500 --> 00:02:31,870
not enough and it use what I owe what I

00:02:24,700 --> 00:02:36,820
owe it managed ring buffers so and all

00:02:31,870 --> 00:02:39,760
the and all the other buffers the length

00:02:36,820 --> 00:02:43,030
of the buffers in the rpms that remote

00:02:39,760 --> 00:02:45,970
IO implementation they are fixed even

00:02:43,030 --> 00:02:50,920
though we are talking about how to make

00:02:45,970 --> 00:02:55,720
the buffers configurable but however so

00:02:50,920 --> 00:02:58,480
far all the other pop-up shows it is

00:02:55,720 --> 00:03:04,690
still need to fix the buffers before the

00:02:58,480 --> 00:03:08,290
communication setup and also for in

00:03:04,690 --> 00:03:11,950
order for coprocessor to to write to

00:03:08,290 --> 00:03:14,739
share data with the master processor the

00:03:11,950 --> 00:03:17,980
application processor and the all the

00:03:14,739 --> 00:03:20,290
buffers need to be allocated by the

00:03:17,980 --> 00:03:23,350
master professor before the

00:03:20,290 --> 00:03:28,360
communication setup and for large data

00:03:23,350 --> 00:03:30,760
sharing we need to have better

00:03:28,360 --> 00:03:34,209
performance and we need zero copy and

00:03:30,760 --> 00:03:36,670
also where the memory is and the size of

00:03:34,209 --> 00:03:40,540
the required memory it can be predefined

00:03:36,670 --> 00:03:43,030
or it can be or it will be defined by

00:03:40,540 --> 00:03:45,970
the application at runtime that is we

00:03:43,030 --> 00:03:50,110
need dynamically allocate memory of

00:03:45,970 --> 00:03:54,250
large data at runtime and in mineral

00:03:50,110 --> 00:03:58,150
system we also have some issues with the

00:03:54,250 --> 00:04:02,170
existing ninis RP message implementation

00:03:58,150 --> 00:04:04,630
and for dinners in order to share large

00:04:02,170 --> 00:04:06,070
data between the process between the

00:04:04,630 --> 00:04:09,519
main processor and the core processor

00:04:06,070 --> 00:04:12,040
the application need to access directly

00:04:09,519 --> 00:04:17,739
to the share memory so we will have

00:04:12,040 --> 00:04:20,229
issue to expose the DMA the DMA buffer

00:04:17,739 --> 00:04:24,700
into the user application so that the

00:04:20,229 --> 00:04:27,840
user application can directly access the

00:04:24,700 --> 00:04:32,130
data from the share memory

00:04:27,840 --> 00:04:35,130
so this these are some use cases one is

00:04:32,130 --> 00:04:39,509
the share memory are defined and the

00:04:35,130 --> 00:04:42,240
other is the the memory is not pretty

00:04:39,509 --> 00:04:45,330
fund and you will need to irrigate it

00:04:42,240 --> 00:04:47,910
from the system memory at runtime the

00:04:45,330 --> 00:04:51,240
other it is it is possible that there is

00:04:47,910 --> 00:04:54,630
IO mmu between the main processor and

00:04:51,240 --> 00:04:59,060
the coprocessors so people are working

00:04:54,630 --> 00:05:03,210
on softest issues with different options

00:04:59,060 --> 00:05:06,509
so some people comes up with the app

00:05:03,210 --> 00:05:09,030
message zero copying support which this

00:05:06,509 --> 00:05:12,240
idea was from nxp in their app message

00:05:09,030 --> 00:05:15,180
light and also recently some company

00:05:12,240 --> 00:05:20,190
like Xiaomi he is trying to they are

00:05:15,180 --> 00:05:25,710
trying to to at this support 20 support

00:05:20,190 --> 00:05:29,009
in geo OpenMP but this change there were

00:05:25,710 --> 00:05:31,710
however this proposal there is no change

00:05:29,009 --> 00:05:35,130
to the app message buffer allocation and

00:05:31,710 --> 00:05:38,780
all the buffers are stupid allocated and

00:05:35,130 --> 00:05:43,849
each buffer as the effect size and so

00:05:38,780 --> 00:05:47,690
and this per however what is what is

00:05:43,849 --> 00:05:52,050
proposal gates to user is instead of

00:05:47,690 --> 00:05:55,430
unit you copy the message data from

00:05:52,050 --> 00:06:00,509
application memory into the share memory

00:05:55,430 --> 00:06:04,020
the the library can directly expose the

00:06:00,509 --> 00:06:06,930
pelo the pelo area of the shape of our

00:06:04,020 --> 00:06:10,469
into application so this will help to

00:06:06,930 --> 00:06:14,340
improve the performance for sending shot

00:06:10,469 --> 00:06:19,400
messages and the other idea was actually

00:06:14,340 --> 00:06:24,810
from mantle they they were talking about

00:06:19,400 --> 00:06:28,620
to have chained buffers to increase the

00:06:24,810 --> 00:06:33,990
size of the app message buffers but

00:06:28,620 --> 00:06:37,409
however with this approach the chamber

00:06:33,990 --> 00:06:39,830
far is actually a scatter catalyst so

00:06:37,409 --> 00:06:42,830
some cases if you want to use kindig

00:06:39,830 --> 00:06:47,180
memory for your large data you cannot

00:06:42,830 --> 00:06:50,240
use this this approach and also because

00:06:47,180 --> 00:06:54,590
the IP message itself the length field

00:06:50,240 --> 00:06:57,229
it's just a stupid so in some cases if

00:06:54,590 --> 00:07:00,050
your if your data size is larger than

00:06:57,229 --> 00:07:02,090
that and this doesn't fit so there are

00:07:00,050 --> 00:07:04,970
multiple approaches with different use

00:07:02,090 --> 00:07:09,349
cases and there is one which mentioned

00:07:04,970 --> 00:07:13,580
by Thomas earlier which is we some user

00:07:09,349 --> 00:07:18,409
they allocate the memory at runtime and

00:07:13,580 --> 00:07:20,419
then use a message to to exchange the

00:07:18,409 --> 00:07:23,120
share memory information and use up a

00:07:20,419 --> 00:07:25,400
message for synchronization and this is

00:07:23,120 --> 00:07:34,310
the option I'm going to give more

00:07:25,400 --> 00:07:38,629
details in today's discussion so for

00:07:34,310 --> 00:07:43,759
large data sharing there are a couple

00:07:38,629 --> 00:07:46,340
common steps to we usually do one it is

00:07:43,759 --> 00:07:49,240
you will allocate the memory from some

00:07:46,340 --> 00:07:52,430
memory allocator after you've got this

00:07:49,240 --> 00:07:56,630
allocated shared memory you will attach

00:07:52,430 --> 00:07:59,930
this memory to a remote prop and this

00:07:56,630 --> 00:08:02,630
attachment what it will do is it can if

00:07:59,930 --> 00:08:06,110
you you can achieve the device address

00:08:02,630 --> 00:08:07,340
from the attachment because the

00:08:06,110 --> 00:08:10,310
coprocessor

00:08:07,340 --> 00:08:13,789
the address space may not be the same as

00:08:10,310 --> 00:08:17,690
the main processor so you will meet you

00:08:13,789 --> 00:08:20,990
know that device adjust in order to tell

00:08:17,690 --> 00:08:24,319
the coprocessor where the memory is and

00:08:20,990 --> 00:08:26,690
maybe you will use something some

00:08:24,319 --> 00:08:30,560
perform specific synchronization matter

00:08:26,690 --> 00:08:33,500
for example like hardware locks and in

00:08:30,560 --> 00:08:35,240
this attachment operation you can

00:08:33,500 --> 00:08:40,039
prepare for those synchronization

00:08:35,240 --> 00:08:42,860
resource and then you can send the

00:08:40,039 --> 00:08:46,160
message to the core processor to tell

00:08:42,860 --> 00:08:48,160
about this is the share memory I'm going

00:08:46,160 --> 00:08:52,070
to use to share some data with you and

00:08:48,160 --> 00:08:57,560
then this is about a set up

00:08:52,070 --> 00:09:00,470
and after the setup and when you after

00:08:57,560 --> 00:09:03,980
the Ming processor write something to

00:09:00,470 --> 00:09:07,130
the to the share memory and and get it

00:09:03,980 --> 00:09:07,850
ready to share this this data to the

00:09:07,130 --> 00:09:15,080
coprocessor

00:09:07,850 --> 00:09:18,830
and you will do a star sync operation to

00:09:15,080 --> 00:09:21,980
the remote prop so that you can a map

00:09:18,830 --> 00:09:23,600
the memory for to the main processor so

00:09:21,980 --> 00:09:27,380
that our main processor will no longer

00:09:23,600 --> 00:09:31,550
access memory and then you can use app

00:09:27,380 --> 00:09:34,850
message to tell the coprocessor there is

00:09:31,550 --> 00:09:39,590
some shared data ready for you to assess

00:09:34,850 --> 00:09:43,130
and then when the coprocessor finished

00:09:39,590 --> 00:09:47,300
assessing the data and the application

00:09:43,130 --> 00:09:52,070
you do a sync and operation which it is

00:09:47,300 --> 00:09:55,910
to make sure the coprocessor do not do

00:09:52,070 --> 00:09:59,450
not touch the memory and make sure the

00:09:55,910 --> 00:10:02,480
memory is M mapped that you is a mapped

00:09:59,450 --> 00:10:08,560
so that the main processor can continue

00:10:02,480 --> 00:10:11,750
to use the map to use the memory so

00:10:08,560 --> 00:10:16,550
that's the explanation of those steps

00:10:11,750 --> 00:10:19,460
and for memory system the education can

00:10:16,550 --> 00:10:24,020
be simple for something like malloc but

00:10:19,460 --> 00:10:26,510
however if the operating system is a

00:10:24,020 --> 00:10:29,090
little bit more more complicated the

00:10:26,510 --> 00:10:31,820
memory is not flat for example Adina's

00:10:29,090 --> 00:10:34,480
kernel there is kernel space user space

00:10:31,820 --> 00:10:40,760
and then we need to have a more

00:10:34,480 --> 00:10:44,450
complicated approach so this is about

00:10:40,760 --> 00:10:46,550
some idea on how to use up message for

00:10:44,450 --> 00:10:49,910
shared memories and colonization so

00:10:46,550 --> 00:10:52,590
today we don't have this serviced yet in

00:10:49,910 --> 00:10:56,400
the OpenMP however

00:10:52,590 --> 00:11:00,480
sigh this is a very common issue so we

00:10:56,400 --> 00:11:03,150
are trying to have some common happy

00:11:00,480 --> 00:11:06,960
message service should cover that so

00:11:03,150 --> 00:11:09,600
basically we use our message to tell the

00:11:06,960 --> 00:11:19,260
coprocessor where the share memory is

00:11:09,600 --> 00:11:23,540
and use the IP message to sync up so

00:11:19,260 --> 00:11:29,850
let's talk about the tardiness

00:11:23,540 --> 00:11:33,510
implementation and in meanness there is

00:11:29,850 --> 00:11:38,150
a remote kernel driver and a B message

00:11:33,510 --> 00:11:41,730
kernel driver and at the moment

00:11:38,150 --> 00:11:45,420
different windows has a different way to

00:11:41,730 --> 00:11:48,330
educate a memory and tell the the

00:11:45,420 --> 00:11:50,070
coprocessor where the memory is and so

00:11:48,330 --> 00:11:53,040
we are looking for a common way and

00:11:50,070 --> 00:11:56,580
today there is some limitation to the

00:11:53,040 --> 00:11:59,010
remote proc implementation remote Pro it

00:11:56,580 --> 00:12:01,410
uses the resource table to describe the

00:11:59,010 --> 00:12:05,010
shared resources including the share

00:12:01,410 --> 00:12:07,680
memory but however in order to use the

00:12:05,010 --> 00:12:10,580
resource table to describe the share

00:12:07,680 --> 00:12:14,010
memory the share memory need to be

00:12:10,580 --> 00:12:17,130
pre-allocated even before the leaners

00:12:14,010 --> 00:12:20,790
loads the coprocessor and which it is

00:12:17,130 --> 00:12:24,360
not feasible in a lot of cases because

00:12:20,790 --> 00:12:26,940
we need we don't even know the size and

00:12:24,360 --> 00:12:32,820
whether share memory should be for large

00:12:26,940 --> 00:12:36,230
data and also today the resource table

00:12:32,820 --> 00:12:39,300
it only supports the word IO devices and

00:12:36,230 --> 00:12:43,380
but however in a lot of application

00:12:39,300 --> 00:12:46,770
those large data those large memory for

00:12:43,380 --> 00:12:51,140
shared data it is not what IO devices

00:12:46,770 --> 00:12:51,140
it's just some large chunk of memory

00:12:51,710 --> 00:12:59,350
so here so that's what we are that's

00:12:55,240 --> 00:13:02,390
some idea to how to solve it with some

00:12:59,350 --> 00:13:06,200
changes to the current limo pro

00:13:02,390 --> 00:13:09,170
implementation about allocating the

00:13:06,200 --> 00:13:12,709
memory we need to allocate the memory

00:13:09,170 --> 00:13:16,610
from some anakata

00:13:12,709 --> 00:13:19,730
unlike the flat memory system earliness

00:13:16,610 --> 00:13:23,140
is different and in this user space

00:13:19,730 --> 00:13:28,070
usually cannot directly access that DMA

00:13:23,140 --> 00:13:31,730
memory so we found that there is a yawn

00:13:28,070 --> 00:13:35,870
implementation which it is used to

00:13:31,730 --> 00:13:38,589
manage memory proofs and today the eye

00:13:35,870 --> 00:13:43,279
on it is in the staging area it is

00:13:38,589 --> 00:13:46,760
introduced by Android and it exposed a

00:13:43,279 --> 00:13:50,930
DMA buffer to the to the dimmest user

00:13:46,760 --> 00:13:56,300
space with the DMA buff kernel

00:13:50,930 --> 00:13:58,790
implementation the the DMA memory can be

00:13:56,300 --> 00:14:02,990
shared within different Nina's kernel

00:13:58,790 --> 00:14:08,540
devices and also the Venus user space

00:14:02,990 --> 00:14:12,140
applications and so after we get a DMA

00:14:08,540 --> 00:14:14,930
puff from the ion and also this ion you

00:14:12,140 --> 00:14:17,980
can allocate memory from the system

00:14:14,930 --> 00:14:20,870
memory or you can also specify your

00:14:17,980 --> 00:14:23,300
specific memory pool to tell where you

00:14:20,870 --> 00:14:25,400
want this memory from so it will also

00:14:23,300 --> 00:14:28,580
work for statically defined shared

00:14:25,400 --> 00:14:31,370
memory and after you've got the after

00:14:28,580 --> 00:14:37,940
the application got a DMA pass from the

00:14:31,370 --> 00:14:41,570
ion and we can we will need to expose

00:14:37,940 --> 00:14:43,700
export this DM a path to a remote to a

00:14:41,570 --> 00:14:46,430
device driver for some whole either

00:14:43,700 --> 00:14:50,750
remove pop driver which it is for the

00:14:46,430 --> 00:14:53,779
coprocessor case and today there is no

00:14:50,750 --> 00:14:57,740
API for more profit over to get a DMA

00:14:53,779 --> 00:15:01,880
path so we suggest you introduce a API

00:14:57,740 --> 00:15:04,620
for the mo probe to so that it can you

00:15:01,880 --> 00:15:06,570
can get the DMA path from the user space

00:15:04,620 --> 00:15:10,790
and the remote probe we need to

00:15:06,570 --> 00:15:13,830
implement DMA above Colonel operations

00:15:10,790 --> 00:15:17,340
the the DMF of operations defined by the

00:15:13,830 --> 00:15:20,730
linux kernel and then from this

00:15:17,340 --> 00:15:24,870
operation from importing from exporting

00:15:20,730 --> 00:15:27,510
the DMA path to the remote probe and the

00:15:24,870 --> 00:15:31,980
user application can get the device

00:15:27,510 --> 00:15:33,990
adjusts of the share memory so that

00:15:31,980 --> 00:15:37,250
because the remote probe knows the

00:15:33,990 --> 00:15:42,150
device adjust mapping of the coprocessor

00:15:37,250 --> 00:15:44,580
and then the the application can send a

00:15:42,150 --> 00:15:46,920
message to the core processor to tell

00:15:44,580 --> 00:15:50,070
the common sense aware the shared memory

00:15:46,920 --> 00:15:51,990
is and how big the size is and so that

00:15:50,070 --> 00:15:56,250
the core processor on its own site

00:15:51,990 --> 00:16:02,550
it can do memory mapping in order for it

00:15:56,250 --> 00:16:04,770
to assess the memory and then dinners

00:16:02,550 --> 00:16:06,930
and then the user application when it is

00:16:04,770 --> 00:16:09,840
ready to share the data to with the

00:16:06,930 --> 00:16:14,430
coprocessor it can use the standard

00:16:09,840 --> 00:16:18,570
Linux kernel EMF of operation the DMA

00:16:14,430 --> 00:16:25,290
pop operation provides sync to device

00:16:18,570 --> 00:16:28,110
and sink to CPU so that the so that the

00:16:25,290 --> 00:16:31,050
memory can be a mapped for the

00:16:28,110 --> 00:16:34,620
coprocessor to SS and it can be mapped

00:16:31,050 --> 00:16:37,460
again so that CPU can SS them so that

00:16:34,620 --> 00:16:44,100
application can assess the memory again

00:16:37,460 --> 00:16:46,830
and user application will also need to

00:16:44,100 --> 00:16:50,700
use a key message to tell the

00:16:46,830 --> 00:16:54,780
coprocessor when you can assess the

00:16:50,700 --> 00:16:57,390
memory and when when the coprocessor can

00:16:54,780 --> 00:16:59,640
assess the memory and the processor can

00:16:57,390 --> 00:17:04,200
also use up a message to tell the

00:16:59,640 --> 00:17:07,340
application I have done with with the

00:17:04,200 --> 00:17:10,680
memory access and of course if you have

00:17:07,340 --> 00:17:13,290
if your platform support

00:17:10,680 --> 00:17:15,120
some other locking mechanism you don't

00:17:13,290 --> 00:17:18,270
have to use the IP message for the

00:17:15,120 --> 00:17:25,590
synchronization but our message is it is

00:17:18,270 --> 00:17:27,900
a generic way and so in case of iommu it

00:17:25,590 --> 00:17:30,060
is actually easier from the application

00:17:27,900 --> 00:17:34,050
point of view it just allocate some

00:17:30,060 --> 00:17:38,850
memory some space and then ask remote

00:17:34,050 --> 00:17:40,740
proc to do a DMA mapping and then and

00:17:38,850 --> 00:17:42,450
then it can use a key message to tell

00:17:40,740 --> 00:17:50,160
the coprocessor and for the

00:17:42,450 --> 00:17:54,360
synchronization as well so actually the

00:17:50,160 --> 00:17:57,060
process for a application to share the

00:17:54,360 --> 00:17:59,700
memory with a coprocessor it is very

00:17:57,060 --> 00:18:02,520
similar for the application to share the

00:17:59,700 --> 00:18:09,510
memory to share large data with a device

00:18:02,520 --> 00:18:12,270
and as we and as a tension we have a bit

00:18:09,510 --> 00:18:15,660
metal layer which it is provide a

00:18:12,270 --> 00:18:18,270
primitive extraction across different

00:18:15,660 --> 00:18:22,160
operating system and hardware platform

00:18:18,270 --> 00:18:25,290
and today the leap metal provides a io

00:18:22,160 --> 00:18:27,690
abstraction interrupt abstraction device

00:18:25,290 --> 00:18:30,990
obstruction and some locks obstruction

00:18:27,690 --> 00:18:36,180
and so we are thinking about to extend

00:18:30,990 --> 00:18:41,660
it to at a share memory extraction to to

00:18:36,180 --> 00:18:44,990
cover the memory sharing between the the

00:18:41,660 --> 00:18:51,660
processor and the devices and also

00:18:44,990 --> 00:18:55,830
between the coprocessors so this is our

00:18:51,660 --> 00:18:57,900
what we are working on so this is the

00:18:55,830 --> 00:19:03,080
shape man this is the net metal share

00:18:57,900 --> 00:19:05,850
memory abstraction api's you open a

00:19:03,080 --> 00:19:09,360
share memory with the lip metal share

00:19:05,850 --> 00:19:12,860
map api and this operation it will

00:19:09,360 --> 00:19:18,120
return you a share memory objects and

00:19:12,860 --> 00:19:21,270
then you use the share memory attachment

00:19:18,120 --> 00:19:24,780
operation and this operation

00:19:21,270 --> 00:19:27,900
can prepared can attach assign the

00:19:24,780 --> 00:19:32,160
memory to a device coprocessor or

00:19:27,900 --> 00:19:35,760
another process and then that you can

00:19:32,160 --> 00:19:38,880
use the new metal memory sync api to

00:19:35,760 --> 00:19:42,720
sync the shipment to sync the share

00:19:38,880 --> 00:19:50,750
memory between the main processor the

00:19:42,720 --> 00:19:56,130
device coprocessor or other processes so

00:19:50,750 --> 00:20:00,990
and so we are and then we are thinking

00:19:56,130 --> 00:20:04,710
about to use this new metal api as the

00:20:00,990 --> 00:20:07,050
main api to share the memory between

00:20:04,710 --> 00:20:10,710
core processor and device and domain and

00:20:07,050 --> 00:20:15,350
the main processor and then have the IP

00:20:10,710 --> 00:20:22,410
message and remote proc implementation

00:20:15,350 --> 00:20:26,070
under the metal api for the for the

00:20:22,410 --> 00:20:30,390
large data sharing between the between

00:20:26,070 --> 00:20:36,990
the data processors in a heater genius

00:20:30,390 --> 00:20:45,810
system so but however in this there is

00:20:36,990 --> 00:20:49,260
something which we we are still in

00:20:45,810 --> 00:20:52,670
discussion and we haven't really sorted

00:20:49,260 --> 00:20:55,080
out how to shop yet which is there is a

00:20:52,670 --> 00:20:57,600
message implementation inside the

00:20:55,080 --> 00:21:01,080
Dinah's kernel and so there is use cases

00:20:57,600 --> 00:21:04,050
that not just the meanest user space

00:21:01,080 --> 00:21:07,680
application want to share the the large

00:21:04,050 --> 00:21:10,410
data with the coprocessor so some cases

00:21:07,680 --> 00:21:13,800
it is also possible that there is a

00:21:10,410 --> 00:21:16,440
kernel driver to share that the want to

00:21:13,800 --> 00:21:18,660
share the data with the coprocessor but

00:21:16,440 --> 00:21:23,040
we haven't figured really figure out how

00:21:18,660 --> 00:21:25,500
to do it yet because we in order to

00:21:23,040 --> 00:21:28,860
share them in order to tell the

00:21:25,500 --> 00:21:31,950
coprocessor where the memory is

00:21:28,860 --> 00:21:34,230
the coprocessor share the same adjust

00:21:31,950 --> 00:21:36,210
wheel as the main processor otherwise

00:21:34,230 --> 00:21:39,720
you need to know the device address

00:21:36,210 --> 00:21:42,539
mapping of the coprocessor and only the

00:21:39,720 --> 00:21:48,990
remote probe knows those address mapping

00:21:42,539 --> 00:21:53,960
and so so far that's the ugly message

00:21:48,990 --> 00:21:57,390
device doesn't know which remote device

00:21:53,960 --> 00:22:00,899
this upper message device is attached to

00:21:57,390 --> 00:22:04,620
and the remote Pro doesn't device

00:22:00,899 --> 00:22:06,299
doesn't know which other message devices

00:22:04,620 --> 00:22:09,480
attached to it either

00:22:06,299 --> 00:22:15,779
so this is a still a open issue we need

00:22:09,480 --> 00:22:20,340
to figure out for those cases and so I

00:22:15,779 --> 00:22:35,059
think that's all my sharing today so any

00:22:20,340 --> 00:22:37,590
questions are you breaking the lip metal

00:22:35,059 --> 00:22:39,960
abstraction view right if what you're

00:22:37,590 --> 00:22:42,899
saying is that lib metal would then call

00:22:39,960 --> 00:22:46,440
into our P message right that's kind of

00:22:42,899 --> 00:22:48,600
backwards I guess from what it would the

00:22:46,440 --> 00:22:50,809
way it works today right where our pH is

00:22:48,600 --> 00:22:53,429
been using live metal to abstract

00:22:50,809 --> 00:22:57,059
functionality so it feels like there

00:22:53,429 --> 00:22:58,830
should be something else right yes so

00:22:57,059 --> 00:23:03,270
this is what we are thinking about

00:22:58,830 --> 00:23:06,450
whether that because if you look at a

00:23:03,270 --> 00:23:09,240
higher level the coprocessor can also be

00:23:06,450 --> 00:23:11,340
considered as a device and also the

00:23:09,240 --> 00:23:13,890
leaners kernel provides a key message

00:23:11,340 --> 00:23:16,710
interface and removal interface so

00:23:13,890 --> 00:23:20,820
that's why we are thinking we can have

00:23:16,710 --> 00:23:25,620
another abstraction so that you to make

00:23:20,820 --> 00:23:27,149
a generic API to for the I think sorry I

00:23:25,620 --> 00:23:29,100
think the abstraction is fine I just

00:23:27,149 --> 00:23:30,710
don't think I would call it Lib metal I

00:23:29,100 --> 00:23:32,300
think the

00:23:30,710 --> 00:23:34,700
you know I get the idea of the

00:23:32,300 --> 00:23:37,700
abstraction I just think the what lip

00:23:34,700 --> 00:23:40,610
metal has been to date this doesn't fit

00:23:37,700 --> 00:23:42,410
to me the layer where you're cutting it

00:23:40,610 --> 00:23:43,970
right where lip metal has kind of sort

00:23:42,410 --> 00:23:46,490
of provided a set of services of

00:23:43,970 --> 00:23:48,080
abstraction I think this is kind of

00:23:46,490 --> 00:23:51,260
inverted from what has been there

00:23:48,080 --> 00:23:52,700
historically so I would I think the

00:23:51,260 --> 00:23:56,360
abstraction I understand I just would

00:23:52,700 --> 00:23:59,440
have it be called something new for one

00:23:56,360 --> 00:24:04,840
I guess the other question I have is

00:23:59,440 --> 00:24:07,580
what's the use case for the coprocessor

00:24:04,840 --> 00:24:11,980
needing to request memory versus being

00:24:07,580 --> 00:24:16,130
told where memory is yeah it is possible

00:24:11,980 --> 00:24:20,060
so there can be cases that it is the

00:24:16,130 --> 00:24:22,880
whole processor want to tell the main

00:24:20,060 --> 00:24:26,030
processor I want to share the data with

00:24:22,880 --> 00:24:28,700
main processor so what we are thinking

00:24:26,030 --> 00:24:31,430
it is we can do this with a key message

00:24:28,700 --> 00:24:33,950
so it is to the main processor to

00:24:31,430 --> 00:24:37,130
allocate the memory but it is the

00:24:33,950 --> 00:24:39,410
coprocessor to send a request to the

00:24:37,130 --> 00:24:41,450
main processor right I guess what I'm

00:24:39,410 --> 00:24:43,040
trying to understand is what so if I

00:24:41,450 --> 00:24:45,320
think of the coprocessor is being a

00:24:43,040 --> 00:24:48,260
device right and you think about DMA

00:24:45,320 --> 00:24:51,040
style devices typically right so let's

00:24:48,260 --> 00:24:53,090
take an Ethernet controller right at the

00:24:51,040 --> 00:24:56,090
processor and the driver there is

00:24:53,090 --> 00:24:58,790
responsible for setting up a ring

00:24:56,090 --> 00:25:01,760
structure with memory adverb you know

00:24:58,790 --> 00:25:03,970
buffers for the let's say the Ethernet

00:25:01,760 --> 00:25:06,110
receive - right in - right so that

00:25:03,970 --> 00:25:08,360
coprocessor in this case is the Ethernet

00:25:06,110 --> 00:25:11,600
controller and it is told where the

00:25:08,360 --> 00:25:14,180
memory is right it's not ever requesting

00:25:11,600 --> 00:25:15,920
back somehow where so I've just try

00:25:14,180 --> 00:25:18,860
understand I imagine there is some use

00:25:15,920 --> 00:25:20,960
case or some use model that is that you

00:25:18,860 --> 00:25:21,950
guys have or something of when it is

00:25:20,960 --> 00:25:24,550
that what you know what's the

00:25:21,950 --> 00:25:28,100
application example of the coprocessor

00:25:24,550 --> 00:25:31,400
wanting to ask for memory versus sort of

00:25:28,100 --> 00:25:33,710
being initialized and told an over run

00:25:31,400 --> 00:25:35,390
time maybe in some ring structure or

00:25:33,710 --> 00:25:37,880
something that here's where the here's

00:25:35,390 --> 00:25:41,090
here where the buffers are for you to

00:25:37,880 --> 00:25:42,880
either work on or here's a pool of

00:25:41,090 --> 00:25:43,990
buffers for you to write to

00:25:42,880 --> 00:25:51,070
whatever it is that you're trying to

00:25:43,990 --> 00:25:54,160
accomplish right so here it sounds to me

00:25:51,070 --> 00:25:56,310
that it looks I in this case it is more

00:25:54,160 --> 00:25:59,020
light or share memory it is pretty find

00:25:56,310 --> 00:26:03,220
is it correct and then it is not like

00:25:59,020 --> 00:26:05,680
the Eco processor dynamically decide I

00:26:03,220 --> 00:26:07,900
want to share some data about however it

00:26:05,680 --> 00:26:10,960
is pretty found it's not that it's

00:26:07,900 --> 00:26:13,060
predefined it's just that as as the life

00:26:10,960 --> 00:26:15,460
cycle of what you're doing though it's

00:26:13,060 --> 00:26:17,730
who owns the memory right and in this

00:26:15,460 --> 00:26:20,860
case the memory is managed and owned by

00:26:17,730 --> 00:26:22,540
quote unquote the host processor right

00:26:20,860 --> 00:26:24,670
but it's still it can still be

00:26:22,540 --> 00:26:27,490
dynamically managed and allocated over

00:26:24,670 --> 00:26:30,370
the life cycle to the coprocessor so

00:26:27,490 --> 00:26:32,320
what I'm trying to understand is what's

00:26:30,370 --> 00:26:34,660
the user there's some example that you

00:26:32,320 --> 00:26:36,990
guys must have of what it is that the

00:26:34,660 --> 00:26:40,750
coprocessor wants to explicitly ask

00:26:36,990 --> 00:26:43,150
versus being told where the memory a

00:26:40,750 --> 00:26:47,590
buffer is for it to use for some

00:26:43,150 --> 00:26:49,480
application purpose right so so far we

00:26:47,590 --> 00:26:53,980
haven't actually have this case but I

00:26:49,480 --> 00:26:58,630
believe that that is such a cases so in

00:26:53,980 --> 00:27:01,660
our our cases it is more like you still

00:26:58,630 --> 00:27:07,270
need someone to manage the share memory

00:27:01,660 --> 00:27:09,910
and so this one it is so for all the

00:27:07,270 --> 00:27:13,540
cases are described in this session it

00:27:09,910 --> 00:27:16,780
is always the the main processor so even

00:27:13,540 --> 00:27:20,050
the coprocessor won't you share data it

00:27:16,780 --> 00:27:22,720
needs to ask but however we may also

00:27:20,050 --> 00:27:25,930
want to consider whether the memory

00:27:22,720 --> 00:27:30,570
allocator can be exists outside of these

00:27:25,930 --> 00:27:34,870
two processors as well but we haven't

00:27:30,570 --> 00:27:37,510
think through it yet okay but that's a

00:27:34,870 --> 00:27:39,840
very good use case to to we need to

00:27:37,510 --> 00:27:39,840
consider

00:27:46,179 --> 00:27:50,659
it's just that this is one of those

00:27:48,830 --> 00:27:53,059
things we're going to discuss in the in

00:27:50,659 --> 00:28:03,049
the meeting tomorrow yeah I've got a

00:27:53,059 --> 00:28:06,740
bunch of other questions did you take

00:28:03,049 --> 00:28:09,980
trustzone into account into this opening

00:28:06,740 --> 00:28:22,429
and regarding what is trusted who can

00:28:09,980 --> 00:28:24,919
access which so we have fun so what I

00:28:22,429 --> 00:28:27,529
put in this slide haven't considered

00:28:24,919 --> 00:28:32,179
that rustle but it looks like there is a

00:28:27,529 --> 00:28:35,830
opti which can also allocate them so

00:28:32,179 --> 00:28:40,549
that you can control you can limit your

00:28:35,830 --> 00:28:45,980
DMA SS but maybe this is also another

00:28:40,549 --> 00:28:47,330
thing we can consider as well can you go

00:28:45,980 --> 00:28:48,309
back to the slide that you kind of

00:28:47,330 --> 00:28:53,960
talked about some of the other

00:28:48,309 --> 00:28:55,519
implementations or you know people have

00:28:53,960 --> 00:28:58,690
looked at I was kind of curious they're

00:28:55,519 --> 00:28:58,690
trying to understand a little bit about

00:29:00,610 --> 00:29:07,159
is the what's the quote unquote on the

00:29:04,340 --> 00:29:10,490
wire for what you guys are talking about

00:29:07,159 --> 00:29:14,619
so is the idea here that the RP message

00:29:10,490 --> 00:29:17,090
payload that you would define a a

00:29:14,619 --> 00:29:18,830
structure to an art B message payload

00:29:17,090 --> 00:29:19,940
that then would have sort of the

00:29:18,830 --> 00:29:22,369
information that you would need for

00:29:19,940 --> 00:29:24,529
sharing and so forth is that they kind

00:29:22,369 --> 00:29:26,749
of the thought and then sort of how does

00:29:24,529 --> 00:29:28,279
that compare to what I guess it wasn't

00:29:26,749 --> 00:29:30,889
clear to me what some of these other I

00:29:28,279 --> 00:29:33,379
get the scatter gather one but I don't

00:29:30,889 --> 00:29:35,559
quite understand what the NXP zero

00:29:33,379 --> 00:29:38,779
copies what he was trying to do was it

00:29:35,559 --> 00:29:42,920
this one is different so what they are

00:29:38,779 --> 00:29:46,040
doing it is so today

00:29:42,920 --> 00:29:49,070
to send a message to a to a coprocessor

00:29:46,040 --> 00:29:51,950
you need to copy the message data from

00:29:49,070 --> 00:29:55,330
the application memory into to share

00:29:51,950 --> 00:29:58,340
buffer and so what they are doing it is

00:29:55,330 --> 00:30:01,700
when you try to do that you first will

00:29:58,340 --> 00:30:04,850
want your application you ask for a

00:30:01,700 --> 00:30:07,450
buffer from the ring first and then and

00:30:04,850 --> 00:30:10,550
what's returned from the ring is the

00:30:07,450 --> 00:30:14,360
adjust pointer to the payroll of the IP

00:30:10,550 --> 00:30:19,010
message buffer and then your application

00:30:14,360 --> 00:30:21,890
can directly input message to the

00:30:19,010 --> 00:30:25,160
payload and then it will return the ring

00:30:21,890 --> 00:30:27,620
to the irulu team turn the buffer to the

00:30:25,160 --> 00:30:29,120
rate okay I think I understand is as it

00:30:27,620 --> 00:30:31,970
has there been talk or thought about

00:30:29,120 --> 00:30:35,690
having a different a new V ring

00:30:31,970 --> 00:30:37,100
structure that would about sort of deal

00:30:35,690 --> 00:30:39,170
with some of the limitations that the

00:30:37,100 --> 00:30:41,210
current one has maybe the size fields

00:30:39,170 --> 00:30:42,860
and being able to encode more

00:30:41,210 --> 00:30:45,740
information and there as opposed to

00:30:42,860 --> 00:30:47,420
having to encode keeping the same ring

00:30:45,740 --> 00:30:53,210
structure but then encoding it in the

00:30:47,420 --> 00:30:55,820
payload but maybe it will be good to

00:30:53,210 --> 00:30:58,000
discuss in that's why we didn't hurt

00:30:55,820 --> 00:30:58,000
them

00:31:06,080 --> 00:31:10,650

YouTube URL: https://www.youtube.com/watch?v=RaCaUkKUCSM


