Title: BKK19-308: Low Power AI Edge Hardware
Publication date: 2019-04-11
Playlist: Linaro Connect Bangkok 2019
Description: 
	To Be Provided
Captions: 
	00:00:05,970 --> 00:00:13,809
we're very happy to be here to discuss

00:00:09,820 --> 00:00:17,170
the wonderful world of AI and embedded

00:00:13,809 --> 00:00:24,039
and arm-based low-power low-cost

00:00:17,170 --> 00:00:26,679
solutions with everybody so to start I

00:00:24,039 --> 00:00:30,150
will briefly to introduce our company

00:00:26,679 --> 00:00:38,790
and then I will introduce our solutions

00:00:30,150 --> 00:00:38,790
based on Leonardo and ARM based server

00:00:38,850 --> 00:00:44,010
we started the company about two years

00:00:41,410 --> 00:00:46,810
ago just a little over two years by now

00:00:44,010 --> 00:00:50,920
in two years we taped out four chips

00:00:46,810 --> 00:00:55,840
each chip was designed to target

00:00:50,920 --> 00:01:00,340
different applications or different

00:00:55,840 --> 00:01:04,299
market so our team came from three

00:01:00,340 --> 00:01:08,770
different background of course in

00:01:04,299 --> 00:01:11,799
Silicon Valley we design chips and also

00:01:08,770 --> 00:01:17,740
we believe our vision was the

00:01:11,799 --> 00:01:20,020
next-generation low-power AI power

00:01:17,740 --> 00:01:24,759
consumption is the key that leads to the

00:01:20,020 --> 00:01:29,069
memory problem so we have the top

00:01:24,759 --> 00:01:32,679
scientist from the storage and memory

00:01:29,069 --> 00:01:36,119
industry to also design his chip

00:01:32,679 --> 00:01:42,100
so our first neural network based paper

00:01:36,119 --> 00:01:45,429
was published back in 1988 at the time

00:01:42,100 --> 00:01:51,280
actually when our chief scientist was a

00:01:45,429 --> 00:01:54,999
PhD student at UC Berkeley the title of

00:01:51,280 --> 00:01:57,030
the paper was named cellular neural

00:01:54,999 --> 00:02:00,069
network we call it a convolutional today

00:01:57,030 --> 00:02:05,950
that paper was cited more than 5,000

00:02:00,069 --> 00:02:08,590
times in the last three four years so

00:02:05,950 --> 00:02:11,860
our first silicon is already in mass

00:02:08,590 --> 00:02:16,420
production so you will see the product

00:02:11,860 --> 00:02:18,260
based on that silicon starting from this

00:02:16,420 --> 00:02:22,050
quarter

00:02:18,260 --> 00:02:25,610
so we came from a consumer background we

00:02:22,050 --> 00:02:28,950
wanted to really make AI accessible to

00:02:25,610 --> 00:02:31,410
everybody on the daily day-to-day base

00:02:28,950 --> 00:02:35,370
not just on the cloud so a couple years

00:02:31,410 --> 00:02:38,630
ago and people talked about AI we always

00:02:35,370 --> 00:02:43,709
linked that to Facebook Amazon Microsoft

00:02:38,630 --> 00:02:45,239
you know and media people learning but

00:02:43,709 --> 00:02:48,260
we wanted to make something really

00:02:45,239 --> 00:02:51,660
low-power low-cost that can be used

00:02:48,260 --> 00:02:57,450
online or offline that was our mission

00:02:51,660 --> 00:02:59,930
that's how we were what drives us okay

00:02:57,450 --> 00:03:07,319
let's take a look of the technology so

00:02:59,930 --> 00:03:11,280
we make small chips very very small the

00:03:07,319 --> 00:03:16,560
first chip was 7 by 7 the most current

00:03:11,280 --> 00:03:19,290
chip is actually 6 by 6 so that enables

00:03:16,560 --> 00:03:24,150
super low low power consumption but it

00:03:19,290 --> 00:03:27,709
does produce very good performance in

00:03:24,150 --> 00:03:32,400
terms of neural network processing why

00:03:27,709 --> 00:03:37,920
because we believe today general purpose

00:03:32,400 --> 00:03:41,820
CPU definitely is not going to be the

00:03:37,920 --> 00:03:44,340
main platform or architecture for AI so

00:03:41,820 --> 00:03:47,100
we believe what is called the domain

00:03:44,340 --> 00:03:50,670
specific architecture based on that

00:03:47,100 --> 00:03:56,579
concept we designed all of our chips to

00:03:50,670 --> 00:04:04,620
cover the any anywhere from the edge to

00:03:56,579 --> 00:04:08,910
the IOT to the cloud so what is a domain

00:04:04,620 --> 00:04:12,709
specific architecture in this chip we do

00:04:08,910 --> 00:04:17,010
not have we have a very unique data flow

00:04:12,709 --> 00:04:21,440
pattern data flow architecture we do not

00:04:17,010 --> 00:04:23,900
have the instruction set we do not have

00:04:21,440 --> 00:04:26,939
the traditional

00:04:23,900 --> 00:04:29,810
centralized the memory management in

00:04:26,939 --> 00:04:34,939
this trip we have funny more than 28,000

00:04:29,810 --> 00:04:39,389
small memory based course that enables

00:04:34,939 --> 00:04:44,610
high-speed super high-speed neural

00:04:39,389 --> 00:04:50,340
network computation so the difference is

00:04:44,610 --> 00:04:52,710
that the traditional 0 the CPU based so

00:04:50,340 --> 00:04:55,439
we have memory we have central we have

00:04:52,710 --> 00:04:58,529
we have bars we have software to manage

00:04:55,439 --> 00:05:04,319
that of course it's the speed is very

00:04:58,529 --> 00:05:07,199
slow now we jump to 1 T which is you

00:05:04,319 --> 00:05:10,800
know typically like a GPU multi-core

00:05:07,199 --> 00:05:14,509
scenario the power consumption is pretty

00:05:10,800 --> 00:05:18,120
high and the efficiency is not as great

00:05:14,509 --> 00:05:21,930
so that's how we design our chip is a 2d

00:05:18,120 --> 00:05:25,529
matrix we call it NP u matrix processing

00:05:21,930 --> 00:05:28,909
unit so in this little chip the foreign

00:05:25,529 --> 00:05:32,759
consumption you know is only less than

00:05:28,909 --> 00:05:36,509
0.4 watts but we can produce almost 9 T

00:05:32,759 --> 00:05:39,599
ops so that's that that's just a

00:05:36,509 --> 00:05:47,129
snapshot of our technology next I will

00:05:39,599 --> 00:05:50,370
introduce the products ok so we have 4

00:05:47,129 --> 00:05:54,210
chips now 2 chips are in production when

00:05:50,370 --> 00:05:58,580
one chip was a special MRAM based chip

00:05:54,210 --> 00:06:02,669
that we worked with TSMC to co.design

00:05:58,580 --> 00:06:04,680
this chip so this chip is very unique it

00:06:02,669 --> 00:06:08,729
supports multi neural network

00:06:04,680 --> 00:06:12,120
simultaneously for example you can you

00:06:08,729 --> 00:06:14,550
can do your voice authentication /

00:06:12,120 --> 00:06:17,250
recognition together with face

00:06:14,550 --> 00:06:20,599
recognition typically this is very

00:06:17,250 --> 00:06:24,060
difficult to do due to the special

00:06:20,599 --> 00:06:26,279
material and characteristics of the

00:06:24,060 --> 00:06:31,009
Amram we were able to achieve that with

00:06:26,279 --> 00:06:34,560
we showed this this year at CES as well

00:06:31,009 --> 00:06:36,060
so this year we plan to introduce

00:06:34,560 --> 00:06:39,810
another

00:06:36,060 --> 00:06:46,230
two chips one ship would be video-based

00:06:39,810 --> 00:06:49,400
I will introduce that later so we would

00:06:46,230 --> 00:06:54,990
like to cover the entire ecosystem

00:06:49,400 --> 00:07:02,370
because from the power-saving point of

00:06:54,990 --> 00:07:04,830
view for the AIA ot our latest chip is

00:07:02,370 --> 00:07:07,430
very very low power can be battery

00:07:04,830 --> 00:07:11,250
operated that'll solve a lot of problems

00:07:07,430 --> 00:07:16,010
first our second offline processing

00:07:11,250 --> 00:07:21,150
imagine your your google speaker or your

00:07:16,010 --> 00:07:23,790
echo that we cut the internet off it

00:07:21,150 --> 00:07:25,290
doesn't work right but our goal is to

00:07:23,790 --> 00:07:30,000
design something that really works

00:07:25,290 --> 00:07:32,580
offline as well we also work with social

00:07:30,000 --> 00:07:42,150
necks to build the enterprise level of

00:07:32,580 --> 00:07:47,640
the server based on our chip these are a

00:07:42,150 --> 00:07:53,160
snapshot of what our customer have been

00:07:47,640 --> 00:07:59,220
building their applications based on our

00:07:53,160 --> 00:08:02,520
devices on the enterprise level we have

00:07:59,220 --> 00:08:06,990
you know the big surveillance data

00:08:02,520 --> 00:08:12,650
center typically an access entry type of

00:08:06,990 --> 00:08:12,650
scenario for the industrial we work with

00:08:13,520 --> 00:08:24,180
cop manufacturers to do the factory

00:08:21,510 --> 00:08:27,510
automation and inspection based on our

00:08:24,180 --> 00:08:31,139
technology of course consumer smart home

00:08:27,510 --> 00:08:34,200
you know we actually introduced quite a

00:08:31,139 --> 00:08:40,620
few smart home products with our

00:08:34,200 --> 00:08:44,099
customers this year SES government we

00:08:40,620 --> 00:08:47,130
were selected by the kyoto government to

00:08:44,099 --> 00:08:48,520
participate they're smart city projects

00:08:47,130 --> 00:08:56,280
we were selected as

00:08:48,520 --> 00:09:07,990
only one AI computation power provider

00:08:56,280 --> 00:09:14,800
so this is a snapshot compares that with

00:09:07,990 --> 00:09:19,930
the industry-leading solutions or the

00:09:14,800 --> 00:09:24,250
popular solutions first of all as PR

00:09:19,930 --> 00:09:29,980
tornado 1s is our chip so we run at 50

00:09:24,250 --> 00:09:34,660
megahertz produced about 2.8 T ops power

00:09:29,980 --> 00:09:36,760
is under 0.3 so based on that our top

00:09:34,660 --> 00:09:39,100
four watt power efficiency is around

00:09:36,760 --> 00:09:44,610
nine point three were psa's other

00:09:39,100 --> 00:09:44,610
solutions our number is much better

00:09:45,300 --> 00:09:52,330
tornado 3s is the latest chip we

00:09:49,480 --> 00:09:55,420
introduced idea quarter for last year

00:09:52,330 --> 00:09:58,120
and this chip produce about sixteen

00:09:55,420 --> 00:10:02,770
point eight T ops at three hundred

00:09:58,120 --> 00:10:04,690
megahertz peak performance the highest

00:10:02,770 --> 00:10:11,020
performance we have is around twenty

00:10:04,690 --> 00:10:15,100
four T ops per watt so we believe this

00:10:11,020 --> 00:10:17,530
chips very small - so it's around under

00:10:15,100 --> 00:10:20,710
ten so it's around nine by nine we

00:10:17,530 --> 00:10:24,580
believe this chip so far is the best

00:10:20,710 --> 00:10:35,130
power consumption best performance edge

00:10:24,580 --> 00:10:38,070
based AI chip today so we provide our

00:10:35,130 --> 00:10:42,030
vision solutions you know anyway

00:10:38,070 --> 00:10:44,830
anywhere from small image classification

00:10:42,030 --> 00:10:48,280
simple tasks - all the way to the

00:10:44,830 --> 00:10:52,300
hardest you know semantic segmentation

00:10:48,280 --> 00:10:58,780
or user-defined detection video

00:10:52,300 --> 00:11:03,690
segmentation and also we have some

00:10:58,780 --> 00:11:03,690
special algorithm that allows you to

00:11:04,040 --> 00:11:10,540
performed a super-resolution tasks and

00:11:06,830 --> 00:11:14,900
also low-light HDR style transfer

00:11:10,540 --> 00:11:17,170
pixel-based a pixel level based neural

00:11:14,900 --> 00:11:21,830
network based on computer vision based

00:11:17,170 --> 00:11:27,260
real-time you probably used some online

00:11:21,830 --> 00:11:30,980
based style transfer software before

00:11:27,260 --> 00:11:33,770
maybe it takes about 2 3 4 seconds

00:11:30,980 --> 00:11:39,920
depending on how big your image is we

00:11:33,770 --> 00:11:44,210
can do around 10 frames per second this

00:11:39,920 --> 00:11:47,600
is an example that we took for the

00:11:44,210 --> 00:11:54,890
low-light enhancement so before and

00:11:47,600 --> 00:11:57,500
after a real-time - as I mentioned

00:11:54,890 --> 00:12:03,170
earlier this chip also does the latest

00:11:57,500 --> 00:12:06,680
CNN based NLP natural language

00:12:03,170 --> 00:12:10,520
processing which is more efficient than

00:12:06,680 --> 00:12:14,630
the traditional way of using RNN for

00:12:10,520 --> 00:12:17,180
arised here so that's why we can do

00:12:14,630 --> 00:12:28,760
real-time voice authentication now

00:12:17,180 --> 00:12:33,680
record recognition applications we work

00:12:28,760 --> 00:12:38,090
with social next sequence or hardware

00:12:33,680 --> 00:12:42,500
platform and of course running lean lean

00:12:38,090 --> 00:12:47,300
arrow software so this is our first

00:12:42,500 --> 00:12:50,080
generation based on our first chip this

00:12:47,300 --> 00:12:59,120
example shows you a fully loaded

00:12:50,080 --> 00:13:00,170
sequencer server with a total of 16

00:12:59,120 --> 00:13:05,240
blades

00:13:00,170 --> 00:13:12,050
built in so that gives you about 352 T

00:13:05,240 --> 00:13:14,490
ops so here I about the example one of

00:13:12,050 --> 00:13:18,870
one of the cards so

00:13:14,490 --> 00:13:23,930
this site is the social next day eleven

00:13:18,870 --> 00:13:29,370
armed 24 multi-sport chip with zero amps

00:13:23,930 --> 00:13:34,500
on both side in the back it has a slot

00:13:29,370 --> 00:13:45,329
and that tube a slot with our four of

00:13:34,500 --> 00:13:49,320
our chip built-in so this is the

00:13:45,329 --> 00:13:56,610
configuration so on each side you can

00:13:49,320 --> 00:13:58,649
put in 16 of those cards and also you

00:13:56,610 --> 00:14:00,540
can select you know how many cards you

00:13:58,649 --> 00:14:08,730
wanted to put put in it's configurable

00:14:00,540 --> 00:14:12,420
and upgradeable this is the second

00:14:08,730 --> 00:14:18,329
generation so the second generation is

00:14:12,420 --> 00:14:25,520
based on our latest 2803 chip

00:14:18,329 --> 00:14:30,720
so it's pcie based interface so that in

00:14:25,520 --> 00:14:36,450
a fully loaded configuration that gives

00:14:30,720 --> 00:14:42,990
you around 4000 4500 T ops and we

00:14:36,450 --> 00:14:45,630
believe this solution is the lowest

00:14:42,990 --> 00:14:50,610
power consumption highest performance to

00:14:45,630 --> 00:14:54,500
you based AI inferencing server today in

00:14:50,610 --> 00:14:57,709
comparison of course in comparison to

00:14:54,500 --> 00:14:57,709
GPU based

00:15:03,610 --> 00:15:12,110
lastly I wanted to introduce some most

00:15:07,490 --> 00:15:13,640
updated application scenarios for for

00:15:12,110 --> 00:15:17,450
this particular server that were

00:15:13,640 --> 00:15:21,830
building last week actually the unpaid

00:15:17,450 --> 00:15:23,570
committee just approved the latest next

00:15:21,830 --> 00:15:28,790
video encoding standard which is

00:15:23,570 --> 00:15:32,060
unpacked seven so in this unpacked seven

00:15:28,790 --> 00:15:36,530
there are separate parts there are three

00:15:32,060 --> 00:15:39,470
parts that are related to the neural

00:15:36,530 --> 00:15:42,680
network so that the approved neural

00:15:39,470 --> 00:15:46,430
network compression is based on etg

00:15:42,680 --> 00:15:51,380
sixteen so part thirteen is called the C

00:15:46,430 --> 00:15:56,930
DVS compact distributors of video search

00:15:51,380 --> 00:15:59,110
and 15 is video analysis and 17 is

00:15:56,930 --> 00:16:03,460
neural network representative

00:15:59,110 --> 00:16:07,210
representer and we were selected

00:16:03,460 --> 00:16:10,940
fortunately enough luckily we were

00:16:07,210 --> 00:16:11,390
participating the standard since last

00:16:10,940 --> 00:16:17,200
year

00:16:11,390 --> 00:16:20,950
and we are now the committee of this

00:16:17,200 --> 00:16:24,320
unpacked new standard that our chip is

00:16:20,950 --> 00:16:26,690
the first chip in the world that

00:16:24,320 --> 00:16:29,420
supports this new standard so basically

00:16:26,690 --> 00:16:32,150
it'll give you the capabilities of doing

00:16:29,420 --> 00:16:36,590
all the parts three part thirteen part

00:16:32,150 --> 00:16:41,840
15 and part 17 here is a example of how

00:16:36,590 --> 00:16:45,140
the visual search is done we all search

00:16:41,840 --> 00:16:47,420
video before right so you sit there you

00:16:45,140 --> 00:16:50,510
just screw everything oh you passed over

00:16:47,420 --> 00:16:54,500
you sometimes fast-forward for some time

00:16:50,510 --> 00:16:56,330
you back forward right backward in this

00:16:54,500 --> 00:17:02,120
case you can just you know take a

00:16:56,330 --> 00:17:04,940
snapshot or input a frame or a picture

00:17:02,120 --> 00:17:08,510
of the object either you you wanted to

00:17:04,940 --> 00:17:10,209
search then you will see the the result

00:17:08,510 --> 00:17:13,760
so

00:17:10,209 --> 00:17:18,140
this search result on the screen is a

00:17:13,760 --> 00:17:24,140
isn't an actual search we've done using

00:17:18,140 --> 00:17:28,490
our chip from a video so we try to have

00:17:24,140 --> 00:17:32,030
visual input of object like seedy bars

00:17:28,490 --> 00:17:35,590
traffic signals and then we found you

00:17:32,030 --> 00:17:43,550
know identical object from the video

00:17:35,590 --> 00:17:50,480
based on our server which is the the

00:17:43,550 --> 00:17:53,150
2801 based our first generation this is

00:17:50,480 --> 00:17:55,520
the street image search so you can

00:17:53,150 --> 00:17:59,570
search people statues object like

00:17:55,520 --> 00:18:02,330
umbrella so though though the frames on

00:17:59,570 --> 00:18:06,110
the right side are the actual return

00:18:02,330 --> 00:18:10,190
image search results this is the the

00:18:06,110 --> 00:18:13,810
video actually we used I'm gonna skip

00:18:10,190 --> 00:18:20,000
the video it's it's about 20 seconds

00:18:13,810 --> 00:18:25,940
lastly our collaboration with Leonora in

00:18:20,000 --> 00:18:30,310
arrow in the next six months we will

00:18:25,940 --> 00:18:34,490
work with Lin arrow to have the

00:18:30,310 --> 00:18:38,510
integration work in arm and and also we

00:18:34,490 --> 00:18:43,300
will be building as decays together and

00:18:38,510 --> 00:18:47,570
they make that publicly available

00:18:43,300 --> 00:18:50,240
together with our hard work and also we

00:18:47,570 --> 00:18:53,810
will optimize the neural clear neural

00:18:50,240 --> 00:19:00,080
network supported by gennaro to run

00:18:53,810 --> 00:19:05,140
faster better our chip on our sdk and we

00:19:00,080 --> 00:19:09,460
will define the middleware and sdk and

00:19:05,140 --> 00:19:13,370
on both sides we will be supporting the

00:19:09,460 --> 00:19:16,910
look we will have the low level support

00:19:13,370 --> 00:19:22,360
in terms of hardware on the driver level

00:19:16,910 --> 00:19:22,360
and of course together with social next

00:19:23,520 --> 00:19:26,670
thank you

00:19:26,680 --> 00:19:31,619

YouTube URL: https://www.youtube.com/watch?v=4v61gMx7hl4


