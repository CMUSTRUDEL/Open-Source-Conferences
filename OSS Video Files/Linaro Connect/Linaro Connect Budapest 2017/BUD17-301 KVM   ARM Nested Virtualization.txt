Title: BUD17-301 KVM   ARM Nested Virtualization
Publication date: 2017-03-11
Playlist: Linaro Connect Budapest 2017
Description: 
	"Session ID: BUD17-301
Session Name: KVM/ARM Nested Virtualization - BUD17-301
Speaker: Christoffer Dall
Track: Virtualization


★ Session Summary ★
Nested virtualization, the ability to run a virtual machine inside another virtual machine, is increasingly important because of the need to deploy virtual machines running software stacks on top of virtualized cloud infrastructure, as well as for prototyping and testing. As ARM servers make inroads in various deployment scenarios, being able to support nested virtualization on ARM is a key requirement, which has been met recently with the introduction of nested virtualization support in the latest ARMv8.3 revision of the architecture. I will present the initial effort to introduce ARM nested virtualization support to KVM/ARM, which involves adding significant logic to core KVM/ARM code, MMU support, timers, and the GIC emulation. I will also briefly discuss a paravirtualization approach we have used to prototype and evaluate the implementation on current ARMv8 hardware without hardware support for nested virtualization.
---------------------------------------------------
★ Resources ★
Event Page: http://connect.linaro.org/resource/bud17/bud17-301/
Presentation: https://www.slideshare.net/linaroorg/bud17301-zenos-paradox-optimizing-kvmarm
Video: https://youtu.be/Mqh9J83xFxo
 ---------------------------------------------------

★ Event Details ★
Linaro Connect Budapest 2017 (BUD17)
6-10 March 2017
Corinthia Hotel, Budapest,
Erzsébet krt. 43-49,
1073 Hungary

---------------------------------------------------
Keyword: virtualization, KVM, ARM
http://www.linaro.org
http://connect.linaro.org
---------------------------------------------------
Follow us on Social Media
https://www.facebook.com/LinaroOrg
https://twitter.com/linaroorg
https://www.youtube.com/user/linaroorg?sub_confirmation=1
https://www.linkedin.com/company/1026961"
Captions: 
	00:00:00,130 --> 00:00:07,509
[Music]

00:00:10,120 --> 00:00:14,240
so for those of you don't know me I'm

00:00:12,080 --> 00:00:16,580
Christopher doll I'm the tech lead for

00:00:14,240 --> 00:00:18,710
virtualization of the narrow today I'm

00:00:16,580 --> 00:00:20,449
going to talk about nested

00:00:18,710 --> 00:00:22,609
virtualization so I'll cover a little

00:00:20,449 --> 00:00:26,210
bit of theory about nessa virtualization

00:00:22,609 --> 00:00:28,490
but mostly I'll assume some existing OS

00:00:26,210 --> 00:00:29,810
and virtualization knowledge we have a

00:00:28,490 --> 00:00:31,820
lot of stuff to go through and it's a

00:00:29,810 --> 00:00:34,070
complicated topic but feel free to stop

00:00:31,820 --> 00:00:38,060
me if something is completely unclear at

00:00:34,070 --> 00:00:40,850
some time and so NASA virtualization

00:00:38,060 --> 00:00:42,320
sort of intuitively the discipline of

00:00:40,850 --> 00:00:43,640
running multiple levels of

00:00:42,320 --> 00:00:46,520
virtualization on a single hardware

00:00:43,640 --> 00:00:51,620
platform and it looks something like

00:00:46,520 --> 00:00:53,180
that so when you run a hypervisor you

00:00:51,620 --> 00:00:56,810
run it directly on the hardware and that

00:00:53,180 --> 00:00:59,240
runs vm right with nested virtualization

00:00:56,810 --> 00:01:03,800
you nest so you run another layer VMs

00:00:59,240 --> 00:01:06,290
inside your vm we do that by running a

00:01:03,800 --> 00:01:08,869
another layer of hypervisors in between

00:01:06,290 --> 00:01:10,820
the virtual hardware abstraction created

00:01:08,869 --> 00:01:11,990
by the first level hypervisor and the

00:01:10,820 --> 00:01:14,540
Colonel's running inside your nest

00:01:11,990 --> 00:01:16,280
advanced so already at this point it

00:01:14,540 --> 00:01:17,780
gets confusing to talk about which bm's

00:01:16,280 --> 00:01:19,820
we're talking about which hypervisors

00:01:17,780 --> 00:01:21,290
and so on so that's a good time to start

00:01:19,820 --> 00:01:22,580
talking about terminology which is kind

00:01:21,290 --> 00:01:25,000
of important when discussing nesting

00:01:22,580 --> 00:01:27,350
because otherwise people just lose track

00:01:25,000 --> 00:01:29,120
so what we do is we call the first level

00:01:27,350 --> 00:01:31,159
hypervisor that we usually talk about

00:01:29,120 --> 00:01:34,010
when we run VMS for the host hypervisor

00:01:31,159 --> 00:01:35,810
and the vm that run on top of the whole

00:01:34,010 --> 00:01:37,400
type of Iser we call those simply VMs

00:01:35,810 --> 00:01:40,640
right regardless of whether they run

00:01:37,400 --> 00:01:42,500
just normal vm code or if they also run

00:01:40,640 --> 00:01:45,890
an additional level of hypervisors and

00:01:42,500 --> 00:01:48,890
and the end and the vm inside vs we call

00:01:45,890 --> 00:01:51,049
those netted beams some people also like

00:01:48,890 --> 00:01:54,049
to call these things for the l0

00:01:51,049 --> 00:01:56,119
hypervisor and then the l1 vm or l-1

00:01:54,049 --> 00:01:57,470
hypervisor and then l to vm and so on

00:01:56,119 --> 00:02:00,979
let's get handy when you start running

00:01:57,470 --> 00:02:02,390
even more levels of virtualization it's

00:02:00,979 --> 00:02:04,700
confusing an arm though because we have

00:02:02,390 --> 00:02:06,530
l0 and l1 and l2 and so on right and

00:02:04,700 --> 00:02:07,909
these things are loosely related they're

00:02:06,530 --> 00:02:11,720
not completely separate but they are

00:02:07,909 --> 00:02:14,810
very loosely related so it's confusing

00:02:11,720 --> 00:02:16,670
and you have to live with it so why do

00:02:14,810 --> 00:02:18,140
you want to run use mentioned

00:02:16,670 --> 00:02:20,590
virtualization there's a couple of sort

00:02:18,140 --> 00:02:22,700
of regular use case

00:02:20,590 --> 00:02:24,440
the first one is if you have if you're

00:02:22,700 --> 00:02:26,540
an infrastructure as a service provider

00:02:24,440 --> 00:02:28,460
and you say we want to provide

00:02:26,540 --> 00:02:29,570
infrastructure for your existing IT

00:02:28,460 --> 00:02:31,310
infrastructure and a company that

00:02:29,570 --> 00:02:32,690
already uses virtualization well then

00:02:31,310 --> 00:02:34,010
that's a virtualization let you do that

00:02:32,690 --> 00:02:36,020
director lets you take a private cloud

00:02:34,010 --> 00:02:39,340
move it on to a public cloud and run

00:02:36,020 --> 00:02:42,020
multiple levels people actually do that

00:02:39,340 --> 00:02:43,310
testing and debugging is a it's an

00:02:42,020 --> 00:02:44,690
important case now you want to test the

00:02:43,310 --> 00:02:47,090
full software stack in a vm that

00:02:44,690 --> 00:02:49,100
includes a vm and i think the last one

00:02:47,090 --> 00:02:50,600
is probably my favorite it gets it lets

00:02:49,100 --> 00:02:54,260
people who want to play with hypervisor

00:02:50,600 --> 00:02:56,150
development using GV psss right so if

00:02:54,260 --> 00:02:57,770
you if you have a three dollar month VPN

00:02:56,150 --> 00:03:02,180
systems and you want to write a

00:02:57,770 --> 00:03:04,340
hypervisor you can actually do that so

00:03:02,180 --> 00:03:06,200
if we go back to nineteen seventy-four

00:03:04,340 --> 00:03:07,610
that's the time when people started

00:03:06,200 --> 00:03:08,989
talking about nested virtualization the

00:03:07,610 --> 00:03:10,340
first time when virtualization as a

00:03:08,989 --> 00:03:12,860
theory was sort of established in the

00:03:10,340 --> 00:03:15,860
academic community right so public and

00:03:12,860 --> 00:03:18,470
Goldberg they set in their famous paper

00:03:15,860 --> 00:03:21,940
with their second theorem that if you

00:03:18,470 --> 00:03:24,230
can construct a a hypervisor of emm

00:03:21,940 --> 00:03:26,299
without any strange timing dependencies

00:03:24,230 --> 00:03:28,670
on a virtual virtual I zabal machine

00:03:26,299 --> 00:03:30,680
then you can also create additional

00:03:28,670 --> 00:03:32,600
levels of hypervisors than the machine

00:03:30,680 --> 00:03:36,560
is also recursively virtual I suppose

00:03:32,600 --> 00:03:39,049
it's a somewhat reveal proof so this

00:03:36,560 --> 00:03:41,720
concept of recursively virtualize double

00:03:39,049 --> 00:03:43,340
in the theory that only really applies

00:03:41,720 --> 00:03:44,420
to sort of classically virtualized able

00:03:43,340 --> 00:03:46,850
architectures where you can be

00:03:44,420 --> 00:03:49,360
privileged your entire vm and use trap

00:03:46,850 --> 00:03:52,610
and emulate that's not the case on

00:03:49,360 --> 00:03:54,260
neither arms nor ignored kt6 right here

00:03:52,610 --> 00:03:55,700
we have that these architectures are not

00:03:54,260 --> 00:03:58,209
virtualized one we have to rely on

00:03:55,700 --> 00:04:01,370
hardware support for virtualization and

00:03:58,209 --> 00:04:03,049
so as it turns out when you do nested

00:04:01,370 --> 00:04:04,760
virtualization on non-virtual I zabal

00:04:03,049 --> 00:04:06,980
architectures it becomes a discipline of

00:04:04,760 --> 00:04:08,239
figuring out how to do that using the

00:04:06,980 --> 00:04:11,660
underlying hardware support for

00:04:08,239 --> 00:04:15,320
virtualization so let's look at the arm

00:04:11,660 --> 00:04:16,790
V for a minute that works by expanding

00:04:15,320 --> 00:04:18,500
the existing projection system where you

00:04:16,790 --> 00:04:22,669
have yelled 0 and y 0 1 for user in

00:04:18,500 --> 00:04:25,640
kernel mode whoops with a new mode yield

00:04:22,669 --> 00:04:27,740
to on hype mode and the idea that you

00:04:25,640 --> 00:04:31,360
run the hypervisor in yield to and you

00:04:27,740 --> 00:04:33,380
run VMs on top and then you run your

00:04:31,360 --> 00:04:35,030
existing user space

00:04:33,380 --> 00:04:37,430
and Colonels in the most they were

00:04:35,030 --> 00:04:40,190
designed to do and you use co2 to

00:04:37,430 --> 00:04:45,740
control what these software components

00:04:40,190 --> 00:04:48,830
can and cannot do so the central part of

00:04:45,740 --> 00:04:51,350
doing nested virtualization on arm is to

00:04:48,830 --> 00:04:55,370
provide a virtual yield to instance to

00:04:51,350 --> 00:04:58,220
run your guest hypervisor so we're

00:04:55,370 --> 00:05:00,680
before we would emulate a vm that had l0

00:04:58,220 --> 00:05:01,970
l1 we're not moving to a world where we

00:05:00,680 --> 00:05:05,870
have to angle eight a vm that has

00:05:01,970 --> 00:05:08,600
virtual l2 in addition to l0 l1 and this

00:05:05,870 --> 00:05:14,270
is basically what the entire work and

00:05:08,600 --> 00:05:17,090
talk is about the question is which

00:05:14,270 --> 00:05:22,690
physical cpu mode do you run that in all

00:05:17,090 --> 00:05:25,130
right well there's a couple of options

00:05:22,690 --> 00:05:26,420
you cannot run it in yell too because

00:05:25,130 --> 00:05:28,220
that's where your host hypervisor runs

00:05:26,420 --> 00:05:29,960
so if you run Neil to the whole vm

00:05:28,220 --> 00:05:31,310
becomes s privilege that you're for a

00:05:29,960 --> 00:05:33,950
hypervisor and the whole point of

00:05:31,310 --> 00:05:37,880
virtualization is long so it's l0 or

00:05:33,950 --> 00:05:40,160
you'll one with l0 that's actually

00:05:37,880 --> 00:05:41,720
possible on today's hardware but it's

00:05:40,160 --> 00:05:44,600
really slow and it's really hard to

00:05:41,720 --> 00:05:45,980
write a hypervisor that does that but

00:05:44,600 --> 00:05:49,300
you can do it and you can trap and

00:05:45,980 --> 00:05:52,030
emulate like back in the good ol days

00:05:49,300 --> 00:05:54,440
eal one is a much better alternative

00:05:52,030 --> 00:05:57,740
it's a much faster way of doing it and

00:05:54,440 --> 00:06:01,340
it's much easier in terms of writing the

00:05:57,740 --> 00:06:03,770
hypervisor it doesn't work unfortunately

00:06:01,340 --> 00:06:07,250
because you can't trap a lot of yield to

00:06:03,770 --> 00:06:08,780
operations from l1 into Yale too so if

00:06:07,250 --> 00:06:11,060
you for example want to read it any all

00:06:08,780 --> 00:06:13,160
to and register in dl 1 instead of

00:06:11,060 --> 00:06:16,460
trapping too real too it'll undef at

00:06:13,160 --> 00:06:20,170
Yale one right so instead of traffic and

00:06:16,460 --> 00:06:25,460
emulating you getting at and emulate so

00:06:20,170 --> 00:06:27,320
luckily arm fix this in RB 8.3 what they

00:06:25,460 --> 00:06:29,270
do is they introduce a new bit in the

00:06:27,320 --> 00:06:31,700
hypervisor configuration register the

00:06:29,270 --> 00:06:33,260
env bit and when you set that all those

00:06:31,700 --> 00:06:38,240
two operations that didn't track before

00:06:33,260 --> 00:06:42,830
they begin to trap you also track the

00:06:38,240 --> 00:06:43,850
rep from when you execute yell one so

00:06:42,830 --> 00:06:45,919
you can emulate it in your host

00:06:43,850 --> 00:06:46,940
hypervisor and if you try to read your

00:06:45,919 --> 00:06:48,140
current exception level

00:06:46,940 --> 00:06:49,580
when you're Neil one and this bit is set

00:06:48,140 --> 00:06:55,450
it'll likely you and tell you that

00:06:49,580 --> 00:07:00,170
you're actually in the l2 so using the

00:06:55,450 --> 00:07:02,750
the rmv 8.3 support we have a pad set

00:07:00,170 --> 00:07:06,080
out to support next virtualization on

00:07:02,750 --> 00:07:08,240
kvm arm using that as usual i'll go

00:07:06,080 --> 00:07:10,520
through sort of the four steps of Korra

00:07:08,240 --> 00:07:12,680
virtualization CPU memory timer and

00:07:10,520 --> 00:07:16,760
interrupts and see how we how we use the

00:07:12,680 --> 00:07:18,560
new hardware features so the first step

00:07:16,760 --> 00:07:20,620
in providing necesita virtualization is

00:07:18,560 --> 00:07:23,360
to add the state into memory to

00:07:20,620 --> 00:07:25,040
represent a virtual CPU that now has

00:07:23,360 --> 00:07:27,620
yield to annotations real zero near one

00:07:25,040 --> 00:07:29,000
right and so that's great it's pretty

00:07:27,620 --> 00:07:31,100
much a set of system registers it's an

00:07:29,000 --> 00:07:34,310
array that you add into the contact in

00:07:31,100 --> 00:07:37,250
your memory so fantastic you can then

00:07:34,310 --> 00:07:40,130
describe a virtual CPU that has virtual

00:07:37,250 --> 00:07:45,010
real too but if you can't really run it

00:07:40,130 --> 00:07:48,680
it's not as much help so small step back

00:07:45,010 --> 00:07:51,680
we consider how kvm works using vhe as

00:07:48,680 --> 00:07:53,690
an example what we do is we switch back

00:07:51,680 --> 00:07:55,970
and forth between your hypervisor and

00:07:53,690 --> 00:08:00,250
host system to your vm and when we do

00:07:55,970 --> 00:08:02,660
that we assuming you enter the yield one

00:08:00,250 --> 00:08:06,530
kernel the vm what you do is when you

00:08:02,660 --> 00:08:08,300
enter the the vm here you restore all of

00:08:06,530 --> 00:08:10,190
the yield one system registers on that

00:08:08,300 --> 00:08:13,280
virtual CPU array in memory on to the

00:08:10,190 --> 00:08:15,620
physical you one registers on cpu we go

00:08:13,280 --> 00:08:17,390
the other way we save the status of the

00:08:15,620 --> 00:08:23,540
cpu and put that into the array in

00:08:17,390 --> 00:08:25,550
memory for example when we do this with

00:08:23,540 --> 00:08:26,960
nessa virtualization you can enter the

00:08:25,550 --> 00:08:29,120
physical yield one mode but you can

00:08:26,960 --> 00:08:31,520
enter either as the guest hypervisor or

00:08:29,120 --> 00:08:35,690
ask the beat as the colonel inside the

00:08:31,520 --> 00:08:38,270
vm all right and it's basically the same

00:08:35,690 --> 00:08:39,830
idea but the problem is if you enter the

00:08:38,270 --> 00:08:45,860
guest hypervisor you want to somehow

00:08:39,830 --> 00:08:47,120
shave into the store the these yield to

00:08:45,860 --> 00:08:52,120
registration steps but you're still

00:08:47,120 --> 00:08:54,170
running in yellow one so a lot of the

00:08:52,120 --> 00:08:57,500
challenge in supporting CPU

00:08:54,170 --> 00:08:59,240
virtualization CPU nessa virtualization

00:08:57,500 --> 00:09:00,110
on arm is to figure out a mappings

00:08:59,240 --> 00:09:02,029
between

00:09:00,110 --> 00:09:04,279
the virtual yield two registers you have

00:09:02,029 --> 00:09:05,480
in memory and deal one of physical

00:09:04,279 --> 00:09:08,870
registers that you're going to actually

00:09:05,480 --> 00:09:10,490
use on the CPU when you run your virtual

00:09:08,870 --> 00:09:14,360
you'll two and your guests hypervisor in

00:09:10,490 --> 00:09:15,620
l1 so this mapping is it depends a

00:09:14,360 --> 00:09:17,420
little bit of the registers how you do

00:09:15,620 --> 00:09:18,740
that exactly so if you consider

00:09:17,420 --> 00:09:20,779
something like the page table base

00:09:18,740 --> 00:09:22,399
register it's pretty easy they have

00:09:20,779 --> 00:09:24,769
exactly the same semantics so you can

00:09:22,399 --> 00:09:26,480
just take the content of the EO to

00:09:24,769 --> 00:09:27,649
register and put it into the yield one

00:09:26,480 --> 00:09:31,399
register when you run and things will

00:09:27,649 --> 00:09:33,470
just work the SCT lr is a little bit

00:09:31,399 --> 00:09:36,230
different they are similar in what they

00:09:33,470 --> 00:09:37,670
do they have similar semantics but

00:09:36,230 --> 00:09:39,620
they're different in their bit position

00:09:37,670 --> 00:09:42,350
some things that were served in one mode

00:09:39,620 --> 00:09:45,019
and not in another mode so you have to

00:09:42,350 --> 00:09:47,060
actually apply logic to translate the

00:09:45,019 --> 00:09:49,970
meaning of the yield to register into an

00:09:47,060 --> 00:09:51,350
ye'll one register the way we do it

00:09:49,970 --> 00:09:53,269
slightly more mechanically is we come

00:09:51,350 --> 00:09:56,800
with this concept of shadow l1 registers

00:09:53,269 --> 00:09:59,180
so that's an array of l1 registers that

00:09:56,800 --> 00:10:02,380
represent the transform yield two

00:09:59,180 --> 00:10:07,910
registers so that you can emulate your

00:10:02,380 --> 00:10:09,470
virtual l2 and l1 the way we do it in

00:10:07,910 --> 00:10:10,640
practice is we introduce this Hardware

00:10:09,470 --> 00:10:11,720
pointer the reason why we call the

00:10:10,640 --> 00:10:12,860
hardware pointer is that it's the

00:10:11,720 --> 00:10:16,190
pointer to the registers that you're

00:10:12,860 --> 00:10:17,810
going to use in the hardware and then

00:10:16,190 --> 00:10:19,220
when you enter the vm remember that

00:10:17,810 --> 00:10:22,160
diagram before when you were saving and

00:10:19,220 --> 00:10:23,839
restoring state we look at the virtual

00:10:22,160 --> 00:10:27,890
CPU state and we say okay it's that

00:10:23,839 --> 00:10:29,329
virtual CPU state in l0 l1 in which case

00:10:27,890 --> 00:10:32,360
we point the hardware pointer to the

00:10:29,329 --> 00:10:34,820
normal you'll one system registers but

00:10:32,360 --> 00:10:36,410
if you're in your virtual CPU is in your

00:10:34,820 --> 00:10:37,910
virtual you'll to you're going to run

00:10:36,410 --> 00:10:39,470
your guest hypervisor you just pointed

00:10:37,910 --> 00:10:41,540
to the shadow system register array and

00:10:39,470 --> 00:10:43,190
then all the complicated logic of

00:10:41,540 --> 00:10:45,560
actually switching between your vm and

00:10:43,190 --> 00:10:47,149
your hypervisor remains unmodified

00:10:45,560 --> 00:10:49,310
because they just follow that pointer

00:10:47,149 --> 00:10:57,040
and then you end up emulating the right

00:10:49,310 --> 00:11:01,040
mode you also need a mode switch between

00:10:57,040 --> 00:11:02,449
yo one in the BM and virtual l2 both

00:11:01,040 --> 00:11:08,209
running in the same physical to view

00:11:02,449 --> 00:11:11,959
mode so trapping from virtual ill once

00:11:08,209 --> 00:11:13,430
or il-12 virtual you'll to it's done by

00:11:11,959 --> 00:11:16,760
sort of forwarding

00:11:13,430 --> 00:11:19,550
exceptions so I can describe this to an

00:11:16,760 --> 00:11:23,180
example right so consider Wi-Fi holding

00:11:19,550 --> 00:11:24,529
the processor you can trap that to yell

00:11:23,180 --> 00:11:26,390
too and we want to maintain those

00:11:24,529 --> 00:11:27,830
semantics when you have a nested vm so

00:11:26,390 --> 00:11:30,050
you want to be able to trap that from

00:11:27,830 --> 00:11:33,140
the deal one kernel into your virtual

00:11:30,050 --> 00:11:35,899
YouTube when we run the vm we always

00:11:33,140 --> 00:11:37,850
trap Wi-Fi into the host hypervisor all

00:11:35,899 --> 00:11:40,100
right so what we do now is that whenever

00:11:37,850 --> 00:11:42,260
you execute Wi-Fi in yellow one in the

00:11:40,100 --> 00:11:43,880
vm that will always trap as per the

00:11:42,260 --> 00:11:45,950
architecture into your ho type of item

00:11:43,880 --> 00:11:47,120
and then we look at things we consider

00:11:45,950 --> 00:11:49,550
what should we do which is we handle it

00:11:47,120 --> 00:11:52,310
directly or forward it to the vm that

00:11:49,550 --> 00:11:54,470
depends on how your guest hypervisor has

00:11:52,310 --> 00:11:55,910
configured it is virtual hardware so

00:11:54,470 --> 00:11:57,560
what you do is you look at the virtual

00:11:55,910 --> 00:12:00,830
hypervisor configuration register if

00:11:57,560 --> 00:12:04,730
your guest hypervisor has set it up to

00:12:00,830 --> 00:12:06,740
virtually trap w 5 then you forward the

00:12:04,730 --> 00:12:09,200
exception and you do that by simply

00:12:06,740 --> 00:12:11,480
manipulating the virtual CPU state in

00:12:09,200 --> 00:12:13,790
memory and then you run your normal

00:12:11,480 --> 00:12:15,890
switch code which will now see oh I've

00:12:13,790 --> 00:12:17,690
entered virtual l2 because you

00:12:15,890 --> 00:12:20,150
manipulated your virtual piece days

00:12:17,690 --> 00:12:21,920
switch the hardware point around run the

00:12:20,150 --> 00:12:23,270
normal switching code and you'll enter

00:12:21,920 --> 00:12:28,400
your exception vector in virtually all

00:12:23,270 --> 00:12:32,300
true the other way around going from

00:12:28,400 --> 00:12:35,089
virtual yield to bacterial one depends

00:12:32,300 --> 00:12:36,800
on traffic on the US right so what you

00:12:35,089 --> 00:12:38,150
generally do what you want to change to

00:12:36,800 --> 00:12:40,400
a less privileged mode from Yale to as

00:12:38,150 --> 00:12:43,160
you execute the e-rate instruction with

00:12:40,400 --> 00:12:45,880
rmv 8.3 this will trap when executing

00:12:43,160 --> 00:12:49,610
the l1 and the env bit is set and the

00:12:45,880 --> 00:12:50,959
whole hypervisor again just emulate that

00:12:49,610 --> 00:12:57,050
exception return on the memory

00:12:50,959 --> 00:13:00,760
structures and returns and it works so

00:12:57,050 --> 00:13:00,760
if we move on to memory virtualization

00:13:01,240 --> 00:13:05,300
normal virtual memory works something

00:13:03,770 --> 00:13:08,089
like this most of you are probably

00:13:05,300 --> 00:13:10,790
familiar with this so you have a set of

00:13:08,089 --> 00:13:12,200
memory translations performed by the MMU

00:13:10,790 --> 00:13:13,730
from virtual addresses to physical

00:13:12,200 --> 00:13:17,420
addresses on arm we call that the stage

00:13:13,730 --> 00:13:19,880
one translations when you introduce the

00:13:17,420 --> 00:13:21,620
concept of a vm you want to be able to

00:13:19,880 --> 00:13:24,829
virtualize your physical memory and

00:13:21,620 --> 00:13:25,840
isolate each VM and we do that with a

00:13:24,829 --> 00:13:27,850
second set of 10

00:13:25,840 --> 00:13:30,010
relations we call stage two translations

00:13:27,850 --> 00:13:32,200
and your first dates become virtual

00:13:30,010 --> 00:13:33,730
addresses to intermediate physical

00:13:32,200 --> 00:13:35,140
addresses and estates to intermediate

00:13:33,730 --> 00:13:37,750
physical address to physical addresses

00:13:35,140 --> 00:13:39,610
and the stage two is managed by the host

00:13:37,750 --> 00:13:43,810
hypervisor that uses a separate set of

00:13:39,610 --> 00:13:45,490
page tables with nested virtualization

00:13:43,810 --> 00:13:47,860
you have the same requirement you want

00:13:45,490 --> 00:13:50,590
to isolate your nested VMs between each

00:13:47,860 --> 00:13:54,040
other and be able to virtualize the vm

00:13:50,590 --> 00:13:56,440
view of physical memory the problem is

00:13:54,040 --> 00:14:00,340
you only have two stages of translation

00:13:56,440 --> 00:14:04,000
in hardware but you now need three to

00:14:00,340 --> 00:14:05,290
support this you're useless so what we

00:14:04,000 --> 00:14:06,700
end up doing is we end up using a

00:14:05,290 --> 00:14:10,540
favorite old technology called shadow

00:14:06,700 --> 00:14:13,120
page tables and the idea is that you

00:14:10,540 --> 00:14:17,770
built these shadows page to page tables

00:14:13,120 --> 00:14:19,120
by so sorry the shatt the shadows page

00:14:17,770 --> 00:14:20,830
to page tables are the ones that you

00:14:19,120 --> 00:14:22,750
actually give to the hardware that's

00:14:20,830 --> 00:14:24,370
used by the MMU and they're building

00:14:22,750 --> 00:14:26,740
constructed by the Hopis provider and

00:14:24,370 --> 00:14:29,620
what they do is they combine those two

00:14:26,740 --> 00:14:33,160
stages of translation here and here into

00:14:29,620 --> 00:14:35,860
one pace table you build them on demand

00:14:33,160 --> 00:14:39,010
so you initially start out empty and

00:14:35,860 --> 00:14:42,700
whenever you hit a fault what you do is

00:14:39,010 --> 00:14:45,490
you walk the guests hypervisors virtual

00:14:42,700 --> 00:14:48,160
space to page tables in software to

00:14:45,490 --> 00:14:50,590
figure out the mappings between the IPA

00:14:48,160 --> 00:14:53,410
and the guest hypervisors view of

00:14:50,590 --> 00:14:55,720
physical memory and the host hypervisor

00:14:53,410 --> 00:14:58,330
already has an idea of how to map the

00:14:55,720 --> 00:15:00,190
first level VMs physical memory to real

00:14:58,330 --> 00:15:01,540
physical memory and it combines those

00:15:00,190 --> 00:15:02,890
two pieces of information into each

00:15:01,540 --> 00:15:04,900
entry that you add in the shadow saves

00:15:02,890 --> 00:15:08,590
to page tables and then you basically

00:15:04,900 --> 00:15:10,840
rely on guest hypervisors having to do

00:15:08,590 --> 00:15:13,690
tlb invalidations which will pass real

00:15:10,840 --> 00:15:16,140
too and then you flush your cash shadows

00:15:13,690 --> 00:15:16,140
a stupid

00:15:17,279 --> 00:15:28,019
you can even described that way yeah yes

00:15:26,370 --> 00:15:31,230
the whole type of Iser walks to the

00:15:28,019 --> 00:15:33,809
guests yeah states to play stable and

00:15:31,230 --> 00:15:35,430
there and neither you don't have a

00:15:33,809 --> 00:15:37,319
concept of normal stage to page tables

00:15:35,430 --> 00:15:40,769
anymore right there sort of become

00:15:37,319 --> 00:15:42,029
transient and the guests states to page

00:15:40,769 --> 00:15:43,800
tables are never used I rectify the

00:15:42,029 --> 00:15:47,910
hardware right only the shadow states to

00:15:43,800 --> 00:15:49,769
paste it was you know you can nest

00:15:47,910 --> 00:15:52,079
multiple times what happens then is that

00:15:49,769 --> 00:15:54,509
the guest hypervisor starts walking your

00:15:52,079 --> 00:15:56,399
l2 hypervisor Shh state to page table it

00:15:54,509 --> 00:15:58,829
creates a shadow stage to page table and

00:15:56,399 --> 00:16:00,600
then your host hypervisor will walk the

00:15:58,829 --> 00:16:01,949
shadow stage to page tables of your

00:16:00,600 --> 00:16:03,689
guests hypervisor and create another

00:16:01,949 --> 00:16:07,740
layer of shadow face-to-face table just

00:16:03,689 --> 00:16:13,559
use by the hardware we've tried four

00:16:07,740 --> 00:16:17,939
levels yes it is don't ask me if they

00:16:13,559 --> 00:16:23,490
were fast though okay so moving on to

00:16:17,939 --> 00:16:26,459
timers so the ARM architecture provides

00:16:23,490 --> 00:16:29,759
two timers for l1 and yell 0 the virtual

00:16:26,459 --> 00:16:31,680
on the physical timer you also get a

00:16:29,759 --> 00:16:33,779
separate timer for yell to that yelled

00:16:31,680 --> 00:16:35,670
to timer of the hype timer you actually

00:16:33,779 --> 00:16:39,540
get to with UT but that's a different

00:16:35,670 --> 00:16:41,459
discussion so again right coming back to

00:16:39,540 --> 00:16:44,009
our first principle with nessa

00:16:41,459 --> 00:16:48,360
virtualization you add the capability to

00:16:44,009 --> 00:16:51,000
emulate virtual l2 in your vm right so

00:16:48,360 --> 00:16:52,980
again here now we have to also provide a

00:16:51,000 --> 00:16:55,139
virtual yield two timer to the vm in

00:16:52,980 --> 00:16:58,259
addition to the normal virtual and

00:16:55,139 --> 00:17:00,629
physical timers and what we do is we

00:16:58,259 --> 00:17:02,360
simply multiplex it on software using

00:17:00,629 --> 00:17:05,520
the timer that's a hypervisor uses so

00:17:02,360 --> 00:17:08,610
you present a virtual timer to the to

00:17:05,520 --> 00:17:10,919
the to the vm the virtual you'll to

00:17:08,610 --> 00:17:12,360
timer which will cost wraps if the DN

00:17:10,919 --> 00:17:14,189
prior to program it or your guest

00:17:12,360 --> 00:17:16,620
hypervisor tries to program it and then

00:17:14,189 --> 00:17:18,419
you simply look at is the shortest

00:17:16,620 --> 00:17:20,520
deadline the my virtual timer

00:17:18,419 --> 00:17:21,839
programming or the timer requirements i

00:17:20,520 --> 00:17:24,089
have on the whole time provider and you

00:17:21,839 --> 00:17:25,559
program your hardware timer for your

00:17:24,089 --> 00:17:27,480
hypervisor for your host hypervisor

00:17:25,559 --> 00:17:29,570
accordingly and then use you multiplex

00:17:27,480 --> 00:17:32,100
and software

00:17:29,570 --> 00:17:33,360
into a virtualization so I make a point

00:17:32,100 --> 00:17:37,040
out of never doing a talk without

00:17:33,360 --> 00:17:37,040
talking about the gig which we all love

00:17:37,100 --> 00:17:42,720
so the gig is the arm generic interrupt

00:17:40,050 --> 00:17:45,060
controller and very very very simplified

00:17:42,720 --> 00:17:47,340
the idea is that you get a bunch of

00:17:45,060 --> 00:17:49,800
devices that have lines into the gig and

00:17:47,340 --> 00:17:52,200
then the gig can signal interrupt to the

00:17:49,800 --> 00:17:55,260
CPU up here on the TV you can then

00:17:52,200 --> 00:17:57,500
acknowledged and eoi interrupts the gig

00:17:55,260 --> 00:18:00,750
has built-in support for virtualization

00:17:57,500 --> 00:18:02,520
we call the be kick and what that

00:18:00,750 --> 00:18:04,470
essentially does again very very

00:18:02,520 --> 00:18:07,080
simplified is that it adds an additional

00:18:04,470 --> 00:18:09,240
line into the CPU to signal virtual

00:18:07,080 --> 00:18:11,040
interrupts right but we're before those

00:18:09,240 --> 00:18:13,170
virtual interrupts sorry work before the

00:18:11,040 --> 00:18:14,520
interrupt came from real devices now

00:18:13,170 --> 00:18:15,690
we're signalling virtual interrupts

00:18:14,520 --> 00:18:18,150
which of course don't comfortable

00:18:15,690 --> 00:18:19,470
devices instead they come from a set of

00:18:18,150 --> 00:18:22,080
special registers called the list

00:18:19,470 --> 00:18:23,910
registers which are programmed by the

00:18:22,080 --> 00:18:25,950
hypervisor and the advantage of these

00:18:23,910 --> 00:18:27,330
features is that you can act and you I

00:18:25,950 --> 00:18:31,770
interrupt without trapping to the

00:18:27,330 --> 00:18:32,880
underlying heart the hypervisor so the

00:18:31,770 --> 00:18:34,350
thing we want to do with method is we

00:18:32,880 --> 00:18:36,420
would like to use those hardware

00:18:34,350 --> 00:18:38,820
features to deliver interrupts to both

00:18:36,420 --> 00:18:44,010
your guest hypervisor if that's your

00:18:38,820 --> 00:18:46,230
first level vm and to your nested vm so

00:18:44,010 --> 00:18:49,260
that both of them can act and you I

00:18:46,230 --> 00:18:51,960
interest without traffic we do that by

00:18:49,260 --> 00:18:54,570
when we run the guest hypervisor the

00:18:51,960 --> 00:18:56,220
first level vm we let the host

00:18:54,570 --> 00:18:58,680
hypervisor program the list registers

00:18:56,220 --> 00:19:00,690
and we signal those intervals when we

00:18:58,680 --> 00:19:02,130
switch into the nested vm we let the

00:19:00,690 --> 00:19:03,800
guests hypervisor program the list

00:19:02,130 --> 00:19:07,170
registers and we signal those directly

00:19:03,800 --> 00:19:11,520
at this point you have a interrupt for

00:19:07,170 --> 00:19:12,810
your guests hypervisor that will go

00:19:11,520 --> 00:19:14,490
through the whole typo visor and it'll

00:19:12,810 --> 00:19:20,490
simply change back to switch between the

00:19:14,490 --> 00:19:22,260
two all the time in practice the you

00:19:20,490 --> 00:19:24,090
don't let the guests hypervisor control

00:19:22,260 --> 00:19:27,330
the alarms directly you again have this

00:19:24,090 --> 00:19:29,280
concept of shadowless registers because

00:19:27,330 --> 00:19:30,420
you want to sanitize it and there are

00:19:29,280 --> 00:19:31,500
some features on the list registers

00:19:30,420 --> 00:19:34,050
where you need some some level

00:19:31,500 --> 00:19:35,940
translation but the same principle

00:19:34,050 --> 00:19:38,010
applies that your shadowless registers

00:19:35,940 --> 00:19:40,470
are sort of on a representation to be

00:19:38,010 --> 00:19:43,310
used by the Hardware off whatever the

00:19:40,470 --> 00:19:43,310
guest hypervisor rope

00:19:44,009 --> 00:19:50,049
in terms of status we have a an RC v 1

00:19:48,039 --> 00:19:52,200
on the kvm armless develop I colleague

00:19:50,049 --> 00:19:56,259
of mine from Columbia called Jim Tech

00:19:52,200 --> 00:19:58,570
and right now it's all based on a config

00:19:56,259 --> 00:20:00,429
option and if you enable at contact

00:19:58,570 --> 00:20:02,799
option you add user space have the

00:20:00,429 --> 00:20:04,989
option to say when I create virtual CPUs

00:20:02,799 --> 00:20:06,669
I want them to support method

00:20:04,989 --> 00:20:10,690
virtualization and emulate a virtual

00:20:06,669 --> 00:20:13,119
real too so there's a lot of interesting

00:20:10,690 --> 00:20:14,409
stuff to do still in network one thing

00:20:13,119 --> 00:20:16,570
that I forgot to mention here is that

00:20:14,409 --> 00:20:19,359
what I already commented on the list is

00:20:16,570 --> 00:20:20,889
that that patch it is like 50 plus

00:20:19,359 --> 00:20:23,950
patches and we need to split them up

00:20:20,889 --> 00:20:27,070
into some smallville series probably a

00:20:23,950 --> 00:20:28,809
split in CPU memory timers interrupts

00:20:27,070 --> 00:20:32,049
like I talked about here would be a good

00:20:28,809 --> 00:20:33,279
a good way to do it there are some

00:20:32,049 --> 00:20:34,899
obvious things will need to be fake like

00:20:33,279 --> 00:20:36,609
hard-coded address and interrupt numbers

00:20:34,899 --> 00:20:39,269
which where we have to define interfaces

00:20:36,609 --> 00:20:41,289
to user space so that it can select them

00:20:39,269 --> 00:20:42,639
we don't have any sort of reverse

00:20:41,289 --> 00:20:44,169
mappings from shadow slaves to pay

00:20:42,639 --> 00:20:46,450
stables so if you want to invalidate

00:20:44,169 --> 00:20:48,070
portions of your shadows page to page

00:20:46,450 --> 00:20:51,149
tables what we do right now is we flush

00:20:48,070 --> 00:20:54,820
everything and if you run multiple

00:20:51,149 --> 00:20:56,590
side-by-side nested vm so sorry if you

00:20:54,820 --> 00:20:59,200
want multiple guests hypervisors on top

00:20:56,590 --> 00:21:00,639
of your first level hypervisor then when

00:20:59,200 --> 00:21:02,739
you switch between them we basically

00:21:00,639 --> 00:21:08,169
flush everything so that's really slow

00:21:02,739 --> 00:21:10,690
so much better I don't like to get rid

00:21:08,169 --> 00:21:12,369
of this contact option so that we at

00:21:10,690 --> 00:21:15,190
least compile all the code every time we

00:21:12,369 --> 00:21:16,210
compile the colonel but there's an

00:21:15,190 --> 00:21:18,009
interesting discussion of whether this

00:21:16,210 --> 00:21:19,359
should just be a feature that announced

00:21:18,009 --> 00:21:21,730
and can be enabled or if it's something

00:21:19,359 --> 00:21:22,989
you specifically have to to enable on

00:21:21,730 --> 00:21:27,179
your command line option so that maybe

00:21:22,989 --> 00:21:27,179
we can remove some of the complicated

00:21:27,539 --> 00:21:31,210
logic in some of the in the critical

00:21:29,739 --> 00:21:33,730
path using static ease that Aquis and

00:21:31,210 --> 00:21:34,720
that kind of thing so there's the space

00:21:33,730 --> 00:21:36,609
of a lot of interesting stuff to look

00:21:34,720 --> 00:21:38,139
into so if anybody's interested in

00:21:36,609 --> 00:21:41,109
participating and has some ideas of

00:21:38,139 --> 00:21:42,549
something that like to do you know feel

00:21:41,109 --> 00:21:43,690
free to reach out to me urgent AG and

00:21:42,549 --> 00:21:45,190
say hey I'd like to work on this part

00:21:43,690 --> 00:21:48,970
and we really well vote on that kind of

00:21:45,190 --> 00:21:50,169
help at this point you know I have four

00:21:48,970 --> 00:21:52,659
minutes left for questions and

00:21:50,169 --> 00:21:54,190
discussions and as usual as well a

00:21:52,659 --> 00:21:54,570
reminder to please go and review the

00:21:54,190 --> 00:21:55,980
patches

00:21:54,570 --> 00:22:04,380
50 some patches and they're a lot of

00:21:55,980 --> 00:22:06,929
work for Marco negative soldier firstly

00:22:04,380 --> 00:22:10,679
up hypervisor in the kvm for the second

00:22:06,929 --> 00:22:12,950
can we mix the egg is n cross K p.m. so

00:22:10,679 --> 00:22:15,659
our goal in developing this has been to

00:22:12,950 --> 00:22:17,490
emulate the architecture correctly so

00:22:15,659 --> 00:22:20,340
that the yield the virtual yields who

00:22:17,490 --> 00:22:24,419
you get is not a thing made for kvm it

00:22:20,340 --> 00:22:25,679
is emulating a virtual yield to rest for

00:22:24,419 --> 00:22:29,429
the architecture she'll see reticle you

00:22:25,679 --> 00:22:30,840
should be able to run any hypervisor the

00:22:29,429 --> 00:22:33,450
way this was developed it was actually

00:22:30,840 --> 00:22:35,100
without a model for 8.3 the initial

00:22:33,450 --> 00:22:36,840
prototype the wait was developed without

00:22:35,100 --> 00:22:40,230
a model using para virtualization on

00:22:36,840 --> 00:22:42,659
current hardware so that would be a lot

00:22:40,230 --> 00:22:44,279
of work for another hypervisor but I

00:22:42,659 --> 00:22:46,830
don't see any immediate problems of

00:22:44,279 --> 00:22:49,620
course we have to test it ok and second

00:22:46,830 --> 00:22:53,940
question is have you concede the pci

00:22:49,620 --> 00:22:56,970
device as our iove you know how it works

00:22:53,940 --> 00:22:58,379
in jackass hypervisor no because of the

00:22:56,970 --> 00:23:01,860
platforms again that we've used for this

00:22:58,379 --> 00:23:04,710
don't have PCI but the prototype that

00:23:01,860 --> 00:23:08,220
use / virtualization use both vertigo

00:23:04,710 --> 00:23:11,100
and use vio pass through but not the PGI

00:23:08,220 --> 00:23:13,409
with platform to the first level vm but

00:23:11,100 --> 00:23:14,820
we don't have a virtual immu so you

00:23:13,409 --> 00:23:17,700
can't do pass through again to the next

00:23:14,820 --> 00:23:21,149
level but we have done both pass through

00:23:17,700 --> 00:23:22,850
and verdi oh but for the first level but

00:23:21,149 --> 00:23:26,279
always bored i 0 for the second level I

00:23:22,850 --> 00:23:31,799
shrink then is very important we need to

00:23:26,279 --> 00:23:36,600
look into and yes or no definitely use

00:23:31,799 --> 00:23:38,429
case I think which hardware would it be

00:23:36,600 --> 00:23:40,980
possible to actually test this on given

00:23:38,429 --> 00:23:44,600
beyond the 803 requirement I think you

00:23:40,980 --> 00:23:44,600
need a nice point remodel at this point

00:23:47,549 --> 00:23:56,019
sorry any 5 6 ep 6 yes like that review

00:23:52,469 --> 00:23:57,519
so the prototype that would actually use

00:23:56,019 --> 00:23:59,830
for academic work and for for

00:23:57,519 --> 00:24:01,509
measurements and stuff used /

00:23:59,830 --> 00:24:03,729
virtualization assume it would actually

00:24:01,509 --> 00:24:05,739
quite a simple I think like five patches

00:24:03,729 --> 00:24:08,289
on the host and since five for linux and

00:24:05,739 --> 00:24:09,700
what they do is they say encode the

00:24:08,289 --> 00:24:11,289
instructions that would note that would

00:24:09,700 --> 00:24:15,009
have to trap which don't trap on on

00:24:11,289 --> 00:24:16,539
versions prior to 8.3 into a hyper

00:24:15,009 --> 00:24:17,889
called payload and then do a hyper call

00:24:16,539 --> 00:24:21,580
and set and then just replace those with

00:24:17,889 --> 00:24:22,599
a macro and so you know we've thought

00:24:21,580 --> 00:24:24,219
about whether which makes them available

00:24:22,599 --> 00:24:26,309
or not so the people could play with it

00:24:24,219 --> 00:24:28,330
and develop on turn hardware with this I

00:24:26,309 --> 00:24:29,769
don't know right because then once you

00:24:28,330 --> 00:24:33,070
make them available than people might

00:24:29,769 --> 00:24:36,580
start using them and support things and

00:24:33,070 --> 00:24:38,139
it was a hack job so that I people ask

00:24:36,580 --> 00:24:39,580
for them will probably give them but I'm

00:24:38,139 --> 00:24:49,749
not sure we want to try to push them in

00:24:39,580 --> 00:24:55,289
any more public manner the performance

00:24:49,749 --> 00:24:57,879
of the nested virtualization yes we have

00:24:55,289 --> 00:25:00,460
okay so how about that how about the

00:24:57,879 --> 00:25:03,729
data so i have to be a little bit

00:25:00,460 --> 00:25:05,259
careful in what i can say here but so

00:25:03,729 --> 00:25:06,519
first of all the performance we've

00:25:05,259 --> 00:25:08,460
tested has been with the power

00:25:06,519 --> 00:25:10,389
virtualization approach because

00:25:08,460 --> 00:25:12,399
obviously other words we don't have hard

00:25:10,389 --> 00:25:16,749
cause i can actually run that so it may

00:25:12,399 --> 00:25:18,399
not be it may not be you know correct in

00:25:16,749 --> 00:25:22,809
terms of how I points reaches it would

00:25:18,399 --> 00:25:24,159
actually perform I mean nessa

00:25:22,809 --> 00:25:27,820
virtualization general doesn't perform

00:25:24,159 --> 00:25:31,719
fantastic also not on x86 there were

00:25:27,820 --> 00:25:35,729
cases where arm was the same several

00:25:31,719 --> 00:25:38,169
cases where arm were was worse I

00:25:35,729 --> 00:25:39,789
wouldn't move your you know super

00:25:38,169 --> 00:25:41,940
critical performance workloads into your

00:25:39,789 --> 00:25:43,899
nested vm just now let's put it that way

00:25:41,940 --> 00:25:46,289
that's it but there are ideas on how to

00:25:43,899 --> 00:25:46,289
improve that

00:25:47,360 --> 00:25:52,309
are there security implications for

00:25:49,970 --> 00:25:58,400
walking through the guests supervisor

00:25:52,309 --> 00:26:00,320
provided make tables and other lists if

00:25:58,400 --> 00:26:04,000
there are security concerns of walking

00:26:00,320 --> 00:26:06,590
the guest page tables specifically I

00:26:04,000 --> 00:26:07,940
mean there's the general configured to

00:26:06,590 --> 00:26:09,740
concern that if you add a bunch of more

00:26:07,940 --> 00:26:10,850
functionality into the whole thing and

00:26:09,740 --> 00:26:14,210
make it more complicated you have a

00:26:10,850 --> 00:26:15,770
larger attack surface I don't think that

00:26:14,210 --> 00:26:18,200
that particular aspect unless you have

00:26:15,770 --> 00:26:20,809
really obvious box there is a major

00:26:18,200 --> 00:26:29,290
security concern but then again another

00:26:20,809 --> 00:26:29,290
security guy so anything else

00:26:30,720 --> 00:26:38,120
alright well thank you

00:26:32,830 --> 00:26:42,830
[Applause]

00:26:38,120 --> 00:26:42,830

YouTube URL: https://www.youtube.com/watch?v=Mqh9J83xFxo


