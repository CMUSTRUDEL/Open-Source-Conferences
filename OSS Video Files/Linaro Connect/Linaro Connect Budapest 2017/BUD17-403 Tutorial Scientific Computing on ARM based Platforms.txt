Title: BUD17-403 Tutorial Scientific Computing on ARM based Platforms
Publication date: 2017-03-11
Playlist: Linaro Connect Budapest 2017
Description: 
	"Session ID: BUD17-403
Session Name: Tutorial Scientific Computing on ARM-based Platforms - BUD17-403
Speaker: Chris Goodyer, Chris Adeniyi-Jones
Track: LEG


★ Session Summary ★
Developing applications on ARM based machines: compilers, debuggers, runtimes and basic optimizations
---------------------------------------------------
★ Resources ★
Event Page: http://connect.linaro.org/resource/bud17/bud17-403/
Presentation: https://www.slideshare.net/linaroorg/bud17403-tutorial-scientific-computing-on-armbased-platforms
Video: https://youtu.be/H-TPoVpQ4Jo
 ---------------------------------------------------

★ Event Details ★
Linaro Connect Budapest 2017 (BUD17)
6-10 March 2017
Corinthia Hotel, Budapest,
Erzsébet krt. 43-49,
1073 Hungary

---------------------------------------------------
Keyword: LEG, ARM-based, platforms
http://www.linaro.org
http://connect.linaro.org
---------------------------------------------------
Follow us on Social Media
https://www.facebook.com/LinaroOrg
https://twitter.com/linaroorg
https://www.youtube.com/user/linaroorg?sub_confirmation=1
https://www.linkedin.com/company/1026961"
Captions: 
	00:00:00,130 --> 00:00:12,649
[Music]

00:00:12,799 --> 00:00:17,850
okay good morning I think we should

00:00:15,870 --> 00:00:20,609
start let me introduce myself my name is

00:00:17,850 --> 00:00:22,560
chris dodd any germs I work for arm in

00:00:20,609 --> 00:00:24,840
arm research in the software and

00:00:22,560 --> 00:00:26,369
large-scale systems group so I'm going

00:00:24,840 --> 00:00:29,640
to be talking today about scientific

00:00:26,369 --> 00:00:31,949
computing on arm originally when this

00:00:29,640 --> 00:00:35,880
talk was planned it was going to be in

00:00:31,949 --> 00:00:39,600
two section with some hands-on sessions

00:00:35,880 --> 00:00:41,670
in between for the i think i'm going to

00:00:39,600 --> 00:00:43,649
optimize the talk and do all the

00:00:41,670 --> 00:00:45,090
presentation in one girls and then

00:00:43,649 --> 00:00:47,969
people who want to do the hands-on

00:00:45,090 --> 00:00:50,370
tutorial stuff can do that afterwards

00:00:47,969 --> 00:00:53,730
we're going to be using the linaro

00:00:50,370 --> 00:00:56,480
developer cloud and some example things

00:00:53,730 --> 00:00:58,649
people can run to get a feel for how

00:00:56,480 --> 00:01:01,079
scientific computing on armors

00:00:58,649 --> 00:01:03,690
progressed so a little bit about my

00:01:01,079 --> 00:01:06,150
history i've been with arm a long time i

00:01:03,690 --> 00:01:10,500
first started working in design

00:01:06,150 --> 00:01:11,820
automation within arm looking at when

00:01:10,500 --> 00:01:14,189
people write their own tools to do

00:01:11,820 --> 00:01:15,750
design automation and then i moved into

00:01:14,189 --> 00:01:18,270
the compiler team of work from the

00:01:15,750 --> 00:01:20,640
compiler for a good few years and then

00:01:18,270 --> 00:01:24,299
finally i've landed up in research where

00:01:20,640 --> 00:01:29,780
i've been working on I mean HPC for

00:01:24,299 --> 00:01:29,780
quite a long time so this is the agenda

00:01:30,770 --> 00:01:37,079
are a little bit of an intro after how

00:01:34,590 --> 00:01:40,350
this got started how I mean HPC has

00:01:37,079 --> 00:01:42,899
become a thing and then we're going to

00:01:40,350 --> 00:01:45,210
look through the ecosystem for hpc what

00:01:42,899 --> 00:01:48,799
are the pieces that are required to make

00:01:45,210 --> 00:01:51,750
a successful you know deployment for

00:01:48,799 --> 00:01:55,140
forearm in hpc so there's a number of

00:01:51,750 --> 00:01:56,899
areas to go through i have a very brief

00:01:55,140 --> 00:01:58,920
section on the scalable vector

00:01:56,899 --> 00:02:01,770
extensions because that's particularly

00:01:58,920 --> 00:02:03,750
relevant for hpc so it's just a very

00:02:01,770 --> 00:02:07,079
brief introduction mr. what it's about

00:02:03,750 --> 00:02:09,830
and then just some conclusions right at

00:02:07,079 --> 00:02:12,020
the end and then the hands-on session

00:02:09,830 --> 00:02:16,670
after that

00:02:12,020 --> 00:02:18,800
oh how this all got started so it

00:02:16,670 --> 00:02:20,840
started from very small beginnings with

00:02:18,800 --> 00:02:24,560
a project called the Mont Blanc project

00:02:20,840 --> 00:02:28,220
which was a European funded a framework

00:02:24,560 --> 00:02:30,710
7 project were a number of different

00:02:28,220 --> 00:02:34,850
companies and organizations institutions

00:02:30,710 --> 00:02:36,950
got together and the the leader of the

00:02:34,850 --> 00:02:39,020
project was Boston somebody at Barcelona

00:02:36,950 --> 00:02:41,060
supercomputing center and what they were

00:02:39,020 --> 00:02:43,910
really wanted to know was is there a

00:02:41,060 --> 00:02:48,230
different way of building large-scale

00:02:43,910 --> 00:02:51,230
systems than what was present then so

00:02:48,230 --> 00:02:54,470
they had this plan to design an

00:02:51,230 --> 00:02:56,710
energy-efficient HPC prototype using low

00:02:54,470 --> 00:02:59,690
power commodity and better technology

00:02:56,710 --> 00:03:01,700
and where you see low power commodity

00:02:59,690 --> 00:03:04,490
and better technology they really meant

00:03:01,700 --> 00:03:09,380
arm so the idea was to build a prototype

00:03:04,490 --> 00:03:13,250
to build the HPC software and see how it

00:03:09,380 --> 00:03:15,560
went so in order to do that they need to

00:03:13,250 --> 00:03:17,420
support and optimize real HBC

00:03:15,560 --> 00:03:20,080
applications on the prototype so there

00:03:17,420 --> 00:03:23,120
were some application partners and then

00:03:20,080 --> 00:03:25,160
taking all this learning to kind of work

00:03:23,120 --> 00:03:29,240
out what you would do for the next

00:03:25,160 --> 00:03:32,000
system okay so how does that work you

00:03:29,240 --> 00:03:35,930
can see here this is the prototype that

00:03:32,000 --> 00:03:41,780
exists kind of a couple of racks that's

00:03:35,930 --> 00:03:46,209
about a thousand cortex a15 so 2000

00:03:41,780 --> 00:03:50,600
cortex a15 and a thousand-mile ET 604

00:03:46,209 --> 00:03:56,900
cpus kind of embedded in that system on

00:03:50,600 --> 00:03:59,150
the software side throughout the Mont

00:03:56,900 --> 00:04:01,850
Blanc project we worked on the whole

00:03:59,150 --> 00:04:04,540
ecosystem and basically some of the

00:04:01,850 --> 00:04:07,640
stuff I'm talking about later will be

00:04:04,540 --> 00:04:10,220
have come about or it's been matured

00:04:07,640 --> 00:04:13,570
because of projects like more block so

00:04:10,220 --> 00:04:17,209
alison tyler sighs and on the library's

00:04:13,570 --> 00:04:21,080
developer tools cluster management

00:04:17,209 --> 00:04:23,150
stretch etc so one question to answer is

00:04:21,080 --> 00:04:25,700
why commodity why were people interested

00:04:23,150 --> 00:04:28,280
in commodity and that the reason then

00:04:25,700 --> 00:04:32,690
which is still true was because of this

00:04:28,280 --> 00:04:35,330
graph so this is showing a time across

00:04:32,690 --> 00:04:38,330
the bottom and the number of systems in

00:04:35,330 --> 00:04:41,480
the top 500 list which is a list of the

00:04:38,330 --> 00:04:44,390
top biggest most powerful supercomputers

00:04:41,480 --> 00:04:46,760
in the world and then these different

00:04:44,390 --> 00:04:48,170
lines show the the underlying technology

00:04:46,760 --> 00:04:52,760
that's being used to implement systems

00:04:48,170 --> 00:04:55,580
and what we can see is before 1995 we

00:04:52,760 --> 00:04:58,220
had some very proprietary kind of

00:04:55,580 --> 00:05:00,530
architectures at the top of the list or

00:04:58,220 --> 00:05:03,770
making up most of the systems in the

00:05:00,530 --> 00:05:07,130
list and then over time this line begins

00:05:03,770 --> 00:05:10,630
to creep up and this line is RISC

00:05:07,130 --> 00:05:15,080
processors so things like spark and

00:05:10,630 --> 00:05:18,140
power from IBM so they kind of took over

00:05:15,080 --> 00:05:20,420
and and the advantages they had over

00:05:18,140 --> 00:05:22,880
over these in comparison was that they

00:05:20,420 --> 00:05:24,530
were the economies of scale really

00:05:22,880 --> 00:05:27,590
helped them they were they were less

00:05:24,530 --> 00:05:28,910
proprietary more commodity and then we

00:05:27,590 --> 00:05:31,040
see another inflection point coming

00:05:28,910 --> 00:05:34,910
along after the in 2000's blue line here

00:05:31,040 --> 00:05:37,850
which is essentially x86 taking up the

00:05:34,910 --> 00:05:40,100
mantle again eventually crossing over

00:05:37,850 --> 00:05:43,460
and then kind of running the roost and

00:05:40,100 --> 00:05:46,270
so the idea is commodity have some

00:05:43,460 --> 00:05:49,250
advantages you know in terms of cost

00:05:46,270 --> 00:05:52,520
because you can amortize your your

00:05:49,250 --> 00:05:55,730
development and your manufacturing over

00:05:52,520 --> 00:05:58,100
a larger number of units availability so

00:05:55,730 --> 00:06:00,290
you know the more people who are able to

00:05:58,100 --> 00:06:05,930
design with your your your product for

00:06:00,290 --> 00:06:08,810
better performance again that could be

00:06:05,930 --> 00:06:13,880
true and then the thing for for looking

00:06:08,810 --> 00:06:16,520
at low power embedded commodity was the

00:06:13,880 --> 00:06:17,960
question is energy efficiency because in

00:06:16,520 --> 00:06:20,210
terms of energy efficiencies are most

00:06:17,960 --> 00:06:21,380
energy efficient things we we had were

00:06:20,210 --> 00:06:26,060
the things we're carrying around in our

00:06:21,380 --> 00:06:28,880
pockets I suppose so that's where we

00:06:26,060 --> 00:06:34,430
started and that's why we started and

00:06:28,880 --> 00:06:37,850
where are we now so this year we're

00:06:34,430 --> 00:06:39,050
quite well quite a way forwards from

00:06:37,850 --> 00:06:41,870
where we were so

00:06:39,050 --> 00:06:45,560
in the UK there is a consortium called

00:06:41,870 --> 00:06:48,349
GW forest and universities and the UK

00:06:45,560 --> 00:06:51,050
Met Office down in the southwest of

00:06:48,349 --> 00:06:55,629
England and they're building a system

00:06:51,050 --> 00:06:58,759
called Isambard which is a tray system

00:06:55,629 --> 00:07:03,800
but it has more than 10,000 for it will

00:06:58,759 --> 00:07:05,990
have more than 10,000 on VA course so it

00:07:03,800 --> 00:07:08,270
what I mean it's not purely arm there

00:07:05,990 --> 00:07:10,460
are some things that they're using to

00:07:08,270 --> 00:07:14,719
compare the technologies but this will

00:07:10,460 --> 00:07:18,919
be at the largest actually the largest

00:07:14,719 --> 00:07:22,490
paid for by a customer system that's

00:07:18,919 --> 00:07:24,080
arm-based so you know the plan is it's

00:07:22,490 --> 00:07:30,860
being installed and commissioned over

00:07:24,080 --> 00:07:33,830
over the course of this year in Europe

00:07:30,860 --> 00:07:36,219
the continuation of the Mont Blanc

00:07:33,830 --> 00:07:41,180
project so this is now montblanc phase 3

00:07:36,219 --> 00:07:43,460
is working using cavium Thunder x2 to

00:07:41,180 --> 00:07:44,900
build a prototype that will be a lot

00:07:43,460 --> 00:07:46,750
larger than the original more blog

00:07:44,900 --> 00:07:50,599
prototype so this is going from

00:07:46,750 --> 00:07:53,509
small-scale to more serious skills so

00:07:50,599 --> 00:07:57,800
again with with at off who are already a

00:07:53,509 --> 00:07:59,630
and hpc systems integrator they're

00:07:57,800 --> 00:08:07,099
building this this system and that will

00:07:59,630 --> 00:08:11,650
be may be situated at Barcelona

00:08:07,099 --> 00:08:11,650
supercomputing center and then finally

00:08:11,800 --> 00:08:18,259
particularly relevant for spe is fujitsu

00:08:16,039 --> 00:08:21,529
announcing that you know their post

00:08:18,259 --> 00:08:25,370
confuse double will be using arm HP sync

00:08:21,529 --> 00:08:30,830
arm the arm v8 architecture including

00:08:25,370 --> 00:08:33,229
hpc and one of the one of the reasons

00:08:30,830 --> 00:08:36,229
that the national stage resist is the

00:08:33,229 --> 00:08:38,839
ecosystem is something that is the army

00:08:36,229 --> 00:08:40,889
consistent is growing in a way that is

00:08:38,839 --> 00:08:45,839
attractive

00:08:40,889 --> 00:08:49,709
okay so in terms of ecosystem what kinds

00:08:45,839 --> 00:08:51,749
of things do we need for hpc obviously

00:08:49,709 --> 00:08:55,649
we need to know s so something like

00:08:51,749 --> 00:08:57,029
Linux we need compilers we need

00:08:55,649 --> 00:08:59,189
libraries libraries are especially

00:08:57,029 --> 00:09:02,009
important for hpc because lots of

00:08:59,189 --> 00:09:05,790
higher-level hpc applications are

00:09:02,009 --> 00:09:08,579
relying on highly optimized math

00:09:05,790 --> 00:09:11,579
libraries to do their calculations for

00:09:08,579 --> 00:09:14,129
them those libraries need to be optimal

00:09:11,579 --> 00:09:16,019
and they also need to be correct so

00:09:14,129 --> 00:09:17,309
there needs to be kind of some level of

00:09:16,019 --> 00:09:19,139
validation that's gone into the

00:09:17,309 --> 00:09:20,579
development of libraries and then in

00:09:19,139 --> 00:09:22,829
terms of tools there's things like

00:09:20,579 --> 00:09:24,329
debuggers and profilers as the scale of

00:09:22,829 --> 00:09:27,329
your software increases that you have

00:09:24,329 --> 00:09:31,139
more cores and more threads and possibly

00:09:27,329 --> 00:09:34,829
different programming models the tools

00:09:31,139 --> 00:09:36,389
you need to actually work out where your

00:09:34,829 --> 00:09:38,059
bottlenecks are and what things you

00:09:36,389 --> 00:09:41,639
should change become more sophisticated

00:09:38,059 --> 00:09:43,709
and it finally seems like job shitless

00:09:41,639 --> 00:09:45,779
so there's a mixture here of things that

00:09:43,709 --> 00:09:48,209
the end-user really want the person's

00:09:45,779 --> 00:09:51,389
developing their application and the

00:09:48,209 --> 00:09:54,419
things that the system administrator

00:09:51,389 --> 00:09:58,019
once they want their arm HPC system to

00:09:54,419 --> 00:09:59,819
look as much like any other HPC system

00:09:58,019 --> 00:10:01,769
as possible so that's where some of

00:09:59,819 --> 00:10:04,649
these these other you know things like

00:10:01,769 --> 00:10:07,499
job scheduling as Linux and components

00:10:04,649 --> 00:10:10,669
that are going into that so I'm going to

00:10:07,499 --> 00:10:16,259
talk a little bit about four middle ones

00:10:10,669 --> 00:10:18,360
now so in terms of what we you know how

00:10:16,259 --> 00:10:20,669
we're seeing it overall on the hardware

00:10:18,360 --> 00:10:22,319
side things are progressing so we you

00:10:20,669 --> 00:10:26,970
know we know that there are products

00:10:22,319 --> 00:10:28,679
from people like Fabian for example

00:10:26,970 --> 00:10:31,019
rather that are doing well people are

00:10:28,679 --> 00:10:34,829
beginning to investigate using them for

00:10:31,019 --> 00:10:38,519
their HPC applications in the future so

00:10:34,829 --> 00:10:40,679
these these times are very what shall we

00:10:38,519 --> 00:10:44,160
say don't take any notice of the actual

00:10:40,679 --> 00:10:46,800
numbers here you know things that have

00:10:44,160 --> 00:10:52,130
been announced that our that are coming

00:10:46,800 --> 00:10:56,160
our processes from people like Qualcomm

00:10:52,130 --> 00:10:58,730
fight am a Chinese company who are

00:10:56,160 --> 00:11:02,220
designing as part specifically for hpc

00:10:58,730 --> 00:11:04,610
cavion with under x2 and then more in

00:11:02,220 --> 00:11:09,000
the future we have the fujitsu post k

00:11:04,610 --> 00:11:11,490
cpu in terms of open source software so

00:11:09,000 --> 00:11:18,930
this is this line here to see we have

00:11:11,490 --> 00:11:22,290
things like GCC in llvm and libraries of

00:11:18,930 --> 00:11:25,950
sorry optimized routines for for useful

00:11:22,290 --> 00:11:27,660
compiler as nhpc is now a thing that i

00:11:25,950 --> 00:11:30,209
was involved with so this is a way of

00:11:27,660 --> 00:11:35,339
trying to more standardized the

00:11:30,209 --> 00:11:38,459
deployment of hpc tools and ecosystem so

00:11:35,339 --> 00:11:41,279
i have a slide on that later as well and

00:11:38,459 --> 00:11:42,899
then in terms of tools we have got the

00:11:41,279 --> 00:11:45,930
arm performance of libraries and then we

00:11:42,899 --> 00:11:49,860
have arms arm specific tool sorry to

00:11:45,930 --> 00:11:54,079
lamar the arm compiler for hpc arm code

00:11:49,860 --> 00:11:56,760
advisor which is a tool for to help you

00:11:54,079 --> 00:11:59,130
profile your code work out bottlenecks

00:11:56,760 --> 00:12:00,990
work out ways you can improve the

00:11:59,130 --> 00:12:03,990
vectorization and things like that and i

00:12:00,990 --> 00:12:05,880
have a site about that as well and then

00:12:03,990 --> 00:12:08,940
it says in terms of independent software

00:12:05,880 --> 00:12:10,829
vendors so we have a linear up here when

00:12:08,940 --> 00:12:13,709
this slide was made they they weren't

00:12:10,829 --> 00:12:16,290
part of our but now they are still that

00:12:13,709 --> 00:12:20,820
their tools DDT a map are you know

00:12:16,290 --> 00:12:23,310
widely used in in the HPC world we have

00:12:20,820 --> 00:12:26,250
nags and numerical algorithms groups and

00:12:23,310 --> 00:12:28,350
their libraries and compiler Pascal and

00:12:26,250 --> 00:12:30,750
their compiler and environment rogue

00:12:28,350 --> 00:12:35,910
waves of total views and down the road

00:12:30,750 --> 00:12:38,550
we see you no more Ivy's beginning to

00:12:35,910 --> 00:12:42,720
dip their toes into should they poured

00:12:38,550 --> 00:12:48,420
their commercial application to 64-bit

00:12:42,720 --> 00:12:50,970
hour on the open source side there are

00:12:48,420 --> 00:12:53,370
very many packages and applications that

00:12:50,970 --> 00:12:55,500
have been ported to a or six before and

00:12:53,370 --> 00:12:57,370
are running so these are just some of

00:12:55,500 --> 00:12:59,830
them covers the whole run

00:12:57,370 --> 00:13:04,630
quite a wide spectrum of application

00:12:59,830 --> 00:13:08,260
areas of foam is a computational fluid

00:13:04,630 --> 00:13:14,080
dynamics application there's molecular

00:13:08,260 --> 00:13:15,820
dynamics quantum expresar the yeah yeah

00:13:14,080 --> 00:13:17,380
basically they're all there and they're

00:13:15,820 --> 00:13:19,020
all ported and then we'll running and

00:13:17,380 --> 00:13:25,570
now there's some process of optimization

00:13:19,020 --> 00:13:28,029
that can go on on the Linux side you can

00:13:25,570 --> 00:13:31,930
see all the logos there there is now

00:13:28,029 --> 00:13:38,140
widespread support for running on a out

00:13:31,930 --> 00:13:42,900
64 both open source and kind of

00:13:38,140 --> 00:13:42,900
commercial supported versions as well

00:13:44,910 --> 00:13:52,060
another aspect for hpc Africa systems is

00:13:49,360 --> 00:13:54,160
the file system typically the workloads

00:13:52,060 --> 00:13:58,330
are large the file size of a large and

00:13:54,160 --> 00:14:01,150
people want to have reliable high

00:13:58,330 --> 00:14:02,950
performance file systems with you know

00:14:01,150 --> 00:14:07,060
the ability to have lots of parallel

00:14:02,950 --> 00:14:10,230
axis as going at the same time so these

00:14:07,060 --> 00:14:12,820
candidates already ported to 64-bit ARM

00:14:10,230 --> 00:14:15,880
you know essentially on the clock you

00:14:12,820 --> 00:14:18,550
know the client side the actual system

00:14:15,880 --> 00:14:20,440
that's providing the storage could be

00:14:18,550 --> 00:14:23,310
any architecture but from the clients

00:14:20,440 --> 00:14:29,589
from the actual compute side of things

00:14:23,310 --> 00:14:32,680
all these clients are a ported workload

00:14:29,589 --> 00:14:36,070
and cluster manager says this is a

00:14:32,680 --> 00:14:40,420
mixture of open source and some

00:14:36,070 --> 00:14:42,250
commercial offerings and these are

00:14:40,420 --> 00:14:45,430
reported as well and running so things

00:14:42,250 --> 00:14:47,580
like firm which is a very common open

00:14:45,430 --> 00:14:51,520
source workload manager that lets you

00:14:47,580 --> 00:14:55,390
distribute jobs across a huge system and

00:14:51,520 --> 00:14:57,700
has user level accounting and workload

00:14:55,390 --> 00:15:00,070
balancing of all this kind of stuff so

00:14:57,700 --> 00:15:03,160
this is all this is all on the side that

00:15:00,070 --> 00:15:05,650
makes the system administrators job

00:15:03,160 --> 00:15:09,040
easier because it's the same software

00:15:05,650 --> 00:15:10,899
with the phone set up for their maybe

00:15:09,040 --> 00:15:13,480
intel-based HPC

00:15:10,899 --> 00:15:18,519
system as their arm one this is all

00:15:13,480 --> 00:15:20,470
coming ok so moving on to compilers so

00:15:18,519 --> 00:15:22,240
there's a number of open source and

00:15:20,470 --> 00:15:27,100
commercial compilers that generate code

00:15:22,240 --> 00:15:31,300
for a are 64 so all the usual suspects

00:15:27,100 --> 00:15:33,040
oh so GCC is well supported and that's

00:15:31,300 --> 00:15:36,059
been supported through you know work at

00:15:33,040 --> 00:15:42,249
lennar l and that arm that's going on

00:15:36,059 --> 00:15:44,139
llvm as well c and c++ a LVN for chinese

00:15:42,249 --> 00:15:47,699
coming to an oem said his work some

00:15:44,139 --> 00:15:50,679
what's going on with an open source

00:15:47,699 --> 00:15:53,829
front end or extensions to the front end

00:15:50,679 --> 00:15:59,800
from PGI for example for fortran that

00:15:53,829 --> 00:16:04,110
will make llvm viable for component

00:15:59,800 --> 00:16:07,389
fortran applications the arm HBC

00:16:04,110 --> 00:16:09,999
sequences compiler is lov n based and so

00:16:07,389 --> 00:16:12,040
we work you know with the normal open

00:16:09,999 --> 00:16:15,610
source level map and then we have some

00:16:12,040 --> 00:16:18,429
commercial compilers the past scale have

00:16:15,610 --> 00:16:22,779
their own kind of compiler flow the C

00:16:18,429 --> 00:16:25,740
C++ for trent also supports open ACC

00:16:22,779 --> 00:16:30,009
which is another acceleration style

00:16:25,740 --> 00:16:34,870
programming environment programming

00:16:30,009 --> 00:16:37,540
model it's it's like a combination of

00:16:34,870 --> 00:16:39,220
well it's like a simple OpenMP is

00:16:37,540 --> 00:16:40,720
probably the way to put it they probably

00:16:39,220 --> 00:16:43,620
wouldn't see it exactly like that but

00:16:40,720 --> 00:16:48,879
it's that style of directive based

00:16:43,620 --> 00:16:53,549
programming and then nag they have their

00:16:48,879 --> 00:16:56,709
own fortran compiler supporting a or 64

00:16:53,549 --> 00:16:58,059
the level of support for OpenMP kind of

00:16:56,709 --> 00:17:01,809
is varying between some of these

00:16:58,059 --> 00:17:04,299
compilers lots of work is going on the

00:17:01,809 --> 00:17:07,329
kind of boost especially for a loan of

00:17:04,299 --> 00:17:11,309
them for example support for the newest

00:17:07,329 --> 00:17:15,370
versions of openmp that are coming along

00:17:11,309 --> 00:17:18,730
so arm is a member of the openmp body

00:17:15,370 --> 00:17:20,949
and so we do get advanced notice we get

00:17:18,730 --> 00:17:23,360
involved in the technical discussions or

00:17:20,949 --> 00:17:25,429
new features for OpenMP

00:17:23,360 --> 00:17:27,199
what what is more difficult is to

00:17:25,429 --> 00:17:30,350
translate that intellectual engineering

00:17:27,199 --> 00:17:38,059
into the compilers awkward we're working

00:17:30,350 --> 00:17:44,230
on that ok so the arm C and C++ compiler

00:17:38,059 --> 00:17:47,720
for hpc is it as llvm based it's

00:17:44,230 --> 00:17:49,580
designed to run on arm so designed to

00:17:47,720 --> 00:17:51,290
run natively not designed to be a cross

00:17:49,580 --> 00:17:53,500
compiler this is the profiler that you

00:17:51,290 --> 00:17:57,470
run actually on your article for

00:17:53,500 --> 00:17:59,540
hardware so application development so

00:17:57,470 --> 00:18:03,740
this is really distinguishing it from

00:17:59,540 --> 00:18:05,690
other compilers Lamar that are more

00:18:03,740 --> 00:18:09,020
focused on embedded and can do bare

00:18:05,690 --> 00:18:11,150
metal as well so we are regularly you

00:18:09,020 --> 00:18:14,740
know pulling from upstream LOL vm and

00:18:11,150 --> 00:18:18,470
then we're adding support sve and then

00:18:14,740 --> 00:18:22,640
work has been done to support arm code

00:18:18,470 --> 00:18:24,559
advisor so that the compiler is

00:18:22,640 --> 00:18:27,049
essentially annotating some extra

00:18:24,559 --> 00:18:30,470
information that arm code advisor can

00:18:27,049 --> 00:18:32,570
then show will be that later yeah and

00:18:30,470 --> 00:18:36,410
then OpenMP we're using the latest

00:18:32,570 --> 00:18:38,450
version of the llvm OpenMP runtime with

00:18:36,410 --> 00:18:41,650
some arm optimization that were pushing

00:18:38,450 --> 00:18:45,080
these changes rest of the community ah

00:18:41,650 --> 00:18:47,630
it's a normal compiler this was the part

00:18:45,080 --> 00:18:51,860
of the forthcoming tutorial it's just a

00:18:47,630 --> 00:18:55,370
normal compiler normal flags and then

00:18:51,860 --> 00:19:02,090
you know with a normal normal set of

00:18:55,370 --> 00:19:04,400
options it's ready standard in terms of

00:19:02,090 --> 00:19:06,880
LOL all VMS openmp development we had

00:19:04,400 --> 00:19:10,220
done some work on optimizations and

00:19:06,880 --> 00:19:11,809
we've done some studies to compare the

00:19:10,220 --> 00:19:15,679
performance in terms of absolute

00:19:11,809 --> 00:19:20,540
performance of scaling when you use GCC

00:19:15,679 --> 00:19:23,150
use llvm and you use the GCC runtime for

00:19:20,540 --> 00:19:25,580
an imperial example or you use the llvm

00:19:23,150 --> 00:19:29,600
long time and we can see here this is

00:19:25,580 --> 00:19:35,770
for an application called co md now

00:19:29,600 --> 00:19:38,420
nilesh so foolish so this is a another

00:19:35,770 --> 00:19:43,030
scientific computing benchmark or many

00:19:38,420 --> 00:19:46,160
applications so we are running this on

00:19:43,030 --> 00:19:47,809
Thunder X based platform so the number

00:19:46,160 --> 00:19:50,870
of threads is going from zero to ninety

00:19:47,809 --> 00:19:58,540
six while from one to nine six so that

00:19:50,870 --> 00:20:03,980
will be 22 cause each with 48 sorry to

00:19:58,540 --> 00:20:07,760
soch with 48 cause kind of on a single

00:20:03,980 --> 00:20:11,059
in a single mode and then we have three

00:20:07,760 --> 00:20:14,150
lines so the blue line is GCC user in

00:20:11,059 --> 00:20:15,500
Assam and as we as we gather as we

00:20:14,150 --> 00:20:17,570
increase the number of threads this is

00:20:15,500 --> 00:20:20,059
the measure of performance on the y-axis

00:20:17,570 --> 00:20:25,309
and then we have the purple line which

00:20:20,059 --> 00:20:26,780
is GCC plus the llv llvm openmp runtime

00:20:25,309 --> 00:20:32,750
and it's finally the red crosses are

00:20:26,780 --> 00:20:38,960
llvm using the openmp the llvm affinity

00:20:32,750 --> 00:20:40,970
runtime so we can see as we scale the

00:20:38,960 --> 00:20:41,960
number of threads increasing number

00:20:40,970 --> 00:20:43,400
threat to the performance of the

00:20:41,960 --> 00:20:47,960
application is different depending on

00:20:43,400 --> 00:20:51,890
which compiler or untimely years so the

00:20:47,960 --> 00:20:53,870
GCC with lib glomps is tailing off quite

00:20:51,890 --> 00:20:59,000
significantly as a number of threads

00:20:53,870 --> 00:21:02,030
increases when we use GCC with the open

00:20:59,000 --> 00:21:05,360
interior of the llvm of mmp-1 time we

00:21:02,030 --> 00:21:09,110
get the best performance there is a

00:21:05,360 --> 00:21:12,740
slight turning off as we go across from

00:21:09,110 --> 00:21:14,120
one using one sse2 using two so we can

00:21:12,740 --> 00:21:18,110
kind of see it's kind of telling off

00:21:14,120 --> 00:21:20,230
here and then finally the llvm compiled

00:21:18,110 --> 00:21:26,120
code with the llvm open appear on time

00:21:20,230 --> 00:21:30,160
following a similar trend but is lower

00:21:26,120 --> 00:21:30,160
actually performances here

00:21:31,640 --> 00:21:38,820
okay so obviously for hpc applications

00:21:36,960 --> 00:21:40,680
you the key to getting the maximum

00:21:38,820 --> 00:21:43,050
performance because you're trying to run

00:21:40,680 --> 00:21:47,160
on with lots of course lots of threads

00:21:43,050 --> 00:21:51,740
is parallel ism so we are working on the

00:21:47,160 --> 00:21:54,390
open empty side of things to enhance the

00:21:51,740 --> 00:21:57,720
llvm implementation to get better

00:21:54,390 --> 00:21:59,160
performance together and as I said

00:21:57,720 --> 00:22:00,720
before we're an active member of the

00:21:59,160 --> 00:22:02,520
openmp Standards Committee so we're

00:22:00,720 --> 00:22:07,710
looking at the things that are coming up

00:22:02,520 --> 00:22:10,980
coming in to open mp5 for example with

00:22:07,710 --> 00:22:14,160
more emphasis on offloading to

00:22:10,980 --> 00:22:17,720
accelerators for example more emphasis

00:22:14,160 --> 00:22:20,550
on managing your memory hierarchy better

00:22:17,720 --> 00:22:24,630
adding more numeral where awareness

00:22:20,550 --> 00:22:26,760
stuff things like that openly open ACC

00:22:24,630 --> 00:22:30,390
supported within the Pascal compiler

00:22:26,760 --> 00:22:34,950
that's something some people allow very

00:22:30,390 --> 00:22:39,090
strong users of open ACC particularly

00:22:34,950 --> 00:22:41,430
some places in the US and then auto

00:22:39,090 --> 00:22:43,710
vectorization you know this is something

00:22:41,430 --> 00:22:48,000
on is actively working on in GCC and l

00:22:43,710 --> 00:22:50,400
llvm to try and improve the level of

00:22:48,000 --> 00:22:55,650
optimization or vectorization that you

00:22:50,400 --> 00:22:58,740
can get in just normal code things like

00:22:55,650 --> 00:23:02,630
MPI message passing interface using that

00:22:58,740 --> 00:23:04,860
for pilot isn't just works there are

00:23:02,630 --> 00:23:07,170
improvements that can be made on the

00:23:04,860 --> 00:23:09,090
kind of device driver side of things and

00:23:07,170 --> 00:23:18,180
that's really coming from the device

00:23:09,090 --> 00:23:22,680
providers ok moving on to libraries and

00:23:18,180 --> 00:23:27,600
other related stuff so open each pc is

00:23:22,680 --> 00:23:29,820
now working on arm so open HPC is this

00:23:27,600 --> 00:23:34,470
it's the kind of open community effort

00:23:29,820 --> 00:23:37,309
to have a common set of packages for

00:23:34,470 --> 00:23:39,620
deploying or on hpc systems so

00:23:37,309 --> 00:23:41,960
it defines a context packages that are

00:23:39,620 --> 00:23:43,279
all validated and you know definitely

00:23:41,960 --> 00:23:46,519
build on their number of different

00:23:43,279 --> 00:23:50,480
architectures and the idea is to make it

00:23:46,519 --> 00:23:52,460
easy to just deploy them and and know

00:23:50,480 --> 00:23:53,960
that you're using the right stuff the

00:23:52,460 --> 00:23:55,100
same stuff that other people are using

00:23:53,960 --> 00:23:57,679
particular if you want to compare

00:23:55,100 --> 00:23:59,870
results so I'm is a silver member of

00:23:57,679 --> 00:24:02,389
open hpc and we're on the technical

00:23:59,870 --> 00:24:07,220
steering committee in order to keep

00:24:02,389 --> 00:24:11,090
driving the arm build support so there's

00:24:07,220 --> 00:24:14,389
a 1.2 release of open HPC all the

00:24:11,090 --> 00:24:17,990
packages are built for rb8 on centos and

00:24:14,389 --> 00:24:22,820
Suzy we actually are essentially

00:24:17,990 --> 00:24:25,759
contributing some machine cycles to the

00:24:22,820 --> 00:24:29,029
open HBC build infrastructure so that

00:24:25,759 --> 00:24:32,929
you know nightly builds and regressions

00:24:29,029 --> 00:24:34,809
and things keep going forwards they have

00:24:32,929 --> 00:24:38,419
some examples of the different

00:24:34,809 --> 00:24:39,950
functional areas within open HPC there's

00:24:38,419 --> 00:24:44,240
quite a lot of them and then the

00:24:39,950 --> 00:24:46,159
examples of options so you don't you

00:24:44,240 --> 00:24:48,499
wouldn't you would be deploying all of

00:24:46,159 --> 00:24:51,139
these at the same time you might need to

00:24:48,499 --> 00:24:54,139
just appoint one for each of the N it's

00:24:51,139 --> 00:24:57,529
obviously one base LS you might decide

00:24:54,139 --> 00:25:00,049
to use you know ganglia for your your

00:24:57,529 --> 00:25:03,769
admin and stuff you might decide to use

00:25:00,049 --> 00:25:07,129
firm for your workload scheduling like

00:25:03,769 --> 00:25:10,779
this cluster etc etc so it's quite a lot

00:25:07,129 --> 00:25:13,009
in there and we're working quite hard to

00:25:10,779 --> 00:25:14,779
improve the number of packages that

00:25:13,009 --> 00:25:21,470
build forearm and the quality of those

00:25:14,779 --> 00:25:25,159
packages obviously yes in terms of open

00:25:21,470 --> 00:25:27,590
source libraries we're doing some work

00:25:25,159 --> 00:25:31,929
with the community to improve the

00:25:27,590 --> 00:25:34,789
performance of these libraries either by

00:25:31,929 --> 00:25:37,429
contributing ideas or you know

00:25:34,789 --> 00:25:41,950
suggestions or we've had some people

00:25:37,429 --> 00:25:45,200
come and spend time are armed with

00:25:41,950 --> 00:25:47,210
access to CPU Michael architects to

00:25:45,200 --> 00:25:50,179
really drill down on what they need to

00:25:47,210 --> 00:25:54,309
do to optimize the performance

00:25:50,179 --> 00:25:58,009
social example the Bliss developers that

00:25:54,309 --> 00:26:00,350
so so Blass and bliss and Atlas are all

00:25:58,009 --> 00:26:04,179
kind of linear algebra libraries that

00:26:00,350 --> 00:26:09,320
are widely used for scientific computing

00:26:04,179 --> 00:26:11,600
yeah so you know trying to with what

00:26:09,320 --> 00:26:14,230
with the app developers we've worked

00:26:11,600 --> 00:26:19,730
with the Bliss developers as well

00:26:14,230 --> 00:26:22,519
they're 50 fftw people essentially just

00:26:19,730 --> 00:26:26,330
gotta lead it did it including me on as

00:26:22,519 --> 00:26:27,980
well which has been fantastic I'm a

00:26:26,330 --> 00:26:29,419
commercial side of things in terms of

00:26:27,980 --> 00:26:30,679
libraries as the arm performance

00:26:29,419 --> 00:26:32,659
libraries which I'll come up with in a

00:26:30,679 --> 00:26:35,769
minute there's the NAG library so this

00:26:32,659 --> 00:26:39,139
is the largest library available for

00:26:35,769 --> 00:26:42,220
numerical and statistical algorithms so

00:26:39,139 --> 00:26:46,580
there's a huge number of functions

00:26:42,220 --> 00:26:48,820
scales well they're testing on 64-bit

00:26:46,580 --> 00:26:51,080
ARM so they are kind of Li the

00:26:48,820 --> 00:26:55,580
independent leaders in terms of

00:26:51,080 --> 00:26:57,230
providing libraries for hpc you know

00:26:55,580 --> 00:27:01,419
libraries that you're not getting from

00:26:57,230 --> 00:27:03,110
your systems Easter eggs are included

00:27:01,419 --> 00:27:04,669
Pascal has their own black

00:27:03,110 --> 00:27:07,460
synchronization but again that comes

00:27:04,669 --> 00:27:09,860
with their their invert compiler for the

00:27:07,460 --> 00:27:14,990
the arm performance libraries so these

00:27:09,860 --> 00:27:18,139
are commercially available libraries

00:27:14,990 --> 00:27:20,749
available from arm providing some of the

00:27:18,139 --> 00:27:23,509
lowest some of the lower level Macks

00:27:20,749 --> 00:27:27,139
routines or things like glass the pack

00:27:23,509 --> 00:27:28,879
and FST and one of the reasons that you

00:27:27,139 --> 00:27:30,649
might want to go with a commercial

00:27:28,879 --> 00:27:33,259
library rather than just using the open

00:27:30,649 --> 00:27:34,789
source libraries which do work is that

00:27:33,259 --> 00:27:36,470
you're getting you know you're getting

00:27:34,789 --> 00:27:41,539
some guarantees in terms of validation

00:27:36,470 --> 00:27:43,009
so you work is going on in making sure

00:27:41,539 --> 00:27:45,769
the libraries of validators give the

00:27:43,009 --> 00:27:49,840
right answers and many problems are

00:27:45,769 --> 00:27:52,549
fixed the library sir mama also choose

00:27:49,840 --> 00:27:53,539
so part of again while you're part of

00:27:52,549 --> 00:27:55,789
what you're getting for with your

00:27:53,539 --> 00:27:58,450
commercial support is optimizing the

00:27:55,789 --> 00:28:00,310
libraries for different arm

00:27:58,450 --> 00:28:04,150
implementations

00:28:00,310 --> 00:28:05,470
and there's also the opportunity for

00:28:04,150 --> 00:28:08,580
parlors with their own

00:28:05,470 --> 00:28:12,970
microarchitectures to work with us to

00:28:08,580 --> 00:28:17,620
get this level of optimization as well

00:28:12,970 --> 00:28:22,150
so that's why and and we can see the

00:28:17,620 --> 00:28:23,860
benefits of that so in terms of the work

00:28:22,150 --> 00:28:26,740
we've done for blast so we've added some

00:28:23,860 --> 00:28:28,890
parallel ISM extra parallelism in blast

00:28:26,740 --> 00:28:32,020
because less itself isn't necessarily

00:28:28,890 --> 00:28:35,620
implemented in a parallel way and some

00:28:32,020 --> 00:28:39,100
hand-tuned kernels or black level 3 so

00:28:35,620 --> 00:28:41,500
here we can see so in this graph this is

00:28:39,100 --> 00:28:44,650
the percentage of peak performance so

00:28:41,500 --> 00:28:47,230
the percentage of theoretical peak and

00:28:44,650 --> 00:28:49,710
the purple line is a serial version so

00:28:47,230 --> 00:28:53,230
it sucks just over you know eighty

00:28:49,710 --> 00:28:57,730
eighty-five percent and then the eight

00:28:53,230 --> 00:29:04,330
core version again it's not quite as

00:28:57,730 --> 00:29:08,440
high but it's so much it's pretty good

00:29:04,330 --> 00:29:09,880
and it's roughly stable so in terms of

00:29:08,440 --> 00:29:12,750
possibilities in terms of peak

00:29:09,880 --> 00:29:18,040
percentage of peak performance which is

00:29:12,750 --> 00:29:20,100
how much of the theoretical capability

00:29:18,040 --> 00:29:24,730
or using this is in terms of performance

00:29:20,100 --> 00:29:28,030
for which one is this issues for life

00:29:24,730 --> 00:29:31,330
hack so this is another linear linear

00:29:28,030 --> 00:29:32,950
algebra library so here we have the

00:29:31,330 --> 00:29:36,130
problem size going up so we're

00:29:32,950 --> 00:29:39,820
increasing the size of one side of the

00:29:36,130 --> 00:29:41,140
matrix and then this is the mega flocks

00:29:39,820 --> 00:29:44,080
a measure of performance higher is

00:29:41,140 --> 00:29:48,160
better so the original version had this

00:29:44,080 --> 00:29:52,470
kind of shape and then once we've added

00:29:48,160 --> 00:29:55,360
be directed a cyclical graph

00:29:52,470 --> 00:29:59,350
optimization so it's just another way of

00:29:55,360 --> 00:30:02,500
directing how parallel how and how to

00:29:59,350 --> 00:30:05,800
structure the algorithm asian as you do

00:30:02,500 --> 00:30:07,960
it with multiple threads obviously for

00:30:05,800 --> 00:30:10,480
small matrix sizes it's not that

00:30:07,960 --> 00:30:11,450
important but once you start increasing

00:30:10,480 --> 00:30:15,320
the matrix I

00:30:11,450 --> 00:30:18,529
we get much better performance as well

00:30:15,320 --> 00:30:20,389
so this is this is this is why people

00:30:18,529 --> 00:30:25,970
will be thinking of looking at the arm

00:30:20,389 --> 00:30:32,149
performance libraries sorry yes yeah

00:30:25,970 --> 00:30:34,669
yeah yeah yes good point yeah in terms

00:30:32,149 --> 00:30:36,649
of micro micro architecture obviously

00:30:34,669 --> 00:30:38,570
you want to tailor your code to your

00:30:36,649 --> 00:30:40,789
micro architecture we have done some

00:30:38,570 --> 00:30:43,669
some works and look at the effects of

00:30:40,789 --> 00:30:45,860
running if you don't child if you don't

00:30:43,669 --> 00:30:47,299
run the code that's tubs between your

00:30:45,860 --> 00:30:50,389
micro architecture on the right core

00:30:47,299 --> 00:30:53,630
what do you see so this is an example

00:30:50,389 --> 00:30:57,679
using D gem which is a double precision

00:30:53,630 --> 00:31:00,320
general matrix multiply routine this is

00:30:57,679 --> 00:31:02,090
a very fundamental piece of code many

00:31:00,320 --> 00:31:06,950
very many many algorithms are using this

00:31:02,090 --> 00:31:10,130
and so we can see here we have different

00:31:06,950 --> 00:31:12,889
versions of the D Jim colonel so we have

00:31:10,130 --> 00:31:16,429
a version tuned for cortex a53 which is

00:31:12,889 --> 00:31:18,590
an inorder core we have a version tuned

00:31:16,429 --> 00:31:22,070
for cortex a57 which is an affable the

00:31:18,590 --> 00:31:23,899
call and so if you run the right court

00:31:22,070 --> 00:31:25,669
Colonel on the right call you get the

00:31:23,899 --> 00:31:27,740
best performance so this purple line

00:31:25,669 --> 00:31:31,760
here is running at be a 53 turtle on the

00:31:27,740 --> 00:31:35,269
cortex a53 it's purple line and then be

00:31:31,760 --> 00:31:38,600
a 57 Colonel on XP 7 it's the highest

00:31:35,269 --> 00:31:41,389
performing line here so that's all great

00:31:38,600 --> 00:31:43,370
but if you run the a 53 colonel I'll

00:31:41,389 --> 00:31:45,470
make 57 you get this blue line so you're

00:31:43,370 --> 00:31:47,690
losing performance because you're

00:31:45,470 --> 00:31:49,070
running the wrong colonel you're getting

00:31:47,690 --> 00:31:50,600
the same results against the rams ox

00:31:49,070 --> 00:31:52,070
you're just getting it with lower

00:31:50,600 --> 00:31:55,190
performance and then the same

00:31:52,070 --> 00:32:02,269
surrounding a 57 colonel on a 53 is this

00:31:55,190 --> 00:32:04,340
blue this green line here so that's

00:32:02,269 --> 00:32:07,010
that's why you want to have the right

00:32:04,340 --> 00:32:08,269
version targeted so with the arm

00:32:07,010 --> 00:32:13,760
performance libraries you get different

00:32:08,269 --> 00:32:15,559
versions as well in terms of whether

00:32:13,760 --> 00:32:18,529
you're using a serial implementation or

00:32:15,559 --> 00:32:22,549
an open MP build so if your application

00:32:18,529 --> 00:32:25,070
is already using as an MP or using some

00:32:22,549 --> 00:32:25,370
other parallel library you may not want

00:32:25,070 --> 00:32:27,590
you

00:32:25,370 --> 00:32:29,150
or underlying scientific your own delon

00:32:27,590 --> 00:32:31,700
mass routine to also be using

00:32:29,150 --> 00:32:34,010
parallelism you may want to constrain

00:32:31,700 --> 00:32:35,809
them to be cereal and your algorithm is

00:32:34,010 --> 00:32:38,690
parallel or you might do the other way

00:32:35,809 --> 00:32:41,210
around you might have a more cereal on a

00:32:38,690 --> 00:32:46,960
single node algorithm and then you want

00:32:41,210 --> 00:32:49,040
your math libraries to use power levels

00:32:46,960 --> 00:32:51,890
so that's just showing how you can use

00:32:49,040 --> 00:32:54,110
them okay so that's the end of the first

00:32:51,890 --> 00:32:55,580
part I don't offend what it's going to

00:32:54,110 --> 00:32:58,490
eat any more questions or anything

00:32:55,580 --> 00:33:00,160
before I go on to the second part where

00:32:58,490 --> 00:33:07,870
I'll be talking about tools and stuff

00:33:00,160 --> 00:33:11,210
well okay so obviously the buzzards are

00:33:07,870 --> 00:33:15,200
part of liking and part of life on your

00:33:11,210 --> 00:33:17,840
writing software all this stuff that in

00:33:15,200 --> 00:33:21,309
terms of running on I'm 64-bit platforms

00:33:17,840 --> 00:33:24,020
just work so the usual tools the debug

00:33:21,309 --> 00:33:28,429
probably in order of priority princess

00:33:24,020 --> 00:33:32,630
obviously gdb just works valgrind and

00:33:28,429 --> 00:33:34,880
its associated tools also just works one

00:33:32,630 --> 00:33:36,440
thing that we were pointing out to

00:33:34,880 --> 00:33:38,750
people is to make sure that you use the

00:33:36,440 --> 00:33:41,780
most recent versions of all these tools

00:33:38,750 --> 00:33:44,809
and we're advising people to check on

00:33:41,780 --> 00:33:46,970
them Lenara web pages to get up-to-date

00:33:44,809 --> 00:33:52,970
source for some of these things that's

00:33:46,970 --> 00:33:56,840
all sat GDB so so this that's the source

00:33:52,970 --> 00:33:59,840
in terms of commercial tools there's

00:33:56,840 --> 00:34:03,110
total views from rogue wave so this is a

00:33:59,840 --> 00:34:05,929
very common hpc debugging environment

00:34:03,110 --> 00:34:10,720
it's been going a long time and it has a

00:34:05,929 --> 00:34:15,100
lot of tools and techniques you can use

00:34:10,720 --> 00:34:17,720
to debug large-scale multi-threaded

00:34:15,100 --> 00:34:19,700
programs that might be running over

00:34:17,720 --> 00:34:23,690
multiple nodes as well so things like

00:34:19,700 --> 00:34:27,919
you know red specific grade points ways

00:34:23,690 --> 00:34:31,190
to control just single threads to use

00:34:27,919 --> 00:34:33,050
red specific spec and data and all this

00:34:31,190 --> 00:34:35,260
kind of stuff allows you to track memory

00:34:33,050 --> 00:34:35,260
leaks

00:34:36,220 --> 00:34:44,120
yeah so you know and so these are the

00:34:41,090 --> 00:34:46,399
versions you know there's gonna be three

00:34:44,120 --> 00:34:49,220
of total view again this is running on

00:34:46,399 --> 00:34:51,440
the arm natively on the arm based

00:34:49,220 --> 00:34:54,200
platform when they're planning the full

00:34:51,440 --> 00:34:55,760
release for last month I haven't updated

00:34:54,200 --> 00:35:00,500
this one I'm not a hundred percent sure

00:34:55,760 --> 00:35:03,980
of what happened that yet okay so

00:35:00,500 --> 00:35:07,190
another debugger again for threaded and

00:35:03,980 --> 00:35:09,140
parallel code is a linear DDT so just in

00:35:07,190 --> 00:35:12,470
case you weren't aware I'm a quieter

00:35:09,140 --> 00:35:17,090
linear so we see a linear you can now

00:35:12,470 --> 00:35:20,270
see a linear from arm and their debugger

00:35:17,090 --> 00:35:22,870
is also has also been developed for a

00:35:20,270 --> 00:35:25,850
long time and have quite a lot of a

00:35:22,870 --> 00:35:29,720
sophisticated functionality they like to

00:35:25,850 --> 00:35:32,030
you know enable people to answer these

00:35:29,720 --> 00:35:34,280
kinds of questions you know which red

00:35:32,030 --> 00:35:36,260
had a rogue behavior so you can compare

00:35:34,280 --> 00:35:38,690
lots of different threads and sport

00:35:36,260 --> 00:35:43,250
outliers twitter is that did something

00:35:38,690 --> 00:35:45,170
different to all the others where you

00:35:43,250 --> 00:35:47,090
know so you can you have different views

00:35:45,170 --> 00:35:48,460
and you can switch between them and go

00:35:47,090 --> 00:35:53,510
to the source and all this kind of stuff

00:35:48,460 --> 00:35:59,900
how did it happen so if there's a some

00:35:53,510 --> 00:36:02,540
kind of error in terms of what the

00:35:59,900 --> 00:36:04,760
underlying which we say implementation

00:36:02,540 --> 00:36:07,880
it can it can track that kind of stuff

00:36:04,760 --> 00:36:09,860
and then it has different ways of

00:36:07,880 --> 00:36:12,440
viewing the same data to try and give

00:36:09,860 --> 00:36:14,030
you the right picture that's right for

00:36:12,440 --> 00:36:19,220
your application for the problem you're

00:36:14,030 --> 00:36:22,820
trying to debug that's all good one

00:36:19,220 --> 00:36:25,220
thing that we do have to point out to

00:36:22,820 --> 00:36:29,330
people hpc people if they're coming from

00:36:25,220 --> 00:36:31,070
a strongly in a very x86 world if that

00:36:29,330 --> 00:36:34,130
arm has a weekly ordered memory model

00:36:31,070 --> 00:36:37,640
and so this this can make something

00:36:34,130 --> 00:36:41,630
surprising to them because it means that

00:36:37,640 --> 00:36:43,730
the changes memory memory accesses can

00:36:41,630 --> 00:36:44,460
be reordered and sometimes the effects

00:36:43,730 --> 00:36:46,980
and

00:36:44,460 --> 00:36:50,430
seeing when the programmer might naively

00:36:46,980 --> 00:36:51,720
expect them to to be seen okay so if

00:36:50,430 --> 00:36:53,400
you'll just write some single threaded

00:36:51,720 --> 00:36:55,050
programs this is not normally a problem

00:36:53,400 --> 00:36:57,780
as soon as you start having multiple

00:36:55,050 --> 00:37:01,320
threads running on multiple cores with

00:36:57,780 --> 00:37:04,099
shared virtual memory and all this kind

00:37:01,320 --> 00:37:06,660
of stuff you begin to see this effect so

00:37:04,099 --> 00:37:08,630
we normally tell people you know people

00:37:06,660 --> 00:37:11,970
are using things like I've been in pain

00:37:08,630 --> 00:37:13,410
that should just work everything should

00:37:11,970 --> 00:37:15,300
be taken care of by the programming

00:37:13,410 --> 00:37:17,880
model but if people are writing their

00:37:15,300 --> 00:37:19,680
own bespoke you know parallelization

00:37:17,880 --> 00:37:24,540
using P threads and things like this

00:37:19,680 --> 00:37:26,130
then you can see they can be prone to

00:37:24,540 --> 00:37:28,710
some problems if they don't understand

00:37:26,130 --> 00:37:32,970
the the weekly lot of memory models so

00:37:28,710 --> 00:37:35,220
things like locks and valleys and ways

00:37:32,970 --> 00:37:36,630
of synchronizing me to be scrutinized

00:37:35,220 --> 00:37:42,690
quite closely to make sure that they

00:37:36,630 --> 00:37:48,930
comply with the member model okay in

00:37:42,690 --> 00:37:50,700
terms of profilers again there are you

00:37:48,930 --> 00:37:52,530
know you need to use the latest compiler

00:37:50,700 --> 00:37:54,869
to get the best performance there are

00:37:52,530 --> 00:37:58,109
some things you can do for openmp to

00:37:54,869 --> 00:38:00,680
help the openmp runtime do the best

00:37:58,109 --> 00:38:05,880
thing for your application so you can

00:38:00,680 --> 00:38:09,230
you can use affinity to schedule jobs to

00:38:05,880 --> 00:38:11,760
particular nodes of particular cause

00:38:09,230 --> 00:38:13,880
particularly should have more than one

00:38:11,760 --> 00:38:16,380
socket or if you have any kind of

00:38:13,880 --> 00:38:21,119
non-uniform memory hierarchy going on as

00:38:16,380 --> 00:38:25,980
well and then you can use only places to

00:38:21,119 --> 00:38:27,599
make things repeatable so you know we

00:38:25,980 --> 00:38:29,550
have we've seen some few successes with

00:38:27,599 --> 00:38:34,910
with people using the Alinea tools for

00:38:29,550 --> 00:38:37,890
example this customer came to linearly

00:38:34,910 --> 00:38:40,349
they had this what is this this is like

00:38:37,890 --> 00:38:43,260
a gas combustion chamber simulation or

00:38:40,349 --> 00:38:45,780
something and they wanted to run it up

00:38:43,260 --> 00:38:49,619
so the application was called converge

00:38:45,780 --> 00:38:52,500
and they had a problem presumably in the

00:38:49,619 --> 00:38:55,650
caramelization and creating some from

00:38:52,500 --> 00:38:56,770
bottleneck and their then using the

00:38:55,650 --> 00:38:58,930
avenia tools

00:38:56,770 --> 00:39:02,590
they managed to get the runtimes down

00:38:58,930 --> 00:39:04,660
from two hours 24 seconds yes which

00:39:02,590 --> 00:39:07,030
sounds amazing but again if you don't

00:39:04,660 --> 00:39:08,830
have the right view of what your

00:39:07,030 --> 00:39:12,340
application is doing it can be difficult

00:39:08,830 --> 00:39:13,900
to track things down so on the open

00:39:12,340 --> 00:39:18,120
source side of the whole load of pools

00:39:13,900 --> 00:39:22,210
42 64-bit arms just work so things like

00:39:18,120 --> 00:39:24,520
Scholastica and scorpy so again these

00:39:22,210 --> 00:39:26,890
have been work formed part of more Blanc

00:39:24,520 --> 00:39:29,820
as well which has been great so again

00:39:26,890 --> 00:39:35,050
they give you a view of your application

00:39:29,820 --> 00:39:36,780
and what's going on in terms of you know

00:39:35,050 --> 00:39:39,250
you can have a look in terms of MPI

00:39:36,780 --> 00:39:42,100
primitives of things like that and all

00:39:39,250 --> 00:39:45,270
the different threads where where the

00:39:42,100 --> 00:39:47,800
time is being spent and then there's mte

00:39:45,270 --> 00:39:50,190
which is another gives you another view

00:39:47,800 --> 00:39:53,650
where you know one color might be

00:39:50,190 --> 00:39:55,510
complete time and then another color

00:39:53,650 --> 00:39:58,600
might be wait time and so you can see

00:39:55,510 --> 00:40:00,820
which jobs are waiting or eats jobs its

00:39:58,600 --> 00:40:05,470
threads away from of experience and then

00:40:00,820 --> 00:40:09,790
finally the Tau tool as well again

00:40:05,470 --> 00:40:11,170
actually expect so I'm not sure exactly

00:40:09,790 --> 00:40:14,260
what this is showing so this is showing

00:40:11,170 --> 00:40:16,690
the wall clock time and then I think

00:40:14,260 --> 00:40:19,090
that the different colors represent what

00:40:16,690 --> 00:40:22,020
the sled was doing at that time how much

00:40:19,090 --> 00:40:27,310
time is spent doing the particular thing

00:40:22,020 --> 00:40:30,910
yeah okay so finally arm code advisor so

00:40:27,310 --> 00:40:34,660
this is this is a way of compiling your

00:40:30,910 --> 00:40:37,420
code with the compiler adding some extra

00:40:34,660 --> 00:40:40,720
information that you can then use when

00:40:37,420 --> 00:40:42,670
you profile and then you can then kind

00:40:40,720 --> 00:40:44,260
of see the combination of the

00:40:42,670 --> 00:40:47,170
information from the profiler a little

00:40:44,260 --> 00:40:50,710
Tyler so it can give you advice on you

00:40:47,170 --> 00:40:53,110
know performance tell you what things

00:40:50,710 --> 00:40:54,640
you might want to do vectorization what

00:40:53,110 --> 00:40:57,370
compiler flanks you might want to use

00:40:54,640 --> 00:41:00,610
things you might be doing wrong with

00:40:57,370 --> 00:41:04,049
fortran sub-arrays it can be looking at

00:41:00,610 --> 00:41:07,170
the instrumentation as well and so

00:41:04,049 --> 00:41:09,089
it's using a compiler insights from the

00:41:07,170 --> 00:41:11,489
compiler and then it's using the OM PT

00:41:09,089 --> 00:41:14,660
interface again which is a standard

00:41:11,489 --> 00:41:19,079
interface in the openmp one time for

00:41:14,660 --> 00:41:20,789
tracing and it's extensible so people

00:41:19,079 --> 00:41:22,410
can write their own plugins throughout

00:41:20,789 --> 00:41:25,890
their own analysis information for

00:41:22,410 --> 00:41:28,109
example and we'll see have a look video

00:41:25,890 --> 00:41:30,390
to show how it works so the typical

00:41:28,109 --> 00:41:32,549
typical workflow is you you know you

00:41:30,390 --> 00:41:34,410
start with your source you compile so

00:41:32,549 --> 00:41:37,170
then you have your compiled binary plus

00:41:34,410 --> 00:41:39,900
some insight information then you run

00:41:37,170 --> 00:41:41,849
the profile you run in to run the

00:41:39,900 --> 00:41:45,359
profiler that gives you a runtime

00:41:41,849 --> 00:41:47,249
profile then you analyzed using both of

00:41:45,359 --> 00:41:49,489
these things the insight from the

00:41:47,249 --> 00:41:54,449
compiled binary and the runtime profile

00:41:49,489 --> 00:41:59,489
and then you can use the web viewer to

00:41:54,449 --> 00:42:02,130
see the information ok so this just

00:41:59,489 --> 00:42:04,529
shows you know how easy it is you use

00:42:02,130 --> 00:42:06,059
the insight flag to the arm htpc

00:42:04,529 --> 00:42:08,759
compiler that says we want inside

00:42:06,059 --> 00:42:11,459
information then you can run arm code

00:42:08,759 --> 00:42:13,289
advisor collect your run run your

00:42:11,459 --> 00:42:14,849
example and it does the collection so

00:42:13,289 --> 00:42:17,429
it's essentially doing profiling

00:42:14,849 --> 00:42:20,130
forefront code doing sampling to work

00:42:17,429 --> 00:42:23,160
out what's going on then you run the

00:42:20,130 --> 00:42:25,859
analysis step and then you view the

00:42:23,160 --> 00:42:30,059
analysis so essentially just start the

00:42:25,859 --> 00:42:33,959
web browser that you sorry but for web

00:42:30,059 --> 00:42:36,929
server to the local web server but you

00:42:33,959 --> 00:42:39,469
can then view with your browser so

00:42:36,929 --> 00:42:39,469
here's a video

00:42:42,599 --> 00:42:58,279
ah I need to start the video the video

00:42:49,619 --> 00:43:01,049
is not working the video is working so

00:42:58,279 --> 00:43:04,979
so this is just setting up to run and

00:43:01,049 --> 00:43:08,009
then we are going to uncompress the new

00:43:04,979 --> 00:43:10,470
leisure application but the valley this

00:43:08,009 --> 00:43:13,769
is the same as we handle sessions just

00:43:10,470 --> 00:43:17,009
not using SPE so we're changing the make

00:43:13,769 --> 00:43:20,130
file for Lou leche to use the arm

00:43:17,009 --> 00:43:24,450
compiler and then we're going to add the

00:43:20,130 --> 00:43:26,729
insight flag and we just build a

00:43:24,450 --> 00:43:31,650
compartment build the application so

00:43:26,729 --> 00:43:36,779
that's compiling and linking relatively

00:43:31,650 --> 00:43:39,119
straightforward so then we run the

00:43:36,779 --> 00:43:43,380
collect face so this is running the

00:43:39,119 --> 00:43:49,319
application and sound playing to to get

00:43:43,380 --> 00:43:52,049
information about what's happening so

00:43:49,319 --> 00:43:55,739
what you can see on collect with the

00:43:52,049 --> 00:43:58,049
election then it runs gives us some

00:43:55,739 --> 00:44:01,019
answers now we're running the analysis

00:43:58,049 --> 00:44:03,809
phase which certainly just takes the

00:44:01,019 --> 00:44:08,210
information from there the previous

00:44:03,809 --> 00:44:08,210
space and now we're going to run the web

00:44:08,749 --> 00:44:15,420
server to get the webview so here we

00:44:12,660 --> 00:44:17,489
just we're just telling it week we're

00:44:15,420 --> 00:44:20,039
not doing any authentication and then

00:44:17,489 --> 00:44:22,619
this is a view you get in your web

00:44:20,039 --> 00:44:26,460
browser and then it's showing you the

00:44:22,619 --> 00:44:29,460
issues that the process is identified in

00:44:26,460 --> 00:44:33,150
order of importance so you can click on

00:44:29,460 --> 00:44:35,700
one of these and then it will tell you

00:44:33,150 --> 00:44:38,599
something in particular bathroom in here

00:44:35,700 --> 00:44:40,859
this is information about the openmp

00:44:38,599 --> 00:44:42,509
behavior of the program how much time

00:44:40,859 --> 00:44:45,839
was spent in wait how much time was

00:44:42,509 --> 00:44:48,150
spent idling here's some advice about

00:44:45,839 --> 00:44:52,619
vectorization it says why something

00:44:48,150 --> 00:44:53,650
couldn't be done yeah so here we have an

00:44:52,619 --> 00:44:55,690
example

00:44:53,650 --> 00:44:56,980
you know a conditional prevented and

00:44:55,690 --> 00:44:59,470
incidence of this loop from being

00:44:56,980 --> 00:45:01,720
vectorized so you're doing something in

00:44:59,470 --> 00:45:05,319
your loop that made it more difficult to

00:45:01,720 --> 00:45:07,990
vectorize this leap was vectorized and

00:45:05,319 --> 00:45:10,869
so you get some information without the

00:45:07,990 --> 00:45:18,039
quality of the vectorization what the

00:45:10,869 --> 00:45:20,920
trip count was it etc so this loop that

00:45:18,039 --> 00:45:22,839
the compiler determined using me on it

00:45:20,920 --> 00:45:24,460
wasn't going to be beneficial so what we

00:45:22,839 --> 00:45:27,160
can do is go back and see well if we use

00:45:24,460 --> 00:45:29,109
we're able to use it sve what would that

00:45:27,160 --> 00:45:31,329
make any difference so now we're

00:45:29,109 --> 00:45:32,619
compiling this for you so they actually

00:45:31,329 --> 00:45:36,849
said that quickly we just added a flag

00:45:32,619 --> 00:45:40,539
so now we rebuild oh it's saying compile

00:45:36,849 --> 00:45:43,589
for sve obviously if you run this thing

00:45:40,539 --> 00:45:47,529
now we get an illegal instruction

00:45:43,589 --> 00:45:49,329
because this arm machine doesn't have CA

00:45:47,529 --> 00:45:54,339
so we get an illegal instruction

00:45:49,329 --> 00:45:56,950
exception so I'm close advisor comes

00:45:54,339 --> 00:46:01,510
with an emulator that we can use to

00:45:56,950 --> 00:46:05,349
emulate sve so we can give it we can

00:46:01,510 --> 00:46:09,819
tell it how wide we want to you how wide

00:46:05,349 --> 00:46:12,609
n fe we're specifying so we run it under

00:46:09,819 --> 00:46:20,079
we can run it under the collection phase

00:46:12,609 --> 00:46:23,230
as well so it runs and then we can go

00:46:20,079 --> 00:46:25,329
through the same analysis at the

00:46:23,230 --> 00:46:30,940
analyzed step and then bring up the

00:46:25,329 --> 00:46:35,490
webview this is all the same and then we

00:46:30,940 --> 00:46:39,599
can see what the effect was on that loop

00:46:35,490 --> 00:46:39,599
if we were able to use SVA

00:46:40,930 --> 00:46:47,140
and the loop has now been vectorized

00:46:44,160 --> 00:46:50,230
using a trini instructions and it can

00:46:47,140 --> 00:46:52,869
tell you two elements of the vector

00:46:50,230 --> 00:46:58,420
register at least two elements correct

00:46:52,869 --> 00:47:08,079
for vector register okay so that's a

00:46:58,420 --> 00:47:11,500
very good one run three so that is a

00:47:08,079 --> 00:47:14,050
commercial tool yes I think we're Abby

00:47:11,500 --> 00:47:16,030
it's in beta at the moment so there is

00:47:14,050 --> 00:47:18,609
some flexibility for people to to

00:47:16,030 --> 00:47:23,579
evaluate it but I think ultimately it

00:47:18,609 --> 00:47:26,740
will be a a commercial tool from our

00:47:23,579 --> 00:47:28,890
kind of part of the exes yeah the extra

00:47:26,740 --> 00:47:28,890
add

00:47:36,670 --> 00:47:52,930
an open source tool for vectorization

00:47:39,799 --> 00:47:52,930
advice that's a good question so yeah

00:47:54,609 --> 00:48:00,650
yeah so it yet so you can use you could

00:47:57,980 --> 00:48:01,869
use clang llvm to give you something to

00:48:00,650 --> 00:48:05,180
give you the static information

00:48:01,869 --> 00:48:06,619
definitely getting there's a dynamic

00:48:05,180 --> 00:48:08,869
information where you're able to say

00:48:06,619 --> 00:48:14,539
this loop isn't worth vectorizing is

00:48:08,869 --> 00:48:23,829
slightly more tricky but if the trip can

00:48:14,539 --> 00:48:23,829
be dynamic then it but yeah yes

00:48:36,359 --> 00:48:45,760
yeah yeah it would be possible yeah

00:48:42,090 --> 00:48:49,510
thank you so the the map tool from a

00:48:45,760 --> 00:48:51,940
linear is a it's a profiler so it's

00:48:49,510 --> 00:48:54,310
designed to add you know we want it's

00:48:51,940 --> 00:48:58,420
very low over here to the measurement

00:48:54,310 --> 00:48:59,560
and have it non intrusive and also

00:48:58,420 --> 00:49:01,390
seamless so you don't want to have to

00:48:59,560 --> 00:49:05,320
recompile or relink in order to be able

00:49:01,390 --> 00:49:07,180
to do profiling subsea easy to use and

00:49:05,320 --> 00:49:08,950
it also goes deep as well it's actually

00:49:07,180 --> 00:49:12,550
able to go you know right down it's

00:49:08,950 --> 00:49:16,060
using the lowest level of information to

00:49:12,550 --> 00:49:19,450
try and identify probably problems also

00:49:16,060 --> 00:49:21,099
integrated with matt is some extra

00:49:19,450 --> 00:49:24,220
information about energy efficiency

00:49:21,099 --> 00:49:26,440
which can be quite useful to some people

00:49:24,220 --> 00:49:31,660
so for example you can run your code and

00:49:26,440 --> 00:49:33,910
if your system has the right information

00:49:31,660 --> 00:49:35,800
available to the tool it can be

00:49:33,910 --> 00:49:38,589
monitoring the you know how much you

00:49:35,800 --> 00:49:41,920
empower your system is using how much

00:49:38,589 --> 00:49:45,580
power your cpus are using and it can

00:49:41,920 --> 00:49:48,010
produce some kind of breakdown of how

00:49:45,580 --> 00:49:51,040
the energy for running your applications

00:49:48,010 --> 00:49:55,330
was used okay can you even give you some

00:49:51,040 --> 00:49:56,800
insight insight if then significant

00:49:55,330 --> 00:49:59,560
energy has been wasted through mpi

00:49:56,800 --> 00:50:01,750
communication so it might be more

00:49:59,560 --> 00:50:04,780
efficient to use fewer nodes so two

00:50:01,750 --> 00:50:06,310
course on your your parallelism in order

00:50:04,780 --> 00:50:07,990
to reduce the amount of communication

00:50:06,310 --> 00:50:13,390
between the between us between the

00:50:07,990 --> 00:50:17,980
threads so in the new version of adding

00:50:13,390 --> 00:50:20,080
a forge there's even more ability to

00:50:17,980 --> 00:50:21,550
have custom metrics so these metrics

00:50:20,080 --> 00:50:25,359
that you're looking at are from the

00:50:21,550 --> 00:50:27,940
application themselves so they're being

00:50:25,359 --> 00:50:30,130
provided to the to the tool and then you

00:50:27,940 --> 00:50:32,349
have this is looking at the file system

00:50:30,130 --> 00:50:35,859
so this is looking at the lustra file

00:50:32,349 --> 00:50:42,280
system metrics whatnot ously use the

00:50:35,859 --> 00:50:43,869
pappy metrics as well so this is just

00:50:42,280 --> 00:50:46,089
showing an example where you are able to

00:50:43,869 --> 00:50:48,280
compare using the seat just you just

00:50:46,089 --> 00:50:50,770
using a cpu or just using a number of

00:50:48,280 --> 00:50:53,680
cpus to do the calculation to renounce

00:50:50,770 --> 00:50:55,540
nation or if you have a GPU version you

00:50:53,680 --> 00:50:59,800
can use the GPU and you can do a

00:50:55,540 --> 00:51:01,960
comparison you know these will bear the

00:50:59,800 --> 00:51:04,990
total energy so in this case it was

00:51:01,960 --> 00:51:08,320
lower how much was primed how much was

00:51:04,990 --> 00:51:13,750
this energy was spent where so that's

00:51:08,320 --> 00:51:16,450
the kind of useful thing okay just a

00:51:13,750 --> 00:51:18,369
very brief couple of slides about sve so

00:51:16,450 --> 00:51:19,750
just in case people aren't aware so

00:51:18,369 --> 00:51:23,349
actually stands for scalable vector

00:51:19,750 --> 00:51:26,589
expansion this is adding vectors to the

00:51:23,349 --> 00:51:29,800
arm v8 architecture it has a number of

00:51:26,589 --> 00:51:32,920
features that mean it's not just normal

00:51:29,800 --> 00:51:35,200
kind of adding wide wide registers and

00:51:32,920 --> 00:51:37,780
then adding lots of instructions to use

00:51:35,200 --> 00:51:39,730
those there are some features that SP

00:51:37,780 --> 00:51:43,420
has that will give it enhanced

00:51:39,730 --> 00:51:45,190
flexibility and also without exploding

00:51:43,420 --> 00:51:50,700
kind of the number of instructions you

00:51:45,190 --> 00:51:53,050
need so things like per Lane predication

00:51:50,700 --> 00:51:56,080
predicate driven loot control and

00:51:53,050 --> 00:51:57,880
management so i'll be showing some of

00:51:56,080 --> 00:52:00,700
that well i'll be explained that a bit

00:51:57,880 --> 00:52:03,190
bit later vector partitioning and

00:52:00,700 --> 00:52:06,099
software manage speculation as well

00:52:03,190 --> 00:52:09,089
there's some support for horizontal

00:52:06,099 --> 00:52:11,859
reductions as well as well as the normal

00:52:09,089 --> 00:52:14,320
gather load and scatter store which is a

00:52:11,859 --> 00:52:16,990
normal thing so it's important saying

00:52:14,320 --> 00:52:19,330
you know sve is not an extension as

00:52:16,990 --> 00:52:21,339
advanced in d which was also known as me

00:52:19,330 --> 00:52:24,790
on it's a separate architectural

00:52:21,339 --> 00:52:28,359
extension and it has an you know a

00:52:24,790 --> 00:52:32,740
different instruction encoding in a 64

00:52:28,359 --> 00:52:34,180
and the focus is HPC are not mediate

00:52:32,740 --> 00:52:38,280
image processing so that means there are

00:52:34,180 --> 00:52:41,830
some things that essentially SV is not

00:52:38,280 --> 00:52:43,960
suitable for because it doesn't have

00:52:41,830 --> 00:52:47,690
some of the features that you require

00:52:43,960 --> 00:52:50,940
for for that

00:52:47,690 --> 00:52:54,390
so when people talk about adding vectors

00:52:50,940 --> 00:52:55,859
to architectures the question is what's

00:52:54,390 --> 00:52:59,250
the vector length you know how are your

00:52:55,859 --> 00:53:01,800
vectors and we answer 44 sve is that

00:52:59,250 --> 00:53:04,140
there's no preferred vector length this

00:53:01,800 --> 00:53:05,970
man's kind of set vector length the

00:53:04,140 --> 00:53:09,690
vector length is a hardware choice is

00:53:05,970 --> 00:53:11,720
something that we implement the person

00:53:09,690 --> 00:53:17,339
implementing the hardware gets to decide

00:53:11,720 --> 00:53:20,900
so the vector lenses can be from 128

00:53:17,339 --> 00:53:24,990
bits to 2048-bit in increments of 128

00:53:20,900 --> 00:53:29,040
doesn't need to be a power of two so

00:53:24,990 --> 00:53:32,310
what this means is that you have this

00:53:29,040 --> 00:53:36,599
male concept of excellence agnosticism

00:53:32,310 --> 00:53:39,630
so that the software doesn't necessarily

00:53:36,599 --> 00:53:41,609
know the actual length of the vectors

00:53:39,630 --> 00:53:44,550
doesn't know how many elements there are

00:53:41,609 --> 00:53:46,589
but you can write with the right

00:53:44,550 --> 00:53:49,830
instruction set you can write algorithms

00:53:46,589 --> 00:53:51,540
that can work very well in that case

00:53:49,830 --> 00:53:52,830
they don't need to know if the exact

00:53:51,540 --> 00:53:56,490
length they just know that there is a

00:53:52,830 --> 00:53:59,400
length and they know how to to use it

00:53:56,490 --> 00:54:01,830
the advantage of doing that means that

00:53:59,400 --> 00:54:03,900
you can write one binary that will work

00:54:01,830 --> 00:54:05,580
on platforms with different vector

00:54:03,900 --> 00:54:07,260
lengths so you don't have to keep

00:54:05,580 --> 00:54:08,670
recompiling because you're you're

00:54:07,260 --> 00:54:10,349
running on a platform of the different

00:54:08,670 --> 00:54:13,740
vector less than you originally started

00:54:10,349 --> 00:54:15,660
with for example so this I mean

00:54:13,740 --> 00:54:17,880
obviously has quite a lot of

00:54:15,660 --> 00:54:19,950
implications to select the Olympic

00:54:17,880 --> 00:54:24,869
agnostic way of approaching thing for

00:54:19,950 --> 00:54:26,430
how you optimize loops okay so hopefully

00:54:24,869 --> 00:54:28,470
more information will be coming out over

00:54:26,430 --> 00:54:32,490
the over this year about more of the

00:54:28,470 --> 00:54:37,440
details of you know the sve instruction

00:54:32,490 --> 00:54:42,720
set in terms of support for sve so in

00:54:37,440 --> 00:54:45,869
the the rhd c compiler for sve it

00:54:42,720 --> 00:54:48,330
obviously generates SB instructions so

00:54:45,869 --> 00:54:51,089
we do have a public snapshot of i lov

00:54:48,330 --> 00:54:53,369
and changes for SVA so these are being

00:54:51,089 --> 00:54:54,330
kind of incrementally up streamed into

00:54:53,369 --> 00:54:57,360
the main llvm

00:54:54,330 --> 00:55:01,020
Thanks and we started up streaming the

00:54:57,360 --> 00:55:03,630
GCC changes and the bin utils changes

00:55:01,020 --> 00:55:06,590
all Rudy upstream which is great so

00:55:03,630 --> 00:55:09,660
there's more information on our blogs

00:55:06,590 --> 00:55:15,440
while the arm community website about

00:55:09,660 --> 00:55:19,680
you know sve yeah and how you can use it

00:55:15,440 --> 00:55:22,850
in terms of compiling literally is just

00:55:19,680 --> 00:55:22,850
the case of specifying the right

00:55:23,450 --> 00:55:28,320
architecture to the compiler and very

00:55:26,340 --> 00:55:30,780
obviously you do not specify of

00:55:28,320 --> 00:55:33,540
excellence because you don't need to

00:55:30,780 --> 00:55:35,730
know in terms of being able to run

00:55:33,540 --> 00:55:40,860
binary so that have axion obviously

00:55:35,730 --> 00:55:42,600
there's no hard way yet so as shown in

00:55:40,860 --> 00:55:45,060
the video there is an emulator that

00:55:42,600 --> 00:55:48,780
comes with arm close advisor that lets

00:55:45,060 --> 00:55:50,640
you track in eagle userspace

00:55:48,780 --> 00:55:53,610
instructions so these would be there

00:55:50,640 --> 00:55:56,340
clean structures for example and then

00:55:53,610 --> 00:55:58,410
emulate those so we all this has the

00:55:56,340 --> 00:55:59,970
advantage of all the normal on VA

00:55:58,410 --> 00:56:01,890
instructions just to run at full speed

00:55:59,970 --> 00:56:04,980
and a native hardware and you're only

00:56:01,890 --> 00:56:09,690
slowing down to emulate the BFE

00:56:04,980 --> 00:56:13,590
instructions yeah and this is integrated

00:56:09,690 --> 00:56:17,010
into intercom code advisor as you can

00:56:13,590 --> 00:56:18,420
see how to run it here so you run the

00:56:17,010 --> 00:56:21,270
arm instruction emulator you expect to

00:56:18,420 --> 00:56:24,120
specify of excellence and your your

00:56:21,270 --> 00:56:30,320
thing and you can get a list of the

00:56:24,120 --> 00:56:30,320
valid legs that the year as well

00:56:30,390 --> 00:56:34,200
you

00:56:32,220 --> 00:56:36,330
okay this is just showing what's

00:56:34,200 --> 00:56:39,900
happening in the video compiling with

00:56:36,330 --> 00:56:42,510
inside and compiling for sve and then

00:56:39,900 --> 00:56:45,210
during the collect stage so the Shoshone

00:56:42,510 --> 00:56:48,140
collect use the arm emulator set the

00:56:45,210 --> 00:56:51,990
vector lens and then run this program

00:56:48,140 --> 00:56:54,840
okay final thoughts this is really as

00:56:51,990 --> 00:56:58,140
the end now so in terms of arm HBC in

00:56:54,840 --> 00:56:59,840
2017 we would say that the software

00:56:58,140 --> 00:57:02,510
ecosystem has really matured

00:56:59,840 --> 00:57:05,250
significantly in the past two years a

00:57:02,510 --> 00:57:07,140
lot of that is due to you know of the

00:57:05,250 --> 00:57:10,530
source contributions you collect their

00:57:07,140 --> 00:57:12,780
narrow people in the arm Manchester

00:57:10,530 --> 00:57:17,280
design centers who are working on the

00:57:12,780 --> 00:57:19,740
HPC tools there are now commercially

00:57:17,280 --> 00:57:23,400
available compilers libraries people

00:57:19,740 --> 00:57:27,020
those profilers that are available for

00:57:23,400 --> 00:57:30,630
people who want supported tools that way

00:57:27,020 --> 00:57:32,460
we would say ng users that you know

00:57:30,630 --> 00:57:37,470
there's very few hurdles now for

00:57:32,460 --> 00:57:39,599
migrating coned from from a system to an

00:57:37,470 --> 00:57:42,480
arm based system the programming

00:57:39,599 --> 00:57:45,000
environment in terms of Linux as gdb and

00:57:42,480 --> 00:57:49,140
all the other environment stuff is

00:57:45,000 --> 00:57:51,000
already there on HBC hard ways beginning

00:57:49,140 --> 00:57:54,300
to appear from many partners and there's

00:57:51,000 --> 00:57:55,980
no they're smaller people turning small

00:57:54,300 --> 00:57:59,900
proof-of-concept systems into bigger

00:57:55,980 --> 00:58:02,250
systems that we've seen with GW for and

00:57:59,900 --> 00:58:05,130
the actress engagement are more blanc

00:58:02,250 --> 00:58:07,230
and once we have some SVG systems that

00:58:05,130 --> 00:58:08,910
only you know bae systems that's even

00:58:07,230 --> 00:58:12,839
going to enhance the performance even

00:58:08,910 --> 00:58:16,080
more there is a website so nice and easy

00:58:12,839 --> 00:58:18,210
to remember I'm dot-com flash HPC so we

00:58:16,080 --> 00:58:22,290
launched this microsite to be the home

00:58:18,210 --> 00:58:23,940
of the HPC kind of ecosystem offering so

00:58:22,290 --> 00:58:27,930
you know you can go there and find

00:58:23,940 --> 00:58:31,290
reference material have two guides links

00:58:27,930 --> 00:58:33,210
and updates and partners and the web

00:58:31,290 --> 00:58:35,910
forum for community discussion and help

00:58:33,210 --> 00:58:38,220
so you know we're really hoping that

00:58:35,910 --> 00:58:41,829
people who are interested in our mates

00:58:38,220 --> 00:58:44,559
base hpc will go here first

00:58:41,829 --> 00:58:49,779
and then can be directed to specific

00:58:44,559 --> 00:58:51,940
places as as necessary that's just a

00:58:49,779 --> 00:58:56,589
reminder of the different arm products

00:58:51,940 --> 00:58:59,170
that you can get liar um complex bc or

00:58:56,589 --> 00:59:02,769
at least them are mentioned there so the

00:58:59,170 --> 00:59:05,469
arm compiler for hpc the arma 3 e

00:59:02,769 --> 00:59:10,569
compiler for hpc and arm code advisor

00:59:05,469 --> 00:59:12,609
beta so the summary hopefully I've given

00:59:10,569 --> 00:59:16,359
you an overview of the state of the HBC

00:59:12,609 --> 00:59:17,709
ecosystem talks a little bit about some

00:59:16,359 --> 00:59:20,170
of the commercial tools that have been

00:59:17,709 --> 00:59:23,979
developed by almond and some ecosystem

00:59:20,170 --> 00:59:27,190
partners and told you all to visit under

00:59:23,979 --> 00:59:29,410
concert HTC for more information and to

00:59:27,190 --> 00:59:31,509
Lexus so people who are interested in

00:59:29,410 --> 00:59:34,869
arm toad advisor for example can go here

00:59:31,509 --> 00:59:38,289
and I think fill in a form to indicate

00:59:34,869 --> 00:59:43,420
their interest in you know engage that

00:59:38,289 --> 00:59:45,670
way and then this bit will be afterwards

00:59:43,420 --> 00:59:48,930
for people who who are interested in

00:59:45,670 --> 00:59:53,160
actually seeing it in action themselves

00:59:48,930 --> 00:59:57,160
okay that's that's my final slide so

00:59:53,160 --> 01:00:00,190
anybody has any questions I can answer

00:59:57,160 --> 01:00:01,979
them now I think probably what we should

01:00:00,190 --> 01:00:04,239
do is have a short break and then

01:00:01,979 --> 01:00:06,819
anybody who's interested in actually

01:00:04,239 --> 01:00:09,549
doing a hands-on session from your own

01:00:06,819 --> 01:00:12,369
laptop to the machine set up in the

01:00:09,549 --> 01:00:14,709
linares developer cloud I have some user

01:00:12,369 --> 01:00:18,339
IDs and passwords and things that people

01:00:14,709 --> 01:00:19,869
can try hopefully the tutorials the

01:00:18,339 --> 01:00:23,199
front of hands-on session will be

01:00:19,869 --> 01:00:25,359
available for a number of weeks ask the

01:00:23,199 --> 01:00:32,199
linaro connect so this is not your only

01:00:25,359 --> 01:00:36,039
opportunity yep okay there's no

01:00:32,199 --> 01:00:38,109
questions we'll have a short five minute

01:00:36,039 --> 01:00:40,930
break and then anybody who's left in the

01:00:38,109 --> 01:00:45,910
room who wants to do the hands-on we can

01:00:40,930 --> 01:00:46,540
go through that there okay thank you

01:00:45,910 --> 01:00:51,250
you

01:00:46,540 --> 01:00:51,250

YouTube URL: https://www.youtube.com/watch?v=H-TPoVpQ4Jo


