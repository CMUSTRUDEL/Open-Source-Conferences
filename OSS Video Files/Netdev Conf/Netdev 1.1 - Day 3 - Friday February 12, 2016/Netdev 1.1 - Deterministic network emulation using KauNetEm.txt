Title: Netdev 1.1 - Deterministic network emulation using KauNetEm
Publication date: 2016-03-15
Playlist: Netdev 1.1 - Day 3 - Friday February 12, 2016
Description: 
	Per Hurtig, Johan Garcia
February 2016
Captions: 
	00:00:00,000 --> 00:00:06,660
so hi everyone my name is Joanne Garcia

00:00:04,200 --> 00:00:09,530
I'm from coastal university in sweden

00:00:06,660 --> 00:00:12,030
and i'm here today to talk to you about

00:00:09,530 --> 00:00:16,440
deterministic network emulation in line

00:00:12,030 --> 00:00:18,090
ups and we call that cowl net mne so we

00:00:16,440 --> 00:00:20,279
have worked a bit previously with

00:00:18,090 --> 00:00:23,460
deterministic network emulation but that

00:00:20,279 --> 00:00:26,250
has been in freebsd and now we are

00:00:23,460 --> 00:00:32,219
looking to move that functionality also

00:00:26,250 --> 00:00:35,160
to lineups so this is the outline of my

00:00:32,219 --> 00:00:37,079
talk today i will first just describe

00:00:35,160 --> 00:00:39,989
what we mean by deterministic network

00:00:37,079 --> 00:00:43,770
simulation i will provide some use case

00:00:39,989 --> 00:00:46,950
examples to show you why we consider it

00:00:43,770 --> 00:00:49,200
to be useful i will discuss the system

00:00:46,950 --> 00:00:51,570
design give you a short demo of the

00:00:49,200 --> 00:00:54,360
functionality discuss some open issues

00:00:51,570 --> 00:00:59,090
and conclude with how we viewed way

00:00:54,360 --> 00:01:02,940
forward and some closing remarks so

00:00:59,090 --> 00:01:06,450
deterministic network emulation with

00:01:02,940 --> 00:01:10,830
that we mean an emulation that allows

00:01:06,450 --> 00:01:15,479
the experiment sorry not only to

00:01:10,830 --> 00:01:18,420
generate various effects but to place

00:01:15,479 --> 00:01:23,939
these effects at precisely controlled

00:01:18,420 --> 00:01:28,400
places in space or time and in the case

00:01:23,939 --> 00:01:32,549
of space this correlates to the packet

00:01:28,400 --> 00:01:34,619
loss number the packet numbering so we

00:01:32,549 --> 00:01:38,250
can say that we want to have an

00:01:34,619 --> 00:01:40,590
emulation effect at the fifteenth packet

00:01:38,250 --> 00:01:43,619
in a flow or the second or three hundred

00:01:40,590 --> 00:01:48,090
fifty fourth or whatever or we can

00:01:43,619 --> 00:01:49,490
control the emulation effects in time to

00:01:48,090 --> 00:01:54,950
specify them have

00:01:49,490 --> 00:01:57,799
points in time as we will see so how can

00:01:54,950 --> 00:02:00,140
we use this a typical emulation setup is

00:01:57,799 --> 00:02:02,330
either physical emulation setup as shown

00:02:00,140 --> 00:02:05,149
in the top part or a virtual emulation

00:02:02,330 --> 00:02:07,189
setup as shown in the lower part with a

00:02:05,149 --> 00:02:10,099
physical emanation setup we have a

00:02:07,189 --> 00:02:12,700
dedicated machine with at least two

00:02:10,099 --> 00:02:15,440
network interfaces that does the

00:02:12,700 --> 00:02:17,630
applying of the emulation effects create

00:02:15,440 --> 00:02:22,640
extra loss or induces the packet losses

00:02:17,630 --> 00:02:24,830
or has some rate restrictions so that is

00:02:22,640 --> 00:02:28,299
one way of doing it alternatively we can

00:02:24,830 --> 00:02:31,069
use a virtual emulation setup and we do

00:02:28,299 --> 00:02:33,019
everything inside one computer we have

00:02:31,069 --> 00:02:37,940
the receiver and the sender and we have

00:02:33,019 --> 00:02:39,650
some type of network between these and

00:02:37,940 --> 00:02:41,900
that network can be more or less

00:02:39,650 --> 00:02:45,290
complicated and can be realized with

00:02:41,900 --> 00:02:51,260
virtual machines or with network name

00:02:45,290 --> 00:02:54,230
spaces for example so if we consider how

00:02:51,260 --> 00:02:56,329
we actually employ a Malaysian for the

00:02:54,230 --> 00:03:00,290
physical case so in the middle we have

00:02:56,329 --> 00:03:04,220
the machine with netta and the hosts

00:03:00,290 --> 00:03:07,579
that do the communication so to use net

00:03:04,220 --> 00:03:09,799
mne as it stands today we use TC to

00:03:07,579 --> 00:03:12,079
configure the emulation effects that we

00:03:09,799 --> 00:03:16,370
want to apply and be that packet loss

00:03:12,079 --> 00:03:20,239
rate or delay or rate restrictions or

00:03:16,370 --> 00:03:24,920
duplications so that it is how it is

00:03:20,239 --> 00:03:27,170
done today with TC we can also specify

00:03:24,920 --> 00:03:31,819
the use of a particular delay

00:03:27,170 --> 00:03:33,470
distribution file if we want our packet

00:03:31,819 --> 00:03:36,290
losses to have some particular

00:03:33,470 --> 00:03:38,569
distribution like normal distribution or

00:03:36,290 --> 00:03:42,200
Pareto distribution or something like

00:03:38,569 --> 00:03:45,319
that additionally it is also possible to

00:03:42,200 --> 00:03:48,739
use the tool make table to create your

00:03:45,319 --> 00:03:50,480
own dedicated tables with some

00:03:48,739 --> 00:03:55,160
distribution that you are interested of

00:03:50,480 --> 00:03:56,930
having these can be sourced either from

00:03:55,160 --> 00:03:59,830
traces that we have collected on the

00:03:56,930 --> 00:04:01,990
network or you can use analytical x

00:03:59,830 --> 00:04:04,600
chance to come up with the distributions

00:04:01,990 --> 00:04:06,640
that you want to have or you can take

00:04:04,600 --> 00:04:08,890
them from simulation results or hand

00:04:06,640 --> 00:04:13,570
crafts your distributions if you need

00:04:08,890 --> 00:04:18,220
some particular way of having a

00:04:13,570 --> 00:04:20,739
distribution however the important thing

00:04:18,220 --> 00:04:22,660
to consider here is that what you get is

00:04:20,739 --> 00:04:26,020
a distribution so you get a

00:04:22,660 --> 00:04:28,810
probabilistic behavior you know that

00:04:26,020 --> 00:04:31,450
okay my delay will follow this

00:04:28,810 --> 00:04:34,420
distribution but you have no control of

00:04:31,450 --> 00:04:36,520
which delay is applied to the individual

00:04:34,420 --> 00:04:38,650
packets only that they have some

00:04:36,520 --> 00:04:42,520
probability of having some particular

00:04:38,650 --> 00:04:46,330
delay so that is basically what we want

00:04:42,520 --> 00:04:52,390
to change and how do we do that well in

00:04:46,330 --> 00:04:54,700
this setup we instead exchange the delay

00:04:52,390 --> 00:04:59,110
distribution that we saw earlier here

00:04:54,700 --> 00:05:02,410
with a pattern file so now we have a

00:04:59,110 --> 00:05:04,660
pattern file which has a loss pattern or

00:05:02,410 --> 00:05:07,660
a related rate pattern or a delay

00:05:04,660 --> 00:05:10,270
pattern and this pattern file is

00:05:07,660 --> 00:05:13,600
constructed with apache on utility and

00:05:10,270 --> 00:05:17,230
this can then use the same sources as

00:05:13,600 --> 00:05:20,440
before and with this pattern then you

00:05:17,230 --> 00:05:23,380
can control exactly when the malaysian

00:05:20,440 --> 00:05:28,419
effects are applied so you can control

00:05:23,380 --> 00:05:31,540
for each packet if you want if it should

00:05:28,419 --> 00:05:33,900
be dropped or not or which rate it

00:05:31,540 --> 00:05:33,900
should have

00:05:38,530 --> 00:05:45,139
the CalNet em framework allows us to

00:05:42,470 --> 00:05:47,080
control it in two different dimensions

00:05:45,139 --> 00:05:51,590
as I mentioned earlier these are

00:05:47,080 --> 00:05:54,710
data-driven mode and time driven mode so

00:05:51,590 --> 00:05:59,060
for the data-driven mode the pattern

00:05:54,710 --> 00:06:01,610
file specifies what a Malaysian effect

00:05:59,060 --> 00:06:03,710
or how the immolation effect should be

00:06:01,610 --> 00:06:07,460
applied on the basis of individual

00:06:03,710 --> 00:06:10,430
packets so in this case the pattern file

00:06:07,460 --> 00:06:12,289
says that this particular package should

00:06:10,430 --> 00:06:16,039
be lost and this particular package

00:06:12,289 --> 00:06:20,720
should be lost so here this is of course

00:06:16,039 --> 00:06:24,590
independent of time it just depends on

00:06:20,720 --> 00:06:27,470
when packets happen to occur the other

00:06:24,590 --> 00:06:29,720
way of specifying the application of

00:06:27,470 --> 00:06:33,440
emulation effects is to use time driven

00:06:29,720 --> 00:06:36,139
mode in that case we have particular

00:06:33,440 --> 00:06:38,509
points in time where we say that at

00:06:36,139 --> 00:06:42,199
these points in time we change the state

00:06:38,509 --> 00:06:46,010
of the emulation effects so if we use a

00:06:42,199 --> 00:06:48,320
lost pattern then we say that at this

00:06:46,010 --> 00:06:50,510
point in time we start to lose all

00:06:48,320 --> 00:06:53,060
packets that arrive after that time so

00:06:50,510 --> 00:06:55,550
that would be this packet then we have a

00:06:53,060 --> 00:06:59,990
period of not losing packets and then a

00:06:55,550 --> 00:07:02,120
period again of losing packets and in

00:06:59,990 --> 00:07:06,919
the current implementation we use a

00:07:02,120 --> 00:07:10,419
millisecond as the boundary for creating

00:07:06,919 --> 00:07:10,419
new time slots

00:07:14,880 --> 00:07:22,500
so this allows quite some flexibility

00:07:18,750 --> 00:07:24,990
however it is not possible to have both

00:07:22,500 --> 00:07:27,090
of these running at the same time so

00:07:24,990 --> 00:07:32,550
either you have data driven mode or you

00:07:27,090 --> 00:07:35,750
have time driven mode so what a

00:07:32,550 --> 00:07:38,580
Malaysian effects can we apply well

00:07:35,750 --> 00:07:40,620
these are this is a list of the

00:07:38,580 --> 00:07:43,980
emulation effects that are currently

00:07:40,620 --> 00:07:46,350
implemented so we can control packet

00:07:43,980 --> 00:07:50,010
losses and that can be either data

00:07:46,350 --> 00:07:53,040
driven or time driven we can control the

00:07:50,010 --> 00:07:56,130
addition of delay and we can do that in

00:07:53,040 --> 00:07:59,490
data driven or time driven mode the same

00:07:56,130 --> 00:08:02,100
applies for changes to the rate we have

00:07:59,490 --> 00:08:04,620
the functionality to insert bit errors

00:08:02,100 --> 00:08:08,700
and that is only possible to do in the

00:08:04,620 --> 00:08:10,740
traitor tripping mode and the bitter or

00:08:08,700 --> 00:08:13,800
functionality is done in such a way that

00:08:10,740 --> 00:08:16,770
you can specify which pattern should

00:08:13,800 --> 00:08:20,190
have a bit error and you can also

00:08:16,770 --> 00:08:30,170
specify which bit in that package should

00:08:20,190 --> 00:08:33,060
be flipped but you can only flip one bit

00:08:30,170 --> 00:08:35,219
currently this is the same or similar

00:08:33,060 --> 00:08:37,830
functionality that is available for net

00:08:35,219 --> 00:08:40,020
them just with the difference that for

00:08:37,830 --> 00:08:47,520
net them the position of the bit flip is

00:08:40,020 --> 00:08:49,920
randomly decided so we also have the

00:08:47,520 --> 00:08:51,930
application capabilities there is also

00:08:49,920 --> 00:08:53,550
coming from netam and this can be

00:08:51,930 --> 00:08:57,030
controlled on a data-driven or time

00:08:53,550 --> 00:08:59,040
different fashion reordering can also be

00:08:57,030 --> 00:09:01,430
controlled and we can specify the amount

00:08:59,040 --> 00:09:05,070
of reordering that we want to have and

00:09:01,430 --> 00:09:06,600
finally we have trigger patterns so this

00:09:05,070 --> 00:09:10,740
is some functionality that is not

00:09:06,600 --> 00:09:13,350
available in regular neta and the idea

00:09:10,740 --> 00:09:18,020
with trigger pattern is is that it's the

00:09:13,350 --> 00:09:21,870
mechanism to allow the generation of

00:09:18,020 --> 00:09:23,310
like cross-layer signaling so what

00:09:21,870 --> 00:09:24,209
happens here if you have a trigger

00:09:23,310 --> 00:09:27,209
pattern

00:09:24,209 --> 00:09:29,819
that the emulator will generate the UDP

00:09:27,209 --> 00:09:32,639
packet and send that to a particular IP

00:09:29,819 --> 00:09:35,939
address and on that IP address your

00:09:32,639 --> 00:09:40,259
application can listen and we have an

00:09:35,939 --> 00:09:42,600
adaptation layer that then makes the

00:09:40,259 --> 00:09:44,459
semantic interpretation of this and one

00:09:42,600 --> 00:09:45,899
example where this can be useful can be

00:09:44,459 --> 00:09:48,240
for example in the late Halloran

00:09:45,899 --> 00:09:51,389
networking where you would like to

00:09:48,240 --> 00:09:54,329
emulate some link layer signaling that

00:09:51,389 --> 00:09:56,639
now you have some connectivity so you

00:09:54,329 --> 00:10:00,209
should start your transmissions so this

00:09:56,639 --> 00:10:04,589
can be realized with trigger patterns

00:10:00,209 --> 00:10:07,800
and we intend to implement this in the

00:10:04,589 --> 00:10:18,119
data-driven way and possibly also for

00:10:07,800 --> 00:10:22,369
time driven mode so this is a range of

00:10:18,119 --> 00:10:22,369
the emulation effects that are available

00:10:22,459 --> 00:10:29,429
so now we come to some use case examples

00:10:25,589 --> 00:10:31,379
so how can we use this how have

00:10:29,429 --> 00:10:35,069
deterministic emulation being used

00:10:31,379 --> 00:10:39,209
before well when we considered several

00:10:35,069 --> 00:10:41,069
cases of course it is very useful to use

00:10:39,209 --> 00:10:45,149
this kind of functionality if you want

00:10:41,069 --> 00:10:47,699
to validate your implementation so you

00:10:45,149 --> 00:10:49,619
want to make sure that your transport

00:10:47,699 --> 00:10:51,749
protocol implementation conforms to the

00:10:49,619 --> 00:10:56,069
specification you need to test a lot of

00:10:51,749 --> 00:11:00,529
cases and for example you might want to

00:10:56,069 --> 00:11:04,259
test the tail loss probing functionality

00:11:00,529 --> 00:11:06,749
so that can be useful and then you need

00:11:04,259 --> 00:11:09,149
to be able to control exactly where the

00:11:06,749 --> 00:11:12,629
packet losses happen so that is possible

00:11:09,149 --> 00:11:14,129
with deterministic emulation you might

00:11:12,629 --> 00:11:16,199
come up with a new transport layer

00:11:14,129 --> 00:11:18,119
mechanism for some transport protocol

00:11:16,199 --> 00:11:20,639
that you want to evaluate then of course

00:11:18,119 --> 00:11:23,220
it's very useful to have the ability to

00:11:20,639 --> 00:11:27,679
precisely control the conditions that

00:11:23,220 --> 00:11:31,829
the transport protocol sees you can also

00:11:27,679 --> 00:11:33,329
evaluate various applications and see

00:11:31,829 --> 00:11:34,660
how they work under different conditions

00:11:33,329 --> 00:11:37,480
and where

00:11:34,660 --> 00:11:39,699
you can deterministically recreate these

00:11:37,480 --> 00:11:43,050
conditions with the high level of

00:11:39,699 --> 00:11:47,470
control so for example if you are

00:11:43,050 --> 00:11:50,230
considering some VoIP application

00:11:47,470 --> 00:11:54,939
performance then you can create traces

00:11:50,230 --> 00:11:57,899
that add amounts of jitters a not in a

00:11:54,939 --> 00:12:01,540
random way but in a deterministic way

00:11:57,899 --> 00:12:03,670
and as a general observation we can see

00:12:01,540 --> 00:12:06,670
that when you do evaluations it's good

00:12:03,670 --> 00:12:09,370
to try to control what you can and then

00:12:06,670 --> 00:12:11,709
you randomize the rest so with

00:12:09,370 --> 00:12:16,240
deterministic Network emulation this

00:12:11,709 --> 00:12:18,339
allows you to control slightly more than

00:12:16,240 --> 00:12:22,180
is possible without deterministic

00:12:18,339 --> 00:12:27,189
Network emulation and that can be a good

00:12:22,180 --> 00:12:30,339
thing and one illustration of this is

00:12:27,189 --> 00:12:35,920
what we see here so this is an

00:12:30,339 --> 00:12:42,459
evaluation of how much impact changes of

00:12:35,920 --> 00:12:45,699
the initial window of TCP has for some

00:12:42,459 --> 00:12:48,189
particular bandwidth and delay and what

00:12:45,699 --> 00:12:50,290
we see on the I axis is the flow

00:12:48,189 --> 00:12:53,740
completion time for a fairly short flow

00:12:50,290 --> 00:12:55,870
and on the x-axis is a number of

00:12:53,740 --> 00:13:02,110
replications so third clear applications

00:12:55,870 --> 00:13:04,600
and here we had also losses when we ran

00:13:02,110 --> 00:13:08,170
these experiments and of course the

00:13:04,600 --> 00:13:10,449
results is highly dependent on whether

00:13:08,170 --> 00:13:13,600
or not we happen to have a packet loss

00:13:10,449 --> 00:13:15,970
for each particular replication so when

00:13:13,600 --> 00:13:20,800
we have a packet loss we get very high

00:13:15,970 --> 00:13:23,110
values and we run this over an emulated

00:13:20,800 --> 00:13:26,170
link where the losses are inserted

00:13:23,110 --> 00:13:29,680
randomly so we don't have any control

00:13:26,170 --> 00:13:33,009
over that which means that when we make

00:13:29,680 --> 00:13:35,350
a run with one setting we may get a loss

00:13:33,009 --> 00:13:36,699
or we may not get a loss and then we

00:13:35,350 --> 00:13:39,399
change the setting to another

00:13:36,699 --> 00:13:41,769
configuration and run the experiment

00:13:39,399 --> 00:13:45,910
again and then we may get a loss or may

00:13:41,769 --> 00:13:47,890
not get a loss we can only specify a

00:13:45,910 --> 00:13:51,860
particular loss rate for the

00:13:47,890 --> 00:13:56,150
so this is the way it is done if you

00:13:51,860 --> 00:13:58,700
don't have deterministic emulation an

00:13:56,150 --> 00:14:02,750
alternative approach is instead of

00:13:58,700 --> 00:14:07,310
having random losses we generate loss

00:14:02,750 --> 00:14:09,890
patterns so we generate 30 patterns

00:14:07,310 --> 00:14:14,060
because we have certainty replications

00:14:09,890 --> 00:14:17,240
and in these patterns we randomly place

00:14:14,060 --> 00:14:20,060
losses and then we apply the same

00:14:17,240 --> 00:14:23,870
pattern for both different configuration

00:14:20,060 --> 00:14:28,520
options and if you do that then the

00:14:23,870 --> 00:14:31,310
results look like this so here we see

00:14:28,520 --> 00:14:34,760
that there's somewhat more tighter

00:14:31,310 --> 00:14:37,700
coupling to the behavior so in this case

00:14:34,760 --> 00:14:40,660
the pattern has a loss at some

00:14:37,700 --> 00:14:43,610
particular position so we get an

00:14:40,660 --> 00:14:47,360
increase in the flow completion time for

00:14:43,610 --> 00:14:51,980
both configurations in some cases there

00:14:47,360 --> 00:14:53,960
is a difference that is due to how to

00:14:51,980 --> 00:14:56,270
the particular configuration so that

00:14:53,960 --> 00:14:59,930
depends on where and the loss happened

00:14:56,270 --> 00:15:03,110
here in inside the flow at with at which

00:14:59,930 --> 00:15:05,780
position so now instead of having

00:15:03,110 --> 00:15:08,150
totally random losses we still have

00:15:05,780 --> 00:15:11,060
randomly placed losses that we have them

00:15:08,150 --> 00:15:15,040
placed at exactly the same positions for

00:15:11,060 --> 00:15:20,150
both configuration options so is this

00:15:15,040 --> 00:15:23,090
then beneficial or not well if you

00:15:20,150 --> 00:15:25,370
calculate the difference between these

00:15:23,090 --> 00:15:28,580
different configurations options for the

00:15:25,370 --> 00:15:32,510
initial window then you end up with this

00:15:28,580 --> 00:15:37,460
so what you see here is the mean

00:15:32,510 --> 00:15:40,640
difference between the the mean of the

00:15:37,460 --> 00:15:43,910
30 replications and this is for the

00:15:40,640 --> 00:15:46,940
paired case so where we have our loss

00:15:43,910 --> 00:15:49,640
patterns and then we see that we have a

00:15:46,940 --> 00:15:52,340
meaning difference of 200 milliseconds

00:15:49,640 --> 00:15:55,040
and that it's statistically significant

00:15:52,340 --> 00:15:58,310
at this particular significance level

00:15:55,040 --> 00:16:00,000
that is used here which is five percent

00:15:58,310 --> 00:16:03,570
significance or 95

00:16:00,000 --> 00:16:07,140
confluence whereas if we instead look at

00:16:03,570 --> 00:16:11,550
the first case where we just had random

00:16:07,140 --> 00:16:13,500
losses on the link then we see a very

00:16:11,550 --> 00:16:15,750
small difference in the means and a

00:16:13,500 --> 00:16:19,260
considerably larger confidence interval

00:16:15,750 --> 00:16:21,960
and of course this is because the effect

00:16:19,260 --> 00:16:25,620
of the random packet losses is

00:16:21,960 --> 00:16:28,820
confounding the effect of the parameter

00:16:25,620 --> 00:16:34,010
change that we are examining so this is

00:16:28,820 --> 00:16:37,590
an illustration to show that using

00:16:34,010 --> 00:16:40,110
patterns can provide an increased otisco

00:16:37,590 --> 00:16:43,530
strength if you are evaluating some

00:16:40,110 --> 00:16:46,530
particular parameter change over here we

00:16:43,530 --> 00:16:49,020
see the results for another

00:16:46,530 --> 00:16:52,260
configuration set up with a much higher

00:16:49,020 --> 00:16:57,630
delay and here of course we see an

00:16:52,260 --> 00:17:01,080
effect for both approaches deterministic

00:16:57,630 --> 00:17:04,260
or non deterministic losses but for the

00:17:01,080 --> 00:17:07,290
non deterministic losses the confidence

00:17:04,260 --> 00:17:12,199
interval is quite a bit larger so this

00:17:07,290 --> 00:17:17,900
is one illustration of how pattern based

00:17:12,199 --> 00:17:17,900
control can be useful in the evaluation

00:17:19,130 --> 00:17:25,589
so here we have another illustration

00:17:22,579 --> 00:17:30,330
what is done here is that we have a flow

00:17:25,589 --> 00:17:34,710
of 21 packets and we want to transmit it

00:17:30,330 --> 00:17:38,310
and now instead of having the losses

00:17:34,710 --> 00:17:42,750
placed randomly we can replace a loss at

00:17:38,310 --> 00:17:46,140
each position in the flow so and then we

00:17:42,750 --> 00:17:49,080
measure the transmission time of the

00:17:46,140 --> 00:17:51,720
flow and of course we see that if we

00:17:49,080 --> 00:17:53,760
lose the very first packet then we have

00:17:51,720 --> 00:17:58,860
a much higher transmission time because

00:17:53,760 --> 00:18:02,730
we need to make a timeout for the scene

00:17:58,860 --> 00:18:08,250
which is takes quite a bit of law longer

00:18:02,730 --> 00:18:12,270
time and then for the later packets we

00:18:08,250 --> 00:18:13,560
see that the amount of flow completion

00:18:12,270 --> 00:18:16,620
time is of course much low

00:18:13,560 --> 00:18:19,380
because the recuperation from the packet

00:18:16,620 --> 00:18:22,050
loss is much faster and then in the end

00:18:19,380 --> 00:18:26,400
we see that okay in this case we are

00:18:22,050 --> 00:18:29,250
examining if you change the value of the

00:18:26,400 --> 00:18:32,460
early retransmit parameter in the line

00:18:29,250 --> 00:18:36,390
exists control what actually happens in

00:18:32,460 --> 00:18:40,620
the end and we see that if you turn off

00:18:36,390 --> 00:18:44,070
the tailor's probe and early retransmit

00:18:40,620 --> 00:18:47,730
mechanisms then if you happen to have a

00:18:44,070 --> 00:18:49,110
loss at the end of TCP flow then the

00:18:47,730 --> 00:18:52,370
flow completion time will take a

00:18:49,110 --> 00:18:56,310
considerable heat whereas if you have

00:18:52,370 --> 00:18:58,440
the TLP and the ER turned on then it

00:18:56,310 --> 00:19:02,010
works quite a bit better and it's just

00:18:58,440 --> 00:19:04,110
for the final packet that you will have

00:19:02,010 --> 00:19:07,740
an extra delay so this is one way to

00:19:04,110 --> 00:19:10,560
validate that the behavior that you

00:19:07,740 --> 00:19:18,870
expect for from a transport protocol is

00:19:10,560 --> 00:19:20,580
actually occurring so I will cover a

00:19:18,870 --> 00:19:27,810
little bit about the cabinet system

00:19:20,580 --> 00:19:30,570
design so as we saw earlier we have TC

00:19:27,810 --> 00:19:33,390
to do the pattern loading and we have

00:19:30,570 --> 00:19:37,290
patent to do the pattern creation this

00:19:33,390 --> 00:19:39,660
is done in user space and we have added

00:19:37,290 --> 00:19:45,570
as you can see the orange part here is

00:19:39,660 --> 00:19:48,750
the stuff that is net them and counted

00:19:45,570 --> 00:19:57,210
joint and red part is just a kalinihta

00:19:48,750 --> 00:19:59,370
so pertinent table management is reusing

00:19:57,210 --> 00:20:01,470
part of the functionality from the

00:19:59,370 --> 00:20:02,760
loading of the distribution table so we

00:20:01,470 --> 00:20:06,240
didn't have to do all that from scratch

00:20:02,760 --> 00:20:07,650
and however we did the pattern decoding

00:20:06,240 --> 00:20:14,070
and forwarding because we have to

00:20:07,650 --> 00:20:17,460
represent the amount of rate that we

00:20:14,070 --> 00:20:20,340
want to have or what particular level of

00:20:17,460 --> 00:20:23,250
of losses that we want to have and this

00:20:20,340 --> 00:20:24,720
is encoded as we will see for shortly in

00:20:23,250 --> 00:20:28,810
a particular way so

00:20:24,720 --> 00:20:31,120
decoded in the kernel and then we have

00:20:28,810 --> 00:20:34,060
the individual a Malaysian effects that

00:20:31,120 --> 00:20:36,550
are applied as traffic goes by so here

00:20:34,060 --> 00:20:40,150
we use this a Malaysian effects that are

00:20:36,550 --> 00:20:42,520
already available in net them and we

00:20:40,150 --> 00:20:45,400
just change their parameters at

00:20:42,520 --> 00:20:47,500
particular points in time or when a

00:20:45,400 --> 00:20:52,390
particular number of packets have been

00:20:47,500 --> 00:20:56,290
seen so how do we represent the data so

00:20:52,390 --> 00:20:59,020
this is shown here for the case where we

00:20:56,290 --> 00:21:00,760
need to represent large values so this

00:20:59,020 --> 00:21:03,420
is the case for bandwidth patterns or

00:21:00,760 --> 00:21:06,370
delayed patterns and we have designed a

00:21:03,420 --> 00:21:11,350
format where we can have a 11 bit

00:21:06,370 --> 00:21:14,860
mantissa and 4-bit exponent and if we

00:21:11,350 --> 00:21:18,280
have a value and if we instead want to

00:21:14,860 --> 00:21:21,100
specify okay how long is it until which

00:21:18,280 --> 00:21:24,040
should change the value the next time so

00:21:21,100 --> 00:21:26,470
if we want to say that okay after 1000

00:21:24,040 --> 00:21:28,420
packets we should set a new value then

00:21:26,470 --> 00:21:31,810
we specify the run length value here and

00:21:28,420 --> 00:21:33,970
then we specify a new value here and the

00:21:31,810 --> 00:21:37,090
interpretation is of course controlled

00:21:33,970 --> 00:21:39,280
by the flag value over there so with

00:21:37,090 --> 00:21:43,900
this particular way of representing the

00:21:39,280 --> 00:21:47,020
data we can represent rates from zero

00:21:43,900 --> 00:21:49,930
bits per second up to 2 theta bits per

00:21:47,020 --> 00:21:53,760
second so hopefully this should hold out

00:21:49,930 --> 00:21:57,310
for for some wife while in the future

00:21:53,760 --> 00:22:00,670
also with the lace we can represent them

00:21:57,310 --> 00:22:03,370
to the order of years so that shouldn't

00:22:00,670 --> 00:22:06,220
be a problem however you could think

00:22:03,370 --> 00:22:08,830
about okay only using 11 bits for a

00:22:06,220 --> 00:22:11,890
mantissa what will that do to the

00:22:08,830 --> 00:22:14,920
accuracy that you can achieve so in fact

00:22:11,890 --> 00:22:17,710
that shouldn't be any major problem as

00:22:14,920 --> 00:22:21,850
we can see here so this show is the

00:22:17,710 --> 00:22:26,110
representation error for a range of

00:22:21,850 --> 00:22:31,200
values between 1 and 10 so if you want

00:22:26,110 --> 00:22:31,200
to specify okay I need to have a rate of

00:22:31,650 --> 00:22:39,980
20 point 57 megabits per sec

00:22:36,890 --> 00:22:42,380
and that cannot be represented exactly

00:22:39,980 --> 00:22:47,960
instead that would have to be rounded up

00:22:42,380 --> 00:22:51,530
in this case to 20.5 so then we are just

00:22:47,960 --> 00:22:55,820
here so in this case the max the worst

00:22:51,530 --> 00:22:59,450
case in inefficiency in the

00:22:55,820 --> 00:23:02,150
representation is around 0.5 percent and

00:22:59,450 --> 00:23:05,000
we consider that to be quite acceptable

00:23:02,150 --> 00:23:10,220
given that the emulation framework in

00:23:05,000 --> 00:23:12,410
itself has some level of in accuracy and

00:23:10,220 --> 00:23:15,140
again this is only if you have these

00:23:12,410 --> 00:23:19,280
very uneven numbers so of course if you

00:23:15,140 --> 00:23:21,460
need to have like 2 3 4 or 20 something

00:23:19,280 --> 00:23:28,130
like that then and that is without any

00:23:21,460 --> 00:23:30,740
representation error at all okay so

00:23:28,130 --> 00:23:34,640
looking at other ways of representing

00:23:30,740 --> 00:23:36,920
data we can see that if we have packet

00:23:34,640 --> 00:23:39,320
data we just have a run length value to

00:23:36,920 --> 00:23:42,950
control when the packet loss should be

00:23:39,320 --> 00:23:47,120
applied and something to note here is

00:23:42,950 --> 00:23:50,030
that due to how the patterns are loaded

00:23:47,120 --> 00:23:53,150
into the kernel with TC currently there

00:23:50,030 --> 00:23:55,460
is a limit on 16 of 16 kilobytes for the

00:23:53,150 --> 00:23:58,850
patterns which means that we can now

00:23:55,460 --> 00:24:02,210
only have a restricted number of packet

00:23:58,850 --> 00:24:05,270
losses so in this example if we have a

00:24:02,210 --> 00:24:09,530
0.1 percent packet loss rate at 100

00:24:05,270 --> 00:24:12,740
million megabytes per second then we can

00:24:09,530 --> 00:24:17,030
run for 24 minutes that before we

00:24:12,740 --> 00:24:18,950
exhaust the pattern we can also

00:24:17,030 --> 00:24:21,560
represent injured integers for

00:24:18,950 --> 00:24:24,110
reordering bit errors and these trigger

00:24:21,560 --> 00:24:25,520
patterns that I mentioned and that is

00:24:24,110 --> 00:24:29,960
done in a similar way to the float

00:24:25,520 --> 00:24:32,780
representation so what we do what did we

00:24:29,960 --> 00:24:34,820
need to do to implement this well it

00:24:32,780 --> 00:24:37,400
turned out that we didn't need to change

00:24:34,820 --> 00:24:39,170
a lot of the code inside the colonel in

00:24:37,400 --> 00:24:44,540
this case we start by looking at the

00:24:39,170 --> 00:24:46,250
user code extensions and for TC we just

00:24:44,540 --> 00:24:48,440
added some code to do

00:24:46,250 --> 00:24:51,110
the loading and transfer of the patterns

00:24:48,440 --> 00:24:54,110
and then we have the pattern utility

00:24:51,110 --> 00:25:02,320
which takes care of generating these

00:24:54,110 --> 00:25:07,640
encoded patterns io related to that and

00:25:02,320 --> 00:25:10,070
this is the some of the comments that

00:25:07,640 --> 00:25:12,170
can be used with patents so we specify

00:25:10,070 --> 00:25:16,250
which type of pattern we should generate

00:25:12,170 --> 00:25:18,050
and we can specify a list of values

00:25:16,250 --> 00:25:22,100
directly on the common line or read them

00:25:18,050 --> 00:25:25,330
from a file and there are some

00:25:22,100 --> 00:25:31,970
particular options for packet losses so

00:25:25,330 --> 00:25:35,000
we can set here the fraction of packet

00:25:31,970 --> 00:25:39,490
losses that we want to have so 0.5

00:25:35,000 --> 00:25:42,560
percent or 0.2 percent or whatever or

00:25:39,490 --> 00:25:44,840
alternatively we can say how many losses

00:25:42,560 --> 00:25:48,140
do we want to have for this particular

00:25:44,840 --> 00:25:52,310
pattern so we say that okay we generate

00:25:48,140 --> 00:25:54,440
a pattern that is covering 1,000 packets

00:25:52,310 --> 00:25:58,340
and we want to make sure that there are

00:25:54,440 --> 00:26:00,470
exactly two losses for these 1000

00:25:58,340 --> 00:26:03,260
packets but the losses can be randomly

00:26:00,470 --> 00:26:06,800
placed so is there really a difference

00:26:03,260 --> 00:26:09,860
between specifying and 0.2 packet loss

00:26:06,800 --> 00:26:14,110
probability were specifying that you

00:26:09,860 --> 00:26:17,240
should have two losses per 1,000 packets

00:26:14,110 --> 00:26:20,870
well it turns out that yes there is

00:26:17,240 --> 00:26:23,390
quite a bit of a difference so for the

00:26:20,870 --> 00:26:27,080
case where you specify the packet loss

00:26:23,390 --> 00:26:30,920
probability then in fact what you will

00:26:27,080 --> 00:26:34,630
get is something that looks like this so

00:26:30,920 --> 00:26:39,190
for a given thousand packet flow with

00:26:34,630 --> 00:26:42,710
0.2 loss probability then on average on

00:26:39,190 --> 00:26:46,540
average you should get two losses

00:26:42,710 --> 00:26:50,450
because you have 0.2% over 1,000 packets

00:26:46,540 --> 00:26:54,500
but for any individual flow the

00:26:50,450 --> 00:26:58,310
probability of the number of losses that

00:26:54,500 --> 00:26:59,890
that flow sees is shown here so in fact

00:26:58,310 --> 00:27:02,690
it's almost as

00:26:59,890 --> 00:27:06,430
probable that you will get just one loss

00:27:02,690 --> 00:27:11,660
as the case where you get two losses and

00:27:06,430 --> 00:27:15,740
it's also the case that on approximately

00:27:11,660 --> 00:27:18,140
one in seven of the flows which has this

00:27:15,740 --> 00:27:20,900
specification will not see any packet

00:27:18,140 --> 00:27:23,230
loss at all and of course if you are

00:27:20,900 --> 00:27:26,240
trying to evaluate the behavior when

00:27:23,230 --> 00:27:28,220
packet losses occur if no packet losses

00:27:26,240 --> 00:27:31,640
occurred and what are you actually

00:27:28,220 --> 00:27:34,250
evaluating so of course alternatively we

00:27:31,640 --> 00:27:36,860
can specify it okay for a particular

00:27:34,250 --> 00:27:40,100
pattern size we say that there should be

00:27:36,860 --> 00:27:42,260
two losses and then you know that in one

00:27:40,100 --> 00:27:45,590
hundred percent of the cases there will

00:27:42,260 --> 00:27:51,550
be two losses so then you know what you

00:27:45,590 --> 00:27:55,400
are actually evaluating okay so

00:27:51,550 --> 00:27:58,970
scheduling we have to do some work on

00:27:55,400 --> 00:28:03,470
that and the net time itself of course

00:27:58,970 --> 00:28:11,420
we did some modifications so just some

00:28:03,470 --> 00:28:16,700
brief demonstration so what we see here

00:28:11,420 --> 00:28:20,480
is script where we and do some

00:28:16,700 --> 00:28:22,910
data-driven packet loss test and I don't

00:28:20,480 --> 00:28:24,650
we have the control comments for the

00:28:22,910 --> 00:28:28,480
script and we want to place the losses

00:28:24,650 --> 00:28:28,480
at positions three five and ten

00:28:32,360 --> 00:28:43,940
and when we run that well as we expected

00:28:38,900 --> 00:28:51,500
we have lost the packets at position 3 5

00:28:43,940 --> 00:28:55,870
and 10 another example is where we can

00:28:51,500 --> 00:28:59,030
have reordering so here we specify that

00:28:55,870 --> 00:29:01,100
packet number two should be reordered

00:28:59,030 --> 00:29:05,350
five places and packet number three

00:29:01,100 --> 00:29:05,350
should be reordered one place

00:29:10,870 --> 00:29:19,750
and when we run that we see that that is

00:29:16,780 --> 00:29:22,470
actually what is happening so if we look

00:29:19,750 --> 00:29:26,380
at the sequence numbers we see one and

00:29:22,470 --> 00:29:28,120
then three four because pack number

00:29:26,380 --> 00:29:30,610
three should be reordered and we have

00:29:28,120 --> 00:29:33,520
packet number two down here so this is

00:29:30,610 --> 00:29:38,800
one example of how we can control these

00:29:33,520 --> 00:29:42,010
different emulation effects so what are

00:29:38,800 --> 00:29:44,080
the open issues with the cowl netam well

00:29:42,010 --> 00:29:45,790
things that we haven't decided yet is

00:29:44,080 --> 00:29:50,080
what should happen at the end of a

00:29:45,790 --> 00:29:51,910
pattern for now it just ends but we

00:29:50,080 --> 00:29:56,050
could add functionality for wraparound

00:29:51,910 --> 00:29:59,230
or a pending additional patterns another

00:29:56,050 --> 00:30:03,130
issue what should happen when we have a

00:29:59,230 --> 00:30:05,770
change in the configured rate so this is

00:30:03,130 --> 00:30:09,340
basically tied to question if we should

00:30:05,770 --> 00:30:15,730
be able to change the rate when a packet

00:30:09,340 --> 00:30:17,260
is being transmitted or not if we so

00:30:15,730 --> 00:30:22,780
that is also something that we need to

00:30:17,260 --> 00:30:26,830
decide on also we are considering if we

00:30:22,780 --> 00:30:30,370
should add additional pattern types that

00:30:26,830 --> 00:30:32,050
is one open issue and we have some

00:30:30,370 --> 00:30:35,170
architectural issues so should we

00:30:32,050 --> 00:30:38,260
perhaps fold the patch encode into TC

00:30:35,170 --> 00:30:40,510
instead of having a separate command

00:30:38,260 --> 00:30:42,550
line utility for that and should we

00:30:40,510 --> 00:30:44,860
maybe split the delay patent

00:30:42,550 --> 00:30:48,730
functionality to two different types of

00:30:44,860 --> 00:30:51,790
patterns so that could be delays where

00:30:48,730 --> 00:30:53,830
reordering can happen if you have a very

00:30:51,790 --> 00:30:56,290
large variation in the configured delay

00:30:53,830 --> 00:30:59,590
or and one other variation is where you

00:30:56,290 --> 00:31:01,630
have 50 so regardless of what you set

00:30:59,590 --> 00:31:03,940
the delay for the individual packets

00:31:01,630 --> 00:31:10,570
reordering can not occur so there is

00:31:03,940 --> 00:31:14,650
also a possibility when we implemented

00:31:10,570 --> 00:31:16,600
this the way that we did we chose nair

00:31:14,650 --> 00:31:17,630
em because that meant that we didn't

00:31:16,600 --> 00:31:20,600
have to add

00:31:17,630 --> 00:31:22,400
of code we could reuse much of the

00:31:20,600 --> 00:31:27,170
functionality that is already available

00:31:22,400 --> 00:31:29,900
in neta some disadvantages of net them

00:31:27,170 --> 00:31:32,900
is that we cannot nest the net Thank You

00:31:29,900 --> 00:31:34,880
disk so if you want to have a particular

00:31:32,900 --> 00:31:38,990
watering of when you apply to different

00:31:34,880 --> 00:31:44,240
effects that cannot be achieved so that

00:31:38,990 --> 00:31:46,990
is one drawback so there are some

00:31:44,240 --> 00:31:49,670
alternatives of implementing this

00:31:46,990 --> 00:31:52,040
deterministic emulation functionality

00:31:49,670 --> 00:31:54,350
and we are very interested to hear if

00:31:52,040 --> 00:31:57,020
somebody has some suggestions of other

00:31:54,350 --> 00:32:02,420
ways of doing it that would be very

00:31:57,020 --> 00:32:04,400
helpful so what will we do in the future

00:32:02,420 --> 00:32:06,380
we will continue to add code

00:32:04,400 --> 00:32:10,490
functionality this is a work in progress

00:32:06,380 --> 00:32:12,980
so we have working version but that

00:32:10,490 --> 00:32:15,980
version still have some bugs that we

00:32:12,980 --> 00:32:18,850
need to iron out and we will provide

00:32:15,980 --> 00:32:21,410
documentation and examples and so on and

00:32:18,850 --> 00:32:24,920
we are also considering to integrate

00:32:21,410 --> 00:32:28,160
these into the core emulator and maybe

00:32:24,920 --> 00:32:31,670
have a look if we can do something nice

00:32:28,160 --> 00:32:34,370
with l NS t as well and of course we are

00:32:31,670 --> 00:32:36,440
interested in any contribution so bug

00:32:34,370 --> 00:32:41,090
reports called patchy areas feature

00:32:36,440 --> 00:32:44,000
requests that are more than welcome so

00:32:41,090 --> 00:32:46,460
to conclude I'd like to say that we

00:32:44,000 --> 00:32:49,040
believe that deterministic emulation has

00:32:46,460 --> 00:32:51,170
an important role to fight to fill for

00:32:49,040 --> 00:32:56,060
networking researchers and protocol

00:32:51,170 --> 00:32:58,820
implementers and corona TM is one way of

00:32:56,060 --> 00:33:01,070
achieving deterministic emulation and we

00:32:58,820 --> 00:33:03,620
hope we will be able to make it easy to

00:33:01,070 --> 00:33:06,410
use and well documented for those that

00:33:03,620 --> 00:33:09,080
are interested and with that note I

00:33:06,410 --> 00:33:12,560
would like to conclude and open up for

00:33:09,080 --> 00:33:14,900
any questions you can see here my email

00:33:12,560 --> 00:33:17,120
address and the mail address of pair who

00:33:14,900 --> 00:33:20,440
dig who is my collaborator on this and

00:33:17,120 --> 00:33:24,580
in fact the person who has been

00:33:20,440 --> 00:33:27,710
implementing most of the code we have a

00:33:24,580 --> 00:33:28,909
git repo with the current state of the

00:33:27,710 --> 00:33:32,419
code and some document

00:33:28,909 --> 00:33:34,940
asian available as you can see here so

00:33:32,419 --> 00:33:37,789
with that I thank you for your attention

00:33:34,940 --> 00:34:05,960
and if there are any questions I will be

00:33:37,789 --> 00:34:11,059
happy to answer them thank you know so

00:34:05,960 --> 00:34:14,149
if you if you add traffic at a faster

00:34:11,059 --> 00:34:18,440
rate than what the computational

00:34:14,149 --> 00:34:21,770
resources allow then we cannot guarantee

00:34:18,440 --> 00:34:27,049
any determinism No so there is some

00:34:21,770 --> 00:34:30,710
performance limit and but as we view it

00:34:27,049 --> 00:34:32,569
this we we we don't think that the

00:34:30,710 --> 00:34:35,960
primary use case for deterministic

00:34:32,569 --> 00:34:41,210
emulation will be 44 extremely high

00:34:35,960 --> 00:34:43,480
speed links so hopefully it won't be a

00:34:41,210 --> 00:34:43,480

YouTube URL: https://www.youtube.com/watch?v=nt0G48lizUQ


