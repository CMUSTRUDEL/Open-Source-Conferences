Title: Netdev 0x13 - TCP Analytics Workshop
Publication date: 2019-05-20
Playlist: Netdev 0x13 - Day 1
Description: 
	Sowmini Varadhan chairs the TCP Analytics Workshop
at Netdev 0x13 with numerous speakers from many
organizations.

There are numerous cases of TCP performance challenges and
anomalies reported in production environments that are very
hard to debug, raising an interest in the answer to the
question "how to monitor TCP flows efficiently".

The workshop constituted the sharing of experience from
folks who deal with TCP Analytics Extraction at very large
TCP deployments from several organizations. Discussions
include descriptions of the instrumentation used at these
organizations, the motivation behind these diagnostics,
and ways to improve/enhance this as we go forward

More information:
https://netdevconf.org/0x13/session.html?tcp-analytics
Captions: 
	00:00:00,030 --> 00:00:07,950
so today I'm going to talk about TCP

00:00:03,210 --> 00:00:12,090
info and TCP time-stamping oh I am by no

00:00:07,950 --> 00:00:15,030
means the most knowledgeable expert Erik

00:00:12,090 --> 00:00:16,920
team as a Emil you Charlie Larry Willem

00:00:15,030 --> 00:00:25,560
have all contributed to this I'm just

00:00:16,920 --> 00:00:28,070
presenting as one of the contributors my

00:00:25,560 --> 00:00:28,070
slide is

00:00:37,850 --> 00:00:48,070
and the pointer

00:00:40,899 --> 00:00:51,070
so TCP info is probably if we exclude

00:00:48,070 --> 00:00:53,739
pcap is the most well known TCP

00:00:51,070 --> 00:00:55,809
instrumentation it basically captures

00:00:53,739 --> 00:00:59,350
TCP state and the fields we care about

00:00:55,809 --> 00:01:02,769
in TCP on the other hand we have

00:00:59,350 --> 00:01:05,770
transmit and receive timestamps that we

00:01:02,769 --> 00:01:07,600
support for TCP and there is a new

00:01:05,770 --> 00:01:10,630
addition to transmit turn stamps called

00:01:07,600 --> 00:01:12,880
up stats which is basically TCP info in

00:01:10,630 --> 00:01:17,710
timestamps and I'm gonna go walk through

00:01:12,880 --> 00:01:20,830
all of these and provide a summary so

00:01:17,710 --> 00:01:23,800
TCP info it's a softer option if you

00:01:20,830 --> 00:01:27,100
haven't used it is in TCP level so you

00:01:23,800 --> 00:01:30,340
have to get socket on solve TCP it's

00:01:27,100 --> 00:01:34,030
read-only you can't set the fields so it

00:01:30,340 --> 00:01:36,280
just gets off that's obvious but there

00:01:34,030 --> 00:01:41,350
are fields in that astruc that we have

00:01:36,280 --> 00:01:45,849
some setters for them it basically have

00:01:41,350 --> 00:01:50,130
a very simple interface there is a

00:01:45,849 --> 00:01:50,130
structured called TCP

00:01:51,030 --> 00:01:54,570
and then you just create that a

00:01:52,740 --> 00:01:59,250
structure passage oh dear no cannot fill

00:01:54,570 --> 00:02:01,800
it out and then send it to you the

00:01:59,250 --> 00:02:04,380
structure TCP info is a collection of

00:02:01,800 --> 00:02:06,260
fields for example minimum RTT delivery

00:02:04,380 --> 00:02:10,110
rate with transmissions bytes and

00:02:06,260 --> 00:02:14,160
pasting rate max facing grade and it

00:02:10,110 --> 00:02:17,550
provides a very important backward and

00:02:14,160 --> 00:02:21,210
forward property backward and forward

00:02:17,550 --> 00:02:23,070
compatibility this structure is append

00:02:21,210 --> 00:02:25,890
only when we want to change this

00:02:23,070 --> 00:02:27,930
structure add a new field we can only

00:02:25,890 --> 00:02:30,570
append to this so it's binary compatible

00:02:27,930 --> 00:02:32,880
with this previous version except for

00:02:30,570 --> 00:02:35,100
the holes in data structure so we can if

00:02:32,880 --> 00:02:38,850
we find a bit somewhere we just reuse

00:02:35,100 --> 00:02:41,250
that otherwise just dependent Lea the

00:02:38,850 --> 00:02:44,760
get socket power plant is also in and

00:02:41,250 --> 00:02:47,340
out parameters as you know so deadlines

00:02:44,760 --> 00:02:51,630
is very important on finding the version

00:02:47,340 --> 00:02:53,610
of TCP info so this slide basically

00:02:51,630 --> 00:02:56,930
explains how we do backward

00:02:53,610 --> 00:03:00,330
compatibility so let's say we have a

00:02:56,930 --> 00:03:04,080
binary compiled with an older version of

00:03:00,330 --> 00:03:06,180
TCP info running on a new kernel what

00:03:04,080 --> 00:03:07,920
kernel does is basically gets our cob to

00:03:06,180 --> 00:03:10,260
be called a routine that feels the

00:03:07,920 --> 00:03:13,530
structure for us and then we copy the

00:03:10,260 --> 00:03:15,690
bits onto the user-provided buffer so if

00:03:13,530 --> 00:03:18,660
the buffer is just one bite you get the

00:03:15,690 --> 00:03:21,600
first bite of TCP info if it is 20 bytes

00:03:18,660 --> 00:03:22,950
it's the first 20 bytes and as a result

00:03:21,600 --> 00:03:25,080
when you're compiled with an older

00:03:22,950 --> 00:03:26,310
version of TCP info you get the fields

00:03:25,080 --> 00:03:29,400
that you had in your structure in your

00:03:26,310 --> 00:03:32,370
user space binary but not all the fields

00:03:29,400 --> 00:03:33,930
that kernel provides but you still pay

00:03:32,370 --> 00:03:35,280
for the cost of memory bandwidth in the

00:03:33,930 --> 00:03:36,780
kernel because we said all those fields

00:03:35,280 --> 00:03:40,170
but if we don't just copy that in the

00:03:36,780 --> 00:03:44,280
user space if you run a new binary

00:03:40,170 --> 00:03:47,400
compile the recent recently updated TCP

00:03:44,280 --> 00:03:51,040
info running on a very old colonel

00:03:47,400 --> 00:03:52,810
colonel we'll just field the field that

00:03:51,040 --> 00:03:55,510
it knows and then the rest of those

00:03:52,810 --> 00:03:58,780
fields are on touched or uninitialized

00:03:55,510 --> 00:04:02,190
so you have to make sure you read the

00:03:58,780 --> 00:04:04,450
Len returned by get saw copped as a

00:04:02,190 --> 00:04:07,750
reference for the which version of

00:04:04,450 --> 00:04:11,590
Journal you're running on so when you're

00:04:07,750 --> 00:04:14,560
on the older colonel make sure you check

00:04:11,590 --> 00:04:20,169
the Len then would be smaller than your

00:04:14,560 --> 00:04:21,970
TCP info if it has changed and based on

00:04:20,169 --> 00:04:23,650
the offset of the fields you can see

00:04:21,970 --> 00:04:26,229
which version of the TCP info you're

00:04:23,650 --> 00:04:28,780
actually using and I'll explain why that

00:04:26,229 --> 00:04:30,639
is important later so let's take a look

00:04:28,780 --> 00:04:33,580
at the structure in the field in that

00:04:30,639 --> 00:04:37,450
structure there are some fields that

00:04:33,580 --> 00:04:39,070
represent the TCP state the first one is

00:04:37,450 --> 00:04:44,320
the connection state like if it is

00:04:39,070 --> 00:04:46,000
established and sent this is basically a

00:04:44,320 --> 00:04:48,010
byte

00:04:46,000 --> 00:04:50,889
there are you can see the options that

00:04:48,010 --> 00:04:55,930
are negotiated you can see time stamping

00:04:50,889 --> 00:04:58,900
ecn what is the like if you have

00:04:55,930 --> 00:05:02,950
receiving those scaling all of that you

00:04:58,900 --> 00:05:07,270
can see RTO and USAC you can you have

00:05:02,950 --> 00:05:09,160
three fields for maximum segment size so

00:05:07,270 --> 00:05:10,960
why do we have three fields the first

00:05:09,160 --> 00:05:12,880
one is advertised like what we advertise

00:05:10,960 --> 00:05:14,890
to the other side the next one is what

00:05:12,880 --> 00:05:17,680
we negotiated so it's like the minimum

00:05:14,890 --> 00:05:20,380
of the two sides so this is what the

00:05:17,680 --> 00:05:22,810
maximum segment size we can send on so

00:05:20,380 --> 00:05:24,580
that's a send MSS the last one is

00:05:22,810 --> 00:05:27,190
receive MSS and this is very confusing

00:05:24,580 --> 00:05:28,810
for people who haven't used it it can be

00:05:27,190 --> 00:05:30,700
a very small value because it's the

00:05:28,810 --> 00:05:33,430
maximum segment you have received on

00:05:30,700 --> 00:05:37,600
this connection so for example let's say

00:05:33,430 --> 00:05:40,479
I'm using 9 km to you but you're sending

00:05:37,600 --> 00:05:42,340
me ping-pong traffic the maximum segment

00:05:40,479 --> 00:05:44,860
I've received so far is just one byte

00:05:42,340 --> 00:05:46,840
plus a TCP IP header there receive thing

00:05:44,860 --> 00:05:48,760
is basically the maximum of whatever

00:05:46,840 --> 00:05:50,860
I've received so far

00:05:48,760 --> 00:05:52,780
and this is very important for debugging

00:05:50,860 --> 00:05:54,450
if you're using variable empty like

00:05:52,780 --> 00:05:57,280
multiple empty using your network

00:05:54,450 --> 00:05:59,320
sometimes some connections work because

00:05:57,280 --> 00:06:00,970
they don't actually use the larger MTU

00:05:59,320 --> 00:06:03,460
they're just sending one bite and you'll

00:06:00,970 --> 00:06:05,920
receive one byte but the connections are

00:06:03,460 --> 00:06:08,170
actually sending larger MTU sizes but in

00:06:05,920 --> 00:06:10,000
actually being send the packets so you

00:06:08,170 --> 00:06:11,860
can use this to as a reference to see

00:06:10,000 --> 00:06:13,450
what is the maximum segment size Eve

00:06:11,860 --> 00:06:18,400
done all of my TCP connections if you

00:06:13,450 --> 00:06:21,850
collect it on all of your machines so

00:06:18,400 --> 00:06:23,620
for transmission stats TCP has just too

00:06:21,850 --> 00:06:26,260
many retransmit

00:06:23,620 --> 00:06:28,240
fields in the TCP infrastructure the

00:06:26,260 --> 00:06:30,970
first one that is in the like the first

00:06:28,240 --> 00:06:32,700
eight fields is TCP retransmits but it's

00:06:30,970 --> 00:06:35,320
not really the resistance mission

00:06:32,700 --> 00:06:37,510
because and you can obviously see that

00:06:35,320 --> 00:06:39,760
because it's just one byte how come TCP

00:06:37,510 --> 00:06:42,220
can reach ends with up to 256 seconds

00:06:39,760 --> 00:06:45,100
right what it is is actually retries

00:06:42,220 --> 00:06:47,410
it's basically the number of time TCP

00:06:45,100 --> 00:06:50,350
has a stalled on a sequence on the first

00:06:47,410 --> 00:06:52,330
on ACK sequence so I'm RT owing I'm

00:06:50,350 --> 00:06:55,390
trying to send some time and this thing

00:06:52,330 --> 00:06:57,550
gets increased until despite is act or a

00:06:55,390 --> 00:07:00,250
closer connection so if for example

00:06:57,550 --> 00:07:03,070
there's a Cisco door TCP 3 tries to for

00:07:00,250 --> 00:07:05,080
example if you reach that after that

00:07:03,070 --> 00:07:07,300
many tree tries we just close the

00:07:05,080 --> 00:07:09,520
connection or a board to connection this

00:07:07,300 --> 00:07:11,860
is basically the counter if this counter

00:07:09,520 --> 00:07:13,310
goes above that Cisco door we close the

00:07:11,860 --> 00:07:17,389
connection

00:07:13,310 --> 00:07:19,310
the next one is TCP I re trans that is

00:07:17,389 --> 00:07:20,810
also not the retransmission this is the

00:07:19,310 --> 00:07:24,860
number of packets retransmitted in

00:07:20,810 --> 00:07:26,419
flight not they're useful for most use

00:07:24,860 --> 00:07:30,680
cases the next one which we added

00:07:26,419 --> 00:07:33,970
recently is the total retransmission by

00:07:30,680 --> 00:07:37,070
recently I mean it's about a year ago

00:07:33,970 --> 00:07:38,990
this is basically the number of data

00:07:37,070 --> 00:07:41,480
packets that are retransmitted note that

00:07:38,990 --> 00:07:43,910
TCP has acts and data packets right so

00:07:41,480 --> 00:07:45,110
some packets are just pure acts we don't

00:07:43,910 --> 00:07:48,080
have retransmission for them these are

00:07:45,110 --> 00:07:49,970
the data a transmitted there's segments

00:07:48,080 --> 00:07:52,730
out the counterpart to that is also

00:07:49,970 --> 00:07:54,470
prefixed by data sets out because it is

00:07:52,730 --> 00:07:56,660
only the data segments out this it

00:07:54,470 --> 00:08:00,400
doesn't account for acts are packets

00:07:56,660 --> 00:08:03,860
that we send out there's a de sac dupes

00:08:00,400 --> 00:08:06,800
if you're not familiar but do these acts

00:08:03,860 --> 00:08:08,720
or duplicates acts when we retransmits

00:08:06,800 --> 00:08:10,610
something and the other side have

00:08:08,720 --> 00:08:12,950
already received that sequence it would

00:08:10,610 --> 00:08:14,540
send us a deseg so that the other side

00:08:12,950 --> 00:08:15,410
knows this was a spurious

00:08:14,540 --> 00:08:17,300
retransmissions

00:08:15,410 --> 00:08:19,010
for example it has more aggressive more

00:08:17,300 --> 00:08:21,320
than needed more aggressive than needed

00:08:19,010 --> 00:08:23,360
RTO like you've transmitted something

00:08:21,320 --> 00:08:24,890
but it wasn't actually lost so we

00:08:23,360 --> 00:08:27,919
receive a de sac for that and you can

00:08:24,890 --> 00:08:29,810
use this to estimate the number of a

00:08:27,919 --> 00:08:32,510
spurious retransmissions you have had on

00:08:29,810 --> 00:08:36,070
your connection this is very good to see

00:08:32,510 --> 00:08:38,839
if you're using a very aggressive RTO or

00:08:36,070 --> 00:08:42,380
somehow your receiver is just too slow

00:08:38,839 --> 00:08:43,969
to process the packets or someone has

00:08:42,380 --> 00:08:47,570
installed a queue that's cut on the

00:08:43,969 --> 00:08:50,720
ingress path of that of that box there's

00:08:47,570 --> 00:08:54,860
also the Sexson which is the data

00:08:50,720 --> 00:08:58,100
segments received by this connection the

00:08:54,860 --> 00:09:02,089
last row are also very recent this is

00:08:58,100 --> 00:09:03,480
TCP delivered it's basically the number

00:09:02,089 --> 00:09:07,680
of

00:09:03,480 --> 00:09:08,400
like packets you have delivered to the

00:09:07,680 --> 00:09:12,630
other side

00:09:08,400 --> 00:09:15,450
it's sum of Acts and sacked packets

00:09:12,630 --> 00:09:16,560
segments up to this point and then

00:09:15,450 --> 00:09:18,780
there's delivered seee

00:09:16,560 --> 00:09:21,090
which is the packets that were delivered

00:09:18,780 --> 00:09:24,180
but had an ACN mark that the congestion

00:09:21,090 --> 00:09:26,340
event on them on the AK this way you may

00:09:24,180 --> 00:09:28,920
not have loss but if you're using DC TCP

00:09:26,340 --> 00:09:31,020
you can see what fraction of your

00:09:28,920 --> 00:09:33,380
delivered bytes or packets to the other

00:09:31,020 --> 00:09:38,600
side had an easy n mark on them so they

00:09:33,380 --> 00:09:44,370
experienced congestion these two are

00:09:38,600 --> 00:09:46,680
important recipes that come useful if

00:09:44,370 --> 00:09:48,330
you want to see the your TCP

00:09:46,680 --> 00:09:51,090
retransmission rate in person just

00:09:48,330 --> 00:09:53,610
divide the total returns by its X out

00:09:51,090 --> 00:09:58,950
those casts are not needed but I casted

00:09:53,610 --> 00:10:01,800
them just to make sure it is clear if

00:09:58,950 --> 00:10:04,620
you want to know the actual loss rate of

00:10:01,800 --> 00:10:07,500
that tcp measures for your connection

00:10:04,620 --> 00:10:09,480
you have to deduct the d sacks from the

00:10:07,500 --> 00:10:11,700
number of retransmits because those very

00:10:09,480 --> 00:10:13,920
foolishly retransmitted so it's not

00:10:11,700 --> 00:10:15,150
networks fault it's just TCP

00:10:13,920 --> 00:10:18,900
retransmitting something that he

00:10:15,150 --> 00:10:21,020
shouldn't have retransmitted does make

00:10:18,900 --> 00:10:21,020
sense

00:10:21,820 --> 00:10:24,540
okay

00:10:25,260 --> 00:10:33,580
so a huge chunk of TCP is basically

00:10:29,800 --> 00:10:35,890
congestion control the second field in

00:10:33,580 --> 00:10:38,740
the TCP info if you look at it by order

00:10:35,890 --> 00:10:43,920
it's a CA State or congestion avoidance

00:10:38,740 --> 00:10:48,430
State they're like open disorder

00:10:43,920 --> 00:10:49,390
recovery law CW are you can they have

00:10:48,430 --> 00:10:52,990
different meanings for different

00:10:49,390 --> 00:10:55,420
congestion controls so if you're using

00:10:52,990 --> 00:10:57,190
Reno and cubic it might be useful if

00:10:55,420 --> 00:10:59,800
you're using BB or you have to be very

00:10:57,190 --> 00:11:01,750
careful about like how you interpret

00:10:59,800 --> 00:11:06,670
them it's there they have different

00:11:01,750 --> 00:11:09,459
meanings one thing that is very useful

00:11:06,670 --> 00:11:11,350
to just read sometimes from your

00:11:09,459 --> 00:11:13,450
connection is just the congestion window

00:11:11,350 --> 00:11:17,529
this is the sand side condition window

00:11:13,450 --> 00:11:21,700
is not the receive window it's in terms

00:11:17,529 --> 00:11:26,290
of packets and it can go up to you 32

00:11:21,700 --> 00:11:27,940
and we have had we have had events that

00:11:26,290 --> 00:11:30,550
it actually reaches a very large number

00:11:27,940 --> 00:11:32,459
so it's very good to monitor this value

00:11:30,550 --> 00:11:38,140
to make sure your congestion control is

00:11:32,459 --> 00:11:42,730
doing the same thing a slow start

00:11:38,140 --> 00:11:45,220
threshold basically is the threshold of

00:11:42,730 --> 00:11:48,010
congestion window up to which we slow

00:11:45,220 --> 00:11:49,870
start for some condition controls for

00:11:48,010 --> 00:11:55,899
bbr it has a very different meaning for

00:11:49,870 --> 00:11:58,180
example so this field also should be you

00:11:55,899 --> 00:11:59,740
should actually use this when you're

00:11:58,180 --> 00:12:03,040
very familiar with a congestion control

00:11:59,740 --> 00:12:04,810
you're using otherwise it can be

00:12:03,040 --> 00:12:06,520
misleading for example a slow start

00:12:04,810 --> 00:12:12,140
threshold of Reno is very different than

00:12:06,520 --> 00:12:15,350
what you get from PBR TCP pacing rate

00:12:12,140 --> 00:12:18,230
I have a typo on my slide sorry so the

00:12:15,350 --> 00:12:20,560
other one is TCP max spacing great so

00:12:18,230 --> 00:12:24,500
TCP has a pacing rate of this connection

00:12:20,560 --> 00:12:27,230
it is bytes per second not bits per

00:12:24,500 --> 00:12:31,520
second so all these times 8 if you want

00:12:27,230 --> 00:12:33,770
to see the bits per second rate and

00:12:31,520 --> 00:12:36,680
there's a max pacing rate for the

00:12:33,770 --> 00:12:39,290
connection which TCP would never go

00:12:36,680 --> 00:12:41,570
above this rate so if you set the so max

00:12:39,290 --> 00:12:45,140
pacing rate soccer option you can

00:12:41,570 --> 00:12:48,440
basically cap the the max pacing rates

00:12:45,140 --> 00:12:50,750
of your connection that also is in bytes

00:12:48,440 --> 00:12:53,840
per second and that is a source of

00:12:50,750 --> 00:13:02,060
errors if you're not familiar with a

00:12:53,840 --> 00:13:05,930
units delivery rate is basically from

00:13:02,060 --> 00:13:08,770
the building block of TCP bbr so

00:13:05,930 --> 00:13:11,510
bottleneck bandwidth the first part is

00:13:08,770 --> 00:13:14,270
basically max filtering that they leave

00:13:11,510 --> 00:13:16,190
a rate of the connection this delivery

00:13:14,270 --> 00:13:20,600
rate comes from that source basically

00:13:16,190 --> 00:13:23,660
TCP is measuring the bytes delivered to

00:13:20,600 --> 00:13:29,180
the other side in bytes per second using

00:13:23,660 --> 00:13:31,730
ax and sax it's just an estimate and it

00:13:29,180 --> 00:13:33,080
is available for you to read on TCP info

00:13:31,730 --> 00:13:35,720
it's basically the goodput of your

00:13:33,080 --> 00:13:38,630
connection however there is a catch to

00:13:35,720 --> 00:13:41,180
this field let's say I have a connection

00:13:38,630 --> 00:13:44,240
a TCP connection and a 100 Gig link I

00:13:41,180 --> 00:13:46,250
send one byte for a second the

00:13:44,240 --> 00:13:48,580
throughput of the TCP connection cannot

00:13:46,250 --> 00:13:50,830
be higher than one byte per second

00:13:48,580 --> 00:13:52,360
because TCP doesn't generate bytes it's

00:13:50,830 --> 00:13:54,790
the application that is generating the

00:13:52,360 --> 00:13:57,459
bytes so the good put of TCP can never

00:13:54,790 --> 00:14:00,970
go higher than that right or one byte

00:13:57,459 --> 00:14:02,920
divided by RT T sorry so if you are TT

00:14:00,970 --> 00:14:04,330
is 100 millisecond is one byte divided

00:14:02,920 --> 00:14:06,190
about 100 second but you could actually

00:14:04,330 --> 00:14:08,740
reach 100 gigabits per second you

00:14:06,190 --> 00:14:12,730
actually don't know that we have a bit

00:14:08,740 --> 00:14:15,490
in TCP that estimates if TCP could send

00:14:12,730 --> 00:14:18,310
something but it was limited by the

00:14:15,490 --> 00:14:22,450
application backlog so if for example my

00:14:18,310 --> 00:14:25,089
I could send another TSO chunk but I

00:14:22,450 --> 00:14:28,810
didn't have any data to send I set this

00:14:25,089 --> 00:14:32,200
bit and we call that app limited so when

00:14:28,810 --> 00:14:33,730
this bit is set next to deliberate you

00:14:32,200 --> 00:14:35,500
shouldn't really use that delivery you

00:14:33,730 --> 00:14:40,720
can't rely on this delivery this is just

00:14:35,500 --> 00:14:44,110
a guesstimate of TCP 3-way right when

00:14:40,720 --> 00:14:46,390
you chung added tcp rate up limited to

00:14:44,110 --> 00:14:50,649
TCP info I think two years there was two

00:14:46,390 --> 00:14:54,190
years ago we use the hole in TCP info so

00:14:50,649 --> 00:14:55,930
it's in the top of the structure but if

00:14:54,190 --> 00:14:57,790
you're using an old kernel that doesn't

00:14:55,930 --> 00:15:01,990
support this feature that bit is not set

00:14:57,790 --> 00:15:03,550
or is basically zero so make sure you

00:15:01,990 --> 00:15:05,860
check the versioning because this is a

00:15:03,550 --> 00:15:10,390
whole its notice it's not a pendant it's

00:15:05,860 --> 00:15:13,180
inserted in this structure tcp tcp also

00:15:10,390 --> 00:15:16,240
has like - Artie T's currently in the

00:15:13,180 --> 00:15:19,149
structure one is smooth RT t it's in

00:15:16,240 --> 00:15:23,680
usage the smooth RT t is the weighted

00:15:19,149 --> 00:15:24,970
average of RTD samples again it can be

00:15:23,680 --> 00:15:28,029
very very misleading

00:15:24,970 --> 00:15:31,360
why because TCP delays acknowledgments

00:15:28,029 --> 00:15:33,160
if you are on a ping pong traffic you're

00:15:31,360 --> 00:15:36,730
always getting delayed acknowledgments

00:15:33,160 --> 00:15:39,760
and your SR TT can be bloated so this is

00:15:36,730 --> 00:15:41,829
usually the upper bound and those upper

00:15:39,760 --> 00:15:43,720
bound of RT t under connection you can

00:15:41,829 --> 00:15:46,000
also see the RTT variance for that is

00:15:43,720 --> 00:15:48,370
used for calculating smooth RT t as per

00:15:46,000 --> 00:15:49,520
RFC there is another field in the

00:15:48,370 --> 00:15:54,290
structure that

00:15:49,520 --> 00:15:58,760
added after PBR which is mean RTT this

00:15:54,290 --> 00:16:01,640
is the main filtered RTT sample it is

00:15:58,760 --> 00:16:04,940
not the minimum RTG used by PBR it is

00:16:01,640 --> 00:16:06,650
RTT samples using another mean filter

00:16:04,940 --> 00:16:08,990
the length of the main filter is

00:16:06,650 --> 00:16:11,860
controlled by sis coddled by default is

00:16:08,990 --> 00:16:15,260
set to 5 minutes so if you want more

00:16:11,860 --> 00:16:17,720
recent article you your TCP info you

00:16:15,260 --> 00:16:21,290
have to change that sis coddle to use a

00:16:17,720 --> 00:16:23,660
shorter window VBR has its own min

00:16:21,290 --> 00:16:26,840
filter length it's very different than

00:16:23,660 --> 00:16:31,340
what we have what we provide in TCP info

00:16:26,840 --> 00:16:36,590
but overall this is a very useful field

00:16:31,340 --> 00:16:39,530
to have a lower bound of your RTT after

00:16:36,590 --> 00:16:42,980
Eric changed the model to EDT like

00:16:39,530 --> 00:16:46,340
earlier departure time presented by van

00:16:42,980 --> 00:16:49,220
in last night of this min RTT can have a

00:16:46,340 --> 00:16:52,640
slightly different measurement as before

00:16:49,220 --> 00:16:56,270
that it could be it would include cutest

00:16:52,640 --> 00:16:59,000
delays after that it sometimes doesn't

00:16:56,270 --> 00:17:03,170
have the cutest delay so it it depends

00:16:59,000 --> 00:17:05,780
on the cutest you use I think but make

00:17:03,170 --> 00:17:08,839
sure like depending on the version of

00:17:05,780 --> 00:17:11,990
the kernel this value can include some

00:17:08,839 --> 00:17:17,930
overheads and a new version it would

00:17:11,990 --> 00:17:19,790
just exclude them so their Kronos I've

00:17:17,930 --> 00:17:22,760
been asked to explain the same more

00:17:19,790 --> 00:17:26,000
details because we added this to kernel

00:17:22,760 --> 00:17:27,730
it was a one of our interns out of this

00:17:26,000 --> 00:17:31,500
[Music]

00:17:27,730 --> 00:17:36,090
this is basically two

00:17:31,500 --> 00:17:38,789
measure how long tcp was in a particular

00:17:36,090 --> 00:17:41,970
state and it was very useful for us

00:17:38,789 --> 00:17:44,549
because people can open TCP connections

00:17:41,970 --> 00:17:47,039
don't use them for a for a long time or

00:17:44,549 --> 00:17:49,590
for some weird reason TCP couldn't

00:17:47,039 --> 00:17:52,169
actually send anything so we wanted to

00:17:49,590 --> 00:17:55,309
create a chronal that basically captures

00:17:52,169 --> 00:17:58,019
the time TCP spending doing something

00:17:55,309 --> 00:18:02,730
the first time is busy busy time

00:17:58,019 --> 00:18:04,620
it's the interval that TCP was busy

00:18:02,730 --> 00:18:08,370
sending something

00:18:04,620 --> 00:18:11,130
it wasn't limited by anything but when

00:18:08,370 --> 00:18:13,110
we hit the receipt window we stopped the

00:18:11,130 --> 00:18:16,860
crowd a busy time colonel if he were

00:18:13,110 --> 00:18:19,110
sending and we start Arvind our wnd

00:18:16,860 --> 00:18:21,360
limited or Arvind limited Crona

00:18:19,110 --> 00:18:23,700
basically I am from this point on I'm

00:18:21,360 --> 00:18:26,730
limited for the other side to open is

00:18:23,700 --> 00:18:29,610
receiving the for me so it goes until

00:18:26,730 --> 00:18:31,950
the receiving the opens up if I exit

00:18:29,610 --> 00:18:34,710
this point now I'm busy sending so the

00:18:31,950 --> 00:18:38,850
busy cron will start to be yes it starts

00:18:34,710 --> 00:18:41,820
to get incremented and then the Arvind

00:18:38,850 --> 00:18:45,139
limited stops sent off limited is when

00:18:41,820 --> 00:18:48,659
the user was in send message context and

00:18:45,139 --> 00:18:51,769
it had more payload to son but sandbox

00:18:48,659 --> 00:18:55,049
wasn't open so we start the Chronos a

00:18:51,769 --> 00:18:58,289
user actually could send something but

00:18:55,049 --> 00:19:00,480
we are basically in limited by sin Buffy

00:18:58,289 --> 00:19:02,639
couldn't accept their the bytes that

00:19:00,480 --> 00:19:04,470
wanted to send so this is another

00:19:02,639 --> 00:19:08,010
Khurana and these are prioritized when

00:19:04,470 --> 00:19:09,450
we are in send off limited we are not if

00:19:08,010 --> 00:19:11,370
you are receiving the limited I think

00:19:09,450 --> 00:19:14,539
means read that one first then send off

00:19:11,370 --> 00:19:14,539
and then busy type so

00:19:16,909 --> 00:19:21,259
questions we can do it now

00:19:22,249 --> 00:19:26,629
sure you can do interactive

00:19:33,070 --> 00:19:39,550
a very good clarification question the

00:19:37,270 --> 00:19:42,220
previous slide you had delivery date and

00:19:39,550 --> 00:19:46,270
application limited now presumably app

00:19:42,220 --> 00:19:48,970
limited is is constantly changing so

00:19:46,270 --> 00:19:51,400
it's delivery rate an instantaneous

00:19:48,970 --> 00:19:53,260
value and up limited in deliveries are

00:19:51,400 --> 00:19:57,430
they both instantaneous values that's a

00:19:53,260 --> 00:20:00,120
very good question and it's actually the

00:19:57,430 --> 00:20:05,140
source of confusion when using TCP info

00:20:00,120 --> 00:20:08,160
then you call TCP info we look into the

00:20:05,140 --> 00:20:10,210
socket if the last delivery rate sample

00:20:08,160 --> 00:20:12,400
was enough limited it's the

00:20:10,210 --> 00:20:14,290
instantaneous delivery if it is a

00:20:12,400 --> 00:20:17,650
Plymouth it is the last non-apple

00:20:14,290 --> 00:20:20,020
imitating hate on that socket so what

00:20:17,650 --> 00:20:24,130
that or or the last delivery sample so

00:20:20,020 --> 00:20:25,660
the idea is our last accurate estimate

00:20:24,130 --> 00:20:27,280
on this connection is when we burned

00:20:25,660 --> 00:20:29,320
half a minute so let's give that to the

00:20:27,280 --> 00:20:30,610
user and also tell them that I am up

00:20:29,320 --> 00:20:34,530
limited I can't tell you the actual

00:20:30,610 --> 00:20:37,360
ascent I see so the app limited flag is

00:20:34,530 --> 00:20:38,740
not something that I should check to see

00:20:37,360 --> 00:20:40,570
if the delivery date is valid or not

00:20:38,740 --> 00:20:42,640
because the delivery date will always be

00:20:40,570 --> 00:20:44,710
valid but it might be very stale it

00:20:42,640 --> 00:20:47,260
might be old here you very slow starting

00:20:44,710 --> 00:20:50,980
it might be very actually very smaller

00:20:47,260 --> 00:20:52,450
attending your current boy even even if

00:20:50,980 --> 00:20:53,470
it's up limited yes I see understood

00:20:52,450 --> 00:20:55,000
understood

00:20:53,470 --> 00:20:57,850
okay thank you for example the send off

00:20:55,000 --> 00:21:00,280
can be 10 Meg yeah I have 1 Meg I'm

00:20:57,850 --> 00:21:01,090
absolutely but still a lot of data yeah

00:21:00,280 --> 00:21:03,280
that makes sense

00:21:01,090 --> 00:21:09,400
Thanks sure

00:21:03,280 --> 00:21:12,100
I had a couple of questions about the CA

00:21:09,400 --> 00:21:13,510
state is there any documentation on what

00:21:12,100 --> 00:21:14,860
these states mean because I was trying

00:21:13,510 --> 00:21:16,300
to figure it out and you read the code

00:21:14,860 --> 00:21:19,230
and it's not necessary you might be

00:21:16,300 --> 00:21:19,230
misunderstanding the code

00:21:21,669 --> 00:21:27,009
there's like disorder last recovery star

00:21:24,450 --> 00:21:28,389
CCL does it mean does almost the same

00:21:27,009 --> 00:21:31,329
thing it would be good if there was

00:21:28,389 --> 00:21:34,139
documented somewhere so at least in a

00:21:31,329 --> 00:21:34,139
comment in the core or something

00:21:35,540 --> 00:21:40,100
okay

00:21:37,790 --> 00:21:41,450
Yeah right so so so the reason I was

00:21:40,100 --> 00:21:44,120
looking at this is trying to figure out

00:21:41,450 --> 00:21:46,940
when last recovery starts and when it

00:21:44,120 --> 00:21:48,320
ends and even if you Paul it's you it's

00:21:46,940 --> 00:22:00,950
easy to misinterpret it's not these

00:21:48,320 --> 00:22:05,860
states and please speak in the mic so we

00:22:00,950 --> 00:22:05,860
can Eric we leave the mic there with you

00:22:15,400 --> 00:22:22,130
so these are the TCP kernels

00:22:18,890 --> 00:22:26,240
note that these are cumulative counters

00:22:22,130 --> 00:22:28,670
so if you get it at time T the Delta at

00:22:26,240 --> 00:22:32,570
time t2 has to be calculated based on

00:22:28,670 --> 00:22:35,870
cumulative values there's another cache

00:22:32,570 --> 00:22:38,470
here these are in USAC units we actually

00:22:35,870 --> 00:22:43,160
sent the RFC patch with you sec

00:22:38,470 --> 00:22:46,580
resolution but we need a 64 3 64 bits

00:22:43,160 --> 00:22:48,380
the feedback was make them 32 bits store

00:22:46,580 --> 00:22:50,150
them in in milliseconds so the

00:22:48,380 --> 00:22:51,800
resolution is actually milliseconds but

00:22:50,150 --> 00:22:54,710
because we wanted to make sure the AP

00:22:51,800 --> 00:22:56,450
later if we decided you use use ik the

00:22:54,710 --> 00:22:58,520
API doesn't have because we can't really

00:22:56,450 --> 00:23:01,130
change the definitions on if it isn't

00:22:58,520 --> 00:23:03,410
easy info it's just done so they are

00:23:01,130 --> 00:23:07,130
exported as you said but the resolution

00:23:03,410 --> 00:23:10,420
of the actual kernel in implementation

00:23:07,130 --> 00:23:14,000
currently is milliseconds is a jiffy

00:23:10,420 --> 00:23:17,139
yes sorry yeah she said you

00:23:14,000 --> 00:23:17,139
is 32 bits

00:23:17,590 --> 00:23:26,470
so caveats we cannot remove fields from

00:23:23,680 --> 00:23:29,710
TCP in for y because fields and TCP info

00:23:26,470 --> 00:23:32,410
is part of the public API if I remove a

00:23:29,710 --> 00:23:34,870
field and a user space program access

00:23:32,410 --> 00:23:38,140
that I feel that field that that program

00:23:34,870 --> 00:23:40,540
wouldn't compile so we can't really

00:23:38,140 --> 00:23:42,610
remove any field so there are deprecated

00:23:40,540 --> 00:23:45,130
fields in that structure that are not

00:23:42,610 --> 00:23:48,670
set on newer kernel but they are just

00:23:45,130 --> 00:23:51,670
there so you can always agree zero a

00:23:48,670 --> 00:23:54,580
most notable example was TCP packet then

00:23:51,670 --> 00:23:57,570
we replaced back with rack and just

00:23:54,580 --> 00:24:01,870
remove back every forward acknowledgment

00:23:57,570 --> 00:24:04,300
from TCP of you just don't send packets

00:24:01,870 --> 00:24:07,420
but it's still there and we always have

00:24:04,300 --> 00:24:13,570
to copy so this is one caveat you always

00:24:07,420 --> 00:24:17,320
pay for the memory bandwidth of the of

00:24:13,570 --> 00:24:20,860
setting these vehicles TCP info don't

00:24:17,320 --> 00:24:22,630
try to get it every nanosecond or every

00:24:20,860 --> 00:24:25,930
microseconds on your machine it has a

00:24:22,630 --> 00:24:28,480
very very high overhead especially if

00:24:25,930 --> 00:24:30,280
you are in a high performance NIC the

00:24:28,480 --> 00:24:33,310
reason is that we have to grab the

00:24:30,280 --> 00:24:36,220
socket lock it didn't have to used to do

00:24:33,310 --> 00:24:39,550
this currently except for listening

00:24:36,220 --> 00:24:41,440
sockets we grab the log Eric did that

00:24:39,550 --> 00:24:43,870
because there was a very important catch

00:24:41,440 --> 00:24:46,510
here we were updating retransmission

00:24:43,870 --> 00:24:49,390
after the byte sent user always assumed

00:24:46,510 --> 00:24:51,460
the number of packets through send is

00:24:49,390 --> 00:24:54,700
always larger than retransmission but we

00:24:51,460 --> 00:24:56,830
were reading the field after packets and

00:24:54,700 --> 00:24:58,450
and usually were complaining oh why is

00:24:56,830 --> 00:25:00,370
it larger and it was actually very

00:24:58,450 --> 00:25:03,630
dangerous because they were these are

00:25:00,370 --> 00:25:05,530
unsigned fields the Delta overflows

00:25:03,630 --> 00:25:07,720
ridiculously large numbers that that

00:25:05,530 --> 00:25:11,140
doesn't make sense so we grabbed a lock

00:25:07,720 --> 00:25:13,030
we unlock it don't try to use this like

00:25:11,140 --> 00:25:15,270
every send message or every receive

00:25:13,030 --> 00:25:19,000
message is just costing

00:25:15,270 --> 00:25:20,920
and the other overheard the TCP for

00:25:19,000 --> 00:25:23,200
house it's just a large block of memory

00:25:20,920 --> 00:25:26,860
sometimes you just need the minimum RCT

00:25:23,200 --> 00:25:29,860
but you have to read a lot of data from

00:25:26,860 --> 00:25:32,080
the kernel as I said there are two set

00:25:29,860 --> 00:25:34,480
writes here one for the kernel to fill

00:25:32,080 --> 00:25:38,230
in the TCP info fields and one for us to

00:25:34,480 --> 00:25:41,680
copy to user space so it's a very memory

00:25:38,230 --> 00:25:46,120
bandwidth intensive call for a socket

00:25:41,680 --> 00:25:48,220
option not for i/o and it doesn't really

00:25:46,120 --> 00:25:49,600
include everything for example if you

00:25:48,220 --> 00:25:52,090
want to know the condition control of

00:25:49,600 --> 00:25:54,940
your tcp you should use the TCP

00:25:52,090 --> 00:25:57,130
congestion server option if you want to

00:25:54,940 --> 00:25:59,920
know the parameters of your condition

00:25:57,130 --> 00:26:02,740
control algorithm should use CC info or

00:25:59,920 --> 00:26:06,580
congestion control info which has the

00:26:02,740 --> 00:26:11,680
netlink attribute of the parameters say

00:26:06,580 --> 00:26:15,970
for PBR or for cubic if you want to know

00:26:11,680 --> 00:26:18,730
the right man read ma'am Oh ma'am the

00:26:15,970 --> 00:26:22,740
maximum value you should use many info

00:26:18,730 --> 00:26:22,740
these are not available in TCP info

00:26:23,880 --> 00:26:29,740
there were other fields in the structure

00:26:26,350 --> 00:26:32,740
I think I am already almost out of time

00:26:29,740 --> 00:26:34,830
so I didn't go through all of them but

00:26:32,740 --> 00:26:39,730
if you had any query

00:26:34,830 --> 00:26:42,160
discuss to create a man entry for TCP

00:26:39,730 --> 00:26:44,320
info after this all time there is

00:26:42,160 --> 00:26:47,020
basically no documentation not in the

00:26:44,320 --> 00:26:48,310
source code nor advantage so we are

00:26:47,020 --> 00:26:51,430
hopefully going to document all the

00:26:48,310 --> 00:26:54,100
fields now the next thing that I want to

00:26:51,430 --> 00:26:57,970
cover is TCP so time stamping I should

00:26:54,100 --> 00:27:01,210
acknowledge that william de Bruijn is

00:26:57,970 --> 00:27:03,970
the person who added different is the

00:27:01,210 --> 00:27:05,920
person who added the so times and

00:27:03,970 --> 00:27:11,620
support to TCP so what I'm presenting

00:27:05,920 --> 00:27:17,260
here is mostly his contributions so time

00:27:11,620 --> 00:27:20,110
stamping for TCP provides three main a

00:27:17,260 --> 00:27:24,310
fourth main timestamps for you one is

00:27:20,110 --> 00:27:26,170
called a scheduled basically when your

00:27:24,310 --> 00:27:29,400
hack had entered cutest yes I think in

00:27:26,170 --> 00:27:33,100
def QX met so drip you could get a

00:27:29,400 --> 00:27:35,710
schedule timestamp there then you have

00:27:33,100 --> 00:27:38,050
the transmitted timestamp hardware or

00:27:35,710 --> 00:27:40,690
software on older kernel these are

00:27:38,050 --> 00:27:43,270
mutually exclusive a new kernel

00:27:40,690 --> 00:27:44,830
I think then a new feature was added so

00:27:43,270 --> 00:27:47,700
that you can get both hardware and

00:27:44,830 --> 00:27:50,110
software timestamp for transmit

00:27:47,700 --> 00:27:52,539
retransmission of a packet

00:27:50,110 --> 00:27:54,610
on the receive side you can get the

00:27:52,539 --> 00:27:56,919
received timestamp for hardware or

00:27:54,610 --> 00:27:59,529
software I think they're still mutually

00:27:56,919 --> 00:28:04,450
exclusive but I'm not sure I have to

00:27:59,529 --> 00:28:06,279
check this one and the last time stamp

00:28:04,450 --> 00:28:09,429
is the acknowledged timestamp when the

00:28:06,279 --> 00:28:14,580
acknowledgment for a byte was received

00:28:09,429 --> 00:28:20,860
by the sender each of these timestamp

00:28:14,580 --> 00:28:22,809
after I think 4.10 have up stats

00:28:20,860 --> 00:28:25,330
attached to them why do we have this

00:28:22,809 --> 00:28:28,389
let's say you receive a scheduled time

00:28:25,330 --> 00:28:31,500
stamp from the kernel this when you read

00:28:28,389 --> 00:28:34,870
it when you user space reads this from

00:28:31,500 --> 00:28:38,950
the socket it might be minutes or

00:28:34,870 --> 00:28:40,840
seconds a long period after the time has

00:28:38,950 --> 00:28:43,059
happened because your users a thread can

00:28:40,840 --> 00:28:46,510
get this schedule it just may not get

00:28:43,059 --> 00:28:50,110
scheduled to run and at that time if you

00:28:46,510 --> 00:28:53,889
call TCP info to see why TCP is not

00:28:50,110 --> 00:28:56,409
sending fast enough your TCP info is not

00:28:53,889 --> 00:28:59,200
for the time that you have actually sent

00:28:56,409 --> 00:29:01,990
the packet right you want the state of

00:28:59,200 --> 00:29:03,669
TCP at the time an event has occurred

00:29:01,990 --> 00:29:04,870
not at the time you're reading that

00:29:03,669 --> 00:29:06,899
event or seeing that event because

00:29:04,870 --> 00:29:12,519
you're just too slow

00:29:06,899 --> 00:29:14,880
no offense the users days so up stats

00:29:12,519 --> 00:29:17,250
are basically TCP info

00:29:14,880 --> 00:29:19,559
attached to your time stamps you enable

00:29:17,250 --> 00:29:21,779
that and then on your time stamp you get

00:29:19,559 --> 00:29:25,320
your condition window RTT that will rate

00:29:21,779 --> 00:29:27,210
loss rate whites and all the Kronos

00:29:25,320 --> 00:29:29,519
actually we added this first the first

00:29:27,210 --> 00:29:31,019
version only had the Kronos because

00:29:29,519 --> 00:29:34,110
those we using those pronouns you can

00:29:31,019 --> 00:29:37,289
you can reason a lot about the lifetime

00:29:34,110 --> 00:29:39,710
of your of the packet in TCP and then we

00:29:37,289 --> 00:29:42,450
gradually added everything we are in

00:29:39,710 --> 00:29:44,100
lessons learned based on the rigid

00:29:42,450 --> 00:29:46,259
structure of TCP info these are all

00:29:44,100 --> 00:29:51,809
nothing attributes are harder to read

00:29:46,259 --> 00:29:53,970
but it gives us the opportunity can

00:29:51,809 --> 00:29:59,730
deprecated them so it's much easier for

00:29:53,970 --> 00:30:01,860
us to maintain there are there there's a

00:29:59,730 --> 00:30:04,259
main there is a major difference between

00:30:01,860 --> 00:30:06,169
receive and some time stamps overall

00:30:04,259 --> 00:30:10,850
between anything you do in send and

00:30:06,169 --> 00:30:13,710
receive or have this inherent difference

00:30:10,850 --> 00:30:15,210
when you're receiving a packet and

00:30:13,710 --> 00:30:16,009
received message I'm reading something

00:30:15,210 --> 00:30:18,179
from the socket

00:30:16,009 --> 00:30:20,220
everything here now wants to do with

00:30:18,179 --> 00:30:22,139
that packet is already done it knows the

00:30:20,220 --> 00:30:24,019
time stamps it knows when it is receive

00:30:22,139 --> 00:30:27,299
you know how many bytes there are

00:30:24,019 --> 00:30:29,820
whatever it's just there so it gives you

00:30:27,299 --> 00:30:32,250
those time stamps wires see message in

00:30:29,820 --> 00:30:34,710
your receive message on transmit it's

00:30:32,250 --> 00:30:36,480
much more different you send the packet

00:30:34,710 --> 00:30:39,659
tcp may decide to send a ten minute

00:30:36,480 --> 00:30:41,429
later so you cannot have a c message

00:30:39,659 --> 00:30:43,830
piggyback it to their user space you

00:30:41,429 --> 00:30:46,100
have to have an asynchronous mechanism

00:30:43,830 --> 00:30:49,799
to send these time stamps to user space

00:30:46,100 --> 00:30:51,980
that's where error cue comes in play so

00:30:49,799 --> 00:30:55,860
in

00:30:51,980 --> 00:30:58,140
in Linux there is the actual queue like

00:30:55,860 --> 00:31:01,170
your data queue and there is error queue

00:30:58,140 --> 00:31:03,600
which was used to receive the ICMP

00:31:01,170 --> 00:31:05,520
errors of that on that connection this

00:31:03,600 --> 00:31:08,160
is how trace route is implemented so

00:31:05,520 --> 00:31:11,790
you've read your ICMP packets whenever

00:31:08,160 --> 00:31:14,160
they are received on this side we use

00:31:11,790 --> 00:31:16,410
the same error queue as a control

00:31:14,160 --> 00:31:18,210
channel now so zero copy transmit time

00:31:16,410 --> 00:31:20,310
stamping everything anything that is

00:31:18,210 --> 00:31:24,590
asynchronous to be asynchronously sent

00:31:20,310 --> 00:31:24,590
to the user space is sent by a a polar

00:31:26,720 --> 00:31:33,630
this is one example I'm running out of

00:31:29,160 --> 00:31:38,220
time okay so this is one example let's

00:31:33,630 --> 00:31:40,170
say you receive and you call your send

00:31:38,220 --> 00:31:42,450
message and some time twenty nine

00:31:40,170 --> 00:31:46,230
microseconds after this TCP sends it out

00:31:42,450 --> 00:31:49,590
to the cutest so packet is there and it

00:31:46,230 --> 00:31:51,210
takes about 11 milliseconds to send this

00:31:49,590 --> 00:31:53,490
packet this is from production traffic

00:31:51,210 --> 00:31:56,790
it actually sends the packet out after

00:31:53,490 --> 00:31:59,580
11 milliseconds why that happens it

00:31:56,790 --> 00:32:01,650
basically means something throttle your

00:31:59,580 --> 00:32:03,990
packet I installed an HTTP on my machine

00:32:01,650 --> 00:32:05,550
to generate these timestamps so you're

00:32:03,990 --> 00:32:08,580
just looking at these numbers you can

00:32:05,550 --> 00:32:10,590
say the main bottleneck is between enter

00:32:08,580 --> 00:32:13,800
and cutest scanned giving it to the

00:32:10,590 --> 00:32:16,230
driver the device in the driver so I'm

00:32:13,800 --> 00:32:17,929
basically spending most of my time

00:32:16,230 --> 00:32:20,849
inside the cutest

00:32:17,929 --> 00:32:22,529
there are many more examples I have

00:32:20,849 --> 00:32:23,820
another talk that goes into the detail

00:32:22,529 --> 00:32:27,659
of like how to interpret these

00:32:23,820 --> 00:32:30,929
timestamps and more examples on from

00:32:27,659 --> 00:32:32,549
production and as you can see you always

00:32:30,929 --> 00:32:34,169
receive the OP stats next to each

00:32:32,549 --> 00:32:37,229
timestamp so you can for example see the

00:32:34,169 --> 00:32:39,959
RTT of the network is about 110

00:32:37,229 --> 00:32:43,499
microseconds so this 11 milliseconds is

00:32:39,959 --> 00:32:46,519
like two orders of magnitude longer

00:32:43,499 --> 00:32:49,139
delay than the actual physical network

00:32:46,519 --> 00:32:50,909
so caveats

00:32:49,139 --> 00:32:53,809
current timestamps have their own

00:32:50,909 --> 00:32:56,669
overhead if you enable it on 100% of

00:32:53,809 --> 00:32:59,369
packets I've done this it's 20%

00:32:56,669 --> 00:33:03,989
regression on high-speed network give or

00:32:59,369 --> 00:33:10,950
take if you want to use it in production

00:33:03,989 --> 00:33:13,739
make sure you use C messages to have

00:33:10,950 --> 00:33:16,529
accurate sample like I just sample a few

00:33:13,739 --> 00:33:19,309
of your send messages and then come up

00:33:16,529 --> 00:33:21,749
with the proper sampling rate

00:33:19,309 --> 00:33:26,849
empirically just deploy it and then try

00:33:21,749 --> 00:33:28,190
to see for your workload which sampling

00:33:26,849 --> 00:33:32,339
rate makes sense

00:33:28,190 --> 00:33:36,169
prior to 4.10 you basically shouldn't

00:33:32,339 --> 00:33:39,690
use time stamps it pauses your i/o

00:33:36,169 --> 00:33:42,029
whenever we ank you something ICMP on an

00:33:39,690 --> 00:33:44,639
error queue we set the sk error of the

00:33:42,029 --> 00:33:47,190
socket for timestamps when we include

00:33:44,639 --> 00:33:49,440
them we wouldn't say set sk error but

00:33:47,190 --> 00:33:51,029
when we DQ'd them we would set the SK

00:33:49,440 --> 00:33:54,690
error to the next time stamp on that

00:33:51,029 --> 00:33:56,249
sock and Venice Kerry says TCP send

00:33:54,690 --> 00:33:57,520
message and received message will return

00:33:56,249 --> 00:33:59,860
with an error

00:33:57,520 --> 00:34:02,080
and if you know the error number you can

00:33:59,860 --> 00:34:06,910
handle that but it basically pauses your

00:34:02,080 --> 00:34:10,659
i/o so make sure you have this the

00:34:06,910 --> 00:34:12,399
you're using it after for 4.10 it was

00:34:10,659 --> 00:34:14,740
the smallest path to be sent up a stream

00:34:12,399 --> 00:34:17,530
was removing one line it broke

00:34:14,740 --> 00:34:19,750
traceroute and pink the day after so it

00:34:17,530 --> 00:34:23,590
wasn't easy to do and then we did a lot

00:34:19,750 --> 00:34:25,750
of workarounds with Erics old and so

00:34:23,590 --> 00:34:28,600
there's no bug reported as far as I know

00:34:25,750 --> 00:34:30,940
and it's very stable to use now with

00:34:28,600 --> 00:34:33,130
pretty good performance you're where are

00:34:30,940 --> 00:34:36,130
you aren't going to be paused this is

00:34:33,130 --> 00:34:39,820
exactly the same reason in 0 'clock tcp

00:34:36,130 --> 00:34:42,610
0 copy bilham used an error code of 0 so

00:34:39,820 --> 00:34:47,159
before this patch 0 would be set on a

00:34:42,610 --> 00:34:47,159
scare so that your audio is not paused

00:34:47,550 --> 00:34:54,070
so these two mechanisms are both very

00:34:51,909 --> 00:34:57,460
useful with up stats you basically have

00:34:54,070 --> 00:34:59,020
to see them fall in time stamping if you

00:34:57,460 --> 00:35:02,170
want to have a summarized view of your

00:34:59,020 --> 00:35:06,130
TCP state TCP info is great it's very

00:35:02,170 --> 00:35:07,810
easy to use it's just once - Skaal tcp

00:35:06,130 --> 00:35:10,450
times something is much more difficult

00:35:07,810 --> 00:35:13,450
each you have to handle errors read Erik

00:35:10,450 --> 00:35:15,790
you understand timestamps but they

00:35:13,450 --> 00:35:18,160
provide more functionalities especially

00:35:15,790 --> 00:35:20,740
if you want to debug application

00:35:18,160 --> 00:35:24,700
performance like why this I should eb-2

00:35:20,740 --> 00:35:28,600
frame was delivered out at this time why

00:35:24,700 --> 00:35:30,490
this particular G RPC RPC is slow for

00:35:28,600 --> 00:35:31,990
those you really need to know the

00:35:30,490 --> 00:35:34,180
timestamp you can't just look at TC

00:35:31,990 --> 00:35:37,510
people say oh I see this pack

00:35:34,180 --> 00:35:40,270
there was a retransmission during when I

00:35:37,510 --> 00:35:43,470
was sending this RPC unless you're Eric

00:35:40,270 --> 00:35:47,470
he looks at TCP info and debugs RPC

00:35:43,470 --> 00:35:48,460
so moving forward these two things are

00:35:47,470 --> 00:35:50,470
both very rigid

00:35:48,460 --> 00:35:52,060
they're like timestamps are a limited

00:35:50,470 --> 00:35:55,210
set of events

00:35:52,060 --> 00:35:57,520
and you can't really customize it there

00:35:55,210 --> 00:35:59,440
should be a new journal version for the

00:35:57,520 --> 00:36:01,510
like if you should we go to net nax if

00:35:59,440 --> 00:36:05,080
you want to introduce a new time stamp

00:36:01,510 --> 00:36:07,840
bank it's it's very rigid and you can't

00:36:05,080 --> 00:36:12,670
easily customize that ebps

00:36:07,840 --> 00:36:14,800
provides a great opportunity here I

00:36:12,670 --> 00:36:16,930
think if we can provide the same

00:36:14,800 --> 00:36:20,830
functionalities using them Larry has a

00:36:16,930 --> 00:36:22,570
great talk and he's working on like TCP

00:36:20,830 --> 00:36:25,950
UBF that provides many of these

00:36:22,570 --> 00:36:25,950
functionalities in a vpf

00:36:28,859 --> 00:36:37,949
thank you any Christmas

00:36:32,560 --> 00:36:37,949
[Applause]

00:36:40,460 --> 00:36:46,200
so I guess these options require

00:36:43,710 --> 00:36:49,430
applications to be changed right can we

00:36:46,200 --> 00:36:49,430
use these

00:36:52,300 --> 00:36:57,100
you mean so time something yes so time

00:36:54,370 --> 00:37:01,950
stamping or ass or PCP info yes they do

00:36:57,100 --> 00:37:01,950
both need application so we cannot use

00:37:02,430 --> 00:37:07,240
TCP who is also provided by SS so if you

00:37:05,320 --> 00:37:09,820
SS on your machine its

00:37:07,240 --> 00:37:12,640
get from you can see the same values

00:37:09,820 --> 00:37:19,600
that are available in TCP info you don't

00:37:12,640 --> 00:37:21,850
really need to well for time stamping

00:37:19,600 --> 00:37:23,830
you have to modify your application it

00:37:21,850 --> 00:37:26,140
has to be instructed to the kernel that

00:37:23,830 --> 00:37:31,270
this socket needs these timestamps

00:37:26,140 --> 00:37:33,700
otherwise it wouldn't be generated you

00:37:31,270 --> 00:37:36,150
can grab this all of these all of the

00:37:33,700 --> 00:37:39,280
points that we captured time stamps have

00:37:36,150 --> 00:37:41,830
probes so you can do it like BCC or flow

00:37:39,280 --> 00:37:43,180
to them and capture the same time sense

00:37:41,830 --> 00:37:45,990
but there are different mechanism

00:37:43,180 --> 00:37:45,990
they're not so times

00:37:57,120 --> 00:38:01,890
that's a great question I'll go into

00:37:59,310 --> 00:38:05,280
more details in the talk but basically

00:38:01,890 --> 00:38:07,170
the time stamping captures one time some

00:38:05,280 --> 00:38:09,960
percent message for UDP that makes sense

00:38:07,170 --> 00:38:14,580
is one packet for TCP it is the last

00:38:09,960 --> 00:38:16,530
byte of that send message and but you

00:38:14,580 --> 00:38:19,110
can you can do creative stuff like

00:38:16,530 --> 00:38:22,380
there's you are added to TCP so you can

00:38:19,110 --> 00:38:24,750
like say one MTU size send message be

00:38:22,380 --> 00:38:27,780
the new your and then your rest of bytes

00:38:24,750 --> 00:38:31,980
so you you basically capture timestamp

00:38:27,780 --> 00:38:35,670
or a specific packet if you want but you

00:38:31,980 --> 00:38:39,300
have to for if you just want your normal

00:38:35,670 --> 00:38:41,160
send message to capture time sampling

00:38:39,300 --> 00:38:43,640
without any modification it would be the

00:38:41,160 --> 00:38:43,640
last byte

00:38:49,350 --> 00:38:54,480
a quick question on the on the errors

00:38:53,160 --> 00:38:56,730
that he talked about is there so time

00:38:54,480 --> 00:38:58,440
stamping can you very briefly say what

00:38:56,730 --> 00:39:01,410
the errors are that you have to deal

00:38:58,440 --> 00:39:02,940
with as an application from a so time

00:39:01,410 --> 00:39:04,890
stamping you mentioned that it's it's

00:39:02,940 --> 00:39:06,180
that there are some errors that you have

00:39:04,890 --> 00:39:06,780
to deal with or maybe I misheard what

00:39:06,180 --> 00:39:11,190
you said

00:39:06,780 --> 00:39:13,560
you mean when we were doing escapees

00:39:11,190 --> 00:39:17,070
bigger sect in SK error no not before

00:39:13,560 --> 00:39:18,510
4:10 if I'm going to use a so time

00:39:17,070 --> 00:39:22,650
stamping right now do I have to deal

00:39:18,510 --> 00:39:27,170
with any errors oh you have to deal with

00:39:22,650 --> 00:39:30,630
error cue not errors I see but

00:39:27,170 --> 00:39:32,400
timestamps are socket extended errors so

00:39:30,630 --> 00:39:34,230
they have their own error code they're

00:39:32,400 --> 00:39:37,230
not errors but they have email message

00:39:34,230 --> 00:39:39,000
error code and that is what is you can

00:39:37,230 --> 00:39:43,110
describe in which this with like I seen

00:39:39,000 --> 00:39:44,670
Pierre's on your your error cue they're

00:39:43,110 --> 00:39:46,770
not really errors you need to deal with

00:39:44,670 --> 00:39:48,620
it just you have error codes they look

00:39:46,770 --> 00:39:50,400
like errors but there are times

00:39:48,620 --> 00:39:52,560
understood okay

00:39:50,400 --> 00:39:56,660
it's a control channel but we are still

00:39:52,560 --> 00:39:56,660
using the same API yeah I get that

00:39:57,620 --> 00:40:02,600
so because you said that the opt stats

00:39:59,930 --> 00:40:04,490
are captured with the time stamps how

00:40:02,600 --> 00:40:06,290
many such statistics are stored in

00:40:04,490 --> 00:40:07,790
memory is there is that historical

00:40:06,290 --> 00:40:09,740
information like the error queue would

00:40:07,790 --> 00:40:11,000
have a set of I'm assuming time stands

00:40:09,740 --> 00:40:13,100
that you can retrieve are you storing

00:40:11,000 --> 00:40:15,050
all those stars for every event for

00:40:13,100 --> 00:40:17,810
every event so that's a great question

00:40:15,050 --> 00:40:20,120
the time stamps are counted for your arm

00:40:17,810 --> 00:40:22,520
M so up until you feel the arm and B

00:40:20,120 --> 00:40:25,310
just sink you timestamps and for all of

00:40:22,520 --> 00:40:27,080
them be attached everything ok so if the

00:40:25,310 --> 00:40:29,030
user space is billiard inquiry you just

00:40:27,080 --> 00:40:31,100
keep on our community and they are

00:40:29,030 --> 00:40:32,780
captured at the time we are so before

00:40:31,100 --> 00:40:34,670
adding them to the air queue we capture

00:40:32,780 --> 00:40:36,620
TCP state attach it to the time stamp

00:40:34,670 --> 00:40:38,120
put them on the air queue user can read

00:40:36,620 --> 00:40:39,740
it a minute or even when the connection

00:40:38,120 --> 00:40:43,550
is closed they don't have to read it now

00:40:39,740 --> 00:40:45,620
okay a follow-up question to the 20%

00:40:43,550 --> 00:40:47,630
overhead that you said for time stamping

00:40:45,620 --> 00:40:49,970
similarly you certain TCP involved also

00:40:47,630 --> 00:40:52,010
as overhead do you have any idea of like

00:40:49,970 --> 00:40:53,270
how much that overhead is left let's say

00:40:52,010 --> 00:40:55,390
the application queries every one

00:40:53,270 --> 00:40:58,610
millisecond is that even noticeable

00:40:55,390 --> 00:40:59,900
every one millisecond depends on the

00:40:58,610 --> 00:41:04,910
number of connections just one

00:40:59,900 --> 00:41:07,100
connection that I wouldn't do that on a

00:41:04,910 --> 00:41:10,760
100 Gig link for example but it looks

00:41:07,100 --> 00:41:12,260
like a van link internet-facing that

00:41:10,760 --> 00:41:14,690
would be completely fine it really

00:41:12,260 --> 00:41:17,390
depends on the worktop so when you hold

00:41:14,690 --> 00:41:20,630
the log for a few Mac or even in one

00:41:17,390 --> 00:41:22,580
microsecond that would cause enough harm

00:41:20,630 --> 00:41:26,780
for 100 Gig connection because of the

00:41:22,580 --> 00:41:27,500
gap in the extreme but if you have a 200

00:41:26,780 --> 00:41:30,730
millisecond

00:41:27,500 --> 00:41:33,620
RTT it just doesn't matter thank you

00:41:30,730 --> 00:41:36,320
another thing that I forgot whenever we

00:41:33,620 --> 00:41:39,950
have something on the air Q equal error

00:41:36,320 --> 00:41:43,160
would be fired so if you keep them there

00:41:39,950 --> 00:41:45,260
and never read anything their errors so

00:41:43,160 --> 00:41:48,680
April there is there an e polar has this

00:41:45,260 --> 00:41:50,570
quirk that it's always set you don't you

00:41:48,680 --> 00:41:52,760
don't have to ask for it it's always

00:41:50,570 --> 00:41:54,710
given to you so it's like just waking up

00:41:52,760 --> 00:41:57,050
a pool area put up you can

00:41:54,710 --> 00:41:59,890
you have to be very careful if you want

00:41:57,050 --> 00:41:59,890
to delay reading times

00:42:03,790 --> 00:42:10,369
so what are you doing at ETS offload

00:42:07,100 --> 00:42:12,890
using a neck and

00:42:10,369 --> 00:42:16,790
you said the the time stamp is for the

00:42:12,890 --> 00:42:20,780
last byte of the whole packet and say

00:42:16,790 --> 00:42:22,900
you have an EDT offload how do you paste

00:42:20,780 --> 00:42:26,420
the segment's within the tears oh

00:42:22,900 --> 00:42:28,280
there's segments within that here so I

00:42:26,420 --> 00:42:31,150
don't think if you're facing cases

00:42:28,280 --> 00:42:31,150
within yourself

00:42:35,140 --> 00:42:41,249
yeah TCB SEC doesn't paper packet so you

00:42:38,319 --> 00:42:44,589
will see you will see berths with TSO

00:42:41,249 --> 00:42:46,630
you will see the one time stamp for the

00:42:44,589 --> 00:42:49,210
last part of the tier so Chuck if it is

00:42:46,630 --> 00:42:51,450
the last byte and if you call as

00:42:49,210 --> 00:42:53,829
multiple packets in the same tier so

00:42:51,450 --> 00:42:56,670
you'll get one time stand for all those

00:42:53,829 --> 00:42:56,670
coalesce packets

00:43:16,310 --> 00:43:21,900
so just to repeat what Eric said for the

00:43:19,140 --> 00:43:23,700
mic and you don't want to paste here so

00:43:21,900 --> 00:43:25,350
chunks because on the other side if we

00:43:23,700 --> 00:43:27,630
just killed Europe you want to burst

00:43:25,350 --> 00:43:31,320
them out so that you get at one large

00:43:27,630 --> 00:43:32,070
ero on the other side and that goes was

00:43:31,320 --> 00:43:35,900
that correct

00:43:32,070 --> 00:43:39,810
okay don't last myself

00:43:35,900 --> 00:43:42,210
hello a quick question so first thanks

00:43:39,810 --> 00:43:45,180
for the talk TCP info is indeed pretty

00:43:42,210 --> 00:43:48,210
poorly documented the questions about

00:43:45,180 --> 00:43:51,300
OTT you mentioned that LDT and is being

00:43:48,210 --> 00:43:53,520
focused on caveats I kind of got what

00:43:51,300 --> 00:44:00,000
you try to say but is there anything

00:43:53,520 --> 00:44:03,930
else because sure so the the thing is

00:44:00,000 --> 00:44:09,300
what TCP measures that are TT is as good

00:44:03,930 --> 00:44:12,540
as the delays you're introducing on the

00:44:09,300 --> 00:44:15,090
end hosts so for example if I send you

00:44:12,540 --> 00:44:19,590
the packet you just don't send me an act

00:44:15,090 --> 00:44:20,310
for one second even if my RTT is 20

00:44:19,590 --> 00:44:23,700
metros

00:44:20,310 --> 00:44:25,440
tcp is view of RT t is going to be 10

00:44:23,700 --> 00:44:30,180
micro second plus one second of your

00:44:25,440 --> 00:44:32,820
delay right so whatever you're the

00:44:30,180 --> 00:44:35,910
receiver delay is that is accumulated in

00:44:32,820 --> 00:44:38,670
the RTT samples in TCP because TCP

00:44:35,910 --> 00:44:40,710
doesn't have any other signal right so

00:44:38,670 --> 00:44:42,359
it means that the earth you will have

00:44:40,710 --> 00:44:44,700
reasonable value at the start of the

00:44:42,359 --> 00:44:48,210
connection of their date and check and

00:44:44,700 --> 00:44:50,700
then it can go berserk scenic or TT can

00:44:48,210 --> 00:44:56,070
be more accurate but it really depends

00:44:50,700 --> 00:44:58,290
so if your receiver is just busy it

00:44:56,070 --> 00:45:00,180
wouldn't if even for scenic sending the

00:44:58,290 --> 00:45:03,330
scenic it would take a long time for

00:45:00,180 --> 00:45:05,640
that so we have like situations in proud

00:45:03,330 --> 00:45:07,380
that our TT just bounces up because one

00:45:05,640 --> 00:45:09,420
and hose would like it was a faulty

00:45:07,380 --> 00:45:11,820
hardware or was just too busy it

00:45:09,420 --> 00:45:12,830
couldn't do anything on it was just

00:45:11,820 --> 00:45:15,590
stress

00:45:12,830 --> 00:45:18,740
so yeah that that's a quirk of TC PRTG

00:45:15,590 --> 00:45:22,430
you have to be it's not really Nick -

00:45:18,740 --> 00:45:25,180
Nick RTP its end host it's tcp - tcp RTG

00:45:22,430 --> 00:45:25,180
if you will

00:45:40,180 --> 00:45:42,990
that's great

00:45:51,400 --> 00:45:56,079
as well start hi my name is Chris rapier

00:45:54,430 --> 00:45:57,450
I'm with the Pittsburgh supercomputing

00:45:56,079 --> 00:45:59,769
Center out of Pittsburgh Pennsylvania

00:45:57,450 --> 00:46:04,299
were associated with Carnegie Mellon

00:45:59,769 --> 00:46:08,279
University we are a I am specifically in

00:46:04,299 --> 00:46:10,630
the network research section of PSC but

00:46:08,279 --> 00:46:12,160
because of the way that funding works I

00:46:10,630 --> 00:46:14,259
work all over the entire center

00:46:12,160 --> 00:46:23,470
everywhere from file systems to storage

00:46:14,259 --> 00:46:25,690
raise to production to research alright

00:46:23,470 --> 00:46:29,980
so what I'm here to talk to you about

00:46:25,690 --> 00:46:36,789
today is our implementation of RFC 48

00:46:29,980 --> 00:46:39,279
and 98 now RFC 48 98 is a mid of around

00:46:36,789 --> 00:46:41,799
120 different tcp instruments that was

00:46:39,279 --> 00:46:46,809
published around 12 years ago by Matt

00:46:41,799 --> 00:46:50,410
Mathis who is currently at Google this

00:46:46,809 --> 00:46:53,140
provides a superset of instrumentations

00:46:50,410 --> 00:46:54,700
that are not found in TCP info and at

00:46:53,140 --> 00:46:58,059
the time that we were developing this

00:46:54,700 --> 00:47:00,450
TCP info was a relatively bare set of

00:46:58,059 --> 00:47:02,559
instrumentations within the kernel and

00:47:00,450 --> 00:47:04,690
we thought it would be good to have more

00:47:02,559 --> 00:47:09,400
of an insight into what we considered to

00:47:04,690 --> 00:47:11,860
be the black box of the TCP stack

00:47:09,400 --> 00:47:14,350
now these instruments that we have we

00:47:11,860 --> 00:47:17,610
have them grouped into various number of

00:47:14,350 --> 00:47:21,160
classifications these deal with stack

00:47:17,610 --> 00:47:23,620
which would be options state do packs in

00:47:21,160 --> 00:47:27,250
congestion avoidance events things like

00:47:23,620 --> 00:47:32,140
that then we have our path metrics RTT

00:47:27,250 --> 00:47:33,850
RTO due backs out application metrics

00:47:32,140 --> 00:47:36,700
now we found the application metrics be

00:47:33,850 --> 00:47:40,330
very important these would be send

00:47:36,700 --> 00:47:44,770
unacknowledged send max the number of

00:47:40,330 --> 00:47:46,780
octets act both of 32 and 64-bit things

00:47:44,770 --> 00:47:48,130
dealing with the application queues so

00:47:46,780 --> 00:47:50,560
that we can get some information that

00:47:48,130 --> 00:47:54,010
how the application is interacting with

00:47:50,560 --> 00:47:57,220
the stack we have the performance stack

00:47:54,010 --> 00:48:01,150
which would be segments not tetes in and

00:47:57,220 --> 00:48:02,950
out and then unlike tcp info we actually

00:48:01,150 --> 00:48:07,120
have three instruments that we actually

00:48:02,950 --> 00:48:08,770
have write access to these write acts as

00:48:07,120 --> 00:48:11,290
instruments allow us to actually tune

00:48:08,770 --> 00:48:15,040
the performance characteristics of this

00:48:11,290 --> 00:48:17,290
stack specifically the received window

00:48:15,040 --> 00:48:18,850
the receive window is one of the things

00:48:17,290 --> 00:48:22,210
that'll actually allows you to able to

00:48:18,850 --> 00:48:24,310
do the receive window auto tuning and

00:48:22,210 --> 00:48:30,760
that came out of a previous incarnation

00:48:24,310 --> 00:48:33,580
of RFC 48 98 were called web 103

00:48:30,760 --> 00:48:38,020
implementations of RFC 48 98 currently

00:48:33,580 --> 00:48:41,680
exist we have web 100 which was it's

00:48:38,020 --> 00:48:44,020
quite old now and that is defunct and

00:48:41,680 --> 00:48:46,240
that was Linux based we have web 10g

00:48:44,020 --> 00:48:48,540
which is what I'm here to talk to you

00:48:46,240 --> 00:48:50,740
about I was currently active and

00:48:48,540 --> 00:48:54,550
shockingly enough a dog who exists

00:48:50,740 --> 00:48:58,870
inside the Microsoft TCP stack as the

00:48:54,550 --> 00:49:01,930
TCE stats instrumentation structure

00:48:58,870 --> 00:49:04,570
some of these RFC 48 98 instruments have

00:49:01,930 --> 00:49:07,510
been incorporated into the TCP info

00:49:04,570 --> 00:49:08,680
stack the last time I checked just

00:49:07,510 --> 00:49:10,390
looking at the comments there were

00:49:08,680 --> 00:49:14,920
around nine of these instruments that

00:49:10,390 --> 00:49:20,380
were included in the TCP info stack now

00:49:14,920 --> 00:49:22,870
tell you a little bit about web 10g this

00:49:20,380 --> 00:49:25,510
is implemented as a set of patches to

00:49:22,870 --> 00:49:26,740
the linux kernel and this set of patches

00:49:25,510 --> 00:49:31,420
actually provide the base

00:49:26,740 --> 00:49:33,430
instrumentation as as is required there

00:49:31,420 --> 00:49:35,260
is also a set of memory structures that

00:49:33,430 --> 00:49:37,090
we store the information and we do not

00:49:35,260 --> 00:49:39,790
store the information directly in the

00:49:37,090 --> 00:49:42,280
socket we actually store it in a hash of

00:49:39,790 --> 00:49:44,590
memory structs its memory struck is

00:49:42,280 --> 00:49:47,710
instantiated every time a new socket is

00:49:44,590 --> 00:49:53,920
created and entered into the hash we're

00:49:47,710 --> 00:49:56,680
using UT hash for that we have a way of

00:49:53,920 --> 00:49:59,430
enabling that through a kernel

00:49:56,680 --> 00:50:02,800
parameters we enable it through the TCP

00:49:59,430 --> 00:50:05,950
East stats parameter one of the things

00:50:02,800 --> 00:50:08,170
that we also have in this is we have a

00:50:05,950 --> 00:50:10,090
persistence timer now the persistence

00:50:08,170 --> 00:50:12,850
timer is actually important for what we

00:50:10,090 --> 00:50:14,650
do which on the research side the

00:50:12,850 --> 00:50:16,240
persistence timer allows this memory

00:50:14,650 --> 00:50:19,450
struct that we created on the hash to

00:50:16,240 --> 00:50:21,220
exist beyond the close of the socket so

00:50:19,450 --> 00:50:23,170
that we can get after the close of the

00:50:21,220 --> 00:50:26,310
socket we can actually get finals data

00:50:23,170 --> 00:50:26,310
out of the socket

00:50:26,490 --> 00:50:31,570
the access is provided via net link via

00:50:29,440 --> 00:50:34,840
kernel module dynamically loadable

00:50:31,570 --> 00:50:39,250
kernel module the module call the module

00:50:34,840 --> 00:50:41,170
draws of both from TCP East ATS and TCP

00:50:39,250 --> 00:50:43,810
info as appropriate we're not doubling

00:50:41,170 --> 00:50:46,360
up the number of instruments in there if

00:50:43,810 --> 00:50:48,910
TCP info has something that's important

00:50:46,360 --> 00:50:50,790
that we're calling in RFC 48 98 then we

00:50:48,910 --> 00:50:56,020
just grab it from there as opposed to

00:50:50,790 --> 00:50:59,050
Dublin L finally we have a user land API

00:50:56,020 --> 00:51:00,790
that's built around live M&L that allows

00:50:59,050 --> 00:51:02,680
us to get the information directly out

00:51:00,790 --> 00:51:04,360
of the kernel via net link into user

00:51:02,680 --> 00:51:07,690
lands so we can do something for

00:51:04,360 --> 00:51:10,270
productive with it we have multiple

00:51:07,690 --> 00:51:13,960
examples and utilities that are provided

00:51:10,270 --> 00:51:17,080
in the user land library these large

00:51:13,960 --> 00:51:22,920
directly access all of the information

00:51:17,080 --> 00:51:25,860
provided by TCP info and TCP stats and

00:51:22,920 --> 00:51:27,540
you can

00:51:25,860 --> 00:51:30,780
one of the interesting things about it

00:51:27,540 --> 00:51:32,940
is that you can actually get information

00:51:30,780 --> 00:51:36,690
on any application that's running where

00:51:32,940 --> 00:51:38,700
you have rights to that socket without

00:51:36,690 --> 00:51:40,590
actually changing the instant without

00:51:38,700 --> 00:51:44,550
actually changing the code base for that

00:51:40,590 --> 00:51:46,980
application so that if we can actually

00:51:44,550 --> 00:51:49,500
basically provide instrumentation for

00:51:46,980 --> 00:51:54,420
any network application without

00:51:49,500 --> 00:51:56,790
providing any modifications now for

00:51:54,420 --> 00:52:00,630
anyone who's actually has any experience

00:51:56,790 --> 00:52:07,470
previously with web 10g I presented on

00:52:00,630 --> 00:52:09,360
this four years ago at net dev 15 we

00:52:07,470 --> 00:52:12,330
have actually done some modifications to

00:52:09,360 --> 00:52:15,840
we'd have removed all of the externs at

00:52:12,330 --> 00:52:17,820
were associated with an amusing the new

00:52:15,840 --> 00:52:20,310
structures to allow for to past kernel

00:52:17,820 --> 00:52:22,530
options forward we have been forward

00:52:20,310 --> 00:52:24,270
porting this every time that we've had a

00:52:22,530 --> 00:52:27,360
new kernel revision come out we're

00:52:24,270 --> 00:52:31,470
currently at 419 we have not yet forward

00:52:27,360 --> 00:52:33,630
ported to 500 yet we are working on

00:52:31,470 --> 00:52:37,380
incorporating the instrumentation that

00:52:33,630 --> 00:52:39,000
TCP info provides for bbr and we're also

00:52:37,380 --> 00:52:43,220
doing some work on actually improving

00:52:39,000 --> 00:52:46,740
the performance handling of this as

00:52:43,220 --> 00:52:48,510
mostly in terms of creating the memory

00:52:46,740 --> 00:52:51,030
structures associated with a hash so

00:52:48,510 --> 00:52:54,410
that we can decrease some of the

00:52:51,030 --> 00:52:54,410
overhead associated with that

00:52:55,780 --> 00:53:01,780
now one of the things that I have been

00:52:58,900 --> 00:53:03,250
told is as an academic we just like to

00:53:01,780 --> 00:53:04,930
throw everything at the wall and see

00:53:03,250 --> 00:53:07,150
what sticks we don't really think about

00:53:04,930 --> 00:53:08,650
what's going in there we just you know

00:53:07,150 --> 00:53:09,970
hey let's just throw a hundred and

00:53:08,650 --> 00:53:13,900
twenty instruments into the stack and

00:53:09,970 --> 00:53:17,980
see what happens this is entirely true

00:53:13,900 --> 00:53:19,540
this is what we do there's funding

00:53:17,980 --> 00:53:21,250
reasons for that but basically because

00:53:19,540 --> 00:53:22,600
we have a limited amount of funding we

00:53:21,250 --> 00:53:24,790
want to get as much done and that

00:53:22,600 --> 00:53:26,470
funding period as possible and then we

00:53:24,790 --> 00:53:31,030
let everyone else figure out what the

00:53:26,470 --> 00:53:32,710
hell we've done but the question is now

00:53:31,030 --> 00:53:34,900
that we have everything thrown at the

00:53:32,710 --> 00:53:36,960
wall what can we do about seeing what

00:53:34,900 --> 00:53:41,380
sticks

00:53:36,960 --> 00:53:44,860
well we actually feel that Webb 10g has

00:53:41,380 --> 00:53:49,180
value in terms of P analytics outside of

00:53:44,860 --> 00:53:52,570
the boundaries provided by TCP info web

00:53:49,180 --> 00:53:54,850
10g in and of itself is a really good

00:53:52,570 --> 00:53:58,420
way of getting real-world detailed flow

00:53:54,850 --> 00:54:00,220
metrics one of the major advantages of

00:53:58,420 --> 00:54:03,820
it that we have is that we have an

00:54:00,220 --> 00:54:07,000
entire ecosystem based around web 10g

00:54:03,820 --> 00:54:08,920
that can provide you with detailed

00:54:07,000 --> 00:54:15,010
metrics of any running Network

00:54:08,920 --> 00:54:16,960
application now this is a sampled data I

00:54:15,010 --> 00:54:19,630
mean it's not going to replace a TCP

00:54:16,960 --> 00:54:22,170
dump but it can provide you pretty high

00:54:19,630 --> 00:54:26,890
pretty decently high resolution in terms

00:54:22,170 --> 00:54:29,080
of flow evolution for example one of the

00:54:26,890 --> 00:54:32,290
items that we have is we have what's

00:54:29,080 --> 00:54:37,030
called web 10g logger this actually

00:54:32,290 --> 00:54:39,370
reports TCP info TCP e stats information

00:54:37,030 --> 00:54:43,300
on every single application running on

00:54:39,370 --> 00:54:45,730
that system network application

00:54:43,300 --> 00:54:47,890
and we can do that as user defined

00:54:45,730 --> 00:54:51,300
sample rate the default is every second

00:54:47,890 --> 00:54:53,619
but we can do that every millisecond

00:54:51,300 --> 00:54:57,430
every millisecond is going to destroy

00:54:53,619 --> 00:55:00,280
your performance but if you only have

00:54:57,430 --> 00:55:02,050
one or two applications on there that

00:55:00,280 --> 00:55:03,460
you're really interested in we can still

00:55:02,050 --> 00:55:05,980
actually provide some very good

00:55:03,460 --> 00:55:12,820
information on how that TCP flow is

00:55:05,980 --> 00:55:14,680
evolving over time now we do have some

00:55:12,820 --> 00:55:17,200
experience with help with how this has

00:55:14,680 --> 00:55:19,960
been used in research application

00:55:17,200 --> 00:55:21,850
settings I don't know if any of you are

00:55:19,960 --> 00:55:26,500
familiar with tea cup out of swine burn

00:55:21,850 --> 00:55:28,180
in Australia tea cup I don't think it

00:55:26,500 --> 00:55:30,580
exists anymore I think he got

00:55:28,180 --> 00:55:33,130
incorporated into another organisation

00:55:30,580 --> 00:55:35,940
at Swinburne but it was actually making

00:55:33,130 --> 00:55:40,030
significant use of web 10g in their

00:55:35,940 --> 00:55:41,920
research infrastructure specifically in

00:55:40,030 --> 00:55:44,680
terms of flow evolution trying to

00:55:41,920 --> 00:55:51,190
determine how flows interact in

00:55:44,680 --> 00:55:53,650
real-world settings now not everyone who

00:55:51,190 --> 00:55:58,690
uses web 10g tells me that they're using

00:55:53,650 --> 00:56:02,830
it because they just don't but a review

00:55:58,690 --> 00:56:05,470
on various citations information and

00:56:02,830 --> 00:56:07,119
things like that we have been finding

00:56:05,470 --> 00:56:09,760
that it has been used in a number of

00:56:07,119 --> 00:56:12,070
different ways in terms of published

00:56:09,760 --> 00:56:15,700
papers from academic research research

00:56:12,070 --> 00:56:18,810
institutions exploring buffer bloat

00:56:15,700 --> 00:56:21,070
plaid performance Wireless issues

00:56:18,810 --> 00:56:23,220
they've also been using it interestingly

00:56:21,070 --> 00:56:28,720
enough in network modelling reproduce

00:56:23,220 --> 00:56:30,850
reproducibility basically using web 10g

00:56:28,720 --> 00:56:33,910
to determine if their network model

00:56:30,850 --> 00:56:37,390
actually is reproducible in the real

00:56:33,910 --> 00:56:38,770
world and that was actually unique

00:56:37,390 --> 00:56:40,510
application that I never thought of

00:56:38,770 --> 00:56:42,250
doing before but it's kind of cool that

00:56:40,510 --> 00:56:45,520
someone's actually using this in a way I

00:56:42,250 --> 00:56:48,610
haven't thought of and if any of you are

00:56:45,520 --> 00:56:51,430
familiar with a measurement lab this is

00:56:48,610 --> 00:56:53,620
also one of the foundations are SC 48 98

00:56:51,430 --> 00:56:56,680
is one of the foundations for the

00:56:53,620 --> 00:56:59,110
publicly available datasets measurement

00:56:56,680 --> 00:57:03,070
lab specifically the MDT network

00:56:59,110 --> 00:57:07,660
diagnostic tool kit the data that's

00:57:03,070 --> 00:57:09,550
coming out of there and this these

00:57:07,660 --> 00:57:12,570
datasets have been proven to be very

00:57:09,550 --> 00:57:18,660
useful in terms of people trying to do

00:57:12,570 --> 00:57:18,660
research into flow evolution and the

00:57:20,770 --> 00:57:30,880
in malice automated analysis of Network

00:57:25,270 --> 00:57:32,560
pathologies now the automated analysis

00:57:30,880 --> 00:57:32,859
and Network pathologies is kind of my

00:57:32,560 --> 00:57:35,050
thing

00:57:32,859 --> 00:57:38,980
so I'm really excited to see that people

00:57:35,050 --> 00:57:40,839
are doing that now there are a number of

00:57:38,980 --> 00:57:43,599
different ways in which you might think

00:57:40,839 --> 00:57:48,580
about deploying web 10g and why you want

00:57:43,599 --> 00:57:50,349
to deploy it I think the thing isn't

00:57:48,580 --> 00:57:54,790
this you don't really want to do this in

00:57:50,349 --> 00:57:59,920
a high scale production networking the

00:57:54,790 --> 00:58:01,420
as previously mentioned it's expensive I

00:57:59,920 --> 00:58:03,849
didn't know about the socket being

00:58:01,420 --> 00:58:06,730
locked down with the newer versions of

00:58:03,849 --> 00:58:10,089
the kernel and that's yeah that's a

00:58:06,730 --> 00:58:12,910
problem and one of the other things that

00:58:10,089 --> 00:58:14,890
we find is that just the process of

00:58:12,910 --> 00:58:17,020
actually creating these sockets of

00:58:14,890 --> 00:58:20,490
creating the memory structs has a

00:58:17,020 --> 00:58:25,480
negative impact on socket creation so

00:58:20,490 --> 00:58:28,150
what ends up happening is the time to

00:58:25,480 --> 00:58:29,710
create the socket is actually delayed by

00:58:28,150 --> 00:58:32,740
the creation of the external memory

00:58:29,710 --> 00:58:34,780
structure and this is an impact this is

00:58:32,740 --> 00:58:37,089
a negative impact in places we're

00:58:34,780 --> 00:58:38,859
dealing with you know hundreds of

00:58:37,089 --> 00:58:41,120
thousands or even tens of thousands of

00:58:38,859 --> 00:58:43,460
concurrent connections

00:58:41,120 --> 00:58:48,230
so where you would want to deploy this

00:58:43,460 --> 00:58:50,990
is where you're dealing with lower lower

00:58:48,230 --> 00:58:52,970
volume servers specifically in terms of

00:58:50,990 --> 00:58:56,630
what we call data transferred nodes or

00:58:52,970 --> 00:58:58,100
DT NS we use these specifically in the

00:58:56,630 --> 00:59:01,150
research community on these things

00:58:58,100 --> 00:59:03,770
called science DM Z's these are how we

00:59:01,150 --> 00:59:08,420
transfer the large data sets that we're

00:59:03,770 --> 00:59:10,070
using from the data collection areas to

00:59:08,420 --> 00:59:12,590
the compute resources where we analyze

00:59:10,070 --> 00:59:17,000
the data and these can be datasets

00:59:12,590 --> 00:59:21,880
anywhere from you know several hundred

00:59:17,000 --> 00:59:21,880
gigabytes to tens of terabytes

00:59:23,210 --> 00:59:27,619
but actually having information on how

00:59:25,849 --> 00:59:29,540
those flows evolved over time is

00:59:27,619 --> 00:59:31,910
actually really important in terms of

00:59:29,540 --> 00:59:34,069
determining when we're coming across

00:59:31,910 --> 00:59:37,099
pathological conditions that either lead

00:59:34,069 --> 00:59:40,849
to transfer failures or suboptimal

00:59:37,099 --> 00:59:42,319
transfers and one of the things that's

00:59:40,849 --> 00:59:44,960
important is when we're transferring you

00:59:42,319 --> 00:59:47,150
know a couple terabytes even if we're

00:59:44,960 --> 00:59:49,940
running at 80% below even if we're

00:59:47,150 --> 00:59:53,960
running just 20% below where we should

00:59:49,940 --> 00:59:56,809
be on that flow that can actually add

00:59:53,960 --> 00:59:58,849
another 1012 hours onto our transfer

00:59:56,809 --> 01:00:02,170
time which significantly impacts the

00:59:58,849 --> 01:00:02,170
workflow that we're trying to deal with

01:00:02,230 --> 01:00:08,800
again we're only doing sampling with

01:00:04,880 --> 01:00:10,790
this but your sample rate is up to you

01:00:08,800 --> 01:00:12,829
one of the things we have found it's

01:00:10,790 --> 01:00:15,410
even though it's sampling we're accurate

01:00:12,829 --> 01:00:17,210
at line rate so we can get data out

01:00:15,410 --> 01:00:19,700
regardless of what your line rate is

01:00:17,210 --> 01:00:21,890
because as long as the kernel can keep

01:00:19,700 --> 01:00:24,700
up with what's going on we can get the

01:00:21,890 --> 01:00:24,700
data out of there

01:00:25,630 --> 01:00:31,840
this is the same in the same caveats

01:00:29,290 --> 01:00:35,620
apply to this as would apply to polling

01:00:31,840 --> 01:00:43,510
TCP info because we are polling TCP info

01:00:35,620 --> 01:00:45,040
in this process as well now one of the

01:00:43,510 --> 01:00:47,140
main reasons why they had me come here

01:00:45,040 --> 01:00:49,810
is to talk about one of our applications

01:00:47,140 --> 01:00:55,600
of this of web 10g in a production

01:00:49,810 --> 01:01:00,730
environment this is a an application

01:00:55,600 --> 01:01:03,190
called X site X site was a program

01:01:00,730 --> 01:01:05,290
sponsored by the NSF under their eager

01:01:03,190 --> 01:01:10,300
program which is for high-risk

01:01:05,290 --> 01:01:12,640
high-return ideas and the idea behind X

01:01:10,300 --> 01:01:14,890
site is a distributed flow data

01:01:12,640 --> 01:01:18,940
collection and analysis platform powered

01:01:14,890 --> 01:01:22,780
by web 10g the goal of it is really to

01:01:18,940 --> 01:01:24,760
identify failing flows automatically

01:01:22,780 --> 01:01:28,180
identify failing flows within the

01:01:24,760 --> 01:01:31,270
lifetime of that flow so that we can

01:01:28,180 --> 01:01:33,130
apply we can either apply corrective

01:01:31,270 --> 01:01:35,820
measures during the life span of that

01:01:33,130 --> 01:01:38,020
flow or we can actually identify

01:01:35,820 --> 01:01:40,660
persistent pathologies within our

01:01:38,020 --> 01:01:41,950
network these persistent pathologies

01:01:40,660 --> 01:01:45,070
might be anything from the

01:01:41,950 --> 01:01:47,380
infrastructure level buffer bloat poorly

01:01:45,070 --> 01:01:49,960
configured switch is middleboxes

01:01:47,380 --> 01:01:52,090
or it could be application level issues

01:01:49,960 --> 01:01:55,089
such as with one of the main things that

01:01:52,090 --> 01:01:57,759
we use for transferring data is

01:01:55,089 --> 01:02:02,650
a application called grit FTP which

01:01:57,759 --> 01:02:04,779
comes out of Globus the other idea

01:02:02,650 --> 01:02:06,969
behind it as it distributed know as a

01:02:04,779 --> 01:02:08,920
distributed network monitoring system is

01:02:06,969 --> 01:02:13,269
it gives us what what I like to call a

01:02:08,920 --> 01:02:15,999
panopticon view of the network for every

01:02:13,269 --> 01:02:18,460
place where we have one of these I'll

01:02:15,999 --> 01:02:19,749
get to that the structure in a moment

01:02:18,460 --> 01:02:22,839
for every place where we have an

01:02:19,749 --> 01:02:24,759
instrumented data transfer node we can

01:02:22,839 --> 01:02:27,729
actually draw that information to a

01:02:24,759 --> 01:02:29,950
centralized storage location run reports

01:02:27,729 --> 01:02:34,029
and analysis on it and provide network

01:02:29,950 --> 01:02:37,180
operators a view of not just how their

01:02:34,029 --> 01:02:39,910
network is working in an aggregate like

01:02:37,180 --> 01:02:42,400
we might get with a network weather

01:02:39,910 --> 01:02:46,869
monitoring service but on a per flow

01:02:42,400 --> 01:02:49,089
basis we find this to be very important

01:02:46,869 --> 01:02:50,920
because one of the things that we find

01:02:49,089 --> 01:02:53,979
is that if we're just doing bandwidth

01:02:50,920 --> 01:02:57,420
monitoring or if we're just doing perfs

01:02:53,979 --> 01:03:01,180
on our tests or if we're just looking at

01:02:57,420 --> 01:03:03,339
you know some of the various you know

01:03:01,180 --> 01:03:08,259
errors on the network that we're seeing

01:03:03,339 --> 01:03:10,989
the switches we can actually miss

01:03:08,259 --> 01:03:12,670
important information that is happening

01:03:10,989 --> 01:03:15,519
we can say like oh the bandwidth is

01:03:12,670 --> 01:03:18,420
great because you know we're seeing you

01:03:15,519 --> 01:03:21,130
know 75% utilization across this link

01:03:18,420 --> 01:03:24,440
but what we're missing is that it's one

01:03:21,130 --> 01:03:26,540
flow that's clobbering every other flow

01:03:24,440 --> 01:03:28,880
and we don't have that information

01:03:26,540 --> 01:03:34,400
without getting this more detailed flow

01:03:28,880 --> 01:03:38,150
based analysis now website is set up as

01:03:34,400 --> 01:03:41,599
a set of three independent agents the

01:03:38,150 --> 01:03:47,240
first are the listeners now the

01:03:41,599 --> 01:03:50,210
listeners live on web 10g enabled DT NS

01:03:47,240 --> 01:03:52,550
that live within the science DMZ s web

01:03:50,210 --> 01:03:54,349
10g is a series of kernel patches so of

01:03:52,550 --> 01:03:58,940
course we have to have a custom kernels

01:03:54,349 --> 01:04:03,790
on here yes yes I move very quickly at

01:03:58,940 --> 01:04:05,990
this point we do policy based sampling

01:04:03,790 --> 01:04:09,770
filtering duration and things like that

01:04:05,990 --> 01:04:11,810
so what we can do is we only want to

01:04:09,770 --> 01:04:14,630
look at flows that are originating from

01:04:11,810 --> 01:04:16,339
one specific subnet that are only using

01:04:14,630 --> 01:04:19,490
a specific application in this case

01:04:16,339 --> 01:04:21,500
great FTP and the flow has to last

01:04:19,490 --> 01:04:23,960
longer than 30 seconds before we start

01:04:21,500 --> 01:04:28,579
collecting data on it and incorporating

01:04:23,960 --> 01:04:32,630
that into our database minimal overhead

01:04:28,579 --> 01:04:36,770
on these we seem less than 2% uses your

01:04:32,630 --> 01:04:38,450
the CPU and most of our DT ends it's

01:04:36,770 --> 01:04:42,290
multi-threaded to have and the

01:04:38,450 --> 01:04:44,210
interactions within the listeners are

01:04:42,290 --> 01:04:47,450
multi-threaded so we can actually fire

01:04:44,210 --> 01:04:49,190
off trace routes so that as we get the

01:04:47,450 --> 01:04:51,650
flow not only do we have a flow we can a

01:04:49,190 --> 01:04:54,040
so get the trace route to and from the

01:04:51,650 --> 01:04:54,040
origin

01:04:55,420 --> 01:05:00,039
let's see moving quickly we have a

01:04:58,450 --> 01:05:01,809
centralized storage engine this is

01:05:00,039 --> 01:05:05,440
actually a time series database we're

01:05:01,809 --> 01:05:06,789
using influx influx DB for this because

01:05:05,440 --> 01:05:10,829
someone told us it was the right thing

01:05:06,789 --> 01:05:13,240
to do so far it's working well for us

01:05:10,829 --> 01:05:14,950
then we have an analysis engine the

01:05:13,240 --> 01:05:17,230
analysis engine trials through the

01:05:14,950 --> 01:05:19,990
information that we capture an influx DB

01:05:17,230 --> 01:05:24,730
and provide some at this point

01:05:19,990 --> 01:05:28,140
rudimentary level analysis on it we do

01:05:24,730 --> 01:05:30,190
hope to his work on that in the future

01:05:28,140 --> 01:05:33,460
currently just over the past seven

01:05:30,190 --> 01:05:36,430
months we just deployed a new schema on

01:05:33,460 --> 01:05:37,779
2d tiens we had three hundred sixty

01:05:36,430 --> 01:05:39,309
eight thousand flows that we've

01:05:37,779 --> 01:05:42,220
monitored all of these flows have

01:05:39,309 --> 01:05:43,960
existed longer than thirty seconds we've

01:05:42,220 --> 01:05:47,440
captured close to seven million data

01:05:43,960 --> 01:05:49,150
points one of the big things that we

01:05:47,440 --> 01:05:51,010
learned is schema is really important

01:05:49,150 --> 01:05:53,079
because if we have too high of a level

01:05:51,010 --> 01:05:58,539
of cardinality on the data it makes it

01:05:53,079 --> 01:06:02,619
impossible to do reads on it status no

01:05:58,539 --> 01:06:04,569
buts no Buck Rogers proposals have been

01:06:02,619 --> 01:06:08,079
submitted to the NSF to expand on this

01:06:04,569 --> 01:06:11,410
both a night in 2017 and 2018 both were

01:06:08,079 --> 01:06:13,119
unfortunately declined because we have

01:06:11,410 --> 01:06:14,950
not shown that the research is valid

01:06:13,119 --> 01:06:18,160
before they gave us money to do the

01:06:14,950 --> 01:06:22,180
research to see if it was valid that's

01:06:18,160 --> 01:06:24,069
how the NSF works however the process of

01:06:22,180 --> 01:06:26,140
developing these proposals has provided

01:06:24,069 --> 01:06:27,670
us a good roadmap for future work and if

01:06:26,140 --> 01:06:29,619
anyone has a couple hundred thousand

01:06:27,670 --> 01:06:32,450
dollars they'd like to give us we can do

01:06:29,619 --> 01:06:35,100
some great work with it

01:06:32,450 --> 01:06:39,780
we've developed a better deployment

01:06:35,100 --> 01:06:46,950
model we've have incorporated work for

01:06:39,780 --> 01:06:47,730
machine learning analysis with this one

01:06:46,950 --> 01:06:51,090
of the things that we're actually

01:06:47,730 --> 01:06:52,800
looking at doing is causal discovery net

01:06:51,090 --> 01:06:54,420
algorithms to establish whether or not

01:06:52,800 --> 01:06:57,630
the instruments were collecting actually

01:06:54,420 --> 01:07:03,030
mean anything that's part of seeing what

01:06:57,630 --> 01:07:04,350
sticks one of the ideas that we'd like

01:07:03,030 --> 01:07:05,910
to do is actually tear down the

01:07:04,350 --> 01:07:07,859
instrument set to just the things that

01:07:05,910 --> 01:07:11,670
are most important for determining flow

01:07:07,859 --> 01:07:13,440
flow health we're also looking at this

01:07:11,670 --> 01:07:15,540
is the moonshot here is some doing some

01:07:13,440 --> 01:07:17,160
predictive models seeing if we can

01:07:15,540 --> 01:07:20,960
determine based on the Mitchells

01:07:17,160 --> 01:07:24,270
initial conditions the TCP options and

01:07:20,960 --> 01:07:25,859
temporal variables whether or not we can

01:07:24,270 --> 01:07:28,500
make any predictions about the health of

01:07:25,859 --> 01:07:31,080
the flow over the long term this does

01:07:28,500 --> 01:07:32,820
just sound like AI sauce and because we

01:07:31,080 --> 01:07:34,140
just throw a eye on everything to see

01:07:32,820 --> 01:07:39,390
whether or not we get something out of

01:07:34,140 --> 01:07:42,869
it but our collaborator is basically an

01:07:39,390 --> 01:07:44,790
expert at CMU he thinks that there's

01:07:42,869 --> 01:07:47,459
somebody with his based on previous work

01:07:44,790 --> 01:07:50,759
that he's done

01:07:47,459 --> 01:07:53,690
we'll see be submitting again in 2019 if

01:07:50,759 --> 01:07:56,670
we can because I love writing proposals

01:07:53,690 --> 01:07:58,799
currently X site is being maintained as

01:07:56,670 --> 01:08:01,319
much as I can because I have no money on

01:07:58,799 --> 01:08:04,099
it and I'm the last man standing on this

01:08:01,319 --> 01:08:04,099
project as well

01:08:04,160 --> 01:08:10,170
useful URLs please take a note if you

01:08:08,699 --> 01:08:12,180
have any questions I didn't have a lot

01:08:10,170 --> 01:08:14,099
of time here please come up and talk to

01:08:12,180 --> 01:08:14,599
me I'll answer your questions as best I

01:08:14,099 --> 01:08:17,909
can

01:08:14,599 --> 01:08:20,909
thank you very much for your time and I

01:08:17,909 --> 01:08:22,889
think it's time for a break my name is

01:08:20,909 --> 01:08:25,230
Larry Bracknell lords Bracknell and from

01:08:22,889 --> 01:08:29,670
Facebook and I'm gonna be talking about

01:08:25,230 --> 01:08:38,329
TCP BPF and the latest updates and plans

01:08:29,670 --> 01:08:43,759
for TCP vpf related to TCP Analytics so

01:08:38,329 --> 01:08:46,469
the initial focus participe BPF was on

01:08:43,759 --> 01:08:49,259
optimization of TCP parameters so for

01:08:46,469 --> 01:08:51,750
example if we know a connection is

01:08:49,259 --> 01:08:55,980
within the data center we can optimize

01:08:51,750 --> 01:08:58,790
it by tuning its parameters having small

01:08:55,980 --> 01:09:01,290
buffers small sin RTO

01:08:58,790 --> 01:09:03,599
clamping the congestion window because

01:09:01,290 --> 01:09:06,329
we know that we do not need a condition

01:09:03,599 --> 01:09:09,420
windows 700 within a data center to full

01:09:06,329 --> 01:09:12,079
fully utilize the the bandwidth and

01:09:09,420 --> 01:09:14,969
similarly if the connection is going

01:09:12,079 --> 01:09:17,909
between regions we can also optimize

01:09:14,969 --> 01:09:19,469
we're having larger buffers larger in

01:09:17,909 --> 01:09:23,159
each organization window a larger

01:09:19,469 --> 01:09:27,210
receive window lately we're also

01:09:23,159 --> 01:09:30,179
starting to focus on TCP analytics you

01:09:27,210 --> 01:09:31,920
know things so that we can gather good

01:09:30,179 --> 01:09:33,790
information on the parts holding our

01:09:31,920 --> 01:09:36,009
throughput

01:09:33,790 --> 01:09:37,330
so for example we have callbacks for

01:09:36,009 --> 01:09:39,040
with transmissions every time we have it

01:09:37,330 --> 01:09:41,350
with just mission we can have a callback

01:09:39,040 --> 01:09:45,190
anytime we have an RTO when the TCP

01:09:41,350 --> 01:09:47,200
changes stay we can also have a an event

01:09:45,190 --> 01:09:49,989
we can have a callback and then we can

01:09:47,200 --> 01:09:53,080
lock some information or try to catch

01:09:49,989 --> 01:09:54,640
some corner conditions and lately we sum

01:09:53,080 --> 01:09:56,650
up someone added preferred a

01:09:54,640 --> 01:10:01,330
notification support so that we can use

01:09:56,650 --> 01:10:06,670
the perf cute to share information with

01:10:01,330 --> 01:10:09,489
user space and for those who are not

01:10:06,670 --> 01:10:12,700
familiar with TCP vpf let me just give

01:10:09,489 --> 01:10:15,640
you a quick overview so TCP vpf has a

01:10:12,700 --> 01:10:18,310
new tap of the PF program so BPF is that

01:10:15,640 --> 01:10:21,100
wonderful tool or extended BPF that

01:10:18,310 --> 01:10:25,810
allow us to compile programs that run in

01:10:21,100 --> 01:10:28,900
kernel space but unlike modules kernel

01:10:25,810 --> 01:10:32,650
modules these are safe they cannot cross

01:10:28,900 --> 01:10:34,570
the kernel right we can hurt things that

01:10:32,650 --> 01:10:36,580
were controlling like a connection you

01:10:34,570 --> 01:10:37,780
know it will change the buffer space and

01:10:36,580 --> 01:10:40,210
will make it too small we're going to

01:10:37,780 --> 01:10:43,000
limit it but we cannot hurt the system

01:10:40,210 --> 01:10:47,230
only the things that we are giving

01:10:43,000 --> 01:10:51,640
permission to modify normally bps

01:10:47,230 --> 01:10:53,830
programs they have a cold point at one

01:10:51,640 --> 01:10:55,150
place in the network stack so they when

01:10:53,830 --> 01:10:57,930
they are cold you always know it's being

01:10:55,150 --> 01:11:00,730
called from this particular point

01:10:57,930 --> 01:11:03,040
disability air is different in that it

01:11:00,730 --> 01:11:07,570
gets cold but from many places within

01:11:03,040 --> 01:11:09,700
the TCP code and then we use an not feel

01:11:07,570 --> 01:11:12,070
to tell us what happened you know

01:11:09,700 --> 01:11:13,989
probably in culture sometimes is being

01:11:12,070 --> 01:11:17,110
cold so that we can return up a

01:11:13,989 --> 01:11:20,020
particular value to the TCP style for

01:11:17,110 --> 01:11:21,970
example the initial timer and it's used

01:11:20,020 --> 01:11:24,370
for scenarios

01:11:21,970 --> 01:11:26,950
there is a window we want to use whether

01:11:24,370 --> 01:11:32,770
we need to use ECM for the congestion

01:11:26,950 --> 01:11:35,020
control or not the base RTT or you can

01:11:32,770 --> 01:11:38,740
also specify that the place were being

01:11:35,020 --> 01:11:41,620
called from for example when the

01:11:38,740 --> 01:11:44,620
connection when we do a connect call

01:11:41,620 --> 01:11:47,260
back and that's a good place to set 73

01:11:44,620 --> 01:11:49,360
buffer sizes for example or when the

01:11:47,260 --> 01:11:51,220
condition is being established either

01:11:49,360 --> 01:11:52,840
active or passive and those are also

01:11:51,220 --> 01:11:55,240
good places to do certain things like

01:11:52,840 --> 01:11:57,490
some buffer sizes could you to control

01:11:55,240 --> 01:11:59,530
algorithm etc and the idea here was that

01:11:57,490 --> 01:12:00,400
we wanted to limit the number of

01:11:59,530 --> 01:12:02,950
callbacks

01:12:00,400 --> 01:12:05,050
so initially most of those are done when

01:12:02,950 --> 01:12:09,100
the connection has been established so

01:12:05,050 --> 01:12:11,290
as not to hurt performance later on land

01:12:09,100 --> 01:12:13,120
a convention we had a callback for every

01:12:11,290 --> 01:12:15,190
time we would just meet a packet which

01:12:13,120 --> 01:12:16,480
are going to be a rare event in general

01:12:15,190 --> 01:12:23,530
which wannabe do it with meaning all the

01:12:16,480 --> 01:12:26,350
time and within the TCP BPF program we

01:12:23,530 --> 01:12:29,980
have access to a lot of the TCP

01:12:26,350 --> 01:12:33,130
subfields and they can just beam is just

01:12:29,980 --> 01:12:35,260
a week there's no over here forever we

01:12:33,130 --> 01:12:37,750
want to get a particular field like same

01:12:35,260 --> 01:12:41,320
condition windows and as a threshold the

01:12:37,750 --> 01:12:45,160
RTT is just a real no more overhead at

01:12:41,320 --> 01:12:48,730
that you can also actually condition

01:12:45,160 --> 01:12:51,700
control to a helper function called BPF

01:12:48,730 --> 01:12:54,250
gets a CAPTCHA and the reason is that

01:12:51,700 --> 01:12:58,230
the you know it returns a string so you

01:12:54,250 --> 01:12:58,230
just matter a simple field

01:12:59,600 --> 01:13:04,820
and we also have a support for another

01:13:02,660 --> 01:13:06,890
couple function of VPS at Sauk adoption

01:13:04,820 --> 01:13:09,230
to change some of the fields what we

01:13:06,890 --> 01:13:12,020
need to do some checking and like I

01:13:09,230 --> 01:13:15,140
mentioned before one of the guidelines

01:13:12,020 --> 01:13:17,480
is that a DPS program can add heard the

01:13:15,140 --> 01:13:20,180
colonel right so you can add we're not

01:13:17,480 --> 01:13:21,470
allowed to change a particular field so

01:13:20,180 --> 01:13:23,270
that would give it a value that could

01:13:21,470 --> 01:13:25,040
cause problems like same congestion with

01:13:23,270 --> 01:13:27,260
the for example if we set a value of

01:13:25,040 --> 01:13:28,520
zero that would cause really really bad

01:13:27,260 --> 01:13:32,210
behaviour in the colonel and it can

01:13:28,520 --> 01:13:35,000
crash it so please like that we just a

01:13:32,210 --> 01:13:36,710
helper function that will check whether

01:13:35,000 --> 01:13:44,450
the parameter we're trying to write is

01:13:36,710 --> 01:13:48,170
value or not okay so now going back to

01:13:44,450 --> 01:13:50,120
the updates so there are nearly

01:13:48,170 --> 01:13:55,430
questions about participate appear fees

01:13:50,120 --> 01:13:59,320
or or not oh okay perfect

01:13:55,430 --> 01:14:03,050
so there are some plans for this coming

01:13:59,320 --> 01:14:05,450
have to add new cobalt and some of those

01:14:03,050 --> 01:14:08,720
maybe we're going to get some pushback

01:14:05,450 --> 01:14:10,760
from Eric probably the Eric is I knew it

01:14:08,720 --> 01:14:12,470
so one is when a packet is set to

01:14:10,760 --> 01:14:15,080
receive right once again we're going to

01:14:12,470 --> 01:14:19,460
use a bit flag so that the overhead is

01:14:15,080 --> 01:14:21,140
only to check this bit flag and that is

01:14:19,460 --> 01:14:23,210
that we will not enable follow-up flows

01:14:21,140 --> 01:14:25,940
because there's too much overhead but

01:14:23,210 --> 01:14:31,310
only do it as needed so for example we

01:14:25,940 --> 01:14:36,290
can pick one ten thousand flow and for

01:14:31,310 --> 01:14:39,490
that flow we may want to get a call back

01:14:36,290 --> 01:14:42,250
to get more information about the

01:14:39,490 --> 01:14:44,740
flow also we only want to turn around

01:14:42,250 --> 01:14:46,960
when things start going south you know

01:14:44,740 --> 01:14:50,290
work jig problem for example have too

01:14:46,960 --> 01:14:53,470
many witless meat or too many RTOS we

01:14:50,290 --> 01:14:56,230
had called us for those it was 13 a

01:14:53,470 --> 01:14:58,060
level that is way too high could be

01:14:56,230 --> 01:15:00,670
based on averages or standard deviations

01:14:58,060 --> 01:15:04,090
or maybe other flow going to support the

01:15:00,670 --> 01:15:06,610
same there you could enable find your

01:15:04,090 --> 01:15:10,600
tracking you know like a packet to get

01:15:06,610 --> 01:15:11,710
more inside of a what's going on or and

01:15:10,600 --> 01:15:14,620
also you know another way would be to

01:15:11,710 --> 01:15:16,600
trigger externally and this is something

01:15:14,620 --> 01:15:19,120
that we do for right now it went bad so

01:15:16,600 --> 01:15:21,580
that we could say we could another one

01:15:19,120 --> 01:15:23,410
Troy behaving typically something's

01:15:21,580 --> 01:15:25,870
wrong the banquet is the rate is very

01:15:23,410 --> 01:15:28,750
low we don't know why you know we can do

01:15:25,870 --> 01:15:32,710
some pickup captures who could also turn

01:15:28,750 --> 01:15:35,110
on the the big so that we're going to

01:15:32,710 --> 01:15:37,270
cut to per per packet and to look at

01:15:35,110 --> 01:15:40,990
more information when we know that this

01:15:37,270 --> 01:15:44,020
flow is behaving abnormally and why not

01:15:40,990 --> 01:15:46,330
tape rose when because those are called

01:15:44,020 --> 01:15:48,130
all the time right and yes once you get

01:15:46,330 --> 01:15:50,110
cold you can decide not to do anything

01:15:48,130 --> 01:15:52,990
for that low but you get call all the

01:15:50,110 --> 01:15:54,670
time whereas with the other one you know

01:15:52,990 --> 01:15:57,190
the other heard of the bitch-slap but we

01:15:54,670 --> 01:16:00,610
can control better for which connections

01:15:57,190 --> 01:16:02,650
we want to do it and in some ways is the

01:16:00,610 --> 01:16:09,060
idea that the selection is only done

01:16:02,650 --> 01:16:09,060
once matter packet but you know what

01:16:12,110 --> 01:16:16,429
so admission is eternal trigger and the

01:16:14,869 --> 01:16:18,590
idea once again is that we want to be

01:16:16,429 --> 01:16:22,250
able to learn I think we all experience

01:16:18,590 --> 01:16:23,599
is that one of one of the flaws one of

01:16:22,250 --> 01:16:25,099
the connections will be having very of

01:16:23,599 --> 01:16:27,739
normally and then we try to figure out

01:16:25,099 --> 01:16:29,869
what's going on but we can do the TCP

01:16:27,739 --> 01:16:31,429
info you know to try to see what we see

01:16:29,869 --> 01:16:34,400
from there this would be another

01:16:31,429 --> 01:16:39,199
mechanism where we can enable finer

01:16:34,400 --> 01:16:42,219
grain cold but for TCP BPF and the idea

01:16:39,199 --> 01:16:45,679
that externally like I mentioned earlier

01:16:42,219 --> 01:16:51,050
we would trigger the callback for a TCP

01:16:45,679 --> 01:16:55,969
program sorry I could trigger the call

01:16:51,050 --> 01:16:59,059
before participating PF and then that

01:16:55,969 --> 01:17:01,699
program could do things like enable the

01:16:59,059 --> 01:17:03,409
bit so that we could get callbacks for

01:17:01,699 --> 01:17:06,380
every packet we sent or every packet we

01:17:03,409 --> 01:17:08,869
receive or anything else so for example

01:17:06,380 --> 01:17:11,210
for me I tend to play a lot with

01:17:08,869 --> 01:17:13,280
condition controls and with the

01:17:11,210 --> 01:17:15,889
mechanism we have right now in TCP BPF

01:17:13,280 --> 01:17:18,199
to set when you to control is when a

01:17:15,889 --> 01:17:21,650
connection is established but if

01:17:18,199 --> 01:17:23,900
something goes wrong for the exiting

01:17:21,650 --> 01:17:27,949
flows we don't have a good way to go

01:17:23,900 --> 01:17:29,239
back this way we could trigger a call

01:17:27,949 --> 01:17:31,190
back into TCP BPF

01:17:29,239 --> 01:17:34,070
and that is maybe a program for this

01:17:31,190 --> 01:17:37,340
particular up field which say okay fall

01:17:34,070 --> 01:17:40,510
back into cubic for example because

01:17:37,340 --> 01:17:40,510
things are propelling very badly

01:17:45,920 --> 01:17:52,650
so in terms of implementing this idea

01:17:49,760 --> 01:17:55,350
one way to do it would be similar to how

01:17:52,650 --> 01:17:58,230
we get TCP info where we would call it

01:17:55,350 --> 01:18:01,440
for all of the TCP flows we need to grab

01:17:58,230 --> 01:18:04,890
the socket lock but we will call it for

01:18:01,440 --> 01:18:07,200
all existing flows and you know the same

01:18:04,890 --> 01:18:10,440
whether it's Anguilla says we could have

01:18:07,200 --> 01:18:13,590
a filter to select the connect which

01:18:10,440 --> 01:18:16,500
connection we want to call the program

01:18:13,590 --> 01:18:18,750
and then the BPA program itself can also

01:18:16,500 --> 01:18:21,150
do its own filtering to the site even

01:18:18,750 --> 01:18:25,980
with more group finer granularity for

01:18:21,150 --> 01:18:27,570
which flows to do something it is

01:18:25,980 --> 01:18:29,700
expensive but it's probably not

01:18:27,570 --> 01:18:32,220
something we would run very often this

01:18:29,700 --> 01:18:34,380
is like the congestion control were

01:18:32,220 --> 01:18:37,530
playing with is creating habits so we

01:18:34,380 --> 01:18:39,390
want to fall back quickly or because the

01:18:37,530 --> 01:18:41,220
connection is behaving very badly and we

01:18:39,390 --> 01:18:43,140
want to figure out what's going on so it

01:18:41,220 --> 01:18:45,090
should be a rare occurrence it's not

01:18:43,140 --> 01:18:46,610
something that we run every you know a

01:18:45,090 --> 01:18:50,100
few times a second to collect statistics

01:18:46,610 --> 01:18:52,650
but just to you know to investigate a

01:18:50,100 --> 01:18:56,340
particular occurrence so typically would

01:18:52,650 --> 01:19:00,590
be driven more by human being so she'll

01:18:56,340 --> 01:19:00,590
have lower hair because of that

01:19:01,600 --> 01:19:06,620
a different way to implement it would be

01:19:04,400 --> 01:19:08,390
to only call it per connection right so

01:19:06,620 --> 01:19:11,090
we have a mechanism that we give a party

01:19:08,390 --> 01:19:13,370
which is of a particular flow and then

01:19:11,090 --> 01:19:16,640
we trigger for that one but I haven't

01:19:13,370 --> 01:19:19,370
given much thought about this particular

01:19:16,640 --> 01:19:20,570
scenario so if people have ideas I'll be

01:19:19,370 --> 01:19:23,030
interested to know you know that the

01:19:20,570 --> 01:19:26,210
best way to do that I'm more interested

01:19:23,030 --> 01:19:33,590
on the fallback for congestion control

01:19:26,210 --> 01:19:36,110
for my personal reasons other code bucks

01:19:33,590 --> 01:19:39,860
that we have in mind should prolly stay

01:19:36,110 --> 01:19:42,620
in the same place are for example for

01:19:39,860 --> 01:19:44,690
TCP CA event although that one probably

01:19:42,620 --> 01:19:47,210
nad was is too common right if we had DC

01:19:44,690 --> 01:19:50,900
TCP we get a callback every time we get

01:19:47,210 --> 01:19:52,970
a packet that has CC and enable right so

01:19:50,900 --> 01:19:55,700
it's it would be called too often so

01:19:52,970 --> 01:19:57,890
probably makes more sense for for the CA

01:19:55,700 --> 01:20:01,220
state whenever the congestion avoidance

01:19:57,890 --> 01:20:03,820
state changes and that's a good time to

01:20:01,220 --> 01:20:06,080
like if we're going to recovery or cwr

01:20:03,820 --> 01:20:08,150
then we can draw information or recover

01:20:06,080 --> 01:20:09,710
the peers congestion window and why it

01:20:08,150 --> 01:20:11,090
happen

01:20:09,710 --> 01:20:12,710
another one that to me is very

01:20:11,090 --> 01:20:15,890
interesting is that if we could trigger

01:20:12,710 --> 01:20:18,440
a callback every RTT as opposed to every

01:20:15,890 --> 01:20:21,740
packets right so it will be less

01:20:18,440 --> 01:20:24,410
granular that per packet but every TT it

01:20:21,740 --> 01:20:26,930
really allows us to get a lot of

01:20:24,410 --> 01:20:29,240
information right like things in TCP

01:20:26,930 --> 01:20:31,910
don't happen very often you know more

01:20:29,240 --> 01:20:33,740
than once per activity usually and for

01:20:31,910 --> 01:20:36,320
example when I look at pickup typically

01:20:33,740 --> 01:20:39,320
the first thing I do is just print out

01:20:36,320 --> 01:20:41,180
information state it for every RTT right

01:20:39,320 --> 01:20:44,090
how many packets we say in how many acts

01:20:41,180 --> 01:20:49,370
we got how was the RTT and just looking

01:20:44,090 --> 01:20:50,720
at the the duration of the RTT can tell

01:20:49,370 --> 01:20:53,030
me that we are nowhere to run in the

01:20:50,720 --> 01:20:55,900
later acts were you know tricking or

01:20:53,030 --> 01:20:55,900
other reasons like that

01:20:55,949 --> 01:21:04,660
yes I did look at this T CPC a state

01:21:01,719 --> 01:21:07,150
thing right and I it's a it's a bit and

01:21:04,660 --> 01:21:09,070
EPF validator gets really mad at me when

01:21:07,150 --> 01:21:10,840
I try to pass a bit around so I this

01:21:09,070 --> 01:21:12,310
might be an implementation issue right

01:21:10,840 --> 01:21:24,400
so I have to do it like it's full sock

01:21:12,310 --> 01:21:26,800
you have no but this the TCP I see a

01:21:24,400 --> 01:21:29,770
state in the TCP Sox structure it's a

01:21:26,800 --> 01:21:31,420
single bit there was there were some

01:21:29,770 --> 01:21:33,520
some stuff but I think it made might be

01:21:31,420 --> 01:21:35,050
about set of bits maybe three bits yes

01:21:33,520 --> 01:21:39,160
but when you start trying to pass big

01:21:35,050 --> 01:21:42,790
fields an hour it gets upset the so TCP

01:21:39,160 --> 01:21:44,830
vpf has support for passing things back

01:21:42,790 --> 01:21:46,120
and forth right so that might be an

01:21:44,830 --> 01:21:47,800
implementation issue we might be able to

01:21:46,120 --> 01:21:50,350
get around that but the other thing was

01:21:47,800 --> 01:21:52,210
I it calls it when it enters loss

01:21:50,350 --> 01:21:56,440
recovery but not when it's when it goes

01:21:52,210 --> 01:21:58,510
back to normal so so that was another

01:21:56,440 --> 01:22:00,760
thing I think that was done deliberately

01:21:58,510 --> 01:22:04,090
maybe because you only wanted to take

01:22:00,760 --> 01:22:08,010
the hit of calling EBP F when bad stuff

01:22:04,090 --> 01:22:10,810
happens whenever you get out of class

01:22:08,010 --> 01:22:13,140
recovery I mean just the safe state does

01:22:10,810 --> 01:22:13,140
change

01:22:14,370 --> 01:22:19,660
no that's not so this is like things are

01:22:17,380 --> 01:22:21,930
planning to to do yeah those are two

01:22:19,660 --> 01:22:21,930
things I

01:22:27,389 --> 01:22:30,830
any other questions

01:22:34,320 --> 01:22:42,300
oh you mentioned that you wanted to

01:22:40,770 --> 01:22:44,099
dynamically change the congestion

01:22:42,300 --> 01:22:48,360
control algorithm back to cubic is

01:22:44,099 --> 01:22:49,889
something wrong it has that been tested

01:22:48,360 --> 01:22:52,409
like how did you know would you

01:22:49,889 --> 01:22:54,320
reinitialize all the state and start

01:22:52,409 --> 01:22:57,030
from the initial condition window

01:22:54,320 --> 01:22:59,400
there's a very support in the kernel to

01:22:57,030 --> 01:23:02,310
change you know there's a such a caption

01:22:59,400 --> 01:23:03,690
to change the position control right and

01:23:02,310 --> 01:23:05,909
typically when it does it initializes

01:23:03,690 --> 01:23:16,949
everything like because you have no

01:23:05,909 --> 01:23:18,210
previous state so the TC BPF things

01:23:16,949 --> 01:23:20,310
you're talking about earlier I thought

01:23:18,210 --> 01:23:22,290
some of them were already implemented so

01:23:20,310 --> 01:23:24,750
that once I mentioned before what we

01:23:22,290 --> 01:23:26,550
have is what is there like in the

01:23:24,750 --> 01:23:30,360
background and then the stuff I talk

01:23:26,550 --> 01:23:33,480
about per packet see a state etc those

01:23:30,360 --> 01:23:35,099
would be new to it I see and we have a

01:23:33,480 --> 01:23:37,829
sense for when that might happen

01:23:35,099 --> 01:23:45,210
hopefully this happens hopefully what

01:23:37,829 --> 01:23:47,719
this have too much unlovely depending on

01:23:45,210 --> 01:23:47,719
Eric right

01:23:54,500 --> 01:24:01,889
okay here's a callback Artie I don't

01:24:00,119 --> 01:24:03,750
have it right about parity movie value

01:24:01,889 --> 01:24:05,789
so that is that we don't want to have

01:24:03,750 --> 01:24:08,880
too many coats right because of

01:24:05,789 --> 01:24:11,159
performance reasons so the reason I

01:24:08,880 --> 01:24:13,710
didn't put in the past per packet or you

01:24:11,159 --> 01:24:15,210
know scent packer we see that packet is

01:24:13,710 --> 01:24:17,340
because I was concerned about the earth

01:24:15,210 --> 01:24:19,469
and then knew I would get some pushback

01:24:17,340 --> 01:24:21,059
but I think there's also value and I

01:24:19,469 --> 01:24:23,760
will talk more little bit about it where

01:24:21,059 --> 01:24:26,099
we can do more intelligent analyses in

01:24:23,760 --> 01:24:28,199
the BPF program to this iPod to lock

01:24:26,099 --> 01:24:30,119
because log into March is expensive you

01:24:28,199 --> 01:24:33,270
know you were talking about the memory

01:24:30,119 --> 01:24:37,739
you know that we need to capitals so we

01:24:33,270 --> 01:24:39,239
can make some initial determination in

01:24:37,739 --> 01:24:41,789
the corner in the biggest program to

01:24:39,239 --> 01:24:44,539
decide for example try to determine when

01:24:41,789 --> 01:24:48,179
we are in an a typical situation right

01:24:44,539 --> 01:24:49,500
we could compare the performance of all

01:24:48,179 --> 01:24:53,219
of the flows target a particular

01:24:49,500 --> 01:24:56,070
particular net and if we are too far our

01:24:53,219 --> 01:24:57,599
range you know like some averages at

01:24:56,070 --> 01:25:01,050
number of standard deviations away from

01:24:57,599 --> 01:25:03,659
a from the others we wouldn't want to do

01:25:01,050 --> 01:25:05,010
something with more detail so we want to

01:25:03,659 --> 01:25:09,170
have a mechanism can track a better

01:25:05,010 --> 01:25:09,170
collection in a smart way

01:25:09,800 --> 01:25:16,010
and can you envision that time when you

01:25:12,200 --> 01:25:19,640
implemented to be packet RTG or wall

01:25:16,010 --> 01:25:21,890
time RTG so the RTT thing so it would be

01:25:19,640 --> 01:25:24,230
like typically the way we do it with PCP

01:25:21,890 --> 01:25:25,940
is like you know we start at some point

01:25:24,230 --> 01:25:27,820
and we send a packet we receive the act

01:25:25,940 --> 01:25:30,830
that's what it is right so you figured

01:25:27,820 --> 01:25:33,710
totally but by the packet and the so

01:25:30,830 --> 01:25:48,560
it's not wall time because there's no

01:25:33,710 --> 01:25:50,810
fixed architecture okay and this is what

01:25:48,560 --> 01:25:51,890
I was talking about right now is that we

01:25:50,810 --> 01:25:55,010
want to be able to do some smart

01:25:51,890 --> 01:25:57,680
filtering in TCP BPF to only log

01:25:55,010 --> 01:26:01,160
relevant events right I want to be

01:25:57,680 --> 01:26:03,320
capturing the you know the stats of

01:26:01,160 --> 01:26:05,270
every flow if they're behaving fine

01:26:03,320 --> 01:26:09,140
right there's a lot of work we want to

01:26:05,270 --> 01:26:11,180
be able to to detect a typical flows of

01:26:09,140 --> 01:26:14,180
normal flows and then estar Anala

01:26:11,180 --> 01:26:15,710
collecting more data for those and the

01:26:14,180 --> 01:26:18,860
idea is like right now we could do it

01:26:15,710 --> 01:26:22,250
trigger by you know an abnormal number

01:26:18,860 --> 01:26:24,620
of rtos or retransmissions but maybe we

01:26:22,250 --> 01:26:27,770
want to be able to be smarter about it

01:26:24,620 --> 01:26:30,500
but we also you know also statistical

01:26:27,770 --> 01:26:33,260
connect the collection of data so you do

01:26:30,500 --> 01:26:34,760
one every a thousand every 10,000 flows

01:26:33,260 --> 01:26:36,950
it would be nice to her but it would be

01:26:34,760 --> 01:26:40,100
nice to have like the whole life maybe

01:26:36,950 --> 01:26:42,740
of that particular connection as opposed

01:26:40,100 --> 01:26:44,510
to just random times for different

01:26:42,740 --> 01:26:46,870
connections which is what we can do

01:26:44,510 --> 01:26:46,870
right now

01:26:46,880 --> 01:26:51,230
so for example I mentioned before too

01:26:48,860 --> 01:26:54,469
many RT RT owes too many retransmissions

01:26:51,230 --> 01:26:56,600
for too many could be based on an

01:26:54,469 --> 01:26:58,610
average of like from a particularly data

01:26:56,600 --> 01:27:00,980
center toward talking to a particular

01:26:58,610 --> 01:27:03,139
destination you know what is the address

01:27:00,980 --> 01:27:04,880
we have and if it's abnormal then we

01:27:03,139 --> 01:27:07,550
start collecting more information for

01:27:04,880 --> 01:27:10,550
that one and logging it so it could be

01:27:07,550 --> 01:27:14,300
placed on reordering you know MSS

01:27:10,550 --> 01:27:16,699
sometimes we get situations where you

01:27:14,300 --> 01:27:18,650
know the end MSS starts decreasing badly

01:27:16,699 --> 01:27:22,219
because some packets are getting through

01:27:18,650 --> 01:27:26,350
and really hurts the performance and we

01:27:22,219 --> 01:27:26,350
want to catch those as soon as possible

01:27:28,070 --> 01:27:35,510
okay and I did say I would finish

01:27:31,400 --> 01:27:38,630
quickly so the program I build to BPF

01:27:35,510 --> 01:27:41,240
is opening new opportunities you know at

01:27:38,630 --> 01:27:43,160
federal were using it for many many

01:27:41,240 --> 01:27:46,280
different things and I think is

01:27:43,160 --> 01:27:48,650
especially true for TCP analytics and

01:27:46,280 --> 01:27:50,320
unlocking collecting information we can

01:27:48,650 --> 01:27:53,360
be smart about how we live we can do

01:27:50,320 --> 01:27:55,220
whereas would be difficult to put this

01:27:53,360 --> 01:27:57,410
instrumentation in the kernel where a

01:27:55,220 --> 01:28:00,190
BPF because we'll be fit we want the

01:27:57,410 --> 01:28:04,820
flexibility to experiment with new ideas

01:28:00,190 --> 01:28:07,610
BPF is the ideal candidate for this and

01:28:04,820 --> 01:28:09,650
so like I mentioned there's a whole

01:28:07,610 --> 01:28:12,980
bunch of new features planned for this

01:28:09,650 --> 01:28:24,080
year and we'll see how many Eric left

01:28:12,980 --> 01:28:26,870
lets us implement any questions for TCP

01:28:24,080 --> 01:28:29,480
analytics do you think you'll have the

01:28:26,870 --> 01:28:34,000
user have some capabilities or you allow

01:28:29,480 --> 01:28:34,000
everyone to install a program

01:28:35,110 --> 01:28:39,280
the problem right now is that we don't

01:28:37,630 --> 01:28:41,889
have that fine-grained control

01:28:39,280 --> 01:28:47,590
so the your a tcp/ip program you can

01:28:41,889 --> 01:28:50,499
change you know many things so yeah we

01:28:47,590 --> 01:28:52,300
will need to give it I mean for our

01:28:50,499 --> 01:28:54,400
environment it doesn't matter the people

01:28:52,300 --> 01:28:56,440
who will be doing it usually you know

01:28:54,400 --> 01:28:59,380
have full control and you know we have

01:28:56,440 --> 01:29:01,840
privileges so it's not an issue you know

01:28:59,380 --> 01:29:05,440
we need to see that there's a I need to

01:29:01,840 --> 01:29:07,030
be able to have a more finer control so

01:29:05,440 --> 01:29:09,340
that certain things are in allowed or

01:29:07,030 --> 01:29:11,170
not and you know we would need to modify

01:29:09,340 --> 01:29:12,099
this will appear so that some

01:29:11,170 --> 01:29:15,190
functionality is only available

01:29:12,099 --> 01:29:16,479
depending your capabilities and will

01:29:15,190 --> 01:29:18,820
need to visit that issue I think that

01:29:16,479 --> 01:29:20,469
can be very useful because this would be

01:29:18,820 --> 01:29:22,239
a replacement for TCP and for time

01:29:20,469 --> 01:29:23,949
stamping and all those and those are

01:29:22,239 --> 01:29:28,269
generally available you don't need any

01:29:23,949 --> 01:29:30,789
capability that's a good point yeah yeah

01:29:28,269 --> 01:29:33,010
I'll second that being able to separate

01:29:30,789 --> 01:29:34,630
the functions allows not just it's not

01:29:33,010 --> 01:29:36,190
just a question of whether you have

01:29:34,630 --> 01:29:37,479
privilege or not because know whether

01:29:36,190 --> 01:29:40,059
you want the program to run with that

01:29:37,479 --> 01:29:42,820
privilege or not we should be able to in

01:29:40,059 --> 01:29:44,380
the verifier to check the capability of

01:29:42,820 --> 01:29:47,079
course or in the program yeah and

01:29:44,380 --> 01:29:48,670
they're only allowed certain operations

01:29:47,079 --> 01:29:50,590
right like you can read field but if you

01:29:48,670 --> 01:29:52,630
don't call yes it's a corruption or

01:29:50,590 --> 01:29:56,940
those things so it should be easily

01:29:52,630 --> 01:29:56,940
there'll be super useful okay okay

01:30:03,130 --> 01:30:15,890
yes you plan something like to attach a

01:30:11,960 --> 01:30:20,440
TCP TCP BPF program to a particular

01:30:15,890 --> 01:30:27,410
socket or it still works with cgroups

01:30:20,440 --> 01:30:28,940
right now just press a group I haven't

01:30:27,410 --> 01:30:30,460
given any thought for a particular

01:30:28,940 --> 01:30:34,790
program actually offer a particular

01:30:30,460 --> 01:30:37,640
connection I don't know how how easy

01:30:34,790 --> 01:30:40,630
would be you had to be a totally

01:30:37,640 --> 01:30:43,310
different mechanism for the 4c group so

01:30:40,630 --> 01:30:47,030
yeah I'll have to look into it what did

01:30:43,310 --> 01:30:52,280
you use case for example if you don't

01:30:47,030 --> 01:30:55,120
want to use C groups just you because

01:30:52,280 --> 01:30:57,830
you don't interested it in any

01:30:55,120 --> 01:31:00,940
connection and it AC P connection just

01:30:57,830 --> 01:31:04,970
one for example you can listen on a

01:31:00,940 --> 01:31:08,120
socket server so cat C my initial goal

01:31:04,970 --> 01:31:10,790
was to allow like a global tcp v PF

01:31:08,120 --> 01:31:12,710
program that would be nice that's what I

01:31:10,790 --> 01:31:16,010
wanted in the initial part set but I was

01:31:12,710 --> 01:31:17,840
overruled and you know they said that C

01:31:16,010 --> 01:31:22,240
groups you know does the word of future

01:31:17,840 --> 01:31:22,240
so okay thank you sure

01:31:23,980 --> 01:31:31,450
I should say that if you just add a Sikh

01:31:29,110 --> 01:31:35,440
roots a group it just works for

01:31:31,450 --> 01:31:38,370
everything it's trivial to make it work

01:31:35,440 --> 01:31:41,170
for everything don't just see groups

01:31:38,370 --> 01:31:42,430
yeah you have just one see group you

01:31:41,170 --> 01:31:45,850
know like the roots see group and that's

01:31:42,430 --> 01:31:49,560
you have to create I have one question

01:31:45,850 --> 01:31:53,010
about the CP Reaper stuff for the

01:31:49,560 --> 01:31:53,010
checkpoint restore

01:31:53,360 --> 01:32:00,829
do you have that with all this info TCP

01:31:57,050 --> 01:32:03,050
BPF stuff can we freeze a TCP flow and

01:32:00,829 --> 01:32:09,230
then unfreeze it later with all the this

01:32:03,050 --> 01:32:12,440
infra back I'm not sure I fully giving

01:32:09,230 --> 01:32:15,170
with TCP PPF or understand so right now

01:32:12,440 --> 01:32:17,590
you can freeze a program with TCP which

01:32:15,170 --> 01:32:20,690
pair so you can freeze the TCP session

01:32:17,590 --> 01:32:23,360
migrate a VM whatever I'm restore the

01:32:20,690 --> 01:32:26,440
program as if it was not interrupted at

01:32:23,360 --> 01:32:30,219
all at all meaning that the program

01:32:26,440 --> 01:32:33,699
restarts where it was first

01:32:30,219 --> 01:32:40,570
what about PDF function that you loaded

01:32:33,699 --> 01:32:43,820
do we do we usually don't have any so

01:32:40,570 --> 01:32:46,489
mother the TCP people as I write have no

01:32:43,820 --> 01:32:49,130
stay typically so you will need to be

01:32:46,489 --> 01:32:51,230
running the same program on the holes

01:32:49,130 --> 01:32:52,820
where you remove the connection to and

01:32:51,230 --> 01:32:55,550
then it would be in the same situation

01:32:52,820 --> 01:32:57,199
it would keep running right but once you

01:32:55,550 --> 01:33:00,739
have stayed you had to migrate the state

01:32:57,199 --> 01:33:01,909
and I don't think that's being done so

01:33:00,739 --> 01:33:05,110
that's something that would need to be

01:33:01,909 --> 01:33:05,110
done that's a good point

01:33:15,709 --> 01:33:34,420
thank you so I'm going to follow up on

01:33:27,039 --> 01:33:34,420
the talks from Google and dCPP yes

01:33:37,460 --> 01:33:43,640
it's okay to talk about some of the use

01:33:41,960 --> 01:33:45,230
cases for both of us infra what I was

01:33:43,640 --> 01:33:47,840
looking at it right so I was looking at

01:33:45,230 --> 01:33:50,960
some client-server use cases where we

01:33:47,840 --> 01:33:52,400
were examining high availability use

01:33:50,960 --> 01:33:54,560
cases where he had a primary and a

01:33:52,400 --> 01:33:59,870
backup and their state needed to be in

01:33:54,560 --> 01:34:02,960
sync and the state was computed with a

01:33:59,870 --> 01:34:04,880
lot of CPU intensive algorithms so if

01:34:02,960 --> 01:34:06,380
the state was not in sync AJ would fail

01:34:04,880 --> 01:34:07,640
people to complain and then you get to

01:34:06,380 --> 01:34:10,940
figure out if it's an application

01:34:07,640 --> 01:34:12,530
bottleneck or a network modeling so we

01:34:10,940 --> 01:34:14,030
won't talk about these statistics that

01:34:12,530 --> 01:34:15,710
you need to figure out the application

01:34:14,030 --> 01:34:17,780
bar like because you're not deaf so

01:34:15,710 --> 01:34:20,480
let's look at the network statistics

01:34:17,780 --> 01:34:21,200
that are helpful in this case so there

01:34:20,480 --> 01:34:23,930
are two subproblems

01:34:21,200 --> 01:34:26,330
one is what's just what statistics to

01:34:23,930 --> 01:34:29,900
collect and the next one is how

01:34:26,330 --> 01:34:31,520
frequently to collect this so I was

01:34:29,900 --> 01:34:33,710
looking at the TCP chrono surface

01:34:31,520 --> 01:34:36,380
especially useful it's very neat that it

01:34:33,710 --> 01:34:38,630
splits up the connection time into the

01:34:36,380 --> 01:34:40,580
time that you were busy sending data the

01:34:38,630 --> 01:34:43,430
time you were Arwen limited in this end

01:34:40,580 --> 01:34:46,130
of limited so if you see high values for

01:34:43,430 --> 01:34:47,540
R been limited and send off limited the

01:34:46,130 --> 01:34:48,890
chances are high that it's an

01:34:47,540 --> 01:34:50,660
application bottleneck of course you

01:34:48,890 --> 01:34:52,160
could have bugs in your auto tuning and

01:34:50,660 --> 01:34:54,740
stuff like that but it's very likely

01:34:52,160 --> 01:34:56,840
that is an application problem if you're

01:34:54,740 --> 01:34:58,610
busy sending data time is hide that

01:34:56,840 --> 01:35:00,380
doesn't mean your network was good and

01:34:58,610 --> 01:35:02,780
you're fine as far as the network is

01:35:00,380 --> 01:35:05,420
concerned because the busy sending time

01:35:02,780 --> 01:35:09,260
counts both the good put as well as the

01:35:05,420 --> 01:35:10,910
time in lost recovery right so I had a

01:35:09,260 --> 01:35:13,010
discussion with Neil Cardwell from

01:35:10,910 --> 01:35:16,210
Google I said can be split up this busy

01:35:13,010 --> 01:35:18,740
time into the good put time and the

01:35:16,210 --> 01:35:20,300
congestion of Orenstein and he said yeah

01:35:18,740 --> 01:35:22,040
we looked at it we talked about it we

01:35:20,300 --> 01:35:22,850
argued a lot about it there was a lot of

01:35:22,040 --> 01:35:25,160
ambivalence

01:35:22,850 --> 01:35:27,230
there's no way to split it up so we

01:35:25,160 --> 01:35:29,900
backed away from it right so one thing

01:35:27,230 --> 01:35:31,160
that would be useful for me if sometime

01:35:29,900 --> 01:35:32,900
during this workshop or afterwards if

01:35:31,160 --> 01:35:34,400
somebody could explain to me what were

01:35:32,900 --> 01:35:36,020
the ambivalences things that you should

01:35:34,400 --> 01:35:37,640
be aware of where are the places where

01:35:36,020 --> 01:35:40,220
it's not clear

01:35:37,640 --> 01:35:42,200
going on and of course new pointed out

01:35:40,220 --> 01:35:43,610
to me that even if you're busy sending

01:35:42,200 --> 01:35:46,010
time is high and you don't have any

01:35:43,610 --> 01:35:47,540
packet loss you may not be using the

01:35:46,010 --> 01:35:49,850
network effectively simply because you

01:35:47,540 --> 01:35:52,600
may be taking a scenic route or you may

01:35:49,850 --> 01:35:57,080
have deep buffers or other problems that

01:35:52,600 --> 01:35:59,720
are not necessarily a healthy network so

01:35:57,080 --> 01:36:02,810
what was suggested to me was to compute

01:35:59,720 --> 01:36:05,750
be good but using this expression that

01:36:02,810 --> 01:36:08,150
you see here and Neil said ok compare

01:36:05,750 --> 01:36:11,330
that with the maximum possible through

01:36:08,150 --> 01:36:13,190
good what you can get which is good to

01:36:11,330 --> 01:36:15,680
know if you know the maximum possible

01:36:13,190 --> 01:36:18,260
good but which is possible if you have a

01:36:15,680 --> 01:36:19,490
dark fiber or dedicated line but if

01:36:18,260 --> 01:36:21,710
you're sharing this with somebody and

01:36:19,490 --> 01:36:23,120
you're good put varies depending on the

01:36:21,710 --> 01:36:25,370
time of the day and the time and the day

01:36:23,120 --> 01:36:26,990
of the month you need some samples to

01:36:25,370 --> 01:36:29,690
compare the variance in your good book

01:36:26,990 --> 01:36:32,780
so that takes me to the second problem

01:36:29,690 --> 01:36:34,940
how frequently the sample is and this is

01:36:32,780 --> 01:36:36,830
tricky if you sample too frequently your

01:36:34,940 --> 01:36:40,130
sampling itself will be a performance

01:36:36,830 --> 01:36:43,160
bottleneck so as I pointed out there is

01:36:40,130 --> 01:36:44,570
a cost to doing things like TCP info you

01:36:43,160 --> 01:36:45,980
don't want to be the problem yourself

01:36:44,570 --> 01:36:48,440
just because you're trying to find out

01:36:45,980 --> 01:36:49,850
if things are fine and if you sample too

01:36:48,440 --> 01:36:51,890
seldom you don't have enough int data

01:36:49,850 --> 01:36:53,210
right so for examples if the connection

01:36:51,890 --> 01:36:55,700
is running for several hours and you

01:36:53,210 --> 01:36:57,890
just have one sample on TCP close which

01:36:55,700 --> 01:36:59,150
is frequently what people do that's

01:36:57,890 --> 01:37:00,470
enough not enough to tell you what

01:36:59,150 --> 01:37:02,000
happened it's like taking one blood

01:37:00,470 --> 01:37:06,950
sample and telling me I know your whole

01:37:02,000 --> 01:37:08,480
medical history so then also if you have

01:37:06,950 --> 01:37:10,310
too many short connections and you're

01:37:08,480 --> 01:37:12,530
doing a lot of the sampling unclose

01:37:10,310 --> 01:37:13,670
there is too much sampling going on and

01:37:12,530 --> 01:37:15,200
you don't want to be doing that it's not

01:37:13,670 --> 01:37:17,540
even useful because most of the time the

01:37:15,200 --> 01:37:19,250
network is doing fine right so you

01:37:17,540 --> 01:37:21,080
really only want to monitor things when

01:37:19,250 --> 01:37:22,640
interesting things happen so interesting

01:37:21,080 --> 01:37:23,990
things are the most obvious way to say

01:37:22,640 --> 01:37:25,610
something interesting is going on as you

01:37:23,990 --> 01:37:28,310
see a lot of retransmission so you see a

01:37:25,610 --> 01:37:29,450
lot of easy encounters going up right

01:37:28,310 --> 01:37:32,570
it's the rest of the time you want to

01:37:29,450 --> 01:37:34,790
fall less frequently right and you want

01:37:32,570 --> 01:37:38,030
to define this thing of what is

01:37:34,790 --> 01:37:41,510
interesting through filters and here the

01:37:38,030 --> 01:37:44,750
TCP BPF infer actually comes in very

01:37:41,510 --> 01:37:46,400
useful right so Flores talked about the

01:37:44,750 --> 01:37:49,160
whole infrastructure and then I add

01:37:46,400 --> 01:37:52,280
a sick notification back in like

01:37:49,160 --> 01:37:54,770
November and with that I was able to

01:37:52,280 --> 01:37:56,630
actually write some pretty useful stuff

01:37:54,770 --> 01:37:57,890
if you look in the Colonel's case

01:37:56,630 --> 01:37:59,480
self-test there is actually an example

01:37:57,890 --> 01:38:00,290
which doesn't do all of this but that's

01:37:59,480 --> 01:38:04,520
most of it

01:38:00,290 --> 01:38:07,370
right so what you can do is you can set

01:38:04,520 --> 01:38:08,990
up your tcp kernel module to look at the

01:38:07,370 --> 01:38:10,970
state counters for example the

01:38:08,990 --> 01:38:14,300
retransmit counters and based on that

01:38:10,970 --> 01:38:15,620
sent a perfect back up to user space but

01:38:14,300 --> 01:38:17,540
you don't even have to send that per

01:38:15,620 --> 01:38:18,950
favore and up for each time you see

01:38:17,540 --> 01:38:22,250
something interesting going on you can

01:38:18,950 --> 01:38:24,410
use the BPF map types you can use a hash

01:38:22,250 --> 01:38:26,750
table you can track the state and

01:38:24,410 --> 01:38:28,940
periodically the application can check

01:38:26,750 --> 01:38:30,620
on things and to solve the problem of

01:38:28,940 --> 01:38:32,660
just monitoring on a particular socket

01:38:30,620 --> 01:38:34,520
what I was doing was I was setting up

01:38:32,660 --> 01:38:37,070
the fault I was using before to put a

01:38:34,520 --> 01:38:38,870
set up the hashtag hash look up and the

01:38:37,070 --> 01:38:42,230
callback would only update the taper of

01:38:38,870 --> 01:38:43,610
table if there was a match now of course

01:38:42,230 --> 01:38:45,020
this means that you get called for each

01:38:43,610 --> 01:38:46,910
socket and then you see if there's hash

01:38:45,020 --> 01:38:48,830
entry and then you won't update it which

01:38:46,910 --> 01:38:50,990
is not as efficient as saying I only

01:38:48,830 --> 01:38:54,230
call you if the socket is interested in

01:38:50,990 --> 01:38:56,420
this but it's better than nothing so

01:38:54,230 --> 01:39:01,520
this was actually quite useful and quite

01:38:56,420 --> 01:39:04,520
powerful but it still had some rough

01:39:01,520 --> 01:39:09,050
edges right the way things are set up

01:39:04,520 --> 01:39:11,150
with the whole EBP f DC infrastructure

01:39:09,050 --> 01:39:13,910
today is that the perfo whence you need

01:39:11,150 --> 01:39:15,920
one per file descriptor per CPU right so

01:39:13,910 --> 01:39:18,320
if you have 256 CPUs you need you have

01:39:15,920 --> 01:39:20,690
end up needing 256 file descriptors and

01:39:18,320 --> 01:39:22,670
to set them up is not a simple thing

01:39:20,690 --> 01:39:25,130
there's a lot of shared memory per frame

01:39:22,670 --> 01:39:26,420
there so the API czar there's like five

01:39:25,130 --> 01:39:28,700
or six API is that you have to call

01:39:26,420 --> 01:39:31,340
before you're ready to do this right and

01:39:28,700 --> 01:39:34,160
if this is this is clumsy so if I'm

01:39:31,340 --> 01:39:35,900
trying to do this monitoring in addition

01:39:34,160 --> 01:39:38,300
to like regular file and disk and

01:39:35,900 --> 01:39:40,880
network i/o I have all these and file

01:39:38,300 --> 01:39:42,590
descriptors plus my other useful work

01:39:40,880 --> 01:39:45,080
file descriptors all going on there my

01:39:42,590 --> 01:39:46,370
dispatcher gets more complicated so when

01:39:45,080 --> 01:39:48,440
I was writing this I found myself

01:39:46,370 --> 01:39:49,580
wishing that this was more POSIX like so

01:39:48,440 --> 01:39:50,530
that's one area that could use

01:39:49,580 --> 01:39:53,230
improvement

01:39:50,530 --> 01:39:55,840
right the other thing is that just

01:39:53,230 --> 01:39:58,090
intuitively TCP info is much easier to

01:39:55,840 --> 01:39:59,410
use it's a simple API it's like meta

01:39:58,090 --> 01:40:00,970
link sockets you know you do a send

01:39:59,410 --> 01:40:03,430
message you get back something or you

01:40:00,970 --> 01:40:04,630
set up TCP diag yeah clearly defined

01:40:03,430 --> 01:40:05,770
data structure you just read it and

01:40:04,630 --> 01:40:07,840
you're good right

01:40:05,770 --> 01:40:09,130
with TCP BPF you have to really know

01:40:07,840 --> 01:40:11,470
what the kernel is doing sometimes you

01:40:09,130 --> 01:40:14,290
have to massage the kernel data into

01:40:11,470 --> 01:40:16,060
other stuff to get the real-time so for

01:40:14,290 --> 01:40:18,310
example all the stuff that's trapped in

01:40:16,060 --> 01:40:20,410
the kernel for rate interval MSS cache

01:40:18,310 --> 01:40:21,760
if if what so high if what's a higher

01:40:20,410 --> 01:40:23,110
site is confusing what's in the kernel

01:40:21,760 --> 01:40:26,170
is even more confusing because you have

01:40:23,110 --> 01:40:28,660
to transform it to get real-time that's

01:40:26,170 --> 01:40:30,940
but you want to look ok and then there

01:40:28,660 --> 01:40:32,590
was the stuff about CA stayed right it's

01:40:30,940 --> 01:40:35,260
a couple of two or three bits I don't

01:40:32,590 --> 01:40:38,200
remember how many to pass that through

01:40:35,260 --> 01:40:41,830
the BPF validators takes some gymnastics

01:40:38,200 --> 01:40:45,610
it's not obvious right and the third

01:40:41,830 --> 01:40:46,180
thing here is just this I guess it's not

01:40:45,610 --> 01:40:47,770
a fault

01:40:46,180 --> 01:40:49,120
this is all being this is like building

01:40:47,770 --> 01:40:51,490
the plane as you're flying it so it's

01:40:49,120 --> 01:40:53,710
constantly in flux but it is kind of

01:40:51,490 --> 01:40:55,450
painful if the infrastructure keeps

01:40:53,710 --> 01:40:57,040
changing right there was stuff that I

01:40:55,450 --> 01:40:58,930
was work that I had working the relevant

01:40:57,040 --> 01:41:01,180
for suddenly I had moved a limb 6 so

01:40:58,930 --> 01:41:06,540
that there is some turbulence there that

01:41:01,180 --> 01:41:06,540
you have to be prepared to deal with so

01:41:07,730 --> 01:41:13,960
should be one more sling okay so seems

01:41:12,860 --> 01:41:15,110
like they don't have the last slide

01:41:13,960 --> 01:41:17,480
lately

01:41:15,110 --> 01:41:18,890
so in conclusion right so what I was

01:41:17,480 --> 01:41:21,020
hoping we'd get out of this workshop is

01:41:18,890 --> 01:41:22,940
this problem interesting what are the

01:41:21,020 --> 01:41:24,050
pain points how can we unify all of this

01:41:22,940 --> 01:41:26,270
so one of the things I was finding

01:41:24,050 --> 01:41:29,179
myself wishing is I wish we could just

01:41:26,270 --> 01:41:30,710
use the TCP vpf infra for a sink

01:41:29,179 --> 01:41:33,170
notification but have something simple

01:41:30,710 --> 01:41:35,420
being sent up like the TCP info

01:41:33,170 --> 01:41:36,890
I even tried an RFC patch said at one

01:41:35,420 --> 01:41:39,980
point but even I was not happy with it

01:41:36,890 --> 01:41:42,650
where you had your TCP BPF program send

01:41:39,980 --> 01:41:44,260
a bit return a bit value and based on

01:41:42,650 --> 01:41:46,520
that bit value you trigger a

01:41:44,260 --> 01:41:48,739
signification but then you shouldn't be

01:41:46,520 --> 01:41:50,690
using those two types of system calls to

01:41:48,739 --> 01:41:53,300
get your answer so that wasn't really a

01:41:50,690 --> 01:41:55,190
perfect solution either so one of the

01:41:53,300 --> 01:41:57,380
things working for is suggestions and

01:41:55,190 --> 01:41:59,210
you know how interesting is this problem

01:41:57,380 --> 01:42:01,610
how much do we want to invest in this

01:41:59,210 --> 01:42:04,640
do we want to really improve the perfect

01:42:01,610 --> 01:42:10,420
dapi and things like that so looking for

01:42:04,640 --> 01:42:10,420
comments here questions comments

01:42:11,499 --> 01:42:18,169
good question TCP VPS versus ebps TCP be

01:42:16,159 --> 01:42:19,999
PFC oh sorry they have an older version

01:42:18,169 --> 01:42:25,010
of slides I mean TCP we have versus TCP

01:42:19,999 --> 01:42:26,659
in for they okay

01:42:25,010 --> 01:42:29,989
I'm not sure I understood your issue

01:42:26,659 --> 01:42:32,449
with the bit yeah in the in the filter

01:42:29,989 --> 01:42:33,979
that see you need to convert you know

01:42:32,449 --> 01:42:34,129
like you need to add a new field into

01:42:33,979 --> 01:42:37,699
the

01:42:34,129 --> 01:42:39,559
suck-ups that didn't work for me the

01:42:37,699 --> 01:42:40,939
validator just got really mad at me I

01:42:39,559 --> 01:42:43,459
wasn't able to add it as just another

01:42:40,939 --> 01:42:46,249
feel like like there re trans and things

01:42:43,459 --> 01:42:48,739
like that because the validator checks

01:42:46,249 --> 01:42:51,499
to see if the size correctly matches no

01:42:48,739 --> 01:42:54,499
no but but you if your field is like

01:42:51,499 --> 01:42:57,320
small you will need to in filter that

01:42:54,499 --> 01:42:59,869
see you will need to have a that code to

01:42:57,320 --> 01:43:01,729
convert it ok we should talk about this

01:42:59,869 --> 01:43:03,679
afterwards I tried this and in any

01:43:01,729 --> 01:43:04,669
anyway after Neil pointed out to me that

01:43:03,679 --> 01:43:06,139
you really want to be looking at good

01:43:04,669 --> 01:43:09,619
port I backed away from trying to pass

01:43:06,139 --> 01:43:11,510
CSD through because as I'm selling Eric

01:43:09,619 --> 01:43:13,010
first of all if you look at a CH state

01:43:11,510 --> 01:43:15,469
it's not even obvious what does bits

01:43:13,010 --> 01:43:17,119
mean and if you pass it up and you tell

01:43:15,469 --> 01:43:21,399
me it's not an ABI so don't look at it

01:43:17,119 --> 01:43:21,399
I'm not sure I want to go there yeah

01:43:34,340 --> 01:43:40,020
about the simplicity of netlink like

01:43:37,830 --> 01:43:43,170
interface I I think Craig Garrick added

01:43:40,020 --> 01:43:45,510
two years ago something to get TCP info

01:43:43,170 --> 01:43:49,469
when you close the circuit it's a

01:43:45,510 --> 01:43:51,180
broadcast that is the ASIC notification

01:43:49,469 --> 01:43:53,670
that is the only ASIC notification yeah

01:43:51,180 --> 01:43:55,980
so I think this could be easily extended

01:43:53,670 --> 01:43:57,750
no no that's that's where I started

01:43:55,980 --> 01:43:59,460
right and but if you have a connection

01:43:57,750 --> 01:44:01,140
that's been running for like eight ten

01:43:59,460 --> 01:44:06,150
hours and you have one sample at the end

01:44:01,140 --> 01:44:09,810
of me finish you extend this Macon is to

01:44:06,150 --> 01:44:12,360
get the net additional samples whenever

01:44:09,810 --> 01:44:14,160
you detect some anomaly in your own flow

01:44:12,360 --> 01:44:17,969
not at the end of the flow but whenever

01:44:14,160 --> 01:44:21,150
you want okay call this function to to

01:44:17,969 --> 01:44:22,530
spread broadcast to any listen you mean

01:44:21,150 --> 01:44:23,940
you want to add more callbacks more

01:44:22,530 --> 01:44:25,680
racing callbacks I said I don't quite

01:44:23,940 --> 01:44:29,489
understand what is it's just a callback

01:44:25,680 --> 01:44:31,980
you need to explicitly call just this

01:44:29,489 --> 01:44:35,880
function to generate a one event one tip

01:44:31,980 --> 01:44:37,500
info to an internet link receiver yeah

01:44:35,880 --> 01:44:38,940
but you'd have to sprinkle more calls

01:44:37,500 --> 01:44:41,280
through our stack right saying

01:44:38,940 --> 01:44:42,810
broadcasting yeah but I think it could

01:44:41,280 --> 01:44:47,100
be done quite easy okay

01:44:42,810 --> 01:44:50,880
I was afraid more easy than having to

01:44:47,100 --> 01:44:52,530
deal with an LVN for sure but I thought

01:44:50,880 --> 01:44:53,969
that they would be a push back that this

01:44:52,530 --> 01:44:57,120
is going to impact performance if you

01:44:53,969 --> 01:44:58,560
start doing that and that might be a

01:44:57,120 --> 01:45:00,540
that would be a perfectly fine I think

01:44:58,560 --> 01:45:02,460
you can implement that without changing

01:45:00,540 --> 01:45:06,860
the fast path you can implement that

01:45:02,460 --> 01:45:06,860
dynamically when when you want okay

01:45:14,720 --> 01:45:18,230
 you're up next

01:45:29,430 --> 01:45:34,810
so Eric you'll accept small changes to

01:45:32,500 --> 01:45:37,900
disappear for you just suggested a new

01:45:34,810 --> 01:45:40,540
brand new event there he's ok with that

01:45:37,900 --> 01:45:42,900
ok good all right good because this all

01:45:40,540 --> 01:45:46,270
effort is to avoid changing anything I

01:45:42,900 --> 01:45:48,880
can give an additional detail about this

01:45:46,270 --> 01:45:51,730
if info having to lock the socket

01:45:48,880 --> 01:45:54,040
actually it was done because of 32-bit

01:45:51,730 --> 01:45:57,310
commands because many fields on this

01:45:54,040 --> 01:45:58,630
structure are 64-bit fields and so it's

01:45:57,310 --> 01:46:01,240
very hard to read

01:45:58,630 --> 01:46:03,730
64-bit field on a 32-bit kernel while

01:46:01,240 --> 01:46:06,550
this will are chained by soft interrupts

01:46:03,730 --> 01:46:08,620
so that's why it was done that I think

01:46:06,550 --> 01:46:11,770
that we could just remove this lock for

01:46:08,620 --> 01:46:14,860
64-bit come on so that should be easy to

01:46:11,770 --> 01:46:18,940
do we can get rid of it for 64-bit

01:46:14,860 --> 01:46:21,430
commands ok any this I'll talk a little

01:46:18,940 --> 01:46:23,530
bit about some challenges in TCP info in

01:46:21,430 --> 01:46:27,810
this ok so I'm not allowed to say which

01:46:23,530 --> 01:46:27,810
telco but this is a Nutella environment

01:46:29,800 --> 01:46:34,980
I'll go change that thing right

01:46:36,190 --> 01:46:44,010
that's the big green okay all right so

01:46:44,730 --> 01:46:53,380
this is how we so this is how we we we

01:46:51,340 --> 01:46:55,180
have this the environment is a proxy

01:46:53,380 --> 01:47:01,120
environment you have a big you have a

01:46:55,180 --> 01:47:02,920
proxy you have a proxy on one side the

01:47:01,120 --> 01:47:04,960
telcos have what they call the mobile

01:47:02,920 --> 01:47:06,970
side it could be a VLAN it could be at

01:47:04,960 --> 01:47:08,770
port on the other hand you have the

01:47:06,970 --> 01:47:13,720
network side the big bad internet is on

01:47:08,770 --> 01:47:17,230
that side the proxy on we collect stats

01:47:13,720 --> 01:47:20,430
from the left hand side and the right

01:47:17,230 --> 01:47:22,600
hand side okay so the interest here is

01:47:20,430 --> 01:47:24,490
this is not of interest to you but we

01:47:22,600 --> 01:47:28,000
also collect that stats and like Chris

01:47:24,490 --> 01:47:30,280
we push to a time series database so i

01:47:28,000 --> 01:47:33,160
unlike chris we're interested in all

01:47:30,280 --> 01:47:37,090
flows okay not just anything about 30

01:47:33,160 --> 01:47:40,590
seconds so we Paul we depend on those

01:47:37,090 --> 01:47:45,390
events the TCP disappearing for events

01:47:40,590 --> 01:47:45,390
and we also poll every five seconds

01:47:46,680 --> 01:47:52,380
here's some specs a hundred thousand

01:47:50,050 --> 01:47:53,560
transactions per second on each side

01:47:52,380 --> 01:47:59,170
okay

01:47:53,560 --> 01:48:02,710
that means 200,000 seen accepts or or or

01:47:59,170 --> 01:48:05,530
connects that happen per second on the

01:48:02,710 --> 01:48:07,210
on one box you have 1 million active

01:48:05,530 --> 01:48:08,230
flows that just flows that are still

01:48:07,210 --> 01:48:10,950
hanging there they haven't been

01:48:08,230 --> 01:48:13,210
disconnected so a total of two million

01:48:10,950 --> 01:48:14,710
this is sort of the upper bound on

01:48:13,210 --> 01:48:17,220
practice it could be a lot lower than

01:48:14,710 --> 01:48:19,540
this but we spec for this kind of stuff

01:48:17,220 --> 01:48:23,560
we need to see the beginning of the flow

01:48:19,540 --> 01:48:25,840
and the end the end is easy if we forget

01:48:23,560 --> 01:48:27,370
to Paul or we are too slow there's an

01:48:25,840 --> 01:48:28,900
event there's an ethnic event that

01:48:27,370 --> 01:48:31,080
happens that we listen to it seems

01:48:28,900 --> 01:48:34,620
everybody is using that

01:48:31,080 --> 01:48:37,950
event the beginning is kind of hard it

01:48:34,620 --> 01:48:41,580
if we time it and we pull at the right

01:48:37,950 --> 01:48:48,030
moment we will get this we'll be able to

01:48:41,580 --> 01:48:50,970
acquire this stat but often with short

01:48:48,030 --> 01:48:53,190
flows we miss them right we sampled

01:48:50,970 --> 01:48:57,780
every five seconds is that six second

01:48:53,190 --> 01:49:01,070
magic billing number that telcos like

01:48:57,780 --> 01:49:03,810
and our goal is not to lose any event

01:49:01,070 --> 01:49:06,030
this starts are stored in a time series

01:49:03,810 --> 01:49:08,640
database that is mostly for debugging I

01:49:06,030 --> 01:49:15,240
don't know what else is useful but our

01:49:08,640 --> 01:49:19,530
job is to get it there so issues a tiny

01:49:15,240 --> 01:49:21,660
tag events get dropped right you you can

01:49:19,530 --> 01:49:24,660
see there from the sheer number of those

01:49:21,660 --> 01:49:30,660
flaws closing about two hundred thousand

01:49:24,660 --> 01:49:32,220
a second hitting TCP close that you will

01:49:30,660 --> 01:49:37,140
you're bound to lose events this is a

01:49:32,220 --> 01:49:39,150
broadcast pass so polling takes a long

01:49:37,140 --> 01:49:40,860
time when you have two million flows

01:49:39,150 --> 01:49:43,440
your polling you can start putting

01:49:40,860 --> 01:49:44,640
filters but even then there's there's

01:49:43,440 --> 01:49:49,800
challenges that I'm going to talk about

01:49:44,640 --> 01:49:51,900
in a second one of the problems we have

01:49:49,800 --> 01:49:54,240
is connection setup when I when I accept

01:49:51,900 --> 01:49:56,070
happens or connect there's no event that

01:49:54,240 --> 01:50:00,840
gets generated so again it depends with

01:49:56,070 --> 01:50:03,150
the poll had a patch for this based on

01:50:00,840 --> 01:50:04,830
some work so mean II did with EBP a if I

01:50:03,150 --> 01:50:08,670
looked at I said oh I could just reuse

01:50:04,830 --> 01:50:12,180
that and it generated an event for every

01:50:08,670 --> 01:50:16,110
except for every connection setup right

01:50:12,180 --> 01:50:17,940
so so I have that event Eric I can put I

01:50:16,110 --> 01:50:20,100
can push that patch upstream if it's

01:50:17,940 --> 01:50:22,800
exciting so so now we have two events

01:50:20,100 --> 01:50:26,980
one when the socket create happens not

01:50:22,800 --> 01:50:31,880
the create but when it enters either the

01:50:26,980 --> 01:50:35,720
when it hits connect or or accept one of

01:50:31,880 --> 01:50:38,540
the established states right this is

01:50:35,720 --> 01:50:39,440
useful to us but again sensing that I'm

01:50:38,540 --> 01:50:44,900
going to have to go through a long

01:50:39,440 --> 01:50:48,080
discussions never pushed that another

01:50:44,900 --> 01:50:49,760
issue that I need tag is the filtering

01:50:48,080 --> 01:50:51,680
if you have two million flows and you're

01:50:49,760 --> 01:50:53,510
trying to do a get of these flows from

01:50:51,680 --> 01:50:57,260
the kernel you want to do some filtering

01:50:53,510 --> 01:50:58,850
I can say things like give me so what

01:50:57,260 --> 01:51:00,530
what we do is we shot right we have

01:50:58,850 --> 01:51:02,440
multiple sockets each one of them trying

01:51:00,530 --> 01:51:05,540
to filter to a subset of this flows

01:51:02,440 --> 01:51:11,330
right so but I can say like give me a

01:51:05,540 --> 01:51:13,480
just a b c d / give me all but the

01:51:11,330 --> 01:51:16,760
following subset of flaws that

01:51:13,480 --> 01:51:18,380
Bennigan's is missing the DSL that Alexa

01:51:16,760 --> 01:51:22,940
had in there is kind of useful but

01:51:18,380 --> 01:51:24,500
insufficient for it does a positive

01:51:22,940 --> 01:51:26,690
expression but not a you can't

01:51:24,500 --> 01:51:29,600
have a negation and if you want to shout

01:51:26,690 --> 01:51:31,340
across multiple sockets then you need to

01:51:29,600 --> 01:51:34,390
play games by observing what floors

01:51:31,340 --> 01:51:36,560
exist and have each socket only be

01:51:34,390 --> 01:51:41,390
responsible for a specific set of

01:51:36,560 --> 01:51:44,480
subfloors I I want to disagree the

01:51:41,390 --> 01:51:48,730
negation exists negation exists yes okay

01:51:44,480 --> 01:51:48,730
we have to talk then after this

01:51:49,170 --> 01:51:58,770
so there's other stuff that comes with

01:51:53,180 --> 01:52:00,030
with the TCP info when the socket gets

01:51:58,770 --> 01:52:01,620
closed we don't have congestion

01:52:00,030 --> 01:52:03,540
information now there's a lot of

01:52:01,620 --> 01:52:07,770
different types of congestion algorithms

01:52:03,540 --> 01:52:09,840
being used and if we missed to Paul we

01:52:07,770 --> 01:52:11,340
would have liked to see what congestion

01:52:09,840 --> 01:52:14,220
algorithm was used and it's missing in

01:52:11,340 --> 01:52:16,290
this before I sent a patch on this and

01:52:14,220 --> 01:52:18,510
it was a bit problematic and I I don't

01:52:16,290 --> 01:52:21,150
have time to follow up so I we have it

01:52:18,510 --> 01:52:22,680
working on our scenario so I didn't

01:52:21,150 --> 01:52:26,580
pursue that discussion for long

01:52:22,680 --> 01:52:29,910
PID we also want to know which which the

01:52:26,580 --> 01:52:31,710
process ID and the name of of the

01:52:29,910 --> 01:52:36,090
process that's responsible for a flow or

01:52:31,710 --> 01:52:37,770
the proxy and you can actually get you

01:52:36,090 --> 01:52:42,420
do get this information but you have to

01:52:37,770 --> 01:52:45,540
go and grok /proc to find details of the

01:52:42,420 --> 01:52:47,720
process name and P and I and PID it's

01:52:45,540 --> 01:52:50,070
extremely expensive it's an order

01:52:47,720 --> 01:52:52,470
n-cubed algorithm or something of that

01:52:50,070 --> 01:52:54,420
sort so it would be nice if we could

01:52:52,470 --> 01:53:00,030
pass this information from the kernel

01:52:54,420 --> 01:53:01,080
the kernel already knows right and I I'm

01:53:00,030 --> 01:53:05,190
not asking it has to be returned for

01:53:01,080 --> 01:53:08,460
everybody's just optional yeah SS shows

01:53:05,190 --> 01:53:11,010
the congestion control duty yes do you

01:53:08,460 --> 01:53:12,930
proc no not for the events the events

01:53:11,010 --> 01:53:15,690
don't have it talked when the socket

01:53:12,930 --> 01:53:17,430
closes when you hit TCP close this ugly

01:53:15,690 --> 01:53:19,530
gets destroyed there's one last event

01:53:17,430 --> 01:53:23,160
that gets sent but it doesn't have the

01:53:19,530 --> 01:53:26,700
congestion SS will show you the process

01:53:23,160 --> 01:53:27,240
naman and PID when you do SS minus 10 or

01:53:26,700 --> 01:53:31,170
something

01:53:27,240 --> 01:53:33,360
I mean if you do SS - t mo like mo I

01:53:31,170 --> 01:53:34,860
chose the congestion control algorithm

01:53:33,360 --> 01:53:36,360
for the live connections because the

01:53:34,860 --> 01:53:38,100
connections to the connection is still

01:53:36,360 --> 01:53:40,230
active at that all right and you can get

01:53:38,100 --> 01:53:42,450
it if you do a dump you get it but not

01:53:40,230 --> 01:53:45,180
when it when the event gets run the CC

01:53:42,450 --> 01:53:48,140
after ya action system and I had a patch

01:53:45,180 --> 01:53:48,140
that I posted actually

01:53:49,449 --> 01:53:54,890
so some resolutions we you make the

01:53:52,940 --> 01:53:57,770
socket buffer big okay

01:53:54,890 --> 01:54:01,969
we that patch that email thread if you

01:53:57,770 --> 01:54:04,250
want to take a look is where we had the

01:54:01,969 --> 01:54:08,210
congestion algorithm being sent in the

01:54:04,250 --> 01:54:10,699
event so again we try to share with

01:54:08,210 --> 01:54:14,929
multiple apps so one of the solutions to

01:54:10,699 --> 01:54:18,080
overcome the little DSL that's built

01:54:14,929 --> 01:54:21,590
into TCP info was to use classical BPF

01:54:18,080 --> 01:54:23,870
so with classical BPF when we receive

01:54:21,590 --> 01:54:27,380
the skb we could drop the packet in the

01:54:23,870 --> 01:54:32,510
kernel without having to one of our

01:54:27,380 --> 01:54:35,330
shared sockets to listen to yeah the DSL

01:54:32,510 --> 01:54:38,810
is very useful it's unlike other net

01:54:35,330 --> 01:54:42,890
link subsystems out there it's a really

01:54:38,810 --> 01:54:47,179
it has some very nice properties we

01:54:42,890 --> 01:54:49,250
could select at a socket level weather

01:54:47,179 --> 01:54:51,130
which source and destination IP and

01:54:49,250 --> 01:54:54,020
which source and destination port I

01:54:51,130 --> 01:54:55,969
think and I thought the only positive

01:54:54,020 --> 01:54:58,090
but Erik says you can do negative as

01:54:55,969 --> 01:54:58,090
well

01:54:59,670 --> 01:55:07,150
right so again I took so many Spach when

01:55:05,080 --> 01:55:09,310
she was playing with the EPF and I was

01:55:07,150 --> 01:55:11,980
able to get it to just how to generate

01:55:09,310 --> 01:55:14,590
these events and it works with no change

01:55:11,980 --> 01:55:16,960
to SS by the way if you are a smile

01:55:14,590 --> 01:55:20,680
monitoring it just works you can see the

01:55:16,960 --> 01:55:21,910
socket showing when the socket enters

01:55:20,680 --> 01:55:28,960
established state you you will see the

01:55:21,910 --> 01:55:32,080
event so after going through this

01:55:28,960 --> 01:55:34,540
exercise and having some discussions

01:55:32,080 --> 01:55:38,200
with some in here so let me look at a

01:55:34,540 --> 01:55:45,040
BPF right so so my first attempt was to

01:55:38,200 --> 01:55:47,200
take you are to just - I only wanted to

01:55:45,040 --> 01:55:48,670
use net like okay so I was using EB PF

01:55:47,200 --> 01:55:54,280
as a backdoor to generate net link

01:55:48,670 --> 01:55:57,000
events and again then we started playing

01:55:54,280 --> 01:55:57,000
around with

01:55:57,110 --> 01:56:04,099
EVP of actually generating these events

01:55:59,699 --> 01:56:04,099
the connection setup and teardown

01:56:05,179 --> 01:56:09,179
my experience of the BPF hasn't been

01:56:07,560 --> 01:56:10,949
very positive I'd like to talk to other

01:56:09,179 --> 01:56:13,250
people I mean I have to put everything

01:56:10,949 --> 01:56:14,730
in the kernel like different clangs

01:56:13,250 --> 01:56:18,630
versions

01:56:14,730 --> 01:56:23,369
I run Debian 9 maybe it's not many

01:56:18,630 --> 01:56:25,349
people are using Debbie 9 so the tooling

01:56:23,369 --> 01:56:29,310
didn't seem to work well for me right

01:56:25,349 --> 01:56:31,610
but I will download a new kernel and see

01:56:29,310 --> 01:56:31,610
how that goes

01:56:33,290 --> 01:56:40,050
it's a lot of time okay so the my

01:56:37,949 --> 01:56:44,929
initial attempts with EBP f-for events

01:56:40,050 --> 01:56:48,360
it's I noticed a lot more drops however

01:56:44,929 --> 01:56:51,210
I do see a lot of promise with the EBP F

01:56:48,360 --> 01:56:55,170
approach where you from user space you

01:56:51,210 --> 01:56:58,860
open ring to the kernel and from the

01:56:55,170 --> 01:57:03,900
kind of I can send whatever I want to it

01:56:58,860 --> 01:57:07,290
so there's some a lot of promise in what

01:57:03,900 --> 01:57:08,940
EBP F would allow me to do that some

01:57:07,290 --> 01:57:12,119
other people may have no interest at all

01:57:08,940 --> 01:57:15,420
so the events to work they require some

01:57:12,119 --> 01:57:17,429
tweaking and the tooling is still in my

01:57:15,420 --> 01:57:20,909
laptop Atlas is still work in progress

01:57:17,429 --> 01:57:23,400
and I'm I would claim I'm above average

01:57:20,909 --> 01:57:25,110
user I've downloaded all I have like

01:57:23,400 --> 01:57:30,179
four or five versions of clang in there

01:57:25,110 --> 01:57:31,860
and it and my goal is to isolate code

01:57:30,179 --> 01:57:34,530
that doesn't depend on the kind of maybe

01:57:31,860 --> 01:57:36,270
I could talk to you after this that's it

01:57:34,530 --> 01:57:39,810
for me

01:57:36,270 --> 01:57:39,810
and questions

01:57:41,540 --> 01:57:52,489
we give back the time thanks

01:57:46,540 --> 01:57:52,489
[Applause]

01:58:09,190 --> 01:58:15,940
hello everyone so here to talk about TCP

01:58:12,760 --> 01:58:18,810
analytics at Microsoft so this is more

01:58:15,940 --> 01:58:21,130
of an experience talk not much code here

01:58:18,810 --> 01:58:22,900
it's surprising that for a protocol that

01:58:21,130 --> 01:58:24,670
was like invented in the 70s

01:58:22,900 --> 01:58:26,830
we still have installed analytics but

01:58:24,670 --> 01:58:33,310
there's a pretty big problem today every

01:58:26,830 --> 01:58:35,320
day in production for us so these are

01:58:33,310 --> 01:58:37,210
the two kind of class of problems that

01:58:35,320 --> 01:58:39,280
we deal with pretty much every day day

01:58:37,210 --> 01:58:41,200
in day out the first class is

01:58:39,280 --> 01:58:43,650
connectivity and the other is

01:58:41,200 --> 01:58:46,660
performance

01:58:43,650 --> 01:58:48,760
so generally applications in the cloud

01:58:46,660 --> 01:58:50,530
when they connect when there are

01:58:48,760 --> 01:58:51,850
connection failures you know you've got

01:58:50,530 --> 01:58:55,540
a question hey why did my have failed to

01:58:51,850 --> 01:58:57,610
connect and typically the I type to list

01:58:55,540 --> 01:58:59,860
some of the common reasons why that

01:58:57,610 --> 01:59:01,600
happens there's of course net first

01:58:59,860 --> 01:59:02,980
network or infrastructure issues like

01:59:01,600 --> 01:59:08,110
your package could be getting dropped in

01:59:02,980 --> 01:59:10,240
the network sometimes there is no

01:59:08,110 --> 01:59:12,160
listening socket this actually becomes a

01:59:10,240 --> 01:59:14,920
very challenging problem to debug

01:59:12,160 --> 01:59:16,150
because a process could have died like

01:59:14,920 --> 01:59:19,960
your listening process could have died

01:59:16,150 --> 01:59:21,520
and then and and that analysis post

01:59:19,960 --> 01:59:23,830
factum right so by the time process

01:59:21,520 --> 01:59:25,300
could have spun back up as a recovery

01:59:23,830 --> 01:59:27,460
mechanism and then you don't know why

01:59:25,300 --> 01:59:28,990
this heart actually failed this means we

01:59:27,460 --> 01:59:31,210
need some sort of historical information

01:59:28,990 --> 01:59:32,730
to be able to tell that there was no

01:59:31,210 --> 01:59:35,530
listening socket

01:59:32,730 --> 01:59:38,530
listen backlog this is again like a

01:59:35,530 --> 01:59:40,570
socket API thing if your server

01:59:38,530 --> 01:59:43,660
application hasn't correctly said the

01:59:40,570 --> 01:59:45,160
backlog value it's possible that if

01:59:43,660 --> 01:59:46,990
there are too many haves have

01:59:45,160 --> 01:59:49,390
established connections that you might

01:59:46,990 --> 01:59:51,640
see failures like this again a difficult

01:59:49,390 --> 01:59:53,800
problem to debug

01:59:51,640 --> 01:59:56,120
firewall rules are a pretty big problem

01:59:53,800 --> 01:59:57,590
this could be infrastructure firewall

01:59:56,120 --> 01:59:59,780
rules or this could be application layer

01:59:57,590 --> 02:00:02,960
firewalls rules this falls outside of

01:59:59,780 --> 02:00:05,090
TCP protocol sort of debugging but ends

02:00:02,960 --> 02:00:08,450
up being a pretty common case why

02:00:05,090 --> 02:00:11,510
connectivity would fail pot exhaustion

02:00:08,450 --> 02:00:15,050
this is a big one so ephemeral ports

02:00:11,510 --> 02:00:18,350
outbound typically limited to 16 K based

02:00:15,050 --> 02:00:20,180
on the IANA ephemeral port range so if

02:00:18,350 --> 02:00:23,510
the application is making a lot of out

02:00:20,180 --> 02:00:25,250
born connect calls or if there's a

02:00:23,510 --> 02:00:27,860
socket leak which also happens to be a

02:00:25,250 --> 02:00:29,780
very common you know application bug

02:00:27,860 --> 02:00:32,000
where socket handles are leaked then you

02:00:29,780 --> 02:00:33,650
quickly run out of ports so having

02:00:32,000 --> 02:00:36,590
something in the operating system to

02:00:33,650 --> 02:00:39,610
signal this event or collect the

02:00:36,590 --> 02:00:44,840
subscale is really really critical

02:00:39,610 --> 02:00:46,700
routing msconfig this is less common but

02:00:44,840 --> 02:00:51,050
there are cases where you won't have a

02:00:46,700 --> 02:00:55,240
route to the destination and this ends

02:00:51,050 --> 02:00:57,440
up looking to the application like a

02:00:55,240 --> 02:01:00,230
sometimes you look like a firewall block

02:00:57,440 --> 02:01:04,100
but it's actually a routing problem and

02:01:00,230 --> 02:01:05,780
then there are cases where Nick drivers

02:01:04,100 --> 02:01:07,940
because there's a lot of like stateful

02:01:05,780 --> 02:01:10,070
processing being done today on middle

02:01:07,940 --> 02:01:12,950
boxes and Nick's now there are cases

02:01:10,070 --> 02:01:15,410
where you might hit a connectivity

02:01:12,950 --> 02:01:19,070
problem because the NIC failed to

02:01:15,410 --> 02:01:21,080
allocate resources and the other class

02:01:19,070 --> 02:01:23,270
is white why is TCP throughput so low

02:01:21,080 --> 02:01:24,740
this is another you know I think this is

02:01:23,270 --> 02:01:26,270
what all the previous talks have been

02:01:24,740 --> 02:01:27,969
talking about is this is what they are

02:01:26,270 --> 02:01:30,309
you know the workload owners at

02:01:27,969 --> 02:01:33,909
I need to know is like why is the

02:01:30,309 --> 02:01:36,280
performance or bad application issues so

02:01:33,909 --> 02:01:37,929
I've noted to like not posting you know

02:01:36,280 --> 02:01:39,340
data fast enough or not training fast

02:01:37,929 --> 02:01:43,239
enough those are not just the only

02:01:39,340 --> 02:01:45,849
reasons applications typically do not

02:01:43,239 --> 02:01:47,650
make any as or do not actually know how

02:01:45,849 --> 02:01:49,780
to speak underneath for example delay

02:01:47,650 --> 02:01:51,670
tax right so if you have a send and your

02:01:49,780 --> 02:01:53,619
deal a sensitive application you might

02:01:51,670 --> 02:01:57,300
want to split the sender into two cents

02:01:53,619 --> 02:02:00,699
to not hit the delay type problem but

02:01:57,300 --> 02:02:02,979
applications typically even today have

02:02:00,699 --> 02:02:05,139
no idea about how TCP works underneath

02:02:02,979 --> 02:02:07,090
and you know don't change there's any

02:02:05,139 --> 02:02:08,559
patterns to overcome those sort of

02:02:07,090 --> 02:02:11,710
problems even today we see problems

02:02:08,559 --> 02:02:13,960
where silly window syndrome kicks in or

02:02:11,710 --> 02:02:17,650
you know delay that kicks in and then

02:02:13,960 --> 02:02:20,499
there's a latency problem tcp receive

02:02:17,650 --> 02:02:21,789
window auto-tuning yeah there are

02:02:20,499 --> 02:02:23,650
algorithms in every operating system

02:02:21,789 --> 02:02:25,449
today but even today we find that there

02:02:23,650 --> 02:02:28,179
are cases where the receive window does

02:02:25,449 --> 02:02:30,400
not grow correctly and there's also a

02:02:28,179 --> 02:02:32,590
lot of misinformation out there that

02:02:30,400 --> 02:02:34,360
causes people to disable water tuning

02:02:32,590 --> 02:02:36,519
believe it or not like window scaling

02:02:34,360 --> 02:02:37,869
issues were seen in the early 2000s like

02:02:36,519 --> 02:02:40,179
when we introduced the options like

02:02:37,869 --> 02:02:42,280
routers would like reboot and such so

02:02:40,179 --> 02:02:43,809
all that information on the Internet is

02:02:42,280 --> 02:02:45,400
still there so people actually think

02:02:43,809 --> 02:02:47,349
that tis be receiving or deterring is a

02:02:45,400 --> 02:02:48,969
bad thing and they go disable window

02:02:47,349 --> 02:02:50,920
scaling and then you suddenly see that

02:02:48,969 --> 02:02:53,769
your throughput is limited to like a 64

02:02:50,920 --> 02:02:55,960
K you see window and we see this in

02:02:53,769 --> 02:02:58,090
practice even today so bubbling up

02:02:55,960 --> 02:03:01,749
statistics on that is again something

02:02:58,090 --> 02:03:04,949
that needs to be done network congestion

02:03:01,749 --> 02:03:08,949
this is somewhat outside of control of

02:03:04,949 --> 02:03:11,739
the end host but again this is a pretty

02:03:08,949 --> 02:03:13,539
common reason especially when the

02:03:11,739 --> 02:03:17,199
network is oversubscribed that we see

02:03:13,539 --> 02:03:19,539
that performance suffers when there are

02:03:17,199 --> 02:03:20,829
packet drops because most congestion

02:03:19,539 --> 02:03:25,229
control that is deployed today does

02:03:20,829 --> 02:03:25,229
react pretty negatively to packet loss

02:03:25,900 --> 02:03:31,330
application performance issues I think

02:03:28,660 --> 02:03:34,660
this kind of is probably the same as the

02:03:31,330 --> 02:03:37,270
first one but this could also be like

02:03:34,660 --> 02:03:41,650
threads not getting scheduled that would

02:03:37,270 --> 02:03:43,510
cause the throughput could be low CPU

02:03:41,650 --> 02:03:45,280
usage if the system itself is

02:03:43,510 --> 02:03:46,870
oversubscribed again I mean this is

02:03:45,280 --> 02:03:47,770
another reason why to put may not be

02:03:46,870 --> 02:03:51,340
good

02:03:47,770 --> 02:03:53,890
NIC driver issues so we have seen cases

02:03:51,340 --> 02:03:56,560
where you know the NIC driver itself

02:03:53,890 --> 02:03:58,960
could run out of you know rx buffers

02:03:56,560 --> 02:04:00,640
like it the RS buffer setting may not be

02:03:58,960 --> 02:04:03,880
set correctly so it could start dropping

02:04:00,640 --> 02:04:10,870
packets and that would cause TCP

02:04:03,880 --> 02:04:14,980
throughput to again collapse what's the

02:04:10,870 --> 02:04:16,600
typical analysis process for this so for

02:04:14,980 --> 02:04:22,480
connectivity issues what we end up

02:04:16,600 --> 02:04:25,540
typically doing is try to attempt the

02:04:22,480 --> 02:04:30,040
failure again and collect tracing and

02:04:25,540 --> 02:04:31,750
packet capture one thing that we have

02:04:30,040 --> 02:04:34,180
found really really useful is to be able

02:04:31,750 --> 02:04:35,770
to look at packet capture and tracing

02:04:34,180 --> 02:04:37,540
from the operating system at the same

02:04:35,770 --> 02:04:39,490
time so we build tooling to be able to

02:04:37,540 --> 02:04:43,480
do this this we find this to be

02:04:39,490 --> 02:04:45,370
extremely useful especially I think like

02:04:43,480 --> 02:04:48,070
having details tracing in the connection

02:04:45,370 --> 02:04:49,930
setup path where there could be a bunch

02:04:48,070 --> 02:04:55,380
of various reasons why the connection

02:04:49,930 --> 02:04:58,510
setup could fail is extremely useful for

02:04:55,380 --> 02:05:00,850
performance issues one of the things

02:04:58,510 --> 02:05:04,710
that we found very useful is to have a

02:05:00,850 --> 02:05:06,300
micro benchmark that is written

02:05:04,710 --> 02:05:08,610
you know rule out any kind of

02:05:06,300 --> 02:05:11,820
application issues so you know this

02:05:08,610 --> 02:05:14,880
could be iperf for example running iperf

02:05:11,820 --> 02:05:16,860
with the settings that are good enough

02:05:14,880 --> 02:05:18,690
to saturate the link is one of the first

02:05:16,860 --> 02:05:22,140
things we would do to rule out that this

02:05:18,690 --> 02:05:25,290
is not a network stack problem of course

02:05:22,140 --> 02:05:27,420
time sequence plots any sort of analysis

02:05:25,290 --> 02:05:28,860
of there are gaps in the capture those

02:05:27,420 --> 02:05:30,900
are things that kind of stand out

02:05:28,860 --> 02:05:35,190
typically when there's performance

02:05:30,900 --> 02:05:38,100
issues so that would be indicative of

02:05:35,190 --> 02:05:40,680
either you know an application problem

02:05:38,100 --> 02:05:42,720
or a TCP level problem but typically

02:05:40,680 --> 02:05:46,650
that's what you would look at to figure

02:05:42,720 --> 02:05:48,810
out why performance is bad we talked a

02:05:46,650 --> 02:05:51,630
lot about TCP info and his PE stats so

02:05:48,810 --> 02:05:54,120
yeah those are very widely used to

02:05:51,630 --> 02:05:56,420
figure out where the bottleneck is

02:05:54,120 --> 02:05:59,310
whether it's on the sender the receiver

02:05:56,420 --> 02:06:03,390
or or it or the connection is network

02:05:59,310 --> 02:06:05,760
limited of course CPU usage profile is

02:06:03,390 --> 02:06:07,890
another very very useful thing this is

02:06:05,760 --> 02:06:10,770
for like you know weighted call stack

02:06:07,890 --> 02:06:13,320
analysis where the CPU is being spent or

02:06:10,770 --> 02:06:14,850
you know flame graphs so basically that

02:06:13,320 --> 02:06:16,350
shows the distribution of where in the

02:06:14,850 --> 02:06:17,670
network stack most of the processing is

02:06:16,350 --> 02:06:20,040
occurring that is useful for finding

02:06:17,670 --> 02:06:22,880
like perf bottlenecks that are at very

02:06:20,040 --> 02:06:22,880
very high data rates

02:06:24,570 --> 02:06:32,050
so some of the challenges that we face

02:06:27,190 --> 02:06:36,160
today so the data rates are increasing

02:06:32,050 --> 02:06:38,080
so 40 Gbps plus collecting any sort of

02:06:36,160 --> 02:06:41,350
tracing or packet capture at that data

02:06:38,080 --> 02:06:43,630
rate is extremely challenging we end up

02:06:41,350 --> 02:06:45,010
with a lot of lost events you know the

02:06:43,630 --> 02:06:46,780
kernels are not able to keep up there's

02:06:45,010 --> 02:06:48,960
also a production performance impact

02:06:46,780 --> 02:06:51,220
when you turn on tracing in capture so

02:06:48,960 --> 02:06:54,460
one of the solution that we have been

02:06:51,220 --> 02:06:56,710
looking at is filtered tracing being

02:06:54,460 --> 02:06:59,800
able to specify the four tuple of

02:06:56,710 --> 02:07:01,750
interest or a 2-tuple of interest and

02:06:59,800 --> 02:07:04,230
being able to only collect capture or

02:07:01,750 --> 02:07:07,330
tracing for that limited set of traffic

02:07:04,230 --> 02:07:12,640
somewhat solves this problem there might

02:07:07,330 --> 02:07:15,370
also be using like having tracing that

02:07:12,640 --> 02:07:18,580
can only trace particularly events for

02:07:15,370 --> 02:07:23,950
example retransmits or congestion window

02:07:18,580 --> 02:07:26,260
events large trace and capital files

02:07:23,950 --> 02:07:28,810
these are again a problem it's at that

02:07:26,260 --> 02:07:31,240
kind of data rate one a solution we have

02:07:28,810 --> 02:07:32,470
now is automated analysis that can parse

02:07:31,240 --> 02:07:36,490
these kind of captured files

02:07:32,470 --> 02:07:37,810
automatically enlist all the connections

02:07:36,490 --> 02:07:42,760
of interest and what their performance

02:07:37,810 --> 02:07:45,550
characteristics are in the cloud one of

02:07:42,760 --> 02:07:47,170
the problems we face is that so as I

02:07:45,550 --> 02:07:48,970
said before one of the first steps we do

02:07:47,170 --> 02:07:50,680
is to try to reproduce the problem when

02:07:48,970 --> 02:07:52,120
there's like a connectivity issue or a

02:07:50,680 --> 02:07:53,740
performance issue with the repo is

02:07:52,120 --> 02:07:55,810
sometimes not consistent so it would

02:07:53,740 --> 02:07:58,210
happen like you know once every 24 hours

02:07:55,810 --> 02:08:02,380
and it's not really possible to run the

02:07:58,210 --> 02:08:03,880
tracing running like all the time so one

02:08:02,380 --> 02:08:06,850
of possible solution there is something

02:08:03,880 --> 02:08:09,760
like a flight recorder which records TCP

02:08:06,850 --> 02:08:11,740
starts of interest and keeps it in

02:08:09,760 --> 02:08:14,020
memory even after the connection dies so

02:08:11,740 --> 02:08:16,630
you can do some kind of like post

02:08:14,020 --> 02:08:19,030
analysis after the incident and go back

02:08:16,630 --> 02:08:21,280
and filter for the 4-tuple that failed

02:08:19,030 --> 02:08:23,830
and look at it starts so this is

02:08:21,280 --> 02:08:26,850
something that we have recently built

02:08:23,830 --> 02:08:26,850
and we find it very useful

02:08:27,340 --> 02:08:33,410
tc-stats so sometimes we have a problem

02:08:31,430 --> 02:08:36,380
where we have no control over the sender

02:08:33,410 --> 02:08:39,200
so if you're on the receiver the TCP

02:08:36,380 --> 02:08:41,270
stats are not very useful like there is

02:08:39,200 --> 02:08:44,270
no congestion control information

02:08:41,270 --> 02:08:46,280
available on the receiver this is a

02:08:44,270 --> 02:08:49,940
problem that we have not yet solved one

02:08:46,280 --> 02:08:51,860
of the option here would be to well a

02:08:49,940 --> 02:08:53,660
TCP option has pretty limited space so I

02:08:51,860 --> 02:08:55,760
don't think that's going to be very

02:08:53,660 --> 02:08:58,640
feasible but maybe if the application

02:08:55,760 --> 02:09:00,440
protocol is like HTTP 2 then we might

02:08:58,640 --> 02:09:02,510
have a frame or something that could

02:09:00,440 --> 02:09:04,130
communicate kind of statistics from the

02:09:02,510 --> 02:09:07,430
sender to the receiver this will require

02:09:04,130 --> 02:09:09,080
like protocol standardization work but

02:09:07,430 --> 02:09:10,460
if you are on the receive side of the

02:09:09,080 --> 02:09:12,380
connection let's say your server is like

02:09:10,460 --> 02:09:15,500
receiving data if it's our upload from a

02:09:12,380 --> 02:09:18,290
client then the visibility into ytc

02:09:15,500 --> 02:09:19,640
performances bad is very very limited so

02:09:18,290 --> 02:09:21,380
having this sort of network

02:09:19,640 --> 02:09:26,240
communication to communicate the stats

02:09:21,380 --> 02:09:28,790
might be very very useful so core

02:09:26,240 --> 02:09:31,510
topologies are a problem so things are

02:09:28,790 --> 02:09:34,250
getting extremely complicated because of

02:09:31,510 --> 02:09:37,100
virtualization as well as containers so

02:09:34,250 --> 02:09:40,010
you have multiple layers of nesting so

02:09:37,100 --> 02:09:43,130
even on an end host the network topology

02:09:40,010 --> 02:09:45,350
has become extremely complicated so

02:09:43,130 --> 02:09:47,720
having the ability to like trace the

02:09:45,350 --> 02:09:50,290
path that a network packet takes through

02:09:47,720 --> 02:09:53,099
the whole stack is again something that

02:09:50,290 --> 02:09:58,940
would be very very useful

02:09:53,099 --> 02:09:58,940
I think that's about it any questions

02:10:08,070 --> 02:10:13,920
so the flight recorder idea is pretty

02:10:10,380 --> 02:10:16,050
interesting was it TCP States or was a

02:10:13,920 --> 02:10:18,360
TCP stats that you were recording and

02:10:16,050 --> 02:10:22,230
not if it was the latter how big was the

02:10:18,360 --> 02:10:26,010
buffer yeah so the TCP statistics it is

02:10:22,230 --> 02:10:28,530
TCP statistics and it is basically a

02:10:26,010 --> 02:10:30,540
buffer that's very similar to TCP info

02:10:28,530 --> 02:10:33,120
so it's a subset of all the possible

02:10:30,540 --> 02:10:37,410
statistics that we track today and the

02:10:33,120 --> 02:10:40,260
amount of memory to use to collect those

02:10:37,410 --> 02:10:41,760
statistics is configurable so roughly

02:10:40,260 --> 02:10:44,400
how many records were you holding

02:10:41,760 --> 02:10:47,190
because if you're holding this in an

02:10:44,400 --> 02:10:48,660
internet facing thing that is like tens

02:10:47,190 --> 02:10:51,720
of thousands of conversions coming and

02:10:48,660 --> 02:10:55,200
going yeah how do you decide yeah so the

02:10:51,720 --> 02:10:56,880
the configuration is that you can set a

02:10:55,200 --> 02:10:58,680
filter you can say that I'm only

02:10:56,880 --> 02:11:00,210
interested in this four tuple or this

02:10:58,680 --> 02:11:03,480
two tuple so you can set a wild-card

02:11:00,210 --> 02:11:05,190
filter and collect just the statistics

02:11:03,480 --> 02:11:07,080
for those connections right so so I

02:11:05,190 --> 02:11:08,910
understand all of this is configurable

02:11:07,080 --> 02:11:10,830
my question was what configuration did

02:11:08,910 --> 02:11:14,640
you use like how big was it in practice

02:11:10,830 --> 02:11:16,320
that was usable like where did you end

02:11:14,640 --> 02:11:18,180
up I mean is there any data you can

02:11:16,320 --> 02:11:20,400
share with us about what was a

02:11:18,180 --> 02:11:23,160
reasonable set is this like a megabyte

02:11:20,400 --> 02:11:25,380
gigabyte yeah so I would say like people

02:11:23,160 --> 02:11:26,760
typically set it to like thousand 10,000

02:11:25,380 --> 02:11:28,440
connections all depends on how much

02:11:26,760 --> 02:11:29,970
memory there is on the server so we are

02:11:28,440 --> 02:11:32,550
finding today that the memory on the

02:11:29,970 --> 02:11:36,420
servers is pretty high so there is ample

02:11:32,550 --> 02:11:38,400
space like even in VMs you know there's

02:11:36,420 --> 02:11:40,440
ample memory for people to be able to do

02:11:38,400 --> 02:11:44,160
this this of course comes from something

02:11:40,440 --> 02:11:47,430
called as it is kernel memory so it is

02:11:44,160 --> 02:11:48,900
costly but there is enough memory to get

02:11:47,430 --> 02:11:52,730
like thousands of connections worth of

02:11:48,900 --> 02:11:52,730
data thank you

02:11:57,199 --> 02:12:00,250
any other questions

02:12:08,929 --> 02:12:15,080
hi sorry I didn't get maybe so what are

02:12:12,140 --> 02:12:17,960
you using for filter tracing is a BPF

02:12:15,080 --> 02:12:18,380
based tracing like high-level BPS trace

02:12:17,960 --> 02:12:20,900
Robin

02:12:18,380 --> 02:12:22,310
sorry so this to clarify yeah this was

02:12:20,900 --> 02:12:23,719
this has not been done on the Linux

02:12:22,310 --> 02:12:25,219
kernel I was talking about the Windows

02:12:23,719 --> 02:12:26,719
operating system but I think this is

02:12:25,219 --> 02:12:27,409
this is something that should be done in

02:12:26,719 --> 02:12:30,429
the Linux kernel

02:12:27,409 --> 02:12:30,429
ok thank you

02:12:39,330 --> 02:12:45,720
the TCP stats collection are using the

02:12:41,430 --> 02:12:49,710
TC PE stats headers that are in were

02:12:45,720 --> 02:12:51,720
using for the TCP stats so there is yeah

02:12:49,710 --> 02:12:53,430
so there's there's e stats which is

02:12:51,720 --> 02:12:54,600
based on the RFC that you quoted and

02:12:53,430 --> 02:12:56,370
that is available

02:12:54,600 --> 02:12:58,080
it does require admin it does require a

02:12:56,370 --> 02:12:59,820
numerating all connections on the system

02:12:58,080 --> 02:13:02,820
to be able to narrow the connection of

02:12:59,820 --> 02:13:05,220
interest there is also TCP info API now

02:13:02,820 --> 02:13:07,740
that you can query per on a per socket

02:13:05,220 --> 02:13:10,250
basis so there's both of them I will

02:13:07,740 --> 02:13:10,250
right now

02:13:14,079 --> 02:13:20,139
any other questions Josh

02:13:28,870 --> 02:13:32,029
[Music]

02:13:34,849 --> 02:13:39,340
I have to figure this out to you like

02:13:36,739 --> 02:13:39,340
everybody else

02:13:40,699 --> 02:13:48,860
go far okay all right uh hi

02:13:45,080 --> 02:13:53,150
so thanks for having me um Jason my work

02:13:48,860 --> 02:13:59,660
at Akamai I'm a software engineer there

02:13:53,150 --> 02:14:02,989
and yeah so we have we've had a stats

02:13:59,660 --> 02:14:07,280
collection infrastructure around TCP for

02:14:02,989 --> 02:14:11,320
quite some time and so I'm gonna talk a

02:14:07,280 --> 02:14:14,300
little bit about that and then hopefully

02:14:11,320 --> 02:14:16,900
given the context and interest in TCP

02:14:14,300 --> 02:14:20,380
BPF I'm very interested in that as well

02:14:16,900 --> 02:14:22,340
you know with an eye towards maybe

02:14:20,380 --> 02:14:25,870
converting our infrastructure to use

02:14:22,340 --> 02:14:25,870
some of that so

02:14:45,690 --> 02:14:51,750
hey I got it alright so like I said talk

02:14:49,950 --> 02:14:55,260
a little bit about you know why we're

02:14:51,750 --> 02:14:57,990
collecting all these stats I'll talk

02:14:55,260 --> 02:15:01,320
about the TCP implementation that we

02:14:57,990 --> 02:15:04,230
have around stats ours actually dates

02:15:01,320 --> 02:15:07,110
back to when the company started so it's

02:15:04,230 --> 02:15:10,470
quite old but it's it's been updated

02:15:07,110 --> 02:15:12,660
since then mostly by me I'll talk about

02:15:10,470 --> 02:15:14,940
the metrics that we're collecting and

02:15:12,660 --> 02:15:18,080
then sort of some of the requirements

02:15:14,940 --> 02:15:20,880
that we've we've had in it and hopefully

02:15:18,080 --> 02:15:24,390
we'll be able to use the TCP BPF

02:15:20,880 --> 02:15:29,490
infrastructure going forward that's

02:15:24,390 --> 02:15:32,070
that's my hope so so to give you a

02:15:29,490 --> 02:15:35,460
little bit a background about Akamai for

02:15:32,070 --> 02:15:38,090
people not familiar with it so we have

02:15:35,460 --> 02:15:43,470
you know servers all over the world and

02:15:38,090 --> 02:15:47,640
we try to redirect we cache content for

02:15:43,470 --> 02:15:51,890
lots of different companies and so one

02:15:47,640 --> 02:15:56,310
of the inputs into figuring out where to

02:15:51,890 --> 02:15:58,470
redirect users is you know some of the

02:15:56,310 --> 02:16:01,680
statistics that we collect using this

02:15:58,470 --> 02:16:04,440
disk TCP framework so that's we call

02:16:01,680 --> 02:16:07,579
that mapping which is mapping end-users

02:16:04,440 --> 02:16:10,659
to servers

02:16:07,579 --> 02:16:13,729
we also used the stats for figuring out

02:16:10,659 --> 02:16:15,619
where different bottlenecks are so

02:16:13,729 --> 02:16:21,260
everybody's talked about that already

02:16:15,619 --> 02:16:24,440
applications network we have lots of

02:16:21,260 --> 02:16:26,449
stats around delivery metrics I have

02:16:24,440 --> 02:16:27,800
some charts that I'll show you graphs

02:16:26,449 --> 02:16:29,959
that I'll show you we use it for

02:16:27,800 --> 02:16:32,120
debugging and then as people have

02:16:29,959 --> 02:16:34,519
mentioned we also use it for tuning

02:16:32,120 --> 02:16:38,660
parameters for TCP so for example sewing

02:16:34,519 --> 02:16:41,269
sea winds and things like that we can

02:16:38,660 --> 02:16:46,029
use the statistics or the stats that we

02:16:41,269 --> 02:16:48,559
gather as input into that framework so

02:16:46,029 --> 02:16:50,960
that's sort of why we're collecting them

02:16:48,559 --> 02:16:53,330
a little bit

02:16:50,960 --> 02:16:54,889
so what are we actually doing so we

02:16:53,330 --> 02:16:57,500
actually unfortunately have two

02:16:54,889 --> 02:17:01,189
infrastructures right now both in the

02:16:57,500 --> 02:17:05,540
kernel so one of them sort of for

02:17:01,189 --> 02:17:09,290
historical reasons but so one is we have

02:17:05,540 --> 02:17:11,300
this random sampling mechanism where you

02:17:09,290 --> 02:17:13,969
basically add samples every nth

02:17:11,300 --> 02:17:17,840
connection I think typically on our

02:17:13,969 --> 02:17:20,649
servers we have that set around 5% I

02:17:17,840 --> 02:17:22,969
think but it's dynamically configurable

02:17:20,649 --> 02:17:25,040
and those stats basically cover the

02:17:22,969 --> 02:17:28,399
entire connection so you could think of

02:17:25,040 --> 02:17:30,590
that as like the TCP info diag I think

02:17:28,399 --> 02:17:34,099
it's called where you know after the

02:17:30,590 --> 02:17:36,620
connection closes you can get the TCP

02:17:34,099 --> 02:17:38,929
info dumped out that's sort of what

02:17:36,620 --> 02:17:41,080
that's doing and then we have this other

02:17:38,929 --> 02:17:45,219
one which we call like object based

02:17:41,080 --> 02:17:50,389
which is basically it's used basically

02:17:45,219 --> 02:17:52,429
we have an sets a cop call but that we

02:17:50,389 --> 02:17:54,229
have that basically says start sampling

02:17:52,429 --> 02:17:57,500
now and then we have a corresponding one

02:17:54,229 --> 02:18:00,380
that says stop both using sets off top

02:17:57,500 --> 02:18:04,609
and so the way that works is basically

02:18:00,380 --> 02:18:06,679
you know the application wants to write

02:18:04,609 --> 02:18:08,730
and what we would call an object but

02:18:06,679 --> 02:18:13,720
basically just a you know

02:18:08,730 --> 02:18:16,000
you know an image or something you know

02:18:13,720 --> 02:18:18,450
it's just a set of bytes to the network

02:18:16,000 --> 02:18:22,690
and when it says start it's basically

02:18:18,450 --> 02:18:25,360
snapshots the the right sequence number

02:18:22,690 --> 02:18:27,880
and then when the when we do the stop we

02:18:25,360 --> 02:18:30,610
wait for the ACK for that one and and so

02:18:27,880 --> 02:18:34,210
we sort of do it based on these

02:18:30,610 --> 02:18:35,470
boundaries part of the motivation of

02:18:34,210 --> 02:18:37,270
this is we don't want to always be

02:18:35,470 --> 02:18:40,120
collecting the stats like people said

02:18:37,270 --> 02:18:41,620
you get lots of stats and you know we're

02:18:40,120 --> 02:18:46,360
trying to minimize the amount of stats

02:18:41,620 --> 02:18:48,280
that we have so so I'm gonna talk a

02:18:46,360 --> 02:18:52,360
little bit about those two ones so first

02:18:48,280 --> 02:18:54,220
the random sampling I think I so there's

02:18:52,360 --> 02:18:56,590
basically callbacks through the TCP

02:18:54,220 --> 02:18:58,780
layer that we have you can think of them

02:18:56,590 --> 02:19:01,180
as like kind of like the trace points

02:18:58,780 --> 02:19:03,040
that are in the kernel right now very

02:19:01,180 --> 02:19:06,310
similar to that it's just our own ones

02:19:03,040 --> 02:19:08,920
that we have so we have maybe I don't

02:19:06,310 --> 02:19:10,600
know maybe around 20 25 callbacks

02:19:08,920 --> 02:19:13,960
sprinkled through the layers it's not a

02:19:10,600 --> 02:19:16,510
ton but there's a fair number and so

02:19:13,960 --> 02:19:20,470
those are sort of where we kind of

02:19:16,510 --> 02:19:22,510
instrument into the code and yeah so the

02:19:20,470 --> 02:19:24,880
structure is like 300 bytes I'm not sure

02:19:22,510 --> 02:19:29,220
how big the TCP info is did anybody know

02:19:24,880 --> 02:19:35,500
offhand I think it's probably bigger but

02:19:29,220 --> 02:19:37,780
yeah I would guess yeah so anyway and

02:19:35,500 --> 02:19:40,330
then the way we read it is we have a dev

02:19:37,780 --> 02:19:42,640
TCP stats just a character device which

02:19:40,330 --> 02:19:44,051
we can read and pull and and we also

02:19:42,640 --> 02:19:46,270
have this forward backwards

02:19:44,051 --> 02:19:47,920
compatibility issue around TCP info we

02:19:46,270 --> 02:19:49,840
have the same thing where you know

02:19:47,920 --> 02:19:52,931
basically the user space and the kernel

02:19:49,840 --> 02:19:55,780
can agree on a version and output that

02:19:52,931 --> 02:19:59,290
it's not super interesting and then this

02:19:55,780 --> 02:20:01,640
object based one same rough idea there's

02:19:59,290 --> 02:20:04,370
callbacks throughout the TCP layer

02:20:01,640 --> 02:20:07,580
it's a little smaller and as I mentioned

02:20:04,370 --> 02:20:11,930
it basically is based around the right

02:20:07,580 --> 02:20:14,840
sequence number and then yeah so there's

02:20:11,930 --> 02:20:16,939
optional fields around for different

02:20:14,840 --> 02:20:18,830
congestion control algorithms so it's

02:20:16,939 --> 02:20:21,590
actually a variable size structure

02:20:18,830 --> 02:20:23,899
depending on which which congestion

02:20:21,590 --> 02:20:26,000
control algorithms are in place so a lot

02:20:23,899 --> 02:20:30,530
of this is around sort of customizing

02:20:26,000 --> 02:20:32,750
what stats we get to be sort of tailored

02:20:30,530 --> 02:20:35,500
to what we're doing because we're trying

02:20:32,750 --> 02:20:38,240
to minimize like I said the amount of

02:20:35,500 --> 02:20:41,930
network traffic and stats that we're

02:20:38,240 --> 02:20:44,420
collecting and then similarly if there's

02:20:41,930 --> 02:20:47,359
a character device for that which we can

02:20:44,420 --> 02:20:49,640
M map and pull and actually has a ring

02:20:47,359 --> 02:20:51,740
buffer that's this lock lifts ring

02:20:49,640 --> 02:20:53,870
buffer everybody likes to write ring

02:20:51,740 --> 02:20:57,979
buffers I do too I guess

02:20:53,870 --> 02:21:00,200
and yeah it's about getting into the

02:20:57,979 --> 02:21:03,439
details of it but basically it there's

02:21:00,200 --> 02:21:05,060
this um map the buffer and you know user

02:21:03,439 --> 02:21:10,520
space reads it and consumes all the

02:21:05,060 --> 02:21:12,319
stats so let's jump into some of the

02:21:10,520 --> 02:21:14,240
metrics I think they're probably similar

02:21:12,319 --> 02:21:18,859
to what a lot of people are already

02:21:14,240 --> 02:21:20,960
collecting but yeah so how you know

02:21:18,859 --> 02:21:23,420
bytes entry the retransmits

02:21:20,960 --> 02:21:25,750
a lot of these are in obviously the TCP

02:21:23,420 --> 02:21:25,750
info

02:21:26,080 --> 02:21:34,330
Seawind handshake minimum SR TT so these

02:21:32,830 --> 02:21:37,811
are these aren't all the fields I

02:21:34,330 --> 02:21:39,671
collect a bunch of them I wrote down we

02:21:37,811 --> 02:21:43,931
also try to get at the as I mentioned

02:21:39,671 --> 02:21:47,740
like we see when bound are we limited by

02:21:43,931 --> 02:21:53,110
the received window the remote receive

02:21:47,740 --> 02:21:56,021
window and then yeah we actually have

02:21:53,110 --> 02:22:02,801
one around TTL so that's actually the

02:21:56,021 --> 02:22:06,761
receiver TTL field we count that like

02:22:02,801 --> 02:22:11,110
the number of hops I guess to see how

02:22:06,761 --> 02:22:13,091
far things are so those are some of the

02:22:11,110 --> 02:22:15,280
stats so now I'm gonna jump into some

02:22:13,091 --> 02:22:18,101
charts so these I didn't actually

02:22:15,280 --> 02:22:19,450
realize before I started this talk what

02:22:18,101 --> 02:22:21,461
different groups do with some of these

02:22:19,450 --> 02:22:24,820
stats I've sort of worked in the kernel

02:22:21,461 --> 02:22:26,440
bit and produced the stats but I didn't

02:22:24,820 --> 02:22:28,330
realize that there's a lot of teams

02:22:26,440 --> 02:22:31,030
actually consuming them so I have a

02:22:28,330 --> 02:22:33,700
bunch of charts that other groups have

02:22:31,030 --> 02:22:36,641
done or continuously do on the network

02:22:33,700 --> 02:22:38,620
this is basically um continuous

02:22:36,641 --> 02:22:41,171
monitoring that we do I did have to

02:22:38,620 --> 02:22:43,511
cover up the if you see on the left side

02:22:41,171 --> 02:22:45,790
there sort of well it actually doesn't

02:22:43,511 --> 02:22:47,681
look too bad but I didn't want I didn't

02:22:45,790 --> 02:22:52,511
actually put in the absolute numbers

02:22:47,681 --> 02:22:56,200
here just because I I wasn't really

02:22:52,511 --> 02:22:58,540
supposed to do so I have this X here but

02:22:56,200 --> 02:23:00,940
anyway this is for like a certain region

02:22:58,540 --> 02:23:04,690
that we serve traffic from and so this

02:23:00,940 --> 02:23:07,751
is gigabytes per second over I guess the

02:23:04,690 --> 02:23:11,261
psych snapshot at this earlier in the

02:23:07,751 --> 02:23:14,860
month so this might be a little more

02:23:11,261 --> 02:23:20,910
interesting so it has this is basically

02:23:14,860 --> 02:23:24,790
sent the throughput for various

02:23:20,910 --> 02:23:30,880
objects that we're sending through the

02:23:24,790 --> 02:23:32,980
network so you can see let's see you can

02:23:30,880 --> 02:23:37,360
see like sort of when things dip down

02:23:32,980 --> 02:23:41,620
here it's actually so this is saying

02:23:37,360 --> 02:23:45,640
sorry for a given throughput how many

02:23:41,620 --> 02:23:48,030
requests are what percentage of them are

02:23:45,640 --> 02:23:50,650
sort of less than that throughput and

02:23:48,030 --> 02:23:52,330
that's what the lines are so when it

02:23:50,650 --> 02:23:53,771
goes down it actually means we're

02:23:52,330 --> 02:23:57,100
getting higher throughput because

02:23:53,771 --> 02:24:00,670
there's more a higher percentage of them

02:23:57,100 --> 02:24:03,540
or at a higher throughput so we use this

02:24:00,670 --> 02:24:06,760
or different teams that use this within

02:24:03,540 --> 02:24:08,410
the company to understand you know what

02:24:06,760 --> 02:24:19,680
what kind of performance we're getting

02:24:08,410 --> 02:24:23,110
basically okay so basically it's saying

02:24:19,680 --> 02:24:28,150
what percent so the left side is the

02:24:23,110 --> 02:24:29,800
percentage of requests know the

02:24:28,150 --> 02:24:33,910
percentage of requests that got that

02:24:29,800 --> 02:24:36,540
level of throughput so for example the I

02:24:33,910 --> 02:24:43,180
don't know just pick any of the lines

02:24:36,540 --> 02:24:46,061
it's how many you know out of a hundred

02:24:43,180 --> 02:24:48,190
out of all the requests that we get how

02:24:46,061 --> 02:24:52,200
many are getting that level of

02:24:48,190 --> 02:24:57,340
throughput so when it goes down saying

02:24:52,200 --> 02:25:00,839
you know that that percentage or getting

02:24:57,340 --> 02:25:03,149
that level which means there's you know

02:25:00,839 --> 02:25:10,729
one minus that or a hundred minus that I

02:25:03,149 --> 02:25:10,729
getting greater than that yep

02:25:17,870 --> 02:25:23,220
so why is it so nicely synchronized why

02:25:21,029 --> 02:25:25,350
is everything going up at the same time

02:25:23,220 --> 02:25:27,840
and going down at the same time that's a

02:25:25,350 --> 02:25:31,529
good question I was wondering that too

02:25:27,840 --> 02:25:35,550
based on this we'll see I have a few

02:25:31,529 --> 02:25:38,340
more charts that actually are at the

02:25:35,550 --> 02:25:40,640
same time so we'll kind of look at that

02:25:38,340 --> 02:25:44,520
and I think it'll explain that ok yeah

02:25:40,640 --> 02:25:47,850
so I mean I just snapshotted this from a

02:25:44,520 --> 02:25:49,949
bunch of charts we had internally and so

02:25:47,850 --> 02:25:51,989
I don't really have you know a lot of

02:25:49,949 --> 02:25:53,699
color around it but I think we'll see it

02:25:51,989 --> 02:25:56,010
as we go along so this was the next one

02:25:53,699 --> 02:25:57,989
so the request size so you'll see these

02:25:56,010 --> 02:26:01,109
kind of match up to the previous one

02:25:57,989 --> 02:26:03,420
those dips so this is it so what's

02:26:01,109 --> 02:26:04,620
happening is at those dips where I was

02:26:03,420 --> 02:26:07,649
saying there's actually higher

02:26:04,620 --> 02:26:15,420
throughput you see that the request size

02:26:07,649 --> 02:26:21,960
is actually bigger at those times so you

02:26:15,420 --> 02:26:24,779
know you know we're serving sort of

02:26:21,960 --> 02:26:26,489
bigger I guess the in aggregate the the

02:26:24,779 --> 02:26:30,800
objects are bigger that we're serving at

02:26:26,489 --> 02:26:32,899
those times what

02:26:30,800 --> 02:26:36,109
I guess it depends on what people are

02:26:32,899 --> 02:26:38,420
happen to be requesting so I mean it's

02:26:36,109 --> 02:26:40,760
not a huge difference I mean it's only

02:26:38,420 --> 02:26:43,159
moving around a little bit but it's

02:26:40,760 --> 02:26:44,659
basically saying that there's the things

02:26:43,159 --> 02:26:55,130
we're sending out or larger at those

02:26:44,659 --> 02:26:58,250
times and then this is the RTT and again

02:26:55,130 --> 02:27:04,970
so this chart may be a little confusing

02:26:58,250 --> 02:27:08,470
but basically saying the RTT is greater

02:27:04,970 --> 02:27:12,260
than the percentage of requests that are

02:27:08,470 --> 02:27:17,239
greater than art than a given RTT so

02:27:12,260 --> 02:27:19,909
each line is a certain RTT that that's

02:27:17,239 --> 02:27:22,670
measured in the network and so when the

02:27:19,909 --> 02:27:29,350
lines here dip down it's basically

02:27:22,670 --> 02:27:36,739
saying that the there's fewer or the rtt

02:27:29,350 --> 02:27:38,979
is is is actually getting lower in this

02:27:36,739 --> 02:27:38,979
case

02:27:40,750 --> 02:27:56,690
and then here's retransmits over time

02:27:49,120 --> 02:27:58,311
and and now here's another chart this

02:27:56,690 --> 02:28:01,180
one doesn't line up with the previous

02:27:58,311 --> 02:28:05,450
ones but it's basically breaking down

02:28:01,180 --> 02:28:09,260
the request into we were application

02:28:05,450 --> 02:28:12,710
bound see when bound or arlynn bound so

02:28:09,260 --> 02:28:16,760
from this chart you can see most things

02:28:12,710 --> 02:28:19,790
are network mount or a network bound I

02:28:16,760 --> 02:28:23,620
know if that's expected or not I I mean

02:28:19,790 --> 02:28:26,900
I I would expect that I guess and then

02:28:23,620 --> 02:28:29,660
receiver bound and then we have this

02:28:26,900 --> 02:28:33,290
metric around whether you know or

02:28:29,660 --> 02:28:35,660
application bound so luckily that or I

02:28:33,290 --> 02:28:39,440
think it's a positive that that's

02:28:35,660 --> 02:28:41,590
smaller but but I there's some

02:28:39,440 --> 02:28:43,700
percentage of time that we're bound by

02:28:41,590 --> 02:28:48,290
you know the application that we're

02:28:43,700 --> 02:28:51,950
sending with so that's sort of a little

02:28:48,290 --> 02:28:54,710
bit around some of the metrics so this

02:28:51,950 --> 02:28:57,920
was sort of just some just me thinking

02:28:54,710 --> 02:29:02,180
about what we would need from TCP BPF to

02:28:57,920 --> 02:29:05,660
move our infrastructure onto it

02:29:02,180 --> 02:29:07,670
so you know this is very open I'm not

02:29:05,660 --> 02:29:10,460
saying this is how it should be but it's

02:29:07,670 --> 02:29:15,620
just kind of my brainstorming so I sort

02:29:10,460 --> 02:29:17,330
of had you know similar ideas to some I

02:29:15,620 --> 02:29:20,990
guess people have already spoken about

02:29:17,330 --> 02:29:24,340
this so you know we have these callbacks

02:29:20,990 --> 02:29:27,110
or trace points through the kernel

02:29:24,340 --> 02:29:30,290
so I like the idea of having this per

02:29:27,110 --> 02:29:33,560
socket flag I know somebody are lawrence

02:29:30,290 --> 02:29:35,860
i guess it suggested that earlier I sort

02:29:33,560 --> 02:29:39,380
of was thinking along the same lines as

02:29:35,860 --> 02:29:42,320
that because basically we don't want the

02:29:39,380 --> 02:29:44,570
overhead when were you know not tracing

02:29:42,320 --> 02:29:48,980
it we're not interested in those

02:29:44,570 --> 02:29:50,390
particular sockets so I don't know that

02:29:48,980 --> 02:29:52,910
was sort of one idea the other thing

02:29:50,390 --> 02:29:56,000
though - that is important for us is to

02:29:52,910 --> 02:29:57,800
be able to not so once we get into the

02:29:56,000 --> 02:30:00,410
BPF program I don't want to have to go

02:29:57,800 --> 02:30:03,980
and look up either in a hash table or

02:30:00,410 --> 02:30:06,350
something to find sort of my record so I

02:30:03,980 --> 02:30:11,930
definitely wanted to have some local

02:30:06,350 --> 02:30:14,270
storage that's sort of per socket so the

02:30:11,930 --> 02:30:17,150
API was sort of suggesting maybe is to

02:30:14,270 --> 02:30:21,170
sort of when we enable these the tracing

02:30:17,150 --> 02:30:23,810
to be able to pass in a map so that was

02:30:21,170 --> 02:30:27,260
just one idea so there are plans to

02:30:23,810 --> 02:30:30,530
introduce for a socket storage for BPF

02:30:27,260 --> 02:30:33,620
yeah so you know you would create it and

02:30:30,530 --> 02:30:36,910
then you can access it directly so it

02:30:33,620 --> 02:30:42,170
will replace a lot of the use of maps

02:30:36,910 --> 02:30:47,600
okay so would we be able to specify one

02:30:42,170 --> 02:30:48,980
from user space like a specific map so

02:30:47,600 --> 02:30:51,110
it's not a map but it will be an area

02:30:48,980 --> 02:30:54,140
another site that belongs per socket and

02:30:51,110 --> 02:30:57,410
per bps program so the beeping program

02:30:54,140 --> 02:30:59,750
can store data right that it can access

02:30:57,410 --> 02:31:01,880
all the time so that if you are want to

02:30:59,750 --> 02:31:03,530
keep track of like the old stats and the

02:31:01,880 --> 02:31:05,960
difference of the new starts to trigger

02:31:03,530 --> 02:31:08,180
something because some country increased

02:31:05,960 --> 02:31:11,000
too much you could do it just locally as

02:31:08,180 --> 02:31:12,230
opposed to having to have a map that you

02:31:11,000 --> 02:31:14,390
had to access and and there will be a

02:31:12,230 --> 02:31:15,921
mechanism to read it from user space - I

02:31:14,390 --> 02:31:22,620
see okay

02:31:15,921 --> 02:31:25,320
that might work for us okay so that's

02:31:22,620 --> 02:31:28,771
just some ideas there and then I think

02:31:25,320 --> 02:31:30,660
similarly too I think people have talked

02:31:28,771 --> 02:31:33,091
about how do we actually read them so

02:31:30,660 --> 02:31:37,141
one idea was to used peripheral for

02:31:33,091 --> 02:31:40,500
structure so the TCP info like I said

02:31:37,141 --> 02:31:42,990
before is interesting but a lot of we

02:31:40,500 --> 02:31:44,671
probably are only interested in us or we

02:31:42,990 --> 02:31:47,761
are interested in a subset of those

02:31:44,671 --> 02:31:51,360
fields so we'd like to tailor it to sort

02:31:47,761 --> 02:31:55,051
of our use case so we felt or I was

02:31:51,360 --> 02:32:00,530
thinking that the the perf output where

02:31:55,051 --> 02:32:03,870
you can sort of specify exactly which

02:32:00,530 --> 02:32:06,990
you know which field you want would be a

02:32:03,870 --> 02:32:12,570
better fit and you know we can map and

02:32:06,990 --> 02:32:16,410
read that so just comparing at least for

02:32:12,570 --> 02:32:18,841
me the this you know trying to use EPF

02:32:16,410 --> 02:32:22,830
versus what we have right now so we have

02:32:18,841 --> 02:32:25,500
you know a fairly substantial out of

02:32:22,830 --> 02:32:29,400
tree patches for this so we could

02:32:25,500 --> 02:32:33,450
hopefully get rid of that you know the

02:32:29,400 --> 02:32:34,860
proposal or I I sort of was thinking of

02:32:33,450 --> 02:32:37,141
it as more general has been being

02:32:34,860 --> 02:32:39,330
specific to TCP I was thinking of it as

02:32:37,141 --> 02:32:43,171
being a mechanism that could trace all

02:32:39,330 --> 02:32:47,540
socket types I'm not sure if that's sort

02:32:43,171 --> 02:32:50,370
of in the thinking for this right now

02:32:47,540 --> 02:32:51,860
you know being able to just use the

02:32:50,370 --> 02:32:56,341
fields that you're interested in is

02:32:51,860 --> 02:32:58,950
definitely important to us one concern I

02:32:56,341 --> 02:33:01,320
sort of had though regarding all this is

02:32:58,950 --> 02:33:05,370
okay we implement all this but now sort

02:33:01,320 --> 02:33:07,740
of all the logic around the metrics is

02:33:05,370 --> 02:33:10,351
out of tree now so everybody might be

02:33:07,740 --> 02:33:12,440
doing it differently but on the other

02:33:10,351 --> 02:33:12,440
hand

02:33:12,470 --> 02:33:18,790
you know repositories that keep TCP

02:33:15,950 --> 02:33:18,790
programs and

02:33:20,290 --> 02:33:25,340
so I don't know if that's a major

02:33:23,210 --> 02:33:27,050
concern but it's just a point that you

02:33:25,340 --> 02:33:29,510
know I think it's nice to be able to

02:33:27,050 --> 02:33:31,100
leverage you know obviously the metrics

02:33:29,510 --> 02:33:33,710
that different people are collecting and

02:33:31,100 --> 02:33:34,880
to be able to reuse that so I don't

02:33:33,710 --> 02:33:38,720
really see that in his issue but I

02:33:34,880 --> 02:33:40,480
thought I'd mention it and that's

02:33:38,720 --> 02:33:43,460
basically all I have

02:33:40,480 --> 02:33:45,710
so one comment is all the metrics they

02:33:43,460 --> 02:33:47,660
sure are really a subset of TCP info so

02:33:45,710 --> 02:33:50,450
there's really no reason you cannot use

02:33:47,660 --> 02:33:52,370
TC painful other than that you think

02:33:50,450 --> 02:33:54,920
it's too much it's too big update

02:33:52,370 --> 02:33:56,030
structure is that right well I didn't

02:33:54,920 --> 02:33:57,920
yeah

02:33:56,030 --> 02:34:00,710
so in terms of the metrics were

02:33:57,920 --> 02:34:02,870
collecting there are some I I believe

02:34:00,710 --> 02:34:07,640
that aren't in TCP info so for example

02:34:02,870 --> 02:34:11,690
handshake rtt is one that we look at is

02:34:07,640 --> 02:34:14,900
the TTL field in TCP info and no I mean

02:34:11,690 --> 02:34:16,610
there's and this is actually a subset of

02:34:14,900 --> 02:34:18,500
the ones we have we actually collect

02:34:16,610 --> 02:34:22,100
more I didn't list every single one that

02:34:18,500 --> 02:34:24,680
we have so there's yeah two issues one

02:34:22,100 --> 02:34:27,680
is it's not they're not all in TCP info

02:34:24,680 --> 02:34:29,930
and the other one like I said is it's

02:34:27,680 --> 02:34:33,790
it's more you know there's some that

02:34:29,930 --> 02:34:36,140
we're not necessarily interested in so I

02:34:33,790 --> 02:34:38,540
personally like the idea of being able

02:34:36,140 --> 02:34:40,250
to you know customize that's sort of why

02:34:38,540 --> 02:34:42,771
we have our own implementation to some

02:34:40,250 --> 02:34:44,930
extent is that it's very customized to

02:34:42,771 --> 02:34:46,790
the stats that we're interested in so if

02:34:44,930 --> 02:34:49,070
there are things that are interesting

02:34:46,790 --> 02:34:50,720
but are not a DC painful it's better to

02:34:49,070 --> 02:34:53,210
get them into DC painful right rather

02:34:50,720 --> 02:34:55,311
than happies out of three things one are

02:34:53,210 --> 02:34:57,550
things they might be useful to other

02:34:55,311 --> 02:34:59,860
people as well right that's true

02:34:57,550 --> 02:35:02,440
yeah we could try if people are

02:34:59,860 --> 02:35:04,271
interested in I'm happy to try to add

02:35:02,440 --> 02:35:06,721
them to it yeah

02:35:04,271 --> 02:35:06,721
that make sense

02:35:14,900 --> 02:35:22,591
hi so I'm quite interested in that

02:35:19,591 --> 02:35:25,950
semantical the details of the get sucked

02:35:22,591 --> 02:35:27,511
opt so in our case one of the problems

02:35:25,950 --> 02:35:30,841
we're struggling is comparing the

02:35:27,511 --> 02:35:33,721
throughput of user which receives a

02:35:30,841 --> 02:35:36,931
dozen of simple index HTML pages which

02:35:33,721 --> 02:35:39,601
each of them is 4k to a user which

02:35:36,931 --> 02:35:43,710
downloads 100 kilobytes piece of data is

02:35:39,601 --> 02:35:46,021
unfair so what we're trying to do is

02:35:43,710 --> 02:35:48,841
we're trying to measure the counters

02:35:46,021 --> 02:35:50,761
more per request as opposed to per

02:35:48,841 --> 02:35:51,660
connection so it doesn't really fit that

02:35:50,761 --> 02:35:54,811
it's bientt model

02:35:51,660 --> 02:35:56,761
you mentioned that in your case the set

02:35:54,811 --> 02:35:59,851
sock of when you disable the

02:35:56,761 --> 02:36:02,820
measurements it synchronizes it waits

02:35:59,851 --> 02:36:04,681
for the final acknowledgment is that it

02:36:02,820 --> 02:36:06,421
doesn't allow you basically to wait till

02:36:04,681 --> 02:36:08,521
all the data was currently sent and

02:36:06,421 --> 02:36:10,040
basically get counters per request as

02:36:08,521 --> 02:36:14,370
opposed to per connection

02:36:10,040 --> 02:36:16,351
yes yeah so it's really a around the

02:36:14,370 --> 02:36:19,381
request like you mentioned so to be

02:36:16,351 --> 02:36:21,360
specific the start you know snapshots

02:36:19,381 --> 02:36:22,830
the right sequence number so this the

02:36:21,360 --> 02:36:24,540
statistics really don't start counting

02:36:22,830 --> 02:36:25,740
until we hit that right one right

02:36:24,540 --> 02:36:27,631
because there could be a lot in the

02:36:25,740 --> 02:36:32,101
right buffer ready and then similarly

02:36:27,631 --> 02:36:34,410
for the the stop we again snapshot the

02:36:32,101 --> 02:36:37,311
right sequence number but we don't stop

02:36:34,410 --> 02:36:42,391
collecting until we hit the final

02:36:37,311 --> 02:36:44,580
acknowledgment for that so and actually

02:36:42,391 --> 02:36:47,040
our API is pretty general and cannot

02:36:44,580 --> 02:36:49,921
allow overlapping and you can deal with

02:36:47,040 --> 02:36:52,681
all that kind of thing so you could have

02:36:49,921 --> 02:36:54,631
two starts in a row or it doesn't really

02:36:52,681 --> 02:36:59,101
understand what the user space is doing

02:36:54,631 --> 02:37:02,150
but it'll output the records so it

02:36:59,101 --> 02:37:02,150
sounds like that's what you're asking

02:37:02,881 --> 02:37:09,131
do you have any bottlenecks like the

02:37:05,471 --> 02:37:10,301
socket lock that sorry machine um in

02:37:09,131 --> 02:37:14,950
terms of locks

02:37:10,301 --> 02:37:18,511
well sets aa cop takes a lock already by

02:37:14,950 --> 02:37:21,610
default I believe right oh well actually

02:37:18,511 --> 02:37:24,940
certain ones I think it drops in certain

02:37:21,610 --> 02:37:34,631
cases right but so you're asking around

02:37:24,940 --> 02:37:36,541
the cycle yeah so our cost yeah so we

02:37:34,631 --> 02:37:39,641
don't have any locks they're like the

02:37:36,541 --> 02:37:42,251
you know as the statistics are getting

02:37:39,641 --> 02:37:46,181
gathered you know TCP does its own

02:37:42,251 --> 02:37:49,381
locking that already does and then when

02:37:46,181 --> 02:37:49,381
we output the records

02:37:55,561 --> 02:38:01,360
well the get call well we don't have a

02:37:59,021 --> 02:38:07,631
get call basically because we're reading

02:38:01,360 --> 02:38:14,671
them asynchronously so so we don't we

02:38:07,631 --> 02:38:18,161
don't have a so for request based like

02:38:14,671 --> 02:38:20,650
looking at a sequence number capturing

02:38:18,161 --> 02:38:23,261
TCP stats and then receiving the arc for

02:38:20,650 --> 02:38:26,851
that and then giving it to user space so

02:38:23,261 --> 02:38:29,980
time stamping with ops that does that so

02:38:26,851 --> 02:38:34,240
why don't you just aren't you just using

02:38:29,980 --> 02:38:36,520
the timestamp Bank so you can like on a

02:38:34,240 --> 02:38:39,669
send message you can give a

02:38:36,520 --> 02:38:45,009
see message there's even not that reason

02:38:39,669 --> 02:38:47,049
to do a extra disco you tell I want this

02:38:45,009 --> 02:38:51,640
send message to beat race and then you

02:38:47,049 --> 02:38:54,009
collect the TCP info and on a consent

02:38:51,640 --> 02:38:56,409
and you have this stats right

02:38:54,009 --> 02:38:58,239
so you're saying I've just understand

02:38:56,409 --> 02:39:01,720
where you're saying that using the

02:38:58,239 --> 02:39:07,689
existing send message with time stamping

02:39:01,720 --> 02:39:09,640
would cover that use case yes okay yeah

02:39:07,689 --> 02:39:14,259
I mean if I understand the details of it

02:39:09,640 --> 02:39:17,009
better it might work like I said TCP

02:39:14,259 --> 02:39:20,319
impose a lot bigger than what we need

02:39:17,009 --> 02:39:22,089
well the time something we don't have

02:39:20,319 --> 02:39:26,979
all of the fields in TCP in photos

02:39:22,089 --> 02:39:28,629
smaller there is there are certainly

02:39:26,979 --> 02:39:33,819
fields there that you might not need

02:39:28,629 --> 02:39:36,220
yeah yeah I mean it might I think a lot

02:39:33,819 --> 02:39:40,539
of them are pretty close fits I think

02:39:36,220 --> 02:39:43,209
like I've kind of I think the the crux

02:39:40,539 --> 02:39:45,249
for me at least is you know with

02:39:43,209 --> 02:39:49,419
something like PPF we can get exactly

02:39:45,249 --> 02:39:51,479
what we want so and I think that's where

02:39:49,419 --> 02:39:54,909
most people are thinking this is headed

02:39:51,479 --> 02:39:56,710
so you know it seems like a good

02:39:54,909 --> 02:39:59,710
direction

02:39:56,710 --> 02:40:03,370
and for the size of TCP info is it the

02:39:59,710 --> 02:40:06,090
size of read and write to ram that is

02:40:03,370 --> 02:40:09,070
the public for you or storing this yeah

02:40:06,090 --> 02:40:10,360
that's a good question I think it's more

02:40:09,070 --> 02:40:11,680
probably around the stores because we

02:40:10,360 --> 02:40:14,229
have to then pump all these stats

02:40:11,680 --> 02:40:17,770
through our whole network so if we

02:40:14,229 --> 02:40:19,600
double the size of it what we need well

02:40:17,770 --> 02:40:27,850
I guess we could drop it when I send it

02:40:19,600 --> 02:40:30,910
right oh right yeah I mean it's just

02:40:27,850 --> 02:40:31,920
more to read out and you know trying to

02:40:30,910 --> 02:40:35,139
be as efficient as possible

02:40:31,920 --> 02:40:35,139
[Music]

02:40:36,930 --> 02:40:40,500
any other questions

02:40:51,660 --> 02:40:57,330
[Applause]

02:41:10,450 --> 02:41:16,990
hello this is Jay Chou I work for a

02:41:14,630 --> 02:41:19,190
company called by said we are the

02:41:16,990 --> 02:41:21,940
company that actually makes the

02:41:19,190 --> 02:41:26,300
satellite and then provide the broadband

02:41:21,940 --> 02:41:31,790
internet services to let's say airplanes

02:41:26,300 --> 02:41:33,500
and stuff like that okay so I'm gonna

02:41:31,790 --> 02:41:36,320
actually talk about a little bit about

02:41:33,500 --> 02:41:39,800
like you know what we do in terms of

02:41:36,320 --> 02:41:41,750
like you know why we need a TCP

02:41:39,800 --> 02:41:45,730
performance and and and all that stuff

02:41:41,750 --> 02:41:50,120
so if you actually look at you know this

02:41:45,730 --> 02:41:51,830
picture you know one of the things that

02:41:50,120 --> 02:41:55,400
we actually provide is actually

02:41:51,830 --> 02:41:58,400
broadband gyro juicer like you know link

02:41:55,400 --> 02:42:01,280
based you know Internet services which

02:41:58,400 --> 02:42:04,971
actually provides like hundreds of movie

02:42:01,280 --> 02:42:07,160
pieces of speed with more than 500

02:42:04,971 --> 02:42:11,090
milliseconds of RDT that actually give

02:42:07,160 --> 02:42:14,480
us huge you know be DP which is actually

02:42:11,090 --> 02:42:17,960
very hard to you know manage and and not

02:42:14,480 --> 02:42:19,971
only that but you know the acts are

02:42:17,960 --> 02:42:22,971
actually coming back with like a 500

02:42:19,971 --> 02:42:25,370
millisecond delay so we are actually at

02:42:22,971 --> 02:42:27,590
any congestion control algorithm is

02:42:25,370 --> 02:42:30,320
actually dealing with 500 millisecond

02:42:27,590 --> 02:42:35,061
late information so it's it's actually

02:42:30,320 --> 02:42:38,000
very tough and also any packet

02:42:35,061 --> 02:42:40,550
retransmission actually happening on the

02:42:38,000 --> 02:42:43,550
satellite link is gonna hold up the

02:42:40,550 --> 02:42:46,010
other pipe so it's gonna drain the pipe

02:42:43,550 --> 02:42:47,960
because you cannot really the TCP cannot

02:42:46,010 --> 02:42:51,940
really you know transmit the new packets

02:42:47,960 --> 02:42:54,891
during the RTT where we actually see the

02:42:51,940 --> 02:42:57,880
debris transmissions so after the

02:42:54,891 --> 02:43:01,240
retransmission so that actually cause

02:42:57,880 --> 02:43:03,580
you know a lot of performance issues so

02:43:01,240 --> 02:43:06,060
in order to

02:43:03,580 --> 02:43:10,330
you know address this performance issue

02:43:06,060 --> 02:43:10,899
typically we use you know the proxy

02:43:10,330 --> 02:43:14,229
Nance

02:43:10,899 --> 02:43:16,810
enhancing proxy and also use active

02:43:14,229 --> 02:43:19,870
queue management to use ecn rather than

02:43:16,810 --> 02:43:24,700
packet drop on the satellite link so in

02:43:19,870 --> 02:43:26,700
this graph you know as you can see the

02:43:24,700 --> 02:43:30,790
end-to-end TCP connections will

02:43:26,700 --> 02:43:34,689
typically you know cut into three

02:43:30,790 --> 02:43:39,130
different pieces and you know two paths

02:43:34,689 --> 02:43:41,200
to TCP PAP one in the the hop size and

02:43:39,130 --> 02:43:43,210
then one in on the the remote station

02:43:41,200 --> 02:43:47,500
will actually maintain its own TCP

02:43:43,210 --> 02:43:50,649
connection okay so basically you know

02:43:47,500 --> 02:43:54,790
that is the setup that we have and I

02:43:50,649 --> 02:43:57,130
think the majority of you know the

02:43:54,790 --> 02:44:00,550
traffic in terms of volume is still TCP

02:43:57,130 --> 02:44:03,100
although quick is actually catching up

02:44:00,550 --> 02:44:07,060
so it is actually very important for us

02:44:03,100 --> 02:44:12,399
to actually manage the TCP especially

02:44:07,060 --> 02:44:14,350
with the pet performance okay so so that

02:44:12,399 --> 02:44:18,550
actually gave enough reason for us to

02:44:14,350 --> 02:44:21,609
monitor TCP performances and also I

02:44:18,550 --> 02:44:25,450
didn't actually mention here going

02:44:21,609 --> 02:44:27,899
further the infrastructure of you know

02:44:25,450 --> 02:44:32,380
mobile edge computing is actually coming

02:44:27,899 --> 02:44:35,380
you know it's pretty big that means you

02:44:32,380 --> 02:44:40,870
know mobile edge computing means in in

02:44:35,380 --> 02:44:43,000
in this graph you know the TCP PAP we

02:44:40,870 --> 02:44:45,840
might actually have a mobile edge

02:44:43,000 --> 02:44:51,040
computing you know platform so using

02:44:45,840 --> 02:44:53,229
standard Linux based you know TCP with

02:44:51,040 --> 02:44:56,920
the proxy there would be actually you

02:44:53,229 --> 02:44:59,940
know very much of an option for ISPs as

02:44:56,920 --> 02:45:03,670
well and if that's the case I mean

02:44:59,940 --> 02:45:06,880
the ISPs actually and I'll getting the

02:45:03,670 --> 02:45:13,601
TCP stat information out of the kernel

02:45:06,880 --> 02:45:16,271
is actually very valuable okay so so one

02:45:13,601 --> 02:45:18,970
of the reason that we actually use the

02:45:16,271 --> 02:45:22,601
TCPS that information is to ensure the

02:45:18,970 --> 02:45:24,640
service of law object is and you know we

02:45:22,601 --> 02:45:26,860
won we wanted to actually make sure the

02:45:24,640 --> 02:45:29,260
our customers will actually have an a

02:45:26,860 --> 02:45:31,990
high quality of experience from

02:45:29,260 --> 02:45:34,240
transportation services and also we

02:45:31,990 --> 02:45:36,550
would like to proactively I know detect

02:45:34,240 --> 02:45:38,740
a subscriber with you know poor no

02:45:36,550 --> 02:45:44,470
connection and see if we can actually

02:45:38,740 --> 02:45:46,150
make them better and and people use

02:45:44,470 --> 02:45:48,070
active measurement as well

02:45:46,150 --> 02:45:50,410
however active measurement cannot be

02:45:48,070 --> 02:45:53,340
actually used as a tool to ensure the

02:45:50,410 --> 02:45:55,990
SLO for Mo'Nique monitored SLO or

02:45:53,340 --> 02:45:57,940
monitor for the do kyoya of the

02:45:55,990 --> 02:46:01,900
subscriber so this is really important

02:45:57,940 --> 02:46:05,351
for us so typically wide transmission

02:46:01,900 --> 02:46:07,870
level transmission layer level

02:46:05,351 --> 02:46:10,390
statistics because that's exactly what

02:46:07,870 --> 02:46:13,780
you know our customers are actually

02:46:10,390 --> 02:46:16,960
seeing in terms of performance and also

02:46:13,780 --> 02:46:18,880
we need to know a layer to statistics

02:46:16,960 --> 02:46:22,510
but when we actually married those two

02:46:18,880 --> 02:46:24,990
and also with some physical layer

02:46:22,510 --> 02:46:28,150
statistics we can actually you know

02:46:24,990 --> 02:46:31,780
debug the you know the our network very

02:46:28,150 --> 02:46:34,510
much no more you know very easily so

02:46:31,780 --> 02:46:37,390
that's exactly why we are using PAP and

02:46:34,510 --> 02:46:42,070
we are using you know we are monitoring

02:46:37,390 --> 02:46:43,510
the TCP performance of the path okay so

02:46:42,070 --> 02:46:47,980
I would like to actually give a little

02:46:43,510 --> 02:46:49,510
more picture in terms of SLO so this

02:46:47,980 --> 02:46:51,280
picture actually shows like a

02:46:49,510 --> 02:46:53,561
traditional satellite and then high

02:46:51,280 --> 02:46:57,070
throughput satellite in the high throw

02:46:53,561 --> 02:46:59,650
Posada like these days actually you uses

02:46:57,070 --> 02:47:02,710
something called spot beam that means

02:46:59,650 --> 02:47:06,100
you know we are actually reusing

02:47:02,710 --> 02:47:09,939
you know the frequency you know a

02:47:06,100 --> 02:47:13,710
smaller no cell so that we can do you

02:47:09,939 --> 02:47:17,340
know broadband high-speed you know

02:47:13,710 --> 02:47:22,750
create a high-speed link in that smaller

02:47:17,340 --> 02:47:27,090
area and and then basically we really

02:47:22,750 --> 02:47:30,850
have to monitor the bandwidth and usage

02:47:27,090 --> 02:47:35,859
performance of each of the beam so we

02:47:30,850 --> 02:47:38,739
typically sell you know we actually load

02:47:35,859 --> 02:47:40,120
the you know the customer into one of

02:47:38,739 --> 02:47:43,120
these beams and then we don't want to

02:47:40,120 --> 02:47:45,399
actually overload these beams if in in

02:47:43,120 --> 02:47:48,340
that case you know the performance that

02:47:45,399 --> 02:47:53,920
the the transmission performance will be

02:47:48,340 --> 02:47:56,649
really go down and that's probably what

02:47:53,920 --> 02:47:59,590
we don't want to happen so we we are

02:47:56,649 --> 02:48:04,630
actually more interring something we

02:47:59,590 --> 02:48:07,870
call speed availability so and and

02:48:04,630 --> 02:48:10,660
that's basically for samples that we

02:48:07,870 --> 02:48:13,210
actually measure the speed we want the

02:48:10,660 --> 02:48:15,609
median to be over the you know is

02:48:13,210 --> 02:48:17,710
actually graded and advertised speed of

02:48:15,609 --> 02:48:20,739
the service plant that we actually sold

02:48:17,710 --> 02:48:27,239
so those are the things that we are

02:48:20,739 --> 02:48:29,770
monitoring and and then also for similar

02:48:27,239 --> 02:48:32,880
stats can be actually used for a

02:48:29,770 --> 02:48:37,350
qualitative experience assurance

02:48:32,880 --> 02:48:39,479
okay so in order to use the TCP stats

02:48:37,350 --> 02:48:42,890
what do we really need to actually I

02:48:39,479 --> 02:48:46,790
mean in order to actually measure the

02:48:42,890 --> 02:48:50,430
speed what do we need from the TCP stat

02:48:46,790 --> 02:48:52,020
basically we need a and and one of the

02:48:50,430 --> 02:48:55,350
the constraints that we have I think

02:48:52,020 --> 02:48:56,909
Jamal mentioned a little bit but this

02:48:55,350 --> 02:49:00,359
has no I mean what Rommel did was

02:48:56,909 --> 02:49:06,630
nothing to do with our company but in

02:49:00,359 --> 02:49:09,869
general so so we need a burst and we we

02:49:06,630 --> 02:49:14,699
need a yeah in the long burst to be

02:49:09,869 --> 02:49:17,880
actually extract per connection so and

02:49:14,699 --> 02:49:19,979
we don't we can really you know pull too

02:49:17,880 --> 02:49:22,500
often of each of the connection because

02:49:19,979 --> 02:49:26,520
we in our business actually has a lot of

02:49:22,500 --> 02:49:28,500
connections going on and therefore at

02:49:26,520 --> 02:49:31,680
the end of the connection we would like

02:49:28,500 --> 02:49:33,390
to actually have a statistics about the

02:49:31,680 --> 02:49:36,119
connection and and one of the most

02:49:33,390 --> 02:49:38,159
important you know attribute that we

02:49:36,119 --> 02:49:40,470
need is actually the largest person

02:49:38,159 --> 02:49:46,939
within the connection that means in

02:49:40,470 --> 02:49:50,699
between the period of what is that the

02:49:46,939 --> 02:49:52,590
app limit we want that the biggest burst

02:49:50,699 --> 02:49:55,380
and then what was how many bytes were

02:49:52,590 --> 02:49:57,869
actually you know transmitted you know

02:49:55,380 --> 02:49:59,430
within within the burst what was the

02:49:57,869 --> 02:50:02,189
burst length and then what was the

02:49:59,430 --> 02:50:04,140
maximum available bandwidth during the

02:50:02,189 --> 02:50:06,029
burst and and those are the three things

02:50:04,140 --> 02:50:10,069
that we really need to actually keep

02:50:06,029 --> 02:50:10,069
track of the dispute availability

02:50:10,220 --> 02:50:19,670
okay alright so so so each connection

02:50:17,610 --> 02:50:22,500
will actually dump these you know

02:50:19,670 --> 02:50:25,050
statistics and then we actually look at

02:50:22,500 --> 02:50:28,010
the you know we actually filter the

02:50:25,050 --> 02:50:31,681
samples such that we we set a threshold

02:50:28,010 --> 02:50:33,960
such that the the burst is actually

02:50:31,681 --> 02:50:36,660
greater than let's say for example 10

02:50:33,960 --> 02:50:39,811
seconds and then we look at the average

02:50:36,660 --> 02:50:41,880
burst speed in that maximum burst speed

02:50:39,811 --> 02:50:44,190
distribution and and this is basically

02:50:41,880 --> 02:50:49,351
you know showing the average you know

02:50:44,190 --> 02:50:53,010
speed distribution for you know 100 Mbps

02:50:49,351 --> 02:50:55,590
plan and as you can see the median if

02:50:53,010 --> 02:50:59,521
you it this is a cdf so if you look at

02:50:55,590 --> 02:51:03,391
the the fifty percent and that actually

02:50:59,521 --> 02:51:06,360
gives us about hundred maybe hundred six

02:51:03,391 --> 02:51:11,910
my WPS in median so it's actually

02:51:06,360 --> 02:51:13,920
meeting over at cell oh but so but in I

02:51:11,910 --> 02:51:17,431
have an actual I didn't actually show

02:51:13,920 --> 02:51:20,820
the other in the grass here but we can

02:51:17,431 --> 02:51:23,670
actually look the same graph for each

02:51:20,820 --> 02:51:27,870
subscriber and then identify a

02:51:23,670 --> 02:51:31,771
subscriber that really has a poor what

02:51:27,870 --> 02:51:34,170
is it the for TCP performance in terms

02:51:31,771 --> 02:51:39,601
of you know bursts for for the large

02:51:34,170 --> 02:51:41,290
bursts and and we I'm actually you know

02:51:39,601 --> 02:51:44,380
currently working on

02:51:41,290 --> 02:51:47,260
you know how to actually you know while

02:51:44,380 --> 02:51:51,460
detect and looking to the debugging for

02:51:47,260 --> 02:51:54,790
those users as well but so that's

02:51:51,460 --> 02:51:58,470
basically you know one of the the key

02:51:54,790 --> 02:52:04,689
stuff that we are actually doing so the

02:51:58,470 --> 02:52:06,880
collected you know statistic how do we

02:52:04,689 --> 02:52:09,640
actually do that I mean as Jamal

02:52:06,880 --> 02:52:13,990
presented we can actually do it based on

02:52:09,640 --> 02:52:16,120
the net link or TCP you know BPF I think

02:52:13,990 --> 02:52:18,399
is actually you know a very good

02:52:16,120 --> 02:52:21,700
candidate to actually use it and then we

02:52:18,399 --> 02:52:25,060
just stream to our data centers for

02:52:21,700 --> 02:52:26,740
analysis and for real-time you know

02:52:25,060 --> 02:52:30,340
entering and stuff like that that's

02:52:26,740 --> 02:52:37,260
basically you know what we have for you

02:52:30,340 --> 02:52:40,689
know for that picture so summary just

02:52:37,260 --> 02:52:44,620
introduced like you know why we actually

02:52:40,689 --> 02:52:46,840
need a you know TCP stats for ISPs like

02:52:44,620 --> 02:52:49,120
satellite you know broadband service is

02:52:46,840 --> 02:52:52,960
piece one of the biggest thing is

02:52:49,120 --> 02:52:55,080
actually a SLO for speed availability we

02:52:52,960 --> 02:52:59,340
would and also quality of experience

02:52:55,080 --> 02:53:01,899
assurance and detecting abnormal

02:52:59,340 --> 02:53:05,670
connections and users and debug those

02:53:01,899 --> 02:53:10,649
you know connections is actually why we

02:53:05,670 --> 02:53:10,649
pointer TCP performances and

02:53:10,751 --> 02:53:19,061
okay so that's about it yep thank you

02:53:18,131 --> 02:53:22,751
for the presentation

02:53:19,061 --> 02:53:26,051
did you get a chance to try end to end

02:53:22,751 --> 02:53:28,291
with PBR over these links it did you get

02:53:26,051 --> 02:53:30,851
a chance to ever try and to end

02:53:28,291 --> 02:53:33,730
performance with bbr over these things

02:53:30,851 --> 02:53:34,751
or even even just that performance but

02:53:33,730 --> 02:53:39,490
yes

02:53:34,751 --> 02:53:42,730
so basically bbr I was I was really

02:53:39,490 --> 02:53:44,681
happy to play with VBR because you know

02:53:42,730 --> 02:53:49,721
the satellite that one of the biggest

02:53:44,681 --> 02:53:51,371
problem in the satellite is basically if

02:53:49,721 --> 02:53:56,980
they argue them if congestion avoidance

02:53:51,371 --> 02:54:00,371
algorithm is you know reacting to packet

02:53:56,980 --> 02:54:04,751
loss then packet loss might actually

02:54:00,371 --> 02:54:08,740
come from it is it's not always you know

02:54:04,751 --> 02:54:11,440
the signal of congestion and that

02:54:08,740 --> 02:54:13,480
actually caused some grief so we

02:54:11,440 --> 02:54:15,721
actually know tested to be be are

02:54:13,480 --> 02:54:17,831
necessarily linked and then the

02:54:15,721 --> 02:54:21,311
intermediate result is actually pretty

02:54:17,831 --> 02:54:25,211
promising it's not as good as the path

02:54:21,311 --> 02:54:29,980
which is you know engineered to actually

02:54:25,211 --> 02:54:31,780
work well on a specific link but I I was

02:54:29,980 --> 02:54:35,351
able to see 80 to 90 percent of the

02:54:31,780 --> 02:54:37,451
performance that we used to see so yeah

02:54:35,351 --> 02:54:40,980
but I cannot really generalize it I mean

02:54:37,451 --> 02:54:40,980
I just did a couple of tests

02:54:41,870 --> 02:54:47,930
yeah do you terminate TCP connections on

02:54:45,750 --> 02:54:52,380
the performance enhancing proxies or

02:54:47,930 --> 02:54:58,010
you're just passed through routers yes

02:54:52,380 --> 02:55:00,870
so we we do terminate the TCP and do you

02:54:58,010 --> 02:55:03,480
have a statistics on how much of the

02:55:00,870 --> 02:55:07,230
time connections spent in being receive

02:55:03,480 --> 02:55:13,190
endo limited or do you encounter that

02:55:07,230 --> 02:55:15,720
often you mean you mean the basically

02:55:13,190 --> 02:55:19,380
are you talking about the milliseconds

02:55:15,720 --> 02:55:22,740
or delays or maybe CPU you're like how

02:55:19,380 --> 02:55:25,470
do you like for in these proxies do you

02:55:22,740 --> 02:55:29,610
up the Armen to a very high value or

02:55:25,470 --> 02:55:32,730
large review or do you incur any delay

02:55:29,610 --> 02:55:34,620
because receiving though is too small or

02:55:32,730 --> 02:55:37,230
you couldn't get updates oh fast enough

02:55:34,620 --> 02:55:40,860
well I didn't actually you know look too

02:55:37,230 --> 02:55:48,750
much into those statistics yet we're

02:55:40,860 --> 02:56:01,620
running short of time so you yeah

02:55:48,750 --> 02:56:03,000
actually you know thank you thanks

02:56:01,620 --> 02:56:05,300
everyone

02:56:03,000 --> 02:56:07,609
at least what I got out of this is that

02:56:05,300 --> 02:56:11,060
we can start looking at adding more DCPI

02:56:07,609 --> 02:56:13,430
callbacks at least for like like

02:56:11,060 --> 02:56:18,159
three-way handshake do just get our feet

02:56:13,430 --> 02:56:18,159
wet all right

02:56:18,380 --> 02:56:20,439

YouTube URL: https://www.youtube.com/watch?v=ZUihWPyt_zo


