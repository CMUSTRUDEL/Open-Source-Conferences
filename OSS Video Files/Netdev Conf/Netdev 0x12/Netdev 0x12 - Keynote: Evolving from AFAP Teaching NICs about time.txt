Title: Netdev 0x12 - Keynote: Evolving from AFAP Teaching NICs about time
Publication date: 2018-07-31
Playlist: Netdev 0x12
Description: 
	We were pleased to announce our Netdev 0x12 keynote speaker: Van Jacobson

For most people involved in the networking world, Van needs very little introduction for his work, amongst many, in TCP/IP network performance and scaling of the internet. For the young lads amongst us who may be oblivious of his accomplishments, Van is typically referred to as a G.O.A.T. (Greatest Of All Time) or as a living legend[1] for others. A few of his accomplishments are listed on his Internet Hall of Fame Induction bio: https://www.internethalloffame.org/inductees/van-jacobson

Much could be enumerated for his many accomplishments and current passions - but we wanted to highlight one buzzword in particular: You would not have EBPF today if Van was not there[2].

At the moment, Van is involved, at Google, in a passion of his - Network Performance Scaling.

Having Van at this conference was both a privilege and an honor as he has seen a lot of ideas take wing from the early days of the internet to the specialized roles around Data Center, Web, IOT and more that we see today (July 12th, 2018). We wished to learn from this sage.

To paraphrase European Communication Magazine[3]:
"When Van Jacobson has something to say, people listen."

And Van had something he wanted to say to us at Netdev 0x12 in Montreal:
We need to teach Network Interface Cards about time.
What kind of surgery do we need on the kernel NIC interfaces?
What kind of features do NIC vendors need to provide?
Tune in and listen to Van.

More info:
https://netdevconf.org/0x12/session.html?evolving-from-afap-teaching-nics-about-time

[1]https://www.merriam-webster.com/dictionary/living%20legend
[2]http://www.tcpdump.org/papers/bpf-usenix93.pdf
[3]https://www.eurocomms.com/features/analysis/8238-could-content-centric-networking-provide-a-profitable-future-
Captions: 
	00:00:00,030 --> 00:00:07,859
so our next speaker keynote Fernet dev

00:00:05,540 --> 00:00:10,910
doesn't need a lot of introduction I'm

00:00:07,859 --> 00:00:13,920
sure a lot of you have heard of him

00:00:10,910 --> 00:00:17,970
internet Hall of Famer I'm not allowed

00:00:13,920 --> 00:00:19,800
to say he saved TCP but obviously had a

00:00:17,970 --> 00:00:24,510
lot of influence on congestion control

00:00:19,800 --> 00:00:26,460
algorithms but actually for me what he's

00:00:24,510 --> 00:00:29,880
not most known for when I started

00:00:26,460 --> 00:00:32,009
working at Sun quite a bit of time ago I

00:00:29,880 --> 00:00:36,210
was working on this protocol called PPP

00:00:32,009 --> 00:00:39,510
and there was this funny thing band or

00:00:36,210 --> 00:00:41,250
VJ compression and VJ compression so

00:00:39,510 --> 00:00:42,660
that's kind of interesting and I never

00:00:41,250 --> 00:00:46,440
knew what the VJ stands for

00:00:42,660 --> 00:00:48,780
turns out it's van Jacobson and so to me

00:00:46,440 --> 00:00:51,300
that's pretty cool somebody actually

00:00:48,780 --> 00:00:53,129
having a major algorithm or protocol

00:00:51,300 --> 00:00:55,649
named after them very rarer in this

00:00:53,129 --> 00:01:00,690
industry so that's pretty impressive to

00:00:55,649 --> 00:01:03,090
me but anyway so I think without any

00:01:00,690 --> 00:01:16,490
further ado I'd like to introduce van

00:01:03,090 --> 00:01:16,490
Jacobson thanks John

00:01:16,990 --> 00:01:20,700
thanks for inviting me I hope this won't

00:01:19,930 --> 00:01:28,990
put you to sleep

00:01:20,700 --> 00:01:32,560
I want to try and convince you that we

00:01:28,990 --> 00:01:34,810
should make some small changes to the

00:01:32,560 --> 00:01:37,840
contract between protocols and NICs

00:01:34,810 --> 00:01:42,210
and if we do that it will solve a lot of

00:01:37,840 --> 00:01:48,220
problems I'm going to try and motivate

00:01:42,210 --> 00:01:50,979
the small changes by talking about the

00:01:48,220 --> 00:01:54,069
history for why it is the way it is

00:01:50,979 --> 00:01:57,610
because a lot of design decisions in

00:01:54,069 --> 00:02:00,970
tcp/ip weren't made because there was

00:01:57,610 --> 00:02:04,030
only one right way to do things and the

00:02:00,970 --> 00:02:06,700
designers hit on that way after a bunch

00:02:04,030 --> 00:02:09,789
of discussion many parts of the design

00:02:06,700 --> 00:02:12,760
came from that but many parts of the

00:02:09,789 --> 00:02:15,220
design came from historical accidents

00:02:12,760 --> 00:02:20,290
there was something that had been tried

00:02:15,220 --> 00:02:21,910
and worked so they copied it or

00:02:20,290 --> 00:02:24,310
something had been tried and failed so

00:02:21,910 --> 00:02:26,700
they did something different it's not

00:02:24,310 --> 00:02:31,359
that they knew one true way because

00:02:26,700 --> 00:02:34,030
Internet tcp/ip didn't exist yet it was

00:02:31,359 --> 00:02:34,890
a search of a space and context matters

00:02:34,030 --> 00:02:38,410
a lot

00:02:34,890 --> 00:02:42,579
so going all the way back to the

00:02:38,410 --> 00:02:46,350
beginning dark ages of networking this

00:02:42,579 --> 00:02:50,260
is what the word networking meant in

00:02:46,350 --> 00:02:52,390
1970s this was IBM's product

00:02:50,260 --> 00:02:55,030
announcement for their brand-new network

00:02:52,390 --> 00:02:58,930
architecture that became known as SNA

00:02:55,030 --> 00:03:01,959
and if you look at it it's got a lot of

00:02:58,930 --> 00:03:04,120
printers and terminals on it and that's

00:03:01,959 --> 00:03:07,299
what networking was sitting up in the

00:03:04,120 --> 00:03:08,799
left hand corner there's a mainframe

00:03:07,299 --> 00:03:12,280
they sold mainframes they were

00:03:08,799 --> 00:03:14,799
fabulously expensive only really

00:03:12,280 --> 00:03:18,160
high-end enterprises could afford to buy

00:03:14,799 --> 00:03:21,160
them they wanted to move down market but

00:03:18,160 --> 00:03:24,579
to do that they had to meet say smaller

00:03:21,160 --> 00:03:27,280
banks with a few branch offices in order

00:03:24,579 --> 00:03:28,870
to get those customers they had to be

00:03:27,280 --> 00:03:29,660
able to give connectivity to the branch

00:03:28,870 --> 00:03:31,610
offices

00:03:29,660 --> 00:03:34,400
and they couldn't they were all designed

00:03:31,610 --> 00:03:36,200
around data centers a few channels real

00:03:34,400 --> 00:03:39,170
expensive peripherals sitting within

00:03:36,200 --> 00:03:41,570
about a hundred feet of the computer and

00:03:39,170 --> 00:03:44,960
so that they designed some remote

00:03:41,570 --> 00:03:47,060
controllers that would drive their

00:03:44,960 --> 00:03:49,190
display controllers and said well you

00:03:47,060 --> 00:03:51,230
can put this in your branch office you

00:03:49,190 --> 00:03:53,600
can talk back to the mainframe in your

00:03:51,230 --> 00:03:56,420
central office we've got a dozen branch

00:03:53,600 --> 00:04:00,170
offices the cost of the whole system is

00:03:56,420 --> 00:04:02,690
way less because you divide it by 12 so

00:04:00,170 --> 00:04:05,330
they go cool lots of banks financial

00:04:02,690 --> 00:04:09,620
services retail outlets they all went

00:04:05,330 --> 00:04:13,940
buy these things so great sales pitch

00:04:09,620 --> 00:04:17,890
this was a network the way that you

00:04:13,940 --> 00:04:20,840
build this network is first you're

00:04:17,890 --> 00:04:23,840
trying to sell hardware you are a big

00:04:20,840 --> 00:04:26,300
computer company you don't want your

00:04:23,840 --> 00:04:30,650
customers to be able to use your

00:04:26,300 --> 00:04:36,470
competitors gear rule one is locking

00:04:30,650 --> 00:04:39,050
your customers so if you think that the

00:04:36,470 --> 00:04:40,940
basis of networking is let's help the

00:04:39,050 --> 00:04:43,850
world communicate let's let everything

00:04:40,940 --> 00:04:45,980
talk to everything else that's a great

00:04:43,850 --> 00:04:47,480
fantasy world but that wasn't the world

00:04:45,980 --> 00:04:50,270
at the beginning the objective was

00:04:47,480 --> 00:04:54,530
exactly the opposite was make sure that

00:04:50,270 --> 00:04:58,310
our customers can only talk to our stuff

00:04:54,530 --> 00:05:00,260
and nothing else connects and because

00:04:58,310 --> 00:05:02,090
they're trying to sell more hardware and

00:05:00,260 --> 00:05:03,620
they're trying to fill a hole in their

00:05:02,090 --> 00:05:05,240
product line of they don't have

00:05:03,620 --> 00:05:08,270
terminals in the places that they want

00:05:05,240 --> 00:05:10,130
them the people that were in charge of

00:05:08,270 --> 00:05:11,780
the project where the engineers have

00:05:10,130 --> 00:05:13,820
made terminals and printers the

00:05:11,780 --> 00:05:16,670
peripherals that the customers would see

00:05:13,820 --> 00:05:19,040
because obviously that's the important

00:05:16,670 --> 00:05:21,080
part of the objective the communication

00:05:19,040 --> 00:05:22,730
part is whatever is necessary to make

00:05:21,080 --> 00:05:26,240
the display work or make the printer

00:05:22,730 --> 00:05:28,190
work and lastly be really really sure

00:05:26,240 --> 00:05:34,580
that you lock in those customers our

00:05:28,190 --> 00:05:37,520
peripherals and and everything so the

00:05:34,580 --> 00:05:39,950
upshot of that is you get engineers who

00:05:37,520 --> 00:05:42,470
made the peripherals driving the design

00:05:39,950 --> 00:05:45,230
and what was important to them

00:05:42,470 --> 00:05:47,510
became the top priority objectives what

00:05:45,230 --> 00:05:50,540
that meant is when you're making

00:05:47,510 --> 00:05:52,310
protocols the device artifacts were

00:05:50,540 --> 00:05:53,630
stuck right in the protocol with all of

00:05:52,310 --> 00:05:57,110
the weirdness that you normally get from

00:05:53,630 --> 00:06:00,650
communication like if there's a printer

00:05:57,110 --> 00:06:03,710
that takes two pages to eject it takes

00:06:00,650 --> 00:06:05,780
two seconds to eject a page in the

00:06:03,710 --> 00:06:09,950
low-level communication protocol you put

00:06:05,780 --> 00:06:13,640
an eject page command and when you send

00:06:09,950 --> 00:06:16,430
that command down you know to wait two

00:06:13,640 --> 00:06:19,090
seconds it's written so that you get the

00:06:16,430 --> 00:06:22,280
page delay in the transport protocol

00:06:19,090 --> 00:06:24,710
because there's not much smarts and not

00:06:22,280 --> 00:06:28,280
much memory memory at these days was

00:06:24,710 --> 00:06:32,210
still core and relays fabulously

00:06:28,280 --> 00:06:35,000
expensive there wasn't much of it you

00:06:32,210 --> 00:06:37,460
were sending things over dead slow

00:06:35,000 --> 00:06:40,940
communication links a lot of three under

00:06:37,460 --> 00:06:42,130
bought links for their retail customers

00:06:40,940 --> 00:06:45,919
[Music]

00:06:42,130 --> 00:06:48,320
2000 by 2.4 K for the financial

00:06:45,919 --> 00:06:51,830
customers and if you were really really

00:06:48,320 --> 00:06:53,600
rich you get 56 kilobits that was the

00:06:51,830 --> 00:06:55,790
upper end of bandwidth which means that

00:06:53,600 --> 00:06:58,700
you try to make the header is really

00:06:55,790 --> 00:07:01,490
small and it's always good not to say

00:06:58,700 --> 00:07:03,530
something like yes I got that packet you

00:07:01,490 --> 00:07:05,330
don't want to say that assume it was

00:07:03,530 --> 00:07:08,350
right in their various device timeouts

00:07:05,330 --> 00:07:10,790
it'll tell you if it got it wrong and

00:07:08,350 --> 00:07:12,770
you're winding your way through this

00:07:10,790 --> 00:07:14,840
really high ad hoc mixture of

00:07:12,770 --> 00:07:16,550
controllers there were hung on i/o

00:07:14,840 --> 00:07:18,950
channels that were never meant to be

00:07:16,550 --> 00:07:20,990
communication channels they were really

00:07:18,950 --> 00:07:24,229
meant for a mainframe to talk to disks

00:07:20,990 --> 00:07:26,540
or printers they had smart channel

00:07:24,229 --> 00:07:28,669
programs but smart in the sense they

00:07:26,540 --> 00:07:31,310
could talk well to devices not to

00:07:28,669 --> 00:07:33,500
communication lies and because of that

00:07:31,310 --> 00:07:35,240
you had layers of encapsulation that

00:07:33,500 --> 00:07:39,650
migrated you through those controllers

00:07:35,240 --> 00:07:41,450
but being capsulation depended on which

00:07:39,650 --> 00:07:43,400
particular model of controller and what

00:07:41,450 --> 00:07:44,900
his function was in the system which

00:07:43,400 --> 00:07:47,630
meant every different thing that you

00:07:44,900 --> 00:07:49,340
talked to had a different packet format

00:07:47,630 --> 00:07:51,170
because it required different

00:07:49,340 --> 00:07:54,620
encapsulations

00:07:51,170 --> 00:08:00,110
so this is a recipe for disaster and it

00:07:54,620 --> 00:08:02,330
was I mean it took 15 years to get

00:08:00,110 --> 00:08:08,360
rolled out important pieces went out

00:08:02,330 --> 00:08:15,370
early but most of it showed up in

00:08:08,360 --> 00:08:19,300
industry article saying SMA when it was

00:08:15,370 --> 00:08:26,810
contemporaneous with the IP TCP design

00:08:19,300 --> 00:08:29,120
and early to mid 70s the designers of

00:08:26,810 --> 00:08:32,620
the internet architecture could look

00:08:29,120 --> 00:08:39,650
over and see what was happening in SMA

00:08:32,620 --> 00:08:43,160
enough of it hadn't rolled out to supply

00:08:39,650 --> 00:08:46,430
lessons learned but there were things

00:08:43,160 --> 00:08:48,410
you could see that said this is really

00:08:46,430 --> 00:08:53,450
not the way that you want to do it you

00:08:48,410 --> 00:08:56,680
want to focus not on what's using the

00:08:53,450 --> 00:09:01,100
network but making the network usable

00:08:56,680 --> 00:09:02,420
you don't want to build in the problems

00:09:01,100 --> 00:09:04,580
that you're solving you want to make a

00:09:02,420 --> 00:09:09,380
tool box it'll solve a whole variety of

00:09:04,580 --> 00:09:13,670
problems an order to make that shift the

00:09:09,380 --> 00:09:16,270
architecture emphasizes simple if you

00:09:13,670 --> 00:09:18,260
can't justify something throw it out and

00:09:16,270 --> 00:09:20,450
everybody has to agree it's

00:09:18,260 --> 00:09:22,910
unambiguously useful before you leave it

00:09:20,450 --> 00:09:24,560
in you want really expressive

00:09:22,910 --> 00:09:29,050
abstractions things that will solve a

00:09:24,560 --> 00:09:32,170
lot of problems but they want to have

00:09:29,050 --> 00:09:36,500
implementable api's contracts between

00:09:32,170 --> 00:09:38,600
one level and the next because a lot of

00:09:36,500 --> 00:09:39,860
things sound good in theory but you go

00:09:38,600 --> 00:09:41,360
to do it and the world's more

00:09:39,860 --> 00:09:43,330
complicated than that or doesn't like

00:09:41,360 --> 00:09:45,890
you to do it that way and almost

00:09:43,330 --> 00:09:48,560
everybody that was on the architecture

00:09:45,890 --> 00:09:50,300
team had implemented protocols already

00:09:48,560 --> 00:09:53,420
they'd already worked on the ARPANET

00:09:50,300 --> 00:09:56,990
knew about how a reality interferes with

00:09:53,420 --> 00:10:01,520
your beautiful designs so we know they

00:09:56,990 --> 00:10:03,470
made two main protocols the IP part

00:10:01,520 --> 00:10:05,209
interface to interface small messages

00:10:03,470 --> 00:10:07,850
based on an

00:10:05,209 --> 00:10:09,319
unreliable best effort delivery I want

00:10:07,850 --> 00:10:14,779
to say a little bit about best effort

00:10:09,319 --> 00:10:16,879
much later that doesn't you know when

00:10:14,779 --> 00:10:20,749
the computer vendors doing their own

00:10:16,879 --> 00:10:22,879
networks saw that spec for IP they said

00:10:20,749 --> 00:10:25,550
oh yeah this is the hippy protocol says

00:10:22,879 --> 00:10:28,519
hey I may deliver your probe your pocket

00:10:25,550 --> 00:10:31,220
or I may go surfing and you know you

00:10:28,519 --> 00:10:33,529
take two chances that's not what

00:10:31,220 --> 00:10:36,860
best-effort meant the network has

00:10:33,529 --> 00:10:38,990
nothing to do but deliver packets and if

00:10:36,860 --> 00:10:40,699
it can't deliver your packet is because

00:10:38,990 --> 00:10:42,829
there are other packets that are in the

00:10:40,699 --> 00:10:46,490
way or there's some sort of resource

00:10:42,829 --> 00:10:51,529
contention that stops it so best effort

00:10:46,490 --> 00:10:53,809
is not laissez-faire it's focused on the

00:10:51,529 --> 00:10:54,769
problem doing everything possible to

00:10:53,809 --> 00:10:58,879
make this happen

00:10:54,769 --> 00:10:59,990
but things fail be prepared to deal with

00:10:58,879 --> 00:11:04,129
it

00:10:59,990 --> 00:11:07,790
TCP protocol on top of that contract

00:11:04,129 --> 00:11:09,949
saying all right given your best effort

00:11:07,790 --> 00:11:12,799
I can turn that into reliable eventual

00:11:09,949 --> 00:11:15,049
delivery eventual is important you can't

00:11:12,799 --> 00:11:18,850
say when because you don't know what's

00:11:15,049 --> 00:11:22,040
going to fail and you may have to retry

00:11:18,850 --> 00:11:25,189
that's pretty much it it was a couple of

00:11:22,040 --> 00:11:27,619
short RFC's because they left a whole

00:11:25,189 --> 00:11:29,689
bunch out they pretty much left out

00:11:27,619 --> 00:11:31,730
everything that was in SMA and

00:11:29,689 --> 00:11:34,579
everything that made it impossible to

00:11:31,730 --> 00:11:36,889
implement they don't talk about the

00:11:34,579 --> 00:11:38,689
intended applications there was no

00:11:36,889 --> 00:11:41,329
concern about protocol efficiency the

00:11:38,689 --> 00:11:45,019
headers said what they needed to say in

00:11:41,329 --> 00:11:47,139
clearer ways by at alignment not a lot

00:11:45,019 --> 00:11:50,929
of overloading not a lot of compression

00:11:47,139 --> 00:11:53,839
this Tom said many years afterwards I

00:11:50,929 --> 00:11:56,329
did some TCP header compression is easy

00:11:53,839 --> 00:11:59,149
to compress redundant information out

00:11:56,329 --> 00:12:02,449
it's really hard to put non-existent

00:11:59,149 --> 00:12:05,449
information back so starting with a

00:12:02,449 --> 00:12:07,249
focus on making the header small means

00:12:05,449 --> 00:12:09,350
you're highly probable to leave out

00:12:07,249 --> 00:12:10,240
something important if you can't get it

00:12:09,350 --> 00:12:14,709
back later

00:12:10,240 --> 00:12:14,709
so they made some nice decisions

00:12:14,800 --> 00:12:23,930
one of them led to the data delivery

00:12:20,360 --> 00:12:27,410
model listen TCP which is and as fast as

00:12:23,930 --> 00:12:32,240
possible model it comes about because

00:12:27,410 --> 00:12:38,420
all the you say at the TCP contract is I

00:12:32,240 --> 00:12:40,610
do reliable delivery and implicitly

00:12:38,420 --> 00:12:43,279
because the reliability requires you

00:12:40,610 --> 00:12:45,980
hold on to date at both ends that puts a

00:12:43,279 --> 00:12:48,319
bound on how much can be sent because

00:12:45,980 --> 00:12:51,800
you can only send as much as both ends

00:12:48,319 --> 00:12:53,689
are willing to buffer it only be as much

00:12:51,800 --> 00:12:55,910
unacknowledged as both as I'm willing to

00:12:53,689 --> 00:13:00,949
buffer but this says nothing about how

00:12:55,910 --> 00:13:02,750
fast you can go if it's not said it's

00:13:00,949 --> 00:13:05,089
left up to the implementation and the

00:13:02,750 --> 00:13:06,500
standards are really careful to say

00:13:05,089 --> 00:13:08,629
nothing about implementations

00:13:06,500 --> 00:13:10,399
they say it's implementable we did it

00:13:08,629 --> 00:13:12,730
once like this you can copy it you can

00:13:10,399 --> 00:13:17,029
do something better that's really cool

00:13:12,730 --> 00:13:20,120
the reference implementation used a

00:13:17,029 --> 00:13:21,920
queue on the interface output the

00:13:20,120 --> 00:13:24,259
protocol stack dump packets into the

00:13:21,920 --> 00:13:28,430
queue the interface pull packets out of

00:13:24,259 --> 00:13:31,519
the queue and basically you ran as fast

00:13:28,430 --> 00:13:34,579
as the interface let you and that's what

00:13:31,519 --> 00:13:37,370
defines as fast as possible the amount

00:13:34,579 --> 00:13:40,629
that was in flight was determined by the

00:13:37,370 --> 00:13:45,410
minimum of either a limit on that queue

00:13:40,629 --> 00:13:48,199
you know typically hundred to a thousand

00:13:45,410 --> 00:13:50,629
packets or the receive window which in

00:13:48,199 --> 00:13:59,000
the East days was two four eight

00:13:50,629 --> 00:14:03,529
kilobytes small number of packets the

00:13:59,000 --> 00:14:06,519
big issue is if you do it that way the

00:14:03,529 --> 00:14:09,829
rate constraint how fast things go is

00:14:06,519 --> 00:14:14,660
entirely a local constraint because it's

00:14:09,829 --> 00:14:16,699
determined by the rate that you're

00:14:14,660 --> 00:14:19,850
sending packets the local interface and

00:14:16,699 --> 00:14:22,040
it has absolutely nothing to do with the

00:14:19,850 --> 00:14:25,140
network at this point because it's

00:14:22,040 --> 00:14:28,080
upstream of the interface

00:14:25,140 --> 00:14:32,010
so if your interface will accept a

00:14:28,080 --> 00:14:33,570
million packets at a gigabit as fast as

00:14:32,010 --> 00:14:35,480
possible as a million packets at a

00:14:33,570 --> 00:14:40,850
gigabit

00:14:35,480 --> 00:14:43,500
that's a beloved work conserving

00:14:40,850 --> 00:14:48,570
architecture which is easy to analyze

00:14:43,500 --> 00:14:51,830
but kind of deadly in practice but if

00:14:48,570 --> 00:14:55,580
you're starting a protocol from nothing

00:14:51,830 --> 00:14:59,040
it's a really good starting point

00:14:55,580 --> 00:15:00,630
because if you're successful with your

00:14:59,040 --> 00:15:04,740
network and it gets used

00:15:00,630 --> 00:15:07,770
it'll get faster because it's being used

00:15:04,740 --> 00:15:09,810
it's getting full the only way to get

00:15:07,770 --> 00:15:13,230
more data through it and get more use is

00:15:09,810 --> 00:15:16,800
to speed up the interfaces it was really

00:15:13,230 --> 00:15:18,990
successful it drove a lot of evolution

00:15:16,800 --> 00:15:23,640
and our communication interfaces so this

00:15:18,990 --> 00:15:26,400
is 25 years of Ethernet evolution that

00:15:23,640 --> 00:15:31,350
blue line is the Moore's Law line

00:15:26,400 --> 00:15:33,660
doubling every 18 months and Ethernet

00:15:31,350 --> 00:15:36,870
you know if we look over the entire 25

00:15:33,660 --> 00:15:42,560
years it's exactly on top of the Moore's

00:15:36,870 --> 00:15:42,560
Law line it evolved as fast as anything

00:15:43,550 --> 00:15:50,370
so unlike a lot of other protocols that

00:15:48,780 --> 00:15:53,190
were built for particular communication

00:15:50,370 --> 00:15:55,770
signs or particular bandwidth

00:15:53,190 --> 00:15:58,800
hierarchies like the telcos T carrier

00:15:55,770 --> 00:16:01,920
hierarchy they all had speeds built into

00:15:58,800 --> 00:16:04,680
them there was no speed built in

00:16:01,920 --> 00:16:07,800
anywhere in tcp/ip it was one of the

00:16:04,680 --> 00:16:10,110
first things that got left out and

00:16:07,800 --> 00:16:14,250
because of that the speeds externally

00:16:10,110 --> 00:16:15,660
determined and if you change the entity

00:16:14,250 --> 00:16:18,240
that's controlling it you change the

00:16:15,660 --> 00:16:21,300
interface speed and everything magically

00:16:18,240 --> 00:16:22,620
goes faster and this evolution was

00:16:21,300 --> 00:16:25,770
surprisingly painless

00:16:22,620 --> 00:16:30,030
we had to tune things when you went a

00:16:25,770 --> 00:16:34,280
lot faster but at least for the first

00:16:30,030 --> 00:16:37,389
step up to about Gigabit Ethernet just

00:16:34,280 --> 00:16:43,850
absolutely painless

00:16:37,389 --> 00:16:46,639
but there's issues with running as fast

00:16:43,850 --> 00:16:50,750
as possible some of them are first

00:16:46,639 --> 00:16:53,600
principle issues queuing theory says

00:16:50,750 --> 00:16:56,870
that if you decide to run your bottle

00:16:53,600 --> 00:16:59,209
next to a hundred percent then if you

00:16:56,870 --> 00:17:05,659
get a backlog there's no way to get rid

00:16:59,209 --> 00:17:07,850
of it because I accuse a balance between

00:17:05,659 --> 00:17:11,299
an arrival parcel process and a

00:17:07,850 --> 00:17:14,390
departure process I had a bottleneck

00:17:11,299 --> 00:17:17,120
you've got a deterministic departure

00:17:14,390 --> 00:17:21,049
process that runs at the bottleneck link

00:17:17,120 --> 00:17:24,319
rate if the arrivals are the bottleneck

00:17:21,049 --> 00:17:28,339
link rate whenever they go slightly

00:17:24,319 --> 00:17:30,350
above you get extra stuff in the queue

00:17:28,339 --> 00:17:33,520
because you were going faster than the

00:17:30,350 --> 00:17:36,200
departure rate but the departure rates

00:17:33,520 --> 00:17:38,809
deterministic and fixed and so you can't

00:17:36,200 --> 00:17:42,289
get rid of that stuff so all the cues

00:17:38,809 --> 00:17:44,630
that you make any little gaps that build

00:17:42,289 --> 00:17:49,610
up will translate back logs they all

00:17:44,630 --> 00:17:52,820
make use that live forever and so this

00:17:49,610 --> 00:17:57,309
is for the best-case queueing system

00:17:52,820 --> 00:17:59,419
plus zone arrivals deterministic service

00:17:57,309 --> 00:18:00,940
everything else is going to be worse

00:17:59,419 --> 00:18:03,380
yeah

00:18:00,940 --> 00:18:06,260
plus zones as nice as traffic and

00:18:03,380 --> 00:18:08,210
possibly be the left-hand edge of the

00:18:06,260 --> 00:18:10,669
graph is what happens to the delay in

00:18:08,210 --> 00:18:13,270
terms of packet time as you approach

00:18:10,669 --> 00:18:17,870
100% utilization of the bottleneck link

00:18:13,270 --> 00:18:20,450
it hockey sticks and skyrockets the

00:18:17,870 --> 00:18:23,870
right-hand graph is how that looks on a

00:18:20,450 --> 00:18:26,120
log graph and it's kind of intuitive

00:18:23,870 --> 00:18:29,750
there it says that if you're at really

00:18:26,120 --> 00:18:33,950
low traffic rates there's basically no

00:18:29,750 --> 00:18:37,309
queue you you just sail right through is

00:18:33,950 --> 00:18:40,520
the queue gets up towards or the rake is

00:18:37,309 --> 00:18:42,650
up towards 50% busy the probability that

00:18:40,520 --> 00:18:45,500
you see one packet in front of you

00:18:42,650 --> 00:18:49,029
starts to get really high that's when

00:18:45,500 --> 00:18:52,130
you get to 1 so 1 packet time

00:18:49,029 --> 00:18:57,019
is more or less linear until you get up

00:18:52,130 --> 00:18:59,890
about 90% and then it takes off and it

00:18:57,019 --> 00:18:59,890
takes off really fast

00:18:59,980 --> 00:19:07,100
now if the right-hand edge is your

00:19:05,000 --> 00:19:11,870
operating point you've got something

00:19:07,100 --> 00:19:13,880
this really fabulously brittle and the

00:19:11,870 --> 00:19:16,370
fabulously brittle maybe somewhere where

00:19:13,880 --> 00:19:18,380
it's hard to deal with it like 9 hops

00:19:16,370 --> 00:19:22,250
away from you in a poorly buffered

00:19:18,380 --> 00:19:25,490
switch or at some ISPs connection to

00:19:22,250 --> 00:19:27,169
some users home again is poorly buffered

00:19:25,490 --> 00:19:30,590
because they want it went really cheap

00:19:27,169 --> 00:19:38,049
on that switch so this is sort of about

00:19:30,590 --> 00:19:41,840
recipe for problems now it wasn't a

00:19:38,049 --> 00:19:44,570
recipe for problems early on and memory

00:19:41,840 --> 00:19:47,659
was super expensive links were super

00:19:44,570 --> 00:19:50,360
slow what that meant is the delay

00:19:47,659 --> 00:19:53,240
bandwidth product was tiny

00:19:50,360 --> 00:19:56,899
it was kilobytes small kilobytes

00:19:53,240 --> 00:19:58,760
you know like less than 10 if you were

00:19:56,899 --> 00:20:02,029
inside a campus if you were close

00:19:58,760 --> 00:20:04,429
while the RTT was small and it was 10 to

00:20:02,029 --> 00:20:06,590
100 megabit connections that's not

00:20:04,429 --> 00:20:08,330
enough to you all you pay for

00:20:06,590 --> 00:20:10,580
store-and-forward delays but you can't

00:20:08,330 --> 00:20:13,789
store many bits in a wire and if you're

00:20:10,580 --> 00:20:18,139
that close so you're within the sort of

00:20:13,789 --> 00:20:20,600
10 kilobyte ish range if we're going

00:20:18,139 --> 00:20:24,139
long-haul telcos charged up the wazoo

00:20:20,600 --> 00:20:29,149
for bandwidth so again be dps are small

00:20:24,139 --> 00:20:33,799
because the bandwidth is small so for a

00:20:29,149 --> 00:20:37,279
long time up to at least 1995 the first

00:20:33,799 --> 00:20:41,120
issue said I you know a fad no issue

00:20:37,279 --> 00:20:43,820
we're never we can't build big enough

00:20:41,120 --> 00:20:45,139
queues to cause a problem so even though

00:20:43,820 --> 00:20:50,330
there's a hockey stick it's not

00:20:45,139 --> 00:20:52,220
affecting us past 95 router vendors

00:20:50,330 --> 00:20:56,480
started to make a lot of memory selling

00:20:52,220 --> 00:21:00,110
router buffers had a real 65% premium

00:20:56,480 --> 00:21:01,850
and memory price but if you put a router

00:21:00,110 --> 00:21:04,610
with a bandwidth filet product

00:21:01,850 --> 00:21:07,070
with a buffering in front of every

00:21:04,610 --> 00:21:08,390
potential bottleneck and you're also not

00:21:07,070 --> 00:21:10,130
going to have an issue you can dump your

00:21:08,390 --> 00:21:12,200
packets into the router and it will deal

00:21:10,130 --> 00:21:13,670
with them and you've got to stop because

00:21:12,200 --> 00:21:18,460
you've got a B DP in flight

00:21:13,670 --> 00:21:21,830
so again non problem

00:21:18,460 --> 00:21:26,030
lastly you can have the telco of style

00:21:21,830 --> 00:21:29,210
shape bandwidth architecture so you can

00:21:26,030 --> 00:21:31,970
have say your host links run at 10 gig

00:21:29,210 --> 00:21:34,190
but the things that they talk to the

00:21:31,970 --> 00:21:37,760
first level of switch is or aggregation

00:21:34,190 --> 00:21:41,620
boxes are running at a hundred you okay

00:21:37,760 --> 00:21:45,680
the hosts to 100 gig you upgrade the

00:21:41,620 --> 00:21:47,990
switches to a gig host to a gig switches

00:21:45,680 --> 00:21:50,270
10 gig you can always stay it to step

00:21:47,990 --> 00:21:52,220
ahead then it doesn't matter that the

00:21:50,270 --> 00:21:55,190
hosts are sending as fast as possible

00:21:52,220 --> 00:21:57,440
because as fast as possible can only get

00:21:55,190 --> 00:22:00,920
one hop away from the host and then it's

00:21:57,440 --> 00:22:04,000
in a fatter pipe and so now you got room

00:22:00,920 --> 00:22:07,900
and things can sort themselves out so

00:22:04,000 --> 00:22:10,610
the second two issues you know from

00:22:07,900 --> 00:22:14,150
shortly before the Millenium through

00:22:10,610 --> 00:22:17,320
about 2012 they basically saved our ass

00:22:14,150 --> 00:22:21,440
yeah you were doing one or the other and

00:22:17,320 --> 00:22:24,890
we weren't seeing these massive queues

00:22:21,440 --> 00:22:28,610
so we did start to see massive massive

00:22:24,890 --> 00:22:31,520
buffer bloat because the packets have to

00:22:28,610 --> 00:22:33,890
get queued somewhere and if it's the

00:22:31,520 --> 00:22:37,580
second option that's in a downstream

00:22:33,890 --> 00:22:38,780
router memory is fairly cheap and it

00:22:37,580 --> 00:22:42,620
makes a lot of money for the router

00:22:38,780 --> 00:22:47,330
vendor so you get multi second queues

00:22:42,620 --> 00:22:55,559
even in multi gigabit routers kind of

00:22:47,330 --> 00:22:59,999
painful past 2012 the

00:22:55,559 --> 00:23:02,940
pain started to increase and there was a

00:22:59,999 --> 00:23:04,769
technology reason for that if you look

00:23:02,940 --> 00:23:07,110
in more detail about the Ethernet

00:23:04,769 --> 00:23:09,480
scalene there's clearly two lines in the

00:23:07,110 --> 00:23:13,730
data and they're different there is an

00:23:09,480 --> 00:23:17,460
early time up to about 2000 where it's

00:23:13,730 --> 00:23:22,320
doubling time was 50% better than

00:23:17,460 --> 00:23:25,590
Moore's Law the the rate over that 20

00:23:22,320 --> 00:23:29,580
years was double every 12 months rather

00:23:25,590 --> 00:23:33,690
than ever 18 for the next two

00:23:29,580 --> 00:23:37,649
generations for the 10 gig and our

00:23:33,690 --> 00:23:41,399
current approach to a hundred gig that

00:23:37,649 --> 00:23:44,789
was way harder there the spacing between

00:23:41,399 --> 00:23:48,419
generations wasn't eighteen months it

00:23:44,789 --> 00:23:53,730
was 24 it took at least two years to get

00:23:48,419 --> 00:23:56,909
each new generation out and that kind of

00:23:53,730 --> 00:23:58,619
broke this nice sort of tick-tock thing

00:23:56,909 --> 00:24:07,200
we had going in campuses and data

00:23:58,619 --> 00:24:12,110
centers where you would upgrade your

00:24:07,200 --> 00:24:14,999
fabrics to the latest generation of NICs

00:24:12,110 --> 00:24:17,190
because there aren't all that many

00:24:14,999 --> 00:24:18,929
switches compared to hosts they're you

00:24:17,190 --> 00:24:23,070
know ten times more leaves than there

00:24:18,929 --> 00:24:25,169
are network nodes with even small fan

00:24:23,070 --> 00:24:29,100
out from your switches that means this

00:24:25,169 --> 00:24:31,409
upgrading switches is high leverage the

00:24:29,100 --> 00:24:34,139
switches got the faster interfaces first

00:24:31,409 --> 00:24:36,509
so when the one gig standard was

00:24:34,139 --> 00:24:38,399
published their whole bunch of switch

00:24:36,509 --> 00:24:40,679
and router boxes that had one gig

00:24:38,399 --> 00:24:43,769
interfaces they weren't on the

00:24:40,679 --> 00:24:46,019
motherboard of any server weren't on the

00:24:43,769 --> 00:24:48,419
motherboard of any host so you had all

00:24:46,019 --> 00:24:50,340
of your server infrastructure that was

00:24:48,419 --> 00:24:54,679
running ten times slower than the

00:24:50,340 --> 00:24:59,789
switches cool when you got your servers

00:24:54,679 --> 00:25:01,110
updated when the new one gig interfaces

00:24:59,789 --> 00:25:03,360
started to be standard on the

00:25:01,110 --> 00:25:05,070
motherboards orderable on weather boards

00:25:03,360 --> 00:25:11,070
or cheap NICs

00:25:05,070 --> 00:25:13,139
upgrade your entire compute and about

00:25:11,070 --> 00:25:15,720
that time the next standard would be

00:25:13,139 --> 00:25:18,029
published and suddenly you had new

00:25:15,720 --> 00:25:24,779
switch offerings that went at ten gig

00:25:18,029 --> 00:25:26,700
not at one gig so you get a cycle of

00:25:24,779 --> 00:25:29,630
alternate upgrades that for the most

00:25:26,700 --> 00:25:33,149
part kept the fabric ahead of the hosts

00:25:29,630 --> 00:25:34,710
until one generation suddenly took a lot

00:25:33,149 --> 00:25:36,090
longer than anybody thought it would

00:25:34,710 --> 00:25:37,710
take and it was a lot more expensive

00:25:36,090 --> 00:25:41,220
than anybody would thought it would be

00:25:37,710 --> 00:25:44,220
and that caused the switches to catch up

00:25:41,220 --> 00:25:46,470
with the hosts or the host to catch up

00:25:44,220 --> 00:25:49,139
with the switches now everything's

00:25:46,470 --> 00:25:52,139
running at the same speed and now

00:25:49,139 --> 00:25:53,700
there's a lot of a faff issues because

00:25:52,139 --> 00:25:55,980
now you can get that hockey stick

00:25:53,700 --> 00:25:59,639
anywhere in your fabric almost certainly

00:25:55,980 --> 00:26:01,320
downstream of the host but anywhere when

00:25:59,639 --> 00:26:02,669
we're both Apple active hosts come

00:26:01,320 --> 00:26:10,409
together and try and talk to the same

00:26:02,669 --> 00:26:14,659
output port issues so this is a bunch of

00:26:10,409 --> 00:26:16,740
Google published papers and I was

00:26:14,659 --> 00:26:18,029
desperately trying to finish slides at

00:26:16,740 --> 00:26:19,710
3:00 in the morning and I didn't turn

00:26:18,029 --> 00:26:23,220
all of these into links yet but I'll do

00:26:19,710 --> 00:26:29,250
that before I upload the copy of the

00:26:23,220 --> 00:26:31,769
slides I picked Google papers not for in

00:26:29,250 --> 00:26:35,070
a corporate agendas just I know about

00:26:31,769 --> 00:26:40,370
this work I know its context why it was

00:26:35,070 --> 00:26:40,370
done and the problems that address and

00:26:40,580 --> 00:26:49,009
it's representative of things that were

00:26:44,100 --> 00:26:52,080
happening throughout networking at both

00:26:49,009 --> 00:26:54,659
other datacenter computing and edge

00:26:52,080 --> 00:26:58,169
networking everybody was seeing the same

00:26:54,659 --> 00:27:01,799
issues they're driven by the same core

00:26:58,169 --> 00:27:08,600
problem if you remember the world really

00:27:01,799 --> 00:27:11,580
changed in between 2000 2005 because

00:27:08,600 --> 00:27:16,139
we've been used to processors doubling

00:27:11,580 --> 00:27:19,440
their speed every 18 months and then

00:27:16,139 --> 00:27:22,840
suddenly around 2003

00:27:19,440 --> 00:27:26,950
until says well the next generation of

00:27:22,840 --> 00:27:28,450
Pentium is not going to be two times

00:27:26,950 --> 00:27:29,890
faster it's actually going to be a

00:27:28,450 --> 00:27:32,230
little bit slower but there will be more

00:27:29,890 --> 00:27:36,700
of them on the die well we'll give you

00:27:32,230 --> 00:27:39,180
two or four because we can't make it any

00:27:36,700 --> 00:27:41,920
faster because we can't move the

00:27:39,180 --> 00:27:44,470
electrons in silicon any faster and

00:27:41,920 --> 00:27:46,510
they're already moving you know we put a

00:27:44,470 --> 00:27:48,820
field on them tell them to go left and

00:27:46,510 --> 00:27:50,320
before they can start to move which

00:27:48,820 --> 00:27:52,120
reverse the field and tell them to go

00:27:50,320 --> 00:27:54,910
right yeah that's what high speed

00:27:52,120 --> 00:27:58,240
signaling it's all about when that

00:27:54,910 --> 00:28:00,040
happens then you can't do logic anymore

00:27:58,240 --> 00:28:03,610
because you don't have currents anymore

00:28:00,040 --> 00:28:05,380
and it happens at a couple of Gerrits

00:28:03,610 --> 00:28:09,850
and silicon doesn't have really high

00:28:05,380 --> 00:28:11,680
electron mobility so because we hit that

00:28:09,850 --> 00:28:13,660
wall we could still put lots of

00:28:11,680 --> 00:28:15,520
transistors on the chip so we had to do

00:28:13,660 --> 00:28:18,310
more in parallel doesn't do any good to

00:28:15,520 --> 00:28:22,080
do one CPU in parallel but you can put a

00:28:18,310 --> 00:28:25,930
lot more CPUs let them work in parallel

00:28:22,080 --> 00:28:29,500
you can get around the same wall at the

00:28:25,930 --> 00:28:32,410
application level by spreading out your

00:28:29,500 --> 00:28:35,860
computations we used to be solving

00:28:32,410 --> 00:28:38,380
problems by saying oh we really would

00:28:35,860 --> 00:28:40,720
like this to go faster okay you know

00:28:38,380 --> 00:28:44,740
wait six months buy a new CPU it'll be

00:28:40,720 --> 00:28:51,190
twice as fast yeah early 2000 that no

00:28:44,740 --> 00:28:52,720
longer worked and so because we hit this

00:28:51,190 --> 00:28:55,390
one with silicon that affected both

00:28:52,720 --> 00:28:59,290
networking and computation but it

00:28:55,390 --> 00:29:01,180
affected networking worse one was we

00:28:59,290 --> 00:29:04,540
didn't get the bandwidth hierarchy in

00:29:01,180 --> 00:29:07,300
our fabrics that let us prevent these

00:29:04,540 --> 00:29:09,370
problems from happening secondly because

00:29:07,300 --> 00:29:11,440
we had to distribute the computations a

00:29:09,370 --> 00:29:14,140
lot more we put a lot more stress on the

00:29:11,440 --> 00:29:17,170
network something that would have been

00:29:14,140 --> 00:29:19,420
handled by a CPU upgrade which has zero

00:29:17,170 --> 00:29:22,150
impact on the network the links that are

00:29:19,420 --> 00:29:25,210
connecting it to your fabric still the

00:29:22,150 --> 00:29:28,730
same wink now you can't do it with a CPU

00:29:25,210 --> 00:29:32,390
upgrade you have to do it with another

00:29:28,730 --> 00:29:33,710
more CPUs big impact on the network

00:29:32,390 --> 00:29:36,830
completely different application

00:29:33,710 --> 00:29:44,750
structure huge multiplier on the traffic

00:29:36,830 --> 00:29:47,570
and issues so we saw pain in our fabric

00:29:44,750 --> 00:29:50,420
is talked about it a bit in the jupiter

00:29:47,570 --> 00:29:53,690
paper and say cough if teen we saw a lot

00:29:50,420 --> 00:29:56,540
of pain on our when internal wound

00:29:53,690 --> 00:30:00,560
infrastructure before start about a wit

00:29:56,540 --> 00:30:05,330
a little bit in the sitcom 13 paper that

00:30:00,560 --> 00:30:07,550
describes that more details on the

00:30:05,330 --> 00:30:11,890
problems in the mitigations are in that

00:30:07,550 --> 00:30:14,690
bottom set of papers starting back with

00:30:11,890 --> 00:30:16,930
whole paper which is all about spreading

00:30:14,690 --> 00:30:20,060
traffic out so as fast as possible

00:30:16,930 --> 00:30:22,580
becomes 95 percent rather than a hundred

00:30:20,060 --> 00:30:24,890
percent if you look at how that hockey

00:30:22,580 --> 00:30:27,430
stick goes in bandwidth if you back off

00:30:24,890 --> 00:30:29,930
just a little bit you get a huge win

00:30:27,430 --> 00:30:32,330
there's no benefit and backing off a lot

00:30:29,930 --> 00:30:34,010
because it's really flat but if you can

00:30:32,330 --> 00:30:37,610
back off a little bit from a hundred

00:30:34,010 --> 00:30:42,470
percent your delays and queues drops all

00:30:37,610 --> 00:30:47,320
go to almost zero so stanford google

00:30:42,470 --> 00:30:50,630
paper said why don't we do that be we

00:30:47,320 --> 00:30:51,440
you're heavily sharing when links that

00:30:50,630 --> 00:30:55,640
means there's a lot of traffic

00:30:51,440 --> 00:31:01,400
converging on them that means that a lot

00:30:55,640 --> 00:31:04,070
of stuff can get dropped really hard to

00:31:01,400 --> 00:31:07,130
get tcp to open this window if you've

00:31:04,070 --> 00:31:08,780
got lots of drops so you tried to do

00:31:07,130 --> 00:31:12,050
traffic management on the end house

00:31:08,780 --> 00:31:15,140
you're making a fabric I ran out of

00:31:12,050 --> 00:31:17,540
switches that have point one percent of

00:31:15,140 --> 00:31:21,200
bdp buffer I mean they're basically

00:31:17,540 --> 00:31:24,770
unbuffered switches you're sending them

00:31:21,200 --> 00:31:26,930
lots of stochastic traffic if it happens

00:31:24,770 --> 00:31:28,730
to be correlated then you lose because

00:31:26,930 --> 00:31:32,870
there's no buffer to fix it in the

00:31:28,730 --> 00:31:34,580
switch so the only option you've got the

00:31:32,870 --> 00:31:37,370
only place where there is buffers at the

00:31:34,580 --> 00:31:39,430
originating host so be.we is all about

00:31:37,370 --> 00:31:41,680
how you fix

00:31:39,430 --> 00:31:42,940
things at the originating host because

00:31:41,680 --> 00:31:48,820
you can no longer fix them in the

00:31:42,940 --> 00:31:52,630
network similar paying FQ pay seen Eric

00:31:48,820 --> 00:31:55,840
de Menezes beautiful cue disk that would

00:31:52,630 --> 00:31:58,020
give you really good traffic mixing by

00:31:55,840 --> 00:32:01,150
fqe

00:31:58,020 --> 00:32:02,800
round-robin FQ on all the active sockets

00:32:01,150 --> 00:32:05,680
which gives you really high entropy

00:32:02,800 --> 00:32:09,190
going up the link as opposed to big

00:32:05,680 --> 00:32:11,170
bursts from different connections you

00:32:09,190 --> 00:32:13,120
need really high entropy and a fabric

00:32:11,170 --> 00:32:16,030
because if you don't you get head of

00:32:13,120 --> 00:32:18,610
line blocking a switch can only send the

00:32:16,030 --> 00:32:20,290
packets it sees if all the packets of

00:32:18,610 --> 00:32:21,880
C's have the same destination they're

00:32:20,290 --> 00:32:24,610
all going to follow the same path that

00:32:21,880 --> 00:32:28,330
path will be congested and you can't use

00:32:24,610 --> 00:32:31,720
downstream alternates you can't keep a

00:32:28,330 --> 00:32:33,250
lot of paths busy in parallel unless

00:32:31,720 --> 00:32:35,530
there's enough mixing in the traffic to

00:32:33,250 --> 00:32:37,630
support that you have to do that on the

00:32:35,530 --> 00:32:39,250
edge and there's no buffer in the

00:32:37,630 --> 00:32:42,700
switches that would make it possible

00:32:39,250 --> 00:32:46,540
traffic's just blowing through other

00:32:42,700 --> 00:32:48,640
things on the theme looking at the

00:32:46,540 --> 00:32:52,180
queues building up in the data center

00:32:48,640 --> 00:32:54,610
that's timely trying to pace them spread

00:32:52,180 --> 00:32:57,510
them out looking accused building up on

00:32:54,610 --> 00:33:02,860
the customer access link the final tale

00:32:57,510 --> 00:33:09,040
that's bbr these are all if you look at

00:33:02,860 --> 00:33:11,440
this arc that's six years long it's all

00:33:09,040 --> 00:33:14,460
the same theme it's saying let's back

00:33:11,440 --> 00:33:17,080
away from this a FAP you know this local

00:33:14,460 --> 00:33:19,390
work conserving ship the package

00:33:17,080 --> 00:33:22,330
downstream as quick as you can because

00:33:19,390 --> 00:33:25,690
it's going to hurt if we do that instead

00:33:22,330 --> 00:33:29,200
let's try to figure out what's the

00:33:25,690 --> 00:33:31,990
slowest thing downstream what's the

00:33:29,200 --> 00:33:34,060
bottleneck link that really determines

00:33:31,990 --> 00:33:37,690
what's as fast as possible and it's

00:33:34,060 --> 00:33:41,110
never local right you can't congest your

00:33:37,690 --> 00:33:44,520
uplink to the tour it's it runs as fast

00:33:41,110 --> 00:33:48,970
as it runs is what sent in your rate so

00:33:44,520 --> 00:33:50,690
there's no way that the current model

00:33:48,970 --> 00:33:53,180
that helps off the

00:33:50,690 --> 00:33:54,980
a FAP you know 100% model could help

00:33:53,180 --> 00:33:58,880
solve the problem because the problems

00:33:54,980 --> 00:34:00,530
not local and it is local you have to

00:33:58,880 --> 00:34:03,470
know what's happening downstream and you

00:34:00,530 --> 00:34:05,930
have to figure it out some way and most

00:34:03,470 --> 00:34:09,500
of these things are about figuring that

00:34:05,930 --> 00:34:11,780
out and then using that to sate your

00:34:09,500 --> 00:34:13,250
delivery rate locally so you're not

00:34:11,780 --> 00:34:20,660
putting pressure on downstream buffers

00:34:13,250 --> 00:34:22,130
the last one is the one I really want to

00:34:20,660 --> 00:34:26,390
highlight and it's sort of the subject

00:34:22,130 --> 00:34:29,570
of the pitch here the current way we're

00:34:26,390 --> 00:34:31,310
doing a fap it doesn't work every we

00:34:29,570 --> 00:34:34,040
can't work can't work anywhere it

00:34:31,310 --> 00:34:36,460
doesn't work well in home routers it

00:34:34,040 --> 00:34:41,720
doesn't work well in data center routers

00:34:36,460 --> 00:34:43,370
or switches I eat it's not sufficiently

00:34:41,720 --> 00:34:49,700
constrained it's looking at the wrong

00:34:43,370 --> 00:34:52,910
thing we need something that allows us a

00:34:49,700 --> 00:34:53,810
more nuanced control the bottlenecks or

00:34:52,910 --> 00:34:56,540
remote that means they're not

00:34:53,810 --> 00:34:58,700
one-size-fits-all you can't look at your

00:34:56,540 --> 00:35:02,270
NIC and say oh you're a gig that's how

00:34:58,700 --> 00:35:05,030
fast I'll give you packets or I will go

00:35:02,270 --> 00:35:06,830
as fast as my Nick wants to go it

00:35:05,030 --> 00:35:09,380
doesn't matter how fast your Nick wants

00:35:06,830 --> 00:35:12,170
to go what matters is how fast the

00:35:09,380 --> 00:35:14,390
bottleneck wants to go and that's

00:35:12,170 --> 00:35:17,030
different for different sets of traffic

00:35:14,390 --> 00:35:18,950
and you need to figure it out and when

00:35:17,030 --> 00:35:21,290
you figure it out you need to act on it

00:35:18,950 --> 00:35:25,400
so that you don't put too much pressure

00:35:21,290 --> 00:35:28,130
on it here we're dealing with lots of

00:35:25,400 --> 00:35:30,800
different traffic anchor grits not flows

00:35:28,130 --> 00:35:33,080
whatever they happen to be this is like

00:35:30,800 --> 00:35:35,570
all the packets that are going over the

00:35:33,080 --> 00:35:37,280
wind link all the packets are going up

00:35:35,570 --> 00:35:38,620
to my tour all the packets that are

00:35:37,280 --> 00:35:43,610
going to that server

00:35:38,620 --> 00:35:45,530
lots of collections and many different

00:35:43,610 --> 00:35:48,880
collections simultaneously in packets

00:35:45,530 --> 00:35:54,160
participating in multiple connections

00:35:48,880 --> 00:35:59,000
bbr is looking at a bottleneck that's on

00:35:54,160 --> 00:36:01,490
some dsl tail going out to a user is

00:35:59,000 --> 00:36:04,730
picking a packet rate based on that

00:36:01,490 --> 00:36:07,730
all of those user connections are being

00:36:04,730 --> 00:36:10,820
collected into one group that's going

00:36:07,730 --> 00:36:14,210
over a particular fiber color across the

00:36:10,820 --> 00:36:17,540
land and that color can only handle

00:36:14,210 --> 00:36:20,150
about two gigabits per second of

00:36:17,540 --> 00:36:22,040
additional traffic so there's a shaper

00:36:20,150 --> 00:36:25,760
at the host this is all right everything

00:36:22,040 --> 00:36:28,220
Dustin for that wine color can only go

00:36:25,760 --> 00:36:30,650
two gigabits per second and then finally

00:36:28,220 --> 00:36:33,650
there's some length that says and I can

00:36:30,650 --> 00:36:36,349
only go ten gate per second so you get

00:36:33,650 --> 00:36:37,940
the composition of those different

00:36:36,349 --> 00:36:40,580
constraints and each constraint with

00:36:37,940 --> 00:36:42,349
different packets in it you need a

00:36:40,580 --> 00:36:47,089
mechanism that would let you express

00:36:42,349 --> 00:36:53,210
that from the protocol stack all the way

00:36:47,089 --> 00:36:55,690
out the carousel paper in sitcom 17 was

00:36:53,210 --> 00:37:00,260
such a mechanism and it's pretty simple

00:36:55,690 --> 00:37:03,680
the core idea is you get rid of the

00:37:00,260 --> 00:37:06,670
picture that we have today which is a

00:37:03,680 --> 00:37:10,760
bunch of pack of streams they get

00:37:06,670 --> 00:37:14,180
classified shoved into a bunch of queues

00:37:10,760 --> 00:37:16,970
which set the policy for that particular

00:37:14,180 --> 00:37:20,089
collection of packets so we have things

00:37:16,970 --> 00:37:24,410
like a protocol figuring out how fast a

00:37:20,089 --> 00:37:27,760
particular color of traffic should go

00:37:24,410 --> 00:37:31,880
here one particular flow or connection

00:37:27,760 --> 00:37:33,710
but in addition to the color packets are

00:37:31,880 --> 00:37:38,390
aggregated different ways like this is

00:37:33,710 --> 00:37:40,970
when traffic this is traffic to a slow

00:37:38,390 --> 00:37:42,050
downstream ISP that goes in two

00:37:40,970 --> 00:37:44,349
different queues which all have

00:37:42,050 --> 00:37:47,119
different shaping rates there's a

00:37:44,349 --> 00:37:49,580
service discipline pulling packets off

00:37:47,119 --> 00:37:51,920
those queues as they're allowed to be

00:37:49,580 --> 00:37:56,930
sent there and then sending them down to

00:37:51,920 --> 00:38:02,119
a NIC so I mean that works not very

00:37:56,930 --> 00:38:04,160
flexible hard to set up if instead you

00:38:02,119 --> 00:38:06,380
say this is all about figuring out when

00:38:04,160 --> 00:38:08,810
packets can go in the wire if we put a

00:38:06,380 --> 00:38:11,450
timestamp in the packet that gives the

00:38:08,810 --> 00:38:12,720
earliest legal departure time for this

00:38:11,450 --> 00:38:16,109
packet

00:38:12,720 --> 00:38:18,869
the way that we then shape it is send it

00:38:16,109 --> 00:38:26,329
through a bunch of policy blocks sort of

00:38:18,869 --> 00:38:34,650
the equivalent of the fur queueing

00:38:26,329 --> 00:38:37,589
shapers or going black the very is

00:38:34,650 --> 00:38:41,130
shaping subsystems in Linux cutis but

00:38:37,589 --> 00:38:43,260
you don't need the Q part what you do is

00:38:41,130 --> 00:38:44,880
look at the traffic and say okay based

00:38:43,260 --> 00:38:47,369
on the packets that have recently gone

00:38:44,880 --> 00:38:50,069
through me the next time I can accept a

00:38:47,369 --> 00:38:53,309
packet is time X and I look in the

00:38:50,069 --> 00:38:56,579
packet the packet says has a time in it

00:38:53,309 --> 00:38:58,470
and the time is after X says cool you

00:38:56,579 --> 00:38:59,130
can go because you're not constrained by

00:38:58,470 --> 00:39:01,559
my shaper

00:38:59,130 --> 00:39:03,960
so unless the packet go through and then

00:39:01,559 --> 00:39:06,990
it updates the next packet apart your

00:39:03,960 --> 00:39:09,809
time or it looks in the packet package

00:39:06,990 --> 00:39:12,510
as some timestamp that's less than the

00:39:09,809 --> 00:39:15,119
next departure time so you say oh you

00:39:12,510 --> 00:39:17,220
can't go until time X so you replace the

00:39:15,119 --> 00:39:19,710
timestamp in the packet with X and you

00:39:17,220 --> 00:39:22,470
send it on towards the neck it's purely

00:39:19,710 --> 00:39:24,240
computational because rather than

00:39:22,470 --> 00:39:26,160
queueing things you're changing the

00:39:24,240 --> 00:39:27,539
timestamp it has the same effect it's

00:39:26,160 --> 00:39:30,000
going to determine when the pack that

00:39:27,539 --> 00:39:37,410
hits the wire but it means that the

00:39:30,000 --> 00:39:40,349
packets all flow through so you move the

00:39:37,410 --> 00:39:42,359
scheduling state from being implicit in

00:39:40,349 --> 00:39:45,599
the structure of a queue and having a

00:39:42,359 --> 00:39:50,039
long concatenation of queues to explicit

00:39:45,599 --> 00:39:52,770
as a field in the xkp so it moves with

00:39:50,039 --> 00:39:54,750
the packet and then it's implemented by

00:39:52,770 --> 00:40:01,349
a single scheduler this sitting right up

00:39:54,750 --> 00:40:04,410
in front of the neck so why would you do

00:40:01,349 --> 00:40:06,510
that well it's a superset of what a

00:40:04,410 --> 00:40:10,319
queue does it's functionally equivalent

00:40:06,510 --> 00:40:13,920
will do everything that akyuu does but

00:40:10,319 --> 00:40:16,230
we'll do some additional stuff when it's

00:40:13,920 --> 00:40:19,140
doing what a queue does it does it

00:40:16,230 --> 00:40:20,990
faster queues and timing wheels are both

00:40:19,140 --> 00:40:24,080
order one

00:40:20,990 --> 00:40:25,880
but in a queue

00:40:24,080 --> 00:40:28,220
you've got packets linked to other

00:40:25,880 --> 00:40:31,580
packets so when you're moving packets

00:40:28,220 --> 00:40:33,740
onto an out of the queue you're taking

00:40:31,580 --> 00:40:35,660
additional cash misses you not only have

00:40:33,740 --> 00:40:38,030
the packet you're dealing with which is

00:40:35,660 --> 00:40:39,560
hot in the cash but you've also got the

00:40:38,030 --> 00:40:43,400
packet you've got to link it to which

00:40:39,560 --> 00:40:44,780
probably not hot in the cash and since

00:40:43,400 --> 00:40:47,500
their double ended queue you're linking

00:40:44,780 --> 00:40:50,630
forward and backwards so you get

00:40:47,500 --> 00:40:55,119
additional memory traffic in a queue

00:40:50,630 --> 00:40:58,850
that you don't have in a timing wheel

00:40:55,119 --> 00:41:01,670
it's not only cash friendly but it's

00:40:58,850 --> 00:41:04,520
also RCU friendly pretty much the same

00:41:01,670 --> 00:41:07,970
reasons there's a single slot the packet

00:41:04,520 --> 00:41:11,560
gets laid in a slot in this linear

00:41:07,970 --> 00:41:15,110
structure that's made for our Cu you can

00:41:11,560 --> 00:41:18,410
read it lock free which means you can

00:41:15,110 --> 00:41:24,470
figure out the constraints super cheap

00:41:18,410 --> 00:41:28,310
and you can use the RCU update also make

00:41:24,470 --> 00:41:37,369
a lock free fairly minimal cost because

00:41:28,310 --> 00:41:40,460
it's a single slot you get to choose the

00:41:37,369 --> 00:41:43,580
length of the timing wheel and unlike

00:41:40,460 --> 00:41:45,950
the length of a queue you can choose a

00:41:43,580 --> 00:41:49,369
physically meaningful length because

00:41:45,950 --> 00:41:50,840
it's in time and what you want in the

00:41:49,369 --> 00:41:53,240
length of a queue is something that

00:41:50,840 --> 00:41:57,950
amortized this time right

00:41:53,240 --> 00:42:00,550
what bql is all about is estimating how

00:41:57,950 --> 00:42:05,020
much interrupt latency in bus latency is

00:42:00,550 --> 00:42:08,990
between the queue - subsystem the

00:42:05,020 --> 00:42:11,600
drivers initial input output routine and

00:42:08,990 --> 00:42:14,090
the device all the way to pack a

00:42:11,600 --> 00:42:16,640
completion so you want a queue enough

00:42:14,090 --> 00:42:20,090
downstream to the device to cover that

00:42:16,640 --> 00:42:21,740
latency but very little more because

00:42:20,090 --> 00:42:24,590
anything you push downstream you've lost

00:42:21,740 --> 00:42:26,570
control of you're saying oh the

00:42:24,590 --> 00:42:28,340
network's gonna have to figure out what

00:42:26,570 --> 00:42:30,320
to do about these packets because I

00:42:28,340 --> 00:42:34,160
can't rewarder things I can't mix them

00:42:30,320 --> 00:42:35,750
up once I push them downstream so

00:42:34,160 --> 00:42:37,340
coo-all says well i can figure out how

00:42:35,750 --> 00:42:40,580
much latency I've got to cover I won't

00:42:37,340 --> 00:42:42,980
let any more packets go downstream then

00:42:40,580 --> 00:42:46,370
we'll cover that latency plus you know a

00:42:42,980 --> 00:42:48,410
little bit of extra room that happens

00:42:46,370 --> 00:42:51,380
automatically in a timing wheel because

00:42:48,410 --> 00:42:53,630
it's time which is what you're trying to

00:42:51,380 --> 00:42:56,450
cover when you're trying to mask a

00:42:53,630 --> 00:42:58,880
latency so you can set the length or the

00:42:56,450 --> 00:43:00,590
timing will if you takes 10 microseconds

00:42:58,880 --> 00:43:03,440
to get an interrupt Senator 20

00:43:00,590 --> 00:43:07,190
microseconds that will keep things 100%

00:43:03,440 --> 00:43:10,700
busy while keeping a minimum cue you

00:43:07,190 --> 00:43:12,260
said it's a little bit longer but okay

00:43:10,700 --> 00:43:14,090
you lose control of the packets if you

00:43:12,260 --> 00:43:15,560
push them downstream and your caches

00:43:14,090 --> 00:43:18,530
stop working if you push things

00:43:15,560 --> 00:43:20,870
downstream because the things that are

00:43:18,530 --> 00:43:22,490
closest to the Nick or things that

00:43:20,870 --> 00:43:23,750
haven't been touched in a long time

00:43:22,490 --> 00:43:24,980
which means that they've been flushed

00:43:23,750 --> 00:43:34,400
from the cache even though they were

00:43:24,980 --> 00:43:37,160
initially built in the cache say you can

00:43:34,400 --> 00:43:39,650
easily get packets like you start a

00:43:37,160 --> 00:43:42,680
MapReduce and suddenly 50,000 processes

00:43:39,650 --> 00:43:52,370
do the reduce steps so they want to send

00:43:42,680 --> 00:43:54,950
their results so huge influx of data you

00:43:52,370 --> 00:43:59,000
start to queue those as soon as you've

00:43:54,950 --> 00:44:02,780
hit the event horizon you know because

00:43:59,000 --> 00:44:05,180
you're keeping track of how the time on

00:44:02,780 --> 00:44:07,070
the wire has been allocated basically

00:44:05,180 --> 00:44:11,570
the timing will is a picture of the time

00:44:07,070 --> 00:44:16,480
on the wire you know that you've got all

00:44:11,570 --> 00:44:19,010
that you can handle so you can either

00:44:16,480 --> 00:44:21,710
propagate an error back up to the sender

00:44:19,010 --> 00:44:24,590
saying you've asked me to send something

00:44:21,710 --> 00:44:28,100
too far in the future or more likely you

00:44:24,590 --> 00:44:30,830
can put a call back on a second level

00:44:28,100 --> 00:44:34,100
timing wheel one that's working on time

00:44:30,830 --> 00:44:37,670
scales that are multiples of the event

00:44:34,100 --> 00:44:39,890
horizon time and say okay at this point

00:44:37,670 --> 00:44:43,250
in the future you will be eligible to

00:44:39,890 --> 00:44:44,710
send and I will give you a call back so

00:44:43,250 --> 00:44:49,150
that you can inject your packet then

00:44:44,710 --> 00:44:50,890
so this is a tsq like mechanism that

00:44:49,150 --> 00:44:53,589
kind of crawl back already exists for

00:44:50,890 --> 00:44:56,260
the TCP small queues limit but unlike

00:44:53,589 --> 00:44:59,200
tsq you've now got a meaningful bound on

00:44:56,260 --> 00:45:01,990
it tsq only lets a flow put in three

00:44:59,200 --> 00:45:06,280
packets but if you've got 50,000 flows

00:45:01,990 --> 00:45:09,490
that's still a welcome big queue here

00:45:06,280 --> 00:45:11,589
you can only put in whatever the horizon

00:45:09,490 --> 00:45:14,440
is and millisecond worth of packets the

00:45:11,589 --> 00:45:16,180
rest of its handled by callbacks they're

00:45:14,440 --> 00:45:17,559
all event-driven so there's not a lot of

00:45:16,180 --> 00:45:22,839
polling or other infrastructure

00:45:17,559 --> 00:45:27,130
associated and because the horizon puts

00:45:22,839 --> 00:45:32,010
a hard bound on the active output bytes

00:45:27,130 --> 00:45:35,349
the you know it's the heart bound is

00:45:32,010 --> 00:45:40,740
nick rate times whatever the horizon

00:45:35,349 --> 00:45:44,440
time is that's Vice per second times

00:45:40,740 --> 00:45:51,540
seconds equals bytes is a bandwidth

00:45:44,440 --> 00:45:51,540
delay product that's a hard bound on how

00:45:51,660 --> 00:46:02,079
poor in time the oldest packet sent to

00:45:57,460 --> 00:46:04,540
the NIC is if it's short with high

00:46:02,079 --> 00:46:06,420
probability that's still sitting in l3

00:46:04,540 --> 00:46:08,680
cache because that's where it was built

00:46:06,420 --> 00:46:11,530
which means that if you've got a system

00:46:08,680 --> 00:46:13,119
that can DNA from l3 it runs out of cash

00:46:11,530 --> 00:46:19,000
rather than running out of memory so

00:46:13,119 --> 00:46:21,490
things speed up if you've got this model

00:46:19,000 --> 00:46:22,780
queue just get really easy because they

00:46:21,490 --> 00:46:26,680
don't whole pack us anymore they're

00:46:22,780 --> 00:46:28,660
purely computational you just push them

00:46:26,680 --> 00:46:30,869
through you update the cutest state that

00:46:28,660 --> 00:46:35,530
says all right what's the next time

00:46:30,869 --> 00:46:39,010
stamp that I enforce but that's it what

00:46:35,530 --> 00:46:41,619
that means is a win for both ends the

00:46:39,010 --> 00:46:44,380
driver gets to see all the packets

00:46:41,619 --> 00:46:47,589
because that's where the queue is and so

00:46:44,380 --> 00:46:50,260
drivers right now like Wi-Fi where you

00:46:47,589 --> 00:46:52,609
have to turn off cutis because the

00:46:50,260 --> 00:46:55,609
driver needs to aggregate packets

00:46:52,609 --> 00:46:57,410
and it will try to defeat any cutis you

00:46:55,609 --> 00:47:00,079
put in front of it by pulling packets

00:46:57,410 --> 00:47:02,719
too early so that it can see them to

00:47:00,079 --> 00:47:04,759
aggregate by destination well now all

00:47:02,719 --> 00:47:07,099
the drivers get to see all of the

00:47:04,759 --> 00:47:09,319
packets as soon as possible as soon as

00:47:07,099 --> 00:47:11,390
they're shipped so they can do really

00:47:09,319 --> 00:47:14,089
efficient aggregation they now work with

00:47:11,390 --> 00:47:16,009
the cutest rather than against them they

00:47:14,089 --> 00:47:17,359
call the library routine that implements

00:47:16,009 --> 00:47:20,630
the timing wheel but that's it

00:47:17,359 --> 00:47:24,499
at the other end when you're doing a

00:47:20,630 --> 00:47:27,559
send Sand calls through all of those

00:47:24,499 --> 00:47:30,049
cutest Sall of the constraints every one

00:47:27,559 --> 00:47:32,449
of them looks at the packet according to

00:47:30,049 --> 00:47:35,390
its constraint rules updates the

00:47:32,449 --> 00:47:38,059
timestamp when you get done in the

00:47:35,390 --> 00:47:41,599
packet is queued the timestamp in that

00:47:38,059 --> 00:47:46,219
skp says when this package is going to

00:47:41,599 --> 00:47:48,019
hit the wire so the sender the thing at

00:47:46,219 --> 00:47:51,019
the same call when the send call returns

00:47:48,019 --> 00:47:52,849
it says oh this packet tells me that

00:47:51,019 --> 00:47:54,289
it's not going to go on the wire for 100

00:47:52,849 --> 00:47:57,439
milliseconds and I don't want to wait

00:47:54,289 --> 00:48:01,279
that long I'm going to use plan B it now

00:47:57,439 --> 00:48:04,160
knows as early as possible what the

00:48:01,279 --> 00:48:06,199
implications of its send are when the

00:48:04,160 --> 00:48:08,509
send is going to happen and so it can be

00:48:06,199 --> 00:48:10,069
smart about that it can either adapt the

00:48:08,509 --> 00:48:13,579
delay if this thing that's concerned

00:48:10,069 --> 00:48:15,670
about phase and inter packet times or

00:48:13,579 --> 00:48:18,229
can plant information on applications

00:48:15,670 --> 00:48:23,890
saying this is going to take a long time

00:48:18,229 --> 00:48:28,910
if you've gotten altering to do it so

00:48:23,890 --> 00:48:31,009
this is working because you're making a

00:48:28,910 --> 00:48:34,969
picture a packets on the wire it's a

00:48:31,009 --> 00:48:36,619
really direct implementation in memory

00:48:34,969 --> 00:48:40,969
simulation of what you're trying to

00:48:36,619 --> 00:48:43,819
accomplish and what that means is any

00:48:40,969 --> 00:48:46,880
pattern of packets on the wire that you

00:48:43,819 --> 00:48:49,819
have a reason to construct this

00:48:46,880 --> 00:48:53,449
mechanism can make it can put it there

00:48:49,819 --> 00:48:56,089
for you that's really unlike queues they

00:48:53,449 --> 00:48:57,849
have big constraints on the kind of

00:48:56,089 --> 00:49:00,369
queueing mechanisms you've got

00:48:57,849 --> 00:49:04,059
and there's a particular one that we've

00:49:00,369 --> 00:49:07,209
wanted for years ever since indeed is

00:49:04,059 --> 00:49:10,089
thisis saying look the metric you really

00:49:07,209 --> 00:49:11,619
want to optimize in service and

00:49:10,089 --> 00:49:14,769
transactional systems this completion

00:49:11,619 --> 00:49:18,849
rate not fairness because if you've got

00:49:14,769 --> 00:49:20,859
two multi-party transactions if you

00:49:18,849 --> 00:49:26,190
schedule them interleave they both

00:49:20,859 --> 00:49:29,380
finish at the same time that's fair but

00:49:26,190 --> 00:49:31,719
if you were to send all of one and then

00:49:29,380 --> 00:49:33,910
all of the other that first one is going

00:49:31,719 --> 00:49:35,440
to finish in half the time the second

00:49:33,910 --> 00:49:38,140
one's going to finish in the same time

00:49:35,440 --> 00:49:42,249
as if you mix them together so you've

00:49:38,140 --> 00:49:47,199
reduced the total service time by at

00:49:42,249 --> 00:49:51,029
least 25% because one finishes and time

00:49:47,199 --> 00:49:51,029
one and the other finishes at time two

00:49:51,269 --> 00:49:58,569
potentially a lot more than that if the

00:49:55,059 --> 00:50:03,039
transactions as soon as they arrive they

00:49:58,569 --> 00:50:04,839
can be processed if you do fare you're

00:50:03,039 --> 00:50:06,759
causing everything to arrive at once

00:50:04,839 --> 00:50:09,269
which means you hold off all the

00:50:06,759 --> 00:50:12,400
processing until everything is there

00:50:09,269 --> 00:50:14,949
maximizes the memory pressure minimizes

00:50:12,400 --> 00:50:18,519
the parallelism it's really stupid so

00:50:14,949 --> 00:50:21,999
we'd like to use service policies for

00:50:18,519 --> 00:50:23,949
transactional traffic to keep all of our

00:50:21,999 --> 00:50:27,489
transaction together about round-robin

00:50:23,949 --> 00:50:31,209
among transactions you can't express

00:50:27,489 --> 00:50:33,880
that with any existing queue disk it's

00:50:31,209 --> 00:50:37,719
just no way to say it because only the

00:50:33,880 --> 00:50:40,660
app knows about transactions it's really

00:50:37,719 --> 00:50:43,479
easy to express the timing wheel you

00:50:40,660 --> 00:50:45,670
just put the same timestamp on all of

00:50:43,479 --> 00:50:47,890
the packets for one transaction it says

00:50:45,670 --> 00:50:50,739
all these guys are one unit they'll go

00:50:47,890 --> 00:50:56,440
together carry soon it all works

00:50:50,739 --> 00:50:59,700
move the first one they all move so

00:50:56,440 --> 00:51:00,950
that's all I had to say

00:50:59,700 --> 00:51:03,900
[Music]

00:51:00,950 --> 00:51:05,220
small change right throw away ik you put

00:51:03,900 --> 00:51:08,340
at a time you will functionally

00:51:05,220 --> 00:51:11,910
equivalent put another field in packets

00:51:08,340 --> 00:51:16,260
got a timestamp cutis get simpler system

00:51:11,910 --> 00:51:19,380
gets more capable it's faster so you

00:51:16,260 --> 00:51:20,940
know I'm voting why don't we do it we

00:51:19,380 --> 00:51:23,100
can do it in Linux it's really hard in

00:51:20,940 --> 00:51:31,530
other systems but it makes is like build

00:51:23,100 --> 00:51:33,390
for this so thank you so ok we're going

00:51:31,530 --> 00:51:34,740
to do this slightly different if you

00:51:33,390 --> 00:51:36,330
have a question line up with the mics

00:51:34,740 --> 00:51:46,650
instead it's a lot easier than running

00:51:36,330 --> 00:51:47,850
around hi me a cool event thank you for

00:51:46,650 --> 00:51:51,090
the presentation really interesting I

00:51:47,850 --> 00:51:52,680
think now you have like reduce the

00:51:51,090 --> 00:51:54,360
problem you had previously to a problem

00:51:52,680 --> 00:51:57,480
where you need to define the right

00:51:54,360 --> 00:52:00,240
interface between the socket API and the

00:51:57,480 --> 00:52:05,070
policy scheduling API whatever which

00:52:00,240 --> 00:52:10,070
might be also challenging any ideas I

00:52:05,070 --> 00:52:10,070
mean interface that easy right so

00:52:10,400 --> 00:52:22,380
there's already yeah I I hate the socket

00:52:19,860 --> 00:52:24,360
interface I just you know there at

00:52:22,380 --> 00:52:30,030
creation time I was part of the Berkeley

00:52:24,360 --> 00:52:32,790
UNIX group and I wish we could have done

00:52:30,030 --> 00:52:34,980
it better but we've lived with it the

00:52:32,790 --> 00:52:36,060
way that we've moved it into the futures

00:52:34,980 --> 00:52:39,660
bias ah cops

00:52:36,060 --> 00:52:41,880
so there's 60 gazillion saw cops and

00:52:39,660 --> 00:52:46,770
things that we can put in saw cops we

00:52:41,880 --> 00:52:49,710
put in mrs. send or send message tags so

00:52:46,770 --> 00:52:53,460
there are already tags that let you do

00:52:49,710 --> 00:52:54,960
per packet rates that could easily be

00:52:53,460 --> 00:52:57,030
tagged so it you do per packet

00:52:54,960 --> 00:53:00,960
timestamps that let you cross the

00:52:57,030 --> 00:53:03,750
boundary from apps to Colonel preserving

00:53:00,960 --> 00:53:05,760
the apps intent on the time structure of

00:53:03,750 --> 00:53:07,410
the traffic so it can say things like

00:53:05,760 --> 00:53:09,650
transactions order if you're doing a

00:53:07,410 --> 00:53:14,960
protocol like quick that

00:53:09,650 --> 00:53:17,450
is trying to enforce bottleneck you know

00:53:14,960 --> 00:53:19,990
tell bandwidth constraints it can say oh

00:53:17,450 --> 00:53:25,099
these packets need to be this far apart

00:53:19,990 --> 00:53:27,529
at the other end if rather than doing a

00:53:25,099 --> 00:53:31,400
timing wheel in software which is really

00:53:27,529 --> 00:53:33,230
problematic if you 100 gig you've got

00:53:31,400 --> 00:53:36,859
something microsecond packets that's

00:53:33,230 --> 00:53:40,190
really not software timing space and you

00:53:36,859 --> 00:53:42,829
like to run at 95% which is really fine

00:53:40,190 --> 00:53:46,069
grain dicks already have timers in them

00:53:42,829 --> 00:53:48,380
the protocol that contention protocol

00:53:46,069 --> 00:53:53,059
and Ethernet requires that they be able

00:53:48,380 --> 00:53:56,660
to back off small times compared to

00:53:53,059 --> 00:53:59,150
packet times so in the NIC you can

00:53:56,660 --> 00:54:01,039
easily put the timing wheel you have to

00:53:59,150 --> 00:54:03,440
agree on conventions between the two

00:54:01,039 --> 00:54:07,130
ends but that doesn't mean synchronize

00:54:03,440 --> 00:54:10,059
clocks because these departure time

00:54:07,130 --> 00:54:16,869
stamps are just the relationship between

00:54:10,059 --> 00:54:20,510
two packets from the same source and

00:54:16,869 --> 00:54:22,700
because it's a difference the clock

00:54:20,510 --> 00:54:26,809
offset doesn't matter at all which means

00:54:22,700 --> 00:54:31,549
both from application level and across

00:54:26,809 --> 00:54:34,819
hardware boundaries when the downstream

00:54:31,549 --> 00:54:38,660
is accepting packets from particular

00:54:34,819 --> 00:54:40,640
descriptor ring a particular source it

00:54:38,660 --> 00:54:45,559
has to keep associated with that ring a

00:54:40,640 --> 00:54:48,589
clock offset from the timestamps in that

00:54:45,559 --> 00:54:50,539
source to a silikal clock it can set the

00:54:48,589 --> 00:54:55,390
offset when it gets the first packet and

00:54:50,539 --> 00:54:58,849
then just use it to map the timestamps

00:54:55,390 --> 00:55:01,099
from whatever the source clock was to

00:54:58,849 --> 00:55:05,329
its local clock as it gets each no

00:55:01,099 --> 00:55:09,230
timestamp and if it doesn't get packets

00:55:05,329 --> 00:55:10,760
for a long time it resets picks the new

00:55:09,230 --> 00:55:13,400
offset so you can make a really

00:55:10,760 --> 00:55:15,780
lightweight coordination protocol that's

00:55:13,400 --> 00:55:21,690
not like a time sync protocol

00:55:15,780 --> 00:55:23,880
that enforces the timing constraints but

00:55:21,690 --> 00:55:26,010
works across boundaries where clock

00:55:23,880 --> 00:55:30,050
synchronization is really approximate or

00:55:26,010 --> 00:55:34,320
undesirable that answers a question I

00:55:30,050 --> 00:55:35,610
was more thinking about like how - there

00:55:34,320 --> 00:55:37,380
must be a step where you have like

00:55:35,610 --> 00:55:40,290
application intents or whatever or

00:55:37,380 --> 00:55:42,110
socket intents that transfer transfer

00:55:40,290 --> 00:55:47,220
this information into a time stamp

00:55:42,110 --> 00:55:52,220
basically yeah so we're the model is

00:55:47,220 --> 00:55:57,770
were just annotating the packets so it's

00:55:52,220 --> 00:56:00,480
packet by packet but rather the

00:55:57,770 --> 00:56:03,510
implicitly declaring the departure order

00:56:00,480 --> 00:56:05,630
by handing the packet to the interface

00:56:03,510 --> 00:56:09,300
at the time that we wanted to go out

00:56:05,630 --> 00:56:11,520
we're explicitly declaring the

00:56:09,300 --> 00:56:13,200
separation between packets which means

00:56:11,520 --> 00:56:15,330
that we can present them early I

00:56:13,200 --> 00:56:20,550
wouldn't have sent them in larger units

00:56:15,330 --> 00:56:22,350
than one at a time and because it's per

00:56:20,550 --> 00:56:25,840
packet annotation at least in socket

00:56:22,350 --> 00:56:28,280
interface that's easy as we go to better

00:56:25,840 --> 00:56:31,740
[Music]

00:56:28,280 --> 00:56:38,000
interfaces you know wherever you're

00:56:31,740 --> 00:56:40,590
describing a packet to your interface

00:56:38,000 --> 00:56:43,500
subsystem there needs to be a slot for a

00:56:40,590 --> 00:56:44,670
timestamp I'm working in the IETF and

00:56:43,500 --> 00:56:47,070
there's a working group called taps

00:56:44,670 --> 00:56:48,930
which looks at this interface and there

00:56:47,070 --> 00:56:50,220
we go away from the socket interface and

00:56:48,930 --> 00:56:51,480
rather to get like a message based

00:56:50,220 --> 00:56:53,940
interface because that's what he usually

00:56:51,480 --> 00:56:56,430
needs to do so like what we have in this

00:56:53,940 --> 00:56:58,140
interface is giving like a latest

00:56:56,430 --> 00:56:59,640
timestamp basically like this is the

00:56:58,140 --> 00:57:01,530
latest point of time where the packet is

00:56:59,640 --> 00:57:03,720
still useful to send out but we didn't

00:57:01,530 --> 00:57:05,460
consider like kind of what's the what's

00:57:03,720 --> 00:57:06,690
the right point or like the earliest or

00:57:05,460 --> 00:57:15,440
whatever so something we have to think

00:57:06,690 --> 00:57:20,610
about there so it's probably one

00:57:15,440 --> 00:57:25,170
answer the question but this was an

00:57:20,610 --> 00:57:29,010
issue that came up sort of what's the

00:57:25,170 --> 00:57:31,860
right service model in an IP like

00:57:29,010 --> 00:57:34,350
protocol C so what was the right service

00:57:31,860 --> 00:57:36,450
model for IP to present a TCP what was

00:57:34,350 --> 00:57:44,840
the right service model for an interface

00:57:36,450 --> 00:57:48,780
to present to IP and the thought behind

00:57:44,840 --> 00:57:51,750
best effort was stuff happens and so

00:57:48,780 --> 00:57:56,870
anything tighter than that unless you

00:57:51,750 --> 00:58:03,090
can handle a variable world which is

00:57:56,870 --> 00:58:04,800
things can get worse they there's a

00:58:03,090 --> 00:58:08,100
limit to how much better they can get

00:58:04,800 --> 00:58:09,930
right you can't move things faster than

00:58:08,100 --> 00:58:15,660
the speed of light similarly when you're

00:58:09,930 --> 00:58:18,000
queuing you can say the earliest I want

00:58:15,660 --> 00:58:20,580
this pack to go out is now or sometime

00:58:18,000 --> 00:58:25,110
later than now but you can't go back in

00:58:20,580 --> 00:58:27,180
time you know all your offsets times can

00:58:25,110 --> 00:58:29,880
only get pushed in the future queuing is

00:58:27,180 --> 00:58:32,160
really asymmetric and packet

00:58:29,880 --> 00:58:36,150
interferences really asymmetric which

00:58:32,160 --> 00:58:39,090
means that you can unambiguously say

00:58:36,150 --> 00:58:42,990
this is the earliest this packet should

00:58:39,090 --> 00:58:44,850
leave that is always meaningful says

00:58:42,990 --> 00:58:50,070
it's something no value if you send it

00:58:44,850 --> 00:58:53,070
before this time but I have absolutely

00:58:50,070 --> 00:58:55,710
no say over whether you're going to have

00:58:53,070 --> 00:58:58,640
to send it later than this time because

00:58:55,710 --> 00:59:03,480
that's not a choice you get to make

00:58:58,640 --> 00:59:05,340
that's determined by sharing the lengths

00:59:03,480 --> 00:59:10,080
of the traffic conditions interference

00:59:05,340 --> 00:59:12,240
and in that philosophy it's it seems

00:59:10,080 --> 00:59:15,480
like there's only one reasonable choice

00:59:12,240 --> 00:59:18,060
for the timestamps that say this is the

00:59:15,480 --> 00:59:21,090
earliest it can go out but in the best

00:59:18,060 --> 00:59:21,940
effort spirit it can go out later than

00:59:21,090 --> 00:59:24,490
this

00:59:21,940 --> 00:59:30,970
and there's no real constraint on how

00:59:24,490 --> 00:59:34,210
much later accept the fact that the

00:59:30,970 --> 00:59:37,079
departure time is determined by state in

00:59:34,210 --> 00:59:40,809
cutis that was set by previous packets

00:59:37,079 --> 00:59:42,609
means you could ask the question if I

00:59:40,809 --> 00:59:46,240
gave you this packet when would it hit

00:59:42,609 --> 00:59:48,250
the wire you can walk through all the

00:59:46,240 --> 00:59:51,760
cutest that's a read-only operation

00:59:48,250 --> 00:59:54,880
doesn't mutate state it's really cheap

00:59:51,760 --> 00:59:56,589
you know there's a chain of about you in

00:59:54,880 --> 01:00:01,000
computation elements they all look about

00:59:56,589 --> 01:00:02,530
the same you know ten or so and you get

01:00:01,000 --> 01:00:04,089
back a number that says if you gave this

01:00:02,530 --> 01:00:07,450
to me it's going to go out in 200

01:00:04,089 --> 01:00:10,420
milliseconds and say thank you very much

01:00:07,450 --> 01:00:14,619
I'm going to do something else so you

01:00:10,420 --> 01:00:17,410
can inspect the time really cheaply with

01:00:14,619 --> 01:00:20,730
this architecture but you can't really

01:00:17,410 --> 01:00:22,990
control it we should probably take this

01:00:20,730 --> 01:00:24,280
offline but like we look at the

01:00:22,990 --> 01:00:26,859
interface that is between like the

01:00:24,280 --> 01:00:28,569
transport and the application and we

01:00:26,859 --> 01:00:30,039
have this deadline there because

01:00:28,569 --> 01:00:31,869
basically what you're saying is if you

01:00:30,039 --> 01:00:33,520
try to send this packet out after this

01:00:31,869 --> 01:00:35,770
deadline the receiver will throw away it

01:00:33,520 --> 01:00:37,510
anyway like you can still send it out or

01:00:35,770 --> 01:00:38,890
even if you send it before it might be

01:00:37,510 --> 01:00:40,000
thrown away by the sender but like after

01:00:38,890 --> 01:00:41,559
this deadline I don't know like it's not

01:00:40,000 --> 01:00:45,460
useful anymore that's the kind of

01:00:41,559 --> 01:00:49,630
deadline we have yeah should take that

01:00:45,460 --> 01:00:54,130
offline it's it's a good discussion tom

01:00:49,630 --> 01:00:56,289
herbert so stuff is great I think the

01:00:54,130 --> 01:00:59,099
operative question from this audience

01:00:56,289 --> 01:01:03,089
would be how do we get this into Linux I

01:00:59,099 --> 01:01:03,089
I think it's pretty painless

01:01:05,890 --> 01:01:13,150
hey yeah I think the short answer for a

01:01:10,540 --> 01:01:15,310
lot of these things is for us is talk to

01:01:13,150 --> 01:01:17,470
Eric Dumas a and convinced him that it

01:01:15,310 --> 01:01:21,640
could be analytics and full powers

01:01:17,470 --> 01:01:29,500
leaders there so the answer for me is

01:01:21,640 --> 01:01:32,050
trying to talk Eric into it just throw

01:01:29,500 --> 01:01:33,340
something out so it's a little bit

01:01:32,050 --> 01:01:34,900
unfortunate for the term queueing

01:01:33,340 --> 01:01:36,520
discipline there's a little bit of a

01:01:34,900 --> 01:01:39,340
misnomer it's actually a packet

01:01:36,520 --> 01:01:41,560
scheduler mechanism we can do arbitrary

01:01:39,340 --> 01:01:43,060
things in queueing disciplines so for

01:01:41,560 --> 01:01:44,680
instance employment in carousel and

01:01:43,060 --> 01:01:47,460
Okuma queueing discipline putting the

01:01:44,680 --> 01:01:50,140
timer wheel there to do that then

01:01:47,460 --> 01:01:53,980
instantaneously that would provide some

01:01:50,140 --> 01:01:56,830
level of granularity for the solution up

01:01:53,980 --> 01:01:58,420
to bql but for all drivers and then

01:01:56,830 --> 01:02:00,970
subsequently maybe figure out how to

01:01:58,420 --> 01:02:05,530
offload that functionality into devices

01:02:00,970 --> 01:02:07,060
right so yeah let me answer the right

01:02:05,530 --> 01:02:10,930
question which is evolutionary strategy

01:02:07,060 --> 01:02:13,420
so if all packets are born with a

01:02:10,930 --> 01:02:18,270
timestamp that says send it now which is

01:02:13,420 --> 01:02:23,680
a fountains the current semantics then

01:02:18,270 --> 01:02:27,760
all of the cutest that we have today

01:02:23,680 --> 01:02:29,770
work exactly the way they work now no

01:02:27,760 --> 01:02:33,010
changes because they're not going to

01:02:29,770 --> 01:02:35,920
mutate the timestamp the stuff is going

01:02:33,010 --> 01:02:40,360
to show up at a driver with a timestamp

01:02:35,920 --> 01:02:42,400
that says send it at earliest this time

01:02:40,360 --> 01:02:45,550
in the past this time before a few

01:02:42,400 --> 01:02:49,480
pacing saw it and held on to it for ten

01:02:45,550 --> 01:02:50,920
milliseconds so all the packets will go

01:02:49,480 --> 01:02:54,880
through the cutest which work the way

01:02:50,920 --> 01:02:58,390
they are now get to a driver which if

01:02:54,880 --> 01:03:00,460
the driver has been changed to run off

01:02:58,390 --> 01:03:02,230
the timing wheel will say okay I can

01:03:00,460 --> 01:03:04,630
send this back up now because it's

01:03:02,230 --> 01:03:08,170
timestamp is in the past will ship out

01:03:04,630 --> 01:03:14,290
on the wire so you don't have to evolve

01:03:08,170 --> 01:03:15,660
everything at once if you can evolve sim

01:03:14,290 --> 01:03:17,459
layer

01:03:15,660 --> 01:03:20,459
sitting next to the driver output

01:03:17,459 --> 01:03:22,739
routine to handle the time stamps leave

01:03:20,459 --> 01:03:25,920
all the cutest sin tack

01:03:22,739 --> 01:03:30,539
then semantics of time stamps starts

01:03:25,920 --> 01:03:36,539
saying sent it now Otis works if you

01:03:30,539 --> 01:03:38,849
then start changing cue disks so that if

01:03:36,539 --> 01:03:41,940
the time stamp is set you follow a

01:03:38,849 --> 01:03:45,029
different path the computational part of

01:03:41,940 --> 01:03:48,749
a scheduling cutest but take out the

01:03:45,029 --> 01:03:50,849
scheduler part so that would mean some

01:03:48,749 --> 01:03:52,469
parallel code and handling the two

01:03:50,849 --> 01:03:56,219
different paths and some memory of it

01:03:52,469 --> 01:03:59,089
worst case but it lets things coexist

01:03:56,219 --> 01:04:02,969
until you've changed everything and

01:03:59,089 --> 01:04:04,529
stays backwards compatible until you've

01:04:02,969 --> 01:04:07,459
got enough change you say ok let's

01:04:04,529 --> 01:04:09,839
finish it off so there is one subtlety

01:04:07,459 --> 01:04:13,279
when you say that the driver is going to

01:04:09,839 --> 01:04:17,219
do something we have like what 200

01:04:13,279 --> 01:04:18,839
device drivers and Linux I mean we went

01:04:17,219 --> 01:04:21,660
through the bTW experience it's a long

01:04:18,839 --> 01:04:23,579
path to make an updated nature so I

01:04:21,660 --> 01:04:24,900
think like I said the path is if we

01:04:23,579 --> 01:04:27,509
could start in the queueing discipline

01:04:24,900 --> 01:04:29,670
and then move down as like offload or

01:04:27,509 --> 01:04:31,769
acceleration that's generally the kind

01:04:29,670 --> 01:04:34,559
of path but it's separate questions so

01:04:31,769 --> 01:04:36,479
carousel has been I think to find a

01:04:34,559 --> 01:04:39,479
while and I know that at least at Google

01:04:36,479 --> 01:04:41,099
there was some experimentation with it

01:04:39,479 --> 01:04:42,599
has that I've been converted to

01:04:41,099 --> 01:04:45,479
something that we could actually see in

01:04:42,599 --> 01:04:54,989
code like a queueing discipline or

01:04:45,479 --> 01:05:00,599
something so I I'm not sure about the

01:04:54,989 --> 01:05:02,400
status of carousel code but I will ask

01:05:00,599 --> 01:05:06,930
about that it's an excellent question

01:05:02,400 --> 01:05:11,309
there is a lot of deployment

01:05:06,930 --> 01:05:13,859
measurements and background given in the

01:05:11,309 --> 01:05:16,529
paper not the implementation details

01:05:13,859 --> 01:05:18,740
because its deployment context wasn't

01:05:16,529 --> 01:05:22,890
the Linux kernel

01:05:18,740 --> 01:05:25,140
and I guess I would like to change that

01:05:22,890 --> 01:05:28,440
and I need to go back and ask how we

01:05:25,140 --> 01:05:30,950
would do that yes please come up with

01:05:28,440 --> 01:05:35,130
some kind of reference implementation

01:05:30,950 --> 01:05:39,390
Eric is on ads on remote and he wanted

01:05:35,130 --> 01:05:44,849
to say something Eric can you hear me we

01:05:39,390 --> 01:05:49,320
can hear ya so I was just very very nice

01:05:44,849 --> 01:05:51,900
presentation thank you very much I was

01:05:49,320 --> 01:05:55,710
just wanting to say that we were going

01:05:51,900 --> 01:06:01,170
to send a batch series converting TCP +

01:05:55,710 --> 01:06:04,680
@ Q to this new EDT model following the

01:06:01,170 --> 01:06:08,609
recent addition in Linux of ETF packets

01:06:04,680 --> 01:06:12,140
killer implementing not exactly the

01:06:08,609 --> 01:06:14,700
ohrid the pathway of time but most the

01:06:12,140 --> 01:06:19,890
maximal time the packet is allowed to

01:06:14,700 --> 01:06:23,490
exit the host but anyway TCP will soon

01:06:19,890 --> 01:06:28,140
be converted this new model allowing for

01:06:23,490 --> 01:06:30,869
better control by TCP of the best time

01:06:28,140 --> 01:06:34,740
to leave the host and subsequently to

01:06:30,869 --> 01:06:38,720
have a better RTT estimation so it will

01:06:34,740 --> 01:06:44,849
probably help a lot at least under

01:06:38,720 --> 01:06:47,839
communications oh that's it it's great

01:06:44,849 --> 01:06:47,839
news thank you

01:06:50,940 --> 01:06:59,530
okay so my name is hi I'm John

01:06:54,339 --> 01:07:04,890
I have one question is to you to memory

01:06:59,530 --> 01:07:08,049
copy from your socket a buffer to the

01:07:04,890 --> 01:07:13,990
timing wheel buffer so these they are

01:07:08,049 --> 01:07:16,690
any memory copy between the two I say no

01:07:13,990 --> 01:07:21,640
copies the time stamps in the skp which

01:07:16,690 --> 01:07:24,309
is the buffer descriptor so the the

01:07:21,640 --> 01:07:27,670
packet and the data intact unmodified

01:07:24,309 --> 01:07:31,960
it's just that a description systems

01:07:27,670 --> 01:07:34,270
description of the packet has a pad feel

01:07:31,960 --> 01:07:35,980
that's giving the departure time it only

01:07:34,270 --> 01:07:40,480
has local meaning there's no reason for

01:07:35,980 --> 01:07:44,710
it to be in the packet as I think Eric

01:07:40,480 --> 01:07:48,369
just said right now we put what we hope

01:07:44,710 --> 01:07:52,839
is the departure time in TCP packets and

01:07:48,369 --> 01:07:54,880
quick packets say well here's we can't

01:07:52,839 --> 01:07:56,920
say the departure time we don't know it

01:07:54,880 --> 01:08:02,190
so we say here's when the Packer was

01:07:56,920 --> 01:08:05,589
built if you have a scheduled system and

01:08:02,190 --> 01:08:08,650
if you put the earliest departure time

01:08:05,589 --> 01:08:10,299
in the packets time stamp field you're

01:08:08,650 --> 01:08:12,280
expressing in your intent you're saying

01:08:10,299 --> 01:08:18,750
well this is when I wanted the packet to

01:08:12,280 --> 01:08:22,929
hit the wire and what that means is any

01:08:18,750 --> 01:08:24,640
transport imposed to ways are included

01:08:22,929 --> 01:08:26,890
in that time stamp because you're saying

01:08:24,640 --> 01:08:30,850
when you want it to leave but no system

01:08:26,890 --> 01:08:33,759
imposed delays no contention or shearing

01:08:30,850 --> 01:08:38,890
delays are included so you can

01:08:33,759 --> 01:08:40,750
accurately measure vocal delays in

01:08:38,890 --> 01:08:42,670
addition to all of that it worked away

01:08:40,750 --> 01:08:44,589
so it's a it's a big step forward for

01:08:42,670 --> 01:08:49,290
timing it makes things like a lot more

01:08:44,589 --> 01:08:52,290
precise it doesn't modify the packet

01:08:49,290 --> 01:08:53,819
you don't have to if you match the users

01:08:52,290 --> 01:08:56,160
intent if you send the packet when the

01:08:53,819 --> 01:08:59,190
agent wanted to send it okay

01:08:56,160 --> 01:09:02,640
and my next question is you put a time

01:08:59,190 --> 01:09:05,310
stamp so what was the procedure required

01:09:02,640 --> 01:09:08,219
for the this time stamp is that her like

01:09:05,310 --> 01:09:11,250
a precision opt for the microseconds or

01:09:08,219 --> 01:09:20,219
even more robust appreciation of this

01:09:11,250 --> 01:09:28,170
time and so the ethernet evolution has

01:09:20,219 --> 01:09:31,819
taught us that it's a mistake to pick a

01:09:28,170 --> 01:09:35,699
course time granularity we thought that

01:09:31,819 --> 01:09:37,770
ten milliseconds was good and then we

01:09:35,699 --> 01:09:43,410
needed a millisecond and then we needed

01:09:37,770 --> 01:09:46,350
a microsecond now packets are deep

01:09:43,410 --> 01:09:52,739
submicron and you know 100 K Nick

01:09:46,350 --> 01:09:56,489
they're hundred nanoseconds so we're

01:09:52,739 --> 01:10:00,210
pretty safe with nanoseconds that that

01:09:56,489 --> 01:10:05,730
will take us up to the bandwidth limits

01:10:00,210 --> 01:10:10,699
fibre which seems likely to be a pretty

01:10:05,730 --> 01:10:15,179
hard wall for some time in the future

01:10:10,699 --> 01:10:19,190
there's nothing in the model that puts a

01:10:15,179 --> 01:10:23,400
hard constraint on time stamp format

01:10:19,190 --> 01:10:24,960
because as you go across some boundary

01:10:23,400 --> 01:10:28,050
that was two different time stamp

01:10:24,960 --> 01:10:31,080
formats it's just an affine transform

01:10:28,050 --> 01:10:34,440
you read a multiply pose that had to

01:10:31,080 --> 01:10:37,320
convert from one format to another and

01:10:34,440 --> 01:10:39,620
so you can avoid the multiply if you use

01:10:37,320 --> 01:10:48,390
the same resolution on both sides and

01:10:39,620 --> 01:10:50,850
nanoseconds would do that today and if

01:10:48,390 --> 01:10:55,530
we need something finer grain like

01:10:50,850 --> 01:10:57,990
picoseconds and we can buy into a

01:10:55,530 --> 01:11:00,870
multiplier or a shift as you cross a

01:10:57,990 --> 01:11:03,600
boundary to convert the old low res nano

01:11:00,870 --> 01:11:06,150
second time stamps to our super new high

01:11:03,600 --> 01:11:10,530
res so it's not a showstopper

01:11:06,150 --> 01:11:13,050
and too much of talk about time stamping

01:11:10,530 --> 01:11:16,440
has focused on synchronizing clocks and

01:11:13,050 --> 01:11:18,270
representing clocks and that's a it's a

01:11:16,440 --> 01:11:21,090
rat's nest you don't want to go there

01:11:18,270 --> 01:11:23,190
because it's really a non-problem thank

01:11:21,090 --> 01:11:25,410
you okay maybe we'll cut off the

01:11:23,190 --> 01:11:26,760
questions I'm sorry but unless you guys

01:11:25,410 --> 01:11:28,710
want to stay here for the break I'm fine

01:11:26,760 --> 01:11:32,540
with it you want to stay for the break

01:11:28,710 --> 01:11:36,360
in here one guy said yeah everybody

01:11:32,540 --> 01:11:40,020
people wanna continue asking van I think

01:11:36,360 --> 01:11:42,300
the majority are saying no sorry so but

01:11:40,020 --> 01:11:42,960
van is gonna only gonna be around for a

01:11:42,300 --> 01:11:46,080
while longer

01:11:42,960 --> 01:11:48,380
yes okay thanks a lot bye Bridget let's

01:11:46,080 --> 01:11:48,380
give you a round

01:11:51,210 --> 01:11:55,590

YouTube URL: https://www.youtube.com/watch?v=MAni0_lN7zE


