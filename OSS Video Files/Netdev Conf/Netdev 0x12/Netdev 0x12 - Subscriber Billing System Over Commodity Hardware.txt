Title: Netdev 0x12 - Subscriber Billing System Over Commodity Hardware
Publication date: 2018-08-01
Playlist: Netdev 0x12
Description: 
	Do you know how your data plan gets billed by the telecommunication companies? What about a shared (family) plan? How can one use existing kernel features to build a robust billing and service platform?

On July 12th, 2018, at Netdev 0x12 in Montreal, Vikram Siwach described the challenges faced in getting Linux on commodity hardware and kernel changes made to make all this work. Beomjun Kim gave a demo.

More info:
https://www.netdevconf.org/0x12/session.html?subscriber-billing-system-over-commodity-hardware
Captions: 
	00:00:05,180 --> 00:00:18,990
all right so today here we are to

00:00:17,430 --> 00:00:20,520
present the subscriber billing system we

00:00:18,990 --> 00:00:23,820
built on commodity hardware

00:00:20,520 --> 00:00:26,820
I am Vikram I'm an architect Verizon on

00:00:23,820 --> 00:00:29,609
this project and my colleague Bob Jun

00:00:26,820 --> 00:00:32,369
will actually show the demo this project

00:00:29,609 --> 00:00:33,780
we picked up a year or so back so most

00:00:32,369 --> 00:00:36,510
of the people who actually worked on

00:00:33,780 --> 00:00:38,340
this project are not here but the TC and

00:00:36,510 --> 00:00:41,250
the kernel experts are here so we have a

00:00:38,340 --> 00:00:46,200
back-to-back TC talks so I hope you

00:00:41,250 --> 00:00:47,820
don't fall asleep so let's get there so

00:00:46,200 --> 00:00:49,530
I'll start with something I mean I had

00:00:47,820 --> 00:00:52,230
some conversations last night with

00:00:49,530 --> 00:00:55,050
people here some of you understand the

00:00:52,230 --> 00:00:58,410
EPC architecture well but for the people

00:00:55,050 --> 00:01:00,870
who are not abreast with it so I'll take

00:00:58,410 --> 00:01:03,090
few minutes to explain how typical telco

00:01:00,870 --> 00:01:04,890
runs their billing um so if you look at

00:01:03,090 --> 00:01:08,369
this picture I mean the idea is that

00:01:04,890 --> 00:01:10,920
from ran to Internet they're a bunch of

00:01:08,369 --> 00:01:12,840
forwarding elements I mean we you call a

00:01:10,920 --> 00:01:14,220
test gateway p8 way but there's long

00:01:12,840 --> 00:01:15,869
chain of network elements which are

00:01:14,220 --> 00:01:17,640
running through the network and then

00:01:15,869 --> 00:01:19,799
there are some control functions which

00:01:17,640 --> 00:01:20,880
could be centralized with there's some

00:01:19,799 --> 00:01:23,100
aspects of control

00:01:20,880 --> 00:01:25,590
also within the align functions which

00:01:23,100 --> 00:01:29,369
actually set policies and these

00:01:25,590 --> 00:01:31,579
forwarding elements basically are

00:01:29,369 --> 00:01:33,900
controlled through these interfaces

00:01:31,579 --> 00:01:35,939
3gpp is a body to standardize this

00:01:33,900 --> 00:01:37,979
interfaces so that when we buy stuff

00:01:35,939 --> 00:01:40,380
from vendors everybody can comply and

00:01:37,979 --> 00:01:43,200
interoperate I'll highlight few of those

00:01:40,380 --> 00:01:45,630
boxes for you one is the PC RF which is

00:01:43,200 --> 00:01:48,840
important so when you call us and say

00:01:45,630 --> 00:01:52,200
hey I want a different billing plan or I

00:01:48,840 --> 00:01:53,939
want a different service typically we

00:01:52,200 --> 00:01:55,320
will actually in for static policies on

00:01:53,939 --> 00:01:57,710
these boxes and they'll actually get

00:01:55,320 --> 00:02:00,299
program over 24 hour period

00:01:57,710 --> 00:02:01,890
similarly OCS is the one which actually

00:02:00,299 --> 00:02:05,040
maintains your credit so when you buy a

00:02:01,890 --> 00:02:06,960
plan for food gigabytes that's where we

00:02:05,040 --> 00:02:08,310
are on the credit system those are the

00:02:06,960 --> 00:02:11,220
systems which are connected to alerting

00:02:08,310 --> 00:02:12,459
and that's how you get alerts and then

00:02:11,220 --> 00:02:16,120
finally then the

00:02:12,459 --> 00:02:19,120
the part which we have most impact on

00:02:16,120 --> 00:02:20,950
monetary wise is the offline charging

00:02:19,120 --> 00:02:22,569
system these are basically time-based

00:02:20,950 --> 00:02:25,799
records which are shipped across the

00:02:22,569 --> 00:02:28,150
network in one of the studies we did

00:02:25,799 --> 00:02:31,180
essentially we had 18 different data

00:02:28,150 --> 00:02:33,700
store points if I just roughly do some

00:02:31,180 --> 00:02:36,310
calculation around every 30 minute we

00:02:33,700 --> 00:02:38,349
cut this record or 18 data points on 100

00:02:36,310 --> 00:02:40,900
million subscribers it adds up very fast

00:02:38,349 --> 00:02:44,290
so around 2.5 trillion records who would

00:02:40,900 --> 00:02:47,530
show up so this is how we lay out our

00:02:44,290 --> 00:02:48,790
billing network today but this is not

00:02:47,530 --> 00:02:50,739
what he wanted when we started off this

00:02:48,790 --> 00:02:53,650
project we wanted to simplify this

00:02:50,739 --> 00:02:58,900
picture so let me show you what vision

00:02:53,650 --> 00:03:01,780
we had really thank you so the first

00:02:58,900 --> 00:03:05,859
thing we wanted to do was get rid of all

00:03:01,780 --> 00:03:07,569
the boxes set up a controller somewhere

00:03:05,859 --> 00:03:11,040
in the cloud and actually have a

00:03:07,569 --> 00:03:13,989
programmable infrastructure we didn't

00:03:11,040 --> 00:03:16,540
envision that we want to solve all the

00:03:13,989 --> 00:03:18,849
protocol problems but we had specific

00:03:16,540 --> 00:03:20,919
cases which we wanted to solve the first

00:03:18,849 --> 00:03:23,229
being that we should not be having

00:03:20,919 --> 00:03:24,639
multiple data storage points so we

00:03:23,229 --> 00:03:27,819
should not be having multiple databases

00:03:24,639 --> 00:03:31,180
but on the billing line but also like a

00:03:27,819 --> 00:03:33,010
user could program through an app what

00:03:31,180 --> 00:03:34,510
kind of billing service he needs and it

00:03:33,010 --> 00:03:37,989
should get in force in the network right

00:03:34,510 --> 00:03:40,359
away so the api's and network itself

00:03:37,989 --> 00:03:42,280
should be programmable from a verizon

00:03:40,359 --> 00:03:44,259
app so if you look at this picture

00:03:42,280 --> 00:03:47,290
carefully the idea is that the business

00:03:44,259 --> 00:03:49,090
applications are essentially the

00:03:47,290 --> 00:03:51,220
services which are running which will

00:03:49,090 --> 00:03:53,379
connect to the Verizon apps and they do

00:03:51,220 --> 00:03:56,560
a trigger a restful call and these

00:03:53,379 --> 00:03:59,709
translate into actual policies the talk

00:03:56,560 --> 00:04:02,769
before highlighted some aspect of using

00:03:59,709 --> 00:04:04,810
an asset in control to program DC rules

00:04:02,769 --> 00:04:06,669
so we extended it to a real-life

00:04:04,810 --> 00:04:09,370
situation we actually have a Sdn

00:04:06,669 --> 00:04:12,159
controller which inserts the real

00:04:09,370 --> 00:04:13,930
policies and we get a feedback in real

00:04:12,159 --> 00:04:17,139
time back from a programmed

00:04:13,930 --> 00:04:19,780
infrastructure for the simplicity we

00:04:17,139 --> 00:04:21,509
just use x86 card as a programmable

00:04:19,780 --> 00:04:24,430
infrastructure

00:04:21,509 --> 00:04:26,949
but yeah that was the vision we had when

00:04:24,430 --> 00:04:31,150
we started thank you

00:04:26,949 --> 00:04:33,250
so now if I really normalize how these

00:04:31,150 --> 00:04:35,590
forwarding elements work you will see

00:04:33,250 --> 00:04:37,030
every element in our network for the

00:04:35,590 --> 00:04:39,190
packet who is running to the Internet

00:04:37,030 --> 00:04:41,050
follows these class of functions they

00:04:39,190 --> 00:04:43,599
basically the package gained into the

00:04:41,050 --> 00:04:45,610
port which classify them if this is a

00:04:43,599 --> 00:04:47,979
GDP protocol running we'll do a

00:04:45,610 --> 00:04:50,080
decapsulation will further figure out

00:04:47,979 --> 00:04:51,910
what policies to apply and then forward

00:04:50,080 --> 00:04:54,910
it or shape it and send it back out of

00:04:51,910 --> 00:04:57,220
the board so across all the elements

00:04:54,910 --> 00:04:59,740
these are the mace basic most basic

00:04:57,220 --> 00:05:05,020
functions now what is missing in this

00:04:59,740 --> 00:05:07,870
picture anyway the hint is it's a

00:05:05,020 --> 00:05:10,300
billing system so probably if you look

00:05:07,870 --> 00:05:12,340
at it if we just added some function in

00:05:10,300 --> 00:05:14,919
this forwarding pipeline to count I

00:05:12,340 --> 00:05:17,050
think all the headaches from managing

00:05:14,919 --> 00:05:20,530
multiple boxes and multiple interfaces

00:05:17,050 --> 00:05:22,680
probably might be simplified so let's go

00:05:20,530 --> 00:05:25,360
to the next slide I think so

00:05:22,680 --> 00:05:27,460
don't get scared with the no no go back

00:05:25,360 --> 00:05:29,800
yeah don't get scared with the big

00:05:27,460 --> 00:05:35,169
picture but I hope you can see the

00:05:29,800 --> 00:05:36,820
forwarding plane down essentially the

00:05:35,169 --> 00:05:39,280
previous slide when it showed the

00:05:36,820 --> 00:05:41,020
datapath pipeline the one function which

00:05:39,280 --> 00:05:45,340
we was missing in the data path pipeline

00:05:41,020 --> 00:05:48,639
was to account for bytes so what we did

00:05:45,340 --> 00:05:51,430
was we used TC as the mechanism to

00:05:48,639 --> 00:05:53,169
instantiate this beta path pipeline if

00:05:51,430 --> 00:05:56,770
you look at the structure below it's

00:05:53,169 --> 00:06:00,699
essentially has sets of classifier

00:05:56,770 --> 00:06:04,180
actions I'm assuming most of the people

00:06:00,699 --> 00:06:07,120
here know TC if not Jamal runs TC

00:06:04,180 --> 00:06:09,099
workshop so I think but to give an idea

00:06:07,120 --> 00:06:10,599
we need to filter packets and we need to

00:06:09,099 --> 00:06:12,460
change a bunch of actions the chain of

00:06:10,599 --> 00:06:15,479
action which I showed before is the

00:06:12,460 --> 00:06:18,310
typical chain of actions networks run so

00:06:15,479 --> 00:06:19,990
from the from the egress side if I look

00:06:18,310 --> 00:06:23,620
at it if the chain is programmed from

00:06:19,990 --> 00:06:25,150
red to light sorry right to left there's

00:06:23,620 --> 00:06:26,289
a sum function called QE which we

00:06:25,150 --> 00:06:28,360
developed which will actually show you

00:06:26,289 --> 00:06:30,880
today and this bunch of polices and

00:06:28,360 --> 00:06:31,830
there's a filter to actually identify

00:06:30,880 --> 00:06:34,020
these chains

00:06:31,830 --> 00:06:36,569
now the

00:06:34,020 --> 00:06:38,430
this is very simplistic in view but when

00:06:36,569 --> 00:06:40,800
you actually deploy what we are showing

00:06:38,430 --> 00:06:42,780
here is an operator's view of how this

00:06:40,800 --> 00:06:44,879
service will typically run whether this

00:06:42,780 --> 00:06:46,919
is actually deployed the same way add

00:06:44,879 --> 00:06:49,229
Verizon we won't be able to comment on

00:06:46,919 --> 00:06:52,310
that but this gives you a model of how

00:06:49,229 --> 00:06:55,199
we want to program our network in future

00:06:52,310 --> 00:06:57,990
so some of the instructions which I am

00:06:55,199 --> 00:06:59,849
showing the red lines are actually

00:06:57,990 --> 00:07:01,710
control instructions which are affecting

00:06:59,849 --> 00:07:04,349
parts of this data path pipeline and

00:07:01,710 --> 00:07:08,880
then I have a bunch of things going out

00:07:04,349 --> 00:07:11,039
to the B to the cloud these are mostly

00:07:08,880 --> 00:07:14,430
the blue lines I don't know if you can

00:07:11,039 --> 00:07:17,370
read it but the idea being that when a

00:07:14,430 --> 00:07:19,080
package shows up I know that you your

00:07:17,370 --> 00:07:21,060
phone number is tied to particular IP

00:07:19,080 --> 00:07:22,680
address from that I could figure out

00:07:21,060 --> 00:07:25,080
what kind of services have you

00:07:22,680 --> 00:07:26,990
subscribed for and those services are

00:07:25,080 --> 00:07:30,750
pre-configured in form of this QE chain

00:07:26,990 --> 00:07:33,000
and once I know what type of services

00:07:30,750 --> 00:07:35,550
you want I can associate in skb mark

00:07:33,000 --> 00:07:39,090
with a packet the packet goes in again

00:07:35,550 --> 00:07:41,490
and I actually service you the one part

00:07:39,090 --> 00:07:43,889
which people might ask is why do you

00:07:41,490 --> 00:07:45,780
actually do a user space transaction

00:07:43,889 --> 00:07:48,539
there why can we just run it in Kerala

00:07:45,780 --> 00:07:50,270
we can possibly run this service in

00:07:48,539 --> 00:07:54,539
kernel without interaction with user

00:07:50,270 --> 00:07:56,130
space but we wanted to do a little bit

00:07:54,539 --> 00:07:58,229
more sophistication we wanted to

00:07:56,130 --> 00:08:00,990
understand the consumer behavior what

00:07:58,229 --> 00:08:03,330
apps are they running I know somebody

00:08:00,990 --> 00:08:05,940
talked about encrypting S&I with me last

00:08:03,330 --> 00:08:09,029
night but still most of the traffic

00:08:05,940 --> 00:08:11,520
which runs today 40% is HTTP so we can

00:08:09,029 --> 00:08:13,319
do lots of parsing and also still not of

00:08:11,520 --> 00:08:16,080
the lot of the semis are not encrypted

00:08:13,319 --> 00:08:18,360
yet so we can get real data about

00:08:16,080 --> 00:08:19,979
consumer behavior and that's what the

00:08:18,360 --> 00:08:22,080
analytics field is about so we

00:08:19,979 --> 00:08:25,380
understand what our subscribers are

00:08:22,080 --> 00:08:29,990
consuming at what time possibly at what

00:08:25,380 --> 00:08:32,039
rate - so that's the view we had and I

00:08:29,990 --> 00:08:34,260
don't know if I want to go to the cloud

00:08:32,039 --> 00:08:39,029
but you're more than welcome to ask me

00:08:34,260 --> 00:08:40,709
questions we have any okay so now let me

00:08:39,029 --> 00:08:41,990
dig into the piece we are actually

00:08:40,709 --> 00:08:44,730
developed and we're going to contribute

00:08:41,990 --> 00:08:46,200
this is the idea that we wanted to

00:08:44,730 --> 00:08:49,560
centralize the

00:08:46,200 --> 00:08:52,680
and the counting in one state so what

00:08:49,560 --> 00:08:54,420
I'm showing you is a no is a very naive

00:08:52,680 --> 00:08:56,370
picture where the green actually

00:08:54,420 --> 00:08:58,290
represents your four gigabytes quota and

00:08:56,370 --> 00:09:00,600
just imagine it's actually squeezing as

00:08:58,290 --> 00:09:03,060
you consuming data and the blue one is

00:09:00,600 --> 00:09:05,130
the left allowance that you have when

00:09:03,060 --> 00:09:06,750
you once you run out there are possible

00:09:05,130 --> 00:09:08,459
actions we could do is we could drop you

00:09:06,750 --> 00:09:10,380
or we could actually write a limit you

00:09:08,459 --> 00:09:12,180
or we could just continue to give you a

00:09:10,380 --> 00:09:13,680
service but charge you differently right

00:09:12,180 --> 00:09:16,500
so these are the possible actions we

00:09:13,680 --> 00:09:19,199
could attach with the one thing which is

00:09:16,500 --> 00:09:22,260
of interest for people is when you store

00:09:19,199 --> 00:09:25,920
these transactions in colano we need a

00:09:22,260 --> 00:09:27,810
hash index to go and identify a database

00:09:25,920 --> 00:09:29,790
entry as fast as possible

00:09:27,810 --> 00:09:32,370
so we actually inserted something called

00:09:29,790 --> 00:09:34,620
cookie which actually will identify not

00:09:32,370 --> 00:09:36,720
only the NBN but the services associated

00:09:34,620 --> 00:09:39,930
with this 128-bit cookie is actually a

00:09:36,720 --> 00:09:43,470
direct index into the database so that

00:09:39,930 --> 00:09:44,519
helps and yeah the idea is that the

00:09:43,470 --> 00:09:46,139
packet just run through

00:09:44,519 --> 00:09:47,760
so you're deducting the credit and at

00:09:46,139 --> 00:09:49,589
the same time you're accounting it so

00:09:47,760 --> 00:09:52,500
the synchronization problems do not

00:09:49,589 --> 00:09:54,870
happen so that's the counting which

00:09:52,500 --> 00:09:58,199
actually goes to the user space which we

00:09:54,870 --> 00:10:00,000
store in some distributed database to

00:09:58,199 --> 00:10:01,290
actually make it work now the logic of

00:10:00,000 --> 00:10:03,899
the queue is actually on the right hand

00:10:01,290 --> 00:10:06,240
side which actually highlights how the

00:10:03,899 --> 00:10:08,670
packet arrives we check the packet

00:10:06,240 --> 00:10:11,010
length we remove the excess adders we

00:10:08,670 --> 00:10:12,570
check if the code ayah is within the

00:10:11,010 --> 00:10:15,029
length of the packet if so we actually

00:10:12,570 --> 00:10:16,260
go and run and increment the counts and

00:10:15,029 --> 00:10:18,660
we let it go

00:10:16,260 --> 00:10:23,579
if not there the possible actions are

00:10:18,660 --> 00:10:27,449
that we actually can drop it okay next

00:10:23,579 --> 00:10:29,100
one please thank you so people might ask

00:10:27,449 --> 00:10:31,680
this question that why did you guys

00:10:29,100 --> 00:10:35,610
actually use DC to build these data path

00:10:31,680 --> 00:10:37,500
pipelines and the logical question is to

00:10:35,610 --> 00:10:40,680
answer is if I'm using a commodity

00:10:37,500 --> 00:10:43,740
hardware I'm using DC what would be the

00:10:40,680 --> 00:10:46,610
performance of TC at scale so this is

00:10:43,740 --> 00:10:48,959
actually how our network is set up today

00:10:46,610 --> 00:10:51,480
we have a Juniper router and we actually

00:10:48,959 --> 00:10:53,940
extensively use VLAN tags to identify

00:10:51,480 --> 00:10:55,529
the service cards which are sitting

00:10:53,940 --> 00:10:58,740
behind the plain if you look at it these

00:10:55,529 --> 00:10:59,910
are the exodus cards and the these the

00:10:58,740 --> 00:11:01,050
inner VLANs in this

00:10:59,910 --> 00:11:04,470
should identify the direction of the

00:11:01,050 --> 00:11:05,670
traffic so from that we know whether it

00:11:04,470 --> 00:11:09,000
was an uplink packet or a downlink

00:11:05,670 --> 00:11:10,940
packet on the right side is essentially

00:11:09,000 --> 00:11:13,710
a very simplistic chain in Colonel I

00:11:10,940 --> 00:11:15,750
haven't shown all the actions there but

00:11:13,710 --> 00:11:17,220
essentially when a package shows up we

00:11:15,750 --> 00:11:18,840
want to pop the wheel and now we're

00:11:17,220 --> 00:11:22,080
going to classify and we want to push

00:11:18,840 --> 00:11:23,640
the wheel and again and out so we

00:11:22,080 --> 00:11:25,260
actually scaled it I mean the paper we

00:11:23,640 --> 00:11:28,320
highlight the the hardware configuration

00:11:25,260 --> 00:11:31,260
you could go and read it but this is

00:11:28,320 --> 00:11:33,870
like 128 thousand TC graphs we scaled it

00:11:31,260 --> 00:11:36,930
to that level and we actually pushed

00:11:33,870 --> 00:11:39,330
traffic at different rates so the

00:11:36,930 --> 00:11:40,110
numbers we have I think next slide bomb

00:11:39,330 --> 00:11:43,170
yeah

00:11:40,110 --> 00:11:45,780
so next slide actually highlights what

00:11:43,170 --> 00:11:48,630
our intention was to see can we actually

00:11:45,780 --> 00:11:50,700
do this at line rate without introducing

00:11:48,630 --> 00:11:52,970
latency is which we typically experience

00:11:50,700 --> 00:11:57,750
in the forwarding elements today so

00:11:52,970 --> 00:12:00,000
roughly the latency of a packet from ran

00:11:57,750 --> 00:12:01,950
to Internet is probably 40 milliseconds

00:12:00,000 --> 00:12:04,380
so you can imagine how many hops they're

00:12:01,950 --> 00:12:06,210
going through and how how much it

00:12:04,380 --> 00:12:09,120
consumes but with using this

00:12:06,210 --> 00:12:13,980
infrastructure if you look at it our the

00:12:09,120 --> 00:12:16,560
latencies are in microseconds and the if

00:12:13,980 --> 00:12:19,560
you look at the higher packet size it's

00:12:16,560 --> 00:12:22,080
almost equal to the line rate so it it

00:12:19,560 --> 00:12:26,970
doesn't compromise us on the latency

00:12:22,080 --> 00:12:30,150
which is important for us see these were

00:12:26,970 --> 00:12:31,770
basically the actual numbers for details

00:12:30,150 --> 00:12:34,830
on the setup and everything you can

00:12:31,770 --> 00:12:41,070
consult paper but that should show you

00:12:34,830 --> 00:12:43,820
the power of this T C so bunch of

00:12:41,070 --> 00:12:46,560
challenges we faced while dropping QE

00:12:43,820 --> 00:12:48,570
and the team actually fixed these

00:12:46,560 --> 00:12:51,420
changes in kernel and I think some of

00:12:48,570 --> 00:12:54,500
them are already upstream but I think

00:12:51,420 --> 00:12:56,760
Beom Jin's code will actually come later

00:12:54,500 --> 00:12:59,310
then we will probably upstream that too

00:12:56,760 --> 00:13:01,980
and share the github repository but I

00:12:59,310 --> 00:13:03,480
think if you look at it when you

00:13:01,980 --> 00:13:06,420
naturally run a service of that scale

00:13:03,480 --> 00:13:07,920
you have so many graphs and the

00:13:06,420 --> 00:13:10,080
subscriber could choose different graphs

00:13:07,920 --> 00:13:12,899
at different point in time collecting

00:13:10,080 --> 00:13:15,240
stats is going to be a problem so

00:13:12,899 --> 00:13:16,619
what we did was we don't want to collect

00:13:15,240 --> 00:13:18,569
all them non-moving stats out of the

00:13:16,619 --> 00:13:21,420
kernel so we actually inserted a time

00:13:18,569 --> 00:13:24,540
filter so you could actually set it say

00:13:21,420 --> 00:13:26,670
from the user app I am requesting from

00:13:24,540 --> 00:13:28,860
this time to this time on the stats

00:13:26,670 --> 00:13:29,999
which are moving so that I don't have to

00:13:28,860 --> 00:13:33,600
collect all the stats which haven't

00:13:29,999 --> 00:13:34,980
changed that was one fix also there was

00:13:33,600 --> 00:13:37,949
an artificial limit on the number of

00:13:34,980 --> 00:13:40,110
actions you could pack in a batch and I

00:13:37,949 --> 00:13:43,889
don't know why that was there but

00:13:40,110 --> 00:13:45,540
essentially I think the team fixed based

00:13:43,889 --> 00:13:47,339
on the actual memory in the socket how

00:13:45,540 --> 00:13:49,170
much can we pack in that and that would

00:13:47,339 --> 00:13:52,639
be sent as a single batch so those were

00:13:49,170 --> 00:13:56,220
the mostly performance problems we saw

00:13:52,639 --> 00:13:57,929
shipping stats out the cloud instruction

00:13:56,220 --> 00:13:59,519
wise we didn't have much problem sitting

00:13:57,929 --> 00:14:02,329
the control instructions into the fast

00:13:59,519 --> 00:14:05,939
path that was not a problem

00:14:02,329 --> 00:14:08,399
thank you so the other parts was later

00:14:05,939 --> 00:14:10,889
performance and what I'm highlighting

00:14:08,399 --> 00:14:12,749
mostly are the performance results I

00:14:10,889 --> 00:14:15,240
showed you before how are we able to

00:14:12,749 --> 00:14:18,059
achieve that we actually enabled RSS on

00:14:15,240 --> 00:14:19,920
the neck and we used RSS is an escapee

00:14:18,059 --> 00:14:23,519
mark to identifying from the chain which

00:14:19,920 --> 00:14:25,050
I showed you before and we I think this

00:14:23,519 --> 00:14:30,300
was already checked in into the kernel

00:14:25,050 --> 00:14:33,420
I think the 128k hash bucket size the

00:14:30,300 --> 00:14:36,449
biggest if you look at the chain the

00:14:33,420 --> 00:14:38,579
biggest consumption was actually the

00:14:36,449 --> 00:14:42,329
filter so the filtering I think was

00:14:38,579 --> 00:14:44,519
limited to I think 16 Jamal would

00:14:42,329 --> 00:14:46,649
remember but this is the fix to ration

00:14:44,519 --> 00:14:49,920
increase the hard bucket size to make it

00:14:46,649 --> 00:14:52,939
faster then there were bunch of

00:14:49,920 --> 00:14:56,279
challenges we had with using single

00:14:52,939 --> 00:14:59,519
prior queue disk so we actually did

00:14:56,279 --> 00:15:02,670
multi cue priority so multi key priority

00:14:59,519 --> 00:15:04,110
disk and also we had some changes in TC

00:15:02,670 --> 00:15:05,699
VLAN actions because they were using

00:15:04,110 --> 00:15:08,790
spin locks will be updated to our CEO

00:15:05,699 --> 00:15:11,129
and I think QE now is also our cui I can

00:15:08,790 --> 00:15:13,019
comment on the only harsh

00:15:11,129 --> 00:15:17,639
I think that's we suggested to fix the

00:15:13,019 --> 00:15:20,129
TC action ash but the IDR patch that

00:15:17,639 --> 00:15:21,830
came from Chris me from Mellanox was the

00:15:20,129 --> 00:15:24,370
final solution

00:15:21,830 --> 00:15:28,160
I see we don't need that patch anymore

00:15:24,370 --> 00:15:30,050
awesome thank you so yeah that's that's

00:15:28,160 --> 00:15:31,580
primarily our data path performance

00:15:30,050 --> 00:15:34,779
problems and challenges and those are

00:15:31,580 --> 00:15:38,750
some of the fixes we have contributed

00:15:34,779 --> 00:15:40,250
all right so this is demo time what we

00:15:38,750 --> 00:15:42,500
want to show is a very simplistic demo

00:15:40,250 --> 00:15:45,769
we won't be able to show you the entire

00:15:42,500 --> 00:15:46,790
operator view at this point but these

00:15:45,769 --> 00:15:48,980
are three containers

00:15:46,790 --> 00:15:50,870
I guess Bob didn't write and the

00:15:48,980 --> 00:15:52,970
instruction set is shown on the left all

00:15:50,870 --> 00:15:54,829
we're going to show you is a client

00:15:52,970 --> 00:15:57,410
connect to the router router will have a

00:15:54,829 --> 00:15:58,910
QA action set and a certain point in

00:15:57,410 --> 00:16:00,079
time I think you're going to drop the

00:15:58,910 --> 00:16:06,589
packets right after you've run out of

00:16:00,079 --> 00:16:08,630
credit so yeah so I'll just briefly

00:16:06,589 --> 00:16:11,450
describe the arrows here the cool air is

00:16:08,630 --> 00:16:14,680
going around so from a client if you

00:16:11,450 --> 00:16:17,120
look at the red arrow which is going

00:16:14,680 --> 00:16:19,940
basically it is a transaction going to

00:16:17,120 --> 00:16:21,589
the server we actually have a QA

00:16:19,940 --> 00:16:24,709
programmed on the egress cutis which is

00:16:21,589 --> 00:16:28,100
the worth interface there so the packets

00:16:24,709 --> 00:16:30,470
show up on the red router it's zero if

00:16:28,100 --> 00:16:33,110
they run through QA and I think he has

00:16:30,470 --> 00:16:35,930
programmed so type in destination IP I

00:16:33,110 --> 00:16:37,339
think for the client so that every

00:16:35,930 --> 00:16:38,959
packet emanating from the client and

00:16:37,339 --> 00:16:40,940
coming to the client comes through a GUI

00:16:38,959 --> 00:16:42,680
and if you look at careful and

00:16:40,940 --> 00:16:46,040
restriction said I think that QE credit

00:16:42,680 --> 00:16:49,790
is almost like a megabyte 10 megabyte

00:16:46,040 --> 00:16:52,459
okay and yeah so what we'll see is

00:16:49,790 --> 00:16:53,930
actually after some time the file I

00:16:52,459 --> 00:16:55,910
think you're transferring a file from a

00:16:53,930 --> 00:16:58,850
server to the client and I'll stop and

00:16:55,910 --> 00:17:00,800
you will see the stats from the this

00:16:58,850 --> 00:17:03,170
action and we'll see how these stats

00:17:00,800 --> 00:17:08,679
actually become actual CDRs for billing

00:17:03,170 --> 00:17:08,679
purposes in our network function

00:17:38,640 --> 00:17:54,390
so you know for this demo I have a few

00:17:44,049 --> 00:18:00,669
helper scripts so Jeru - setup script

00:17:54,390 --> 00:18:05,679
will enable the IP for adoption - one

00:18:00,669 --> 00:18:10,179
and he creates the sober router client

00:18:05,679 --> 00:18:16,419
namespace and creates the fears fest

00:18:10,179 --> 00:18:20,010
devices for those namespaces and it just

00:18:16,419 --> 00:18:24,309
assigns the IP address to delete she

00:18:20,010 --> 00:18:24,820
first devices and using the route

00:18:24,309 --> 00:18:29,470
command

00:18:24,820 --> 00:18:32,049
it just had our doubts - from proper

00:18:29,470 --> 00:18:33,669
default a little larger can you increase

00:18:32,049 --> 00:18:34,890
the font maybe unless people can see

00:18:33,669 --> 00:18:37,720
this okay

00:18:34,890 --> 00:18:42,159
pardon is a can you make the font bigger

00:18:37,720 --> 00:18:44,669
or okay and just as a warning you don't

00:18:42,159 --> 00:18:44,669
have much time

00:18:49,580 --> 00:19:01,070
would it be good I think it looks better

00:18:53,940 --> 00:19:06,030
yes yeah so now I'm just creating the

00:19:01,070 --> 00:19:10,220
namespace and vests devices and running

00:19:06,030 --> 00:19:17,540
the route command in order to create a

00:19:10,220 --> 00:19:17,540
route so I'm just going to run it

00:19:25,600 --> 00:19:37,990
and this helper script will run the

00:19:34,679 --> 00:19:42,789
pistol command that we described

00:19:37,990 --> 00:19:46,000
previously yeah so issues the teeth

00:19:42,789 --> 00:19:50,260
command that is when in the this script

00:19:46,000 --> 00:19:52,110
and here

00:19:50,260 --> 00:20:05,049
[Music]

00:19:52,110 --> 00:20:09,539
so yeah credit is set to almost hundred

00:20:05,049 --> 00:20:09,539
are 10 megabit

00:20:13,159 --> 00:20:16,359
just a second

00:20:30,020 --> 00:20:39,110
yes so it should be the upstream byte

00:20:35,600 --> 00:20:40,640
passed by 10 I just used with obscene

00:20:39,110 --> 00:20:45,620
pass fight and it should be the

00:20:40,640 --> 00:20:54,820
downstream pathway and let's learn the

00:20:45,620 --> 00:20:59,780
actual demo this demo we'll just use the

00:20:54,820 --> 00:21:07,550
TCP sender from the suicide and TCP T

00:20:59,780 --> 00:21:11,570
speed receiver from the Klan site so the

00:21:07,550 --> 00:21:20,210
file transfer were stopped because it

00:21:11,570 --> 00:21:23,390
reached each quota yeah so here is the

00:21:20,210 --> 00:21:27,679
amount of pipe that went to the upstream

00:21:23,390 --> 00:21:34,240
here is the amount of light that is

00:21:27,679 --> 00:21:39,880
downloaded and this is the what is left

00:21:34,240 --> 00:21:39,880
so if I just add them

00:21:52,490 --> 00:21:55,490
No

00:21:59,480 --> 00:22:03,230
it should be around

00:22:06,400 --> 00:22:24,010
yeah

00:22:08,860 --> 00:22:25,840
just a joke number I mean this this idea

00:22:24,010 --> 00:22:27,880
can be scaled to any environment if you

00:22:25,840 --> 00:22:29,920
are actually looking to I saw the

00:22:27,880 --> 00:22:31,330
previous presentation the use T C

00:22:29,920 --> 00:22:33,160
infrastructure in cloud environment you

00:22:31,330 --> 00:22:38,020
could actually look at this as a way to

00:22:33,160 --> 00:22:41,169
count bytes going into containers you

00:22:38,020 --> 00:22:45,990
could run it across hose so I think this

00:22:41,169 --> 00:22:49,929
is pretty scalable that way so okay so

00:22:45,990 --> 00:22:52,179
you want to put it back so I I think

00:22:49,929 --> 00:22:54,160
we're done so if you have some questions

00:22:52,179 --> 00:22:56,080
there's something about building data

00:22:54,160 --> 00:22:57,549
pipelines around these models which I'm

00:22:56,080 --> 00:22:58,919
super excited about if somebody wants to

00:22:57,549 --> 00:23:01,750
know how to actually build

00:22:58,919 --> 00:23:03,940
recommendation engines I'll be more than

00:23:01,750 --> 00:23:08,460
happy to talk about that but that's all

00:23:03,940 --> 00:23:08,460
in cloud questions

00:23:10,620 --> 00:23:14,669
okay I have a question boom Jim where

00:23:13,559 --> 00:23:18,450
are you putting out the patch again

00:23:14,669 --> 00:23:20,549
you're gonna submit the QE action are

00:23:18,450 --> 00:23:25,620
you going to submit the QA action to the

00:23:20,549 --> 00:23:28,950
list yeah okay I might put you on the

00:23:25,620 --> 00:23:30,570
spot you know this is how we work here

00:23:28,950 --> 00:23:32,520
you have to you have to push that code

00:23:30,570 --> 00:23:35,190
upstream okay yeah

00:23:32,520 --> 00:23:40,380
okay I've maintained and then I could

00:23:35,190 --> 00:23:42,120
you know code yes yes yeah that's

00:23:40,380 --> 00:23:46,830
upstream I pushed that badge actually

00:23:42,120 --> 00:23:49,380
what yeah yeah so in DC in the actions

00:23:46,830 --> 00:23:51,539
you code you can say I want you to dump

00:23:49,380 --> 00:23:54,630
something I don't if you looked at that

00:23:51,539 --> 00:23:57,990
and you provide a filter which restricts

00:23:54,630 --> 00:24:00,240
which will look at the time last used

00:23:57,990 --> 00:24:02,010
and it says is it greater than fact at

00:24:00,240 --> 00:24:03,899
that time you passed five seconds then

00:24:02,010 --> 00:24:06,000
it won't give it to you if it's hasn't

00:24:03,899 --> 00:24:08,399
been used in the last five seconds so

00:24:06,000 --> 00:24:12,929
when you have I think we had close to in

00:24:08,399 --> 00:24:15,960
this case we had 256,000 actions you

00:24:12,929 --> 00:24:19,740
then only dumped 5,000 because the other

00:24:15,960 --> 00:24:22,200
cell phone users had never crossed by

00:24:19,740 --> 00:24:23,669
the hardware was a connect x3 I know he

00:24:22,200 --> 00:24:24,960
didn't mention that I said but we were

00:24:23,669 --> 00:24:36,830
proud were able to get that thing to

00:24:24,960 --> 00:24:36,830
work and still exist all right thank you

00:24:37,850 --> 00:24:41,080

YouTube URL: https://www.youtube.com/watch?v=sT7dssMcEAc


