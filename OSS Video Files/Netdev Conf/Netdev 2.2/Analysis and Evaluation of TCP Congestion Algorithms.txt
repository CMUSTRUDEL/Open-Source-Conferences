Title: Analysis and Evaluation of TCP Congestion Algorithms
Publication date: 2018-03-14
Playlist: Netdev 2.2
Description: 
	Speaker: Lawrence Brakmo
Friday November 10th, 2017 
Seoul, Korea
https://www.netdevconf.org/2.2/session.html?brakmo-tcpcongestionanalysis-talk
Captions: 
	00:00:01,910 --> 00:00:07,520
so congestion control is a very hard

00:00:05,420 --> 00:00:08,299
problem people have been working for it

00:00:07,520 --> 00:00:11,119
for decades

00:00:08,299 --> 00:00:14,660
I specifically in TCP studying in the

00:00:11,119 --> 00:00:16,699
80s when when Jacobson studied you know

00:00:14,660 --> 00:00:20,570
introducing the window controls for slow

00:00:16,699 --> 00:00:22,820
start and the congestion window until

00:00:20,570 --> 00:00:27,380
last year this year with Google and BB

00:00:22,820 --> 00:00:29,599
are it is hard because the floors need

00:00:27,380 --> 00:00:31,909
to utilize the available bandwidth which

00:00:29,599 --> 00:00:35,360
they do not know how much there is in a

00:00:31,909 --> 00:00:38,809
fairly way be fair about it when many

00:00:35,360 --> 00:00:40,940
unrelated flows are competing so

00:00:38,809 --> 00:00:43,460
consider when the ax flow is starting up

00:00:40,940 --> 00:00:45,170
right you have no idea of the available

00:00:43,460 --> 00:00:46,129
bandwidth you have to figure out a way

00:00:45,170 --> 00:00:49,539
to use it

00:00:46,129 --> 00:00:52,010
now imagine that for some magical way

00:00:49,539 --> 00:00:54,140
the flow could know how much available

00:00:52,010 --> 00:00:56,510
bandwidth there is right so you could

00:00:54,140 --> 00:00:57,980
think well I'm just gonna use some rate

00:00:56,510 --> 00:01:00,170
control and use all of the available

00:00:57,980 --> 00:01:01,969
bandwidth I mean it's right there the

00:01:00,170 --> 00:01:04,790
problem is that there could be two five

00:01:01,969 --> 00:01:06,490
ten flows starting at the same time and

00:01:04,790 --> 00:01:09,050
they would all get the same information

00:01:06,490 --> 00:01:10,850
right but you do not know how many there

00:01:09,050 --> 00:01:13,370
are so that even if you knew how much

00:01:10,850 --> 00:01:16,670
bandwidth there is it was still you know

00:01:13,370 --> 00:01:21,770
be hard problems you know to solve to be

00:01:16,670 --> 00:01:24,680
able to use it quickly so in this talk I

00:01:21,770 --> 00:01:27,740
will focus and do an analysis of Reno

00:01:24,680 --> 00:01:32,260
you know the grandfather cubic which is

00:01:27,740 --> 00:01:36,590
an improvement for longer our titties

00:01:32,260 --> 00:01:39,620
DC TCP data center TCP the use accn

00:01:36,590 --> 00:01:41,990
markings to adapt to the available

00:01:39,620 --> 00:01:44,780
bandwidth and its really good for data

00:01:41,990 --> 00:01:47,450
centers VB are the new player in town

00:01:44,780 --> 00:01:51,710
with still a lot of questions about it

00:01:47,450 --> 00:01:53,480
and B new vegas which is a follow to beg

00:01:51,710 --> 00:01:57,070
to vegas and that's my baby

00:01:53,480 --> 00:01:59,600
and it's only tuned for the data center

00:01:57,070 --> 00:02:03,920
so i will only use it in the environment

00:01:59,600 --> 00:02:09,170
and it's also using tcp v PF to get a

00:02:03,920 --> 00:02:12,739
base RT t and also we'll talk about tcp

00:02:09,170 --> 00:02:14,870
BPF which is cubic by using tcp v PF

00:02:12,739 --> 00:02:17,180
like i described yesterday

00:02:14,870 --> 00:02:19,370
to control the congestion window to

00:02:17,180 --> 00:02:23,660
clamp it and other improvements like

00:02:19,370 --> 00:02:26,030
that and this week you know let the last

00:02:23,660 --> 00:02:29,330
three days because I had time I decided

00:02:26,030 --> 00:02:32,180
to add big G huh

00:02:29,330 --> 00:02:35,180
high-speed HTTP and Westwood in the

00:02:32,180 --> 00:02:38,660
analysis for some of these scenarios so

00:02:35,180 --> 00:02:40,370
I have about 50 slides I hope you guys

00:02:38,660 --> 00:02:41,349
are not hungry you're gonna be late for

00:02:40,370 --> 00:02:45,319
lunch

00:02:41,349 --> 00:02:48,680
so just kidding I have future slides but

00:02:45,319 --> 00:02:50,329
I will cut them quickly so let me start

00:02:48,680 --> 00:02:51,920
by differentiating between congestion

00:02:50,329 --> 00:02:53,590
control and congestion avoidance and

00:02:51,920 --> 00:02:56,420
that's something I'd like to do

00:02:53,590 --> 00:02:59,450
congestion control like what renown

00:02:56,420 --> 00:03:01,670
cubic do do not avoid congestion on the

00:02:59,450 --> 00:03:05,360
contrary they periodically create

00:03:01,670 --> 00:03:08,150
congestion to create losses to figure

00:03:05,360 --> 00:03:11,000
out how much that they have reach all of

00:03:08,150 --> 00:03:13,220
the available bandwidth and as a result

00:03:11,000 --> 00:03:16,160
of the losses typically the high

00:03:13,220 --> 00:03:21,260
percentile latencies for small transfers

00:03:16,160 --> 00:03:25,370
or high DC TCP baby R&B do congestion

00:03:21,260 --> 00:03:27,200
avoidance they try to detect congestion

00:03:25,370 --> 00:03:31,670
the cube built up before elites to

00:03:27,200 --> 00:03:33,950
losses in order to prevent losses and I

00:03:31,670 --> 00:03:36,200
have our asteroids on bbr because under

00:03:33,950 --> 00:03:40,940
some conditions it is very happy with

00:03:36,200 --> 00:03:45,200
losses so so obviously no losses means

00:03:40,940 --> 00:03:48,829
there are high percentile latencies so

00:03:45,200 --> 00:03:50,900
for these experiments the setup was you

00:03:48,829 --> 00:03:53,720
know for simplicity I just wanted to

00:03:50,900 --> 00:03:57,130
have a simple environment for this

00:03:53,720 --> 00:04:00,319
experiment I have three hosts sending

00:03:57,130 --> 00:04:03,709
going to a suite going to a receiver so

00:04:00,319 --> 00:04:05,780
this offer that TG 10 gigabit test and

00:04:03,709 --> 00:04:08,120
when I want to introduce latency on the

00:04:05,780 --> 00:04:09,829
receiver I used Neddie a.m. and I'm

00:04:08,120 --> 00:04:11,569
using a limit of twenty thousand packets

00:04:09,829 --> 00:04:15,290
so that I'll make sure that nari M will

00:04:11,569 --> 00:04:17,090
not drop packets and I'm only doing for

00:04:15,290 --> 00:04:19,549
these experiments when I used an ATM 10

00:04:17,090 --> 00:04:22,990
millisecond delays so that 20,000

00:04:19,549 --> 00:04:25,190
buffers is more than enough for that and

00:04:22,990 --> 00:04:26,780
by the way do you have any questions

00:04:25,190 --> 00:04:28,700
feel free to interrupt me as I'm doing

00:04:26,780 --> 00:04:31,430
it because by the time we get to the air

00:04:28,700 --> 00:04:33,830
you probably forget your questions and

00:04:31,430 --> 00:04:35,450
if it starts getting too crazy I'll stop

00:04:33,830 --> 00:04:38,030
you

00:04:35,450 --> 00:04:40,070
for the other experimental setup I'm

00:04:38,030 --> 00:04:42,440
doing ten and a hundred megabyte per

00:04:40,070 --> 00:04:44,060
second test with 40 millisecond

00:04:42,440 --> 00:04:48,200
latencies and for those and using

00:04:44,060 --> 00:04:52,310
another host as a router and I'm using a

00:04:48,200 --> 00:04:53,930
TBF to limit the bandwidth and then use

00:04:52,310 --> 00:04:57,050
an ATM in the receiver to add the

00:04:53,930 --> 00:05:00,050
latency and this way I can control the

00:04:57,050 --> 00:05:07,460
number of buffers on the bottleneck

00:05:00,050 --> 00:05:09,050
switch okay so I'm going to cover I

00:05:07,460 --> 00:05:11,930
looked into a couple different scenarios

00:05:09,050 --> 00:05:14,120
the first one is just the LAN like at a

00:05:11,930 --> 00:05:17,120
data center with 20 micro second RT T's

00:05:14,120 --> 00:05:19,670
10 gigabits per second another word

00:05:17,120 --> 00:05:21,740
scenario is like a fast one taking a bit

00:05:19,670 --> 00:05:24,190
per second 10 millisecond or two T's and

00:05:21,740 --> 00:05:28,190
then the final one is like a 1 like

00:05:24,190 --> 00:05:31,450
going to the internet 40 milliseconds RT

00:05:28,190 --> 00:05:35,360
T's 10 and 100 megabits per second and

00:05:31,450 --> 00:05:39,370
for my taste I did a couple different

00:05:35,360 --> 00:05:41,950
scenarios for the test or that so test

00:05:39,370 --> 00:05:45,950
one type consists of two or three

00:05:41,950 --> 00:05:47,990
streaming flows like few flows just to

00:05:45,950 --> 00:05:49,970
be able to visually look at the behavior

00:05:47,990 --> 00:05:52,460
and the dynamics of the congestion

00:05:49,970 --> 00:05:55,670
algorithms you know like if we had too

00:05:52,460 --> 00:05:57,260
many we cannot see it so just a few - we

00:05:55,670 --> 00:05:59,600
have to analyze it and if there's

00:05:57,260 --> 00:06:01,580
problems with 2 or 3 it probably will

00:05:59,600 --> 00:06:04,760
indicate that there's fundamentally

00:06:01,580 --> 00:06:08,360
something that needs to be dealt with

00:06:04,760 --> 00:06:11,930
with the congestion algorithm and I also

00:06:08,360 --> 00:06:15,770
did another type of test would have

00:06:11,930 --> 00:06:18,920
multiple flows of streaming one or a

00:06:15,770 --> 00:06:22,220
megabyte or 10 kilobyte are pieces and

00:06:18,920 --> 00:06:24,410
these are really good to see how fair is

00:06:22,220 --> 00:06:26,390
the condition algorithm when the flows

00:06:24,410 --> 00:06:29,810
are different sizes you know that the

00:06:26,390 --> 00:06:31,940
bigger flows take all the bandwidth away

00:06:29,810 --> 00:06:40,100
from the smaller flows like 10 kilowatt

00:06:31,940 --> 00:06:43,340
our pcs are using a tester that I talked

00:06:40,100 --> 00:06:46,580
about last time to run the experiment

00:06:43,340 --> 00:06:48,860
it allows me I have a small scrape run

00:06:46,580 --> 00:06:52,340
it it you know starts running like a

00:06:48,860 --> 00:06:53,840
hundred tests one by one changing a lots

00:06:52,340 --> 00:06:56,900
of parameter like congestion algorithm

00:06:53,840 --> 00:06:59,750
it's just a few lines of no test Oh it

00:06:56,900 --> 00:07:01,550
controls the sender of the receivers

00:06:59,750 --> 00:07:04,250
collects all the data instead back

00:07:01,550 --> 00:07:06,520
creates of the graphs grass of good puts

00:07:04,250 --> 00:07:08,210
RTT is conditioned windows

00:07:06,520 --> 00:07:11,170
retransmissions everything is done

00:07:08,210 --> 00:07:13,250
automatically and yes I to you know

00:07:11,170 --> 00:07:17,440
trusted the data or look at it

00:07:13,250 --> 00:07:22,670
I used the latest Linux Cornelis of a

00:07:17,440 --> 00:07:26,140
week or so ago I also use mq & fq Corral

00:07:22,670 --> 00:07:28,370
at screwing disciplines on the sender's

00:07:26,140 --> 00:07:33,140
because you know beabea is the default

00:07:28,370 --> 00:07:36,980
and we are prefers it and for the DCT CP

00:07:33,140 --> 00:07:40,190
n NB the swiss has two queues one for

00:07:36,980 --> 00:07:43,670
them and one for the other traffic and

00:07:40,190 --> 00:07:46,880
the reason that both of these had issues

00:07:43,670 --> 00:07:50,060
with furnace when competing with other

00:07:46,880 --> 00:07:52,640
types of flows like cubic DC tcp will

00:07:50,060 --> 00:07:55,370
hurt cubic if there's only one e CN

00:07:52,640 --> 00:08:01,250
marking q an MB will be hurt by cubic

00:07:55,370 --> 00:08:04,190
there's only one Q okay now the results

00:08:01,250 --> 00:08:06,620
so let's start with that ng LAN and

00:08:04,190 --> 00:08:10,040
let's just look at two flows and I hope

00:08:06,620 --> 00:08:13,640
you guys is that visible okay great so

00:08:10,040 --> 00:08:16,400
this is cubic and in for this experiment

00:08:13,640 --> 00:08:18,770
with the flows a star one flow that will

00:08:16,400 --> 00:08:20,690
run for 60 seconds then like 23 seconds

00:08:18,770 --> 00:08:24,470
later we'll start another flow also

00:08:20,690 --> 00:08:27,230
cubic and see how they interact and Q we

00:08:24,470 --> 00:08:31,430
see that given enough time the goodput

00:08:27,230 --> 00:08:33,650
will converge surprisingly running on al

00:08:31,430 --> 00:08:34,280
and it takes a long time to converge

00:08:33,650 --> 00:08:38,089
right

00:08:34,280 --> 00:08:39,320
and the reason sorry and the reason it

00:08:38,089 --> 00:08:41,510
takes a long time to converge because

00:08:39,320 --> 00:08:44,380
the congestion window which by the way I

00:08:41,510 --> 00:08:47,300
set the buffer sizes to 30 megabytes

00:08:44,380 --> 00:08:48,620
because I do not want them to affect the

00:08:47,300 --> 00:08:50,990
behavior of the conditioner algorithm

00:08:48,620 --> 00:08:53,720
right because if I said small buffer

00:08:50,990 --> 00:08:56,240
sizes artificially I'm affecting that

00:08:53,720 --> 00:08:59,180
behavior I want to lay the conditioner

00:08:56,240 --> 00:09:02,330
go read and do it something and I'd be

00:08:59,180 --> 00:09:04,850
banned by any restrictions so we can see

00:09:02,330 --> 00:09:08,089
that the initially the condition window

00:09:04,850 --> 00:09:11,180
is like five hundred packets for cubic

00:09:08,089 --> 00:09:13,220
one the other flow start jumps to twenty

00:09:11,180 --> 00:09:14,870
five hundred packets right in it's less

00:09:13,220 --> 00:09:18,140
than hundred packets to achieve full

00:09:14,870 --> 00:09:21,350
throughput so the ITT because of these

00:09:18,140 --> 00:09:22,910
now became like more than 10

00:09:21,350 --> 00:09:26,720
milliseconds and that's why it's taking

00:09:22,910 --> 00:09:28,790
so long to converge the RTT seen by the

00:09:26,720 --> 00:09:29,899
floor rather than been 20 microseconds

00:09:28,790 --> 00:09:32,420
which would allow you to convert

00:09:29,899 --> 00:09:39,160
converge very quickly is more than 10

00:09:32,420 --> 00:09:48,290
milliseconds and this is what I mean by

00:09:39,160 --> 00:09:50,149
sorry and this is what I mean that we

00:09:48,290 --> 00:09:52,790
know and cubic you know periodically

00:09:50,149 --> 00:09:58,070
congest right so every time it goes down

00:09:52,790 --> 00:10:00,290
it because it last packet DC TCP you

00:09:58,070 --> 00:10:02,600
know that when they very quickly

00:10:00,290 --> 00:10:04,250
converges to be fair and then when the

00:10:02,600 --> 00:10:08,029
other flow starts very quickly goes back

00:10:04,250 --> 00:10:11,360
up okay which is what is to be expected

00:10:08,029 --> 00:10:13,850
I should mention however that for some

00:10:11,360 --> 00:10:18,890
reason in my environment I'm getting

00:10:13,850 --> 00:10:21,380
losses with DC TCP okay and I do not

00:10:18,890 --> 00:10:24,770
know if it's a bug in the code or an

00:10:21,380 --> 00:10:26,300
issue with my environment like in this

00:10:24,770 --> 00:10:29,839
experiment with there's only one flow

00:10:26,300 --> 00:10:32,810
and it was meeting 7,000 packets within

00:10:29,839 --> 00:10:35,270
the first 200 milliseconds so as a

00:10:32,810 --> 00:10:37,880
result of the slow start something is

00:10:35,270 --> 00:10:39,890
going on now the chili my congestion all

00:10:37,880 --> 00:10:41,630
of the links are the same bandwidth 10

00:10:39,890 --> 00:10:44,720
gigabits per second right so there

00:10:41,630 --> 00:10:47,120
should be no congestion but DC TCP

00:10:44,720 --> 00:10:50,620
strands meeting which was meeting seven

00:10:47,120 --> 00:10:50,620
thousand packets initially

00:10:54,850 --> 00:11:08,449
what do you mean by yeah packet loss

00:11:05,869 --> 00:11:11,029
yeah but if I look at the switch queue

00:11:08,449 --> 00:11:13,129
and see how many packets the key the

00:11:11,029 --> 00:11:19,629
switch drop for that four days in queue

00:11:13,129 --> 00:11:22,790
it says zero oh because I can look at a

00:11:19,629 --> 00:11:24,559
disappeared amp and see whether you know

00:11:22,790 --> 00:11:27,050
those packets were received later

00:11:24,559 --> 00:11:28,490
what is reordering or not yeah and it's

00:11:27,050 --> 00:11:32,899
not reordering yeah there's also a

00:11:28,490 --> 00:11:35,149
counter know saying you know so I will

00:11:32,899 --> 00:11:36,410
look at it after I get back I just

00:11:35,149 --> 00:11:40,069
didn't have time to figure out what's

00:11:36,410 --> 00:11:43,749
going on so so it's a caveat that that's

00:11:40,069 --> 00:11:46,279
what I'm saying and by mistake okay

00:11:43,749 --> 00:11:48,920
now interestingly you know like when

00:11:46,279 --> 00:11:50,839
this it this is TCP start is congestion

00:11:48,920 --> 00:11:52,819
window is very large five hundred

00:11:50,839 --> 00:11:54,619
packets right the reason is that it's

00:11:52,819 --> 00:11:57,980
not getting in the ec n markings there's

00:11:54,619 --> 00:12:00,139
only one flaw the switch is not that no

00:11:57,980 --> 00:12:03,499
bottleneck in the switch so it has no

00:12:00,139 --> 00:12:05,389
ecn markings when the other flow start

00:12:03,499 --> 00:12:07,129
now we're getting congestion at the

00:12:05,389 --> 00:12:10,189
switch on the congestion windows

00:12:07,129 --> 00:12:12,800
decreased to less than 100 when the

00:12:10,189 --> 00:12:14,269
second flow stops that congestion you

00:12:12,800 --> 00:12:15,439
know the congestion window again

00:12:14,269 --> 00:12:22,579
increases because it's not getting any

00:12:15,439 --> 00:12:25,850
markings i could tune cordell you know

00:12:22,579 --> 00:12:29,360
to so that it would give me markings

00:12:25,850 --> 00:12:35,679
when it's a having a queuing in the host

00:12:29,360 --> 00:12:35,679
but i did use the default values VAR

00:12:36,040 --> 00:12:42,470
this way you know it starts very nicely

00:12:40,790 --> 00:12:44,629
it very quickly goes to the right

00:12:42,470 --> 00:12:47,269
bandwidth we see the periodic decrease

00:12:44,629 --> 00:12:50,540
of the rate and congestion window as it

00:12:47,269 --> 00:12:53,350
proved for the RTT when the other flow

00:12:50,540 --> 00:12:56,509
starts you know it's more or less fair

00:12:53,350 --> 00:12:58,040
matters for us as a beer are but it's

00:12:56,509 --> 00:12:59,990
not too bad and then when the other flow

00:12:58,040 --> 00:13:02,480
starts the very quickly goes up the

00:12:59,990 --> 00:13:05,689
congestion windows are also much better

00:13:02,480 --> 00:13:09,970
control than with DC tcp when there's

00:13:05,689 --> 00:13:09,970
only one flow or we with key

00:13:15,110 --> 00:13:19,610
so this is saying be just in the base

00:13:17,540 --> 00:13:22,160
RTT uh very much microseconds if I don't

00:13:19,610 --> 00:13:26,300
use it then there's more variability

00:13:22,160 --> 00:13:29,720
okay so caveat this helps a lot you know

00:13:26,300 --> 00:13:32,360
telling and be that more than any eighty

00:13:29,720 --> 00:13:33,410
microseconds RT team is congestion it

00:13:32,360 --> 00:13:35,330
really helps it it doesn't need to

00:13:33,410 --> 00:13:38,210
figure that on its own and other

00:13:35,330 --> 00:13:46,700
algorithms could use this feature if

00:13:38,210 --> 00:13:47,990
they wanted to and this is cubic also

00:13:46,700 --> 00:13:49,580
using TCP BPF

00:13:47,990 --> 00:13:51,790
to clamp the congestion window to one

00:13:49,580 --> 00:13:53,780
hundred packets obviously you know

00:13:51,790 --> 00:13:55,220
everything works really really nicely

00:13:53,780 --> 00:13:58,190
perfect because they all stay at a

00:13:55,220 --> 00:14:03,860
hundred packet so it's perfect perfectly

00:13:58,190 --> 00:14:06,350
share perfect everything so the next one

00:14:03,860 --> 00:14:07,580
is going to be three flows the first one

00:14:06,350 --> 00:14:11,560
is going to be cubic and it's going to

00:14:07,580 --> 00:14:11,560
be competing with two of something else

00:14:12,500 --> 00:14:21,140
so this is cubic versus to be BR and for

00:14:17,750 --> 00:14:25,880
this specific case cubic stars very

00:14:21,140 --> 00:14:27,680
nicely when BB are stars start it decide

00:14:25,880 --> 00:14:30,070
there is congestion so it slows down and

00:14:27,680 --> 00:14:32,960
cubic keeps a lot of the bandwidth and

00:14:30,070 --> 00:14:36,650
then for us for a moment you know they

00:14:32,960 --> 00:14:38,480
change places and then the second floor

00:14:36,650 --> 00:14:41,630
that third the second third flow starts

00:14:38,480 --> 00:14:47,000
right here and so it's a live a chaotic

00:14:41,630 --> 00:14:49,790
behavior and in some cases cubic get

00:14:47,000 --> 00:14:51,950
most of the bandwidth in other cases VBR

00:14:49,790 --> 00:14:55,340
gets most of the bandwidth depending on

00:14:51,950 --> 00:14:57,290
the dynamics of bbr the congestion

00:14:55,340 --> 00:15:00,290
windows are small when cubics by itself

00:14:57,290 --> 00:15:05,540
when the other flow start q just goes

00:15:00,290 --> 00:15:07,100
crazy and then in DB is here the

00:15:05,540 --> 00:15:11,860
condition window and then it goes all

00:15:07,100 --> 00:15:11,860
the way here and then it goes down so

00:15:12,520 --> 00:15:20,000
let's see cubic with DC tcp is very nice

00:15:18,440 --> 00:15:21,980
when there's two flows like we saw when

00:15:20,000 --> 00:15:24,830
we get another flow

00:15:21,980 --> 00:15:26,570
then because we have two queues we have

00:15:24,830 --> 00:15:28,760
to specify how much bandwidth is queue

00:15:26,570 --> 00:15:31,460
is going to get right and the idea is

00:15:28,760 --> 00:15:36,650
that if there is contention you divided

00:15:31,460 --> 00:15:38,630
50/50 so in this case cubic as 50% and

00:15:36,650 --> 00:15:41,000
the other 50% are divided evenly by the

00:15:38,630 --> 00:15:44,360
other two DC TCP flows so that's one of

00:15:41,000 --> 00:15:46,490
the drawbacks of having to have multiple

00:15:44,360 --> 00:15:48,650
queues where you're changing the the

00:15:46,490 --> 00:15:51,860
bandwidth like this fairly like this and

00:15:48,650 --> 00:15:55,540
for the congestion windows cubic goes

00:15:51,860 --> 00:15:57,440
crazy again this it is P is very low and

00:15:55,540 --> 00:16:00,980
because they're in different queues are

00:15:57,440 --> 00:16:02,840
protected and everything is good and the

00:16:00,980 --> 00:16:06,820
DC TCP flows will have low latency and

00:16:02,840 --> 00:16:06,820
that cubic flows will have high latency

00:16:08,410 --> 00:16:15,020
if we use the TCP BPF program to clamp

00:16:12,140 --> 00:16:16,870
the windows and we run the cubic VD our

00:16:15,020 --> 00:16:24,550
experiment then everything looks perfect

00:16:16,870 --> 00:16:28,400
okay so TCP BPF does help like on the

00:16:24,550 --> 00:16:29,960
data center to get good results with you

00:16:28,400 --> 00:16:35,510
know at least with an unlimited number

00:16:29,960 --> 00:16:37,160
of flows okay so now we're going to look

00:16:35,510 --> 00:16:40,730
at the semi environment the data center

00:16:37,160 --> 00:16:44,090
with many more flows and I'm doing for

00:16:40,730 --> 00:16:50,660
each host sender is running one

00:16:44,090 --> 00:16:52,370
streaming 110 kilobyte RPC and many one

00:16:50,660 --> 00:16:53,780
megabyte are PCs and I'm gonna increase

00:16:52,370 --> 00:16:56,330
the number of one megabyte pieces to

00:16:53,780 --> 00:17:00,470
create more load more congestion to see

00:16:56,330 --> 00:17:04,100
how the algorithms react to it so this

00:17:00,470 --> 00:17:07,070
is the environment I told you one stream

00:17:04,100 --> 00:17:13,990
in 110 kilo by RPC and many one megabyte

00:17:07,070 --> 00:17:18,530
are pieces ok so what happens so the X

00:17:13,990 --> 00:17:20,780
sorry so here we had the number of flows

00:17:18,530 --> 00:17:24,350
so as we move to this side were

00:17:20,780 --> 00:17:27,440
increasing the number of flows okay the

00:17:24,350 --> 00:17:31,130
left axis the bars are the rate in

00:17:27,440 --> 00:17:34,100
gigabits per second and this is the this

00:17:31,130 --> 00:17:34,940
is for the streaming flows right so I'm

00:17:34,100 --> 00:17:35,930
gonna look at each of those

00:17:34,940 --> 00:17:37,720
independently

00:17:35,930 --> 00:17:41,000
so what happens with the streaming flows

00:17:37,720 --> 00:17:46,700
this is the rate and on the right side

00:17:41,000 --> 00:17:49,550
is the number of retransmissions so and

00:17:46,700 --> 00:17:52,940
I have cubic TC TC p and b vb r and t CP

00:17:49,550 --> 00:17:56,030
BPF so we see that BD r which is the red

00:17:52,940 --> 00:17:58,940
one you know it has I'm sorry the brown

00:17:56,030 --> 00:18:00,290
one or the master color it seems like

00:17:58,940 --> 00:18:01,580
you know it's much higher than the other

00:18:00,290 --> 00:18:04,190
one so you would think well that's great

00:18:01,580 --> 00:18:06,350
you know that is working well it's

00:18:04,190 --> 00:18:08,840
rubbing a lot of the bandwidth but

00:18:06,350 --> 00:18:11,929
remember that that language is being

00:18:08,840 --> 00:18:14,900
shared by the other flows so if it's

00:18:11,929 --> 00:18:17,030
high here it probably means that the one

00:18:14,900 --> 00:18:20,300
megabyte are pcs and then kilobyte our

00:18:17,030 --> 00:18:22,790
pcs are going to suffer they all utilize

00:18:20,300 --> 00:18:26,140
all of the bandwidth very well so there

00:18:22,790 --> 00:18:29,690
was no case of under utilization okay

00:18:26,140 --> 00:18:32,809
and we also see that bbr has a large

00:18:29,690 --> 00:18:35,000
number of retransmission and VBR is not

00:18:32,809 --> 00:18:37,100
tuned for the land necessarily it needs

00:18:35,000 --> 00:18:40,340
certain amount of buffers at the

00:18:37,100 --> 00:18:43,520
bottleneck so the DC is not the ideal

00:18:40,340 --> 00:18:48,200
environment for bbr so should give that

00:18:43,520 --> 00:18:52,429
caveat but the 1 million line it's a run

00:18:48,200 --> 00:18:54,200
two percent retransmissions okay so and

00:18:52,429 --> 00:18:58,580
everybody else has like point zero one

00:18:54,200 --> 00:19:01,790
percent with transmissions so you know

00:18:58,580 --> 00:19:05,630
the main thing here that bbr gives more

00:19:01,790 --> 00:19:10,309
the bandwidth to the streaming flow this

00:19:05,630 --> 00:19:14,000
is the one megabyte RPC good put let's

00:19:10,309 --> 00:19:16,340
see so the other ones are given more

00:19:14,000 --> 00:19:20,660
bandwidth to the BB arc as compared to

00:19:16,340 --> 00:19:23,000
to the one megabyte our pcs bbr is

00:19:20,660 --> 00:19:25,429
suffering a little bit although similar

00:19:23,000 --> 00:19:27,490
i would ignore this it tcp because of

00:19:25,429 --> 00:19:31,370
the problems i saw with transmissions

00:19:27,490 --> 00:19:33,440
and also once again BB iris has a higher

00:19:31,370 --> 00:19:35,660
number with transmissions quite a bit

00:19:33,440 --> 00:19:37,250
higher so now let's look at the more

00:19:35,660 --> 00:19:40,040
interesting this is the ten kilobyte our

00:19:37,250 --> 00:19:44,179
pcs okay how are they doing when they're

00:19:40,040 --> 00:19:47,870
competing with the other flows so we can

00:19:44,179 --> 00:19:50,419
see that as we increase the number of

00:19:47,870 --> 00:19:54,109
flows bbr is doing you know

00:19:50,419 --> 00:19:56,269
worst and worst and worst right so it

00:19:54,109 --> 00:19:59,029
tends to give more bandwidth to the

00:19:56,269 --> 00:20:04,940
fatter flows the streaming and that 1

00:19:59,029 --> 00:20:10,820
megabyte RPC flows let's see

00:20:04,940 --> 00:20:12,379
TCP BPF is good and the reason the other

00:20:10,820 --> 00:20:17,059
floats get more bandwidth it was at

00:20:12,379 --> 00:20:19,970
their congestion windows cubic bbr etc

00:20:17,059 --> 00:20:22,999
and allowing the fighter flow to have

00:20:19,970 --> 00:20:25,879
bigger congestion windows they they

00:20:22,999 --> 00:20:27,109
don't need more than 100 packets to

00:20:25,879 --> 00:20:29,059
fully utilize the bandwidth by

00:20:27,109 --> 00:20:33,049
themselves right but they allow them to

00:20:29,059 --> 00:20:35,749
grow 200 therefore every RTT they are

00:20:33,049 --> 00:20:38,749
sending hundreds of packet the 10 kilo

00:20:35,749 --> 00:20:41,989
byte RPC is sending 7 packets so it's

00:20:38,749 --> 00:20:44,509
trooper obviously suffers a lot tcp BPF

00:20:41,989 --> 00:20:47,539
health by limiting the congestion window

00:20:44,509 --> 00:20:49,879
to 100 so the further flows will not

00:20:47,539 --> 00:20:52,909
have more than hundred packets ok so

00:20:49,879 --> 00:20:55,519
therefore the RTT is smaller and the 10

00:20:52,909 --> 00:20:57,350
kilo byte RPC is do well and be - even

00:20:55,519 --> 00:21:00,049
better than that it decreases it to like

00:20:57,350 --> 00:21:02,480
20 packets or 15 packets as we get more

00:21:00,049 --> 00:21:04,429
flows therefore that 10 kilo byte our

00:21:02,480 --> 00:21:07,129
pieces are doing really well the RTT is

00:21:04,429 --> 00:21:10,429
very small so they can send you know

00:21:07,129 --> 00:21:13,519
they can push the 7 packet very quickly

00:21:10,429 --> 00:21:14,809
in one RTT that is only you know a

00:21:13,519 --> 00:21:20,600
millisecond as opposed to 10

00:21:14,809 --> 00:21:22,669
milliseconds for for the other cases and

00:21:20,600 --> 00:21:26,359
it shows the latencies for the 10

00:21:22,669 --> 00:21:31,279
kilobyte our pcs in milliseconds and

00:21:26,359 --> 00:21:36,789
this is a log scale so once again you

00:21:31,279 --> 00:21:40,129
know for let's say bbr has high one and

00:21:36,789 --> 00:21:42,529
goes up this it is as I say ignore DC

00:21:40,129 --> 00:21:44,570
TCP was dropping packet so it's not

00:21:42,529 --> 00:21:47,840
behaving that way should be behaving by

00:21:44,570 --> 00:21:48,859
comparing with everybody else bbr has

00:21:47,840 --> 00:21:52,759
higher latencies

00:21:48,859 --> 00:21:55,570
quite a bit and and this distance is a

00:21:52,759 --> 00:22:01,249
factor of 5 right this is a log scale

00:21:55,570 --> 00:22:04,440
interestingly both + b & b BF p TCP BPF

00:22:01,249 --> 00:22:07,320
the 99 percentile latencies on the

00:22:04,440 --> 00:22:13,710
left and the 99.9% of latencies are

00:22:07,320 --> 00:22:14,610
about the same VBR it's a factor of five

00:22:13,710 --> 00:22:18,260
at least

00:22:14,610 --> 00:22:20,970
so you're getting to these second

00:22:18,260 --> 00:22:24,120
latencies in the worst case scenario for

00:22:20,970 --> 00:22:26,940
the 99.9% of latencies a quick question

00:22:24,120 --> 00:22:29,670
Larry yes your previous slide shows VPO

00:22:26,940 --> 00:22:36,510
has a high transmission as well the

00:22:29,670 --> 00:22:38,850
previous one the green for the day came

00:22:36,510 --> 00:22:42,420
flows right and it's not sending very

00:22:38,850 --> 00:22:43,950
many of those so all of the do

00:22:42,420 --> 00:22:47,100
transmissions for VB are in this

00:22:43,950 --> 00:22:50,580
experiment were like 2% retransmissions

00:22:47,100 --> 00:22:52,230
overall okay the 10 kilobytes they look

00:22:50,580 --> 00:22:57,480
like small because it's not sending many

00:22:52,230 --> 00:23:00,510
our pieces right so the primary issue is

00:22:57,480 --> 00:23:04,470
that long latency latency is due to

00:23:00,510 --> 00:23:06,510
research machine the long tail that 99.9

00:23:04,470 --> 00:23:10,430
probably guess that's what we see the

00:23:06,510 --> 00:23:14,430
factor of 5 going up but you know like

00:23:10,430 --> 00:23:17,210
like here they're still big and they're

00:23:14,430 --> 00:23:21,810
not you know the RTO is 200,000 right

00:23:17,210 --> 00:23:24,390
these are in microsecond this should be

00:23:21,810 --> 00:23:27,000
microseconds I forgot 2/10 sorry this

00:23:24,390 --> 00:23:33,510
should be microseconds so this line is a

00:23:27,000 --> 00:23:37,110
hundred milliseconds so let's see bbr is

00:23:33,510 --> 00:23:40,110
below it right so did like at this point

00:23:37,110 --> 00:23:43,140
is not due to our Tio's right you just

00:23:40,110 --> 00:23:47,970
do to the bigger congestion window for

00:23:43,140 --> 00:23:51,990
the other flows okay so now I'm going to

00:23:47,970 --> 00:23:55,170
move right we will be able to get to the

00:23:51,990 --> 00:23:58,940
50 slice of the row so the next scenario

00:23:55,170 --> 00:24:03,900
is a 10 G without 10 milliseconds

00:23:58,940 --> 00:24:07,170
latency RTT okay and these are somewhat

00:24:03,900 --> 00:24:08,820
more interesting so what I did here I

00:24:07,170 --> 00:24:10,590
don't want to go to all the flaws even

00:24:08,820 --> 00:24:12,870
though they look really interesting the

00:24:10,590 --> 00:24:15,420
behaviors I will show some of those this

00:24:12,870 --> 00:24:18,300
is that 2 & 3 flow aggregate goodput and

00:24:15,420 --> 00:24:21,090
retransmissions are they able

00:24:18,300 --> 00:24:24,150
to fully utilize the bandwidth when we

00:24:21,090 --> 00:24:27,360
have a 10 millisecond delay right and so

00:24:24,150 --> 00:24:30,780
this reflects how quickly the congestion

00:24:27,360 --> 00:24:32,610
algorithm can ramp up its congestion

00:24:30,780 --> 00:24:35,160
window to fully use the available

00:24:32,610 --> 00:24:37,590
bandwidth so initially you know they

00:24:35,160 --> 00:24:40,140
would do slow start how quickly they

00:24:37,590 --> 00:24:41,660
stopped if they stopped to know how

00:24:40,140 --> 00:24:44,340
quickly they can go up after that

00:24:41,660 --> 00:24:48,120
indicate how well do utilize the

00:24:44,340 --> 00:24:51,870
available bandwidth sorry

00:24:48,120 --> 00:24:54,900
so bbr that's really really well right

00:24:51,870 --> 00:24:58,710
it's able to use you know as much as it

00:24:54,900 --> 00:25:00,870
can almost and the blue one reflects two

00:24:58,710 --> 00:25:04,290
flows the real one bill reflects three

00:25:00,870 --> 00:25:05,910
flows the Diamonds the green diamonds

00:25:04,290 --> 00:25:08,010
are the number of percent with

00:25:05,910 --> 00:25:08,670
transmissions and it has Hydra

00:25:08,010 --> 00:25:12,230
transmissions

00:25:08,670 --> 00:25:15,350
like point seven percent for two flows

00:25:12,230 --> 00:25:20,040
more than three percent for three flows

00:25:15,350 --> 00:25:23,640
okay and this is due to the fact that

00:25:20,040 --> 00:25:26,580
the buffer size on the cue on the switch

00:25:23,640 --> 00:25:32,970
is small it's not bang with delay

00:25:26,580 --> 00:25:34,700
product size it's smaller than that so

00:25:32,970 --> 00:25:36,870
let's see what else

00:25:34,700 --> 00:25:40,980
everybody else has very small with

00:25:36,870 --> 00:25:43,830
transmissions like less than 0.1% some

00:25:40,980 --> 00:25:46,550
of these you know like Wedgwood does

00:25:43,830 --> 00:25:50,610
horrible and utilizing the bandwidth

00:25:46,550 --> 00:25:53,580
winner is not good either high speed is

00:25:50,610 --> 00:25:54,710
in between cubic is not too good at it

00:25:53,580 --> 00:25:57,540
either

00:25:54,710 --> 00:25:59,910
it takes a long while to run pop and I'm

00:25:57,540 --> 00:26:02,250
surprised about cubic because in the

00:25:59,910 --> 00:26:03,720
past I thought I've seen it run pop a

00:26:02,250 --> 00:26:06,240
lot faster you know it has this mark

00:26:03,720 --> 00:26:07,650
where it is logarithm around that time

00:26:06,240 --> 00:26:10,200
of the previous losses then it goes

00:26:07,650 --> 00:26:11,970
exponential and I've seen it do a lot

00:26:10,200 --> 00:26:14,760
better so I don't know if any changes in

00:26:11,970 --> 00:26:20,070
our in the in the code pad have affected

00:26:14,760 --> 00:26:21,990
it big that's really well we you know I

00:26:20,070 --> 00:26:24,750
would imagine people who have done just

00:26:21,990 --> 00:26:27,950
as well in this environment and yeah

00:26:24,750 --> 00:26:27,950
that's really well too

00:26:28,880 --> 00:26:33,169
so let's look at some examples of the

00:26:30,980 --> 00:26:35,029
good boot for D scenarios right I took

00:26:33,169 --> 00:26:36,500
explain why we saw the behavior that

00:26:35,029 --> 00:26:38,899
they didn't use all of the available

00:26:36,500 --> 00:26:41,630
bandwidth during this 16 second period

00:26:38,899 --> 00:26:44,120
if I waited you know three four or five

00:26:41,630 --> 00:26:46,820
minutes they probably would have use you

00:26:44,120 --> 00:26:48,860
know better utilization so cubic you

00:26:46,820 --> 00:26:50,840
know had losses here and then very

00:26:48,860 --> 00:26:54,679
slowly grows you know it takes it more

00:26:50,840 --> 00:26:56,690
than 12 seconds you know to try to get

00:26:54,679 --> 00:26:58,880
to the fuel utilization at this time the

00:26:56,690 --> 00:27:00,649
second flow starts things look a little

00:26:58,880 --> 00:27:04,129
bit better you know it's fully utilizing

00:27:00,649 --> 00:27:06,379
the bandwidth now another flow starts so

00:27:04,129 --> 00:27:08,779
it's slowly converging so that you have

00:27:06,379 --> 00:27:12,200
fairness but for example here once all

00:27:08,779 --> 00:27:15,740
the flows stop cubic you know like in

00:27:12,200 --> 00:27:18,129
the seven seconds that he has left it

00:27:15,740 --> 00:27:22,070
really doesn't make much headway on gay

00:27:18,129 --> 00:27:27,039
using the available bandwidth and again

00:27:22,070 --> 00:27:27,039
I'm surprised about these four cubic

00:27:27,759 --> 00:27:37,580
this is bbr and this is the normal case

00:27:34,909 --> 00:27:39,830
for PBR meaning most of the time it

00:27:37,580 --> 00:27:41,899
behaves like this and it works really

00:27:39,830 --> 00:27:43,820
well it very quickly runs up uses all

00:27:41,899 --> 00:27:46,879
the bandwidth every now and then it does

00:27:43,820 --> 00:27:49,250
the RTT probing when another flow starts

00:27:46,879 --> 00:27:51,799
you immediately you know become fair

00:27:49,250 --> 00:27:52,700
another flow starts it really behaves

00:27:51,799 --> 00:27:55,639
really really nicely

00:27:52,700 --> 00:27:58,490
the third flow stops it goes up very

00:27:55,639 --> 00:28:00,019
quickly these flow stops you know the

00:27:58,490 --> 00:28:05,750
first flow goes up right it looks

00:28:00,019 --> 00:28:07,100
perfect just gorgeous this image source

00:28:05,750 --> 00:28:09,710
what's going on with the retransmissions

00:28:07,100 --> 00:28:14,090
a lot of them right 700,000

00:28:09,710 --> 00:28:15,169
retransmissions for the for the first

00:28:14,090 --> 00:28:17,240
and second flows

00:28:15,169 --> 00:28:19,460
his route was meeting a lot but he

00:28:17,240 --> 00:28:22,340
doesn't care you know it's like 2% it's

00:28:19,460 --> 00:28:23,990
happy it makes use of the bandwidth you

00:28:22,340 --> 00:28:25,730
know it's a small price to pay in many

00:28:23,990 --> 00:28:31,639
scenarios unless you're trying to

00:28:25,730 --> 00:28:34,700
compete with it obviously so this is big

00:28:31,639 --> 00:28:37,490
and big is doing a lot better than cubic

00:28:34,700 --> 00:28:40,100
which I again am surprised very quickly

00:28:37,490 --> 00:28:42,559
uses it when a narrow flow starts they

00:28:40,100 --> 00:28:43,820
slowly converge when

00:28:42,559 --> 00:28:45,440
another start you know they're slowly

00:28:43,820 --> 00:28:49,249
converging so they're not as fair

00:28:45,440 --> 00:28:51,289
obviously as bbr and when the turf law

00:28:49,249 --> 00:28:53,389
stops you know very quickly they use the

00:28:51,289 --> 00:28:55,070
bandwidth when the lot slow start it

00:28:53,389 --> 00:28:58,279
jumps very quickly to use it right

00:28:55,070 --> 00:29:00,259
remember Cuba could not do this job in

00:28:58,279 --> 00:29:02,029
more than six seconds this is doing it

00:29:00,259 --> 00:29:03,850
like in one or two seconds it's jumping

00:29:02,029 --> 00:29:06,110
and using a lot of bandwidth

00:29:03,850 --> 00:29:11,480
retransmissions are about six thousand

00:29:06,110 --> 00:29:14,419
so a hundred times less than VB are so

00:29:11,480 --> 00:29:17,240
you are getting not the fairness or bbr

00:29:14,419 --> 00:29:19,190
but the utilization of bbr with a lot

00:29:17,240 --> 00:29:22,940
fewer with transmissions with big we

00:29:19,190 --> 00:29:24,529
suggest kind of ironic many times many

00:29:22,940 --> 00:29:27,019
of us in the past used to run big in our

00:29:24,529 --> 00:29:29,679
data centers when Cuba came about we run

00:29:27,019 --> 00:29:32,450
Kubek because it was better but

00:29:29,679 --> 00:29:35,240
something is going on right now that for

00:29:32,450 --> 00:29:42,369
longer Artie T's big is much better than

00:29:35,240 --> 00:29:44,720
Kubek yeah that's really really well

00:29:42,369 --> 00:29:46,999
you said the bandwidth would one flow

00:29:44,720 --> 00:29:49,249
when another one starts very quickly

00:29:46,999 --> 00:29:51,169
they converge when the turbine starts

00:29:49,249 --> 00:29:53,919
the conversion more or less not as good

00:29:51,169 --> 00:29:56,360
as we are but very quickly one stops

00:29:53,919 --> 00:29:58,519
they you know they very quickly use it

00:29:56,360 --> 00:30:00,559
if you can see like this line is the

00:29:58,519 --> 00:30:03,710
aggregate good put it's pretty good

00:30:00,559 --> 00:30:06,529
and the retransmissions are like seven

00:30:03,710 --> 00:30:07,879
thousand initially with the slow start

00:30:06,529 --> 00:30:11,740
and then there's almost barely any

00:30:07,879 --> 00:30:14,499
retransmission so it looks really nice

00:30:11,740 --> 00:30:17,990
the part would be VR is that I've seen

00:30:14,499 --> 00:30:22,960
flow collapse where one of the flows

00:30:17,990 --> 00:30:28,340
will just collapse right and this shows

00:30:22,960 --> 00:30:30,950
some of I ran 20 times the same

00:30:28,340 --> 00:30:33,529
experiment with three flows and with two

00:30:30,950 --> 00:30:38,029
flows and you know like every now and

00:30:33,529 --> 00:30:39,470
then this would happen one is great the

00:30:38,029 --> 00:30:40,519
other one start is great that they're

00:30:39,470 --> 00:30:41,809
gonna start using is great and

00:30:40,519 --> 00:30:44,809
incidentally the first flow just

00:30:41,809 --> 00:30:47,450
collapses totally collapses the other

00:30:44,809 --> 00:30:49,429
one when the tur flow stops the second

00:30:47,450 --> 00:30:53,090
float jumps and you said when these

00:30:49,429 --> 00:30:56,179
collapses the first flows dies collapse

00:30:53,090 --> 00:30:58,700
maybe we have gone up later I do

00:30:56,179 --> 00:31:00,440
no but you know like a key you can see

00:30:58,700 --> 00:31:03,860
that he did the RTT problem right here

00:31:00,440 --> 00:31:06,889
and he still stay done no idea what's

00:31:03,860 --> 00:31:09,440
going on retransmissions again there hi

00:31:06,889 --> 00:31:11,629
about two percent for all of them but

00:31:09,440 --> 00:31:13,789
even like after the second floor stops

00:31:11,629 --> 00:31:17,740
there is no retransmission and it's just

00:31:13,789 --> 00:31:21,740
not not increasing this one is even

00:31:17,740 --> 00:31:22,009
worse the first floor for VBR is doing

00:31:21,740 --> 00:31:25,580
great

00:31:22,009 --> 00:31:26,720
second floor starts it stays down it

00:31:25,580 --> 00:31:30,080
doesn't do anything

00:31:26,720 --> 00:31:31,399
third floor start stays down right if we

00:31:30,080 --> 00:31:33,289
look at there with transmissions they

00:31:31,399 --> 00:31:35,720
are not many anymore right there's only

00:31:33,289 --> 00:31:37,429
a few transmissions that are seen by the

00:31:35,720 --> 00:31:40,519
blue flow which is the first flow

00:31:37,429 --> 00:31:43,220
there's only like 9,000 Tora the other

00:31:40,519 --> 00:31:44,720
flows didn't see any transmissions so

00:31:43,220 --> 00:31:46,159
they are not suppressed because they

00:31:44,720 --> 00:31:48,710
serve with transmissions they are

00:31:46,159 --> 00:31:50,269
suppressed because their mechanism to

00:31:48,710 --> 00:31:52,070
the tech ingest and decided there is

00:31:50,269 --> 00:31:58,249
congestion so I'm going to slow it down

00:31:52,070 --> 00:32:00,499
and I'm going to stay down and so what

00:31:58,249 --> 00:32:04,309
I've seen in my experiments you know 20

00:32:00,499 --> 00:32:07,519
repeats is that in 10% of the cases with

00:32:04,309 --> 00:32:09,889
two flows there will be at some time one

00:32:07,519 --> 00:32:12,830
of the flow collapses with the three

00:32:09,889 --> 00:32:16,940
flows 20% of the times one or two of the

00:32:12,830 --> 00:32:18,980
flow collapse now this collapse may also

00:32:16,940 --> 00:32:23,480
be triggered by noise introduced by

00:32:18,980 --> 00:32:25,220
medium okay however you will expect it

00:32:23,480 --> 00:32:29,960
to be able to recover right like in the

00:32:25,220 --> 00:32:33,409
previous one who said here this flow has

00:32:29,960 --> 00:32:34,389
40 seconds to recover right I mean and

00:32:33,409 --> 00:32:36,619
if we saw before

00:32:34,389 --> 00:32:40,639
sometimes the flows were very happy like

00:32:36,619 --> 00:32:43,429
this slow so you know unless this flow

00:32:40,639 --> 00:32:46,519
is being punished by Nady aim it was in

00:32:43,429 --> 00:32:48,889
a lot of noise only for this flow you

00:32:46,519 --> 00:32:55,100
know it's not able to recover in 40

00:32:48,889 --> 00:32:57,309
seconds so okay so whatever furnace

00:32:55,100 --> 00:33:00,860
against cubic I look at all the graphs

00:32:57,309 --> 00:33:02,840
to any grasp or perish combination and

00:33:00,860 --> 00:33:05,509
all that to to get an idea has some

00:33:02,840 --> 00:33:07,419
numbers but I decided you're not gonna

00:33:05,509 --> 00:33:10,040
show them for other things not these

00:33:07,419 --> 00:33:13,700
cubic losses against beacon bbr

00:33:10,040 --> 00:33:15,530
typically jail losses against kill it

00:33:13,700 --> 00:33:17,780
so he doesn't I mean he like totally

00:33:15,530 --> 00:33:19,820
suppressed I guess cubic so it does

00:33:17,780 --> 00:33:22,250
really well against itself it was really

00:33:19,820 --> 00:33:24,620
poorly against cubic and cubic and Reno

00:33:22,250 --> 00:33:26,930
and that being even right and I'm

00:33:24,620 --> 00:33:29,630
surprised because a 10 millisecond RTT

00:33:26,930 --> 00:33:32,390
case clinic should be able to do better

00:33:29,630 --> 00:33:34,580
right I mean big that's much better that

00:33:32,390 --> 00:33:36,350
you know I guess cubic so I think

00:33:34,580 --> 00:33:39,800
something Frankie is going on with cubic

00:33:36,350 --> 00:33:46,120
do you have any number on new big versus

00:33:39,800 --> 00:33:50,690
PPR no you know this is the result of a

00:33:46,120 --> 00:33:53,150
couple more than a thousand experiment

00:33:50,690 --> 00:33:58,130
so I have to limit you know like if you

00:33:53,150 --> 00:33:59,000
look back like once I saw that like wait

00:33:58,130 --> 00:34:00,920
was doing poorly

00:33:59,000 --> 00:34:06,440
I stopped testing it right so I only

00:34:00,920 --> 00:34:10,159
stay with beacon yeah but I ran hundreds

00:34:06,440 --> 00:34:14,530
or like 2000 experiment so it's hard to

00:34:10,159 --> 00:34:16,550
process everything we don't have time

00:34:14,530 --> 00:34:23,929
okay

00:34:16,550 --> 00:34:26,000
so good put and retransmissions for okay

00:34:23,929 --> 00:34:27,950
so now we're going to go back to the

00:34:26,000 --> 00:34:30,560
size and furnace test where I'm doing

00:34:27,950 --> 00:34:33,740
multiple you know like streaming in this

00:34:30,560 --> 00:34:35,600
case a megabyte and one megabyte the 10

00:34:33,740 --> 00:34:37,760
kilobyte doesn't make sense with the art

00:34:35,600 --> 00:34:39,260
it is so large you know it doesn't get

00:34:37,760 --> 00:34:42,560
much throughput so I use a mega by our

00:34:39,260 --> 00:34:44,600
pcs and one megabyte our pcs to see what

00:34:42,560 --> 00:34:46,190
happens and so this is the overall good

00:34:44,600 --> 00:34:49,220
put and the number of retransmissions

00:34:46,190 --> 00:34:53,990
and this is four cubic maybe are big and

00:34:49,220 --> 00:34:56,270
yeah so this is as we move on the x-axis

00:34:53,990 --> 00:34:59,630
we're increasing the number of a

00:34:56,270 --> 00:35:03,140
megabyte our pcs there's always one

00:34:59,630 --> 00:35:04,370
streaming and one one megabyte RPC but

00:35:03,140 --> 00:35:07,970
we increase the number of immigrant

00:35:04,370 --> 00:35:08,570
visas and this is the good put so in the

00:35:07,970 --> 00:35:10,790
good

00:35:08,570 --> 00:35:14,600
they all do more or less the same VBR

00:35:10,790 --> 00:35:15,980
does better initially but the other ones

00:35:14,600 --> 00:35:19,190
are not too far behind in terms of

00:35:15,980 --> 00:35:22,250
overall good put in terms of

00:35:19,190 --> 00:35:24,020
retransmission which is the diamond bbr

00:35:22,250 --> 00:35:27,080
you know in the order of

00:35:24,020 --> 00:35:29,600
almost 4% going down to one and a half

00:35:27,080 --> 00:35:36,710
percent the other ones are very very low

00:35:29,600 --> 00:35:38,600
like 0.1% or lower so now I'm going to

00:35:36,710 --> 00:35:41,180
look at the good put of each of the

00:35:38,600 --> 00:35:43,970
different flow types streaming a

00:35:41,180 --> 00:35:49,100
megabyte and 10 kilobytes to see how

00:35:43,970 --> 00:35:51,380
they have fared the algorithm is with

00:35:49,100 --> 00:35:54,470
the different sizes so this is the

00:35:51,380 --> 00:35:55,640
streaming and again VBR that's really

00:35:54,470 --> 00:35:59,300
well right

00:35:55,640 --> 00:36:01,880
the bbr flows the streaming flows will

00:35:59,300 --> 00:36:04,250
be they are do really well remember that

00:36:01,880 --> 00:36:06,830
means is taken up with a wet bandwidth

00:36:04,250 --> 00:36:11,630
from the a megabyte and that one mega by

00:36:06,830 --> 00:36:14,000
our pcs right so well again the overall

00:36:11,630 --> 00:36:16,610
utilization at the bandwidth is very

00:36:14,000 --> 00:36:19,369
close to the same for all of them but

00:36:16,610 --> 00:36:25,960
this means and furnace based on the flow

00:36:19,369 --> 00:36:28,280
size the Omega Bazaar pcs you know

00:36:25,960 --> 00:36:30,740
obviously the OB b are the red ones

00:36:28,280 --> 00:36:35,300
suffer they're giving most of it to the

00:36:30,740 --> 00:36:38,170
streaming flow and the retransmissions

00:36:35,300 --> 00:36:45,640
obviously you know again are higher for

00:36:38,170 --> 00:36:48,770
DVR and let's see big that's really well

00:36:45,640 --> 00:36:51,320
and yeah that's well also for the a

00:36:48,770 --> 00:36:55,369
megabytes and this is the one megabyte

00:36:51,320 --> 00:36:57,380
our pcs right this is the cost the

00:36:55,369 --> 00:36:59,720
streaming does really well the one

00:36:57,380 --> 00:37:02,090
megabyte our pcs do really poorly this

00:36:59,720 --> 00:37:05,180
is the average good put you know like

00:37:02,090 --> 00:37:11,630
four or five times slower than everybody

00:37:05,180 --> 00:37:13,460
else and in terms of the latencies which

00:37:11,630 --> 00:37:15,710
is probably probably think more about

00:37:13,460 --> 00:37:17,900
when we talk about our pcs not the troop

00:37:15,710 --> 00:37:21,830
about the latencies obviously you know

00:37:17,900 --> 00:37:24,380
like the bbr latencies are huge like man

00:37:21,830 --> 00:37:27,170
I don't know 10 times more than the

00:37:24,380 --> 00:37:29,990
other ones for all of these and if you

00:37:27,170 --> 00:37:31,609
do look at the 99% lateness on 99

00:37:29,990 --> 00:37:37,210
percent latencies they're quite large

00:37:31,609 --> 00:37:39,880
also so BER

00:37:37,210 --> 00:37:42,849
gives more bandwidth to the streaming

00:37:39,880 --> 00:37:44,589
flows than the smaller our pcs right and

00:37:42,849 --> 00:37:46,660
if you only had one megabyte and one

00:37:44,589 --> 00:37:48,309
megabyte our pcs it will give more to

00:37:46,660 --> 00:37:51,130
the a megabyte less to the one megawatt

00:37:48,309 --> 00:37:55,809
our pcs do you know that's just inherent

00:37:51,130 --> 00:37:58,809
Olivia so what do we know what the

00:37:55,809 --> 00:38:00,249
result first of all you know we see no

00:37:58,809 --> 00:38:02,769
conditional algorithm is perfect right

00:38:00,249 --> 00:38:05,619
they suffer in one way or another one

00:38:02,769 --> 00:38:09,490
like DVR has more transmissions but it's

00:38:05,619 --> 00:38:10,990
very fair most of the cases GL suffers

00:38:09,490 --> 00:38:12,400
against cubic so it's probably not a

00:38:10,990 --> 00:38:16,210
good choice if you're going to help mix

00:38:12,400 --> 00:38:18,490
congested traffic be BRM big her cubic

00:38:16,210 --> 00:38:21,700
DVR is good at using a barrel bandwidth

00:38:18,490 --> 00:38:25,119
it's really good at that bbl does well

00:38:21,700 --> 00:38:27,099
when it's the only flow bvr does hurt

00:38:25,119 --> 00:38:30,009
itself sometimes like animation 20% of

00:38:27,099 --> 00:38:32,650
the time Amelia has a lot with

00:38:30,009 --> 00:38:39,999
transmissions in this environment that H

00:38:32,650 --> 00:38:42,519
alright any comments oh I told you

00:38:39,999 --> 00:38:43,210
shaking your hand sorry okay so now

00:38:42,519 --> 00:38:47,440
we're going to look at different

00:38:43,210 --> 00:38:49,299
scenario forty milliseconds RTT ten

00:38:47,440 --> 00:38:51,880
megabits per second okay

00:38:49,299 --> 00:38:55,239
I also run a Hana megabits per second

00:38:51,880 --> 00:38:58,210
but didn't have time to make the slide

00:38:55,239 --> 00:38:59,529
so we're going to stick with this one so

00:38:58,210 --> 00:39:01,630
one gonna start we'd you know again

00:38:59,529 --> 00:39:03,460
there's three hosts ending but because

00:39:01,630 --> 00:39:05,410
the bandwidth is so much smaller 10

00:39:03,460 --> 00:39:08,170
megabit we're going to start with one

00:39:05,410 --> 00:39:10,539
flow per host one flow is going to be

00:39:08,170 --> 00:39:12,160
doing the streaming and other floods

00:39:10,539 --> 00:39:14,109
going to be doing that one megabyte RPC

00:39:12,160 --> 00:39:16,420
and I'm going back to that one megabyte

00:39:14,109 --> 00:39:18,730
because the banquet is a lot smaller and

00:39:16,420 --> 00:39:21,900
the other host is going to be doing the

00:39:18,730 --> 00:39:25,150
ten kilo byte RPC okay so we have less

00:39:21,900 --> 00:39:28,690
contention the goodput is good for all

00:39:25,150 --> 00:39:30,039
of them and some of these I don't have

00:39:28,690 --> 00:39:31,359
her big and yet because those

00:39:30,039 --> 00:39:33,759
experiments were running when I was

00:39:31,359 --> 00:39:35,259
creating these the slides so sorry about

00:39:33,759 --> 00:39:38,410
that

00:39:35,259 --> 00:39:40,660
and so in the lower axis I had the

00:39:38,410 --> 00:39:42,660
number of buffers in the bottleneck okay

00:39:40,660 --> 00:39:50,049
it starts to half

00:39:42,660 --> 00:39:50,980
vdp1 be DP - b DP for b DP a b DP that's

00:39:50,049 --> 00:39:56,770
how much buffering the

00:39:50,980 --> 00:39:59,950
on the bottleneck rather so let's see

00:39:56,770 --> 00:40:03,760
they all use the bandwidth very well in

00:39:59,950 --> 00:40:07,930
terms of retransmissions again bbr has a

00:40:03,760 --> 00:40:10,630
lot of the transmissions with a slower a

00:40:07,930 --> 00:40:14,020
fewer number of flows you know almost

00:40:10,630 --> 00:40:15,970
10% but when they answer with a number

00:40:14,020 --> 00:40:18,099
smaller number of buffers on the

00:40:15,970 --> 00:40:22,690
bottleneck but when when when we give it

00:40:18,099 --> 00:40:25,300
more buffers to 4 or 8 v DP then it does

00:40:22,690 --> 00:40:29,589
really well you know like brave few

00:40:25,300 --> 00:40:35,890
retransmissions okay so DVR in some ways

00:40:29,589 --> 00:40:38,740
needs more buffers more than - when we

00:40:35,890 --> 00:40:40,510
delay product to really do its best and

00:40:38,740 --> 00:40:41,890
in this case you know it's it's not

00:40:40,510 --> 00:40:46,030
worth meeting that much it's working

00:40:41,890 --> 00:40:48,130
really well I'm gonna skip the one

00:40:46,030 --> 00:40:50,710
megabyte numbers I'm going to focus on

00:40:48,130 --> 00:40:55,300
the 10 kilobytes and I'm gonna look at

00:40:50,710 --> 00:40:58,750
the good put and the 99% latency and you

00:40:55,300 --> 00:41:02,109
know VBR again for the smaller number of

00:40:58,750 --> 00:41:05,560
buffers it's hurting the the good put

00:41:02,109 --> 00:41:08,109
and the latency for the 10 kilo byte are

00:41:05,560 --> 00:41:10,480
pieces everybody else is doing better as

00:41:08,109 --> 00:41:14,770
we increase the number of buffers to 2 4

00:41:10,480 --> 00:41:19,329
and 8 BP bbr is doing better but still

00:41:14,770 --> 00:41:21,550
you know let's see the grouper is higher

00:41:19,329 --> 00:41:25,270
yeah so you're doing a lot better than

00:41:21,550 --> 00:41:28,650
than these guys when it has enough

00:41:25,270 --> 00:41:31,270
buffers it's performing quite well

00:41:28,650 --> 00:41:33,099
now let's see I'm doing okay so now

00:41:31,270 --> 00:41:35,349
rather than having one flaw per host I'm

00:41:33,099 --> 00:41:37,060
going to put three flows per host every

00:41:35,349 --> 00:41:39,460
host is doing one streaming when one

00:41:37,060 --> 00:41:42,280
megabyte and 1/10 kilobyte are pcs so we

00:41:39,460 --> 00:41:46,960
had three times the traffic so we have a

00:41:42,280 --> 00:41:48,849
lot more contention again for beacon

00:41:46,960 --> 00:41:50,740
yeah I don't have all the numbers those

00:41:48,849 --> 00:41:53,290
things were running up when I prepared

00:41:50,740 --> 00:41:56,319
this light this morning at 5 a.m. or

00:41:53,290 --> 00:41:59,800
area they all use the bandwidth the

00:41:56,319 --> 00:42:01,770
aggregate bandwidth very well so this is

00:41:59,800 --> 00:42:04,000
the link utilization and the

00:42:01,770 --> 00:42:04,930
retransmissions again you know baby art

00:42:04,000 --> 00:42:07,420
has to be high

00:42:04,930 --> 00:42:09,250
with the smaller buffer sizes but he

00:42:07,420 --> 00:42:11,940
decreases as you increase you give it

00:42:09,250 --> 00:42:17,800
more buffer size okay

00:42:11,940 --> 00:42:20,020
so BB r really needs bigger buffer sizes

00:42:17,800 --> 00:42:22,060
and taking into account that it was

00:42:20,020 --> 00:42:25,060
created initially I think one of the

00:42:22,060 --> 00:42:26,230
reason was to deal with buffer bloat you

00:42:25,060 --> 00:42:27,490
know it does really well with buffer

00:42:26,230 --> 00:42:35,470
block buffer blog we have a lot of

00:42:27,490 --> 00:42:38,890
buffering typically oh really okay okay

00:42:35,470 --> 00:42:40,720
so I initially thought that one of the

00:42:38,890 --> 00:42:46,120
reasons was - so buffer bloat

00:42:40,720 --> 00:42:51,970
Rikki's is okay to decrease packet

00:42:46,120 --> 00:42:54,340
losses we okay well PPO on the shell

00:42:51,970 --> 00:42:56,140
buffer is being actively working

00:42:54,340 --> 00:43:02,770
hopefully you know they have yes I

00:42:56,140 --> 00:43:05,500
understand okay okay so this is true

00:43:02,770 --> 00:43:10,630
flows overall this is true flows 10

00:43:05,500 --> 00:43:13,360
kilobyte good put let's see for small

00:43:10,630 --> 00:43:18,280
buffers only have cubic and VBR cubic

00:43:13,360 --> 00:43:25,450
that's better this earlier it mixed

00:43:18,280 --> 00:43:28,810
numbers you know so for this environment

00:43:25,450 --> 00:43:31,270
I mean look at the latest here that's

00:43:28,810 --> 00:43:32,440
what the ladies are the diamonds so we

00:43:31,270 --> 00:43:34,540
be are you doing well for this

00:43:32,440 --> 00:43:36,910
environment you know with more traffic

00:43:34,540 --> 00:43:41,410
is even better than we feared traffic

00:43:36,910 --> 00:43:44,350
and I think what happens is that it

00:43:41,410 --> 00:43:45,840
falls back to just cannot try to do

00:43:44,350 --> 00:43:48,340
congestion avoidance is just doing

00:43:45,840 --> 00:43:54,750
congestion control in some ways and it's

00:43:48,340 --> 00:43:59,980
actually performing better than it was

00:43:54,750 --> 00:44:03,490
with six flows per host for the overall

00:43:59,980 --> 00:44:05,500
they all you said well more or less and

00:44:03,490 --> 00:44:11,500
the transmissions are again higher for

00:44:05,500 --> 00:44:15,460
bbr and for the 10 kilobytes the good

00:44:11,500 --> 00:44:18,640
puts are lower for VBR the latencies are

00:44:15,460 --> 00:44:20,260
a little higher not too bad

00:44:18,640 --> 00:44:23,650
oh my god these are one second two

00:44:20,260 --> 00:44:25,349
seconds three seconds they're bad for

00:44:23,650 --> 00:44:28,329
everybody

00:44:25,349 --> 00:44:30,700
cause you know so outside of streaming

00:44:28,329 --> 00:44:41,380
case you don't see any of the bandwidth

00:44:30,700 --> 00:44:44,200
collapse for PPR right okay sorry it's

00:44:41,380 --> 00:44:46,569
obviously not as often as a 20% we saw

00:44:44,200 --> 00:44:48,640
with two flows for the eye scenario

00:44:46,569 --> 00:44:50,019
right I'm by the way that scenario is

00:44:48,640 --> 00:44:52,630
really bad because baby art needs

00:44:50,019 --> 00:44:56,890
buffering and the worst case that I saw

00:44:52,630 --> 00:45:04,150
you the 20% case was for ten gigabits

00:44:56,890 --> 00:45:05,980
per second and very like one tenth or

00:45:04,150 --> 00:45:07,720
one twentieth the bang with delay

00:45:05,980 --> 00:45:09,220
product of buffering right so that's

00:45:07,720 --> 00:45:12,130
like the worst case scenario for baby

00:45:09,220 --> 00:45:16,150
are in these last ones that I did the

00:45:12,130 --> 00:45:18,369
cueing was have one full bdb two four

00:45:16,150 --> 00:45:21,670
eight so it's a lot better for PBR in

00:45:18,369 --> 00:45:24,369
the dissing area so I didn't do the

00:45:21,670 --> 00:45:26,710
numbers to see there was collapse I'll

00:45:24,369 --> 00:45:28,210
go back and see if this if if one flow

00:45:26,710 --> 00:45:30,430
collapse or not in the distant areas it

00:45:28,210 --> 00:45:32,410
may not happen right and remember that

00:45:30,430 --> 00:45:34,839
bbr is being used and in their

00:45:32,410 --> 00:45:36,670
production numbers for google you know

00:45:34,839 --> 00:45:40,150
they're seeing good results so and

00:45:36,670 --> 00:45:41,920
they're more realistic Network

00:45:40,150 --> 00:45:43,869
conditions it seems to be performing

00:45:41,920 --> 00:45:48,609
well for them I think my one of my

00:45:43,869 --> 00:45:50,619
concerns is you know under some

00:45:48,609 --> 00:45:52,269
scenarios where there's high losses and

00:45:50,619 --> 00:45:54,970
BTL doesn't carry that's really well

00:45:52,269 --> 00:45:57,910
with lasses right it's one losses it may

00:45:54,970 --> 00:46:00,160
be hurting other type of flows like

00:45:57,910 --> 00:46:02,920
cubic and all that right and also I

00:46:00,160 --> 00:46:04,990
didn't cover here that's an area because

00:46:02,920 --> 00:46:07,299
out of time what happens when you have

00:46:04,990 --> 00:46:09,519
random losses not losses due to

00:46:07,299 --> 00:46:11,619
congestion maybe I would do really well

00:46:09,519 --> 00:46:13,720
on those are scenarios everybody else

00:46:11,619 --> 00:46:16,299
would suffer right so under those cases

00:46:13,720 --> 00:46:18,490
VB is ideal it will do really well but I

00:46:16,299 --> 00:46:22,440
didn't cover them because I currently

00:46:18,490 --> 00:46:22,440
run so many thousands of experiments

00:46:28,380 --> 00:46:32,740
that's right

00:46:29,740 --> 00:46:37,359
how do you simulate or email ad

00:46:32,740 --> 00:46:40,660
streaming by the net e/m I mean so if I

00:46:37,359 --> 00:46:43,810
see like a collapse right how do we know

00:46:40,660 --> 00:46:47,560
that this is not the streaming server

00:46:43,810 --> 00:46:49,750
actually collapse not the where's that

00:46:47,560 --> 00:46:52,480
the they're going they're going they're

00:46:49,750 --> 00:46:54,340
just going slowly right so I'm not sure

00:46:52,480 --> 00:46:57,150
I understand I mean so these are what

00:46:54,340 --> 00:47:00,280
the Saints are streaming actually really

00:46:57,150 --> 00:47:02,980
model the what do you call it like you

00:47:00,280 --> 00:47:04,510
know media downscale I'm using it for to

00:47:02,980 --> 00:47:07,359
do what like a streaming at birth right

00:47:04,510 --> 00:47:08,619
so from one so the same host in many of

00:47:07,359 --> 00:47:12,010
this experiment is running multiple

00:47:08,619 --> 00:47:14,320
flows one happens to be a streaming you

00:47:12,010 --> 00:47:17,140
know using that nerd perv and as using

00:47:14,320 --> 00:47:19,359
near Perth to do the you know request

00:47:17,140 --> 00:47:23,400
reply transfers of one megabyte or 10

00:47:19,359 --> 00:47:26,740
kilobytes and so for the streaming

00:47:23,400 --> 00:47:28,750
experiments where it collapse it was

00:47:26,740 --> 00:47:30,220
still going but the congestion window

00:47:28,750 --> 00:47:31,690
collapse right I mean I could see

00:47:30,220 --> 00:47:34,420
congestion window was all the way down

00:47:31,690 --> 00:47:36,369
so it was not that the process was

00:47:34,420 --> 00:47:39,970
blocked for something the congestion

00:47:36,369 --> 00:47:40,839
window TCP totally slow it down right

00:47:39,970 --> 00:47:45,040
okay got it

00:47:40,839 --> 00:47:47,560
yeah I mean I get the grass for I get

00:47:45,040 --> 00:47:51,300
like 10 grass per experiment I'll show

00:47:47,560 --> 00:47:54,760
you congestion windows rates are crates

00:47:51,300 --> 00:47:56,589
retransmits you know our titties Minard

00:47:54,760 --> 00:47:59,140
titties so when I see something strange

00:47:56,589 --> 00:48:05,070
I go there look at it and you know it

00:47:59,140 --> 00:48:05,070
show me there that any other questions

00:48:06,930 --> 00:48:10,990
even if you don't ask questions I'm not

00:48:09,160 --> 00:48:17,859
gonna let you go out and eat yet okay so

00:48:10,990 --> 00:48:19,720
you better ask I'm actually interested

00:48:17,859 --> 00:48:22,900
in the data center case so you said you

00:48:19,720 --> 00:48:26,530
use two cues and what kind of congestion

00:48:22,900 --> 00:48:31,060
what kind of yeah so for DC TCP you have

00:48:26,530 --> 00:48:33,339
to if you're gonna have cubic flows you

00:48:31,060 --> 00:48:35,320
know competing you need to separate them

00:48:33,339 --> 00:48:37,240
otherwise cubic will fail

00:48:35,320 --> 00:48:40,750
right I mean will do really poorly

00:48:37,240 --> 00:48:43,810
so one cue had is he an enable with you

00:48:40,750 --> 00:48:46,180
know with I think the we're using the

00:48:43,810 --> 00:48:52,690
same threshold like high and low around

00:48:46,180 --> 00:48:54,970
I think 80 kilobytes to mark this en and

00:48:52,690 --> 00:48:57,490
then for him be I'm not doing any

00:48:54,970 --> 00:49:02,290
marking is just to segregate and be from

00:48:57,490 --> 00:49:04,360
pubic to to protect and be from cubic so

00:49:02,290 --> 00:49:06,430
there is something which is called f-4s

00:49:04,360 --> 00:49:09,670
where you also have like two separate

00:49:06,430 --> 00:49:11,920
cues but you couple the AKM that is used

00:49:09,670 --> 00:49:13,510
on both cues so you can actually be more

00:49:11,920 --> 00:49:15,070
fair depending on the number of flows

00:49:13,510 --> 00:49:17,290
you have so it will adapt automatically

00:49:15,070 --> 00:49:19,570
yeah that the top associate we have do

00:49:17,290 --> 00:49:21,940
not connect do not know the number of

00:49:19,570 --> 00:49:23,890
flows so there yeah that would be good

00:49:21,940 --> 00:49:25,750
but then what would happen is that

00:49:23,890 --> 00:49:27,430
people would say like oh right in the

00:49:25,750 --> 00:49:29,980
running one big flow I'm gonna run 50

00:49:27,430 --> 00:49:37,870
some other flows right so I get more

00:49:29,980 --> 00:49:40,570
bandwidth but yeah but thank you is your

00:49:37,870 --> 00:49:42,760
TCP BPF congestion when you're clamping

00:49:40,570 --> 00:49:47,980
is that functionally equivalent to

00:49:42,760 --> 00:49:50,590
putting a clamp in the route yes it is

00:49:47,980 --> 00:49:53,280
the same it's only just a mechanism that

00:49:50,590 --> 00:49:59,560
it's easier I think for us to deploy

00:49:53,280 --> 00:50:01,630
because you know yeah so anyway you want

00:49:59,560 --> 00:50:04,180
to clamp it we have and most of the

00:50:01,630 --> 00:50:05,980
gains of TCP vpf you know I mean it

00:50:04,180 --> 00:50:08,290
decreases the scene RTO so there are

00:50:05,980 --> 00:50:10,930
losses for the scene it will recover

00:50:08,290 --> 00:50:12,430
very quickly and it also decreases the

00:50:10,930 --> 00:50:17,110
buffer sizes so that you don't waste

00:50:12,430 --> 00:50:18,610
space you know but yeah the main games

00:50:17,110 --> 00:50:25,660
are reflected in these experiments you

00:50:18,610 --> 00:50:27,730
do to the clamping correct so in the

00:50:25,660 --> 00:50:30,040
test implementation that I show here is

00:50:27,730 --> 00:50:33,070
done initially it looks at the IP

00:50:30,040 --> 00:50:35,710
addresses and you know we have a period

00:50:33,070 --> 00:50:37,450
v6 addresses that encode some

00:50:35,710 --> 00:50:41,200
geographical information in terms of

00:50:37,450 --> 00:50:43,810
data center cluster region etc and we

00:50:41,200 --> 00:50:46,060
can use those two to decide what would

00:50:43,810 --> 00:50:47,200
be the right clamp you know I know how

00:50:46,060 --> 00:50:50,110
far away we are

00:50:47,200 --> 00:50:53,050
I see so it's not a function of

00:50:50,110 --> 00:50:54,940
flows it's just you know no it would be

00:50:53,050 --> 00:50:57,940
very hard to do it right because I got

00:50:54,940 --> 00:50:59,770
congestion it's a switch that is going

00:50:57,940 --> 00:51:01,480
through many different holes are going

00:50:59,770 --> 00:51:03,580
through it there's really no good way

00:51:01,480 --> 00:51:05,920
for you to know how many flows are are

00:51:03,580 --> 00:51:07,090
competing right and if you knew you do

00:51:05,920 --> 00:51:12,520
not know that all of them are actually

00:51:07,090 --> 00:51:13,930
active at that time so correctly that's

00:51:12,520 --> 00:51:16,330
why I you know like we try to do things

00:51:13,930 --> 00:51:17,980
like NV and BB are they are more

00:51:16,330 --> 00:51:20,830
dynamically trying to tow for example

00:51:17,980 --> 00:51:22,330
for this scenario and B is reducing the

00:51:20,830 --> 00:51:24,910
congestion window in some cases you know

00:51:22,330 --> 00:51:28,360
to 20 or 10 packets right because it's

00:51:24,910 --> 00:51:29,980
seen that Kentuckian so it's actually it

00:51:28,360 --> 00:51:36,460
works well to reduce it on the die

00:51:29,980 --> 00:51:38,320
environment talking more than any

00:51:36,460 --> 00:51:40,330
illusion we don't know the congestion

00:51:38,320 --> 00:51:42,790
control is very dynamic and T should be

00:51:40,330 --> 00:51:44,950
all gerson right yeah I remember there

00:51:42,790 --> 00:51:47,590
was a facebook paper a few years back

00:51:44,950 --> 00:51:52,870
yes trying to schedule packet by packet

00:51:47,590 --> 00:51:55,300
right how does that go I haven't tested

00:51:52,870 --> 00:51:57,150
it you know they run some experiments it

00:51:55,300 --> 00:52:00,340
seemed to work

00:51:57,150 --> 00:52:06,310
so okay you guys are not deploying it is

00:52:00,340 --> 00:52:07,480
not deployed you know so it was it was

00:52:06,310 --> 00:52:08,770
an academic you know and we were

00:52:07,480 --> 00:52:11,170
interested to see how far it could be

00:52:08,770 --> 00:52:17,290
done but it was not an academic 18

00:52:11,170 --> 00:52:20,160
project but I wasn't involved on that so

00:52:17,290 --> 00:52:24,430
you know I'm the wrong person to ask

00:52:20,160 --> 00:52:26,410
okay okay I guess you guys are hungry so

00:52:24,430 --> 00:52:29,920
thank you

00:52:26,410 --> 00:52:29,920

YouTube URL: https://www.youtube.com/watch?v=5iC7j7G8wsw


