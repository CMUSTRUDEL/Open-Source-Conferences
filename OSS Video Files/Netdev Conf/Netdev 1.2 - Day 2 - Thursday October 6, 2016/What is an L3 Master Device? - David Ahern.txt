Title: What is an L3 Master Device? - David Ahern
Publication date: 2016-10-07
Playlist: Netdev 1.2 - Day 2 - Thursday October 6, 2016
Description: 
	http://netdevconf.org/1.2/session.html?david-ahern-talk
Captions: 
	00:00:09,530 --> 00:00:15,849
Aherne and I work for cumulus and want

00:00:14,269 --> 00:00:17,660
to talk about the ultra master device

00:00:15,849 --> 00:00:20,509
implementation that was put into the

00:00:17,660 --> 00:00:23,779
kernel it's something that was accepted

00:00:20,509 --> 00:00:26,000
into the for that core kernel as a way

00:00:23,779 --> 00:00:29,689
of generalizing changes that we had put

00:00:26,000 --> 00:00:31,279
in for VR apps it is a standalone API it

00:00:29,689 --> 00:00:34,700
is something that can be leveraged by

00:00:31,279 --> 00:00:36,559
other l-3 drivers such as the IP VLAN

00:00:34,700 --> 00:00:41,839
recently started using the receive hook

00:00:36,559 --> 00:00:45,170
on it in terms of its overall objective

00:00:41,839 --> 00:00:46,730
of the intent is for it to influence fib

00:00:45,170 --> 00:00:48,829
lookups which is one of the primary

00:00:46,730 --> 00:00:52,449
things for layer 3 and then give you

00:00:48,829 --> 00:00:52,449
access to packets at layer 3

00:00:52,780 --> 00:00:59,420
implementation wise there is a kernel

00:00:55,819 --> 00:01:01,039
configure a merc if that config option

00:00:59,420 --> 00:01:03,409
is disabled it completely compiles out

00:01:01,039 --> 00:01:06,110
but you have to have it enabled if you

00:01:03,409 --> 00:01:12,260
want to see the vrf driver or now the IP

00:01:06,110 --> 00:01:14,719
deal and driver so I said the primary

00:01:12,260 --> 00:01:17,659
motivation behind the l3 master device

00:01:14,719 --> 00:01:20,780
is for VR apps and for VR app the intent

00:01:17,659 --> 00:01:23,299
is to create l3 domains and then the the

00:01:20,780 --> 00:01:25,520
idea here is that you have a domain that

00:01:23,299 --> 00:01:27,229
goes with the table so packets that are

00:01:25,520 --> 00:01:29,360
flowing through that domain would

00:01:27,229 --> 00:01:34,009
reference that fib table for route

00:01:29,360 --> 00:01:38,479
lookups or source addressing or source

00:01:34,009 --> 00:01:40,369
validation operationally it's a model

00:01:38,479 --> 00:01:43,030
the models kind of following the

00:01:40,369 --> 00:01:46,189
bridging from the standpoint of

00:01:43,030 --> 00:01:48,259
associating an interface to an l-3

00:01:46,189 --> 00:01:51,799
domain you're going to enslave that

00:01:48,259 --> 00:01:55,070
interface to an l 3m dev an LT master

00:01:51,799 --> 00:01:57,140
device so like in the case of vrf you

00:01:55,070 --> 00:02:00,229
associate say three front panel ports

00:01:57,140 --> 00:02:02,329
and slave them to that VR app as packets

00:02:00,229 --> 00:02:03,740
come in through that bad verse through

00:02:02,329 --> 00:02:06,320
those interfaces in that verb that goes

00:02:03,740 --> 00:02:09,200
to the table associated with it and then

00:02:06,320 --> 00:02:11,180
as packets are going out bgp for example

00:02:09,200 --> 00:02:13,580
sending outbound packets it has a socket

00:02:11,180 --> 00:02:17,360
bound to the master device so that tells

00:02:13,580 --> 00:02:19,459
the lookup to go to that fib table one

00:02:17,360 --> 00:02:20,490
of the key points of the l3m dev

00:02:19,459 --> 00:02:22,620
framework is

00:02:20,490 --> 00:02:25,830
that it only impacts layer three

00:02:22,620 --> 00:02:28,800
decisions address resolution or address

00:02:25,830 --> 00:02:30,660
selection or route lookups so if you've

00:02:28,800 --> 00:02:32,730
got LLDPE running on those same

00:02:30,660 --> 00:02:35,010
interfaces it doesn't have any impact

00:02:32,730 --> 00:02:36,060
lldp will still see the interfaces and

00:02:35,010 --> 00:02:37,860
it will still be able to send and

00:02:36,060 --> 00:02:42,450
receive packets over it without any

00:02:37,860 --> 00:02:45,360
impact to them so albury domain as a net

00:02:42,450 --> 00:02:48,360
device kind of like in in the UNIX world

00:02:45,360 --> 00:02:50,280
everything is pile descriptor when it

00:02:48,360 --> 00:02:52,470
comes to networking constructs and then

00:02:50,280 --> 00:02:54,660
that device is a core construct so many

00:02:52,470 --> 00:02:58,680
things are anchored off of it from

00:02:54,660 --> 00:03:01,800
cutest TC filters net filter rules fib

00:02:58,680 --> 00:03:03,900
rules all these things leverage the fact

00:03:01,800 --> 00:03:06,270
you know are based on rather the the

00:03:03,900 --> 00:03:08,850
presence of a network device and that

00:03:06,270 --> 00:03:11,670
device structure and we even have this

00:03:08,850 --> 00:03:13,740
this ability with creating a net device

00:03:11,670 --> 00:03:17,640
for an l-3 domain now we have a place to

00:03:13,740 --> 00:03:19,200
anchor l3 domain local loopback

00:03:17,640 --> 00:03:21,630
addresses which are something that's

00:03:19,200 --> 00:03:27,660
very important for l3 routing protocols

00:03:21,630 --> 00:03:28,950
I also by using the net device construct

00:03:27,660 --> 00:03:31,440
we can elaborate we can leverage a lot

00:03:28,950 --> 00:03:33,450
of the existing code paths in the kernel

00:03:31,440 --> 00:03:37,200
so for example fib rules that are based

00:03:33,450 --> 00:03:39,240
on Alya for iya socket API is using

00:03:37,200 --> 00:03:41,790
socket binder device so an application

00:03:39,240 --> 00:03:45,450
can specify which domain is of interest

00:03:41,790 --> 00:03:47,880
to it and then the operational semantics

00:03:45,450 --> 00:03:50,850
so when you create a vrf device or an l3

00:03:47,880 --> 00:03:52,980
mem dev device you get no net def

00:03:50,850 --> 00:03:55,590
notifiers going through the kernel you

00:03:52,980 --> 00:03:57,840
get notifications to user space when it

00:03:55,590 --> 00:04:00,840
gets deleted and created or created

00:03:57,840 --> 00:04:04,110
deleted when you want to monitor what's

00:04:00,840 --> 00:04:05,880
going on the existing IP link show

00:04:04,110 --> 00:04:08,820
commands will now list out healthy

00:04:05,880 --> 00:04:11,280
domains as well so from an operational

00:04:08,820 --> 00:04:12,780
perspective the user doesn't have to go

00:04:11,280 --> 00:04:14,130
learn any kind of new semantics

00:04:12,780 --> 00:04:15,210
everything you've done for bridging

00:04:14,130 --> 00:04:17,910
everything you've done for existing

00:04:15,210 --> 00:04:20,150
interfaces now just works for l3 domains

00:04:17,910 --> 00:04:20,150
as well

00:04:21,340 --> 00:04:27,250
like I said the the primary motivation

00:04:23,950 --> 00:04:30,669
here is fib tables and one of the

00:04:27,250 --> 00:04:32,620
operations is this l3m dev fib table to

00:04:30,669 --> 00:04:35,590
return the table ID associated with that

00:04:32,620 --> 00:04:39,669
l3m dev device it's called in the fact

00:04:35,590 --> 00:04:42,550
fast app and it really since this table

00:04:39,669 --> 00:04:44,290
ID is local to a device you have to call

00:04:42,550 --> 00:04:46,180
an operation to do it so you really want

00:04:44,290 --> 00:04:51,070
to store that in private data on the

00:04:46,180 --> 00:04:53,050
device route why's the the fib table

00:04:51,070 --> 00:04:55,360
that's associated with that l3m dev is

00:04:53,050 --> 00:04:57,430
expected to contain all the routes so

00:04:55,360 --> 00:04:59,560
host routes local routes unique after

00:04:57,430 --> 00:05:01,570
all it's broadcast routes all of it are

00:04:59,560 --> 00:05:05,200
going to be in that table that you've

00:05:01,570 --> 00:05:06,880
identified with the l 3m duck and then

00:05:05,200 --> 00:05:09,310
the host in connected routes are moved

00:05:06,880 --> 00:05:12,820
to that table when the link is brought

00:05:09,310 --> 00:05:14,470
up and of course the additional routes

00:05:12,820 --> 00:05:18,130
can be added to any way any one of those

00:05:14,470 --> 00:05:20,229
fib tables using BGP or statically

00:05:18,130 --> 00:05:22,150
adding routes you put them into that fib

00:05:20,229 --> 00:05:26,919
table and become part of that L 3

00:05:22,150 --> 00:05:31,479
domains lookup again from a policy

00:05:26,919 --> 00:05:33,820
routing perspective by using the in L 3

00:05:31,479 --> 00:05:36,850
master device you can set up the fib

00:05:33,820 --> 00:05:39,310
rules either per device or using an L 3

00:05:36,850 --> 00:05:40,930
M dev rule which is the target of that

00:05:39,310 --> 00:05:42,729
rule is to address the scalability

00:05:40,930 --> 00:05:45,610
issues of having to have multiple rules

00:05:42,729 --> 00:05:48,340
per device with the L 3 in dev rule

00:05:45,610 --> 00:05:51,039
you've got one rule that works for

00:05:48,340 --> 00:05:53,260
everything for all L 3 M dubs and then

00:05:51,039 --> 00:05:56,620
when you hit the hit a match it'll go

00:05:53,260 --> 00:05:58,720
look up it'll use that that fib table

00:05:56,620 --> 00:06:01,479
operation to go look up that of the

00:05:58,720 --> 00:06:03,220
table for that specific device and then

00:06:01,479 --> 00:06:05,650
direct to look up to that table so

00:06:03,220 --> 00:06:09,750
that's been a big help from scalability

00:06:05,650 --> 00:06:12,789
aspects of it and then as a part of

00:06:09,750 --> 00:06:14,860
getting that match to work you know the

00:06:12,789 --> 00:06:16,570
floor strut gets set up through the

00:06:14,860 --> 00:06:19,810
different parts of the the networking

00:06:16,570 --> 00:06:22,810
stack and we have to flip the OIF for

00:06:19,810 --> 00:06:25,060
the iaf from by the ingress device or

00:06:22,810 --> 00:06:27,370
the socket that's been bound to a device

00:06:25,060 --> 00:06:29,380
have to flip that over to the l3 in dev

00:06:27,370 --> 00:06:30,970
right before the lookup so that it can

00:06:29,380 --> 00:06:34,129
hit the fill rule so they can go to the

00:06:30,970 --> 00:06:36,739
table associated with that device so

00:06:34,129 --> 00:06:38,899
some of the the api's that have been put

00:06:36,739 --> 00:06:40,309
in the upper um dev api's that have been

00:06:38,899 --> 00:06:43,279
put in for a fulfilled work out

00:06:40,309 --> 00:06:47,239
perspective from a network address

00:06:43,279 --> 00:06:49,580
perspective only devices within that l3

00:06:47,239 --> 00:06:51,529
domain are considered when you're doing

00:06:49,580 --> 00:06:54,080
address selection so when you do the

00:06:51,529 --> 00:06:56,179
route lookup if the device itself has an

00:06:54,080 --> 00:06:58,699
address that's the preferred one next

00:06:56,179 --> 00:07:00,139
we'll look at the l3m dub itself to say

00:06:58,699 --> 00:07:01,879
if it has an address so I'm going to

00:07:00,139 --> 00:07:03,649
prefer that and then I'll start looking

00:07:01,879 --> 00:07:10,039
at other interfaces that have been

00:07:03,649 --> 00:07:12,769
associated with the l3m dub the kernel

00:07:10,039 --> 00:07:15,199
does not put link local addresses on an

00:07:12,769 --> 00:07:17,779
l3m dev device and it does not insert

00:07:15,199 --> 00:07:21,289
multicast routes for those it's not

00:07:17,779 --> 00:07:24,199
expected to work and in fact the vrf

00:07:21,289 --> 00:07:27,439
driver will specifically fail any time

00:07:24,199 --> 00:07:29,689
any kind of look up for a link local or

00:07:27,439 --> 00:07:31,490
multicast address because the the

00:07:29,689 --> 00:07:34,159
operational semantics get kind of weird

00:07:31,490 --> 00:07:36,709
so we just shut it down and only do link

00:07:34,159 --> 00:07:38,419
local addresses I mean yeah I link local

00:07:36,709 --> 00:07:43,669
and multicast addresses on the enslaved

00:07:38,419 --> 00:07:46,129
devices themselves so user space API

00:07:43,669 --> 00:07:50,360
again because we've used this net device

00:07:46,129 --> 00:07:53,329
construct we have existing POSIX API is

00:07:50,360 --> 00:07:55,879
like the Esso binder device and the C

00:07:53,329 --> 00:07:58,339
message with IP packet info as a way for

00:07:55,879 --> 00:07:59,689
an application to specify what domain is

00:07:58,339 --> 00:08:02,659
of interest to it when it's sending a

00:07:59,689 --> 00:08:04,189
packet and those that those api's

00:08:02,659 --> 00:08:06,919
provide ability for an application

00:08:04,189 --> 00:08:10,159
determine which l3 domain it's a member

00:08:06,919 --> 00:08:14,300
of so for example if you've got a global

00:08:10,159 --> 00:08:17,179
TCP server and it has a child socket

00:08:14,300 --> 00:08:18,619
which this sis control allows it has a

00:08:17,179 --> 00:08:20,809
child socket that gets bound to a

00:08:18,619 --> 00:08:23,419
specific domain it can do it gets a

00:08:20,809 --> 00:08:25,909
copped on that FD to see which domain

00:08:23,419 --> 00:08:27,499
that packet of that sockets tied to so

00:08:25,909 --> 00:08:30,079
know which domain is talking in and out

00:08:27,499 --> 00:08:32,060
of or it can use IP packet info to

00:08:30,079 --> 00:08:34,610
retrieve that for UDP and raw sockets

00:08:32,060 --> 00:08:36,709
and for those cases it's the original

00:08:34,610 --> 00:08:42,919
ingress device they get saved and passed

00:08:36,709 --> 00:08:45,920
to to the application so another aspect

00:08:42,919 --> 00:08:46,580
that l3 indep provides is the ability to

00:08:45,920 --> 00:08:49,850
hook packet

00:08:46,580 --> 00:08:52,820
at l3 so this is happening after some of

00:08:49,850 --> 00:08:56,480
the protocol verifications so ipv4 ipv6

00:08:52,820 --> 00:08:58,460
can do basic validation on the skb that

00:08:56,480 --> 00:09:02,390
says the app the headers fine checksum

00:08:58,460 --> 00:09:06,590
fine etc and then it can be handed off

00:09:02,390 --> 00:09:08,690
to an l-3 in dev driver if they've

00:09:06,590 --> 00:09:12,020
registered the receive hook for it and

00:09:08,690 --> 00:09:16,130
this gives the driver a chance to do

00:09:12,020 --> 00:09:17,990
something to the packet for example it

00:09:16,130 --> 00:09:20,210
could set the DST it can run it through

00:09:17,990 --> 00:09:22,100
met filter hooks it can do whatever it

00:09:20,210 --> 00:09:24,770
wants to do for layer 3 features and

00:09:22,100 --> 00:09:27,950
then it returns and the desk the input

00:09:24,770 --> 00:09:31,580
is invoked the handler for the DST input

00:09:27,950 --> 00:09:34,340
handler is invoked if the if the l3m dev

00:09:31,580 --> 00:09:36,770
receive function returns null then the

00:09:34,340 --> 00:09:38,390
stack assumes that that handler consumed

00:09:36,770 --> 00:09:41,720
the packet and no more processing is

00:09:38,390 --> 00:09:45,500
done on it so to look at the vrf driver

00:09:41,720 --> 00:09:48,560
as an example of what can be done inside

00:09:45,500 --> 00:09:52,100
the receive hook the verb driver uses

00:09:48,560 --> 00:09:54,310
this as a way to flip the skb dev to the

00:09:52,100 --> 00:09:57,170
verb device and that's needed because

00:09:54,310 --> 00:09:59,810
sockets are expected to be bound to the

00:09:57,170 --> 00:10:02,870
the verb device so then we got to make

00:09:59,810 --> 00:10:05,390
sure the skb dev and the SQ vif is set

00:10:02,870 --> 00:10:08,150
to that worth device so that you get the

00:10:05,390 --> 00:10:11,090
socket match and then it runs it through

00:10:08,150 --> 00:10:14,060
the packet gets run through the network

00:10:11,090 --> 00:10:17,000
taps so if you're running TCP dump on on

00:10:14,060 --> 00:10:19,100
a earth device for example you get to

00:10:17,000 --> 00:10:21,500
see packets flowing through any of the

00:10:19,100 --> 00:10:26,270
by any interfaces in slave to the

00:10:21,500 --> 00:10:27,890
perfect device for link ipv6 link

00:10:26,270 --> 00:10:30,050
addresses i mentioned that you know the

00:10:27,890 --> 00:10:33,560
v RF driver specifically shuts down

00:10:30,050 --> 00:10:36,470
lookups on that device itself and it

00:10:33,560 --> 00:10:39,110
also has some special handling is needed

00:10:36,470 --> 00:10:40,790
because you can't flip the o io for high

00:10:39,110 --> 00:10:43,070
F in the flow struct you have to

00:10:40,790 --> 00:10:44,810
actually go to that table because the

00:10:43,070 --> 00:10:47,440
the device that you're looking at is

00:10:44,810 --> 00:10:50,810
very important in terms of resolving

00:10:47,440 --> 00:10:53,390
resolving the route and then lastly it's

00:10:50,810 --> 00:10:55,670
the packets run through a net filter

00:10:53,390 --> 00:10:57,470
hook right now it's just the I think

00:10:55,670 --> 00:11:00,350
it's pre pre routing hook is only one

00:10:57,470 --> 00:11:03,110
done it can easily add other netfilter

00:11:00,350 --> 00:11:05,630
hooks as as interest as people have

00:11:03,110 --> 00:11:07,490
interests for now we're not using rules

00:11:05,630 --> 00:11:11,780
on these hooks but it is something that

00:11:07,490 --> 00:11:14,600
can be done from the driver and then

00:11:11,780 --> 00:11:16,220
similarly on the TX path there is a hook

00:11:14,600 --> 00:11:20,200
that allows you to get access to that

00:11:16,220 --> 00:11:23,960
packet as it's going down the stack and

00:11:20,200 --> 00:11:27,880
the the hook here is called from the NFL

00:11:23,960 --> 00:11:30,200
from the IP IP six local out functions

00:11:27,880 --> 00:11:33,290
before it's gone through the NF hook

00:11:30,200 --> 00:11:36,650
which calls DST output as its output

00:11:33,290 --> 00:11:38,510
handler or okay function I should say so

00:11:36,650 --> 00:11:40,880
this gives the the drivers an

00:11:38,510 --> 00:11:43,280
opportunity to do something with the

00:11:40,880 --> 00:11:45,260
packet again and just like with the

00:11:43,280 --> 00:11:47,300
receive path if you reach her null the

00:11:45,260 --> 00:11:51,530
packets dropped and no more processing

00:11:47,300 --> 00:11:54,200
is done on it as an example of what a

00:11:51,530 --> 00:11:57,110
driver can do in their output function

00:11:54,200 --> 00:12:00,650
the vrf driver uses this as a way to set

00:11:57,110 --> 00:12:02,900
the DST on the sk b to its cache DST

00:12:00,650 --> 00:12:03,980
which means its output function is going

00:12:02,900 --> 00:12:06,470
to send it right back to the verse

00:12:03,980 --> 00:12:09,140
driver so he gets to go down the stack a

00:12:06,470 --> 00:12:11,270
little bit hits the DST output kicks

00:12:09,140 --> 00:12:13,700
back over to the berth driver for it to

00:12:11,270 --> 00:12:16,700
implement device based features for

00:12:13,700 --> 00:12:19,490
example if someone's put acutest on the

00:12:16,700 --> 00:12:22,460
divert device or any kind of filtering

00:12:19,490 --> 00:12:24,710
rules net filter rules etc and the same

00:12:22,460 --> 00:12:27,290
with the network taps it goes down the

00:12:24,710 --> 00:12:28,700
stack inside the verse driver hits all

00:12:27,290 --> 00:12:31,610
these packet or hits all these device

00:12:28,700 --> 00:12:35,030
based features and then jumps back or

00:12:31,610 --> 00:12:36,890
resets the DST and then injects the

00:12:35,030 --> 00:12:38,780
packet back into the stack so you can go

00:12:36,890 --> 00:12:42,620
out the door like it was intended the

00:12:38,780 --> 00:12:48,070
original code path but really this is a

00:12:42,620 --> 00:12:50,030
via device specific goal of having

00:12:48,070 --> 00:12:55,220
device based features that can be

00:12:50,030 --> 00:12:56,780
applied to the l3 domain as a whole so a

00:12:55,220 --> 00:12:59,540
summary of the operations

00:12:56,780 --> 00:13:01,280
there's the l3 in dev fib table which is

00:12:59,540 --> 00:13:04,370
responsible for returning the table ID

00:13:01,280 --> 00:13:06,920
associated with that device the receive

00:13:04,370 --> 00:13:09,040
and the output hooks so you get access

00:13:06,920 --> 00:13:10,570
to the packet in the output and receive

00:13:09,040 --> 00:13:13,600
the end guard

00:13:10,570 --> 00:13:17,590
and egress paths and then handling ipv6

00:13:13,600 --> 00:13:19,300
link scope addresses from Flags

00:13:17,590 --> 00:13:22,900
perspective we are trying to be you know

00:13:19,300 --> 00:13:23,920
cognizant obviously performance and we

00:13:22,900 --> 00:13:26,500
use these flags

00:13:23,920 --> 00:13:29,530
so master devices have the Al 3m dev

00:13:26,500 --> 00:13:32,470
master flag set slave and slave devices

00:13:29,530 --> 00:13:34,660
have the l 3m dev slave flag set and we

00:13:32,470 --> 00:13:36,880
use these flags as a way to kind of

00:13:34,660 --> 00:13:39,550
quickly determine is the ernie of the l

00:13:36,880 --> 00:13:41,290
3m deaf folks that are trying to reset

00:13:39,550 --> 00:13:45,040
the flow struct or to redirect the

00:13:41,290 --> 00:13:51,310
packets is that particular path relevant

00:13:45,040 --> 00:13:54,160
for this device from an overhead

00:13:51,310 --> 00:13:56,800
perspective like i said before if this

00:13:54,160 --> 00:13:58,720
kernel config is not enabled the l 3m

00:13:56,800 --> 00:14:01,390
def code completely compiles out so

00:13:58,720 --> 00:14:02,380
there's no impact on performance when it

00:14:01,390 --> 00:14:05,970
is enabled

00:14:02,380 --> 00:14:08,050
i have tried to be you know very

00:14:05,970 --> 00:14:11,440
sensitive to any kind of performance

00:14:08,050 --> 00:14:14,620
overhead so structuring the lookups so

00:14:11,440 --> 00:14:17,530
that most likely pass or hit first using

00:14:14,620 --> 00:14:21,520
the flag checks as often as possible but

00:14:17,530 --> 00:14:23,770
the l 3m dev by definition means we do

00:14:21,520 --> 00:14:26,640
have some extra device lookups we do

00:14:23,770 --> 00:14:29,290
have those five checks we do have the

00:14:26,640 --> 00:14:31,360
retrieving if it's an enslaved device

00:14:29,290 --> 00:14:33,400
that's being operated on or being looked

00:14:31,360 --> 00:14:35,800
at in the packet then you have to go

00:14:33,400 --> 00:14:38,050
pull the master device from it and then

00:14:35,800 --> 00:14:42,670
any kind of driver operation for that

00:14:38,050 --> 00:14:45,460
device so there is a bit of overhead but

00:14:42,670 --> 00:14:46,960
we have to have tried to keep that to as

00:14:45,460 --> 00:14:49,960
admitted to it as none of them as

00:14:46,960 --> 00:14:51,190
possible and then of course with the

00:14:49,960 --> 00:14:53,830
verve driver i showed you a lot of

00:14:51,190 --> 00:14:56,290
processing that that driver is doing on

00:14:53,830 --> 00:14:58,540
packets so certainly the overall

00:14:56,290 --> 00:15:02,400
performance impact is dictated by what

00:14:58,540 --> 00:15:06,160
the all 3m debt driver is doing itself

00:15:02,400 --> 00:15:09,490
so to give you an idea of what kind of

00:15:06,160 --> 00:15:11,740
overhead we're talking about tcp our r2

00:15:09,490 --> 00:15:14,080
request response packets with one byte

00:15:11,740 --> 00:15:16,060
payloads is what really stresses that

00:15:14,080 --> 00:15:17,650
lookup path because you're the idea is

00:15:16,060 --> 00:15:19,300
to go as fast as possible in and out of

00:15:17,650 --> 00:15:20,980
the stack you're not worried about mem

00:15:19,300 --> 00:15:22,880
copies or any kind of big payload that

00:15:20,980 --> 00:15:25,730
you're dealing with so we're

00:15:22,880 --> 00:15:28,220
stressing the FIB lookups and and the

00:15:25,730 --> 00:15:30,440
the network processing path of that so I

00:15:28,220 --> 00:15:33,340
looked at three cases the the baseline

00:15:30,440 --> 00:15:36,680
is l3m doubt completely compiled out

00:15:33,340 --> 00:15:39,170
next up would be the kernel config is

00:15:36,680 --> 00:15:41,720
enabled but nothing's being used so

00:15:39,170 --> 00:15:44,180
we've added the hooks but we're not

00:15:41,720 --> 00:15:46,730
using the hooks and then the last one is

00:15:44,180 --> 00:15:48,740
the l3m Devi's compiled in and we're

00:15:46,730 --> 00:15:50,330
going to configure a vrf so that we're

00:15:48,740 --> 00:15:54,380
actually activating these lookups the

00:15:50,330 --> 00:15:58,120
lookups are you know returning a master

00:15:54,380 --> 00:16:02,600
device flipping the OIF flipping over to

00:15:58,120 --> 00:16:04,610
the l3m dev driver itself but I don't

00:16:02,600 --> 00:16:08,120
want what's being done in the berth

00:16:04,610 --> 00:16:10,940
module to prejudice the overall health

00:16:08,120 --> 00:16:13,340
really P I itself so I went into the

00:16:10,940 --> 00:16:14,990
roof module and I took out all the draw

00:16:13,340 --> 00:16:18,170
all the processing that it does in the

00:16:14,990 --> 00:16:21,140
Rx and TX paths and just kept the fib

00:16:18,170 --> 00:16:23,570
lookup influenced since that's what kind

00:16:21,140 --> 00:16:25,250
of dominates that the intent of the l3m

00:16:23,570 --> 00:16:28,040
dev api and what I'm looking at here

00:16:25,250 --> 00:16:29,210
from a performance perspective so that's

00:16:28,040 --> 00:16:30,590
important when you look at the

00:16:29,210 --> 00:16:32,720
performance results because if you

00:16:30,590 --> 00:16:34,550
actually use the full of our capability

00:16:32,720 --> 00:16:40,880
the performance hit is a little bit

00:16:34,550 --> 00:16:43,490
higher so using l3m def compiled out as

00:16:40,880 --> 00:16:48,170
the baseline and then looking at

00:16:43,490 --> 00:16:50,390
relative to that compiling it in and

00:16:48,170 --> 00:16:56,270
then activating it compiling it in

00:16:50,390 --> 00:16:59,030
there's about 0.75 for ipv6 0.664 IBB 4

00:16:56,270 --> 00:17:03,740
so there's a small impact to performance

00:16:59,030 --> 00:17:05,240
just enabling the the kernel config but

00:17:03,740 --> 00:17:05,900
then when you start activating those

00:17:05,240 --> 00:17:08,839
lookups

00:17:05,900 --> 00:17:11,540
so the OIF of AF is actually an

00:17:08,839 --> 00:17:13,610
uninsulated device or is actually an l3

00:17:11,540 --> 00:17:17,260
master device that performance hit

00:17:13,610 --> 00:17:20,980
climbs to about 1.7 to 2.0 percent which

00:17:17,260 --> 00:17:24,380
fairly small overall but there is a

00:17:20,980 --> 00:17:29,800
noticeable impact with you know

00:17:24,380 --> 00:17:29,800
activating these hooks yep

00:17:33,230 --> 00:17:37,850
I just want to clarify this one we're

00:17:36,200 --> 00:17:40,010
looking at these numbers so you said

00:17:37,850 --> 00:17:44,000
that there's your testing to fit look up

00:17:40,010 --> 00:17:45,529
is the TCP request response benchmark

00:17:44,000 --> 00:17:52,159
making a new connection every request

00:17:45,529 --> 00:17:53,419
response no before their router is

00:17:52,159 --> 00:17:55,880
cached in the socket and you're not

00:17:53,419 --> 00:17:56,889
testing lookups at all yes that's a very

00:17:55,880 --> 00:18:00,350
good point

00:17:56,889 --> 00:18:02,269
first instead is the packet blasts a UDP

00:18:00,350 --> 00:18:03,350
unconnected socket out to a dummy device

00:18:02,269 --> 00:18:05,120
or something like yeah is that

00:18:03,350 --> 00:18:07,399
guarantees that there's right look up

00:18:05,120 --> 00:18:08,929
every single so it wouldn't hit it it

00:18:07,399 --> 00:18:11,269
does hit it I'm going through the vrf

00:18:08,929 --> 00:18:13,700
device Pat I understand the TX path yes

00:18:11,269 --> 00:18:17,899
the TX path that is gonna get hit right

00:18:13,700 --> 00:18:20,059
no there's a shock to the yes the the VF

00:18:17,899 --> 00:18:22,639
device path that before dest output will

00:18:20,059 --> 00:18:25,519
get hit right and similarly on input for

00:18:22,639 --> 00:18:27,110
the input or x hook right but in both

00:18:25,519 --> 00:18:28,490
direction but it allows even though it's

00:18:27,110 --> 00:18:30,590
gonna be cached because we'll do a pre

00:18:28,490 --> 00:18:43,100
de MUX on receive and we have the route

00:18:30,590 --> 00:18:44,870
available on transmit yes and yes so I

00:18:43,100 --> 00:18:47,299
think your number will improve is what

00:18:44,870 --> 00:18:49,070
David is saying right because I think

00:18:47,299 --> 00:18:51,529
Dave thing would actually be worse he a

00:18:49,070 --> 00:18:53,419
lot more zip lookups I I it's not even

00:18:51,529 --> 00:18:55,970
in the benchmark the lookups aren't

00:18:53,419 --> 00:18:57,169
happening Connect happens and that's

00:18:55,970 --> 00:18:58,429
where the route gets looked up and

00:18:57,169 --> 00:18:59,720
cached into the socket and that's it

00:18:58,429 --> 00:19:03,880
that's the only fit lookup that happens

00:18:59,720 --> 00:19:06,880
at all for the whole benchmark oh it's

00:19:03,880 --> 00:19:06,880
yeah

00:19:07,990 --> 00:19:12,890
and but it is important to see if

00:19:11,360 --> 00:19:16,340
there's any influence upon the FIB look

00:19:12,890 --> 00:19:17,929
up at all because that this is what I

00:19:16,340 --> 00:19:19,640
spent doing for two and a half years

00:19:17,929 --> 00:19:21,380
when I did the routing cash removal and

00:19:19,640 --> 00:19:24,230
yeah that canonic the canonical

00:19:21,380 --> 00:19:26,420
benchmark is an unconnected UDP socket

00:19:24,230 --> 00:19:28,370
blasting out to Deb dummy with a fixed

00:19:26,420 --> 00:19:30,740
arm address for entry attached that's

00:19:28,370 --> 00:19:32,750
the way to so the the the receive and

00:19:30,740 --> 00:19:34,550
they so they receive and the output

00:19:32,750 --> 00:19:36,950
functions are getting hit because those

00:19:34,550 --> 00:19:39,950
are before the D mocks for example so it

00:19:36,950 --> 00:19:43,490
is stressing that aspect of it from you

00:19:39,950 --> 00:19:45,410
know activating the the device lookup or

00:19:43,490 --> 00:19:47,330
the the master pulling out the master

00:19:45,410 --> 00:19:48,950
and looking up that operation kicking it

00:19:47,330 --> 00:19:51,140
over sent it right back right all the

00:19:48,950 --> 00:19:53,179
device traversal all turning into V RF

00:19:51,140 --> 00:19:54,590
device rewetting addresses whatever I do

00:19:53,179 --> 00:19:57,050
inside the device yes that's getting

00:19:54,590 --> 00:19:58,340
triggered for sure yes so yeah I guess I

00:19:57,050 --> 00:20:00,710
did overlook the fact that it's not

00:19:58,340 --> 00:20:03,520
doing the field lookups on everyone okay

00:20:00,710 --> 00:20:03,520
cool just want to clarify

00:20:07,250 --> 00:20:12,309
all right it's Q&A any other questions

00:20:17,830 --> 00:20:22,250
so are there any limitations on what

00:20:20,780 --> 00:20:24,799
type of devices you can actually have

00:20:22,250 --> 00:20:28,039
enslaves like can you have a VLAN device

00:20:24,799 --> 00:20:32,299
for example yes okay you can we've done

00:20:28,039 --> 00:20:34,340
VLAN bond back VLAN bridges anything

00:20:32,299 --> 00:20:38,809
with an address can be enslaved to an L

00:20:34,340 --> 00:20:41,510
3 m dev yes periodic periodic have you

00:20:38,809 --> 00:20:43,340
tested ipv6 or confirmation on this and

00:20:41,510 --> 00:20:48,020
does it work I haven't known

00:20:43,340 --> 00:20:51,590
auto-configuration know the sort of

00:20:48,020 --> 00:20:53,360
selection limitations yes can you never

00:20:51,590 --> 00:20:54,620
choose a source address from anywhere

00:20:53,360 --> 00:20:56,360
else in the system like you couldn't

00:20:54,620 --> 00:20:58,909
have a address assigned to loop back and

00:20:56,360 --> 00:21:01,539
have no never know and that was

00:20:58,909 --> 00:21:05,179
something out of net dev in Spain that

00:21:01,539 --> 00:21:07,130
David Lam parter noticed that the source

00:21:05,179 --> 00:21:10,070
address selection was wrong and we fixed

00:21:07,130 --> 00:21:12,380
that so that it only returns an address

00:21:10,070 --> 00:21:15,620
associated with devices inside the l3

00:21:12,380 --> 00:21:18,919
domain but sometimes you can assign like

00:21:15,620 --> 00:21:20,299
a true loop that addresses right to see

00:21:18,919 --> 00:21:22,190
you else in the system when you would

00:21:20,299 --> 00:21:24,289
put those for this case you'd put those

00:21:22,190 --> 00:21:26,059
on the l3m dev device itself you'd have

00:21:24,289 --> 00:21:28,549
to move them to the ends music yes if

00:21:26,059 --> 00:21:30,950
you want that address to be considered

00:21:28,549 --> 00:21:33,340
on the source address okay thank you

00:21:30,950 --> 00:21:33,340
yeah

00:21:35,559 --> 00:21:45,149
anything else all right I guess I sped

00:21:41,710 --> 00:21:45,149

YouTube URL: https://www.youtube.com/watch?v=FDv4KbHzUYY


