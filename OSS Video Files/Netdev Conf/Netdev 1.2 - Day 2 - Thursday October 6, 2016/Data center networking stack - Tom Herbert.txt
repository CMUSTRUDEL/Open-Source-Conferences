Title: Data center networking stack - Tom Herbert
Publication date: 2016-10-07
Playlist: Netdev 1.2 - Day 2 - Thursday October 6, 2016
Description: 
	http://netdevconf.org/1.2/session.html?tom-herbert
Captions: 
	00:00:09,549 --> 00:00:15,039
work and I'm an engineer from Facebook

00:00:12,309 --> 00:00:17,430
and today I'm going to talk about some

00:00:15,039 --> 00:00:20,410
of the work we've been doing

00:00:17,430 --> 00:00:21,699
specifically in the data center to kind

00:00:20,410 --> 00:00:26,050
of evolve the data center networking

00:00:21,699 --> 00:00:28,090
stack per our needs you know imagine a

00:00:26,050 --> 00:00:30,849
data center I cover like Facebook has a

00:00:28,090 --> 00:00:32,710
lot of different applications primarily

00:00:30,849 --> 00:00:34,899
we use TCP feel our interest in

00:00:32,710 --> 00:00:37,510
optimizing TCP we have a lot of

00:00:34,899 --> 00:00:39,699
different hardware and as you probably

00:00:37,510 --> 00:00:42,579
know Facebook is rolling in to come on

00:00:39,699 --> 00:00:46,000
Abbey based hardware a CP service things

00:00:42,579 --> 00:00:48,760
like that so I work in the kind of

00:00:46,000 --> 00:00:53,350
kernel networking team and we're looking

00:00:48,760 --> 00:00:55,870
kind of across the stack and their goal

00:00:53,350 --> 00:00:58,510
is as I mentioned we want to build a

00:00:55,870 --> 00:01:00,250
network stats for the data center and it

00:00:58,510 --> 00:01:02,320
needs to be forward-looking meaning we

00:01:00,250 --> 00:01:03,670
want to meet future requirements in

00:01:02,320 --> 00:01:05,520
terms of scalability number of

00:01:03,670 --> 00:01:09,430
applications what-have-you

00:01:05,520 --> 00:01:12,850
so the requirements for this performance

00:01:09,430 --> 00:01:15,149
is always going to be near the top but

00:01:12,850 --> 00:01:17,380
we need scalability security is becoming

00:01:15,149 --> 00:01:19,479
more and more paramount especially from

00:01:17,380 --> 00:01:21,459
the data center preventability

00:01:19,479 --> 00:01:24,399
obviously we we've talked a lot about

00:01:21,459 --> 00:01:26,049
that so far in the conference this is

00:01:24,399 --> 00:01:27,670
something that we are integrating in

00:01:26,049 --> 00:01:30,159
various layers and I'll talk a little

00:01:27,670 --> 00:01:33,090
bit about that real identity

00:01:30,159 --> 00:01:35,829
availability a whole bunch of

00:01:33,090 --> 00:01:40,479
characteristics like that data center

00:01:35,829 --> 00:01:42,549
gene level up time and we obviously like

00:01:40,479 --> 00:01:45,399
to have systems running without having

00:01:42,549 --> 00:01:48,159
to muck with him too much I would point

00:01:45,399 --> 00:01:49,990
out that this is obviously not something

00:01:48,159 --> 00:01:51,279
that ever ever end as long as we have

00:01:49,990 --> 00:01:53,139
data centers we're gonna be looking at

00:01:51,279 --> 00:01:55,840
ways to improve them evolve them

00:01:53,139 --> 00:02:01,899
different technologies even different

00:01:55,840 --> 00:02:04,359
protocols at some point so we are kind

00:02:01,899 --> 00:02:06,849
of addressing this from a holistic point

00:02:04,359 --> 00:02:08,410
of view so from the applications all the

00:02:06,849 --> 00:02:12,349
way down to the Knicks and the drivers

00:02:08,410 --> 00:02:14,910
and I think one of the

00:02:12,349 --> 00:02:16,650
big additions to data center networking

00:02:14,910 --> 00:02:18,540
stacks really our security and

00:02:16,650 --> 00:02:20,400
virtualization that are now becoming

00:02:18,540 --> 00:02:23,879
commonplace to the point I think we need

00:02:20,400 --> 00:02:26,489
to kind of modify the networking stack

00:02:23,879 --> 00:02:28,590
model that we have and as I mentioned

00:02:26,489 --> 00:02:30,360
programmability is important this is not

00:02:28,590 --> 00:02:31,920
really specific to any layer it turns

00:02:30,360 --> 00:02:34,349
out that we're finding programmability

00:02:31,920 --> 00:02:37,049
of the networking stack almost at every

00:02:34,349 --> 00:02:39,060
every single layer so we obviously have

00:02:37,049 --> 00:02:40,230
a lot of instances where they want to

00:02:39,060 --> 00:02:43,349
program the NIC with certain things

00:02:40,230 --> 00:02:45,319
drivers like XDP but this even

00:02:43,349 --> 00:02:51,239
percolates all the way up to sockets and

00:02:45,319 --> 00:02:53,610
and some other things so this is kind of

00:02:51,239 --> 00:02:56,549
a modified view of the stack layer or

00:02:53,610 --> 00:02:58,709
the network stack on the right so you

00:02:56,549 --> 00:03:01,410
can see we have a modified view of kind

00:02:58,709 --> 00:03:06,150
of sockets and security becomes part of

00:03:01,410 --> 00:03:09,360
this ila is going to be our network

00:03:06,150 --> 00:03:12,000
virtualization solution ipv6 is

00:03:09,360 --> 00:03:14,730
extremely critical Facebook was one of

00:03:12,000 --> 00:03:18,959
the first companies to you to move

00:03:14,730 --> 00:03:23,430
connect units pp6 only data center and

00:03:18,959 --> 00:03:25,980
then we have drivers and all floods so

00:03:23,430 --> 00:03:28,049
each of these layers we have specific

00:03:25,980 --> 00:03:35,220
technologies we're looking at and I'll

00:03:28,049 --> 00:03:38,910
touch a little bit on each of these so

00:03:35,220 --> 00:03:40,590
at the API layer we invented this thing

00:03:38,910 --> 00:03:42,870
called kernel connection multiplexer

00:03:40,590 --> 00:03:46,530
Dave Watson actually talked a little bit

00:03:42,870 --> 00:03:48,480
about it yesterday the motivation for

00:03:46,530 --> 00:03:50,609
this really is the fact that in the data

00:03:48,480 --> 00:03:53,639
center nearly all of our communications

00:03:50,609 --> 00:03:56,040
are some sort of RPC or message based

00:03:53,639 --> 00:03:58,500
communication and since we're doing this

00:03:56,040 --> 00:04:00,730
over TCP this turns out to be a little

00:03:58,500 --> 00:04:03,519
bit of a mismatch so TCP is

00:04:00,730 --> 00:04:06,640
based protocol yeah we're almost always

00:04:03,519 --> 00:04:10,180
using some sort of data gram application

00:04:06,640 --> 00:04:14,080
layer protocol over it historically this

00:04:10,180 --> 00:04:16,930
requires a lot of complexity and user

00:04:14,080 --> 00:04:18,729
space to deal with this especially in a

00:04:16,930 --> 00:04:21,489
multi-sided application when we might be

00:04:18,729 --> 00:04:24,280
sharing a TCP connection among studs we

00:04:21,489 --> 00:04:27,010
have to guarantee atomicity when we send

00:04:24,280 --> 00:04:29,199
messages and receive messages so often

00:04:27,010 --> 00:04:31,479
that would mean if we one and then I

00:04:29,199 --> 00:04:33,460
said to send on a TCP socket for

00:04:31,479 --> 00:04:37,600
instance it needs to obtain a lock and

00:04:33,460 --> 00:04:39,340
user space on that socket send data it

00:04:37,600 --> 00:04:42,070
might get blocked on the socket and have

00:04:39,340 --> 00:04:43,660
to wait or something like that but take

00:04:42,070 --> 00:04:47,639
some time send the data once it's done

00:04:43,660 --> 00:04:50,050
sending release the lock and continue so

00:04:47,639 --> 00:04:52,810
there's a lot of locking user space as

00:04:50,050 --> 00:04:56,289
an equivalent receive side problem also

00:04:52,810 --> 00:04:57,669
they mentioned pulling and things like

00:04:56,289 --> 00:05:00,250
that all have to take this into account

00:04:57,669 --> 00:05:02,500
so you wind up with a fairly complex

00:05:00,250 --> 00:05:07,389
layer and applications to deal with this

00:05:02,500 --> 00:05:10,419
kind of stream to Datagram mismatch so

00:05:07,389 --> 00:05:13,210
we'll begin with KCM is provide a new

00:05:10,419 --> 00:05:15,580
kind of kernel socket that actually

00:05:13,210 --> 00:05:20,950
orchestrates this kind of message over

00:05:15,580 --> 00:05:22,750
of a stream inside the kernel and as I

00:05:20,950 --> 00:05:25,120
mentioned it's a new socket type we can

00:05:22,750 --> 00:05:29,830
read write messages atomic layer on a

00:05:25,120 --> 00:05:31,900
KCM socket and the C side does require

00:05:29,830 --> 00:05:35,139
that the kernel parses application layer

00:05:31,900 --> 00:05:38,139
messages and this is where we actually

00:05:35,139 --> 00:05:40,780
introduce BPF in in programmability into

00:05:38,139 --> 00:05:41,740
KCM so the idea is when a packet comes

00:05:40,780 --> 00:05:44,410
in we have

00:05:41,740 --> 00:05:46,840
our sir Nelson Stream parser which is a

00:05:44,410 --> 00:05:48,430
functionality we added to do this but

00:05:46,840 --> 00:05:51,190
what it does is it parses packets as

00:05:48,430 --> 00:05:52,900
they come in and the only thing we need

00:05:51,190 --> 00:05:55,120
out of this really is to know where the

00:05:52,900 --> 00:05:56,530
message boundaries are so we can figure

00:05:55,120 --> 00:05:58,569
out here's a message here the message

00:05:56,530 --> 00:06:01,720
here the message and then we can treat

00:05:58,569 --> 00:06:04,330
those separately so all of this is going

00:06:01,720 --> 00:06:06,280
on a multiplexer and it's an n-by-n

00:06:04,330 --> 00:06:13,660
multiplexer so at the top we have a

00:06:06,280 --> 00:06:15,610
number of sockets KPM sockets and on the

00:06:13,660 --> 00:06:20,409
bottom we have a number of TCP

00:06:15,610 --> 00:06:21,970
connections that can be be attached I'll

00:06:20,409 --> 00:06:23,949
go back to the slide in a minute but I

00:06:21,970 --> 00:06:25,569
don't want to mention the stream parts

00:06:23,949 --> 00:06:29,259
or this was one of the things we added

00:06:25,569 --> 00:06:31,659
fairly recently and as I mentioned the

00:06:29,259 --> 00:06:33,759
idea of the stream parser is to parse a

00:06:31,659 --> 00:06:36,970
TCP stream and the individual messages

00:06:33,759 --> 00:06:39,789
and deliver those to kind of the upper

00:06:36,970 --> 00:06:42,789
layer and this is based on a few

00:06:39,789 --> 00:06:45,250
callbacks so one of the callbacks is

00:06:42,789 --> 00:06:47,830
just to simply a callback to parse a

00:06:45,250 --> 00:06:50,469
message in the case of kcn this turns

00:06:47,830 --> 00:06:52,690
into a BPF program in the case of que

00:06:50,469 --> 00:06:55,389
TLS which is the other user this just

00:06:52,690 --> 00:06:59,740
goes into a function that parses the

00:06:55,389 --> 00:07:01,389
stream of a TLS message and once the

00:06:59,740 --> 00:07:04,870
stream processor has a message it cause

00:07:01,389 --> 00:07:07,570
receive message so it marshals a message

00:07:04,870 --> 00:07:10,150
together passes the sk buff up and gives

00:07:07,570 --> 00:07:12,069
the message one of the bigger issues

00:07:10,150 --> 00:07:15,849
though is what's the deal with parsing

00:07:12,069 --> 00:07:18,340
failure is what happens if we exceed the

00:07:15,849 --> 00:07:20,139
possible length or the connection times

00:07:18,340 --> 00:07:22,599
are things like this so we have to

00:07:20,139 --> 00:07:26,289
incorporate a fair amount of complexity

00:07:22,599 --> 00:07:28,330
and dealing with parsing failures now

00:07:26,289 --> 00:07:29,740
one of the important things we did and

00:07:28,330 --> 00:07:33,250
this was actually based on some of the

00:07:29,740 --> 00:07:37,030
feedback we had from KCM how do you

00:07:33,250 --> 00:07:39,849
limit the amount of memory that's being

00:07:37,030 --> 00:07:41,940
consumed by this message reassembly so

00:07:39,849 --> 00:07:46,290
these messages messages in theory

00:07:41,940 --> 00:07:49,620
the arbitrarily sized length so some

00:07:46,290 --> 00:07:51,720
protocols have actually au 32 as a

00:07:49,620 --> 00:07:54,240
message size so conceptually they could

00:07:51,720 --> 00:07:57,270
they could have a 4 gigabyte message now

00:07:54,240 --> 00:07:59,220
in reality most protocols are kind of

00:07:57,270 --> 00:08:01,800
saying and usually we see about 1

00:07:59,220 --> 00:08:04,650
megabyte messages maybe a little more so

00:08:01,800 --> 00:08:07,290
what we did to limit the message size is

00:08:04,650 --> 00:08:08,880
we just say to set a rule that the

00:08:07,290 --> 00:08:12,330
message has to be less than or equal to

00:08:08,880 --> 00:08:14,340
the socket buffer size so if you can

00:08:12,330 --> 00:08:18,120
imagine you clearly see it in this

00:08:14,340 --> 00:08:21,270
picture at the bottom each TCP socket is

00:08:18,120 --> 00:08:24,510
associated with a stream parser so the

00:08:21,270 --> 00:08:26,580
TCP sockets behave as normal packets

00:08:24,510 --> 00:08:28,890
come in they're put on to the TCP socket

00:08:26,580 --> 00:08:32,310
what we do in the stream parser is we

00:08:28,890 --> 00:08:36,120
collect the sk bus off the TCP socket

00:08:32,310 --> 00:08:37,590
into normal sized messages so the

00:08:36,120 --> 00:08:40,380
maximum amount of data that can be

00:08:37,590 --> 00:08:43,080
consumed in this model with that limit I

00:08:40,380 --> 00:08:46,320
mentioned is really the stream parser

00:08:43,080 --> 00:08:48,330
can have one message up to the socket

00:08:46,320 --> 00:08:50,820
buffer size and then TCP could have an

00:08:48,330 --> 00:08:53,790
equivalent amount in its receive queue

00:08:50,820 --> 00:08:56,520
so it basically 2x so that formed the

00:08:53,790 --> 00:08:59,400
first limit now the other thing we

00:08:56,520 --> 00:09:01,770
noticed is that when we assembling or

00:08:59,400 --> 00:09:04,110
assembling these messages is quite

00:09:01,770 --> 00:09:06,510
possible that the sending application

00:09:04,110 --> 00:09:09,090
may just stop sending part of a message

00:09:06,510 --> 00:09:11,700
so we could have the first 900k of the

00:09:09,090 --> 00:09:14,160
message and be waiting for the last

00:09:11,700 --> 00:09:16,110
hundred K indefinitely so to solve that

00:09:14,160 --> 00:09:19,400
problem we just added a simple timer

00:09:16,110 --> 00:09:21,300
which basically says after n

00:09:19,400 --> 00:09:26,120
milliseconds if you don't have a full

00:09:21,300 --> 00:09:27,839
message declare failure and bug out

00:09:26,120 --> 00:09:31,290
filters are usually pretty

00:09:27,839 --> 00:09:34,860
straightforward we just be catch the TCP

00:09:31,290 --> 00:09:37,410
connection close the TCP socket and if

00:09:34,860 --> 00:09:39,060
the application was to recover it can

00:09:37,410 --> 00:09:40,830
goes from create a new socket so not a

00:09:39,060 --> 00:09:41,220
lot of fanciness but the important thing

00:09:40,830 --> 00:09:44,519
is

00:09:41,220 --> 00:09:45,569
we we do try to detect failures and

00:09:44,519 --> 00:09:47,850
report them

00:09:45,569 --> 00:09:50,459
so everything's maintain consistent we

00:09:47,850 --> 00:09:52,829
don't try to do a lot of recovery or the

00:09:50,459 --> 00:09:56,540
little synchronization there's not a lot

00:09:52,829 --> 00:09:56,540
of effort to recover from that

00:09:59,920 --> 00:10:06,189
so I kind of leads us into KT LS they've

00:10:04,269 --> 00:10:08,199
given a lot of description about this

00:10:06,189 --> 00:10:12,759
yesterday so I won't go too much into

00:10:08,199 --> 00:10:15,790
this the important points for this talk

00:10:12,759 --> 00:10:18,069
is this is integrated into engine layers

00:10:15,790 --> 00:10:21,309
of the stack so for example we have the

00:10:18,069 --> 00:10:28,899
the KC M plus K TLS or Katie Ellis could

00:10:21,309 --> 00:10:32,439
be used independently so they've

00:10:28,899 --> 00:10:36,160
mentioned that k CN plus K TLS and this

00:10:32,439 --> 00:10:39,249
is actually accomplished by hooking

00:10:36,160 --> 00:10:40,660
together three sockets in a sense and so

00:10:39,249 --> 00:10:42,189
today I mentioned that had this picture

00:10:40,660 --> 00:10:44,319
of yesterday I wanted to go into a

00:10:42,189 --> 00:10:47,499
little more detail so if you look at the

00:10:44,319 --> 00:10:51,639
left side the TLS and userspace this is

00:10:47,499 --> 00:10:54,160
the traditional data path so application

00:10:51,639 --> 00:10:57,959
goes through an open SSL library and

00:10:54,160 --> 00:11:01,359
then sends TLS on on a normal TCP socket

00:10:57,959 --> 00:11:04,869
in the middle we have the or in the

00:11:01,359 --> 00:11:07,149
second row the K pls that's the first

00:11:04,869 --> 00:11:10,509
instantiation of K tlf so we have the

00:11:07,149 --> 00:11:17,379
TLS socket over by the stream parser in

00:11:10,509 --> 00:11:19,209
TCP socket so once and the TLX sockets

00:11:17,379 --> 00:11:21,819
ascends directly on the TCP socket

00:11:19,209 --> 00:11:25,660
essentially ability go through the

00:11:21,819 --> 00:11:28,809
stream parser for some marshaling but

00:11:25,660 --> 00:11:30,639
definitely one receive we use the stream

00:11:28,809 --> 00:11:33,399
parser to do the message boundary

00:11:30,639 --> 00:11:35,709
delineation that collects and messages

00:11:33,399 --> 00:11:39,459
up so again that has one limitation

00:11:35,709 --> 00:11:42,129
which is the size of socket buffer and

00:11:39,459 --> 00:11:44,049
then TCP socket has a socket buffer and

00:11:42,129 --> 00:11:46,169
then CLS has a socket buffer so now we

00:11:44,049 --> 00:11:49,779
can do the math and figure out the

00:11:46,169 --> 00:11:55,539
amount of memory that can be cured in

00:11:49,779 --> 00:12:00,279
that there is one kind of caveat in KT

00:11:55,539 --> 00:12:01,880
LS that we haven't resolved yet when we

00:12:00,279 --> 00:12:06,050
get a large message

00:12:01,880 --> 00:12:08,840
say a grms it could be up to 64 K that

00:12:06,050 --> 00:12:12,680
could actually contain a multiple number

00:12:08,840 --> 00:12:19,190
of application layer messages and when

00:12:12,680 --> 00:12:22,100
we do the message message delineation on

00:12:19,190 --> 00:12:24,650
that what we do is we clone an sk buff

00:12:22,100 --> 00:12:27,830
for each of these messages and that

00:12:24,650 --> 00:12:30,830
works great so now if we have a 64 K

00:12:27,830 --> 00:12:33,350
message we might have say a thousand

00:12:30,830 --> 00:12:35,660
messages a thousand 64 byte messages in

00:12:33,350 --> 00:12:38,360
that so we get a thousand sk buffs and

00:12:35,660 --> 00:12:41,660
we can deal with that the problem that

00:12:38,360 --> 00:12:44,300
that they found out was that to size is

00:12:41,660 --> 00:12:46,760
not changed when we clone so when we

00:12:44,300 --> 00:12:49,250
actually in queue these messages on to a

00:12:46,760 --> 00:12:51,200
socket buffer if we're measuring by true

00:12:49,250 --> 00:12:56,720
size it looks like we have a thousand

00:12:51,200 --> 00:12:57,290
times 64 K of data so that's kind of

00:12:56,720 --> 00:12:58,940
interesting

00:12:57,290 --> 00:13:01,220
we need to figure out a way to this

00:12:58,940 --> 00:13:02,900
because the memory that appears to be

00:13:01,220 --> 00:13:05,660
consumed is nowhere near or the actual

00:13:02,900 --> 00:13:08,900
memory and one of the open issues we

00:13:05,660 --> 00:13:14,020
have with K TLS so on the right though

00:13:08,900 --> 00:13:16,400
we have the full k CL s plus k CM so

00:13:14,020 --> 00:13:18,830
from the application point of view this

00:13:16,400 --> 00:13:22,340
is going through a k CLS socket and then

00:13:18,830 --> 00:13:24,710
have one stream parser which is for the

00:13:22,340 --> 00:13:28,460
TLS socket so that's the part that takes

00:13:24,710 --> 00:13:31,640
the unencrypted data does the stream

00:13:28,460 --> 00:13:34,910
part on and delivers it to KCl and the

00:13:31,640 --> 00:13:38,830
receive side and then below that we have

00:13:34,910 --> 00:13:42,920
the TLS socket which does the same thing

00:13:38,830 --> 00:13:45,020
basically decrypt CTLs as it comes in

00:13:42,920 --> 00:13:49,460
and get that KCM because that to user

00:13:45,020 --> 00:13:51,590
space so one of the things that kind of

00:13:49,460 --> 00:13:54,290
was walking KCM for us is obviously that

00:13:51,590 --> 00:13:55,050
we need it to move crypto into the

00:13:54,290 --> 00:14:00,000
kernel

00:13:55,050 --> 00:14:02,100
do this and look this works great it

00:14:00,000 --> 00:14:03,780
does have some disadvantages in some

00:14:02,100 --> 00:14:06,210
sense and that we have to have the full

00:14:03,780 --> 00:14:09,630
crypto path in the kernel it also is

00:14:06,210 --> 00:14:12,600
kind of low which means an application

00:14:09,630 --> 00:14:14,460
doing a right from user space we can't

00:14:12,600 --> 00:14:17,070
really encrypt at that point the

00:14:14,460 --> 00:14:19,290
encryption happens later so Dave's idea

00:14:17,070 --> 00:14:21,780
for instance of doing the copy plus

00:14:19,290 --> 00:14:24,600
script oh really want to apply here

00:14:21,780 --> 00:14:27,000
since its separate however the advantage

00:14:24,600 --> 00:14:28,950
obviously of having all of this in the

00:14:27,000 --> 00:14:32,790
kernel is that middle box where we can

00:14:28,950 --> 00:14:35,340
displace now we can as if they point out

00:14:32,790 --> 00:14:38,130
to the advantages of splice with with

00:14:35,340 --> 00:14:40,350
crypto now splice over KCM all in the

00:14:38,130 --> 00:14:45,270
kernel so that has a pretty big

00:14:40,350 --> 00:14:48,960
advantage okay so I'm moving on to the

00:14:45,270 --> 00:14:50,910
TCP layer layer back mill one of our

00:14:48,960 --> 00:14:54,780
colleagues put a lot of effort into

00:14:50,910 --> 00:14:56,670
datacenter TCP implementation the basic

00:14:54,780 --> 00:15:00,480
idea of this and TCP is to extract

00:14:56,670 --> 00:15:03,750
information from a nice en mark and the

00:15:00,480 --> 00:15:06,390
IP header the ECM mark is set by routers

00:15:03,750 --> 00:15:09,150
when they're kind of approaching they're

00:15:06,390 --> 00:15:11,070
there for Q and the idea is when we

00:15:09,150 --> 00:15:13,530
received me C unmarked we can back off

00:15:11,070 --> 00:15:17,340
on our TCP connection so it's really an

00:15:13,530 --> 00:15:21,660
active signal from the network that

00:15:17,340 --> 00:15:24,630
we're getting q builder so we come with

00:15:21,660 --> 00:15:26,220
this we can achieve full-length

00:15:24,630 --> 00:15:28,830
utilizations we have we have some nice

00:15:26,220 --> 00:15:31,140
results from that there are some

00:15:28,830 --> 00:15:33,300
interesting consequences especially when

00:15:31,140 --> 00:15:36,120
we have communications between data

00:15:33,300 --> 00:15:39,390
centers and different congestion control

00:15:36,120 --> 00:15:43,650
algorithms so Larry actually implemented

00:15:39,390 --> 00:15:45,750
a few nice optimizations for this one of

00:15:43,650 --> 00:15:48,780
the things though and I know this idea

00:15:45,750 --> 00:15:49,500
keeps popping in and out is when we

00:15:48,780 --> 00:15:51,990
introduced and

00:15:49,500 --> 00:15:55,170
congestion control algorithms we want to

00:15:51,990 --> 00:15:58,020
have separate Network his to eliminate

00:15:55,170 --> 00:16:00,720
the interference between different

00:15:58,020 --> 00:16:02,880
algorithms so we've seen this a lot okay

00:16:00,720 --> 00:16:05,460
I tend to think this is kind of punning

00:16:02,880 --> 00:16:08,040
I would rather have conditioning can

00:16:05,460 --> 00:16:10,800
corroborate or thans actually work in

00:16:08,040 --> 00:16:13,800
concert with others but for practical

00:16:10,800 --> 00:16:15,360
reasons we may have to occasionally do

00:16:13,800 --> 00:16:19,830
stuff like that so even though it's less

00:16:15,360 --> 00:16:23,610
preferable so the results the data

00:16:19,830 --> 00:16:25,920
center TCP are generally pretty good in

00:16:23,610 --> 00:16:29,340
this craft graph you can see the green

00:16:25,920 --> 00:16:31,470
line bar indicates the throughput we're

00:16:29,340 --> 00:16:34,110
definitely doing better than cubic as

00:16:31,470 --> 00:16:36,360
flows increase and with Reno it's

00:16:34,110 --> 00:16:37,980
definitely competitive the more

00:16:36,360 --> 00:16:40,290
interesting part though are the white

00:16:37,980 --> 00:16:42,900
dashes and the red dashes so the red

00:16:40,290 --> 00:16:45,210
dash is indicate 50% latency and the

00:16:42,900 --> 00:16:48,090
scale is on the right side or the white

00:16:45,210 --> 00:16:51,170
dash is indicate 50% latency the red

00:16:48,090 --> 00:16:53,670
diamonds indicate and 99.9 % latency

00:16:51,170 --> 00:16:56,160
which a large extent is is the most

00:16:53,670 --> 00:16:58,290
interesting latency in the data center

00:16:56,160 --> 00:17:01,320
or interest in the tail as opposed to

00:16:58,290 --> 00:17:03,750
the as opposed to the medium so if you

00:17:01,320 --> 00:17:07,230
look though one of the important

00:17:03,750 --> 00:17:10,760
attributes of data center TCP is that

00:17:07,230 --> 00:17:14,520
the red diamond is close to the white -

00:17:10,760 --> 00:17:16,860
meaning our worst case latency is very

00:17:14,520 --> 00:17:19,079
close to the median case latency this is

00:17:16,860 --> 00:17:21,870
actually a very good property so for

00:17:19,079 --> 00:17:24,860
instance if you look at the far left for

00:17:21,870 --> 00:17:28,620
that example in Reno with one flow the

00:17:24,860 --> 00:17:32,280
median latency of great but that 99.9%

00:17:28,620 --> 00:17:34,740
latency is it's just off the scale so

00:17:32,280 --> 00:17:37,890
what we're looking for really is how do

00:17:34,740 --> 00:17:40,530
you how do you pull that tail latency at

00:17:37,890 --> 00:17:44,070
99.9% latency how do you pull that

00:17:40,530 --> 00:17:45,810
median latency so you can see that we're

00:17:44,070 --> 00:17:54,090
getting that effect out of data center

00:17:45,810 --> 00:17:57,360
TCP pretty much through all the flows so

00:17:54,090 --> 00:18:01,080
moving next layer so identifiers look at

00:17:57,360 --> 00:18:03,300
our addressing this is basically our

00:18:01,080 --> 00:18:06,060
solution to network virtualization at

00:18:03,300 --> 00:18:08,610
Facebook and the idea is we're going to

00:18:06,060 --> 00:18:11,970
split the ipv6 address into two

00:18:08,610 --> 00:18:15,180
components the high order bits 64 bits

00:18:11,970 --> 00:18:17,190
for the locator no other 64 bits on

00:18:15,180 --> 00:18:20,190
earth and the fire locator basically

00:18:17,190 --> 00:18:23,040
says where the packet goes identifier

00:18:20,190 --> 00:18:24,450
says who so you can think in terms of

00:18:23,040 --> 00:18:27,390
network virtualization the identify

00:18:24,450 --> 00:18:30,810
locator as a physical address identifier

00:18:27,390 --> 00:18:33,150
as virtual address so in this model

00:18:30,810 --> 00:18:35,850
applications what they see is sort of a

00:18:33,150 --> 00:18:38,700
globally visible address they can get

00:18:35,850 --> 00:18:40,020
this out of DNS but when they send at

00:18:38,700 --> 00:18:43,350
some point we need to convert that

00:18:40,020 --> 00:18:45,600
address into an actual kind of physical

00:18:43,350 --> 00:18:48,150
address so we do a translation on the

00:18:45,600 --> 00:18:51,840
upper 64 bits from this global level

00:18:48,150 --> 00:18:55,020
calling so address into a locator so the

00:18:51,840 --> 00:18:55,710
sending process is pretty

00:18:55,020 --> 00:18:58,140
straightforward

00:18:55,710 --> 00:19:00,240
we look at the identifier and in the

00:18:58,140 --> 00:19:03,270
table if that returned the structure

00:19:00,240 --> 00:19:05,340
that gives us the locator to write in we

00:19:03,270 --> 00:19:09,290
did one kind of nice optimization based

00:19:05,340 --> 00:19:11,880
on I believe it was a six to four RFC

00:19:09,290 --> 00:19:14,460
Francisco that is to do a checksum

00:19:11,880 --> 00:19:18,000
neutral translation so when you change

00:19:14,460 --> 00:19:19,740
the IP addresses and this is technically

00:19:18,000 --> 00:19:23,750
form that when we change the IP

00:19:19,740 --> 00:19:26,010
addresses that can mess up the checksum

00:19:23,750 --> 00:19:27,870
transport checksum that's using the IP

00:19:26,010 --> 00:19:29,650
address address is in the pseudo header

00:19:27,870 --> 00:19:31,540
so instead of going

00:19:29,650 --> 00:19:35,530
trying to find that transport layer

00:19:31,540 --> 00:19:37,900
checksum what we do is we modify the IP

00:19:35,530 --> 00:19:40,060
header or IP addresses in such a way to

00:19:37,900 --> 00:19:43,360
compensate for that so we actually use

00:19:40,060 --> 00:19:45,850
the low-order 16 bits of the destination

00:19:43,360 --> 00:19:48,730
IP address to do this

00:19:45,850 --> 00:19:50,410
nice trick of modifying a

00:19:48,730 --> 00:19:52,810
straightforward modification run a

00:19:50,410 --> 00:19:57,630
modification modify that and then the

00:19:52,810 --> 00:19:57,630
checksum is the same as we send a packet

00:19:58,110 --> 00:20:03,070
so this is kind of a example of it and

00:20:01,330 --> 00:20:07,090
if you can imagine we have a source

00:20:03,070 --> 00:20:11,710
sending to the virtual address of quad 3

00:20:07,090 --> 00:20:14,590
one at the left and we have the ability

00:20:11,710 --> 00:20:17,620
to actually cache mappings at the host

00:20:14,590 --> 00:20:19,240
of what we're going to deploy this the

00:20:17,620 --> 00:20:21,250
first time we send the packet we won't

00:20:19,240 --> 00:20:23,350
know the host will know where this

00:20:21,250 --> 00:20:26,200
packet is actually going so we send the

00:20:23,350 --> 00:20:28,270
packet out into the network untranslated

00:20:26,200 --> 00:20:31,600
that would hit what we're calling the

00:20:28,270 --> 00:20:33,610
ILA router and the il $1 job is to

00:20:31,600 --> 00:20:35,650
basically receive these sort of

00:20:33,610 --> 00:20:38,350
untranslated packets and translate them

00:20:35,650 --> 00:20:42,100
and forward on to the destination so

00:20:38,350 --> 00:20:44,440
it's a lot like in that box so step one

00:20:42,100 --> 00:20:49,150
we send the packet hits the router do

00:20:44,440 --> 00:20:51,640
the translation to quad 2 : 1 : home 1

00:20:49,150 --> 00:20:54,130
which is now a physical address send the

00:20:51,640 --> 00:20:56,290
packet on to a locator at the

00:20:54,130 --> 00:20:59,140
destination host it does the reverse

00:20:56,290 --> 00:21:04,120
translation so it'll replace the quad 2

00:20:59,140 --> 00:21:05,530
: 1 : : 1 with the quad 3 : : 1 and that

00:21:04,120 --> 00:21:07,240
is what the application sees so the

00:21:05,530 --> 00:21:09,850
application network to see the locator

00:21:07,240 --> 00:21:12,250
addresses it just sees the kind of

00:21:09,850 --> 00:21:19,570
virtual addresses now in addition to

00:21:12,250 --> 00:21:21,490
avoiding the untranslated ila packets a

00:21:19,570 --> 00:21:24,070
router can also send back a type of

00:21:21,490 --> 00:21:26,000
redirect and this would basically be

00:21:24,070 --> 00:21:28,470
telling me the send

00:21:26,000 --> 00:21:30,899
by the way you don't have to send to me

00:21:28,470 --> 00:21:33,029
anymore here's the actual locator use

00:21:30,899 --> 00:21:35,820
this from now on and we eliminate the

00:21:33,029 --> 00:21:38,370
triangular routing so there is some some

00:21:35,820 --> 00:21:41,789
discussion about this this looks a lot

00:21:38,370 --> 00:21:44,610
like an ICMP redirect but ICP directs or

00:21:41,789 --> 00:21:46,799
inert aureus lis insecure so we can only

00:21:44,610 --> 00:21:49,380
do the redirect that we saw the security

00:21:46,799 --> 00:21:51,659
problem we also have another proposal

00:21:49,380 --> 00:21:54,929
which actually I sent some patches

00:21:51,659 --> 00:21:58,980
recently to do an ila resolver in which

00:21:54,929 --> 00:22:01,799
case the hosts before it sends the host

00:21:58,980 --> 00:22:04,740
minutes and connects a send a resolve

00:22:01,799 --> 00:22:07,110
request saying here is the server

00:22:04,740 --> 00:22:09,840
address the global 'visible address can

00:22:07,110 --> 00:22:11,600
you tell me what the locator is for that

00:22:09,840 --> 00:22:14,190
so I would send this and it would hit

00:22:11,600 --> 00:22:16,380
basically a resolver and the resolver

00:22:14,190 --> 00:22:20,940
returned that so the other way to

00:22:16,380 --> 00:22:23,880
eliminate the triangular routing so once

00:22:20,940 --> 00:22:26,880
that below that we have ipv6 as I

00:22:23,880 --> 00:22:30,840
mentioned Facebook is heavily invested

00:22:26,880 --> 00:22:34,950
1986 in the data center and this does

00:22:30,840 --> 00:22:36,870
solve one obvious problem and a large

00:22:34,950 --> 00:22:40,380
data center we historically tended to

00:22:36,870 --> 00:22:43,409
use 10/8 addresses 10/8 theoretically

00:22:40,380 --> 00:22:46,080
gives you 16 million addresses as far as

00:22:43,409 --> 00:22:48,630
I know mmm data center has nearly that

00:22:46,080 --> 00:22:51,899
not many hosts but the problem is in how

00:22:48,630 --> 00:22:54,480
we allocate and America hierarchical

00:22:51,899 --> 00:22:56,340
allocation of these address spaces so it

00:22:54,480 --> 00:22:59,190
is actually possible to run out of a

00:22:56,340 --> 00:23:03,779
10/8 space because I need to give racks

00:22:59,190 --> 00:23:06,419
of say 48 machines need 64 host

00:23:03,779 --> 00:23:10,059
addresses or something like that so

00:23:06,419 --> 00:23:12,340
instead of continuously we numbering

00:23:10,059 --> 00:23:14,739
which a lot of companies have been doing

00:23:12,340 --> 00:23:17,529
or we're trying to consider of address

00:23:14,739 --> 00:23:19,779
space some of the other Facebook at one

00:23:17,529 --> 00:23:22,359
point that said let's just go and make

00:23:19,779 --> 00:23:25,690
it ipv6 and they've ended up being the

00:23:22,359 --> 00:23:26,889
kind of thing in order to do this at the

00:23:25,690 --> 00:23:28,479
large scale you really need somebody

00:23:26,889 --> 00:23:32,889
dedicated to this and in this case it

00:23:28,479 --> 00:23:34,929
was Paul Saab this went hog-wild to to

00:23:32,889 --> 00:23:37,600
find every application deal with

00:23:34,929 --> 00:23:39,549
providers things like that and what

00:23:37,600 --> 00:23:42,609
about two years later in all ipv6

00:23:39,549 --> 00:23:45,759
network it is a one-way ticket I don't

00:23:42,609 --> 00:23:49,389
think we can ever go back to ipv4 so I

00:23:45,759 --> 00:23:53,799
mean it's real invested but that being

00:23:49,389 --> 00:23:55,989
said a lot of benefits out of ipv6 the

00:23:53,799 --> 00:23:58,269
addressing flexibility is really amazing

00:23:55,989 --> 00:24:01,359
we can do things like a sign every

00:23:58,269 --> 00:24:03,820
single host its own flat 64 which means

00:24:01,359 --> 00:24:06,399
we have two 64th objects we can address

00:24:03,820 --> 00:24:10,899
in every coast so that easily gets us

00:24:06,399 --> 00:24:12,639
the idea of one address per task but I

00:24:10,899 --> 00:24:16,090
think we're gonna way beyond that and

00:24:12,639 --> 00:24:17,649
have individual pieces of content

00:24:16,090 --> 00:24:20,019
eventually will have their own IP

00:24:17,649 --> 00:24:23,070
address so there's a lot of of course

00:24:20,019 --> 00:24:25,690
stuff we can do there one of the other

00:24:23,070 --> 00:24:27,909
interesting features of ipv6 which is

00:24:25,690 --> 00:24:29,529
actually kind of subtle and I think

00:24:27,909 --> 00:24:32,409
hasn't really been used to its fullest

00:24:29,529 --> 00:24:36,129
extent is flow label so we talked a lot

00:24:32,409 --> 00:24:38,710
about ecmp we talked a lot about using

00:24:36,129 --> 00:24:42,879
UDP encapsulation and things like that

00:24:38,710 --> 00:24:45,909
all of these have this property that the

00:24:42,879 --> 00:24:48,279
for ipv6 and before flow label devices

00:24:45,909 --> 00:24:49,610
had to actually parse into transport

00:24:48,279 --> 00:24:51,830
layers in order to get

00:24:49,610 --> 00:24:54,770
later information in order to do let L

00:24:51,830 --> 00:24:57,020
for labor for a CMP it turns out if you

00:24:54,770 --> 00:24:59,660
use the formal email correctly all of

00:24:57,020 --> 00:25:02,720
that goes away we can now too late for

00:24:59,660 --> 00:25:06,170
ecmp labor for hashing just based on the

00:25:02,720 --> 00:25:10,100
IP header and this this really huge when

00:25:06,170 --> 00:25:11,960
I did settle in a sense and it took us a

00:25:10,100 --> 00:25:13,660
while to actually get to the point of

00:25:11,960 --> 00:25:15,980
even setting flow labels on the internet

00:25:13,660 --> 00:25:19,190
but I'm hoping that vendors picked this

00:25:15,980 --> 00:25:21,799
up and and once we get to really an all

00:25:19,190 --> 00:25:24,679
pipe ev6 world this is the first step

00:25:21,799 --> 00:25:26,690
where vendors and stop doing VPI just

00:25:24,679 --> 00:25:28,490
for the purposes of getting transport

00:25:26,690 --> 00:25:29,840
ports so I think it was actually a

00:25:28,490 --> 00:25:31,730
little thing that's going to have a big

00:25:29,840 --> 00:25:33,350
impact eventually one of the other

00:25:31,730 --> 00:25:36,410
interesting things though is extension

00:25:33,350 --> 00:25:37,880
headers this is a little more checkered

00:25:36,410 --> 00:25:39,790
and whether or not we'll ever get full

00:25:37,880 --> 00:25:42,200
use out of this

00:25:39,790 --> 00:25:45,590
the idea of extension headers of course

00:25:42,200 --> 00:25:48,860
is to extend IP but requires adding bits

00:25:45,590 --> 00:25:50,780
to headers and this is where again the

00:25:48,860 --> 00:25:53,450
vendors have a say because they

00:25:50,780 --> 00:25:55,490
historically want to parse into packets

00:25:53,450 --> 00:25:57,530
to get the transport layer putting an

00:25:55,490 --> 00:26:00,830
extension header as kind of messes them

00:25:57,530 --> 00:26:02,419
up and it's a vendor problem but we kind

00:26:00,830 --> 00:26:04,669
of have to deal with this and it does

00:26:02,419 --> 00:26:06,530
limit us to when and where we can use

00:26:04,669 --> 00:26:09,590
extension headers I'm kind of optimistic

00:26:06,530 --> 00:26:12,340
though specifically because of segment

00:26:09,590 --> 00:26:14,210
routing then they actually kind of

00:26:12,340 --> 00:26:17,150
finally give us a reason to use

00:26:14,210 --> 00:26:18,980
extension headers and maybe force and

00:26:17,150 --> 00:26:21,590
specifically the dollar vendors actually

00:26:18,980 --> 00:26:26,450
gives this and start parsing this

00:26:21,590 --> 00:26:28,179
correctly moving down to kind of lower

00:26:26,450 --> 00:26:31,190
layers so we have Nick offloads

00:26:28,179 --> 00:26:33,679
I think a lot of this has already been

00:26:31,190 --> 00:26:37,700
talked about definitely less with less

00:26:33,679 --> 00:26:40,360
is more it's critical to us and more

00:26:37,700 --> 00:26:43,120
generic to better from a data center

00:26:40,360 --> 00:26:45,730
you we have a lot of different hardware

00:26:43,120 --> 00:26:48,700
from different vendors sometimes we've

00:26:45,730 --> 00:26:52,170
come to nominator it does drive our

00:26:48,700 --> 00:26:54,970
design so there is some element of that

00:26:52,170 --> 00:26:58,179
peripheral devices these are kind of

00:26:54,970 --> 00:27:02,350
exciting to think about especially we

00:26:58,179 --> 00:27:05,080
mentioned that euro LRO has historically

00:27:02,350 --> 00:27:07,390
been very difficult the black box nature

00:27:05,080 --> 00:27:09,610
of it the inconsistencies between

00:27:07,390 --> 00:27:11,669
hardware implementations if we have the

00:27:09,610 --> 00:27:14,140
opportunity to implement our own LRO

00:27:11,669 --> 00:27:16,929
running on different devices that have

00:27:14,140 --> 00:27:18,010
exactly the same behavior that that's

00:27:16,929 --> 00:27:21,820
interesting that could actually be a

00:27:18,010 --> 00:27:24,070
segue into some more impressive types of

00:27:21,820 --> 00:27:25,750
program abilities so this is kind of

00:27:24,070 --> 00:27:29,549
important and I think this is an

00:27:25,750 --> 00:27:31,330
opportunity to maybe move the needle on

00:27:29,549 --> 00:27:34,390
offloads I think we've kind of been

00:27:31,330 --> 00:27:36,669
stuck for a long time as I mentioned

00:27:34,390 --> 00:27:39,580
yesterday there's five basic offloads

00:27:36,669 --> 00:27:42,970
and for those we we've kind of deployed

00:27:39,580 --> 00:27:45,460
and I think Alex's work and others are

00:27:42,970 --> 00:27:47,230
kind of computing as much as we can out

00:27:45,460 --> 00:27:49,720
of those so the questions in the future

00:27:47,230 --> 00:27:51,070
how do we move forward how can we extend

00:27:49,720 --> 00:27:54,299
the concept of offloads

00:27:51,070 --> 00:27:58,330
with fairly include parsing inside

00:27:54,299 --> 00:28:00,220
various forms of hardware so for their

00:27:58,330 --> 00:28:05,140
ability as I mentioned this kind of

00:28:00,220 --> 00:28:07,480
spans all the different layers we're

00:28:05,140 --> 00:28:10,600
obviously very interested in VPS that

00:28:07,480 --> 00:28:14,950
seems to be kind of getting traction as

00:28:10,600 --> 00:28:17,380
as the way that arbitrary program the

00:28:14,950 --> 00:28:20,110
devices in the stack we see some very

00:28:17,380 --> 00:28:23,140
examples of this so SRU leaves port I

00:28:20,110 --> 00:28:25,419
thought that was quite innovative making

00:28:23,140 --> 00:28:27,880
decisions based on not just a simple

00:28:25,419 --> 00:28:30,429
hash or anything even fixed but now we

00:28:27,880 --> 00:28:35,440
can program as early as port to do kind

00:28:30,429 --> 00:28:38,049
of creative arbitrary managing of a

00:28:35,440 --> 00:28:42,250
package during I guess what is what it

00:28:38,049 --> 00:28:46,000
would be innovating TC xpp we've talked

00:28:42,250 --> 00:28:46,550
a lot about that works well sockets etc

00:28:46,000 --> 00:28:48,970
case

00:28:46,550 --> 00:28:52,160
was actually another use case of that

00:28:48,970 --> 00:28:55,310
one of the big advantages a BPF really

00:28:52,160 --> 00:28:58,660
was when the LVM and claim support got

00:28:55,310 --> 00:29:02,110
on the BPF extension so now we can write

00:28:58,660 --> 00:29:06,260
BPF programs in plain c looks like c

00:29:02,110 --> 00:29:08,480
compiles as c and that works works great

00:29:06,260 --> 00:29:13,040
i think this is also kind of an

00:29:08,480 --> 00:29:16,190
interesting thing once we've made this a

00:29:13,040 --> 00:29:19,790
compiler problem now or if we want to

00:29:16,190 --> 00:29:21,830
optimize BPF it's a compiler issue so

00:29:19,790 --> 00:29:23,360
it's no longer like we have to actually

00:29:21,830 --> 00:29:25,550
code it ourselves it's not like writing

00:29:23,360 --> 00:29:27,770
assembly we've moved this problem into

00:29:25,550 --> 00:29:30,220
something higher layer so so eventually

00:29:27,770 --> 00:29:33,950
it's pretty inevitable and really large

00:29:30,220 --> 00:29:36,140
BPF programs and we'll give you on the

00:29:33,950 --> 00:29:38,000
ability of anyone to delight the

00:29:36,140 --> 00:29:41,000
assembly for that effectively so getting

00:29:38,000 --> 00:29:42,770
that into and to C or a compiler and we

00:29:41,000 --> 00:29:45,200
can now optimize for this so I think

00:29:42,770 --> 00:29:48,020
it's possible the next extension of this

00:29:45,200 --> 00:29:50,720
is if we can put something into a

00:29:48,020 --> 00:29:53,360
compiler can we optimize for particular

00:29:50,720 --> 00:29:54,710
pieces of hardware and one of the things

00:29:53,360 --> 00:29:59,840
I was thinking about yesterday was the

00:29:54,710 --> 00:30:02,300
concept of putting p4 into into TC or P

00:29:59,840 --> 00:30:06,320
Florence and devices this is interesting

00:30:02,300 --> 00:30:07,490
because p4 and BPF in some sense they're

00:30:06,320 --> 00:30:10,070
they're kind of like two ends of the

00:30:07,490 --> 00:30:11,770
spectrum there could they do equivalent

00:30:10,070 --> 00:30:13,240
things which we're both trying to get

00:30:11,770 --> 00:30:15,800
programmability

00:30:13,240 --> 00:30:17,510
in the hardware at least in the case of

00:30:15,800 --> 00:30:20,930
p4 but but the idea is somehow

00:30:17,510 --> 00:30:23,120
programmability somehow allow the user

00:30:20,930 --> 00:30:24,740
to control the device and do different

00:30:23,120 --> 00:30:26,540
things other than what the hardware

00:30:24,740 --> 00:30:30,350
allows so nobody has been the question

00:30:26,540 --> 00:30:32,420
that that that's kind of no Sen model

00:30:30,350 --> 00:30:34,580
and where we're going but it's gonna be

00:30:32,420 --> 00:30:37,820
interesting to see how these two kind of

00:30:34,580 --> 00:30:38,540
concepts rectifies to people is really

00:30:37,820 --> 00:30:41,030
design

00:30:38,540 --> 00:30:43,430
to do like hardware it kind of has a

00:30:41,030 --> 00:30:45,950
hardware model in mine BPF was saying

00:30:43,430 --> 00:30:48,470
there's no hardware model we're kind of

00:30:45,950 --> 00:30:50,500
hoping that BPF can be adapted into

00:30:48,470 --> 00:30:52,820
different hardware model so it's

00:30:50,500 --> 00:30:54,260
interesting to me to see where these two

00:30:52,820 --> 00:30:56,240
will intersect

00:30:54,260 --> 00:30:57,500
I think that's one of the things that

00:30:56,240 --> 00:31:00,560
we'll be looking at kind of from a

00:30:57,500 --> 00:31:01,990
higher layer as it going so one thing

00:31:00,560 --> 00:31:06,770
about the programmability

00:31:01,990 --> 00:31:10,370
we also intend this in cases like xdp or

00:31:06,770 --> 00:31:12,680
hardware to the portability so that

00:31:10,370 --> 00:31:14,900
potentially has a lot of value and in

00:31:12,680 --> 00:31:17,150
fact something like xpp I would love to

00:31:14,900 --> 00:31:18,890
see that not just in Linux but actually

00:31:17,150 --> 00:31:21,620
we could do this in Windows or some

00:31:18,890 --> 00:31:23,150
other other OSS with a lot of a lot of

00:31:21,620 --> 00:31:27,020
cool things there and I think this is

00:31:23,150 --> 00:31:33,020
like leading how we maybe do a lot of

00:31:27,020 --> 00:31:33,950
networking in the future this is kind of

00:31:33,020 --> 00:31:37,310
kind of the overview

00:31:33,950 --> 00:31:39,370
it's the conscious networking obviously

00:31:37,310 --> 00:31:41,480
it's being applied all over the kernel

00:31:39,370 --> 00:31:44,570
persons actually seems to be the biggest

00:31:41,480 --> 00:31:46,750
user of it now but if you look at it

00:31:44,570 --> 00:31:50,150
from a kind of hierarchy point of view

00:31:46,750 --> 00:31:52,850
we have the use cases we allow different

00:31:50,150 --> 00:31:54,620
languages as I mentioned the compilers

00:31:52,850 --> 00:31:58,310
and then within the Krone all these

00:31:54,620 --> 00:31:59,480
areas trace points and kernel support

00:31:58,310 --> 00:32:02,720
has jets

00:31:59,480 --> 00:32:04,460
things like that so we're able to put up

00:32:02,720 --> 00:32:06,770
in the kernel and then hardware we have

00:32:04,460 --> 00:32:10,010
various forms of support for that so

00:32:06,770 --> 00:32:12,350
this obviously is a direction in its own

00:32:10,010 --> 00:32:14,180
I think it'll continue but we'll

00:32:12,350 --> 00:32:16,400
continue to look at how we apply this to

00:32:14,180 --> 00:32:18,830
networking one of the things we have to

00:32:16,400 --> 00:32:21,070
be careful about BPF is we're now

00:32:18,830 --> 00:32:23,420
applying it to the data path so

00:32:21,070 --> 00:32:26,480
performance and things like that get

00:32:23,420 --> 00:32:29,150
sleeping become critical always measure

00:32:26,480 --> 00:32:32,060
its know is I keeping the evaluating

00:32:29,150 --> 00:32:34,960
seems to be a good policy expressed data

00:32:32,060 --> 00:32:38,270
path so I won't go into this too much

00:32:34,960 --> 00:32:39,049
obviously Dave gave a good intro for the

00:32:38,270 --> 00:32:43,429
keynote

00:32:39,049 --> 00:32:46,070
we'll also have the work workshop

00:32:43,429 --> 00:32:47,720
tomorrow on it and we'll have a couple

00:32:46,070 --> 00:32:51,320
of presentations that give a little more

00:32:47,720 --> 00:32:52,429
detail into us but I think the key thing

00:32:51,320 --> 00:32:56,539
to take away here

00:32:52,429 --> 00:33:02,029
XDP it's going to be programmable via

00:32:56,539 --> 00:33:04,279
BPF portable and kind of leveraging all

00:33:02,029 --> 00:33:05,809
the work we've done in BPF and just

00:33:04,279 --> 00:33:08,659
acknowledging that that bare metal

00:33:05,809 --> 00:33:14,269
packet processing at least will get us

00:33:08,659 --> 00:33:16,359
the performance so with that any

00:33:14,269 --> 00:33:16,359
questions

00:33:23,460 --> 00:33:31,390
what happened to the new Vegas Larry

00:33:26,560 --> 00:33:33,930
Bracknell did how come

00:33:31,390 --> 00:33:47,680
Facebook is not using the new Vegas

00:33:33,930 --> 00:33:54,490
condition control to do some deployment

00:33:47,680 --> 00:33:58,530
of it I think the main issue we had in

00:33:54,490 --> 00:34:01,210
the data center a new congestion control

00:33:58,530 --> 00:34:04,750
algorithm the question is how does that

00:34:01,210 --> 00:34:06,730
affect the existing stuff usually it's

00:34:04,750 --> 00:34:11,560
hard to turn on a switch for all of this

00:34:06,730 --> 00:34:14,980
stuff so it is a phased approach TCP NV

00:34:11,560 --> 00:34:17,860
we just see I think I think have a

00:34:14,980 --> 00:34:20,940
similar intent to be be are finding that

00:34:17,860 --> 00:34:24,780
I I think that was a term for that point

00:34:20,940 --> 00:34:28,300
measure the latency of RTT find the

00:34:24,780 --> 00:34:30,010
inflection point where increasing the

00:34:28,300 --> 00:34:33,190
rate of data in the network doesn't

00:34:30,010 --> 00:34:37,870
increase the throughput so yes it is

00:34:33,190 --> 00:34:39,580
still active I think it's it's is in

00:34:37,870 --> 00:34:40,750
evolutionary so I don't have a straight

00:34:39,580 --> 00:34:43,510
answer whether or not we'll be running

00:34:40,750 --> 00:34:44,920
it next year or not in fact I think

00:34:43,510 --> 00:34:49,750
that's almost true for anything we're

00:34:44,920 --> 00:34:54,420
presenting here today whatever we do

00:34:49,750 --> 00:34:57,280
will be for the benefit of the network

00:34:54,420 --> 00:35:01,000
some things are becoming less negotiate

00:34:57,280 --> 00:35:03,250
of all security for instance more and

00:35:01,000 --> 00:35:04,990
more it's looking like Morgan is just

00:35:03,250 --> 00:35:08,860
going to have to Spisak Y all the time

00:35:04,990 --> 00:35:10,690
and that becomes kind of a cost benefit

00:35:08,860 --> 00:35:12,070
thing and one of the reasons we want

00:35:10,690 --> 00:35:13,960
something like Katie Ellis for instance

00:35:12,070 --> 00:35:16,810
is to get that cost benefit down to

00:35:13,960 --> 00:35:17,710
security become an advantage so it's

00:35:16,810 --> 00:35:19,960
always a con

00:35:17,710 --> 00:35:21,130
the process of evaluating evaluating

00:35:19,960 --> 00:35:24,790
where you are and what the next

00:35:21,130 --> 00:35:26,530
technologies are so a new technology

00:35:24,790 --> 00:35:28,660
like XDP is interesting because that has

00:35:26,530 --> 00:35:30,130
a lot of opportunity at the end of the

00:35:28,660 --> 00:35:34,960
day question is how do you actually

00:35:30,130 --> 00:35:36,880
apply that measure it show improvement

00:35:34,960 --> 00:35:41,680
especially in the data center where it's

00:35:36,880 --> 00:35:44,349
a very generic kind of atmosphere for

00:35:41,680 --> 00:35:46,630
running TCP env to the Internet

00:35:44,349 --> 00:35:48,550
I think the interactions with cubic

00:35:46,630 --> 00:35:50,619
probably are are kind of difficult at

00:35:48,550 --> 00:35:53,980
this point I know a few seeing thought

00:35:50,619 --> 00:35:56,070
about that with PBR but a large-scale

00:35:53,980 --> 00:35:58,450
Internet where we can't control much

00:35:56,070 --> 00:35:59,680
these protocols you become even harder

00:35:58,450 --> 00:36:01,030
they descent at least we have the

00:35:59,680 --> 00:36:03,490
advantage that's kind of a closed system

00:36:01,030 --> 00:36:05,530
so you might be able to do a deployment

00:36:03,490 --> 00:36:08,380
of something like TCP MV but it would

00:36:05,530 --> 00:36:11,680
take some some time and energy okay I

00:36:08,380 --> 00:36:15,250
have another question that's for the KC

00:36:11,680 --> 00:36:17,230
and sockets do anything if say you know

00:36:15,250 --> 00:36:19,420
one plication writes a one time message

00:36:17,230 --> 00:36:23,380
by the other writes a hundred megabyte

00:36:19,420 --> 00:36:26,250
message how do you do anything to do

00:36:23,380 --> 00:36:30,970
this kind of hell light blocking issue

00:36:26,250 --> 00:36:32,650
so right now it's it first of all has an

00:36:30,970 --> 00:36:35,800
advantage and that you can do that in

00:36:32,650 --> 00:36:38,170
parallel so if you have two KCM sockets

00:36:35,800 --> 00:36:39,760
and willing one TCP connection there's a

00:36:38,170 --> 00:36:42,010
nice effect that both of them could be

00:36:39,760 --> 00:36:44,020
writing to the KCM sockets you can do

00:36:42,010 --> 00:36:46,780
copies in parallel which is an advantage

00:36:44,020 --> 00:36:49,630
of having only one TCP socket now in

00:36:46,780 --> 00:36:52,510
terms of fairness between the sockets I

00:36:49,630 --> 00:36:56,770
don't think we've done too much on that

00:36:52,510 --> 00:37:00,099
except mostly a round-robin sort of

00:36:56,770 --> 00:37:03,849
thing but obviously we can't extend that

00:37:00,099 --> 00:37:06,030
to have priority levels probably could

00:37:03,849 --> 00:37:09,520
use some sort of even a programmable

00:37:06,030 --> 00:37:11,530
which which one do you send first so

00:37:09,520 --> 00:37:13,480
there are a lot of options there I think

00:37:11,530 --> 00:37:18,730
for the most part though the model of

00:37:13,480 --> 00:37:21,460
KCM we have initially is that it's say a

00:37:18,730 --> 00:37:23,350
web web back-end or something like that

00:37:21,460 --> 00:37:26,620
and we're considering all

00:37:23,350 --> 00:37:29,460
all packets to be equal importance but

00:37:26,620 --> 00:37:32,140
there's no there's nothing to prevent

00:37:29,460 --> 00:37:34,570
prevent that from changing there also is

00:37:32,140 --> 00:37:37,000
another thing in KCM which might be an

00:37:34,570 --> 00:37:39,130
extension right now Casey and sockets

00:37:37,000 --> 00:37:42,760
are effectively connected so if you

00:37:39,130 --> 00:37:45,490
write to a KCM socket that writes to a

00:37:42,760 --> 00:37:46,800
specific set of PCP sockets are going to

00:37:45,490 --> 00:37:49,480
a specific destination

00:37:46,800 --> 00:37:51,700
so all KCM sockets are currently

00:37:49,480 --> 00:37:53,170
connected one thing we might do is I can

00:37:51,700 --> 00:37:55,090
make an unconnected mode which is

00:37:53,170 --> 00:37:57,280
interesting because now we could have

00:37:55,090 --> 00:38:01,630
one KCM socket that can send to

00:37:57,280 --> 00:38:03,760
thousands of different destinations and

00:38:01,630 --> 00:38:06,760
we would specify in some sort of address

00:38:03,760 --> 00:38:09,220
which which destination to send on so

00:38:06,760 --> 00:38:10,960
that might be an extension to kco now to

00:38:09,220 --> 00:38:13,840
reduce the number of KCM sockets that

00:38:10,960 --> 00:38:15,600
we're gonna need but within that just be

00:38:13,840 --> 00:38:18,280
UDP sockets

00:38:15,600 --> 00:38:24,000
they look like UDP sockets but they're

00:38:18,280 --> 00:38:29,890
they're just KCM said we also use the

00:38:24,000 --> 00:38:32,530
that Sox seek seek packet which is like

00:38:29,890 --> 00:38:35,410
the third type of socket say a Datagram

00:38:32,530 --> 00:38:38,290
streams seat packet this actually allows

00:38:35,410 --> 00:38:42,130
you to form kind of pseudo streams using

00:38:38,290 --> 00:38:47,890
data grounds and that actually is very

00:38:42,130 --> 00:38:51,250
useful to so KP Singh of Casey on that

00:38:47,890 --> 00:38:53,020
is being UDP like in terms of

00:38:51,250 --> 00:38:54,880
application layer interface which pretty

00:38:53,020 --> 00:38:57,840
much is what application riders want I

00:38:54,880 --> 00:38:57,840
think that's the best way to phrase it

00:39:06,270 --> 00:39:12,250
so you mentioned secretary than we

00:39:08,710 --> 00:39:14,590
needed KCM one of the Oracle entities

00:39:12,250 --> 00:39:16,360
maybe in five six years ago into the

00:39:14,590 --> 00:39:19,960
kernel the audio socket which is also

00:39:16,360 --> 00:39:23,050
sec packets so what were your well you

00:39:19,960 --> 00:39:27,070
think use it what it was broke up in the

00:39:23,050 --> 00:39:30,480
mainland listen what for the way yes why

00:39:27,070 --> 00:39:30,480
you couldn't you have used audio

00:39:35,190 --> 00:39:43,420
specific type of protocol right so for

00:39:39,640 --> 00:39:45,280
case IAM we can use this with almost any

00:39:43,420 --> 00:39:48,760
application layer protocol so we have an

00:39:45,280 --> 00:39:51,130
HTTP method you could just uh be in

00:39:48,760 --> 00:39:53,740
distress so we really wanted to

00:39:51,130 --> 00:39:56,290
accelerate existing application layer

00:39:53,740 --> 00:39:59,440
protocols and in fact you can even

00:39:56,290 --> 00:40:03,490
imagine we could use KCM as as a

00:39:59,440 --> 00:40:06,250
webserver to parse HTTP to which would

00:40:03,490 --> 00:40:08,740
be pretty straightforward so the the new

00:40:06,250 --> 00:40:11,890
ran of KCM where the enabler was and

00:40:08,740 --> 00:40:14,140
actually BPF without BPF what we would

00:40:11,890 --> 00:40:15,940
have had to do was put a little module

00:40:14,140 --> 00:40:17,740
that implements each of these little

00:40:15,940 --> 00:40:21,580
protocols inside the kernel so we'd have

00:40:17,740 --> 00:40:24,280
the thrift module the HTTP to module and

00:40:21,580 --> 00:40:26,860
that was just so unpleasant so this is a

00:40:24,280 --> 00:40:30,670
great convergence of technology at the

00:40:26,860 --> 00:40:31,840
code BPF arbitrarily programmable KCM we

00:40:30,670 --> 00:40:34,030
don't want to put application layer

00:40:31,840 --> 00:40:37,210
protocols in the kernel at all it's a

00:40:34,030 --> 00:40:38,530
bad idea but now we can because in a way

00:40:37,210 --> 00:40:41,710
that the kernel doesn't know about so

00:40:38,530 --> 00:40:46,440
it's a beautiful use case for for BPF

00:40:41,710 --> 00:40:49,500
turned out to work out really great okay

00:40:46,440 --> 00:40:49,500

YouTube URL: https://www.youtube.com/watch?v=bwoTqnyR3jo


