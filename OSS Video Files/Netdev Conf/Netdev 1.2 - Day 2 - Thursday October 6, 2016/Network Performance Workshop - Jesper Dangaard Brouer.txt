Title: Network Performance Workshop - Jesper Dangaard Brouer
Publication date: 2016-10-07
Playlist: Netdev 1.2 - Day 2 - Thursday October 6, 2016
Description: 
	http://netdevconf.org/1.2/session.html?jesper-performance-workshop
Captions: 
	00:00:09,530 --> 00:00:15,590
I was just waiting for the last

00:00:11,980 --> 00:00:18,369
co-presenter but it gets you can stop it

00:00:15,590 --> 00:00:21,439
up how do it turn on the timeline I

00:00:18,369 --> 00:00:24,310
think yes we can just start I was

00:00:21,439 --> 00:00:24,310
waiting for us eight

00:00:32,710 --> 00:00:37,900
so yeah the microphone is on right

00:00:41,490 --> 00:00:48,960
yeah so this is the network performance

00:00:44,190 --> 00:00:50,820
workshop so the background for the

00:00:48,960 --> 00:00:53,070
workshop is that i'll i'll give a status

00:00:50,820 --> 00:00:57,750
about I cannot stand here get to slide

00:00:53,070 --> 00:00:59,760
in my head go ahead I'll get the stages

00:00:57,750 --> 00:01:01,620
of the process which starts done but I'm

00:00:59,760 --> 00:01:04,980
actually actually most mostly focused on

00:01:01,620 --> 00:01:07,530
all the stuff you didn't do yet because

00:01:04,980 --> 00:01:11,790
that's that's what it's all about all

00:01:07,530 --> 00:01:13,650
all just stuff we have to fix so I'll

00:01:11,790 --> 00:01:16,470
talk about all of the sort of existing

00:01:13,650 --> 00:01:19,340
bottlenecks in the kernel and some ideas

00:01:16,470 --> 00:01:23,970
to what direction we should go and i

00:01:19,340 --> 00:01:26,760
highly encourage people like discuss

00:01:23,970 --> 00:01:30,840
that all of my ideas are stupid or

00:01:26,760 --> 00:01:38,070
something and very much up to two

00:01:30,840 --> 00:01:39,990
discussing that so so it's it's also

00:01:38,070 --> 00:01:43,170
time to come up with good good ideas new

00:01:39,990 --> 00:01:46,649
ideas maybe just bad ideas that says

00:01:43,170 --> 00:01:48,330
okay well first I want to give a like a

00:01:46,649 --> 00:01:50,700
shout out so it's all of the many

00:01:48,330 --> 00:01:52,440
contributors this is not that's also why

00:01:50,700 --> 00:01:54,030
what wants to do a workshop not just

00:01:52,440 --> 00:01:56,820
that i'm talking about network

00:01:54,030 --> 00:01:58,740
performance is actually a lot of

00:01:56,820 --> 00:02:02,820
contributors helping addressing these

00:01:58,740 --> 00:02:05,250
issues for most alexander dike was just

00:02:02,820 --> 00:02:07,050
hearing which did a lot of the

00:02:05,250 --> 00:02:09,979
optimization for the for the free plug

00:02:07,050 --> 00:02:13,500
up which was really great basically

00:02:09,979 --> 00:02:17,250
doubled the performance of the colonel

00:02:13,500 --> 00:02:20,100
running look up and we also have i've

00:02:17,250 --> 00:02:22,050
done some things like the page flag and

00:02:20,100 --> 00:02:24,180
eric too messy was also involved in that

00:02:22,050 --> 00:02:26,880
you move that into the memory area which

00:02:24,180 --> 00:02:28,890
is great and alex also did a lot of

00:02:26,880 --> 00:02:34,440
small automation all over the place but

00:02:28,890 --> 00:02:37,200
they all add up and david also did a lot

00:02:34,440 --> 00:02:38,970
of things but it's we finally pushed

00:02:37,200 --> 00:02:41,520
through the ex MIT more and we have seen

00:02:38,970 --> 00:02:45,510
a lot of action going around this and a

00:02:41,520 --> 00:02:46,860
huge improvement and also call for for

00:02:45,510 --> 00:02:49,200
being the most efficient maintainer

00:02:46,860 --> 00:02:50,240
because now i actually had to to break

00:02:49,200 --> 00:02:53,600
through to memory

00:02:50,240 --> 00:02:56,990
rule and and took that pain of how slow

00:02:53,600 --> 00:02:58,910
this it is to get my patches in there so

00:02:56,990 --> 00:03:01,520
I was really happy when I came back off

00:02:58,910 --> 00:03:05,360
though I almost spent a year in the

00:03:01,520 --> 00:03:07,190
memory allocator then 10 then you

00:03:05,360 --> 00:03:09,740
realize how could I maintain and we have

00:03:07,190 --> 00:03:14,270
in the networking area unofficially yes

00:03:09,740 --> 00:03:17,450
please and then I also want to thank i

00:03:14,270 --> 00:03:19,580
replied an election Brendan who who

00:03:17,450 --> 00:03:22,030
started this xtp stuff which David

00:03:19,580 --> 00:03:24,950
Justice was the most greatest thing ever

00:03:22,030 --> 00:03:26,540
I'll really happy to hear that so that

00:03:24,950 --> 00:03:29,780
they also started that was one of my

00:03:26,540 --> 00:03:32,980
really crazy ideas since the last last

00:03:29,780 --> 00:03:39,050
virtual and let they've won that one I

00:03:32,980 --> 00:03:43,610
think was called the page the packet

00:03:39,050 --> 00:03:46,640
page i called it a packet page idea yeah

00:03:43,610 --> 00:03:48,980
and john festive and put him on stage

00:03:46,640 --> 00:03:50,480
because he's doing so much great work in

00:03:48,980 --> 00:03:52,370
the in the cutest carrier which i've

00:03:50,480 --> 00:03:53,950
been bitching about for two years or

00:03:52,370 --> 00:03:58,100
something and he's actually fixing him

00:03:53,950 --> 00:04:00,140
so I'm really heavy about that and and

00:03:58,100 --> 00:04:03,020
made a large hoping that the first

00:04:00,140 --> 00:04:05,150
driver that actually like took two cakes

00:04:03,020 --> 00:04:06,550
to take stupi idea we had John the board

00:04:05,150 --> 00:04:11,630
and said okay we are going to do this

00:04:06,550 --> 00:04:13,610
that's yes that's really great and throw

00:04:11,630 --> 00:04:16,670
any also does optimizations winded

00:04:13,610 --> 00:04:18,560
within the the dead filter area even

00:04:16,670 --> 00:04:20,989
though I want a super hot path it's

00:04:18,560 --> 00:04:22,550
actually Netflix using use everywhere so

00:04:20,989 --> 00:04:24,860
optimization in that area is also very

00:04:22,550 --> 00:04:27,560
valuable you should be shouldn't forget

00:04:24,860 --> 00:04:29,270
that and then harness and Paulo are

00:04:27,560 --> 00:04:32,540
doing some really interesting work

00:04:29,270 --> 00:04:35,270
within the the how are we inside with

00:04:32,540 --> 00:04:37,790
the scheduler and that's actually I'm

00:04:35,270 --> 00:04:39,620
really scared of jumping into that

00:04:37,790 --> 00:04:41,270
because like last time I jumped into

00:04:39,620 --> 00:04:43,730
something at that it cost me full gear

00:04:41,270 --> 00:04:45,620
in the memory educator and now i hope

00:04:43,730 --> 00:04:49,160
that hannahs will jump in the end up in

00:04:45,620 --> 00:04:52,040
the scheduler area I don't have to jump

00:04:49,160 --> 00:04:54,950
in there and and we have have all that

00:04:52,040 --> 00:04:57,440
abuse going on a net so it's really a

00:04:54,950 --> 00:05:01,460
joint effort of many people to getting

00:04:57,440 --> 00:05:03,560
this this working so so this this status

00:05:01,460 --> 00:05:06,590
is like approximate two years I

00:05:03,560 --> 00:05:08,540
think like I would say that I've been

00:05:06,590 --> 00:05:10,790
working on the lowest layers we've been

00:05:08,540 --> 00:05:14,740
working on the lowest layers so to

00:05:10,790 --> 00:05:18,380
transmit layer is when we started out

00:05:14,740 --> 00:05:20,419
was quite disappointing that we had just

00:05:18,380 --> 00:05:22,460
ran some some bike benchmark and tried

00:05:20,419 --> 00:05:24,740
to cut out just to the lowest layer

00:05:22,460 --> 00:05:26,270
transmitted and the curlew could only do

00:05:24,740 --> 00:05:30,830
four million packets per second was like

00:05:26,270 --> 00:05:33,200
whoa what's going on and that's the

00:05:30,830 --> 00:05:34,940
whole discovery of X myth more than that

00:05:33,200 --> 00:05:36,979
it was expensive calling the hardware

00:05:34,940 --> 00:05:39,740
writing the tape on door ringing the

00:05:36,979 --> 00:05:42,740
doorbell under the driver there was sort

00:05:39,740 --> 00:05:44,810
of a revolution so that was where Delta

00:05:42,740 --> 00:05:46,340
X need more stuff came in and I would

00:05:44,810 --> 00:05:49,940
say with basic you solved a transmit

00:05:46,340 --> 00:05:54,410
area like we could do single co full 10

00:05:49,940 --> 00:05:59,389
gig why speed so then we have the lowest

00:05:54,410 --> 00:06:01,729
receive layer and when last year started

00:05:59,389 --> 00:06:04,070
looking at that I think this numbers

00:06:01,729 --> 00:06:05,479
from the mellanox driver that I was also

00:06:04,070 --> 00:06:07,190
disappointed because we only have six

00:06:05,479 --> 00:06:08,960
million package per second just

00:06:07,190 --> 00:06:12,289
receiving in the driver I'm dropping it

00:06:08,960 --> 00:06:14,539
does not wear it it's not good enough so

00:06:12,289 --> 00:06:16,550
but i think i use the day i would say if

00:06:14,539 --> 00:06:20,030
you do the same kind of test basically i

00:06:16,550 --> 00:06:23,120
think for the same driver was like 16

00:06:20,030 --> 00:06:27,229
million packets per second and and we

00:06:23,120 --> 00:06:28,700
have like hdb drop for the mlx for which

00:06:27,229 --> 00:06:30,500
is actually like 20 million pages per

00:06:28,700 --> 00:06:33,350
second so this I'll talk a little bit

00:06:30,500 --> 00:06:35,870
more about HTTP later but you shouldn't

00:06:33,350 --> 00:06:38,000
like this is like forgetting the whole

00:06:35,870 --> 00:06:40,430
stack exists right so we're just fixing

00:06:38,000 --> 00:06:43,220
to lose layer so but we have to like do

00:06:40,430 --> 00:06:45,139
IP forwarding actually like double the

00:06:43,220 --> 00:06:46,820
performance for a single code like to

00:06:45,139 --> 00:06:48,350
before we did like 1,000,000 package per

00:06:46,820 --> 00:06:50,479
second and are we doing 2 million pack

00:06:48,350 --> 00:06:51,979
is pressing and actually I would

00:06:50,479 --> 00:06:56,840
actually say most of the break comes

00:06:51,979 --> 00:06:59,030
from Alex's optimizations and then we

00:06:56,840 --> 00:07:00,560
also so and the problem was mostly

00:06:59,030 --> 00:07:03,139
actually we didn't scale that well and

00:07:00,560 --> 00:07:04,820
you could also did some things there so

00:07:03,139 --> 00:07:06,680
now we actually scale up you have

00:07:04,820 --> 00:07:08,630
multicolored to truck laden package

00:07:06,680 --> 00:07:11,210
percenters I took ya took just took a

00:07:08,630 --> 00:07:13,270
hell excessive benchmark from a real

00:07:11,210 --> 00:07:17,220
colonel we peg part of this stuff too

00:07:13,270 --> 00:07:19,650
and and a single core with

00:07:17,220 --> 00:07:21,120
xtp we can bounce I'm saying 10 million

00:07:19,650 --> 00:07:24,410
packets per second I think tom is saying

00:07:21,120 --> 00:07:27,000
14 something of just how do I dependent

00:07:24,410 --> 00:07:28,710
so I think you think you'd be doing

00:07:27,000 --> 00:07:31,590
pretty good crossing progress as this is

00:07:28,710 --> 00:07:34,980
josh from the last net net worth which

00:07:31,590 --> 00:07:37,770
was it was in February for no no this

00:07:34,980 --> 00:07:40,040
was not this this was the HTTP this was

00:07:37,770 --> 00:07:43,980
actually like juniors work yes of work

00:07:40,040 --> 00:07:45,960
so i also want to explain at least by

00:07:43,980 --> 00:07:48,240
I've been focused on answer at the

00:07:45,960 --> 00:07:53,010
lowest layer it's been provoked quite a

00:07:48,240 --> 00:07:55,050
lot with the DVD k work going on and so

00:07:53,010 --> 00:07:57,150
that's have sort of made me focus on

00:07:55,050 --> 00:07:59,520
like I said that transmit part like is

00:07:57,150 --> 00:08:02,100
pacing assault and we are working on the

00:07:59,520 --> 00:08:03,770
bottom leg in the received path and I've

00:08:02,100 --> 00:08:09,000
noticed a lot of issues with their

00:08:03,770 --> 00:08:11,970
memory allocators so I've I think Eric

00:08:09,000 --> 00:08:13,680
will have some sometimes a list

00:08:11,970 --> 00:08:15,480
complained a little bit but it's

00:08:13,680 --> 00:08:17,400
actually on purpose I've been testing

00:08:15,480 --> 00:08:19,230
and avoiding the socket layer because

00:08:17,400 --> 00:08:21,030
there's a lot of work to do there that's

00:08:19,230 --> 00:08:24,960
what I talked about hennes and Pablo are

00:08:21,030 --> 00:08:32,880
actually looking into that now you can

00:08:24,960 --> 00:08:36,539
send something about a few one hello and

00:08:32,880 --> 00:08:38,640
so so one a few things bbcode you look

00:08:36,539 --> 00:08:41,940
into is like the first of all is we want

00:08:38,640 --> 00:08:44,970
to remove the backlog so Croesus

00:08:41,940 --> 00:08:46,860
situation is like if UD p receives a

00:08:44,970 --> 00:08:48,420
packet but if you have like the socket

00:08:46,860 --> 00:08:51,780
locked from user space we actually

00:08:48,420 --> 00:08:54,240
include in circuit structure and later

00:08:51,780 --> 00:08:56,160
unless the software dislike unlocked we

00:08:54,240 --> 00:08:58,589
call back and and basically process the

00:08:56,160 --> 00:09:02,280
UDP packet until it receives gets into

00:08:58,589 --> 00:09:04,440
the ska music you and so when the reason

00:09:02,280 --> 00:09:07,500
why this is done is that we have some

00:09:04,440 --> 00:09:12,089
operations in regard to follow up memory

00:09:07,500 --> 00:09:15,300
allocation that require the socket look

00:09:12,089 --> 00:09:18,370
at that moment so the idea is to to

00:09:15,300 --> 00:09:20,020
somehow fiddle around was like atomic

00:09:18,370 --> 00:09:23,140
but instead of taking the full socket

00:09:20,020 --> 00:09:26,140
lock so we have a lot less pass in while

00:09:23,140 --> 00:09:30,220
and cue the UDP packets which which

00:09:26,140 --> 00:09:33,760
shows like great significant performance

00:09:30,220 --> 00:09:35,860
improvements as soon as we kind of

00:09:33,760 --> 00:09:38,670
figure out how to safely do that so the

00:09:35,860 --> 00:09:42,370
problem is like we have like a temporal

00:09:38,670 --> 00:09:44,080
was a updating the atomic lawyer versus

00:09:42,370 --> 00:09:46,240
there are multiple atomic variables so

00:09:44,080 --> 00:09:49,810
we could now have the problem that we

00:09:46,240 --> 00:09:51,520
have temporal over-allocation wonder

00:09:49,810 --> 00:09:53,680
allocation the forward path so we need

00:09:51,520 --> 00:09:59,710
to find a way to keep those minimal so

00:09:53,680 --> 00:10:01,690
so there is no like over-allocation or

00:09:59,710 --> 00:10:04,839
too much over-allocation one location in

00:10:01,690 --> 00:10:07,990
the van for that Malik and and after

00:10:04,839 --> 00:10:11,770
that our plan is to actually do UDP

00:10:07,990 --> 00:10:14,950
vector so doing gr 0 on UDP so that we

00:10:11,770 --> 00:10:16,420
can basically we check that the UDP

00:10:14,950 --> 00:10:18,520
header is exactly the same when

00:10:16,420 --> 00:10:21,610
receiving fragments only received

00:10:18,520 --> 00:10:23,110
friends so we can basically get all

00:10:21,610 --> 00:10:26,290
those escapees together push them

00:10:23,110 --> 00:10:28,570
through the routing engine and the corn

00:10:26,290 --> 00:10:30,490
patch I last reviewed was like right

00:10:28,570 --> 00:10:33,160
before we actually put it into the

00:10:30,490 --> 00:10:37,600
socket we actually dekap smita we just

00:10:33,160 --> 00:10:40,570
break the queue into normal skb so

00:10:37,600 --> 00:10:42,670
basically the UDP receive message

00:10:40,570 --> 00:10:45,820
project basically CC escapees like that

00:10:42,670 --> 00:10:48,070
would have been and cute without this

00:10:45,820 --> 00:10:50,620
feature and we are like right now

00:10:48,070 --> 00:10:52,920
looking at look looking into if we can

00:10:50,620 --> 00:10:56,910
just expand it to have like the normal

00:10:52,920 --> 00:10:58,480
goog so symmetrical approach that we can

00:10:56,910 --> 00:11:00,639
accumulate those

00:10:58,480 --> 00:11:02,680
cats and have a proper geez or function

00:11:00,639 --> 00:11:04,839
tools and the mode and the idea is to

00:11:02,680 --> 00:11:07,290
actually expanded upon tyne but I also

00:11:04,839 --> 00:11:09,370
we have like good UDP throughput for

00:11:07,290 --> 00:11:11,790
connected sockets in the middle of all

00:11:09,370 --> 00:11:17,170
circuits where we actually match the

00:11:11,790 --> 00:11:19,779
veda up until virtual machines and the

00:11:17,170 --> 00:11:21,699
third part would then be to revisit also

00:11:19,779 --> 00:11:23,290
the receive and message functions and

00:11:21,699 --> 00:11:25,720
send a message functions which are right

00:11:23,290 --> 00:11:28,690
now in a bit of a sorry state because

00:11:25,720 --> 00:11:31,029
like we actually they just loop around

00:11:28,690 --> 00:11:32,740
the received message stuff inside the

00:11:31,029 --> 00:11:35,019
corner and we don't actually like go

00:11:32,740 --> 00:11:37,630
into the socket take the soccer team up

00:11:35,019 --> 00:11:40,269
once and DQ or NQ multiple or send

00:11:37,630 --> 00:11:43,180
output to pull friends at once so those

00:11:40,269 --> 00:11:46,300
whose that's exactly right now and what

00:11:43,180 --> 00:11:48,639
we are looking into I hope so that that

00:11:46,300 --> 00:11:51,970
work actually also like there we have to

00:11:48,639 --> 00:11:53,889
the user space calls to do the multiple

00:11:51,970 --> 00:11:55,269
procedure of UDP packets as you talk

00:11:53,889 --> 00:11:57,220
about babe but we are not really not

00:11:55,269 --> 00:11:59,290
taking advantage of it so I'm gonna

00:11:57,220 --> 00:12:02,230
fight benchmarks Cody show an increase

00:11:59,290 --> 00:12:04,149
from 500 to 500,000 packets per second

00:12:02,230 --> 00:12:10,779
22 dot five million packets per second

00:12:04,149 --> 00:12:14,260
yeah like really significant so one of

00:12:10,779 --> 00:12:17,079
my ancestors this is like mounted my

00:12:14,260 --> 00:12:18,519
long-term targets which also created a

00:12:17,079 --> 00:12:21,399
bit to de to the socket layer that I

00:12:18,519 --> 00:12:23,050
actually want to to start works towards

00:12:21,399 --> 00:12:26,470
what when Jacobson called the net

00:12:23,050 --> 00:12:29,110
channels that like to derby that's

00:12:26,470 --> 00:12:31,480
spreading these flows across the

00:12:29,110 --> 00:12:33,190
different queues and this this requires

00:12:31,480 --> 00:12:36,459
this heavy-looking that Tanis is also

00:12:33,190 --> 00:12:37,990
talking about and so I want I really

00:12:36,459 --> 00:12:39,880
wanted to create some kind of channel

00:12:37,990 --> 00:12:42,339
isolation directly from the neck to the

00:12:39,880 --> 00:12:44,470
application so it's really a bad stuff

00:12:42,339 --> 00:12:46,060
and we have there's no multiple steps

00:12:44,470 --> 00:12:48,130
along the way before we can actually do

00:12:46,060 --> 00:12:51,130
this when we would need to cooperate

00:12:48,130 --> 00:12:52,540
with the Nick hardware filters which is

00:12:51,130 --> 00:12:55,060
really annoying now because it's not

00:12:52,540 --> 00:12:56,980
expressed in a uniform way Duke there's

00:12:55,060 --> 00:13:01,660
no like API to it you just called user

00:12:56,980 --> 00:13:04,870
space ezh2 we use XD be you can use XP p

00:13:01,660 --> 00:13:06,939
for you produce extra pieces but that

00:13:04,870 --> 00:13:08,889
takes using HTTP with this would be like

00:13:06,939 --> 00:13:15,009
a tea milk

00:13:08,889 --> 00:13:16,299
step in in software but it was given

00:13:15,009 --> 00:13:18,730
someone who performs I want to push it

00:13:16,299 --> 00:13:21,429
like all the way to to hardware so i

00:13:18,730 --> 00:13:23,679
know when i get delivered something on a

00:13:21,429 --> 00:13:26,259
specific Hardwick you as far as I

00:13:23,679 --> 00:13:28,329
understand it you have you I think you

00:13:26,259 --> 00:13:30,040
told me that you sum up somehow the guy

00:13:28,329 --> 00:13:31,449
told me you can easily create a lot of

00:13:30,040 --> 00:13:33,639
cues in the hard way that's right

00:13:31,449 --> 00:13:39,970
there's nobody limited about that so

00:13:33,639 --> 00:13:43,079
right those people don't understand that

00:13:39,970 --> 00:13:45,399
the mic Jacobson's idea is basically

00:13:43,079 --> 00:13:47,439
those pills are planted like single

00:13:45,399 --> 00:13:50,529
producer and take a consumer scheme so

00:13:47,439 --> 00:13:54,639
my Jenkins is also always a relationship

00:13:50,529 --> 00:13:56,079
with like a producer and I consumer so

00:13:54,639 --> 00:13:58,329
why don't we take advantage of this and

00:13:56,079 --> 00:14:02,139
the network protocols because if you can

00:13:58,329 --> 00:14:04,269
just sort of peermark it's the

00:14:02,139 --> 00:14:06,009
concurrent proswitcher we just use the

00:14:04,269 --> 00:14:08,619
access hatch and spread it out and

00:14:06,009 --> 00:14:10,449
because it's sort of a best-effort we

00:14:08,619 --> 00:14:13,299
don't have any strict requirements and

00:14:10,449 --> 00:14:15,879
this it even though we let me configure

00:14:13,299 --> 00:14:18,639
it and set it up it's that's how we

00:14:15,879 --> 00:14:20,980
recommend users are doing it and we try

00:14:18,639 --> 00:14:25,329
to keep we try to keep the flows on on

00:14:20,980 --> 00:14:28,720
the same cpus and but in practice it can

00:14:25,329 --> 00:14:30,399
it take they can jump around if it gets

00:14:28,720 --> 00:14:32,619
rehashed or something in the hardware or

00:14:30,399 --> 00:14:34,569
something going on so we need to lock

00:14:32,619 --> 00:14:38,649
anyway so we can really remove these

00:14:34,569 --> 00:14:40,899
locks so your question no the woods

00:14:38,649 --> 00:14:44,110
point again you're in a process tcp user

00:14:40,899 --> 00:14:48,730
space no no no no no no i want to create

00:14:44,110 --> 00:14:50,889
a complete connection with all the way

00:14:48,730 --> 00:14:54,009
from the milk basic is sort of what

00:14:50,889 --> 00:14:55,649
David once which is the sockets and I

00:14:54,009 --> 00:14:59,799
had the next I think the next slide is

00:14:55,649 --> 00:15:02,709
about how you do this for the service so

00:14:59,799 --> 00:15:05,980
you did the socket cues between a nick

00:15:02,709 --> 00:15:07,959
yeah basically so I created a new new

00:15:05,980 --> 00:15:10,209
receive queue for for every circuit I

00:15:07,959 --> 00:15:12,459
want how many sockets cues can you have

00:15:10,209 --> 00:15:15,069
I think the limit is probably a hundred

00:15:12,459 --> 00:15:16,209
thousand marks maybe yep but the app

00:15:15,069 --> 00:15:18,699
like I told me that

00:15:16,209 --> 00:15:21,779
I element that has to be a limit yeah

00:15:18,699 --> 00:15:25,809
there is a limit but for as we said it's

00:15:21,779 --> 00:15:29,100
configurable for Kinect x three four and

00:15:25,809 --> 00:15:33,699
five cards you can have up to millions

00:15:29,100 --> 00:15:35,290
mediums yeah yeah but in practice you if

00:15:33,699 --> 00:15:38,410
you wanted to scale out your application

00:15:35,290 --> 00:15:40,329
lots of millions you you like you would

00:15:38,410 --> 00:15:42,759
like some kind of not do some

00:15:40,329 --> 00:15:44,619
multiplexing Oh or not to create a

00:15:42,759 --> 00:15:46,509
million if you have a lot of small flow

00:15:44,619 --> 00:15:48,519
switch this might not be the solution

00:15:46,509 --> 00:15:53,350
you want because they were too short

00:15:48,519 --> 00:15:55,480
lift so well the bicycle details but how

00:15:53,350 --> 00:15:57,309
you would do it and this is like the

00:15:55,480 --> 00:16:00,100
long-term plan so if there was existed I

00:15:57,309 --> 00:16:03,639
like a hardware filter system I could

00:16:00,100 --> 00:16:05,860
just like an listen or bind call the

00:16:03,639 --> 00:16:08,800
hardware filter make it deliver into a

00:16:05,860 --> 00:16:12,730
specific receive queue and and all of a

00:16:08,800 --> 00:16:14,740
sudden I have this this finding of for

00:16:12,730 --> 00:16:17,920
the listener circuit of have a single I

00:16:14,740 --> 00:16:19,509
know it can only occur on one receive

00:16:17,920 --> 00:16:21,249
queue and I know there's only one

00:16:19,509 --> 00:16:24,670
listener so it's completely love free

00:16:21,249 --> 00:16:25,899
and single producer single consumer but

00:16:24,670 --> 00:16:30,040
i need some heartbreaker and cheese

00:16:25,899 --> 00:16:33,459
there so the more difficult part is once

00:16:30,040 --> 00:16:38,679
you get the except call you would you

00:16:33,459 --> 00:16:41,619
would like get back a channel which is a

00:16:38,679 --> 00:16:44,079
new producer consumer queue and you

00:16:41,619 --> 00:16:45,819
could like as the hardware to to process

00:16:44,079 --> 00:16:50,199
that on another receive queue which

00:16:45,819 --> 00:16:53,290
would be on another ha another likes it

00:16:50,199 --> 00:16:55,899
process by another cpu so it's the

00:16:53,290 --> 00:16:58,089
tricky part is or the difficult part for

00:16:55,899 --> 00:17:01,929
hardware is updating the update speech i

00:16:58,089 --> 00:17:04,870
can do this in I don't want to it can

00:17:01,929 --> 00:17:06,939
slow down so I can I can I can sort of

00:17:04,870 --> 00:17:08,919
block the the packets and have run to

00:17:06,939 --> 00:17:11,110
the hardware filters updated that's one

00:17:08,919 --> 00:17:14,949
approach but that slow start if we want

00:17:11,110 --> 00:17:17,189
to establish connections so so there's a

00:17:14,949 --> 00:17:20,169
lot of like uncertainty in this area

00:17:17,189 --> 00:17:21,030
don't you but you must make sure they're

00:17:20,169 --> 00:17:24,710
basically

00:17:21,030 --> 00:17:26,910
it was going with out of the same core

00:17:24,710 --> 00:17:31,290
the transmit this is on the under

00:17:26,910 --> 00:17:32,850
receive site but if you an assault like

00:17:31,290 --> 00:17:37,860
as you actually want to keep like

00:17:32,850 --> 00:17:41,820
everything in in 111 CPU so you want to

00:17:37,860 --> 00:17:44,700
basically create like per CPU network

00:17:41,820 --> 00:17:46,440
stacks yes exactly but for that to

00:17:44,700 --> 00:17:47,640
matter of interlocking on the sending

00:17:46,440 --> 00:17:49,170
set because something that needs to

00:17:47,640 --> 00:17:53,670
update also counters and stuff like that

00:17:49,170 --> 00:17:55,200
you actually need to keep the sending

00:17:53,670 --> 00:17:57,930
side also on the same so you need to

00:17:55,200 --> 00:18:00,390
like I don't know create some hashing

00:17:57,930 --> 00:18:02,190
scheme or like fiddle along desires as

00:18:00,390 --> 00:18:05,220
key so it actually creates symmetric

00:18:02,190 --> 00:18:07,260
keys yeah yeah you have yeah but that I

00:18:05,220 --> 00:18:10,320
think I believe Google are doing stuff

00:18:07,260 --> 00:18:11,460
like a bit uh negating as if key just

00:18:10,320 --> 00:18:14,450
for how is this different from

00:18:11,460 --> 00:18:16,530
accelerated or a faster floor director

00:18:14,450 --> 00:18:19,020
different how's Ella different from

00:18:16,530 --> 00:18:22,740
accelerated or FS the end of the same

00:18:19,020 --> 00:18:27,810
exit of it up yes it's basically to say

00:18:22,740 --> 00:18:31,140
I so so this is doing the same thing I'm

00:18:27,810 --> 00:18:33,570
some confused why do we need this then I

00:18:31,140 --> 00:18:36,330
I told it's not doing the same thing

00:18:33,570 --> 00:18:38,400
worse but excited a PS we could I guess

00:18:36,330 --> 00:18:40,980
we could then add some hooks that says

00:18:38,400 --> 00:18:43,640
this we know this connection so so don't

00:18:40,980 --> 00:18:45,690
use the socket locks use another stroke

00:18:43,640 --> 00:18:48,180
construct to have date the cue for the

00:18:45,690 --> 00:18:51,990
circuit that's I don't think we do that

00:18:48,180 --> 00:18:55,440
today do we I'll try to remove the locks

00:18:51,990 --> 00:18:56,850
so I understand that so in order to do

00:18:55,440 --> 00:19:00,180
that I think what we're basically saying

00:18:56,850 --> 00:19:03,810
is packets for a flow will only go to a

00:19:00,180 --> 00:19:06,540
specific cpu guaranteed and then we can

00:19:03,810 --> 00:19:11,100
remove the lock from that yeah i think

00:19:06,540 --> 00:19:13,020
you could do that without without

00:19:11,100 --> 00:19:16,410
meeting exactly what you want here i

00:19:13,020 --> 00:19:19,020
think the issue here is something that's

00:19:16,410 --> 00:19:19,900
not excited RFS the question is if I

00:19:19,020 --> 00:19:23,020
program

00:19:19,900 --> 00:19:25,600
turn in hardware and I say this precise

00:19:23,020 --> 00:19:30,520
flow this precise TCP connection has to

00:19:25,600 --> 00:19:33,790
go to this cpu what will it's not only

00:19:30,520 --> 00:19:36,520
CPU it's for it it's on cue it's a

00:19:33,790 --> 00:19:37,840
junkie so let's assume that but then I

00:19:36,520 --> 00:19:41,530
ask myself what if i have an

00:19:37,840 --> 00:19:45,040
encapsulated connection then my device

00:19:41,530 --> 00:19:46,420
has to be able to parse all of these all

00:19:45,040 --> 00:19:47,830
of these different encapsulations

00:19:46,420 --> 00:19:50,140
because the difference here with

00:19:47,830 --> 00:19:52,150
accelerated RFS says we're not just

00:19:50,140 --> 00:19:55,350
saying this it's good enough to have a

00:19:52,150 --> 00:19:57,340
strong hash with very few hash

00:19:55,350 --> 00:19:58,900
collisions the difference here is we're

00:19:57,340 --> 00:20:01,210
saying the hardware has to be very

00:19:58,900 --> 00:20:03,160
precise and picked the exact TCP

00:20:01,210 --> 00:20:06,280
connections on that and I think that's

00:20:03,160 --> 00:20:07,420
going to be a big gap to actually get to

00:20:06,280 --> 00:20:08,920
the hardware at that point especially

00:20:07,420 --> 00:20:10,630
with all the encapsulations they're

00:20:08,920 --> 00:20:12,370
happening yeah I'm also a little bit

00:20:10,630 --> 00:20:15,010
afraid of what guarantees the hopper

00:20:12,370 --> 00:20:16,960
kiki three another question is what if

00:20:15,010 --> 00:20:18,520
you have what if what if you call listen

00:20:16,960 --> 00:20:20,950
or buying it sets up your channel and

00:20:18,520 --> 00:20:22,780
then somebody configures and iptables

00:20:20,950 --> 00:20:25,450
rule it drops that packet or mangles

00:20:22,780 --> 00:20:30,760
that what happens then right you gonna

00:20:25,450 --> 00:20:32,380
run the net filter looks no okay I think

00:20:30,760 --> 00:20:34,800
you would you would have to up into this

00:20:32,380 --> 00:20:37,360
like a suck it up and say I want this I

00:20:34,800 --> 00:20:42,160
say it's a yet-to-be you have to be

00:20:37,360 --> 00:20:43,630
captain I just want this has been a

00:20:42,160 --> 00:20:45,310
fundamental issue with net channels from

00:20:43,630 --> 00:20:46,780
the very beginning when van gave his

00:20:45,310 --> 00:20:48,760
first talk in new zealand it's the first

00:20:46,780 --> 00:20:51,250
thing out of rusty russell in my mouth

00:20:48,760 --> 00:20:52,540
was well now no more netfilter is going

00:20:51,250 --> 00:20:55,150
to be happening if you pass this stuff

00:20:52,540 --> 00:20:57,520
straight to the stack yeah but it's sort

00:20:55,150 --> 00:21:01,420
of 27 probably wait it doesn't under way

00:20:57,520 --> 00:21:03,100
to look at this so you can also say that

00:21:01,420 --> 00:21:07,560
the same problem kind of exists for

00:21:03,100 --> 00:21:10,000
socket prix de box and we had a mutual

00:21:07,560 --> 00:21:12,130
problems like that the routing table can

00:21:10,000 --> 00:21:14,060
actually like have IP whois for example

00:21:12,130 --> 00:21:16,970
which don't get like consultants

00:21:14,060 --> 00:21:18,890
so the premise is once we've established

00:21:16,970 --> 00:21:20,200
a connection started to move data past

00:21:18,890 --> 00:21:23,240
it and set up that pre deluxe

00:21:20,200 --> 00:21:25,580
configuration we've legitimized that

00:21:23,240 --> 00:21:27,230
path and we no longer need to do

00:21:25,580 --> 00:21:30,110
netfilter stuff on it anymore but you

00:21:27,230 --> 00:21:31,910
may want to change the path later and

00:21:30,110 --> 00:21:39,590
start dropping packets in an ANOVA

00:21:31,910 --> 00:21:43,100
session so anyways yes the second hook

00:21:39,590 --> 00:21:44,780
up and on the DC but we still doing in

00:21:43,100 --> 00:21:46,550
that filter stuff but this is taking it

00:21:44,780 --> 00:21:49,490
one step further and limiting layers

00:21:46,550 --> 00:21:51,800
altogether yeah yeah so it is a radical

00:21:49,490 --> 00:21:54,770
I did it and I said to stop it this is

00:21:51,800 --> 00:21:56,810
not going to be tomorrow if I go to more

00:21:54,770 --> 00:21:58,850
fundamental question so if your angles

00:21:56,810 --> 00:22:01,160
salvo you have multiple nics how does

00:21:58,850 --> 00:22:05,090
this work every you can have passed

00:22:01,160 --> 00:22:06,230
socket q and every Nick let you got you

00:22:05,090 --> 00:22:07,610
have to do that we have to have this

00:22:06,230 --> 00:22:12,380
relationship at the cube there's a

00:22:07,610 --> 00:22:14,330
finger between what the same socket so

00:22:12,380 --> 00:22:16,550
you're basically moving the socket Q

00:22:14,330 --> 00:22:18,800
into the neck correct yeah basically and

00:22:16,550 --> 00:22:21,440
so if I have techniques on a server I

00:22:18,800 --> 00:22:23,540
will have ten socket cues on each one on

00:22:21,440 --> 00:22:27,500
each neck no only one nick is receiving

00:22:23,540 --> 00:22:31,100
traffic for a particular socket oh well

00:22:27,500 --> 00:22:34,040
if you have that kind of flapping routes

00:22:31,100 --> 00:22:36,770
then that this is not for you yet

00:22:34,040 --> 00:22:39,320
there's no definite unique Magli good

00:22:36,770 --> 00:22:44,200
will need to set explosivity I want this

00:22:39,320 --> 00:22:47,060
feature this saga duct or whatever that

00:22:44,200 --> 00:22:49,220
and like we also best bypass the nest

00:22:47,060 --> 00:22:51,710
builder stuff and this there's a lot of

00:22:49,220 --> 00:22:53,810
implications going on just as people can

00:22:51,710 --> 00:22:55,880
explicitly not configure any net filter

00:22:53,810 --> 00:22:57,170
rules people can explicitly say I want

00:22:55,880 --> 00:23:00,260
these cues to go straight from the

00:22:57,170 --> 00:23:01,610
device incident their socket I mean

00:23:00,260 --> 00:23:03,830
to change all your containers with

00:23:01,610 --> 00:23:07,100
yourself right baby I might as well do

00:23:03,830 --> 00:23:09,860
this right but but I think actually that

00:23:07,100 --> 00:23:11,810
the multi-cut setup could move to work

00:23:09,860 --> 00:23:14,300
if the action is consistent over apple

00:23:11,810 --> 00:23:16,070
devices and if the house key is like

00:23:14,300 --> 00:23:19,280
synchronized between of them that said

00:23:16,070 --> 00:23:22,310
maybe if yeah yeah but I think it put it

00:23:19,280 --> 00:23:24,250
yeah okay yeah yeah that's that's why

00:23:22,310 --> 00:23:27,680
we're afraid of doing it right yeah

00:23:24,250 --> 00:23:32,090
that's the if if it all of sudden goes

00:23:27,680 --> 00:23:34,010
out of sync yeah that does it doesn't be

00:23:32,090 --> 00:23:37,670
like done optimistically and be we

00:23:34,010 --> 00:23:39,290
actually check the RSS hash or the hash

00:23:37,670 --> 00:23:41,270
actually and we can disable this feature

00:23:39,290 --> 00:23:42,830
in this back as soon we see like one

00:23:41,270 --> 00:23:45,470
metro card is not cooperating for

00:23:42,830 --> 00:23:46,580
example yeah I was also considering

00:23:45,470 --> 00:23:49,040
stuff like that but that's it's

00:23:46,580 --> 00:23:51,590
difficult to do without the heart that

00:23:49,040 --> 00:23:59,000
the performers Palin see you the check

00:23:51,590 --> 00:24:01,790
costs right yeah how is this different

00:23:59,000 --> 00:24:02,690
than our DNA I'm just asking because the

00:24:01,790 --> 00:24:04,790
only difference between whether I

00:24:02,690 --> 00:24:07,310
subscribe there and and what an RDA me

00:24:04,790 --> 00:24:11,120
Nick does is that the the audio mainak

00:24:07,310 --> 00:24:12,470
is able to it has a stack of its own but

00:24:11,120 --> 00:24:14,390
if you're bypassing the whole stack

00:24:12,470 --> 00:24:15,590
anyway why wouldn't you just bother just

00:24:14,390 --> 00:24:20,240
forget it and just use the rtm a

00:24:15,590 --> 00:24:21,500
capability to Nick this is do you don't

00:24:20,240 --> 00:24:22,880
have to do the data it makes me this is

00:24:21,500 --> 00:24:26,420
looking provide the data buffers that

00:24:22,880 --> 00:24:28,250
this the did this doesn't think it's the

00:24:26,420 --> 00:24:30,260
next slide you you're going to complain

00:24:28,250 --> 00:24:33,950
about I might jumping ahead again yeah

00:24:30,260 --> 00:24:36,380
no that's so in that side i would say

00:24:33,950 --> 00:24:38,870
yes maybe you're right there but not not

00:24:36,380 --> 00:24:40,220
nothin about two circuits because

00:24:38,870 --> 00:24:44,060
decided i want to stay in two seconds

00:24:40,220 --> 00:24:46,340
once it go here when that one stay in

00:24:44,060 --> 00:24:49,850
soccer and i'm going to use like data

00:24:46,340 --> 00:24:52,010
provided by backing pages for some comes

00:24:49,850 --> 00:24:53,780
from something that's not might not be

00:24:52,010 --> 00:24:56,480
did front directly from the socket and

00:24:53,780 --> 00:24:59,150
the idea may kiss me i can give two

00:24:56,480 --> 00:25:00,950
pages so just something with the memory

00:24:59,150 --> 00:25:04,070
education but RDMA and not too familiar

00:25:00,950 --> 00:25:06,530
there but the other the more easy thing

00:25:04,070 --> 00:25:08,870
we could do which would be like

00:25:06,530 --> 00:25:12,440
channelizing a ball socket and using

00:25:08,870 --> 00:25:13,900
HTTP for that so I could I could say

00:25:12,440 --> 00:25:17,660
well I wanted TCP

00:25:13,900 --> 00:25:20,600
and I want a filter for tcpdump but that

00:25:17,660 --> 00:25:22,150
food over TCP dump if I if I just have

00:25:20,600 --> 00:25:25,220
to plumb second I can steal the packet

00:25:22,150 --> 00:25:27,470
that a fever for TCP dump it's actually

00:25:25,220 --> 00:25:30,950
a eep eep air filters I could just load

00:25:27,470 --> 00:25:34,900
that as my htp filter and if I find it

00:25:30,950 --> 00:25:38,060
if I find it if I had to have a filter

00:25:34,900 --> 00:25:41,510
promising I put into a specific receive

00:25:38,060 --> 00:25:44,000
queue I can is she achieved a single

00:25:41,510 --> 00:25:46,850
producer pod and I wouldn't need to lock

00:25:44,000 --> 00:25:48,770
that part when I put it in and the user

00:25:46,850 --> 00:25:51,560
space can promise they were only run and

00:25:48,770 --> 00:25:57,410
and putting packets out from a single

00:25:51,560 --> 00:26:01,960
single a single process I could sort of

00:25:57,410 --> 00:26:06,590
creates like a TCP dump channel

00:26:01,960 --> 00:26:13,190
interface it's also sort of a radical

00:26:06,590 --> 00:26:15,770
idea now have to only who know i can i

00:26:13,190 --> 00:26:20,570
can run more it's not a problem that i

00:26:15,770 --> 00:26:22,550
can have bro yes so just thinking about

00:26:20,570 --> 00:26:24,140
it essentially so you keep calling it

00:26:22,550 --> 00:26:25,820
single producer said that single

00:26:24,140 --> 00:26:28,250
producer could be multiplexed over

00:26:25,820 --> 00:26:31,580
multiple of your socket channels

00:26:28,250 --> 00:26:33,440
couldn't it no i don't this this this is

00:26:31,580 --> 00:26:36,530
fun to receive side on the Nick so all

00:26:33,440 --> 00:26:38,570
right I'm going to for example for

00:26:36,530 --> 00:26:41,090
example if you took received packets

00:26:38,570 --> 00:26:42,890
digging enabled it on your 1q that one Q

00:26:41,090 --> 00:26:46,220
then has traffic multiplex to multiple

00:26:42,890 --> 00:26:48,920
CPUs then in that case you'd have one

00:26:46,220 --> 00:26:50,630
cube eating maybe eight CPUs and you

00:26:48,920 --> 00:26:52,790
could be okay I hand this one to this

00:26:50,630 --> 00:26:54,860
socket via a la clustering anyone to

00:26:52,790 --> 00:26:56,960
this socket via la clustering so on and

00:26:54,860 --> 00:27:00,070
so forth it basically span the whole set

00:26:56,960 --> 00:27:03,920
of CPUs with just our PS doing the

00:27:00,070 --> 00:27:05,480
distribution instead of RSS so you could

00:27:03,920 --> 00:27:07,190
actually get away with one ring feeding

00:27:05,480 --> 00:27:08,810
multiple sockets which would help to

00:27:07,190 --> 00:27:11,600
reduce the total ring count needed

00:27:08,810 --> 00:27:16,430
theoretically so the receipt wouldn't it

00:27:11,600 --> 00:27:18,620
up a problem for their seat I I've

00:27:16,430 --> 00:27:20,060
looked at I can just poke I can't test

00:27:18,620 --> 00:27:22,730
the nephew schedule which makes me

00:27:20,060 --> 00:27:25,130
support that it's okay even though when

00:27:22,730 --> 00:27:27,130
you have like one receive bringing a cue

00:27:25,130 --> 00:27:29,050
number this Q number we can actually add

00:27:27,130 --> 00:27:30,280
actually have to a simply affinity stuff

00:27:29,050 --> 00:27:32,440
so we can actually jump between

00:27:30,280 --> 00:27:33,820
different sub views so I thought oh this

00:27:32,440 --> 00:27:36,340
is going to be a problem but the

00:27:33,820 --> 00:27:40,780
Navigator actually protects us from from

00:27:36,340 --> 00:27:44,710
the desert yes we'll say okay I see this

00:27:40,780 --> 00:27:45,700
packet on my preferred row rps gives you

00:27:44,710 --> 00:27:47,790
the same kind of protection because

00:27:45,700 --> 00:27:50,620
it'll be okay or see this pack on cpu 0

00:27:47,790 --> 00:27:52,330
he goes to cpu 5 know you'll be

00:27:50,620 --> 00:27:54,520
processed over there in that backlog

00:27:52,330 --> 00:27:55,750
yeah so it essentially just becomes you

00:27:54,520 --> 00:27:57,760
know that's kind of the whole point of

00:27:55,750 --> 00:28:01,360
our PS take a single cute and be able to

00:27:57,760 --> 00:28:03,010
treat it like multiple queues yeah yeah

00:28:01,360 --> 00:28:05,830
but they never have this team boxing

00:28:03,010 --> 00:28:07,690
step like an IPS by guys in my growl

00:28:05,830 --> 00:28:10,270
tiger's eye I don't need to allocate or

00:28:07,690 --> 00:28:13,570
anything I'll just take whatever comes

00:28:10,270 --> 00:28:17,110
in down this receive ring and pump it

00:28:13,570 --> 00:28:19,120
directly into right of cute so you wanna

00:28:17,110 --> 00:28:20,740
copy it because they wanted to make the

00:28:19,120 --> 00:28:22,180
reason they a packet like even packet

00:28:20,740 --> 00:28:25,840
our rec serious slow is that it has

00:28:22,180 --> 00:28:26,980
cannot begin to concern and so I guess

00:28:25,840 --> 00:28:29,350
the question is do you are you gonna

00:28:26,980 --> 00:28:30,580
like is this xtp dump mean this channel

00:28:29,350 --> 00:28:33,310
is going to get this packet nobody else

00:28:30,580 --> 00:28:36,130
is ever gonna see it because you saw

00:28:33,310 --> 00:28:38,110
yeah that's that's the sort of a we can

00:28:36,130 --> 00:28:42,160
still change change change the adoption

00:28:38,110 --> 00:28:44,050
is powerful for xtp right but for now

00:28:42,160 --> 00:28:46,950
the model is a little bit that we don't

00:28:44,050 --> 00:28:49,330
allow sharing of these pages for xtp

00:28:46,950 --> 00:28:51,370
noble like you mention a packet right

00:28:49,330 --> 00:28:54,820
well AI facut is slow because it's a

00:28:51,370 --> 00:28:56,860
copy cuz they can steal stuff and I she

00:28:54,820 --> 00:28:59,950
didn't know actually pinch market it's

00:28:56,860 --> 00:29:02,350
fifteen percent so if you park bench

00:28:59,950 --> 00:29:04,540
market and the benchmark naively give

00:29:02,350 --> 00:29:06,250
real thing it's like thirty percent but

00:29:04,540 --> 00:29:10,090
it's actually at the cash mesh versus

00:29:06,250 --> 00:29:12,700
the problem I've written code that

00:29:10,090 --> 00:29:18,550
switch from packet read and to packet RX

00:29:12,700 --> 00:29:21,190
ring and it didn't get any faster the v3

00:29:18,550 --> 00:29:23,050
was like five percent better but BTW but

00:29:21,190 --> 00:29:23,650
it was pretty much the same so i guess

00:29:23,050 --> 00:29:25,420
then

00:29:23,650 --> 00:29:27,670
if you look at the packet socket handler

00:29:25,420 --> 00:29:29,020
it makes a copy it runs the BPF program

00:29:27,670 --> 00:29:30,760
on the original packet because it

00:29:29,020 --> 00:29:31,990
doesn't matter waste its time now though

00:29:30,760 --> 00:29:34,060
you've got a packet okie who you are

00:29:31,990 --> 00:29:36,250
here's a copy but if you could steal it

00:29:34,060 --> 00:29:38,440
right but but that's how you agree silly

00:29:36,250 --> 00:29:39,970
trade-off semantics with speed but you

00:29:38,440 --> 00:29:41,470
can't those they think because you do

00:29:39,970 --> 00:29:46,350
have to make a copy if you handed to do

00:29:41,470 --> 00:29:48,700
sockets yeah in silence in such weird

00:29:46,350 --> 00:29:50,980
yeah but that's also why I have version

00:29:48,700 --> 00:29:52,900
version bond the first iteration if you

00:29:50,980 --> 00:29:56,350
use a copyright the second we could do a

00:29:52,900 --> 00:29:58,360
serial copy and two but that's that that

00:29:56,350 --> 00:30:03,780
Patrick Eisenberg and in the memory area

00:29:58,360 --> 00:30:07,090
which I'm actually doing so so that's so

00:30:03,780 --> 00:30:08,680
how much so I won't want to change the

00:30:07,090 --> 00:30:15,250
topic unless there's more questions

00:30:08,680 --> 00:30:19,180
within the first area so this is quite a

00:30:15,250 --> 00:30:21,730
big big thing to receive button like and

00:30:19,180 --> 00:30:24,490
it was a little bit larger than I first

00:30:21,730 --> 00:30:27,370
imagined because it's actually the

00:30:24,490 --> 00:30:30,370
multiple things act to solve which is

00:30:27,370 --> 00:30:32,260
transmitted beside be figuring out this

00:30:30,370 --> 00:30:34,150
this you did a lot of smaller tumor

00:30:32,260 --> 00:30:36,040
stations but the big thing was figure

00:30:34,150 --> 00:30:38,350
out X bit more and the tail pointer

00:30:36,040 --> 00:30:41,320
ringing the doorbell that's one now we

00:30:38,350 --> 00:30:43,990
get superfast speed but the receipt part

00:30:41,320 --> 00:30:47,500
as multiple things I have to fix so

00:30:43,990 --> 00:30:49,270
there's the latency when the first cigar

00:30:47,500 --> 00:30:51,670
have to do some lady's head because we

00:30:49,270 --> 00:30:53,950
have cash mess when we read the first

00:30:51,670 --> 00:30:57,460
packet there's hot some hardware support

00:30:53,950 --> 00:31:00,760
to help help that so and I also wants to

00:30:57,460 --> 00:31:02,860
do some in change how did receive driver

00:31:00,760 --> 00:31:05,200
got all the way down the driver how we

00:31:02,860 --> 00:31:09,220
we are not taking a message of bulking

00:31:05,200 --> 00:31:12,700
or what I call stages and we have some

00:31:09,220 --> 00:31:16,360
error in the MM park elegant free api's

00:31:12,700 --> 00:31:18,610
we have to address and I hit this text

00:31:16,360 --> 00:31:20,890
processing stages basically that's I

00:31:18,610 --> 00:31:22,810
cash optimization is its basic related

00:31:20,890 --> 00:31:26,590
to this ring buffer stuff it if I

00:31:22,810 --> 00:31:30,960
interpret all code in EPF the code would

00:31:26,590 --> 00:31:30,960
actually only big data and not I cash

00:31:32,570 --> 00:31:43,800
this yeah well so I think several people

00:31:40,110 --> 00:31:46,110
had difficulty understanding this Eric

00:31:43,800 --> 00:31:47,580
status or I'll sort of go through it

00:31:46,110 --> 00:31:51,630
what I'm what i mean by these receive

00:31:47,580 --> 00:31:54,720
stages so it's sort of an instruction

00:31:51,630 --> 00:31:56,460
cache optimization and used to see this

00:31:54,720 --> 00:32:00,390
like working on a big tough packets

00:31:56,460 --> 00:32:04,080
that's sort of in the lower layer of the

00:32:00,390 --> 00:32:05,730
earth which each day so what I'm saying

00:32:04,080 --> 00:32:08,370
is that the drivers have missed

00:32:05,730 --> 00:32:10,170
opportunities we already have received

00:32:08,370 --> 00:32:12,090
parking but we don't take advantage of

00:32:10,170 --> 00:32:14,820
it the drivers today we'll just take one

00:32:12,090 --> 00:32:16,530
pack it out to the receive ring and call

00:32:14,820 --> 00:32:19,470
it do all the things that has to do with

00:32:16,530 --> 00:32:21,870
it and call them that the full networks

00:32:19,470 --> 00:32:23,310
like when it comes back as a hundred

00:32:21,870 --> 00:32:24,870
percent others have flushed their

00:32:23,310 --> 00:32:26,160
instruction cast and have to even have

00:32:24,870 --> 00:32:29,070
to reload instruction cast off the

00:32:26,160 --> 00:32:31,350
drivers themselves so there's

00:32:29,070 --> 00:32:34,170
opportunities we can you can take care

00:32:31,350 --> 00:32:36,060
and we stole on cache misses because we

00:32:34,170 --> 00:32:38,040
want to read two packets the first thing

00:32:36,060 --> 00:32:40,020
we do is need to read the head after

00:32:38,040 --> 00:32:44,190
packet figure out what kind of easy type

00:32:40,020 --> 00:32:51,320
it is and you don't have any knowledge

00:32:44,190 --> 00:32:55,680
on how many packets are Brady so so my

00:32:51,320 --> 00:32:58,020
claim is that well if the receiver ring

00:32:55,680 --> 00:33:00,720
contains multiple rated packets that

00:32:58,020 --> 00:33:02,610
means that can only mean that the

00:33:00,720 --> 00:33:05,640
colonel has to slow processing these

00:33:02,610 --> 00:33:07,380
packets so we under state where orders

00:33:05,640 --> 00:33:10,380
will be small micro bursts but that's

00:33:07,380 --> 00:33:12,600
also ok so what we should do is switch

00:33:10,380 --> 00:33:14,730
into a more efficient mode so i know

00:33:12,600 --> 00:33:17,520
people see this as a controversial idea

00:33:14,730 --> 00:33:20,480
so we stop seeing this as individual

00:33:17,520 --> 00:33:22,890
packets in the receive ring and and

00:33:20,480 --> 00:33:26,540
instead seed of as a vector of packets

00:33:22,890 --> 00:33:30,360
that we need to process and as a whole

00:33:26,540 --> 00:33:33,460
in the driver there's not too many

00:33:30,360 --> 00:33:37,120
people objecting that's good

00:33:33,460 --> 00:33:41,240
yeah let me add something here that

00:33:37,120 --> 00:33:43,159
there are three basic stages when device

00:33:41,240 --> 00:33:45,679
driver receiver I actually have this

00:33:43,159 --> 00:33:49,129
year ok so it's what all this the stages

00:33:45,679 --> 00:33:51,679
yeah um so you can see say if you agree

00:33:49,129 --> 00:33:57,879
with it I agree and I view this

00:33:51,679 --> 00:34:02,149
optimization I think in 10 guys here I

00:33:57,879 --> 00:34:04,460
the basic idea here is to split those

00:34:02,149 --> 00:34:05,750
pages and doing do them all at once for

00:34:04,460 --> 00:34:09,800
all the packets that already in the

00:34:05,750 --> 00:34:14,060
queue instead of doing doing the whole

00:34:09,800 --> 00:34:18,079
process for each packet individually

00:34:14,060 --> 00:34:21,020
yeah yeah so I don't think you've seen

00:34:18,079 --> 00:34:24,200
this one with it xtp also seeds i want

00:34:21,020 --> 00:34:27,139
to also i call it drag it's in two

00:34:24,200 --> 00:34:32,000
stages just to explain what what I want

00:34:27,139 --> 00:34:34,399
that's not what we had today so just the

00:34:32,000 --> 00:34:36,500
first thing is to we take like we look

00:34:34,399 --> 00:34:37,760
at the to receive the scriptures and see

00:34:36,500 --> 00:34:40,819
if they're ready that's basically what

00:34:37,760 --> 00:34:43,669
we do always before going on to the next

00:34:40,819 --> 00:34:46,399
step but now we'll just take a number of

00:34:43,669 --> 00:34:49,819
them maybe like eight or something and

00:34:46,399 --> 00:34:52,310
we start prefacing in too late to the l2

00:34:49,819 --> 00:34:54,710
cache and then then we have to http

00:34:52,310 --> 00:34:57,349
first stage where we actually called xtp

00:34:54,710 --> 00:35:01,609
handing it over to the what i called the

00:34:57,349 --> 00:35:03,770
packet page and it doesn't do the action

00:35:01,609 --> 00:35:05,900
immediately instead it marks like the

00:35:03,770 --> 00:35:09,770
vector what what kind of action it's if

00:35:05,900 --> 00:35:11,150
you do that minimizes the whole

00:35:09,770 --> 00:35:13,130
instruction uses there and it's

00:35:11,150 --> 00:35:16,640
basically these four loops going on and

00:35:13,130 --> 00:35:18,859
and then then the important part here to

00:35:16,640 --> 00:35:21,609
understand is after this xtp stage what

00:35:18,859 --> 00:35:23,420
will be left is all the HTTP pass

00:35:21,609 --> 00:35:28,010
package we had to go through the normal

00:35:23,420 --> 00:35:30,619
stack and that means that that the HTTP

00:35:28,010 --> 00:35:32,119
code that get attitude it doesn't need

00:35:30,619 --> 00:35:35,109
to be like if there was one packet

00:35:32,119 --> 00:35:37,130
surpass call the entire stack gets its

00:35:35,109 --> 00:35:39,980
instruction cache brush and come back

00:35:37,130 --> 00:35:41,090
and actually reload the EBV program from

00:35:39,980 --> 00:35:44,990
from

00:35:41,090 --> 00:35:47,570
from from memory so so that's important

00:35:44,990 --> 00:35:49,250
but after this stage there are 0 BB HD

00:35:47,570 --> 00:35:50,990
peep aspects that need to go to the

00:35:49,250 --> 00:35:53,390
state it'll to the payment we have not

00:35:50,990 --> 00:35:54,830
allocated esta página yes actually and

00:35:53,390 --> 00:35:58,190
now we start allocating escapees and

00:35:54,830 --> 00:36:00,260
populated and set up set it up so we can

00:35:58,190 --> 00:36:03,830
sort of the next stage can for each

00:36:00,260 --> 00:36:06,110
packet call call the stack and then

00:36:03,830 --> 00:36:07,310
there's some optimizations that someone

00:36:06,110 --> 00:36:11,450
else proposed so this is basically

00:36:07,310 --> 00:36:14,540
contained in the driver so um until in

00:36:11,450 --> 00:36:17,060
RFC on the e1000 driver yeah did this um

00:36:14,540 --> 00:36:18,650
because I was a because I wanted we want

00:36:17,060 --> 00:36:20,720
to do XD peony 1000 which is maybe a

00:36:18,650 --> 00:36:23,840
side topic but also because i was using

00:36:20,720 --> 00:36:25,490
it to explain some of this stuff to one

00:36:23,840 --> 00:36:29,210
of the developers working on i-40 not

00:36:25,490 --> 00:36:31,850
these guys here but somebody else and

00:36:29,210 --> 00:36:34,340
then the other comment is we do a mem

00:36:31,850 --> 00:36:35,810
set on the SQ be right now and i'm not

00:36:34,340 --> 00:36:39,830
entirely sure we need to do that at all

00:36:35,810 --> 00:36:41,240
it's that we promptly right into all of

00:36:39,830 --> 00:36:43,580
the fields that are needed by the driver

00:36:41,240 --> 00:36:45,920
and i don't think the CB field is is

00:36:43,580 --> 00:36:48,950
guaranteed to be coherent across layers

00:36:45,920 --> 00:36:52,970
so and as far as i can tell it doesn't

00:36:48,950 --> 00:36:55,100
actually we have certain special cases

00:36:52,970 --> 00:36:56,960
where we guarantee that it the value

00:36:55,100 --> 00:36:58,460
will survive layers but they're few and

00:36:56,960 --> 00:37:00,260
far between and it's not coming out of

00:36:58,460 --> 00:37:02,480
the driver on the receive side no no not

00:37:00,260 --> 00:37:04,160
that case its other situation so this

00:37:02,480 --> 00:37:05,360
just in your perf numbers that you're

00:37:04,160 --> 00:37:07,450
not showing here but you sure you should

00:37:05,360 --> 00:37:09,410
this memset it's being a huge cost but i

00:37:07,450 --> 00:37:12,620
really don't think it's needed at all

00:37:09,410 --> 00:37:14,930
actually and that to showcase thing we

00:37:12,620 --> 00:37:16,220
can reduce the memset just as just do it

00:37:14,930 --> 00:37:17,480
and then do a couple there's a few

00:37:16,220 --> 00:37:18,950
fields that do you need to be set but

00:37:17,480 --> 00:37:20,570
these can just be written to directly

00:37:18,950 --> 00:37:24,520
you don't need to do a giant memset over

00:37:20,570 --> 00:37:24,520
the four lines yeah

00:37:31,020 --> 00:37:36,340
you have thousands of course sites in

00:37:33,640 --> 00:37:39,760
the camera using auto Cascadia so maybe

00:37:36,340 --> 00:37:42,010
one of them is assuming there's this skb

00:37:39,760 --> 00:37:43,510
CB is clear so now we need to code it

00:37:42,010 --> 00:37:46,090
all the code in garner before the

00:37:43,510 --> 00:37:48,130
media's change I guess yeah it's totally

00:37:46,090 --> 00:37:50,440
doable because a little break okay

00:37:48,130 --> 00:37:53,710
because introduce a new function that

00:37:50,440 --> 00:37:55,630
only the receive yeah sure we can have

00:37:53,710 --> 00:37:57,250
you look at the sign of dysfunction we

00:37:55,630 --> 00:37:59,710
already have multiple function lino

00:37:57,250 --> 00:38:02,200
photo writings transmitted whatever so

00:37:59,710 --> 00:38:05,470
we can hear like I cash brochure is not

00:38:02,200 --> 00:38:07,600
matter so just hey just for one thing

00:38:05,470 --> 00:38:09,250
I'd ask for when when you're doing all

00:38:07,600 --> 00:38:11,470
this work is that you think about when

00:38:09,250 --> 00:38:14,200
you're you think about improving the API

00:38:11,470 --> 00:38:15,760
for drivers to have a have a cleaner API

00:38:14,200 --> 00:38:17,380
tooth either that's both easier

00:38:15,760 --> 00:38:19,330
hopefully to understand and implement to

00:38:17,380 --> 00:38:21,910
without mistakes right so that maybe

00:38:19,330 --> 00:38:24,370
this API that when you're not just

00:38:21,910 --> 00:38:26,650
focused on doing the packet pages right

00:38:24,370 --> 00:38:29,590
but that you actually help the drivers

00:38:26,650 --> 00:38:31,120
by having a packet page receive call so

00:38:29,590 --> 00:38:32,620
that we don't have to mess with the sk

00:38:31,120 --> 00:38:34,300
BS anymore there's no point in having a

00:38:32,620 --> 00:38:35,830
driver populate the skb there's no point

00:38:34,300 --> 00:38:37,540
in having the driver call xdp and do a

00:38:35,830 --> 00:38:38,800
drop there's no point in doing any of

00:38:37,540 --> 00:38:41,470
that let the drivers handle the

00:38:38,800 --> 00:38:43,810
descriptor and hand it to you yeah right

00:38:41,470 --> 00:38:45,190
and and that work that's common to all

00:38:43,810 --> 00:38:46,840
the device drivers that want to use this

00:38:45,190 --> 00:38:49,300
subsystem just moves up into into the

00:38:46,840 --> 00:38:51,160
next layer yeah that's right and there's

00:38:49,300 --> 00:38:54,160
no really cool there's no relevance

00:38:51,160 --> 00:38:56,020
really if if we can if we can build it

00:38:54,160 --> 00:38:58,150
like a mini structure like a metadata

00:38:56,020 --> 00:39:00,520
structure that the driver provides that

00:38:58,150 --> 00:39:02,020
is handed to the skb builder up above

00:39:00,520 --> 00:39:03,820
and we can provide all the information

00:39:02,020 --> 00:39:06,910
that our descriptor gave basically

00:39:03,820 --> 00:39:09,010
extracting it right into what the skb

00:39:06,910 --> 00:39:10,570
could need to be filled out and then you

00:39:09,010 --> 00:39:12,040
use it or you don't we already had all

00:39:10,570 --> 00:39:13,750
the info it's almost nothing to fill up

00:39:12,040 --> 00:39:15,370
that little tiny structure right yeah

00:39:13,750 --> 00:39:16,810
we're we're not allocating a full skb

00:39:15,370 --> 00:39:18,850
what you talked about the mem said I

00:39:16,810 --> 00:39:21,340
just pushed that I actually agree that

00:39:18,850 --> 00:39:23,710
that's their small talk too much later

00:39:21,340 --> 00:39:25,330
just missed the point because I think

00:39:23,710 --> 00:39:26,650
we'll do this first and then then we can

00:39:25,330 --> 00:39:28,390
push this up and it's a really good

00:39:26,650 --> 00:39:30,820
basically you're proposing to push up

00:39:28,390 --> 00:39:33,160
don't let the driver elekta escapee and

00:39:30,820 --> 00:39:35,109
just push up these

00:39:33,160 --> 00:39:37,420
yeah but this way you are adding another

00:39:35,109 --> 00:39:42,789
overhead of processing the new me that

00:39:37,420 --> 00:39:44,500
metadata which will add new yeah cpu

00:39:42,789 --> 00:39:46,359
cycles to the receipt path yeah that

00:39:44,500 --> 00:39:48,430
that way I would do it I think which

00:39:46,359 --> 00:39:51,490
would be actually to allocate the same

00:39:48,430 --> 00:39:54,329
size as stays kb and pass that up and

00:39:51,490 --> 00:39:57,579
then we use that father-son escape yeah

00:39:54,329 --> 00:40:01,569
there's a 30 heck yeah but you make me a

00:39:57,579 --> 00:40:03,400
copy or something yeah but we already

00:40:01,569 --> 00:40:05,289
set this in for me I think yeah but

00:40:03,400 --> 00:40:07,180
that's definitely more chocolate yeah I

00:40:05,289 --> 00:40:08,920
think it's better to keep daisuke be

00:40:07,180 --> 00:40:11,020
inside that device driver yeah so this

00:40:08,920 --> 00:40:12,730
is basically a little bit in this area

00:40:11,020 --> 00:40:14,500
that the more controversial is like to

00:40:12,730 --> 00:40:15,940
deliver a portal to the network stack

00:40:14,500 --> 00:40:20,020
because now we're changing the network's

00:40:15,940 --> 00:40:23,349
like ap is and how that goes on and it

00:40:20,020 --> 00:40:25,329
works acree actually proposed some fc7

00:40:23,349 --> 00:40:27,400
the performance on was a really good of

00:40:25,329 --> 00:40:30,359
avoiding this instruction cache problem

00:40:27,400 --> 00:40:32,530
of just basic what happens here is that

00:40:30,359 --> 00:40:34,990
what he did he didn't do all these steps

00:40:32,530 --> 00:40:39,400
he just took tunnel drivin just about it

00:40:34,990 --> 00:40:42,700
calling the stack and just created skb

00:40:39,400 --> 00:40:45,730
list handled that affleck david has a as

00:40:42,700 --> 00:40:49,990
a Christian so this reminds me of the

00:40:45,730 --> 00:40:51,640
Giro thing if you bundle the things with

00:40:49,990 --> 00:40:53,589
skb is attached to them you're actually

00:40:51,640 --> 00:40:56,170
allocating more escapees because what gr

00:40:53,589 --> 00:40:58,630
0 does is it attaches it Pope it

00:40:56,170 --> 00:40:59,859
attaches to the end of an existing skb

00:40:58,630 --> 00:41:01,630
when the flow matches and then it gets

00:40:59,859 --> 00:41:04,990
rid of desk AP which could have been

00:41:01,630 --> 00:41:07,000
recycled into the next user the next

00:41:04,990 --> 00:41:08,829
packet that comes in to the stack so

00:41:07,000 --> 00:41:10,599
you'd be losing that you'd be actually

00:41:08,829 --> 00:41:13,510
using more sk bees in aggregate that

00:41:10,599 --> 00:41:17,109
doesn't this by that's the best best

00:41:13,510 --> 00:41:19,599
ipsa once if your proposal that you just

00:41:17,109 --> 00:41:21,730
push up this thing up which doesn't have

00:41:19,599 --> 00:41:23,349
advocated escapees yet actually it's

00:41:21,730 --> 00:41:25,180
actually better although you could look

00:41:23,349 --> 00:41:27,339
at it from another way the resident set

00:41:25,180 --> 00:41:28,660
size of these this skb cluster is like

00:41:27,339 --> 00:41:30,789
eight at a time or whatever and that

00:41:28,660 --> 00:41:32,920
might not hurt a lot it may actually

00:41:30,789 --> 00:41:34,750
still be faster to do but the dulcet

00:41:32,920 --> 00:41:37,750
escapees that also makes like the

00:41:34,750 --> 00:41:40,180
programming model much harder I think

00:41:37,750 --> 00:41:43,119
it's easier if we can keep all the skb

00:41:40,180 --> 00:41:44,430
code I think what would I her about like

00:41:43,119 --> 00:41:46,110
trust write novels like

00:41:44,430 --> 00:41:48,450
to basically do this function pointers

00:41:46,110 --> 00:41:51,420
so we actually do like I I think the

00:41:48,450 --> 00:41:53,250
basic idea would be to always like to

00:41:51,420 --> 00:41:54,630
processing and just give back a function

00:41:53,250 --> 00:41:56,760
pointer for the next processing stage

00:41:54,630 --> 00:42:00,150
and then after that we basically just

00:41:56,760 --> 00:42:01,860
look which s KBS the same next function

00:42:00,150 --> 00:42:03,630
point end and they execute all those sk

00:42:01,860 --> 00:42:06,180
disposal next function something like

00:42:03,630 --> 00:42:08,520
that but i would like to do like

00:42:06,180 --> 00:42:09,960
processing of an esque of one thing

00:42:08,520 --> 00:42:12,210
that's kept in one functional not like

00:42:09,960 --> 00:42:21,210
like while loops all the way around that

00:42:12,210 --> 00:42:23,520
gets very dirty so I so it one more

00:42:21,210 --> 00:42:25,800
comment so if you start pushing like a

00:42:23,520 --> 00:42:27,480
bunch of packets upstream let this for

00:42:25,800 --> 00:42:29,130
the sake of argument assume is going to

00:42:27,480 --> 00:42:32,250
some UDP socket and they're all being

00:42:29,130 --> 00:42:33,720
dropped right so maybe a good idea to

00:42:32,250 --> 00:42:37,020
you're looking at the feedback that

00:42:33,720 --> 00:42:41,370
comes back or what the return codes are

00:42:37,020 --> 00:42:43,860
for each packet is sent yep so using 64

00:42:41,370 --> 00:42:45,560
packets one gets through the elders the

00:42:43,860 --> 00:42:48,690
buffer is full and you start dropping

00:42:45,560 --> 00:42:50,880
yeah what's is that estimate that the

00:42:48,690 --> 00:42:54,090
life goes on or that's what there's not

00:42:50,880 --> 00:42:55,740
big no big difference and well we're

00:42:54,090 --> 00:42:58,070
sending one pocket at a time before and

00:42:55,740 --> 00:43:01,970
now yeah of course now you've made the

00:42:58,070 --> 00:43:04,230
what is your quarter they did not be not

00:43:01,970 --> 00:43:07,380
actually only passed a dog but Esther

00:43:04,230 --> 00:43:10,020
also be useful something to think about

00:43:07,380 --> 00:43:13,170
is probably use that information that

00:43:10,020 --> 00:43:15,180
comes back to do something meaningful

00:43:13,170 --> 00:43:17,970
maybe don't send it the rest of the

00:43:15,180 --> 00:43:20,700
packets up or schedule something to be

00:43:17,970 --> 00:43:24,180
restarted afterwards or it's all so

00:43:20,700 --> 00:43:25,710
complicated when you have this bunch of

00:43:24,180 --> 00:43:27,840
packets may be going through different

00:43:25,710 --> 00:43:29,340
paths in the code right maybe some are

00:43:27,840 --> 00:43:31,710
being forwarded some are going to some

00:43:29,340 --> 00:43:35,220
TCP socket some things going to UDP

00:43:31,710 --> 00:43:38,340
socket yeah they're useful if you're the

00:43:35,220 --> 00:43:40,530
original idea out of the RSS may be

00:43:38,340 --> 00:43:44,730
shooting packets for a single flow on a

00:43:40,530 --> 00:43:49,080
single hardware Q then it's easier to

00:43:44,730 --> 00:43:50,840
control yeah due to time constraints I

00:43:49,080 --> 00:43:55,470
want to move on but

00:43:50,840 --> 00:43:57,240
so like David already talked about HD p

00:43:55,470 --> 00:43:58,859
HD pictures are all presentations

00:43:57,240 --> 00:44:01,859
there's also a hdb workshop you should

00:43:58,859 --> 00:44:04,790
go sit in but so even though it is not

00:44:01,859 --> 00:44:06,510
the XP thing that I'm talking about

00:44:04,790 --> 00:44:11,820
performance you cannot go without

00:44:06,510 --> 00:44:13,140
mentioning XP or so so this xtp actually

00:44:11,820 --> 00:44:15,510
basically start out but it's a way for

00:44:13,140 --> 00:44:18,330
me to to benchmark that the receive code

00:44:15,510 --> 00:44:21,140
path because I wanted to fix that as

00:44:18,330 --> 00:44:23,760
sort of section made things to fix

00:44:21,140 --> 00:44:25,830
that's how it started out and then then

00:44:23,760 --> 00:44:27,540
Tom and Alexei came around said we can

00:44:25,830 --> 00:44:30,750
actually do something useful about put

00:44:27,540 --> 00:44:36,000
this and David just called it the next

00:44:30,750 --> 00:44:38,790
big thing so that's great so it's basic

00:44:36,000 --> 00:44:40,560
what started as a that's just just a way

00:44:38,790 --> 00:44:43,350
for me to make sure Luke doing this but

00:44:40,560 --> 00:44:45,090
I call sumin benchmarking to to figure

00:44:43,350 --> 00:44:50,220
out where the different performance bond

00:44:45,090 --> 00:44:52,890
matures so I've been focused on using

00:44:50,220 --> 00:44:56,580
this to to Trent with the driver seat

00:44:52,890 --> 00:44:58,470
but legs and I think I already mentioned

00:44:56,580 --> 00:45:01,320
it that that's that it's that they've

00:44:58,470 --> 00:45:03,210
won 2-1 we had these numbers and they'll

00:45:01,320 --> 00:45:07,680
approve a concept and this is great

00:45:03,210 --> 00:45:11,670
let's just move on so it's a little bit

00:45:07,680 --> 00:45:14,220
evil to say because what what why not

00:45:11,670 --> 00:45:16,050
this facing a functional solution for

00:45:14,220 --> 00:45:17,970
him so let's ride with developers so

00:45:16,050 --> 00:45:20,310
actually do this stuff to fix their to

00:45:17,970 --> 00:45:22,680
receive bottlenecks which is great from

00:45:20,310 --> 00:45:23,850
my point of view so what important

00:45:22,680 --> 00:45:25,470
things to realize is that we have to

00:45:23,850 --> 00:45:27,840
change the mayor model to beat these

00:45:25,470 --> 00:45:33,210
rideable pages David already mentioned

00:45:27,840 --> 00:45:34,800
that so but some of the secret to the

00:45:33,210 --> 00:45:38,369
performance that we're seeing with X 2 P

00:45:34,800 --> 00:45:39,720
which we are all like where is that we

00:45:38,369 --> 00:45:42,330
actually avoid calling the memory layer

00:45:39,720 --> 00:45:46,859
that's the whole trick you basically

00:45:42,330 --> 00:45:49,140
only we drop packets it's basic you

00:45:46,859 --> 00:45:50,670
gotta do it faster you take the receiver

00:45:49,140 --> 00:45:52,710
and you look at the target and say oh

00:45:50,670 --> 00:45:55,170
this should be top what what is a drop

00:45:52,710 --> 00:45:58,410
actually well just reinsert it basically

00:45:55,170 --> 00:45:59,810
that ones that are receiving so you're

00:45:58,410 --> 00:46:01,910
doing one point I was thinking of and

00:45:59,810 --> 00:46:04,910
putting it back

00:46:01,910 --> 00:46:06,500
so that's that's really fast but you are

00:46:04,910 --> 00:46:07,789
we're also cheating ourselves a little

00:46:06,500 --> 00:46:10,460
bit right because we are not really

00:46:07,789 --> 00:46:11,839
calling the memory layer and so the

00:46:10,460 --> 00:46:16,789
driver implemented is different

00:46:11,839 --> 00:46:18,470
recycling techniques and I think we need

00:46:16,789 --> 00:46:20,630
a more generic solution especially when

00:46:18,470 --> 00:46:26,990
you want to transmit out of a lot of

00:46:20,630 --> 00:46:28,910
another device drivers exit path so yeah

00:46:26,990 --> 00:46:33,950
i'll talk about liberal about page full

00:46:28,910 --> 00:46:35,119
of my proposal so there's actually sort

00:46:33,950 --> 00:46:38,950
of a battle between memory and

00:46:35,119 --> 00:46:42,490
networking and at least for yep and

00:46:38,950 --> 00:46:45,380
going down that road of provoking

00:46:42,490 --> 00:46:49,490
bottlenecks in the memory case are using

00:46:45,380 --> 00:46:53,180
networking that's has been fun so a lot

00:46:49,490 --> 00:46:56,089
more work is needed so there's sort of

00:46:53,180 --> 00:46:58,940
two layers there's a locating skp itself

00:46:56,089 --> 00:47:02,059
which is the key memcache with the slap

00:46:58,940 --> 00:47:05,210
educators I've saves almost on Bella I

00:47:02,059 --> 00:47:06,920
want more more users of this interface

00:47:05,210 --> 00:47:10,039
and then there's a page elevator which

00:47:06,920 --> 00:47:11,299
ampuan they are taking a stance on

00:47:10,039 --> 00:47:13,970
graphs assures that baseline performance

00:47:11,299 --> 00:47:18,730
of the page educator is just outright

00:47:13,970 --> 00:47:21,710
wrong weekend it's not fast enough I

00:47:18,730 --> 00:47:24,650
described our recycling it's nice but it

00:47:21,710 --> 00:47:26,599
doesn't it can get some of the same

00:47:24,650 --> 00:47:30,460
performance things but it doesn't

00:47:26,599 --> 00:47:30,460
address all areas of problem

00:47:31,630 --> 00:47:36,600
so I can remember when it was but I

00:47:34,870 --> 00:47:38,950
discovered that the this we had this

00:47:36,600 --> 00:47:41,680
thing that the network's tank was always

00:47:38,950 --> 00:47:45,010
always hitting the slow path in the when

00:47:41,680 --> 00:47:48,250
we are releasing objects in the stopper

00:47:45,010 --> 00:47:53,290
ok sir so i went ahead and make the

00:47:48,250 --> 00:47:56,680
parking api's for for slapping sloop for

00:47:53,290 --> 00:48:01,390
for the slap a locator it's just a fall

00:47:56,680 --> 00:48:03,010
true like a fallback function but it's

00:48:01,390 --> 00:48:05,590
actually upstream and the network stack

00:48:03,010 --> 00:48:07,120
uses the free side it's also the most

00:48:05,590 --> 00:48:10,660
powerful side because we're hitting too

00:48:07,120 --> 00:48:12,970
slow path there the allocation side we

00:48:10,660 --> 00:48:15,400
don't use that because we don't know how

00:48:12,970 --> 00:48:21,430
many incoming is SK bees or packets

00:48:15,400 --> 00:48:23,440
available so we would this it's it's not

00:48:21,430 --> 00:48:25,240
not now that we have these stages and

00:48:23,440 --> 00:48:28,180
called the packet like we've discussed a

00:48:25,240 --> 00:48:30,040
little bit and and now we can sort of

00:48:28,180 --> 00:48:31,510
counter many escapees we need but in

00:48:30,040 --> 00:48:34,450
reality we cannot count them anyway

00:48:31,510 --> 00:48:35,800
because this is jia going on so it's

00:48:34,450 --> 00:48:39,520
even though right now I would have

00:48:35,800 --> 00:48:41,860
account to when I send it up to the to

00:48:39,520 --> 00:48:46,180
the network stack I could do a bulk a

00:48:41,860 --> 00:48:48,180
lot there but due to dr g SL i actually

00:48:46,180 --> 00:48:51,340
have to wait doing to sparkle up so i

00:48:48,180 --> 00:48:54,220
was introduced a kt bug api which is

00:48:51,340 --> 00:48:56,860
completely generic you don't have to

00:48:54,220 --> 00:49:01,270
sell that what s KP what slap a label

00:48:56,860 --> 00:49:03,130
came from yeah i'm advocating for more

00:49:01,270 --> 00:49:07,390
use cases as you is actually a critical

00:49:03,130 --> 00:49:10,570
use case i think we don't have time to

00:49:07,390 --> 00:49:13,570
discuss all these so this is a more

00:49:10,570 --> 00:49:16,600
interesting slide for a lot of people so

00:49:13,570 --> 00:49:20,460
if you look at the sources of the skb

00:49:16,600 --> 00:49:23,200
rohit we have the memory location I

00:49:20,460 --> 00:49:26,950
matter seeing that with the parking API

00:49:23,200 --> 00:49:28,930
so it's almost fixed and then we just

00:49:26,950 --> 00:49:31,930
John mentioned we have the purple off we

00:49:28,930 --> 00:49:33,250
have to clear forecast lines that's an

00:49:31,930 --> 00:49:35,410
expensive part and then we have the

00:49:33,250 --> 00:49:37,450
problem with the video when you receive

00:49:35,410 --> 00:49:39,640
pages which caused a more expensive

00:49:37,450 --> 00:49:41,920
construction of the escapee and that's

00:49:39,640 --> 00:49:43,980
what we're trying out right to push with

00:49:41,920 --> 00:49:45,720
HTTP that the driver

00:49:43,980 --> 00:49:48,390
not going to give us writable pages

00:49:45,720 --> 00:49:52,670
which means that we can do a less

00:49:48,390 --> 00:49:52,670
expensive construction of the skb

00:49:56,560 --> 00:50:01,670
so this is sort of this slide maybe you

00:49:59,750 --> 00:50:04,010
are talking about Bob to be active in

00:50:01,670 --> 00:50:07,010
options so putting just keep you and

00:50:04,010 --> 00:50:09,110
diet I think Florian wistful worked a

00:50:07,010 --> 00:50:11,570
bit on that and there was like quite

00:50:09,110 --> 00:50:14,210
those too hard to reduce the size of

00:50:11,570 --> 00:50:17,570
this baby I do it really happy every

00:50:14,210 --> 00:50:21,290
time you remove elemental say because

00:50:17,570 --> 00:50:22,720
size or clearing it right a minute your

00:50:21,290 --> 00:50:25,250
ass about the side I'm just saying that

00:50:22,720 --> 00:50:27,410
it's we cleared for convenience in

00:50:25,250 --> 00:50:30,200
Dakota Vince believe ya rab' should work

00:50:27,410 --> 00:50:33,050
but these are independent issues I think

00:50:30,200 --> 00:50:35,450
making clearing more sane and making the

00:50:33,050 --> 00:50:39,080
things smaller to begin with our two

00:50:35,450 --> 00:50:40,810
separate things so one one thing one

00:50:39,080 --> 00:50:43,400
area that could that we could

00:50:40,810 --> 00:50:46,730
investigate as telling cpu vendors that

00:50:43,400 --> 00:50:48,020
hey faster clears are really forget

00:50:46,730 --> 00:50:49,490
important maybe you could make your

00:50:48,020 --> 00:50:53,300
cpu's do it even better than you do

00:50:49,490 --> 00:50:55,070
today and you know if it can be done

00:50:53,300 --> 00:50:56,480
with some constraints like if it's on an

00:50:55,070 --> 00:50:58,280
8-byte boundary then we can do a

00:50:56,480 --> 00:50:59,720
super-fast clear then yes we can

00:50:58,280 --> 00:51:01,640
guarantee that cuz that's currently the

00:50:59,720 --> 00:51:03,830
allocation alignment that's guaranteed

00:51:01,640 --> 00:51:05,390
by slovak slope that's not a problem we

00:51:03,830 --> 00:51:08,780
could even increase that if we needed to

00:51:05,390 --> 00:51:10,490
there's ways to do that so i think we

00:51:08,780 --> 00:51:12,140
need to have a discussion with the cpu

00:51:10,490 --> 00:51:14,180
crowd to make sure that we tell them

00:51:12,140 --> 00:51:16,100
that this is a pretty soon I kind of

00:51:14,180 --> 00:51:18,050
found it weird ab0 isn't isn't a

00:51:16,100 --> 00:51:19,730
priority because this is a pretty

00:51:18,050 --> 00:51:22,490
fundamental operation that every single

00:51:19,730 --> 00:51:23,570
piece of the software stack does but yet

00:51:22,490 --> 00:51:29,060
I felt still think there's room for

00:51:23,570 --> 00:51:30,950
improvement I'm kind of how are you aunt

00:51:29,060 --> 00:51:33,140
opal a clearing yeah so that's why I was

00:51:30,950 --> 00:51:36,680
about this as like did this is really

00:51:33,140 --> 00:51:38,630
hard to to digest yeah if you just do it

00:51:36,680 --> 00:51:41,690
under on the receipt to drive up receive

00:51:38,630 --> 00:51:44,990
on to the next layer could we do that so

00:51:41,690 --> 00:51:46,340
you know how ok so in for context of

00:51:44,990 --> 00:51:48,050
everyone else in net cough we're

00:51:46,340 --> 00:51:50,090
discussing how to make net devices

00:51:48,050 --> 00:51:51,620
smaller and one of the ideas that came

00:51:50,090 --> 00:51:54,250
up in a discussion was to have a neck

00:51:51,620 --> 00:51:56,750
device common as an anonymous Union and

00:51:54,250 --> 00:51:59,150
you could we could therefore support a

00:51:56,750 --> 00:52:00,710
more lightweight net net device so maybe

00:51:59,150 --> 00:52:03,190
we can support a more lightweight as

00:52:00,710 --> 00:52:06,119
Cape up by having an escape of common

00:52:03,190 --> 00:52:08,069
some smaller object

00:52:06,119 --> 00:52:10,499
yeah some media is Kippy or lab

00:52:08,069 --> 00:52:12,599
instructor at home yeah so like we only

00:52:10,499 --> 00:52:14,369
initialize the common area when the

00:52:12,599 --> 00:52:16,349
device receives a packet and then we do

00:52:14,369 --> 00:52:18,359
the rest of the stuff as the full

00:52:16,349 --> 00:52:20,009
identity of the object becomes apparent

00:52:18,359 --> 00:52:22,170
to the arrest of the stack yeah because

00:52:20,009 --> 00:52:23,999
the memory case i overhead is the same

00:52:22,170 --> 00:52:27,299
if it doesn't really matter our picked

00:52:23,999 --> 00:52:29,249
up it is then that thing is type safe we

00:52:27,299 --> 00:52:31,170
know the moment in which the object gets

00:52:29,249 --> 00:52:32,549
upgraded into a full-fledged eskape up

00:52:31,170 --> 00:52:33,690
and then we know that's the moment in

00:52:32,549 --> 00:52:35,549
which we have to make sure the rest of

00:52:33,690 --> 00:52:37,170
the fields are initialized so that's a

00:52:35,549 --> 00:52:40,710
clear demarcation point that can be

00:52:37,170 --> 00:52:42,660
enforced by the compiler we don't be

00:52:40,710 --> 00:52:44,999
kind of do the same trick for circuits

00:52:42,660 --> 00:52:47,430
where we have like those silly every

00:52:44,999 --> 00:52:50,190
length maps and just clear parts of it

00:52:47,430 --> 00:52:54,839
always a specific pic and they chose

00:52:50,190 --> 00:52:56,460
there's a special key yeah we already

00:52:54,839 --> 00:52:58,079
have that we have that we had the thing

00:52:56,460 --> 00:52:59,519
in ask you before you say how you have

00:52:58,079 --> 00:53:01,109
to clear up to this point and then we

00:52:59,519 --> 00:53:05,609
explicitly initialize there so we have

00:53:01,109 --> 00:53:09,990
something similar yes yeah so that's a

00:53:05,609 --> 00:53:12,410
lot of options no we can't make the big

00:53:09,990 --> 00:53:12,410
one bigger

00:53:13,349 --> 00:53:17,220
so we're already trying to take

00:53:15,329 --> 00:53:25,470
advantage of this change by suggesting

00:53:17,220 --> 00:53:27,329
bigger more change things yeah so so

00:53:25,470 --> 00:53:29,339
this is a slight describing why the

00:53:27,329 --> 00:53:31,619
read-only pages cost more expensive set

00:53:29,339 --> 00:53:34,049
up I don't think we have time to

00:53:31,619 --> 00:53:38,099
actually explain all this stuff actually

00:53:34,049 --> 00:53:40,799
one quick thing on this if you're

00:53:38,099 --> 00:53:43,349
planning to use build skb it billed as

00:53:40,799 --> 00:53:47,220
kb is made more a bit more expensive in

00:53:43,349 --> 00:53:48,479
some cases if you read if you're using

00:53:47,220 --> 00:53:51,450
the page because you're going to be

00:53:48,479 --> 00:53:53,839
writing into a cash cold region for the

00:53:51,450 --> 00:53:55,799
shared info yet a shed employ atif so

00:53:53,839 --> 00:53:57,569
something to keep in mind especially if

00:53:55,799 --> 00:53:59,970
you're like the nappy g ro frags

00:53:57,569 --> 00:54:01,529
interfaces reusing sk BS so you may see

00:53:59,970 --> 00:54:03,450
a penalty there for drivers that we're

00:54:01,529 --> 00:54:05,960
using that yeah but we could we could

00:54:03,450 --> 00:54:15,690
hide that because we go prefix that area

00:54:05,960 --> 00:54:17,130
before I guess you yeah I think that's

00:54:15,690 --> 00:54:19,829
like it says it says here there's like

00:54:17,130 --> 00:54:22,249
11 minutes left because because they

00:54:19,829 --> 00:54:26,039
shipped it to program ten minutes right

00:54:22,249 --> 00:54:28,170
ok so you still have 10 minutes so this

00:54:26,039 --> 00:54:30,509
this is this is just me showing that

00:54:28,170 --> 00:54:33,450
this is basic my budget from 10 gigabit

00:54:30,509 --> 00:54:36,499
and this is the page order if you

00:54:33,450 --> 00:54:40,049
allocate see where order pages or

00:54:36,499 --> 00:54:44,400
advocating that the htp should do it's

00:54:40,049 --> 00:54:47,190
the base overhead of allocating is

00:54:44,400 --> 00:54:49,680
higher than my budget so that's not good

00:54:47,190 --> 00:54:52,349
what the Green Line shows us what the

00:54:49,680 --> 00:54:54,930
drivers so soft do today actually they

00:54:52,349 --> 00:54:56,819
do smaller fragments than 4k but this

00:54:54,930 --> 00:55:00,059
disk categories I used to slide for the

00:54:56,819 --> 00:55:02,819
memory summit sir so that's basically

00:55:00,059 --> 00:55:05,269
the drivers look at the curve goes up

00:55:02,819 --> 00:55:09,569
here so we are selecting this area here

00:55:05,269 --> 00:55:11,839
and then we are motor sizing by by

00:55:09,569 --> 00:55:15,239
partitioning this larger page up in in

00:55:11,839 --> 00:55:16,260
in fragments we don't have so much

00:55:15,239 --> 00:55:17,880
higher

00:55:16,260 --> 00:55:19,080
yeah that's the thing that you are

00:55:17,880 --> 00:55:21,660
circulated we're located handout

00:55:19,080 --> 00:55:24,450
fragments but it struggles on for

00:55:21,660 --> 00:55:25,740
several reasons this model because

00:55:24,450 --> 00:55:28,370
sometimes it seems a college is really

00:55:25,740 --> 00:55:30,930
fast and then all of a sudden the page

00:55:28,370 --> 00:55:34,710
subsystem goes into reclaimer compaction

00:55:30,930 --> 00:55:36,630
and then it can stall for longer periods

00:55:34,710 --> 00:55:38,400
of time there's a single block going

00:55:36,630 --> 00:55:42,090
when you allocate something larger than

00:55:38,400 --> 00:55:44,100
the oldest your page and Eric points out

00:55:42,090 --> 00:55:45,690
that clever attackers can can pin pin

00:55:44,100 --> 00:55:50,520
down memory if you allocate these larger

00:55:45,690 --> 00:55:53,160
order pages and it doesn't scale very

00:55:50,520 --> 00:55:58,560
well and concurring workloads but this

00:55:53,160 --> 00:56:01,410
one shows it's because if there's a

00:55:58,560 --> 00:56:04,320
there's a central lock when you allocate

00:56:01,410 --> 00:56:07,200
something larger order pages in the I

00:56:04,320 --> 00:56:10,650
said cuz as actually end up / and Numa

00:56:07,200 --> 00:56:13,770
node but you can see the scaling this is

00:56:10,650 --> 00:56:15,930
a very micro benchmarks it's not that

00:56:13,770 --> 00:56:18,180
Professor representative for the good

00:56:15,930 --> 00:56:21,890
seed occurs completely off chart when

00:56:18,180 --> 00:56:26,220
the order you have all the three pages

00:56:21,890 --> 00:56:30,150
and I even petitioned Jesper divided

00:56:26,220 --> 00:56:35,430
this to to be 4k pages so it goes

00:56:30,150 --> 00:56:36,660
completely outside my budget so we make

00:56:35,430 --> 00:56:45,210
the pages rideable there's a lot of

00:56:36,660 --> 00:56:49,290
details and and then what I'm proposing

00:56:45,210 --> 00:56:51,210
to do the page pool and as I'm set like

00:56:49,290 --> 00:56:54,870
the local breeze recycling things can

00:56:51,210 --> 00:56:57,810
fix some of the issues but I'm trying to

00:56:54,870 --> 00:56:59,790
fix a larger or address a larger area so

00:56:57,810 --> 00:57:02,460
first as always more generic solution

00:56:59,790 --> 00:57:05,210
that all the drivers could use and it's

00:57:02,460 --> 00:57:07,670
faster than the page allocates a speed

00:57:05,210 --> 00:57:12,090
because we don't need to reach basically

00:57:07,670 --> 00:57:14,850
so basically it can do recycling and

00:57:12,090 --> 00:57:16,320
don't needs to be a be specialized

00:57:14,850 --> 00:57:18,570
instead of the page educator has to

00:57:16,320 --> 00:57:20,670
check all different kind of issues so

00:57:18,570 --> 00:57:22,500
there's no way that the page and okay so

00:57:20,670 --> 00:57:24,090
itself can compete just as fast as

00:57:22,500 --> 00:57:25,010
something we can do a specialized there

00:57:24,090 --> 00:57:31,530
look

00:57:25,010 --> 00:57:37,740
so a trick is to keep the cuter pages

00:57:31,530 --> 00:57:39,990
Matt to its health both the dma iommu

00:57:37,740 --> 00:57:43,260
mapping which can because in some

00:57:39,990 --> 00:57:45,540
situation and we also make the pages

00:57:43,260 --> 00:57:47,430
rideable that's I didn't explain how

00:57:45,540 --> 00:57:49,200
that sort of happens it'll be

00:57:47,430 --> 00:57:50,280
complicated to explain but it has

00:57:49,200 --> 00:57:54,060
something to do with we have a

00:57:50,280 --> 00:57:58,620
predictable DNA on that point is

00:57:54,060 --> 00:58:00,300
something Alex told me that that this is

00:57:58,620 --> 00:58:03,830
what other tricks to get it get the

00:58:00,300 --> 00:58:09,030
pages right writable some of the drivers

00:58:03,830 --> 00:58:12,690
have this issue I'm also trying to say

00:58:09,030 --> 00:58:16,200
that that we can also limit we can input

00:58:12,690 --> 00:58:18,180
today we have this problem that we only

00:58:16,200 --> 00:58:20,910
we just allocate pages on a page ball

00:58:18,180 --> 00:58:23,310
and just hand them off we have no way of

00:58:20,910 --> 00:58:24,990
knowing when when the pages are returned

00:58:23,310 --> 00:58:26,910
back to us that means we can at the

00:58:24,990 --> 00:58:28,710
device driver as we talked about for

00:58:26,910 --> 00:58:31,710
work you can eat all the memory and

00:58:28,710 --> 00:58:33,780
cause out of memory system errors but as

00:58:31,710 --> 00:58:35,250
the page where we have this sort of

00:58:33,780 --> 00:58:37,680
feedback group the pages had to be

00:58:35,250 --> 00:58:40,920
returned back to me for the painful for

00:58:37,680 --> 00:58:42,720
this year keeping DMA mapping to work so

00:58:40,920 --> 00:58:45,000
we could introduce some limitations

00:58:42,720 --> 00:58:47,520
saying how many pages are device drivers

00:58:45,000 --> 00:58:50,130
is allowed to eat before we say though

00:58:47,520 --> 00:58:52,440
no you're not getting anymore so we have

00:58:50,130 --> 00:58:54,650
it sort of protection for the entire

00:58:52,440 --> 00:58:54,650
system

00:58:56,989 --> 00:59:01,410
then tested this this is this is really

00:58:59,789 --> 00:59:04,079
a future change with you could 20 copy

00:59:01,410 --> 00:59:05,309
because we know the patients are

00:59:04,079 --> 00:59:07,859
returned back to us that's a basic

00:59:05,309 --> 00:59:10,650
problem we cannot leak kernel memory but

00:59:07,859 --> 00:59:13,319
if an expensive to clear the page before

00:59:10,650 --> 00:59:14,880
using it but if I can I'm also science

00:59:13,319 --> 00:59:16,799
that cost without the pages of returned

00:59:14,880 --> 00:59:18,029
back to me so I could have a mode let's

00:59:16,799 --> 00:59:20,969
say I want to see what copy on this

00:59:18,029 --> 00:59:22,499
receive queue and when I get pages from

00:59:20,969 --> 00:59:24,449
the page I ok I have to clear mount

00:59:22,499 --> 00:59:25,890
which is an expensive operation but

00:59:24,449 --> 00:59:27,569
after that I know the pages are returned

00:59:25,890 --> 00:59:31,109
to me if I know I'm only talking to a

00:59:27,569 --> 00:59:33,839
specific security domain I can I can

00:59:31,109 --> 00:59:36,479
avoid again I could do soooo copy him

00:59:33,839 --> 00:59:41,609
into that don't you have a secret for

00:59:36,479 --> 00:59:44,239
the OEM case already in the drivers put

00:59:41,609 --> 00:59:48,499
the coming coming over to see group

00:59:44,239 --> 00:59:48,499
maybe you could do miss Persy good

00:59:50,890 --> 00:59:58,900
I'm going to have five minutes yeah face

00:59:55,329 --> 01:00:00,819
move aside CH box I don't think I've

00:59:58,900 --> 01:00:03,450
that much more to you already talked

01:00:00,819 --> 01:00:03,450
about this one

01:00:06,170 --> 01:00:13,880
yeah the Q disc you just you have five

01:00:10,250 --> 01:00:16,730
minutes it was what what did it dude the

01:00:13,880 --> 01:00:18,500
q disc sure we talked about this earlier

01:00:16,730 --> 01:00:20,300
but we're working on removing the cutest

01:00:18,500 --> 01:00:23,000
block I'm working on it for a while I

01:00:20,300 --> 01:00:24,350
think we have some ideas on how to

01:00:23,000 --> 01:00:27,880
actually get this upstream here in the

01:00:24,350 --> 01:00:31,370
next short while there's a RFC to on the

01:00:27,880 --> 01:00:33,680
p2 or p3 or some version on the list

01:00:31,370 --> 01:00:35,330
from actually think was an RFC I think

01:00:33,680 --> 01:00:37,490
it was just a regular patch and then I

01:00:35,330 --> 01:00:39,650
have some issues on the mailing list you

01:00:37,490 --> 01:00:42,230
could dig it up there's a whole bunch of

01:00:39,650 --> 01:00:45,110
them I think like I said I think we can

01:00:42,230 --> 01:00:47,630
get this out and fairly soon it looks

01:00:45,110 --> 01:00:50,390
like by working around some of the

01:00:47,630 --> 01:00:56,870
corner cases by disabling the blacklist

01:00:50,390 --> 01:01:01,130
and effects in that case um yeah single

01:00:56,870 --> 01:01:02,750
feeling so how the q4 just filling in

01:01:01,130 --> 01:01:04,340
your driver in that gets rid of most of

01:01:02,750 --> 01:01:06,080
the corner pieces waste all the ones I'm

01:01:04,340 --> 01:01:07,700
aware of that are still still around so

01:01:06,080 --> 01:01:09,680
yeah I thought that was a good solution

01:01:07,700 --> 01:01:13,400
we discussed that at netcom that yeah

01:01:09,680 --> 01:01:15,230
that we read about all the corner cases

01:01:13,400 --> 01:01:17,750
but we can actually reduce those and say

01:01:15,230 --> 01:01:19,700
do we like that we did the park DQ you

01:01:17,750 --> 01:01:22,190
say they're so then the next thing is

01:01:19,700 --> 01:01:24,650
that you right now we do with the latest

01:01:22,190 --> 01:01:27,200
RFC we do a compare exchange for every

01:01:24,650 --> 01:01:29,270
DQ if you turn that into a broke DQ you

01:01:27,200 --> 01:01:32,960
can do one compare exchange for every X

01:01:29,270 --> 01:01:34,580
number of packets they're probably the

01:01:32,960 --> 01:01:37,060
simplest most capable of things to then

01:01:34,580 --> 01:01:38,900
turn that into a excellent more list

01:01:37,060 --> 01:01:40,340
just because you don't change any

01:01:38,900 --> 01:01:41,510
drivers there's an interesting thing

01:01:40,340 --> 01:01:43,580
that you could do with the driver to

01:01:41,510 --> 01:01:46,100
pull the whole array directly into the

01:01:43,580 --> 01:01:48,950
into the TX routine and not bother with

01:01:46,100 --> 01:01:50,750
building this list at all which requires

01:01:48,950 --> 01:01:54,710
another driver look on the flip side

01:01:50,750 --> 01:01:56,330
it's it might have it you're either

01:01:54,710 --> 01:01:58,400
performance benefit by doing this you

01:01:56,330 --> 01:02:00,620
want to do that two shoots off hdb

01:01:58,400 --> 01:02:03,200
leaves the same thing when we want to

01:02:00,620 --> 01:02:04,430
have a searcher star seems good arm

01:02:03,200 --> 01:02:06,680
she do this the next thing is how to

01:02:04,430 --> 01:02:08,900
rebuild key discs like this p 50 fastest

01:02:06,680 --> 01:02:12,079
is kind of done in the first series here

01:02:08,900 --> 01:02:16,040
we have some ideas to build other key

01:02:12,079 --> 01:02:19,790
disks around this for qos as far as a

01:02:16,040 --> 01:02:20,869
hierarchical token buckets or TBF is

01:02:19,790 --> 01:02:23,300
pretty straight forward to actually do

01:02:20,869 --> 01:02:24,950
this with so you might want to think

01:02:23,300 --> 01:02:28,250
about building a kind of a stacked

01:02:24,950 --> 01:02:29,420
version of TBF taking HTTP directly

01:02:28,250 --> 01:02:31,579
they'll begin loculus is quite difficult

01:02:29,420 --> 01:02:33,140
and it just because it's the algorithm

01:02:31,579 --> 01:02:36,500
isn't built for it so you probably need

01:02:33,140 --> 01:02:38,300
a new algorithm to do that I was toying

01:02:36,500 --> 01:02:42,710
with fair queuing so maybe we'll get

01:02:38,300 --> 01:02:45,200
something for fair queuing and I think

01:02:42,710 --> 01:02:46,400
those are the big points here the nice

01:02:45,200 --> 01:02:49,250
thing about this if you get this all

01:02:46,400 --> 01:02:51,020
lined up correctly I did package in

01:02:49,250 --> 01:02:52,970
numbers that you like to show where you

01:02:51,020 --> 01:02:54,619
attach directly onto a driver you can

01:02:52,970 --> 01:02:57,410
get the same numbers but when you move

01:02:54,619 --> 01:02:58,940
up a layer into the key desk and so it's

01:02:57,410 --> 01:03:02,780
it's quite nice I think it's a really

01:02:58,940 --> 01:03:06,109
great workout so so sorry it's not waver

01:03:02,780 --> 01:03:07,460
finding it doesn't yeah I don't think

01:03:06,109 --> 01:03:10,690
that's much more today hadn't you

01:03:07,460 --> 01:03:17,270
already talked about your your soft IQ

01:03:10,690 --> 01:03:19,609
and shredded lappy right as I was told

01:03:17,270 --> 01:03:21,740
by Ricky has some concerns that that

01:03:19,609 --> 01:03:24,680
could be like starving situations so

01:03:21,740 --> 01:03:29,720
instead of a we still have to look and

01:03:24,680 --> 01:03:32,060
find bugs and investigate Monza's yeah

01:03:29,720 --> 01:03:36,200
so so we have to fix soft like you first

01:03:32,060 --> 01:03:38,150
like making sure that we push out those

01:03:36,200 --> 01:03:42,079
box that or make sure that they measure

01:03:38,150 --> 01:03:43,940
the correct things yeah yeah that's also

01:03:42,079 --> 01:03:47,810
there's a lot of different combinations

01:03:43,940 --> 01:03:50,869
you can measure like we identified the

01:03:47,810 --> 01:03:52,700
light block and Eric fixed it and also

01:03:50,869 --> 01:03:55,010
talking to him I actually wrote and we

01:03:52,700 --> 01:04:00,319
might still have four issues which with

01:03:55,010 --> 01:04:02,359
that how we fixed it and so so there

01:04:00,319 --> 01:04:05,240
still might still be box hiding in

01:04:02,359 --> 01:04:07,790
software cool and how to be intact with

01:04:05,240 --> 01:04:09,799
the scheduler and and there was though

01:04:07,790 --> 01:04:12,619
she cried

01:04:09,799 --> 01:04:14,359
bad performance it if you have like unit

01:04:12,619 --> 01:04:16,130
piece I'll get receiving and you

01:04:14,359 --> 01:04:18,289
actually run this UDP receiver on the

01:04:16,130 --> 01:04:20,839
same CPU which we saw recommend people

01:04:18,289 --> 01:04:22,640
do there was like the performance truck

01:04:20,839 --> 01:04:26,119
to like a thousand packets per second

01:04:22,640 --> 01:04:28,009
and billy shakespeare right like 900,000

01:04:26,119 --> 01:04:34,630
packets per second but if you move it to

01:04:28,009 --> 01:04:39,160
another cpu even do my tests 1.6 million

01:04:34,630 --> 01:04:43,039
but this mr. dropping packets on the

01:04:39,160 --> 01:04:45,829
grandest the application on the same cpu

01:04:43,039 --> 01:04:50,359
as the receiver in the utopia sort of

01:04:45,829 --> 01:04:53,630
overload case and that's yeah there are

01:04:50,359 --> 01:04:55,369
kind of family issues if a sucker for a

01:04:53,630 --> 01:04:57,469
moment cpu basically overrides the

01:04:55,369 --> 01:04:59,929
socket from another cpu and it's like

01:04:57,469 --> 01:05:03,249
too much time on another cpu it could

01:04:59,929 --> 01:05:05,269
get up in like fairness issue so we

01:05:03,249 --> 01:05:07,999
probably need to have more feedback

01:05:05,269 --> 01:05:10,670
loops to to block not be earlier for

01:05:07,999 --> 01:05:12,890
like for threats may be a bitter moet

01:05:10,670 --> 01:05:15,799
that's that's still like robert early

01:05:12,890 --> 01:05:18,380
investigations yeah after i saw this

01:05:15,799 --> 01:05:19,579
problem and erics after ex-fix i can

01:05:18,380 --> 01:05:22,069
actually understand that people are

01:05:19,579 --> 01:05:23,599
complaining about that simple UDP floods

01:05:22,069 --> 01:05:25,729
can kill the whole traffic because

01:05:23,599 --> 01:05:28,699
nothing actually reach the application

01:05:25,729 --> 01:05:32,049
everything was dropped because the sun

01:05:28,699 --> 01:05:34,640
like you used too much time also the

01:05:32,049 --> 01:05:37,400
removal of the bedrock actually apps in

01:05:34,640 --> 01:05:38,660
you too yeah but i'm really excited

01:05:37,400 --> 01:05:42,949
about the work you're doing together

01:05:38,660 --> 01:05:46,910
powder to to fix this area because it

01:05:42,949 --> 01:05:51,759
was worse than I expected so I'm out of

01:05:46,910 --> 01:05:51,759
time yeah

01:05:57,240 --> 01:05:59,300

YouTube URL: https://www.youtube.com/watch?v=vsjxgOpv1n8


