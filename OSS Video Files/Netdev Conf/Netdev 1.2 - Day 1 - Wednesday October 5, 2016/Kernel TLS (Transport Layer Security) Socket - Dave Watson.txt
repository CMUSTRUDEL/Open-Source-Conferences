Title: Kernel TLS (Transport Layer Security) Socket - Dave Watson
Publication date: 2016-10-06
Playlist: Netdev 1.2 - Day 1 - Wednesday October 5, 2016
Description: 
	http://netdevconf.org/1.2/session.html?dave-watson
Captions: 
	00:00:09,780 --> 00:00:14,369
talk about is a colonel TLS socket

00:00:12,179 --> 00:00:22,919
implementation TLS being transport layer

00:00:14,369 --> 00:00:24,390
security so from my level we're just

00:00:22,919 --> 00:00:26,520
making a new socket type and you'll

00:00:24,390 --> 00:00:28,739
either instantiate it as a stream socket

00:00:26,520 --> 00:00:32,309
so TLS or a Datagram socket and you'll

00:00:28,739 --> 00:00:33,780
get DTLS so we've implemented this at

00:00:32,309 --> 00:00:36,870
Facebook and we're gonna talk about our

00:00:33,780 --> 00:00:38,700
experiments experience experiences how

00:00:36,870 --> 00:00:42,269
well it worked and some of our results

00:00:38,700 --> 00:00:43,890
from running it in production but first

00:00:42,269 --> 00:00:45,359
we're gonna do a little review of TLS

00:00:43,890 --> 00:00:46,339
cuz I don't know if everyone is the most

00:00:45,359 --> 00:00:51,989
familiar with it

00:00:46,339 --> 00:00:54,480
TLS is the s in HTTP in HTTP 2 or H 2

00:00:51,989 --> 00:00:56,550
it's actually the standard transport

00:00:54,480 --> 00:00:59,940
layer so everything in H 2 is actually

00:00:56,550 --> 00:01:01,589
encrypted with TLS which means it's very

00:00:59,940 --> 00:01:03,059
widely deployed there were some

00:01:01,589 --> 00:01:04,199
discussions I like the loss in that dev

00:01:03,059 --> 00:01:05,909
about like what are we gonna do in the

00:01:04,199 --> 00:01:07,620
data center is it going to be IPSec is

00:01:05,909 --> 00:01:09,720
it gonna be TLS isn't gonna be something

00:01:07,620 --> 00:01:11,490
else that really isn't a choice you have

00:01:09,720 --> 00:01:14,369
on the wider internet everything is

00:01:11,490 --> 00:01:16,649
really TLS at this point the versioning

00:01:14,369 --> 00:01:19,890
is kind of wacky Hyo is SSL one two and

00:01:16,649 --> 00:01:23,219
three and then it reset to TLS 1.1 1.2

00:01:19,890 --> 00:01:24,719
and the current draft is TLS with 1.3 so

00:01:23,219 --> 00:01:27,990
we're going to be going over the draft

00:01:24,719 --> 00:01:30,509
to the pretty much in this talk if the

00:01:27,990 --> 00:01:33,289
draft is that draft like 16 I believe

00:01:30,509 --> 00:01:37,590
now so it's pretty far along

00:01:33,289 --> 00:01:39,509
someone is TLS so tell us is the

00:01:37,590 --> 00:01:40,680
security protocol it has a handshake at

00:01:39,509 --> 00:01:42,719
the beginning there's really two parts

00:01:40,680 --> 00:01:44,340
to it there's a handshake and then the

00:01:42,719 --> 00:01:46,320
record protocol that does symmetric

00:01:44,340 --> 00:01:49,820
encryption after the handshake which is

00:01:46,320 --> 00:01:53,159
public private key asymmetric encryption

00:01:49,820 --> 00:01:54,810
so just like TCP there is some sort of

00:01:53,159 --> 00:01:55,920
handshake at the beginning of which

00:01:54,810 --> 00:01:57,509
there's a bunch of different options

00:01:55,920 --> 00:01:59,310
here and it's actually really quite

00:01:57,509 --> 00:02:01,500
complicated and it changes quite a lot

00:01:59,310 --> 00:02:03,689
between different versions so our

00:02:01,500 --> 00:02:07,859
approach was to essentially leave the

00:02:03,689 --> 00:02:09,300
handshake and user space so before we

00:02:07,859 --> 00:02:11,610
started this project I went and grabbed

00:02:09,300 --> 00:02:13,590
like the last seven vulnerabilities of

00:02:11,610 --> 00:02:15,990
open SSL there's a list I didn't list

00:02:13,590 --> 00:02:17,700
exactly what they were here but three of

00:02:15,990 --> 00:02:19,200
them were handshaking issues like

00:02:17,700 --> 00:02:20,580
something that had to change in the

00:02:19,200 --> 00:02:22,420
handshake protocol to fix the

00:02:20,580 --> 00:02:24,670
vulnerability

00:02:22,420 --> 00:02:26,260
ended up being bugs in the control

00:02:24,670 --> 00:02:27,849
messages so you probably heard of that

00:02:26,260 --> 00:02:30,130
the heartbleed one it was pretty recent

00:02:27,849 --> 00:02:31,270
and the heartbeat messages there's also

00:02:30,130 --> 00:02:34,209
a couple different types of control

00:02:31,270 --> 00:02:36,160
messages that had issues in them and

00:02:34,209 --> 00:02:37,810
then the last one was a sniper suite

00:02:36,160 --> 00:02:40,959
that happened to have found an attack

00:02:37,810 --> 00:02:43,000
against a so I approach also specifies

00:02:40,959 --> 00:02:44,500
the cipher suites from user space so

00:02:43,000 --> 00:02:46,630
when you instantiate the socket you also

00:02:44,500 --> 00:02:49,540
tell her what cipher suite you want to

00:02:46,630 --> 00:02:51,040
use so basically all these issues would

00:02:49,540 --> 00:02:55,450
have been resolved without having to

00:02:51,040 --> 00:02:57,340
change anything in a kernel space so the

00:02:55,450 --> 00:02:59,709
record protocol looks something like

00:02:57,340 --> 00:03:02,769
this application data for TLS anyway

00:02:59,709 --> 00:03:06,340
comes in as a stream it's fragmented

00:03:02,769 --> 00:03:08,650
into the the maximum message size it is

00:03:06,340 --> 00:03:09,819
optionally compressed this graphic is

00:03:08,650 --> 00:03:11,830
actual a little bit all that turns out

00:03:09,819 --> 00:03:13,450
compression has been broken at one point

00:03:11,830 --> 00:03:16,540
as well so no one compresses anymore if

00:03:13,450 --> 00:03:18,750
they compress their data first then a

00:03:16,540 --> 00:03:21,190
Mac is added and it is encrypted

00:03:18,750 --> 00:03:23,790
typically these now happened at the same

00:03:21,190 --> 00:03:27,010
time especially with like GCM protocols

00:03:23,790 --> 00:03:31,810
and then finally the header is attached

00:03:27,010 --> 00:03:35,410
to the front of the record somatic right

00:03:31,810 --> 00:03:37,630
max frame size is four pages 16 K the

00:03:35,410 --> 00:03:40,030
header is 13 bytes which is a little bit

00:03:37,630 --> 00:03:41,650
annoying because it's unaligned which it

00:03:40,030 --> 00:03:43,450
doesn't play quite as nicely with the

00:03:41,650 --> 00:03:45,010
AES and I hardware routines as perhaps

00:03:43,450 --> 00:03:48,730
you would like it to means you have to

00:03:45,010 --> 00:03:52,239
to pad everything out the Mac is 16

00:03:48,730 --> 00:03:54,940
bytes the first byte is the message type

00:03:52,239 --> 00:03:56,380
which for our implementation where we

00:03:54,940 --> 00:03:58,630
are leaving all the handshake and

00:03:56,380 --> 00:04:00,280
control messages in user space that's

00:03:58,630 --> 00:04:01,870
really the only thing we have to look at

00:04:00,280 --> 00:04:03,160
to know whether we are going to deal

00:04:01,870 --> 00:04:06,190
with the message or not we just look at

00:04:03,160 --> 00:04:07,930
the very first byte and the next four

00:04:06,190 --> 00:04:09,100
bytes of our version in size so you can

00:04:07,930 --> 00:04:11,670
figure out the size of the measures very

00:04:09,100 --> 00:04:13,720
quickly and then the next date our nonce

00:04:11,670 --> 00:04:16,510
nonce appeared on familiar with crypto

00:04:13,720 --> 00:04:17,950
is a number used only once per the spec

00:04:16,510 --> 00:04:20,320
this is allowed to be the sequence

00:04:17,950 --> 00:04:22,510
number and most implementations do make

00:04:20,320 --> 00:04:23,740
it the sequence number three zijn for

00:04:22,510 --> 00:04:25,570
this is it's very easy to figure out if

00:04:23,740 --> 00:04:27,580
you've used number or not and you don't

00:04:25,570 --> 00:04:29,560
want to when your secrets number wraps

00:04:27,580 --> 00:04:30,880
you then have to go and re handshake to

00:04:29,560 --> 00:04:33,210
make sure you don't reuse the same

00:04:30,880 --> 00:04:33,210
numbers

00:04:33,770 --> 00:04:37,980
control messages there's a bunch of

00:04:35,699 --> 00:04:40,430
different types renegotiate shutdown

00:04:37,980 --> 00:04:42,600
alerts heartbleed hard to beat

00:04:40,430 --> 00:04:44,340
renegotiate is of course redoing your

00:04:42,600 --> 00:04:47,669
asymmetric encryption to get symmetric

00:04:44,340 --> 00:04:48,990
cipher keys shutdown is important when

00:04:47,669 --> 00:04:50,610
you want to close the connection you

00:04:48,990 --> 00:04:52,590
actually have to send some control

00:04:50,610 --> 00:04:54,810
messages this securely shuts down the

00:04:52,590 --> 00:04:57,260
connections so that an attacker can't go

00:04:54,810 --> 00:04:59,220
and try and continue your session

00:04:57,260 --> 00:05:02,040
there's different alert types and

00:04:59,220 --> 00:05:04,380
heartbeats as it turns out in practice

00:05:02,040 --> 00:05:06,300
you really don't have to deal with any

00:05:04,380 --> 00:05:09,120
of these control messages at least

00:05:06,300 --> 00:05:10,470
Facebook doesn't pretty much all we can

00:05:09,120 --> 00:05:12,479
receive any sort of control message we

00:05:10,470 --> 00:05:14,400
just immediately close the connection we

00:05:12,479 --> 00:05:16,760
do Matthew that the proper down sequence

00:05:14,400 --> 00:05:20,850
so the one we do deal with is shut down

00:05:16,760 --> 00:05:23,460
so our handoff looks like we do the

00:05:20,850 --> 00:05:24,840
handshake and user space we put

00:05:23,460 --> 00:05:26,550
everything into the kernel and do all

00:05:24,840 --> 00:05:28,410
our symmetric encryption for our entire

00:05:26,550 --> 00:05:30,210
connection and then when either side

00:05:28,410 --> 00:05:31,590
closes the connection we finally put

00:05:30,210 --> 00:05:35,910
everything back to user space to do the

00:05:31,590 --> 00:05:37,530
shutdown command and that's it and so

00:05:35,910 --> 00:05:39,330
the one annoying part about this is

00:05:37,530 --> 00:05:41,340
trying to separate the data in control

00:05:39,330 --> 00:05:43,860
messages the annoying part is that they

00:05:41,340 --> 00:05:45,270
use the same sequence numbers so you do

00:05:43,860 --> 00:05:47,039
have to make sure that you manage the

00:05:45,270 --> 00:05:52,470
sequence numbers explicitly between user

00:05:47,039 --> 00:05:54,840
space and kernel space DTLS

00:05:52,470 --> 00:05:56,669
we have like initial support ready TLS

00:05:54,840 --> 00:05:58,740
as well it's pretty much exactly the

00:05:56,669 --> 00:06:00,060
same as TLS your it is a Datagram

00:05:58,740 --> 00:06:02,700
message so you're allowed to drop the

00:06:00,060 --> 00:06:04,680
messages it actually has additional

00:06:02,700 --> 00:06:06,930
complexity on top of TLS and then it

00:06:04,680 --> 00:06:09,090
implements its own sliding window the

00:06:06,930 --> 00:06:10,650
sliding window is only for replay

00:06:09,090 --> 00:06:12,330
protection so it's not terribly

00:06:10,650 --> 00:06:14,639
complicated you just have to remember

00:06:12,330 --> 00:06:15,840
the last X number of messages to make

00:06:14,639 --> 00:06:17,370
sure an attacker isn't trying to send

00:06:15,840 --> 00:06:20,639
you multiple messages of the same

00:06:17,370 --> 00:06:21,990
sequence number this also means there's

00:06:20,639 --> 00:06:23,099
a little bit of extra State for detail

00:06:21,990 --> 00:06:27,570
outs that you may have to pass between

00:06:23,099 --> 00:06:29,190
user space and kernel space so I said a

00:06:27,570 --> 00:06:30,870
TLS that actually won on the internet

00:06:29,190 --> 00:06:31,860
it's not quite true there are a couple

00:06:30,870 --> 00:06:34,620
others that you've probably heard of

00:06:31,860 --> 00:06:35,940
quic is one of them Facebook has one we

00:06:34,620 --> 00:06:37,800
haven't advertised it's super heavily

00:06:35,940 --> 00:06:40,800
but mentioned it a few times called a

00:06:37,800 --> 00:06:43,500
zero protocol our version is exact and

00:06:40,800 --> 00:06:44,930
we actually talked quick encryption from

00:06:43,500 --> 00:06:48,229
UDP and

00:06:44,930 --> 00:06:50,630
use it in TCP instead so what this is

00:06:48,229 --> 00:06:53,990
trying to add is actually just a zero

00:06:50,630 --> 00:06:56,210
round-trip handshake what that means is

00:06:53,990 --> 00:06:58,039
just like TCP that has the the three-way

00:06:56,210 --> 00:07:00,350
handshake at the beginning instead you

00:06:58,039 --> 00:07:01,729
could do like a DCP fast open this is

00:07:00,350 --> 00:07:03,259
the exact same thing but for encryption

00:07:01,729 --> 00:07:05,389
where you can send some data along with

00:07:03,259 --> 00:07:07,460
the handshake and assuming the handshake

00:07:05,389 --> 00:07:10,180
is successful you already have some data

00:07:07,460 --> 00:07:14,090
to reduce latency

00:07:10,180 --> 00:07:15,919
so this is all planning to be in TLS one

00:07:14,090 --> 00:07:18,020
three already so while all these

00:07:15,919 --> 00:07:20,240
companies are experimenting with these

00:07:18,020 --> 00:07:22,190
different formats they're actually just

00:07:20,240 --> 00:07:24,710
planning for the W and TLS one three so

00:07:22,190 --> 00:07:26,419
it makes a nice target it's not actually

00:07:24,710 --> 00:07:29,900
very fragmented space and everyone seems

00:07:26,419 --> 00:07:32,509
to be converging on the same thing in

00:07:29,900 --> 00:07:35,270
terms of TLS one three there's actually

00:07:32,509 --> 00:07:37,490
only one other major change in terms of

00:07:35,270 --> 00:07:39,620
the parts we're looking at it actually

00:07:37,490 --> 00:07:41,840
calls almost all the old cypress suites

00:07:39,620 --> 00:07:44,870
which is awesome we only have to deal

00:07:41,840 --> 00:07:46,789
with two of them GCM AES and cha-cha

00:07:44,870 --> 00:07:48,349
poly are the two that are in the spec

00:07:46,789 --> 00:07:50,780
there's actually a third one but it's

00:07:48,349 --> 00:07:54,169
almost never used in production so these

00:07:50,780 --> 00:07:56,270
are the two remain they looking at GCM

00:07:54,169 --> 00:07:58,220
AES is the one you're probably familiar

00:07:56,270 --> 00:08:00,530
with it's the ones that have AES and I

00:07:58,220 --> 00:08:03,680
Hardware instruction support on Intel

00:08:00,530 --> 00:08:05,599
chipsets and a few other chipsets this

00:08:03,680 --> 00:08:07,789
makes it substantially faster to do the

00:08:05,599 --> 00:08:09,440
crypto but it's still taking up your CPU

00:08:07,789 --> 00:08:14,060
time it's not any sort of offloaded

00:08:09,440 --> 00:08:16,729
anywhere else so as opposed to that

00:08:14,060 --> 00:08:18,620
cha-cha poly if you don't have Hardware

00:08:16,729 --> 00:08:21,380
instructions is actually faster to do in

00:08:18,620 --> 00:08:23,570
software so chipsets that don't have a

00:08:21,380 --> 00:08:26,449
yes and I hardware instructions end up

00:08:23,570 --> 00:08:28,759
using cha-cha poly instead and so for

00:08:26,449 --> 00:08:30,500
our use cases this mostly means mobile

00:08:28,759 --> 00:08:33,680
applications that we have control over

00:08:30,500 --> 00:08:35,450
end up using cha-cha poly while all of

00:08:33,680 --> 00:08:38,300
our server backends if they're choosing

00:08:35,450 --> 00:08:39,950
to do the crypto that way use GCM AES so

00:08:38,300 --> 00:08:41,209
you can make this trade-off of which end

00:08:39,950 --> 00:08:44,630
is going to end up spending the extra

00:08:41,209 --> 00:08:47,750
CPU cycles both these are actually

00:08:44,630 --> 00:08:49,520
already in the crypto subsystem the GCM

00:08:47,750 --> 00:08:52,190
AES required a few changes that I'll

00:08:49,520 --> 00:08:54,550
talk about but it actually works quite

00:08:52,190 --> 00:08:54,550
well for us

00:08:54,660 --> 00:09:00,090
so I'll share some numbers of what our

00:08:56,930 --> 00:09:02,760
actual production traffic looks like GC

00:09:00,090 --> 00:09:05,610
mas makes up like 80% of our encrypted

00:09:02,760 --> 00:09:09,630
traffic so it's quite high cha-cha poly

00:09:05,610 --> 00:09:12,480
from mobile is about 6 percent and the

00:09:09,630 --> 00:09:14,790
older ciphers that are pre 1/3 ciphers

00:09:12,480 --> 00:09:16,440
that are going away is only 0.1% at this

00:09:14,790 --> 00:09:19,380
time and in going down so it's actually

00:09:16,440 --> 00:09:22,290
pretty insignificant these don't add up

00:09:19,380 --> 00:09:30,210
to 100 because there is a bunch of data

00:09:22,290 --> 00:09:31,140
that I can't share sorry so why are we

00:09:30,210 --> 00:09:32,790
trying to do this why are we trying to

00:09:31,140 --> 00:09:34,050
put it in the kernel there's a bunch of

00:09:32,790 --> 00:09:36,090
different reasons I'm going to list them

00:09:34,050 --> 00:09:40,080
out here and talk about them send files

00:09:36,090 --> 00:09:41,670
slice standard POSIX API is right now if

00:09:40,080 --> 00:09:43,050
you want to go and use TLS encryption

00:09:41,670 --> 00:09:44,970
you have to go and figure out the

00:09:43,050 --> 00:09:46,800
different libraries so open SSL G new

00:09:44,970 --> 00:09:49,230
TLS whatever they all have their own

00:09:46,800 --> 00:09:51,720
sort of interface while our our

00:09:49,230 --> 00:09:53,610
interface to the kernel sockets has

00:09:51,720 --> 00:09:55,050
improved of time we have you know send

00:09:53,610 --> 00:09:58,380
that message we have send file we have

00:09:55,050 --> 00:10:00,000
splice most of the user space TLS

00:09:58,380 --> 00:10:02,310
libraries haven't gained these same

00:10:00,000 --> 00:10:04,440
things or very slowly we've had to do a

00:10:02,310 --> 00:10:05,850
bunch of work retrofitting open SSL with

00:10:04,440 --> 00:10:07,650
a bunch of stuff that I wish we wouldn't

00:10:05,850 --> 00:10:09,960
have had to done but what we did anyway

00:10:07,650 --> 00:10:11,760
which if we had the standard interface

00:10:09,960 --> 00:10:15,540
it would have just worked out of the box

00:10:11,760 --> 00:10:16,590
for us so send file is interesting in

00:10:15,540 --> 00:10:19,560
that it actually might give you a

00:10:16,590 --> 00:10:21,360
performance increase we tested this used

00:10:19,560 --> 00:10:24,450
some micro benchmarks versus a bunch of

00:10:21,360 --> 00:10:26,550
other strategies so the one on the left

00:10:24,450 --> 00:10:29,040
here is just SSL we're calling read on

00:10:26,550 --> 00:10:30,900
some sort of static resource on disk and

00:10:29,040 --> 00:10:32,970
then calling SSL writes straight out to

00:10:30,900 --> 00:10:34,200
the network card so we called that a

00:10:32,970 --> 00:10:37,530
hundred percent of CPU that's our

00:10:34,200 --> 00:10:39,480
benchmark so that involves two copies

00:10:37,530 --> 00:10:41,670
one from the kernel user space and one

00:10:39,480 --> 00:10:44,910
from user space to the kernel after we

00:10:41,670 --> 00:10:47,370
encrypted we can avoid the kernel to

00:10:44,910 --> 00:10:49,440
user space one by using a map to try and

00:10:47,370 --> 00:10:51,240
map the file into memory it does save a

00:10:49,440 --> 00:10:53,790
little bit of CPU it looks like it's

00:10:51,240 --> 00:10:56,040
about three percent we could try and use

00:10:53,790 --> 00:10:57,750
VM splice to save the other one from

00:10:56,040 --> 00:10:59,430
going from user space into the kernel I

00:10:57,750 --> 00:11:00,840
never had much luck with it and of

00:10:59,430 --> 00:11:03,830
course did get rid of the copies but

00:11:00,840 --> 00:11:06,450
involved a bunch of extra vm overhead

00:11:03,830 --> 00:11:07,810
send files seems to be at about seven

00:11:06,450 --> 00:11:11,590
percent from the baseline or

00:11:07,810 --> 00:11:16,029
faster than em map so the profiles look

00:11:11,590 --> 00:11:17,410
something like this so the AES and I

00:11:16,029 --> 00:11:18,460
encryption cost is roughly the same

00:11:17,410 --> 00:11:19,900
which is awesome

00:11:18,460 --> 00:11:21,940
it means our user space and kernel

00:11:19,900 --> 00:11:24,310
encryption routines are performing

00:11:21,940 --> 00:11:26,560
roughly the same and there seems to be

00:11:24,310 --> 00:11:29,050
some extra cost here and the the copying

00:11:26,560 --> 00:11:34,120
and the mapping of pages so almost

00:11:29,050 --> 00:11:36,610
exactly what I would have expected in

00:11:34,120 --> 00:11:38,410
addition to just the API changes it also

00:11:36,610 --> 00:11:40,660
gives us access to the unencrypted bytes

00:11:38,410 --> 00:11:43,680
in the kernel this is the short term

00:11:40,660 --> 00:11:47,589
what we ended up using this for the most

00:11:43,680 --> 00:11:48,670
and so this is BPF type programs so we

00:11:47,589 --> 00:11:50,830
have something called the kernel

00:11:48,670 --> 00:11:52,690
connection multiplexer and then uses

00:11:50,830 --> 00:11:56,050
this extensively I'll talk about it just

00:11:52,690 --> 00:12:00,040
a little bit essentially we're taking a

00:11:56,050 --> 00:12:01,410
single TCP socket usually on receive and

00:12:00,040 --> 00:12:03,940
we're putting it through the multiplexer

00:12:01,410 --> 00:12:06,970
breaking it up into individual datagrams

00:12:03,940 --> 00:12:09,550
so our use cases are RPC so we use

00:12:06,970 --> 00:12:12,610
Apache thrift but really any RPC service

00:12:09,550 --> 00:12:14,350
is probably some sort of Datagram in h2

00:12:12,610 --> 00:12:15,490
which is also some sort of Datagram that

00:12:14,350 --> 00:12:16,930
you have the size at the beginning and

00:12:15,490 --> 00:12:20,589
it's very easy to detect the size of the

00:12:16,930 --> 00:12:22,089
message using BPF we then have a bunch

00:12:20,589 --> 00:12:25,330
of sockets that are over here in

00:12:22,089 --> 00:12:26,860
userspace all in different threads so

00:12:25,330 --> 00:12:28,330
what we're doing is just round robbing

00:12:26,860 --> 00:12:30,310
across these choosing one that is

00:12:28,330 --> 00:12:31,780
waiting in e-poll to do something and

00:12:30,310 --> 00:12:35,380
giving it a packet to go and do

00:12:31,780 --> 00:12:37,450
something with so we built the KCM on

00:12:35,380 --> 00:12:39,430
top of TLS when they're layered so we

00:12:37,450 --> 00:12:41,589
have the TCP socket and then the the TLS

00:12:39,430 --> 00:12:43,000
socket that's doing the decryption and

00:12:41,589 --> 00:12:45,190
then the criminal connection multiplexer

00:12:43,000 --> 00:12:47,260
sits on top of that since the bytes are

00:12:45,190 --> 00:12:49,839
decrypted now we can use BPF in the

00:12:47,260 --> 00:12:52,180
kernel to read what the actual encrypted

00:12:49,839 --> 00:12:58,480
messages are and then send them to some

00:12:52,180 --> 00:13:00,070
some socket in userspace so the main

00:12:58,480 --> 00:13:02,200
advantage of this is that we're waking

00:13:00,070 --> 00:13:03,790
up a single thread that's actually

00:13:02,200 --> 00:13:06,850
waiting for data so we're able to

00:13:03,790 --> 00:13:08,050
paralyze this work in user space I tried

00:13:06,850 --> 00:13:11,320
to make a little diagram here to

00:13:08,050 --> 00:13:14,260
describe things are coming in on in from

00:13:11,320 --> 00:13:15,370
the kernel on one thread and then in

00:13:14,260 --> 00:13:17,380
user space there's a bunch of different

00:13:15,370 --> 00:13:19,300
threads that are waiting to do something

00:13:17,380 --> 00:13:20,230
they're probably having a bunch of

00:13:19,300 --> 00:13:22,090
different TC

00:13:20,230 --> 00:13:25,570
be connections in them so they could be

00:13:22,090 --> 00:13:27,130
doing work for other connections but one

00:13:25,570 --> 00:13:28,870
if one is free and just sitting there

00:13:27,130 --> 00:13:30,220
waiting to do some work will give the

00:13:28,870 --> 00:13:31,900
message to it as opposed to trying to

00:13:30,220 --> 00:13:33,940
give it to some other thread that is

00:13:31,900 --> 00:13:36,220
currently busy the previous

00:13:33,940 --> 00:13:38,860
implementation of this we had tied

00:13:36,220 --> 00:13:40,990
connections to threads so all the

00:13:38,860 --> 00:13:43,960
requests on a single connection went to

00:13:40,990 --> 00:13:45,610
the same thread in userspace and then on

00:13:43,960 --> 00:13:47,260
top of that user space would then pick

00:13:45,610 --> 00:13:48,610
apart the messages and then load balance

00:13:47,260 --> 00:13:50,290
again so we required an additional

00:13:48,610 --> 00:13:54,040
thread hop that we're avoiding with this

00:13:50,290 --> 00:13:56,200
strategy so we went and implemented all

00:13:54,040 --> 00:13:58,240
this and ran it in production for a

00:13:56,200 --> 00:14:00,190
bunch of different services this is

00:13:58,240 --> 00:14:04,300
perhaps the most impressive result we

00:14:00,190 --> 00:14:06,220
got a TLS is mostly neutral right now

00:14:04,300 --> 00:14:07,660
we're just using the AES and I hardware

00:14:06,220 --> 00:14:09,310
instructions which are available in

00:14:07,660 --> 00:14:11,620
userspace or kernel space so they don't

00:14:09,310 --> 00:14:13,540
affect affect the results much this one

00:14:11,620 --> 00:14:15,700
is not using send file so we're not

00:14:13,540 --> 00:14:18,850
seeing any improvement in terms of

00:14:15,700 --> 00:14:23,650
sending CPU so this is mostly a benefit

00:14:18,850 --> 00:14:26,320
from KCM over the encrypted data so this

00:14:23,650 --> 00:14:28,420
is some services p99 latency so the tail

00:14:26,320 --> 00:14:30,010
latency the worst the win latency of the

00:14:28,420 --> 00:14:32,620
worst message is over time I think this

00:14:30,010 --> 00:14:33,910
is about a day if you can't read the

00:14:32,620 --> 00:14:36,550
numbers of the less they're there in

00:14:33,910 --> 00:14:38,530
milliseconds so the big peak was about a

00:14:36,550 --> 00:14:40,030
20 percent improvement in latency and

00:14:38,530 --> 00:14:42,280
the smaller peak over here on the right

00:14:40,030 --> 00:14:48,280
is about a 10 percent so we're seeing

00:14:42,280 --> 00:14:49,480
some improvement in tail latency so you

00:14:48,280 --> 00:14:51,310
get access to unencrypted bytes you

00:14:49,480 --> 00:14:54,160
could also do other things with this in

00:14:51,310 --> 00:14:57,250
BPF if you're doing DTLS you could also

00:14:54,160 --> 00:14:59,350
do sock reuse port has a BPF hook you

00:14:57,250 --> 00:15:01,810
can choose explicitly which socket to

00:14:59,350 --> 00:15:03,700
actually give the message to which is

00:15:01,810 --> 00:15:07,600
very similar to what we're doing with

00:15:03,700 --> 00:15:09,310
KCM finally we have Hardware offload the

00:15:07,600 --> 00:15:11,050
whole next talk is about hardware

00:15:09,310 --> 00:15:13,000
offload so I'm not going to talk about

00:15:11,050 --> 00:15:14,980
it too much other than we have a choice

00:15:13,000 --> 00:15:16,630
of what the interface is really going to

00:15:14,980 --> 00:15:17,190
be e to the hardware offload if we're

00:15:16,630 --> 00:15:19,990
gonna do it

00:15:17,190 --> 00:15:21,820
so we've implanted a socket type which

00:15:19,990 --> 00:15:23,680
is essentially saying to the kernel that

00:15:21,820 --> 00:15:25,870
we are going to encrypt this data and

00:15:23,680 --> 00:15:28,140
then we're going to send it out it's

00:15:25,870 --> 00:15:30,760
going to be going over the the network

00:15:28,140 --> 00:15:33,360
there's also an existing socket type the

00:15:30,760 --> 00:15:35,310
F out of sockets algorithm sockets where

00:15:33,360 --> 00:15:39,779
give it a block of data in our case it

00:15:35,310 --> 00:15:42,630
would be a 1 record of 16 K for TLS it

00:15:39,779 --> 00:15:44,399
would encrypt it off for you and then it

00:15:42,630 --> 00:15:46,079
would give it back to you which means

00:15:44,399 --> 00:15:49,260
it's a little more flexible and that you

00:15:46,079 --> 00:15:51,360
could do the framing from user space and

00:15:49,260 --> 00:15:52,950
then choose what to do with it you could

00:15:51,360 --> 00:15:55,019
still splice that data around and like

00:15:52,950 --> 00:15:58,740
splice it out so you could get a very

00:15:55,019 --> 00:16:00,600
rough version of send file going the

00:15:58,740 --> 00:16:01,950
main issue is that it implies you're

00:16:00,600 --> 00:16:03,240
getting the data back and it doesn't

00:16:01,950 --> 00:16:05,579
know what you're doing with it after

00:16:03,240 --> 00:16:07,649
that so if you wanted to put the offload

00:16:05,579 --> 00:16:09,180
on the network card it would have to

00:16:07,649 --> 00:16:11,310
send the data in and our card encrypt it

00:16:09,180 --> 00:16:13,079
send it back and then you have to add it

00:16:11,310 --> 00:16:14,519
to your tcp saga and then it would send

00:16:13,079 --> 00:16:16,980
it off again to the neck so it'd be

00:16:14,519 --> 00:16:19,440
going back and forth more times than you

00:16:16,980 --> 00:16:21,269
really want it to this probably works

00:16:19,440 --> 00:16:24,779
just fine if we want some sort of other

00:16:21,269 --> 00:16:26,990
offload like PCIe offload or an onboard

00:16:24,779 --> 00:16:29,399
offload or something like that

00:16:26,990 --> 00:16:31,079
anyways the point is that we're tying

00:16:29,399 --> 00:16:32,579
together the fact that we're sending the

00:16:31,079 --> 00:16:34,230
data out with the fact that we're

00:16:32,579 --> 00:16:36,029
encrypting it so we're giving a little

00:16:34,230 --> 00:16:38,690
more information and it can specialize

00:16:36,029 --> 00:16:38,690
that a little bit more

00:16:42,870 --> 00:16:47,190
I purchased some numbers from our

00:16:45,510 --> 00:16:49,740
production machines in terms of what

00:16:47,190 --> 00:16:53,220
this is currently costing us we have a

00:16:49,740 --> 00:16:55,380
bunch of terminators looking at those

00:16:53,220 --> 00:16:58,500
about 10% of our CPU is still spent

00:16:55,380 --> 00:17:00,630
doing AES and I instructions so even

00:16:58,500 --> 00:17:02,670
though these are faster than doing it in

00:17:00,630 --> 00:17:07,050
software it still takes up like a lot of

00:17:02,670 --> 00:17:09,420
CPU it's quite expensive 132 percent is

00:17:07,050 --> 00:17:11,939
spending doing avoidable copy 2 and copy

00:17:09,420 --> 00:17:14,309
from user for our CDN machines so this

00:17:11,939 --> 00:17:16,290
is static resources from disk going

00:17:14,309 --> 00:17:17,970
straight up the network that we're

00:17:16,290 --> 00:17:21,050
currently copying into user space

00:17:17,970 --> 00:17:24,000
encrypting and then then sending out

00:17:21,050 --> 00:17:25,829
none of our internal services currently

00:17:24,000 --> 00:17:28,920
used send file or splice at all because

00:17:25,829 --> 00:17:30,360
they're all mostly written after TLS had

00:17:28,920 --> 00:17:31,860
become a thing so we just didn't even

00:17:30,360 --> 00:17:34,350
bother like we can't use them at all

00:17:31,860 --> 00:17:36,720
right now so this kind of exists we've

00:17:34,350 --> 00:17:38,040
noticed there and so we're experiencing

00:17:36,720 --> 00:17:41,820
now with trying to get rid of this one

00:17:38,040 --> 00:17:43,559
to two percent of course just this

00:17:41,820 --> 00:17:45,059
implementation using AES and I doesn't

00:17:43,559 --> 00:17:46,410
get rid of this ten percent cost for us

00:17:45,059 --> 00:17:52,380
you actually would need some screw-up

00:17:46,410 --> 00:17:54,300
offload to get rid of that so asymmetric

00:17:52,380 --> 00:17:57,450
encryption is actually more expensive

00:17:54,300 --> 00:17:59,220
than symmetric encryption so just some

00:17:57,450 --> 00:18:02,340
explanation of why we've been focusing

00:17:59,220 --> 00:18:04,200
on the symmetric encryption when you do

00:18:02,340 --> 00:18:07,170
a handshake there's actually a feature

00:18:04,200 --> 00:18:09,090
called session resumption that if the

00:18:07,170 --> 00:18:10,350
user knows that it has previously talked

00:18:09,090 --> 00:18:12,360
to you you can try and resume the

00:18:10,350 --> 00:18:16,620
previous session instead of doing the

00:18:12,360 --> 00:18:18,840
expensive asymmetric encryption so our

00:18:16,620 --> 00:18:20,460
resume rate is somewhere greater than 50

00:18:18,840 --> 00:18:21,960
percent it's actually much greater than

00:18:20,460 --> 00:18:25,020
50 percent but I can't share an exact

00:18:21,960 --> 00:18:26,580
number so the more you guys log on to

00:18:25,020 --> 00:18:28,710
Facebook multiple times per day the

00:18:26,580 --> 00:18:31,920
greater session resumption is which is

00:18:28,710 --> 00:18:35,010
awesome so it's about 5% of CPU so half

00:18:31,920 --> 00:18:36,150
as much and going down of course when

00:18:35,010 --> 00:18:37,500
you're using it in the data center you

00:18:36,150 --> 00:18:39,690
can actually control your pooled

00:18:37,500 --> 00:18:43,020
connections much more closely and crops

00:18:39,690 --> 00:18:45,360
even pre share your keys so this is only

00:18:43,020 --> 00:18:48,260
really a concern with the internet and

00:18:45,360 --> 00:18:48,260
external clients

00:18:49,180 --> 00:18:54,520
I'm so let's take just a brief look at

00:18:51,250 --> 00:18:56,080
our implementation so there isn't

00:18:54,520 --> 00:18:57,250
actually a whole lot left to do if

00:18:56,080 --> 00:18:58,810
you're leaving the handshake in

00:18:57,250 --> 00:19:00,640
userspace and leaving all the control

00:18:58,810 --> 00:19:03,130
messages in userspace you just have to

00:19:00,640 --> 00:19:06,040
split the messages somehow into control

00:19:03,130 --> 00:19:07,360
and use your space messages you have to

00:19:06,040 --> 00:19:09,190
parse the framing you have to deal with

00:19:07,360 --> 00:19:11,350
the sequence number management because

00:19:09,190 --> 00:19:13,720
both the control and data messages are

00:19:11,350 --> 00:19:15,190
using the same sequence number you have

00:19:13,720 --> 00:19:16,600
to encrypt and decrypt things and

00:19:15,190 --> 00:19:20,200
finally just deal with all the buffers

00:19:16,600 --> 00:19:22,510
that are flying around so currently our

00:19:20,200 --> 00:19:24,880
approach is to have two file descriptors

00:19:22,510 --> 00:19:27,370
to split the data we have the original

00:19:24,880 --> 00:19:29,290
TCP file descriptor that anything you

00:19:27,370 --> 00:19:31,690
read or write from is just said straight

00:19:29,290 --> 00:19:34,540
out to the network and so we actually

00:19:31,690 --> 00:19:38,620
give this one to our user space open SSL

00:19:34,540 --> 00:19:41,200
library or GNU TLS we've tested both and

00:19:38,620 --> 00:19:43,420
then we chain onto it our keys TLS

00:19:41,200 --> 00:19:45,250
socket that will decrypt the bytes it

00:19:43,420 --> 00:19:47,140
Peaks into the original socket at the

00:19:45,250 --> 00:19:48,730
first byte and says hey I'm going to

00:19:47,140 --> 00:19:50,260
either detective this is a data message

00:19:48,730 --> 00:19:51,420
and steal the buffers and then decrypt

00:19:50,260 --> 00:19:53,890
them and send them up

00:19:51,420 --> 00:19:56,770
so we give that one to our application

00:19:53,890 --> 00:19:59,590
to go and get the decrypted data and

00:19:56,770 --> 00:20:03,850
then the only special logic between the

00:19:59,590 --> 00:20:07,180
two is grabbing the the the encrypted

00:20:03,850 --> 00:20:08,860
encryption keys and IVs from the open

00:20:07,180 --> 00:20:11,530
SSL implementation and sticking it in

00:20:08,860 --> 00:20:14,380
the TLS socket there's other ways you

00:20:11,530 --> 00:20:16,720
could do this you could use one FD and

00:20:14,380 --> 00:20:18,610
have some sort of like stateful sock opt

00:20:16,720 --> 00:20:20,350
and make it work so that you would

00:20:18,610 --> 00:20:22,710
actually pass the FD between the two

00:20:20,350 --> 00:20:24,760
library implementations

00:20:22,710 --> 00:20:26,800
there's also mentioned you could use the

00:20:24,760 --> 00:20:29,020
Eric you to try and separate out the

00:20:26,800 --> 00:20:30,520
control and data messages that way my

00:20:29,020 --> 00:20:34,000
biggest problem with that is that

00:20:30,520 --> 00:20:35,920
current library implementations and user

00:20:34,000 --> 00:20:37,810
space aren't expecting anything on the

00:20:35,920 --> 00:20:39,400
air queue so you'd have to go and either

00:20:37,810 --> 00:20:41,680
make a bunch of different shims or

00:20:39,400 --> 00:20:45,790
modify them to work with this so it

00:20:41,680 --> 00:20:46,960
seems like a little bit more work for

00:20:45,790 --> 00:20:48,520
parsing the framing there wasn't

00:20:46,960 --> 00:20:50,080
actually anything that did this

00:20:48,520 --> 00:20:52,330
specifically is a library in the kernel

00:20:50,080 --> 00:20:53,650
before so we added this stream parser

00:20:52,330 --> 00:20:56,320
library it's currently used by the

00:20:53,650 --> 00:20:58,980
kernel connection multiplexer basically

00:20:56,320 --> 00:21:02,290
it's taking the the TCP stream data and

00:20:58,980 --> 00:21:02,630
finding the right points and s KB's to

00:21:02,290 --> 00:21:04,520
make

00:21:02,630 --> 00:21:07,580
actual messages and then handing them

00:21:04,520 --> 00:21:14,360
off to either KCM or in our case the TLS

00:21:07,580 --> 00:21:16,100
locket secrets numbers this is pretty

00:21:14,360 --> 00:21:18,230
much all of the implementation and user

00:21:16,100 --> 00:21:20,600
space that you need now is the actual

00:21:18,230 --> 00:21:22,160
grabbing of the keys from your users

00:21:20,600 --> 00:21:24,200
basic limitation and sticking it at the

00:21:22,160 --> 00:21:26,120
socket and then at the right place

00:21:24,200 --> 00:21:27,650
grabbing them out of the kernel

00:21:26,120 --> 00:21:29,450
implementation and sticking them back in

00:21:27,650 --> 00:21:31,070
user space and you actually do need to

00:21:29,450 --> 00:21:34,790
do both if you want to properly take

00:21:31,070 --> 00:21:36,350
care of the shutdown message um some of

00:21:34,790 --> 00:21:38,150
the user space libraries right now don't

00:21:36,350 --> 00:21:39,950
actually expose their encryption keys

00:21:38,150 --> 00:21:41,330
it's a little bit of a pic so we're

00:21:39,950 --> 00:21:43,070
actually working on getting some of

00:21:41,330 --> 00:21:44,450
those patches upstream to actually make

00:21:43,070 --> 00:21:49,610
it you so you can grab them in a

00:21:44,450 --> 00:21:53,300
reasonable way using a standard API so

00:21:49,610 --> 00:21:54,830
the crypto actually is GCM we have a

00:21:53,300 --> 00:21:56,600
software implementation for as well as

00:21:54,830 --> 00:21:59,540
the AES and I hardware implementation

00:21:56,600 --> 00:22:03,290
for the Arbor implementation was written

00:21:59,540 --> 00:22:05,090
for IPSec IP sex header is 16 bytes

00:22:03,290 --> 00:22:07,280
which is nice and fits in with the

00:22:05,090 --> 00:22:08,660
hardware instructions very nicely TLS is

00:22:07,280 --> 00:22:10,790
13 and is super annoying

00:22:08,660 --> 00:22:13,490
we have to go through and pad all the

00:22:10,790 --> 00:22:15,080
numbers out so some minor changes we're

00:22:13,490 --> 00:22:18,440
needed to get the AES and I instructions

00:22:15,080 --> 00:22:21,710
working these crypto patches would be

00:22:18,440 --> 00:22:23,510
necessary even with the ALB socket so

00:22:21,710 --> 00:22:25,460
you need a little bit of work right now

00:22:23,510 --> 00:22:32,180
even if you want to support send file

00:22:25,460 --> 00:22:33,860
abusing the Alex akka management just is

00:22:32,180 --> 00:22:36,860
pretty standard except for the fact that

00:22:33,860 --> 00:22:39,980
the max message size is 4k which means

00:22:36,860 --> 00:22:42,920
you always have to have 4k available to

00:22:39,980 --> 00:22:44,300
decrypt the message we of course at

00:22:42,920 --> 00:22:46,670
Facebook dealing with the huge machines

00:22:44,300 --> 00:22:49,580
with you know 32 gigabytes of memory so

00:22:46,670 --> 00:22:51,740
it's not usually an issue but we do have

00:22:49,580 --> 00:22:53,660
to take care of the special case that we

00:22:51,740 --> 00:22:55,220
have not enough of the data or it's

00:22:53,660 --> 00:22:56,330
fragmented and out of water that we

00:22:55,220 --> 00:22:58,550
don't have enough to actually put

00:22:56,330 --> 00:23:01,070
together a crypto message so we have to

00:22:58,550 --> 00:23:02,660
fail and hand it back to user space so

00:23:01,070 --> 00:23:04,490
this is the one case when user space may

00:23:02,660 --> 00:23:07,460
actually have to deal with a message

00:23:04,490 --> 00:23:10,120
somehow that is normal data and not a

00:23:07,460 --> 00:23:10,120
control message

00:23:11,260 --> 00:23:16,210
I'm suggest a review for over 7% CPU

00:23:14,620 --> 00:23:18,460
savings using 10 file depending on how

00:23:16,210 --> 00:23:20,380
you want to count it 10 to 20% p99

00:23:18,460 --> 00:23:22,059
latency depending on which service we

00:23:20,380 --> 00:23:25,290
were actually looking at and they

00:23:22,059 --> 00:23:27,730
provide support for Hardware offload our

00:23:25,290 --> 00:23:29,320
code is currently on github still

00:23:27,730 --> 00:23:31,630
needing a little bit of polish we've

00:23:29,320 --> 00:23:34,630
only implemented the GCM a yes portions

00:23:31,630 --> 00:23:38,260
of this so Shasha poly should be next on

00:23:34,630 --> 00:23:40,390
the list oh and the D TLS is kind of a

00:23:38,260 --> 00:23:42,940
work in progress at the moment but it is

00:23:40,390 --> 00:23:44,830
very little change necessary to actually

00:23:42,940 --> 00:23:48,400
get it to work so we're probably gonna

00:23:44,830 --> 00:23:51,480
support that - cool do you guys have any

00:23:48,400 --> 00:23:51,480
questions yes

00:23:55,080 --> 00:24:01,240
so you mentioned another slide that the

00:23:58,210 --> 00:24:03,910
GCM AES ni overheads sticks at 10% right

00:24:01,240 --> 00:24:05,830
and you're discussing ways to get rid of

00:24:03,910 --> 00:24:07,870
it it also discussed on the previous

00:24:05,830 --> 00:24:10,240
slide that you have this four page

00:24:07,870 --> 00:24:12,640
buffer requirement and that gets tricky

00:24:10,240 --> 00:24:14,410
and in certain cases you can fail

00:24:12,640 --> 00:24:16,750
partially and have to kick it down to

00:24:14,410 --> 00:24:19,030
user space I think you can get rid of

00:24:16,750 --> 00:24:21,730
both things to 10% overhead and this

00:24:19,030 --> 00:24:23,110
crazy Buffett requirement the thing

00:24:21,730 --> 00:24:24,850
that's missing in all this is think

00:24:23,110 --> 00:24:27,520
about do about what's happening as you

00:24:24,850 --> 00:24:30,040
as you were eliminating peeling away

00:24:27,520 --> 00:24:31,390
layers of copies in this thing so I

00:24:30,040 --> 00:24:32,890
don't know about you but I'm a little

00:24:31,390 --> 00:24:34,540
disappointed that you only got a 7

00:24:32,890 --> 00:24:36,309
percent improvement percent file it

00:24:34,540 --> 00:24:37,570
should have been a lot bigger right

00:24:36,309 --> 00:24:39,160
especially since all the data is being

00:24:37,570 --> 00:24:40,870
handled in the kernel we're limiting at

00:24:39,160 --> 00:24:44,230
least theoretically certain levels of

00:24:40,870 --> 00:24:46,650
copies right one thing the crypto layer

00:24:44,230 --> 00:24:48,790
isn't doing for you is combining the

00:24:46,650 --> 00:24:51,160
computational overhead of the AES and I

00:24:48,790 --> 00:24:52,600
with the users base copy and that's what

00:24:51,160 --> 00:24:55,650
needs to be added to the crypto layer

00:24:52,600 --> 00:24:58,390
you need a es and I operations that can

00:24:55,650 --> 00:25:00,640
scatter into user space and scatter from

00:24:58,390 --> 00:25:04,030
users phase and that way the 10% just

00:25:00,640 --> 00:25:05,440
evaporates into the copy overhead also

00:25:04,030 --> 00:25:09,880
you wouldn't need that temporary buffer

00:25:05,440 --> 00:25:11,950
anymore you're correct

00:25:09,880 --> 00:25:14,530
so we had an initial implementation of

00:25:11,950 --> 00:25:18,030
this that works for a very subset of

00:25:14,530 --> 00:25:21,010
cases yeah the current GCM AES

00:25:18,030 --> 00:25:22,840
implementation doesn't let you it

00:25:21,010 --> 00:25:24,190
doesn't really do Skylar gather and it's

00:25:22,840 --> 00:25:25,360
the main problem we're running into

00:25:24,190 --> 00:25:28,120
is that it requires everything to be in

00:25:25,360 --> 00:25:29,559
a contiguous buffer so okay if your data

00:25:28,120 --> 00:25:31,149
lines up perfectly with what the buffer

00:25:29,559 --> 00:25:32,980
user usually face is giving you you can

00:25:31,149 --> 00:25:34,629
currently do it but right yeah that's a

00:25:32,980 --> 00:25:36,250
piece of work as we showed you did the

00:25:34,629 --> 00:25:37,960
key is we have to have the crypto layer

00:25:36,250 --> 00:25:40,840
of support cooking in and out of user

00:25:37,960 --> 00:25:42,460
space so there'd be a shim with a dumb

00:25:40,840 --> 00:25:44,200
layer for all the algorithms that don't

00:25:42,460 --> 00:25:45,909
support it that do a copy afterwards out

00:25:44,200 --> 00:25:47,649
of a temporary buffer for example but

00:25:45,909 --> 00:25:50,139
the thing we really want is that piece

00:25:47,649 --> 00:25:52,299
of assembler that that amortizes all the

00:25:50,139 --> 00:25:54,750
a s and I cost in the copy operation

00:25:52,299 --> 00:25:58,029
itself just like we do for checksums for

00:25:54,750 --> 00:26:01,409
almost three decades now so I agree I

00:25:58,029 --> 00:26:03,879
think that's where we need to go and so

00:26:01,409 --> 00:26:04,840
if we get to that point do you also

00:26:03,879 --> 00:26:09,450
agree that we can get rid of the

00:26:04,840 --> 00:26:11,769
temporary buffer yes okay great thanks I

00:26:09,450 --> 00:26:14,460
don't think any of that requires changes

00:26:11,769 --> 00:26:14,460
to the interface though

00:26:24,420 --> 00:26:31,380
I think that $0.04 file you will still

00:26:28,650 --> 00:26:35,100
have to use one copy because you can

00:26:31,380 --> 00:26:39,540
encrypt the central payload from the

00:26:35,100 --> 00:26:41,460
page yeah I mean encryption I don't know

00:26:39,540 --> 00:26:44,640
if it's a copy it's something that's

00:26:41,460 --> 00:26:47,130
there yeah well you need to copy it to

00:26:44,640 --> 00:26:50,580
another buffer to encrypt it know it's

00:26:47,130 --> 00:26:53,250
encrypted from the pager then you modify

00:26:50,580 --> 00:26:57,530
the data in the page cache no you're

00:26:53,250 --> 00:26:57,530
reading from one and writing to another

00:27:01,460 --> 00:27:06,510
yeah but you don't want to modify the

00:27:04,530 --> 00:27:12,810
data in the page cache it's not

00:27:06,510 --> 00:27:14,580
encrypted in place so the crypto is done

00:27:12,810 --> 00:27:17,220
from a source buffer to a destination

00:27:14,580 --> 00:27:19,320
buffer so you read from one and and

00:27:17,220 --> 00:27:22,530
write to another buffer so you'll if the

00:27:19,320 --> 00:27:25,250
debtor else it is and decrypt operation

00:27:22,530 --> 00:27:25,250
you have to anyways

00:27:44,500 --> 00:27:53,450
do you require specific that you align

00:27:49,940 --> 00:27:56,480
the friend size of the tin as that you

00:27:53,450 --> 00:27:59,270
align the sizes of the buffers you need

00:27:56,480 --> 00:28:01,160
to user space to the frame sizes or do

00:27:59,270 --> 00:28:03,530
you need to have lots of special logic

00:28:01,160 --> 00:28:06,350
to actually do the encryption on a full

00:28:03,530 --> 00:28:09,470
block then store half of the unencrypted

00:28:06,350 --> 00:28:12,770
data back into the SK receive queue and

00:28:09,470 --> 00:28:14,720
just give part of it to you the space so

00:28:12,770 --> 00:28:18,350
for example if or do you also command

00:28:14,720 --> 00:28:20,600
message peak is that peaking on a socket

00:28:18,350 --> 00:28:23,240
like I I want to read from data from it

00:28:20,600 --> 00:28:24,620
unencrypted but I don't want to remove

00:28:23,240 --> 00:28:28,550
the data which is already in the queue

00:28:24,620 --> 00:28:33,500
right we support that right right now

00:28:28,550 --> 00:28:36,350
it is on the receive queue do you just

00:28:33,500 --> 00:28:38,780
do one just one just one say you star

00:28:36,350 --> 00:28:40,420
out of the decrypted data if it's

00:28:38,780 --> 00:28:43,400
already decrypted and then hand it back

00:28:40,420 --> 00:28:49,130
so we receive the data and then we

00:28:43,400 --> 00:28:50,930
decrypt it in place right and then it's

00:28:49,130 --> 00:28:53,510
stored in the received queue okay I was

00:28:50,930 --> 00:28:55,190
asking if the feature I like David says

00:28:53,510 --> 00:28:56,930
like you basically have the dr.

00:28:55,190 --> 00:29:00,110
encrypted and the receive queue then I

00:28:56,930 --> 00:29:02,060
just that would be an optimization that

00:29:00,110 --> 00:29:03,560
yes you'd have to make a copy in some

00:29:02,060 --> 00:29:06,250
cases and you wouldn't in others

00:29:03,560 --> 00:29:06,250
okay thanks

00:29:13,270 --> 00:29:16,270

YouTube URL: https://www.youtube.com/watch?v=LbZu0D05Wko


