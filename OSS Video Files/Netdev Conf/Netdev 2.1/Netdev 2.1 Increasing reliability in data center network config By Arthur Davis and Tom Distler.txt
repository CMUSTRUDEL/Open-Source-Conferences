Title: Netdev 2.1 Increasing reliability in data center network config By Arthur Davis and Tom Distler
Publication date: 2017-06-03
Playlist: Netdev 2.1
Description: 
	In this talk given at Netdev 2.1 on the 8th of April, Arthur Davis and Tom Distler talk about their quest for a network configuration solution for a large Linux storage application. Their application is based on a highly available cluster architecture which requires dynamic and reliable software-driven network configuration.
The talk expands upon a  set of core requirements and discusses some of the difficulties around meeting these requirements with currently available open source solutions.

Content: https://www.netdevconf.org/2.1/session.html?davis
Captions: 
	00:00:00,030 --> 00:00:07,830
alright this on alright so thank you for

00:00:05,759 --> 00:00:11,309
being here last talk of the conference

00:00:07,830 --> 00:00:12,240
is always a dicey thing so um thank you

00:00:11,309 --> 00:00:13,349
for staying hopefully we'll make it

00:00:12,240 --> 00:00:16,440
worth your while

00:00:13,349 --> 00:00:18,570
my name is Tom Destler arthur davis we

00:00:16,440 --> 00:00:22,140
work on the SolidFire product at NetApp

00:00:18,570 --> 00:00:24,180
and today we wanted to present a project

00:00:22,140 --> 00:00:28,140
we're working on it's a round network

00:00:24,180 --> 00:00:30,929
configuration management for distributed

00:00:28,140 --> 00:00:34,020
systems for the data center and I'll get

00:00:30,929 --> 00:00:35,760
into a little bit about kind of some

00:00:34,020 --> 00:00:38,520
background who we are and what SolidFire

00:00:35,760 --> 00:00:42,450
is so you have some context we're on the

00:00:38,520 --> 00:00:44,879
platform team so there is this division

00:00:42,450 --> 00:00:46,860
there's a the SolidFire application

00:00:44,879 --> 00:00:50,879
which is a storage application it's a

00:00:46,860 --> 00:00:55,140
scale out share nothing data center

00:00:50,879 --> 00:00:56,579
storage solution and that is one team

00:00:55,140 --> 00:01:00,000
that works on that the platform team

00:00:56,579 --> 00:01:02,280
provides the entire environment that

00:01:00,000 --> 00:01:06,060
executes since a hard work wall like it

00:01:02,280 --> 00:01:08,610
says we're using Linux the OS zookeeper

00:01:06,060 --> 00:01:10,830
drivers all that kind of stuff we're

00:01:08,610 --> 00:01:15,570
currently working on improving network

00:01:10,830 --> 00:01:18,600
management and configuration some things

00:01:15,570 --> 00:01:22,400
to know about DB context but the problem

00:01:18,600 --> 00:01:24,990
we're trying to solve so first of all

00:01:22,400 --> 00:01:27,030
it's a shared nothing architecture so

00:01:24,990 --> 00:01:29,430
it's not if you're familiar with storage

00:01:27,030 --> 00:01:31,829
architectures it's not a central

00:01:29,430 --> 00:01:35,430
controller with a bunch of storage

00:01:31,829 --> 00:01:37,590
arrays behind it it's basically rack and

00:01:35,430 --> 00:01:39,990
stack one 1u nodes where every node

00:01:37,590 --> 00:01:42,329
participates in hosting traffic every

00:01:39,990 --> 00:01:44,759
node has similar network config every

00:01:42,329 --> 00:01:48,240
node participates equally in serving

00:01:44,759 --> 00:01:51,090
volumes their primaries for some volumes

00:01:48,240 --> 00:01:54,380
and their backups for other ones I'll

00:01:51,090 --> 00:01:54,380
show that a little bit another slide

00:01:54,409 --> 00:01:59,820
multi-tenancy is a big deal because

00:01:56,159 --> 00:02:02,790
we're in a lot of not only data centers

00:01:59,820 --> 00:02:06,299
but service provider environments will

00:02:02,790 --> 00:02:08,039
where they will sell storage to

00:02:06,299 --> 00:02:10,470
customers on top of our system and

00:02:08,039 --> 00:02:12,569
they'll sell it at certain tiers and so

00:02:10,470 --> 00:02:13,870
we have a lot of QoS things we have to

00:02:12,569 --> 00:02:16,630
guarantee

00:02:13,870 --> 00:02:18,810
we can't be making Network changes let's

00:02:16,630 --> 00:02:21,550
say for one customer adding a VLAN and

00:02:18,810 --> 00:02:24,850
have it disrupt traffic for other

00:02:21,550 --> 00:02:26,650
customers on the same nodes

00:02:24,850 --> 00:02:28,300
that's where VLANs verse come in to a

00:02:26,650 --> 00:02:30,850
lot of customers now are moving from

00:02:28,300 --> 00:02:31,870
their private local data centers up into

00:02:30,850 --> 00:02:33,430
the cloud and they want to bring their

00:02:31,870 --> 00:02:35,110
IP space with them and they don't want

00:02:33,430 --> 00:02:38,490
to react e-everything so we need verse

00:02:35,110 --> 00:02:41,080
so they can have overlapping IP spaces

00:02:38,490 --> 00:02:45,120
high availability and reliability are

00:02:41,080 --> 00:02:48,300
really important you could imagine if a

00:02:45,120 --> 00:02:50,740
hard drive vendor got a reputation for

00:02:48,300 --> 00:02:51,130
every once in a while corrupting your

00:02:50,740 --> 00:02:52,870
data

00:02:51,130 --> 00:02:54,160
nobody would probably buy their stuff

00:02:52,870 --> 00:02:56,430
anymore and they go out of business

00:02:54,160 --> 00:02:59,440
we can't lose data we can't corrupt data

00:02:56,430 --> 00:03:02,800
some of the workloads that are running

00:02:59,440 --> 00:03:04,720
are you know things like entire product

00:03:02,800 --> 00:03:07,060
databases therefore banks they're trying

00:03:04,720 --> 00:03:10,360
to run payroll on it people get mad when

00:03:07,060 --> 00:03:12,690
they don't get their paychecks so very

00:03:10,360 --> 00:03:14,770
very important that we're reliable

00:03:12,690 --> 00:03:18,130
there's just a link to a youtube video

00:03:14,770 --> 00:03:19,510
if you want the one hour presentation on

00:03:18,130 --> 00:03:23,950
the entire on how the architecture

00:03:19,510 --> 00:03:26,560
actually works this is just a node and I

00:03:23,950 --> 00:03:28,750
wanted to just give you a sense of what

00:03:26,560 --> 00:03:31,000
our network can look like on all the

00:03:28,750 --> 00:03:34,450
nodes each node would have a matching

00:03:31,000 --> 00:03:35,739
network config some of the physical

00:03:34,450 --> 00:03:37,840
interface names have been changed to

00:03:35,739 --> 00:03:40,090
protect the innocent but we're saying

00:03:37,840 --> 00:03:42,220
eat zero through three we have four

00:03:40,090 --> 00:03:45,400
physical NICs on the back we are running

00:03:42,220 --> 00:03:48,100
Ethernet LR cluster traffic like cluster

00:03:45,400 --> 00:03:53,980
cluster traffic's TCP we bond them

00:03:48,100 --> 00:03:55,660
together in pairs and we do aught that

00:03:53,980 --> 00:03:59,110
can be an optional VLAN on tops for

00:03:55,660 --> 00:04:00,910
traffic traffic tagging and then if

00:03:59,110 --> 00:04:02,680
there's one node in the cluster that

00:04:00,910 --> 00:04:04,750
selected cluster master and it may host

00:04:02,680 --> 00:04:07,720
what we call the M zip the management

00:04:04,750 --> 00:04:09,580
virtual IP which is where if you're

00:04:07,720 --> 00:04:13,120
going to hit our REST API hit the

00:04:09,580 --> 00:04:15,670
cluster webpage that's where that that

00:04:13,120 --> 00:04:18,040
IP is what's going to get hit this is

00:04:15,670 --> 00:04:20,940
the storage and inter cluster traffic

00:04:18,040 --> 00:04:23,860
side so we separate management because

00:04:20,940 --> 00:04:25,300
management doesn't use the people who

00:04:23,860 --> 00:04:27,010
manage the cluster don't necessarily get

00:04:25,300 --> 00:04:29,020
access to the storage

00:04:27,010 --> 00:04:32,380
the storage client can't manage the

00:04:29,020 --> 00:04:36,070
cluster so just allow segmentation but

00:04:32,380 --> 00:04:38,710
this is really the part that there's two

00:04:36,070 --> 00:04:42,490
parts that can change one is we support

00:04:38,710 --> 00:04:45,790
up to 256 VLANs which may or may not be

00:04:42,490 --> 00:04:48,990
in their own network namespaces and

00:04:45,790 --> 00:04:51,850
these change as new customers are added

00:04:48,990 --> 00:04:53,410
they make they'll create a VLAN for the

00:04:51,850 --> 00:04:55,990
customer and then put all the volumes in

00:04:53,410 --> 00:04:58,570
it and so boom another VLAN appears off

00:04:55,990 --> 00:05:02,020
here when a node is elected cluster

00:04:58,570 --> 00:05:04,060
master every VLAN has to get its own

00:05:02,020 --> 00:05:06,040
version of what we call the s fit which

00:05:04,060 --> 00:05:09,760
is the storage virtual IP these are vs

00:05:06,040 --> 00:05:12,460
that's VLAN virtual storage ipys but

00:05:09,760 --> 00:05:17,260
these are basically become the I scuzzy

00:05:12,460 --> 00:05:20,050
targets for system over scuzzy so we

00:05:17,260 --> 00:05:22,540
can't have this VLAN come up and disrupt

00:05:20,050 --> 00:05:24,910
traffic on this viewing just can't

00:05:22,540 --> 00:05:26,920
happen and a lot of network the network

00:05:24,910 --> 00:05:30,310
managers we've surveyed and we've played

00:05:26,920 --> 00:05:31,690
with and used in the past sometimes you

00:05:30,310 --> 00:05:32,920
go change one thing over here and

00:05:31,690 --> 00:05:35,050
they'll tear the whole thing down and

00:05:32,920 --> 00:05:37,390
build the entire the bond and everything

00:05:35,050 --> 00:05:39,340
back up even sometimes for simple things

00:05:37,390 --> 00:05:42,430
like changing them to you you have to go

00:05:39,340 --> 00:05:44,530
restart the networking service I have no

00:05:42,430 --> 00:05:46,780
idea why they do this but it must be

00:05:44,530 --> 00:05:49,720
just completely different use cases but

00:05:46,780 --> 00:05:52,510
we can't do that so it's kind of a

00:05:49,720 --> 00:05:57,460
picture an overlay maybe to give you

00:05:52,510 --> 00:05:59,020
some context so right now and this is

00:05:57,460 --> 00:06:00,550
pretty typical of any distributed system

00:05:59,020 --> 00:06:03,100
I've worked in for multiple companies

00:06:00,550 --> 00:06:04,840
the network configuration becomes is

00:06:03,100 --> 00:06:09,840
built into the application the

00:06:04,840 --> 00:06:12,070
distributed application and what needs

00:06:09,840 --> 00:06:13,170
what really is happens it needs to be

00:06:12,070 --> 00:06:15,540
pulled out because they're two

00:06:13,170 --> 00:06:17,470
completely separate problem domains

00:06:15,540 --> 00:06:19,420
distributed systems is like a whole

00:06:17,470 --> 00:06:21,480
specialty and problem domain in and of

00:06:19,420 --> 00:06:23,200
itself you've ever worked in them

00:06:21,480 --> 00:06:24,820
they're a whole beast in and of

00:06:23,200 --> 00:06:26,230
themselves and so for like it's

00:06:24,820 --> 00:06:28,240
SolidFire we have our architecture and

00:06:26,230 --> 00:06:30,220
then a few years ago we did like key la

00:06:28,240 --> 00:06:33,940
plus analysis on it to go for familiar

00:06:30,220 --> 00:06:36,610
with was a temple logic analysis to go

00:06:33,940 --> 00:06:38,860
try and prove out or failover algorithms

00:06:36,610 --> 00:06:40,270
and other things and then you want the

00:06:38,860 --> 00:06:40,510
code to match the architecture in the

00:06:40,270 --> 00:06:41,860
mall

00:06:40,510 --> 00:06:44,110
to match the code there's this nice

00:06:41,860 --> 00:06:45,490
triad but then when you go to try and

00:06:44,110 --> 00:06:47,050
make it a product you end up with

00:06:45,490 --> 00:06:50,020
network management and drive management

00:06:47,050 --> 00:06:52,420
all these other things that kind of gut

00:06:50,020 --> 00:06:53,980
can gum up the code and it from an

00:06:52,420 --> 00:06:55,420
architectural perspective you really

00:06:53,980 --> 00:06:58,630
want to pull all that network management

00:06:55,420 --> 00:07:01,420
stuff out because the application itself

00:06:58,630 --> 00:07:03,430
really only cares about is something

00:07:01,420 --> 00:07:05,230
wrong can I connect you know did the

00:07:03,430 --> 00:07:06,910
network get partitioned much higher

00:07:05,230 --> 00:07:08,920
level things can I still communicate

00:07:06,910 --> 00:07:12,400
with things love I allow elected cluster

00:07:08,920 --> 00:07:13,360
master so pulling this out is really

00:07:12,400 --> 00:07:15,370
important for us that's what we're

00:07:13,360 --> 00:07:17,140
working on now we haven't really found

00:07:15,370 --> 00:07:19,690
something that does what we need and

00:07:17,140 --> 00:07:20,980
although through some of these but if

00:07:19,690 --> 00:07:23,770
you guys know of something please tell

00:07:20,980 --> 00:07:27,420
us then we don't have to write it but we

00:07:23,770 --> 00:07:29,920
haven't found it yet so a couple things

00:07:27,420 --> 00:07:32,380
when the node boots up this thing needs

00:07:29,920 --> 00:07:34,510
to start early and create the bonds for

00:07:32,380 --> 00:07:36,580
us set the eye piece put it in LACP mode

00:07:34,510 --> 00:07:37,960
or whatever bonding mode we have things

00:07:36,580 --> 00:07:40,800
like that

00:07:37,960 --> 00:07:45,100
we need an application interface to it

00:07:40,800 --> 00:07:47,500
so shelling out to bash rain bash

00:07:45,100 --> 00:07:50,230
scripts or doing exactly doing other

00:07:47,500 --> 00:07:52,570
things like that much more error-prone

00:07:50,230 --> 00:07:55,390
in our experience and we really want

00:07:52,570 --> 00:07:59,400
some sort of like programmatic API that

00:07:55,390 --> 00:08:03,010
we can interact with we also need

00:07:59,400 --> 00:08:05,140
notifications back so when we lose link

00:08:03,010 --> 00:08:07,510
for instance we need to know or the

00:08:05,140 --> 00:08:09,280
application needs to know when there's a

00:08:07,510 --> 00:08:10,750
config mismatch or someone in support or

00:08:09,280 --> 00:08:13,000
an engineer fat-fingers something on a

00:08:10,750 --> 00:08:16,570
command line we need to know there was a

00:08:13,000 --> 00:08:19,480
problem for various reasons our cluster

00:08:16,570 --> 00:08:21,580
faults and different things we support

00:08:19,480 --> 00:08:24,460
multiple concurrent actors acting on the

00:08:21,580 --> 00:08:27,700
network so we have problem today where

00:08:24,460 --> 00:08:29,410
we have two processes that sometimes you

00:08:27,700 --> 00:08:32,410
can have the user trying out a VLAN

00:08:29,410 --> 00:08:34,270
through the API at the same time that no

00:08:32,410 --> 00:08:37,229
get selected cluster master and now two

00:08:34,270 --> 00:08:42,280
processes are making network changes and

00:08:37,229 --> 00:08:43,900
we need a way to serialize it through so

00:08:42,280 --> 00:08:46,870
that we're doing one set of changes and

00:08:43,900 --> 00:08:51,070
the config moves in a very consistent

00:08:46,870 --> 00:08:53,230
manner forward so that's where these

00:08:51,070 --> 00:08:53,560
transaction semantics come in how to

00:08:53,230 --> 00:08:57,070
live

00:08:53,560 --> 00:08:59,500
more about that later monitoring for

00:08:57,070 --> 00:09:01,300
networks changes right now we have a

00:08:59,500 --> 00:09:03,510
bunch of monitoring code built-in to the

00:09:01,300 --> 00:09:05,950
app the app really only cares about

00:09:03,510 --> 00:09:08,590
reacting to events so if something goes

00:09:05,950 --> 00:09:10,810
wrong that's built into the architecture

00:09:08,590 --> 00:09:12,700
that we lost connections a cluster

00:09:10,810 --> 00:09:14,339
master or we or cluster master there's a

00:09:12,700 --> 00:09:16,750
problem we need to call a new election

00:09:14,339 --> 00:09:18,400
those are distributed system problems

00:09:16,750 --> 00:09:19,690
that's the apps problem the app doesn't

00:09:18,400 --> 00:09:20,200
want to sit and have to interact with

00:09:19,690 --> 00:09:21,550
netlink

00:09:20,200 --> 00:09:24,070
it doesn't make sense it's and it's a

00:09:21,550 --> 00:09:27,279
architectural problem that I don't think

00:09:24,070 --> 00:09:29,050
is good architecture and a best-effort

00:09:27,279 --> 00:09:33,130
tempt to repair things that finger

00:09:29,050 --> 00:09:35,770
things on a command line when things go

00:09:33,130 --> 00:09:37,450
wrong there's a certain set interfaces

00:09:35,770 --> 00:09:39,670
we need that that daemon just just sit

00:09:37,450 --> 00:09:44,890
there and keep trying to put the net the

00:09:39,670 --> 00:09:46,270
network config in that state so so I've

00:09:44,890 --> 00:09:49,029
talked about design patterns this is a

00:09:46,270 --> 00:09:51,700
lot just kind of compare and contrast

00:09:49,029 --> 00:09:54,060
what I was saying before about the

00:09:51,700 --> 00:09:56,020
application problems and the network

00:09:54,060 --> 00:09:58,360
management solution problems and they're

00:09:56,020 --> 00:10:00,520
really two separate problems and to

00:09:58,360 --> 00:10:02,920
really be able to scale and maintain

00:10:00,520 --> 00:10:08,260
your code it makes it much easier if you

00:10:02,920 --> 00:10:09,460
can just split these to see if anything

00:10:08,260 --> 00:10:12,970
is anything actually on here I actually

00:10:09,460 --> 00:10:18,700
want to point out a lot of it I did say

00:10:12,970 --> 00:10:21,520
so so Arthur here is going to describe

00:10:18,700 --> 00:10:23,170
the design of the demon war building I

00:10:21,520 --> 00:10:26,470
really want to go over some of the

00:10:23,170 --> 00:10:30,220
motivations like I've already been doing

00:10:26,470 --> 00:10:31,660
but non destructive network changes are

00:10:30,220 --> 00:10:34,300
a big one and there are some places

00:10:31,660 --> 00:10:36,910
where we can handle it where it would be

00:10:34,300 --> 00:10:39,839
okay we could explain it to customers

00:10:36,910 --> 00:10:42,250
it'd be fine but the kernel provides

00:10:39,839 --> 00:10:44,800
this network stack and the ability to

00:10:42,250 --> 00:10:46,330
make changes in so many places without

00:10:44,800 --> 00:10:48,850
being disruptive and we're using good

00:10:46,330 --> 00:10:53,440
network hardware and the drivers support

00:10:48,850 --> 00:10:55,360
it why would we not build and have a

00:10:53,440 --> 00:10:57,279
network management solution that takes

00:10:55,360 --> 00:10:59,140
advantage of that and just artificially

00:10:57,279 --> 00:11:01,390
make it disruptive because we couldn't

00:10:59,140 --> 00:11:04,300
design our manager very well so that's

00:11:01,390 --> 00:11:05,850
one transaction semantics and asset

00:11:04,300 --> 00:11:08,170
guarantees that's just for the

00:11:05,850 --> 00:11:11,080
configuration itself

00:11:08,170 --> 00:11:13,990
we can't we can't take a block of

00:11:11,080 --> 00:11:16,000
changes and with the current kernel

00:11:13,990 --> 00:11:18,820
interfaces make the give acid guarantees

00:11:16,000 --> 00:11:21,940
on changing the system but on the config

00:11:18,820 --> 00:11:23,790
we can so if we are elected cluster

00:11:21,940 --> 00:11:27,280
master and we need to go create 200

00:11:23,790 --> 00:11:29,560
virtual interfaces we want those to

00:11:27,280 --> 00:11:33,700
succeed and fail in a block as far as

00:11:29,560 --> 00:11:36,460
applying them to the config so because

00:11:33,700 --> 00:11:39,250
if we don't want that the config to show

00:11:36,460 --> 00:11:40,900
half the interfaces were created and the

00:11:39,250 --> 00:11:42,850
other half never got created or

00:11:40,900 --> 00:11:45,760
especially the crashed in the middle

00:11:42,850 --> 00:11:47,860
when we come back up the config we read

00:11:45,760 --> 00:11:51,250
needs to be some the last known good

00:11:47,860 --> 00:11:52,870
state or for changing routes and we're

00:11:51,250 --> 00:11:53,890
trying to change two routes and one of

00:11:52,870 --> 00:11:55,540
them got changed but the other one

00:11:53,890 --> 00:11:56,920
didn't all these kind of problems we

00:11:55,540 --> 00:11:58,660
can't have it either only the config

00:11:56,920 --> 00:12:01,750
needs to this block of config changes

00:11:58,660 --> 00:12:03,910
needs to happen or fail and needs to be

00:12:01,750 --> 00:12:07,030
durable and always move from one

00:12:03,910 --> 00:12:09,580
consistent state to the next

00:12:07,030 --> 00:12:12,340
recovery if the daemon crashes needs to

00:12:09,580 --> 00:12:15,130
replay its log or it get back to its

00:12:12,340 --> 00:12:16,840
last known config hopefully the we write

00:12:15,130 --> 00:12:18,670
a client library write the application

00:12:16,840 --> 00:12:21,070
won't know it'll just know that maybe it

00:12:18,670 --> 00:12:22,510
failed to apply the latest config and

00:12:21,070 --> 00:12:25,780
got some error back until the daemon

00:12:22,510 --> 00:12:28,240
came back up we also end up the system

00:12:25,780 --> 00:12:31,650
crashes that config any part of the

00:12:28,240 --> 00:12:34,660
persistent config has to be consistent

00:12:31,650 --> 00:12:38,560
which is part of that asset guarantee of

00:12:34,660 --> 00:12:41,830
durability the D on their scope

00:12:38,560 --> 00:12:45,160
management this is something that's

00:12:41,830 --> 00:12:47,140
really important to me it's very much if

00:12:45,160 --> 00:12:49,480
we're told to manage a set of interfaces

00:12:47,140 --> 00:12:50,620
we manage those and those only and if

00:12:49,480 --> 00:12:52,180
you have docker running we have

00:12:50,620 --> 00:12:53,740
containers on the node and other things

00:12:52,180 --> 00:12:56,680
and they're creating bridges and other

00:12:53,740 --> 00:12:58,660
things don't touch those that's not your

00:12:56,680 --> 00:13:01,750
domain like leave those alone it's not

00:12:58,660 --> 00:13:02,800
your business and if those come over

00:13:01,750 --> 00:13:04,300
into our side we're just going to keep

00:13:02,800 --> 00:13:06,940
trying to repair it and end up fighting

00:13:04,300 --> 00:13:09,310
it but like there's this domain and the

00:13:06,940 --> 00:13:11,380
scope like this is what you're dealing

00:13:09,310 --> 00:13:13,660
with just touch that don't try and take

00:13:11,380 --> 00:13:15,550
over the whole system things like that

00:13:13,660 --> 00:13:16,150
and then support ability that's more

00:13:15,550 --> 00:13:19,800
around log

00:13:16,150 --> 00:13:21,670
and stuff so that's all I had

00:13:19,800 --> 00:13:27,240
Arthur's going to talk about the design

00:13:21,670 --> 00:13:27,240
which one that's I get this mixer I

00:13:27,720 --> 00:13:32,830
wanted to just remember back to the

00:13:31,330 --> 00:13:38,580
title of the talk which was about

00:13:32,830 --> 00:13:41,730
increasing reliability um which well so

00:13:38,580 --> 00:13:45,450
for us the main point with the

00:13:41,730 --> 00:13:48,720
increasing reliability is about these

00:13:45,450 --> 00:13:53,860
application concerns versus

00:13:48,720 --> 00:13:57,670
configuration concerns and allowing us

00:13:53,860 --> 00:13:59,020
to write applications that focus just on

00:13:57,670 --> 00:14:01,000
doing Lenna

00:13:59,020 --> 00:14:04,240
or implementing the product behaviors

00:14:01,000 --> 00:14:07,540
for what the application how you know

00:14:04,240 --> 00:14:09,310
how is the network supposed to be behave

00:14:07,540 --> 00:14:11,410
on this or how is this product supposed

00:14:09,310 --> 00:14:15,250
to be used on the network and what sort

00:14:11,410 --> 00:14:17,530
of things should happen in the case of

00:14:15,250 --> 00:14:21,070
certain network faults or events and

00:14:17,530 --> 00:14:23,230
that sort of thing so what I'm going to

00:14:21,070 --> 00:14:28,170
do is just really kind of a high-level

00:14:23,230 --> 00:14:31,600
overview of the solution that we're

00:14:28,170 --> 00:14:33,160
moving forwards with mainly because we

00:14:31,600 --> 00:14:35,530
did we spent quite a bit of time

00:14:33,160 --> 00:14:37,720
actually surveying things that were

00:14:35,530 --> 00:14:39,310
available from the community right

00:14:37,720 --> 00:14:42,040
that's the way we started this project

00:14:39,310 --> 00:14:45,700
was to go find the open source project

00:14:42,040 --> 00:14:50,530
or even a commercial project product

00:14:45,700 --> 00:14:52,630
that would would work for us and we kept

00:14:50,530 --> 00:14:55,060
looking for something and just never

00:14:52,630 --> 00:14:56,560
really found the thing that hit the mark

00:14:55,060 --> 00:14:58,890
for us and so that's what brought us

00:14:56,560 --> 00:15:03,310
here we certainly didn't start out

00:14:58,890 --> 00:15:07,180
build-your-own which i think is never a

00:15:03,310 --> 00:15:13,920
good place to start without at least

00:15:07,180 --> 00:15:16,480
looking around so the for us and tong

00:15:13,920 --> 00:15:18,640
let's see if I can cry on the right

00:15:16,480 --> 00:15:21,790
slide so this is a sort of a small silly

00:15:18,640 --> 00:15:24,220
little diagram but it highlights this

00:15:21,790 --> 00:15:26,750
application logic versus network

00:15:24,220 --> 00:15:31,040
configuration logic and in an hour

00:15:26,750 --> 00:15:34,850
our solution this network configuration

00:15:31,040 --> 00:15:36,700
piece is just exposing the kernel

00:15:34,850 --> 00:15:40,400
interfaces the kernel configuration

00:15:36,700 --> 00:15:43,160
interfaces and so there's no logic that

00:15:40,400 --> 00:15:45,920
would allow us or that where this would

00:15:43,160 --> 00:15:47,900
say tell me when we can get to the

00:15:45,920 --> 00:15:50,120
internet or something that's higher

00:15:47,900 --> 00:15:51,980
level that requires putting together

00:15:50,120 --> 00:15:54,470
several pieces and imposing some

00:15:51,980 --> 00:15:57,650
specific behaviors or looking for some

00:15:54,470 --> 00:16:01,640
specific behaviors and so this is really

00:15:57,650 --> 00:16:05,630
a low-level solution this data model

00:16:01,640 --> 00:16:08,290
concept is really just what sort of data

00:16:05,630 --> 00:16:11,750
are we working with and it is exactly

00:16:08,290 --> 00:16:13,520
the data that you would see the

00:16:11,750 --> 00:16:15,410
organization of data that you would see

00:16:13,520 --> 00:16:17,090
in the kernel interfaces so if you go

00:16:15,410 --> 00:16:21,700
and you look and you see addresses you

00:16:17,090 --> 00:16:24,620
see firewall IP tables or nf tables or

00:16:21,700 --> 00:16:27,110
route tables and so the organization

00:16:24,620 --> 00:16:28,940
here would be exactly what you would see

00:16:27,110 --> 00:16:33,860
from the kernel there's no attempt to

00:16:28,940 --> 00:16:37,010
add any extra abstractions or to undo

00:16:33,860 --> 00:16:40,160
any other sort of fancy modeling to

00:16:37,010 --> 00:16:43,220
bundle these up into something different

00:16:40,160 --> 00:16:45,280
than what the kernel provides when a

00:16:43,220 --> 00:16:48,430
client wants to make some changes

00:16:45,280 --> 00:16:51,020
through this little daemon to

00:16:48,430 --> 00:16:54,589
reconfigure the network they will fetch

00:16:51,020 --> 00:16:57,920
some portion of this database rearrange

00:16:54,589 --> 00:17:00,530
or make some changes to it and then tell

00:16:57,920 --> 00:17:02,480
the daemon here's some disk and or some

00:17:00,530 --> 00:17:07,069
changes that I want you to make based on

00:17:02,480 --> 00:17:11,199
that thing that I just read internally

00:17:07,069 --> 00:17:13,910
we have this same sort of data model

00:17:11,199 --> 00:17:19,360
it's version and that's an important

00:17:13,910 --> 00:17:24,709
piece to the the concurrent actors

00:17:19,360 --> 00:17:28,910
solution the one way to explain that I

00:17:24,709 --> 00:17:33,650
guess is by an example if two clients

00:17:28,910 --> 00:17:35,420
read the database they both make or

00:17:33,650 --> 00:17:38,690
compute some deltas that they want to

00:17:35,420 --> 00:17:41,870
apply then they both come one will come

00:17:38,690 --> 00:17:44,779
first and it will apply its changes

00:17:41,870 --> 00:17:46,580
those will presumably succeed the next

00:17:44,779 --> 00:17:50,539
one will come and try to apply those

00:17:46,580 --> 00:17:52,549
same changes and will be refused because

00:17:50,539 --> 00:17:55,730
you're trying to change something that

00:17:52,549 --> 00:18:01,129
is based on an old view of the network

00:17:55,730 --> 00:18:03,259
or of the configuration so internally

00:18:01,129 --> 00:18:08,049
we'll have objects those objects are

00:18:03,259 --> 00:18:11,330
that represent each one of the the

00:18:08,049 --> 00:18:14,179
configurable entity so like a route or a

00:18:11,330 --> 00:18:17,179
route table or an interface and that for

00:18:14,179 --> 00:18:20,600
us is a place to put just logic with

00:18:17,179 --> 00:18:22,279
respect to how do you manage the

00:18:20,600 --> 00:18:24,230
configuration how do you talk to the

00:18:22,279 --> 00:18:26,389
colonel for this particular type of

00:18:24,230 --> 00:18:30,850
object some of these things have

00:18:26,389 --> 00:18:35,230
different interfaces and so those

00:18:30,850 --> 00:18:38,169
contain that logic they also deal with

00:18:35,230 --> 00:18:41,990
some other things like verification and

00:18:38,169 --> 00:18:44,870
validation that I'll get to in a minute

00:18:41,990 --> 00:18:47,330
so this I wanted to just it's a really

00:18:44,870 --> 00:18:50,779
kind of a really high level course

00:18:47,330 --> 00:18:52,909
picture I'll just highlight three pieces

00:18:50,779 --> 00:18:57,350
and I don't have a slide for each of the

00:18:52,909 --> 00:19:00,080
three pieces this side here is all about

00:18:57,350 --> 00:19:03,009
talking these we call them sources and

00:19:00,080 --> 00:19:06,200
I'll get to that this middle section is

00:19:03,009 --> 00:19:09,200
kind of the heart of the system it's the

00:19:06,200 --> 00:19:11,659
logic for dealing with the configuration

00:19:09,200 --> 00:19:14,330
and and synchronizing the system with

00:19:11,659 --> 00:19:19,070
what the context PEX it to look like and

00:19:14,330 --> 00:19:22,190
then this last tip this last bit is the

00:19:19,070 --> 00:19:26,750
the monitoring and the repair logic that

00:19:22,190 --> 00:19:30,350
Tom alluded to or referred to earlier so

00:19:26,750 --> 00:19:32,179
this one won't come back to this but we

00:19:30,350 --> 00:19:36,559
have in so these three slides that will

00:19:32,179 --> 00:19:42,169
kind of touch on each piece sources for

00:19:36,559 --> 00:19:44,750
us is a way to decouple the internal

00:19:42,169 --> 00:19:46,039
logic from how do you want to talk you

00:19:44,750 --> 00:19:48,810
know what sort of language do you want

00:19:46,039 --> 00:19:51,060
to talk with the client it could be

00:19:48,810 --> 00:19:52,830
for us JSON is kind of ubiquitous

00:19:51,060 --> 00:19:54,900
through our system and so that's kind of

00:19:52,830 --> 00:19:57,660
our natural first stock step but you

00:19:54,900 --> 00:20:00,420
could imagine other things on we've

00:19:57,660 --> 00:20:02,040
d-bus in the context of network

00:20:00,420 --> 00:20:05,010
configuration seems to always come up

00:20:02,040 --> 00:20:07,290
and people ask internally ask us about

00:20:05,010 --> 00:20:08,940
that or we've asked ourselves about that

00:20:07,290 --> 00:20:11,040
if that's the right thing for us to use

00:20:08,940 --> 00:20:14,220
and maybe for some sort of integrations

00:20:11,040 --> 00:20:17,550
or something but this notion of sources

00:20:14,220 --> 00:20:20,370
allows us to sort of say ok will we have

00:20:17,550 --> 00:20:24,830
a place to put that when when we need to

00:20:20,370 --> 00:20:30,480
do something besides just the basic JSON

00:20:24,830 --> 00:20:32,430
yeah so the sequential that that's the

00:20:30,480 --> 00:20:37,140
really the other piece of the concurrent

00:20:32,430 --> 00:20:40,020
actors solution aside from the

00:20:37,140 --> 00:20:43,230
versioning we just do one thing at a

00:20:40,020 --> 00:20:46,950
time so and this is these are config

00:20:43,230 --> 00:20:49,170
changes and so when one config change

00:20:46,950 --> 00:20:51,570
comes in will you take care of it and we

00:20:49,170 --> 00:20:55,290
take care of it in its entirety and then

00:20:51,570 --> 00:20:58,290
we move on to the next one and so on the

00:20:55,290 --> 00:21:01,020
socket source is really for us how you

00:20:58,290 --> 00:21:04,020
talk to the clients this is the internal

00:21:01,020 --> 00:21:06,150
IPC communication so everything in the

00:21:04,020 --> 00:21:09,690
system that is a configurator or an

00:21:06,150 --> 00:21:12,000
actor will come across this simple sort

00:21:09,690 --> 00:21:13,890
of UNIX domain socket it gives us some

00:21:12,000 --> 00:21:16,500
nice features first of all it highlights

00:21:13,890 --> 00:21:19,860
that it's internal only so there's no

00:21:16,500 --> 00:21:23,450
like remote management capabilities and

00:21:19,860 --> 00:21:26,850
then also it gives us some easy

00:21:23,450 --> 00:21:28,740
authorization solutions so that we can

00:21:26,850 --> 00:21:32,370
get the user group and then derived

00:21:28,740 --> 00:21:34,710
network name space from each message

00:21:32,370 --> 00:21:39,960
that we or each request that we get from

00:21:34,710 --> 00:21:41,400
various clients on the system ok so this

00:21:39,960 --> 00:21:46,620
I wanted to just walk through real

00:21:41,400 --> 00:21:49,110
quickly a client request so and this is

00:21:46,620 --> 00:21:53,490
that whole heart of the the middle

00:21:49,110 --> 00:21:55,260
section from the earlier diagram so the

00:21:53,490 --> 00:21:57,390
client request comes in and says I want

00:21:55,260 --> 00:21:58,860
to change something some configuration

00:21:57,390 --> 00:22:00,059
doesn't matter what it is

00:21:58,860 --> 00:22:04,409
and

00:22:00,059 --> 00:22:08,869
so the the first thing we'll do is we'll

00:22:04,409 --> 00:22:08,869
clone this internal database and we'll

00:22:09,710 --> 00:22:16,320
then give that to the source that

00:22:13,859 --> 00:22:19,830
abstraction and say here please apply

00:22:16,320 --> 00:22:25,529
your changes to this this clone of the

00:22:19,830 --> 00:22:28,950
database once that's done then we'll

00:22:25,529 --> 00:22:35,190
take that full clone and we'll validate

00:22:28,950 --> 00:22:36,719
it and there's there's two that mean so

00:22:35,190 --> 00:22:38,609
there's there's two kinds of validations

00:22:36,719 --> 00:22:40,589
there's the syntactic validation which

00:22:38,609 --> 00:22:42,659
says you know is everything in range or

00:22:40,589 --> 00:22:45,719
did they pick some silly value that's

00:22:42,659 --> 00:22:47,429
just never going to apply to the kernel

00:22:45,719 --> 00:22:49,559
will just outright reject but then

00:22:47,429 --> 00:22:54,989
there's more complicated the semantics

00:22:49,559 --> 00:22:58,159
sort of enter object validations that

00:22:54,989 --> 00:23:01,049
allow us to say for instance they're

00:22:58,159 --> 00:23:03,450
trying to install some route and there's

00:23:01,049 --> 00:23:08,549
no interface to go to get through that

00:23:03,450 --> 00:23:12,049
that next hop router and so there's the

00:23:08,549 --> 00:23:17,369
the main point of this validation phase

00:23:12,049 --> 00:23:20,149
is to come out with high confidence that

00:23:17,369 --> 00:23:23,580
we will be able to apply this

00:23:20,149 --> 00:23:25,259
configuration change to the kernel and

00:23:23,580 --> 00:23:25,889
that'll make a little more sense as we

00:23:25,259 --> 00:23:29,789
move on

00:23:25,889 --> 00:23:31,259
so the next thing now that we have this

00:23:29,789 --> 00:23:34,889
high confidence that this configuration

00:23:31,259 --> 00:23:39,029
change is good then we deal with writing

00:23:34,889 --> 00:23:42,539
it to files we save our internal state

00:23:39,029 --> 00:23:45,029
and we log maybe you know for like a

00:23:42,539 --> 00:23:46,919
journal type change log so that we can

00:23:45,029 --> 00:23:49,700
see you know just one after the other

00:23:46,919 --> 00:23:53,519
what sort of changes the the client made

00:23:49,700 --> 00:23:56,999
or all the clients together made and so

00:23:53,519 --> 00:24:00,330
then once we've written this information

00:23:56,999 --> 00:24:03,539
out and all of that has succeeded then

00:24:00,330 --> 00:24:06,479
we make this clone proposed

00:24:03,539 --> 00:24:09,120
configuration the active configuration

00:24:06,479 --> 00:24:14,640
and that's when this version increment

00:24:09,120 --> 00:24:17,430
and so anything the before this step if

00:24:14,640 --> 00:24:23,160
if something fails were able to just

00:24:17,430 --> 00:24:26,550
throw away this proposed change and the

00:24:23,160 --> 00:24:31,680
system is is exactly the same way that

00:24:26,550 --> 00:24:33,720
it was so it's a unchanged its once and

00:24:31,680 --> 00:24:34,980
so this kind of gets back to that point

00:24:33,720 --> 00:24:38,610
that tom was making about these

00:24:34,980 --> 00:24:42,540
transactional guarantees that we make

00:24:38,610 --> 00:24:47,160
that to the configuration not to the

00:24:42,540 --> 00:24:51,240
system state and so at this point once

00:24:47,160 --> 00:24:53,940
we've accepted that configuration we've

00:24:51,240 --> 00:24:55,950
incremented the version then we make

00:24:53,940 --> 00:25:00,420
this first past attempt to modify the

00:24:55,950 --> 00:25:02,670
system and I say first past because

00:25:00,420 --> 00:25:05,820
maybe there's something that takes time

00:25:02,670 --> 00:25:07,559
or we need you know some things need to

00:25:05,820 --> 00:25:10,140
settle and before all of the

00:25:07,559 --> 00:25:13,010
configuration changes can be made and

00:25:10,140 --> 00:25:16,830
that's where this next phase comes in

00:25:13,010 --> 00:25:20,070
notice though that if something fails at

00:25:16,830 --> 00:25:22,110
this point we're not failing the change

00:25:20,070 --> 00:25:24,330
there's no that as far as the client

00:25:22,110 --> 00:25:28,650
concerned their change was successful

00:25:24,330 --> 00:25:32,429
and now this demon is responsible for

00:25:28,650 --> 00:25:34,500
making the system look in that state and

00:25:32,429 --> 00:25:36,620
so then that's when this monitoring

00:25:34,500 --> 00:25:39,840
repair becomes or comes into the picture

00:25:36,620 --> 00:25:42,210
and so it has the ability to look at

00:25:39,840 --> 00:25:44,910
things that didn't apply completely the

00:25:42,210 --> 00:25:47,900
first time or that needed some more time

00:25:44,910 --> 00:25:51,690
to be able to successfully apply or

00:25:47,900 --> 00:25:53,790
maybe some software error or some other

00:25:51,690 --> 00:25:55,440
problem or even a user has logged on to

00:25:53,790 --> 00:25:58,650
the system and deleted something that

00:25:55,440 --> 00:26:00,809
the software that the you know like the

00:25:58,650 --> 00:26:02,790
cluster master software has said no it

00:26:00,809 --> 00:26:05,580
needs to be in this state so the system

00:26:02,790 --> 00:26:08,700
will notice those problems will detect

00:26:05,580 --> 00:26:12,179
that and well first of all generate a

00:26:08,700 --> 00:26:15,090
notification for these problems and then

00:26:12,179 --> 00:26:18,600
secondly on attempt to put the

00:26:15,090 --> 00:26:21,240
configuration back and then if they do

00:26:18,600 --> 00:26:22,600
you know if it does successfully repair

00:26:21,240 --> 00:26:24,220
the configuration then it can go

00:26:22,600 --> 00:26:26,140
unclear that notification and the client

00:26:24,220 --> 00:26:27,850
is you know there was a little fault

00:26:26,140 --> 00:26:32,380
that popped up in one way but that's

00:26:27,850 --> 00:26:35,169
okay it's all better so that's kind of

00:26:32,380 --> 00:26:39,610
the walk through for this system that

00:26:35,169 --> 00:26:43,270
were that we're working on the reason

00:26:39,610 --> 00:26:46,270
that were here yes we I mean so this

00:26:43,270 --> 00:26:50,110
this is something that we mentioned that

00:26:46,270 --> 00:26:52,390
we looked for a solution that did fit

00:26:50,110 --> 00:26:55,630
what we were trying to fit our

00:26:52,390 --> 00:26:57,340
requirements didn't exactly find it

00:26:55,630 --> 00:26:58,659
there really are some good solutions out

00:26:57,340 --> 00:27:01,350
there and there were some that were very

00:26:58,659 --> 00:27:06,960
close and I would definitely admit that

00:27:01,350 --> 00:27:10,150
but we felt like there was room for

00:27:06,960 --> 00:27:12,250
something that was more along what we

00:27:10,150 --> 00:27:14,159
like what we've described and so we do

00:27:12,250 --> 00:27:19,809
intend to share this with the community

00:27:14,159 --> 00:27:22,690
and we're eager to have feedback and to

00:27:19,809 --> 00:27:25,750
hear ideas this is a stupid idea this is

00:27:22,690 --> 00:27:28,919
great or somewhere in between and

00:27:25,750 --> 00:27:32,770
different things to point out um also

00:27:28,919 --> 00:27:38,140
you know to to work with others as well

00:27:32,770 --> 00:27:41,140
so yeah these other two bullets I will

00:27:38,140 --> 00:27:45,220
I'm pretty short so short on time so I

00:27:41,140 --> 00:27:47,950
will just skip those but yeah I mean we

00:27:45,220 --> 00:27:50,230
do have a substantial investment in

00:27:47,950 --> 00:27:52,120
testing I'm really happy to have this

00:27:50,230 --> 00:27:54,880
project grow up in that environment

00:27:52,120 --> 00:27:57,010
it'll get banged on pretty hard and in

00:27:54,880 --> 00:27:59,679
addition to just the testing the Tom and

00:27:57,010 --> 00:28:03,820
I will do as part as developers of the

00:27:59,679 --> 00:28:06,909
system there's substantial tests staff

00:28:03,820 --> 00:28:08,950
infrastructure environments that it will

00:28:06,909 --> 00:28:14,730
also go through as part of being part of

00:28:08,950 --> 00:28:14,730
other products so yep

00:28:19,390 --> 00:28:34,650
[Applause]

00:28:22,820 --> 00:28:36,300
any questions no questions you have a

00:28:34,650 --> 00:28:45,510
question oh there's a question back

00:28:36,300 --> 00:28:47,310
there Jamal hi so to go back like two

00:28:45,510 --> 00:28:49,440
slides I think this is very useful and

00:28:47,310 --> 00:28:52,230
you mentioned there are other systems

00:28:49,440 --> 00:28:55,170
like this but they are not exactly like

00:28:52,230 --> 00:28:57,410
this can you sort of summarize exactly

00:28:55,170 --> 00:28:59,880
what's unique about your solution and

00:28:57,410 --> 00:29:03,060
what systems it differs from or looks

00:28:59,880 --> 00:29:06,600
most like yeah to some degree I

00:29:03,060 --> 00:29:09,390
purposefully came up here choosing not

00:29:06,600 --> 00:29:13,920
to name names in cooking and throw darts

00:29:09,390 --> 00:29:16,440
so but like I said there's some really

00:29:13,920 --> 00:29:22,040
good things out there and they were

00:29:16,440 --> 00:29:26,400
close the the biggest problem that we

00:29:22,040 --> 00:29:29,900
kept coming across was finding too much

00:29:26,400 --> 00:29:32,400
stuff kind of bundled up into too much

00:29:29,900 --> 00:29:34,080
application specific logic bundled up

00:29:32,400 --> 00:29:37,230
into the configuration configuration

00:29:34,080 --> 00:29:39,750
system so there would be some extra

00:29:37,230 --> 00:29:42,600
assumptions that didn't apply to what we

00:29:39,750 --> 00:29:47,250
were trying to do Tom mentioned we've

00:29:42,600 --> 00:29:49,380
also had some problems with one system

00:29:47,250 --> 00:29:52,550
that we're using now that just likes to

00:29:49,380 --> 00:29:55,070
tear things down when you make a change

00:29:52,550 --> 00:29:58,980
so there's yes I mean there's a

00:29:55,070 --> 00:30:01,230
collection of different little issues

00:29:58,980 --> 00:30:04,160
that we and in the end I guess the main

00:30:01,230 --> 00:30:06,060
point for us was that we wanted to

00:30:04,160 --> 00:30:08,790
something that really allowed us to

00:30:06,060 --> 00:30:11,250
focus on what we felt like were kind of

00:30:08,790 --> 00:30:15,900
best practices for application design

00:30:11,250 --> 00:30:19,400
and designing a robust reliable system

00:30:15,900 --> 00:30:19,400
without having to work around

00:30:19,720 --> 00:30:24,950
some things that force that's kind of

00:30:22,250 --> 00:30:26,360
into a corner wrong I think it got back

00:30:24,950 --> 00:30:29,480
to when I was trying in the beginning to

00:30:26,360 --> 00:30:32,240
say what we're building this thing and

00:30:29,480 --> 00:30:34,850
really the things we need some of some

00:30:32,240 --> 00:30:37,460
of the solutions are great we need we

00:30:34,850 --> 00:30:39,830
need like some guarantees around the

00:30:37,460 --> 00:30:43,610
config moving from consistent state to

00:30:39,830 --> 00:30:46,820
consistent state or some solutions will

00:30:43,610 --> 00:30:48,260
get us where we want to go but there's

00:30:46,820 --> 00:30:53,470
there's not an active monitoring

00:30:48,260 --> 00:30:55,730
solution and repair built into it that I

00:30:53,470 --> 00:30:58,400
don't think we found anything that

00:30:55,730 --> 00:30:59,750
really met if you forget even monitoring

00:30:58,400 --> 00:31:03,110
a repair like let's assume we could

00:30:59,750 --> 00:31:07,100
build that on top of clumpy no that

00:31:03,110 --> 00:31:09,230
really got us the transaction stuff you

00:31:07,100 --> 00:31:10,790
did a lot more research on this kind of

00:31:09,230 --> 00:31:12,740
stuff so I can't leave it to you but I

00:31:10,790 --> 00:31:16,429
came across as like checking all of

00:31:12,740 --> 00:31:18,980
those boxes that a lot of this we

00:31:16,429 --> 00:31:21,650
actually have today in the SolidFire

00:31:18,980 --> 00:31:22,910
system and going to I don't even know if

00:31:21,650 --> 00:31:26,000
we found a system that wouldn't be a

00:31:22,910 --> 00:31:28,250
regression for us as far as what network

00:31:26,000 --> 00:31:30,190
like what we do in a SolidFire product

00:31:28,250 --> 00:31:32,390
that we're trying to keep and pull out I

00:31:30,190 --> 00:31:33,559
have a fuzzy answer I'm not giving

00:31:32,390 --> 00:31:36,169
statistics and we're trying to avoid

00:31:33,559 --> 00:31:45,710
naming certain things and well yeah yeah

00:31:36,169 --> 00:31:46,900
so this sounds great anything else thank

00:31:45,710 --> 00:31:50,259
you

00:31:46,900 --> 00:31:50,259

YouTube URL: https://www.youtube.com/watch?v=eYp5xAr-irA


