Title: Netdev 2.1 Network Testing with Netesto By Lawrence Brakmo
Publication date: 2017-06-03
Playlist: Netdev 2.1
Description: 
	In this talk given on April the 7th 2017 at Netdev 2.1, Lawrence Brakmo describes Netesto.

Netesto (NEtwork TESting TOolkit) is a suite of tools for running multi-host network experiments that supports the collection and display of relevant data and statistics.

Content: https://www.netdevconf.org/2.1/session.html?brakmo
Captions: 
	00:00:00,030 --> 00:00:04,069
so my name is our Lord Bracknell and I'm

00:00:02,370 --> 00:00:06,240
a member of the colonel team at Facebook

00:00:04,069 --> 00:00:08,309
I've been interested in a network

00:00:06,240 --> 00:00:11,190
performance for a long time specifically

00:00:08,309 --> 00:00:13,469
with TCP performance and the main lesson

00:00:11,190 --> 00:00:16,109
I've learned during this time is the

00:00:13,469 --> 00:00:17,910
value of good testing tools you know

00:00:16,109 --> 00:00:20,160
they are priceless and what I mean by a

00:00:17,910 --> 00:00:23,760
good tool I mean a tool because you can

00:00:20,160 --> 00:00:25,769
specify in a scenario very easily you

00:00:23,760 --> 00:00:28,140
can run it you can collect that data you

00:00:25,769 --> 00:00:30,240
need to bring it back create some

00:00:28,140 --> 00:00:31,710
initial output that you can look at and

00:00:30,240 --> 00:00:35,790
then be able to analyze the data in

00:00:31,710 --> 00:00:37,050
multiple dimensions the second lesson I

00:00:35,790 --> 00:00:40,860
learned is that it's very difficult to

00:00:37,050 --> 00:00:44,219
buy these tools Sony testo the network

00:00:40,860 --> 00:00:47,399
testing tool kit is my attempt to do

00:00:44,219 --> 00:00:56,219
this and it's proven very valuable for

00:00:47,399 --> 00:00:57,989
me and the remote is ok so what does it

00:00:56,219 --> 00:01:01,410
look like you know to run under net

00:00:57,989 --> 00:01:03,660
tester so you have a set of servers the

00:01:01,410 --> 00:01:06,000
testing servers that are running the net

00:01:03,660 --> 00:01:07,680
test of service you know a demon they

00:01:06,000 --> 00:01:11,090
will accept connections for the net

00:01:07,680 --> 00:01:13,770
tester controller okay and by the way a

00:01:11,090 --> 00:01:18,140
host can be the controller and a server

00:01:13,770 --> 00:01:21,840
at the same time in a particular test a

00:01:18,140 --> 00:01:24,119
subset of the servers will decline and

00:01:21,840 --> 00:01:26,670
others would be servers test servers

00:01:24,119 --> 00:01:28,409
that means that the client will

00:01:26,670 --> 00:01:31,590
visualize connections to the test

00:01:28,409 --> 00:01:33,329
servers okay and once again the same

00:01:31,590 --> 00:01:38,670
host can be bought a test client and a

00:01:33,329 --> 00:01:40,439
test server the type of file flows that

00:01:38,670 --> 00:01:41,850
I took that it supports right now are

00:01:40,439 --> 00:01:45,329
based in net worth

00:01:41,850 --> 00:01:47,700
so in particular TCP stream and TCP

00:01:45,329 --> 00:01:50,280
requests reply it would be very easy to

00:01:47,700 --> 00:01:53,070
us support for UDP and others I don't

00:01:50,280 --> 00:01:56,520
haven't done it because I haven't had I

00:01:53,070 --> 00:01:59,159
need to do it myself and then the dental

00:01:56,520 --> 00:02:01,590
controller just talks to the tester

00:01:59,159 --> 00:02:05,689
servers and give them commands star

00:02:01,590 --> 00:02:05,689
flows collect data etc

00:02:09,280 --> 00:02:13,790
so there should be some warning and it

00:02:11,599 --> 00:02:16,519
has to grew organically I did not sit

00:02:13,790 --> 00:02:19,010
down one day and thought you know to

00:02:16,519 --> 00:02:20,420
design a really great testing tool do a

00:02:19,010 --> 00:02:21,319
beautiful design and do a beautiful

00:02:20,420 --> 00:02:23,330
implementation

00:02:21,319 --> 00:02:25,610
it grew organically I needed to do some

00:02:23,330 --> 00:02:27,709
basic stuff I implemented it I did a

00:02:25,610 --> 00:02:29,989
more complex stuff I added those

00:02:27,709 --> 00:02:31,580
features and it grew like that and

00:02:29,989 --> 00:02:34,819
because of that you reflect some of my

00:02:31,580 --> 00:02:36,080
idea of synchronous for example right

00:02:34,819 --> 00:02:36,769
now again it's one being tested without

00:02:36,080 --> 00:02:38,930
tv6

00:02:36,769 --> 00:02:41,120
because at Facebook all our production

00:02:38,930 --> 00:02:44,630
servers you know run at 36 most of them

00:02:41,120 --> 00:02:48,769
do not even run a TV for I have a

00:02:44,630 --> 00:02:50,329
graphing tool and anybody saying who had

00:02:48,769 --> 00:02:53,569
used one of the existing tools to do

00:02:50,329 --> 00:02:56,450
grass on the other hand somebody like me

00:02:53,569 --> 00:02:59,180
a long time ago when I was developing

00:02:56,450 --> 00:03:01,970
TCP Vegas I needed to create really

00:02:59,180 --> 00:03:05,799
complex graph that I wanted to also be

00:03:01,970 --> 00:03:05,799
able to publish in tournament in

00:03:06,519 --> 00:03:16,549
conferences or other places and for that

00:03:13,010 --> 00:03:19,489
they need to be a based on posted so my

00:03:16,549 --> 00:03:23,060
graphing tools is actually written in

00:03:19,489 --> 00:03:27,889
PostScript so very powerful by this

00:03:23,060 --> 00:03:30,319
QWERTY the main tools are written in

00:03:27,889 --> 00:03:34,040
Python and originally I envisioned

00:03:30,319 --> 00:03:37,389
writing the test scenarios in Python but

00:03:34,040 --> 00:03:40,760
then I ended up actually implementing a

00:03:37,389 --> 00:03:43,519
simple test clicking scripting language

00:03:40,760 --> 00:03:46,579
for two reasons one it was actually

00:03:43,519 --> 00:03:48,769
easier to write the scripts that way it

00:03:46,579 --> 00:03:52,690
was I thought was cleaner secondly is

00:03:48,769 --> 00:03:56,720
that as we start to share test scripts

00:03:52,690 --> 00:03:59,000
is safer to do it without more limited

00:03:56,720 --> 00:04:01,970
scripting language as opposed to sharing

00:03:59,000 --> 00:04:04,700
Python layer programs that can do a lot

00:04:01,970 --> 00:04:10,190
of other things intentionally or

00:04:04,700 --> 00:04:12,109
unintentionally so in generality so that

00:04:10,190 --> 00:04:14,239
we set up as two different directories

00:04:12,109 --> 00:04:16,509
one you stolen your test servers the

00:04:14,239 --> 00:04:18,829
other one you store in your your client

00:04:16,509 --> 00:04:20,560
you will start the service the test

00:04:18,829 --> 00:04:22,960
would be Y - s

00:04:20,560 --> 00:04:25,960
if you want you can also create a lot

00:04:22,960 --> 00:04:28,690
and then to run locally you just give it

00:04:25,960 --> 00:04:33,430
a script file and it would just do

00:04:28,690 --> 00:04:35,350
everything so what doesn't that that's a

00:04:33,430 --> 00:04:37,630
plain doing general you know there are

00:04:35,350 --> 00:04:40,270
commands to do test setup so for example

00:04:37,630 --> 00:04:42,700
you could use a net en to introduce

00:04:40,270 --> 00:04:46,900
delays in the experiment you can use a

00:04:42,700 --> 00:04:49,330
clean discipline to reduce bandwidth and

00:04:46,900 --> 00:04:52,210
test you know different buffer sizes at

00:04:49,330 --> 00:04:54,550
other bottlenecks it also collect Nishal

00:04:52,210 --> 00:04:56,140
information before or not and then at

00:04:54,550 --> 00:04:59,440
the end of the test so these are

00:04:56,140 --> 00:05:03,160
typically counters like netstat SNMP

00:04:59,440 --> 00:05:05,860
snp6 but it also collect for example the

00:05:03,160 --> 00:05:08,740
output of sis control - a and also the

00:05:05,860 --> 00:05:10,390
output for me th - and the reason to do

00:05:08,740 --> 00:05:12,370
that is that many times of this running

00:05:10,390 --> 00:05:14,830
experiment you're analyzing the data and

00:05:12,370 --> 00:05:16,090
you see something unexpected and the

00:05:14,830 --> 00:05:18,970
first thing you want to do is make sure

00:05:16,090 --> 00:05:21,100
that there was not something set up on

00:05:18,970 --> 00:05:24,040
the system that affected the results and

00:05:21,100 --> 00:05:26,530
because I save all the state information

00:05:24,040 --> 00:05:30,070
of the system I can look at it and make

00:05:26,530 --> 00:05:32,950
sure that nothing weird is going on and

00:05:30,070 --> 00:05:34,510
then we'll start flows and it starts the

00:05:32,950 --> 00:05:36,880
flow collection information so we use

00:05:34,510 --> 00:05:38,620
networks to start the flows it would use

00:05:36,880 --> 00:05:42,850
access to collect information about the

00:05:38,620 --> 00:05:46,360
flows condition Windows RT T's which was

00:05:42,850 --> 00:05:50,020
meat and it actually runs ping to be

00:05:46,360 --> 00:05:52,570
able to measure delays when the test

00:05:50,020 --> 00:05:54,010
would finish it will locally process a

00:05:52,570 --> 00:05:57,460
lot of information create a key value

00:05:54,010 --> 00:05:59,560
pair file all the data is copied back to

00:05:57,460 --> 00:06:02,289
the controller the controller aggregates

00:05:59,560 --> 00:06:05,860
this individual test key value files

00:06:02,289 --> 00:06:08,200
into an aggregate equally also obtains a

00:06:05,860 --> 00:06:09,820
comma separated value file with with the

00:06:08,200 --> 00:06:11,650
results and I'll show you that for a

00:06:09,820 --> 00:06:14,050
loop circuit in a second and then you

00:06:11,650 --> 00:06:17,860
create graph for activities you know

00:06:14,050 --> 00:06:21,910
good food congestion windows and you can

00:06:17,860 --> 00:06:24,640
also process the CSV files to create

00:06:21,910 --> 00:06:26,919
more complex dimensions of the results

00:06:24,640 --> 00:06:29,440
and most of this is done automatically

00:06:26,919 --> 00:06:32,320
you just run the script and everything

00:06:29,440 --> 00:06:33,840
happened by magic and the script can run

00:06:32,320 --> 00:06:36,630
like hundreds of tests

00:06:33,840 --> 00:06:39,990
you better run and you don't worry about

00:06:36,630 --> 00:06:43,020
it now what about security

00:06:39,990 --> 00:06:46,080
you know we're running a service on

00:06:43,020 --> 00:06:48,510
these machines other people you know

00:06:46,080 --> 00:06:50,100
their machines could need to hook up -

00:06:48,510 --> 00:06:52,770
you could hook up to it and maybe try to

00:06:50,100 --> 00:06:55,380
do something bad so there are some

00:06:52,770 --> 00:06:57,870
mechanisms - for security but they are

00:06:55,380 --> 00:06:59,520
limited one is by using a test script

00:06:57,870 --> 00:07:02,940
language at least locally for the

00:06:59,520 --> 00:07:04,950
controller it cannot do any really worse

00:07:02,940 --> 00:07:10,350
things right the scripting languages is

00:07:04,950 --> 00:07:13,139
a can only do Network kind type of work

00:07:10,350 --> 00:07:16,200
workload right the service also have a

00:07:13,139 --> 00:07:18,960
whitelist of whom they will accept

00:07:16,200 --> 00:07:21,750
connection from so that prevents anybody

00:07:18,960 --> 00:07:23,370
else to connecting to them and also the

00:07:21,750 --> 00:07:26,400
command that the remote commands going

00:07:23,370 --> 00:07:28,620
to the new test acerous are very limited

00:07:26,400 --> 00:07:31,800
and will specify so for example the get

00:07:28,620 --> 00:07:33,570
data command to copy the data back you

00:07:31,800 --> 00:07:35,750
do not tell a quad to copy it would only

00:07:33,570 --> 00:07:38,850
copy the data related to the experiment

00:07:35,750 --> 00:07:41,130
okay so you cannot try to be use it to

00:07:38,850 --> 00:07:45,210
copy something else on that system you

00:07:41,130 --> 00:07:49,650
know you don't have the choice so what

00:07:45,210 --> 00:07:51,870
does a simple script look like okay the

00:07:49,650 --> 00:07:54,000
first line says house host Suffolk and

00:07:51,870 --> 00:07:55,169
then a domain name and this is just a

00:07:54,000 --> 00:07:57,720
shortcut so I don't have to use the

00:07:55,169 --> 00:08:00,690
domain name for that when I certify the

00:07:57,720 --> 00:08:04,200
host names then sourcing lib is reading

00:08:00,690 --> 00:08:06,600
the default macro library that I'd

00:08:04,200 --> 00:08:09,450
written then I set some variables like

00:08:06,600 --> 00:08:12,180
duration or the experiment 60 seconds

00:08:09,450 --> 00:08:15,419
duration number - so this clip will run

00:08:12,180 --> 00:08:18,539
- string tests the second one will start

00:08:15,419 --> 00:08:21,539
within the first one so we'll wait on

00:08:18,539 --> 00:08:23,460
like 20 seconds start the string and

00:08:21,539 --> 00:08:25,410
then ended because I want to see that

00:08:23,460 --> 00:08:26,729
dynamic what happens when you're running

00:08:25,410 --> 00:08:28,470
one flow and you start another one in

00:08:26,729 --> 00:08:31,229
the middle

00:08:28,470 --> 00:08:33,450
you say the condition avoidance DVR for

00:08:31,229 --> 00:08:35,360
example and something that is not here

00:08:33,450 --> 00:08:38,130
but it was before I just didn't copy it

00:08:35,360 --> 00:08:40,200
I'm also setting between discipline to

00:08:38,130 --> 00:08:42,930
be the surfer queuing to discipline and

00:08:40,200 --> 00:08:46,560
then the last command is the run

00:08:42,930 --> 00:08:47,819
specifies to run a macro the comma one

00:08:46,560 --> 00:08:49,290
that one could be any number it tells

00:08:47,819 --> 00:08:51,420
you how many times you want to run it

00:08:49,290 --> 00:08:54,269
and the reason you want to do that is I

00:08:51,420 --> 00:08:57,300
would packet based networks smoke

00:08:54,269 --> 00:08:59,129
perturbations can create very different

00:08:57,300 --> 00:09:01,319
results so many times you want to run a

00:08:59,129 --> 00:09:03,269
multiple time and most of my masters had

00:09:01,319 --> 00:09:04,819
setup that they introduced small

00:09:03,269 --> 00:09:12,300
perturbations and experiments

00:09:04,819 --> 00:09:16,259
automatically okay so this is for

00:09:12,300 --> 00:09:21,720
example a sample output on top is what

00:09:16,259 --> 00:09:23,550
the CSV file would look like the

00:09:21,720 --> 00:09:25,170
experiments have individual names if you

00:09:23,550 --> 00:09:27,839
click on the program name it will show

00:09:25,170 --> 00:09:30,240
you a summary that includes the gulper

00:09:27,839 --> 00:09:34,170
and congestion window grass plus other

00:09:30,240 --> 00:09:36,839
graph RTT etc and it has I only am only

00:09:34,170 --> 00:09:38,430
showing a few of the fields that are

00:09:36,839 --> 00:09:43,189
usually collect I collect a lot more

00:09:38,430 --> 00:09:45,420
than that so this is the same graph but

00:09:43,189 --> 00:09:48,059
individual so given the back and see it

00:09:45,420 --> 00:09:51,779
better so this is the good put right we

00:09:48,059 --> 00:09:54,420
start one flow initially in blue VBR and

00:09:51,779 --> 00:09:56,970
VBR every 10 seconds is like the quiz

00:09:54,420 --> 00:10:00,269
detection window to probe the the

00:09:56,970 --> 00:10:03,000
network then run 23 seconds we start the

00:10:00,269 --> 00:10:05,250
second flow things look very cleanly you

00:10:03,000 --> 00:10:07,860
know the their achievement bodies the

00:10:05,250 --> 00:10:10,589
same bandwidth the second flow ends at

00:10:07,860 --> 00:10:13,879
43 seconds on the engine so it looks

00:10:10,589 --> 00:10:16,050
very cleanly done by VBR in this example

00:10:13,879 --> 00:10:19,470
and this is what the congestion windows

00:10:16,050 --> 00:10:21,329
look like you know every 10 seconds more

00:10:19,470 --> 00:10:23,639
layers maybe i'll decreases the

00:10:21,329 --> 00:10:26,309
condition window to pro the network you

00:10:23,639 --> 00:10:31,139
know it has a face we just never seen do

00:10:26,309 --> 00:10:33,240
tonight so what does the Mac you look

00:10:31,139 --> 00:10:38,279
like that I run you know he was a two

00:10:33,240 --> 00:10:41,879
floor macro so it begins with the name

00:10:38,279 --> 00:10:43,589
of the macro begins the macro name the

00:10:41,879 --> 00:10:46,819
experiment counter means you know use

00:10:43,589 --> 00:10:49,589
the next number for the experiment ID

00:10:46,819 --> 00:10:52,199
then I have like a nice depth preserver

00:10:49,589 --> 00:10:54,870
so if I define the macro 3 server will

00:10:52,199 --> 00:10:56,129
be run at this time and I like to do

00:10:54,870 --> 00:10:58,470
this because for example I want to make

00:10:56,129 --> 00:10:59,570
sure the my experiments are not affected

00:10:58,470 --> 00:11:01,550
by

00:10:59,570 --> 00:11:04,610
settings that are default in the system

00:11:01,550 --> 00:11:06,800
for example fan or receive buffer sizes

00:11:04,610 --> 00:11:08,990
right what we're trying to do congestion

00:11:06,800 --> 00:11:12,890
control experiment I want to pollute the

00:11:08,990 --> 00:11:16,430
results by having buffer sizes that you

00:11:12,890 --> 00:11:20,420
know are very small or very you know do

00:11:16,430 --> 00:11:22,100
not really let the collision control try

00:11:20,420 --> 00:11:24,920
to figure out what is the right brake

00:11:22,100 --> 00:11:27,110
you should be going then I start the do

00:11:24,920 --> 00:11:29,510
server command that just collects the

00:11:27,110 --> 00:11:31,940
statistics initially then I do the same

00:11:29,510 --> 00:11:34,070
for that client the freak line dr. Kline

00:11:31,940 --> 00:11:36,680
macro is defined I would run it

00:11:34,070 --> 00:11:39,730
typically do it to set buffer sizes

00:11:36,680 --> 00:11:42,380
center to see buffer sizes very large I

00:11:39,730 --> 00:11:45,140
also have a you know if there's a TCP

00:11:42,380 --> 00:11:47,780
dump variables define I will run TCP

00:11:45,140 --> 00:11:49,550
dump on the client and I will collect

00:11:47,780 --> 00:11:51,860
only the package that going from the

00:11:49,550 --> 00:11:54,260
client to the server and I will collect

00:11:51,860 --> 00:11:57,080
as many clients as artifically dump

00:11:54,260 --> 00:11:59,150
variable specifies right so it's really

00:11:57,080 --> 00:12:01,160
easy to run experiments where you know

00:11:59,150 --> 00:12:03,200
we can collect TTP dam would collect

00:12:01,160 --> 00:12:06,020
congestion windows and it's all almost

00:12:03,200 --> 00:12:08,870
you know transparently for you then you

00:12:06,020 --> 00:12:11,420
know I run the client I waste a random

00:12:08,870 --> 00:12:13,370
delay typically between like between

00:12:11,420 --> 00:12:17,050
zero and one second will be uniformly

00:12:13,370 --> 00:12:20,630
distributed before I start the second

00:12:17,050 --> 00:12:23,330
flow so the second flow will start 23

00:12:20,630 --> 00:12:25,640
seconds later plus that delay and the

00:12:23,330 --> 00:12:29,240
reason I added random delayed because if

00:12:25,640 --> 00:12:31,130
I run the same macro many times I will

00:12:29,240 --> 00:12:33,800
get different results to the small

00:12:31,130 --> 00:12:38,270
perturbation of the start time will

00:12:33,800 --> 00:12:40,610
create significant different results and

00:12:38,270 --> 00:12:42,230
then you know like I collect the

00:12:40,610 --> 00:12:44,390
information at the end with a do server

00:12:42,230 --> 00:12:45,770
where a little bit get the data as you

00:12:44,390 --> 00:12:48,140
can see there there's no specification

00:12:45,770 --> 00:12:51,310
about the data the data is experiment

00:12:48,140 --> 00:12:53,960
for the experiment was running and then

00:12:51,310 --> 00:12:56,120
so this is what's running locally then I

00:12:53,960 --> 00:12:57,800
process the experiment that would you

00:12:56,120 --> 00:13:02,470
not date there's to be a file and create

00:12:57,800 --> 00:13:05,330
the graphs and do all that so this is a

00:13:02,470 --> 00:13:06,890
the same macro but now we're running

00:13:05,330 --> 00:13:09,470
with 10 milliseconds RTT

00:13:06,890 --> 00:13:12,280
and only a hundred megabits of 10

00:13:09,470 --> 00:13:12,280
gigabits per second

00:13:12,710 --> 00:13:17,020
so in this case you know the behavior is

00:13:14,600 --> 00:13:21,020
a little bit different as you can see

00:13:17,020 --> 00:13:23,480
you know DVR starts very nicely when the

00:13:21,020 --> 00:13:25,850
new flow starts you know you lose a

00:13:23,480 --> 00:13:27,920
little bit of utilization and then you

00:13:25,850 --> 00:13:30,430
start staying around but then we insert

00:13:27,920 --> 00:13:36,100
in which habit when the second flow ends

00:13:30,430 --> 00:13:38,000
the first flow states law right

00:13:36,100 --> 00:13:41,810
you know sometimes that happens

00:13:38,000 --> 00:13:45,290
sometimes it doesn't happen and I guess

00:13:41,810 --> 00:13:47,570
I should have shown you the big graph

00:13:45,290 --> 00:13:48,530
okay so this is for good food and this

00:13:47,570 --> 00:13:49,760
is for congestion window

00:13:48,530 --> 00:13:51,650
you know the congestion window for the

00:13:49,760 --> 00:13:56,560
first flow went down and for some reason

00:13:51,650 --> 00:13:59,120
is stay low and the vertical bars are

00:13:56,560 --> 00:14:01,010
retransmissions so you know that in the

00:13:59,120 --> 00:14:04,190
middle when they were both running there

00:14:01,010 --> 00:14:09,890
was some congestion and if we look at

00:14:04,190 --> 00:14:11,720
the on this one the last field column is

00:14:09,890 --> 00:14:15,650
that Richard meets percent right so

00:14:11,720 --> 00:14:17,180
there were 1.7 which was made 1.7

00:14:15,650 --> 00:14:24,260
percent of the packets were interested

00:14:17,180 --> 00:14:29,300
for this experiment so you know I ran

00:14:24,260 --> 00:14:31,040
the same script again right and that's

00:14:29,300 --> 00:14:33,260
why that's the value of the macro comma

00:14:31,040 --> 00:14:35,810
repetitions and yet with the smoke

00:14:33,260 --> 00:14:36,950
predation that happens naturally I got a

00:14:35,810 --> 00:14:38,630
very different result

00:14:36,950 --> 00:14:40,910
right the first flow is doing

00:14:38,630 --> 00:14:42,470
beautifully you know it states there

00:14:40,910 --> 00:14:46,100
that congestion window does not keep

00:14:42,470 --> 00:14:48,560
growing right so I like to do that we

00:14:46,100 --> 00:14:51,530
just keep wrong it and you have buffer

00:14:48,560 --> 00:14:56,410
bloat it stays you know a done at a good

00:14:51,530 --> 00:15:00,160
level but the second flow in this case

00:14:56,410 --> 00:15:02,839
did not grow right for some reason is

00:15:00,160 --> 00:15:04,730
assumed there was too mad you know if

00:15:02,839 --> 00:15:10,130
I'd already achieve as much bandwidth as

00:15:04,730 --> 00:15:14,480
it could I missed a load nice so for

00:15:10,130 --> 00:15:18,170
example I run these same script 25 times

00:15:14,480 --> 00:15:20,959
and 3 of those 25 times this happen

00:15:18,170 --> 00:15:24,430
for the second flow just stayed low you

00:15:20,959 --> 00:15:24,430
know to what is the rate

00:15:24,830 --> 00:15:35,070
124 megabits per second for that flow so

00:15:33,149 --> 00:15:36,750
some people want to look for that cubic

00:15:35,070 --> 00:15:41,310
- in this environment right I'm not

00:15:36,750 --> 00:15:43,260
trying to speak badly of EDR so it does

00:15:41,310 --> 00:15:45,440
badly - right the first flow stays up

00:15:43,260 --> 00:15:48,779
there that's really well the second flow

00:15:45,440 --> 00:15:50,459
takes a long time to try to grow so it

00:15:48,779 --> 00:15:52,529
also achieves very low bandwidth right

00:15:50,459 --> 00:15:59,700
don't have enough time to grow

00:15:52,529 --> 00:16:03,570
it's congestion window part of this

00:15:59,700 --> 00:16:06,300
package also it's a program called

00:16:03,570 --> 00:16:09,120
experimental py that allows you to

00:16:06,300 --> 00:16:12,959
process the data in two different views

00:16:09,120 --> 00:16:15,060
right so for example for the so for this

00:16:12,959 --> 00:16:17,160
experiment I'm by the way if you look at

00:16:15,060 --> 00:16:23,880
experiment numbers I run a lot of

00:16:17,160 --> 00:16:26,580
experiments on on that day right so the

00:16:23,880 --> 00:16:28,920
CDF file is being has a lot of stuff we

00:16:26,580 --> 00:16:31,290
did you know I use a scripting language

00:16:28,920 --> 00:16:34,079
also for this that I tell the you know

00:16:31,290 --> 00:16:36,660
just look at this life of the data the

00:16:34,079 --> 00:16:39,240
quadric all the twists 2 into 1 decide

00:16:36,660 --> 00:16:40,980
for the delays 10 milliseconds and the

00:16:39,240 --> 00:16:46,649
bandwidth is 100 megabits per second

00:16:40,980 --> 00:16:49,740
right and then I tell it to to plot the

00:16:46,649 --> 00:16:52,500
table and once again I also restricted

00:16:49,740 --> 00:16:55,440
the columns I was going to display just

00:16:52,500 --> 00:16:58,020
because that's not enough loop State on

00:16:55,440 --> 00:17:00,839
the slide but I also created a new

00:16:58,020 --> 00:17:04,380
column which are called fairness at the

00:17:00,839 --> 00:17:07,110
end that it is the ratio the maximum

00:17:04,380 --> 00:17:09,949
rate and the minimum rate right so that

00:17:07,110 --> 00:17:13,800
gives me an idea about how fair the

00:17:09,949 --> 00:17:15,600
experiments are right if the value is 1

00:17:13,800 --> 00:17:18,480
it's perfectly fair all of the flows

00:17:15,600 --> 00:17:20,760
assume the same good put the big a

00:17:18,480 --> 00:17:23,189
release it means that the faster flow

00:17:20,760 --> 00:17:26,640
achieve much more throughput for good

00:17:23,189 --> 00:17:28,920
food and then I can also create bar

00:17:26,640 --> 00:17:31,980
graphs so this one tells me the number

00:17:28,920 --> 00:17:33,960
of requests meets with the bars and the

00:17:31,980 --> 00:17:35,960
diamond the green diamonds represent the

00:17:33,960 --> 00:17:39,409
the furnace

00:17:35,960 --> 00:17:41,450
and we for both Cilic and BB are so

00:17:39,409 --> 00:17:43,460
initially you know there's very few

00:17:41,450 --> 00:17:46,159
transmissions but as we increase the

00:17:43,460 --> 00:17:48,409
load will be we are we grow up to 15%

00:17:46,159 --> 00:17:48,799
with transmissions 15% of the packets

00:17:48,409 --> 00:17:53,679
and

00:17:48,799 --> 00:17:57,110
our retransmissions the fairness starts

00:17:53,679 --> 00:17:59,720
you know more or less okay for that many

00:17:57,110 --> 00:18:03,350
flows but once again as we increase the

00:17:59,720 --> 00:18:06,320
load BB are for this experiment turns

00:18:03,350 --> 00:18:09,019
out to be a little bit less fair you

00:18:06,320 --> 00:18:11,480
know the ratio between the flows and the

00:18:09,019 --> 00:18:13,940
fastest is between 4 & 5 in the worst

00:18:11,480 --> 00:18:17,179
case right and that's a heavy load of 32

00:18:13,940 --> 00:18:21,259
32 flows per holes so there are three

00:18:17,179 --> 00:18:29,210
holes so that's a 96 floats total going

00:18:21,259 --> 00:18:32,929
to one server on the drive okay so this

00:18:29,210 --> 00:18:35,269
is a sample the script to do the table

00:18:32,929 --> 00:18:38,059
and the graph that I show you okay

00:18:35,269 --> 00:18:44,090
initially a specify for the CSV files

00:18:38,059 --> 00:18:46,820
are then I select which flows to use I'm

00:18:44,090 --> 00:18:49,100
by the way the paper that is being put

00:18:46,820 --> 00:18:52,070
on as part of the conference has a lot

00:18:49,100 --> 00:18:55,369
more detail about the tester then I

00:18:52,070 --> 00:18:57,850
create a new column with a furnace then

00:18:55,369 --> 00:18:59,749
I tell it with columns to use and

00:18:57,850 --> 00:19:03,830
finally I tell it to write the table

00:18:59,749 --> 00:19:07,279
then I tell it to to write a plot a give

00:19:03,830 --> 00:19:10,039
it you know what is the on the x-axis do

00:19:07,279 --> 00:19:12,169
the instances on the y-axis on the Left

00:19:10,039 --> 00:19:14,029
do that which was mixed packets on the

00:19:12,169 --> 00:19:15,679
right when do the furnace and then do a

00:19:14,029 --> 00:19:18,309
series of based on the addition of

00:19:15,679 --> 00:19:22,190
audience cubic and VBR

00:19:18,309 --> 00:19:25,100
okay and that's what created this graph

00:19:22,190 --> 00:19:27,590
here and the idea is that we developed

00:19:25,100 --> 00:19:29,509
script to run test will also create

00:19:27,590 --> 00:19:32,059
script to analyze the data from those

00:19:29,509 --> 00:19:34,369
days right so as new people want to use

00:19:32,059 --> 00:19:36,519
this script they'll know you know I just

00:19:34,369 --> 00:19:39,860
run the script you know I just need to

00:19:36,519 --> 00:19:41,899
have enough machines to be able to do it

00:19:39,860 --> 00:19:44,359
and then I will just run the script to

00:19:41,899 --> 00:19:48,249
plot the data and give me all the views

00:19:44,359 --> 00:19:48,249
I want to see right for that screen

00:19:51,570 --> 00:19:57,760
so although the things you can do as I

00:19:56,170 --> 00:19:59,880
mentioned earlier with with the tester

00:19:57,760 --> 00:20:03,370
is that you can use MIDI em to a delay

00:19:59,880 --> 00:20:04,750
you can collect TCP dump and you want to

00:20:03,370 --> 00:20:06,130
microscopically copy them to the

00:20:04,750 --> 00:20:08,290
controller so you can look at them if

00:20:06,130 --> 00:20:10,690
you want to would watch out you can also

00:20:08,290 --> 00:20:13,810
set up tuning disciplines either to set

00:20:10,690 --> 00:20:16,360
surfer queuing for VBR or if you're

00:20:13,810 --> 00:20:19,120
using a Linux host at a rather you can

00:20:16,360 --> 00:20:22,030
use it to limit bandwidth and you know

00:20:19,120 --> 00:20:26,400
try different buffer sizes you can also

00:20:22,030 --> 00:20:29,890
set this controls at the metal servers

00:20:26,400 --> 00:20:33,790
but these are also whitelisted so that

00:20:29,890 --> 00:20:36,460
you can only do certain things there's a

00:20:33,790 --> 00:20:38,170
whole bunch of Modesto macros that I

00:20:36,460 --> 00:20:40,900
have the sample

00:20:38,170 --> 00:20:45,070
M server RR will do multiple client

00:20:40,900 --> 00:20:47,200
multiple servers request reply and you

00:20:45,070 --> 00:20:50,080
can subscribe multiple requests sizes so

00:20:47,200 --> 00:20:52,840
for example you could say one you know

00:20:50,080 --> 00:20:54,370
from three clients to two servers for

00:20:52,840 --> 00:20:59,160
every client will send to each server

00:20:54,370 --> 00:21:02,640
and do three different flows with 10k

00:20:59,160 --> 00:21:05,200
100k or one megabyte Lucas replies and

00:21:02,640 --> 00:21:06,760
you only need to specify one line to do

00:21:05,200 --> 00:21:09,280
all that it will run collect the data

00:21:06,760 --> 00:21:12,730
copy it back to the graph all done

00:21:09,280 --> 00:21:15,640
automatically so you can also do streams

00:21:12,730 --> 00:21:18,730
you can do for a code versus where you

00:21:15,640 --> 00:21:19,750
can complete to different clients may be

00:21:18,730 --> 00:21:23,920
set up with different condition

00:21:19,750 --> 00:21:28,720
avoidances see how they do so for

00:21:23,920 --> 00:21:31,960
example I wrote also at PCP three eight

00:21:28,720 --> 00:21:35,080
to three marker so this one's the to

00:21:31,960 --> 00:21:37,600
flow and three flows to compare the

00:21:35,080 --> 00:21:39,640
behavior of two or more condition

00:21:37,600 --> 00:21:41,200
avoidances so what you will do here is

00:21:39,640 --> 00:21:42,820
you will specify a base position

00:21:41,200 --> 00:21:46,450
avoidance and a test congestion

00:21:42,820 --> 00:21:48,250
avoidance and then the macro you know

00:21:46,450 --> 00:21:50,350
just specify that you run the macro and

00:21:48,250 --> 00:21:52,270
it will run two and three flows use in

00:21:50,350 --> 00:21:54,700
the base to want to flows using the test

00:21:52,270 --> 00:21:57,460
yes and we used to find more than once a

00:21:54,700 --> 00:21:59,680
CA will do we should do this for all the

00:21:57,460 --> 00:22:00,470
individual tests cas

00:21:59,680 --> 00:22:03,350
condition avoiding

00:22:00,470 --> 00:22:06,890
maybe our window cheddar it will run 20

00:22:03,350 --> 00:22:09,230
flows using the base here for the first

00:22:06,890 --> 00:22:11,450
flow and using the test CA for the other

00:22:09,230 --> 00:22:20,360
ones so you can see how they compete how

00:22:11,450 --> 00:22:22,130
does one live ers fqv or vice versa in

00:22:20,360 --> 00:22:24,410
my experience I also set up a Linux

00:22:22,130 --> 00:22:26,030
machine as a router and then I use the

00:22:24,410 --> 00:22:28,910
Qt discipline to set different rate

00:22:26,030 --> 00:22:32,600
sighs excuse Isis use natty aim to set

00:22:28,910 --> 00:22:36,070
delays okay and then I can very easily

00:22:32,600 --> 00:22:39,080
do a script with a loop but I can try

00:22:36,070 --> 00:22:41,090
you know to delays 10m 40 milliseconds

00:22:39,080 --> 00:22:45,380
for rates between five and a hundred

00:22:41,090 --> 00:22:48,470
megabits per second and then I have the

00:22:45,380 --> 00:22:52,460
loop and then this test will do the TC

00:22:48,470 --> 00:22:55,040
TC a macro will do eight runs and then I

00:22:52,460 --> 00:22:57,620
have two and four so that's another rate

00:22:55,040 --> 00:23:00,620
will be 64 tests we does that small

00:22:57,620 --> 00:23:03,470
script and if you add a comma after the

00:23:00,620 --> 00:23:07,090
the macro name then it will run a whole

00:23:03,470 --> 00:23:09,620
bunch of them so let me type up a pair a

00:23:07,090 --> 00:23:12,590
variability so there's an initial

00:23:09,620 --> 00:23:15,500
version there don't use it it has one or

00:23:12,590 --> 00:23:18,920
two bucks by the end of this week I will

00:23:15,500 --> 00:23:25,750
release the belated version that you can

00:23:18,920 --> 00:23:25,750
use and that's it any questions

00:23:29,529 --> 00:23:37,110
question somebody has to ask a question

00:23:34,179 --> 00:23:37,110
okay

00:23:37,929 --> 00:23:45,850
just use the lead equation what would be

00:23:41,440 --> 00:23:48,340
the learning curve of this tool how much

00:23:45,850 --> 00:23:50,200
the learning curve or math time so if

00:23:48,340 --> 00:23:53,460
you want to use the existing mattress

00:23:50,200 --> 00:23:56,009
and it's Christmas crate it's very easy

00:23:53,460 --> 00:23:58,539
you know it's like you actually just

00:23:56,009 --> 00:24:02,259
install the rectory from the metal

00:23:58,539 --> 00:24:04,870
servers you start the program with minus

00:24:02,259 --> 00:24:08,200
s so that if you know is running as a

00:24:04,870 --> 00:24:10,450
daemon and then you type the scrape to

00:24:08,200 --> 00:24:13,000
the metas to py in your controller and

00:24:10,450 --> 00:24:16,000
it will do everything and you would

00:24:13,000 --> 00:24:17,799
create a lot of the artwork right so do

00:24:16,000 --> 00:24:20,019
you have a hole to something like that

00:24:17,799 --> 00:24:22,149
so it will be there's something there

00:24:20,019 --> 00:24:23,919
but I will updated you know by the other

00:24:22,149 --> 00:24:25,419
with when I post the latest one so that

00:24:23,919 --> 00:24:28,000
you can have a a quick start

00:24:25,419 --> 00:24:31,690
thank you sure so we're going to put him

00:24:28,000 --> 00:24:38,129
on the penalty box for five minutes they

00:24:31,690 --> 00:24:38,129
were going to talk to him next week

00:24:38,789 --> 00:24:41,909

YouTube URL: https://www.youtube.com/watch?v=ySHK5JrRMzo


