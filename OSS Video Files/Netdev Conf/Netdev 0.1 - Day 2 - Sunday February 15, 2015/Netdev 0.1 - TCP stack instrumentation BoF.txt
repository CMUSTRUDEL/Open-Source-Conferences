Title: Netdev 0.1 - TCP stack instrumentation BoF
Publication date: 2015-03-21
Playlist: Netdev 0.1 - Day 2 - Sunday February 15, 2015
Description: 
	TCP stack instrumentation BoF by Chris Rapier
February 2015

Description from netdev01.org:
 The TCP stack, by design, hides much of the information about it's functioning and performance from userland. As such, unearthing the root cause of performance problems can be both frustrating and time consuming. While some instrumentation is available through the current TCP_INFO struct a more extensive set of instruments may provide better data for TCP diagnostics and performance monitoring. This BoF intends to bring together interested parties and stakeholders in order to discuss the need and requirements for extending the current set of TCP instruments. The discussion will include potential instruments, use case scenarios, access methods, metric validation, and other issues. 

https://www.netdev01.org

This video is licensed under Creative Commons Attribution-ShareAlike 4.0 International license. Feel free to download and distribute.
Captions: 
	00:00:04,580 --> 00:00:09,859
anybody knows where Chris is where the

00:00:07,470 --> 00:00:09,859
speakers

00:00:14,650 --> 00:00:27,710
all right there comes Chris all right

00:00:19,900 --> 00:00:31,579
well introduce yourself my name is Chris

00:00:27,710 --> 00:00:35,149
rapier I am here to lead a discussion

00:00:31,579 --> 00:00:37,610
about TCP stack instrumentation so I'd

00:00:35,149 --> 00:00:40,550
first like to start by saying this is a

00:00:37,610 --> 00:00:42,289
few more people than I expected so I

00:00:40,550 --> 00:00:45,079
really appreciate your interest in this

00:00:42,289 --> 00:00:46,670
and I hope that we can get started with

00:00:45,079 --> 00:00:50,089
a good discussion on what we want to see

00:00:46,670 --> 00:00:51,710
out of stock instrumentation and try and

00:00:50,089 --> 00:00:56,839
determine what our next steps are with

00:00:51,710 --> 00:00:58,280
this if you could all do me a favor part

00:00:56,839 --> 00:01:00,319
of the goals of this is to actually come

00:00:58,280 --> 00:01:02,780
up with a mailing list so we can

00:01:00,319 --> 00:01:05,900
continue this conversation later on I'd

00:01:02,780 --> 00:01:07,550
also appreciate it if so in that sense I

00:01:05,900 --> 00:01:09,740
was hoping you could sign a sign up

00:01:07,550 --> 00:01:11,060
sheet that I can be passing around also

00:01:09,740 --> 00:01:12,800
my boss is like to know how many people

00:01:11,060 --> 00:01:15,140
have actually talked to so that helps

00:01:12,800 --> 00:01:17,840
with that as well so if you could take a

00:01:15,140 --> 00:01:20,979
moment to sign this email and let me

00:01:17,840 --> 00:01:20,979
know if you actually want to join

00:01:23,770 --> 00:01:27,399
and if you don't want to sign or put

00:01:25,689 --> 00:01:33,219
your email down that's fine with me too

00:01:27,399 --> 00:01:34,990
so so for privacy reasons if you don't

00:01:33,219 --> 00:01:37,890
want to sign you don't have to know you

00:01:34,990 --> 00:01:41,920
have no obligation to sign whatsoever

00:01:37,890 --> 00:01:43,990
right just get to put Joe Blow or

00:01:41,920 --> 00:01:47,439
whatever you just wants numbers I'm

00:01:43,990 --> 00:01:49,899
sorry yeah i'm going to set be setting

00:01:47,439 --> 00:01:51,189
that up later so don't worry about if

00:01:49,899 --> 00:01:55,929
you don't want to put your email down I

00:01:51,189 --> 00:01:57,909
understand entirely so what's the agenda

00:01:55,929 --> 00:02:00,099
please sign in if you can and if you're

00:01:57,909 --> 00:02:02,979
comfortable doing that otherwise not a

00:02:00,099 --> 00:02:05,530
problem give a quick introduction as to

00:02:02,979 --> 00:02:08,429
who I am what my view and stack your

00:02:05,530 --> 00:02:10,000
instrumentation is use cases

00:02:08,429 --> 00:02:13,030
implementation questions and

00:02:10,000 --> 00:02:14,709
considerations and then next steps and

00:02:13,030 --> 00:02:17,860
throughout all of this I want you all to

00:02:14,709 --> 00:02:19,480
know I want your input I only have a few

00:02:17,860 --> 00:02:21,879
minutes worth of stuff to talk about so

00:02:19,480 --> 00:02:24,790
if no one else is talking this is going

00:02:21,879 --> 00:02:28,720
to get real boring so please share in

00:02:24,790 --> 00:02:31,780
the conversation my name is Chris rapier

00:02:28,720 --> 00:02:34,209
I'm I'm an academic please don't hold

00:02:31,780 --> 00:02:36,100
that against me I work at the Pittsburgh

00:02:34,209 --> 00:02:37,780
supercomputing Center in lovely

00:02:36,100 --> 00:02:40,060
Pittsburgh Pennsylvania we're part of

00:02:37,780 --> 00:02:42,760
Carnegie Mellon University I'm a

00:02:40,060 --> 00:02:45,880
research engineer / scientist with them

00:02:42,760 --> 00:02:49,840
specifically focused in high-performance

00:02:45,880 --> 00:02:51,489
Network behavior diagnostics and things

00:02:49,840 --> 00:02:54,609
along those lines specifically geared

00:02:51,489 --> 00:02:58,540
towards how we improve the network for

00:02:54,609 --> 00:03:00,130
users we support scientific users from a

00:02:58,540 --> 00:03:02,079
lot of different fields were mostly

00:03:00,130 --> 00:03:06,400
involved with moving large amounts of

00:03:02,079 --> 00:03:08,590
data big data from collection points and

00:03:06,400 --> 00:03:10,930
other nodes on our research and

00:03:08,590 --> 00:03:16,269
education network to compute nodes and

00:03:10,930 --> 00:03:19,560
data storage sites we are dealing with

00:03:16,269 --> 00:03:22,870
very large data sets we're dealing with

00:03:19,560 --> 00:03:26,200
particle physics datasets astrophysics

00:03:22,870 --> 00:03:27,459
data sets genomics data sets we're

00:03:26,200 --> 00:03:30,220
talking about data sets that are

00:03:27,459 --> 00:03:33,160
currently running 50 to 75 terabytes in

00:03:30,220 --> 00:03:35,680
size and our projection is that within

00:03:33,160 --> 00:03:37,030
the next 12 to 18 months we'll start

00:03:35,680 --> 00:03:39,160
seeing 200 plus

00:03:37,030 --> 00:03:43,270
tera byte size data sets that we're

00:03:39,160 --> 00:03:45,880
going to have to be moving and our view

00:03:43,270 --> 00:03:49,030
is that this is just going to be normal

00:03:45,880 --> 00:03:50,590
for us and that the amount of data that

00:03:49,030 --> 00:03:52,780
we're going to be transferring is just

00:03:50,590 --> 00:03:55,900
going to keep increasing especially in

00:03:52,780 --> 00:03:57,459
the genomics field their devices out

00:03:55,900 --> 00:04:02,650
there now that can generate a terabyte

00:03:57,459 --> 00:04:05,590
of data a day of genomics data and that

00:04:02,650 --> 00:04:08,470
data has to go from the collection point

00:04:05,590 --> 00:04:11,140
to data aggregation sites to compute

00:04:08,470 --> 00:04:12,940
nodes and in that aspect we're

00:04:11,140 --> 00:04:16,230
supporting the National Institute of

00:04:12,940 --> 00:04:19,870
Health National Library of Medicine

00:04:16,230 --> 00:04:25,240
various genomics groups all over the

00:04:19,870 --> 00:04:26,470
country I have done some previous work I

00:04:25,240 --> 00:04:30,400
don't know if any of you are familiar

00:04:26,470 --> 00:04:32,320
with hpn SSH that's a set of performance

00:04:30,400 --> 00:04:35,760
patches to ssh that I implemented around

00:04:32,320 --> 00:04:39,430
10 years ago that never made it upstream

00:04:35,760 --> 00:04:41,740
people are still using it though lately

00:04:39,430 --> 00:04:44,200
though I've been involved in web 10 10 G

00:04:41,740 --> 00:04:48,220
also known as web 10 gig this is our

00:04:44,200 --> 00:04:51,970
attempt at implementing an RC called RSC

00:04:48,220 --> 00:04:53,169
4898 which is a description of around

00:04:51,970 --> 00:04:58,750
one hundred and twenty seven different

00:04:53,169 --> 00:05:00,580
tcp stack metrics the goal of that was

00:04:58,750 --> 00:05:03,100
to actually break open the black box

00:05:00,580 --> 00:05:06,550
that is the stack and get more

00:05:03,100 --> 00:05:09,360
information about what's happening along

00:05:06,550 --> 00:05:12,580
the stack the path the application and

00:05:09,360 --> 00:05:15,370
various other classes of metrics up to

00:05:12,580 --> 00:05:17,770
the user or into user land to be more

00:05:15,370 --> 00:05:25,000
specific so we can provide actionable

00:05:17,770 --> 00:05:26,620
information based on that data so what

00:05:25,000 --> 00:05:28,180
it's always good to have a shared

00:05:26,620 --> 00:05:29,470
language with this so I just want to

00:05:28,180 --> 00:05:33,130
start with what I view is

00:05:29,470 --> 00:05:34,900
instrumentation specifically I'm talking

00:05:33,130 --> 00:05:38,050
about a method of collecting data

00:05:34,900 --> 00:05:41,320
regarding / flow characteristics not

00:05:38,050 --> 00:05:43,180
normally revealed by the stack so these

00:05:41,320 --> 00:05:45,490
are specific instruments that are not

00:05:43,180 --> 00:05:47,950
currently implemented which tells us

00:05:45,490 --> 00:05:50,560
something about what's happening in the

00:05:47,950 --> 00:05:52,600
stack or at least in terms of

00:05:50,560 --> 00:05:57,510
how the network is performing in terms

00:05:52,600 --> 00:06:00,060
of throughput performance congestion and

00:05:57,510 --> 00:06:04,690
failure modes and things like that and

00:06:00,060 --> 00:06:06,700
bring them up to the user it's important

00:06:04,690 --> 00:06:08,770
that we make sure that all the collected

00:06:06,700 --> 00:06:11,500
metrics are brought are revealed to user

00:06:08,770 --> 00:06:14,350
land if they just stay within the stack

00:06:11,500 --> 00:06:15,760
there are there is value to that but it

00:06:14,350 --> 00:06:24,130
does not necessarily provide the maximum

00:06:15,760 --> 00:06:25,990
amount of value to our goals now the

00:06:24,130 --> 00:06:29,740
issue is also that the instruments have

00:06:25,990 --> 00:06:30,970
to provide some sort of real value they

00:06:29,740 --> 00:06:32,470
don't have to provide real value to

00:06:30,970 --> 00:06:34,840
every user but they have to provide

00:06:32,470 --> 00:06:38,290
value to some set of users that has a

00:06:34,840 --> 00:06:39,520
valid use case for them this leads to

00:06:38,290 --> 00:06:41,380
questions about how we're going to

00:06:39,520 --> 00:06:42,940
validate the instruments how do we make

00:06:41,380 --> 00:06:45,750
sure that they know the instruments are

00:06:42,940 --> 00:06:47,919
doing what we think they're doing and

00:06:45,750 --> 00:06:51,520
related to that as well especially when

00:06:47,919 --> 00:06:52,930
we're dealing with you know production

00:06:51,520 --> 00:06:54,520
environments especially high load

00:06:52,930 --> 00:06:56,830
production environments how do we

00:06:54,520 --> 00:07:00,310
quantify the impact of each instrument

00:06:56,830 --> 00:07:03,340
on overall performance if we can't

00:07:00,310 --> 00:07:04,750
determine what impact the instruments

00:07:03,340 --> 00:07:07,180
are having we can never turn around and

00:07:04,750 --> 00:07:08,919
say like yeah have this on all the time

00:07:07,180 --> 00:07:10,419
or only use this when you really really

00:07:08,919 --> 00:07:13,240
need it because it's going to screw your

00:07:10,419 --> 00:07:17,710
performance up quantification I think is

00:07:13,240 --> 00:07:20,410
a really important aspect of this so

00:07:17,710 --> 00:07:23,650
this is where the audience participate

00:07:20,410 --> 00:07:25,800
audience-participation part starts and I

00:07:23,650 --> 00:07:29,500
really hope you'll help me out with this

00:07:25,800 --> 00:07:31,990
so we need to talk about use cases and

00:07:29,500 --> 00:07:34,450
in terms of use cases we need to talk

00:07:31,990 --> 00:07:37,150
about what instruments or what kind of

00:07:34,450 --> 00:07:43,180
information would support those use

00:07:37,150 --> 00:07:48,820
cases now in my community we're really

00:07:43,180 --> 00:07:51,250
focused on overall flow throughput we do

00:07:48,820 --> 00:07:53,169
have some issues with contention but our

00:07:51,250 --> 00:07:55,830
networks are currently under subscribed

00:07:53,169 --> 00:07:58,180
right now so we have a lot of headroom

00:07:55,830 --> 00:07:59,380
but we're really interested in making

00:07:58,180 --> 00:08:02,290
sure that

00:07:59,380 --> 00:08:04,480
any of the any of the flows that are in

00:08:02,290 --> 00:08:07,330
progress are actually making optimal use

00:08:04,480 --> 00:08:10,390
of the network this is not as you all

00:08:07,330 --> 00:08:14,830
know this is not as easy as it would

00:08:10,390 --> 00:08:20,140
seem so we want to have real-world data

00:08:14,830 --> 00:08:23,140
on a per flow basis on to allow us to

00:08:20,140 --> 00:08:28,030
try and get a better look into how each

00:08:23,140 --> 00:08:29,670
flow is currently the performance of

00:08:28,030 --> 00:08:34,410
individual flows at that point

00:08:29,670 --> 00:08:37,030
specifically between data transfer notes

00:08:34,410 --> 00:08:38,470
the other aspect to this is that we

00:08:37,030 --> 00:08:41,050
really want to be able to use it so we

00:08:38,470 --> 00:08:42,669
can have a collected set of data so when

00:08:41,050 --> 00:08:45,010
a user comes to us and says they're

00:08:42,669 --> 00:08:46,990
having a problem we don't have to do

00:08:45,010 --> 00:08:48,460
that standard dance where you end up

00:08:46,990 --> 00:08:50,500
spending three weeks trying to get a

00:08:48,460 --> 00:08:53,290
trace route from a user who doesn't know

00:08:50,500 --> 00:08:55,540
what a trace route is so we have a set

00:08:53,290 --> 00:08:58,600
of data on their real world flows at

00:08:55,540 --> 00:09:02,080
that time we can start the process of

00:08:58,600 --> 00:09:06,430
diagnosing and resolving their problems

00:09:02,080 --> 00:09:09,300
as soon as possible so that's my use

00:09:06,430 --> 00:09:13,180
case that's why I'm interested in this

00:09:09,300 --> 00:09:17,770
we have other people who have use cases

00:09:13,180 --> 00:09:19,390
which are very different been in

00:09:17,770 --> 00:09:22,900
communication with some people from

00:09:19,390 --> 00:09:24,670
twitter twitter is interested in terms

00:09:22,900 --> 00:09:26,710
of for example what they're interested

00:09:24,670 --> 00:09:27,990
in is they have a bunch of containers

00:09:26,710 --> 00:09:29,920
each running their own stack

00:09:27,990 --> 00:09:31,780
occasionally what happens is they have

00:09:29,920 --> 00:09:33,420
jobs interfering with each other and

00:09:31,780 --> 00:09:36,790
they'd like to know why that's happening

00:09:33,420 --> 00:09:39,540
so in terms of trying to determine that

00:09:36,790 --> 00:09:42,190
they want specific set of instruments

00:09:39,540 --> 00:09:47,470
packet and bite statistics congestion

00:09:42,190 --> 00:09:48,820
metrics RTT metrics queue lengths things

00:09:47,470 --> 00:09:50,290
along those lines that'll tell them

00:09:48,820 --> 00:09:52,030
what's happening inside of their data

00:09:50,290 --> 00:09:54,450
center as their containers are talking

00:09:52,030 --> 00:09:54,450
to each other

00:09:55,180 --> 00:10:00,880
so at this point if anyone has any use

00:09:59,380 --> 00:10:03,700
cases that their interest in doing and

00:10:00,880 --> 00:10:05,440
again this is an open discussion I

00:10:03,700 --> 00:10:07,960
really want people to start talking

00:10:05,440 --> 00:10:10,930
about what they're interested in trying

00:10:07,960 --> 00:10:12,220
to see with these instruments yeah I

00:10:10,930 --> 00:10:14,740
just have one question you were talking

00:10:12,220 --> 00:10:15,790
earlier about moving your terabytes of

00:10:14,740 --> 00:10:17,560
data around I'm curious what the

00:10:15,790 --> 00:10:21,550
geographic distance is you're moving

00:10:17,560 --> 00:10:23,560
them across a at least transcontinental

00:10:21,550 --> 00:10:26,520
like we're doing a lot from San Diego

00:10:23,560 --> 00:10:29,710
over to New York New York down to Miami

00:10:26,520 --> 00:10:31,450
we have you know we also have

00:10:29,710 --> 00:10:35,380
transnational like trans-pacific and

00:10:31,450 --> 00:10:36,700
transatlantic transfers as well so we're

00:10:35,380 --> 00:10:39,940
also dealing with shorter latency

00:10:36,700 --> 00:10:41,860
smaller Layton sees as well so we'll

00:10:39,940 --> 00:10:43,510
have ones that like 10 millisecond

00:10:41,860 --> 00:10:48,850
latency then we'll have ones that are

00:10:43,510 --> 00:10:51,160
150 millisecond so it's all over the

00:10:48,850 --> 00:10:53,590
place we're also dealing with issues

00:10:51,160 --> 00:10:57,670
that are inside of campus networks as

00:10:53,590 --> 00:11:00,160
well we're moving data from dedicated

00:10:57,670 --> 00:11:02,920
data transfer nodes to the compute

00:11:00,160 --> 00:11:06,210
resources and we want to get an idea of

00:11:02,920 --> 00:11:06,210
what's happening in there as well

00:11:08,579 --> 00:11:12,119
so does anyone have any use cases that

00:11:10,679 --> 00:11:13,679
they think instrumentation would be

00:11:12,119 --> 00:11:17,449
useful for where they're not getting

00:11:13,679 --> 00:11:17,449
enough information out of the stack and

00:11:24,010 --> 00:11:26,790
ok

00:11:27,370 --> 00:11:30,450
but i think most

00:11:30,579 --> 00:11:34,840
companies with their own data centers

00:11:32,319 --> 00:11:39,580
want to get

00:11:34,840 --> 00:11:41,530
bite bite or packets per second etc but

00:11:39,580 --> 00:11:43,270
as there's also the other you scenario

00:11:41,530 --> 00:11:46,090
where we may want to get very detailed

00:11:43,270 --> 00:11:48,280
information of a particular flows which

00:11:46,090 --> 00:11:50,290
could be there statistically or some

00:11:48,280 --> 00:11:52,840
specific clothes to understand better

00:11:50,290 --> 00:11:56,320
the behavior of those flows to try to

00:11:52,840 --> 00:11:59,170
find problems with TCP or with some

00:11:56,320 --> 00:12:00,550
other environments and I think the

00:11:59,170 --> 00:12:03,790
solution for each of these may be

00:12:00,550 --> 00:12:08,200
different yes but I think those are two

00:12:03,790 --> 00:12:11,410
important cases to consider so one of

00:12:08,200 --> 00:12:15,130
the things that I think instrumentation

00:12:11,410 --> 00:12:17,830
can provide is if it's done correctly so

00:12:15,130 --> 00:12:20,200
all right we're academic so the thing

00:12:17,830 --> 00:12:21,610
that we did is we just implemented 127

00:12:20,200 --> 00:12:26,410
different metrics and just threw

00:12:21,610 --> 00:12:29,670
everything against a wall I'm not

00:12:26,410 --> 00:12:31,810
suggesting that we do anything like that

00:12:29,670 --> 00:12:33,430
there are different use cases where

00:12:31,810 --> 00:12:35,530
subsets of instruments would be useful

00:12:33,430 --> 00:12:36,940
so like in your case you'd want some

00:12:35,530 --> 00:12:40,000
general statistics and then the same

00:12:36,940 --> 00:12:42,610
time you probably want more detailed

00:12:40,000 --> 00:12:44,710
data from a certain subset of these

00:12:42,610 --> 00:12:48,250
flows or for a specific server or

00:12:44,710 --> 00:12:51,160
something like that that's one of those

00:12:48,250 --> 00:12:52,960
implementation questions that need to be

00:12:51,160 --> 00:12:56,290
addressed once we figure out what

00:12:52,960 --> 00:12:58,960
instruments were most interested in it

00:12:56,290 --> 00:13:01,960
should be possible to be able to enable

00:12:58,960 --> 00:13:07,380
or disable subsets of instruments that

00:13:01,960 --> 00:13:10,120
are of most used to specific use cases

00:13:07,380 --> 00:13:11,470
so we could have lightweight set of

00:13:10,120 --> 00:13:15,670
instruments that are providing general

00:13:11,470 --> 00:13:18,910
statistics and then as a need arises we

00:13:15,670 --> 00:13:22,600
might have a way of enabling it extended

00:13:18,910 --> 00:13:24,130
step extended set of statistics that'll

00:13:22,600 --> 00:13:26,140
give us a detailed analysis that you're

00:13:24,130 --> 00:13:27,700
looking for so I did yeah I agree

00:13:26,140 --> 00:13:29,950
ideally would be something that we can

00:13:27,700 --> 00:13:33,060
do dynamically yes the specification and

00:13:29,950 --> 00:13:35,410
also the data containers need to be

00:13:33,060 --> 00:13:36,850
self-describing because when they went

00:13:35,410 --> 00:13:39,130
to say it well for these connections I

00:13:36,850 --> 00:13:42,340
want to get you know detail about RTT

00:13:39,130 --> 00:13:42,910
congestion window much later than 127

00:13:42,340 --> 00:13:46,330
you know

00:13:42,910 --> 00:13:47,530
if you have yeah that did you want to

00:13:46,330 --> 00:13:49,480
talk about the self-describing

00:13:47,530 --> 00:13:51,660
containers from self-describing data for

00:13:49,480 --> 00:13:51,660
a moment

00:13:54,980 --> 00:14:03,250
i'm at mathis the first author and 4898

00:13:59,500 --> 00:14:05,300
before i talk about self-describing

00:14:03,250 --> 00:14:07,730
binary representations i wanted to

00:14:05,300 --> 00:14:10,459
actually make two other comments so I

00:14:07,730 --> 00:14:13,250
was Chris's predecessor at PSC all the

00:14:10,459 --> 00:14:15,829
titles that exactly match and I came

00:14:13,250 --> 00:14:18,769
from an environment of at that point

00:14:15,829 --> 00:14:21,440
nearly two decades of TCP debugging

00:14:18,769 --> 00:14:23,959
experienced my first TCP trace was on a

00:14:21,440 --> 00:14:29,240
network that maximum speed coast to

00:14:23,959 --> 00:14:32,810
coast was only let's see I'll say five

00:14:29,240 --> 00:14:36,769
megabits but that was a total well a

00:14:32,810 --> 00:14:39,139
totally nevermind anyhow 20 years of

00:14:36,769 --> 00:14:42,290
debugging applications and the question

00:14:39,139 --> 00:14:44,180
that the that the 4898 really had tried

00:14:42,290 --> 00:14:46,220
to answer is for all the debugging

00:14:44,180 --> 00:14:47,750
flowcharts I ever went through what's

00:14:46,220 --> 00:14:50,660
the fastest way to get close to the

00:14:47,750 --> 00:14:53,930
problem and that was the intent of the

00:14:50,660 --> 00:14:56,209
prop of the sort of the design the other

00:14:53,930 --> 00:14:58,990
goal for the document was to have always

00:14:56,209 --> 00:15:01,670
on statistics that one could imagine

00:14:58,990 --> 00:15:04,850
aggregating in various ways to do things

00:15:01,670 --> 00:15:07,730
like fingerprinting of ISPs that we're

00:15:04,850 --> 00:15:10,760
doing mischief so if you collect data

00:15:07,730 --> 00:15:12,769
from lots of places and you can do

00:15:10,760 --> 00:15:14,750
imagine doing sort of tomography of ISPs

00:15:12,769 --> 00:15:18,740
that are perhaps doing something you

00:15:14,750 --> 00:15:20,959
wanted to know about so those were the

00:15:18,740 --> 00:15:23,209
two sort of driving forces behind the

00:15:20,959 --> 00:15:25,790
original design of the document I was

00:15:23,209 --> 00:15:27,889
told that it was much too big and

00:15:25,790 --> 00:15:30,800
complicated and I ignored the advice I

00:15:27,889 --> 00:15:34,279
now regret that there are some other

00:15:30,800 --> 00:15:35,870
mistakes at it as well one of the things

00:15:34,279 --> 00:15:37,579
that strikes me as being and this is

00:15:35,870 --> 00:15:39,589
what Chris was referring to that's a big

00:15:37,579 --> 00:15:44,930
problem this space is one-size-fits-all

00:15:39,589 --> 00:15:47,000
is not a good answer here and if any

00:15:44,930 --> 00:15:50,170
service in the kernel needs to have a

00:15:47,000 --> 00:15:53,060
way of doing a self-describing compact

00:15:50,170 --> 00:15:58,089
binary format which can be tuned per

00:15:53,060 --> 00:16:01,699
customer this is one of them and I I

00:15:58,089 --> 00:16:03,230
don't know i'm not really a kernel guy

00:16:01,699 --> 00:16:05,000
i'm a networking guy i don't know if

00:16:03,230 --> 00:16:05,760
this kind of service exists elsewhere in

00:16:05,000 --> 00:16:08,610
the colonel

00:16:05,760 --> 00:16:09,930
where you can do things I know google

00:16:08,610 --> 00:16:13,320
recently published protobuf

00:16:09,930 --> 00:16:16,200
specification we use it at scale for the

00:16:13,320 --> 00:16:19,250
things of the sort and something like

00:16:16,200 --> 00:16:19,250
that would actually make a lot of sense

00:16:26,170 --> 00:16:28,980
over here

00:16:33,850 --> 00:16:37,600
so I'm Dave Miller I maintain a

00:16:36,220 --> 00:16:44,709
networking stack so maybe I can answer

00:16:37,600 --> 00:16:46,389
some of those questions so first I want

00:16:44,709 --> 00:16:49,060
to say something first which is that the

00:16:46,389 --> 00:16:50,620
impression that I the most significant

00:16:49,060 --> 00:16:55,709
impression I get from this is that if

00:16:50,620 --> 00:16:59,970
you create an RFC with a couple hundred

00:16:55,709 --> 00:17:03,790
statistical recommendations in it for us

00:16:59,970 --> 00:17:05,410
that creates a large gap and what

00:17:03,790 --> 00:17:07,720
traditionally what would happen for some

00:17:05,410 --> 00:17:10,179
facility like this is that evolutionary

00:17:07,720 --> 00:17:12,579
in an evolutionary way over too many

00:17:10,179 --> 00:17:14,470
years people would gradually recommend

00:17:12,579 --> 00:17:17,309
specific use cases where they're finding

00:17:14,470 --> 00:17:19,750
a specific counter being useful to them

00:17:17,309 --> 00:17:21,789
so now we've created a situation where

00:17:19,750 --> 00:17:24,459
somebody has to invest the time to go

00:17:21,789 --> 00:17:26,350
through all these and and individually

00:17:24,459 --> 00:17:28,840
justify each of them and go through this

00:17:26,350 --> 00:17:31,120
whole conversation the original context

00:17:28,840 --> 00:17:33,370
of where you at what led you to add that

00:17:31,120 --> 00:17:35,710
counter in the first place my even he

00:17:33,370 --> 00:17:39,130
lost upon the person who has to justify

00:17:35,710 --> 00:17:40,659
it for us so I think that's that's the

00:17:39,130 --> 00:17:43,770
disconnect that's happening with this

00:17:40,659 --> 00:17:46,150
facility right now and why it's we

00:17:43,770 --> 00:17:48,010
perhaps taking more effort than it

00:17:46,150 --> 00:17:49,870
otherwise would have to integrate the

00:17:48,010 --> 00:17:54,700
functionality that you're looking for

00:17:49,870 --> 00:17:59,910
I actually agree with that very much we

00:17:54,700 --> 00:18:04,390
made a mistake and fully admit to that

00:17:59,910 --> 00:18:07,000
the mistake we made was that honestly we

00:18:04,390 --> 00:18:09,720
just implemented everything in that RFC

00:18:07,000 --> 00:18:11,680
and then threw it at the dev team

00:18:09,720 --> 00:18:13,450
without providing any sort of

00:18:11,680 --> 00:18:14,950
justification or providing the use cases

00:18:13,450 --> 00:18:17,080
or the validation that they need to

00:18:14,950 --> 00:18:21,790
actually make it functional and actually

00:18:17,080 --> 00:18:25,450
really consider it the goal here at this

00:18:21,790 --> 00:18:29,220
point is not to turn around and justify

00:18:25,450 --> 00:18:33,130
RFC 4898 not interested in doing that

00:18:29,220 --> 00:18:37,270
what I am interested in doing is trying

00:18:33,130 --> 00:18:40,620
to find where people think about stack

00:18:37,270 --> 00:18:44,410
instrumentation and if there is interest

00:18:40,620 --> 00:18:47,710
what's the subset of instruments that

00:18:44,410 --> 00:18:49,570
enough people agree on to make it

00:18:47,710 --> 00:18:56,080
worthwhile to really invest the time in

00:18:49,570 --> 00:18:58,030
and moving from that subset we can start

00:18:56,080 --> 00:19:00,370
exploring different instruments in a

00:18:58,030 --> 00:19:06,640
more piece mail and evolutionary sort of

00:19:00,370 --> 00:19:08,890
basis so I mean I fully agree with you I

00:19:06,640 --> 00:19:13,050
really do and we really made a mistake

00:19:08,890 --> 00:19:15,700
when we we submitted that patch so

00:19:13,050 --> 00:19:17,770
that's the goal here is to actually try

00:19:15,700 --> 00:19:20,980
and figure out where people have enough

00:19:17,770 --> 00:19:25,210
overlap to make the time investment

00:19:20,980 --> 00:19:29,470
worthwhile I guess one of the questions

00:19:25,210 --> 00:19:31,630
I have is do people think that there

00:19:29,470 --> 00:19:35,710
should be some higher level of

00:19:31,630 --> 00:19:38,100
instrumentation in the stack can I yeah

00:19:35,710 --> 00:19:42,350
so to the question I'm Eric Timothy I

00:19:38,100 --> 00:19:47,690
just oh oh hi sorry

00:19:42,350 --> 00:19:53,059
so yeah so we do have some needs for

00:19:47,690 --> 00:19:55,160
adding specific stuff what one thing to

00:19:53,059 --> 00:19:57,830
understand is that Ryan sorry could you

00:19:55,160 --> 00:20:01,760
speak up a lil one thing to understand

00:19:57,830 --> 00:20:05,240
right now is that the TCP socket is big

00:20:01,760 --> 00:20:11,480
in the journal it's about two kilobytes

00:20:05,240 --> 00:20:15,500
of memory typically it means that an

00:20:11,480 --> 00:20:19,929
incoming packet can bring in the CPU

00:20:15,500 --> 00:20:22,789
cache a lot of cache lines yes it's

00:20:19,929 --> 00:20:27,679
something like one or two microseconds

00:20:22,789 --> 00:20:30,080
per packet so it's interesting to see

00:20:27,679 --> 00:20:33,230
that the networking speed is increasing

00:20:30,080 --> 00:20:39,230
very fast we use to have 10 gig we now

00:20:33,230 --> 00:20:41,870
have 40 gig 100 link get it very shortly

00:20:39,230 --> 00:20:45,490
but the processing speed is the same the

00:20:41,870 --> 00:20:53,390
memory bandwidth is the same so a

00:20:45,490 --> 00:20:56,299
counter is 8 bytes eight counters are 64

00:20:53,390 --> 00:21:02,840
bytes a cache line a cache line is 100

00:20:56,299 --> 00:21:07,840
nanosecond it so we really need to don't

00:21:02,840 --> 00:21:10,850
bloat the TCP socket that's real real

00:21:07,840 --> 00:21:13,280
that's a real thing so like I agree with

00:21:10,850 --> 00:21:16,490
that so at Google we prefer just

00:21:13,280 --> 00:21:23,179
extending the TCP info which already

00:21:16,490 --> 00:21:26,860
contains a lot of metrics and we plan to

00:21:23,179 --> 00:21:31,809
send a trim patch for that but we do not

00:21:26,860 --> 00:21:36,110
want to add more than eight new metrics

00:21:31,809 --> 00:21:39,169
so that's the girl and and if someone

00:21:36,110 --> 00:21:42,300
wants something else some specific use

00:21:39,169 --> 00:21:45,390
you always can add

00:21:42,300 --> 00:21:49,320
probes or whatever you need into your

00:21:45,390 --> 00:21:52,920
local tree for your specific needs or

00:21:49,320 --> 00:21:56,550
you can use external tools like tcpdump

00:21:52,920 --> 00:22:00,990
and you can infer or a lot of matrix

00:21:56,550 --> 00:22:03,840
just by analyzing raw data and you can

00:22:00,990 --> 00:22:07,110
get much more entropic much more useful

00:22:03,840 --> 00:22:09,390
input from raw data than statistic or

00:22:07,110 --> 00:22:14,220
controls anyway I have to say I disagree

00:22:09,390 --> 00:22:17,160
about TCP dump and that's I mean having

00:22:14,220 --> 00:22:19,410
a disagreement is fine with this one of

00:22:17,160 --> 00:22:20,970
the issues we found with TCP dump is if

00:22:19,410 --> 00:22:22,860
we're going to be monitoring a large

00:22:20,970 --> 00:22:26,640
number of connections TCP dump just

00:22:22,860 --> 00:22:29,160
isn't an effective tool for that in our

00:22:26,640 --> 00:22:31,560
use case we want to have instrumentation

00:22:29,160 --> 00:22:34,470
on all of the flows that we have going

00:22:31,560 --> 00:22:37,860
in and out of our data transfers our

00:22:34,470 --> 00:22:40,890
data transfer centers having a TCP dump

00:22:37,860 --> 00:22:44,280
running on those when we're moving you

00:22:40,890 --> 00:22:47,220
know so night gig is living in explain

00:22:44,280 --> 00:22:50,840
what we are doing we use the global SNMP

00:22:47,220 --> 00:22:54,510
encounters to try to track for anomalies

00:22:50,840 --> 00:22:57,720
and if we have some anomalies we do use

00:22:54,510 --> 00:23:01,950
TCP dump on selected flows for example

00:22:57,720 --> 00:23:05,400
at Google we have these user facing

00:23:01,950 --> 00:23:12,050
servers serving YouTube stuff like that

00:23:05,400 --> 00:23:16,130
and we have this on random capture of

00:23:12,050 --> 00:23:21,600
about one hand one percent of the flows

00:23:16,130 --> 00:23:23,970
so even if we have some problems we can

00:23:21,600 --> 00:23:25,920
have some historical data game is raw

00:23:23,970 --> 00:23:29,340
data and we don't need to capture all

00:23:25,920 --> 00:23:31,230
data because it would be insane yes we

00:23:29,340 --> 00:23:33,900
are you are speaking of terabytes the

00:23:31,230 --> 00:23:39,800
rabbits you can multiply by 1000 for

00:23:33,900 --> 00:23:44,790
google it's just insane oh okay and so

00:23:39,800 --> 00:23:47,910
the other thing is what brings this

00:23:44,790 --> 00:23:50,100
matrix they are useful to attract some

00:23:47,910 --> 00:23:52,110
anomalies in the stack Vicksburg's

00:23:50,100 --> 00:23:56,990
things like that

00:23:52,110 --> 00:24:00,360
so and really really in this case

00:23:56,990 --> 00:24:06,000
tcpdump helps a lot because you are

00:24:00,360 --> 00:24:07,860
capturing the packet and you can spot

00:24:06,000 --> 00:24:10,710
some anomalies like something like a

00:24:07,860 --> 00:24:12,960
statistical control cannot right there

00:24:10,710 --> 00:24:17,030
is no way you can track some anomaly in

00:24:12,960 --> 00:24:19,799
sac processing or whatever you know it's

00:24:17,030 --> 00:24:25,860
it's very hot track trigger works in the

00:24:19,799 --> 00:24:29,100
stack with just contours I understand

00:24:25,860 --> 00:24:33,750
where you're coming from and I I really

00:24:29,100 --> 00:24:35,190
do I actually really appreciate what

00:24:33,750 --> 00:24:36,960
you're saying I really do and I think

00:24:35,190 --> 00:24:41,480
this sort of back and forth is important

00:24:36,960 --> 00:24:46,890
to figuring out where we want to go I

00:24:41,480 --> 00:24:53,090
don't think that methodology works as

00:24:46,890 --> 00:24:55,590
well in our situation as main yours and

00:24:53,090 --> 00:24:56,910
for very obvious reasons we have

00:24:55,590 --> 00:24:59,190
different business cases we have

00:24:56,910 --> 00:25:01,610
different use cases we have different

00:24:59,190 --> 00:25:04,710
ways of actually setting up our networks

00:25:01,610 --> 00:25:07,470
and I think that's really what we're

00:25:04,710 --> 00:25:09,990
trying to get here is where do we have

00:25:07,470 --> 00:25:11,940
at least some level of overlap that we

00:25:09,990 --> 00:25:14,730
can work together on and move forward

00:25:11,940 --> 00:25:17,010
from there and I agree with you about

00:25:14,730 --> 00:25:20,549
not one bloke the bloat the socket any

00:25:17,010 --> 00:25:24,960
more than I already is we don't want to

00:25:20,549 --> 00:25:26,730
add make it even slower we don't want to

00:25:24,960 --> 00:25:29,340
have our instruments make things slower

00:25:26,730 --> 00:25:30,660
if they're not providing any value in

00:25:29,340 --> 00:25:37,950
fact we don't want to have them make any

00:25:30,660 --> 00:25:40,650
make it slower at all so I guess what

00:25:37,950 --> 00:25:42,030
I'm really trying to get it at get at is

00:25:40,650 --> 00:25:43,950
one of the things I really want to try

00:25:42,030 --> 00:25:45,360
doing is find where we have some overlap

00:25:43,950 --> 00:25:47,850
and see if there's someplace where we

00:25:45,360 --> 00:25:50,130
can actually find some common ground so

00:25:47,850 --> 00:25:57,049
we can work together on this as opposed

00:25:50,130 --> 00:25:59,760
to opposing each other yeah one thing I

00:25:57,049 --> 00:26:01,770
I'm not opposed even though I have a

00:25:59,760 --> 00:26:03,840
different methodology for bringing the

00:26:01,770 --> 00:26:05,440
stat bring the instruments out of the

00:26:03,840 --> 00:26:07,269
stack I not

00:26:05,440 --> 00:26:10,840
that I have no ego invested in my

00:26:07,269 --> 00:26:12,490
specific code I'm willing to do whatever

00:26:10,840 --> 00:26:14,470
is necessary to get the instruments out

00:26:12,490 --> 00:26:17,649
I care about the instruments rather than

00:26:14,470 --> 00:26:21,370
my specific implementation I'm sorry to

00:26:17,649 --> 00:26:24,149
interrupt going my name is Thomas cough

00:26:21,370 --> 00:26:27,070
maybe i can give you another use case

00:26:24,149 --> 00:26:29,250
our use case probably overlaps with the

00:26:27,070 --> 00:26:31,659
with the twitter use case we were

00:26:29,250 --> 00:26:34,029
introduced in multi-tenant data centers

00:26:31,659 --> 00:26:36,460
and we use metrics for two different

00:26:34,029 --> 00:26:38,139
purposes one is troubleshooting

00:26:36,460 --> 00:26:40,179
providing troubleshooting tools if you

00:26:38,139 --> 00:26:43,240
have a problem and I agree if Eric that

00:26:40,179 --> 00:26:45,250
a static set of counters doesn't work

00:26:43,240 --> 00:26:47,649
for us we figured out that if yet

00:26:45,250 --> 00:26:50,200
counters it's usually not the ones that

00:26:47,649 --> 00:26:52,240
you need at that time so you're just

00:26:50,200 --> 00:26:53,919
slowing down a networking stack without

00:26:52,240 --> 00:26:57,009
providing any additional well if that's

00:26:53,919 --> 00:26:58,779
just my my existing experience so far so

00:26:57,009 --> 00:27:00,669
what we figured is that if you want to

00:26:58,779 --> 00:27:02,279
capture additional metrics for

00:27:00,669 --> 00:27:05,230
troubleshooting you need to make it

00:27:02,279 --> 00:27:06,820
programmable so you can if you want to

00:27:05,230 --> 00:27:09,789
troubleshoot a specific problem you can

00:27:06,820 --> 00:27:11,710
insert certain rules some program EPF

00:27:09,789 --> 00:27:13,600
whatever to capture additional metrics

00:27:11,710 --> 00:27:15,190
obviously that only works if you if you

00:27:13,600 --> 00:27:16,629
know ahead of time that you're going to

00:27:15,190 --> 00:27:18,159
want to capture something yeah you

00:27:16,629 --> 00:27:20,529
cannot look back right this is the

00:27:18,159 --> 00:27:22,840
digital disadvantage the second use case

00:27:20,529 --> 00:27:25,600
is if you have a policy and you have to

00:27:22,840 --> 00:27:27,100
monitor your network and you need some

00:27:25,600 --> 00:27:29,679
kind of feedback from the network that

00:27:27,100 --> 00:27:31,509
so you can you can you can modify how

00:27:29,679 --> 00:27:36,730
you how you configure or program your

00:27:31,509 --> 00:27:38,830
your network and in this case I said a

00:27:36,730 --> 00:27:39,850
set of study counters works a little bit

00:27:38,830 --> 00:27:42,159
better because usually you're

00:27:39,850 --> 00:27:46,379
interesting common statistics like I

00:27:42,159 --> 00:27:48,669
counters RTT queue length whatever so

00:27:46,379 --> 00:27:51,970
what what I have learned so far is that

00:27:48,669 --> 00:27:56,190
for static counters works fairly well

00:27:51,970 --> 00:27:58,690
for well-known defined use cases like

00:27:56,190 --> 00:28:00,879
monitoring qbank but it does not really

00:27:58,690 --> 00:28:03,309
work for any kind of trouble shooting of

00:28:00,879 --> 00:28:06,009
complex networking issues okay now I

00:28:03,309 --> 00:28:10,360
think that a programmable approach would

00:28:06,009 --> 00:28:12,840
be superior so how would you how do you

00:28:10,360 --> 00:28:12,840
envision that

00:28:12,850 --> 00:28:18,580
have you seen Alexis EPP f ganization

00:28:16,270 --> 00:28:20,440
yesterday I think that is pretty close

00:28:18,580 --> 00:28:23,290
to what I would have in mind as well too

00:28:20,440 --> 00:28:25,840
I agree that a a common self

00:28:23,290 --> 00:28:29,560
self-describing data format would be

00:28:25,840 --> 00:28:31,000
extremely beneficial but I think into

00:28:29,560 --> 00:28:33,780
the interfacing if the colonel could be

00:28:31,000 --> 00:28:35,980
based on EPP app where you worry only

00:28:33,780 --> 00:28:37,720
insert the overhead of capturing

00:28:35,980 --> 00:28:39,640
additional metrics when you actually

00:28:37,720 --> 00:28:41,740
need it yes if you if you want to

00:28:39,640 --> 00:28:43,480
capture it all the time fine you can you

00:28:41,740 --> 00:28:45,310
can put your Colonel and just insert

00:28:43,480 --> 00:28:48,670
epfo right away what you're not

00:28:45,310 --> 00:28:50,640
requiring everybody to run these metrics

00:28:48,670 --> 00:28:53,980
all the time and you're not inserting

00:28:50,640 --> 00:28:56,110
fast path checks to actually disable or

00:28:53,980 --> 00:28:58,470
enable counters and stuff like that yeah

00:28:56,110 --> 00:29:03,190
one of the things we did with web tangi

00:28:58,470 --> 00:29:06,520
is we actually have instruments are

00:29:03,190 --> 00:29:08,920
enabled via a mask so you only have the

00:29:06,520 --> 00:29:10,840
instruments on that you care about so

00:29:08,920 --> 00:29:14,050
we're not capturing we don't necessarily

00:29:10,840 --> 00:29:15,760
capture all the data all the time we

00:29:14,050 --> 00:29:19,360
just capture the subset that people are

00:29:15,760 --> 00:29:23,080
most interested in again these are

00:29:19,360 --> 00:29:24,730
static counters some of them are some of

00:29:23,080 --> 00:29:26,770
them are just you know bike counters how

00:29:24,730 --> 00:29:28,900
many bytes have we seen how many sacks

00:29:26,770 --> 00:29:31,420
have we seen others are how many

00:29:28,900 --> 00:29:35,190
congestion events we've seen and then we

00:29:31,420 --> 00:29:38,860
have some instruments that are actually

00:29:35,190 --> 00:29:42,850
computed things like pipe size things

00:29:38,860 --> 00:29:45,310
like that so I agree with you that

00:29:42,850 --> 00:29:48,370
having all the metrics on all the time

00:29:45,310 --> 00:29:49,620
is not the way to do this and having

00:29:48,370 --> 00:29:53,830
some sort of programmable interface

00:29:49,620 --> 00:29:56,830
where we can enable certain instruments

00:29:53,830 --> 00:29:59,740
on the fly or based on certain

00:29:56,830 --> 00:30:03,060
conditions is probably the way to move

00:29:59,740 --> 00:30:03,060
forward on something like this

00:30:04,530 --> 00:30:08,430
Matt are you looking for something

00:30:13,460 --> 00:30:18,649
might as well move forward a tiny bit

00:30:15,460 --> 00:30:21,289
Eric I have a question about cache

00:30:18,649 --> 00:30:25,010
efficiency and so on really be on my

00:30:21,289 --> 00:30:27,500
area how much would it does it matter if

00:30:25,010 --> 00:30:30,049
you have instruments that are not hit

00:30:27,500 --> 00:30:33,970
particularly often as opposed off

00:30:30,049 --> 00:30:33,970
instrument that are hit in every packet

00:30:45,420 --> 00:30:50,960
I guess the answer depends how you

00:30:47,670 --> 00:30:52,950
organize the fields in the circuit and

00:30:50,960 --> 00:30:59,340
currently in the kernel we have this

00:30:52,950 --> 00:31:04,140
layout of having the list you know we

00:30:59,340 --> 00:31:06,660
have this class of objects with a

00:31:04,140 --> 00:31:08,820
comment so get layer very small circuit

00:31:06,660 --> 00:31:11,520
and then I net circuit and then TCP

00:31:08,820 --> 00:31:13,980
socket and actually it's pretty hard to

00:31:11,520 --> 00:31:16,710
organize the fields in a efficient way

00:31:13,980 --> 00:31:19,290
for example the receive path and output

00:31:16,710 --> 00:31:21,510
path because we still have to hit

00:31:19,290 --> 00:31:23,970
different fields from these three

00:31:21,510 --> 00:31:29,070
different circuits so it's very hard to

00:31:23,970 --> 00:31:32,940
cache optimize the thing so we could do

00:31:29,070 --> 00:31:35,220
that doing some very smart placement of

00:31:32,940 --> 00:31:39,350
the fields but the current architecture

00:31:35,220 --> 00:31:39,350
of the colonel doesn't really have that

00:31:40,130 --> 00:31:43,730
that's a bit hard

00:31:46,510 --> 00:31:51,190
he gave you some idea about that

00:31:53,250 --> 00:31:59,120
so since we kind of brought it up with

00:31:55,620 --> 00:32:01,170
what Thomas was talking about earlier

00:31:59,120 --> 00:32:02,790
actually I'm going to direct a question

00:32:01,170 --> 00:32:05,730
of Thomas so if you you were envisioning

00:32:02,790 --> 00:32:08,040
a nanny BBF type solution where people

00:32:05,730 --> 00:32:09,510
would insert EPF rules that are

00:32:08,040 --> 00:32:12,140
triggered by the events or function

00:32:09,510 --> 00:32:14,580
calls and whatever to collect statistics

00:32:12,140 --> 00:32:16,590
I'm Conor wondering if you thought about

00:32:14,580 --> 00:32:19,140
where you would be storing that metadata

00:32:16,590 --> 00:32:20,940
that EBF would be operating on and

00:32:19,140 --> 00:32:22,470
collecting the statistics would it be

00:32:20,940 --> 00:32:23,930
like an indirect pointer from the TCP

00:32:22,470 --> 00:32:28,110
socket or something like-like-like

00:32:23,930 --> 00:32:29,280
better because we're not going to want

00:32:28,110 --> 00:32:31,380
to eat up the storage all the time

00:32:29,280 --> 00:32:34,370
obviously he's not wondering what kind

00:32:31,380 --> 00:32:34,370
of ideas you had in that area

00:32:39,180 --> 00:32:42,870
so maybe it would be over tracing with

00:32:41,520 --> 00:32:45,840
the legs a short yesterday that you

00:32:42,870 --> 00:32:49,650
insert those trays points dynamically

00:32:45,840 --> 00:32:52,110
and toilet Conger sandy BPF maps so you

00:32:49,650 --> 00:32:53,820
wouldn't actually I mean if that

00:32:52,110 --> 00:32:57,750
approach would work didn't you wouldn't

00:32:53,820 --> 00:32:59,940
need to store anything in a socket for

00:32:57,750 --> 00:33:01,140
example because I kind of imagined that

00:32:59,940 --> 00:33:04,440
a lot of people who would use these

00:33:01,140 --> 00:33:06,750
tools would want to be able to fetch the

00:33:04,440 --> 00:33:08,940
information for a particular flow as if

00:33:06,750 --> 00:33:12,630
in the tree and the traditional way to

00:33:08,940 --> 00:33:14,130
do that is the dump socket state so you

00:33:12,630 --> 00:33:15,870
would have to have some mapping back to

00:33:14,130 --> 00:33:20,280
the tracing information from socket ID

00:33:15,870 --> 00:33:21,900
or something like this I haven't really

00:33:20,280 --> 00:33:24,840
thought it through yet I would have

00:33:21,900 --> 00:33:28,560
imagined that we can we can use a a map

00:33:24,840 --> 00:33:31,170
that is where we when we map this

00:33:28,560 --> 00:33:33,390
metadata and it's well known basically

00:33:31,170 --> 00:33:34,710
just inject the EBP f program to

00:33:33,390 --> 00:33:37,380
actually start capturing but the

00:33:34,710 --> 00:33:41,460
definition of the connors could be could

00:33:37,380 --> 00:33:43,850
already exists but and the map to the

00:33:41,460 --> 00:33:46,290
socket would be about defined one that

00:33:43,850 --> 00:33:47,460
focuses so my question so basically what

00:33:46,290 --> 00:33:49,380
you're saying is that the metadata is an

00:33:47,460 --> 00:33:50,640
external entity that is not going to be

00:33:49,380 --> 00:33:53,160
in the socket in any way shape or form

00:33:50,640 --> 00:33:54,930
yeah I'm maybe you have a map and you

00:33:53,160 --> 00:33:56,640
can you can you can access that map if

00:33:54,930 --> 00:33:59,010
to sock a pointer for example to stores

00:33:56,640 --> 00:34:00,690
/ socket metrics okay maybe you want to

00:33:59,010 --> 00:34:03,540
want to store metrics not just for

00:34:00,690 --> 00:34:06,210
soccer / / your own flow definition do

00:34:03,540 --> 00:34:07,860
you want to store it based on another

00:34:06,210 --> 00:34:10,080
classifier so you could define your own

00:34:07,860 --> 00:34:12,390
classifier which says I want to store

00:34:10,080 --> 00:34:15,240
these counters based on a hash of the

00:34:12,390 --> 00:34:16,950
packet or something like that so I kind

00:34:15,240 --> 00:34:19,050
of like this idea even more because it

00:34:16,950 --> 00:34:20,790
kind of obviates the whole discussion of

00:34:19,050 --> 00:34:22,080
how efficient all of these counters

00:34:20,790 --> 00:34:23,300
going to be inside a socket because

00:34:22,080 --> 00:34:25,470
we're storing them somewhere else

00:34:23,300 --> 00:34:27,240
therefore when it counters the counter

00:34:25,470 --> 00:34:31,210
collection is not enabled the storage

00:34:27,240 --> 00:34:33,349
overhead doesn't exist as well as the

00:34:31,210 --> 00:34:35,239
inefficient layouts are cashing issues

00:34:33,349 --> 00:34:37,999
within the socket itself or kind of like

00:34:35,239 --> 00:34:40,279
it's not even an issue yeah I mean one

00:34:37,999 --> 00:34:41,929
one typical example of beta some people

00:34:40,279 --> 00:34:44,089
might just want to keep metrics /

00:34:41,929 --> 00:34:46,339
namespace and up even / / soccer because

00:34:44,089 --> 00:34:48,049
they know whatever socket is in a given

00:34:46,339 --> 00:34:50,089
name space actually shares the same I

00:34:48,049 --> 00:34:51,649
think they don't care between the

00:34:50,089 --> 00:34:53,210
different sockets and you could use that

00:34:51,649 --> 00:34:55,819
to isolate the case that you're trying

00:34:53,210 --> 00:34:57,829
to analyze you can say when I have this

00:34:55,819 --> 00:35:00,019
this researcher is running this problem

00:34:57,829 --> 00:35:01,880
to this site we're going to put him in a

00:35:00,019 --> 00:35:04,489
namespace and enable the tracing for

00:35:01,880 --> 00:35:07,339
that namespace and that eliminates all

00:35:04,489 --> 00:35:08,599
the difficulty of filtering your tracing

00:35:07,339 --> 00:35:12,710
on a per connection basis you can

00:35:08,599 --> 00:35:14,539
control it in a namespace races Matt

00:35:12,710 --> 00:35:17,180
correct me if I'm wrong but we are

00:35:14,539 --> 00:35:23,470
storing the we are storing the counters

00:35:17,180 --> 00:35:27,019
outside and socket correct in web 10g ok

00:35:23,470 --> 00:35:28,579
yet so we've actually implemented the

00:35:27,019 --> 00:35:31,309
way that we implement the storage for

00:35:28,579 --> 00:35:32,749
this probably not the most efficient way

00:35:31,309 --> 00:35:34,099
but we're not storing it inside of the

00:35:32,749 --> 00:35:35,809
socket we're storing it out we're

00:35:34,099 --> 00:35:39,529
starting the storing the data outside of

00:35:35,809 --> 00:35:44,089
the socket and so what's the mechanism

00:35:39,529 --> 00:35:50,029
you get to that ah that's a good

00:35:44,089 --> 00:35:51,410
question so you have a hash table ok so

00:35:50,029 --> 00:35:53,779
there's a pointer that references to it

00:35:51,410 --> 00:35:55,940
ok so yes that's how that's like kind of

00:35:53,779 --> 00:35:57,319
like the midway between the external

00:35:55,940 --> 00:35:58,999
solution and the one where you actually

00:35:57,319 --> 00:36:01,549
put the counters inside there is one

00:35:58,999 --> 00:36:04,579
thing i don't really like about web 10g

00:36:01,549 --> 00:36:08,710
the truth is we try to use web tangi at

00:36:04,579 --> 00:36:13,430
Google and we revert it the patch so

00:36:08,710 --> 00:36:15,890
there is this thing about web 10g it

00:36:13,430 --> 00:36:17,569
wants to derm the state at the end of

00:36:15,890 --> 00:36:19,489
the circuit so when you close the

00:36:17,569 --> 00:36:22,789
circuit you have this a synchronous

00:36:19,489 --> 00:36:26,509
event it use a walk you and it wants to

00:36:22,789 --> 00:36:30,249
dumb data to a remote character and it's

00:36:26,509 --> 00:36:33,349
kind of it is anything that net link so

00:36:30,249 --> 00:36:35,380
really this kind of stuff should be

00:36:33,349 --> 00:36:37,329
under by net link

00:36:35,380 --> 00:36:41,849
because we already have this monitoring

00:36:37,329 --> 00:36:45,430
stuff in net link you can have any

00:36:41,849 --> 00:36:49,240
subscriber to the multicast event it's

00:36:45,430 --> 00:36:51,490
yeah so right now there are days this

00:36:49,240 --> 00:36:53,470
walk you and one of the issue we had at

00:36:51,490 --> 00:36:55,420
Google was that the walk you management

00:36:53,470 --> 00:36:57,579
was not really working properly and we

00:36:55,420 --> 00:36:59,890
had crashed because of that so that's

00:36:57,579 --> 00:37:04,119
partially why we reverted to the patch

00:36:59,890 --> 00:37:06,519
yeah and we understood that was we we

00:37:04,119 --> 00:37:08,680
were told that was happening the only

00:37:06,519 --> 00:37:10,029
thing I would have asked is that no one

00:37:08,680 --> 00:37:13,359
at Google told us that was happening

00:37:10,029 --> 00:37:15,039
until it was too late we've resolved a

00:37:13,359 --> 00:37:19,059
lot of those problems and later versions

00:37:15,039 --> 00:37:20,529
of the code the work queue management is

00:37:19,059 --> 00:37:24,039
possibly not the most efficient way of

00:37:20,529 --> 00:37:27,160
doing this we do have net link

00:37:24,039 --> 00:37:29,170
interfaces to the data so that we can

00:37:27,160 --> 00:37:31,059
bring it out of the colonel if we can

00:37:29,170 --> 00:37:32,559
integrate that more tightly into the

00:37:31,059 --> 00:37:33,849
existing netlink structures for

00:37:32,559 --> 00:37:42,150
monitoring that's probably going to be a

00:37:33,849 --> 00:37:46,329
better move moving forward the goal is a

00:37:42,150 --> 00:37:50,880
you know had too much coffee and I just

00:37:46,329 --> 00:37:50,880
lost my train of thought so

00:37:52,420 --> 00:37:55,960
anyway so this moves us onto I mean like

00:37:54,790 --> 00:37:58,450
we've already been talking about some of

00:37:55,960 --> 00:38:01,300
the implementation aspects of this I

00:37:58,450 --> 00:38:03,070
really do think that and I really hope

00:38:01,300 --> 00:38:04,720
as many of you actually join the mailing

00:38:03,070 --> 00:38:05,620
list as possible because I think that's

00:38:04,720 --> 00:38:09,970
we're really going to start talking

00:38:05,620 --> 00:38:11,590
about what set of instruments are going

00:38:09,970 --> 00:38:13,690
to be most useful and I really want

00:38:11,590 --> 00:38:16,750
Google involved in this so if i can

00:38:13,690 --> 00:38:18,850
continue oh yes sir so we we did revert

00:38:16,750 --> 00:38:22,300
this thing and we are planning to extend

00:38:18,850 --> 00:38:25,300
TCP info so that we can get the netting

00:38:22,300 --> 00:38:28,780
identification for free so at the end of

00:38:25,300 --> 00:38:32,590
the circuit we will provide a copy of

00:38:28,780 --> 00:38:35,410
the TCP info through netlink verticals

00:38:32,590 --> 00:38:39,610
interface so it will basically provide

00:38:35,410 --> 00:38:44,610
what web tangi users wanted at Google

00:38:39,610 --> 00:38:47,290
without the full web 10g footprint I

00:38:44,610 --> 00:38:48,640
kind of suspect that as we go along

00:38:47,290 --> 00:38:51,790
doing this you're going to have two

00:38:48,640 --> 00:38:53,590
classes of information that you want to

00:38:51,790 --> 00:38:54,610
look at it you're going to have a bunch

00:38:53,590 --> 00:38:57,160
of things that you're going to be able

00:38:54,610 --> 00:38:59,290
to narrow down to your eight magic

00:38:57,160 --> 00:39:01,750
counters or whatever that number ends up

00:38:59,290 --> 00:39:03,430
being that we kind of all agree that is

00:39:01,750 --> 00:39:04,960
useful to be in there all the time and

00:39:03,430 --> 00:39:06,340
always being collected and always being

00:39:04,960 --> 00:39:08,470
a vegetable and always being available

00:39:06,340 --> 00:39:10,060
for users then we're going to have this

00:39:08,470 --> 00:39:12,550
stuff that that's going to be like we

00:39:10,060 --> 00:39:15,100
only want to this is extra this is

00:39:12,550 --> 00:39:17,020
applied to a narrower scope of use cases

00:39:15,100 --> 00:39:21,240
and therefore wants to be turned on and

00:39:17,020 --> 00:39:27,420
the overhead for which being happening

00:39:21,240 --> 00:39:31,240
only one explicitly asked for so yeah

00:39:27,420 --> 00:39:33,700
hello so that's sexually true and I

00:39:31,240 --> 00:39:35,800
would do it more like there's things

00:39:33,700 --> 00:39:38,290
that are more operational and the

00:39:35,800 --> 00:39:41,290
operational stuff we want on all the

00:39:38,290 --> 00:39:44,230
time and then for debugging the deep

00:39:41,290 --> 00:39:45,790
problems what's happening so what point

00:39:44,230 --> 00:39:49,300
out one interesting thing about Google

00:39:45,790 --> 00:39:52,660
is all of this is in a larger context

00:39:49,300 --> 00:39:54,340
which is network operations and one of

00:39:52,660 --> 00:39:55,990
the things that obviously a lot of

00:39:54,340 --> 00:39:58,869
people do is they're running s

00:39:55,990 --> 00:40:01,540
routers and switches and what we need to

00:39:58,869 --> 00:40:04,990
do is often is correlate information in

00:40:01,540 --> 00:40:06,700
the kernel with information in s flow s

00:40:04,990 --> 00:40:09,940
flow by definition is kind of a

00:40:06,700 --> 00:40:12,730
statistical sampling so we don't have

00:40:09,940 --> 00:40:13,960
perfect information there theoretically

00:40:12,730 --> 00:40:15,990
the colonel does have perfect

00:40:13,960 --> 00:40:19,540
information which is a big difference

00:40:15,990 --> 00:40:22,510
the one thing that we don't get out of s

00:40:19,540 --> 00:40:26,050
flow that we really kind of want is

00:40:22,510 --> 00:40:29,340
anything to do with state or retransmits

00:40:26,050 --> 00:40:31,720
and things like that and that's where

00:40:29,340 --> 00:40:33,160
you know there are obviously people who

00:40:31,720 --> 00:40:35,710
just want to do everything in s flow

00:40:33,160 --> 00:40:37,810
because it's a standard you have to deal

00:40:35,710 --> 00:40:40,480
with fewer entities actually so a lot

00:40:37,810 --> 00:40:42,310
fewer switches and hoes what we found

00:40:40,480 --> 00:40:45,000
out is there are just certain things you

00:40:42,310 --> 00:40:48,190
cannot get out of s flow by sampling and

00:40:45,000 --> 00:40:50,230
the big one was retransmits and that was

00:40:48,190 --> 00:40:52,840
very important to figure out what's

00:40:50,230 --> 00:40:54,730
happening so I think what dey say is

00:40:52,840 --> 00:40:56,110
that it's very true and it does come

00:40:54,730 --> 00:40:58,480
down to these two sets of information

00:40:56,110 --> 00:41:00,220
the things that are up kind of

00:40:58,480 --> 00:41:02,530
operational that always have to be there

00:41:00,220 --> 00:41:05,530
to maybe more than just bites and pack

00:41:02,530 --> 00:41:07,630
accounts and then obviously the ability

00:41:05,530 --> 00:41:10,869
when you're doing debugging or deeper

00:41:07,630 --> 00:41:12,900
analysis or possibly random sampling the

00:41:10,869 --> 00:41:15,850
turn on the more advanced statistics so

00:41:12,900 --> 00:41:19,390
I think if you start from that point of

00:41:15,850 --> 00:41:21,400
view then look at how the api's project

00:41:19,390 --> 00:41:22,450
from that so we need TCP Oh info in that

00:41:21,400 --> 00:41:24,609
length because they're going to be

00:41:22,450 --> 00:41:26,560
different even with a single use case

00:41:24,609 --> 00:41:28,690
there's different users yeah different

00:41:26,560 --> 00:41:31,690
people who are different interested in

00:41:28,690 --> 00:41:34,900
different aspects of the same connection

00:41:31,690 --> 00:41:39,190
I agree and like I said one of the

00:41:34,900 --> 00:41:41,020
things that we tried to do in web 10g

00:41:39,190 --> 00:41:44,680
we're actually calling it East stats at

00:41:41,020 --> 00:41:46,690
this point but web 10g is enabling

00:41:44,680 --> 00:41:48,339
different sets of instruments on the fly

00:41:46,690 --> 00:41:50,440
so you can actually change what

00:41:48,339 --> 00:41:52,030
instruments you're going to be

00:41:50,440 --> 00:41:53,260
collecting at any point you can turn

00:41:52,030 --> 00:41:56,140
them all off you can turn them all on

00:41:53,260 --> 00:41:59,109
you can turn on we have them separated

00:41:56,140 --> 00:42:00,819
into five different tables so you can

00:41:59,109 --> 00:42:03,339
turn on an entire table or you can turn

00:42:00,819 --> 00:42:11,589
on a subset of instruments within a

00:42:03,339 --> 00:42:13,390
specific table or across tables we found

00:42:11,589 --> 00:42:15,190
that to be probably the best way of

00:42:13,390 --> 00:42:16,920
doing things just because no one wants

00:42:15,190 --> 00:42:19,839
all the information all the time and

00:42:16,920 --> 00:42:22,450
some of these instruments are only going

00:42:19,839 --> 00:42:28,500
to be useful in a very small subset of

00:42:22,450 --> 00:42:30,910
cases I like the idea of having

00:42:28,500 --> 00:42:32,890
different namespaces having different

00:42:30,910 --> 00:42:35,730
instruments enabled I don't know how

00:42:32,890 --> 00:42:38,470
difficult that would be to implement

00:42:35,730 --> 00:42:42,400
right now this is a system-wide setting

00:42:38,470 --> 00:42:46,470
so it's you know all the instruments are

00:42:42,400 --> 00:42:49,089
on and the entire kernel for all users

00:42:46,470 --> 00:42:52,390
or the subset for all users would be

00:42:49,089 --> 00:42:57,569
interesting to have one user or one set

00:42:52,390 --> 00:42:57,569
of one set of

00:42:57,630 --> 00:43:01,920
group having a different set of

00:43:00,390 --> 00:43:04,339
instruments enabled in another depending

00:43:01,920 --> 00:43:08,880
on the namespace or something like that

00:43:04,339 --> 00:43:11,299
and I really think that's that could be

00:43:08,880 --> 00:43:11,299
really cool

00:43:14,040 --> 00:43:18,690
so the implementation aspects of this I

00:43:16,560 --> 00:43:21,870
do think there's some overlap between

00:43:18,690 --> 00:43:25,590
what we've already done with web 10g and

00:43:21,870 --> 00:43:28,740
where we want to go and again I'm not I

00:43:25,590 --> 00:43:30,450
have no ego invested in the code all I

00:43:28,740 --> 00:43:33,540
really care about is trying to provide

00:43:30,450 --> 00:43:34,740
better I really care about my users I

00:43:33,540 --> 00:43:37,140
want to provide a better experience to

00:43:34,740 --> 00:43:40,920
my users so whatever method we need to

00:43:37,140 --> 00:43:43,500
get there I'm behind if we can capture

00:43:40,920 --> 00:43:45,060
some of the concepts or code that we've

00:43:43,500 --> 00:43:47,640
already developed for web 10g and

00:43:45,060 --> 00:43:49,500
integrate it with other aspects and

00:43:47,640 --> 00:43:53,850
other ideas I think that might be

00:43:49,500 --> 00:43:56,790
helpful but however we want to move

00:43:53,850 --> 00:43:58,470
forward on this you know I'm invested in

00:43:56,790 --> 00:44:00,210
this I spent many years of my life

00:43:58,470 --> 00:44:03,360
already working on this I'd like to see

00:44:00,210 --> 00:44:06,750
it go forward and I think this would be

00:44:03,360 --> 00:44:09,630
something that be useful for the Linux

00:44:06,750 --> 00:44:11,070
community as a whole so I think we've

00:44:09,630 --> 00:44:12,660
already made some progress on that I

00:44:11,070 --> 00:44:15,090
think it all kind of agreed that the

00:44:12,660 --> 00:44:17,280
about the operational verse is not an

00:44:15,090 --> 00:44:18,720
operational issue and that TCP info

00:44:17,280 --> 00:44:20,850
would be the logical place to put the

00:44:18,720 --> 00:44:22,890
original values so does that leave us

00:44:20,850 --> 00:44:24,870
with what that leaves us with designing

00:44:22,890 --> 00:44:26,490
the non operational aspect of this

00:44:24,870 --> 00:44:27,840
problem which is the aspect of you are

00:44:26,490 --> 00:44:32,220
the most interested in right now I think

00:44:27,840 --> 00:44:34,170
yes so I think once once we have a game

00:44:32,220 --> 00:44:35,700
plan for where it goes and how it gets

00:44:34,170 --> 00:44:38,280
collected then you can start talking

00:44:35,700 --> 00:44:40,650
about adding things to individual

00:44:38,280 --> 00:44:42,390
elements and one by one going through

00:44:40,650 --> 00:44:44,580
the justification process or whatever

00:44:42,390 --> 00:44:48,450
you want to do about it so I think

00:44:44,580 --> 00:44:50,760
considering either what Thomas adjusted

00:44:48,450 --> 00:44:53,100
with EBP PPF probes that get dynamically

00:44:50,760 --> 00:44:55,650
otic enable they're just disabled or

00:44:53,100 --> 00:44:57,630
some other conditional ization like

00:44:55,650 --> 00:44:59,220
static probes which is another facility

00:44:57,630 --> 00:45:00,750
that we have inside the kernel for doing

00:44:59,220 --> 00:45:02,070
things in a fast manner to test that

00:45:00,750 --> 00:45:04,830
long time whether we should do something

00:45:02,070 --> 00:45:06,210
or not we should work that out that's

00:45:04,830 --> 00:45:09,180
what needs to get worked out the others

00:45:06,210 --> 00:45:10,830
and so so work out the implementation

00:45:09,180 --> 00:45:13,500
work out the implementation of the non

00:45:10,830 --> 00:45:16,470
operational aspects of the counters that

00:45:13,500 --> 00:45:19,620
everyone is interested in ok ok sounds

00:45:16,470 --> 00:45:20,940
good to me us in five minutes left yeah

00:45:19,620 --> 00:45:22,840
i was going to wrap things up at this

00:45:20,940 --> 00:45:25,850
point

00:45:22,840 --> 00:45:26,930
again if you want to be on the mailings

00:45:25,850 --> 00:45:31,190
I'm going to be setting up the mailing

00:45:26,930 --> 00:45:32,720
list hopefully tomorrow and make a

00:45:31,190 --> 00:45:34,640
suggestion sure now you talk out the

00:45:32,720 --> 00:45:36,650
mailing list whatever you discuss can

00:45:34,640 --> 00:45:41,680
you periodically kind of say here's

00:45:36,650 --> 00:45:44,180
where we are and netdev yes yes I'm

00:45:41,680 --> 00:45:46,010
overloaded already so i i'm not going to

00:45:44,180 --> 00:45:47,720
join your mailing list i understand i

00:45:46,010 --> 00:45:48,800
interested what you're working on so i

00:45:47,720 --> 00:45:51,140
would like to know where things are

00:45:48,800 --> 00:45:52,580
standing once in a while okay okay yeah

00:45:51,140 --> 00:45:55,280
that's not a problem at all so we'll get

00:45:52,580 --> 00:45:56,870
mailing list together see bad forming

00:45:55,280 --> 00:45:59,600
some sort of working group on this maybe

00:45:56,870 --> 00:46:01,370
some future meetups and the big thing is

00:45:59,600 --> 00:46:05,870
i do want to coordinate our effort I

00:46:01,370 --> 00:46:08,150
don't want to have I think having

00:46:05,870 --> 00:46:10,250
disagreements and different ideas of how

00:46:08,150 --> 00:46:11,990
to implement things make sense and it

00:46:10,250 --> 00:46:13,640
really helps push things forward but I'd

00:46:11,990 --> 00:46:16,010
really rather not having us working

00:46:13,640 --> 00:46:22,160
against each other as we move forward on

00:46:16,010 --> 00:46:24,920
this so and while i am setting this up I

00:46:22,160 --> 00:46:26,800
not saying that I'm in a leadership role

00:46:24,920 --> 00:46:29,060
on this I'd be happy to take that but

00:46:26,800 --> 00:46:31,190
whoever wants to start doing more work

00:46:29,060 --> 00:46:36,830
on this just please stand up and let me

00:46:31,190 --> 00:46:39,080
know I am very happy you're all here and

00:46:36,830 --> 00:46:43,840
thank you so much for your time and

00:46:39,080 --> 00:46:43,840
attention on this that's it

00:46:44,950 --> 00:46:48,040

YouTube URL: https://www.youtube.com/watch?v=6VuniIff9z0


