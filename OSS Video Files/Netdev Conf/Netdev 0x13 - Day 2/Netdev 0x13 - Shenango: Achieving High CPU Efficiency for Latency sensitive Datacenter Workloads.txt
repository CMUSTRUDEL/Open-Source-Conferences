Title: Netdev 0x13 - Shenango: Achieving High CPU Efficiency for Latency sensitive Datacenter Workloads
Publication date: 2019-07-03
Playlist: Netdev 0x13 - Day 2
Description: 
	In this talk Amy Ousterhout describes the approach taken by Shenango which achieves
great CPU efficiency while maintaining the high request rates.

Datacenter applications demand microsecond-scale tail latencies and high request rates from operating systems. Achieving these goals in a CPU-efficient way is an open problem. Because of the high overheads of todayâ€™s kernel, the best available solution to achieve
microsecond-scale latencies is kernel-bypass networking, which dedicates CPU cores to applications for spin-polling the network card. But this approach wastes CPU: even at
modest average loads, one must dedicate enough cores for the peak expected load.

More info:
https://netdevconf.org/0x13/session.html?talk-shenango
Captions: 
	00:00:00,030 --> 00:00:03,629
hi I'm Amy I'm a graduate student at MIT

00:00:02,129 --> 00:00:05,430
and today I'm going to talk to you guys

00:00:03,629 --> 00:00:08,189
about Chenango which is a system that

00:00:05,430 --> 00:00:09,719
enables applications to achieve high CPU

00:00:08,189 --> 00:00:12,240
efficiency and Lotte latency

00:00:09,719 --> 00:00:14,340
simultaneously so we've prototyped our

00:00:12,240 --> 00:00:15,900
system to run on top of unmodified Linux

00:00:14,340 --> 00:00:17,430
but we'd be really interested in trying

00:00:15,900 --> 00:00:19,070
to incorporate some of the ideas I'm

00:00:17,430 --> 00:00:20,970
going to talk about into Linux as well

00:00:19,070 --> 00:00:22,680
and this is joint work with my

00:00:20,970 --> 00:00:27,330
colleagues at MIT Josh

00:00:22,680 --> 00:00:28,590
Jonathan Adam and Hari there are two

00:00:27,330 --> 00:00:30,869
major trends and hardware that are

00:00:28,590 --> 00:00:32,219
impacting data centers today the first

00:00:30,869 --> 00:00:33,780
is that networking hardware is getting

00:00:32,219 --> 00:00:35,219
faster so if we look at how networking

00:00:33,780 --> 00:00:36,870
Hardware has changed over the last 10

00:00:35,219 --> 00:00:38,070
years you can see that Layton sees have

00:00:36,870 --> 00:00:39,210
dropped by a factor of 20 and

00:00:38,070 --> 00:00:41,670
throughputs have increased by a factor

00:00:39,210 --> 00:00:44,789
of 100 and faster networking hardware is

00:00:41,670 --> 00:00:46,379
on its way but unfortunately today's

00:00:44,789 --> 00:00:49,020
operating systems add significant

00:00:46,379 --> 00:00:50,340
overheads to i/o operations because

00:00:49,020 --> 00:00:52,620
they're not optimized for such fast

00:00:50,340 --> 00:00:54,270
networking hardware so this makes it

00:00:52,620 --> 00:00:55,379
difficult for applications today to

00:00:54,270 --> 00:00:56,850
achieve the high performance that the

00:00:55,379 --> 00:01:01,079
underlying networking hardware has to

00:00:56,850 --> 00:01:02,489
offer as a result people are

00:01:01,079 --> 00:01:04,110
increasingly turning to using kernel

00:01:02,489 --> 00:01:05,420
bypasses approaches in order to achieve

00:01:04,110 --> 00:01:08,100
high network performance

00:01:05,420 --> 00:01:09,600
so traditionally cores which are shown

00:01:08,100 --> 00:01:11,670
in blue here are shared between

00:01:09,600 --> 00:01:13,590
applications in the kernel in order to

00:01:11,670 --> 00:01:15,210
send and receive a packet an application

00:01:13,590 --> 00:01:16,560
performs a system call and then the

00:01:15,210 --> 00:01:19,830
kernel interfaces with the networking

00:01:16,560 --> 00:01:22,380
hardware with kernel bypass applications

00:01:19,830 --> 00:01:25,380
circumvent the kernel we dedicate some

00:01:22,380 --> 00:01:27,509
number of cores too busy spinning and

00:01:25,380 --> 00:01:31,020
these cores pull the NIC hardware in

00:01:27,509 --> 00:01:33,290
order to send and receive packets these

00:01:31,020 --> 00:01:35,549
cores run only the dedicated application

00:01:33,290 --> 00:01:37,200
so this enables much higher throughput

00:01:35,549 --> 00:01:39,450
and lower latency than the traditional

00:01:37,200 --> 00:01:40,979
approach because applications avoid the

00:01:39,450 --> 00:01:44,790
overhead of traversing the kernel for

00:01:40,979 --> 00:01:46,409
all network operations at the same time

00:01:44,790 --> 00:01:47,970
another major trend is impacting data

00:01:46,409 --> 00:01:50,159
centers today and that's the slowing of

00:01:47,970 --> 00:01:51,540
Moore's law with the slowing of Moore's

00:01:50,159 --> 00:01:53,220
Law it becomes more difficult to

00:01:51,540 --> 00:01:55,649
increase the compute capabilities of an

00:01:53,220 --> 00:01:57,570
individual CPU so to keep up with

00:01:55,649 --> 00:01:59,070
increasing demands for compute we will

00:01:57,570 --> 00:02:01,799
require more and more servers which in

00:01:59,070 --> 00:02:02,939
turn require more and more energy to

00:02:01,799 --> 00:02:05,159
make matters worse we're not fully

00:02:02,939 --> 00:02:06,600
utilizing our CPUs today across

00:02:05,159 --> 00:02:08,399
different data centers and clusters we

00:02:06,600 --> 00:02:10,979
see utilization numbers ranging from 10

00:02:08,399 --> 00:02:12,810
to 66% so wouldn't it be great if

00:02:10,979 --> 00:02:13,680
instead of buying more servers we could

00:02:12,810 --> 00:02:17,310
use our existing CP

00:02:13,680 --> 00:02:18,959
use more efficiently instead and when I

00:02:17,310 --> 00:02:20,129
say CPU efficiency what I mean is the

00:02:18,959 --> 00:02:21,870
fraction of cycles that are spent

00:02:20,129 --> 00:02:23,489
performing useful application level work

00:02:21,870 --> 00:02:26,099
as opposed to busy spinning or sitting

00:02:23,489 --> 00:02:27,689
idle and because of the scale at which

00:02:26,099 --> 00:02:29,730
these data center applications operate

00:02:27,689 --> 00:02:31,680
even a small increase in CPU utilization

00:02:29,730 --> 00:02:34,310
can save millions of dollars and

00:02:31,680 --> 00:02:34,310
terawatts of power

00:02:34,549 --> 00:02:38,040
unfortunately achieving high CPU

00:02:36,329 --> 00:02:39,420
efficiency is challenging and the reason

00:02:38,040 --> 00:02:41,730
for this is that data center workloads

00:02:39,420 --> 00:02:43,469
experience high variability in load so

00:02:41,730 --> 00:02:44,969
for example load can vary over daily

00:02:43,469 --> 00:02:47,010
time skills as you can see in this graph

00:02:44,969 --> 00:02:48,599
here but load can also vary over a much

00:02:47,010 --> 00:02:50,189
shorter time scale so we can have bursts

00:02:48,599 --> 00:02:52,200
of packet arrivals at microsecond time

00:02:50,189 --> 00:02:55,379
scale or threads that are spawned in

00:02:52,200 --> 00:02:56,669
bursts also at microsecond time scale so

00:02:55,379 --> 00:02:58,859
what this means is that peak load

00:02:56,669 --> 00:03:01,049
requires a lot more CPU resources than

00:02:58,859 --> 00:03:03,510
average load so for example if you run

00:03:01,049 --> 00:03:04,980
just one application on a server even if

00:03:03,510 --> 00:03:06,989
it uses the whole server at peak load

00:03:04,980 --> 00:03:11,730
you'll waste a significant amount of CPU

00:03:06,989 --> 00:03:13,469
resources as load varies over time as a

00:03:11,730 --> 00:03:15,540
result data center operators have turned

00:03:13,469 --> 00:03:17,159
to multiplexing in general there are two

00:03:15,540 --> 00:03:19,109
main classes of applications within data

00:03:17,159 --> 00:03:21,269
centers the first is user facing

00:03:19,109 --> 00:03:22,680
applications these tend to be latency

00:03:21,269 --> 00:03:24,209
sensitive and they have demand that

00:03:22,680 --> 00:03:26,639
varies over time in response to user

00:03:24,209 --> 00:03:27,930
demands the second main class of

00:03:26,639 --> 00:03:29,909
application is batch processing

00:03:27,930 --> 00:03:31,409
applications and these typically don't

00:03:29,909 --> 00:03:32,879
have a user who's waiting immediately

00:03:31,409 --> 00:03:34,620
for a response on the other end so we

00:03:32,879 --> 00:03:38,129
care less about latency and more about

00:03:34,620 --> 00:03:39,720
just achieving high throughput and today

00:03:38,129 --> 00:03:41,310
data center operators packed both types

00:03:39,720 --> 00:03:44,009
of applications on the same server in

00:03:41,310 --> 00:03:45,359
order to achieve high CPU efficiency so

00:03:44,009 --> 00:03:47,159
for example in the past they might have

00:03:45,359 --> 00:03:49,290
run latency sensitive applications such

00:03:47,159 --> 00:03:51,209
as a memcache D key value store on one

00:03:49,290 --> 00:03:52,439
set of servers and on another set of

00:03:51,209 --> 00:03:54,780
servers run their batch processing

00:03:52,439 --> 00:03:56,340
applications such as Hadoop but today

00:03:54,780 --> 00:03:57,870
what you would do is pack both of these

00:03:56,340 --> 00:03:58,799
applications on all of your servers and

00:03:57,870 --> 00:04:00,659
you might pack several other

00:03:58,799 --> 00:04:02,430
applications on there as well

00:04:00,659 --> 00:04:03,959
and this is done in practice today so

00:04:02,430 --> 00:04:08,310
for example Bing does this on over

00:04:03,959 --> 00:04:09,900
90,000 servers so how do existing

00:04:08,310 --> 00:04:12,329
systems perform in this sort of heavily

00:04:09,900 --> 00:04:13,620
multiplexed environment as an example

00:04:12,329 --> 00:04:15,930
let's look at the performance we can

00:04:13,620 --> 00:04:17,370
achieve with memcache G in this

00:04:15,930 --> 00:04:18,750
experiment we're going to have a client

00:04:17,370 --> 00:04:20,849
that sends requests to a server the

00:04:18,750 --> 00:04:22,109
server is running Memphis D it looks up

00:04:20,849 --> 00:04:23,880
a response which takes about a

00:04:22,109 --> 00:04:26,130
microsecond and then spends it sends it

00:04:23,880 --> 00:04:27,210
back to the client at the same time we

00:04:26,130 --> 00:04:29,280
also run a batch process

00:04:27,210 --> 00:04:30,960
application on the server to use any

00:04:29,280 --> 00:04:35,009
cycles that are not used by memcache D

00:04:30,960 --> 00:04:36,060
as memcache D load varies so what kind

00:04:35,009 --> 00:04:37,530
of performance would we hope to achieve

00:04:36,060 --> 00:04:39,030
on this graph I'm going to show the

00:04:37,530 --> 00:04:41,190
performance from memcache D so the

00:04:39,030 --> 00:04:43,650
x-axis shows the memcache D offered load

00:04:41,190 --> 00:04:46,470
and the y-axis shows the 99.9 percent

00:04:43,650 --> 00:04:47,759
I'll latency so let's suppose that the

00:04:46,470 --> 00:04:49,530
maximum throughput that we can achieve

00:04:47,759 --> 00:04:51,570
on our server from memcache D is about

00:04:49,530 --> 00:04:53,009
six million requests per second we would

00:04:51,570 --> 00:04:54,990
hope that the tail latency would remain

00:04:53,009 --> 00:04:56,039
low up until we approach this maximum

00:04:54,990 --> 00:04:59,639
throughput and then would increase

00:04:56,039 --> 00:05:00,780
dramatically at the same time we are

00:04:59,639 --> 00:05:02,520
also running the batch processing

00:05:00,780 --> 00:05:04,020
application on the server so we would

00:05:02,520 --> 00:05:06,330
expect that at peak memcache D

00:05:04,020 --> 00:05:07,680
throughput we have no cycles to run the

00:05:06,330 --> 00:05:09,300
batch processing application and achieve

00:05:07,680 --> 00:05:11,310
no batch throughput but we would hope

00:05:09,300 --> 00:05:12,840
that at lower memcache D offered loads

00:05:11,310 --> 00:05:14,639
we can linearly trade throughput for

00:05:12,840 --> 00:05:18,030
memcache D for throughput for this batch

00:05:14,639 --> 00:05:20,400
processing application so this is the

00:05:18,030 --> 00:05:22,050
results that we see if we run Linux in

00:05:20,400 --> 00:05:24,150
this environment we can see that Linux

00:05:22,050 --> 00:05:26,009
achieves pretty poor latency in this

00:05:24,150 --> 00:05:28,800
configuration especially if you consider

00:05:26,009 --> 00:05:30,060
that if you run only memcache D alone on

00:05:28,800 --> 00:05:31,590
Linux with no batch processing

00:05:30,060 --> 00:05:33,240
application you would have at a latency

00:05:31,590 --> 00:05:34,800
for around 50 microseconds in this

00:05:33,240 --> 00:05:36,389
setting so the presence of the batch

00:05:34,800 --> 00:05:37,740
processing application significantly

00:05:36,389 --> 00:05:41,370
degrades the performance for a memcache

00:05:37,740 --> 00:05:43,500
D here in addition with Linux we can't

00:05:41,370 --> 00:05:45,750
sustain this this latency for memcache D

00:05:43,500 --> 00:05:47,220
for very high throughput sat all but

00:05:45,750 --> 00:05:48,690
Linux is able to multiplex between

00:05:47,220 --> 00:05:50,099
different applications so we do achieve

00:05:48,690 --> 00:05:51,780
some throughput for the batch processing

00:05:50,099 --> 00:05:54,659
application as you can see in the Laura

00:05:51,780 --> 00:05:55,949
graph so now let's look at what happens

00:05:54,659 --> 00:05:57,990
if you use a state-of-the-art kernel

00:05:55,949 --> 00:06:00,449
bypass approach so one example of this

00:05:57,990 --> 00:06:02,430
is I goes so Sycho achieves much better

00:06:00,449 --> 00:06:04,530
performance for memcache D it maintains

00:06:02,430 --> 00:06:07,199
Lotte latency up to throughputs of over

00:06:04,530 --> 00:06:08,729
4 million requests per second however in

00:06:07,199 --> 00:06:10,470
order to achieve peak throughput for

00:06:08,729 --> 00:06:13,169
memcache D we must statically allocate

00:06:10,470 --> 00:06:14,460
our cores to running memcache D so this

00:06:13,169 --> 00:06:16,560
leaves no cores available to run the

00:06:14,460 --> 00:06:18,419
batch processing application and this

00:06:16,560 --> 00:06:20,039
means that at lower loads we're wasting

00:06:18,419 --> 00:06:22,440
a lot of CPU resources and achieving

00:06:20,039 --> 00:06:24,240
very poor efficiency so what we can see

00:06:22,440 --> 00:06:25,470
from this experiment is that Linux

00:06:24,240 --> 00:06:27,330
doesn't achieve good performance from

00:06:25,470 --> 00:06:28,770
memcache D and state-of-the-art kernel

00:06:27,330 --> 00:06:30,120
bypass approaches don't achieve good

00:06:28,770 --> 00:06:32,400
performance for batch processing

00:06:30,120 --> 00:06:33,990
applications so no existing approach is

00:06:32,400 --> 00:06:38,029
able to provide high network performance

00:06:33,990 --> 00:06:40,409
and high CPU efficiency simultaneously

00:06:38,029 --> 00:06:41,009
our goal is Chenango is to reconcile

00:06:40,409 --> 00:06:42,749
this trade-off

00:06:41,009 --> 00:06:44,789
between CPU efficiency and network

00:06:42,749 --> 00:06:46,169
performance and the way we hope to do

00:06:44,789 --> 00:06:47,849
this is by granting applications

00:06:46,169 --> 00:06:49,289
exclusive use of a set of course and

00:06:47,849 --> 00:06:51,809
then reallocating cores across

00:06:49,289 --> 00:06:54,349
applications at microsecond granularity

00:06:51,809 --> 00:06:56,490
so we do this every five microseconds

00:06:54,349 --> 00:06:58,770
now you might wonder if microsecond

00:06:56,490 --> 00:07:00,360
granularity is really necessary their

00:06:58,770 --> 00:07:02,339
existing systems that reallocate cores

00:07:00,360 --> 00:07:03,659
across applications every 50 to 100

00:07:02,339 --> 00:07:05,180
milliseconds so would one of these

00:07:03,659 --> 00:07:07,279
approaches be sufficient and

00:07:05,180 --> 00:07:09,509
unfortunately the answer is no

00:07:07,279 --> 00:07:11,339
intuitively if your tasks take only a

00:07:09,509 --> 00:07:13,289
few microseconds to complete you have

00:07:11,339 --> 00:07:15,149
burst in load that occur at microsecond

00:07:13,289 --> 00:07:17,279
time scale and you can only reallocate

00:07:15,149 --> 00:07:19,289
cores every 50 to 100 milliseconds you

00:07:17,279 --> 00:07:21,569
have to over provision cores in order to

00:07:19,289 --> 00:07:22,979
maintain low tail latency so with

00:07:21,569 --> 00:07:24,629
coarser granularities of Corbie

00:07:22,979 --> 00:07:30,029
allocations you must sacrifice either

00:07:24,629 --> 00:07:31,469
CPU efficiency or tail latency so what's

00:07:30,029 --> 00:07:33,569
difficult about reallocating course

00:07:31,469 --> 00:07:34,979
quickly one might naively think that you

00:07:33,569 --> 00:07:36,419
could just take an existing system the

00:07:34,979 --> 00:07:37,709
reallocate scores at millisecond

00:07:36,419 --> 00:07:39,029
granularity and just tune it to

00:07:37,709 --> 00:07:41,009
reallocate cores in microsecond

00:07:39,029 --> 00:07:42,569
granularity but unfortunately this

00:07:41,009 --> 00:07:43,860
doesn't work because existing approaches

00:07:42,569 --> 00:07:46,589
have failed to address two main

00:07:43,860 --> 00:07:48,959
challenges so first how many cores is an

00:07:46,589 --> 00:07:50,999
application need some existing

00:07:48,959 --> 00:07:52,830
approaches use application level metrics

00:07:50,999 --> 00:07:54,629
such as latency or throughput but these

00:07:52,830 --> 00:07:56,909
provide feedback only around every 100

00:07:54,629 --> 00:07:59,729
microseconds or so which is too slow for

00:07:56,909 --> 00:08:01,050
our purposes in addition there are

00:07:59,729 --> 00:08:02,669
multiple sources of load that need to be

00:08:01,050 --> 00:08:04,259
considered you can have packets that

00:08:02,669 --> 00:08:06,059
arrive over the network but applications

00:08:04,259 --> 00:08:07,860
can also spawn threads and both of these

00:08:06,059 --> 00:08:12,120
impact how many cores an application

00:08:07,860 --> 00:08:13,949
needs the second main channel challenge

00:08:12,120 --> 00:08:16,439
is maintaining low overheads quarry

00:08:13,949 --> 00:08:18,180
allocations so for example some prior

00:08:16,439 --> 00:08:19,889
approaches take hundreds of microseconds

00:08:18,180 --> 00:08:21,539
to reallocate a core because they

00:08:19,889 --> 00:08:23,909
reconfigure packets during rules in

00:08:21,539 --> 00:08:27,209
Hardware in the hardware NICs every time

00:08:23,909 --> 00:08:28,620
the core allocations change so

00:08:27,209 --> 00:08:33,089
unfortunately no existing system

00:08:28,620 --> 00:08:34,620
addresses these challenges Chenango

00:08:33,089 --> 00:08:37,019
overcomes both of these challenges with

00:08:34,620 --> 00:08:38,699
two main contributions the first is an

00:08:37,019 --> 00:08:40,860
efficient algorithm for determining when

00:08:38,699 --> 00:08:43,019
out when applications need more cores

00:08:40,860 --> 00:08:45,769
and this algorithm is based on the

00:08:43,019 --> 00:08:48,180
queuing delays of threads and of packets

00:08:45,769 --> 00:08:49,649
this algorithm requires fine-grained

00:08:48,180 --> 00:08:51,240
high frequency visibility into

00:08:49,649 --> 00:08:52,740
application threads and packet queues

00:08:51,240 --> 00:08:53,560
which is not available in existing

00:08:52,740 --> 00:08:55,149
systems

00:08:53,560 --> 00:08:56,889
so therefore Chenango makes a second

00:08:55,149 --> 00:08:59,079
contribution which is in to introduce

00:08:56,889 --> 00:09:01,029
the IO kernel a single busy spinning

00:08:59,079 --> 00:09:03,540
core which steers packets in software

00:09:01,029 --> 00:09:05,829
and allocates cords across applications

00:09:03,540 --> 00:09:07,420
because the IO kernel steers packets in

00:09:05,829 --> 00:09:09,310
software it can quickly reconfigure

00:09:07,420 --> 00:09:11,079
packet queues whenever core allocations

00:09:09,310 --> 00:09:12,610
change so the result is the core

00:09:11,079 --> 00:09:15,670
reallocations complete and around 5

00:09:12,610 --> 00:09:17,290
microseconds in addition to these two

00:09:15,670 --> 00:09:20,709
main contributions Chenango makes two

00:09:17,290 --> 00:09:23,290
other contributions so we introduced a

00:09:20,709 --> 00:09:24,939
core where cash a cache aware core

00:09:23,290 --> 00:09:26,949
selection algorithm which decides how to

00:09:24,939 --> 00:09:29,769
allocate cores to each application based

00:09:26,949 --> 00:09:31,420
on cache affinity and also an approach

00:09:29,769 --> 00:09:33,249
to load balancing which allows packet

00:09:31,420 --> 00:09:35,170
protocol handling to be load balanced

00:09:33,249 --> 00:09:37,149
across cores in addition to application

00:09:35,170 --> 00:09:38,769
level work so this enables better

00:09:37,149 --> 00:09:43,240
performance for unbalanced workloads

00:09:38,769 --> 00:09:44,670
such as those with few connections so

00:09:43,240 --> 00:09:46,720
let's talk more about Chenango x' design

00:09:44,670 --> 00:09:48,639
Chenango design consists of two main

00:09:46,720 --> 00:09:50,800
components the first is the runtime

00:09:48,639 --> 00:09:53,339
application logic runs in per

00:09:50,800 --> 00:09:55,209
application runtimes one per application

00:09:53,339 --> 00:09:56,709
applications link with the runtime is a

00:09:55,209 --> 00:09:58,389
library which provides useful

00:09:56,709 --> 00:10:00,790
programming abstractions such as threads

00:09:58,389 --> 00:10:03,850
mutexes condition variables and blocking

00:10:00,790 --> 00:10:05,829
sockets at any given time a runtime is

00:10:03,850 --> 00:10:08,170
is granted a specific number of course

00:10:05,829 --> 00:10:09,610
each cora has its own local run queue

00:10:08,170 --> 00:10:11,079
and application logic runs in

00:10:09,610 --> 00:10:13,899
light-weight user level threads which

00:10:11,079 --> 00:10:14,949
are placed into these run queues work is

00:10:13,899 --> 00:10:16,350
balanced across scores using

00:10:14,949 --> 00:10:18,699
work-stealing

00:10:16,350 --> 00:10:20,949
the second main component of Chenango is

00:10:18,699 --> 00:10:23,529
the i/o kernel the i/o kernel is a

00:10:20,949 --> 00:10:24,819
single busy spinning core it pulls and

00:10:23,529 --> 00:10:26,559
it queues so that applications don't

00:10:24,819 --> 00:10:28,839
have to and steers packets between these

00:10:26,559 --> 00:10:31,689
Hardware knit queues and per core packet

00:10:28,839 --> 00:10:33,339
queues in the run times in addition the

00:10:31,689 --> 00:10:34,689
i/o criminal tracks which cores are idle

00:10:33,339 --> 00:10:37,269
and how many cores have been allocated

00:10:34,689 --> 00:10:39,129
to each application and it orchestrate

00:10:37,269 --> 00:10:40,509
score reallocations by running the

00:10:39,129 --> 00:10:44,679
algorithm that determines when

00:10:40,509 --> 00:10:45,939
applications need more cores so how

00:10:44,679 --> 00:10:47,559
should the Iowa kernel decide how many

00:10:45,939 --> 00:10:49,809
cores to grant to each application at

00:10:47,559 --> 00:10:51,100
any given time there are two main ways

00:10:49,809 --> 00:10:53,470
that the i/o kernel grants an

00:10:51,100 --> 00:10:55,120
application and additional core the

00:10:53,470 --> 00:10:56,769
first is that if packets arrive for an

00:10:55,120 --> 00:10:58,629
application that currently has no cores

00:10:56,769 --> 00:11:01,269
granted to it we can immediately grant

00:10:58,629 --> 00:11:03,009
it a core and this is only possible

00:11:01,269 --> 00:11:04,899
because the i/o kernel is on the data

00:11:03,009 --> 00:11:05,940
path so it has visibility into packet

00:11:04,899 --> 00:11:07,800
arrivals

00:11:05,940 --> 00:11:09,630
the second way that we grant additional

00:11:07,800 --> 00:11:11,670
course to applications is that the Iowa

00:11:09,630 --> 00:11:13,440
kernel periodically runs an algorithm to

00:11:11,670 --> 00:11:15,480
check if applications would benefit from

00:11:13,440 --> 00:11:16,920
additional course and if this is the

00:11:15,480 --> 00:11:20,550
case it also grants them an additional

00:11:16,920 --> 00:11:22,320
core in either case granting a core to

00:11:20,550 --> 00:11:23,490
an application might require pre-empting

00:11:22,320 --> 00:11:26,250
a running core from a different

00:11:23,490 --> 00:11:27,990
application and when an applications

00:11:26,250 --> 00:11:30,660
have no work to occupy a core they yield

00:11:27,990 --> 00:11:33,230
them voluntarily so now let's talk more

00:11:30,660 --> 00:11:35,580
about how this periodic algorithm works

00:11:33,230 --> 00:11:37,230
to help us understand how many cores and

00:11:35,580 --> 00:11:38,580
applications meet an application needs

00:11:37,230 --> 00:11:40,530
we introduced an idea that we call

00:11:38,580 --> 00:11:41,910
compute congestion and this term is

00:11:40,530 --> 00:11:44,250
inspired by the notion of congestion and

00:11:41,910 --> 00:11:45,870
networking we say that an application

00:11:44,250 --> 00:11:47,760
suffers from compute congestion if

00:11:45,870 --> 00:11:49,110
granting it in an additional core would

00:11:47,760 --> 00:11:51,990
allow it to complete it to work more

00:11:49,110 --> 00:11:53,340
quickly so for example if we have an

00:11:51,990 --> 00:11:54,690
application that currently has two

00:11:53,340 --> 00:11:56,400
threads and is running on two cores

00:11:54,690 --> 00:11:57,780
which one with one thread on each core

00:11:56,400 --> 00:11:59,760
it's not suffering from compute

00:11:57,780 --> 00:12:00,840
congestion but if it were to spawn an

00:11:59,760 --> 00:12:02,280
additional thread it would now be

00:12:00,840 --> 00:12:03,750
suffering from compute congestion

00:12:02,280 --> 00:12:07,560
because this thread could be handled in

00:12:03,750 --> 00:12:09,210
parallel on a third core our goal with

00:12:07,560 --> 00:12:10,710
Chenango is to grant each application as

00:12:09,210 --> 00:12:13,260
few cores as possible while avoiding

00:12:10,710 --> 00:12:15,300
compute congestion this ensures that we

00:12:13,260 --> 00:12:17,160
can maintain Lotte latency while freeing

00:12:15,300 --> 00:12:19,200
up underused cores for use by other

00:12:17,160 --> 00:12:23,370
applications thereby achieving high CPU

00:12:19,200 --> 00:12:25,290
efficiency so how can we detect when

00:12:23,370 --> 00:12:26,910
compute congestion is occurring note

00:12:25,290 --> 00:12:28,140
that we have to do this efficiently we

00:12:26,910 --> 00:12:29,430
cannot afford to spend tens of

00:12:28,140 --> 00:12:32,070
microseconds determining if an

00:12:29,430 --> 00:12:33,450
application is congested so for this we

00:12:32,070 --> 00:12:36,030
introduced the compute congestion

00:12:33,450 --> 00:12:38,070
detection algorithm this algorithm

00:12:36,030 --> 00:12:40,470
considers two indications of queuing or

00:12:38,070 --> 00:12:41,910
sorry of congestion it consider is the

00:12:40,470 --> 00:12:44,790
queuing delay of threads and the queuing

00:12:41,910 --> 00:12:46,500
delay of packets the way it works is

00:12:44,790 --> 00:12:48,390
that it runs every five microseconds and

00:12:46,500 --> 00:12:50,370
every time it runs it checks each of the

00:12:48,390 --> 00:12:52,260
run queues within a run time and each of

00:12:50,370 --> 00:12:54,210
the incoming packet queues and it checks

00:12:52,260 --> 00:12:55,710
to see if any thread or any packet has

00:12:54,210 --> 00:12:57,630
remained queued since the last time we

00:12:55,710 --> 00:12:59,970
ran this algorithm five microseconds ago

00:12:57,630 --> 00:13:02,790
and if this is the case it grants the

00:12:59,970 --> 00:13:04,140
application an additional core and it

00:13:02,790 --> 00:13:05,760
turns out that we can actually check

00:13:04,140 --> 00:13:07,680
this very efficiently by implementing

00:13:05,760 --> 00:13:09,840
these queues as ring buffers so let's

00:13:07,680 --> 00:13:11,460
look at an example suppose that this is

00:13:09,840 --> 00:13:13,560
one of the incoming packet queues for

00:13:11,460 --> 00:13:15,200
this runtime the head pointer indicates

00:13:13,560 --> 00:13:17,370
where the i/o kernel will end queue

00:13:15,200 --> 00:13:19,030
incoming packets and the tail pointer

00:13:17,370 --> 00:13:20,980
indicates where the runtime will process

00:13:19,030 --> 00:13:22,270
packets from so suppose the queue looks

00:13:20,980 --> 00:13:24,370
like this one time we run the algorithm

00:13:22,270 --> 00:13:26,620
then over the next five microseconds

00:13:24,370 --> 00:13:28,720
perhaps some more packets arrive and the

00:13:26,620 --> 00:13:30,010
runtime processes some packets so the

00:13:28,720 --> 00:13:32,080
next time we run the algorithm the head

00:13:30,010 --> 00:13:33,700
and tail pointers have now moved and we

00:13:32,080 --> 00:13:35,170
can see by looking at this diagram that

00:13:33,700 --> 00:13:36,490
there are two packets that remain queued

00:13:35,170 --> 00:13:38,260
since the last time we ran the algorithm

00:13:36,490 --> 00:13:40,420
so this application is suffering from

00:13:38,260 --> 00:13:42,220
compute congestion and we can actually

00:13:40,420 --> 00:13:43,600
determine this quite efficiently by

00:13:42,220 --> 00:13:45,430
observing that the head pointer from the

00:13:43,600 --> 00:13:46,930
previous iteration is greater than the

00:13:45,430 --> 00:13:48,850
tail pointer from the current iteration

00:13:46,930 --> 00:13:51,580
indicating that congestion has occurred

00:13:48,850 --> 00:13:53,200
if instead the run time had processed

00:13:51,580 --> 00:13:55,000
two more packets so that the head and

00:13:53,200 --> 00:13:58,600
tail pointers were not equal we would

00:13:55,000 --> 00:14:00,040
see that congestion was not occurring so

00:13:58,600 --> 00:14:01,750
runtimes can expose these head and tail

00:14:00,040 --> 00:14:03,340
pointers to the IO kernel in a single

00:14:01,750 --> 00:14:05,440
cache line of shared memory per core

00:14:03,340 --> 00:14:07,000
this means that checking for compute

00:14:05,440 --> 00:14:08,380
congestion can be done efficiently and

00:14:07,000 --> 00:14:11,080
without an expensive synchronization

00:14:08,380 --> 00:14:12,700
costs so this contrasts with Linux today

00:14:11,080 --> 00:14:14,050
we're rebalancing threads across cores

00:14:12,700 --> 00:14:15,430
requires reading and potentially

00:14:14,050 --> 00:14:17,770
modifying data structures across

00:14:15,430 --> 00:14:19,210
different cores in the system which can

00:14:17,770 --> 00:14:22,450
lead to expensive cache misses and

00:14:19,210 --> 00:14:23,830
synchronization costs the two key

00:14:22,450 --> 00:14:25,870
features of this algorithm are that it

00:14:23,830 --> 00:14:27,430
considers both cued threads and cute

00:14:25,870 --> 00:14:28,840
packets as sources of congestion and

00:14:27,430 --> 00:14:31,300
then it's mechanisms are efficient and

00:14:28,840 --> 00:14:32,710
enough to run every few microseconds no

00:14:31,300 --> 00:14:33,880
existing system has either these

00:14:32,710 --> 00:14:38,320
features and these are what make this

00:14:33,880 --> 00:14:39,850
algorithm really effective so once we've

00:14:38,320 --> 00:14:42,070
decided to grant an application a core

00:14:39,850 --> 00:14:44,230
we must must decide which core to grant

00:14:42,070 --> 00:14:45,850
it for this we introduce a core

00:14:44,230 --> 00:14:48,670
selection algorithm that tries to choose

00:14:45,850 --> 00:14:50,290
the core with the best cache affinity so

00:14:48,670 --> 00:14:52,360
for example let's consider the CPU

00:14:50,290 --> 00:14:54,280
topology it has six physical cores which

00:14:52,360 --> 00:14:57,010
are shown in blue each with two hyper

00:14:54,280 --> 00:14:58,690
threads all the cores share the l3 cache

00:14:57,010 --> 00:15:02,320
and hyper threads on the same physical

00:14:58,690 --> 00:15:03,580
core share the l1 and l2 caches so

00:15:02,320 --> 00:15:05,290
suppose an application is currently

00:15:03,580 --> 00:15:07,000
using these three hyper threaded shown

00:15:05,290 --> 00:15:09,220
in black and we want to grant it an

00:15:07,000 --> 00:15:10,570
additional hyper thread different hyper

00:15:09,220 --> 00:15:13,960
threads will have better or worse cache

00:15:10,570 --> 00:15:16,300
affinity for this application so for

00:15:13,960 --> 00:15:17,920
example the hyper thread care of a

00:15:16,300 --> 00:15:19,600
currently running hyper thread will have

00:15:17,920 --> 00:15:21,940
the best cache affinity but there might

00:15:19,600 --> 00:15:23,170
be other cores or other hyper threads

00:15:21,940 --> 00:15:25,030
that this application has run on

00:15:23,170 --> 00:15:26,440
recently but also still have some state

00:15:25,030 --> 00:15:28,080
in their cache so they would also have

00:15:26,440 --> 00:15:30,550
fairly good cache affinity

00:15:28,080 --> 00:15:31,820
our core selection algorithm tries to

00:15:30,550 --> 00:15:33,470
allocate the hyper

00:15:31,820 --> 00:15:35,720
with the best cache affinity first and

00:15:33,470 --> 00:15:37,280
then we'll move on to colder - caches

00:15:35,720 --> 00:15:39,850
with colder two courses cold your caches

00:15:37,280 --> 00:15:42,290
if it can't allocate that hyper thread

00:15:39,850 --> 00:15:43,940
however it will always grant an idle

00:15:42,290 --> 00:15:44,930
core if possible because pre-empting a

00:15:43,940 --> 00:15:48,020
running core from a different

00:15:44,930 --> 00:15:49,550
application takes some time this

00:15:48,020 --> 00:15:51,230
algorithm is also quite efficient

00:15:49,550 --> 00:15:52,790
because the IO kernel contract locally

00:15:51,230 --> 00:15:56,740
which cores each application is running

00:15:52,790 --> 00:15:56,740
on and which cores it is run on recently

00:15:57,280 --> 00:16:01,370
so now I'll describe one feature of

00:15:59,240 --> 00:16:03,290
shanaine gos runtime the runtime

00:16:01,370 --> 00:16:04,850
provides useful programming abstractions

00:16:03,290 --> 00:16:08,540
such as threading blocking sockets

00:16:04,850 --> 00:16:10,220
timers and mutexes Chenango runtimes

00:16:08,540 --> 00:16:13,000
also perform all Network protocol

00:16:10,220 --> 00:16:15,650
handling such as TCP or UDP processing

00:16:13,000 --> 00:16:17,990
within an application the IR kernel

00:16:15,650 --> 00:16:20,090
steers raw packets to a specific core

00:16:17,990 --> 00:16:22,330
based on an RSS hash and the runtime

00:16:20,090 --> 00:16:24,560
performs the packet processing in

00:16:22,330 --> 00:16:26,360
addition our runtime includes a unique

00:16:24,560 --> 00:16:27,830
feature in addition to allowing the

00:16:26,360 --> 00:16:29,480
work-stealing of threads across cores

00:16:27,830 --> 00:16:32,240
our runtime also allows batches of

00:16:29,480 --> 00:16:35,390
packets to be still to be work stolen

00:16:32,240 --> 00:16:36,680
across cores within an application so

00:16:35,390 --> 00:16:39,380
this means that protocol handling work

00:16:36,680 --> 00:16:41,150
such as TCP processing can be can also

00:16:39,380 --> 00:16:42,770
be load balanced across cores instead of

00:16:41,150 --> 00:16:45,440
being required to be performed on the

00:16:42,770 --> 00:16:46,580
cord which a packet arrives at so this

00:16:45,440 --> 00:16:48,140
yields better performance for in

00:16:46,580 --> 00:16:51,620
balanced workloads such as those with a

00:16:48,140 --> 00:16:53,300
very small number of connections one

00:16:51,620 --> 00:16:54,590
consequence of this work-stealing is

00:16:53,300 --> 00:16:56,930
that packets can arrive at the network

00:16:54,590 --> 00:16:58,850
stack out of order this can happen due

00:16:56,930 --> 00:17:01,490
to work stealing or also as a result of

00:16:58,850 --> 00:17:02,660
changes in core allocations so therefore

00:17:01,490 --> 00:17:04,310
Chenango includes a lightweight

00:17:02,660 --> 00:17:06,470
mechanism for resequencing packets

00:17:04,310 --> 00:17:07,640
before passing them up the TCP stack so

00:17:06,470 --> 00:17:09,439
that they are generally processed in

00:17:07,640 --> 00:17:15,050
order and the TCP dynamics are not

00:17:09,439 --> 00:17:16,850
impacted we've implemented Chenango the

00:17:15,050 --> 00:17:19,660
i/o kernel uses DP DK for low latency

00:17:16,850 --> 00:17:22,130
access to Nick queues from user space

00:17:19,660 --> 00:17:24,770
our runtime includes implementations of

00:17:22,130 --> 00:17:27,079
UDP and TCP and bindings for C++ and

00:17:24,770 --> 00:17:28,490
rust in total or our system is about

00:17:27,079 --> 00:17:33,350
13,000 lines of code

00:17:28,490 --> 00:17:36,170
most of which is C in our evaluation we

00:17:33,350 --> 00:17:37,910
focus on three main questions first how

00:17:36,170 --> 00:17:39,830
well dishing Chenango reconciled the

00:17:37,910 --> 00:17:42,470
trade-off between cpu efficiency and

00:17:39,830 --> 00:17:44,000
network performance second how does

00:17:42,470 --> 00:17:44,990
Chenango respond to sudden bursts in

00:17:44,000 --> 00:17:46,850
load

00:17:44,990 --> 00:17:50,090
and finally how well dition and go

00:17:46,850 --> 00:17:52,429
preserve cash affinity for our

00:17:50,090 --> 00:17:54,470
experiments we use one server and six

00:17:52,429 --> 00:17:57,260
clients and all of them run 10 gigabit

00:17:54,470 --> 00:17:58,880
per second Knicks clients run our own

00:17:57,260 --> 00:18:01,280
open-loop low generator which is built

00:17:58,880 --> 00:18:04,400
on top of Chenango request follow

00:18:01,280 --> 00:18:06,080
Poisson arrivals and use TCP then we

00:18:04,400 --> 00:18:08,450
evaluate four different systems so first

00:18:06,080 --> 00:18:10,340
we evaluate Linux which rebalances tasks

00:18:08,450 --> 00:18:13,340
across cores at a granularity of 4

00:18:10,340 --> 00:18:14,809
milliseconds next we evaluate die ghost

00:18:13,340 --> 00:18:16,880
which is a state-of-the-art kernel

00:18:14,809 --> 00:18:18,590
bypass networking system which provides

00:18:16,880 --> 00:18:20,690
no support for lightweight threading and

00:18:18,590 --> 00:18:23,809
no mechanisms for reallocating cores

00:18:20,690 --> 00:18:25,610
across applications third we evaluate

00:18:23,809 --> 00:18:28,309
Arachne which is a state-of-the-art user

00:18:25,610 --> 00:18:29,540
level threading system which we allocate

00:18:28,309 --> 00:18:31,880
scores across applications at a

00:18:29,540 --> 00:18:33,740
granularity of 50 milliseconds however

00:18:31,880 --> 00:18:36,559
Arachne also does not integrate with

00:18:33,740 --> 00:18:38,420
kernel bypass networking and finally we

00:18:36,559 --> 00:18:39,950
evaluate Chenango our own system with

00:18:38,420 --> 00:18:41,450
which integrates with kernel bypass

00:18:39,950 --> 00:18:42,980
networking provide support for

00:18:41,450 --> 00:18:44,540
lightweight threading and reallocate

00:18:42,980 --> 00:18:48,679
scores across applications every 5

00:18:44,540 --> 00:18:50,059
microseconds so let's revisit the

00:18:48,679 --> 00:18:52,309
memcache D experiment that we looked at

00:18:50,059 --> 00:18:53,540
earlier in this talk to refresh your

00:18:52,309 --> 00:18:54,770
memory in this experiment we had a

00:18:53,540 --> 00:18:56,570
client that's sending requests to a

00:18:54,770 --> 00:18:57,950
server the server is running memcache D

00:18:56,570 --> 00:18:59,960
and sends a response back to the client

00:18:57,950 --> 00:19:01,400
and we also run a batch processing

00:18:59,960 --> 00:19:04,100
application on the server to use any

00:19:01,400 --> 00:19:05,780
cycles not used by memcache D so we saw

00:19:04,100 --> 00:19:07,370
that Linux achieved poor performance for

00:19:05,780 --> 00:19:08,809
memcache D but did achieved throughput

00:19:07,370 --> 00:19:11,059
for the batch processing application

00:19:08,809 --> 00:19:12,500
well as I ghost the state the state of

00:19:11,059 --> 00:19:14,540
the art kernel bypass approach achieve

00:19:12,500 --> 00:19:15,710
good performance for memcache G but no

00:19:14,540 --> 00:19:18,980
throughput for the batch processing

00:19:15,710 --> 00:19:20,480
application if we add Arachne to this

00:19:18,980 --> 00:19:22,820
graph we can just see we can see that

00:19:20,480 --> 00:19:25,580
Arachne outperforms Linux it maintains

00:19:22,820 --> 00:19:27,350
Lotte latency of around 100 microseconds

00:19:25,580 --> 00:19:29,660
up to throughputs of around a million

00:19:27,350 --> 00:19:31,160
requests per second and at the same time

00:19:29,660 --> 00:19:32,840
Arachne is able to adjust core

00:19:31,160 --> 00:19:34,010
allocations across applications so it

00:19:32,840 --> 00:19:37,340
does achieve some throughput for the

00:19:34,010 --> 00:19:39,230
batch processing application if we look

00:19:37,340 --> 00:19:40,970
at how Chenango performs we can see that

00:19:39,230 --> 00:19:43,250
from Memphis G it maintains low tail

00:19:40,970 --> 00:19:44,390
latency similar to that as I goes up to

00:19:43,250 --> 00:19:46,940
a throughput of over five million

00:19:44,390 --> 00:19:49,070
requests per second at the same time

00:19:46,940 --> 00:19:50,570
Chenango was able to achieve better

00:19:49,070 --> 00:19:51,830
throughput for the batch processing

00:19:50,570 --> 00:19:55,100
application than any of the other

00:19:51,830 --> 00:19:56,630
systems that we evaluated so what we can

00:19:55,100 --> 00:19:58,370
see here is that Chenango is able to

00:19:56,630 --> 00:19:59,809
achieve the tail latency of

00:19:58,370 --> 00:20:02,510
state-of-the-art Colonel bypass approach

00:19:59,809 --> 00:20:04,550
while also fully utilizing the CPU for

00:20:02,510 --> 00:20:07,580
productive work thereby achieving high

00:20:04,550 --> 00:20:08,930
CPU efficiency and there are a couple of

00:20:07,580 --> 00:20:11,780
interesting things to note about these

00:20:08,930 --> 00:20:13,850
graphs so first if we compare the tail

00:20:11,780 --> 00:20:15,350
latency of Chenango and I goes to those

00:20:13,850 --> 00:20:16,850
of Linux and Arachne we can see the

00:20:15,350 --> 00:20:19,190
benefits of using kernel bypass

00:20:16,850 --> 00:20:20,990
networking and it's only possible for

00:20:19,190 --> 00:20:22,550
Chenango to use kernel bypass networking

00:20:20,990 --> 00:20:24,950
while also reallocating cores across

00:20:22,550 --> 00:20:26,450
applications this quickly because the

00:20:24,950 --> 00:20:28,100
i/o kernel can reconfigure packet

00:20:26,450 --> 00:20:31,880
steering rules in software when core

00:20:28,100 --> 00:20:33,650
allocations change at the same time

00:20:31,880 --> 00:20:35,179
having a single chord that forwards all

00:20:33,650 --> 00:20:37,370
the packets in the system can eventually

00:20:35,179 --> 00:20:38,690
become a bottleneck so in this

00:20:37,370 --> 00:20:40,820
experiment the Iowa kernel becomes

00:20:38,690 --> 00:20:42,770
saturated at around 5.5 million requests

00:20:40,820 --> 00:20:44,330
per second for memcache D preventing

00:20:42,770 --> 00:20:45,080
Chenango from supporting higher memcache

00:20:44,330 --> 00:20:47,030
D throughputs

00:20:45,080 --> 00:20:48,890
and this is because of the short one

00:20:47,030 --> 00:20:51,050
microsecond service times of memcache D

00:20:48,890 --> 00:20:54,590
with longer service times the IO kernel

00:20:51,050 --> 00:20:56,000
does not limit throughput and finally

00:20:54,590 --> 00:20:57,530
Chenango achieves higher throughput for

00:20:56,000 --> 00:20:59,150
the batch processing application than

00:20:57,530 --> 00:21:01,190
any of the other systems we evaluated

00:20:59,150 --> 00:21:03,080
and the reason for this is that Shengo

00:21:01,190 --> 00:21:04,520
reallocate scores across applications so

00:21:03,080 --> 00:21:06,320
quickly that it doesn't need to over

00:21:04,520 --> 00:21:08,179
provision cores from memcache D in order

00:21:06,320 --> 00:21:09,650
to maintain low to latency and this

00:21:08,179 --> 00:21:16,070
frees up more cycles to be used by the

00:21:09,650 --> 00:21:17,360
batch processing application okay so in

00:21:16,070 --> 00:21:19,429
the previous experiment each data point

00:21:17,360 --> 00:21:20,929
represented a constant fixed load but

00:21:19,429 --> 00:21:23,450
what happens if we suddenly change the

00:21:20,929 --> 00:21:25,520
load in this experiment we have a client

00:21:23,450 --> 00:21:27,860
that sends tcp tcp request to a server

00:21:25,520 --> 00:21:29,330
the server performs 1 microsecond of

00:21:27,860 --> 00:21:30,770
synthetic work and then responds to the

00:21:29,330 --> 00:21:33,020
client and we also run a batch

00:21:30,770 --> 00:21:33,800
processing application and in this

00:21:33,020 --> 00:21:35,480
experiment we're going to

00:21:33,800 --> 00:21:38,090
instantaneously change the load every

00:21:35,480 --> 00:21:39,290
one microsecond so this graph shows the

00:21:38,090 --> 00:21:41,090
load that we're going to offer over the

00:21:39,290 --> 00:21:42,559
course of the experiment we begin by

00:21:41,090 --> 00:21:44,690
offering a baseline rate of a hundred

00:21:42,559 --> 00:21:47,030
thousand requests per second after a

00:21:44,690 --> 00:21:48,679
second at this rate we increase the rate

00:21:47,030 --> 00:21:50,120
to an elevated rate we maintain the

00:21:48,679 --> 00:21:51,950
elevated rate for one second and then

00:21:50,120 --> 00:21:53,330
decrease back to the baseline rate and

00:21:51,950 --> 00:21:54,920
we repeat this process for several

00:21:53,330 --> 00:21:57,890
different elevated rates up to five

00:21:54,920 --> 00:21:59,510
million requests per second so if we

00:21:57,890 --> 00:22:01,220
look at how Arachne performs we can see

00:21:59,510 --> 00:22:03,140
that every time we increase the rate or

00:22:01,220 --> 00:22:04,880
acnes tail latency spikes to over a

00:22:03,140 --> 00:22:06,200
millisecond and it takes it hundreds of

00:22:04,880 --> 00:22:08,570
milliseconds to recover from these

00:22:06,200 --> 00:22:09,920
spikes an Arachne can only maintain this

00:22:08,570 --> 00:22:12,410
load to up to a million requests

00:22:09,920 --> 00:22:14,150
for a second if we look at how Chenango

00:22:12,410 --> 00:22:15,980
performs we can see that Chenango

00:22:14,150 --> 00:22:17,510
maintains Lotte latency across all these

00:22:15,980 --> 00:22:18,950
changes in loads even when we

00:22:17,510 --> 00:22:20,360
drastically increased the load from a

00:22:18,950 --> 00:22:23,120
hundred thousand requests per second to

00:22:20,360 --> 00:22:24,230
five million requests per second and the

00:22:23,120 --> 00:22:25,460
reason for this is that Chenango

00:22:24,230 --> 00:22:27,920
reallocate scores across applications

00:22:25,460 --> 00:22:29,570
ten thousand times as often as Arachne

00:22:27,920 --> 00:22:31,160
allowing it to react quickly to changes

00:22:29,570 --> 00:22:35,480
in load before any queuing built up in

00:22:31,160 --> 00:22:37,070
the system so now I'm going to show how

00:22:35,480 --> 00:22:39,140
a mingoes core selection algorithm for

00:22:37,070 --> 00:22:40,550
service cache affinity for this

00:22:39,140 --> 00:22:42,500
experiment we have a client that sends

00:22:40,550 --> 00:22:44,120
request to a server the server performs

00:22:42,500 --> 00:22:45,680
some synthetic work with a mean of 10

00:22:44,120 --> 00:22:48,620
microseconds and then responds to the

00:22:45,680 --> 00:22:50,330
client I'm going to show an execution

00:22:48,620 --> 00:22:52,640
trace of which core handles each request

00:22:50,330 --> 00:22:54,890
so we'll see on the y-axis the CPU

00:22:52,640 --> 00:22:56,180
number and x-axis will show time which

00:22:54,890 --> 00:22:59,270
is a thousand times slower than

00:22:56,180 --> 00:23:07,700
real-time so let's start by looking at

00:22:59,270 --> 00:23:09,050
how Linux performs so again the y-axis

00:23:07,700 --> 00:23:10,730
here shows which cores handling the

00:23:09,050 --> 00:23:12,560
requests in each rectangle indicates a

00:23:10,730 --> 00:23:14,090
request you can see that in Linux the

00:23:12,560 --> 00:23:15,380
requests are handled across basically

00:23:14,090 --> 00:23:16,640
all the different cores in the system

00:23:15,380 --> 00:23:18,530
and over the course of this

00:23:16,640 --> 00:23:20,150
visualization the load is increasing so

00:23:18,530 --> 00:23:21,710
towards the end of this visual agent you

00:23:20,150 --> 00:23:23,990
can see that basically all the cores are

00:23:21,710 --> 00:23:25,370
getting hit by requests so if you have

00:23:23,990 --> 00:23:27,380
some state that's shared across these

00:23:25,370 --> 00:23:29,480
different requests you're incurring a

00:23:27,380 --> 00:23:36,200
lot of cache misses trying to handle all

00:23:29,480 --> 00:23:38,870
of these so now let's look at how Ango

00:23:36,200 --> 00:23:40,280
performs we can see that even though

00:23:38,870 --> 00:23:41,930
Chenango is reallocating courts across

00:23:40,280 --> 00:23:43,730
applications very quickly it tends to

00:23:41,930 --> 00:23:45,770
reallocate the same cores over and over

00:23:43,730 --> 00:23:47,990
again so if you have state that shared

00:23:45,770 --> 00:23:49,940
across requests it's generally only used

00:23:47,990 --> 00:23:51,200
on a couple of different cores and as

00:23:49,940 --> 00:23:53,000
the load increases over the course of

00:23:51,200 --> 00:23:54,500
the experiment we're still concentrating

00:23:53,000 --> 00:23:56,120
our requests on a small number of cores

00:23:54,500 --> 00:23:57,800
so there are a lot of cores that are

00:23:56,120 --> 00:24:00,010
left completely idle to be used by other

00:23:57,800 --> 00:24:00,010
applications

00:24:12,480 --> 00:24:17,140
so to conclude Chenango is a system that

00:24:15,190 --> 00:24:20,050
reconciles this trade-off between Lotte

00:24:17,140 --> 00:24:21,070
latency and high CPU efficiency and the

00:24:20,050 --> 00:24:22,810
way that it does this is that it

00:24:21,070 --> 00:24:24,550
reallocate scores across applications at

00:24:22,810 --> 00:24:27,040
microsecond granularity so every five

00:24:24,550 --> 00:24:28,900
microseconds and this is possible

00:24:27,040 --> 00:24:30,280
because of two main contributions first

00:24:28,900 --> 00:24:32,290
an efficient congestion detection

00:24:30,280 --> 00:24:34,150
algorithm and second a component called

00:24:32,290 --> 00:24:35,770
the IO kernel which is a single busy

00:24:34,150 --> 00:24:37,570
spinning core that allocates cores

00:24:35,770 --> 00:24:40,450
across applications and steers packets

00:24:37,570 --> 00:24:41,860
and software the code for our system and

00:24:40,450 --> 00:24:44,140
for running all of our experiments is

00:24:41,860 --> 00:24:59,560
available on github thank you and I'm

00:24:44,140 --> 00:25:01,060
happy to take questions so I'm a little

00:24:59,560 --> 00:25:03,250
concerned that this is following it

00:25:01,060 --> 00:25:07,960
falling into a common trap that we get

00:25:03,250 --> 00:25:10,630
from kernel bypass in that they will run

00:25:07,960 --> 00:25:12,310
a kernel bypass it's not just you so

00:25:10,630 --> 00:25:15,190
they run a kernel bypass and then they

00:25:12,310 --> 00:25:15,910
compare that to live I don't know what

00:25:15,190 --> 00:25:18,700
that means

00:25:15,910 --> 00:25:20,710
Linux is a general-purpose OS it has

00:25:18,700 --> 00:25:23,530
many different schedulers it has many

00:25:20,710 --> 00:25:26,380
different ways to steer packets I don't

00:25:23,530 --> 00:25:29,110
know how much effort was put into

00:25:26,380 --> 00:25:30,670
optimizing Linux for this particular

00:25:29,110 --> 00:25:32,050
workload because you're comparing this

00:25:30,670 --> 00:25:35,080
against something that is basically

00:25:32,050 --> 00:25:37,690
optimized for very specific workloads so

00:25:35,080 --> 00:25:41,290
in order to a fair comparison we really

00:25:37,690 --> 00:25:42,760
need to see what the difference is why

00:25:41,290 --> 00:25:44,740
why is this better

00:25:42,760 --> 00:25:47,290
so Linux has an immense number of

00:25:44,740 --> 00:25:48,870
schedulers and anyone who's worked in a

00:25:47,290 --> 00:25:51,340
data center on linux knows that

00:25:48,870 --> 00:25:52,870
scheduling is one of the priorities we

00:25:51,340 --> 00:25:54,580
need to schedule for batch we need to

00:25:52,870 --> 00:25:57,910
schedule for latency yes they need to be

00:25:54,580 --> 00:26:00,820
combined in the same system we've done a

00:25:57,910 --> 00:26:03,160
lot of work there and I can't tell how

00:26:00,820 --> 00:26:06,940
much of that's been applied here so the

00:26:03,160 --> 00:26:09,550
comparison against Linux I can't derive

00:26:06,940 --> 00:26:11,470
any conclusions from that that being

00:26:09,550 --> 00:26:12,950
said I am interested in one thing which

00:26:11,470 --> 00:26:16,820
is this idea of

00:26:12,950 --> 00:26:19,850
high frequency poor allocation I don't

00:26:16,820 --> 00:26:21,470
know if we have anything like that in in

00:26:19,850 --> 00:26:23,780
the Linux it might be worth it look at

00:26:21,470 --> 00:26:26,000
the schedulers I think there's gonna be

00:26:23,780 --> 00:26:28,700
a lot of issues with that overheads and

00:26:26,000 --> 00:26:30,950
certainly can't bounce applications

00:26:28,700 --> 00:26:32,110
between caches would be insane so you've

00:26:30,950 --> 00:26:35,060
obviously solve some of those problems

00:26:32,110 --> 00:26:38,330
so it might be interesting to see if

00:26:35,060 --> 00:26:39,680
some of this is applicable to some of

00:26:38,330 --> 00:26:41,330
that after all this is the technical

00:26:39,680 --> 00:26:43,340
Linux conference anyway so we always

00:26:41,330 --> 00:26:51,830
want to know how can we take stuff like

00:26:43,340 --> 00:26:53,780
this and apply productively yeah I think

00:26:51,830 --> 00:26:54,770
we definitely would be really interested

00:26:53,780 --> 00:26:57,500
in trying to apply some of these ideas

00:26:54,770 --> 00:26:59,180
till Thanks yeah so I would love to talk

00:26:57,500 --> 00:27:01,550
to people who have opinions about that

00:26:59,180 --> 00:27:03,620
and to address your first point I agree

00:27:01,550 --> 00:27:04,940
that evaluating things on Linux is

00:27:03,620 --> 00:27:07,010
really tricky because there are a lot of

00:27:04,940 --> 00:27:08,690
different ways you can configure it we

00:27:07,010 --> 00:27:09,680
did it we did invest substantial time

00:27:08,690 --> 00:27:11,150
and trying out a lot of different

00:27:09,680 --> 00:27:13,370
configurations so we really tried to

00:27:11,150 --> 00:27:14,270
configure it as best we could it's very

00:27:13,370 --> 00:27:17,930
possible if there's a better

00:27:14,270 --> 00:27:19,880
configuration for that there's a there's

00:27:17,930 --> 00:27:21,980
a simple note to be made here right

00:27:19,880 --> 00:27:24,230
which is all of the state-of-the-art

00:27:21,980 --> 00:27:26,270
kernel bypass technologies are deployed

00:27:24,230 --> 00:27:27,890
in almost zero places so it and the

00:27:26,270 --> 00:27:29,060
nexus deployed everywhere and there's a

00:27:27,890 --> 00:27:32,200
reason because people have figured out

00:27:29,060 --> 00:27:34,520
how to make it work this question yes I

00:27:32,200 --> 00:27:35,660
you started it off with the problem you

00:27:34,520 --> 00:27:38,930
were solving which I thought was really

00:27:35,660 --> 00:27:40,690
good but have we asked is you know so

00:27:38,930 --> 00:27:43,520
we're sort of looking at like a micro

00:27:40,690 --> 00:27:45,890
orchestration of cores right and the

00:27:43,520 --> 00:27:48,470
reason is maybe because we failed at the

00:27:45,890 --> 00:27:50,450
macro orchestration you know like you're

00:27:48,470 --> 00:27:53,060
saying being combines all these things

00:27:50,450 --> 00:27:54,830
could we approach it from solving the

00:27:53,060 --> 00:27:57,290
bigger problem of just trying to put

00:27:54,830 --> 00:27:58,940
things on systems and hardware that you

00:27:57,290 --> 00:28:02,510
know the way they should be running like

00:27:58,940 --> 00:28:04,070
memcache dm1 and you know I do plan on a

00:28:02,510 --> 00:28:05,360
different system like you know sort of

00:28:04,070 --> 00:28:08,000
coming in from the other way I think

00:28:05,360 --> 00:28:09,500
this is still useful but I mean if we're

00:28:08,000 --> 00:28:11,090
not doing the work there too that we

00:28:09,500 --> 00:28:12,530
need to do I think the problem with that

00:28:11,090 --> 00:28:14,000
is just that since there's so much

00:28:12,530 --> 00:28:15,980
burstiness in these different workloads

00:28:14,000 --> 00:28:19,280
that we see in datacenters it's hard to

00:28:15,980 --> 00:28:21,530
like perfectly provision things so if

00:28:19,280 --> 00:28:23,300
you could you know provision like by

00:28:21,530 --> 00:28:25,430
fractional CPUs then you wouldn't have

00:28:23,300 --> 00:28:26,720
this problem but if you have to

00:28:25,430 --> 00:28:27,740
provision by a whole machine

00:28:26,720 --> 00:28:29,539
then you're going to have to run

00:28:27,740 --> 00:28:30,890
multiple applications on the machine in

00:28:29,539 --> 00:28:35,720
order to make sure you're still using it

00:28:30,890 --> 00:28:37,340
as the load changes over time quick

00:28:35,720 --> 00:28:38,929
question how much of the win of your

00:28:37,340 --> 00:28:40,610
system comes from the charters to get to

00:28:38,929 --> 00:28:41,289
their quanta versus the smarter core

00:28:40,610 --> 00:28:45,320
scheduling

00:28:41,289 --> 00:28:46,190
specifically cache or scheduling that's

00:28:45,320 --> 00:28:48,440
a good question

00:28:46,190 --> 00:28:50,210
which we haven't concretely evaluated

00:28:48,440 --> 00:28:53,330
but I think I would say like the vast

00:28:50,210 --> 00:29:00,350
majority of it is from the shorter time

00:28:53,330 --> 00:29:02,600
schedule the time quanta so add one

00:29:00,350 --> 00:29:05,659
additional comment so since you're

00:29:02,600 --> 00:29:07,490
running there's a 10 gig it is I think

00:29:05,659 --> 00:29:09,260
you will find that the Linux kernel will

00:29:07,490 --> 00:29:11,630
do a lot better if you start running at

00:29:09,260 --> 00:29:14,570
much higher throughput and you have to

00:29:11,630 --> 00:29:16,640
now do more than 5 6 million operations

00:29:14,570 --> 00:29:18,440
per second on your IO kernel and you

00:29:16,640 --> 00:29:20,480
have to load balanced that guy and

00:29:18,440 --> 00:29:22,429
you're going to have to be numa aware

00:29:20,480 --> 00:29:23,960
and all the problems that you have to

00:29:22,429 --> 00:29:25,789
have a locality will need to get address

00:29:23,960 --> 00:29:27,440
so it would be interesting to see what

00:29:25,789 --> 00:29:29,539
these what the results look like if

00:29:27,440 --> 00:29:33,110
you're running at like a 40 gig or a 100

00:29:29,539 --> 00:29:35,299
picnic and much wider load not two or

00:29:33,110 --> 00:29:37,580
three threads but maybe 20 30 threads

00:29:35,299 --> 00:29:41,570
hitting the same thing and have you guys

00:29:37,580 --> 00:29:43,190
run so most of our experiments were

00:29:41,570 --> 00:29:44,299
conducted on 10k bit per second Nix

00:29:43,190 --> 00:29:46,970
because that's what we had available to

00:29:44,299 --> 00:29:48,500
us but we recently got some 40 genic so

00:29:46,970 --> 00:29:49,640
we're starting to look into this we're

00:29:48,500 --> 00:29:53,140
very interesting to see what those

00:29:49,640 --> 00:30:00,640
results look like any last question

00:29:53,140 --> 00:30:00,640
thank you sorry sorry I didn't

00:30:08,280 --> 00:30:14,680
hi and congratulations

00:30:11,650 --> 00:30:20,710
I'm very impressed by the work you did I

00:30:14,680 --> 00:30:25,780
have one sort of a question would it be

00:30:20,710 --> 00:30:28,660
useful for you if you could identify the

00:30:25,780 --> 00:30:29,890
flaws that are all the connections that

00:30:28,660 --> 00:30:33,820
are associated with a particular

00:30:29,890 --> 00:30:37,270
application and then not share the cues

00:30:33,820 --> 00:30:42,900
over there but just you know assign them

00:30:37,270 --> 00:30:42,900
their own individual set of cues okay

00:30:43,110 --> 00:30:47,920
you mean assign them their own

00:30:45,160 --> 00:30:49,240
individual Hardware cues yes yeah I

00:30:47,920 --> 00:30:52,360
think I think there are a lot of

00:30:49,240 --> 00:30:56,620
features of Nyx that could make this

00:30:52,360 --> 00:30:59,770
sort of like steering a lot easier I can

00:30:56,620 --> 00:31:01,360
show you how to at least configure some

00:30:59,770 --> 00:31:04,650
of the Intel NYX if you're using them

00:31:01,360 --> 00:31:04,650
okay yeah that would be great

00:31:08,290 --> 00:31:11,540

YouTube URL: https://www.youtube.com/watch?v=INA-ICPAsXk


