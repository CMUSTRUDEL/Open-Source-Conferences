Title: Netdev 0x13 - NVMe over TCP IP
Publication date: 2019-05-25
Playlist: Netdev 0x13 - Day 2
Description: 
	Roy Shterman goes over the linux NVMe over TCP implementation

NVMe is hot! Imagine writing to storage and not having to twiddle your thumbs
while waiting for a write to complete.
NVMe over Fabrics (NVMe-OF) is changing how we think about remote storage.
Using TCP as a transport alternative to RDMA or FC brings forward an interesting
perspective in relation to the networking stack.

More info:
https://www.netdevconf.org/0x13/session.html?nvme-over-tcpip
Captions: 
	00:00:00,000 --> 00:00:10,800
hello again I'm I'm Roy Sherman from

00:00:06,029 --> 00:00:15,089
light beets labs and I'm going to talk

00:00:10,800 --> 00:00:17,430
today about nvme over TCP I'm going to

00:00:15,089 --> 00:00:19,080
speak in general about nvme over fabrics

00:00:17,430 --> 00:00:23,789
and what we've done in the last few

00:00:19,080 --> 00:00:26,720
years in the community and then I'm

00:00:23,789 --> 00:00:31,080
going to present the new cool protocol

00:00:26,720 --> 00:00:35,100
which is over tcp/ip we'll talk a little

00:00:31,080 --> 00:00:37,170
bit about the future work that we see

00:00:35,100 --> 00:00:40,680
that we need to implement as part of the

00:00:37,170 --> 00:00:43,649
protocol and we will discuss the

00:00:40,680 --> 00:00:46,230
performance comparison between nvme or

00:00:43,649 --> 00:00:50,219
TCP versus different storage protocols

00:00:46,230 --> 00:00:56,250
that seems to be the competitors of

00:00:50,219 --> 00:01:01,140
engineering TCP so few years ago we got

00:00:56,250 --> 00:01:04,129
those new NVA controllers which let us

00:01:01,140 --> 00:01:07,049
the opportunity to to ran application

00:01:04,129 --> 00:01:10,250
intensive i/o application locally on a

00:01:07,049 --> 00:01:14,220
direct attached storage device with high

00:01:10,250 --> 00:01:16,830
very high performance versus the versus

00:01:14,220 --> 00:01:21,090
the other storage devices that we were

00:01:16,830 --> 00:01:23,640
familiar with but the problem the

00:01:21,090 --> 00:01:25,979
problem was that those devices were

00:01:23,640 --> 00:01:32,250
installed locally they couldn't be

00:01:25,979 --> 00:01:34,710
shared between different clients and in

00:01:32,250 --> 00:01:37,590
that point we got Envy me over fabrics

00:01:34,710 --> 00:01:40,259
into the picture so we we understood

00:01:37,590 --> 00:01:43,409
that we need to share those devices over

00:01:40,259 --> 00:01:46,950
the network the same way that I scuzzy

00:01:43,409 --> 00:01:50,610
for example is doing for scuzzy so in

00:01:46,950 --> 00:01:54,210
early 2014 and we initialize the pre

00:01:50,610 --> 00:01:56,610
standard of nvme over our DMA how DMA is

00:01:54,210 --> 00:02:00,119
remote direct memory access I believe

00:01:56,610 --> 00:02:03,030
most of you are familiar with and

00:02:00,119 --> 00:02:06,119
it basically was the first over the

00:02:03,030 --> 00:02:08,489
fabric standard that include nvme inside

00:02:06,119 --> 00:02:09,599
of it so you can use and images from

00:02:08,489 --> 00:02:13,520
remote host

00:02:09,599 --> 00:02:18,630
later on we got the standardization of

00:02:13,520 --> 00:02:22,650
nvme of' 1.0 which was released by nvme

00:02:18,630 --> 00:02:25,200
dot org and later on in 2015 and

00:02:22,650 --> 00:02:28,099
rhema.org basically formed a group of

00:02:25,200 --> 00:02:31,860
key developers in the Linux community

00:02:28,099 --> 00:02:34,440
that will develop together both the

00:02:31,860 --> 00:02:38,100
local stock day and Vimy PCI stack

00:02:34,440 --> 00:02:40,920
together on the same git repository with

00:02:38,100 --> 00:02:43,620
the nvme of a fabric stack so they

00:02:40,920 --> 00:02:45,690
converge we converse basically to a

00:02:43,620 --> 00:02:48,989
common starting point on the same

00:02:45,690 --> 00:02:53,220
repository and we we did some heavy

00:02:48,989 --> 00:02:55,049
lifting of both stacks the local and the

00:02:53,220 --> 00:02:59,190
mystic and the over the fabric stack

00:02:55,049 --> 00:03:02,430
which was pretty new later on in 2016

00:02:59,190 --> 00:03:05,329
nvme of a fabric support was merged into

00:03:02,430 --> 00:03:09,060
the Linux kernel I think it was channel

00:03:05,329 --> 00:03:10,940
4 point 8 and people started to use it

00:03:09,060 --> 00:03:13,739
and to deploy it and we started to see

00:03:10,940 --> 00:03:18,209
people are opening bugs at the community

00:03:13,739 --> 00:03:20,459
and it was first it left the nice and

00:03:18,209 --> 00:03:22,709
cozy place where only the developers

00:03:20,459 --> 00:03:25,590
were one were the one that we're using

00:03:22,709 --> 00:03:27,390
it and move to a place that everyone can

00:03:25,590 --> 00:03:29,930
use it and everyone's are starting to

00:03:27,390 --> 00:03:29,930
install it

00:03:34,840 --> 00:03:45,580
okay yep so what we had since we we did

00:03:41,760 --> 00:03:47,739
multiple stability fixes okay and we

00:03:45,580 --> 00:03:51,310
move fabrics was a new driver that was

00:03:47,739 --> 00:03:56,140
using mainly caramel generic api's but

00:03:51,310 --> 00:03:59,440
it has its own kv8 where we we discover

00:03:56,140 --> 00:04:02,380
later we added instrumentation because

00:03:59,440 --> 00:04:04,569
giving someone a driver to use without

00:04:02,380 --> 00:04:07,180
the proper tools to debug it

00:04:04,569 --> 00:04:09,489
it's very hard you know if you want him

00:04:07,180 --> 00:04:12,549
to deploy it and we enhance the tool

00:04:09,489 --> 00:04:15,610
chain to give so there is like four nvme

00:04:12,549 --> 00:04:20,040
there is the CLI which is the nvac line

00:04:15,610 --> 00:04:23,350
and which gives you many options to to

00:04:20,040 --> 00:04:25,690
configure your controller with

00:04:23,350 --> 00:04:27,990
attributes that you are willing to use

00:04:25,690 --> 00:04:32,169
like we will talk about it later

00:04:27,990 --> 00:04:34,360
we also added you your ID support in

00:04:32,169 --> 00:04:36,190
case someone wants consistency of the

00:04:34,360 --> 00:04:39,700
fabric let's say I want to keep the same

00:04:36,190 --> 00:04:41,620
block device below the file system over

00:04:39,700 --> 00:04:44,350
and over again so we added the UUID

00:04:41,620 --> 00:04:48,190
support into the target side of the

00:04:44,350 --> 00:04:51,610
fabrics driver a few more enhancements

00:04:48,190 --> 00:04:55,870
are the opal support which is basically

00:04:51,610 --> 00:04:57,430
used today in the nvme pci layer and the

00:04:55,870 --> 00:04:59,770
i/o poling support which is a

00:04:57,430 --> 00:05:02,550
opportunistic polling in the block layer

00:04:59,770 --> 00:05:05,650
and the AMA which is the a synchronic

00:05:02,550 --> 00:05:07,389
namespace support and we'll talk about

00:05:05,650 --> 00:05:10,419
it later but just in few words

00:05:07,389 --> 00:05:12,520
ena gives you the option to have a fast

00:05:10,419 --> 00:05:16,120
path and slow path to the same namespace

00:05:12,520 --> 00:05:18,490
and so in case of network disruption you

00:05:16,120 --> 00:05:22,500
can get through the slow path and just

00:05:18,490 --> 00:05:22,500
make it the faster if you want

00:05:23,000 --> 00:05:29,400
after nvme over the fabric

00:05:25,970 --> 00:05:32,720
standardization basically we got the 1.1

00:05:29,400 --> 00:05:35,820
version the 1.1 standard where we

00:05:32,720 --> 00:05:38,940
initially saw the the new protocol which

00:05:35,820 --> 00:05:42,210
is nvme over TCP pretty exciting moment

00:05:38,940 --> 00:05:44,640
for us after a few years of writing the

00:05:42,210 --> 00:05:48,000
code and debugging and trying to push it

00:05:44,640 --> 00:05:51,240
further into the standardization part we

00:05:48,000 --> 00:05:53,670
saw also a few other things that we'll

00:05:51,240 --> 00:05:57,060
discuss one of them is the dynamic

00:05:53,670 --> 00:05:58,830
resource enumeration so dynamic resource

00:05:57,060 --> 00:06:02,250
enumeration gives you the opportunity to

00:05:58,830 --> 00:06:07,050
have a stronger ecosystem by building a

00:06:02,250 --> 00:06:11,580
discovery discovery service that can

00:06:07,050 --> 00:06:14,310
discover new subsystem in your in your

00:06:11,580 --> 00:06:18,720
cluster without any without doing

00:06:14,310 --> 00:06:21,240
anything else basically and the other

00:06:18,720 --> 00:06:23,430
thing is SQ submission queue flow

00:06:21,240 --> 00:06:25,620
control disable mode so submission queue

00:06:23,430 --> 00:06:29,000
flow control disable mode is actually

00:06:25,620 --> 00:06:32,340
because in the original spec of nvme

00:06:29,000 --> 00:06:35,040
there is some field in the completion

00:06:32,340 --> 00:06:37,440
queue entry that says that the

00:06:35,040 --> 00:06:40,680
controller needs to put the submission

00:06:37,440 --> 00:06:42,930
queue entry head like where the the

00:06:40,680 --> 00:06:44,370
submission queue where the controller is

00:06:42,930 --> 00:06:46,590
processing in the submission queue

00:06:44,370 --> 00:06:48,960
currently over the fabric it doesn't

00:06:46,590 --> 00:06:52,440
have any meaning so in this standard we

00:06:48,960 --> 00:06:54,750
basically gave the host the option not

00:06:52,440 --> 00:06:59,100
to use this field because till then it

00:06:54,750 --> 00:07:02,010
was just nothing and the last one is

00:06:59,100 --> 00:07:08,340
traffic based keepalive so we we saw

00:07:02,010 --> 00:07:11,310
multiple tests in TCP and our DMA that

00:07:08,340 --> 00:07:13,950
during high congestion over the network

00:07:11,310 --> 00:07:17,699
the keepalive message that should say

00:07:13,950 --> 00:07:20,520
that the connection is still alive

00:07:17,699 --> 00:07:22,530
when it was delayed too much and it

00:07:20,520 --> 00:07:24,900
caused the connection to to go into a

00:07:22,530 --> 00:07:27,870
low flow which caused many destruction

00:07:24,900 --> 00:07:30,180
in the session itself so we changed it

00:07:27,870 --> 00:07:32,550
in the standard and in the code itself

00:07:30,180 --> 00:07:34,469
so in case there is any traffic between

00:07:32,550 --> 00:07:36,629
the host and the controller you don't

00:07:34,469 --> 00:07:39,449
need to send any keepalive because there

00:07:36,629 --> 00:07:42,629
is traffic so the connection is is alive

00:07:39,449 --> 00:07:44,460
basically and it's important to

00:07:42,629 --> 00:07:48,509
understand that all those suggestions

00:07:44,460 --> 00:07:50,879
and all the the the code that were was

00:07:48,509 --> 00:07:53,069
developed by the community was both

00:07:50,879 --> 00:07:56,029
developed and deployed by the same

00:07:53,069 --> 00:07:59,389
people so it was very nice and easy to

00:07:56,029 --> 00:07:59,389
get things going

00:07:59,569 --> 00:08:08,009
so why Envy me over TCP first of all

00:08:04,879 --> 00:08:11,699
it's easy to use you know it's wrong it

00:08:08,009 --> 00:08:14,580
runs over anything when people ask me

00:08:11,699 --> 00:08:17,639
usually ok I want to deploy it via TCP I

00:08:14,580 --> 00:08:19,860
got the code I cloned the Linux option

00:08:17,639 --> 00:08:22,560
you know what what do I need to do I

00:08:19,860 --> 00:08:23,969
told you you need pink okay if pink is

00:08:22,560 --> 00:08:26,310
working between the client and the

00:08:23,969 --> 00:08:29,099
server you can deploy nvme a TCP without

00:08:26,310 --> 00:08:31,259
any issues it's well understood

00:08:29,099 --> 00:08:34,529
TCP is probably the most common

00:08:31,259 --> 00:08:35,820
transport high-performance disapear

00:08:34,529 --> 00:08:38,039
scalable it delivers excellent

00:08:35,820 --> 00:08:40,469
performance it well suited for

00:08:38,039 --> 00:08:42,899
large-scale deployments and long longer

00:08:40,469 --> 00:08:45,329
distances so actually few weeks ago we

00:08:42,899 --> 00:08:49,769
did an experiment week we use them via

00:08:45,329 --> 00:08:54,240
TCP like I think it was I know but a few

00:08:49,769 --> 00:08:56,959
dozen of kilometers like so it it was a

00:08:54,240 --> 00:09:00,149
long distance in terms of data centers

00:08:56,959 --> 00:09:03,000
it's evolving it's maintained and

00:09:00,149 --> 00:09:05,459
enhanced and TCP in the kernel is

00:09:03,000 --> 00:09:08,699
developed by key developers and major

00:09:05,459 --> 00:09:11,010
players so we don't need actually to

00:09:08,699 --> 00:09:13,050
maintain nvme rotisserie the transport

00:09:11,010 --> 00:09:15,360
layer inside the protocol because there

00:09:13,050 --> 00:09:17,010
is a strong community of TCP IP in the

00:09:15,360 --> 00:09:20,010
kernel itself

00:09:17,010 --> 00:09:22,230
and inherently it supports in transit

00:09:20,010 --> 00:09:29,310
encryption which we'll talk about in few

00:09:22,230 --> 00:09:31,560
slides so here I'm going to present from

00:09:29,310 --> 00:09:33,389
the host perspective and from the target

00:09:31,560 --> 00:09:37,649
perspective the changes that we have

00:09:33,389 --> 00:09:39,959
done inside the drivers when we started

00:09:37,649 --> 00:09:43,500
to develop and Vemuri TCP we didn't want

00:09:39,959 --> 00:09:46,019
it to be like an extension to the driver

00:09:43,500 --> 00:09:48,149
we just wanted to be another transport

00:09:46,019 --> 00:09:51,510
binding that will just make it as

00:09:48,149 --> 00:09:54,540
another transport that is using most of

00:09:51,510 --> 00:09:58,380
the common code of nvme over fabrics so

00:09:54,540 --> 00:10:02,040
as you can see here it goes from user

00:09:58,380 --> 00:10:04,850
space prove EFS through the block multi

00:10:02,040 --> 00:10:07,980
cue layer and then it goes and basically

00:10:04,850 --> 00:10:10,940
define the transport so you have there

00:10:07,980 --> 00:10:13,740
nvme fibre channel on the right side

00:10:10,940 --> 00:10:16,589
just next to it you have env mirror TCP

00:10:13,740 --> 00:10:18,089
and VAR DMA and the one that is a little

00:10:16,589 --> 00:10:21,720
bit different because it goes through

00:10:18,089 --> 00:10:26,130
PCI and not through Ethernet or some

00:10:21,720 --> 00:10:28,889
fiber channel is the nvme pci stack so

00:10:26,130 --> 00:10:31,410
we just added it as another transport

00:10:28,889 --> 00:10:33,779
binding without any unnecessary changes

00:10:31,410 --> 00:10:38,279
control plane very similar to our DMA

00:10:33,779 --> 00:10:39,899
and Aero flow is also very similar but

00:10:38,279 --> 00:10:42,029
we still have plenty of home and

00:10:39,899 --> 00:10:44,670
actually these days we are working about

00:10:42,029 --> 00:10:46,740
few extra changes that will make it even

00:10:44,670 --> 00:10:51,000
more generic and agnostic to other

00:10:46,740 --> 00:10:54,750
transport on the target side we try to

00:10:51,000 --> 00:10:58,589
do the same thing basically we we put

00:10:54,750 --> 00:11:00,690
the nvme over tcp again just as the

00:10:58,589 --> 00:11:03,960
transport binding very few changes to

00:11:00,690 --> 00:11:07,380
the existing core and fabric stack

00:11:03,960 --> 00:11:09,570
and as you can see here this is actually

00:11:07,380 --> 00:11:11,520
a few weeks ago this is not from

00:11:09,570 --> 00:11:13,710
yesterday because yesterday I checked it

00:11:11,520 --> 00:11:15,840
and it's different but as you can see

00:11:13,710 --> 00:11:18,900
here most of the code sits in the common

00:11:15,840 --> 00:11:22,230
driver we today we are almost reaching

00:11:18,900 --> 00:11:23,910
the 45 percent of the coding common

00:11:22,230 --> 00:11:26,370
driver but we are still working on it

00:11:23,910 --> 00:11:32,700
and still there is plenty of room for

00:11:26,370 --> 00:11:36,090
improvements okay so let's discuss a

00:11:32,700 --> 00:11:37,980
little bit about the advantages of nvme

00:11:36,090 --> 00:11:42,000
or tcp versus different storage

00:11:37,980 --> 00:11:45,750
protocols over over the network so nvme

00:11:42,000 --> 00:11:49,710
or tcp actually map is mapping each and

00:11:45,750 --> 00:11:52,710
every nvm EQ to TCP connection so

00:11:49,710 --> 00:11:56,610
basically if you have let's say many

00:11:52,710 --> 00:11:59,730
CPUs many cores on the host side and you

00:11:56,610 --> 00:12:02,970
want to run many I ops you can you can

00:11:59,730 --> 00:12:05,790
open multiple TCP connections which will

00:12:02,970 --> 00:12:10,860
be mapped to multiple and vehicles which

00:12:05,790 --> 00:12:12,570
will act as separate queues like I said

00:12:10,860 --> 00:12:15,840
in the slide there is no controller

00:12:12,570 --> 00:12:17,850
white signal sequencing okay you don't

00:12:15,840 --> 00:12:19,680
need to wait for packets to arrive to a

00:12:17,850 --> 00:12:22,080
different queue to send a message on

00:12:19,680 --> 00:12:25,980
this case they are working in two

00:12:22,080 --> 00:12:28,260
parallelism so there is also no control

00:12:25,980 --> 00:12:30,060
of white reassembly constraints if you

00:12:28,260 --> 00:12:33,390
are familiar with other storage

00:12:30,060 --> 00:12:35,340
protocols which basically gives the high

00:12:33,390 --> 00:12:39,270
performance that we will see in few

00:12:35,340 --> 00:12:41,970
slides with and we marry TCP by the way

00:12:39,270 --> 00:12:44,940
the connection binding is performed

00:12:41,970 --> 00:12:46,920
during the connect phase of nvme of

00:12:44,940 --> 00:12:49,690
fabrics in general nothing special for

00:12:46,920 --> 00:12:53,780
TCP here

00:12:49,690 --> 00:12:55,970
this is the protocol data unit if we're

00:12:53,780 --> 00:13:01,010
going a little bit deeper into the

00:12:55,970 --> 00:13:05,600
protocol itself every nvme over TCP

00:13:01,010 --> 00:13:10,010
message is encapsulated inside this PDO

00:13:05,600 --> 00:13:12,560
basically and this is the only overhead

00:13:10,010 --> 00:13:16,310
that we have with nvm every TCP if we

00:13:12,560 --> 00:13:18,560
are excluding stuff like TLS and other

00:13:16,310 --> 00:13:19,900
cool stuff that you can use with nvm

00:13:18,560 --> 00:13:22,460
your TCP

00:13:19,900 --> 00:13:25,820
so the capsules and data are

00:13:22,460 --> 00:13:29,900
encapsulated inside the video and it has

00:13:25,820 --> 00:13:32,060
few structures inside of it there is the

00:13:29,900 --> 00:13:34,370
header on the top as you can see which

00:13:32,060 --> 00:13:36,410
is which includes the common header

00:13:34,370 --> 00:13:38,300
which every PD you have and PD a

00:13:36,410 --> 00:13:41,630
specific header we will talk about it in

00:13:38,300 --> 00:13:44,270
the next slide the header as other

00:13:41,630 --> 00:13:46,930
digest if you want to use digest over

00:13:44,270 --> 00:13:50,150
the network and Vemuri TCP supports it

00:13:46,930 --> 00:13:52,310
we have the PDU padding in case you're

00:13:50,150 --> 00:13:55,340
working with some how to acceleration we

00:13:52,310 --> 00:13:57,620
wanted to make the spec words with also

00:13:55,340 --> 00:14:00,740
how to acceleration in case there they

00:13:57,620 --> 00:14:03,620
need alignment of I don't know like 64

00:14:00,740 --> 00:14:06,470
bytes or something after the padding we

00:14:03,620 --> 00:14:10,340
have the data itself and after the data

00:14:06,470 --> 00:14:12,530
we have the data digest if you want to

00:14:10,340 --> 00:14:13,640
enable it data digest and header they

00:14:12,530 --> 00:14:15,800
just work together

00:14:13,640 --> 00:14:22,490
you can't enable only one of them you

00:14:15,800 --> 00:14:25,070
need to work with both or none so what

00:14:22,490 --> 00:14:29,270
are the PDU types that we will use in

00:14:25,070 --> 00:14:32,060
nvme a TCP first one are the initialized

00:14:29,270 --> 00:14:35,960
connection videos each and every PDO

00:14:32,060 --> 00:14:38,600
it's its unidirectional which means that

00:14:35,960 --> 00:14:40,490
every PD you has a direction it can be

00:14:38,600 --> 00:14:43,130
from host to controller or from

00:14:40,490 --> 00:14:44,990
controller to host now for those of you

00:14:43,130 --> 00:14:47,510
who are more familiar with protocols

00:14:44,990 --> 00:14:50,990
like I scuzzy for example where we have

00:14:47,510 --> 00:14:54,590
the initiator and the target terminology

00:14:50,990 --> 00:14:56,240
in nvme and nvme / fabrics the client

00:14:54,590 --> 00:14:58,220
side called host and the target side

00:14:56,240 --> 00:14:59,930
it's called the controller so where

00:14:58,220 --> 00:15:00,950
where it says host to controller

00:14:59,930 --> 00:15:03,740
basically

00:15:00,950 --> 00:15:06,170
client to target so we have the connect

00:15:03,740 --> 00:15:09,440
videos which basically initiating the

00:15:06,170 --> 00:15:12,200
connection we have the terminate videos

00:15:09,440 --> 00:15:14,900
terminate videos are only used for a low

00:15:12,200 --> 00:15:17,630
flow in case there is internal transport

00:15:14,900 --> 00:15:20,120
arrow inside the protocol itself and the

00:15:17,630 --> 00:15:22,160
target want to say they initiate ok I'm

00:15:20,120 --> 00:15:24,200
going to shut down the connection so

00:15:22,160 --> 00:15:25,850
feel free to do whatever you want before

00:15:24,200 --> 00:15:27,650
but I'm going to shut down the

00:15:25,850 --> 00:15:31,760
connection because I identified some

00:15:27,650 --> 00:15:33,530
kind of error and capsule command and

00:15:31,760 --> 00:15:35,330
capsule response are basically the

00:15:33,530 --> 00:15:37,850
commands and the completions that are

00:15:35,330 --> 00:15:41,330
that the host and the controller sending

00:15:37,850 --> 00:15:43,250
over the wire and host to controller

00:15:41,330 --> 00:15:46,640
data and controller to host data are

00:15:43,250 --> 00:15:48,590
basically the the actual data the thing

00:15:46,640 --> 00:15:51,190
that we want to get over the wire and to

00:15:48,590 --> 00:15:53,990
process in the storage or in the compute

00:15:51,190 --> 00:15:57,130
now the last one is the interesting one

00:15:53,990 --> 00:16:00,590
because it basically gives you the

00:15:57,130 --> 00:16:02,810
opportunity to to control a protocol

00:16:00,590 --> 00:16:05,240
like envy Mary TCP over the wire without

00:16:02,810 --> 00:16:09,050
getting out of memory and stuff like

00:16:05,240 --> 00:16:11,680
this so it's ready to transfer its video

00:16:09,050 --> 00:16:15,590
that is only sent from the target side

00:16:11,680 --> 00:16:18,710
unlike other protocols like our DMA for

00:16:15,590 --> 00:16:21,080
example when the target and the client

00:16:18,710 --> 00:16:24,620
knows for sure that the other side has a

00:16:21,080 --> 00:16:26,870
buffer for the for the upcoming data in

00:16:24,620 --> 00:16:30,440
TCP you can't you can't be sure that the

00:16:26,870 --> 00:16:33,350
other side has a free space of memory to

00:16:30,440 --> 00:16:36,650
get this data so basically ready to

00:16:33,350 --> 00:16:39,860
transfer is used for the target side for

00:16:36,650 --> 00:16:43,430
the controller side to say to the hot

00:16:39,860 --> 00:16:45,010
side ok you can send data we will see it

00:16:43,430 --> 00:16:49,850
in a minute

00:16:45,010 --> 00:16:52,100
so here io flows for envy me read and

00:16:49,850 --> 00:16:54,440
Envy me right as you can see the red is

00:16:52,100 --> 00:16:57,320
more simpler it has only the command

00:16:54,440 --> 00:16:59,930
capsule video and then we see the data

00:16:57,320 --> 00:17:04,070
the data from the controller to the host

00:16:59,930 --> 00:17:07,310
and after the controller finish to send

00:17:04,070 --> 00:17:09,680
the data it send the completion inside

00:17:07,310 --> 00:17:11,360
the response capsule on the right side

00:17:09,680 --> 00:17:13,820
you can see it is much more interesting

00:17:11,360 --> 00:17:16,370
because during the IO

00:17:13,820 --> 00:17:20,120
you can see they ready to to transmit

00:17:16,370 --> 00:17:22,910
ready to transfer their packets and you

00:17:20,120 --> 00:17:25,579
can see that the host will not send data

00:17:22,910 --> 00:17:28,700
until it will get the ready to transfer

00:17:25,579 --> 00:17:31,790
now inside the ready to transfer it says

00:17:28,700 --> 00:17:33,380
how many bytes the host can send so as

00:17:31,790 --> 00:17:35,630
you can see there are two packets there

00:17:33,380 --> 00:17:37,910
are two PDUs of ready to transfer

00:17:35,630 --> 00:17:40,700
because probably the first one was I

00:17:37,910 --> 00:17:43,120
don't know only for 2k and the hosts

00:17:40,700 --> 00:17:46,190
wanted to send 4k so he needed to wait

00:17:43,120 --> 00:17:49,490
until it it will send another ready to

00:17:46,190 --> 00:17:52,700
transfer also today the spec is defining

00:17:49,490 --> 00:17:54,260
parallel multiple ready to transfer but

00:17:52,700 --> 00:17:58,460
it's not yet implemented we are

00:17:54,260 --> 00:18:01,220
currently working on it okay so then we

00:17:58,460 --> 00:18:04,370
mira tcp linux support actually started

00:18:01,220 --> 00:18:07,100
in 2017 after a few different branches

00:18:04,370 --> 00:18:09,710
and git repositories a few different

00:18:07,100 --> 00:18:13,010
vendors provide nvme over tcp solution

00:18:09,710 --> 00:18:15,290
like bits of chelsea and others and we

00:18:13,010 --> 00:18:17,300
converged on a single codebase against

00:18:15,290 --> 00:18:20,750
the same as we did with the env me over

00:18:17,300 --> 00:18:22,760
fabrics code and code currently is in

00:18:20,750 --> 00:18:28,070
solid shape and you can actually find it

00:18:22,760 --> 00:18:32,390
in kernel 5.0 then vm every TCP so it's

00:18:28,070 --> 00:18:34,970
nice and exciting for fast I guess when

00:18:32,390 --> 00:18:37,610
we design the when we basically

00:18:34,970 --> 00:18:39,290
implemented driver and edit the design

00:18:37,610 --> 00:18:42,290
for the client-side there were a few a

00:18:39,290 --> 00:18:44,510
bullets that we try to keep and I hope

00:18:42,290 --> 00:18:46,970
we did but we are still working on it so

00:18:44,510 --> 00:18:49,520
we have a single reactor third Percy PU

00:18:46,970 --> 00:18:52,100
we are not sharing any resources between

00:18:49,520 --> 00:18:57,110
different CPUs on there and V me over

00:18:52,100 --> 00:18:59,570
TCP host site and we we basically did it

00:18:57,110 --> 00:19:02,300
to try and keep a context switches to

00:18:59,570 --> 00:19:06,380
the absolute minimum we are still seeing

00:19:02,300 --> 00:19:08,030
some some spikes of latency because of

00:19:06,380 --> 00:19:10,240
context switches in the driver that we

00:19:08,030 --> 00:19:13,370
are currently working on these days and

00:19:10,240 --> 00:19:15,770
but we also wanted to spread all the

00:19:13,370 --> 00:19:19,130
nvme cues among different reactors also

00:19:15,770 --> 00:19:21,149
to have one a context and one and we

00:19:19,130 --> 00:19:23,429
make you pair CPU

00:19:21,149 --> 00:19:24,210
the client-side on the hot side we never

00:19:23,429 --> 00:19:28,200
block on Io

00:19:24,210 --> 00:19:30,690
unlike other TCP implementation for

00:19:28,200 --> 00:19:32,339
those of you are familiar with we

00:19:30,690 --> 00:19:34,919
aggressively avoid data copy so

00:19:32,339 --> 00:19:38,909
currently we are copying in Aleks path

00:19:34,919 --> 00:19:42,019
and we have plans to change that as well

00:19:38,909 --> 00:19:44,729
but today ticks path is zero copy

00:19:42,019 --> 00:19:46,679
without any any copy and we'll see we

00:19:44,729 --> 00:19:48,869
had some issues with it but alex is

00:19:46,679 --> 00:19:52,229
still single copy and we would like to

00:19:48,869 --> 00:19:56,399
change it and we reuse common kernel

00:19:52,229 --> 00:19:58,889
interfaces biomech Oviatt ER socket data

00:19:56,399 --> 00:20:03,570
compression we didn't add any other

00:19:58,889 --> 00:20:06,179
layer of transport inside our protocol

00:20:03,570 --> 00:20:08,969
we wanted to use as much as possible the

00:20:06,179 --> 00:20:14,249
existing stuff from the kernel and just

00:20:08,969 --> 00:20:17,039
use it wisely so Erik's is either

00:20:14,249 --> 00:20:19,169
handled in software queue or in the same

00:20:17,039 --> 00:20:22,139
reactor context here we discovered that

00:20:19,169 --> 00:20:24,330
there are few network devices that form

00:20:22,139 --> 00:20:26,609
the network device if you are handling

00:20:24,330 --> 00:20:28,859
the data processing and data processing

00:20:26,609 --> 00:20:32,729
in this case is copying the data as we

00:20:28,859 --> 00:20:35,940
said from the ir q context you can get

00:20:32,729 --> 00:20:38,159
multiple out of order packets which can

00:20:35,940 --> 00:20:40,559
be crucial in protocols like TCP we want

00:20:38,159 --> 00:20:43,169
to avoid out of all the packets as much

00:20:40,559 --> 00:20:44,879
as possible and we discovered that there

00:20:43,169 --> 00:20:47,519
are few cases that you don't want to

00:20:44,879 --> 00:20:48,719
post this data from the ir q context and

00:20:47,519 --> 00:20:51,599
you want to do it from the reactor

00:20:48,719 --> 00:20:53,909
context we keep atomic operations to an

00:20:51,599 --> 00:20:56,820
absolute minimum and keep it uncontested

00:20:53,909 --> 00:20:59,460
so we have few locks in the in the

00:20:56,820 --> 00:21:04,529
driver but most of them are uncontested

00:20:59,460 --> 00:21:06,960
and probably necessary and we have also

00:21:04,529 --> 00:21:09,419
fairness and budgeting in the reactor

00:21:06,960 --> 00:21:12,119
itself so there will know there will not

00:21:09,419 --> 00:21:14,190
be any starvation from one and V McHugh

00:21:12,119 --> 00:21:16,559
to the others on the same reactor we

00:21:14,190 --> 00:21:18,479
want because we want to serve all env

00:21:16,559 --> 00:21:22,799
McHugh's and we don't want to starve any

00:21:18,479 --> 00:21:25,229
one of those so now now I'll present

00:21:22,799 --> 00:21:26,909
like I think two or three issues that we

00:21:25,229 --> 00:21:29,460
discovered during the development of

00:21:26,909 --> 00:21:32,000
nvme or TCP and we contributed back to

00:21:29,460 --> 00:21:34,580
the kernel the first

00:21:32,000 --> 00:21:37,100
the first problem that we saw that it

00:21:34,580 --> 00:21:40,160
was we had like performance degradation

00:21:37,100 --> 00:21:44,140
when working with data digest with the

00:21:40,160 --> 00:21:48,050
interfaces the kernel is providing and

00:21:44,140 --> 00:21:52,430
we were using skb copy data gram eater

00:21:48,050 --> 00:21:54,410
for incoming data placement and all the

00:21:52,430 --> 00:21:57,770
abstraction was there the only problem

00:21:54,410 --> 00:22:00,680
is that when you're doing data digest

00:21:57,770 --> 00:22:03,080
you have two options you can do data

00:22:00,680 --> 00:22:06,710
digest on each and every skb that you're

00:22:03,080 --> 00:22:08,930
processing on runtime basically but you

00:22:06,710 --> 00:22:12,620
didn't had any kind of interface to do

00:22:08,930 --> 00:22:14,780
or you can get the whole frame basically

00:22:12,620 --> 00:22:18,110
the whole and remarry TCP message and do

00:22:14,780 --> 00:22:20,300
that ideally digest on that so we

00:22:18,110 --> 00:22:22,130
discovered that when you're waiting for

00:22:20,300 --> 00:22:25,400
the whole data to come the whole message

00:22:22,130 --> 00:22:27,740
to arrive before digesting it the data

00:22:25,400 --> 00:22:30,560
is not hot in the cache and it causes

00:22:27,740 --> 00:22:32,690
performance degradation so we provided a

00:22:30,560 --> 00:22:35,300
new interface and we contributed it back

00:22:32,690 --> 00:22:37,850
to the kernel which called skb copy and

00:22:35,300 --> 00:22:42,170
hash Datagram eater which receive a

00:22:37,850 --> 00:22:45,700
plane initialize struct so so all the

00:22:42,170 --> 00:22:48,410
digest will happen online basically and

00:22:45,700 --> 00:22:51,670
all the data will be hot in the cache

00:22:48,410 --> 00:22:56,420
when you want to digest it

00:22:51,670 --> 00:22:59,290
the the other problem that we discovered

00:22:56,420 --> 00:23:03,860
actually it happened during one of our

00:22:59,290 --> 00:23:07,610
continuous integration runs and nvme TCP

00:23:03,860 --> 00:23:09,920
PDUs are like any other data a zero

00:23:07,610 --> 00:23:11,840
copied on the way out okay we are not

00:23:09,920 --> 00:23:13,550
copying the videos also on the Teague's

00:23:11,840 --> 00:23:16,100
although they are not big but we didn't

00:23:13,550 --> 00:23:19,670
want to copy any any type of data in the

00:23:16,100 --> 00:23:21,950
protocol and when the queue depth was

00:23:19,670 --> 00:23:25,370
high and the network was very congested

00:23:21,950 --> 00:23:28,400
we got into a situation where with

00:23:25,370 --> 00:23:30,920
specific kernel hardening we got this

00:23:28,400 --> 00:23:33,890
beautiful crash log that you see on the

00:23:30,920 --> 00:23:36,050
right we started to investigate it as

00:23:33,890 --> 00:23:40,200
you can see the

00:23:36,050 --> 00:23:42,390
the process that caused this crash is th

00:23:40,200 --> 00:23:46,100
client and we we actually couldn't

00:23:42,390 --> 00:23:48,870
understand how it happened but

00:23:46,100 --> 00:23:51,900
eventually we understand that the kernel

00:23:48,870 --> 00:23:54,330
will panic when user copy attempts to

00:23:51,900 --> 00:23:57,390
read slab originated buffer if they

00:23:54,330 --> 00:24:00,390
cause slab object so the PDU headers

00:23:57,390 --> 00:24:04,220
were allocated using the slab we didn't

00:24:00,390 --> 00:24:08,970
use the the original page allocation

00:24:04,220 --> 00:24:11,520
which caused the th client just to to

00:24:08,970 --> 00:24:14,100
take some packets and to try and parse

00:24:11,520 --> 00:24:17,580
it but those packets were from two

00:24:14,100 --> 00:24:19,680
different slab objects and the heuristic

00:24:17,580 --> 00:24:25,950
here says that it can be attempt to

00:24:19,680 --> 00:24:28,170
catch and exploit the data so as as

00:24:25,950 --> 00:24:30,290
mentioned use of user space programs is

00:24:28,170 --> 00:24:34,350
allowed to use packet filters in rate

00:24:30,290 --> 00:24:36,150
BPF tap and the edge client basically

00:24:34,350 --> 00:24:38,400
every user space program can panic the

00:24:36,150 --> 00:24:42,480
kernel which is not the behavior that we

00:24:38,400 --> 00:24:45,830
wanted to have and we solved it by page

00:24:42,480 --> 00:24:51,120
fragments API so we moved each and every

00:24:45,830 --> 00:24:53,400
PD you basically to okay

00:24:51,120 --> 00:24:55,500
so used page for a cache which is an

00:24:53,400 --> 00:24:57,630
interface of the kernel and we got to

00:24:55,500 --> 00:24:59,520
optimization from there the first one we

00:24:57,630 --> 00:25:01,980
are not getting the kernel cache because

00:24:59,520 --> 00:25:05,190
of that the second one we are much more

00:25:01,980 --> 00:25:07,860
and we are avoiding CPU cost sharing

00:25:05,190 --> 00:25:09,840
atomic areas because two CPUs can use

00:25:07,860 --> 00:25:12,480
the same slab object which basically

00:25:09,840 --> 00:25:14,580
means the two CPUs are taking left count

00:25:12,480 --> 00:25:18,210
on this object which is causing

00:25:14,580 --> 00:25:21,090
performance degradation eventually so as

00:25:18,210 --> 00:25:23,190
mentioned and the current features today

00:25:21,090 --> 00:25:24,810
in the kernel is zero copy transmission

00:25:23,190 --> 00:25:28,290
and we are not copying on the Teague's

00:25:24,810 --> 00:25:31,830
and we do online integrity with header

00:25:28,290 --> 00:25:34,929
data digest and we have a CPU Numa

00:25:31,830 --> 00:25:39,710
affinity assignment for ultra

00:25:34,929 --> 00:25:41,720
and future work will be TLS support we

00:25:39,710 --> 00:25:43,670
want to end encryption support we have

00:25:41,720 --> 00:25:46,340
it in the standard polling mode IO

00:25:43,670 --> 00:25:48,770
currently is not implemented and out of

00:25:46,340 --> 00:25:52,520
folder data transfers form the

00:25:48,770 --> 00:25:54,650
controller to the host so I'll go quick

00:25:52,520 --> 00:25:57,020
about the TLS TLS currently is not

00:25:54,650 --> 00:25:59,170
implemented in the kernel currently we

00:25:57,020 --> 00:26:03,530
are working on putting the TLS handshake

00:25:59,170 --> 00:26:05,630
from the user space to the kernel and we

00:26:03,530 --> 00:26:09,800
we saw so many issues with implementing

00:26:05,630 --> 00:26:12,050
it by trampling the handshake to

00:26:09,800 --> 00:26:14,600
userspace like other protocols but we're

00:26:12,050 --> 00:26:16,790
currently working it but it is in the

00:26:14,600 --> 00:26:20,210
standard so basically on Vimeo TCP is

00:26:16,790 --> 00:26:25,010
can be the first consumer of TLS

00:26:20,210 --> 00:26:27,080
handshake inside the kernel and I will

00:26:25,010 --> 00:26:28,880
just go quick about the performance so

00:26:27,080 --> 00:26:30,980
we have three protocols that we are

00:26:28,880 --> 00:26:33,530
comparing the first one is nvme tcp

00:26:30,980 --> 00:26:36,740
dollars and Vimeo DMA and the third is I

00:26:33,530 --> 00:26:38,990
scuzzy as you can see here and Vimeo TCP

00:26:36,740 --> 00:26:41,480
is much more comparable with nvme

00:26:38,990 --> 00:26:44,690
overall DMA than with I scuzzy

00:26:41,480 --> 00:26:48,679
so this is the QT one a canonical

00:26:44,690 --> 00:26:51,830
latency this is the throughput

00:26:48,679 --> 00:26:54,230
comparison and via TCP versus I scuzzy

00:26:51,830 --> 00:26:57,280
where you can see nvme TCP is much more

00:26:54,230 --> 00:27:01,429
scalable and I scuzzy is basically it

00:26:57,280 --> 00:27:03,710
doesn't go over the I'm not sure how

00:27:01,429 --> 00:27:09,050
much is it I think it's 2.5 gigabytes

00:27:03,710 --> 00:27:12,020
and the same experiment just with 4k I

00:27:09,050 --> 00:27:15,220
hopes that you can see the Envy Mira TCP

00:27:12,020 --> 00:27:15,220
is going high and high

00:27:16,690 --> 00:27:23,830
okay that that was all and any questions

00:27:27,190 --> 00:27:29,790
yeah

00:27:31,930 --> 00:27:34,980
I think

00:27:36,090 --> 00:27:46,889
this one one question no time hi so what

00:27:45,119 --> 00:27:50,369
we saw with the nvme or TCP

00:27:46,889 --> 00:27:52,859
implementation is most of the time the

00:27:50,369 --> 00:27:55,049
submission and the completion does not

00:27:52,859 --> 00:27:57,269
happen in a software it is happen in the

00:27:55,049 --> 00:28:03,679
worker thread and that is one of the

00:27:57,269 --> 00:28:03,679
reason of the high context switches so

00:28:06,890 --> 00:28:12,559
can you hear me yes but you saw that the

00:28:10,610 --> 00:28:18,710
submission and completion are not coming

00:28:12,559 --> 00:28:22,070
from the reactor itself no our trace

00:28:18,710 --> 00:28:24,710
does not show okay so actually the only

00:28:22,070 --> 00:28:28,580
thing that we witnessed with stuff that

00:28:24,710 --> 00:28:31,580
that are related to the completion and

00:28:28,580 --> 00:28:34,520
submission is that sometimes inherently

00:28:31,580 --> 00:28:37,580
from the tcp/ip stack when you are

00:28:34,520 --> 00:28:39,980
working with single reactor you can see

00:28:37,580 --> 00:28:42,710
that the reactor is not processing

00:28:39,980 --> 00:28:45,620
anything because it it holds on the

00:28:42,710 --> 00:28:49,400
socket look so I'm not sure if that's

00:28:45,620 --> 00:28:51,350
the case but with many reactors we

00:28:49,400 --> 00:28:53,510
didn't saw any processing issues and

00:28:51,350 --> 00:28:55,010
most of the time we we measure the

00:28:53,510 --> 00:28:57,860
context switches and we see that the

00:28:55,010 --> 00:29:00,500
application and the driver itself are

00:28:57,860 --> 00:29:05,980
getting almost the same slice of of

00:29:00,500 --> 00:29:05,980
cycles from the CPU okay okay

00:29:08,379 --> 00:29:11,529
thank you

00:29:12,280 --> 00:29:15,569

YouTube URL: https://www.youtube.com/watch?v=8KGTSuy8W2o


