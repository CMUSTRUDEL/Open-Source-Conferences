Title: Netdev 0x14 - Performance study of kernel TLS handshakes
Publication date: 2020-10-09
Playlist: Netdev 0x14
Description: 
	Speakers: Alexander Krizhanovsky, Ivan Koveshnikov

More info: https://netdevconf.info/0x14/session.html?talk-performance-study-of-kernel-TLS-handshakes

Date: Friday, August 14, 2020

In this talk, Alexander Krizhanovsky and Ivan Koveshnikov continue
their quest(see netdev 0x12 talk) to investigate and improve TLS
handshake by moving it into the kernel. They will quantify how much
performance improvement one can gain for TLS handshake by exploring
an example of an HTTPS server moving into the kernel space.
Captions: 
	00:00:01,040 --> 00:00:06,480
today we are going to talk about

00:00:03,280 --> 00:00:10,160
uh the kernel uh cheerless handshakes

00:00:06,480 --> 00:00:13,040
uh this is actually the third part of

00:00:10,160 --> 00:00:13,519
discussion uh previously there were uh

00:00:13,040 --> 00:00:16,640
to

00:00:13,519 --> 00:00:19,920
our talks on previous df conferences

00:00:16,640 --> 00:00:23,359
and today we will have a look on why

00:00:19,920 --> 00:00:26,400
uh cannot tell us handshakes matter uh

00:00:23,359 --> 00:00:30,080
we will look on to some benchmarks

00:00:26,400 --> 00:00:32,640
and we'll discuss design proposal for

00:00:30,080 --> 00:00:36,480
the linux mainstream

00:00:32,640 --> 00:00:39,600
uh in our case we develop

00:00:36,480 --> 00:00:41,360
a temperature w which is a application

00:00:39,600 --> 00:00:43,440
delivery controller

00:00:41,360 --> 00:00:44,480
application delivery controllers are

00:00:43,440 --> 00:00:47,520
typically

00:00:44,480 --> 00:00:50,559
http and proxies which also provide you

00:00:47,520 --> 00:00:51,440
a lot of security features like ddos

00:00:50,559 --> 00:00:54,640
protection

00:00:51,440 --> 00:00:57,760
jls or ssl uploading

00:00:54,640 --> 00:00:58,960
web security and so on and typical

00:00:57,760 --> 00:01:02,800
players in the market

00:00:58,960 --> 00:01:06,080
are f5 big ip or fortunate adc

00:01:02,800 --> 00:01:09,360
and the tempest fw is considered to be

00:01:06,080 --> 00:01:12,720
an open source alternative to such

00:01:09,360 --> 00:01:13,840
proprietary appliances we do care about

00:01:12,720 --> 00:01:17,200
high performance

00:01:13,840 --> 00:01:20,240
uh chariot handshakes and

00:01:17,200 --> 00:01:21,600
telescope checks is a typical very

00:01:20,240 --> 00:01:24,720
important

00:01:21,600 --> 00:01:28,080
measurement in check specifications

00:01:24,720 --> 00:01:30,159
of the appliances for example how many

00:01:28,080 --> 00:01:32,159
connections per seconds you can

00:01:30,159 --> 00:01:35,600
establish uh i mean tls

00:01:32,159 --> 00:01:38,640
connections per second or how many https

00:01:35,600 --> 00:01:42,000
transactions per second you can make

00:01:38,640 --> 00:01:45,520
this also very good uh video

00:01:42,000 --> 00:01:48,640
uh from f5 uh guy who

00:01:45,520 --> 00:01:51,680
compared performance of uh big-ip and

00:01:48,640 --> 00:01:55,280
agent x on top of dbtk using

00:01:51,680 --> 00:01:57,920
f stack uh cpm ipa stack

00:01:55,280 --> 00:01:59,360
on top of dpdk inside the virtual

00:01:57,920 --> 00:02:02,560
machine using only

00:01:59,360 --> 00:02:05,920
a cpu and in that

00:02:02,560 --> 00:02:09,360
measurements big-ip wins about 30

00:02:05,920 --> 00:02:12,480
to 50 percent transactions per second

00:02:09,360 --> 00:02:15,760
and just because big-ip uses

00:02:12,480 --> 00:02:18,879
their own uh italian implementation

00:02:15,760 --> 00:02:22,879
so js is very very crucial for us

00:02:18,879 --> 00:02:26,400
however if we talk about generic

00:02:22,879 --> 00:02:29,200
linux users there are cases uh

00:02:26,400 --> 00:02:30,560
where you can benefit from uh fast

00:02:29,200 --> 00:02:33,040
satellites haven't checked

00:02:30,560 --> 00:02:34,480
or kernel jellies can checks in

00:02:33,040 --> 00:02:37,840
particular

00:02:34,480 --> 00:02:40,000
for example there are uh jidos uh

00:02:37,840 --> 00:02:40,959
attacks on chelsea's handshakes and

00:02:40,000 --> 00:02:44,480
everybody

00:02:40,959 --> 00:02:46,080
uh probably can we win from the faster

00:02:44,480 --> 00:02:47,519
handshakes to mitigate some kind of

00:02:46,080 --> 00:02:50,800
attacks and

00:02:47,519 --> 00:02:55,200
uh this particular concern about

00:02:50,800 --> 00:02:58,640
uh security security uh so

00:02:55,200 --> 00:03:01,760
uh actually it does make sense to

00:02:58,640 --> 00:03:04,239
uh separate your uh private

00:03:01,760 --> 00:03:06,080
uh private key and all security

00:03:04,239 --> 00:03:09,519
sensitive data

00:03:06,080 --> 00:03:12,800
outside of your main working threads

00:03:09,519 --> 00:03:17,280
so in varnish case uh

00:03:12,800 --> 00:03:19,760
guys you separate a huge jls blockchain

00:03:17,280 --> 00:03:21,120
outside of the main varnish uh working

00:03:19,760 --> 00:03:24,159
process

00:03:21,120 --> 00:03:27,760
so if you separate a key

00:03:24,159 --> 00:03:31,280
management and all security sensitive uh

00:03:27,760 --> 00:03:34,319
data like uh jls

00:03:31,280 --> 00:03:37,519
session keys and so on outside of the

00:03:34,319 --> 00:03:38,000
uh main working logic and uh actually

00:03:37,519 --> 00:03:40,720
this

00:03:38,000 --> 00:03:41,680
logic is considered to be evolved very

00:03:40,720 --> 00:03:44,400
very quickly

00:03:41,680 --> 00:03:45,120
and you could uh put a lot of bugs into

00:03:44,400 --> 00:03:48,400
production

00:03:45,120 --> 00:03:52,080
uh thanks to the uh quick development

00:03:48,400 --> 00:03:55,360
uh in particular in cloudbleed uh

00:03:52,080 --> 00:03:58,640
case for cloudflare the guy starts the

00:03:55,360 --> 00:04:02,080
blog post from the words that no one

00:03:58,640 --> 00:04:05,200
um client private key were

00:04:02,080 --> 00:04:10,080
compromised thanks to separation

00:04:05,200 --> 00:04:13,120
of the main or working logic from the

00:04:10,080 --> 00:04:16,560
tls termination logic so

00:04:13,120 --> 00:04:20,160
uh security can be generally uh improved

00:04:16,560 --> 00:04:23,199
uh by separation of quality

00:04:20,160 --> 00:04:24,000
management inside of kernel space and

00:04:23,199 --> 00:04:26,880
keeping

00:04:24,000 --> 00:04:28,080
uh the main working logic in user space

00:04:26,880 --> 00:04:31,759
uh

00:04:28,080 --> 00:04:35,280
in worker process besides this

00:04:31,759 --> 00:04:38,880
token there are also good good to have

00:04:35,280 --> 00:04:42,320
faster handshakes you see that even

00:04:38,880 --> 00:04:45,440
fast session resumption can be even more

00:04:42,320 --> 00:04:48,240
faster with kernel class

00:04:45,440 --> 00:04:50,000
uh speaking about uh performance let's

00:04:48,240 --> 00:04:53,440
have a look on

00:04:50,000 --> 00:04:57,759
profile this profile for openness cell

00:04:53,440 --> 00:05:00,800
and nginx with uh nist

00:04:57,759 --> 00:05:03,759
elliptic curve uh 256

00:05:00,800 --> 00:05:04,400
and in the profile we just establish uh

00:05:03,759 --> 00:05:07,840
in this case

00:05:04,400 --> 00:05:08,560
a lot of cherius connections and in the

00:05:07,840 --> 00:05:12,639
profile we

00:05:08,560 --> 00:05:15,199
see that uh most of the codes are about

00:05:12,639 --> 00:05:16,320
uh memory management uh copies they're

00:05:15,199 --> 00:05:19,600
going and so on

00:05:16,320 --> 00:05:22,840
uh genius speaking uh routines uh

00:05:19,600 --> 00:05:24,560
not uh not about cryptography

00:05:22,840 --> 00:05:27,280
mathematics

00:05:24,560 --> 00:05:28,639
also interesting routines are

00:05:27,280 --> 00:05:32,160
interesting in our

00:05:28,639 --> 00:05:35,600
presentation are in red in the side

00:05:32,160 --> 00:05:39,360
and also there are uh blue two routines

00:05:35,600 --> 00:05:41,680
in blue uh second and third it's about

00:05:39,360 --> 00:05:42,560
montgomery multiplication and montgomery

00:05:41,680 --> 00:05:46,320
squaring

00:05:42,560 --> 00:05:46,800
we'll talk more about the routines later

00:05:46,320 --> 00:05:50,400
in the

00:05:46,800 --> 00:05:53,120
presentation but this uh um

00:05:50,400 --> 00:05:54,320
in this site we uh can consider that we

00:05:53,120 --> 00:05:57,440
can dramatically improve

00:05:54,320 --> 00:05:59,120
performance of uh chileans can shakes uh

00:05:57,440 --> 00:06:02,880
just by eliminating

00:05:59,120 --> 00:06:06,639
uh the overhead of memory management

00:06:02,880 --> 00:06:09,759
and the copies and zeroing uh by the way

00:06:06,639 --> 00:06:13,199
uh since um the nist

00:06:09,759 --> 00:06:16,479
uh cove is still uh

00:06:13,199 --> 00:06:17,759
it's a quite old cool curve it's still

00:06:16,479 --> 00:06:22,639
important because

00:06:17,759 --> 00:06:25,680
uh you need uh to use the code for sdsa

00:06:22,639 --> 00:06:29,280
uh certificate so why is the core

00:06:25,680 --> 00:06:32,319
uh still important and it's old uh we

00:06:29,280 --> 00:06:35,360
still uh have have to have the code

00:06:32,319 --> 00:06:38,639
to manage our uh certificates

00:06:35,360 --> 00:06:39,440
and uh the more the mathematical

00:06:38,639 --> 00:06:42,960
evidence are

00:06:39,440 --> 00:06:45,840
involved in the cuff implementations uh

00:06:42,960 --> 00:06:47,120
some of them are just outdated we'll

00:06:45,840 --> 00:06:50,560
talk more about this

00:06:47,120 --> 00:06:53,599
uh later during the presentation we will

00:06:50,560 --> 00:06:54,319
use our two benchmark tools the first

00:06:53,599 --> 00:06:58,560
one

00:06:54,319 --> 00:07:02,000
italia's pf is developed by our team

00:06:58,560 --> 00:07:04,160
basically it just establishes as many

00:07:02,000 --> 00:07:06,160
cherries connections as possible and

00:07:04,160 --> 00:07:09,440
drop the connection

00:07:06,160 --> 00:07:14,840
velcro is very widely used

00:07:09,440 --> 00:07:17,599
on hp benchmarking tool and it also can

00:07:14,840 --> 00:07:20,720
use openness cell

00:07:17,599 --> 00:07:24,160
or another ssl uh libraries for

00:07:20,720 --> 00:07:28,000
challenges and we use a benchmark

00:07:24,160 --> 00:07:31,280
to measure hps transaction performance

00:07:28,000 --> 00:07:33,840
in our performance

00:07:31,280 --> 00:07:35,680
measurements we use a virtual machine

00:07:33,840 --> 00:07:39,520
unfortunately we had no

00:07:35,680 --> 00:07:42,160
uh machine with a virtual api team

00:07:39,520 --> 00:07:44,560
and the physical pair of physical

00:07:42,160 --> 00:07:47,599
machine with very fast uh

00:07:44,560 --> 00:07:51,120
internet connection uh

00:07:47,599 --> 00:07:54,319
so uh to start uh

00:07:51,120 --> 00:07:58,000
to start from from the source code

00:07:54,319 --> 00:07:58,479
uh actually we started champions jls

00:07:58,000 --> 00:08:01,520
from

00:07:58,479 --> 00:08:05,599
mbit uh jellies

00:08:01,520 --> 00:08:09,039
and we moved to mbtls

00:08:05,599 --> 00:08:12,400
uh to the kernel and uh

00:08:09,039 --> 00:08:14,000
we used vtls because of two four main

00:08:12,400 --> 00:08:18,000
factors the first one is it's

00:08:14,000 --> 00:08:21,199
uh very portable we needed only one

00:08:18,000 --> 00:08:23,840
uh human month to move into piano

00:08:21,199 --> 00:08:25,360
the second thing is that mbtos provides

00:08:23,840 --> 00:08:28,960
very serious security

00:08:25,360 --> 00:08:31,840
uh however vtos is too slow

00:08:28,960 --> 00:08:32,719
it's uh that doesn't care about

00:08:31,840 --> 00:08:35,760
performance

00:08:32,719 --> 00:08:37,839
at all and uh there are a lot of

00:08:35,760 --> 00:08:38,880
things which can be improved in which

00:08:37,839 --> 00:08:42,880
areas

00:08:38,880 --> 00:08:45,600
uh to improve our performance on btls we

00:08:42,880 --> 00:08:46,080
develop some of mathematical algorithms

00:08:45,600 --> 00:08:49,760
on

00:08:46,080 --> 00:08:51,120
our own and also we use a world-face

00:08:49,760 --> 00:08:54,160
cell for

00:08:51,120 --> 00:08:57,360
some routines which we can't

00:08:54,160 --> 00:09:01,200
make very better we didn't use

00:08:57,360 --> 00:09:04,880
volt for the sale uh because

00:09:01,200 --> 00:09:07,760
it's very very large and it's

00:09:04,880 --> 00:09:08,720
not so easy to port it into the linux

00:09:07,760 --> 00:09:10,640
kernel

00:09:08,720 --> 00:09:13,040
uh it's very fast and we'll see

00:09:10,640 --> 00:09:16,240
benchmarks for wi-fi today

00:09:13,040 --> 00:09:16,800
uh but there might be some uh security

00:09:16,240 --> 00:09:20,480
issues

00:09:16,800 --> 00:09:23,839
uh in the library and we i also

00:09:20,480 --> 00:09:27,200
cover um issues with datum

00:09:23,839 --> 00:09:30,320
uh so um speaking about mbtls

00:09:27,200 --> 00:09:32,240
uh we let's start from the benchmark of

00:09:30,320 --> 00:09:34,560
the original and bt areas

00:09:32,240 --> 00:09:35,519
are being ported into the linux kernel

00:09:34,560 --> 00:09:38,320
and

00:09:35,519 --> 00:09:38,959
our current implementation uh which is

00:09:38,320 --> 00:09:41,360
that

00:09:38,959 --> 00:09:42,000
the original implementation is about 30

00:09:41,360 --> 00:09:44,560
times

00:09:42,000 --> 00:09:46,080
slower than current uh temperature yes

00:09:44,560 --> 00:09:49,279
code

00:09:46,080 --> 00:09:52,800
this is just a proof how vtos

00:09:49,279 --> 00:09:56,560
so uh the next thing is

00:09:52,800 --> 00:09:59,920
let's see how how we uh compare with

00:09:56,560 --> 00:10:00,320
uh current open se and nginx performance

00:09:59,920 --> 00:10:03,360
this

00:10:00,320 --> 00:10:05,360
benchmark on a virtual machine

00:10:03,360 --> 00:10:07,760
which is that uh current impressive

00:10:05,360 --> 00:10:10,160
challenges is about 40

00:10:07,760 --> 00:10:11,040
percent uh better performance in

00:10:10,160 --> 00:10:13,839
connections

00:10:11,040 --> 00:10:14,800
js connections per second and uh

00:10:13,839 --> 00:10:18,079
provides about

00:10:14,800 --> 00:10:20,880
40 times lower latency also

00:10:18,079 --> 00:10:22,560
in leverage also if we see the best

00:10:20,880 --> 00:10:25,440
cases for performance peak

00:10:22,560 --> 00:10:27,040
and the latency we also provide that

00:10:25,440 --> 00:10:32,079
better numbers

00:10:27,040 --> 00:10:34,560
uh the next thing is about um

00:10:32,079 --> 00:10:35,600
the previous slide was about uh full

00:10:34,560 --> 00:10:39,680
challenges

00:10:35,600 --> 00:10:43,040
um handshake but this one is about

00:10:39,680 --> 00:10:44,640
uh cheerless session resumption in

00:10:43,040 --> 00:10:46,399
this case we provide about eighty

00:10:44,640 --> 00:10:49,040
percent battery performance

00:10:46,399 --> 00:10:50,959
and the same legacy as nginx and

00:10:49,040 --> 00:10:56,160
openness ssa

00:10:50,959 --> 00:10:56,160
however in our tests we observed

00:10:56,800 --> 00:11:04,640
spikes or huge spikes of latency

00:11:00,480 --> 00:11:09,519
and this github issue which we need to

00:11:04,640 --> 00:11:09,519
work on more in our implementation

00:11:09,920 --> 00:11:14,959
we also compared different linux kernel

00:11:14,160 --> 00:11:19,680
versions

00:11:14,959 --> 00:11:22,800
uh 4.14 and 5.7

00:11:19,680 --> 00:11:23,839
in uh chelya session resumption and we

00:11:22,800 --> 00:11:27,360
see that

00:11:23,839 --> 00:11:30,800
those kernels provide a bit

00:11:27,360 --> 00:11:31,360
higher performance this mostly because

00:11:30,800 --> 00:11:34,560
of

00:11:31,360 --> 00:11:37,760
uh recent uh

00:11:34,560 --> 00:11:42,399
attacks mitigation in

00:11:37,760 --> 00:11:44,880
intel cpus uh also

00:11:42,399 --> 00:11:46,240
speaking about um the recent cpu

00:11:44,880 --> 00:11:49,360
vulnerabilities we

00:11:46,240 --> 00:11:52,639
assumed that kpti will uh

00:11:49,360 --> 00:11:54,800
impart performance a lot however it

00:11:52,639 --> 00:11:56,399
actually isn't the case and we didn't

00:11:54,800 --> 00:11:59,279
observe more than four

00:11:56,399 --> 00:12:00,000
percent of performance degradation uh

00:11:59,279 --> 00:12:02,800
with uh

00:12:00,000 --> 00:12:04,240
kpti enabled and this uh pretty

00:12:02,800 --> 00:12:07,279
different from

00:12:04,240 --> 00:12:10,480
what mariadb observed but hdbr

00:12:07,279 --> 00:12:13,360
uh server observed up to 40 percent

00:12:10,480 --> 00:12:17,040
performance degradation with kpti

00:12:13,360 --> 00:12:20,959
uh actually the reason for this

00:12:17,040 --> 00:12:24,880
is that uh tls handshakes don't involve

00:12:20,959 --> 00:12:27,760
so many system calls

00:12:24,880 --> 00:12:29,760
uh either for network io or memory

00:12:27,760 --> 00:12:33,040
allocation or

00:12:29,760 --> 00:12:36,639
random uh generation

00:12:33,040 --> 00:12:40,480
uh this slide is uh maybe a

00:12:36,639 --> 00:12:43,760
kind of obvious but it's always good to

00:12:40,480 --> 00:12:47,920
see some numbers this uh how

00:12:43,760 --> 00:12:53,839
chelya's handshake impacts the

00:12:47,920 --> 00:12:53,839
hp as transaction performance

00:12:53,920 --> 00:13:02,079
this uh in this slide uh previously we

00:12:58,959 --> 00:13:05,120
discussed uh how the network

00:13:02,079 --> 00:13:05,920
performance differs in open cell case

00:13:05,120 --> 00:13:09,440
and generics

00:13:05,920 --> 00:13:12,720
or for infestations but in this uh

00:13:09,440 --> 00:13:14,079
to see uh how the cryptography

00:13:12,720 --> 00:13:18,160
mathematic uh

00:13:14,079 --> 00:13:20,800
is fast uh this completion of benchmark

00:13:18,160 --> 00:13:22,480
results for openness sale of welfare

00:13:20,800 --> 00:13:25,200
sale and invested areas

00:13:22,480 --> 00:13:26,639
we see that what if we say uh seems the

00:13:25,200 --> 00:13:30,320
fastest one

00:13:26,639 --> 00:13:33,360
uh however this uh this

00:13:30,320 --> 00:13:36,560
question why the cdh are

00:13:33,360 --> 00:13:41,279
so fast than the cdsa

00:13:36,560 --> 00:13:43,680
typically cghe uses

00:13:41,279 --> 00:13:45,279
unknown point multiplication i will

00:13:43,680 --> 00:13:48,480
describe about this

00:13:45,279 --> 00:13:49,600
math a bit later uh it means that each

00:13:48,480 --> 00:13:52,720
cdsa

00:13:49,600 --> 00:13:55,760
uh can be optimized uh for

00:13:52,720 --> 00:13:59,040
uh fixed point multiplication why cdhe

00:13:55,760 --> 00:14:01,519
uh cannot be optimized in this way

00:13:59,040 --> 00:14:03,199
and we actually see for open cell case

00:14:01,519 --> 00:14:06,480
that cgh e

00:14:03,199 --> 00:14:09,519
is much slower than csa however it's

00:14:06,480 --> 00:14:11,920
this not the case for world for sale

00:14:09,519 --> 00:14:12,800
if we look at the temperature numbers

00:14:11,920 --> 00:14:17,120
which is that

00:14:12,800 --> 00:14:20,240
the cgh also slows slower than cdsa

00:14:17,120 --> 00:14:22,240
uh however if we compare uh team pasta

00:14:20,240 --> 00:14:23,680
benchmark results with wordpress cell

00:14:22,240 --> 00:14:28,480
and open cell

00:14:23,680 --> 00:14:31,519
uh actually the results aren't um

00:14:28,480 --> 00:14:33,600
completely fair the reason is that word

00:14:31,519 --> 00:14:36,959
for cell and open cell

00:14:33,600 --> 00:14:40,000
uh measure only uh

00:14:36,959 --> 00:14:43,199
only ecgs uh say sign

00:14:40,000 --> 00:14:46,240
ncdhi uh secret key

00:14:43,199 --> 00:14:49,360
generation but in case of uh

00:14:46,240 --> 00:14:49,760
team pasta benchmark we uh beach markets

00:14:49,360 --> 00:14:52,240
uh

00:14:49,760 --> 00:14:52,959
home mathematic operations involve

00:14:52,240 --> 00:14:56,000
including

00:14:52,959 --> 00:14:59,360
ephemeral case generation uh it's

00:14:56,000 --> 00:15:02,639
maybe uh not so

00:14:59,360 --> 00:15:05,839
dramatic for a cdsa but this

00:15:02,639 --> 00:15:10,639
is absolutely dramatic for a cage in

00:15:05,839 --> 00:15:14,320
ecghj we in our case we

00:15:10,639 --> 00:15:17,279
execute uh as much as uh two more

00:15:14,320 --> 00:15:19,199
uh logic uh as uh in comparison with

00:15:17,279 --> 00:15:22,480
world for cell or openc

00:15:19,199 --> 00:15:26,160
this because uh in our case we have to

00:15:22,480 --> 00:15:30,000
perform uh two point multiplication

00:15:26,160 --> 00:15:35,440
instead of only one uh

00:15:30,000 --> 00:15:35,440
in um mean time while we

00:15:35,519 --> 00:15:41,120
probably were not so bad in uh low uh

00:15:38,880 --> 00:15:42,160
performance uh mathematical performance

00:15:41,120 --> 00:15:44,480
comparison

00:15:42,160 --> 00:15:46,959
against open source and voip said we

00:15:44,480 --> 00:15:49,440
know that our mathematic

00:15:46,959 --> 00:15:50,320
still isn't uh perfect and we need to

00:15:49,440 --> 00:15:54,399
work more

00:15:50,320 --> 00:15:57,199
uh however even if he is not so uh

00:15:54,399 --> 00:15:57,519
super optimized mathematically which is

00:15:57,199 --> 00:15:59,920
that

00:15:57,519 --> 00:16:01,199
investor jls can deliver much more

00:15:59,920 --> 00:16:05,600
performance than

00:16:01,199 --> 00:16:08,800
openness sale uh this uh exactly because

00:16:05,600 --> 00:16:11,199
of reducing memory copies

00:16:08,800 --> 00:16:12,320
contract switches no system calls for

00:16:11,199 --> 00:16:15,120
network io

00:16:12,320 --> 00:16:15,600
less message queues on circuit io and so

00:16:15,120 --> 00:16:17,920
on

00:16:15,600 --> 00:16:19,040
all the things which we discussed on the

00:16:17,920 --> 00:16:23,360
one of the first

00:16:19,040 --> 00:16:26,399
slides with nginx and open cell profiles

00:16:23,360 --> 00:16:30,079
speaking about elliptic of

00:16:26,399 --> 00:16:35,199
mathematics i want to

00:16:30,079 --> 00:16:38,240
reference more is nist elliptic off

00:16:35,199 --> 00:16:41,600
five r256 and this uh very nice

00:16:38,240 --> 00:16:45,440
um uh paper from uh guyron

00:16:41,600 --> 00:16:49,279
and kastnav by 2014.

00:16:45,440 --> 00:16:51,199
it's pretty old however this

00:16:49,279 --> 00:16:52,639
the paper describes the real

00:16:51,199 --> 00:16:56,000
implementation of

00:16:52,639 --> 00:16:59,279
current open cell implementation uh

00:16:56,000 --> 00:17:02,160
in the most simple case uh the most

00:16:59,279 --> 00:17:05,919
expensive operation in elliptic of

00:17:02,160 --> 00:17:09,280
course is uh to multiply uh point p

00:17:05,919 --> 00:17:12,799
on uh scalar m scalar m is always

00:17:09,280 --> 00:17:16,319
a security sensitive for some secret uh

00:17:12,799 --> 00:17:19,360
p uh is secret for ecghe

00:17:16,319 --> 00:17:22,880
and the fixed point for cgsa

00:17:19,360 --> 00:17:26,720
uh in uh the most uh straightforward

00:17:22,880 --> 00:17:30,840
uh algorithm we just iterate each bit of

00:17:26,720 --> 00:17:34,720
the scalar which is uh 256

00:17:30,840 --> 00:17:37,919
bits uh and for each bit we

00:17:34,720 --> 00:17:41,360
perform one point doubling and uh

00:17:37,919 --> 00:17:46,640
one half of the cases we uh perform

00:17:41,360 --> 00:17:49,840
point addition the uh second layer of

00:17:46,640 --> 00:17:50,799
mathematics uh actually there are

00:17:49,840 --> 00:17:54,720
several

00:17:50,799 --> 00:17:57,440
uh layers in mathematic construction the

00:17:54,720 --> 00:17:58,160
first layer is our point multiplication

00:17:57,440 --> 00:18:02,080
the second

00:17:58,160 --> 00:18:05,919
one is point doubling and additional

00:18:02,080 --> 00:18:08,240
uh after that there uh

00:18:05,919 --> 00:18:09,600
we you can make a choice in which

00:18:08,240 --> 00:18:12,960
coordinate system you

00:18:09,600 --> 00:18:15,039
uh you prefer to work uh

00:18:12,960 --> 00:18:16,960
perform a point doubling and radiation

00:18:15,039 --> 00:18:20,160
could be jacobian coordinates

00:18:16,960 --> 00:18:21,200
fin cabinets that schedule coordinates

00:18:20,160 --> 00:18:24,320
and so on

00:18:21,200 --> 00:18:29,360
um and after that uh

00:18:24,320 --> 00:18:33,039
you have uh operations uh

00:18:29,360 --> 00:18:36,160
operations on big integers and they also

00:18:33,039 --> 00:18:39,919
have modular reduction on the top layer

00:18:36,160 --> 00:18:42,320
of algorithms we just saw

00:18:39,919 --> 00:18:43,520
the most straightforward implementation

00:18:42,320 --> 00:18:46,480
however there are

00:18:43,520 --> 00:18:47,200
recent uh research uh exactly in the

00:18:46,480 --> 00:18:50,160
point

00:18:47,200 --> 00:18:51,280
of multiplication however open and cell

00:18:50,160 --> 00:18:54,480
and welfare say

00:18:51,280 --> 00:18:57,200
don't use their approach uh

00:18:54,480 --> 00:18:58,000
point dublin conditions uh seems the

00:18:57,200 --> 00:19:01,039
same for

00:18:58,000 --> 00:19:01,520
all the crypto libraries uh also it

00:19:01,039 --> 00:19:03,600
seems

00:19:01,520 --> 00:19:04,720
all the libraries use jacobian

00:19:03,600 --> 00:19:07,919
coordinates

00:19:04,720 --> 00:19:08,559
and if you use uh jacobian coordinates

00:19:07,919 --> 00:19:11,520
you need

00:19:08,559 --> 00:19:13,360
a modular inversion module inversion is

00:19:11,520 --> 00:19:17,919
the second most expensive

00:19:13,360 --> 00:19:19,360
mathematical operation after a point

00:19:17,919 --> 00:19:22,559
multiplication actually point

00:19:19,360 --> 00:19:26,000
multiplication includes model inversion

00:19:22,559 --> 00:19:28,400
uh and there's also very recent research

00:19:26,000 --> 00:19:31,440
from bench stain about fast model

00:19:28,400 --> 00:19:32,559
uh inversion we use uh this uh

00:19:31,440 --> 00:19:35,919
algorithms

00:19:32,559 --> 00:19:39,280
with some variations after that we

00:19:35,919 --> 00:19:40,799
may decide which uh model reduction we

00:19:39,280 --> 00:19:43,440
can use there

00:19:40,799 --> 00:19:43,840
montgomery reduction used by warfare

00:19:43,440 --> 00:19:46,960
cell

00:19:43,840 --> 00:19:50,559
and open cell and fips

00:19:46,960 --> 00:19:53,679
reduction used originally by mbtlis

00:19:50,559 --> 00:19:56,880
at the moment uh we use fips

00:19:53,679 --> 00:20:00,080
uh model reduction we applied uh

00:19:56,880 --> 00:20:00,640
all the research which we found to speed

00:20:00,080 --> 00:20:04,320
up the

00:20:00,640 --> 00:20:07,440
model reduction uh in particular the

00:20:04,320 --> 00:20:07,919
work from both but it seems this uh dead

00:20:07,440 --> 00:20:10,960
end

00:20:07,919 --> 00:20:12,159
and probably will move to montgomery

00:20:10,960 --> 00:20:15,520
reduction

00:20:12,159 --> 00:20:19,600
at some point um oh

00:20:15,520 --> 00:20:20,720
no mathematic layers and for example if

00:20:19,600 --> 00:20:24,159
you use

00:20:20,720 --> 00:20:28,159
uh first module inversion then uh

00:20:24,159 --> 00:20:31,520
you run less

00:20:28,159 --> 00:20:34,480
scalar multiplication or scalar uh

00:20:31,520 --> 00:20:34,960
squaring in this this algorithms this

00:20:34,480 --> 00:20:38,000
means

00:20:34,960 --> 00:20:41,039
uh in terms that you can

00:20:38,000 --> 00:20:43,520
use different model reduction maybe a

00:20:41,039 --> 00:20:44,320
model reduction with smaller heads than

00:20:43,520 --> 00:20:48,960
montgomery

00:20:44,320 --> 00:20:52,000
but uh costly at the end like fips

00:20:48,960 --> 00:20:52,480
so if you change one of the layer or of

00:20:52,000 --> 00:20:55,440
the

00:20:52,480 --> 00:20:56,880
elliptical algorithms you typically need

00:20:55,440 --> 00:20:59,520
to adjust all the

00:20:56,880 --> 00:21:00,720
layers above and below or this

00:20:59,520 --> 00:21:04,159
particular layer to

00:21:00,720 --> 00:21:08,400
make very balanced and well optimized

00:21:04,159 --> 00:21:11,600
implementation uh for example

00:21:08,400 --> 00:21:14,480
uh as an example of such

00:21:11,600 --> 00:21:15,200
optimization we can consider protection

00:21:14,480 --> 00:21:17,440
against

00:21:15,200 --> 00:21:18,720
side channel attacks there are a number

00:21:17,440 --> 00:21:20,799
of different

00:21:18,720 --> 00:21:22,799
side channel attacks like timing attacks

00:21:20,799 --> 00:21:26,080
power novelizers and so on

00:21:22,799 --> 00:21:28,799
and usually uh cryptography uh

00:21:26,080 --> 00:21:30,159
libraries use different approaches to

00:21:28,799 --> 00:21:33,280
protect against

00:21:30,159 --> 00:21:36,880
such an attack the first one is to use

00:21:33,280 --> 00:21:40,240
and construct constant time algorithms

00:21:36,880 --> 00:21:43,280
by design the second one is to

00:21:40,240 --> 00:21:47,520
have a non-constant time algorithm

00:21:43,280 --> 00:21:50,000
uh into add uh additional damien

00:21:47,520 --> 00:21:50,559
operations which can make the algorithm

00:21:50,000 --> 00:21:53,840
uh

00:21:50,559 --> 00:21:56,240
constant time essentially

00:21:53,840 --> 00:21:57,679
and the last approach is to use uh point

00:21:56,240 --> 00:22:00,880
randomization so

00:21:57,679 --> 00:22:04,000
if we uh randomize our calculations

00:22:00,880 --> 00:22:06,640
then the attacker can cannot uh make

00:22:04,000 --> 00:22:08,559
uh assumption what was the secret

00:22:06,640 --> 00:22:12,080
because we randomized it

00:22:08,559 --> 00:22:15,520
uh and in this point uh for example

00:22:12,080 --> 00:22:19,520
if we uh use the technique for

00:22:15,520 --> 00:22:22,799
model inversion of the benchtime

00:22:19,520 --> 00:22:26,159
benzene algorithm we can

00:22:22,799 --> 00:22:28,559
run up to three times less number of

00:22:26,159 --> 00:22:33,440
iterations in comparison with

00:22:28,559 --> 00:22:33,440
original constant time algorithm

00:22:34,320 --> 00:22:40,960
actually modern cpus

00:22:37,600 --> 00:22:44,480
provide regions insertion

00:22:40,960 --> 00:22:47,600
which allows you uh to get random

00:22:44,480 --> 00:22:51,039
values very very quickly so if we

00:22:47,600 --> 00:22:54,640
uh move from constant time algorithms to

00:22:51,039 --> 00:22:56,000
point randomization point randomization

00:22:54,640 --> 00:23:00,000
and non-constant time

00:22:56,000 --> 00:23:01,280
algorithms uh using the led land

00:23:00,000 --> 00:23:04,960
instructions means that

00:23:01,280 --> 00:23:08,320
tpu can go much much faster

00:23:04,960 --> 00:23:11,440
however unfortunately there are recent

00:23:08,320 --> 00:23:13,440
attacks against their instruction and

00:23:11,440 --> 00:23:16,640
mitigation against their attacks

00:23:13,440 --> 00:23:19,919
cost us about uh 97

00:23:16,640 --> 00:23:24,880
persons of performance

00:23:19,919 --> 00:23:28,400
uh the next topic about

00:23:24,880 --> 00:23:30,960
sca is memory usage actually

00:23:28,400 --> 00:23:31,840
different libraries uh use different

00:23:30,960 --> 00:23:37,280
approaches

00:23:31,840 --> 00:23:40,880
uh to compute for example cdsa

00:23:37,280 --> 00:23:43,360
cgsa actually as i

00:23:40,880 --> 00:23:44,640
mentioned before csa allows you to

00:23:43,360 --> 00:23:47,360
pre-compute

00:23:44,640 --> 00:23:48,559
uh some data for fixed point

00:23:47,360 --> 00:23:52,000
multiplication

00:23:48,559 --> 00:23:55,279
and with uh uses very small uh table

00:23:52,000 --> 00:23:58,320
relatively small of eight uh kilobytes

00:23:55,279 --> 00:23:59,520
and dynamically computed openness cell

00:23:58,320 --> 00:24:02,840
and volt facil

00:23:59,520 --> 00:24:06,159
use very similar tables of 150

00:24:02,840 --> 00:24:08,960
kilobytes and the um

00:24:06,159 --> 00:24:09,919
open cell and the vtls uh uses full

00:24:08,960 --> 00:24:11,440
table scan

00:24:09,919 --> 00:24:13,360
on each iteration of point

00:24:11,440 --> 00:24:14,559
multiplication uh the point

00:24:13,360 --> 00:24:18,080
multiplication algorithm

00:24:14,559 --> 00:24:21,520
uh uses about 36 uh iteration

00:24:18,080 --> 00:24:26,640
it means that all open cell and bts

00:24:21,520 --> 00:24:30,159
uh scans the whole tables about 36

00:24:26,640 --> 00:24:32,720
times uh also vtls uh uses

00:24:30,159 --> 00:24:34,000
uh point randomization uh for more

00:24:32,720 --> 00:24:37,520
security

00:24:34,000 --> 00:24:38,799
but warfare sale uh just uses direct

00:24:37,520 --> 00:24:41,760
access

00:24:38,799 --> 00:24:42,720
uh to the pre-computed values the worst

00:24:41,760 --> 00:24:46,960
thing is that

00:24:42,720 --> 00:24:50,640
uh the table is successful

00:24:46,960 --> 00:24:53,760
depending on the security values of the

00:24:50,640 --> 00:24:57,600
secret it means that uh measuring

00:24:53,760 --> 00:25:00,960
the time of access times

00:24:57,600 --> 00:25:01,679
to the table you can uh you you can

00:25:00,960 --> 00:25:05,760
reveal

00:25:01,679 --> 00:25:09,360
some secret bits from them

00:25:05,760 --> 00:25:12,720
secret scholar and having that

00:25:09,360 --> 00:25:15,600
we use a very large table which is

00:25:12,720 --> 00:25:16,320
much larger than first level of data

00:25:15,600 --> 00:25:20,080
cache

00:25:16,320 --> 00:25:23,600
it's probably not so hard to measure

00:25:20,080 --> 00:25:27,200
different access times uh we

00:25:23,600 --> 00:25:29,039
created a security issue security report

00:25:27,200 --> 00:25:32,240
for world for sale for this

00:25:29,039 --> 00:25:36,000
non-constant time success

00:25:32,240 --> 00:25:38,960
uh one of the uh most uh

00:25:36,000 --> 00:25:40,240
performance uh crucial part of nvidia

00:25:38,960 --> 00:25:43,520
less why it's so

00:25:40,240 --> 00:25:45,400
slow is uh managing uh

00:25:43,520 --> 00:25:46,720
big integer also known as

00:25:45,400 --> 00:25:50,400
multi-precision

00:25:46,720 --> 00:25:53,520
integers uh also we have apis in the

00:25:50,400 --> 00:25:54,960
linux kernel and most of the crypto

00:25:53,520 --> 00:25:58,960
libraries actually use

00:25:54,960 --> 00:26:02,559
uh mpis however opencl wordpress cell

00:25:58,960 --> 00:26:07,279
and current wireguard don't use

00:26:02,559 --> 00:26:10,559
apis and hotpath but embed cos uses

00:26:07,279 --> 00:26:13,600
guys everywhere apis for example

00:26:10,559 --> 00:26:17,039
in our case of ni tl curve

00:26:13,600 --> 00:26:20,480
is a large integer

00:26:17,039 --> 00:26:23,679
of 32 bits which is

00:26:20,480 --> 00:26:26,880
four longs and

00:26:23,679 --> 00:26:30,799
working with mpis you need to manage uh

00:26:26,880 --> 00:26:34,000
the data structure or like allocated

00:26:30,799 --> 00:26:36,640
uh size of buyers how

00:26:34,000 --> 00:26:37,200
or how many actual buyers are used to

00:26:36,640 --> 00:26:40,320
the sign

00:26:37,200 --> 00:26:43,520
and so on uh so

00:26:40,320 --> 00:26:46,159
uh in mbtl yes uh

00:26:43,520 --> 00:26:48,000
well uh elliptic off uh computation

00:26:46,159 --> 00:26:50,559
involves uh hundreds of

00:26:48,000 --> 00:26:52,159
mpis in each round it means that you

00:26:50,559 --> 00:26:54,640
need to

00:26:52,159 --> 00:26:55,360
allocate and then survive hundreds of

00:26:54,640 --> 00:26:58,799
this small

00:26:55,360 --> 00:26:59,600
data data structures so we significantly

00:26:58,799 --> 00:27:02,320
optimized

00:26:59,600 --> 00:27:04,080
a bit less approach by introducing uh

00:27:02,320 --> 00:27:07,840
memory pools

00:27:04,080 --> 00:27:10,640
which are actually just uh like uh

00:27:07,840 --> 00:27:12,640
static uh snapshots of all the

00:27:10,640 --> 00:27:15,840
elliptical computation means that

00:27:12,640 --> 00:27:18,559
at uh startup we allocate uh

00:27:15,840 --> 00:27:20,320
contiguous uh memory pages with all

00:27:18,559 --> 00:27:23,840
allocated and terrorized

00:27:20,320 --> 00:27:24,720
uh mpis and we when we go to handshake

00:27:23,840 --> 00:27:28,480
we just

00:27:24,720 --> 00:27:32,000
uh copy their whole uh pages

00:27:28,480 --> 00:27:35,120
uh in a stream uh fashion instead of

00:27:32,000 --> 00:27:36,480
installizing and copying apis are

00:27:35,120 --> 00:27:39,679
separately

00:27:36,480 --> 00:27:41,120
uh we still use uh memory pools but not

00:27:39,679 --> 00:27:44,240
so heavily because we

00:27:41,120 --> 00:27:47,520
mostly move from mpis to

00:27:44,240 --> 00:27:49,279
low uh integer computations just like

00:27:47,520 --> 00:27:52,080
another

00:27:49,279 --> 00:27:52,640
libraries so we are approaching end of

00:27:52,080 --> 00:27:56,559
this

00:27:52,640 --> 00:27:59,120
presentation with a proposal uh for the

00:27:56,559 --> 00:28:00,320
scanner inclusion of the canon tls

00:27:59,120 --> 00:28:04,000
implementation

00:28:00,320 --> 00:28:07,120
uh this is uh example of proposed api

00:28:04,000 --> 00:28:10,880
for circuit api more details

00:28:07,120 --> 00:28:13,840
will be described in our paper and this

00:28:10,880 --> 00:28:15,520
link to our github issue when we

00:28:13,840 --> 00:28:19,440
appreciate you to

00:28:15,520 --> 00:28:22,480
comment the api design

00:28:19,440 --> 00:28:26,000
and propose some

00:28:22,480 --> 00:28:29,279
additions or requests for the api

00:28:26,000 --> 00:28:33,440
uh typically we propose to

00:28:29,279 --> 00:28:35,039
load public key with a certificate and

00:28:33,440 --> 00:28:38,159
private key using existing

00:28:35,039 --> 00:28:41,679
ad key api so we create

00:28:38,159 --> 00:28:42,640
a separate key link for each pair of

00:28:41,679 --> 00:28:46,000
certificate

00:28:42,640 --> 00:28:49,120
and private key next we

00:28:46,000 --> 00:28:52,080
create a normal uh circuit

00:28:49,120 --> 00:28:52,960
and make a set scope just like contact

00:28:52,080 --> 00:28:56,399
elias

00:28:52,960 --> 00:28:59,520
and in the sets so we point out the

00:28:56,399 --> 00:29:03,200
key required carrying cypher suit

00:28:59,520 --> 00:29:06,480
and the cheerleaders version next accept

00:29:03,200 --> 00:29:08,559
system call will return you not only

00:29:06,480 --> 00:29:10,720
tcp connected circuit but also the

00:29:08,559 --> 00:29:13,919
socket with

00:29:10,720 --> 00:29:17,520
established uh cls connection this

00:29:13,919 --> 00:29:21,279
uh question how to fall back

00:29:17,520 --> 00:29:24,960
uh from uh if we not able to

00:29:21,279 --> 00:29:27,039
uh establish uh handshake to user space

00:29:24,960 --> 00:29:28,880
about this night and so on the other

00:29:27,039 --> 00:29:32,640
that will be described in

00:29:28,880 --> 00:29:36,159
paper and in github issue

00:29:32,640 --> 00:29:39,360
uh we propose the server side only

00:29:36,159 --> 00:29:42,480
implementation because servers are

00:29:39,360 --> 00:29:46,240
it seems uh service will benefit uh

00:29:42,480 --> 00:29:49,360
mostly from the uh in kernel inclusion

00:29:46,240 --> 00:29:51,919
uh next we propose to

00:29:49,360 --> 00:29:53,760
uh perform future less handshakes in

00:29:51,919 --> 00:29:57,760
software queue just like

00:29:53,760 --> 00:30:00,320
tcp handshakes this will improve

00:29:57,760 --> 00:30:01,360
overall throughput and reduce the

00:30:00,320 --> 00:30:06,159
latency

00:30:01,360 --> 00:30:06,159
and also while uh soft eq

00:30:06,399 --> 00:30:11,440
bypasses a bunch of network packets we

00:30:08,960 --> 00:30:14,960
can make only one fpu context

00:30:11,440 --> 00:30:18,080
uh uh storing and uh restoring

00:30:14,960 --> 00:30:19,440
and concepts of uh for the whole a batch

00:30:18,080 --> 00:30:22,480
of

00:30:19,440 --> 00:30:25,679
jls handshakes we made the

00:30:22,480 --> 00:30:28,880
micro benchmark uh showing how important

00:30:25,679 --> 00:30:31,919
uh to make exactly one uh fpu

00:30:28,880 --> 00:30:36,640
uh save and restore for batch of

00:30:31,919 --> 00:30:40,000
uh network packets uh in software queue

00:30:36,640 --> 00:30:43,039
session so it's just

00:30:40,000 --> 00:30:46,159
have no point to

00:30:43,039 --> 00:30:49,840
to save and restore fpu context

00:30:46,159 --> 00:30:53,039
for each packets or each uh

00:30:49,840 --> 00:30:57,200
jls handshake message

00:30:53,039 --> 00:31:00,640
um actually most of the code uh

00:30:57,200 --> 00:31:04,080
for charis can shakes can be found in uh

00:31:00,640 --> 00:31:06,399
current kernel linux kernel

00:31:04,080 --> 00:31:07,519
uh for example this symmetric keys

00:31:06,399 --> 00:31:11,120
management this

00:31:07,519 --> 00:31:14,399
ad key api the curve uh

00:31:11,120 --> 00:31:18,000
25 5 19 sa

00:31:14,399 --> 00:31:20,640
and maybe almost all

00:31:18,000 --> 00:31:21,279
the symmetric uh crypto algorithms are

00:31:20,640 --> 00:31:24,399
already in

00:31:21,279 --> 00:31:27,760
the linux girl so it uh allows us

00:31:24,399 --> 00:31:30,000
to introduce only about thirteen

00:31:27,760 --> 00:31:33,519
thousand lines of code official

00:31:30,000 --> 00:31:38,240
uh cherry state machine cherries tickets

00:31:33,519 --> 00:31:42,000
the nist elliptic roof and the

00:31:38,240 --> 00:31:42,000
logic for cyphex fields

00:31:42,640 --> 00:31:49,760
so before going to upstream we

00:31:46,080 --> 00:31:53,679
are planning to finish this uh tasks

00:31:49,760 --> 00:31:56,480
the first one is to finish our

00:31:53,679 --> 00:31:57,519
work with performance optimization of an

00:31:56,480 --> 00:32:00,640
ict

00:31:57,519 --> 00:32:04,559
carve the second one is we

00:32:00,640 --> 00:32:07,919
want to go to upstream with tls 1.3

00:32:04,559 --> 00:32:10,320
and also this task to

00:32:07,919 --> 00:32:11,440
match our current hls implementation

00:32:10,320 --> 00:32:13,519
with the kernel

00:32:11,440 --> 00:32:14,880
asymmetric keys api because at the

00:32:13,519 --> 00:32:18,640
moment this

00:32:14,880 --> 00:32:21,760
wasn't done yet uh that's all we love

00:32:18,640 --> 00:32:22,559
to hear from you or if you can benefit

00:32:21,760 --> 00:32:26,159
from

00:32:22,559 --> 00:32:29,039
uh the kernel jellies handshakes

00:32:26,159 --> 00:32:29,919
in particular uh if you can benefit even

00:32:29,039 --> 00:32:32,640
on

00:32:29,919 --> 00:32:33,360
one point uh two uh challenges can

00:32:32,640 --> 00:32:36,960
checks and

00:32:33,360 --> 00:32:40,080
don't need 1.3 uh also

00:32:36,960 --> 00:32:41,519
we'd love to see your feedback about our

00:32:40,080 --> 00:32:44,320
api

00:32:41,519 --> 00:32:46,000
some implementation requests and so on

00:32:44,320 --> 00:32:49,519
and also we will

00:32:46,000 --> 00:32:53,200
happy to receive your questions on

00:32:49,519 --> 00:32:57,840
our email or github so that's all

00:32:53,200 --> 00:32:57,840
thank you

00:32:58,080 --> 00:33:04,559
okay uh thank you uh

00:33:01,120 --> 00:33:07,120
so looks like i don't see any questions

00:33:04,559 --> 00:33:07,760
um if anyone has any i'll give a few

00:33:07,120 --> 00:33:11,600
seconds

00:33:07,760 --> 00:33:14,720
but um we'll go ahead and proceed to the

00:33:11,600 --> 00:33:14,720
next talk otherwise

00:33:17,039 --> 00:33:25,120
um i just have a comment from

00:33:21,279 --> 00:33:28,720
um from our side that uh unfortunately

00:33:25,120 --> 00:33:32,080
i had not enough time to uh

00:33:28,720 --> 00:33:35,679
say speak more about uh the circuit

00:33:32,080 --> 00:33:36,159
api proposal for cannot s uh handshakes

00:33:35,679 --> 00:33:39,279
so

00:33:36,159 --> 00:33:42,399
i appreciate if you can visit our github

00:33:39,279 --> 00:33:45,519
issue one for free free uh

00:33:42,399 --> 00:33:48,000
to comment and read more about the uh

00:33:45,519 --> 00:33:48,720
particular technical proposal for the

00:33:48,000 --> 00:33:50,880
api

00:33:48,720 --> 00:33:52,720
the commands are very important for us

00:33:50,880 --> 00:33:55,840
to make the right

00:33:52,720 --> 00:33:58,799
design of the api and

00:33:55,840 --> 00:34:00,640
may make something useful for other

00:33:58,799 --> 00:34:02,399
people

00:34:00,640 --> 00:34:04,799
so uh what forum do you think the

00:34:02,399 --> 00:34:05,120
discussion would take place on the apis

00:34:04,799 --> 00:34:08,560
is

00:34:05,120 --> 00:34:10,560
this one netdev or somewhere else uh we

00:34:08,560 --> 00:34:11,839
we had uh internally we had a lot of

00:34:10,560 --> 00:34:15,679
discussions about

00:34:11,839 --> 00:34:18,480
uh which features of uh can shakes we

00:34:15,679 --> 00:34:20,079
have to support for example uh how to

00:34:18,480 --> 00:34:23,679
manage snipes

00:34:20,079 --> 00:34:26,399
uh how uh how snice should be matched

00:34:23,679 --> 00:34:27,919
uh we propose cbpf for custom matching

00:34:26,399 --> 00:34:30,960
for snice

00:34:27,919 --> 00:34:34,399
uh there are many issues with uh

00:34:30,960 --> 00:34:37,919
js api like uh

00:34:34,399 --> 00:34:41,679
sometimes for the same s9 you need to

00:34:37,919 --> 00:34:42,720
load different um certificates and

00:34:41,679 --> 00:34:46,320
private key

00:34:42,720 --> 00:34:49,440
in the case if the size

00:34:46,320 --> 00:34:53,119
size certificate was revoked

00:34:49,440 --> 00:34:55,359
so uh if we speak on engineering level

00:34:53,119 --> 00:34:56,320
uh probably it's not so complex but

00:34:55,359 --> 00:34:59,760
overall

00:34:56,320 --> 00:35:01,760
api and the the features to support

00:34:59,760 --> 00:35:03,920
uh certificates management they are

00:35:01,760 --> 00:35:08,079
quite complex

00:35:03,920 --> 00:35:10,160
okay so uh so we'll look for that

00:35:08,079 --> 00:35:11,839
but let's go ahead and move on to the

00:35:10,160 --> 00:35:17,599
next talk thank you

00:35:11,839 --> 00:35:17,599

YouTube URL: https://www.youtube.com/watch?v=THJ6zC1V10c


