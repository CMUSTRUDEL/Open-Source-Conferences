Title: Netdev 0x14 - Evaluating BBRv2 on the Edge
Publication date: 2021-02-04
Playlist: Netdev 0x14
Description: 
	Speaker: Alexey Ivanov

More info: https://netdevconf.info/0x14/session.html?talk-evaluating-BBRv2-on-the-edge

Date: Thursday, August 13, 2020

Alexey Ivanov will discuss evaluation of TCP BBRv2
on the Dropbox Edge Network. 

Alexey will dissect BBR design principles and discuss whether
the intended theoretical goals match real world results.
He will then dig into the BBRv2 design and discuss the intended 
improvements over BBRv1. Eventually, using practical examples,
compare the behaviors of BBRv2 vs BBRv1 vs CUBIC as applied to
an edge network.
Captions: 
	00:00:02,480 --> 00:00:05,600
hi um

00:00:03,280 --> 00:00:06,319
my name is alexi i and today i'm going

00:00:05,600 --> 00:00:09,920
to talk about

00:00:06,319 --> 00:00:12,719
uh evaluating bbr v2 on badge

00:00:09,920 --> 00:00:14,400
so i'm an infrastructure engineer i work

00:00:12,719 --> 00:00:17,039
at dropbox previously i've worked at

00:00:14,400 --> 00:00:20,240
linkedin and yandex i was working on

00:00:17,039 --> 00:00:23,359
databases storage systems and right now

00:00:20,240 --> 00:00:25,680
on traffic slash networking so

00:00:23,359 --> 00:00:26,480
um we talked a lot in our tech blog

00:00:25,680 --> 00:00:30,240
about

00:00:26,480 --> 00:00:33,280
all the optimizations that we do to our

00:00:30,240 --> 00:00:35,680
traffic stack from like lower levels uh

00:00:33,280 --> 00:00:36,880
on operating system driver side to a

00:00:35,680 --> 00:00:38,960
higher level of

00:00:36,880 --> 00:00:40,239
intelligent dns routing and library

00:00:38,960 --> 00:00:43,440
optimizations

00:00:40,239 --> 00:00:46,000
uh but uh our team is very small and

00:00:43,440 --> 00:00:48,239
we don't have a dedicated uh kernel

00:00:46,000 --> 00:00:50,800
engineers we don't even have kernel team

00:00:48,239 --> 00:00:52,239
currently uh but we really like to

00:00:50,800 --> 00:00:52,800
experiment with different types of

00:00:52,239 --> 00:00:55,680
things

00:00:52,800 --> 00:00:57,120
and these talk will be about one of

00:00:55,680 --> 00:01:00,399
these experiments

00:00:57,120 --> 00:01:03,359
so it's all started with bbr v1

00:01:00,399 --> 00:01:04,159
when we tried out hot new congestion

00:01:03,359 --> 00:01:08,240
control thing

00:01:04,159 --> 00:01:11,119
back in 2007 so

00:01:08,240 --> 00:01:12,000
our first experiment was bbr v1 showed

00:01:11,119 --> 00:01:15,520
great results

00:01:12,000 --> 00:01:17,119
we saw uh so the users that we thought

00:01:15,520 --> 00:01:21,040
were actually bottlenecked by

00:01:17,119 --> 00:01:23,520
their um internet connection

00:01:21,040 --> 00:01:24,720
actually happened to be uh bottlenecked

00:01:23,520 --> 00:01:26,960
on the

00:01:24,720 --> 00:01:28,000
our congestion control and when we

00:01:26,960 --> 00:01:30,479
rolled out um

00:01:28,000 --> 00:01:31,840
bbr we won which we we seen great

00:01:30,479 --> 00:01:34,560
results from

00:01:31,840 --> 00:01:35,680
uh that was a very interesting food for

00:01:34,560 --> 00:01:38,079
thought

00:01:35,680 --> 00:01:41,280
and eventually we rolled out bbr we want

00:01:38,079 --> 00:01:44,000
to our whole edge network

00:01:41,280 --> 00:01:45,439
over time though we saw some downsides

00:01:44,000 --> 00:01:48,479
of bbr v1

00:01:45,439 --> 00:01:51,119
um mainly uh probably all of you

00:01:48,479 --> 00:01:52,240
know that it's not very fair to the rest

00:01:51,119 --> 00:01:55,520
of congestion control

00:01:52,240 --> 00:01:55,920
algorithms it has an insane packet loss

00:01:55,520 --> 00:01:59,439
of

00:01:55,920 --> 00:02:03,040
up to six percent we saw in our boxes um

00:01:59,439 --> 00:02:05,840
like all all the downsides started to be

00:02:03,040 --> 00:02:06,560
more and more apparent now still a good

00:02:05,840 --> 00:02:09,599
benefit

00:02:06,560 --> 00:02:13,599
in uh performance so

00:02:09,599 --> 00:02:15,680
bbr developers also notice that so

00:02:13,599 --> 00:02:17,280
that is a list of issues with bbr we

00:02:15,680 --> 00:02:21,760
want straight from the

00:02:17,280 --> 00:02:22,080
developers uh so they've identified um

00:02:21,760 --> 00:02:24,080
uh

00:02:22,080 --> 00:02:25,360
unfairness of bbr we want they've

00:02:24,080 --> 00:02:28,800
identified

00:02:25,360 --> 00:02:32,959
its aggressiveness um also some issues

00:02:28,800 --> 00:02:35,360
in aggregated parts when there is

00:02:32,959 --> 00:02:36,640
aggregations and of course no support

00:02:35,360 --> 00:02:40,640
for ecm

00:02:36,640 --> 00:02:43,519
so they started to address that

00:02:40,640 --> 00:02:45,120
before we jump into the experimental

00:02:43,519 --> 00:02:48,800
results couple of caveats

00:02:45,120 --> 00:02:51,120
about uh all of you who own production

00:02:48,800 --> 00:02:53,680
systems just well we probably know but

00:02:51,120 --> 00:02:56,160
just want to repeat it uh please upgrade

00:02:53,680 --> 00:02:59,440
your kernels if you

00:02:56,160 --> 00:03:02,000
uh support any uh operate any production

00:02:59,440 --> 00:03:02,800
networks like new kernel usually gives a

00:03:02,000 --> 00:03:04,159
lot of

00:03:02,800 --> 00:03:06,720
performance so the best thing for

00:03:04,159 --> 00:03:07,200
performance uh is usually upgrading your

00:03:06,720 --> 00:03:08,319
kernel

00:03:07,200 --> 00:03:09,920
of course there are occasional

00:03:08,319 --> 00:03:11,519
regressions there are new

00:03:09,920 --> 00:03:13,280
vulnerabilities that are getting

00:03:11,519 --> 00:03:15,440
mitigated with new kernels and

00:03:13,280 --> 00:03:18,159
occasional slowdowns from networking

00:03:15,440 --> 00:03:20,480
perspective um

00:03:18,159 --> 00:03:23,519
each new kernel is generally faster than

00:03:20,480 --> 00:03:26,799
the previous one here is an example how

00:03:23,519 --> 00:03:30,560
uh just for upgrading from our

00:03:26,799 --> 00:03:32,879
main production kernel 415 to 5.3

00:03:30,560 --> 00:03:34,239
test kernel that we used for bbr we do

00:03:32,879 --> 00:03:36,799
test we got

00:03:34,239 --> 00:03:37,440
around 15 percent performance across 15

00:03:36,799 --> 00:03:40,480
00:03:37,440 --> 00:03:42,640
performance increase just for free uh

00:03:40,480 --> 00:03:44,000
but that most likely related to

00:03:42,640 --> 00:03:47,440
improvements to bdr v1 and

00:03:44,000 --> 00:03:49,200
uh like uh they've added optimizations

00:03:47,440 --> 00:03:51,200
for wi-fi and aggregation but

00:03:49,200 --> 00:03:52,640
uh regardless each new kernel the

00:03:51,200 --> 00:03:55,680
initial art test

00:03:52,640 --> 00:03:58,159
usually performs better uh second

00:03:55,680 --> 00:04:01,040
upgrading your user space so if you

00:03:58,159 --> 00:04:01,519
operate again any product any large

00:04:01,040 --> 00:04:04,560
scale

00:04:01,519 --> 00:04:06,720
networks having

00:04:04,560 --> 00:04:07,599
new user space helps a lot with

00:04:06,720 --> 00:04:11,280
troubleshooting

00:04:07,599 --> 00:04:14,319
for example uh here is a ipr

00:04:11,280 --> 00:04:17,519
ip route that comes with ubuntu 16

00:04:14,319 --> 00:04:20,239
and that is a relatively new ip route

00:04:17,519 --> 00:04:21,440
just notice that like all the new fields

00:04:20,239 --> 00:04:25,520
that we have

00:04:21,440 --> 00:04:27,280
um it's essential for troubleshooting

00:04:25,520 --> 00:04:29,199
especially any performance issues so in

00:04:27,280 --> 00:04:30,880
the ui for example we see all the

00:04:29,199 --> 00:04:33,759
internal bbr data

00:04:30,880 --> 00:04:34,560
uh like basin gain and estimated mean

00:04:33,759 --> 00:04:37,440
rtt

00:04:34,560 --> 00:04:39,040
uh to worry very very useful things like

00:04:37,440 --> 00:04:40,840
how much time you spend being

00:04:39,040 --> 00:04:42,160
receiving the limited send window

00:04:40,840 --> 00:04:46,160
limited um

00:04:42,160 --> 00:04:48,400
like that is uh generally

00:04:46,160 --> 00:04:50,639
a very useful tools for you to be able

00:04:48,400 --> 00:04:54,000
to troubleshoot any issues with

00:04:50,639 --> 00:04:56,160
this performance and third one uh fair q

00:04:54,000 --> 00:04:56,800
and scheduler please use first human

00:04:56,160 --> 00:04:59,919
scheduler

00:04:56,800 --> 00:05:01,520
if you can um it's not for fair queue in

00:04:59,919 --> 00:05:03,840
itself it's mostly for

00:05:01,520 --> 00:05:06,000
pacing pacing is very important in the

00:05:03,840 --> 00:05:09,199
modern network especially high speed

00:05:06,000 --> 00:05:10,960
um and there is a lot of

00:05:09,199 --> 00:05:12,479
symmetry between your speeds and your

00:05:10,960 --> 00:05:16,160
client speeds uh

00:05:12,479 --> 00:05:19,280
we he and even within the bank bond so

00:05:16,160 --> 00:05:20,320
um there is great talk from uh bond

00:05:19,280 --> 00:05:22,639
jakobson

00:05:20,320 --> 00:05:25,280
about beyond as fast as possible that

00:05:22,639 --> 00:05:26,320
sending data as fast as possible is not

00:05:25,280 --> 00:05:29,360
actually the

00:05:26,320 --> 00:05:30,320
uh in theory it's not actually the best

00:05:29,360 --> 00:05:34,880
thing you can do

00:05:30,320 --> 00:05:34,880
but in practice it also like

00:05:36,400 --> 00:05:39,759
there isn't any girl for example from

00:05:38,000 --> 00:05:42,320
our production network when we

00:05:39,759 --> 00:05:44,240
uh saw a lot like packet drops were a

00:05:42,320 --> 00:05:46,880
large problem in our networks and

00:05:44,240 --> 00:05:48,400
uh our network engineering actually

00:05:46,880 --> 00:05:50,320
wanted to replace some of the shallow

00:05:48,400 --> 00:05:53,440
buffer switches with the more

00:05:50,320 --> 00:05:54,639
um advanced ones uh with uh larger

00:05:53,440 --> 00:05:57,759
buffer spaces but

00:05:54,639 --> 00:05:58,240
just by rolling out fq we get rid of all

00:05:57,759 --> 00:06:00,720
these

00:05:58,240 --> 00:06:01,280
drops even on the backbone when there is

00:06:00,720 --> 00:06:04,479
not

00:06:01,280 --> 00:06:07,680
as much uh speedy symmetry

00:06:04,479 --> 00:06:10,160
anyway um use fq fq uh

00:06:07,680 --> 00:06:12,000
can actually improve your packet loss

00:06:10,160 --> 00:06:15,520
quite a bit

00:06:12,000 --> 00:06:16,880
uh and before we jump into experimental

00:06:15,520 --> 00:06:19,120
results of bbr v2

00:06:16,880 --> 00:06:20,160
a couple of disclaimers and the test

00:06:19,120 --> 00:06:23,120
setup

00:06:20,160 --> 00:06:25,280
so first of all it's not a low latency

00:06:23,120 --> 00:06:26,080
experiment all our flows that we were

00:06:25,280 --> 00:06:29,600
examining

00:06:26,080 --> 00:06:32,080
were around were filtered by

00:06:29,600 --> 00:06:33,600
one megabyte of transfer data so this is

00:06:32,080 --> 00:06:36,560
high throughput bulk

00:06:33,600 --> 00:06:38,639
bulk flows uh second data is heavily

00:06:36,560 --> 00:06:39,840
aggregated there are no like single tcp

00:06:38,639 --> 00:06:42,240
dump slash tcp

00:06:39,840 --> 00:06:43,919
trace drill downs uh we have millions

00:06:42,240 --> 00:06:47,280
and millions of connections

00:06:43,919 --> 00:06:49,360
um so data is heavily aggregated

00:06:47,280 --> 00:06:50,800
and of course that is the real

00:06:49,360 --> 00:06:54,639
production test so

00:06:50,800 --> 00:06:57,599
all the imperfections of traffic uh be

00:06:54,639 --> 00:06:59,520
like duplicated packets real heavy

00:06:57,599 --> 00:07:01,520
reordering passwords high packet loss

00:06:59,520 --> 00:07:03,520
everything will be present in that uh

00:07:01,520 --> 00:07:05,039
in that data set it's a real production

00:07:03,520 --> 00:07:08,319
traffic

00:07:05,039 --> 00:07:10,080
uh even more specifically we used one

00:07:08,319 --> 00:07:12,880
single pop in tokyo

00:07:10,080 --> 00:07:15,199
four boxes in it uh three one boxes with

00:07:12,880 --> 00:07:18,319
all the kernel all bbr we want

00:07:15,199 --> 00:07:20,560
and three boxes with the new kernel with

00:07:18,319 --> 00:07:23,360
cubic bbr v1 and bbr return

00:07:20,560 --> 00:07:24,400
again only bulk flows uh and we were

00:07:23,360 --> 00:07:27,520
looking at

00:07:24,400 --> 00:07:31,840
sampled ss data and sampled

00:07:27,520 --> 00:07:34,080
nginx logs

00:07:31,840 --> 00:07:36,560
yep that's pretty much all of it uh

00:07:34,080 --> 00:07:37,360
we'll be covering only new kernels uh

00:07:36,560 --> 00:07:39,840
from now on

00:07:37,360 --> 00:07:41,039
uh comparison between all the new kernel

00:07:39,840 --> 00:07:43,280
bbr v1 code

00:07:41,039 --> 00:07:45,440
i've showed previously so now we will be

00:07:43,280 --> 00:07:48,479
only looking at 5.3

00:07:45,440 --> 00:07:49,520
um yeah so sorry the kernel is a bit too

00:07:48,479 --> 00:07:51,919
old at that point

00:07:49,520 --> 00:07:52,879
the presentation was for the first um

00:07:51,919 --> 00:07:58,160
first version of

00:07:52,879 --> 00:08:01,520
um not conference

00:07:58,160 --> 00:08:02,879
okay so and again before we jump into

00:08:01,520 --> 00:08:05,919
the

00:08:02,879 --> 00:08:07,440
uh practical results a bit of theory so

00:08:05,919 --> 00:08:08,319
that slide is straight from neil's

00:08:07,440 --> 00:08:11,599
presentation

00:08:08,319 --> 00:08:15,120
from ietf um

00:08:11,599 --> 00:08:19,120
it shows pbr design principles with

00:08:15,120 --> 00:08:20,800
all the new stuff from bbrv2 in bold

00:08:19,120 --> 00:08:24,400
you can see that uh there is a lot of

00:08:20,800 --> 00:08:27,759
stuff but the general idea is

00:08:24,400 --> 00:08:29,440
twofold first make it fair uh make it

00:08:27,759 --> 00:08:32,399
more fair uh fairer to

00:08:29,440 --> 00:08:32,880
other congestion control protocols uh

00:08:32,399 --> 00:08:36,320
and

00:08:32,880 --> 00:08:40,640
uh put some notion of

00:08:36,320 --> 00:08:44,159
packet loss into the model so uh do uh

00:08:40,640 --> 00:08:47,760
react quickly to change in conditions so

00:08:44,159 --> 00:08:50,000
these are two things and we'll see um

00:08:47,760 --> 00:08:51,600
we'll see how it actually affects

00:08:50,000 --> 00:08:52,560
experimental results here here is a

00:08:51,600 --> 00:08:56,640
comparison

00:08:52,560 --> 00:08:58,800
from between bbr v1 and vbrv2

00:08:56,640 --> 00:09:00,640
in a more table format so we can see

00:08:58,800 --> 00:09:02,959
that there are no new additions

00:09:00,640 --> 00:09:02,959
to the

00:09:04,399 --> 00:09:10,560
network model itself there is uh

00:09:07,680 --> 00:09:12,160
finally the explicit loss targets and

00:09:10,560 --> 00:09:14,160
early exit from startup

00:09:12,160 --> 00:09:17,040
if these loss targets are either

00:09:14,160 --> 00:09:19,760
explicit or implicit are broken

00:09:17,040 --> 00:09:20,640
okay and ecn we did not test the cnn in

00:09:19,760 --> 00:09:24,080
our test but

00:09:20,640 --> 00:09:24,959
uh it seems like bbr v2 can be a drop-in

00:09:24,080 --> 00:09:28,959
replacement

00:09:24,959 --> 00:09:32,880
for uh dc-tcp but who knows

00:09:28,959 --> 00:09:34,080
okay now uh we jump into all the graphs

00:09:32,880 --> 00:09:36,640
so first we're gonna

00:09:34,080 --> 00:09:37,839
go over properties that we see on the

00:09:36,640 --> 00:09:40,480
link and then we

00:09:37,839 --> 00:09:41,680
will jump into what it how does it

00:09:40,480 --> 00:09:44,480
actually affect

00:09:41,680 --> 00:09:45,680
the throughput uh throughput that we see

00:09:44,480 --> 00:09:48,000
on the link

00:09:45,680 --> 00:09:50,080
so first thing that we do even without

00:09:48,000 --> 00:09:53,680
like uh

00:09:50,080 --> 00:09:56,399
first thing that we noticed even without

00:09:53,680 --> 00:09:58,399
actually looking at this uh per

00:09:56,399 --> 00:09:59,440
connection status is that when we deploy

00:09:58,399 --> 00:10:02,560
bbr

00:09:59,440 --> 00:10:02,959
uh to code we see way lower packet loss

00:10:02,560 --> 00:10:06,000
so

00:10:02,959 --> 00:10:09,200
immediately packet loss drops a lot

00:10:06,000 --> 00:10:12,480
uh it's still higher than cubic uh

00:10:09,200 --> 00:10:18,880
but i assume that that is expected

00:10:12,480 --> 00:10:22,399
uh if we look deeper into our

00:10:18,880 --> 00:10:23,519
retransmission percentage we uh on per

00:10:22,399 --> 00:10:27,839
connection level

00:10:23,519 --> 00:10:31,200
so we see that generally bbr v2

00:10:27,839 --> 00:10:32,480
looks way better on pdf graphs the only

00:10:31,200 --> 00:10:35,440
caveat is

00:10:32,480 --> 00:10:37,360
there are some connections that are that

00:10:35,440 --> 00:10:41,360
have higher pocket loss at 60

00:10:37,360 --> 00:10:43,760
sometimes 80 or even 90. so there is

00:10:41,360 --> 00:10:46,800
something is definitely wrong there

00:10:43,760 --> 00:10:49,440
beside that a small percentage of

00:10:46,800 --> 00:10:50,640
connections with really bad packet loss

00:10:49,440 --> 00:10:54,000
everything else

00:10:50,640 --> 00:10:56,079
looks uh looks really good i would

00:10:54,000 --> 00:10:57,120
suspect some kind of bug there but i'm

00:10:56,079 --> 00:11:00,560
not sure

00:10:57,120 --> 00:11:03,680
uh if we compare to cubic

00:11:00,560 --> 00:11:06,240
bbr v2 has still higher connect packet

00:11:03,680 --> 00:11:09,519
loss on

00:11:06,240 --> 00:11:11,920
cubic on per connection bases

00:11:09,519 --> 00:11:12,560
still i would assume that is expected

00:11:11,920 --> 00:11:15,680
given

00:11:12,560 --> 00:11:18,240
its tolerance to some packet loss so

00:11:15,680 --> 00:11:19,200
since it has that packet loss uh target

00:11:18,240 --> 00:11:21,279
i would assume

00:11:19,200 --> 00:11:22,399
it is fine for it to have higher packet

00:11:21,279 --> 00:11:26,240
loss except for that

00:11:22,399 --> 00:11:29,120
60 percent case and above if we look at

00:11:26,240 --> 00:11:29,760
uh heat map of that we can see that the

00:11:29,120 --> 00:11:33,600
vbr

00:11:29,760 --> 00:11:34,399
um we v1 on the top v2 on the bottom

00:11:33,600 --> 00:11:37,440
it's more

00:11:34,399 --> 00:11:37,920
v2 is more squashed along all rtt so

00:11:37,440 --> 00:11:40,959
it's not

00:11:37,920 --> 00:11:43,360
um it's very fairly

00:11:40,959 --> 00:11:44,480
distributed so there is no uh

00:11:43,360 --> 00:11:47,600
correlation between like

00:11:44,480 --> 00:11:52,079
packet loss and um

00:11:47,600 --> 00:11:55,440
and rtt then we can look into in-flight

00:11:52,079 --> 00:11:59,440
packets and we see that bbr v1

00:11:55,440 --> 00:11:59,440
way less packets in fly

00:11:59,680 --> 00:12:03,760
that is actually one of the properties

00:12:03,360 --> 00:12:07,440
of

00:12:03,760 --> 00:12:10,560
bbr v2 model so they have max

00:12:07,440 --> 00:12:11,920
max in flight now and that in theory

00:12:10,560 --> 00:12:13,519
that should be

00:12:11,920 --> 00:12:15,279
like that and in private practice

00:12:13,519 --> 00:12:18,320
actually prove that

00:12:15,279 --> 00:12:19,120
uh what's even more interesting that bbr

00:12:18,320 --> 00:12:22,160
v2 has

00:12:19,120 --> 00:12:24,000
less packets in flight than cubic which

00:12:22,160 --> 00:12:27,680
makes it better which is quite

00:12:24,000 --> 00:12:28,399
uh quite interesting so less buffer

00:12:27,680 --> 00:12:32,079
bloat from

00:12:28,399 --> 00:12:32,079
um bbr v2

00:12:32,160 --> 00:12:38,800
if we plot uh rtt versus in flight

00:12:35,680 --> 00:12:39,440
in bbr v2 we can see that general upward

00:12:38,800 --> 00:12:42,560
trend with

00:12:39,440 --> 00:12:46,639
more like data on the wire depending on

00:12:42,560 --> 00:12:50,399
rtt uh and

00:12:46,639 --> 00:12:51,600
in we v2 we can actually see it more

00:12:50,399 --> 00:12:55,279
down to earth

00:12:51,600 --> 00:12:58,639
there is one line a strange line that um

00:12:55,279 --> 00:13:00,880
dependency between uh rtt and uh

00:12:58,639 --> 00:13:02,000
in flight segments which which looks

00:13:00,880 --> 00:13:04,240
very besides that

00:13:02,000 --> 00:13:05,200
it's all squished normally distributed

00:13:04,240 --> 00:13:08,320
and if we

00:13:05,200 --> 00:13:10,320
compare it to uh cubic when we

00:13:08,320 --> 00:13:11,440
we can see that it's still better it's

00:13:10,320 --> 00:13:14,000
more uh

00:13:11,440 --> 00:13:15,120
more down to earth so uh even compared

00:13:14,000 --> 00:13:19,040
to cubic in flight

00:13:15,120 --> 00:13:20,720
looks way better on rtt wise we did not

00:13:19,040 --> 00:13:23,200
look in rtt too much because

00:13:20,720 --> 00:13:24,560
these are about flows but since we still

00:13:23,200 --> 00:13:28,399
collected that data

00:13:24,560 --> 00:13:30,160
uh we know that bbr v2 rtts are better

00:13:28,399 --> 00:13:33,200
than bbr v1

00:13:30,160 --> 00:13:33,680
uh based on pdfs and but still worse

00:13:33,200 --> 00:13:37,120
than

00:13:33,680 --> 00:13:38,959
cubic for some reason that may be uh

00:13:37,120 --> 00:13:40,639
some bug in our code because we see

00:13:38,959 --> 00:13:42,880
lower in flight but for some reason

00:13:40,639 --> 00:13:45,279
rtt's are

00:13:42,880 --> 00:13:47,360
uh are higher from our uh from our

00:13:45,279 --> 00:13:49,360
perspective

00:13:47,360 --> 00:13:51,600
oh one one more interesting graph is

00:13:49,360 --> 00:13:53,040
about receive window limiter that's in

00:13:51,600 --> 00:13:56,079
that new start from new

00:13:53,040 --> 00:13:59,279
uh ip route uh version ss version

00:13:56,079 --> 00:14:02,800
we see that uh dbrv

00:13:59,279 --> 00:14:06,240
2 is way uh way less

00:14:02,800 --> 00:14:07,519
less often window uh limited receiving

00:14:06,240 --> 00:14:09,920
delimited

00:14:07,519 --> 00:14:11,920
which is also great that means we burst

00:14:09,920 --> 00:14:14,800
less on the wire

00:14:11,920 --> 00:14:15,519
and uh leave some headroom which which

00:14:14,800 --> 00:14:18,880
is good

00:14:15,519 --> 00:14:22,240
a it even less received window limited

00:14:18,880 --> 00:14:26,240
than uh cubic which is again uh

00:14:22,240 --> 00:14:29,600
quite quite good we burst less

00:14:26,240 --> 00:14:32,000
we buffer below at less

00:14:29,600 --> 00:14:33,839
so all of these theoretical properties

00:14:32,000 --> 00:14:35,600
lead to some interesting practical

00:14:33,839 --> 00:14:38,320
results in terms of bandwidth so

00:14:35,600 --> 00:14:38,800
what we saw is all different facets of

00:14:38,320 --> 00:14:40,560
the

00:14:38,800 --> 00:14:42,320
of the traffic and now we can actually

00:14:40,560 --> 00:14:45,440
see what what the bandwidth

00:14:42,320 --> 00:14:49,279
looks like and bandwidth wise uh

00:14:45,440 --> 00:14:53,360
bbr v2 is slower and we can see that

00:14:49,279 --> 00:14:57,600
like the it is

00:14:53,360 --> 00:14:57,600
it is slower in the this

00:14:57,760 --> 00:15:04,560
we can see that it is slower in that um

00:15:01,519 --> 00:15:06,000
high uh like low low performance range

00:15:04,560 --> 00:15:09,760
with on low speeds it

00:15:06,000 --> 00:15:12,399
is uh slower than bbr v2 so

00:15:09,760 --> 00:15:13,040
and on higher connection speeds it is

00:15:12,399 --> 00:15:16,560
actually

00:15:13,040 --> 00:15:18,880
quite close to bvr v2 uh we have hard

00:15:16,560 --> 00:15:22,160
cut off here at around

00:15:18,880 --> 00:15:26,480
one uh i think one

00:15:22,160 --> 00:15:28,560
135 or so but the further down the line

00:15:26,480 --> 00:15:30,880
data gets more noisy but we're very in

00:15:28,560 --> 00:15:32,959
line so the on higher speeds

00:15:30,880 --> 00:15:34,000
bbr which is actually very comparable to

00:15:32,959 --> 00:15:36,800
bbr we want

00:15:34,000 --> 00:15:38,560
on lower speeds uh speeds where

00:15:36,800 --> 00:15:42,399
congestion is more

00:15:38,560 --> 00:15:43,759
uh likely we we see that bbr v2 is

00:15:42,399 --> 00:15:47,120
slower

00:15:43,759 --> 00:15:50,320
um okay and uh compared to cubic

00:15:47,120 --> 00:15:51,440
compared to cubic bbr v2 is faster and

00:15:50,320 --> 00:15:54,000
you can see that

00:15:51,440 --> 00:15:56,480
on the further side of the graph the the

00:15:54,000 --> 00:15:59,120
faster connection of user becomes

00:15:56,480 --> 00:15:59,600
the more is the difference so the more

00:15:59,120 --> 00:16:01,360
uh

00:15:59,600 --> 00:16:03,279
the faster is user's connection the more

00:16:01,360 --> 00:16:06,160
benefit you get from bbr v2

00:16:03,279 --> 00:16:06,959
without like increasing congestion uh

00:16:06,160 --> 00:16:09,600
that one

00:16:06,959 --> 00:16:11,040
so as you can see it just gets further

00:16:09,600 --> 00:16:13,839
and further apart

00:16:11,040 --> 00:16:16,000
as connection speed grows and if you

00:16:13,839 --> 00:16:16,720
look at good put from my engine exponent

00:16:16,000 --> 00:16:19,279
of you know

00:16:16,720 --> 00:16:20,880
the these are based on nginx logs we can

00:16:19,279 --> 00:16:23,500
see that on lower speeds

00:16:20,880 --> 00:16:25,279
bbr v2 is way closer to

00:16:23,500 --> 00:16:28,800
[Music]

00:16:25,279 --> 00:16:31,040
cubic but on higher connections it's

00:16:28,800 --> 00:16:34,000
actually closer to

00:16:31,040 --> 00:16:35,199
bbr v2 performance so you can see here

00:16:34,000 --> 00:16:38,240
that balance that

00:16:35,199 --> 00:16:40,480
it became more cubic friendly and at the

00:16:38,240 --> 00:16:41,680
same time it's way faster for users who

00:16:40,480 --> 00:16:44,880
can actually

00:16:41,680 --> 00:16:48,959
use that spin so um

00:16:44,880 --> 00:16:50,560
as far for conclusions uh the that is

00:16:48,959 --> 00:16:54,560
initial slide with all the issues

00:16:50,560 --> 00:16:54,560
highlighted for bbm v1

00:16:56,320 --> 00:17:00,000
um we can actually prove that most of

00:16:59,680 --> 00:17:03,759
them

00:17:00,000 --> 00:17:04,079
were fixed uh except for ecm that we did

00:17:03,759 --> 00:17:07,360
not

00:17:04,079 --> 00:17:10,079
test everything else from

00:17:07,360 --> 00:17:10,400
throughput perspective it does look way

00:17:10,079 --> 00:17:14,959
uh

00:17:10,400 --> 00:17:18,319
fairer um and uh packet loss is reduced

00:17:14,959 --> 00:17:19,039
and the throughput variation is reduced

00:17:18,319 --> 00:17:22,079
so

00:17:19,039 --> 00:17:22,720
um all of that our experimental results

00:17:22,079 --> 00:17:25,439
show that

00:17:22,720 --> 00:17:26,720
bandwidth is comparable to cubic on for

00:17:25,439 --> 00:17:29,760
users that have lower

00:17:26,720 --> 00:17:32,720
internet speeds and way better

00:17:29,760 --> 00:17:34,160
and comparable to bbr v1 uh for users

00:17:32,720 --> 00:17:36,880
with higher internet speeds

00:17:34,160 --> 00:17:38,559
lower packet loss than the bbr v1 still

00:17:36,880 --> 00:17:41,840
a bit higher than cubic

00:17:38,559 --> 00:17:45,600
uh that data in flight is comparable

00:17:41,840 --> 00:17:49,280
uh sorry slightly lower than cubic

00:17:45,600 --> 00:17:52,880
and way lower than bbr v1

00:17:49,280 --> 00:17:56,000
uh yeah our better rtt fairness

00:17:52,880 --> 00:17:56,720
and uh slightly lower rtgs at bbr1

00:17:56,000 --> 00:17:58,960
overall

00:17:56,720 --> 00:18:00,000
across all of that i can say that from

00:17:58,960 --> 00:18:03,039
our test

00:18:00,000 --> 00:18:06,000
results it seems like bbr v2 is drop in

00:18:03,039 --> 00:18:09,280
replacement for bbr v1 which is better

00:18:06,000 --> 00:18:13,120
in all um all the cases

00:18:09,280 --> 00:18:15,200
the only word thing that we saw is that

00:18:13,120 --> 00:18:17,440
that small amount of connections with

00:18:15,200 --> 00:18:21,039
more than um

00:18:17,440 --> 00:18:23,520
uh 60 packet loss except that

00:18:21,039 --> 00:18:25,679
it's literally dropping replacement that

00:18:23,520 --> 00:18:29,840
is better in all the respects

00:18:25,679 --> 00:18:33,120
uh it may actually be even considered as

00:18:29,840 --> 00:18:35,039
a relatively good drop in replacement

00:18:33,120 --> 00:18:37,120
for cubic especially if you have a high

00:18:35,039 --> 00:18:41,200
performance clients they will benefit

00:18:37,120 --> 00:18:44,640
from bbr v1 compared to cubic um

00:18:41,200 --> 00:18:46,640
and uh depending on how we sent us go

00:18:44,640 --> 00:18:47,840
goes in our data center if we ever get

00:18:46,640 --> 00:18:50,880
to do that

00:18:47,840 --> 00:18:51,280
uh maybe we can prove that uh bbr v1 can

00:18:50,880 --> 00:18:53,919
be

00:18:51,280 --> 00:18:54,480
a drop-in replacement for dctc but

00:18:53,919 --> 00:18:57,520
that's

00:18:54,480 --> 00:18:59,440
that's way further out so recently i was

00:18:57,520 --> 00:19:02,880
troubleshooting uh

00:18:59,440 --> 00:19:05,520
tcp performance in windows and

00:19:02,880 --> 00:19:07,039
very small note uh for all of you

00:19:05,520 --> 00:19:09,919
software engineers out here

00:19:07,039 --> 00:19:11,760
like windows snap shell trace is way

00:19:09,919 --> 00:19:14,960
ahead what we have in uh

00:19:11,760 --> 00:19:17,520
in linux world so natural trace notch

00:19:14,960 --> 00:19:18,320
trace for those who don't know it's

00:19:17,520 --> 00:19:22,240
actually

00:19:18,320 --> 00:19:25,760
uh it collects data like tcp dump

00:19:22,240 --> 00:19:27,760
but also puts in all data from all the

00:19:25,760 --> 00:19:29,919
various subsystems in the kernel so you

00:19:27,760 --> 00:19:32,000
not only have packet trace you also have

00:19:29,919 --> 00:19:33,120
all the events that happen in inside the

00:19:32,000 --> 00:19:36,240
kernel you have

00:19:33,120 --> 00:19:39,200
um i i think async subsystem

00:19:36,240 --> 00:19:40,880
events like uh iocp events for example

00:19:39,200 --> 00:19:43,840
you have socket events

00:19:40,880 --> 00:19:44,559
like rights and reads you have uh data

00:19:43,840 --> 00:19:46,799
from

00:19:44,559 --> 00:19:47,919
what you usually get from tcp info or

00:19:46,799 --> 00:19:50,960
netlink

00:19:47,919 --> 00:19:53,120
about congestion windows and properties

00:19:50,960 --> 00:19:56,400
of of the tcp connection you

00:19:53,120 --> 00:19:59,120
you get reordering you get uh some

00:19:56,400 --> 00:20:00,000
memory subsystem events like buffers etc

00:19:59,120 --> 00:20:02,400
etc like

00:20:00,000 --> 00:20:04,159
uh all the things in one place your

00:20:02,400 --> 00:20:06,320
unnatural trace you get

00:20:04,159 --> 00:20:07,360
all the things that you need for

00:20:06,320 --> 00:20:10,480
troubleshooting

00:20:07,360 --> 00:20:12,799
while in linux world uh when you

00:20:10,480 --> 00:20:14,480
collect just plain tcp dump it is the

00:20:12,799 --> 00:20:17,679
same tcp dump that was uh

00:20:14,480 --> 00:20:21,039
20 years ago uh what you get is

00:20:17,679 --> 00:20:22,960
uh data on the wire where you need to

00:20:21,039 --> 00:20:26,240
infer what actually happened into

00:20:22,960 --> 00:20:29,520
in the kernel and uh

00:20:26,240 --> 00:20:32,159
like based on sex based on uh some other

00:20:29,520 --> 00:20:34,000
uh some other weird things like window

00:20:32,159 --> 00:20:37,360
advertisement changes like

00:20:34,000 --> 00:20:41,840
there is there is not enough uh debug

00:20:37,360 --> 00:20:44,240
data in there uh

00:20:41,840 --> 00:20:44,960
if we see in bbr we took out they added

00:20:44,240 --> 00:20:48,240
a lot of

00:20:44,960 --> 00:20:49,440
debugging code uh just for ease of

00:20:48,240 --> 00:20:52,720
troubleshooting

00:20:49,440 --> 00:20:53,760
um nowadays with ebpf we can actually

00:20:52,720 --> 00:20:56,240
get

00:20:53,760 --> 00:20:57,919
a utility we can create as a community

00:20:56,240 --> 00:21:00,799
and utility that can

00:20:57,919 --> 00:21:03,280
pipe all the relevant data from all the

00:21:00,799 --> 00:21:06,720
subsystems in the kernel

00:21:03,280 --> 00:21:08,799
inside the trace as for example comments

00:21:06,720 --> 00:21:10,720
anticipated

00:21:08,799 --> 00:21:11,840
that would be quite useful for any

00:21:10,720 --> 00:21:15,120
performance

00:21:11,840 --> 00:21:17,280
related either research like we did

00:21:15,120 --> 00:21:19,039
or any performance related

00:21:17,280 --> 00:21:19,840
troubleshooting so please for those of

00:21:19,039 --> 00:21:23,280
you who

00:21:19,840 --> 00:21:25,600
never tried like touching windows please

00:21:23,280 --> 00:21:28,880
look into nutshell trace and uh

00:21:25,600 --> 00:21:30,880
message analyzer they are great

00:21:28,880 --> 00:21:34,240
okay so uh that's pretty much all of it

00:21:30,880 --> 00:21:34,240
uh now here and then

00:21:35,760 --> 00:21:39,039
okay thanks for the great talk uh okay

00:21:38,400 --> 00:21:41,520
so i guess

00:21:39,039 --> 00:21:45,840
we have someone ready to ask the

00:21:41,520 --> 00:21:45,840
question go ahead

00:21:48,400 --> 00:21:53,840
um then i'll read out this question on

00:21:52,480 --> 00:21:57,440
the chat

00:21:53,840 --> 00:21:59,919
um we

00:21:57,440 --> 00:22:00,880
on the higher rtt then qb can you please

00:21:59,919 --> 00:22:04,080
elaborate

00:22:00,880 --> 00:22:06,480
what do you mean by bug in our code is

00:22:04,080 --> 00:22:10,000
that the stats gathering code

00:22:06,480 --> 00:22:14,080
in this test okay

00:22:10,000 --> 00:22:18,159
yeah it is likely the bug in our code um

00:22:14,080 --> 00:22:18,159
i was recently reviewing it um

00:22:18,960 --> 00:22:23,120
ss basically provides two sets of

00:22:20,880 --> 00:22:28,159
information for bbr it has

00:22:23,120 --> 00:22:31,280
mrtt from bbr and mrtt from

00:22:28,159 --> 00:22:33,760
a generic mean rtt so i think

00:22:31,280 --> 00:22:35,440
we misplaced these two and for cubic

00:22:33,760 --> 00:22:38,240
because it doesn't provide

00:22:35,440 --> 00:22:40,720
uh mrtt from bbr cells because it's

00:22:38,240 --> 00:22:40,720
cubic

00:22:41,120 --> 00:22:44,960
we actually compare two different sets

00:22:42,960 --> 00:22:47,440
of data that may uh

00:22:44,960 --> 00:22:49,120
that may uh actually result in that kind

00:22:47,440 --> 00:22:51,039
of inconsistency

00:22:49,120 --> 00:22:52,960
so i would actually ascribe to that part

00:22:51,039 --> 00:22:56,320
from the presentation about comparing

00:22:52,960 --> 00:22:57,280
uh specifically ddr to be dbr 1 to brv 2

00:22:56,320 --> 00:23:00,799
comparison

00:22:57,280 --> 00:23:03,120
is right bbr uh versus cubic may be

00:23:00,799 --> 00:23:05,440
a bug in our code just because we use

00:23:03,120 --> 00:23:07,120
two different sets of data and i

00:23:05,440 --> 00:23:09,120
haven't looked at how they are

00:23:07,120 --> 00:23:12,960
implemented in kernel how does

00:23:09,120 --> 00:23:16,159
bbr estimate uh mrtt in its code and how

00:23:12,960 --> 00:23:17,120
uh the last remaining question on your

00:23:16,159 --> 00:23:19,360
talk

00:23:17,120 --> 00:23:22,400
was that when you were running the

00:23:19,360 --> 00:23:24,559
experiment let's say for bbr v2

00:23:22,400 --> 00:23:25,679
uh was the other traffic still using

00:23:24,559 --> 00:23:27,679
cubic so

00:23:25,679 --> 00:23:31,440
maybe you are not you are seeing an

00:23:27,679 --> 00:23:34,559
effect of like the bbr v2 versus bvr

00:23:31,440 --> 00:23:36,000
uh and cubic competition i think that

00:23:34,559 --> 00:23:39,679
was the intention of the

00:23:36,000 --> 00:23:42,799
question okay so in our tasks uh

00:23:39,679 --> 00:23:43,520
bottleneck is uh way outside of our

00:23:42,799 --> 00:23:45,760
network

00:23:43,520 --> 00:23:46,559
bottleneck usually is a network

00:23:45,760 --> 00:23:48,799
equipment

00:23:46,559 --> 00:23:51,200
or the police or slash shaper on the

00:23:48,799 --> 00:23:54,400
client side

00:23:51,200 --> 00:23:57,520
or closer to client so there is in

00:23:54,400 --> 00:24:00,799
there will be some competition uh

00:23:57,520 --> 00:24:02,640
depending on users um usage between bdr

00:24:00,799 --> 00:24:05,840
v1 bbr v2

00:24:02,640 --> 00:24:10,000
and cubic and

00:24:05,840 --> 00:24:12,000
on these links uh that's true we just

00:24:10,000 --> 00:24:13,919
uh don't know what what is the

00:24:12,000 --> 00:24:17,279
proportion depending on what

00:24:13,919 --> 00:24:18,400
site's user uses there will be some

00:24:17,279 --> 00:24:21,679
competition so of course

00:24:18,400 --> 00:24:23,840
us change and congestion control um

00:24:21,679 --> 00:24:25,840
changes the mix of that competition just

00:24:23,840 --> 00:24:27,679
like if google changes uh

00:24:25,840 --> 00:24:29,840
congestion control on youtube that

00:24:27,679 --> 00:24:30,640
changes the mix of that competition on

00:24:29,840 --> 00:24:33,679
the bottleneck

00:24:30,640 --> 00:24:35,760
um which is way closer to the client on

00:24:33,679 --> 00:24:38,000
our networks we don't uh

00:24:35,760 --> 00:24:39,440
since we are not using bbr v2 internally

00:24:38,000 --> 00:24:42,720
inside our networks we

00:24:39,440 --> 00:24:44,080
uh we cannot say what is happening when

00:24:42,720 --> 00:24:46,159
uh these uh

00:24:44,080 --> 00:24:48,240
tcp congestion control actually compete

00:24:46,159 --> 00:24:50,799
directly on our network in known

00:24:48,240 --> 00:24:50,799
proportions

00:24:50,880 --> 00:24:57,600
okay great and then um i just remembered

00:24:54,159 --> 00:25:01,679
another question uh before uh

00:24:57,600 --> 00:25:05,120
the outage um the

00:25:01,679 --> 00:25:08,799
i think the the data that on the receive

00:25:05,120 --> 00:25:12,159
limited um that we are seeing bbr v2

00:25:08,799 --> 00:25:15,039
uh has lower receive limited uh cases

00:25:12,159 --> 00:25:17,760
probably because it has lower in flight

00:25:15,039 --> 00:25:17,760
in general

00:25:24,320 --> 00:25:28,080
that is true that that that that theory

00:25:27,360 --> 00:25:31,330
correlates

00:25:28,080 --> 00:25:32,400
uh very well with um uh

00:25:31,330 --> 00:25:34,320
[Music]

00:25:32,400 --> 00:25:35,840
with the data though at the same time

00:25:34,320 --> 00:25:39,679
like just having

00:25:35,840 --> 00:25:41,919
lower received window limit does not

00:25:39,679 --> 00:25:44,159
mean much by itself like if you're zero

00:25:41,919 --> 00:25:45,840
percent receive uh window limited you're

00:25:44,159 --> 00:25:49,360
probably doing something wrong

00:25:45,840 --> 00:25:49,360
so um just by

00:25:49,520 --> 00:25:53,440
just by saying that the it is lower um

00:25:52,400 --> 00:25:55,440
doesn't say much

00:25:53,440 --> 00:25:56,640
in the meantime if it's the full graph

00:25:55,440 --> 00:26:00,000
is kind of

00:25:56,640 --> 00:26:04,799
lower than it is probably a good thing

00:26:00,000 --> 00:26:08,000
um yeah it means less buffer blood uh

00:26:04,799 --> 00:26:11,679
yep okay great

00:26:08,000 --> 00:26:14,559
um i think last question um clarify

00:26:11,679 --> 00:26:15,679
clarifying question when you say cubic

00:26:14,559 --> 00:26:19,200
is this cubic

00:26:15,679 --> 00:26:22,559
plus p5 or fast or cubic plus

00:26:19,200 --> 00:26:22,960
fq oh yeah uh that that's a very good

00:26:22,559 --> 00:26:26,080
one

00:26:22,960 --> 00:26:29,679
yes everywhere we use uh

00:26:26,080 --> 00:26:30,880
cubic plus at q so fq with spacing uh so

00:26:29,679 --> 00:26:34,080
that is a very

00:26:30,880 --> 00:26:37,120
um i would say

00:26:34,080 --> 00:26:40,880
even specifically it's cubic

00:26:37,120 --> 00:26:44,400
with fq with spacing without the

00:26:40,880 --> 00:26:46,960
i think high start packet train uh

00:26:44,400 --> 00:26:52,159
heuristic i think that's that's a full

00:26:46,960 --> 00:26:55,120
technical definition

00:26:52,159 --> 00:26:56,640
okay sounds good it's glad to see that

00:26:55,120 --> 00:26:59,600
uh fq is used uh

00:26:56,640 --> 00:27:00,240
in um any kind any congestion control i

00:26:59,600 --> 00:27:03,600
think it's

00:27:00,240 --> 00:27:05,760
okay yeah one small node the the

00:27:03,600 --> 00:27:08,559
the thing that i've mentioned about

00:27:05,760 --> 00:27:10,640
switches running out of um

00:27:08,559 --> 00:27:11,679
of buffer space and producing drops even

00:27:10,640 --> 00:27:14,080
on our like

00:27:11,679 --> 00:27:15,440
hd network like top of the rack switches

00:27:14,080 --> 00:27:17,360
for age rights

00:27:15,440 --> 00:27:18,640
uh the problem i've described when we

00:27:17,360 --> 00:27:22,000
rolled out fq

00:27:18,640 --> 00:27:24,240
and these package drop drops disappeared

00:27:22,000 --> 00:27:25,120
um basically the first hop of our

00:27:24,240 --> 00:27:27,120
network

00:27:25,120 --> 00:27:30,000
uh it happened even with cubic so it

00:27:27,120 --> 00:27:32,640
wasn't bbr v1 or bbr v2 test 7.

00:27:30,000 --> 00:27:34,799
it was preparation for initial bbr v1

00:27:32,640 --> 00:27:37,120
rollout when we first rolled out

00:27:34,799 --> 00:27:37,919
basin everywhere and then we started

00:27:37,120 --> 00:27:41,120
rolling out

00:27:37,919 --> 00:27:45,039
the bbr v1 itself

00:27:41,120 --> 00:27:46,880
so even with a cubic fq is very very

00:27:45,039 --> 00:27:49,840
useful

00:27:46,880 --> 00:27:52,320
it does uh or facing enough q is very

00:27:49,840 --> 00:27:52,320
very useful

00:27:53,039 --> 00:27:57,120
okay i agree sounds good um all right so

00:27:56,159 --> 00:28:02,080
i think for that

00:27:57,120 --> 00:28:02,080

YouTube URL: https://www.youtube.com/watch?v=inLCBXXRzWk


