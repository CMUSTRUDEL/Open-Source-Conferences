Title: Netdev 0x14 - TC Connection tracking hardware offload
Publication date: 2020-10-09
Playlist: Netdev 0x14
Description: 
	Speakers: Oz Shlomo, Paul Blakey

More info: https://netdevconf.info/0x14/session.html?talk-tc-connection-tracking-hardware-offload-upstream-work

Date: Thursday, August 20, 2020

In this talk Oz Shlomo provides an update on the effort
on getting Connection-Tracking within TC.

In this talk Oz describes the upstream work that 
took more than a year of effort. He goes over the changes 
that were submitted upstream in order to support the required features.
Oz shows an example of use of CT NAT action and describes
a comparison the performance improvement of HW offload relative
to CPU execution.
Captions: 
	00:00:02,000 --> 00:00:05,120
it's been around about uh two years

00:00:03,919 --> 00:00:07,600
since my colleagues

00:00:05,120 --> 00:00:08,400
uh warning prime and rashata presented

00:00:07,600 --> 00:00:11,599
the idea

00:00:08,400 --> 00:00:15,280
of uh offloading connection tracking in

00:00:11,599 --> 00:00:18,880
nether18 since uh it was upstream

00:00:15,280 --> 00:00:21,920
in kernel 5.7 uh it has been

00:00:18,880 --> 00:00:23,600
a long and sometimes bumpy road

00:00:21,920 --> 00:00:25,439
uh but it would not have been possible

00:00:23,600 --> 00:00:27,359
without the community work

00:00:25,439 --> 00:00:28,640
and some of the credit goes to the

00:00:27,359 --> 00:00:30,880
people listed here

00:00:28,640 --> 00:00:32,880
uh the first is aaron from red hat for

00:00:30,880 --> 00:00:34,719
holding those bi-weekly meetings with

00:00:32,880 --> 00:00:36,160
all the relevant uh stakeholders

00:00:34,719 --> 00:00:38,960
regarding this including

00:00:36,160 --> 00:00:40,480
melanox metronome intel and broadcom

00:00:38,960 --> 00:00:42,879
actually these meetings had a few guest

00:00:40,480 --> 00:00:45,920
appearances by david miller himself

00:00:42,879 --> 00:00:47,840
um martello from red hat who helped

00:00:45,920 --> 00:00:50,320
during the development and the code

00:00:47,840 --> 00:00:52,399
reviews before all this went upstream

00:00:50,320 --> 00:00:53,440
uh jiri who helped with the tc

00:00:52,399 --> 00:00:55,920
integration and

00:00:53,440 --> 00:00:56,719
actually a lot of the system design and

00:00:55,920 --> 00:00:58,879
the platform

00:00:56,719 --> 00:01:00,480
to make everything work together and a

00:00:58,879 --> 00:01:03,120
very special thanks to

00:01:00,480 --> 00:01:04,799
pablo who through joint work and while

00:01:03,120 --> 00:01:07,920
we were working together

00:01:04,799 --> 00:01:10,720
uh made possible to take uh to extend nf

00:01:07,920 --> 00:01:12,000
flow table offload and to make it the

00:01:10,720 --> 00:01:14,799
platform for

00:01:12,000 --> 00:01:15,520
offloading established connections to tc

00:01:14,799 --> 00:01:17,600
um

00:01:15,520 --> 00:01:21,280
actually we're going to go in depth

00:01:17,600 --> 00:01:21,280
about this work in this presentation

00:01:21,680 --> 00:01:25,680
so what are basically going to describe

00:01:24,640 --> 00:01:28,240
today

00:01:25,680 --> 00:01:30,079
well let's first start off by just uh

00:01:28,240 --> 00:01:30,720
reminding usf what is connection

00:01:30,079 --> 00:01:33,680
tracking

00:01:30,720 --> 00:01:35,040
why what is it used for why is it makes

00:01:33,680 --> 00:01:38,159
a lot of sense to

00:01:35,040 --> 00:01:41,200
to offload this uh this action

00:01:38,159 --> 00:01:44,320
um we will continue to discuss the

00:01:41,200 --> 00:01:46,240
um offloading of established connections

00:01:44,320 --> 00:01:47,759
and what it takes to offload only the

00:01:46,240 --> 00:01:50,560
established collections

00:01:47,759 --> 00:01:51,920
and then lastly we'll show the

00:01:50,560 --> 00:01:53,439
connection we'll have a high level

00:01:51,920 --> 00:01:55,280
overview of the connection tracking

00:01:53,439 --> 00:01:57,280
hardware model and we'll see what is

00:01:55,280 --> 00:02:00,560
needed from the platform in order to

00:01:57,280 --> 00:02:00,560
properly integrate with it

00:02:01,680 --> 00:02:05,600
so just a quick reminder about what is

00:02:04,479 --> 00:02:08,160
connection tracking

00:02:05,600 --> 00:02:09,039
so connection tracking is a building

00:02:08,160 --> 00:02:11,360
block

00:02:09,039 --> 00:02:13,360
uh it's not a system by itself but this

00:02:11,360 --> 00:02:14,720
building was but used by other systems

00:02:13,360 --> 00:02:16,400
mainly to provide the

00:02:14,720 --> 00:02:18,319
the ability to do stateful packet

00:02:16,400 --> 00:02:20,560
filtering so what this building block

00:02:18,319 --> 00:02:24,400
provides is basically

00:02:20,560 --> 00:02:26,640
a database of connections get financial

00:02:24,400 --> 00:02:27,599
given us the capability that once a

00:02:26,640 --> 00:02:29,599
packet

00:02:27,599 --> 00:02:31,840
comes into the system we're basically

00:02:29,599 --> 00:02:35,280
able to look up this database

00:02:31,840 --> 00:02:37,760
and understand um at what stage

00:02:35,280 --> 00:02:38,560
the connection is of this fact that just

00:02:37,760 --> 00:02:40,480
came in

00:02:38,560 --> 00:02:41,920
so uh when a packet comes into the

00:02:40,480 --> 00:02:42,560
system we can query database and

00:02:41,920 --> 00:02:44,640
understand

00:02:42,560 --> 00:02:46,160
if this packet is the first packet that

00:02:44,640 --> 00:02:46,879
we see on that connection this is a new

00:02:46,160 --> 00:02:48,720
connection

00:02:46,879 --> 00:02:50,560
if this packet is part of an established

00:02:48,720 --> 00:02:52,400
connection that already had that have

00:02:50,560 --> 00:02:54,800
bi-directional communication

00:02:52,400 --> 00:02:55,599
or this packet is is new but it is

00:02:54,800 --> 00:02:57,120
related

00:02:55,599 --> 00:03:00,480
or it is related to some other

00:02:57,120 --> 00:03:02,800
connection that already exists

00:03:00,480 --> 00:03:04,000
um once we do this database lookup we

00:03:02,800 --> 00:03:05,680
can also associate

00:03:04,000 --> 00:03:07,120
with this packet or this connection more

00:03:05,680 --> 00:03:10,560
precisely

00:03:07,120 --> 00:03:12,720
a user defines um user-defined data in

00:03:10,560 --> 00:03:16,080
the form of the 32-bit mark on the

00:03:12,720 --> 00:03:18,080
or a 128-bit label

00:03:16,080 --> 00:03:19,440
in addition connection tracking model

00:03:18,080 --> 00:03:22,480
can perform nat

00:03:19,440 --> 00:03:22,879
if it is uh required and lastly it can

00:03:22,480 --> 00:03:26,560
also

00:03:22,879 --> 00:03:29,200
validate the packet for example uh

00:03:26,560 --> 00:03:29,599
it can for example check that uh tc that

00:03:29,200 --> 00:03:33,040
the

00:03:29,599 --> 00:03:34,000
the sequence of this packet in a tcp

00:03:33,040 --> 00:03:37,280
connection

00:03:34,000 --> 00:03:38,959
is within the expected sliding window

00:03:37,280 --> 00:03:43,120
we will note that this validation can be

00:03:38,959 --> 00:03:45,280
controlled with the tcp liberal flag

00:03:43,120 --> 00:03:47,040
as we said the connection tracking is a

00:03:45,280 --> 00:03:48,799
building block it is used by multiple

00:03:47,040 --> 00:03:52,239
user space applications such as

00:03:48,799 --> 00:03:55,760
ip tables nft and also open v-switch

00:03:52,239 --> 00:03:57,519
in order to provide users with the

00:03:55,760 --> 00:04:01,840
ability to configure

00:03:57,519 --> 00:04:01,840
stateful packet filtering

00:04:01,920 --> 00:04:05,360
so connection tracking in tc to

00:04:03,920 --> 00:04:06,000
basically add connection tracking

00:04:05,360 --> 00:04:09,519
support

00:04:06,000 --> 00:04:10,560
to tc uh to tc we needed to add a

00:04:09,519 --> 00:04:14,480
connection tracking

00:04:10,560 --> 00:04:18,560
action and a classifier

00:04:14,480 --> 00:04:20,400
the tc action actually reuses the net

00:04:18,560 --> 00:04:22,400
filter contract module so basically when

00:04:20,400 --> 00:04:26,080
packet comes into the tc

00:04:22,400 --> 00:04:29,040
action it calls the net

00:04:26,080 --> 00:04:30,320
filter contract model which it does the

00:04:29,040 --> 00:04:33,199
connection lookup

00:04:30,320 --> 00:04:36,880
does the nat and it sets the city state

00:04:33,199 --> 00:04:40,080
marking label on the skb

00:04:36,880 --> 00:04:43,840
uh we also provide the ability to query

00:04:40,080 --> 00:04:45,040
and match uh on the city state that was

00:04:43,840 --> 00:04:48,080
initialized

00:04:45,040 --> 00:04:50,000
to uh so we can do the packet steering

00:04:48,080 --> 00:04:51,680
according to this information

00:04:50,000 --> 00:04:53,759
so we actually extended the flower

00:04:51,680 --> 00:04:55,199
classifier to also be able to match on

00:04:53,759 --> 00:04:58,240
the 60-state

00:04:55,199 --> 00:05:01,840
mark in label as it is on as it is

00:04:58,240 --> 00:05:04,240
referenced in the skb the classifier and

00:05:01,840 --> 00:05:06,080
actions were added and introduced to

00:05:04,240 --> 00:05:09,520
kernel 5.3

00:05:06,080 --> 00:05:13,039
at this reference at the

00:05:09,520 --> 00:05:13,039
series that is referenced here

00:05:14,160 --> 00:05:17,280
now let's see how connection tracking is

00:05:16,000 --> 00:05:20,479
used in a in

00:05:17,280 --> 00:05:21,600
a real use case um suppose we are

00:05:20,479 --> 00:05:24,880
running

00:05:21,600 --> 00:05:27,440
a vm which is uh connected

00:05:24,880 --> 00:05:28,479
to a virtual function that is exposed

00:05:27,440 --> 00:05:30,960
from

00:05:28,479 --> 00:05:31,919
nick and this vm is running the web

00:05:30,960 --> 00:05:34,160
server

00:05:31,919 --> 00:05:36,400
now the system administrator or the

00:05:34,160 --> 00:05:38,400
network administrator would like to uh

00:05:36,400 --> 00:05:39,440
enforce a policy basically saying that

00:05:38,400 --> 00:05:42,800
it would allow

00:05:39,440 --> 00:05:43,759
ingress http traffic to go to that vm to

00:05:42,800 --> 00:05:46,000
go to that

00:05:43,759 --> 00:05:48,400
server and it wants to make sure that

00:05:46,000 --> 00:05:50,320
any traffic that is leaving this server

00:05:48,400 --> 00:05:52,639
will only be on established connections

00:05:50,320 --> 00:05:55,759
basically what we want is that

00:05:52,639 --> 00:05:57,919
um um connections

00:05:55,759 --> 00:05:58,800
uh that packets leaving the server will

00:05:57,919 --> 00:06:01,600
only be

00:05:58,800 --> 00:06:02,639
for replies that came in from legitimate

00:06:01,600 --> 00:06:04,400
requests

00:06:02,639 --> 00:06:06,800
so in order to program that into the

00:06:04,400 --> 00:06:08,880
system uh in the form of uh

00:06:06,800 --> 00:06:10,240
so if we have a system in that has a

00:06:08,880 --> 00:06:12,639
virtual switch

00:06:10,240 --> 00:06:14,240
um the policy can be implemented in the

00:06:12,639 --> 00:06:16,639
virtual switch itself

00:06:14,240 --> 00:06:18,240
saying basically the packets that come

00:06:16,639 --> 00:06:21,680
from the uplink

00:06:18,240 --> 00:06:24,319
um and those are http packets

00:06:21,680 --> 00:06:25,039
that that can be classified into using

00:06:24,319 --> 00:06:27,919
uh

00:06:25,039 --> 00:06:29,360
by looking at the tcp destination 480

00:06:27,919 --> 00:06:32,000
then we would like to send this packet

00:06:29,360 --> 00:06:34,240
to the connection tracking database

00:06:32,000 --> 00:06:35,120
and if this is a new connection this is

00:06:34,240 --> 00:06:36,479
the um

00:06:35,120 --> 00:06:38,319
the first packet that we see on that

00:06:36,479 --> 00:06:41,680
connection we basically want to

00:06:38,319 --> 00:06:43,440
uh commit or or add this connection into

00:06:41,680 --> 00:06:44,240
the database and forward this packet to

00:06:43,440 --> 00:06:45,840
the vm

00:06:44,240 --> 00:06:48,000
otherwise if it is an established

00:06:45,840 --> 00:06:49,680
connection then we would just forward it

00:06:48,000 --> 00:06:51,919
to that vm

00:06:49,680 --> 00:06:53,199
on the other way around if a packet came

00:06:51,919 --> 00:06:55,520
from out of the pm

00:06:53,199 --> 00:06:57,199
that means that we will receive it on

00:06:55,520 --> 00:06:57,680
the representer and that vm if we're

00:06:57,199 --> 00:07:00,720
working

00:06:57,680 --> 00:07:02,960
in a switch depth model then

00:07:00,720 --> 00:07:04,800
we would like to take this packet send

00:07:02,960 --> 00:07:05,919
it to the connection tracking module do

00:07:04,800 --> 00:07:07,520
a connection lookup

00:07:05,919 --> 00:07:09,360
and if this is part of an established

00:07:07,520 --> 00:07:12,880
connection then we will let the packet

00:07:09,360 --> 00:07:15,520
go out through the uplink interface

00:07:12,880 --> 00:07:16,000
or if this is not an established

00:07:15,520 --> 00:07:18,400
connection

00:07:16,000 --> 00:07:20,080
if this is like a new or invalid packet

00:07:18,400 --> 00:07:22,000
we just want to drop it

00:07:20,080 --> 00:07:23,919
so this is how we're basically allowing

00:07:22,000 --> 00:07:26,160
all ingress traffic that is coming

00:07:23,919 --> 00:07:27,680
into the server to be accepted and

00:07:26,160 --> 00:07:28,319
recording the connection tracking

00:07:27,680 --> 00:07:30,560
database

00:07:28,319 --> 00:07:31,919
and we're only allowing packets going

00:07:30,560 --> 00:07:34,960
out of the server

00:07:31,919 --> 00:07:38,479
to be um to be forwarded only if they

00:07:34,960 --> 00:07:40,240
are part of an established connection

00:07:38,479 --> 00:07:41,840
offloading the connection tracking

00:07:40,240 --> 00:07:44,479
action is a bit tricky

00:07:41,840 --> 00:07:46,639
um the reason for that is that um

00:07:44,479 --> 00:07:49,840
current hardware does not have the

00:07:46,639 --> 00:07:54,400
stateful engines that will be able to do

00:07:49,840 --> 00:07:57,120
uh exactly what the net filter contract

00:07:54,400 --> 00:07:59,360
module is doing in software so that

00:07:57,120 --> 00:08:02,400
means that even

00:07:59,360 --> 00:08:03,840
so what we basically want to do is is we

00:08:02,400 --> 00:08:06,560
want to still rely

00:08:03,840 --> 00:08:07,280
on the software to take care of the

00:08:06,560 --> 00:08:10,840
connection

00:08:07,280 --> 00:08:12,080
setup tear down and aging of the

00:08:10,840 --> 00:08:14,879
connections

00:08:12,080 --> 00:08:16,639
but once the connections entered the

00:08:14,879 --> 00:08:18,639
established state

00:08:16,639 --> 00:08:20,560
there's actually not much that is done

00:08:18,639 --> 00:08:21,360
in software in terms of stateful

00:08:20,560 --> 00:08:24,080
processing

00:08:21,360 --> 00:08:24,560
other than tcp window validation which

00:08:24,080 --> 00:08:28,080
can

00:08:24,560 --> 00:08:28,080
also be controlled using the

00:08:28,160 --> 00:08:35,760
using the tcp liberal flag

00:08:32,000 --> 00:08:36,080
in software so what we actually want to

00:08:35,760 --> 00:08:38,240
do

00:08:36,080 --> 00:08:39,599
is to partially offload the connection

00:08:38,240 --> 00:08:41,680
tracking action

00:08:39,599 --> 00:08:42,640
making sure that packets that are part

00:08:41,680 --> 00:08:45,920
of

00:08:42,640 --> 00:08:48,399
uh uh of the of the setup or

00:08:45,920 --> 00:08:49,519
or tear down sequence will be processed

00:08:48,399 --> 00:08:51,040
in software

00:08:49,519 --> 00:08:53,360
but packets that are going through

00:08:51,040 --> 00:08:56,240
connections that are in established

00:08:53,360 --> 00:08:58,160
state will go through hardware for that

00:08:56,240 --> 00:08:59,680
to work we would need the platform to

00:08:58,160 --> 00:09:02,560
notify the drivers

00:08:59,680 --> 00:09:04,240
which connections enter and exit when

00:09:02,560 --> 00:09:07,519
connections enter and exit

00:09:04,240 --> 00:09:09,279
the uh the established state and that is

00:09:07,519 --> 00:09:11,760
a new mechanism that needs to be

00:09:09,279 --> 00:09:11,760
developed

00:09:12,560 --> 00:09:15,760
so when we started uh looking at this

00:09:14,640 --> 00:09:18,399
problem there were

00:09:15,760 --> 00:09:20,640
a few entry points that we identified

00:09:18,399 --> 00:09:22,959
where we can start implementing

00:09:20,640 --> 00:09:24,399
um this mechanism that would notify

00:09:22,959 --> 00:09:25,519
drivers when connections become

00:09:24,399 --> 00:09:27,760
established

00:09:25,519 --> 00:09:30,000
the first of course is nf contract

00:09:27,760 --> 00:09:31,440
itself and if contract is the model that

00:09:30,000 --> 00:09:33,600
does the connection tracking

00:09:31,440 --> 00:09:35,600
it obviously knows when connectors enter

00:09:33,600 --> 00:09:38,720
and leave the established state

00:09:35,600 --> 00:09:39,360
it has um timeout mechanism and

00:09:38,720 --> 00:09:42,560
connection

00:09:39,360 --> 00:09:44,000
and aging mechanisms and and what we

00:09:42,560 --> 00:09:46,000
need to do is somehow hook it up

00:09:44,000 --> 00:09:48,720
with the callbacks to notify drivers

00:09:46,000 --> 00:09:51,600
when these events are happening

00:09:48,720 --> 00:09:52,560
another alternative is to is to

00:09:51,600 --> 00:09:55,760
integrate with the

00:09:52,560 --> 00:09:58,959
action city um

00:09:55,760 --> 00:10:01,279
module the action city actually calls

00:09:58,959 --> 00:10:02,160
uh nf contract module and from its

00:10:01,279 --> 00:10:04,800
return value

00:10:02,160 --> 00:10:07,519
it can know when connections are

00:10:04,800 --> 00:10:10,560
entering and exiting established states

00:10:07,519 --> 00:10:12,959
um what it is missing is

00:10:10,560 --> 00:10:14,160
the agent mechanism because aging is

00:10:12,959 --> 00:10:16,000
transparent to

00:10:14,160 --> 00:10:18,079
action city because it's done internally

00:10:16,000 --> 00:10:20,560
in the contract and of course it also

00:10:18,079 --> 00:10:23,839
would have to integrate with um with

00:10:20,560 --> 00:10:25,839
drivers for notifications

00:10:23,839 --> 00:10:27,839
the third option and this is actually

00:10:25,839 --> 00:10:31,040
the option that we used

00:10:27,839 --> 00:10:32,399
is to is to integrate with nf flow

00:10:31,040 --> 00:10:35,680
tables

00:10:32,399 --> 00:10:38,959
now nfl table is the mechanism that was

00:10:35,680 --> 00:10:40,959
added to kernel 416 and

00:10:38,959 --> 00:10:42,079
the motivation for it was actually the

00:10:40,959 --> 00:10:45,519
realization

00:10:42,079 --> 00:10:46,079
that packets that go through connections

00:10:45,519 --> 00:10:49,519
that are

00:10:46,079 --> 00:10:50,959
in established states always do the same

00:10:49,519 --> 00:10:54,720
thing

00:10:50,959 --> 00:10:55,200
so what can be done is that if we would

00:10:54,720 --> 00:10:58,320
put

00:10:55,200 --> 00:11:00,399
um a flow table um in the beginning

00:10:58,320 --> 00:11:02,480
before we start the ingress processing

00:11:00,399 --> 00:11:04,720
to check if the packet that was just

00:11:02,480 --> 00:11:05,760
received is part of an established

00:11:04,720 --> 00:11:08,880
connection

00:11:05,760 --> 00:11:10,000
then basically we can just do the packet

00:11:08,880 --> 00:11:12,640
manipulation

00:11:10,000 --> 00:11:13,360
that is required such as nat had a

00:11:12,640 --> 00:11:16,959
rewrite

00:11:13,360 --> 00:11:19,120
and maybe ttl decrement and then just

00:11:16,959 --> 00:11:21,440
forward this packet to the equestria to

00:11:19,120 --> 00:11:23,120
the relevant ingress device

00:11:21,440 --> 00:11:24,959
if we have this setup in place then we

00:11:23,120 --> 00:11:27,440
can basically bypass

00:11:24,959 --> 00:11:28,000
all the all the chain the normal chain

00:11:27,440 --> 00:11:30,720
processing

00:11:28,000 --> 00:11:32,720
the in in in nft being the ingress

00:11:30,720 --> 00:11:36,079
pre-routing routing and post-routing

00:11:32,720 --> 00:11:37,519
uh logic uh bypass everything and go

00:11:36,079 --> 00:11:41,279
from ingress processing

00:11:37,519 --> 00:11:41,279
directly to the egress processing

00:11:41,440 --> 00:11:44,800
so what it appears is that we have a

00:11:43,279 --> 00:11:47,920
slow table okay

00:11:44,800 --> 00:11:50,720
this flow table identifies connections

00:11:47,920 --> 00:11:53,279
that are in established state

00:11:50,720 --> 00:11:55,920
and there is and and it just bypasses

00:11:53,279 --> 00:11:58,959
everything and continues to exist but

00:11:55,920 --> 00:12:02,000
the the thing that it also bypasses is

00:11:58,959 --> 00:12:03,680
the nf contract itself so

00:12:02,000 --> 00:12:06,079
if the packets don't go through nf

00:12:03,680 --> 00:12:07,440
contract then the patch then the

00:12:06,079 --> 00:12:10,240
connections can first

00:12:07,440 --> 00:12:11,680
um age in contract because contract

00:12:10,240 --> 00:12:12,880
doesn't know that packets went through

00:12:11,680 --> 00:12:16,079
that connections

00:12:12,880 --> 00:12:17,519
and and also um uh connection engine is

00:12:16,079 --> 00:12:21,440
not really managed because

00:12:17,519 --> 00:12:24,160
um uh it happens somewhere else so

00:12:21,440 --> 00:12:26,240
nfl tables also has its own ancient

00:12:24,160 --> 00:12:29,360
mechanism where it ages the

00:12:26,240 --> 00:12:32,560
connections that exist in the nf

00:12:29,360 --> 00:12:36,320
flow table um autonomous in

00:12:32,560 --> 00:12:38,560
autonomously from uh from nf contract

00:12:36,320 --> 00:12:40,800
actually it was there was there is

00:12:38,560 --> 00:12:43,680
integration with nf contract saying that

00:12:40,800 --> 00:12:44,000
when a connection is now being handled

00:12:43,680 --> 00:12:47,200
by

00:12:44,000 --> 00:12:50,399
nft flow table then

00:12:47,200 --> 00:12:52,480
uh uh the flow table is the one that

00:12:50,399 --> 00:12:53,839
owns this connection that means it flags

00:12:52,480 --> 00:12:55,200
from the end of contract that it should

00:12:53,839 --> 00:12:56,480
not manage the agent with that

00:12:55,200 --> 00:12:59,200
connection it's managed

00:12:56,480 --> 00:13:00,959
somewhere else so this is another great

00:12:59,200 --> 00:13:02,560
building about that we have in nft flow

00:13:00,959 --> 00:13:04,800
table so we have

00:13:02,560 --> 00:13:06,720
a database of established connections

00:13:04,800 --> 00:13:08,880
aging is being taken care of

00:13:06,720 --> 00:13:10,000
and the only thing that we're missing is

00:13:08,880 --> 00:13:13,920
this hook

00:13:10,000 --> 00:13:13,920
into the driver offloads

00:13:14,079 --> 00:13:19,360
now luckily for us and and also pablo

00:13:17,360 --> 00:13:22,399
who is the maintainer of this

00:13:19,360 --> 00:13:24,639
of this net filter code is that we both

00:13:22,399 --> 00:13:26,880
wanted to offload this flow table

00:13:24,639 --> 00:13:27,760
we want to offload this table from tc

00:13:26,880 --> 00:13:29,360
for this con

00:13:27,760 --> 00:13:31,680
for this connection tracking offload

00:13:29,360 --> 00:13:33,760
work and pablo wanted to offload this

00:13:31,680 --> 00:13:35,120
flow table in order to accelerate the

00:13:33,760 --> 00:13:37,600
processing through nft

00:13:35,120 --> 00:13:38,160
in hardware so it really made sense for

00:13:37,600 --> 00:13:40,079
us to

00:13:38,160 --> 00:13:42,399
for us both to start to work together

00:13:40,079 --> 00:13:45,279
and devise and try to generalize a bit

00:13:42,399 --> 00:13:46,240
the flow table mechanism in a way that

00:13:45,279 --> 00:13:48,480
it will be able

00:13:46,240 --> 00:13:50,480
to to be it for it to be part of the

00:13:48,480 --> 00:13:52,639
core engines for to be able to create

00:13:50,480 --> 00:13:55,600
instantiate and manage flow tables from

00:13:52,639 --> 00:13:56,480
two different models and and sharing the

00:13:55,600 --> 00:13:58,240
capability

00:13:56,480 --> 00:14:00,639
of offloading the connections in that

00:13:58,240 --> 00:14:00,639
table

00:14:01,279 --> 00:14:04,800
let's see how we would use this table

00:14:02,959 --> 00:14:07,279
from the tc perspective

00:14:04,800 --> 00:14:09,519
okay so assuming that we have this and a

00:14:07,279 --> 00:14:11,600
flow table that contains the entries of

00:14:09,519 --> 00:14:12,800
established connections then when a

00:14:11,600 --> 00:14:16,480
packet comes into

00:14:12,800 --> 00:14:19,040
action city what we can do is to first

00:14:16,480 --> 00:14:19,920
look up this connection in this flow

00:14:19,040 --> 00:14:21,760
table

00:14:19,920 --> 00:14:23,279
if this is an established connection

00:14:21,760 --> 00:14:26,000
they would we would hit

00:14:23,279 --> 00:14:28,000
this hash we will find the connection

00:14:26,000 --> 00:14:30,160
and then we will be able to set the city

00:14:28,000 --> 00:14:33,760
info on the escaping

00:14:30,160 --> 00:14:35,360
and basically then we're done um if

00:14:33,760 --> 00:14:36,880
uh although the connection is not

00:14:35,360 --> 00:14:39,920
established and for some reason

00:14:36,880 --> 00:14:42,639
it is not part of this nfl table then

00:14:39,920 --> 00:14:42,959
we will continue to to send this packet

00:14:42,639 --> 00:14:46,240
to

00:14:42,959 --> 00:14:46,800
the nf contract module and it will set

00:14:46,240 --> 00:14:48,079
the ct

00:14:46,800 --> 00:14:51,199
info on the skb where we can

00:14:48,079 --> 00:14:54,480
continuously classification

00:14:51,199 --> 00:14:56,839
so so this is how we would uh

00:14:54,480 --> 00:14:58,079
integrate with this nf flow table in

00:14:56,839 --> 00:15:02,079
software

00:14:58,079 --> 00:15:03,440
and actually this would be the table

00:15:02,079 --> 00:15:08,399
that we will wish to have

00:15:03,440 --> 00:15:08,399
to offload when we offload action ct

00:15:10,160 --> 00:15:15,040
um let's just first understand then then

00:15:12,639 --> 00:15:18,160
what we need basically is to somehow

00:15:15,040 --> 00:15:20,399
so so what we need is action ct to

00:15:18,160 --> 00:15:21,519
manage this table basically create

00:15:20,399 --> 00:15:24,480
destroy

00:15:21,519 --> 00:15:26,320
and and instantiate and is on that table

00:15:24,480 --> 00:15:30,000
so so how is this done

00:15:26,320 --> 00:15:31,440
so action city creates a flow table per

00:15:30,000 --> 00:15:34,560
city zone

00:15:31,440 --> 00:15:36,959
um the first city action that that

00:15:34,560 --> 00:15:38,079
is created on that zone also creates the

00:15:36,959 --> 00:15:41,120
flow table

00:15:38,079 --> 00:15:43,440
the last ct action that is deleted uh

00:15:41,120 --> 00:15:44,399
using the zone also deletes this flow

00:15:43,440 --> 00:15:46,079
table

00:15:44,399 --> 00:15:48,000
whenever a connection enters the

00:15:46,079 --> 00:15:51,839
established state the flow table

00:15:48,000 --> 00:15:54,560
entry is created um when this

00:15:51,839 --> 00:15:56,240
connection is leaving the connection the

00:15:54,560 --> 00:15:58,480
established state it is deleted from

00:15:56,240 --> 00:16:01,759
this full table

00:15:58,480 --> 00:16:03,839
aging is transparent to action city

00:16:01,759 --> 00:16:06,320
because it is internally managed by the

00:16:03,839 --> 00:16:10,000
nfl table and the city is not

00:16:06,320 --> 00:16:13,920
an action city is not aware of this

00:16:10,000 --> 00:16:17,240
um integrating this with action city

00:16:13,920 --> 00:16:18,399
um this work was introduced in kernel

00:16:17,240 --> 00:16:23,839
5.6

00:16:18,399 --> 00:16:23,839
in this reference patch set series

00:16:24,240 --> 00:16:30,079
next is how do we notify drivers

00:16:27,519 --> 00:16:31,759
when entries are added or removed from

00:16:30,079 --> 00:16:35,120
this flow table

00:16:31,759 --> 00:16:38,480
so before the how first let's discuss

00:16:35,120 --> 00:16:38,959
uh the what um what is notified to the

00:16:38,480 --> 00:16:41,040
driver

00:16:38,959 --> 00:16:42,800
when something happens so basically what

00:16:41,040 --> 00:16:43,680
we want to what we want to communicate

00:16:42,800 --> 00:16:46,079
to the driver

00:16:43,680 --> 00:16:48,000
is a flow offload object the existing

00:16:46,079 --> 00:16:51,839
flow offload object that is shared

00:16:48,000 --> 00:16:55,440
uh that is now shared by by nft and uh

00:16:51,839 --> 00:16:57,199
ntc and this flow of object has a match

00:16:55,440 --> 00:16:58,720
parameter which basically in this use

00:16:57,199 --> 00:16:59,759
case it matches based on the zone and

00:16:58,720 --> 00:17:01,839
the five tuple

00:16:59,759 --> 00:17:03,120
and a list of actions that needs to be

00:17:01,839 --> 00:17:05,679
executed on

00:17:03,120 --> 00:17:06,799
a successful match the actions that we

00:17:05,679 --> 00:17:09,439
would like to execute

00:17:06,799 --> 00:17:10,959
is first uh a city meta action this is a

00:17:09,439 --> 00:17:12,959
new action that we introduced to this

00:17:10,959 --> 00:17:16,480
work this action sets

00:17:12,959 --> 00:17:19,679
uh the mark label and uh

00:17:16,480 --> 00:17:21,839
and the city state uh that

00:17:19,679 --> 00:17:24,640
that and also it provides a reference to

00:17:21,839 --> 00:17:27,600
the nf city contract object

00:17:24,640 --> 00:17:30,000
uh and in addition we might have um nat

00:17:27,600 --> 00:17:31,039
manual action basically packet manual

00:17:30,000 --> 00:17:34,240
actions that do

00:17:31,039 --> 00:17:37,360
not either source net or destination nut

00:17:34,240 --> 00:17:40,480
uh sources ip or source test

00:17:37,360 --> 00:17:40,480
that needs to be handled

00:17:41,679 --> 00:17:45,280
now how is it notified so so it is

00:17:44,320 --> 00:17:48,559
notified in

00:17:45,280 --> 00:17:50,000
actually it is using the same um uh tc

00:17:48,559 --> 00:17:52,640
block structure that

00:17:50,000 --> 00:17:53,440
have an array of uh of callbacks that

00:17:52,640 --> 00:17:56,080
should be called

00:17:53,440 --> 00:17:57,440
on a certain uh when a certain event is

00:17:56,080 --> 00:18:01,280
happening

00:17:57,440 --> 00:18:02,400
um but in this case it is the drivers

00:18:01,280 --> 00:18:06,240
themselves

00:18:02,400 --> 00:18:09,520
that register uh themselves to the block

00:18:06,240 --> 00:18:10,080
and not the platform uh the reason for

00:18:09,520 --> 00:18:12,400
that

00:18:10,080 --> 00:18:14,080
is that registering from the platform is

00:18:12,400 --> 00:18:17,200
a bit tricky uh

00:18:14,080 --> 00:18:19,120
if we would like to register from the

00:18:17,200 --> 00:18:20,640
action city for example we want the

00:18:19,120 --> 00:18:22,400
action city to register driver the

00:18:20,640 --> 00:18:24,559
problem is that action city

00:18:22,400 --> 00:18:26,160
does not have um does not know of the

00:18:24,559 --> 00:18:26,880
net devices it doesn't know which net

00:18:26,160 --> 00:18:30,480
devices

00:18:26,880 --> 00:18:32,480
now use this action uh and a flow table

00:18:30,480 --> 00:18:34,720
if we want to uh and a flow table

00:18:32,480 --> 00:18:36,960
register the callbacks and flow table is

00:18:34,720 --> 00:18:40,160
also not aware of these devices

00:18:36,960 --> 00:18:43,600
um tc is one of the devices that are

00:18:40,160 --> 00:18:44,160
participating in this flow but tc is not

00:18:43,600 --> 00:18:45,919
aware

00:18:44,160 --> 00:18:48,080
of the existence of the nfl table

00:18:45,919 --> 00:18:50,080
because it is internal to action city

00:18:48,080 --> 00:18:51,120
so what we're left with is the drivers

00:18:50,080 --> 00:18:54,640
themselves

00:18:51,120 --> 00:18:58,080
um when uh the ct filter

00:18:54,640 --> 00:19:00,559
flow is offloaded the uh

00:18:58,080 --> 00:19:02,559
in the offload data structure we also

00:19:00,559 --> 00:19:03,600
provide a reference to the flow table

00:19:02,559 --> 00:19:06,480
that represents

00:19:03,600 --> 00:19:08,480
this zone and once the driver receives

00:19:06,480 --> 00:19:11,919
this parameter it's able to call the

00:19:08,480 --> 00:19:14,880
nf flow table at cb dell cb methods

00:19:11,919 --> 00:19:15,600
and this is how it registers itself when

00:19:14,880 --> 00:19:18,240
the

00:19:15,600 --> 00:19:19,440
first one in the first rule that uses

00:19:18,240 --> 00:19:21,679
this flow table

00:19:19,440 --> 00:19:23,840
and deletes its callback when this is

00:19:21,679 --> 00:19:25,039
the last rule that uses the flow table

00:19:23,840 --> 00:19:29,039
or when the driver

00:19:25,039 --> 00:19:32,320
unloads um

00:19:29,039 --> 00:19:34,640
the melanox implementation the dragon

00:19:32,320 --> 00:19:36,000
implementation uh was implemented in

00:19:34,640 --> 00:19:38,320
kernel 5.7

00:19:36,000 --> 00:19:41,360
and it is done in this in the series

00:19:38,320 --> 00:19:41,360
that is referenced here

00:19:41,760 --> 00:19:45,600
so let's summarize what we're doing with

00:19:43,679 --> 00:19:47,520
this established connections upload

00:19:45,600 --> 00:19:48,880
so we started off their motivation for

00:19:47,520 --> 00:19:50,880
all of this is that because

00:19:48,880 --> 00:19:52,000
action city offloads is actually

00:19:50,880 --> 00:19:55,200
uploading the

00:19:52,000 --> 00:19:59,039
established connections um we need to

00:19:55,200 --> 00:20:02,159
uh we developed a flow table object

00:19:59,039 --> 00:20:03,440
that is managed by tc uh it is created

00:20:02,159 --> 00:20:06,400
by tc

00:20:03,440 --> 00:20:07,919
when when needed when flows become

00:20:06,400 --> 00:20:10,320
established

00:20:07,919 --> 00:20:11,120
entries are added to this table this

00:20:10,320 --> 00:20:15,360
table is

00:20:11,120 --> 00:20:17,039
is used first by software

00:20:15,360 --> 00:20:18,960
it can accelerate the software

00:20:17,039 --> 00:20:20,640
processing where it bypasses the nf

00:20:18,960 --> 00:20:22,480
contract if there's an establishment

00:20:20,640 --> 00:20:23,760
from that phone we already know what we

00:20:22,480 --> 00:20:26,880
need to do with this

00:20:23,760 --> 00:20:28,000
package and it is also used for hardware

00:20:26,880 --> 00:20:29,600
offload

00:20:28,000 --> 00:20:31,280
in order to notify the drivers on

00:20:29,600 --> 00:20:33,120
established connections

00:20:31,280 --> 00:20:34,559
uh i remind here that connection setup

00:20:33,120 --> 00:20:36,240
and teardown the packages that are

00:20:34,559 --> 00:20:37,919
responsible for this always go up to

00:20:36,240 --> 00:20:39,120
software and therefore it is managed by

00:20:37,919 --> 00:20:42,080
software

00:20:39,120 --> 00:20:43,520
aging is managed by nfl tables basically

00:20:42,080 --> 00:20:45,919
when connection is aged

00:20:43,520 --> 00:20:47,679
an entry is deleted from the flow table

00:20:45,919 --> 00:20:49,200
and this is how this

00:20:47,679 --> 00:20:51,200
and therefore it's also deleted from the

00:20:49,200 --> 00:20:53,120
hardware um

00:20:51,200 --> 00:20:54,240
and we would know that also when flows

00:20:53,120 --> 00:20:55,679
are offloaded the

00:20:54,240 --> 00:20:57,520
software also needs to get the

00:20:55,679 --> 00:20:59,200
statistics from the hardware because the

00:20:57,520 --> 00:20:59,679
software is not aware of packets going

00:20:59,200 --> 00:21:01,520
through

00:20:59,679 --> 00:21:03,039
uh flows anymore and there's also a

00:21:01,520 --> 00:21:05,039
statistics called that

00:21:03,039 --> 00:21:06,640
uh that is implemented by the device

00:21:05,039 --> 00:21:09,840
drivers to to

00:21:06,640 --> 00:21:12,080
to um reflect the uh the

00:21:09,840 --> 00:21:13,919
connection statistics to the software in

00:21:12,080 --> 00:21:17,679
a very similar manner that it is done in

00:21:13,919 --> 00:21:20,159
tc offloads

00:21:17,679 --> 00:21:21,280
um we also enhance the monitoring

00:21:20,159 --> 00:21:23,679
capabilities

00:21:21,280 --> 00:21:25,440
basically letting the user know if the

00:21:23,679 --> 00:21:26,240
connection is offloaded or not so we

00:21:25,440 --> 00:21:30,000
extended

00:21:26,240 --> 00:21:32,960
the nf contract proc fs the nf contract

00:21:30,000 --> 00:21:33,919
broker has already had a flag uh the

00:21:32,960 --> 00:21:36,559
offload flag

00:21:33,919 --> 00:21:37,919
saying that a connection is owned by nf

00:21:36,559 --> 00:21:41,039
flow table this was done

00:21:37,919 --> 00:21:42,000
uh when uh nfl uh table was introduced

00:21:41,039 --> 00:21:44,799
to the kernel

00:21:42,000 --> 00:21:46,159
so when we take ownership for that uh

00:21:44,799 --> 00:21:47,039
there is an outflow flag that is

00:21:46,159 --> 00:21:49,360
reflecting here

00:21:47,039 --> 00:21:51,520
we also added the hardware also class

00:21:49,360 --> 00:21:53,919
indicating that this connection is now

00:21:51,520 --> 00:21:56,159
in hardware this flag was also

00:21:53,919 --> 00:21:58,320
introduced in kernel 5.7

00:21:56,159 --> 00:22:00,559
in this in the apache that is referenced

00:21:58,320 --> 00:22:00,559
here

00:22:02,320 --> 00:22:06,559
let's have a quick now let's have a

00:22:04,080 --> 00:22:08,320
quick view about what's happening in the

00:22:06,559 --> 00:22:09,760
hardware model when we're offloading

00:22:08,320 --> 00:22:12,559
connection tracking

00:22:09,760 --> 00:22:14,960
so i just remind you that the hardware

00:22:12,559 --> 00:22:17,600
basically replicates the software model

00:22:14,960 --> 00:22:18,640
the hardware is um connection tracking

00:22:17,600 --> 00:22:20,880
is a

00:22:18,640 --> 00:22:22,559
multi-chain process because the first

00:22:20,880 --> 00:22:24,320
chain would send the pack into the

00:22:22,559 --> 00:22:26,480
to do a connection tracking database

00:22:24,320 --> 00:22:27,120
lookup and only once the lookup is

00:22:26,480 --> 00:22:29,039
complete

00:22:27,120 --> 00:22:31,440
we're basically able to steer the packet

00:22:29,039 --> 00:22:34,480
based on the connection tracking state

00:22:31,440 --> 00:22:37,679
so we would call the connection tracking

00:22:34,480 --> 00:22:39,760
and recirculate back to the packet

00:22:37,679 --> 00:22:41,120
classification but now we can also match

00:22:39,760 --> 00:22:44,320
on the city states

00:22:41,120 --> 00:22:44,960
so connection tracking logic is broken

00:22:44,320 --> 00:22:48,559
down

00:22:44,960 --> 00:22:50,880
to at least two chains okay

00:22:48,559 --> 00:22:52,799
and and when we offer that we're not

00:22:50,880 --> 00:22:53,600
really aware what the packet is doing

00:22:52,799 --> 00:22:56,640
that we're just

00:22:53,600 --> 00:22:57,039
offloading the filters one by one as

00:22:56,640 --> 00:22:59,440
they

00:22:57,039 --> 00:23:01,200
are added to the system so the first

00:22:59,440 --> 00:23:02,559
filter that is added to the system is a

00:23:01,200 --> 00:23:04,960
filter that is defined here in this

00:23:02,559 --> 00:23:08,159
example on chain zero prior one

00:23:04,960 --> 00:23:09,200
uh which does some tcp classification on

00:23:08,159 --> 00:23:10,480
destination port

00:23:09,200 --> 00:23:12,480
and then sends to the connection

00:23:10,480 --> 00:23:13,360
tracking action and continues in chain

00:23:12,480 --> 00:23:15,360
two

00:23:13,360 --> 00:23:17,520
when we receive so in hardware we have a

00:23:15,360 --> 00:23:19,520
table per chain prior every chain

00:23:17,520 --> 00:23:21,280
parallel has a specific table

00:23:19,520 --> 00:23:22,799
so here it's chain zero prime one so we

00:23:21,280 --> 00:23:25,120
will add this table to the hardware

00:23:22,799 --> 00:23:26,880
table representing chain zero prior one

00:23:25,120 --> 00:23:29,120
we will add the flow matches between

00:23:26,880 --> 00:23:30,559
matching on ip tcp and the destination

00:23:29,120 --> 00:23:32,159
uh tcp port

00:23:30,559 --> 00:23:34,320
and the action would be well we could

00:23:32,159 --> 00:23:36,880
decap if this was a big fan

00:23:34,320 --> 00:23:38,159
for example or a tunneled packet and

00:23:36,880 --> 00:23:40,559
then instead of

00:23:38,159 --> 00:23:42,480
doing connection tracking action we

00:23:40,559 --> 00:23:44,240
basically jump to a temple

00:23:42,480 --> 00:23:45,840
that has the connection that the

00:23:44,240 --> 00:23:48,480
connection tracking entries that are

00:23:45,840 --> 00:23:50,400
established

00:23:48,480 --> 00:23:52,080
when we receive the offload request to

00:23:50,400 --> 00:23:53,440
also this command we actually see that

00:23:52,080 --> 00:23:56,240
this command tries to match

00:23:53,440 --> 00:23:56,640
on this filter tries to uh match on the

00:23:56,240 --> 00:23:59,919
new

00:23:56,640 --> 00:24:01,200
and tracked city state and uh this is

00:23:59,919 --> 00:24:03,039
we know that this is something that we

00:24:01,200 --> 00:24:04,880
cannot offer so we basically don't do

00:24:03,039 --> 00:24:07,600
anything with this and we don't put this

00:24:04,880 --> 00:24:08,240
flowing hardware when we receive the

00:24:07,600 --> 00:24:11,600
third

00:24:08,240 --> 00:24:13,440
um filter uh to off to offload

00:24:11,600 --> 00:24:15,600
then this filter is defined on chain two

00:24:13,440 --> 00:24:18,240
prior one so we basically added to the

00:24:15,600 --> 00:24:20,000
chain two prior one table we match on

00:24:18,240 --> 00:24:21,360
the matches in the dispenser discussion

00:24:20,000 --> 00:24:24,080
matches on the ip

00:24:21,360 --> 00:24:25,039
and the ct state and then its action is

00:24:24,080 --> 00:24:28,240
to forward

00:24:25,039 --> 00:24:30,480
to um here a representer which in the

00:24:28,240 --> 00:24:31,279
embedded piece which is translated to a

00:24:30,480 --> 00:24:35,120
v port

00:24:31,279 --> 00:24:36,880
using this example of v port one

00:24:35,120 --> 00:24:38,799
what happens when the connection becomes

00:24:36,880 --> 00:24:40,559
established so establish connection

00:24:38,799 --> 00:24:41,840
again is another entry point for the

00:24:40,559 --> 00:24:44,720
hardware offload

00:24:41,840 --> 00:24:45,520
an established connection right uh

00:24:44,720 --> 00:24:48,080
offloads it

00:24:45,520 --> 00:24:49,840
to the city table to a global city table

00:24:48,080 --> 00:24:52,799
that is managed by the hardware

00:24:49,840 --> 00:24:55,440
where it matches on the city um zone and

00:24:52,799 --> 00:24:58,080
a city on the city zone in five chapel

00:24:55,440 --> 00:24:59,760
and if there is a match then it sets the

00:24:58,080 --> 00:25:00,799
the city state on some hardware

00:24:59,760 --> 00:25:02,559
registers

00:25:00,799 --> 00:25:04,640
and then it continues to jump on chain

00:25:02,559 --> 00:25:06,320
two prior one table

00:25:04,640 --> 00:25:07,679
once all of this is performed we can see

00:25:06,320 --> 00:25:09,360
that this pro this package

00:25:07,679 --> 00:25:10,720
is actually processed in hardware when

00:25:09,360 --> 00:25:11,760
it starts it does the initial

00:25:10,720 --> 00:25:14,080
classifications

00:25:11,760 --> 00:25:16,400
jumps to the ct action if there is an

00:25:14,080 --> 00:25:18,000
established it sets the city state

00:25:16,400 --> 00:25:19,919
if this if this is established in the

00:25:18,000 --> 00:25:21,600
city state mark and label will be

00:25:19,919 --> 00:25:22,960
initialized and will continue in chain

00:25:21,600 --> 00:25:24,480
two which will do another match and

00:25:22,960 --> 00:25:26,480
forward to this v table

00:25:24,480 --> 00:25:30,640
this is basically how we replicate the

00:25:26,480 --> 00:25:30,640
software model in hardware

00:25:31,120 --> 00:25:34,640
the thing is is that once we start with

00:25:33,440 --> 00:25:36,480
this multi-table

00:25:34,640 --> 00:25:38,400
architecture and hardware and we're

00:25:36,480 --> 00:25:39,240
jumping from one table and all of this

00:25:38,400 --> 00:25:42,159
is done

00:25:39,240 --> 00:25:44,320
asynchronously and not atomically

00:25:42,159 --> 00:25:45,520
then we're basically exposed to hardware

00:25:44,320 --> 00:25:48,880
misses

00:25:45,520 --> 00:25:52,720
that means that um the hardware can can

00:25:48,880 --> 00:25:55,279
start the processing but not complete it

00:25:52,720 --> 00:25:56,960
okay in this example for example if this

00:25:55,279 --> 00:25:58,720
if we were in the initial state and we

00:25:56,960 --> 00:26:00,720
also knew also that the first rule

00:25:58,720 --> 00:26:01,840
then we would do the matching jump to

00:26:00,720 --> 00:26:04,159
the city table

00:26:01,840 --> 00:26:05,919
the city table would not have the entry

00:26:04,159 --> 00:26:08,000
and it would miss

00:26:05,919 --> 00:26:10,080
and in every week what we need to do is

00:26:08,000 --> 00:26:11,600
to continue in software wherever the

00:26:10,080 --> 00:26:13,440
hardware left off

00:26:11,600 --> 00:26:15,600
and the reason for that is that the

00:26:13,440 --> 00:26:18,080
hardware may have already updated

00:26:15,600 --> 00:26:20,240
filter statistics and and the counter

00:26:18,080 --> 00:26:22,799
and the packets will be counted twice

00:26:20,240 --> 00:26:24,080
and in addition um it could have

00:26:22,799 --> 00:26:25,679
processed some packet

00:26:24,080 --> 00:26:27,440
manual action so the packet may have

00:26:25,679 --> 00:26:28,960
been modified and if we would start

00:26:27,440 --> 00:26:29,760
roasting the packet from the beginning

00:26:28,960 --> 00:26:31,600
we will actually

00:26:29,760 --> 00:26:33,200
not match because it's not the original

00:26:31,600 --> 00:26:34,880
packet anymore

00:26:33,200 --> 00:26:37,760
we can think the most trivial example to

00:26:34,880 --> 00:26:39,840
think about is is encapsulated packets

00:26:37,760 --> 00:26:41,520
the first rule may have decapsulated the

00:26:39,840 --> 00:26:42,880
packet and now we have a miss

00:26:41,520 --> 00:26:44,880
so when we will miss we will need to

00:26:42,880 --> 00:26:46,080
communicate the driver to to start from

00:26:44,880 --> 00:26:48,880
the chain that missed

00:26:46,080 --> 00:26:49,279
and to restore the tunnel information

00:26:48,880 --> 00:26:52,400
that

00:26:49,279 --> 00:26:55,279
was decapitated

00:26:52,400 --> 00:26:56,159
uh um so this can be seen in this

00:26:55,279 --> 00:26:59,440
example when

00:26:56,159 --> 00:27:00,880
when we do some matches we actually have

00:26:59,440 --> 00:27:01,679
the established connection state but

00:27:00,880 --> 00:27:04,080
then we meet

00:27:01,679 --> 00:27:04,720
on the second rule and basically we have

00:27:04,080 --> 00:27:07,360
here

00:27:04,720 --> 00:27:08,240
the software start processing from tc

00:27:07,360 --> 00:27:10,320
chain 2

00:27:08,240 --> 00:27:12,080
while restoring the tunnel info and also

00:27:10,320 --> 00:27:14,960
restoring the city state because

00:27:12,080 --> 00:27:16,799
the software expects already to have an

00:27:14,960 --> 00:27:19,919
initialized

00:27:16,799 --> 00:27:21,440
city state on the skb so what we were

00:27:19,919 --> 00:27:23,279
missing in terms of the platform in

00:27:21,440 --> 00:27:26,559
order to enable that is to somehow

00:27:23,279 --> 00:27:29,520
communicate to tc where to start

00:27:26,559 --> 00:27:31,120
and and and this was and in order to

00:27:29,520 --> 00:27:32,000
provide this information we had to

00:27:31,120 --> 00:27:35,120
extend

00:27:32,000 --> 00:27:38,240
the skb via a tcskb

00:27:35,120 --> 00:27:40,799
extension where we could store the last

00:27:38,240 --> 00:27:41,840
um a chain that was processed in

00:27:40,799 --> 00:27:45,440
hardware

00:27:41,840 --> 00:27:48,559
and and and having this at the beginning

00:27:45,440 --> 00:27:51,039
uh the beginning change for tc to start

00:27:48,559 --> 00:27:53,840
processing

00:27:51,039 --> 00:27:54,480
actually this requirement is not uh just

00:27:53,840 --> 00:27:57,440
for

00:27:54,480 --> 00:27:58,640
hardware misses it's actually also

00:27:57,440 --> 00:28:01,600
relevant for

00:27:58,640 --> 00:28:03,279
open v-switch because open once open v

00:28:01,600 --> 00:28:05,600
switch offload this then open v switch

00:28:03,279 --> 00:28:08,480
relies on the tc data path

00:28:05,600 --> 00:28:09,520
uh to do it on tc to do the data path

00:28:08,480 --> 00:28:12,159
processing

00:28:09,520 --> 00:28:13,200
and and the way it works is that tc

00:28:12,159 --> 00:28:15,840
comes first

00:28:13,200 --> 00:28:17,360
in the rx pipeline in the kernel so this

00:28:15,840 --> 00:28:20,000
is done first and only then

00:28:17,360 --> 00:28:21,279
the open v switch rx handler is being

00:28:20,000 --> 00:28:23,919
processed

00:28:21,279 --> 00:28:24,799
so so again because we have this

00:28:23,919 --> 00:28:28,720
multi-chain

00:28:24,799 --> 00:28:29,760
architecture um tc can start processing

00:28:28,720 --> 00:28:32,960
the chains

00:28:29,760 --> 00:28:33,840
and then it can jump so so so openv

00:28:32,960 --> 00:28:36,240
switch has

00:28:33,840 --> 00:28:36,960
the same notion of chains which is

00:28:36,240 --> 00:28:40,200
called the

00:28:36,960 --> 00:28:43,039
recirculations and and open v switch

00:28:40,200 --> 00:28:45,440
recirculations are directly mapped to tc

00:28:43,039 --> 00:28:46,880
chains so cc can start processing the

00:28:45,440 --> 00:28:49,039
packet in some chains

00:28:46,880 --> 00:28:51,360
and then it can jump to a chain which is

00:28:49,039 --> 00:28:53,520
not offloaded to tc maybe because

00:28:51,360 --> 00:28:55,760
uh there's no tc support for that action

00:28:53,520 --> 00:28:58,159
or because asynchronously

00:28:55,760 --> 00:29:00,159
the packet wouldn't um it was not

00:28:58,159 --> 00:29:03,360
offloaded to dc yet

00:29:00,159 --> 00:29:05,039
and and then tc would miss it would not

00:29:03,360 --> 00:29:06,080
do what to continue with this packet and

00:29:05,039 --> 00:29:08,320
the packet would go

00:29:06,080 --> 00:29:11,600
to it continue down the kernel pipeline

00:29:08,320 --> 00:29:13,679
and we'll enter the open views which

00:29:11,600 --> 00:29:15,679
are its handler in this case the open v

00:29:13,679 --> 00:29:17,039
switch also needs to start processing

00:29:15,679 --> 00:29:18,880
from the circulation

00:29:17,039 --> 00:29:21,200
one in this example and not from zero

00:29:18,880 --> 00:29:23,120
from the same reasons because the packet

00:29:21,200 --> 00:29:25,120
first was counted and then it could have

00:29:23,120 --> 00:29:27,679
been recirculated it could have been

00:29:25,120 --> 00:29:28,159
manipulated and wouldn't know how to do

00:29:27,679 --> 00:29:31,120
so

00:29:28,159 --> 00:29:32,960
we used the same tcskb extension to also

00:29:31,120 --> 00:29:35,279
communicate the last chain that was

00:29:32,960 --> 00:29:36,720
processing tc that may be used in openly

00:29:35,279 --> 00:29:39,279
switched

00:29:36,720 --> 00:29:40,880
this um extension was introduced already

00:29:39,279 --> 00:29:44,480
in kernel 5.3

00:29:40,880 --> 00:29:44,480
in this patch set

00:29:44,559 --> 00:29:48,159
so to summarize the work that was done

00:29:46,720 --> 00:29:49,440
this summary is actually in the

00:29:48,159 --> 00:29:52,000
chronological order

00:29:49,440 --> 00:29:52,880
that the series were applied to the

00:29:52,000 --> 00:29:56,000
kernel

00:29:52,880 --> 00:29:57,919
um we first needed to introduce

00:29:56,000 --> 00:29:59,520
uh tc connection tracking action

00:29:57,919 --> 00:30:01,760
classifier uh

00:29:59,520 --> 00:30:03,200
to software even in software so this was

00:30:01,760 --> 00:30:06,320
introduced first

00:30:03,200 --> 00:30:08,880
then we extended um the skd

00:30:06,320 --> 00:30:10,320
to allow um communicating their

00:30:08,880 --> 00:30:13,520
circulation id

00:30:10,320 --> 00:30:15,120
uh to tc to allow tc to continue from

00:30:13,520 --> 00:30:16,640
where to allow obs to continue from

00:30:15,120 --> 00:30:18,480
where tc left off

00:30:16,640 --> 00:30:19,840
then we did the multiplication in net

00:30:18,480 --> 00:30:22,480
filter to extend

00:30:19,840 --> 00:30:24,080
the flow table to support hardware also

00:30:22,480 --> 00:30:27,279
this is the work that we've done

00:30:24,080 --> 00:30:30,640
uh jointly with pablo then um

00:30:27,279 --> 00:30:31,600
we used this uh these net filter

00:30:30,640 --> 00:30:34,080
infrastructure

00:30:31,600 --> 00:30:34,640
in action city we first used it in

00:30:34,080 --> 00:30:36,880
software

00:30:34,640 --> 00:30:39,919
basically we populated the the net

00:30:36,880 --> 00:30:42,080
filter um we created the net filter

00:30:39,919 --> 00:30:43,679
flow tables and we populate them with

00:30:42,080 --> 00:30:45,120
established connection used it in

00:30:43,679 --> 00:30:48,960
software

00:30:45,120 --> 00:30:52,240
then we added the um the monitoring

00:30:48,960 --> 00:30:53,600
capability for uh to monitor connections

00:30:52,240 --> 00:30:56,880
that are in hardware

00:30:53,600 --> 00:30:57,830
uh and lastly we uh

00:30:56,880 --> 00:31:00,399
we

00:30:57,830 --> 00:31:01,919
[Music]

00:31:00,399 --> 00:31:03,840
upstream the melon obstructor

00:31:01,919 --> 00:31:06,240
implementation for for connection

00:31:03,840 --> 00:31:06,240
tracking

00:31:06,640 --> 00:31:12,880
now a word about uh performance um

00:31:09,760 --> 00:31:15,200
um before we conclude um we're actually

00:31:12,880 --> 00:31:17,519
um i'm still working on the performance

00:31:15,200 --> 00:31:20,480
full performance report in our lab

00:31:17,519 --> 00:31:20,799
we will we will publish it when it will

00:31:20,480 --> 00:31:24,480
be

00:31:20,799 --> 00:31:26,880
available but what we can say is that

00:31:24,480 --> 00:31:27,519
um when we look at large scales for

00:31:26,880 --> 00:31:29,760
example

00:31:27,519 --> 00:31:31,120
when we have systems that have uh that

00:31:29,760 --> 00:31:33,120
that have a

00:31:31,120 --> 00:31:34,720
connection track database that has about

00:31:33,120 --> 00:31:35,919
one million connections

00:31:34,720 --> 00:31:38,000
then we see that the software

00:31:35,919 --> 00:31:39,919
performance is about

00:31:38,000 --> 00:31:42,000
one million connections per se at one

00:31:39,919 --> 00:31:45,120
sorry one million packets per second

00:31:42,000 --> 00:31:46,480
and when we offload we're basically able

00:31:45,120 --> 00:31:49,519
to achieve

00:31:46,480 --> 00:31:49,519
um um

00:31:49,600 --> 00:31:54,480
about 20 about line rate performance for

00:31:53,279 --> 00:31:57,600
25 gig

00:31:54,480 --> 00:31:59,840
interfaces that means

00:31:57,600 --> 00:32:01,360
about 23 million packets per second

00:31:59,840 --> 00:32:05,200
these are these are like

00:32:01,360 --> 00:32:08,480
encapsulated traffic 114 bytes

00:32:05,200 --> 00:32:09,840
over 25g ports so we're basically able

00:32:08,480 --> 00:32:13,519
to achieve line rate

00:32:09,840 --> 00:32:16,880
uh performance um versus about 1 million

00:32:13,519 --> 00:32:17,600
packets per second um we can think about

00:32:16,880 --> 00:32:20,559
it for

00:32:17,600 --> 00:32:22,000
for about um five percent uh port

00:32:20,559 --> 00:32:23,840
utilization

00:32:22,000 --> 00:32:25,600
bandwidth utilization compared to one

00:32:23,840 --> 00:32:29,840
hundred percent that determination with

00:32:25,600 --> 00:32:29,840
hardware outlets

00:32:30,159 --> 00:32:33,200
that's it thank you all

00:32:37,279 --> 00:32:41,679
uh so thank you so um for the purpose of

00:32:40,960 --> 00:32:44,159
the

00:32:41,679 --> 00:32:46,960
purposes of discussion i'd like to maybe

00:32:44,159 --> 00:32:50,159
divide this up into two parts

00:32:46,960 --> 00:32:50,960
uh the first part the the apis which i

00:32:50,159 --> 00:32:53,200
think

00:32:50,960 --> 00:32:56,240
um were covered very well in the

00:32:53,200 --> 00:32:59,279
presentation so the apis to set this up

00:32:56,240 --> 00:33:00,000
uh the commands the extensions uh i

00:32:59,279 --> 00:33:01,840
think that's

00:33:00,000 --> 00:33:03,760
that's one category so obviously you

00:33:01,840 --> 00:33:06,000
want to have the correct apis and make

00:33:03,760 --> 00:33:08,240
it generic uh to control

00:33:06,000 --> 00:33:10,480
connection tracking offline but the

00:33:08,240 --> 00:33:13,279
second it's a little more um

00:33:10,480 --> 00:33:14,240
on the philosophical side and and some

00:33:13,279 --> 00:33:17,279
of the questions

00:33:14,240 --> 00:33:20,000
uh are going to quickly get into these

00:33:17,279 --> 00:33:21,919
so when we offload connection tracking

00:33:20,000 --> 00:33:25,760
and hardware

00:33:21,919 --> 00:33:28,640
this instantly creates

00:33:25,760 --> 00:33:30,080
some convolutions so for instance first

00:33:28,640 --> 00:33:31,039
question people are going to ask is how

00:33:30,080 --> 00:33:34,480
many

00:33:31,039 --> 00:33:37,679
how many flows can you offload and

00:33:34,480 --> 00:33:40,880
as we know hardware memory

00:33:37,679 --> 00:33:42,000
is almost always a fraction of host

00:33:40,880 --> 00:33:45,919
memory

00:33:42,000 --> 00:33:46,399
so what happens when somebody tries to

00:33:45,919 --> 00:33:49,279
push

00:33:46,399 --> 00:33:49,760
the limits and we go beyond that so that

00:33:49,279 --> 00:33:51,600
gets us

00:33:49,760 --> 00:33:52,799
into the need for state evictions and

00:33:51,600 --> 00:33:56,159
things like that

00:33:52,799 --> 00:33:58,000
so in that regard and this problem

00:33:56,159 --> 00:33:59,760
really is no different than

00:33:58,000 --> 00:34:02,000
any other device in the network that's

00:33:59,760 --> 00:34:05,039
doing connection tracking

00:34:02,000 --> 00:34:06,000
when we do that it creates um those sort

00:34:05,039 --> 00:34:08,560
of headaches the other one

00:34:06,000 --> 00:34:10,320
that that comes to mind is what if we

00:34:08,560 --> 00:34:13,280
have multiple device systems

00:34:10,320 --> 00:34:13,839
and the receive path and the transmit

00:34:13,280 --> 00:34:16,240
paths are

00:34:13,839 --> 00:34:18,639
asymmetric such that the receive path is

00:34:16,240 --> 00:34:21,359
one device and the

00:34:18,639 --> 00:34:22,560
transit path is another and in fact that

00:34:21,359 --> 00:34:23,760
could actually change in the middle of

00:34:22,560 --> 00:34:26,560
the flow

00:34:23,760 --> 00:34:27,119
so these are things that we need to

00:34:26,560 --> 00:34:29,119
consider

00:34:27,119 --> 00:34:30,320
um the multi-path problem is basically

00:34:29,119 --> 00:34:33,520
undissolved by

00:34:30,320 --> 00:34:35,200
stateful firewalls unfortunately um

00:34:33,520 --> 00:34:37,200
but in host case it's kind of

00:34:35,200 --> 00:34:39,520
interesting because

00:34:37,200 --> 00:34:41,760
the host itself had actually been doing

00:34:39,520 --> 00:34:45,119
the connection tracking would see

00:34:41,760 --> 00:34:48,639
all of those packets so um

00:34:45,119 --> 00:34:49,760
with that let's see uh

00:34:48,639 --> 00:34:52,720
uh let's go through some of the

00:34:49,760 --> 00:34:55,599
questions um the concept of

00:34:52,720 --> 00:34:58,640
flow state could that work for udp as

00:34:55,599 --> 00:35:03,040
well or is the strictly tcp

00:34:58,640 --> 00:35:06,000
also also udp udpntc

00:35:03,040 --> 00:35:07,920
okay so presumably in udp since it's a

00:35:06,000 --> 00:35:09,599
stateless protocol

00:35:07,920 --> 00:35:11,119
we're doing that kind of creating soft

00:35:09,599 --> 00:35:13,280
state

00:35:11,119 --> 00:35:14,720
um as opposed to tcp where we're

00:35:13,280 --> 00:35:18,000
tracking the actual

00:35:14,720 --> 00:35:20,160
um tcp connection state

00:35:18,000 --> 00:35:22,160
well actually even in tcp connection

00:35:20,160 --> 00:35:23,839
like for connection tracking the

00:35:22,160 --> 00:35:25,760
it enters the established state when it

00:35:23,839 --> 00:35:26,240
sees the bi-directional traffic it's not

00:35:25,760 --> 00:35:28,640
really

00:35:26,240 --> 00:35:30,800
aware of the tcp it's not it's not the

00:35:28,640 --> 00:35:32,880
tcp protocol that is uh

00:35:30,800 --> 00:35:34,880
that is dictating this so the only thing

00:35:32,880 --> 00:35:38,640
is that tcp has um

00:35:34,880 --> 00:35:39,520
as um as a very it can shut down

00:35:38,640 --> 00:35:43,280
connections

00:35:39,520 --> 00:35:47,680
uh explicitly for utk they will only age

00:35:43,280 --> 00:35:51,359
um so so

00:35:47,680 --> 00:35:53,599
so we actually offload both tcp and udp

00:35:51,359 --> 00:35:55,119
okay so in the case of tcp what happens

00:35:53,599 --> 00:35:59,680
if we get

00:35:55,119 --> 00:36:02,240
a regular packet not a sin

00:35:59,680 --> 00:36:05,760
that we don't recognize would we try to

00:36:02,240 --> 00:36:05,760
create a connection state for this

00:36:07,359 --> 00:36:11,040
again i'm not i wasn't following so so

00:36:09,839 --> 00:36:14,480
in the case of tcp

00:36:11,040 --> 00:36:16,640
suppose we receive a

00:36:14,480 --> 00:36:18,960
plain tcp packet without the send flag

00:36:16,640 --> 00:36:22,000
without the thin flag

00:36:18,960 --> 00:36:22,880
for some connection and suppose a device

00:36:22,000 --> 00:36:24,720
can't

00:36:22,880 --> 00:36:28,079
can't identify that so it never saw the

00:36:24,720 --> 00:36:30,480
three-way handshake what would happen

00:36:28,079 --> 00:36:32,160
so it's it's uh it's a it's either the

00:36:30,480 --> 00:36:33,040
connection is identified by the hardware

00:36:32,160 --> 00:36:35,520
or not okay

00:36:33,040 --> 00:36:37,119
every time that that so for example when

00:36:35,520 --> 00:36:38,400
we receive a packet and there's the ct

00:36:37,119 --> 00:36:39,920
action so we

00:36:38,400 --> 00:36:41,839
basically process the packet through the

00:36:39,920 --> 00:36:44,560
ct table that we store in hardware

00:36:41,839 --> 00:36:45,200
so if if we don't have a record for this

00:36:44,560 --> 00:36:47,280
connection

00:36:45,200 --> 00:36:48,800
then we will miss and it will go up to

00:36:47,280 --> 00:36:50,240
software and then software will

00:36:48,800 --> 00:36:53,280
will continue the processing of that

00:36:50,240 --> 00:36:54,480
packet so it's either in hardware or not

00:36:53,280 --> 00:36:56,160
in hardware

00:36:54,480 --> 00:36:58,240
and and there's no there's nothing in

00:36:56,160 --> 00:36:59,920
the middle there so uh

00:36:58,240 --> 00:37:02,480
so so it will always be handled

00:36:59,920 --> 00:37:04,960
correctly so so we copy we copycat

00:37:02,480 --> 00:37:06,839
what is the software is doing we're not

00:37:04,960 --> 00:37:09,280
we are offloading only established

00:37:06,839 --> 00:37:11,040
connections

00:37:09,280 --> 00:37:13,040
well sort of right but if we're doing

00:37:11,040 --> 00:37:14,320
this in udp there's no concept of

00:37:13,040 --> 00:37:16,960
established connections so

00:37:14,320 --> 00:37:17,680
we have a bit of a disparity in the

00:37:16,960 --> 00:37:20,480
models

00:37:17,680 --> 00:37:22,640
so i'm assuming in udp when we receive a

00:37:20,480 --> 00:37:23,200
packet we don't recognize we just create

00:37:22,640 --> 00:37:26,640
a

00:37:23,200 --> 00:37:27,680
state for it but tcp it's a little a

00:37:26,640 --> 00:37:30,160
little more difficult

00:37:27,680 --> 00:37:31,839
and if we're doing a firewall off it or

00:37:30,160 --> 00:37:35,040
something like that then

00:37:31,839 --> 00:37:38,240
this could have other ramifications

00:37:35,040 --> 00:37:40,000
okay so we are we are offloading so we

00:37:38,240 --> 00:37:42,880
are not choosing what to do

00:37:40,000 --> 00:37:45,599
we bring the pocket to the software and

00:37:42,880 --> 00:37:47,680
what the software is decide

00:37:45,599 --> 00:37:48,880
we're doing the same thing we're just

00:37:47,680 --> 00:37:52,079
offloading if the

00:37:48,880 --> 00:37:55,200
connection is established and

00:37:52,079 --> 00:37:56,640
and as i said for udp also udp has an

00:37:55,200 --> 00:37:58,400
established state in

00:37:56,640 --> 00:37:59,760
connection tracking basically once it

00:37:58,400 --> 00:38:01,280
sees bi-directional traffic it's

00:37:59,760 --> 00:38:02,960
established

00:38:01,280 --> 00:38:04,480
according to the definitions of

00:38:02,960 --> 00:38:08,079
connection track

00:38:04,480 --> 00:38:10,400
so um so so even though

00:38:08,079 --> 00:38:11,200
even though udp is stateless okay it

00:38:10,400 --> 00:38:13,359
doesn't it

00:38:11,200 --> 00:38:14,720
it doesn't have connections but for

00:38:13,359 --> 00:38:16,320
connection tracking still hasn't

00:38:14,720 --> 00:38:18,480
established it

00:38:16,320 --> 00:38:19,920
okay that's an interesting question so

00:38:18,480 --> 00:38:23,520
if we receive a udp

00:38:19,920 --> 00:38:26,240
packet that we don't recognize

00:38:23,520 --> 00:38:26,240
what happens

00:38:27,520 --> 00:38:34,240
so so again if if the packet is

00:38:31,680 --> 00:38:35,680
not in heart not recognized i'm not

00:38:34,240 --> 00:38:37,599
really clear what what you mean by not

00:38:35,680 --> 00:38:39,440
recognized but if the packet is not if

00:38:37,599 --> 00:38:41,440
for some reason we don't have this five

00:38:39,440 --> 00:38:44,560
tuple in hardware

00:38:41,440 --> 00:38:46,160
then we just then then then our hardware

00:38:44,560 --> 00:38:48,240
just will send up this packet to the

00:38:46,160 --> 00:38:51,040
relevant representative so

00:38:48,240 --> 00:38:52,000
so um so it will continue processing in

00:38:51,040 --> 00:38:54,079
software

00:38:52,000 --> 00:38:55,359
and this is the the work that we did to

00:38:54,079 --> 00:38:57,839
make sure that the pros

00:38:55,359 --> 00:38:58,960
that the software receives all the state

00:38:57,839 --> 00:39:00,560
that was

00:38:58,960 --> 00:39:02,000
that will continue processing according

00:39:00,560 --> 00:39:04,320
to the last state that was

00:39:02,000 --> 00:39:06,240
um stored by the hardware meaning that

00:39:04,320 --> 00:39:08,000
if they had already jumped to multiple

00:39:06,240 --> 00:39:09,599
to it to a certain chain then we would

00:39:08,000 --> 00:39:11,119
be able to restore the last chain that

00:39:09,599 --> 00:39:13,359
was processing hardware

00:39:11,119 --> 00:39:15,040
if if if it went through ct already and

00:39:13,359 --> 00:39:16,560
it already has some city state we will

00:39:15,040 --> 00:39:19,280
restore the city state

00:39:16,560 --> 00:39:19,839
if the packet was decapsulated and now

00:39:19,280 --> 00:39:21,680
um

00:39:19,839 --> 00:39:23,839
the the packet itself does not have the

00:39:21,680 --> 00:39:25,839
outer headers like the tunnel headers

00:39:23,839 --> 00:39:27,200
we will restore the tunnel info and put

00:39:25,839 --> 00:39:30,000
it on the skb

00:39:27,200 --> 00:39:31,040
so from a software perspective uh it

00:39:30,000 --> 00:39:33,440
would just continue

00:39:31,040 --> 00:39:34,720
processing from the point where the

00:39:33,440 --> 00:39:36,480
hardware laptop

00:39:34,720 --> 00:39:38,560
so if you started processing the packet

00:39:36,480 --> 00:39:40,079
hit some wanted to do connection

00:39:38,560 --> 00:39:40,720
tracking there was no record in hardware

00:39:40,079 --> 00:39:42,400
for that

00:39:40,720 --> 00:39:43,839
it goes up software so it has everything

00:39:42,400 --> 00:39:46,240
it needs to continue its processing in

00:39:43,839 --> 00:39:46,240
software

00:39:46,480 --> 00:39:51,520
okay so there was a question um is this

00:39:48,880 --> 00:39:53,119
appropriate for short-lived connections

00:39:51,520 --> 00:39:54,560
yeah that's a good question obviously

00:39:53,119 --> 00:39:55,280
short-lived connections and there are

00:39:54,560 --> 00:39:58,720
many of those

00:39:55,280 --> 00:40:00,720
um we know um they're

00:39:58,720 --> 00:40:02,000
they wouldn't benefit that much from

00:40:00,720 --> 00:40:05,359
from offloads

00:40:02,000 --> 00:40:08,000
but um as we know uh um

00:40:05,359 --> 00:40:08,480
and and we know even more that that that

00:40:08,000 --> 00:40:12,000
uh

00:40:08,480 --> 00:40:15,040
internet traffic and web traffic is

00:40:12,000 --> 00:40:18,640
has um a fat tail distribution

00:40:15,040 --> 00:40:20,560
so um so so currently we don't make the

00:40:18,640 --> 00:40:21,920
distinctions between um

00:40:20,560 --> 00:40:23,440
between short-lived and long-lived

00:40:21,920 --> 00:40:24,000
connect between myself and elephant

00:40:23,440 --> 00:40:26,880
clothes but

00:40:24,000 --> 00:40:28,160
um we do wanted we we had an attempt but

00:40:26,880 --> 00:40:30,800
we need to revise it

00:40:28,160 --> 00:40:32,240
of of of introducing to tc some type of

00:40:30,800 --> 00:40:35,760
offload policy

00:40:32,240 --> 00:40:38,560
saying um some type of policy um

00:40:35,760 --> 00:40:40,240
that would characterize when we would

00:40:38,560 --> 00:40:42,319
like to offload the connection so

00:40:40,240 --> 00:40:43,280
so so the first parameters that come to

00:40:42,319 --> 00:40:45,359
mind is

00:40:43,280 --> 00:40:46,720
number of packets or number of bytes

00:40:45,359 --> 00:40:48,640
that go through a connection

00:40:46,720 --> 00:40:50,480
and and once you reach a certain

00:40:48,640 --> 00:40:53,359
threshold um

00:40:50,480 --> 00:40:55,440
um uh only then this connection will be

00:40:53,359 --> 00:40:58,319
established it will be offloaded

00:40:55,440 --> 00:40:58,800
so um and this and this would also that

00:40:58,319 --> 00:41:00,960
give

00:40:58,800 --> 00:41:02,800
a lot of value for the offload and also

00:41:00,960 --> 00:41:04,880
would relieve some of the stress

00:41:02,800 --> 00:41:07,200
of um the insertion rate because

00:41:04,880 --> 00:41:09,520
basically the bottleneck for this is the

00:41:07,200 --> 00:41:10,640
keep of how many flows the hardware is

00:41:09,520 --> 00:41:14,560
able to

00:41:10,640 --> 00:41:14,560
um to introduce per second

00:41:14,640 --> 00:41:18,640
i don't quite understand that so if i'm

00:41:16,560 --> 00:41:20,160
counting the number of packets or bytes

00:41:18,640 --> 00:41:22,720
on a connection

00:41:20,160 --> 00:41:24,800
don't i have to establish a state in the

00:41:22,720 --> 00:41:27,200
device to be able to count the packets

00:41:24,800 --> 00:41:27,839
no so the idea is i mean again a

00:41:27,200 --> 00:41:30,960
connection

00:41:27,839 --> 00:41:33,280
is is offloaded to hardware when the

00:41:30,960 --> 00:41:34,000
software decides to offload it meaning

00:41:33,280 --> 00:41:36,880
when action

00:41:34,000 --> 00:41:38,640
city decides to offload it so so we

00:41:36,880 --> 00:41:40,319
could postpone the offload so currently

00:41:38,640 --> 00:41:41,839
when a connection enters the establish

00:41:40,319 --> 00:41:43,359
this is when we create the flow table

00:41:41,839 --> 00:41:44,000
entry and then it's offloaded to

00:41:43,359 --> 00:41:48,319
hardware

00:41:44,000 --> 00:41:50,400
but we can postpone the the

00:41:48,319 --> 00:41:51,760
when we create this record on the flow

00:41:50,400 --> 00:41:54,720
table to the

00:41:51,760 --> 00:41:56,240
according to those counters so so we can

00:41:54,720 --> 00:41:58,480
still process the packet in

00:41:56,240 --> 00:41:59,599
in software okay it would go through

00:41:58,480 --> 00:42:01,920
action city

00:41:59,599 --> 00:42:03,040
action city would would count the bytes

00:42:01,920 --> 00:42:05,040
on every connection and

00:42:03,040 --> 00:42:07,760
would then be able to know and then it

00:42:05,040 --> 00:42:09,599
would be able to apply this post

00:42:07,760 --> 00:42:11,040
so when it would hit like for example

00:42:09,599 --> 00:42:13,040
the number of packet marks then

00:42:11,040 --> 00:42:14,800
then it would just create only then it

00:42:13,040 --> 00:42:18,319
would create a flow table

00:42:14,800 --> 00:42:18,319
entry and then it will be offered

00:42:18,480 --> 00:42:21,599
okay uh jamal had a question i guess

00:42:21,280 --> 00:42:24,240
he's

00:42:21,599 --> 00:42:26,960
asking um why do we need to offload is

00:42:24,240 --> 00:42:30,000
this primarily for nat

00:42:26,960 --> 00:42:32,000
it's primarily for um it's uh

00:42:30,000 --> 00:42:34,640
it's it's the mechanisms that users use

00:42:32,000 --> 00:42:36,640
for um for security policies

00:42:34,640 --> 00:42:39,760
for example in openstack this is the

00:42:36,640 --> 00:42:43,119
mechanism that's used for every every um

00:42:39,760 --> 00:42:46,400
every um well every um

00:42:43,119 --> 00:42:48,160
acl that is stateful so um

00:42:46,400 --> 00:42:49,920
so so this is so this is one primary

00:42:48,160 --> 00:42:50,880
reason for security groups and the other

00:42:49,920 --> 00:42:53,280
one is of course

00:42:50,880 --> 00:42:53,280
maps

00:42:54,880 --> 00:42:58,079
uh what matches can be used to direct

00:42:57,200 --> 00:43:01,040
packet to

00:42:58,079 --> 00:43:01,680
the connection tracking table basically

00:43:01,040 --> 00:43:04,480
everything

00:43:01,680 --> 00:43:06,000
it's it's it's all the matches i mean we

00:43:04,480 --> 00:43:08,160
integrated with flowers so

00:43:06,000 --> 00:43:09,680
so connection tracking is an action so

00:43:08,160 --> 00:43:11,520
once you have

00:43:09,680 --> 00:43:13,359
whatever matches you want and you decide

00:43:11,520 --> 00:43:14,640
that according to those matches you need

00:43:13,359 --> 00:43:15,359
to go through connection tracking that

00:43:14,640 --> 00:43:17,839
just goes with

00:43:15,359 --> 00:43:17,839
connection

00:43:19,040 --> 00:43:22,880
so uh this is along the lines of my

00:43:21,520 --> 00:43:24,560
earlier comment but

00:43:22,880 --> 00:43:27,440
is it possible to fill the hardware

00:43:24,560 --> 00:43:29,359
table with partial connections

00:43:27,440 --> 00:43:30,960
and exhaust hardware resources in other

00:43:29,359 --> 00:43:32,560
words um

00:43:30,960 --> 00:43:34,880
can the sustain a denial of service

00:43:32,560 --> 00:43:34,880
attack

00:43:35,040 --> 00:43:40,000
yeah so so um so assuming

00:43:38,319 --> 00:43:41,760
i mean the way that the way that it

00:43:40,000 --> 00:43:45,200
works is that um

00:43:41,760 --> 00:43:47,599
um the

00:43:45,200 --> 00:43:49,359
that is that i mean the the offload

00:43:47,599 --> 00:43:50,000
itself obviously is done by the driver

00:43:49,359 --> 00:43:53,040
right so

00:43:50,000 --> 00:43:55,760
so so the platform just creates a

00:43:53,040 --> 00:43:56,560
net filter and then a flow table entry

00:43:55,760 --> 00:43:58,079
and then this

00:43:56,560 --> 00:44:00,480
there is a callback to the driver to

00:43:58,079 --> 00:44:00,880
offload this now if the driver decides

00:44:00,480 --> 00:44:03,920
to

00:44:00,880 --> 00:44:05,839
not offload this connection okay

00:44:03,920 --> 00:44:08,000
because of scale issues or some other

00:44:05,839 --> 00:44:08,640
issues then it would just not offload it

00:44:08,000 --> 00:44:10,720
but

00:44:08,640 --> 00:44:12,079
the way that it works is that every time

00:44:10,720 --> 00:44:15,200
that the packet goes

00:44:12,079 --> 00:44:16,160
through but so basically every time that

00:44:15,200 --> 00:44:18,160
the packet will go through this

00:44:16,160 --> 00:44:19,359
connection there will be re-attempts to

00:44:18,160 --> 00:44:21,359
upload this

00:44:19,359 --> 00:44:23,359
to the hardware so the driver would

00:44:21,359 --> 00:44:28,160
always receive notifications to

00:44:23,359 --> 00:44:31,280
to to um to uh offload this connection

00:44:28,160 --> 00:44:33,440
and and and obviously once

00:44:31,280 --> 00:44:34,720
if it is successful and the connection

00:44:33,440 --> 00:44:36,319
is in hardware then

00:44:34,720 --> 00:44:38,400
then the packets would not go through

00:44:36,319 --> 00:44:39,040
software anymore and would not expect

00:44:38,400 --> 00:44:42,000
this

00:44:39,040 --> 00:44:42,960
so the the um the general idea behind

00:44:42,000 --> 00:44:44,319
this is saying that

00:44:42,960 --> 00:44:46,640
we would expect packets to be in

00:44:44,319 --> 00:44:48,800
hardware if they're not then something

00:44:46,640 --> 00:44:50,400
is wrong and we would basically this is

00:44:48,800 --> 00:44:52,400
the way for us to be trying

00:44:50,400 --> 00:44:53,599
to resend the connections back to

00:44:52,400 --> 00:44:57,280
hardware

00:44:53,599 --> 00:45:00,880
now regarding um um

00:44:57,280 --> 00:45:03,359
uh denial of service um so

00:45:00,880 --> 00:45:04,960
so it really defines i mean this first

00:45:03,359 --> 00:45:06,400
of all we offload only when connections

00:45:04,960 --> 00:45:08,880
are established so

00:45:06,400 --> 00:45:11,520
so all the denial service stacks that

00:45:08,880 --> 00:45:14,640
come before connections is established

00:45:11,520 --> 00:45:18,319
are not mitigated here anyways and

00:45:14,640 --> 00:45:21,920
uh and um and uh

00:45:18,319 --> 00:45:23,839
and obviously now there's um um

00:45:21,920 --> 00:45:25,359
very limited uh actually there's very

00:45:23,839 --> 00:45:29,200
limited mechanisms for

00:45:25,359 --> 00:45:31,920
uh for controlling the the load that uh

00:45:29,200 --> 00:45:33,440
they like the queues and the offload and

00:45:31,920 --> 00:45:36,480
load that goes into the offload

00:45:33,440 --> 00:45:42,000
mechanism so maybe that could be um

00:45:36,480 --> 00:45:42,000
that could be um research further

00:45:42,319 --> 00:45:46,480
so it's up to the host uh stack to

00:45:45,200 --> 00:45:48,720
decide

00:45:46,480 --> 00:45:50,400
which connections to offload and which

00:45:48,720 --> 00:45:55,119
to run in the

00:45:50,400 --> 00:45:56,960
host is that true basically yes

00:45:55,119 --> 00:46:00,400
okay so if there's a policy that would

00:45:56,960 --> 00:46:02,079
have to be implemented in the host yes

00:46:00,400 --> 00:46:03,680
yeah if a vendor if a vendor would like

00:46:02,079 --> 00:46:06,800
to implement some type of policy he has

00:46:03,680 --> 00:46:06,800
he has the ability to do it

00:46:06,880 --> 00:46:09,920
so that's an interesting point

00:46:10,240 --> 00:46:15,920
go ahead yeah so currently there is no

00:46:14,079 --> 00:46:17,520
definition what is going so everything

00:46:15,920 --> 00:46:20,000
is going to the harder

00:46:17,520 --> 00:46:20,960
what is established is going directly to

00:46:20,000 --> 00:46:23,680
the other

00:46:20,960 --> 00:46:25,680
but as as mentioned we want to add in

00:46:23,680 --> 00:46:27,440
the future you know more

00:46:25,680 --> 00:46:29,520
way to distinguish what is going to the

00:46:27,440 --> 00:46:30,079
software what's going to the hardware

00:46:29,520 --> 00:46:32,960
may

00:46:30,079 --> 00:46:33,520
if it's the first packet or maybe later

00:46:32,960 --> 00:46:36,480
uh

00:46:33,520 --> 00:46:38,079
for example by definition we know that

00:46:36,480 --> 00:46:41,839
the dns packet

00:46:38,079 --> 00:46:45,119
are not worth it to offload

00:46:41,839 --> 00:46:49,119
was i'm not sure did we cover also the

00:46:45,119 --> 00:46:50,960
ftp the the one that said need the

00:46:49,119 --> 00:46:54,079
helper function

00:46:50,960 --> 00:46:54,400
also not to offload this was not um this

00:46:54,079 --> 00:46:56,480
one's

00:46:54,400 --> 00:46:57,599
not thoroughly tested yet but but what i

00:46:56,480 --> 00:47:00,079
was saying more is that

00:46:57,599 --> 00:47:01,119
we we assume that even if a driver not

00:47:00,079 --> 00:47:02,800
that necessarily

00:47:01,119 --> 00:47:04,560
what we do in monologues will load

00:47:02,800 --> 00:47:05,839
everything but suppose there's a vendor

00:47:04,560 --> 00:47:07,440
what i was referring to that question

00:47:05,839 --> 00:47:10,480
suppose there's a vendor that would like

00:47:07,440 --> 00:47:11,680
to control because the scale that goes

00:47:10,480 --> 00:47:13,200
into hardware meaning that

00:47:11,680 --> 00:47:14,800
he doesn't want to offload anything

00:47:13,200 --> 00:47:17,040
because of his reasons

00:47:14,800 --> 00:47:18,400
then then the platform makes sure that

00:47:17,040 --> 00:47:20,319
as long as packets come

00:47:18,400 --> 00:47:22,160
into this connection the drivers will be

00:47:20,319 --> 00:47:25,119
notified it's not a one shot

00:47:22,160 --> 00:47:26,800
um it's not a one-shot um uh opportunity

00:47:25,119 --> 00:47:29,119
to offload this connection

00:47:26,800 --> 00:47:30,319
so so even if a driver so this is in a

00:47:29,119 --> 00:47:32,640
way that that

00:47:30,319 --> 00:47:34,000
that the driver is able to uh control

00:47:32,640 --> 00:47:36,240
its own scalability

00:47:34,000 --> 00:47:37,599
and it will not be and the platform will

00:47:36,240 --> 00:47:39,359
notify you more packets going through

00:47:37,599 --> 00:47:44,160
that connection so that's what that

00:47:39,359 --> 00:47:47,200
means so that that's a little bit um

00:47:44,160 --> 00:47:49,359
i don't want to say worrisome but

00:47:47,200 --> 00:47:50,800
it seems like the host stack has the

00:47:49,359 --> 00:47:52,720
best visibility

00:47:50,800 --> 00:47:53,839
of what connections it would want to

00:47:52,720 --> 00:47:57,839
offload

00:47:53,839 --> 00:48:00,240
and so it looks like right now

00:47:57,839 --> 00:48:02,400
these melanox device for instance is

00:48:00,240 --> 00:48:04,000
limited to two million connections

00:48:02,400 --> 00:48:06,880
but i'm thinking what if we have a host

00:48:04,000 --> 00:48:10,400
stack that has 10 million connections

00:48:06,880 --> 00:48:12,319
and it wants to optimize the offload so

00:48:10,400 --> 00:48:13,920
of those 10 million what if only 2

00:48:12,319 --> 00:48:16,079
million are active

00:48:13,920 --> 00:48:17,520
and the other ones are idle so it makes

00:48:16,079 --> 00:48:19,839
no sense to

00:48:17,520 --> 00:48:22,319
just persistently offload a connection

00:48:19,839 --> 00:48:25,040
that's that's completely inactive

00:48:22,319 --> 00:48:26,480
so it seems like the host would be

00:48:25,040 --> 00:48:28,960
wanting to manage that that

00:48:26,480 --> 00:48:29,760
doesn't seem like that's a driver or

00:48:28,960 --> 00:48:33,040
vendor thing

00:48:29,760 --> 00:48:35,680
so um it would be nice if

00:48:33,040 --> 00:48:36,079
we presented to the host the the apis

00:48:35,680 --> 00:48:39,119
and

00:48:36,079 --> 00:48:39,680
all the controls saying um here's a

00:48:39,119 --> 00:48:42,559
number

00:48:39,680 --> 00:48:43,760
maximum number of connections we have so

00:48:42,559 --> 00:48:45,440
take your

00:48:43,760 --> 00:48:46,800
workload and figure out which

00:48:45,440 --> 00:48:48,480
connections you want to offload and

00:48:46,800 --> 00:48:50,559
which you don't

00:48:48,480 --> 00:48:51,839
and really leave it up to this post

00:48:50,559 --> 00:48:53,599
stack and then

00:48:51,839 --> 00:48:54,880
once we get into that sort of policy

00:48:53,599 --> 00:48:57,119
obviously it's going to get

00:48:54,880 --> 00:48:58,640
pretty quickly into we want to have ebpf

00:48:57,119 --> 00:49:00,319
to

00:48:58,640 --> 00:49:02,880
be able to gather the statistics and

00:49:00,319 --> 00:49:05,520
basically an arbitrary policies

00:49:02,880 --> 00:49:06,240
um so the host can customize for the

00:49:05,520 --> 00:49:08,480
actual or

00:49:06,240 --> 00:49:10,319
for the particular workload so i know

00:49:08,480 --> 00:49:13,119
that's probably a leap forward

00:49:10,319 --> 00:49:14,640
but you know again this i think

00:49:13,119 --> 00:49:16,640
management resource management is going

00:49:14,640 --> 00:49:18,240
to be critical in this sort of thing

00:49:16,640 --> 00:49:30,160
i think you're right i think it's a good

00:49:18,240 --> 00:49:31,839
i think it's a good follow

00:49:30,160 --> 00:49:33,599
the next question what is the learning

00:49:31,839 --> 00:49:35,119
rate how many new flows can be

00:49:33,599 --> 00:49:38,559
configured to the hardware

00:49:35,119 --> 00:49:40,319
per second so this is again this is

00:49:38,559 --> 00:49:41,040
vendor-specific and talk for for our

00:49:40,319 --> 00:49:46,160
hardware

00:49:41,040 --> 00:49:46,160
um only we're at um um

00:49:47,119 --> 00:49:50,240
i haven't even i'm having a blackout

00:49:48,720 --> 00:49:54,079
number what do you remember

00:49:50,240 --> 00:49:56,160
how many um yeah so currently

00:49:54,079 --> 00:49:58,000
and you know we are always i think there

00:49:56,160 --> 00:50:01,280
is a huge effort that we did

00:49:58,000 --> 00:50:02,880
to improve tc um and

00:50:01,280 --> 00:50:04,720
i think now we are reaching roughly

00:50:02,880 --> 00:50:10,559
about uh

00:50:04,720 --> 00:50:10,559
few hundreds kilo new flows per second

00:50:10,839 --> 00:50:19,200
so and and we're working to improve it

00:50:14,960 --> 00:50:22,160
yeah so yeah it's about 100k 100k

00:50:19,200 --> 00:50:22,160
new flows per second

00:50:22,240 --> 00:50:25,520
ronnie that's a software software answer

00:50:24,640 --> 00:50:28,400
what's the

00:50:25,520 --> 00:50:30,480
hardware answer no this is they have

00:50:28,400 --> 00:50:34,400
your answer

00:50:30,480 --> 00:50:38,000
okay yeah yes remember

00:50:34,400 --> 00:50:40,960
this is not true tc right this is

00:50:38,000 --> 00:50:41,440
from the hudder itself from the kernel

00:50:40,960 --> 00:50:44,079
itself

00:50:41,440 --> 00:50:46,079
right because we are already inside the

00:50:44,079 --> 00:50:49,040
kernel we not need to get

00:50:46,079 --> 00:50:49,040
the tc lock

00:50:52,160 --> 00:50:55,359
kind of a follow-up question how are

00:50:53,599 --> 00:50:58,000
connections removed

00:50:55,359 --> 00:50:58,480
from the connection tracking so if this

00:50:58,000 --> 00:51:00,800
is

00:50:58,480 --> 00:51:01,920
if this is uh tcp connections and it's

00:51:00,800 --> 00:51:04,720
like they have an

00:51:01,920 --> 00:51:05,760
an ordinary shutdown then the teardown

00:51:04,720 --> 00:51:07,359
flags that the fin

00:51:05,760 --> 00:51:08,800
and the reset flaps are sent to software

00:51:07,359 --> 00:51:10,800
and incent and well

00:51:08,800 --> 00:51:12,160
let's say they're removed from software

00:51:10,800 --> 00:51:14,319
okay now there's two paths

00:51:12,160 --> 00:51:15,839
that software can remove connections

00:51:14,319 --> 00:51:18,000
either they are aged

00:51:15,839 --> 00:51:19,359
and and we have and the aging and by the

00:51:18,000 --> 00:51:20,880
way the aging is also something that

00:51:19,359 --> 00:51:22,319
we'd like to control currently it's

00:51:20,880 --> 00:51:24,160
hard-coded hardcoded

00:51:22,319 --> 00:51:25,440
the hardware aging is set currently for

00:51:24,160 --> 00:51:28,640
30 seconds

00:51:25,440 --> 00:51:31,040
and uh or it's uh there's a

00:51:28,640 --> 00:51:31,760
there's an orderly teardown and and

00:51:31,040 --> 00:51:34,720
through

00:51:31,760 --> 00:51:36,559
like tcp teardown uh sequence these are

00:51:34,720 --> 00:51:38,559
connections are deleted

00:51:36,559 --> 00:51:41,200
so so it is software that is deleting

00:51:38,559 --> 00:51:41,200
the connections

00:51:44,400 --> 00:51:48,880
and uh one thing that's probably worth

00:51:46,640 --> 00:51:52,000
noting here is that the sea of load

00:51:48,880 --> 00:51:56,319
is a synchronous operation while

00:51:52,000 --> 00:51:56,319
ct of load is asynchronous

00:51:58,160 --> 00:52:05,359
you know also when you say onyx is

00:52:01,359 --> 00:52:08,000
because it's coming from a pocket right

00:52:05,359 --> 00:52:08,000
nobody did this

00:52:10,079 --> 00:52:14,559
sorry could you repeat that statement

00:52:12,240 --> 00:52:14,559
please

00:52:15,119 --> 00:52:19,040
what's synchronous and what's

00:52:16,839 --> 00:52:21,440
asynchronous

00:52:19,040 --> 00:52:23,119
i mean so synthesizing it's what you had

00:52:21,440 --> 00:52:26,640
a tc action that's adding

00:52:23,119 --> 00:52:28,640
a rule asynchronous

00:52:26,640 --> 00:52:30,240
oh i'm not sure so i it's the

00:52:28,640 --> 00:52:33,920
asymptotics is what

00:52:30,240 --> 00:52:36,160
when you have a pocket like a the synap

00:52:33,920 --> 00:52:39,599
that is generating and inside the kernel

00:52:36,160 --> 00:52:39,599
an event that's going to the driver

00:52:42,160 --> 00:52:46,559
so actually actually the offload is also

00:52:44,559 --> 00:52:48,640
a synchronous once uh

00:52:46,559 --> 00:52:50,400
once once we understand that that that

00:52:48,640 --> 00:52:54,559
this should be offload this is happening

00:52:50,400 --> 00:52:54,559
on uh on another screen

00:52:58,000 --> 00:53:02,240
okay uh brianna do you have a question

00:53:12,839 --> 00:53:19,040
okay

00:53:15,520 --> 00:53:20,960
so the the work that vlad has been doing

00:53:19,040 --> 00:53:22,720
is he was watching from user space i

00:53:20,960 --> 00:53:24,480
think he's he's getting more than 100

00:53:22,720 --> 00:53:27,599
000 per second but it's batch

00:53:24,480 --> 00:53:30,559
process right so he batches a

00:53:27,599 --> 00:53:32,960
bunch of flaws through tc to the

00:53:30,559 --> 00:53:32,960
hardware

00:53:34,160 --> 00:53:38,960
yes so here it's more than that right

00:53:38,079 --> 00:53:40,880
because

00:53:38,960 --> 00:53:42,000
we don't need to get the from tc you're

00:53:40,880 --> 00:53:45,760
not getting an event

00:53:42,000 --> 00:53:45,760
for a net link event from user space

00:53:48,000 --> 00:53:51,599
yeah you're doing only one at a time but

00:53:49,839 --> 00:53:53,599
i'm saying that the capacity of uh

00:53:51,599 --> 00:53:55,440
offloading to hardware

00:53:53,599 --> 00:53:57,359
according to his numbers and he he did

00:53:55,440 --> 00:53:57,760
some uh he showed some numbers again on

00:53:57,359 --> 00:54:01,599
this

00:53:57,760 --> 00:54:02,880
tc workshop a few days back

00:54:01,599 --> 00:54:05,280
it's it's a few hundred thousand per

00:54:02,880 --> 00:54:08,319
second on your hardware

00:54:05,280 --> 00:54:08,640
yeah but yeah but what will you think

00:54:08,319 --> 00:54:10,720
that

00:54:08,640 --> 00:54:14,079
now we have two entry points one one is

00:54:10,720 --> 00:54:16,960
tc offload which is what vlad presented

00:54:14,079 --> 00:54:17,440
and this is like the nft offload which

00:54:16,960 --> 00:54:19,200
is

00:54:17,440 --> 00:54:20,960
which is which goes through just in

00:54:19,200 --> 00:54:24,319
kernel so

00:54:20,960 --> 00:54:24,319
so the update rate there

00:54:27,040 --> 00:54:33,280
and it's also multi-thread because this

00:54:30,079 --> 00:54:35,599
to getting an established event is

00:54:33,280 --> 00:54:36,319
from pockets so if you have rss of

00:54:35,599 --> 00:54:38,799
course

00:54:36,319 --> 00:54:39,359
it's coming from multiple threads are

00:54:38,799 --> 00:54:41,200
you saying

00:54:39,359 --> 00:54:43,440
you're doing more capacity through net

00:54:41,200 --> 00:54:45,520
filter this way

00:54:43,440 --> 00:54:47,520
yeah i i dare the software performance

00:54:45,520 --> 00:54:49,200
since i don't have the numbers but it's

00:54:47,520 --> 00:54:51,680
in the

00:54:49,200 --> 00:54:53,599
up hundreds of thousands for sure it's

00:54:51,680 --> 00:54:57,280
like the hardware is the bottom half no

00:54:53,599 --> 00:54:57,280
no for sure

00:54:57,520 --> 00:55:01,200
okay i find that surprising but okay

00:55:02,400 --> 00:55:08,400
is the flow table a subset of connection

00:55:06,000 --> 00:55:11,040
tracking table that has only candidates

00:55:08,400 --> 00:55:12,880
established connections and parentheses

00:55:11,040 --> 00:55:15,760
and is a flow table common to both net

00:55:12,880 --> 00:55:15,760
filter and tc

00:55:19,359 --> 00:55:23,200
again the flow the flow table is is is

00:55:22,400 --> 00:55:25,200
and

00:55:23,200 --> 00:55:26,640
the flow table is is just an

00:55:25,200 --> 00:55:29,359
infrastructure um

00:55:26,640 --> 00:55:30,319
we chose to use it in action tc to store

00:55:29,359 --> 00:55:34,480
only the

00:55:30,319 --> 00:55:36,240
uh established events um

00:55:34,480 --> 00:55:39,040
what was the second part of the question

00:55:36,240 --> 00:55:39,040
it was not that

00:55:40,640 --> 00:55:43,839
marisa do you want to follow up

00:55:46,160 --> 00:55:50,559
hi as the question was uh i think i

00:55:49,280 --> 00:55:52,319
probably missed the part where you were

00:55:50,559 --> 00:55:55,440
explaining the specifics of

00:55:52,319 --> 00:55:58,960
offloading this so uh so

00:55:55,440 --> 00:56:00,160
the uh net filter manages and keeps the

00:55:58,960 --> 00:56:03,599
track of

00:56:00,160 --> 00:56:07,359
uh all the connections right uh

00:56:03,599 --> 00:56:08,400
the aging and uh the ct table is

00:56:07,359 --> 00:56:10,880
essentially a table of

00:56:08,400 --> 00:56:12,799
all kinds of flows uh all states

00:56:10,880 --> 00:56:16,000
establish new and such

00:56:12,799 --> 00:56:19,040
but then uh the offload candidates

00:56:16,000 --> 00:56:21,200
need to be communicated to the tc for

00:56:19,040 --> 00:56:23,119
which you select only the

00:56:21,200 --> 00:56:24,880
connections that are in established

00:56:23,119 --> 00:56:28,559
state so is the

00:56:24,880 --> 00:56:31,280
middle layer between net filter and dc

00:56:28,559 --> 00:56:33,200
uh the flow of load infrastructure and

00:56:31,280 --> 00:56:34,240
tc or the flow offload table which has

00:56:33,200 --> 00:56:37,760
only the connect

00:56:34,240 --> 00:56:40,319
uh the offload candidates exactly so we

00:56:37,760 --> 00:56:42,720
yeah so we we create we generalize the

00:56:40,319 --> 00:56:44,000
flow table to something that we can with

00:56:42,720 --> 00:56:46,880
an api that we can create

00:56:44,000 --> 00:56:48,640
from pc and and and we populate it with

00:56:46,880 --> 00:56:50,400
the established connections that's right

00:56:48,640 --> 00:56:53,359
and and there are and there and drivers

00:56:50,400 --> 00:56:57,200
can register to receive notifications

00:56:53,359 --> 00:57:00,400
yes and the action

00:56:57,200 --> 00:57:03,119
uh action is performed only on those

00:57:00,400 --> 00:57:04,640
uh connections in the flow of flow table

00:57:03,119 --> 00:57:06,000
right

00:57:04,640 --> 00:57:08,640
right so the flow auction table is

00:57:06,000 --> 00:57:09,680
actually just just uses the generic flow

00:57:08,640 --> 00:57:12,160
offload uh

00:57:09,680 --> 00:57:14,000
like the the flow offload structure when

00:57:12,160 --> 00:57:14,720
it has like the flow flow matches and

00:57:14,000 --> 00:57:17,760
actions

00:57:14,720 --> 00:57:19,680
as we normally have in tsp so

00:57:17,760 --> 00:57:21,599
so then when so so the input that the

00:57:19,680 --> 00:57:23,119
driver gets is that an entry was added

00:57:21,599 --> 00:57:25,520
to this flow table and here are the

00:57:23,119 --> 00:57:27,839
matches and here are the actions in

00:57:25,520 --> 00:57:30,240
in data structures it is well known and

00:57:27,839 --> 00:57:32,880
can process

00:57:30,240 --> 00:57:32,880
all right thanks

00:57:35,920 --> 00:57:38,799

YouTube URL: https://www.youtube.com/watch?v=gWklbJSk0YI


