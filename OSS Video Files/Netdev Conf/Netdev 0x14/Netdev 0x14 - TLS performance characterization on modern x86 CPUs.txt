Title: Netdev 0x14 - TLS performance characterization on modern x86 CPUs
Publication date: 2020-10-09
Playlist: Netdev 0x14
Description: 
	Speakers: Pawel Szymanski, Manasi Deval

More info: https://netdevconf.info/0x14/session.html?talk-TLS-performance-characterization-on-modern-x86-CPUs

Date: Friday, August 14, 2020

To offload TLS to the NIC or just get yourself a more modern
X86 CPU which ash AESNI instructions?
In this talk, Pawel Szymanski and Manasi Deval are leaning towards
letting the CPU do it.
They run experiments that compare user mode TLS, Kernel TLS write and
kernel TLS Sendfile to contrast various bottlenecks in each one with
regards to encryption and authentication, cost of system calls and the
memory bandwidth. They will present their results. The talk will provide
some insight on which of the three approaches is best suited for
different type of application scenarios
Captions: 
	00:00:01,599 --> 00:00:07,200
my name is pawel schmanski and uh

00:00:04,799 --> 00:00:08,080
today i would like to present the

00:00:07,200 --> 00:00:10,800
results of

00:00:08,080 --> 00:00:12,559
my performance characterization

00:00:10,800 --> 00:00:16,880
experiments that

00:00:12,559 --> 00:00:20,560
i did with my colleague manasi deval

00:00:16,880 --> 00:00:22,160
so let's look on the agenda of the

00:00:20,560 --> 00:00:24,880
presentation

00:00:22,160 --> 00:00:26,000
uh first we'll start with some

00:00:24,880 --> 00:00:29,039
background about

00:00:26,000 --> 00:00:33,120
tls next i will talk about

00:00:29,039 --> 00:00:36,120
test setup and

00:00:33,120 --> 00:00:37,920
also give you results of the performance

00:00:36,120 --> 00:00:40,559
characterization

00:00:37,920 --> 00:00:41,920
and we'll have some short summary at the

00:00:40,559 --> 00:00:45,440
end

00:00:41,920 --> 00:00:48,800
so starting with some

00:00:45,440 --> 00:00:52,399
basic knowledge about tls so

00:00:48,800 --> 00:00:56,079
this is a most commonly

00:00:52,399 --> 00:00:59,359
used network protocol that

00:00:56,079 --> 00:01:02,719
provides privacy and data integrity

00:00:59,359 --> 00:01:06,159
it runs on on top of

00:01:02,719 --> 00:01:09,520
layer 3 protocols

00:01:06,159 --> 00:01:14,000
like tcp or udp

00:01:09,520 --> 00:01:16,960
and consists of two sub-protocols

00:01:14,000 --> 00:01:18,159
the first one is the handshake protocol

00:01:16,960 --> 00:01:21,600
with

00:01:18,159 --> 00:01:24,240
which deals with negotiating the the

00:01:21,600 --> 00:01:27,759
security parameters

00:01:24,240 --> 00:01:31,200
of the tls connection

00:01:27,759 --> 00:01:33,200
like crypt algorithms encryption keys

00:01:31,200 --> 00:01:36,799
and things like that

00:01:33,200 --> 00:01:40,479
the other sub-protocol is

00:01:36,799 --> 00:01:40,960
record protocol and it is responsible

00:01:40,479 --> 00:01:44,479
for

00:01:40,960 --> 00:01:45,759
fragmenting the application data into

00:01:44,479 --> 00:01:49,360
records

00:01:45,759 --> 00:01:53,040
protecting them with the crypto

00:01:49,360 --> 00:01:56,320
algorithm and then transmitting

00:01:53,040 --> 00:01:59,439
the encrypted data over uh

00:01:56,320 --> 00:02:02,880
transport protocol and uh

00:01:59,439 --> 00:02:06,320
uh tls supports uh multiple

00:02:02,880 --> 00:02:08,720
cryptographic algorithm but

00:02:06,320 --> 00:02:09,520
in this presentation and in general in

00:02:08,720 --> 00:02:13,920
my

00:02:09,520 --> 00:02:17,840
uh in my experiments uh uh

00:02:13,920 --> 00:02:21,920
i focused on aes gcm

00:02:17,840 --> 00:02:25,360
encryption uh because

00:02:21,920 --> 00:02:28,400
this is uh the algorithm that

00:02:25,360 --> 00:02:31,760
could be uh improved by using

00:02:28,400 --> 00:02:35,120
uh special aesni instructions

00:02:31,760 --> 00:02:39,360
available on uh intel

00:02:35,120 --> 00:02:39,360
x86 cpus

00:02:39,760 --> 00:02:46,239
uh so here you can

00:02:42,879 --> 00:02:49,360
see uh two uh

00:02:46,239 --> 00:02:52,640
options or two possibilities to

00:02:49,360 --> 00:02:56,239
implement tls the first one

00:02:52,640 --> 00:03:00,159
i call user space tls

00:02:56,239 --> 00:03:03,440
and in this

00:03:00,159 --> 00:03:07,040
option all the tls functionalities

00:03:03,440 --> 00:03:10,159
implemented in a dls library

00:03:07,040 --> 00:03:11,599
in user space hence the name user space

00:03:10,159 --> 00:03:14,640
tls

00:03:11,599 --> 00:03:18,319
and the second

00:03:14,640 --> 00:03:21,680
option is ktls or kernel tls

00:03:18,319 --> 00:03:25,519
where the handshake protocol

00:03:21,680 --> 00:03:28,000
is still implemented in tls library

00:03:25,519 --> 00:03:30,000
but the record protocol is implemented

00:03:28,000 --> 00:03:33,200
inside a

00:03:30,000 --> 00:03:38,239
kernel and also the

00:03:33,200 --> 00:03:38,239
tls record protocol implementation

00:03:38,560 --> 00:03:45,040
uses a crypto algorithm

00:03:41,920 --> 00:03:49,920
module to to perform actual data

00:03:45,040 --> 00:03:49,920
encryption and decryption

00:03:52,640 --> 00:04:00,720
when when we uh log into

00:03:56,319 --> 00:04:04,879
a typical http

00:04:00,720 --> 00:04:09,200
server implementation

00:04:04,879 --> 00:04:12,840
the data flow when handling

00:04:09,200 --> 00:04:16,799
http get

00:04:12,840 --> 00:04:22,479
requests looks like in this

00:04:16,799 --> 00:04:22,479
slide so basically after receiving the

00:04:25,919 --> 00:04:34,960
http get request the server

00:04:30,560 --> 00:04:39,360
sends a file to read cisco

00:04:34,960 --> 00:04:42,479
to request kernel to read the file

00:04:39,360 --> 00:04:45,520
from storage device

00:04:42,479 --> 00:04:46,320
so the file content is first copied to

00:04:45,520 --> 00:04:49,040
the

00:04:46,320 --> 00:04:50,000
kernel to the page cache inside kernel

00:04:49,040 --> 00:04:53,280
and next it

00:04:50,000 --> 00:04:57,840
it is copied into buffers in

00:04:53,280 --> 00:05:00,400
user space then the tls library

00:04:57,840 --> 00:05:02,880
performs the cryptographic operation and

00:05:00,400 --> 00:05:06,240
the encrypted

00:05:02,880 --> 00:05:09,440
data is sent from user space

00:05:06,240 --> 00:05:13,919
buffer to kernel using

00:05:09,440 --> 00:05:16,960
socket write cisco and finally

00:05:13,919 --> 00:05:20,080
it gets sent

00:05:16,960 --> 00:05:23,120
to network

00:05:20,080 --> 00:05:25,360
interface so this is

00:05:23,120 --> 00:05:27,600
this is what happens in case of user

00:05:25,360 --> 00:05:30,800
space dls

00:05:27,600 --> 00:05:35,520
and uh uh in current in

00:05:30,800 --> 00:05:39,840
in case of kernel tls uh

00:05:35,520 --> 00:05:39,840
the only difference is that

00:05:39,919 --> 00:05:44,880
the data is not encrypted in user space

00:05:43,680 --> 00:05:49,440
it is still

00:05:44,880 --> 00:05:50,840
transferred to to buffers in user space

00:05:49,440 --> 00:05:55,840
but it's

00:05:50,840 --> 00:05:59,199
not encrypted in user space but it is

00:05:55,840 --> 00:06:03,120
sent to a kernel

00:05:59,199 --> 00:06:06,479
still using socket write cisco

00:06:03,120 --> 00:06:09,600
and then it is

00:06:06,479 --> 00:06:13,600
again encrypted

00:06:09,600 --> 00:06:17,680
and sent to the network interface

00:06:13,600 --> 00:06:21,360
however with kernel tls there is a

00:06:17,680 --> 00:06:24,960
another option possible which i

00:06:21,360 --> 00:06:29,440
call a kernel tls

00:06:24,960 --> 00:06:32,560
send file flow so in this case

00:06:29,440 --> 00:06:35,600
the http server uses a

00:06:32,560 --> 00:06:38,639
send file system call

00:06:35,600 --> 00:06:42,319
and this system call a request

00:06:38,639 --> 00:06:43,440
kernel to read data from the storage

00:06:42,319 --> 00:06:49,039
device

00:06:43,440 --> 00:06:52,560
and sends a content of a file

00:06:49,039 --> 00:06:54,960
in tls or

00:06:52,560 --> 00:06:54,960
general

00:06:54,980 --> 00:07:00,960
[Music]

00:06:56,400 --> 00:07:00,960
tcp connection

00:07:01,440 --> 00:07:09,520
and as you can see the data is not

00:07:05,919 --> 00:07:13,680
transferred to user space so it is

00:07:09,520 --> 00:07:13,680
read from storage device to

00:07:13,919 --> 00:07:21,039
page cache inside kernel

00:07:17,440 --> 00:07:26,479
next the tls module inside kernel

00:07:21,039 --> 00:07:30,080
encrypts the data and then the encrypted

00:07:26,479 --> 00:07:33,360
data is sent over network

00:07:30,080 --> 00:07:36,880
interface so in fact we have

00:07:33,360 --> 00:07:41,280
three options possible

00:07:36,880 --> 00:07:45,840
to to implement tls the first one

00:07:41,280 --> 00:07:49,280
is user space the second one is

00:07:45,840 --> 00:07:52,479
ktls with right syscall and

00:07:49,280 --> 00:07:56,720
the third one is ktls with

00:07:52,479 --> 00:08:00,960
send file cisco and

00:07:56,720 --> 00:08:04,240
in our uh characterization

00:08:00,960 --> 00:08:07,520
performance characterization experiments

00:08:04,240 --> 00:08:11,039
we were focused on comparing

00:08:07,520 --> 00:08:13,520
these three scenarios

00:08:11,039 --> 00:08:15,039
these three implementation options with

00:08:13,520 --> 00:08:17,280
the

00:08:15,039 --> 00:08:17,280
two

00:08:18,160 --> 00:08:22,400
scenarios the first scenario was

00:08:21,039 --> 00:08:25,759
something we

00:08:22,400 --> 00:08:31,280
named a simple web server

00:08:25,759 --> 00:08:31,280
in this case http server

00:08:31,680 --> 00:08:34,959
sends files

00:08:35,760 --> 00:08:40,640
of size between one kilobyte and 10

00:08:38,839 --> 00:08:44,159
megabytes

00:08:40,640 --> 00:08:46,320
and the number of tls connection is

00:08:44,159 --> 00:08:50,959
quite moderate it's

00:08:46,320 --> 00:08:55,040
one we picked 100 connections

00:08:50,959 --> 00:08:58,240
each connection sends http get requests

00:08:55,040 --> 00:09:02,000
back to back the second

00:08:58,240 --> 00:09:03,120
scenario that we measured was a

00:09:02,000 --> 00:09:06,160
[Music]

00:09:03,120 --> 00:09:09,440
simulation of media streaming

00:09:06,160 --> 00:09:12,560
similar to mpeg dash protocol

00:09:09,440 --> 00:09:15,839
although we didn't use actual

00:09:12,560 --> 00:09:16,959
empag dash protocol so the difference

00:09:15,839 --> 00:09:23,120
here is that

00:09:16,959 --> 00:09:27,120
the file size was fixed to one megabyte

00:09:23,120 --> 00:09:31,120
there was significantly more

00:09:27,120 --> 00:09:34,160
tls connections we used 10 000

00:09:31,120 --> 00:09:34,160
connections and

00:09:34,480 --> 00:09:40,500
for each connection the http requests

00:09:38,320 --> 00:09:41,839
requests were sent with some

00:09:40,500 --> 00:09:47,360
[Music]

00:09:41,839 --> 00:09:52,080
time gap or time window yeah there was

00:09:47,360 --> 00:09:55,839
one to five seconds space

00:09:52,080 --> 00:10:04,010
between each http get

00:09:55,839 --> 00:10:05,760
request sent over a single connection

00:10:04,010 --> 00:10:09,360
[Music]

00:10:05,760 --> 00:10:14,000
in terms of uh hardware setup

00:10:09,360 --> 00:10:17,120
we use two machines one with

00:10:14,000 --> 00:10:19,920
http server or one

00:10:17,120 --> 00:10:20,800
playing the role of http server the

00:10:19,920 --> 00:10:25,120
other

00:10:20,800 --> 00:10:27,440
playing the role of a http uh client

00:10:25,120 --> 00:10:28,480
and both of them were equipped equipped

00:10:27,440 --> 00:10:32,160
with

00:10:28,480 --> 00:10:35,279
intel xeon gold

00:10:32,160 --> 00:10:38,399
cpu skylake generation

00:10:35,279 --> 00:10:42,079
with 32 cores

00:10:38,399 --> 00:10:45,040
and with 384 gigabyte of

00:10:42,079 --> 00:10:47,519
ddr memory and the machines were

00:10:45,040 --> 00:10:51,120
connected with 100 gigabit

00:10:47,519 --> 00:10:55,760
ethernet connection uh

00:10:51,120 --> 00:10:58,880
using uh intel 100

00:10:55,760 --> 00:11:02,480
800 series

00:10:58,880 --> 00:11:04,880
network controllers the bios

00:11:02,480 --> 00:11:09,040
configuration was

00:11:04,880 --> 00:11:15,350
modified to basically disabled

00:11:09,040 --> 00:11:17,279
to disable all the features that may

00:11:15,350 --> 00:11:21,360
[Music]

00:11:17,279 --> 00:11:24,079
cause problem with the repeatability of

00:11:21,360 --> 00:11:24,959
results so things like hyper threading c

00:11:24,079 --> 00:11:29,839
states

00:11:24,959 --> 00:11:29,839
p states and turbo are disabled

00:11:31,760 --> 00:11:36,640
and in terms of software configuration

00:11:35,760 --> 00:11:41,200
we were using

00:11:36,640 --> 00:11:44,720
um ubuntu with the

00:11:41,200 --> 00:11:44,720
linux kernel 1.

00:11:45,079 --> 00:11:50,800
5.1.0

00:11:47,760 --> 00:11:54,720
and with obviously ktls

00:11:50,800 --> 00:11:56,000
enabled and also a sni crypto driver so

00:11:54,720 --> 00:11:58,160
this is the driver that

00:11:56,000 --> 00:11:58,160
is

00:12:00,160 --> 00:12:08,079
that supports aes gcm

00:12:05,040 --> 00:12:11,440
algorithm using

00:12:08,079 --> 00:12:15,279
a esi

00:12:11,440 --> 00:12:19,360
instructions similarly the openssl

00:12:15,279 --> 00:12:23,600
library so that the user space library

00:12:19,360 --> 00:12:27,680
was also compiled with the aesni

00:12:23,600 --> 00:12:32,240
support enabled on the server side we

00:12:27,680 --> 00:12:36,959
had nginx as an http server

00:12:32,240 --> 00:12:40,320
application with a special ktls

00:12:36,959 --> 00:12:43,200
send file patch so it was a page that

00:12:40,320 --> 00:12:43,200
allows us to

00:12:43,760 --> 00:12:50,639
use uh ktls with send file

00:12:47,760 --> 00:12:53,040
uh at least at that time the official

00:12:50,639 --> 00:12:56,240
version was not

00:12:53,040 --> 00:12:59,880
supporting such a combination

00:12:56,240 --> 00:13:02,880
and on the client side we we were using

00:12:59,880 --> 00:13:02,880
wrk

00:13:03,120 --> 00:13:09,360
traffic generator or http traffic

00:13:06,560 --> 00:13:09,360
generator

00:13:09,680 --> 00:13:16,399
we set the tls configuration

00:13:13,360 --> 00:13:21,839
to tls1.2 with max

00:13:16,399 --> 00:13:21,839
record size 16 kilobytes and

00:13:22,079 --> 00:13:31,360
the crypto algorithm was aes 128

00:13:27,839 --> 00:13:34,560
with gcm

00:13:31,360 --> 00:13:36,000
and we also enabled persistent

00:13:34,560 --> 00:13:40,800
connections

00:13:36,000 --> 00:13:43,680
in http to avoid

00:13:40,800 --> 00:13:43,680
the overhead

00:13:44,240 --> 00:13:52,720
required to perform

00:13:47,600 --> 00:13:56,959
establishment and both tcp and tls

00:13:52,720 --> 00:13:56,959
connection establishment and handshake

00:13:57,120 --> 00:14:01,360
so basically we were measuring only the

00:14:00,160 --> 00:14:04,480
performance of the

00:14:01,360 --> 00:14:07,040
record protocol not the handshake

00:14:04,480 --> 00:14:07,040
protocol

00:14:07,360 --> 00:14:11,519
and in this

00:14:12,639 --> 00:14:17,839
chart you can see a comparison of

00:14:18,480 --> 00:14:27,839
throughput for the simple web server

00:14:22,880 --> 00:14:32,000
scenario so the dark blue

00:14:27,839 --> 00:14:35,600
bar is always 100 percent it

00:14:32,000 --> 00:14:37,839
and it's the performance of user space

00:14:35,600 --> 00:14:37,839
and

00:14:38,000 --> 00:14:44,959
the all the other are

00:14:41,040 --> 00:14:50,320
the ktls right and ktls send file

00:14:44,959 --> 00:14:50,320
so you can see that

00:14:51,279 --> 00:14:58,480
for smaller file sizes like

00:14:54,720 --> 00:15:02,720
one kilobyte or four kilobytes

00:14:58,480 --> 00:15:03,440
uh the kdls and especially ktls send

00:15:02,720 --> 00:15:06,320
file

00:15:03,440 --> 00:15:06,639
performance it is much lower yes it's up

00:15:06,320 --> 00:15:10,959
to

00:15:06,639 --> 00:15:14,079
40 percent lower comparing to

00:15:10,959 --> 00:15:17,279
user space tls

00:15:14,079 --> 00:15:21,600
but with 64 kilobytes

00:15:17,279 --> 00:15:25,440
and above for

00:15:21,600 --> 00:15:28,560
the ktls send file

00:15:25,440 --> 00:15:31,600
performance is higher than

00:15:28,560 --> 00:15:34,000
user space so this higher performance

00:15:31,600 --> 00:15:38,079
was something that

00:15:34,000 --> 00:15:38,839
we expected but the lower performance

00:15:38,079 --> 00:15:42,160
for

00:15:38,839 --> 00:15:45,199
uh smaller

00:15:42,160 --> 00:15:45,680
smaller file sizes and especially lower

00:15:45,199 --> 00:15:48,720
by

00:15:45,680 --> 00:15:52,720
40 percent was

00:15:48,720 --> 00:15:56,160
a surprise definitely a surprise

00:15:52,720 --> 00:15:59,519
for us um so we did some

00:15:56,160 --> 00:16:03,199
uh investigation uh and

00:15:59,519 --> 00:16:06,240
uh uh came to

00:16:03,199 --> 00:16:11,360
two conclusions or two two reasons

00:16:06,240 --> 00:16:15,120
why the ktls has

00:16:11,360 --> 00:16:15,120
lower performance than

00:16:15,360 --> 00:16:21,680
user space for smaller files

00:16:18,480 --> 00:16:27,279
so the first reason is how the

00:16:21,680 --> 00:16:31,279
http response is sent by the http server

00:16:27,279 --> 00:16:34,480
so when a http response

00:16:31,279 --> 00:16:35,279
must be sent it consists of two parts

00:16:34,480 --> 00:16:39,519
the

00:16:35,279 --> 00:16:42,639
response header and the response payload

00:16:39,519 --> 00:16:45,440
and for in case of a

00:16:42,639 --> 00:16:45,440
send file

00:16:47,680 --> 00:16:54,240
flow the http server must

00:16:50,800 --> 00:16:57,519
first prepare the response

00:16:54,240 --> 00:17:01,199
header in user space buffer

00:16:57,519 --> 00:17:04,959
and use write cisco

00:17:01,199 --> 00:17:08,880
to transfer this buffer

00:17:04,959 --> 00:17:12,480
content to the network stack

00:17:08,880 --> 00:17:16,079
and next uh it is using uh

00:17:12,480 --> 00:17:16,720
send file cisco to send http response

00:17:16,079 --> 00:17:20,799
payload

00:17:16,720 --> 00:17:25,520
uh from file located in

00:17:20,799 --> 00:17:25,520
file system so in

00:17:25,600 --> 00:17:30,160
as you can see you know it's uh two

00:17:31,120 --> 00:17:38,080
first of all there are two syscalls

00:17:34,320 --> 00:17:41,280
not one and uh the other reason is that

00:17:38,080 --> 00:17:44,640
okay this uh uh

00:17:41,280 --> 00:17:47,840
there is still some overhead of

00:17:44,640 --> 00:17:52,480
transferring data from user space

00:17:47,840 --> 00:17:52,480
if the files are i are

00:17:53,440 --> 00:17:59,520
small then the relative amount of

00:17:56,559 --> 00:18:00,080
data which is sent from user space

00:17:59,520 --> 00:18:02,480
buffer

00:18:00,080 --> 00:18:02,480
is uh

00:18:03,120 --> 00:18:11,039
higher and

00:18:07,200 --> 00:18:15,039
the second reason for this

00:18:11,039 --> 00:18:15,840
lower efficiency less send file lower

00:18:15,039 --> 00:18:19,600
efficiency

00:18:15,840 --> 00:18:19,600
for smaller files is a

00:18:19,840 --> 00:18:27,280
the way how asni

00:18:23,200 --> 00:18:30,480
driver and tls modules

00:18:27,280 --> 00:18:34,400
uh interact with each other

00:18:30,480 --> 00:18:36,080
so basically when yes and so the esni

00:18:34,400 --> 00:18:39,679
driver

00:18:36,080 --> 00:18:42,880
implements an algorithm

00:18:39,679 --> 00:18:46,000
called karatsuba algorithm and it

00:18:42,880 --> 00:18:46,000
pre-computes some

00:18:47,600 --> 00:18:53,200
values some you know heavy computation

00:18:50,799 --> 00:18:53,200
values

00:18:54,160 --> 00:19:01,919
which are which then can be reused for

00:18:57,520 --> 00:19:05,360
the entire uh tls

00:19:01,919 --> 00:19:08,840
connection lifetime

00:19:05,360 --> 00:19:12,960
uh however uh when

00:19:08,840 --> 00:19:12,960
tls module uh

00:19:13,120 --> 00:19:19,600
calls cryptodriver uh

00:19:16,480 --> 00:19:22,880
it's there there is no mechanism to

00:19:19,600 --> 00:19:26,640
uh let's say

00:19:22,880 --> 00:19:29,200
save this and provide

00:19:26,640 --> 00:19:29,200
again this

00:19:30,160 --> 00:19:39,360
pre-computed values uh to the crypto

00:19:34,320 --> 00:19:39,360
driver so basically with each uh

00:19:39,440 --> 00:19:44,080
encryption request sent from tls to the

00:19:42,400 --> 00:19:47,840
crypto driver

00:19:44,080 --> 00:19:50,880
the driver uh pre-computes this

00:19:47,840 --> 00:19:52,400
values again and again so they are only

00:19:50,880 --> 00:19:56,559
reused for

00:19:52,400 --> 00:20:00,799
a single single tls

00:19:56,559 --> 00:20:03,600
record while in

00:20:00,799 --> 00:20:05,039
user space implementation these

00:20:03,600 --> 00:20:09,120
precomputed values

00:20:05,039 --> 00:20:13,280
are reused for entire tls

00:20:09,120 --> 00:20:13,280
connection lifetime so that's

00:20:14,159 --> 00:20:18,880
that's the the problem and again

00:20:19,840 --> 00:20:27,760
it's uh more visible if the

00:20:24,480 --> 00:20:27,760
tls records are

00:20:28,480 --> 00:20:35,840
lower size which happens for

00:20:32,559 --> 00:20:40,159
small file sizes sent over

00:20:35,840 --> 00:20:40,159
http connection

00:20:41,919 --> 00:20:48,080
the second scenario that

00:20:45,039 --> 00:20:51,440
we looked into is media streaming

00:20:48,080 --> 00:20:54,559
scenario and in this case uh

00:20:51,440 --> 00:20:56,880
instead of measuring uh

00:20:54,559 --> 00:20:58,240
throughput with the maximum cpu

00:20:56,880 --> 00:21:02,640
utilization we did

00:20:58,240 --> 00:21:05,760
something different basically we

00:21:02,640 --> 00:21:10,720
uh kept that throughput on

00:21:05,760 --> 00:21:15,679
uh on a uh

00:21:10,720 --> 00:21:19,039
on the same level with

00:21:15,679 --> 00:21:21,760
gigabit per second or 30 gigabit per

00:21:19,039 --> 00:21:25,200
second so so we we had two options

00:21:21,760 --> 00:21:30,000
the first one was uh with

00:21:25,200 --> 00:21:33,200
files sent from tmpfs from memory

00:21:30,000 --> 00:21:37,039
and the other option was

00:21:33,200 --> 00:21:40,640
what the files transferred from

00:21:37,039 --> 00:21:45,200
nvme device

00:21:40,640 --> 00:21:47,280
and we measured in this case we we

00:21:45,200 --> 00:21:50,799
measured the cpu utilization

00:21:47,280 --> 00:21:53,600
and memory bandwidth

00:21:50,799 --> 00:21:53,600
utilization

00:21:54,320 --> 00:22:01,280
and here we can see that the results of

00:21:58,080 --> 00:22:03,919
cpu utilization so there is no big

00:22:01,280 --> 00:22:09,039
surprise

00:22:03,919 --> 00:22:12,720
the user space efficiency in terms of

00:22:09,039 --> 00:22:16,000
cpu utilization was lower

00:22:12,720 --> 00:22:19,520
between 16 and 20

00:22:16,000 --> 00:22:22,640
percent lower

00:22:19,520 --> 00:22:27,360
and this was something we

00:22:22,640 --> 00:22:30,799
expected based on the results with a

00:22:27,360 --> 00:22:34,080
simple web server uh scenario

00:22:30,799 --> 00:22:37,440
okay because for uh bigger

00:22:34,080 --> 00:22:39,120
file sizes and in this case that the

00:22:37,440 --> 00:22:43,440
file sizes were

00:22:39,120 --> 00:22:47,520
around one megabyte uh

00:22:43,440 --> 00:22:47,840
basically the user space tls performance

00:22:47,520 --> 00:22:52,840
was

00:22:47,840 --> 00:22:55,600
uh lower comparing to

00:22:52,840 --> 00:22:59,200
ktls both write and

00:22:55,600 --> 00:23:02,400
send file however

00:22:59,200 --> 00:23:05,200
the memory bandwidth

00:23:02,400 --> 00:23:05,200
measurements

00:23:05,520 --> 00:23:12,240
which you can see now we're

00:23:08,960 --> 00:23:15,360
um a surprise

00:23:12,240 --> 00:23:18,559
again for us uh

00:23:15,360 --> 00:23:18,880
the basically we expected since the you

00:23:18,559 --> 00:23:22,400
know

00:23:18,880 --> 00:23:25,039
the the but the ktls

00:23:22,400 --> 00:23:26,159
send file eliminates some memory copy

00:23:25,039 --> 00:23:29,280
operations

00:23:26,159 --> 00:23:29,919
it eliminates transfer of data into user

00:23:29,280 --> 00:23:32,159
space we

00:23:29,919 --> 00:23:33,679
we expect that memory bandwidth

00:23:32,159 --> 00:23:38,720
utilization to be

00:23:33,679 --> 00:23:42,480
lower for kt less than file

00:23:38,720 --> 00:23:45,919
but it was

00:23:42,480 --> 00:23:49,360
the other way around is the kdls

00:23:45,919 --> 00:23:54,640
send file and also ktls write

00:23:49,360 --> 00:23:54,640
generated higher memory bandwidth

00:23:54,720 --> 00:24:00,960
we suspect that you know

00:23:57,919 --> 00:24:04,919
this is mainly related

00:24:00,960 --> 00:24:06,159
to the fact that in case of ktls the

00:24:04,919 --> 00:24:08,000
implementation

00:24:06,159 --> 00:24:09,919
is

00:24:08,000 --> 00:24:13,679
[Music]

00:24:09,919 --> 00:24:16,880
let's see scattered among

00:24:13,679 --> 00:24:18,400
three different pieces of code as there

00:24:16,880 --> 00:24:22,799
is a

00:24:18,400 --> 00:24:26,799
tls library in user space with

00:24:22,799 --> 00:24:30,840
which stills

00:24:26,799 --> 00:24:36,480
still transfers the data and

00:24:30,840 --> 00:24:36,480
from application then there is a

00:24:36,559 --> 00:24:42,799
ktls module and

00:24:39,679 --> 00:24:47,520
crypto module in kernel

00:24:42,799 --> 00:24:52,159
and since this implementation is

00:24:47,520 --> 00:24:55,840
put in three different places

00:24:52,159 --> 00:24:59,970
the cash efficiency is lower

00:24:55,840 --> 00:25:03,039
and so it basically

00:24:59,970 --> 00:25:07,200
[Music]

00:25:03,039 --> 00:25:11,279
generates uh more

00:25:07,200 --> 00:25:15,840
cash pollution and generates more

00:25:11,279 --> 00:25:15,840
traffic memory

00:25:17,150 --> 00:25:24,640
[Music]

00:25:20,400 --> 00:25:28,720
uh so to summarize summarize my

00:25:24,640 --> 00:25:32,480
presentation in

00:25:28,720 --> 00:25:36,799
our experiments we focused on

00:25:32,480 --> 00:25:41,679
three implementation options for tls

00:25:36,799 --> 00:25:45,200
the user space tls ktls

00:25:41,679 --> 00:25:47,840
write and ktls send file

00:25:45,200 --> 00:25:49,919
and in the simple web server scenario

00:25:47,840 --> 00:25:52,960
the ktls send file

00:25:49,919 --> 00:25:56,320
provides its highest performance

00:25:52,960 --> 00:26:00,799
for files uh of

00:25:56,320 --> 00:26:05,279
64 kilobyte size and above and for lower

00:26:00,799 --> 00:26:08,880
uh sizes uh the user space tls

00:26:05,279 --> 00:26:12,799
provides better performance uh

00:26:08,880 --> 00:26:16,640
and in the multimedia streaming scenario

00:26:12,799 --> 00:26:19,760
the kdls send file and ktls

00:26:16,640 --> 00:26:24,240
right now

00:26:19,760 --> 00:26:29,679
provide lower cpu utilization but

00:26:24,240 --> 00:26:29,679
higher memory bandwidth utilization

00:26:30,480 --> 00:26:38,320
that's all what i wanted to present

00:26:33,919 --> 00:26:41,840
thank you okay

00:26:38,320 --> 00:26:44,240
uh thank you that was uh somewhat

00:26:41,840 --> 00:26:47,279
enlightening performance results

00:26:44,240 --> 00:26:49,679
uh i don't see any questions

00:26:47,279 --> 00:26:52,320
at this point um do you have any further

00:26:49,679 --> 00:26:55,840
comments on that

00:26:52,320 --> 00:26:59,120
okay so there's a comment on the chat

00:26:55,840 --> 00:27:03,679
uh gcm aes and goes through k

00:26:59,120 --> 00:27:06,559
malloc and scatter walk copy chunk calls

00:27:03,679 --> 00:27:08,080
so yes the the part about the complexity

00:27:06,559 --> 00:27:08,559
of the chrome implementation certainly

00:27:08,080 --> 00:27:12,400
was

00:27:08,559 --> 00:27:14,640
uh interesting and um

00:27:12,400 --> 00:27:16,080
i guess there's an opportunity there to

00:27:14,640 --> 00:27:19,360
clean that up and

00:27:16,080 --> 00:27:23,880
improve that okay so

00:27:19,360 --> 00:27:26,880
with that let's proceed to our third

00:27:23,880 --> 00:27:26,880

YouTube URL: https://www.youtube.com/watch?v=vu8LZ5ZSiKc


