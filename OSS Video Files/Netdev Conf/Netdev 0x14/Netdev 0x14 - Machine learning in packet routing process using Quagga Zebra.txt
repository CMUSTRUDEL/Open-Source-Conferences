Title: Netdev 0x14 - Machine learning in packet routing process using Quagga Zebra
Publication date: 2020-10-09
Playlist: Netdev 0x14
Description: 
	Speakers: Maciej Paczkowski, Aleksandra Jereczek, Patrycja Kochmanska

More info: https://netdevconf.info/0x14/session.html?talk-machine-learning-in-packet-routing-process-using-Quagga-Zebra-routing-sw-suite

Date: Friday, August 14, 2020

In this talk from Maciej Paczkowski, Aleksandra Jereczek, and
Patrycja Kochmanska describe integrating into FRR
to understand how to best optimize the path selection in an environemnt
with multiple simultenous link faults and incestant link flapps.
Could routing decisions better helped with ML hooks in
the kernel/datapath? Could we make use of offloading some of
the algos to AI hardware?
Captions: 
	00:00:02,159 --> 00:00:06,839
hello my name is patricia kommanska

00:00:04,799 --> 00:00:09,280
i work at intel and together with

00:00:06,839 --> 00:00:11,120
alexandria and mati pachkovsky

00:00:09,280 --> 00:00:13,200
we prepare the talk regarding machine

00:00:11,120 --> 00:00:17,920
learning in pocket rooting process using

00:00:13,200 --> 00:00:17,920
quagga or zebra software suit

00:00:18,000 --> 00:00:22,000
we will start by introducing a bunch of

00:00:19,920 --> 00:00:22,880
information about linked state routing

00:00:22,000 --> 00:00:24,640
protocols

00:00:22,880 --> 00:00:26,160
then we will tell about possible

00:00:24,640 --> 00:00:28,000
improvement areas

00:00:26,160 --> 00:00:30,400
we will describe current linked state

00:00:28,000 --> 00:00:32,320
routing protocols implementation and how

00:00:30,400 --> 00:00:35,600
it is possible to use machine learning

00:00:32,320 --> 00:00:37,120
in current ospf or isis networks

00:00:35,600 --> 00:00:39,440
we will show you the results of our

00:00:37,120 --> 00:00:41,360
experiments in simulated environments

00:00:39,440 --> 00:00:45,840
and describe potential practical

00:00:41,360 --> 00:00:45,840
applications and their limitations

00:00:46,320 --> 00:00:50,079
modern routing protocols are taking

00:00:48,239 --> 00:00:52,079
various approaches on how to select

00:00:50,079 --> 00:00:52,960
paths for packets in the most effective

00:00:52,079 --> 00:00:54,640
way

00:00:52,960 --> 00:00:56,160
there are two main classes of routing

00:00:54,640 --> 00:00:58,800
protocols the first one

00:00:56,160 --> 00:00:59,840
is distance vector routing protocols in

00:00:58,800 --> 00:01:01,600
which routers have

00:00:59,840 --> 00:01:04,000
no information about the whole network

00:01:01,600 --> 00:01:06,000
topology and the decisions about the

00:01:04,000 --> 00:01:07,040
best routes are based only on the data

00:01:06,000 --> 00:01:09,600
about costs

00:01:07,040 --> 00:01:10,479
gained from router's nearest neighbors

00:01:09,600 --> 00:01:12,640
and there are also

00:01:10,479 --> 00:01:13,760
link state routing protocols which

00:01:12,640 --> 00:01:15,840
assume that each

00:01:13,760 --> 00:01:18,240
network node creates and stores its own

00:01:15,840 --> 00:01:20,560
scheme of the whole network topology

00:01:18,240 --> 00:01:22,479
and then independently calculates the

00:01:20,560 --> 00:01:23,520
list goes back from itself to every

00:01:22,479 --> 00:01:25,600
other node

00:01:23,520 --> 00:01:26,799
the topology scheme may be considered as

00:01:25,600 --> 00:01:28,640
a graph

00:01:26,799 --> 00:01:30,320
the paths are calculated basing on

00:01:28,640 --> 00:01:32,240
dijkstra's algorithm

00:01:30,320 --> 00:01:34,159
it finds the shortest path between two

00:01:32,240 --> 00:01:35,680
graph nodes by adding up the cost of

00:01:34,159 --> 00:01:37,920
links by itself

00:01:35,680 --> 00:01:42,560
the most popular examples of link state

00:01:37,920 --> 00:01:42,560
routing protocols are ospf and isis

00:01:43,600 --> 00:01:47,759
over recent years computer networks have

00:01:46,079 --> 00:01:49,600
experienced a huge and dynamic

00:01:47,759 --> 00:01:52,399
change modern networks are getting

00:01:49,600 --> 00:01:54,479
bigger more virtualized and more dynamic

00:01:52,399 --> 00:01:56,479
the virtualized environments are being

00:01:54,479 --> 00:01:57,439
widely used in data centers and lab

00:01:56,479 --> 00:02:00,320
providers

00:01:57,439 --> 00:02:02,079
the virtualization aspect allows us to

00:02:00,320 --> 00:02:03,119
allows networks to have more and more

00:02:02,079 --> 00:02:05,040
nodes and therefore

00:02:03,119 --> 00:02:06,799
have a huge amount of virtual machines

00:02:05,040 --> 00:02:08,720
that are being dynamically added or

00:02:06,799 --> 00:02:10,959
removed from the network

00:02:08,720 --> 00:02:12,560
initially network recovery time having

00:02:10,959 --> 00:02:14,800
reached few tens of seconds was

00:02:12,560 --> 00:02:17,440
considered sufficiently fast

00:02:14,800 --> 00:02:20,000
therefore ospf's original design was not

00:02:17,440 --> 00:02:22,560
comprehensively optimized in this field

00:02:20,000 --> 00:02:24,239
however over almost 20 years these

00:02:22,560 --> 00:02:26,319
requirements have changed

00:02:24,239 --> 00:02:28,080
nowadays networks are using more and

00:02:26,319 --> 00:02:30,000
more powerful and computationally

00:02:28,080 --> 00:02:32,800
efficient devices and currently

00:02:30,000 --> 00:02:33,200
such long inoperable network state would

00:02:32,800 --> 00:02:36,000
cause

00:02:33,200 --> 00:02:37,599
unacceptable traffic loss level having

00:02:36,000 --> 00:02:38,959
in mind the dynamic character of

00:02:37,599 --> 00:02:41,599
computer networks

00:02:38,959 --> 00:02:42,560
they are still expected to be stable and

00:02:41,599 --> 00:02:45,200
00:02:42,560 --> 00:02:46,560
accurate the problem occurs when

00:02:45,200 --> 00:02:49,920
networks experience

00:02:46,560 --> 00:02:51,599
a huge amount of link failures in this

00:02:49,920 --> 00:02:54,239
case the adaptation time of such

00:02:51,599 --> 00:02:56,239
networks may take even a few seconds

00:02:54,239 --> 00:02:57,360
the core of our idea is to reduce

00:02:56,239 --> 00:02:59,519
recovery time and

00:02:57,360 --> 00:03:04,000
therefore faster adjust to the new

00:02:59,519 --> 00:03:06,959
network topology

00:03:04,000 --> 00:03:09,680
the main goal of ospf is to determine

00:03:06,959 --> 00:03:11,760
best paths between all network nodes

00:03:09,680 --> 00:03:13,840
link state advertisement packets are

00:03:11,760 --> 00:03:14,560
being sent each time a change occurs in

00:03:13,840 --> 00:03:16,640
the network

00:03:14,560 --> 00:03:18,879
and based on these packets link state

00:03:16,640 --> 00:03:21,200
database is being filled

00:03:18,879 --> 00:03:23,040
the extra algorithm that is used in

00:03:21,200 --> 00:03:25,840
current ospf implementation

00:03:23,040 --> 00:03:26,159
operates on data stored in lsdb in order

00:03:25,840 --> 00:03:29,200
to

00:03:26,159 --> 00:03:30,959
calculate shortest path tree the spt

00:03:29,200 --> 00:03:33,680
represents the shortest paths to each

00:03:30,959 --> 00:03:35,680
destination in giving routing area

00:03:33,680 --> 00:03:38,480
in the picture we can see how lsa

00:03:35,680 --> 00:03:40,400
packets are used to build up the spt

00:03:38,480 --> 00:03:46,159
next packets are used to build the

00:03:40,400 --> 00:03:49,440
overall view of the network topology

00:03:46,159 --> 00:03:50,640
lsdb is later used by ostf in spf

00:03:49,440 --> 00:03:52,879
algorithm

00:03:50,640 --> 00:03:53,760
in order to create routing information

00:03:52,879 --> 00:03:55,760
base

00:03:53,760 --> 00:03:56,879
changes in the topological database

00:03:55,760 --> 00:03:59,760
trigger partial

00:03:56,879 --> 00:04:01,760
or full routing table recalculations

00:03:59,760 --> 00:04:03,760
with spf algorithm

00:04:01,760 --> 00:04:06,000
full recalculation of course takes

00:04:03,760 --> 00:04:08,319
longer time and is more expensive

00:04:06,000 --> 00:04:09,599
since each transit link that fails is

00:04:08,319 --> 00:04:12,159
connected to at least

00:04:09,599 --> 00:04:13,200
two routers it results in at least two

00:04:12,159 --> 00:04:16,799
routers

00:04:13,200 --> 00:04:19,040
forced to run full spf recalculation

00:04:16,799 --> 00:04:20,639
this recalculation has a negative impact

00:04:19,040 --> 00:04:22,560
on the overall network of

00:04:20,639 --> 00:04:24,240
efficiency because it may result in

00:04:22,560 --> 00:04:26,320
packet losses

00:04:24,240 --> 00:04:28,400
the final base that is used to choose

00:04:26,320 --> 00:04:29,440
output interface to direct the packet to

00:04:28,400 --> 00:04:32,400
its destination

00:04:29,440 --> 00:04:33,759
is called forwarding information base in

00:04:32,400 --> 00:04:34,880
case of full routing table

00:04:33,759 --> 00:04:37,440
recalculations

00:04:34,880 --> 00:04:38,000
spf requires some time to generate new

00:04:37,440 --> 00:04:39,919
routing

00:04:38,000 --> 00:04:41,199
information base so the forwarding

00:04:39,919 --> 00:04:44,080
information base

00:04:41,199 --> 00:04:45,440
is not updated at the same time lsa come

00:04:44,080 --> 00:04:48,320
into the database

00:04:45,440 --> 00:04:50,880
and this create network outage this

00:04:48,320 --> 00:04:53,520
picture shows examples of routing table

00:04:50,880 --> 00:04:55,600
that is calculated by ospf

00:04:53,520 --> 00:04:57,600
and forwarding table that is finally

00:04:55,600 --> 00:05:00,479
used to forward packets

00:04:57,600 --> 00:05:01,840
it is worth mentioning that the rip is

00:05:00,479 --> 00:05:04,240
used in user space

00:05:01,840 --> 00:05:07,120
and tip in kernel space of linux

00:05:04,240 --> 00:05:07,120
operating system

00:05:09,440 --> 00:05:14,639
in order to create booting information

00:05:11,680 --> 00:05:15,759
base link state protocol undertakes few

00:05:14,639 --> 00:05:18,320
steps

00:05:15,759 --> 00:05:20,320
firstly it creates link state database

00:05:18,320 --> 00:05:22,960
based on lsa packets

00:05:20,320 --> 00:05:25,600
then it performs spf calculations in

00:05:22,960 --> 00:05:27,600
order to create shortest path three

00:05:25,600 --> 00:05:28,639
the tree is then used to determine the

00:05:27,600 --> 00:05:31,120
most efficient

00:05:28,639 --> 00:05:33,360
routes and create a routing table this

00:05:31,120 --> 00:05:35,440
routing table is then passed to the

00:05:33,360 --> 00:05:39,840
kernel space and effectively used to

00:05:35,440 --> 00:05:39,840
forward packets to specific ports

00:05:40,639 --> 00:05:46,400
the current ospf implementation is 100

00:05:43,840 --> 00:05:48,320
accurate but have an area of improvement

00:05:46,400 --> 00:05:50,400
when it comes to the recovery time after

00:05:48,320 --> 00:05:52,960
multiple link failures

00:05:50,400 --> 00:05:55,039
to optimize the problem of recovery time

00:05:52,960 --> 00:05:57,440
spf calculations are not only run in

00:05:55,039 --> 00:06:00,400
full mode but there are also partial or

00:05:57,440 --> 00:06:02,240
incremental modes of spf recalculations

00:06:00,400 --> 00:06:03,680
in which not all of the sdg is

00:06:02,240 --> 00:06:06,639
recalculated

00:06:03,680 --> 00:06:07,600
however full spf recalculations still

00:06:06,639 --> 00:06:09,680
occur

00:06:07,600 --> 00:06:10,800
and lead to an outdated forwarding

00:06:09,680 --> 00:06:13,600
information base

00:06:10,800 --> 00:06:16,080
and network outage here we can see on

00:06:13,600 --> 00:06:18,720
which stages of ospf operations the

00:06:16,080 --> 00:06:20,880
network may be in inoperable state

00:06:18,720 --> 00:06:23,280
and as we can see this is a relatively

00:06:20,880 --> 00:06:26,319
long period of time

00:06:23,280 --> 00:06:26,639
thank you patricia and now let's focus

00:06:26,319 --> 00:06:28,880
on

00:06:26,639 --> 00:06:29,759
how can we use machine learning in

00:06:28,880 --> 00:06:33,360
current

00:06:29,759 --> 00:06:35,600
link stand database protocols like ocpf

00:06:33,360 --> 00:06:37,440
or isis

00:06:35,600 --> 00:06:38,720
we want to use machine learning to

00:06:37,440 --> 00:06:40,800
enhance the

00:06:38,720 --> 00:06:43,759
routing information based recalculation

00:06:40,800 --> 00:06:45,840
step in the picture on the right

00:06:43,759 --> 00:06:48,319
here you can notice that we added

00:06:45,840 --> 00:06:52,000
additional parallel ai

00:06:48,319 --> 00:06:53,120
algorithm so our solution is based on

00:06:52,000 --> 00:06:56,000
the running ai

00:06:53,120 --> 00:06:58,400
algorithm it can be neural network that

00:06:56,000 --> 00:07:02,560
would compute the roots in parallel with

00:06:58,400 --> 00:07:04,080
primary dextra algorithm and algorithm

00:07:02,560 --> 00:07:06,880
can be implemented in a

00:07:04,080 --> 00:07:07,440
as i said in form of a neural network it

00:07:06,880 --> 00:07:10,160
would be

00:07:07,440 --> 00:07:11,599
trained to output the next hub from the

00:07:10,160 --> 00:07:15,840
local router to

00:07:11,599 --> 00:07:19,120
reach other router in the network

00:07:15,840 --> 00:07:21,120
as patricia said before the overall goal

00:07:19,120 --> 00:07:23,520
is to reduce the time needed to

00:07:21,120 --> 00:07:26,319
construct the functional

00:07:23,520 --> 00:07:28,720
forwarding information base that is with

00:07:26,319 --> 00:07:31,599
high probability good enough to

00:07:28,720 --> 00:07:34,720
erect bucket until the full spf

00:07:31,599 --> 00:07:38,319
calculation is done

00:07:34,720 --> 00:07:42,800
the additional parallel ai algorithm

00:07:38,319 --> 00:07:46,080
i mean this one creates a temporary

00:07:42,800 --> 00:07:47,919
routing information base

00:07:46,080 --> 00:07:49,840
and then we pass it to the system as a

00:07:47,919 --> 00:07:53,360
temporary firmware

00:07:49,840 --> 00:07:56,479
uh forwarding uh information base

00:07:53,360 --> 00:07:58,560
and temporary fib with high probability

00:07:56,479 --> 00:08:00,000
allows reaching the destinations of the

00:07:58,560 --> 00:08:02,560
packets

00:08:00,000 --> 00:08:03,360
because of not fully predictable nature

00:08:02,560 --> 00:08:06,560
of ai

00:08:03,360 --> 00:08:09,199
algorithms the decision may not be 100

00:08:06,560 --> 00:08:12,080
accurate but well-trained neural network

00:08:09,199 --> 00:08:15,680
can get close to this value

00:08:12,080 --> 00:08:16,720
the ai algorithm will anticipate the spf

00:08:15,680 --> 00:08:19,199
recalculation

00:08:16,720 --> 00:08:19,840
providing probably the best next hop

00:08:19,199 --> 00:08:23,039
given

00:08:19,840 --> 00:08:24,840
that lsdb state

00:08:23,039 --> 00:08:27,360
the calculation of this next hop

00:08:24,840 --> 00:08:29,680
corresponds from the packet forwarding

00:08:27,360 --> 00:08:30,960
perspective to the minimum spanning tree

00:08:29,680 --> 00:08:36,159
calculation

00:08:30,960 --> 00:08:36,159
which is a completionary more intensive

00:08:36,560 --> 00:08:42,880
here here's another picture of our

00:08:40,080 --> 00:08:45,200
idea as you can see we want to add

00:08:42,880 --> 00:08:48,000
parallel roots recalculation

00:08:45,200 --> 00:08:49,200
only in case of full recalculation

00:08:48,000 --> 00:08:51,839
request

00:08:49,200 --> 00:08:54,240
since this is the only place where ai

00:08:51,839 --> 00:08:55,519
algorithm is faster than original

00:08:54,240 --> 00:08:58,399
approach

00:08:55,519 --> 00:08:59,600
full recalculation request is performed

00:08:58,399 --> 00:09:03,200
every time

00:08:59,600 --> 00:09:03,519
when transit link fails this results in

00:09:03,200 --> 00:09:05,760
two

00:09:03,519 --> 00:09:08,399
or more routers always forced to run

00:09:05,760 --> 00:09:10,959
expensive full spf recalculation

00:09:08,399 --> 00:09:12,080
with a very negative impact in the

00:09:10,959 --> 00:09:15,360
routing

00:09:12,080 --> 00:09:17,680
of overall network uh

00:09:15,360 --> 00:09:20,720
why do we claim that ai solution is

00:09:17,680 --> 00:09:23,040
faster than our original approach

00:09:20,720 --> 00:09:24,000
well it's simple mathematics uh let's

00:09:23,040 --> 00:09:26,640
say that n

00:09:24,000 --> 00:09:28,240
is the number of routers in the network

00:09:26,640 --> 00:09:31,279
so the extra algorithm is

00:09:28,240 --> 00:09:33,040
n square complexity while neural network

00:09:31,279 --> 00:09:36,080
is only n complexity

00:09:33,040 --> 00:09:38,640
so let's say uh for 50 nodes

00:09:36,080 --> 00:09:40,399
and neural network will be incomparably

00:09:38,640 --> 00:09:44,320
faster than old good

00:09:40,399 --> 00:09:47,279
extra of course

00:09:44,320 --> 00:09:49,680
as i mentioned before we don't want to

00:09:47,279 --> 00:09:52,080
replace dijkstra with neural network

00:09:49,680 --> 00:09:54,160
all we want to achieve is to generate

00:09:52,080 --> 00:09:56,800
temporary routing table

00:09:54,160 --> 00:09:59,279
and pass it as soon as possible to

00:09:56,800 --> 00:10:01,839
system forwarding table

00:09:59,279 --> 00:10:03,600
we realize that the forwarding table

00:10:01,839 --> 00:10:06,720
based on neural network

00:10:03,600 --> 00:10:09,360
is not 100 percent accurate but it's

00:10:06,720 --> 00:10:11,760
better than nothing at this point we

00:10:09,360 --> 00:10:14,880
have a choice to use totally outdated

00:10:11,760 --> 00:10:15,839
fib or writing table or use the new one

00:10:14,880 --> 00:10:19,440
generated by

00:10:15,839 --> 00:10:23,600
neural network and rely on it in case of

00:10:19,440 --> 00:10:27,120
dye extra calculation are not done yet

00:10:23,600 --> 00:10:28,079
ai algorithm will be trained separately

00:10:27,120 --> 00:10:30,320
for each node

00:10:28,079 --> 00:10:31,519
to output the next hub from the local

00:10:30,320 --> 00:10:34,079
router to reach

00:10:31,519 --> 00:10:36,160
each other router in the network thanks

00:10:34,079 --> 00:10:37,200
to that we'll have a forwarding table

00:10:36,160 --> 00:10:41,200
that is good enough

00:10:37,200 --> 00:10:42,720
until the full spf recalculation is done

00:10:41,200 --> 00:10:45,200
neural network is trained based on

00:10:42,720 --> 00:10:46,480
previously calculated spf routes and may

00:10:45,200 --> 00:10:49,839
be retrained

00:10:46,480 --> 00:10:53,440
adaptively while network is operating

00:10:49,839 --> 00:10:56,880
uh the data set of the ail

00:10:53,440 --> 00:10:58,800
algorithm is trained with the

00:10:56,880 --> 00:10:59,920
per router data set that can be easily

00:10:58,800 --> 00:11:04,160
obtained in uh

00:10:59,920 --> 00:11:06,160
simulations for every of network

00:11:04,160 --> 00:11:07,600
okay on this slide we have a firmware

00:11:06,160 --> 00:11:10,880
information

00:11:07,600 --> 00:11:12,399
uh base state chart with the spf

00:11:10,880 --> 00:11:16,560
dijkstra

00:11:12,399 --> 00:11:19,519
based process and ai based process

00:11:16,560 --> 00:11:20,480
please notice that the chart is not in a

00:11:19,519 --> 00:11:23,600
scale

00:11:20,480 --> 00:11:27,120
however the ai process part

00:11:23,600 --> 00:11:28,160
will be always less than spf algorithm

00:11:27,120 --> 00:11:29,920
part

00:11:28,160 --> 00:11:31,519
when you look at the fib state you can

00:11:29,920 --> 00:11:34,240
notice three colors

00:11:31,519 --> 00:11:36,480
three different colors the orange one is

00:11:34,240 --> 00:11:38,720
the network outage state

00:11:36,480 --> 00:11:40,480
our goal is to reduce this orange part

00:11:38,720 --> 00:11:43,040
as much as possible

00:11:40,480 --> 00:11:45,839
this is stage when we need to rely on

00:11:43,040 --> 00:11:49,040
outdated old forwarding table

00:11:45,839 --> 00:11:49,760
and this state is a chaos the yellow

00:11:49,040 --> 00:11:53,040
part

00:11:49,760 --> 00:11:54,399
is the state we want to run our network

00:11:53,040 --> 00:11:58,000
using forwarding table

00:11:54,399 --> 00:12:00,240
produced by ai algorithm

00:11:58,000 --> 00:12:01,839
as i said this is not the final stem

00:12:00,240 --> 00:12:05,760
state and it's not

00:12:01,839 --> 00:12:09,040
100 percent reliable

00:12:05,760 --> 00:12:12,000
uh in yellow part we want to control the

00:12:09,040 --> 00:12:14,079
chaos caused by topology changes

00:12:12,000 --> 00:12:16,160
and where the old forwarding table is

00:12:14,079 --> 00:12:20,399
totally outdated

00:12:16,160 --> 00:12:24,399
temporary fib is used until the full

00:12:20,399 --> 00:12:26,800
spf recalculation has come to its end

00:12:24,399 --> 00:12:27,760
as i mentioned before it's worth

00:12:26,800 --> 00:12:31,120
remembering

00:12:27,760 --> 00:12:35,680
that the complexity of the generation of

00:12:31,120 --> 00:12:38,800
table with our algorithms case with n

00:12:35,680 --> 00:12:40,800
when n is the number of routers as

00:12:38,800 --> 00:12:43,040
for each router we need to compute the

00:12:40,800 --> 00:12:45,200
next hop from the local router

00:12:43,040 --> 00:12:47,120
and this is done with the constant cost

00:12:45,200 --> 00:12:49,440
that is the cost of having ai

00:12:47,120 --> 00:12:52,399
algorithm to generate the output for

00:12:49,440 --> 00:12:55,600
each router to reach

00:12:52,399 --> 00:12:56,160
and due to the spf complexity this spark

00:12:55,600 --> 00:13:00,720
can much

00:12:56,160 --> 00:13:04,079
much longer than ai algorithm takes

00:13:00,720 --> 00:13:04,959
the green part is the state when all spf

00:13:04,079 --> 00:13:08,720
dijkstra

00:13:04,959 --> 00:13:12,399
calculations are already done and

00:13:08,720 --> 00:13:16,079
final fib is ready to use at this moment

00:13:12,399 --> 00:13:19,320
we stop using neural network based fib

00:13:16,079 --> 00:13:21,680
and we start using the final better

00:13:19,320 --> 00:13:24,720
deterministically generated routing and

00:13:21,680 --> 00:13:24,720
forwarding tables

00:13:26,720 --> 00:13:32,480
okay on this slide we have a time chart

00:13:30,000 --> 00:13:33,120
based on our initial calculation and

00:13:32,480 --> 00:13:36,560
testing

00:13:33,120 --> 00:13:37,120
fully simulated environments as you can

00:13:36,560 --> 00:13:40,560
notice

00:13:37,120 --> 00:13:41,279
we are able to reduce network time

00:13:40,560 --> 00:13:45,199
outage

00:13:41,279 --> 00:13:47,440
even three to four times in case of 50

00:13:45,199 --> 00:13:50,399
nodes networks

00:13:47,440 --> 00:13:51,920
uh so apparently temporary fib

00:13:50,399 --> 00:13:54,000
calculated by

00:13:51,920 --> 00:13:55,839
artificial intelligence significantly

00:13:54,000 --> 00:13:58,320
decreased the outage time

00:13:55,839 --> 00:14:01,279
and even if rooting decisions based on

00:13:58,320 --> 00:14:03,440
it are not hundred percent accurate

00:14:01,279 --> 00:14:05,680
they can decrease packet loss level when

00:14:03,440 --> 00:14:09,279
network state is not stable

00:14:05,680 --> 00:14:10,800
we didn't put uh exact time on a scale

00:14:09,279 --> 00:14:12,639
since for different simulation

00:14:10,800 --> 00:14:16,079
environments this time

00:14:12,639 --> 00:14:19,440
a are these times are different

00:14:16,079 --> 00:14:22,160
however the shape of this chart

00:14:19,440 --> 00:14:22,639
and the notes times correlation of the

00:14:22,160 --> 00:14:25,360
charts

00:14:22,639 --> 00:14:25,360
are constant

00:14:27,120 --> 00:14:33,760
okay now let's talk a little bit

00:14:30,320 --> 00:14:34,160
about potential practical applications

00:14:33,760 --> 00:14:37,760
and

00:14:34,160 --> 00:14:41,440
limitations the main targets

00:14:37,760 --> 00:14:44,560
of our solution are big industrial size

00:14:41,440 --> 00:14:48,240
data centers with many physical and

00:14:44,560 --> 00:14:52,320
virtual devices connected in the network

00:14:48,240 --> 00:14:53,839
the proposed ospf or isis recovery time

00:14:52,320 --> 00:14:56,720
optimization

00:14:53,839 --> 00:14:57,440
applies to big and dynamic networks

00:14:56,720 --> 00:15:01,279
where a

00:14:57,440 --> 00:15:05,199
full spf recalculation often occur

00:15:01,279 --> 00:15:08,720
and packet loss tolerance is quite low

00:15:05,199 --> 00:15:10,240
moreover the ai part of offred solution

00:15:08,720 --> 00:15:12,720
may be supported by

00:15:10,240 --> 00:15:13,920
using hardware ai accelerator

00:15:12,720 --> 00:15:16,800
accelerators

00:15:13,920 --> 00:15:18,880
that additionally would decrease the cpu

00:15:16,800 --> 00:15:20,880
usage of data center

00:15:18,880 --> 00:15:23,360
send servers which may have different

00:15:20,880 --> 00:15:26,160
efficiency

00:15:23,360 --> 00:15:28,720
we may imagine that solution can be

00:15:26,160 --> 00:15:30,480
implemented on a hardware working in a

00:15:28,720 --> 00:15:33,680
plug-and-play manner

00:15:30,480 --> 00:15:35,519
and this will be accelerate data centers

00:15:33,680 --> 00:15:37,839
network performance

00:15:35,519 --> 00:15:40,480
without significant inference in the

00:15:37,839 --> 00:15:43,279
network devices and

00:15:40,480 --> 00:15:46,320
this project can be also adapted to be

00:15:43,279 --> 00:15:50,720
used in a smart network

00:15:46,320 --> 00:15:53,920
interface cards called called smart nics

00:15:50,720 --> 00:15:57,360
they can act as a linux based routers

00:15:53,920 --> 00:16:00,880
while being a traditional hardware nic

00:15:57,360 --> 00:16:04,240
according to our observations

00:16:00,880 --> 00:16:06,720
even one ai based ruler node

00:16:04,240 --> 00:16:08,880
in the network can decrease the average

00:16:06,720 --> 00:16:11,839
overall network self lead

00:16:08,880 --> 00:16:12,560
time of course this is not the rule it

00:16:11,839 --> 00:16:14,880
depends

00:16:12,560 --> 00:16:16,079
where the router is placed in the

00:16:14,880 --> 00:16:18,560
topology

00:16:16,079 --> 00:16:19,519
so if the router is in some critical

00:16:18,560 --> 00:16:21,519
place

00:16:19,519 --> 00:16:22,880
with the plenty connection to other

00:16:21,519 --> 00:16:26,480
readers it will

00:16:22,880 --> 00:16:28,800
help decrease decrease average outage

00:16:26,480 --> 00:16:28,800
time

00:16:29,120 --> 00:16:35,360
now a few words about limitations

00:16:32,800 --> 00:16:37,920
unfortunately our solution will not

00:16:35,360 --> 00:16:40,240
resolve congestion problems

00:16:37,920 --> 00:16:41,440
this one this is one of the biggest

00:16:40,240 --> 00:16:46,560
problem including

00:16:41,440 --> 00:16:49,519
link state protocols unfortunately

00:16:46,560 --> 00:16:51,360
our idea will not help here we believe

00:16:49,519 --> 00:16:52,480
this would require totally different

00:16:51,360 --> 00:16:54,880
approach

00:16:52,480 --> 00:16:58,079
and we just wanted to focus right now on

00:16:54,880 --> 00:16:58,079
a self-healing time

00:16:58,560 --> 00:17:04,959
uh okay for the end i want to say few

00:17:01,600 --> 00:17:06,640
words about next steps we still have a

00:17:04,959 --> 00:17:08,880
lot of work to do here

00:17:06,640 --> 00:17:10,799
for now we have an initial

00:17:08,880 --> 00:17:13,360
implementation quagga

00:17:10,799 --> 00:17:14,880
software routing suit however the

00:17:13,360 --> 00:17:18,240
solution can be implemented in

00:17:14,880 --> 00:17:21,439
fr or any other software routing suit

00:17:18,240 --> 00:17:23,919
and next steps are tests in the real

00:17:21,439 --> 00:17:25,919
unstable and predictable environment

00:17:23,919 --> 00:17:29,200
with the frequent topology changes

00:17:25,919 --> 00:17:31,679
so there is a lot of tests for us

00:17:29,200 --> 00:17:33,360
we need to compare results from real

00:17:31,679 --> 00:17:35,520
environment

00:17:33,360 --> 00:17:38,400
then we'll assess the real advantage of

00:17:35,520 --> 00:17:38,400
our solution

00:17:40,880 --> 00:17:44,720
okay we put some more interesting

00:17:43,039 --> 00:17:47,760
information in our paper

00:17:44,720 --> 00:17:51,039
so i very encourage you to read it

00:17:47,760 --> 00:17:52,720
and i think that's all we had that was

00:17:51,039 --> 00:17:54,559
our brief idea

00:17:52,720 --> 00:17:56,960
thank you very much for spending time

00:17:54,559 --> 00:18:01,520
with us and

00:17:56,960 --> 00:18:05,120
take care

00:18:01,520 --> 00:18:08,160
okay uh thank you so we have

00:18:05,120 --> 00:18:10,720
a few questions on the chat

00:18:08,160 --> 00:18:12,400
um i'll go ahead and read them then if

00:18:10,720 --> 00:18:14,480
the

00:18:12,400 --> 00:18:16,320
person asking the question wants to

00:18:14,480 --> 00:18:18,480
wants to have follow-up they

00:18:16,320 --> 00:18:19,679
are welcome to unmute their microphone

00:18:18,480 --> 00:18:22,880
and of course the

00:18:19,679 --> 00:18:24,720
presenters can answer as needed so the

00:18:22,880 --> 00:18:27,919
first one perhaps we could use

00:18:24,720 --> 00:18:30,320
reinforcement learning and use spf

00:18:27,919 --> 00:18:32,240
dijkstra's algorithm

00:18:30,320 --> 00:18:34,880
for reward function to make this more

00:18:32,240 --> 00:18:34,880
adaptive

00:18:35,679 --> 00:18:39,520
uh do you hear me sorry

00:18:40,400 --> 00:18:47,039
can you okay

00:18:43,600 --> 00:18:47,039
okay i think i'm newt

00:18:48,320 --> 00:18:53,600
we can hear you okay great

00:18:52,160 --> 00:18:56,640
so yeah i had some problems when i

00:18:53,600 --> 00:18:59,679
headphones uh

00:18:56,640 --> 00:19:01,760
we could use a real informants well uh

00:18:59,679 --> 00:19:04,160
i would say that this is a

00:19:01,760 --> 00:19:08,880
implementation detail for this moment

00:19:04,160 --> 00:19:11,840
uh this is a brief idea uh

00:19:08,880 --> 00:19:11,840
yes we use uh

00:19:12,000 --> 00:19:15,760
we thought about this uh also there was

00:19:15,360 --> 00:19:18,799
a

00:19:15,760 --> 00:19:21,440
patricia who was more involved in uh

00:19:18,799 --> 00:19:22,320
in implementation part she's she

00:19:21,440 --> 00:19:25,280
couldn't join

00:19:22,320 --> 00:19:27,280
unfortunately because of the internet

00:19:25,280 --> 00:19:30,320
access on in her area

00:19:27,280 --> 00:19:31,120
right now uh we'll think about it of

00:19:30,320 --> 00:19:34,559
course

00:19:31,120 --> 00:19:35,440
about reinforcements but uh for now we

00:19:34,559 --> 00:19:39,440
just want to

00:19:35,440 --> 00:19:42,880
focus on the next step which is the

00:19:39,440 --> 00:19:46,799
test in the real environment so uh

00:19:42,880 --> 00:19:46,799
this is what we want to do right now

00:19:47,039 --> 00:19:50,480
yeah there was a kind of a part two that

00:19:49,280 --> 00:19:53,120
looks like we're

00:19:50,480 --> 00:19:54,320
using supervised learning here what is

00:19:53,120 --> 00:19:57,120
the neural network

00:19:54,320 --> 00:19:58,559
mod nor not model how many uh layers in

00:19:57,120 --> 00:20:01,600
it

00:19:58,559 --> 00:20:04,720
well as far as i remember is uh

00:20:01,600 --> 00:20:06,000
five layers but you know this is a kind

00:20:04,720 --> 00:20:09,679
of the that

00:20:06,000 --> 00:20:11,840
we have to experiment so this is not the

00:20:09,679 --> 00:20:13,840
this is not the final solution this is

00:20:11,840 --> 00:20:14,240
not a final implementation we still have

00:20:13,840 --> 00:20:17,280
to

00:20:14,240 --> 00:20:20,640
uh uh find they know

00:20:17,280 --> 00:20:21,440
that uh which which what what what what

00:20:20,640 --> 00:20:22,420
is the best

00:20:21,440 --> 00:20:25,039
uh way to

00:20:22,420 --> 00:20:28,080
[Music]

00:20:25,039 --> 00:20:28,960
we we don't have that uh final solution

00:20:28,080 --> 00:20:31,120
so the

00:20:28,960 --> 00:20:32,480
as i said now we have a five layers but

00:20:31,120 --> 00:20:34,320
it can be five

00:20:32,480 --> 00:20:35,760
it could be six it wouldn't be seven so

00:20:34,320 --> 00:20:38,240
it's uh

00:20:35,760 --> 00:20:40,559
now now we stick to five as far as i

00:20:38,240 --> 00:20:40,559
remember

00:20:41,440 --> 00:20:44,559
okay uh and one more so what are the

00:20:44,000 --> 00:20:46,880
events

00:20:44,559 --> 00:20:49,600
and or the events and weights on the

00:20:46,880 --> 00:20:52,720
events in the model

00:20:49,600 --> 00:20:54,480
uh events in the model it's the same

00:20:52,720 --> 00:20:55,360
question dom it's basically what is the

00:20:54,480 --> 00:20:57,039
model right like

00:20:55,360 --> 00:20:59,120
what is the model that you're using and

00:20:57,039 --> 00:21:00,880
are you biasing them in any way right so

00:20:59,120 --> 00:21:02,799
yes it's a full connected uh full

00:21:00,880 --> 00:21:03,679
connected network with the five layers

00:21:02,799 --> 00:21:05,760
but uh

00:21:03,679 --> 00:21:07,039
as i said this can be changed during the

00:21:05,760 --> 00:21:09,280
the next step so it's

00:21:07,039 --> 00:21:11,200
uh i would not stick to this one no so

00:21:09,280 --> 00:21:13,360
so i guess my question was what did you

00:21:11,200 --> 00:21:17,760
use today right like how did you

00:21:13,360 --> 00:21:21,840
train the model what was what were the

00:21:17,760 --> 00:21:25,200
design criteria uh

00:21:21,840 --> 00:21:26,240
to be honest uh is that pastorisa is not

00:21:25,200 --> 00:21:27,840
here

00:21:26,240 --> 00:21:29,360
because she was mostly involved in the

00:21:27,840 --> 00:21:31,840
implementation right now

00:21:29,360 --> 00:21:32,640
so uh i think we can take it offline and

00:21:31,840 --> 00:21:35,679
uh

00:21:32,640 --> 00:21:37,039
if you want we can just uh we can answer

00:21:35,679 --> 00:21:40,880
it by mail

00:21:37,039 --> 00:21:42,400
sounds good okay so it looks like uh

00:21:40,880 --> 00:21:45,600
christian has

00:21:42,400 --> 00:21:47,440
multiple questions so um go ahead

00:21:45,600 --> 00:21:49,760
christian

00:21:47,440 --> 00:21:49,760
hi

00:21:50,559 --> 00:21:54,880
okay i the little mic thing is moving so

00:21:53,280 --> 00:21:58,000
i hope you can hear me

00:21:54,880 --> 00:22:00,400
um yeah we can hear you yeah so this

00:21:58,000 --> 00:22:01,520
is pretty interesting to me um i'll just

00:22:00,400 --> 00:22:04,320
let you know i'm the

00:22:01,520 --> 00:22:05,360
co-chair of the uh lsr working group in

00:22:04,320 --> 00:22:08,480
itf so

00:22:05,360 --> 00:22:10,240
of isis and ospf um

00:22:08,480 --> 00:22:12,159
i also probably been working on this

00:22:10,240 --> 00:22:14,880
stuff for about 20 years

00:22:12,159 --> 00:22:15,360
and one of the things that we did you

00:22:14,880 --> 00:22:18,080
know

00:22:15,360 --> 00:22:18,480
look at what for my decade at cisco we

00:22:18,080 --> 00:22:20,080
worked

00:22:18,480 --> 00:22:21,520
particularly on a project for fast

00:22:20,080 --> 00:22:24,720
convergence

00:22:21,520 --> 00:22:25,600
so we were looking at you know how to

00:22:24,720 --> 00:22:28,000
converge

00:22:25,600 --> 00:22:29,760
the network and end to end so in other

00:22:28,000 --> 00:22:30,880
words all the routers along the path

00:22:29,760 --> 00:22:33,679
right

00:22:30,880 --> 00:22:34,720
for any failure and we were using for to

00:22:33,679 --> 00:22:37,600
give you real world

00:22:34,720 --> 00:22:39,600
uh numbers we were using a a real world

00:22:37,600 --> 00:22:41,600
network of customer bars

00:22:39,600 --> 00:22:43,760
and it was a thousand node network a

00:22:41,600 --> 00:22:47,120
thousand node global network

00:22:43,760 --> 00:22:49,120
and so we when we did all of our

00:22:47,120 --> 00:22:50,640
optimizations that we could we focused

00:22:49,120 --> 00:22:52,799
on this project for many months and

00:22:50,640 --> 00:22:54,320
optimized up and down the stack

00:22:52,799 --> 00:22:56,640
uh the fastest we could get the

00:22:54,320 --> 00:22:58,240
convergence down to is about 120

00:22:56,640 --> 00:23:00,000
milliseconds

00:22:58,240 --> 00:23:02,080
we didn't advertise that but that's what

00:23:00,000 --> 00:23:05,520
we got um

00:23:02,080 --> 00:23:08,640
and uh of that 120 milliseconds

00:23:05,520 --> 00:23:10,159
uh the full spf calculation was seven

00:23:08,640 --> 00:23:13,200
milliseconds

00:23:10,159 --> 00:23:15,760
right so i you know

00:23:13,200 --> 00:23:16,400
it's there are so many bigger problems i

00:23:15,760 --> 00:23:18,000
i'm not

00:23:16,400 --> 00:23:19,760
not saying that your work isn't isn't

00:23:18,000 --> 00:23:21,280
useful right because knowing how to do

00:23:19,760 --> 00:23:23,039
things faster is

00:23:21,280 --> 00:23:24,799
but you know we you're sort of

00:23:23,039 --> 00:23:26,880
optimizing

00:23:24,799 --> 00:23:28,000
we have bigger much bigger issues the

00:23:26,880 --> 00:23:30,960
biggest one

00:23:28,000 --> 00:23:33,120
um is propagation delay right the amount

00:23:30,960 --> 00:23:34,159
of time that it takes to propagate the

00:23:33,120 --> 00:23:37,440
failure the

00:23:34,159 --> 00:23:39,039
the the new link state uh across the

00:23:37,440 --> 00:23:41,039
thousand node network now you talked

00:23:39,039 --> 00:23:42,400
about that i think you were sort of

00:23:41,039 --> 00:23:44,320
you were getting at that when you said

00:23:42,400 --> 00:23:45,919
congestion problems um

00:23:44,320 --> 00:23:47,520
it's not even i mean it's not even that

00:23:45,919 --> 00:23:48,080
it's just you know our protocols have

00:23:47,520 --> 00:23:50,159
built-in

00:23:48,080 --> 00:23:51,600
uh dampening and whatever and we're

00:23:50,159 --> 00:23:53,279
we're working on that actively to

00:23:51,600 --> 00:23:56,400
actually really speed that up

00:23:53,279 --> 00:23:59,520
um but yeah

00:23:56,400 --> 00:24:02,159
and you know so so right so this is

00:23:59,520 --> 00:24:03,200
interesting but maybe not too useful

00:24:02,159 --> 00:24:05,840
right away

00:24:03,200 --> 00:24:07,360
what i um so that that wasn't really a

00:24:05,840 --> 00:24:08,320
question it was just kind of giving you

00:24:07,360 --> 00:24:12,559
some feedback

00:24:08,320 --> 00:24:14,480
um uh the question that i had

00:24:12,559 --> 00:24:15,600
was and where i would think that this

00:24:14,480 --> 00:24:19,200
might be

00:24:15,600 --> 00:24:22,480
interesting uh for current day use

00:24:19,200 --> 00:24:25,919
would be if you were doing something

00:24:22,480 --> 00:24:28,480
to guess

00:24:25,919 --> 00:24:30,799
guess at failures so instead of just

00:24:28,480 --> 00:24:32,480
trying to optimize the spf algorithm

00:24:30,799 --> 00:24:32,960
right which is pretty optimal even

00:24:32,480 --> 00:24:34,880
though it's

00:24:32,960 --> 00:24:36,400
i mean i don't know what how expensive

00:24:34,880 --> 00:24:38,000
each operation is in the machine

00:24:36,400 --> 00:24:40,159
learning right but it's super

00:24:38,000 --> 00:24:42,559
cheap in dijkstra so even though it's n

00:24:40,159 --> 00:24:42,960
squared it's still really fast right

00:24:42,559 --> 00:24:46,240
until

00:24:42,960 --> 00:24:48,240
n gets you know unreasonably large right

00:24:46,240 --> 00:24:49,600
like maybe millions or something i don't

00:24:48,240 --> 00:24:52,320
know but um

00:24:49,600 --> 00:24:53,600
but what i'm what i'm wondering is can

00:24:52,320 --> 00:24:54,400
can we do something with machine

00:24:53,600 --> 00:24:57,760
learning where

00:24:54,400 --> 00:24:59,919
if i see a certain failure pattern

00:24:57,760 --> 00:25:01,120
right like i see a link fail in one

00:24:59,919 --> 00:25:02,799
place and

00:25:01,120 --> 00:25:05,120
you know and because of that it's going

00:25:02,799 --> 00:25:05,840
to shift traffic naturally to another

00:25:05,120 --> 00:25:07,200
link right

00:25:05,840 --> 00:25:09,200
which might because of the way the

00:25:07,200 --> 00:25:11,120
network is currently running might cause

00:25:09,200 --> 00:25:11,520
another failure downstream right which

00:25:11,120 --> 00:25:13,120
then

00:25:11,520 --> 00:25:15,120
has a cascading effect through the

00:25:13,120 --> 00:25:16,720
network it seems to me that that's the

00:25:15,120 --> 00:25:18,720
type of pattern stuff

00:25:16,720 --> 00:25:22,080
that maybe machine learning could could

00:25:18,720 --> 00:25:24,159
uh get at right so you could almost be

00:25:22,080 --> 00:25:25,760
predicting a better route because you

00:25:24,159 --> 00:25:27,200
know that if you took the first choice

00:25:25,760 --> 00:25:28,559
spf came up with

00:25:27,200 --> 00:25:30,559
you were going to cause a cascade

00:25:28,559 --> 00:25:32,159
failure and so it just avoided it all

00:25:30,559 --> 00:25:33,600
together and picked a different one like

00:25:32,159 --> 00:25:35,440
maybe a sub-optimal route

00:25:33,600 --> 00:25:37,440
you know i mean that's crazy talk from

00:25:35,440 --> 00:25:39,039
from the chair right don't you it's that

00:25:37,440 --> 00:25:41,279
sub-optimal route sounds like routing

00:25:39,039 --> 00:25:42,159
loops but uh but yeah i mean you know

00:25:41,279 --> 00:25:43,840
that that seems like

00:25:42,159 --> 00:25:45,919
like where the real power of machine

00:25:43,840 --> 00:25:47,120
learning maybe could show up is a better

00:25:45,919 --> 00:25:50,400
path

00:25:47,120 --> 00:25:52,960
prediction yeah

00:25:50,400 --> 00:25:55,200
have you thought about that yeah but

00:25:52,960 --> 00:25:58,320
this is a very good feedback

00:25:55,200 --> 00:26:01,679
to be honest uh so you know

00:25:58,320 --> 00:26:02,640
we tried to uh find a way how can we

00:26:01,679 --> 00:26:04,559
implement

00:26:02,640 --> 00:26:07,679
uh artificial intelligence machine

00:26:04,559 --> 00:26:07,679
learning in there in

00:26:07,919 --> 00:26:13,600
reading protocols at all so uh that was

00:26:11,039 --> 00:26:17,039
our first guess that maybe we'll be able

00:26:13,600 --> 00:26:20,080
to you know decrease this uh

00:26:17,039 --> 00:26:23,120
time with uh dixtra so uh

00:26:20,080 --> 00:26:23,120
as you said that uh

00:26:23,200 --> 00:26:30,559
your idea or uh this this could be

00:26:26,240 --> 00:26:33,919
this would uh require changing our uh

00:26:30,559 --> 00:26:36,480
uh model i think that uh

00:26:33,919 --> 00:26:38,000
we we were focused only on the you know

00:26:36,480 --> 00:26:41,679
decrease the the

00:26:38,000 --> 00:26:43,440
this part with the uh with the extra

00:26:41,679 --> 00:26:45,919
algorithm so well

00:26:43,440 --> 00:26:46,559
well and you know i mean uh also

00:26:45,919 --> 00:26:48,640
dijkstra

00:26:46,559 --> 00:26:50,240
is used can use a lot of places in graph

00:26:48,640 --> 00:26:52,400
theory right so there might actually be

00:26:50,240 --> 00:26:53,679
applications for this you know maybe not

00:26:52,400 --> 00:26:55,520
in real world

00:26:53,679 --> 00:26:56,880
networks because they're not that large

00:26:55,520 --> 00:26:57,760
even at a thousand nodes they're not

00:26:56,880 --> 00:26:59,520
that large but

00:26:57,760 --> 00:27:01,520
yeah you know there might be other graph

00:26:59,520 --> 00:27:01,840
applications where the numbers get into

00:27:01,520 --> 00:27:04,000
the

00:27:01,840 --> 00:27:05,120
hundreds of thousands where it really

00:27:04,000 --> 00:27:09,919
could make a difference i

00:27:05,120 --> 00:27:12,480
i don't know yeah so as i said we

00:27:09,919 --> 00:27:13,200
we need to test first this on a real

00:27:12,480 --> 00:27:16,320
environment

00:27:13,200 --> 00:27:19,520
then we can uh say that we are

00:27:16,320 --> 00:27:21,440
achieve something here and uh

00:27:19,520 --> 00:27:23,840
but that was a very good feedback i

00:27:21,440 --> 00:27:23,840
would say

00:27:24,559 --> 00:27:31,440
okay so next question uh please share

00:27:27,840 --> 00:27:33,760
the link to your paper uh we will have

00:27:31,440 --> 00:27:37,279
those links on the net dev site

00:27:33,760 --> 00:27:40,000
i guess if you want an advanced copy

00:27:37,279 --> 00:27:42,559
mate can can post it on the chat at his

00:27:40,000 --> 00:27:42,559
discretion

00:27:43,840 --> 00:27:46,320
sorry

00:27:47,120 --> 00:27:52,559
i i i see the chat

00:27:50,320 --> 00:27:55,039
so that that yeah if you will if you

00:27:52,559 --> 00:28:01,120
want um you don't have to

00:27:55,039 --> 00:28:03,120
but uh there is one other question

00:28:01,120 --> 00:28:04,880
to give you a hint this problem looks

00:28:03,120 --> 00:28:07,520
close to

00:28:04,880 --> 00:28:09,120
autonomous autonomous self-driving car

00:28:07,520 --> 00:28:12,080
so if the car drive

00:28:09,120 --> 00:28:14,399
could drive from source to destination

00:28:12,080 --> 00:28:16,559
then a packet could be used to drive

00:28:14,399 --> 00:28:18,559
from source to destination

00:28:16,559 --> 00:28:21,840
so are we doing the same thing that

00:28:18,559 --> 00:28:21,840
self-driving cars are doing

00:28:24,080 --> 00:28:28,159
yeah feedback i don't know this is the

00:28:27,760 --> 00:28:31,679
real

00:28:28,159 --> 00:28:34,720
question uh

00:28:31,679 --> 00:28:35,279
so i wonder maybe it's more if we're

00:28:34,720 --> 00:28:38,640
asking

00:28:35,279 --> 00:28:42,720
to find commonalities and analogies

00:28:38,640 --> 00:28:45,520
in between different processes that

00:28:42,720 --> 00:28:47,279
don't appear to be uh the same thing

00:28:45,520 --> 00:28:49,520
offhand right so

00:28:47,279 --> 00:28:52,000
um you know thinking about maybe not so

00:28:49,520 --> 00:28:54,720
much self-driving cars but

00:28:52,000 --> 00:28:56,840
when we look at uh google maps for

00:28:54,720 --> 00:28:59,679
instance

00:28:56,840 --> 00:29:02,559
so probably use a similar algorithm

00:28:59,679 --> 00:29:04,000
to to go from point a to point b um in

00:29:02,559 --> 00:29:05,919
an optimal fashion so

00:29:04,000 --> 00:29:07,120
that's that's an easy algorithm to

00:29:05,919 --> 00:29:10,640
implement

00:29:07,120 --> 00:29:12,640
but i think once you start looking at

00:29:10,640 --> 00:29:14,480
uh parameterizations of the algorithms

00:29:12,640 --> 00:29:16,640
and complexities

00:29:14,480 --> 00:29:18,880
uh that's where the ai and machine

00:29:16,640 --> 00:29:22,000
learning becomes interesting right so

00:29:18,880 --> 00:29:24,399
um to get from point a to point b in the

00:29:22,000 --> 00:29:26,880
shortest distance is fixed

00:29:24,399 --> 00:29:28,720
to get from point a to point d b in the

00:29:26,880 --> 00:29:30,880
shortest time

00:29:28,720 --> 00:29:32,559
uh is very variable and that could

00:29:30,880 --> 00:29:34,159
depend heavily on a lot of

00:29:32,559 --> 00:29:34,880
characteristics time of day and what

00:29:34,159 --> 00:29:37,520
have you

00:29:34,880 --> 00:29:38,799
so it seems like the the ai and machine

00:29:37,520 --> 00:29:42,080
learning kicks in

00:29:38,799 --> 00:29:44,559
once the algorithms become

00:29:42,080 --> 00:29:45,200
less deterministic and you have more

00:29:44,559 --> 00:29:49,279
inputs

00:29:45,200 --> 00:29:51,120
and there's some sort of um randomness

00:29:49,279 --> 00:29:52,799
to those inputs that maybe make it a

00:29:51,120 --> 00:29:54,720
chaotic system

00:29:52,799 --> 00:29:56,720
so do you think uh that's that's where

00:29:54,720 --> 00:29:58,080
all this is going is is going beyond

00:29:56,720 --> 00:30:00,080
just

00:29:58,080 --> 00:30:02,080
um re-implementing the the static

00:30:00,080 --> 00:30:04,559
algorithms but actually coming out with

00:30:02,080 --> 00:30:05,840
with improved algorithms that add in

00:30:04,559 --> 00:30:09,360
some of these

00:30:05,840 --> 00:30:11,760
uh less tangible inputs well

00:30:09,360 --> 00:30:14,240
i i think so so that that this is a

00:30:11,760 --> 00:30:14,240
direction

00:30:14,320 --> 00:30:17,760
however as i said we all not solve the

00:30:16,240 --> 00:30:19,679
congestion problems with the

00:30:17,760 --> 00:30:22,080
with the solution we we just described

00:30:19,679 --> 00:30:25,840
so uh

00:30:22,080 --> 00:30:28,640
we just want to make faster network

00:30:25,840 --> 00:30:29,840
but yes this is also the the the

00:30:28,640 --> 00:30:32,399
direction

00:30:29,840 --> 00:30:34,960
when to go yeah so everybody wants

00:30:32,399 --> 00:30:38,080
faster networks

00:30:34,960 --> 00:30:40,240
uh let's see so it's a little uh

00:30:38,080 --> 00:30:41,679
sure for large-scale networks this could

00:30:40,240 --> 00:30:44,799
be key

00:30:41,679 --> 00:30:47,120
so uh interesting statement so

00:30:44,799 --> 00:30:49,679
i guess the question there is in scaling

00:30:47,120 --> 00:30:52,399
do we do we believe that

00:30:49,679 --> 00:30:53,840
as we scale to larger and larger

00:30:52,399 --> 00:30:55,520
networks

00:30:53,840 --> 00:30:58,880
at some point i think the prediction was

00:30:55,520 --> 00:31:01,919
we'd have over a trillion iot devices

00:30:58,880 --> 00:31:03,279
clearly it's only going to get bigger do

00:31:01,919 --> 00:31:06,159
we start to need

00:31:03,279 --> 00:31:07,919
to go beyond the fixed algorithms and to

00:31:06,159 --> 00:31:11,360
the sort of

00:31:07,919 --> 00:31:15,039
aim machine learning algorithms

00:31:11,360 --> 00:31:16,720
yeah i think this is uh for uh

00:31:15,039 --> 00:31:19,519
our solution is designed for a

00:31:16,720 --> 00:31:23,120
large-scale networks i mean

00:31:19,519 --> 00:31:24,000
we are aiming into the big big data

00:31:23,120 --> 00:31:27,760
centers

00:31:24,000 --> 00:31:27,760
so uh yeah

00:31:30,480 --> 00:31:33,840

YouTube URL: https://www.youtube.com/watch?v=eqmPs4A9leQ


