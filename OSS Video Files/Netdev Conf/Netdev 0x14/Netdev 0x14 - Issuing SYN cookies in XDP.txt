Title: Netdev 0x14 - Issuing SYN cookies in XDP
Publication date: 2020-10-09
Playlist: Netdev 0x14
Description: 
	Speakers: Petar Penkov, Eric Dumazet, Stanislav Fomichev

More info: https://netdevconf.info/0x14/session.html?talk-issuing-SYN-cookies-in-XDP

Date: Wednesday, August 19, 2020

The Problem: TCP SYN attack.

TCP SYN attacks flood a targetted server with SYN requests.
Each SYN request received by the server is responded to with
a SYN ACK which results in a connection state being created
and put in a half-open (SYN RCVD) TCP state awaiting an ACK to
come back. The ACK response _never comes_ and the SYN
request keep coming in resulting in more half-open state
creation in the backlog.
At some point, during this attack, there will be a lot of 
TCP half-open state such that the target server's ability
to respond to new SYN requests is lost because all the available
port resources have been exhausted...

How does one defend against SYN flood attack?

A popular defense against SYN attacks uses what is known as
SYN cookies.
So, how do SYN cookies work?
When the server sees the TCP SYN, it constructs the SYN ACK
using a sequence number chosen from a cryptographic hash
function of some flow attributes. The ACK sequence has enough encoding
within it such that it is able to construct the original SYN
request should the original sender respond.

Two possibilities on responses:

1) This is an attack - meaning the server will never receive
a response.
It is no big deal since no server resources are wasted in
anticipation of that response.

2) This is legit client request - in which case there will be
a response coming back. When the ACK is received, 
the server is able to reconstruct the SYN queue entry using the
information that was originally encoded in the SYN ACK.

Is there anything wrong with SYN cookies?
Not really. They are effective, but:
the setup requires the packets traverse the TCP/IP layers
all the way up. For a busy server, extra code path and computation
limits how fast you can issue SYN cookies back.

In this talk, Petar Penkov, discusses SynGate, an XDP-based approach
to handling SYN cookies.
By moving the response lower in the stack it enables the
system to increase the rate at which a host can issue SYN cookies
and therefore improving its resilience to SYN flood attacks. 

Petar will detail the design of this solution, the advantages
eBPF provided them and, challenges faced during development of
of SynGate and finally they will discuss areas they are considering
for improvement.
Captions: 
	00:00:03,280 --> 00:00:06,080
um

00:00:03,760 --> 00:00:06,960
hello everyone uh this talk is going to

00:00:06,080 --> 00:00:10,480
be about

00:00:06,960 --> 00:00:12,320
one application of xdp in particular for

00:00:10,480 --> 00:00:13,519
improving host performance under sim

00:00:12,320 --> 00:00:15,280
flood

00:00:13,519 --> 00:00:17,440
and we think it's exciting to share

00:00:15,280 --> 00:00:19,840
because of how much

00:00:17,440 --> 00:00:21,199
the technology xzp has evolved in the

00:00:19,840 --> 00:00:24,720
past four years

00:00:21,199 --> 00:00:26,160
and we can see now more and more complex

00:00:24,720 --> 00:00:28,080
applications that use it

00:00:26,160 --> 00:00:31,119
and we think the performance results

00:00:28,080 --> 00:00:33,360
we're seeing from

00:00:31,119 --> 00:00:35,520
doing this particular task issuing same

00:00:33,360 --> 00:00:38,640
cookies in xdp

00:00:35,520 --> 00:00:39,840
are quite exciting so as a high level

00:00:38,640 --> 00:00:41,520
overview

00:00:39,840 --> 00:00:43,280
this talk is going to start by

00:00:41,520 --> 00:00:45,039
introducing the problem and

00:00:43,280 --> 00:00:46,559
uh what are the opportunities for

00:00:45,039 --> 00:00:49,840
improvement we're gonna

00:00:46,559 --> 00:00:52,960
then dive deep into the exact design

00:00:49,840 --> 00:00:53,840
and how the different pieces uh come in

00:00:52,960 --> 00:00:55,039
together

00:00:53,840 --> 00:00:56,879
uh we're gonna share the performance

00:00:55,039 --> 00:00:59,199
results we're seeing and

00:00:56,879 --> 00:01:00,879
we're going to close off the talk with

00:00:59,199 --> 00:01:02,399
uh some areas for future work and some

00:01:00,879 --> 00:01:04,799
of the challenges we saw during

00:01:02,399 --> 00:01:06,960
development

00:01:04,799 --> 00:01:07,920
so to begin with uh you might recall

00:01:06,960 --> 00:01:10,880
simple attack

00:01:07,920 --> 00:01:13,600
exploits the stateful nature of the tcp

00:01:10,880 --> 00:01:16,960
handshake setup

00:01:13,600 --> 00:01:20,320
when an attacker sends a sin

00:01:16,960 --> 00:01:23,439
a sim packet a host has to keep some

00:01:20,320 --> 00:01:24,720
form of state because it needs to

00:01:23,439 --> 00:01:27,280
associate

00:01:24,720 --> 00:01:28,479
the this packet with the third packet in

00:01:27,280 --> 00:01:31,600
the handshake

00:01:28,479 --> 00:01:32,880
so if uh the host keeps that state of

00:01:31,600 --> 00:01:35,439
memory

00:01:32,880 --> 00:01:35,920
an attacker can very quickly exhaust

00:01:35,439 --> 00:01:39,600
memory

00:01:35,920 --> 00:01:41,840
on the host and disrupt normal traffic

00:01:39,600 --> 00:01:42,880
so a historical mitigation for this

00:01:41,840 --> 00:01:46,880
issue

00:01:42,880 --> 00:01:50,079
is called so-called cinco key which uh

00:01:46,880 --> 00:01:53,600
moves the state from in host memory to

00:01:50,079 --> 00:01:56,079
the corresponding synaptic packet and we

00:01:53,600 --> 00:01:57,439
effectively uh pick carefully what the

00:01:56,079 --> 00:02:00,320
sequence number should be

00:01:57,439 --> 00:02:01,439
for this for the synagogue by encoding

00:02:00,320 --> 00:02:04,159
the timestamp

00:02:01,439 --> 00:02:05,360
uh a mapping of the maximum segment size

00:02:04,159 --> 00:02:08,800
or mss

00:02:05,360 --> 00:02:13,120
and a hash over the dcp4 tuple and

00:02:08,800 --> 00:02:15,360
uh d timestamp so the 32 bits

00:02:13,120 --> 00:02:16,800
of the sequence number are gonna involve

00:02:15,360 --> 00:02:19,440
five bits of the timestamp

00:02:16,800 --> 00:02:20,879
three-bit mapping of the mss and a

00:02:19,440 --> 00:02:22,879
24-bit hash function

00:02:20,879 --> 00:02:25,200
and note that the 3-bit mapping of the

00:02:22,879 --> 00:02:28,239
mss effectively restricts

00:02:25,200 --> 00:02:30,400
uh shapes the maximum segment size

00:02:28,239 --> 00:02:31,920
of connections with cookies to eight

00:02:30,400 --> 00:02:33,040
possible values this is a technical

00:02:31,920 --> 00:02:36,319
notation

00:02:33,040 --> 00:02:38,959
um and just how it is

00:02:36,319 --> 00:02:40,319
and when the third pack in the handshake

00:02:38,959 --> 00:02:42,959
is received

00:02:40,319 --> 00:02:44,640
uh we can just recompute uh again what

00:02:42,959 --> 00:02:45,360
the cookie should be and as long as the

00:02:44,640 --> 00:02:47,280
timestamp

00:02:45,360 --> 00:02:48,800
is recent typically within a minute or

00:02:47,280 --> 00:02:50,239
two we should have

00:02:48,800 --> 00:02:52,959
we should be able to verify that there

00:02:50,239 --> 00:02:56,080
was indeed an initial synth packet

00:02:52,959 --> 00:02:58,400
and this uh as we said earlier

00:02:56,080 --> 00:02:59,200
uh means that we don't need to keep

00:02:58,400 --> 00:03:02,879
in-state

00:02:59,200 --> 00:03:06,959
in memory state and uh we

00:03:02,879 --> 00:03:10,000
just solve maybe solve this problem

00:03:06,959 --> 00:03:10,560
so when an attacker sends many many sim

00:03:10,000 --> 00:03:14,720
packets

00:03:10,560 --> 00:03:16,879
now host just the host just replies with

00:03:14,720 --> 00:03:19,519
uh packets with cinco keys and

00:03:16,879 --> 00:03:23,280
everything is good right

00:03:19,519 --> 00:03:25,840
so uh we argue that this

00:03:23,280 --> 00:03:26,799
actually just moves the problem from

00:03:25,840 --> 00:03:29,519
memory bound

00:03:26,799 --> 00:03:31,280
to cpu bound because uh for each

00:03:29,519 --> 00:03:34,159
synaptic packet

00:03:31,280 --> 00:03:35,680
we need to traverse a variable trx stack

00:03:34,159 --> 00:03:37,680
there are many allocations from the

00:03:35,680 --> 00:03:41,599
driver to the navigate

00:03:37,680 --> 00:03:43,280
rps and rfs layer then to the tcp stack

00:03:41,599 --> 00:03:44,400
and in reverse when we try to transmit

00:03:43,280 --> 00:03:46,159
the synaptic packet

00:03:44,400 --> 00:03:47,440
which results in many instructions per

00:03:46,159 --> 00:03:51,040
se um

00:03:47,440 --> 00:03:52,560
per synagogue now this doesn't mean the

00:03:51,040 --> 00:03:53,760
performance of the kernel is bad

00:03:52,560 --> 00:03:56,159
we just believe that there's an

00:03:53,760 --> 00:03:58,799
opportunity uh for improvement

00:03:56,159 --> 00:04:01,040
by moving specialized uh the specialized

00:03:58,799 --> 00:04:04,159
functionality very early in the

00:04:01,040 --> 00:04:06,000
university stack and the secondary

00:04:04,159 --> 00:04:08,799
opportunity we see for improvement here

00:04:06,000 --> 00:04:09,840
is that the kernel only exposes a global

00:04:08,799 --> 00:04:12,799
counter

00:04:09,840 --> 00:04:14,080
whereas bpf offers many many

00:04:12,799 --> 00:04:17,440
opportunities effectively

00:04:14,080 --> 00:04:19,280
limitless limitless land for improvement

00:04:17,440 --> 00:04:21,120
of this

00:04:19,280 --> 00:04:22,560
so the rest of the talk is going to

00:04:21,120 --> 00:04:24,960
focus on

00:04:22,560 --> 00:04:27,120
how to build this specialized program in

00:04:24,960 --> 00:04:30,000
dpf

00:04:27,120 --> 00:04:30,960
the first piece is a helper function

00:04:30,000 --> 00:04:34,160
which is

00:04:30,960 --> 00:04:36,720
uh present in linux after 5.4 the

00:04:34,160 --> 00:04:38,000
function computes a single key a given

00:04:36,720 --> 00:04:41,040
uh socket

00:04:38,000 --> 00:04:43,040
and the iptcp headers uh

00:04:41,040 --> 00:04:44,560
what we need from the images tcp ip4

00:04:43,040 --> 00:04:47,840
tuple and the mss option

00:04:44,560 --> 00:04:50,960
of tcp header this

00:04:47,840 --> 00:04:51,919
helper is needed because to compute the

00:04:50,960 --> 00:04:53,919
hash

00:04:51,919 --> 00:04:55,040
for the sim cookie we need to use a

00:04:53,919 --> 00:04:58,000
kernel key

00:04:55,040 --> 00:05:00,400
which we don't want to expose to bpf and

00:04:58,000 --> 00:05:02,639
the helper works in both xdp and tc

00:05:00,400 --> 00:05:03,680
we just perform some basic verification

00:05:02,639 --> 00:05:06,160
and then follows

00:05:03,680 --> 00:05:06,880
the behavior of the syscontrol tcps and

00:05:06,160 --> 00:05:10,000
cookies

00:05:06,880 --> 00:05:11,919
so if the value is zero uh secret keys

00:05:10,000 --> 00:05:13,199
are disabled and this uh helper is

00:05:11,919 --> 00:05:15,919
always going to fail

00:05:13,199 --> 00:05:17,919
if uh the value is two c cookies are

00:05:15,919 --> 00:05:19,600
always enabled and we're always going to

00:05:17,919 --> 00:05:21,199
uh try to issue a single key as long as

00:05:19,600 --> 00:05:23,600
there is a valid socket

00:05:21,199 --> 00:05:25,120
and if the value is one we're only going

00:05:23,600 --> 00:05:26,720
to issue syn cookies if

00:05:25,120 --> 00:05:29,520
the sync you for the corresponding

00:05:26,720 --> 00:05:32,160
socket is not overflowing

00:05:29,520 --> 00:05:33,919
uh the helper is going to pick the mss

00:05:32,160 --> 00:05:36,960
similar to how the kernel is doing that

00:05:33,919 --> 00:05:37,520
map it to uh three-bit space and encode

00:05:36,960 --> 00:05:40,080
it into

00:05:37,520 --> 00:05:42,560
the sim cookie and then the return value

00:05:40,080 --> 00:05:46,400
is going to be a concatenation between

00:05:42,560 --> 00:05:47,039
the 16 bit 16 bit mss and the 32 bit

00:05:46,400 --> 00:05:50,320
cookie

00:05:47,039 --> 00:05:53,759
and the top unsuccessful top 16 bits of

00:05:50,320 --> 00:05:55,759
the return value should be o0 on failure

00:05:53,759 --> 00:05:57,440
we're going to have a sign extended

00:05:55,759 --> 00:06:00,240
error code

00:05:57,440 --> 00:06:02,160
which is going to let us just verify

00:06:00,240 --> 00:06:06,240
whether or not the

00:06:02,160 --> 00:06:08,880
helper failed by comparing to zero

00:06:06,240 --> 00:06:09,759
um the bpf program at a high level is

00:06:08,880 --> 00:06:12,240
going to

00:06:09,759 --> 00:06:13,280
try to punt to the kernel as much as

00:06:12,240 --> 00:06:15,280
possible

00:06:13,280 --> 00:06:17,120
um there are opportunities for

00:06:15,280 --> 00:06:20,240
improvement uh

00:06:17,120 --> 00:06:22,720
to drop on parsing errors or

00:06:20,240 --> 00:06:24,240
if the socket fails uh just for

00:06:22,720 --> 00:06:24,880
simplicity we're going to assume we punt

00:06:24,240 --> 00:06:27,840
all these

00:06:24,880 --> 00:06:29,280
issues to the kernel for now so first of

00:06:27,840 --> 00:06:29,919
all we're going to try to parse the tcp

00:06:29,280 --> 00:06:32,080
packet

00:06:29,919 --> 00:06:33,440
if the packet is not tcp or is not same

00:06:32,080 --> 00:06:34,319
packet we're going to let the kernel

00:06:33,440 --> 00:06:35,840
handle it

00:06:34,319 --> 00:06:37,440
if we cannot find the socket

00:06:35,840 --> 00:06:40,160
corresponding to

00:06:37,440 --> 00:06:41,840
uh corresponding to the packet or if the

00:06:40,160 --> 00:06:43,039
socket is not in the correct state we're

00:06:41,840 --> 00:06:46,720
going to pass it to the kernel

00:06:43,039 --> 00:06:48,560
here we obviously can drop if

00:06:46,720 --> 00:06:49,759
we find a socket we're going to try to

00:06:48,560 --> 00:06:52,000
issue a single key

00:06:49,759 --> 00:06:53,919
if we cannot measure the same cookie

00:06:52,000 --> 00:06:55,199
we're going to let the kernel handle it

00:06:53,919 --> 00:06:57,039
here we don't know that here we don't

00:06:55,199 --> 00:07:00,319
have the opportunity to drop a packet

00:06:57,039 --> 00:07:01,599
because it might be that the cq for the

00:07:00,319 --> 00:07:04,240
socket is not full

00:07:01,599 --> 00:07:05,759
so uh we in this case we want the

00:07:04,240 --> 00:07:08,560
current to establish connection

00:07:05,759 --> 00:07:10,240
uh with request sockets like it does

00:07:08,560 --> 00:07:12,400
usually

00:07:10,240 --> 00:07:13,599
uh if we do issues in cookie we're going

00:07:12,400 --> 00:07:15,199
to generate

00:07:13,599 --> 00:07:16,880
the corresponding synthetic packet in

00:07:15,199 --> 00:07:20,720
place we're using the same buffer

00:07:16,880 --> 00:07:22,800
for us the uh as the packet for

00:07:20,720 --> 00:07:24,479
to be received we're then gonna do

00:07:22,800 --> 00:07:27,599
accounting and then transmit the packet

00:07:24,479 --> 00:07:27,599
back on the same interface

00:07:27,759 --> 00:07:33,199
in terms of uh the metrics which we can

00:07:31,120 --> 00:07:34,240
which we can export know that the kernel

00:07:33,199 --> 00:07:36,639
only has

00:07:34,240 --> 00:07:38,319
some simple counters that let us know

00:07:36,639 --> 00:07:41,360
globally what's going on

00:07:38,319 --> 00:07:44,400
but with bpf we can enhance enhance this

00:07:41,360 --> 00:07:46,240
by a very minimum adding

00:07:44,400 --> 00:07:48,639
making this counter the per port so we

00:07:46,240 --> 00:07:51,919
know which ports are under attack

00:07:48,639 --> 00:07:52,560
uh something maybe slightly better is we

00:07:51,919 --> 00:07:54,639
can

00:07:52,560 --> 00:07:56,160
detect heavy hitters and see if the

00:07:54,639 --> 00:07:58,960
symphony is coming from any particular

00:07:56,160 --> 00:08:01,199
host or ip address and

00:07:58,960 --> 00:08:02,879
filter based on that based on that ip

00:08:01,199 --> 00:08:05,759
address

00:08:02,879 --> 00:08:07,440
to gain insight into the structure of

00:08:05,759 --> 00:08:10,479
incoming attacks

00:08:07,440 --> 00:08:13,199
we can export information about what

00:08:10,479 --> 00:08:14,400
the packet size distribution is or what

00:08:13,199 --> 00:08:17,120
tcp options

00:08:14,400 --> 00:08:19,039
ip options the incoming packets use and

00:08:17,120 --> 00:08:22,160
this can inform us better

00:08:19,039 --> 00:08:24,400
about making rules to filter incoming

00:08:22,160 --> 00:08:26,319
traffic and further improve the

00:08:24,400 --> 00:08:28,879
performance under attack

00:08:26,319 --> 00:08:29,599
now one caveat here to note is that

00:08:28,879 --> 00:08:31,360
collection

00:08:29,599 --> 00:08:33,519
of each of these metrics can be

00:08:31,360 --> 00:08:35,200
expensive because

00:08:33,519 --> 00:08:36,880
each of these metrics is more

00:08:35,200 --> 00:08:37,919
instructions we run per packet and we

00:08:36,880 --> 00:08:40,000
are under attack

00:08:37,919 --> 00:08:42,240
we see many many packets per second so

00:08:40,000 --> 00:08:44,560
you do many many instructions per second

00:08:42,240 --> 00:08:45,839
uh for metric collection whereas we can

00:08:44,560 --> 00:08:49,120
be doing that

00:08:45,839 --> 00:08:50,720
for uh to handle

00:08:49,120 --> 00:08:53,279
either normal traffic or issue more same

00:08:50,720 --> 00:08:55,519
cookies so

00:08:53,279 --> 00:08:57,680
the rest of the talk is gonna fall is

00:08:55,519 --> 00:09:00,560
going to only use purport counters

00:08:57,680 --> 00:09:01,600
uh but we just want to highlight that is

00:09:00,560 --> 00:09:03,760
a trade-off

00:09:01,600 --> 00:09:05,680
for the administrator to decide how much

00:09:03,760 --> 00:09:07,040
metric metrics they want to export

00:09:05,680 --> 00:09:10,080
versus how much

00:09:07,040 --> 00:09:10,080
performance they want to get

00:09:10,640 --> 00:09:14,240
in pseudocode the program is going to

00:09:13,120 --> 00:09:15,760
look roughly like this

00:09:14,240 --> 00:09:17,920
we're going to try to parse the tcp

00:09:15,760 --> 00:09:20,800
header and if the parsing fails

00:09:17,920 --> 00:09:22,640
whether because this is due to

00:09:20,800 --> 00:09:25,519
encapsulation that is not supported

00:09:22,640 --> 00:09:27,040
or if the packet is not uh synack uh

00:09:25,519 --> 00:09:28,399
we're gonna let the kernel handle it

00:09:27,040 --> 00:09:30,399
we're gonna look up the socket

00:09:28,399 --> 00:09:31,680
try to generate a same cookie if we

00:09:30,399 --> 00:09:33,120
cannot uh

00:09:31,680 --> 00:09:35,360
find a cookie we're gonna release a

00:09:33,120 --> 00:09:37,200
socket and pass it to a kernel

00:09:35,360 --> 00:09:38,399
then we're going to extract the cookie

00:09:37,200 --> 00:09:40,640
in the mss

00:09:38,399 --> 00:09:42,320
from their term value of the helper

00:09:40,640 --> 00:09:42,880
function we're going to do any form of

00:09:42,320 --> 00:09:44,720
accounting

00:09:42,880 --> 00:09:46,320
in our case this is just increment the

00:09:44,720 --> 00:09:48,399
purport counters

00:09:46,320 --> 00:09:49,519
and then we're going to create and place

00:09:48,399 --> 00:09:51,279
the

00:09:49,519 --> 00:09:53,440
back packet take into consideration the

00:09:51,279 --> 00:09:54,399
cookie and mss the cookie is used for

00:09:53,440 --> 00:09:57,200
sequence number

00:09:54,399 --> 00:09:58,880
of the packet we send out and the mss is

00:09:57,200 --> 00:10:00,399
used for tcp option

00:09:58,880 --> 00:10:02,399
and then we're going to release a socket

00:10:00,399 --> 00:10:04,399
and transmit the packet

00:10:02,399 --> 00:10:06,240
here we can also redirect it to a

00:10:04,399 --> 00:10:07,760
different interface uh or

00:10:06,240 --> 00:10:09,760
uh rely on some of the batching

00:10:07,760 --> 00:10:11,040
functionality of xdp for simplicity

00:10:09,760 --> 00:10:13,440
which is going to say that we transmit

00:10:11,040 --> 00:10:13,440
the packet

00:10:13,920 --> 00:10:20,240
um now we have improved significantly

00:10:18,640 --> 00:10:21,839
the performance while under simply

00:10:20,240 --> 00:10:22,560
because we now we're going to issue uh

00:10:21,839 --> 00:10:25,040
we're going to

00:10:22,560 --> 00:10:25,680
do significantly less instructions for

00:10:25,040 --> 00:10:29,279
every

00:10:25,680 --> 00:10:29,920
uh cinco cube issue however the reality

00:10:29,279 --> 00:10:32,880
is that

00:10:29,920 --> 00:10:34,560
most of the time each host is not

00:10:32,880 --> 00:10:36,480
understand flood so we're going to

00:10:34,560 --> 00:10:38,399
introduce a lot of our head per packet

00:10:36,480 --> 00:10:39,040
because we do parsing and then socket

00:10:38,399 --> 00:10:42,640
lookup

00:10:39,040 --> 00:10:45,120
cookie generation and

00:10:42,640 --> 00:10:46,720
this adds up especially if there are

00:10:45,120 --> 00:10:48,800
many many sockets on the machine the

00:10:46,720 --> 00:10:52,560
socket lookup can be quite expensive

00:10:48,800 --> 00:10:54,640
so on average we've significantly hurt

00:10:52,560 --> 00:10:55,760
normal traffic which is exactly the

00:10:54,640 --> 00:10:58,800
reverse

00:10:55,760 --> 00:11:01,279
of what we want to do

00:10:58,800 --> 00:11:02,560
so to mitigate this problem we define

00:11:01,279 --> 00:11:04,800
two modes of operation

00:11:02,560 --> 00:11:07,120
we're going to when we're going to find

00:11:04,800 --> 00:11:08,880
flood mode for when we're under attack

00:11:07,120 --> 00:11:11,040
uh this we're going to try to issue some

00:11:08,880 --> 00:11:14,399
cookies for every single packet

00:11:11,040 --> 00:11:16,160
and to the to mitigate

00:11:14,399 --> 00:11:17,920
the effect of normal traffic we're going

00:11:16,160 --> 00:11:19,040
to sample to determine whether or not

00:11:17,920 --> 00:11:22,240
we're under flood

00:11:19,040 --> 00:11:23,519
so uh we're going to define a sampling

00:11:22,240 --> 00:11:25,839
interval t1

00:11:23,519 --> 00:11:28,560
which says basically we're gonna try to

00:11:25,839 --> 00:11:30,399
issue a cookie for a packet every q1

00:11:28,560 --> 00:11:33,040
seconds or milliseconds or any other

00:11:30,399 --> 00:11:35,040
unit of time if we

00:11:33,040 --> 00:11:37,200
do successfully issue a synchro key

00:11:35,040 --> 00:11:40,800
we're going to go under syn flood for

00:11:37,200 --> 00:11:43,040
t2 seconds and t2

00:11:40,800 --> 00:11:44,240
basically defines how many seconds or

00:11:43,040 --> 00:11:46,399
milliseconds

00:11:44,240 --> 00:11:48,160
since the last cookie we issued are we

00:11:46,399 --> 00:11:50,160
going to keep trying and trying and

00:11:48,160 --> 00:11:54,000
trying to issue some cookies

00:11:50,160 --> 00:11:56,880
and the two parameters trade off the

00:11:54,000 --> 00:11:58,240
speed at which we can detect ongoing

00:11:56,880 --> 00:12:01,200
attacks

00:11:58,240 --> 00:12:02,399
with um the overhead on regular traffic

00:12:01,200 --> 00:12:05,680
so a high t1

00:12:02,399 --> 00:12:07,440
is going to have low impact on regular

00:12:05,680 --> 00:12:10,959
traffic while we're not under simplet

00:12:07,440 --> 00:12:13,519
but we might not react as quickly to

00:12:10,959 --> 00:12:14,240
to them whereas a low one is going to

00:12:13,519 --> 00:12:15,760
have high

00:12:14,240 --> 00:12:17,040
overhead or normal traffic we're going

00:12:15,760 --> 00:12:18,880
to very quickly detect if we have

00:12:17,040 --> 00:12:20,720
ongoing attacks

00:12:18,880 --> 00:12:22,560
and for the rest of the talk we use t1

00:12:20,720 --> 00:12:23,519
and t2 of one second for the sake of

00:12:22,560 --> 00:12:24,959
simplicity

00:12:23,519 --> 00:12:28,399
but obviously this is a choice that

00:12:24,959 --> 00:12:28,399
administrators i can make

00:12:28,880 --> 00:12:33,279
in code this involves maintaining

00:12:31,680 --> 00:12:36,480
several global variables

00:12:33,279 --> 00:12:37,519
here we can also just use regular bpf

00:12:36,480 --> 00:12:40,399
maps

00:12:37,519 --> 00:12:40,720
we think global variables are as good

00:12:40,399 --> 00:12:43,600
but

00:12:40,720 --> 00:12:44,800
more performant so that's why we made

00:12:43,600 --> 00:12:48,320
this choice

00:12:44,800 --> 00:12:52,560
um we just take a timestamp

00:12:48,320 --> 00:12:54,160
um if we're under flow mode so if uh

00:12:52,560 --> 00:12:55,920
the flood timer hasn't expired we're

00:12:54,160 --> 00:12:57,519
always going to try to retry

00:12:55,920 --> 00:12:59,440
otherwise we're in passive mode and

00:12:57,519 --> 00:13:02,480
we're only going to try a packet if

00:12:59,440 --> 00:13:04,320
the sampling timer hasn't expired and

00:13:02,480 --> 00:13:05,680
uh we're just going to prep the skip or

00:13:04,320 --> 00:13:08,160
sample function to

00:13:05,680 --> 00:13:09,360
the code we had earlier to inform

00:13:08,160 --> 00:13:12,800
whether or not we're going to execute

00:13:09,360 --> 00:13:15,920
the expensive parsing or expensive

00:13:12,800 --> 00:13:15,920
expensive socket lockup

00:13:16,399 --> 00:13:22,000
so going to performance we the test we

00:13:20,000 --> 00:13:23,920
ran involved measuring the maximum sim

00:13:22,000 --> 00:13:27,040
float rate the host can handle

00:13:23,920 --> 00:13:28,240
and then sampling at uh subjecting the

00:13:27,040 --> 00:13:30,560
host to different simple

00:13:28,240 --> 00:13:31,600
syn floods up to that uh up to that

00:13:30,560 --> 00:13:35,040
maximum so it's

00:13:31,600 --> 00:13:35,760
5 10 uh 20 and so on uh we have around

00:13:35,040 --> 00:13:39,040
00:13:35,760 --> 00:13:40,959
sampling points then we compared

00:13:39,040 --> 00:13:42,800
at each of these simple rates the

00:13:40,959 --> 00:13:46,079
throughput of

00:13:42,800 --> 00:13:48,399
tcpr flows and we did

00:13:46,079 --> 00:13:49,120
an ap comparison between these

00:13:48,399 --> 00:13:53,040
throughputs

00:13:49,120 --> 00:13:55,760
with and without the bpf program

00:13:53,040 --> 00:13:56,320
uh so as you can see on this graph when

00:13:55,760 --> 00:13:59,600
we

00:13:56,320 --> 00:14:00,399
just do a normal like the regular kernel

00:13:59,600 --> 00:14:03,600
path

00:14:00,399 --> 00:14:04,480
the performance of regular traffic while

00:14:03,600 --> 00:14:06,320
under simplet

00:14:04,480 --> 00:14:09,199
very quickly degrades as we increase the

00:14:06,320 --> 00:14:13,040
sim flood uh simple trade

00:14:09,199 --> 00:14:14,800
and at around 50 of the maximum rate we

00:14:13,040 --> 00:14:16,240
basically are at 20 percent sure but

00:14:14,800 --> 00:14:17,920
then after that we quickly

00:14:16,240 --> 00:14:19,600
quickly degrade to not being able to

00:14:17,920 --> 00:14:22,959
establish connections

00:14:19,600 --> 00:14:23,760
whereas when we do use xdp uh we do

00:14:22,959 --> 00:14:26,800
degrade

00:14:23,760 --> 00:14:27,680
but we are about 80 percent true but

00:14:26,800 --> 00:14:30,480
even when we

00:14:27,680 --> 00:14:31,680
are at very very high sampling rates and

00:14:30,480 --> 00:14:34,320
note that

00:14:31,680 --> 00:14:36,160
here we're not cpu bound because cpus

00:14:34,320 --> 00:14:39,120
are around 40

00:14:36,160 --> 00:14:39,760
um at this influence rate and this

00:14:39,120 --> 00:14:43,199
throughput

00:14:39,760 --> 00:14:46,160
we just hit limits on

00:14:43,199 --> 00:14:46,160
the nic itself

00:14:47,519 --> 00:14:51,120
um so i would like to close off by

00:14:50,399 --> 00:14:53,199
talking

00:14:51,120 --> 00:14:54,720
uh just about some of the challenges and

00:14:53,199 --> 00:14:57,279
how we can

00:14:54,720 --> 00:14:58,240
uh some of the areas for future work of

00:14:57,279 --> 00:15:01,440
this project

00:14:58,240 --> 00:15:03,920
so the first the first challenge we hit

00:15:01,440 --> 00:15:05,760
was parsing the tcp options for the

00:15:03,920 --> 00:15:09,040
incoming packet

00:15:05,760 --> 00:15:11,040
because they have tcp options are going

00:15:09,040 --> 00:15:12,639
to be inherently a variable offset

00:15:11,040 --> 00:15:14,720
and they're going to be a variable

00:15:12,639 --> 00:15:16,959
number of them it was very hard to

00:15:14,720 --> 00:15:20,320
convince the bpm verifier

00:15:16,959 --> 00:15:24,000
that our accesses to

00:15:20,320 --> 00:15:26,959
options are indeed valid we

00:15:24,000 --> 00:15:28,240
jumped around this hoop by uh just

00:15:26,959 --> 00:15:32,480
having a switch statement

00:15:28,240 --> 00:15:32,480
around a number of options uh there's

00:15:33,120 --> 00:15:36,880
as you saw in the previous slide this

00:15:35,040 --> 00:15:37,600
didn't inherently hurt performance too

00:15:36,880 --> 00:15:40,000
bad but

00:15:37,600 --> 00:15:41,120
we can obviously improve it a little bit

00:15:40,000 --> 00:15:44,399
by

00:15:41,120 --> 00:15:47,440
um by

00:15:44,399 --> 00:15:50,639
doing something smart in verifier

00:15:47,440 --> 00:15:51,920
but behind it as of now uh perhaps a

00:15:50,639 --> 00:15:54,000
more interesting challenge

00:15:51,920 --> 00:15:55,519
is not specific to this project itself

00:15:54,000 --> 00:15:58,160
but more general to xdp

00:15:55,519 --> 00:15:58,800
and how to how to handle multi-buffer

00:15:58,160 --> 00:16:02,639
packets and

00:15:58,800 --> 00:16:05,440
xp at the same time um so far

00:16:02,639 --> 00:16:06,800
this is kind of an either or but there's

00:16:05,440 --> 00:16:10,720
very exciting development

00:16:06,800 --> 00:16:14,079
um stream for having support for now

00:16:10,720 --> 00:16:17,199
if we want to use both of these features

00:16:14,079 --> 00:16:18,639
we both the bpf program and multibuffer

00:16:17,199 --> 00:16:20,880
packets are options

00:16:18,639 --> 00:16:23,839
basically to trade off some performance

00:16:20,880 --> 00:16:27,120
back and run the program at tc

00:16:23,839 --> 00:16:29,519
um this is

00:16:27,120 --> 00:16:30,240
obviously suboptimal but it allows us to

00:16:29,519 --> 00:16:33,440
get like

00:16:30,240 --> 00:16:38,079
uh to get both functionalities

00:16:33,440 --> 00:16:40,399
and last um there is

00:16:38,079 --> 00:16:41,759
uh there is a very clear area for future

00:16:40,399 --> 00:16:44,000
work um

00:16:41,759 --> 00:16:45,199
currently we only issue some cookies but

00:16:44,000 --> 00:16:46,959
there is another

00:16:45,199 --> 00:16:48,639
another part to simply which is

00:16:46,959 --> 00:16:52,240
verifying that the incoming

00:16:48,639 --> 00:16:53,440
incomings and cookies are correct um

00:16:52,240 --> 00:16:55,759
there's already there was already

00:16:53,440 --> 00:16:57,360
support for this in the curdle uh before

00:16:55,759 --> 00:16:59,759
we started this project

00:16:57,360 --> 00:17:00,880
there is a bpf tcp checks and cookie

00:16:59,759 --> 00:17:03,519
helper

00:17:00,880 --> 00:17:04,640
added which allows us to actually reject

00:17:03,519 --> 00:17:06,720
very quickly

00:17:04,640 --> 00:17:07,839
any packets that have incorrect syn

00:17:06,720 --> 00:17:10,880
cookies

00:17:07,839 --> 00:17:12,240
the challenge here is for normal

00:17:10,880 --> 00:17:15,760
connections

00:17:12,240 --> 00:17:18,559
we are going to have two stages of

00:17:15,760 --> 00:17:19,520
verification one in the bpf or xdp

00:17:18,559 --> 00:17:21,520
program

00:17:19,520 --> 00:17:22,799
where we verified correct and then we're

00:17:21,520 --> 00:17:24,480
going to pass it to the kernel to

00:17:22,799 --> 00:17:28,160
establish a connection

00:17:24,480 --> 00:17:30,160
and verify it again there which

00:17:28,160 --> 00:17:31,840
is overhead that we would like to avoid

00:17:30,160 --> 00:17:32,559
and we don't have an answer to this

00:17:31,840 --> 00:17:34,320
question how

00:17:32,559 --> 00:17:35,760
how do we propagate this information to

00:17:34,320 --> 00:17:39,679
the tcp stack

00:17:35,760 --> 00:17:43,039
so that we can avoid the overhead on uh

00:17:39,679 --> 00:17:45,760
genuine connections yeah and

00:17:43,039 --> 00:17:48,320
uh this is this is my talk and thanks

00:17:45,760 --> 00:17:48,320
for listening

00:17:50,080 --> 00:17:56,240
hey uh thanks peter you actually

00:17:53,120 --> 00:18:00,160
we recovered our time i think

00:17:56,240 --> 00:18:03,440
so uh okay there's a there's a bunch of

00:18:00,160 --> 00:18:07,280
questions here i'm gonna go over them

00:18:03,440 --> 00:18:08,799
uh first one is from tom

00:18:07,280 --> 00:18:10,160
i i know you've you've been responding

00:18:08,799 --> 00:18:11,520
on on the chat but for the sake of the

00:18:10,160 --> 00:18:14,400
video i'm just gonna repeat them and

00:18:11,520 --> 00:18:15,200
you if you can respond in more detail

00:18:14,400 --> 00:18:18,720
the first one

00:18:15,200 --> 00:18:19,679
is from tom why what are the multiple

00:18:18,720 --> 00:18:21,440
allocations

00:18:19,679 --> 00:18:23,120
in this lengthy receive stack that you

00:18:21,440 --> 00:18:24,640
talk about don't you just need to

00:18:23,120 --> 00:18:28,559
allocate an sk buff

00:18:24,640 --> 00:18:31,440
on the scene um so i i don't remember

00:18:28,559 --> 00:18:32,160
the full list right now um what what i

00:18:31,440 --> 00:18:34,320
do know is

00:18:32,160 --> 00:18:36,080
we have the sqp allocation that we need

00:18:34,320 --> 00:18:39,120
to do we can avoid that with

00:18:36,080 --> 00:18:40,240
um syngate and there's also as far as i

00:18:39,120 --> 00:18:42,320
remember

00:18:40,240 --> 00:18:43,840
several allocations uh with at least my

00:18:42,320 --> 00:18:46,400
allocation for request socket

00:18:43,840 --> 00:18:47,280
and i believe also an allocation for the

00:18:46,400 --> 00:18:50,640
tx packet

00:18:47,280 --> 00:18:52,480
for the synag yeah i think i think the

00:18:50,640 --> 00:18:55,440
state for this uh

00:18:52,480 --> 00:18:56,960
uh rx stock the socket uh trans

00:18:55,440 --> 00:18:58,799
transient state is probably the most

00:18:56,960 --> 00:19:00,640
expensive right

00:18:58,799 --> 00:19:03,440
because you have to store that under

00:19:00,640 --> 00:19:03,440
normal conditions

00:19:05,440 --> 00:19:10,960
i i don't know which one is the most

00:19:07,200 --> 00:19:15,039
expensive i just know they add up um

00:19:10,960 --> 00:19:17,360
next questions sorry like i said

00:19:15,039 --> 00:19:20,320
um my assumption was that the stack

00:19:17,360 --> 00:19:22,160
would be doing sin cookies anyway

00:19:20,320 --> 00:19:23,840
assume that that was doing sin cookies

00:19:22,160 --> 00:19:25,200
for all the connections then when we

00:19:23,840 --> 00:19:27,919
pass the

00:19:25,200 --> 00:19:29,280
packet into the stack i believe the only

00:19:27,919 --> 00:19:32,640
allocation would be the sk

00:19:29,280 --> 00:19:34,000
buff which granite is is extremely

00:19:32,640 --> 00:19:37,200
expensive

00:19:34,000 --> 00:19:39,039
and and well worth bypassing but

00:19:37,200 --> 00:19:41,039
what i was getting to more and and i

00:19:39,039 --> 00:19:43,679
think this is great work

00:19:41,039 --> 00:19:45,919
but the possible extension of this is to

00:19:43,679 --> 00:19:48,080
figure out how to

00:19:45,919 --> 00:19:50,960
um more eliminate that problem and i had

00:19:48,080 --> 00:19:53,679
done some work on something called txtp

00:19:50,960 --> 00:19:55,200
where if we observe that there there's a

00:19:53,679 --> 00:19:56,720
lot of types of packets that really

00:19:55,200 --> 00:20:00,160
don't require an sk buff

00:19:56,720 --> 00:20:01,840
a tcp send carries no data so there's no

00:20:00,160 --> 00:20:04,799
reason why it shouldn't just be

00:20:01,840 --> 00:20:07,520
processed uh directly by the stack here

00:20:04,799 --> 00:20:09,280
here's the end bytes of send

00:20:07,520 --> 00:20:11,039
process it and then dump the data so we

00:20:09,280 --> 00:20:12,159
should be processing these directly as

00:20:11,039 --> 00:20:13,679
instead of sk buff

00:20:12,159 --> 00:20:15,520
but we're also going to see this in pure

00:20:13,679 --> 00:20:19,039
x and some other cases

00:20:15,520 --> 00:20:20,559
um so it might be it might be an

00:20:19,039 --> 00:20:22,799
extension of some sort to this sort of

00:20:20,559 --> 00:20:22,799
work

00:20:23,840 --> 00:20:28,240
thank you all right next question is

00:20:27,280 --> 00:20:30,240
from johannes

00:20:28,240 --> 00:20:31,760
is asking why you just don't drop the

00:20:30,240 --> 00:20:33,120
packet if there's no socket

00:20:31,760 --> 00:20:37,200
when you do the lookup right when we

00:20:33,120 --> 00:20:40,640
have a mess on our stats

00:20:37,200 --> 00:20:41,039
uh yeah we can drop the packet uh we

00:20:40,640 --> 00:20:42,799
just

00:20:41,039 --> 00:20:45,120
decided to pick between passing to the

00:20:42,799 --> 00:20:48,159
kernel um and

00:20:45,120 --> 00:20:49,679
uh transmitting the packet this seemed

00:20:48,159 --> 00:20:50,960
like a right place to drop the packet we

00:20:49,679 --> 00:20:52,320
just wanted to avoid potential

00:20:50,960 --> 00:20:54,400
interactions with the kernel

00:20:52,320 --> 00:20:55,360
with some behavior the simplest simplest

00:20:54,400 --> 00:20:58,720
thing to do is to just

00:20:55,360 --> 00:21:00,960
drop it i guess another one was a

00:20:58,720 --> 00:21:04,000
comment from david argen mostly

00:21:00,960 --> 00:21:06,720
it wasn't prefixed with q david prefix

00:21:04,000 --> 00:21:07,840
next time bpfk time get an s is

00:21:06,720 --> 00:21:10,320
expensive

00:21:07,840 --> 00:21:12,159
and he's seen this in his high pps

00:21:10,320 --> 00:21:16,080
workloads

00:21:12,159 --> 00:21:19,679
uh and you're using it your response

00:21:16,080 --> 00:21:22,799
uh my response was that um

00:21:19,679 --> 00:21:24,320
it definitely is expensive there as uh i

00:21:22,799 --> 00:21:26,559
suggested there's cheaper options than

00:21:24,320 --> 00:21:27,440
that um that we can use and are gonna be

00:21:26,559 --> 00:21:29,360
good enough

00:21:27,440 --> 00:21:30,559
but we noticed that even for bpfk time

00:21:29,360 --> 00:21:32,559
get an s

00:21:30,559 --> 00:21:35,120
the cost ended up being smaller than the

00:21:32,559 --> 00:21:39,840
cost for missing a socket lookup

00:21:35,120 --> 00:21:42,000
um so yeah which would be the case

00:21:39,840 --> 00:21:44,960
sorry uh when we're not under a sim

00:21:42,000 --> 00:21:46,799
flood we would look up a socket

00:21:44,960 --> 00:21:48,080
and see that the sync cue is not full so

00:21:46,799 --> 00:21:49,200
we're going to do this

00:21:48,080 --> 00:21:50,240
it's not even going to be missed we're

00:21:49,200 --> 00:21:51,679
going to find the socket it's not going

00:21:50,240 --> 00:21:53,280
to be full unless you're going to waste

00:21:51,679 --> 00:21:55,520
that time

00:21:53,280 --> 00:21:56,880
okay it's not just finding the socket

00:21:55,520 --> 00:21:59,200
it's not just looking for this in the

00:21:56,880 --> 00:22:01,520
socket but rather

00:21:59,200 --> 00:22:02,799
after you have to do extra work after

00:22:01,520 --> 00:22:04,960
you find it

00:22:02,799 --> 00:22:07,280
and then you decide that that wasn't

00:22:04,960 --> 00:22:09,679
worth pursuing yeah

00:22:07,280 --> 00:22:11,360
yes uh i remember numbers from like a

00:22:09,679 --> 00:22:14,480
very synthetic benchmark with

00:22:11,360 --> 00:22:14,960
uh bpf program like the difference was

00:22:14,480 --> 00:22:16,240
like

00:22:14,960 --> 00:22:18,400
an order of like several hundred

00:22:16,240 --> 00:22:21,440
nanoseconds uh but that's

00:22:18,400 --> 00:22:22,880
dpf problem so okay

00:22:21,440 --> 00:22:24,480
so you don't want to optimize for

00:22:22,880 --> 00:22:26,799
something that's not lowest hanging

00:22:24,480 --> 00:22:28,320
fruit i guess next question is from

00:22:26,799 --> 00:22:30,400
justin

00:22:28,320 --> 00:22:33,840
do you have a performance comparison

00:22:30,400 --> 00:22:36,799
with and without the mitigation process

00:22:33,840 --> 00:22:38,480
as you said the timestamp is not free

00:22:36,799 --> 00:22:39,760
but he was just curious how it cancels

00:22:38,480 --> 00:22:42,880
the benefit or not

00:22:39,760 --> 00:22:42,880
of having this mitigation

00:22:44,080 --> 00:22:49,600
uh sorry i missed the question can you

00:22:47,200 --> 00:22:51,039
repeat the question

00:22:49,600 --> 00:22:54,000
which mitigation are you talking about

00:22:51,039 --> 00:22:54,000
here just the

00:22:59,919 --> 00:23:06,400
yeah actually um he was talking about

00:23:03,120 --> 00:23:07,120
the time stamp to to know if he was

00:23:06,400 --> 00:23:09,440
under

00:23:07,120 --> 00:23:11,600
attack or not so he was switching uh

00:23:09,440 --> 00:23:15,120
from one mode to another mode

00:23:11,600 --> 00:23:17,360
so i was curious how

00:23:15,120 --> 00:23:20,000
it has been it benefits or not to of

00:23:17,360 --> 00:23:22,000
having this or not

00:23:20,000 --> 00:23:23,039
uh i don't i don't i definitely don't

00:23:22,000 --> 00:23:26,080
have a perf

00:23:23,039 --> 00:23:27,760
uh benchmark we uh i also don't have

00:23:26,080 --> 00:23:28,320
readily available the results i just

00:23:27,760 --> 00:23:31,440
know that

00:23:28,320 --> 00:23:34,159
lower the uh like small number of

00:23:31,440 --> 00:23:35,360
percentages lower the overhead

00:23:34,159 --> 00:23:38,559
but yeah i don't have the numbers right

00:23:35,360 --> 00:23:40,480
now in front of me okay

00:23:38,559 --> 00:23:42,559
uh there's no suggestion from us here

00:23:40,480 --> 00:23:46,400
says jefferies would be probably better

00:23:42,559 --> 00:23:50,159
it's good enough and your answer is

00:23:46,400 --> 00:23:52,320
absolutely all right

00:23:50,159 --> 00:23:54,080
question from uh i'm sorry if i missed

00:23:52,320 --> 00:23:57,520
francis pierre paolo

00:23:54,080 --> 00:23:58,880
santucci is the code for syngat open

00:23:57,520 --> 00:24:00,870
source

00:23:58,880 --> 00:24:02,240
uh no it is not um

00:24:00,870 --> 00:24:04,320
[Music]

00:24:02,240 --> 00:24:05,919
yeah there is small amount of code in

00:24:04,320 --> 00:24:07,039
the self-test that like shows how to

00:24:05,919 --> 00:24:08,799
issue the same cookies

00:24:07,039 --> 00:24:11,360
but i guess the things that are missing

00:24:08,799 --> 00:24:14,480
there are parsing the

00:24:11,360 --> 00:24:16,960
uh tcp uh

00:24:14,480 --> 00:24:18,400
pressing hp packet i guess i mean the

00:24:16,960 --> 00:24:19,679
code looked trivial from what you showed

00:24:18,400 --> 00:24:20,480
in your slides it doesn't look that

00:24:19,679 --> 00:24:22,000
complex

00:24:20,480 --> 00:24:24,720
if you understand the concepts you know

00:24:22,000 --> 00:24:26,559
you need the helpers the vpf helpers

00:24:24,720 --> 00:24:29,200
a little bit of parsing and that's it

00:24:26,559 --> 00:24:30,400
right yeah

00:24:29,200 --> 00:24:32,559
sorry the interrupt yeah most of the

00:24:30,400 --> 00:24:34,240
code is parsing yeah

00:24:32,559 --> 00:24:36,480
i mean the over if i print that code

00:24:34,240 --> 00:24:39,200
it's probably less than two pages of c

00:24:36,480 --> 00:24:40,320
from what i saw yeah it's not a lot of

00:24:39,200 --> 00:24:43,520
code

00:24:40,320 --> 00:24:45,919
right so someone could create an

00:24:43,520 --> 00:24:47,360
equivalent version and open source it

00:24:45,919 --> 00:24:48,880
you may have your own management

00:24:47,360 --> 00:24:49,520
interfaces maybe hooked up into it

00:24:48,880 --> 00:24:53,200
that's why

00:24:49,520 --> 00:24:53,200
it's not uh it's not open source

00:24:53,760 --> 00:24:58,320
uh yeah we yeah can't go on

00:24:58,559 --> 00:25:02,240
all right any other questions anybody

00:25:08,000 --> 00:25:11,600
does do things like the fact that xtp

00:25:10,080 --> 00:25:13,520
can't do tso affect you

00:25:11,600 --> 00:25:15,200
anyway i mean this is this connection

00:25:13,520 --> 00:25:19,520
setup but uh does

00:25:15,200 --> 00:25:19,520
since you keep track of the sockets uh

00:25:19,679 --> 00:25:23,120
is is that gonna be a problem or not i

00:25:22,240 --> 00:25:25,679
probably not

00:25:23,120 --> 00:25:26,880
just just crosstalk yeah i don't think

00:25:25,679 --> 00:25:28,880
it should be a problem

00:25:26,880 --> 00:25:30,159
um because it's as you said it's just

00:25:28,880 --> 00:25:32,880
the connection set up

00:25:30,159 --> 00:25:34,480
after that yeah after that you don't

00:25:32,880 --> 00:25:35,600
handle the socket anymore it's gone

00:25:34,480 --> 00:25:38,640
right you don't start

00:25:35,600 --> 00:25:44,000
keeping ref counts to it or no

00:25:38,640 --> 00:25:45,840
i we have to release for you yeah okay

00:25:44,000 --> 00:25:47,600
all right anybody else with questions

00:25:45,840 --> 00:25:48,960
all this i'm sorry i'm just missing a

00:25:47,600 --> 00:25:52,559
lot of questions i guess here

00:25:48,960 --> 00:25:52,559
okay um

00:25:53,840 --> 00:25:58,799
people maybe raise their hands david

00:25:55,679 --> 00:26:01,360
ahead you didn't put a queue again

00:25:58,799 --> 00:26:01,840
he says he would like to get a local

00:26:01,360 --> 00:26:04,640
clock

00:26:01,840 --> 00:26:06,159
exposed as ppfk get fast ns half the

00:26:04,640 --> 00:26:08,720
cost and still maintaining the same

00:26:06,159 --> 00:26:08,720
resolution

00:26:08,840 --> 00:26:11,840
um

00:26:12,000 --> 00:26:14,640
yeah i guess that's not a question for

00:26:13,279 --> 00:26:15,360
me as much as it is for the bpf

00:26:14,640 --> 00:26:19,120
maintainers

00:26:15,360 --> 00:26:21,200
um right right that's true

00:26:19,120 --> 00:26:22,159
uh and then you know the counter

00:26:21,200 --> 00:26:24,960
response from rc

00:26:22,159 --> 00:26:25,360
is gifts wouldn't even need a ppf call

00:26:24,960 --> 00:26:29,039
uh

00:26:25,360 --> 00:26:30,720
from srinivas narayana uh question is

00:26:29,039 --> 00:26:34,159
what was the next speed for the graph

00:26:30,720 --> 00:26:36,799
you showed that's part one

00:26:34,159 --> 00:26:38,960
uh part one and gigabit nick if i

00:26:36,799 --> 00:26:42,480
remember correctly or

00:26:38,960 --> 00:26:46,240
it's a 10 it's a 10 or a 2x

00:26:42,480 --> 00:26:47,600
or a w310 or 20. okay

00:26:46,240 --> 00:26:49,279
the other question is do you see any

00:26:47,600 --> 00:26:51,360
opportunities to keep

00:26:49,279 --> 00:26:53,039
the useful throughput high near the

00:26:51,360 --> 00:26:56,640
maximum throughput

00:26:53,039 --> 00:26:56,640
i'm not sure if i followed that

00:26:57,120 --> 00:27:02,960
uh i think that we're still like the the

00:27:00,880 --> 00:27:04,000
triple like rapidly dropping off i

00:27:02,960 --> 00:27:05,760
believe this is

00:27:04,000 --> 00:27:07,600
uh we're hitting a nick limitation

00:27:05,760 --> 00:27:10,080
rather than limitation of

00:27:07,600 --> 00:27:11,679
xdp or just like not receiving packets

00:27:10,080 --> 00:27:13,279
fast enough

00:27:11,679 --> 00:27:15,200
what what what would be the unique

00:27:13,279 --> 00:27:17,279
limitation is it

00:27:15,200 --> 00:27:18,960
uh we didn't investigate the problem uh

00:27:17,279 --> 00:27:22,159
sterling is probably we should have

00:27:18,960 --> 00:27:24,080
um but yeah it was an issue of not

00:27:22,159 --> 00:27:26,159
receiving packets

00:27:24,080 --> 00:27:27,760
okay so the falloff that you showed in a

00:27:26,159 --> 00:27:31,279
graph was because of

00:27:27,760 --> 00:27:34,720
some nick limitation yeah

00:27:31,279 --> 00:27:36,960
okay musia eric dumas ed

00:27:34,720 --> 00:27:39,039
says you could you would have to send a

00:27:36,960 --> 00:27:39,840
reset which is another 15 nanosecond

00:27:39,039 --> 00:27:42,399
cost

00:27:39,840 --> 00:27:45,440
i don't know what point that is i think

00:27:42,399 --> 00:27:48,480
it's response to three of us

00:27:45,440 --> 00:27:52,159
uh i think that's missing a socket

00:27:48,480 --> 00:27:53,840
if i remember correctly uh if you

00:27:52,159 --> 00:27:55,200
want to drop the packet you can't just

00:27:53,840 --> 00:27:58,720
drop a pack you have to

00:27:55,200 --> 00:27:58,720
send a reset in a lot of situations

00:27:58,799 --> 00:28:02,480
you you still have to do that management

00:28:01,039 --> 00:28:05,279
at that level yeah

00:28:02,480 --> 00:28:05,279
reset is a must-see

00:28:05,760 --> 00:28:11,039
if i understand correctly what derek was

00:28:07,600 --> 00:28:11,039
saying that's what she was referring to

00:28:11,120 --> 00:28:20,480
okay uh the next question here is

00:28:16,000 --> 00:28:20,480
um to do who's asking a question

00:28:21,200 --> 00:28:25,600
okay eric is correcting saying that 15 a

00:28:23,279 --> 00:28:30,720
second was for the local stuff

00:28:25,600 --> 00:28:32,960
not uh not for the reset

00:28:30,720 --> 00:28:32,960
uh

00:28:34,159 --> 00:28:37,520
is there not out okay so i think these

00:28:36,799 --> 00:28:40,559
are sort of uh

00:28:37,520 --> 00:28:43,279
deviations from the questions um

00:28:40,559 --> 00:28:44,080
anybody wants to ask pedro any question

00:28:43,279 --> 00:28:46,720
related to the

00:28:44,080 --> 00:28:47,679
talk please uh either raise your hand or

00:28:46,720 --> 00:28:51,679
chime in

00:28:47,679 --> 00:28:51,679
or just sp uh type your question

00:28:54,880 --> 00:28:58,399
hey jamal i think some of that is just

00:28:56,559 --> 00:28:58,720
bantering in the chat channel as opposed

00:28:58,399 --> 00:29:01,679
to

00:28:58,720 --> 00:29:01,679
questions for him

00:29:02,880 --> 00:29:06,640
yeah okay well there's a happy hour

00:29:05,039 --> 00:29:09,600
coming up so

00:29:06,640 --> 00:29:10,880
uh we can we can banter all night long

00:29:09,600 --> 00:29:14,480
all right so

00:29:10,880 --> 00:29:18,080
thank you peter that was an amazing talk

00:29:14,480 --> 00:29:19,200
um and i'm sure people i've got a lot of

00:29:18,080 --> 00:29:21,520
other ideas here

00:29:19,200 --> 00:29:22,240
listening this in cookie inc integration

00:29:21,520 --> 00:29:23,520
was

00:29:22,240 --> 00:29:25,440
is the first i've heard of there's a lot

00:29:23,520 --> 00:29:27,760
of people trying to do sin uh

00:29:25,440 --> 00:29:29,200
dos prevention but you this is the first

00:29:27,760 --> 00:29:34,880
i've had that

00:29:29,200 --> 00:29:34,880

YouTube URL: https://www.youtube.com/watch?v=3e2yeyTzh_c


