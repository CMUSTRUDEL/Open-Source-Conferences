Title: Netdev 0x13 - Conntrack  tales of software datapaths
Publication date: 2019-05-26
Playlist: Netdev 0x13 - Day 3
Description: 
	Aaron Conole and Marcelo Leitner want to make it easier to integrate TC offload with conntracking.
This talk describes their efforts to integrate ConnTrack with TC in software datapath. They 
describe their implementation approach, the challenges that they had to overcome, testing approach taken and finally some preliminary performance numbers.

More info:
https://netdevconf.org/0x13/session.html?talk-conntrack-tales
Captions: 
	00:00:00,030 --> 00:00:05,549
hello everyone I'm Marcelo I'm here with

00:00:02,610 --> 00:00:08,460
Aaron so that we can talk with you about

00:00:05,549 --> 00:00:15,990
our experience or integrating contract

00:00:08,460 --> 00:00:17,520
on other subsystems these our agenda for

00:00:15,990 --> 00:00:20,369
today we are going to explain the

00:00:17,520 --> 00:00:22,769
motivation for this work describe what

00:00:20,369 --> 00:00:25,039
we have done so far some some initial

00:00:22,769 --> 00:00:29,310
test results really really an issue

00:00:25,039 --> 00:00:37,530
future work that we are seeing and we

00:00:29,310 --> 00:00:40,620
have some time for question answers so

00:00:37,530 --> 00:00:43,350
motivations for contract it's a really

00:00:40,620 --> 00:00:46,230
big do as vector if you have it in your

00:00:43,350 --> 00:00:49,440
network and if you are not prepared

00:00:46,230 --> 00:00:52,079
it may get fueled by it some attacker

00:00:49,440 --> 00:00:56,300
because it's like a tree and it can be

00:00:52,079 --> 00:00:59,160
routed it can it is routable and some

00:00:56,300 --> 00:01:01,680
entity outside of your network can just

00:00:59,160 --> 00:01:05,150
feel it and new connections won't get

00:01:01,680 --> 00:01:08,580
through and choose or older ones expire

00:01:05,150 --> 00:01:10,320
but in spite of this contracts is still

00:01:08,580 --> 00:01:15,200
important it provides stateful

00:01:10,320 --> 00:01:17,970
forwarding for VMs and small galleries

00:01:15,200 --> 00:01:22,229
one of the critical features of it is

00:01:17,970 --> 00:01:24,420
that it has what they call helpers that

00:01:22,229 --> 00:01:27,990
they can track of cedar connections for

00:01:24,420 --> 00:01:36,210
FTP for example so you can have the data

00:01:27,990 --> 00:01:39,810
connection getting to so we need it and

00:01:36,210 --> 00:01:43,320
we also need uploaded because the lack

00:01:39,810 --> 00:01:46,140
of it is going to be hindering the open

00:01:43,320 --> 00:01:48,090
V switch offloading adoption and we have

00:01:46,140 --> 00:01:50,549
information that major cloud providers

00:01:48,090 --> 00:01:52,829
are abandoning contract where they can

00:01:50,549 --> 00:01:54,540
because it cannot be offloaded and they

00:01:52,829 --> 00:01:57,079
read they speak they need the

00:01:54,540 --> 00:01:57,079
performance

00:01:58,100 --> 00:02:02,700
[Music]

00:02:00,320 --> 00:02:03,659
open second order cloud technologist

00:02:02,700 --> 00:02:08,789
you'll need it

00:02:03,659 --> 00:02:12,270
contract is how we do net it has it

00:02:08,789 --> 00:02:14,900
holds the entire table on which AP and

00:02:12,270 --> 00:02:18,330
which parts should be translated to what

00:02:14,900 --> 00:02:20,970
it is the base functionality for

00:02:18,330 --> 00:02:23,010
security groups so whenever you enable

00:02:20,970 --> 00:02:27,209
it and OpenStack you were relying on

00:02:23,010 --> 00:02:30,150
contract there you can see already that

00:02:27,209 --> 00:02:33,500
in this case you cannot upload that

00:02:30,150 --> 00:02:39,470
OpenStack load because it requires

00:02:33,500 --> 00:02:39,470
contract and also load ports also use it

00:02:39,800 --> 00:02:45,420
so what we need to know that your float

00:02:43,110 --> 00:02:48,000
contract you first have to have the

00:02:45,420 --> 00:02:50,910
software data path don't because that's

00:02:48,000 --> 00:02:53,640
how you control it you cannot control

00:02:50,910 --> 00:02:56,610
your hybrid directly and assume that the

00:02:53,640 --> 00:02:58,530
software data path is in there so we

00:02:56,610 --> 00:03:01,080
must integrate first in the subtitle

00:02:58,530 --> 00:03:07,230
path and that's what we did as I step

00:03:01,080 --> 00:03:09,989
towards offloading so on this torque

00:03:07,230 --> 00:03:12,959
it's all software for now but with the

00:03:09,989 --> 00:03:15,480
goal of offloading and since contract is

00:03:12,959 --> 00:03:17,790
part of that future it's easy to start

00:03:15,480 --> 00:03:21,269
integrating the the entry points they

00:03:17,790 --> 00:03:25,709
are well identified there well the API

00:03:21,269 --> 00:03:28,049
is well contained again no connections

00:03:25,709 --> 00:03:34,560
were offloaded on this presentation but

00:03:28,049 --> 00:03:36,989
we actually integrated with TC so how it

00:03:34,560 --> 00:03:38,430
was integrated with TC we followed the

00:03:36,989 --> 00:03:40,070
approach that Mellanox has been

00:03:38,430 --> 00:03:42,299
proposing for the past conferences

00:03:40,070 --> 00:03:44,609
there's a link in there for the paper

00:03:42,299 --> 00:03:48,420
that is really the base of the

00:03:44,609 --> 00:03:50,430
implementation that we did we extend a

00:03:48,420 --> 00:03:53,609
float sector and flower classifier to

00:03:50,430 --> 00:03:56,340
match on contract information so when

00:03:53,609 --> 00:03:59,010
you ask no flower hey please match on

00:03:56,340 --> 00:04:02,430
contract state established the float

00:03:59,010 --> 00:04:05,250
sector will be able to reference the NFC

00:04:02,430 --> 00:04:08,100
T pointer on S key be and checked for

00:04:05,250 --> 00:04:10,590
the State Information and match based on

00:04:08,100 --> 00:04:11,280
that and only if the pointer is already

00:04:10,590 --> 00:04:13,410
there

00:04:11,280 --> 00:04:15,720
if it's not there yet it's not going to

00:04:13,410 --> 00:04:18,660
fetch for you because a match is not

00:04:15,720 --> 00:04:22,350
supposed to alter any information even

00:04:18,660 --> 00:04:23,880
its data or metadata on the packet and

00:04:22,350 --> 00:04:26,040
we also add a new action

00:04:23,880 --> 00:04:29,550
it's called CT should take contract

00:04:26,040 --> 00:04:31,860
actions on a packet such as sand into a

00:04:29,550 --> 00:04:35,790
contract which is how we get the initial

00:04:31,860 --> 00:04:39,600
information on settings on information

00:04:35,790 --> 00:04:45,480
and marking for now this is the action

00:04:39,600 --> 00:04:48,390
that we tested here once RCU be fired

00:04:45,480 --> 00:04:52,310
which so we don't have any spring-locks

00:04:48,390 --> 00:04:55,530
because of this action it should scale

00:04:52,310 --> 00:04:57,690
quite well and the patches that we use

00:04:55,530 --> 00:05:01,590
it they are newer than the ones that we

00:04:57,690 --> 00:05:02,820
posted on the mailing list as RFC and we

00:05:01,590 --> 00:05:05,820
are working in collaboration with

00:05:02,820 --> 00:05:08,130
Mellanox for streaming them so we should

00:05:05,820 --> 00:05:15,540
be able to post a new version quite soon

00:05:08,130 --> 00:05:18,540
I would say like two weeks or so so what

00:05:15,540 --> 00:05:21,000
we started the iptables plus up and this

00:05:18,540 --> 00:05:23,040
reach plus contract scenario and then we

00:05:21,000 --> 00:05:26,250
compared with TC plus up in this reach

00:05:23,040 --> 00:05:28,919
plus contract we didn't rely all up and

00:05:26,250 --> 00:05:31,160
we switch to do that because we didn't

00:05:28,919 --> 00:05:35,430
integrate it with open V switch yet so

00:05:31,160 --> 00:05:40,590
we did that based on our IP tables and

00:05:35,430 --> 00:05:43,289
then TC this is a sample of the rule set

00:05:40,590 --> 00:05:46,979
that we use it the first one is supposed

00:05:43,289 --> 00:05:49,470
to drop some packets so we have a bit

00:05:46,979 --> 00:05:51,510
more of processing going on like

00:05:49,470 --> 00:05:54,930
simulating other rules that would be

00:05:51,510 --> 00:05:56,789
matching and it's also able to select

00:05:54,930 --> 00:06:00,000
the amount of flows that we are working

00:05:56,789 --> 00:06:04,710
with it's just a standard drop so the

00:06:00,000 --> 00:06:06,510
second one is the one that starts to

00:06:04,710 --> 00:06:09,630
match using contract information it's

00:06:06,510 --> 00:06:12,210
matching on packets that they are not in

00:06:09,630 --> 00:06:14,280
track at state so if there is no

00:06:12,210 --> 00:06:16,770
information on contract on the package

00:06:14,280 --> 00:06:19,530
it's going to match this one and then

00:06:16,770 --> 00:06:21,720
action Ct is sending this packet to

00:06:19,530 --> 00:06:24,400
contract and the next action will go to

00:06:21,720 --> 00:06:28,180
change a hundred which is the

00:06:24,400 --> 00:06:31,090
that button ox has been doing and then

00:06:28,180 --> 00:06:34,180
on the chain a hundred we match on city

00:06:31,090 --> 00:06:36,280
state which in this case with the new

00:06:34,180 --> 00:06:39,699
state and the tracking state ok so

00:06:36,280 --> 00:06:42,490
that's a little connection that we want

00:06:39,699 --> 00:06:44,830
to commit we can actually confirm it in

00:06:42,490 --> 00:06:47,259
the contract table and then take the

00:06:44,830 --> 00:06:49,870
action to output this packet on another

00:06:47,259 --> 00:06:52,479
port this is just a sample there were

00:06:49,870 --> 00:06:55,570
more rules on the testing like for

00:06:52,479 --> 00:06:59,650
output in the packet in the - new state

00:06:55,570 --> 00:07:07,990
but for just to have an idea these are

00:06:59,650 --> 00:07:12,970
enough yeah so I'm gonna explain kind of

00:07:07,990 --> 00:07:17,199
the test set up a little bit so we as

00:07:12,970 --> 00:07:24,460
Marcelo said we used IP tables and open

00:07:17,199 --> 00:07:26,259
V switch and contract and so sort of the

00:07:24,460 --> 00:07:28,780
problem with just going with straight

00:07:26,259 --> 00:07:32,139
OVS into a into a VM and doing like a

00:07:28,780 --> 00:07:35,800
PvP test that way is there's not an easy

00:07:32,139 --> 00:07:37,210
way to call into IP tables now you might

00:07:35,800 --> 00:07:39,460
say like oh you could just call into the

00:07:37,210 --> 00:07:42,639
contractor from OVS and that's true but

00:07:39,460 --> 00:07:46,229
the offload support for contract to

00:07:42,639 --> 00:07:49,060
actually like call the TC flower side

00:07:46,229 --> 00:07:50,639
isn't there and rather than spend time

00:07:49,060 --> 00:07:53,010
like writing that if things could change

00:07:50,639 --> 00:07:55,659
you know it just made more sense to

00:07:53,010 --> 00:07:58,539
create this kind of slightly more

00:07:55,659 --> 00:08:00,310
complicated topology where we push

00:07:58,539 --> 00:08:02,949
packets through this bridge and there we

00:08:00,310 --> 00:08:06,639
can run IP tables go to the connection

00:08:02,949 --> 00:08:10,750
tracker do some drops and forward into

00:08:06,639 --> 00:08:13,900
guest and then come back out we use tier

00:08:10,750 --> 00:08:17,409
X as a packet generator we had some

00:08:13,900 --> 00:08:18,970
issues using the latest version so we

00:08:17,409 --> 00:08:23,050
did end up using like slightly older

00:08:18,970 --> 00:08:26,139
version I don't have any specific reason

00:08:23,050 --> 00:08:27,880
why other than we ran into some bug so

00:08:26,139 --> 00:08:33,010
we had to use a slightly older version

00:08:27,880 --> 00:08:36,159
of tier X for the TC side you'll notice

00:08:33,010 --> 00:08:37,890
there's some red arrows those are like

00:08:36,159 --> 00:08:41,620
us like a shunt

00:08:37,890 --> 00:08:44,260
when packets come in normally they would

00:08:41,620 --> 00:08:46,990
be passed for the iptables testing

00:08:44,260 --> 00:08:48,580
there'd be passed from the NIC you know

00:08:46,990 --> 00:08:50,260
through the bridge to OVS and then into

00:08:48,580 --> 00:08:52,900
the guests but for us we could actually

00:08:50,260 --> 00:08:55,570
just shop for the TC side we did I

00:08:52,900 --> 00:08:57,850
decided to shut them on the ingress side

00:08:55,570 --> 00:09:01,060
means the guests and then the egress

00:08:57,850 --> 00:09:06,640
follows the the same path out that that

00:09:01,060 --> 00:09:09,210
iptables follows so that's kind of a

00:09:06,640 --> 00:09:14,470
setup I know it looks a little funky but

00:09:09,210 --> 00:09:17,740
yeah that's that's what we did so this

00:09:14,470 --> 00:09:20,710
is the some initial results for some

00:09:17,740 --> 00:09:22,930
latency measurements we took this is

00:09:20,710 --> 00:09:30,400
from the IP tables testings we call this

00:09:22,930 --> 00:09:33,040
like kind of the baseline so at each at

00:09:30,400 --> 00:09:35,410
each like test that we did we we ran

00:09:33,040 --> 00:09:37,630
about we only did about 3,000

00:09:35,410 --> 00:09:39,730
connections per second we could have

00:09:37,630 --> 00:09:41,800
done more but that would require again

00:09:39,730 --> 00:09:45,040
some additional tuning and some

00:09:41,800 --> 00:09:46,960
additional like attempt to isolate like

00:09:45,040 --> 00:09:50,020
more the effects of what else is going

00:09:46,960 --> 00:09:54,070
on in the system so I figure a low rate

00:09:50,020 --> 00:09:56,050
is easier to maybe see that the system

00:09:54,070 --> 00:10:00,730
isn't loaded so the effect of calling

00:09:56,050 --> 00:10:02,500
contract might be more obvious we ran

00:10:00,730 --> 00:10:06,670
the test for about a hundred seconds and

00:10:02,500 --> 00:10:08,230
at each you know row there we have like

00:10:06,670 --> 00:10:12,490
the percentage of traffic being dropped

00:10:08,230 --> 00:10:15,190
so we kind of divided the traffic into

00:10:12,490 --> 00:10:17,080
like few different subnets and each

00:10:15,190 --> 00:10:19,900
subnet represented about five percent of

00:10:17,080 --> 00:10:22,830
the traffic so then we could just like

00:10:19,900 --> 00:10:26,890
mask off a slash eight and drop it and

00:10:22,830 --> 00:10:33,220
you know get like 5 10 15 20 here we

00:10:26,890 --> 00:10:35,740
only did by 10 but yeah so these are the

00:10:33,220 --> 00:10:38,890
numbers I guess they're just numbers

00:10:35,740 --> 00:10:43,330
right they don't mean much until we look

00:10:38,890 --> 00:10:49,240
at kind of the TC side where we did like

00:10:43,330 --> 00:10:51,640
I said the same test this was again from

00:10:49,240 --> 00:10:54,550
the topology packets come in they

00:10:51,640 --> 00:10:57,610
get shunted directly to the VM and then

00:10:54,550 --> 00:11:01,090
they you know egress through open V

00:10:57,610 --> 00:11:04,450
switch and the V and bridge and all back

00:11:01,090 --> 00:11:07,360
out to the Nick so and and again we

00:11:04,450 --> 00:11:10,810
collected the you know kind of like the

00:11:07,360 --> 00:11:15,130
the latency that it took or the latency

00:11:10,810 --> 00:11:20,040
through the system and here we kind of

00:11:15,130 --> 00:11:23,470
plot as sort of what we think was the

00:11:20,040 --> 00:11:26,320
you know like a comparison just to kind

00:11:23,470 --> 00:11:29,760
of see like where things are and and I

00:11:26,320 --> 00:11:33,490
don't quite understand why the graph

00:11:29,760 --> 00:11:37,240
showed up the way it did meaning like

00:11:33,490 --> 00:11:41,260
that iptables slope is a little strange

00:11:37,240 --> 00:11:43,510
and I didn't expect it but TC kind of

00:11:41,260 --> 00:11:47,670
looks more closer to what I would expect

00:11:43,510 --> 00:11:50,290
which is like as you drop packets

00:11:47,670 --> 00:11:52,600
there's less calls into contract and

00:11:50,290 --> 00:11:56,800
that means there would be like less

00:11:52,600 --> 00:11:58,870
latency imposed by kind of you know the

00:11:56,800 --> 00:12:04,090
latency imposed on the packet by going

00:11:58,870 --> 00:12:05,590
to the connection tracker so yeah there

00:12:04,090 --> 00:12:06,880
was the performance results here are

00:12:05,590 --> 00:12:08,740
like kind of interesting but they're

00:12:06,880 --> 00:12:11,550
still very preliminary I mean like this

00:12:08,740 --> 00:12:14,260
was not done on a very optimized like

00:12:11,550 --> 00:12:15,940
optimally tuned system so I didn't like

00:12:14,260 --> 00:12:17,710
tune the number of max connection

00:12:15,940 --> 00:12:19,750
tracker entries that could be there I

00:12:17,710 --> 00:12:21,160
didn't like play with the time outs to

00:12:19,750 --> 00:12:22,810
make sure that connections would expire

00:12:21,160 --> 00:12:24,880
really quickly to make sure there were

00:12:22,810 --> 00:12:27,690
no like other effects of lingering

00:12:24,880 --> 00:12:32,310
connections after they were torn down

00:12:27,690 --> 00:12:36,340
yeah it was really like very very rough

00:12:32,310 --> 00:12:39,640
numbers and then one thing I forgot to

00:12:36,340 --> 00:12:43,360
mention is the test itself the traffic

00:12:39,640 --> 00:12:46,540
is really just an HTTP request for 32 K

00:12:43,360 --> 00:12:48,790
bytes and then the response and so T Rex

00:12:46,540 --> 00:12:50,830
would kind of partition it into the

00:12:48,790 --> 00:12:53,560
sending side and receiving side and play

00:12:50,830 --> 00:12:57,970
them out the correct ports so we could

00:12:53,560 --> 00:12:59,740
see the we could see kind of like what

00:12:57,970 --> 00:13:02,850
it would look like to have you know

00:12:59,740 --> 00:13:02,850
simulated real traffic

00:13:04,660 --> 00:13:12,140
so for the future work on this TC side

00:13:08,320 --> 00:13:14,570
like we want to better understand the

00:13:12,140 --> 00:13:17,660
performance we have some numbers doing

00:13:14,570 --> 00:13:21,140
like a more tuned setup where we run

00:13:17,660 --> 00:13:24,110
like C hundred K and we're also working

00:13:21,140 --> 00:13:26,240
on or I'm working on getting to like C 1

00:13:24,110 --> 00:13:27,800
M so that's for anyone that doesn't know

00:13:26,240 --> 00:13:32,360
that's a hundred thousand and one

00:13:27,800 --> 00:13:36,519
million connections we do need to add

00:13:32,360 --> 00:13:38,870
some integration to Fernet actions like

00:13:36,519 --> 00:13:43,399
to actually perform the NAT

00:13:38,870 --> 00:13:47,329
transformation and on the packet as it

00:13:43,399 --> 00:13:50,630
passes through the data path one thing

00:13:47,329 --> 00:13:54,170
that so actually I really don't

00:13:50,630 --> 00:13:57,860
understand why this is the case but when

00:13:54,170 --> 00:14:00,589
OVS calls the CT action it actually

00:13:57,860 --> 00:14:02,360
Forks it creates a copy of the packet

00:14:00,589 --> 00:14:06,560
and reruns it through the rules engine

00:14:02,360 --> 00:14:08,240
completely and and it has some other

00:14:06,560 --> 00:14:10,720
side effects as well for instance on the

00:14:08,240 --> 00:14:15,800
current action chain after the CT action

00:14:10,720 --> 00:14:18,290
the sk buff has its CT information

00:14:15,800 --> 00:14:20,600
cleared the action chain is completed

00:14:18,290 --> 00:14:24,950
and then the CT information is like

00:14:20,600 --> 00:14:28,459
Reata and it's processed so it's there's

00:14:24,950 --> 00:14:32,750
a strange design there and i don't know

00:14:28,459 --> 00:14:34,670
why it is that way but that's something

00:14:32,750 --> 00:14:38,540
that we would need to be able to have

00:14:34,670 --> 00:14:44,740
OVS offload correctly and i don't know

00:14:38,540 --> 00:14:47,180
why it is that way and then the final is

00:14:44,740 --> 00:14:54,050
offloading hooks but you added that and

00:14:47,180 --> 00:14:57,320
i don't know what that means hooks would

00:14:54,050 --> 00:14:59,630
be the contract integration so that the

00:14:57,320 --> 00:15:05,230
entries can be actually offloaded to a

00:14:59,630 --> 00:15:08,930
card and that's like one feet in a half

00:15:05,230 --> 00:15:11,540
inside offloading already but that would

00:15:08,930 --> 00:15:14,170
be needed and interior should an

00:15:11,540 --> 00:15:16,860
interview with CT action and the flower

00:15:14,170 --> 00:15:23,340
classifier it

00:15:16,860 --> 00:15:26,340
good you have keeping an eye on it okay

00:15:23,340 --> 00:15:31,440
so now the second part is like a little

00:15:26,340 --> 00:15:35,700
bit more radical and this is something

00:15:31,440 --> 00:15:38,460
I've been looking at in parallel along

00:15:35,700 --> 00:15:41,240
with Marcelo which is actually

00:15:38,460 --> 00:15:46,460
integrating the connection tracker with

00:15:41,240 --> 00:15:50,550
kind of EBP f4x DP and enabling like

00:15:46,460 --> 00:15:55,800
lookups or you know kind of informing

00:15:50,550 --> 00:15:58,110
the the Express data path about these

00:15:55,800 --> 00:16:00,090
connection tracking entries and so you

00:15:58,110 --> 00:16:01,710
could kind of use it as like you know vs

00:16:00,090 --> 00:16:03,480
they have an exact match cache you could

00:16:01,710 --> 00:16:05,490
you could use it as like an exact tupple

00:16:03,480 --> 00:16:10,320
match that you could do you could make

00:16:05,490 --> 00:16:12,810
forwarding decisions on and yeah the

00:16:10,320 --> 00:16:15,600
approach I took initially was to add

00:16:12,810 --> 00:16:20,370
like this flow map but that got enact

00:16:15,600 --> 00:16:21,870
pretty quickly I was told or rather the

00:16:20,370 --> 00:16:24,510
response was it was a little too

00:16:21,870 --> 00:16:27,150
specialized and they wanted something

00:16:24,510 --> 00:16:32,850
more generic I don't quite know what

00:16:27,150 --> 00:16:34,590
that means but but I I took that into

00:16:32,850 --> 00:16:36,000
consideration and and the approaches I'm

00:16:34,590 --> 00:16:39,290
looking at now are either adding

00:16:36,000 --> 00:16:42,120
performance into the net filter area or

00:16:39,290 --> 00:16:43,850
like using the flow table offload

00:16:42,120 --> 00:16:47,790
infrastructure and being able to attach

00:16:43,850 --> 00:16:50,130
vpf program there and then a user could

00:16:47,790 --> 00:16:53,430
just like register for like either

00:16:50,130 --> 00:16:56,820
register for a perfect or attach of BPF

00:16:53,430 --> 00:16:58,800
program you know get get these events as

00:16:56,820 --> 00:17:03,210
they come along and populate their own

00:16:58,800 --> 00:17:04,230
maps and push it that way I still

00:17:03,210 --> 00:17:06,150
haven't figured out the best way of

00:17:04,230 --> 00:17:09,030
doing like any of this metadata sharing

00:17:06,150 --> 00:17:11,430
so like the protocol information like

00:17:09,030 --> 00:17:14,490
window offsets and that kind of stuff

00:17:11,430 --> 00:17:16,890
that the core stack needs one of the

00:17:14,490 --> 00:17:19,650
challenges with like offloading

00:17:16,890 --> 00:17:21,480
connections this way is if there's an

00:17:19,650 --> 00:17:24,900
exception and a packet does have to go

00:17:21,480 --> 00:17:26,640
back through the host the host doesn't

00:17:24,900 --> 00:17:27,270
have any more accurate information about

00:17:26,640 --> 00:17:29,010
it it's

00:17:27,270 --> 00:17:31,770
it's been kind of offloaded the hope the

00:17:29,010 --> 00:17:33,270
husband bypassed and so we need to

00:17:31,770 --> 00:17:35,520
figure out a way to kind of like share

00:17:33,270 --> 00:17:38,640
that metadata and that's not actually

00:17:35,520 --> 00:17:47,220
exclusive to this approach it's also in

00:17:38,640 --> 00:17:52,880
the in the TC path as well but and and

00:17:47,220 --> 00:17:52,880
that's actually it for the presentation

00:17:53,900 --> 00:17:58,890
we would like to know if what do you

00:17:57,180 --> 00:18:02,310
think about integrating contract on

00:17:58,890 --> 00:18:03,900
other subsystems like PPI for TC we have

00:18:02,310 --> 00:18:07,650
some of the metal box guys that brownie

00:18:03,900 --> 00:18:13,200
in Roy's Ronnie you would take a nap or

00:18:07,650 --> 00:18:15,470
something I'm hard to speak what I am

00:18:13,200 --> 00:18:15,470
here

00:18:19,670 --> 00:18:26,160
so I said they mention we do working

00:18:22,890 --> 00:18:28,560
with it and think I presented it I think

00:18:26,160 --> 00:18:30,540
it's all it's wasn't not only the last

00:18:28,560 --> 00:18:34,710
night ever think it was another one

00:18:30,540 --> 00:18:39,210
before but it's it's take time to do

00:18:34,710 --> 00:18:42,170
that it's it's a complicated task I hope

00:18:39,210 --> 00:18:44,910
that's we will have it shortly

00:18:42,170 --> 00:18:54,390
I'm not running writing the code so it's

00:18:44,910 --> 00:18:56,340
I can't help it make it fast and there

00:18:54,390 --> 00:18:58,110
are challenges in TC and the

00:18:56,340 --> 00:19:02,520
relationship with connective contract

00:18:58,110 --> 00:19:05,040
that's whittling in to resolve and we

00:19:02,520 --> 00:19:07,160
believe that's it we have all our

00:19:05,040 --> 00:19:09,980
customer that's using obvious that's

00:19:07,160 --> 00:19:12,120
using and especially not because

00:19:09,980 --> 00:19:17,070
connection tracking by itself you can

00:19:12,120 --> 00:19:19,680
disable and and spare it but for forever

00:19:17,070 --> 00:19:22,860
for example all the kubernetes and all

00:19:19,680 --> 00:19:26,490
the time that's needed a service says so

00:19:22,860 --> 00:19:28,560
you need actually using not for for

00:19:26,490 --> 00:19:34,850
floating IP so there is a requirement

00:19:28,560 --> 00:19:34,850
that's we need we need to support

00:19:47,359 --> 00:19:53,299
can you share a little bit about the

00:19:49,700 --> 00:19:57,440
details of the EPP f integration that

00:19:53,299 --> 00:19:59,690
you tried because there are other let's

00:19:57,440 --> 00:20:01,519
say other use cases for accessing

00:19:59,690 --> 00:20:03,799
contract information from BPF that are

00:20:01,519 --> 00:20:05,989
not related specifically to hardware

00:20:03,799 --> 00:20:08,629
offload like for example being able to

00:20:05,989 --> 00:20:10,879
get information like this from an XD BBF

00:20:08,629 --> 00:20:13,549
program if that were available so if you

00:20:10,879 --> 00:20:16,159
could share some details on the approach

00:20:13,549 --> 00:20:18,950
that you actually tried yeah sure so

00:20:16,159 --> 00:20:21,769
it's on the mailing list I posted it

00:20:18,950 --> 00:20:26,450
back in November but the basic idea was

00:20:21,769 --> 00:20:28,669
to extend the BPF sub system to allow

00:20:26,450 --> 00:20:31,099
like some loadable modules support that

00:20:28,669 --> 00:20:33,919
was like kind of the I just kind of made

00:20:31,099 --> 00:20:36,499
a quick shunt so that we had a map that

00:20:33,919 --> 00:20:39,739
you could load when you loaded that map

00:20:36,499 --> 00:20:42,320
and made requests to the map for

00:20:39,739 --> 00:20:44,589
specific key like which would be like a

00:20:42,320 --> 00:20:47,269
connection tupple it would go to

00:20:44,589 --> 00:20:50,690
contract it would go to this flow table

00:20:47,269 --> 00:20:53,659
that was set up and used the the NFT

00:20:50,690 --> 00:20:56,029
flow offload infrastructure or the the

00:20:53,659 --> 00:20:59,799
flow table infrastructure and kind of

00:20:56,029 --> 00:21:03,349
pull out the tupple information and the

00:20:59,799 --> 00:21:05,739
connection information so it wasn't from

00:21:03,349 --> 00:21:10,330
from contract itself it was from the

00:21:05,739 --> 00:21:10,330
floor it was from the flow table yeah

00:21:17,200 --> 00:21:26,810
any questions this side so when you're

00:21:24,140 --> 00:21:29,390
trying to offload right is the plant to

00:21:26,810 --> 00:21:34,550
offload the rule after the connection is

00:21:29,390 --> 00:21:36,470
established okay so that means the

00:21:34,550 --> 00:21:42,050
software is going to maintain the state

00:21:36,470 --> 00:21:45,260
the hardware is only offloaded after the

00:21:42,050 --> 00:21:47,480
connection so it may be there may be a

00:21:45,260 --> 00:21:49,120
delay in adding the rule right so the

00:21:47,480 --> 00:21:52,340
packets may come into the slow path

00:21:49,120 --> 00:21:55,490
before the rule is actually added so

00:21:52,340 --> 00:21:59,050
those type of issues need to be this may

00:21:55,490 --> 00:22:01,580
cost out of order packets like this yes

00:21:59,050 --> 00:22:03,170
yes it would be you'd get out of order

00:22:01,580 --> 00:22:08,240
packets and then again like I said

00:22:03,170 --> 00:22:09,590
because because the packets are being

00:22:08,240 --> 00:22:13,700
actually processed all by the hardware

00:22:09,590 --> 00:22:16,040
you lose the the metadata that contract

00:22:13,700 --> 00:22:18,770
actually cares about you know or needs

00:22:16,040 --> 00:22:20,600
to make decisions when you have to take

00:22:18,770 --> 00:22:22,340
an exception so for instance of some

00:22:20,600 --> 00:22:24,260
packet you know needs to follow that

00:22:22,340 --> 00:22:26,960
exceptional path and and go back into

00:22:24,260 --> 00:22:28,610
software it may have invalid like window

00:22:26,960 --> 00:22:37,450
number even window information or

00:22:28,610 --> 00:22:39,310
something else so is anybody else oh

00:22:37,450 --> 00:22:42,040
okay

00:22:39,310 --> 00:22:44,830
so I will just explain a little bit what

00:22:42,040 --> 00:22:48,880
we're thinking about doing so as you

00:22:44,830 --> 00:22:51,030
mentioned we we don't want to mask at

00:22:48,880 --> 00:22:54,160
least from the beginning with the

00:22:51,030 --> 00:22:58,030
creation of the CD of or for any other

00:22:54,160 --> 00:23:00,490
protocol so we let the software decided

00:22:58,030 --> 00:23:02,470
where it's established and one only to

00:23:00,490 --> 00:23:08,040
establish a valid only to offload

00:23:02,470 --> 00:23:12,010
establish connections for for TCP

00:23:08,040 --> 00:23:15,070
blaming also to have in the harder

00:23:12,010 --> 00:23:17,500
window validation so then we'll can

00:23:15,070 --> 00:23:20,680
offload also the window validation but

00:23:17,500 --> 00:23:22,060
also there there was the problem what

00:23:20,680 --> 00:23:23,830
you do if you have something that's the

00:23:22,060 --> 00:23:26,200
harder can't process and you want to

00:23:23,830 --> 00:23:28,300
take it back to the software we need to

00:23:26,200 --> 00:23:30,280
update the connection tracking the

00:23:28,300 --> 00:23:33,130
software connection tracking with the

00:23:30,280 --> 00:23:35,980
latest window validation information so

00:23:33,130 --> 00:23:37,810
these are things that we will also will

00:23:35,980 --> 00:23:40,000
need to solve what I think right now we

00:23:37,810 --> 00:23:42,970
want to to have the first version that's

00:23:40,000 --> 00:23:46,150
we start off loaded well when the

00:23:42,970 --> 00:23:48,730
connection is established and only to

00:23:46,150 --> 00:23:51,370
let this pocket for with every set and

00:23:48,730 --> 00:23:54,000
faint go back to the software in order

00:23:51,370 --> 00:23:59,820
to to terminate the TCP connection and

00:23:54,000 --> 00:23:59,820
of course to have counters to do aging

00:24:02,070 --> 00:24:09,760
to have an option to clean of course the

00:24:04,300 --> 00:24:12,100
table that's its want so how many how

00:24:09,760 --> 00:24:14,520
many flows can you offload then because

00:24:12,100 --> 00:24:17,980
you got a lot of state going on there

00:24:14,520 --> 00:24:20,200
yes so I think we already support more

00:24:17,980 --> 00:24:22,990
than million rules a few minutes I know

00:24:20,200 --> 00:24:26,740
that's your magic number Oni solos so

00:24:22,990 --> 00:24:29,110
also for of course a rules can be a five

00:24:26,740 --> 00:24:30,580
double match so it's a connection no but

00:24:29,110 --> 00:24:32,800
yeah but in this case you're keeping

00:24:30,580 --> 00:24:36,100
track of TCP windows and everything that

00:24:32,800 --> 00:24:41,590
flies by right we're having the same

00:24:36,100 --> 00:24:44,890
rough of number millions okay any

00:24:41,590 --> 00:24:47,460
someone else has a question behind you

00:24:44,890 --> 00:24:47,460
beside me

00:24:49,840 --> 00:24:56,050
in all the pictures and what we were

00:24:52,690 --> 00:24:58,930
talking about the connections always

00:24:56,050 --> 00:25:01,720
where from outside to some VM or

00:24:58,930 --> 00:25:05,140
something inside is there any chance

00:25:01,720 --> 00:25:07,390
that this could work somehow in case of

00:25:05,140 --> 00:25:11,070
classical gateway where the packets come

00:25:07,390 --> 00:25:12,820
to a different device from each side

00:25:11,070 --> 00:25:16,150
yeah yeah definitely

00:25:12,820 --> 00:25:19,929
yes so it would be usable in that case

00:25:16,150 --> 00:25:21,790
for sure and that's I think one well

00:25:19,929 --> 00:25:23,620
like I don't know what small hardware

00:25:21,790 --> 00:25:26,080
does as far as like the ability to

00:25:23,620 --> 00:25:29,170
provide offloads or anything but it

00:25:26,080 --> 00:25:32,020
certainly could be used by like some

00:25:29,170 --> 00:25:33,820
small gateway device yeah the problem is

00:25:32,020 --> 00:25:36,340
that when the packet in the opposite

00:25:33,820 --> 00:25:39,610
direction comes you don't really know

00:25:36,340 --> 00:25:44,700
where to look for where where was the

00:25:39,610 --> 00:25:49,559
connection established at that moment

00:25:44,700 --> 00:25:53,950
what do you mean well if you establish

00:25:49,559 --> 00:25:57,610
connection or entry contract entry when

00:25:53,950 --> 00:26:00,220
a connection is created for say simple

00:25:57,610 --> 00:26:02,230
cut in one direction then when packets

00:26:00,220 --> 00:26:05,440
in the opposite direction come that at

00:26:02,230 --> 00:26:09,040
the time they arrive at some other

00:26:05,440 --> 00:26:11,260
device you don't know what was the first

00:26:09,040 --> 00:26:13,890
device but contra country was

00:26:11,260 --> 00:26:13,890
established

00:26:15,510 --> 00:26:22,840
I'd have to like see it drawn out I I

00:26:18,910 --> 00:26:24,610
don't know why don't you take that off

00:26:22,840 --> 00:26:28,170
for later yes so we can take it offline

00:26:24,610 --> 00:26:31,600
maybe but a connection tracking is not

00:26:28,170 --> 00:26:32,920
only working by itself so for example

00:26:31,600 --> 00:26:36,580
we're talking about connection tracking

00:26:32,920 --> 00:26:39,010
that is inside open race which or here

00:26:36,580 --> 00:26:41,470
it's will be offloaded to TC so there is

00:26:39,010 --> 00:26:44,170
a pipeline the connection tracking is

00:26:41,470 --> 00:26:47,230
not as something that is standing alone

00:26:44,170 --> 00:26:50,830
it's heavy some inputs the packet is

00:26:47,230 --> 00:26:53,890
coming from a vehicle with rules from of

00:26:50,830 --> 00:26:56,140
year so from TC that's suspense affine

00:26:53,890 --> 00:26:58,300
if it's come from this port go to the

00:26:56,140 --> 00:26:59,950
con track and continue to another port

00:26:58,300 --> 00:27:02,800
so those kind of

00:26:59,950 --> 00:27:06,760
are done not in the contract itself it

00:27:02,800 --> 00:27:10,270
coming from the rules that's table

00:27:06,760 --> 00:27:13,390
before table after so that's how it's

00:27:10,270 --> 00:27:17,290
going to be used with obvious but I

00:27:13,390 --> 00:27:21,400
think two days ago a Pablo mentioned

00:27:17,290 --> 00:27:23,860
that there is an also IP IP table a

00:27:21,400 --> 00:27:28,720
caching that's doing approximately the

00:27:23,860 --> 00:27:31,390
same and there is also keeping a kind of

00:27:28,720 --> 00:27:34,330
a harder table that's handle their

00:27:31,390 --> 00:27:36,490
incoming port in the outcoming port and

00:27:34,330 --> 00:27:39,010
so maybe this is also something that can

00:27:36,490 --> 00:27:40,570
be used okay can you take this fat like

00:27:39,010 --> 00:27:45,370
for later if we guys don't mind

00:27:40,570 --> 00:27:48,930
so give chance to other people sure yes

00:27:45,370 --> 00:27:51,790
so my remark is basically we should

00:27:48,930 --> 00:27:53,950
consider the edge cases where does my

00:27:51,790 --> 00:27:56,230
conflict was the existing stack behavior

00:27:53,950 --> 00:27:58,930
because if you have TC rules that

00:27:56,230 --> 00:28:00,490
perform City actions then it changes

00:27:58,930 --> 00:28:02,590
from from net fittest point of view it

00:28:00,490 --> 00:28:05,020
changes behavior because now if a packet

00:28:02,590 --> 00:28:06,250
comes up into a stack and for instance

00:28:05,020 --> 00:28:08,350
to the raw table

00:28:06,250 --> 00:28:09,610
it will now see that there is a contract

00:28:08,350 --> 00:28:11,490
attached to the packet which will

00:28:09,610 --> 00:28:15,490
currently only ever happen for loopback

00:28:11,490 --> 00:28:19,560
traffic so we should be careful to not

00:28:15,490 --> 00:28:21,400
add anything that breaks existing

00:28:19,560 --> 00:28:22,960
assumptions in the stack and if

00:28:21,400 --> 00:28:25,360
necessary we might have to consider

00:28:22,960 --> 00:28:27,970
adding additional tracking information

00:28:25,360 --> 00:28:30,700
to the to the entry if if this was

00:28:27,970 --> 00:28:33,610
created by the contract action or by the

00:28:30,700 --> 00:28:35,530
net filter stack itself if that comes to

00:28:33,610 --> 00:28:37,570
past and I think we can probably do it

00:28:35,530 --> 00:28:41,880
so I don't see any fundamental reasons

00:28:37,570 --> 00:28:41,880
why we can't do this integration work

00:28:43,970 --> 00:28:51,559
anybody else so I have a question so one

00:28:49,820 --> 00:28:53,269
of you I think I may be imagining this

00:28:51,559 --> 00:28:58,070
but I think you said that you had a

00:28:53,269 --> 00:29:00,230
problem with TC not being able to to do

00:28:58,070 --> 00:29:02,600
to defy drop to later on because

00:29:00,230 --> 00:29:04,549
somebody may and drop in a pipeline or

00:29:02,600 --> 00:29:08,389
did you say something it's not of your

00:29:04,549 --> 00:29:11,299
slides I think we're open I think of es

00:29:08,389 --> 00:29:13,779
has this rule which seems to be built

00:29:11,299 --> 00:29:17,240
based on hardware pipeline point of view

00:29:13,779 --> 00:29:19,570
so pocket kami when we say drop later on

00:29:17,240 --> 00:29:23,320
you can decide that you want to under op

00:29:19,570 --> 00:29:25,000
okay maybe I'm just too much all right

00:29:23,320 --> 00:29:32,660
one more question

00:29:25,000 --> 00:29:36,829
anybody know well thank you

00:29:32,660 --> 00:29:36,829

YouTube URL: https://www.youtube.com/watch?v=WNzFBEnmH1k


