Title: Netdev 0x13 - XDP based DDoS Mitigation
Publication date: 2019-05-26
Playlist: Netdev 0x13 - Day 3
Description: 
	In this talk, Arthur Fabre describes the implementation of the Cloudflare XDP solution.
Perf-based packet sampling is used to detect an attack. The followup mitigation subsystem
automatically generates eBPF code in response to attacks.

https://netdevconf.org/0x13/session.html?talk-XDP-based-DDoS-mitigation
Captions: 
	00:00:00,060 --> 00:00:03,480
hi everyone my name is Arthur I'm a

00:00:01,560 --> 00:00:04,859
systems engineer at cobbler and I'm here

00:00:03,480 --> 00:00:06,779
to tell you about how we migrated our

00:00:04,859 --> 00:00:10,500
das mitigation systems of denial service

00:00:06,779 --> 00:00:12,900
attack mitigation system to xdp so a bit

00:00:10,500 --> 00:00:14,460
about us we are kind of a big content

00:00:12,900 --> 00:00:17,340
delivery network so we serve lots of cat

00:00:14,460 --> 00:00:19,080
pictures we have about 170 points of

00:00:17,340 --> 00:00:21,779
presence among the world where we serve

00:00:19,080 --> 00:00:23,760
the cat pictures and we do about 10

00:00:21,779 --> 00:00:25,380
million HTTP requests per second so we

00:00:23,760 --> 00:00:27,210
end up seeing a lot of traffic and a lot

00:00:25,380 --> 00:00:29,849
of malicious traffic and a lot of denial

00:00:27,210 --> 00:00:31,679
service states and we've have we've had

00:00:29,849 --> 00:00:32,930
our new xdv base solution in production

00:00:31,679 --> 00:00:35,370
for about six months now

00:00:32,930 --> 00:00:38,149
so a bit about what is a denial service

00:00:35,370 --> 00:00:40,350
attack and what we see on our end so

00:00:38,149 --> 00:00:42,260
it's pretty much a constant occurrence

00:00:40,350 --> 00:00:44,670
to just a part of doing business for us

00:00:42,260 --> 00:00:45,930
we are under denial of service attacks

00:00:44,670 --> 00:00:47,520
and distributed now service attacks

00:00:45,930 --> 00:00:49,559
every day all the time there's always

00:00:47,520 --> 00:00:51,000
attacks somewhere for the purpose of

00:00:49,559 --> 00:00:53,460
this talk we're mostly going to focus on

00:00:51,000 --> 00:00:55,020
layer for denial service attacks because

00:00:53,460 --> 00:00:56,640
that's kind of what I do it and we're

00:00:55,020 --> 00:00:59,730
gonna forget about l7 because those are

00:00:56,640 --> 00:01:01,620
much more complicated so the two major

00:00:59,730 --> 00:01:03,600
kinds of attacks we see overlay or four

00:01:01,620 --> 00:01:05,519
are kind of TCP flood attacks where we

00:01:03,600 --> 00:01:07,409
just get big floods of sin Iraq packets

00:01:05,519 --> 00:01:09,900
usually with a kind of a source a

00:01:07,409 --> 00:01:11,430
spoofed source dress or UDP

00:01:09,900 --> 00:01:13,260
amplification attacks and those are

00:01:11,430 --> 00:01:14,369
mainly either DNS or memcache which you

00:01:13,260 --> 00:01:18,030
saw about a year ago and there was that

00:01:14,369 --> 00:01:19,680
big bug one notable point is that we use

00:01:18,030 --> 00:01:21,509
anycast everywhere so all of our data

00:01:19,680 --> 00:01:24,060
centers advertise the exact same IP

00:01:21,509 --> 00:01:25,470
ranges everywhere so distributed denial

00:01:24,060 --> 00:01:27,240
service attacks tend to hit us in a very

00:01:25,470 --> 00:01:28,430
distributed way we tend to see the

00:01:27,240 --> 00:01:31,170
attacks in most of our data centers

00:01:28,430 --> 00:01:32,340
everywhere it's rare that we get attacks

00:01:31,170 --> 00:01:35,310
that single out kind of a single

00:01:32,340 --> 00:01:36,900
location and so these are two examples

00:01:35,310 --> 00:01:38,729
of what we see on our end so this is

00:01:36,900 --> 00:01:40,619
kind of a global view inside cloud fair

00:01:38,729 --> 00:01:41,579
of what traffic we're seeing when we get

00:01:40,619 --> 00:01:44,070
attacks as you can see it's pretty

00:01:41,579 --> 00:01:46,049
obvious they're hard to miss which makes

00:01:44,070 --> 00:01:48,780
our life easy which is good so the top

00:01:46,049 --> 00:01:50,399
is what happened when the memcached UDP

00:01:48,780 --> 00:01:52,979
application attacks a it so we get got

00:01:50,399 --> 00:01:55,649
about 800 megabits per second of kind of

00:01:52,979 --> 00:01:56,880
a junky traffic and at this point normal

00:01:55,649 --> 00:01:59,670
traffic levels are pretty much just

00:01:56,880 --> 00:02:00,840
noise in the graph and we can see the

00:01:59,670 --> 00:02:03,810
same thing on the bottom here we have a

00:02:00,840 --> 00:02:05,549
TCP syn flood that hit hit us then it

00:02:03,810 --> 00:02:07,680
got up to about 300 million packets per

00:02:05,549 --> 00:02:10,229
second and once again normal traffic is

00:02:07,680 --> 00:02:11,610
just noise at this point which makes our

00:02:10,229 --> 00:02:12,599
life easy because at least we can detect

00:02:11,610 --> 00:02:15,629
the attacks

00:02:12,599 --> 00:02:18,269
and so our mitigation pipeline is kind

00:02:15,629 --> 00:02:20,069
of three major steps so packets come in

00:02:18,269 --> 00:02:23,489
they hit an edge server and that's over

00:02:20,069 --> 00:02:25,139
any cast and then we send a sample so

00:02:23,489 --> 00:02:26,189
can we sample incoming packets and send

00:02:25,139 --> 00:02:28,499
a small fraction of these to a

00:02:26,189 --> 00:02:29,639
centralized system called kapok okay but

00:02:28,499 --> 00:02:31,739
aggregates all the traffic it's

00:02:29,639 --> 00:02:33,840
receiving and does metric to figure out

00:02:31,739 --> 00:02:35,969
which traffic is malicious or traffic is

00:02:33,840 --> 00:02:38,639
it an all service attack from that we

00:02:35,969 --> 00:02:40,650
put out rules which describe which

00:02:38,639 --> 00:02:43,530
packets are incoming denial service

00:02:40,650 --> 00:02:45,629
attack packets and push these out to

00:02:43,530 --> 00:02:47,010
back to the edge now it's important note

00:02:45,629 --> 00:02:49,620
here that we need to sample packets

00:02:47,010 --> 00:02:50,939
before we drop them because we want to

00:02:49,620 --> 00:02:52,139
keep the feedback loop going even when

00:02:50,939 --> 00:02:54,930
we're dropping packets to know if the

00:02:52,139 --> 00:02:57,629
attack is still ongoing or not that's

00:02:54,930 --> 00:02:59,040
pretty much it so rules so we tend to

00:02:57,629 --> 00:03:00,750
have one person ature attack sometimes

00:02:59,040 --> 00:03:03,389
attack have attacks have multiple

00:03:00,750 --> 00:03:04,620
signatures so there can be hundreds of

00:03:03,389 --> 00:03:06,359
rules at the same time and they all need

00:03:04,620 --> 00:03:07,799
to match and so we only let a packet

00:03:06,359 --> 00:03:08,959
through if it matches none of the rules

00:03:07,799 --> 00:03:13,019
we have deployed right now

00:03:08,959 --> 00:03:15,449
and so our rules have to kind of key

00:03:13,019 --> 00:03:17,430
parts to them we have a classic vpf

00:03:15,449 --> 00:03:20,159
filter so no not extended BPF classic

00:03:17,430 --> 00:03:22,019
vpf and traditional is that it's very

00:03:20,159 --> 00:03:24,900
flexible this lets us match on any part

00:03:22,019 --> 00:03:25,859
of the packet and see if you have is

00:03:24,900 --> 00:03:28,019
great for this that's all let's you do

00:03:25,859 --> 00:03:29,639
let you match packets there are lots of

00:03:28,019 --> 00:03:31,439
tools to generate CPF so we have our own

00:03:29,639 --> 00:03:33,329
BPF tools products on github and that

00:03:31,439 --> 00:03:36,269
lets us generate CPF matching DNS

00:03:33,329 --> 00:03:38,579
queries so we can say any any DNS query

00:03:36,269 --> 00:03:41,430
matching you know foo.example.com should

00:03:38,579 --> 00:03:44,040
match from puff-puff is kind of a small

00:03:41,430 --> 00:03:45,709
DSL for describing IP and TCP header

00:03:44,040 --> 00:03:48,060
options and what order they're coming

00:03:45,709 --> 00:03:49,530
because usually attackers are kind of

00:03:48,060 --> 00:03:50,939
dumb and they redo the same software and

00:03:49,530 --> 00:03:54,150
some of the header bits are the same or

00:03:50,939 --> 00:03:55,680
whatever and lead pica for TCP dump also

00:03:54,150 --> 00:03:57,180
generates classic BPF which lets us

00:03:55,680 --> 00:03:59,159
generate even more filters for our parts

00:03:57,180 --> 00:03:59,489
and we can run them in lots of places as

00:03:59,159 --> 00:04:00,810
well

00:03:59,489 --> 00:04:02,310
so you can run them in the kernel with

00:04:00,810 --> 00:04:05,040
Esso attach filter you can run em in AK

00:04:02,310 --> 00:04:06,659
IP tables with HT v PF and we can also

00:04:05,040 --> 00:04:10,319
run in user space lots of languages have

00:04:06,659 --> 00:04:11,609
interpreters or VMs for CPF second part

00:04:10,319 --> 00:04:13,289
of our rule is the Torquay datacenters

00:04:11,609 --> 00:04:15,180
so I know I said that most of our texts

00:04:13,289 --> 00:04:16,949
are distributed all over the world but

00:04:15,180 --> 00:04:18,150
sometimes we do get attacks that focus

00:04:16,949 --> 00:04:20,549
on one data center so we want the

00:04:18,150 --> 00:04:24,419
ability to scope rules to specific data

00:04:20,549 --> 00:04:25,800
centers in some cases and so now on xdp

00:04:24,419 --> 00:04:26,130
so I'm sure most of you have heard what

00:04:25,800 --> 00:04:27,570
actually

00:04:26,130 --> 00:04:31,320
before but we'll do a quick little recap

00:04:27,570 --> 00:04:33,330
so XDP uses EVP f which is extended EP f

00:04:31,320 --> 00:04:34,890
and one of the main things that we use

00:04:33,330 --> 00:04:36,570
for that is helper functions so we can

00:04:34,890 --> 00:04:37,980
call them the kernel from BP F to have

00:04:36,570 --> 00:04:39,990
the kernel do some bits for us

00:04:37,980 --> 00:04:41,610
and the main one we use is tail calling

00:04:39,990 --> 00:04:43,260
which lets us chain EVP F programs

00:04:41,610 --> 00:04:44,550
together so we can have one EVP F

00:04:43,260 --> 00:04:46,050
program that decides okay I'm done

00:04:44,550 --> 00:04:50,100
pressing this packet on to the next EVP

00:04:46,050 --> 00:04:51,780
F program and we also have of the kernel

00:04:50,100 --> 00:04:53,310
verifier which checks that our EVP F

00:04:51,780 --> 00:04:54,690
program is correct does not do out of

00:04:53,310 --> 00:04:57,030
balance packet accesses does not read

00:04:54,690 --> 00:04:58,740
random kernel memory and this is great

00:04:57,030 --> 00:05:00,270
but it comes with lots of limits so the

00:04:58,740 --> 00:05:01,980
very far imposes strict complexity

00:05:00,270 --> 00:05:03,960
limits on the actual EBP F code we get

00:05:01,980 --> 00:05:06,000
to run so we're limited to 4,000

00:05:03,960 --> 00:05:08,670
instructions right now and you can only

00:05:06,000 --> 00:05:10,440
do 32 tail calls in one go there are

00:05:08,670 --> 00:05:12,260
also limits to your stack usage how many

00:05:10,440 --> 00:05:14,360
branches you can have at the same time

00:05:12,260 --> 00:05:16,560
these are all things to keep in mind a

00:05:14,360 --> 00:05:18,600
next EP is really just a mechanism to

00:05:16,560 --> 00:05:20,880
attach a single EVP F program to an

00:05:18,600 --> 00:05:22,680
interface and the program and the chain

00:05:20,880 --> 00:05:24,540
of programs it changed calls tail calls

00:05:22,680 --> 00:05:26,580
into runs for every packet we receive

00:05:24,540 --> 00:05:27,780
and the two actions we care about is we

00:05:26,580 --> 00:05:29,040
can either pass it and then it reaches

00:05:27,780 --> 00:05:30,690
the normal it's networking stack or we

00:05:29,040 --> 00:05:33,210
can drop it and it just disappears which

00:05:30,690 --> 00:05:34,410
is great so if we remember this is kind

00:05:33,210 --> 00:05:35,580
of what our mitigation pipeline looks

00:05:34,410 --> 00:05:37,170
like and at first glance it seems like

00:05:35,580 --> 00:05:39,300
we want to do all the dropping next EP

00:05:37,170 --> 00:05:41,100
seems perfect we can have a rule xdp

00:05:39,300 --> 00:05:42,360
drop everything's great now the one

00:05:41,100 --> 00:05:43,680
thing number is we need to sample before

00:05:42,360 --> 00:05:45,240
we drop so kind of a requirement of

00:05:43,680 --> 00:05:47,930
dropping packets and HTTPS that we need

00:05:45,240 --> 00:05:49,950
be able to sample them in XDP as well

00:05:47,930 --> 00:05:51,420
and so this is kind of what we could

00:05:49,950 --> 00:05:53,400
imagine it would look like so I've drawn

00:05:51,420 --> 00:05:55,020
little dots over the XTP parts so we

00:05:53,400 --> 00:05:56,880
could have a sample or program that

00:05:55,020 --> 00:05:58,590
would somehow sample packets send them

00:05:56,880 --> 00:05:59,550
off to kpop and then we would tell call

00:05:58,590 --> 00:06:01,230
in to our dropping off which would

00:05:59,550 --> 00:06:03,590
either pass it on up the stack or drop

00:06:01,230 --> 00:06:07,260
the packet seems simple enough

00:06:03,590 --> 00:06:09,720
so first the sampling so we need to tail

00:06:07,260 --> 00:06:11,550
call into the next potential rule

00:06:09,720 --> 00:06:13,380
dropping program which means me to

00:06:11,550 --> 00:06:15,150
somehow copy the packets out we need

00:06:13,380 --> 00:06:17,370
some kind of a side channel to submit

00:06:15,150 --> 00:06:20,670
our sample packets outside of the whole

00:06:17,370 --> 00:06:22,200
HTTP program chain thankfully we need a

00:06:20,670 --> 00:06:24,900
really low separate as we saw in the

00:06:22,200 --> 00:06:28,560
graphs attacks tend to be really big so

00:06:24,900 --> 00:06:30,780
even tiny sample rates serve as well it

00:06:28,560 --> 00:06:33,030
turns out there is an a kernel BPF

00:06:30,780 --> 00:06:34,530
hopper called perf then output which

00:06:33,030 --> 00:06:35,940
lets you put whatever you want in a kind

00:06:34,530 --> 00:06:37,740
of a perfe bent and we can put turns out

00:06:35,940 --> 00:06:39,349
you can put the whole packet as well so

00:06:37,740 --> 00:06:40,729
we can put the whole packet in a perfect

00:06:39,349 --> 00:06:42,529
which adds up in a perforin buffer and

00:06:40,729 --> 00:06:44,719
then we can read that from you space and

00:06:42,529 --> 00:06:46,039
that is a nice property of degrading

00:06:44,719 --> 00:06:47,300
gracefully as well purpose kind of meant

00:06:46,039 --> 00:06:49,009
to be a lossy thing where if you put too

00:06:47,300 --> 00:06:50,360
many events they'll just get lost along

00:06:49,009 --> 00:06:51,740
the way and for sampling that works

00:06:50,360 --> 00:06:53,389
great as well if we get a huge attack in

00:06:51,740 --> 00:06:56,349
our sample rate you set too high will

00:06:53,389 --> 00:06:59,449
drop the extra samples and well so what

00:06:56,349 --> 00:07:01,729
so sampling done how do we drop things

00:06:59,449 --> 00:07:03,199
though so if remember our rules have two

00:07:01,729 --> 00:07:05,719
main parts that we have got the classic

00:07:03,199 --> 00:07:07,490
vpf filter and that sucks we can't

00:07:05,719 --> 00:07:08,839
really just eval that any DPF there's no

00:07:07,490 --> 00:07:10,669
magic helpers for anything like this

00:07:08,839 --> 00:07:13,129
which kind of means that we need to

00:07:10,669 --> 00:07:14,689
compile our rules in instead of having

00:07:13,129 --> 00:07:16,399
you can imagine we could have one

00:07:14,689 --> 00:07:17,509
generic eb PF program and our rules

00:07:16,399 --> 00:07:19,279
would be stored in a map and we could

00:07:17,509 --> 00:07:21,439
look them up but with the CPF this

00:07:19,279 --> 00:07:23,029
doesn't work and since we have to build

00:07:21,439 --> 00:07:24,619
our rules in then the complexity limits

00:07:23,029 --> 00:07:26,449
start being a challenge because the more

00:07:24,619 --> 00:07:28,399
rules we have the more complex the

00:07:26,449 --> 00:07:29,930
program is and the closer we get to be

00:07:28,399 --> 00:07:32,209
complexity limits imposed to us by the

00:07:29,930 --> 00:07:34,789
kernel we also have this target data

00:07:32,209 --> 00:07:36,349
center thing and compiling EBP F can be

00:07:34,789 --> 00:07:38,089
a bit Fafi you need to generate the code

00:07:36,349 --> 00:07:39,289
then usually compile it with clang and

00:07:38,089 --> 00:07:40,610
we really don't want to do this all

00:07:39,289 --> 00:07:42,080
across our edge on thousands of servers

00:07:40,610 --> 00:07:43,999
at the same time it's error-prone it's

00:07:42,080 --> 00:07:45,680
wasteful so we want to compile one elf

00:07:43,999 --> 00:07:47,449
distributed everywhere in a key value

00:07:45,680 --> 00:07:49,370
store but we still wanna be able to

00:07:47,449 --> 00:07:52,610
specialize the elf or do something to

00:07:49,370 --> 00:07:53,809
restrict what rules are enabled in it so

00:07:52,610 --> 00:07:55,580
if you imagine this is kind of what if

00:07:53,809 --> 00:07:56,749
we our C template looks like when we're

00:07:55,580 --> 00:07:59,120
done during rules so we have kind of our

00:07:56,749 --> 00:08:00,559
main xtp entry point here and it's

00:07:59,120 --> 00:08:02,539
pretty simple if the first rule matches

00:08:00,559 --> 00:08:04,370
drop the packet go on to every rule if

00:08:02,539 --> 00:08:07,459
no rules match then we pass the packet

00:08:04,370 --> 00:08:10,009
must be fine so the first part is

00:08:07,459 --> 00:08:11,419
converting the classic BPF so at first

00:08:10,009 --> 00:08:13,479
you think this is gonna be great

00:08:11,419 --> 00:08:15,919
eb PF was kind of designed to be

00:08:13,479 --> 00:08:17,360
converted to from classic v PF and the

00:08:15,919 --> 00:08:19,369
kernel can do this if USO attached

00:08:17,360 --> 00:08:21,229
filter now and use classic v PF and you

00:08:19,369 --> 00:08:23,180
have an e vp f jip the kernel will

00:08:21,229 --> 00:08:25,189
convert the classic BPF to e vp f for

00:08:23,180 --> 00:08:27,499
you and Jin it but that only works for

00:08:25,189 --> 00:08:29,209
us to attach filter so we kind of have

00:08:27,499 --> 00:08:30,949
to compile or convert this on our own so

00:08:29,209 --> 00:08:33,439
we ended up writing a compiler to

00:08:30,949 --> 00:08:35,240
compile classic BPF to see because then

00:08:33,439 --> 00:08:37,759
ideas that we can embed it in our C

00:08:35,240 --> 00:08:39,800
template and compile it to EBP F with

00:08:37,759 --> 00:08:41,389
clang which is also nice because clang

00:08:39,800 --> 00:08:43,759
can sometimes do some Co optimizations

00:08:41,389 --> 00:08:45,380
between rules and stuff and most of the

00:08:43,759 --> 00:08:47,149
instructions kind of map one to one so a

00:08:45,380 --> 00:08:48,470
loose with all the math operations most

00:08:47,149 --> 00:08:50,329
of the jumps kind of have one-to-one

00:08:48,470 --> 00:08:50,790
direct mapping between classic vpf and

00:08:50,329 --> 00:08:54,480
EBP

00:08:50,790 --> 00:08:55,830
which makes our life much easier so

00:08:54,480 --> 00:08:57,930
here's an example though of instruction

00:08:55,830 --> 00:09:00,030
that really sucks packet loads so in

00:08:57,930 --> 00:09:01,740
classic vpf you can easily check the

00:09:00,030 --> 00:09:03,570
bounds of packets how long the packet is

00:09:01,740 --> 00:09:06,540
so dealing with classic vpf is you just

00:09:03,570 --> 00:09:08,820
write your filter and you say bite for

00:09:06,540 --> 00:09:10,200
needs to match and if the packet is not

00:09:08,820 --> 00:09:11,640
4 bytes long the kernel will just say

00:09:10,200 --> 00:09:12,780
your filter does not match which is fair

00:09:11,640 --> 00:09:16,140
enough you want your packet to be at

00:09:12,780 --> 00:09:17,580
least that much long but the problem of

00:09:16,140 --> 00:09:18,690
that is that that exits your program so

00:09:17,580 --> 00:09:20,520
if you want to combine multiple these

00:09:18,690 --> 00:09:21,900
filters together we can't have the

00:09:20,520 --> 00:09:23,430
filter the first filter that makes an

00:09:21,900 --> 00:09:24,780
out of bound packet access return all of

00:09:23,430 --> 00:09:27,030
our filters we need to run them all all

00:09:24,780 --> 00:09:29,280
the time so for this though thankfully

00:09:27,030 --> 00:09:30,780
EB PF offers much more generic ways of

00:09:29,280 --> 00:09:32,190
loading memories so from UPF you can

00:09:30,780 --> 00:09:34,260
load a pointer dereference it have

00:09:32,190 --> 00:09:36,120
offsets and thankfully HTTP gives us a

00:09:34,260 --> 00:09:37,290
packet pointer we need us use so that's

00:09:36,120 --> 00:09:39,810
great but we need to check the bounds

00:09:37,290 --> 00:09:41,460
everywhere and then end up sucking a bit

00:09:39,810 --> 00:09:43,080
because a single classic vpf instruction

00:09:41,460 --> 00:09:45,270
something like here we're just loading a

00:09:43,080 --> 00:09:47,430
32-bit word from buy 12 of the packet

00:09:45,270 --> 00:09:49,380
ends up being at least 4 instructions in

00:09:47,430 --> 00:09:51,420
EB PF and this doesn't even include the

00:09:49,380 --> 00:09:53,520
end eunice things classic vpf always

00:09:51,420 --> 00:09:55,680
returns packet loads in the native and

00:09:53,520 --> 00:09:57,300
eunice so here we also need to go bytes

00:09:55,680 --> 00:09:59,550
off before a little engine which is most

00:09:57,300 --> 00:10:01,520
of the time and this sucks even more for

00:09:59,550 --> 00:10:03,720
BPF indirect which lets us load kind of

00:10:01,520 --> 00:10:04,860
packets with variable offset so we can

00:10:03,720 --> 00:10:06,660
use another register to calculate the

00:10:04,860 --> 00:10:07,890
offset then we to do much more faffing

00:10:06,660 --> 00:10:10,200
around and that doesn't mean at least 6

00:10:07,890 --> 00:10:11,910
instructions which is a lot especially

00:10:10,200 --> 00:10:14,490
when we have our 4k limit and we want to

00:10:11,910 --> 00:10:15,960
support hundreds of rules everywhere so

00:10:14,490 --> 00:10:16,950
it turns out though that we can do much

00:10:15,960 --> 00:10:19,350
better than this so if we imagine a

00:10:16,950 --> 00:10:22,380
typical classic BPF program it turns out

00:10:19,350 --> 00:10:23,640
that most of them load a byte and so you

00:10:22,380 --> 00:10:25,230
can imagine that there they load bytes

00:10:23,640 --> 00:10:26,760
in increasing order so first they check

00:10:25,230 --> 00:10:28,380
the IP header then they check a UDP

00:10:26,760 --> 00:10:31,290
header and then they check a dns ID or

00:10:28,380 --> 00:10:32,970
something and so most of them check the

00:10:31,290 --> 00:10:34,290
first byte they want to check and then

00:10:32,970 --> 00:10:36,540
either they fall through to the next

00:10:34,290 --> 00:10:38,460
checks or they return no match so in

00:10:36,540 --> 00:10:40,620
most classic vpf programs the only way

00:10:38,460 --> 00:10:42,810
for the packet to match is for every

00:10:40,620 --> 00:10:44,520
single load to happen and so with this

00:10:42,810 --> 00:10:45,660
we can just have a single packet

00:10:44,520 --> 00:10:47,400
balanced check at the start that checks

00:10:45,660 --> 00:10:49,020
for the greatest access and we don't

00:10:47,400 --> 00:10:50,070
actually end up changing the semantics

00:10:49,020 --> 00:10:51,540
of the program we return from a

00:10:50,070 --> 00:10:53,160
different place but will always return

00:10:51,540 --> 00:10:54,510
the same value because the fact it needs

00:10:53,160 --> 00:10:57,120
to be at least that long to match in the

00:10:54,510 --> 00:10:59,220
first place and this ends up being quite

00:10:57,120 --> 00:11:00,840
a saving so here on this graph we've

00:10:59,220 --> 00:11:02,370
compiled some filters so the first two

00:11:00,840 --> 00:11:03,810
are TCP dump stalls filters that we

00:11:02,370 --> 00:11:06,150
generate pcap and the bottom

00:11:03,810 --> 00:11:09,150
is one from our BPF tools project to

00:11:06,150 --> 00:11:11,910
generate classic vpf that matches a DNS

00:11:09,150 --> 00:11:13,529
of query and the first column cdpf shows

00:11:11,910 --> 00:11:16,440
how many classic vpf constructions that

00:11:13,529 --> 00:11:18,210
filter actually is and then cv PFC is

00:11:16,440 --> 00:11:21,270
the name we've given to our classic vpf

00:11:18,210 --> 00:11:22,830
compiler generate c and how many EVP F

00:11:21,270 --> 00:11:25,710
instructions that is that generated

00:11:22,830 --> 00:11:27,690
after a pass to Clank so it's not great

00:11:25,710 --> 00:11:28,950
but it's not terrible and then on the

00:11:27,690 --> 00:11:30,570
third column we'd have how many

00:11:28,950 --> 00:11:32,700
instructions that ends up in x86 once

00:11:30,570 --> 00:11:34,950
interested by the kernel and on the

00:11:32,700 --> 00:11:36,390
right column for the kernel just for

00:11:34,950 --> 00:11:38,010
comparison of what s au attached filter

00:11:36,390 --> 00:11:40,529
ends up doing when it converts your

00:11:38,010 --> 00:11:42,240
classic vpf to EPF now it's not entirely

00:11:40,529 --> 00:11:44,730
apples to apples comparison because for

00:11:42,240 --> 00:11:46,710
some reason socket filters in EB PF

00:11:44,730 --> 00:11:49,320
don't get to access the sk buff data

00:11:46,710 --> 00:11:51,060
pointer they can only use the old load

00:11:49,320 --> 00:11:53,550
in direct load absolute stuff and any

00:11:51,060 --> 00:11:54,960
vpf tendons of calling socket load

00:11:53,550 --> 00:11:56,700
helper which means that you have to make

00:11:54,960 --> 00:11:58,200
a V PF call which means you clobber over

00:11:56,700 --> 00:12:00,779
into registers and it's a lot of faffing

00:11:58,200 --> 00:12:02,279
around and that's why the kernel is so

00:12:00,779 --> 00:12:03,800
inefficient we have almost like a 2x

00:12:02,279 --> 00:12:05,670
improvement in doing this just ourselves

00:12:03,800 --> 00:12:09,030
compared to what the kernel managed to

00:12:05,670 --> 00:12:10,260
do in a socket filter and now compile

00:12:09,030 --> 00:12:11,730
wants run everywhere so this is really

00:12:10,260 --> 00:12:13,770
key we really don't want to faff around

00:12:11,730 --> 00:12:15,450
with clang compiling all of our BPF and

00:12:13,770 --> 00:12:17,490
converting all this everywhere on the

00:12:15,450 --> 00:12:18,990
edge and we won't enable disable

00:12:17,490 --> 00:12:20,250
remember initially our thing where we

00:12:18,990 --> 00:12:21,330
have several rules on after the other we

00:12:20,250 --> 00:12:23,100
want to have a single program with

00:12:21,330 --> 00:12:25,140
multiple rules and we want to

00:12:23,100 --> 00:12:27,570
selectively enable or disable each and

00:12:25,140 --> 00:12:29,100
every one of these rules and it turns

00:12:27,570 --> 00:12:30,600
out that the first impression we'd be

00:12:29,100 --> 00:12:32,700
like oh we can do this in a map BPF has

00:12:30,600 --> 00:12:35,010
BPF has maps we can look up values in

00:12:32,700 --> 00:12:36,270
maps we can store program IDs as keys or

00:12:35,010 --> 00:12:38,070
something and check if the rules enabled

00:12:36,270 --> 00:12:40,290
this ends up being really expensive

00:12:38,070 --> 00:12:41,580
though a map lookup is for instructions

00:12:40,290 --> 00:12:43,050
minimum by the time you set up all the

00:12:41,580 --> 00:12:44,339
arguments for the vpf calling convention

00:12:43,050 --> 00:12:46,470
and actually made the call and check the

00:12:44,339 --> 00:12:48,360
return value and the verifier makes sure

00:12:46,470 --> 00:12:50,010
you check the return value and it also

00:12:48,360 --> 00:12:51,600
clobbers a bunch of registers R 0 and R

00:12:50,010 --> 00:12:52,830
5 r clobbered which means that clang

00:12:51,600 --> 00:12:55,020
will spill a bunch of register the stack

00:12:52,830 --> 00:12:56,640
and then spill them back and for us on

00:12:55,020 --> 00:12:57,540
average a single map lookup for a rule

00:12:56,640 --> 00:12:59,760
like this ended up being ten

00:12:57,540 --> 00:13:01,350
instructions which is a lot when you

00:12:59,760 --> 00:13:03,330
only have 4,000 and you need hundreds of

00:13:01,350 --> 00:13:04,740
rules so instead it seems like we want

00:13:03,330 --> 00:13:06,510
to kind of just modify the elf instead

00:13:04,740 --> 00:13:08,040
or do something like this it turns all

00:13:06,510 --> 00:13:09,300
that work so if we write code like this

00:13:08,040 --> 00:13:11,250
so the key part here is that we have a

00:13:09,300 --> 00:13:13,530
single enabled variable in so imagine we

00:13:11,250 --> 00:13:14,790
repeat this for every rule and we load

00:13:13,530 --> 00:13:15,779
that and that variable is assigned to a

00:13:14,790 --> 00:13:18,300
register and then

00:13:15,779 --> 00:13:20,399
a single 64-bit vpf load using the

00:13:18,300 --> 00:13:22,290
inline assembly into that register and

00:13:20,399 --> 00:13:24,329
the key part here is that if you put a

00:13:22,290 --> 00:13:25,949
symbol name in the inline assembly which

00:13:24,329 --> 00:13:27,959
I've highlighted here rule 0 is enabled

00:13:25,949 --> 00:13:31,079
in yellow that then shows up in the

00:13:27,959 --> 00:13:32,720
relocation info of the elf and then we

00:13:31,079 --> 00:13:34,709
detect the value of that register and

00:13:32,720 --> 00:13:36,389
this is great so if we don't actually

00:13:34,709 --> 00:13:37,949
dump the relocation info of enough

00:13:36,389 --> 00:13:39,809
compiled like this we find the offset of

00:13:37,949 --> 00:13:41,639
our load instruction and that runtime

00:13:39,809 --> 00:13:43,410
all we have to do is find all the

00:13:41,639 --> 00:13:45,480
symbols named rule and then underscore

00:13:43,410 --> 00:13:47,370
ID whatever enabled and rewrite all

00:13:45,480 --> 00:13:48,809
these loads to either load 0 to disable

00:13:47,370 --> 00:13:51,420
the rule or load 1 to enable the rule

00:13:48,809 --> 00:13:53,220
and this gets even better it turns out

00:13:51,420 --> 00:13:55,350
the verifier prunes constant branches

00:13:53,220 --> 00:13:57,480
like this so the verifier tracks the

00:13:55,350 --> 00:13:59,579
value of variables in registers and

00:13:57,480 --> 00:14:00,959
seeing as we do 1 64-bit constant load

00:13:59,579 --> 00:14:02,879
it knows that the register has a

00:14:00,959 --> 00:14:04,470
constant value and it knows that we're

00:14:02,879 --> 00:14:06,420
using this in a jump with a constant

00:14:04,470 --> 00:14:08,189
value and so if the rules disabled it'll

00:14:06,420 --> 00:14:09,779
knob out the whole rule and if the rule

00:14:08,189 --> 00:14:10,980
is enabled it'll not bail just the check

00:14:09,779 --> 00:14:13,819
and the rules always there so this has a

00:14:10,980 --> 00:14:16,410
zero runtime cost which is great

00:14:13,819 --> 00:14:17,670
now on to debugging so this is all great

00:14:16,410 --> 00:14:19,290
and we're dropping packets everywhere

00:14:17,670 --> 00:14:20,430
how do we actually figure out what we're

00:14:19,290 --> 00:14:23,370
dropping about when we have a problem

00:14:20,430 --> 00:14:24,629
so metrics only go so far we have met

00:14:23,370 --> 00:14:26,160
great metrics and you can put them in

00:14:24,629 --> 00:14:27,449
BPF maps and we have metrics of drop

00:14:26,160 --> 00:14:29,430
packets per rule and we can tell which

00:14:27,449 --> 00:14:30,329
rules are dropping how many packets but

00:14:29,430 --> 00:14:31,620
if we're searching for a needle in a

00:14:30,329 --> 00:14:34,019
haystack there's one packet that's being

00:14:31,620 --> 00:14:35,100
dropped or disappear or something it can

00:14:34,019 --> 00:14:36,240
be really hard to figure out what

00:14:35,100 --> 00:14:37,740
actually happened to it so we really

00:14:36,240 --> 00:14:40,139
want some kind of TCP dump like tool

00:14:37,740 --> 00:14:42,269
where we want a filter to match the

00:14:40,139 --> 00:14:43,920
packet that we're looking for and we

00:14:42,269 --> 00:14:46,379
want to be able to look at the packet

00:14:43,920 --> 00:14:47,759
and see what happened to it now it turns

00:14:46,379 --> 00:14:49,889
out we already have all the things we

00:14:47,759 --> 00:14:51,509
need to do this we only talked about lid

00:14:49,889 --> 00:14:53,850
P cap and TCP dump and that just

00:14:51,509 --> 00:14:55,259
generates classic BPF and we've just

00:14:53,850 --> 00:14:58,649
talked about how we can now convert

00:14:55,259 --> 00:15:00,929
classic BPF to EVPs and we can also use

00:14:58,649 --> 00:15:03,600
perfect output matching packets so we

00:15:00,929 --> 00:15:06,000
can use any TCP dump filter compile it

00:15:03,600 --> 00:15:09,110
to classic vpf compile that to extended

00:15:06,000 --> 00:15:11,189
BPF add some extra EVP F to use perf and

00:15:09,110 --> 00:15:12,449
that would be some EVP F that would

00:15:11,189 --> 00:15:14,939
filter out packets and match one

00:15:12,449 --> 00:15:18,839
anything we want and now for this we

00:15:14,939 --> 00:15:20,790
updated our classic vpf - EVP F compiler

00:15:18,839 --> 00:15:21,899
to generate directly EVP F instead of

00:15:20,790 --> 00:15:23,160
going through C and clang

00:15:21,899 --> 00:15:26,759
because it was a lot of faffing around

00:15:23,160 --> 00:15:28,050
to get this for so little and so this is

00:15:26,759 --> 00:15:29,279
kind of currently what our setup looks

00:15:28,050 --> 00:15:30,030
like and so the big question is how do

00:15:29,279 --> 00:15:32,160
we hook the same

00:15:30,030 --> 00:15:34,320
we don't really we need to tell call in

00:15:32,160 --> 00:15:37,590
to this extra program we've made somehow

00:15:34,320 --> 00:15:41,760
but how to do that and so we always want

00:15:37,590 --> 00:15:43,110
to tell go into it and that's fine

00:15:41,760 --> 00:15:44,280
because it turns out that the tail call

00:15:43,110 --> 00:15:45,750
helper is really great this way and then

00:15:44,280 --> 00:15:47,790
if you tell call and nothing is attached

00:15:45,750 --> 00:15:49,590
it's a no op so tell calling with

00:15:47,790 --> 00:15:50,910
nothing has pretty much zero runtime

00:15:49,590 --> 00:15:53,340
performance overhead so we can just tell

00:15:50,910 --> 00:15:55,770
call all the time and if we do this at

00:15:53,340 --> 00:15:57,840
the end of the chain and at the start we

00:15:55,770 --> 00:15:59,940
can also get the final action that the

00:15:57,840 --> 00:16:00,690
packet took because until we get to the

00:15:59,940 --> 00:16:02,040
final program

00:16:00,690 --> 00:16:03,240
it's just tail calls and we don't know

00:16:02,040 --> 00:16:05,790
if the packet was supposed to be HTP

00:16:03,240 --> 00:16:07,530
dropped or XDP passed that makes sense

00:16:05,790 --> 00:16:08,670
and the great part we're doing at the

00:16:07,530 --> 00:16:09,990
end as well is in the case of other

00:16:08,670 --> 00:16:11,190
projects so we're also working on a load

00:16:09,990 --> 00:16:12,810
balancing project where we modify

00:16:11,190 --> 00:16:14,490
packets then we can actually get the

00:16:12,810 --> 00:16:16,920
dump of the modified packet and see what

00:16:14,490 --> 00:16:17,550
it looks like and so this end up looking

00:16:16,920 --> 00:16:21,330
something like this

00:16:17,550 --> 00:16:22,740
so after the drop Alf we tail call into

00:16:21,330 --> 00:16:23,970
two separate filter programs and those

00:16:22,740 --> 00:16:27,330
are the ones that we've compiled from

00:16:23,970 --> 00:16:29,550
cdpf - EVP F and do perf and both of

00:16:27,330 --> 00:16:31,230
these programs have the action embedded

00:16:29,550 --> 00:16:33,030
in them and we can then output that as

00:16:31,230 --> 00:16:35,760
perf metadata and then a user space

00:16:33,030 --> 00:16:37,560
demon is gonna read from the perf ring

00:16:35,760 --> 00:16:38,580
buffer and uh put that to a pcap and

00:16:37,560 --> 00:16:41,010
this works really well because we can

00:16:38,580 --> 00:16:43,410
even add the action that was taken as

00:16:41,010 --> 00:16:45,390
the interface metadata in the PCAT file

00:16:43,410 --> 00:16:47,040
and then we have an annotated pcap with

00:16:45,390 --> 00:16:49,980
all the packets that we saw and what xdp

00:16:47,040 --> 00:16:51,870
action they actually took so this is all

00:16:49,980 --> 00:16:53,310
great now there are some pain points the

00:16:51,870 --> 00:16:55,380
main ones being in the complexity limits

00:16:53,310 --> 00:16:56,700
we always want to support more and more

00:16:55,380 --> 00:16:58,680
rules and we never really know how many

00:16:56,700 --> 00:17:00,240
it's hard to place an upper bound on the

00:16:58,680 --> 00:17:02,190
amount of rules we need at any given

00:17:00,240 --> 00:17:03,690
point in time and different rules end up

00:17:02,190 --> 00:17:05,790
being vastly different in the number of

00:17:03,690 --> 00:17:06,780
instructions they actually use so we've

00:17:05,790 --> 00:17:08,459
been trying to do lots of work on

00:17:06,780 --> 00:17:10,860
reducing the amount of instruction than

00:17:08,459 --> 00:17:12,720
supporting more rules an early attempt

00:17:10,860 --> 00:17:14,760
involved trying to actually brute force

00:17:12,720 --> 00:17:16,470
rules into elves so the idea was that we

00:17:14,760 --> 00:17:18,810
would put all of our rules into a single

00:17:16,470 --> 00:17:20,189
elf shove it through the verifier and if

00:17:18,810 --> 00:17:21,569
they've ever complained we would assume

00:17:20,189 --> 00:17:23,339
that we had too many rules or hit some

00:17:21,569 --> 00:17:24,329
complexity limit till the problem is

00:17:23,339 --> 00:17:25,380
there are lots of different complexity

00:17:24,329 --> 00:17:26,430
limits and they all have different air

00:17:25,380 --> 00:17:28,620
nodes and they're all really hard to

00:17:26,430 --> 00:17:30,060
check for and then if we hit that limit

00:17:28,620 --> 00:17:31,470
we would just have some terrible

00:17:30,060 --> 00:17:33,570
heuristic to try and guesstimate how

00:17:31,470 --> 00:17:35,220
many instructions each rule used so we

00:17:33,570 --> 00:17:36,420
can move some rules to different elves

00:17:35,220 --> 00:17:37,950
and you would keep doing this until we

00:17:36,420 --> 00:17:39,120
ended up with a set of elves that are

00:17:37,950 --> 00:17:41,940
all the rules we needed and then we

00:17:39,120 --> 00:17:43,300
could just chain belts together now this

00:17:41,940 --> 00:17:45,340
sounds great but it was terrible

00:17:43,300 --> 00:17:46,750
it was really hard to be bugged and very

00:17:45,340 --> 00:17:48,130
unobtrusive all because it depended a

00:17:46,750 --> 00:17:49,810
lot on which kernel you were actually

00:17:48,130 --> 00:17:51,070
compiling these rules because lots of

00:17:49,810 --> 00:17:52,600
air power limits are tweaked all the

00:17:51,070 --> 00:17:54,970
time and it was really hard to actually

00:17:52,600 --> 00:17:56,260
reproduce this so for now we've decided

00:17:54,970 --> 00:17:58,510
to stick with just increasing the kernel

00:17:56,260 --> 00:18:01,710
complexity limits to same values and

00:17:58,510 --> 00:18:04,180
close enough another thing is that clang

00:18:01,710 --> 00:18:06,100
EVP F inline assembly kind of sucks you

00:18:04,180 --> 00:18:07,540
can't really specify what up codes you

00:18:06,100 --> 00:18:09,640
want to use you have to use this C like

00:18:07,540 --> 00:18:11,620
syntax to guesstimate what instruction

00:18:09,640 --> 00:18:13,000
that's giving you and if you mess it up

00:18:11,620 --> 00:18:16,810
the instructions just get silently

00:18:13,000 --> 00:18:18,850
dropped which makes it really fun

00:18:16,810 --> 00:18:20,860
we're also been working on race for you

00:18:18,850 --> 00:18:22,360
rate limiting so most of our rules we

00:18:20,860 --> 00:18:24,610
discussed here either drop or pass the

00:18:22,360 --> 00:18:25,660
packet but in lots of conditions we

00:18:24,610 --> 00:18:27,100
actually just want to rate limit

00:18:25,660 --> 00:18:29,110
specific packets so especially like if

00:18:27,100 --> 00:18:30,730
you can imagine we have we want to write

00:18:29,110 --> 00:18:33,460
limit new TCP connections we can just

00:18:30,730 --> 00:18:35,710
rate limit new syn packets coming in but

00:18:33,460 --> 00:18:37,450
implementing a race free token bucket in

00:18:35,710 --> 00:18:38,890
EVP F cheaply is actually really hard

00:18:37,450 --> 00:18:41,500
because there are no proper atomic

00:18:38,890 --> 00:18:43,600
instructions so you can lock X add which

00:18:41,500 --> 00:18:44,890
adds atomically but you don't get the

00:18:43,600 --> 00:18:47,140
previous value out there's no comparison

00:18:44,890 --> 00:18:49,810
for no fetch and add really but we're

00:18:47,140 --> 00:18:54,580
working on implementing that and yeah so

00:18:49,810 --> 00:18:55,870
thanks for UPF it runs CVP F great and

00:18:54,580 --> 00:18:58,480
here are some links to things so BPF

00:18:55,870 --> 00:18:59,710
tools is our puff and dns cdpf compiler

00:18:58,480 --> 00:19:02,890
which we use for matching packets

00:18:59,710 --> 00:19:05,980
triggering rules cv PFC is our classic

00:19:02,890 --> 00:19:07,390
vp f - c or - e v PF compiler and that's

00:19:05,980 --> 00:19:09,190
not quite open source yet but it should

00:19:07,390 --> 00:19:11,530
be next week so the link will work next

00:19:09,190 --> 00:19:13,150
week for github and same for xt pcap

00:19:11,530 --> 00:19:15,280
that's our XDP packet capture tool that

00:19:13,150 --> 00:19:17,890
uses cv PFC and that should be open

00:19:15,280 --> 00:19:19,570
source next week and new tools et PF is

00:19:17,890 --> 00:19:22,000
the loader we use that's entirely an NGO

00:19:19,570 --> 00:19:23,800
that allows doing this runtime kind of

00:19:22,000 --> 00:19:33,480
elf fudging to enable and disable rules

00:19:23,800 --> 00:19:36,480
force and that is it excellent questions

00:19:33,480 --> 00:19:36,480
yeah

00:19:37,889 --> 00:19:44,679
great talk

00:19:40,029 --> 00:19:47,649
since quick folks are here you know you

00:19:44,679 --> 00:19:50,259
think it would replace TCP do you think

00:19:47,649 --> 00:19:53,919
you can do like syn flood detection for

00:19:50,259 --> 00:19:57,039
quick in X DP or do you need to decrypt

00:19:53,919 --> 00:19:58,269
packets and it's it seems harder we

00:19:57,039 --> 00:20:00,489
haven't looked into it that much but it

00:19:58,269 --> 00:20:01,570
seems there's a lot less we can do in xt

00:20:00,489 --> 00:20:03,100
p without being able to decrypt the

00:20:01,570 --> 00:20:05,139
packets i see so just getting there all

00:20:03,100 --> 00:20:06,729
packet seems kind of hard we can do rate

00:20:05,139 --> 00:20:08,109
limiting i think based on like

00:20:06,729 --> 00:20:17,279
destination IP and stuff but nothing

00:20:08,109 --> 00:20:17,279
much more right but not on somebody else

00:20:19,320 --> 00:20:37,210
plenty of questions questions if the

00:20:34,779 --> 00:20:41,499
kinds of attacks quick would have would

00:20:37,210 --> 00:20:44,889
be similar to tcp or not and the minimum

00:20:41,499 --> 00:20:48,519
packet size in quic is not tiny like syn

00:20:44,889 --> 00:20:52,149
flood so it's hard to send that many

00:20:48,519 --> 00:20:54,549
packets like this huge stream of small

00:20:52,149 --> 00:20:58,389
packets basically to bring down the cell

00:20:54,549 --> 00:21:00,700
I'm sorry this is not entirely I'm here

00:20:58,389 --> 00:21:02,859
yeah this is not entirely true because

00:21:00,700 --> 00:21:05,320
the main bottleneck of an attacker is

00:21:02,859 --> 00:21:09,580
not the size of the packet the bandwidth

00:21:05,320 --> 00:21:14,019
but but the main cost is about writing a

00:21:09,580 --> 00:21:17,200
packet the network card and with quick

00:21:14,019 --> 00:21:19,809
you will just see the the same syn flood

00:21:17,200 --> 00:21:22,029
but not the same packet rate about the

00:21:19,809 --> 00:21:26,830
same packet rate probably but with

00:21:22,029 --> 00:21:30,309
higher bandwidth so yeah it having

00:21:26,830 --> 00:21:33,099
having an MTU sized first initial packet

00:21:30,309 --> 00:21:37,269
doesn't help you at all it it actually

00:21:33,099 --> 00:21:40,210
makes things worse so for what it's

00:21:37,269 --> 00:21:42,380
worth there is a silk cookie-like

00:21:40,210 --> 00:21:46,390
mechanism that's built into

00:21:42,380 --> 00:21:48,650
no I'm here in the front row oh yeah

00:21:46,390 --> 00:21:50,720
because there's a sim cookie like

00:21:48,650 --> 00:21:53,060
mechanism built into quick no it's

00:21:50,720 --> 00:21:56,270
called a retry packet okay so if I

00:21:53,060 --> 00:21:58,370
receive a packet and I am III the server

00:21:56,270 --> 00:22:00,590
decides that it's it's undergoing dose I

00:21:58,370 --> 00:22:02,750
can simply say retry packet to ensure

00:22:00,590 --> 00:22:04,490
that the client is where it says it is

00:22:02,750 --> 00:22:06,860
for examples I can I can choose to not

00:22:04,490 --> 00:22:09,260
respect zero oddity handshake right like

00:22:06,860 --> 00:22:11,120
the mitigations for for toss that's

00:22:09,260 --> 00:22:13,730
ultimately what ya think for so that all

00:22:11,120 --> 00:22:15,710
happens in userspace though that

00:22:13,730 --> 00:22:17,990
happened well that's an implementation

00:22:15,710 --> 00:22:20,360
yes then you're asking right so how you

00:22:17,990 --> 00:22:22,010
send a retry if you centrally try for

00:22:20,360 --> 00:22:23,810
every single client at all that comes in

00:22:22,010 --> 00:22:26,330
then you can certainly do it in simple

00:22:23,810 --> 00:22:30,830
XTP with no encryption so the retries

00:22:26,330 --> 00:22:32,390
aren't encrypted they are no okay so so

00:22:30,830 --> 00:22:35,060
the the token that's actually sent in

00:22:32,390 --> 00:22:37,760
the retry is sent in plain text so you

00:22:35,060 --> 00:22:39,380
can totally do this in xtp and how do

00:22:37,760 --> 00:22:40,310
you tell new connections from existing

00:22:39,380 --> 00:22:44,000
connections what happens if you send a

00:22:40,310 --> 00:22:45,590
retry to an existing connection you can

00:22:44,000 --> 00:22:49,010
tell from the packet type okay and

00:22:45,590 --> 00:22:50,720
that's visible so so there are so there

00:22:49,010 --> 00:22:52,310
are medications that one can one can

00:22:50,720 --> 00:22:54,560
talk about and one can build for this

00:22:52,310 --> 00:22:56,480
especially for the dass condition for

00:22:54,560 --> 00:22:58,490
the 404 for the door situation you can

00:22:56,480 --> 00:23:00,410
absolutely build something that that

00:22:58,490 --> 00:23:02,890
runs much faster than the rest of the

00:23:00,410 --> 00:23:02,890
stack does

00:23:09,610 --> 00:23:17,380
oh I'm surprised sure

00:23:15,130 --> 00:23:18,880
so you know how we say Department output

00:23:17,380 --> 00:23:19,500
was dropping sometimes then you didn't

00:23:18,880 --> 00:23:23,440
care

00:23:19,500 --> 00:23:27,400
sorry yeah what you're sending one of

00:23:23,440 --> 00:23:40,900
your slides was showing this call I can

00:23:27,400 --> 00:23:44,770
go backwards a few way back the perf

00:23:40,900 --> 00:23:45,580
event output yeah yeah that that thing

00:23:44,770 --> 00:23:48,549
there yeah

00:23:45,580 --> 00:23:50,470
you says it you're happy that it drops

00:23:48,549 --> 00:23:52,900
it can't keep up with you yeah I mean

00:23:50,470 --> 00:23:54,309
it's kind of it fails gracefully so in

00:23:52,900 --> 00:23:55,690
the case where we would be overwhelmed

00:23:54,309 --> 00:23:58,750
with too many packets samples or drop

00:23:55,690 --> 00:24:00,549
which is what we want and that works out

00:23:58,750 --> 00:24:02,140
fine okay but it has no back break she

00:24:00,549 --> 00:24:04,660
doesn't you know you just keep sending

00:24:02,140 --> 00:24:05,890
even though yeah we keep sending but I

00:24:04,660 --> 00:24:07,480
think if the ring buffer spool is pretty

00:24:05,890 --> 00:24:16,840
cheap because it just checks the reebok

00:24:07,480 --> 00:24:19,059
respond then just drops it well so

00:24:16,840 --> 00:24:21,280
people actually you you'll find out this

00:24:19,059 --> 00:24:22,960
when it's full I think I don't think

00:24:21,280 --> 00:24:24,400
this thing yeah we can't know if it's

00:24:22,960 --> 00:24:25,990
for for me BBF but as soon as we call

00:24:24,400 --> 00:24:27,970
the helper the helper will know there's

00:24:25,990 --> 00:24:33,309
no more one funny thing about that thing

00:24:27,970 --> 00:24:35,620
in userspace you know of it yes yes yeah

00:24:33,309 --> 00:24:37,059
yeah oh yeah you can add your own

00:24:35,620 --> 00:24:38,770
metrics and EVPs for this pretty easily

00:24:37,059 --> 00:24:40,150
so we have our own metrics for how many

00:24:38,770 --> 00:24:41,290
times per fair about how many packets

00:24:40,150 --> 00:24:42,880
we've sent over perf and how many we've

00:24:41,290 --> 00:24:45,450
actually received and you can pretty

00:24:42,880 --> 00:24:45,450
good statistics

00:24:50,940 --> 00:24:59,559
you mentioned you do some other stuff in

00:24:53,649 --> 00:25:04,080
l7 but do you handle any HTTP drops in

00:24:59,559 --> 00:25:07,029
xcp - no we don't do any HTTP like an

00:25:04,080 --> 00:25:12,700
HTTP inspection XTP no okay so let me

00:25:07,029 --> 00:25:14,919
know dpi in no only for DNS really okay

00:25:12,700 --> 00:25:18,460
so there no more questions I have a

00:25:14,919 --> 00:25:20,830
question oh so you mentioned the there

00:25:18,460 --> 00:25:24,220
is different semantics and reading data

00:25:20,830 --> 00:25:29,830
from pocket from so a touch filter

00:25:24,220 --> 00:25:33,730
versus xdp yeah so and do you mention

00:25:29,830 --> 00:25:35,320
that in one case is that it's a pointer

00:25:33,730 --> 00:25:37,419
in the other case is a function hole

00:25:35,320 --> 00:25:38,919
yeah is it fixable what do you know why

00:25:37,419 --> 00:25:40,720
yes I'm not entirely sure if anyone

00:25:38,919 --> 00:25:42,789
doesn't know this why if you attach if

00:25:40,720 --> 00:25:45,159
you use s o8 h vp f on a socket with an

00:25:42,789 --> 00:25:46,749
EVP F program then you're not allowed to

00:25:45,159 --> 00:25:49,149
read the data pointer from the SK buff

00:25:46,749 --> 00:25:50,379
it's there and it exists in SK buff and

00:25:49,149 --> 00:25:51,759
if you're privileged and you're loading

00:25:50,379 --> 00:25:52,929
like a TC filter you get the same SK

00:25:51,759 --> 00:25:57,059
buff and you're allowed to read the data

00:25:52,929 --> 00:26:02,710
pointer but from unprivileged so filter

00:25:57,059 --> 00:26:04,659
you cannot which is why do you want to

00:26:02,710 --> 00:26:06,039
redo that a pointer for what oh it's

00:26:04,659 --> 00:26:07,960
much I mean it's so it just kind of

00:26:06,039 --> 00:26:10,360
remark that it's much cheaper so if you

00:26:07,960 --> 00:26:12,070
want to have if you do SL attach BPF

00:26:10,360 --> 00:26:13,450
right now with an e b PF program you

00:26:12,070 --> 00:26:15,309
have to use load absolute and load

00:26:13,450 --> 00:26:16,450
indirect yes which ends up being a

00:26:15,309 --> 00:26:18,549
function call what ends up being like

00:26:16,450 --> 00:26:20,379
ten instructions to do it because all

00:26:18,549 --> 00:26:25,749
this function call do the appropriate

00:26:20,379 --> 00:26:29,200
sure of that which is not in this cab

00:26:25,749 --> 00:26:31,600
ahead but if only is DP you have all the

00:26:29,200 --> 00:26:36,490
data in one frame in one portion of

00:26:31,600 --> 00:26:38,499
memory arbitrary skb then you can stay

00:26:36,490 --> 00:26:39,759
with you but from TC you can still read

00:26:38,499 --> 00:26:40,990
the data point of yourself as long as

00:26:39,759 --> 00:26:43,419
you're privileged there's a check in the

00:26:40,990 --> 00:26:48,119
verifier if caps is admin you can read

00:26:43,419 --> 00:26:48,119
the data pointer yourself

00:26:48,880 --> 00:26:55,630
I'm not sure what you want to do is

00:26:53,020 --> 00:26:56,620
detail data pointer I'm just saying you

00:26:55,630 --> 00:26:58,690
can do it from teeth I don't

00:26:56,620 --> 00:27:00,790
particularly want to do this we don't

00:26:58,690 --> 00:27:03,580
use I don't use socket I so attached I

00:27:00,790 --> 00:27:05,710
think you can redo that a point our only

00:27:03,580 --> 00:27:09,700
if the verifier can make sure that you

00:27:05,710 --> 00:27:12,850
are not going to read the byte above the

00:27:09,700 --> 00:27:16,000
frame so yeah and that's so verify your

00:27:12,850 --> 00:27:17,590
limits I'm not sure you can know it

00:27:16,000 --> 00:27:21,240
seems you can do that NTC but I don't

00:27:17,590 --> 00:27:21,240
know I have a looked into it that much

00:27:22,710 --> 00:27:27,270
all right thanks

00:27:28,180 --> 00:27:34,789

YouTube URL: https://www.youtube.com/watch?v=1Yw6YISaSkg


