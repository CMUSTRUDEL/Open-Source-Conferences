Title: Bottleneck Analysis - Ilia Alshanetsky | IPC14
Publication date: 2016-06-09
Playlist: International PHP Conference Spring 2014
Description: 
	This session covers a full-stack analysis of the request delivery process for a web-based application and identify tools and techniques that can be used to identify common bottlenecks within the application. It contains topics from browser based profiling, web server behaviour profiling, php application profiling & analysis as well as caching & database bottlenecks.


More information: https://phpconference.com/en/
Captions: 
	00:00:07,379 --> 00:00:10,410
so this session is about bottleneck

00:00:08,970 --> 00:00:12,929
analysis and I'm going to run you

00:00:10,410 --> 00:00:14,730
through the full stack of analyzing

00:00:12,929 --> 00:00:17,250
everything from the browser all the way

00:00:14,730 --> 00:00:19,439
down to the nitty-gritty of the server

00:00:17,250 --> 00:00:21,359
just to give you kind of a full quick

00:00:19,439 --> 00:00:23,039
overview of you know how you can

00:00:21,359 --> 00:00:26,460
identify performance and scalability

00:00:23,039 --> 00:00:27,000
issues within the application so before

00:00:26,460 --> 00:00:29,550
we get going

00:00:27,000 --> 00:00:31,769
a few quick words about myself so I'm a

00:00:29,550 --> 00:00:33,719
longtime contributor to the PHP project

00:00:31,769 --> 00:00:35,370
so I helped develop a number of

00:00:33,719 --> 00:00:38,070
extensions worked on core and a variety

00:00:35,370 --> 00:00:39,629
of other things and as part of that I've

00:00:38,070 --> 00:00:42,360
actually worked on a performance aspect

00:00:39,629 --> 00:00:44,879
of PHP as well so some of the things you

00:00:42,360 --> 00:00:47,070
see here actually came from having to

00:00:44,879 --> 00:00:51,870
work on optimizing both PHP and the

00:00:47,070 --> 00:00:53,280
applications written in PHP so um the

00:00:51,870 --> 00:00:55,440
first thing I guess what's causing

00:00:53,280 --> 00:00:56,699
bottlenecks and what's why bottlenecks

00:00:55,440 --> 00:00:59,699
are a problem

00:00:56,699 --> 00:01:02,250
so bottlenecks are not a performance

00:00:59,699 --> 00:01:04,379
problem as many people like to put

00:01:02,250 --> 00:01:06,270
there's actually a mix of both a

00:01:04,379 --> 00:01:08,610
scalability and a performance problem

00:01:06,270 --> 00:01:11,070
because if you had a something that was

00:01:08,610 --> 00:01:13,650
a purely a speed issue where something

00:01:11,070 --> 00:01:15,450
was not as quick you know one of the

00:01:13,650 --> 00:01:17,400
easy solutions to do is throw hardware

00:01:15,450 --> 00:01:18,710
the problem and as much as people would

00:01:17,400 --> 00:01:21,150
tell you that that's the wrong approach

00:01:18,710 --> 00:01:22,920
trust me it works and it works really

00:01:21,150 --> 00:01:24,360
really well you get faster disk you

00:01:22,920 --> 00:01:26,970
throw more memory all of a sudden your

00:01:24,360 --> 00:01:28,290
database is able to fly scalability

00:01:26,970 --> 00:01:29,790
problems on the other hand you can't

00:01:28,290 --> 00:01:32,970
solve with hardware because it means

00:01:29,790 --> 00:01:34,380
that the code cannot expand cannot you

00:01:32,970 --> 00:01:35,909
know grow to a point that even if you

00:01:34,380 --> 00:01:38,150
throw hardware at it you're just buying

00:01:35,909 --> 00:01:41,520
yourself a very short amount of time

00:01:38,150 --> 00:01:43,049
before the problem scales up to a point

00:01:41,520 --> 00:01:44,909
where even the extra hardware is not

00:01:43,049 --> 00:01:48,689
going to be able to help you so that's a

00:01:44,909 --> 00:01:49,979
very important point to keep in mind so

00:01:48,689 --> 00:01:51,420
let's take a look at a typical web

00:01:49,979 --> 00:01:52,890
process and you really got to think of

00:01:51,420 --> 00:01:55,619
the entire stack if you're really

00:01:52,890 --> 00:01:58,229
thinking about scalability so first of

00:01:55,619 --> 00:02:00,930
all you have your users or clients using

00:01:58,229 --> 00:02:02,520
the web browser and before the request

00:02:00,930 --> 00:02:05,820
hits your web server you got to think

00:02:02,520 --> 00:02:08,459
about things like DNS latency page sizes

00:02:05,820 --> 00:02:10,140
because of the network speed number of

00:02:08,459 --> 00:02:12,330
components to the page so that's a

00:02:10,140 --> 00:02:13,210
number of JavaScript and CSS files that

00:02:12,330 --> 00:02:15,460
you have

00:02:13,210 --> 00:02:17,500
that are being transmitted as well as

00:02:15,460 --> 00:02:19,750
the complexity of the extra things like

00:02:17,500 --> 00:02:21,400
JavaScript and CSS and JavaScript

00:02:19,750 --> 00:02:23,200
nowadays in particular because most

00:02:21,400 --> 00:02:25,360
browsers for performance reasons

00:02:23,200 --> 00:02:26,890
actually compile JavaScript to

00:02:25,360 --> 00:02:29,110
effectively native code whether it's

00:02:26,890 --> 00:02:31,480
Chrome ie Firefox doesn't really matter

00:02:29,110 --> 00:02:34,180
and those things can have an impact on

00:02:31,480 --> 00:02:37,360
the speed and ultimately a scalability

00:02:34,180 --> 00:02:39,130
of the application now when it hits the

00:02:37,360 --> 00:02:41,820
web server you still have other things

00:02:39,130 --> 00:02:44,320
like SSL negotiation page caching

00:02:41,820 --> 00:02:45,490
compression overhead which is one of the

00:02:44,320 --> 00:02:47,350
things that you have to think about if

00:02:45,490 --> 00:02:49,570
you have big resources as well as

00:02:47,350 --> 00:02:51,550
pre-processing of requests how many

00:02:49,570 --> 00:02:56,320
people here have used Apache with

00:02:51,550 --> 00:02:58,270
htaccess and Madhuri right okay so you

00:02:56,320 --> 00:03:00,400
probably know at this point that if you

00:02:58,270 --> 00:03:02,290
do non-trivial mod rewrite rules they

00:03:00,400 --> 00:03:04,510
can actually take quite a bit of time to

00:03:02,290 --> 00:03:07,180
process in fact it's not uncommon that a

00:03:04,510 --> 00:03:09,520
simple PHP request let alone a static

00:03:07,180 --> 00:03:11,200
file will actually be processed faster

00:03:09,520 --> 00:03:13,810
than it takes to modern rewrite to

00:03:11,200 --> 00:03:15,580
figure out how to do the remapping of

00:03:13,810 --> 00:03:16,780
the URLs and so on that you have so

00:03:15,580 --> 00:03:19,450
that's definitely one of the things to

00:03:16,780 --> 00:03:20,920
keep in mind now when you get to the

00:03:19,450 --> 00:03:22,240
scripting language itself I mean you

00:03:20,920 --> 00:03:24,820
have the obvious things you have slow

00:03:22,240 --> 00:03:27,220
code so slow code needs to be optimized

00:03:24,820 --> 00:03:29,020
in some way you may have lock contention

00:03:27,220 --> 00:03:30,400
so if you're writing things to disk or

00:03:29,020 --> 00:03:33,340
you're writing things to things like

00:03:30,400 --> 00:03:35,140
databases in some cases or caching

00:03:33,340 --> 00:03:36,940
system you may have to deal with things

00:03:35,140 --> 00:03:38,500
where you know you have multiple writers

00:03:36,940 --> 00:03:41,110
trying to write to the same block of

00:03:38,500 --> 00:03:42,520
data simultaneously and subsequently one

00:03:41,110 --> 00:03:45,850
has to wait for the other to complete

00:03:42,520 --> 00:03:47,320
before you can have an issue and when it

00:03:45,850 --> 00:03:49,420
comes to PHP you also have something

00:03:47,320 --> 00:03:51,250
called non-critical errors so those are

00:03:49,420 --> 00:03:53,320
the warnings and notices e strict's and

00:03:51,250 --> 00:03:55,750
all that wonderful stuff that you'd

00:03:53,320 --> 00:03:58,000
think well how can it have an impact on

00:03:55,750 --> 00:04:00,070
performance and scalability well I'll

00:03:58,000 --> 00:04:02,020
show you some benchmarks down the line

00:04:00,070 --> 00:04:03,910
to show you just how big of an impact

00:04:02,020 --> 00:04:07,090
some players can have within the

00:04:03,910 --> 00:04:10,030
application then you get to the things

00:04:07,090 --> 00:04:12,370
like the caching layer so you know and

00:04:10,030 --> 00:04:16,270
database so you have lock contentions

00:04:12,370 --> 00:04:18,040
data storage lack of indexes and all of

00:04:16,270 --> 00:04:20,470
the other interesting things that

00:04:18,040 --> 00:04:23,410
anytime you deal with databases you have

00:04:20,470 --> 00:04:25,090
to be aware of so the bottom line is

00:04:23,410 --> 00:04:26,530
that there's a lot of different sources

00:04:25,090 --> 00:04:27,910
with bottlenecks so

00:04:26,530 --> 00:04:30,250
start from the very beginning which is

00:04:27,910 --> 00:04:31,870
the browser now the reason I want to

00:04:30,250 --> 00:04:34,060
start for the browser because this is a

00:04:31,870 --> 00:04:35,830
very common mistake so a developer would

00:04:34,060 --> 00:04:38,290
complete an application they want to

00:04:35,830 --> 00:04:39,820
test or convince you know their boss or

00:04:38,290 --> 00:04:42,010
whoever that the application is quick

00:04:39,820 --> 00:04:43,840
they fire up a patchy bench just because

00:04:42,010 --> 00:04:45,669
it's pretty much in any UNIX machine

00:04:43,840 --> 00:04:47,889
they hit the request with the number of

00:04:45,669 --> 00:04:50,410
URLs they see the number at the bottom

00:04:47,889 --> 00:04:52,419
oh wow almost 2100 requests per second

00:04:50,410 --> 00:04:55,000
you know we don't have any issues here

00:04:52,419 --> 00:04:56,440
we can deploy this into production the

00:04:55,000 --> 00:04:59,590
challenge what it doesn't consider is

00:04:56,440 --> 00:05:01,300
that most users don't use Apache bench

00:04:59,590 --> 00:05:03,100
to browse the web they actually use

00:05:01,300 --> 00:05:04,930
their web browser as strange as it may

00:05:03,100 --> 00:05:06,700
be and the web browser needs to parse

00:05:04,930 --> 00:05:09,640
the HTML needs to load the JavaScript

00:05:06,700 --> 00:05:11,710
load CSS load though the images do a

00:05:09,640 --> 00:05:13,600
whole bunch of pre-processing and only

00:05:11,710 --> 00:05:15,250
then does a user see the final outcome

00:05:13,600 --> 00:05:16,930
which is your page so even though it's

00:05:15,250 --> 00:05:19,510
your server it looks like this is a

00:05:16,930 --> 00:05:22,570
really quick piece of content to the

00:05:19,510 --> 00:05:24,610
user it may seem really slow and when it

00:05:22,570 --> 00:05:27,010
comes to web serving it's the user

00:05:24,610 --> 00:05:28,630
perception that sometimes matters more

00:05:27,010 --> 00:05:31,240
than the actual speed of the server

00:05:28,630 --> 00:05:32,830
that's why apple in particular they

00:05:31,240 --> 00:05:34,120
focused on a user perception and it

00:05:32,830 --> 00:05:36,100
looks like if you have an apple computer

00:05:34,120 --> 00:05:37,690
it wakes up from sleep really quickly

00:05:36,100 --> 00:05:39,430
well it doesn't it just shows you fake

00:05:37,690 --> 00:05:41,050
images of a screenshot taken right

00:05:39,430 --> 00:05:42,970
before it went to sleep but it can load

00:05:41,050 --> 00:05:44,590
it really quickly so it seems to you

00:05:42,970 --> 00:05:46,750
like there's something on the screen

00:05:44,590 --> 00:05:48,640
something you can interact with you know

00:05:46,750 --> 00:05:52,360
very quickly so the same thing applies

00:05:48,640 --> 00:05:54,460
to web experience as well now in order

00:05:52,360 --> 00:05:56,710
to understand the users web experience

00:05:54,460 --> 00:05:58,930
you need to profile how the browser is

00:05:56,710 --> 00:06:00,729
interpreting that page now there's a

00:05:58,930 --> 00:06:02,350
variety of tools that you can use for

00:06:00,729 --> 00:06:04,930
this personally I prefer to use Chrome

00:06:02,350 --> 00:06:06,910
it has a really good analyzer of

00:06:04,930 --> 00:06:08,740
requests built right into it's called

00:06:06,910 --> 00:06:11,770
developer tools but if you're using

00:06:08,740 --> 00:06:13,840
Safari or Firefox Firefox its Firebug in

00:06:11,770 --> 00:06:17,229
Safari it's also a built into they all

00:06:13,840 --> 00:06:19,539
nowadays have similar tools like this so

00:06:17,229 --> 00:06:21,789
I decided to pick on php.net this is

00:06:19,539 --> 00:06:24,850
actually the previous design of php.net

00:06:21,789 --> 00:06:27,100
so now I can safely poke fun at php.net

00:06:24,850 --> 00:06:29,830
because that's been fixed to some extent

00:06:27,100 --> 00:06:33,970
so this is a portion of the profile of

00:06:29,830 --> 00:06:36,099
php.net so if we look at the very first

00:06:33,970 --> 00:06:38,860
portion here which is a blue bar at the

00:06:36,099 --> 00:06:39,520
top this is what it takes to load the

00:06:38,860 --> 00:06:41,530
mage

00:06:39,520 --> 00:06:43,240
a main site what is interesting here and

00:06:41,530 --> 00:06:46,479
I know those of you in the back probably

00:06:43,240 --> 00:06:48,490
can see it is it says that it took 206

00:06:46,479 --> 00:06:51,039
milliseconds just to establish the

00:06:48,490 --> 00:06:53,259
connection to php.net so a fifth of a

00:06:51,039 --> 00:06:56,440
second effectively was wasted without

00:06:53,259 --> 00:06:58,810
any positive outcome because nothing

00:06:56,440 --> 00:07:02,110
happened in this particular case then it

00:06:58,810 --> 00:07:03,699
took another 200 milliseconds for the

00:07:02,110 --> 00:07:05,470
web server to say okay I got your

00:07:03,699 --> 00:07:07,060
request I got to do some thinking and

00:07:05,470 --> 00:07:08,440
then once I'm done thinking I'll start

00:07:07,060 --> 00:07:10,690
sending you the data so we're already

00:07:08,440 --> 00:07:13,630
close to being half a second mark and

00:07:10,690 --> 00:07:15,039
then last but not least I happened to be

00:07:13,630 --> 00:07:16,569
at another conference so the internet

00:07:15,039 --> 00:07:17,259
connection was really slow when I made

00:07:16,569 --> 00:07:19,750
those slides

00:07:17,259 --> 00:07:23,080
it took 1.2 seconds to actually download

00:07:19,750 --> 00:07:25,539
the content of php.net so even though

00:07:23,080 --> 00:07:28,030
the server potentially only took a fifth

00:07:25,539 --> 00:07:30,280
of a second to provide me with the

00:07:28,030 --> 00:07:32,949
content from a user perception it

00:07:30,280 --> 00:07:34,539
actually took 2 seconds to load just the

00:07:32,949 --> 00:07:36,190
HTML of the page and I'm not even

00:07:34,539 --> 00:07:39,250
talking about all the static content

00:07:36,190 --> 00:07:42,729
like JavaScript CSS and so on so this is

00:07:39,250 --> 00:07:46,419
a perfect example of you know perception

00:07:42,729 --> 00:07:48,909
driving the users experience in terms of

00:07:46,419 --> 00:07:51,219
the application so let's take a look at

00:07:48,909 --> 00:07:54,909
a couple of other things on php.net so

00:07:51,219 --> 00:07:58,360
php.net loads a bunch of images that's

00:07:54,909 --> 00:08:02,319
pretty normal but it actually takes 162

00:07:58,360 --> 00:08:05,440
milliseconds to wait to transmit that

00:08:02,319 --> 00:08:07,389
image so why does the web server need to

00:08:05,440 --> 00:08:08,949
think that long before transmitting a

00:08:07,389 --> 00:08:11,409
static file it should be pretty instant

00:08:08,949 --> 00:08:13,810
well this is where things like mod

00:08:11,409 --> 00:08:15,159
rewrite rule or any access rules come in

00:08:13,810 --> 00:08:16,479
because even though the web server

00:08:15,159 --> 00:08:18,430
technically is not doing anything

00:08:16,479 --> 00:08:19,960
there's a whole bunch of pre-processing

00:08:18,430 --> 00:08:22,509
that needs to happen to transmit that

00:08:19,960 --> 00:08:24,789
file or maybe you have really really

00:08:22,509 --> 00:08:26,229
slow discs you're serving things of CF

00:08:24,789 --> 00:08:28,810
cards or something in your server in

00:08:26,229 --> 00:08:33,479
which case this could in fact be a valid

00:08:28,810 --> 00:08:36,459
possibility so a couple of other things

00:08:33,479 --> 00:08:38,860
that are worth noting this is actually

00:08:36,459 --> 00:08:42,279
Facebook another popular site perhaps a

00:08:38,860 --> 00:08:44,800
little bit more popular than php.net so

00:08:42,279 --> 00:08:47,020
I actually broke down this into three

00:08:44,800 --> 00:08:48,970
steps which actually are shown by these

00:08:47,020 --> 00:08:52,570
lines so the first thing you can see is

00:08:48,970 --> 00:08:54,280
that it took a roughly 413 milliseconds

00:08:52,570 --> 00:08:56,170
to finish transmitting the content

00:08:54,280 --> 00:08:58,030
that's not particularly bad that's not

00:08:56,170 --> 00:09:00,040
particularly good average it's under a

00:08:58,030 --> 00:09:03,730
second which is what people like to see

00:09:00,040 --> 00:09:05,800
however it took another 400 milliseconds

00:09:03,730 --> 00:09:07,840
to actually finish transmitting all of

00:09:05,800 --> 00:09:09,820
the relevant data and another 400

00:09:07,840 --> 00:09:11,230
milliseconds to actually have the page

00:09:09,820 --> 00:09:13,180
fully load for the user

00:09:11,230 --> 00:09:15,580
so even though your back-end was pretty

00:09:13,180 --> 00:09:17,260
quick from the user did not actually see

00:09:15,580 --> 00:09:19,510
the page as quickly as you thought it

00:09:17,260 --> 00:09:21,670
might show up it basically look three

00:09:19,510 --> 00:09:23,760
times longer then it took for just the

00:09:21,670 --> 00:09:27,280
back end to do all the other processing

00:09:23,760 --> 00:09:30,070
so let's pick on Facebook a little bit

00:09:27,280 --> 00:09:32,410
more so one of the things that Facebook

00:09:30,070 --> 00:09:33,880
does is to optimize some of the loading

00:09:32,410 --> 00:09:37,990
the actual load content from different

00:09:33,880 --> 00:09:39,640
subdomains now the challenge with using

00:09:37,990 --> 00:09:41,200
different subdomains is that every

00:09:39,640 --> 00:09:44,140
single time you load something it means

00:09:41,200 --> 00:09:46,540
to do a DNS lookup now some people have

00:09:44,140 --> 00:09:49,390
fast DNS servers some people not so much

00:09:46,540 --> 00:09:51,400
so what you can see here is that the

00:09:49,390 --> 00:09:52,600
first DNS request took an extra 20

00:09:51,400 --> 00:09:54,580
milliseconds that's pretty

00:09:52,600 --> 00:09:56,620
inconsequential we can ignore it but

00:09:54,580 --> 00:09:58,870
another DNS request took 106

00:09:56,620 --> 00:10:01,330
milliseconds because for whatever it is

00:09:58,870 --> 00:10:02,860
possibly using a CDN so it wasn't a

00:10:01,330 --> 00:10:04,960
subdomain of Facebook it may have been a

00:10:02,860 --> 00:10:07,420
completely different domain it had to

00:10:04,960 --> 00:10:10,030
resolve it completely from scratch so

00:10:07,420 --> 00:10:12,280
people who are using domain and

00:10:10,030 --> 00:10:14,440
subdomain tricks to load a JavaScript

00:10:12,280 --> 00:10:16,330
asynchronously or other things they may

00:10:14,440 --> 00:10:17,890
be solving one problem that now you can

00:10:16,330 --> 00:10:19,690
load JavaScript and parallel but

00:10:17,890 --> 00:10:21,600
creating another because those DNS

00:10:19,690 --> 00:10:24,880
lookups especially in a first page load

00:10:21,600 --> 00:10:26,830
are not end up being you know a lot

00:10:24,880 --> 00:10:28,870
slower than you'd like now you may say

00:10:26,830 --> 00:10:31,630
well DNS lookup it happens once and

00:10:28,870 --> 00:10:34,720
after that it's cached that is true

00:10:31,630 --> 00:10:37,000
however if you're dealing with a site

00:10:34,720 --> 00:10:38,800
where a lot of the traffic is not repeat

00:10:37,000 --> 00:10:41,380
users like it's in the case of Facebook

00:10:38,800 --> 00:10:43,120
or people just come back over and over

00:10:41,380 --> 00:10:45,100
again but it is something where you're

00:10:43,120 --> 00:10:47,200
driving traffic from Google Adwords or

00:10:45,100 --> 00:10:49,150
from other form of advertising it's been

00:10:47,200 --> 00:10:51,340
said that if a page takes more than a

00:10:49,150 --> 00:10:53,260
second and a half to load you have a

00:10:51,340 --> 00:10:54,910
substantial number of visitors starting

00:10:53,260 --> 00:10:56,500
to drop off the site so you're losing

00:10:54,910 --> 00:10:58,960
traffic that you're now trying to drive

00:10:56,500 --> 00:11:00,490
to the application so the DNS loads do

00:10:58,960 --> 00:11:02,230
add up and you want to be really careful

00:11:00,490 --> 00:11:04,970
around how many domains or subdomains

00:11:02,230 --> 00:11:06,950
you're using to process this

00:11:04,970 --> 00:11:08,570
now here's another site in this case I

00:11:06,950 --> 00:11:09,680
decided to hide domain because this is

00:11:08,570 --> 00:11:11,360
pretty bad

00:11:09,680 --> 00:11:13,220
this particular site loads a ton of

00:11:11,360 --> 00:11:14,870
JavaScript there's literally almost the

00:11:13,220 --> 00:11:16,940
full page of different JavaScript files

00:11:14,870 --> 00:11:18,560
being loaded now the JavaScript files

00:11:16,940 --> 00:11:21,050
are actually pretty small most of them

00:11:18,560 --> 00:11:23,350
are only you know few hundred bytes in

00:11:21,050 --> 00:11:25,700
size but because javascript is loaded

00:11:23,350 --> 00:11:27,020
sequentially not as synchronously you'll

00:11:25,700 --> 00:11:29,270
see that most of the requests are

00:11:27,020 --> 00:11:30,650
sitting and blocking so you end up by

00:11:29,270 --> 00:11:32,720
the end of this waiting through almost

00:11:30,650 --> 00:11:34,430
four seconds waiting for all the

00:11:32,720 --> 00:11:36,800
previous JavaScript files to finish

00:11:34,430 --> 00:11:39,080
loading so from a user experience once

00:11:36,800 --> 00:11:43,130
again not a particularly good thing that

00:11:39,080 --> 00:11:45,200
you want to see have happened so this is

00:11:43,130 --> 00:11:46,280
PayPal another company I'd like to pick

00:11:45,200 --> 00:11:49,010
on

00:11:46,280 --> 00:11:51,950
so PayPal I uses as a cell which is

00:11:49,010 --> 00:11:54,650
great the one thing to note is that in

00:11:51,950 --> 00:11:56,840
case of PayPal their SSL takes almost

00:11:54,650 --> 00:11:58,310
half a second to load and when you're

00:11:56,840 --> 00:12:00,710
using SSL when you're using multiple

00:11:58,310 --> 00:12:02,630
subdomains guess what for every single

00:12:00,710 --> 00:12:05,390
subdomain there has to be a separate SSL

00:12:02,630 --> 00:12:07,190
negotiation so once you start doing this

00:12:05,390 --> 00:12:08,870
those things start to add up because

00:12:07,190 --> 00:12:11,210
this was a first request this was a

00:12:08,870 --> 00:12:12,800
second another 190 milliseconds so it

00:12:11,210 --> 00:12:14,540
gets slower and slower and slower and I

00:12:12,800 --> 00:12:16,790
haven't done the full analysis just to

00:12:14,540 --> 00:12:20,810
give you a brief sample of what can be

00:12:16,790 --> 00:12:22,490
found the other thing and this is a

00:12:20,810 --> 00:12:24,080
little bit contextual perhaps to North

00:12:22,490 --> 00:12:26,240
America so maybe you guys will correct

00:12:24,080 --> 00:12:28,100
me if the situation is different in

00:12:26,240 --> 00:12:29,780
Europe or in Germany in particular in

00:12:28,100 --> 00:12:31,730
North America the Internet connectivity

00:12:29,780 --> 00:12:33,410
of a typical house is that you can

00:12:31,730 --> 00:12:35,360
download things really really quickly

00:12:33,410 --> 00:12:38,390
but if you need to send data back to the

00:12:35,360 --> 00:12:41,000
server that is usually five to ten times

00:12:38,390 --> 00:12:42,740
slower now a lot of web developers

00:12:41,000 --> 00:12:45,380
forget that and they start creating a

00:12:42,740 --> 00:12:46,970
ton of cookies one of the common

00:12:45,380 --> 00:12:50,060
culprits to it if you use a lot of the

00:12:46,970 --> 00:12:52,430
grid controls and things like jQuery and

00:12:50,060 --> 00:12:53,990
dojo j/s and so on there is really

00:12:52,430 --> 00:12:55,820
convenient feature that says that every

00:12:53,990 --> 00:12:57,260
time you sort a grid it's going to set a

00:12:55,820 --> 00:12:59,089
cookie and remember your sorting

00:12:57,260 --> 00:13:00,950
preferences so you can do that next time

00:12:59,089 --> 00:13:02,330
now what it doesn't mention that for

00:13:00,950 --> 00:13:04,790
every single grid it's going to create a

00:13:02,330 --> 00:13:07,040
new cookie so what ends up being is that

00:13:04,790 --> 00:13:08,540
now every time a user is requesting any

00:13:07,040 --> 00:13:10,940
piece of content from your domain

00:13:08,540 --> 00:13:12,620
whether it's a static file or dynamic

00:13:10,940 --> 00:13:14,540
file it's going to send all of those

00:13:12,620 --> 00:13:17,120
cookies which could end up being

00:13:14,540 --> 00:13:18,680
hundreds of kilobytes now if you're

00:13:17,120 --> 00:13:20,869
happen to be in North America

00:13:18,680 --> 00:13:22,430
using a typical you know home connection

00:13:20,869 --> 00:13:24,230
I'm not saying dial-up but even a

00:13:22,430 --> 00:13:26,769
high-speed connection this can actually

00:13:24,230 --> 00:13:29,350
substantially slow down the request

00:13:26,769 --> 00:13:32,180
serving process because on every

00:13:29,350 --> 00:13:33,559
retrieval the browser needs to send you

00:13:32,180 --> 00:13:35,929
know maybe two or three or four

00:13:33,559 --> 00:13:38,029
kilobytes of cookies to the server and

00:13:35,929 --> 00:13:40,009
surprisingly enough it does add up and

00:13:38,029 --> 00:13:42,050
it could mean that the page is going to

00:13:40,009 --> 00:13:44,949
take an extra couple of seconds to load

00:13:42,050 --> 00:13:48,889
before it can be rendered to the user

00:13:44,949 --> 00:13:51,290
now all of these things are great

00:13:48,889 --> 00:13:53,119
and it's wonderful but one of the things

00:13:51,290 --> 00:13:54,679
that we're using all of those extensions

00:13:53,119 --> 00:13:55,999
where are you doing your testing well

00:13:54,679 --> 00:13:57,649
you're doing a testing on your local

00:13:55,999 --> 00:13:59,779
machine which means you probably are

00:13:57,649 --> 00:14:01,309
local to the application server you

00:13:59,779 --> 00:14:04,040
don't really have a true expression of

00:14:01,309 --> 00:14:05,899
the network overhead how can you test

00:14:04,040 --> 00:14:07,850
the experience of multiple different

00:14:05,899 --> 00:14:10,249
users on different browsers and all

00:14:07,850 --> 00:14:12,350
those wonderful problems so this is

00:14:10,249 --> 00:14:14,660
where this interesting tool comes in

00:14:12,350 --> 00:14:16,939
called boomerang and boomerang is

00:14:14,660 --> 00:14:19,610
actually something that was came up by a

00:14:16,939 --> 00:14:21,709
guy by name of Phillip Telus and this is

00:14:19,610 --> 00:14:25,009
a URL where you can grab it from github

00:14:21,709 --> 00:14:27,079
and what boomerang does is it's a

00:14:25,009 --> 00:14:30,589
JavaScript tool that you can embed into

00:14:27,079 --> 00:14:33,410
your application and when a request is

00:14:30,589 --> 00:14:35,629
being loaded or finished being loaded by

00:14:33,410 --> 00:14:38,120
the server it's going to transmit the

00:14:35,629 --> 00:14:40,399
data back to your server saying here's

00:14:38,120 --> 00:14:42,350
what was the users perception in terms

00:14:40,399 --> 00:14:44,929
of how long it took for all the files to

00:14:42,350 --> 00:14:47,089
load how long it took for the page to

00:14:44,929 --> 00:14:49,040
actually finish rendering and all those

00:14:47,089 --> 00:14:51,230
wonderful statistics and in order to

00:14:49,040 --> 00:14:53,779
integrate it into your application all

00:14:51,230 --> 00:14:57,379
you need to do is load boomerang the GS

00:14:53,779 --> 00:14:58,639
and then initialize a beacon URL which

00:14:57,379 --> 00:15:01,100
is usually recommended to be a

00:14:58,639 --> 00:15:03,769
transparent pixel or just like a one

00:15:01,100 --> 00:15:05,660
pixel image and it's a static request so

00:15:03,769 --> 00:15:09,949
your server is going to be request for

00:15:05,660 --> 00:15:12,230
this pixel gift dynamically and via the

00:15:09,949 --> 00:15:14,149
URL it's going to indicate all of the

00:15:12,230 --> 00:15:16,100
timing statistics so you're on the this

00:15:14,149 --> 00:15:17,720
really really long URL with a ton of

00:15:16,100 --> 00:15:19,790
different parameters inside that

00:15:17,720 --> 00:15:22,369
particular URL that are going to be

00:15:19,790 --> 00:15:26,149
shown and then all of that information

00:15:22,369 --> 00:15:29,839
can be retrieved from your Apache or

00:15:26,149 --> 00:15:31,430
nginx or lighty whatever HTTP server you

00:15:29,839 --> 00:15:33,260
happen to be using and the

00:15:31,430 --> 00:15:35,089
does it via URL so that you don't need

00:15:33,260 --> 00:15:37,160
to deploy any additional logging or

00:15:35,089 --> 00:15:38,510
tracking tools because this type of

00:15:37,160 --> 00:15:41,120
analysis you don't need to do in a

00:15:38,510 --> 00:15:43,370
real-time and you can download or

00:15:41,120 --> 00:15:45,710
archive your web server logs and then

00:15:43,370 --> 00:15:47,420
simply extract all the requests for

00:15:45,710 --> 00:15:50,630
pixel gif for what you end up calling

00:15:47,420 --> 00:15:52,399
the file and then parsing the URL for

00:15:50,630 --> 00:15:55,190
all the statistical information that

00:15:52,399 --> 00:15:57,980
boomeranged ideas that has captured so

00:15:55,190 --> 00:15:59,930
on the most basic iteration it will tell

00:15:57,980 --> 00:16:01,610
you the version of boomerang it will

00:15:59,930 --> 00:16:04,250
tell you how long it took to retrieve

00:16:01,610 --> 00:16:06,320
the page and what was the URL that was

00:16:04,250 --> 00:16:08,209
requested in a URL encoded form if you

00:16:06,320 --> 00:16:09,459
happen to have any URL parameters as

00:16:08,209 --> 00:16:12,230
part of the URL

00:16:09,459 --> 00:16:14,420
now what boomerang uses in a background

00:16:12,230 --> 00:16:16,580
is something called w3c navigation

00:16:14,420 --> 00:16:19,339
timing API and it's supported by pretty

00:16:16,580 --> 00:16:21,380
much all the modern browsers and what it

00:16:19,339 --> 00:16:24,140
does is it actually uses the browser's

00:16:21,380 --> 00:16:26,450
internal timing statistics to give you a

00:16:24,140 --> 00:16:28,940
really really detailed breakdown of the

00:16:26,450 --> 00:16:30,470
request serving process so you can

00:16:28,940 --> 00:16:32,690
literally find out how long it took to

00:16:30,470 --> 00:16:35,450
load a particular JavaScript file or a

00:16:32,690 --> 00:16:37,910
particular image or basically any piece

00:16:35,450 --> 00:16:40,940
of information just to give you an idea

00:16:37,910 --> 00:16:42,920
this is all of the information that w3c

00:16:40,940 --> 00:16:44,390
navigation timing is able to capture it

00:16:42,920 --> 00:16:47,270
can even tell you how long it took for

00:16:44,390 --> 00:16:50,360
the previous page to be unloaded and

00:16:47,270 --> 00:16:52,850
basically freed up from memory and you

00:16:50,360 --> 00:16:55,339
can see DNS resolution tcp/ip

00:16:52,850 --> 00:16:57,440
negotiation request response processing

00:16:55,339 --> 00:16:59,209
unload and so on so effectively all of

00:16:57,440 --> 00:17:02,029
the same statistics that you can see in

00:16:59,209 --> 00:17:04,600
the web developer tools now you can see

00:17:02,029 --> 00:17:07,220
from the perception of your users

00:17:04,600 --> 00:17:09,170
basically for every single request with

00:17:07,220 --> 00:17:11,660
virtually no overhead because the extent

00:17:09,170 --> 00:17:13,429
of your overhead is loading boomerang GS

00:17:11,660 --> 00:17:15,380
which believe me is not a particularly

00:17:13,429 --> 00:17:17,990
large javascript file so it's not going

00:17:15,380 --> 00:17:19,790
to slow things down now from all this

00:17:17,990 --> 00:17:21,500
data there's really four key points that

00:17:19,790 --> 00:17:22,910
you want to focus on startup user

00:17:21,500 --> 00:17:24,559
experience because you can't really

00:17:22,910 --> 00:17:26,870
count how long it took to free up memory

00:17:24,559 --> 00:17:30,440
from a previous request

00:17:26,870 --> 00:17:32,179
when did the server begin processing the

00:17:30,440 --> 00:17:34,520
requests that came in so this is where

00:17:32,179 --> 00:17:38,150
things finally got to more or less your

00:17:34,520 --> 00:17:39,620
control when was the page loaded so this

00:17:38,150 --> 00:17:42,830
is where all the content has been loaded

00:17:39,620 --> 00:17:44,419
and finally you can find out when all

00:17:42,830 --> 00:17:46,249
the post events

00:17:44,419 --> 00:17:47,840
have finished firing so when you have

00:17:46,249 --> 00:17:50,539
the JavaScript code that says on

00:17:47,840 --> 00:17:52,460
document ready and so on this is when

00:17:50,539 --> 00:17:53,659
all those events finished their work

00:17:52,460 --> 00:17:55,669
this is where you're going to get the

00:17:53,659 --> 00:17:57,950
final timing so you really get a full

00:17:55,669 --> 00:17:59,210
breakdown of the requests just to give

00:17:57,950 --> 00:18:01,730
you an idea how much data you have

00:17:59,210 --> 00:18:04,129
access to this in very very small font I

00:18:01,730 --> 00:18:06,559
know is the listing of all the

00:18:04,129 --> 00:18:08,629
parameters most of them are timings and

00:18:06,559 --> 00:18:10,460
milliseconds that you can see here that

00:18:08,629 --> 00:18:13,789
are available for every single request

00:18:10,460 --> 00:18:17,149
if the browser supports the w3c API for

00:18:13,789 --> 00:18:19,009
tracking it now if you don't want to use

00:18:17,149 --> 00:18:20,509
boomerang I don't know why but if you

00:18:19,009 --> 00:18:23,840
don't want to you can actually implement

00:18:20,509 --> 00:18:25,549
a very simple variant of boomerang on

00:18:23,840 --> 00:18:28,239
your own using just a few lines of

00:18:25,549 --> 00:18:30,619
JavaScript so you initialize a timer

00:18:28,239 --> 00:18:33,200
once the script loaded so you really

00:18:30,619 --> 00:18:35,269
want this to be the very first script

00:18:33,200 --> 00:18:36,980
inside your head block and then you set

00:18:35,269 --> 00:18:38,779
up an onload function that is going to

00:18:36,980 --> 00:18:40,609
create a new image tag with the same

00:18:38,779 --> 00:18:42,710
pixel that gif and it's going to say

00:18:40,609 --> 00:18:44,749
page load which is you know a new time

00:18:42,710 --> 00:18:47,269
less the original timing and then the

00:18:44,749 --> 00:18:49,279
URL that was taken and this is a kind of

00:18:47,269 --> 00:18:51,379
a poor-man's boomerang which is only

00:18:49,279 --> 00:18:54,230
going to give you the timing of how long

00:18:51,379 --> 00:18:55,970
it took for the page to effectively

00:18:54,230 --> 00:18:58,759
render for the most part because you're

00:18:55,970 --> 00:19:01,429
starting the data tracking already after

00:18:58,759 --> 00:19:03,080
the page is finished requesting so just

00:19:01,429 --> 00:19:04,970
a simple variant and if you want to

00:19:03,080 --> 00:19:08,480
analyze the data here's a little auks

00:19:04,970 --> 00:19:09,499
script that will parse your you know web

00:19:08,480 --> 00:19:11,419
server log file

00:19:09,499 --> 00:19:14,330
extract the appropriate entries and give

00:19:11,419 --> 00:19:16,419
you kind of a summary of how quick or

00:19:14,330 --> 00:19:18,739
how slow various requests have happened

00:19:16,419 --> 00:19:21,950
so this is kind of a quick run-through

00:19:18,739 --> 00:19:24,919
today web server so let's talk about the

00:19:21,950 --> 00:19:27,320
web server bottlenecks now when talking

00:19:24,919 --> 00:19:29,059
about web server bottlenecks you can use

00:19:27,320 --> 00:19:31,309
Apache bench it's sufficiently

00:19:29,059 --> 00:19:34,249
sufficient for that purpose I know some

00:19:31,309 --> 00:19:36,019
people prefer to use siege which is a

00:19:34,249 --> 00:19:37,519
little bit more sophisticated there's a

00:19:36,019 --> 00:19:39,230
couple of other tools that you can use

00:19:37,519 --> 00:19:41,419
but you know for the most purposes

00:19:39,230 --> 00:19:44,239
Apache benches to be honestly is good

00:19:41,419 --> 00:19:45,470
enough now one key thing is that a lot

00:19:44,239 --> 00:19:47,149
of people forget when they're using

00:19:45,470 --> 00:19:49,700
Apache benches paying attention to the

00:19:47,149 --> 00:19:52,129
failed requests because what sometimes

00:19:49,700 --> 00:19:54,080
happens is that Apache bench by default

00:19:52,129 --> 00:19:55,129
has actually a set amount of time that

00:19:54,080 --> 00:19:56,960
is going to wait for the server to

00:19:55,129 --> 00:19:58,460
respond and if the server does not

00:19:56,960 --> 00:20:00,380
respond because maybe

00:19:58,460 --> 00:20:02,660
there's no available processes to do so

00:20:00,380 --> 00:20:04,340
it will simply mark the request has

00:20:02,660 --> 00:20:06,860
failed so sometimes you can see an

00:20:04,340 --> 00:20:08,870
artificially quick communication between

00:20:06,860 --> 00:20:10,460
the server and Apache bench but it's

00:20:08,870 --> 00:20:12,650
because your failed requests are

00:20:10,460 --> 00:20:14,480
basically through the roof so make sure

00:20:12,650 --> 00:20:16,310
that this number is zero because any

00:20:14,480 --> 00:20:20,440
value other than zero indicates that

00:20:16,310 --> 00:20:20,440
something is not going according to plan

00:20:20,540 --> 00:20:24,950
the other thing you want to focus on is

00:20:22,700 --> 00:20:26,840
another this is a kind of a copy of a

00:20:24,950 --> 00:20:29,300
table from one of the outputs of Apache

00:20:26,840 --> 00:20:32,360
bench is the processing and the waiting

00:20:29,300 --> 00:20:34,190
times because waiting times means that

00:20:32,360 --> 00:20:35,870
this is how long something is waiting to

00:20:34,190 --> 00:20:38,330
be executed versus processing is the

00:20:35,870 --> 00:20:40,130
actual execution so ideally you want

00:20:38,330 --> 00:20:43,010
those to be pretty close to being the

00:20:40,130 --> 00:20:45,830
same but definitely something to keep an

00:20:43,010 --> 00:20:48,110
eye out the last bit of Apache bench

00:20:45,830 --> 00:20:49,910
output is a breakdown of percentage of

00:20:48,110 --> 00:20:51,620
requests that are served within a

00:20:49,910 --> 00:20:53,630
certain time so in this particular

00:20:51,620 --> 00:20:56,060
example you could see that 90% of the

00:20:53,630 --> 00:20:58,460
requests have been served in basically a

00:20:56,060 --> 00:21:00,920
quarter of a second which may be within

00:20:58,460 --> 00:21:03,350
your target and only do the remaining 5%

00:21:00,920 --> 00:21:05,030
took longer now the reason this great is

00:21:03,350 --> 00:21:07,160
important is because when you get the

00:21:05,030 --> 00:21:09,320
initial set of output from Apache bench

00:21:07,160 --> 00:21:11,030
it gives you the averages and the

00:21:09,320 --> 00:21:12,920
averages could be skewed by the fact

00:21:11,030 --> 00:21:14,930
that when the server was not doing

00:21:12,920 --> 00:21:16,460
anything the first couple of hundred

00:21:14,930 --> 00:21:18,620
requests get processed really really

00:21:16,460 --> 00:21:20,510
quickly but then after those requests

00:21:18,620 --> 00:21:22,400
were process the service starting to get

00:21:20,510 --> 00:21:24,200
slow because of lock contention and all

00:21:22,400 --> 00:21:27,260
the other things and the remaining 50

00:21:24,200 --> 00:21:29,030
percent were very very slow as a result

00:21:27,260 --> 00:21:30,980
and the average may still look okay but

00:21:29,030 --> 00:21:33,020
it doesn't mean you don't have a problem

00:21:30,980 --> 00:21:35,390
so you really are looking for situations

00:21:33,020 --> 00:21:37,700
where whatever your target happens to be

00:21:35,390 --> 00:21:39,380
between 80 and 90 percent are served

00:21:37,700 --> 00:21:40,970
within that target and then the

00:21:39,380 --> 00:21:42,830
remaining ten percent or five percent

00:21:40,970 --> 00:21:45,590
whatever the number happens to be are

00:21:42,830 --> 00:21:48,770
slower but that's because maybe they hit

00:21:45,590 --> 00:21:50,420
were not a--not the computer was loading

00:21:48,770 --> 00:21:51,890
stuff into cache or a floating stuff

00:21:50,420 --> 00:21:53,510
into cache or maybe there are something

00:21:51,890 --> 00:21:54,980
unrelated to your application happening

00:21:53,510 --> 00:21:58,010
in a machine and that caused some

00:21:54,980 --> 00:21:59,570
temporary slowdown now when you're

00:21:58,010 --> 00:22:02,450
testing your web server for bottleneck

00:21:59,570 --> 00:22:04,010
there is a number of basic tests that

00:22:02,450 --> 00:22:05,660
you want to conduct before actually

00:22:04,010 --> 00:22:08,660
running your application to see if you

00:22:05,660 --> 00:22:10,700
can identify a variety of web server

00:22:08,660 --> 00:22:11,840
type of issues that you can have within

00:22:10,700 --> 00:22:13,850
your server

00:22:11,840 --> 00:22:15,680
so the first thing you want to do is you

00:22:13,850 --> 00:22:17,120
want to create a static file it doesn't

00:22:15,680 --> 00:22:20,690
matter whether it's a JavaScript or HTML

00:22:17,120 --> 00:22:22,400
or CSS but basically a static file about

00:22:20,690 --> 00:22:24,470
ten kilobytes in size so it's really

00:22:22,400 --> 00:22:28,160
shouldn't you know cause any issues on

00:22:24,470 --> 00:22:29,600
its own and you want to request the file

00:22:28,160 --> 00:22:31,700
the first thing you want to watch for is

00:22:29,600 --> 00:22:33,890
the response size the same as a file

00:22:31,700 --> 00:22:35,330
size if the answer is yes that means

00:22:33,890 --> 00:22:36,620
you're not using compression and then

00:22:35,330 --> 00:22:39,980
the question is why are you not using

00:22:36,620 --> 00:22:41,630
compression in most cases nowadays a web

00:22:39,980 --> 00:22:43,970
server will be able to do compression at

00:22:41,630 --> 00:22:46,520
virtually nominal overhead and the

00:22:43,970 --> 00:22:49,190
saving of sending smaller content to the

00:22:46,520 --> 00:22:51,770
user is far better from a user

00:22:49,190 --> 00:22:53,240
experience then the little overhead that

00:22:51,770 --> 00:22:55,520
the web server is going to do for

00:22:53,240 --> 00:22:56,960
compression in most cases compression is

00:22:55,520 --> 00:22:58,910
so quick that is statistically

00:22:56,960 --> 00:23:01,400
insignificant you actually have to

00:22:58,910 --> 00:23:03,740
really have big files in order to be

00:23:01,400 --> 00:23:06,860
able to detect the overhead caused by

00:23:03,740 --> 00:23:10,550
compression now the other thing you want

00:23:06,860 --> 00:23:14,180
to watch for is does the number request

00:23:10,550 --> 00:23:16,250
max out before the network does the

00:23:14,180 --> 00:23:18,260
reality is that any modern web server

00:23:16,250 --> 00:23:21,050
should be able to max out the network

00:23:18,260 --> 00:23:23,510
before you hit the nut maximum number of

00:23:21,050 --> 00:23:26,300
requests and just to give you an example

00:23:23,510 --> 00:23:28,250
Mac Mini not you know to be confused

00:23:26,300 --> 00:23:31,010
with you know a really powerful server

00:23:28,250 --> 00:23:33,890
but a Mac Mini has a one gigabit port

00:23:31,010 --> 00:23:35,660
for static files Mac Mini using almost

00:23:33,890 --> 00:23:39,710
no matter which web server use whether

00:23:35,660 --> 00:23:42,440
it's Apache nginx light httpd I don't

00:23:39,710 --> 00:23:43,940
know anybody who installed is so I guess

00:23:42,440 --> 00:23:46,850
I shouldn't say anything about that but

00:23:43,940 --> 00:23:49,300
any one of those what web servers will

00:23:46,850 --> 00:23:51,890
saturate the network before the

00:23:49,300 --> 00:23:53,240
processor or the server itself is

00:23:51,890 --> 00:23:55,070
saturated so you want to make sure the

00:23:53,240 --> 00:23:57,350
same thing happens on your machine if it

00:23:55,070 --> 00:24:00,230
doesn't then that means that you have

00:23:57,350 --> 00:24:02,840
some sort of a server overhead maybe you

00:24:00,230 --> 00:24:05,180
have some complex rerouting rules using

00:24:02,840 --> 00:24:07,310
mod rewrite or maybe there's something

00:24:05,180 --> 00:24:09,410
else that you're doing on a server which

00:24:07,310 --> 00:24:11,510
is interfering with static content

00:24:09,410 --> 00:24:13,730
serving because whatever the what's

00:24:11,510 --> 00:24:15,500
slowing down static content is also

00:24:13,730 --> 00:24:17,540
going to slow down dynamic content it's

00:24:15,500 --> 00:24:19,550
just on static content you have less

00:24:17,540 --> 00:24:22,790
variables so it's a lot easier to detect

00:24:19,550 --> 00:24:24,080
and ultimately resolve now the other

00:24:22,790 --> 00:24:25,639
thing you want to check is are there any

00:24:24,080 --> 00:24:28,099
fluctuations with connect

00:24:25,639 --> 00:24:29,839
times again because static content is

00:24:28,099 --> 00:24:31,070
dead simple and one of the things that

00:24:29,839 --> 00:24:33,049
you'll see is that if you keep

00:24:31,070 --> 00:24:35,899
requesting the same piece of static

00:24:33,049 --> 00:24:37,579
content Linux in particular will say hey

00:24:35,899 --> 00:24:39,649
you're requesting this file very

00:24:37,579 --> 00:24:41,450
frequently how about I put it this file

00:24:39,649 --> 00:24:43,459
into memory so I don't actually have to

00:24:41,450 --> 00:24:46,190
read it from disk next time you request

00:24:43,459 --> 00:24:48,469
the file so after the initial cache warm

00:24:46,190 --> 00:24:50,419
up you actually should have basically

00:24:48,469 --> 00:24:52,909
virtually no fluctuation in the speed

00:24:50,419 --> 00:24:54,739
that it takes the file to be served and

00:24:52,909 --> 00:24:56,719
it should be pretty consistent once

00:24:54,739 --> 00:24:57,739
again if you see in a fluctuation that

00:24:56,719 --> 00:25:00,019
means that there is some sort of

00:24:57,739 --> 00:25:01,519
processing going on and that processing

00:25:00,019 --> 00:25:03,019
is causing that extra bit of overhead

00:25:01,519 --> 00:25:05,539
that sometimes make it slow sometimes

00:25:03,019 --> 00:25:07,070
fast sometimes you know neither slow or

00:25:05,539 --> 00:25:09,769
fast sort of this average speed in

00:25:07,070 --> 00:25:12,019
between the other thing you want to keep

00:25:09,769 --> 00:25:14,779
an eye out is are there any spikes in

00:25:12,019 --> 00:25:17,419
your disk i/o while you're serving this

00:25:14,779 --> 00:25:19,700
content now there's really only one

00:25:17,419 --> 00:25:23,089
reason why that could be the case maybe

00:25:19,700 --> 00:25:24,649
two one is maybe you disabled or didn't

00:25:23,089 --> 00:25:26,779
give enough memory for the operating

00:25:24,649 --> 00:25:28,129
system to cache content on disk or it's

00:25:26,779 --> 00:25:29,570
full of other things let's say you're

00:25:28,129 --> 00:25:31,399
running a web server and a database

00:25:29,570 --> 00:25:32,839
server on the same machine and the

00:25:31,399 --> 00:25:35,359
database server because of the usage

00:25:32,839 --> 00:25:37,249
pattern already had eaten up all the you

00:25:35,359 --> 00:25:39,349
know the cache memory that the kernel

00:25:37,249 --> 00:25:41,299
had allocated to do the caching the

00:25:39,349 --> 00:25:43,369
other possibility is could be is that

00:25:41,299 --> 00:25:44,719
you have a lot of write operations this

00:25:43,369 --> 00:25:47,779
is actually common when you have a

00:25:44,719 --> 00:25:50,779
shared environment so whether it's a you

00:25:47,779 --> 00:25:52,729
know virtual private server or whether

00:25:50,779 --> 00:25:54,739
you have a lot of VMs running on the

00:25:52,729 --> 00:25:57,619
same machine there may be something else

00:25:54,739 --> 00:26:00,139
that's chewing up disk and for the most

00:25:57,619 --> 00:26:01,759
part you know the old saying that the

00:26:00,139 --> 00:26:03,799
hard disk is the slowest part of the

00:26:01,759 --> 00:26:06,559
server is still true even if you're

00:26:03,799 --> 00:26:08,239
using SSDs there's still a lot slower

00:26:06,559 --> 00:26:11,239
than Ram or anything else you really

00:26:08,239 --> 00:26:13,700
have to go to PCI Express based cards to

00:26:11,239 --> 00:26:15,440
start getting to a point where your disk

00:26:13,700 --> 00:26:18,739
may not be the slowest part of your

00:26:15,440 --> 00:26:23,149
machine another thing you want to take a

00:26:18,739 --> 00:26:25,820
look at is your network i/o and this is

00:26:23,149 --> 00:26:29,779
one of the things that we talked about

00:26:25,820 --> 00:26:31,429
so maxing out the request size and you

00:26:29,779 --> 00:26:33,619
should be able to max it out even if you

00:26:31,429 --> 00:26:35,359
enable compression you really want to

00:26:33,619 --> 00:26:37,949
make sure that that's something that's

00:26:35,359 --> 00:26:40,599
that's going to happen

00:26:37,949 --> 00:26:44,499
now the other thing you want to do is

00:26:40,599 --> 00:26:47,049
that you know do the requests per second

00:26:44,499 --> 00:26:48,579
max out before whatever your desired

00:26:47,049 --> 00:26:50,769
goal and your desired goal is going to

00:26:48,579 --> 00:26:53,139
be set roughly based on when is your

00:26:50,769 --> 00:26:54,669
network going to max out and for this

00:26:53,139 --> 00:26:56,769
you typically will need a slightly

00:26:54,669 --> 00:26:58,929
bigger file and what I mean by that is

00:26:56,769 --> 00:27:01,929
you want to determine what is your

00:26:58,929 --> 00:27:04,149
typical page request size nowadays it's

00:27:01,929 --> 00:27:06,399
not uncommon for a website's HTML just

00:27:04,149 --> 00:27:08,709
the HTML to be about 80 kilobytes in

00:27:06,399 --> 00:27:10,179
size this is before compression and when

00:27:08,709 --> 00:27:12,299
you're talking about JavaScript files

00:27:10,179 --> 00:27:14,499
when you get to jQuery and all those big

00:27:12,299 --> 00:27:16,179
extensions they can also get into that

00:27:14,499 --> 00:27:18,699
range sometimes even exceeding 100

00:27:16,179 --> 00:27:20,889
kilobytes now this is where things get

00:27:18,699 --> 00:27:23,529
interesting because when you're serving

00:27:20,889 --> 00:27:25,689
large files your web server does not

00:27:23,529 --> 00:27:27,699
actually serve the file entirely to the

00:27:25,689 --> 00:27:29,589
kernel who is ultimately responsible for

00:27:27,699 --> 00:27:31,929
transmitting the file to the user it

00:27:29,589 --> 00:27:33,549
actually works in blocks and those

00:27:31,929 --> 00:27:35,979
blocks are called buffers and the

00:27:33,549 --> 00:27:38,139
buffers if they are significantly

00:27:35,979 --> 00:27:40,089
smaller than the page size and what

00:27:38,139 --> 00:27:42,099
actually happens is that the webserver

00:27:40,089 --> 00:27:43,689
passes a buffer to the kernel the

00:27:42,099 --> 00:27:45,489
colonel says okay great

00:27:43,689 --> 00:27:47,979
hold on I'm going to send this buffer to

00:27:45,489 --> 00:27:49,509
the user once the user receives that

00:27:47,979 --> 00:27:52,709
buffer the kernel says okay give me the

00:27:49,509 --> 00:27:55,599
next buffer so if you have big pages

00:27:52,709 --> 00:27:56,829
certainly about 50 kilobytes you need to

00:27:55,599 --> 00:27:58,839
take a look at the kernel buffer

00:27:56,829 --> 00:28:00,579
settings that you have and probably

00:27:58,839 --> 00:28:02,649
increase them so that the entire page

00:28:00,579 --> 00:28:04,809
can fit in a kernel buffer so that the

00:28:02,649 --> 00:28:08,229
web server can say here's the content

00:28:04,809 --> 00:28:09,969
that goes to your to the user the kernel

00:28:08,229 --> 00:28:11,469
says okay great I'll take it and then

00:28:09,969 --> 00:28:13,119
the web server is free to handle the

00:28:11,469 --> 00:28:14,949
next request and then it's entirely in

00:28:13,119 --> 00:28:16,839
the hands of the kernel to serve the

00:28:14,949 --> 00:28:18,909
requests to the user in which case you

00:28:16,839 --> 00:28:20,619
don't need as many Apache or whatever

00:28:18,909 --> 00:28:22,119
processes that you're using to serve the

00:28:20,619 --> 00:28:24,039
content which can in many cases

00:28:22,119 --> 00:28:27,669
substantially reduce the load on the

00:28:24,039 --> 00:28:28,839
server now the other thing you want to

00:28:27,669 --> 00:28:30,789
measure on a server and now we're

00:28:28,839 --> 00:28:33,279
getting to a little bit of PHP stuff is

00:28:30,789 --> 00:28:35,139
take your static file give it a dot PHP

00:28:33,279 --> 00:28:37,569
extension and see what happens

00:28:35,139 --> 00:28:39,159
now suffice to say it's going to become

00:28:37,569 --> 00:28:41,139
a lot slower because even though you're

00:28:39,159 --> 00:28:42,789
not running any PHP code the PHP

00:28:41,139 --> 00:28:44,709
interpreter needs to be fired up it

00:28:42,789 --> 00:28:46,690
needs to do some processing and that has

00:28:44,709 --> 00:28:48,669
an overhead but if you see that there is

00:28:46,690 --> 00:28:50,600
more than two times speed difference so

00:28:48,669 --> 00:28:53,179
if we were able to do 100 requests

00:28:50,600 --> 00:28:56,120
per second you know before adding the

00:28:53,179 --> 00:28:57,500
PHP extension now drop to 30 chances are

00:28:56,120 --> 00:29:00,139
you're not using an OP code cache

00:28:57,500 --> 00:29:01,880
because if the overhead of adding PHP

00:29:00,139 --> 00:29:04,340
interpreter should not be more than 2 if

00:29:01,880 --> 00:29:06,019
it is more than 2 then up code cache is

00:29:04,340 --> 00:29:08,509
probably what's missing or the OP code

00:29:06,019 --> 00:29:09,740
cache you have is badly misconfigured

00:29:08,509 --> 00:29:14,659
and it's not actually doing anything

00:29:09,740 --> 00:29:16,549
maybe it's turned off the other thing is

00:29:14,659 --> 00:29:18,679
that if the OP code cache does not help

00:29:16,549 --> 00:29:20,570
consider a different zappy so if you're

00:29:18,679 --> 00:29:22,669
still one of those people using CGI

00:29:20,570 --> 00:29:26,929
and I don't mean fast CGI but CGI the

00:29:22,669 --> 00:29:29,990
original CGI switch to fast cgi or you

00:29:26,929 --> 00:29:31,700
know some other API to serve PHP because

00:29:29,990 --> 00:29:35,029
that's not really doing a service for

00:29:31,700 --> 00:29:36,379
your web serving process now the next

00:29:35,029 --> 00:29:38,840
overhead you want to take a look at the

00:29:36,379 --> 00:29:40,549
server is the SSL overhead so if you're

00:29:38,840 --> 00:29:43,100
seeing more than a hundred milliseconds

00:29:40,549 --> 00:29:45,350
difference and you will have an overhead

00:29:43,100 --> 00:29:47,690
because SSL requires negotiation back

00:29:45,350 --> 00:29:48,860
and forth it's not free then one of the

00:29:47,690 --> 00:29:51,830
things you want to do on a server is

00:29:48,860 --> 00:29:54,679
enable things like SSL cache can

00:29:51,830 --> 00:29:57,230
consider enabling tcp/ip congestion

00:29:54,679 --> 00:29:58,730
settings in the kernel because see SSL

00:29:57,230 --> 00:30:00,620
negotiation requires a lot of

00:29:58,730 --> 00:30:03,110
back-and-forth between the server and

00:30:00,620 --> 00:30:04,970
the client and that's not something the

00:30:03,110 --> 00:30:06,769
kernel is particularly keen on it's it's

00:30:04,970 --> 00:30:08,299
thinking more along the lines of I'm

00:30:06,769 --> 00:30:09,620
going to send data and I'm going to get

00:30:08,299 --> 00:30:12,259
data back and that's going to be the end

00:30:09,620 --> 00:30:13,850
of it so for there are some settings

00:30:12,259 --> 00:30:15,889
that would allow you to fine tune the

00:30:13,850 --> 00:30:18,740
tcp/ip settings for that particular

00:30:15,889 --> 00:30:21,740
purpose last but not least is geo aware

00:30:18,740 --> 00:30:23,809
request routing so if your users are

00:30:21,740 --> 00:30:26,720
let's say in North America and your

00:30:23,809 --> 00:30:28,070
server happens to be in Germany there's

00:30:26,720 --> 00:30:29,629
going to be because of a lot of that

00:30:28,070 --> 00:30:32,210
back and forth there's going to be a lot

00:30:29,629 --> 00:30:33,860
of overhead to doing SSL so you really

00:30:32,210 --> 00:30:37,580
are better off putting in the server

00:30:33,860 --> 00:30:39,320
that's local or as local as it can be to

00:30:37,580 --> 00:30:40,940
your users so that back and forth

00:30:39,320 --> 00:30:44,210
communication does not suffer from

00:30:40,940 --> 00:30:45,740
latency of doing a transatlantic data

00:30:44,210 --> 00:30:47,779
transfer which is what you're doing

00:30:45,740 --> 00:30:49,490
every time you're doing as a cell in

00:30:47,779 --> 00:30:51,559
that particular case one of the things

00:30:49,490 --> 00:30:54,500
to mention with SSL now that I'm talking

00:30:51,559 --> 00:30:57,919
about it is if you happen to buy your

00:30:54,500 --> 00:31:00,559
SSL certificate from some of the SSL

00:30:57,919 --> 00:31:03,320
vendors and those SSL vendors happen to

00:31:00,559 --> 00:31:04,070
be in a different geographic region than

00:31:03,320 --> 00:31:05,960
what you are

00:31:04,070 --> 00:31:07,820
they may be using something code a chain

00:31:05,960 --> 00:31:09,500
certificate which means you have to load

00:31:07,820 --> 00:31:11,029
their certificate in addition to your

00:31:09,500 --> 00:31:13,789
own in order for your certificate to

00:31:11,029 --> 00:31:15,649
validate and a lot of the smaller or

00:31:13,789 --> 00:31:17,630
even some of the medium-sized vendors

00:31:15,649 --> 00:31:19,880
don't consider the fact that all their

00:31:17,630 --> 00:31:22,610
users may not be in the same country as

00:31:19,880 --> 00:31:24,500
where the SSL vendor is so even your

00:31:22,610 --> 00:31:26,659
even though your SSL certificate may be

00:31:24,500 --> 00:31:28,250
local the chain certificate may be in a

00:31:26,659 --> 00:31:29,450
completely different part of the world

00:31:28,250 --> 00:31:31,250
so that's definitely one of the things

00:31:29,450 --> 00:31:33,919
to take a look at a little bit different

00:31:31,250 --> 00:31:36,740
from webstore overheads but certainly

00:31:33,919 --> 00:31:38,720
something to consider

00:31:36,740 --> 00:31:40,340
compression overhead so confession

00:31:38,720 --> 00:31:42,110
overhead really should not cause a

00:31:40,340 --> 00:31:43,760
problem in most cases the only thing you

00:31:42,110 --> 00:31:45,409
want to confirm is the compression

00:31:43,760 --> 00:31:47,539
doesn't add more than 10 to 20

00:31:45,409 --> 00:31:50,720
milliseconds to the speed of the request

00:31:47,539 --> 00:31:53,149
so it's pretty insignificant load if

00:31:50,720 --> 00:31:56,620
you're seeing more one of the things

00:31:53,149 --> 00:31:59,000
that could cause a problem is most

00:31:56,620 --> 00:32:01,460
compression implementations like mod

00:31:59,000 --> 00:32:04,010
gzip and Apache for example allow you to

00:32:01,460 --> 00:32:06,350
come to set the compression level and it

00:32:04,010 --> 00:32:08,330
usually goes from 1 to 9 where 1 means

00:32:06,350 --> 00:32:11,029
it's a most minimal level of compression

00:32:08,330 --> 00:32:13,580
9 is a maximum level of compression the

00:32:11,029 --> 00:32:15,019
reality is that in most cases the file

00:32:13,580 --> 00:32:17,690
size is not going to be very different

00:32:15,019 --> 00:32:20,149
but 9 a level which is a maximum level

00:32:17,690 --> 00:32:21,740
of compression can take in some cases up

00:32:20,149 --> 00:32:24,470
to twice as long to actually do the

00:32:21,740 --> 00:32:26,299
compression for next to no result so you

00:32:24,470 --> 00:32:28,940
actually want to set the compression

00:32:26,299 --> 00:32:31,250
level to 1/2 at the very maximum because

00:32:28,940 --> 00:32:33,590
after that the value getting from the

00:32:31,250 --> 00:32:35,539
extra processing of having to do more

00:32:33,590 --> 00:32:40,580
elaborate compression really doesn't

00:32:35,539 --> 00:32:43,549
make that much of a difference so now we

00:32:40,580 --> 00:32:46,490
get to actual PHP so there's a number of

00:32:43,549 --> 00:32:48,409
different ways to profile PHP one of the

00:32:46,490 --> 00:32:51,320
tools that I strongly recommend the

00:32:48,409 --> 00:32:54,169
something code xh prof how many people

00:32:51,320 --> 00:32:56,510
have heard of xh prof okay so a lot of

00:32:54,169 --> 00:33:00,049
you have how many have you used xh prof

00:32:56,510 --> 00:33:01,669
okay slight with your hands so xh prof

00:33:00,049 --> 00:33:04,220
is basically it's a very lightweight

00:33:01,669 --> 00:33:06,860
profiler originally designed by folks at

00:33:04,220 --> 00:33:09,169
facebook and the whole goal this

00:33:06,860 --> 00:33:11,850
profiler is to minimize the overhead and

00:33:09,169 --> 00:33:13,379
actually be able to do profiling in a

00:33:11,850 --> 00:33:14,879
production environment you're not

00:33:13,379 --> 00:33:17,369
necessarily going to profile every

00:33:14,879 --> 00:33:18,809
single application instance because you

00:33:17,369 --> 00:33:20,669
don't want to slow down every single

00:33:18,809 --> 00:33:22,919
user but you can turn it down on a few

00:33:20,669 --> 00:33:25,679
application servers with a relatively

00:33:22,919 --> 00:33:28,529
minimal overhead and the beauty of XH

00:33:25,679 --> 00:33:30,809
profit like tools like X debug for

00:33:28,529 --> 00:33:32,970
example that also includes profiler is

00:33:30,809 --> 00:33:35,100
it's able to aggregate a multitude of

00:33:32,970 --> 00:33:37,259
requests into a single report so you're

00:33:35,100 --> 00:33:38,700
not basing your profile on a single

00:33:37,259 --> 00:33:40,350
request which could be affected by a

00:33:38,700 --> 00:33:42,119
variety of different things happening in

00:33:40,350 --> 00:33:44,789
a server but you can actually do the

00:33:42,119 --> 00:33:46,049
profiling on the basis of any number of

00:33:44,789 --> 00:33:49,320
requests actually coming out of

00:33:46,049 --> 00:33:50,820
production or test environment now exit

00:33:49,320 --> 00:33:52,619
froth comes in two pieces so you have

00:33:50,820 --> 00:33:54,479
the PHP extension which is what

00:33:52,619 --> 00:33:56,820
something you can get from pecco and you

00:33:54,479 --> 00:33:59,039
also have the visualizer which you can

00:33:56,820 --> 00:33:59,489
grab from another person paul rhine

00:33:59,039 --> 00:34:01,859
heimer

00:33:59,489 --> 00:34:03,749
on github which actually gives you a

00:34:01,859 --> 00:34:06,299
nice thing which will draw graphs and

00:34:03,749 --> 00:34:09,750
allow you to more easily be able to

00:34:06,299 --> 00:34:11,760
interpret the information so to start

00:34:09,750 --> 00:34:14,129
the profiling is actually quite simple

00:34:11,760 --> 00:34:17,339
and that may show you one of the tricks

00:34:14,129 --> 00:34:19,139
that are possible in PHP so in PHP you

00:34:17,339 --> 00:34:21,240
have the setting code Auto prepend file

00:34:19,139 --> 00:34:23,040
and what it does is without modifying a

00:34:21,240 --> 00:34:24,899
single line of your PHP code it allows

00:34:23,040 --> 00:34:27,629
you to effectively do the same thing as

00:34:24,899 --> 00:34:30,030
include but inside every single file so

00:34:27,629 --> 00:34:32,790
into this include I loaded this code

00:34:30,030 --> 00:34:35,159
which is load all the configuration and

00:34:32,790 --> 00:34:37,470
all the elements coming from X H proof

00:34:35,159 --> 00:34:38,909
and then tell me profile the CPU and

00:34:37,470 --> 00:34:41,730
memory usage and then enable the

00:34:38,909 --> 00:34:43,559
profiler and then at the end I have

00:34:41,730 --> 00:34:45,329
another file being loaded via auto

00:34:43,559 --> 00:34:46,980
append file which is going to do an

00:34:45,329 --> 00:34:49,200
include at the end of the file and that

00:34:46,980 --> 00:34:50,809
is going to disable the profiler because

00:34:49,200 --> 00:34:53,159
you don't want to profile the profiler

00:34:50,809 --> 00:34:55,200
it's going to aggregate the data and

00:34:53,159 --> 00:34:57,569
then save the data and by default it

00:34:55,200 --> 00:34:59,849
saves than a mile database so nowadays

00:34:57,569 --> 00:35:02,069
you could save it in sequel Lite or even

00:34:59,849 --> 00:35:04,349
MongoDB are the possible back-end where

00:35:02,069 --> 00:35:06,660
the data can be stored so literally

00:35:04,349 --> 00:35:08,640
without modifying a single line of your

00:35:06,660 --> 00:35:10,980
PHP application because changing code

00:35:08,640 --> 00:35:13,319
tends to break it you're able to

00:35:10,980 --> 00:35:14,760
introduce profiler into the application

00:35:13,319 --> 00:35:16,559
and when you don't need it anymore you

00:35:14,760 --> 00:35:19,730
just comment out these two directives

00:35:16,559 --> 00:35:23,369
and you're done so very very easy to

00:35:19,730 --> 00:35:25,450
enable and use this mechanism now exit

00:35:23,369 --> 00:35:27,220
prof has a variety of outputs

00:35:25,450 --> 00:35:29,680
this is basically a general summary

00:35:27,220 --> 00:35:31,390
screen it's going to give you some

00:35:29,680 --> 00:35:34,450
information like for example how many

00:35:31,390 --> 00:35:35,980
times a particular URL was executed so

00:35:34,450 --> 00:35:38,950
you can actually see the historical

00:35:35,980 --> 00:35:41,020
profile of what's going on it's going to

00:35:38,950 --> 00:35:43,390
give you the memory utilization which is

00:35:41,020 --> 00:35:45,010
you know a fairly important metric when

00:35:43,390 --> 00:35:47,619
it comes to PHP performance and

00:35:45,010 --> 00:35:49,780
scalability because there's only so much

00:35:47,619 --> 00:35:52,119
RAM available in your server

00:35:49,780 --> 00:35:54,310
although nowadays you can still still

00:35:52,119 --> 00:35:57,400
stick a couple of hundred gigabytes but

00:35:54,310 --> 00:35:59,770
it's can be exhausted very easily if a

00:35:57,400 --> 00:36:02,950
typical request takes almost 200 Meg's

00:35:59,770 --> 00:36:06,250
of memory to execute it gives you a

00:36:02,950 --> 00:36:08,680
breakdown of execution time also minimum

00:36:06,250 --> 00:36:10,780
maximum parameters and it actually can

00:36:08,680 --> 00:36:12,609
go as far as showing you the CPU time

00:36:10,780 --> 00:36:15,010
and the retailer gives you the breakdown

00:36:12,609 --> 00:36:16,780
of the to is because the execution time

00:36:15,010 --> 00:36:19,300
is a total time it took to execute the

00:36:16,780 --> 00:36:22,119
request the CPU time is how much time

00:36:19,300 --> 00:36:23,800
the actual CPU was spending to execute

00:36:22,119 --> 00:36:25,359
the request so the big difference

00:36:23,800 --> 00:36:27,640
between the two means you may be doing

00:36:25,359 --> 00:36:29,589
things like waiting on a lock or waiting

00:36:27,640 --> 00:36:31,780
for a database query to return your data

00:36:29,589 --> 00:36:33,310
so it takes longer for your request to

00:36:31,780 --> 00:36:35,319
execute but the actual application

00:36:33,310 --> 00:36:37,240
server is not doing any real work it's

00:36:35,319 --> 00:36:39,150
waiting for somebody to complete

00:36:37,240 --> 00:36:41,380
whatever it is they happen to be doing

00:36:39,150 --> 00:36:43,869
now one of the nice things about X

00:36:41,380 --> 00:36:45,819
debugger which is why you know people

00:36:43,869 --> 00:36:48,010
and management like it it can draw

00:36:45,819 --> 00:36:49,750
pretty graphs and by those graphs can be

00:36:48,010 --> 00:36:51,579
quite useful so this is actually a

00:36:49,750 --> 00:36:53,890
profile of the profiler

00:36:51,579 --> 00:36:57,810
so which part takes the most memory well

00:36:53,890 --> 00:37:00,400
it's our friend MySQL taking 2.5 million

00:36:57,810 --> 00:37:04,030
milliseconds to execute something within

00:37:00,400 --> 00:37:05,980
the page so any basically visually

00:37:04,030 --> 00:37:07,329
identifies really quickly what are the

00:37:05,980 --> 00:37:09,880
parts of the application you want to

00:37:07,329 --> 00:37:12,069
focus on now that is not to say you

00:37:09,880 --> 00:37:13,810
don't have you know the detailed per

00:37:12,069 --> 00:37:16,180
call statistics that you normally are

00:37:13,810 --> 00:37:17,740
used to see from a profiler what it

00:37:16,180 --> 00:37:20,230
tells you how long each individual

00:37:17,740 --> 00:37:23,170
function took to execute and so on but

00:37:20,230 --> 00:37:24,760
one of the really big payoffs especially

00:37:23,170 --> 00:37:26,290
if you have continuous integration or

00:37:24,760 --> 00:37:28,630
continuous code deployments that is

00:37:26,290 --> 00:37:31,000
possible with XH Prophecy historical

00:37:28,630 --> 00:37:33,160
analysis so this is one of the graphs

00:37:31,000 --> 00:37:35,020
that it generates so you can see okay we

00:37:33,160 --> 00:37:37,810
had a suboptimal application and made it

00:37:35,020 --> 00:37:39,310
faster then somebody decided to add some

00:37:37,810 --> 00:37:41,710
extra optimizations things

00:37:39,310 --> 00:37:43,510
didn't quite go according to plan then

00:37:41,710 --> 00:37:45,310
those optimizations were reverted and

00:37:43,510 --> 00:37:47,530
we're back to our optimal state which

00:37:45,310 --> 00:37:49,030
was achieved after the initial load and

00:37:47,530 --> 00:37:51,550
you have three lines which tells you

00:37:49,030 --> 00:37:53,860
memory utilization CPU usage and the

00:37:51,550 --> 00:37:55,330
overall request load time so pretty much

00:37:53,860 --> 00:37:57,490
everything you need to be able to see

00:37:55,330 --> 00:38:00,610
and track the performance of your

00:37:57,490 --> 00:38:04,600
application over time now one of the

00:38:00,610 --> 00:38:06,640
other really neat things that xh prof is

00:38:04,600 --> 00:38:08,560
able to do is if you install the call

00:38:06,640 --> 00:38:10,720
graph utility it's also able to generate

00:38:08,560 --> 00:38:12,280
your call graphs which in visual terms

00:38:10,720 --> 00:38:14,800
allow you to see the flow of the

00:38:12,280 --> 00:38:16,510
application to the slowest portion which

00:38:14,800 --> 00:38:18,520
is conveniently marked in red and the

00:38:16,510 --> 00:38:20,800
yellow path which is basically how the

00:38:18,520 --> 00:38:23,260
application got to the slowest portion

00:38:20,800 --> 00:38:25,270
of the request so once again it's trying

00:38:23,260 --> 00:38:27,580
to make things visual to make it as easy

00:38:25,270 --> 00:38:30,840
as possible to identify where are the

00:38:27,580 --> 00:38:35,320
bottlenecks are within the application

00:38:30,840 --> 00:38:36,820
now one of the problems with profiling

00:38:35,320 --> 00:38:39,460
especially in a production environment

00:38:36,820 --> 00:38:43,510
is profiling itself can be a bottleneck

00:38:39,460 --> 00:38:46,450
and as fast as xh prof may be the moment

00:38:43,510 --> 00:38:48,580
you enable it a request that took let's

00:38:46,450 --> 00:38:50,530
say a second to execute could easily now

00:38:48,580 --> 00:38:52,030
take two seconds to execute or maybe

00:38:50,530 --> 00:38:54,100
even two and a half if you're using

00:38:52,030 --> 00:38:56,440
things like X debug or some of the other

00:38:54,100 --> 00:38:58,450
profilers this can be a factor of five

00:38:56,440 --> 00:39:00,820
or six compared to the original request

00:38:58,450 --> 00:39:03,430
time so there are a couple of things

00:39:00,820 --> 00:39:05,350
that you can do to minimize the overhead

00:39:03,430 --> 00:39:07,480
of the profiler which do not involve

00:39:05,350 --> 00:39:09,850
optimizing the profiler itself that's a

00:39:07,480 --> 00:39:11,440
moot point and that is you can do

00:39:09,850 --> 00:39:13,450
statistical sampling so if you have

00:39:11,440 --> 00:39:15,580
multiple application servers enable the

00:39:13,450 --> 00:39:17,110
profiler on ten percent of them so

00:39:15,580 --> 00:39:20,080
you're not affecting the overall traffic

00:39:17,110 --> 00:39:22,150
and only those servers are going to do

00:39:20,080 --> 00:39:24,760
the profiling the other thing you can do

00:39:22,150 --> 00:39:26,920
is you can pre identify targets so you

00:39:24,760 --> 00:39:28,570
can use data from things like boomerang

00:39:26,920 --> 00:39:31,180
which tells you which pages take the

00:39:28,570 --> 00:39:33,250
longest to load focusing on the time it

00:39:31,180 --> 00:39:35,230
took to serve the HTML content which I

00:39:33,250 --> 00:39:37,150
was showing before and say only when

00:39:35,230 --> 00:39:38,890
it's this particular page only then

00:39:37,150 --> 00:39:40,240
enable the profiler because you want to

00:39:38,890 --> 00:39:42,610
figure out what's going on in those

00:39:40,240 --> 00:39:45,010
cases all other requests which right now

00:39:42,610 --> 00:39:46,540
are being served quickly enough you

00:39:45,010 --> 00:39:48,340
don't need to examine them at least for

00:39:46,540 --> 00:39:50,980
the point until they become the slowest

00:39:48,340 --> 00:39:52,570
part of your application the other trick

00:39:50,980 --> 00:39:53,080
you can do and this does require a bit

00:39:52,570 --> 00:39:54,610
more

00:39:53,080 --> 00:39:57,520
work is something called replay log

00:39:54,610 --> 00:39:59,590
profiling so if you configure your web

00:39:57,520 --> 00:40:02,140
server or your application in such a way

00:39:59,590 --> 00:40:04,240
that every single request and I mean the

00:40:02,140 --> 00:40:06,430
get content the post content whatever

00:40:04,240 --> 00:40:09,220
coming via cookies is going to be logged

00:40:06,430 --> 00:40:11,860
somewhere you can actually simulate what

00:40:09,220 --> 00:40:13,810
the user behavior was in a production

00:40:11,860 --> 00:40:16,570
environment by replaying that very

00:40:13,810 --> 00:40:18,970
detailed log file and that's one of the

00:40:16,570 --> 00:40:22,180
most reliable ways of simulating user

00:40:18,970 --> 00:40:23,920
behavior without actually putting any

00:40:22,180 --> 00:40:25,600
debugging code into production

00:40:23,920 --> 00:40:26,980
environment but that does mean that

00:40:25,600 --> 00:40:29,890
you're going to put some sort of a

00:40:26,980 --> 00:40:31,660
intercept layer into your typically the

00:40:29,890 --> 00:40:33,760
web server is the best place to do it

00:40:31,660 --> 00:40:35,290
to log every single parameter of the

00:40:33,760 --> 00:40:37,510
request and you literally need to log

00:40:35,290 --> 00:40:39,160
every single parameter request otherwise

00:40:37,510 --> 00:40:43,960
your simulation may not necessarily

00:40:39,160 --> 00:40:46,120
resemble reality so how can you pre

00:40:43,960 --> 00:40:50,200
identify profiling targets without even

00:40:46,120 --> 00:40:53,020
using boomerang so in Apache that's as

00:40:50,200 --> 00:40:55,630
simple as taking your log format which

00:40:53,020 --> 00:40:57,280
is a Apache configuration setting that

00:40:55,630 --> 00:40:58,960
allows you to say what do you want to

00:40:57,280 --> 00:41:01,750
log into the request and adding three

00:40:58,960 --> 00:41:07,870
parameters D IO not to be confused with

00:41:01,750 --> 00:41:09,670
the old metalbend so the D represents

00:41:07,870 --> 00:41:11,200
the processing time in milliseconds so

00:41:09,670 --> 00:41:14,320
that will tell you how much it actually

00:41:11,200 --> 00:41:16,810
took to process this request the I will

00:41:14,320 --> 00:41:19,210
tell you how big the request itself was

00:41:16,810 --> 00:41:21,220
so was there anything more complex in a

00:41:19,210 --> 00:41:22,600
request maybe it was a file upload so

00:41:21,220 --> 00:41:25,060
the reason it took so long is because

00:41:22,600 --> 00:41:27,460
there was all this time that took to you

00:41:25,060 --> 00:41:28,810
know receive the file and the o is the

00:41:27,460 --> 00:41:30,580
amount of data that was sent

00:41:28,810 --> 00:41:32,170
so maybe the request was slow because

00:41:30,580 --> 00:41:34,780
you decided to send ten megabytes of

00:41:32,170 --> 00:41:38,110
data to user it's possible for those of

00:41:34,780 --> 00:41:40,150
you not using Apache and using nginx you

00:41:38,110 --> 00:41:41,650
have the same thing except the format is

00:41:40,150 --> 00:41:44,590
a little bit different it uses log

00:41:41,650 --> 00:41:46,600
format lowercase and with underscore

00:41:44,590 --> 00:41:49,690
separator and you have a little bit more

00:41:46,600 --> 00:41:51,880
verbose settings bytes sent request

00:41:49,690 --> 00:41:54,100
length and the request time which

00:41:51,880 --> 00:41:59,110
basically give you the same data but in

00:41:54,100 --> 00:42:01,990
a context of nginx did I skip slide no

00:41:59,110 --> 00:42:03,430
we're good so one of the things that I

00:42:01,990 --> 00:42:05,590
promised in the beginning of the request

00:42:03,430 --> 00:42:06,260
as I was talking about PHP errors and I

00:42:05,590 --> 00:42:08,120
made this

00:42:06,260 --> 00:42:10,490
even that there are no harmless errors

00:42:08,120 --> 00:42:13,130
so here's a little sample of co2 have a

00:42:10,490 --> 00:42:15,080
function a which uses a uninitialized

00:42:13,130 --> 00:42:16,970
variable which is perfectly fine with in

00:42:15,080 --> 00:42:18,860
PHP context but it does generate a

00:42:16,970 --> 00:42:21,650
notice and then I have function B which

00:42:18,860 --> 00:42:24,920
does not do that now in order to make

00:42:21,650 --> 00:42:26,900
this a purely yes pure test as I can be

00:42:24,920 --> 00:42:30,380
I only set my error reporting to e error

00:42:26,900 --> 00:42:32,600
so I'm ignoring in notices which is what

00:42:30,380 --> 00:42:35,030
this is going to trigger and I'm doing

00:42:32,600 --> 00:42:37,010
this a hundred thousand times so when I

00:42:35,030 --> 00:42:39,290
execute the first function it takes a

00:42:37,010 --> 00:42:41,120
whooping 0.06 seconds basically

00:42:39,290 --> 00:42:43,130
statistically irrelevant I mean this is

00:42:41,120 --> 00:42:45,830
a hundred thousand runs when I do it

00:42:43,130 --> 00:42:47,930
without errors it takes you know a fifth

00:42:45,830 --> 00:42:50,450
of the time but who cares it's still

00:42:47,930 --> 00:42:52,910
very very quick there is however one

00:42:50,450 --> 00:42:54,590
little problem I mean doing this type of

00:42:52,910 --> 00:42:56,360
optimization would be firmly in the

00:42:54,590 --> 00:42:58,010
realm of you know micro optimizations

00:42:56,360 --> 00:43:01,040
and you don't want to do those those are

00:42:58,010 --> 00:43:02,810
typically a waste of time but if we

00:43:01,040 --> 00:43:04,490
modify this a little bit which is more

00:43:02,810 --> 00:43:06,710
resembling of a typical production

00:43:04,490 --> 00:43:08,450
environment I set my error reporting so

00:43:06,710 --> 00:43:10,010
I now get a all and he notice

00:43:08,450 --> 00:43:12,530
I don't display errors because that's

00:43:10,010 --> 00:43:15,260
bad but I also log my errors to files

00:43:12,530 --> 00:43:16,880
which most production systems do now at

00:43:15,260 --> 00:43:19,250
this point I actually had to reduce the

00:43:16,880 --> 00:43:20,900
number of runs that I'm doing to only a

00:43:19,250 --> 00:43:22,190
thousand because I was not patient

00:43:20,900 --> 00:43:24,350
enough to wait for a hundred thousand

00:43:22,190 --> 00:43:26,210
runs to complete at this point you can

00:43:24,350 --> 00:43:28,480
actually see that a hundred sorry a

00:43:26,210 --> 00:43:31,310
thousand instances of the error takes

00:43:28,480 --> 00:43:33,350
0.15 seconds which is already noticeable

00:43:31,310 --> 00:43:36,800
however without errors this takes zero

00:43:33,350 --> 00:43:39,800
point zero zero two so now we're talking

00:43:36,800 --> 00:43:41,390
about you know a fairly significant

00:43:39,800 --> 00:43:43,460
difference so in a production

00:43:41,390 --> 00:43:46,250
environment error start to count and

00:43:43,460 --> 00:43:48,080
I've seen a number of large usually with

00:43:46,250 --> 00:43:49,850
legacy applications that don't pay

00:43:48,080 --> 00:43:52,400
attention to things like II notice and

00:43:49,850 --> 00:43:55,040
now you have another error mode kody

00:43:52,400 --> 00:43:57,680
strict or deprecated which tells you

00:43:55,040 --> 00:44:01,490
about things that are about to leave PHP

00:43:57,680 --> 00:44:05,240
as syntax ignoring those can actually be

00:44:01,490 --> 00:44:06,830
a very noticeable source of performance

00:44:05,240 --> 00:44:08,630
issues in PHP and if you happen to log

00:44:06,830 --> 00:44:10,280
your errors into database well I

00:44:08,630 --> 00:44:11,660
wouldn't need a thousand runs probably

00:44:10,280 --> 00:44:14,600
about a hundred would do in order to

00:44:11,660 --> 00:44:17,030
make a noticeable difference so what you

00:44:14,600 --> 00:44:20,539
want to do is fix your errors now one of

00:44:17,030 --> 00:44:21,979
the tricks that I like to do

00:44:20,539 --> 00:44:24,949
and that usually gets all the errors

00:44:21,979 --> 00:44:27,890
fixed really quickly is make in PHP

00:44:24,949 --> 00:44:29,749
error handler and make that air handler

00:44:27,890 --> 00:44:31,429
treat every single error is fatal

00:44:29,749 --> 00:44:32,839
doesn't matter you notice he's strict

00:44:31,429 --> 00:44:34,969
whatever it's just going to exit the

00:44:32,839 --> 00:44:36,799
application say error has occurred that

00:44:34,969 --> 00:44:38,359
really encourages developers to fix

00:44:36,799 --> 00:44:39,979
their errors really quickly because no

00:44:38,359 --> 00:44:42,319
matter how minor the error is the

00:44:39,979 --> 00:44:47,359
application breaks you know effectively

00:44:42,319 --> 00:44:48,650
a simulation of a blue screen so let's

00:44:47,359 --> 00:44:50,449
talk a little bit about caching

00:44:48,650 --> 00:44:51,739
bottlenecks now this is one of the

00:44:50,449 --> 00:44:52,999
things a lot of people don't think about

00:44:51,739 --> 00:44:55,579
because the reason you're putting a

00:44:52,999 --> 00:44:57,919
caching system is to make things faster

00:44:55,579 --> 00:44:59,779
so why would the caching system slow

00:44:57,919 --> 00:45:03,319
things down well surprisingly enough it

00:44:59,779 --> 00:45:05,900
can I'm basing my example and some data

00:45:03,319 --> 00:45:07,609
from memcache D simply because when it

00:45:05,900 --> 00:45:09,529
comes to caching most people use

00:45:07,609 --> 00:45:12,679
memcache D that's sort of the prevalent

00:45:09,529 --> 00:45:14,390
solution nowadays so this is a data from

00:45:12,679 --> 00:45:16,130
the stat command from memcache D which

00:45:14,390 --> 00:45:18,199
gives you all sorts of statistics from

00:45:16,130 --> 00:45:20,959
memcache now the first thing you want to

00:45:18,199 --> 00:45:24,289
take a look at is am i maxing out the

00:45:20,959 --> 00:45:26,209
network on my memcache server so if you

00:45:24,289 --> 00:45:27,409
take the bytes redd+ bytes written and

00:45:26,209 --> 00:45:29,150
divided by uptime

00:45:27,409 --> 00:45:32,179
what is that throughput if that

00:45:29,150 --> 00:45:33,380
throughput is approaching the 10 megabit

00:45:32,179 --> 00:45:35,059
connection that you happen to be

00:45:33,380 --> 00:45:36,919
connecting your memcache server to your

00:45:35,059 --> 00:45:39,609
application server it's probably the

00:45:36,919 --> 00:45:42,199
time to upgrade and put a 1 gigabit

00:45:39,609 --> 00:45:44,029
network card or whatever into that

00:45:42,199 --> 00:45:48,769
particular machine because that's what's

00:45:44,029 --> 00:45:49,939
holding your application back now the

00:45:48,769 --> 00:45:52,999
other thing you want to take a look at

00:45:49,939 --> 00:45:55,130
is the our usage divided by the app time

00:45:52,999 --> 00:45:57,949
and that's the effectively the CPU usage

00:45:55,130 --> 00:45:59,719
that memcache is doing now memcache is

00:45:57,949 --> 00:46:01,429
not doing anything sophisticated all it

00:45:59,719 --> 00:46:05,749
is is putting key value pairs into

00:46:01,429 --> 00:46:07,969
memory so if that is more than 1% you

00:46:05,749 --> 00:46:13,039
must be doing something really really

00:46:07,969 --> 00:46:16,249
creative the other thing you want to

00:46:13,039 --> 00:46:18,919
take a look at is the art usage user

00:46:16,249 --> 00:46:20,569
divided by our usage system and that is

00:46:18,919 --> 00:46:23,449
the difference between how much time

00:46:20,569 --> 00:46:25,819
memcache is spending doing various tasks

00:46:23,449 --> 00:46:28,069
on its own versus how much it's doing in

00:46:25,819 --> 00:46:30,619
terms of i/o operations with the CPU

00:46:28,069 --> 00:46:34,250
once again if this ratio is greater than

00:46:30,619 --> 00:46:35,420
0.5 chances are you are having lock

00:46:34,250 --> 00:46:37,280
contention which means you're trying

00:46:35,420 --> 00:46:38,840
having multiple requests trying to write

00:46:37,280 --> 00:46:40,730
or modify the same block and that's

00:46:38,840 --> 00:46:43,010
slowing down memcache because it's

00:46:40,730 --> 00:46:45,170
sitting and trying to resolve locks

00:46:43,010 --> 00:46:47,630
instead of sending the data back so

00:46:45,170 --> 00:46:49,400
that's a very important parameter to

00:46:47,630 --> 00:46:51,230
send especially if you have busy servers

00:46:49,400 --> 00:46:52,340
because lock contention it's one of

00:46:51,230 --> 00:46:53,990
those things it doesn't matter if you

00:46:52,340 --> 00:46:55,400
have a hundred application servers in

00:46:53,990 --> 00:46:57,200
fact the more application servers you

00:46:55,400 --> 00:46:59,960
have the slower things become not faster

00:46:57,200 --> 00:47:02,240
from a lock contention point of view it

00:46:59,960 --> 00:47:03,980
also be caused by a network overhead but

00:47:02,240 --> 00:47:06,560
that's more of a rare scenario it's

00:47:03,980 --> 00:47:09,050
because you know that means that it can

00:47:06,560 --> 00:47:10,880
send data to the application server fast

00:47:09,050 --> 00:47:14,020
enough usually it is a lock contention

00:47:10,880 --> 00:47:15,980
that would cause that ratio to be upset

00:47:14,020 --> 00:47:17,690
now the other thing you want to take a

00:47:15,980 --> 00:47:19,880
look at is a number of total connections

00:47:17,690 --> 00:47:21,650
now mem kept memcache connections are

00:47:19,880 --> 00:47:24,530
pretty quick but they still have an

00:47:21,650 --> 00:47:26,390
overhead so if your consequence you to

00:47:24,530 --> 00:47:28,160
talk to memcache consider using

00:47:26,390 --> 00:47:29,870
persistent connections where PHP does

00:47:28,160 --> 00:47:32,510
not need to open a connection to

00:47:29,870 --> 00:47:33,650
memcache every single time the other

00:47:32,510 --> 00:47:36,830
thing you want to take a look at is a

00:47:33,650 --> 00:47:39,020
ratio of get misses to get hits meaning

00:47:36,830 --> 00:47:41,210
how many times you try to fetch

00:47:39,020 --> 00:47:43,730
something from cache and you get nothing

00:47:41,210 --> 00:47:47,180
which is equivalent if I get miss so if

00:47:43,730 --> 00:47:49,670
your ratio is greater than 10% you

00:47:47,180 --> 00:47:52,940
really need to examine how you're using

00:47:49,670 --> 00:47:54,320
the caching mechanism because you know

00:47:52,940 --> 00:47:56,390
your caching things that you shouldn't

00:47:54,320 --> 00:47:58,670
be caching because most of the time the

00:47:56,390 --> 00:48:00,920
data is not in cache so maybe a caching

00:47:58,670 --> 00:48:02,420
data that changes so frequently that you

00:48:00,920 --> 00:48:02,780
write it and then you have to retrieve

00:48:02,420 --> 00:48:04,820
it

00:48:02,780 --> 00:48:06,200
you know only once or you never ended up

00:48:04,820 --> 00:48:08,990
retrieving and when you try to get it

00:48:06,200 --> 00:48:11,480
it's not there the other ratio I want to

00:48:08,990 --> 00:48:13,460
take a look at is evictions weenie times

00:48:11,480 --> 00:48:15,830
memcache has to clear data out of memory

00:48:13,460 --> 00:48:17,510
versus how many times you write data to

00:48:15,830 --> 00:48:21,440
memory again you're looking for that

00:48:17,510 --> 00:48:23,570
magic 0.1 or 10% ratio if it's higher

00:48:21,440 --> 00:48:25,490
than that chances are you didn't give

00:48:23,570 --> 00:48:27,350
memcache enough memory so the garbage

00:48:25,490 --> 00:48:29,030
collector inside memcache says well I

00:48:27,350 --> 00:48:30,530
got to clean up some stuff because

00:48:29,030 --> 00:48:32,540
there's not enough memory for me to

00:48:30,530 --> 00:48:34,840
write new data because that's what

00:48:32,540 --> 00:48:37,370
memcache is going to do when you

00:48:34,840 --> 00:48:40,040
basically run out of RAM it's not going

00:48:37,370 --> 00:48:41,270
to say no to writing more data it's

00:48:40,040 --> 00:48:42,740
simply going to throw something out of

00:48:41,270 --> 00:48:45,610
memory so you want to make sure that

00:48:42,740 --> 00:48:48,380
doesn't happen very frequently

00:48:45,610 --> 00:48:50,000
so databases you know when it comes to

00:48:48,380 --> 00:48:51,890
performance databases usually are the

00:48:50,000 --> 00:48:53,360
first thing people start with in our

00:48:51,890 --> 00:48:56,960
case it was the last thing that we're

00:48:53,360 --> 00:48:59,810
getting to so databases are you know

00:48:56,960 --> 00:49:01,640
truly in many cases can be the big

00:48:59,810 --> 00:49:03,590
source of bottlenecks simply because if

00:49:01,640 --> 00:49:05,720
you don't have the right indexes you can

00:49:03,590 --> 00:49:06,680
write data into a database initially and

00:49:05,720 --> 00:49:08,870
it's going to be pretty quick because

00:49:06,680 --> 00:49:11,030
it's quickly in memory but as you write

00:49:08,870 --> 00:49:12,890
more and more data the database gets

00:49:11,030 --> 00:49:15,800
exponentially not progressively but

00:49:12,890 --> 00:49:17,060
exponentially slower so you always want

00:49:15,800 --> 00:49:19,910
to monitor what's going on with the

00:49:17,060 --> 00:49:21,260
database so in my sequel it means two

00:49:19,910 --> 00:49:23,960
things first of all you always want to

00:49:21,260 --> 00:49:25,460
log your slow queries the other thing is

00:49:23,960 --> 00:49:27,950
that you actually want to define what

00:49:25,460 --> 00:49:30,710
does a slow query mean for some strange

00:49:27,950 --> 00:49:33,320
reason MySQL says the default timing for

00:49:30,710 --> 00:49:34,550
slow query is ten seconds well if you're

00:49:33,320 --> 00:49:36,560
going to have a slow query of ten

00:49:34,550 --> 00:49:39,230
seconds in a web applications you have a

00:49:36,560 --> 00:49:41,390
serious problem so you definitely want

00:49:39,230 --> 00:49:43,070
to set this value to one second so that

00:49:41,390 --> 00:49:44,840
it's a little bit more practical in a

00:49:43,070 --> 00:49:46,400
context of the application because most

00:49:44,840 --> 00:49:48,590
web applications are going to need more

00:49:46,400 --> 00:49:50,570
than one query in order to execute the

00:49:48,590 --> 00:49:53,030
page so having one take a second is

00:49:50,570 --> 00:49:54,950
already a little bit concerning the

00:49:53,030 --> 00:49:56,960
other nice thing you can do in MySQL is

00:49:54,950 --> 00:49:59,390
you can enable this flag code log

00:49:56,960 --> 00:50:01,550
queries not using indexes so anytime you

00:49:59,390 --> 00:50:03,170
fire a query and no index is being used

00:50:01,550 --> 00:50:05,090
it's actually going to log that query

00:50:03,170 --> 00:50:06,620
and a benefit of that especially for

00:50:05,090 --> 00:50:08,360
applications that are just starting is

00:50:06,620 --> 00:50:10,220
that you can identify all the queries

00:50:08,360 --> 00:50:11,840
not using indexes before they become

00:50:10,220 --> 00:50:14,180
problems and you have so much data there

00:50:11,840 --> 00:50:16,970
all of a sudden you know the application

00:50:14,180 --> 00:50:18,620
or website just stops because you know

00:50:16,970 --> 00:50:21,800
it's waiting for some data to get

00:50:18,620 --> 00:50:24,170
processed now Maya ski also has some

00:50:21,800 --> 00:50:26,240
wonderful statistics that I had to use

00:50:24,170 --> 00:50:28,580
real really small font and actually have

00:50:26,240 --> 00:50:30,170
to truncate it but the bottom line is to

00:50:28,580 --> 00:50:31,940
give you something like 300 different

00:50:30,170 --> 00:50:33,490
data points telling you what's going on

00:50:31,940 --> 00:50:36,200
with a data base at any given point

00:50:33,490 --> 00:50:38,240
suffice to say in order for me to go

00:50:36,200 --> 00:50:40,610
through those I probably need a full day

00:50:38,240 --> 00:50:42,170
tutorial and I'd still not be oh you

00:50:40,610 --> 00:50:44,300
know done with all those settings and if

00:50:42,170 --> 00:50:46,580
using post gray or any other database

00:50:44,300 --> 00:50:48,890
there's many more settings so if you

00:50:46,580 --> 00:50:52,130
have problems with the database you know

00:50:48,890 --> 00:50:54,440
get a book that's pretty much the

00:50:52,130 --> 00:50:57,200
solution now when it comes to MySQL

00:50:54,440 --> 00:50:59,119
there are a couple of resources there's

00:50:57,200 --> 00:51:01,190
something called MySQL performance blog

00:50:59,119 --> 00:51:03,529
it's run by a guy called Peter Zaitsev

00:51:01,190 --> 00:51:06,289
and he is a really clever guy who knows

00:51:03,529 --> 00:51:07,309
the ins and outs of MySQL like a back of

00:51:06,289 --> 00:51:09,200
his hand

00:51:07,309 --> 00:51:10,999
there's also planet MySQL and planet

00:51:09,200 --> 00:51:13,670
Postgres for the few of you using

00:51:10,999 --> 00:51:15,079
Postgres I'm one of those people and

00:51:13,670 --> 00:51:16,489
there's a lot of people who work with

00:51:15,079 --> 00:51:18,769
the databases and they frequently not

00:51:16,489 --> 00:51:20,479
published a lot of blogs materials you

00:51:18,769 --> 00:51:22,099
know various little things they came

00:51:20,479 --> 00:51:25,099
across to help you improve the

00:51:22,099 --> 00:51:26,779
performance of the database and yes a

00:51:25,099 --> 00:51:31,160
bit of luck when it comes to database

00:51:26,779 --> 00:51:32,660
performance never hurts now one of the

00:51:31,160 --> 00:51:34,219
things that you want to watch as you're

00:51:32,660 --> 00:51:36,140
doing your benchmark tests when I

00:51:34,219 --> 00:51:38,630
mentioned a couple of times when we were

00:51:36,140 --> 00:51:41,509
profiling the web server is you want to

00:51:38,630 --> 00:51:43,880
watch your i/o now Linux by default has

00:51:41,509 --> 00:51:46,219
a wonderful tool called VM stats it

00:51:43,880 --> 00:51:48,710
gives you this information which is

00:51:46,219 --> 00:51:50,779
pretty much I like to call it machine

00:51:48,710 --> 00:51:52,519
readable it's not intended for normal

00:51:50,779 --> 00:51:54,739
humans I mean it gives you all the right

00:51:52,519 --> 00:51:56,690
data but gotta help you if you actually

00:51:54,739 --> 00:51:59,630
need to understand and make sense of it

00:51:56,690 --> 00:52:01,369
all fortunately there is an alternate

00:51:59,630 --> 00:52:03,289
tool there is a tool called side R which

00:52:01,369 --> 00:52:05,359
is based on a library called Lipstadt

00:52:03,289 --> 00:52:07,670
grab and what it does it basically

00:52:05,359 --> 00:52:10,519
creates a top like utility which

00:52:07,670 --> 00:52:12,259
organizes a variety of the i/o and now

00:52:10,519 --> 00:52:15,319
in a more human readable fashion so you

00:52:12,259 --> 00:52:17,059
can see your CPU load memory load you

00:52:15,319 --> 00:52:19,099
can see how much memory is used how many

00:52:17,059 --> 00:52:21,529
processes are running what's going on in

00:52:19,099 --> 00:52:23,479
the network interface you can actually

00:52:21,529 --> 00:52:24,950
see how many I ops are happening like

00:52:23,479 --> 00:52:27,890
how many reads and writes are happening

00:52:24,950 --> 00:52:29,420
on disk and so on and one of the things

00:52:27,890 --> 00:52:32,390
that I did a while back I actually

00:52:29,420 --> 00:52:34,579
wrapped the Lipstadt grab inside a PHP

00:52:32,390 --> 00:52:36,710
extension that you can find on Peko so

00:52:34,579 --> 00:52:38,210
you can actually integrate gathering of

00:52:36,710 --> 00:52:40,009
statistics right from your PHP

00:52:38,210 --> 00:52:41,569
application so if side R for example

00:52:40,009 --> 00:52:44,719
doesn't give you the data that you want

00:52:41,569 --> 00:52:46,759
with maybe 30 or 40 lines of PHP code

00:52:44,719 --> 00:52:48,410
you can create your own version of it

00:52:46,759 --> 00:52:50,869
which could be a web panel telling you

00:52:48,410 --> 00:52:52,880
the statistics without having to you

00:52:50,869 --> 00:52:55,609
know execute the site or utility on a

00:52:52,880 --> 00:52:58,339
command line and then pipe the output to

00:52:55,609 --> 00:53:01,130
the web application so a handy little

00:52:58,339 --> 00:53:02,719
tool for doing it so that's all the

00:53:01,130 --> 00:53:04,640
slides that I have for you guys on this

00:53:02,719 --> 00:53:06,229
website this is my blog I'm going to

00:53:04,640 --> 00:53:07,940
pose the slides from this so if you

00:53:06,229 --> 00:53:10,249
didn't manage to capture any of many of

00:53:07,940 --> 00:53:11,809
the URLs that I've included you'll be

00:53:10,249 --> 00:53:12,230
able to download the slides and grab all

00:53:11,809 --> 00:53:15,109
the

00:53:12,230 --> 00:53:16,730
or else from there we're a little bit

00:53:15,109 --> 00:53:18,260
over time but I'm not getting kicked out

00:53:16,730 --> 00:53:21,700
of the room so if you guys have any

00:53:18,260 --> 00:53:21,700
questions fire away

00:53:22,510 --> 00:53:28,580
no questions all right you must really

00:53:26,690 --> 00:53:30,859
be interested in either keynote or then

00:53:28,580 --> 00:53:32,270
a much better job than I thought in

00:53:30,859 --> 00:53:34,910
terms of explaining all those topics

00:53:32,270 --> 00:53:37,330
there all right

00:53:34,910 --> 00:53:37,330

YouTube URL: https://www.youtube.com/watch?v=fGy9FAW1gj4


