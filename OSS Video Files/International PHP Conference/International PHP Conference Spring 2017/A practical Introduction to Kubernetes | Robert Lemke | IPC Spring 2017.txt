Title: A practical Introduction to Kubernetes | Robert Lemke | IPC Spring 2017
Publication date: 2019-01-23
Playlist: International PHP Conference Spring 2017
Description: 
	Robert Lemke (Flownative GmbH): Kubernetes is an open source system for automating deployment, operations, and scaling of containerized applications. It’s one of the promising options you have for deploying your container-based applications to the Internet. In this session we’ll take a look at the concepts of Kubernetes and then go trough all steps necessary to launch and maintain a real-world PHP application in your own Kubernetes cluster.
Captions: 
	00:00:03,180 --> 00:00:11,040
[Music]

00:00:06,020 --> 00:00:13,500
okay welcome everybody I'd really like

00:00:11,040 --> 00:00:15,599
to start this with a little prayer to

00:00:13,500 --> 00:00:18,779
the demo gods but I don't know which

00:00:15,599 --> 00:00:21,210
language they speak because I'll go to

00:00:18,779 --> 00:00:23,550
do a lot of things live and you know

00:00:21,210 --> 00:00:25,830
with the internet stuff and so on let's

00:00:23,550 --> 00:00:29,730
let's just hope that everything works

00:00:25,830 --> 00:00:34,190
out fine all right so welcome to the

00:00:29,730 --> 00:00:36,630
session about kubernetes this is to

00:00:34,190 --> 00:00:38,910
intended as as an introduction to

00:00:36,630 --> 00:00:42,120
kubernetes if you haven't used it before

00:00:38,910 --> 00:00:44,820
if you tried it before then you probably

00:00:42,120 --> 00:00:47,780
can ask some some questions and I can

00:00:44,820 --> 00:00:51,149
try to answer them I did anyone actually

00:00:47,780 --> 00:00:55,559
look into kubernetes already or started

00:00:51,149 --> 00:00:59,030
you didn't just wait okay looks like the

00:00:55,559 --> 00:01:05,460
right audience then and who has some

00:00:59,030 --> 00:01:12,810
experience with docker already who hates

00:01:05,460 --> 00:01:16,710
docker nobody here me sometimes okay I'm

00:01:12,810 --> 00:01:19,320
Robert most of the time I'm working in

00:01:16,710 --> 00:01:23,340
an open-source project like for 16 17

00:01:19,320 --> 00:01:27,360
years now nowadays it's an open source

00:01:23,340 --> 00:01:32,340
project called Neos neo CMS a very nice

00:01:27,360 --> 00:01:34,979
community and that is basically my

00:01:32,340 --> 00:01:39,360
background I'm a PHP developer but I was

00:01:34,979 --> 00:01:43,710
always curious about the server side as

00:01:39,360 --> 00:01:46,409
well the hosting part and when I started

00:01:43,710 --> 00:01:50,460
creating the initial parts of Neos and

00:01:46,409 --> 00:01:52,649
the flow framework I already started

00:01:50,460 --> 00:01:56,130
creating stuff which nowadays you would

00:01:52,649 --> 00:01:58,860
call and cloud native application so

00:01:56,130 --> 00:02:01,649
that brings me to closer to cloud and

00:01:58,860 --> 00:02:04,200
more specifically why I am so much into

00:02:01,649 --> 00:02:06,030
darker and kubernetes is that during the

00:02:04,200 --> 00:02:09,420
last two and a half years I've been

00:02:06,030 --> 00:02:12,150
working on platform as a service for

00:02:09,420 --> 00:02:13,340
nails which isn't launched publicly yet

00:02:12,150 --> 00:02:15,950
but

00:02:13,340 --> 00:02:17,870
I've been busy working with that a lot

00:02:15,950 --> 00:02:20,840
like with micro services and event

00:02:17,870 --> 00:02:24,709
sourcing and all that stuff in PHP and

00:02:20,840 --> 00:02:26,959
also a lot with kubernetes so I have

00:02:24,709 --> 00:02:29,180
nobody from the kubernetes core team or

00:02:26,959 --> 00:02:32,269
something I'm I'm just the passionate

00:02:29,180 --> 00:02:34,870
user but I think that's all fine to

00:02:32,269 --> 00:02:37,450
share my experience with you

00:02:34,870 --> 00:02:40,430
right that was the disclaimer I'm not

00:02:37,450 --> 00:02:43,310
like one of the official guys I'm also

00:02:40,430 --> 00:02:45,980
not affiliated with Google or any other

00:02:43,310 --> 00:02:48,920
project I'm going to show you it's just

00:02:45,980 --> 00:02:51,799
I tried a lot of things and I'll

00:02:48,920 --> 00:02:53,900
probably recommend you a few things but

00:02:51,799 --> 00:02:55,670
that doesn't mean that that is the right

00:02:53,900 --> 00:02:59,660
thing for everyone of course it's just

00:02:55,670 --> 00:03:03,470
what my experience shows so how do you

00:02:59,660 --> 00:03:08,030
deploy PHP applications so just roughly

00:03:03,470 --> 00:03:12,340
who does mostly rely on manual steps or

00:03:08,030 --> 00:03:16,910
scripts or FTP SSH something like that

00:03:12,340 --> 00:03:24,310
yeah and who automated that and can form

00:03:16,910 --> 00:03:29,900
of Jenkins gitlab CI whatnot okay cool

00:03:24,310 --> 00:03:31,880
right so because containers I don't know

00:03:29,900 --> 00:03:33,950
it's I won't talk too much about

00:03:31,880 --> 00:03:37,280
containers because you all know docker

00:03:33,950 --> 00:03:39,790
right but I think docker is not just

00:03:37,280 --> 00:03:43,010
some some way to have some lightweight

00:03:39,790 --> 00:03:44,389
virtualization but the really cool thing

00:03:43,010 --> 00:03:47,630
about docker

00:03:44,389 --> 00:03:50,569
is that we kind of reached a standard

00:03:47,630 --> 00:03:53,590
for containers container images how to

00:03:50,569 --> 00:03:59,180
run them how to stop them how to monitor

00:03:53,590 --> 00:04:02,480
the basic metrics like RAM usage CPU and

00:03:59,180 --> 00:04:05,120
so on and that is really what what makes

00:04:02,480 --> 00:04:07,720
darker at the moment are some some of

00:04:05,120 --> 00:04:11,090
the few other container frameworks very

00:04:07,720 --> 00:04:14,030
interesting and of course containers are

00:04:11,090 --> 00:04:18,650
much easier to ship than any non

00:04:14,030 --> 00:04:21,109
standardized format and you could for

00:04:18,650 --> 00:04:23,450
example use some other package manager

00:04:21,109 --> 00:04:26,900
like Debian or whatever to ship your

00:04:23,450 --> 00:04:29,479
application but that lacks the

00:04:26,900 --> 00:04:32,060
part like for example telling something

00:04:29,479 --> 00:04:35,810
about the resource consumption and so on

00:04:32,060 --> 00:04:38,960
so it's just just a package and docker

00:04:35,810 --> 00:04:41,479
is basically like a container which has

00:04:38,960 --> 00:04:46,870
its own electricity and air condition

00:04:41,479 --> 00:04:49,639
and GPS system and so on you know so

00:04:46,870 --> 00:04:52,009
deploying applications with something

00:04:49,639 --> 00:04:55,940
like kubernetes is really interesting

00:04:52,009 --> 00:04:59,060
and awesome so just wanted to make that

00:04:55,940 --> 00:05:01,820
clear that don't see darker as

00:04:59,060 --> 00:05:04,760
virtualization technology it's it is

00:05:01,820 --> 00:05:07,340
more lightweight than like a virtual

00:05:04,760 --> 00:05:12,139
machine but it can do much more awesome

00:05:07,340 --> 00:05:14,030
stuff okay so it's it's not always easy

00:05:12,139 --> 00:05:16,630
to deal with containers who's using

00:05:14,030 --> 00:05:22,960
docker in production

00:05:16,630 --> 00:05:27,199
ok who lost data so Isis it's at least

00:05:22,960 --> 00:05:29,930
you know that that it is of was at least

00:05:27,199 --> 00:05:32,210
a very bumpy ride and I don't know what

00:05:29,930 --> 00:05:34,849
the future will bring it's still not I

00:05:32,210 --> 00:05:36,979
I'm still not confident that docker will

00:05:34,849 --> 00:05:40,639
be there in five years from now maybe it

00:05:36,979 --> 00:05:42,740
is they maybe it isn't but I think it's

00:05:40,639 --> 00:05:46,159
not so important actually because

00:05:42,740 --> 00:05:50,000
fortunately the whole community reached

00:05:46,159 --> 00:05:53,690
a consensus on let's abstract that

00:05:50,000 --> 00:05:56,599
container technology and build something

00:05:53,690 --> 00:05:59,120
more important on top of it so if for

00:05:56,599 --> 00:06:01,490
some reason Dhaka should go away at some

00:05:59,120 --> 00:06:04,340
point that doesn't really matter because

00:06:01,490 --> 00:06:06,440
the movement about containers and

00:06:04,340 --> 00:06:08,870
orchestration is so strong already that

00:06:06,440 --> 00:06:14,750
we could just use a different container

00:06:08,870 --> 00:06:18,349
technology but to be honest it's not so

00:06:14,750 --> 00:06:20,750
easy to find a reliable production

00:06:18,349 --> 00:06:23,210
environment for running docker and so on

00:06:20,750 --> 00:06:25,789
you still have to know much about which

00:06:23,210 --> 00:06:29,690
Linux kernel patches do you need to have

00:06:25,789 --> 00:06:31,880
to apply it and so on so but I'll get

00:06:29,690 --> 00:06:35,690
get about talk about the challenges a

00:06:31,880 --> 00:06:40,760
bit later so orchestration what is that

00:06:35,690 --> 00:06:43,580
actually just imagine all your doctor

00:06:40,760 --> 00:06:46,340
containers are parts of an orchestra so

00:06:43,580 --> 00:06:48,590
that means you don't tell them exactly

00:06:46,340 --> 00:06:51,020
what they need to do they can do that on

00:06:48,590 --> 00:06:54,110
their own but there needs to be someone

00:06:51,020 --> 00:06:57,380
who says okay now it's your part and now

00:06:54,110 --> 00:07:00,680
you please be a bit quieter and and so

00:06:57,380 --> 00:07:02,510
on so someone who oversees that

00:07:00,680 --> 00:07:05,120
everything plays nicely together and

00:07:02,510 --> 00:07:08,330
that is basically the idea of an

00:07:05,120 --> 00:07:11,770
Orchestrator and moseph specifically

00:07:08,330 --> 00:07:14,300
when you look at containers

00:07:11,770 --> 00:07:16,880
you don't need an Orchestrator if you

00:07:14,300 --> 00:07:20,060
want to run one container on one machine

00:07:16,880 --> 00:07:22,910
that really doesn't make sense it's also

00:07:20,060 --> 00:07:25,640
not efficient right because in order to

00:07:22,910 --> 00:07:31,430
run kubernetes you already need at least

00:07:25,640 --> 00:07:33,410
five servers only for kubernetes so it

00:07:31,430 --> 00:07:36,140
doesn't make sense if you only run one

00:07:33,410 --> 00:07:38,090
container right if you have two servers

00:07:36,140 --> 00:07:41,120
it also probably doesn't make sense

00:07:38,090 --> 00:07:43,820
because then you can run a for loop with

00:07:41,120 --> 00:07:46,610
bash scripts and and still get the same

00:07:43,820 --> 00:07:49,400
nice results but it gets very

00:07:46,610 --> 00:07:52,850
interesting if you do more than two

00:07:49,400 --> 00:07:55,700
servers and then there's no difference

00:07:52,850 --> 00:07:59,360
if you run your applications on three

00:07:55,700 --> 00:08:02,750
servers or in five thousand so in

00:07:59,360 --> 00:08:05,180
Orchestrator actually decides where to

00:08:02,750 --> 00:08:08,360
put in content and put a container if

00:08:05,180 --> 00:08:10,400
the machine goes away just dies or

00:08:08,360 --> 00:08:13,180
something it will relocate the container

00:08:10,400 --> 00:08:16,100
to some other machine it will make sure

00:08:13,180 --> 00:08:17,930
that traffic is going to the right

00:08:16,100 --> 00:08:24,320
containers and all all that stuff is

00:08:17,930 --> 00:08:28,840
done by an orchestration so something

00:08:24,320 --> 00:08:33,320
about kubernetes specifically so Google

00:08:28,840 --> 00:08:35,840
is like like other providers of course

00:08:33,320 --> 00:08:38,930
is providing something they call Google

00:08:35,840 --> 00:08:40,880
compute engine you know that from Amazon

00:08:38,930 --> 00:08:44,450
or some other providers so you basically

00:08:40,880 --> 00:08:45,860
can rent a virtual machine and you pay

00:08:44,450 --> 00:08:48,320
by the minute and you get a whole

00:08:45,860 --> 00:08:52,220
machine with one CPU or five or ten or

00:08:48,320 --> 00:08:53,870
whatever and so they launch that and

00:08:52,220 --> 00:08:56,810
then they looked at

00:08:53,870 --> 00:08:59,300
how these virtual machines were used and

00:08:56,810 --> 00:09:02,720
said like that is completely stupid they

00:08:59,300 --> 00:09:04,640
are idling a lot I mean yes we do earn

00:09:02,720 --> 00:09:06,529
money with it but it just doesn't make

00:09:04,640 --> 00:09:12,470
sense you know like that you have these

00:09:06,529 --> 00:09:16,490
15% CPU usage and we internally use a

00:09:12,470 --> 00:09:19,460
container system for 15 years so we

00:09:16,490 --> 00:09:23,180
should actually provide container

00:09:19,460 --> 00:09:24,200
technology to to those who currently

00:09:23,180 --> 00:09:29,360
Arend

00:09:24,200 --> 00:09:32,390
our virtual machines and that is

00:09:29,360 --> 00:09:34,820
actually a bit that is a slide from last

00:09:32,390 --> 00:09:39,490
year and I wondered if I should still

00:09:34,820 --> 00:09:44,480
keep it there's something called

00:09:39,490 --> 00:09:47,029
artisanal infrastructure or so that

00:09:44,480 --> 00:09:50,720
means yeah that's the nicer name

00:09:47,029 --> 00:09:54,490
previously it was called the Pats versus

00:09:50,720 --> 00:10:00,160
cattle paradigm anyone heard of that

00:09:54,490 --> 00:10:03,250
cats and paddle pets and cattle so

00:10:00,160 --> 00:10:06,709
imagine your server is like a pet right

00:10:03,250 --> 00:10:10,220
so it becomes part of your family you

00:10:06,709 --> 00:10:13,160
give it a nice name you care for it you

00:10:10,220 --> 00:10:15,170
are worried when feel sick and you get

00:10:13,160 --> 00:10:19,279
up at night when it screams and so on

00:10:15,170 --> 00:10:22,730
that's a pet right and the other idea

00:10:19,279 --> 00:10:24,470
about cattle service is you just buy 500

00:10:22,730 --> 00:10:26,720
of them and if some of them the highest

00:10:24,470 --> 00:10:31,670
you just buy some new they only have

00:10:26,720 --> 00:10:33,890
numbers right and yeah I said I I

00:10:31,670 --> 00:10:37,790
wondered if I should still have that

00:10:33,890 --> 00:10:41,660
slide I mean it's very it explains the

00:10:37,790 --> 00:10:44,000
idea and actually there was the concept

00:10:41,660 --> 00:10:47,360
in kubernetes which was called pet set

00:10:44,000 --> 00:10:50,000
just because of this paradigm and I

00:10:47,360 --> 00:10:52,330
think that was the biggest discussion

00:10:50,000 --> 00:10:55,700
and biggest backwards incompatible

00:10:52,330 --> 00:10:58,279
change they did during a beta phase they

00:10:55,700 --> 00:11:00,800
completely removed that name again just

00:10:58,279 --> 00:11:03,110
because of ethical constraints and and

00:11:00,800 --> 00:11:05,920
concerns so currently it's called

00:11:03,110 --> 00:11:05,920
stateless set

00:11:07,160 --> 00:11:11,540
yeah I like that quote from Vanna

00:11:09,170 --> 00:11:13,700
Fogle's from Amazon and so I

00:11:11,540 --> 00:11:17,140
service enough in my life and that do

00:11:13,700 --> 00:11:20,270
not have queue back they hate you so

00:11:17,140 --> 00:11:23,840
nowadays there's really there's no sense

00:11:20,270 --> 00:11:26,000
in caring for a specific server and you

00:11:23,840 --> 00:11:28,190
know running it installing an operating

00:11:26,000 --> 00:11:35,330
system on it and so on it just doesn't

00:11:28,190 --> 00:11:39,110
make sense anymore so the system Google

00:11:35,330 --> 00:11:42,640
has internally is called BARC and they

00:11:39,110 --> 00:11:45,380
yeah introduced it like 17 years ago and

00:11:42,640 --> 00:11:48,530
you need to imagine that everything

00:11:45,380 --> 00:11:51,890
Google is doing internally beard like

00:11:48,530 --> 00:11:55,460
Google search Google Mail or even the

00:11:51,890 --> 00:11:58,040
Google compute engine where they provide

00:11:55,460 --> 00:12:03,560
service to you is based on containers in

00:11:58,040 --> 00:12:08,540
Bach so that is kind of a planetary

00:12:03,560 --> 00:12:11,510
scale cluster for containers and it

00:12:08,540 --> 00:12:14,450
changed the way people are developing

00:12:11,510 --> 00:12:17,120
and working with applications a lot as

00:12:14,450 --> 00:12:20,480
you can imagine because previously you

00:12:17,120 --> 00:12:22,730
would develop something and try to

00:12:20,480 --> 00:12:27,020
specify what it needs and then talk to

00:12:22,730 --> 00:12:29,089
operations and I mean we have customers

00:12:27,020 --> 00:12:31,580
who don't have just one operations

00:12:29,089 --> 00:12:35,000
department but like seven one is

00:12:31,580 --> 00:12:37,490
specifically responsible for databases

00:12:35,000 --> 00:12:40,520
one for firewall and so on so you talk

00:12:37,490 --> 00:12:42,560
to all these departments and then agree

00:12:40,520 --> 00:12:46,700
on how you can deploy that software and

00:12:42,560 --> 00:12:50,210
so on and when you use containers what

00:12:46,700 --> 00:12:53,300
you do is with some configuration you

00:12:50,210 --> 00:12:57,290
specify I think that this application

00:12:53,300 --> 00:13:01,670
needs eight CPUs and that amount of RAM

00:12:57,290 --> 00:13:04,520
and for example it likes to be on a

00:13:01,670 --> 00:13:07,640
server which has a strong GPU yeah I

00:13:04,520 --> 00:13:09,560
need a very fast hard disk or I don't

00:13:07,640 --> 00:13:11,660
really need a very fast hard disk you

00:13:09,560 --> 00:13:14,570
just specify that in configuration and

00:13:11,660 --> 00:13:16,339
put it into the cluster and the

00:13:14,570 --> 00:13:19,869
orchestrator will make sure that it runs

00:13:16,339 --> 00:13:23,899
somewhere it doesn't really matter where

00:13:19,869 --> 00:13:26,029
and if that feels awkward to you like

00:13:23,899 --> 00:13:29,029
where is my application actually running

00:13:26,029 --> 00:13:30,799
on which server I mean when you run a

00:13:29,029 --> 00:13:34,189
process on your computer you have

00:13:30,799 --> 00:13:36,109
multiple cause of course does it really

00:13:34,189 --> 00:13:39,489
matter on which core your process is

00:13:36,109 --> 00:13:39,489
running you don't decide that right

00:13:39,579 --> 00:13:44,720
there's software which does that for you

00:13:42,529 --> 00:13:47,679
and that's just the same with containers

00:13:44,720 --> 00:13:51,559
it really doesn't matter where it is and

00:13:47,679 --> 00:13:53,480
by that you can use your whole

00:13:51,559 --> 00:13:57,109
infrastructure much more efficiently

00:13:53,480 --> 00:13:59,569
because you don't need servers for one

00:13:57,109 --> 00:14:01,999
specific application and service for

00:13:59,569 --> 00:14:03,980
production for testing for staging you

00:14:01,999 --> 00:14:05,809
don't need to isolate all that because

00:14:03,980 --> 00:14:10,279
it can run all in the same

00:14:05,809 --> 00:14:12,739
infrastructure and in fact when Google

00:14:10,279 --> 00:14:17,689
runs tests they have different classes

00:14:12,739 --> 00:14:19,519
of tests how big these tests are they

00:14:17,689 --> 00:14:23,059
actually run on the same infrastructure

00:14:19,519 --> 00:14:25,879
like the live production applications

00:14:23,059 --> 00:14:28,100
and the orchestrator will make sure that

00:14:25,879 --> 00:14:33,589
they are nicely isolated and get the

00:14:28,100 --> 00:14:36,949
right resources right so they had bog

00:14:33,589 --> 00:14:40,129
and only guys is kind of the successor

00:14:36,949 --> 00:14:44,179
of it so but then some of the developers

00:14:40,129 --> 00:14:46,759
came to us Hertzler the vice president

00:14:44,179 --> 00:14:51,049
of infrastructure and asked him how how

00:14:46,759 --> 00:14:54,949
about we just take these ideas and open

00:14:51,049 --> 00:14:58,100
sourced and wouldn't that be cool and I

00:14:54,949 --> 00:15:00,619
mean you can imagine that this is really

00:14:58,100 --> 00:15:02,739
part of the one one of the secrets of

00:15:00,619 --> 00:15:08,480
Google how they run their infrastructure

00:15:02,739 --> 00:15:13,449
and also to competing with companies

00:15:08,480 --> 00:15:16,699
like Amazon and so on but they actually

00:15:13,449 --> 00:15:21,470
convinced him and and so they didn't

00:15:16,699 --> 00:15:23,329
open-source Bork fortunately because as

00:15:21,470 --> 00:15:26,660
you can imagine it was a software which

00:15:23,329 --> 00:15:30,439
grew over 15 years and so on but what

00:15:26,660 --> 00:15:32,809
they did was some of the very developers

00:15:30,439 --> 00:15:33,529
who created bog and and some others as

00:15:32,809 --> 00:15:35,480
well

00:15:33,529 --> 00:15:38,019
just took all the concepts and the

00:15:35,480 --> 00:15:40,639
lessons learned and created a whole new

00:15:38,019 --> 00:15:45,410
open-source project on it and that is

00:15:40,639 --> 00:15:45,829
kubernetes it is not owned by Google

00:15:45,410 --> 00:15:48,889
anymore

00:15:45,829 --> 00:15:51,019
so nowadays kubernetes belongs to the

00:15:48,889 --> 00:15:52,509
cloud native computing foundation which

00:15:51,019 --> 00:15:55,220
is part of the Linux Foundation

00:15:52,509 --> 00:15:59,689
foundation and there are lots of

00:15:55,220 --> 00:16:02,149
companies involved it is the most active

00:15:59,689 --> 00:16:06,620
open-source project on github actually

00:16:02,149 --> 00:16:09,019
and I must say as a developer I mean I'm

00:16:06,620 --> 00:16:13,339
really not into go and and everything

00:16:09,019 --> 00:16:15,470
unfortunately but just from using it

00:16:13,339 --> 00:16:18,410
from seeing the API it's just a

00:16:15,470 --> 00:16:21,069
beautiful piece of software I is it's

00:16:18,410 --> 00:16:24,259
like the the wisdom of the people

00:16:21,069 --> 00:16:25,999
appears and what you see that and every

00:16:24,259 --> 00:16:28,730
time they ship a new features for me

00:16:25,999 --> 00:16:31,220
it's like Christmas anyway so there are

00:16:28,730 --> 00:16:34,370
of course alternatives there are other

00:16:31,220 --> 00:16:38,600
systems mezzos and andhaka swarm for

00:16:34,370 --> 00:16:40,670
example but they have really a different

00:16:38,600 --> 00:16:44,209
approach they concentrate much more in

00:16:40,670 --> 00:16:47,209
the infrastructure kubernetes is really

00:16:44,209 --> 00:16:51,319
a special thing and I think it's safe to

00:16:47,209 --> 00:16:56,019
say that kubernetes will be the thing to

00:16:51,319 --> 00:16:58,759
stay really as I said two days ago and

00:16:56,019 --> 00:17:01,040
that's not because I created that

00:16:58,759 --> 00:17:04,309
sentence but I think that kubernetes

00:17:01,040 --> 00:17:07,730
will be like for cloud hosting what

00:17:04,309 --> 00:17:11,299
Linux is for service now so it's it's a

00:17:07,730 --> 00:17:13,789
really cool thing okay so that wasn't

00:17:11,299 --> 00:17:17,299
very practical I promised that I would

00:17:13,789 --> 00:17:20,240
be practical your application runs in a

00:17:17,299 --> 00:17:22,459
cluster and the cluster consists of

00:17:20,240 --> 00:17:24,500
multiple machines which need an

00:17:22,459 --> 00:17:26,360
operating system but that operating

00:17:24,500 --> 00:17:28,580
system doesn't need to do very much in

00:17:26,360 --> 00:17:32,030
fact it would be good if it doesn't do

00:17:28,580 --> 00:17:35,409
anything at all besides running docker

00:17:32,030 --> 00:17:38,390
right and that is how most clusters are

00:17:35,409 --> 00:17:42,080
used you can use something like chorus

00:17:38,390 --> 00:17:44,659
or some specialized operating system

00:17:42,080 --> 00:17:46,370
like Rancho OS or whatever for example

00:17:44,659 --> 00:17:47,419
Google also introduced their own

00:17:46,370 --> 00:17:49,190
operating

00:17:47,419 --> 00:17:54,889
operating system for running their

00:17:49,190 --> 00:18:00,499
managed clusters the idea is just run

00:17:54,889 --> 00:18:04,299
docker and kubernetes and that's it okay

00:18:00,499 --> 00:18:07,070
besides this orchestration functionality

00:18:04,299 --> 00:18:09,259
kubernetes also does a few more things

00:18:07,070 --> 00:18:12,289
which are really nice and that is a way

00:18:09,259 --> 00:18:16,639
not complete of this list of course but

00:18:12,289 --> 00:18:18,710
it groups your containers so probably

00:18:16,639 --> 00:18:21,470
you know that from docker compose where

00:18:18,710 --> 00:18:25,220
you group containers into one thing that

00:18:21,470 --> 00:18:28,940
is called a part in kubernetes that

00:18:25,220 --> 00:18:34,009
group but it also does load balancing so

00:18:28,940 --> 00:18:36,049
any machine in Dhaka in kubernetes can

00:18:34,009 --> 00:18:39,259
receive traffic and route it to the

00:18:36,049 --> 00:18:43,190
right machine where your container needs

00:18:39,259 --> 00:18:45,950
to handle it and it is configurable it

00:18:43,190 --> 00:18:47,869
can have something like session affinity

00:18:45,950 --> 00:18:51,980
and and lots of things so there's a

00:18:47,869 --> 00:18:54,320
built-in load balancer it is auto

00:18:51,980 --> 00:18:56,330
healing as I said so it's constantly

00:18:54,320 --> 00:18:58,820
looking at your containers and metrics

00:18:56,330 --> 00:19:02,559
and so on will restart containers you

00:18:58,820 --> 00:19:05,749
can actually communicate with kubernetes

00:19:02,559 --> 00:19:08,600
by probes for example you say my

00:19:05,749 --> 00:19:10,730
application tells kubernetes when it's

00:19:08,600 --> 00:19:12,679
ready to receive traffic there's a

00:19:10,730 --> 00:19:14,690
readiness probe for that or my

00:19:12,679 --> 00:19:18,139
application has some health indicator

00:19:14,690 --> 00:19:20,539
aliveness probe where where your

00:19:18,139 --> 00:19:21,440
application tells like okay I think I'm

00:19:20,539 --> 00:19:25,779
going to die now

00:19:21,440 --> 00:19:29,090
just don't get me more traffic and for

00:19:25,779 --> 00:19:31,299
sure here scaling is also very

00:19:29,090 --> 00:19:34,070
sophisticated you have automatically

00:19:31,299 --> 00:19:37,029
horizontal scaling for containers

00:19:34,070 --> 00:19:40,460
depending on metrics you provide and

00:19:37,029 --> 00:19:44,509
lots of cool things so the backbone of

00:19:40,460 --> 00:19:48,519
all it is the r2 basically two networks

00:19:44,509 --> 00:19:52,759
and and that is of course software

00:19:48,519 --> 00:19:55,249
driven networks so the Internet is

00:19:52,759 --> 00:19:58,940
connected to your network somehow and

00:19:55,249 --> 00:20:01,620
will be able to access the different

00:19:58,940 --> 00:20:03,840
machines which are called nodes

00:20:01,620 --> 00:20:05,700
through some overlay Network and then

00:20:03,840 --> 00:20:08,789
there's some internal service network

00:20:05,700 --> 00:20:11,249
which is a completely different network

00:20:08,789 --> 00:20:14,490
isolated network where these machines

00:20:11,249 --> 00:20:20,279
can communicate with each other and with

00:20:14,490 --> 00:20:24,080
a kinetise master server so the cube

00:20:20,279 --> 00:20:28,080
master is basically provides a REST API

00:20:24,080 --> 00:20:30,929
to allow you to to launch containers

00:20:28,080 --> 00:20:33,629
configure everything that can be

00:20:30,929 --> 00:20:35,460
clustered of course as well and well

00:20:33,629 --> 00:20:38,840
there are lots of details how to run

00:20:35,460 --> 00:20:41,909
that but it's basically the API of

00:20:38,840 --> 00:20:44,909
kubernetes and the nodes

00:20:41,909 --> 00:20:46,649
I called minions right they just do the

00:20:44,909 --> 00:20:53,039
work and you can have lots of them

00:20:46,649 --> 00:20:54,990
thousands of them okay so I created a

00:20:53,039 --> 00:20:57,509
little hello world example for you in

00:20:54,990 --> 00:21:01,950
PHP and to see how that really works oh

00:20:57,509 --> 00:21:03,720
and by the way I measured the time so I

00:21:01,950 --> 00:21:05,580
think this is now the time where I

00:21:03,720 --> 00:21:08,549
actually need to start a cluster because

00:21:05,580 --> 00:21:13,289
I haven't prepared any cluster in let's

00:21:08,549 --> 00:21:20,129
see in green cloud container clusters

00:21:13,289 --> 00:21:23,610
create IPC 2017 let's say we start with

00:21:20,129 --> 00:21:26,970
two machines okay can you guys read that

00:21:23,610 --> 00:21:34,169
from behind yeah fine okay it's creating

00:21:26,970 --> 00:21:39,830
new plaster now very nice I hope it's

00:21:34,169 --> 00:21:44,610
finished in time okay you have your PHP

00:21:39,830 --> 00:21:47,610
application and you have some which is

00:21:44,610 --> 00:21:49,649
in one container probably right so like

00:21:47,610 --> 00:21:52,619
a data container so and then you have

00:21:49,649 --> 00:21:55,440
further containers based on images for

00:21:52,619 --> 00:21:59,999
something like nginx and PHP fpm and

00:21:55,440 --> 00:22:01,860
then you group that into one part and

00:21:59,999 --> 00:22:03,809
you can do the same with docker compose

00:22:01,860 --> 00:22:06,629
of course on the for development and

00:22:03,809 --> 00:22:11,970
that is your application and then you

00:22:06,629 --> 00:22:14,340
define that whole pod can be replicated

00:22:11,970 --> 00:22:16,320
and receives traffic on

00:22:14,340 --> 00:22:21,779
certain part like pod 80 or something

00:22:16,320 --> 00:22:24,150
right so for your application you can

00:22:21,779 --> 00:22:27,090
just define I start with one replica of

00:22:24,150 --> 00:22:30,840
my part or I need three or five or I

00:22:27,090 --> 00:22:36,900
change it along the way and then traffic

00:22:30,840 --> 00:22:40,260
is routed to each of you parts these

00:22:36,900 --> 00:22:43,950
parts within one part you have one

00:22:40,260 --> 00:22:46,830
shared network and shared volumes so

00:22:43,950 --> 00:22:50,100
that means any container within a part

00:22:46,830 --> 00:22:54,059
can reach any other parts network

00:22:50,100 --> 00:22:57,600
through localhost so if you put nginx

00:22:54,059 --> 00:23:02,520
and PHP fpm into one part and gen-x can

00:22:57,600 --> 00:23:06,120
just reach PHP fpm directly and it's not

00:23:02,520 --> 00:23:08,279
reachable from outside and then you can

00:23:06,120 --> 00:23:13,710
define that you want to expose a certain

00:23:08,279 --> 00:23:15,929
part to your overlay Network like nginx

00:23:13,710 --> 00:23:22,679
in this case so you wouldn't expose PHP

00:23:15,929 --> 00:23:24,960
fpm but nginx in this case right and one

00:23:22,679 --> 00:23:26,940
thing they introduced which they it

00:23:24,960 --> 00:23:30,080
didn't have in Borg which is very

00:23:26,940 --> 00:23:33,390
powerful our labels so each part and

00:23:30,080 --> 00:23:36,299
basically almost every other thing in in

00:23:33,390 --> 00:23:39,510
kubernetes can have multiple labels you

00:23:36,299 --> 00:23:43,230
give it a key and a value and then you

00:23:39,510 --> 00:23:48,390
can do selections you can say give me

00:23:43,230 --> 00:23:51,210
all parts where the label app is nails

00:23:48,390 --> 00:23:53,490
IO and where the label stage is

00:23:51,210 --> 00:23:57,809
production and then you can filter by it

00:23:53,490 --> 00:24:00,770
and run operations on it so that that is

00:23:57,809 --> 00:24:05,730
a very basic but very powerful feature

00:24:00,770 --> 00:24:08,760
and this whole thing can be called

00:24:05,730 --> 00:24:11,010
something like replica set so it's it

00:24:08,760 --> 00:24:15,330
says okay we have two replicas here of

00:24:11,010 --> 00:24:18,390
parts and with a certain label and they

00:24:15,330 --> 00:24:21,510
they form a logical group because they

00:24:18,390 --> 00:24:25,200
share the same label selector right so I

00:24:21,510 --> 00:24:27,480
call this my so imagine there would be

00:24:25,200 --> 00:24:28,500
another label production I would have

00:24:27,480 --> 00:24:30,450
one replica set

00:24:28,500 --> 00:24:32,310
for production and another for staging

00:24:30,450 --> 00:24:35,010
and the difference is just that the

00:24:32,310 --> 00:24:41,940
parts have different labels but I can

00:24:35,010 --> 00:24:44,190
address them differently now in order to

00:24:41,940 --> 00:24:47,580
to launch all that I can theoretically

00:24:44,190 --> 00:24:50,280
just run a part but then I am

00:24:47,580 --> 00:24:54,510
responsible for stopping it and and so

00:24:50,280 --> 00:24:57,450
on what I really want is some mechanism

00:24:54,510 --> 00:25:01,770
in kubernetes to take care for me - that

00:24:57,450 --> 00:25:04,560
that amount of replica that amount of

00:25:01,770 --> 00:25:07,650
parts actually is running so when as I

00:25:04,560 --> 00:25:10,260
said when one machine dies then the

00:25:07,650 --> 00:25:12,740
mechanism called replica set or

00:25:10,260 --> 00:25:16,980
replication controller is another

00:25:12,740 --> 00:25:20,190
feature will always compare the amount

00:25:16,980 --> 00:25:24,210
of running part against the amount of

00:25:20,190 --> 00:25:26,400
desired parts and will fix it if there

00:25:24,210 --> 00:25:31,320
are too many it will kill some without a

00:25:26,400 --> 00:25:34,950
few it will start some by the way anyone

00:25:31,320 --> 00:25:41,880
has a question I saw some questionable

00:25:34,950 --> 00:25:43,710
faces or tired faces anyway if you have

00:25:41,880 --> 00:25:49,170
some you can you are allowed to write

00:25:43,710 --> 00:25:51,450
just ask right away so if you want to

00:25:49,170 --> 00:25:53,910
deploy from one version to another

00:25:51,450 --> 00:25:56,250
version there is a really nice mechanism

00:25:53,910 --> 00:25:59,130
for that which allows you to do rolling

00:25:56,250 --> 00:26:01,440
updates so imagine you have your

00:25:59,130 --> 00:26:03,630
application running with two parts in

00:26:01,440 --> 00:26:07,520
parallel so you automatically have load

00:26:03,630 --> 00:26:10,740
balancing and failover and so on

00:26:07,520 --> 00:26:13,350
actually you can even tell kubernetes to

00:26:10,740 --> 00:26:15,480
put these parts on different machines if

00:26:13,350 --> 00:26:19,470
possible so there's something called

00:26:15,480 --> 00:26:22,170
some some affinity mechanisms where I

00:26:19,470 --> 00:26:26,430
say please if possible try to distribute

00:26:22,170 --> 00:26:28,410
it across availability zones or don't

00:26:26,430 --> 00:26:28,800
put them on the same machine or things

00:26:28,410 --> 00:26:32,340
like that

00:26:28,800 --> 00:26:37,980
so that gives you stability and if you

00:26:32,340 --> 00:26:41,190
want to deploy version one one then you

00:26:37,980 --> 00:26:42,360
just change the deployment resource

00:26:41,190 --> 00:26:45,450
object kind of

00:26:42,360 --> 00:26:48,450
and kubernetes will not just stop

00:26:45,450 --> 00:26:50,580
everything and start anything but we'll

00:26:48,450 --> 00:26:53,760
create a new part of the new version and

00:26:50,580 --> 00:26:56,640
when that is running and the readiness

00:26:53,760 --> 00:26:59,100
probe is ready and so on we'll stop one

00:26:56,640 --> 00:27:01,050
of the old parts and then you have

00:26:59,100 --> 00:27:03,590
basically two versions running at the

00:27:01,050 --> 00:27:08,280
same time yeah

00:27:03,590 --> 00:27:10,310
imagine you have 10 or 50 replicas

00:27:08,280 --> 00:27:12,660
running then it will gradually

00:27:10,310 --> 00:27:15,800
transition from the old version to the

00:27:12,660 --> 00:27:18,330
new version and direct traffic to it of

00:27:15,800 --> 00:27:20,940
course your application should be able

00:27:18,330 --> 00:27:24,990
to to deal with that but there are some

00:27:20,940 --> 00:27:26,790
rather easy strategies to do that and if

00:27:24,990 --> 00:27:28,920
you can if your application can actually

00:27:26,790 --> 00:27:30,900
handle that that's just beautiful

00:27:28,920 --> 00:27:35,370
nobody will notice that you're rolling

00:27:30,900 --> 00:27:38,640
out a new update you can also stop it in

00:27:35,370 --> 00:27:41,610
the middle depending so for example when

00:27:38,640 --> 00:27:44,670
you see all my purchases on my shop by

00:27:41,610 --> 00:27:49,650
going down by 50% then you can stop your

00:27:44,670 --> 00:27:51,510
rolling deployment and see or actually

00:27:49,650 --> 00:27:56,000
roll back and see if it gets better and

00:27:51,510 --> 00:27:59,400
so on you can script all that okay so

00:27:56,000 --> 00:28:05,700
this up here is a incredible docker

00:27:59,400 --> 00:28:07,710
image I created it copies index.php into

00:28:05,700 --> 00:28:12,060
some directory and then runs the

00:28:07,710 --> 00:28:16,710
internal PHP web server to serve that

00:28:12,060 --> 00:28:19,950
and the index.php will just display its

00:28:16,710 --> 00:28:25,860
version number and the hostname where it

00:28:19,950 --> 00:28:28,590
is hosted and then the configuration for

00:28:25,860 --> 00:28:31,440
kubernetes there are two different

00:28:28,590 --> 00:28:34,020
versions I'm going to show you one is

00:28:31,440 --> 00:28:37,680
called a replication controller and the

00:28:34,020 --> 00:28:39,450
second is called a deployment so

00:28:37,680 --> 00:28:42,750
deployment is actually what you want to

00:28:39,450 --> 00:28:44,640
use in the future replication controller

00:28:42,750 --> 00:28:46,530
is still valid but it's the older

00:28:44,640 --> 00:28:52,110
concept so this is a replication

00:28:46,530 --> 00:28:55,470
controller it basically says okay up

00:28:52,110 --> 00:28:56,190
here it there's a specification which

00:28:55,470 --> 00:28:59,519
says I

00:28:56,190 --> 00:29:01,830
when one replica of the container

00:28:59,519 --> 00:29:06,960
I'm of the containers I'm going to

00:29:01,830 --> 00:29:09,149
explain you and in order to check if one

00:29:06,960 --> 00:29:12,570
container is running I need a selector

00:29:09,149 --> 00:29:14,850
which matches the labels of the part

00:29:12,570 --> 00:29:17,100
which is running so imagine there's a

00:29:14,850 --> 00:29:19,950
search query running all the time with

00:29:17,100 --> 00:29:22,649
this selector and if there are parts in

00:29:19,950 --> 00:29:25,950
the result list then everything is fine

00:29:22,649 --> 00:29:30,419
so these two must match the selector and

00:29:25,950 --> 00:29:34,080
the labels and it starts of course with

00:29:30,419 --> 00:29:36,360
zero parts and when it sees oh there are

00:29:34,080 --> 00:29:39,000
zero pots I need to create some and for

00:29:36,360 --> 00:29:40,740
that it needs a template and that's what

00:29:39,000 --> 00:29:42,929
you see in the second part here's a

00:29:40,740 --> 00:29:46,409
template how to create a new part of

00:29:42,929 --> 00:29:48,769
what I want to have first of all the

00:29:46,409 --> 00:29:52,590
labels and then comes the actual

00:29:48,769 --> 00:29:55,860
specification of which containers that

00:29:52,590 --> 00:29:59,429
part should consist like I need an

00:29:55,860 --> 00:30:02,009
engine X PHP fpm and my application of

00:29:59,429 --> 00:30:06,720
course this is a very simple one the

00:30:02,009 --> 00:30:13,470
specification just says I need one in a

00:30:06,720 --> 00:30:16,769
1 container running on this image ok

00:30:13,470 --> 00:30:21,120
ah I'd slept it needs some coffee

00:30:16,769 --> 00:30:23,370
you feed this one with coffee so now you

00:30:21,120 --> 00:30:25,700
have that pod running but how can you

00:30:23,370 --> 00:30:28,889
actually access it from the outside

00:30:25,700 --> 00:30:31,919
well you for that you'd use something

00:30:28,889 --> 00:30:34,980
called a service a service is something

00:30:31,919 --> 00:30:38,190
which has an IP address a stable IP

00:30:34,980 --> 00:30:40,230
address no matter if you I mean a part

00:30:38,190 --> 00:30:42,149
also has an internal IP address but that

00:30:40,230 --> 00:30:44,879
changes every time you start a new pod

00:30:42,149 --> 00:30:47,309
and and stop it pod you get a different

00:30:44,879 --> 00:30:49,679
IP address internally but the service

00:30:47,309 --> 00:30:52,350
has a stable IP address and also a

00:30:49,679 --> 00:30:54,409
stable dns name because kubernetes

00:30:52,350 --> 00:30:57,240
provides you with a DNS server

00:30:54,409 --> 00:31:01,590
internally and you can just use the name

00:30:57,240 --> 00:31:03,990
of the service to reach to get some

00:31:01,590 --> 00:31:09,149
traffic to it and this service here

00:31:03,990 --> 00:31:09,940
defines that it has one port 80 which is

00:31:09,149 --> 00:31:14,710
target

00:31:09,940 --> 00:31:16,509
to the pod 8080 in the container and the

00:31:14,710 --> 00:31:18,730
connection between the service and the

00:31:16,509 --> 00:31:22,210
pot is again done through selectors

00:31:18,730 --> 00:31:24,190
right so it's a really loose coupling

00:31:22,210 --> 00:31:26,769
you have the service there and that can

00:31:24,190 --> 00:31:29,799
live without parts and so on it will

00:31:26,769 --> 00:31:32,440
just not drought any traffic as long as

00:31:29,799 --> 00:31:35,440
there are no pots but if any parts are

00:31:32,440 --> 00:31:40,409
met matching the selector it will direct

00:31:35,440 --> 00:31:45,279
traffic to it and that can be tcp or UDP

00:31:40,409 --> 00:31:47,679
for all kinds of purposes and this here

00:31:45,279 --> 00:31:49,840
type load balancer is a nice thing if

00:31:47,679 --> 00:31:54,190
you have a certain cloud provider like

00:31:49,840 --> 00:31:56,470
for example google or AWS this means oh

00:31:54,190 --> 00:31:59,620
by the way could you please create me

00:31:56,470 --> 00:32:01,330
some external IP address and configure

00:31:59,620 --> 00:32:04,299
the firewall that this service is

00:32:01,330 --> 00:32:08,399
reachable from the internet that's just

00:32:04,299 --> 00:32:11,799
this line type load balancer please okay

00:32:08,399 --> 00:32:16,929
finally let's see if there's a cluster

00:32:11,799 --> 00:32:19,990
waiting for us yeah there is

00:32:16,929 --> 00:32:23,950
oh and there are updates for my tool

00:32:19,990 --> 00:32:28,179
they haven't been 30 minutes ago okay so

00:32:23,950 --> 00:32:31,529
we have a cluster running now with two

00:32:28,179 --> 00:32:35,679
nodes so what I'm doing first now is I

00:32:31,529 --> 00:32:37,870
start a little dashboard nice thing is

00:32:35,679 --> 00:32:39,460
kubernetes cluster already comes with a

00:32:37,870 --> 00:32:42,070
little dashboard where you can see which

00:32:39,460 --> 00:32:45,450
nodes exist which paths and so on so

00:32:42,070 --> 00:32:50,710
I'll just do that here there's a command

00:32:45,450 --> 00:32:53,320
line tool called cube control which

00:32:50,710 --> 00:32:55,179
allows you to run all kinds of commands

00:32:53,320 --> 00:32:55,710
for the API very convenient and nicely

00:32:55,179 --> 00:32:59,259
done

00:32:55,710 --> 00:33:03,129
so I say cube control I know first I

00:32:59,259 --> 00:33:12,279
need to get the credentials g-cloud

00:33:03,129 --> 00:33:16,889
container what was it like this so keep

00:33:12,279 --> 00:33:22,659
control proxy on port

00:33:16,889 --> 00:33:28,289
eighty eighty ninety nine and now let's

00:33:22,659 --> 00:33:28,289
see low cost eighty eighty ninety nine

00:33:33,520 --> 00:33:39,679
various internet fortunately so this is

00:33:37,309 --> 00:33:42,910
the little dashboard and you can see

00:33:39,679 --> 00:33:46,700
that we now have two nodes running and

00:33:42,910 --> 00:33:48,890
they they already consume some CPU

00:33:46,700 --> 00:33:50,510
because the dashboard is running there

00:33:48,890 --> 00:33:55,010
and some monitoring is automatically

00:33:50,510 --> 00:33:57,020
running there but here this tab workload

00:33:55,010 --> 00:34:00,410
says there is no container running and

00:33:57,020 --> 00:34:02,780
there the services tab says there's just

00:34:00,410 --> 00:34:10,580
one service running for kubernetes

00:34:02,780 --> 00:34:13,280
itself okay so that is running and now I

00:34:10,580 --> 00:34:20,690
the the files I've shown you I have they

00:34:13,280 --> 00:34:21,710
has actual files so let me do that this

00:34:20,690 --> 00:34:23,480
way

00:34:21,710 --> 00:34:27,770
the replication controller for example

00:34:23,480 --> 00:34:35,020
which I've shown you earlier I'll just

00:34:27,770 --> 00:34:35,020
apply that to our API server so

00:34:40,620 --> 00:34:46,350
okay let's see first of all there should

00:34:43,560 --> 00:34:50,580
be a replication controller right there

00:34:46,350 --> 00:34:53,460
is one and that replication controller

00:34:50,580 --> 00:34:57,300
is going to create a part the current

00:34:53,460 --> 00:35:00,000
status is container creating so and I

00:34:57,300 --> 00:35:07,530
can see details of it but currently it's

00:35:00,000 --> 00:35:09,390
not running so I can actually ask the

00:35:07,530 --> 00:35:13,590
command line tool to show me events

00:35:09,390 --> 00:35:16,860
happening there there you see for

00:35:13,590 --> 00:35:19,380
example events like okay the node is now

00:35:16,860 --> 00:35:25,560
running and so on that is all from from

00:35:19,380 --> 00:35:31,200
the startup and then you can also see

00:35:25,560 --> 00:35:34,410
hopefully then it's pulling the image

00:35:31,200 --> 00:35:36,450
and so on you see the events here and

00:35:34,410 --> 00:35:40,110
then it's hopefully running let's see is

00:35:36,450 --> 00:35:43,260
it running it's running and you can look

00:35:40,110 --> 00:35:45,540
at the logs but there are no logs yet so

00:35:43,260 --> 00:35:49,800
nice there is a container running but we

00:35:45,540 --> 00:35:53,150
can't access it yet so for that I create

00:35:49,800 --> 00:35:53,150
a service as I said

00:35:58,270 --> 00:36:07,810
so that service has now been created

00:36:00,610 --> 00:36:10,780
let's take a look so the service here

00:36:07,810 --> 00:36:13,780
shows me all parts which match the

00:36:10,780 --> 00:36:16,170
selector defined in the service so and

00:36:13,780 --> 00:36:20,950
that is called an end a service endpoint

00:36:16,170 --> 00:36:23,610
which means okay if if I would ask that

00:36:20,950 --> 00:36:29,470
service now with the internal IP address

00:36:23,610 --> 00:36:33,220
10:51 243 193 on port 80 it will

00:36:29,470 --> 00:36:35,980
actually get that traffic to my

00:36:33,220 --> 00:36:40,690
container which is running because it

00:36:35,980 --> 00:36:43,000
matches here what it does now is also

00:36:40,690 --> 00:36:45,010
acquire some external IP address so I

00:36:43,000 --> 00:36:49,240
can actually test it before we have that

00:36:45,010 --> 00:36:52,840
we can already access the part by using

00:36:49,240 --> 00:36:56,770
a nice command called port forward first

00:36:52,840 --> 00:37:00,820
of all I need to get the pot name which

00:36:56,770 --> 00:37:05,520
is this one here and then I can say okay

00:37:00,820 --> 00:37:11,260
please forward the port of that part and

00:37:05,520 --> 00:37:18,550
so I say 80 90 that will be my machine

00:37:11,260 --> 00:37:25,330
here to the container port 8080 so it's

00:37:18,550 --> 00:37:29,400
now doing that so when I access port 80

00:37:25,330 --> 00:37:33,280
90 I see my incredible index.php now and

00:37:29,400 --> 00:37:34,990
just think about that for a second you

00:37:33,280 --> 00:37:36,970
have a cluster with hundreds of nodes

00:37:34,990 --> 00:37:40,150
and whatever and if you only know the

00:37:36,970 --> 00:37:43,270
the pot name you can actually forward

00:37:40,150 --> 00:37:47,109
that traffic to your machine through a

00:37:43,270 --> 00:37:49,869
secure channel without having to you

00:37:47,109 --> 00:37:52,869
know actually log in somewhere or so so

00:37:49,869 --> 00:37:57,070
this is I mean this is a really nice way

00:37:52,869 --> 00:37:59,080
to debug things I think probably it's

00:37:57,070 --> 00:38:00,070
not allowed or whatever but it's really

00:37:59,080 --> 00:38:06,270
nice in practice

00:38:00,070 --> 00:38:06,270
it pays off okay let's stop that again

00:38:07,560 --> 00:38:14,279
I'll just delete this

00:38:11,099 --> 00:38:14,279
replication controller

00:38:20,990 --> 00:38:29,910
goodbye okay

00:38:26,810 --> 00:38:39,300
so and obviously this is now gone here

00:38:29,910 --> 00:38:41,520
and now the service will tell me the

00:38:39,300 --> 00:38:43,650
service will tell me okay they're still

00:38:41,520 --> 00:38:46,590
the part is still there but it will be

00:38:43,650 --> 00:38:48,260
cleaned up in a second and when that is

00:38:46,590 --> 00:38:50,700
gone the service won't be able to

00:38:48,260 --> 00:38:54,180
provide any traffic to it anymore

00:38:50,700 --> 00:38:57,240
see is it gonna take a cleaning up takes

00:38:54,180 --> 00:39:00,270
a bit sometimes so what I really want to

00:38:57,240 --> 00:39:03,770
show you now is the deployment let's

00:39:00,270 --> 00:39:03,770
take a look at the deployment again

00:39:11,079 --> 00:39:19,630
okay so let's start this deployment

00:39:15,519 --> 00:39:22,989
let's say we want 15 replicas of this

00:39:19,630 --> 00:39:25,509
part okay and there are nice things you

00:39:22,989 --> 00:39:28,660
can tell about when it will deploy a new

00:39:25,509 --> 00:39:31,569
version what strategy introduced create

00:39:28,660 --> 00:39:33,369
everything from scratch again or in this

00:39:31,569 --> 00:39:38,349
case we want a rolling update and we

00:39:33,369 --> 00:39:41,079
want to make sure that let's say there

00:39:38,349 --> 00:39:47,529
can be three more than the 15 replicas

00:39:41,079 --> 00:39:49,989
but at maximum it can three parts can be

00:39:47,529 --> 00:39:54,279
unavailable at a given time so that's

00:39:49,989 --> 00:39:56,229
the strategy you said and what you see

00:39:54,279 --> 00:39:59,529
down here is an example of how much

00:39:56,229 --> 00:40:02,049
resources will that contain a need that

00:39:59,529 --> 00:40:06,009
part need actually you can say at I

00:40:02,049 --> 00:40:09,579
think also by measuring it needs six

00:40:06,009 --> 00:40:13,900
movie bytes and basically no CPU and

00:40:09,579 --> 00:40:16,599
that is very important for kubernetes to

00:40:13,900 --> 00:40:20,229
calculate on which know does that part

00:40:16,599 --> 00:40:21,880
fit nicely and that is the soft limit

00:40:20,229 --> 00:40:24,759
and then you could give it a hard limit

00:40:21,880 --> 00:40:28,180
and say okay when it goes beyond 50

00:40:24,759 --> 00:40:31,170
megabytes of RAM kill it it will kill

00:40:28,180 --> 00:40:36,369
the process and restart the container

00:40:31,170 --> 00:40:40,989
and the same for CPU it will throttle

00:40:36,369 --> 00:40:44,880
the speed of the container so let's run

00:40:40,989 --> 00:40:44,880
that oops

00:40:47,990 --> 00:40:55,040
and see what happens we have a new

00:40:51,650 --> 00:40:58,130
deployment here a new deployment creates

00:40:55,040 --> 00:41:00,890
a new replica set so that's the

00:40:58,130 --> 00:41:04,580
intermediate stuff in there and you see

00:41:00,890 --> 00:41:06,560
two of them are already running reloaded

00:41:04,580 --> 00:41:07,849
almost all are already running after

00:41:06,560 --> 00:41:11,510
eighteen seconds

00:41:07,849 --> 00:41:15,320
and uh yeah first we and now we need the

00:41:11,510 --> 00:41:18,950
IP address of the service you see now it

00:41:15,320 --> 00:41:21,320
has some external IP address try that if

00:41:18,950 --> 00:41:25,160
you don't believe me and when I reload

00:41:21,320 --> 00:41:28,010
here what you see is that different

00:41:25,160 --> 00:41:30,950
hosts are responding so you see now that

00:41:28,010 --> 00:41:33,980
load balancing is in effect and it will

00:41:30,950 --> 00:41:37,130
des to distribute the traffic to

00:41:33,980 --> 00:41:39,410
different containers you could even tell

00:41:37,130 --> 00:41:41,030
it to have session affinity so that

00:41:39,410 --> 00:41:43,160
depending on your cookies you will end

00:41:41,030 --> 00:41:46,640
up or IP address actually you will end

00:41:43,160 --> 00:41:54,230
up on the same container if possible and

00:41:46,640 --> 00:41:57,050
now let's let's upgrade to a new version

00:41:54,230 --> 00:41:58,790
and the different to the previous file

00:41:57,050 --> 00:42:02,119
is just that it's using a different

00:41:58,790 --> 00:42:06,170
docker image right a different docker

00:42:02,119 --> 00:42:09,980
image version so and let's see yes I I

00:42:06,170 --> 00:42:14,720
knew it because I I changed the original

00:42:09,980 --> 00:42:17,200
file I need to do that for the vision

00:42:14,720 --> 00:42:17,200
too as well

00:42:21,869 --> 00:42:30,940
so don't mess the files before the demo

00:42:26,339 --> 00:42:35,200
so now now it should go like and it's

00:42:30,940 --> 00:42:38,380
very fast so let's see how it's already

00:42:35,200 --> 00:42:42,490
version to tube and maybe I need to roll

00:42:38,380 --> 00:42:49,650
back it's too fast maybe I put it on the

00:42:42,490 --> 00:42:52,450
side here and try vision one again

00:42:49,650 --> 00:43:06,190
version 2 version 2 isn't - version 2

00:42:52,450 --> 00:43:10,150
version 2 version 1 2 1 2 1 2 1 is

00:43:06,190 --> 00:43:13,119
getting more so I mean that there's the

00:43:10,150 --> 00:43:15,640
idea right so it's it's in the end it's

00:43:13,119 --> 00:43:20,770
only 1 and then you rolled out your

00:43:15,640 --> 00:43:25,540
application so yeah just quickly about

00:43:20,770 --> 00:43:27,760
the challenges cluster upgrades you need

00:43:25,540 --> 00:43:30,190
to take care of that there are nice

00:43:27,760 --> 00:43:32,829
computer commands for it now in the

00:43:30,190 --> 00:43:37,260
meantime something like cube control

00:43:32,829 --> 00:43:39,849
drain which will throw will move out all

00:43:37,260 --> 00:43:42,700
containers from a given node and then

00:43:39,849 --> 00:43:44,619
you can start new nodes and so on but if

00:43:42,700 --> 00:43:46,630
you don't have at least two replicas

00:43:44,619 --> 00:43:50,290
running you will have some downtime when

00:43:46,630 --> 00:43:53,020
the containers relocated of course which

00:43:50,290 --> 00:43:56,410
brings me to application fitness I mean

00:43:53,020 --> 00:43:59,800
if you just put a word press on on

00:43:56,410 --> 00:44:03,430
kubernetes which needs a persistent file

00:43:59,800 --> 00:44:05,980
system yeah how did you do that right

00:44:03,430 --> 00:44:08,170
because usually these persistent file

00:44:05,980 --> 00:44:10,599
systems can be only connected to one

00:44:08,170 --> 00:44:13,420
node at least with the major providers

00:44:10,599 --> 00:44:15,550
we have so that means you actually need

00:44:13,420 --> 00:44:17,260
to stop the container put it on a

00:44:15,550 --> 00:44:20,410
different node and then reattach the

00:44:17,260 --> 00:44:23,170
hard drives if you want so but if you

00:44:20,410 --> 00:44:26,170
have a more modern application the 12

00:44:23,170 --> 00:44:28,390
factor application is this the deal then

00:44:26,170 --> 00:44:32,349
it works very nicely and of course with

00:44:28,390 --> 00:44:34,570
microservices it's ideal and storage is

00:44:32,349 --> 00:44:38,500
still the problem of course

00:44:34,570 --> 00:44:41,200
kubernetes could mount read/write

00:44:38,500 --> 00:44:43,330
storage to multiple containers at the

00:44:41,200 --> 00:44:47,620
same time but the cloud providers cannot

00:44:43,330 --> 00:44:49,210
do that yet so that you have to keep in

00:44:47,620 --> 00:44:53,560
mind if you need a persistent file

00:44:49,210 --> 00:44:56,680
system like I don't know from database

00:44:53,560 --> 00:44:59,560
for example you will have some downtime

00:44:56,680 --> 00:45:03,420
when you relocate it but you can do the

00:44:59,560 --> 00:45:07,120
read replicas for example or as

00:45:03,420 --> 00:45:08,650
master-slave replication and so on you

00:45:07,120 --> 00:45:10,960
need to take care of your image build

00:45:08,650 --> 00:45:13,120
process right away I mean right now you

00:45:10,960 --> 00:45:15,850
can even get that from major cloud

00:45:13,120 --> 00:45:19,210
providers for example Google Offers that

00:45:15,850 --> 00:45:21,010
for free basically you can use get lab

00:45:19,210 --> 00:45:24,070
CI for that I can really recommend it

00:45:21,010 --> 00:45:25,750
but the whole deal about monitoring and

00:45:24,070 --> 00:45:27,430
debugging and so on will be very

00:45:25,750 --> 00:45:29,740
different from what you probably know

00:45:27,430 --> 00:45:32,230
from regular service so you need new

00:45:29,740 --> 00:45:34,690
solutions for that I'm not such a big

00:45:32,230 --> 00:45:38,080
fan of New Relic because so expensive

00:45:34,690 --> 00:45:40,900
data dark is not free but it's pretty

00:45:38,080 --> 00:45:43,750
specialized on and and tailored to

00:45:40,900 --> 00:45:45,910
kubernetes I think it's for free for if

00:45:43,750 --> 00:45:48,640
you have five machines so I can

00:45:45,910 --> 00:45:52,600
definitely recommend it for that purpose

00:45:48,640 --> 00:45:54,940
they have a very intensive sales process

00:45:52,600 --> 00:45:56,740
they will call you lots of times like

00:45:54,940 --> 00:45:59,760
New Relic and so on they will send you

00:45:56,740 --> 00:46:03,610
t-shirts and helicopters and whatnot so

00:45:59,760 --> 00:46:06,040
but you're used to that right so if you

00:46:03,610 --> 00:46:08,080
want to get started basically just go to

00:46:06,040 --> 00:46:12,490
kubernetes i/o there are some really

00:46:08,080 --> 00:46:15,010
nice talks if you watch for some guy

00:46:12,490 --> 00:46:18,040
just you will stumble over him anyway a

00:46:15,010 --> 00:46:22,000
Kelsey Hightower is kind of the most

00:46:18,040 --> 00:46:24,220
famous and and humble and friendly ghost

00:46:22,000 --> 00:46:27,100
of the kubernetes universe very nice

00:46:24,220 --> 00:46:31,090
talks and that's even something called

00:46:27,100 --> 00:46:34,390
mini cube which is all right for testing

00:46:31,090 --> 00:46:36,730
that locally it's basically in a virtual

00:46:34,390 --> 00:46:42,520
machine running of it kubernetes cluster

00:46:36,730 --> 00:46:45,010
on your machine right so yeah but yeah

00:46:42,520 --> 00:46:47,490
my personal recommendation is currently

00:46:45,010 --> 00:46:49,500
as you've seen Google Google

00:46:47,490 --> 00:46:51,900
engine because you don't need to take

00:46:49,500 --> 00:46:54,210
care of the management of cube master

00:46:51,900 --> 00:46:58,140
and so on yourself they'll just do that

00:46:54,210 --> 00:47:00,240
and it runs flawlessly for me for over

00:46:58,140 --> 00:47:05,100
one and a half years now so I never had

00:47:00,240 --> 00:47:09,480
really any big problems so it's very

00:47:05,100 --> 00:47:13,500
exciting I can say but don't rush it

00:47:09,480 --> 00:47:15,210
think about why you wants that and need

00:47:13,500 --> 00:47:18,540
that but I think it's definitely worth

00:47:15,210 --> 00:47:21,960
looking at it and by the way nails is

00:47:18,540 --> 00:47:24,570
really nicely suited for cloud ok cloud

00:47:21,960 --> 00:47:27,080
environments right so thank you so so

00:47:24,570 --> 00:47:27,080
far

00:47:28,010 --> 00:47:32,959

YouTube URL: https://www.youtube.com/watch?v=MW5ol1C13as


