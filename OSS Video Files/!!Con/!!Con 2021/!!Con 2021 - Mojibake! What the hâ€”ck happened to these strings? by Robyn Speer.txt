Title: !!Con 2021 - Mojibake! What the hâ€”ck happened to these strings? by Robyn Speer
Publication date: 2021-07-06
Playlist: !!Con 2021
Description: 
	Mojibake! What the hâ€”ck happened to these strings? by Robyn Speer

Our natural-language systems need to be prepared to deal with real-world text. But sometimes real-world text says something like “Merci de t‚Äö√†√∂¬¨¬©l‚Äö√†√∂¬¨¬©charger le plug-in”, and that’s terrible.

I made a Python module called “ftfy” that can solve the puzzle of what happened to Unicode text like this, and in many cases undo it. I want to talk briefly (without too much blame) about why mojibake happens, how we can fix it and maybe prevent it, and why this isn’t a job for machine learning.pens, how we can fix it and maybe prevent it, and why this isn’t a job for machine learning.

Robyn Speer is the developer of the multilingual knowledge graph ConceptNet, as well as several open source projects including ftfy. A decade ago, she co-founded an NLP startup called Luminoso. Now, in her increased free time, she plays and modifies randomizers for retro video games.
Captions: 
	00:00:13,519 --> 00:00:15,759
hi

00:00:14,400 --> 00:00:17,920
i'm robin spear and i'm going to be

00:00:15,759 --> 00:00:18,960
talking about how text breaks and how to

00:00:17,920 --> 00:00:21,199
fix it

00:00:18,960 --> 00:00:22,480
so mojibake is the phenomenon when text

00:00:21,199 --> 00:00:23,279
ends up with the wrong unicode

00:00:22,480 --> 00:00:26,320
characters in it

00:00:23,279 --> 00:00:28,000
due to an encoding mistake and ftfy is a

00:00:26,320 --> 00:00:28,720
python library that i developed over

00:00:28,000 --> 00:00:31,039
several years

00:00:28,720 --> 00:00:32,559
that understands in several cases how to

00:00:31,039 --> 00:00:34,880
fix these characters

00:00:32,559 --> 00:00:35,760
so here's an example of what ftfy can do

00:00:34,880 --> 00:00:37,600
it can take

00:00:35,760 --> 00:00:39,200
this mess and understand it as the

00:00:37,600 --> 00:00:40,160
french sentence that it was actually

00:00:39,200 --> 00:00:41,840
supposed to be

00:00:40,160 --> 00:00:44,800
even though one of the words got

00:00:41,840 --> 00:00:47,920
extremely mangled

00:00:44,800 --> 00:00:49,840
so uh let me introduce the the mascot of

00:00:47,920 --> 00:00:52,719
ftfy who is this little guy

00:00:49,840 --> 00:00:54,160
um this actually comes from this text

00:00:52,719 --> 00:00:56,399
that i found in the wild

00:00:54,160 --> 00:00:57,760
and if you use ftfy to decode the

00:00:56,399 --> 00:00:59,440
multiple layers of mistakes that

00:00:57,760 --> 00:01:00,960
happened to this text you can see

00:00:59,440 --> 00:01:03,359
the face that it was actually intended

00:01:00,960 --> 00:01:04,720
to be and i like this guy because you

00:01:03,359 --> 00:01:07,760
know he's giving you a really

00:01:04,720 --> 00:01:09,119
you can do it face um and uh it's the

00:01:07,760 --> 00:01:12,799
result of actually

00:01:09,119 --> 00:01:15,280
decoding some very messed up text

00:01:12,799 --> 00:01:17,200
so let's go back to a simpler time when

00:01:15,280 --> 00:01:18,479
one byte represented one character

00:01:17,200 --> 00:01:20,880
and this meant that there were at most

00:01:18,479 --> 00:01:21,280
256 possible characters of text that you

00:01:20,880 --> 00:01:23,280
could

00:01:21,280 --> 00:01:25,040
represent on any given computer and

00:01:23,280 --> 00:01:26,560
let's hack up some quick python code

00:01:25,040 --> 00:01:29,520
that's going to show us

00:01:26,560 --> 00:01:30,960
tables of these characters so a very

00:01:29,520 --> 00:01:34,799
straightforward character table

00:01:30,960 --> 00:01:35,360
is called ascii um and these are 128 of

00:01:34,799 --> 00:01:37,840
these

00:01:35,360 --> 00:01:38,479
characters that we agreed on back in the

00:01:37,840 --> 00:01:40,479
60s

00:01:38,479 --> 00:01:42,159
and we can all agree on what byte

00:01:40,479 --> 00:01:42,720
corresponds to what character as long as

00:01:42,159 --> 00:01:45,360
it's

00:01:42,720 --> 00:01:46,240
uh one of the one of the 128 characters

00:01:45,360 --> 00:01:48,479
in ascii

00:01:46,240 --> 00:01:50,240
and if it's one of the other bytes then

00:01:48,479 --> 00:01:51,200
there is then ascii just doesn't say

00:01:50,240 --> 00:01:52,720
what it means

00:01:51,200 --> 00:01:54,640
and this is a set of characters that

00:01:52,720 --> 00:01:56,320
works out pretty well especially if

00:01:54,640 --> 00:01:58,719
you're a monolingual american

00:01:56,320 --> 00:01:59,759
but there are many more things you're

00:01:58,719 --> 00:02:01,280
going to do with text

00:01:59,759 --> 00:02:03,759
and eventually you're going to realize

00:02:01,280 --> 00:02:05,040
that you need more characters than that

00:02:03,759 --> 00:02:07,119
especially if you're speaking other

00:02:05,040 --> 00:02:08,000
languages so people started talking

00:02:07,119 --> 00:02:10,720
about the idea of

00:02:08,000 --> 00:02:13,200
extended ascii um where we could use the

00:02:10,720 --> 00:02:14,879
other 128 bytes as characters also

00:02:13,200 --> 00:02:16,959
and extended ascii just means whatever

00:02:14,879 --> 00:02:18,239
my computer does with the other bytes

00:02:16,959 --> 00:02:20,080
and it's going to differ from one

00:02:18,239 --> 00:02:21,360
computer to another because it could be

00:02:20,080 --> 00:02:22,720
from a different country so using a

00:02:21,360 --> 00:02:24,239
different character set it could be

00:02:22,720 --> 00:02:27,040
running a different os

00:02:24,239 --> 00:02:28,319
and this is how mojibaki started let's

00:02:27,040 --> 00:02:30,080
take a look at these different

00:02:28,319 --> 00:02:31,040
extensions of asp which are called code

00:02:30,080 --> 00:02:32,720
pages

00:02:31,040 --> 00:02:35,040
so a code page you might be familiar

00:02:32,720 --> 00:02:37,680
with is windows 1252

00:02:35,040 --> 00:02:38,720
which would be used on english copies of

00:02:37,680 --> 00:02:41,440
windows

00:02:38,720 --> 00:02:42,160
um but actually wait in this one here's

00:02:41,440 --> 00:02:43,760
latin one

00:02:42,160 --> 00:02:45,760
this is a very straightforward code page

00:02:43,760 --> 00:02:48,000
because it's the first 256 characters of

00:02:45,760 --> 00:02:50,160
unicode

00:02:48,000 --> 00:02:52,319
and so it's very easy to implement by

00:02:50,160 --> 00:02:54,160
accident if you don't really know about

00:02:52,319 --> 00:02:56,000
uh unicode and you just replace every

00:02:54,160 --> 00:02:56,720
byte with the unicode character with the

00:02:56,000 --> 00:02:59,840
same number

00:02:56,720 --> 00:03:01,280
you end up getting latin one and i

00:02:59,840 --> 00:03:02,800
labeled two of these rows as hereby

00:03:01,280 --> 00:03:05,280
dragons because those

00:03:02,800 --> 00:03:06,480
are two rows of the table that are full

00:03:05,280 --> 00:03:08,239
of control characters

00:03:06,480 --> 00:03:11,760
that nobody ever agreed on what they do

00:03:08,239 --> 00:03:14,159
even when it became an iso standard

00:03:11,760 --> 00:03:16,239
and windows 1252 fills in those rows

00:03:14,159 --> 00:03:17,680
with more punctuation characters curly

00:03:16,239 --> 00:03:20,560
quotes bullets things that ended up

00:03:17,680 --> 00:03:22,640
being useful on windows

00:03:20,560 --> 00:03:24,959
um but that's only on windows if you are

00:03:22,640 --> 00:03:26,239
looking at the 256 characters you have

00:03:24,959 --> 00:03:29,120
available in dos

00:03:26,239 --> 00:03:30,319
then you would end up with uh with this

00:03:29,120 --> 00:03:32,080
different character set which has all

00:03:30,319 --> 00:03:33,920
these line art characters in it

00:03:32,080 --> 00:03:35,680
and yet another character set if you're

00:03:33,920 --> 00:03:37,200
using mac os classic

00:03:35,680 --> 00:03:38,560
and if for example you had a russian

00:03:37,200 --> 00:03:40,159
version of windows and you have this

00:03:38,560 --> 00:03:42,000
character set which has the cyrillic

00:03:40,159 --> 00:03:45,120
alphabet in it which is of course very

00:03:42,000 --> 00:03:46,560
important for writing in russian

00:03:45,120 --> 00:03:48,799
so clearly the situation is

00:03:46,560 --> 00:03:49,519
unsustainable and you know unicode came

00:03:48,799 --> 00:03:51,440
along and said

00:03:49,519 --> 00:03:53,840
you know hey it turns out there are one

00:03:51,440 --> 00:03:56,239
way more than 256 characters

00:03:53,840 --> 00:03:57,680
uh but unicode was originally uh hard to

00:03:56,239 --> 00:03:58,560
use because it wasn't compatible with

00:03:57,680 --> 00:04:01,200
ascii

00:03:58,560 --> 00:04:01,760
and utf-8 is a great idea which is what

00:04:01,200 --> 00:04:03,920
if we leave

00:04:01,760 --> 00:04:06,720
ascii alone and instead of using those

00:04:03,920 --> 00:04:07,360
120 other bytes as just 128 more

00:04:06,720 --> 00:04:09,280
characters

00:04:07,360 --> 00:04:12,239
what if we use them as a variable length

00:04:09,280 --> 00:04:13,920
encoding for the entire rest of unicode

00:04:12,239 --> 00:04:16,079
and there are some really great ideas in

00:04:13,920 --> 00:04:19,040
utf-8 uh such as

00:04:16,079 --> 00:04:21,199
not overlapping with ascii ever and also

00:04:19,040 --> 00:04:23,040
uh being self-synchronizing it's got

00:04:21,199 --> 00:04:24,960
patterns in its bytes that uh tell you

00:04:23,040 --> 00:04:26,560
where each character begins and ends

00:04:24,960 --> 00:04:28,400
and so if you jump into the middle of a

00:04:26,560 --> 00:04:29,919
utf-8 string you can tell where the

00:04:28,400 --> 00:04:30,880
start and end of each character is in

00:04:29,919 --> 00:04:32,560
the bytes

00:04:30,880 --> 00:04:34,479
and so everybody adopted these great

00:04:32,560 --> 00:04:36,320
ideas and used utf-8 right

00:04:34,479 --> 00:04:38,720
well no of course it's not that simple

00:04:36,320 --> 00:04:39,120
especially because microsoft had just

00:04:38,720 --> 00:04:40,639
done

00:04:39,120 --> 00:04:44,080
all that work to make windows support

00:04:40,639 --> 00:04:46,400
unicode and all of their apis use utf-16

00:04:44,080 --> 00:04:47,919
which is more difficult to use and so

00:04:46,400 --> 00:04:50,160
this provides more opportunities for

00:04:47,919 --> 00:04:51,840
mojibake

00:04:50,160 --> 00:04:53,759
so let's have some more code that's

00:04:51,840 --> 00:04:54,400
going to show us the sequence of bytes

00:04:53,759 --> 00:04:56,800
that

00:04:54,400 --> 00:04:57,759
represent each character in utf-8 so if

00:04:56,800 --> 00:05:01,120
you take this name

00:04:57,759 --> 00:05:01,520
l'hopital um we can look at it in utf-8

00:05:01,120 --> 00:05:04,560
and

00:05:01,520 --> 00:05:06,800
the simple letters that are ascii

00:05:04,560 --> 00:05:09,680
letters are single bytes

00:05:06,800 --> 00:05:10,320
but this curly quote turns into three

00:05:09,680 --> 00:05:12,400
bytes

00:05:10,320 --> 00:05:14,880
and the o with an accent on it turns

00:05:12,400 --> 00:05:17,199
into two bytes

00:05:14,880 --> 00:05:18,160
and so if you've got text that's in

00:05:17,199 --> 00:05:20,080
utf-8

00:05:18,160 --> 00:05:22,000
um you can encode it as bytes and

00:05:20,080 --> 00:05:23,280
somebody can else can decode it as utf-8

00:05:22,000 --> 00:05:25,120
and get the same text

00:05:23,280 --> 00:05:26,880
but if they decode it as a different

00:05:25,120 --> 00:05:28,320
character set uh then they're going to

00:05:26,880 --> 00:05:30,000
end up with something like this

00:05:28,320 --> 00:05:31,120
with a bunch of miscellaneous symbols in

00:05:30,000 --> 00:05:33,520
it that weren't intended and that's

00:05:31,120 --> 00:05:35,280
mojibaki

00:05:33,520 --> 00:05:36,720
and any mistake that you can make with a

00:05:35,280 --> 00:05:39,680
computer can also

00:05:36,720 --> 00:05:41,600
be repeated so um you end up with these

00:05:39,680 --> 00:05:43,600
pileups of mojibaki where the same

00:05:41,600 --> 00:05:46,080
encoding and decoding mistakes get uh

00:05:43,600 --> 00:05:46,080
iterated

00:05:46,160 --> 00:05:50,400
and the fortunate thing here is because

00:05:48,960 --> 00:05:51,280
of the self-synchronizing nature of

00:05:50,400 --> 00:05:53,520
utf-8

00:05:51,280 --> 00:05:55,120
we can recognize the patterns that it

00:05:53,520 --> 00:05:56,639
leaves behind because the patterns of

00:05:55,120 --> 00:05:58,000
bytes that make up utf-8

00:05:56,639 --> 00:06:00,000
show up as distinct patterns of

00:05:58,000 --> 00:06:03,120
characters in the emoji pocket

00:06:00,000 --> 00:06:03,520
so this second string here with all of

00:06:03,120 --> 00:06:05,759
the

00:06:03,520 --> 00:06:06,800
square root signs and not signs in it is

00:06:05,759 --> 00:06:09,440
sending us a big

00:06:06,800 --> 00:06:11,360
a huge signal that like hey this is

00:06:09,440 --> 00:06:14,720
actually supposed to be

00:06:11,360 --> 00:06:16,800
utf-8 but it came out in mac os roman

00:06:14,720 --> 00:06:18,560
and when we see a pattern like that we

00:06:16,800 --> 00:06:18,960
encode as whatever the other encoding

00:06:18,560 --> 00:06:21,360
was

00:06:18,960 --> 00:06:22,479
and decode it as utf-8 and presumably

00:06:21,360 --> 00:06:24,800
get out what the text was

00:06:22,479 --> 00:06:26,639
expected to be so we can take that

00:06:24,800 --> 00:06:29,199
example

00:06:26,639 --> 00:06:30,960
um and we can decode it encode it with

00:06:29,199 --> 00:06:33,520
macro and decode it as utf-8

00:06:30,960 --> 00:06:34,080
and get this which is still moji

00:06:33,520 --> 00:06:35,680
because

00:06:34,080 --> 00:06:38,160
it turns out that we need to do that

00:06:35,680 --> 00:06:39,840
again and we need to do it again

00:06:38,160 --> 00:06:41,520
and after decoding three layers of

00:06:39,840 --> 00:06:43,840
mojibaki we get the text that was

00:06:41,520 --> 00:06:45,520
intended

00:06:43,840 --> 00:06:47,280
but this is a job that the computer can

00:06:45,520 --> 00:06:50,000
do for us so

00:06:47,280 --> 00:06:51,199
here's some code to use ftfy and format

00:06:50,000 --> 00:06:54,400
its output nicely

00:06:51,199 --> 00:06:56,800
and we can put the text into ftfy and so

00:06:54,400 --> 00:06:57,599
the first example here um it shows us

00:06:56,800 --> 00:06:59,039
that this was

00:06:57,599 --> 00:07:00,639
that what you need to do with this text

00:06:59,039 --> 00:07:04,319
is encoded as macromin

00:07:00,639 --> 00:07:06,960
and decode decoded his utf-8 three times

00:07:04,319 --> 00:07:08,639
in this other example um it turns out

00:07:06,960 --> 00:07:09,599
that all of this mojibake was just one

00:07:08,639 --> 00:07:12,800
apostrophe

00:07:09,599 --> 00:07:14,639
um and you need to encode it as

00:07:12,800 --> 00:07:16,000
something like windows 1252 and decode

00:07:14,639 --> 00:07:18,080
it as utf-8 three times

00:07:16,000 --> 00:07:20,479
and maybe even uncurl the curly quote at

00:07:18,080 --> 00:07:22,639
the end if you want

00:07:20,479 --> 00:07:23,919
and this is example i love because they

00:07:22,639 --> 00:07:24,720
said i just figured out how to tweet

00:07:23,919 --> 00:07:25,840
emojis and

00:07:24,720 --> 00:07:28,400
they hadn't quite figured out how to

00:07:25,840 --> 00:07:29,919
tweet emojis uh because they're tweeting

00:07:28,400 --> 00:07:31,520
through something that used a broken

00:07:29,919 --> 00:07:33,599
implementation of utf-8

00:07:31,520 --> 00:07:35,919
and also somehow came out as latin 1

00:07:33,599 --> 00:07:36,880
instead but if we recognize that we can

00:07:35,919 --> 00:07:38,639
figure out what the

00:07:36,880 --> 00:07:40,880
what the emoji were actually intended to

00:07:38,639 --> 00:07:40,880
be

00:07:41,440 --> 00:07:44,240
now we can't just apply this to every

00:07:43,120 --> 00:07:45,280
string that looks like it could have

00:07:44,240 --> 00:07:46,720
been utf-8

00:07:45,280 --> 00:07:48,479
because we don't want to have false

00:07:46,720 --> 00:07:50,240
positives there are combinations of

00:07:48,479 --> 00:07:51,440
symbols that could have been utf-8 but

00:07:50,240 --> 00:07:53,840
are actually what you meant

00:07:51,440 --> 00:07:54,879
in the text so you could be writing in

00:07:53,840 --> 00:07:57,520
capital letters

00:07:54,879 --> 00:07:59,039
uh with accents next to punctuation or

00:07:57,520 --> 00:08:00,240
you could actually be talking about the

00:07:59,039 --> 00:08:02,879
square root of pi

00:08:00,240 --> 00:08:04,160
and uh we don't want to replace every

00:08:02,879 --> 00:08:05,120
instance of one of these with a

00:08:04,160 --> 00:08:06,879
different character

00:08:05,120 --> 00:08:08,560
you would get examples that are wrong

00:08:06,879 --> 00:08:10,240
like these down here at the bottom of

00:08:08,560 --> 00:08:12,800
the screen

00:08:10,240 --> 00:08:14,000
so it's important for mojibake to have a

00:08:12,800 --> 00:08:16,960
regular expression

00:08:14,000 --> 00:08:18,800
that uh can uh detect when something is

00:08:16,960 --> 00:08:20,639
likely to be mojibaki

00:08:18,800 --> 00:08:23,120
um and so we call this the badness

00:08:20,639 --> 00:08:25,039
metric um and so it looks for things

00:08:23,120 --> 00:08:26,720
like these improbable combinations with

00:08:25,039 --> 00:08:28,080
accented letters next to particular

00:08:26,720 --> 00:08:30,639
currency signs

00:08:28,080 --> 00:08:31,840
or maybe unpopular punctuation like the

00:08:30,639 --> 00:08:34,640
pilcrow sign

00:08:31,840 --> 00:08:36,320
next to another uh character that comes

00:08:34,640 --> 00:08:38,959
from one of these character sets

00:08:36,320 --> 00:08:40,159
and with this big regular expression we

00:08:38,959 --> 00:08:43,039
can recognize

00:08:40,159 --> 00:08:44,320
um patterns like this so in this string

00:08:43,039 --> 00:08:46,560
three out of four of the instances of

00:08:44,320 --> 00:08:48,640
mojibaki match the regular expression

00:08:46,560 --> 00:08:50,000
and they all have the same explanation

00:08:48,640 --> 00:08:54,560
for what went wrong with them and we can

00:08:50,000 --> 00:08:56,480
use that to just fix the entire string

00:08:54,560 --> 00:08:58,800
so this is a heuristic that i've been

00:08:56,480 --> 00:09:00,399
hand tuning for several years and

00:08:58,800 --> 00:09:02,560
people have asked me well you know you

00:09:00,399 --> 00:09:03,920
know machine learning why doesn't ftfy

00:09:02,560 --> 00:09:06,000
use machine learning

00:09:03,920 --> 00:09:07,760
um and i don't think i'd be able to keep

00:09:06,000 --> 00:09:10,320
the rate of false positives this low

00:09:07,760 --> 00:09:12,080
using machine learning it's very hard to

00:09:10,320 --> 00:09:12,880
explain to machine learning the idea of

00:09:12,080 --> 00:09:15,040
an error rate

00:09:12,880 --> 00:09:16,720
of once in several gigabytes of

00:09:15,040 --> 00:09:18,640
multilingual text

00:09:16,720 --> 00:09:20,480
and also in my experience with language

00:09:18,640 --> 00:09:22,560
models they have a tendency to kind of

00:09:20,480 --> 00:09:23,680
homogenize text to make it say what they

00:09:22,560 --> 00:09:25,279
expect it says

00:09:23,680 --> 00:09:26,560
instead of what it actually says and i

00:09:25,279 --> 00:09:27,920
don't want to do that i don't want to

00:09:26,560 --> 00:09:29,920
cause more problems

00:09:27,920 --> 00:09:31,680
using ftfy and so that's why i tune it

00:09:29,920 --> 00:09:32,720
by hand instead of using machine

00:09:31,680 --> 00:09:34,240
learning

00:09:32,720 --> 00:09:35,760
but let's talk about some of the root

00:09:34,240 --> 00:09:37,920
causes of mojibake

00:09:35,760 --> 00:09:39,279
and i identify three causes that i

00:09:37,920 --> 00:09:42,000
encounter over and over

00:09:39,279 --> 00:09:43,040
one of them is microsoft excel the

00:09:42,000 --> 00:09:46,000
second one in general

00:09:43,040 --> 00:09:47,760
is programming language apis that

00:09:46,000 --> 00:09:48,320
confuse you about how to use unicode and

00:09:47,760 --> 00:09:50,959
let you

00:09:48,320 --> 00:09:51,519
mix up bytes and text and the third one

00:09:50,959 --> 00:09:53,120
that i

00:09:51,519 --> 00:09:55,040
run into a surprising amount is an

00:09:53,120 --> 00:09:57,120
outdated heuristic called chardet

00:09:55,040 --> 00:09:59,279
let's take a look at that so charted

00:09:57,120 --> 00:10:02,640
originated as part of netscape navigator

00:09:59,279 --> 00:10:04,000
in 1998 and in the 90s because there

00:10:02,640 --> 00:10:05,760
were all these different code pages

00:10:04,000 --> 00:10:07,760
that people were sending around uh text

00:10:05,760 --> 00:10:09,760
in you needed to be able to guess

00:10:07,760 --> 00:10:11,920
based on completely unlabeled bytes what

00:10:09,760 --> 00:10:13,920
encoding it was in

00:10:11,920 --> 00:10:15,680
uh the problem is that the assumptions

00:10:13,920 --> 00:10:17,200
uh come from the 90s

00:10:15,680 --> 00:10:19,440
and these assumptions aren't necessarily

00:10:17,200 --> 00:10:20,880
true anymore chardet doesn't know that

00:10:19,440 --> 00:10:21,200
the correct answer to what encoding is

00:10:20,880 --> 00:10:23,920
this

00:10:21,200 --> 00:10:24,640
is usually utf-8 and it's never seen an

00:10:23,920 --> 00:10:27,200
emoji

00:10:24,640 --> 00:10:28,480
so if you show it the bytes that make up

00:10:27,200 --> 00:10:31,040
an emoji it thinks that there's some

00:10:28,480 --> 00:10:32,800
kind of turkish

00:10:31,040 --> 00:10:34,959
but the biggest problem is microsoft

00:10:32,800 --> 00:10:36,480
excel because there have been so many

00:10:34,959 --> 00:10:38,480
different ways to export

00:10:36,480 --> 00:10:40,800
supposedly plain text csvs from

00:10:38,480 --> 00:10:42,640
microsoft excel over the uh

00:10:40,800 --> 00:10:44,000
many decades of its existence and

00:10:42,640 --> 00:10:45,600
microsoft never breaks backwards

00:10:44,000 --> 00:10:47,440
compatibility with anything so if you're

00:10:45,600 --> 00:10:49,680
trying to export a csv

00:10:47,440 --> 00:10:50,560
you have all of these options for how

00:10:49,680 --> 00:10:53,839
you could export

00:10:50,560 --> 00:10:54,880
text from from excel and if you want to

00:10:53,839 --> 00:10:56,480
use utf-8

00:10:54,880 --> 00:10:58,079
every single one of these options is

00:10:56,480 --> 00:10:59,040
wrong even the one that says unicode

00:10:58,079 --> 00:11:00,320
text

00:10:59,040 --> 00:11:02,240
and i know that you might have to use

00:11:00,320 --> 00:11:05,120
excel sometimes but if you're

00:11:02,240 --> 00:11:06,959
if you want to make a csv file uh to

00:11:05,120 --> 00:11:08,560
have comma separated plain text i

00:11:06,959 --> 00:11:10,240
strongly recommend that you use

00:11:08,560 --> 00:11:14,000
libreoffice or google spreadsheets

00:11:10,240 --> 00:11:16,160
instead because they can handle utf-8

00:11:14,000 --> 00:11:17,839
in general i've got a recommendation for

00:11:16,160 --> 00:11:20,560
how to avoid mojibake

00:11:17,839 --> 00:11:20,959
being produced by your code because if

00:11:20,560 --> 00:11:22,800
you

00:11:20,959 --> 00:11:24,480
use english a lot you might go for a

00:11:22,800 --> 00:11:25,120
long time without noticing mojibaki

00:11:24,480 --> 00:11:27,440
because all the

00:11:25,120 --> 00:11:28,240
ascii characters are still right but the

00:11:27,440 --> 00:11:31,200
good news

00:11:28,240 --> 00:11:32,240
is emoji are everywhere and people

00:11:31,200 --> 00:11:34,800
expect them to work

00:11:32,240 --> 00:11:35,519
and they are a really good test of your

00:11:34,800 --> 00:11:37,279
unicode

00:11:35,519 --> 00:11:39,680
so my recommendation is use lots of

00:11:37,279 --> 00:11:42,079
emoji put them in your code your uis

00:11:39,680 --> 00:11:43,600
definitely put them in your test cases

00:11:42,079 --> 00:11:44,959
and make sure that they come out right

00:11:43,600 --> 00:11:47,839
and it won't even look weird because

00:11:44,959 --> 00:11:50,320
people use emoji all the time anyway

00:11:47,839 --> 00:11:51,360
this is similar to the way web

00:11:50,320 --> 00:11:53,760
frameworks used to put

00:11:51,360 --> 00:11:54,480
extra parameters in the url like snowman

00:11:53,760 --> 00:11:56,800
equals

00:11:54,480 --> 00:11:58,160
this picture of a snowman um because

00:11:56,800 --> 00:12:00,000
then the web framework could

00:11:58,160 --> 00:12:01,519
uh make sure that the browser had to use

00:12:00,000 --> 00:12:05,040
utf-8 and

00:12:01,519 --> 00:12:05,040
detect if it came out wrong

00:12:05,440 --> 00:12:09,040
and that's what i've got to say right

00:12:06,959 --> 00:12:10,639
now here is some extra information about

00:12:09,040 --> 00:12:13,519
ftfi and about myself

00:12:10,639 --> 00:12:13,519

YouTube URL: https://www.youtube.com/watch?v=N5TOYep70CI


