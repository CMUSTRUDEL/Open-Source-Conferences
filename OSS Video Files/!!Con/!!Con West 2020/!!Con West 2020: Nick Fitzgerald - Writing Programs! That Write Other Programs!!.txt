Title: !!Con West 2020: Nick Fitzgerald - Writing Programs! That Write Other Programs!!
Publication date: 2020-03-23
Playlist: !!Con West 2020
Description: 
	Presented at !!Con West 2020: http://bangbangcon.com/west

Why write programs when you can write a program to write programs for you? And that program writes programs that are faster than the programs you’d write by hand. And that program’s programs are actually, you know, correct. Wow!

Yep, it’s time to synthesize. But this ain’t Moog, this is program synthesis. What is that, and how can it upgrade our optimizers into super-optimizers? We’ll find out!!

#bangbangcon #bangbangconwest #bangbangconwest2020
Captions: 
	00:00:26,520 --> 00:00:27,780
Hi!

00:00:27,780 --> 00:00:28,980
I'm Nick.

00:00:28,990 --> 00:00:32,910
And I'm gonna talk about writing programs that write other programs.

00:00:32,910 --> 00:00:38,530
And so technically, a program that writes other programs is called a program synthesizer.

00:00:38,530 --> 00:00:44,750
And so what it does is it takes this kind of formal specification that describes basically

00:00:44,750 --> 00:00:49,690
your desired program, and then it searches for such a program, and if it finds one, it

00:00:49,690 --> 00:00:51,120
will return one to you.

00:00:51,120 --> 00:00:56,289
So you might be wondering: Why do I need a program synthesizer?

00:00:56,289 --> 00:01:00,210
Am I just too lazy to write these programs myself?

00:01:00,210 --> 00:01:01,210
And the answer is yes.

00:01:01,210 --> 00:01:02,479
But that's not actually how I got here.

00:01:02,479 --> 00:01:06,500
So let me digress for a bit and talk about compilers.

00:01:06,500 --> 00:01:11,190
So kind of -- the common things that we want out of an optimizing compiler are like...

00:01:11,190 --> 00:01:13,570
Well, it's an optimizing compiler.

00:01:13,570 --> 00:01:18,770
Hopefully it has good code generation and our programs that we compile with it run fast.

00:01:18,770 --> 00:01:21,619
But at the same time, we're busy people.

00:01:21,619 --> 00:01:22,619
We have places to go.

00:01:22,619 --> 00:01:23,619
People to see.

00:01:23,619 --> 00:01:27,720
And so this thing should compile code pretty fast as well.

00:01:27,720 --> 00:01:30,549
But most of all, it needs to be correct.

00:01:30,549 --> 00:01:34,630
Because otherwise, everything else was useless.

00:01:34,630 --> 00:01:38,829
And you know, if you want a fast compiler, but you don't care about correctness, I can

00:01:38,829 --> 00:01:43,579
emit garbage really fast, but that's not actually what you want.

00:01:43,579 --> 00:01:44,579
Right?

00:01:44,579 --> 00:01:50,270
And so each one of these things is a lot of effort, but all together, this is really a

00:01:50,270 --> 00:01:54,119
tremendous feat of engineering, to get all of them.

00:01:54,119 --> 00:01:59,700
So to really illustrate this, let's consider a peephole optimizer.

00:01:59,700 --> 00:02:05,659
So what a peephole optimizer does is it matches patterns of kind of known suboptimal instruction

00:02:05,659 --> 00:02:10,289
sequences, and then it replaces them with the better version.

00:02:10,289 --> 00:02:14,510
Something that runs in fewer CPU cycles, or has smaller code size.

00:02:14,510 --> 00:02:17,440
So, for example, adding zero to X is useless.

00:02:17,440 --> 00:02:19,690
You can just use X directly.

00:02:19,690 --> 00:02:25,640
So the peephole optimizer will recognize the pattern, X+0, and replace it with X.

00:02:25,640 --> 00:02:30,200
Or X multiplied by 2 is the same as X shifted left by 1.

00:02:30,200 --> 00:02:36,250
But a left shift is generally faster to execute than a multiply in most architectures.

00:02:36,250 --> 00:02:43,770
So LLVM is a compiler framework that's used by the Clang, C, and C++ compiler, the Rust

00:02:43,770 --> 00:02:46,250
compiler, and a bunch of other compilers.

00:02:46,250 --> 00:02:53,680
There are a bunch of engineers who work full-time on LLVM at places like Apple and Google, and

00:02:53,680 --> 00:03:01,170
the peephole optimizer inside LLVM has over 1,000 of these pattern and replacement pairs.

00:03:01,170 --> 00:03:07,040
So even half that many is way too many for me to write by hand.

00:03:07,040 --> 00:03:10,410
And some of these replacements aren't, like, easy to write, either.

00:03:10,410 --> 00:03:14,850
Especially to get them correct for, like, all the corner cases.

00:03:14,850 --> 00:03:19,210
So I need something that's kind of like a more efficient approach, that doesn't require

00:03:19,210 --> 00:03:23,190
a bunch of engineers at, like, Apple and Google working on this.

00:03:23,190 --> 00:03:27,110
Something that, you know, maybe I could do myself.

00:03:27,110 --> 00:03:31,440
And so if you kind of squint and tilt your head to the side, well...

00:03:31,440 --> 00:03:38,000
These patterns are maybe, like, specifications and the replacements are kind of like mini-programs

00:03:38,000 --> 00:03:42,260
that implement that specification, in that they have the same behavior, but they're just

00:03:42,260 --> 00:03:44,570
also better in some way.

00:03:44,570 --> 00:03:50,650
So can I use program synthesis, where I'm taking these unoptimized programs, as a specification,

00:03:50,650 --> 00:03:57,300
to find not just a better program, but ideally the optimal program?

00:03:57,300 --> 00:04:02,850
And it turns out that kind of finding the optimal program has a name, and this is superoptimization,

00:04:02,850 --> 00:04:07,620
because it's just that much better than regular optimization.

00:04:07,620 --> 00:04:13,340
So the goal here is basically: Can I automatically and kind of mechanically create a peephole

00:04:13,340 --> 00:04:17,980
superoptimizer via program synthesis?

00:04:17,980 --> 00:04:20,850
So here is kind of the language that we're working with.

00:04:20,850 --> 00:04:23,120
It's fairly low level.

00:04:23,120 --> 00:04:27,810
Each instruction defines a new variable, and then those variables are never reassigned.

00:04:27,810 --> 00:04:30,210
And each instruction has just one operation.

00:04:30,210 --> 00:04:34,900
So we have operations for, like, addition and multiplication, and we have bitwise stuff

00:04:34,900 --> 00:04:36,610
like XOR and AND.

00:04:36,610 --> 00:04:39,910
What we're not dealing with is, like, loops or function calls.

00:04:39,910 --> 00:04:44,130
This is just, like, straight line programs.

00:04:44,130 --> 00:04:49,310
But if we have 32 different operators, and we're synthesizing a program that's n instructions

00:04:49,310 --> 00:04:54,470
long, that means we have 32 choices for the first instructions operator.

00:04:54,470 --> 00:04:55,470
We have...

00:04:55,470 --> 00:05:02,260
Well, times 32 instructions, or 32 operations that are choices for the second instructions

00:05:02,260 --> 00:05:03,460
operator.

00:05:03,460 --> 00:05:06,320
Times 32 choices for the third instructions operator.

00:05:06,320 --> 00:05:07,600
Et cetera.

00:05:07,600 --> 00:05:08,600
Up to n.

00:05:08,600 --> 00:05:12,210
And we have an exponential search space.

00:05:12,210 --> 00:05:13,480
That's not good.

00:05:13,480 --> 00:05:19,420
With just a 10-instruction-long program, which is really not able to do that much, we're

00:05:19,420 --> 00:05:21,340
already past the billions.

00:05:21,340 --> 00:05:22,420
We're past the trillions.

00:05:22,420 --> 00:05:24,400
And we're in the quadrillions.

00:05:24,400 --> 00:05:26,910
And this is just choice of operator!

00:05:26,910 --> 00:05:29,160
Not even dealing with, like, operands yet.

00:05:29,160 --> 00:05:35,190
So brute force search is not really a good option here.

00:05:35,190 --> 00:05:41,000
But luckily, there's these tools called SMT solvers, and kind of fundamentally what SMT

00:05:41,000 --> 00:05:45,150
solvers are good at is doing exponential search.

00:05:45,150 --> 00:05:49,389
Because it turns out that most of the problems that we want to solve aren't, like, the super,

00:05:49,389 --> 00:05:51,130
super hard cases.

00:05:51,130 --> 00:05:56,900
And so SMT solvers have gotten pretty effective in practice at exponential search.

00:05:56,900 --> 00:06:02,740
So what an SMT solver does is it solves a logic formula for you.

00:06:02,740 --> 00:06:08,330
And so in this case, say we have some integer X whose value we don't know, but we're kind

00:06:08,330 --> 00:06:09,980
of searching for the value.

00:06:09,980 --> 00:06:10,980
Right?

00:06:10,980 --> 00:06:14,730
What we do know about it is that X+2 is 5.

00:06:14,730 --> 00:06:19,180
And we can ask the solver whether there is a satisfying assignment to the unbound variables

00:06:19,180 --> 00:06:24,340
-- in this case, that's just X -- that makes all of these assertions true.

00:06:24,340 --> 00:06:29,610
And so in this case, there is, and so the solver replies to us: Sat.

00:06:29,610 --> 00:06:33,870
And once it does that, we can ask what those assignments are, and it tells us that X is

00:06:33,870 --> 00:06:36,290
3, because 3+2 is 5.

00:06:36,290 --> 00:06:42,330
So can we take our exponential program synthesis search problem and just give it to the SMT

00:06:42,330 --> 00:06:48,420
solver by translating it into a logic formula and then get an answer?

00:06:48,420 --> 00:06:51,210
This is what program synthesis looks like as a logic formula.

00:06:51,210 --> 00:06:53,860
And I know this is fairly big and scary.

00:06:53,860 --> 00:06:54,860
But don't worry.

00:06:54,860 --> 00:06:57,600
We're gonna break it down together.

00:06:57,600 --> 00:07:02,180
So there exists some program P. This is the program that we're searching for.

00:07:02,180 --> 00:07:07,169
Maybe there's multiple programs, but we're really just looking for one right now.

00:07:07,169 --> 00:07:14,460
And for all of the different variables I and O, basically when we run the program on those

00:07:14,460 --> 00:07:21,610
input variables to get the output variable, O, then the specification should be satisfied.

00:07:21,610 --> 00:07:25,740
We're looking for a program that satisfies the specification for all inputs.

00:07:25,740 --> 00:07:29,169
Because if there's some input for which a specification is not satisfied, that kind

00:07:29,169 --> 00:07:33,171
of like represents a bug, and we don't want a buggy program, because that's not what we're

00:07:33,171 --> 00:07:34,540
looking for.

00:07:34,540 --> 00:07:38,840
So if we plug this formula into an SMT solver, do we just...

00:07:38,840 --> 00:07:39,840
Are we done?

00:07:39,840 --> 00:07:40,840
Do we get an answer?

00:07:40,840 --> 00:07:42,900
And unfortunately, not quite.

00:07:42,900 --> 00:07:48,770
But because SMT solvers don't like to have these kind of nested "exists" and "for all"s.

00:07:48,770 --> 00:07:53,180
They kind of struggle with it, and it makes them go "bluh".

00:07:53,180 --> 00:07:55,070
Hope is not lost here.

00:07:55,070 --> 00:08:03,260
We have another tool in our tool box, Counterexample-Guided Iterative Synthesis, also known as CEGIS.

00:08:03,260 --> 00:08:09,460
And so basically rather than asking the solver to solve the whole big nested exists for all

00:08:09,460 --> 00:08:14,300
problem, all at once, we kind of decompose it into two different parts.

00:08:14,300 --> 00:08:18,770
And the key is that each of these two different parts is without nesting.

00:08:18,770 --> 00:08:25,879
Which means that the SMT solver can solve each of these parts on its own.

00:08:25,879 --> 00:08:28,320
So the first part is finite synthesis.

00:08:28,320 --> 00:08:35,229
And finite synthesis takes kind of a set of examples, here we have 17 and 42, and it finds

00:08:35,229 --> 00:08:41,729
a program that satisfies the specification, just for those examples, and for other examples,

00:08:41,729 --> 00:08:46,360
like 0 or 100, maybe the specification is satisfied.

00:08:46,360 --> 00:08:47,360
Maybe not.

00:08:47,360 --> 00:08:49,959
We just don't really know yet.

00:08:49,959 --> 00:08:52,509
And the second step is verification.

00:08:52,509 --> 00:08:57,260
So it says: Given that you've synthesized a program that works for some inputs, are

00:08:57,260 --> 00:09:00,990
there any inputs for which this program is not correct?

00:09:00,990 --> 00:09:06,110
And if it can find one, we call that a counterexample.

00:09:06,110 --> 00:09:09,860
So in this case, we find the counterexample, 16.

00:09:09,860 --> 00:09:13,459
And so we go back to finite synthesis again, and we say: Okay.

00:09:13,459 --> 00:09:21,319
Can you find a program that works not just for 17 and 42, but also for 16?

00:09:21,319 --> 00:09:25,930
And so we kind of repeat this back and forth, over and over, and finite synthesis is gonna

00:09:25,930 --> 00:09:34,570
generate more and more general programs, as it learns more counterexamples, until eventually

00:09:34,570 --> 00:09:38,589
verification can't find any inputs for which the program is correct.

00:09:38,589 --> 00:09:40,820
There aren't any more counterexamples.

00:09:40,820 --> 00:09:43,920
Which means that it's correct for all of the inputs, and...

00:09:43,920 --> 00:09:45,369
Well, this is what we were searching for.

00:09:45,369 --> 00:09:46,850
And we found it.

00:09:46,850 --> 00:09:49,070
So we're done!

00:09:49,070 --> 00:09:54,579
I don't have time to explain in depth how finite synthesis and verification work, but

00:09:54,579 --> 00:10:01,290
the key takeaway is that CEGIS breaks apart the problem into two parts that don't have

00:10:01,290 --> 00:10:04,730
the nesting, and that solvers can solve.

00:10:04,730 --> 00:10:11,990
So I implemented CEGIS in Rust with the Z3 solver, and here is an example of a synthesized

00:10:11,990 --> 00:10:13,910
optimization.

00:10:13,910 --> 00:10:19,170
We're rounding the variable ‘a’ up to the next multiple of 4, and so we managed

00:10:19,170 --> 00:10:21,660
to shave off two instructions.

00:10:21,660 --> 00:10:27,580
And we also replaced expensive multiply and divide instructions with bitwise XOR and AND,

00:10:27,580 --> 00:10:30,110
which are a bit cheaper.

00:10:30,110 --> 00:10:34,610
And if you want to learn more about that, I wrote a very in-depth blog post about it

00:10:34,610 --> 00:10:39,320
here, and the source code is up on GitHub there.

00:10:39,320 --> 00:10:42,970
Please support the striking grad students, if you can.

00:10:42,970 --> 00:10:45,970
And also, shout out to our captioner, Mirabai.

00:10:45,970 --> 00:10:48,230
And all the AV folks.

00:10:48,230 --> 00:10:49,250
And that's everything.

00:10:49,250 --> 00:10:50,029

YouTube URL: https://www.youtube.com/watch?v=kR6rkVwQPos


