Title: !!Con West 2020 - don-E Merson: Sonification: You Can See Your Complex Data with Sound!!
Publication date: 2020-03-23
Playlist: !!Con West 2020
Description: 
	Presented at !!Con West 2020: http://bangbangcon.com/west

Sonification is using sound to map data. While visualization techniques are limited to a few dimensions, the use of sound and sight at the same time allows the user to comprehend more dimensions simultaneously. This talk will explain some new ideas about using sound in concert with sight to envision data in a new way.

#bangbangcon #bangbangconwest #bangbangconwest2020
Captions: 
	00:00:26,400 --> 00:00:32,290
Hi. I'm gonna be talking about sonification. So first, who I am. I'm don-E Merson. That's

00:00:32,290 --> 00:00:40,890
me before I donated my hair. I'm from the University of Arizona, and I am a PhD student

00:00:40,890 --> 00:00:47,390
at the School of Information. I'm also a programmer. Full stack developer by trade. I'm doing my

00:00:47,390 --> 00:00:52,110
PhD part-time, and hopefully eventually will get through it. And what you're about to hear

00:00:52,110 --> 00:00:58,120
is what I'm gonna do my thesis on. So the basic game plan for the next ten minutes is:

00:00:58,120 --> 00:01:01,809
What is sonification? In case you've never heard of this term before. What are some of

00:01:01,809 --> 00:01:07,520
the problems around that? And what are some of the solutions to these problems? And how

00:01:07,520 --> 00:01:12,799
can sonification let us see more dimensions? And that's really the gist of what I'm really

00:01:12,799 --> 00:01:19,640
interested in, is being able to see more dimensions. Not see with eyes, but actually perceive more

00:01:19,640 --> 00:01:23,420
dimensions simultaneously. And that's what I think we can do with sonification. And I'll

00:01:23,420 --> 00:01:27,689
talk a little about my future research, give you my email, in case you're interested in

00:01:27,689 --> 00:01:32,820
being part of that research. So what is it? So first let's think about visualization.

00:01:32,820 --> 00:01:37,090
What is visualization? Visualization is data turned into some kind of visual representation.

00:01:37,090 --> 00:01:46,640
That's a tough word. I shouldn't use multisyllable words here at the beginning. And sonification

00:01:46,640 --> 00:01:53,060
is data turned into audible representations. Right? So Wikipedia says: The sonification

00:01:53,060 --> 00:01:58,880
is the use of non-speech audio to convey information or perceptualize data. And part of me right

00:01:58,880 --> 00:02:04,620
off the bat wants to say: Why do we care about that it's non-speech data? Speech data could

00:02:04,620 --> 00:02:10,920
be one more dimension that we put in there. So sonification in real life. You know about

00:02:10,920 --> 00:02:15,659
sonification. You just never realized it was sonification. So a Geiger counter is an example

00:02:15,659 --> 00:02:19,170
of sonification. It's one dimensional data that you're walking around, and it's telling

00:02:19,170 --> 00:02:23,230
you... gee-gee-gee. I apologize to whoever is captioning. Because there will be lots

00:02:23,230 --> 00:02:30,400
of sound effects and stuff like that too. There's that. Heartbeat monitor. Once again,

00:02:30,400 --> 00:02:34,063
something that we can hear. And the rhythm will tell you whether or not -- I won't do

00:02:34,063 --> 00:02:40,090
the heartbeat. I know you're waiting for me to do that. And then radar. Radar has the

00:02:40,090 --> 00:02:44,719
sound, once again. And so these are ways that we can perceive information with sound. These

00:02:44,719 --> 00:02:50,049
are sonification in real life. So advantages and disadvantages. Visualization -- the pro

00:02:50,049 --> 00:02:54,939
is you can see all the data at once. It's gonna be the opposite for sonification, obviously.

00:02:54,939 --> 00:02:58,909
And it's a known entity. Ever since you were in grade school, you've been taught how to

00:02:58,909 --> 00:03:03,459
understand data in some kind of form like a bar chart, a pie chart, or something like

00:03:03,459 --> 00:03:09,049
that. So the con is there's a limited number of dimensions. There's really X, Y, and kind

00:03:09,049 --> 00:03:17,069
of Z. Z.5, maybe. Sonification -- the pro is you can perceive multiple dimensions. And

00:03:17,069 --> 00:03:21,379
this is the part to me that's the most interesting. And I kind of came about it in a really weird

00:03:21,379 --> 00:03:28,040
way. In a former life, I was a musician. And I was learning this -- creating this music

00:03:28,040 --> 00:03:32,120
theory, and I was trying to get all these dimensions that I was hearing musically, and

00:03:32,120 --> 00:03:36,670
put them down on paper, and it finally hit me. Wait. I'm going the wrong way. I can't

00:03:36,670 --> 00:03:40,330
put all these dimensions that I'm hearing -- I can't talk about all these things on

00:03:40,330 --> 00:03:46,309
sound and then put them down on paper. Because music notation is kind of weak in that way.

00:03:46,309 --> 00:03:49,340
And there's all these dimensions that I'm hearing, that are not on the page when I put

00:03:49,340 --> 00:03:54,000
it down, so I decided: Let's try to get it another way. If you're not 100% sure what

00:03:54,000 --> 00:03:58,400
I mean by all these different dimensions, let me give you an example. When I was a music

00:03:58,400 --> 00:04:03,749
teacher, I had a student. He would come in, and people would bring their songs in. I would

00:04:03,749 --> 00:04:08,809
teach them music. He came in. He was into punk rock. I taught him some power chords,

00:04:08,809 --> 00:04:15,920
he had an electric guitar, and he came up to me one day and said: Can you show me how

00:04:15,920 --> 00:04:19,910
they're doing it downstairs? He was just playing what you were playing, but he didn't hear

00:04:19,910 --> 00:04:25,490
it that way. I finally realized what the problem was. Went out to my car, got my distortion

00:04:25,490 --> 00:04:30,260
pedal, put in the distortion pedal. He's like... Oh yeah! That's exactly what I want to hear!

00:04:30,260 --> 00:04:34,850
To him, it wasn't the tone -- it was the tone that was the important part. It wasn't the

00:04:34,850 --> 00:04:39,250
actual pitch. Right? He was hearing something that was more important to him, that actually

00:04:39,250 --> 00:04:45,620
wasn't down on the music. So that's an example of one of those important dimensions that

00:04:45,620 --> 00:04:51,930
we don't hear. You don't write down "I have a distortion", or "I have an overdrive" or

00:04:51,930 --> 00:04:54,590
chorus or something like that. You don't write that down in the written music. All these

00:04:54,590 --> 00:04:59,510
other dimensions you hear and understand but you don't do it. The problem is unknown entity.

00:04:59,510 --> 00:05:05,660
You probably never heard of sonification before we came today. You can't see the data all

00:05:05,660 --> 00:05:09,750
at once. A Geiger counter, you don't have a readout of all the data you've seen as you

00:05:09,750 --> 00:05:14,990
walk around. That's the problem. And limited range of hearing. You can only hear so far.

00:05:14,990 --> 00:05:18,780
So there's gonna be a mapping of that. There's gonna be a compression of that, a lot of times.

00:05:18,780 --> 00:05:25,080
You can have really wide information. So... Multidimensional data. So what I mean by that

00:05:25,080 --> 00:05:29,080
is data with multiple columns. So visualizations -- you'll see something like this. You have

00:05:29,080 --> 00:05:34,790
the two real dimensions, the X and the Y, and you have these ocular variables. We have

00:05:34,790 --> 00:05:38,819
a few ocular variables. You see one right there. It's color. That color can let you

00:05:38,819 --> 00:05:43,240
understand what's going on here. You can't really see this. This is three types of biological

00:05:43,240 --> 00:05:49,240
entities. But you see you have X and Y, it's a positive correlation, and you see by color

00:05:49,240 --> 00:05:55,011
that these are related to these X and Y variables, very much so. Right? Another thing you can

00:05:55,011 --> 00:05:59,180
do is patterns. So if you ever had a heat map, and sometimes you'll have some kind of

00:05:59,180 --> 00:06:04,120
scratch pattern that you would see. Or another type of pattern would be like a -- if you

00:06:04,120 --> 00:06:09,789
ever work with R and they always have the obligatory ggplot cars data, and it has triangles

00:06:09,789 --> 00:06:14,419
or circles as part of a dimension, and there's size. Something could be bigger or smaller.

00:06:14,419 --> 00:06:18,850
And that can show another dimension of the data that you have. And there's faceting,

00:06:18,850 --> 00:06:22,949
which is basically taking a picture and doing it multiple times. So you have four dimensions

00:06:22,949 --> 00:06:27,630
that you see all at once. So sonification has lots of different things. For one thing,

00:06:27,630 --> 00:06:34,289
it's got pitch. So pitch is something that we hear right away. We can hear something...

00:06:34,289 --> 00:06:39,199
What pitch it is, and what we're really good at is hearing timbre or tone. We can tell

00:06:39,199 --> 00:06:43,069
the difference between a guitar and piano instantly. We don't have to think about it.

00:06:43,069 --> 00:06:49,719
It's just instant into our brain. Rhythm -- we have a good idea of basic rhythm. So when

00:06:49,719 --> 00:06:55,759
we hear duh-duh-duh or duh-duh-DUH. We can hear those are really different? We can understand

00:06:55,759 --> 00:07:03,669
that. Again, apologies to the captioner. How does that come across? Awesome. And then there's

00:07:03,669 --> 00:07:07,289
harmony. Harmony is basically chords, a whole bunch of notes put together, that end up having

00:07:07,289 --> 00:07:13,860
another quality to it. There's major and minor, like... When you're first learning, you think

00:07:13,860 --> 00:07:19,599
minor chords sound sad and major chords sound happy and stuff like that. There's much more

00:07:19,599 --> 00:07:26,000
different types of harmony out there. And there's melody. We use melody all the time.

00:07:26,000 --> 00:07:31,400
For example, you might hear something like... duhhh-duhh... (Star Wars) we know what's gonna

00:07:31,400 --> 00:07:35,660
happen. John Williams has told us the good guys are about to do something. Dunn-dunn…

00:07:35,660 --> 00:07:44,320
(imperial March) if we hear that... Here's that guy. The Darth Vader song comes on. That's

00:07:44,320 --> 00:07:49,610
a bit of data! In case you're not paying attention, falling asleep in the chair in the movie theater.

00:07:49,610 --> 00:07:56,520
Here's what you got. We have that ability to hear multiple types. We can hear the Darth

00:07:56,520 --> 00:08:04,199
Vader theme with a different pitch, a different instrument, maybe, and we can all of a sudden

00:08:04,199 --> 00:08:11,030
perceive multiple dimensions simultaneously. Also, placement in the aural field. So we

00:08:11,030 --> 00:08:15,860
are very good if we have headphones on -- you can hear left, right, and center. In the old

00:08:15,860 --> 00:08:20,419
days, they used to use that a lot with stereo. One guy would be on the left, one guy on the

00:08:20,419 --> 00:08:24,969
right. Actually, there's been studies that we actually are better at perceiving sound

00:08:24,969 --> 00:08:30,009
around us like that than we are with our eyes. So our aural field is actually really good.

00:08:30,009 --> 00:08:34,510
There are people who are actually doing this right now. If you've ever heard the song New

00:08:34,510 --> 00:08:41,830
York State of Mind, there's an ABAA pattern -- if you have the headphones on, you'll go

00:08:41,830 --> 00:08:45,668
left, right, left, left. Left, right, left, left.

00:08:45,668 --> 00:08:48,880
In the actual thing. So musicians already

00:08:48,880 --> 00:08:51,490
know it. They’re already using it. They kind of intuitively know it. They're not thinking

00:08:51,490 --> 00:08:58,191
about what that could actually mean. And there's echo. We're really good at hearing echo. You

00:08:58,191 --> 00:09:03,271
can tell I'm in a room right now that's kind of big. Versus if I was in a stadium. You

00:09:03,271 --> 00:09:07,770
can tell when people are in a stadium -- if you ever heard your favorite band in a rock

00:09:07,770 --> 00:09:12,690
stadium, you can understand that echo. We can hear that. We just don't have a way to

00:09:12,690 --> 00:09:19,030
talk about that yet. Right now. So the early experiments all used pitch to indicate size.

00:09:19,030 --> 00:09:22,940
So the data unfolds in time. Think about the Geiger counter, the heartbeat monitor, the

00:09:22,940 --> 00:09:29,160
data unfolding in time. There's another one. If anyone is interested in the gravity waves

00:09:29,160 --> 00:09:33,630
that were just discovered, the way they're representing the data is through sonification!

00:09:33,630 --> 00:09:37,950
It's this bllooooooop!

00:09:37,950 --> 00:09:40,100
(laughter)

00:09:40,100 --> 00:09:48,690
Awesome. So... That's one of the things they did. But there's some problems. It's really

00:09:48,690 --> 00:09:52,980
only one dimensional. Which is a big thing. And mapping the pitch -- that's another problem

00:09:52,980 --> 00:09:57,930
that we'll have to figure out. But it also takes -- takes away the multiple -- we haven't

00:09:57,930 --> 00:10:03,290
really talked about the multidimensional attributes of it. And it's a problem, because most people

00:10:03,290 --> 00:10:07,660
who are not musicians can't hear the difference between small pitch changes. Right? So you

00:10:07,660 --> 00:10:13,030
really... Having something like that, you're kind of excluding people who aren't musically

00:10:13,030 --> 00:10:18,510
trained. So this is where my research ideas come in. So I want to use sonification to

00:10:18,510 --> 00:10:25,650
expand the dimensions perceived. And I'd like to use it with a mouse with a tooltip. Imagine...

00:10:25,650 --> 00:10:33,030
Also add more dimensions visually. Imagine like a heat map. You have a heatmap and with

00:10:33,030 --> 00:10:42,300
your mouse... Am I done? Okay. All right. Sorry. I heard sound and reacted to it!

00:10:42,300 --> 00:10:43,330
(laughter)

00:10:43,330 --> 00:10:49,220
So as I mouse over something, I can hear multiple musical tones that explain something about

00:10:49,220 --> 00:10:52,910
what I'm actually touching at that moment. So that's the idea here. What I'm trying to

00:10:52,910 --> 00:10:58,141
do is find heat maps of the ear. So heat maps break down quantitative data into easy to

00:10:58,141 --> 00:11:04,370
distinguish colors. So it's not so much tone in the way that it's -- you know, it's a C

00:11:04,370 --> 00:11:10,160
versus a B, et cetera. But it's more like... Because people can't hear these minor changes.

00:11:10,160 --> 00:11:15,750
So break these up into easier distinguishing pitches. For example, low, medium, high. Right?

00:11:15,750 --> 00:11:19,690
For example... Other dimensions are easy to break up. Short melodies. We already did the

00:11:19,690 --> 00:11:25,090
John Williams thing with those little melodies. Different instruments. If a different instrument

00:11:25,090 --> 00:11:31,800
is playing a different melody, that's two dimensions that we can hear at a time, simultaneously.

00:11:31,800 --> 00:11:35,291
Left, right, and center. If we hear it on the left, it means something. If we hear it

00:11:35,291 --> 00:11:37,440
on the right, it means something, if we hear it in the center, it means something, if we

00:11:37,440 --> 00:11:43,950
hear all three, it might mean something else. The stadium, the small room, no echo, these

00:11:43,950 --> 00:11:50,200
are three different dimensions. We would break up and discretize the data into these ideas

00:11:50,200 --> 00:11:55,840
and simultaneously be able to put all the information together. So that's what my research

00:11:55,840 --> 00:12:00,700
is about in the next two years. What different dimensions can people perceive simultaneously?

00:12:00,700 --> 00:12:05,470
This is how I can hear it, but I was a trained musician. Maybe the normal person is not gonna

00:12:05,470 --> 00:12:10,100
be able to hear this. Part of that is gonna be some research time and actually... Hey,

00:12:10,100 --> 00:12:14,700
here's what this means. I play this. Can you tell me what that means? Does it matter if

00:12:14,700 --> 00:12:18,800
they're a musician or not, which is probably gonna be a big question, and then I'm gonna

00:12:18,800 --> 00:12:22,500
build a prototype tool to allow the configuration of different sonic dimensions. Once I know

00:12:22,500 --> 00:12:26,860
what people perceive, I'm gonna build this tool that is gonna allow people to take their

00:12:26,860 --> 00:12:32,000
data and be able to sonify it, and then test the usability of others, put together sonifications

00:12:32,000 --> 00:12:37,510
of other ideas to others. When you give the tool to someone and see what they do, actually

00:12:37,510 --> 00:12:42,790
help to see if that information is getting conveyed. So that's the idea there. If anyone

00:12:42,790 --> 00:12:50,230
is interested, I'm just starting. I'm working on my comprehensive this summer. That's my

00:12:50,230 --> 00:12:56,140
email address right there. dmerson@arizona.edu. Talk to me, I’ve got a lot of cards. If

00:12:56,140 --> 00:13:04,060
you're interested in the subject or have any ideas, I'm really early on this, so I'm happy

00:13:04,060 --> 00:13:09,630
to hear them. If anyone has ideas, I'm really excited to hear about them. So in conclusion,

00:13:09,630 --> 00:13:15,680
sonification is turning data into sound. Early experiments didn't use multidimensional aspects.

00:13:15,680 --> 00:13:21,270
And I'm looking to use heat maps of sound. And researching people's abilities to understand

00:13:21,270 --> 00:13:24,330

YouTube URL: https://www.youtube.com/watch?v=GbCL7k5K3BI


