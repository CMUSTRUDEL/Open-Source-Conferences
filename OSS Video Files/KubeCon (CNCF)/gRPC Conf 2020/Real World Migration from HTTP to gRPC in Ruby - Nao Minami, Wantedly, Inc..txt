Title: Real World Migration from HTTP to gRPC in Ruby - Nao Minami, Wantedly, Inc.
Publication date: 2020-08-01
Playlist: gRPC Conf 2020
Description: 
	Real World Migration from HTTP to gRPC in Ruby - Nao Minami, Wantedly, Inc. 

As of today we are running about 100 microservices at Wantedly, built with Ruby, Go, Python, Node, and Rust on our production Kubernetes cluster. While we’ve been historically using HTTP/1.1 for majority of inter microservices process communication, since the last year we have started introducing gRPC for some of our microservices which requires low latency and high throughput. This talk will cover the details of our migration approach and the performance improvement we’ve achieved as a result. Average latency got decreased by 50%, and 90%tile latency was decreased to a seventh. We will discuss our migration steps we’ve took, technical and organizational challenges we’ve faced during the migration, and also tools and libraries we’ve made in order for smooth transitions for servers originally built with Ruby on Rails.
Captions: 
	00:00:00,719 --> 00:00:04,880
thanks for joining my session today i'd

00:00:03,439 --> 00:00:07,440
like to talk about

00:00:04,880 --> 00:00:09,440
iowa and why we migrated into micro

00:00:07,440 --> 00:00:12,880
services communication method

00:00:09,440 --> 00:00:15,519
from http to jbc especially in our

00:00:12,880 --> 00:00:18,240
rubric microservice

00:00:15,519 --> 00:00:19,039
my name is nao and i work advantage from

00:00:18,240 --> 00:00:21,119
tokyo

00:00:19,039 --> 00:00:23,199
and i work as a software engineer at the

00:00:21,119 --> 00:00:26,480
infrastructure team

00:00:23,199 --> 00:00:29,519
my team has two responsibilities sre and

00:00:26,480 --> 00:00:32,160
development infrastructure why

00:00:29,519 --> 00:00:34,719
i worked on introducing of grpc in the

00:00:32,160 --> 00:00:36,640
microservices

00:00:34,719 --> 00:00:38,719
in this talk i'd like to talk about

00:00:36,640 --> 00:00:41,280
those three things

00:00:38,719 --> 00:00:42,840
the first one is why we decided to

00:00:41,280 --> 00:00:45,360
introduce

00:00:42,840 --> 00:00:48,480
grpc and the second one

00:00:45,360 --> 00:00:50,239
is about how we migrate it from http to

00:00:48,480 --> 00:00:52,719
jpc

00:00:50,239 --> 00:00:55,680
and the third one is what we achieved by

00:00:52,719 --> 00:00:55,680
using jpc

00:00:55,760 --> 00:00:59,440
okay let's start from y

00:00:59,680 --> 00:01:04,799
at first as a background let me

00:01:02,000 --> 00:01:08,240
introduce my company's products

00:01:04,799 --> 00:01:10,240
we have several products advantage visit

00:01:08,240 --> 00:01:11,119
is a product for javascript candidate

00:01:10,240 --> 00:01:13,600
matching

00:01:11,119 --> 00:01:16,240
advantage people is a product for

00:01:13,600 --> 00:01:18,560
professional contact management

00:01:16,240 --> 00:01:19,520
by this product we offer our user

00:01:18,560 --> 00:01:22,720
experience like

00:01:19,520 --> 00:01:25,280
linkedin based in agil

00:01:22,720 --> 00:01:25,759
these products are on one platform which

00:01:25,280 --> 00:01:28,000
means

00:01:25,759 --> 00:01:29,040
they share the same set of users profile

00:01:28,000 --> 00:01:31,119
data

00:01:29,040 --> 00:01:34,479
so use that profile data is very

00:01:31,119 --> 00:01:34,479
important for our products

00:01:34,880 --> 00:01:39,119
our products are built with more than

00:01:36,560 --> 00:01:42,320
100 micro services

00:01:39,119 --> 00:01:45,759
they are written in ruby girl python

00:01:42,320 --> 00:01:47,360
non.js etc and run on the kubernetes

00:01:45,759 --> 00:01:50,799
cluster

00:01:47,360 --> 00:01:54,240
we have been using h1 for majority of my

00:01:50,799 --> 00:01:56,479
microservices as i said

00:01:54,240 --> 00:01:57,680
user profile data is very important for

00:01:56,479 --> 00:01:59,840
our products

00:01:57,680 --> 00:02:01,600
and it is managed by a service we call

00:01:59,840 --> 00:02:05,759
user service

00:02:01,600 --> 00:02:08,080
so this service is very important for us

00:02:05,759 --> 00:02:09,599
now this service is written in a movie

00:02:08,080 --> 00:02:13,200
by historical reason

00:02:09,599 --> 00:02:17,120
and today i focus on this service

00:02:13,200 --> 00:02:19,360
let's dig into the details of user size

00:02:17,120 --> 00:02:22,720
user services and microservice used to

00:02:19,360 --> 00:02:25,520
get or update user's profile data

00:02:22,720 --> 00:02:27,200
this substrate fundamental data so used

00:02:25,520 --> 00:02:30,480
from many micro services

00:02:27,200 --> 00:02:33,280
and the high throughput is required

00:02:30,480 --> 00:02:35,280
and this services latency often directly

00:02:33,280 --> 00:02:39,120
affects the user experience

00:02:35,280 --> 00:02:40,879
the low latency is also required

00:02:39,120 --> 00:02:42,560
this service was widely used in the

00:02:40,879 --> 00:02:46,239
microservices

00:02:42,560 --> 00:02:47,920
but there was a problem so what was the

00:02:46,239 --> 00:02:50,400
problem

00:02:47,920 --> 00:02:52,560
the problem was the latency caused by

00:02:50,400 --> 00:02:55,360
using h1

00:02:52,560 --> 00:02:57,680
without keep arrive hn does not perform

00:02:55,360 --> 00:03:00,879
well for several reasons

00:02:57,680 --> 00:03:03,680
for example dns program and the tcp 3

00:03:00,879 --> 00:03:05,280
handshake is necessary increase their

00:03:03,680 --> 00:03:07,920
latency

00:03:05,280 --> 00:03:09,760
and the tcp strong stuff is also a

00:03:07,920 --> 00:03:11,840
problem

00:03:09,760 --> 00:03:13,120
we reduced the server side latency as

00:03:11,840 --> 00:03:15,040
much as possible

00:03:13,120 --> 00:03:18,000
but it was not enough to meet the

00:03:15,040 --> 00:03:22,640
increasing demand

00:03:18,000 --> 00:03:22,640
so we decided to introduce jrpc

00:03:23,599 --> 00:03:28,799
ygrpc as you know there are some rpc

00:03:27,120 --> 00:03:31,599
frameworks involved

00:03:28,799 --> 00:03:32,720
and we could choose a suitable one in

00:03:31,599 --> 00:03:36,080
that situation

00:03:32,720 --> 00:03:38,000
we've decided to use grpc by those three

00:03:36,080 --> 00:03:41,360
reasons

00:03:38,000 --> 00:03:44,560
the first reason is high performance

00:03:41,360 --> 00:03:46,720
grpc is written h2 and

00:03:44,560 --> 00:03:48,959
so it can use run drive real-time

00:03:46,720 --> 00:03:51,120
communication streams

00:03:48,959 --> 00:03:53,280
this gives us low latency and high

00:03:51,120 --> 00:03:56,720
throughput

00:03:53,280 --> 00:04:00,080
the second reason is protocol buffers

00:03:56,720 --> 00:04:02,560
grpc uses protocol buffers it provides

00:04:00,080 --> 00:04:04,720
a single source of truth of grpc service

00:04:02,560 --> 00:04:07,840
definition

00:04:04,720 --> 00:04:09,040
it is a very good point and as an

00:04:07,840 --> 00:04:11,439
additional good point

00:04:09,040 --> 00:04:14,720
we were already using protocol buffers

00:04:11,439 --> 00:04:18,160
over h1 before using jpc

00:04:14,720 --> 00:04:20,479
so it was a very natural choice for us

00:04:18,160 --> 00:04:22,240
and the third reason is multiple ranking

00:04:20,479 --> 00:04:24,080
support

00:04:22,240 --> 00:04:25,440
we have micro services written in

00:04:24,080 --> 00:04:29,360
several languages such as

00:04:25,440 --> 00:04:32,479
ruby python go nos.js etc

00:04:29,360 --> 00:04:36,080
and the grpc support disadvantages

00:04:32,479 --> 00:04:40,400
it was a very important point

00:04:36,080 --> 00:04:40,400
for these reasons we chose grpc

00:04:40,880 --> 00:04:44,479
ok the next topic is how we migrate it

00:04:43,440 --> 00:04:49,280
from http

00:04:44,479 --> 00:04:52,479
to jpc how we migrate it

00:04:49,280 --> 00:04:55,199
looking back i think there are two steps

00:04:52,479 --> 00:04:58,320
the first step is preparation and the

00:04:55,199 --> 00:05:02,720
second step is migration

00:04:58,320 --> 00:05:05,199
let's start from the preparation step

00:05:02,720 --> 00:05:06,639
for using jvc there are four required

00:05:05,199 --> 00:05:09,520
preparations

00:05:06,639 --> 00:05:10,160
schema management monitoring productive

00:05:09,520 --> 00:05:13,919
development

00:05:10,160 --> 00:05:16,320
environment and load balancing right now

00:05:13,919 --> 00:05:17,759
the jvc ecosystem is not so mentioned

00:05:16,320 --> 00:05:19,919
enough so

00:05:17,759 --> 00:05:22,320
especially in ruby so we have to think

00:05:19,919 --> 00:05:25,840
about those things

00:05:22,320 --> 00:05:25,840
the first one is schema management

00:05:26,400 --> 00:05:31,280
without the monorail which means under

00:05:28,560 --> 00:05:33,039
the system maintain multiple robberies

00:05:31,280 --> 00:05:35,919
we have to share the same profiles

00:05:33,039 --> 00:05:38,880
across the multiple repositories

00:05:35,919 --> 00:05:41,120
so how should we share profiles a few

00:05:38,880 --> 00:05:44,240
approaches we can take here

00:05:41,120 --> 00:05:45,360
for example copy and paste manually in

00:05:44,240 --> 00:05:47,520
this approach

00:05:45,360 --> 00:05:50,720
it's very hard to update multiple

00:05:47,520 --> 00:05:53,039
laboratories continuously

00:05:50,720 --> 00:05:54,560
download profiles automatically in each

00:05:53,039 --> 00:05:56,720
battery

00:05:54,560 --> 00:05:58,479
in this approach you still need to

00:05:56,720 --> 00:06:00,160
generate code manually for each

00:05:58,479 --> 00:06:02,240
repository

00:06:00,160 --> 00:06:03,680
so you will suffer from the differences

00:06:02,240 --> 00:06:06,560
in each device

00:06:03,680 --> 00:06:08,000
environment for example version of proxy

00:06:06,560 --> 00:06:11,520
presence over plugins

00:06:08,000 --> 00:06:14,880
etc so we decided to make a central

00:06:11,520 --> 00:06:14,880
repository for profiles

00:06:15,199 --> 00:06:20,400
apis this is the central repository for

00:06:17,520 --> 00:06:23,680
schema management

00:06:20,400 --> 00:06:28,720
api source open files for our company

00:06:23,680 --> 00:06:28,720
and do various tasks in the ca pipelines

00:06:28,880 --> 00:06:33,759
how to use aps report3 in this

00:06:31,759 --> 00:06:36,160
repository code is automatically

00:06:33,759 --> 00:06:39,199
generated in the series pipelines

00:06:36,160 --> 00:06:42,319
ruby go and node.js code is generated

00:06:39,199 --> 00:06:45,280
in for each profile then

00:06:42,319 --> 00:06:46,240
generated code is distributed via packet

00:06:45,280 --> 00:06:50,240
managers

00:06:46,240 --> 00:06:52,960
such as bandwagon commodores and npm

00:06:50,240 --> 00:06:55,840
with this workflow developers don't need

00:06:52,960 --> 00:06:57,919
to generate code by themselves and

00:06:55,840 --> 00:07:00,240
can focus on the implementation of

00:06:57,919 --> 00:07:03,280
features

00:07:00,240 --> 00:07:06,000
this is an example code in apis

00:07:03,280 --> 00:07:07,840
ruby code generated and published at

00:07:06,000 --> 00:07:10,800
rubygems

00:07:07,840 --> 00:07:14,639
by using bandra the robot can fetch and

00:07:10,800 --> 00:07:14,639
use a generated ruby code

00:07:15,520 --> 00:07:22,319
so with this workflow how we drop jp

00:07:19,360 --> 00:07:26,240
servers on the client in ruby

00:07:22,319 --> 00:07:28,479
for jpc servers we implement a cloud

00:07:26,240 --> 00:07:31,360
which enhance the generated grpc service

00:07:28,479 --> 00:07:33,199
class based from apis

00:07:31,360 --> 00:07:34,639
by implementing instance methods for

00:07:33,199 --> 00:07:38,319
each ipc method

00:07:34,639 --> 00:07:41,360
we can use jpc servers written in ruby

00:07:38,319 --> 00:07:44,639
and for jrpg clients

00:07:41,360 --> 00:07:47,440
we use a subgraph first from apis

00:07:44,639 --> 00:07:49,840
by using a stub object like this we can

00:07:47,440 --> 00:07:51,520
communicate with grpc servers in ruby

00:07:49,840 --> 00:07:54,319
code

00:07:51,520 --> 00:07:59,280
this is the basic usage of apis and we

00:07:54,319 --> 00:08:03,440
drop grpc servers and clients like this

00:07:59,280 --> 00:08:05,360
okay and the next topic is monitoring

00:08:03,440 --> 00:08:08,400
as you know application monitoring is

00:08:05,360 --> 00:08:10,400
required in production

00:08:08,400 --> 00:08:12,160
as a background we were using various

00:08:10,400 --> 00:08:15,680
source products such as feedback

00:08:12,160 --> 00:08:17,599
numeric animation etc for monitoring our

00:08:15,680 --> 00:08:20,000
h1 servers

00:08:17,599 --> 00:08:20,800
we wanted to continue to use them for

00:08:20,000 --> 00:08:26,240
grpc

00:08:20,800 --> 00:08:29,199
servers the hard monitor grpc servers

00:08:26,240 --> 00:08:31,199
for this purpose we can use grpc

00:08:29,199 --> 00:08:34,640
interceptors

00:08:31,199 --> 00:08:37,200
we need to send metrics of hdfc request

00:08:34,640 --> 00:08:40,000
and with grpc intercepts that we can

00:08:37,200 --> 00:08:43,599
implement such features

00:08:40,000 --> 00:08:45,600
jrpc intercepts as a user activist

00:08:43,599 --> 00:08:47,200
the current interceptors and server

00:08:45,600 --> 00:08:50,000
interceptors

00:08:47,200 --> 00:08:51,120
client interceptors are executed on the

00:08:50,000 --> 00:08:53,360
jvc client

00:08:51,120 --> 00:08:54,399
around the user code and server

00:08:53,360 --> 00:08:57,200
interceptors are

00:08:54,399 --> 00:08:59,360
executed on the jvc server before the

00:08:57,200 --> 00:09:01,519
request is passed onto the user's

00:08:59,360 --> 00:09:03,680
application logic

00:09:01,519 --> 00:09:05,440
it is a perfect way to implement command

00:09:03,680 --> 00:09:08,720
patterns for example logging

00:09:05,440 --> 00:09:10,959
monitoring authentication etc

00:09:08,720 --> 00:09:13,440
so we can use jpc interceptors for

00:09:10,959 --> 00:09:16,240
monitoring

00:09:13,440 --> 00:09:17,279
but jpc interceptors for each such

00:09:16,240 --> 00:09:20,240
products are

00:09:17,279 --> 00:09:22,880
not actually provided at this time so we

00:09:20,240 --> 00:09:26,320
have to implement some grpc interceptors

00:09:22,880 --> 00:09:28,399
by ourselves we implemented

00:09:26,320 --> 00:09:29,680
them and made them available to the

00:09:28,399 --> 00:09:32,480
rubric community as

00:09:29,680 --> 00:09:35,680
open source software the published

00:09:32,480 --> 00:09:37,920
interceptors are shown here

00:09:35,680 --> 00:09:40,480
for example we implemented the grpc

00:09:37,920 --> 00:09:42,399
interceptor from neuric

00:09:40,480 --> 00:09:45,920
with this channel we can send the metric

00:09:42,399 --> 00:09:49,120
matrix to numeric in each request

00:09:45,920 --> 00:09:51,040
and the other one is a jpc interceptor

00:09:49,120 --> 00:09:53,279
for open sensors

00:09:51,040 --> 00:09:55,200
with this gel we can send the metrics to

00:09:53,279 --> 00:09:56,800
some such products supporting open

00:09:55,200 --> 00:09:59,200
sensors

00:09:56,800 --> 00:10:00,959
and another one is the jpc interceptor

00:09:59,200 --> 00:10:03,120
for access logging

00:10:00,959 --> 00:10:05,600
with this gen we can print access routes

00:10:03,120 --> 00:10:08,640
in a specified format

00:10:05,600 --> 00:10:11,920
by this grpc interceptors we monitor

00:10:08,640 --> 00:10:11,920
our grpc servers

00:10:12,640 --> 00:10:17,279
ok the next topic is productive

00:10:14,959 --> 00:10:21,760
development environment

00:10:17,279 --> 00:10:21,760
as you know it is very important topic

00:10:22,079 --> 00:10:26,079
now we need to create a product

00:10:23,920 --> 00:10:29,440
development environment for jpc

00:10:26,079 --> 00:10:31,920
by ourselves for h1 servers

00:10:29,440 --> 00:10:32,959
the ecosystem is major and the many open

00:10:31,920 --> 00:10:35,600
source

00:10:32,959 --> 00:10:37,120
source libraries exist so we can use

00:10:35,600 --> 00:10:39,440
them

00:10:37,120 --> 00:10:40,480
but this is not the case with grpt

00:10:39,440 --> 00:10:44,079
servers

00:10:40,480 --> 00:10:46,079
especially in ruby we need to

00:10:44,079 --> 00:10:48,720
create a productive development

00:10:46,079 --> 00:10:54,079
environment by ourselves

00:10:48,720 --> 00:10:54,079
so how to create success environment

00:10:54,160 --> 00:10:57,760
for the productivity we use a common

00:10:56,560 --> 00:11:01,360
utility library

00:10:57,760 --> 00:11:02,399
named subsix we want to use some useful

00:11:01,360 --> 00:11:04,560
features for you

00:11:02,399 --> 00:11:06,399
for example hot reloading and utility

00:11:04,560 --> 00:11:08,880
for protocol buffers

00:11:06,399 --> 00:11:09,760
and we want to avoid repeating the same

00:11:08,880 --> 00:11:12,800
configuration

00:11:09,760 --> 00:11:14,720
in multiple micro services so we

00:11:12,800 --> 00:11:16,959
implemented a common utility library

00:11:14,720 --> 00:11:19,200
named servicex

00:11:16,959 --> 00:11:20,480
servicex is used by all jpc

00:11:19,200 --> 00:11:23,279
microservices

00:11:20,480 --> 00:11:23,279
in our company

00:11:23,519 --> 00:11:26,959
i'll show you some useful features of

00:11:25,279 --> 00:11:30,079
servicex

00:11:26,959 --> 00:11:31,760
for jbc servers we implemented jpc

00:11:30,079 --> 00:11:35,120
server command

00:11:31,760 --> 00:11:38,480
this is used like this we execute

00:11:35,120 --> 00:11:39,360
bundle xx jvc server then jfc server

00:11:38,480 --> 00:11:42,959
process starts

00:11:39,360 --> 00:11:47,200
run it prints some rocks and the third

00:11:42,959 --> 00:11:47,200
reason known about 6046

00:11:48,560 --> 00:11:52,399
with this command the rpc service class

00:11:50,959 --> 00:11:55,200
is automatically

00:11:52,399 --> 00:11:56,079
loaded and the sum of jvc intercepts are

00:11:55,200 --> 00:11:59,360
automatically

00:11:56,079 --> 00:12:02,800
set afterwarding feature is also

00:11:59,360 --> 00:12:04,320
implemented with this command developers

00:12:02,800 --> 00:12:06,959
can just focus on the

00:12:04,320 --> 00:12:08,959
implementation of the grpc service

00:12:06,959 --> 00:12:11,760
classes

00:12:08,959 --> 00:12:12,880
and next for javascript clients we

00:12:11,760 --> 00:12:16,320
implemented

00:12:12,880 --> 00:12:19,680
servicex jpc start form method

00:12:16,320 --> 00:12:19,680
this is just like this

00:12:21,120 --> 00:12:25,680
with this method some jbc intercepts

00:12:23,440 --> 00:12:26,160
that are automatically set and the user

00:12:25,680 --> 00:12:29,519
agent

00:12:26,160 --> 00:12:31,519
is automatically configured so their

00:12:29,519 --> 00:12:33,839
developers don't need to do

00:12:31,519 --> 00:12:34,880
complicated configuration so they can

00:12:33,839 --> 00:12:38,639
just focus on

00:12:34,880 --> 00:12:41,120
implementing the business logic

00:12:38,639 --> 00:12:42,079
and the next by using protocol buffers

00:12:41,120 --> 00:12:46,079
in ruby

00:12:42,079 --> 00:12:48,480
we implement the utd library named pb

00:12:46,079 --> 00:12:51,120
with vb we can create photograph objects

00:12:48,480 --> 00:12:53,279
more easily

00:12:51,120 --> 00:12:55,519
for example as shown here we can create

00:12:53,279 --> 00:12:59,040
a timestamp object from a string object

00:12:55,519 --> 00:13:00,880
in the easy way without bb we have to

00:12:59,040 --> 00:13:03,920
convert a string object to a time

00:13:00,880 --> 00:13:06,000
object by time.first method then pass it

00:13:03,920 --> 00:13:09,120
to the google.timestamp class

00:13:06,000 --> 00:13:11,519
as an argument on the other hand

00:13:09,120 --> 00:13:13,680
with bb we don't need to do such

00:13:11,519 --> 00:13:16,800
complicated things

00:13:13,680 --> 00:13:19,279
by passing a string object to bb.27

00:13:16,800 --> 00:13:19,839
stamp method we can get a protocol

00:13:19,279 --> 00:13:25,040
timestamp

00:13:19,839 --> 00:13:28,160
object easily and the fibo.method

00:13:25,040 --> 00:13:30,079
is also useful with this method

00:13:28,160 --> 00:13:32,560
we can create user-defined prototype

00:13:30,079 --> 00:13:35,360
object from hash object

00:13:32,560 --> 00:13:35,600
as shown here the values of hash objects

00:13:35,360 --> 00:13:37,839
are

00:13:35,600 --> 00:13:39,040
automatically converted to broadband

00:13:37,839 --> 00:13:40,720
objects

00:13:39,040 --> 00:13:44,000
so we can create nested prototype

00:13:40,720 --> 00:13:44,000
objects in the easy way

00:13:44,480 --> 00:13:49,199
maybe it's included in subsets but we

00:13:47,120 --> 00:13:52,320
made it available to the ruby community

00:13:49,199 --> 00:13:53,040
as open source software so if you are

00:13:52,320 --> 00:13:56,160
interested

00:13:53,040 --> 00:13:59,519
please try it that's all for

00:13:56,160 --> 00:14:03,519
services and the next topic is

00:13:59,519 --> 00:14:04,639
vmrays for productivity we decided to

00:14:03,519 --> 00:14:07,760
use grpc

00:14:04,639 --> 00:14:09,920
combined with parts of program rates

00:14:07,760 --> 00:14:12,000
at the background we migrated to

00:14:09,920 --> 00:14:14,240
migrated from ruby on race

00:14:12,000 --> 00:14:16,000
and wanted to keep using possible

00:14:14,240 --> 00:14:18,639
features in it

00:14:16,000 --> 00:14:20,480
so we decided to use jerpush jam with

00:14:18,639 --> 00:14:22,560
rav jam

00:14:20,480 --> 00:14:24,720
and we found that it's very useful to

00:14:22,560 --> 00:14:27,839
build a jpc server with portable

00:14:24,720 --> 00:14:28,800
uploading rate so we recommend this

00:14:27,839 --> 00:14:32,639
configuration

00:14:28,800 --> 00:14:32,639
if you are in the same situation

00:14:33,040 --> 00:14:37,199
and then next let's think about the load

00:14:35,680 --> 00:14:40,560
balancing

00:14:37,199 --> 00:14:43,360
what should we consider for it

00:14:40,560 --> 00:14:45,440
for grpc f4 load balancers and very

00:14:43,360 --> 00:14:48,480
useful

00:14:45,440 --> 00:14:50,560
as you know jrpc is the rhythm h2

00:14:48,480 --> 00:14:53,120
which is designed to have a single long

00:14:50,560 --> 00:14:56,560
live tcp connection

00:14:53,120 --> 00:14:58,959
so in forward balances once that

00:14:56,560 --> 00:15:01,519
connection is established there's no

00:14:58,959 --> 00:15:03,600
more browsing to be done

00:15:01,519 --> 00:15:05,519
our request will get into a single

00:15:03,600 --> 00:15:09,040
destination

00:15:05,519 --> 00:15:12,160
this is not a good situation

00:15:09,040 --> 00:15:14,399
so we use steel for s7 load balancing in

00:15:12,160 --> 00:15:16,560
kubernetes classes

00:15:14,399 --> 00:15:18,000
as shown here and by continents

00:15:16,560 --> 00:15:21,279
configured by steel

00:15:18,000 --> 00:15:25,199
are injected as cycle proxies and used

00:15:21,279 --> 00:15:28,240
for l7 application level road balancing

00:15:25,199 --> 00:15:31,040
by this configuration the load is evenly

00:15:28,240 --> 00:15:31,040
distributed

00:15:31,680 --> 00:15:39,279
okay i explained the preparation step

00:15:35,040 --> 00:15:42,560
next i'll introduce our migration step

00:15:39,279 --> 00:15:45,360
so how we migrate it

00:15:42,560 --> 00:15:47,759
in the migration a basic strategy that

00:15:45,360 --> 00:15:50,240
tries more

00:15:47,759 --> 00:15:53,680
at first we made a prototype as a

00:15:50,240 --> 00:15:56,480
profile concept to frequency impact

00:15:53,680 --> 00:15:57,360
and then next we used grpc for our part

00:15:56,480 --> 00:16:00,240
of the traffic

00:15:57,360 --> 00:16:01,440
in production and gradually increase the

00:16:00,240 --> 00:16:08,000
percentage of the

00:16:01,440 --> 00:16:10,959
jvc this is a schematic diagram of plc

00:16:08,000 --> 00:16:13,680
have a development vanettes cluster this

00:16:10,959 --> 00:16:17,199
is separate from production faster

00:16:13,680 --> 00:16:20,000
and we tried jrpc in this cluster

00:16:17,199 --> 00:16:22,160
by using a development cluster we could

00:16:20,000 --> 00:16:25,759
try jrpc without worrying about

00:16:22,160 --> 00:16:25,759
affecting production environment

00:16:26,000 --> 00:16:31,199
this is the result of poc

00:16:29,279 --> 00:16:33,360
this diagram shows the distribution of

00:16:31,199 --> 00:16:35,440
latency

00:16:33,360 --> 00:16:38,480
as shown here latency decreased

00:16:35,440 --> 00:16:41,199
dramatically in all cases

00:16:38,480 --> 00:16:45,120
by seeing this result we decided to try

00:16:41,199 --> 00:16:45,120
jpc in a production cluster

00:16:45,519 --> 00:16:52,959
so how we tried grpc in production

00:16:50,480 --> 00:16:56,399
this is a schematic diagram of our trial

00:16:52,959 --> 00:16:59,120
observation in the production cluster

00:16:56,399 --> 00:17:01,120
at first we used jvc for only a small

00:16:59,120 --> 00:17:03,199
part of the traffic

00:17:01,120 --> 00:17:04,400
by trying small we could minimize the

00:17:03,199 --> 00:17:07,439
preparation cost

00:17:04,400 --> 00:17:10,000
to minimize risk and the next

00:17:07,439 --> 00:17:12,240
we gradually increase increase the

00:17:10,000 --> 00:17:15,360
percentage of grpc

00:17:12,240 --> 00:17:18,559
by gradually increasing the traffic

00:17:15,360 --> 00:17:22,720
we could control the risk and finally

00:17:18,559 --> 00:17:22,720
we could achieve the complete migration

00:17:23,760 --> 00:17:28,400
with these steps we migrated to grpc

00:17:28,799 --> 00:17:32,000
okay on the next let me introduce the

00:17:30,880 --> 00:17:35,039
result achieved by

00:17:32,000 --> 00:17:35,039
using jpc

00:17:35,280 --> 00:17:39,600
as a result we've achieved the

00:17:37,200 --> 00:17:42,799
performance improvement

00:17:39,600 --> 00:17:46,080
by using jpc average latency decrease

00:17:42,799 --> 00:17:48,720
dramatically average latency

00:17:46,080 --> 00:17:49,840
decreased by about 20 milliseconds per

00:17:48,720 --> 00:17:52,240
request

00:17:49,840 --> 00:17:54,080
and the impact was more remarkable when

00:17:52,240 --> 00:17:57,200
many requests to user service were

00:17:54,080 --> 00:17:59,760
involved in one web transaction

00:17:57,200 --> 00:18:01,039
for example as soon as shown here in the

00:17:59,760 --> 00:18:04,160
microservices

00:18:01,039 --> 00:18:06,720
average frequency decreased by a half

00:18:04,160 --> 00:18:07,600
the brand one is the latency when using

00:18:06,720 --> 00:18:09,520
h1

00:18:07,600 --> 00:18:11,600
and the later one is the latency when

00:18:09,520 --> 00:18:14,320
using jpc

00:18:11,600 --> 00:18:15,120
average latency to decreased from 130

00:18:14,320 --> 00:18:19,120
milliseconds

00:18:15,120 --> 00:18:21,760
to 65 music by switching to jrpc

00:18:19,120 --> 00:18:23,600
in this microservice multiple request

00:18:21,760 --> 00:18:27,120
user service were involved

00:18:23,600 --> 00:18:30,559
so the impact was remarkable

00:18:27,120 --> 00:18:32,160
so by using jrpc we could achieve a

00:18:30,559 --> 00:18:36,000
performance improvement

00:18:32,160 --> 00:18:36,000
and improve the user experience

00:18:36,080 --> 00:18:41,360
next let me introduce what we are doing

00:18:38,080 --> 00:18:41,360
since migration

00:18:41,760 --> 00:18:44,880
after the success of the migration from

00:18:44,080 --> 00:18:46,960
http

00:18:44,880 --> 00:18:48,960
to jvc and the achievement of

00:18:46,960 --> 00:18:51,679
performance improvement

00:18:48,960 --> 00:18:54,640
the use of grpc is increasing throughout

00:18:51,679 --> 00:18:54,640
the organization

00:18:54,960 --> 00:19:00,000
now almost all clients of user service

00:18:57,520 --> 00:19:01,840
are using jvc

00:19:00,000 --> 00:19:04,480
and the new microservices are being

00:19:01,840 --> 00:19:07,520
developed using grpc

00:19:04,480 --> 00:19:08,559
and the jvc started to be used in other

00:19:07,520 --> 00:19:12,240
languages

00:19:08,559 --> 00:19:15,200
for example gold not js etc

00:19:12,240 --> 00:19:17,919
so jrpc is becoming vitally used in the

00:19:15,200 --> 00:19:17,919
organization

00:19:18,640 --> 00:19:24,080
this is the summary of this talk

00:19:21,840 --> 00:19:25,840
at first i talked about why we chose

00:19:24,080 --> 00:19:28,480
jrpc

00:19:25,840 --> 00:19:30,799
and the answer is what we needed a high

00:19:28,480 --> 00:19:34,880
performance average framework

00:19:30,799 --> 00:19:37,280
and the jvc was performant enough

00:19:34,880 --> 00:19:39,039
and another reason is that we by already

00:19:37,280 --> 00:19:42,160
using protocol first

00:19:39,039 --> 00:19:44,000
so it was a natural choice and

00:19:42,160 --> 00:19:46,640
we also needed multiple languages

00:19:44,000 --> 00:19:49,679
support because we had micro services

00:19:46,640 --> 00:19:51,840
seats written in several languages

00:19:49,679 --> 00:19:53,840
jvg supported them it was a very

00:19:51,840 --> 00:19:56,400
important point

00:19:53,840 --> 00:19:57,440
and next i talked about how we migrated

00:19:56,400 --> 00:20:00,720
from http

00:19:57,440 --> 00:20:02,799
to jrpc by using jpc

00:20:00,720 --> 00:20:06,559
we have created a workflow for protocol

00:20:02,799 --> 00:20:08,559
buffers using our aps repository

00:20:06,559 --> 00:20:10,880
and we have also developed some

00:20:08,559 --> 00:20:14,159
libraries for productive development

00:20:10,880 --> 00:20:17,120
environment of jrpc and published some

00:20:14,159 --> 00:20:20,400
of them as oss

00:20:17,120 --> 00:20:21,760
and in migration step the basic strategy

00:20:20,400 --> 00:20:23,760
were try small

00:20:21,760 --> 00:20:27,760
so we tried in the smoke and the quick

00:20:23,760 --> 00:20:30,240
way then we could achieve the migration

00:20:27,760 --> 00:20:33,520
at last i talked about some results of

00:20:30,240 --> 00:20:36,000
migration from http to jpc

00:20:33,520 --> 00:20:38,320
by using jpc we could achieve the

00:20:36,000 --> 00:20:40,799
performance improvement

00:20:38,320 --> 00:20:43,360
now the use of jpc is increasing

00:20:40,799 --> 00:20:48,480
throughout the organization

00:20:43,360 --> 00:20:48,480

YouTube URL: https://www.youtube.com/watch?v=rx8pzZC6PYw


