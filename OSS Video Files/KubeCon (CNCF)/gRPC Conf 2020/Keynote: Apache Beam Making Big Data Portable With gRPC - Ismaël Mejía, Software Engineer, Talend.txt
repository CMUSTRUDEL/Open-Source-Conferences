Title: Keynote: Apache Beam Making Big Data Portable With gRPC - Ismaël Mejía, Software Engineer, Talend
Publication date: 2020-08-01
Playlist: gRPC Conf 2020
Description: 
	Keynote: Apache Beam Making Big Data Portable With gRPC - Ismaël Mejía, Software Engineer, Talend 

Apache Beam is a unified programming model designed to create efficient and portable data processing pipelines. Portability in Apache Beam has two meanings: Users of Apache Beam can run their programs in different execution systems e.g. Apache Spark, Apache Flink, etc and they can choose their favorite (supported) language and be able to execute pipelines even if the targeted execution system does not support the language natively. In this talk we introduce Beam, its architecture based on translators (runners) and its portability framework: a set of gRPC services to coordinate the execution of functions isolated in language specific environments. The use of gRPC on Beam provides not only clear and easy to evolve contracts to coordinate the execution of functions but it offers nice isolation properties if combined with containers.
Captions: 
	00:00:00,160 --> 00:00:04,000
hello everyone thanks for joining this

00:00:02,639 --> 00:00:06,000
session

00:00:04,000 --> 00:00:07,759
i'm going to talk with you about apache

00:00:06,000 --> 00:00:10,160
beam and how we

00:00:07,759 --> 00:00:12,240
use grpc to make big data processing

00:00:10,160 --> 00:00:14,480
portable portable between different

00:00:12,240 --> 00:00:16,720
execution systems and portable between

00:00:14,480 --> 00:00:20,000
different languages also

00:00:16,720 --> 00:00:21,199
uh so first i introduced myself my name

00:00:20,000 --> 00:00:24,160
is ismael mejia

00:00:21,199 --> 00:00:26,640
i'm a software engineer and you can

00:00:24,160 --> 00:00:30,000
follow me on twitter in this handle

00:00:26,640 --> 00:00:32,320
um mostly working in apache big

00:00:30,000 --> 00:00:33,760
data projects basically apache abram

00:00:32,320 --> 00:00:36,079
apache pmc

00:00:33,760 --> 00:00:37,840
i also contribute to others and i'm a

00:00:36,079 --> 00:00:39,280
member of the apache solar foundation i

00:00:37,840 --> 00:00:43,040
work for italian

00:00:39,280 --> 00:00:45,039
which is a big data and data integration

00:00:43,040 --> 00:00:46,239
company that has software opens to

00:00:45,039 --> 00:00:48,960
software and supporting the cloud in

00:00:46,239 --> 00:00:51,440
case you want to take a look about

00:00:48,960 --> 00:00:53,440
okay so first we are going to talk about

00:00:51,440 --> 00:00:55,360
the big data world

00:00:53,440 --> 00:00:57,039
and this is that small introduction

00:00:55,360 --> 00:00:58,719
because i know the

00:00:57,039 --> 00:01:00,960
people who come to this conference

00:00:58,719 --> 00:01:03,840
mostly are into grpc

00:01:00,960 --> 00:01:05,280
services web services stuff and this is

00:01:03,840 --> 00:01:08,479
a little bit different from

00:01:05,280 --> 00:01:12,159
a different use case and interesting too

00:01:08,479 --> 00:01:14,720
so in the big data wars what we have is

00:01:12,159 --> 00:01:16,560
basically we have big amounts of data

00:01:14,720 --> 00:01:19,040
that is distributed in different

00:01:16,560 --> 00:01:20,400
machines through a file distributed file

00:01:19,040 --> 00:01:23,439
system or a

00:01:20,400 --> 00:01:25,520
distributed data store and this part

00:01:23,439 --> 00:01:27,119
this we divide into partitions and with

00:01:25,520 --> 00:01:29,680
these partitions we apply

00:01:27,119 --> 00:01:30,880
some functions for example maps or that

00:01:29,680 --> 00:01:32,960
we use to transform

00:01:30,880 --> 00:01:34,159
data from one format to the other you

00:01:32,960 --> 00:01:36,880
can see this in the left

00:01:34,159 --> 00:01:39,200
side with the geometric figures and also

00:01:36,880 --> 00:01:42,399
we have reduced functions that we use to

00:01:39,200 --> 00:01:45,360
to group and aggregate data

00:01:42,399 --> 00:01:47,439
and produce resource to analyze data for

00:01:45,360 --> 00:01:49,200
example

00:01:47,439 --> 00:01:51,360
this is for the best case the streaming

00:01:49,200 --> 00:01:52,640
case is quite similar the

00:01:51,360 --> 00:01:54,640
big difference is that we have

00:01:52,640 --> 00:01:56,000
continuous data that is arriving all the

00:01:54,640 --> 00:01:58,960
time

00:01:56,000 --> 00:02:00,399
uh and but the operations are similar

00:01:58,960 --> 00:02:02,399
but with the

00:02:00,399 --> 00:02:03,439
kind of constraint and that is the fact

00:02:02,399 --> 00:02:05,119
that the data is

00:02:03,439 --> 00:02:06,960
still continuously arriving and we have

00:02:05,119 --> 00:02:09,039
to decide at which point we want to

00:02:06,960 --> 00:02:11,599
calculate or aggregate the data

00:02:09,039 --> 00:02:13,760
so this is when we stop and we aggregate

00:02:11,599 --> 00:02:14,959
so this needs some extra functions to do

00:02:13,760 --> 00:02:18,480
this

00:02:14,959 --> 00:02:20,400
and to do this kind of programming

00:02:18,480 --> 00:02:21,680
we have created many many different

00:02:20,400 --> 00:02:23,920
frameworks in the last

00:02:21,680 --> 00:02:26,959
15 years and you probably know some of

00:02:23,920 --> 00:02:28,560
those this from name like hadoop

00:02:26,959 --> 00:02:30,080
and most of these frameworks are java

00:02:28,560 --> 00:02:33,599
based because that's what

00:02:30,080 --> 00:02:35,519
we everybody started using at the time

00:02:33,599 --> 00:02:37,040
so the support for java is quite mature

00:02:35,519 --> 00:02:41,120
in most of them

00:02:37,040 --> 00:02:41,120
uh but not for other languages

00:02:41,519 --> 00:02:45,519
and we we also just just for reference

00:02:44,879 --> 00:02:47,599
what we

00:02:45,519 --> 00:02:50,160
basically do in big data is that you

00:02:47,599 --> 00:02:53,280
write your job that is a set of steps

00:02:50,160 --> 00:02:55,200
of that transform the data and these

00:02:53,280 --> 00:02:57,920
steps are coordinated through a

00:02:55,200 --> 00:02:57,920
coordinator

00:02:58,159 --> 00:03:02,959
process and assigned to different

00:03:00,640 --> 00:03:05,599
workers that are going to

00:03:02,959 --> 00:03:06,400
to execute the task and the tasks are in

00:03:05,599 --> 00:03:08,800
the end are you

00:03:06,400 --> 00:03:09,680
user-defined functions that the the

00:03:08,800 --> 00:03:13,360
programmer put

00:03:09,680 --> 00:03:17,440
into into the system so

00:03:13,360 --> 00:03:21,599
in in in the java cases is like that

00:03:17,440 --> 00:03:23,920
okay so well so what happened when

00:03:21,599 --> 00:03:24,720
when what happened in the last years in

00:03:23,920 --> 00:03:27,840
the last

00:03:24,720 --> 00:03:31,440
10 years is that uh the latter science

00:03:27,840 --> 00:03:33,599
revolution appeared and we

00:03:31,440 --> 00:03:34,799
people started to demand support for

00:03:33,599 --> 00:03:36,560
different languages

00:03:34,799 --> 00:03:38,159
like python for example because they

00:03:36,560 --> 00:03:40,080
like their syntax they like the

00:03:38,159 --> 00:03:42,480
expressiveness of the language

00:03:40,080 --> 00:03:44,080
also because they can they could reuse

00:03:42,480 --> 00:03:46,000
code that they already have

00:03:44,080 --> 00:03:48,239
because they wanted to use the libraries

00:03:46,000 --> 00:03:50,560
and the ecosystems they they have like

00:03:48,239 --> 00:03:51,360
for example spite or you know this kind

00:03:50,560 --> 00:03:52,879
of pandas

00:03:51,360 --> 00:03:54,799
libraries that people are familiar and

00:03:52,879 --> 00:03:56,080
pretty mature and good

00:03:54,799 --> 00:03:58,480
and of course also because of the

00:03:56,080 --> 00:03:59,760
communities that's a reason to prefer

00:03:58,480 --> 00:04:03,760
some language

00:03:59,760 --> 00:04:06,159
above the others uh so

00:04:03,760 --> 00:04:07,760
but this is something that we have to

00:04:06,159 --> 00:04:09,680
give importance the importance that it

00:04:07,760 --> 00:04:11,840
has is that the the use of languages

00:04:09,680 --> 00:04:13,519
changes in time and as you can see here

00:04:11,840 --> 00:04:16,239
in the last 15 years

00:04:13,519 --> 00:04:16,880
we can see the decline of java versus

00:04:16,239 --> 00:04:18,959
the

00:04:16,880 --> 00:04:20,720
growing interest into python of course

00:04:18,959 --> 00:04:22,880
javascript huge language but

00:04:20,720 --> 00:04:24,880
more people want to have more languages

00:04:22,880 --> 00:04:26,479
to be able to do their tasks not only

00:04:24,880 --> 00:04:29,600
python

00:04:26,479 --> 00:04:31,919
so we enter apache beam apache beam

00:04:29,600 --> 00:04:33,199
is a project uh it's an open source

00:04:31,919 --> 00:04:35,040
project

00:04:33,199 --> 00:04:37,199
in the apache server foundation this was

00:04:35,040 --> 00:04:37,840
donated by google the idea is that we

00:04:37,199 --> 00:04:40,000
want to have

00:04:37,840 --> 00:04:40,960
a unified programming model let's say

00:04:40,000 --> 00:04:43,600
like an sdk

00:04:40,960 --> 00:04:44,400
that we can use to create efficient and

00:04:43,600 --> 00:04:47,120
portable

00:04:44,400 --> 00:04:47,680
data processing pipelines so the idea is

00:04:47,120 --> 00:04:50,880
that

00:04:47,680 --> 00:04:51,840
we use the beam apis with the sdk and we

00:04:50,880 --> 00:04:55,040
can run this in

00:04:51,840 --> 00:04:56,479
every system that we want and every of

00:04:55,040 --> 00:04:59,360
these existing systems

00:04:56,479 --> 00:05:00,960
that are supported of course uh when we

00:04:59,360 --> 00:05:02,479
talk about unified model the idea is

00:05:00,960 --> 00:05:04,880
that we want to support both

00:05:02,479 --> 00:05:05,759
batch and streaming computations with

00:05:04,880 --> 00:05:09,520
the same model

00:05:05,759 --> 00:05:11,520
the idea is that we can have somehow

00:05:09,520 --> 00:05:12,720
somehow kind of deterministic streaming

00:05:11,520 --> 00:05:15,120
processing by

00:05:12,720 --> 00:05:15,919
assigning an even time to every element

00:05:15,120 --> 00:05:18,639
in

00:05:15,919 --> 00:05:20,639
in the system and with this we can

00:05:18,639 --> 00:05:22,479
define when to aggregate the data

00:05:20,639 --> 00:05:24,560
if we don't want to wait too much to

00:05:22,479 --> 00:05:27,440
agree that i have results in advance

00:05:24,560 --> 00:05:28,800
we can do it maybe with some trigger or

00:05:27,440 --> 00:05:32,320
maybe with defining

00:05:28,800 --> 00:05:34,400
small smaller windows in time again

00:05:32,320 --> 00:05:36,800
just what we want here is to deal with

00:05:34,400 --> 00:05:38,400
the trade of latency and correctness

00:05:36,800 --> 00:05:40,639
so we cannot wait all the time to have

00:05:38,400 --> 00:05:41,360
correct results but we can we can adjust

00:05:40,639 --> 00:05:43,520
this

00:05:41,360 --> 00:05:44,880
so this is what we mean with unified

00:05:43,520 --> 00:05:48,479
models so basically we add

00:05:44,880 --> 00:05:48,800
some extra semantics with transforms to

00:05:48,479 --> 00:05:51,520
the

00:05:48,800 --> 00:05:53,680
to the system and when we talk about

00:05:51,520 --> 00:05:54,560
portability what we want is to be able

00:05:53,680 --> 00:05:56,639
to write

00:05:54,560 --> 00:05:57,759
our pipelines in our favorite language

00:05:56,639 --> 00:06:00,240
and then

00:05:57,759 --> 00:06:02,479
be able to translate those so they can

00:06:00,240 --> 00:06:04,400
be executed in the target system

00:06:02,479 --> 00:06:06,160
in this case for example we want to run

00:06:04,400 --> 00:06:07,680
it in spark or in flink

00:06:06,160 --> 00:06:10,880
well we're going to do this trans

00:06:07,680 --> 00:06:14,160
transformation with the runners

00:06:10,880 --> 00:06:16,000
uh okay so basically the model force

00:06:14,160 --> 00:06:19,120
like this we define a pipeline

00:06:16,000 --> 00:06:20,080
that is a collection of uh that uses a

00:06:19,120 --> 00:06:21,520
collection of data

00:06:20,080 --> 00:06:23,840
that we're going to process in parallel

00:06:21,520 --> 00:06:25,680
we call this collection peak collection

00:06:23,840 --> 00:06:27,039
and then we start to do transforms to

00:06:25,680 --> 00:06:29,840
these collections to produce

00:06:27,039 --> 00:06:30,080
new new new collections and then output

00:06:29,840 --> 00:06:32,639
the

00:06:30,080 --> 00:06:34,400
the datas by basic data flow model for

00:06:32,639 --> 00:06:38,560
those who are familiar with it

00:06:34,400 --> 00:06:41,440
it's a simple graph of steps

00:06:38,560 --> 00:06:41,840
and but each of these transforms that we

00:06:41,440 --> 00:06:45,039
have

00:06:41,840 --> 00:06:47,120
here are again parameterized by the user

00:06:45,039 --> 00:06:48,560
in with the configuration of the

00:06:47,120 --> 00:06:52,560
transform the

00:06:48,560 --> 00:06:55,360
the the user defined function let's say

00:06:52,560 --> 00:06:56,319
uh so how how does this how about this

00:06:55,360 --> 00:06:58,560
working beam

00:06:56,319 --> 00:07:01,199
until recently for example from java to

00:06:58,560 --> 00:07:03,360
java translation what we do is that

00:07:01,199 --> 00:07:05,039
users write the program in using the

00:07:03,360 --> 00:07:08,080
beam sdk

00:07:05,039 --> 00:07:10,800
this is for java and then we

00:07:08,080 --> 00:07:11,520
in bim we translate this we translate

00:07:10,800 --> 00:07:13,759
from the

00:07:11,520 --> 00:07:15,199
bim functions into the target functions

00:07:13,759 --> 00:07:16,240
if you are familiar with the spar for

00:07:15,199 --> 00:07:19,759
example we produce

00:07:16,240 --> 00:07:21,039
an rdd and we do rdd.map and we map the

00:07:19,759 --> 00:07:23,440
function

00:07:21,039 --> 00:07:24,960
and and all of this is quite

00:07:23,440 --> 00:07:26,400
straightforward because the functions

00:07:24,960 --> 00:07:28,319
are similar between the different

00:07:26,400 --> 00:07:30,479
systems because they almost

00:07:28,319 --> 00:07:31,840
all do them have to support the basic

00:07:30,479 --> 00:07:34,319
same functions

00:07:31,840 --> 00:07:35,599
and what we do is mostly wrapping and

00:07:34,319 --> 00:07:39,199
unwrapping

00:07:35,599 --> 00:07:42,080
and unwrapping the the functions there

00:07:39,199 --> 00:07:43,120
uh okay so that's okay for java but what

00:07:42,080 --> 00:07:44,720
happens when we

00:07:43,120 --> 00:07:46,560
have to support other languages what

00:07:44,720 --> 00:07:49,199
happens with python

00:07:46,560 --> 00:07:50,160
one approach that we can take is just to

00:07:49,199 --> 00:07:53,120
see how

00:07:50,160 --> 00:07:54,879
jbn systems are supported support python

00:07:53,120 --> 00:07:56,639
today for example spark

00:07:54,879 --> 00:07:58,240
spark what it does is that if the user

00:07:56,639 --> 00:08:01,919
rises the program in python

00:07:58,240 --> 00:08:05,120
it invokes the the java part

00:08:01,919 --> 00:08:06,479
using py4j and then the job is

00:08:05,120 --> 00:08:08,400
distributed and the

00:08:06,479 --> 00:08:10,319
worker is going to do the task but

00:08:08,400 --> 00:08:11,199
instead of doing the task it's going to

00:08:10,319 --> 00:08:14,080
instantiate

00:08:11,199 --> 00:08:15,280
the java sorry the python process and

00:08:14,080 --> 00:08:18,560
they're going to talk with

00:08:15,280 --> 00:08:21,360
true unix pipes this is how it works

00:08:18,560 --> 00:08:23,840
this of course is a good solution it

00:08:21,360 --> 00:08:26,319
solves the problem but has some issues

00:08:23,840 --> 00:08:27,199
and so some of the issues is the issue

00:08:26,319 --> 00:08:29,520
of that

00:08:27,199 --> 00:08:31,199
of passing the data from back and forth

00:08:29,520 --> 00:08:33,039
and you can enter in some

00:08:31,199 --> 00:08:34,800
kind of global serialization or at least

00:08:33,039 --> 00:08:36,399
you have to get data in and out of the

00:08:34,800 --> 00:08:39,680
jvm

00:08:36,399 --> 00:08:41,200
also you have the the you lose the risk

00:08:39,680 --> 00:08:43,599
the control of the resources because the

00:08:41,200 --> 00:08:45,200
python memory is not inside of the jbm

00:08:43,599 --> 00:08:47,600
so it's not going to respect the limits

00:08:45,200 --> 00:08:50,880
that you put in the jvm so it can go

00:08:47,600 --> 00:08:51,680
out and it's a common problem and more

00:08:50,880 --> 00:08:53,680
important

00:08:51,680 --> 00:08:56,320
the dependencies cannot be ready in the

00:08:53,680 --> 00:09:00,160
cluster when you are running the job

00:08:56,320 --> 00:09:02,800
so it is it is uh

00:09:00,160 --> 00:09:04,800
they should be prepared or they won't be

00:09:02,800 --> 00:09:07,600
working so this is another issue that is

00:09:04,800 --> 00:09:10,240
not solved by this approach

00:09:07,600 --> 00:09:12,880
so beam for to tackle this created what

00:09:10,240 --> 00:09:16,720
we call the portability framework

00:09:12,880 --> 00:09:18,720
and the portability framework is uh

00:09:16,720 --> 00:09:20,240
is well the main goal is to tackle the

00:09:18,720 --> 00:09:23,040
problem with how to execute

00:09:20,240 --> 00:09:24,560
any language in every runner in every

00:09:23,040 --> 00:09:26,240
existing system

00:09:24,560 --> 00:09:28,080
of course we have some constraints first

00:09:26,240 --> 00:09:29,920
we need we have to support java and

00:09:28,080 --> 00:09:32,480
python because for historical reasons

00:09:29,920 --> 00:09:35,040
that's what we have we support now

00:09:32,480 --> 00:09:36,240
we support us from the beginning also we

00:09:35,040 --> 00:09:38,560
have to provide

00:09:36,240 --> 00:09:40,480
an expected execution environment so

00:09:38,560 --> 00:09:43,760
with the current dependencies

00:09:40,480 --> 00:09:45,519
we expect that to solve this problem we

00:09:43,760 --> 00:09:48,240
won't have a big overhead good

00:09:45,519 --> 00:09:50,640
performance going to be important also

00:09:48,240 --> 00:09:52,880
and we're going to support also multiple

00:09:50,640 --> 00:09:56,560
language data representations

00:09:52,880 --> 00:09:58,720
so so but of course finally we want to

00:09:56,560 --> 00:10:01,120
have an easy to evolve system

00:09:58,720 --> 00:10:03,279
so the gist of the the idea is that

00:10:01,120 --> 00:10:05,680
instead of just using this

00:10:03,279 --> 00:10:06,480
user-defined function as we do can do

00:10:05,680 --> 00:10:08,880
with java

00:10:06,480 --> 00:10:10,160
what we're going to do is to delegate

00:10:08,880 --> 00:10:13,279
this execution

00:10:10,160 --> 00:10:15,519
to a companion

00:10:13,279 --> 00:10:16,480
container it's kind of like a sidecar

00:10:15,519 --> 00:10:18,880
container that

00:10:16,480 --> 00:10:20,079
you can that we are going to control

00:10:18,880 --> 00:10:22,560
through services

00:10:20,079 --> 00:10:24,079
to pass data pass the function and be

00:10:22,560 --> 00:10:27,440
able to execute it in every

00:10:24,079 --> 00:10:29,120
task executed by the work so this is

00:10:27,440 --> 00:10:30,720
basically the big idea of course there

00:10:29,120 --> 00:10:32,880
are more things so this

00:10:30,720 --> 00:10:35,839
this full design includes three three

00:10:32,880 --> 00:10:38,160
big elements the runner api so called

00:10:35,839 --> 00:10:39,440
this is basically an agnostic uh

00:10:38,160 --> 00:10:41,839
representation of

00:10:39,440 --> 00:10:43,680
what a pipeline is of this set of steps

00:10:41,839 --> 00:10:46,800
of transformation

00:10:43,680 --> 00:10:49,839
uh the job api that is a service to

00:10:46,800 --> 00:10:51,440
submit submit the pipelines to be

00:10:49,839 --> 00:10:55,120
executed and to manage

00:10:51,440 --> 00:10:56,720
this execution uh the fn api is

00:10:55,120 --> 00:10:58,560
a little bit more complex is the set of

00:10:56,720 --> 00:11:00,640
services that allows us to control the

00:10:58,560 --> 00:11:01,120
execution to transfer the data i'm going

00:11:00,640 --> 00:11:04,000
to see

00:11:01,120 --> 00:11:06,079
those in detail now but first why we

00:11:04,000 --> 00:11:08,560
chose grpc what usbc

00:11:06,079 --> 00:11:10,480
first it has an efficient serialization

00:11:08,560 --> 00:11:11,680
format and this was important because we

00:11:10,480 --> 00:11:15,040
wanted to pass

00:11:11,680 --> 00:11:18,160
the bus to have a well-defined

00:11:15,040 --> 00:11:19,680
messages and efficient of course

00:11:18,160 --> 00:11:22,240
portable code offers

00:11:19,680 --> 00:11:24,240
uh as many of the things that we wanted

00:11:22,240 --> 00:11:26,079
first you post multiple languages

00:11:24,240 --> 00:11:28,480
and and we can use it with java and

00:11:26,079 --> 00:11:30,720
python pretty easily we have a

00:11:28,480 --> 00:11:32,320
consistent civilization format that was

00:11:30,720 --> 00:11:34,720
an historical problem we have because

00:11:32,320 --> 00:11:36,720
java serialization is not deterministic

00:11:34,720 --> 00:11:39,120
we it was extremely tight so we can have

00:11:36,720 --> 00:11:39,120
a more

00:11:39,680 --> 00:11:42,880
representation that is more consistent

00:11:41,440 --> 00:11:46,240
in time we're going to find errors more

00:11:42,880 --> 00:11:46,240
easily not like with json

00:11:46,480 --> 00:11:49,600
and we have a compact and efficient

00:11:48,240 --> 00:11:51,519
encoding and decoding

00:11:49,600 --> 00:11:53,680
and we can involve this like we do with

00:11:51,519 --> 00:11:55,360
our

00:11:53,680 --> 00:11:56,959
also while we have the support of

00:11:55,360 --> 00:11:58,480
backwards compatible support also

00:11:56,959 --> 00:12:00,000
protocol buffers for managed versions

00:11:58,480 --> 00:12:03,200
that's good too

00:12:00,000 --> 00:12:04,720
uh back to your pc well other thing of

00:12:03,200 --> 00:12:07,279
grpc that is

00:12:04,720 --> 00:12:08,959
really nice is that we have a really

00:12:07,279 --> 00:12:10,639
simple

00:12:08,959 --> 00:12:12,480
service definition so it's quite

00:12:10,639 --> 00:12:13,120
straightforward to define the services

00:12:12,480 --> 00:12:14,959
and

00:12:13,120 --> 00:12:17,040
we gain the network performance

00:12:14,959 --> 00:12:19,600
advantages of grpc

00:12:17,040 --> 00:12:20,560
we get the the multiplexing because of

00:12:19,600 --> 00:12:23,200
http 2

00:12:20,560 --> 00:12:24,480
so in the in the networking side so this

00:12:23,200 --> 00:12:27,680
is pretty good

00:12:24,480 --> 00:12:29,440
and really interesting for our use cases

00:12:27,680 --> 00:12:30,720
we have the rich communication models we

00:12:29,440 --> 00:12:32,480
have subscriptions we have

00:12:30,720 --> 00:12:34,720
bi-directional streaming which

00:12:32,480 --> 00:12:38,079
can apply for different tasks as we are

00:12:34,720 --> 00:12:40,079
going to see in our services

00:12:38,079 --> 00:12:41,760
so the portability framework this is the

00:12:40,079 --> 00:12:44,160
full image now it's a little bit

00:12:41,760 --> 00:12:45,680
more complex than than before but i'm

00:12:44,160 --> 00:12:47,600
going to explain it in detail don't

00:12:45,680 --> 00:12:49,120
be overwhelmed by the image it's quite

00:12:47,600 --> 00:12:52,639
straightforward

00:12:49,120 --> 00:12:54,959
once jus it's explained so first we have

00:12:52,639 --> 00:12:56,959
now the users write their program and

00:12:54,959 --> 00:12:59,040
instead of sending the code

00:12:56,959 --> 00:13:01,040
we're going to transform all of this

00:12:59,040 --> 00:13:02,000
into a protocol buffers object that is

00:13:01,040 --> 00:13:05,200
going to

00:13:02,000 --> 00:13:06,720
be the input of the execution so this is

00:13:05,200 --> 00:13:09,200
going to be produced from

00:13:06,720 --> 00:13:10,079
python from java in the same kind of

00:13:09,200 --> 00:13:12,079
object and

00:13:10,079 --> 00:13:13,760
and then sent to the to the job server

00:13:12,079 --> 00:13:16,720
to be executed

00:13:13,760 --> 00:13:17,760
they just the this definition is if you

00:13:16,720 --> 00:13:21,839
remember the

00:13:17,760 --> 00:13:21,839
the small

00:13:22,160 --> 00:13:26,240
piece of code that i showed before well

00:13:24,560 --> 00:13:27,839
it's almost the same ideas we have the

00:13:26,240 --> 00:13:30,079
transform we have the collection

00:13:27,839 --> 00:13:31,920
we have some internal details like when

00:13:30,079 --> 00:13:35,040
how are their window

00:13:31,920 --> 00:13:38,079
and we we send this the

00:13:35,040 --> 00:13:40,240
the job server on the job service it

00:13:38,079 --> 00:13:42,079
allows us to control the execution of of

00:13:40,240 --> 00:13:44,399
a job of a pipeline

00:13:42,079 --> 00:13:47,519
uh and if you see this is just a

00:13:44,399 --> 00:13:49,040
submission and management protocol we

00:13:47,519 --> 00:13:50,800
even if you are not familiar with your

00:13:49,040 --> 00:13:51,519
pc this is the first time you're seeing

00:13:50,800 --> 00:13:53,920
grpc

00:13:51,519 --> 00:13:54,800
i think you can immediately understand

00:13:53,920 --> 00:13:56,880
this i mean like

00:13:54,800 --> 00:13:58,639
we define a service that has this kind

00:13:56,880 --> 00:14:01,680
of

00:13:58,639 --> 00:14:02,000
methods uh and well we can we can

00:14:01,680 --> 00:14:03,920
prepare

00:14:02,000 --> 00:14:05,680
an execution we can get the state the

00:14:03,920 --> 00:14:06,240
current state of the job we want to run

00:14:05,680 --> 00:14:08,560
and we can

00:14:06,240 --> 00:14:09,760
cancel and a running job but more

00:14:08,560 --> 00:14:12,399
important

00:14:09,760 --> 00:14:14,320
for the for the to prove the semantics

00:14:12,399 --> 00:14:16,079
of grpc is that we can also be

00:14:14,320 --> 00:14:18,320
interested in subscribing to some

00:14:16,079 --> 00:14:20,320
changes in this job and this is common

00:14:18,320 --> 00:14:21,040
for example i can i can be interested to

00:14:20,320 --> 00:14:23,760
know

00:14:21,040 --> 00:14:25,600
to have an alert or have a react to diff

00:14:23,760 --> 00:14:26,160
when a message is finished so we can do

00:14:25,600 --> 00:14:29,199
this

00:14:26,160 --> 00:14:31,839
there is this description and then the

00:14:29,199 --> 00:14:34,560
then also well you can be interested in

00:14:31,839 --> 00:14:38,800
other kind of messages

00:14:34,560 --> 00:14:42,079
uh now we have also the

00:14:38,800 --> 00:14:45,760
the the final set of services

00:14:42,079 --> 00:14:49,120
is the fn api we call those

00:14:45,760 --> 00:14:52,399
and this fnapi uh

00:14:49,120 --> 00:14:54,079
allows us to invoke the function inside

00:14:52,399 --> 00:14:56,959
of the container and to

00:14:54,079 --> 00:14:58,639
control this execution but to do this we

00:14:56,959 --> 00:14:59,040
need different things first we need to

00:14:58,639 --> 00:15:01,199
have

00:14:59,040 --> 00:15:02,240
the right artifacts as part of the

00:15:01,199 --> 00:15:04,079
container

00:15:02,240 --> 00:15:06,320
and this is what the artifact services

00:15:04,079 --> 00:15:08,320
do and this is basically to get the

00:15:06,320 --> 00:15:13,040
dependencies

00:15:08,320 --> 00:15:14,160
um and

00:15:13,040 --> 00:15:16,240
okay so this is this is what the

00:15:14,160 --> 00:15:18,639
artifact service does and then

00:15:16,240 --> 00:15:20,639
once we have the dependencies what well

00:15:18,639 --> 00:15:23,680
we can see the service sorry

00:15:20,639 --> 00:15:26,079
uh what we what you can see this we can

00:15:23,680 --> 00:15:29,199
put artifacts to store them and we can

00:15:26,079 --> 00:15:32,240
commit a manifest to save their their

00:15:29,199 --> 00:15:33,040
as they hash and uh and the permissions

00:15:32,240 --> 00:15:34,320
they have

00:15:33,040 --> 00:15:36,079
of course we can retrieve these

00:15:34,320 --> 00:15:38,880
artifacts and use them that's what the

00:15:36,079 --> 00:15:40,320
what the container does and this

00:15:38,880 --> 00:15:43,440
container that this we

00:15:40,320 --> 00:15:45,600
call hardness is is

00:15:43,440 --> 00:15:47,440
doing then we have to instantiate the

00:15:45,600 --> 00:15:49,120
hardness the container and to do this we

00:15:47,440 --> 00:15:52,000
have this provision api

00:15:49,120 --> 00:15:53,199
the provision api allows us to define a

00:15:52,000 --> 00:15:55,040
set of

00:15:53,199 --> 00:15:56,880
resources let's say like we can define

00:15:55,040 --> 00:16:00,000
memory for this container

00:15:56,880 --> 00:16:00,320
limits against cpu limits also so this

00:16:00,000 --> 00:16:02,560
is

00:16:00,320 --> 00:16:04,160
this is what it does once we have the

00:16:02,560 --> 00:16:05,839
dependencies and being container

00:16:04,160 --> 00:16:07,839
resistant heated then it comes the

00:16:05,839 --> 00:16:08,800
services to pass the data and the

00:16:07,839 --> 00:16:12,320
functions

00:16:08,800 --> 00:16:14,079
so we have the data plane services that

00:16:12,320 --> 00:16:16,000
basically allows us to pass data

00:16:14,079 --> 00:16:18,160
straight to the to the system we have

00:16:16,000 --> 00:16:19,040
below the state api that is mostly for

00:16:18,160 --> 00:16:22,560
caching

00:16:19,040 --> 00:16:25,680
data in the different workers

00:16:22,560 --> 00:16:27,759
uh and the data apis as you can see here

00:16:25,680 --> 00:16:28,320
is quite straightforward it's just bytes

00:16:27,759 --> 00:16:30,720
i mean

00:16:28,320 --> 00:16:32,639
bi-directional streams of bytes that

00:16:30,720 --> 00:16:34,399
we've other are tied to at least

00:16:32,639 --> 00:16:36,399
structures that are going to be using

00:16:34,399 --> 00:16:38,480
this data

00:16:36,399 --> 00:16:40,399
is a logical stream of data that

00:16:38,480 --> 00:16:44,480
contains the elements

00:16:40,399 --> 00:16:47,040
and and for the case of protobuf

00:16:44,480 --> 00:16:48,000
we we in protocol we have this

00:16:47,040 --> 00:16:51,440
limitation of

00:16:48,000 --> 00:16:52,079
that oh sorry in protocol buffers we

00:16:51,440 --> 00:16:55,360
have this

00:16:52,079 --> 00:16:57,440
difference between between languages

00:16:55,360 --> 00:16:59,440
uh some languages support a maximum size

00:16:57,440 --> 00:17:01,120
of two gigabytes or there's a maximum

00:16:59,440 --> 00:17:02,880
size of four gigabytes

00:17:01,120 --> 00:17:05,360
well in the case of beam we'll assume

00:17:02,880 --> 00:17:09,839
the lowest common

00:17:05,360 --> 00:17:12,959
size size that is two gigabytes for this

00:17:09,839 --> 00:17:14,799
uh okay so now the control apis the

00:17:12,959 --> 00:17:17,039
control apis allows us to

00:17:14,799 --> 00:17:18,959
basically control the execution so we

00:17:17,039 --> 00:17:20,959
sent a graph with the specific user

00:17:18,959 --> 00:17:21,839
defined functions we stream the elements

00:17:20,959 --> 00:17:24,959
and we get the

00:17:21,839 --> 00:17:28,240
the the elements out uh

00:17:24,959 --> 00:17:30,320
how is this done this is done

00:17:28,240 --> 00:17:31,280
with this definition again we have a

00:17:30,320 --> 00:17:34,799
bi-directional

00:17:31,280 --> 00:17:36,960
stream uh we just send requests and

00:17:34,799 --> 00:17:41,440
responses

00:17:36,960 --> 00:17:44,720
and the common requests here are

00:17:41,440 --> 00:17:45,679
the request here is to process a bundle

00:17:44,720 --> 00:17:48,720
a bundle is a

00:17:45,679 --> 00:17:49,840
subset of data that is going to be tied

00:17:48,720 --> 00:17:51,440
to a function

00:17:49,840 --> 00:17:52,640
also well of course we have we can

00:17:51,440 --> 00:17:53,520
request to have progress of the

00:17:52,640 --> 00:17:57,520
execution

00:17:53,520 --> 00:17:59,280
and on another common instruction is to

00:17:57,520 --> 00:18:01,120
split the execution and when this

00:17:59,280 --> 00:18:02,080
happens this happens when we want to

00:18:01,120 --> 00:18:04,320
divide

00:18:02,080 --> 00:18:05,360
the execution and pass the the missing

00:18:04,320 --> 00:18:07,440
part to a different

00:18:05,360 --> 00:18:08,880
task or a different maybe in a different

00:18:07,440 --> 00:18:12,080
work this is

00:18:08,880 --> 00:18:14,000
this allows us to have more parallelism

00:18:12,080 --> 00:18:15,840
how this works well this is a simple

00:18:14,000 --> 00:18:16,960
diagram but basically we register the

00:18:15,840 --> 00:18:19,760
functions

00:18:16,960 --> 00:18:22,559
then we request the sdk to process the

00:18:19,760 --> 00:18:24,320
function we prepare the functions

00:18:22,559 --> 00:18:26,720
once we initialize the functions we

00:18:24,320 --> 00:18:28,640
start to stream the input elements we

00:18:26,720 --> 00:18:30,240
process the elements then we signal this

00:18:28,640 --> 00:18:33,280
is the end and then we

00:18:30,240 --> 00:18:35,200
get the outputs this is basically how it

00:18:33,280 --> 00:18:39,039
works

00:18:35,200 --> 00:18:41,120
uh finally we have last

00:18:39,039 --> 00:18:42,559
service that is the login service again

00:18:41,120 --> 00:18:46,000
a bi-directional

00:18:42,559 --> 00:18:47,360
streaming service why vibrational

00:18:46,000 --> 00:18:49,520
because we have we want to have the

00:18:47,360 --> 00:18:51,600
results also as fast as we can

00:18:49,520 --> 00:18:53,360
vlog we have to have the information if

00:18:51,600 --> 00:18:57,120
you are familiar with any login

00:18:53,360 --> 00:18:59,760
system like log4j well you can see this

00:18:57,120 --> 00:19:02,080
the the different levels you have and

00:18:59,760 --> 00:19:04,160
the the timestamp of when things happen

00:19:02,080 --> 00:19:08,840
and the message

00:19:04,160 --> 00:19:12,320
this is pretty straightforward also

00:19:08,840 --> 00:19:15,120
okay so this is the

00:19:12,320 --> 00:19:17,520
this is the world set of services this

00:19:15,120 --> 00:19:20,400
is how we re-implemented beam to support

00:19:17,520 --> 00:19:22,000
multiple languages execution and now

00:19:20,400 --> 00:19:24,640
we're going to talk about the present

00:19:22,000 --> 00:19:25,840
so some of the things that we get with

00:19:24,640 --> 00:19:28,640
the portability framework

00:19:25,840 --> 00:19:30,720
was isolation of user code now we can

00:19:28,640 --> 00:19:31,760
produce a satellite environment that the

00:19:30,720 --> 00:19:35,200
user wants

00:19:31,760 --> 00:19:36,240
to execute their job uh which is super

00:19:35,200 --> 00:19:39,039
important

00:19:36,240 --> 00:19:40,880
and this gives us a blueprint also for

00:19:39,039 --> 00:19:41,280
new languages to support new languages

00:19:40,880 --> 00:19:42,880
now

00:19:41,280 --> 00:19:45,039
if we want to support a new language we

00:19:42,880 --> 00:19:46,240
know exactly what we have to do you have

00:19:45,039 --> 00:19:48,320
to implement this

00:19:46,240 --> 00:19:49,600
these services of course the the all the

00:19:48,320 --> 00:19:51,919
erp services

00:19:49,600 --> 00:19:52,720
and you have to implement an api for the

00:19:51,919 --> 00:19:54,640
language and

00:19:52,720 --> 00:19:55,840
the integration is immediate with all

00:19:54,640 --> 00:19:58,480
the different systems

00:19:55,840 --> 00:19:59,280
so we don't have to re-translate into

00:19:58,480 --> 00:20:02,480
java or

00:19:59,280 --> 00:20:04,240
into flinks or into spark no now if this

00:20:02,480 --> 00:20:05,760
is supported it will be supported

00:20:04,240 --> 00:20:08,799
we just have to work in the language

00:20:05,760 --> 00:20:10,960
path uh of course then the present we

00:20:08,799 --> 00:20:12,799
have now our implementation

00:20:10,960 --> 00:20:14,720
full implementation for different open

00:20:12,799 --> 00:20:16,320
source systems like flink apache link

00:20:14,720 --> 00:20:18,559
and apache spark

00:20:16,320 --> 00:20:19,440
and the google data flow runner now

00:20:18,559 --> 00:20:21,200
supports this

00:20:19,440 --> 00:20:23,120
it's experimental this is not open

00:20:21,200 --> 00:20:24,880
source but the users of data flow in the

00:20:23,120 --> 00:20:28,000
cloud can use it

00:20:24,880 --> 00:20:28,640
and the samsung runner also makes a work

00:20:28,000 --> 00:20:31,679
in progress

00:20:28,640 --> 00:20:33,600
so this is getting more material now

00:20:31,679 --> 00:20:35,440
uh we have this thing we call the

00:20:33,600 --> 00:20:36,960
protagon the capability matrix that

00:20:35,440 --> 00:20:38,640
shows how much of the beam model is

00:20:36,960 --> 00:20:40,480
supported by

00:20:38,640 --> 00:20:41,919
by the different systems that we

00:20:40,480 --> 00:20:44,720
translate into

00:20:41,919 --> 00:20:47,039
uh we are the runners so for free we

00:20:44,720 --> 00:20:49,120
have full support for spark we have

00:20:47,039 --> 00:20:51,200
only support for batch but work on

00:20:49,120 --> 00:20:54,400
streaming is coming

00:20:51,200 --> 00:20:57,200
we also are now

00:20:54,400 --> 00:20:58,559
testing all of these through what we

00:20:57,200 --> 00:21:00,080
call the validus runner suite the

00:20:58,559 --> 00:21:04,000
validate runner suite

00:21:00,080 --> 00:21:06,720
is a set of uh is a set of uh

00:21:04,000 --> 00:21:08,320
they say like a tck to validate the

00:21:06,720 --> 00:21:10,640
completeness of the model

00:21:08,320 --> 00:21:12,000
so this is corner cases for every kind

00:21:10,640 --> 00:21:14,799
of transform and

00:21:12,000 --> 00:21:16,080
use case we run this for every pr that

00:21:14,799 --> 00:21:17,840
is done into beam and

00:21:16,080 --> 00:21:19,679
now we have all of this passing for the

00:21:17,840 --> 00:21:21,600
classic translation we did

00:21:19,679 --> 00:21:25,840
from java to java but also for this new

00:21:21,600 --> 00:21:25,840
translation with all the grpc services

00:21:26,480 --> 00:21:31,840
thanks to that now we have support for

00:21:28,480 --> 00:21:34,159
golang that is the most recent

00:21:31,840 --> 00:21:36,559
language that we support now on bim and

00:21:34,159 --> 00:21:39,440
go is the first language that is pure

00:21:36,559 --> 00:21:41,200
portable so go from the beginning

00:21:39,440 --> 00:21:43,919
translates into protocol buffers and

00:21:41,200 --> 00:21:45,520
uses all these services of course go is

00:21:43,919 --> 00:21:47,200
still a work in progress but this is

00:21:45,520 --> 00:21:49,840
pretty nice that we can now run for

00:21:47,200 --> 00:21:53,440
example go pipelines with a spark

00:21:49,840 --> 00:21:56,000
with thanks to beam and finally

00:21:53,440 --> 00:21:57,760
what is coming now is just working into

00:21:56,000 --> 00:21:58,559
performance tests to catch progressions

00:21:57,760 --> 00:22:01,679
and try to

00:21:58,559 --> 00:22:02,080
make things even faster okay so we had

00:22:01,679 --> 00:22:05,360
nice

00:22:02,080 --> 00:22:08,720
outcomes of this work first one was that

00:22:05,360 --> 00:22:10,840
since now we can support uh python like

00:22:08,720 --> 00:22:12,799
running in different open source systems

00:22:10,840 --> 00:22:15,679
well

00:22:12,799 --> 00:22:17,760
projects that use bim python api now can

00:22:15,679 --> 00:22:20,159
be used also in the open source site

00:22:17,760 --> 00:22:22,799
and in particular tfx that is this

00:22:20,159 --> 00:22:26,080
tensorflow project

00:22:22,799 --> 00:22:29,679
to deploy production to deploy email

00:22:26,080 --> 00:22:31,919
machine learning pipelines uh now is

00:22:29,679 --> 00:22:33,679
can be used in the open source runners

00:22:31,919 --> 00:22:35,760
without any modifications so they can

00:22:33,679 --> 00:22:36,960
use all these data validation functions

00:22:35,760 --> 00:22:41,039
that are pre-processing

00:22:36,960 --> 00:22:43,440
everything is this works out of the box

00:22:41,039 --> 00:22:45,120
also another interesting outcome is that

00:22:43,440 --> 00:22:46,559
this new architecture

00:22:45,120 --> 00:22:48,080
allows us to have close language

00:22:46,559 --> 00:22:48,960
pipelines which means that we can have

00:22:48,080 --> 00:22:51,600
pipelines that have

00:22:48,960 --> 00:22:52,799
steps in different languages for example

00:22:51,600 --> 00:22:56,320
you can

00:22:52,799 --> 00:22:57,760
i mean you can wonder how when

00:22:56,320 --> 00:23:00,559
it's interesting to support different

00:22:57,760 --> 00:23:03,120
languages one case can be when

00:23:00,559 --> 00:23:04,640
you don't have an available connector

00:23:03,120 --> 00:23:06,159
for example to a data store

00:23:04,640 --> 00:23:07,840
in your language but it's in the

00:23:06,159 --> 00:23:10,159
different language so you can

00:23:07,840 --> 00:23:11,679
use the java api from python for example

00:23:10,159 --> 00:23:13,600
just to get the data in

00:23:11,679 --> 00:23:14,960
or the opposite once you want to use one

00:23:13,600 --> 00:23:16,159
of the libraries for example an

00:23:14,960 --> 00:23:19,120
inference

00:23:16,159 --> 00:23:19,919
function from tensorflow from java what

00:23:19,120 --> 00:23:22,960
you can do now

00:23:19,919 --> 00:23:23,679
through the python apis so this is a mix

00:23:22,960 --> 00:23:26,799
and match

00:23:23,679 --> 00:23:28,720
but really useful

00:23:26,799 --> 00:23:30,159
another nice outcome we have is

00:23:28,720 --> 00:23:32,480
performance

00:23:30,159 --> 00:23:34,320
and this i have to confess that i was

00:23:32,480 --> 00:23:37,520
kind of negative when all this

00:23:34,320 --> 00:23:41,840
architecture was proposed because i mean

00:23:37,520 --> 00:23:44,799
i i expected a big overhead but the

00:23:41,840 --> 00:23:46,799
the interesting results that are in this

00:23:44,799 --> 00:23:50,159
graph that my colleague alex saint

00:23:46,799 --> 00:23:52,080
shared is that uh

00:23:50,159 --> 00:23:53,200
with once you have more data the

00:23:52,080 --> 00:23:56,240
overhead of this

00:23:53,200 --> 00:23:57,279
grpc communication and services doesn't

00:23:56,240 --> 00:23:59,360
matter that much

00:23:57,279 --> 00:24:01,360
and this is really nice because it

00:23:59,360 --> 00:24:01,919
proves that for our use case that is

00:24:01,360 --> 00:24:06,799
mostly

00:24:01,919 --> 00:24:10,880
big uh it's a good solution

00:24:06,799 --> 00:24:12,159
uh finally also another another really

00:24:10,880 --> 00:24:14,799
nice outcome is that

00:24:12,159 --> 00:24:15,360
this uh let's say architectural

00:24:14,799 --> 00:24:18,480
reference

00:24:15,360 --> 00:24:22,000
of you is using this

00:24:18,480 --> 00:24:25,039
sidecar container control with with the

00:24:22,000 --> 00:24:26,480
grpc services it's a good base because

00:24:25,039 --> 00:24:29,919
now apache flink is

00:24:26,480 --> 00:24:30,880
starting to use it to use the to execute

00:24:29,919 --> 00:24:34,000
python code

00:24:30,880 --> 00:24:34,960
since the last version and also they

00:24:34,000 --> 00:24:36,480
have a project called

00:24:34,960 --> 00:24:37,919
stateful functions that is very

00:24:36,480 --> 00:24:38,799
interesting because you want to take a

00:24:37,919 --> 00:24:40,720
look at this

00:24:38,799 --> 00:24:43,520
the idea here is to have lambda-like

00:24:40,720 --> 00:24:45,840
functions lambda in the serverless sense

00:24:43,520 --> 00:24:47,520
and one alternative in stateful

00:24:45,840 --> 00:24:48,880
functions is that you can collocate

00:24:47,520 --> 00:24:50,400
functions in different languages and

00:24:48,880 --> 00:24:52,080
this will be executed with

00:24:50,400 --> 00:24:54,080
let's do the same approach with this

00:24:52,080 --> 00:24:56,400
kind of services that pass data pass the

00:24:54,080 --> 00:24:59,679
function and then running it

00:24:56,400 --> 00:25:01,360
so it's a pretty neat result to see that

00:24:59,679 --> 00:25:03,279
other other projects saw what we were

00:25:01,360 --> 00:25:07,440
doing and found that this is a good

00:25:03,279 --> 00:25:09,279
idea to solve their problems uh

00:25:07,440 --> 00:25:11,840
finally well and more related to this

00:25:09,279 --> 00:25:14,799
conference while using grpc was

00:25:11,840 --> 00:25:16,240
really nice to detect the changes and

00:25:14,799 --> 00:25:18,400
and

00:25:16,240 --> 00:25:19,679
well first because we have we put well

00:25:18,400 --> 00:25:21,840
first to detect the changes

00:25:19,679 --> 00:25:23,039
and add new features for example we we

00:25:21,840 --> 00:25:26,080
have uh

00:25:23,039 --> 00:25:27,360
things that we didn't conceive correctly

00:25:26,080 --> 00:25:29,520
from the beginning like the

00:25:27,360 --> 00:25:31,279
addition of environments that means that

00:25:29,520 --> 00:25:33,120
people some people don't want to execute

00:25:31,279 --> 00:25:33,840
for example docker but run in the side

00:25:33,120 --> 00:25:36,400
projects

00:25:33,840 --> 00:25:37,679
the site processes so we can do this

00:25:36,400 --> 00:25:39,440
with environments

00:25:37,679 --> 00:25:41,200
we can also support new features that

00:25:39,440 --> 00:25:42,880
were not in the beam model before like

00:25:41,200 --> 00:25:45,200
time your families all of this

00:25:42,880 --> 00:25:46,799
has been added into the into our

00:25:45,200 --> 00:25:48,960
messages contracts and

00:25:46,799 --> 00:25:50,240
i want our services it's been pretty

00:25:48,960 --> 00:25:51,520
good of course having a rich

00:25:50,240 --> 00:25:54,559
communication model

00:25:51,520 --> 00:25:57,279
uh to adapt to the different use cases

00:25:54,559 --> 00:25:58,559
has been pretty useful also for beam

00:25:57,279 --> 00:26:00,640
and of course all the backwards

00:25:58,559 --> 00:26:02,799
compatibility and and now

00:26:00,640 --> 00:26:04,080
soon versioning that we will have has

00:26:02,799 --> 00:26:07,279
been

00:26:04,080 --> 00:26:09,039
some problems things of your pc

00:26:07,279 --> 00:26:10,799
uh the pain points that we have because

00:26:09,039 --> 00:26:12,320
both not everything is perfect is that

00:26:10,799 --> 00:26:15,760
we have to vendor grpc

00:26:12,320 --> 00:26:17,919
but this is so a common problem in java

00:26:15,760 --> 00:26:21,600
because grpc and protocol buffers

00:26:17,919 --> 00:26:22,559
leaks from others of our systems apis

00:26:21,600 --> 00:26:24,320
not

00:26:22,559 --> 00:26:26,720
for example our dependencies some of

00:26:24,320 --> 00:26:28,799
those end up leaking protobuf and we had

00:26:26,720 --> 00:26:30,720
a mess with this liquid pull at above so

00:26:28,799 --> 00:26:34,240
we bend our grpc

00:26:30,720 --> 00:26:36,880
but but we keep up today with the latest

00:26:34,240 --> 00:26:39,120
versions as much as we can

00:26:36,880 --> 00:26:41,120
what is the future of this well uh we

00:26:39,120 --> 00:26:43,520
are working now on establish

00:26:41,120 --> 00:26:44,400
the stabilization of all these apis uh

00:26:43,520 --> 00:26:47,840
the

00:26:44,400 --> 00:26:49,760
services and messages uh just to give

00:26:47,840 --> 00:26:52,480
backwards compatibility and guarantees

00:26:49,760 --> 00:26:55,440
to other projects that may use it

00:26:52,480 --> 00:26:56,799
we have also well we plan now to have

00:26:55,440 --> 00:26:59,120
better ergonomics that

00:26:56,799 --> 00:27:01,120
running all of this together is more

00:26:59,120 --> 00:27:03,520
easy for the end users

00:27:01,120 --> 00:27:04,640
and have better documentation for this

00:27:03,520 --> 00:27:06,320
also

00:27:04,640 --> 00:27:08,799
we of course will plan to continue the

00:27:06,320 --> 00:27:12,240
work in performance analysis and improve

00:27:08,799 --> 00:27:13,520
and improve also some maybe rough areas

00:27:12,240 --> 00:27:15,440
that are still there

00:27:13,520 --> 00:27:17,600
and we're going to have deployments how

00:27:15,440 --> 00:27:19,360
to so you can run this

00:27:17,600 --> 00:27:21,440
kind of architecture with the different

00:27:19,360 --> 00:27:24,559
services depending on your use case in

00:27:21,440 --> 00:27:28,720
kubernetes or in hadoop or

00:27:24,559 --> 00:27:31,840
or in emr but or with just a spark

00:27:28,720 --> 00:27:33,200
the difference between uses if you are

00:27:31,840 --> 00:27:35,360
more interested and you want to

00:27:33,200 --> 00:27:37,840
contribute to this but you can try

00:27:35,360 --> 00:27:40,000
to try the first thing you can do is try

00:27:37,840 --> 00:27:43,440
it see how it works if you want to

00:27:40,000 --> 00:27:46,720
go into the grpc part well go ahead we

00:27:43,440 --> 00:27:49,039
will be happy to help you and give you

00:27:46,720 --> 00:27:50,799
feedback or receive of course your ideas

00:27:49,039 --> 00:27:52,640
and if you have future requests

00:27:50,799 --> 00:27:54,159
if you want to add more observability

00:27:52,640 --> 00:27:57,279
capabilities to this

00:27:54,159 --> 00:27:58,720
because we don't have many you can do uh

00:27:57,279 --> 00:28:00,720
and of course if you are interested in

00:27:58,720 --> 00:28:03,520
working.net and grpc

00:28:00,720 --> 00:28:05,760
and you want to bring donate to to us it

00:28:03,520 --> 00:28:08,320
would be super great to work with you

00:28:05,760 --> 00:28:10,080
oh but but more important you any

00:28:08,320 --> 00:28:13,120
correlation would be acceptable

00:28:10,080 --> 00:28:13,760
using it and seeing and and using beam

00:28:13,120 --> 00:28:15,679
also

00:28:13,760 --> 00:28:16,799
if you are not just into the erp simple

00:28:15,679 --> 00:28:19,120
but those who want to

00:28:16,799 --> 00:28:21,279
use the big data parts would be perfect

00:28:19,120 --> 00:28:22,960
we are very interested in having you

00:28:21,279 --> 00:28:24,960
if you want to go deeper into this

00:28:22,960 --> 00:28:26,799
design want to learn more about beam i

00:28:24,960 --> 00:28:30,480
like these links that you can

00:28:26,799 --> 00:28:32,159
get with slides finally i just wanted to

00:28:30,480 --> 00:28:32,799
invite you to the bim summit that is

00:28:32,159 --> 00:28:35,039
happening

00:28:32,799 --> 00:28:36,799
at the end of august of this year it's

00:28:35,039 --> 00:28:37,760
going to be free and online so you can

00:28:36,799 --> 00:28:40,559
register now

00:28:37,760 --> 00:28:42,320
and and assist definitely there will be

00:28:40,559 --> 00:28:44,240
more presentations that go deeper than i

00:28:42,320 --> 00:28:45,140
went into the

00:28:44,240 --> 00:28:47,760
into the

00:28:45,140 --> 00:28:50,320
[Music]

00:28:47,760 --> 00:28:51,919
portability framework and of course all

00:28:50,320 --> 00:28:55,039
the word of me

00:28:51,919 --> 00:28:59,840
okay that's all for me thanks

00:28:55,039 --> 00:28:59,840

YouTube URL: https://www.youtube.com/watch?v=WX_iLomattg


