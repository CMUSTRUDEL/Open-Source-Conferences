Title: Observability with Consul Connect - Bram Vogelaar, Hot Potatoes
Publication date: 2021-05-05
Playlist: ServiceMeshCon EU 2021
Description: 
	Don’t miss out! Join us at our upcoming event: KubeCon + CloudNativeCon North America 2021 in Los Angeles, CA from October 12-15. Learn more at https://kubecon.io The conference features presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects.

Observability with Consul Connect - Bram Vogelaar, Hot Potatoes

Things like Infrastructure as Code, Service Discovery and Config Management can and have helped us to quickly build and rebuild infrastructure but we haven't nearly spend enough time to train our self to review, monitor and respond to outages. Does our platform degrade in a graceful way or what does a high cpu load really mean? What can we learn from level 1 outages to be able to run our platforms more reliably. We all love infrastructure as code, we automate everything ™. However making sure all of our infrastructure assets are monitored effectively can be slow and resource intensive multi stage process. During this talk we will investigate how we can setup and observe a service mesh platform using HashiCorp's Consul Connect by recording its metrics. logs and traces using Prometheus, Loki, Tempo and Grafana.
Captions: 
	00:00:00,240 --> 00:00:03,520
good day my name is ben voclar and today

00:00:02,240 --> 00:00:07,200
we'll be discussing

00:00:03,520 --> 00:00:09,920
uh observability with console connect um

00:00:07,200 --> 00:00:10,880
but first before we start moving into

00:00:09,920 --> 00:00:13,840
directly into

00:00:10,880 --> 00:00:14,559
to service meshes we need to build up

00:00:13,840 --> 00:00:17,279
slowly

00:00:14,559 --> 00:00:18,720
to how we used to do stuff to how we

00:00:17,279 --> 00:00:21,840
want to do stuff now

00:00:18,720 --> 00:00:23,760
um back in the days when you wanted

00:00:21,840 --> 00:00:25,439
more compute power you would have to get

00:00:23,760 --> 00:00:27,199
management by and you would need to

00:00:25,439 --> 00:00:28,640
raise money you would have to get a new

00:00:27,199 --> 00:00:30,560
purchase order

00:00:28,640 --> 00:00:32,640
you would have to order the thing the

00:00:30,560 --> 00:00:34,960
thing would eventually show up to your

00:00:32,640 --> 00:00:36,559
your loading bay you would have to

00:00:34,960 --> 00:00:39,200
install it you would have to

00:00:36,559 --> 00:00:40,399
um install the os and then you would

00:00:39,200 --> 00:00:43,520
have new os

00:00:40,399 --> 00:00:46,320
um eventually that would mean like as

00:00:43,520 --> 00:00:48,320
in this picture the damn things were big

00:00:46,320 --> 00:00:50,960
um

00:00:48,320 --> 00:00:52,239
so it would require building new rooms

00:00:50,960 --> 00:00:55,520
or new buildings

00:00:52,239 --> 00:00:57,280
um that wasn't that so easy so it took

00:00:55,520 --> 00:01:00,239
years to get new compute

00:00:57,280 --> 00:01:01,840
in the 90s when the first internet

00:01:00,239 --> 00:01:04,479
bubble happened

00:01:01,840 --> 00:01:06,400
we were at a point where we would

00:01:04,479 --> 00:01:07,520
instead of building new computers we

00:01:06,400 --> 00:01:09,680
tried to

00:01:07,520 --> 00:01:13,600
solve our problems in such way that we

00:01:09,680 --> 00:01:16,240
could spread it across multiple servers

00:01:13,600 --> 00:01:17,040
when i was still in the lab that's how

00:01:16,240 --> 00:01:19,840
we used to do

00:01:17,040 --> 00:01:21,680
stuff and the list of servers was fairly

00:01:19,840 --> 00:01:23,439
small the list of users was fairly small

00:01:21,680 --> 00:01:24,880
so we could just say you work on server

00:01:23,439 --> 00:01:27,840
one you work on server two

00:01:24,880 --> 00:01:29,200
or this happens to be there and there

00:01:27,840 --> 00:01:31,040
when we started to

00:01:29,200 --> 00:01:32,960
connect stuff to the internet and our

00:01:31,040 --> 00:01:34,720
users weren't internally anymore

00:01:32,960 --> 00:01:36,000
um things like load balancers were

00:01:34,720 --> 00:01:38,880
introduced

00:01:36,000 --> 00:01:40,079
this way we could design a vanity url

00:01:38,880 --> 00:01:42,399
like google.com

00:01:40,079 --> 00:01:43,840
to our load balancers and then we could

00:01:42,399 --> 00:01:45,439
tell our users that's where it goes and

00:01:43,840 --> 00:01:48,000
then the load balancers works out

00:01:45,439 --> 00:01:48,799
where uh how to a how to spread the load

00:01:48,000 --> 00:01:52,000
or

00:01:48,799 --> 00:01:53,840
where stuff is um that was fine when

00:01:52,000 --> 00:01:54,479
purchasing was still slow like in the

00:01:53,840 --> 00:01:57,360
90s

00:01:54,479 --> 00:01:58,560
you'd still have to raise um purchase

00:01:57,360 --> 00:02:00,960
order you would still

00:01:58,560 --> 00:02:02,000
have to wait for stuff to show up on the

00:02:00,960 --> 00:02:04,000
loading dock and you would have to

00:02:02,000 --> 00:02:07,200
install it in your your own data center

00:02:04,000 --> 00:02:08,560
so um adding new new nodes and adding

00:02:07,200 --> 00:02:10,160
them to a static

00:02:08,560 --> 00:02:12,080
list in the load balancer was fine

00:02:10,160 --> 00:02:14,400
because that's how slow

00:02:12,080 --> 00:02:15,440
things were it was actually a manageable

00:02:14,400 --> 00:02:18,319
job but

00:02:15,440 --> 00:02:20,160
when we started moving to the cloud um

00:02:18,319 --> 00:02:22,319
adding new nodes removing new nodes

00:02:20,160 --> 00:02:23,520
adding new services became much much

00:02:22,319 --> 00:02:24,800
quicker and that's when service

00:02:23,520 --> 00:02:26,959
discovery showed

00:02:24,800 --> 00:02:28,080
showed up and that's um basically what

00:02:26,959 --> 00:02:31,120
service discovery is

00:02:28,080 --> 00:02:32,640
it's a method of announcing yourself

00:02:31,120 --> 00:02:35,599
into a cluster or a pool

00:02:32,640 --> 00:02:36,160
and saying i am service x or b in this

00:02:35,599 --> 00:02:39,280
case

00:02:36,160 --> 00:02:41,599
and i am ready for action and then

00:02:39,280 --> 00:02:43,840
the load balancer you announce yourself

00:02:41,599 --> 00:02:46,959
to the notepads and no bounces starts

00:02:43,840 --> 00:02:48,800
assigning you work and that's where

00:02:46,959 --> 00:02:51,120
uh console comes in that's how it

00:02:48,800 --> 00:02:52,319
originally was envisioned as a service

00:02:51,120 --> 00:02:55,120
discovery tool

00:02:52,319 --> 00:02:56,640
that could basically route stuff to your

00:02:55,120 --> 00:02:58,879
uh

00:02:56,640 --> 00:03:00,640
to your your networks or your clusters

00:02:58,879 --> 00:03:02,080
how do we set up a service in console

00:03:00,640 --> 00:03:04,800
it's actually very simple

00:03:02,080 --> 00:03:05,519
uh it's a file on disk um it's written

00:03:04,800 --> 00:03:08,560
in a

00:03:05,519 --> 00:03:10,000
dsl called hcl the hashicorp's uh

00:03:08,560 --> 00:03:14,000
configuration language

00:03:10,000 --> 00:03:15,599
and um here it shows as such we have a

00:03:14,000 --> 00:03:17,280
service name counting and it runs on a

00:03:15,599 --> 00:03:20,560
local port 9003

00:03:17,280 --> 00:03:23,760
and has one health check um basically

00:03:20,560 --> 00:03:26,000
and it pings the slash health endpoint

00:03:23,760 --> 00:03:27,599
every one second and if it's healthy

00:03:26,000 --> 00:03:29,840
it gets announced as such into the

00:03:27,599 --> 00:03:30,959
cluster and it is accepting work if it's

00:03:29,840 --> 00:03:33,040
no longer healthy

00:03:30,959 --> 00:03:35,120
console will take it out of the cluster

00:03:33,040 --> 00:03:36,239
and until such time that it's fixed

00:03:35,120 --> 00:03:39,519
again

00:03:36,239 --> 00:03:40,959
console is uh you can not only ask

00:03:39,519 --> 00:03:42,959
console direct questions

00:03:40,959 --> 00:03:44,319
console can also act as a dns server so

00:03:42,959 --> 00:03:47,840
it actually lives

00:03:44,319 --> 00:03:50,480
in your old school platform

00:03:47,840 --> 00:03:51,519
or environment just ever like like

00:03:50,480 --> 00:03:54,159
everybody else

00:03:51,519 --> 00:03:55,159
by all your services you can dig it on a

00:03:54,159 --> 00:03:59,920
local port

00:03:55,159 --> 00:04:02,239
8600 and there you need to ask it is a

00:03:59,920 --> 00:04:04,680
dns question in a specific way if i

00:04:02,239 --> 00:04:07,040
want service counting then it's

00:04:04,680 --> 00:04:09,040
counting.service.console

00:04:07,040 --> 00:04:11,120
and you can even incorporate this into

00:04:09,040 --> 00:04:13,519
your existing dns services

00:04:11,120 --> 00:04:15,120
and like i show here for my bind server

00:04:13,519 --> 00:04:17,440
that is console zone

00:04:15,120 --> 00:04:19,440
that forwards all the questions that for

00:04:17,440 --> 00:04:20,239
services and then dot console to my

00:04:19,440 --> 00:04:24,160
local

00:04:20,239 --> 00:04:24,160
console server and then

00:04:25,680 --> 00:04:29,759
the cloud was fast kubernetes containers

00:04:28,639 --> 00:04:31,759
was even faster

00:04:29,759 --> 00:04:34,479
instead of minutes we now start can

00:04:31,759 --> 00:04:36,720
start and stop services in seconds

00:04:34,479 --> 00:04:38,240
we can run services across multiple

00:04:36,720 --> 00:04:41,040
clouds

00:04:38,240 --> 00:04:42,000
and that brought a whole new layer of

00:04:41,040 --> 00:04:43,840
questions and problems

00:04:42,000 --> 00:04:45,360
to solve and that's where service meshes

00:04:43,840 --> 00:04:49,360
came in this is where

00:04:45,360 --> 00:04:52,560
we start to think about how do services

00:04:49,360 --> 00:04:54,080
collaborate or interact and how can i

00:04:52,560 --> 00:04:55,919
distinguish between

00:04:54,080 --> 00:04:57,680
different services or how can i block

00:04:55,919 --> 00:05:01,039
access to these different services

00:04:57,680 --> 00:05:03,840
and that's where um console

00:05:01,039 --> 00:05:04,960
grew into console connect and that's

00:05:03,840 --> 00:05:07,360
connect is where

00:05:04,960 --> 00:05:08,560
the lovely people at hashicorp

00:05:07,360 --> 00:05:11,600
incorporated

00:05:08,560 --> 00:05:13,919
or grew the service mess level of

00:05:11,600 --> 00:05:15,600
um of console that's what we're gonna

00:05:13,919 --> 00:05:21,199
discuss in the next couple of slides

00:05:15,600 --> 00:05:23,600
so how do i extend my service definition

00:05:21,199 --> 00:05:24,400
for a service to become console

00:05:23,600 --> 00:05:26,400
connected

00:05:24,400 --> 00:05:27,919
or service measure where and that's

00:05:26,400 --> 00:05:30,960
fairly simple we need to add

00:05:27,919 --> 00:05:32,800
just a little connect stanza with some

00:05:30,960 --> 00:05:36,400
mtv um

00:05:32,800 --> 00:05:40,880
other stanzas that's it now it's called

00:05:36,400 --> 00:05:42,960
console connect it has a tls certificate

00:05:40,880 --> 00:05:44,479
and it's ready for action so how do i

00:05:42,960 --> 00:05:46,880
connect to this it doesn't

00:05:44,479 --> 00:05:47,759
we have a accounting service which is

00:05:46,880 --> 00:05:49,520
our backhand

00:05:47,759 --> 00:05:51,280
now we'll add a dashboard on top of it

00:05:49,520 --> 00:05:52,720
runs on port 9002

00:05:51,280 --> 00:05:55,039
the only thing we need to add is a

00:05:52,720 --> 00:05:56,160
similar connect stanza but now we

00:05:55,039 --> 00:05:57,759
declare

00:05:56,160 --> 00:05:59,680
uh our upstream so we're basically

00:05:57,759 --> 00:06:02,080
saying we want to um

00:05:59,680 --> 00:06:03,520
use another service the service in this

00:06:02,080 --> 00:06:06,720
case is called counting

00:06:03,520 --> 00:06:08,319
and bind it on a local local.5000 why

00:06:06,720 --> 00:06:09,680
this is cool we're gonna discuss in the

00:06:08,319 --> 00:06:11,440
next couple of slides

00:06:09,680 --> 00:06:13,120
uh first we need to fire up the

00:06:11,440 --> 00:06:16,400
connections

00:06:13,120 --> 00:06:18,720
so we need to tell console um

00:06:16,400 --> 00:06:20,080
that the connect side of things need to

00:06:18,720 --> 00:06:22,800
be started and that's fairly simple

00:06:20,080 --> 00:06:25,039
it's a command line command called

00:06:22,800 --> 00:06:27,680
console connect proxy and then

00:06:25,039 --> 00:06:29,280
you basically say for service accounting

00:06:27,680 --> 00:06:31,280
and for service dashboard let's

00:06:29,280 --> 00:06:33,919
let's give me a sidecar and basically

00:06:31,280 --> 00:06:35,759
make it connect aware wire

00:06:33,919 --> 00:06:38,240
this is very cool it brings us a couple

00:06:35,759 --> 00:06:42,960
of additional features that we want

00:06:38,240 --> 00:06:44,479
um remember i mentioned we bind it to a

00:06:42,960 --> 00:06:48,080
local port 5000

00:06:44,479 --> 00:06:50,960
so when we use service discovery

00:06:48,080 --> 00:06:51,599
we no longer need the vanity url of a

00:06:50,960 --> 00:06:53,599
service

00:06:51,599 --> 00:06:54,960
but we still need to know which port is

00:06:53,599 --> 00:06:56,880
bound to and

00:06:54,960 --> 00:06:58,880
if people bind it if it's a known

00:06:56,880 --> 00:07:02,000
service that binds to its known

00:06:58,880 --> 00:07:04,479
port then i can infer it and i can

00:07:02,000 --> 00:07:06,080
still similarly use it um if you start

00:07:04,479 --> 00:07:09,120
using things like kubernetes

00:07:06,080 --> 00:07:09,680
hashicorps nomad as a scheduler stuff

00:07:09,120 --> 00:07:12,160
might not

00:07:09,680 --> 00:07:13,520
run on its predefined port it might be

00:07:12,160 --> 00:07:18,319
on a random number

00:07:13,520 --> 00:07:20,400
um so we need to either make um

00:07:18,319 --> 00:07:22,080
rules about which ports to use or we

00:07:20,400 --> 00:07:22,720
need to have a ledger of what the port

00:07:22,080 --> 00:07:24,800
to use

00:07:22,720 --> 00:07:26,800
and that's basically what console does

00:07:24,800 --> 00:07:29,680
for us and instead of

00:07:26,800 --> 00:07:30,960
using trying to work out a way to ask

00:07:29,680 --> 00:07:34,560
console for that port

00:07:30,960 --> 00:07:37,120
console connects actually says no

00:07:34,560 --> 00:07:38,319
i know i'll work out the port but bind

00:07:37,120 --> 00:07:40,720
it to a local port

00:07:38,319 --> 00:07:42,080
so for your local application it will

00:07:40,720 --> 00:07:44,479
look just like it

00:07:42,080 --> 00:07:47,919
is connecting to a local hosting and

00:07:44,479 --> 00:07:50,319
console connect does the magic below

00:07:47,919 --> 00:07:51,919
the other great feature about console

00:07:50,319 --> 00:07:55,199
connect is acls or

00:07:51,919 --> 00:07:58,479
in console speak intentions so i i can

00:07:55,199 --> 00:08:01,840
either i can i can block services

00:07:58,479 --> 00:08:04,639
from connect from um using my servers

00:08:01,840 --> 00:08:08,560
i can allow stuff to to happen so we

00:08:04,639 --> 00:08:10,960
never get into a situation where our

00:08:08,560 --> 00:08:11,599
development database connects tries to

00:08:10,960 --> 00:08:13,919
connect

00:08:11,599 --> 00:08:15,280
to our uh no sorry our development

00:08:13,919 --> 00:08:17,360
platform starts to connect to our

00:08:15,280 --> 00:08:20,879
production database or vice versa

00:08:17,360 --> 00:08:21,840
um that should definitely never happen

00:08:20,879 --> 00:08:24,720
you should run

00:08:21,840 --> 00:08:26,479
a console cluster for your development

00:08:24,720 --> 00:08:28,560
platform you should run a console

00:08:26,479 --> 00:08:30,479
servers for your production platform

00:08:28,560 --> 00:08:30,960
because having forbid if that ever

00:08:30,479 --> 00:08:34,000
happens

00:08:30,960 --> 00:08:34,000
due to copy and paste

00:08:34,640 --> 00:08:39,200
error you can use all the stuff i've

00:08:37,919 --> 00:08:40,640
discussed

00:08:39,200 --> 00:08:42,719
now in previous slides you can actually

00:08:40,640 --> 00:08:44,800
try yourself the lovely people at

00:08:42,719 --> 00:08:45,760
hashicorp have a very good tutorial to

00:08:44,800 --> 00:08:48,080
follow

00:08:45,760 --> 00:08:50,720
that brings us to observing stuff so

00:08:48,080 --> 00:08:54,240
i've used the words

00:08:50,720 --> 00:08:57,519
console abstracts the magic away

00:08:54,240 --> 00:08:59,760
for you um i've only i've also

00:08:57,519 --> 00:09:00,560
used a i've carried a pager for the last

00:08:59,760 --> 00:09:04,560
10 years and

00:09:00,560 --> 00:09:06,240
abstracting magic is scares me because

00:09:04,560 --> 00:09:07,760
i will never want to end up in a

00:09:06,240 --> 00:09:10,399
situation where

00:09:07,760 --> 00:09:11,279
restart and pray is my only way out of a

00:09:10,399 --> 00:09:15,120
problem

00:09:11,279 --> 00:09:15,120
so luckily um

00:09:15,440 --> 00:09:20,080
the lovely people at hashicorp have ways

00:09:17,519 --> 00:09:21,440
to work to work out what is going on and

00:09:20,080 --> 00:09:22,560
that's actually what we need to do in

00:09:21,440 --> 00:09:25,360
general anyway

00:09:22,560 --> 00:09:27,600
so just three ways to work out what is

00:09:25,360 --> 00:09:31,040
going on we either look at the metrics

00:09:27,600 --> 00:09:32,800
that the system emits so

00:09:31,040 --> 00:09:34,560
how many purchases are happening how

00:09:32,800 --> 00:09:37,920
what's uh how many

00:09:34,560 --> 00:09:39,360
uh users do i have what's what's the hit

00:09:37,920 --> 00:09:42,880
rate per second

00:09:39,360 --> 00:09:45,440
um also can i look at the logs the

00:09:42,880 --> 00:09:46,080
platform is emitting how many errors are

00:09:45,440 --> 00:09:49,680
are there

00:09:46,080 --> 00:09:51,920
other information messages

00:09:49,680 --> 00:09:53,120
and also since we're using well

00:09:51,920 --> 00:09:55,040
hopefully or

00:09:53,120 --> 00:09:56,800
possibly using microservice you also

00:09:55,040 --> 00:09:57,920
need to look at traces and tracing is

00:09:56,800 --> 00:10:00,160
basically

00:09:57,920 --> 00:10:01,920
working out where in your platform your

00:10:00,160 --> 00:10:02,800
application is spending its time is it

00:10:01,920 --> 00:10:06,320
in the database

00:10:02,800 --> 00:10:09,200
is it um rehashing acls is it

00:10:06,320 --> 00:10:11,279
waiting for the accounting servers that

00:10:09,200 --> 00:10:13,120
is waiting for its own database

00:10:11,279 --> 00:10:15,519
um so the three things that we need to

00:10:13,120 --> 00:10:17,760
look at is metric traces and logs

00:10:15,519 --> 00:10:19,839
and the rest of this con presentation is

00:10:17,760 --> 00:10:20,160
going to dig into how we're going to use

00:10:19,839 --> 00:10:23,360
the

00:10:20,160 --> 00:10:26,640
grafana stack or the

00:10:23,360 --> 00:10:29,839
to look at into where

00:10:26,640 --> 00:10:30,800
the magic is happening in console

00:10:29,839 --> 00:10:34,720
connect

00:10:30,800 --> 00:10:36,320
so console connect is built on the

00:10:34,720 --> 00:10:38,880
shoulder of giant so it's not an

00:10:36,320 --> 00:10:39,839
a novel implementation but it's actually

00:10:38,880 --> 00:10:42,560
reusing

00:10:39,839 --> 00:10:44,079
a cncf tool called envoy which is great

00:10:42,560 --> 00:10:44,880
because there's more people looking at

00:10:44,079 --> 00:10:46,959
it it's not a

00:10:44,880 --> 00:10:49,040
not invented here product but it's

00:10:46,959 --> 00:10:51,680
actually a nice wrapper around

00:10:49,040 --> 00:10:53,760
around envoy so when we i talk about

00:10:51,680 --> 00:10:54,720
metrics i'm talking about prometheus

00:10:53,760 --> 00:10:58,880
collecting

00:10:54,720 --> 00:11:04,240
your exposed metrics from cncf tool

00:10:58,880 --> 00:11:06,560
it and it scrapes metrics as i said so

00:11:04,240 --> 00:11:07,519
instead of the classic old-school tools

00:11:06,560 --> 00:11:09,440
that push in the

00:11:07,519 --> 00:11:11,839
metrics it actually pulls metrics that

00:11:09,440 --> 00:11:11,839
brings in

00:11:11,920 --> 00:11:15,600
the need for service discovery which we

00:11:13,600 --> 00:11:17,760
have and is very cool

00:11:15,600 --> 00:11:19,839
and nicely integrated into prometheus

00:11:17,760 --> 00:11:23,839
prometheus also has its own

00:11:19,839 --> 00:11:26,320
query language that allows us to

00:11:23,839 --> 00:11:27,519
query the data but also ask very very

00:11:26,320 --> 00:11:31,680
specific questions

00:11:27,519 --> 00:11:34,480
so how do i expose my prometheus metrics

00:11:31,680 --> 00:11:36,079
um in console connect not actually i'm

00:11:34,480 --> 00:11:38,320
not exposing console connect

00:11:36,079 --> 00:11:39,839
console metrics we although you also

00:11:38,320 --> 00:11:43,200
should but

00:11:39,839 --> 00:11:45,040
um this way we actually exposing the

00:11:43,200 --> 00:11:48,079
built-in android metrics

00:11:45,040 --> 00:11:48,880
which is very cool and we the only thing

00:11:48,079 --> 00:11:52,079
we need to do

00:11:48,880 --> 00:11:56,000
is add a three-line blob to

00:11:52,079 --> 00:11:58,639
our already existing console connect

00:11:56,000 --> 00:12:00,720
configuration basically saying i want to

00:11:58,639 --> 00:12:04,160
inject a little bit of configuration

00:12:00,720 --> 00:12:06,880
and i want to make sure that i expose my

00:12:04,160 --> 00:12:10,480
envoy prometheus endpoint at a certain

00:12:06,880 --> 00:12:14,320
port in on my local

00:12:10,480 --> 00:12:16,480
system um that the way i showed it in

00:12:14,320 --> 00:12:18,079
the previous slide is actually

00:12:16,480 --> 00:12:20,800
a bit cumbersome because now we need to

00:12:18,079 --> 00:12:23,040
actually make a promise

00:12:20,800 --> 00:12:24,320
well i need to ask all our developers in

00:12:23,040 --> 00:12:26,079
every job you

00:12:24,320 --> 00:12:28,000
you make make sure that this line is

00:12:26,079 --> 00:12:31,360
available the other way around is

00:12:28,000 --> 00:12:33,040
um injecting it into the global console

00:12:31,360 --> 00:12:35,200
configuration

00:12:33,040 --> 00:12:38,639
and by basically saying enable the

00:12:35,200 --> 00:12:39,519
central service config and make sure

00:12:38,639 --> 00:12:42,639
that

00:12:39,519 --> 00:12:47,040
for every type every kind of pro

00:12:42,639 --> 00:12:49,760
of a proxy we um we inject this

00:12:47,040 --> 00:12:50,079
this bind address and of course as i

00:12:49,760 --> 00:12:52,880
said

00:12:50,079 --> 00:12:54,000
please make sure that you're exposing

00:12:52,880 --> 00:12:55,680
the console metrics

00:12:54,000 --> 00:12:57,680
itself and that's the last four lines

00:12:55,680 --> 00:12:59,600
basically i have a

00:12:57,680 --> 00:13:00,880
telemetry blog and make sure you

00:12:59,600 --> 00:13:04,160
configure a few

00:13:00,880 --> 00:13:06,160
exposure as premises data how to collect

00:13:04,160 --> 00:13:08,079
this in prometheus there's two ways

00:13:06,160 --> 00:13:09,440
uh one is a hardcoded list which is the

00:13:08,079 --> 00:13:11,680
top part um

00:13:09,440 --> 00:13:12,880
which is a little bit of yaml and you

00:13:11,680 --> 00:13:16,079
say

00:13:12,880 --> 00:13:18,240
have a straight config that's

00:13:16,079 --> 00:13:19,440
the the way prometheus names those

00:13:18,240 --> 00:13:23,120
things have a job

00:13:19,440 --> 00:13:25,040
and scrape all the static targets now

00:13:23,120 --> 00:13:26,560
did the cool meta way of doing it a

00:13:25,040 --> 00:13:26,959
cooler matter way of doing it is

00:13:26,560 --> 00:13:29,920
actually

00:13:26,959 --> 00:13:30,880
using consoles service discovery so have

00:13:29,920 --> 00:13:33,839
prometheus

00:13:30,880 --> 00:13:35,360
query console for all services that have

00:13:33,839 --> 00:13:37,920
a certain name

00:13:35,360 --> 00:13:40,959
in this case console connect envoy and

00:13:37,920 --> 00:13:43,920
then make sure that you just

00:13:40,959 --> 00:13:44,800
scrape those that way we actually

00:13:43,920 --> 00:13:46,639
announce

00:13:44,800 --> 00:13:49,199
services that need to be scraped by

00:13:46,639 --> 00:13:52,240
prometheus and then the circle is round

00:13:49,199 --> 00:13:53,920
so how do we use uh prometheus data

00:13:52,240 --> 00:13:56,320
there's two ways actually console has a

00:13:53,920 --> 00:13:58,880
ui and since version 1.7

00:13:56,320 --> 00:13:59,920
you can actually have a nice integration

00:13:58,880 --> 00:14:02,959
with prometheus

00:13:59,920 --> 00:14:04,720
and in the general console

00:14:02,959 --> 00:14:07,680
configuration you need to add a ui

00:14:04,720 --> 00:14:10,720
config blob and you need to point that

00:14:07,680 --> 00:14:14,160
towards your your prometheus

00:14:10,720 --> 00:14:14,880
server and that's it then if you look at

00:14:14,160 --> 00:14:18,399
the ui

00:14:14,880 --> 00:14:20,959
you now have little exploratory usage

00:14:18,399 --> 00:14:22,959
view if you drill down into your

00:14:20,959 --> 00:14:24,720
services in this case i have a product

00:14:22,959 --> 00:14:27,199
a product api that needs to talk to my

00:14:24,720 --> 00:14:28,560
database and i can actually see data

00:14:27,199 --> 00:14:31,120
going on

00:14:28,560 --> 00:14:32,480
that's all it shows but if you want to

00:14:31,120 --> 00:14:34,240
drill deeper you actually

00:14:32,480 --> 00:14:36,160
can click on open the metrics that

00:14:34,240 --> 00:14:36,800
dashboard and then what happens it goes

00:14:36,160 --> 00:14:39,440
to your

00:14:36,800 --> 00:14:40,320
local grafana instance and grafina is a

00:14:39,440 --> 00:14:42,720
dashboard

00:14:40,320 --> 00:14:45,040
that does metrics and does metrics

00:14:42,720 --> 00:14:48,079
involved in a general way

00:14:45,040 --> 00:14:51,680
it started out as a project that could

00:14:48,079 --> 00:14:53,600
visualize graphite data um

00:14:51,680 --> 00:14:54,880
but over the years it's gained a plug-in

00:14:53,600 --> 00:14:57,040
system and it

00:14:54,880 --> 00:14:58,880
gained data back-end plug-ins for

00:14:57,040 --> 00:15:01,519
basically any

00:14:58,880 --> 00:15:03,519
metrics back-end but also logging and

00:15:01,519 --> 00:15:05,760
tracing at the moment

00:15:03,519 --> 00:15:07,600
so it's very cool how do we connect

00:15:05,760 --> 00:15:11,040
gravana to our prometheus it's a

00:15:07,600 --> 00:15:14,160
little yammer file with a standard blob

00:15:11,040 --> 00:15:17,600
uh offtide prometheus pointed to

00:15:14,160 --> 00:15:19,839
uh dns where prometheus lives in my case

00:15:17,600 --> 00:15:21,440
that's the console service so console

00:15:19,839 --> 00:15:24,959
also does dns for this

00:15:21,440 --> 00:15:27,360
and i do it in a wildly insecure way by

00:15:24,959 --> 00:15:29,040
not having any authentication if you run

00:15:27,360 --> 00:15:30,560
into production please add it but for

00:15:29,040 --> 00:15:34,000
this

00:15:30,560 --> 00:15:34,639
presentation itself then in grafana i

00:15:34,000 --> 00:15:37,839
can use

00:15:34,639 --> 00:15:40,800
a bunch of cool dashboards

00:15:37,839 --> 00:15:42,800
you can also download them off of the

00:15:40,800 --> 00:15:44,240
grafana website and in this case i

00:15:42,800 --> 00:15:46,160
actually have a visualization of my

00:15:44,240 --> 00:15:46,959
console cluster i have three nodes

00:15:46,160 --> 00:15:49,040
there's a

00:15:46,959 --> 00:15:51,440
leader and i have a fairly healthy

00:15:49,040 --> 00:15:55,120
amount of careers going on

00:15:51,440 --> 00:15:56,240
next up is logs um i'm introducing a

00:15:55,120 --> 00:15:59,360
tool called loki

00:15:56,240 --> 00:16:00,000
which came out of grafana labs uh fairly

00:15:59,360 --> 00:16:03,839
recently

00:16:00,000 --> 00:16:05,920
and in the byline is prometheus for logs

00:16:03,839 --> 00:16:08,000
so

00:16:05,920 --> 00:16:09,440
in the olden days or not that long ago

00:16:08,000 --> 00:16:12,240
actually um

00:16:09,440 --> 00:16:12,880
locking aggregation systems like the ax

00:16:12,240 --> 00:16:15,920
stack like

00:16:12,880 --> 00:16:17,199
splunk were platforms in and of itself

00:16:15,920 --> 00:16:20,320
so it took

00:16:17,199 --> 00:16:22,560
skills time resources to run that

00:16:20,320 --> 00:16:24,639
just for your actual platform to push

00:16:22,560 --> 00:16:25,199
stuff into so loki is a much simpler way

00:16:24,639 --> 00:16:26,800
but

00:16:25,199 --> 00:16:30,720
also much more powerful way in my

00:16:26,800 --> 00:16:34,079
opinion of doing stuff it's um

00:16:30,720 --> 00:16:37,759
it's heavily influenced on on prometheus

00:16:34,079 --> 00:16:39,519
um and you can run it basically off of a

00:16:37,759 --> 00:16:42,399
single go binary as a

00:16:39,519 --> 00:16:43,920
monolithic instance or you can spread it

00:16:42,399 --> 00:16:46,720
out as microservices all

00:16:43,920 --> 00:16:48,839
using the same binary um how do i push

00:16:46,720 --> 00:16:50,560
my stuff

00:16:48,839 --> 00:16:53,440
from

00:16:50,560 --> 00:16:55,040
from my console connect into loki i

00:16:53,440 --> 00:16:56,320
there's a couple of ways doing this the

00:16:55,040 --> 00:16:57,920
first one is if you're running

00:16:56,320 --> 00:16:59,040
everything in docker anyway on

00:16:57,920 --> 00:17:02,880
kubernetes

00:16:59,040 --> 00:17:05,839
um install the docker plug-in um

00:17:02,880 --> 00:17:07,760
they kephana provide there are some

00:17:05,839 --> 00:17:10,079
issues at the moment so it's a

00:17:07,760 --> 00:17:11,760
blocking call so if your look is down

00:17:10,079 --> 00:17:15,199
you'll have issues

00:17:11,760 --> 00:17:15,199
manipulating your containers

00:17:16,559 --> 00:17:20,319
if you're running still bare metal or

00:17:18,160 --> 00:17:23,760
you're a bit scared about the blocking

00:17:20,319 --> 00:17:27,199
query thing is you can actually

00:17:23,760 --> 00:17:31,520
make console connect write its logs

00:17:27,199 --> 00:17:33,600
into a file and then scrape it using the

00:17:31,520 --> 00:17:35,440
loki's command line tool called prom

00:17:33,600 --> 00:17:38,559
tail and

00:17:35,440 --> 00:17:41,919
the weird ish command line

00:17:38,559 --> 00:17:42,640
on online number one is um so we have

00:17:41,919 --> 00:17:44,880
the

00:17:42,640 --> 00:17:46,240
the first part of the command is the

00:17:44,880 --> 00:17:49,760
command we're used to

00:17:46,240 --> 00:17:52,000
and then dash dash which means it tells

00:17:49,760 --> 00:17:53,360
console everything after this is not

00:17:52,000 --> 00:17:56,160
your configuration

00:17:53,360 --> 00:17:58,880
but it's invoice so you can parse stuff

00:17:56,160 --> 00:18:02,799
directly to envoy and this is how you

00:17:58,880 --> 00:18:05,039
this is how we now ask android to

00:18:02,799 --> 00:18:06,080
parse everything to a config file which

00:18:05,039 --> 00:18:09,360
then gets

00:18:06,080 --> 00:18:11,679
scraped and pushed into loki um again

00:18:09,360 --> 00:18:12,960
how do i set up the data source similar

00:18:11,679 --> 00:18:17,280
like before

00:18:12,960 --> 00:18:20,240
yammer file after and then type loki

00:18:17,280 --> 00:18:21,760
put push it towards the url and then

00:18:20,240 --> 00:18:22,799
bob's your own code what does that look

00:18:21,760 --> 00:18:25,280
like if you want to

00:18:22,799 --> 00:18:27,360
initially you want to do exploratory

00:18:25,280 --> 00:18:29,360
research

00:18:27,360 --> 00:18:31,200
what is my application actually pushing

00:18:29,360 --> 00:18:34,720
what are his neighbors pushing

00:18:31,200 --> 00:18:38,720
therefore grafana has a very cool

00:18:34,720 --> 00:18:41,600
new explore tool and then we can query

00:18:38,720 --> 00:18:42,160
you can push push in any lock ul queries

00:18:41,600 --> 00:18:43,919
that

00:18:42,160 --> 00:18:46,960
you can come up with and then eventually

00:18:43,919 --> 00:18:51,039
you can turn that into dashboarding

00:18:46,960 --> 00:18:54,080
last lastly it's traces traces

00:18:51,039 --> 00:18:55,840
can be stored in a new tool called

00:18:54,080 --> 00:18:59,120
grafana temple

00:18:55,840 --> 00:19:02,559
which has a similar impetus as

00:18:59,120 --> 00:19:05,280
as loki the generation

00:19:02,559 --> 00:19:07,360
one tools like zipkin like jaeger

00:19:05,280 --> 00:19:09,600
actually are quite cumbersome to run

00:19:07,360 --> 00:19:11,200
you require databases you require

00:19:09,600 --> 00:19:13,360
storage

00:19:11,200 --> 00:19:14,880
and tempo is a much leaner way of

00:19:13,360 --> 00:19:17,440
running things but not

00:19:14,880 --> 00:19:17,440
stopping you

00:19:18,880 --> 00:19:22,559
running your own platforms it's a single

00:19:21,280 --> 00:19:26,480
go binary

00:19:22,559 --> 00:19:29,600
it speaks uh zipkin

00:19:26,480 --> 00:19:32,720
jaeger open telemetry um

00:19:29,600 --> 00:19:34,799
dialects so you can use your

00:19:32,720 --> 00:19:36,240
your tools you're used to but in a much

00:19:34,799 --> 00:19:37,679
leaner way and then it stores it

00:19:36,240 --> 00:19:39,039
directly into cloud

00:19:37,679 --> 00:19:40,720
cloud-based storage instead of a

00:19:39,039 --> 00:19:44,240
database you have to run

00:19:40,720 --> 00:19:44,960
um making envoy emit traces is a bit

00:19:44,240 --> 00:19:48,160
more work

00:19:44,960 --> 00:19:49,200
than than logs or metrics so there's a

00:19:48,160 --> 00:19:52,640
two-way

00:19:49,200 --> 00:19:55,760
two-way blob ones of json

00:19:52,640 --> 00:19:59,120
firstly you need to tell

00:19:55,760 --> 00:20:04,000
envoy that it needs to emit zipkin or

00:19:59,120 --> 00:20:04,000
in this case they can type traces

00:20:04,320 --> 00:20:08,320
and then next of all that's the more

00:20:06,799 --> 00:20:10,320
elaborate blob that

00:20:08,320 --> 00:20:11,679
hopefully hashicorp will eventually

00:20:10,320 --> 00:20:13,520
abstract away for us

00:20:11,679 --> 00:20:15,840
is there's a large blob that basically

00:20:13,520 --> 00:20:18,320
has a three line

00:20:15,840 --> 00:20:19,919
bits of information where's the address

00:20:18,320 --> 00:20:24,480
what port

00:20:19,919 --> 00:20:26,960
is my uh my zipkin or in my case

00:20:24,480 --> 00:20:28,960
my tempo living and please push the

00:20:26,960 --> 00:20:31,360
traces to that

00:20:28,960 --> 00:20:32,240
again we can simply add it to um to

00:20:31,360 --> 00:20:35,039
kufana

00:20:32,240 --> 00:20:36,400
my little yaml file pointed towards the

00:20:35,039 --> 00:20:39,840
tempo query

00:20:36,400 --> 00:20:43,600
um front end tempo at the moment

00:20:39,840 --> 00:20:46,799
needs a second component to visualize

00:20:43,600 --> 00:20:48,960
traces in grafana there

00:20:46,799 --> 00:20:51,280
in the process of removing this

00:20:48,960 --> 00:20:55,039
requirement so that you simply only have

00:20:51,280 --> 00:20:58,480
temple um but for the moment it's a

00:20:55,039 --> 00:20:58,880
mini slightly manipulated jager front

00:20:58,480 --> 00:21:02,400
end

00:20:58,880 --> 00:21:03,200
that needs to run so hopefully when 0.7

00:21:02,400 --> 00:21:05,360
comes out

00:21:03,200 --> 00:21:06,400
which hasn't happened yet at the time of

00:21:05,360 --> 00:21:10,320
this recording

00:21:06,400 --> 00:21:14,400
you will be able to run this as a single

00:21:10,320 --> 00:21:17,840
single binary um if we have

00:21:14,400 --> 00:21:19,760
tempo traces we can set up in such a way

00:21:17,840 --> 00:21:21,760
that we can correlate between low key to

00:21:19,760 --> 00:21:23,440
sources and tempo sources therefore we

00:21:21,760 --> 00:21:26,480
need to

00:21:23,440 --> 00:21:30,159
extend the loki data source slightly

00:21:26,480 --> 00:21:32,480
by saying there's now the right field

00:21:30,159 --> 00:21:34,320
or if you find a derived field that

00:21:32,480 --> 00:21:37,600
smells like trace id

00:21:34,320 --> 00:21:39,919
then couple it to um

00:21:37,600 --> 00:21:41,039
then it probably is a trace id and make

00:21:39,919 --> 00:21:43,679
sure that you couple it

00:21:41,039 --> 00:21:44,960
to to the tempo data source so what does

00:21:43,679 --> 00:21:48,320
that look like if you

00:21:44,960 --> 00:21:51,200
on the left i will we're looking at logs

00:21:48,320 --> 00:21:53,039
and if it finds its trace id then

00:21:51,200 --> 00:21:56,080
there's a new button you can click

00:21:53,039 --> 00:21:56,559
and then on the right hand side a trace

00:21:56,080 --> 00:21:59,280
panel

00:21:56,559 --> 00:22:00,159
shows up so therefore we can very easily

00:21:59,280 --> 00:22:02,320
and simply

00:22:00,159 --> 00:22:03,280
correlate between our logs and our

00:22:02,320 --> 00:22:04,720
traces

00:22:03,280 --> 00:22:06,960
and hopefully you can work out what

00:22:04,720 --> 00:22:09,200
happens so that's the end of my

00:22:06,960 --> 00:22:11,760
presentation thank you for listening

00:22:09,200 --> 00:22:12,720
if you want to talk to me about it ping

00:22:11,760 --> 00:22:15,120
me on email

00:22:12,720 --> 00:22:15,760
uh you wanna stop me on twitter please

00:22:15,120 --> 00:22:18,640
do

00:22:15,760 --> 00:22:19,679
and if you wanna look at these slides a

00:22:18,640 --> 00:22:24,400
bit more slowly

00:22:19,679 --> 00:22:24,400

YouTube URL: https://www.youtube.com/watch?v=ZmCxCbvNAx0


