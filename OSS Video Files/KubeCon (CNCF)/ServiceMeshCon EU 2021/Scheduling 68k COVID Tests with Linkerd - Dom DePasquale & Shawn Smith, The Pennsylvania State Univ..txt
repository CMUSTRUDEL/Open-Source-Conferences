Title: Scheduling 68k COVID Tests with Linkerd - Dom DePasquale & Shawn Smith, The Pennsylvania State Univ.
Publication date: 2021-05-05
Playlist: ServiceMeshCon EU 2021
Description: 
	Donâ€™t miss out! Join us at our upcoming event: KubeCon + CloudNativeCon North America 2021 in Los Angeles, CA from October 12-15. Learn more at https://kubecon.io The conference features presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects.

Scheduling 68k COVID Tests with Linkerd - Dom DePasquale & Shawn Smith, The Pennsylvania State University

In the summer of 2020, Penn State's software engineering team was tasked with building a system for scheduling the testing of students, faculty, and staff for their arrival back to campus in the fall. In this HIPAA-compliant testing and scheduling system, Linkerd was installed because of its reputation for security and observability. As the team came to learn in February 2021, the #1 reason to have Linkerd is to troubleshoot performance issues. The engineering team sent out over 68,000 invites to those returning to campus to log into the system and schedule COVID tests upon return for the spring semester. The large load on the system highlighted where bottlenecks and bugs really existed. In this presentation, members of that team will discuss how they utilized Linkerd to secure, monitor, and troubleshoot the microservice-based system.
Captions: 
	00:00:00,080 --> 00:00:03,520
uh so okay let's go ahead and get

00:00:01,199 --> 00:00:03,520
started

00:00:06,000 --> 00:00:08,880
so this is science a slightly

00:00:07,600 --> 00:00:09,840
interesting title for this particular

00:00:08,880 --> 00:00:11,920
presentation

00:00:09,840 --> 00:00:12,880
um we didn't really use liquor d to

00:00:11,920 --> 00:00:14,559
schedule the test

00:00:12,880 --> 00:00:16,080
but linker d greatly facilitated our

00:00:14,559 --> 00:00:17,520
ability to schedule the tests

00:00:16,080 --> 00:00:18,880
uh six to eight thousand coveted tests

00:00:17,520 --> 00:00:20,160
in a very short period of time and we're

00:00:18,880 --> 00:00:21,680
gonna kind of talk you through how it

00:00:20,160 --> 00:00:24,320
helped us troubleshoot some problems and

00:00:21,680 --> 00:00:26,960
get us over some humps

00:00:24,320 --> 00:00:27,920
so introductions first um dom you want

00:00:26,960 --> 00:00:30,160
to say hi

00:00:27,920 --> 00:00:30,960
sure i'm dom d pasquale i'm the devops

00:00:30,160 --> 00:00:32,719
architect

00:00:30,960 --> 00:00:35,040
at penn state university in the

00:00:32,719 --> 00:00:38,320
department of software engineering

00:00:35,040 --> 00:00:40,800
and i am trump oh sorry sorry

00:00:38,320 --> 00:00:42,800
i do all things kubernetes and pipelines

00:00:40,800 --> 00:00:44,079
and all that fun stuff

00:00:42,800 --> 00:00:45,840
and i'm sean smith i'm the director of

00:00:44,079 --> 00:00:48,000
software engineering and uh

00:00:45,840 --> 00:00:50,320
we we built software for penn state

00:00:48,000 --> 00:00:53,120
university

00:00:50,320 --> 00:00:54,800
next please so a little bit of

00:00:53,120 --> 00:00:56,559
background so last march like everybody

00:00:54,800 --> 00:00:58,480
else we were all kind of affected by

00:00:56,559 --> 00:00:59,680
what happened with the covet outbreak

00:00:58,480 --> 00:01:00,960
and

00:00:59,680 --> 00:01:03,120
since we work in higher education what

00:01:00,960 --> 00:01:04,559
that meant for us is that we had to find

00:01:03,120 --> 00:01:05,680
a way to send all of our students home

00:01:04,559 --> 00:01:07,520
very very quickly

00:01:05,680 --> 00:01:08,880
while trying to keep them engaged and

00:01:07,520 --> 00:01:09,439
coming up with a plan to bring them back

00:01:08,880 --> 00:01:12,880
safely

00:01:09,439 --> 00:01:14,960
in the fall what happened

00:01:12,880 --> 00:01:16,320
was we reached out we had a bunch of

00:01:14,960 --> 00:01:18,720
vendors that we were dealing with for

00:01:16,320 --> 00:01:20,000
doing testing we had on-site testing

00:01:18,720 --> 00:01:21,920
and we had no way to tie all these

00:01:20,000 --> 00:01:23,119
things together so we quickly took a

00:01:21,920 --> 00:01:24,960
built a system

00:01:23,119 --> 00:01:27,119
to pull all the pieces together to go

00:01:24,960 --> 00:01:28,960
all the way from testing test resulting

00:01:27,119 --> 00:01:30,640
to contact tracing um unfortunately

00:01:28,960 --> 00:01:31,920
we're built on top of a micro service

00:01:30,640 --> 00:01:33,759
infrastructure

00:01:31,920 --> 00:01:35,439
uh and dom has done a really great job

00:01:33,759 --> 00:01:37,280
of terraforming a lot of the

00:01:35,439 --> 00:01:38,880
our actual backend infrastructure out so

00:01:37,280 --> 00:01:40,560
we were able to turn things very very

00:01:38,880 --> 00:01:42,479
quickly

00:01:40,560 --> 00:01:43,759
we changed directions in the spring

00:01:42,479 --> 00:01:46,320
semester of

00:01:43,759 --> 00:01:48,560
2021. it was decided by the university

00:01:46,320 --> 00:01:50,399
that all the students would have to be

00:01:48,560 --> 00:01:52,399
tested 72 hours before they could come

00:01:50,399 --> 00:01:54,399
back and then again within

00:01:52,399 --> 00:01:55,600
10 days of return um and for those of

00:01:54,399 --> 00:01:56,079
you who aren't familiar with penn state

00:01:55,600 --> 00:01:58,799
we're

00:01:56,079 --> 00:02:00,159
a pretty large institution so for those

00:01:58,799 --> 00:02:02,479
that were returning to campus that

00:02:00,159 --> 00:02:04,079
really equated to about 68 000

00:02:02,479 --> 00:02:06,320
scheduled tests in a kind of a very

00:02:04,079 --> 00:02:09,840
short period of time

00:02:06,320 --> 00:02:09,840
um next please

00:02:11,280 --> 00:02:15,200
so what we were doing is we have a bunch

00:02:13,840 --> 00:02:16,319
of commonwealth campuses and we have the

00:02:15,200 --> 00:02:19,680
main campus

00:02:16,319 --> 00:02:21,920
and we were sending out test uh requests

00:02:19,680 --> 00:02:22,800
invitations for tests a thousand at a

00:02:21,920 --> 00:02:25,760
time

00:02:22,800 --> 00:02:27,200
um and somebody who don was kind enough

00:02:25,760 --> 00:02:29,840
to not want to mention so he called

00:02:27,200 --> 00:02:31,200
him someone but he knows who he is chris

00:02:29,840 --> 00:02:32,879
i wanted to see just how

00:02:31,200 --> 00:02:34,239
quickly we could kind of push the system

00:02:32,879 --> 00:02:35,440
and see what it could take

00:02:34,239 --> 00:02:37,599
and again this is something that we

00:02:35,440 --> 00:02:39,200
didn't really plan for large scaling we

00:02:37,599 --> 00:02:40,879
had to build it very very quickly

00:02:39,200 --> 00:02:42,319
so we weren't entirely sure how it was

00:02:40,879 --> 00:02:43,840
going to work we had half of the

00:02:42,319 --> 00:02:45,519
infrastructure on premise half the

00:02:43,840 --> 00:02:47,680
infrastructure was in the cloud

00:02:45,519 --> 00:02:48,800
um so we had to kind of figure out what

00:02:47,680 --> 00:02:52,800
what the heck was going to happen

00:02:48,800 --> 00:02:52,800
when we did this uh next slide

00:02:54,480 --> 00:02:58,239
so why linker d um so linker d we we had

00:02:57,680 --> 00:03:01,760
tried

00:02:58,239 --> 00:03:03,760
other service meshes previously

00:03:01,760 --> 00:03:05,360
and we found some challenges in them in

00:03:03,760 --> 00:03:07,200
the configuration we couldn't we had we

00:03:05,360 --> 00:03:10,080
struggled with some of the the

00:03:07,200 --> 00:03:10,319
tools that we wanted um and then i was

00:03:10,080 --> 00:03:12,159
at

00:03:10,319 --> 00:03:13,599
kubecon a couple years back and i went

00:03:12,159 --> 00:03:15,200
to a presentation on linker d and i saw

00:03:13,599 --> 00:03:17,040
how easily it installed

00:03:15,200 --> 00:03:18,400
um how smoothly things went and i

00:03:17,040 --> 00:03:20,159
immediately texted don

00:03:18,400 --> 00:03:21,840
uh the pr the person that was

00:03:20,159 --> 00:03:24,080
aforementioned in the previous slide was

00:03:21,840 --> 00:03:25,120
also in the presentation also texted don

00:03:24,080 --> 00:03:26,720
dom

00:03:25,120 --> 00:03:28,480
and what we recognize is that you know

00:03:26,720 --> 00:03:29,760
with linker d we we got a lot of

00:03:28,480 --> 00:03:32,560
capability with far less

00:03:29,760 --> 00:03:34,000
complexity mutual tls is great i mean

00:03:32,560 --> 00:03:35,840
who doesn't like security

00:03:34,000 --> 00:03:37,680
free retries is great because we get

00:03:35,840 --> 00:03:39,599
tired of building that into our code

00:03:37,680 --> 00:03:41,519
but the real bang that we got from

00:03:39,599 --> 00:03:43,440
linker d is the observability so

00:03:41,519 --> 00:03:46,400
observability really gave us the

00:03:43,440 --> 00:03:50,159
opportunity to go in and kind of

00:03:46,400 --> 00:03:50,159
visualize and see things at a new level

00:03:51,519 --> 00:03:57,120
okay let's get started with the demo

00:03:54,560 --> 00:03:58,319
on my laptop i have two clusters of

00:03:57,120 --> 00:04:01,439
minicube running

00:03:58,319 --> 00:04:04,239
an east and west cluster and i will show

00:04:01,439 --> 00:04:05,120
what that means here in the next slide

00:04:04,239 --> 00:04:07,040
liquor d

00:04:05,120 --> 00:04:08,959
2.8 running since at the time of the

00:04:07,040 --> 00:04:13,040
event we had lincoln d2.8

00:04:08,959 --> 00:04:16,000
and i didn't want to change anything

00:04:13,040 --> 00:04:18,000
the load test will be run via kate's k6

00:04:16,000 --> 00:04:19,840
and

00:04:18,000 --> 00:04:22,000
i'll be quickly stepping up to 200

00:04:19,840 --> 00:04:25,680
virtual users to really

00:04:22,000 --> 00:04:28,800
drive drive load on the on my laptop

00:04:25,680 --> 00:04:32,000
and we're just doing simple gets

00:04:28,800 --> 00:04:34,000
for this endpoint i will mention quickly

00:04:32,000 --> 00:04:36,000
that since we are doing both

00:04:34,000 --> 00:04:38,720
running two clusters on my laptop and

00:04:36,000 --> 00:04:40,479
the load test tool on my laptop

00:04:38,720 --> 00:04:42,479
there will be some resource contention

00:04:40,479 --> 00:04:44,639
and there's a good chance that

00:04:42,479 --> 00:04:47,040
some of the performance issues we see

00:04:44,639 --> 00:04:49,440
aren't necessarily induced by

00:04:47,040 --> 00:04:52,720
latent services it's just a system

00:04:49,440 --> 00:04:52,720
resource contention problem

00:04:53,520 --> 00:04:58,560
but the way the east and west clusters

00:04:55,120 --> 00:05:00,960
are laid out on my laptop are

00:04:58,560 --> 00:05:02,560
similar to what our environment was

00:05:00,960 --> 00:05:05,520
during the real

00:05:02,560 --> 00:05:06,560
production outage well partial lavish

00:05:05,520 --> 00:05:08,639
east

00:05:06,560 --> 00:05:09,680
is representing what we had running in

00:05:08,639 --> 00:05:12,400
aws

00:05:09,680 --> 00:05:14,880
and west is representing what is running

00:05:12,400 --> 00:05:18,400
on-prem at penn state

00:05:14,880 --> 00:05:21,039
and the you know unhappy stick figure

00:05:18,400 --> 00:05:24,160
here with had a browser

00:05:21,039 --> 00:05:25,680
launched from the invite

00:05:24,160 --> 00:05:28,080
taking you to the scheduling system the

00:05:25,680 --> 00:05:30,960
scheduling app you know in the browser

00:05:28,080 --> 00:05:33,360
was calling the top level back end

00:05:30,960 --> 00:05:36,960
service demo service x

00:05:33,360 --> 00:05:40,960
demo service x depends on the on prem

00:05:36,960 --> 00:05:41,280
on these three demo demo servers a b and

00:05:40,960 --> 00:05:44,479
c

00:05:41,280 --> 00:05:45,520
so x depends on a b and c you also

00:05:44,479 --> 00:05:48,560
notice that a and b

00:05:45,520 --> 00:05:52,479
depend on c and then c

00:05:48,560 --> 00:05:57,120
depends on two simple http bins and

00:05:52,479 --> 00:05:59,759
demo service d now

00:05:57,120 --> 00:06:00,880
demo service c is actually our rbok

00:05:59,759 --> 00:06:03,680
service

00:06:00,880 --> 00:06:04,560
and which is which is why it's so

00:06:03,680 --> 00:06:07,840
dependent

00:06:04,560 --> 00:06:07,840
everything depends on it

00:06:08,560 --> 00:06:13,440
from demo service c it depends on

00:06:11,840 --> 00:06:15,520
what we're simulating here is just you

00:06:13,440 --> 00:06:18,720
know three random little services but in

00:06:15,520 --> 00:06:18,720
reality it would have been

00:06:19,360 --> 00:06:23,199
authentication and authentication and

00:06:21,520 --> 00:06:26,080
authorization databases

00:06:23,199 --> 00:06:27,840
or services that are out of our control

00:06:26,080 --> 00:06:31,600
out of our

00:06:27,840 --> 00:06:31,600
software engineering's control

00:06:31,680 --> 00:06:35,840
so we're going to jump over now

00:06:36,160 --> 00:06:44,560
to some terminal so we could go

00:06:40,000 --> 00:06:44,560
i could show you how this is all set up

00:06:46,560 --> 00:06:55,360
let's see first i have

00:06:50,960 --> 00:06:55,360
nothing magic uh just a quick

00:06:55,599 --> 00:07:00,160
script to start the mini cube clusters i

00:06:58,960 --> 00:07:04,400
have a

00:07:00,160 --> 00:07:06,240
east and west cluster start and i have

00:07:04,400 --> 00:07:08,639
port ranges specified so we don't

00:07:06,240 --> 00:07:10,639
overlap port ranges on my laptop

00:07:08,639 --> 00:07:12,880
and we just do a basic install of link

00:07:10,639 --> 00:07:18,160
or d on both of those

00:07:12,880 --> 00:07:21,919
east and west clusters so we can see

00:07:18,160 --> 00:07:23,840
on my current context which is the west

00:07:21,919 --> 00:07:27,440
cluster

00:07:23,840 --> 00:07:30,479
we have lincoln stalled in west

00:07:27,440 --> 00:07:34,319
lincoln installed running from east

00:07:30,479 --> 00:07:37,280
and we have the applications that were

00:07:34,319 --> 00:07:37,280
in the diagram

00:07:37,680 --> 00:07:42,560
we have a simple service definition and

00:07:40,319 --> 00:07:46,400
deployment definition

00:07:42,560 --> 00:07:48,400
and the application is dependent via

00:07:46,400 --> 00:07:49,520
configuration and environment variables

00:07:48,400 --> 00:07:51,759
on

00:07:49,520 --> 00:07:54,560
three service running for services

00:07:51,759 --> 00:07:59,840
running in the west cluster

00:07:54,560 --> 00:07:59,840
0.4 is the ip for the west clusters

00:08:00,639 --> 00:08:06,400
ingress on my laptop 0.3 is for the east

00:08:04,000 --> 00:08:06,400
cluster

00:08:07,440 --> 00:08:13,360
i won't spend too much time looking at

00:08:10,560 --> 00:08:14,960
all of the definitions in the west

00:08:13,360 --> 00:08:18,400
cluster sensor there are a

00:08:14,960 --> 00:08:20,639
lot but demo service c which is

00:08:18,400 --> 00:08:23,039
back to the diagram demo service c which

00:08:20,639 --> 00:08:23,039
is the

00:08:23,599 --> 00:08:30,400
what the r the r box simulator right

00:08:26,800 --> 00:08:31,759
it depends on d and the two simple http

00:08:30,400 --> 00:08:35,039
bins

00:08:31,759 --> 00:08:36,880
here's that set up here the demo service

00:08:35,039 --> 00:08:38,560
c is down here

00:08:36,880 --> 00:08:40,240
the definition for the deployment for

00:08:38,560 --> 00:08:43,519
demo service d

00:08:40,240 --> 00:08:49,040
as one replica and a sim

00:08:43,519 --> 00:08:49,040
a injected delay of 200 milliseconds

00:08:53,040 --> 00:08:58,240
all right so to

00:08:56,240 --> 00:09:00,560
i just wrote another quick little script

00:08:58,240 --> 00:09:02,160
nothing fancy again just to

00:09:00,560 --> 00:09:05,760
make sure that i apply the right

00:09:02,160 --> 00:09:07,839
configuration to the right cluster

00:09:05,760 --> 00:09:09,120
i just run that and it will deploy those

00:09:07,839 --> 00:09:13,120
pods as

00:09:09,120 --> 00:09:13,120
needed so in the west cluster

00:09:14,480 --> 00:09:20,839
we have all the components

00:09:18,560 --> 00:09:22,080
in east we have the components and a

00:09:20,839 --> 00:09:23,680
quick

00:09:22,080 --> 00:09:25,360
i'm going to switch tabs one more time

00:09:23,680 --> 00:09:26,720
and

00:09:25,360 --> 00:09:29,360
quick test here just make sure it's

00:09:26,720 --> 00:09:33,839
still running yes so when i call

00:09:29,360 --> 00:09:36,080
0.3 i'm calling demo service x

00:09:33,839 --> 00:09:38,320
and that's then calling making calls to

00:09:36,080 --> 00:09:39,200
these three services and demo services

00:09:38,320 --> 00:09:42,399
calling

00:09:39,200 --> 00:09:45,920
these three services so that's the way

00:09:42,399 --> 00:09:45,920
that the traffic is flowing

00:09:46,560 --> 00:09:50,160
the load generator script like i

00:09:49,120 --> 00:09:51,760
mentioned earlier it's just going to

00:09:50,160 --> 00:09:56,959
ramp up quickly to 200

00:09:51,760 --> 00:09:56,959
virtual users calling demo service x

00:09:57,360 --> 00:10:00,480
do that right now

00:10:02,480 --> 00:10:06,079
while that's launching in another

00:10:05,040 --> 00:10:09,839
terminal over here

00:10:06,079 --> 00:10:12,800
i'm going to start my

00:10:09,839 --> 00:10:14,000
monitoring so i'm just doing quick

00:10:12,800 --> 00:10:17,360
simple port forwards

00:10:14,000 --> 00:10:21,200
to each cluster for the linker d web

00:10:17,360 --> 00:10:21,200
portal the dashboard

00:10:24,160 --> 00:10:29,760
then in this browser here i will launch

00:10:26,320 --> 00:10:29,760
this localhost ap

00:10:30,079 --> 00:10:33,760
not increase the font size because i'm

00:10:31,519 --> 00:10:39,279
not i don't want it to be

00:10:33,760 --> 00:10:39,279
too small localhost 8081.

00:10:40,000 --> 00:10:45,920
so we'll see here in

00:10:43,279 --> 00:10:47,839
in our deployments we have on the west

00:10:45,920 --> 00:10:51,360
cluster

00:10:47,839 --> 00:10:54,560
demo service abcd and

00:10:51,360 --> 00:10:58,160
in our east cluster demo service x

00:10:54,560 --> 00:11:00,640
already we're seeing p95 latencies of 28

00:10:58,160 --> 00:11:02,240
seconds so it's going bad already

00:11:00,640 --> 00:11:04,079
and this is what it was like once we

00:11:02,240 --> 00:11:05,760
sent out a thousand invites and then all

00:11:04,079 --> 00:11:08,160
of a sudden those thousand people

00:11:05,760 --> 00:11:09,680
or so decided to click on the link to

00:11:08,160 --> 00:11:14,640
start signing up for their

00:11:09,680 --> 00:11:16,079
their test scheduling their test

00:11:14,640 --> 00:11:18,399
all right so what i would like to do

00:11:16,079 --> 00:11:20,800
right now is

00:11:18,399 --> 00:11:22,240
show you the what we really used to see

00:11:20,800 --> 00:11:24,640
what was going on we

00:11:22,240 --> 00:11:26,320
we were big in the grafana dashboards

00:11:24,640 --> 00:11:29,839
that day watching performance of

00:11:26,320 --> 00:11:29,839
everything so let me just launch

00:11:30,640 --> 00:11:37,839
these two dashboards

00:11:33,920 --> 00:11:41,200
so here we have demo service x

00:11:37,839 --> 00:11:44,560
and we can see now we don't have a very

00:11:41,200 --> 00:11:44,560
high request per second

00:11:44,800 --> 00:11:48,720
but our latency is just terrible over

00:11:47,040 --> 00:11:51,600
here

00:11:48,720 --> 00:11:53,200
the success rate panel we seem to be

00:11:51,600 --> 00:11:56,240
okay

00:11:53,200 --> 00:11:58,320
in reality when we had our problems

00:11:56,240 --> 00:12:00,480
the success rate was not 100 the whole

00:11:58,320 --> 00:12:00,800
way across and our latency was terrible

00:12:00,480 --> 00:12:02,880
so

00:12:00,800 --> 00:12:07,040
we had a mix of you know the best of

00:12:02,880 --> 00:12:07,040
both worlds as far as failure was going

00:12:07,440 --> 00:12:11,519
the interesting thing is the reason we

00:12:10,079 --> 00:12:14,160
really wanted to

00:12:11,519 --> 00:12:16,160
share what we went through here is we

00:12:14,160 --> 00:12:17,040
could see in demo service x the outbound

00:12:16,160 --> 00:12:20,160
traffic had

00:12:17,040 --> 00:12:22,320
high latency so that was something that

00:12:20,160 --> 00:12:24,160
was would help us troubleshoot like oh

00:12:22,320 --> 00:12:25,600
okay so we have this terrible outbound

00:12:24,160 --> 00:12:27,200
latency

00:12:25,600 --> 00:12:28,720
but there's nothing down here in this

00:12:27,200 --> 00:12:30,399
dashboard telling us that we're

00:12:28,720 --> 00:12:33,600
connected to anything

00:12:30,399 --> 00:12:36,079
that's because we have dependent we

00:12:33,600 --> 00:12:37,680
have dependencies in another cluster

00:12:36,079 --> 00:12:39,600
this is

00:12:37,680 --> 00:12:42,800
the other cluster we're just connect to

00:12:39,600 --> 00:12:46,480
via simple ingress it's not a

00:12:42,800 --> 00:12:48,079
link or d multi-cluster and even then

00:12:46,480 --> 00:12:50,079
a few of us in the linker d community

00:12:48,079 --> 00:12:51,839
we're chatting currently

00:12:50,079 --> 00:12:54,639
or last time i checked there wasn't a

00:12:51,839 --> 00:12:57,839
way to aggregate metrics between

00:12:54,639 --> 00:13:00,880
multiple clusters prometheus to then

00:12:57,839 --> 00:13:04,160
render these other

00:13:00,880 --> 00:13:07,040
um out outbound deployment dependencies

00:13:04,160 --> 00:13:08,399
so in other words to have back to my

00:13:07,040 --> 00:13:10,800
diagram here

00:13:08,399 --> 00:13:12,399
to have the metrics linkedin metrics for

00:13:10,800 --> 00:13:14,160
service x

00:13:12,399 --> 00:13:15,440
and service a and service b and sort of

00:13:14,160 --> 00:13:18,399
see in this

00:13:15,440 --> 00:13:19,360
separate cluster all in one dashboard

00:13:18,399 --> 00:13:22,399
that

00:13:19,360 --> 00:13:23,360
that's something we would love to see in

00:13:22,399 --> 00:13:24,800
the future and

00:13:23,360 --> 00:13:26,959
maybe we'll try to figure it out another

00:13:24,800 --> 00:13:26,959
day

00:13:27,360 --> 00:13:31,760
so we this is what gave us our first

00:13:29,839 --> 00:13:33,600
indication that

00:13:31,760 --> 00:13:35,600
it must be happening on-prem so whatever

00:13:33,600 --> 00:13:37,279
we're talking to

00:13:35,600 --> 00:13:39,440
in our other cluster must be the problem

00:13:37,279 --> 00:13:41,040
so we jumped into the linker d

00:13:39,440 --> 00:13:43,040
just like here we had a separate linker

00:13:41,040 --> 00:13:48,079
d dashboard and separate

00:13:43,040 --> 00:13:49,519
grafana dashboards to dig into um

00:13:48,079 --> 00:13:50,959
you know we started poking around

00:13:49,519 --> 00:13:52,880
looking at all the different services

00:13:50,959 --> 00:13:54,880
that

00:13:52,880 --> 00:13:56,079
our service x was dependent on and we

00:13:54,880 --> 00:13:59,440
could see like

00:13:56,079 --> 00:14:00,000
oh these are all failing miserably you

00:13:59,440 --> 00:14:02,880
know

00:14:00,000 --> 00:14:03,680
latency is really high and then of

00:14:02,880 --> 00:14:06,959
course we check

00:14:03,680 --> 00:14:08,959
service c or demo servicing because it's

00:14:06,959 --> 00:14:12,480
our box system we check it

00:14:08,959 --> 00:14:15,040
you know usually first and we saw that

00:14:12,480 --> 00:14:19,040
it had terrible latency

00:14:15,040 --> 00:14:22,399
down here we would have seen

00:14:19,040 --> 00:14:25,680
our dependent services for service c

00:14:22,399 --> 00:14:27,440
and that well this service call was okay

00:14:25,680 --> 00:14:29,760
this service call was okay but it was

00:14:27,440 --> 00:14:32,560
really this one to demo service d

00:14:29,760 --> 00:14:32,560
that was the problem

00:14:33,600 --> 00:14:37,120
so if we go to demo service d we see

00:14:36,000 --> 00:14:40,639
that

00:14:37,120 --> 00:14:44,800
oh this thing is just you know it has

00:14:40,639 --> 00:14:49,199
no outbound traffic it's super latent

00:14:44,800 --> 00:14:49,199
um so of course the first thing we did

00:14:49,440 --> 00:14:53,120
is we just scaled that guy up i have to

00:14:52,000 --> 00:14:55,839
restart my

00:14:53,120 --> 00:14:55,839
load test but

00:14:56,639 --> 00:15:02,399
wrong terminal so we're going to go to

00:14:59,600 --> 00:15:02,399
demo service d

00:15:03,279 --> 00:15:06,880
and we're going to scale him up because

00:15:05,440 --> 00:15:10,399
well maybe he's

00:15:06,880 --> 00:15:10,399
a single threaded app and he just

00:15:10,720 --> 00:15:15,760
needs some more replicas so we're going

00:15:12,959 --> 00:15:15,760
to apply that

00:15:18,320 --> 00:15:21,680
this should be the west cluster

00:15:22,079 --> 00:15:28,800
starting up right now and we're going to

00:15:25,680 --> 00:15:28,800
restart that load test

00:15:34,720 --> 00:15:38,000
so it's going to ramp up pretty hard

00:15:36,160 --> 00:15:41,680
here

00:15:38,000 --> 00:15:43,920
we'll watch we'll watch the demo service

00:15:41,680 --> 00:15:43,920
x

00:15:44,320 --> 00:15:49,279
to see what kind of picture we get here

00:15:47,600 --> 00:15:55,839
i'm going to change the refresh rate

00:15:49,279 --> 00:15:55,839
to 30 seconds on these

00:15:58,800 --> 00:16:04,800
apologize for the pop-ups it seems like

00:16:00,639 --> 00:16:04,800
you can't uh actually stop everything

00:16:06,079 --> 00:16:09,440
so we're at 54 simulated users and it's

00:16:08,720 --> 00:16:11,839
going and going

00:16:09,440 --> 00:16:11,839
going

00:16:13,920 --> 00:16:19,839
so we can see here our latencies were

00:16:17,440 --> 00:16:21,759
you know pegged at 50 seconds but in

00:16:19,839 --> 00:16:23,120
reality if we go back to the load test

00:16:21,759 --> 00:16:25,440
screen

00:16:23,120 --> 00:16:27,920
well it's not letting me scroll up right

00:16:25,440 --> 00:16:27,920
now

00:16:28,079 --> 00:16:33,360
we had failed requests coming from the

00:16:30,079 --> 00:16:35,759
load test tool

00:16:33,360 --> 00:16:38,079
where we you know just having timeouts

00:16:35,759 --> 00:16:39,680
and they were probably

00:16:38,079 --> 00:16:41,440
exactly the type of thing that the

00:16:39,680 --> 00:16:42,880
students were feeling

00:16:41,440 --> 00:16:45,279
when they were trying to schedule their

00:16:42,880 --> 00:16:49,519
cl uh sketch their classes

00:16:45,279 --> 00:16:50,800
their tests let's go back here let's see

00:16:49,519 --> 00:16:53,759
refresh one more time

00:16:50,800 --> 00:16:55,600
well we have a 20 second p90 what's that

00:16:53,759 --> 00:16:58,240
p95

00:16:55,600 --> 00:17:00,399
yeah p99 p95 or both 20 seconds right

00:16:58,240 --> 00:17:00,399
now

00:17:00,480 --> 00:17:07,760
so so far it is better

00:17:05,199 --> 00:17:08,400
we can see over here that demo service d

00:17:07,760 --> 00:17:11,919
its

00:17:08,400 --> 00:17:15,199
latency is better but again

00:17:11,919 --> 00:17:17,439
still 10 seconds is not ideal

00:17:15,199 --> 00:17:18,240
whatsoever since everything depends on

00:17:17,439 --> 00:17:21,199
service c

00:17:18,240 --> 00:17:21,839
and service c depends on service d which

00:17:21,199 --> 00:17:24,799
has

00:17:21,839 --> 00:17:24,799
this latency problem

00:17:29,360 --> 00:17:33,520
so in while this was happening while we

00:17:31,679 --> 00:17:35,120
were trying to scale out components and

00:17:33,520 --> 00:17:35,840
we were staring at these graphs trying

00:17:35,120 --> 00:17:38,720
to understand

00:17:35,840 --> 00:17:38,720
what was happening

00:17:39,120 --> 00:17:43,679
uh all that kind of good stuff we had

00:17:42,080 --> 00:17:45,679
one of our

00:17:43,679 --> 00:17:46,880
or maybe a few of our other teammates

00:17:45,679 --> 00:17:50,240
looking at the

00:17:46,880 --> 00:17:54,160
code of service c

00:17:50,240 --> 00:17:54,160
to determine if there was any

00:17:54,960 --> 00:18:02,080
inefficient logic in the application

00:17:58,640 --> 00:18:05,200
and it turned out there was so we

00:18:02,080 --> 00:18:05,440
we were constantly checking demo service

00:18:05,200 --> 00:18:07,280
d

00:18:05,440 --> 00:18:10,960
with every request that came from the

00:18:07,280 --> 00:18:10,960
user here all the way through

00:18:11,120 --> 00:18:15,840
well it turns out we didn't need to do

00:18:12,799 --> 00:18:15,840
that check it was

00:18:16,640 --> 00:18:19,679
i won't go into the details about why it

00:18:19,360 --> 00:18:21,120
was

00:18:19,679 --> 00:18:22,720
the check was there and why it's no

00:18:21,120 --> 00:18:25,120
longer important but

00:18:22,720 --> 00:18:27,200
the moral of the story is it helped us

00:18:25,120 --> 00:18:30,400
understand that we had this extra code

00:18:27,200 --> 00:18:31,120
in demo service c checking d for no good

00:18:30,400 --> 00:18:33,840
reason

00:18:31,120 --> 00:18:35,679
and demo service d ended up being a

00:18:33,840 --> 00:18:38,799
service that was

00:18:35,679 --> 00:18:40,640
single threaded and wasn't meant to

00:18:38,799 --> 00:18:43,440
handle this type of load and it was also

00:18:40,640 --> 00:18:46,000
out of our control

00:18:43,440 --> 00:18:47,039
so our load test is currently scaling

00:18:46,000 --> 00:18:50,480
down i believe

00:18:47,039 --> 00:18:53,039
yes it is and let's see what our

00:18:50,480 --> 00:18:55,120
pictures look like from that last run

00:18:53,039 --> 00:18:58,080
now see it's still crept up to a 40

00:18:55,120 --> 00:18:58,080
second response time

00:18:59,280 --> 00:19:03,760
however we didn't have any failures this

00:19:02,480 --> 00:19:05,520
time

00:19:03,760 --> 00:19:06,960
so you know from a user point of view

00:19:05,520 --> 00:19:08,640
you waited for 40 seconds and that's

00:19:06,960 --> 00:19:11,840
totally unacceptable

00:19:08,640 --> 00:19:15,360
however we didn't have any timeouts

00:19:11,840 --> 00:19:15,360
so i'm going to make one more change

00:19:15,679 --> 00:19:21,280
we modified the code and i'll just turn

00:19:19,120 --> 00:19:23,520
this back down to

00:19:21,280 --> 00:19:24,880
one replica because we don't need it we

00:19:23,520 --> 00:19:28,400
modified the code

00:19:24,880 --> 00:19:30,799
to not depend on demo service d

00:19:28,400 --> 00:19:30,799
anymore

00:19:33,919 --> 00:19:41,360
apply that

00:19:38,480 --> 00:19:41,360
check the pods

00:19:42,400 --> 00:19:50,240
rest and i apologize i've been doing

00:19:46,720 --> 00:19:53,360
um aliases this whole time

00:19:50,240 --> 00:19:57,840
so all kgpo is

00:19:53,360 --> 00:19:57,840
is two control git pods

00:19:59,520 --> 00:20:04,159
once this guy's ready to go is all right

00:20:02,720 --> 00:20:07,840
we're gonna run this load test

00:20:04,159 --> 00:20:07,840
one last time

00:20:08,320 --> 00:20:12,640
well i tell one little one last little

00:20:11,039 --> 00:20:14,400
story about how this went so

00:20:12,640 --> 00:20:16,640
the way this happened in real life it

00:20:14,400 --> 00:20:16,640
was

00:20:16,799 --> 00:20:20,000
there weren't breaks like they're

00:20:19,120 --> 00:20:22,080
happening with my

00:20:20,000 --> 00:20:24,240
load testing right this was just

00:20:22,080 --> 00:20:27,360
constant load and constant users

00:20:24,240 --> 00:20:29,440
and a team of us frantically trying to

00:20:27,360 --> 00:20:31,919
figure out what was happening

00:20:29,440 --> 00:20:32,559
and uh you know lots of lots of stress

00:20:31,919 --> 00:20:37,200
and worry

00:20:32,559 --> 00:20:41,120
and all that kind of good stuff um we

00:20:37,200 --> 00:20:44,159
if we didn't have these pictures these

00:20:41,120 --> 00:20:46,799
that dashboards that linker d has

00:20:44,159 --> 00:20:47,679
pre pre-made for us right this is all

00:20:46,799 --> 00:20:51,360
out of the can

00:20:47,679 --> 00:20:54,080
i showed a little bit ago the uh

00:20:51,360 --> 00:20:55,440
the installation of linkedin was default

00:20:54,080 --> 00:20:58,400
all custom

00:20:55,440 --> 00:21:00,000
all right no custom configuration at all

00:20:58,400 --> 00:21:01,919
i mean without these

00:21:00,000 --> 00:21:03,679
metrics that the linker de systems

00:21:01,919 --> 00:21:06,880
giving us we would

00:21:03,679 --> 00:21:08,799
we would have been in trouble for a much

00:21:06,880 --> 00:21:10,960
longer period of time i'm sure we would

00:21:08,799 --> 00:21:14,400
have figured it out eventually

00:21:10,960 --> 00:21:15,520
by you know looking at metrics coming

00:21:14,400 --> 00:21:18,640
out of

00:21:15,520 --> 00:21:19,679
ingress logs or something like that but

00:21:18,640 --> 00:21:23,600
because we had

00:21:19,679 --> 00:21:24,960
linker d and what it gives us

00:21:23,600 --> 00:21:26,720
out of the box we were able to

00:21:24,960 --> 00:21:28,840
troubleshoot fairly quickly where the

00:21:26,720 --> 00:21:31,039
bottleneck was because of the latency

00:21:28,840 --> 00:21:33,760
graph and

00:21:31,039 --> 00:21:35,440
the outbound traffic latency to kind of

00:21:33,760 --> 00:21:37,600
tell us hey this is

00:21:35,440 --> 00:21:39,919
upstream or downstream depending on how

00:21:37,600 --> 00:21:43,120
you tell your stories

00:21:39,919 --> 00:21:44,880
um we'll see here demo service d now has

00:21:43,120 --> 00:21:47,280
no traffic

00:21:44,880 --> 00:21:48,880
because i turned it off the call for it

00:21:47,280 --> 00:21:54,559
so here's demo service c

00:21:48,880 --> 00:21:54,559
again demo service c our rbox service

00:21:54,640 --> 00:22:00,799
it's now its latency is super low now

00:21:58,960 --> 00:22:02,880
because it's no longer dependent on that

00:22:00,799 --> 00:22:04,559
problem service

00:22:02,880 --> 00:22:06,480
and this is the same type of experience

00:22:04,559 --> 00:22:09,360
we had that day

00:22:06,480 --> 00:22:10,720
we got rid of that extra check and all

00:22:09,360 --> 00:22:12,080
of a sudden everything just started

00:22:10,720 --> 00:22:13,440
zooming right along and we were

00:22:12,080 --> 00:22:16,000
able to get through the rest of our

00:22:13,440 --> 00:22:19,280
testing in a reasonable

00:22:16,000 --> 00:22:22,960
amount of time are testing our

00:22:19,280 --> 00:22:22,960
invites to schedule the testing

00:22:24,159 --> 00:22:28,640
this load test is almost done why don't

00:22:27,120 --> 00:22:32,720
we just wait

00:22:28,640 --> 00:22:35,520
to see it complete um

00:22:32,720 --> 00:22:36,960
there we go so this is demo service x

00:22:35,520 --> 00:22:39,280
our top level service

00:22:36,960 --> 00:22:40,640
that the user's browser is directly

00:22:39,280 --> 00:22:44,080
connecting to

00:22:40,640 --> 00:22:45,919
we can see our latency now is much much

00:22:44,080 --> 00:22:48,480
lower in a much

00:22:45,919 --> 00:22:50,799
more reasonable range in fact our p99 is

00:22:48,480 --> 00:22:54,159
two seconds

00:22:50,799 --> 00:22:56,159
which is

00:22:54,159 --> 00:22:58,880
i would say well compared to 60 seconds

00:22:56,159 --> 00:22:58,880
it's super good

00:23:00,000 --> 00:23:04,000
i'm looking at my low test app here in

00:23:03,120 --> 00:23:05,360
the background

00:23:04,000 --> 00:23:07,200
seeing that we're still scaling up to

00:23:05,360 --> 00:23:09,679
200 users so why don't we let it go the

00:23:07,200 --> 00:23:14,559
whole way before we

00:23:09,679 --> 00:23:16,320
end the demo part of our presentation

00:23:14,559 --> 00:23:19,280
plus it's always fun to see what happens

00:23:16,320 --> 00:23:21,840
if you let it run long enough maybe

00:23:19,280 --> 00:23:25,440
my operating or my laptop or out of

00:23:21,840 --> 00:23:25,440
resources but we're scaling down

00:23:26,080 --> 00:23:30,480
so just to zoom in on this time frame

00:23:30,799 --> 00:23:37,600
we can see that our p99 was

00:23:34,640 --> 00:23:38,559
at two seconds or 95 was even lower so

00:23:37,600 --> 00:23:41,200
this is

00:23:38,559 --> 00:23:42,880
much more acceptable as far as you know

00:23:41,200 --> 00:23:45,919
real time feel for the

00:23:42,880 --> 00:23:49,120
human and and trying to schedule

00:23:45,919 --> 00:23:49,120
uh schedule their testing

00:23:49,200 --> 00:23:52,480
all right with that we'll move on

00:23:52,640 --> 00:23:55,840
in in summary without the visibility

00:23:54,559 --> 00:23:58,400
that linker d was giving us

00:23:55,840 --> 00:23:59,440
we would we would still be no not

00:23:58,400 --> 00:24:01,039
literally but we would have been

00:23:59,440 --> 00:24:03,919
troubleshooting that

00:24:01,039 --> 00:24:04,400
problem for hours trying to dig down to

00:24:03,919 --> 00:24:06,080
where

00:24:04,400 --> 00:24:08,159
the real performance bottleneck was and

00:24:06,080 --> 00:24:10,480
everything um

00:24:08,159 --> 00:24:12,000
and as i mentioned in a demo there was

00:24:10,480 --> 00:24:13,279
the ability to do multi-cluster

00:24:12,000 --> 00:24:15,440
performance

00:24:13,279 --> 00:24:16,640
metrics and visualization that would

00:24:15,440 --> 00:24:19,120
have been even

00:24:16,640 --> 00:24:21,360
better and faster because what i did in

00:24:19,120 --> 00:24:24,720
you know 15 20 minutes

00:24:21,360 --> 00:24:25,679
we spent a long time just figuring out

00:24:24,720 --> 00:24:27,760
where

00:24:25,679 --> 00:24:29,039
where to dig and i just kind of zoomed

00:24:27,760 --> 00:24:32,960
through the solution

00:24:29,039 --> 00:24:34,400
all in all in the demo

00:24:32,960 --> 00:24:36,799
with that i'd like to thank everybody

00:24:34,400 --> 00:24:40,320
for watching

00:24:36,799 --> 00:24:40,320

YouTube URL: https://www.youtube.com/watch?v=dDW1OoTaMdU


