Title: Confident Canary Deployment to Production With Istio - Raju Dawadi, Oyster
Publication date: 2020-11-25
Playlist: ServiceMeshCon North America 2020
Description: 
	Confident Canary Deployment to Production With Istio - Raju Dawadi, Oyster

The session covers covers the production use case of Oyster Financial on using Istio service mesh for handling traffic. The testing in non-production environment and rolling out to live users was not effective for fintech product where the usage is critical. Also, due to the inconsistent in third party, there was need to test traffic in live environment for internal user and that has to be for selective or all services.  The usage of Istio feature on routing traffic based on header as well as percentage rollout was used effectively which has made deployment to Prod0 seamless. Also measuring the performance as well as real use case test of newer version helped in providing a good end user experience for evolving fintech startup in Mexico.  But the management complexity rises when number of services increases and there are too may configs to be managed. Combination of helm helped a lot throughout the process.
Captions: 
	00:00:00,000 --> 00:00:03,520
hello everyone thank you for attending

00:00:01,680 --> 00:00:05,600
this lightning session on confident

00:00:03,520 --> 00:00:08,000
canary deployment uh to production

00:00:05,600 --> 00:00:10,320
with stu uh today i will be sharing a

00:00:08,000 --> 00:00:12,080
casey study or the use case of uh

00:00:10,320 --> 00:00:13,599
using the stu service base at our

00:00:12,080 --> 00:00:16,560
financial uh

00:00:13,599 --> 00:00:18,800
platform austral financial so i am raju

00:00:16,560 --> 00:00:20,240
davardi uh cycling iit engineer at

00:00:18,800 --> 00:00:22,160
oyster financial

00:00:20,240 --> 00:00:23,519
and a google developer expert in uh

00:00:22,160 --> 00:00:26,160
cloud as well as building

00:00:23,519 --> 00:00:28,080
a devops and the community community in

00:00:26,160 --> 00:00:31,279
kathmandu

00:00:28,080 --> 00:00:33,200
so talking about briefly on uh oyster

00:00:31,279 --> 00:00:35,200
financial so we had a mexico-based

00:00:33,200 --> 00:00:36,480
fintech startup which is mostly targeted

00:00:35,200 --> 00:00:38,879
for the freelancers

00:00:36,480 --> 00:00:39,600
startups and small and medium-sized

00:00:38,879 --> 00:00:41,520
businesses

00:00:39,600 --> 00:00:42,719
so that they will get a banking account

00:00:41,520 --> 00:00:44,879
and a debit card

00:00:42,719 --> 00:00:47,200
ah within few days and we recently

00:00:44,879 --> 00:00:48,879
raised a lot of street down in latin

00:00:47,200 --> 00:00:50,559
america

00:00:48,879 --> 00:00:52,399
and were distributed in multiple time

00:00:50,559 --> 00:00:55,680
zones of u.s mexico

00:00:52,399 --> 00:00:59,039
or nepal and india and we are a mobile

00:00:55,680 --> 00:01:02,320
first application platform so starting

00:00:59,039 --> 00:01:04,720
from the early days it was uh late 2018

00:01:02,320 --> 00:01:06,000
uh we started with five services how's

00:01:04,720 --> 00:01:09,280
it going up to 80

00:01:06,000 --> 00:01:10,159
in uh in the span of uh mode of one and

00:01:09,280 --> 00:01:13,439
a half years

00:01:10,159 --> 00:01:15,280
with both grpc and the uh http services

00:01:13,439 --> 00:01:16,400
and from the early days from the day one

00:01:15,280 --> 00:01:19,520
we started adopting

00:01:16,400 --> 00:01:22,720
ht services who said a lot

00:01:19,520 --> 00:01:24,000
for managing uh the traffic routes

00:01:22,720 --> 00:01:26,799
between those applications

00:01:24,000 --> 00:01:27,680
keeping us our cluster and the services

00:01:26,799 --> 00:01:29,920
secure

00:01:27,680 --> 00:01:31,920
uh communication between them using the

00:01:29,920 --> 00:01:33,759
mtls or the address gateways

00:01:31,920 --> 00:01:34,960
invest gateways and also with the

00:01:33,759 --> 00:01:37,119
integration of

00:01:34,960 --> 00:01:38,240
application load balancer of aws how we

00:01:37,119 --> 00:01:41,040
gained

00:01:38,240 --> 00:01:43,360
more security in terms of the firewall

00:01:41,040 --> 00:01:43,360
as well

00:01:44,159 --> 00:01:48,560
so talking about the deployment and the

00:01:46,640 --> 00:01:51,040
releases uh we created a new

00:01:48,560 --> 00:01:52,880
we triggered a new build of the docker

00:01:51,040 --> 00:01:55,280
image when you create a new

00:01:52,880 --> 00:01:57,680
git tag and all any of those services

00:01:55,280 --> 00:01:59,840
whether it be grpc or the sgp

00:01:57,680 --> 00:02:00,960
are run inside the istio service mess

00:01:59,840 --> 00:02:03,520
and there are multiple

00:02:00,960 --> 00:02:05,439
naming spaces for managing each of the

00:02:03,520 --> 00:02:07,280
tenant of those applications

00:02:05,439 --> 00:02:09,440
but they can communicate but we still

00:02:07,280 --> 00:02:12,480
keep it secure by using

00:02:09,440 --> 00:02:14,720
uh the policies uh between them and a

00:02:12,480 --> 00:02:16,319
very good health section mechanism for

00:02:14,720 --> 00:02:17,920
taking the liveness and the readiness

00:02:16,319 --> 00:02:19,920
props and uh

00:02:17,920 --> 00:02:22,239
there are two cases like for serving the

00:02:19,920 --> 00:02:24,400
internal users and for the

00:02:22,239 --> 00:02:26,480
live users uh for getting us more

00:02:24,400 --> 00:02:29,760
confident during the release time

00:02:26,480 --> 00:02:33,599
and for that in the early days we built

00:02:29,760 --> 00:02:35,280
two stacks of our application the live

00:02:33,599 --> 00:02:37,360
one for the live users which is called

00:02:35,280 --> 00:02:38,720
green and another one for the internal

00:02:37,360 --> 00:02:41,280
users which is

00:02:38,720 --> 00:02:42,160
called gray so that means uh we had two

00:02:41,280 --> 00:02:44,480
instance of

00:02:42,160 --> 00:02:45,920
the same service one for the live users

00:02:44,480 --> 00:02:49,040
and another for the

00:02:45,920 --> 00:02:52,160
internal users the green and the gray

00:02:49,040 --> 00:02:53,360
that was not a quite of uh solving

00:02:52,160 --> 00:02:56,160
things for us

00:02:53,360 --> 00:02:57,440
because we had to run two stacks of our

00:02:56,160 --> 00:03:00,159
application that was not only the

00:02:57,440 --> 00:03:02,000
resource consuming but also we felt like

00:03:00,159 --> 00:03:03,840
uh we are dealing with the mine on this

00:03:02,000 --> 00:03:05,599
way and though we're following the micro

00:03:03,840 --> 00:03:08,959
service architecture and

00:03:05,599 --> 00:03:12,080
uh even by testing in uh

00:03:08,959 --> 00:03:13,840
in the gray segment that didn't give us

00:03:12,080 --> 00:03:16,720
more confidence for releasing to the

00:03:13,840 --> 00:03:17,440
live users so and also it felt like

00:03:16,720 --> 00:03:20,000
we're using

00:03:17,440 --> 00:03:21,760
a kind of staging environment like it

00:03:20,000 --> 00:03:23,760
would have been better if we can

00:03:21,760 --> 00:03:25,440
plug in any of the new service to the

00:03:23,760 --> 00:03:28,720
green environment so for

00:03:25,440 --> 00:03:30,480
that we started uh applying the studio

00:03:28,720 --> 00:03:32,879
virtual service routing

00:03:30,480 --> 00:03:35,280
based on header headers that before

00:03:32,879 --> 00:03:36,400
releasing the app to the green users or

00:03:35,280 --> 00:03:39,760
the live users

00:03:36,400 --> 00:03:40,560
then the internal user can test a rest

00:03:39,760 --> 00:03:42,000
of the version

00:03:40,560 --> 00:03:43,760
rest of the green version of the

00:03:42,000 --> 00:03:46,000
services but can also

00:03:43,760 --> 00:03:47,280
use the specific gray version so in this

00:03:46,000 --> 00:03:50,400
case we can see

00:03:47,280 --> 00:03:52,159
uh the internal user can test the gray

00:03:50,400 --> 00:03:53,760
version of the user service along with

00:03:52,159 --> 00:03:56,319
the green version of the rest of the

00:03:53,760 --> 00:03:57,760
services so we can directly plug in

00:03:56,319 --> 00:03:59,840
any of the test version of our

00:03:57,760 --> 00:04:00,720
application without impacting the live

00:03:59,840 --> 00:04:02,959
users and

00:04:00,720 --> 00:04:04,799
when we are confident then we release

00:04:02,959 --> 00:04:05,280
that and also further the integration of

00:04:04,799 --> 00:04:08,720
the

00:04:05,280 --> 00:04:11,120
uh third parties or our partners uh

00:04:08,720 --> 00:04:13,120
that used to work mostly with the dive

00:04:11,120 --> 00:04:16,160
and the staging environment but

00:04:13,120 --> 00:04:20,160
uh but that was not too expected

00:04:16,160 --> 00:04:21,680
uh for uh in that way to run inside the

00:04:20,160 --> 00:04:22,479
production environment so we have to

00:04:21,680 --> 00:04:25,520
deal

00:04:22,479 --> 00:04:27,680
uh do a lot of digging uh to get the

00:04:25,520 --> 00:04:28,560
proper response from the third parties

00:04:27,680 --> 00:04:31,919
or the partners

00:04:28,560 --> 00:04:32,720
so in that scenario also by testing the

00:04:31,919 --> 00:04:34,880
endpoints

00:04:32,720 --> 00:04:36,240
for the internal users before reaching

00:04:34,880 --> 00:04:39,360
to the live users

00:04:36,240 --> 00:04:42,639
that give us very much flexibility and

00:04:39,360 --> 00:04:44,400
confidence in us so for that uh we use

00:04:42,639 --> 00:04:46,000
the history routing rule of the virtual

00:04:44,400 --> 00:04:48,240
service and the destination rule

00:04:46,000 --> 00:04:50,240
the personal service basically uh with

00:04:48,240 --> 00:04:52,720
the mobile app sending the header

00:04:50,240 --> 00:04:53,360
so in this case the tenant have gray b1

00:04:52,720 --> 00:04:55,600
so

00:04:53,360 --> 00:04:58,000
the header will be sent from the mobile

00:04:55,600 --> 00:05:00,960
to the api and to all of the

00:04:58,000 --> 00:05:03,360
services and based on that the routing

00:05:00,960 --> 00:05:05,520
will be done with that to be sent to

00:05:03,360 --> 00:05:07,280
the gray version or the green version

00:05:05,520 --> 00:05:09,520
and for the destination rule

00:05:07,280 --> 00:05:10,720
we have the two deployment with a

00:05:09,520 --> 00:05:13,360
different level

00:05:10,720 --> 00:05:14,080
with the instance uh that will separate

00:05:13,360 --> 00:05:15,919
uh

00:05:14,080 --> 00:05:18,800
that would be the green or the great

00:05:15,919 --> 00:05:18,800
release of the app

00:05:18,960 --> 00:05:22,320
so when the internal user do the testing

00:05:21,280 --> 00:05:24,479
and we're really

00:05:22,320 --> 00:05:25,600
good to go we generally release the

00:05:24,479 --> 00:05:28,560
version to

00:05:25,600 --> 00:05:29,039
all of the uh to all of the live users

00:05:28,560 --> 00:05:32,880
but

00:05:29,039 --> 00:05:34,400
we split the traffic to 30 70 or 25 75

00:05:32,880 --> 00:05:37,759
percent and we gradually

00:05:34,400 --> 00:05:39,680
roll out to rest of the users

00:05:37,759 --> 00:05:41,520
based on the error rates and all of the

00:05:39,680 --> 00:05:42,400
and the monitoring metrics as well as

00:05:41,520 --> 00:05:44,240
our own

00:05:42,400 --> 00:05:46,160
uh golden signals or some business

00:05:44,240 --> 00:05:47,919
metrics

00:05:46,160 --> 00:05:49,360
so for that also the virtual service

00:05:47,919 --> 00:05:50,639
with the integration or the user

00:05:49,360 --> 00:05:53,039
combination of the header

00:05:50,639 --> 00:05:54,320
logic as well as uh the way it is of the

00:05:53,039 --> 00:05:57,440
traffic to be splitted

00:05:54,320 --> 00:06:00,160
and that uh that helped us uh

00:05:57,440 --> 00:06:01,520
for for not releasing the whole of the

00:06:00,160 --> 00:06:02,240
stack of the application or the full

00:06:01,520 --> 00:06:06,800
version of

00:06:02,240 --> 00:06:09,600
the application to all sets of the users

00:06:06,800 --> 00:06:11,440
so during uh this transformation we

00:06:09,600 --> 00:06:14,319
faced few of the challenges

00:06:11,440 --> 00:06:15,199
because the header has to be sent from

00:06:14,319 --> 00:06:17,120
the mobile

00:06:15,199 --> 00:06:19,199
to the api and to rest of all of the

00:06:17,120 --> 00:06:22,319
services but in some cases

00:06:19,199 --> 00:06:24,880
while doing the grpc call in some of the

00:06:22,319 --> 00:06:26,080
asynchronous calls some services didn't

00:06:24,880 --> 00:06:28,479
send the header

00:06:26,080 --> 00:06:29,840
uh to that service and we handled that

00:06:28,479 --> 00:06:32,639
very nicely

00:06:29,840 --> 00:06:33,680
and we started adopting the event-based

00:06:32,639 --> 00:06:36,080
services

00:06:33,680 --> 00:06:38,400
so let's say if one of the service has

00:06:36,080 --> 00:06:40,000
to subscribe to kafka topic or publish

00:06:38,400 --> 00:06:42,319
to kafka topic then

00:06:40,000 --> 00:06:43,600
uh if that has to be rolled out to the

00:06:42,319 --> 00:06:46,960
grave segment

00:06:43,600 --> 00:06:49,599
then we started creating two

00:06:46,960 --> 00:06:50,639
topic for uh for the one purpose one for

00:06:49,599 --> 00:06:53,599
the green and

00:06:50,639 --> 00:06:55,360
one for the great topic so that the grey

00:06:53,599 --> 00:06:58,080
person of the service will

00:06:55,360 --> 00:06:59,039
listen or subscribe to the grey topic

00:06:58,080 --> 00:07:02,240
and another uh

00:06:59,039 --> 00:07:04,080
to the green so also let's say

00:07:02,240 --> 00:07:05,919
there was a case like uh the gray

00:07:04,080 --> 00:07:07,199
version of the event-based service has

00:07:05,919 --> 00:07:09,440
to call to

00:07:07,199 --> 00:07:12,479
uh the grade or the green version of

00:07:09,440 --> 00:07:14,479
another service so in that case

00:07:12,479 --> 00:07:16,479
the event-based service inject the

00:07:14,479 --> 00:07:18,160
header based on the environment variable

00:07:16,479 --> 00:07:20,639
presenting it

00:07:18,160 --> 00:07:21,360
also the syncing with the mobile app

00:07:20,639 --> 00:07:23,360
team because

00:07:21,360 --> 00:07:24,479
uh the mobile has to say in the header

00:07:23,360 --> 00:07:27,039
and we need to be see

00:07:24,479 --> 00:07:28,800
in sync with the mobile app development

00:07:27,039 --> 00:07:30,639
team as well as the backend development

00:07:28,800 --> 00:07:32,800
and the operations so for that

00:07:30,639 --> 00:07:34,080
uh we started keeping all of the

00:07:32,800 --> 00:07:36,800
configuration to

00:07:34,080 --> 00:07:37,919
uh the version control so that we all

00:07:36,800 --> 00:07:40,639
were in a very

00:07:37,919 --> 00:07:42,240
good sync and for gaining the extra

00:07:40,639 --> 00:07:45,039
confidence

00:07:42,240 --> 00:07:46,000
we made a very good use of uh kiyali

00:07:45,039 --> 00:07:49,039
which is

00:07:46,000 --> 00:07:52,240
uh present as a add-on in istio

00:07:49,039 --> 00:07:55,120
as well as jager and uh prometheus uh

00:07:52,240 --> 00:07:55,520
so with the use of chiali uh we are able

00:07:55,120 --> 00:07:58,720
to

00:07:55,520 --> 00:07:59,599
scan our companies if they are outdated

00:07:58,720 --> 00:08:01,520
or

00:07:59,599 --> 00:08:03,360
if they are not good or if there is any

00:08:01,520 --> 00:08:04,160
problem in those configuration and also

00:08:03,360 --> 00:08:06,319
the routing

00:08:04,160 --> 00:08:08,160
uh things like how we services calling

00:08:06,319 --> 00:08:11,520
the we service and what is the

00:08:08,160 --> 00:08:13,599
uh latency what is the all of those

00:08:11,520 --> 00:08:15,120
traffic handling between those services

00:08:13,599 --> 00:08:18,240
though that is for a small

00:08:15,120 --> 00:08:19,440
duration of the time uh uh offered by

00:08:18,240 --> 00:08:22,160
the kiali

00:08:19,440 --> 00:08:22,879
uh and also for uh keeping traces of our

00:08:22,160 --> 00:08:26,319
application

00:08:22,879 --> 00:08:26,720
we used jaeger and by using the jaeger

00:08:26,319 --> 00:08:28,639
of

00:08:26,720 --> 00:08:30,800
as is to add on we didn't have to

00:08:28,639 --> 00:08:32,399
implement uh

00:08:30,800 --> 00:08:34,159
does all of those stress inclined to

00:08:32,399 --> 00:08:37,680
each of our micro services which are

00:08:34,159 --> 00:08:40,719
very very good overhead

00:08:37,680 --> 00:08:43,360
and so that that took us uh

00:08:40,719 --> 00:08:44,000
uh that would took us a lot of

00:08:43,360 --> 00:08:47,760
engineering

00:08:44,000 --> 00:08:51,040
resource also the time and resource both

00:08:47,760 --> 00:08:53,839
so and for the monitoring part uh

00:08:51,040 --> 00:08:55,120
we built a central monitoring dashboard

00:08:53,839 --> 00:08:57,360
with a

00:08:55,120 --> 00:08:58,480
use the of graphene and pulling the

00:08:57,360 --> 00:09:01,440
prometheus metric

00:08:58,480 --> 00:09:03,360
from the cluster yourself but also from

00:09:01,440 --> 00:09:04,800
the service mesh or from the seo service

00:09:03,360 --> 00:09:08,800
mesh

00:09:04,800 --> 00:09:11,839
and by setting the uh by setting

00:09:08,800 --> 00:09:12,560
uh the threshold of the uh of the

00:09:11,839 --> 00:09:15,519
monitoring

00:09:12,560 --> 00:09:15,920
uh we get a very good allotting things

00:09:15,519 --> 00:09:18,480
uh

00:09:15,920 --> 00:09:20,959
to our on-call system page duty as well

00:09:18,480 --> 00:09:22,800
as the slack so that will be proactive

00:09:20,959 --> 00:09:24,320
in terms of the error response or the

00:09:22,800 --> 00:09:26,640
latencies and

00:09:24,320 --> 00:09:29,440
those golden metrics of the business

00:09:26,640 --> 00:09:29,440
logics as well

00:09:29,600 --> 00:09:36,880
but while doing these things

00:09:33,360 --> 00:09:38,399
there was a lot of there is the yaml

00:09:36,880 --> 00:09:39,760
file or the manifest file of the

00:09:38,399 --> 00:09:42,320
communities as well as

00:09:39,760 --> 00:09:43,600
uh uh the history routes and all of

00:09:42,320 --> 00:09:46,399
those things and

00:09:43,600 --> 00:09:46,880
it is very hard to keep them centralized

00:09:46,399 --> 00:09:49,920
so

00:09:46,880 --> 00:09:50,720
we started using helm for managing all

00:09:49,920 --> 00:09:53,040
of the

00:09:50,720 --> 00:09:55,040
hta configuration as well as the

00:09:53,040 --> 00:09:57,040
application the deployment service and

00:09:55,040 --> 00:09:59,760
laws all of those things so that we

00:09:57,040 --> 00:10:00,959
are confident like either all of those

00:09:59,760 --> 00:10:03,040
configs are applied

00:10:00,959 --> 00:10:04,160
or none of those are there and also

00:10:03,040 --> 00:10:06,160
development team

00:10:04,160 --> 00:10:08,480
started taking uh the ownership of

00:10:06,160 --> 00:10:10,480
adding uh the environment variable or

00:10:08,480 --> 00:10:11,519
tweaking a few of those configurations

00:10:10,480 --> 00:10:14,480
inside the helm

00:10:11,519 --> 00:10:16,640
so that was a very good path towards a

00:10:14,480 --> 00:10:19,360
devops model

00:10:16,640 --> 00:10:19,839
so that's all obviously centralized all

00:10:19,360 --> 00:10:23,040
of the

00:10:19,839 --> 00:10:23,680
uh resource control for the kubernetes

00:10:23,040 --> 00:10:25,279
part

00:10:23,680 --> 00:10:26,880
or for handling the resources of the

00:10:25,279 --> 00:10:30,320
given 80s

00:10:26,880 --> 00:10:32,880
so by the use of istio we're really

00:10:30,320 --> 00:10:34,160
fast enough for uh solving our business

00:10:32,880 --> 00:10:37,839
requirement and

00:10:34,160 --> 00:10:38,399
uh getting it done at a very small span

00:10:37,839 --> 00:10:41,279
of time

00:10:38,399 --> 00:10:42,399
and without impacting uh a lot of

00:10:41,279 --> 00:10:45,040
customer at once

00:10:42,399 --> 00:10:46,160
so that is a very cheering point for us

00:10:45,040 --> 00:10:50,560
so

00:10:46,160 --> 00:10:50,560

YouTube URL: https://www.youtube.com/watch?v=5jkXtz87AqI


