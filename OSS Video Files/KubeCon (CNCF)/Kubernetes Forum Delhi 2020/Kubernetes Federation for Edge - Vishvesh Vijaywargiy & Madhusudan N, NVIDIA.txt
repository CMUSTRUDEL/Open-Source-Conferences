Title: Kubernetes Federation for Edge - Vishvesh Vijaywargiy & Madhusudan N, NVIDIA
Publication date: 2020-02-27
Playlist: Kubernetes Forum Delhi 2020
Description: 
	Don't miss KubeCon + CloudNativeCon 2020 events in Amsterdam March 30 - April 2, Shanghai July 28-30 and Boston November 17-20! The conference features presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects - Learn more at https://kubecon.io

Kubernetes Federation for Edge - Vishvesh Vijaywargiy & Madhusudan N, NVIDIA 

What does it take to run Kubernetes at the edge? Running applications on edge devices is a fundamental shift from the cloud native world and this talk explores if Kubernetes is ready for it. We will start by exploring the different shades of the edge through the lens of several use cases: retail store, edge antenas, highways, cars and cargo ships. We will also highlight the challenges that applications and infrastructure faces when running at the edge (NAT boundaries, intermittent connectivity, limited compute resources etc). Finally we will present a kubernetes federation solution that can handle the scale of managing thousands of edge devices. An example deep learning application will be used to demonstrate the solution. 

https://sched.co/YWIw
Captions: 
	                              good afternoon everyone I am rich fish                               working for NVIDIA has decklid I'm                               mother Susan working as a senior                               software engineer at Nvidia we have a                               third speaker but he could not make it                               to this presentation because he's he                               works from us                               Rajat Chopra so today we are going to                               talk about kubernetes Federation at age                                we will also talk about the AI                                deployment to the H clusters in the real                                world                                let me start with the agenda Kuechly so                                for the agenda first we need to                                understand what it scenarios are we                                looking at and what are the type of                                issues that we would encounter and what                                we are actually trying to solve so first                                we will start off with that and we will                                also explore what are the different                                kinds of workloads that is different                                from what runs at the edge and what runs                                in a regular Kuban at a server which is                                probably be hosting micro services we                                will also look at how the kubernetes                                setup at edge is different than the                                regular kubernetes which we do on our                                own frame or cloud data centers we will                                have a very high-level overview about                                the cube Federation architecture                                suitable for the H will also explore                                challenges and the solutions that you                                know we have encountered and we have                                solved respectively so you're gonna see                                all that soon so let's start with a few                                at scenarios yeah quick show of hands                                how many of you are familiar with the                                edge compute or edge clusters nice I can                                say couple of friends so edge clusters                                are generally set up on the customer                                premises for the AI functional of                                functionality you have to set up the                                edge devices or H clusters at the data                                sources and why do we need to do that                                look at this edge scenario this traffic                                signal                                you see that it's a right candidate for                                the real-time analysis let me give you                                an example let's say an ambulance come                                traffic signals are meant for the                                traffic flow and if the signal is red                                and ambulance is there will this traffic                                signal be able to take the intelligent                                decision I stopped the other direction                                traffic flow and let the ambulance go                                well let's look at a different scenario                                also you know you have a ship over there                                and especially when it's in the sea it                                doesn't have any network connectivity                                and it doesn't really host a web                                application also but what's really                                happening is it's running AI workloads                                which is looking at the real-time                                information of whether the tides or you                                know the crews and giving real-time                                information to the captain of the ship                                and we have to really focus on this                                network isolation aspect as well very                                true I look at this Mission Control                                Nueske's when air models are used in the                                medical industry think a scenario when                                this work is going on and suddenly a non                                trustworthy container gets updated the                                edge cluster well we had really three                                problems or three scenarios that we were                                discussing right the real time                                processing became a real constraint and                                we had the isolated Network and the                                security which is really important and                                we also mentioned that the inference the                                I inference which is really happening                                it's important that it happens at the                                edge as well in the scenarios that we                                showed you it doesn't happen somewhere                                in the cloud you know you can't really                                wait for that long you cannot wait for                                the network connectivity exactly so by                                those use cases you must have seen that                                it's clusters are not always connected                                with the public cloud or network also                                there are there are requirements when                                you have to keep upgrading your data                                models you have to keep upgrading your                                workloads live and even you have to                                deploy them yeah we have also seen use                                cases where it had to be single node                                plus                                I know using the word single not in                                class or don't go well together but                                 let's assume that it's a single node                                 device that you really have and defining                                 high availability for this use case what                                 does high availability for this use case                                 yeah you must have seen as the first use                                 case that it's a traffic signal you will                                 not have the luxury of setting up the                                 high available kubernetes cluster most                                 of the H compute for the a use cases                                 that the data sources are minimalistic                                 set up like a single node master which                                 is working as a worker also and then it                                 is doing the data processing inferencing                                 yeah let's look at the Federation                                 architecture so Federation is not new                                 which we bring here it's it's it's a                                 well solve problem that you have                                 multiple kubernetes clusters behind the                                 federated cluster you deploy your CR DS                                 or CRS to the federated cluster which                                 takes care of pushing the data to all                                 the kubernetes cluster which are behind                                 the Federation unfortunately all the use                                 cases which talk about does not have                                 luxury of all the features like network                                 connectivity it has to be secured it has                                 to be always processing the real at the                                 real time in that scenario how we will                                 update the date update the workloads or                                 raid our models running on the edge                                 control so here we talk about this                                 architecture which is not push based it                                 is more of a pull based architecture in                                 this we have a federated cluster this                                 federated cluster has a namespace and                                 workloads are running on that and this                                 is a namespace ABC then you have the H                                 controllers these H controller H                                 clustered which has multiple controllers                                 running on that one of the controller is                                 the Federation controller whose main                                 responsibility is to watch all the CRS                                 or C already submitted to the Federation                                 controller as when as and when the                                 network reestablishes it downloads those                                 c ARS and CRS and create a local                                 representation of those years there is                                 another controller called H controller                                 which does it performs the action on the                                 new submitted request                                 and create the final objects for that                                 well to help you understand and simpler                                 terms assume when I'm a teacher and                                 you're all my students instead of                                 writing the homework in each of your                                 individual notebooks every day and                                 asking you to finish it I would just                                 write it on a notebook and ask you to                                 copy it so in a real world analogy I                                 believe that it's better right is this a                                 classic example I believe which all of                                 you can correlate that you just write on                                 the board and all the students can make                                 a note of that how I would like to bring                                 up a very interesting question here how                                 do you expose services from the edge to                                 the outside world so let's say you know                                 I resumed my network connectivity but                                 and I want to really export some of the                                 really important information like the                                 logs that help metrics the monitoring or                                 what really happened in the cluster how                                 do I really expose these services yeah                                 that is another challenge which you are                                 going to talk about later                                 so as I mentioned that you may have to                                 expose your services outside the cluster                                 for n number of reasons                                 altmetrics log collection and all in                                 this example we are talking about a                                 middleware where most of you and your                                 day-to-day work must have used the                                 reverse tunnel when you connect to a                                 private cloud set up on the AWS you have                                 to use the bastion connectivity or your                                 own data center you use the jump boxes                                 there we use the same concept in in this                                 design your H cluster which is running                                 the H controller is responsible to                                 create the reverse tunnel and open all                                 the ports for services which are running                                 inside that cluster these ports are                                 opened up and a reverse tunnel is set up                                 for the federated or cluster Federation                                 cluster where your SSH server pod is                                 running and this SSH server pod is                                 responsible to expose these services                                 behind load balancer so when outside                                 user connects to the federated cluster                                 this federated cluster can expose the                                 services and the data which it is                                 requesting for the important thing to                                 note here is the network boundaries I                                 would like to remind that we don't have                                 a luxury of push or                                 getting query query to the H clusters we                                 have to pull the data right so you know                                 we have been talking about edge                                 deployments so let's also look at a use                                 case where a I federated learning use                                 keys could also be solved so for people                                 who do not know what federated learning                                 is I'll give you a simple example                                 let's say I have finals and I ask these                                 fine notes to train the data                                 continuously and you know update the                                 models but it's very local to them the                                 models are pretty local and now I want                                 to build a combined model so from these                                 individual models which have been                                 generated and this is the concept behind                                 the federated learning and how it                                 essentially works as pools of the nodes                                 combines the models and written new                                 model and then pushes back the updates                                 that's the important process how do we                                 really solve this with you know using                                 the reverse SSH proxy architecture it's                                 pretty much the same so what we also did                                 was with the same intent we introduced                                 the service mesh and the service mesh                                 the init containers update the IP tables                                 so essentially an application developer                                 doesn't really have to focus on you know                                 routing his data to certain Federation                                 clusters he doesn't have to even have                                 the configuration to do it all he would                                 do is forward his data to a local host                                 local port and you know at the                                 infrastructure layer based on the                                 business rules we would be configuring                                 these endpoints using the service mesh                                 and there are a lot of available                                 solutions in the market on the service                                 mesh you could explore and that's really                                 interesting as a application developer I                                 don't have to worry about infrastructure                                 I will just send the information to the                                 local host at some port and it always be                                 like that so yeah we spoke about a is                                 workload deployments on the edge                                 clusters we spoke about how we can                                 expose the services outside the edge                                 clusters how we can use the service mesh                                 to                                 actually send the application data and                                 forwarded to the federated cluster and                                 finally consume it but that's it edge                                 computer is still primitive mother yeah                                 that's a very difficult question to                                 answer because we have to define a lot                                 of things about what really high                                 availability means you know I can have                                 refrigerator at my home which is really                                 a smart refrigerator and do I mean that                                 I have two refrigerators in case one                                 goes down and so we have to really                                 define what high availability means and                                 also about backup and restore how do we                                 really do it at the edge when there is                                 no person who is really specially                                 trained to perform this activity just                                 sitting there doing it so what is a real                                 concept about backup and restore so we                                 have to answer these very true and as                                 clusters are very minimalistic single                                 node clusters what if a lot of data is                                 coming there how will be load balanced                                 doing a luxury of adding more nodes in                                 fact if you want to reconfigure the                                 workloads which are deployed at the edge                                 edge from the security perspective is                                 very sensitive                                 you have to even restrict the cluster                                 administrator access you're not allowed                                 to give them SSH access so mostly the                                 practicer we have noticed is when the H                                 node comes up it bootstraps itself it                                 knows what role it has to play in the                                 kubernetes cluster and then it initiates                                 that bootstrapping workflow so basically                                 if you want to upgrade the workloads if                                 you want to reconfigure the applications                                 what are the right ways to do that and                                 also a few things about edges that you                                 know you may have real data sources                                 could be the sensors could be the                                 surveillance cameras but how do you                                 discover them and how do you you know                                 configure them and also about the                                 sources of information it could be the                                 container itself which is running and it                                 could be about the models you know where                                 do I fetch this data from trusted                                 sources and this has to be pretty much                                 Auto configured so that human                                 intervention does not cause you know                                 anomalies because we tend to do errors                                 right so so this is where we are looking                                 for the community help I'm sure that as                                 I saw a lot of people                                 working under h SE and nvidia is working                                 on AI workloads at the edge for the h                                 compute we are this is exploring these                                 solutions it's an ongoing process and we                                 expect or we at least looking for a                                 similar kind of contribution if                                 community also provides and we we are                                 available after this talk you can have a                                 chit chat around it right so the                                 takeaways for you are how to use                                 kubernetes for the edge compute and you                                 also learned about the federated                                 architecture you know which we are                                 proposing based on the pool models you                                 know instead of a push model and so                                 please feel free to write back so his                                 wish wish and I mother Susan our email                                 ids are on the screen so have a nice day                                 thank you this
YouTube URL: https://www.youtube.com/watch?v=evsyK5gWI2k


