Title: Multiplex tcp requests through Envoy HTTP 2 stack - Yuchen Dai
Publication date: 2020-10-21
Playlist: EnvoyCon 2020 - Virtual
Description: 
	Multiplex tcp requests through Envoy HTTP/2 stack - Yuchen Dai

This talk will go over the recent update of HTTP/2 CONNECT support in Envoy. Envoy not only can terminate or proxy an H2 CONNECT, but also proxy the raw tcp plain text request in establish H2 CONNECT. In this talk, Yuchen will also go through the on going efforts to optimize the CONNECT dispatch. With these efforts, Yuchen will demonstrate istio sidecar proxy(which is literally Envoy) tunnels http requests and raw tcp requests into HTTP2, multiplexed in one TLS/TCP connection as if the request is directly established by application.
Captions: 
	00:00:00,960 --> 00:00:04,160
hi everyone uh today i'm going to talk

00:00:03,679 --> 00:00:08,720
about

00:00:04,160 --> 00:00:12,240
multiplex tcp over and over hdb2 stack

00:00:08,720 --> 00:00:14,920
a little bit about me uh i'm my name is

00:00:12,240 --> 00:00:16,800
i'm a software engineer at google since

00:00:14,920 --> 00:00:19,199
2019 uh

00:00:16,800 --> 00:00:22,480
i mean the usq networking team almost

00:00:19,199 --> 00:00:25,519
work on that data play

00:00:22,480 --> 00:00:27,279
and this is outline of today's topic uh

00:00:25,519 --> 00:00:29,279
i've introduced the background the

00:00:27,279 --> 00:00:32,960
problems as a solutions

00:00:29,279 --> 00:00:37,520
and the real-world usage

00:00:32,960 --> 00:00:40,960
this is the traditional uh

00:00:37,520 --> 00:00:43,280
scenario of the service mesh so on the

00:00:40,960 --> 00:00:46,559
left side we will have a

00:00:43,280 --> 00:00:49,680
tcp client and away as

00:00:46,559 --> 00:00:52,960
this sidecar of the client

00:00:49,680 --> 00:00:56,079
would run the tcp proxy

00:00:52,960 --> 00:01:00,000
network plugin released by

00:00:56,079 --> 00:01:03,440
a stream to from tcp client to the other

00:01:00,000 --> 00:01:06,080
uh um way as the server-side sidecar

00:01:03,440 --> 00:01:10,720
and that's how i would also use tcp

00:01:06,080 --> 00:01:10,720
proxy to relate bytes to the tcp server

00:01:10,960 --> 00:01:18,000
and uh the variation today is

00:01:14,560 --> 00:01:21,040
about hdb2 uh in the stack

00:01:18,000 --> 00:01:23,200
so the changes i marked

00:01:21,040 --> 00:01:24,720
here use the red color instead of

00:01:23,200 --> 00:01:28,240
relaying the by

00:01:24,720 --> 00:01:32,000
stream from this reclined to

00:01:28,240 --> 00:01:33,600
the upstream uh onward server side arm

00:01:32,000 --> 00:01:36,079
way

00:01:33,600 --> 00:01:37,040
the live stream would be translated into

00:01:36,079 --> 00:01:40,960
http2

00:01:37,040 --> 00:01:43,759
client a connect method with the

00:01:40,960 --> 00:01:45,759
data framing encapsulating the bat

00:01:43,759 --> 00:01:48,799
stream that beef

00:01:45,759 --> 00:01:52,159
of course at the server side down way

00:01:48,799 --> 00:01:53,840
uh the http connection manager has a

00:01:52,159 --> 00:01:55,840
network

00:01:53,840 --> 00:01:56,880
network filter would terminate the

00:01:55,840 --> 00:02:00,399
connect request

00:01:56,880 --> 00:02:04,320
and extract the byte stream and relay to

00:02:00,399 --> 00:02:09,200
the ttp server so the problem

00:02:04,320 --> 00:02:12,319
uh or what we can benefit from the

00:02:09,200 --> 00:02:15,599
variated structure

00:02:12,319 --> 00:02:18,720
i will explain the further slides

00:02:15,599 --> 00:02:21,760
so uh in this

00:02:18,720 --> 00:02:22,480
slide on the top corner uh there's a

00:02:21,760 --> 00:02:25,760
thumbnail

00:02:22,480 --> 00:02:28,640
of the whole structure and

00:02:25,760 --> 00:02:29,280
on this side the sun weighs the tcp

00:02:28,640 --> 00:02:33,200
client

00:02:29,280 --> 00:02:36,000
side and way which is responsible

00:02:33,200 --> 00:02:37,920
to relay the black string to the

00:02:36,000 --> 00:02:40,959
upstream h2 request

00:02:37,920 --> 00:02:44,000
so this is done by our tcp

00:02:40,959 --> 00:02:47,680
proxy but with the h2

00:02:44,000 --> 00:02:49,680
extension at the tcp

00:02:47,680 --> 00:02:51,760
connection pro which is recently

00:02:49,680 --> 00:02:55,040
developed by

00:02:51,760 --> 00:02:58,959
alisa thank you alisa and this

00:02:55,040 --> 00:03:02,480
h2 codec in the tcp connection pool

00:02:58,959 --> 00:03:05,200
would custom magic

00:03:02,480 --> 00:03:07,680
translate from by stream to http to

00:03:05,200 --> 00:03:10,800
connect three

00:03:07,680 --> 00:03:11,840
and this slide is about the server side

00:03:10,800 --> 00:03:15,120
and way

00:03:11,840 --> 00:03:18,239
so this server side i would use uh

00:03:15,120 --> 00:03:22,239
http connection manager uh live in

00:03:18,239 --> 00:03:23,840
the tunnel listener on port 80 which is

00:03:22,239 --> 00:03:27,440
a common http

00:03:23,840 --> 00:03:28,000
port and the specialized configuration

00:03:27,440 --> 00:03:31,360
is that

00:03:28,000 --> 00:03:32,159
in the route configuration you can use

00:03:31,360 --> 00:03:35,360
the connect

00:03:32,159 --> 00:03:38,799
config field

00:03:35,360 --> 00:03:42,640
to declare that uh instead of relay the

00:03:38,799 --> 00:03:46,400
http to connect method please use

00:03:42,640 --> 00:03:49,599
extract data from the connect stream

00:03:46,400 --> 00:03:52,959
and relay to upstream and

00:03:49,599 --> 00:03:55,519
in my specialized design i would

00:03:52,959 --> 00:03:56,159
introduce another tcp proxy listener

00:03:55,519 --> 00:03:59,200
which is

00:03:56,159 --> 00:04:02,640
similar to the traditional architecture

00:03:59,200 --> 00:04:06,640
this tcp proxy uh network filter

00:04:02,640 --> 00:04:09,519
would do byte two byte uh trans uh relay

00:04:06,640 --> 00:04:10,560
uh you may wonder why we are why i'm

00:04:09,519 --> 00:04:14,000
introducing

00:04:10,560 --> 00:04:17,519
a duplicate listener uh the idea is

00:04:14,000 --> 00:04:19,919
uh maybe quite naive because

00:04:17,519 --> 00:04:21,199
in service mesh especially in skill at

00:04:19,919 --> 00:04:24,400
the server side

00:04:21,199 --> 00:04:28,080
we already invest a lot including

00:04:24,400 --> 00:04:31,040
error for rbac network user including

00:04:28,080 --> 00:04:32,479
the access log the monitoring pipeline

00:04:31,040 --> 00:04:34,880
which is a promise

00:04:32,479 --> 00:04:36,880
to the developer and these two users so

00:04:34,880 --> 00:04:40,240
we don't want to

00:04:36,880 --> 00:04:45,120
mutate the structure too

00:04:40,240 --> 00:04:50,080
huge to break the existing

00:04:45,120 --> 00:04:53,440
structure and this side

00:04:50,080 --> 00:04:56,000
give an introduction on

00:04:53,440 --> 00:04:57,680
the necessary config or the component

00:04:56,000 --> 00:05:00,800
introduced in this

00:04:57,680 --> 00:05:04,720
scenario i can explain in the

00:05:00,800 --> 00:05:06,160
further slide so what we can gain from

00:05:04,720 --> 00:05:09,440
this

00:05:06,160 --> 00:05:12,960
complex structure so we can

00:05:09,440 --> 00:05:14,960
obtain the risk we can get the

00:05:12,960 --> 00:05:17,520
functionality of metadata exchange

00:05:14,960 --> 00:05:20,639
between the two and voice

00:05:17,520 --> 00:05:21,840
so because the to one wise is using is

00:05:20,639 --> 00:05:25,440
connected with

00:05:21,840 --> 00:05:30,560
hdb2 connect stream so

00:05:25,440 --> 00:05:34,880
then we can use the h2

00:05:30,560 --> 00:05:38,160
header uh to encode our metadata

00:05:34,880 --> 00:05:41,600
in this page uh at demonstrate as

00:05:38,160 --> 00:05:44,800
x full client id which is

00:05:41,600 --> 00:05:47,360
my fake client node id and

00:05:44,800 --> 00:05:48,320
server would respond uh whatever you

00:05:47,360 --> 00:05:52,160
like but

00:05:48,320 --> 00:05:55,759
in this example is a server id

00:05:52,160 --> 00:05:57,680
and what we can obtain beyond the

00:05:55,759 --> 00:06:00,720
traditional tcp

00:05:57,680 --> 00:06:05,440
proxy connected scenario

00:06:00,720 --> 00:06:09,199
we can use the hdb2 uh http filter

00:06:05,440 --> 00:06:12,560
which is far more powerful than the

00:06:09,199 --> 00:06:14,880
tcp proxy routing so we can match the

00:06:12,560 --> 00:06:18,960
headers we provided in the metadata

00:06:14,880 --> 00:06:22,240
to decide which upstream endpoint we are

00:06:18,960 --> 00:06:25,360
we the server side hd uh

00:06:22,240 --> 00:06:28,560
upstream we would redirect to

00:06:25,360 --> 00:06:31,680
and uh we can

00:06:28,560 --> 00:06:32,479
obtain the low cost handshake uh in the

00:06:31,680 --> 00:06:34,800
service mesh

00:06:32,479 --> 00:06:36,479
scenario are the clients and wei and

00:06:34,800 --> 00:06:40,800
server and well

00:06:36,479 --> 00:06:43,840
mostly would be connected with trs hand

00:06:40,800 --> 00:06:44,400
connection and everybody knows that drs

00:06:43,840 --> 00:06:46,960
handshake

00:06:44,400 --> 00:06:49,039
is inexpensive in terms of the latency

00:06:46,960 --> 00:06:52,160
and the cpu cycle

00:06:49,039 --> 00:06:55,360
what is even worse is that

00:06:52,160 --> 00:06:56,479
this traditional tcp proxy uses tcp

00:06:55,360 --> 00:06:59,039
connection pro but

00:06:56,479 --> 00:07:01,280
the connection itself is not reused so

00:06:59,039 --> 00:07:04,880
for each incoming

00:07:01,280 --> 00:07:06,960
connection the connection pool

00:07:04,880 --> 00:07:08,000
would establish a new connection tcp

00:07:06,960 --> 00:07:11,440
connection

00:07:08,000 --> 00:07:13,440
to the upstream and introduce another

00:07:11,440 --> 00:07:17,840
handshake

00:07:13,440 --> 00:07:17,840
but with http tools stacked

00:07:17,919 --> 00:07:24,400
to incoming tcp connection can be

00:07:20,960 --> 00:07:26,400
encapsulated in the same upstream tcp

00:07:24,400 --> 00:07:29,680
connection

00:07:26,400 --> 00:07:32,960
and the boundaries the data frames are

00:07:29,680 --> 00:07:36,160
the hv2 streams uh

00:07:32,960 --> 00:07:39,199
between the two away so

00:07:36,160 --> 00:07:42,560
you handshake once and you use

00:07:39,199 --> 00:07:46,479
the trs connection

00:07:42,560 --> 00:07:50,080
for many many tcp uh connections

00:07:46,479 --> 00:07:53,840
between the client and server

00:07:50,080 --> 00:07:58,879
and you may wonder uh with this

00:07:53,840 --> 00:08:02,240
uh actual layers would it be expensive

00:07:58,879 --> 00:08:05,840
yes it is uh without optimization

00:08:02,240 --> 00:08:09,440
uh there are many copies i

00:08:05,840 --> 00:08:13,199
introduced uh between the two listeners

00:08:09,440 --> 00:08:15,440
at the server side i'm way so each

00:08:13,199 --> 00:08:16,639
we basically create two extra

00:08:15,440 --> 00:08:19,680
connections

00:08:16,639 --> 00:08:21,680
and uh the kernel space would to

00:08:19,680 --> 00:08:24,639
maintain two socket buffers

00:08:21,680 --> 00:08:27,039
and connection user space connection

00:08:24,639 --> 00:08:30,000
copy to circuit buffer in the kernel

00:08:27,039 --> 00:08:31,840
kernel to copy between two socket buffer

00:08:30,000 --> 00:08:37,360
and socket buffer would

00:08:31,840 --> 00:08:40,560
copy to the user connection again

00:08:37,360 --> 00:08:43,279
but remember the

00:08:40,560 --> 00:08:45,279
scenario that that's two listeners sit

00:08:43,279 --> 00:08:49,040
in the same onward process

00:08:45,279 --> 00:08:52,880
so i introduce a concept of internal

00:08:49,040 --> 00:08:56,640
client connection internal listener and

00:08:52,880 --> 00:09:00,000
a specialized io socket implementation

00:08:56,640 --> 00:09:03,200
to eliminate the two socket

00:09:00,000 --> 00:09:06,240
buffer with the

00:09:03,200 --> 00:09:10,240
two connections extra connections

00:09:06,240 --> 00:09:13,040
so the data is not copied instead we use

00:09:10,240 --> 00:09:13,920
a way building buffer to move chunk of

00:09:13,040 --> 00:09:17,360
data

00:09:13,920 --> 00:09:20,800
uh in the pipeline

00:09:17,360 --> 00:09:24,399
in runway components so not many

00:09:20,800 --> 00:09:27,519
data are copied so

00:09:24,399 --> 00:09:28,320
the real world usage will be in ucl one

00:09:27,519 --> 00:09:31,440
night which

00:09:28,320 --> 00:09:32,240
will be released in november 2020 and i

00:09:31,440 --> 00:09:35,120
see

00:09:32,240 --> 00:09:36,640
you don't have to introduce the whole

00:09:35,120 --> 00:09:40,399
stack in your

00:09:36,640 --> 00:09:41,839
system you can use the connection

00:09:40,399 --> 00:09:45,440
internal connection

00:09:41,839 --> 00:09:49,839
uh with very little config change

00:09:45,440 --> 00:09:53,760
uh and gain the change uh listener

00:09:49,839 --> 00:09:57,040
regardless is chained tcp

00:09:53,760 --> 00:09:59,519
proxy to http

00:09:57,040 --> 00:10:00,880
connection manager i also use connection

00:09:59,519 --> 00:10:05,279
tcp

00:10:00,880 --> 00:10:08,480
to tcp or hdb2 to hdb2

00:10:05,279 --> 00:10:12,560
or other protocols so the code is still

00:10:08,480 --> 00:10:12,560
up streaming you will see that in

00:10:13,600 --> 00:10:21,680
along with my upstream so uh this page

00:10:18,640 --> 00:10:25,040
i provide some links uh in that

00:10:21,680 --> 00:10:28,480
to the rfc of hdb or

00:10:25,040 --> 00:10:30,240
and the life of amway request and the

00:10:28,480 --> 00:10:33,279
building

00:10:30,240 --> 00:10:35,279
component in our way to support the full

00:10:33,279 --> 00:10:39,680
picture

00:10:35,279 --> 00:10:39,680

YouTube URL: https://www.youtube.com/watch?v=L_5mG6eBllQ


