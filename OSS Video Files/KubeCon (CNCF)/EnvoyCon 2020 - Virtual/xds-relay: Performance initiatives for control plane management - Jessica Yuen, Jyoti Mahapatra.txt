Title: xds-relay: Performance initiatives for control plane management - Jessica Yuen, Jyoti Mahapatra
Publication date: 2020-10-21
Playlist: EnvoyCon 2020 - Virtual
Description: 
	xds-relay: Performance initiatives for control plane management - Jessica Yuen, Jyoti Mahapatra

In this talk, presenters will share their experience running Envoy and Lyft’s control plane at scale. They will explore the challenges of operating Lyft’s service mesh to be reactive to Kubernetes’ dynamic infrastructure and evolving xDS versions. This talk is a deep dive into a new open source project, xds-relay, that the Lyft team has developed to bring their solutions to the greater community. xds-relay is a lightweight caching, aggregation, and low latency distribution layer for xDS compliant clients and servers. At scale, xds-relay reliably distributes xDS protos to thousands of xDS clients over gRPC. Join Lyft’s journey as the presenters share how Lyft envisions the future of control planes. The presenters will cover a range of topics including pluggable xDS transformations, automatic endpoint subsetting, API driven configurations, and State-of-the-world to Delta xDS conversion.
Captions: 
	00:00:01,360 --> 00:00:05,600
hi everyone thanks for joining our chat

00:00:03,840 --> 00:00:07,279
today about xts relay

00:00:05,600 --> 00:00:09,200
it's a new project in the onboarding

00:00:07,279 --> 00:00:10,639
system and we are very excited about

00:00:09,200 --> 00:00:12,559
introducing it

00:00:10,639 --> 00:00:14,880
we are hoping to tell a story about how

00:00:12,559 --> 00:00:15,519
it started the problems it's trying to

00:00:14,880 --> 00:00:17,440
solve

00:00:15,519 --> 00:00:20,240
and we're hoping to answer some of the

00:00:17,440 --> 00:00:20,240
open questions

00:00:21,279 --> 00:00:26,400
i'm jyoti and i'm here with just today

00:00:24,480 --> 00:00:29,039
we both work in the networking team at

00:00:26,400 --> 00:00:30,160
lyft we are the maintainers of the xts

00:00:29,039 --> 00:00:32,079
relay project

00:00:30,160 --> 00:00:33,680
as well as the new maintenance on the go

00:00:32,079 --> 00:00:36,320
control plane

00:00:33,680 --> 00:00:37,040
our contact information is mentioned on

00:00:36,320 --> 00:00:39,040
the slide

00:00:37,040 --> 00:00:42,480
and would be very happy to connect and

00:00:39,040 --> 00:00:42,480
engage further after the talk

00:00:42,640 --> 00:00:46,800
everything has a history and we are not

00:00:44,399 --> 00:00:48,399
different the networking team at left

00:00:46,800 --> 00:00:51,199
has been maintaining the lift edge

00:00:48,399 --> 00:00:52,800
and service mesh over numerous years the

00:00:51,199 --> 00:00:54,000
lift compute architecture has evolved

00:00:52,800 --> 00:00:57,600
from vm based

00:00:54,000 --> 00:01:00,000
asgs to kubernetes initial adapters of

00:00:57,600 --> 00:01:02,320
kubernetes slowly tripled into the match

00:01:00,000 --> 00:01:04,320
as the platform became more robust the

00:01:02,320 --> 00:01:06,159
adoption became more widespread

00:01:04,320 --> 00:01:07,600
in order to maintain one way of doing

00:01:06,159 --> 00:01:09,680
things the leadership also

00:01:07,600 --> 00:01:12,400
made a mandate to move all services to

00:01:09,680 --> 00:01:14,400
communities by the end of williamson

00:01:12,400 --> 00:01:16,400
lift service discovery based on the open

00:01:14,400 --> 00:01:18,640
source discovery service

00:01:16,400 --> 00:01:20,159
was accompanied by a kubernetes spot

00:01:18,640 --> 00:01:23,040
informal model

00:01:20,159 --> 00:01:23,600
the envoy control plane slowly evolved

00:01:23,040 --> 00:01:26,159
to

00:01:23,600 --> 00:01:26,960
accommodate both mechanisms there were

00:01:26,159 --> 00:01:30,560
talks at

00:01:26,960 --> 00:01:32,400
con san diego 2019 and amsterdam 2720

00:01:30,560 --> 00:01:34,479
which described more about the service

00:01:32,400 --> 00:01:37,680
discovery architecture

00:01:34,479 --> 00:01:39,920
so much so that by the end of 2019

00:01:37,680 --> 00:01:40,720
25 of the services were migrated to

00:01:39,920 --> 00:01:43,040
qualities

00:01:40,720 --> 00:01:44,320
and were running production workloads

00:01:43,040 --> 00:01:46,960
this was enough scale

00:01:44,320 --> 00:01:48,079
for ugly incidents to occur and at the

00:01:46,960 --> 00:01:51,759
center of it all

00:01:48,079 --> 00:01:52,560
was lyft's homegrown controlling by 2019

00:01:51,759 --> 00:01:53,759
december

00:01:52,560 --> 00:01:55,439
it was clear that the current

00:01:53,759 --> 00:01:56,159
architecture won't scale if more

00:01:55,439 --> 00:01:58,640
services

00:01:56,159 --> 00:01:59,759
kept moving to communities he made point

00:01:58,640 --> 00:02:01,680
in time sixes

00:01:59,759 --> 00:02:03,360
to keep the systems running and at the

00:02:01,680 --> 00:02:03,840
same time came up with the novel

00:02:03,360 --> 00:02:06,479
approach

00:02:03,840 --> 00:02:09,840
of managing service with discovery it's

00:02:06,479 --> 00:02:09,840
called next instrument

00:02:10,399 --> 00:02:14,000
briefly describe a bit if about the

00:02:12,720 --> 00:02:16,640
before and after model

00:02:14,000 --> 00:02:17,520
of the of how service discovery works

00:02:16,640 --> 00:02:19,520
left

00:02:17,520 --> 00:02:21,520
we have a homegrown control plane based

00:02:19,520 --> 00:02:23,680
on the door control plane

00:02:21,520 --> 00:02:25,360
subscribes to endpoint updates from vm

00:02:23,680 --> 00:02:27,840
based discovery service

00:02:25,360 --> 00:02:29,680
and kubernetes api server it also

00:02:27,840 --> 00:02:33,680
subscribes to cluster updates

00:02:29,680 --> 00:02:35,440
from a relatively low flux s3 files

00:02:33,680 --> 00:02:38,560
the control plane is connected to the

00:02:35,440 --> 00:02:41,519
on-voice height cards via grpc

00:02:38,560 --> 00:02:45,040
these sidecars could be on literacy vms

00:02:41,519 --> 00:02:45,040
or containers on the phones

00:02:46,480 --> 00:02:50,800
so far so good one striking difference

00:02:49,200 --> 00:02:51,360
between the legacy and the kubernetes

00:02:50,800 --> 00:02:53,920
stack

00:02:51,360 --> 00:02:54,800
was that vms take minutes to spin up

00:02:53,920 --> 00:02:57,360
while the pods

00:02:54,800 --> 00:02:59,120
take a few seconds to be ready this

00:02:57,360 --> 00:03:01,120
gives the services an advantage

00:02:59,120 --> 00:03:02,959
to keep the instance counts low and

00:03:01,120 --> 00:03:04,239
aggressively scale up when traffic

00:03:02,959 --> 00:03:06,480
spikes

00:03:04,239 --> 00:03:08,239
this pattern causes more services to

00:03:06,480 --> 00:03:10,640
scale up at each morning

00:03:08,239 --> 00:03:13,760
and evening commute hours and then

00:03:10,640 --> 00:03:13,760
quickly scale down too

00:03:14,480 --> 00:03:20,319
we like most control planes use on voice

00:03:18,720 --> 00:03:22,560
state of the world xps

00:03:20,319 --> 00:03:23,680
this means if there's a service a having

00:03:22,560 --> 00:03:26,720
an end point

00:03:23,680 --> 00:03:27,920
and a dependent uh service b with m n

00:03:26,720 --> 00:03:30,319
points

00:03:27,920 --> 00:03:31,280
a new part coming up in service b will

00:03:30,319 --> 00:03:33,920
cause at least

00:03:31,280 --> 00:03:35,840
m membership updates on service a based

00:03:33,920 --> 00:03:37,599
on how much each service scales

00:03:35,840 --> 00:03:39,680
this quickly becomes an m crossing

00:03:37,599 --> 00:03:41,519
problem and causes too many updates

00:03:39,680 --> 00:03:42,640
across the hundreds of services in the

00:03:41,519 --> 00:03:44,159
mesh

00:03:42,640 --> 00:03:47,040
these operations come at a cost of

00:03:44,159 --> 00:03:48,879
elevated cpu they frequently encountered

00:03:47,040 --> 00:03:50,400
long periods of elevated cpu on the

00:03:48,879 --> 00:03:54,560
control plane instances

00:03:50,400 --> 00:03:54,560
and this caused some bad output outages

00:03:55,920 --> 00:03:59,840
next such a huge influx of new parts

00:03:58,239 --> 00:04:01,920
causes all parts to create new

00:03:59,840 --> 00:04:04,159
connections to the control plane

00:04:01,920 --> 00:04:05,040
at scale connection management becomes a

00:04:04,159 --> 00:04:07,519
bottleneck

00:04:05,040 --> 00:04:09,200
it has a cost which adds up quickly and

00:04:07,519 --> 00:04:11,360
causes cpu pressure

00:04:09,200 --> 00:04:15,840
since the control plane was vm based it

00:04:11,360 --> 00:04:15,840
could not scale proportionally

00:04:16,000 --> 00:04:20,079
the interesting part starts next it is a

00:04:18,400 --> 00:04:21,680
control plane's responsibility to

00:04:20,079 --> 00:04:24,080
understand the update

00:04:21,680 --> 00:04:24,800
pack the information in the grpc object

00:04:24,080 --> 00:04:27,040
and send that

00:04:24,800 --> 00:04:28,800
across the dependent sidecars this

00:04:27,040 --> 00:04:31,600
process needs a grpc payload to be

00:04:28,800 --> 00:04:33,280
serialized into network bytes and sent

00:04:31,600 --> 00:04:35,360
serialization is a cpu intensive

00:04:33,280 --> 00:04:37,600
operation and we noticed that as more

00:04:35,360 --> 00:04:39,199
and more services adopted communities

00:04:37,600 --> 00:04:41,440
the control plane cpu was through the

00:04:39,199 --> 00:04:43,360
roof when everything scaled up and down

00:04:41,440 --> 00:04:45,120
the scaled down characteristics is very

00:04:43,360 --> 00:04:47,759
similar to scalar and suffers from the

00:04:45,120 --> 00:04:51,680
same symptoms

00:04:47,759 --> 00:04:54,560
the next question is why is high cpu bad

00:04:51,680 --> 00:04:56,320
high cpu usage causes throttling and

00:04:54,560 --> 00:04:58,400
slows down the system

00:04:56,320 --> 00:05:00,800
the payload cannot be serialized and

00:04:58,400 --> 00:05:02,880
sent fast enough to the sidecars

00:05:00,800 --> 00:05:05,680
this happens while there are more

00:05:02,880 --> 00:05:07,600
payloads still getting queued

00:05:05,680 --> 00:05:09,120
the endpoint discovery at left does not

00:05:07,600 --> 00:05:11,280
have a durable storage

00:05:09,120 --> 00:05:12,560
and any missed updates would mean

00:05:11,280 --> 00:05:15,840
membership information

00:05:12,560 --> 00:05:18,080
to diverge and become stale too

00:05:15,840 --> 00:05:25,199
a spare membership can cause incorrect

00:05:18,080 --> 00:05:26,880
routing and panic loading in your body

00:05:25,199 --> 00:05:30,000
while all these problems were happening

00:05:26,880 --> 00:05:30,000
we spun into action

00:05:30,400 --> 00:05:33,759
one of the first approach was to move

00:05:31,919 --> 00:05:34,800
the control plane infrastructure took

00:05:33,759 --> 00:05:37,280
abilities

00:05:34,800 --> 00:05:39,840
so that it could scale quickly and

00:05:37,280 --> 00:05:42,800
proportionally with other services

00:05:39,840 --> 00:05:44,639
we could also scale up or pre-scale the

00:05:42,800 --> 00:05:47,680
existing legacy control plane

00:05:44,639 --> 00:05:49,039
before known events control plane parts

00:05:47,680 --> 00:05:50,840
were deployed in the two-way disk

00:05:49,039 --> 00:05:53,840
clusters so they could scale

00:05:50,840 --> 00:05:53,840
proportionally

00:05:54,000 --> 00:05:58,000
we changed the bokeh channels in the go

00:05:56,880 --> 00:06:01,280
controls name

00:05:58,000 --> 00:06:01,759
from unbuffered to buffer and buffer

00:06:01,280 --> 00:06:04,319
channels

00:06:01,759 --> 00:06:04,960
of length one for the state of the world

00:06:04,319 --> 00:06:07,280
eds

00:06:04,960 --> 00:06:08,960
the last update wins if one of the

00:06:07,280 --> 00:06:11,199
sidecars network was getting

00:06:08,960 --> 00:06:13,440
flow control and the pro control plane's

00:06:11,199 --> 00:06:15,120
channel was blocked from making progress

00:06:13,440 --> 00:06:17,520
we could keep the keep overriding the

00:06:15,120 --> 00:06:21,840
latest update in the buffer channel

00:06:17,520 --> 00:06:21,840
to maintain correctness

00:06:22,160 --> 00:06:26,639
we performed flame graph analysis and

00:06:24,400 --> 00:06:28,880
fixed a few wasteful relationships

00:06:26,639 --> 00:06:32,560
both in go control plane library and in

00:06:28,880 --> 00:06:32,560
our own private control plane

00:06:33,199 --> 00:06:36,319
instantaneous in point update was cost

00:06:35,520 --> 00:06:38,160
for everything

00:06:36,319 --> 00:06:40,400
so we make sure that the rate limit and

00:06:38,160 --> 00:06:41,680
batch kubernetes end point updates to a

00:06:40,400 --> 00:06:44,639
configurable interval

00:06:41,680 --> 00:06:45,440
say tens of seconds envoy is eventually

00:06:44,639 --> 00:06:48,000
consistent

00:06:45,440 --> 00:06:49,360
so this worked out fine for now although

00:06:48,000 --> 00:06:50,160
we slowed down the membership

00:06:49,360 --> 00:06:52,080
convergence

00:06:50,160 --> 00:06:53,759
and made the control plan response times

00:06:52,080 --> 00:06:56,479
flow

00:06:53,759 --> 00:06:58,479
all of this has led us to think about a

00:06:56,479 --> 00:07:01,120
different approach or service discovery

00:06:58,479 --> 00:07:02,560
and we are calling it the xps relay i'll

00:07:01,120 --> 00:07:05,759
take i'll

00:07:02,560 --> 00:07:05,759
just talk about it

00:07:09,440 --> 00:07:13,680
thanks jody so excess really is a

00:07:11,919 --> 00:07:14,080
project that we started early in the

00:07:13,680 --> 00:07:16,479
year

00:07:14,080 --> 00:07:18,960
to address some of the stock gaps that

00:07:16,479 --> 00:07:18,960
we mentioned

00:07:21,039 --> 00:07:24,240
from its conception we had a few goals

00:07:22,880 --> 00:07:26,400
in mind

00:07:24,240 --> 00:07:27,520
first we wanted to be about entirely in

00:07:26,400 --> 00:07:30,080
the open

00:07:27,520 --> 00:07:30,800
so we spoken with a few companies in the

00:07:30,080 --> 00:07:32,720
past months

00:07:30,800 --> 00:07:34,720
operating at a similar or larger scale

00:07:32,720 --> 00:07:35,680
than lyft and there's always this

00:07:34,720 --> 00:07:38,080
reoccurring theme

00:07:35,680 --> 00:07:40,560
and questions of what is the standard

00:07:38,080 --> 00:07:42,840
for control plane implementation

00:07:40,560 --> 00:07:44,560
will lift be open sourcing our control

00:07:42,840 --> 00:07:46,400
plane

00:07:44,560 --> 00:07:47,759
and control plane development is

00:07:46,400 --> 00:07:49,919
difficult and there's

00:07:47,759 --> 00:07:51,120
a lot of intricacies to get it operating

00:07:49,919 --> 00:07:52,720
at a level that

00:07:51,120 --> 00:07:55,280
behaves correctly for a particular

00:07:52,720 --> 00:07:57,199
company's infrastructure

00:07:55,280 --> 00:07:59,360
one of the goals with xcs relay is to be

00:07:57,199 --> 00:08:01,840
able to abstract away the layers of

00:07:59,360 --> 00:08:03,520
list control plane that we do believe is

00:08:01,840 --> 00:08:05,599
shareable

00:08:03,520 --> 00:08:06,879
and secondly we want this to be an out

00:08:05,599 --> 00:08:09,520
of the box solution

00:08:06,879 --> 00:08:13,039
that users can run and operate with

00:08:09,520 --> 00:08:16,000
minimal knobs xcs really also will

00:08:13,039 --> 00:08:19,759
implement a popular and well supported

00:08:16,000 --> 00:08:19,759
open source go control plane library

00:08:22,000 --> 00:08:28,240
so we see xcs relay as a cdn for xds

00:08:26,639 --> 00:08:29,759
initially it's an aggregation and

00:08:28,240 --> 00:08:31,199
caching layer that's meant to reside

00:08:29,759 --> 00:08:33,680
physically close to

00:08:31,199 --> 00:08:34,399
xcs clients so those running on the same

00:08:33,680 --> 00:08:37,760
region

00:08:34,399 --> 00:08:39,360
data center etc

00:08:37,760 --> 00:08:41,519
similar to general benefits of using a

00:08:39,360 --> 00:08:44,159
cdn users of xcs relay can

00:08:41,519 --> 00:08:44,959
benefit from faster delivery of xcs

00:08:44,159 --> 00:08:47,279
responses

00:08:44,959 --> 00:08:49,120
faster service uptime and reduce

00:08:47,279 --> 00:08:50,800
bandwidth costs from caching

00:08:49,120 --> 00:08:53,440
and other optimizations that we have for

00:08:50,800 --> 00:08:53,440
this project

00:08:53,760 --> 00:08:57,279
exes really will be configurable with

00:08:55,600 --> 00:08:59,839
rule-based definitions in order to

00:08:57,279 --> 00:09:02,000
specify a group of exes requests that

00:08:59,839 --> 00:09:03,600
should get aggregated and cached to the

00:09:02,000 --> 00:09:05,760
same key

00:09:03,600 --> 00:09:07,519
xds really will maintain a grpc stream

00:09:05,760 --> 00:09:10,240
to the control plane server for each of

00:09:07,519 --> 00:09:10,240
the unique keys

00:09:13,120 --> 00:09:16,720
so lyft's current control plane manages

00:09:15,360 --> 00:09:18,959
multiple facets

00:09:16,720 --> 00:09:20,640
pre-processing of multiple sources of

00:09:18,959 --> 00:09:23,760
lift service metadata

00:09:20,640 --> 00:09:25,760
in order to generate the xcs responses

00:09:23,760 --> 00:09:27,360
pulling from legacy discovery mechanisms

00:09:25,760 --> 00:09:30,240
in the kubernetes api server

00:09:27,360 --> 00:09:31,920
in order to get endpoint information and

00:09:30,240 --> 00:09:36,000
last but not least caching

00:09:31,920 --> 00:09:38,080
and fanning out of discovery responses

00:09:36,000 --> 00:09:39,440
excess really will pull out the

00:09:38,080 --> 00:09:42,080
connection management and

00:09:39,440 --> 00:09:43,839
caching aspect allowing the control

00:09:42,080 --> 00:09:46,800
plane server to scale independently of

00:09:43,839 --> 00:09:46,800
xcs clients

00:09:47,040 --> 00:09:50,480
we're also making a lot of optimizations

00:09:48,800 --> 00:09:52,000
into the transport layer

00:09:50,480 --> 00:09:55,600
in order to make the connections low

00:09:52,000 --> 00:09:55,600
latency and low throughput

00:09:57,600 --> 00:10:01,360
excess relay will also have built-in

00:09:59,600 --> 00:10:02,720
common control plane observability

00:10:01,360 --> 00:10:04,720
mechanisms

00:10:02,720 --> 00:10:06,000
including stats supporting multiple

00:10:04,720 --> 00:10:08,320
syncs

00:10:06,000 --> 00:10:10,000
error warning and debug level logs as

00:10:08,320 --> 00:10:12,079
well as admin endpoints for

00:10:10,000 --> 00:10:13,680
viewing the cache and other common

00:10:12,079 --> 00:10:18,720
control plane

00:10:13,680 --> 00:10:21,200
endpoint usability tools

00:10:18,720 --> 00:10:21,839
so alongside upstream server retries xcs

00:10:21,200 --> 00:10:23,839
relay

00:10:21,839 --> 00:10:25,680
will implement mechanisms to stop a

00:10:23,839 --> 00:10:26,480
thundering herd of requests from xcs

00:10:25,680 --> 00:10:28,079
clients

00:10:26,480 --> 00:10:30,640
through a queuing and rate limiting

00:10:28,079 --> 00:10:30,640
mechanism

00:10:30,880 --> 00:10:34,240
lastly we want to build xcs relay in a

00:10:33,279 --> 00:10:35,519
way that

00:10:34,240 --> 00:10:38,320
the components operate in a

00:10:35,519 --> 00:10:40,000
plug-and-play manner

00:10:38,320 --> 00:10:41,519
we'll get into a lot of ambitious goals

00:10:40,000 --> 00:10:44,240
we have surrounding a general

00:10:41,519 --> 00:10:45,839
relaying type component later but we

00:10:44,240 --> 00:10:48,079
understand that a feature

00:10:45,839 --> 00:10:49,279
rich set can be bloated for a company

00:10:48,079 --> 00:10:51,519
that wants to

00:10:49,279 --> 00:10:53,040
just run lightweight components for that

00:10:51,519 --> 00:10:55,279
reason we're

00:10:53,040 --> 00:11:00,480
conscious to make axios relay as

00:10:55,279 --> 00:11:03,040
extensible as possible

00:11:00,480 --> 00:11:04,720
so at the heart of xcs relay is

00:11:03,040 --> 00:11:07,519
rule-based definitions for

00:11:04,720 --> 00:11:09,519
request aggregation and caching and

00:11:07,519 --> 00:11:10,720
here's an example where we've decided to

00:11:09,519 --> 00:11:15,519
cache on

00:11:10,720 --> 00:11:18,560
service and request type pairings

00:11:15,519 --> 00:11:21,200
we use yaml structured match and result

00:11:18,560 --> 00:11:23,600
compilers in order to create the unique

00:11:21,200 --> 00:11:25,440
aggregated keys

00:11:23,600 --> 00:11:26,839
we won't dive into the specifics here

00:11:25,440 --> 00:11:29,839
because we'll be doing a demo

00:11:26,839 --> 00:11:29,839
shortly

00:11:33,200 --> 00:11:36,640
we thought that it would be easiest to

00:11:35,120 --> 00:11:39,120
understand the architecture of

00:11:36,640 --> 00:11:41,519
xcs relay by going through a workflow

00:11:39,120 --> 00:11:42,959
diagram

00:11:41,519 --> 00:11:44,880
so on the slide you can see the

00:11:42,959 --> 00:11:48,399
workflows numbered one

00:11:44,880 --> 00:11:49,360
all the way to six when discovery

00:11:48,399 --> 00:11:52,480
requests first

00:11:49,360 --> 00:11:53,279
make their way into xcs relay they go

00:11:52,480 --> 00:11:55,760
through an

00:11:53,279 --> 00:11:57,279
aggregator component this is the

00:11:55,760 --> 00:11:59,440
component that takes the rules we

00:11:57,279 --> 00:12:01,680
mentioned in the previous slide

00:11:59,440 --> 00:12:04,880
and translates these requests into

00:12:01,680 --> 00:12:04,880
unique discovery keys

00:12:05,120 --> 00:12:08,639
so in this example we've chosen to map

00:12:07,200 --> 00:12:11,519
both requests

00:12:08,639 --> 00:12:13,040
to the same key using a combination of

00:12:11,519 --> 00:12:17,200
the node id

00:12:13,040 --> 00:12:17,200
the cluster and the request type

00:12:18,959 --> 00:12:22,000
so once the aggregated key is generated

00:12:21,120 --> 00:12:24,560
for a request

00:12:22,000 --> 00:12:25,839
the request gets added into an in-memory

00:12:24,560 --> 00:12:29,920
cache

00:12:25,839 --> 00:12:31,760
with configurable ttl and size limits

00:12:29,920 --> 00:12:34,320
if there is already a response in the

00:12:31,760 --> 00:12:36,959
cache and the versioning is different

00:12:34,320 --> 00:12:38,480
xds relay will immediately return the

00:12:36,959 --> 00:12:41,760
discovery response

00:12:38,480 --> 00:12:43,839
to the sender however

00:12:41,760 --> 00:12:45,680
if there's not a response available or

00:12:43,839 --> 00:12:48,079
the versioning is the same

00:12:45,680 --> 00:12:50,720
xcs relay will maintain an open watch

00:12:48,079 --> 00:12:53,279
for this request

00:12:50,720 --> 00:12:54,880
by storing it in the cache and it will

00:12:53,279 --> 00:12:58,240
wait for a new response from the

00:12:54,880 --> 00:12:58,240
upstream management server

00:12:58,320 --> 00:13:02,880
so excess really only ever maintains a

00:13:00,720 --> 00:13:05,519
single grpc stream

00:13:02,880 --> 00:13:07,760
per cache key and this coincides with

00:13:05,519 --> 00:13:10,800
the first unique request

00:13:07,760 --> 00:13:12,800
to log a cache entry for the key

00:13:10,800 --> 00:13:14,560
the first request is propagated to the

00:13:12,800 --> 00:13:16,959
upstream management server

00:13:14,560 --> 00:13:18,320
through our upstream client and go

00:13:16,959 --> 00:13:21,680
routines and channels

00:13:18,320 --> 00:13:23,279
are used in order to

00:13:21,680 --> 00:13:26,079
await discover responses from the

00:13:23,279 --> 00:13:28,720
management server

00:13:26,079 --> 00:13:30,000
upon a response from the server xcs

00:13:28,720 --> 00:13:32,000
relay will then

00:13:30,000 --> 00:13:34,320
fan out the response to all of the xcs

00:13:32,000 --> 00:13:37,440
clients with an open watch in the cache

00:13:34,320 --> 00:13:38,959
for the specified aggregated key

00:13:37,440 --> 00:13:42,399
and then remove the watches from the

00:13:38,959 --> 00:13:44,560
cache and all of these components are

00:13:42,399 --> 00:13:49,839
orchestrated by what we internally call

00:13:44,560 --> 00:13:49,839
the orchestrator

00:13:50,720 --> 00:13:55,519
so at lyft we run a group of control

00:13:52,800 --> 00:13:58,240
plane servers on each kubernetes cluster

00:13:55,519 --> 00:13:59,519
with services distributed across each of

00:13:58,240 --> 00:14:01,519
the clusters

00:13:59,519 --> 00:14:02,560
and our control plane cluster was scaled

00:14:01,519 --> 00:14:04,399
up to run on

00:14:02,560 --> 00:14:08,079
multiple nodes in order to support the

00:14:04,399 --> 00:14:09,760
number of online clients we had at lyft

00:14:08,079 --> 00:14:11,519
with this new architecture we're running

00:14:09,760 --> 00:14:13,040
a group of excess relays on each

00:14:11,519 --> 00:14:15,680
kubernetes cluster

00:14:13,040 --> 00:14:16,800
allowing us to scale down our control

00:14:15,680 --> 00:14:18,720
plane server

00:14:16,800 --> 00:14:20,959
and refocus the control plane core logic

00:14:18,720 --> 00:14:22,959
on pre-processing and generating new xcs

00:14:20,959 --> 00:14:25,839
responses

00:14:22,959 --> 00:14:27,040
we're now also able to scale the

00:14:25,839 --> 00:14:28,959
response generation

00:14:27,040 --> 00:14:31,839
logic independently from the connection

00:14:28,959 --> 00:14:33,519
management portion

00:14:31,839 --> 00:14:35,279
in this specific example we've

00:14:33,519 --> 00:14:36,000
aggregated the request for the location

00:14:35,279 --> 00:14:38,639
service

00:14:36,000 --> 00:14:41,040
and the request for the user service two

00:14:38,639 --> 00:14:43,440
unique cache keys

00:14:41,040 --> 00:14:44,399
access relay is responsible for caching

00:14:43,440 --> 00:14:47,519
and optimize

00:14:44,399 --> 00:14:49,120
response fan out so

00:14:47,519 --> 00:14:51,519
this implies that the connections to the

00:14:49,120 --> 00:14:52,240
upstream server is also a lot smaller

00:14:51,519 --> 00:14:56,240
than

00:14:52,240 --> 00:14:56,240
they would be without the relaying type

00:14:56,839 --> 00:14:59,839
component

00:15:00,079 --> 00:15:04,480
so lyft runs all of its infrastructure

00:15:02,320 --> 00:15:06,320
on a giant vpc

00:15:04,480 --> 00:15:07,519
but we envision other interesting

00:15:06,320 --> 00:15:10,240
topologies

00:15:07,519 --> 00:15:10,839
for running axis relay on hybrid clouds

00:15:10,240 --> 00:15:14,320
and

00:15:10,839 --> 00:15:17,600
multiple vpc infrastructure setups

00:15:14,320 --> 00:15:21,040
so for example here's a topology where

00:15:17,600 --> 00:15:22,639
we run a cluster of xts relay on-prem so

00:15:21,040 --> 00:15:24,880
on this data center in another data

00:15:22,639 --> 00:15:27,279
center physically close to

00:15:24,880 --> 00:15:28,320
the onboard services while hosting the

00:15:27,279 --> 00:15:31,519
control plane server

00:15:28,320 --> 00:15:34,079
on a centralized vpc for faster services

00:15:31,519 --> 00:15:34,079
discovery

00:15:35,279 --> 00:15:42,639
now we're going to get into a demo

00:15:40,880 --> 00:15:44,560
all right in this demo we'll be running

00:15:42,639 --> 00:15:46,320
a very simple setup with a management

00:15:44,560 --> 00:15:47,519
server that just sends snapshots every

00:15:46,320 --> 00:15:50,480
10 seconds

00:15:47,519 --> 00:15:51,759
a xcs relay server and two onward

00:15:50,480 --> 00:15:54,240
clients

00:15:51,759 --> 00:15:57,120
so we'll begin by starting up our

00:15:54,240 --> 00:15:57,120
management server

00:16:01,199 --> 00:16:05,199
there we have it snapshots are now being

00:16:02,880 --> 00:16:06,560
generated every 10 seconds

00:16:05,199 --> 00:16:08,320
while that's running let's take a look

00:16:06,560 --> 00:16:09,920
at some of our configuration files that

00:16:08,320 --> 00:16:13,120
we'll be using for our onward clients

00:16:09,920 --> 00:16:13,120
and exeus relay server

00:16:17,519 --> 00:16:22,399
so we have two bootstrap files here for

00:16:19,199 --> 00:16:25,040
the onward clients

00:16:22,399 --> 00:16:27,279
and they're quite simple one of them has

00:16:25,040 --> 00:16:28,800
the node id on the client one

00:16:27,279 --> 00:16:31,120
the other one has the node id over

00:16:28,800 --> 00:16:32,000
client two they both run on slightly

00:16:31,120 --> 00:16:34,320
different ports

00:16:32,000 --> 00:16:37,279
one runs on port nineteen thousand the

00:16:34,320 --> 00:16:39,680
other one runs on port 9001

00:16:37,279 --> 00:16:40,959
but everything else is the same most

00:16:39,680 --> 00:16:44,079
notably is the

00:16:40,959 --> 00:16:46,399
cluster you notice that they both

00:16:44,079 --> 00:16:48,560
share the same staging cluster which is

00:16:46,399 --> 00:16:51,199
what we'll be using to define our xcs

00:16:48,560 --> 00:16:52,639
relay aggregation rules later on

00:16:51,199 --> 00:16:54,959
and they both designate the same control

00:16:52,639 --> 00:16:56,360
plane server to point to xcs relay

00:16:54,959 --> 00:16:59,360
running on port

00:16:56,360 --> 00:16:59,360
00:16:59,759 --> 00:17:03,440
let's just quickly confirm the bootstrap

00:17:01,440 --> 00:17:06,079
file of our second onward client

00:17:03,440 --> 00:17:06,480
as you can see it's identical except for

00:17:06,079 --> 00:17:10,240
the

00:17:06,480 --> 00:17:10,240
node id and the

00:17:10,400 --> 00:17:13,679
the port which it's running on

00:17:14,559 --> 00:17:19,839
so now let's take a look at some of our

00:17:16,000 --> 00:17:19,839
xcs relay configuration file

00:17:20,400 --> 00:17:25,520
so as i mentioned xcs relay is going to

00:17:22,480 --> 00:17:27,439
be running on port 9991

00:17:25,520 --> 00:17:28,720
it's going to be pointing to our simple

00:17:27,439 --> 00:17:31,600
control plane server

00:17:28,720 --> 00:17:33,440
that's running on port 18000 and there's

00:17:31,600 --> 00:17:34,720
some other miscellaneous server metadata

00:17:33,440 --> 00:17:39,679
including the log level

00:17:34,720 --> 00:17:39,679
cache sizing the admin endpoint etc

00:17:41,120 --> 00:17:46,240
finally let's take a look at the xcs

00:17:43,440 --> 00:17:47,840
relay aggregation rules

00:17:46,240 --> 00:17:49,600
and these rules might look quite

00:17:47,840 --> 00:17:52,720
intimidating at first but it's actually

00:17:49,600 --> 00:17:56,000
pretty easy to understand

00:17:52,720 --> 00:17:57,039
so it's going to end up generating keys

00:17:56,000 --> 00:18:00,559
that look like staging

00:17:57,039 --> 00:18:03,280
underscore eds or staging underscore cds

00:18:00,559 --> 00:18:04,400
and how that works is via these

00:18:03,280 --> 00:18:06,480
fragments so

00:18:04,400 --> 00:18:08,400
for the first fragments we look at these

00:18:06,480 --> 00:18:11,600
request types that fall under

00:18:08,400 --> 00:18:14,320
lds cds eds or rds

00:18:11,600 --> 00:18:15,440
and we apply this regex match and

00:18:14,320 --> 00:18:18,720
replace operation

00:18:15,440 --> 00:18:21,280
on the node cluster

00:18:18,720 --> 00:18:23,840
so because in our armor bootstrap files

00:18:21,280 --> 00:18:25,600
we have the node cluster set to staging

00:18:23,840 --> 00:18:27,200
this will actually always result in

00:18:25,600 --> 00:18:30,160
staging as the first

00:18:27,200 --> 00:18:30,160
cache key fragment

00:18:30,640 --> 00:18:34,000
for the second fragment it's just a

00:18:32,080 --> 00:18:37,039
static constant

00:18:34,000 --> 00:18:40,480
so if it's of type listener then

00:18:37,039 --> 00:18:43,679
we append lds as the second

00:18:40,480 --> 00:18:47,600
string fragment with cds

00:18:43,679 --> 00:18:49,760
we append this static constant cds

00:18:47,600 --> 00:18:50,799
so forth and for the very last fragment

00:18:49,760 --> 00:18:52,320
if this

00:18:50,799 --> 00:18:54,640
request type is of type welt

00:18:52,320 --> 00:18:56,559
configuration we're going to append an

00:18:54,640 --> 00:19:00,160
additional fragment that

00:18:56,559 --> 00:19:00,160
has the resource name

00:19:02,960 --> 00:19:06,160
so again all that is saying is that

00:19:04,960 --> 00:19:09,039
we're going to end up with these

00:19:06,160 --> 00:19:10,080
aggregated cache keys in fcs relay that

00:19:09,039 --> 00:19:13,760
they end up looking like

00:19:10,080 --> 00:19:16,320
staging cds or staging eds

00:19:13,760 --> 00:19:16,320
etc

00:19:16,960 --> 00:19:22,080
all right so now let's start our xcs

00:19:20,000 --> 00:19:24,000
relay server

00:19:22,080 --> 00:19:25,679
using those bootstrap configuration and

00:19:24,000 --> 00:19:27,919
aggregation rules that we just talked

00:19:25,679 --> 00:19:27,919
about

00:19:29,039 --> 00:19:33,520
okay so

00:19:34,240 --> 00:19:39,120
if we were to curl the xcs relay

00:19:37,919 --> 00:19:41,919
endpoint right now

00:19:39,120 --> 00:19:44,720
we're going to notice that the cache is

00:19:41,919 --> 00:19:44,720
going to be empty

00:19:49,760 --> 00:19:54,640
and the reason for this is that we

00:19:52,400 --> 00:19:58,400
haven't had any on the clients

00:19:54,640 --> 00:20:00,559
hitting the cache yet so there is no

00:19:58,400 --> 00:20:02,880
response being cached or any of the

00:20:00,559 --> 00:20:07,840
requests being cached

00:20:02,880 --> 00:20:07,840
so let's start our two onboard clients

00:20:13,620 --> 00:20:16,730
[Applause]

00:20:20,240 --> 00:20:22,799
this is the first client being started

00:20:21,600 --> 00:20:24,799
and you can see a bunch of activity

00:20:22,799 --> 00:20:25,679
happening in our xcs relay server since

00:20:24,799 --> 00:20:28,960
we have

00:20:25,679 --> 00:20:34,480
debug level logs turned on

00:20:28,960 --> 00:20:36,880
let's start the second client

00:20:34,480 --> 00:20:37,600
again some more activity and now if we

00:20:36,880 --> 00:20:40,960
were to run

00:20:37,600 --> 00:20:44,000
the same curl on our cache endpoint

00:20:40,960 --> 00:20:44,000
we'll see something different

00:20:47,520 --> 00:20:51,200
also note here is that we're using jq to

00:20:49,520 --> 00:20:53,520
make the output more concise for this

00:20:51,200 --> 00:20:53,520
demo

00:20:55,919 --> 00:21:03,600
so as you can see

00:21:00,799 --> 00:21:05,360
the response contains the version of the

00:21:03,600 --> 00:21:06,000
latest snapshot that was generated by

00:21:05,360 --> 00:21:10,720
the

00:21:06,000 --> 00:21:12,400
server in this case it's 95 197

00:21:10,720 --> 00:21:14,320
more seconds have passed since i've ran

00:21:12,400 --> 00:21:16,720
this query so that's why we're not

00:21:14,320 --> 00:21:17,840
seeing the latest but we can also see

00:21:16,720 --> 00:21:19,679
that

00:21:17,840 --> 00:21:22,000
both onward clients are cash in the

00:21:19,679 --> 00:21:23,520
requests

00:21:22,000 --> 00:21:26,159
all right are all my client two and all

00:21:23,520 --> 00:21:26,159
the client one

00:21:28,480 --> 00:21:32,640
so since these clients fall under the

00:21:31,360 --> 00:21:34,640
same aggregation rule

00:21:32,640 --> 00:21:36,880
if we were to observe the stats we'd

00:21:34,640 --> 00:21:38,880
also know that there's only one grpc

00:21:36,880 --> 00:21:42,640
stream being made to our upstream server

00:21:38,880 --> 00:21:44,159
despite there being two onward clients

00:21:42,640 --> 00:21:45,919
we can also validate that the online

00:21:44,159 --> 00:21:46,799
clients have received valid cds

00:21:45,919 --> 00:21:50,960
information

00:21:46,799 --> 00:21:50,960
by querying on voice admin endpoint

00:21:54,080 --> 00:21:58,400
so this is querying our second onward

00:21:55,840 --> 00:22:00,080
client and indeed you can see the latest

00:21:58,400 --> 00:22:02,240
cluster information if we were to clear

00:22:00,080 --> 00:22:05,280
the other onward client we should

00:22:02,240 --> 00:22:06,480
receive the same information

00:22:05,280 --> 00:22:09,440
you can see it very slightly because

00:22:06,480 --> 00:22:10,559
we've generated a new snapshot since but

00:22:09,440 --> 00:22:13,600
if we

00:22:10,559 --> 00:22:14,159
quickly run both in sequence you notice

00:22:13,600 --> 00:22:19,120
that

00:22:14,159 --> 00:22:20,720
their cluster information is the same

00:22:19,120 --> 00:22:22,320
and this example is available on our

00:22:20,720 --> 00:22:24,159
github if you would like to try it out

00:22:22,320 --> 00:22:27,840
for yourself

00:22:24,159 --> 00:22:27,840
please let us know your thoughts thanks

00:22:33,039 --> 00:22:36,159
so we're excited to announce that in the

00:22:34,640 --> 00:22:39,120
next few weeks here we're going to be

00:22:36,159 --> 00:22:41,200
releasing version 1 of xts relay

00:22:39,120 --> 00:22:42,559
and this covers the mvp mechanisms that

00:22:41,200 --> 00:22:46,320
we showed in the demo

00:22:42,559 --> 00:22:46,880
and earlier so beyond that we're looking

00:22:46,320 --> 00:22:48,960
to create

00:22:46,880 --> 00:22:51,200
extensions including a few here that

00:22:48,960 --> 00:22:53,600
we're pretty excited about

00:22:51,200 --> 00:22:55,840
one is the state of the world to delta

00:22:53,600 --> 00:22:57,679
xcs transformation

00:22:55,840 --> 00:23:00,480
very few control planes in the wild have

00:22:57,679 --> 00:23:03,600
implemented support for incremental

00:23:00,480 --> 00:23:05,440
despite big performance gains so rather

00:23:03,600 --> 00:23:08,240
than having all control plane servers

00:23:05,440 --> 00:23:09,919
make this migration xcs relay can

00:23:08,240 --> 00:23:13,760
implicitly make the conversion

00:23:09,919 --> 00:23:13,760
and cache the response delta

00:23:14,159 --> 00:23:19,039
another is api driven configuration

00:23:17,200 --> 00:23:21,360
rather than having xds relay maintain

00:23:19,039 --> 00:23:22,880
connections to the upstream server

00:23:21,360 --> 00:23:25,280
we want to make it possible for

00:23:22,880 --> 00:23:26,400
operators to directly write to the xds

00:23:25,280 --> 00:23:28,080
relay cache

00:23:26,400 --> 00:23:31,280
in a push model when there's updated

00:23:28,080 --> 00:23:31,280
configuration information

00:23:32,240 --> 00:23:36,559
another one that we're particularly

00:23:33,520 --> 00:23:38,320
excited about is endpoint subsetting

00:23:36,559 --> 00:23:40,720
so in a topology that we mentioned

00:23:38,320 --> 00:23:42,960
earlier it might not be a deal for

00:23:40,720 --> 00:23:44,320
xcs clients to be aware of clients

00:23:42,960 --> 00:23:47,279
running in a different vpc

00:23:44,320 --> 00:23:48,400
or data center similar to the

00:23:47,279 --> 00:23:49,679
aggregation rules

00:23:48,400 --> 00:23:51,919
we're looking at creating rule based

00:23:49,679 --> 00:23:54,960
configuration where operators can

00:23:51,919 --> 00:23:57,840
use xcs relay to send back a subset

00:23:54,960 --> 00:23:59,279
of the eds information rather than all

00:23:57,840 --> 00:24:02,080
endpoints that exist from the control

00:23:59,279 --> 00:24:02,080
plane response

00:24:02,559 --> 00:24:06,880
another interesting use case is blue

00:24:04,240 --> 00:24:08,559
green control plane deploys

00:24:06,880 --> 00:24:10,559
so being able to use xcs relay to

00:24:08,559 --> 00:24:12,240
determine a percentage of traffic

00:24:10,559 --> 00:24:14,960
that should roll out to the new control

00:24:12,240 --> 00:24:14,960
plane server

00:24:16,480 --> 00:24:19,760
and this list goes on in the interest of

00:24:18,559 --> 00:24:22,320
time we won't be able to cover

00:24:19,760 --> 00:24:23,760
them all today but as you can see

00:24:22,320 --> 00:24:25,760
there's plenty of directions that we

00:24:23,760 --> 00:24:27,360
could and want to take this project

00:24:25,760 --> 00:24:28,960
so we're always looking for contributors

00:24:27,360 --> 00:24:30,559
and love talking to people curious about

00:24:28,960 --> 00:24:33,520
control plan implementations

00:24:30,559 --> 00:24:35,200
and their use cases please reach out to

00:24:33,520 --> 00:24:38,799
one of us directly or

00:24:35,200 --> 00:24:38,799
visit the envoy slack here

00:24:38,960 --> 00:24:42,240
if you'd like to talk with us more

00:24:42,400 --> 00:24:46,159
lyft is also looking for engineers that

00:24:44,320 --> 00:24:47,520
have onboard experience so if that's

00:24:46,159 --> 00:24:50,400
something that you're interested in

00:24:47,520 --> 00:24:52,640
please reach out to me or jody directly

00:24:50,400 --> 00:24:56,799
thanks

00:24:52,640 --> 00:24:56,799
awesome hi everyone i think we're both

00:24:58,840 --> 00:25:02,880
live

00:25:01,039 --> 00:25:04,559
in the context of endpoint subsetting

00:25:02,880 --> 00:25:06,400
where do you draw the line between logic

00:25:04,559 --> 00:25:09,679
that belongs in xcs relay and logic that

00:25:06,400 --> 00:25:09,679
should be in the control plane

00:25:10,640 --> 00:25:14,240
personally i think it's going to vary by

00:25:12,080 --> 00:25:17,679
a lot of the use cases that

00:25:14,240 --> 00:25:19,279
your company is implementing i think

00:25:17,679 --> 00:25:20,880
the part that we want to implement in

00:25:19,279 --> 00:25:23,520
exclusive relay is if

00:25:20,880 --> 00:25:25,200
it can be defined based on rules that

00:25:23,520 --> 00:25:26,559
anyone might have to live in xts relay

00:25:25,200 --> 00:25:28,799
but if there is

00:25:26,559 --> 00:25:30,159
too much custom logic that should be

00:25:28,799 --> 00:25:32,400
generated from

00:25:30,159 --> 00:25:33,919
service metadata based on your company's

00:25:32,400 --> 00:25:36,159
logic then it should fall in the control

00:25:33,919 --> 00:25:36,159
plane

00:25:37,120 --> 00:25:41,120
the plug-in model also allows us to

00:25:40,000 --> 00:25:43,919
define custom

00:25:41,120 --> 00:25:44,960
ways of splitting the subsetting line

00:25:43,919 --> 00:25:49,200
points

00:25:44,960 --> 00:25:49,200
um so yeah that should help too

00:25:52,159 --> 00:25:55,440
do they maybe you can take this next one

00:25:53,600 --> 00:25:57,120
just work a lot on the

00:25:55,440 --> 00:25:58,720
yeah in case the control plane is not

00:25:57,120 --> 00:26:00,880
present momentarily we'll always

00:25:58,720 --> 00:26:03,919
continue to receive configuration

00:26:00,880 --> 00:26:05,600
um the htc delay all this depends on the

00:26:03,919 --> 00:26:08,159
upstream but if the upstream is not

00:26:05,600 --> 00:26:10,480
present we have pre-tries and back off

00:26:08,159 --> 00:26:12,799
mechanisms built in so that we'll keep

00:26:10,480 --> 00:26:15,039
trying until the controller comes back

00:26:12,799 --> 00:26:16,240
but it will keep serving contribution

00:26:15,039 --> 00:26:18,799
from the cash

00:26:16,240 --> 00:26:20,559
uh to the sidecar so the fleet will

00:26:18,799 --> 00:26:23,360
continue operating

00:26:20,559 --> 00:26:39,840
um and there will be no disruption until

00:26:23,360 --> 00:26:39,840
the back in the total comes back

00:26:44,940 --> 00:26:48,199
[Music]

00:26:50,559 --> 00:26:56,000
how widely has this been used in a while

00:26:53,600 --> 00:26:57,360
because as we haven't issued an initial

00:26:56,000 --> 00:26:59,520
release yet

00:26:57,360 --> 00:27:00,799
i would say there's no customers using

00:26:59,520 --> 00:27:02,720
in the wild we have a few

00:27:00,799 --> 00:27:04,320
people from other companies that are

00:27:02,720 --> 00:27:07,600
testing it for us and we're

00:27:04,320 --> 00:27:10,720
internally mixing it within lyft but

00:27:07,600 --> 00:27:12,960
so far it's sort of in a early alpha

00:27:10,720 --> 00:27:15,440
stage

00:27:12,960 --> 00:27:16,080
we are uh serving our staging traffic on

00:27:15,440 --> 00:27:18,720
this

00:27:16,080 --> 00:27:20,399
at this point and once again production

00:27:18,720 --> 00:27:22,799
will probably do a mvp

00:27:20,399 --> 00:27:22,799
release

00:27:32,880 --> 00:27:36,640
in case the back end control plane comes

00:27:34,720 --> 00:27:37,279
back will it invaded the caching delay

00:27:36,640 --> 00:27:39,600
so

00:27:37,279 --> 00:27:41,520
yes uh when the back-end control thing

00:27:39,600 --> 00:27:42,799
comes back it will be a new stream from

00:27:41,520 --> 00:27:45,279
exchange delay to the

00:27:42,799 --> 00:27:46,080
back-end control plane as if everything

00:27:45,279 --> 00:27:48,320
is fresh

00:27:46,080 --> 00:28:03,840
so whatever the version updated version

00:27:48,320 --> 00:28:03,840
there is it will reflect in the cache

00:28:15,440 --> 00:28:21,290
i guess we're at time almost uh unless

00:28:19,200 --> 00:28:24,369
there's any other questions

00:28:21,290 --> 00:28:24,369
[Music]

00:28:25,120 --> 00:28:28,480
how many points do you have in your

00:28:26,799 --> 00:28:31,760
clusters

00:28:28,480 --> 00:28:35,360
uh it varies uh

00:28:31,760 --> 00:28:37,520
we had times when we are like 50k

00:28:35,360 --> 00:28:38,559
or something but yeah i have no exact

00:28:37,520 --> 00:28:45,840
numbers to

00:28:38,559 --> 00:28:45,840
share at this point

00:28:53,679 --> 00:28:57,679
yeah probably we can take this offline

00:28:55,919 --> 00:28:58,159
you could engage with us on the xds

00:28:57,679 --> 00:29:02,240
relay

00:28:58,159 --> 00:29:05,919
slack or on github uh i am afraid of the

00:29:02,240 --> 00:29:09,039
cut off at 130 so it was great

00:29:05,919 --> 00:29:09,600
uh sharing our information with you

00:29:09,039 --> 00:29:15,039
today

00:29:09,600 --> 00:29:15,039
and thank you yeah thanks everyone

00:29:16,440 --> 00:29:19,440

YouTube URL: https://www.youtube.com/watch?v=sdKklehKW78


