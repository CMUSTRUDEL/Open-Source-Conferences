Title: Using VPP as Envoy's Network Stack - Florin Coras
Publication date: 2020-10-21
Playlist: EnvoyCon 2020 - Virtual
Description: 
	Using VPP as Envoy's Network Stack - Florin Coras

Vector Packet Processing (VPP), part of fd.io, is a high performance, layer 2-7 scalable and multi-platform user space networking stack. Typical VPP use cases include, amongst others, deployments as a vSwitch/Router, Firewall, Load Balancer and TCP Proxy. This talk will discuss how some of the recent socket layer API changes can be leveraged to cleanly integrate Envoy with VPP's socket layer, the VPP Comms Library (VCL), and some of the potential benefits thereof.
Captions: 
	00:00:00,960 --> 00:00:04,400
hi everyone my name is florian korres

00:00:02,879 --> 00:00:07,680
i'm a cisco technical lead

00:00:04,400 --> 00:00:10,000
also an fdio vpp project container

00:00:07,680 --> 00:00:12,160
and in today's talk i'd like to give you

00:00:10,000 --> 00:00:13,440
a high level overview of the benefits of

00:00:12,160 --> 00:00:16,320
using bbp

00:00:13,440 --> 00:00:16,720
as on voice network stack my background

00:00:16,320 --> 00:00:18,720
is

00:00:16,720 --> 00:00:21,119
in networking in particular i'm one of

00:00:18,720 --> 00:00:22,480
the co-creators of vbp's whole stack so

00:00:21,119 --> 00:00:25,199
i typically talk about

00:00:22,480 --> 00:00:26,240
transparent protocols and socket layer

00:00:25,199 --> 00:00:28,880
implementations

00:00:26,240 --> 00:00:30,000
however today i'll mainly focus on how

00:00:28,880 --> 00:00:32,960
envoy can leverage

00:00:30,000 --> 00:00:33,760
user space networking and some of the

00:00:32,960 --> 00:00:37,040
benefits

00:00:33,760 --> 00:00:39,440
thereof now before we dive in

00:00:37,040 --> 00:00:40,160
um and in the interest of those of you

00:00:39,440 --> 00:00:42,840
who are not

00:00:40,160 --> 00:00:44,160
familiar with vpp a very quick

00:00:42,840 --> 00:00:48,079
introduction

00:00:44,160 --> 00:00:50,079
vp is an l2 l7 networking stack which

00:00:48,079 --> 00:00:51,680
at its core leverages two important

00:00:50,079 --> 00:00:54,000
ideas vectorized

00:00:51,680 --> 00:00:55,440
packet processing and the modeling of

00:00:54,000 --> 00:00:57,760
the forwarding

00:00:55,440 --> 00:00:58,559
as a directed graph of nodes when done

00:00:57,760 --> 00:01:01,120
correctly

00:00:58,559 --> 00:01:03,039
this to ensure really efficient use of a

00:01:01,120 --> 00:01:06,080
cpus caching hierarchy

00:01:03,039 --> 00:01:08,880
and consequently minimal overhead per

00:01:06,080 --> 00:01:11,760
packet when doing software forwarding

00:01:08,880 --> 00:01:12,000
but another really important aspect of

00:01:11,760 --> 00:01:14,479
this

00:01:12,000 --> 00:01:15,600
approach is composability that is

00:01:14,479 --> 00:01:18,320
starting from these

00:01:15,600 --> 00:01:20,320
these simple ideas one can implement all

00:01:18,320 --> 00:01:23,600
types of network functions

00:01:20,320 --> 00:01:25,360
from device drivers to l4 features

00:01:23,600 --> 00:01:26,720
and then tie them together to build a

00:01:25,360 --> 00:01:29,759
really efficient

00:01:26,720 --> 00:01:32,960
full network processing pipeline

00:01:29,759 --> 00:01:35,280
now looking at this from a last abstract

00:01:32,960 --> 00:01:38,000
standpoint it might be worth noting that

00:01:35,280 --> 00:01:40,159
vpp is typically used together with dpdk

00:01:38,000 --> 00:01:41,439
so it supports a large set of network

00:01:40,159 --> 00:01:44,000
interfaces

00:01:41,439 --> 00:01:44,880
but it should be noted that it also has

00:01:44,000 --> 00:01:47,759
a smaller set

00:01:44,880 --> 00:01:48,320
of really efficient native drivers it

00:01:47,759 --> 00:01:51,040
supports

00:01:48,320 --> 00:01:53,119
l2 switching bridging ip forwarding

00:01:51,040 --> 00:01:54,880
virtual routing and forwarding

00:01:53,119 --> 00:01:57,680
that is vrf so it has the right

00:01:54,880 --> 00:02:01,200
constructs for iplayer multi-tenancy

00:01:57,680 --> 00:02:01,759
but in addition to these basic l2 and l3

00:02:01,200 --> 00:02:04,000
functions

00:02:01,759 --> 00:02:05,040
it also supports a multitude of

00:02:04,000 --> 00:02:07,680
additional features

00:02:05,040 --> 00:02:09,200
and just to name a few a very efficient

00:02:07,680 --> 00:02:12,800
ibsec implementation

00:02:09,200 --> 00:02:14,879
acl nat npls segment routing

00:02:12,800 --> 00:02:16,879
and several flavors of throwing

00:02:14,879 --> 00:02:20,720
protocols things like pxlan

00:02:16,879 --> 00:02:21,680
and lisp now on top of the networking

00:02:20,720 --> 00:02:24,400
stack vbp

00:02:21,680 --> 00:02:24,879
also implements a custom host stack

00:02:24,400 --> 00:02:27,599
built

00:02:24,879 --> 00:02:29,520
and optimized in a similar fashion as

00:02:27,599 --> 00:02:31,840
one might expect it supports

00:02:29,520 --> 00:02:32,560
commonly used transports like tcp and

00:02:31,840 --> 00:02:36,480
udp

00:02:32,560 --> 00:02:38,160
but also tls and quick the session or

00:02:36,480 --> 00:02:40,000
socket layer provides a number of

00:02:38,160 --> 00:02:42,720
features but perhaps the most

00:02:40,000 --> 00:02:44,239
important for the context of the stock

00:02:42,720 --> 00:02:47,280
is the shared memory infra

00:02:44,239 --> 00:02:48,239
that can be used to exchange i o and

00:02:47,280 --> 00:02:51,120
control events

00:02:48,239 --> 00:02:51,840
with external applications using per

00:02:51,120 --> 00:02:55,720
worker

00:02:51,840 --> 00:02:58,640
message queues and finally to simplify

00:02:55,720 --> 00:03:02,159
interoperability with applications

00:02:58,640 --> 00:03:05,280
vpp provides a comms library or vcl

00:03:02,159 --> 00:03:09,120
which exposes posix like

00:03:05,280 --> 00:03:11,360
apis so i guess that by

00:03:09,120 --> 00:03:13,280
this point some of you may be asking the

00:03:11,360 --> 00:03:16,239
inescapable question

00:03:13,280 --> 00:03:17,680
why yet another host stack and you'd be

00:03:16,239 --> 00:03:18,959
right to ask that because from a

00:03:17,680 --> 00:03:21,760
functional perspective

00:03:18,959 --> 00:03:22,400
linux is obviously the one stack to use

00:03:21,760 --> 00:03:25,040
however

00:03:22,400 --> 00:03:26,720
because linux's networking stack was

00:03:25,040 --> 00:03:29,200
designed around a single pass

00:03:26,720 --> 00:03:30,159
run to completion model per packet

00:03:29,200 --> 00:03:32,799
performance

00:03:30,159 --> 00:03:33,200
is limited this is especially noticeable

00:03:32,799 --> 00:03:35,040
when

00:03:33,200 --> 00:03:36,239
hardware acceleration cannot be

00:03:35,040 --> 00:03:38,480
leveraged

00:03:36,239 --> 00:03:39,599
furthermore in addition to the

00:03:38,480 --> 00:03:41,840
performance benefit

00:03:39,599 --> 00:03:42,640
the fact that the stack is in user space

00:03:41,840 --> 00:03:45,280
could be

00:03:42,640 --> 00:03:46,400
utilized to optimize interactions and

00:03:45,280 --> 00:03:49,440
perhaps minimize

00:03:46,400 --> 00:03:50,640
data copies also because the whole

00:03:49,440 --> 00:03:53,439
protocol stack

00:03:50,640 --> 00:03:54,720
is packaged with the application it

00:03:53,439 --> 00:03:57,760
could potentially

00:03:54,720 --> 00:03:59,439
be customized or extended in certain

00:03:57,760 --> 00:04:01,200
situations

00:03:59,439 --> 00:04:03,599
one can certainly imagine scenarios

00:04:01,200 --> 00:04:04,239
where the sockets provide more context

00:04:03,599 --> 00:04:07,200
data to

00:04:04,239 --> 00:04:09,439
the underlying layers with the aim of

00:04:07,200 --> 00:04:12,799
improving network utilization

00:04:09,439 --> 00:04:15,200
by the apps also note that all of

00:04:12,799 --> 00:04:16,239
this does not preclude coordinates

00:04:15,200 --> 00:04:19,759
integration

00:04:16,239 --> 00:04:23,680
in fact vbp can be used as a data plane

00:04:19,759 --> 00:04:26,960
um by cnns by calico

00:04:23,680 --> 00:04:29,360
so how exactly does envoy

00:04:26,960 --> 00:04:30,560
integrate with vcl and what sort of

00:04:29,360 --> 00:04:33,680
changes were

00:04:30,560 --> 00:04:35,199
needed well rather intuitively the first

00:04:33,680 --> 00:04:36,720
step was to make sure that envoy

00:04:35,199 --> 00:04:38,320
components do not make

00:04:36,720 --> 00:04:40,160
any assumptions with respect to the

00:04:38,320 --> 00:04:43,199
underlying socket layer

00:04:40,160 --> 00:04:44,800
and consequently always use generic

00:04:43,199 --> 00:04:46,720
socket interfaces

00:04:44,800 --> 00:04:47,919
such that they can potentially

00:04:46,720 --> 00:04:50,720
interoperate with

00:04:47,919 --> 00:04:51,120
custom socket layer implementations once

00:04:50,720 --> 00:04:53,759
they're

00:04:51,120 --> 00:04:54,800
available obviously this is not exactly

00:04:53,759 --> 00:04:57,919
glamorous work

00:04:54,800 --> 00:04:59,360
as the changes are not so much features

00:04:57,919 --> 00:05:02,240
as they are focused

00:04:59,360 --> 00:05:03,199
on api refactoring still out of the set

00:05:02,240 --> 00:05:05,360
of changes

00:05:03,199 --> 00:05:06,479
that have gone in perhaps the most

00:05:05,360 --> 00:05:08,960
notable are

00:05:06,479 --> 00:05:10,080
the fact that as a core rule we now

00:05:08,960 --> 00:05:12,639
avoid using

00:05:10,080 --> 00:05:13,840
raw file descriptors anywhere in the

00:05:12,639 --> 00:05:16,639
code eye handles

00:05:13,840 --> 00:05:17,440
still expose the fds but last time i've

00:05:16,639 --> 00:05:19,440
checked

00:05:17,440 --> 00:05:20,639
we've managed to clean them to a point

00:05:19,440 --> 00:05:22,840
where they were

00:05:20,639 --> 00:05:24,000
only used in i believe a couple of

00:05:22,840 --> 00:05:26,639
places

00:05:24,000 --> 00:05:28,479
we added support for pluggable i o

00:05:26,639 --> 00:05:29,759
handle factories that is support for

00:05:28,479 --> 00:05:32,560
multiple types

00:05:29,759 --> 00:05:33,840
of sockets another interesting

00:05:32,560 --> 00:05:36,400
consequence of the

00:05:33,840 --> 00:05:38,000
first point is that file event creation

00:05:36,400 --> 00:05:41,039
is now delegated to

00:05:38,000 --> 00:05:43,440
i o handle implementations so as a

00:05:41,039 --> 00:05:45,520
desired side effect the socket layer

00:05:43,440 --> 00:05:46,240
that provides the i o handle is now the

00:05:45,520 --> 00:05:49,280
one that

00:05:46,240 --> 00:05:52,000
decides how events are created

00:05:49,280 --> 00:05:52,560
or in other words socket events are no

00:05:52,000 --> 00:05:55,600
longer

00:05:52,560 --> 00:05:59,199
tightly coupled with lib event

00:05:55,600 --> 00:06:01,520
and finally an interesting scenario

00:05:59,199 --> 00:06:02,240
that might serve as an example going

00:06:01,520 --> 00:06:04,880
forward

00:06:02,240 --> 00:06:07,120
was tls which mainly for convenience

00:06:04,880 --> 00:06:10,639
reasons relied on bios that needed

00:06:07,120 --> 00:06:12,720
explicit access to the fd it eventually

00:06:10,639 --> 00:06:15,280
turned out that writing a custom bio

00:06:12,720 --> 00:06:16,240
that uses the i o handle as opposed to

00:06:15,280 --> 00:06:18,160
the fd

00:06:16,240 --> 00:06:19,600
is relatively straightforward so we

00:06:18,160 --> 00:06:22,960
actually switched

00:06:19,600 --> 00:06:23,680
to that now all of these changes are

00:06:22,960 --> 00:06:26,160
enough

00:06:23,680 --> 00:06:28,240
to allow the implementation of a vcl

00:06:26,160 --> 00:06:28,720
specific socket interface but they still

00:06:28,240 --> 00:06:31,199
leave

00:06:28,720 --> 00:06:33,520
one more problem to be solved namely

00:06:31,199 --> 00:06:36,160
both libivant and vcl

00:06:33,520 --> 00:06:38,319
want to handle the async polling and the

00:06:36,160 --> 00:06:40,400
dispatching of the i o handles but only

00:06:38,319 --> 00:06:42,639
one of them can be the main dispatcher

00:06:40,400 --> 00:06:44,080
so the solution to this problem is to

00:06:42,639 --> 00:06:47,360
leave control to lib event

00:06:44,080 --> 00:06:50,319
and to register event of the um

00:06:47,360 --> 00:06:51,840
the event of the associated to a vcl

00:06:50,319 --> 00:06:55,039
workers message queue

00:06:51,840 --> 00:06:57,840
with lib event if you recall the mqs are

00:06:55,039 --> 00:06:59,599
used by vp to convey i o and control

00:06:57,840 --> 00:07:02,639
events to vcl

00:06:59,599 --> 00:07:05,039
um and the event is d is used to signal

00:07:02,639 --> 00:07:06,639
enqueue transitions from empty to

00:07:05,039 --> 00:07:09,280
non-empty state

00:07:06,639 --> 00:07:10,639
this ultimately means that bpp uh

00:07:09,280 --> 00:07:14,240
generated events

00:07:10,639 --> 00:07:17,599
force lib event to hand over control to

00:07:14,240 --> 00:07:20,639
the vcl interface which for each

00:07:17,599 --> 00:07:21,280
envoy worker uses a locally maintained

00:07:20,639 --> 00:07:25,360
epo

00:07:21,280 --> 00:07:29,360
fd to pull or pull events from vcl

00:07:25,360 --> 00:07:32,000
and subsequently dispatch them

00:07:29,360 --> 00:07:33,840
now these are just the stepping stones

00:07:32,000 --> 00:07:37,199
for the envoy vcl integration

00:07:33,840 --> 00:07:39,840
and uh as first next steps the plan is

00:07:37,199 --> 00:07:41,919
to further optimize the performance

00:07:39,840 --> 00:07:43,039
the lowest hanging through here are the

00:07:41,919 --> 00:07:45,520
read operations

00:07:43,039 --> 00:07:46,720
as vcl could pass pointers to socket

00:07:45,520 --> 00:07:49,280
data

00:07:46,720 --> 00:07:50,080
in the shape of buffer fragments instead

00:07:49,280 --> 00:07:53,520
of doing

00:07:50,080 --> 00:07:55,919
a full copy now the groundwork for this

00:07:53,520 --> 00:07:57,039
is already done what's left is the

00:07:55,919 --> 00:07:59,199
actual

00:07:57,039 --> 00:08:00,080
integration and speaking about

00:07:59,199 --> 00:08:02,240
performance

00:08:00,080 --> 00:08:03,680
to evaluate the potential benefits of

00:08:02,240 --> 00:08:06,879
this integration i built

00:08:03,680 --> 00:08:08,240
the following topology wherein wrk

00:08:06,879 --> 00:08:11,599
connects to vcl

00:08:08,240 --> 00:08:13,919
and envoy which performs http routing

00:08:11,599 --> 00:08:15,440
to a back-end nginx now this type of

00:08:13,919 --> 00:08:18,160
scenario might not be relevant

00:08:15,440 --> 00:08:19,840
in practice and in fact i'd be delighted

00:08:18,160 --> 00:08:21,840
to learn if that's the case and also

00:08:19,840 --> 00:08:25,440
what type of scenarios

00:08:21,840 --> 00:08:26,080
would um be interesting for those who

00:08:25,440 --> 00:08:29,120
actively

00:08:26,080 --> 00:08:30,560
deploy envoy nonetheless for the purpose

00:08:29,120 --> 00:08:32,800
of this experiment

00:08:30,560 --> 00:08:33,839
this is ideal because it gives us an

00:08:32,800 --> 00:08:37,279
idea of how many

00:08:33,839 --> 00:08:40,719
bdp workers are needed to load envoy

00:08:37,279 --> 00:08:43,760
and an upper bound on performance now

00:08:40,719 --> 00:08:44,080
at a glance these results show us that

00:08:43,760 --> 00:08:47,519
for

00:08:44,080 --> 00:08:50,399
an equal number of cores

00:08:47,519 --> 00:08:51,920
one vbp worker is actually enough to

00:08:50,399 --> 00:08:54,000
outperform the kernel by

00:08:51,920 --> 00:08:55,040
a significant margin that is performance

00:08:54,000 --> 00:08:58,399
seems to be good

00:08:55,040 --> 00:08:59,200
20 to 40 percent better and to scale

00:08:58,399 --> 00:09:02,080
pretty well

00:08:59,200 --> 00:09:03,120
however after a certain point about four

00:09:02,080 --> 00:09:06,320
to five workers

00:09:03,120 --> 00:09:09,440
performance does not scale linearly and

00:09:06,320 --> 00:09:12,480
it behaves somewhat worse for larger

00:09:09,440 --> 00:09:15,680
payloads albeit it should be noted that

00:09:12,480 --> 00:09:18,240
uh tso4 vpp was not enabled in

00:09:15,680 --> 00:09:20,240
in this scenario so results are really

00:09:18,240 --> 00:09:21,360
encouraging but there are still

00:09:20,240 --> 00:09:23,360
some things that need further

00:09:21,360 --> 00:09:27,839
investigation for a better um

00:09:23,360 --> 00:09:30,000
understanding so with that

00:09:27,839 --> 00:09:32,959
um should you be interested in further

00:09:30,000 --> 00:09:35,519
exploring avoid vpp integration please

00:09:32,959 --> 00:09:36,560
give the code a try for more in-depth

00:09:35,519 --> 00:09:39,760
conversations

00:09:36,560 --> 00:09:40,720
you should um be able to grab me on one

00:09:39,760 --> 00:09:43,440
of envoy's

00:09:40,720 --> 00:09:44,800
slack channels and before i conclude i'd

00:09:43,440 --> 00:09:46,959
like to quickly say

00:09:44,800 --> 00:09:48,240
thank you to matt and the whole

00:09:46,959 --> 00:09:51,360
community

00:09:48,240 --> 00:09:52,959
lizen antonio dragyan just to name a few

00:09:51,360 --> 00:09:55,600
for the constant support and

00:09:52,959 --> 00:09:56,480
openness towards the refactoring effort

00:09:55,600 --> 00:09:58,480
and with that

00:09:56,480 --> 00:10:02,720
thank you very much for your attention

00:09:58,480 --> 00:10:02,720

YouTube URL: https://www.youtube.com/watch?v=AUVuUevPzZ4


