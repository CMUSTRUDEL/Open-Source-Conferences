Title: Tutorial: Introduction to Using the Container Storage Interface (CSI) Primitives - Michael Mattsson
Publication date: 2020-11-23
Playlist: KubeCon + CloudNativeCon North America 2020 - Virtual
Description: 
	Don’t miss out! Join us at our upcoming event: KubeCon + CloudNativeCon Europe 2021 Virtual from May 4–7, 2021. Learn more at https://kubecon.io. The conference features presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects.

Tutorial: Introduction to Using the Container Storage Interface (CSI) Primitives - Michael Mattsson, HPE  

The Container Storage Interface (CSI) does not only allow dynamic provisioning of Persistent Volumes from various vendors. It’s a wealth of new API objects that can perform various data management tasks through kubectl. In this end user focused session we’ll inform ourselves of the current status of CSI capabilities and demonstrate a few pragmatic use case of each individual feature. Learn about inline ephemeral volumes, volume expansion, raw block volumes and volume snapshot classes that will allow cloning and restoring of volumes — all with practical examples that can be broadly applied to many of the backend CSI drivers available. We’ll also discuss the anatomy of the already present primitives, Storage Class, Persistent Volume Claim and Persistent Volume for completeness. 

https://sched.co/ekFc
Captions: 
	00:00:01,839 --> 00:00:05,040
hi everyone uh welcome to this tutorial

00:00:04,080 --> 00:00:06,799
well i will

00:00:05,040 --> 00:00:08,080
introduce the container storage

00:00:06,799 --> 00:00:10,800
interface primitives

00:00:08,080 --> 00:00:12,320
and how to use those in kubernetes my

00:00:10,800 --> 00:00:14,559
name is michael matson

00:00:12,320 --> 00:00:16,400
i'm a tech marketing engineer and master

00:00:14,559 --> 00:00:17,520
technologist with the hula packet

00:00:16,400 --> 00:00:20,000
enterprise

00:00:17,520 --> 00:00:21,199
i'm presenting this at cubecon virtual

00:00:20,000 --> 00:00:23,840
00:00:21,199 --> 00:00:25,599
and if you're watching this live thank

00:00:23,840 --> 00:00:26,960
you so much for hanging in there this is

00:00:25,599 --> 00:00:29,279
on the last day

00:00:26,960 --> 00:00:30,160
and if you're watching this as a rerun

00:00:29,279 --> 00:00:32,960
thank you so much

00:00:30,160 --> 00:00:35,680
for for watching this content i hope you

00:00:32,960 --> 00:00:39,440
find it interesting

00:00:35,680 --> 00:00:40,640
so um this tutorial is basically all

00:00:39,440 --> 00:00:42,160
about csi

00:00:40,640 --> 00:00:44,800
and what you can do with it in

00:00:42,160 --> 00:00:47,120
kubernetes and that is sort of

00:00:44,800 --> 00:00:48,960
the introduction to csi i'm going to

00:00:47,120 --> 00:00:49,680
talk about some of the csi drivers that

00:00:48,960 --> 00:00:52,879
are out there

00:00:49,680 --> 00:00:54,960
and what csi is the the

00:00:52,879 --> 00:00:56,079
second part of the presentation we'll

00:00:54,960 --> 00:00:57,120
talk a little bit about dynamic

00:00:56,079 --> 00:00:59,280
provisioning of

00:00:57,120 --> 00:01:00,640
persistent volumes in kubernetes it i

00:00:59,280 --> 00:01:01,280
think it's important that we kind of

00:01:00,640 --> 00:01:03,920
nail down

00:01:01,280 --> 00:01:05,519
the basics before we go into the more

00:01:03,920 --> 00:01:07,119
advanced topics

00:01:05,519 --> 00:01:09,360
and i also want to talk a little bit

00:01:07,119 --> 00:01:10,640
about how parts and controllers attach

00:01:09,360 --> 00:01:12,880
to persistent storage

00:01:10,640 --> 00:01:14,240
as that is also a very um important

00:01:12,880 --> 00:01:17,600
primitive to understand

00:01:14,240 --> 00:01:19,280
while working with persistent storage um

00:01:17,600 --> 00:01:22,000
the more fun stuff kind of begins when

00:01:19,280 --> 00:01:24,240
we start talking about csi snapshots

00:01:22,000 --> 00:01:26,640
and using data sources in your

00:01:24,240 --> 00:01:28,479
persistent volume claims uh to be able

00:01:26,640 --> 00:01:31,759
to clone external storage

00:01:28,479 --> 00:01:32,960
into a new pod and leverage data sets

00:01:31,759 --> 00:01:36,479
that already exist

00:01:32,960 --> 00:01:37,920
uh on your storage system uh using raw

00:01:36,479 --> 00:01:41,360
block volumes is something that

00:01:37,920 --> 00:01:42,640
uh is uh introduced in csi as well has

00:01:41,360 --> 00:01:44,479
been around for a while

00:01:42,640 --> 00:01:47,280
and i'm going to show you how that works

00:01:44,479 --> 00:01:51,520
and how those different use cases

00:01:47,280 --> 00:01:54,079
around using raw block volumes work

00:01:51,520 --> 00:01:55,280
another interesting concept is using

00:01:54,079 --> 00:01:58,880
ephemeral volumes

00:01:55,280 --> 00:02:01,119
uh with the with your uh with your pods

00:01:58,880 --> 00:02:03,520
and that basically makes your

00:02:01,119 --> 00:02:04,479
external persistent storage volume act

00:02:03,520 --> 00:02:06,240
like it

00:02:04,479 --> 00:02:08,239
is a container right and there are

00:02:06,240 --> 00:02:11,280
various different ways on how to

00:02:08,239 --> 00:02:13,440
attach those ephemeral volumes to your

00:02:11,280 --> 00:02:15,920
uh to your parts and and we're going to

00:02:13,440 --> 00:02:18,239
talk a little bit about how that works

00:02:15,920 --> 00:02:19,440
uh at the end of the at the end of the

00:02:18,239 --> 00:02:20,879
presentation

00:02:19,440 --> 00:02:23,680
i will kind of summarize what we talked

00:02:20,879 --> 00:02:26,239
about and there will also be a live q a

00:02:23,680 --> 00:02:27,840
right so this session is pre-recorded

00:02:26,239 --> 00:02:30,000
but at the end of the session

00:02:27,840 --> 00:02:31,200
there will be a live q a i will be there

00:02:30,000 --> 00:02:32,640
in person answer

00:02:31,200 --> 00:02:34,239
any questions you might have on this

00:02:32,640 --> 00:02:35,840
presentation or

00:02:34,239 --> 00:02:38,080
or anything that kind of relates to this

00:02:35,840 --> 00:02:39,200
subject uh i will also hang out in the

00:02:38,080 --> 00:02:40,640
slack channel

00:02:39,200 --> 00:02:42,319
and i've been i've been in the slack

00:02:40,640 --> 00:02:44,160
channel for up throughout the the event

00:02:42,319 --> 00:02:46,080
as well

00:02:44,160 --> 00:02:47,200
and and one important detail i kind of

00:02:46,080 --> 00:02:49,120
want to touch on

00:02:47,200 --> 00:02:50,800
as well here that i'm obviously going to

00:02:49,120 --> 00:02:52,000
deploy a lot of yaml files and and

00:02:50,800 --> 00:02:54,720
things like that and

00:02:52,000 --> 00:02:55,440
and run through a lot of hands-on labs i

00:02:54,720 --> 00:02:58,080
got

00:02:55,440 --> 00:03:00,480
11 hands-on labs for you so this

00:02:58,080 --> 00:03:04,080
presentation really goes to 11

00:03:00,480 --> 00:03:04,879
and and i kind of put together a github

00:03:04,080 --> 00:03:08,000
repo where

00:03:04,879 --> 00:03:11,280
all these config files

00:03:08,000 --> 00:03:12,879
and there's also asking ema cast files

00:03:11,280 --> 00:03:16,480
so this if there's any

00:03:12,879 --> 00:03:19,120
thing you actually see in the demo

00:03:16,480 --> 00:03:19,840
in the video you can use the cast files

00:03:19,120 --> 00:03:22,480
and play them

00:03:19,840 --> 00:03:23,599
play them on your local computer and

00:03:22,480 --> 00:03:25,440
basically

00:03:23,599 --> 00:03:27,200
copy and paste the text from from the

00:03:25,440 --> 00:03:28,799
demo right because

00:03:27,200 --> 00:03:31,519
that is really difficult to capture from

00:03:28,799 --> 00:03:34,000
from a video file into a terminal

00:03:31,519 --> 00:03:35,120
and so that is the repo that we are

00:03:34,000 --> 00:03:38,720
going to use

00:03:35,120 --> 00:03:40,080
throughout the entire tutorial so let

00:03:38,720 --> 00:03:42,319
let me uh

00:03:40,080 --> 00:03:43,519
start off here and kind of talk a little

00:03:42,319 --> 00:03:47,200
bit about

00:03:43,519 --> 00:03:48,959
what is csi you know that csi stands for

00:03:47,200 --> 00:03:52,080
container storage interface but

00:03:48,959 --> 00:03:55,760
uh what what is actually behind it

00:03:52,080 --> 00:03:57,519
uh so it's basically a specification

00:03:55,760 --> 00:03:59,519
right uh it's a it's a set of

00:03:57,519 --> 00:04:01,840
specifications and the lack for a

00:03:59,519 --> 00:04:04,000
better comparison it's sort of like the

00:04:01,840 --> 00:04:07,680
cinder for kubernetes right

00:04:04,000 --> 00:04:10,640
with the benefit of that the drivers and

00:04:07,680 --> 00:04:11,519
the entire frameworks live outside the

00:04:10,640 --> 00:04:14,239
um

00:04:11,519 --> 00:04:16,079
the main kubernetes project right so the

00:04:14,239 --> 00:04:17,440
drivers and and all the

00:04:16,079 --> 00:04:19,280
side cars i'm going to talk a little bit

00:04:17,440 --> 00:04:20,720
about this later they

00:04:19,280 --> 00:04:23,280
they know they're not part of the main

00:04:20,720 --> 00:04:25,120
kubernetes upstream

00:04:23,280 --> 00:04:26,479
tree right so that their the sidecar

00:04:25,120 --> 00:04:28,320
lives in their own repos

00:04:26,479 --> 00:04:30,639
all the csi drivers are delivered by

00:04:28,320 --> 00:04:34,560
vendors in in various different ways

00:04:30,639 --> 00:04:36,880
right it's also governed by the

00:04:34,560 --> 00:04:38,000
special interest group kubernetes

00:04:36,880 --> 00:04:41,120
storage

00:04:38,000 --> 00:04:44,479
they meet on a regular cadence and

00:04:41,120 --> 00:04:46,000
also put some links here into the csi

00:04:44,479 --> 00:04:47,759
documentation itself and i'm going to

00:04:46,000 --> 00:04:50,960
reference that in the

00:04:47,759 --> 00:04:51,520
in in some of the demos as well on how

00:04:50,960 --> 00:04:55,040
you kind of

00:04:51,520 --> 00:04:55,520
find stuff and such and the main goal

00:04:55,040 --> 00:04:59,280
for

00:04:55,520 --> 00:05:01,280
the csi specification is to provide

00:04:59,280 --> 00:05:03,039
an interface standard on how to

00:05:01,280 --> 00:05:05,840
provision and attach

00:05:03,039 --> 00:05:06,479
storage to container orchestrators that

00:05:05,840 --> 00:05:09,759
is often

00:05:06,479 --> 00:05:11,280
uh referred to as a ceo right and we're

00:05:09,759 --> 00:05:12,240
obviously going to talk about kubernetes

00:05:11,280 --> 00:05:16,240
today

00:05:12,240 --> 00:05:18,880
but you can also use uh csi for nomad or

00:05:16,240 --> 00:05:20,000
cloud foundry and mesos and and those

00:05:18,880 --> 00:05:21,759
are like the the less

00:05:20,000 --> 00:05:23,280
popular ones i know that no matter has

00:05:21,759 --> 00:05:27,600
got csi support

00:05:23,280 --> 00:05:29,199
uh in in in that container orchestrator

00:05:27,600 --> 00:05:32,479
as well so we'll probably see

00:05:29,199 --> 00:05:32,479
a few more

00:05:32,560 --> 00:05:37,199
use cases for that coming up uh

00:05:35,840 --> 00:05:40,080
so i just want to kind of touch a little

00:05:37,199 --> 00:05:42,720
bit on the history of the

00:05:40,080 --> 00:05:43,360
csi how how it kind of came to be right

00:05:42,720 --> 00:05:45,199
so if

00:05:43,360 --> 00:05:47,039
we kind of go back to the early days of

00:05:45,199 --> 00:05:48,880
kubernetes uh

00:05:47,039 --> 00:05:50,639
we have these like intri persistent

00:05:48,880 --> 00:05:52,400
volume plug-ins right and the two

00:05:50,639 --> 00:05:53,840
example plugins i have here like fiber

00:05:52,400 --> 00:05:55,039
channel and iscsi

00:05:53,840 --> 00:05:57,039
and they were kind of introduced in

00:05:55,039 --> 00:06:00,639
kubernetes 101 iscsi

00:05:57,039 --> 00:06:02,000
in 0.15 right but there's a slew of

00:06:00,639 --> 00:06:04,240
different plugins

00:06:02,000 --> 00:06:06,000
uh in the that is part of the main

00:06:04,240 --> 00:06:08,639
kubernetes distribution

00:06:06,000 --> 00:06:09,440
right and somehow this became really

00:06:08,639 --> 00:06:12,080
unwieldy

00:06:09,440 --> 00:06:13,600
really early on because what happens is

00:06:12,080 --> 00:06:16,319
that every vendor

00:06:13,600 --> 00:06:17,759
needed to learn how to contribute to

00:06:16,319 --> 00:06:20,639
kubernetes right

00:06:17,759 --> 00:06:21,840
and that wasn't really an easy feat back

00:06:20,639 --> 00:06:23,919
then right and and

00:06:21,840 --> 00:06:25,680
everything needs to be code reviewed and

00:06:23,919 --> 00:06:28,720
you also stuck to the

00:06:25,680 --> 00:06:30,800
release cadence of kubernetes and that

00:06:28,720 --> 00:06:33,199
prohibits the vendor to kind of innovate

00:06:30,800 --> 00:06:34,319
at his pace and always have to wait for

00:06:33,199 --> 00:06:37,039
the next release for

00:06:34,319 --> 00:06:38,080
new features or bug fixes and things

00:06:37,039 --> 00:06:41,759
like that and and

00:06:38,080 --> 00:06:41,759
that was pretty unmanageable

00:06:41,919 --> 00:06:48,720
what came along in kubernetes 1.2 is the

00:06:45,280 --> 00:06:51,120
entry flex volume plug-in and and that

00:06:48,720 --> 00:06:51,840
introduced the concept of allowing

00:06:51,120 --> 00:06:54,639
vendors to

00:06:51,840 --> 00:06:56,400
to write flex volume drivers and flex

00:06:54,639 --> 00:06:59,680
volume drivers were kind of useful

00:06:56,400 --> 00:07:03,360
it was it was a pretty decent stop gap

00:06:59,680 --> 00:07:05,280
but somehow that become became very

00:07:03,360 --> 00:07:06,960
unuser friendly as well right because

00:07:05,280 --> 00:07:10,080
the flex volume driver itself

00:07:06,960 --> 00:07:14,160
it was it's a self-contained binary that

00:07:10,080 --> 00:07:16,800
needs to be needed to reside on every

00:07:14,160 --> 00:07:19,039
cubelet in the cluster that was supposed

00:07:16,800 --> 00:07:21,520
to attach persistent storage

00:07:19,039 --> 00:07:22,639
and it did not have any dynamic

00:07:21,520 --> 00:07:24,720
provisioning

00:07:22,639 --> 00:07:25,759
support either so if you had a if you

00:07:24,720 --> 00:07:28,080
were a vendor

00:07:25,759 --> 00:07:28,960
and want to provide a flex volume driver

00:07:28,080 --> 00:07:32,319
you also have to

00:07:28,960 --> 00:07:34,319
write your own provisioner to be able to

00:07:32,319 --> 00:07:35,520
satisfy persistent volume claims with

00:07:34,319 --> 00:07:38,639
that driver

00:07:35,520 --> 00:07:41,280
and and that's what kind of

00:07:38,639 --> 00:07:42,960
when we can't move into the face of the

00:07:41,280 --> 00:07:44,800
container storage interface

00:07:42,960 --> 00:07:46,479
it's just completely lives outside of

00:07:44,800 --> 00:07:49,919
kubernetes there's like nothing

00:07:46,479 --> 00:07:53,840
inside kubernetes that depends on

00:07:49,919 --> 00:07:54,160
the csi the delivery vehicles of csi or

00:07:53,840 --> 00:07:57,199
the

00:07:54,160 --> 00:07:59,520
velocity of how things are

00:07:57,199 --> 00:08:00,240
introduced and such right and the entire

00:07:59,520 --> 00:08:01,840
framework

00:08:00,240 --> 00:08:03,360
is actually deployed on top of

00:08:01,840 --> 00:08:06,639
kubernetes right so

00:08:03,360 --> 00:08:09,440
nothing lives entry and that allows

00:08:06,639 --> 00:08:11,039
vendors then to once you have all the

00:08:09,440 --> 00:08:14,000
csi side cores and such

00:08:11,039 --> 00:08:15,120
in install on the kubernetes cluster

00:08:14,000 --> 00:08:17,360
vendors can then

00:08:15,120 --> 00:08:18,240
provide their csi controller driver and

00:08:17,360 --> 00:08:21,599
their csi

00:08:18,240 --> 00:08:23,280
no driver right and that is

00:08:21,599 --> 00:08:24,800
the vehicle that i'm going to talk about

00:08:23,280 --> 00:08:27,039
today on how to

00:08:24,800 --> 00:08:29,120
install csi drivers and how to use the

00:08:27,039 --> 00:08:31,759
particular feature that the csi driver

00:08:29,120 --> 00:08:31,759
provides

00:08:32,800 --> 00:08:38,880
so i also have this simplified

00:08:36,000 --> 00:08:39,760
architecture view of csi right so you

00:08:38,880 --> 00:08:42,159
kind of have the the

00:08:39,760 --> 00:08:44,080
side cars that i've been talking about

00:08:42,159 --> 00:08:45,680
first you have the no driver registrar

00:08:44,080 --> 00:08:47,760
and you will see like on every node that

00:08:45,680 --> 00:08:49,279
have csi drivers on them you will see

00:08:47,760 --> 00:08:51,760
what drivers they have and some of the

00:08:49,279 --> 00:08:53,120
features that they provide like topology

00:08:51,760 --> 00:08:55,200
keys and such

00:08:53,120 --> 00:08:57,200
and and then you have the all the side

00:08:55,200 --> 00:08:59,200
cars like the provisioner the attache

00:08:57,200 --> 00:09:01,519
the resizer the snapshotter

00:08:59,200 --> 00:09:03,440
uh they are all provided by the

00:09:01,519 --> 00:09:05,839
kubernetes sig storage community

00:09:03,440 --> 00:09:07,040
right and then you have the external

00:09:05,839 --> 00:09:09,360
components

00:09:07,040 --> 00:09:10,880
which is the csi controller driver and

00:09:09,360 --> 00:09:14,320
the csi no driver

00:09:10,880 --> 00:09:16,320
that that then then talks to a

00:09:14,320 --> 00:09:18,160
external storage system the storage

00:09:16,320 --> 00:09:18,880
system can actually run on kubernetes

00:09:18,160 --> 00:09:21,839
itself

00:09:18,880 --> 00:09:23,519
or it can be outside the cluster

00:09:21,839 --> 00:09:24,480
entirely right so if you have like an

00:09:23,519 --> 00:09:27,519
external

00:09:24,480 --> 00:09:30,959
nfs server or a block storage server

00:09:27,519 --> 00:09:32,399
and that can live entirely outside

00:09:30,959 --> 00:09:34,640
and then you have the container native

00:09:32,399 --> 00:09:36,160
storage uh or container attached storage

00:09:34,640 --> 00:09:36,959
solutions that are out there where you

00:09:36,160 --> 00:09:41,680
actually deploy

00:09:36,959 --> 00:09:44,399
everything on your cluster as well right

00:09:41,680 --> 00:09:45,680
the communication that is between the

00:09:44,399 --> 00:09:48,160
sidecar images and

00:09:45,680 --> 00:09:49,120
and the um the controller driver and the

00:09:48,160 --> 00:09:52,160
no driver

00:09:49,120 --> 00:09:54,560
is using a g or pc interface

00:09:52,160 --> 00:09:56,399
so some of these components they need to

00:09:54,560 --> 00:09:58,160
run on the same nodes but the external

00:09:56,399 --> 00:09:58,720
storage system or the storage system

00:09:58,160 --> 00:10:02,240
component

00:09:58,720 --> 00:10:05,440
they can talk over an entirely different

00:10:02,240 --> 00:10:08,560
interface like using rest and iscsi and

00:10:05,440 --> 00:10:11,760
whatnot another

00:10:08,560 --> 00:10:15,120
uh detail you can see up there in the um

00:10:11,760 --> 00:10:16,640
in the uh light bulb there is that csi

00:10:15,120 --> 00:10:18,959
drivers today they may provide either

00:10:16,640 --> 00:10:21,360
file or block storage

00:10:18,959 --> 00:10:22,000
and we're also seeing that there are a

00:10:21,360 --> 00:10:24,800
few

00:10:22,000 --> 00:10:26,800
kubernetes enhancement proposals around

00:10:24,800 --> 00:10:28,000
providing object storage with sort of

00:10:26,800 --> 00:10:29,839
similar

00:10:28,000 --> 00:10:32,800
semantics so we're surely looking

00:10:29,839 --> 00:10:36,640
forward to that

00:10:32,800 --> 00:10:39,200
and we all almost have uh

00:10:36,640 --> 00:10:40,000
over a hundred drivers uh there is 90

00:10:39,200 --> 00:10:41,839
some drivers

00:10:40,000 --> 00:10:45,120
available today right so if you go to

00:10:41,839 --> 00:10:47,600
the the url that is on the slide there

00:10:45,120 --> 00:10:48,560
you will see a list of the different

00:10:47,600 --> 00:10:51,200
drivers

00:10:48,560 --> 00:10:52,480
and also what kind of features that they

00:10:51,200 --> 00:10:55,279
support

00:10:52,480 --> 00:10:57,040
so i'm going to use the hp csi driver

00:10:55,279 --> 00:10:58,720
for kubernetes in the hands-on labs and

00:10:57,040 --> 00:10:59,680
such but it doesn't really matter what

00:10:58,720 --> 00:11:02,079
csi driver

00:10:59,680 --> 00:11:03,680
you use as long as it supports the

00:11:02,079 --> 00:11:05,279
different features

00:11:03,680 --> 00:11:08,800
and in the different specification

00:11:05,279 --> 00:11:11,680
levels of the csi specification

00:11:08,800 --> 00:11:12,000
and if you pull up this page you will

00:11:11,680 --> 00:11:13,920
then

00:11:12,000 --> 00:11:15,200
be able to see that there are certain

00:11:13,920 --> 00:11:17,760
aspects

00:11:15,200 --> 00:11:18,480
uh of each individual driver right so i

00:11:17,760 --> 00:11:20,240
i just

00:11:18,480 --> 00:11:22,399
took a good example here in the

00:11:20,240 --> 00:11:25,440
driverless uh

00:11:22,399 --> 00:11:26,399
cfs and and ceph rdb which provides

00:11:25,440 --> 00:11:30,079
block storage

00:11:26,399 --> 00:11:33,040
and they provide um sort of like

00:11:30,079 --> 00:11:34,079
different uh aspects of the spec that it

00:11:33,040 --> 00:11:36,560
supports

00:11:34,079 --> 00:11:39,040
and and different features right so uh

00:11:36,560 --> 00:11:40,880
we can see that um

00:11:39,040 --> 00:11:42,560
the modes that the driver support is

00:11:40,880 --> 00:11:43,920
persistent it doesn't support ephemeral

00:11:42,560 --> 00:11:45,600
so the mode could be either persistent

00:11:43,920 --> 00:11:47,760
or ephemeral

00:11:45,600 --> 00:11:49,680
the access mode if you look at cfs they

00:11:47,760 --> 00:11:52,320
can do read write multiple pods

00:11:49,680 --> 00:11:55,279
i'm going to talk about that later in

00:11:52,320 --> 00:11:56,639
this tutorial what that actually means

00:11:55,279 --> 00:11:58,320
but this is just a way for you to kind

00:11:56,639 --> 00:12:00,639
of assess the different drivers

00:11:58,320 --> 00:12:04,000
depending on your use case

00:12:00,639 --> 00:12:04,000
you can see that the block storage

00:12:04,480 --> 00:12:08,079
driver will only support read write a

00:12:06,399 --> 00:12:09,519
single pod

00:12:08,079 --> 00:12:11,279
and different features that are very

00:12:09,519 --> 00:12:13,440
similar the only difference here what

00:12:11,279 --> 00:12:16,800
you can see here is that the

00:12:13,440 --> 00:12:17,920
the raw block volume or the block volume

00:12:16,800 --> 00:12:20,399
driver will support

00:12:17,920 --> 00:12:21,600
raw block and it will also support

00:12:20,399 --> 00:12:24,720
topology

00:12:21,600 --> 00:12:25,680
and and and those keys are not needed

00:12:24,720 --> 00:12:28,240
for

00:12:25,680 --> 00:12:29,680
using ceph the file system component

00:12:28,240 --> 00:12:30,639
right because it's a distributed file

00:12:29,680 --> 00:12:33,120
system

00:12:30,639 --> 00:12:35,120
will be available everywhere and it does

00:12:33,120 --> 00:12:37,120
not have any block cap capabilities

00:12:35,120 --> 00:12:38,959
right so depending on your use case what

00:12:37,120 --> 00:12:40,240
kind of apps you're deploying

00:12:38,959 --> 00:12:42,160
you kind of want to assess the driver

00:12:40,240 --> 00:12:42,720
list to make sure that the driver you're

00:12:42,160 --> 00:12:44,720
using

00:12:42,720 --> 00:12:47,440
supported the specific capability that

00:12:44,720 --> 00:12:47,440
you're looking for

00:12:48,800 --> 00:12:53,360
all right so these are the different

00:12:52,000 --> 00:12:53,839
features that we're going to talk about

00:12:53,360 --> 00:12:55,839
today

00:12:53,839 --> 00:12:56,959
and and kind of run through the

00:12:55,839 --> 00:13:00,160
different tutorials

00:12:56,959 --> 00:13:03,519
uh for provisioning storage and

00:13:00,160 --> 00:13:04,399
show you how to attach raw block volumes

00:13:03,519 --> 00:13:06,560
and

00:13:04,399 --> 00:13:08,160
and so forth and these all have

00:13:06,560 --> 00:13:09,200
different maturity levels within

00:13:08,160 --> 00:13:13,600
kubernetes today

00:13:09,200 --> 00:13:16,800
right we have the the features made

00:13:13,600 --> 00:13:18,560
ga and a few uh data features

00:13:16,800 --> 00:13:20,639
and we also have one alpha feature we're

00:13:18,560 --> 00:13:23,200
going to talk about today the

00:13:20,639 --> 00:13:25,680
generic ephemeral volumes you got got

00:13:23,200 --> 00:13:28,320
introduced in 119 and it's a pretty neat

00:13:25,680 --> 00:13:30,160
addition to if you compare that to the

00:13:28,320 --> 00:13:30,560
ephemeral local volumes and i'm going to

00:13:30,160 --> 00:13:33,680
talk

00:13:30,560 --> 00:13:36,639
in in depth about the difference around

00:13:33,680 --> 00:13:36,639
that when we get there

00:13:36,880 --> 00:13:40,399
so and this is also something you need

00:13:38,720 --> 00:13:41,839
to consider when

00:13:40,399 --> 00:13:44,959
you want to use persistent storage with

00:13:41,839 --> 00:13:46,480
your workloads in kubernetes and it also

00:13:44,959 --> 00:13:48,000
the fact that different kubernetes

00:13:46,480 --> 00:13:51,040
distributions they

00:13:48,000 --> 00:13:52,240
may mature these features on on on a

00:13:51,040 --> 00:13:55,330
different cadence

00:13:52,240 --> 00:13:57,440
or a faster cadence depending on um

00:13:55,330 --> 00:13:59,440
[Music]

00:13:57,440 --> 00:14:01,920
the particular use cases that particular

00:13:59,440 --> 00:14:03,519
vendor want to cater for so

00:14:01,920 --> 00:14:05,680
that is also something to keep an eye

00:14:03,519 --> 00:14:08,480
out our ielts on and

00:14:05,680 --> 00:14:10,079
all these different features are

00:14:08,480 --> 00:14:14,720
described in depth

00:14:10,079 --> 00:14:15,680
um on the kubernetes csi github repo as

00:14:14,720 --> 00:14:18,160
well

00:14:15,680 --> 00:14:19,600
and we're going to cover most of these

00:14:18,160 --> 00:14:21,040
i'm not going to talk that much about

00:14:19,600 --> 00:14:22,480
topology i'm going to touch a little bit

00:14:21,040 --> 00:14:24,800
about that when we walk through the

00:14:22,480 --> 00:14:26,399
storage class

00:14:24,800 --> 00:14:27,839
volume limits i'm not going to talk

00:14:26,399 --> 00:14:31,440
about that either but that's a

00:14:27,839 --> 00:14:35,040
way for the csi driver vendor to

00:14:31,440 --> 00:14:35,040
put a node limit on

00:14:35,440 --> 00:14:38,800
on the node how many volumes you can

00:14:37,120 --> 00:14:40,000
provision from that particular driver to

00:14:38,800 --> 00:14:42,639
that particular node

00:14:40,000 --> 00:14:44,560
which is quite useful but the rest of

00:14:42,639 --> 00:14:47,680
the capabilities here i'm going to show

00:14:44,560 --> 00:14:50,639
volume expansion thermal local volumes

00:14:47,680 --> 00:14:53,519
volume snapshots and also use the

00:14:50,639 --> 00:14:56,000
persistent volume clone

00:14:53,519 --> 00:14:57,519
using the data source stanza in the

00:14:56,000 --> 00:15:00,800
persistent volume claim

00:14:57,519 --> 00:15:03,839
so we have a a full agenda uh

00:15:00,800 --> 00:15:05,519
for sure and so we're kind of

00:15:03,839 --> 00:15:06,240
approaching the first kind of hands-on

00:15:05,519 --> 00:15:08,240
lab here

00:15:06,240 --> 00:15:10,720
right so and that is basically

00:15:08,240 --> 00:15:14,480
installing and inspecting csi driver

00:15:10,720 --> 00:15:15,360
right and drivers are you can find most

00:15:14,480 --> 00:15:18,639
drivers on

00:15:15,360 --> 00:15:21,199
artifact hub dot io

00:15:18,639 --> 00:15:22,160
most of them install as as helm charts

00:15:21,199 --> 00:15:25,519
some of them

00:15:22,160 --> 00:15:28,480
have fully blown operators and

00:15:25,519 --> 00:15:30,240
some of the drivers you just reference

00:15:28,480 --> 00:15:33,120
and

00:15:30,240 --> 00:15:34,959
a configuration file that points to

00:15:33,120 --> 00:15:37,360
lives in a ghetto brief or a web server

00:15:34,959 --> 00:15:39,040
and that will install the driver for you

00:15:37,360 --> 00:15:40,079
and once you have a driver or if you

00:15:39,040 --> 00:15:42,000
have access to a cluster

00:15:40,079 --> 00:15:43,199
now what you can do is it's just you do

00:15:42,000 --> 00:15:46,079
a cube codel get

00:15:43,199 --> 00:15:47,360
csi drivers that will list the the

00:15:46,079 --> 00:15:48,079
drivers that you have installed on your

00:15:47,360 --> 00:15:51,040
cluster and

00:15:48,079 --> 00:15:53,040
the capabilities of the driver and if

00:15:51,040 --> 00:15:55,440
you do a coupe call get csi nodes

00:15:53,040 --> 00:15:57,279
you will see what nodes in your cluster

00:15:55,440 --> 00:15:58,000
have csi drivers on them and you can do

00:15:57,279 --> 00:16:00,320
a like

00:15:58,000 --> 00:16:01,920
verbose output and see what driver they

00:16:00,320 --> 00:16:05,360
actually have

00:16:01,920 --> 00:16:09,279
installed right so now we

00:16:05,360 --> 00:16:10,000
are going to install a csi driver that's

00:16:09,279 --> 00:16:12,880
our first

00:16:10,000 --> 00:16:14,720
hands-on lab in this tutorial so i'm

00:16:12,880 --> 00:16:17,920
going to switch over to my terminal

00:16:14,720 --> 00:16:19,920
and hang on for one second

00:16:17,920 --> 00:16:21,040
all right as i mentioned i'm going to

00:16:19,920 --> 00:16:23,759
use the

00:16:21,040 --> 00:16:25,040
hpe csi driver for kubernetes and you

00:16:23,759 --> 00:16:27,440
install that with helm

00:16:25,040 --> 00:16:28,959
right and i'm just going to add the helm

00:16:27,440 --> 00:16:32,880
repo to my cluster

00:16:28,959 --> 00:16:35,440
do a helm repo update and then

00:16:32,880 --> 00:16:36,720
i'm going to create a separate namespace

00:16:35,440 --> 00:16:38,560
for

00:16:36,720 --> 00:16:40,079
that driver that what i want to install

00:16:38,560 --> 00:16:43,040
it

00:16:40,079 --> 00:16:43,040
do a helm install

00:16:44,959 --> 00:16:47,920
namespace vendor

00:16:49,120 --> 00:16:54,000
csi driver name i've obviously made a

00:16:51,600 --> 00:16:55,360
typo there

00:16:54,000 --> 00:16:57,120
i want to give the release a name

00:16:55,360 --> 00:16:59,759
because this is something

00:16:57,120 --> 00:17:01,120
switching from helm2 to helm3 obviously

00:16:59,759 --> 00:17:03,040
provides that headache

00:17:01,120 --> 00:17:04,720
and once the driver is installed you can

00:17:03,040 --> 00:17:07,039
do a cube called get

00:17:04,720 --> 00:17:08,720
csi drivers you will see the

00:17:07,039 --> 00:17:11,679
capabilities of the driver

00:17:08,720 --> 00:17:13,919
and the driver name and you will also

00:17:11,679 --> 00:17:15,839
see on your nodes that you will have

00:17:13,919 --> 00:17:18,799
i have four working nodes in my cluster

00:17:15,839 --> 00:17:22,400
and they all have the driver installed

00:17:18,799 --> 00:17:25,199
the drivers also have

00:17:22,400 --> 00:17:26,880
a way to configure themselves right so

00:17:25,199 --> 00:17:30,080
for the um

00:17:26,880 --> 00:17:32,720
csi dr hpcs driver for kubernetes i'm

00:17:30,080 --> 00:17:33,440
i need to provide a secret that provide

00:17:32,720 --> 00:17:35,600
a

00:17:33,440 --> 00:17:36,960
means for me to find the backend that i

00:17:35,600 --> 00:17:38,720
want to use right

00:17:36,960 --> 00:17:40,320
so for me to be able to start

00:17:38,720 --> 00:17:41,520
provisioning storage from storage

00:17:40,320 --> 00:17:44,000
classes and such

00:17:41,520 --> 00:17:45,120
and i need to create that secret to make

00:17:44,000 --> 00:17:47,679
sure that

00:17:45,120 --> 00:17:48,160
the csi provisioner attacher and such

00:17:47,679 --> 00:17:50,000
will they

00:17:48,160 --> 00:17:52,559
be able to find that secret when they

00:17:50,000 --> 00:17:54,480
need to talk to

00:17:52,559 --> 00:17:56,559
the hp csi driver so i'm just going to

00:17:54,480 --> 00:18:00,880
go ahead and create that

00:17:56,559 --> 00:18:03,039
and there we go driver installed

00:18:00,880 --> 00:18:05,039
so now when we have the driver installed

00:18:03,039 --> 00:18:07,200
uh we can do a lot of things

00:18:05,039 --> 00:18:08,960
right and the first thing i want to talk

00:18:07,200 --> 00:18:11,520
about is how we can

00:18:08,960 --> 00:18:12,840
do dynamic provisioning of persistent

00:18:11,520 --> 00:18:15,760
volumes

00:18:12,840 --> 00:18:16,559
and dynamic provisioning in kubernetes

00:18:15,760 --> 00:18:19,679
is nothing that is

00:18:16,559 --> 00:18:22,160
exclusive to csi drivers in in any way

00:18:19,679 --> 00:18:23,280
right so if we just uh imagine for a

00:18:22,160 --> 00:18:25,120
second here that we're

00:18:23,280 --> 00:18:27,280
we might be using a kubernetes entry

00:18:25,120 --> 00:18:28,400
storage plug-in we might be leveraging a

00:18:27,280 --> 00:18:31,360
cloud providers

00:18:28,400 --> 00:18:33,039
manage communities service to provide

00:18:31,360 --> 00:18:36,080
persistent storage and so forth

00:18:33,039 --> 00:18:39,039
or we might be using um

00:18:36,080 --> 00:18:40,840
a csi driver so on the left hand side

00:18:39,039 --> 00:18:42,880
here you will see that the cluster

00:18:40,840 --> 00:18:44,400
administrator he will create something

00:18:42,880 --> 00:18:46,559
called a storage class

00:18:44,400 --> 00:18:48,480
and that will reference the um the

00:18:46,559 --> 00:18:51,039
provisioner you want to use

00:18:48,480 --> 00:18:51,760
and you want to give it a name and you

00:18:51,039 --> 00:18:53,520
also

00:18:51,760 --> 00:18:54,840
you might have a list of parameters that

00:18:53,520 --> 00:18:58,640
are specific

00:18:54,840 --> 00:19:00,720
to to that particular provisioner

00:18:58,640 --> 00:19:03,280
for csi drivers you need to have a list

00:19:00,720 --> 00:19:05,760
of keys that references the the secret

00:19:03,280 --> 00:19:08,160
to the different side cars and if you're

00:19:05,760 --> 00:19:11,039
you have your own side cars

00:19:08,160 --> 00:19:11,679
you need to call them out there as well

00:19:11,039 --> 00:19:14,000
you want to

00:19:11,679 --> 00:19:15,120
specify things like file system type and

00:19:14,000 --> 00:19:16,320
things like that

00:19:15,120 --> 00:19:17,520
and there are some other keys in the

00:19:16,320 --> 00:19:21,280
storage class that i'm going to talk

00:19:17,520 --> 00:19:21,280
about later in the presentation

00:19:21,360 --> 00:19:24,400
the middle piece here the the user

00:19:23,440 --> 00:19:27,360
aspect of it

00:19:24,400 --> 00:19:29,360
is that users create persistent volume

00:19:27,360 --> 00:19:32,799
claims and persistent volume claims

00:19:29,360 --> 00:19:35,200
are name-spaced right so uh

00:19:32,799 --> 00:19:36,720
and that will in turn he will request

00:19:35,200 --> 00:19:38,640
the access mode i'm going to talk about

00:19:36,720 --> 00:19:41,440
that later as well what that is

00:19:38,640 --> 00:19:42,000
and then you request a storage size

00:19:41,440 --> 00:19:44,640
right so

00:19:42,000 --> 00:19:45,039
that is where you specify the capacity

00:19:44,640 --> 00:19:47,919
in

00:19:45,039 --> 00:19:49,280
you can do either terabyte gigabytes or

00:19:47,919 --> 00:19:52,240
kilobytes megabytes

00:19:49,280 --> 00:19:54,320
uh whatever uni unit you want and you

00:19:52,240 --> 00:19:56,320
might want to call out the storage class

00:19:54,320 --> 00:19:57,840
there is a annotation you can do on the

00:19:56,320 --> 00:19:58,960
storage class i'm going to show you how

00:19:57,840 --> 00:20:01,280
that works as well

00:19:58,960 --> 00:20:02,400
that will allow you to specify default

00:20:01,280 --> 00:20:04,880
storage class

00:20:02,400 --> 00:20:06,880
and that means that any persistent

00:20:04,880 --> 00:20:10,080
volume claim without a storage class

00:20:06,880 --> 00:20:12,799
name called out explicitly it will be

00:20:10,080 --> 00:20:14,240
provisioned from that storage class

00:20:12,799 --> 00:20:15,919
once the persistent volume claim has

00:20:14,240 --> 00:20:19,600
been submitted to the cluster

00:20:15,919 --> 00:20:22,480
the dynamic provisioner which listens to

00:20:19,600 --> 00:20:23,039
the that pro pro specific provisioner

00:20:22,480 --> 00:20:25,360
name

00:20:23,039 --> 00:20:26,720
will uh provision something called a

00:20:25,360 --> 00:20:29,840
persistent volume

00:20:26,720 --> 00:20:32,320
and that is a a stanza that

00:20:29,840 --> 00:20:34,880
basically describes the backend storage

00:20:32,320 --> 00:20:37,120
right so that's where you will have your

00:20:34,880 --> 00:20:38,640
your driver name and your implementation

00:20:37,120 --> 00:20:41,039
specific keys and such

00:20:38,640 --> 00:20:42,000
and how to find the volume on the back

00:20:41,039 --> 00:20:43,919
end

00:20:42,000 --> 00:20:45,919
in the case of csi you will also have a

00:20:43,919 --> 00:20:47,760
bunch of secrets and things to

00:20:45,919 --> 00:20:49,440
to be able to attach and detach that

00:20:47,760 --> 00:20:52,000
storage uh

00:20:49,440 --> 00:20:53,600
from a particular node at any given time

00:20:52,000 --> 00:20:55,200
right and you will also have the access

00:20:53,600 --> 00:20:58,480
mode and all that metadata

00:20:55,200 --> 00:21:00,000
that the kubernetes needs to be able to

00:20:58,480 --> 00:21:02,960
attach and detach the volume and

00:21:00,000 --> 00:21:05,760
provision the volume

00:21:02,960 --> 00:21:05,760
and so forth

00:21:06,799 --> 00:21:11,120
so diving into the different uh objects

00:21:09,679 --> 00:21:12,799
here too if you look at the storage

00:21:11,120 --> 00:21:16,320
class here right as i mentioned

00:21:12,799 --> 00:21:19,679
then having a default storage class is

00:21:16,320 --> 00:21:22,000
usually good hygiene right so if you

00:21:19,679 --> 00:21:24,080
provision a managed kubernetes cluster

00:21:22,000 --> 00:21:25,520
on any of the public cloud providers

00:21:24,080 --> 00:21:27,360
uh you will see that you will have a

00:21:25,520 --> 00:21:28,799
storage class right so do a coupe call

00:21:27,360 --> 00:21:29,760
get storage class you will see that

00:21:28,799 --> 00:21:32,240
there will be

00:21:29,760 --> 00:21:34,480
a storage class there it's mark default

00:21:32,240 --> 00:21:36,559
and that will use the cloud providers

00:21:34,480 --> 00:21:37,760
storage solution to provide persistent

00:21:36,559 --> 00:21:41,760
storage to your

00:21:37,760 --> 00:21:45,120
to your workloads in the case of csi you

00:21:41,760 --> 00:21:45,120
will have these keys that say says

00:21:45,159 --> 00:21:50,559
csi.storage.cates.io

00:21:47,120 --> 00:21:50,880
and a set of um published secret names

00:21:50,559 --> 00:21:53,280
or

00:21:50,880 --> 00:21:55,120
or secret namespace for the different

00:21:53,280 --> 00:21:57,120
side course and you need this for every

00:21:55,120 --> 00:21:58,080
site card right so the csi expander

00:21:57,120 --> 00:21:59,679
sidecar

00:21:58,080 --> 00:22:01,280
that would need a secret and the

00:21:59,679 --> 00:22:03,440
publishing and

00:22:01,280 --> 00:22:04,880
and a few others that you need to

00:22:03,440 --> 00:22:05,760
reference in the storage class need to

00:22:04,880 --> 00:22:09,360
be pointed out there

00:22:05,760 --> 00:22:10,799
explicitly you also have the ability to

00:22:09,360 --> 00:22:13,840
set the reclaim policy

00:22:10,799 --> 00:22:15,039
on them on the persistent volume so it's

00:22:13,840 --> 00:22:17,200
basically when a user

00:22:15,039 --> 00:22:18,240
deletes a persistent volume claim what

00:22:17,200 --> 00:22:20,720
is going to happen

00:22:18,240 --> 00:22:21,760
uh when that persistent volume claim

00:22:20,720 --> 00:22:24,000
gets deleted

00:22:21,760 --> 00:22:26,080
will it be will the persistent volume

00:22:24,000 --> 00:22:28,000
that references to back-end storage

00:22:26,080 --> 00:22:29,280
would be retained on the cluster or will

00:22:28,000 --> 00:22:32,799
it be deleted

00:22:29,280 --> 00:22:34,720
um another key here i'm

00:22:32,799 --> 00:22:36,640
showcasing is the volume binding mode

00:22:34,720 --> 00:22:39,120
and if there's going to be immediate

00:22:36,640 --> 00:22:40,000
or wait for first consumer and that is

00:22:39,120 --> 00:22:43,679
important if you're

00:22:40,000 --> 00:22:45,120
using a topology within your cluster

00:22:43,679 --> 00:22:46,960
right so if you have a driver that

00:22:45,120 --> 00:22:49,520
supports topology

00:22:46,960 --> 00:22:50,720
you might want to be able to

00:22:49,520 --> 00:22:54,080
[Music]

00:22:50,720 --> 00:22:56,159
separate your different controllers

00:22:54,080 --> 00:22:57,440
or your paws in different zones in your

00:22:56,159 --> 00:22:59,280
cluster right

00:22:57,440 --> 00:23:00,880
and when you provision storage you want

00:22:59,280 --> 00:23:03,200
to make sure that you

00:23:00,880 --> 00:23:04,880
attach storage that is close to the node

00:23:03,200 --> 00:23:08,159
right so what happens is

00:23:04,880 --> 00:23:09,760
once kubernetes have selected a node to

00:23:08,159 --> 00:23:12,559
provision your pod

00:23:09,760 --> 00:23:13,360
that's when the persistent volume gets

00:23:12,559 --> 00:23:15,440
provisioned

00:23:13,360 --> 00:23:16,480
and the persistent volume will then be

00:23:15,440 --> 00:23:19,039
attached

00:23:16,480 --> 00:23:19,679
to those set of nodes right because and

00:23:19,039 --> 00:23:22,960
it will

00:23:19,679 --> 00:23:25,840
then annotate the persistent volume

00:23:22,960 --> 00:23:27,280
with the um with the affinity keys and

00:23:25,840 --> 00:23:28,960
that means that that persistent volume

00:23:27,280 --> 00:23:31,360
will only be able to be

00:23:28,960 --> 00:23:33,760
attached to those particular sets of

00:23:31,360 --> 00:23:33,760
nodes

00:23:33,840 --> 00:23:38,240
if you want to allow the or if the csi

00:23:36,480 --> 00:23:40,480
driver you want to use

00:23:38,240 --> 00:23:42,240
allows expansion uh you will set that in

00:23:40,480 --> 00:23:43,039
the storage class as well right so if it

00:23:42,240 --> 00:23:45,200
allows

00:23:43,039 --> 00:23:46,480
expansion you will set that to true and

00:23:45,200 --> 00:23:49,440
you will then be able to

00:23:46,480 --> 00:23:50,240
resize your persistent volume claims as

00:23:49,440 --> 00:23:52,159
you desire

00:23:50,240 --> 00:23:54,080
or not resize that's the wrong term

00:23:52,159 --> 00:23:55,440
because you can only expand you cannot

00:23:54,080 --> 00:23:56,720
shrink

00:23:55,440 --> 00:23:59,120
and i'm going to show you how that works

00:23:56,720 --> 00:23:59,120
as well

00:24:00,799 --> 00:24:04,559
so looking at the persistent volume

00:24:02,880 --> 00:24:06,720
claim uh

00:24:04,559 --> 00:24:09,200
it's it's is very straightforward very

00:24:06,720 --> 00:24:11,600
basic and

00:24:09,200 --> 00:24:13,120
you need to specify the access mode i in

00:24:11,600 --> 00:24:13,600
my next slide i'm going to talk a little

00:24:13,120 --> 00:24:16,960
bit

00:24:13,600 --> 00:24:19,039
broader about what access modes are and

00:24:16,960 --> 00:24:21,200
then you need to specify the uh the

00:24:19,039 --> 00:24:22,880
resource request

00:24:21,200 --> 00:24:24,880
the capacity that i mentioned right so

00:24:22,880 --> 00:24:26,720
in this example i'm going to provision

00:24:24,880 --> 00:24:28,720
or i'm going to actually request a two

00:24:26,720 --> 00:24:31,520
terabyte volume

00:24:28,720 --> 00:24:33,279
uh the volume mode is is set to file

00:24:31,520 --> 00:24:35,440
system per default but this is where you

00:24:33,279 --> 00:24:37,279
would specify a volume mode block if you

00:24:35,440 --> 00:24:40,799
want to provision a block device and

00:24:37,279 --> 00:24:42,720
the underlying driver supports that

00:24:40,799 --> 00:24:44,720
and you will also also be able to

00:24:42,720 --> 00:24:46,960
specify the storage class name

00:24:44,720 --> 00:24:49,360
or or omit the storage class name if you

00:24:46,960 --> 00:24:51,200
have a default storage class but

00:24:49,360 --> 00:24:52,720
in clusters where you have multiple

00:24:51,200 --> 00:24:53,679
tiers of storage say you have a gold

00:24:52,720 --> 00:24:56,640
silver bronze

00:24:53,679 --> 00:24:58,960
style thing or you have like fast ssd or

00:24:56,640 --> 00:25:01,360
slow media kind of

00:24:58,960 --> 00:25:02,799
segregation right it might be useful for

00:25:01,360 --> 00:25:03,679
users to be able to make that

00:25:02,799 --> 00:25:06,320
distinction

00:25:03,679 --> 00:25:08,080
between uh provisioning fast storage or

00:25:06,320 --> 00:25:08,640
slow storage because there's usually

00:25:08,080 --> 00:25:12,000
cost

00:25:08,640 --> 00:25:13,039
associated with that and the billing and

00:25:12,000 --> 00:25:15,840
accounting apartment

00:25:13,039 --> 00:25:17,360
is will be happier if if the right

00:25:15,840 --> 00:25:20,400
workload is running at the right

00:25:17,360 --> 00:25:23,120
place so

00:25:20,400 --> 00:25:25,919
pvc access mode or persistent volume

00:25:23,120 --> 00:25:28,080
claim access mode

00:25:25,919 --> 00:25:29,760
this is a graphic i put together to kind

00:25:28,080 --> 00:25:31,360
of like illustrate what types of

00:25:29,760 --> 00:25:33,679
applications

00:25:31,360 --> 00:25:34,400
require different types of storage right

00:25:33,679 --> 00:25:36,960
so

00:25:34,400 --> 00:25:38,240
one of the absolute absolute most

00:25:36,960 --> 00:25:40,080
popular

00:25:38,240 --> 00:25:41,440
kubernetes controller to use with

00:25:40,080 --> 00:25:44,159
persistent storage

00:25:41,440 --> 00:25:44,960
is a stateful set right and you will

00:25:44,159 --> 00:25:48,480
find

00:25:44,960 --> 00:25:51,440
like min io rook redis

00:25:48,480 --> 00:25:53,279
kafka all these different workloads that

00:25:51,440 --> 00:25:54,799
you run on top of kubernetes

00:25:53,279 --> 00:25:57,919
they use something called a state for

00:25:54,799 --> 00:25:59,360
staple set and staple set in itself

00:25:57,919 --> 00:26:01,200
i'm not going to cover that in detail

00:25:59,360 --> 00:26:04,640
but that is a controller that

00:26:01,200 --> 00:26:05,840
has a has ordered starts persistent

00:26:04,640 --> 00:26:08,159
network naming

00:26:05,840 --> 00:26:09,840
and also persistent naming of the

00:26:08,159 --> 00:26:12,000
volumes that gets attached to each of

00:26:09,840 --> 00:26:15,840
the parts as well

00:26:12,000 --> 00:26:16,799
right and what happens is that each part

00:26:15,840 --> 00:26:19,760
that starts up

00:26:16,799 --> 00:26:21,200
will basically have its own file system

00:26:19,760 --> 00:26:23,039
so each part

00:26:21,200 --> 00:26:26,000
will benefit greatly by having a read

00:26:23,039 --> 00:26:27,600
write once

00:26:26,000 --> 00:26:29,200
persistent volume claim right because

00:26:27,600 --> 00:26:32,080
that storage will then

00:26:29,200 --> 00:26:32,880
be private to that pod for the duration

00:26:32,080 --> 00:26:34,799
of

00:26:32,880 --> 00:26:36,559
that stateful set right so if you delete

00:26:34,799 --> 00:26:38,960
the pod the port will attach the exact

00:26:36,559 --> 00:26:42,159
same storage at the same time

00:26:38,960 --> 00:26:43,679
and storage will also be provisioned

00:26:42,159 --> 00:26:45,279
dynamically and i'm going to talk about

00:26:43,679 --> 00:26:48,559
this in detail

00:26:45,279 --> 00:26:49,679
later in the tutorial as well another

00:26:48,559 --> 00:26:52,320
very popular

00:26:49,679 --> 00:26:54,559
pattern for deploying legacy

00:26:52,320 --> 00:26:57,039
applications on kubernetes is to use

00:26:54,559 --> 00:26:58,960
something called a deployment right and

00:26:57,039 --> 00:27:00,640
in this case if you're using single

00:26:58,960 --> 00:27:03,120
replica deployment

00:27:00,640 --> 00:27:04,880
uh they usually leverage read write

00:27:03,120 --> 00:27:06,960
one's

00:27:04,880 --> 00:27:09,120
persistent volume claims so as you can

00:27:06,960 --> 00:27:10,080
see here i have my sql both in the

00:27:09,120 --> 00:27:11,679
legacy app

00:27:10,080 --> 00:27:13,520
single instance and the shared nothing

00:27:11,679 --> 00:27:15,360
distributed because you can run that

00:27:13,520 --> 00:27:16,640
database in two different modes right

00:27:15,360 --> 00:27:19,279
you can have

00:27:16,640 --> 00:27:20,320
the replicated uh one as a stateful set

00:27:19,279 --> 00:27:22,559
where you have

00:27:20,320 --> 00:27:24,000
one main instance and multiple replica

00:27:22,559 --> 00:27:26,480
instances

00:27:24,000 --> 00:27:28,320
and you can also run it as a single uh

00:27:26,480 --> 00:27:30,320
replica pod where you only have

00:27:28,320 --> 00:27:31,600
one single part accessing one file

00:27:30,320 --> 00:27:33,279
system so that is a

00:27:31,600 --> 00:27:34,960
matter of preference how you would like

00:27:33,279 --> 00:27:36,720
to run that particular

00:27:34,960 --> 00:27:38,000
application and the same goes for

00:27:36,720 --> 00:27:41,279
postgres it also

00:27:38,000 --> 00:27:43,840
postgres also has the same

00:27:41,279 --> 00:27:45,360
pattern as my sequel in the stable set

00:27:43,840 --> 00:27:49,440
as well if you want to run it in a

00:27:45,360 --> 00:27:52,320
shared nothing distributed architecture

00:27:49,440 --> 00:27:53,200
and when we get to scalable distributed

00:27:52,320 --> 00:27:55,840
applications

00:27:53,200 --> 00:27:56,399
uh that uh require shared storage right

00:27:55,840 --> 00:27:58,799
so

00:27:56,399 --> 00:27:59,600
say that you have nginx a distributed

00:27:58,799 --> 00:28:01,919
front-end

00:27:59,600 --> 00:28:03,679
with a lot of content right it's really

00:28:01,919 --> 00:28:05,679
practical to kind of have them reference

00:28:03,679 --> 00:28:09,039
the exact same storage

00:28:05,679 --> 00:28:12,240
across the cluster so when you scale

00:28:09,039 --> 00:28:14,399
replicas up and down it will exactly

00:28:12,240 --> 00:28:16,080
it will attach the exact same storage to

00:28:14,399 --> 00:28:19,600
that particular pawn

00:28:16,080 --> 00:28:20,640
uh also a lot of the uh ai ml based

00:28:19,600 --> 00:28:24,480
workloads like

00:28:20,640 --> 00:28:27,440
running a jupiter hub or kubeflow

00:28:24,480 --> 00:28:28,480
they kind of see storage as a data lake

00:28:27,440 --> 00:28:31,120
right so

00:28:28,480 --> 00:28:31,840
every instance that you spin up of uber

00:28:31,120 --> 00:28:35,039
or

00:28:31,840 --> 00:28:38,159
you you a certain uh aspect

00:28:35,039 --> 00:28:40,000
in your ai ml pipeline requires

00:28:38,159 --> 00:28:41,840
all the different replicas of that

00:28:40,000 --> 00:28:44,240
particular workload to access the exact

00:28:41,840 --> 00:28:46,559
same storage at any given point in time

00:28:44,240 --> 00:28:48,000
and you accomplish that by using

00:28:46,559 --> 00:28:49,840
something called a read write many

00:28:48,000 --> 00:28:51,919
persistent volume claims so

00:28:49,840 --> 00:28:52,880
then multiple parts can access the same

00:28:51,919 --> 00:28:55,840
storage

00:28:52,880 --> 00:28:55,840
at any given time

00:28:56,480 --> 00:29:00,080
so if you look at uh on the the content

00:28:59,440 --> 00:29:02,960
serving

00:29:00,080 --> 00:29:05,440
aspect of it where you want to provide

00:29:02,960 --> 00:29:08,799
read write many access

00:29:05,440 --> 00:29:10,640
uh in read-only mode essentially

00:29:08,799 --> 00:29:12,320
i see some of the use cases i see that

00:29:10,640 --> 00:29:15,600
you want to provide

00:29:12,320 --> 00:29:17,360
read-only content to nginx to serve

00:29:15,600 --> 00:29:19,840
static content

00:29:17,360 --> 00:29:20,559
you might have a jenkins server that

00:29:19,840 --> 00:29:22,880
attach

00:29:20,559 --> 00:29:24,960
storage but you don't want your build

00:29:22,880 --> 00:29:25,520
jobs to screw up your storage sort of

00:29:24,960 --> 00:29:27,679
thing

00:29:25,520 --> 00:29:29,120
and and running those jobs on a

00:29:27,679 --> 00:29:31,840
read-only file system

00:29:29,120 --> 00:29:32,880
makes sense uh uh for that particular

00:29:31,840 --> 00:29:35,279
purpose

00:29:32,880 --> 00:29:36,240
right and and the way that you kind of

00:29:35,279 --> 00:29:38,960
attach reader

00:29:36,240 --> 00:29:41,200
only many storage is essentially you

00:29:38,960 --> 00:29:43,520
request you you have to specify it in

00:29:41,200 --> 00:29:45,200
the request that you do a read only many

00:29:43,520 --> 00:29:47,120
and then in the mount point you said i

00:29:45,200 --> 00:29:48,399
want to request this read only and that

00:29:47,120 --> 00:29:52,880
is basically how you

00:29:48,399 --> 00:29:56,559
request a read only many or rwo

00:29:52,880 --> 00:29:59,760
or rwx's it's called read write many

00:29:56,559 --> 00:30:03,760
so i hope that clarifies the different

00:29:59,760 --> 00:30:06,480
aspects of the persistent volume claim

00:30:03,760 --> 00:30:06,480
access modes

00:30:06,960 --> 00:30:10,640
so uh with that said so the last slide

00:30:09,039 --> 00:30:12,640
kind of in the dynamic provisioning

00:30:10,640 --> 00:30:14,080
piece here is i just want to lay out the

00:30:12,640 --> 00:30:15,760
persistent volume

00:30:14,080 --> 00:30:17,279
overview here for our csi driver and

00:30:15,760 --> 00:30:19,279
this is kind of

00:30:17,279 --> 00:30:21,120
slightly abbreviated this object

00:30:19,279 --> 00:30:24,640
contains a lot of information

00:30:21,120 --> 00:30:27,360
right so so once the csi

00:30:24,640 --> 00:30:28,000
provisioner has provided instantiated

00:30:27,360 --> 00:30:30,480
this

00:30:28,000 --> 00:30:31,520
persistent volume it will have a lot of

00:30:30,480 --> 00:30:33,279
metadata

00:30:31,520 --> 00:30:35,279
around the driver what parameters the

00:30:33,279 --> 00:30:37,840
driver needs to attach it

00:30:35,279 --> 00:30:39,039
all the secrets will be enumerated uh

00:30:37,840 --> 00:30:41,679
there will also be

00:30:39,039 --> 00:30:42,320
something called a claim reference which

00:30:41,679 --> 00:30:45,760
which

00:30:42,320 --> 00:30:47,760
claim the pv is buying bound to

00:30:45,760 --> 00:30:49,919
and so forth also you see the volume

00:30:47,760 --> 00:30:51,600
mode there and the volume handle there

00:30:49,919 --> 00:30:54,080
actually references the um

00:30:51,600 --> 00:30:55,760
the back end that's basically the id

00:30:54,080 --> 00:30:57,519
that you send to the back-end storage to

00:30:55,760 --> 00:30:59,840
be able to uh

00:30:57,519 --> 00:31:01,679
see what uh to be able to look up the

00:30:59,840 --> 00:31:03,840
volume and attach the volume

00:31:01,679 --> 00:31:05,679
and so forth and there's also a bunch of

00:31:03,840 --> 00:31:06,000
finalizers up there at the top that

00:31:05,679 --> 00:31:09,360
you'll

00:31:06,000 --> 00:31:10,000
be able to see uh so that essentially

00:31:09,360 --> 00:31:12,480
means that

00:31:10,000 --> 00:31:14,720
you cannot delete uh persistent volume

00:31:12,480 --> 00:31:15,360
if there's a pv holding a claim against

00:31:14,720 --> 00:31:18,960
it

00:31:15,360 --> 00:31:20,480
and and such and and you can have other

00:31:18,960 --> 00:31:22,320
finalizers on there

00:31:20,480 --> 00:31:24,559
that are all specific to your driver as

00:31:22,320 --> 00:31:24,559
well

00:31:25,440 --> 00:31:31,360
so um that leads me to uh

00:31:28,720 --> 00:31:32,880
hands-on lab number two uh going to

00:31:31,360 --> 00:31:34,240
create a storage class

00:31:32,880 --> 00:31:36,640
we're going to create a persistent

00:31:34,240 --> 00:31:38,640
volume claim and we're going to attach a

00:31:36,640 --> 00:31:41,360
workload to that persistent volume claim

00:31:38,640 --> 00:31:43,919
and i'm also going to show you how to

00:31:41,360 --> 00:31:46,559
expand a volume

00:31:43,919 --> 00:31:49,840
for that running workload so hang on

00:31:46,559 --> 00:31:51,840
while i switch over to my demo

00:31:49,840 --> 00:31:53,279
all right so what i'm going to do here

00:31:51,840 --> 00:31:56,000
first is i'm going to show you the

00:31:53,279 --> 00:31:57,519
storage class that i'm going to use here

00:31:56,000 --> 00:31:59,279
i want to make this storage class a

00:31:57,519 --> 00:32:00,720
default storage class this is the only

00:31:59,279 --> 00:32:03,760
storage class we're going to use

00:32:00,720 --> 00:32:05,440
for the entire tutorial

00:32:03,760 --> 00:32:07,360
and it supports all the different

00:32:05,440 --> 00:32:10,159
capabilities that

00:32:07,360 --> 00:32:11,600
i talked about in the introduction there

00:32:10,159 --> 00:32:14,080
and we need to specify

00:32:11,600 --> 00:32:16,080
all the different keys for the site and

00:32:14,080 --> 00:32:17,039
we also want to specify what file system

00:32:16,080 --> 00:32:20,480
we want to use

00:32:17,039 --> 00:32:22,880
in this case xfs we want to specify the

00:32:20,480 --> 00:32:26,480
reclaim policy

00:32:22,880 --> 00:32:29,120
and we want to allow

00:32:26,480 --> 00:32:30,320
volume expansion and we want to make

00:32:29,120 --> 00:32:33,039
sure that the

00:32:30,320 --> 00:32:34,080
the volume binding mode is immediate so

00:32:33,039 --> 00:32:37,360
when the pv gets

00:32:34,080 --> 00:32:39,200
bound to the pvc we

00:32:37,360 --> 00:32:40,480
can use it immediately and we don't care

00:32:39,200 --> 00:32:42,880
where kubernetes

00:32:40,480 --> 00:32:44,480
schedules in so we're going to create

00:32:42,880 --> 00:32:48,080
that

00:32:44,480 --> 00:32:51,200
the next step here is

00:32:48,080 --> 00:32:53,120
creating a persistent volume claim

00:32:51,200 --> 00:32:54,240
and you can also see here that in this

00:32:53,120 --> 00:32:57,840
particular storage class

00:32:54,240 --> 00:32:57,840
we marked it as default

00:32:59,360 --> 00:33:03,360
and this is the persistent volume claim

00:33:01,279 --> 00:33:05,519
i'm just going to give it a name

00:33:03,360 --> 00:33:07,360
specify access mode read write once

00:33:05,519 --> 00:33:10,480
because it's a block storage back end

00:33:07,360 --> 00:33:11,039
i'm using and i'm going to make that

00:33:10,480 --> 00:33:13,360
volume

00:33:11,039 --> 00:33:14,880
32 gig initially i'm going to resize

00:33:13,360 --> 00:33:16,240
this later i'm going to show you how

00:33:14,880 --> 00:33:23,919
that works

00:33:16,240 --> 00:33:25,279
so we're just going to create that

00:33:23,919 --> 00:33:28,480
persistent volume claim

00:33:25,279 --> 00:33:29,600
created and we can see here that the

00:33:28,480 --> 00:33:31,360
status is bound

00:33:29,600 --> 00:33:33,200
and the volume is actually a reference

00:33:31,360 --> 00:33:35,360
in there in the volume columns

00:33:33,200 --> 00:33:37,600
referencing the actual pv

00:33:35,360 --> 00:33:41,360
which is which shows here even more

00:33:37,600 --> 00:33:41,360
metadata about that particular

00:33:42,320 --> 00:33:49,440
persistent volume all right

00:33:46,960 --> 00:33:50,480
let's uh see what we can do next let's

00:33:49,440 --> 00:33:53,760
uh yeah so

00:33:50,480 --> 00:33:56,799
i'm going to deploy my sequel with the

00:33:53,760 --> 00:33:58,480
with help i'm going to specify my sql

00:33:56,799 --> 00:34:00,480
root password as admin i

00:33:58,480 --> 00:34:02,159
don't recommend that and i'm going to

00:34:00,480 --> 00:34:02,799
use my existing claim that i just

00:34:02,159 --> 00:34:04,320
created

00:34:02,799 --> 00:34:07,360
right so i'm just going to help install

00:34:04,320 --> 00:34:10,560
my sql reference the

00:34:07,360 --> 00:34:12,800
the values file and specify stable

00:34:10,560 --> 00:34:14,000
slash mysql and i managed to get the

00:34:12,800 --> 00:34:17,440
helm syntax right

00:34:14,000 --> 00:34:18,320
right in this example just going to wait

00:34:17,440 --> 00:34:22,079
for the um

00:34:18,320 --> 00:34:22,079
by sql deployment to come up

00:34:27,040 --> 00:34:34,159
we're waiting the dolphin

00:34:30,639 --> 00:34:37,200
there we go successfully uh rolled out

00:34:34,159 --> 00:34:39,040
and uh then i'm gonna exec into the

00:34:37,200 --> 00:34:41,359
container here and then

00:34:39,040 --> 00:34:43,280
or into the pot i'd say and and and do

00:34:41,359 --> 00:34:46,000
some inspection here for you

00:34:43,280 --> 00:34:46,720
to show how things are wired up so so i

00:34:46,000 --> 00:34:49,520
know that

00:34:46,720 --> 00:34:50,000
uh the mount points for my sequel is

00:34:49,520 --> 00:34:51,440
usually

00:34:50,000 --> 00:34:54,079
my sequel something i'm just going to

00:34:51,440 --> 00:34:54,720
grab that uh we'll see that we have in

00:34:54,079 --> 00:34:57,040
the um

00:34:54,720 --> 00:34:57,839
we have a multipath device uh mounted on

00:34:57,040 --> 00:35:01,440
slash

00:34:57,839 --> 00:35:02,960
mysql uh it's a xfs file system

00:35:01,440 --> 00:35:04,960
and we can see here with the disk free

00:35:02,960 --> 00:35:08,480
command that we have a

00:35:04,960 --> 00:35:10,800
32gb volume mounted there and i'm just

00:35:08,480 --> 00:35:14,000
going to jump into the database here

00:35:10,800 --> 00:35:15,839
and create a new database

00:35:14,000 --> 00:35:18,240
and you will see that a database gets

00:35:15,839 --> 00:35:21,599
created on the

00:35:18,240 --> 00:35:21,599
on the volume there we go

00:35:22,160 --> 00:35:27,280
pop back out and when

00:35:25,520 --> 00:35:28,720
we can now see that we have that

00:35:27,280 --> 00:35:31,839
database

00:35:28,720 --> 00:35:31,839
living in the file system

00:35:32,480 --> 00:35:36,320
which references that persistent volume

00:35:38,240 --> 00:35:41,599
all right we're going to pop out in the

00:35:40,480 --> 00:35:45,200
shell here again

00:35:41,599 --> 00:35:47,359
and i prepared a um a separate

00:35:45,200 --> 00:35:48,640
persistent volume claim uh yaml

00:35:47,359 --> 00:35:51,760
specification

00:35:48,640 --> 00:35:52,640
that will essentially expand the volume

00:35:51,760 --> 00:35:55,760
so i'm going to double

00:35:52,640 --> 00:35:55,760
the size of the volume

00:35:56,720 --> 00:36:01,119
and we also referenced the same pvc

00:35:58,640 --> 00:36:04,079
there so i'm just going to apply that

00:36:01,119 --> 00:36:04,960
you can do different methods here right

00:36:04,079 --> 00:36:07,280
so you can

00:36:04,960 --> 00:36:08,320
uh you can edit the pvc you can do a

00:36:07,280 --> 00:36:09,920
cube call edit

00:36:08,320 --> 00:36:12,000
and reference the pvc on the running

00:36:09,920 --> 00:36:15,119
cluster you can also use

00:36:12,000 --> 00:36:18,720
the cube cuddle patch command

00:36:15,119 --> 00:36:21,680
to to patch it and

00:36:18,720 --> 00:36:22,960
and and it doesn't really matter which

00:36:21,680 --> 00:36:26,480
way you go right i mean

00:36:22,960 --> 00:36:29,839
you will get the exact same results

00:36:26,480 --> 00:36:32,320
so i'm just putting a cube color get uh

00:36:29,839 --> 00:36:33,920
on my persistent volume claim here and

00:36:32,320 --> 00:36:35,040
i'm just going to wait for the capacity

00:36:33,920 --> 00:36:36,560
to expand here

00:36:35,040 --> 00:36:40,000
so what happens here in the background

00:36:36,560 --> 00:36:43,040
is that the um the csi

00:36:40,000 --> 00:36:45,599
resizer sidecar

00:36:43,040 --> 00:36:47,119
tells the underlying csi driver to

00:36:45,599 --> 00:36:48,800
expand the volume

00:36:47,119 --> 00:36:50,480
the volume gets expanded on the back-end

00:36:48,800 --> 00:36:53,760
storage system

00:36:50,480 --> 00:36:55,839
and once that operation completes

00:36:53,760 --> 00:36:56,960
then there's a node expansion operation

00:36:55,839 --> 00:36:59,520
that happens that

00:36:56,960 --> 00:37:00,480
talks to the csi node driver and that

00:36:59,520 --> 00:37:04,160
will essentially

00:37:00,480 --> 00:37:06,560
expand the file system on the um

00:37:04,160 --> 00:37:07,359
on the node itself right so it will do

00:37:06,560 --> 00:37:11,440
xfs

00:37:07,359 --> 00:37:14,160
resize there we go 64 gig now

00:37:11,440 --> 00:37:14,800
and once we kind of clear this watch

00:37:14,160 --> 00:37:18,560
here we'll

00:37:14,800 --> 00:37:21,680
jump back into the container and see

00:37:18,560 --> 00:37:22,400
that we can actually leverage that extra

00:37:21,680 --> 00:37:25,200
capacity

00:37:22,400 --> 00:37:27,119
yeah so there we go uh 64 gig mounted on

00:37:25,200 --> 00:37:28,960
slash wall in my sequel

00:37:27,119 --> 00:37:30,160
and you don't need to restore anything

00:37:28,960 --> 00:37:32,400
or

00:37:30,160 --> 00:37:34,960
doing any other operations so that is

00:37:32,400 --> 00:37:38,079
basically how simple it is to

00:37:34,960 --> 00:37:38,560
expand a volume in kubernetes with a csi

00:37:38,079 --> 00:37:41,920
driver

00:37:38,560 --> 00:37:42,400
that supports it and this is all user

00:37:41,920 --> 00:37:44,960
driven

00:37:42,400 --> 00:37:45,440
right so since the persistent volume

00:37:44,960 --> 00:37:48,480
claims

00:37:45,440 --> 00:37:50,640
are namespaced you will then be able to

00:37:48,480 --> 00:37:55,200
the end user will basically be able to

00:37:50,640 --> 00:37:55,200
uh to expand the persistent volume claim

00:37:57,760 --> 00:38:02,800
all right that was the dynamic

00:38:00,800 --> 00:38:05,520
provisioning

00:38:02,800 --> 00:38:06,640
101 i'd say uh i just want to talk a

00:38:05,520 --> 00:38:07,760
little bit about the workload

00:38:06,640 --> 00:38:09,760
controllers here

00:38:07,760 --> 00:38:11,040
you notice i i deploy the application

00:38:09,760 --> 00:38:14,079
using a helm chart

00:38:11,040 --> 00:38:16,000
uh which is kind of practical on how to

00:38:14,079 --> 00:38:18,000
how and how you would manage

00:38:16,000 --> 00:38:19,680
applications on

00:38:18,000 --> 00:38:21,119
on kubernetes right but what you see

00:38:19,680 --> 00:38:25,680
here in these two windows here

00:38:21,119 --> 00:38:29,359
is sort of like most controllers they

00:38:25,680 --> 00:38:30,240
reference uh volumes in in the pod

00:38:29,359 --> 00:38:32,800
specification

00:38:30,240 --> 00:38:33,760
right so you specify a mount path and

00:38:32,800 --> 00:38:35,920
then you give

00:38:33,760 --> 00:38:37,760
the volume out a name which is my mount

00:38:35,920 --> 00:38:40,079
and then you have a volume section

00:38:37,760 --> 00:38:41,839
uh which points to the persistent volume

00:38:40,079 --> 00:38:43,520
claim claim name

00:38:41,839 --> 00:38:45,839
and that's kind of how you key those two

00:38:43,520 --> 00:38:47,760
together right on the right hand side on

00:38:45,839 --> 00:38:48,800
this slide you will see the stateful set

00:38:47,760 --> 00:38:51,520
and that is

00:38:48,800 --> 00:38:52,320
slightly different from the other

00:38:51,520 --> 00:38:54,480
controllers

00:38:52,320 --> 00:38:55,839
right there you have a construct called

00:38:54,480 --> 00:39:00,160
a volume clamp

00:38:55,839 --> 00:39:02,400
claim template and that is basically a

00:39:00,160 --> 00:39:03,520
it's more of a less a inline

00:39:02,400 --> 00:39:06,320
specification

00:39:03,520 --> 00:39:08,000
a persistent volume claim specification

00:39:06,320 --> 00:39:08,480
where you call out the storage class

00:39:08,000 --> 00:39:10,800
name

00:39:08,480 --> 00:39:12,960
if you want you can leave that to the

00:39:10,800 --> 00:39:15,520
default one to resolve it

00:39:12,960 --> 00:39:17,280
or and you also provide like how much

00:39:15,520 --> 00:39:19,680
capacity each of the volumes

00:39:17,280 --> 00:39:21,119
are supposed to have and but you still

00:39:19,680 --> 00:39:22,880
use that uh keying

00:39:21,119 --> 00:39:25,440
with the volume mount for a particular

00:39:22,880 --> 00:39:27,200
path uh in the volume claim template

00:39:25,440 --> 00:39:29,119
right so what happens here is when you

00:39:27,200 --> 00:39:31,440
deploy the stateful set say you you

00:39:29,119 --> 00:39:32,320
deploy a single replica stable set that

00:39:31,440 --> 00:39:35,200
will provision

00:39:32,320 --> 00:39:37,280
one volume and after you as you scale

00:39:35,200 --> 00:39:39,839
the stateful set it will provision

00:39:37,280 --> 00:39:40,480
a new volume for each replica that comes

00:39:39,839 --> 00:39:42,320
online

00:39:40,480 --> 00:39:44,480
right and and that's why it's very

00:39:42,320 --> 00:39:46,720
practical to use read write one storage

00:39:44,480 --> 00:39:48,079
uh with with with a stateful set because

00:39:46,720 --> 00:39:49,920
that individual pod

00:39:48,079 --> 00:39:51,760
will have private access to that

00:39:49,920 --> 00:39:54,640
particular volume

00:39:51,760 --> 00:39:56,560
and that is uh that was a short slide

00:39:54,640 --> 00:39:57,359
because we are already on hands-on lab

00:39:56,560 --> 00:39:59,119
number three

00:39:57,359 --> 00:40:00,880
where we will deploy an application

00:39:59,119 --> 00:40:02,640
utilizing a stateful set

00:40:00,880 --> 00:40:05,359
so hang on here while i'll switch over

00:40:02,640 --> 00:40:05,359
to my terminal

00:40:06,240 --> 00:40:09,839
so what i'm going to do here is deploy

00:40:08,800 --> 00:40:13,920
redis

00:40:09,839 --> 00:40:16,960
i'm going to deploy it with a

00:40:13,920 --> 00:40:18,880
a helm chart as well and this is the

00:40:16,960 --> 00:40:22,079
values file i'm going to provide

00:40:18,880 --> 00:40:24,640
a use password equals false

00:40:22,079 --> 00:40:26,720
and i'm also going to uh prepare a watch

00:40:24,640 --> 00:40:27,200
command here right so this watch command

00:40:26,720 --> 00:40:29,200
will

00:40:27,200 --> 00:40:30,240
watch my stateful sets my pods and my

00:40:29,200 --> 00:40:33,119
pvc

00:40:30,240 --> 00:40:34,800
as redis comes up right so i'm just

00:40:33,119 --> 00:40:38,160
gonna do a helm install

00:40:34,800 --> 00:40:38,880
call it my redis reference my values

00:40:38,160 --> 00:40:40,800
file

00:40:38,880 --> 00:40:42,640
and i'm going to use the bitnami

00:40:40,800 --> 00:40:45,920
distribution of redis

00:40:42,640 --> 00:40:45,920
and here we go

00:40:49,200 --> 00:40:53,280
and here's my watch command that i had

00:40:50,960 --> 00:40:55,920
prepared and you will see here

00:40:53,280 --> 00:40:57,119
that the the main instance is already

00:40:55,920 --> 00:41:01,680
coming up

00:40:57,119 --> 00:41:04,400
and there's also a a replica instance

00:41:01,680 --> 00:41:04,800
being set up as well and down in the

00:41:04,400 --> 00:41:06,800
list

00:41:04,800 --> 00:41:09,200
of persistent volume claims you will see

00:41:06,800 --> 00:41:11,520
that there are two claims

00:41:09,200 --> 00:41:13,359
uh that has been fulfilled and now you

00:41:11,520 --> 00:41:13,920
can see that there is another pod coming

00:41:13,359 --> 00:41:15,760
up and

00:41:13,920 --> 00:41:17,040
it automatically created a new

00:41:15,760 --> 00:41:20,079
persistent volume claim

00:41:17,040 --> 00:41:22,560
right and once all these uh

00:41:20,079 --> 00:41:23,839
ports have started uh all this uh that

00:41:22,560 --> 00:41:24,720
means that all the storage has been

00:41:23,839 --> 00:41:26,240
attached

00:41:24,720 --> 00:41:28,160
uh from the persistent volume claims

00:41:26,240 --> 00:41:30,880
that were dynamically provisioned

00:41:28,160 --> 00:41:31,680
right and although you're using a helm

00:41:30,880 --> 00:41:34,240
chart here

00:41:31,680 --> 00:41:35,280
uh it is a stateful set that red is

00:41:34,240 --> 00:41:37,680
leverages

00:41:35,280 --> 00:41:39,040
and you can see by the persistent naming

00:41:37,680 --> 00:41:42,240
of the volumes here that

00:41:39,040 --> 00:41:43,599
there are derived from what you call the

00:41:42,240 --> 00:41:46,720
release name

00:41:43,599 --> 00:41:47,280
and and so forth and that that means

00:41:46,720 --> 00:41:49,040
that

00:41:47,280 --> 00:41:50,800
you have predictive naming of the

00:41:49,040 --> 00:41:52,640
volumes and the same thing with the

00:41:50,800 --> 00:41:54,319
with the network naming and stable sets

00:41:52,640 --> 00:41:56,640
as well that means that

00:41:54,319 --> 00:41:58,720
the the pods and the instances that runs

00:41:56,640 --> 00:42:00,400
in those pods will be able to find each

00:41:58,720 --> 00:42:04,480
other

00:42:00,400 --> 00:42:06,560
i'm just going to insert a key here um

00:42:04,480 --> 00:42:07,599
kubecon status what do we think it's

00:42:06,560 --> 00:42:08,960
awesome right

00:42:07,599 --> 00:42:11,280
so i'm just going to put that key in

00:42:08,960 --> 00:42:14,640
here and make sure that we

00:42:11,280 --> 00:42:16,640
we flush the store to disk and

00:42:14,640 --> 00:42:18,800
because i'm gonna i'm gonna use this in

00:42:16,640 --> 00:42:22,560
in subsequent uh

00:42:18,800 --> 00:42:25,760
labs throughout the presentation

00:42:22,560 --> 00:42:28,400
so we have the kubecon status is awesome

00:42:25,760 --> 00:42:31,839
i'm gonna exit there and i will go back

00:42:28,400 --> 00:42:31,839
to my powerpoint

00:42:32,400 --> 00:42:37,040
all right in this next section we're

00:42:34,640 --> 00:42:39,760
going to talk about csi snapshots and

00:42:37,040 --> 00:42:41,760
using pvc data sources and this is kind

00:42:39,760 --> 00:42:43,359
of where it starts to get interested we

00:42:41,760 --> 00:42:45,440
interesting because we kind of passed

00:42:43,359 --> 00:42:48,720
all the the basic stuff now

00:42:45,440 --> 00:42:51,440
right so the way

00:42:48,720 --> 00:42:52,160
csi snapshots work in kubernetes is that

00:42:51,440 --> 00:42:54,160
it works

00:42:52,160 --> 00:42:55,760
very similar to how persistent storage

00:42:54,160 --> 00:42:57,520
works right so you have something called

00:42:55,760 --> 00:42:59,599
a volume snapshot class

00:42:57,520 --> 00:43:01,680
which allows users to create something

00:42:59,599 --> 00:43:04,400
called a volume snapshot

00:43:01,680 --> 00:43:05,920
and you will have the uh the csi

00:43:04,400 --> 00:43:07,920
snapshotter

00:43:05,920 --> 00:43:08,960
will create something called a volume

00:43:07,920 --> 00:43:11,359
snapshot content

00:43:08,960 --> 00:43:12,720
that will basically point to the

00:43:11,359 --> 00:43:15,119
physical resource

00:43:12,720 --> 00:43:16,400
that references the external snapshot

00:43:15,119 --> 00:43:18,800
right so we will

00:43:16,400 --> 00:43:19,520
start the next hanson lab by creating

00:43:18,800 --> 00:43:22,480
the

00:43:19,520 --> 00:43:22,880
first of all uh yeah i forgot to mention

00:43:22,480 --> 00:43:26,960
this

00:43:22,880 --> 00:43:30,240
right so so the csi snapshot sidecar

00:43:26,960 --> 00:43:31,200
is not installed by default by the csi

00:43:30,240 --> 00:43:33,520
driver

00:43:31,200 --> 00:43:35,119
the csi snapshotter is provided by the

00:43:33,520 --> 00:43:36,640
kubernetes distribution

00:43:35,119 --> 00:43:38,319
right so you need to check with your

00:43:36,640 --> 00:43:40,560
kubernetes distribution vendor

00:43:38,319 --> 00:43:42,079
if the csi snapshot or sidecar is

00:43:40,560 --> 00:43:44,880
installed or not

00:43:42,079 --> 00:43:47,599
in this exercise since i'm leveraging

00:43:44,880 --> 00:43:48,880
vanilla upstream kubernetes

00:43:47,599 --> 00:43:51,280
i'm going to deploy the external

00:43:48,880 --> 00:43:53,359
snapshotter as part of the hands-on lab

00:43:51,280 --> 00:43:54,960
but once we kind of pass this what you

00:43:53,359 --> 00:43:56,640
can do is when once you have all these

00:43:54,960 --> 00:44:00,400
crds installed

00:43:56,640 --> 00:44:03,760
you can create a volume snapshot class

00:44:00,400 --> 00:44:07,040
and reference the again the csi

00:44:03,760 --> 00:44:09,119
driver that you um

00:44:07,040 --> 00:44:12,000
uh that you have installed on your

00:44:09,119 --> 00:44:14,640
cluster some uh

00:44:12,000 --> 00:44:16,720
some csi drivers provide custom keys to

00:44:14,640 --> 00:44:18,000
set different values for the parameters

00:44:16,720 --> 00:44:19,599
that you provide to the volumes natural

00:44:18,000 --> 00:44:20,720
cloud very similar to what you would do

00:44:19,599 --> 00:44:23,200
in a storage class

00:44:20,720 --> 00:44:24,720
if you have any specific parameters you

00:44:23,200 --> 00:44:25,119
want to supply to the driver when you've

00:44:24,720 --> 00:44:27,040
done it

00:44:25,119 --> 00:44:28,640
when you provision a snapshot or

00:44:27,040 --> 00:44:29,200
provision a volume in the storage class

00:44:28,640 --> 00:44:32,480
case

00:44:29,200 --> 00:44:32,960
right and the volume snapshot is also

00:44:32,480 --> 00:44:35,280
very

00:44:32,960 --> 00:44:36,400
simple all you have to do is specify a

00:44:35,280 --> 00:44:39,280
source is just

00:44:36,400 --> 00:44:40,079
what actual persistent volume claim do

00:44:39,280 --> 00:44:43,599
you want to take

00:44:40,079 --> 00:44:45,680
a snapshot of and and that

00:44:43,599 --> 00:44:47,520
then will create a point in time copy of

00:44:45,680 --> 00:44:49,200
that persistent volume claim

00:44:47,520 --> 00:44:51,440
with the content that's in that volume

00:44:49,200 --> 00:44:54,480
at that point in time

00:44:51,440 --> 00:44:55,760
and the volume snapshot content again is

00:44:54,480 --> 00:44:58,000
that is sort of like the physical

00:44:55,760 --> 00:44:59,760
representation on how your back-end

00:44:58,000 --> 00:45:01,200
storage system will be able to find that

00:44:59,760 --> 00:45:03,040
piece of storage

00:45:01,200 --> 00:45:04,560
uh and and reference that in that

00:45:03,040 --> 00:45:08,000
particular snapshot

00:45:04,560 --> 00:45:10,400
so with that i'm going to dive into

00:45:08,000 --> 00:45:11,920
hands-on lab number four

00:45:10,400 --> 00:45:13,440
where i'm going to start deploying the

00:45:11,920 --> 00:45:15,119
csi snapshotter

00:45:13,440 --> 00:45:16,800
i'm going to create a volume snapshot

00:45:15,119 --> 00:45:18,720
class and

00:45:16,800 --> 00:45:20,240
i'm gonna create some volume snapshots

00:45:18,720 --> 00:45:22,240
so uh let's

00:45:20,240 --> 00:45:24,400
go ahead i'm gonna switch over to my

00:45:22,240 --> 00:45:27,440
terminal uh one second

00:45:24,400 --> 00:45:30,640
all right uh let's start by cloning the

00:45:27,440 --> 00:45:35,119
uh kubernetes csi external

00:45:30,640 --> 00:45:35,119
snapshotter repository

00:45:36,480 --> 00:45:41,760
and then we need to create

00:45:39,680 --> 00:45:43,440
some resources that are provided in that

00:45:41,760 --> 00:45:46,480
repository so

00:45:43,440 --> 00:45:48,560
it's the crds that provides the volume

00:45:46,480 --> 00:45:50,400
snatch up classes volume volume snapshot

00:45:48,560 --> 00:45:51,520
contents and volume snapshot that i just

00:45:50,400 --> 00:45:53,440
talked about

00:45:51,520 --> 00:45:55,280
and then you actually need to deploy the

00:45:53,440 --> 00:45:58,000
actual uh csi

00:45:55,280 --> 00:45:58,800
snapshot controller itself and this you

00:45:58,000 --> 00:46:00,960
kind of need to do

00:45:58,800 --> 00:46:02,000
once per cluster and once that's

00:46:00,960 --> 00:46:05,280
deployed

00:46:02,000 --> 00:46:07,520
you can go right ahead and create volume

00:46:05,280 --> 00:46:09,280
snapshot classes

00:46:07,520 --> 00:46:10,800
i'm going to create a default volume

00:46:09,280 --> 00:46:11,520
snapshot class i'm only going to

00:46:10,800 --> 00:46:13,520
leverage one

00:46:11,520 --> 00:46:16,000
in this particular exercise i want to

00:46:13,520 --> 00:46:18,800
point out which driver i'm going to use

00:46:16,000 --> 00:46:20,720
and i also need to reference the

00:46:18,800 --> 00:46:23,920
particular secret the side card

00:46:20,720 --> 00:46:26,160
needs to talk to the the back end that

00:46:23,920 --> 00:46:26,160
we

00:46:26,839 --> 00:46:29,839
deployed

00:46:30,720 --> 00:46:37,359
all right um we're going to create the

00:46:34,079 --> 00:46:37,359
volume snapshot class

00:46:37,599 --> 00:46:44,720
there we go and i prepared a

00:46:40,640 --> 00:46:47,760
a bunch of volume

00:46:44,720 --> 00:46:50,240
snapshots and

00:46:47,760 --> 00:46:51,119
and this will essentially create new

00:46:50,240 --> 00:46:53,440
snapshots

00:46:51,119 --> 00:46:54,160
of the redis instance that i deployed

00:46:53,440 --> 00:46:56,880
right so here

00:46:54,160 --> 00:46:58,319
are the the three parts that make up my

00:46:56,880 --> 00:47:00,000
running radius instance and i'm going to

00:46:58,319 --> 00:47:01,920
create a snapshot on each of those

00:47:00,000 --> 00:47:04,880
persistent volume claims

00:47:01,920 --> 00:47:10,480
that got created when i deployed that

00:47:04,880 --> 00:47:14,640
radius instance

00:47:10,480 --> 00:47:14,640
there we go i'm going to create those

00:47:15,599 --> 00:47:18,640
they're usually created quite fast

00:47:17,280 --> 00:47:20,880
snapshots uh

00:47:18,640 --> 00:47:22,640
are nothing is not usually a heavy

00:47:20,880 --> 00:47:23,040
operation for the back-end storage so i

00:47:22,640 --> 00:47:25,440
can

00:47:23,040 --> 00:47:26,800
do a get there we can see that they're

00:47:25,440 --> 00:47:29,599
uh i'm

00:47:26,800 --> 00:47:31,200
immediately ready to use uh the source

00:47:29,599 --> 00:47:33,359
pvc that we're referencing and the

00:47:31,200 --> 00:47:35,200
restore size you can see in the column

00:47:33,359 --> 00:47:36,800
uh there are a lot of columns here that

00:47:35,200 --> 00:47:41,119
have actually been truncated

00:47:36,800 --> 00:47:41,119
and you can check the outputs in the um

00:47:42,800 --> 00:47:47,040
in the askinimacast files but there are

00:47:45,520 --> 00:47:48,480
there's a bunch of other columns there

00:47:47,040 --> 00:47:51,760
as well

00:47:48,480 --> 00:47:52,319
so and that was actually how easy it was

00:47:51,760 --> 00:47:54,720
to

00:47:52,319 --> 00:47:56,319
create a volume snapshot class and

00:47:54,720 --> 00:47:57,599
create a bunch of snapshots that

00:47:56,319 --> 00:48:00,480
references

00:47:57,599 --> 00:48:01,760
existing pvcs and now we have point in

00:48:00,480 --> 00:48:05,280
time copies

00:48:01,760 --> 00:48:06,400
of our particular redis instance

00:48:05,280 --> 00:48:09,200
so i'm going to switch back to my

00:48:06,400 --> 00:48:09,200
powerpoint here

00:48:09,680 --> 00:48:15,200
in this first exercise

00:48:12,960 --> 00:48:16,400
where we created a volume snapshot class

00:48:15,200 --> 00:48:18,079
and a volume snapshot

00:48:16,400 --> 00:48:20,079
what i want to be able to do is to

00:48:18,079 --> 00:48:22,960
create a new persistent volume

00:48:20,079 --> 00:48:24,960
claim uh that references my volume

00:48:22,960 --> 00:48:27,040
snapshot so this is an example

00:48:24,960 --> 00:48:28,800
persistent volume claim how you would

00:48:27,040 --> 00:48:29,440
reference a snapshot when you create a

00:48:28,800 --> 00:48:31,359
pvc

00:48:29,440 --> 00:48:32,559
right so you have the data source stanza

00:48:31,359 --> 00:48:35,359
here which

00:48:32,559 --> 00:48:36,160
calls out the the um the snapshot name

00:48:35,359 --> 00:48:38,559
you want to use

00:48:36,160 --> 00:48:41,280
what kind it is uh it could be a volume

00:48:38,559 --> 00:48:44,240
snapshot or a persistent volume claim

00:48:41,280 --> 00:48:44,880
um so so far there are other things

00:48:44,240 --> 00:48:48,079
coming here

00:48:44,880 --> 00:48:51,280
um that's not been released yet

00:48:48,079 --> 00:48:53,200
and then when you're using a volume

00:48:51,280 --> 00:48:54,160
snapshot since the volume snapshot is a

00:48:53,200 --> 00:48:56,000
beta feature

00:48:54,160 --> 00:48:58,000
you need to call out the api group as

00:48:56,000 --> 00:49:01,200
well that you want to look for

00:48:58,000 --> 00:49:03,520
this particular kind right and here is a

00:49:01,200 --> 00:49:04,720
very important detail that i i want to

00:49:03,520 --> 00:49:06,400
just call out here

00:49:04,720 --> 00:49:08,000
is that when you create persistent

00:49:06,400 --> 00:49:10,960
volume claims from

00:49:08,000 --> 00:49:11,760
existing snapshots and such is that the

00:49:10,960 --> 00:49:15,280
the storage

00:49:11,760 --> 00:49:17,359
request needs to match what the actual

00:49:15,280 --> 00:49:19,520
snapshot is so you cannot

00:49:17,359 --> 00:49:20,880
say that you took a snapshot of a volume

00:49:19,520 --> 00:49:24,559
and it was two terabytes

00:49:20,880 --> 00:49:26,000
you actually need to uh create a new pvc

00:49:24,559 --> 00:49:30,960
with the exact sign

00:49:26,000 --> 00:49:33,920
it's exact same size as the the volume

00:49:30,960 --> 00:49:34,720
volume snapshot so uh without further

00:49:33,920 --> 00:49:36,640
ado

00:49:34,720 --> 00:49:37,839
i'm gonna dive into lab number five here

00:49:36,640 --> 00:49:41,440
or the hands-on

00:49:37,839 --> 00:49:43,280
lab number five and create a new pvc

00:49:41,440 --> 00:49:44,720
uh from the volume snapshots that we

00:49:43,280 --> 00:49:48,240
just created

00:49:44,720 --> 00:49:49,760
and attach a new redis instance to that

00:49:48,240 --> 00:49:52,160
so i'm just going to switch over to my

00:49:49,760 --> 00:49:52,160
terminal

00:49:52,240 --> 00:49:56,720
so i'm going to use the the volume

00:49:54,960 --> 00:50:00,559
snapshots that we just created

00:49:56,720 --> 00:50:05,440
right and how i'm going to attach those

00:50:00,559 --> 00:50:07,040
is basically i have a set of pvcs

00:50:05,440 --> 00:50:09,359
that references those particular

00:50:07,040 --> 00:50:09,760
snapshots right so in my data source

00:50:09,359 --> 00:50:13,200
stands

00:50:09,760 --> 00:50:14,559
here i reference the the snapshots i

00:50:13,200 --> 00:50:14,800
want to use for each of the snapshots

00:50:14,559 --> 00:50:17,520
i'm

00:50:14,800 --> 00:50:19,760
basically going to start up a new redis

00:50:17,520 --> 00:50:22,400
instance

00:50:19,760 --> 00:50:24,480
that i created initially in this

00:50:22,400 --> 00:50:27,680
tutorial

00:50:24,480 --> 00:50:29,680
and see if i have my

00:50:27,680 --> 00:50:31,599
key that i inserted in the first

00:50:29,680 --> 00:50:33,440
exercise right

00:50:31,599 --> 00:50:36,319
so now i'm going to create those pvcs

00:50:33,440 --> 00:50:39,119
from the snapshots

00:50:36,319 --> 00:50:40,480
i have a bunch of yaml here that you

00:50:39,119 --> 00:50:42,319
might have already seen

00:50:40,480 --> 00:50:43,680
i now created the persistent volume

00:50:42,319 --> 00:50:46,000
claims

00:50:43,680 --> 00:50:47,599
and you can see here since the stateful

00:50:46,000 --> 00:50:50,559
sets have predictive naming

00:50:47,599 --> 00:50:51,920
i know what those the persistent volumes

00:50:50,559 --> 00:50:53,680
are going to be called right so when i

00:50:51,920 --> 00:50:55,280
bring up my redis instance

00:50:53,680 --> 00:50:56,800
i know what persistent volume claim is

00:50:55,280 --> 00:51:00,079
going to ask for right

00:50:56,800 --> 00:51:04,240
so that's so when i name my new instance

00:51:00,079 --> 00:51:06,720
my new redis that means that it will

00:51:04,240 --> 00:51:08,400
either dynamically provision a

00:51:06,720 --> 00:51:09,839
persistent volume claim of that name or

00:51:08,400 --> 00:51:12,480
use the existing one

00:51:09,839 --> 00:51:15,280
right and since i pre-created these

00:51:12,480 --> 00:51:16,960
persistent volume claims

00:51:15,280 --> 00:51:18,640
what essentially happens is that those

00:51:16,960 --> 00:51:23,280
precision voltage claims will be

00:51:18,640 --> 00:51:25,040
attached to the redis instance

00:51:23,280 --> 00:51:27,040
there we go i just want to make sure

00:51:25,040 --> 00:51:29,280
that the instance come up here before we

00:51:27,040 --> 00:51:29,280
um

00:51:30,319 --> 00:51:34,000
before we start poking around in it

00:51:35,359 --> 00:51:40,319
thankfully uh helm makes it easy to find

00:51:37,680 --> 00:51:43,680
the resources that we want to look at

00:51:40,319 --> 00:51:46,000
so we can see here that my new redis

00:51:43,680 --> 00:51:48,000
instance is coming up here i do not list

00:51:46,000 --> 00:51:49,119
the persistent volume claims here

00:51:48,000 --> 00:51:50,800
because

00:51:49,119 --> 00:51:52,400
since i created a persistent volume

00:51:50,800 --> 00:51:53,119
claims and helm did not create that

00:51:52,400 --> 00:51:56,400
resource

00:51:53,119 --> 00:51:59,040
i wouldn't be able to qualify the label

00:51:56,400 --> 00:52:01,280
with release equals my new redis

00:51:59,040 --> 00:52:02,960
but i know that the correct persistent

00:52:01,280 --> 00:52:05,839
volume claims are getting

00:52:02,960 --> 00:52:05,839
connected

00:52:09,760 --> 00:52:12,880
right we're up and running

00:52:13,520 --> 00:52:19,839
so i'm just going to exec into that

00:52:16,000 --> 00:52:19,839
redis instance that i just created

00:52:22,960 --> 00:52:28,319
typos are common i'm going to run the

00:52:26,160 --> 00:52:30,640
radius cli directly

00:52:28,319 --> 00:52:33,839
and i should be able to get the kubecon

00:52:30,640 --> 00:52:33,839
status key

00:52:35,440 --> 00:52:39,200
there we go it's awesome so that is

00:52:37,359 --> 00:52:42,800
basically how you would

00:52:39,200 --> 00:52:44,880
clone a an application

00:52:42,800 --> 00:52:46,480
leveraging multiple persistent volume

00:52:44,880 --> 00:52:48,880
claims from

00:52:46,480 --> 00:52:50,880
multiple snapshots using predictive

00:52:48,880 --> 00:52:53,520
naming

00:52:50,880 --> 00:52:54,960
thanks to the the stateful set right so

00:52:53,520 --> 00:52:57,599
now you would be able to

00:52:54,960 --> 00:52:58,839
provision as many instances you want of

00:52:57,599 --> 00:53:02,400
that particular

00:52:58,839 --> 00:53:05,119
application and since

00:53:02,400 --> 00:53:06,800
the snapshot pvcs that you just created

00:53:05,119 --> 00:53:08,319
are not

00:53:06,800 --> 00:53:10,240
impacting production you would be able

00:53:08,319 --> 00:53:12,480
to do destructive changes

00:53:10,240 --> 00:53:15,440
on this particular application add keys

00:53:12,480 --> 00:53:17,200
remove keys and

00:53:15,440 --> 00:53:18,640
connect an external application to it to

00:53:17,200 --> 00:53:20,880
do some testing

00:53:18,640 --> 00:53:22,480
and obviously this is a very tiny data

00:53:20,880 --> 00:53:24,400
set but it wouldn't really matter if

00:53:22,480 --> 00:53:25,680
this could have been a multi-terabyte

00:53:24,400 --> 00:53:28,400
database right

00:53:25,680 --> 00:53:30,160
and that is very popular for ci cd use

00:53:28,400 --> 00:53:34,079
cases where you want to attach

00:53:30,160 --> 00:53:34,079
production like data into

00:53:34,559 --> 00:53:39,040
into your testing and dev environments

00:53:37,839 --> 00:53:41,520
so i'm just going to switch back to my

00:53:39,040 --> 00:53:44,720
powerpoint here hang on

00:53:41,520 --> 00:53:47,920
right the next demo i'm going to do is

00:53:44,720 --> 00:53:50,000
basically create a

00:53:47,920 --> 00:53:52,160
new persistent volume claim from an

00:53:50,000 --> 00:53:52,559
existing existing persistent volume

00:53:52,160 --> 00:53:56,480
claim

00:53:52,559 --> 00:53:58,400
and that means that you won't have a

00:53:56,480 --> 00:54:01,040
intermediate snapshot right so you will

00:53:58,400 --> 00:54:02,319
create the new pvc directly from the

00:54:01,040 --> 00:54:04,720
from the source one

00:54:02,319 --> 00:54:07,040
and this does not require the external

00:54:04,720 --> 00:54:09,760
csi snapshotter so

00:54:07,040 --> 00:54:10,319
as long as the the the csi driver

00:54:09,760 --> 00:54:13,440
supports

00:54:10,319 --> 00:54:15,359
data source uh a persistent volume claim

00:54:13,440 --> 00:54:17,200
data source i'd say

00:54:15,359 --> 00:54:18,720
you will be able to use this capability

00:54:17,200 --> 00:54:22,079
and features so

00:54:18,720 --> 00:54:24,240
without further ado i'm going to switch

00:54:22,079 --> 00:54:26,640
over to hands-on lab number six

00:54:24,240 --> 00:54:27,520
and create a new pvc from an existing

00:54:26,640 --> 00:54:29,839
pvc

00:54:27,520 --> 00:54:31,839
and attach an application i'm gonna

00:54:29,839 --> 00:54:33,200
switch back to my terminal

00:54:31,839 --> 00:54:36,319
all right so i'm just gonna show you the

00:54:33,200 --> 00:54:38,160
uh my pvcs from pvcs

00:54:36,319 --> 00:54:39,680
and that this is very similar to what i

00:54:38,160 --> 00:54:42,960
showed in the powerpoint slide here

00:54:39,680 --> 00:54:44,480
the data source what i'm going to use uh

00:54:42,960 --> 00:54:46,400
yeah again i'm going to use predictive

00:54:44,480 --> 00:54:48,720
name naming and i'm going to use

00:54:46,400 --> 00:54:50,079
my clone redis as the name the data

00:54:48,720 --> 00:54:51,440
source i'm going to specify is a

00:54:50,079 --> 00:54:53,440
persistent volume claim

00:54:51,440 --> 00:54:56,640
and these are the existing claims that

00:54:53,440 --> 00:54:56,640
got created initially

00:54:58,799 --> 00:55:05,119
i'm going to create those pvcs

00:55:02,160 --> 00:55:05,119
from pvcs

00:55:05,680 --> 00:55:10,400
and you will see that they will be

00:55:06,880 --> 00:55:10,400
instantly created as well

00:55:11,440 --> 00:55:14,720
i forgot to list them here

00:55:15,440 --> 00:55:22,319
or rest assured they will be provisioned

00:55:20,000 --> 00:55:23,280
so i'm going to install a third redis

00:55:22,319 --> 00:55:26,240
instance here

00:55:23,280 --> 00:55:35,839
and i'm going to call it my clone redis

00:55:26,240 --> 00:55:35,839
i'm going to watch it

00:55:37,599 --> 00:55:43,520
listed by label release equals my clone

00:55:41,119 --> 00:55:43,520
redis

00:55:47,680 --> 00:55:51,359
hopefully all my cluster nodes have the

00:55:49,440 --> 00:55:54,160
redis image by now so this should be

00:55:51,359 --> 00:55:54,160
fairly quickly

00:56:00,000 --> 00:56:03,839
it's creating

00:56:05,520 --> 00:56:10,160
there we go all the instances are up and

00:56:07,760 --> 00:56:10,160
running

00:56:15,680 --> 00:56:22,559
not running yet it's not ready yet

00:56:18,799 --> 00:56:24,480
there we are there we go ready one one

00:56:22,559 --> 00:56:28,839
all right so we should now be able to

00:56:24,480 --> 00:56:31,839
uh exec into my new clone

00:56:28,839 --> 00:56:34,559
redis

00:56:31,839 --> 00:56:36,720
clone radius instance yep that's right

00:56:34,559 --> 00:56:40,160
that's the name

00:56:36,720 --> 00:56:42,480
and run this red cli

00:56:40,160 --> 00:56:45,119
and i should be able to observe the key

00:56:42,480 --> 00:56:48,160
that we inserted in the

00:56:45,119 --> 00:56:50,559
initial deployment and there we go it's

00:56:48,160 --> 00:56:50,559
awesome

00:56:56,640 --> 00:57:00,240
and just to illustrate here i'm just

00:56:58,400 --> 00:57:02,720
going to list the volume snapshots and

00:57:00,240 --> 00:57:05,040
volume snapshot contents

00:57:02,720 --> 00:57:06,240
uh that we had and and this only

00:57:05,040 --> 00:57:09,440
references

00:57:06,240 --> 00:57:10,559
the um the original snapshots that we

00:57:09,440 --> 00:57:12,400
created right and

00:57:10,559 --> 00:57:14,480
what this basically means is that there

00:57:12,400 --> 00:57:16,720
is a snapshot created

00:57:14,480 --> 00:57:17,760
uh on the backend storage system but

00:57:16,720 --> 00:57:21,280
it's a snapshot

00:57:17,760 --> 00:57:24,079
that um kubernetes is unaware of

00:57:21,280 --> 00:57:26,160
so it's only the csi driver that knows

00:57:24,079 --> 00:57:30,079
how to

00:57:26,160 --> 00:57:33,440
create a snapshot from that existing pvc

00:57:30,079 --> 00:57:33,440
and attach that to

00:57:33,520 --> 00:57:36,880
the pvc that is running in in in the

00:57:35,280 --> 00:57:38,319
kubernetes cluster and

00:57:36,880 --> 00:57:41,040
and and resolve that and make sure it

00:57:38,319 --> 00:57:44,079
gets staged and

00:57:41,040 --> 00:57:47,200
attached properly all right

00:57:44,079 --> 00:57:47,760
that concludes lab number six i believe

00:57:47,200 --> 00:57:52,160
it was

00:57:47,760 --> 00:57:52,160
yep number six i'm gonna

00:57:53,440 --> 00:58:00,400
show something uh very similar here uh

00:57:57,440 --> 00:58:00,640
so in this particular case here uh what

00:58:00,400 --> 00:58:04,240
is

00:58:00,640 --> 00:58:07,599
fairly popular let's say that uh you

00:58:04,240 --> 00:58:10,079
accidentally delete a application

00:58:07,599 --> 00:58:13,520
right but you still have the volume

00:58:10,079 --> 00:58:16,880
snapshot say that you you delete the um

00:58:13,520 --> 00:58:19,200
you do a helmund install and you wipe

00:58:16,880 --> 00:58:21,280
your pvcs and all of a sudden oh

00:58:19,200 --> 00:58:23,040
that was not my intention you just

00:58:21,280 --> 00:58:24,880
wanted to install the app and

00:58:23,040 --> 00:58:26,559
reinstall the app but you accidentally

00:58:24,880 --> 00:58:28,240
wiped the pvcs but if you have the

00:58:26,559 --> 00:58:29,040
volume snapshots you will then be able

00:58:28,240 --> 00:58:32,640
to create

00:58:29,040 --> 00:58:34,559
a new a new instance from those

00:58:32,640 --> 00:58:35,839
with the original names that you had

00:58:34,559 --> 00:58:36,640
when you initially deployed the

00:58:35,839 --> 00:58:38,960
application

00:58:36,640 --> 00:58:39,920
and sort of revert to your previous

00:58:38,960 --> 00:58:42,240
state if

00:58:39,920 --> 00:58:43,359
you so will right so say that you would

00:58:42,240 --> 00:58:47,119
have a

00:58:43,359 --> 00:58:49,520
that's the other use case for using um

00:58:47,119 --> 00:58:52,400
the restoration procedure right so you

00:58:49,520 --> 00:58:52,400
would essentially

00:58:53,200 --> 00:58:58,000
uh yeah how would i describe this say

00:58:55,920 --> 00:59:00,240
that you're

00:58:58,000 --> 00:59:01,200
running your instance in production you

00:59:00,240 --> 00:59:03,839
would

00:59:01,200 --> 00:59:05,359
accidentally trash your data set right

00:59:03,839 --> 00:59:06,880
but you know that you have a snapshot

00:59:05,359 --> 00:59:10,000
from two hours before

00:59:06,880 --> 00:59:12,160
what you can do is that you can

00:59:10,000 --> 00:59:14,400
undeploy or uninstall the home chart in

00:59:12,160 --> 00:59:16,720
this case and then

00:59:14,400 --> 00:59:18,319
remove your original pvcs and then

00:59:16,720 --> 00:59:20,640
create new pvcs

00:59:18,319 --> 00:59:22,240
from the snapshots that you just created

00:59:20,640 --> 00:59:23,280
so i'm just going to dive into hands-on

00:59:22,240 --> 00:59:26,799
lab number seven

00:59:23,280 --> 00:59:30,240
and restore an application uh from

00:59:26,799 --> 00:59:32,319
a volume snapshot

00:59:30,240 --> 00:59:34,160
just going to switch over to my terminal

00:59:32,319 --> 00:59:38,000
we're back at the terminal

00:59:34,160 --> 00:59:38,000
and uh first i'm

00:59:38,799 --> 00:59:43,839
going to exec into my

00:59:44,880 --> 00:59:49,520
production instance and

00:59:48,079 --> 00:59:52,079
what i'm going to do here is i'm going

00:59:49,520 --> 00:59:54,079
to delete my status key right so

00:59:52,079 --> 00:59:56,079
you will see that i will actually so

00:59:54,079 --> 00:59:57,760
this is kind of an accidental deletion

00:59:56,079 --> 00:59:58,880
use case right so you will see that i've

00:59:57,760 --> 01:00:01,680
deleted

00:59:58,880 --> 01:00:04,000
the key doesn't exist there anymore i

01:00:01,680 --> 01:00:07,359
know that i have a good snapshot that i

01:00:04,000 --> 01:00:10,799
want to be able to leverage to restore

01:00:07,359 --> 01:00:11,359
my radius instance i'm just going to

01:00:10,799 --> 01:00:15,040
inspect

01:00:11,359 --> 01:00:16,559
the pvcs that i want to recreate

01:00:15,040 --> 01:00:18,240
and i'm going to recreate these with

01:00:16,559 --> 01:00:19,040
with the original names right and the

01:00:18,240 --> 01:00:22,240
original

01:00:19,040 --> 01:00:22,799
names of my volumes is just my redis no

01:00:22,240 --> 01:00:26,000
clone

01:00:22,799 --> 01:00:28,319
not my new whatever and the data source

01:00:26,000 --> 01:00:29,119
i'm going to reference is the um the

01:00:28,319 --> 01:00:30,799
snapshots

01:00:29,119 --> 01:00:32,559
that i know i have and we know that

01:00:30,799 --> 01:00:35,200
those snapshots are good because we

01:00:32,559 --> 01:00:37,599
already restored to a new application

01:00:35,200 --> 01:00:40,839
with uh with those particular snapshots

01:00:37,599 --> 01:00:43,839
we're gonna do a helmet uninstall my

01:00:40,839 --> 01:00:43,839
redis

01:00:44,160 --> 01:00:48,480
and i'm also going to wipe the

01:00:46,480 --> 01:00:52,240
persistent volume claims

01:00:48,480 --> 01:00:55,359
that um got created when we deploy that

01:00:52,240 --> 01:00:59,040
so i'm just going to filter by label

01:00:55,359 --> 01:00:59,040
and now the claims are gone

01:01:02,319 --> 01:01:07,119
and before we install the redis instance

01:01:05,680 --> 01:01:09,040
i just need to create my

01:01:07,119 --> 01:01:12,240
persistent volume claims make sure that

01:01:09,040 --> 01:01:12,240
those gets recreated

01:01:15,440 --> 01:01:18,720
i'm just going to list them here and we

01:01:17,119 --> 01:01:20,000
can see that yeah they're bound they're

01:01:18,720 --> 01:01:23,280
good

01:01:20,000 --> 01:01:25,040
uh we want to then attach

01:01:23,280 --> 01:01:26,880
the redis instance i'm going to install

01:01:25,040 --> 01:01:28,400
the exact same

01:01:26,880 --> 01:01:30,480
instance name that we did for the

01:01:28,400 --> 01:01:33,680
initial production

01:01:30,480 --> 01:01:36,079
and this should now

01:01:33,680 --> 01:01:39,040
bring back ourselves to the state we

01:01:36,079 --> 01:01:41,200
were when we took the snapshots

01:01:39,040 --> 01:01:44,319
and basically be ready to serve

01:01:41,200 --> 01:01:44,319
production yet again

01:01:45,599 --> 01:01:53,839
we want to wait for the instance to come

01:01:47,440 --> 01:01:53,839
up here

01:01:58,000 --> 01:02:02,480
the main instance is running we have one

01:02:00,640 --> 01:02:07,839
of the replica instance

01:02:02,480 --> 01:02:07,839
since this is running

01:02:10,880 --> 01:02:17,760
right uh the second replica is up and

01:02:14,160 --> 01:02:23,280
we should be able to um exec into

01:02:17,760 --> 01:02:23,280
the redis instance and list our key

01:02:25,520 --> 01:02:29,440
awesome we've now successfully restored

01:02:27,839 --> 01:02:32,839
the application to

01:02:29,440 --> 01:02:35,680
the status it had when we took the

01:02:32,839 --> 01:02:37,599
snapshot beautiful

01:02:35,680 --> 01:02:38,960
all right i'm going to switch back to my

01:02:37,599 --> 01:02:43,520
powerpoint here

01:02:38,960 --> 01:02:46,880
and the next section

01:02:43,520 --> 01:02:49,680
is going to talk about using

01:02:46,880 --> 01:02:51,760
raw block volumes and with that i just

01:02:49,680 --> 01:02:55,440
want to say that we kind of concluded

01:02:51,760 --> 01:02:58,960
the csi snapshots and cloning and using

01:02:55,440 --> 01:03:02,559
volume data sources so uh

01:02:58,960 --> 01:03:05,280
using raw block volumes is quite

01:03:02,559 --> 01:03:06,240
it's quite nifty so you may have this in

01:03:05,280 --> 01:03:08,480
the um

01:03:06,240 --> 01:03:10,559
persistent volume claims back in that

01:03:08,480 --> 01:03:12,960
stance that you have volume mode

01:03:10,559 --> 01:03:14,160
block and you will also have the same

01:03:12,960 --> 01:03:16,640
ability to specify

01:03:14,160 --> 01:03:17,760
particular storage class or not and but

01:03:16,640 --> 01:03:20,480
that is essentially

01:03:17,760 --> 01:03:22,480
everything you need to do to request a

01:03:20,480 --> 01:03:26,559
block volume from a csi driver

01:03:22,480 --> 01:03:29,599
that supports block storage and

01:03:26,559 --> 01:03:30,319
the way you would reference a a raw

01:03:29,599 --> 01:03:32,319
block volume

01:03:30,319 --> 01:03:33,440
in the port specification is slightly

01:03:32,319 --> 01:03:35,039
different from

01:03:33,440 --> 01:03:37,119
how you would do if it were a file

01:03:35,039 --> 01:03:38,960
system right because all of a sudden

01:03:37,119 --> 01:03:40,559
you're dealing with devices you don't

01:03:38,960 --> 01:03:43,119
have file systems on them

01:03:40,559 --> 01:03:44,160
right so that that's why the the volume

01:03:43,119 --> 01:03:46,000
mounts

01:03:44,160 --> 01:03:47,440
stance has been replaced by volume

01:03:46,000 --> 01:03:49,200
devices and

01:03:47,440 --> 01:03:50,720
instead instead of a mount path you have

01:03:49,200 --> 01:03:52,079
something called a device path and

01:03:50,720 --> 01:03:54,960
that's where you call out

01:03:52,079 --> 01:03:56,480
the virtual device uh and it's also

01:03:54,960 --> 01:03:56,880
ordered right so the first device that

01:03:56,480 --> 01:04:00,000
comes

01:03:56,880 --> 01:04:01,440
up comes to mind is the xvda and you

01:04:00,000 --> 01:04:03,760
will still have a volume standset

01:04:01,440 --> 01:04:06,960
persistent volume claim and a claim name

01:04:03,760 --> 01:04:08,960
and that you would reference and

01:04:06,960 --> 01:04:10,559
in in this particular example i'm gonna

01:04:08,960 --> 01:04:12,000
not yeah i'm just gonna switch over to

01:04:10,559 --> 01:04:14,319
the

01:04:12,000 --> 01:04:16,319
hands on lab number eight here and

01:04:14,319 --> 01:04:18,079
create a raw block device and attach a

01:04:16,319 --> 01:04:19,280
workload to that but this is a very

01:04:18,079 --> 01:04:22,640
simple

01:04:19,280 --> 01:04:26,400
example on how this works so bear

01:04:22,640 --> 01:04:28,000
with me here for a second

01:04:26,400 --> 01:04:29,839
so first i'm going to show you my block

01:04:28,000 --> 01:04:32,799
pvc here so i'm basically going to

01:04:29,839 --> 01:04:34,000
create a two terabyte block device uh

01:04:32,799 --> 01:04:36,880
with a volume mode

01:04:34,000 --> 01:04:37,680
set to block and it's also always

01:04:36,880 --> 01:04:41,839
default

01:04:37,680 --> 01:04:41,839
set to file system

01:04:42,960 --> 01:04:45,920
it's going to create that

01:04:48,000 --> 01:04:51,440
and then i'm going to run the very

01:04:49,680 --> 01:04:53,039
simple part it's the same specification

01:04:51,440 --> 01:04:54,880
i had in the powerpoint actually and

01:04:53,039 --> 01:04:56,559
it's just leveraging a tool called

01:04:54,880 --> 01:04:59,760
ioping

01:04:56,559 --> 01:05:02,880
and it calls the claim name that i just

01:04:59,760 --> 01:05:03,760
created and here we have the um the

01:05:02,880 --> 01:05:05,520
stanza that

01:05:03,760 --> 01:05:06,960
calls out the volume device and the

01:05:05,520 --> 01:05:09,359
device path

01:05:06,960 --> 01:05:10,559
and the results of this is essentially

01:05:09,359 --> 01:05:15,039
that we will

01:05:10,559 --> 01:05:15,039
this tool ioping will um

01:05:15,280 --> 01:05:18,960
will perform perform an io on that

01:05:17,359 --> 01:05:22,319
particular

01:05:18,960 --> 01:05:24,319
device once per second per default

01:05:22,319 --> 01:05:25,839
and you will see the results of that so

01:05:24,319 --> 01:05:27,359
i'm just going to wait for the pod to

01:05:25,839 --> 01:05:29,680
come up here

01:05:27,359 --> 01:05:31,920
and then we will simply look at the logs

01:05:29,680 --> 01:05:31,920
and

01:05:32,079 --> 01:05:37,839
see what it looks like

01:05:40,240 --> 01:05:43,359
all right we're up and running

01:05:44,880 --> 01:05:48,559
we're going to tail the log here on that

01:05:46,720 --> 01:05:51,280
particular pod

01:05:48,559 --> 01:05:52,559
and yeah there we go it's up and running

01:05:51,280 --> 01:05:54,720
it started

01:05:52,559 --> 01:05:56,319
and what you can see happen here is by

01:05:54,720 --> 01:05:59,359
default this so there's a 4k

01:05:56,319 --> 01:06:00,400
i o being read from that particular

01:05:59,359 --> 01:06:02,240
block device

01:06:00,400 --> 01:06:03,599
and you can see that the block device is

01:06:02,240 --> 01:06:05,920
a two terabyte device

01:06:03,599 --> 01:06:08,000
that's exactly what we requested and it

01:06:05,920 --> 01:06:09,440
performs that i o once per second here

01:06:08,000 --> 01:06:11,039
and you can see the response time here

01:06:09,440 --> 01:06:12,880
in the request sequence

01:06:11,039 --> 01:06:14,160
and that is essentially how you would

01:06:12,880 --> 01:06:16,400
address

01:06:14,160 --> 01:06:17,280
raw block storage from your from your

01:06:16,400 --> 01:06:20,400
pod

01:06:17,280 --> 01:06:23,359
in kubernetes all right and

01:06:20,400 --> 01:06:24,559
that concludes lab number eight uh and

01:06:23,359 --> 01:06:26,079
i'm going to switch back to my

01:06:24,559 --> 01:06:29,760
powerpoint here

01:06:26,079 --> 01:06:32,640
and um you might know you you might

01:06:29,760 --> 01:06:33,200
wonder why would you need raw block

01:06:32,640 --> 01:06:36,079
storage

01:06:33,200 --> 01:06:37,119
in kubernetes and to be quite frank with

01:06:36,079 --> 01:06:39,200
you

01:06:37,119 --> 01:06:40,720
there are not a lot of cloud-native

01:06:39,200 --> 01:06:43,599
workloads out there that

01:06:40,720 --> 01:06:45,280
leverages this paradigm but there is one

01:06:43,599 --> 01:06:47,520
in particular that leverages

01:06:45,280 --> 01:06:49,440
raw block volumes and that is the cncf

01:06:47,520 --> 01:06:51,680
project called rook

01:06:49,440 --> 01:06:52,960
which leverages seth in in the

01:06:51,680 --> 01:06:56,559
background right

01:06:52,960 --> 01:06:59,440
and i'm i'm not by any means a rook

01:06:56,559 --> 01:07:01,280
or a ceph expert for that matter uh but

01:06:59,440 --> 01:07:02,640
i can talk a little bit about what it is

01:07:01,280 --> 01:07:03,119
right so it's an open source cloud

01:07:02,640 --> 01:07:05,839
native

01:07:03,119 --> 01:07:07,760
uh storage solution for kubernetes it

01:07:05,839 --> 01:07:10,000
provides both file block

01:07:07,760 --> 01:07:11,839
and object to kubernetes and it uses

01:07:10,000 --> 01:07:15,359
seth as i mentioned

01:07:11,839 --> 01:07:17,280
and the key um differentiator here is

01:07:15,359 --> 01:07:18,160
that it allows you to manage distributed

01:07:17,280 --> 01:07:20,640
storage

01:07:18,160 --> 01:07:22,559
running on kubernetes with native

01:07:20,640 --> 01:07:24,400
controllers on kubernetes

01:07:22,559 --> 01:07:25,680
pretty effortless right so you install

01:07:24,400 --> 01:07:27,119
it as an operator

01:07:25,680 --> 01:07:28,799
and then you create something called a

01:07:27,119 --> 01:07:32,079
theft cluster crd

01:07:28,799 --> 01:07:33,680
and it may and

01:07:32,079 --> 01:07:35,599
the key aspect here is that you can

01:07:33,680 --> 01:07:37,599
leverage existing pvcs

01:07:35,599 --> 01:07:38,640
right or you can create pvcs like volume

01:07:37,599 --> 01:07:41,280
mode

01:07:38,640 --> 01:07:42,160
with volume mode block the most common

01:07:41,280 --> 01:07:45,119
pattern is that you

01:07:42,160 --> 01:07:46,559
simply leverage a raw block device that

01:07:45,119 --> 01:07:49,039
attached to the server

01:07:46,559 --> 01:07:50,880
uh so you don't have to use upper

01:07:49,039 --> 01:07:51,520
external provisioner at all right you

01:07:50,880 --> 01:07:55,200
would just

01:07:51,520 --> 01:07:58,079
use you just statically map in

01:07:55,200 --> 01:08:00,640
an nvme device or whatever you have

01:07:58,079 --> 01:08:02,000
attached to your server

01:08:00,640 --> 01:08:03,839
but if you want to deploy multiple

01:08:02,000 --> 01:08:05,520
clusters and and kind of

01:08:03,839 --> 01:08:07,280
get rid of the business of managing

01:08:05,520 --> 01:08:09,920
local hardware

01:08:07,280 --> 01:08:11,359
using a csi driver that can provide a

01:08:09,920 --> 01:08:14,240
volume mode block is quite

01:08:11,359 --> 01:08:15,599
practical actually and so the hands-on

01:08:14,240 --> 01:08:17,120
lab number nine

01:08:15,599 --> 01:08:20,400
is i'm going to show you how you would

01:08:17,120 --> 01:08:22,640
deploy rook with the

01:08:20,400 --> 01:08:24,560
with volume mode block with your csi

01:08:22,640 --> 01:08:27,839
driver so i'm just going to switch

01:08:24,560 --> 01:08:30,719
over to my terminal here one second

01:08:27,839 --> 01:08:32,400
most of the labs that i've been running

01:08:30,719 --> 01:08:35,839
throughout this tutorial

01:08:32,400 --> 01:08:37,359
i have not sped up and

01:08:35,839 --> 01:08:38,960
this one i'm going to have to speed up

01:08:37,359 --> 01:08:42,480
because it pulls down

01:08:38,960 --> 01:08:44,159
a lot of imager images

01:08:42,480 --> 01:08:45,759
for the operator itself it doesn't pull

01:08:44,159 --> 01:08:48,319
down as much content but

01:08:45,759 --> 01:08:50,159
once you create your set cluster it take

01:08:48,319 --> 01:08:53,359
it took me

01:08:50,159 --> 01:08:53,839
around 10 minutes for for the cluster to

01:08:53,359 --> 01:08:56,880
actually

01:08:53,839 --> 01:08:59,440
get created and and come up so i'm i

01:08:56,880 --> 01:09:00,640
i am going to speed up uh this

01:08:59,440 --> 01:09:02,319
particular demo

01:09:00,640 --> 01:09:04,319
uh when we get to that point right but

01:09:02,319 --> 01:09:07,520
first we i'm just going to show you

01:09:04,319 --> 01:09:08,719
how the the operator gets installed and

01:09:07,520 --> 01:09:11,759
then i'm going to

01:09:08,719 --> 01:09:12,319
show you the ceph cluster stanza the crd

01:09:11,759 --> 01:09:14,480
that

01:09:12,319 --> 01:09:17,199
instantiate the cluster so let's see if

01:09:14,480 --> 01:09:19,920
this operator comes up here

01:09:17,199 --> 01:09:22,319
soon enough so i have prepared a sev

01:09:19,920 --> 01:09:25,600
cluster yaml file here and this is

01:09:22,319 --> 01:09:26,080
a vanilla cef cluster i just uh copied

01:09:25,600 --> 01:09:29,920
this

01:09:26,080 --> 01:09:32,880
from the the rook

01:09:29,920 --> 01:09:34,080
documentation and here you specify

01:09:32,880 --> 01:09:36,640
something called a volume claim

01:09:34,080 --> 01:09:37,759
template right and you set the volume

01:09:36,640 --> 01:09:40,960
mode to block

01:09:37,759 --> 01:09:44,080
the access mode read write once uh

01:09:40,960 --> 01:09:45,679
i omit the storage class and once you

01:09:44,080 --> 01:09:48,400
kind of create this

01:09:45,679 --> 01:09:49,120
cef cluster it will dynamically

01:09:48,400 --> 01:09:52,880
provision

01:09:49,120 --> 01:09:54,960
storage resources that it needs

01:09:52,880 --> 01:09:56,320
from the default storage class so it

01:09:54,960 --> 01:09:58,640
uses actually

01:09:56,320 --> 01:10:00,159
there's three volumes being created one

01:09:58,640 --> 01:10:02,560
once per replica

01:10:00,159 --> 01:10:04,800
for the seth application or the rookie

01:10:02,560 --> 01:10:08,159
application depending on how you see it

01:10:04,800 --> 01:10:10,560
and then you will have uh for the actual

01:10:08,159 --> 01:10:12,000
data pool the ceph file system or the

01:10:10,560 --> 01:10:16,800
osds that is called

01:10:12,000 --> 01:10:19,920
in ceph terminology will provision a

01:10:16,800 --> 01:10:23,120
a block pvc and this is the point where

01:10:19,920 --> 01:10:25,760
i'm going to pause and

01:10:23,120 --> 01:10:26,480
speed up the presentation and once it

01:10:25,760 --> 01:10:27,679
comes back

01:10:26,480 --> 01:10:31,199
we're going to start chatting on what

01:10:27,679 --> 01:10:34,080
we're seeing

01:10:31,199 --> 01:10:34,880
so there it's finally up now so what you

01:10:34,080 --> 01:10:37,199
can see here

01:10:34,880 --> 01:10:38,560
what got provisioned dynamically is that

01:10:37,199 --> 01:10:42,880
you have a

01:10:38,560 --> 01:10:46,400
file system volumes has been provisioned

01:10:42,880 --> 01:10:49,120
named rook cephmon abc

01:10:46,400 --> 01:10:50,320
and then you have the data volumes that

01:10:49,120 --> 01:10:52,800
basically references

01:10:50,320 --> 01:10:54,400
a a block device right and that is

01:10:52,800 --> 01:10:56,159
because the application components

01:10:54,400 --> 01:10:59,679
require a file system

01:10:56,159 --> 01:11:01,040
and the actual distributed file system

01:10:59,679 --> 01:11:04,640
the cep file systems

01:11:01,040 --> 01:11:06,719
require requires block storage so that's

01:11:04,640 --> 01:11:09,360
why it's very practical to have a driver

01:11:06,719 --> 01:11:12,000
that can do both of those things

01:11:09,360 --> 01:11:12,719
to provide persistent storage to read

01:11:12,000 --> 01:11:15,520
write one's

01:11:12,719 --> 01:11:16,400
stateful sets which is that basically

01:11:15,520 --> 01:11:18,480
presents

01:11:16,400 --> 01:11:19,600
so at this point you basically have a

01:11:18,480 --> 01:11:22,159
ceph cluster

01:11:19,600 --> 01:11:24,000
running on your kubernetes cluster so

01:11:22,159 --> 01:11:24,320
you would be able to install this f2

01:11:24,000 --> 01:11:26,960
ball

01:11:24,320 --> 01:11:28,159
toolbox and start creating new storage

01:11:26,960 --> 01:11:31,520
classes

01:11:28,159 --> 01:11:32,320
to provide data services on top of your

01:11:31,520 --> 01:11:34,239
kubernetes

01:11:32,320 --> 01:11:35,520
but it's still backed by your backend

01:11:34,239 --> 01:11:38,239
csi driver

01:11:35,520 --> 01:11:39,360
being that a storage appliance or it

01:11:38,239 --> 01:11:41,440
could be

01:11:39,360 --> 01:11:43,199
your cloud provider's storage block

01:11:41,440 --> 01:11:44,880
service so now you're

01:11:43,199 --> 01:11:46,400
you're more in the pattern of kind of

01:11:44,880 --> 01:11:47,679
controlling your own destiny because you

01:11:46,400 --> 01:11:51,600
have your data services

01:11:47,679 --> 01:11:53,760
running on the kubernetes cluster itself

01:11:51,600 --> 01:11:54,800
and that concludes the the use case

01:11:53,760 --> 01:11:57,440
overview for

01:11:54,800 --> 01:11:58,400
rook that was lab number nine i'm not

01:11:57,440 --> 01:12:01,600
going to switch

01:11:58,400 --> 01:12:02,159
back to my powerpoint all right the next

01:12:01,600 --> 01:12:04,480
section

01:12:02,159 --> 01:12:06,159
and the last section is actually about

01:12:04,480 --> 01:12:09,199
ephemeral volumes

01:12:06,159 --> 01:12:10,320
so something that is very comforting in

01:12:09,199 --> 01:12:13,120
the world of

01:12:10,320 --> 01:12:14,640
containers and kind of one of the

01:12:13,120 --> 01:12:16,880
biggest selling points in my

01:12:14,640 --> 01:12:18,960
uh opinion is that when you start a

01:12:16,880 --> 01:12:20,239
container you're more or less guaranteed

01:12:18,960 --> 01:12:22,560
that it will

01:12:20,239 --> 01:12:24,239
distort the exact same way on your

01:12:22,560 --> 01:12:26,239
laptop

01:12:24,239 --> 01:12:27,280
in the cloud in your data center it

01:12:26,239 --> 01:12:29,520
doesn't really matter

01:12:27,280 --> 01:12:30,880
and it kind of eliminates the whole

01:12:29,520 --> 01:12:34,080
problem of it runs

01:12:30,880 --> 01:12:37,440
on my computer right and

01:12:34,080 --> 01:12:40,320
but once we kind of start talking about

01:12:37,440 --> 01:12:42,800
huge amount of data right it becomes

01:12:40,320 --> 01:12:44,560
very impractical i i remember patterns

01:12:42,800 --> 01:12:47,760
back in the darker days

01:12:44,560 --> 01:12:50,640
where we had the customers shipping

01:12:47,760 --> 01:12:51,679
production databases inside the

01:12:50,640 --> 01:12:54,400
container itself

01:12:51,679 --> 01:12:55,840
right see imagine shipping i mean this

01:12:54,400 --> 01:12:58,480
was in a large database

01:12:55,840 --> 01:12:59,760
it was it was less than a terabyte i

01:12:58,480 --> 01:13:03,360
remember that much

01:12:59,760 --> 01:13:04,960
but still that is a very impractical

01:13:03,360 --> 01:13:07,920
amount

01:13:04,960 --> 01:13:09,520
of content to to store in a in a

01:13:07,920 --> 01:13:11,199
container right because you need to pull

01:13:09,520 --> 01:13:12,000
that instance down from a registry and

01:13:11,199 --> 01:13:14,080
it's just

01:13:12,000 --> 01:13:15,520
all that bandwidth it needs to consume

01:13:14,080 --> 01:13:17,360
store that locally

01:13:15,520 --> 01:13:19,520
and it becomes a bit of a burden and it

01:13:17,360 --> 01:13:21,040
just like grows exponentially it just

01:13:19,520 --> 01:13:23,520
just becomes worse and worse and worse

01:13:21,040 --> 01:13:25,520
as the database grows

01:13:23,520 --> 01:13:26,560
basically and this was for a dev test

01:13:25,520 --> 01:13:28,159
use case

01:13:26,560 --> 01:13:29,840
obviously it wasn't for production or

01:13:28,159 --> 01:13:33,520
anything like that

01:13:29,840 --> 01:13:36,159
but that became very impractical but

01:13:33,520 --> 01:13:38,480
so so that is sort of where ephemeral

01:13:36,159 --> 01:13:39,760
local volumes and generic

01:13:38,480 --> 01:13:42,000
ephemeral volumes i'm going to talk

01:13:39,760 --> 01:13:44,719
about in the next section

01:13:42,000 --> 01:13:46,000
is that that allows you to attach a

01:13:44,719 --> 01:13:48,960
piece of storage

01:13:46,000 --> 01:13:49,360
to your pod that will look exactly the

01:13:48,960 --> 01:13:52,000
same

01:13:49,360 --> 01:13:53,280
each time right and by default you will

01:13:52,000 --> 01:13:55,760
obviously just provision

01:13:53,280 --> 01:13:56,800
an empty volume right but you can use a

01:13:55,760 --> 01:13:59,600
storage vendors

01:13:56,800 --> 01:14:00,960
the capability to to perform a snapshot

01:13:59,600 --> 01:14:04,080
to clone a volume

01:14:00,960 --> 01:14:05,199
or have other pre-populated content in

01:14:04,080 --> 01:14:07,120
that volume

01:14:05,199 --> 01:14:08,480
and that means that each time the

01:14:07,120 --> 01:14:11,040
product gets restarted

01:14:08,480 --> 01:14:12,640
that data gets reattached the way it

01:14:11,040 --> 01:14:14,719
looked right

01:14:12,640 --> 01:14:15,920
the obvious use case here if you just

01:14:14,719 --> 01:14:20,000
use this as

01:14:15,920 --> 01:14:22,320
as a as a means to store data like

01:14:20,000 --> 01:14:24,159
an empty file system is that this is the

01:14:22,320 --> 01:14:27,840
ideal use case to use

01:14:24,159 --> 01:14:29,920
useful scratch disks right and the other

01:14:27,840 --> 01:14:31,600
uptake on this is that

01:14:29,920 --> 01:14:33,360
imagine that you have a high very high

01:14:31,600 --> 01:14:36,000
performance workload

01:14:33,360 --> 01:14:37,760
that consume a lot of compa capacity in

01:14:36,000 --> 01:14:40,159
the compute phase of

01:14:37,760 --> 01:14:41,520
of that particular workload is that it

01:14:40,159 --> 01:14:44,560
needs to store a lot of

01:14:41,520 --> 01:14:47,679
data locally and

01:14:44,560 --> 01:14:50,480
by default if you would store the data

01:14:47,679 --> 01:14:51,280
inside the overlay file system of the

01:14:50,480 --> 01:14:53,760
container

01:14:51,280 --> 01:14:55,040
is that it will battle for iops and

01:14:53,760 --> 01:14:57,360
capacity

01:14:55,040 --> 01:14:58,560
of all your other applications on that

01:14:57,360 --> 01:15:00,159
particular

01:14:58,560 --> 01:15:01,840
mount point where you have all your

01:15:00,159 --> 01:15:05,440
containers running

01:15:01,840 --> 01:15:07,199
so provisioning an external volume uh

01:15:05,440 --> 01:15:09,600
as an ephemeral entity you will be able

01:15:07,199 --> 01:15:11,120
to temporarily use that scratch disk

01:15:09,600 --> 01:15:13,360
for that compute workload and it will

01:15:11,120 --> 01:15:14,800
consume storage resources wherever you

01:15:13,360 --> 01:15:16,320
have it configured right so it could be

01:15:14,800 --> 01:15:19,199
your cloud providers

01:15:16,320 --> 01:15:21,120
the high performance tier for using

01:15:19,199 --> 01:15:22,880
flash disks so you might be using a

01:15:21,120 --> 01:15:24,159
cheaper tier for your temporary storage

01:15:22,880 --> 01:15:26,000
right i mean the thing is you can kind

01:15:24,159 --> 01:15:28,159
of slice it and dice it however you want

01:15:26,000 --> 01:15:29,520
right but at the end of the day is that

01:15:28,159 --> 01:15:32,320
you don't want to have

01:15:29,520 --> 01:15:33,520
your workloads that you know are

01:15:32,320 --> 01:15:36,000
ephemeral

01:15:33,520 --> 01:15:38,080
and you know they're io intensive you

01:15:36,000 --> 01:15:39,600
don't want to have them in the gen pop

01:15:38,080 --> 01:15:41,920
of your applications right you want to

01:15:39,600 --> 01:15:44,800
segregate them some vendors provide

01:15:41,920 --> 01:15:46,640
means to set very fine-grained uh

01:15:44,800 --> 01:15:47,120
quality of service controls as well

01:15:46,640 --> 01:15:49,840
right

01:15:47,120 --> 01:15:51,199
to throttle those workloads and also

01:15:49,840 --> 01:15:53,920
ensure the capacity

01:15:51,199 --> 01:15:56,000
limits are met right so looking at this

01:15:53,920 --> 01:15:58,080
very simple stanza here is that

01:15:56,000 --> 01:15:59,600
you you're well familiar with this at

01:15:58,080 --> 01:16:02,960
this point right where you have

01:15:59,600 --> 01:16:03,440
a volume amount the amount the calls out

01:16:02,960 --> 01:16:05,760
a

01:16:03,440 --> 01:16:08,159
a named volume and here is kind of where

01:16:05,760 --> 01:16:10,239
the the secret sauce comes in right you

01:16:08,159 --> 01:16:12,400
you have the csi stanza here

01:16:10,239 --> 01:16:13,600
you call out your driver and these are

01:16:12,400 --> 01:16:15,280
the volume attributes

01:16:13,600 --> 01:16:16,960
uh that you you will supply to your

01:16:15,280 --> 01:16:18,800
driver right you will say you will tell

01:16:16,960 --> 01:16:19,920
the driver i want an ephemeral volume if

01:16:18,800 --> 01:16:24,080
the driver supports

01:16:19,920 --> 01:16:26,960
ephemerality and then you specify the

01:16:24,080 --> 01:16:28,640
the secret uh where you can find it and

01:16:26,960 --> 01:16:31,920
which name space it is in

01:16:28,640 --> 01:16:34,320
and you specify a size right and

01:16:31,920 --> 01:16:35,679
some vendors support multiple different

01:16:34,320 --> 01:16:36,560
options here how you want to provision

01:16:35,679 --> 01:16:39,199
storage

01:16:36,560 --> 01:16:41,360
and so forth there's also a slightly

01:16:39,199 --> 01:16:42,960
different way to

01:16:41,360 --> 01:16:44,800
reference the secret right so if you

01:16:42,960 --> 01:16:47,280
have your secret to your

01:16:44,800 --> 01:16:48,960
back in storage system sitting in the

01:16:47,280 --> 01:16:49,600
namespace with the application that

01:16:48,960 --> 01:16:50,960
you're actually

01:16:49,600 --> 01:16:52,960
where you're deploying the pod or the

01:16:50,960 --> 01:16:56,080
staples at the home chart what not

01:16:52,960 --> 01:16:58,880
uh you can just reference it by name

01:16:56,080 --> 01:17:00,560
right so you give the uh the alternative

01:16:58,880 --> 01:17:01,600
syntax here by node publish secret

01:17:00,560 --> 01:17:05,120
reference

01:17:01,600 --> 01:17:05,120
and name it csi

01:17:06,159 --> 01:17:10,800
and i already skipped over to my

01:17:07,920 --> 01:17:13,760
hands-on lab number 10 slide here

01:17:10,800 --> 01:17:15,199
about how to use a thermal local volume

01:17:13,760 --> 01:17:16,000
so i'm just going to switch over to my

01:17:15,199 --> 01:17:19,600
terminal here

01:17:16,000 --> 01:17:20,400
real quick i have a very simple example

01:17:19,600 --> 01:17:24,239
here

01:17:20,400 --> 01:17:28,480
in my inline.yaml i will have a

01:17:24,239 --> 01:17:30,560
mount path of an nginx web server

01:17:28,480 --> 01:17:31,920
which is just a very simple stupid

01:17:30,560 --> 01:17:33,679
container and very stupid

01:17:31,920 --> 01:17:35,360
stupid example but it illustrates the

01:17:33,679 --> 01:17:37,760
point i want to make right

01:17:35,360 --> 01:17:39,760
so we have this this inline stanza where

01:17:37,760 --> 01:17:42,960
i'm going to provision a volume

01:17:39,760 --> 01:17:44,400
i'm going to wait for the pod to come up

01:17:42,960 --> 01:17:46,800
i'm then going to exec into the

01:17:44,400 --> 01:17:49,199
container and

01:17:46,800 --> 01:17:50,400
simply put a file there to to prove my

01:17:49,199 --> 01:17:52,480
point

01:17:50,400 --> 01:17:54,480
so i'm going to go to slash user share

01:17:52,480 --> 01:17:58,000
nginx html

01:17:54,480 --> 01:18:02,320
echo kubecon rocks

01:17:58,000 --> 01:18:04,880
into index.html there we go

01:18:02,320 --> 01:18:06,719
content is there and then i'm going to

01:18:04,880 --> 01:18:07,600
do the the brute thing of simply

01:18:06,719 --> 01:18:10,080
replacing

01:18:07,600 --> 01:18:11,520
the pod right and this will essentially

01:18:10,080 --> 01:18:14,640
delete the pod

01:18:11,520 --> 01:18:15,600
and recreate the pod if we were

01:18:14,640 --> 01:18:18,960
referencing

01:18:15,600 --> 01:18:20,480
a persistent volume claim externally

01:18:18,960 --> 01:18:22,000
the content would persist on that

01:18:20,480 --> 01:18:24,400
particular amount points

01:18:22,000 --> 01:18:26,159
but the point i want to make here is

01:18:24,400 --> 01:18:28,239
that we're going to have a new volume

01:18:26,159 --> 01:18:30,000
provision there so i'm going to exec

01:18:28,239 --> 01:18:33,120
into the pod

01:18:30,000 --> 01:18:35,760
go to my mount points there we go

01:18:33,120 --> 01:18:36,480
it's empty there's no index.html file

01:18:35,760 --> 01:18:39,360
there

01:18:36,480 --> 01:18:40,480
and that concludes the first part of the

01:18:39,360 --> 01:18:42,000
ephemeral volumes

01:18:40,480 --> 01:18:44,400
use case i'm just going to switch back

01:18:42,000 --> 01:18:46,080
to my powerpoints

01:18:44,400 --> 01:18:48,320
and i'm going to talk about something

01:18:46,080 --> 01:18:50,080
that got introduced in kubernetes 119

01:18:48,320 --> 01:18:51,679
and that is called gener generic

01:18:50,080 --> 01:18:54,159
ephemeral volumes

01:18:51,679 --> 01:18:54,800
and this is a little bit simpler to

01:18:54,159 --> 01:18:58,080
comprehend

01:18:54,800 --> 01:18:59,760
in in my uh opinion is because what this

01:18:58,080 --> 01:19:02,000
does essentially it

01:18:59,760 --> 01:19:03,280
it kind of copies the behavior a little

01:19:02,000 --> 01:19:06,719
bit like you do

01:19:03,280 --> 01:19:09,440
with a stateful set so you would specify

01:19:06,719 --> 01:19:10,239
essentially a ephemeral volume claim

01:19:09,440 --> 01:19:13,360
template

01:19:10,239 --> 01:19:14,719
that looks very similar to a inline

01:19:13,360 --> 01:19:17,520
persistent volume claim

01:19:14,719 --> 01:19:18,560
and it supports like labels annotations

01:19:17,520 --> 01:19:21,520
and all those things

01:19:18,560 --> 01:19:22,000
that you would expect to work in a in a

01:19:21,520 --> 01:19:25,040
persistent

01:19:22,000 --> 01:19:26,800
volume claim right and

01:19:25,040 --> 01:19:29,120
and the key here is that it will be able

01:19:26,800 --> 01:19:31,679
to leverage any storage class

01:19:29,120 --> 01:19:35,199
you don't have to have a csi driver that

01:19:31,679 --> 01:19:37,840
supports ephemerality you can just use

01:19:35,199 --> 01:19:37,840
the existing

01:19:38,560 --> 01:19:42,239
existing csi drivers to support

01:19:40,400 --> 01:19:44,000
persistence right

01:19:42,239 --> 01:19:45,280
so i'm just going to switch over to my

01:19:44,000 --> 01:19:50,000
last lab here and

01:19:45,280 --> 01:19:52,400
show you real quick how this works going

01:19:50,000 --> 01:19:54,640
to switch over to my terminal

01:19:52,400 --> 01:19:55,600
so i have a yaml file here my ephemeral

01:19:54,640 --> 01:19:58,320
yaml

01:19:55,600 --> 01:20:00,080
and here you can see that i have a um

01:19:58,320 --> 01:20:02,080
ephemeral volume claim template

01:20:00,080 --> 01:20:04,080
i input some metadata there so i will be

01:20:02,080 --> 01:20:07,280
able to find the application

01:20:04,080 --> 01:20:10,400
and you can see here the access mode

01:20:07,280 --> 01:20:13,920
how much storage i'm requesting and

01:20:10,400 --> 01:20:15,600
the the custom label

01:20:13,920 --> 01:20:17,199
i'm going to create that and then i'm

01:20:15,600 --> 01:20:19,520
going to do the exact same

01:20:17,199 --> 01:20:20,560
exercise i did in in the previous

01:20:19,520 --> 01:20:24,639
example

01:20:20,560 --> 01:20:26,080
with the inline local volume example

01:20:24,639 --> 01:20:28,239
i'm going to wait for the part to come

01:20:26,080 --> 01:20:31,920
up

01:20:28,239 --> 01:20:34,080
it's running i'm going to get the pvc

01:20:31,920 --> 01:20:35,480
by my app label you can see here that we

01:20:34,080 --> 01:20:38,480
have a determiner name

01:20:35,480 --> 01:20:41,440
mypodmymount and that maps to the

01:20:38,480 --> 01:20:41,840
the the port name and the volume mount

01:20:41,440 --> 01:20:45,520
name

01:20:41,840 --> 01:20:49,760
that you saw in the yaml stanza

01:20:45,520 --> 01:20:52,560
again i'm going to exec into my pod

01:20:49,760 --> 01:20:54,800
there we see we have a multi-path device

01:20:52,560 --> 01:20:58,960
mounted

01:20:54,800 --> 01:21:04,320
on user share nginx kubecon rocks

01:20:58,960 --> 01:21:04,320
into index.html there we go

01:21:05,360 --> 01:21:09,280
i'm going to do the same replace

01:21:06,639 --> 01:21:13,520
operation that i did on the previous

01:21:09,280 --> 01:21:15,440
example i'm going to delete the pod

01:21:13,520 --> 01:21:18,159
and it's been replaced all right let's

01:21:15,440 --> 01:21:22,800
exact back into it

01:21:18,159 --> 01:21:25,440
after it has come up i'd say

01:21:22,800 --> 01:21:26,239
it's been a long day how you hanging in

01:21:25,440 --> 01:21:28,719
there

01:21:26,239 --> 01:21:29,840
there we go up and running all right

01:21:28,719 --> 01:21:33,040
we'll see here that

01:21:29,840 --> 01:21:34,800
yep the director is empty there's no

01:21:33,040 --> 01:21:37,120
file there

01:21:34,800 --> 01:21:38,639
uh the generic ephemeral volumes

01:21:37,120 --> 01:21:42,560
functionality worked as

01:21:38,639 --> 01:21:45,600
advertised although is a alpha feature

01:21:42,560 --> 01:21:48,639
be careful and you will also see that

01:21:45,600 --> 01:21:51,360
the um the pvc has been replaced

01:21:48,639 --> 01:21:52,719
from my default storage class there as

01:21:51,360 --> 01:21:54,960
you can see that the

01:21:52,719 --> 01:21:56,880
if you compare the ids of the the volume

01:21:54,960 --> 01:21:59,120
names there

01:21:56,880 --> 01:22:00,159
they're different all right that

01:21:59,120 --> 01:22:02,480
concludes uh

01:22:00,159 --> 01:22:03,360
hands-on lab number 11. i'm going to

01:22:02,480 --> 01:22:06,159
switch by

01:22:03,360 --> 01:22:07,600
back to my powerpoints and

01:22:06,159 --> 01:22:09,840
congratulations

01:22:07,600 --> 01:22:11,040
you're done thank you so much for

01:22:09,840 --> 01:22:12,560
participating

01:22:11,040 --> 01:22:15,440
i'm just going to iterate here what

01:22:12,560 --> 01:22:16,400
we've covered we introduced you to csi

01:22:15,440 --> 01:22:17,840
drivers

01:22:16,400 --> 01:22:21,760
how dynamic provisioning works in

01:22:17,840 --> 01:22:24,560
kubernetes how csi snapshots csi restore

01:22:21,760 --> 01:22:27,280
and using pvc cloning

01:22:24,560 --> 01:22:28,159
in depth and how you access raw block

01:22:27,280 --> 01:22:31,199
volumes

01:22:28,159 --> 01:22:33,600
and raw block storage and the last few

01:22:31,199 --> 01:22:36,560
examples here how to use ephemeral

01:22:33,600 --> 01:22:38,239
volumes both local volumes using the

01:22:36,560 --> 01:22:41,280
inline stanza

01:22:38,239 --> 01:22:42,000
and using generic generic ephemeral

01:22:41,280 --> 01:22:46,080
volumes

01:22:42,000 --> 01:22:48,239
using your standard storage classes

01:22:46,080 --> 01:22:50,639
as i mentioned the source files the yaml

01:22:48,239 --> 01:22:53,199
the powerpoint the asciinima cast files

01:22:50,639 --> 01:22:56,639
are all available in this particular

01:22:53,199 --> 01:22:57,920
github repository check out the csi

01:22:56,639 --> 01:23:01,920
specification

01:22:57,920 --> 01:23:01,920
and and you can also see

01:23:02,000 --> 01:23:06,000
all the past meetings and and the

01:23:04,560 --> 01:23:08,800
members of the kubernetes

01:23:06,000 --> 01:23:09,120
special interest group for storage on

01:23:08,800 --> 01:23:12,239
the

01:23:09,120 --> 01:23:13,520
github url there and check out the csi

01:23:12,239 --> 01:23:16,560
documentation

01:23:13,520 --> 01:23:18,400
for more information about

01:23:16,560 --> 01:23:19,600
the development of csi and the different

01:23:18,400 --> 01:23:21,760
maturity

01:23:19,600 --> 01:23:23,040
levels of different drivers and and

01:23:21,760 --> 01:23:26,239
features and

01:23:23,040 --> 01:23:28,239
and god knows one so with that said um

01:23:26,239 --> 01:23:29,760
thank you so much for watching uh if

01:23:28,239 --> 01:23:32,719
you're watching this live

01:23:29,760 --> 01:23:34,480
at kubecon uh please stick around we're

01:23:32,719 --> 01:23:35,679
gonna shut down this video stream

01:23:34,480 --> 01:23:37,760
and we're going to switch over to the

01:23:35,679 --> 01:23:40,719
live q a and

01:23:37,760 --> 01:23:42,320
until if you're watching this offline

01:23:40,719 --> 01:23:44,159
later

01:23:42,320 --> 01:23:45,920
please feel free to reach out to me if

01:23:44,159 --> 01:23:48,000
you have any questions

01:23:45,920 --> 01:23:49,199
you can find me on twitter and all this

01:23:48,000 --> 01:23:51,840
social media

01:23:49,199 --> 01:23:54,239
networks out there the address is in the

01:23:51,840 --> 01:24:00,800
beginning of the video so

01:23:54,239 --> 01:24:00,800

YouTube URL: https://www.youtube.com/watch?v=AnfAd6goq-o


