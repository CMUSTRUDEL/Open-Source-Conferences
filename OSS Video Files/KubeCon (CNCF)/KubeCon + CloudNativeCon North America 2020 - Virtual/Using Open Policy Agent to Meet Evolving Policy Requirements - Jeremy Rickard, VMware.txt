Title: Using Open Policy Agent to Meet Evolving Policy Requirements - Jeremy Rickard, VMware
Publication date: 2020-11-23
Playlist: KubeCon + CloudNativeCon North America 2020 - Virtual
Description: 
	Don’t miss out! Join us at our upcoming event: KubeCon + CloudNativeCon Europe 2021 Virtual from May 4–7, 2021. Learn more at https://kubecon.io. The conference features presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects. 

Using Open Policy Agent to Meet Evolving Policy Requirements - Jeremy Rickard, VMware 

Our team runs a Kubernetes platform for 30+ teams in a variety of commercial and government environments. Each of these environments has different security and compliance requirements, such as PCI and FedRAMP. We must deal with evolving requirements as our tenants pursue new accreditations. While we could implement a variety of mutating and validating webhook implementations to meet our needs, we instead turned to Open Policy Agent (OPA). OPA has allowed us to quickly develop and deploy new policies as these requirements shift and evolve. In this talk, we will look at several concrete examples of how we used OPA to implement our changing kubernetes policy requirements and help our tenants achieve a variety of compliance certifications, while at the same time striving to make these security policies as unobtrusive to their existing CI/CD pipelines and workflows. 

https://sched.co/ekEP
Captions: 
	00:00:00,399 --> 00:00:03,840
hello welcome to using open policy agent

00:00:03,280 --> 00:00:06,480
to meet

00:00:03,840 --> 00:00:08,720
evolving policy requirements in this

00:00:06,480 --> 00:00:11,440
talk i'm going to cover how my team has

00:00:08,720 --> 00:00:13,599
been using open policy agent or opa

00:00:11,440 --> 00:00:15,360
for around the last year in order to

00:00:13,599 --> 00:00:17,600
meet evolving requirements that we've

00:00:15,360 --> 00:00:18,720
faced as we've moved into new regulated

00:00:17,600 --> 00:00:20,880
environments

00:00:18,720 --> 00:00:22,800
my name is jeremy rickard i'm a software

00:00:20,880 --> 00:00:24,960
engineer at vmware

00:00:22,800 --> 00:00:27,039
and my team has really been focused on

00:00:24,960 --> 00:00:28,560
doing things in the kubernetes space for

00:00:27,039 --> 00:00:30,960
the last few years

00:00:28,560 --> 00:00:32,079
i'm also the kubernetes 120 release lead

00:00:30,960 --> 00:00:33,280
and i've worked on a number of open

00:00:32,079 --> 00:00:35,360
source projects

00:00:33,280 --> 00:00:36,640
like virtual cubelet and service catalog

00:00:35,360 --> 00:00:38,160
for kubernetes

00:00:36,640 --> 00:00:40,239
if you'd like to reach out to me after

00:00:38,160 --> 00:00:41,120
this talk feel free to ping me on

00:00:40,239 --> 00:00:42,480
twitter

00:00:41,120 --> 00:00:45,360
or the kubernetes slack where you can

00:00:42,480 --> 00:00:48,800
find me as j-e-r-i-c-k-a-r

00:00:45,360 --> 00:00:51,920
i'm also happy to respond to emails

00:00:48,800 --> 00:00:53,920
so what does my team at vmware do we're

00:00:51,920 --> 00:00:55,440
called the vmware developer platform and

00:00:53,920 --> 00:00:57,440
we've got this long collection of words

00:00:55,440 --> 00:00:59,359
that describe what our team does

00:00:57,440 --> 00:01:01,440
but if i boil it down to a really simple

00:00:59,359 --> 00:01:02,559
explanation our team provides managed

00:01:01,440 --> 00:01:05,280
kubernetes

00:01:02,559 --> 00:01:06,080
to vmware sas services along with

00:01:05,280 --> 00:01:10,320
supporting

00:01:06,080 --> 00:01:12,320
infrastructure like maybe vault or

00:01:10,320 --> 00:01:13,760
creation of resources in aws that might

00:01:12,320 --> 00:01:16,080
support what

00:01:13,760 --> 00:01:18,159
those teams are doing this project has

00:01:16,080 --> 00:01:20,880
been around since mid-2018

00:01:18,159 --> 00:01:22,240
kind of generally available for vmware

00:01:20,880 --> 00:01:24,240
sas teams

00:01:22,240 --> 00:01:25,280
and the the genesis of this thing was

00:01:24,240 --> 00:01:28,320
really

00:01:25,280 --> 00:01:31,280
focused on deploying clusters for

00:01:28,320 --> 00:01:32,479
multi-tenant use so we would deploy kind

00:01:31,280 --> 00:01:34,079
of shared clusters

00:01:32,479 --> 00:01:36,079
and these clusters would have multiple

00:01:34,079 --> 00:01:36,720
tenants on them these were deployed into

00:01:36,079 --> 00:01:39,119
amazon

00:01:36,720 --> 00:01:40,880
so running in public clouds and

00:01:39,119 --> 00:01:42,079
available to the sas teams to deploy

00:01:40,880 --> 00:01:43,439
their workloads

00:01:42,079 --> 00:01:45,520
since we are running multi-tenant

00:01:43,439 --> 00:01:45,840
clusters we kind of use name spaces as

00:01:45,520 --> 00:01:47,439
the

00:01:45,840 --> 00:01:49,280
the level of isolation where we're

00:01:47,439 --> 00:01:51,040
enforcing that multi-tenancy

00:01:49,280 --> 00:01:53,600
and we use our back pretty extensively

00:01:51,040 --> 00:01:55,920
in order to to make that happen

00:01:53,600 --> 00:01:57,439
so to really facilitate that we also

00:01:55,920 --> 00:01:58,479
have a data plane that we run in

00:01:57,439 --> 00:01:59,200
something we call our management

00:01:58,479 --> 00:02:01,920
clusters

00:01:59,200 --> 00:02:04,079
so when a user is going to use vdp they

00:02:01,920 --> 00:02:05,759
use a cli that we've written

00:02:04,079 --> 00:02:07,360
to maybe create namespaces or label

00:02:05,759 --> 00:02:08,640
namespaces do things like that

00:02:07,360 --> 00:02:10,000
then once they have the namespace

00:02:08,640 --> 00:02:11,120
created they're able to do pretty much

00:02:10,000 --> 00:02:12,640
whatever they want inside of that

00:02:11,120 --> 00:02:14,239
namespace and it belongs to them they

00:02:12,640 --> 00:02:17,840
can define network policies

00:02:14,239 --> 00:02:20,879
uh things like that but we very quickly

00:02:17,840 --> 00:02:23,040
came to see that that's not really

00:02:20,879 --> 00:02:24,720
sufficient for all the use cases

00:02:23,040 --> 00:02:27,040
there were teams that needed to do more

00:02:24,720 --> 00:02:28,800
than just exist within one maybe two

00:02:27,040 --> 00:02:30,560
namespaces they needed the ability to

00:02:28,800 --> 00:02:32,400
create more namespaces do other things

00:02:30,560 --> 00:02:34,080
on the cluster

00:02:32,400 --> 00:02:36,160
and doing that doesn't really fit into

00:02:34,080 --> 00:02:38,640
that multi-tenant cluster kind of

00:02:36,160 --> 00:02:40,560
kind of model so we also have evolved to

00:02:38,640 --> 00:02:44,959
support non-shared clusters

00:02:40,560 --> 00:02:47,599
we call these tenant cluster pretendants

00:02:44,959 --> 00:02:49,280
and in those cases they get much more

00:02:47,599 --> 00:02:50,720
access to the cluster they can do things

00:02:49,280 --> 00:02:55,040
like create namespaces they

00:02:50,720 --> 00:02:56,720
they get nearly clustered admin access

00:02:55,040 --> 00:02:58,480
instead of having to rely on our data

00:02:56,720 --> 00:03:00,560
plane to do a lot of that stuff

00:02:58,480 --> 00:03:01,680
but at the same time we have resources

00:03:00,560 --> 00:03:02,560
that we deploy that are really

00:03:01,680 --> 00:03:04,400
responsible

00:03:02,560 --> 00:03:05,680
required for the cluster to operate

00:03:04,400 --> 00:03:07,760
successfully so we

00:03:05,680 --> 00:03:09,680
come to this challenging point of

00:03:07,760 --> 00:03:10,959
tenants really having what amounts to

00:03:09,680 --> 00:03:12,800
cluster admin they can do a lot of

00:03:10,959 --> 00:03:13,680
things that might impact the operation

00:03:12,800 --> 00:03:15,599
of our system

00:03:13,680 --> 00:03:17,599
but we also have resources that we want

00:03:15,599 --> 00:03:18,159
to protect and our back wasn't really

00:03:17,599 --> 00:03:20,319
sufficient

00:03:18,159 --> 00:03:21,840
to handle all of those things maybe we

00:03:20,319 --> 00:03:23,120
need to validate that somebody can do

00:03:21,840 --> 00:03:24,879
something based off of their org

00:03:23,120 --> 00:03:26,319
membership in an external system so

00:03:24,879 --> 00:03:27,120
thinking about how we might solve that

00:03:26,319 --> 00:03:29,680
problem

00:03:27,120 --> 00:03:31,280
we realized pretty quickly that webhooks

00:03:29,680 --> 00:03:32,560
you know the mutating

00:03:31,280 --> 00:03:34,640
dynamic and mission control that's

00:03:32,560 --> 00:03:36,159
available in kubernetes would really

00:03:34,640 --> 00:03:38,000
solve this problem or give us a point

00:03:36,159 --> 00:03:40,159
where we could write some extensions

00:03:38,000 --> 00:03:41,599
to make that happen if you're not

00:03:40,159 --> 00:03:44,159
familiar when you do

00:03:41,599 --> 00:03:44,640
something like a cube ctl apply um the

00:03:44,159 --> 00:03:47,120
two

00:03:44,640 --> 00:03:48,319
the tooling the cli makes a call to the

00:03:47,120 --> 00:03:49,920
kubernetes api

00:03:48,319 --> 00:03:51,280
it does some basic authentication checks

00:03:49,920 --> 00:03:52,879
to make sure you're authorized and

00:03:51,280 --> 00:03:53,840
authenticated to do what you're trying

00:03:52,879 --> 00:03:55,280
to do

00:03:53,840 --> 00:03:57,519
and then it moves into the dynamic and

00:03:55,280 --> 00:03:59,519
mission control in that you can define

00:03:57,519 --> 00:04:01,439
mutating webhooks which might make

00:03:59,519 --> 00:04:04,159
changes to the request coming in

00:04:01,439 --> 00:04:06,799
maybe inserting a sidecar pod or

00:04:04,159 --> 00:04:08,799
changing labels doing things like that

00:04:06,799 --> 00:04:10,000
finally it moves on through the chain

00:04:08,799 --> 00:04:10,720
until it gets to the validating

00:04:10,000 --> 00:04:12,720
workbooks

00:04:10,720 --> 00:04:14,400
in there it makes decisions about

00:04:12,720 --> 00:04:15,439
whether the the request should be

00:04:14,400 --> 00:04:17,280
allowed or not

00:04:15,439 --> 00:04:18,560
you know maybe it's checking parts of

00:04:17,280 --> 00:04:20,079
the

00:04:18,560 --> 00:04:21,919
the request against other things in the

00:04:20,079 --> 00:04:23,759
system to make sure that

00:04:21,919 --> 00:04:25,840
that should be allowed or maybe it's

00:04:23,759 --> 00:04:27,919
checking something against an external

00:04:25,840 --> 00:04:29,440
system so we ended up writing a web

00:04:27,919 --> 00:04:31,120
hooked to do some of this

00:04:29,440 --> 00:04:33,280
and it was focused on protecting the

00:04:31,120 --> 00:04:34,080
resources that vdp manages in the

00:04:33,280 --> 00:04:35,759
clusters

00:04:34,080 --> 00:04:38,320
but allowing them to do most everything

00:04:35,759 --> 00:04:40,800
else so when a request comes into a vdp

00:04:38,320 --> 00:04:41,520
managed namespace where we have deployed

00:04:40,800 --> 00:04:44,000
things

00:04:41,520 --> 00:04:45,840
we can can analyze who's making the

00:04:44,000 --> 00:04:46,880
request and either allow it or not allow

00:04:45,840 --> 00:04:48,800
it

00:04:46,880 --> 00:04:50,639
this uh really became a great just

00:04:48,800 --> 00:04:51,199
general extension point for us to add

00:04:50,639 --> 00:04:52,720
new

00:04:51,199 --> 00:04:54,720
functionality that we couldn't directly

00:04:52,720 --> 00:04:55,600
express with uh with role based access

00:04:54,720 --> 00:04:58,240
control

00:04:55,600 --> 00:04:58,720
but as our scope started to grow you

00:04:58,240 --> 00:05:00,720
know

00:04:58,720 --> 00:05:03,440
we onboarded more tenants we also

00:05:00,720 --> 00:05:05,520
started to pick up some additional

00:05:03,440 --> 00:05:07,280
places where we needed to run we needed

00:05:05,520 --> 00:05:09,759
to you know follow

00:05:07,280 --> 00:05:11,520
our tenants to where they needed to be

00:05:09,759 --> 00:05:13,440
and the first place they needed to be

00:05:11,520 --> 00:05:16,639
beyond our normal commercial

00:05:13,440 --> 00:05:18,800
aws regions was govcloud in the amazon

00:05:16,639 --> 00:05:21,039
govcloud and our tenants wanted to start

00:05:18,800 --> 00:05:23,360
pursuing fedramp certifications

00:05:21,039 --> 00:05:24,479
starting with fedramp moderate moving

00:05:23,360 --> 00:05:26,320
into fat ramp high

00:05:24,479 --> 00:05:28,800
so we recently just completed an effort

00:05:26,320 --> 00:05:29,600
to help the vmware cloud and aws team

00:05:28,800 --> 00:05:31,759
secure

00:05:29,600 --> 00:05:33,360
a fedramp high certification and doing

00:05:31,759 --> 00:05:34,720
that meant that we needed to evaluate a

00:05:33,360 --> 00:05:36,960
lot of what we were doing

00:05:34,720 --> 00:05:39,120
and you know look at the requirements

00:05:36,960 --> 00:05:40,880
for that certification process

00:05:39,120 --> 00:05:42,960
find the gaps in what we had deployed

00:05:40,880 --> 00:05:43,759
already and start to evolve to fix those

00:05:42,960 --> 00:05:45,440
things

00:05:43,759 --> 00:05:47,120
shortly after we started to support a

00:05:45,440 --> 00:05:49,840
pci certification effort

00:05:47,120 --> 00:05:52,400
for vmc again each one of these new

00:05:49,840 --> 00:05:54,160
environments brought new requirements

00:05:52,400 --> 00:05:56,080
when you consider fedramp high there's

00:05:54,160 --> 00:05:56,800
over 400 different controls that you

00:05:56,080 --> 00:05:59,360
have to

00:05:56,800 --> 00:06:00,800
meet in order to get that certification

00:05:59,360 --> 00:06:02,160
pci

00:06:00,800 --> 00:06:03,919
has a completely different set of

00:06:02,160 --> 00:06:05,440
requirements a lot of them are similar

00:06:03,919 --> 00:06:06,000
but there's also differences between

00:06:05,440 --> 00:06:07,520
them

00:06:06,000 --> 00:06:08,639
you need to really review each one of

00:06:07,520 --> 00:06:10,080
these things against what you've

00:06:08,639 --> 00:06:11,280
deployed and how you're operating to

00:06:10,080 --> 00:06:14,400
make sure that you're

00:06:11,280 --> 00:06:16,400
fitting into that those requirements

00:06:14,400 --> 00:06:17,600
does kubernetes directly meet all of

00:06:16,400 --> 00:06:20,160
those things

00:06:17,600 --> 00:06:21,199
probably not and in our case we we

00:06:20,160 --> 00:06:22,960
didn't try to

00:06:21,199 --> 00:06:24,800
to justify each one of those things with

00:06:22,960 --> 00:06:26,319
kubernetes one of the

00:06:24,800 --> 00:06:28,240
nice things about getting these

00:06:26,319 --> 00:06:30,240
certifications is that

00:06:28,240 --> 00:06:31,680
they've realized that not every

00:06:30,240 --> 00:06:33,919
requirement that's written

00:06:31,680 --> 00:06:36,000
can be directly applied to every

00:06:33,919 --> 00:06:38,720
business case or every

00:06:36,000 --> 00:06:39,280
computer system they've allowed for what

00:06:38,720 --> 00:06:41,919
they call

00:06:39,280 --> 00:06:42,720
compensating controls and a compensating

00:06:41,919 --> 00:06:44,800
control

00:06:42,720 --> 00:06:45,840
can be applied to almost all pci

00:06:44,800 --> 00:06:48,720
requirements

00:06:45,840 --> 00:06:50,560
and it it really says that if this

00:06:48,720 --> 00:06:52,319
requirement can't be directly applied

00:06:50,560 --> 00:06:54,800
for technical reasons or business

00:06:52,319 --> 00:06:57,520
reasons that are documented

00:06:54,800 --> 00:06:59,680
you can go ahead and identify additional

00:06:57,520 --> 00:07:02,880
problems that help mitigate the risk

00:06:59,680 --> 00:07:04,880
that those controls are meant to address

00:07:02,880 --> 00:07:06,960
and for us that was a great way for us

00:07:04,880 --> 00:07:08,479
to take the kubernetes clusters and the

00:07:06,960 --> 00:07:11,039
other stuff that we've deployed

00:07:08,479 --> 00:07:11,680
for our tenants and figure out how we

00:07:11,039 --> 00:07:13,680
can

00:07:11,680 --> 00:07:15,360
augment those things maybe with policies

00:07:13,680 --> 00:07:16,639
or maybe some additional things we

00:07:15,360 --> 00:07:20,000
deploy that can help

00:07:16,639 --> 00:07:21,680
to really reduce those risks and as we

00:07:20,000 --> 00:07:24,080
looked at each one of these things

00:07:21,680 --> 00:07:24,960
and considering that we have lots of

00:07:24,080 --> 00:07:26,560
different clusters

00:07:24,960 --> 00:07:28,160
you know we're playing uh in the

00:07:26,560 --> 00:07:31,599
commercial regions

00:07:28,160 --> 00:07:34,639
us west 2 u.s east one um

00:07:31,599 --> 00:07:35,520
various apac or europe regions when we

00:07:34,639 --> 00:07:37,759
look at those

00:07:35,520 --> 00:07:38,639
and compare them to the govcloud

00:07:37,759 --> 00:07:39,919
deployments

00:07:38,639 --> 00:07:41,039
they're pretty different and the

00:07:39,919 --> 00:07:41,919
requirements for them are pretty

00:07:41,039 --> 00:07:44,080
different

00:07:41,919 --> 00:07:45,360
we do have a base set of security things

00:07:44,080 --> 00:07:46,800
that we have to follow for vmware

00:07:45,360 --> 00:07:48,879
security obviously

00:07:46,800 --> 00:07:51,199
um any vmware service that's going to be

00:07:48,879 --> 00:07:53,039
deployed has to go through a set of

00:07:51,199 --> 00:07:54,240
security validation and to make sure

00:07:53,039 --> 00:07:56,319
that it's going to

00:07:54,240 --> 00:07:57,919
meet our internal requirements but when

00:07:56,319 --> 00:07:59,599
we move to the other environments

00:07:57,919 --> 00:08:01,919
there's more and more restrictive

00:07:59,599 --> 00:08:03,280
uh things put in place so we obviously

00:08:01,919 --> 00:08:04,720
don't want to force

00:08:03,280 --> 00:08:07,039
all of these requirements onto the

00:08:04,720 --> 00:08:09,440
tenants that don't need them because

00:08:07,039 --> 00:08:10,879
that would make their jobs harder we

00:08:09,440 --> 00:08:12,879
want to be

00:08:10,879 --> 00:08:14,639
an enabling feature for them help them

00:08:12,879 --> 00:08:16,240
be successful

00:08:14,639 --> 00:08:18,319
that doesn't seem like it fit really

00:08:16,240 --> 00:08:20,160
well with our web hook model

00:08:18,319 --> 00:08:21,840
because we would be adding you know

00:08:20,160 --> 00:08:23,199
different features that we would have to

00:08:21,840 --> 00:08:24,879
probably feature flag in different

00:08:23,199 --> 00:08:26,479
clusters keep track of all those

00:08:24,879 --> 00:08:28,160
different things it's additional code

00:08:26,479 --> 00:08:30,000
we'd have to write and test

00:08:28,160 --> 00:08:32,080
every time we wanted to make one of

00:08:30,000 --> 00:08:33,039
these new uh features available

00:08:32,080 --> 00:08:35,599
then it would have to go through our

00:08:33,039 --> 00:08:37,120
whole rollout process and uh

00:08:35,599 --> 00:08:39,599
just be a little bit more complicated

00:08:37,120 --> 00:08:42,399
than we think would be

00:08:39,599 --> 00:08:43,120
great and we also thinking about this

00:08:42,399 --> 00:08:44,240
problem

00:08:43,120 --> 00:08:46,480
we want to make sure our users don't

00:08:44,240 --> 00:08:49,519
hate us additionally

00:08:46,480 --> 00:08:51,680
some things we we really wanted with

00:08:49,519 --> 00:08:52,959
you know this change these new things we

00:08:51,680 --> 00:08:54,000
wanted to apply

00:08:52,959 --> 00:08:55,600
was that we didn't really want to

00:08:54,000 --> 00:08:56,080
require new code for each one of these

00:08:55,600 --> 00:08:57,519
things

00:08:56,080 --> 00:08:59,680
we didn't want to have to make changes

00:08:57,519 --> 00:09:02,560
to our existing webhook

00:08:59,680 --> 00:09:03,839
code it's written in go we build it into

00:09:02,560 --> 00:09:06,839
a docker container

00:09:03,839 --> 00:09:08,080
we deploy it it rolls through our

00:09:06,839 --> 00:09:10,000
pipelines

00:09:08,080 --> 00:09:11,120
it goes through a full upgrade process

00:09:10,000 --> 00:09:13,440
if we wanted to

00:09:11,120 --> 00:09:15,200
make individual changes to the to that

00:09:13,440 --> 00:09:17,120
thing every time we had to identify one

00:09:15,200 --> 00:09:19,200
of these new policies that we needed to

00:09:17,120 --> 00:09:20,320
enforce that would get a little bit

00:09:19,200 --> 00:09:21,760
complicated

00:09:20,320 --> 00:09:23,600
so we wanted to require something that

00:09:21,760 --> 00:09:25,120
didn't really require new code

00:09:23,600 --> 00:09:27,279
we also wanted to make it easy for the

00:09:25,120 --> 00:09:29,440
team to learn so we wanted to

00:09:27,279 --> 00:09:30,959
to not require them to learn a brand new

00:09:29,440 --> 00:09:31,839
you know programming language from the

00:09:30,959 --> 00:09:33,279
ground up

00:09:31,839 --> 00:09:35,440
um obviously there's probably going to

00:09:33,279 --> 00:09:38,640
be some domain specific language

00:09:35,440 --> 00:09:40,560
involved something that looks like

00:09:38,640 --> 00:09:42,080
code but we didn't want to force you

00:09:40,560 --> 00:09:44,080
know everybody on the team is not a go

00:09:42,080 --> 00:09:46,880
developer to learn go in order to build

00:09:44,080 --> 00:09:48,399
new policies like this and finally while

00:09:46,880 --> 00:09:50,399
we don't want to go through the process

00:09:48,399 --> 00:09:51,680
of doing a full upgrade every time

00:09:50,399 --> 00:09:53,040
and rolling these things out and going

00:09:51,680 --> 00:09:54,320
through the whole process we do want to

00:09:53,040 --> 00:09:56,160
make these things testable

00:09:54,320 --> 00:09:57,680
so we can make sure that when we're

00:09:56,160 --> 00:09:59,839
defining these new policies

00:09:57,680 --> 00:10:01,440
however they're going to be applied that

00:09:59,839 --> 00:10:02,959
we can test them before we roll them out

00:10:01,440 --> 00:10:04,800
so we're not breaking things

00:10:02,959 --> 00:10:06,000
down the road so we looked at all of

00:10:04,800 --> 00:10:07,279
these requirements

00:10:06,000 --> 00:10:09,440
you know the fact that we want to have

00:10:07,279 --> 00:10:11,920
this kind of applied

00:10:09,440 --> 00:10:13,040
on a cluster by cluster basis we wanted

00:10:11,920 --> 00:10:16,800
to make sure that we could

00:10:13,040 --> 00:10:20,000
satisfy these wants we did a search

00:10:16,800 --> 00:10:21,519
across the cncf landscape and

00:10:20,000 --> 00:10:23,360
we really identified something that we

00:10:21,519 --> 00:10:24,000
think would help us we thought would

00:10:23,360 --> 00:10:25,760
help us

00:10:24,000 --> 00:10:27,680
quite a bit but it turns out that was

00:10:25,760 --> 00:10:29,680
opa open policy agent

00:10:27,680 --> 00:10:30,880
open policy agent is pretty extensible

00:10:29,680 --> 00:10:33,200
uh it provides

00:10:30,880 --> 00:10:34,399
its own language for defining what

00:10:33,200 --> 00:10:36,000
policies look like and we'll look at

00:10:34,399 --> 00:10:37,519
that in just a second

00:10:36,000 --> 00:10:39,600
and it turns out it integrates pretty

00:10:37,519 --> 00:10:40,800
well with kubernetes there's a project

00:10:39,600 --> 00:10:43,440
called gatekeeper

00:10:40,800 --> 00:10:45,120
that highly recommend you take a look at

00:10:43,440 --> 00:10:46,720
we ended up not using gatekeeper for a

00:10:45,120 --> 00:10:47,680
few reasons that i'll get into as we go

00:10:46,720 --> 00:10:49,040
through the talk

00:10:47,680 --> 00:10:50,800
mostly because when we started this

00:10:49,040 --> 00:10:51,440
journey it was pretty early days for

00:10:50,800 --> 00:10:54,000
gatekeeper

00:10:51,440 --> 00:10:54,880
and we ended up going with the cube

00:10:54,000 --> 00:10:57,600
management

00:10:54,880 --> 00:10:58,240
approach which runs queue management and

00:10:57,600 --> 00:11:00,720
opa

00:10:58,240 --> 00:11:01,920
together like in a sidecar manner it

00:11:00,720 --> 00:11:02,959
ends up looking something a little bit

00:11:01,920 --> 00:11:06,640
like this

00:11:02,959 --> 00:11:11,760
uh just like we wrote our own

00:11:06,640 --> 00:11:13,920
web hook validating admission controller

00:11:11,760 --> 00:11:15,360
this plugs in pretty much the same way

00:11:13,920 --> 00:11:17,360
so when you deploy

00:11:15,360 --> 00:11:18,560
opa and cube management together you can

00:11:17,360 --> 00:11:20,720
register them as

00:11:18,560 --> 00:11:22,720
validating and mutating web hooks they

00:11:20,720 --> 00:11:23,200
plug into the api server just like any

00:11:22,720 --> 00:11:26,240
other

00:11:23,200 --> 00:11:28,240
web hook would so when a user is making

00:11:26,240 --> 00:11:30,560
requests with cube ctl

00:11:28,240 --> 00:11:32,880
cicd pipelines maybe are using the api

00:11:30,560 --> 00:11:35,200
directly maybe using cube ctl themselves

00:11:32,880 --> 00:11:37,440
or when controllers inside of the

00:11:35,200 --> 00:11:38,560
cluster are making changes to objects

00:11:37,440 --> 00:11:40,560
and resources

00:11:38,560 --> 00:11:42,560
via the api server everything goes

00:11:40,560 --> 00:11:46,160
through that normal admission process

00:11:42,560 --> 00:11:47,440
an admission request hits opa opa looks

00:11:46,160 --> 00:11:49,519
at that request

00:11:47,440 --> 00:11:50,480
determines if any of the policies you've

00:11:49,519 --> 00:11:52,480
applied

00:11:50,480 --> 00:11:54,480
should should result in a deny or a

00:11:52,480 --> 00:11:56,079
block and then it sends that response

00:11:54,480 --> 00:11:56,880
back and the api server handles that

00:11:56,079 --> 00:11:58,800
appropriately

00:11:56,880 --> 00:12:00,959
so let's look at a really simple example

00:11:58,800 --> 00:12:04,079
of what a policy might look like

00:12:00,959 --> 00:12:04,720
here we want to deny any request that

00:12:04,079 --> 00:12:07,680
comes in

00:12:04,720 --> 00:12:08,480
that's labeled with a certain value so

00:12:07,680 --> 00:12:11,200
you can see that

00:12:08,480 --> 00:12:12,160
this is really a declarative language

00:12:11,200 --> 00:12:14,560
we're saying

00:12:12,160 --> 00:12:16,160
a series of facts or in this case really

00:12:14,560 --> 00:12:18,959
just one fact

00:12:16,160 --> 00:12:20,480
and then if that fact is true then we're

00:12:18,959 --> 00:12:21,440
setting a variable value of this getting

00:12:20,480 --> 00:12:23,920
returned

00:12:21,440 --> 00:12:25,760
so we start this off with a deny block

00:12:23,920 --> 00:12:27,920
so the keyword deny

00:12:25,760 --> 00:12:30,079
and then that is a message that's going

00:12:27,920 --> 00:12:31,519
to be returned

00:12:30,079 --> 00:12:32,959
and then the first line in this is

00:12:31,519 --> 00:12:34,880
really the statement that we're checking

00:12:32,959 --> 00:12:38,480
the policy we're enforcing

00:12:34,880 --> 00:12:41,680
so in this case if the metadata

00:12:38,480 --> 00:12:42,880
has a label called pants with the value

00:12:41,680 --> 00:12:44,160
of sweatpants

00:12:42,880 --> 00:12:46,320
then the message we're going to send

00:12:44,160 --> 00:12:48,600
back is you can't sit with us

00:12:46,320 --> 00:12:50,000
if you notice in that line

00:12:48,600 --> 00:12:51,920
input.request.object

00:12:50,000 --> 00:12:53,120
that's really coming from the kubernetes

00:12:51,920 --> 00:12:54,639
admission request if you look at the

00:12:53,120 --> 00:12:55,760
json that makes up a kubernetes

00:12:54,639 --> 00:12:57,440
admission request

00:12:55,760 --> 00:12:59,040
it's got those pieces of it so it's

00:12:57,440 --> 00:12:59,760
really great in this policy you're able

00:12:59,040 --> 00:13:01,680
to say

00:12:59,760 --> 00:13:02,880
i want to look at the metadata of this

00:13:01,680 --> 00:13:04,079
object that's coming in or maybe i want

00:13:02,880 --> 00:13:06,399
to look at the spec

00:13:04,079 --> 00:13:07,600
of this object that's coming in maybe i

00:13:06,399 --> 00:13:09,920
want to look at the

00:13:07,600 --> 00:13:10,959
the verb is this a create or an update

00:13:09,920 --> 00:13:12,160
maybe i want to apply policies

00:13:10,959 --> 00:13:14,079
differently that way

00:13:12,160 --> 00:13:16,160
it's really flexible and gives you a lot

00:13:14,079 --> 00:13:17,519
of power without having to go write you

00:13:16,160 --> 00:13:18,880
know new code

00:13:17,519 --> 00:13:20,560
it's still code obviously you're still

00:13:18,880 --> 00:13:21,600
writing some declarative statements

00:13:20,560 --> 00:13:23,680
and you still have to end up putting

00:13:21,600 --> 00:13:27,120
those in the cluster somehow but it's

00:13:23,680 --> 00:13:27,440
it's a much simpler path forward to test

00:13:27,120 --> 00:13:29,920
this

00:13:27,440 --> 00:13:31,279
opa provides a lot of tooling and you

00:13:29,920 --> 00:13:33,760
can actually

00:13:31,279 --> 00:13:35,040
take this stuff and put it into a opa

00:13:33,760 --> 00:13:36,720
playground i have a link to that at the

00:13:35,040 --> 00:13:38,079
end of the presentation

00:13:36,720 --> 00:13:39,760
just to test these things without having

00:13:38,079 --> 00:13:40,320
to run anything locally on your machine

00:13:39,760 --> 00:13:42,560
you can

00:13:40,320 --> 00:13:44,320
you can build out a sample test document

00:13:42,560 --> 00:13:45,600
and build out your sample policy and

00:13:44,320 --> 00:13:46,959
just and run

00:13:45,600 --> 00:13:49,040
the validation in this playground and

00:13:46,959 --> 00:13:50,000
it's pretty cool so with all of that in

00:13:49,040 --> 00:13:52,000
mind

00:13:50,000 --> 00:13:53,279
let's talk about a few use cases that we

00:13:52,000 --> 00:13:56,000
have solved

00:13:53,279 --> 00:13:57,279
with open policy agent in rego and for

00:13:56,000 --> 00:13:58,720
each one of these i'm going to go

00:13:57,279 --> 00:14:01,120
through three examples

00:13:58,720 --> 00:14:02,000
i'm going to loosely tie this back to

00:14:01,120 --> 00:14:04,800
some control or some

00:14:02,000 --> 00:14:05,199
rule that we found in fedramp or pci

00:14:04,800 --> 00:14:07,360
that

00:14:05,199 --> 00:14:08,320
we needed to apply to our system and the

00:14:07,360 --> 00:14:10,160
first of those

00:14:08,320 --> 00:14:12,160
is the use of external information

00:14:10,160 --> 00:14:13,680
systems inside of this requirement

00:14:12,160 --> 00:14:14,959
there's a whole bunch of different rules

00:14:13,680 --> 00:14:16,399
and a lot of different individual

00:14:14,959 --> 00:14:18,399
control points but the one i'm going to

00:14:16,399 --> 00:14:20,000
focus in on is information systems

00:14:18,399 --> 00:14:21,519
that are outside of the authorization

00:14:20,000 --> 00:14:23,440
boundary really qualify as those

00:14:21,519 --> 00:14:25,519
external information systems

00:14:23,440 --> 00:14:27,199
so we deploy our in govcloud we deploy

00:14:25,519 --> 00:14:29,440
kubernetes into

00:14:27,199 --> 00:14:30,959
those fedramp environments and we play a

00:14:29,440 --> 00:14:34,320
lot of other things in there

00:14:30,959 --> 00:14:36,240
we try to minimize our reliance on

00:14:34,320 --> 00:14:38,079
external resources things that are

00:14:36,240 --> 00:14:39,519
outside of that authentication boundary

00:14:38,079 --> 00:14:41,519
and one of those things is a docker

00:14:39,519 --> 00:14:42,800
registry so in production

00:14:41,519 --> 00:14:44,720
in our commercial environments we're

00:14:42,800 --> 00:14:46,480
using a hosted service from jfrog

00:14:44,720 --> 00:14:49,120
that's not available to us to use

00:14:46,480 --> 00:14:51,760
directly as part of our fedramp offering

00:14:49,120 --> 00:14:52,399
so we needed to run our own registry in

00:14:51,760 --> 00:14:53,920
boundary

00:14:52,399 --> 00:14:55,760
so inside of that govcloud environment

00:14:53,920 --> 00:14:56,800
we have our own docker registry that

00:14:55,760 --> 00:14:59,040
we're running

00:14:56,800 --> 00:15:00,639
and we push all of our images to that so

00:14:59,040 --> 00:15:02,320
then when we want to deploy

00:15:00,639 --> 00:15:04,000
stuff into the cluster we need to

00:15:02,320 --> 00:15:05,199
reference those images

00:15:04,000 --> 00:15:07,040
we also want to make sure that the

00:15:05,199 --> 00:15:08,320
cluster isn't running things that it's

00:15:07,040 --> 00:15:10,000
directly pulling from the internet there

00:15:08,320 --> 00:15:11,920
is some connectivity

00:15:10,000 --> 00:15:13,199
or there was originally we've locked it

00:15:11,920 --> 00:15:15,360
down since then but

00:15:13,199 --> 00:15:17,279
originally you were able to pull things

00:15:15,360 --> 00:15:18,240
from docker hub or pull things from our

00:15:17,279 --> 00:15:20,320
jfrog

00:15:18,240 --> 00:15:21,680
hosted solution so the first thing we

00:15:20,320 --> 00:15:25,040
looked at with opa

00:15:21,680 --> 00:15:27,360
was how do we restrict the use

00:15:25,040 --> 00:15:29,120
of those other registries we really

00:15:27,360 --> 00:15:30,399
block it down to just the one

00:15:29,120 --> 00:15:32,720
so we want to make sure that requests

00:15:30,399 --> 00:15:35,120
that are coming in only come from

00:15:32,720 --> 00:15:35,839
that registry that we want them to come

00:15:35,120 --> 00:15:37,839
from so

00:15:35,839 --> 00:15:39,279
one of the first policies we built was a

00:15:37,839 --> 00:15:41,920
pretty simple one that would look

00:15:39,279 --> 00:15:42,800
at the the image that's being used by

00:15:41,920 --> 00:15:44,320
containers

00:15:42,800 --> 00:15:46,000
so this policy really is cool and it

00:15:44,320 --> 00:15:49,519
lets us restrict

00:15:46,000 --> 00:15:50,720
the any request that's coming in to only

00:15:49,519 --> 00:15:51,839
those that come from certain

00:15:50,720 --> 00:15:54,160
repositories

00:15:51,839 --> 00:15:55,519
so in this case we start off again with

00:15:54,160 --> 00:15:58,480
that deny block

00:15:55,519 --> 00:15:59,680
and the first thing we look at is does

00:15:58,480 --> 00:16:02,320
this

00:15:59,680 --> 00:16:02,720
kind uh the the the kind of this request

00:16:02,320 --> 00:16:05,759
so

00:16:02,720 --> 00:16:08,000
just like um you know you deal with uh

00:16:05,759 --> 00:16:10,160
kinds of kubernetes we're checking that

00:16:08,000 --> 00:16:12,000
here so an admission request will come

00:16:10,160 --> 00:16:14,079
with whatever type of object you're

00:16:12,000 --> 00:16:15,600
dealing with so we really only want to

00:16:14,079 --> 00:16:17,279
apply this to pods

00:16:15,600 --> 00:16:18,240
and you know we could do this at

00:16:17,279 --> 00:16:18,959
different levels we could look at the

00:16:18,240 --> 00:16:20,720
deployments

00:16:18,959 --> 00:16:22,880
replica sets this was the simplest for

00:16:20,720 --> 00:16:26,800
us to just look at when a pod is created

00:16:22,880 --> 00:16:28,320
is the container using something

00:16:26,800 --> 00:16:30,800
using the registry that we expect it to

00:16:28,320 --> 00:16:33,759
use it's a pretty simplistic check

00:16:30,800 --> 00:16:34,560
so we iterate through all of the images

00:16:33,759 --> 00:16:37,279
so

00:16:34,560 --> 00:16:38,560
obviously you can have multiple images

00:16:37,279 --> 00:16:40,639
in uh

00:16:38,560 --> 00:16:41,759
in a pod spec and we want to make sure

00:16:40,639 --> 00:16:44,800
that each one of those things

00:16:41,759 --> 00:16:45,759
is is uh is valid so we start off with

00:16:44,800 --> 00:16:48,800
the second line

00:16:45,759 --> 00:16:50,959
or of the block some i so like just for

00:16:48,800 --> 00:16:52,839
every image that exists in this array

00:16:50,959 --> 00:16:54,079
of input that requests that

00:16:52,839 --> 00:16:55,680
object.spec.containers

00:16:54,079 --> 00:16:57,680
let's grab that thing and validate it so

00:16:55,680 --> 00:16:59,920
then for each one of those images

00:16:57,680 --> 00:17:01,199
we we basically just say does this image

00:16:59,920 --> 00:17:04,240
start with

00:17:01,199 --> 00:17:05,839
what our you know our gov repo is

00:17:04,240 --> 00:17:08,000
i replace it here with vmware is awesome

00:17:05,839 --> 00:17:09,839
just for for notional purposes but

00:17:08,000 --> 00:17:12,400
you can see the you know we're making a

00:17:09,839 --> 00:17:14,240
little bit more complex policy here by

00:17:12,400 --> 00:17:16,160
calling into that function

00:17:14,240 --> 00:17:17,679
when this evaluates true when the first

00:17:16,160 --> 00:17:20,959
line is it's a pod

00:17:17,679 --> 00:17:22,799
and when this is not a govcloud image

00:17:20,959 --> 00:17:24,240
we're going to return the message pod's

00:17:22,799 --> 00:17:26,079
container is not allowed to use the

00:17:24,240 --> 00:17:27,919
image from a non-approved repo in gov so

00:17:26,079 --> 00:17:29,919
what's that look like in practice

00:17:27,919 --> 00:17:31,280
so using this deprecated functionality

00:17:29,919 --> 00:17:32,880
of creating a pod

00:17:31,280 --> 00:17:34,400
with cube ctl run we're still running

00:17:32,880 --> 00:17:35,600
fairly old clusters so i can still do

00:17:34,400 --> 00:17:38,960
this

00:17:35,600 --> 00:17:41,679
i'm going to try to run an mq test

00:17:38,960 --> 00:17:42,559
client from my personal docker hub

00:17:41,679 --> 00:17:46,320
account

00:17:42,559 --> 00:17:48,160
so i run that with cube ctl run

00:17:46,320 --> 00:17:49,679
that cr actually behind the scenes right

00:17:48,160 --> 00:17:51,840
now in that version of kubernetes

00:17:49,679 --> 00:17:53,520
creates a deployment and that deployment

00:17:51,840 --> 00:17:53,760
that will then spin up pots i don't get

00:17:53,520 --> 00:17:55,600
an

00:17:53,760 --> 00:17:57,039
error here though because my policy was

00:17:55,600 --> 00:17:59,760
really applied to

00:17:57,039 --> 00:18:00,320
just the pod so to kind of work around

00:17:59,760 --> 00:18:02,880
that

00:18:00,320 --> 00:18:04,320
or to see how like what feedback you get

00:18:02,880 --> 00:18:06,640
let's take a look at the events

00:18:04,320 --> 00:18:08,400
we can run cube ctl get events and uh

00:18:06,640 --> 00:18:11,039
filter that down to open policy agent

00:18:08,400 --> 00:18:12,400
um in the string and you can see that we

00:18:11,039 --> 00:18:14,320
can't actually create the pod and if i

00:18:12,400 --> 00:18:15,520
did a cube ctl get pods here

00:18:14,320 --> 00:18:17,600
you would see that there were no pods

00:18:15,520 --> 00:18:19,520
created for this deployment

00:18:17,600 --> 00:18:21,200
and it's specifically showing that error

00:18:19,520 --> 00:18:24,720
message that i created before

00:18:21,200 --> 00:18:26,880
so this was great and we were able to

00:18:24,720 --> 00:18:28,000
lock all of the registries down make

00:18:26,880 --> 00:18:29,760
sure that we weren't deploying

00:18:28,000 --> 00:18:31,039
anything from you know the

00:18:29,760 --> 00:18:33,280
non-controlled things that were inside

00:18:31,039 --> 00:18:36,400
of the boundary but now we have

00:18:33,280 --> 00:18:38,799
some fairly unhappy users

00:18:36,400 --> 00:18:39,520
and our goal all along i mentioned this

00:18:38,799 --> 00:18:40,640
at the beginning

00:18:39,520 --> 00:18:41,840
was to make sure that the users didn't

00:18:40,640 --> 00:18:44,320
hate us we wanted to make sure that

00:18:41,840 --> 00:18:46,960
things were as easy as possible for them

00:18:44,320 --> 00:18:48,799
and not every one of our tenants is

00:18:46,960 --> 00:18:49,919
super versed in kubernetes they're using

00:18:48,799 --> 00:18:51,440
kubernetes

00:18:49,919 --> 00:18:54,960
they realize the benefits of deploying

00:18:51,440 --> 00:18:56,880
their stuff under the platform

00:18:54,960 --> 00:18:58,080
they're along for the ride for govcloud

00:18:56,880 --> 00:19:00,960
but

00:18:58,080 --> 00:19:02,240
us adding this constraint makes it a

00:19:00,960 --> 00:19:03,600
little bit more difficult for them they

00:19:02,240 --> 00:19:05,919
either have to go

00:19:03,600 --> 00:19:07,600
um maintain a separate set of values

00:19:05,919 --> 00:19:09,120
files if they're using helm

00:19:07,600 --> 00:19:10,640
or some other tool that does a kind of

00:19:09,120 --> 00:19:12,160
templating and overlaying

00:19:10,640 --> 00:19:13,520
maybe their helm chart doesn't even

00:19:12,160 --> 00:19:14,080
allow them to really template that

00:19:13,520 --> 00:19:15,600
because

00:19:14,080 --> 00:19:17,919
they've uh they've not done a super

00:19:15,600 --> 00:19:19,120
great job of templating that stuff out

00:19:17,919 --> 00:19:20,240
so there were changes that had to be

00:19:19,120 --> 00:19:22,880
made there

00:19:20,240 --> 00:19:24,799
so we thought what can we do to help

00:19:22,880 --> 00:19:27,120
with that situation

00:19:24,799 --> 00:19:28,480
and i mentioned this earlier but you can

00:19:27,120 --> 00:19:31,200
actually run opa

00:19:28,480 --> 00:19:32,640
as a mutating web hook in addition to a

00:19:31,200 --> 00:19:33,440
validating web hook so what's the big

00:19:32,640 --> 00:19:35,679
difference there

00:19:33,440 --> 00:19:36,480
well when it runs as a validating web

00:19:35,679 --> 00:19:38,080
hook

00:19:36,480 --> 00:19:39,840
we have those blocks and they started

00:19:38,080 --> 00:19:42,320
with deny and

00:19:39,840 --> 00:19:44,080
what happens there is when all of the

00:19:42,320 --> 00:19:46,080
rules match for a deny

00:19:44,080 --> 00:19:47,919
the validating web hook functionality

00:19:46,080 --> 00:19:49,600
will say this request is not allowed

00:19:47,919 --> 00:19:51,200
here's the error message

00:19:49,600 --> 00:19:53,039
but just like every other mutating web

00:19:51,200 --> 00:19:54,799
hook opa can also

00:19:53,039 --> 00:19:56,559
update your resource and it does that by

00:19:54,799 --> 00:19:57,760
generating json patches

00:19:56,559 --> 00:19:59,840
the syntax gets a little bit more

00:19:57,760 --> 00:20:01,280
complicated and i'm not going to show

00:19:59,840 --> 00:20:02,720
you the entire thing here

00:20:01,280 --> 00:20:05,039
but i'm going to show the pretty like

00:20:02,720 --> 00:20:08,080
the relevant parts so here we've defined

00:20:05,039 --> 00:20:09,520
two variables uh vdp repo

00:20:08,080 --> 00:20:11,280
so it's going to map you know be

00:20:09,520 --> 00:20:13,919
whatever our upstream

00:20:11,280 --> 00:20:15,039
public managed jfrog thing is and then

00:20:13,919 --> 00:20:17,840
also whatever our

00:20:15,039 --> 00:20:18,720
govcloud the host you know the host name

00:20:17,840 --> 00:20:21,440
for our

00:20:18,720 --> 00:20:22,720
our glove cloud govcloud repo is and

00:20:21,440 --> 00:20:25,039
then instead of using the

00:20:22,720 --> 00:20:26,000
deny block we're going to define a patch

00:20:25,039 --> 00:20:28,320
block

00:20:26,000 --> 00:20:29,760
which is going to return whatever json

00:20:28,320 --> 00:20:31,280
patch needs to be applied

00:20:29,760 --> 00:20:33,120
so in this case we have a couple of

00:20:31,280 --> 00:20:34,080
extra things here i probably should have

00:20:33,120 --> 00:20:36,000
removed from the example

00:20:34,080 --> 00:20:37,280
but we first want to make sure is

00:20:36,000 --> 00:20:40,240
mutation allowed

00:20:37,280 --> 00:20:41,600
so we want to to validate that the type

00:20:40,240 --> 00:20:43,600
of resource that we're going to mutate

00:20:41,600 --> 00:20:45,280
is something we want to mutate we have

00:20:43,600 --> 00:20:48,000
some rules built around

00:20:45,280 --> 00:20:48,880
you know what namespace it's in or what

00:20:48,000 --> 00:20:51,919
labels it might have

00:20:48,880 --> 00:20:54,960
on it specifically labels

00:20:51,919 --> 00:20:56,480
a brown disallowing mutation so we have

00:20:54,960 --> 00:20:57,200
a label that we've put in place for some

00:20:56,480 --> 00:20:58,400
of our components

00:20:57,200 --> 00:21:01,200
we don't want to mutate like this

00:20:58,400 --> 00:21:02,159
because uh could lead to unexpected

00:21:01,200 --> 00:21:04,240
consequences

00:21:02,159 --> 00:21:06,000
but we we essentially check to see if

00:21:04,240 --> 00:21:08,159
that exists or not and then move on

00:21:06,000 --> 00:21:10,320
and then just like the deny rule we're

00:21:08,159 --> 00:21:13,520
going to iterate over all the containers

00:21:10,320 --> 00:21:14,960
and then we're going to check to see if

00:21:13,520 --> 00:21:18,000
that container

00:21:14,960 --> 00:21:20,240
matches the upstream public repo

00:21:18,000 --> 00:21:21,360
and replace it with the downstream value

00:21:20,240 --> 00:21:23,280
if any of that

00:21:21,360 --> 00:21:24,720
generated a new value then we're

00:21:23,280 --> 00:21:25,760
actually going to make the json patch

00:21:24,720 --> 00:21:27,840
here

00:21:25,760 --> 00:21:29,200
so i've removed some of the bits about

00:21:27,840 --> 00:21:30,000
actually making the json patch and i'll

00:21:29,200 --> 00:21:32,559
link to the documentation

00:21:30,000 --> 00:21:33,520
at the end of the talk but what will

00:21:32,559 --> 00:21:36,080
happen here

00:21:33,520 --> 00:21:38,000
is that when we make a request so maybe

00:21:36,080 --> 00:21:39,280
we're going to helm deploy

00:21:38,000 --> 00:21:41,360
some deployment and it's going to

00:21:39,280 --> 00:21:45,120
reference our upstream

00:21:41,360 --> 00:21:47,679
jfrog repository this code will actually

00:21:45,120 --> 00:21:48,720
get invoked it'll look at that request

00:21:47,679 --> 00:21:52,080
that's coming in

00:21:48,720 --> 00:21:54,480
and say oh hey you're using the upstream

00:21:52,080 --> 00:21:56,400
version we can't use that in govcloud

00:21:54,480 --> 00:21:58,080
let me go ahead and mutate that for you

00:21:56,400 --> 00:21:59,520
so when this actually hits the api

00:21:58,080 --> 00:22:01,440
server or sorry ftd

00:21:59,520 --> 00:22:03,360
it's going to actually get the gov repo

00:22:01,440 --> 00:22:04,559
instead of the upstream repo so it'll

00:22:03,360 --> 00:22:06,640
try to pull that down

00:22:04,559 --> 00:22:08,080
and it'll work just like we would expect

00:22:06,640 --> 00:22:10,080
it to work but we've made it a little

00:22:08,080 --> 00:22:11,200
bit transparent to the to the end users

00:22:10,080 --> 00:22:13,520
so that's the first

00:22:11,200 --> 00:22:16,000
use case that we had that we solved with

00:22:13,520 --> 00:22:16,000
opa

00:22:16,720 --> 00:22:20,159
as we got further and further into the

00:22:18,720 --> 00:22:23,280
process one

00:22:20,159 --> 00:22:25,919
thing that kind of bit us was

00:22:23,280 --> 00:22:27,679
this next requirement it's in pci but

00:22:25,919 --> 00:22:29,760
it's also in govcloud but i like the the

00:22:27,679 --> 00:22:31,919
wording here a little bit more

00:22:29,760 --> 00:22:33,520
and this is pci requirement six develop

00:22:31,919 --> 00:22:34,240
and maintain secure systems and

00:22:33,520 --> 00:22:35,760
applications

00:22:34,240 --> 00:22:37,440
so there's a lot of a lot of things to

00:22:35,760 --> 00:22:42,000
unpack in that

00:22:37,440 --> 00:22:43,520
terminology but specifically 6.1

00:22:42,000 --> 00:22:45,120
underneath of this requirement is that

00:22:43,520 --> 00:22:47,360
you need to establish a process

00:22:45,120 --> 00:22:48,480
to basically scan for vulnerabilities

00:22:47,360 --> 00:22:49,520
and when you identify these

00:22:48,480 --> 00:22:51,039
vulnerabilities

00:22:49,520 --> 00:22:52,640
you have to remediate things that are

00:22:51,039 --> 00:22:54,559
medium or higher

00:22:52,640 --> 00:22:57,039
so you get different severity levels and

00:22:54,559 --> 00:22:59,520
these are based off of cvss scores

00:22:57,039 --> 00:23:00,080
and when you get these things you have

00:22:59,520 --> 00:23:01,840
um

00:23:00,080 --> 00:23:03,360
depending on the certificate whatever

00:23:01,840 --> 00:23:05,520
certification you've achieved

00:23:03,360 --> 00:23:07,520
you have n number of days to fix them so

00:23:05,520 --> 00:23:09,520
like in govcloud we have 30 days to fix

00:23:07,520 --> 00:23:11,919
things

00:23:09,520 --> 00:23:13,120
it's not a long time but it's also not a

00:23:11,919 --> 00:23:16,320
short time

00:23:13,120 --> 00:23:18,720
but as we deploy a ton of stuff

00:23:16,320 --> 00:23:20,080
we found as we went through this initial

00:23:18,720 --> 00:23:21,600
process we found a lot of containers

00:23:20,080 --> 00:23:23,919
that we were deploying that actually had

00:23:21,600 --> 00:23:24,640
a number of vulnerabilities so as i

00:23:23,919 --> 00:23:26,080
mentioned

00:23:24,640 --> 00:23:28,480
these things are based off of cvss

00:23:26,080 --> 00:23:30,720
scores so in the pci case

00:23:28,480 --> 00:23:33,360
anything that's mod medium or higher

00:23:30,720 --> 00:23:34,799
which is a cvs has score of four or more

00:23:33,360 --> 00:23:37,039
you actually have to remediate or you

00:23:34,799 --> 00:23:40,240
will fail your pci audit

00:23:37,039 --> 00:23:42,000
and any re reinvestigation or

00:23:40,240 --> 00:23:43,279
you know subsequent audits you go

00:23:42,000 --> 00:23:44,640
through you have to demonstrate that

00:23:43,279 --> 00:23:46,640
you've been doing these things and

00:23:44,640 --> 00:23:48,240
fixing these things

00:23:46,640 --> 00:23:50,720
and you can do this you can check this

00:23:48,240 --> 00:23:51,679
yourself there's a number of tools you

00:23:50,720 --> 00:23:54,400
can use

00:23:51,679 --> 00:23:56,159
we happen to use twist lock but you can

00:23:54,400 --> 00:23:56,960
use an open source tool from aquasec

00:23:56,159 --> 00:24:00,559
called trivi

00:23:56,960 --> 00:24:00,559
that'll do some pretty similar things

00:24:02,240 --> 00:24:05,679
just a really quick example of what that

00:24:03,760 --> 00:24:07,360
might look like i scanned one of the

00:24:05,679 --> 00:24:09,440
images that we have deployed

00:24:07,360 --> 00:24:11,200
in our commercial environment and you

00:24:09,440 --> 00:24:12,320
can see that it found a number of

00:24:11,200 --> 00:24:15,200
vulnerabilities

00:24:12,320 --> 00:24:15,919
two of them are critical three were high

00:24:15,200 --> 00:24:19,039
uh

00:24:15,919 --> 00:24:21,600
four were medium and three were low so

00:24:19,039 --> 00:24:22,960
we definitely have to fix those

00:24:21,600 --> 00:24:25,840
criticals those highs

00:24:22,960 --> 00:24:26,480
and for pci we need to fix those mediums

00:24:25,840 --> 00:24:28,080
what

00:24:26,480 --> 00:24:30,080
kind of things do you find inside of

00:24:28,080 --> 00:24:31,120
that so these can be os level

00:24:30,080 --> 00:24:32,960
vulnerabilities

00:24:31,120 --> 00:24:34,640
you could say like the version you're

00:24:32,960 --> 00:24:37,360
running an ubuntu based

00:24:34,640 --> 00:24:38,720
container and it's got uh glibc

00:24:37,360 --> 00:24:40,640
vulnerability inside of it

00:24:38,720 --> 00:24:42,240
that'll come up in these scanners and

00:24:40,640 --> 00:24:42,880
that will get flagged by one of the

00:24:42,240 --> 00:24:46,480
auditors

00:24:42,880 --> 00:24:49,360
so may not really be a problem but

00:24:46,480 --> 00:24:51,360
it's best to for us at least the least

00:24:49,360 --> 00:24:53,039
amount of effort is to fix the problem

00:24:51,360 --> 00:24:54,880
it could also be application level

00:24:53,039 --> 00:24:55,760
things so in this case this is a java

00:24:54,880 --> 00:24:58,320
application

00:24:55,760 --> 00:25:00,240
and the problem here is actually the

00:24:58,320 --> 00:25:03,360
version of log4j that it's using so

00:25:00,240 --> 00:25:04,159
how do we fix this process how do we how

00:25:03,360 --> 00:25:05,919
do we

00:25:04,159 --> 00:25:07,520
you know the vdp team handle fixing

00:25:05,919 --> 00:25:09,039
these things how would anybody else

00:25:07,520 --> 00:25:11,039
really handle these things

00:25:09,039 --> 00:25:12,960
well you generally need to build some

00:25:11,039 --> 00:25:15,039
new container to do this

00:25:12,960 --> 00:25:16,320
updating libraries may be applying os

00:25:15,039 --> 00:25:17,120
updates inside of the container if

00:25:16,320 --> 00:25:20,320
you're using

00:25:17,120 --> 00:25:22,720
something like photon if you're a vmware

00:25:20,320 --> 00:25:23,600
person or ubuntu or wn as the base

00:25:22,720 --> 00:25:25,120
images

00:25:23,600 --> 00:25:27,360
so we built a little process around that

00:25:25,120 --> 00:25:29,120
for ourselves and

00:25:27,360 --> 00:25:30,640
that involves taking whatever the base

00:25:29,120 --> 00:25:32,400
image that we have so

00:25:30,640 --> 00:25:33,840
maybe it's some upstream component

00:25:32,400 --> 00:25:35,520
that's based off of alpine

00:25:33,840 --> 00:25:38,480
or some upstream component that's based

00:25:35,520 --> 00:25:40,799
off of ubuntu we write a new docker file

00:25:38,480 --> 00:25:42,080
we take the old one as the the from line

00:25:40,799 --> 00:25:45,200
so if you're building a docker file

00:25:42,080 --> 00:25:46,960
out first line is from whatever then we

00:25:45,200 --> 00:25:48,080
run whatever the os appropriate updates

00:25:46,960 --> 00:25:48,799
are just to make sure that we apply

00:25:48,080 --> 00:25:51,039
those things

00:25:48,799 --> 00:25:51,840
and then we add in something we've built

00:25:51,039 --> 00:25:53,039
we add in

00:25:51,840 --> 00:25:54,960
you know we make sure that we've rebuilt

00:25:53,039 --> 00:25:56,960
that with whatever the updated libraries

00:25:54,960 --> 00:25:58,960
are and voila

00:25:56,960 --> 00:26:00,640
that results in a new tag hopefully

00:25:58,960 --> 00:26:02,320
without any vulnerabilities

00:26:00,640 --> 00:26:03,760
then we need to deploy that to the

00:26:02,320 --> 00:26:06,960
cluster so we go

00:26:03,760 --> 00:26:09,919
and maybe we run a helm update or

00:26:06,960 --> 00:26:10,960
k app deploy whatever functionality

00:26:09,919 --> 00:26:13,039
we're using

00:26:10,960 --> 00:26:15,039
but then we have to repeat this process

00:26:13,039 --> 00:26:15,840
whenever the vulnerabilities happen so

00:26:15,039 --> 00:26:18,640
for us

00:26:15,840 --> 00:26:20,400
we scan this pretty pretty regularly um

00:26:18,640 --> 00:26:22,559
and we automated that by

00:26:20,400 --> 00:26:23,679
building this you know these images

00:26:22,559 --> 00:26:25,840
pretty much every day

00:26:23,679 --> 00:26:27,440
so twice daily actually we run through

00:26:25,840 --> 00:26:29,360
that process

00:26:27,440 --> 00:26:31,520
we build all of the images we've

00:26:29,360 --> 00:26:34,240
identified in our inventory file

00:26:31,520 --> 00:26:36,080
which is of course the ammo file and we

00:26:34,240 --> 00:26:37,679
update those things to generate new tags

00:26:36,080 --> 00:26:39,279
then we update the inventory file

00:26:37,679 --> 00:26:40,799
and then we somehow need to deploy that

00:26:39,279 --> 00:26:43,039
to the kubernetes cluster

00:26:40,799 --> 00:26:44,000
and we want to do this in a not really

00:26:43,039 --> 00:26:46,000
manual way

00:26:44,000 --> 00:26:47,919
so we were able to pretty pretty easily

00:26:46,000 --> 00:26:49,440
automate the front half of that process

00:26:47,919 --> 00:26:50,720
where we would rebuild these containers

00:26:49,440 --> 00:26:51,919
we've already written the docker files

00:26:50,720 --> 00:26:53,440
for them

00:26:51,919 --> 00:26:55,520
we have this the skeleton of the

00:26:53,440 --> 00:26:56,159
inventory how do we then take that and

00:26:55,520 --> 00:26:59,679
deploy it

00:26:56,159 --> 00:27:01,360
so one of the cool things is that opa

00:26:59,679 --> 00:27:03,200
especially when you're using the cube

00:27:01,360 --> 00:27:03,760
management sidecar is that you get

00:27:03,200 --> 00:27:06,080
access

00:27:03,760 --> 00:27:07,520
to other resources in kubernetes it acts

00:27:06,080 --> 00:27:08,320
just kind of like any other kubernetes

00:27:07,520 --> 00:27:10,320
client would

00:27:08,320 --> 00:27:11,840
where it establishes a watch sees things

00:27:10,320 --> 00:27:14,000
from the api server

00:27:11,840 --> 00:27:15,279
so we put that into a config map in the

00:27:14,000 --> 00:27:17,360
cluster

00:27:15,279 --> 00:27:19,600
it lists out the name of the image and

00:27:17,360 --> 00:27:23,200
then what version we want to run

00:27:19,600 --> 00:27:24,799
and then the opa sidecar cube management

00:27:23,200 --> 00:27:26,960
sees that those things have changed and

00:27:24,799 --> 00:27:29,760
makes them available as a data field

00:27:26,960 --> 00:27:30,640
to opa you can access it like this so

00:27:29,760 --> 00:27:33,440
next

00:27:30,640 --> 00:27:35,279
we can write a pretty simple policy that

00:27:33,440 --> 00:27:38,320
looks at that inventory

00:27:35,279 --> 00:27:40,240
and compares that to what's deployed and

00:27:38,320 --> 00:27:42,960
then mutates the tag

00:27:40,240 --> 00:27:45,039
so our we again start with a patch block

00:27:42,960 --> 00:27:46,960
we iterate through

00:27:45,039 --> 00:27:48,399
all the images in the in this case the

00:27:46,960 --> 00:27:50,320
unit containers we do this for the

00:27:48,399 --> 00:27:51,919
containers and the regular containers

00:27:50,320 --> 00:27:54,960
obviously we want to update both

00:27:51,919 --> 00:27:57,279
um call this update image

00:27:54,960 --> 00:27:58,559
version function which returns us back a

00:27:57,279 --> 00:28:00,799
modified version of that

00:27:58,559 --> 00:28:03,039
reference and then we make a patch off

00:28:00,799 --> 00:28:05,360
of that and return it

00:28:03,039 --> 00:28:07,039
as just part of the mutation process

00:28:05,360 --> 00:28:09,200
just like we did with the repos

00:28:07,039 --> 00:28:12,399
we're now updating the tag to match what

00:28:09,200 --> 00:28:15,919
we have in our ci cd system

00:28:12,399 --> 00:28:17,760
so now our inventory file gets deployed

00:28:15,919 --> 00:28:19,120
to kubernetes we play that as a config

00:28:17,760 --> 00:28:21,600
map

00:28:19,120 --> 00:28:23,679
that gets reloaded by opa and then we

00:28:21,600 --> 00:28:24,799
run a small job that just labels

00:28:23,679 --> 00:28:26,559
touches the labels on all our

00:28:24,799 --> 00:28:28,399
deployments which then forces them to go

00:28:26,559 --> 00:28:30,480
through the emission process again

00:28:28,399 --> 00:28:31,440
that forces the mutating web hook in

00:28:30,480 --> 00:28:33,760
this case opa

00:28:31,440 --> 00:28:34,559
to update all the tags and then start up

00:28:33,760 --> 00:28:37,120
again with all

00:28:34,559 --> 00:28:38,960
those new um hopefully vulnerable

00:28:37,120 --> 00:28:40,880
vulnerability free images

00:28:38,960 --> 00:28:43,200
so the last policy that we really wanted

00:28:40,880 --> 00:28:45,600
to enforce was running as non-root

00:28:43,200 --> 00:28:47,279
and running is non-root we're doing

00:28:45,600 --> 00:28:49,919
mostly with pod security policies

00:28:47,279 --> 00:28:50,399
cloud security policy works pretty well

00:28:49,919 --> 00:28:51,679
and

00:28:50,399 --> 00:28:54,240
it's pretty easy for our tenants to

00:28:51,679 --> 00:28:54,880
understand except when they don't pay

00:28:54,240 --> 00:28:57,279
attention

00:28:54,880 --> 00:28:58,399
to the notifications we send and don't

00:28:57,279 --> 00:29:01,600
make changes

00:28:58,399 --> 00:29:03,840
to their their their uh 3ml

00:29:01,600 --> 00:29:05,679
so all of a sudden my pods won't start

00:29:03,840 --> 00:29:07,760
what's going on

00:29:05,679 --> 00:29:09,679
well did you specify the context of the

00:29:07,760 --> 00:29:11,360
security context in yaml

00:29:09,679 --> 00:29:13,440
oh you mean i have to update my chart

00:29:11,360 --> 00:29:15,840
again so again

00:29:13,440 --> 00:29:17,200
we bring mutation to bear here and in

00:29:15,840 --> 00:29:19,840
this case

00:29:17,200 --> 00:29:21,360
we take um again checking to see if

00:29:19,840 --> 00:29:24,000
mutations allowed

00:29:21,360 --> 00:29:26,080
we look to see if this the spec already

00:29:24,000 --> 00:29:28,080
has a security context defined and if it

00:29:26,080 --> 00:29:29,279
doesn't then we make another patch where

00:29:28,080 --> 00:29:31,760
we actually um

00:29:29,279 --> 00:29:32,799
add in the run as user and fs group to

00:29:31,760 --> 00:29:35,679
make this thing run

00:29:32,799 --> 00:29:36,799
uh as non-root the great thing here is

00:29:35,679 --> 00:29:38,480
though

00:29:36,799 --> 00:29:40,080
when the users are making these calls

00:29:38,480 --> 00:29:41,760
and they're deploying their stuff they

00:29:40,080 --> 00:29:43,600
can actually specify whatever security

00:29:41,760 --> 00:29:45,679
context they want and we won't mutate it

00:29:43,600 --> 00:29:48,000
this is just a nice add-on for them when

00:29:45,679 --> 00:29:50,000
they don't have that done

00:29:48,000 --> 00:29:53,120
so recapping what if we lo what have i

00:29:50,000 --> 00:29:55,919
uh what did we learn with vdp team learn

00:29:53,120 --> 00:29:56,720
opa is really flexible validation can

00:29:55,919 --> 00:29:58,720
get you pretty far

00:29:56,720 --> 00:30:00,080
you can write a lot of deny rules to

00:29:58,720 --> 00:30:01,200
lock your clusters down and do a lot of

00:30:00,080 --> 00:30:02,799
things

00:30:01,200 --> 00:30:04,240
but mutation can get you even further

00:30:02,799 --> 00:30:06,000
you can do a lot of things when you

00:30:04,240 --> 00:30:08,480
combine these two things together

00:30:06,000 --> 00:30:10,320
rego is pretty pretty easy to learn um

00:30:08,480 --> 00:30:10,799
the declarative nature of it just makes

00:30:10,320 --> 00:30:13,200
it

00:30:10,799 --> 00:30:13,840
pretty easy for people to pick up and we

00:30:13,200 --> 00:30:15,200
have found

00:30:13,840 --> 00:30:16,559
that it's pretty easy for all the team

00:30:15,200 --> 00:30:17,600
members to really learn it and start

00:30:16,559 --> 00:30:20,240
writing new policies

00:30:17,600 --> 00:30:22,000
or fix problems we found in the policies

00:30:20,240 --> 00:30:22,720
and then with those in mind we were able

00:30:22,000 --> 00:30:25,520
to balance

00:30:22,720 --> 00:30:27,760
our security needs pretty closely with

00:30:25,520 --> 00:30:30,080
our desire to make the user experience

00:30:27,760 --> 00:30:33,279
as nice as possible in this security

00:30:30,080 --> 00:30:33,279
world that we're living in

00:30:33,840 --> 00:30:38,720
but let's go back for a second and talk

00:30:36,159 --> 00:30:41,200
about the the mutation aspect of this

00:30:38,720 --> 00:30:43,360
i have mixed feelings about mutating web

00:30:41,200 --> 00:30:44,720
hooks and if you read the documentation

00:30:43,360 --> 00:30:46,880
the kubernetes documentation there's

00:30:44,720 --> 00:30:48,799
actually some call outs to say

00:30:46,880 --> 00:30:50,080
hey you should probably be aware of

00:30:48,799 --> 00:30:50,799
these things and maybe it's not the

00:30:50,080 --> 00:30:52,080
greatest case

00:30:50,799 --> 00:30:54,159
and one of them is that users don't

00:30:52,080 --> 00:30:55,919
necessarily know

00:30:54,159 --> 00:30:57,840
what's happening they may be confused by

00:30:55,919 --> 00:30:59,600
like what this thing that i've created

00:30:57,840 --> 00:31:01,519
uh doesn't look like what's in the

00:30:59,600 --> 00:31:02,880
cluster now what happened

00:31:01,519 --> 00:31:05,039
we actually had that problem with the

00:31:02,880 --> 00:31:07,039
security context mutation

00:31:05,039 --> 00:31:08,880
as we were going through this process

00:31:07,039 --> 00:31:11,840
people weren't specifying

00:31:08,880 --> 00:31:12,480
um security policies on their their uh

00:31:11,840 --> 00:31:14,559
their

00:31:12,480 --> 00:31:16,320
deployments and then actually tried to

00:31:14,559 --> 00:31:18,080
run as root and gave us an

00:31:16,320 --> 00:31:20,159
exception request where we created cert

00:31:18,080 --> 00:31:22,399
security service accounts for them

00:31:20,159 --> 00:31:24,080
um things like that but they didn't

00:31:22,399 --> 00:31:24,960
declare the security context because

00:31:24,080 --> 00:31:27,519
they were just

00:31:24,960 --> 00:31:28,559
you know depending on our automation or

00:31:27,519 --> 00:31:30,960
our easy mode

00:31:28,559 --> 00:31:33,039
access for that so think about the

00:31:30,960 --> 00:31:35,840
things you want to do with mutation

00:31:33,039 --> 00:31:36,880
um and and maybe use it judiciously and

00:31:35,840 --> 00:31:41,440
think about

00:31:36,880 --> 00:31:42,720
what impacts it may have downstream

00:31:41,440 --> 00:31:45,039
so here's some great links if you want

00:31:42,720 --> 00:31:46,320
to kind of follow up on these

00:31:45,039 --> 00:31:49,039
if you want to read more about the

00:31:46,320 --> 00:31:52,120
fedramp high requirements or the pci

00:31:49,039 --> 00:31:53,840
standards i've linked them both here um

00:31:52,120 --> 00:31:56,640
play.openpolicyagent.org is great to go

00:31:53,840 --> 00:31:58,880
experiment and mess around with policy

00:31:56,640 --> 00:32:00,399
there's a great tutorial linked here as

00:31:58,880 --> 00:32:01,760
well and like how to validate ingress in

00:32:00,399 --> 00:32:03,519
the cluster

00:32:01,760 --> 00:32:05,440
and then finally um one of the reasons

00:32:03,519 --> 00:32:06,559
we didn't use gatekeeper was it doesn't

00:32:05,440 --> 00:32:08,320
do mutation yet

00:32:06,559 --> 00:32:10,240
but there's an open issue here and maybe

00:32:08,320 --> 00:32:12,480
by the time cubecom comes around

00:32:10,240 --> 00:32:14,000
this will be done uh i would totally

00:32:12,480 --> 00:32:15,679
advise you to follow this and

00:32:14,000 --> 00:32:18,240
give gatekeeper a try if you're going to

00:32:15,679 --> 00:32:20,159
look at opa especially if you want to do

00:32:18,240 --> 00:32:21,919
just validating sort of things at the

00:32:20,159 --> 00:32:23,440
moment so at that point i'll turn it

00:32:21,919 --> 00:32:24,880
over to questions if you have any

00:32:23,440 --> 00:32:25,600
questions i would love to answer them

00:32:24,880 --> 00:32:28,799
now

00:32:25,600 --> 00:32:28,799

YouTube URL: https://www.youtube.com/watch?v=zVuM7F_BTyc


