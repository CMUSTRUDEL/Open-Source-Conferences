Title: TiFlash: Make TiKV 10x Faster and HTAP-able - Xiaoyu Ma & Liquan Pei, PingCAP
Publication date: 2020-11-23
Playlist: KubeCon + CloudNativeCon North America 2020 - Virtual
Description: 
	Don’t miss out! Join us at our upcoming event: KubeCon + CloudNativeCon Europe 2021 Virtual from May 4–7, 2021. Learn more at https://kubecon.io. The conference features presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects. 

TiFlash: Make TiKV 10x Faster and HTAP-able - Xiaoyu Ma & Liquan Pei, PingCAP 

HTAP is a term introduced by Gartner, describing the capability processing both transactional and analytical workload. It is hard to deal with both workload seamlessly in one platform since the storage format of the two is totally different and workload interference is a big issue. This session introduces a new component for TiKV project called TiFlash. It uses a novel way to solve the problem stated above: raft based HTAP architecture. This design makes TiKV 10x faster on analytical workload and provided strong workload isolation strategy. 

https://sched.co/ekFK
Captions: 
	00:00:02,240 --> 00:00:07,759
hello everyone today's topic is make

00:00:04,400 --> 00:00:10,800
thai tv 10 times faster and established

00:00:07,759 --> 00:00:14,799
this topic is brought by saryama

00:00:10,800 --> 00:00:14,799
and lee tranpay who are from pinkham

00:00:15,759 --> 00:00:21,680
so why to make thai kb edge tappable

00:00:19,359 --> 00:00:24,400
consider if you want to analyze online

00:00:21,680 --> 00:00:26,000
data in real time

00:00:24,400 --> 00:00:28,400
usually we use different types of

00:00:26,000 --> 00:00:28,640
database for transactional processing

00:00:28,400 --> 00:00:31,840
and

00:00:28,640 --> 00:00:33,920
analytical processing workloads

00:00:31,840 --> 00:00:35,520
because these workloads are totally

00:00:33,920 --> 00:00:37,840
different

00:00:35,520 --> 00:00:40,320
so for the database the design goal is

00:00:37,840 --> 00:00:42,079
totally different

00:00:40,320 --> 00:00:44,399
that means we use two different

00:00:42,079 --> 00:00:47,200
composite different type of the system

00:00:44,399 --> 00:00:50,160
different type of database and we need

00:00:47,200 --> 00:00:54,160
to move data from tpu to ap constantly

00:00:50,160 --> 00:00:56,079
by etl the data movement itself

00:00:54,160 --> 00:00:58,800
is very expensive slow and hard to

00:00:56,079 --> 00:00:59,199
maintain so usually people set chrome

00:00:58,800 --> 00:01:02,480
tab

00:00:59,199 --> 00:01:06,400
job constantly maybe like one hour

00:01:02,480 --> 00:01:06,400
or like a day

00:01:07,680 --> 00:01:10,960
and the job is responsible for moving

00:01:10,159 --> 00:01:14,320
data

00:01:10,960 --> 00:01:14,320
between different systems

00:01:14,799 --> 00:01:18,960
and this is not very simple you need to

00:01:17,200 --> 00:01:22,320
constantly watch these

00:01:18,960 --> 00:01:25,360
watch these job to preventing failures

00:01:22,320 --> 00:01:29,280
or you to check data if

00:01:25,360 --> 00:01:32,400
it is consistent during the movie

00:01:29,280 --> 00:01:35,680
and that becomes especially hard if the

00:01:32,400 --> 00:01:35,680
data volume is very big

00:01:38,880 --> 00:01:43,840
so it's not a question only a question

00:01:41,280 --> 00:01:47,600
of complexity

00:01:43,840 --> 00:01:50,159
that also means when you get a report

00:01:47,600 --> 00:01:51,920
that report might be based on data from

00:01:50,159 --> 00:01:55,840
yesterday

00:01:51,920 --> 00:01:55,840
you lost the data freshness

00:01:58,399 --> 00:02:03,280
so that means if you want to read the

00:02:02,159 --> 00:02:05,600
fresh data

00:02:03,280 --> 00:02:09,119
or you want to eat a fresh fruit the

00:02:05,600 --> 00:02:11,840
best way is to directly consume it

00:02:09,119 --> 00:02:11,840
from the source

00:02:17,680 --> 00:02:23,280
so why system is separated why we cannot

00:02:20,239 --> 00:02:26,400
combine two systems into one

00:02:23,280 --> 00:02:29,360
then we can dilate the moving

00:02:26,400 --> 00:02:32,480
data processing and directly read the

00:02:29,360 --> 00:02:36,480
data from the very beginning

00:02:32,480 --> 00:02:38,640
so that's because of

00:02:36,480 --> 00:02:40,640
different database for different goals

00:02:38,640 --> 00:02:43,760
that use different design

00:02:40,640 --> 00:02:45,840
especially the storage formats so for

00:02:43,760 --> 00:02:47,360
transaction processing system we usually

00:02:45,840 --> 00:02:50,239
use a row format

00:02:47,360 --> 00:02:51,519
so what is a row format row format means

00:02:50,239 --> 00:02:55,360
when you store a single

00:02:51,519 --> 00:02:59,280
each row you

00:02:55,360 --> 00:02:59,280
store the column side by side

00:02:59,840 --> 00:03:02,959
consider this kind of query select star

00:03:02,080 --> 00:03:06,720
from emp

00:03:02,959 --> 00:03:09,519
where id equals to 7658

00:03:06,720 --> 00:03:12,400
for a row format system you can directly

00:03:09,519 --> 00:03:14,959
seek to the start of the row

00:03:12,400 --> 00:03:15,680
and do a sequential read and you get all

00:03:14,959 --> 00:03:19,040
the row

00:03:15,680 --> 00:03:22,560
all the row data from that row

00:03:19,040 --> 00:03:26,720
so that means row formats is very

00:03:22,560 --> 00:03:29,200
good for this kind of workloads you read

00:03:26,720 --> 00:03:30,799
very few rows and you process them and

00:03:29,200 --> 00:03:33,200
store it back

00:03:30,799 --> 00:03:34,080
so that's the typical pattern for a

00:03:33,200 --> 00:03:37,120
transactional

00:03:34,080 --> 00:03:37,120
processing system

00:03:38,640 --> 00:03:44,879
let's consider another example select

00:03:41,680 --> 00:03:48,640
average age from emp

00:03:44,879 --> 00:03:51,360
so that looks like a reporting query

00:03:48,640 --> 00:03:54,640
you want to read they want to analyze

00:03:51,360 --> 00:03:57,599
the average age for your employee

00:03:54,640 --> 00:03:58,400
for that kind of query the column format

00:03:57,599 --> 00:04:01,360
is

00:03:58,400 --> 00:04:03,120
more suitable than a row format so what

00:04:01,360 --> 00:04:06,879
is a column format

00:04:03,120 --> 00:04:08,159
a column format is a way to store your

00:04:06,879 --> 00:04:10,490
data

00:04:08,159 --> 00:04:12,319
that for each individual column

00:04:10,490 --> 00:04:16,000
[Music]

00:04:12,319 --> 00:04:20,720
you store it tightly side by side

00:04:16,000 --> 00:04:20,720
instead of in a row bias

00:04:21,440 --> 00:04:28,000
so that means when we answer that query

00:04:25,199 --> 00:04:29,680
for average age you just need to

00:04:28,000 --> 00:04:32,880
directly seek

00:04:29,680 --> 00:04:34,080
to the start of the age column and do a

00:04:32,880 --> 00:04:38,080
sequential reads

00:04:34,080 --> 00:04:40,880
then you get all the data for age

00:04:38,080 --> 00:04:42,720
then you do a aggregation and answer the

00:04:40,880 --> 00:04:46,000
query

00:04:42,720 --> 00:04:49,680
you don't need to touch any data from

00:04:46,000 --> 00:04:49,680
the columns that you don't need

00:04:49,840 --> 00:04:54,080
now you can see that's very efficient

00:04:52,560 --> 00:04:57,840
way to read our data

00:04:54,080 --> 00:04:57,840
than the row format

00:04:58,400 --> 00:05:02,720
but if you want to answer a query like a

00:05:00,720 --> 00:05:06,160
point query

00:05:02,720 --> 00:05:08,800
like where id equals to 7658

00:05:06,160 --> 00:05:10,320
you just need to pick up a single row

00:05:08,800 --> 00:05:12,880
for a column format

00:05:10,320 --> 00:05:14,080
you need to seek three times and to find

00:05:12,880 --> 00:05:16,560
each individual

00:05:14,080 --> 00:05:17,600
column rows of each individual column

00:05:16,560 --> 00:05:20,240
data for that

00:05:17,600 --> 00:05:22,960
a single row and to combine it together

00:05:20,240 --> 00:05:25,440
then you can have the row

00:05:22,960 --> 00:05:26,080
so that means the column format is not

00:05:25,440 --> 00:05:30,240
very

00:05:26,080 --> 00:05:30,240
suitable for the transaction processing

00:05:32,800 --> 00:05:36,840
the other problem need to consider is

00:05:35,120 --> 00:05:39,680
the workload

00:05:36,840 --> 00:05:43,280
interference for tp workloads

00:05:39,680 --> 00:05:46,720
they might need to be very stable stable

00:05:43,280 --> 00:05:50,800
low latency and very high

00:05:46,720 --> 00:05:54,160
very high transactional rate rates

00:05:50,800 --> 00:05:55,840
both for a reporting query the qps might

00:05:54,160 --> 00:05:58,240
be very low

00:05:55,840 --> 00:06:00,960
but they consume a large amount of their

00:05:58,240 --> 00:06:04,960
compute resource

00:06:00,960 --> 00:06:06,880
so that means if you process those two

00:06:04,960 --> 00:06:09,039
kinds of workloads in a single single

00:06:06,880 --> 00:06:11,039
system

00:06:09,039 --> 00:06:12,880
the reporting or the analytical

00:06:11,039 --> 00:06:15,680
workloads might largely

00:06:12,880 --> 00:06:17,600
interfere your transactional workloads

00:06:15,680 --> 00:06:18,800
and the transaction workloads is very

00:06:17,600 --> 00:06:21,840
fragile

00:06:18,800 --> 00:06:21,840
you don't want this happen

00:06:25,759 --> 00:06:30,080
so how to make thai tv edge typical

00:06:30,560 --> 00:06:35,919
in the new version 4.0

00:06:33,680 --> 00:06:39,280
we introduced a new component named

00:06:35,919 --> 00:06:42,400
typeflash into thai kv system

00:06:39,280 --> 00:06:43,120
so what is a tie flash type flash is a

00:06:42,400 --> 00:06:46,720
real-time

00:06:43,120 --> 00:06:48,720
updatable column storage engine

00:06:46,720 --> 00:06:50,560
so the code base is partially based on

00:06:48,720 --> 00:06:51,199
click house the click house is a very

00:06:50,560 --> 00:06:54,240
famous

00:06:51,199 --> 00:06:54,240
open source project

00:06:55,440 --> 00:07:00,400
it's been built from the yandex

00:07:00,720 --> 00:07:08,319
and we think data as a learner role

00:07:04,479 --> 00:07:11,120
from thai tv by raft

00:07:08,319 --> 00:07:12,720
as some of you might know that we use

00:07:11,120 --> 00:07:15,759
raft

00:07:12,720 --> 00:07:16,479
as a consensus algorithm to replicate

00:07:15,759 --> 00:07:20,240
the data

00:07:16,479 --> 00:07:23,520
in thai kv system so in thai kb

00:07:20,240 --> 00:07:26,880
we have different replications

00:07:23,520 --> 00:07:29,120
for each piece of data

00:07:26,880 --> 00:07:30,080
and these replications are maintained by

00:07:29,120 --> 00:07:32,560
raft

00:07:30,080 --> 00:07:33,440
and some of the replication are leader

00:07:32,560 --> 00:07:36,400
replication

00:07:33,440 --> 00:07:37,280
and some are follower replication and

00:07:36,400 --> 00:07:39,759
for

00:07:37,280 --> 00:07:40,800
tie flash replication it's a learner

00:07:39,759 --> 00:07:44,479
role that means

00:07:40,800 --> 00:07:47,280
the tie flash replication will not vote

00:07:44,479 --> 00:07:48,160
and that we're preventing time flash to

00:07:47,280 --> 00:07:53,120
interfere

00:07:48,160 --> 00:07:53,120
the stableness of tank tv system

00:07:54,479 --> 00:07:57,840
so the two-story engine together make

00:07:57,120 --> 00:08:01,840
thai db

00:07:57,840 --> 00:08:05,520
system a htap database

00:08:01,840 --> 00:08:10,080
and we can also access data

00:08:05,520 --> 00:08:12,560
via cpo that means the tidbit optimizer

00:08:10,080 --> 00:08:14,240
is a cost-based optimizer and it can

00:08:12,560 --> 00:08:17,520
choose between

00:08:14,240 --> 00:08:20,319
a column formats or row formats

00:08:17,520 --> 00:08:22,000
from the based on the statistics

00:08:20,319 --> 00:08:23,759
information

00:08:22,000 --> 00:08:25,759
it will choose a path that which can

00:08:23,759 --> 00:08:28,720
provide better performance

00:08:25,759 --> 00:08:31,360
or lower lower cost or lower resource

00:08:28,720 --> 00:08:31,360
consumption

00:08:35,519 --> 00:08:38,560
thank you xiaoyu next i'm going to talk

00:08:38,080 --> 00:08:42,000
about

00:08:38,560 --> 00:08:42,000
the architecture of idb

00:08:42,320 --> 00:08:47,120
this is architectural tidbit and we have

00:08:44,720 --> 00:08:52,000
tidbit as a computation layer

00:08:47,120 --> 00:08:52,000
and attack away as a storage layer

00:08:52,399 --> 00:08:58,800
the data in take away are divided into

00:08:55,440 --> 00:09:02,640
regions and each region contains

00:08:58,800 --> 00:09:02,640
a contiguous key ranges

00:09:02,959 --> 00:09:08,160
each region has multiple replicas and

00:09:06,000 --> 00:09:11,839
they are keeping consistent with the

00:09:08,160 --> 00:09:15,360
rough replication protocol

00:09:11,839 --> 00:09:18,320
what we add here is the latter part

00:09:15,360 --> 00:09:19,360
which is a tie flash cluster and there

00:09:18,320 --> 00:09:23,600
are multiple nodes

00:09:19,360 --> 00:09:25,839
inside the flash cluster

00:09:23,600 --> 00:09:28,399
you can see that here we add a dashed

00:09:25,839 --> 00:09:31,680
line between the

00:09:28,399 --> 00:09:34,480
teflon nodes and take away nodes

00:09:31,680 --> 00:09:35,519
which means that the data replication in

00:09:34,480 --> 00:09:39,279
take away

00:09:35,519 --> 00:09:42,240
will not be affected if one or more

00:09:39,279 --> 00:09:42,240
flash nodes are done

00:09:45,360 --> 00:09:51,040
next i'll talk about how we do

00:09:48,720 --> 00:09:53,200
real-time updatable cloud columnar

00:09:51,040 --> 00:09:55,519
storage

00:09:53,200 --> 00:09:57,440
we designed the columnar storage named

00:09:55,519 --> 00:10:00,160
delta tree

00:09:57,440 --> 00:10:01,120
and the key idea is that we split the

00:10:00,160 --> 00:10:05,839
data

00:10:01,120 --> 00:10:05,839
by primary keys and into blocks

00:10:06,320 --> 00:10:09,760
the design goal of the dirt tray is to

00:10:08,480 --> 00:10:13,360
avoid multi-way

00:10:09,760 --> 00:10:16,720
merge when we scan in batch

00:10:13,360 --> 00:10:20,480
when new data arrives the data is append

00:10:16,720 --> 00:10:23,360
to the dirt space to

00:10:20,480 --> 00:10:25,200
to optimize for the read performance the

00:10:23,360 --> 00:10:29,920
dirt space is sorted and

00:10:25,200 --> 00:10:33,279
indexed periodically

00:10:29,920 --> 00:10:34,640
the dirt space is compacted into the

00:10:33,279 --> 00:10:37,920
stable states

00:10:34,640 --> 00:10:37,920
for better reader performance

00:10:39,360 --> 00:10:46,640
in this picture we want to compare

00:10:42,959 --> 00:10:49,920
and show that why the third

00:10:46,640 --> 00:10:52,800
third dirt tray can offer better

00:10:49,920 --> 00:10:55,120
read performance compared with the lsm

00:10:52,800 --> 00:10:55,120
trees

00:10:56,399 --> 00:10:59,519
in the left-hand side when you want to

00:10:58,959 --> 00:11:03,120
return

00:10:59,519 --> 00:11:05,360
range from lsm tree

00:11:03,120 --> 00:11:06,160
you need to read data from all the

00:11:05,360 --> 00:11:11,279
levels

00:11:06,160 --> 00:11:14,480
in the lsm3 and do a multiple

00:11:11,279 --> 00:11:17,279
way merge and this operation is really

00:11:14,480 --> 00:11:17,279
very heavyweight

00:11:17,360 --> 00:11:21,519
and the read amplification is high

00:11:22,000 --> 00:11:28,000
in dirt 3 you only need to merge data

00:11:25,519 --> 00:11:30,320
from the stable space and the third

00:11:28,000 --> 00:11:30,320
space

00:11:30,640 --> 00:11:36,720
on top of that we use a b plus 3 to

00:11:33,680 --> 00:11:36,720
index the segment

00:11:36,800 --> 00:11:44,880
information in this case if you want to

00:11:42,079 --> 00:11:46,640
return data for a certain reach you only

00:11:44,880 --> 00:11:49,680
need to read data

00:11:46,640 --> 00:11:49,680
from a few segments

00:11:50,240 --> 00:11:54,320
during the read the third space and the

00:11:52,880 --> 00:11:58,959
stable space

00:11:54,320 --> 00:12:02,000
are merged compared with the lsm3

00:11:58,959 --> 00:12:02,639
this merge is a two-way merge which has

00:12:02,000 --> 00:12:04,880
a lower

00:12:02,639 --> 00:12:06,800
overhead compared with the multi-way

00:12:04,880 --> 00:12:10,320
merge

00:12:06,800 --> 00:12:11,760
besides the stable stage is starting

00:12:10,320 --> 00:12:14,160
columnified

00:12:11,760 --> 00:12:15,040
which offers much better read

00:12:14,160 --> 00:12:17,839
performance

00:12:15,040 --> 00:12:17,839
during scans

00:12:20,160 --> 00:12:27,600
next i'm going to talk about how do we

00:12:23,600 --> 00:12:29,760
achieve the rough based edge type

00:12:27,600 --> 00:12:31,920
we introduce a learner role to the

00:12:29,760 --> 00:12:34,000
rafter protocol

00:12:31,920 --> 00:12:36,079
all the tech flash nodes are learner

00:12:34,000 --> 00:12:39,839
rules

00:12:36,079 --> 00:12:42,399
by learning rules we mean that those

00:12:39,839 --> 00:12:43,920
nodes will not participate in the router

00:12:42,399 --> 00:12:46,079
leader reduction

00:12:43,920 --> 00:12:47,200
no they become part of the current

00:12:46,079 --> 00:12:49,760
during the

00:12:47,200 --> 00:12:49,760
data right

00:12:50,480 --> 00:12:58,000
as a result the rising tech away

00:12:54,079 --> 00:13:01,200
does not need to wait for tech flush

00:12:58,000 --> 00:13:04,240
and take away works normally even if

00:13:01,200 --> 00:13:04,240
tesla knows die

00:13:04,480 --> 00:13:08,000
the replication between tacky away nodes

00:13:06,800 --> 00:13:11,040
and teflon nodes

00:13:08,000 --> 00:13:15,040
are direct replication and there's no

00:13:11,040 --> 00:13:18,160
intermediate channel between them

00:13:15,040 --> 00:13:21,120
this replication is very efficient

00:13:18,160 --> 00:13:23,760
and usually the latency between the is

00:13:21,120 --> 00:13:27,839
in milliseconds

00:13:23,760 --> 00:13:30,720
we also also rely on the automatic

00:13:27,839 --> 00:13:31,440
load balance and the fault tolerance

00:13:30,720 --> 00:13:34,320
features

00:13:31,440 --> 00:13:37,839
built in tidbit to make the data

00:13:34,320 --> 00:13:37,839
replication highly available

00:13:38,959 --> 00:13:42,800
this is also an illustration of what i

00:13:41,760 --> 00:13:45,920
just talked about

00:13:42,800 --> 00:13:49,279
in the last slides and compared

00:13:45,920 --> 00:13:52,639
the replication in

00:13:49,279 --> 00:13:55,760
kkv and tie flash with the etl

00:13:52,639 --> 00:13:59,040
this is this is very efficient

00:13:55,760 --> 00:14:00,560
here already during etl we need to copy

00:13:59,040 --> 00:14:02,639
data to a staging area

00:14:00,560 --> 00:14:04,320
and then copy the data to the data

00:14:02,639 --> 00:14:07,360
warehouse

00:14:04,320 --> 00:14:09,839
which causes a lot of data to be

00:14:07,360 --> 00:14:09,839
copied

00:14:15,519 --> 00:14:22,079
another thing people usually ask is how

00:14:18,399 --> 00:14:22,079
do we achieve consistent rate

00:14:23,360 --> 00:14:26,480
because replication from takeaway to

00:14:25,760 --> 00:14:30,079
tesla

00:14:26,480 --> 00:14:33,120
is asynchronous we need to guarantee

00:14:30,079 --> 00:14:34,720
the consistency during the real time how

00:14:33,120 --> 00:14:37,839
do we achieve this

00:14:34,720 --> 00:14:39,519
the idea is pretty simple and we use a

00:14:37,839 --> 00:14:41,920
learner rate algorithm

00:14:39,519 --> 00:14:42,880
and consult leader on the replication

00:14:41,920 --> 00:14:46,480
progress

00:14:42,880 --> 00:14:50,240
before we return the data to the client

00:14:46,480 --> 00:14:54,399
and this actually guarantees we can

00:14:50,240 --> 00:14:58,639
achieve a strongly consistent rate

00:14:54,399 --> 00:15:02,720
for example consider the case that

00:14:58,639 --> 00:15:06,639
at time t 0 there is a write to the

00:15:02,720 --> 00:15:07,360
tech every node and later at the time t

00:15:06,639 --> 00:15:10,720
00:15:07,360 --> 00:15:14,240
gives a rate to the test node

00:15:10,720 --> 00:15:17,440
how do we keep how do we make sure that

00:15:14,240 --> 00:15:18,800
the data read at t1 is strongly

00:15:17,440 --> 00:15:24,079
consistent

00:15:18,800 --> 00:15:24,079
and it can return the data written at t0

00:15:24,320 --> 00:15:31,519
during this the learner will first

00:15:28,560 --> 00:15:33,120
talk to the leader and ask the progress

00:15:31,519 --> 00:15:36,079
of the replication

00:15:33,120 --> 00:15:37,839
in the leader and in this case it knows

00:15:36,079 --> 00:15:41,040
that the leader is ready

00:15:37,839 --> 00:15:43,199
at index four before the

00:15:41,040 --> 00:15:46,560
learner returned to the client it needs

00:15:43,199 --> 00:15:50,639
to wait until it replicates to

00:15:46,560 --> 00:15:54,079
index 4 and then it returns data to the

00:15:50,639 --> 00:15:57,199
client this combined

00:15:54,079 --> 00:15:59,519
with the timestamp and vcc

00:15:57,199 --> 00:16:00,320
you can actually achieve snapshot

00:15:59,519 --> 00:16:03,360
isolation

00:16:00,320 --> 00:16:03,360
in ter flash as well

00:16:06,720 --> 00:16:10,959
next i'm going to talk about performance

00:16:09,519 --> 00:16:14,240
here is an example

00:16:10,959 --> 00:16:17,680
of the benchmark result

00:16:14,240 --> 00:16:20,839
on the on-time data so on-time data

00:16:17,680 --> 00:16:24,720
is a data collected since the 1980s

00:16:20,839 --> 00:16:26,639
about the airplanes it considers

00:16:24,720 --> 00:16:27,759
it contains the data of the flight

00:16:26,639 --> 00:16:31,199
number

00:16:27,759 --> 00:16:34,959
and the start time and the landing time

00:16:31,199 --> 00:16:38,480
you can see from the result that the

00:16:34,959 --> 00:16:41,279
ty tachydb plus tesla

00:16:38,480 --> 00:16:42,160
offers a very good performance compared

00:16:41,279 --> 00:16:45,759
with the

00:16:42,160 --> 00:16:48,839
other solutions some of them are

00:16:45,759 --> 00:16:50,160
built for analytics and big data

00:16:48,839 --> 00:16:53,360
processing

00:16:50,160 --> 00:16:56,160
these queries are multi-dimensional

00:16:53,360 --> 00:16:58,480
analytic queries whereas teddy b and

00:16:56,160 --> 00:17:00,560
teflash is good fit

00:16:58,480 --> 00:17:02,079
if you want to know more about the

00:17:00,560 --> 00:17:05,839
queries look like

00:17:02,079 --> 00:17:05,839
you can look at read about the blog

00:17:09,439 --> 00:17:13,520
here is an example of the performance

00:17:12,319 --> 00:17:16,720
improvement we see

00:17:13,520 --> 00:17:18,319
from an early adopter of tech flash

00:17:16,720 --> 00:17:20,480
it's an internet company called the

00:17:18,319 --> 00:17:24,079
xiaohungshu

00:17:20,480 --> 00:17:25,919
it is a thaidb user and they have tidbit

00:17:24,079 --> 00:17:28,880
running production

00:17:25,919 --> 00:17:30,960
they selected like around 400 queries

00:17:28,880 --> 00:17:34,799
from their production system

00:17:30,960 --> 00:17:34,799
and then migrated them to typeflash

00:17:34,960 --> 00:17:38,960
from this graph we can see there's a

00:17:37,440 --> 00:17:41,520
three to ten times

00:17:38,960 --> 00:17:41,520
speedup

00:17:42,799 --> 00:17:46,320
and we can see that for some long

00:17:44,880 --> 00:17:50,559
running queries

00:17:46,320 --> 00:17:50,559
the speed up can be up to 20 times

00:17:51,120 --> 00:17:54,400
also i want to call out that this result

00:17:53,600 --> 00:17:57,840
is based on

00:17:54,400 --> 00:17:59,600
older version of tesla and since then we

00:17:57,840 --> 00:18:02,720
made a lot of progresses

00:17:59,600 --> 00:18:04,160
and improvements on teleflash and you

00:18:02,720 --> 00:18:04,880
can we can expect much better

00:18:04,160 --> 00:18:08,559
performance

00:18:04,880 --> 00:18:08,559
with the newer version of typeflash

00:18:09,600 --> 00:18:12,880

YouTube URL: https://www.youtube.com/watch?v=Wob_D0ZWF1c


