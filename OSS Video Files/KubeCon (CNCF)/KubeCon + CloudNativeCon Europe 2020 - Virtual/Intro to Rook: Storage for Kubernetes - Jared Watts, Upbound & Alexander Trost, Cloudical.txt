Title: Intro to Rook: Storage for Kubernetes - Jared Watts, Upbound & Alexander Trost, Cloudical
Publication date: 2020-08-28
Playlist: KubeCon + CloudNativeCon Europe 2020 - Virtual
Description: 
	Donâ€™t miss out! Join us at our upcoming events: EnvoyCon Virtual on October 15 and KubeCon + CloudNativeCon North America 2020 Virtual from November 17-20. Learn more atÂ https://kubecon.io. The conferences feature presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects.  

Intro to Rook: Storage for Kubernetes - Jared Watts, Upbound & Alexander Trost, Cloudical 

In this talk, the Rook project will be introduced to attendees of all levels and experience. Rook is an open source cloud-native storage orchestrator for Kubernetes, providing the platform, framework, and support for a diverse set of storage solutions to natively integrate with cloud-native environments. Rook turns storage software into self-managing, self-scaling, and self-healing storage services. It does this by automating deployment, bootstrapping, configuration, provisioning, scaling, upgrading, migration, disaster recovery, monitoring, and resource management. The benefits and use cases of Rook will be explored along with an overview of each of the Rook storage providers: Ceph, EdgeFS, YugabyteDB, Cassandra, NFS, and CockroachDB. Rook was accepted as the first storage project hosted by the Cloud Native Computing Foundation in January 2018.

https://sched.co/Zex7
Captions: 
	00:00:00,080 --> 00:00:04,480
all right good afternoon kubecon eu

00:00:02,720 --> 00:00:07,440
virtual attendees

00:00:04,480 --> 00:00:08,080
this is going to be the uh introduction

00:00:07,440 --> 00:00:11,280
session

00:00:08,080 --> 00:00:11,599
to the rook project and i have here with

00:00:11,280 --> 00:00:14,639
me

00:00:11,599 --> 00:00:16,880
my colleague alexander trost uh who

00:00:14,639 --> 00:00:17,920
is currently a devops engineer at

00:00:16,880 --> 00:00:20,320
claudical

00:00:17,920 --> 00:00:22,320
and i am jared watts i'm a founding

00:00:20,320 --> 00:00:25,279
engineer at upbound and both of us

00:00:22,320 --> 00:00:26,960
are maintainers uh on the brook project

00:00:25,279 --> 00:00:27,920
we got a couple links in the bottom left

00:00:26,960 --> 00:00:29,439
so if you can

00:00:27,920 --> 00:00:31,359
help you find the rook project if you

00:00:29,439 --> 00:00:32,960
haven't been to it before so let's go

00:00:31,359 --> 00:00:34,640
ahead and move on to the agenda for

00:00:32,960 --> 00:00:38,160
today

00:00:34,640 --> 00:00:40,320
so elsa hi from me everyone uh in a from

00:00:38,160 --> 00:00:42,160
a center point we're going to talk about

00:00:40,320 --> 00:00:44,079
storage challenges in kubernetes we're

00:00:42,160 --> 00:00:44,879
going to talk about like what is rook

00:00:44,079 --> 00:00:47,280
what like what

00:00:44,879 --> 00:00:48,879
does it even solve uh we're going to

00:00:47,280 --> 00:00:51,520
look a bit into the architecture

00:00:48,879 --> 00:00:52,800
as it's very vital to understand like

00:00:51,520 --> 00:00:55,199
what is even going on

00:00:52,800 --> 00:00:57,760
under the hood uh there uh we're going

00:00:55,199 --> 00:00:58,399
to give a short demonstration as well

00:00:57,760 --> 00:01:01,039
and

00:00:58,399 --> 00:01:02,800
we are going to give you information on

00:01:01,039 --> 00:01:06,000
how you can get involved like even

00:01:02,800 --> 00:01:08,240
like you know slack and such things and

00:01:06,000 --> 00:01:10,000
if you want to learn more already we

00:01:08,240 --> 00:01:11,920
have a deep dive rook session coming up

00:01:10,000 --> 00:01:13,200
on thursday

00:01:11,920 --> 00:01:16,400
be sure to check it out if you want to

00:01:13,200 --> 00:01:18,400
learn even more about rogue

00:01:16,400 --> 00:01:20,000
okay let's start talking about some of

00:01:18,400 --> 00:01:24,159
the challenges that we

00:01:20,000 --> 00:01:26,960
typically see with storage in kubernetes

00:01:24,159 --> 00:01:28,880
so normally uh especially through the

00:01:26,960 --> 00:01:31,600
early days of kubernetes

00:01:28,880 --> 00:01:33,280
uh it was very typical to rely on

00:01:31,600 --> 00:01:35,600
storage that was outside

00:01:33,280 --> 00:01:37,439
of the cluster external storage uh which

00:01:35,600 --> 00:01:39,520
comes along with a couple problems

00:01:37,439 --> 00:01:41,360
um one of them is it's not portable

00:01:39,520 --> 00:01:44,320
really you think about if you have

00:01:41,360 --> 00:01:46,960
a you know a set of storage appliances

00:01:44,320 --> 00:01:49,439
like nas devices stands whatever

00:01:46,960 --> 00:01:50,240
they're not very portable uh to other

00:01:49,439 --> 00:01:53,439
solutions

00:01:50,240 --> 00:01:54,079
so that can cause some issues and

00:01:53,439 --> 00:01:56,240
there's also

00:01:54,079 --> 00:01:57,759
sort of a deployment burden as well you

00:01:56,240 --> 00:01:59,040
have to you know physically go through

00:01:57,759 --> 00:02:00,479
the effort of setting those up

00:01:59,040 --> 00:02:02,640
plugging them in and all that sort of

00:02:00,479 --> 00:02:04,399
stuff so not ideal

00:02:02,640 --> 00:02:06,640
um would be better software could do

00:02:04,399 --> 00:02:09,679
that for us right and then also

00:02:06,640 --> 00:02:10,800
you could use cloud storage from the

00:02:09,679 --> 00:02:13,760
cloud providers

00:02:10,800 --> 00:02:15,440
your google persistent disk or ebs

00:02:13,760 --> 00:02:17,520
volumes et cetera

00:02:15,440 --> 00:02:19,040
and other managed services as well which

00:02:17,520 --> 00:02:20,720
can typically lead to

00:02:19,040 --> 00:02:22,319
vendor lock-in whenever you use cloud

00:02:20,720 --> 00:02:23,680
provider maintenance services which

00:02:22,319 --> 00:02:26,239
which are good they're they're pretty

00:02:23,680 --> 00:02:27,760
valuable um it does make it harder to

00:02:26,239 --> 00:02:28,720
move to another cloud

00:02:27,760 --> 00:02:30,959
and then there's this whole other

00:02:28,720 --> 00:02:31,280
element of day two operations of you

00:02:30,959 --> 00:02:34,720
know

00:02:31,280 --> 00:02:36,560
backups restores um ongoing operations

00:02:34,720 --> 00:02:38,160
making sure it's healthy somebody has to

00:02:36,560 --> 00:02:40,879
do that right

00:02:38,160 --> 00:02:41,440
um so if we take a look at this visual

00:02:40,879 --> 00:02:44,400
here

00:02:41,440 --> 00:02:46,800
this is just a quick sort of um diagram

00:02:44,400 --> 00:02:48,160
of external storage for kubernetes

00:02:46,800 --> 00:02:49,920
and so we see on the left we have a

00:02:48,160 --> 00:02:51,440
kubernetes cluster on the right we have

00:02:49,920 --> 00:02:52,480
all sorts of different types of storage

00:02:51,440 --> 00:02:55,360
cloud storage

00:02:52,480 --> 00:02:56,800
and storage appliances and such and uh

00:02:55,360 --> 00:02:58,800
volume plugins

00:02:56,800 --> 00:03:00,480
is what is serves as sort of a bridge

00:02:58,800 --> 00:03:02,640
between the cluster and the external

00:03:00,480 --> 00:03:04,239
storage to provision it on demand and

00:03:02,640 --> 00:03:05,680
provide it to applications

00:03:04,239 --> 00:03:08,239
so that's typical way that you would do

00:03:05,680 --> 00:03:10,959
external storage in kubernetes

00:03:08,239 --> 00:03:12,000
which brings us to what is rook uh so

00:03:10,959 --> 00:03:14,239
rook can be thought of

00:03:12,000 --> 00:03:15,840
as a set of storage operators for

00:03:14,239 --> 00:03:16,480
kubernetes and this really brings

00:03:15,840 --> 00:03:19,680
storage

00:03:16,480 --> 00:03:21,440
into inside to the kubernetes cluster uh

00:03:19,680 --> 00:03:24,879
you can think of operators as being

00:03:21,440 --> 00:03:27,599
a you know software for automation

00:03:24,879 --> 00:03:29,200
and an api to do a whole bunch of

00:03:27,599 --> 00:03:31,519
operational tasks for

00:03:29,200 --> 00:03:33,519
running storage you know deploying it

00:03:31,519 --> 00:03:34,560
and configuring it and setting it up and

00:03:33,519 --> 00:03:36,000
provisioning and

00:03:34,560 --> 00:03:37,360
you know upgrading and backups and

00:03:36,000 --> 00:03:37,920
restores and all sorts of stuff like

00:03:37,360 --> 00:03:40,080
that

00:03:37,920 --> 00:03:41,920
and then provisioning storage too for

00:03:40,080 --> 00:03:43,680
when a application needs it

00:03:41,920 --> 00:03:45,599
uh to be able to dynamically provision

00:03:43,680 --> 00:03:46,000
that in cluster storage and have it

00:03:45,599 --> 00:03:48,239
ready

00:03:46,000 --> 00:03:51,200
to be consumed by applications so that's

00:03:48,239 --> 00:03:53,439
one way to think about what rook is

00:03:51,200 --> 00:03:55,280
but you know beyond those operators it's

00:03:53,439 --> 00:03:58,000
also a framework

00:03:55,280 --> 00:03:59,200
to allow a lot of different storage

00:03:58,000 --> 00:04:01,120
providers to

00:03:59,200 --> 00:04:03,760
migrate or make their way into

00:04:01,120 --> 00:04:06,319
cloud-native ecosystem and cloud-native

00:04:03,760 --> 00:04:07,920
environments and kubernetes um we'll

00:04:06,319 --> 00:04:11,040
talk more about that framework in a bit

00:04:07,920 --> 00:04:12,640
it's an open source project and it was

00:04:11,040 --> 00:04:13,599
donated to the cloud native computing

00:04:12,640 --> 00:04:16,479
foundation

00:04:13,599 --> 00:04:17,600
a couple years ago and it's incubation

00:04:16,479 --> 00:04:20,720
level right now

00:04:17,600 --> 00:04:24,160
but the vote is ongoing for

00:04:20,720 --> 00:04:25,040
it to be moved to full graduation from

00:04:24,160 --> 00:04:26,720
the cncf

00:04:25,040 --> 00:04:28,800
so we're very excited about that and

00:04:26,720 --> 00:04:30,240
hopefully by the time this recording is

00:04:28,800 --> 00:04:32,960
being played that

00:04:30,240 --> 00:04:34,160
that we will have made that the vote

00:04:32,960 --> 00:04:36,320
will be complete and will be fully

00:04:34,160 --> 00:04:38,880
graduated

00:04:36,320 --> 00:04:40,479
so the you know quick shout out to the

00:04:38,880 --> 00:04:42,639
community

00:04:40,479 --> 00:04:44,400
gosh this community is so amazing um

00:04:42,639 --> 00:04:46,000
that is absolutely the backbone of why

00:04:44,400 --> 00:04:47,600
the project is successful

00:04:46,000 --> 00:04:49,040
uh so we take a look at some of the more

00:04:47,600 --> 00:04:52,000
recent um

00:04:49,040 --> 00:04:53,120
events and statistics here uh 1.4

00:04:52,000 --> 00:04:55,680
released

00:04:53,120 --> 00:04:56,960
came out which is all sorts of new

00:04:55,680 --> 00:05:00,000
features and improvements

00:04:56,960 --> 00:05:03,440
um to the rook operators uh we have over

00:05:00,000 --> 00:05:05,520
7 000 github stars now 160 million

00:05:03,440 --> 00:05:07,120
downloads of the container image my

00:05:05,520 --> 00:05:08,000
favorite part though is how we almost

00:05:07,120 --> 00:05:11,840
have

00:05:08,000 --> 00:05:13,360
almost 300 contributors uh you know 275

00:05:11,840 --> 00:05:15,120
or more people that have written code

00:05:13,360 --> 00:05:16,000
for rook which is absolutely amazing to

00:05:15,120 --> 00:05:18,080
me

00:05:16,000 --> 00:05:19,039
and got the project where it is and then

00:05:18,080 --> 00:05:20,800
as we mentioned too

00:05:19,039 --> 00:05:25,039
uh the project is currently being voted

00:05:20,800 --> 00:05:27,840
on to graduate from the cncf

00:05:25,039 --> 00:05:29,600
so a little bit more about the framework

00:05:27,840 --> 00:05:31,199
uh so rook is more than just a set of

00:05:29,600 --> 00:05:32,800
operators right it's a whole framework

00:05:31,199 --> 00:05:33,440
and platform and libraries and

00:05:32,800 --> 00:05:35,120
automation

00:05:33,440 --> 00:05:36,560
and functions and code and all sorts of

00:05:35,120 --> 00:05:38,560
stuff to make

00:05:36,560 --> 00:05:39,919
basically make it easier for a storage

00:05:38,560 --> 00:05:42,240
provider to

00:05:39,919 --> 00:05:43,600
uh come into kubernetes and be running

00:05:42,240 --> 00:05:46,639
in cloud nano environments

00:05:43,600 --> 00:05:47,440
so there's functions and and libraries

00:05:46,639 --> 00:05:49,360
to help

00:05:47,440 --> 00:05:51,520
uh you know normalize the way that

00:05:49,360 --> 00:05:53,120
storage resources are described

00:05:51,520 --> 00:05:55,680
you know a set of hard drives a set of

00:05:53,120 --> 00:05:58,240
pvs how much of them to use

00:05:55,680 --> 00:05:59,680
filters patterns etc to say basically

00:05:58,240 --> 00:06:00,880
say what storage to include in the

00:05:59,680 --> 00:06:02,560
cluster

00:06:00,880 --> 00:06:04,840
you know all sorts of the operator

00:06:02,560 --> 00:06:07,360
patterns and plumbing there first

00:06:04,840 --> 00:06:09,600
storage you know specific storage

00:06:07,360 --> 00:06:10,800
needs um one of my favorites so is the

00:06:09,600 --> 00:06:12,240
integration testing

00:06:10,800 --> 00:06:15,360
that we have we have an entire framework

00:06:12,240 --> 00:06:17,520
around uh testing storage solutions

00:06:15,360 --> 00:06:18,720
and storage needs across a variety of

00:06:17,520 --> 00:06:21,520
kubernetes clusters

00:06:18,720 --> 00:06:22,479
versions clouds etc so all those things

00:06:21,520 --> 00:06:24,560
are available

00:06:22,479 --> 00:06:26,639
in a framework for new storage providers

00:06:24,560 --> 00:06:28,960
to come in be part of their book project

00:06:26,639 --> 00:06:30,240
and make it easier to reduce the burden

00:06:28,960 --> 00:06:31,600
that they have to be running in cloud

00:06:30,240 --> 00:06:33,840
native environments

00:06:31,600 --> 00:06:36,240
so you can see a whole series of storage

00:06:33,840 --> 00:06:37,919
providers that the rook project

00:06:36,240 --> 00:06:40,000
currently supports and we'll get into

00:06:37,919 --> 00:06:42,479
details on those on this slide

00:06:40,000 --> 00:06:43,840
so we're going to start with the stable

00:06:42,479 --> 00:06:46,160
providers each one of these storage

00:06:43,840 --> 00:06:47,759
providers has been declared as stable

00:06:46,160 --> 00:06:50,000
so ceph was actually the first storage

00:06:47,759 --> 00:06:51,599
provider that uh rook started with

00:06:50,000 --> 00:06:53,520
the project was kind of founded around

00:06:51,599 --> 00:06:55,919
doing orchestration for ceph

00:06:53,520 --> 00:06:57,759
um seth provides you know uh three

00:06:55,919 --> 00:06:59,759
different types of storage file block

00:06:57,759 --> 00:07:01,039
and object but it's also really highly

00:06:59,759 --> 00:07:03,120
scalable which is

00:07:01,039 --> 00:07:04,720
has some really nice properties because

00:07:03,120 --> 00:07:06,160
you know basically anyone in the cluster

00:07:04,720 --> 00:07:07,520
can figure out where a piece of data

00:07:06,160 --> 00:07:08,400
should go you don't have to centralize

00:07:07,520 --> 00:07:10,160
that information

00:07:08,400 --> 00:07:11,759
so that's a really nice kind of

00:07:10,160 --> 00:07:13,840
offloading uh

00:07:11,759 --> 00:07:16,000
from a central bottleneck to make it a

00:07:13,840 --> 00:07:18,400
very highly scalable solution

00:07:16,000 --> 00:07:19,440
edge fs is the second storage provider

00:07:18,400 --> 00:07:21,759
that made it to

00:07:19,440 --> 00:07:22,800
a stable declaration ready for use in

00:07:21,759 --> 00:07:25,440
production

00:07:22,800 --> 00:07:27,039
and it is um it's kind of this design is

00:07:25,440 --> 00:07:28,960
kind of similar to how git

00:07:27,039 --> 00:07:30,160
is designed where it's based on

00:07:28,960 --> 00:07:31,680
immutable blocks

00:07:30,160 --> 00:07:33,680
and when you change a block uh

00:07:31,680 --> 00:07:34,960
modifications to blocks are globally

00:07:33,680 --> 00:07:35,759
unique and they give the block a new

00:07:34,960 --> 00:07:39,039
identity

00:07:35,759 --> 00:07:41,199
and those properties there kind of set

00:07:39,039 --> 00:07:43,759
edge of s up to be natively designed to

00:07:41,199 --> 00:07:46,240
be globally scalable which is great

00:07:43,759 --> 00:07:46,800
this slide we have both our alpha and

00:07:46,240 --> 00:07:49,840
beta

00:07:46,800 --> 00:07:50,960
providers so these ones are not quite

00:07:49,840 --> 00:07:52,879
too stable

00:07:50,960 --> 00:07:54,479
yet but they are on their way maturing

00:07:52,879 --> 00:07:58,000
and growing cassandra

00:07:54,479 --> 00:08:00,400
is a distributed nosql database that's

00:07:58,000 --> 00:08:01,919
made for large amounts of data

00:08:00,400 --> 00:08:03,440
and i like this one especially too

00:08:01,919 --> 00:08:05,520
because a contributor

00:08:03,440 --> 00:08:07,280
named giannis um he actually did that

00:08:05,520 --> 00:08:09,039
for the initial implementation for his

00:08:07,280 --> 00:08:10,000
master's thesis when he was graduating

00:08:09,039 --> 00:08:11,520
from uh

00:08:10,000 --> 00:08:13,199
graduating with his master's degree so

00:08:11,520 --> 00:08:16,160
that was really awesome

00:08:13,199 --> 00:08:17,199
cockroachdb is a highly resilient

00:08:16,160 --> 00:08:18,800
location aware

00:08:17,199 --> 00:08:20,560
database which has really cool

00:08:18,800 --> 00:08:22,000
properties when you

00:08:20,560 --> 00:08:23,280
have location awareness about where

00:08:22,000 --> 00:08:23,919
you're running you can make decisions

00:08:23,280 --> 00:08:25,440
about

00:08:23,919 --> 00:08:28,639
where to move data to be closer to

00:08:25,440 --> 00:08:30,960
clients uh where to move data to be

00:08:28,639 --> 00:08:32,880
um you know to have excellent

00:08:30,960 --> 00:08:33,599
availability and durability properties

00:08:32,880 --> 00:08:35,839
et cetera

00:08:33,599 --> 00:08:37,200
so it's a well-designed database and

00:08:35,839 --> 00:08:40,000
that's also running as a

00:08:37,200 --> 00:08:41,120
rook storage provider uh nfs the network

00:08:40,000 --> 00:08:43,839
file system

00:08:41,120 --> 00:08:45,680
you typically use this when you want to

00:08:43,839 --> 00:08:46,880
have multiple writers on a shared file

00:08:45,680 --> 00:08:48,880
system

00:08:46,880 --> 00:08:50,800
that was originally implemented as part

00:08:48,880 --> 00:08:52,720
of the google summer of code

00:08:50,800 --> 00:08:54,000
project a couple years ago and then this

00:08:52,720 --> 00:08:55,760
summer there's a

00:08:54,000 --> 00:08:57,440
new google summer of code participant

00:08:55,760 --> 00:08:59,440
his name is ahmad and he

00:08:57,440 --> 00:09:00,399
is making lots of enhancements to nfs

00:08:59,440 --> 00:09:02,160
this summer so there's active

00:09:00,399 --> 00:09:04,080
contributions going on there

00:09:02,160 --> 00:09:05,680
and then you go by db is the newest

00:09:04,080 --> 00:09:08,000
storage provider it is

00:09:05,680 --> 00:09:09,920
it's a relational database as well um

00:09:08,000 --> 00:09:13,040
it's designed for multiple regions

00:09:09,920 --> 00:09:15,200
um you know globally distributed as well

00:09:13,040 --> 00:09:16,160
and it's set up for you know very low

00:09:15,200 --> 00:09:17,920
latency

00:09:16,160 --> 00:09:19,440
uh high ability high availability and

00:09:17,920 --> 00:09:21,279
high scale as well so

00:09:19,440 --> 00:09:22,800
we're glad to have you go by part as uh

00:09:21,279 --> 00:09:24,240
part of rook as a storage provider as

00:09:22,800 --> 00:09:26,160
well

00:09:24,240 --> 00:09:28,000
so at the end of the day though the goal

00:09:26,160 --> 00:09:28,880
of rook and all these storage providers

00:09:28,000 --> 00:09:31,440
that it supports

00:09:28,880 --> 00:09:33,040
is for persistence uh you know

00:09:31,440 --> 00:09:34,080
persistence of data for applications

00:09:33,040 --> 00:09:35,760
right

00:09:34,080 --> 00:09:37,680
so let's start talking about the

00:09:35,760 --> 00:09:38,080
kubernetes native integration because

00:09:37,680 --> 00:09:40,399
rook

00:09:38,080 --> 00:09:42,240
is a set of storage orchestrators and a

00:09:40,399 --> 00:09:43,440
framework for storage in kubernetes so

00:09:42,240 --> 00:09:44,880
let's talk about how it natively

00:09:43,440 --> 00:09:47,920
integrates there

00:09:44,880 --> 00:09:50,160
um which brings us to a visual

00:09:47,920 --> 00:09:52,240
here this is an analogy we're setting up

00:09:50,160 --> 00:09:53,920
here so you can think about you see this

00:09:52,240 --> 00:09:54,800
little tugboat here it's pulling or

00:09:53,920 --> 00:09:56,560
guiding the

00:09:54,800 --> 00:09:58,240
big cargo boat there with lots of

00:09:56,560 --> 00:09:59,920
valuable cargo so you can think about

00:09:58,240 --> 00:10:02,800
the cargo boat

00:09:59,920 --> 00:10:04,079
being a uh the data plane the storage

00:10:02,800 --> 00:10:06,800
providers you know they have

00:10:04,079 --> 00:10:07,600
a ton of valuable cargo on there and the

00:10:06,800 --> 00:10:09,200
tugboat

00:10:07,600 --> 00:10:11,200
is the one that's kind of leading and

00:10:09,200 --> 00:10:13,600
guiding and steering and orchestrating

00:10:11,200 --> 00:10:14,800
uh and managing some of the the

00:10:13,600 --> 00:10:17,040
direction that the

00:10:14,800 --> 00:10:18,079
um that data plane that cargo ship is

00:10:17,040 --> 00:10:20,320
heading in

00:10:18,079 --> 00:10:21,120
so keep that analogy in mind as we move

00:10:20,320 --> 00:10:23,120
forward to

00:10:21,120 --> 00:10:24,320
the operator pattern so the operator

00:10:23,120 --> 00:10:27,360
pattern is fairly common

00:10:24,320 --> 00:10:29,120
in kubernetes now and it's basically

00:10:27,360 --> 00:10:30,640
uh you know software automation that

00:10:29,120 --> 00:10:33,040
sits in a control loop and

00:10:30,640 --> 00:10:34,320
acts in three phases the first is that

00:10:33,040 --> 00:10:36,399
it observes

00:10:34,320 --> 00:10:37,360
the current state of the system the

00:10:36,399 --> 00:10:39,760
actual state

00:10:37,360 --> 00:10:41,519
reality in the cluster and then it

00:10:39,760 --> 00:10:44,240
analyzes and says okay how is

00:10:41,519 --> 00:10:46,079
this actual state that i found how is it

00:10:44,240 --> 00:10:47,920
different than the desired state

00:10:46,079 --> 00:10:49,760
that the user says they want for the

00:10:47,920 --> 00:10:51,040
storage system and it figures out the

00:10:49,760 --> 00:10:53,839
delta between those

00:10:51,040 --> 00:10:54,560
and then acts the third phase on taking

00:10:53,839 --> 00:10:56,959
that delta

00:10:54,560 --> 00:10:57,760
and continually driving the actual state

00:10:56,959 --> 00:11:00,079
of the cluster

00:10:57,760 --> 00:11:02,079
towards the desired state so it'll keep

00:11:00,079 --> 00:11:03,600
in a loop and you're doing this observe

00:11:02,079 --> 00:11:05,519
analyze act and making sure that the

00:11:03,600 --> 00:11:07,279
user's desired state is

00:11:05,519 --> 00:11:08,880
where the cluster is heading at all

00:11:07,279 --> 00:11:10,320
times

00:11:08,880 --> 00:11:11,839
so we take a look at this architecture

00:11:10,320 --> 00:11:13,200
diagram a little bit under the covers

00:11:11,839 --> 00:11:15,920
here about how rook works

00:11:13,200 --> 00:11:16,800
uh let's work left to left to right so

00:11:15,920 --> 00:11:18,720
cube control

00:11:16,800 --> 00:11:20,880
uh is you know the client interface to

00:11:18,720 --> 00:11:22,959
kubernetes api it talks to the

00:11:20,880 --> 00:11:24,480
kubernetes api server there and you can

00:11:22,959 --> 00:11:26,320
do things like you know cube control

00:11:24,480 --> 00:11:29,440
create or get

00:11:26,320 --> 00:11:30,079
storage pools and file storage etc and

00:11:29,440 --> 00:11:31,839
then

00:11:30,079 --> 00:11:33,360
we have the rook operators that are in

00:11:31,839 --> 00:11:34,560
the cluster also talking to the

00:11:33,360 --> 00:11:36,800
kubernetes api

00:11:34,560 --> 00:11:38,880
and so they'll take that desired state

00:11:36,800 --> 00:11:41,760
of okay you want a storage cluster

00:11:38,880 --> 00:11:43,760
uh i will turn that into a set of

00:11:41,760 --> 00:11:47,760
deployments and pods and services

00:11:43,760 --> 00:11:50,639
config maps etc that you know hosts the

00:11:47,760 --> 00:11:52,639
storage demons on the bottom right there

00:11:50,639 --> 00:11:53,519
uh the storage provider specific demons

00:11:52,639 --> 00:11:57,200
like the ceph

00:11:53,519 --> 00:12:00,800
monitors and osds and things like that

00:11:57,200 --> 00:12:03,600
or the cockroachdb instances so

00:12:00,800 --> 00:12:05,120
you know this is a representation of in

00:12:03,600 --> 00:12:08,000
the kubernetes cluster

00:12:05,120 --> 00:12:09,360
how it's based on the kubernetes api you

00:12:08,000 --> 00:12:10,000
have a set of operators watching

00:12:09,360 --> 00:12:13,040
listening

00:12:10,000 --> 00:12:15,760
for desired state and manipulating

00:12:13,040 --> 00:12:16,959
objects in the cluster to drive that

00:12:15,760 --> 00:12:18,560
actual state of the cluster

00:12:16,959 --> 00:12:20,320
in the storage daemons the storage

00:12:18,560 --> 00:12:21,920
provider or fabric

00:12:20,320 --> 00:12:24,079
towards the desired state that the user

00:12:21,920 --> 00:12:26,880
wants which brings us back

00:12:24,079 --> 00:12:27,279
to our analogy of the big cargo ship

00:12:26,880 --> 00:12:29,040
there

00:12:27,279 --> 00:12:30,320
where the storage provider the data

00:12:29,040 --> 00:12:33,040
plane that's hosting

00:12:30,320 --> 00:12:34,000
are holding a lot of bits and bytes and

00:12:33,040 --> 00:12:36,320
important data

00:12:34,000 --> 00:12:38,079
in for the cluster and the little rook

00:12:36,320 --> 00:12:40,320
operators the tugboats there

00:12:38,079 --> 00:12:42,079
that are guiding and steering you know

00:12:40,320 --> 00:12:44,480
managing or orchestrating

00:12:42,079 --> 00:12:46,160
the data plane to make sure that's

00:12:44,480 --> 00:12:48,720
aligned with the desired state that the

00:12:46,160 --> 00:12:50,560
user is expressed

00:12:48,720 --> 00:12:52,079
so now that we've learned about what an

00:12:50,560 --> 00:12:53,839
authority is doing and we've

00:12:52,079 --> 00:12:55,440
already heard about custom resist

00:12:53,839 --> 00:12:57,839
definitions

00:12:55,440 --> 00:12:58,720
uh let's dive into what custom resist

00:12:57,839 --> 00:13:01,360
definitions

00:12:58,720 --> 00:13:01,839
even are and especially at the example

00:13:01,360 --> 00:13:04,639
of the

00:13:01,839 --> 00:13:06,000
rogue ceph operator let's take a look

00:13:04,639 --> 00:13:07,760
what they provide

00:13:06,000 --> 00:13:11,360
to the operator and in the end for you

00:13:07,760 --> 00:13:14,079
the user of an operator

00:13:11,360 --> 00:13:14,639
so it's kind of like that if you think

00:13:14,079 --> 00:13:17,120
of

00:13:14,639 --> 00:13:17,920
the operator i guess the you know like a

00:13:17,120 --> 00:13:20,959
motor

00:13:17,920 --> 00:13:23,920
turning all the wheels in the end

00:13:20,959 --> 00:13:24,880
the custom resist definition is

00:13:23,920 --> 00:13:28,160
basically

00:13:24,880 --> 00:13:29,360
the parameters for those wheels like as

00:13:28,160 --> 00:13:32,399
an example

00:13:29,360 --> 00:13:34,240
let's say for um seth which

00:13:32,399 --> 00:13:36,160
version of ceph you want to have

00:13:34,240 --> 00:13:40,480
deployed that would be

00:13:36,160 --> 00:13:44,399
one parameter and well

00:13:40,480 --> 00:13:48,240
it adds up in the end to the whole big

00:13:44,399 --> 00:13:51,600
uh thing of a being of a sev cluster

00:13:48,240 --> 00:13:54,079
and we have those

00:13:51,600 --> 00:13:56,000
we have to use custom objects there like

00:13:54,079 --> 00:13:57,600
if you would go to any kubernetes

00:13:56,000 --> 00:13:59,199
cluster which does not have rooks if

00:13:57,600 --> 00:14:02,399
installed

00:13:59,199 --> 00:14:02,880
you don't have this type available on

00:14:02,399 --> 00:14:05,600
your

00:14:02,880 --> 00:14:07,199
kubernetes cluster that's what the

00:14:05,600 --> 00:14:10,320
operator brings with it it's bringing

00:14:07,199 --> 00:14:11,760
its custom types for that and

00:14:10,320 --> 00:14:13,519
i mentioned parameters with like the

00:14:11,760 --> 00:14:17,839
wheels and such you know like it's

00:14:13,519 --> 00:14:19,440
um and a custom resist definition is

00:14:17,839 --> 00:14:21,760
basically nothing else like if

00:14:19,440 --> 00:14:23,680
as you think about maybe like a pot

00:14:21,760 --> 00:14:25,519
object like a party ammo

00:14:23,680 --> 00:14:27,160
it's in the end nothing different to

00:14:25,519 --> 00:14:31,440
that it's a

00:14:27,160 --> 00:14:32,639
specification where all parameters on

00:14:31,440 --> 00:14:35,519
how it should look

00:14:32,639 --> 00:14:37,519
like in case of a part like what image

00:14:35,519 --> 00:14:38,399
does it have like readiness liveness

00:14:37,519 --> 00:14:40,560
probes

00:14:38,399 --> 00:14:41,680
how many well if there are more than one

00:14:40,560 --> 00:14:43,360
container in it

00:14:41,680 --> 00:14:45,120
labels and all those things yeah so

00:14:43,360 --> 00:14:46,320
those are basically just parameters

00:14:45,120 --> 00:14:49,600
around it

00:14:46,320 --> 00:14:51,440
um for kubernetes to know

00:14:49,600 --> 00:14:53,839
what the whole thing will look like in

00:14:51,440 --> 00:14:56,160
the end for the whole part

00:14:53,839 --> 00:14:58,959
for self-class object is basically the

00:14:56,160 --> 00:15:01,680
same you have a list of parameters like

00:14:58,959 --> 00:15:02,480
uh for the storage fund like what nodes

00:15:01,680 --> 00:15:04,480
should it use

00:15:02,480 --> 00:15:06,480
should it use all nodes should it your

00:15:04,480 --> 00:15:08,560
all available devices

00:15:06,480 --> 00:15:10,399
uh is there like a device filter you

00:15:08,560 --> 00:15:13,600
want to set any like more

00:15:10,399 --> 00:15:15,040
configuration possibilities and you know

00:15:13,600 --> 00:15:16,639
more and more like i'm not going into

00:15:15,040 --> 00:15:19,279
each parameter here the point being is

00:15:16,639 --> 00:15:21,600
basically a big list of parameters

00:15:19,279 --> 00:15:22,480
which the operator will take and

00:15:21,600 --> 00:15:26,079
interpret

00:15:22,480 --> 00:15:29,120
and based on that begin creating and or

00:15:26,079 --> 00:15:31,839
modifying the existing rook cef cluster

00:15:29,120 --> 00:15:34,880
which is running

00:15:31,839 --> 00:15:37,040
and to be go a bit further into the part

00:15:34,880 --> 00:15:40,959
with like a parameters there

00:15:37,040 --> 00:15:43,440
for example you can specifically

00:15:40,959 --> 00:15:44,560
give a list of notes you want to use and

00:15:43,440 --> 00:15:47,920
in that part

00:15:44,560 --> 00:15:48,800
what devices even to use and that's the

00:15:47,920 --> 00:15:51,759
cool thing

00:15:48,800 --> 00:15:54,720
thanks to kubernetes there we can simply

00:15:51,759 --> 00:15:58,480
specify our custom object there is now

00:15:54,720 --> 00:16:01,759
a magic that we need to do there

00:15:58,480 --> 00:16:04,399
and it allows us to easily um well

00:16:01,759 --> 00:16:05,680
provide users with a safe cluster in

00:16:04,399 --> 00:16:09,680
kubernetes

00:16:05,680 --> 00:16:12,720
based on those parameters

00:16:09,680 --> 00:16:14,560
um for rook cipher especially there it's

00:16:12,720 --> 00:16:14,959
not just a ceph cluster object like

00:16:14,560 --> 00:16:17,680
there's

00:16:14,959 --> 00:16:20,880
more around in ceph as well already

00:16:17,680 --> 00:16:23,199
there's for example the saf block pro

00:16:20,880 --> 00:16:25,839
we have the api version it's not like

00:16:23,199 --> 00:16:27,360
version one or apps slash version one of

00:16:25,839 --> 00:16:29,120
these people that have run around with

00:16:27,360 --> 00:16:30,959
kubernetes already a bit

00:16:29,120 --> 00:16:32,720
the kind is not deployment or something

00:16:30,959 --> 00:16:34,639
it's have block pull that's our custom

00:16:32,720 --> 00:16:35,440
object that the rig operator is bringing

00:16:34,639 --> 00:16:37,759
into

00:16:35,440 --> 00:16:39,360
with the normal like metadata which just

00:16:37,759 --> 00:16:41,040
that's the name of the object it's the

00:16:39,360 --> 00:16:41,360
namespace the object should be created

00:16:41,040 --> 00:16:43,600
in

00:16:41,360 --> 00:16:45,360
and we have the specifications and in

00:16:43,600 --> 00:16:46,639
this case we define the specifications

00:16:45,360 --> 00:16:50,320
just to say well

00:16:46,639 --> 00:16:54,320
failure domain host replicated size free

00:16:50,320 --> 00:16:57,199
require safe replica size and so on um

00:16:54,320 --> 00:16:58,639
these are well those are safe specific

00:16:57,199 --> 00:17:02,160
parameters but

00:16:58,639 --> 00:17:04,959
in the end you know operator takes those

00:17:02,160 --> 00:17:06,240
it takes the specification works it out

00:17:04,959 --> 00:17:09,280
in terms to

00:17:06,240 --> 00:17:10,559
basically translate it to ceph if you

00:17:09,280 --> 00:17:12,559
will so

00:17:10,559 --> 00:17:14,959
and take care of that for you as the

00:17:12,559 --> 00:17:18,000
user

00:17:14,959 --> 00:17:20,959
um to build up from a story there

00:17:18,000 --> 00:17:22,959
basically we have a sev cluster object

00:17:20,959 --> 00:17:24,559
when we create it it will well attack

00:17:22,959 --> 00:17:26,799
will take a few minutes depending on how

00:17:24,559 --> 00:17:27,199
fast like pulling images and all those

00:17:26,799 --> 00:17:30,640
things

00:17:27,199 --> 00:17:33,120
are uh you have created a ceph cluster

00:17:30,640 --> 00:17:34,720
and we have also gone ahead created a

00:17:33,120 --> 00:17:37,760
set block pool

00:17:34,720 --> 00:17:40,480
object because that will instruct

00:17:37,760 --> 00:17:41,520
the operator to create a pool a storage

00:17:40,480 --> 00:17:45,280
pool

00:17:41,520 --> 00:17:47,520
basically in the cef cluster it just

00:17:45,280 --> 00:17:51,360
created

00:17:47,520 --> 00:17:51,360
so um

00:17:52,240 --> 00:17:56,080
that is the part where we should now

00:17:55,440 --> 00:17:58,880
look into

00:17:56,080 --> 00:18:01,280
how can we consume a search and i can

00:17:58,880 --> 00:18:04,320
tell you it's it's pretty simple it's

00:18:01,280 --> 00:18:04,799
all pretty easy integratable thanks to

00:18:04,320 --> 00:18:06,480
like

00:18:04,799 --> 00:18:07,840
with the customer system definitions and

00:18:06,480 --> 00:18:09,120
all but

00:18:07,840 --> 00:18:12,640
the good thing is we don't need

00:18:09,120 --> 00:18:15,120
customers custom things for everything

00:18:12,640 --> 00:18:16,880
um there's for example like storage

00:18:15,120 --> 00:18:20,320
class

00:18:16,880 --> 00:18:23,440
um the um it is an

00:18:20,320 --> 00:18:25,840
object of kubernetes like of the native

00:18:23,440 --> 00:18:26,960
api support like that of the storage

00:18:25,840 --> 00:18:30,000
apis

00:18:26,960 --> 00:18:31,840
and by default basically

00:18:30,000 --> 00:18:33,600
we specify a name for the search class

00:18:31,840 --> 00:18:34,000
we give it the name rooks of block we

00:18:33,600 --> 00:18:37,200
tell

00:18:34,000 --> 00:18:39,520
it's you know some special parameters

00:18:37,200 --> 00:18:41,679
some way like where to even look for

00:18:39,520 --> 00:18:43,760
who's the provisional storage and all

00:18:41,679 --> 00:18:45,919
like all this fancy stuff we don't need

00:18:43,760 --> 00:18:47,840
to consider also too much with that

00:18:45,919 --> 00:18:49,520
um but we pointed to the like to the

00:18:47,840 --> 00:18:51,280
right cluster which is the rook ceph

00:18:49,520 --> 00:18:53,360
cluster we just created

00:18:51,280 --> 00:18:54,400
and that it should use the pool replica

00:18:53,360 --> 00:18:57,600
pool if you remember

00:18:54,400 --> 00:19:00,400
we had created a saf block pool as a

00:18:57,600 --> 00:19:03,600
headed up as a yamal and it would use

00:19:00,400 --> 00:19:06,000
this pool then for the storage

00:19:03,600 --> 00:19:07,520
so thanks to the storage classes in

00:19:06,000 --> 00:19:10,880
kubernetes now the only thing

00:19:07,520 --> 00:19:12,160
ajsa or we need to do

00:19:10,880 --> 00:19:14,559
we could go ahead and create a

00:19:12,160 --> 00:19:17,360
persistent volume claim

00:19:14,559 --> 00:19:19,200
we create a persistent volume claim well

00:19:17,360 --> 00:19:20,880
we give it a cool name microlab is

00:19:19,200 --> 00:19:24,000
probably a well pretty cool name

00:19:20,880 --> 00:19:25,919
so we got this cover we tell

00:19:24,000 --> 00:19:28,320
the persistent volume claim which starts

00:19:25,919 --> 00:19:29,200
class name in our case it's the rook set

00:19:28,320 --> 00:19:30,880
block one

00:19:29,200 --> 00:19:32,480
we tell it what access means i'm not

00:19:30,880 --> 00:19:36,240
going too far into that

00:19:32,480 --> 00:19:39,280
it's basically um telling companies like

00:19:36,240 --> 00:19:41,919
what kind of storage it would need to uh

00:19:39,280 --> 00:19:42,799
look out for like for example block

00:19:41,919 --> 00:19:45,440
storage

00:19:42,799 --> 00:19:45,840
normally can only be used as read write

00:19:45,440 --> 00:19:48,559
one

00:19:45,840 --> 00:19:49,200
storage which basically means that the

00:19:48,559 --> 00:19:51,120
storage

00:19:49,200 --> 00:19:52,480
can only be mounted like this volume

00:19:51,120 --> 00:19:56,000
there that we get in the end

00:19:52,480 --> 00:19:58,480
can only be mounted once on one node

00:19:56,000 --> 00:19:59,360
like not once in the whole life cycle of

00:19:58,480 --> 00:20:01,600
the volume

00:19:59,360 --> 00:20:02,960
but meaning that if you have a pot

00:20:01,600 --> 00:20:06,000
running on node a

00:20:02,960 --> 00:20:09,679
and you start up a pot on a second part

00:20:06,000 --> 00:20:12,799
which also wants to to mount the same

00:20:09,679 --> 00:20:14,240
block volume like a same persistent

00:20:12,799 --> 00:20:17,520
volume claim

00:20:14,240 --> 00:20:19,520
basically there um

00:20:17,520 --> 00:20:21,200
it won't work unless it's well on the

00:20:19,520 --> 00:20:22,400
same note but you know it's those kind

00:20:21,200 --> 00:20:24,720
of edge scenarios

00:20:22,400 --> 00:20:25,840
still where it wouldn't it wouldn't work

00:20:24,720 --> 00:20:28,720
out

00:20:25,840 --> 00:20:29,679
um if it would be on different notes

00:20:28,720 --> 00:20:31,280
because the blocks

00:20:29,679 --> 00:20:32,720
block image normally can only be mounted

00:20:31,280 --> 00:20:34,880
on one server in

00:20:32,720 --> 00:20:35,840
read write mode so that's about that

00:20:34,880 --> 00:20:37,440
blur

00:20:35,840 --> 00:20:39,280
there's also other modes like read write

00:20:37,440 --> 00:20:42,720
many read uh

00:20:39,280 --> 00:20:44,480
read only many as well also but as it

00:20:42,720 --> 00:20:46,559
we're not going to concern ourselves too

00:20:44,480 --> 00:20:48,320
much with that right now

00:20:46,559 --> 00:20:50,480
we're going to set in a position right

00:20:48,320 --> 00:20:52,400
over at persistent volume claim also

00:20:50,480 --> 00:20:53,679
the resources we want in this case we

00:20:52,400 --> 00:20:58,000
basically request

00:20:53,679 --> 00:21:01,520
20 gigabytes of storage um

00:20:58,000 --> 00:21:04,480
and well after we have created one

00:21:01,520 --> 00:21:05,280
we can go ahead in our deployment we

00:21:04,480 --> 00:21:08,720
have well

00:21:05,280 --> 00:21:09,440
named it my cool app obviously and in

00:21:08,720 --> 00:21:12,400
the

00:21:09,440 --> 00:21:15,360
list of volumes we go ahead and specify

00:21:12,400 --> 00:21:18,240
our persistent volume claim

00:21:15,360 --> 00:21:20,080
there's well there's a few more tweaks

00:21:18,240 --> 00:21:21,919
you would want to make to the deployment

00:21:20,080 --> 00:21:24,000
that you have a flawless

00:21:21,919 --> 00:21:26,320
uh way of upgrading like you currently

00:21:24,000 --> 00:21:28,480
can only run this with a replica of one

00:21:26,320 --> 00:21:30,400
because if you would have the need to

00:21:28,480 --> 00:21:32,720
run an application

00:21:30,400 --> 00:21:33,840
where like each replica so each pot

00:21:32,720 --> 00:21:35,520
would have its own

00:21:33,840 --> 00:21:37,360
persistent volume claim it would be

00:21:35,520 --> 00:21:39,600
necessary because you know

00:21:37,360 --> 00:21:42,840
block storage can only be mounted once

00:21:39,600 --> 00:21:46,159
by one part basically

00:21:42,840 --> 00:21:47,600
um you would need to go ahead and use

00:21:46,159 --> 00:21:49,280
the stateful set

00:21:47,600 --> 00:21:50,799
so this is more just the demonstration

00:21:49,280 --> 00:21:53,039
purpose here purpose here

00:21:50,799 --> 00:21:54,000
this would this is how like the volumes

00:21:53,039 --> 00:21:55,840
entry would look

00:21:54,000 --> 00:21:57,200
and in the end you could simply in the

00:21:55,840 --> 00:21:59,679
container section

00:21:57,200 --> 00:22:00,480
and do the volume mounts on well the

00:21:59,679 --> 00:22:03,919
name data

00:22:00,480 --> 00:22:07,600
and say well mount path down there so um

00:22:03,919 --> 00:22:09,280
yeah so we have our

00:22:07,600 --> 00:22:10,799
application they're basically running we

00:22:09,280 --> 00:22:12,240
have one part and now we're going to

00:22:10,799 --> 00:22:15,120
dive into the demo

00:22:12,240 --> 00:22:15,679
okay diving into the demo now for first

00:22:15,120 --> 00:22:19,360
part

00:22:15,679 --> 00:22:21,520
for ceph operator we need to create

00:22:19,360 --> 00:22:23,200
the common.yaml all the objects which

00:22:21,520 --> 00:22:25,440
are in there in a kubernetes class so

00:22:23,200 --> 00:22:28,400
we'll simply do that by well

00:22:25,440 --> 00:22:29,679
and it will really create crds custom

00:22:28,400 --> 00:22:32,480
resist definitions

00:22:29,679 --> 00:22:34,240
rba cluster which includes cluster roles

00:22:32,480 --> 00:22:35,120
role binding service codes and all these

00:22:34,240 --> 00:22:37,679
things

00:22:35,120 --> 00:22:38,840
as next part we're going to create the

00:22:37,679 --> 00:22:41,760
operator

00:22:38,840 --> 00:22:43,919
deployment and the config of the

00:22:41,760 --> 00:22:46,640
operator

00:22:43,919 --> 00:22:47,360
after that we'll move on to the cluster

00:22:46,640 --> 00:22:49,200
level i'll

00:22:47,360 --> 00:22:50,640
show it in a second but just you know it

00:22:49,200 --> 00:22:51,280
takes a bit of time for everything to

00:22:50,640 --> 00:22:53,360
spin up

00:22:51,280 --> 00:22:56,240
so we'll go into that in a second we're

00:22:53,360 --> 00:22:56,240
going to create it

00:22:56,559 --> 00:23:01,360
so let's just do a quick um

00:23:01,600 --> 00:23:05,679
okay containers are already it's already

00:23:03,840 --> 00:23:06,080
creating so that's good the operator

00:23:05,679 --> 00:23:08,640
well

00:23:06,080 --> 00:23:10,320
it you know it just takes a bit in my c

00:23:08,640 --> 00:23:12,559
for the colostomy i think

00:23:10,320 --> 00:23:14,400
and let's take a look at the cluster

00:23:12,559 --> 00:23:18,000
yellow

00:23:14,400 --> 00:23:21,120
um big note here the cluster

00:23:18,000 --> 00:23:24,480
we are currently looking at is um

00:23:21,120 --> 00:23:26,799
it's a free node cluster you have to

00:23:24,480 --> 00:23:29,440
have at least three nodes if you tr

00:23:26,799 --> 00:23:31,440
if you like well want to try it out with

00:23:29,440 --> 00:23:34,559
the cluster. if you want to just play

00:23:31,440 --> 00:23:37,760
around in a network onenote cluster

00:23:34,559 --> 00:23:40,240
well please take a look at the

00:23:37,760 --> 00:23:42,320
um at the cluster cluster minus

00:23:40,240 --> 00:23:45,760
test.yaml for that

00:23:42,320 --> 00:23:49,520
and so let's dive

00:23:45,760 --> 00:23:51,760
right into that um

00:23:49,520 --> 00:23:53,360
so well you know we have a name name

00:23:51,760 --> 00:23:56,320
system all that again

00:23:53,360 --> 00:23:58,080
we have the specification which ceph

00:23:56,320 --> 00:24:00,480
version it will use

00:23:58,080 --> 00:24:01,760
with some additional stuff like data the

00:24:00,480 --> 00:24:03,679
host path

00:24:01,760 --> 00:24:05,600
i would recommend you to read up on like

00:24:03,679 --> 00:24:08,880
what each part here does

00:24:05,600 --> 00:24:12,880
in the documentation on rook.io

00:24:08,880 --> 00:24:14,400
um but you know as we had it there's a

00:24:12,880 --> 00:24:14,799
bunch of parameters which need to be

00:24:14,400 --> 00:24:16,840
said

00:24:14,799 --> 00:24:18,480
in a certain way most of them have

00:24:16,840 --> 00:24:20,000
defaults

00:24:18,480 --> 00:24:22,960
but you should be aware of what the

00:24:20,000 --> 00:24:24,799
defaults are especially when you would

00:24:22,960 --> 00:24:26,240
go ahead and run it in production at one

00:24:24,799 --> 00:24:29,600
point

00:24:26,240 --> 00:24:31,200
so just yeah well you know we have the

00:24:29,600 --> 00:24:34,480
whole

00:24:31,200 --> 00:24:37,679
the whole um structure of the self

00:24:34,480 --> 00:24:38,720
cluster object so let's just jump back

00:24:37,679 --> 00:24:42,240
and see how

00:24:38,720 --> 00:24:45,200
how's it looking okay we have a bunch of

00:24:42,240 --> 00:24:47,600
components already having spun up

00:24:45,200 --> 00:24:49,840
the operator in the background is

00:24:47,600 --> 00:24:53,279
creating all the components we need

00:24:49,840 --> 00:24:54,400
we have the mons spinning up they are a

00:24:53,279 --> 00:24:57,520
vital part of

00:24:54,400 --> 00:24:58,880
ceph and for production already as a

00:24:57,520 --> 00:25:00,880
side note here you should

00:24:58,880 --> 00:25:02,080
have at least three months if you run

00:25:00,880 --> 00:25:05,200
with less than three months

00:25:02,080 --> 00:25:07,440
you're not going to have a quorum

00:25:05,200 --> 00:25:09,120
for the seven months so keep that in

00:25:07,440 --> 00:25:10,880
mind but you know

00:25:09,120 --> 00:25:12,720
if you want to know learn more i would

00:25:10,880 --> 00:25:14,880
check recommend you check out the

00:25:12,720 --> 00:25:16,559
rook.io documentation and depending on

00:25:14,880 --> 00:25:17,760
what storage backend you want to run

00:25:16,559 --> 00:25:19,200
like in case of sev

00:25:17,760 --> 00:25:21,200
check out the theft documentation as

00:25:19,200 --> 00:25:23,600
well to read up on how the architecture

00:25:21,200 --> 00:25:29,360
of ceph is logging

00:25:23,600 --> 00:25:31,679
okay so we have the months now

00:25:29,360 --> 00:25:32,960
it is uh the operator has now started

00:25:31,679 --> 00:25:36,080
the so-called

00:25:32,960 --> 00:25:37,120
rook sap osd prepare parts they are jobs

00:25:36,080 --> 00:25:40,320
basically

00:25:37,120 --> 00:25:42,960
which are running on each node to um

00:25:40,320 --> 00:25:43,840
well create oh well not necessarily

00:25:42,960 --> 00:25:46,960
great but

00:25:43,840 --> 00:25:49,760
prepare uh disks in the server

00:25:46,960 --> 00:25:50,640
for osds so that's what they're doing

00:25:49,760 --> 00:25:53,919
and let me

00:25:50,640 --> 00:25:56,720
just refresh the output here

00:25:53,919 --> 00:25:58,640
it has already finished for two of the

00:25:56,720 --> 00:26:00,159
nodes we have for the master and for the

00:25:58,640 --> 00:26:03,039
node one here

00:26:00,159 --> 00:26:04,559
and we already have even we are it's

00:26:03,039 --> 00:26:07,600
already faster

00:26:04,559 --> 00:26:09,760
and then anticipated right now we

00:26:07,600 --> 00:26:11,440
already have the three osds

00:26:09,760 --> 00:26:13,120
there is this short explanation here

00:26:11,440 --> 00:26:15,760
there is these are the part

00:26:13,120 --> 00:26:16,640
which actually save the data to disk

00:26:15,760 --> 00:26:19,919
there

00:26:16,640 --> 00:26:23,200
now let's run another again to

00:26:19,919 --> 00:26:24,320
update the output one prepared job here

00:26:23,200 --> 00:26:26,720
is still running but

00:26:24,320 --> 00:26:28,080
we have ours these already it will take

00:26:26,720 --> 00:26:31,840
depending on you know

00:26:28,080 --> 00:26:34,240
uh what uh resources the node has a bit

00:26:31,840 --> 00:26:35,679
until everything is prepared on a node

00:26:34,240 --> 00:26:39,760
and as we can see

00:26:35,679 --> 00:26:42,640
we just got the next few osds

00:26:39,760 --> 00:26:44,000
you might be wondering what can i use as

00:26:42,640 --> 00:26:45,600
an asd

00:26:44,000 --> 00:26:48,640
you need to have either an empty

00:26:45,600 --> 00:26:52,080
partition sidenote i would recommend you

00:26:48,640 --> 00:26:52,880
format the disk as unformatted may seem

00:26:52,080 --> 00:26:56,000
weird but

00:26:52,880 --> 00:26:57,679
uh at least then for to talk about she

00:26:56,000 --> 00:26:59,120
parted here at listen to your part

00:26:57,679 --> 00:27:00,960
there's an option to say hey this is

00:26:59,120 --> 00:27:03,440
unformatted and

00:27:00,960 --> 00:27:05,120
in the k clusters i've been setting up

00:27:03,440 --> 00:27:08,159
uh when like

00:27:05,120 --> 00:27:11,039
even though the partition was empty

00:27:08,159 --> 00:27:13,679
and it didn't work after that it worked

00:27:11,039 --> 00:27:15,679
when i've set them to unformatted so

00:27:13,679 --> 00:27:17,360
um yeah just a quick tip here if you

00:27:15,679 --> 00:27:19,440
wanna if you have some trouble getting

00:27:17,360 --> 00:27:22,159
your partition and our disks recognized

00:27:19,440 --> 00:27:25,440
even for just the testing part

00:27:22,159 --> 00:27:26,559
okay so we have our saf cluster running

00:27:25,440 --> 00:27:30,240
now

00:27:26,559 --> 00:27:31,679
um let me jump ahead to the application

00:27:30,240 --> 00:27:34,559
deployment in a second

00:27:31,679 --> 00:27:35,760
okay so now for the application uh

00:27:34,559 --> 00:27:38,480
deployment

00:27:35,760 --> 00:27:40,960
first thing we still need to do is

00:27:38,480 --> 00:27:42,880
create a storage class and a saf block

00:27:40,960 --> 00:27:46,080
pool as we learned from previous uh

00:27:42,880 --> 00:27:49,679
previous slides we uh there's a

00:27:46,080 --> 00:27:52,159
pretty convenient example in a csi rbd

00:27:49,679 --> 00:27:54,080
folder called storage class yaml as you

00:27:52,159 --> 00:27:54,559
can see we just created a set block

00:27:54,080 --> 00:27:56,799
pearl

00:27:54,559 --> 00:27:58,159
called replica pool and a storage class

00:27:56,799 --> 00:28:02,320
so we got that now

00:27:58,159 --> 00:28:04,640
so if i run cube ctrl get storage class

00:28:02,320 --> 00:28:06,159
we'll see there we go we have a storage

00:28:04,640 --> 00:28:09,039
class now

00:28:06,159 --> 00:28:09,760
okay now let's deploy the application

00:28:09,039 --> 00:28:11,840
okay

00:28:09,760 --> 00:28:14,399
now after we have created the storage

00:28:11,840 --> 00:28:16,640
class and with that also self block pool

00:28:14,399 --> 00:28:18,720
we can just run cube ctrl create on our

00:28:16,640 --> 00:28:20,000
application manifests which are also in

00:28:18,720 --> 00:28:22,640
this case as they are

00:28:20,000 --> 00:28:24,240
deployment objects and a persistent

00:28:22,640 --> 00:28:27,600
volume claim object

00:28:24,240 --> 00:28:28,960
so i'm just gonna create the everything

00:28:27,600 --> 00:28:31,279
that's needed for that

00:28:28,960 --> 00:28:32,159
and we can go ahead we're gonna keep

00:28:31,279 --> 00:28:36,080
cuddle get

00:28:32,159 --> 00:28:36,880
part and get pvc minus w so we can watch

00:28:36,080 --> 00:28:40,799
the whole thing

00:28:36,880 --> 00:28:43,919
no we can't do that in a watch mode

00:28:40,799 --> 00:28:45,039
well let's just wait for the pots to be

00:28:43,919 --> 00:28:47,200
running

00:28:45,039 --> 00:28:50,880
and well there we have it if i go ahead

00:28:47,200 --> 00:28:54,159
and run cube ctl get pvc now

00:28:50,880 --> 00:28:55,360
here we go let me just zoom out a slight

00:28:54,159 --> 00:28:57,440
bit here

00:28:55,360 --> 00:29:00,080
we see we have two persistent volume

00:28:57,440 --> 00:29:02,080
claims which we created

00:29:00,080 --> 00:29:03,840
and both of them are bound so they have

00:29:02,080 --> 00:29:05,919
been created on backend and all and are

00:29:03,840 --> 00:29:07,440
provisioned and are now ready for use

00:29:05,919 --> 00:29:10,480
and as we have seen

00:29:07,440 --> 00:29:14,399
at the parts well they're ready

00:29:10,480 --> 00:29:17,440
and they're already used in the parts

00:29:14,399 --> 00:29:19,840
and well that's it from the demo with

00:29:17,440 --> 00:29:22,320
with ease i've been able to consume the

00:29:19,840 --> 00:29:24,880
search after we've created staff cluster

00:29:22,320 --> 00:29:26,000
uh remember you even a testing

00:29:24,880 --> 00:29:29,760
environment needs to have

00:29:26,000 --> 00:29:31,520
certain amount of resources like

00:29:29,760 --> 00:29:33,679
disks or something like empty partition

00:29:31,520 --> 00:29:37,039
or something um

00:29:33,679 --> 00:29:39,679
yeah thanks for that and

00:29:37,039 --> 00:29:40,799
let's continue all right alex thank you

00:29:39,679 --> 00:29:43,840
very much for that

00:29:40,799 --> 00:29:45,440
uh uh helpful demo there to showing us

00:29:43,840 --> 00:29:46,960
uh how some of the book project works

00:29:45,440 --> 00:29:49,520
with a little bit more hands-on

00:29:46,960 --> 00:29:50,240
experience there uh so now we can talk

00:29:49,520 --> 00:29:51,919
about um

00:29:50,240 --> 00:29:54,240
since brooke is a completely open source

00:29:51,919 --> 00:29:56,480
project your cncf project

00:29:54,240 --> 00:29:57,760
we have a pretty broad community now and

00:29:56,480 --> 00:29:59,840
there's a lot of different ways that you

00:29:57,760 --> 00:30:02,399
can get more involved and become more

00:29:59,840 --> 00:30:02,960
uh more involved in the community as a

00:30:02,399 --> 00:30:06,080
whole

00:30:02,960 --> 00:30:07,520
so the main site is rook.io that has

00:30:06,080 --> 00:30:09,440
some more explanation about the project

00:30:07,520 --> 00:30:11,279
and all of our documentation user guide

00:30:09,440 --> 00:30:12,799
quick starts etc is all there so it's a

00:30:11,279 --> 00:30:14,720
great place to go if you want to

00:30:12,799 --> 00:30:16,399
start using the rook project and then

00:30:14,720 --> 00:30:18,799
we're super active on slack

00:30:16,399 --> 00:30:20,240
as well um there's the link right there

00:30:18,799 --> 00:30:21,360
if you have questions you can come and

00:30:20,240 --> 00:30:24,080
find the right channel

00:30:21,360 --> 00:30:26,159
and uh we're a very welcoming bunch so

00:30:24,080 --> 00:30:28,399
you come talk to us there

00:30:26,159 --> 00:30:29,919
you know we have over you know almost

00:30:28,399 --> 00:30:31,039
300 contributors now we're always

00:30:29,919 --> 00:30:34,240
looking for more so

00:30:31,039 --> 00:30:36,720
on github.com that is the

00:30:34,240 --> 00:30:37,440
repo and you can submit issues pull

00:30:36,720 --> 00:30:40,720
requests

00:30:37,440 --> 00:30:42,320
have discussions there um and then uh

00:30:40,720 --> 00:30:44,000
of course we're also on twitter and we

00:30:42,320 --> 00:30:45,919
have community meetings uh

00:30:44,000 --> 00:30:47,600
every other tuesday uh the specific

00:30:45,919 --> 00:30:50,799
links for that is on the uh

00:30:47,600 --> 00:30:51,360
read me in the book repo so yeah thanks

00:30:50,799 --> 00:30:53,919
a lot for

00:30:51,360 --> 00:30:55,039
listening to us today and we can i'll

00:30:53,919 --> 00:30:57,679
just about wrap it up

00:30:55,039 --> 00:30:58,720
thanks jared so yeah if you want to get

00:30:57,679 --> 00:31:01,440
involved

00:30:58,720 --> 00:31:03,440
follow the links check out our slack if

00:31:01,440 --> 00:31:05,120
you have any questions there

00:31:03,440 --> 00:31:06,640
especially for coupon wafer channel

00:31:05,120 --> 00:31:09,679
called conferences

00:31:06,640 --> 00:31:10,240
um well feel free to ask questions and

00:31:09,679 --> 00:31:11,600
yeah

00:31:10,240 --> 00:31:14,760
thanks for listening everyone have a

00:31:11,600 --> 00:31:17,760
good day and well see you next time

00:31:14,760 --> 00:31:17,760

YouTube URL: https://www.youtube.com/watch?v=dA29dIK6g5o


