Title: Enabling Multi-user Machine Learning Workflows for Kubeflow Pipelines - Yannis Zarkadas & Yuan Gong
Publication date: 2020-08-27
Playlist: KubeCon + CloudNativeCon Europe 2020 - Virtual
Description: 
	Don’t miss out! Join us at our upcoming events: EnvoyCon Virtual on October 15 and KubeCon + CloudNativeCon North America 2020 Virtual from November 17-20. Learn more at https://kubecon.io. The conferences feature presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects.  

Enabling Multi-user Machine Learning Workflows for Kubeflow Pipelines - Yannis Zarkadas, Arrikto & Yuan Gong, Google 

Kubeflow is an open source machine learning platform built on Kubernetes. Every service in Kubeflow is implemented either as a Custom Resource Definition (CRD) (e.g., TensorFlow Job) or as a standalone service (e.g., Kubeflow Pipelines).  As enterprises start to adopt Kubeflow, the need for access control, authentication, and authorization is emerging. Kubernetes CRDs come with their own auth story, but what about Services with their own API and database, like Kubeflow Pipelines? In this talk, we explore how we enabled multi-user workflows for Kubeflow Pipelines, in a Kubernetes-native way.  We present how we combined open-source, cloud-native technologies to design and implement a flexible, Kubernetes-native solution for services with their own API and database. The talk will include a live demo.

https://sched.co/Zeok
Captions: 
	00:00:00,000 --> 00:00:04,240
hi everyone and welcome today we will be

00:00:02,399 --> 00:00:06,160
talking about how we enable multi-user

00:00:04,240 --> 00:00:09,280
workflows for kubeflow pipelines

00:00:06,160 --> 00:00:11,599
let's get started first of all

00:00:09,280 --> 00:00:13,200
let us introduce ourselves my name is

00:00:11,599 --> 00:00:14,960
janis and i'm a software engineer at

00:00:13,200 --> 00:00:16,960
arikto working on kubeflow

00:00:14,960 --> 00:00:19,039
i am presenting together with yuan going

00:00:16,960 --> 00:00:20,240
from google who works on kubeflow

00:00:19,039 --> 00:00:22,080
pipelines

00:00:20,240 --> 00:00:24,000
together we worked on designing and

00:00:22,080 --> 00:00:26,800
delivering multi-user support for

00:00:24,000 --> 00:00:28,960
kubeflow pipelines

00:00:26,800 --> 00:00:30,000
in this talk we will explore how

00:00:28,960 --> 00:00:32,000
multiple users can

00:00:30,000 --> 00:00:34,239
work together on kepler pipelines in a

00:00:32,000 --> 00:00:36,079
secure isolated manner

00:00:34,239 --> 00:00:38,000
this completes the kubeflow pipelines

00:00:36,079 --> 00:00:40,000
experience which allows you to

00:00:38,000 --> 00:00:42,239
simplify user onboarding with the

00:00:40,000 --> 00:00:44,079
kubeflow pipeline's intuitive ux

00:00:42,239 --> 00:00:46,160
accelerate pipeline development by

00:00:44,079 --> 00:00:48,559
writing pipelines as python code

00:00:46,160 --> 00:00:50,399
and collaborate in a secure and isolated

00:00:48,559 --> 00:00:53,120
manner

00:00:50,399 --> 00:00:54,399
so let's start at the beginning what is

00:00:53,120 --> 00:00:56,320
kubeflow

00:00:54,399 --> 00:00:58,160
kubeflow is a machine learning platform

00:00:56,320 --> 00:01:00,160
built on top of kubernetes

00:00:58,160 --> 00:01:01,520
dedicated to making deployments of

00:01:00,160 --> 00:01:05,119
machine learning workflows

00:01:01,520 --> 00:01:08,159
simple portable and scalable

00:01:05,119 --> 00:01:09,760
now then what's keyflow pipelines kiplo

00:01:08,159 --> 00:01:11,840
pipelines is a cornerstone

00:01:09,760 --> 00:01:13,520
of the kubeflow platform it provides a

00:01:11,840 --> 00:01:15,119
powerful platform to run machine

00:01:13,520 --> 00:01:17,040
learning pipelines on

00:01:15,119 --> 00:01:19,439
it comes with a powerful ui and a

00:01:17,040 --> 00:01:20,240
diomatic python sdk to define pipelines

00:01:19,439 --> 00:01:22,720
as code

00:01:20,240 --> 00:01:25,040
rich visualizations linux tracking and

00:01:22,720 --> 00:01:25,040
more

00:01:25,600 --> 00:01:30,479
so as we said q flow pipelines are a

00:01:28,640 --> 00:01:31,439
very important component of the kubeflow

00:01:30,479 --> 00:01:33,600
platform

00:01:31,439 --> 00:01:35,040
however when admins try to bring

00:01:33,600 --> 00:01:36,720
pipelines to their users

00:01:35,040 --> 00:01:38,320
they quickly stumble upon the problem

00:01:36,720 --> 00:01:40,479
that kubeflow pipelines has

00:01:38,320 --> 00:01:41,759
no isolation authentication or

00:01:40,479 --> 00:01:43,520
authorization

00:01:41,759 --> 00:01:45,600
all pipelines are running in one

00:01:43,520 --> 00:01:47,119
namespace one search environment

00:01:45,600 --> 00:01:49,439
which means that secret and data

00:01:47,119 --> 00:01:51,840
isolation is impossible

00:01:49,439 --> 00:01:53,840
how are we going to isolate authenticate

00:01:51,840 --> 00:01:55,280
and authorize to the kubeflow pipelines

00:01:53,840 --> 00:01:57,520
api

00:01:55,280 --> 00:01:58,719
kubeflow pipelines is not the kubernetes

00:01:57,520 --> 00:02:01,439
native api

00:01:58,719 --> 00:02:02,799
it is not based on crds or an aggregated

00:02:01,439 --> 00:02:04,960
api server

00:02:02,799 --> 00:02:07,040
instead keyflow pipelines has its own

00:02:04,960 --> 00:02:10,720
api server and database

00:02:07,040 --> 00:02:13,440
mysql and object store in the initial

00:02:10,720 --> 00:02:15,520
kubeflow pipeline's design there is no

00:02:13,440 --> 00:02:16,800
mention of isolation authentication or

00:02:15,520 --> 00:02:18,879
authorization

00:02:16,800 --> 00:02:20,640
so how can we extend the initial design

00:02:18,879 --> 00:02:24,640
to enable multiple users to work

00:02:20,640 --> 00:02:24,640
together in a secure isolated manner

00:02:24,800 --> 00:02:29,040
to design how to isolate authenticate

00:02:27,040 --> 00:02:29,840
and authorize for the kubeflow pipelines

00:02:29,040 --> 00:02:31,360
api

00:02:29,840 --> 00:02:34,000
we first turn our attention to the

00:02:31,360 --> 00:02:37,599
kubernetes api for inspiration

00:02:34,000 --> 00:02:39,519
for isolation kubernetes uses namespaces

00:02:37,599 --> 00:02:41,200
almost every resource lives in a

00:02:39,519 --> 00:02:43,599
namespace

00:02:41,200 --> 00:02:45,440
for authentication the kubernetes api

00:02:43,599 --> 00:02:48,400
server supports multiple methods

00:02:45,440 --> 00:02:50,480
like authenticating user's poi dc that

00:02:48,400 --> 00:02:52,560
is open id connect

00:02:50,480 --> 00:02:54,239
authenticating machine accounts via

00:02:52,560 --> 00:02:56,879
service account tokens

00:02:54,239 --> 00:02:59,760
or getting the user identity from http

00:02:56,879 --> 00:03:02,239
headers set by a trusted proxy

00:02:59,760 --> 00:03:04,560
finally for authorization kubernetes

00:03:02,239 --> 00:03:06,000
uses role-based access control over our

00:03:04,560 --> 00:03:08,400
back for short

00:03:06,000 --> 00:03:11,280
permissions are defined as roles and

00:03:08,400 --> 00:03:13,360
given to subjects via role bindings

00:03:11,280 --> 00:03:15,760
now let's see how we can apply those

00:03:13,360 --> 00:03:18,000
principles for designing isolation

00:03:15,760 --> 00:03:21,280
authentication and authorization for the

00:03:18,000 --> 00:03:21,280
kubeflow pipelines api

00:03:21,519 --> 00:03:26,959
first of all let's talk about isolation

00:03:24,879 --> 00:03:28,959
ql pipeline's initial design has no

00:03:26,959 --> 00:03:31,280
isolation primitive whatsoever

00:03:28,959 --> 00:03:33,040
all pipeline runs are shared and

00:03:31,280 --> 00:03:35,280
everyone can access them

00:03:33,040 --> 00:03:38,080
we introduce the namespace as an

00:03:35,280 --> 00:03:39,920
isolation primitive same as kubernetes

00:03:38,080 --> 00:03:41,680
in the queue flow pipelines data model

00:03:39,920 --> 00:03:43,560
there are pipeline definitions

00:03:41,680 --> 00:03:46,720
and pipeline runs which are

00:03:43,560 --> 00:03:49,120
instantiations of those definitions

00:03:46,720 --> 00:03:50,959
all pipeline runs reside inside of an

00:03:49,120 --> 00:03:53,439
experiment

00:03:50,959 --> 00:03:55,599
now to extend the cubesat pipelines data

00:03:53,439 --> 00:03:57,439
model with an isolation primitive

00:03:55,599 --> 00:03:58,799
we add a namespace attribute to

00:03:57,439 --> 00:04:00,959
experiments

00:03:58,799 --> 00:04:03,280
pipeline runs further an experiment by

00:04:00,959 --> 00:04:05,680
looking up at five minutes in the story

00:04:03,280 --> 00:04:07,920
pipeline runs find their namespace by

00:04:05,680 --> 00:04:10,480
looking up their experiment

00:04:07,920 --> 00:04:12,560
in addition the experiment api endpoints

00:04:10,480 --> 00:04:16,000
are extended

00:04:12,560 --> 00:04:19,680
all api calls must now specify namespace

00:04:16,000 --> 00:04:19,680
same as kubernetes apis

00:04:21,359 --> 00:04:27,120
then let's talk about authentication

00:04:24,720 --> 00:04:29,520
as we saw the kubernetes api server

00:04:27,120 --> 00:04:31,520
supports various ways of authentication

00:04:29,520 --> 00:04:33,360
we want to support that in the pipelines

00:04:31,520 --> 00:04:35,520
api server as well

00:04:33,360 --> 00:04:37,280
we want to be able to authenticate users

00:04:35,520 --> 00:04:39,120
as well as service accounts

00:04:37,280 --> 00:04:40,720
so we designed the following ways of

00:04:39,120 --> 00:04:42,800
authentication

00:04:40,720 --> 00:04:43,919
first of all a user can authenticate

00:04:42,800 --> 00:04:45,680
with oidc

00:04:43,919 --> 00:04:47,680
at the history gateway provided by

00:04:45,680 --> 00:04:49,120
kubeflow and then authenticate to the

00:04:47,680 --> 00:04:53,120
pipelines api server

00:04:49,120 --> 00:04:55,919
via http headers here the steel gateway

00:04:53,120 --> 00:04:57,280
acts as a trusted authentication proxy

00:04:55,919 --> 00:05:00,400
for machine authentication

00:04:57,280 --> 00:05:01,919
htmpls is a good solution but it can't

00:05:00,400 --> 00:05:03,120
easily be used with all kinds of

00:05:01,919 --> 00:05:05,039
workflows

00:05:03,120 --> 00:05:07,360
for example around the completion

00:05:05,039 --> 00:05:09,360
workloads like argo workflows and

00:05:07,360 --> 00:05:11,759
kubernetes jobs don't fully support

00:05:09,360 --> 00:05:13,840
running with an issue sidecar

00:05:11,759 --> 00:05:15,199
for that reason we also designed a third

00:05:13,840 --> 00:05:16,639
way of authentication

00:05:15,199 --> 00:05:19,199
authentication with the service account

00:05:16,639 --> 00:05:20,639
token now be careful

00:05:19,199 --> 00:05:22,639
we use service account tokens with a

00:05:20,639 --> 00:05:24,080
custom audience issued by the token

00:05:22,639 --> 00:05:26,080
request api

00:05:24,080 --> 00:05:27,759
these tokens are only usable at the

00:05:26,080 --> 00:05:30,639
pipeline's api server

00:05:27,759 --> 00:05:33,680
and not the kubernetes api server and as

00:05:30,639 --> 00:05:33,680
job video will tell you

00:05:33,759 --> 00:05:38,080
handing a service account token an

00:05:36,160 --> 00:05:38,960
unbound service account token to

00:05:38,080 --> 00:05:41,360
anything other

00:05:38,960 --> 00:05:44,240
than the kubernetes api server is a very

00:05:41,360 --> 00:05:44,240
very bad idea

00:05:45,520 --> 00:05:49,440
now we saw what we did about isolation

00:05:48,240 --> 00:05:51,680
authentication

00:05:49,440 --> 00:05:53,759
now let's talk about authorization

00:05:51,680 --> 00:05:54,639
authorization is all about answering the

00:05:53,759 --> 00:05:58,080
question of

00:05:54,639 --> 00:05:59,199
can user do action on a resource in

00:05:58,080 --> 00:06:02,639
namespace

00:05:59,199 --> 00:06:05,199
for example cansara list pods

00:06:02,639 --> 00:06:06,000
in namespace kubeflow in the first

00:06:05,199 --> 00:06:07,600
implementation

00:06:06,000 --> 00:06:09,600
keep flow pipelines are using the queue

00:06:07,600 --> 00:06:12,080
to access management service or k-form

00:06:09,600 --> 00:06:14,720
for short to authorize requests

00:06:12,080 --> 00:06:17,039
kfam is introducing a simple view edit

00:06:14,720 --> 00:06:19,039
admin access control list abstraction

00:06:17,039 --> 00:06:20,080
for all actions on top of kubernetes are

00:06:19,039 --> 00:06:21,759
back

00:06:20,080 --> 00:06:23,759
as you can see from the permission table

00:06:21,759 --> 00:06:24,800
below there are only three levels of

00:06:23,759 --> 00:06:26,960
access available

00:06:24,800 --> 00:06:28,400
so an admin can specify a more

00:06:26,960 --> 00:06:30,639
fine-grained policy

00:06:28,400 --> 00:06:32,840
like a user can view and create pipeline

00:06:30,639 --> 00:06:35,440
definitions but not start pipeline

00:06:32,840 --> 00:06:37,360
rounds this method is deprecated

00:06:35,440 --> 00:06:40,400
and will be superseded by our bug and

00:06:37,360 --> 00:06:40,400
subject tax review

00:06:40,560 --> 00:06:43,680
after talking about the current way of

00:06:42,319 --> 00:06:45,919
doing authorization

00:06:43,680 --> 00:06:47,759
let's also see where we want to go the

00:06:45,919 --> 00:06:49,759
endpoint for authorization is to map

00:06:47,759 --> 00:06:51,520
every kubeflow pipeline's api endpoint

00:06:49,759 --> 00:06:54,800
to enter back permission

00:06:51,520 --> 00:06:56,560
for example we get the api's v1beta1

00:06:54,800 --> 00:07:00,160
runs id

00:06:56,560 --> 00:07:02,960
api call to get runs and so on

00:07:00,160 --> 00:07:04,960
the information about permissions lives

00:07:02,960 --> 00:07:06,720
in kubernetes roles and role bindings

00:07:04,960 --> 00:07:07,840
just like with native kubernetes

00:07:06,720 --> 00:07:09,840
resources

00:07:07,840 --> 00:07:11,840
then permissions are checked using a

00:07:09,840 --> 00:07:15,120
subject access review poll

00:07:11,840 --> 00:07:18,000
now be careful and make sure to note

00:07:15,120 --> 00:07:19,840
that these resources are not crds but we

00:07:18,000 --> 00:07:21,360
can use the subject access review api to

00:07:19,840 --> 00:07:23,280
authorize them anyway

00:07:21,360 --> 00:07:25,680
so we are essentially using kubernetes

00:07:23,280 --> 00:07:28,840
as an authorization system

00:07:25,680 --> 00:07:31,840
an authorization database and enable

00:07:28,840 --> 00:07:33,759
admins to assign fine grain permissions

00:07:31,840 --> 00:07:34,720
in the same way they do for kubernetes

00:07:33,759 --> 00:07:38,240
native apis

00:07:34,720 --> 00:07:38,560
with roles and role bindings this method

00:07:38,240 --> 00:07:42,800
of

00:07:38,560 --> 00:07:42,800
authorization will be implemented by

00:07:42,840 --> 00:07:45,840
arito

00:07:48,160 --> 00:07:51,360
so we designed authentication

00:07:50,080 --> 00:07:53,680
authorization

00:07:51,360 --> 00:07:54,879
and isolation for the kepler pipelines

00:07:53,680 --> 00:07:57,120
service

00:07:54,879 --> 00:07:58,560
isolation is achieved using namespaces

00:07:57,120 --> 00:08:00,720
same as kubernetes

00:07:58,560 --> 00:08:02,080
for authentication we support multiple

00:08:00,720 --> 00:08:04,960
ways for both human

00:08:02,080 --> 00:08:06,560
and machine accounts for authorization

00:08:04,960 --> 00:08:08,479
we want to move to using native

00:08:06,560 --> 00:08:10,479
kubernetes or back permissions and

00:08:08,479 --> 00:08:12,879
subject tax review

00:08:10,479 --> 00:08:13,759
now let's see how it all comes together

00:08:12,879 --> 00:08:18,800
a user

00:08:13,759 --> 00:08:21,280
logs in at the http gateway

00:08:18,800 --> 00:08:23,840
and is authenticated then the easter

00:08:21,280 --> 00:08:27,680
gateway will proxy the request

00:08:23,840 --> 00:08:29,520
with the user's identity in http headers

00:08:27,680 --> 00:08:31,440
when inside the workload with no human

00:08:29,520 --> 00:08:32,080
interaction for example a jupiter

00:08:31,440 --> 00:08:34,320
notebook

00:08:32,080 --> 00:08:35,760
we can authenticate in two ways we can

00:08:34,320 --> 00:08:37,360
authenticate with a service account

00:08:35,760 --> 00:08:40,320
token with a custom audience

00:08:37,360 --> 00:08:42,479
issued with a token request api call

00:08:40,320 --> 00:08:45,360
after issuing the token

00:08:42,479 --> 00:08:45,920
we send it via the authorization better

00:08:45,360 --> 00:08:48,560
header

00:08:45,920 --> 00:08:50,000
in http requests to the pipelines api

00:08:48,560 --> 00:08:52,160
server

00:08:50,000 --> 00:08:54,560
finally we can authenticate via

00:08:52,160 --> 00:08:57,040
istiomtls if that's available for a

00:08:54,560 --> 00:08:57,040
workload

00:08:58,399 --> 00:09:04,000
finally the pipeline cpi server

00:09:01,519 --> 00:09:05,839
now that it knows who the user is and

00:09:04,000 --> 00:09:08,560
what the user wants to do

00:09:05,839 --> 00:09:08,880
will ask the simple question of can user

00:09:08,560 --> 00:09:12,080
do

00:09:08,880 --> 00:09:14,560
action on the resource in namespace

00:09:12,080 --> 00:09:16,560
and issue a subject access review code

00:09:14,560 --> 00:09:18,640
to authorize the request

00:09:16,560 --> 00:09:20,320
depending on the answer of the

00:09:18,640 --> 00:09:22,080
authorization decision

00:09:20,320 --> 00:09:25,839
the pipelines api server will then

00:09:22,080 --> 00:09:28,160
execute an action on its database

00:09:25,839 --> 00:09:28,880
so all in all we explore kubernetes

00:09:28,160 --> 00:09:30,560
design for

00:09:28,880 --> 00:09:32,880
isolation authentication and

00:09:30,560 --> 00:09:34,880
authorization and use it as a guide for

00:09:32,880 --> 00:09:37,680
the kubeflow pipelines api

00:09:34,880 --> 00:09:38,720
we isolate using namespaces authenticate

00:09:37,680 --> 00:09:41,440
using oidc

00:09:38,720 --> 00:09:43,600
service account tokens or s2mtls and

00:09:41,440 --> 00:09:45,360
authorized with kubernetes are back

00:09:43,600 --> 00:09:46,640
for the next part of the talk i will

00:09:45,360 --> 00:09:48,839
hand it over to yuan

00:09:46,640 --> 00:09:50,080
who will be talking about isolating

00:09:48,839 --> 00:09:52,480
visualizations

00:09:50,080 --> 00:09:54,160
networking implementation considerations

00:09:52,480 --> 00:09:57,200
and more

00:09:54,160 --> 00:09:59,680
so thanks janice this is rian at google

00:09:57,200 --> 00:10:02,320
cloud working on kubeflow pipelines

00:09:59,680 --> 00:10:03,760
janice just introduced three ways people

00:10:02,320 --> 00:10:05,920
may authenticate

00:10:03,760 --> 00:10:07,680
but for the current phase we have only

00:10:05,920 --> 00:10:11,200
designed and implemented

00:10:07,680 --> 00:10:12,320
using authentication info as a http

00:10:11,200 --> 00:10:14,880
header

00:10:12,320 --> 00:10:18,320
now that the kfp api server takes a

00:10:14,880 --> 00:10:21,120
plain text header for user identity

00:10:18,320 --> 00:10:21,839
it sounds dangerous right so how do we

00:10:21,120 --> 00:10:24,880
make sure

00:10:21,839 --> 00:10:27,200
clients cannot pretend to be others by

00:10:24,880 --> 00:10:30,240
faking a request

00:10:27,200 --> 00:10:31,519
this is where s2 mutual tls comes into

00:10:30,240 --> 00:10:33,279
the play

00:10:31,519 --> 00:10:36,480
you probably know that so here's a

00:10:33,279 --> 00:10:39,920
really simplified explanation

00:10:36,480 --> 00:10:43,120
first we have a client talking to a

00:10:39,920 --> 00:10:46,480
server through plain text http

00:10:43,120 --> 00:10:49,360
after turning on mutual tls the request

00:10:46,480 --> 00:10:50,800
is proxied through an istio sidecar in

00:10:49,360 --> 00:10:52,959
the client pod

00:10:50,800 --> 00:10:54,720
then the client sidecar knows how to

00:10:52,959 --> 00:10:55,839
secure the connection to the server

00:10:54,720 --> 00:10:58,240
sidecar

00:10:55,839 --> 00:10:58,959
and the server sidecar talks to server

00:10:58,240 --> 00:11:02,320
container

00:10:58,959 --> 00:11:04,079
in http again in this way

00:11:02,320 --> 00:11:06,079
the client container and server

00:11:04,079 --> 00:11:09,120
container are still talking

00:11:06,079 --> 00:11:10,160
in plain text http but the connection

00:11:09,120 --> 00:11:14,800
between pods

00:11:10,160 --> 00:11:18,160
are secured and by this mutual tls

00:11:14,800 --> 00:11:18,720
amazing isn't that so in addition to

00:11:18,160 --> 00:11:21,920
that

00:11:18,720 --> 00:11:24,640
the server-side car now knows identity

00:11:21,920 --> 00:11:27,120
of clients talking to it therefore we

00:11:24,640 --> 00:11:27,760
can configure some authorization rules

00:11:27,120 --> 00:11:31,040
like

00:11:27,760 --> 00:11:35,120
only allow requests from this namespace

00:11:31,040 --> 00:11:35,120
or like these service accounts

00:11:35,680 --> 00:11:41,600
so with these hto features

00:11:39,440 --> 00:11:43,200
we are able to set up a set of security

00:11:41,600 --> 00:11:45,920
rules to

00:11:43,200 --> 00:11:47,839
first allow traffic from instill gateway

00:11:45,920 --> 00:11:51,040
to kfb ui

00:11:47,839 --> 00:11:53,680
allow traffic among all kfp components

00:11:51,040 --> 00:11:55,040
allow traffic from kfp to dependent

00:11:53,680 --> 00:11:58,399
services

00:11:55,040 --> 00:11:58,959
and the most important one being denying

00:11:58,399 --> 00:12:02,639
traffic

00:11:58,959 --> 00:12:07,680
from non-kft sources to kf internal

00:12:02,639 --> 00:12:10,959
components so finally with all of this

00:12:07,680 --> 00:12:13,200
when kfp api server receives a request

00:12:10,959 --> 00:12:14,000
we can be sure it's coming from the

00:12:13,200 --> 00:12:17,040
trusted

00:12:14,000 --> 00:12:17,040
istio gateway

00:12:17,760 --> 00:12:21,519
so it took us a lot of efforts just to

00:12:20,639 --> 00:12:24,959
securely

00:12:21,519 --> 00:12:27,360
pass the user identity to our api server

00:12:24,959 --> 00:12:28,959
that's unfortunately just the beginning

00:12:27,360 --> 00:12:31,519
of this story

00:12:28,959 --> 00:12:33,760
the api server also needs to support

00:12:31,519 --> 00:12:35,839
multi-user separation

00:12:33,760 --> 00:12:38,880
think about the generic problem of

00:12:35,839 --> 00:12:40,880
adding user separation to a service

00:12:38,880 --> 00:12:42,079
there are typically two options to do

00:12:40,880 --> 00:12:44,800
this

00:12:42,079 --> 00:12:46,480
the centralized option is to build a

00:12:44,800 --> 00:12:48,160
service that take

00:12:46,480 --> 00:12:49,680
for example here namespace as a

00:12:48,160 --> 00:12:53,279
primitive concept

00:12:49,680 --> 00:12:55,360
and enforces authorization rules on it

00:12:53,279 --> 00:12:56,639
it takes more efforts to implement

00:12:55,360 --> 00:12:58,800
because we have to do

00:12:56,639 --> 00:12:59,839
intrusive logic changes throughout the

00:12:58,800 --> 00:13:02,240
application

00:12:59,839 --> 00:13:03,440
basically we need to add a namespace

00:13:02,240 --> 00:13:05,920
argument

00:13:03,440 --> 00:13:07,680
authorization and application logic to

00:13:05,920 --> 00:13:10,160
every api method

00:13:07,680 --> 00:13:11,440
and don't forget db schema migration

00:13:10,160 --> 00:13:13,839
tool

00:13:11,440 --> 00:13:15,279
on the other hand the decentralized

00:13:13,839 --> 00:13:17,680
option is to start

00:13:15,279 --> 00:13:18,480
independent instances of the original

00:13:17,680 --> 00:13:21,760
service

00:13:18,480 --> 00:13:25,440
for each user we then we need a gateway

00:13:21,760 --> 00:13:27,920
in front of it and we need a controller

00:13:25,440 --> 00:13:29,920
that auto sets up the services in new

00:13:27,920 --> 00:13:32,480
username spaces

00:13:29,920 --> 00:13:33,200
this option is non-intrusive we're just

00:13:32,480 --> 00:13:36,240
composing

00:13:33,200 --> 00:13:38,160
existing application instances in a way

00:13:36,240 --> 00:13:41,519
that they look like a single service

00:13:38,160 --> 00:13:41,519
with multi-user support

00:13:42,000 --> 00:13:47,279
so for kfb api server we decided to

00:13:45,120 --> 00:13:48,560
build a centralized one that takes

00:13:47,279 --> 00:13:52,079
namespace

00:13:48,560 --> 00:13:53,120
as previously described so a single

00:13:52,079 --> 00:13:56,959
instance means

00:13:53,120 --> 00:13:59,279
lower operational and computational cost

00:13:56,959 --> 00:14:01,120
this is important especially because

00:13:59,279 --> 00:14:04,320
usually a platform team

00:14:01,120 --> 00:14:07,279
can handle kfp systems operations like

00:14:04,320 --> 00:14:10,320
upgrade or backup so data scientist

00:14:07,279 --> 00:14:12,959
teams can focus on their own work

00:14:10,320 --> 00:14:15,199
so other reasons including reserving the

00:14:12,959 --> 00:14:16,320
possibility of building cross namespace

00:14:15,199 --> 00:14:20,079
features like

00:14:16,320 --> 00:14:23,199
sharing and this comes with a cost

00:14:20,079 --> 00:14:24,480
but it's a cost only for us we did a lot

00:14:23,199 --> 00:14:27,680
of code changes through

00:14:24,480 --> 00:14:29,040
all apis made the namespace parameter

00:14:27,680 --> 00:14:33,040
primitive concept

00:14:29,040 --> 00:14:33,040
and added authorizations in place

00:14:33,760 --> 00:14:38,959
also remember kfp provides end-to-end

00:14:36,320 --> 00:14:40,800
reusable machine learning workflow

00:14:38,959 --> 00:14:44,399
so it looks like this seeing

00:14:40,800 --> 00:14:45,040
visualization right inside kfpui we also

00:14:44,399 --> 00:14:48,160
provide

00:14:45,040 --> 00:14:49,279
tensorboard self-service instances and

00:14:48,160 --> 00:14:53,120
artifact preview

00:14:49,279 --> 00:14:54,959
right inside ui however users may decide

00:14:53,120 --> 00:14:57,760
to store their artifacts

00:14:54,959 --> 00:14:58,720
in external storages like google cloud

00:14:57,760 --> 00:15:01,839
storage

00:14:58,720 --> 00:15:04,480
so cafe ui server needs to fetch these

00:15:01,839 --> 00:15:06,160
artifacts for them in order to show them

00:15:04,480 --> 00:15:10,959
on the on the ui

00:15:06,160 --> 00:15:13,440
so how do we separate kfe ui permissions

00:15:10,959 --> 00:15:15,760
for this case we decided to take the

00:15:13,440 --> 00:15:18,399
decentralized option here

00:15:15,760 --> 00:15:20,800
because these artifacts tensorboard and

00:15:18,399 --> 00:15:24,079
visualization services are stateless

00:15:20,800 --> 00:15:27,920
lightweight clients so there's not much

00:15:24,079 --> 00:15:30,240
operational cost anyway also users are

00:15:27,920 --> 00:15:31,759
free to configure their own instances

00:15:30,240 --> 00:15:35,920
with correct permissions

00:15:31,759 --> 00:15:38,240
in this way additionally

00:15:35,920 --> 00:15:39,759
one contributor is adding volume support

00:15:38,240 --> 00:15:42,800
for data passing

00:15:39,759 --> 00:15:45,040
a decentralized factory servers can

00:15:42,800 --> 00:15:45,920
even support mounting persistence

00:15:45,040 --> 00:15:47,839
volumes

00:15:45,920 --> 00:15:49,279
because they are also in user name

00:15:47,839 --> 00:15:52,800
spaces

00:15:49,279 --> 00:15:54,720
so comparing to kfp api server we took a

00:15:52,800 --> 00:15:57,519
different approach

00:15:54,720 --> 00:15:59,440
for artifact servers because they have

00:15:57,519 --> 00:16:02,399
different characteristics

00:15:59,440 --> 00:16:03,360
and tradeoffs that in the end both

00:16:02,399 --> 00:16:06,839
different options

00:16:03,360 --> 00:16:08,079
make sense for different things we are

00:16:06,839 --> 00:16:09,839
considering

00:16:08,079 --> 00:16:11,519
so it's interesting that we got the

00:16:09,839 --> 00:16:12,639
experience of building multi-user

00:16:11,519 --> 00:16:17,279
support with both

00:16:12,639 --> 00:16:17,279
options for different components in kfp

00:16:19,040 --> 00:16:22,480
there are still some missing pieces for

00:16:20,800 --> 00:16:25,360
this design

00:16:22,480 --> 00:16:26,079
first how do we integrate other two

00:16:25,360 --> 00:16:29,120
types of

00:16:26,079 --> 00:16:32,160
authentication methods with in-cluster

00:16:29,120 --> 00:16:34,480
traffic authorization

00:16:32,160 --> 00:16:36,959
they can allow other workloads in the

00:16:34,480 --> 00:16:38,800
cluster to authenticate to kft api

00:16:36,959 --> 00:16:41,759
server

00:16:38,800 --> 00:16:42,720
second pipeline definitions are still

00:16:41,759 --> 00:16:45,199
shared

00:16:42,720 --> 00:16:46,639
that basically means code pipeline code

00:16:45,199 --> 00:16:48,800
is shared

00:16:46,639 --> 00:16:51,680
so this is okay for some organizations

00:16:48,800 --> 00:16:54,320
but not others

00:16:51,680 --> 00:16:55,680
then menu object store and machine

00:16:54,320 --> 00:16:59,040
learning metadata

00:16:55,680 --> 00:17:01,519
db are dependencies of kfp they don't

00:16:59,040 --> 00:17:04,559
support separation themselves

00:17:01,519 --> 00:17:08,319
so it's still an open question how kfp

00:17:04,559 --> 00:17:08,319
can support separation for them

00:17:09,360 --> 00:17:13,120
so after discussing all about the design

00:17:12,319 --> 00:17:14,959
let me share

00:17:13,120 --> 00:17:17,199
interesting things i learned when

00:17:14,959 --> 00:17:19,600
implementing this feature

00:17:17,199 --> 00:17:20,959
first on background i was learning still

00:17:19,600 --> 00:17:23,760
from the beginning

00:17:20,959 --> 00:17:24,400
through this so i hope these experiences

00:17:23,760 --> 00:17:27,919
can

00:17:24,400 --> 00:17:31,440
help someone who's listening to and

00:17:27,919 --> 00:17:34,000
disclaimer i was working with st 1.1

00:17:31,440 --> 00:17:34,799
which was a fairly old version kubeflow

00:17:34,000 --> 00:17:36,720
was using

00:17:34,799 --> 00:17:39,280
it's likely some of these have been

00:17:36,720 --> 00:17:42,799
improved without my notice

00:17:39,280 --> 00:17:46,559
okay so let's start lessons i learned

00:17:42,799 --> 00:17:50,480
the hard way

00:17:46,559 --> 00:17:52,880
uh before using any istio features

00:17:50,480 --> 00:17:55,039
clients and servers need to have istio

00:17:52,880 --> 00:17:57,760
sidecars injected

00:17:55,039 --> 00:17:58,720
that became my immediate blocker right

00:17:57,760 --> 00:18:01,280
away

00:17:58,720 --> 00:18:03,600
remember kubeflow is a platform of

00:18:01,280 --> 00:18:05,600
machine learning applications on cloud

00:18:03,600 --> 00:18:06,960
there are a lot of applications other

00:18:05,600 --> 00:18:09,679
than kubeflow pipelines

00:18:06,960 --> 00:18:11,520
in the same control plane namespace

00:18:09,679 --> 00:18:12,880
pipelines was actually the first

00:18:11,520 --> 00:18:15,280
applications

00:18:12,880 --> 00:18:16,240
to require is to security in this

00:18:15,280 --> 00:18:19,600
namespace

00:18:16,240 --> 00:18:22,880
so i had to turn that on turn

00:18:19,600 --> 00:18:25,600
it to sidecar injection on

00:18:22,880 --> 00:18:27,120
um so there are several things that can

00:18:25,600 --> 00:18:30,720
configure it

00:18:27,120 --> 00:18:33,120
there's a cluster-scoped config map

00:18:30,720 --> 00:18:34,480
that changes whether parts are injected

00:18:33,120 --> 00:18:37,440
by default

00:18:34,480 --> 00:18:38,559
there's also a namespace label that is

00:18:37,440 --> 00:18:40,840
required before

00:18:38,559 --> 00:18:42,000
any auto injection can happen in the

00:18:40,840 --> 00:18:44,160
namespace

00:18:42,000 --> 00:18:45,600
of course there's also a pod level

00:18:44,160 --> 00:18:49,440
annotation that works for

00:18:45,600 --> 00:18:52,320
just the parts so in order to

00:18:49,440 --> 00:18:53,919
turn on istio sidecar injection what i

00:18:52,320 --> 00:18:57,039
wanted was that

00:18:53,919 --> 00:18:58,240
all pods in the shared name place should

00:18:57,039 --> 00:19:01,520
default to not

00:18:58,240 --> 00:19:03,679
inject while the kfp parts can use pod

00:19:01,520 --> 00:19:07,600
level annotations to turn on

00:19:03,679 --> 00:19:10,720
injection but that's actually not

00:19:07,600 --> 00:19:13,600
feasible because the default policy

00:19:10,720 --> 00:19:16,080
is a cluster scope configuration uh

00:19:13,600 --> 00:19:18,720
while other namespaces in kubeflow have

00:19:16,080 --> 00:19:20,160
already been depending on that behavior

00:19:18,720 --> 00:19:22,400
uh it would be a

00:19:20,160 --> 00:19:23,360
bigger problem if i wanted to change the

00:19:22,400 --> 00:19:26,640
cluster scope

00:19:23,360 --> 00:19:27,440
default value so in the end i had to add

00:19:26,640 --> 00:19:30,320
the disable

00:19:27,440 --> 00:19:32,160
injection annotation to every other part

00:19:30,320 --> 00:19:35,840
in the shared namespace

00:19:32,160 --> 00:19:37,440
with a really huge pull request

00:19:35,840 --> 00:19:40,320
and got some really hard time

00:19:37,440 --> 00:19:43,679
troubleshooting all the pre-summit tests

00:19:40,320 --> 00:19:44,400
but it was necessary and it was a great

00:19:43,679 --> 00:19:46,640
step

00:19:44,400 --> 00:19:48,000
for the entire qfloor community to move

00:19:46,640 --> 00:19:53,840
towards

00:19:48,000 --> 00:19:53,840
integrating more issue security features

00:19:55,679 --> 00:20:02,400
so when gradually migrating to istu

00:19:59,679 --> 00:20:04,240
at first i was tempted to first set up

00:20:02,400 --> 00:20:07,440
some authorization rules

00:20:04,240 --> 00:20:10,240
without turning on mutual tls

00:20:07,440 --> 00:20:12,799
um because who knows the documentation

00:20:10,240 --> 00:20:15,679
looks complex for mutual trs

00:20:12,799 --> 00:20:16,960
and so i i thought probably i could skip

00:20:15,679 --> 00:20:19,360
it

00:20:16,960 --> 00:20:21,600
but please be careful that wouldn't work

00:20:19,360 --> 00:20:24,320
for many authorization rules

00:20:21,600 --> 00:20:25,360
because a rule that refers to even only

00:20:24,320 --> 00:20:29,120
name spaces

00:20:25,360 --> 00:20:30,640
requires mutual tls it still doesn't

00:20:29,120 --> 00:20:33,840
magically knows

00:20:30,640 --> 00:20:36,799
the namespace of a request

00:20:33,840 --> 00:20:38,960
mutual tls is on these two side cards

00:20:36,799 --> 00:20:41,760
mutually authenticate each other

00:20:38,960 --> 00:20:42,640
so they know each other's identity for

00:20:41,760 --> 00:20:46,240
example

00:20:42,640 --> 00:20:48,720
service account a in namespace b

00:20:46,240 --> 00:20:50,640
so that's why it still can authorize

00:20:48,720 --> 00:20:53,039
requests by namespace

00:20:50,640 --> 00:20:53,679
to put it in another way this is

00:20:53,039 --> 00:20:55,919
actually

00:20:53,679 --> 00:20:57,120
um listen carefully this is actually a

00:20:55,919 --> 00:20:59,840
live takeaway

00:20:57,120 --> 00:21:00,480
so before giving anyone money don't

00:20:59,840 --> 00:21:03,120
forget

00:21:00,480 --> 00:21:04,000
authentication you need to ask them

00:21:03,120 --> 00:21:07,039
prove

00:21:04,000 --> 00:21:09,120
who they are first this is as important

00:21:07,039 --> 00:21:12,559
as authorization

00:21:09,120 --> 00:21:13,520
so these were just showcases of the hard

00:21:12,559 --> 00:21:17,120
problems that

00:21:13,520 --> 00:21:18,559
took me on still learner really a few

00:21:17,120 --> 00:21:21,280
days to figure out

00:21:18,559 --> 00:21:21,280
troubleshooting

00:21:23,679 --> 00:21:30,559
so my takeaways are do not skip

00:21:27,520 --> 00:21:31,440
the basics really understanding is two

00:21:30,559 --> 00:21:34,720
concepts

00:21:31,440 --> 00:21:36,720
save more time later and

00:21:34,720 --> 00:21:38,320
it's good to learn troubleshooting

00:21:36,720 --> 00:21:40,320
techniques for istio system

00:21:38,320 --> 00:21:41,840
end to end um there's a great

00:21:40,320 --> 00:21:44,640
documentation for that

00:21:41,840 --> 00:21:46,960
but from my experience most

00:21:44,640 --> 00:21:47,679
authorization problems can be solved

00:21:46,960 --> 00:21:49,919
with just

00:21:47,679 --> 00:21:50,960
one section in the huge troubleshooting

00:21:49,919 --> 00:21:54,159
doc

00:21:50,960 --> 00:21:56,240
that's the ensuring proxies enforced

00:21:54,159 --> 00:21:58,640
policies correctly section

00:21:56,240 --> 00:21:59,280
it tells you how to enable debugging

00:21:58,640 --> 00:22:03,120
logging

00:21:59,280 --> 00:22:05,440
um for a site card then you can observe

00:22:03,120 --> 00:22:06,320
what information is still parsed from a

00:22:05,440 --> 00:22:12,320
request

00:22:06,320 --> 00:22:15,679
and whether it was denied

00:22:12,320 --> 00:22:18,080
so at the end remember that this

00:22:15,679 --> 00:22:19,280
couldn't happen without these amazing

00:22:18,080 --> 00:22:22,080
people

00:22:19,280 --> 00:22:23,440
we all worked on the design together

00:22:22,080 --> 00:22:27,200
while ning

00:22:23,440 --> 00:22:30,559
chen and i at google cloud implemented

00:22:27,200 --> 00:22:31,760
current features thank you let's proceed

00:22:30,559 --> 00:22:34,559
with our demo

00:22:31,760 --> 00:22:35,360
in this demo we will see two kubeflow

00:22:34,559 --> 00:22:37,600
users

00:22:35,360 --> 00:22:39,360
working on the same kubeflow pipelines

00:22:37,600 --> 00:22:41,679
installation

00:22:39,360 --> 00:22:43,120
or orpheus and yuri dies are two users

00:22:41,679 --> 00:22:44,720
of kubeflow

00:22:43,120 --> 00:22:46,640
who are working on the same kubeflow

00:22:44,720 --> 00:22:46,960
pipelines installation but as you will

00:22:46,640 --> 00:22:49,600
see

00:22:46,960 --> 00:22:52,240
the resources are isolated let's see

00:22:49,600 --> 00:22:52,240
what happens

00:22:53,280 --> 00:22:57,919
first of all orpheus will log into

00:22:55,360 --> 00:22:57,919
kubeflow

00:23:02,559 --> 00:23:06,640
when orthos logs in he will be greeted

00:23:04,640 --> 00:23:08,480
by the kubeflow central dashboard

00:23:06,640 --> 00:23:12,000
where he will navigate to the notebooks

00:23:08,480 --> 00:23:15,520
page and start a new notebook server

00:23:12,000 --> 00:23:22,400
here orpheus is using the codelab

00:23:15,520 --> 00:23:24,960
tutorial the titanic codelab tutorial

00:23:22,400 --> 00:23:26,799
orthos will also select the allow access

00:23:24,960 --> 00:23:28,159
to crypto pipelines and allow access to

00:23:26,799 --> 00:23:30,720
raw configurations

00:23:28,159 --> 00:23:31,360
which add specific service account

00:23:30,720 --> 00:23:33,520
tokens

00:23:31,360 --> 00:23:34,960
to the pod in order to access the

00:23:33,520 --> 00:23:38,240
pipelines api server

00:23:34,960 --> 00:23:39,200
and the rok api server when the notebook

00:23:38,240 --> 00:23:42,400
server is ready

00:23:39,200 --> 00:23:44,080
orfes will connect to it and open the

00:23:42,400 --> 00:23:46,640
jupyter notebook he has prepared

00:23:44,080 --> 00:23:46,640
beforehand

00:23:46,880 --> 00:23:51,440
now in order to convert the jupiter

00:23:50,159 --> 00:23:53,919
notebook to

00:23:51,440 --> 00:23:56,320
a kubeflow pipeline orphans will be

00:23:53,919 --> 00:23:59,520
using the kale tool

00:23:56,320 --> 00:24:02,240
with the kill tool you can just tag your

00:23:59,520 --> 00:24:03,039
notebook cells and with a click of a

00:24:02,240 --> 00:24:05,279
button

00:24:03,039 --> 00:24:08,640
gail will parse your jupiter notebook

00:24:05,279 --> 00:24:11,279
and convert it into kubeflow pipeline

00:24:08,640 --> 00:24:12,559
as we can see here kale converts the

00:24:11,279 --> 00:24:15,039
notebook

00:24:12,559 --> 00:24:16,320
submits the pipeline to the pipelines

00:24:15,039 --> 00:24:18,400
api server

00:24:16,320 --> 00:24:20,000
and will finally present orpheus with a

00:24:18,400 --> 00:24:22,640
link so he can track

00:24:20,000 --> 00:24:22,640
the progress

00:24:27,440 --> 00:24:32,559
orfus visit visits that link and here he

00:24:31,039 --> 00:24:35,679
can track the progress

00:24:32,559 --> 00:24:35,679
of its of his run

00:24:41,679 --> 00:24:51,440
now let's go to the other user

00:24:47,840 --> 00:25:01,840
yuridise also goes to the kubflow page

00:24:51,440 --> 00:25:01,840
and logs in

00:25:05,919 --> 00:25:11,679
after that yuri dies will list all

00:25:08,960 --> 00:25:13,840
pipeline runs

00:25:11,679 --> 00:25:14,880
and as you can see she cannot see the

00:25:13,840 --> 00:25:17,360
runs

00:25:14,880 --> 00:25:20,559
which or face hers have started these

00:25:17,360 --> 00:25:22,559
runs are in namespace cuteplay orpheus

00:25:20,559 --> 00:25:24,480
while she is working in namespace you

00:25:22,559 --> 00:25:26,960
play yuridize

00:25:24,480 --> 00:25:28,880
when she tries to visit the link for one

00:25:26,960 --> 00:25:30,400
of our faces runs

00:25:28,880 --> 00:25:33,279
she gets an error because it's not

00:25:30,400 --> 00:25:33,279
allowed to do that

00:25:38,559 --> 00:25:42,080
and when going to the experiments page

00:25:41,360 --> 00:25:45,360
you can see

00:25:42,080 --> 00:25:47,600
that she cannot see or faces a titanic

00:25:45,360 --> 00:25:50,799
experiment as well

00:25:47,600 --> 00:25:51,360
to find it to prove that we can list the

00:25:50,799 --> 00:25:54,640
pods

00:25:51,360 --> 00:25:57,679
for the namespace of our fails

00:25:54,640 --> 00:25:58,159
called cube flower fails and see that

00:25:57,679 --> 00:26:01,039
all

00:25:58,159 --> 00:26:03,120
the around pods are there while in

00:26:01,039 --> 00:26:07,440
kubeflow uridize

00:26:03,120 --> 00:26:11,600
no pods exist and this is how we isolate

00:26:07,440 --> 00:26:11,600

YouTube URL: https://www.youtube.com/watch?v=U8yWOKOhzes


