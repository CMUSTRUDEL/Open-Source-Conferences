Title: Building the Cloud Native Telco with Network Service Mesh - Ivana Atanasova & Radoslav Dimitrov
Publication date: 2020-08-27
Playlist: KubeCon + CloudNativeCon Europe 2020 - Virtual
Description: 
	Don’t miss out! Join us at our upcoming events: EnvoyCon Virtual on October 15 and KubeCon + CloudNativeCon North America 2020 Virtual from November 17-20. Learn more at https://kubecon.io. The conferences feature presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects.  

Building the Cloud Native Telco with Network Service Mesh - Ivana Atanasova & Radoslav Dimitrov, VMware 

Nowadays, the rapid technology development, significant increase of the number of connected devices and overall generated traffic, are challenging the networking solutions to evolve fast. Those solutions would hardly meet the higher demands for scalability and resiliency without adopting a cloud-native approach. Therefore, network service providers, like ISPs and Telco operators, are at the point of looking for a way to adopt the new cloud-native paradigm for their sophisticated network demands. Network Service Mesh is a CNCF project that offers a potential solution. In this talk we are going to introduce the approach Network Service Mesh is using to solve complicated L2/L3 challenges in Kubernetes and provide an example of building real cloud-native network topology using the tools provided by the NSM project. We are also going to show a demo of that topology implementation with NSM.

https://sched.co/ZepE
Captions: 
	00:00:00,080 --> 00:00:04,400
hey welcome everybody and thank you for

00:00:02,639 --> 00:00:06,640
joining this virtual session

00:00:04,400 --> 00:00:08,240
my name is rodusov dimitrov and i'm here

00:00:06,640 --> 00:00:10,480
with ivana tonassova

00:00:08,240 --> 00:00:12,559
and we're both part of vmware's open

00:00:10,480 --> 00:00:14,240
source technology center

00:00:12,559 --> 00:00:17,680
today we're going to talk about a

00:00:14,240 --> 00:00:20,960
project called network service mesh

00:00:17,680 --> 00:00:21,760
hello looking for a good point to start

00:00:20,960 --> 00:00:23,519
from

00:00:21,760 --> 00:00:26,560
let's talk about the technology

00:00:23,519 --> 00:00:29,119
evolution through the years

00:00:26,560 --> 00:00:30,160
first we had those monolithic

00:00:29,119 --> 00:00:33,520
applications

00:00:30,160 --> 00:00:36,800
ring on bare metal machines

00:00:33,520 --> 00:00:39,520
then the vmwave came out and

00:00:36,800 --> 00:00:41,120
we started migrating our work walls to

00:00:39,520 --> 00:00:43,360
virtual machines

00:00:41,120 --> 00:00:45,120
we did that for benefits like reduced

00:00:43,360 --> 00:00:48,079
operational costs

00:00:45,120 --> 00:00:48,800
faster provisioning improved efficiency

00:00:48,079 --> 00:00:52,239
and much

00:00:48,800 --> 00:00:55,360
more now it's all about

00:00:52,239 --> 00:00:58,480
containers and microservices

00:00:55,360 --> 00:01:00,320
here projects like docker and kubernetes

00:00:58,480 --> 00:01:01,840
are becoming the standard for such

00:01:00,320 --> 00:01:04,799
systems

00:01:01,840 --> 00:01:05,519
of course this maps perfectly in use

00:01:04,799 --> 00:01:07,680
cases

00:01:05,519 --> 00:01:09,439
that allow rapid and fast adoption of

00:01:07,680 --> 00:01:11,840
new technologies

00:01:09,439 --> 00:01:15,280
but let's see how this looks like

00:01:11,840 --> 00:01:15,280
through the eyes of a talk

00:01:15,920 --> 00:01:21,040
so apparently tokus are moving a bit

00:01:17,920 --> 00:01:23,040
slower but that's not always bad

00:01:21,040 --> 00:01:24,799
due to their nature they prefer to use

00:01:23,040 --> 00:01:27,260
only well-established technologies

00:01:24,799 --> 00:01:28,640
in their systems so for example

00:01:27,260 --> 00:01:30,799
[Music]

00:01:28,640 --> 00:01:32,640
this is how a typical telco system

00:01:30,799 --> 00:01:34,799
evolved through the years

00:01:32,640 --> 00:01:36,479
initially temple consisted of lots of

00:01:34,799 --> 00:01:38,000
physical boxes

00:01:36,479 --> 00:01:39,759
each and everyone implementing a

00:01:38,000 --> 00:01:41,520
specific network function within that

00:01:39,759 --> 00:01:42,960
system

00:01:41,520 --> 00:01:45,360
then they decided to adopt

00:01:42,960 --> 00:01:48,880
virtualization so all those physical

00:01:45,360 --> 00:01:50,960
boxes were migrated to virtual machines

00:01:48,880 --> 00:01:54,240
this introduced the concepts called

00:01:50,960 --> 00:01:55,920
virtual network functions or vnfs

00:01:54,240 --> 00:01:57,600
and it pretty much changed the way

00:01:55,920 --> 00:01:58,640
networking was done for the last couple

00:01:57,600 --> 00:02:02,719
of decades

00:01:58,640 --> 00:02:05,360
and it is known as the first wave of nv

00:02:02,719 --> 00:02:06,399
now decors are looking again at the

00:02:05,360 --> 00:02:08,160
enterprise

00:02:06,399 --> 00:02:10,479
to leverage the benefits of the cloud

00:02:08,160 --> 00:02:12,400
native world and for example adopt

00:02:10,479 --> 00:02:14,160
technologies like kubernetes and docker

00:02:12,400 --> 00:02:15,920
in their systems

00:02:14,160 --> 00:02:19,120
this introduces a new concept called

00:02:15,920 --> 00:02:20,879
cloud native network functions or cnfs

00:02:19,120 --> 00:02:24,000
at some point the end goal would be to

00:02:20,879 --> 00:02:26,080
have a mixed setup of network functions

00:02:24,000 --> 00:02:28,080
meaning that bare metal machines virtual

00:02:26,080 --> 00:02:31,360
machines and containers

00:02:28,080 --> 00:02:31,360
live as a single entity

00:02:31,519 --> 00:02:37,680
network service mesh is a project that

00:02:33,680 --> 00:02:39,920
aims to be part of that transition

00:02:37,680 --> 00:02:41,200
let's talk about what is a network

00:02:39,920 --> 00:02:44,400
service

00:02:41,200 --> 00:02:46,640
imagine there is an application and that

00:02:44,400 --> 00:02:49,519
it runs in the public cloud

00:02:46,640 --> 00:02:51,680
it needs to connect to another cloud or

00:02:49,519 --> 00:02:54,000
to a corporate internet

00:02:51,680 --> 00:02:55,760
in order to consume some custom service

00:02:54,000 --> 00:02:59,200
that is exposed

00:02:55,760 --> 00:03:02,159
and this opens a problem because

00:02:59,200 --> 00:03:04,879
usually the application takes care of

00:03:02,159 --> 00:03:07,120
implementing the connection logic

00:03:04,879 --> 00:03:08,239
and the app doesn't actually want to

00:03:07,120 --> 00:03:12,080
know about that

00:03:08,239 --> 00:03:15,360
why for example what if the connection

00:03:12,080 --> 00:03:18,239
changes and what if we have multiple

00:03:15,360 --> 00:03:19,760
applications in that case we would need

00:03:18,239 --> 00:03:21,680
to update each of that

00:03:19,760 --> 00:03:23,280
of them in order to apply those

00:03:21,680 --> 00:03:25,920
connection changes

00:03:23,280 --> 00:03:26,560
and we need to do that every time when

00:03:25,920 --> 00:03:29,519
there is

00:03:26,560 --> 00:03:31,280
such change we can agree that this is

00:03:29,519 --> 00:03:34,560
not very efficient

00:03:31,280 --> 00:03:36,720
so what we can do instead we can offer

00:03:34,560 --> 00:03:39,840
that to a network service

00:03:36,720 --> 00:03:40,400
that provides such functionality in this

00:03:39,840 --> 00:03:44,080
case

00:03:40,400 --> 00:03:45,120
we have clients that requests a network

00:03:44,080 --> 00:03:47,360
service

00:03:45,120 --> 00:03:48,799
we have endpoints that implement a

00:03:47,360 --> 00:03:51,200
network service

00:03:48,799 --> 00:03:53,439
and the communication between them

00:03:51,200 --> 00:03:54,640
happens through wires that are payable

00:03:53,439 --> 00:03:57,840
agnostic

00:03:54,640 --> 00:04:01,840
all these components form the concept of

00:03:57,840 --> 00:04:01,840
network service mesh

00:04:02,400 --> 00:04:07,439
so what is network service mesh it is an

00:04:05,360 --> 00:04:09,200
infrastructure layer for managing layer

00:04:07,439 --> 00:04:10,560
2 and layer 3 service to service

00:04:09,200 --> 00:04:12,879
communication

00:04:10,560 --> 00:04:14,799
it provides on-demand and negotiated

00:04:12,879 --> 00:04:18,160
point-to-point connections

00:04:14,799 --> 00:04:19,759
and it exposes a grpc api through which

00:04:18,160 --> 00:04:21,120
you can publish and consume network

00:04:19,759 --> 00:04:22,800
services

00:04:21,120 --> 00:04:24,479
and finally the great thing is that all

00:04:22,800 --> 00:04:25,360
that happens without any changes to

00:04:24,479 --> 00:04:28,960
kubernetes

00:04:25,360 --> 00:04:30,960
or the underlying cni network

00:04:28,960 --> 00:04:33,520
let's see how we can describe the

00:04:30,960 --> 00:04:34,240
previous example of a network service in

00:04:33,520 --> 00:04:37,440
a simple

00:04:34,240 --> 00:04:40,800
yaml file we need to specify

00:04:37,440 --> 00:04:44,240
a payload type for example an ip

00:04:40,800 --> 00:04:46,639
we need source and destination selection

00:04:44,240 --> 00:04:47,919
in our example the client was connecting

00:04:46,639 --> 00:04:50,960
to a firewall

00:04:47,919 --> 00:04:52,320
and then through the vpn gateway so in

00:04:50,960 --> 00:04:54,080
our yaml file

00:04:52,320 --> 00:04:56,560
the default match is going to the

00:04:54,080 --> 00:04:58,000
firewall and then it goes through gvpn

00:04:56,560 --> 00:05:00,400
gateway

00:04:58,000 --> 00:05:02,400
this way of service definition makes it

00:05:00,400 --> 00:05:05,520
possible to chain multiple

00:05:02,400 --> 00:05:06,400
clients or endpoints and to create the

00:05:05,520 --> 00:05:09,360
so-called

00:05:06,400 --> 00:05:10,000
service composition this allows us to

00:05:09,360 --> 00:05:15,039
describe

00:05:10,000 --> 00:05:15,039
to the technology that serves our needs

00:05:16,240 --> 00:05:20,560
how this example looks like in typical

00:05:19,120 --> 00:05:23,360
kubernetes deployment

00:05:20,560 --> 00:05:25,280
we have kubernetes we have network

00:05:23,360 --> 00:05:27,919
service mesh deployed on top

00:05:25,280 --> 00:05:30,720
and we have three parts to rank one

00:05:27,919 --> 00:05:33,759
client and two end points

00:05:30,720 --> 00:05:36,560
what happens first the endpoints

00:05:33,759 --> 00:05:37,680
announce themselves to network service

00:05:36,560 --> 00:05:40,080
mesh

00:05:37,680 --> 00:05:40,960
then the client requests a network

00:05:40,080 --> 00:05:44,000
service

00:05:40,960 --> 00:05:46,320
from network service mesh finally

00:05:44,000 --> 00:05:48,000
any same takes care of creating the

00:05:46,320 --> 00:05:51,520
necessary connections

00:05:48,000 --> 00:05:52,479
it injects network interfaces to all the

00:05:51,520 --> 00:05:54,639
pots

00:05:52,479 --> 00:05:55,600
and it creates a communication to know

00:05:54,639 --> 00:05:58,800
between them

00:05:55,600 --> 00:06:00,639
and this creates the connection a really

00:05:58,800 --> 00:06:02,800
great thing here is that all this

00:06:00,639 --> 00:06:04,160
happens without any changes to the

00:06:02,800 --> 00:06:06,639
underlying cni

00:06:04,160 --> 00:06:08,479
the cni is great enough so why it

00:06:06,639 --> 00:06:11,759
changed

00:06:08,479 --> 00:06:13,919
now let's zoom a little and see how

00:06:11,759 --> 00:06:16,479
network service mesh works in more

00:06:13,919 --> 00:06:16,479
details

00:06:17,919 --> 00:06:22,160
so how it works nsm consists of two main

00:06:21,280 --> 00:06:25,360
building blocks

00:06:22,160 --> 00:06:27,440
it has a manager and a forwarding plane

00:06:25,360 --> 00:06:29,520
the two live on every node but have

00:06:27,440 --> 00:06:32,400
different responsibilities

00:06:29,520 --> 00:06:35,199
we also use the case api as a registry

00:06:32,400 --> 00:06:37,039
for our network services

00:06:35,199 --> 00:06:39,680
the manager is responsible for

00:06:37,039 --> 00:06:41,360
negotiating the connection details

00:06:39,680 --> 00:06:43,600
and to make sure that the job will be

00:06:41,360 --> 00:06:45,759
done and everything is okay

00:06:43,600 --> 00:06:47,360
once we have set that details then we

00:06:45,759 --> 00:06:48,319
need someone to actually do the work

00:06:47,360 --> 00:06:50,479
right

00:06:48,319 --> 00:06:52,080
well that someone is the forwarding

00:06:50,479 --> 00:06:53,840
plane

00:06:52,080 --> 00:06:56,319
now let's see how a connection request

00:06:53,840 --> 00:06:57,919
looks like

00:06:56,319 --> 00:07:01,440
we start by deploying our network

00:06:57,919 --> 00:07:03,599
service via the yaml file from before

00:07:01,440 --> 00:07:04,800
once our endpoint is started it

00:07:03,599 --> 00:07:07,759
announces itself

00:07:04,800 --> 00:07:10,639
to its local manager that then saves

00:07:07,759 --> 00:07:12,639
that information inside the registry

00:07:10,639 --> 00:07:15,759
on the other side we have a client that

00:07:12,639 --> 00:07:18,880
wants to consume our network service

00:07:15,759 --> 00:07:21,199
it requests it from its local manager

00:07:18,880 --> 00:07:22,319
that seeks for information about that

00:07:21,199 --> 00:07:25,199
network service

00:07:22,319 --> 00:07:26,880
inside the registry once it finds out

00:07:25,199 --> 00:07:28,800
which is the manager responsible for

00:07:26,880 --> 00:07:31,120
that network service

00:07:28,800 --> 00:07:33,440
the two majors start to negotiate the

00:07:31,120 --> 00:07:36,080
connection details

00:07:33,440 --> 00:07:37,199
once this is completed they fit that

00:07:36,080 --> 00:07:40,720
information down

00:07:37,199 --> 00:07:41,440
to the forwarding place then it's up to

00:07:40,720 --> 00:07:43,039
them

00:07:41,440 --> 00:07:44,800
to create the communication tunnel

00:07:43,039 --> 00:07:46,960
between the two nodes

00:07:44,800 --> 00:07:48,000
create the necessary interfaces and

00:07:46,960 --> 00:07:50,879
inject them

00:07:48,000 --> 00:07:52,400
inside the pods and thus complete the

00:07:50,879 --> 00:07:55,199
connection between the client

00:07:52,400 --> 00:07:55,199
and the firewall

00:07:56,160 --> 00:07:59,360
now let's have a more talk oriented

00:07:57,759 --> 00:08:00,960
example

00:07:59,360 --> 00:08:03,759
in this case we're going to recreate the

00:08:00,960 --> 00:08:07,199
topology of a 4g lte network

00:08:03,759 --> 00:08:07,199
using network service mesh

00:08:07,360 --> 00:08:10,560
now let's see how a standard 4g network

00:08:09,360 --> 00:08:12,400
looks like

00:08:10,560 --> 00:08:14,720
first we have the user equipment which

00:08:12,400 --> 00:08:17,680
are the devices that use that network

00:08:14,720 --> 00:08:20,080
stuff like phones cars iot devices and

00:08:17,680 --> 00:08:22,240
so on

00:08:20,080 --> 00:08:23,919
then we have the radio access network

00:08:22,240 --> 00:08:24,879
which which are basically lots of

00:08:23,919 --> 00:08:28,319
antennas

00:08:24,879 --> 00:08:30,160
or base stations then

00:08:28,319 --> 00:08:31,680
we have the evolved packet core network

00:08:30,160 --> 00:08:33,519
or epc

00:08:31,680 --> 00:08:35,440
which are a set of components each

00:08:33,519 --> 00:08:37,039
responsible for different service within

00:08:35,440 --> 00:08:38,959
that system

00:08:37,039 --> 00:08:40,080
for example stuff like user

00:08:38,959 --> 00:08:42,560
authentication

00:08:40,080 --> 00:08:44,640
charging gateways that manage quality of

00:08:42,560 --> 00:08:48,320
service and so on

00:08:44,640 --> 00:08:51,120
the output then goes to the data network

00:08:48,320 --> 00:08:52,800
for example the internet in this talk

00:08:51,120 --> 00:08:53,440
we're going to focus on that box in the

00:08:52,800 --> 00:08:55,279
middle

00:08:53,440 --> 00:08:58,480
and recreate the network topology for

00:08:55,279 --> 00:08:58,480
the packet core network

00:08:59,200 --> 00:09:03,120
so let's see how to do that using

00:09:00,880 --> 00:09:05,360
network service mesh

00:09:03,120 --> 00:09:06,839
first we decide that each component is

00:09:05,360 --> 00:09:09,760
going to be a different pot within

00:09:06,839 --> 00:09:11,120
kubernetes

00:09:09,760 --> 00:09:13,279
now that we have a bunch of ports we

00:09:11,120 --> 00:09:16,240
want to connect we need to decide how to

00:09:13,279 --> 00:09:17,920
map that to network service mesh

00:09:16,240 --> 00:09:19,839
although we can have a port that is both

00:09:17,920 --> 00:09:21,920
client and endpoints

00:09:19,839 --> 00:09:22,880
to simplify it we'll create the setup in

00:09:21,920 --> 00:09:24,720
such a way

00:09:22,880 --> 00:09:27,120
that the single body side of the client

00:09:24,720 --> 00:09:29,279
or an endpoint

00:09:27,120 --> 00:09:32,080
considering that the end result looks

00:09:29,279 --> 00:09:32,080
like the following

00:09:32,480 --> 00:09:37,519
for example we chose mme to be an

00:09:35,279 --> 00:09:41,279
endpoint

00:09:37,519 --> 00:09:41,279
and hss to be a client

00:09:43,120 --> 00:09:47,360
once we have covered that then we need

00:09:45,120 --> 00:09:49,200
to describe the topology in the network

00:09:47,360 --> 00:09:51,519
service yaml file

00:09:49,200 --> 00:09:52,720
as we said before it consists of a set

00:09:51,519 --> 00:09:55,279
of matches

00:09:52,720 --> 00:09:57,360
and each much have a source selector and

00:09:55,279 --> 00:09:58,959
a destination selector

00:09:57,360 --> 00:10:00,560
this means that if your request is

00:09:58,959 --> 00:10:01,680
coming with a label matching the source

00:10:00,560 --> 00:10:03,440
selector

00:10:01,680 --> 00:10:06,079
we should put it for an endpoint with a

00:10:03,440 --> 00:10:11,440
label from the destination selector

00:10:06,079 --> 00:10:13,440
for example s6a is our source selector

00:10:11,440 --> 00:10:15,120
which is a label coming from the hss

00:10:13,440 --> 00:10:18,320
client

00:10:15,120 --> 00:10:20,640
and mme is our destination selector

00:10:18,320 --> 00:10:22,880
which is the label advertised by the mme

00:10:20,640 --> 00:10:24,560
endpoint

00:10:22,880 --> 00:10:26,560
we complete describing the whole

00:10:24,560 --> 00:10:29,279
topology using that same approach for

00:10:26,560 --> 00:10:29,279
each connection

00:10:29,920 --> 00:10:33,680
so let's see how the ktml files looks

00:10:32,320 --> 00:10:37,200
like for both endpoint and

00:10:33,680 --> 00:10:39,600
client for the endpoint we specify the

00:10:37,200 --> 00:10:42,959
network service it belongs to

00:10:39,600 --> 00:10:45,040
in this case this is 4g network then

00:10:42,959 --> 00:10:46,000
we specify the endpoint label we'll

00:10:45,040 --> 00:10:50,399
advertise from this

00:10:46,000 --> 00:10:52,160
endpoint in this case this is mme

00:10:50,399 --> 00:10:54,079
for the client we want to say which

00:10:52,160 --> 00:10:55,279
network service it wants to consume

00:10:54,079 --> 00:10:58,480
right

00:10:55,279 --> 00:10:58,800
to do so we specify the network service

00:10:58,480 --> 00:11:00,640
and

00:10:58,800 --> 00:11:03,680
the label we're going to advertise as a

00:11:00,640 --> 00:11:06,800
client in our case this is 4g network

00:11:03,680 --> 00:11:06,800
and s6a

00:11:07,360 --> 00:11:13,440
now let's see the actual demo of the 4g

00:11:10,640 --> 00:11:16,640
network topology example

00:11:13,440 --> 00:11:18,720
we will be using network service mesh

00:11:16,640 --> 00:11:22,320
with kubernetes

00:11:18,720 --> 00:11:25,040
so we have a simple burnet is deployment

00:11:22,320 --> 00:11:26,720
we have to note cluster there is nothing

00:11:25,040 --> 00:11:29,040
fancy in it

00:11:26,720 --> 00:11:30,079
then we deploy network service mesh

00:11:29,040 --> 00:11:34,160
infrastructure

00:11:30,079 --> 00:11:36,079
using here we will wait for a while

00:11:34,160 --> 00:11:40,720
until the deployment is done and

00:11:36,079 --> 00:11:40,720
until all the pots are available and are

00:11:40,839 --> 00:11:45,680
ready

00:11:42,480 --> 00:11:49,360
so once there once the deployment

00:11:45,680 --> 00:11:49,680
is completed we can see that there are

00:11:49,360 --> 00:11:52,320
two

00:11:49,680 --> 00:11:53,920
nsm managers and there are two

00:11:52,320 --> 00:11:56,240
forwarding planes

00:11:53,920 --> 00:11:57,279
each of them for each note of the

00:11:56,240 --> 00:11:59,519
cluster

00:11:57,279 --> 00:12:02,160
as we showed in the previous in the

00:11:59,519 --> 00:12:02,160
examples

00:12:02,320 --> 00:12:06,160
then we proceeded by deploying the yaml

00:12:05,519 --> 00:12:09,440
files

00:12:06,160 --> 00:12:10,160
that we created earlier after that we

00:12:09,440 --> 00:12:12,959
can see

00:12:10,160 --> 00:12:14,160
that each client and endpoint are being

00:12:12,959 --> 00:12:16,399
deployed

00:12:14,160 --> 00:12:17,680
here are all the components that we

00:12:16,399 --> 00:12:20,880
already showed

00:12:17,680 --> 00:12:22,160
in the example once this is done and

00:12:20,880 --> 00:12:24,959
once all the pots

00:12:22,160 --> 00:12:26,720
are ready this completes deploying the

00:12:24,959 --> 00:12:30,000
4g network topology

00:12:26,720 --> 00:12:32,480
that we described in the yaml file

00:12:30,000 --> 00:12:33,600
this means that all the necessary

00:12:32,480 --> 00:12:36,720
interfaces

00:12:33,600 --> 00:12:38,480
and connections were created created by

00:12:36,720 --> 00:12:40,800
the forwarding planes

00:12:38,480 --> 00:12:42,000
in that all the components can

00:12:40,800 --> 00:12:45,120
communicate with

00:12:42,000 --> 00:12:46,560
each other but we now need to verify

00:12:45,120 --> 00:12:49,440
that

00:12:46,560 --> 00:12:50,639
so that we have everything deployed we

00:12:49,440 --> 00:12:53,920
need to make sure

00:12:50,639 --> 00:12:55,839
that it is created as we wanted it to be

00:12:53,920 --> 00:12:57,760
for that reason we have a script that

00:12:55,839 --> 00:12:58,480
verifies the connections between each

00:12:57,760 --> 00:13:02,000
client and

00:12:58,480 --> 00:13:04,320
endpoint the the script loops through

00:13:02,000 --> 00:13:05,200
all the clients and it pings the

00:13:04,320 --> 00:13:08,399
corresponding

00:13:05,200 --> 00:13:11,120
and from endpoint for that client

00:13:08,399 --> 00:13:12,160
we can see the successful pings from the

00:13:11,120 --> 00:13:15,440
output and

00:13:12,160 --> 00:13:21,440
we can also see the endpoint and client

00:13:15,440 --> 00:13:23,680
port names in the same output

00:13:21,440 --> 00:13:25,279
so what else can we do we can use a

00:13:23,680 --> 00:13:28,320
dashboard like skydive

00:13:25,279 --> 00:13:29,360
to better visualize our deployment and

00:13:28,320 --> 00:13:31,680
what do we see

00:13:29,360 --> 00:13:33,519
we see our two worker nodes being there

00:13:31,680 --> 00:13:34,240
and we can see the pots that live on

00:13:33,519 --> 00:13:36,240
each node

00:13:34,240 --> 00:13:37,760
you can see the clients and we can see

00:13:36,240 --> 00:13:40,000
the end points

00:13:37,760 --> 00:13:41,760
for each pot we can see the containers

00:13:40,000 --> 00:13:43,040
that live inside it and the available

00:13:41,760 --> 00:13:46,160
network interfaces

00:13:43,040 --> 00:13:46,959
has a good thing that we can visualize

00:13:46,160 --> 00:13:49,279
here is that

00:13:46,959 --> 00:13:52,480
we can see the pot to pot connections

00:13:49,279 --> 00:13:54,320
that are created by network service mesh

00:13:52,480 --> 00:13:56,560
we can also see some specific

00:13:54,320 --> 00:13:59,600
information for each interface

00:13:56,560 --> 00:14:01,680
stuff like type state address and even

00:13:59,600 --> 00:14:04,639
its matrix

00:14:01,680 --> 00:14:07,839
and this is available for both nsm and

00:14:04,639 --> 00:14:09,519
cni created interfaces

00:14:07,839 --> 00:14:11,199
with that we can see that having a

00:14:09,519 --> 00:14:13,040
dashboard like skydive

00:14:11,199 --> 00:14:14,959
presents a pretty neat way to better

00:14:13,040 --> 00:14:17,040
understand your deployment

00:14:14,959 --> 00:14:19,279
and visualize it in a nice and simple

00:14:17,040 --> 00:14:22,399
manner

00:14:19,279 --> 00:14:25,360
with that example we showcase that

00:14:22,399 --> 00:14:28,240
nsa makes it possible to have flexible

00:14:25,360 --> 00:14:31,600
and dynamically defined infrastructure

00:14:28,240 --> 00:14:33,839
using a simple api this is something

00:14:31,600 --> 00:14:36,880
really important for use cases

00:14:33,839 --> 00:14:38,480
such as telco another thing to share is

00:14:36,880 --> 00:14:41,920
that we are also actively

00:14:38,480 --> 00:14:44,959
involved in the cncfcnf facebook

00:14:41,920 --> 00:14:48,160
for those of you that don't know about

00:14:44,959 --> 00:14:50,480
it this is an initiative to evaluate how

00:14:48,160 --> 00:14:53,600
cnf architectures compare

00:14:50,480 --> 00:14:54,000
to the more traditional vnf ones there

00:14:53,600 --> 00:14:56,240
are

00:14:54,000 --> 00:14:57,440
two already there are two network

00:14:56,240 --> 00:15:00,560
service mesh

00:14:57,440 --> 00:15:03,680
based use cases that are present there

00:15:00,560 --> 00:15:04,959
and there is an ongoing work by ericsson

00:15:03,680 --> 00:15:08,079
to provide

00:15:04,959 --> 00:15:11,360
a network separation use case

00:15:08,079 --> 00:15:12,079
what's next with the project we have an

00:15:11,360 --> 00:15:14,720
ongoing

00:15:12,079 --> 00:15:16,560
multi-rep refactoring that will improve

00:15:14,720 --> 00:15:19,279
the project structure

00:15:16,560 --> 00:15:21,600
we have a kubernetes operator for

00:15:19,279 --> 00:15:23,040
deploying and managing network service

00:15:21,600 --> 00:15:24,720
mesh

00:15:23,040 --> 00:15:26,880
there are also very interesting

00:15:24,720 --> 00:15:28,320
contributions in the forwarding playing

00:15:26,880 --> 00:15:31,759
context

00:15:28,320 --> 00:15:34,399
we have we are working

00:15:31,759 --> 00:15:36,079
on support for multiple simultaneous

00:15:34,399 --> 00:15:39,199
foreigners

00:15:36,079 --> 00:15:40,079
also ericsson are working on a forwarder

00:15:39,199 --> 00:15:43,440
with hardware

00:15:40,079 --> 00:15:46,000
offloading to smart mix and this will

00:15:43,440 --> 00:15:46,320
deliver a pci passthrough performance

00:15:46,000 --> 00:15:48,880
for

00:15:46,320 --> 00:15:50,720
clients and endpoints in the context of

00:15:48,880 --> 00:15:53,600
network service mesh

00:15:50,720 --> 00:15:54,399
and this will also deliver no host

00:15:53,600 --> 00:15:58,560
consumed

00:15:54,399 --> 00:15:59,120
compared to dpdk we are also working on

00:15:58,560 --> 00:16:03,440
an

00:15:59,120 --> 00:16:04,480
srov forwarder and for those of you that

00:16:03,440 --> 00:16:06,959
are interested

00:16:04,480 --> 00:16:07,519
there will be a same seminar covering

00:16:06,959 --> 00:16:09,519
how

00:16:07,519 --> 00:16:11,839
network service mesh can address the

00:16:09,519 --> 00:16:13,600
networking challenges that cloud native

00:16:11,839 --> 00:16:16,959
tech applications face

00:16:13,600 --> 00:16:19,440
in 5g there will be details and

00:16:16,959 --> 00:16:22,240
proof of concept on how network service

00:16:19,440 --> 00:16:25,279
mesh decouples the infrastructure from

00:16:22,240 --> 00:16:27,519
applications and the speakers you

00:16:25,279 --> 00:16:30,000
also give an update of the network

00:16:27,519 --> 00:16:30,560
separation use case that is ongoing in

00:16:30,000 --> 00:16:36,079
the

00:16:30,560 --> 00:16:38,800
cnf testbed

00:16:36,079 --> 00:16:41,199
so the takeaway that we see here is that

00:16:38,800 --> 00:16:43,199
teleco operators and service providers

00:16:41,199 --> 00:16:45,279
are actively looking at the cloud native

00:16:43,199 --> 00:16:46,880
world to build their next generation

00:16:45,279 --> 00:16:48,639
solutions

00:16:46,880 --> 00:16:50,720
meaning that containers and all that

00:16:48,639 --> 00:16:52,240
ecosystem of projects around them

00:16:50,720 --> 00:16:53,839
will be the next building blocks for

00:16:52,240 --> 00:16:55,920
that

00:16:53,839 --> 00:16:57,759
projects like network service mesh aim

00:16:55,920 --> 00:16:59,519
to provide features that will help to

00:16:57,759 --> 00:17:02,839
create those future systems

00:16:59,519 --> 00:17:05,120
and at the end be part of that

00:17:02,839 --> 00:17:07,039
transition

00:17:05,120 --> 00:17:08,880
and with that i believe we've covered

00:17:07,039 --> 00:17:10,400
all the slides for this talk

00:17:08,880 --> 00:17:12,640
we'd like to say thank you again for

00:17:10,400 --> 00:17:13,600
attending our virtual session at kubecon

00:17:12,640 --> 00:17:15,439
europe

00:17:13,600 --> 00:17:16,799
we hope everyone enjoyed it and got some

00:17:15,439 --> 00:17:20,160
var out of it

00:17:16,799 --> 00:17:26,720
thank you thank you and we are also

00:17:20,160 --> 00:17:26,720

YouTube URL: https://www.youtube.com/watch?v=zPKCZxHrERU


