Title: Ready, Set, Go for K8s at edge today for AI ML with Tensorflow - Amol Chobe & Sachin Rathee, Red Hat
Publication date: 2021-05-05
Playlist: Kubernetes on Edge Day EU 2021
Description: 
	Don’t miss out! Join us at our upcoming event: KubeCon + CloudNativeCon North America 2021 in Los Angeles, CA from October 12-15. Learn more at https://kubecon.io The conference features presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects.

Ready, Set, Go for K8s at edge today for AI/ML with Tensorflow - Amol Chobe & Sachin Rathee, Red Hat

At the edge, you typically have to work with a smaller footprint of infrastructure that don’t have enough capacity to run K8s effectively, such as with the majority of IoT devices that are just sensors. Considerations should also be made for bandwidth, connectivity and latency issues at edge. We will discuss potential K8s architecture patterns that can be used for edge workloads, along with all the different elements you’ll need to build an architecture that matches each application’s requirement of low-latency, data privacy and bandwidth scalability. With TensorFlow running at the edge within K8s, you can deploy deep learning models as microservices. We discuss how to apply ML models to detect real-time IoT anomaly and threat mitigation.
Captions: 
	00:00:00,799 --> 00:00:03,360
good morning good afternoon and good

00:00:02,560 --> 00:00:06,480
evening

00:00:03,360 --> 00:00:07,759
welcome to kubernetes at hd we hope

00:00:06,480 --> 00:00:09,120
everyone is doing well in these

00:00:07,759 --> 00:00:11,519
interesting times

00:00:09,120 --> 00:00:13,679
today we are presenting on kubernetes at

00:00:11,519 --> 00:00:15,839
edge for aiml solutions

00:00:13,679 --> 00:00:19,600
my name is sachin rati i'm a principal

00:00:15,839 --> 00:00:22,240
for edge cloud solutions at red hat

00:00:19,600 --> 00:00:24,240
hi my name is amul chobay i'm a solution

00:00:22,240 --> 00:00:26,640
architect lead at red hat

00:00:24,240 --> 00:00:28,720
so let's go over the agenda at the part

00:00:26,640 --> 00:00:31,039
of today's presentation we'll go over

00:00:28,720 --> 00:00:33,600
following topics we'll cover what is aid

00:00:31,039 --> 00:00:35,840
to understand the definition of aid

00:00:33,600 --> 00:00:37,680
what are typical challenges at age

00:00:35,840 --> 00:00:38,559
deployment architecture type for

00:00:37,680 --> 00:00:42,160
kubernetes at

00:00:38,559 --> 00:00:44,399
8 we'll go into machine learning

00:00:42,160 --> 00:00:46,399
and understand what is tensorflow what

00:00:44,399 --> 00:00:48,879
technology we have used in our

00:00:46,399 --> 00:00:51,440
edge solution design and then we will go

00:00:48,879 --> 00:00:52,640
over the architecture for iot anomaly

00:00:51,440 --> 00:00:54,640
detection using

00:00:52,640 --> 00:00:56,559
tensorflow so let's start by

00:00:54,640 --> 00:00:59,199
understanding what is edge

00:00:56,559 --> 00:01:00,559
now edge is defined as any computing and

00:00:59,199 --> 00:01:03,120
network resource

00:01:00,559 --> 00:01:04,640
along the path between data sources and

00:01:03,120 --> 00:01:07,280
the cloud data centers

00:01:04,640 --> 00:01:09,840
so edge is not a point rather edges are

00:01:07,280 --> 00:01:09,840
continuum

00:01:09,920 --> 00:01:12,960
as you can see on this picture the edge

00:01:12,080 --> 00:01:15,439
spans

00:01:12,960 --> 00:01:17,040
from edge devices all the way back to

00:01:15,439 --> 00:01:18,799
the centralized cloud

00:01:17,040 --> 00:01:20,240
and in between you can have multiple

00:01:18,799 --> 00:01:21,600
intermediate locations

00:01:20,240 --> 00:01:24,560
which can host your additional edge

00:01:21,600 --> 00:01:26,880
infrastructure the location of your edge

00:01:24,560 --> 00:01:28,560
application and infrastructure is

00:01:26,880 --> 00:01:29,759
ultimately going to be defined by a

00:01:28,560 --> 00:01:32,960
number of factors

00:01:29,759 --> 00:01:36,640
such as latency response times available

00:01:32,960 --> 00:01:39,280
compute network or storage resources

00:01:36,640 --> 00:01:40,720
so eight computing challenges some of

00:01:39,280 --> 00:01:43,759
the key challenges for

00:01:40,720 --> 00:01:44,720
adopting eight h computing are listed

00:01:43,759 --> 00:01:46,720
here

00:01:44,720 --> 00:01:49,040
when we look at edge computing there are

00:01:46,720 --> 00:01:51,759
a lot of different choices of hardware

00:01:49,040 --> 00:01:52,159
and we need to define a solution which

00:01:51,759 --> 00:01:55,759
will

00:01:52,159 --> 00:01:58,799
cater this large landscape of hardware

00:01:55,759 --> 00:02:00,079
so when it comes to data locality and

00:01:58,799 --> 00:02:02,960
security

00:02:00,079 --> 00:02:05,360
the rules for governing the data changes

00:02:02,960 --> 00:02:07,360
based on locality of data

00:02:05,360 --> 00:02:08,720
and this brings in the compliance as

00:02:07,360 --> 00:02:10,560
well as security issue

00:02:08,720 --> 00:02:12,239
along with the privacy law the

00:02:10,560 --> 00:02:15,280
confidentiality of data

00:02:12,239 --> 00:02:16,480
can often be at rest and poses a huge

00:02:15,280 --> 00:02:18,800
challenge

00:02:16,480 --> 00:02:20,879
eight devices are resource constrained

00:02:18,800 --> 00:02:23,440
and energy sensitive

00:02:20,879 --> 00:02:24,800
and it's add a huge challenge and

00:02:23,440 --> 00:02:28,000
workload priority become

00:02:24,800 --> 00:02:29,840
important another aspect is

00:02:28,000 --> 00:02:32,000
maintenance device maintenance is one of

00:02:29,840 --> 00:02:33,680
the key challenge for example how

00:02:32,000 --> 00:02:36,160
i will update the device or packet

00:02:33,680 --> 00:02:38,239
reward bandwidth challenges

00:02:36,160 --> 00:02:40,239
so balance challenges arrived due to

00:02:38,239 --> 00:02:41,519
multiple workloads sharing the same

00:02:40,239 --> 00:02:44,400
network part

00:02:41,519 --> 00:02:45,120
so we have to be creative about this and

00:02:44,400 --> 00:02:48,480
use

00:02:45,120 --> 00:02:52,319
workload prioritization or network

00:02:48,480 --> 00:02:55,760
policy restriction to overcome this pump

00:02:52,319 --> 00:02:58,000
also due to unreliable nature of

00:02:55,760 --> 00:02:59,440
network each node need to be

00:02:58,000 --> 00:03:03,040
autonomously managed

00:02:59,440 --> 00:03:07,200
itself and these challenges

00:03:03,040 --> 00:03:09,120
can be overcome

00:03:07,200 --> 00:03:11,280
using kubernetes kubernetes has

00:03:09,120 --> 00:03:14,319
different ways to navigate around it

00:03:11,280 --> 00:03:16,400
or it can be overcome using uh

00:03:14,319 --> 00:03:17,760
other its solutions that we can come up

00:03:16,400 --> 00:03:19,360
with so with that

00:03:17,760 --> 00:03:20,800
understanding of the challenges now

00:03:19,360 --> 00:03:22,640
let's take a look at

00:03:20,800 --> 00:03:24,480
three different deployment models for

00:03:22,640 --> 00:03:26,400
containers at the edge

00:03:24,480 --> 00:03:27,920
first and most straightforward option

00:03:26,400 --> 00:03:30,159
for deployment includes deploying

00:03:27,920 --> 00:03:32,000
kubernetes all in one cluster

00:03:30,159 --> 00:03:33,840
this provides capabilities to have a

00:03:32,000 --> 00:03:35,519
lightweight kubernetes orchestration

00:03:33,840 --> 00:03:39,120
where resources are minimal

00:03:35,519 --> 00:03:40,799
and response times are quite stringent

00:03:39,120 --> 00:03:42,159
second option is where we continue to

00:03:40,799 --> 00:03:43,040
have stringent response time

00:03:42,159 --> 00:03:45,599
requirements

00:03:43,040 --> 00:03:46,319
but we have a bit more resources which

00:03:45,599 --> 00:03:49,120
however

00:03:46,319 --> 00:03:50,720
may be distributed at multiple locations

00:03:49,120 --> 00:03:52,879
here we separate out the kubernetes

00:03:50,720 --> 00:03:55,519
control plane from the data plane

00:03:52,879 --> 00:03:57,519
control plane becomes centralized while

00:03:55,519 --> 00:03:58,959
worker nodes are distributed to multiple

00:03:57,519 --> 00:04:00,640
locations

00:03:58,959 --> 00:04:02,799
finally we're going to have requirements

00:04:00,640 --> 00:04:05,040
where we see all containers already

00:04:02,799 --> 00:04:06,720
deployed in the devices

00:04:05,040 --> 00:04:08,959
in this case the management of those

00:04:06,720 --> 00:04:10,879
devices gets taken care of directly

00:04:08,959 --> 00:04:12,400
by another linux foundation project that

00:04:10,879 --> 00:04:15,840
we have been recently looking at

00:04:12,400 --> 00:04:15,840
called open horizon

00:04:17,440 --> 00:04:21,919
now let's get into the machine learning

00:04:20,160 --> 00:04:24,720
aspect of this presentation

00:04:21,919 --> 00:04:25,360
so let's understand what is tensorflow

00:04:24,720 --> 00:04:26,800
the

00:04:25,360 --> 00:04:28,639
definition is written there but

00:04:26,800 --> 00:04:30,080
typically the tensorflow is machine

00:04:28,639 --> 00:04:32,720
learning framework

00:04:30,080 --> 00:04:34,240
and it might be your new best friend if

00:04:32,720 --> 00:04:36,880
you have a lot of data

00:04:34,240 --> 00:04:37,840
and you are after state of art solution

00:04:36,880 --> 00:04:40,000
in artificial

00:04:37,840 --> 00:04:41,280
intelligence like deep learning or

00:04:40,000 --> 00:04:43,040
neural network

00:04:41,280 --> 00:04:45,440
tensorflow has been used in voice

00:04:43,040 --> 00:04:48,080
recognition text-based application

00:04:45,440 --> 00:04:50,000
image recognition time series algorithm

00:04:48,080 --> 00:04:51,919
video detection and many more

00:04:50,000 --> 00:04:54,000
tensorflow is open source and you can

00:04:51,919 --> 00:04:55,040
download it for free and get started

00:04:54,000 --> 00:04:56,720
immediately

00:04:55,040 --> 00:04:58,720
you can build and train machine learning

00:04:56,720 --> 00:05:00,720
models using apis like kerala

00:04:58,720 --> 00:05:02,080
you can train and deploy model in cloud

00:05:00,720 --> 00:05:04,479
on-prem or even on

00:05:02,080 --> 00:05:06,720
edge you can see on slide there is the

00:05:04,479 --> 00:05:08,000
vast ecosystem of tensorflow deployment

00:05:06,720 --> 00:05:11,199
type

00:05:08,000 --> 00:05:15,919
for our project we use tensorflow

00:05:11,199 --> 00:05:15,919
code as well as tensorflow lite

00:05:16,320 --> 00:05:20,320
in order to build the edge solutions a

00:05:18,160 --> 00:05:22,960
number of components come into play

00:05:20,320 --> 00:05:25,120
so firstly we need a messaging platform

00:05:22,960 --> 00:05:26,400
this is needed to accept data or mqtt

00:05:25,120 --> 00:05:28,080
protocol

00:05:26,400 --> 00:05:30,960
and massive provides this capability

00:05:28,080 --> 00:05:32,880
with the apache active mq artemis

00:05:30,960 --> 00:05:34,479
next for real-time streaming we make use

00:05:32,880 --> 00:05:37,199
of kafka and kubernetes

00:05:34,479 --> 00:05:38,960
and this is provided by project strimzy

00:05:37,199 --> 00:05:39,680
camel k provides the capability for

00:05:38,960 --> 00:05:42,240
mediation

00:05:39,680 --> 00:05:43,680
and routing of the sensory data we also

00:05:42,240 --> 00:05:46,000
make use of prometheus

00:05:43,680 --> 00:05:47,919
on the operation side for monitoring and

00:05:46,000 --> 00:05:49,840
alerting requirements

00:05:47,919 --> 00:05:52,000
sef here is used to provide storage for

00:05:49,840 --> 00:05:52,800
sensor data coming in for the training

00:05:52,000 --> 00:05:55,520
of the models

00:05:52,800 --> 00:05:57,520
as well as for historical reasons

00:05:55,520 --> 00:05:58,800
jupiter notebook helps in providing the

00:05:57,520 --> 00:06:01,199
development environment

00:05:58,800 --> 00:06:03,039
for building and training the model the

00:06:01,199 --> 00:06:04,880
developed artifacts are then checked

00:06:03,039 --> 00:06:06,160
into a source code management system

00:06:04,880 --> 00:06:07,919
such as git

00:06:06,160 --> 00:06:09,919
from where the container images can be

00:06:07,919 --> 00:06:12,639
built and stored in container registry

00:06:09,919 --> 00:06:12,639
such as square

00:06:13,360 --> 00:06:18,160
now let's get into architecture of iot

00:06:16,240 --> 00:06:20,479
anomaly detection

00:06:18,160 --> 00:06:21,440
so we have used iot device simulator in

00:06:20,479 --> 00:06:23,520
our design

00:06:21,440 --> 00:06:24,720
we have deployed kubernetes at page

00:06:23,520 --> 00:06:26,800
using

00:06:24,720 --> 00:06:29,520
all in one cluster deployment model you

00:06:26,800 --> 00:06:31,919
can see it on your bottom of your screen

00:06:29,520 --> 00:06:33,600
we have also used kubernetes on cloud on

00:06:31,919 --> 00:06:37,759
the top which can be run on

00:06:33,600 --> 00:06:39,520
any public cloud or even on private car

00:06:37,759 --> 00:06:41,039
you will see the component mentioned by

00:06:39,520 --> 00:06:42,080
searching in previous slide in this

00:06:41,039 --> 00:06:45,600
diagram

00:06:42,080 --> 00:06:48,000
also from kubernetes as age point of

00:06:45,600 --> 00:06:50,400
view you will see that we will send

00:06:48,000 --> 00:06:52,880
the alert to webhook and webhook can be

00:06:50,400 --> 00:06:53,440
used for feedback loop control as well

00:06:52,880 --> 00:06:57,199
as

00:06:53,440 --> 00:06:59,120
alerting the end user in the next slide

00:06:57,199 --> 00:07:00,479
sachin will go over the details on

00:06:59,120 --> 00:07:03,840
training model flow

00:07:00,479 --> 00:07:03,840
for our architecture design

00:07:04,560 --> 00:07:08,160
excellent so here the training workflow

00:07:06,800 --> 00:07:09,759
is highlighted in the red

00:07:08,160 --> 00:07:11,680
and that's what we're going to follow

00:07:09,759 --> 00:07:12,560
the networking data captured on the

00:07:11,680 --> 00:07:16,080
devices

00:07:12,560 --> 00:07:17,840
is sent over the mqtt protocol to nmase

00:07:16,080 --> 00:07:19,120
which of course has the artemis broker

00:07:17,840 --> 00:07:21,440
running

00:07:19,120 --> 00:07:23,599
this data is then transformed in camel

00:07:21,440 --> 00:07:25,840
care and from this point on

00:07:23,599 --> 00:07:26,880
the training and inference models kind

00:07:25,840 --> 00:07:28,319
of diverge

00:07:26,880 --> 00:07:30,960
those are two different workflows from

00:07:28,319 --> 00:07:33,759
this point for training workflow

00:07:30,960 --> 00:07:34,880
this data is passed on to camel k for

00:07:33,759 --> 00:07:37,199
any normalization

00:07:34,880 --> 00:07:38,880
and then stored in the cef data store

00:07:37,199 --> 00:07:40,880
this allows the models

00:07:38,880 --> 00:07:42,560
and code running with jupyter notebooks

00:07:40,880 --> 00:07:44,240
to use this data for training and

00:07:42,560 --> 00:07:46,560
testing the models

00:07:44,240 --> 00:07:48,639
now once the model training is done the

00:07:46,560 --> 00:07:49,840
artifacts and code are then checked into

00:07:48,639 --> 00:07:51,840
git

00:07:49,840 --> 00:07:53,919
from here on the build process is kicked

00:07:51,840 --> 00:07:55,360
off and the resulting image is stored in

00:07:53,919 --> 00:07:58,479
query registry

00:07:55,360 --> 00:07:59,520
from here it can be replicated to any

00:07:58,479 --> 00:08:02,800
other registries

00:07:59,520 --> 00:08:02,800
at any edge locations

00:08:03,599 --> 00:08:09,280
so let's understand the serving model

00:08:06,800 --> 00:08:10,400
from the tensorflow if you look at this

00:08:09,280 --> 00:08:13,520
diagram

00:08:10,400 --> 00:08:14,000
the green dots will show you the serving

00:08:13,520 --> 00:08:16,240
model

00:08:14,000 --> 00:08:17,680
and we're talking about step number four

00:08:16,240 --> 00:08:21,599
where the tensorflow

00:08:17,680 --> 00:08:24,240
is running on python um application

00:08:21,599 --> 00:08:24,879
for the serving and prediction the model

00:08:24,240 --> 00:08:26,720
serving

00:08:24,879 --> 00:08:29,120
is simply the exposure of the trained

00:08:26,720 --> 00:08:31,440
model so that it can be accessed

00:08:29,120 --> 00:08:32,159
by endpoint input here can be direct

00:08:31,440 --> 00:08:34,800
user

00:08:32,159 --> 00:08:35,680
or other software we are using auto

00:08:34,800 --> 00:08:38,800
encoder model

00:08:35,680 --> 00:08:41,039
intensive flow auto encoder is neural

00:08:38,800 --> 00:08:43,919
network which takes in-stream data

00:08:41,039 --> 00:08:45,519
and create output we are looking at mean

00:08:43,919 --> 00:08:49,200
squared error to detect

00:08:45,519 --> 00:08:50,880
anomaly if the real-time data

00:08:49,200 --> 00:08:52,959
mean squared error is more than

00:08:50,880 --> 00:08:53,760
threshold prometheus will scrape the

00:08:52,959 --> 00:08:56,240
data

00:08:53,760 --> 00:08:57,839
of top end result and then using

00:08:56,240 --> 00:09:02,080
prometheus alert

00:08:57,839 --> 00:09:04,560
manager to notify the end user

00:09:02,080 --> 00:09:05,120
webhooks can be used as a feedback loop

00:09:04,560 --> 00:09:08,480
control

00:09:05,120 --> 00:09:10,080
to remediate the detected anomaly

00:09:08,480 --> 00:09:12,160
we have designed and prototyped this

00:09:10,080 --> 00:09:14,560
solution for anomaly detection we can

00:09:12,160 --> 00:09:15,600
use this design in a lot of different

00:09:14,560 --> 00:09:17,680
scenarios

00:09:15,600 --> 00:09:19,279
the consistency and predictability

00:09:17,680 --> 00:09:20,160
become mission critical for this edge

00:09:19,279 --> 00:09:22,080
solution

00:09:20,160 --> 00:09:23,360
again this is not the only design for

00:09:22,080 --> 00:09:28,160
anomaly detection

00:09:23,360 --> 00:09:28,160
using machine learning for eight devices

00:09:28,720 --> 00:09:31,839
and that is all we can cover in

00:09:30,160 --> 00:09:34,720
allocated 10 minutes

00:09:31,839 --> 00:09:35,680
would love to go over our code and

00:09:34,720 --> 00:09:37,760
design model

00:09:35,680 --> 00:09:40,000
hopefully in some other presentation

00:09:37,760 --> 00:09:42,399
however please do reach out to us

00:09:40,000 --> 00:09:43,680
for any customization of this solution

00:09:42,399 --> 00:09:45,839
or any specific

00:09:43,680 --> 00:09:48,720
use case that you may have thanks a lot

00:09:45,839 --> 00:09:51,360
for attending thank you very much

00:09:48,720 --> 00:09:53,120
so with that we sincerely hope you

00:09:51,360 --> 00:09:56,000
enjoyed this session

00:09:53,120 --> 00:09:58,160
here are our email addresses please do

00:09:56,000 --> 00:09:59,920
let us know how we can help

00:09:58,160 --> 00:10:01,440
also don't forget to provide your

00:09:59,920 --> 00:10:03,120
feedback

00:10:01,440 --> 00:10:05,240
enjoy the rest of the sessions at

00:10:03,120 --> 00:10:08,240
kubernetes hd

00:10:05,240 --> 00:10:08,240

YouTube URL: https://www.youtube.com/watch?v=QBJZityUhK0


