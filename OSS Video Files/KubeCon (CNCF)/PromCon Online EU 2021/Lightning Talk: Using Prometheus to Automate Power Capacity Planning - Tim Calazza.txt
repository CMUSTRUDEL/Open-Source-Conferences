Title: Lightning Talk: Using Prometheus to Automate Power Capacity Planning - Tim Calazza
Publication date: 2021-05-03
Playlist: PromCon Online EU 2021
Description: 
	Donâ€™t miss out! Join us at our upcoming event: KubeCon + CloudNativeCon North America 2021 in Los Angeles, CA from October 12-15. Learn more at https://kubecon.io The conference features presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects.

Lightning Talk: Using Prometheus to Automate Power Capacity Planning - Tim Calazza, Hudson River Trading

At Hudson River Trading, we manage a large amount of physical resources and we are typically constrained by the amount of power available to us in a given rack. In the past all the power capacity planning needed to be manual. Using the snmp_exporter, textfile collector and a bunch of recording rules we are able to normalize power metrics across the many different vendors of PDUs we use to a consistent metric as a percentage of available power. The resulting percentage available power metrics makes it easy to build dashboards and tools to automate the process of find racks with available power.
Captions: 
	00:00:00,080 --> 00:00:04,000
hello my name is tim cayasa and i'm

00:00:02,159 --> 00:00:06,720
going to talk about using prometheus to

00:00:04,000 --> 00:00:08,720
automate power capacity planning

00:00:06,720 --> 00:00:10,320
a quick answer into myself i was a

00:00:08,720 --> 00:00:12,880
traditional network

00:00:10,320 --> 00:00:14,719
engineer but now i focus primarily on

00:00:12,880 --> 00:00:16,080
tool development and monitoring for our

00:00:14,719 --> 00:00:18,160
systems and networking team

00:00:16,080 --> 00:00:19,600
here at hudson river trading hudson

00:00:18,160 --> 00:00:21,439
river trading or hrt

00:00:19,600 --> 00:00:23,359
is an automated trading firm which was

00:00:21,439 --> 00:00:25,119
founded back in 2002.

00:00:23,359 --> 00:00:27,039
being an automated trading firm simply

00:00:25,119 --> 00:00:28,400
means we use computers to buy and sell

00:00:27,039 --> 00:00:31,679
financial instruments

00:00:28,400 --> 00:00:32,559
such as stocks and bonds since hrt is a

00:00:31,679 --> 00:00:34,800
trading company

00:00:32,559 --> 00:00:36,559
latency is key for us and the desire for

00:00:34,800 --> 00:00:38,879
low latency necessitates

00:00:36,559 --> 00:00:39,760
that we co-locate our computers as close

00:00:38,879 --> 00:00:42,640
as possible

00:00:39,760 --> 00:00:44,000
to an exchanges trading platform never

00:00:42,640 --> 00:00:45,600
in the cloud

00:00:44,000 --> 00:00:47,440
operating in the physical computing

00:00:45,600 --> 00:00:50,480
space represents some interesting

00:00:47,440 --> 00:00:52,239
capacity planning challenges for us

00:00:50,480 --> 00:00:54,960
since we don't operate in the cloud and

00:00:52,239 --> 00:00:58,079
we can't click a button to add capacity

00:00:54,960 --> 00:01:00,320
capacity planning is extremely important

00:00:58,079 --> 00:01:01,680
do we have enough servers to run

00:01:00,320 --> 00:01:03,440
additional workloads

00:01:01,680 --> 00:01:05,119
do we have enough rack space for these

00:01:03,440 --> 00:01:07,520
servers and what is almost

00:01:05,119 --> 00:01:10,320
always the gating factor is do we have

00:01:07,520 --> 00:01:11,760
enough power for everything

00:01:10,320 --> 00:01:13,520
if we were looking to grow and the

00:01:11,760 --> 00:01:15,920
answer to any of these is no

00:01:13,520 --> 00:01:17,200
the turnaround time for adding capacity

00:01:15,920 --> 00:01:19,840
grows from days

00:01:17,200 --> 00:01:21,520
to weeks or months so the focus of this

00:01:19,840 --> 00:01:24,080
talk is on how we

00:01:21,520 --> 00:01:24,880
make our power capacity planning more

00:01:24,080 --> 00:01:28,080
accurate

00:01:24,880 --> 00:01:29,920
and how we can then automate it in a

00:01:28,080 --> 00:01:30,640
typical data center our servers will be

00:01:29,920 --> 00:01:32,960
divided

00:01:30,640 --> 00:01:35,040
up into multiple racks and within each

00:01:32,960 --> 00:01:38,000
rack will be multiple pdus

00:01:35,040 --> 00:01:39,119
or power distribution units these pdus

00:01:38,000 --> 00:01:41,600
are what supply

00:01:39,119 --> 00:01:42,960
power to all the servers like all

00:01:41,600 --> 00:01:44,640
capacity planning

00:01:42,960 --> 00:01:46,799
when we are looking to grow our server

00:01:44,640 --> 00:01:48,880
footprint we will look to see where

00:01:46,799 --> 00:01:52,320
there is excess capacity

00:01:48,880 --> 00:01:53,680
and with power that means where is the

00:01:52,320 --> 00:01:56,079
most available power

00:01:53,680 --> 00:01:58,079
to find the available power we just need

00:01:56,079 --> 00:02:00,640
to know how much power is being used

00:01:58,079 --> 00:02:03,040
the load on the pdu and how much power

00:02:00,640 --> 00:02:05,439
has been allocated to that pdo

00:02:03,040 --> 00:02:06,799
from that we can calculate how much

00:02:05,439 --> 00:02:09,679
available power there is

00:02:06,799 --> 00:02:12,319
so this should be simple right in an

00:02:09,679 --> 00:02:14,319
ideal world yes this should be simple

00:02:12,319 --> 00:02:15,360
the first step to tracking power usage

00:02:14,319 --> 00:02:18,800
is easy

00:02:15,360 --> 00:02:20,480
point the snmp exporter at the pdus and

00:02:18,800 --> 00:02:21,520
we know how much power is being used

00:02:20,480 --> 00:02:23,280
there

00:02:21,520 --> 00:02:24,800
and that's exactly what we do but where

00:02:23,280 --> 00:02:28,000
the trouble comes in

00:02:24,800 --> 00:02:30,480
is we have multiple pdu vendors

00:02:28,000 --> 00:02:31,120
with multiple pdu vendors come multiple

00:02:30,480 --> 00:02:34,480
snmp

00:02:31,120 --> 00:02:36,959
nibs which result in multiple metrics so

00:02:34,480 --> 00:02:39,120
the way a pdu displays power load is

00:02:36,959 --> 00:02:42,480
different across the vendors

00:02:39,120 --> 00:02:43,040
one pdu vendor may display the total

00:02:42,480 --> 00:02:45,840
load

00:02:43,040 --> 00:02:46,959
of the pdu in amps another in tenths of

00:02:45,840 --> 00:02:49,280
amps

00:02:46,959 --> 00:02:50,720
and while another we may need to sum

00:02:49,280 --> 00:02:53,360
multiple metrics

00:02:50,720 --> 00:02:54,640
to get the total load on that pdu the

00:02:53,360 --> 00:02:57,120
solution to this

00:02:54,640 --> 00:02:59,120
is to use recording rules to abstract

00:02:57,120 --> 00:03:02,080
away the underlying hardware

00:02:59,120 --> 00:03:04,000
and generate a common metric name once

00:03:02,080 --> 00:03:04,720
we verify all the recording rules are

00:03:04,000 --> 00:03:06,800
correct

00:03:04,720 --> 00:03:09,519
there's no need to touch any of the

00:03:06,800 --> 00:03:11,920
downstream tooling

00:03:09,519 --> 00:03:14,000
now that we have a consistent metric

00:03:11,920 --> 00:03:14,959
representing the load on a particular

00:03:14,000 --> 00:03:17,360
pdu

00:03:14,959 --> 00:03:18,800
we need to know how much power each pdu

00:03:17,360 --> 00:03:21,280
has been allocated

00:03:18,800 --> 00:03:22,720
again in an ideal world all pdus would

00:03:21,280 --> 00:03:25,120
have the same amount of power

00:03:22,720 --> 00:03:26,879
allocated to them however we operate in

00:03:25,120 --> 00:03:29,599
the messy real world

00:03:26,879 --> 00:03:31,680
power is expensive and can be limited in

00:03:29,599 --> 00:03:33,920
some training colas which results in

00:03:31,680 --> 00:03:36,400
us having different power different

00:03:33,920 --> 00:03:38,879
power allocations per pdu

00:03:36,400 --> 00:03:39,840
one site might be able to have 24 amps

00:03:38,879 --> 00:03:42,400
per pdu

00:03:39,840 --> 00:03:44,799
while another might only have 16 and we

00:03:42,400 --> 00:03:46,959
even have variations within globes

00:03:44,799 --> 00:03:48,400
to handle this we have a standalone

00:03:46,959 --> 00:03:50,560
script that queries

00:03:48,400 --> 00:03:51,680
netbox an open source data center

00:03:50,560 --> 00:03:53,599
management tool

00:03:51,680 --> 00:03:55,280
to determine how much power we have

00:03:53,599 --> 00:03:57,360
allocated to each pdu

00:03:55,280 --> 00:04:00,000
then the script writes these power

00:03:57,360 --> 00:04:00,720
allocation thresholds out to a file for

00:04:00,000 --> 00:04:03,280
the text

00:04:00,720 --> 00:04:05,280
file exporter to read in turning what

00:04:03,280 --> 00:04:08,959
used to be configuration data

00:04:05,280 --> 00:04:10,159
into metrics now with the consistent

00:04:08,959 --> 00:04:12,239
metric name

00:04:10,159 --> 00:04:13,599
consistent metric name of the load or

00:04:12,239 --> 00:04:16,799
the pdu

00:04:13,599 --> 00:04:18,239
and the per pdu thresholds calculating

00:04:16,799 --> 00:04:21,359
the power

00:04:18,239 --> 00:04:23,440
free in each rack is easy from here it's

00:04:21,359 --> 00:04:25,600
simple to even write a tool to query

00:04:23,440 --> 00:04:29,280
prometheus to report

00:04:25,600 --> 00:04:30,080
where new servers new servers should be

00:04:29,280 --> 00:04:32,479
racked

00:04:30,080 --> 00:04:33,600
even the power even if the power load is

00:04:32,479 --> 00:04:36,320
highly very

00:04:33,600 --> 00:04:37,199
variable like it is here we can leverage

00:04:36,320 --> 00:04:38,960
prometheus

00:04:37,199 --> 00:04:40,400
to make better capacity planning

00:04:38,960 --> 00:04:42,560
decisions

00:04:40,400 --> 00:04:45,280
we can even use it to create nice

00:04:42,560 --> 00:04:45,280
dashboards

00:04:45,600 --> 00:04:49,360

YouTube URL: https://www.youtube.com/watch?v=XYGzx_hxMag


