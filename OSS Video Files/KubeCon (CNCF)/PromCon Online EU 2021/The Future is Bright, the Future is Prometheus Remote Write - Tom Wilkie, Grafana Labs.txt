Title: The Future is Bright, the Future is Prometheus Remote Write - Tom Wilkie, Grafana Labs
Publication date: 2021-05-03
Playlist: PromCon Online EU 2021
Description: 
	Donâ€™t miss out! Join us at our upcoming event: KubeCon + CloudNativeCon North America 2021 in Los Angeles, CA from October 12-15. Learn more at https://kubecon.io The conference features presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects.

The Future is Bright, the Future is Prometheus Remote Write - Tom Wilkie, Grafana Labs

"Prometheus remote write was introduced almost 5 years ago as a way for Prometheus to send samples to external storage. Since then the protocol has been implemented by ~30 different metrics systems - and in version 2.25, Prometheus itself accepts remote write!

In this talk we'll discuss the use cases for pushing data to Prometheus via remote write - and more importantly, what it's not meant for. We'll present a more thorough specification of the protocol, and some of the future plans and what a remote write v2 might look like - streaming? metadata? exemplars?"
Captions: 
	00:00:00,080 --> 00:00:05,200
hi everyone welcome to the future is

00:00:02,800 --> 00:00:07,839
bright the future is remote right

00:00:05,200 --> 00:00:08,800
my name is uh tom i'm one of the

00:00:07,839 --> 00:00:11,360
prometheus team

00:00:08,800 --> 00:00:12,880
um and actually primarily work on the

00:00:11,360 --> 00:00:15,120
remote write code

00:00:12,880 --> 00:00:16,800
uh in my day job i'm the vp product at

00:00:15,120 --> 00:00:17,680
grafana labs i'm still trying to figure

00:00:16,800 --> 00:00:20,560
out what that means

00:00:17,680 --> 00:00:21,520
after three years um i also started the

00:00:20,560 --> 00:00:24,400
cortex project

00:00:21,520 --> 00:00:25,760
alongside julius and more recently

00:00:24,400 --> 00:00:28,000
started the loki project

00:00:25,760 --> 00:00:30,080
the kind of prometheus inspired log

00:00:28,000 --> 00:00:32,000
aggregation system

00:00:30,080 --> 00:00:33,440
when i'm not when i'm not coding uh when

00:00:32,000 --> 00:00:35,200
i'm not working i

00:00:33,440 --> 00:00:36,719
like to make 3d printers and

00:00:35,200 --> 00:00:40,719
occasionally uh brew

00:00:36,719 --> 00:00:42,399
brew my own beer so without further ado

00:00:40,719 --> 00:00:43,840
um today i'd like to talk about four

00:00:42,399 --> 00:00:45,920
things right i'd like to talk about

00:00:43,840 --> 00:00:47,440
remote right how did it start what is it

00:00:45,920 --> 00:00:49,520
what is it for

00:00:47,440 --> 00:00:51,360
um i'd like to talk about standardizing

00:00:49,520 --> 00:00:51,840
remote right and a lot of the recent

00:00:51,360 --> 00:00:55,120
effort

00:00:51,840 --> 00:00:58,239
efforts over the last two months to

00:00:55,120 --> 00:00:59,680
define what it means and to test that

00:00:58,239 --> 00:01:01,520
i'd like to talk about what's next or

00:00:59,680 --> 00:01:03,359
what's in the immediate future for

00:01:01,520 --> 00:01:04,960
for the remote right protocol so i'd

00:01:03,359 --> 00:01:08,000
like to talk about metadata

00:01:04,960 --> 00:01:10,560
i'd like to talk about exemplars

00:01:08,000 --> 00:01:12,159
and finally i'd like to talk about uh

00:01:10,560 --> 00:01:14,320
you know further off in the future

00:01:12,159 --> 00:01:15,360
for remote right um some of the ideas

00:01:14,320 --> 00:01:18,000
we've got

00:01:15,360 --> 00:01:19,840
i noticed the slide says exam plus i'd

00:01:18,000 --> 00:01:23,040
love to know what they are

00:01:19,840 --> 00:01:24,400
so what is remote right um

00:01:23,040 --> 00:01:26,080
actually funnily enough the story of

00:01:24,400 --> 00:01:27,280
remote right kind of matches my story

00:01:26,080 --> 00:01:30,240
with prometheus

00:01:27,280 --> 00:01:32,720
the first pr i did to the project was to

00:01:30,240 --> 00:01:37,920
to switch the remote right system

00:01:32,720 --> 00:01:39,680
um from grpc over to protobufs and http

00:01:37,920 --> 00:01:41,040
um this was because it was quite hard at

00:01:39,680 --> 00:01:41,759
the time you know this was almost five

00:01:41,040 --> 00:01:43,439
years ago

00:01:41,759 --> 00:01:45,759
it was quite hard at the time to get uh

00:01:43,439 --> 00:01:47,040
to get grpc to go through um an elastic

00:01:45,759 --> 00:01:49,040
load balancer

00:01:47,040 --> 00:01:51,119
and i wanted to use prometheus remote

00:01:49,040 --> 00:01:53,840
right to send data to

00:01:51,119 --> 00:01:55,759
to cortex and really that is what

00:01:53,840 --> 00:01:57,040
prometheus remote right is for it's for

00:01:55,759 --> 00:02:00,079
sending data

00:01:57,040 --> 00:02:02,320
to other systems prometheus sits there

00:02:00,079 --> 00:02:04,240
scrapes the samples scrapes your job

00:02:02,320 --> 00:02:06,640
scrapes metrics from your instrumented

00:02:04,240 --> 00:02:09,119
applications and exporters

00:02:06,640 --> 00:02:12,400
collects them stores them but can also

00:02:09,119 --> 00:02:14,959
forward them on to other systems

00:02:12,400 --> 00:02:16,160
so we did this um we did this about uh

00:02:14,959 --> 00:02:18,879
five years ago

00:02:16,160 --> 00:02:20,720
um and and over the past five years

00:02:18,879 --> 00:02:23,520
we've seen many vendors

00:02:20,720 --> 00:02:23,840
kind of take notice of prometheus and

00:02:23,520 --> 00:02:26,160
and

00:02:23,840 --> 00:02:28,160
really add support for prometheus remote

00:02:26,160 --> 00:02:29,920
right to their to their products

00:02:28,160 --> 00:02:31,680
um you know they've they've made it so

00:02:29,920 --> 00:02:32,400
that you can send data from prometheus

00:02:31,680 --> 00:02:35,760
to pretty much

00:02:32,400 --> 00:02:36,560
any any of the metrics vendors in in the

00:02:35,760 --> 00:02:38,319
world

00:02:36,560 --> 00:02:40,319
in fact if you look at the prometheus

00:02:38,319 --> 00:02:41,519
docs you'll see there are over 30

00:02:40,319 --> 00:02:43,280
different projects

00:02:41,519 --> 00:02:45,200
um that accepts from the accept

00:02:43,280 --> 00:02:46,720
prometheus remote right or send

00:02:45,200 --> 00:02:48,560
prometheus remote right

00:02:46,720 --> 00:02:50,000
and really kind of it's amazing that

00:02:48,560 --> 00:02:53,760
that only over five years has

00:02:50,000 --> 00:02:55,280
been so popular um

00:02:53,760 --> 00:02:56,879
and we're not resting there you know we

00:02:55,280 --> 00:02:58,560
we really want to kind of push the

00:02:56,879 --> 00:03:01,519
interoperability story

00:02:58,560 --> 00:03:03,280
uh in prometheus as far as it will go

00:03:01,519 --> 00:03:04,800
and more recently uh in the

00:03:03,280 --> 00:03:07,680
not the most recent but the one before

00:03:04,800 --> 00:03:09,920
that release we added the ability to

00:03:07,680 --> 00:03:12,720
actually have prometheus receive

00:03:09,920 --> 00:03:15,200
remote write requests as well so you can

00:03:12,720 --> 00:03:19,040
now configure a prometheus

00:03:15,200 --> 00:03:21,599
to send data from one place to another

00:03:19,040 --> 00:03:23,280
right this really solves the kind of

00:03:21,599 --> 00:03:24,319
global federation problem in a very

00:03:23,280 --> 00:03:26,640
different way

00:03:24,319 --> 00:03:28,239
you know we noticed with with federation

00:03:26,640 --> 00:03:28,879
you know federation is the way you can

00:03:28,239 --> 00:03:32,000
send

00:03:28,879 --> 00:03:33,920
uh you can set up a prometheus to scrape

00:03:32,000 --> 00:03:35,920
the metrics from other prometheus

00:03:33,920 --> 00:03:36,879
servers so this allows you to have a

00:03:35,920 --> 00:03:38,640
prometheus server

00:03:36,879 --> 00:03:40,319
let's say in each region and then a

00:03:38,640 --> 00:03:40,959
global one that scrapes all the data

00:03:40,319 --> 00:03:43,200
from the

00:03:40,959 --> 00:03:44,959
from the regional ones and get that kind

00:03:43,200 --> 00:03:46,799
of central view where you can run your

00:03:44,959 --> 00:03:48,879
kind of central aggregations

00:03:46,799 --> 00:03:50,159
however the challenge here is that this

00:03:48,879 --> 00:03:52,239
requires you know the

00:03:50,159 --> 00:03:53,680
the global prometheus to to be able to

00:03:52,239 --> 00:03:55,360
scrape all the edge ones right so you

00:03:53,680 --> 00:03:56,159
have to open up firewall ports and

00:03:55,360 --> 00:03:59,280
figure out

00:03:56,159 --> 00:03:59,680
ways of uh securing you know three or

00:03:59,280 --> 00:04:02,159
more

00:03:59,680 --> 00:04:04,400
different prometheus servers with the

00:04:02,159 --> 00:04:06,560
the push-based approach coming from

00:04:04,400 --> 00:04:08,799
uh prometheus remote right you only have

00:04:06,560 --> 00:04:10,239
to open up that one central location and

00:04:08,799 --> 00:04:12,239
on and kind of lock down and

00:04:10,239 --> 00:04:14,799
authenticate one central location

00:04:12,239 --> 00:04:16,720
and you can have the edge locations push

00:04:14,799 --> 00:04:18,239
to that central location

00:04:16,720 --> 00:04:19,840
um this might not sound like a big deal

00:04:18,239 --> 00:04:22,960
but imagine if that uh

00:04:19,840 --> 00:04:24,479
these edge locations um were on ip

00:04:22,960 --> 00:04:26,880
addresses that were changing

00:04:24,479 --> 00:04:28,560
or were maybe on flaky networks you know

00:04:26,880 --> 00:04:29,040
the remote right protocol might be a

00:04:28,560 --> 00:04:31,840
better

00:04:29,040 --> 00:04:32,160
a better fit for that so this is in the

00:04:31,840 --> 00:04:34,240
uh

00:04:32,160 --> 00:04:36,160
in the second to latest uh prometheus

00:04:34,240 --> 00:04:37,199
release it's experimental we'd love you

00:04:36,160 --> 00:04:38,720
to give it a go

00:04:37,199 --> 00:04:42,080
see if see what works see what doesn't

00:04:38,720 --> 00:04:44,880
work and see if it suits this use case

00:04:42,080 --> 00:04:48,160
so that's remote right that's how it

00:04:44,880 --> 00:04:49,759
started what it's used for

00:04:48,160 --> 00:04:52,400
what we have noticed with all this

00:04:49,759 --> 00:04:54,720
adoption by by many many people

00:04:52,400 --> 00:04:56,240
is there's been some differences in

00:04:54,720 --> 00:04:57,759
implementation and we want to make sure

00:04:56,240 --> 00:05:00,240
that this ecosystem

00:04:57,759 --> 00:05:01,440
is interoperable and and really that all

00:05:00,240 --> 00:05:02,960
the users of all the different

00:05:01,440 --> 00:05:04,160
components can have the best possible

00:05:02,960 --> 00:05:05,520
experience

00:05:04,160 --> 00:05:07,600
in particular one of the things we've

00:05:05,520 --> 00:05:10,560
noticed is there's

00:05:07,600 --> 00:05:12,479
a bunch of projects popping up that that

00:05:10,560 --> 00:05:13,360
fill this kind of scrape prometheus

00:05:12,479 --> 00:05:15,600
metrics

00:05:13,360 --> 00:05:16,479
and send them else elsewhere using

00:05:15,600 --> 00:05:17,919
remote right

00:05:16,479 --> 00:05:19,680
you know obviously prometheus does that

00:05:17,919 --> 00:05:22,960
uh is the original one

00:05:19,680 --> 00:05:25,199
um about a year or two or a year ago

00:05:22,960 --> 00:05:26,479
we launched the grafana agent which is a

00:05:25,199 --> 00:05:28,639
kind of stripped-down version of

00:05:26,479 --> 00:05:30,320
prometheus using all the same code

00:05:28,639 --> 00:05:31,600
but kind of stripped down lighter weight

00:05:30,320 --> 00:05:33,039
version that doesn't have any local

00:05:31,600 --> 00:05:35,120
storage you can't do queries

00:05:33,039 --> 00:05:36,320
but it will just scrape your jobs and

00:05:35,120 --> 00:05:38,800
send them

00:05:36,320 --> 00:05:40,560
using remote right there's also the

00:05:38,800 --> 00:05:42,800
victoria metrics agent

00:05:40,560 --> 00:05:43,600
uh influx's telegraph will scrape

00:05:42,800 --> 00:05:45,919
prometheus

00:05:43,600 --> 00:05:46,880
scrape jobs instrumented with prometheus

00:05:45,919 --> 00:05:48,880
metrics

00:05:46,880 --> 00:05:51,360
and send them elsewhere using remote

00:05:48,880 --> 00:05:53,199
right and then more recently you've got

00:05:51,360 --> 00:05:55,120
open telemetry which will also scrape

00:05:53,199 --> 00:05:57,039
jobs using prometheus metrics and send

00:05:55,120 --> 00:05:58,479
them over remote right

00:05:57,039 --> 00:06:00,400
so these are the five systems that i'm

00:05:58,479 --> 00:06:02,960
going to look at and you know

00:06:00,400 --> 00:06:04,960
there are other systems i have to kind

00:06:02,960 --> 00:06:07,759
of slip in at least one meme into each

00:06:04,960 --> 00:06:10,319
of my talks

00:06:07,759 --> 00:06:12,639
so we started this effort to standardize

00:06:10,319 --> 00:06:15,440
it right we

00:06:12,639 --> 00:06:16,720
we wanted a document that described what

00:06:15,440 --> 00:06:18,560
prometheus remote right

00:06:16,720 --> 00:06:20,080
was what it meant to say you were

00:06:18,560 --> 00:06:21,440
compatible with that

00:06:20,080 --> 00:06:23,280
we also wanted to explain a lot of the

00:06:21,440 --> 00:06:24,720
reasoning behind the decisions why we've

00:06:23,280 --> 00:06:27,120
done it this way

00:06:24,720 --> 00:06:28,319
it wasn't all just arbitrary and finally

00:06:27,120 --> 00:06:30,880
we wanted to give some

00:06:28,319 --> 00:06:32,639
thought to how would we future proof

00:06:30,880 --> 00:06:34,639
this protocol how would we upgrade this

00:06:32,639 --> 00:06:37,280
protocol how would we make it so that

00:06:34,639 --> 00:06:39,280
when we introduced a v2 we could be kind

00:06:37,280 --> 00:06:40,880
of backwards compatible

00:06:39,280 --> 00:06:42,639
i'm hoping that this will allow us to

00:06:40,880 --> 00:06:44,400
remove the experimental flag from

00:06:42,639 --> 00:06:46,080
prometheus remote right

00:06:44,400 --> 00:06:47,280
one of the key things here is that we're

00:06:46,080 --> 00:06:48,560
not changing anything with this

00:06:47,280 --> 00:06:50,639
standardization

00:06:48,560 --> 00:06:52,479
uh we're just documenting the current

00:06:50,639 --> 00:06:53,840
behavior how it currently works

00:06:52,479 --> 00:06:55,360
because there's so many people that use

00:06:53,840 --> 00:06:56,319
this that i don't think realistically we

00:06:55,360 --> 00:07:00,240
can change it

00:06:56,319 --> 00:07:01,599
uh at least not in a uh incompatible way

00:07:00,240 --> 00:07:02,960
you know this will also allow us to

00:07:01,599 --> 00:07:03,599
offer some kind of compatibility

00:07:02,960 --> 00:07:04,880
guarantee

00:07:03,599 --> 00:07:06,240
and i just want to say a big thank you

00:07:04,880 --> 00:07:07,599
to everyone in the community who's

00:07:06,240 --> 00:07:09,520
commented on the doc

00:07:07,599 --> 00:07:11,280
who's proposed changes it's really been

00:07:09,520 --> 00:07:12,800
a big team effort

00:07:11,280 --> 00:07:15,039
so now that we have this standard it's

00:07:12,800 --> 00:07:15,520
time to test those those agents that i

00:07:15,039 --> 00:07:18,639
mentioned

00:07:15,520 --> 00:07:20,720
against this standard and to that end uh

00:07:18,639 --> 00:07:21,759
over the last week or two i've built a

00:07:20,720 --> 00:07:23,599
test harness

00:07:21,759 --> 00:07:25,680
that runs an instance of each of the

00:07:23,599 --> 00:07:26,400
agents exports some metrics for them to

00:07:25,680 --> 00:07:28,000
scrape

00:07:26,400 --> 00:07:30,240
and then configures them to send that

00:07:28,000 --> 00:07:31,599
data back to the test harness via remote

00:07:30,240 --> 00:07:33,360
write

00:07:31,599 --> 00:07:35,360
we then in the test harness in you know

00:07:33,360 --> 00:07:38,160
export various different metrics and

00:07:35,360 --> 00:07:39,919
and you know test examine the the

00:07:38,160 --> 00:07:41,680
response we get over a remote right and

00:07:39,919 --> 00:07:43,440
check it matches what we expect

00:07:41,680 --> 00:07:44,720
you know and you know this is relatively

00:07:43,440 --> 00:07:46,800
straightforward you know we export

00:07:44,720 --> 00:07:48,160
a counter we check we get a counter back

00:07:46,800 --> 00:07:50,240
we export a histogram

00:07:48,160 --> 00:07:52,319
we check we get a histogram back but

00:07:50,240 --> 00:07:53,759
there's a lot of nuance to this protocol

00:07:52,319 --> 00:07:56,080
there's a lot of different areas which

00:07:53,759 --> 00:07:58,639
some people do or don't implement and so

00:07:56,080 --> 00:08:00,879
we wanted to kind of figure out what

00:07:58,639 --> 00:08:03,039
level of coverage we had

00:08:00,879 --> 00:08:04,400
these are early results um you know i'm

00:08:03,039 --> 00:08:06,080
filming this talk

00:08:04,400 --> 00:08:07,440
uh almost a month before you'll be

00:08:06,080 --> 00:08:09,360
watching it so

00:08:07,440 --> 00:08:11,280
hopefully uh over the course of the next

00:08:09,360 --> 00:08:13,199
month some of these vendors

00:08:11,280 --> 00:08:14,960
and some of these other projects will

00:08:13,199 --> 00:08:16,319
improve their compatibility with remote

00:08:14,960 --> 00:08:17,919
right and we're actively working with

00:08:16,319 --> 00:08:19,280
all of them to do that

00:08:17,919 --> 00:08:21,120
so to start with obviously we have

00:08:19,280 --> 00:08:22,160
prometheus right prometheus implements

00:08:21,120 --> 00:08:24,479
all of remote right

00:08:22,160 --> 00:08:26,000
the specification is just a document

00:08:24,479 --> 00:08:27,759
that describes what prometheus does

00:08:26,000 --> 00:08:30,560
so we'd expect it to pass all these

00:08:27,759 --> 00:08:32,719
tests the grafana agent using all the

00:08:30,560 --> 00:08:35,519
same code that prometheus uses

00:08:32,719 --> 00:08:37,519
um just implements the same thing right

00:08:35,519 --> 00:08:40,719
and again we kind of expect it

00:08:37,519 --> 00:08:42,240
to pass all the tests interestingly uh

00:08:40,719 --> 00:08:44,240
we found a bug in the grafana agent

00:08:42,240 --> 00:08:47,760
using this test suite uh it turns out

00:08:44,240 --> 00:08:49,120
we were not removing uh duplicate labels

00:08:47,760 --> 00:08:52,000
um so we fixed that in the point one

00:08:49,120 --> 00:08:54,160
release it was it was one line of code

00:08:52,000 --> 00:08:55,120
the victoria metrics agent does pretty

00:08:54,160 --> 00:08:58,000
well actually

00:08:55,120 --> 00:08:59,519
um it does everything it has some slight

00:08:58,000 --> 00:09:01,120
inconsistencies around how it does the

00:08:59,519 --> 00:09:03,600
up metric it doesn't actually

00:09:01,120 --> 00:09:04,399
um as far as we can tell send the up

00:09:03,600 --> 00:09:06,240
metric

00:09:04,399 --> 00:09:07,600
when there's a failed scrape which is

00:09:06,240 --> 00:09:08,240
kind of important for the test harness

00:09:07,600 --> 00:09:10,320
to set

00:09:08,240 --> 00:09:12,080
to to tell the difference between the

00:09:10,320 --> 00:09:13,200
agent not doing anything and the agent

00:09:12,080 --> 00:09:16,000
successfully

00:09:13,200 --> 00:09:17,440
kind of failing um and also the victoria

00:09:16,000 --> 00:09:19,040
metrics agent doesn't implement the

00:09:17,440 --> 00:09:20,880
staleness markers which are really

00:09:19,040 --> 00:09:24,959
important way we can tell

00:09:20,880 --> 00:09:27,040
when metrics go away telegraph

00:09:24,959 --> 00:09:28,959
not quite as not quite as complete as a

00:09:27,040 --> 00:09:31,440
victoria metric agent in general

00:09:28,959 --> 00:09:32,080
it doesn't do up or staleness at all but

00:09:31,440 --> 00:09:33,680
it

00:09:32,080 --> 00:09:36,000
you know it doesn't quite have the right

00:09:33,680 --> 00:09:37,360
job labels there you can program it to

00:09:36,000 --> 00:09:39,200
add job labels

00:09:37,360 --> 00:09:40,959
um but it's kind of missing some of the

00:09:39,200 --> 00:09:41,519
features of service discovery that

00:09:40,959 --> 00:09:44,480
require

00:09:41,519 --> 00:09:46,080
that would add those job labels then

00:09:44,480 --> 00:09:47,839
finally the open telemetry collectors

00:09:46,080 --> 00:09:50,000
the newest kid on the block so

00:09:47,839 --> 00:09:51,360
not not not as far along in its support

00:09:50,000 --> 00:09:52,160
it doesn't propagate histograms

00:09:51,360 --> 00:09:53,760
correctly

00:09:52,160 --> 00:09:55,839
doesn't do a lot of the job labels

00:09:53,760 --> 00:09:58,640
correctly no up metric

00:09:55,839 --> 00:10:00,320
uh no no stillness markers we're

00:09:58,640 --> 00:10:03,440
actively working with

00:10:00,320 --> 00:10:04,079
the open telemetry team to try and get

00:10:03,440 --> 00:10:05,360
better

00:10:04,079 --> 00:10:07,360
uh better support and hopefully in a

00:10:05,360 --> 00:10:09,040
month or so um we can

00:10:07,360 --> 00:10:10,720
we'll see if they've got better support

00:10:09,040 --> 00:10:12,399
i'll be i'll be hanging around for a

00:10:10,720 --> 00:10:13,279
kind of live q a at the end and i'll

00:10:12,399 --> 00:10:17,279
make sure i

00:10:13,279 --> 00:10:17,279
i bring uh updated results for that

00:10:17,760 --> 00:10:22,480
so next uh metadata and uh exemplars not

00:10:21,279 --> 00:10:25,600
exam plus

00:10:22,480 --> 00:10:26,800
um so first metadata not a lot of people

00:10:25,600 --> 00:10:30,240
know actually that

00:10:26,800 --> 00:10:32,000
that prometheus exports um prometheus uh

00:10:30,240 --> 00:10:33,279
client libraries allow you to add kind

00:10:32,000 --> 00:10:35,760
of help text and

00:10:33,279 --> 00:10:37,200
and and type metadata uh to every metric

00:10:35,760 --> 00:10:40,000
in your application

00:10:37,200 --> 00:10:41,680
and uh prometheus scrapes this and

00:10:40,000 --> 00:10:42,959
stores this in memory stores the latest

00:10:41,680 --> 00:10:45,200
values in memory

00:10:42,959 --> 00:10:46,720
and then has an api so the the client

00:10:45,200 --> 00:10:48,240
library their client applications to

00:10:46,720 --> 00:10:50,880
prometheus like grafana or

00:10:48,240 --> 00:10:52,320
or the prometheus ui can can query this

00:10:50,880 --> 00:10:53,200
and use it to help build these kind of

00:10:52,320 --> 00:10:55,279
uis

00:10:53,200 --> 00:10:56,880
um so grafana builds this particular ui

00:10:55,279 --> 00:10:58,480
just allowing you to see what each each

00:10:56,880 --> 00:11:01,519
metric is

00:10:58,480 --> 00:11:03,120
we want to enable um systems that

00:11:01,519 --> 00:11:04,720
implement remote right to have the same

00:11:03,120 --> 00:11:05,920
information and basically the same

00:11:04,720 --> 00:11:09,519
experience

00:11:05,920 --> 00:11:12,880
uh as prometheus and so back in

00:11:09,519 --> 00:11:16,079
uh february last year so over a year ago

00:11:12,880 --> 00:11:17,200
josh added support for um uh metadata to

00:11:16,079 --> 00:11:18,959
the remote right protocol

00:11:17,200 --> 00:11:20,640
so it's an extra field and it's kind of

00:11:18,959 --> 00:11:22,160
a bit best effort right we're

00:11:20,640 --> 00:11:23,920
we're taking some of the metadata and

00:11:22,160 --> 00:11:26,800
sending it on a period

00:11:23,920 --> 00:11:28,000
alongside your samples we want to make a

00:11:26,800 --> 00:11:29,360
series of improvements to this

00:11:28,000 --> 00:11:31,360
we want to write the metadata to the

00:11:29,360 --> 00:11:33,279
right head log we want to send it

00:11:31,360 --> 00:11:34,800
alongside the same metrics that it's

00:11:33,279 --> 00:11:35,519
supposed to be sent with instead of just

00:11:34,800 --> 00:11:38,399
kind of

00:11:35,519 --> 00:11:39,920
arbitrarily sharding it um and and rob

00:11:38,399 --> 00:11:41,519
from uh from chronosphere

00:11:39,920 --> 00:11:42,959
actually has a pr that achieves some of

00:11:41,519 --> 00:11:46,079
this that we want to work with him to

00:11:42,959 --> 00:11:49,279
get in over the next few months

00:11:46,079 --> 00:11:51,360
so the next example um we want to give

00:11:49,279 --> 00:11:53,600
is exemplars right spelled correctly

00:11:51,360 --> 00:11:56,000
this time in exemplars

00:11:53,600 --> 00:11:56,639
allow you in grafana to to overlay kind

00:11:56,000 --> 00:11:58,399
of dots

00:11:56,639 --> 00:12:00,320
on a graph and then when you click on

00:11:58,399 --> 00:12:02,240
one of those dots one of those exemplars

00:12:00,320 --> 00:12:04,160
you can jump straight to the trace that

00:12:02,240 --> 00:12:07,200
that dot kind of represents

00:12:04,160 --> 00:12:09,279
right so so bjorn added exemplar support

00:12:07,200 --> 00:12:12,000
to client golang quite a while ago

00:12:09,279 --> 00:12:14,560
and callum added exemplar support to um

00:12:12,000 --> 00:12:16,160
to prometheus in the last release

00:12:14,560 --> 00:12:17,839
and together you can implement this

00:12:16,160 --> 00:12:19,360
really cool experience that really

00:12:17,839 --> 00:12:20,959
speeds up kind of

00:12:19,360 --> 00:12:23,200
incident response and debugging

00:12:20,959 --> 00:12:24,000
workflows and and really kind of makes

00:12:23,200 --> 00:12:26,880
the whole system feel

00:12:24,000 --> 00:12:28,399
a lot more integrated prometheus doesn't

00:12:26,880 --> 00:12:30,079
actually care where these traces are

00:12:28,399 --> 00:12:31,519
stored you can store them in jager

00:12:30,079 --> 00:12:33,839
you can store them in zipkin or you can

00:12:31,519 --> 00:12:37,120
store them in grafana tempo itself

00:12:33,839 --> 00:12:40,880
um we want to make this available

00:12:37,120 --> 00:12:42,320
to uh to remote right endpoints to to

00:12:40,880 --> 00:12:44,079
people who are implementing remote right

00:12:42,320 --> 00:12:44,399
should also be able to receive exemplars

00:12:44,079 --> 00:12:46,079
and

00:12:44,399 --> 00:12:47,519
and offer the same apis in the same

00:12:46,079 --> 00:12:50,079
experience

00:12:47,519 --> 00:12:51,279
and to that end callum from grafana labs

00:12:50,079 --> 00:12:54,079
he is adding

00:12:51,279 --> 00:12:54,480
uh a remote right uh for example so this

00:12:54,079 --> 00:12:56,160
is

00:12:54,480 --> 00:12:58,000
gonna be writing the exemplars to the

00:12:56,160 --> 00:12:58,800
right ahead log and then tailing that

00:12:58,000 --> 00:13:01,200
right head log

00:12:58,800 --> 00:13:03,839
is is as part of the remote right code

00:13:01,200 --> 00:13:05,440
and and sending them out in batches

00:13:03,839 --> 00:13:07,040
this will also enable kind of long-term

00:13:05,440 --> 00:13:08,720
storage of exemplars and

00:13:07,040 --> 00:13:10,880
and some really cool use cases around

00:13:08,720 --> 00:13:12,480
that callum assures me this is going to

00:13:10,880 --> 00:13:13,760
be merged by the time you uh you're

00:13:12,480 --> 00:13:15,040
listening to this talk

00:13:13,760 --> 00:13:18,839
and and we really hope that this is

00:13:15,040 --> 00:13:20,320
going to be in the next major release of

00:13:18,839 --> 00:13:23,600
prometheus

00:13:20,320 --> 00:13:25,360
so finally what's next what are the kind

00:13:23,600 --> 00:13:27,760
of more long-term things we want to do

00:13:25,360 --> 00:13:29,120
with uh with remote right

00:13:27,760 --> 00:13:31,600
first thing i want to talk about is

00:13:29,120 --> 00:13:33,120
atomicity so prometheus has this really

00:13:31,600 --> 00:13:35,839
cool guarantee that

00:13:33,120 --> 00:13:38,079
um sorry before i go into the guarantee

00:13:35,839 --> 00:13:40,240
a lot of you will know that prometheus

00:13:38,079 --> 00:13:41,600
metrics are normally you know sometimes

00:13:40,240 --> 00:13:42,880
composite and actually made up of

00:13:41,600 --> 00:13:44,240
multiple time series

00:13:42,880 --> 00:13:46,160
you know the example here being a

00:13:44,240 --> 00:13:47,920
histogram which is made up of uh

00:13:46,160 --> 00:13:49,839
time series per bucket alongside a kind

00:13:47,920 --> 00:13:52,480
of a count and a sum

00:13:49,839 --> 00:13:54,240
time series um this is this is kind of

00:13:52,480 --> 00:13:55,120
how we build up these histograms and how

00:13:54,240 --> 00:13:57,040
we can tell

00:13:55,120 --> 00:13:58,959
latencies in your application and so

00:13:57,040 --> 00:14:01,040
it's really important that

00:13:58,959 --> 00:14:02,000
when you run a query you only see a

00:14:01,040 --> 00:14:03,760
complete scrape

00:14:02,000 --> 00:14:05,519
you see a consistent snapshot of a

00:14:03,760 --> 00:14:06,720
scrape you don't you don't see kind of

00:14:05,519 --> 00:14:08,480
partial data or

00:14:06,720 --> 00:14:10,560
half updates from one scrape and half

00:14:08,480 --> 00:14:13,680
updates from another scrape

00:14:10,560 --> 00:14:15,519
um prometheus offers this right it's

00:14:13,680 --> 00:14:16,399
it's quite a cool feature of tsdb and

00:14:15,519 --> 00:14:19,040
it's uh it's

00:14:16,399 --> 00:14:20,560
it's really uh really useful remote

00:14:19,040 --> 00:14:21,040
right unfortunately doesn't do this

00:14:20,560 --> 00:14:22,959
actually

00:14:21,040 --> 00:14:24,800
prevents systems from from offering this

00:14:22,959 --> 00:14:25,279
guarantee because of the way the remote

00:14:24,800 --> 00:14:27,440
right

00:14:25,279 --> 00:14:28,480
uh the remote right client inside

00:14:27,440 --> 00:14:31,440
prometheus

00:14:28,480 --> 00:14:32,639
um splits up uh batches of requests to

00:14:31,440 --> 00:14:34,639
send them in parallel

00:14:32,639 --> 00:14:37,199
right so this means that you you know

00:14:34,639 --> 00:14:39,519
remote right systems might actually get

00:14:37,199 --> 00:14:41,600
um metrics or samples for different

00:14:39,519 --> 00:14:42,399
series within a histogram in in a

00:14:41,600 --> 00:14:43,680
different order

00:14:42,399 --> 00:14:46,000
right and we'll actually see these

00:14:43,680 --> 00:14:48,160
partial states this means they don't

00:14:46,000 --> 00:14:50,399
have the opportunity to implement this

00:14:48,160 --> 00:14:52,320
um which we we think kind of sucks right

00:14:50,399 --> 00:14:53,199
so we want to fix this we we haven't

00:14:52,320 --> 00:14:55,120
decided yet

00:14:53,199 --> 00:14:57,040
how we're going to fix this you know one

00:14:55,120 --> 00:14:58,800
of the thoughts is that we're going to

00:14:57,040 --> 00:15:00,240
make sure that this scrape the entire

00:14:58,800 --> 00:15:02,480
batch of samples

00:15:00,240 --> 00:15:04,160
that are gathered in a single scrape are

00:15:02,480 --> 00:15:05,920
written to the right head log in a

00:15:04,160 --> 00:15:06,959
single batch which is kind of already

00:15:05,920 --> 00:15:09,839
the case

00:15:06,959 --> 00:15:11,680
but then the the the remote right system

00:15:09,839 --> 00:15:14,800
reads that entire batch in

00:15:11,680 --> 00:15:17,680
a single um in a single kind of scrape

00:15:14,800 --> 00:15:17,920
in a single read of the writehead log

00:15:17,680 --> 00:15:19,760
and

00:15:17,920 --> 00:15:21,360
sends it out to the remote system in a

00:15:19,760 --> 00:15:23,120
single batch as well

00:15:21,360 --> 00:15:24,959
and so kind of aligning this throughout

00:15:23,120 --> 00:15:27,600
the entire pipeline will

00:15:24,959 --> 00:15:28,959
will at least give the kind of uh the

00:15:27,600 --> 00:15:31,279
systems at the other end of the remote

00:15:28,959 --> 00:15:34,399
right will give them the opportunity

00:15:31,279 --> 00:15:36,000
to uh to offer atomicity

00:15:34,399 --> 00:15:37,839
um another thing we're working on

00:15:36,000 --> 00:15:38,480
solving is kind of or improving at least

00:15:37,839 --> 00:15:40,800
is that

00:15:38,480 --> 00:15:41,519
the handling of four to nine so four to

00:15:40,800 --> 00:15:43,279
nine is the

00:15:41,519 --> 00:15:45,360
is the status code that remote systems

00:15:43,279 --> 00:15:47,600
will send when prometheus is sending

00:15:45,360 --> 00:15:48,959
samples to them too quickly it's 429 is

00:15:47,600 --> 00:15:52,480
kind of rate limit is a back off

00:15:48,959 --> 00:15:54,639
right so prometheus is is designed to

00:15:52,480 --> 00:15:56,480
back off and retry on 500s

00:15:54,639 --> 00:15:58,000
now 500s indicate there was something

00:15:56,480 --> 00:15:58,959
wrong with the system you know it's the

00:15:58,000 --> 00:16:00,880
server's fault

00:15:58,959 --> 00:16:02,079
we couldn't handle the request you know

00:16:00,880 --> 00:16:04,720
please try again

00:16:02,079 --> 00:16:06,320
um but but prometheus doesn't retry

00:16:04,720 --> 00:16:07,920
400's right and it that's on purpose

00:16:06,320 --> 00:16:09,120
because 400s indicate there's something

00:16:07,920 --> 00:16:11,199
wrong with the request

00:16:09,120 --> 00:16:12,399
right and that request will not succeed

00:16:11,199 --> 00:16:14,079
if you try it again

00:16:12,399 --> 00:16:15,519
in particular like 400 might be an

00:16:14,079 --> 00:16:17,279
invalid request like it's just gibberish

00:16:15,519 --> 00:16:19,600
like please don't send me gibberish

00:16:17,279 --> 00:16:21,440
you know it might be that the you know

00:16:19,600 --> 00:16:22,880
you've hit some limits on the

00:16:21,440 --> 00:16:24,000
total number of series there's no point

00:16:22,880 --> 00:16:24,639
in trying again because you've hit these

00:16:24,000 --> 00:16:27,199
limits

00:16:24,639 --> 00:16:28,320
and it's weird i think that 429 is a is

00:16:27,199 --> 00:16:30,720
a

00:16:28,320 --> 00:16:32,399
is a is a rate limit right because you

00:16:30,720 --> 00:16:33,360
know actually if you back off and retry

00:16:32,399 --> 00:16:34,959
the 429

00:16:33,360 --> 00:16:36,720
uh the request that received a 429

00:16:34,959 --> 00:16:38,720
response might actually succeed

00:16:36,720 --> 00:16:39,920
either way what happens is you know we

00:16:38,720 --> 00:16:41,759
talked about how prometheus

00:16:39,920 --> 00:16:43,519
is uh collecting data from your

00:16:41,759 --> 00:16:44,560
applications and writing them to a write

00:16:43,519 --> 00:16:46,320
head log and then

00:16:44,560 --> 00:16:47,839
reading that right head log and sending

00:16:46,320 --> 00:16:49,839
it to a remote system

00:16:47,839 --> 00:16:51,600
and if that if that if there's a network

00:16:49,839 --> 00:16:52,880
outage or a heaven forbid an outage on

00:16:51,600 --> 00:16:54,720
the remote system

00:16:52,880 --> 00:16:56,800
um then that will start to buffer up on

00:16:54,720 --> 00:16:58,000
disk right and these samples will buff

00:16:56,800 --> 00:17:00,079
on disk

00:16:58,000 --> 00:17:01,759
and prometheus will basically wait you

00:17:00,079 --> 00:17:04,240
know periodically retrying

00:17:01,759 --> 00:17:05,360
but wait for um wait for the system to

00:17:04,240 --> 00:17:07,039
come back up

00:17:05,360 --> 00:17:08,959
and then after that outage prometheus

00:17:07,039 --> 00:17:12,079
will try and replay that right head log

00:17:08,959 --> 00:17:13,679
to the remote system to fill in any gaps

00:17:12,079 --> 00:17:15,600
you know prometheus will replay as

00:17:13,679 --> 00:17:16,559
quickly as it can and it can replay

00:17:15,600 --> 00:17:18,720
pretty quickly

00:17:16,559 --> 00:17:20,240
so it replays many many many samples and

00:17:18,720 --> 00:17:21,919
that upstream system

00:17:20,240 --> 00:17:24,160
sent a 429 saying you're replaying too

00:17:21,919 --> 00:17:26,559
quickly at that point

00:17:24,160 --> 00:17:27,679
prometheus will basically just uh drop

00:17:26,559 --> 00:17:29,440
the data

00:17:27,679 --> 00:17:31,039
so after after doing all this really

00:17:29,440 --> 00:17:32,799
hard work to

00:17:31,039 --> 00:17:34,640
to batch up the you know to buffer up

00:17:32,799 --> 00:17:35,200
the data on disk and and make sure it's

00:17:34,640 --> 00:17:37,360
there for

00:17:35,200 --> 00:17:38,640
you know during the period of the outage

00:17:37,360 --> 00:17:40,960
when the system comes back

00:17:38,640 --> 00:17:42,640
we replay 429 and drop the data and it's

00:17:40,960 --> 00:17:45,840
a real shame we do this so

00:17:42,640 --> 00:17:47,520
we think we can improve this by backing

00:17:45,840 --> 00:17:50,799
off on four two nines and

00:17:47,520 --> 00:17:52,960
and knowing when to kind of balance um

00:17:50,799 --> 00:17:54,640
you know catching up against kind of

00:17:52,960 --> 00:17:56,320
falling behind because

00:17:54,640 --> 00:18:00,640
you know you never want a system to kind

00:17:56,320 --> 00:18:02,640
of get behind and stay behind so finally

00:18:00,640 --> 00:18:02,880
and another area we're actively looking

00:18:02,640 --> 00:18:04,880
in

00:18:02,880 --> 00:18:06,960
uh and investigating and looking at

00:18:04,880 --> 00:18:09,360
improvements for the remote write system

00:18:06,960 --> 00:18:11,039
is its bandwidth usage you know i i

00:18:09,360 --> 00:18:13,200
perhaps touched on a bit earlier how we

00:18:11,039 --> 00:18:15,200
designed the system to be pretty

00:18:13,200 --> 00:18:16,720
pretty simple pretty stateless right and

00:18:15,200 --> 00:18:18,799
this is a key principle that

00:18:16,720 --> 00:18:20,080
i think has really made the protocol

00:18:18,799 --> 00:18:21,919
easy to implement

00:18:20,080 --> 00:18:24,480
right there are no interdependencies

00:18:21,919 --> 00:18:26,080
between messages in the protocol

00:18:24,480 --> 00:18:28,320
and this simply just drastically

00:18:26,080 --> 00:18:30,080
simplifies downstream implementations

00:18:28,320 --> 00:18:31,520
it makes things like cortex easy to

00:18:30,080 --> 00:18:34,960
write it makes the

00:18:31,520 --> 00:18:37,120
um the adapters between prometheus

00:18:34,960 --> 00:18:39,600
and graphite and prometheus and influx

00:18:37,120 --> 00:18:40,559
it makes those adapters simple to write

00:18:39,600 --> 00:18:42,720
and i think this has been pretty

00:18:40,559 --> 00:18:43,919
successful um you know we've seen as i

00:18:42,720 --> 00:18:46,559
said 30 different

00:18:43,919 --> 00:18:47,679
uh implementations of remote right and i

00:18:46,559 --> 00:18:48,880
think one of those

00:18:47,679 --> 00:18:50,640
one of the reasons this has been

00:18:48,880 --> 00:18:51,520
successful is because it's a relatively

00:18:50,640 --> 00:18:54,880
simple process

00:18:51,520 --> 00:18:56,720
protocol however

00:18:54,880 --> 00:18:58,160
this comes with downsides right it's

00:18:56,720 --> 00:19:00,320
expensive right the

00:18:58,160 --> 00:19:02,000
the fact that the batches are stateless

00:19:00,320 --> 00:19:03,840
means that they have to repeat labels

00:19:02,000 --> 00:19:04,240
many many times you know the same label

00:19:03,840 --> 00:19:06,640
was

00:19:04,240 --> 00:19:08,400
sent in most batches and this really

00:19:06,640 --> 00:19:09,440
eats bandwidth you know we used between

00:19:08,400 --> 00:19:12,240
10 and 20

00:19:09,440 --> 00:19:13,120
bytes per sample to send via remote

00:19:12,240 --> 00:19:16,160
right and

00:19:13,120 --> 00:19:18,559
prometheus only uses one or two bytes

00:19:16,160 --> 00:19:19,200
per sample on local disks so you can see

00:19:18,559 --> 00:19:22,240
there's a big

00:19:19,200 --> 00:19:24,080
big room for for improvement here

00:19:22,240 --> 00:19:26,400
and our internal monitoring at grafana

00:19:24,080 --> 00:19:28,240
labs um just to propagate samples

00:19:26,400 --> 00:19:28,480
between our internal prometheus nodes

00:19:28,240 --> 00:19:30,880
and

00:19:28,480 --> 00:19:31,520
and our internal cortex cluster we're

00:19:30,880 --> 00:19:34,000
doing over

00:19:31,520 --> 00:19:34,799
over 90 megabytes a second of remote

00:19:34,000 --> 00:19:36,559
right

00:19:34,799 --> 00:19:39,200
so there's there's probably a 10x gain

00:19:36,559 --> 00:19:40,559
here and there's various ideas we think

00:19:39,200 --> 00:19:42,720
a lot of the work we're going to do on

00:19:40,559 --> 00:19:44,400
atomicity and and batching and you know

00:19:42,720 --> 00:19:46,160
building these consistent batches

00:19:44,400 --> 00:19:48,960
will allow us to have a kind of symbol

00:19:46,160 --> 00:19:52,240
table in the in the remote right

00:19:48,960 --> 00:19:54,320
um requests that that will probably

00:19:52,240 --> 00:19:56,080
reduce reduce bandwidth usage quite a

00:19:54,320 --> 00:19:57,840
lot

00:19:56,080 --> 00:19:59,360
and that's it really you know we've

00:19:57,840 --> 00:20:00,400
covered kind of what is remote right

00:19:59,360 --> 00:20:03,440
what's the history

00:20:00,400 --> 00:20:05,200
why does it exist how did it start um

00:20:03,440 --> 00:20:07,039
we've covered our efforts over the last

00:20:05,200 --> 00:20:07,679
couple of months to standardize remote

00:20:07,039 --> 00:20:09,600
right to

00:20:07,679 --> 00:20:10,960
really document how it works why it

00:20:09,600 --> 00:20:13,200
works that way and then

00:20:10,960 --> 00:20:16,159
test implementations to make sure that

00:20:13,200 --> 00:20:17,840
they work this the way they should

00:20:16,159 --> 00:20:19,520
we talked about what's coming kind of

00:20:17,840 --> 00:20:21,280
you know pretty soon hopefully in the

00:20:19,520 --> 00:20:22,000
next release or two of prometheus we

00:20:21,280 --> 00:20:24,240
should

00:20:22,000 --> 00:20:25,679
uh improve the way we send metadata via

00:20:24,240 --> 00:20:26,720
remote right and and start sending

00:20:25,679 --> 00:20:29,280
exemplars

00:20:26,720 --> 00:20:31,039
right and finally we've talked about

00:20:29,280 --> 00:20:32,240
some of the ideas we have for the more

00:20:31,039 --> 00:20:34,159
long-term future

00:20:32,240 --> 00:20:36,400
how we want to make it uh remote right

00:20:34,159 --> 00:20:38,559
atomic how we want to

00:20:36,400 --> 00:20:40,559
uh deal with back off and retry on four

00:20:38,559 --> 00:20:40,880
two nines and and how we want to reduce

00:20:40,559 --> 00:20:44,080
the

00:20:40,880 --> 00:20:45,679
bandwidth consumption of remote right

00:20:44,080 --> 00:20:47,679
so i'm gonna i'm gonna hang around now

00:20:45,679 --> 00:20:49,840
um take some live questions

00:20:47,679 --> 00:20:50,960
if any of this was interesting please do

00:20:49,840 --> 00:20:56,720
please do ask and

00:20:50,960 --> 00:20:56,720

YouTube URL: https://www.youtube.com/watch?v=vMeCyX3Y3HY


