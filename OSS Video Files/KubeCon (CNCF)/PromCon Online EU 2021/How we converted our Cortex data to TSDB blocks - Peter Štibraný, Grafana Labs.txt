Title: How we converted our Cortex data to TSDB blocks - Peter Štibraný, Grafana Labs
Publication date: 2021-05-03
Playlist: PromCon Online EU 2021
Description: 
	Don’t miss out! Join us at our upcoming event: KubeCon + CloudNativeCon North America 2021 in Los Angeles, CA from October 12-15. Learn more at https://kubecon.io The conference features presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects.

How we converted our Cortex data to TSDB blocks - Peter Štibraný, Grafana Labs

Cortex has recently gained support for storing data in Prometheus TSDB format (using so-called "blocks engine", also reusing some parts of Thanos). In Grafana Labs, we had hundreds of terabytes of data in previous format, and we wrote scalable tooling to convert it all to TSDB blocks. In the talk, I would like to present the tooling, show some details from Prometheus TSDB internals, and show how simple it is to generate TSDB blocks using Go code and what pitfalls to avoid.
Captions: 
	00:00:00,080 --> 00:00:04,000
hello and welcome to my talk about how

00:00:02,000 --> 00:00:07,120
we converted our cortex data

00:00:04,000 --> 00:00:09,120
to tsdb blocks i am peter and i work as

00:00:07,120 --> 00:00:12,240
software engineer at grafana labs

00:00:09,120 --> 00:00:14,000
where i work on the cortex project for

00:00:12,240 --> 00:00:14,960
those of you who are not familiar with

00:00:14,000 --> 00:00:17,840
cortex

00:00:14,960 --> 00:00:19,279
here is a short introduction cortex is a

00:00:17,840 --> 00:00:22,080
horizontally scalable

00:00:19,279 --> 00:00:23,920
highly available multi-tenant long-term

00:00:22,080 --> 00:00:26,160
storage for prometheus that provides

00:00:23,920 --> 00:00:27,439
global view across all of your permit

00:00:26,160 --> 00:00:30,400
use data

00:00:27,439 --> 00:00:32,399
cortex features blazing fast queries and

00:00:30,400 --> 00:00:33,600
is hundred percent compatible with prom

00:00:32,399 --> 00:00:35,600
ql

00:00:33,600 --> 00:00:37,840
cortex is currently an incubating

00:00:35,600 --> 00:00:40,800
project at cncf

00:00:37,840 --> 00:00:43,200
in short cortex acts as remote right

00:00:40,800 --> 00:00:46,399
target for prometheus servers

00:00:43,200 --> 00:00:47,440
and allow squaring the data back year

00:00:46,399 --> 00:00:49,760
00:00:47,440 --> 00:00:52,000
was the year when we have introduced a

00:00:49,760 --> 00:00:54,879
new storage engine into cortex

00:00:52,000 --> 00:00:55,440
called the blocks engine the storage

00:00:54,879 --> 00:00:58,239
engine

00:00:55,440 --> 00:01:00,160
uses tsdb blocks exactly the same as

00:00:58,239 --> 00:01:02,879
prometheus itself does

00:01:00,160 --> 00:01:05,439
in fact we reuse the tsdb library from

00:01:02,879 --> 00:01:08,080
prometheus to write the data

00:01:05,439 --> 00:01:09,920
in addition to that cortex also reuses

00:01:08,080 --> 00:01:11,760
some components from thanos

00:01:09,920 --> 00:01:13,600
and we have optimized some of those

00:01:11,760 --> 00:01:15,600
components for the benefit of both

00:01:13,600 --> 00:01:18,720
cortex and thanos

00:01:15,600 --> 00:01:19,759
why did we spend all this effort tsdb

00:01:18,720 --> 00:01:21,840
blocks are simply

00:01:19,759 --> 00:01:23,840
much more efficient at storing the same

00:01:21,840 --> 00:01:26,960
data compared to the storage

00:01:23,840 --> 00:01:27,600
used by cortex previously in addition to

00:01:26,960 --> 00:01:29,840
that

00:01:27,600 --> 00:01:31,439
we also get extra features that cortex

00:01:29,840 --> 00:01:33,600
did not have before like

00:01:31,439 --> 00:01:36,159
support for queries without the metric

00:01:33,600 --> 00:01:38,320
name pertinent data retention

00:01:36,159 --> 00:01:41,119
or much simpler data cleanup from the

00:01:38,320 --> 00:01:43,520
long term storage

00:01:41,119 --> 00:01:45,119
introducing the new data storage format

00:01:43,520 --> 00:01:47,200
poses the question about

00:01:45,119 --> 00:01:48,640
what to do with the old data stored in a

00:01:47,200 --> 00:01:50,399
legacy format

00:01:48,640 --> 00:01:52,560
and that is what this talk is going to

00:01:50,399 --> 00:01:55,119
be about

00:01:52,560 --> 00:01:56,320
original storage in cortex is called

00:01:55,119 --> 00:01:59,680
chunk storage

00:01:56,320 --> 00:02:01,040
it has two parts index and store for

00:01:59,680 --> 00:02:03,040
chunks

00:02:01,040 --> 00:02:04,159
on this slide we see example of three

00:02:03,040 --> 00:02:07,280
chunks

00:02:04,159 --> 00:02:08,479
each chunk contains samples for one time

00:02:07,280 --> 00:02:10,879
series

00:02:08,479 --> 00:02:12,480
for a specific time range typically a

00:02:10,879 --> 00:02:15,120
few hours

00:02:12,480 --> 00:02:16,000
in addition to those samples cortex

00:02:15,120 --> 00:02:18,400
chunk

00:02:16,000 --> 00:02:20,400
has submitted data about itself like

00:02:18,400 --> 00:02:23,280
what series it belongs to

00:02:20,400 --> 00:02:25,599
stored as a set of labels or minimum and

00:02:23,280 --> 00:02:28,080
maximum time

00:02:25,599 --> 00:02:30,000
each chunk is stored separately for

00:02:28,080 --> 00:02:30,959
example as individual object in the

00:02:30,000 --> 00:02:34,080
cloud storage

00:02:30,959 --> 00:02:34,800
or individual cell in bigtable as you

00:02:34,080 --> 00:02:36,800
can imagine

00:02:34,800 --> 00:02:38,480
this generates a huge number of objects

00:02:36,800 --> 00:02:40,800
or cells

00:02:38,480 --> 00:02:42,720
due to the replication individual sample

00:02:40,800 --> 00:02:44,800
may end up in multiple chunks

00:02:42,720 --> 00:02:48,879
although cortex chunk storage does have

00:02:44,800 --> 00:02:50,800
some features to reduce this duplicity

00:02:48,879 --> 00:02:53,200
for cortex to be able to locate the

00:02:50,800 --> 00:02:56,959
correct chunks during the queries

00:02:53,200 --> 00:02:57,920
it uses index index is stored in no sql

00:02:56,959 --> 00:03:01,519
database like

00:02:57,920 --> 00:03:02,879
bigtable or dynamodb index needs to have

00:03:01,519 --> 00:03:05,440
multiple features

00:03:02,879 --> 00:03:06,640
first of all index needs to allow for

00:03:05,440 --> 00:03:10,080
efficient lookups

00:03:06,640 --> 00:03:10,640
based on time because promql queries are

00:03:10,080 --> 00:03:13,680
always

00:03:10,640 --> 00:03:15,519
restricted to some specific time range

00:03:13,680 --> 00:03:19,680
to make them run fast we need to

00:03:15,519 --> 00:03:21,920
restrict search to this time range only

00:03:19,680 --> 00:03:24,799
index must support search by specific

00:03:21,920 --> 00:03:26,720
label names and values

00:03:24,799 --> 00:03:27,920
next index must also support

00:03:26,720 --> 00:03:29,920
multi-tenancy

00:03:27,920 --> 00:03:33,040
even though the index entries for all

00:03:29,920 --> 00:03:35,840
users are stored in the same database

00:03:33,040 --> 00:03:37,360
how exactly index looks like in cortex

00:03:35,840 --> 00:03:39,599
has evolved in time

00:03:37,360 --> 00:03:42,239
and cortex uses so-called schemas to

00:03:39,599 --> 00:03:44,400
describe each version of the index

00:03:42,239 --> 00:03:47,360
on the picture you can see simplified

00:03:44,400 --> 00:03:50,080
view of so-called version 9 of the index

00:03:47,360 --> 00:03:52,159
with entry types like label label value

00:03:50,080 --> 00:03:54,400
or series

00:03:52,159 --> 00:03:56,239
here is the fun challenge how to

00:03:54,400 --> 00:03:58,560
efficiently return chunks for

00:03:56,239 --> 00:04:01,680
cortex uptime metric with job names

00:03:58,560 --> 00:04:04,480
starting with queue

00:04:01,680 --> 00:04:05,519
let's take a look at tsdb blocks now

00:04:04,480 --> 00:04:08,640
block consists

00:04:05,519 --> 00:04:10,400
of multiple files on disk each block has

00:04:08,640 --> 00:04:12,159
a unique identifier

00:04:10,400 --> 00:04:14,159
that encodes timestamp when this

00:04:12,159 --> 00:04:17,199
identifier was generated and

00:04:14,159 --> 00:04:19,519
random part for uniqueness inside

00:04:17,199 --> 00:04:21,040
chunks subdirectory there are so called

00:04:19,519 --> 00:04:23,440
segment files

00:04:21,040 --> 00:04:24,960
which are numbered in this image there

00:04:23,440 --> 00:04:27,199
are two

00:04:24,960 --> 00:04:28,800
block also has an index stored in a

00:04:27,199 --> 00:04:31,520
single file

00:04:28,800 --> 00:04:32,639
metadata are stored in a small file in

00:04:31,520 --> 00:04:34,720
json format

00:04:32,639 --> 00:04:37,520
and finally there are tombstones which

00:04:34,720 --> 00:04:40,080
cortex currently doesn't use

00:04:37,520 --> 00:04:42,000
this is what meta json file looks like

00:04:40,080 --> 00:04:44,400
it contains some information about

00:04:42,000 --> 00:04:46,000
the block most importantly the time

00:04:44,400 --> 00:04:48,000
range that it covers

00:04:46,000 --> 00:04:49,050
but also some stats and information

00:04:48,000 --> 00:04:50,720
about compaction

00:04:49,050 --> 00:04:52,880
[Music]

00:04:50,720 --> 00:04:54,960
now let's take a look at segment files

00:04:52,880 --> 00:04:56,479
those numbered files under chunks

00:04:54,960 --> 00:04:59,919
directory

00:04:56,479 --> 00:05:02,080
segment files contain individual chunks

00:04:59,919 --> 00:05:04,000
these are similar to cortex chunks but

00:05:02,080 --> 00:05:07,039
much simpler they only contain

00:05:04,000 --> 00:05:08,639
samples chunks are stored one next to

00:05:07,039 --> 00:05:10,960
another in the segment file

00:05:08,639 --> 00:05:11,919
until they take roughly half of gigabyte

00:05:10,960 --> 00:05:15,280
of space

00:05:11,919 --> 00:05:17,440
and then another segment file is started

00:05:15,280 --> 00:05:19,759
each chunk has so-called reference

00:05:17,440 --> 00:05:21,280
number which is basically the position

00:05:19,759 --> 00:05:23,600
or the offset of the chunk in the

00:05:21,280 --> 00:05:24,080
segment file combined with the number of

00:05:23,600 --> 00:05:27,199
segment

00:05:24,080 --> 00:05:29,520
file 001 in this example

00:05:27,199 --> 00:05:32,400
encoding these two values together gives

00:05:29,520 --> 00:05:35,280
us a reference number

00:05:32,400 --> 00:05:37,360
index in tsdb block is a single file and

00:05:35,280 --> 00:05:40,000
it is quite complicated internally

00:05:37,360 --> 00:05:42,000
for maximum efficiency but the basic

00:05:40,000 --> 00:05:44,320
idea is simple

00:05:42,000 --> 00:05:46,479
it contains information about all time

00:05:44,320 --> 00:05:49,840
series in the block

00:05:46,479 --> 00:05:52,160
that means list of labels list of chunks

00:05:49,840 --> 00:05:53,600
or the reference numbers together with

00:05:52,160 --> 00:05:57,600
minimum and maximum time

00:05:53,600 --> 00:06:00,639
for each chunk index also contains

00:05:57,600 --> 00:06:02,720
all label value pairs for fast lookup

00:06:00,639 --> 00:06:05,199
and these label value pairs are then

00:06:02,720 --> 00:06:07,360
mapped to series ids

00:06:05,199 --> 00:06:10,080
and that's basically it now you know

00:06:07,360 --> 00:06:11,840
what's inside your tsdb blocks

00:06:10,080 --> 00:06:14,160
it's interesting to see that prometheus

00:06:11,840 --> 00:06:16,720
does not encode series type like gauge

00:06:14,160 --> 00:06:18,880
or counter in the index

00:06:16,720 --> 00:06:20,560
what is important about the esdb blocks

00:06:18,880 --> 00:06:22,720
is that they are standalone

00:06:20,560 --> 00:06:23,600
each block is independent from any other

00:06:22,720 --> 00:06:25,360
block

00:06:23,600 --> 00:06:27,440
blocks can be merged together into

00:06:25,360 --> 00:06:28,479
larger blocks through the process called

00:06:27,440 --> 00:06:30,560
compaction

00:06:28,479 --> 00:06:31,840
and this helps to save the disk space

00:06:30,560 --> 00:06:34,560
because big

00:06:31,840 --> 00:06:36,400
part of the index is typically the same

00:06:34,560 --> 00:06:37,520
that is if you have the same label names

00:06:36,400 --> 00:06:40,880
and values for

00:06:37,520 --> 00:06:40,880
longer than couple of hours

00:06:40,960 --> 00:06:44,240
to learn more about esdb blocks i can

00:06:43,120 --> 00:06:46,560
highly recommend

00:06:44,240 --> 00:06:48,000
series of blog posts by my colleague

00:06:46,560 --> 00:06:49,759
ganesh vernicar

00:06:48,000 --> 00:06:51,039
who maintains the sdb library in

00:06:49,759 --> 00:06:52,720
prometheus

00:06:51,039 --> 00:06:54,800
slides contain the link if you are

00:06:52,720 --> 00:06:58,960
interested

00:06:54,800 --> 00:07:01,520
so how are tsdb blocks used by cortex

00:06:58,960 --> 00:07:02,240
cortex components put incoming data to

00:07:01,520 --> 00:07:04,319
blocks

00:07:02,240 --> 00:07:06,319
and upload them to object storage like

00:07:04,319 --> 00:07:08,639
gcs rs3

00:07:06,319 --> 00:07:09,520
we define our own structure for storing

00:07:08,639 --> 00:07:11,039
blocks

00:07:09,520 --> 00:07:13,440
basically each user has its own

00:07:11,039 --> 00:07:16,160
directory full of blocks

00:07:13,440 --> 00:07:18,000
and we also put little extra metadata

00:07:16,160 --> 00:07:20,560
into meta json file

00:07:18,000 --> 00:07:22,000
but otherwise we just use plenty sdb

00:07:20,560 --> 00:07:24,800
blocks

00:07:22,000 --> 00:07:25,759
in cortex we generate two hours blocks

00:07:24,800 --> 00:07:28,479
at first

00:07:25,759 --> 00:07:29,039
but later we compacted them into one day

00:07:28,479 --> 00:07:31,919
blocks

00:07:29,039 --> 00:07:34,160
that is each block covers 24 hours of

00:07:31,919 --> 00:07:36,400
data

00:07:34,160 --> 00:07:37,360
we have seen how cortex chunk storage

00:07:36,400 --> 00:07:40,560
looks like

00:07:37,360 --> 00:07:43,520
and what tsdb blocks look like

00:07:40,560 --> 00:07:44,080
now how do we convert chunks or cortex

00:07:43,520 --> 00:07:47,280
chunks

00:07:44,080 --> 00:07:49,440
to tsdb blocks

00:07:47,280 --> 00:07:52,240
to generate block we need to find series

00:07:49,440 --> 00:07:55,039
and chunks that belong to this block

00:07:52,240 --> 00:07:55,599
since we want one block per day per user

00:07:55,039 --> 00:07:57,919
that means

00:07:55,599 --> 00:07:58,800
finding series for specific user that

00:07:57,919 --> 00:08:02,080
has samples

00:07:58,800 --> 00:08:04,479
in that specific day unfortunately

00:08:02,080 --> 00:08:06,319
cortex index was not designed with these

00:08:04,479 --> 00:08:08,720
requirements in mind

00:08:06,319 --> 00:08:11,120
maybe thinking what isn't that isn't

00:08:08,720 --> 00:08:13,759
that what index is for

00:08:11,120 --> 00:08:14,800
yeah well index is designed to do

00:08:13,759 --> 00:08:16,960
lookups for

00:08:14,800 --> 00:08:18,960
label and value pairs but not to find

00:08:16,960 --> 00:08:21,120
all series for a user

00:08:18,960 --> 00:08:23,759
in fact it's even difficult to quickly

00:08:21,120 --> 00:08:25,680
find all users

00:08:23,759 --> 00:08:27,759
in addition to that cortex uses

00:08:25,680 --> 00:08:31,039
different versions of index

00:08:27,759 --> 00:08:33,599
fortunately in our production databases

00:08:31,039 --> 00:08:34,880
we have only used version 9 and later

00:08:33,599 --> 00:08:38,399
which are compatible

00:08:34,880 --> 00:08:40,959
so that is what we have focused on

00:08:38,399 --> 00:08:41,839
on the other hand we can read the entire

00:08:40,959 --> 00:08:44,240
index

00:08:41,839 --> 00:08:46,640
and generate lists of series and chunks

00:08:44,240 --> 00:08:48,480
that should be put into each block

00:08:46,640 --> 00:08:50,080
and that is actually pretty easy and

00:08:48,480 --> 00:08:52,560
efficient to do

00:08:50,080 --> 00:08:53,839
it just requires single full scan of the

00:08:52,560 --> 00:08:55,839
index

00:08:53,839 --> 00:08:58,720
and this observation draw the design of

00:08:55,839 --> 00:08:58,720
conversion tooling

00:08:59,279 --> 00:09:02,720
our conversion tooling has three main

00:09:01,279 --> 00:09:05,519
components

00:09:02,720 --> 00:09:07,279
index scanner for doing full index scan

00:09:05,519 --> 00:09:09,440
and generating plan files

00:09:07,279 --> 00:09:10,320
which is basically a list of series and

00:09:09,440 --> 00:09:13,440
chunks

00:09:10,320 --> 00:09:16,320
that belong to a single block

00:09:13,440 --> 00:09:17,440
block builder which uses single plan

00:09:16,320 --> 00:09:20,080
file

00:09:17,440 --> 00:09:21,200
downloads all chunks and constructs tsdb

00:09:20,080 --> 00:09:23,360
blocks

00:09:21,200 --> 00:09:24,880
and finally scheduler which monitors

00:09:23,360 --> 00:09:28,800
available blend files

00:09:24,880 --> 00:09:30,320
and distributes them to block builders

00:09:28,800 --> 00:09:31,839
i will shortly talk about these

00:09:30,320 --> 00:09:34,160
components now but

00:09:31,839 --> 00:09:37,839
if you want even more details there is a

00:09:34,160 --> 00:09:37,839
link to the design document

00:09:38,240 --> 00:09:44,800
scanner scans the index tables in cortex

00:09:42,320 --> 00:09:45,440
our index is divided into individual

00:09:44,800 --> 00:09:48,560
tables

00:09:45,440 --> 00:09:51,040
each table covers one week of data

00:09:48,560 --> 00:09:51,680
when scanner scans the table it is

00:09:51,040 --> 00:09:54,800
processing

00:09:51,680 --> 00:09:55,600
all index entries in some order due to

00:09:54,800 --> 00:09:58,160
how cortex

00:09:55,600 --> 00:09:59,600
stores index entries this order is

00:09:58,160 --> 00:10:03,200
basically random because

00:09:59,600 --> 00:10:06,480
cortex prefixes each entry with the hash

00:10:03,200 --> 00:10:08,800
for better key distribution at least

00:10:06,480 --> 00:10:10,720
that is the case when cortex stores

00:10:08,800 --> 00:10:11,850
index in bigtable which is what we have

00:10:10,720 --> 00:10:13,279
used in our production

00:10:11,850 --> 00:10:16,160
[Music]

00:10:13,279 --> 00:10:16,959
while reading all index entries scanner

00:10:16,160 --> 00:10:18,480
only selects

00:10:16,959 --> 00:10:20,079
entries that describe the mapping

00:10:18,480 --> 00:10:22,880
between series ids

00:10:20,079 --> 00:10:24,399
and chunks and stores these mappings

00:10:22,880 --> 00:10:26,240
into a file

00:10:24,399 --> 00:10:28,959
we know minimum and maximum time of

00:10:26,240 --> 00:10:30,959
chunk because it's part of the chunk id

00:10:28,959 --> 00:10:32,640
so we know into which days the chunk

00:10:30,959 --> 00:10:35,120
belongs

00:10:32,640 --> 00:10:37,279
so in the end the scanner produces one

00:10:35,120 --> 00:10:39,680
file per user and day

00:10:37,279 --> 00:10:41,839
and this file contains complete list of

00:10:39,680 --> 00:10:45,279
series ids and their chunks

00:10:41,839 --> 00:10:46,800
and this is called plan file if you have

00:10:45,279 --> 00:10:49,760
thousands of users

00:10:46,800 --> 00:10:50,640
in the index scanning single table will

00:10:49,760 --> 00:10:53,200
produce seven

00:10:50,640 --> 00:10:56,079
times that number of users of pain files

00:10:53,200 --> 00:10:58,160
one per day per user

00:10:56,079 --> 00:10:59,760
plan files are then uploaded to the

00:10:58,160 --> 00:11:02,399
object storage bucket

00:10:59,760 --> 00:11:05,760
and scanner can continue with the next

00:11:02,399 --> 00:11:07,920
table until it processes all of them

00:11:05,760 --> 00:11:10,399
if new table appears which can happen

00:11:07,920 --> 00:11:13,440
because entire conversion take

00:11:10,399 --> 00:11:16,240
takes many days

00:11:13,440 --> 00:11:17,760
and customers are pushing new data in in

00:11:16,240 --> 00:11:23,360
this time

00:11:17,760 --> 00:11:23,360
scanner can still process the new tables

00:11:23,680 --> 00:11:27,839
originally scanner has supported

00:11:25,760 --> 00:11:29,040
bigtable only but now it also supports

00:11:27,839 --> 00:11:30,959
dynamodb

00:11:29,040 --> 00:11:33,440
and there was some community work on

00:11:30,959 --> 00:11:35,519
adding cassandra support

00:11:33,440 --> 00:11:36,480
scanner is not horizontally scalable by

00:11:35,519 --> 00:11:40,160
design

00:11:36,480 --> 00:11:40,160
it's typically pretty fast already

00:11:40,560 --> 00:11:44,640
block builder is the main component of

00:11:42,320 --> 00:11:45,839
the tooling because it generates the sdb

00:11:44,640 --> 00:11:48,160
blocks

00:11:45,839 --> 00:11:49,040
block builder is told which plan to work

00:11:48,160 --> 00:11:51,360
on

00:11:49,040 --> 00:11:55,360
and then it downloads the plan and

00:11:51,360 --> 00:11:57,680
fetches all the chunks from chunk store

00:11:55,360 --> 00:11:59,120
quote builder then builds tsdb index and

00:11:57,680 --> 00:12:01,600
segment files

00:11:59,120 --> 00:12:02,639
and uploads generated tsdb block back

00:12:01,600 --> 00:12:06,240
into bucket

00:12:02,639 --> 00:12:08,480
where cortex can find it block builder

00:12:06,240 --> 00:12:11,839
takes care of many details that

00:12:08,480 --> 00:12:14,560
need to be right it deduplicates samples

00:12:11,839 --> 00:12:17,680
from multiple chunks in the same series

00:12:14,560 --> 00:12:18,560
chunks such chunks may appear because of

00:12:17,680 --> 00:12:21,760
replication

00:12:18,560 --> 00:12:24,000
used in cortex builder can also fix

00:12:21,760 --> 00:12:24,880
some bugs introduced in cortex chunks

00:12:24,000 --> 00:12:28,480
over time

00:12:24,880 --> 00:12:30,560
for example duplicate labels builder

00:12:28,480 --> 00:12:32,399
of course takes care of sorting series

00:12:30,560 --> 00:12:35,760
before building index

00:12:32,399 --> 00:12:39,360
otherwise index would not be correct and

00:12:35,760 --> 00:12:41,200
that's so without getting unkilled

00:12:39,360 --> 00:12:42,720
builder obviously knows how to produce

00:12:41,200 --> 00:12:46,480
meta json file

00:12:42,720 --> 00:12:48,399
with cortex metadata important point

00:12:46,480 --> 00:12:49,440
about block builder is that once it has

00:12:48,399 --> 00:12:51,440
the plan

00:12:49,440 --> 00:12:52,800
it doesn't need to interact with cortex

00:12:51,440 --> 00:12:56,000
index

00:12:52,800 --> 00:12:58,160
it only needs to fetch chunks cortex

00:12:56,000 --> 00:12:59,519
chunks already contain full information

00:12:58,160 --> 00:13:02,079
about the series

00:12:59,519 --> 00:13:05,040
like label names and values and that is

00:13:02,079 --> 00:13:07,519
all that block builder needs

00:13:05,040 --> 00:13:08,160
this also shows one reason why tsd is

00:13:07,519 --> 00:13:09,839
more

00:13:08,160 --> 00:13:11,200
space efficient than cortex chunk

00:13:09,839 --> 00:13:13,120
storage namely

00:13:11,200 --> 00:13:16,320
because the information about the same

00:13:13,120 --> 00:13:19,360
series is not repeated in every chunk

00:13:16,320 --> 00:13:21,440
when it is stored in tsdb instead the

00:13:19,360 --> 00:13:22,399
series information is only stored once

00:13:21,440 --> 00:13:25,760
in the tsdb

00:13:22,399 --> 00:13:26,720
index block builder is horizontally

00:13:25,760 --> 00:13:28,720
scalable

00:13:26,720 --> 00:13:31,440
you can run many of them to get blocks

00:13:28,720 --> 00:13:33,519
built faster

00:13:31,440 --> 00:13:35,680
we have said before that index scanner

00:13:33,519 --> 00:13:38,000
writes plans to the bucket

00:13:35,680 --> 00:13:39,199
scheduler is the component that finds

00:13:38,000 --> 00:13:42,320
those plans

00:13:39,199 --> 00:13:44,480
and sends them to the blog builders

00:13:42,320 --> 00:13:46,639
blog builders communicate their build

00:13:44,480 --> 00:13:47,199
progress using another small file in the

00:13:46,639 --> 00:13:49,360
bucket

00:13:47,199 --> 00:13:50,720
which is regularly updated as long as

00:13:49,360 --> 00:13:53,920
block builder is running

00:13:50,720 --> 00:13:55,519
and working on the plan if scheduler

00:13:53,920 --> 00:13:57,920
finds that the block builder hasn't

00:13:55,519 --> 00:14:00,320
reported its progress recently

00:13:57,920 --> 00:14:01,120
scheduler will consider such builder as

00:14:00,320 --> 00:14:04,079
crashed

00:14:01,120 --> 00:14:06,160
and will abort the build when

00:14:04,079 --> 00:14:08,480
blockbuilder is done with the plan

00:14:06,160 --> 00:14:09,760
it uploads finished file next to the

00:14:08,480 --> 00:14:11,839
plan file

00:14:09,760 --> 00:14:13,040
this tells scheduler that given plan is

00:14:11,839 --> 00:14:15,199
finished

00:14:13,040 --> 00:14:18,560
if build has failed blockbuilder will

00:14:15,199 --> 00:14:20,800
upload failed file instead

00:14:18,560 --> 00:14:23,120
this is a very simple orchestration

00:14:20,800 --> 00:14:24,639
using object storage

00:14:23,120 --> 00:14:26,800
note that the scanner doesn't need to

00:14:24,639 --> 00:14:27,760
read the files it only issues list

00:14:26,800 --> 00:14:31,199
commands

00:14:27,760 --> 00:14:34,320
or information is encoded in file names

00:14:31,199 --> 00:14:36,160
by doing single list scheduler knows

00:14:34,320 --> 00:14:38,959
which plans are available

00:14:36,160 --> 00:14:40,959
which are in progress or finished this

00:14:38,959 --> 00:14:43,920
allows scheduler to update its

00:14:40,959 --> 00:14:45,360
in-memory state every few minutes so

00:14:43,920 --> 00:14:48,160
that when the blog builder

00:14:45,360 --> 00:14:50,399
asks for the next plan scheduler can

00:14:48,160 --> 00:14:53,680
return one

00:14:50,399 --> 00:14:55,760
how did it work well it worked

00:14:53,680 --> 00:14:58,959
we have successfully converted all

00:14:55,760 --> 00:15:00,880
stored chunks data into tsdb blocks

00:14:58,959 --> 00:15:02,480
and we could downscale our bigtable

00:15:00,880 --> 00:15:04,880
instances

00:15:02,480 --> 00:15:07,120
what have we learned that simple

00:15:04,880 --> 00:15:09,519
distributed system is good

00:15:07,120 --> 00:15:10,160
communication using buckets by listing

00:15:09,519 --> 00:15:12,000
of files

00:15:10,160 --> 00:15:14,000
works just fine and it's easy to

00:15:12,000 --> 00:15:17,199
manipulate the state of jobs

00:15:14,000 --> 00:15:19,040
by manipulating files in the bucket

00:15:17,199 --> 00:15:21,920
for example if you delete the failure

00:15:19,040 --> 00:15:23,040
file scheduler will see that the plan

00:15:21,920 --> 00:15:26,160
needs to be built again

00:15:23,040 --> 00:15:28,800
and will give it to the block builders

00:15:26,160 --> 00:15:29,600
were there any problems of course there

00:15:28,800 --> 00:15:31,920
were

00:15:29,600 --> 00:15:34,079
first issue we have run into was related

00:15:31,920 --> 00:15:37,199
to meta json files

00:15:34,079 --> 00:15:40,079
in early versions of both builder

00:15:37,199 --> 00:15:40,880
we did not correctly set all json file

00:15:40,079 --> 00:15:43,680
details

00:15:40,880 --> 00:15:45,440
especially compaction section cortex

00:15:43,680 --> 00:15:48,639
compactor was then confused

00:15:45,440 --> 00:15:50,639
by such box and deleted newly built

00:15:48,639 --> 00:15:52,000
blocks soon after they were uploaded to

00:15:50,639 --> 00:15:54,000
the bucket

00:15:52,000 --> 00:15:56,079
we did not catch this in testing because

00:15:54,000 --> 00:15:57,680
we didn't run compactor in cluster where

00:15:56,079 --> 00:16:01,040
the test was done

00:15:57,680 --> 00:16:03,440
but once fixed one once fixed we were

00:16:01,040 --> 00:16:05,120
quickly able to just redo those blocks

00:16:03,440 --> 00:16:07,600
again

00:16:05,120 --> 00:16:08,720
another issue we have hit was related to

00:16:07,600 --> 00:16:11,440
memory

00:16:08,720 --> 00:16:12,160
when writing tsdb index we were trying

00:16:11,440 --> 00:16:14,720
to sort

00:16:12,160 --> 00:16:16,639
all series in memory but some of our

00:16:14,720 --> 00:16:18,560
customers had so many series that we

00:16:16,639 --> 00:16:21,279
could not fit all the labels in the

00:16:18,560 --> 00:16:23,279
memory during the block build

00:16:21,279 --> 00:16:24,959
after retrying the job several times

00:16:23,279 --> 00:16:27,680
with more and more memory

00:16:24,959 --> 00:16:29,680
we eventually gave up at 30 gigabytes

00:16:27,680 --> 00:16:32,079
and stored series data on the disk

00:16:29,680 --> 00:16:35,279
instead with some sorting afterwards

00:16:32,079 --> 00:16:36,000
that fixed the issue and last point i

00:16:35,279 --> 00:16:38,639
have

00:16:36,000 --> 00:16:40,560
is horizontal scaling for the win by

00:16:38,639 --> 00:16:42,399
using plan files we split the whole

00:16:40,560 --> 00:16:43,279
conversion task into many small sub

00:16:42,399 --> 00:16:44,560
tasks

00:16:43,279 --> 00:16:46,880
allowing block builder to be

00:16:44,560 --> 00:16:48,639
horizontally scalable

00:16:46,880 --> 00:16:50,320
that is we could just run more of them

00:16:48,639 --> 00:16:53,040
to proceed faster

00:16:50,320 --> 00:16:54,720
one of our clusters contains thousands

00:16:53,040 --> 00:16:56,720
of tiny tenants

00:16:54,720 --> 00:16:58,240
and number of plans on this cluster was

00:16:56,720 --> 00:17:00,160
in millions

00:16:58,240 --> 00:17:02,160
but we got it converted in just couple

00:17:00,160 --> 00:17:06,319
of days by running many

00:17:02,160 --> 00:17:08,079
many block builders if you have your own

00:17:06,319 --> 00:17:10,480
chunks data that you would like to cover

00:17:08,079 --> 00:17:13,760
to blocks all this tooling is part of

00:17:10,480 --> 00:17:16,000
open source cortex codebase

00:17:13,760 --> 00:17:17,280
in the last part of the talk i want to

00:17:16,000 --> 00:17:19,520
show you

00:17:17,280 --> 00:17:21,520
how you can write the sdb blocks by some

00:17:19,520 --> 00:17:23,120
simple go code

00:17:21,520 --> 00:17:25,039
of course if you want to convert some

00:17:23,120 --> 00:17:27,120
data to tsdb blocks

00:17:25,039 --> 00:17:28,319
you can also use the new prometheus

00:17:27,120 --> 00:17:30,240
backfilling tool

00:17:28,319 --> 00:17:32,480
but sometimes it may be more efficient

00:17:30,240 --> 00:17:34,720
to write the sdb blocks directly

00:17:32,480 --> 00:17:36,400
without converting data to open metrics

00:17:34,720 --> 00:17:39,679
format first

00:17:36,400 --> 00:17:40,640
and it's also easy and fun to generate

00:17:39,679 --> 00:17:43,679
the sdb block

00:17:40,640 --> 00:17:46,480
we need to just we need to generate

00:17:43,679 --> 00:17:48,240
sorry we need to do three steps write

00:17:46,480 --> 00:17:51,919
chunks into segment files

00:17:48,240 --> 00:17:54,160
write index and red method json file

00:17:51,919 --> 00:17:56,080
and we will use tsd library from pro

00:17:54,160 --> 00:17:58,840
methods to do that

00:17:56,080 --> 00:18:00,880
you can find full example at provided

00:17:58,840 --> 00:18:03,039
link

00:18:00,880 --> 00:18:04,960
this code example shows how to prepare

00:18:03,039 --> 00:18:07,600
chunks for a single time series

00:18:04,960 --> 00:18:08,720
from given list of samples each sample

00:18:07,600 --> 00:18:12,240
has a timestamp

00:18:08,720 --> 00:18:14,559
and a float64 value we need to iterate

00:18:12,240 --> 00:18:16,320
through all samples

00:18:14,559 --> 00:18:18,000
we convert the timestamp to the unix

00:18:16,320 --> 00:18:20,160
timestamp in milliseconds

00:18:18,000 --> 00:18:21,760
and because that is what prometheus

00:18:20,160 --> 00:18:24,400
expects to find in tsd

00:18:21,760 --> 00:18:24,960
block we check we have appender for

00:18:24,400 --> 00:18:27,360
trunk

00:18:24,960 --> 00:18:28,960
if not we create a new sort chunk which

00:18:27,360 --> 00:18:31,760
is used by prometheus

00:18:28,960 --> 00:18:33,760
and we get a pander for this chunk

00:18:31,760 --> 00:18:36,640
appender is used to write

00:18:33,760 --> 00:18:38,240
individual samples to the chunk we are

00:18:36,640 --> 00:18:40,799
not only building chunks but

00:18:38,240 --> 00:18:42,799
also chunk meta information with minimum

00:18:40,799 --> 00:18:44,640
and maximum time

00:18:42,799 --> 00:18:47,520
now that we have appender we can write

00:18:44,640 --> 00:18:49,679
samples to chunk

00:18:47,520 --> 00:18:50,799
we simply append sample to the appender

00:18:49,679 --> 00:18:53,360
and update

00:18:50,799 --> 00:18:54,799
max time in metadata in this step we

00:18:53,360 --> 00:18:57,840
assume that timestamps

00:18:54,799 --> 00:19:00,240
for samples are increasing that is how

00:18:57,840 --> 00:19:02,000
prometheus expects to find samples in

00:19:00,240 --> 00:19:05,280
the chunk

00:19:02,000 --> 00:19:08,000
after writing 120 samples into a chunk

00:19:05,280 --> 00:19:09,360
we finish the chunk append metadata to

00:19:08,000 --> 00:19:12,240
our list of metadatas

00:19:09,360 --> 00:19:13,840
and set appender to nil which will cause

00:19:12,240 --> 00:19:15,120
creation of new chunk in the next

00:19:13,840 --> 00:19:19,039
iteration

00:19:15,120 --> 00:19:20,720
and that's it this creates chunks

00:19:19,039 --> 00:19:23,120
chunks are written to the disk using

00:19:20,720 --> 00:19:24,400
chunk writer one can get the chunk

00:19:23,120 --> 00:19:27,360
writer from tsdb

00:19:24,400 --> 00:19:28,559
chunks package and it currently has

00:19:27,360 --> 00:19:31,919
these two methods

00:19:28,559 --> 00:19:32,960
right chunks and close red chunks can be

00:19:31,919 --> 00:19:35,039
called many times

00:19:32,960 --> 00:19:36,799
we give it a slice of chunks to write

00:19:35,039 --> 00:19:40,000
and after writing them all

00:19:36,799 --> 00:19:40,880
we can close it there are few important

00:19:40,000 --> 00:19:43,360
details

00:19:40,880 --> 00:19:46,320
chunks must be sorted in the same order

00:19:43,360 --> 00:19:48,559
as is the order of series in the index

00:19:46,320 --> 00:19:50,840
prometheus does it this way and

00:19:48,559 --> 00:19:52,799
prometheus may use this fact for future

00:19:50,840 --> 00:19:55,200
optimizations

00:19:52,799 --> 00:19:57,919
within single series chunks must be

00:19:55,200 --> 00:19:59,600
sorted by increasing time

00:19:57,919 --> 00:20:01,520
calling great chunks will update

00:19:59,600 --> 00:20:04,880
reference field of each chunk

00:20:01,520 --> 00:20:06,240
metastructure this reference field is

00:20:04,880 --> 00:20:09,520
important in the next step

00:20:06,240 --> 00:20:10,159
writing index index writer has two

00:20:09,520 --> 00:20:14,480
important

00:20:10,159 --> 00:20:17,120
methods first you must call add a symbol

00:20:14,480 --> 00:20:18,880
with all symbols that is label names and

00:20:17,120 --> 00:20:20,799
values

00:20:18,880 --> 00:20:24,240
and these symbols must be sorted and

00:20:20,799 --> 00:20:26,480
each symbol must be added exactly once

00:20:24,240 --> 00:20:28,640
after writing all symbols to the index

00:20:26,480 --> 00:20:29,760
we can finally start adding series to

00:20:28,640 --> 00:20:32,720
the index

00:20:29,760 --> 00:20:33,760
to add a series we need to pass in ref

00:20:32,720 --> 00:20:36,320
number

00:20:33,760 --> 00:20:37,120
set of labels that the series uses and

00:20:36,320 --> 00:20:40,159
chunks

00:20:37,120 --> 00:20:43,520
and the slice of chunks meta

00:20:40,159 --> 00:20:45,760
structures these chunks meta structures

00:20:43,520 --> 00:20:48,320
must have a reference field set and as

00:20:45,760 --> 00:20:50,559
we have said on previous slide it is set

00:20:48,320 --> 00:20:52,400
after chunks are written to the chunk

00:20:50,559 --> 00:20:54,320
writer

00:20:52,400 --> 00:20:55,840
the reference number passed as first

00:20:54,320 --> 00:20:58,080
argument is somewhat strange

00:20:55,840 --> 00:21:00,400
it's really not needed and the

00:20:58,080 --> 00:21:02,799
implementation of of index writer in

00:21:00,400 --> 00:21:03,360
tsdb library only uses it to check that

00:21:02,799 --> 00:21:06,640
it's

00:21:03,360 --> 00:21:08,559
increased between calls after writing

00:21:06,640 --> 00:21:09,440
chunks and index we are almost finished

00:21:08,559 --> 00:21:11,760
with the block

00:21:09,440 --> 00:21:14,159
last piece that is missing is meta json

00:21:11,760 --> 00:21:14,159
file

00:21:14,400 --> 00:21:18,000
and this file is represented by block

00:21:16,720 --> 00:21:20,960
meta type from the

00:21:18,000 --> 00:21:21,760
tsdb library we need to fill all the

00:21:20,960 --> 00:21:23,000
fields

00:21:21,760 --> 00:21:25,440
and most of them are pretty

00:21:23,000 --> 00:21:25,840
self-explanatory version is currently

00:21:25,440 --> 00:21:29,039
one

00:21:25,840 --> 00:21:32,720
unfortunately this constant is not

00:21:29,039 --> 00:21:34,720
public in tsd library

00:21:32,720 --> 00:21:37,200
compaction information must be set as

00:21:34,720 --> 00:21:38,159
well and we simply set block source to

00:21:37,200 --> 00:21:39,919
itself

00:21:38,159 --> 00:21:41,679
the failure to do this may confuse

00:21:39,919 --> 00:21:44,159
compactor

00:21:41,679 --> 00:21:45,520
after writing meta.json file to disk we

00:21:44,159 --> 00:21:48,080
have a complete block

00:21:45,520 --> 00:21:49,600
that we can use with prometheus for

00:21:48,080 --> 00:21:52,159
thanos and cortex

00:21:49,600 --> 00:21:55,760
we need extra bit of metadata in the

00:21:52,159 --> 00:21:57,360
meta json file but nothing too complex

00:21:55,760 --> 00:21:59,919
you can find the fully functional

00:21:57,360 --> 00:22:01,440
example code at this address

00:21:59,919 --> 00:22:03,440
it contains a tiny program that

00:22:01,440 --> 00:22:04,880
generates the usdb block with the single

00:22:03,440 --> 00:22:06,559
series

00:22:04,880 --> 00:22:08,880
if you put this generated block into

00:22:06,559 --> 00:22:11,919
prometheus you can query it and

00:22:08,880 --> 00:22:14,080
see a sine wave if you want to use this

00:22:11,919 --> 00:22:15,600
approach to generate the sdb blocks

00:22:14,080 --> 00:22:17,440
check out prometheus storage

00:22:15,600 --> 00:22:18,480
documentation and section about

00:22:17,440 --> 00:22:20,159
backfilling

00:22:18,480 --> 00:22:23,200
there are some small things to keep in

00:22:20,159 --> 00:22:26,880
mind when converting very recent data

00:22:23,200 --> 00:22:28,799
and overlapping blocks on the last slide

00:22:26,880 --> 00:22:30,880
you can find some links to learn

00:22:28,799 --> 00:22:33,200
more about the blocks engine in cortex

00:22:30,880 --> 00:22:37,520
and tsdb blocks

00:22:33,200 --> 00:22:37,520

YouTube URL: https://www.youtube.com/watch?v=X8maC_W1rkY


