Title: K8s Labels Everywhere! Decluttering With Node Profile Discovery. - Conor Nolan & Dave Cremins, Intel
Publication date: 2021-05-09
Playlist: KubeCon + CloudNativeCon Europe 2021
Description: 
	Donâ€™t miss out! Join us at our upcoming event: KubeCon + CloudNativeCon North America 2021 in Los Angeles, CA from October 12-15. Learn more at https://kubecon.io The conference features presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects.

K8s Labels Everywhere! Decluttering With Node Profile Discovery. - Conor Nolan & Dave Cremins, Intel

A recent CNCF community survey showed that 57% of respondents have 100+ machines in their fleet and 17% have more than 5000 machines (including VM, bare metal etc.). When managing such broad and diverse clusters, variations in node capabilities and features are inevitable. So how exactly are individual features tracked on a node-by-node basis? Node Feature Discovery (NFD) is commonly used for basic feature discovery and labelling across a Kubernetes cluster. This talk, however, introduces a new component: Node Profile Discovery (NPD). NPD provides an extra layer of abstraction from NFD, alleviating the burden of managing individual features. NPD is designed to work in conjunction with NFD, aggregating individual features into higher level profiles and applying these profiles to suitable nodes. This talk will show how NPD can make life easier for application developers and sys-admins alike.
Captions: 
	00:00:00,320 --> 00:00:05,279
hi welcome to kubecon cloud nativecon

00:00:03,199 --> 00:00:06,879
europe 2021 virtual

00:00:05,279 --> 00:00:08,480
today's talk is going to be focused on

00:00:06,879 --> 00:00:10,960
kubernetes labels everywhere

00:00:08,480 --> 00:00:12,719
decluttering with node profile discovery

00:00:10,960 --> 00:00:14,000
my name is dave kremens i'm a cloud

00:00:12,719 --> 00:00:15,440
software architect in the network

00:00:14,000 --> 00:00:16,800
platform group at intel

00:00:15,440 --> 00:00:18,640
and today i'm going to be joined by

00:00:16,800 --> 00:00:22,160
connor nolan who's a senior engineer

00:00:18,640 --> 00:00:22,160
in the orchestration team at intel

00:00:22,800 --> 00:00:26,320
so for today's agenda we're going to

00:00:24,320 --> 00:00:28,400
cover node feature discovery

00:00:26,320 --> 00:00:30,560
an overview or background on nfd and the

00:00:28,400 --> 00:00:33,360
problem statement associated with it

00:00:30,560 --> 00:00:35,280
we also have an example of a complex

00:00:33,360 --> 00:00:37,120
node specification

00:00:35,280 --> 00:00:39,680
we also intend to provide a conceptual

00:00:37,120 --> 00:00:42,079
overview of node profiles

00:00:39,680 --> 00:00:44,239
and we have orchestrated a very simple

00:00:42,079 --> 00:00:47,039
demo that highlights the the problem

00:00:44,239 --> 00:00:47,360
and presents a possible resolution to

00:00:47,039 --> 00:00:50,719
the

00:00:47,360 --> 00:00:53,920
to the issue and finally we will have

00:00:50,719 --> 00:00:56,719
some key takeaway summaries

00:00:53,920 --> 00:00:56,719
for you guys too

00:00:57,199 --> 00:01:01,359
so before discussing the problem

00:01:00,160 --> 00:01:04,879
statement at hand

00:01:01,359 --> 00:01:06,960
let's focus on what nfd is today so nfd

00:01:04,879 --> 00:01:08,720
is a known feature discovery component

00:01:06,960 --> 00:01:10,560
available in kubernetes

00:01:08,720 --> 00:01:12,560
that detects hardware features and

00:01:10,560 --> 00:01:13,840
advertises those features using node

00:01:12,560 --> 00:01:16,960
labels

00:01:13,840 --> 00:01:20,000
and these particular features

00:01:16,960 --> 00:01:23,680
can be categorized under numerous

00:01:20,000 --> 00:01:24,159
specific domains such as cpu io mmu

00:01:23,680 --> 00:01:28,080
kernel

00:01:24,159 --> 00:01:31,920
memory network storage pci

00:01:28,080 --> 00:01:34,400
system usb etc and it's an important

00:01:31,920 --> 00:01:36,320
component in the kubernetes ecosystem

00:01:34,400 --> 00:01:38,240
given that

00:01:36,320 --> 00:01:40,159
numerous different types of workloads

00:01:38,240 --> 00:01:43,600
need to ha or have

00:01:40,159 --> 00:01:47,119
uh need special attention let's say to

00:01:43,600 --> 00:01:48,079
uh specific features of a platform um so

00:01:47,119 --> 00:01:51,040
for instance

00:01:48,079 --> 00:01:53,200
you know if some platform had um a

00:01:51,040 --> 00:01:55,600
particular feature that was required

00:01:53,200 --> 00:01:57,360
as part of your workload then we want to

00:01:55,600 --> 00:02:00,320
ensure that the workload

00:01:57,360 --> 00:02:03,280
lands on a compute node that has the the

00:02:00,320 --> 00:02:06,799
intended feature available

00:02:03,280 --> 00:02:09,280
but again even though this helped in the

00:02:06,799 --> 00:02:10,560
the placement of workloads um or at

00:02:09,280 --> 00:02:11,520
least complemented the placement of the

00:02:10,560 --> 00:02:14,239
workloads

00:02:11,520 --> 00:02:15,440
it still kind of promoted this tight

00:02:14,239 --> 00:02:18,800
coupling to

00:02:15,440 --> 00:02:20,959
individual platform capabilities and

00:02:18,800 --> 00:02:22,319
you know if i drill into that what i'm

00:02:20,959 --> 00:02:26,000
really saying is

00:02:22,319 --> 00:02:28,959
is that your workload was very

00:02:26,000 --> 00:02:30,480
individual feature aware so each feature

00:02:28,959 --> 00:02:32,000
that was required or intended to be

00:02:30,480 --> 00:02:33,519
leveraged by your workload needs to be

00:02:32,000 --> 00:02:36,480
specified up front

00:02:33,519 --> 00:02:37,920
and that's what i mean by thai coupling

00:02:36,480 --> 00:02:39,120
and when we look at this

00:02:37,920 --> 00:02:40,400
across numerous different types of

00:02:39,120 --> 00:02:41,040
workloads and especially from my

00:02:40,400 --> 00:02:43,680
background

00:02:41,040 --> 00:02:44,720
where it's really based in telco

00:02:43,680 --> 00:02:48,160
workloads

00:02:44,720 --> 00:02:50,080
um there are a lot of features required

00:02:48,160 --> 00:02:51,440
from the platform in order for a

00:02:50,080 --> 00:02:54,560
workload to run

00:02:51,440 --> 00:02:56,879
deterministically and with the right

00:02:54,560 --> 00:02:59,519
level of performance and throughput

00:02:56,879 --> 00:03:00,800
and when we look at what's expected um

00:02:59,519 --> 00:03:03,200
of the platform

00:03:00,800 --> 00:03:04,319
it can become a configuration nightmare

00:03:03,200 --> 00:03:07,680
very quickly

00:03:04,319 --> 00:03:10,720
it really adds to the complexity

00:03:07,680 --> 00:03:13,440
and not to mention that it becomes

00:03:10,720 --> 00:03:13,920
that bit more difficult to schedule when

00:03:13,440 --> 00:03:17,440
you have

00:03:13,920 --> 00:03:18,000
so many different requirements specified

00:03:17,440 --> 00:03:19,760
as part

00:03:18,000 --> 00:03:22,239
of your either workload or your pod

00:03:19,760 --> 00:03:23,680
specification

00:03:22,239 --> 00:03:25,360
also you know when we look at the

00:03:23,680 --> 00:03:27,280
discovery mechanisms there are actually

00:03:25,360 --> 00:03:29,760
multiple ways to

00:03:27,280 --> 00:03:30,319
do detection and labeling nfd is just

00:03:29,760 --> 00:03:32,480
one

00:03:30,319 --> 00:03:33,360
there's also net node labeler and there

00:03:32,480 --> 00:03:36,640
are

00:03:33,360 --> 00:03:39,360
other various components out there

00:03:36,640 --> 00:03:40,000
as part of the ecosystem that are also

00:03:39,360 --> 00:03:43,040
capable

00:03:40,000 --> 00:03:43,760
of labeling their their nodes or

00:03:43,040 --> 00:03:45,280
labeling their

00:03:43,760 --> 00:03:47,120
their features as well and making them

00:03:45,280 --> 00:03:49,519
available but

00:03:47,120 --> 00:03:51,760
with each offering and each component

00:03:49,519 --> 00:03:55,200
that is capable of doing that

00:03:51,760 --> 00:03:56,239
we essentially extend the amount of

00:03:55,200 --> 00:04:00,319
features

00:03:56,239 --> 00:04:02,959
that are let's say claimable

00:04:00,319 --> 00:04:03,519
or schedulable let's say in kubernetes

00:04:02,959 --> 00:04:05,840
and

00:04:03,519 --> 00:04:07,920
we end up creating this laundry list of

00:04:05,840 --> 00:04:09,920
all these different features

00:04:07,920 --> 00:04:11,439
and as i say this can become

00:04:09,920 --> 00:04:14,159
unmanageable and

00:04:11,439 --> 00:04:15,200
adds extra level of complexity and you

00:04:14,159 --> 00:04:17,600
know presents

00:04:15,200 --> 00:04:18,799
new levels of scheduling headaches and

00:04:17,600 --> 00:04:20,239
and the number of features

00:04:18,799 --> 00:04:22,240
continue to grow and this is the

00:04:20,239 --> 00:04:23,520
existing pattern you know this is what's

00:04:22,240 --> 00:04:26,080
out there today and

00:04:23,520 --> 00:04:27,440
you know as every couple of months

00:04:26,080 --> 00:04:29,680
there'll be new

00:04:27,440 --> 00:04:31,280
feature detections added to nfd for

00:04:29,680 --> 00:04:34,240
instance and there'll be new

00:04:31,280 --> 00:04:34,639
node labels available and if a workload

00:04:34,240 --> 00:04:37,759
does

00:04:34,639 --> 00:04:39,759
need a specific feature

00:04:37,759 --> 00:04:41,280
capability out of a platform it's going

00:04:39,759 --> 00:04:42,880
to be added somewhere so that it can be

00:04:41,280 --> 00:04:45,600
claimed

00:04:42,880 --> 00:04:47,600
but again this particular pattern

00:04:45,600 --> 00:04:49,360
focuses too much on the individual

00:04:47,600 --> 00:04:51,360
features

00:04:49,360 --> 00:04:53,520
and when we do that when we focus on

00:04:51,360 --> 00:04:57,600
individual features for a workload

00:04:53,520 --> 00:04:59,520
we tend to misalign on the abstraction

00:04:57,600 --> 00:05:02,560
layers provided by kubernetes

00:04:59,520 --> 00:05:05,520
like kubernetes is a stable api

00:05:02,560 --> 00:05:06,960
with the right level of abstraction and

00:05:05,520 --> 00:05:08,240
you know when we look at it and compare

00:05:06,960 --> 00:05:10,080
it to that

00:05:08,240 --> 00:05:13,120
we kind of break the abstraction by

00:05:10,080 --> 00:05:15,680
tying our workloads to specific

00:05:13,120 --> 00:05:17,759
individual platform capabilities you

00:05:15,680 --> 00:05:18,960
know so the point of my slide here today

00:05:17,759 --> 00:05:21,039
really is

00:05:18,960 --> 00:05:23,120
to try and pivot towards a

00:05:21,039 --> 00:05:25,280
platform-centric perspective

00:05:23,120 --> 00:05:26,560
right so no longer do i need to be

00:05:25,280 --> 00:05:28,880
concerned with

00:05:26,560 --> 00:05:30,960
all of the individual feature

00:05:28,880 --> 00:05:34,479
capabilities of a particular node

00:05:30,960 --> 00:05:36,960
instead i want to be able to avail

00:05:34,479 --> 00:05:38,080
of a platform offering you know

00:05:36,960 --> 00:05:40,639
holistically speaking

00:05:38,080 --> 00:05:41,440
what can my my nose offer me so i can

00:05:40,639 --> 00:05:44,560
land my

00:05:41,440 --> 00:05:45,199
my workload over there when we look at

00:05:44,560 --> 00:05:48,000
it

00:05:45,199 --> 00:05:48,880
under that lens we start to perceive it

00:05:48,000 --> 00:05:50,960
as

00:05:48,880 --> 00:05:53,600
kind of like an almost an optimized

00:05:50,960 --> 00:05:55,440
accelerator for your specific workload

00:05:53,600 --> 00:05:57,440
an example in this case would be

00:05:55,440 --> 00:05:59,919
something like you know

00:05:57,440 --> 00:06:00,720
a power efficient power efficient packed

00:05:59,919 --> 00:06:03,199
processing

00:06:00,720 --> 00:06:04,400
node so when i have a packet processing

00:06:03,199 --> 00:06:05,919
workload

00:06:04,400 --> 00:06:08,160
i don't need to be concerned with all of

00:06:05,919 --> 00:06:09,280
the individual feature items that i need

00:06:08,160 --> 00:06:11,840
for that workload

00:06:09,280 --> 00:06:12,639
instead i can target a specific node

00:06:11,840 --> 00:06:14,479
because

00:06:12,639 --> 00:06:15,680
it's been configured and what's

00:06:14,479 --> 00:06:18,080
available to me

00:06:15,680 --> 00:06:19,680
from a consumer perspective is power

00:06:18,080 --> 00:06:21,280
efficient packet processing

00:06:19,680 --> 00:06:24,880
there's a big difference you know and it

00:06:21,280 --> 00:06:24,880
simplifies things and so on

00:06:25,520 --> 00:06:30,960
in my next slide i wanted to showcase an

00:06:28,800 --> 00:06:32,720
example of a very complicated

00:06:30,960 --> 00:06:35,199
specification

00:06:32,720 --> 00:06:36,160
this is taken from a real real world

00:06:35,199 --> 00:06:38,560
application

00:06:36,160 --> 00:06:40,560
it is telco oriented but it gives you

00:06:38,560 --> 00:06:43,360
guys an idea of um

00:06:40,560 --> 00:06:45,199
how fast things can you know become

00:06:43,360 --> 00:06:47,039
unmanageable and out of control

00:06:45,199 --> 00:06:49,039
when the the list of feature

00:06:47,039 --> 00:06:50,000
requirements be it for your node or your

00:06:49,039 --> 00:06:53,039
workload

00:06:50,000 --> 00:06:53,039
continues to grow

00:06:57,520 --> 00:07:05,360
so as i say this is a realistic

00:07:01,280 --> 00:07:08,720
specification we put it in video format

00:07:05,360 --> 00:07:08,720
because we couldn't fit it on the slide

00:07:08,880 --> 00:07:12,240
and i think we're almost done

00:07:12,720 --> 00:07:20,240
so as well as evident

00:07:16,400 --> 00:07:21,440
um or at least as showcased by that then

00:07:20,240 --> 00:07:23,599
i think it should be clear

00:07:21,440 --> 00:07:25,120
that you know there are a lot of

00:07:23,599 --> 00:07:28,560
opportunities for

00:07:25,120 --> 00:07:31,520
um a really

00:07:28,560 --> 00:07:32,080
large level of complexity within you

00:07:31,520 --> 00:07:34,479
know

00:07:32,080 --> 00:07:35,440
feature capability detection not just

00:07:34,479 --> 00:07:37,440
with nfd

00:07:35,440 --> 00:07:38,560
but the the the feature detection

00:07:37,440 --> 00:07:40,240
mechanism itself

00:07:38,560 --> 00:07:42,560
so that was an example of how

00:07:40,240 --> 00:07:45,680
complicated a specification can become

00:07:42,560 --> 00:07:47,120
and how hard it can be to to manage now

00:07:45,680 --> 00:07:48,400
i'd like to hand you over to my

00:07:47,120 --> 00:07:49,520
colleague connor who will take you

00:07:48,400 --> 00:07:51,599
through

00:07:49,520 --> 00:07:54,240
more of the presentation uh so over to

00:07:51,599 --> 00:07:55,840
you connor thanks

00:07:54,240 --> 00:07:57,759
thanks dave okay i'm going to do a quick

00:07:55,840 --> 00:07:59,120
high level overview of how no profile

00:07:57,759 --> 00:08:00,879
discovery works

00:07:59,120 --> 00:08:02,160
first by showing the flow that currently

00:08:00,879 --> 00:08:04,000
exists and then

00:08:02,160 --> 00:08:05,440
how mpd can make life a little bit

00:08:04,000 --> 00:08:06,639
easier for the user and for the

00:08:05,440 --> 00:08:08,879
scheduler

00:08:06,639 --> 00:08:10,479
so let's take a really simple example so

00:08:08,879 --> 00:08:11,759
here we've got a cluster of eight nodes

00:08:10,479 --> 00:08:12,639
and each node has a different set of

00:08:11,759 --> 00:08:14,160
features

00:08:12,639 --> 00:08:15,919
and i want to keep in mind the example

00:08:14,160 --> 00:08:17,360
that dave has just shown of

00:08:15,919 --> 00:08:19,919
a node with a couple of hundred

00:08:17,360 --> 00:08:21,039
individual features instead of a handful

00:08:19,919 --> 00:08:22,879
like we have here

00:08:21,039 --> 00:08:24,720
and then picture a cluster with five

00:08:22,879 --> 00:08:26,240
thousand of those nodes instead of eight

00:08:24,720 --> 00:08:29,120
and you quickly get an idea of how

00:08:26,240 --> 00:08:30,960
unmanageable the situation can become

00:08:29,120 --> 00:08:33,360
so a part is created and it's looking

00:08:30,960 --> 00:08:35,039
for a list of individual feature levels

00:08:33,360 --> 00:08:37,039
and it's using the node selector

00:08:35,039 --> 00:08:39,599
construct to ensure the scheduler gives

00:08:37,039 --> 00:08:41,279
it a node with all of these features

00:08:39,599 --> 00:08:43,120
so if i'm the scheduler and i'm going

00:08:41,279 --> 00:08:44,480
through my filtering process

00:08:43,120 --> 00:08:46,240
i'm going to look at this part and the

00:08:44,480 --> 00:08:48,880
label specified and say

00:08:46,240 --> 00:08:50,160
okay so this pod wants a sni crypto

00:08:48,880 --> 00:08:52,959
instruction

00:08:50,160 --> 00:08:54,000
so node 5 doesn't have that so that gets

00:08:52,959 --> 00:08:57,040
filtered out

00:08:54,000 --> 00:08:59,680
this part wants avx 512 instruction set

00:08:57,040 --> 00:09:01,040
node 1 has avx but doesn't have avx 512

00:08:59,680 --> 00:09:04,080
so that's no good

00:09:01,040 --> 00:09:04,800
uh this part wants sstbf so speed select

00:09:04,080 --> 00:09:08,240
technology

00:09:04,800 --> 00:09:10,480
base frequency node 7 doesn't have that

00:09:08,240 --> 00:09:11,920
and this part also wants layer 3 cache

00:09:10,480 --> 00:09:13,519
allocation technology

00:09:11,920 --> 00:09:15,760
and node 8 doesn't have that so those

00:09:13,519 --> 00:09:17,200
are all filtered out i see this part is

00:09:15,760 --> 00:09:18,640
also looking for a couple of custom

00:09:17,200 --> 00:09:20,560
feature labels

00:09:18,640 --> 00:09:22,399
so let's say the clustered main has

00:09:20,560 --> 00:09:23,440
configured some nodes in the cluster to

00:09:22,399 --> 00:09:25,600
run the

00:09:23,440 --> 00:09:27,120
single luminal topology manager policy

00:09:25,600 --> 00:09:29,120
and then they've applied a label to

00:09:27,120 --> 00:09:31,440
those nodes to signify that

00:09:29,120 --> 00:09:33,279
likewise they've configured some nodes

00:09:31,440 --> 00:09:35,360
with isil cpus and applied a label to

00:09:33,279 --> 00:09:36,959
those and also represent that as well

00:09:35,360 --> 00:09:38,640
so this pod wants a node where it will

00:09:36,959 --> 00:09:41,360
be guaranteed pneuma alignment

00:09:38,640 --> 00:09:43,519
so that rules out nodes two and four and

00:09:41,360 --> 00:09:45,279
finally the pod wants to run on a node

00:09:43,519 --> 00:09:48,080
configured with iso cpus

00:09:45,279 --> 00:09:48,800
so node three is no good there so after

00:09:48,080 --> 00:09:51,440
all that

00:09:48,800 --> 00:09:53,120
node 6 is the only feasible node and the

00:09:51,440 --> 00:09:55,279
scheduler moves on to the next step in

00:09:53,120 --> 00:09:58,080
its filtering process

00:09:55,279 --> 00:10:00,080
so now instead of polluting our pod spec

00:09:58,080 --> 00:10:02,800
with a bunch of individual features

00:10:00,080 --> 00:10:04,640
let's create a node profile cr

00:10:02,800 --> 00:10:06,560
containing all the features we want to

00:10:04,640 --> 00:10:07,600
make up a profile that best suits our

00:10:06,560 --> 00:10:10,160
workload

00:10:07,600 --> 00:10:11,360
so once the cr is created no profile

00:10:10,160 --> 00:10:13,360
discovery reacts

00:10:11,360 --> 00:10:15,600
and applies a new profile label to any

00:10:13,360 --> 00:10:17,360
nodes that fit that profile

00:10:15,600 --> 00:10:19,440
then when the pod is created instead of

00:10:17,360 --> 00:10:20,560
looking for a plethora of individual

00:10:19,440 --> 00:10:22,880
features

00:10:20,560 --> 00:10:24,560
it's now looking for one label the label

00:10:22,880 --> 00:10:27,760
of the profile that has been tailored to

00:10:24,560 --> 00:10:30,240
optimize this particular workload

00:10:27,760 --> 00:10:31,600
so overall a very simple concept but one

00:10:30,240 --> 00:10:33,440
that lends itself to

00:10:31,600 --> 00:10:36,079
a top-down approach to workload

00:10:33,440 --> 00:10:38,079
scheduling and infrastructure management

00:10:36,079 --> 00:10:39,839
and this approach can be utilized to

00:10:38,079 --> 00:10:41,519
automate and scale the process of

00:10:39,839 --> 00:10:44,640
cluster slicing

00:10:41,519 --> 00:10:45,600
so this is designating nodes optimized

00:10:44,640 --> 00:10:47,360
for a particular

00:10:45,600 --> 00:10:49,360
performance critical workload to run

00:10:47,360 --> 00:10:50,720
those workloads only

00:10:49,360 --> 00:10:52,320
and this is a concept we'll elaborate

00:10:50,720 --> 00:10:54,959
more on in the demo which i'm going to

00:10:52,320 --> 00:10:54,959
go through next

00:10:55,920 --> 00:10:59,760
okay so as a proof of concept we've

00:10:57,760 --> 00:11:01,040
built out no profile discovery as a

00:10:59,760 --> 00:11:03,200
kubernetes operator

00:11:01,040 --> 00:11:04,079
and it's deployed into cluster alongside

00:11:03,200 --> 00:11:05,440
nfg

00:11:04,079 --> 00:11:07,760
and then essentially leverages the

00:11:05,440 --> 00:11:08,880
feature discovery performed by nfd to

00:11:07,760 --> 00:11:11,040
enable these

00:11:08,880 --> 00:11:15,839
uh higher level profiles uh so let's

00:11:11,040 --> 00:11:15,839
take a look at the cluster setup

00:11:16,000 --> 00:11:19,600
so i have a four node cluster three

00:11:17,680 --> 00:11:21,680
worker nodes in the control plane node

00:11:19,600 --> 00:11:24,480
if i look at the pods that are run

00:11:21,680 --> 00:11:25,279
so you can see here the nft master is

00:11:24,480 --> 00:11:27,600
running

00:11:25,279 --> 00:11:28,480
i've got an nfd worker on each of my

00:11:27,600 --> 00:11:31,519
worker nodes

00:11:28,480 --> 00:11:33,440
and down here we can see that the no

00:11:31,519 --> 00:11:35,360
profile discovery operator is running so

00:11:33,440 --> 00:11:37,440
this is a single pad deployment

00:11:35,360 --> 00:11:39,040
so there's no need for individual no

00:11:37,440 --> 00:11:41,360
demons or

00:11:39,040 --> 00:11:43,040
for host level discovery or anything

00:11:41,360 --> 00:11:45,279
like that it's just a single point of

00:11:43,040 --> 00:11:48,320
contact with the kubernetes api

00:11:45,279 --> 00:11:50,320
let's take a look at the labels on our

00:11:48,320 --> 00:11:54,800
worker nodes

00:11:50,320 --> 00:11:56,959
so we can see up here on cube worker one

00:11:54,800 --> 00:11:58,320
as a bunch of feature labels applied by

00:11:56,959 --> 00:12:02,480
nfd

00:11:58,320 --> 00:12:03,360
uh cube worker two also a host of nft

00:12:02,480 --> 00:12:04,560
labels

00:12:03,360 --> 00:12:06,160
we can also see a couple of custom

00:12:04,560 --> 00:12:06,959
labels kind of labels we touched on

00:12:06,160 --> 00:12:09,440
earlier

00:12:06,959 --> 00:12:10,000
uh like a specific topology manager

00:12:09,440 --> 00:12:13,279
policy

00:12:10,000 --> 00:12:17,040
or a node configured with isil cpus

00:12:13,279 --> 00:12:19,519
and cube worker 3 watch the same um

00:12:17,040 --> 00:12:20,079
mix of nfd labels and a couple of custom

00:12:19,519 --> 00:12:21,760
labels

00:12:20,079 --> 00:12:23,440
if it's all pretty standard we can take

00:12:21,760 --> 00:12:26,079
a look at a node profile

00:12:23,440 --> 00:12:26,079
spec now

00:12:28,800 --> 00:12:32,480
this is a simple no profile cr it's been

00:12:31,040 --> 00:12:34,320
given the name

00:12:32,480 --> 00:12:36,639
high performance pack processing and in

00:12:34,320 --> 00:12:38,000
the spec our number of desired feature

00:12:36,639 --> 00:12:39,600
enables to make up this profile

00:12:38,000 --> 00:12:41,040
so again like in the example we have

00:12:39,600 --> 00:12:45,040
before we have

00:12:41,040 --> 00:12:48,240
asni avx 512 sdbf

00:12:45,040 --> 00:12:53,839
layer 3 cache icpus and topology manager

00:12:48,240 --> 00:12:53,839
policy create that profile

00:12:55,200 --> 00:12:59,760
and we can see that it exists

00:12:58,480 --> 00:13:01,680
and i'm just going to leave the no

00:12:59,760 --> 00:13:03,920
profile spec open on the left so we have

00:13:01,680 --> 00:13:05,680
it as a reference

00:13:03,920 --> 00:13:07,920
so now over my other screen i'm going to

00:13:05,680 --> 00:13:09,839
check again for all my worker node

00:13:07,920 --> 00:13:12,160
labels now that the profile has been

00:13:09,839 --> 00:13:14,079
created

00:13:12,160 --> 00:13:15,839
so what we're looking for here is a new

00:13:14,079 --> 00:13:20,000
label with the profile.node

00:13:15,839 --> 00:13:23,040
prefix if i scroll up to cubeworker1

00:13:20,000 --> 00:13:26,079
you can see that there's no change here

00:13:23,040 --> 00:13:28,680
but on cubeworker2

00:13:26,079 --> 00:13:30,240
now we can see this new label with the

00:13:28,680 --> 00:13:32,839
profile.nodeprefix

00:13:30,240 --> 00:13:34,720
and the name of our high performance

00:13:32,839 --> 00:13:38,320
profile

00:13:34,720 --> 00:13:40,160
and on cue worker 3 so that's also

00:13:38,320 --> 00:13:42,240
unchanged and at a glance we can see

00:13:40,160 --> 00:13:44,240
that this node doesn't have the

00:13:42,240 --> 00:13:47,199
desired topology manager label so it

00:13:44,240 --> 00:13:47,199
doesn't fit the profile

00:13:47,279 --> 00:13:50,880
so in summary what this means is of our

00:13:49,519 --> 00:13:52,880
three worker nodes

00:13:50,880 --> 00:13:54,399
uh just one of those nodes fits the

00:13:52,880 --> 00:13:56,160
criteria for our

00:13:54,399 --> 00:13:58,399
high performance profile and has those

00:13:56,160 --> 00:14:02,399
matching labels and it's given the

00:13:58,399 --> 00:14:04,240
additional uh profile label

00:14:02,399 --> 00:14:06,320
so what would happen if a node no longer

00:14:04,240 --> 00:14:07,440
fits a profile due to some change in its

00:14:06,320 --> 00:14:09,040
configuration

00:14:07,440 --> 00:14:11,760
for example let's say the sysadmin

00:14:09,040 --> 00:14:12,160
decides to disable the topology manager

00:14:11,760 --> 00:14:14,639
on

00:14:12,160 --> 00:14:17,120
cube worker 2 and then as a result they

00:14:14,639 --> 00:14:19,760
then remove the topology manager label

00:14:17,120 --> 00:14:19,760
like so

00:14:21,440 --> 00:14:25,680
what we would expect is for no profile

00:14:23,600 --> 00:14:27,279
discovery to react and

00:14:25,680 --> 00:14:28,959
update the node so that it no longer

00:14:27,279 --> 00:14:30,079
matches the profile due to the change in

00:14:28,959 --> 00:14:33,199
circumstances

00:14:30,079 --> 00:14:34,959
and if we check our node labels again

00:14:33,199 --> 00:14:37,040
we can see that not only has the

00:14:34,959 --> 00:14:37,519
topology manager label been removed but

00:14:37,040 --> 00:14:39,360
also

00:14:37,519 --> 00:14:41,040
our profile label has been removed

00:14:39,360 --> 00:14:43,680
because this node no longer fits

00:14:41,040 --> 00:14:45,360
the criteria for this profile so now

00:14:43,680 --> 00:14:47,199
none of our three worker nodes

00:14:45,360 --> 00:14:49,920
fit the profile and as a result none of

00:14:47,199 --> 00:14:52,079
them now possess the profile label

00:14:49,920 --> 00:14:55,120
and likewise if we were to make a change

00:14:52,079 --> 00:14:58,000
to the no profile object itself

00:14:55,120 --> 00:14:59,839
so for example if i was to remove the

00:14:58,000 --> 00:15:02,880
topology manager

00:14:59,839 --> 00:15:05,839
feature label from the spec and then

00:15:02,880 --> 00:15:05,839
reapply that spec

00:15:06,560 --> 00:15:10,079
again i'll just leave it open for

00:15:07,920 --> 00:15:13,199
reference and now we go back

00:15:10,079 --> 00:15:16,399
and check our labels once more

00:15:13,199 --> 00:15:17,440
we can see that now nodes 2 cube worker

00:15:16,399 --> 00:15:20,880
00:15:17,440 --> 00:15:22,399
and cube worker 3 both fit the profile

00:15:20,880 --> 00:15:25,199
and are given the label

00:15:22,399 --> 00:15:26,079
the profile high performance pack

00:15:25,199 --> 00:15:28,160
processing label

00:15:26,079 --> 00:15:30,320
because both of these nodes now match

00:15:28,160 --> 00:15:32,639
the criteria listed over here

00:15:30,320 --> 00:15:34,079
now that the topology manager policy has

00:15:32,639 --> 00:15:36,399
been removed

00:15:34,079 --> 00:15:38,000
also as an optional add-on to the core

00:15:36,399 --> 00:15:39,040
functionality of basic feature

00:15:38,000 --> 00:15:40,800
aggregation

00:15:39,040 --> 00:15:43,440
we've also explored the possibility of

00:15:40,800 --> 00:15:46,079
introducing a node tainting mechanism

00:15:43,440 --> 00:15:49,360
via the crd so i'm going to add in these

00:15:46,079 --> 00:15:51,040
additional fields into my spec

00:15:49,360 --> 00:15:52,480
so what we're aiming to achieve here

00:15:51,040 --> 00:15:54,079
with these additional attained behavior

00:15:52,480 --> 00:15:56,639
parameters is that

00:15:54,079 --> 00:15:58,320
50 of nodes which fit the high

00:15:56,639 --> 00:15:59,920
performance profile

00:15:58,320 --> 00:16:01,839
should be tainted with a no schedule

00:15:59,920 --> 00:16:02,800
taint so in our small example we have

00:16:01,839 --> 00:16:04,240
two nodes

00:16:02,800 --> 00:16:06,320
now labeled with the high performance

00:16:04,240 --> 00:16:09,120
profile and so we're looking

00:16:06,320 --> 00:16:10,480
for one of those nodes to be tainted but

00:16:09,120 --> 00:16:11,440
if you can picture this on a larger

00:16:10,480 --> 00:16:13,120
scale

00:16:11,440 --> 00:16:14,720
the purpose of this to designate

00:16:13,120 --> 00:16:17,519
specific nodes which have been

00:16:14,720 --> 00:16:19,839
optimized and configured for particular

00:16:17,519 --> 00:16:22,079
performance sensitive workloads so

00:16:19,839 --> 00:16:23,759
essentially treating nodes themselves as

00:16:22,079 --> 00:16:26,720
accelerators and

00:16:23,759 --> 00:16:28,320
slicing your cluster accordingly based

00:16:26,720 --> 00:16:30,639
on these profiles

00:16:28,320 --> 00:16:32,880
then workloads with requirements which

00:16:30,639 --> 00:16:35,360
match a given profile are scheduled

00:16:32,880 --> 00:16:37,199
exclusively to these designated nodes

00:16:35,360 --> 00:16:40,399
and those resources are not

00:16:37,199 --> 00:16:42,079
wasted on less critical workloads so

00:16:40,399 --> 00:16:44,639
i'll update the cr

00:16:42,079 --> 00:16:44,639
once again

00:16:45,600 --> 00:16:51,199
and this time i'm going to check the

00:16:46,959 --> 00:16:53,759
taints of my worker nodes

00:16:51,199 --> 00:16:54,800
so we can see here there's no values for

00:16:53,759 --> 00:16:58,160
cube worker

00:16:54,800 --> 00:17:01,440
1 and cube worker 2 but for cube worker

00:16:58,160 --> 00:17:03,360
3 we can see that it has been tainted

00:17:01,440 --> 00:17:05,039
with the high performance profile and

00:17:03,360 --> 00:17:06,559
the no schedule change so this is what

00:17:05,039 --> 00:17:09,600
we were expecting to see

00:17:06,559 --> 00:17:11,760
we had two nodes labeled with the

00:17:09,600 --> 00:17:12,880
correct high performance profile and we

00:17:11,760 --> 00:17:14,400
want to retain 50

00:17:12,880 --> 00:17:15,919
of those which is one and that's what

00:17:14,400 --> 00:17:19,280
happened so also i want to check

00:17:15,919 --> 00:17:20,720
the labels of the worker nodes and now

00:17:19,280 --> 00:17:23,600
we can see so

00:17:20,720 --> 00:17:25,360
uh cubeworker2 is still the same so it

00:17:23,600 --> 00:17:27,839
has this profile

00:17:25,360 --> 00:17:29,600
label which is true keyworker 3 still

00:17:27,839 --> 00:17:31,120
has the profile label but you'll notice

00:17:29,600 --> 00:17:33,760
that the value is changed to

00:17:31,120 --> 00:17:35,520
tainted so this allows workloads with

00:17:33,760 --> 00:17:36,960
tolerations to target this node

00:17:35,520 --> 00:17:40,080
specifically

00:17:36,960 --> 00:17:42,000
as opposed to non-designated nodes which

00:17:40,080 --> 00:17:44,240
also match the profile

00:17:42,000 --> 00:17:47,600
and this information is also reflected

00:17:44,240 --> 00:17:50,160
in our cr so

00:17:47,600 --> 00:17:52,000
if we describe our high performance

00:17:50,160 --> 00:17:53,600
profile we can see

00:17:52,000 --> 00:17:55,280
down here so this is the spec with the

00:17:53,600 --> 00:17:57,440
feature labels that we

00:17:55,280 --> 00:17:59,520
specified and the chain behavior that we

00:17:57,440 --> 00:18:00,480
set and here in the status you can see

00:17:59,520 --> 00:18:02,880
so

00:18:00,480 --> 00:18:03,919
two nodes were labeled i.e two nodes

00:18:02,880 --> 00:18:06,400
match the profile

00:18:03,919 --> 00:18:08,080
and we specified we wanted 50 of those

00:18:06,400 --> 00:18:11,039
tainted and you can see here

00:18:08,080 --> 00:18:12,720
one of those nodes is tainted and for

00:18:11,039 --> 00:18:15,440
completeness sake

00:18:12,720 --> 00:18:17,600
let's say you wanted to scale up the

00:18:15,440 --> 00:18:18,080
number of designated nodes so let's bump

00:18:17,600 --> 00:18:21,679
this up

00:18:18,080 --> 00:18:22,960
now to 100 uh so

00:18:21,679 --> 00:18:25,280
what that means is that we want to

00:18:22,960 --> 00:18:28,080
change basically all of the nodes which

00:18:25,280 --> 00:18:30,960
match the profile so i'll reapply that

00:18:28,080 --> 00:18:32,160
cr and again i'll check the teens and

00:18:30,960 --> 00:18:34,720
now we can see that

00:18:32,160 --> 00:18:36,000
workers node worker nodes two and three

00:18:34,720 --> 00:18:38,640
are both changes

00:18:36,000 --> 00:18:39,120
and likewise with our labels we should

00:18:38,640 --> 00:18:42,400
see

00:18:39,120 --> 00:18:44,400
that again value for um our profile

00:18:42,400 --> 00:18:47,440
label has changed to tainted

00:18:44,400 --> 00:18:49,120
and if i check my cr again we should see

00:18:47,440 --> 00:18:50,640
that reflected in the status so again

00:18:49,120 --> 00:18:52,960
this is updated here

00:18:50,640 --> 00:18:54,160
like i said we we specified 100 and

00:18:52,960 --> 00:18:56,720
that's what we've been given

00:18:54,160 --> 00:18:57,919
uh all nodes which match the profile are

00:18:56,720 --> 00:19:00,480
now tainted

00:18:57,919 --> 00:19:01,679
i.e designated for a specific uh

00:19:00,480 --> 00:19:03,360
workload

00:19:01,679 --> 00:19:05,039
okay we've seen what it is and how it

00:19:03,360 --> 00:19:06,960
works so now let's cover

00:19:05,039 --> 00:19:09,440
why you would use no profile discovery

00:19:06,960 --> 00:19:10,960
and the advantages it can provide

00:19:09,440 --> 00:19:12,480
so a number of advantages present

00:19:10,960 --> 00:19:15,039
themselves when we look at the

00:19:12,480 --> 00:19:16,240
compound effect of multiple features on

00:19:15,039 --> 00:19:19,200
a platform

00:19:16,240 --> 00:19:21,200
versus a single concentrated profile so

00:19:19,200 --> 00:19:22,960
firstly the reduced complexity in the

00:19:21,200 --> 00:19:24,400
workload scheduling process as we've

00:19:22,960 --> 00:19:26,480
shown in the example

00:19:24,400 --> 00:19:27,520
and then and probably the most obvious

00:19:26,480 --> 00:19:29,760
advantage

00:19:27,520 --> 00:19:30,960
at the simplification of the pod spec

00:19:29,760 --> 00:19:33,200
itself and

00:19:30,960 --> 00:19:34,720
so now you can remove this sprawling

00:19:33,200 --> 00:19:36,240
laundry list of feature requirements

00:19:34,720 --> 00:19:38,960
baked into your pod spec

00:19:36,240 --> 00:19:39,360
and instead reference a single profile

00:19:38,960 --> 00:19:41,840
which

00:19:39,360 --> 00:19:44,400
has already been curated for your

00:19:41,840 --> 00:19:46,720
application's performance needs

00:19:44,400 --> 00:19:48,000
uh move towards a top-down perspective

00:19:46,720 --> 00:19:50,080
so what do we mean by this

00:19:48,000 --> 00:19:52,080
um we want to get away from the

00:19:50,080 --> 00:19:54,320
bottom-up mindset of

00:19:52,080 --> 00:19:55,280
my app needs this feature this feature

00:19:54,320 --> 00:19:57,039
and this feature

00:19:55,280 --> 00:19:59,919
in order to fulfill a certain quality of

00:19:57,039 --> 00:20:01,440
service instead let's move towards a

00:19:59,919 --> 00:20:03,200
my app needs to fulfill a certain

00:20:01,440 --> 00:20:04,960
quality of service so what

00:20:03,200 --> 00:20:07,360
make up our profile of features is going

00:20:04,960 --> 00:20:09,280
to achieve that for my application

00:20:07,360 --> 00:20:10,720
and then we can align these profiles of

00:20:09,280 --> 00:20:13,120
these makeups with

00:20:10,720 --> 00:20:15,679
the abstractions that are most prevalent

00:20:13,120 --> 00:20:18,000
in today's deployments

00:20:15,679 --> 00:20:20,320
so cluster slicing no profile discovery

00:20:18,000 --> 00:20:23,039
naturally lends itself to a

00:20:20,320 --> 00:20:25,280
model of cluster slicing or partitioning

00:20:23,039 --> 00:20:27,600
of a cluster into groups of nodes with

00:20:25,280 --> 00:20:29,919
common use cases and the demo showed us

00:20:27,600 --> 00:20:31,760
some functionality for

00:20:29,919 --> 00:20:33,600
designating nodes for specific

00:20:31,760 --> 00:20:36,400
performance critical workloads

00:20:33,600 --> 00:20:37,120
and then providing this mechanism in a

00:20:36,400 --> 00:20:39,840
lightweight

00:20:37,120 --> 00:20:41,120
and scalable way that's kubernetes

00:20:39,840 --> 00:20:42,640
native and

00:20:41,120 --> 00:20:45,360
could potentially remove a lot of

00:20:42,640 --> 00:20:47,600
overhead for a cluster admin

00:20:45,360 --> 00:20:50,559
so with that i will hand back today for

00:20:47,600 --> 00:20:50,559
some closing comments

00:20:51,679 --> 00:20:56,720
thanks for the demo connor um so

00:20:54,720 --> 00:20:58,720
shown there you know we've essentially

00:20:56,720 --> 00:20:59,840
demonstrated the the problem at hand

00:20:58,720 --> 00:21:02,080
whereby

00:20:59,840 --> 00:21:03,679
you know a laundry list of feature asks

00:21:02,080 --> 00:21:05,919
can get out of control

00:21:03,679 --> 00:21:06,799
uh whereby we can generate a profile

00:21:05,919 --> 00:21:11,280
level

00:21:06,799 --> 00:21:13,039
uh label um that has the

00:21:11,280 --> 00:21:15,679
where where the individual capabilities

00:21:13,039 --> 00:21:17,280
roll roll into it

00:21:15,679 --> 00:21:19,120
and you know when we've done something

00:21:17,280 --> 00:21:21,440
like this to try and simplify

00:21:19,120 --> 00:21:22,480
the um the placement models for

00:21:21,440 --> 00:21:24,400
workloads

00:21:22,480 --> 00:21:26,960
you know what what else can we do you

00:21:24,400 --> 00:21:29,919
know so if we do have uh proliferation

00:21:26,960 --> 00:21:30,400
of uh this type of mechanism and you

00:21:29,919 --> 00:21:33,440
know

00:21:30,400 --> 00:21:35,440
new patterns emerge based on

00:21:33,440 --> 00:21:36,640
utilizing something like this you know

00:21:35,440 --> 00:21:37,679
there's always the question of what

00:21:36,640 --> 00:21:39,919
could we do next

00:21:37,679 --> 00:21:42,320
could we build on that um is there

00:21:39,919 --> 00:21:45,520
another avenue of work we could look at

00:21:42,320 --> 00:21:48,240
and there is so um

00:21:45,520 --> 00:21:49,919
we're also looking to you know based on

00:21:48,240 --> 00:21:52,000
you know your profiles

00:21:49,919 --> 00:21:53,600
you know so like it it's easy to have

00:21:52,000 --> 00:21:56,559
this get out of control

00:21:53,600 --> 00:21:58,080
um and to protect you know the integrity

00:21:56,559 --> 00:22:00,480
of of profiles

00:21:58,080 --> 00:22:02,480
you know we're looking at a json schema

00:22:00,480 --> 00:22:03,440
to validate and promote consistency of

00:22:02,480 --> 00:22:07,520
them

00:22:03,440 --> 00:22:09,679
you know and if we do um you know

00:22:07,520 --> 00:22:11,440
start work in that particular domain

00:22:09,679 --> 00:22:13,520
then it's easy then to tie

00:22:11,440 --> 00:22:14,480
this into you know existing automation

00:22:13,520 --> 00:22:17,840
pipelines

00:22:14,480 --> 00:22:18,960
and validate um the the creation of new

00:22:17,840 --> 00:22:21,039
profiles

00:22:18,960 --> 00:22:23,840
right so i'd see this as something that

00:22:21,039 --> 00:22:27,280
would be beneficial going forward

00:22:23,840 --> 00:22:29,840
assuming that you know npd was

00:22:27,280 --> 00:22:31,360
successful or that you know that the

00:22:29,840 --> 00:22:33,360
profile awareness

00:22:31,360 --> 00:22:34,559
that that this brings to the to the

00:22:33,360 --> 00:22:38,159
community

00:22:34,559 --> 00:22:38,159
would be accepted and utilized

00:22:38,799 --> 00:22:42,400
and we have a couple of options here

00:22:40,159 --> 00:22:45,280
right so what's been demonstrated today

00:22:42,400 --> 00:22:46,799
is um is kind of a simple kubernetes

00:22:45,280 --> 00:22:48,799
operator that has

00:22:46,799 --> 00:22:50,159
its own custom resource and its own

00:22:48,799 --> 00:22:52,400
controller

00:22:50,159 --> 00:22:54,080
but you know we could take a different

00:22:52,400 --> 00:22:56,880
approach and extend nfd

00:22:54,080 --> 00:22:58,080
by providing the same capabilities

00:22:56,880 --> 00:23:01,360
directly into it

00:22:58,080 --> 00:23:04,080
whereby nfd actually incorporates

00:23:01,360 --> 00:23:05,360
the profile management and generation

00:23:04,080 --> 00:23:06,960
that's another approach that we could

00:23:05,360 --> 00:23:08,960
look at

00:23:06,960 --> 00:23:10,799
we've also looked at a potential

00:23:08,960 --> 00:23:14,159
integration point with nfd

00:23:10,799 --> 00:23:17,840
whereby we build uh two separations

00:23:14,159 --> 00:23:18,960
and one to uh focus on you know profile

00:23:17,840 --> 00:23:20,559
concerns

00:23:18,960 --> 00:23:23,120
that can then act as a complementary

00:23:20,559 --> 00:23:25,520
component to profile management

00:23:23,120 --> 00:23:27,200
so nfd are profile concerns and

00:23:25,520 --> 00:23:29,200
management of them could be done in one

00:23:27,200 --> 00:23:30,559
component and nfd could manage the

00:23:29,200 --> 00:23:34,480
actual

00:23:30,559 --> 00:23:37,520
the labels the profile labels themselves

00:23:34,480 --> 00:23:40,159
and we've also um

00:23:37,520 --> 00:23:42,000
seen some use cases or potential

00:23:40,159 --> 00:23:44,799
possibilities with

00:23:42,000 --> 00:23:47,120
uh policy-based control systems whereby

00:23:44,799 --> 00:23:47,120
you know

00:23:47,360 --> 00:23:53,120
like um policy system could

00:23:51,200 --> 00:23:54,240
create the profile based on its own

00:23:53,120 --> 00:23:56,320
policies

00:23:54,240 --> 00:23:57,440
um and this is something that you know

00:23:56,320 --> 00:24:01,120
could be leveraged

00:23:57,440 --> 00:24:03,200
in kubernetes given that it's it's um

00:24:01,120 --> 00:24:04,880
policy or it can be policy heavy uh

00:24:03,200 --> 00:24:05,760
depending on your infrastructure and

00:24:04,880 --> 00:24:07,440
platform

00:24:05,760 --> 00:24:09,600
so you could tie it directly in there

00:24:07,440 --> 00:24:12,960
and generate a profile based on

00:24:09,600 --> 00:24:14,559
your existing policy controls

00:24:12,960 --> 00:24:16,159
and again then with this then you have

00:24:14,559 --> 00:24:18,159
the option then of enforcing the

00:24:16,159 --> 00:24:20,080
profiles so that

00:24:18,159 --> 00:24:21,679
if a particular policy is not met or

00:24:20,080 --> 00:24:22,320
honored then the profile is no longer

00:24:21,679 --> 00:24:24,080
valid

00:24:22,320 --> 00:24:26,159
or is invalidated based on some other

00:24:24,080 --> 00:24:27,200
action uh from within your your policy

00:24:26,159 --> 00:24:29,919
control

00:24:27,200 --> 00:24:31,520
so like there are numerous um things

00:24:29,919 --> 00:24:32,640
that we can do next with this particular

00:24:31,520 --> 00:24:35,120
approach

00:24:32,640 --> 00:24:36,000
um so i i hope you've um you've enjoyed

00:24:35,120 --> 00:24:39,520
today's talk

00:24:36,000 --> 00:24:43,120
um it's i wouldn't say that it's um

00:24:39,520 --> 00:24:45,440
too much of a push um beyond

00:24:43,120 --> 00:24:47,279
what nfd does or what you know features

00:24:45,440 --> 00:24:48,720
of feature labels have brought to the

00:24:47,279 --> 00:24:49,679
the community or to the cabrillo's

00:24:48,720 --> 00:24:52,960
ecosystem

00:24:49,679 --> 00:24:55,760
um but it's definitely um you know

00:24:52,960 --> 00:24:57,200
bringing an awareness to your your kind

00:24:55,760 --> 00:24:58,880
of your platform

00:24:57,200 --> 00:25:01,120
your holistic platform capabilities

00:24:58,880 --> 00:25:06,000
versus the individual items

00:25:01,120 --> 00:25:08,000
that are prevalent today so with that

00:25:06,000 --> 00:25:10,159
i'd like to say thank you to the

00:25:08,000 --> 00:25:12,799
audience for attending to talk today

00:25:10,159 --> 00:25:13,679
and we hope you enjoy it and we hope to

00:25:12,799 --> 00:25:16,720
see you again

00:25:13,679 --> 00:25:19,120
in the the next um kubecon so

00:25:16,720 --> 00:25:20,480
thank you very much and now we'll we'll

00:25:19,120 --> 00:25:25,520
see you again maybe in

00:25:20,480 --> 00:25:25,520

YouTube URL: https://www.youtube.com/watch?v=y4UF9ML0BDw


