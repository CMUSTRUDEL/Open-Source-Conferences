Title: Putting Chaos Into Continuous Delivery to Increase App... Juergen Etzlstorfer & Karthik Satchitanand
Publication date: 2021-05-09
Playlist: KubeCon + CloudNativeCon Europe 2021
Description: 
	Don’t miss out! Join us at our upcoming event: KubeCon + CloudNativeCon North America 2021 in Los Angeles, CA from October 12-15. Learn more at https://kubecon.io The conference features presentations from developers and end users of Kubernetes, Prometheus, Envoy, and all of the other CNCF-hosted projects.

Putting Chaos Into Continuous Delivery to Increase Application Resiliency - Juergen Etzlstorfer, Dynatrace & Karthik Satchitanand, Mayadata

Continuous Delivery practices have evolved significantly with the cloud-native paradigm. GitOps & Chaos Engineering are at the forefront of this new CD approach, with an ever-increasing pattern involving Git-backed pipeline definitions that implement “chaos stages” in pre-prod environments to gauge SLO compliance. In this talk, maintainers of the Keptn (Juergen) & LitmusChaos (Karthik) CNCF sandbox projects will discuss how you can construct pipelines that include chaos experimentation (mapped to declarative hypothesis around application steady-state) while simulating real-world load, and implement quality gates to ensure resilient applications are deployed into production. All this - in a GitOps native manner. They will also demonstrate how you can include chaos tests to your existing CD pipelines without the need of rewriting them.
Captions: 
	00:00:00,080 --> 00:00:03,040
hi everyone and welcome to our

00:00:01,839 --> 00:00:05,120
presentation

00:00:03,040 --> 00:00:06,720
on putting chaos into continuous

00:00:05,120 --> 00:00:09,440
delivery to increase

00:00:06,720 --> 00:00:10,880
application resiliency my name is jorgen

00:00:09,440 --> 00:00:13,040
essendorfer i'm a

00:00:10,880 --> 00:00:14,639
maintainer of the captain project and i

00:00:13,040 --> 00:00:17,359
work for dynatrace

00:00:14,639 --> 00:00:19,119
and together i'm here with kartik hello

00:00:17,359 --> 00:00:22,400
kartik

00:00:19,119 --> 00:00:25,199
hi jurgen hi everyone so this is karthik

00:00:22,400 --> 00:00:27,039
i am the maintenance chaos project and

00:00:25,199 --> 00:00:31,439
workforce native

00:00:27,039 --> 00:00:31,439
absolutely thrilled to speak at cubecon

00:00:31,519 --> 00:00:35,600
so let's dive into the topic because we

00:00:34,399 --> 00:00:38,640
have a really exciting

00:00:35,600 --> 00:00:39,760
topic prepared for today so let's start

00:00:38,640 --> 00:00:43,360
with the typical

00:00:39,760 --> 00:00:45,920
cd process in a multi-stage

00:00:43,360 --> 00:00:46,480
delivery pipeline you have your death

00:00:45,920 --> 00:00:48,800
your

00:00:46,480 --> 00:00:50,879
any kind of pre production environments

00:00:48,800 --> 00:00:53,760
and finally your production environment

00:00:50,879 --> 00:00:55,680
and what you already might use are some

00:00:53,760 --> 00:00:58,480
kind of quality gates

00:00:55,680 --> 00:00:59,600
that evaluate based on performance and

00:00:58,480 --> 00:01:01,680
load testing

00:00:59,600 --> 00:01:03,760
the quality of your applications and

00:01:01,680 --> 00:01:04,720
only if those tests pass you're allowed

00:01:03,760 --> 00:01:07,760
to move and

00:01:04,720 --> 00:01:08,960
move them to the next stage this is

00:01:07,760 --> 00:01:10,880
totally fine

00:01:08,960 --> 00:01:12,560
but in production there is always

00:01:10,880 --> 00:01:15,040
something happening that you can maybe

00:01:12,560 --> 00:01:17,840
not foresee or you cannot really test

00:01:15,040 --> 00:01:20,080
so there is one trend that goes into

00:01:17,840 --> 00:01:22,000
testing in production and basically uh

00:01:20,080 --> 00:01:24,560
trying to break production and then

00:01:22,000 --> 00:01:27,360
getting insights into what has to be

00:01:24,560 --> 00:01:28,880
improved but today we really want to

00:01:27,360 --> 00:01:31,520
advocate for

00:01:28,880 --> 00:01:34,159
taking this idea and moving it to

00:01:31,520 --> 00:01:36,640
pre-production environments

00:01:34,159 --> 00:01:39,200
and not adding to your performance in

00:01:36,640 --> 00:01:41,280
your load test adding also chaos tests

00:01:39,200 --> 00:01:43,200
and evaluating them not only on

00:01:41,280 --> 00:01:44,079
performance criteria but actually on

00:01:43,200 --> 00:01:47,439
obsidian's

00:01:44,079 --> 00:01:49,759
criteria and with moving and shifting

00:01:47,439 --> 00:01:50,479
left the chaos into pre-production

00:01:49,759 --> 00:01:53,680
environments

00:01:50,479 --> 00:01:54,079
to keep production let's say a safe

00:01:53,680 --> 00:01:55,680
place

00:01:54,079 --> 00:01:57,920
and keep the green lights on in your

00:01:55,680 --> 00:01:58,560
production environments that's the main

00:01:57,920 --> 00:02:01,280
idea

00:01:58,560 --> 00:02:02,719
of today's presentation and i'm handing

00:02:01,280 --> 00:02:04,320
over here to kartik

00:02:02,719 --> 00:02:06,399
to explain a little bit how we can

00:02:04,320 --> 00:02:09,840
evaluate resiliency

00:02:06,399 --> 00:02:09,840
uh and uh to take it from there

00:02:10,000 --> 00:02:13,440
thanks you again thanks for setting the

00:02:11,760 --> 00:02:14,879
context

00:02:13,440 --> 00:02:16,800
now that we've already spoken about

00:02:14,879 --> 00:02:20,080
chaos and the need for us to

00:02:16,800 --> 00:02:22,800
test it before deploying in production

00:02:20,080 --> 00:02:23,599
let's look at why keras engineering is

00:02:22,800 --> 00:02:25,680
important

00:02:23,599 --> 00:02:28,640
and what are some practices we can

00:02:25,680 --> 00:02:32,480
follow to improve the resiliency of our

00:02:28,640 --> 00:02:35,120
application infrastructure load tests

00:02:32,480 --> 00:02:36,720
are great functional tests are great but

00:02:35,120 --> 00:02:38,400
they need to be augmented with failure

00:02:36,720 --> 00:02:40,800
scenarios

00:02:38,400 --> 00:02:42,080
especially so in a cloud native world

00:02:40,800 --> 00:02:43,440
where everything is

00:02:42,080 --> 00:02:45,120
in the form of a micro service

00:02:43,440 --> 00:02:47,200
everything is loosely coupled

00:02:45,120 --> 00:02:48,640
there is so much points of failure the

00:02:47,200 --> 00:02:50,959
surface attack

00:02:48,640 --> 00:02:52,239
surface area for attacks or failures

00:02:50,959 --> 00:02:54,239
rather more

00:02:52,239 --> 00:02:56,000
and it is important for us to test

00:02:54,239 --> 00:02:58,080
what's happening when

00:02:56,000 --> 00:03:00,480
the components surrounding our

00:02:58,080 --> 00:03:02,640
applications and business apps fail

00:03:00,480 --> 00:03:04,080
if you look at this pyramid for a

00:03:02,640 --> 00:03:05,519
typical application that you have

00:03:04,080 --> 00:03:07,840
deployed on kubernetes

00:03:05,519 --> 00:03:09,760
you have the platform services that

00:03:07,840 --> 00:03:12,080
could be cloud or on-premise

00:03:09,760 --> 00:03:14,159
you have the kubernetes microservices

00:03:12,080 --> 00:03:16,879
humidity is being very dense

00:03:14,159 --> 00:03:18,720
then you have a host of microservices

00:03:16,879 --> 00:03:21,599
that you have from the cloud native

00:03:18,720 --> 00:03:24,080
ecosystem the cncf landscape for service

00:03:21,599 --> 00:03:24,879
discovery the storage for observability

00:03:24,080 --> 00:03:26,959
etc

00:03:24,879 --> 00:03:28,959
and then you have your application stack

00:03:26,959 --> 00:03:30,640
there can be so many things that fail

00:03:28,959 --> 00:03:32,080
and it's important for us to recognize

00:03:30,640 --> 00:03:33,519
what's happening in

00:03:32,080 --> 00:03:36,159
these components and underground

00:03:33,519 --> 00:03:38,239
failures so failure testing is important

00:03:36,159 --> 00:03:39,680
in other words chaos is really important

00:03:38,239 --> 00:03:41,760
for us to inject and find out what's

00:03:39,680 --> 00:03:44,640
happening

00:03:41,760 --> 00:03:46,000
chaos engineering is a discipline every

00:03:44,640 --> 00:03:48,640
scientific one

00:03:46,000 --> 00:03:49,680
and there are a lot of assumptions that

00:03:48,640 --> 00:03:51,440
we go ahead with

00:03:49,680 --> 00:03:53,120
when we write our applications or when

00:03:51,440 --> 00:03:55,439
we go ahead and deploy them

00:03:53,120 --> 00:03:57,519
we assume that networks are reliable the

00:03:55,439 --> 00:03:58,239
latency is always very less or nearly

00:03:57,519 --> 00:04:00,319
zero

00:03:58,239 --> 00:04:01,360
we have infinite bandwidth abundant

00:04:00,319 --> 00:04:03,280
storage and

00:04:01,360 --> 00:04:05,360
compute resources but it's not always

00:04:03,280 --> 00:04:06,720
the case we really want to simulate

00:04:05,360 --> 00:04:07,760
these conditions and find out what

00:04:06,720 --> 00:04:10,400
happens

00:04:07,760 --> 00:04:12,239
there are some failures that you know

00:04:10,400 --> 00:04:14,319
what's going to result

00:04:12,239 --> 00:04:15,360
we call them as known knowns and it's

00:04:14,319 --> 00:04:17,680
important to

00:04:15,360 --> 00:04:19,680
do some kind of regression around that

00:04:17,680 --> 00:04:21,280
some kind of chaos experimentation

00:04:19,680 --> 00:04:22,160
repeatedly to find out if that still

00:04:21,280 --> 00:04:23,840
holds true

00:04:22,160 --> 00:04:25,680
but there are a lot of unknowns and lot

00:04:23,840 --> 00:04:28,000
of assumptions that you want to

00:04:25,680 --> 00:04:29,520
validate especially so in environment

00:04:28,000 --> 00:04:31,600
that mimics production

00:04:29,520 --> 00:04:33,680
where things are really very dynamic and

00:04:31,600 --> 00:04:35,520
this is a lot of churn

00:04:33,680 --> 00:04:37,120
coming to the word churn why is it

00:04:35,520 --> 00:04:40,080
important for us to do

00:04:37,120 --> 00:04:41,840
chaos testing continuously i have taken

00:04:40,080 --> 00:04:42,960
this snippet from the principles of

00:04:41,840 --> 00:04:44,720
chaos.org

00:04:42,960 --> 00:04:46,560
where it is recommended for us to

00:04:44,720 --> 00:04:49,360
automate these experiments and run them

00:04:46,560 --> 00:04:51,520
continuously because we are going to

00:04:49,360 --> 00:04:53,600
have several versions of our software

00:04:51,520 --> 00:04:55,759
several builds several releases is

00:04:53,600 --> 00:04:57,199
important for us to run continuously

00:04:55,759 --> 00:04:58,800
there are a lot of infrastructure

00:04:57,199 --> 00:05:01,199
changes that can happen

00:04:58,800 --> 00:05:02,880
and underlying operating system or your

00:05:01,199 --> 00:05:04,560
kubernetes versions might keep getting

00:05:02,880 --> 00:05:06,320
upgraded

00:05:04,560 --> 00:05:07,600
and the best way to run things

00:05:06,320 --> 00:05:10,400
continuously

00:05:07,600 --> 00:05:12,320
is to put them inside of a cd pipeline

00:05:10,400 --> 00:05:15,520
exploratory and freely style

00:05:12,320 --> 00:05:16,880
a gameplay-oriented model of execution

00:05:15,520 --> 00:05:18,560
of chaos is really

00:05:16,880 --> 00:05:20,479
important that's not to be done away

00:05:18,560 --> 00:05:22,240
with that's really the nirvana of a

00:05:20,479 --> 00:05:24,479
mature chaos engineering practice

00:05:22,240 --> 00:05:26,479
especially when done on production but

00:05:24,479 --> 00:05:28,880
it's important for us to automate this

00:05:26,479 --> 00:05:30,240
and keep running this continuously on

00:05:28,880 --> 00:05:32,880
pre-prior environments

00:05:30,240 --> 00:05:34,080
to find out whether really our services

00:05:32,880 --> 00:05:36,960
behave the way they do

00:05:34,080 --> 00:05:37,759
and we are confident and whenever we do

00:05:36,960 --> 00:05:39,440
chaos

00:05:37,759 --> 00:05:40,800
engineering whenever we do chaos

00:05:39,440 --> 00:05:42,880
experimentation

00:05:40,800 --> 00:05:45,120
it is important for us to carry some

00:05:42,880 --> 00:05:47,759
hypothesis around what's the failure

00:05:45,120 --> 00:05:48,720
going to result in how are my services

00:05:47,759 --> 00:05:50,080
going to behave

00:05:48,720 --> 00:05:52,479
what's the impact on downstream

00:05:50,080 --> 00:05:54,479
applications how is my performance

00:05:52,479 --> 00:05:56,160
statistics going to change

00:05:54,479 --> 00:05:58,479
is my user experience going to remain

00:05:56,160 --> 00:06:00,319
the same all these are important

00:05:58,479 --> 00:06:01,919
so you need to define what your service

00:06:00,319 --> 00:06:04,319
level indicators are

00:06:01,919 --> 00:06:06,560
you need to define slos on top of that

00:06:04,319 --> 00:06:08,720
and these are going to be very close

00:06:06,560 --> 00:06:10,240
and going to con going to form what will

00:06:08,720 --> 00:06:10,800
be the service level agreements that you

00:06:10,240 --> 00:06:13,120
might have

00:06:10,800 --> 00:06:14,319
with your end users it's important for

00:06:13,120 --> 00:06:16,080
us to accompany or

00:06:14,319 --> 00:06:18,960
marry these checks along with chaos

00:06:16,080 --> 00:06:18,960
experiments every time

00:06:19,440 --> 00:06:23,199
now coming to we spoke about why let's

00:06:22,560 --> 00:06:26,560
talk about

00:06:23,199 --> 00:06:27,759
how in chaos we want to go the

00:06:26,560 --> 00:06:29,440
declarative way now

00:06:27,759 --> 00:06:30,800
because in the cloud native world

00:06:29,440 --> 00:06:32,080
everything is declarative

00:06:30,800 --> 00:06:34,560
right from the way you define your

00:06:32,080 --> 00:06:35,440
infrastructure the way you define your

00:06:34,560 --> 00:06:38,720
applications

00:06:35,440 --> 00:06:40,319
the way you manage their life cycle

00:06:38,720 --> 00:06:42,000
the way you define resources on your

00:06:40,319 --> 00:06:42,880
policies everything is done in a

00:06:42,000 --> 00:06:45,520
declarative way as

00:06:42,880 --> 00:06:46,960
a mls we want to do that with resilience

00:06:45,520 --> 00:06:49,199
checks as well in other words

00:06:46,960 --> 00:06:51,280
with chaos experiments as well so it is

00:06:49,199 --> 00:06:52,560
important that we can define chaos into

00:06:51,280 --> 00:06:55,120
our custom resources

00:06:52,560 --> 00:06:56,960
and use the same paradigm that is that

00:06:55,120 --> 00:06:58,000
of operators and controllers to

00:06:56,960 --> 00:06:59,759
reconcile these

00:06:58,000 --> 00:07:02,240
chaos resources and execute your

00:06:59,759 --> 00:07:03,680
experiments and that way it's going to

00:07:02,240 --> 00:07:05,120
lend itself to a model where you can

00:07:03,680 --> 00:07:06,720
store everything in git

00:07:05,120 --> 00:07:10,880
and also use the traditional etops

00:07:06,720 --> 00:07:13,120
controllers in your chaos flow as well

00:07:10,880 --> 00:07:14,160
let me introduce the litmus chaos

00:07:13,120 --> 00:07:16,080
project

00:07:14,160 --> 00:07:18,080
it has been growing for some time now

00:07:16,080 --> 00:07:19,520
it's a sandbox project right now

00:07:18,080 --> 00:07:21,680
it's getting contribution from other

00:07:19,520 --> 00:07:25,280
organizations and

00:07:21,680 --> 00:07:26,960
the chaos intent here is defined as

00:07:25,280 --> 00:07:28,479
custom resources there are multiple

00:07:26,960 --> 00:07:30,720
custom resources each serving a

00:07:28,479 --> 00:07:32,479
different function and there is a chaos

00:07:30,720 --> 00:07:33,360
operator which acts on these and

00:07:32,479 --> 00:07:36,400
actually

00:07:33,360 --> 00:07:39,360
executes your chaos and this

00:07:36,400 --> 00:07:41,520
tool or this platform rather has been

00:07:39,360 --> 00:07:43,280
built with certain principles in mind

00:07:41,520 --> 00:07:44,879
you can see those principles on this

00:07:43,280 --> 00:07:45,199
screen there are a couple of good blogs

00:07:44,879 --> 00:07:47,759
you can

00:07:45,199 --> 00:07:50,400
read about it and this project has seen

00:07:47,759 --> 00:07:52,319
some fair adoption

00:07:50,400 --> 00:07:54,639
because of the way litmus is built

00:07:52,319 --> 00:07:58,080
everything being declarative

00:07:54,639 --> 00:07:59,840
and everything having a result or a word

00:07:58,080 --> 00:08:01,520
at the end of the experiment you

00:07:59,840 --> 00:08:02,720
actually find out whether you met your

00:08:01,520 --> 00:08:05,120
hypothesis

00:08:02,720 --> 00:08:06,400
or around your study state whether you

00:08:05,120 --> 00:08:08,400
met your solos or no all that

00:08:06,400 --> 00:08:10,960
information is captured in an experiment

00:08:08,400 --> 00:08:12,720
because of this model it fits well into

00:08:10,960 --> 00:08:15,120
ci cd pipelines

00:08:12,720 --> 00:08:16,879
in the subsequent portion of this stock

00:08:15,120 --> 00:08:18,080
urine will talk about what the captain

00:08:16,879 --> 00:08:20,080
project is about

00:08:18,080 --> 00:08:21,199
and how it leverages litmus to introduce

00:08:20,080 --> 00:08:23,520
chaos stages

00:08:21,199 --> 00:08:25,840
as part of continuous delivery pipelines

00:08:23,520 --> 00:08:29,440
over to you

00:08:25,840 --> 00:08:32,080
you cartie so we are using

00:08:29,440 --> 00:08:34,240
two cncf projects um for this

00:08:32,080 --> 00:08:36,000
presentation mainly the one is a little

00:08:34,240 --> 00:08:38,479
chaos and the other one is captain

00:08:36,000 --> 00:08:40,080
which is a cloud native application life

00:08:38,479 --> 00:08:42,479
cycle orchestrator

00:08:40,080 --> 00:08:44,159
that means it's not intended to replace

00:08:42,479 --> 00:08:45,279
all the tools that you already have in

00:08:44,159 --> 00:08:47,519
your tool stack

00:08:45,279 --> 00:08:50,399
but actually to orchestrate them and to

00:08:47,519 --> 00:08:52,880
bring them together

00:08:50,399 --> 00:08:53,760
the the main power of captain is to

00:08:52,880 --> 00:08:58,160
automate

00:08:53,760 --> 00:09:00,240
ways of your parts of your organization

00:08:58,160 --> 00:09:01,440
such as observability dashboarding and

00:09:00,240 --> 00:09:03,519
learning to set up

00:09:01,440 --> 00:09:05,760
for example automated dashboards in

00:09:03,519 --> 00:09:07,279
grafana or

00:09:05,760 --> 00:09:09,839
learning rules you promise alert

00:09:07,279 --> 00:09:12,720
miniature another way

00:09:09,839 --> 00:09:15,040
is to automate slo-driven multi-stage

00:09:12,720 --> 00:09:17,760
delivery which is the main part for

00:09:15,040 --> 00:09:19,680
today's talk uh but also to automate

00:09:17,760 --> 00:09:20,320
operations and remediation for example

00:09:19,680 --> 00:09:22,399
to

00:09:20,320 --> 00:09:24,480
orchestrate remediation actions in

00:09:22,399 --> 00:09:26,240
response to alerts from the prometheus

00:09:24,480 --> 00:09:30,320
alloy manager

00:09:26,240 --> 00:09:33,360
everything is based on declarative

00:09:30,320 --> 00:09:34,320
descriptions uh very well aligned also

00:09:33,360 --> 00:09:37,360
to other projects

00:09:34,320 --> 00:09:38,160
such as littles and stored everything in

00:09:37,360 --> 00:09:39,760
git

00:09:38,160 --> 00:09:41,760
so we're following github's approach

00:09:39,760 --> 00:09:44,880
here as well

00:09:41,760 --> 00:09:46,800
so how can we actually use this and how

00:09:44,880 --> 00:09:49,040
can we set up now

00:09:46,800 --> 00:09:50,080
a project where we want to integrate

00:09:49,040 --> 00:09:53,120
litmus chaos

00:09:50,080 --> 00:09:56,720
into a city workflow

00:09:53,120 --> 00:09:59,120
in captain we are following the

00:09:56,720 --> 00:10:00,959
the idea of the captain shipyard

00:09:59,120 --> 00:10:01,760
definition and the ship that definition

00:10:00,959 --> 00:10:04,320
is really

00:10:01,760 --> 00:10:05,920
that what you want to do and not so much

00:10:04,320 --> 00:10:08,399
how you want to do it

00:10:05,920 --> 00:10:10,880
so it's basically a process in

00:10:08,399 --> 00:10:13,279
environment definition in gamma

00:10:10,880 --> 00:10:16,640
you were putting in repository and kept

00:10:13,279 --> 00:10:18,399
will act upon this definition

00:10:16,640 --> 00:10:19,920
and in another concept which is called

00:10:18,399 --> 00:10:22,320
the captain's uniform

00:10:19,920 --> 00:10:23,760
you will then add the tooling that is

00:10:22,320 --> 00:10:26,480
responsible for each

00:10:23,760 --> 00:10:29,360
task for example it has to be executed

00:10:26,480 --> 00:10:32,480
as part of the shipyard definition

00:10:29,360 --> 00:10:35,279
this separation of concerns by the

00:10:32,480 --> 00:10:37,200
how and the what is basically done with

00:10:35,279 --> 00:10:38,959
cloud events so it's an event-based

00:10:37,200 --> 00:10:40,560
approach and captain will make sure to

00:10:38,959 --> 00:10:41,360
send the cloud events with all the

00:10:40,560 --> 00:10:45,120
information

00:10:41,360 --> 00:10:47,839
that is needed for other tools um to

00:10:45,120 --> 00:10:49,120
to act upon this so for example the

00:10:47,839 --> 00:10:51,680
deployment itself

00:10:49,120 --> 00:10:53,760
is not done by captain itself but

00:10:51,680 --> 00:10:56,000
captain can use helm for example

00:10:53,760 --> 00:10:57,680
to um send all the deployment

00:10:56,000 --> 00:10:59,680
information

00:10:57,680 --> 00:11:01,279
to help and get the help integration

00:10:59,680 --> 00:11:04,399
will act upon this

00:11:01,279 --> 00:11:05,440
and will um trigger them on execute the

00:11:04,399 --> 00:11:08,480
deployment

00:11:05,440 --> 00:11:11,200
the same is true for the testing so

00:11:08,480 --> 00:11:12,160
it's not only that we can support litmus

00:11:11,200 --> 00:11:14,880
tests

00:11:12,160 --> 00:11:16,079
but also chimita tests local tests other

00:11:14,880 --> 00:11:18,560
test integrations

00:11:16,079 --> 00:11:20,079
they will wait for captain to trigger

00:11:18,560 --> 00:11:21,279
them and then once triggered they will

00:11:20,079 --> 00:11:23,519
execute the tests

00:11:21,279 --> 00:11:25,760
the test instructions are stored in the

00:11:23,519 --> 00:11:27,360
git repository managed by captain

00:11:25,760 --> 00:11:29,040
will be provided to the test

00:11:27,360 --> 00:11:31,680
integrations and then they can

00:11:29,040 --> 00:11:32,560
execute the tests in the case of litmus

00:11:31,680 --> 00:11:35,600
chaos

00:11:32,560 --> 00:11:35,920
the um the chaos experiment the chaos

00:11:35,600 --> 00:11:38,079
test

00:11:35,920 --> 00:11:40,240
itself is a gamble file it will be

00:11:38,079 --> 00:11:43,360
provided by captain to litmus

00:11:40,240 --> 00:11:44,880
and litmus will then act upon this will

00:11:43,360 --> 00:11:46,640
execute its chaos

00:11:44,880 --> 00:11:48,640
test and will then come back with a

00:11:46,640 --> 00:11:50,399
result to captain so captain can for

00:11:48,640 --> 00:11:52,639
example in the evaluation phase

00:11:50,399 --> 00:11:54,079
then trigger develop the tool that is

00:11:52,639 --> 00:11:56,320
responsible for the evaluation

00:11:54,079 --> 00:11:58,240
we're using here it builds in

00:11:56,320 --> 00:12:00,240
functionality of captain the captain

00:11:58,240 --> 00:12:01,519
lighthouse service doing now the

00:12:00,240 --> 00:12:03,760
evaluation

00:12:01,519 --> 00:12:04,560
so how does an evaluation look like

00:12:03,760 --> 00:12:07,600
again

00:12:04,560 --> 00:12:10,079
here it's a declarative description it's

00:12:07,600 --> 00:12:11,760
based on service level objectives and

00:12:10,079 --> 00:12:13,360
let me start here with the

00:12:11,760 --> 00:12:15,360
um with the second picture here on the

00:12:13,360 --> 00:12:16,240
left hand side where we already have an

00:12:15,360 --> 00:12:19,519
objective

00:12:16,240 --> 00:12:20,480
defined based on an sli let's say the

00:12:19,519 --> 00:12:23,360
probe success

00:12:20,480 --> 00:12:25,360
percentage that means what is the

00:12:23,360 --> 00:12:27,440
success percentage of all the probes we

00:12:25,360 --> 00:12:29,040
are sending within the given time frame

00:12:27,440 --> 00:12:30,560
or that we are doing within that given

00:12:29,040 --> 00:12:33,839
time frame

00:12:30,560 --> 00:12:35,360
and uh we needed uh higher than 95

00:12:33,839 --> 00:12:38,560
percent of success

00:12:35,360 --> 00:12:40,959
if we want this objective to fully pass

00:12:38,560 --> 00:12:42,000
if we cannot meet this criteria capital

00:12:40,959 --> 00:12:44,480
will evaluate

00:12:42,000 --> 00:12:46,399
the boarding criteria it has to still be

00:12:44,480 --> 00:12:49,440
it has to be higher than 90

00:12:46,399 --> 00:12:51,360
for it to receive half the score if we

00:12:49,440 --> 00:12:52,000
cannot meet both the pass and the

00:12:51,360 --> 00:12:54,399
warning

00:12:52,000 --> 00:12:55,200
captain will not give it a score and

00:12:54,399 --> 00:12:58,079
this one

00:12:55,200 --> 00:12:59,040
of objective would fail how the data is

00:12:58,079 --> 00:13:00,800
actually retrieved

00:12:59,040 --> 00:13:02,880
is then defined in the service level

00:13:00,800 --> 00:13:04,320
indicator file this is basically a

00:13:02,880 --> 00:13:06,720
mapping between the

00:13:04,320 --> 00:13:07,440
name of the circuit indicator and you

00:13:06,720 --> 00:13:10,079
can think of as

00:13:07,440 --> 00:13:11,680
a promql with placeholders so that you

00:13:10,079 --> 00:13:14,160
can easily reuse this for different

00:13:11,680 --> 00:13:16,320
services for different time frames

00:13:14,160 --> 00:13:19,279
these kind of things so with these two

00:13:16,320 --> 00:13:23,519
files we can go ahead and do evaluation

00:13:19,279 --> 00:13:26,560
either within the execution of a captain

00:13:23,519 --> 00:13:29,200
um shipyard definition um or also

00:13:26,560 --> 00:13:30,720
triggered via the api or by the cli if

00:13:29,200 --> 00:13:31,360
you're just interested in the captain

00:13:30,720 --> 00:13:35,600
quality

00:13:31,360 --> 00:13:38,240
evaluation um ad let's say

00:13:35,600 --> 00:13:38,959
either way once the evaluation is

00:13:38,240 --> 00:13:40,639
triggered

00:13:38,959 --> 00:13:43,199
captain will reach out to the different

00:13:40,639 --> 00:13:46,079
data providers such as prometheus and we

00:13:43,199 --> 00:13:48,240
query the data that is used in the

00:13:46,079 --> 00:13:49,199
service level objective file it will

00:13:48,240 --> 00:13:51,760
then score

00:13:49,199 --> 00:13:52,240
the data and will come back with a total

00:13:51,760 --> 00:13:55,519
score

00:13:52,240 --> 00:13:57,279
and based on the total score this

00:13:55,519 --> 00:13:58,800
microservice can then be for example

00:13:57,279 --> 00:14:02,000
promoted to the next stage

00:13:58,800 --> 00:14:04,480
even to production if it's meeting the

00:14:02,000 --> 00:14:05,040
criteria or the resilience criteria for

00:14:04,480 --> 00:14:06,720
example

00:14:05,040 --> 00:14:09,199
or it can be automatically rolled back

00:14:06,720 --> 00:14:11,839
or just held back on stage

00:14:09,199 --> 00:14:12,639
depending on what on what is defined in

00:14:11,839 --> 00:14:14,880
the shipyard

00:14:12,639 --> 00:14:16,720
definition so this is the idea how

00:14:14,880 --> 00:14:18,560
captain quality gates work and how you

00:14:16,720 --> 00:14:20,800
can evaluate the resilience

00:14:18,560 --> 00:14:22,480
it's basically how you define your

00:14:20,800 --> 00:14:23,920
service level objectives and which

00:14:22,480 --> 00:14:25,839
service level indicators

00:14:23,920 --> 00:14:27,839
you're using we also have a demo

00:14:25,839 --> 00:14:30,800
prepared for this

00:14:27,839 --> 00:14:32,639
what we will see in the demo is um which

00:14:30,800 --> 00:14:34,160
application we are using how all these

00:14:32,639 --> 00:14:36,720
different

00:14:34,160 --> 00:14:38,480
tools basically come together but for

00:14:36,720 --> 00:14:40,639
the explanation of what we've done here

00:14:38,480 --> 00:14:43,680
and how we validated our approach

00:14:40,639 --> 00:14:44,720
i will hand over the content thanks you

00:14:43,680 --> 00:14:46,720
again

00:14:44,720 --> 00:14:48,800
now that we appreciate the need for

00:14:46,720 --> 00:14:50,399
chaos as part of continuous delivery and

00:14:48,800 --> 00:14:53,839
now that you've learned about

00:14:50,399 --> 00:14:55,440
it and captain projects let's talk about

00:14:53,839 --> 00:14:58,079
a simple use case

00:14:55,440 --> 00:14:59,040
this is a way to illustrate how you can

00:14:58,079 --> 00:15:02,240
do chaos in

00:14:59,040 --> 00:15:04,000
cd using these projects

00:15:02,240 --> 00:15:05,760
the diagram that we have here on this

00:15:04,000 --> 00:15:08,399
slide is essentially

00:15:05,760 --> 00:15:09,839
a representation of the shipyard that

00:15:08,399 --> 00:15:10,880
european talked about a few minutes

00:15:09,839 --> 00:15:13,839
earlier

00:15:10,880 --> 00:15:15,360
so we have got three stages importantly

00:15:13,839 --> 00:15:17,440
one is the deployment stage

00:15:15,360 --> 00:15:19,120
one is the disk stage and then it is the

00:15:17,440 --> 00:15:22,160
quality evaluation

00:15:19,120 --> 00:15:22,720
as part of the deploy stage we deploy a

00:15:22,160 --> 00:15:25,600
simple

00:15:22,720 --> 00:15:26,639
hello world application called the

00:15:25,600 --> 00:15:29,600
potato head

00:15:26,639 --> 00:15:31,120
app so this is a popular hero service

00:15:29,600 --> 00:15:34,560
maintained by the cncf

00:15:31,120 --> 00:15:35,600
sig app delivery crew it is deployed

00:15:34,560 --> 00:15:37,680
using help

00:15:35,600 --> 00:15:39,759
that's the deployment tool of choice and

00:15:37,680 --> 00:15:41,839
once the deployment is completed

00:15:39,759 --> 00:15:43,519
there is a deployment finished event

00:15:41,839 --> 00:15:47,120
which actually triggers the next

00:15:43,519 --> 00:15:50,560
set of tasks one a load generator

00:15:47,120 --> 00:15:50,880
that's a locust starting to put load on

00:15:50,560 --> 00:15:53,519
the

00:15:50,880 --> 00:15:54,000
hello service app so we want to do chaos

00:15:53,519 --> 00:15:55,440
when

00:15:54,000 --> 00:15:57,680
the application is actually serving

00:15:55,440 --> 00:16:00,399
requests not in idle conditions

00:15:57,680 --> 00:16:01,279
that's why we have locust then we use

00:16:00,399 --> 00:16:03,519
litmus

00:16:01,279 --> 00:16:04,800
the chaos experiment and engine crs are

00:16:03,519 --> 00:16:08,399
used to define

00:16:04,800 --> 00:16:10,639
a part delete chaos experiment on the

00:16:08,399 --> 00:16:12,480
hero service app as part of this we're

00:16:10,639 --> 00:16:15,199
going to delete one of the replicas

00:16:12,480 --> 00:16:17,279
of this application and we are going to

00:16:15,199 --> 00:16:18,480
identify what's going to happen as part

00:16:17,279 --> 00:16:21,040
of that

00:16:18,480 --> 00:16:23,759
before and after the experiment there's

00:16:21,040 --> 00:16:25,440
a certain

00:16:23,759 --> 00:16:28,079
where we actually complete the

00:16:25,440 --> 00:16:30,560
experiment and give out a verdict

00:16:28,079 --> 00:16:32,880
and then we have a test finished event

00:16:30,560 --> 00:16:35,920
that gets generated once this is done

00:16:32,880 --> 00:16:36,320
this triggers a quality gate evaluation

00:16:35,920 --> 00:16:38,399
and

00:16:36,320 --> 00:16:40,240
as part of this evaluation we are going

00:16:38,399 --> 00:16:41,839
to use metrics provided to us from

00:16:40,240 --> 00:16:44,079
prometheus we are going to have

00:16:41,839 --> 00:16:45,600
defined some service level indicators

00:16:44,079 --> 00:16:46,240
which are essentially prometheus

00:16:45,600 --> 00:16:49,519
functions

00:16:46,240 --> 00:16:51,600
on top of some metrics that is exposed

00:16:49,519 --> 00:16:53,440
by the applications and the litmus and

00:16:51,600 --> 00:16:56,160
the tools that we have

00:16:53,440 --> 00:16:58,560
and there are some slos defined as

00:16:56,160 --> 00:17:02,000
cutoffs on top of the values

00:16:58,560 --> 00:17:03,920
provided by this sli and we are going to

00:17:02,000 --> 00:17:05,919
evaluate whether those cutoffs are met

00:17:03,920 --> 00:17:08,240
as part of the quality gate evaluation

00:17:05,919 --> 00:17:10,079
and once it is met we are going to

00:17:08,240 --> 00:17:10,880
promote this application to the next

00:17:10,079 --> 00:17:13,039
stage

00:17:10,880 --> 00:17:15,120
probably production or we may go ahead

00:17:13,039 --> 00:17:18,720
and do a next chaos test

00:17:15,120 --> 00:17:19,919
or another another important test if not

00:17:18,720 --> 00:17:22,000
then there's something that we need to

00:17:19,919 --> 00:17:24,400
improve either in the application

00:17:22,000 --> 00:17:25,760
or probably in our deployment practice

00:17:24,400 --> 00:17:27,439
so in this particular

00:17:25,760 --> 00:17:29,280
demonstration we are actually going to

00:17:27,439 --> 00:17:30,400
highlight an inefficient deployment

00:17:29,280 --> 00:17:32,480
approach

00:17:30,400 --> 00:17:33,919
and uruguay is going to inform and take

00:17:32,480 --> 00:17:36,240
you through that demo

00:17:33,919 --> 00:17:38,000
before we actually get into it let us

00:17:36,240 --> 00:17:39,440
spend a couple of minutes

00:17:38,000 --> 00:17:42,320
to detail the flow that's going to

00:17:39,440 --> 00:17:45,200
happen as part of this use case

00:17:42,320 --> 00:17:47,120
first we are going to have the potato

00:17:45,200 --> 00:17:48,799
head hello service app deployed it's

00:17:47,120 --> 00:17:49,919
going to be deployed with the readiness

00:17:48,799 --> 00:17:52,240
pro

00:17:49,919 --> 00:17:53,440
that has a neat delay sequence of around

00:17:52,240 --> 00:17:55,679
30 seconds

00:17:53,440 --> 00:17:57,360
it's actually going to take some time

00:17:55,679 --> 00:17:58,160
for this particular application to be

00:17:57,360 --> 00:18:00,240
ready

00:17:58,160 --> 00:18:01,600
and come up with an end point which can

00:18:00,240 --> 00:18:04,080
be queried

00:18:01,600 --> 00:18:06,160
and then we have a black box exporter

00:18:04,080 --> 00:18:08,799
which is consistently trying to

00:18:06,160 --> 00:18:11,039
access this application and give us some

00:18:08,799 --> 00:18:12,799
accessibility information

00:18:11,039 --> 00:18:14,960
and it's going to give us these two

00:18:12,799 --> 00:18:16,720
metrics that is probe success and probe

00:18:14,960 --> 00:18:19,679
duration seconds

00:18:16,720 --> 00:18:21,440
probe success is an accessibility factor

00:18:19,679 --> 00:18:22,880
and duration seconds is an indicator of

00:18:21,440 --> 00:18:25,200
how long it takes for us

00:18:22,880 --> 00:18:26,960
to access the application successfully

00:18:25,200 --> 00:18:28,240
then we have the request operator and

00:18:26,960 --> 00:18:29,840
the dependencies

00:18:28,240 --> 00:18:31,760
along with the litmus service

00:18:29,840 --> 00:18:33,200
integration service in deciding in the

00:18:31,760 --> 00:18:34,720
kitchen control plane

00:18:33,200 --> 00:18:36,320
which is actually going to help trigger

00:18:34,720 --> 00:18:38,240
this chaos experiment

00:18:36,320 --> 00:18:39,600
the experiment itself is going to be a

00:18:38,240 --> 00:18:41,919
simple graceful

00:18:39,600 --> 00:18:43,520
deletion of a single replica of the

00:18:41,919 --> 00:18:44,960
hello service app

00:18:43,520 --> 00:18:47,120
we're just going to do one instance of

00:18:44,960 --> 00:18:48,720
this part delete and initially we are

00:18:47,120 --> 00:18:51,600
going to do this against

00:18:48,720 --> 00:18:53,679
a single replica deployment and see that

00:18:51,600 --> 00:18:56,320
the slos are not really met

00:18:53,679 --> 00:18:56,720
and these slos are essentially being

00:18:56,320 --> 00:19:00,160
built

00:18:56,720 --> 00:19:01,440
on top of these slides that are averages

00:19:00,160 --> 00:19:03,760
against the probe success and

00:19:01,440 --> 00:19:04,320
probability we are going to see that

00:19:03,760 --> 00:19:06,400
this is

00:19:04,320 --> 00:19:08,559
going to be met when we have a multi

00:19:06,400 --> 00:19:10,080
replica deployment

00:19:08,559 --> 00:19:11,840
that is what we're going to show as part

00:19:10,080 --> 00:19:14,000
of this demo

00:19:11,840 --> 00:19:15,679
and uh with this info i think i'll

00:19:14,000 --> 00:19:18,000
probably hand it over to your game

00:19:15,679 --> 00:19:21,600
to talk us through the actual steps and

00:19:18,000 --> 00:19:25,200
the commands involved in doing this

00:19:21,600 --> 00:19:26,000
thank you carter um so for the sake of

00:19:25,200 --> 00:19:28,160
efficiency

00:19:26,000 --> 00:19:30,080
we took all the screenshots of the demo

00:19:28,160 --> 00:19:32,160
and put it on the slides

00:19:30,080 --> 00:19:34,000
to skip all the waiting times uh

00:19:32,160 --> 00:19:36,480
whenever the tests execute

00:19:34,000 --> 00:19:38,480
so the demo starts with triggering a new

00:19:36,480 --> 00:19:40,160
delivery based on the shipyard file that

00:19:38,480 --> 00:19:43,919
we've seen earlier

00:19:40,160 --> 00:19:45,520
and we are just going to deploy

00:19:43,919 --> 00:19:47,679
one image it's the hello server

00:19:45,520 --> 00:19:48,640
application which is part of the potato

00:19:47,679 --> 00:19:51,679
head

00:19:48,640 --> 00:19:52,480
application once the deployment is

00:19:51,679 --> 00:19:54,799
finished

00:19:52,480 --> 00:19:56,720
we are doing this with hell uh and with

00:19:54,799 --> 00:19:57,760
a replica set of one in the first round

00:19:56,720 --> 00:20:00,000
of the demo

00:19:57,760 --> 00:20:01,280
captain will make sure to trigger the

00:20:00,000 --> 00:20:03,520
tests the test

00:20:01,280 --> 00:20:04,559
definitions and the chaos definitions

00:20:03,520 --> 00:20:06,480
these are all part

00:20:04,559 --> 00:20:07,840
all stored in the git repository of

00:20:06,480 --> 00:20:10,480
captain and

00:20:07,840 --> 00:20:12,400
um basically provided to the tool

00:20:10,480 --> 00:20:14,320
integrations here so both the linkedin

00:20:12,400 --> 00:20:15,039
service and the local service will start

00:20:14,320 --> 00:20:17,440
the work

00:20:15,039 --> 00:20:19,760
they don't even have to know that the

00:20:17,440 --> 00:20:21,919
other services running as well

00:20:19,760 --> 00:20:24,320
so you can just reuse all the

00:20:21,919 --> 00:20:28,320
performance tests you already have and

00:20:24,320 --> 00:20:30,000
add the chaos on top of this once

00:20:28,320 --> 00:20:32,080
the services are finished and capturing

00:20:30,000 --> 00:20:34,000
waits for both services to finish

00:20:32,080 --> 00:20:36,320
the evaluation started so we can see

00:20:34,000 --> 00:20:38,880
here the litmus service was finished

00:20:36,320 --> 00:20:40,240
um successfully also the local service

00:20:38,880 --> 00:20:42,640
was finished successfully

00:20:40,240 --> 00:20:43,440
that means they both did their job and

00:20:42,640 --> 00:20:46,559
indicated

00:20:43,440 --> 00:20:47,360
that during their execution there was no

00:20:46,559 --> 00:20:49,520
problem

00:20:47,360 --> 00:20:50,400
so in the evaluation captain is now

00:20:49,520 --> 00:20:53,520
reaching out to

00:20:50,400 --> 00:20:54,000
me voice and collecting the data we can

00:20:53,520 --> 00:20:57,120
see

00:20:54,000 --> 00:21:00,159
the evaluation is failing in this case

00:20:57,120 --> 00:21:03,200
and taking a look at a detailed um

00:21:00,159 --> 00:21:05,600
evaluation overview we can see why the

00:21:03,200 --> 00:21:07,919
evaluation finished and both of our

00:21:05,600 --> 00:21:08,960
service level objectives actually did

00:21:07,919 --> 00:21:12,000
not meet the

00:21:08,960 --> 00:21:12,640
criteria first the success percentage

00:21:12,000 --> 00:21:14,880
was not

00:21:12,640 --> 00:21:16,159
high enough we expected it to be higher

00:21:14,880 --> 00:21:18,640
than 95

00:21:16,159 --> 00:21:19,679
for a full pass or at least higher than

00:21:18,640 --> 00:21:21,919
00:21:19,679 --> 00:21:23,440
for a warning but we could not meet this

00:21:21,919 --> 00:21:26,960
because our application was not

00:21:23,440 --> 00:21:29,360
available for a given time um

00:21:26,960 --> 00:21:30,640
due to our readiness pro for example it

00:21:29,360 --> 00:21:33,840
took it takes at least

00:21:30,640 --> 00:21:37,039
30 seconds for it to be ready uh after

00:21:33,840 --> 00:21:38,640
it is deleted by a port delete

00:21:37,039 --> 00:21:39,039
experiment the one that we are using

00:21:38,640 --> 00:21:42,080
here

00:21:39,039 --> 00:21:43,679
in the stem so what we can do

00:21:42,080 --> 00:21:45,520
to improve the resilience of our

00:21:43,679 --> 00:21:48,240
application in this case

00:21:45,520 --> 00:21:49,919
is to come up with the idea of a more

00:21:48,240 --> 00:21:51,679
high availability setup

00:21:49,919 --> 00:21:53,039
increasing the replica account of this

00:21:51,679 --> 00:21:55,919
application that would be

00:21:53,039 --> 00:21:57,840
one first good approach to do this and

00:21:55,919 --> 00:21:59,440
we just rewrite the cloud event that we

00:21:57,840 --> 00:22:01,280
are sending to captain and it will be

00:21:59,440 --> 00:22:02,720
then used as the instruction for the

00:22:01,280 --> 00:22:05,440
deployment in hell

00:22:02,720 --> 00:22:07,600
so we are just re writing this file and

00:22:05,440 --> 00:22:09,520
adding the replica count of three

00:22:07,600 --> 00:22:11,360
to this sending it to the captain

00:22:09,520 --> 00:22:13,760
control plane which will then

00:22:11,360 --> 00:22:15,520
forward it to hell helm will do the

00:22:13,760 --> 00:22:17,520
deployment once it's finished

00:22:15,520 --> 00:22:19,919
again the tests will be automatically

00:22:17,520 --> 00:22:22,640
triggered it will be the same tests

00:22:19,919 --> 00:22:24,080
it will be the same integrations once

00:22:22,640 --> 00:22:25,919
the tests are finished

00:22:24,080 --> 00:22:28,240
again they will indicate back to captain

00:22:25,919 --> 00:22:31,039
it's finished captain please go ahead

00:22:28,240 --> 00:22:31,919
and do the evaluation and this time the

00:22:31,039 --> 00:22:34,559
evaluation

00:22:31,919 --> 00:22:36,000
is successful we can even take a look

00:22:34,559 --> 00:22:38,320
why it is successful

00:22:36,000 --> 00:22:41,440
and we can see the probe success

00:22:38,320 --> 00:22:43,520
percentage is now a hundred percent

00:22:41,440 --> 00:22:46,240
and also the probe duration was fast

00:22:43,520 --> 00:22:48,320
enough so a hundred percent

00:22:46,240 --> 00:22:50,240
why we could achieve it to a hundred

00:22:48,320 --> 00:22:52,240
percent because that's basically how

00:22:50,240 --> 00:22:54,640
kubernetes works if there are more

00:22:52,240 --> 00:22:56,559
uh then if there's one more if there is

00:22:54,640 --> 00:22:58,799
more than one replica

00:22:56,559 --> 00:23:00,640
kubernetes will always make sure to send

00:22:58,799 --> 00:23:02,240
the traffic only to the

00:23:00,640 --> 00:23:04,559
instances of this application that

00:23:02,240 --> 00:23:06,000
actually are ready and uh if we are

00:23:04,559 --> 00:23:07,679
going to delete one of those

00:23:06,000 --> 00:23:09,120
instances and they have not indicated

00:23:07,679 --> 00:23:11,360
that they are already

00:23:09,120 --> 00:23:13,760
ready to serve some traffic the traffic

00:23:11,360 --> 00:23:15,760
won't be directed to them

00:23:13,760 --> 00:23:17,120
so the traffic was only served by those

00:23:15,760 --> 00:23:19,679
two other instances

00:23:17,120 --> 00:23:20,240
that were not affected by the populate

00:23:19,679 --> 00:23:22,720
test

00:23:20,240 --> 00:23:24,000
that we triggered with littles so with

00:23:22,720 --> 00:23:27,039
this we can

00:23:24,000 --> 00:23:28,720
evaluate already how to increase the

00:23:27,039 --> 00:23:30,400
resilience of applications we have not

00:23:28,720 --> 00:23:32,400
changed anything in our application

00:23:30,400 --> 00:23:33,600
code but we actually increase the

00:23:32,400 --> 00:23:35,919
resilience by

00:23:33,600 --> 00:23:37,760
tweaking the deployment instructions and

00:23:35,919 --> 00:23:39,440
having a higher replica set

00:23:37,760 --> 00:23:41,279
this of course might be different for

00:23:39,440 --> 00:23:43,919
your applications but this is just

00:23:41,279 --> 00:23:45,360
a validation of the approach that and

00:23:43,919 --> 00:23:46,960
where we also have a continuous

00:23:45,360 --> 00:23:50,000
evaluation

00:23:46,960 --> 00:23:52,799
of chaos and the

00:23:50,000 --> 00:23:55,360
impact of our chaos tests on our

00:23:52,799 --> 00:23:55,360
application

00:23:56,240 --> 00:24:02,960
so with this we want to leave you with

00:23:59,919 --> 00:24:04,000
three key takeaways the first one is we

00:24:02,960 --> 00:24:06,240
really want to encourage

00:24:04,000 --> 00:24:09,120
you to establish a process of

00:24:06,240 --> 00:24:12,480
continuously evaluating the resiliency

00:24:09,120 --> 00:24:15,760
not only to do it uh once or twice

00:24:12,480 --> 00:24:18,000
by a so-called game day but really

00:24:15,760 --> 00:24:19,600
putting this idea of a continuous

00:24:18,000 --> 00:24:22,559
resiliency evaluation

00:24:19,600 --> 00:24:23,200
into your cd pipelines and having chaos

00:24:22,559 --> 00:24:26,159
tests

00:24:23,200 --> 00:24:27,679
in addition to performance tests um i

00:24:26,159 --> 00:24:29,360
think with this you can really

00:24:27,679 --> 00:24:30,720
increase the resilience of the

00:24:29,360 --> 00:24:33,760
applications and

00:24:30,720 --> 00:24:34,480
having this in a continuous way it

00:24:33,760 --> 00:24:37,520
really gives

00:24:34,480 --> 00:24:39,440
the highest value the evaluation

00:24:37,520 --> 00:24:41,520
should be based on service level

00:24:39,440 --> 00:24:45,120
objectives they have proven to be a very

00:24:41,520 --> 00:24:46,960
efficient way to evaluate

00:24:45,120 --> 00:24:49,279
performance criteria but also resilience

00:24:46,960 --> 00:24:51,440
criteria you can even have

00:24:49,279 --> 00:24:53,039
memory consumption or other parts as

00:24:51,440 --> 00:24:54,080
part of your slos and having a

00:24:53,039 --> 00:24:57,600
combination

00:24:54,080 --> 00:25:01,039
between more than one or

00:24:57,600 --> 00:25:01,840
between a huge amount of service level

00:25:01,039 --> 00:25:03,919
objectives

00:25:01,840 --> 00:25:06,320
gives you a very strong quality

00:25:03,919 --> 00:25:09,600
indication of your applications

00:25:06,320 --> 00:25:12,080
and we've already seen what we are

00:25:09,600 --> 00:25:14,640
talking about today adopted by a company

00:25:12,080 --> 00:25:17,440
called ketoki they are using

00:25:14,640 --> 00:25:18,159
exactly the stack that we also used for

00:25:17,440 --> 00:25:20,000
the demo

00:25:18,159 --> 00:25:21,520
they're using locus for the performance

00:25:20,000 --> 00:25:23,840
tests they're using captain

00:25:21,520 --> 00:25:24,640
for orchestrating them for doing the

00:25:23,840 --> 00:25:27,840
evaluation

00:25:24,640 --> 00:25:29,120
and they have added litmus chaos as part

00:25:27,840 --> 00:25:31,360
of their

00:25:29,120 --> 00:25:32,480
quality evaluations and they have

00:25:31,360 --> 00:25:34,720
already run

00:25:32,480 --> 00:25:35,520
those experiments in those tests

00:25:34,720 --> 00:25:37,679
hundreds of

00:25:35,520 --> 00:25:39,120
times and it has already proven to

00:25:37,679 --> 00:25:40,720
increase the resilience of their

00:25:39,120 --> 00:25:44,000
applications

00:25:40,720 --> 00:25:45,840
if you're interested in more we have one

00:25:44,000 --> 00:25:48,240
resource slide here so please

00:25:45,840 --> 00:25:50,080
visit us on litmus chaos dot io that's

00:25:48,240 --> 00:25:50,640
the project website of the litmus case

00:25:50,080 --> 00:25:53,120
project

00:25:50,640 --> 00:25:54,640
on captain.sh you will find everything

00:25:53,120 --> 00:25:57,840
on the captain project and

00:25:54,640 --> 00:25:59,679
how to use it if you want to use the

00:25:57,840 --> 00:26:00,320
litmus integration you will find it on

00:25:59,679 --> 00:26:02,640
github

00:26:00,320 --> 00:26:03,840
there is even a tutorial how to use it

00:26:02,640 --> 00:26:05,600
um the

00:26:03,840 --> 00:26:07,760
litmus chaos team and the captain team

00:26:05,600 --> 00:26:10,559
have even teamed up to

00:26:07,760 --> 00:26:12,000
write the blog two two-part blog series

00:26:10,559 --> 00:26:13,679
on this whole topic

00:26:12,000 --> 00:26:16,400
so there's a lot of resources around

00:26:13,679 --> 00:26:17,039
this um we really encourage you to make

00:26:16,400 --> 00:26:18,960
use of them

00:26:17,039 --> 00:26:20,480
and you can also reach out to us our

00:26:18,960 --> 00:26:23,039
respective twitter handles

00:26:20,480 --> 00:26:25,600
are here and we are really happy also to

00:26:23,039 --> 00:26:28,640
follow up with you on these topics

00:26:25,600 --> 00:26:32,240
with this i think we already can open up

00:26:28,640 --> 00:26:34,799
um the question section thanks so much

00:26:32,240 --> 00:26:36,559
so much uh kartik it was really uh a

00:26:34,799 --> 00:26:38,640
pleasure working with you on this

00:26:36,559 --> 00:26:40,240
and thanks to the whole open source and

00:26:38,640 --> 00:26:43,679
cncf community

00:26:40,240 --> 00:26:45,360
for taking part in this talk thanks

00:26:43,679 --> 00:26:46,799
again enjoyed working on this i hope

00:26:45,360 --> 00:26:50,880
this is useful to the

00:26:46,799 --> 00:26:53,840
cloud native community thank you

00:26:50,880 --> 00:26:53,840

YouTube URL: https://www.youtube.com/watch?v=_DgCc4-BLW8


