Title: Sleeping on the job by Julik Tarkhanov & Kir Shatrov | #NoRuKo 2020
Publication date: 2020-09-11
Playlist: #NoRuKo 2020
Description: 
	We all love our Sidekiq’s and our Resque’s. But they do let us down sometimes. Not because they are bad, but because the queueing theory is limiting us. There is a way to break out of the madness though - let’s explore how to get our job queues under control. 

Kir Shatrov is a platform engineer at Shopify where he works on scalability and reliability of one of the world’s largest ecommerce platforms. When not into working, Kir enjoys cooking, gastronomic tourism (he even has a GitHub repo with his favourite spots!) and exploring London on the bike.
Julik Tarkhanov is a software developer at WeTransfer where he is responsible for the backend components of the Transfer product, enabling effortless transfer of creative ideas. Prior to WeTransfer he worked in the visual effects industry creating images that inspire and befuddle. On his free time he explores weird user interfaces and plays trumpet.

Welcome to the #NoRuKo conference. A virtual unconference organized by Stichting Ruby NL.

#NoRuKo playlist with all talks and panels: https://www.youtube.com/playlist?list=PL9_A7olkztLlmJIAc567KQgKcMi7-qnjg

Recorded 21th of August, 2020.
NoRuKo website: https://noruko.org/
Stichting Ruby NL website: https://rubynl.org/
Captions: 
	00:00:00,240 --> 00:00:04,880
nice so welcome back um

00:00:03,040 --> 00:00:08,639
well we're already at our final talk of

00:00:04,880 --> 00:00:10,639
the day here main track land

00:00:08,639 --> 00:00:12,880
so our next two speakers they're not a

00:00:10,639 --> 00:00:15,759
stranger to the community

00:00:12,880 --> 00:00:18,000
and um ramon can you tell them can you

00:00:15,759 --> 00:00:21,680
tell our audience a bit about them

00:00:18,000 --> 00:00:25,439
absolutely um so here we go folks

00:00:21,680 --> 00:00:28,080
um our next speaker comes in two

00:00:25,439 --> 00:00:30,240
so we've got kier who is a platform

00:00:28,080 --> 00:00:30,800
engineer at shopify quite the culinary

00:00:30,240 --> 00:00:32,640
expert

00:00:30,800 --> 00:00:34,640
he enjoys cooking and touring his

00:00:32,640 --> 00:00:37,680
favorite places to eat and uh

00:00:34,640 --> 00:00:39,920
i hear writing up about them and uh

00:00:37,680 --> 00:00:41,040
unic is a software developer at we

00:00:39,920 --> 00:00:43,760
transform

00:00:41,040 --> 00:00:45,200
villa we transfer he gave a lightning

00:00:43,760 --> 00:00:48,239
talk at urico last year

00:00:45,200 --> 00:00:49,920
and he plays the trumpet a musician

00:00:48,239 --> 00:00:51,520
let's hope that he makes an appearance

00:00:49,920 --> 00:00:55,760
at karaoke today

00:00:51,520 --> 00:00:55,760
but uh i'll let him toot his own horn

00:00:56,399 --> 00:01:00,079
well folks uh let's hear a little bit

00:00:58,399 --> 00:01:03,359
about sleeping on the job

00:01:00,079 --> 00:01:06,799
hello everyone uh welcome to this talk

00:01:03,359 --> 00:01:09,040
uh about background jobs uh

00:01:06,799 --> 00:01:10,400
my name is yudik and today with me we

00:01:09,040 --> 00:01:12,400
have a wonderful mr

00:01:10,400 --> 00:01:15,439
kier and we thought that it's really

00:01:12,400 --> 00:01:18,479
worth it to talk about background jobs

00:01:15,439 --> 00:01:20,240
because these background jobs are also a

00:01:18,479 --> 00:01:21,119
best way to crash your application so

00:01:20,240 --> 00:01:23,119
they're not

00:01:21,119 --> 00:01:25,360
only very useful but they can also be

00:01:23,119 --> 00:01:27,200
dangerous why they can be dangerous

00:01:25,360 --> 00:01:29,200
is because they run with the delay which

00:01:27,200 --> 00:01:31,280
means that they do not start executing

00:01:29,200 --> 00:01:33,680
immediately when you spool them up

00:01:31,280 --> 00:01:35,439
uh they run for a certain amount of time

00:01:33,680 --> 00:01:37,280
which is not always predictable so for

00:01:35,439 --> 00:01:38,840
example it is possible that you spool of

00:01:37,280 --> 00:01:42,079
a certain job and you

00:01:38,840 --> 00:01:44,240
um and you expect it to complete within

00:01:42,079 --> 00:01:44,880
say 300 milliseconds or half a second or

00:01:44,240 --> 00:01:46,960
a second

00:01:44,880 --> 00:01:49,520
but instead it takes 10 seconds or a

00:01:46,960 --> 00:01:51,439
minute there are many of the background

00:01:49,520 --> 00:01:53,280
jobs running at the same time

00:01:51,439 --> 00:01:55,600
even if you're running a single sidekick

00:01:53,280 --> 00:01:57,520
worker you're going to be running

00:01:55,600 --> 00:01:59,520
multiple flows of execution

00:01:57,520 --> 00:02:02,719
simultaneously

00:01:59,520 --> 00:02:06,240
and some of those jobs take a longer

00:02:02,719 --> 00:02:08,959
time than others to complete or to fail

00:02:06,240 --> 00:02:10,560
meaning that it's a little bit difficult

00:02:08,959 --> 00:02:12,800
at times to

00:02:10,560 --> 00:02:14,319
predict how long an execution of a

00:02:12,800 --> 00:02:16,720
certain task in your application

00:02:14,319 --> 00:02:18,879
uh can take and we think this session

00:02:16,720 --> 00:02:22,080
can be useful to you even if you're not

00:02:18,879 --> 00:02:24,080
uh necessarily a company running a very

00:02:22,080 --> 00:02:27,440
large application because

00:02:24,080 --> 00:02:28,560
uh knowing how to approach uh background

00:02:27,440 --> 00:02:31,280
jobs safely

00:02:28,560 --> 00:02:32,640
uh will potentially allow you to size

00:02:31,280 --> 00:02:34,959
your service better

00:02:32,640 --> 00:02:36,319
that is uh to figure out how many

00:02:34,959 --> 00:02:37,519
servers you need to run for your

00:02:36,319 --> 00:02:39,599
background jobs

00:02:37,519 --> 00:02:40,959
but also it could give you some

00:02:39,599 --> 00:02:42,720
indications and some

00:02:40,959 --> 00:02:44,080
hints on where to start looking if you

00:02:42,720 --> 00:02:45,760
feel that your

00:02:44,080 --> 00:02:47,840
background jobs cluster or your

00:02:45,760 --> 00:02:49,680
background job's code

00:02:47,840 --> 00:02:51,680
is doing something silly or something

00:02:49,680 --> 00:02:54,720
that you do not necessarily want

00:02:51,680 --> 00:02:59,120
wanted to be doing uh this is a

00:02:54,720 --> 00:02:59,120
touchy topic why because

00:02:59,360 --> 00:03:02,640
doing things with background jobs well

00:03:02,080 --> 00:03:05,040
is

00:03:02,640 --> 00:03:05,840
controlling parallel parallel processing

00:03:05,040 --> 00:03:07,920
in time

00:03:05,840 --> 00:03:09,280
and sometimes you have to control it in

00:03:07,920 --> 00:03:12,319
a way which is not

00:03:09,280 --> 00:03:14,879
immediate um this image here

00:03:12,319 --> 00:03:17,120
uh for those who never seen it before

00:03:14,879 --> 00:03:21,519
this is a control panel of the

00:03:17,120 --> 00:03:23,200
chernobyl like rbmk nuclear reactor

00:03:21,519 --> 00:03:25,360
and the control panel on the right

00:03:23,200 --> 00:03:26,239
actually allows you to manually control

00:03:25,360 --> 00:03:29,360
the load

00:03:26,239 --> 00:03:30,480
or control the uh the control rods

00:03:29,360 --> 00:03:32,799
within the separate

00:03:30,480 --> 00:03:33,920
nuclear reactor channels and it was

00:03:32,799 --> 00:03:36,239
actually the job

00:03:33,920 --> 00:03:37,599
of the nuclear reactor operator on every

00:03:36,239 --> 00:03:40,000
shift to ensure

00:03:37,599 --> 00:03:41,920
that these channels heat up and produce

00:03:40,000 --> 00:03:43,840
power evenly

00:03:41,920 --> 00:03:45,599
and it required a lot of manual input

00:03:43,840 --> 00:03:47,200
and to provide this input what you would

00:03:45,599 --> 00:03:48,720
actually do here

00:03:47,200 --> 00:03:50,799
is you would hold one of these colored

00:03:48,720 --> 00:03:52,319
buttons on the right and then you would

00:03:50,799 --> 00:03:54,480
operate this rocker switch on the left

00:03:52,319 --> 00:03:57,040
to move the control rods up or down

00:03:54,480 --> 00:03:58,319
and it was actually known to be a

00:03:57,040 --> 00:04:00,640
stressful job

00:03:58,319 --> 00:04:03,280
for the nuclear reactor operators

00:04:00,640 --> 00:04:04,239
because those rbmk reactors require this

00:04:03,280 --> 00:04:07,840
babysitting

00:04:04,239 --> 00:04:11,280
continuously to make sure that in time

00:04:07,840 --> 00:04:13,360
uh and over time their power

00:04:11,280 --> 00:04:14,640
production within those reactor channels

00:04:13,360 --> 00:04:17,120
would stay even

00:04:14,640 --> 00:04:18,320
and this theme of having your background

00:04:17,120 --> 00:04:21,519
job executions

00:04:18,320 --> 00:04:23,040
even or similar in terms of duration and

00:04:21,519 --> 00:04:23,600
load they calls on your system we're

00:04:23,040 --> 00:04:25,680
going to

00:04:23,600 --> 00:04:28,400
uh we're going to touch that uh multiple

00:04:25,680 --> 00:04:29,680
times in this presentation and the first

00:04:28,400 --> 00:04:31,680
thing that we're going to need

00:04:29,680 --> 00:04:34,000
is to have a way to visualize background

00:04:31,680 --> 00:04:35,280
jobs and what we are suggesting is this

00:04:34,000 --> 00:04:38,479
kind of a timeline

00:04:35,280 --> 00:04:41,199
swin lane view where you look

00:04:38,479 --> 00:04:43,040
at your flows of execution from left to

00:04:41,199 --> 00:04:46,080
right and we have time

00:04:43,040 --> 00:04:46,800
laid out from left to right and your

00:04:46,080 --> 00:04:49,840
little job

00:04:46,800 --> 00:04:51,280
which is say a job of a green class in

00:04:49,840 --> 00:04:54,639
this case

00:04:51,280 --> 00:04:56,720
it gets added to your message queue

00:04:54,639 --> 00:04:58,639
which happens when you call um i don't

00:04:56,720 --> 00:05:00,880
know uh process payment

00:04:58,639 --> 00:05:02,960
uh process payment job.perform later

00:05:00,880 --> 00:05:04,960
then your job gets pulled into the queue

00:05:02,960 --> 00:05:06,479
then it spends some time in the queue

00:05:04,960 --> 00:05:07,280
and then it gets picked up by one of the

00:05:06,479 --> 00:05:09,600
worker

00:05:07,280 --> 00:05:10,639
threads or worker processes for

00:05:09,600 --> 00:05:13,039
execution

00:05:10,639 --> 00:05:14,240
and then it takes some time to execute

00:05:13,039 --> 00:05:15,680
then it completes

00:05:14,240 --> 00:05:17,600
and then there is a different job which

00:05:15,680 --> 00:05:20,080
gets picked up by the same worker thread

00:05:17,600 --> 00:05:22,320
which then also gets executed etc etc

00:05:20,080 --> 00:05:23,759
etc and you have multiple workers and

00:05:22,320 --> 00:05:25,600
threads of execution

00:05:23,759 --> 00:05:27,759
running at the same time and each one of

00:05:25,600 --> 00:05:30,800
them is independently

00:05:27,759 --> 00:05:34,000
executing some kind of uh

00:05:30,800 --> 00:05:38,880
some kind of a job

00:05:34,000 --> 00:05:41,280
i think this this is important because

00:05:38,880 --> 00:05:43,280
to to know what to do with your system

00:05:41,280 --> 00:05:45,120
you need a basic degree of knowing what

00:05:43,280 --> 00:05:48,880
your system is doing

00:05:45,120 --> 00:05:51,680
which brings us to this uh thanks ellick

00:05:48,880 --> 00:05:53,680
um you can you still have that picture

00:05:51,680 --> 00:05:55,120
in mind of that huge control plane from

00:05:53,680 --> 00:05:57,120
a nuclear reactor

00:05:55,120 --> 00:05:59,120
where you can imagine workers watching

00:05:57,120 --> 00:06:00,240
all the metrics and levels and figuring

00:05:59,120 --> 00:06:02,319
out what to do

00:06:00,240 --> 00:06:03,440
and we want to have the same level of

00:06:02,319 --> 00:06:06,319
observability

00:06:03,440 --> 00:06:07,600
into the live production system and to

00:06:06,319 --> 00:06:09,199
to know what's happening with the

00:06:07,600 --> 00:06:11,039
background jobs are they stuck

00:06:09,199 --> 00:06:12,319
are they running at what rate they're

00:06:11,039 --> 00:06:14,080
executing

00:06:12,319 --> 00:06:15,440
so it's important to have observability

00:06:14,080 --> 00:06:18,240
into our system

00:06:15,440 --> 00:06:18,880
next slide there is all sorts of metrics

00:06:18,240 --> 00:06:22,560
that we

00:06:18,880 --> 00:06:25,360
want to to see of our background jobs

00:06:22,560 --> 00:06:26,000
uh it's the throughput the the rate of

00:06:25,360 --> 00:06:28,400
the jobs

00:06:26,000 --> 00:06:29,360
uh in time per minute or per second the

00:06:28,400 --> 00:06:32,880
performance

00:06:29,360 --> 00:06:33,680
um how long uh the does each job uh by

00:06:32,880 --> 00:06:37,440
class takes

00:06:33,680 --> 00:06:38,639
and distribution uh usually p99 p95 p50

00:06:37,440 --> 00:06:41,840
and so on

00:06:38,639 --> 00:06:43,759
to see um what's the

00:06:41,840 --> 00:06:44,960
what is the distribution of performance

00:06:43,759 --> 00:06:47,360
of different job classes

00:06:44,960 --> 00:06:48,319
at shopify we use datadog it's a

00:06:47,360 --> 00:06:50,639
third-party

00:06:48,319 --> 00:06:51,520
vendor that gives that gives you

00:06:50,639 --> 00:06:53,280
monitoring

00:06:51,520 --> 00:06:55,599
uh because we we use that because we

00:06:53,280 --> 00:06:57,360
prefer to to build uh

00:06:55,599 --> 00:06:59,039
the actual e-commerce and infrastructure

00:06:57,360 --> 00:07:02,080
for commerce for ourselves

00:06:59,039 --> 00:07:03,120
uh but other stuff like uh monitoring uh

00:07:02,080 --> 00:07:05,039
we use uh

00:07:03,120 --> 00:07:06,240
third party those uh in this case

00:07:05,039 --> 00:07:08,000
datadog yeah

00:07:06,240 --> 00:07:09,360
yeah but yeah but come on i mean at what

00:07:08,000 --> 00:07:11,360
cost uh i mean

00:07:09,360 --> 00:07:12,800
what's the what's the charge uh in a

00:07:11,360 --> 00:07:16,319
data dock per single

00:07:12,800 --> 00:07:18,639
metric that you want to save that's uh

00:07:16,319 --> 00:07:20,319
that's uh that's really extreme we we

00:07:18,639 --> 00:07:22,080
roll uh more frugally

00:07:20,319 --> 00:07:23,599
at retransfer and what we do we use app

00:07:22,080 --> 00:07:25,599
signal which is our provider for

00:07:23,599 --> 00:07:28,639
application performance monitoring

00:07:25,599 --> 00:07:31,599
and with them creating extra metrics is

00:07:28,639 --> 00:07:32,880
uh is pretty easy and it doesn't cost

00:07:31,599 --> 00:07:34,720
extra

00:07:32,880 --> 00:07:36,240
so that's what we use and an example of

00:07:34,720 --> 00:07:37,039
a dashboard that you could use for

00:07:36,240 --> 00:07:39,520
something like this

00:07:37,039 --> 00:07:41,280
is what is what we have here so on the

00:07:39,520 --> 00:07:42,639
bottom we see the number of jobs that

00:07:41,280 --> 00:07:45,280
our workers have

00:07:42,639 --> 00:07:46,800
received for execution from our web

00:07:45,280 --> 00:07:49,199
application

00:07:46,800 --> 00:07:50,879
and uh on the top we see the jobs which

00:07:49,199 --> 00:07:53,360
are currently executing so if we would

00:07:50,879 --> 00:07:55,680
be seeing very large spikes here

00:07:53,360 --> 00:07:57,280
on the top then we would uh we would

00:07:55,680 --> 00:07:59,120
suspect that there was a very large

00:07:57,280 --> 00:08:00,720
spike in a certain type of job

00:07:59,120 --> 00:08:03,199
and here we can observe the general

00:08:00,720 --> 00:08:04,720
pattern in how many jobs are dominating

00:08:03,199 --> 00:08:07,039
the cluster

00:08:04,720 --> 00:08:08,080
at this at this specific moment and here

00:08:07,039 --> 00:08:11,520
for example we are

00:08:08,080 --> 00:08:14,000
at 10 o'clock at night and

00:08:11,520 --> 00:08:14,879
right now the deletions start executing

00:08:14,000 --> 00:08:16,960
so here we see

00:08:14,879 --> 00:08:19,199
the scrub prefix and the scrub transfer

00:08:16,960 --> 00:08:19,919
jobs which start executing at night when

00:08:19,199 --> 00:08:23,280
we expire

00:08:19,919 --> 00:08:24,800
our old data but whichever tool you use

00:08:23,280 --> 00:08:26,479
i would say that these are the metrics

00:08:24,800 --> 00:08:29,680
that you need because you need to

00:08:26,479 --> 00:08:33,120
be able to find the um

00:08:29,680 --> 00:08:33,760
the jobs which are the outliers so the

00:08:33,120 --> 00:08:36,080
job which

00:08:33,760 --> 00:08:37,919
the jobs which take a lot a lot more

00:08:36,080 --> 00:08:40,080
time than others or the jobs that stall

00:08:37,919 --> 00:08:42,880
for whatever reason or the jobs that

00:08:40,080 --> 00:08:44,399
fail a lot another thing that you need

00:08:42,880 --> 00:08:47,600
to take into account

00:08:44,399 --> 00:08:49,360
is the two-step deploy and uh with the

00:08:47,600 --> 00:08:51,920
two-step deploy i mean this

00:08:49,360 --> 00:08:53,600
so normally you deploy in just two steps

00:08:51,920 --> 00:08:55,200
here with the blue-green release so you

00:08:53,600 --> 00:08:57,040
add a process payment job

00:08:55,200 --> 00:08:58,880
you have committed your changes they are

00:08:57,040 --> 00:09:00,800
a master you are deploying your version

00:08:58,880 --> 00:09:02,560
and then it's running and then your

00:09:00,800 --> 00:09:04,640
application spools the process payment

00:09:02,560 --> 00:09:05,040
job and executes the process payment job

00:09:04,640 --> 00:09:07,360
easy

00:09:05,040 --> 00:09:09,120
right well most likely you're going to

00:09:07,360 --> 00:09:11,279
run into a situation like this

00:09:09,120 --> 00:09:13,040
and what's going to happen is that your

00:09:11,279 --> 00:09:14,560
background worker server is still

00:09:13,040 --> 00:09:16,080
running your old version of the

00:09:14,560 --> 00:09:16,800
application which you have already

00:09:16,080 --> 00:09:19,440
introduced

00:09:16,800 --> 00:09:21,200
your spooling of your new job class in

00:09:19,440 --> 00:09:23,279
your web application server

00:09:21,200 --> 00:09:24,560
which means that within this period of

00:09:23,279 --> 00:09:26,080
time this yellow window

00:09:24,560 --> 00:09:28,640
your web application server is going to

00:09:26,080 --> 00:09:30,320
spool the job and your old worker

00:09:28,640 --> 00:09:31,839
is going to pick up this job from the

00:09:30,320 --> 00:09:33,680
job queue and it's going to try to

00:09:31,839 --> 00:09:35,120
instantiate the process payment job and

00:09:33,680 --> 00:09:36,720
it's not going to be able to and so

00:09:35,120 --> 00:09:38,959
you're going to get an error

00:09:36,720 --> 00:09:40,720
so the answer to this is to actually

00:09:38,959 --> 00:09:42,480
deploy in two steps

00:09:40,720 --> 00:09:44,800
so instead of doing a blue green you do

00:09:42,480 --> 00:09:47,680
a blue red green and so in the first

00:09:44,800 --> 00:09:48,640
version that you deploy you make the job

00:09:47,680 --> 00:09:50,959
code itself

00:09:48,640 --> 00:09:52,399
available so that every every worker can

00:09:50,959 --> 00:09:54,800
find the job class

00:09:52,399 --> 00:09:56,240
to execute the job and only once you

00:09:54,800 --> 00:09:58,480
know that all of your

00:09:56,240 --> 00:10:00,720
background workers are running the newer

00:09:58,480 --> 00:10:03,519
version of the code which has this job

00:10:00,720 --> 00:10:04,000
then you deploy your version which

00:10:03,519 --> 00:10:05,760
starts

00:10:04,000 --> 00:10:07,440
actually in queueing the job it's a

00:10:05,760 --> 00:10:09,920
simple thing uh

00:10:07,440 --> 00:10:12,160
not very hard to ensure that it happens

00:10:09,920 --> 00:10:13,120
but it can be very useful so deploying

00:10:12,160 --> 00:10:16,160
two steps

00:10:13,120 --> 00:10:17,839
and if you have a smaller application or

00:10:16,160 --> 00:10:19,360
you want to cheat a little bit you can

00:10:17,839 --> 00:10:20,800
solve this a bit simpler and you can

00:10:19,360 --> 00:10:22,480
actually deploy in sequence

00:10:20,800 --> 00:10:24,480
meaning you deploy your background

00:10:22,480 --> 00:10:26,240
workers first you ensure that they all

00:10:24,480 --> 00:10:28,399
have replaced with the new version and

00:10:26,240 --> 00:10:30,399
then you deploy your web application

00:10:28,399 --> 00:10:31,440
and at wetransfer we really pay

00:10:30,399 --> 00:10:33,120
attention to this

00:10:31,440 --> 00:10:34,959
and so we do this as part of a code

00:10:33,120 --> 00:10:37,200
review so we just say

00:10:34,959 --> 00:10:38,480
yeah these this change is good to go but

00:10:37,200 --> 00:10:39,920
we're putting it in

00:10:38,480 --> 00:10:41,279
we're putting it in request changes so

00:10:39,920 --> 00:10:42,160
that it can be broken up into pull

00:10:41,279 --> 00:10:45,600
requests

00:10:42,160 --> 00:10:46,800
which um the first pull request adds the

00:10:45,600 --> 00:10:48,320
requisite job code

00:10:46,800 --> 00:10:50,160
and the second pull request which comes

00:10:48,320 --> 00:10:51,839
after and will be deployed afterwards

00:10:50,160 --> 00:10:54,079
adds the spooling of the job what do you

00:10:51,839 --> 00:10:56,880
think come on uh

00:10:54,079 --> 00:10:58,560
we're all humans we cannot uh uh spot

00:10:56,880 --> 00:11:01,600
all the things in every pr

00:10:58,560 --> 00:11:04,160
uh and i'm sure uh as a reviewer i would

00:11:01,600 --> 00:11:05,120
often uh miss noticing all the all the

00:11:04,160 --> 00:11:06,959
stuff like this

00:11:05,120 --> 00:11:09,040
so i wouldn't actually rely on people

00:11:06,959 --> 00:11:11,440
here at shopify

00:11:09,040 --> 00:11:14,160
we use github bots to detect different

00:11:11,440 --> 00:11:16,800
uh changes different patterns on your pr

00:11:14,160 --> 00:11:18,640
and this is example of a comment by bot

00:11:16,800 --> 00:11:20,959
on a pr that introduced

00:11:18,640 --> 00:11:21,839
a new job class it suggests that the

00:11:20,959 --> 00:11:23,920
author of the pr

00:11:21,839 --> 00:11:25,279
to read some documentation and to make

00:11:23,920 --> 00:11:27,279
sure that they're not

00:11:25,279 --> 00:11:28,880
that they're doing this two-step deploy

00:11:27,279 --> 00:11:30,480
process that you discussed here

00:11:28,880 --> 00:11:32,320
oh you fancy people you will pass me the

00:11:30,480 --> 00:11:34,320
source code of this question table once

00:11:32,320 --> 00:11:37,920
we finish recording okay

00:11:34,320 --> 00:11:40,079
uh i and uh let's move to the next one

00:11:37,920 --> 00:11:41,920
so there is also this thing where do you

00:11:40,079 --> 00:11:45,200
store your jobs right claire

00:11:41,920 --> 00:11:46,959
uh right uh it's important to talk uh

00:11:45,200 --> 00:11:48,320
well like we're talking about these

00:11:46,959 --> 00:11:50,800
concepts and

00:11:48,320 --> 00:11:51,680
uh best practices in working with

00:11:50,800 --> 00:11:53,279
background jobs

00:11:51,680 --> 00:11:55,680
but i think it's important to also touch

00:11:53,279 --> 00:11:57,279
on on the storage and how that storage

00:11:55,680 --> 00:12:00,480
uh scales and

00:11:57,279 --> 00:12:03,600
what makes it durable at

00:12:00,480 --> 00:12:06,320
shopify we've been using redis for

00:12:03,600 --> 00:12:06,959
probably uh a decade now we have some

00:12:06,320 --> 00:12:10,399
really good

00:12:06,959 --> 00:12:10,399
operational experience with it

00:12:10,560 --> 00:12:14,959
and uh we used to run it in the data

00:12:12,959 --> 00:12:16,560
center when we were at the data center

00:12:14,959 --> 00:12:18,560
now we're in cloud we run redis and

00:12:16,560 --> 00:12:21,279
cloud uh in

00:12:18,560 --> 00:12:21,760
in gcp when it's time to move for us

00:12:21,279 --> 00:12:24,480
from

00:12:21,760 --> 00:12:26,320
one cloud to another we we will still be

00:12:24,480 --> 00:12:28,880
able to uh to use uh

00:12:26,320 --> 00:12:30,240
redis that we manage ourselves there uh

00:12:28,880 --> 00:12:33,600
which is why we invest

00:12:30,240 --> 00:12:35,600
we invest into our redis stack we run uh

00:12:33,600 --> 00:12:38,240
highly available redis with the two

00:12:35,600 --> 00:12:39,200
instances one being primary and the

00:12:38,240 --> 00:12:42,320
watcher process

00:12:39,200 --> 00:12:44,639
that that switches uh prior one uh

00:12:42,320 --> 00:12:46,399
follower to the primary if the previous

00:12:44,639 --> 00:12:50,399
primary uh

00:12:46,399 --> 00:12:53,519
is not uh working well anymore um

00:12:50,399 --> 00:12:54,079
and that's managed through dns and to to

00:12:53,519 --> 00:12:57,519
store

00:12:54,079 --> 00:12:58,800
uh jobs reliably in in redis we use uh

00:12:57,519 --> 00:13:02,560
lpl push

00:12:58,800 --> 00:13:05,760
which moves a a job from a queue into

00:13:02,560 --> 00:13:06,079
the worker queue and uh the worker queue

00:13:05,760 --> 00:13:08,800
uh

00:13:06,079 --> 00:13:09,920
would get acknowledged uh if the job is

00:13:08,800 --> 00:13:14,880
done processing

00:13:09,920 --> 00:13:16,160
or if the job worker has died the um

00:13:14,880 --> 00:13:18,399
it would not get acknowledged and it

00:13:16,160 --> 00:13:21,519
would get back into the queue eventually

00:13:18,399 --> 00:13:23,519
uh next slide please

00:13:21,519 --> 00:13:25,680
uh it's important to note that redis as

00:13:23,519 --> 00:13:28,560
a database is a single cpu

00:13:25,680 --> 00:13:29,600
it's not concurrent and eventually you

00:13:28,560 --> 00:13:32,399
would run out of

00:13:29,600 --> 00:13:34,320
uh that single cpu on redis so you

00:13:32,399 --> 00:13:36,720
you've got to figure out how you

00:13:34,320 --> 00:13:38,399
uh horizontally scale redis of course

00:13:36,720 --> 00:13:41,519
you can make your client

00:13:38,399 --> 00:13:43,440
um your your rails app your ruby app to

00:13:41,519 --> 00:13:44,000
connect to multiple radiuses and choose

00:13:43,440 --> 00:13:46,240
to which

00:13:44,000 --> 00:13:48,320
redis to connect and so on but that

00:13:46,240 --> 00:13:51,839
logic becomes really complex

00:13:48,320 --> 00:13:52,560
instead we run android proxy which for

00:13:51,839 --> 00:13:55,440
the client

00:13:52,560 --> 00:13:56,240
looks like just one single redis but

00:13:55,440 --> 00:13:58,560
underneath

00:13:56,240 --> 00:14:00,720
redis proxy speaks writer's protocol and

00:13:58,560 --> 00:14:03,040
and forwards

00:14:00,720 --> 00:14:03,920
commands to different radiuses depending

00:14:03,040 --> 00:14:06,800
on

00:14:03,920 --> 00:14:09,040
the key prefix or the hash of the key

00:14:06,800 --> 00:14:11,440
which allows us to invisibly

00:14:09,040 --> 00:14:13,440
add more capacity into our redis cluster

00:14:11,440 --> 00:14:15,600
without having to to change a single

00:14:13,440 --> 00:14:18,800
line of

00:14:15,600 --> 00:14:19,600
of the client code um so that's how we

00:14:18,800 --> 00:14:22,240
run redis

00:14:19,600 --> 00:14:23,440
um and that's how we use redis for

00:14:22,240 --> 00:14:26,560
background jobs

00:14:23,440 --> 00:14:27,360
and i'm curious to uh to learn uh how

00:14:26,560 --> 00:14:30,320
you approach that

00:14:27,360 --> 00:14:32,240
at which transfer you like uh well we

00:14:30,320 --> 00:14:33,279
took something off the shelf so we use

00:14:32,240 --> 00:14:36,079
aws

00:14:33,279 --> 00:14:37,199
we're not on gcp and we've decided to go

00:14:36,079 --> 00:14:40,240
for

00:14:37,199 --> 00:14:41,839
the solution called sqs which is

00:14:40,240 --> 00:14:44,959
something that aws provides

00:14:41,839 --> 00:14:46,320
and sqs is a message queue is a message

00:14:44,959 --> 00:14:49,440
queue service

00:14:46,320 --> 00:14:52,480
and uh it's a managed uh thing

00:14:49,440 --> 00:14:55,440
it has built-in uh built-in durability

00:14:52,480 --> 00:14:58,480
meaning that your jobs are not going to

00:14:55,440 --> 00:15:01,360
uh are not going to disappear they have

00:14:58,480 --> 00:15:04,560
very good durability guarantees

00:15:01,360 --> 00:15:06,320
they have they have a number of really

00:15:04,560 --> 00:15:07,440
nice integrations with other aws

00:15:06,320 --> 00:15:10,639
services such as

00:15:07,440 --> 00:15:12,880
s3 notifications and

00:15:10,639 --> 00:15:14,959
also one of the great advantages of sqs

00:15:12,880 --> 00:15:17,040
is that it is not sophisticated it is

00:15:14,959 --> 00:15:18,959
managed and it's not sophisticated

00:15:17,040 --> 00:15:20,959
so we really like it for the things it

00:15:18,959 --> 00:15:22,639
does not have for example it does not

00:15:20,959 --> 00:15:24,720
allow you to prioritize jobs

00:15:22,639 --> 00:15:26,880
it does not have topics or sub cues so

00:15:24,720 --> 00:15:27,440
you cannot create complex topologies of

00:15:26,880 --> 00:15:28,880
the

00:15:27,440 --> 00:15:30,720
separate cues that you fetch from you

00:15:28,880 --> 00:15:31,519
create one queue it takes a long time

00:15:30,720 --> 00:15:33,120
but then

00:15:31,519 --> 00:15:35,519
there is just this one queue that you

00:15:33,120 --> 00:15:37,600
have uh there is no exactly once

00:15:35,519 --> 00:15:39,440
received so there is no complex protocol

00:15:37,600 --> 00:15:41,519
when you pull something from sqs you

00:15:39,440 --> 00:15:42,560
basically open a long polling http

00:15:41,519 --> 00:15:45,360
request and it just

00:15:42,560 --> 00:15:46,800
feeds you jobs to to perform and the

00:15:45,360 --> 00:15:48,720
only setting is a url

00:15:46,800 --> 00:15:50,320
that you connect to as your end point

00:15:48,720 --> 00:15:53,519
for sending jobs and for

00:15:50,320 --> 00:15:55,600
for listening um for listening for the

00:15:53,519 --> 00:15:58,240
for the new messages to execute and you

00:15:55,600 --> 00:16:01,600
have to delete the job manually from sqs

00:15:58,240 --> 00:16:04,000
and all of our um services use

00:16:01,600 --> 00:16:05,199
sqs through a library called skewer

00:16:04,000 --> 00:16:07,120
which we wrote ourselves

00:16:05,199 --> 00:16:09,040
and which also includes an active job

00:16:07,120 --> 00:16:11,759
integration so our rails app

00:16:09,040 --> 00:16:12,800
uses skewer through active jobs and

00:16:11,759 --> 00:16:15,199
talks to sqs

00:16:12,800 --> 00:16:17,040
through skewer and our smaller services

00:16:15,199 --> 00:16:19,839
they work with keyword directly

00:16:17,040 --> 00:16:22,480
as you are you can find here on github i

00:16:19,839 --> 00:16:25,759
guess here just vendor locks to aws

00:16:22,480 --> 00:16:26,079
uh but with with sqs but yeah yeah yeah

00:16:25,759 --> 00:16:28,079
man

00:16:26,079 --> 00:16:29,680
i mean we we just do not have time to

00:16:28,079 --> 00:16:31,040
contemplate you know moving from one

00:16:29,680 --> 00:16:33,839
cloud platform to another

00:16:31,040 --> 00:16:34,720
every every six months or so you know

00:16:33,839 --> 00:16:36,800
it's uh

00:16:34,720 --> 00:16:37,759
it's choices choices everywhere choices

00:16:36,800 --> 00:16:39,279
everywhere

00:16:37,759 --> 00:16:40,560
the next thing that we need to cover is

00:16:39,279 --> 00:16:42,079
something that's called sequential

00:16:40,560 --> 00:16:43,759
execution

00:16:42,079 --> 00:16:45,440
which is not something you are very

00:16:43,759 --> 00:16:48,720
likely to bump into when you have

00:16:45,440 --> 00:16:50,880
very very few of something but it is

00:16:48,720 --> 00:16:52,320
surprisingly easy to start getting very

00:16:50,880 --> 00:16:53,680
very many of something in your

00:16:52,320 --> 00:16:56,240
application if

00:16:53,680 --> 00:16:57,040
not having many of something is is is is

00:16:56,240 --> 00:16:58,480
not

00:16:57,040 --> 00:17:00,560
one of your priorities for example

00:16:58,480 --> 00:17:02,320
imagine you add a notifications table

00:17:00,560 --> 00:17:04,079
and every now and then things need to be

00:17:02,320 --> 00:17:04,640
deleted from that notifications table

00:17:04,079 --> 00:17:06,480
because

00:17:04,640 --> 00:17:08,799
daily you might might be generating a

00:17:06,480 --> 00:17:11,120
few thousand notifications for example

00:17:08,799 --> 00:17:13,520
and usually you do this in jobs which

00:17:11,120 --> 00:17:15,199
perform things in large batches

00:17:13,520 --> 00:17:17,600
and this can create an interesting

00:17:15,199 --> 00:17:20,559
situation uh if we look at it

00:17:17,600 --> 00:17:22,319
in our in terms of our time swiveling

00:17:20,559 --> 00:17:24,240
view or timeline view

00:17:22,319 --> 00:17:25,439
and we imagine that this blue job

00:17:24,240 --> 00:17:27,280
suddenly takes a really

00:17:25,439 --> 00:17:29,440
really long time because it pros it's

00:17:27,280 --> 00:17:32,640
processing a ton of items

00:17:29,440 --> 00:17:36,400
what happens there is that

00:17:32,640 --> 00:17:38,799
it entirely takes over

00:17:36,400 --> 00:17:40,080
a thread of execution so one of your

00:17:38,799 --> 00:17:42,400
workers or threads

00:17:40,080 --> 00:17:43,840
is taken out of rotation and it's

00:17:42,400 --> 00:17:46,080
occupied by this

00:17:43,840 --> 00:17:47,600
one very long-running job and this is

00:17:46,080 --> 00:17:48,480
not a pattern that you want to create

00:17:47,600 --> 00:17:50,799
because

00:17:48,480 --> 00:17:52,480
with three worker threads for instance

00:17:50,799 --> 00:17:55,360
it is enough to have three

00:17:52,480 --> 00:17:56,480
of those blue jobs to take all of your

00:17:55,360 --> 00:17:58,320
capacity away

00:17:56,480 --> 00:18:00,080
which means that the green jobs and the

00:17:58,320 --> 00:18:02,000
pink jobs and the

00:18:00,080 --> 00:18:04,240
yellow jobs are just not going to get

00:18:02,000 --> 00:18:05,520
any time on the workers to execute so it

00:18:04,240 --> 00:18:08,000
means that for example

00:18:05,520 --> 00:18:09,120
your notification cleanup job is going

00:18:08,000 --> 00:18:10,559
to be running all right

00:18:09,120 --> 00:18:12,559
maybe there's going to be two of them

00:18:10,559 --> 00:18:13,600
running but your email deliveries are

00:18:12,559 --> 00:18:16,160
going to stop

00:18:13,600 --> 00:18:16,720
your payment processing is going to stop

00:18:16,160 --> 00:18:18,320
and

00:18:16,720 --> 00:18:20,160
all the workers are going to be taken by

00:18:18,320 --> 00:18:20,880
those blue items and the solution to

00:18:20,160 --> 00:18:23,360
this

00:18:20,880 --> 00:18:25,039
is actually chopping a job that executes

00:18:23,360 --> 00:18:25,840
for a really long time into smaller

00:18:25,039 --> 00:18:28,880
pieces

00:18:25,840 --> 00:18:30,960
and this allows you to schedule uh

00:18:28,880 --> 00:18:32,559
other jobs between your pieces so

00:18:30,960 --> 00:18:33,919
imagine that here we delete

00:18:32,559 --> 00:18:35,600
notifications

00:18:33,919 --> 00:18:37,280
here we delete the first 10

00:18:35,600 --> 00:18:39,440
notifications or the first thousand

00:18:37,280 --> 00:18:42,080
notifications and we spool in

00:18:39,440 --> 00:18:43,760
the subsequent job which deletes

00:18:42,080 --> 00:18:46,480
notifications starting from

00:18:43,760 --> 00:18:47,039
a thousand one up to and including two

00:18:46,480 --> 00:18:48,799
thousand

00:18:47,039 --> 00:18:50,880
and so on and so forth what this allows

00:18:48,799 --> 00:18:54,559
you to do it allows you to create

00:18:50,880 --> 00:18:55,760
room or space for these jobs to execute

00:18:54,559 --> 00:18:57,280
as well

00:18:55,760 --> 00:18:58,640
so it means that you are not allowing

00:18:57,280 --> 00:18:59,440
one job to gobble up all of your

00:18:58,640 --> 00:19:01,520
capacity and

00:18:59,440 --> 00:19:02,720
also has a good advantage that if you

00:19:01,520 --> 00:19:04,400
decide that you want to add more

00:19:02,720 --> 00:19:05,280
capacity and you have to start another

00:19:04,400 --> 00:19:08,160
worker

00:19:05,280 --> 00:19:08,960
then it means that on that worker uh

00:19:08,160 --> 00:19:11,520
again

00:19:08,960 --> 00:19:13,520
those uh dark blue jobs they are going

00:19:11,520 --> 00:19:14,400
to still be using a substantial amount

00:19:13,520 --> 00:19:16,320
of runtime but

00:19:14,400 --> 00:19:18,480
also there will be some room for other

00:19:16,320 --> 00:19:18,880
jobs to execute whereas if you are in

00:19:18,480 --> 00:19:22,000
this

00:19:18,880 --> 00:19:24,240
scenario may very likely that if you

00:19:22,000 --> 00:19:26,000
start another worker or thread

00:19:24,240 --> 00:19:28,000
this job is also going to start

00:19:26,000 --> 00:19:30,080
executing on that worker or thread

00:19:28,000 --> 00:19:31,360
and then the worker that you just have

00:19:30,080 --> 00:19:32,720
launched when you scale up

00:19:31,360 --> 00:19:35,440
is going to immediately be completely

00:19:32,720 --> 00:19:37,440
consumed so we have a code for this

00:19:35,440 --> 00:19:40,160
which is called sequential perform and

00:19:37,440 --> 00:19:42,080
it's relatively uh straightforward you

00:19:40,160 --> 00:19:44,080
you add this module and you call this

00:19:42,080 --> 00:19:46,160
method in your active job class

00:19:44,080 --> 00:19:48,080
and it says perform sequentially and you

00:19:46,160 --> 00:19:50,080
tell it which positional argument in

00:19:48,080 --> 00:19:50,559
your perform method is an array of

00:19:50,080 --> 00:19:53,840
things

00:19:50,559 --> 00:19:55,760
right very straightforward so

00:19:53,840 --> 00:19:57,200
for example here we say that ids of

00:19:55,760 --> 00:19:59,840
things are

00:19:57,200 --> 00:20:01,120
the the argument zero so the only

00:19:59,840 --> 00:20:02,559
argument to perform

00:20:01,120 --> 00:20:05,200
and then we say please do this in

00:20:02,559 --> 00:20:06,240
batches of 200 and then when you enqueue

00:20:05,200 --> 00:20:09,600
the subsequent

00:20:06,240 --> 00:20:12,559
chunk uh in keywords so that it spends

00:20:09,600 --> 00:20:14,000
uh between these many seconds on waiting

00:20:12,559 --> 00:20:16,000
on the queue before it gets delivered so

00:20:14,000 --> 00:20:17,919
that we can create this window for other

00:20:16,000 --> 00:20:18,880
jobs to execute before the next chunk

00:20:17,919 --> 00:20:22,240
begins

00:20:18,880 --> 00:20:23,840
right and this gives the system a really

00:20:22,240 --> 00:20:26,240
nice property is that your jobs also

00:20:23,840 --> 00:20:28,559
become interruptible i think here uh has

00:20:26,240 --> 00:20:32,000
really done a lot of work on this

00:20:28,559 --> 00:20:34,559
apart from chopping up jobs

00:20:32,000 --> 00:20:36,080
for the benefit of better scheduling

00:20:34,559 --> 00:20:38,240
there is another reason you want

00:20:36,080 --> 00:20:39,120
your your jobs to be as short as

00:20:38,240 --> 00:20:42,159
possible

00:20:39,120 --> 00:20:44,880
and this reason is a cloud environment

00:20:42,159 --> 00:20:46,720
in the modern cloud your your workloads

00:20:44,880 --> 00:20:49,840
your vms your containers

00:20:46,720 --> 00:20:50,480
can be terminated with a very little

00:20:49,840 --> 00:20:53,840
notice

00:20:50,480 --> 00:20:56,240
let's say 30 seconds and your

00:20:53,840 --> 00:20:57,520
your job has to be able to to interrupt

00:20:56,240 --> 00:20:59,600
within 30 seconds

00:20:57,520 --> 00:21:01,200
and push itself back to the queue

00:20:59,600 --> 00:21:04,080
otherwise it would be

00:21:01,200 --> 00:21:05,360
the progress would be lost uh which

00:21:04,080 --> 00:21:08,320
which means that

00:21:05,360 --> 00:21:10,080
there is no way we can run a two-hour

00:21:08,320 --> 00:21:13,440
job that iterates over

00:21:10,080 --> 00:21:16,799
million of off-roads uh without uh

00:21:13,440 --> 00:21:20,240
without having to to interrupt it

00:21:16,799 --> 00:21:21,840
when moving to cloud at shopify we

00:21:20,240 --> 00:21:23,840
we spent quite a bit of time thinking

00:21:21,840 --> 00:21:25,440
about that and also about the fair

00:21:23,840 --> 00:21:27,919
scheduling problem

00:21:25,440 --> 00:21:31,200
uh and we we came up with something

00:21:27,919 --> 00:21:35,120
called iteration api

00:21:31,200 --> 00:21:36,720
um it's actually a an open source gem

00:21:35,120 --> 00:21:38,640
and you can you can try it if you're

00:21:36,720 --> 00:21:41,679
curious but the gist of it

00:21:38,640 --> 00:21:42,960
is that rather than defining the job as

00:21:41,679 --> 00:21:46,400
a preferred method

00:21:42,960 --> 00:21:50,080
you define it as as two methods

00:21:46,400 --> 00:21:50,480
one one method is a collection of things

00:21:50,080 --> 00:21:54,640
to

00:21:50,480 --> 00:21:57,679
to work on it's also a enumerator object

00:21:54,640 --> 00:21:59,679
the api provides this easy helpers to

00:21:57,679 --> 00:22:01,280
build your numerator objects out of

00:21:59,679 --> 00:22:05,360
active vector relations

00:22:01,280 --> 00:22:07,120
out of arrays out of csvs um

00:22:05,360 --> 00:22:09,360
anything you can imagine and you can

00:22:07,120 --> 00:22:11,600
also uh put your uh your

00:22:09,360 --> 00:22:13,200
your own your numerical objects and

00:22:11,600 --> 00:22:16,159
another part of job definition

00:22:13,200 --> 00:22:17,120
is the each iteration method which

00:22:16,159 --> 00:22:19,200
describes

00:22:17,120 --> 00:22:21,280
what to do with every item of the

00:22:19,200 --> 00:22:25,039
collection we found that this

00:22:21,280 --> 00:22:28,559
pattern of collection and action

00:22:25,039 --> 00:22:29,280
fits fits quite a lot of jobs on our

00:22:28,559 --> 00:22:32,880
platform

00:22:29,280 --> 00:22:36,000
and right now that's how

00:22:32,880 --> 00:22:40,159
most of jobs shopify are defined

00:22:36,000 --> 00:22:40,640
and and feel free to to check out the

00:22:40,159 --> 00:22:43,280
gem

00:22:40,640 --> 00:22:44,320
um and try it it works with uh sidekick

00:22:43,280 --> 00:22:47,360
and rescue

00:22:44,320 --> 00:22:48,320
as well how long did it take uh for you

00:22:47,360 --> 00:22:50,080
to explain

00:22:48,320 --> 00:22:52,080
to everyone on the team how those

00:22:50,080 --> 00:22:55,200
enumerator builder

00:22:52,080 --> 00:22:58,000
method works and what the cursor is and

00:22:55,200 --> 00:23:00,799
all this kind of stuff was it easy

00:22:58,000 --> 00:23:02,720
um i guess we invest quite a bit into

00:23:00,799 --> 00:23:04,880
documentation and onboarding

00:23:02,720 --> 00:23:06,480
but once developers are familiar with

00:23:04,880 --> 00:23:08,640
the pattern

00:23:06,480 --> 00:23:09,520
they can navigate the code base fairly

00:23:08,640 --> 00:23:12,640
well

00:23:09,520 --> 00:23:13,919
this is commendable this is commendable

00:23:12,640 --> 00:23:15,679
and this one you also have some

00:23:13,919 --> 00:23:19,280
experience with right

00:23:15,679 --> 00:23:19,679
uh yeah uh it's uh interesting to talk

00:23:19,280 --> 00:23:23,120
about

00:23:19,679 --> 00:23:27,360
uh something um called congestion

00:23:23,120 --> 00:23:30,240
on on resources and uh

00:23:27,360 --> 00:23:32,320
you can you've probably we've all been

00:23:30,240 --> 00:23:35,440
in a situation where we see

00:23:32,320 --> 00:23:37,360
um uh where we see workers

00:23:35,440 --> 00:23:38,720
not catching up with the amount of jobs

00:23:37,360 --> 00:23:40,559
maybe it's a spider

00:23:38,720 --> 00:23:42,080
maybe it's a spike of traffic or

00:23:40,559 --> 00:23:45,200
something uh

00:23:42,080 --> 00:23:47,600
is uh slowing down and our first

00:23:45,200 --> 00:23:49,520
reaction is to throw more workers throw

00:23:47,600 --> 00:23:52,559
more money into the problem

00:23:49,520 --> 00:23:54,320
and sometimes that works sometimes that

00:23:52,559 --> 00:23:57,679
doesn't

00:23:54,320 --> 00:23:57,679
let's go to the next slide

00:23:58,080 --> 00:24:01,360
there is always some bottlenecks in the

00:24:00,000 --> 00:24:04,640
system it can be

00:24:01,360 --> 00:24:07,039
database a database can do only

00:24:04,640 --> 00:24:09,200
given amount of writes per second it can

00:24:07,039 --> 00:24:12,240
be a third-party api

00:24:09,200 --> 00:24:15,760
that always has some some rate limits

00:24:12,240 --> 00:24:17,360
and the more workers you have

00:24:15,760 --> 00:24:19,919
concurrently executing something in the

00:24:17,360 --> 00:24:22,320
system the higher chance you will hit

00:24:19,919 --> 00:24:25,440
those uh

00:24:22,320 --> 00:24:27,840
those bottlenecks um so

00:24:25,440 --> 00:24:29,279
it's not as as simple as throwing more

00:24:27,840 --> 00:24:32,640
workers and

00:24:29,279 --> 00:24:35,520
actually we have to throttle uh

00:24:32,640 --> 00:24:36,080
things so that uh we don't do too many

00:24:35,520 --> 00:24:38,000
uh

00:24:36,080 --> 00:24:41,760
rights to the database or we don't do

00:24:38,000 --> 00:24:44,480
too many uh third-party api calls

00:24:41,760 --> 00:24:45,440
that's a good one it's uh that's this

00:24:44,480 --> 00:24:49,200
one right

00:24:45,440 --> 00:24:52,000
um yeah uh as i as i explained uh about

00:24:49,200 --> 00:24:55,440
iteration api it wraps all units of work

00:24:52,000 --> 00:24:57,520
into these uh well-defined methods and

00:24:55,440 --> 00:24:58,559
now that every unit of work is wrapped

00:24:57,520 --> 00:25:01,679
into something

00:24:58,559 --> 00:25:04,080
we can do things platform-wide

00:25:01,679 --> 00:25:04,720
so for instance every each iteration

00:25:04,080 --> 00:25:07,760
method

00:25:04,720 --> 00:25:11,440
from every job would be throttled based

00:25:07,760 --> 00:25:13,440
on the database health uh in a way that

00:25:11,440 --> 00:25:14,720
developers don't even need to learn

00:25:13,440 --> 00:25:16,720
about um

00:25:14,720 --> 00:25:19,039
how to throttle on the database health

00:25:16,720 --> 00:25:21,760
what signals to use and so on and so on

00:25:19,039 --> 00:25:23,760
um and we can we can roll that uh for

00:25:21,760 --> 00:25:25,200
for the entire fleet for all the jobs in

00:25:23,760 --> 00:25:26,640
the platform

00:25:25,200 --> 00:25:28,640
ah that's really that's really

00:25:26,640 --> 00:25:29,039
sophisticated we have it much simpler

00:25:28,640 --> 00:25:30,799
because

00:25:29,039 --> 00:25:32,880
like i would have never guessed that

00:25:30,799 --> 00:25:35,520
this thing actually throttles the db

00:25:32,880 --> 00:25:36,640
but i guess it's it's the trick it has

00:25:35,520 --> 00:25:38,559
up its sleeve

00:25:36,640 --> 00:25:40,159
we do it uh in a more straightforward

00:25:38,559 --> 00:25:43,600
fashion we just have a module called

00:25:40,159 --> 00:25:45,120
db and my former colleague van der

00:25:43,600 --> 00:25:46,080
hillen has made a great presentation

00:25:45,120 --> 00:25:48,720
about this technique

00:25:46,080 --> 00:25:50,799
uh at one of the band bancons i believe

00:25:48,720 --> 00:25:51,919
and what we do is on every batch that we

00:25:50,799 --> 00:25:54,200
want to process

00:25:51,919 --> 00:25:56,240
we wrap it in a call to the

00:25:54,200 --> 00:25:57,600
dbwaiter.gently method and this method

00:25:56,240 --> 00:25:59,840
is just going to wait for db

00:25:57,600 --> 00:26:02,720
availability so it's going to call for a

00:25:59,840 --> 00:26:04,559
certain mysql parameter and when and it

00:26:02,720 --> 00:26:06,240
only is going to allow the method call

00:26:04,559 --> 00:26:07,520
to continue once this parameter is

00:26:06,240 --> 00:26:10,559
within limits

00:26:07,520 --> 00:26:12,480
um but yeah i i think

00:26:10,559 --> 00:26:14,000
this is really this is much slicker

00:26:12,480 --> 00:26:14,960
although i wouldn't have guessed what it

00:26:14,000 --> 00:26:16,799
does

00:26:14,960 --> 00:26:19,520
that's a lot of block of codes to wrap

00:26:16,799 --> 00:26:22,080
into deviator gently

00:26:19,520 --> 00:26:23,279
yeah well it is visible it is visible

00:26:22,080 --> 00:26:26,640
though it is visible

00:26:23,279 --> 00:26:28,159
another uh thing that we uh encounter is

00:26:26,640 --> 00:26:31,200
dock piling

00:26:28,159 --> 00:26:32,400
and by dockpiling i mean that at a

00:26:31,200 --> 00:26:35,520
certain moment

00:26:32,400 --> 00:26:37,919
multiple jobs uh kind of uh

00:26:35,520 --> 00:26:39,600
para drop down on one single resource

00:26:37,919 --> 00:26:41,840
and then this resource

00:26:39,600 --> 00:26:44,000
gets overwhelmed it can be the database

00:26:41,840 --> 00:26:44,880
but for us it can be external apis

00:26:44,000 --> 00:26:47,760
primarily

00:26:44,880 --> 00:26:49,520
for example what happens when you shoot

00:26:47,760 --> 00:26:54,000
too many requests

00:26:49,520 --> 00:26:54,640
into s3 to a certain prefix then s3 is

00:26:54,000 --> 00:26:56,640
going to

00:26:54,640 --> 00:26:58,080
give you back an error which is called

00:26:56,640 --> 00:26:59,360
slow down

00:26:58,080 --> 00:27:01,760
which means that you are hammering it

00:26:59,360 --> 00:27:03,600
too much but it will also before it

00:27:01,760 --> 00:27:05,919
replies to you with the slowdown

00:27:03,600 --> 00:27:06,640
it's going to hold up your http api

00:27:05,919 --> 00:27:08,640
requests

00:27:06,640 --> 00:27:10,400
for a long number of seconds because

00:27:08,640 --> 00:27:12,480
they realize that if you have

00:27:10,400 --> 00:27:14,080
something in your system which sends

00:27:12,480 --> 00:27:16,080
them too many requests

00:27:14,080 --> 00:27:17,520
then if they reply with a slowdown you

00:27:16,080 --> 00:27:19,840
are likely to continue

00:27:17,520 --> 00:27:21,840
sending the requests at this rate so

00:27:19,840 --> 00:27:24,000
what they do they artificially stretch

00:27:21,840 --> 00:27:25,840
the response time to your request

00:27:24,000 --> 00:27:27,760
so that your system does not have the

00:27:25,840 --> 00:27:29,200
opportunity to continue generating more

00:27:27,760 --> 00:27:30,559
and more and more and more requests and

00:27:29,200 --> 00:27:33,600
what happens then

00:27:30,559 --> 00:27:34,399
is that imagine this job uh executes the

00:27:33,600 --> 00:27:38,000
yellow one

00:27:34,399 --> 00:27:41,039
and it executes okay because it

00:27:38,000 --> 00:27:43,200
uh because it uh

00:27:41,039 --> 00:27:45,440
it has enough capacity on this specific

00:27:43,200 --> 00:27:46,640
api call but then another job starts and

00:27:45,440 --> 00:27:49,039
it gets throttled

00:27:46,640 --> 00:27:51,279
and it occupies this execution slot and

00:27:49,039 --> 00:27:53,520
it takes suddenly instead of taking 300

00:27:51,279 --> 00:27:56,240
milliseconds it takes 30 seconds or 20

00:27:53,520 --> 00:27:58,799
seconds before it finally fails

00:27:56,240 --> 00:28:00,399
and in this situation uh if you start

00:27:58,799 --> 00:28:02,159
more workers because you are not

00:28:00,399 --> 00:28:03,279
processing the jobs at a sufficient rate

00:28:02,159 --> 00:28:05,279
what you're going to do you're going to

00:28:03,279 --> 00:28:08,080
make the situation worse

00:28:05,279 --> 00:28:10,159
because all of the jobs which try to

00:28:08,080 --> 00:28:13,200
execute the same api call

00:28:10,159 --> 00:28:14,880
which is blocking or throttling you

00:28:13,200 --> 00:28:16,960
all of these workers are not are now

00:28:14,880 --> 00:28:18,559
going to take 20 or 30 seconds

00:28:16,960 --> 00:28:20,720
which means that all of the new workers

00:28:18,559 --> 00:28:23,039
that you start are going to be stuck

00:28:20,720 --> 00:28:24,720
uh waiting for this error reply from

00:28:23,039 --> 00:28:26,559
from s3 in this particular in this

00:28:24,720 --> 00:28:28,559
particular case so what we do

00:28:26,559 --> 00:28:31,039
is we apply a so-called concurrent

00:28:28,559 --> 00:28:32,640
execution lock in this situation

00:28:31,039 --> 00:28:34,159
and the concurrent execution lock is

00:28:32,640 --> 00:28:37,200
something that sits between

00:28:34,159 --> 00:28:39,520
the job uh the job execution and

00:28:37,200 --> 00:28:40,480
the external resource and what's going

00:28:39,520 --> 00:28:42,880
to happen is that

00:28:40,480 --> 00:28:44,559
here we execute a job which deletes from

00:28:42,880 --> 00:28:47,279
this prefix so the transfer

00:28:44,559 --> 00:28:48,720
slash a b can be a one of the job

00:28:47,279 --> 00:28:49,919
arguments for example one of the job

00:28:48,720 --> 00:28:52,880
parameters

00:28:49,919 --> 00:28:54,559
and uh if a second job arrives which

00:28:52,880 --> 00:28:56,159
processes the same prefix

00:28:54,559 --> 00:28:57,840
and which wants to do the same call

00:28:56,159 --> 00:29:00,480
what's going to happen is that before

00:28:57,840 --> 00:29:01,200
it's allowed to start it's going to be

00:29:00,480 --> 00:29:02,480
cancelled

00:29:01,200 --> 00:29:04,000
it's going to be cancelled and it's

00:29:02,480 --> 00:29:05,440
going to be thrown back into the queue

00:29:04,000 --> 00:29:07,919
with a certain delay

00:29:05,440 --> 00:29:08,480
so that when it arrives in one of the

00:29:07,919 --> 00:29:11,200
workers

00:29:08,480 --> 00:29:13,279
again the previous job which consumes

00:29:11,200 --> 00:29:15,919
capacity on that shared resource

00:29:13,279 --> 00:29:16,559
has finished meaning that we do not

00:29:15,919 --> 00:29:18,080
start

00:29:16,559 --> 00:29:19,919
getting into a situation where we get

00:29:18,080 --> 00:29:22,000
throttled and we also free

00:29:19,919 --> 00:29:24,399
this slot so that this green job can

00:29:22,000 --> 00:29:26,880
execute in there

00:29:24,399 --> 00:29:27,440
instead and we have a small thing for

00:29:26,880 --> 00:29:28,960
that

00:29:27,440 --> 00:29:30,799
which is just called limit concurrent

00:29:28,960 --> 00:29:31,679
executions we try to design our jobs in

00:29:30,799 --> 00:29:34,799
such a way

00:29:31,679 --> 00:29:36,640
that the shapes of the um

00:29:34,799 --> 00:29:38,399
arguments or the parameters of the jobs

00:29:36,640 --> 00:29:40,640
are sufficient to

00:29:38,399 --> 00:29:42,080
set up this concurrent execution lock

00:29:40,640 --> 00:29:44,399
for that job and it gets

00:29:42,080 --> 00:29:46,159
this log gets applied before uh before

00:29:44,399 --> 00:29:48,159
the job event starts

00:29:46,159 --> 00:29:50,480
uh and for that we use something called

00:29:48,159 --> 00:29:51,440
suo which is a very nice gem for inter

00:29:50,480 --> 00:29:53,919
for implementing

00:29:51,440 --> 00:29:54,880
locks and token logs based on radius or

00:29:53,919 --> 00:29:57,600
mkhd

00:29:54,880 --> 00:29:59,520
and we use redis as a supplement to sqs

00:29:57,600 --> 00:30:00,000
so transient data or the data we need

00:29:59,520 --> 00:30:03,120
very

00:30:00,000 --> 00:30:04,960
very very randomly

00:30:03,120 --> 00:30:07,440
we store in redis but the jobs

00:30:04,960 --> 00:30:08,159
themselves has to be durable and they

00:30:07,440 --> 00:30:11,279
are

00:30:08,159 --> 00:30:14,480
on sqs and then of course you need

00:30:11,279 --> 00:30:17,360
to control this thing somehow right here

00:30:14,480 --> 00:30:18,799
uh right we also use a very similar way

00:30:17,360 --> 00:30:23,760
to control concurrency

00:30:18,799 --> 00:30:27,120
uh on based on radis as a metadata story

00:30:23,760 --> 00:30:28,399
uh but uh i was what i what i wanted to

00:30:27,120 --> 00:30:31,039
talk about here

00:30:28,399 --> 00:30:32,720
is disaster scenarios and how we protect

00:30:31,039 --> 00:30:35,760
from those

00:30:32,720 --> 00:30:38,240
imagine an area in code that

00:30:35,760 --> 00:30:39,039
that causes a certain job to to get

00:30:38,240 --> 00:30:41,440
enqueued

00:30:39,039 --> 00:30:42,240
in the infinite loop uh making the the

00:30:41,440 --> 00:30:45,200
queue size

00:30:42,240 --> 00:30:48,159
grow through the roof or imagine

00:30:45,200 --> 00:30:48,159
something retrying

00:30:48,840 --> 00:30:53,919
indefinitely

00:30:50,000 --> 00:30:55,840
we want a way to uh to cancel

00:30:53,919 --> 00:30:56,960
all those things as an as a as an

00:30:55,840 --> 00:31:00,000
emergency

00:30:56,960 --> 00:31:03,440
tool uh to have control over the system

00:31:00,000 --> 00:31:04,960
and uh ideally we want to cancel those

00:31:03,440 --> 00:31:08,640
selectively

00:31:04,960 --> 00:31:11,760
we employ chat ops a lot at shopify

00:31:08,640 --> 00:31:13,600
for all sorts of commands to manage and

00:31:11,760 --> 00:31:16,159
operate our infrastructure

00:31:13,600 --> 00:31:17,519
and we also use chat ups for jobs

00:31:16,159 --> 00:31:21,120
operation

00:31:17,519 --> 00:31:24,320
and one tool called called black hole

00:31:21,120 --> 00:31:25,840
allows us to send all the jobs of the

00:31:24,320 --> 00:31:29,600
certain uh

00:31:25,840 --> 00:31:32,640
filter basically to to to nowhere

00:31:29,600 --> 00:31:34,960
they would not get executed at all

00:31:32,640 --> 00:31:36,960
for instance you could target a certain

00:31:34,960 --> 00:31:40,720
job class with any arguments

00:31:36,960 --> 00:31:41,360
or you can target a job class of payment

00:31:40,720 --> 00:31:44,559
job

00:31:41,360 --> 00:31:45,600
with a specific tenant id that equals a

00:31:44,559 --> 00:31:47,679
specific number

00:31:45,600 --> 00:31:48,799
or you could even use regular

00:31:47,679 --> 00:31:51,519
expressions

00:31:48,799 --> 00:31:51,840
uh if uh if that's something that you

00:31:51,519 --> 00:31:55,360
want

00:31:51,840 --> 00:31:57,200
to manage based on params

00:31:55,360 --> 00:31:58,880
that's uh really nice also very

00:31:57,200 --> 00:31:59,200
sophisticated i think we are a little

00:31:58,880 --> 00:32:01,200
bit

00:31:59,200 --> 00:32:02,320
uh more retrograde in this respect we

00:32:01,200 --> 00:32:04,880
just have this

00:32:02,320 --> 00:32:05,600
which basically you can set a key in

00:32:04,880 --> 00:32:08,320
redis

00:32:05,600 --> 00:32:08,720
to discard jobs of a certain class and

00:32:08,320 --> 00:32:11,279
you

00:32:08,720 --> 00:32:11,760
have to set that radius key explicitly

00:32:11,279 --> 00:32:13,120
on the

00:32:11,760 --> 00:32:15,840
on the radius cluster and you have to

00:32:13,120 --> 00:32:18,159
set it manually chat ups are really nice

00:32:15,840 --> 00:32:19,200
really nice really nice would love to

00:32:18,159 --> 00:32:21,840
have this

00:32:19,200 --> 00:32:22,720
i would uh get slightly uncomfortable

00:32:21,840 --> 00:32:25,039
having to

00:32:22,720 --> 00:32:26,799
get into the red the live radius on

00:32:25,039 --> 00:32:29,200
production to set up

00:32:26,799 --> 00:32:30,399
that forced this card key but i guess

00:32:29,200 --> 00:32:32,480
that works too

00:32:30,399 --> 00:32:34,320
uh yeah works for us but i agree with

00:32:32,480 --> 00:32:35,919
you it's very it's uncomfortable this is

00:32:34,320 --> 00:32:37,279
in time of need man in time of need in

00:32:35,919 --> 00:32:40,720
time of need

00:32:37,279 --> 00:32:44,159
and we have the the classica

00:32:40,720 --> 00:32:47,600
uh yeah uh job priorities something that

00:32:44,159 --> 00:32:47,919
uh every uh library offers as the first

00:32:47,600 --> 00:32:51,120
thing

00:32:47,919 --> 00:32:52,640
in the readme uh but also a topic that i

00:32:51,120 --> 00:32:55,600
don't think we would talk enough

00:32:52,640 --> 00:32:57,440
uh about in the community uh yeah so if

00:32:55,600 --> 00:32:58,880
you if you start using sidekick or

00:32:57,440 --> 00:33:02,480
rescue or any other

00:32:58,880 --> 00:33:04,960
uh library it will tell you uh to define

00:33:02,480 --> 00:33:07,440
a number of queues and every job would

00:33:04,960 --> 00:33:09,279
have a queue assigned and you can

00:33:07,440 --> 00:33:11,519
give a bit more workers to a certain

00:33:09,279 --> 00:33:12,080
queue or a bit less workers to another

00:33:11,519 --> 00:33:13,679
queue

00:33:12,080 --> 00:33:15,279
some queues would be higher priorities

00:33:13,679 --> 00:33:16,559
some would be lower priority and so on

00:33:15,279 --> 00:33:20,240
and so on

00:33:16,559 --> 00:33:22,559
um if we look at e-commerce

00:33:20,240 --> 00:33:24,799
um and like what what are the actual

00:33:22,559 --> 00:33:28,000
business models that that happened there

00:33:24,799 --> 00:33:31,679
uh the one that's most important is

00:33:28,000 --> 00:33:33,600
uh the checkout flow you go

00:33:31,679 --> 00:33:35,600
add something to the card proceed to the

00:33:33,600 --> 00:33:38,720
checkout enter your

00:33:35,600 --> 00:33:39,360
mailing address shipping address and you

00:33:38,720 --> 00:33:41,760
want to see

00:33:39,360 --> 00:33:43,360
how much it costs to to to get something

00:33:41,760 --> 00:33:45,600
shipped for you

00:33:43,360 --> 00:33:46,640
checking shipping rates for a bunch of

00:33:45,600 --> 00:33:48,880
providers

00:33:46,640 --> 00:33:50,000
uh can take a long time we don't want to

00:33:48,880 --> 00:33:52,080
do that from a weather

00:33:50,000 --> 00:33:53,200
from a web request so that happens from

00:33:52,080 --> 00:33:56,000
a background job

00:33:53,200 --> 00:33:57,279
while the well the client is waiting so

00:33:56,000 --> 00:33:59,760
we want the job to

00:33:57,279 --> 00:34:01,679
execute as fast as possible that job

00:33:59,760 --> 00:34:04,799
would be in uh

00:34:01,679 --> 00:34:05,360
some of the highest queues then there

00:34:04,799 --> 00:34:07,919
would be

00:34:05,360 --> 00:34:08,720
a payment happening at the step when

00:34:07,919 --> 00:34:10,800
you've uh

00:34:08,720 --> 00:34:12,960
agreed to that shipping rate and entered

00:34:10,800 --> 00:34:15,520
your credit card number and so on

00:34:12,960 --> 00:34:16,320
and uh payment would probably take uh

00:34:15,520 --> 00:34:18,480
much longer

00:34:16,320 --> 00:34:20,320
because the process of moving money from

00:34:18,480 --> 00:34:24,240
one account to another account

00:34:20,320 --> 00:34:26,879
uh pre-authorizing and doing all the

00:34:24,240 --> 00:34:28,720
uh all the checks uh with the credit

00:34:26,879 --> 00:34:30,480
card takes time

00:34:28,720 --> 00:34:31,919
so maybe that would have a slightly

00:34:30,480 --> 00:34:32,720
different priority from the shipping

00:34:31,919 --> 00:34:34,560
rate

00:34:32,720 --> 00:34:36,000
and then there is different steps like

00:34:34,560 --> 00:34:38,480
updating the inventory

00:34:36,000 --> 00:34:39,839
uh sending mail notifications maybe

00:34:38,480 --> 00:34:42,240
sending web hooks

00:34:39,839 --> 00:34:44,079
to integrations about the fact that

00:34:42,240 --> 00:34:46,320
there is a new purchase

00:34:44,079 --> 00:34:47,919
uh some of those would have uh much

00:34:46,320 --> 00:34:51,359
lower

00:34:47,919 --> 00:34:55,040
priority of their queue

00:34:51,359 --> 00:34:58,720
than than shipping payment rates or

00:34:55,040 --> 00:35:02,079
or doing uh or processing the payment

00:34:58,720 --> 00:35:04,960
so we employ queues quite a lot and

00:35:02,079 --> 00:35:06,800
while it's not always very easy to

00:35:04,960 --> 00:35:08,560
choose the right queue

00:35:06,800 --> 00:35:10,240
that's something that we wouldn't be

00:35:08,560 --> 00:35:12,720
able to to live without

00:35:10,240 --> 00:35:13,680
from the operational point of view okay

00:35:12,720 --> 00:35:15,440
so this is

00:35:13,680 --> 00:35:16,960
this is somewhere i i just i just need

00:35:15,440 --> 00:35:20,240
to throw this out there i think

00:35:16,960 --> 00:35:21,760
priorities are are no good um for two

00:35:20,240 --> 00:35:23,520
reasons so first for us

00:35:21,760 --> 00:35:24,880
uh those priorities are very hard to

00:35:23,520 --> 00:35:26,800
realize we'll talk about this in a

00:35:24,880 --> 00:35:29,040
second but also

00:35:26,800 --> 00:35:30,240
the idea behind using priorities is

00:35:29,040 --> 00:35:32,800
usually that you say

00:35:30,240 --> 00:35:34,800
one job is more important than the other

00:35:32,800 --> 00:35:36,960
so when there is not enough

00:35:34,800 --> 00:35:38,800
capacity to process all the jobs at the

00:35:36,960 --> 00:35:40,400
same time let's process

00:35:38,800 --> 00:35:42,320
a certain job which has a higher

00:35:40,400 --> 00:35:44,320
priority let's process it first

00:35:42,320 --> 00:35:45,680
so you're making an operational decision

00:35:44,320 --> 00:35:47,760
up front as it were

00:35:45,680 --> 00:35:48,960
you're making a guess effectively and

00:35:47,760 --> 00:35:50,880
you're saying this job is

00:35:48,960 --> 00:35:52,560
this job is more important so let's let

00:35:50,880 --> 00:35:54,880
it execute first

00:35:52,560 --> 00:35:57,280
what it gets you to is a situation like

00:35:54,880 --> 00:35:58,640
this so imagine we're running a blue job

00:35:57,280 --> 00:36:00,400
and the blue job has the highest

00:35:58,640 --> 00:36:02,640
priority and as we

00:36:00,400 --> 00:36:04,640
in computer graphics we used to say i do

00:36:02,640 --> 00:36:06,160
not always set my render priority but

00:36:04,640 --> 00:36:09,119
when i do it's nine nine nine

00:36:06,160 --> 00:36:09,760
nine uh and so this blue job executes

00:36:09,119 --> 00:36:11,440
first

00:36:09,760 --> 00:36:13,760
and it starts executing first but it

00:36:11,440 --> 00:36:15,440
also has an error and it also times out

00:36:13,760 --> 00:36:16,880
and it's also slow on the database so

00:36:15,440 --> 00:36:19,119
what it does it consumes

00:36:16,880 --> 00:36:22,400
your entire worker thread again so

00:36:19,119 --> 00:36:23,920
you've taken a unit of capacity out

00:36:22,400 --> 00:36:26,560
it runs for a really long time it does

00:36:23,920 --> 00:36:29,520
not allow other jobs to execute

00:36:26,560 --> 00:36:30,480
and it effectively executes the guess

00:36:29,520 --> 00:36:33,599
that you have made

00:36:30,480 --> 00:36:34,320
that this job can start first whereas in

00:36:33,599 --> 00:36:37,359
practice

00:36:34,320 --> 00:36:40,960
it will still cause the same operational

00:36:37,359 --> 00:36:43,200
the same operational concerns and the

00:36:40,960 --> 00:36:45,520
problem with this guessing is that you

00:36:43,200 --> 00:36:46,800
is that you know the price the actual

00:36:45,520 --> 00:36:49,359
priorities like

00:36:46,800 --> 00:36:51,680
most of the time we find ours ourselves

00:36:49,359 --> 00:36:53,440
uh thinking about oh it would be nice if

00:36:51,680 --> 00:36:55,440
this job had a lower priority than

00:36:53,440 --> 00:36:57,280
others or we think oh it would be nice

00:36:55,440 --> 00:36:58,320
that this job had a higher priority than

00:36:57,280 --> 00:37:00,000
others

00:36:58,320 --> 00:37:01,680
happens when we have an outage and then

00:37:00,000 --> 00:37:03,359
we see oh this particular job has

00:37:01,680 --> 00:37:03,920
failure so it would be nice if it had

00:37:03,359 --> 00:37:06,960
had

00:37:03,920 --> 00:37:09,520
lower priorities but the

00:37:06,960 --> 00:37:10,079
failures can be intermittent so the jobs

00:37:09,520 --> 00:37:12,160
can

00:37:10,079 --> 00:37:13,760
a job that was perfectly fine yesterday

00:37:12,160 --> 00:37:16,000
and was talking to the same email

00:37:13,760 --> 00:37:16,800
provider today the email providers api

00:37:16,000 --> 00:37:19,200
is playing up

00:37:16,800 --> 00:37:20,160
and so this job is suddenly causing you

00:37:19,200 --> 00:37:22,480
a lot of trouble

00:37:20,160 --> 00:37:24,079
but the priorities you set in code and

00:37:22,480 --> 00:37:26,320
you set those priorities

00:37:24,079 --> 00:37:28,640
uh in a in a structured manner in a

00:37:26,320 --> 00:37:30,240
commit so it's not some it's not a knob

00:37:28,640 --> 00:37:31,440
that you can turn in real time it's

00:37:30,240 --> 00:37:33,520
really a

00:37:31,440 --> 00:37:34,960
hard upfront guesstimate that you're

00:37:33,520 --> 00:37:35,680
that you're taking and a bet that you're

00:37:34,960 --> 00:37:38,320
making

00:37:35,680 --> 00:37:39,280
and also for us it's way less relevant

00:37:38,320 --> 00:37:41,760
because

00:37:39,280 --> 00:37:43,359
it's sqs and sqs does not have routing

00:37:41,760 --> 00:37:44,720
topics which would allow you to have

00:37:43,359 --> 00:37:47,119
separate sub-queues

00:37:44,720 --> 00:37:49,200
creating an sqlsq takes a lot of time

00:37:47,119 --> 00:37:52,480
because they use some replication things

00:37:49,200 --> 00:37:55,200
so that the skew is durable and reliable

00:37:52,480 --> 00:37:56,240
and you only can create up to that many

00:37:55,200 --> 00:37:57,920
queues per account

00:37:56,240 --> 00:37:59,359
so when you when you're creating a queue

00:37:57,920 --> 00:38:00,880
you have to be really you

00:37:59,359 --> 00:38:03,280
well you have to take that into

00:38:00,880 --> 00:38:05,839
consideration how many queues you create

00:38:03,280 --> 00:38:07,359
and those cues they are really like they

00:38:05,839 --> 00:38:09,760
are really much more like heaps

00:38:07,359 --> 00:38:11,119
they are not like kafka topics uh kafka

00:38:09,760 --> 00:38:14,640
topics for example they are

00:38:11,119 --> 00:38:17,040
ordered um and um

00:38:14,640 --> 00:38:18,400
uh they are not like routing keys in

00:38:17,040 --> 00:38:21,680
rabbit and queue for example

00:38:18,400 --> 00:38:23,359
so maybe we could have used priorities

00:38:21,680 --> 00:38:24,240
if we were using a more sophisticated

00:38:23,359 --> 00:38:26,880
message broker

00:38:24,240 --> 00:38:28,960
because those systems like sidekick and

00:38:26,880 --> 00:38:31,280
rabbit and q and sqs they're fundament

00:38:28,960 --> 00:38:33,599
usually they're called message brokers

00:38:31,280 --> 00:38:35,200
but for us at this time using priorities

00:38:33,599 --> 00:38:35,839
would actually create more trouble than

00:38:35,200 --> 00:38:38,560
it's worth

00:38:35,839 --> 00:38:39,040
i think for us we take the easy and the

00:38:38,560 --> 00:38:41,920
easy

00:38:39,040 --> 00:38:42,880
hard way out is that we try to get into

00:38:41,920 --> 00:38:45,920
a situation where

00:38:42,880 --> 00:38:47,280
on average more or less most of the jobs

00:38:45,920 --> 00:38:49,680
fit into a hard

00:38:47,280 --> 00:38:51,359
known time window and if the jobs start

00:38:49,680 --> 00:38:52,240
exceeding this time window then we take

00:38:51,359 --> 00:38:54,160
operational

00:38:52,240 --> 00:38:55,760
measures based on that as opposed to

00:38:54,160 --> 00:38:58,400
making bets as to

00:38:55,760 --> 00:38:59,920
well if that job was scheduled first

00:38:58,400 --> 00:39:00,640
then maybe our performance would have

00:38:59,920 --> 00:39:03,359
been better

00:39:00,640 --> 00:39:04,000
than if it weren't but like i said

00:39:03,359 --> 00:39:07,520
that's

00:39:04,000 --> 00:39:10,400
our that's our approach uh that's uh

00:39:07,520 --> 00:39:11,440
uh i guess the the that whole theme of

00:39:10,400 --> 00:39:14,480
different approaches

00:39:11,440 --> 00:39:17,599
it kind of resonates here right yeah i

00:39:14,480 --> 00:39:21,040
i think it's time to to wrap up and

00:39:17,599 --> 00:39:22,800
it's interesting to note that uh uh like

00:39:21,040 --> 00:39:24,640
shopify and we transfer have slightly

00:39:22,800 --> 00:39:26,839
different

00:39:24,640 --> 00:39:29,040
number of of developers at shopify we

00:39:26,839 --> 00:39:30,720
have um

00:39:29,040 --> 00:39:32,640
hundreds of developers working on the

00:39:30,720 --> 00:39:35,280
same uh monolith

00:39:32,640 --> 00:39:37,440
and we optimize for different things and

00:39:35,280 --> 00:39:40,560
different styles of apis

00:39:37,440 --> 00:39:41,280
and it's interesting how based on this

00:39:40,560 --> 00:39:44,320
talk

00:39:41,280 --> 00:39:46,400
and different examples

00:39:44,320 --> 00:39:47,599
you can see how different number of

00:39:46,400 --> 00:39:51,520
developers

00:39:47,599 --> 00:39:54,720
uh leads to different solutions

00:39:51,520 --> 00:39:54,720
but at the same time

00:39:54,880 --> 00:39:59,680
a lot of things are very similar uh like

00:39:57,520 --> 00:40:03,200
operational concerns are

00:39:59,680 --> 00:40:04,960
very similar both uh um everyone needs

00:40:03,200 --> 00:40:08,240
uh fuses early consolation

00:40:04,960 --> 00:40:09,119
concurrency controls uh everyone needs

00:40:08,240 --> 00:40:11,839
uh

00:40:09,119 --> 00:40:13,119
the safe deployment strategy with a

00:40:11,839 --> 00:40:16,720
two-step deploy

00:40:13,119 --> 00:40:19,920
to uh to avoid

00:40:16,720 --> 00:40:21,599
losing jobs everyone needs scalable and

00:40:19,920 --> 00:40:24,400
durable

00:40:21,599 --> 00:40:25,520
data storage for for jobs either it's uh

00:40:24,400 --> 00:40:29,119
redis that you manage

00:40:25,520 --> 00:40:31,040
yourself or redis that the uh

00:40:29,119 --> 00:40:33,040
your hosting manages for you either

00:40:31,040 --> 00:40:36,839
that's sqs

00:40:33,040 --> 00:40:39,040
and uh all the knobs and real-time

00:40:36,839 --> 00:40:41,280
controls

00:40:39,040 --> 00:40:42,640
we both need them yeah and i think this

00:40:41,280 --> 00:40:45,280
is actually something that

00:40:42,640 --> 00:40:46,000
a lot of those message brokers could

00:40:45,280 --> 00:40:47,839
learn from

00:40:46,000 --> 00:40:49,599
sidekick is that the sidekick was a

00:40:47,839 --> 00:40:50,240
little was was kind of pioneering in

00:40:49,599 --> 00:40:52,160
that regard

00:40:50,240 --> 00:40:53,839
that they ship a an application which

00:40:52,160 --> 00:40:54,400
you can use to manipulate your job

00:40:53,839 --> 00:40:56,160
queues

00:40:54,400 --> 00:40:58,079
uh out of the box you just have to

00:40:56,160 --> 00:41:01,119
install it into your application

00:40:58,079 --> 00:41:02,319
but we can see this uh becoming more and

00:41:01,119 --> 00:41:04,800
more of a subject

00:41:02,319 --> 00:41:06,000
uh in the coming um in the coming years

00:41:04,800 --> 00:41:08,319
or months

00:41:06,000 --> 00:41:10,160
like real time controlling your loads

00:41:08,319 --> 00:41:11,839
and the settings of your job execution

00:41:10,160 --> 00:41:13,280
in real time is certainly going to be

00:41:11,839 --> 00:41:14,720
something that's going to become more

00:41:13,280 --> 00:41:17,119
popular

00:41:14,720 --> 00:41:18,839
and uh you know you don't need all of

00:41:17,119 --> 00:41:20,000
the above that we've just listed right

00:41:18,839 --> 00:41:22,480
here

00:41:20,000 --> 00:41:23,280
yeah we don't want the audience to get

00:41:22,480 --> 00:41:26,240
overwhelmed

00:41:23,280 --> 00:41:28,560
overwhelmed of of oh this is so many

00:41:26,240 --> 00:41:31,920
tools that i now need to to develop

00:41:28,560 --> 00:41:35,119
and adopt you don't need all of this

00:41:31,920 --> 00:41:38,160
but you might need uh some of this

00:41:35,119 --> 00:41:38,880
and don't think that we just all figured

00:41:38,160 --> 00:41:42,319
it out

00:41:38,880 --> 00:41:45,040
every two that we mentioned today

00:41:42,319 --> 00:41:46,400
came out of an incident or some kind of

00:41:45,040 --> 00:41:49,119
terrible

00:41:46,400 --> 00:41:49,920
thing that happened uh in in one of our

00:41:49,119 --> 00:41:53,280
apps

00:41:49,920 --> 00:41:55,520
that led us to come up with some safety

00:41:53,280 --> 00:41:58,880
mechanisms to to protect from it

00:41:55,520 --> 00:41:59,760
so it's it's years and years of learning

00:41:58,880 --> 00:42:02,880
from

00:41:59,760 --> 00:42:06,319
our mistakes so hopefully

00:42:02,880 --> 00:42:07,040
you can use our talk today as a cheat

00:42:06,319 --> 00:42:10,240
sheet

00:42:07,040 --> 00:42:12,560
uh learn uh from our mistakes and

00:42:10,240 --> 00:42:13,680
do some exciting stuff with background

00:42:12,560 --> 00:42:16,800
jobs

00:42:13,680 --> 00:42:18,800
yes and now uh by means of

00:42:16,800 --> 00:42:21,040
amazing video technology we're going to

00:42:18,800 --> 00:42:22,560
jump back into real time space with you

00:42:21,040 --> 00:42:24,240
and we're going to be happy to take any

00:42:22,560 --> 00:42:26,560
questions

00:42:24,240 --> 00:42:27,440
thank you thanks everyone for uh

00:42:26,560 --> 00:42:30,720
listening

00:42:27,440 --> 00:42:32,720
thanks everyone hi there

00:42:30,720 --> 00:42:36,720
thank you so much to the both of you

00:42:32,720 --> 00:42:39,440
that was absolutely wonderful

00:42:36,720 --> 00:42:41,040
so we are coming on pretty close to our

00:42:39,440 --> 00:42:44,160
to the time slot for our

00:42:41,040 --> 00:42:47,040
panel discussion so i don't know do we

00:42:44,160 --> 00:42:48,960
have time for a quick question writer

00:42:47,040 --> 00:42:52,400
um i think we're gonna go straight to

00:42:48,960 --> 00:42:52,400

YouTube URL: https://www.youtube.com/watch?v=aEVVbFn0_A4


