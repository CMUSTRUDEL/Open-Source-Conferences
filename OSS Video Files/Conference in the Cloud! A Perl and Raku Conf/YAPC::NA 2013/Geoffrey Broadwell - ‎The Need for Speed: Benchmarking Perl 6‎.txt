Title: Geoffrey Broadwell - ‎The Need for Speed: Benchmarking Perl 6‎
Publication date: 2013-08-20
Playlist: YAPC::NA 2013
Description: 
	Comparison of the various Perl 6-related implementations and VMs, using microbenchmarks attempting to measure very small runtimes of particular features (such as invocation, taking closures, passing arguments, boxing, compilation, coercion, aggregate access/storage, lexical access/storage, unicode property lookup, regexes, etc). Also microbenchmarks of the usual "toy" programs in Perl 6 versus several other languages/environments. Discussion of general measurement and optimization strategies.
Captions: 
	00:00:00,000 --> 00:00:07,710
can everybody hear me yep good okay I'm

00:00:05,819 --> 00:00:09,840
running a little bit late I time this

00:00:07,710 --> 00:00:11,700
for 19 and a half minutes and then added

00:00:09,840 --> 00:00:13,290
a couple of slides so I'm going to go a

00:00:11,700 --> 00:00:19,080
little bit quicker than i had in

00:00:13,290 --> 00:00:21,359
practice so let's see here this one the

00:00:19,080 --> 00:00:25,859
talk is the need for speed benchmarking

00:00:21,359 --> 00:00:29,660
Perl 6 but you know but it's not going

00:00:25,859 --> 00:00:29,660
to the next slide if I can't tell it to

00:00:29,929 --> 00:00:35,040
it's really benchmarking the Pearl

00:00:32,189 --> 00:00:37,500
family it's not just Perl 6 it's n QP

00:00:35,040 --> 00:00:40,739
it's pearl fives and so forth I

00:00:37,500 --> 00:00:43,980
absolutely love pearl six and i really

00:00:40,739 --> 00:00:46,860
want to use it at my day job and not

00:00:43,980 --> 00:00:48,329
just in secret on little things to do

00:00:46,860 --> 00:00:49,739
this i really need pearl sex to be

00:00:48,329 --> 00:00:52,199
production ready if i can sell it to my

00:00:49,739 --> 00:00:54,030
bosses it needs to be production-ready

00:00:52,199 --> 00:00:58,739
in some way but you know what exactly

00:00:54,030 --> 00:01:01,350
does that mean masak says we need

00:00:58,739 --> 00:01:04,320
features we need documentation we need

00:01:01,350 --> 00:01:07,350
concurrency need Sipan access we need

00:01:04,320 --> 00:01:09,450
speed my take on these is features i

00:01:07,350 --> 00:01:11,430
agree with masakan this we mostly have

00:01:09,450 --> 00:01:12,810
them there's a few bugs a few missing

00:01:11,430 --> 00:01:15,810
things but mostly we have the features

00:01:12,810 --> 00:01:20,810
we need documentation we certainly have

00:01:15,810 --> 00:01:24,710
some but we need more yes well but still

00:01:20,810 --> 00:01:27,420
concurrency I'm my personal use cases

00:01:24,710 --> 00:01:30,570
sockets are fine for now I work with our

00:01:27,420 --> 00:01:34,320
pcs all the time both at my previous job

00:01:30,570 --> 00:01:36,390
and now it's the very our pc based

00:01:34,320 --> 00:01:39,810
organization so it's fine for me to not

00:01:36,390 --> 00:01:41,790
worry about the parallelism that that

00:01:39,810 --> 00:01:45,450
Patrick was just talking about the last

00:01:41,790 --> 00:01:47,579
class I just need sockets for now Sipan

00:01:45,450 --> 00:01:49,020
working on that my talk on Monday

00:01:47,579 --> 00:01:50,939
discussed some of the stuff that we were

00:01:49,020 --> 00:01:54,149
doing to try and get Sipan connected

00:01:50,939 --> 00:01:55,619
with pearl fought with perl 6 the speed

00:01:54,149 --> 00:02:01,079
problem that's the thing that's killing

00:01:55,619 --> 00:02:02,640
me it's slow Rikuo is slow and that's a

00:02:01,079 --> 00:02:05,939
problem for me because I often have to

00:02:02,640 --> 00:02:08,550
deal with relatively big sets so the

00:02:05,939 --> 00:02:10,770
speed problem you know to be sure before

00:02:08,550 --> 00:02:12,900
i go on about this there have been some

00:02:10,770 --> 00:02:16,349
big wins already

00:02:12,900 --> 00:02:18,870
Patrick Jonathan heck all of hash / 06

00:02:16,349 --> 00:02:20,250
you guys have done great you've made

00:02:18,870 --> 00:02:24,360
some big improvements but there's

00:02:20,250 --> 00:02:27,060
clearly a long ways to go so how fast is

00:02:24,360 --> 00:02:28,829
fast enough how do we find the worst

00:02:27,060 --> 00:02:30,599
bottlenecks first so we can knock those

00:02:28,829 --> 00:02:32,129
out and get you know the things

00:02:30,599 --> 00:02:33,959
successively closer so that we don't

00:02:32,129 --> 00:02:36,569
have big gotchas that are slowing us

00:02:33,959 --> 00:02:39,659
down when we hit a particular thing well

00:02:36,569 --> 00:02:41,459
my approach was hick Perl 5 as our gold

00:02:39,659 --> 00:02:45,090
standard everybody agrees that it's a

00:02:41,459 --> 00:02:46,920
fast scripting language or o dynamic

00:02:45,090 --> 00:02:50,340
language let's let's pick that as our

00:02:46,920 --> 00:02:52,560
gold standard we can do relatively good

00:02:50,340 --> 00:02:54,599
benchmarking against it because the

00:02:52,560 --> 00:02:55,920
operations of Perl 6 and pro 5 are

00:02:54,599 --> 00:02:58,409
relatively parallel it's easy to

00:02:55,920 --> 00:03:01,319
translate so I pick some thresholds to

00:02:58,409 --> 00:03:02,970
be if it's no more than twice as slow as

00:03:01,319 --> 00:03:05,370
pro 5 that's actually pretty good you

00:03:02,970 --> 00:03:07,049
know I think for a lot of the use cases

00:03:05,370 --> 00:03:11,389
people would pick the programmer

00:03:07,049 --> 00:03:15,599
productivity over a few percent faster

00:03:11,389 --> 00:03:18,269
if they could get more stuff done uh

00:03:15,599 --> 00:03:20,730
less than an order of magnitude okay

00:03:18,269 --> 00:03:22,590
that's okay it's not great but for some

00:03:20,730 --> 00:03:24,389
use cases it's acceptable so that's okay

00:03:22,590 --> 00:03:26,220
but otherwise we're just going to call

00:03:24,389 --> 00:03:28,129
it bad and then we're going to bench

00:03:26,220 --> 00:03:31,769
market then CH mark the heck out of it

00:03:28,129 --> 00:03:33,980
but there are several Perl 6 compilers

00:03:31,769 --> 00:03:36,930
some of which have multiple backends and

00:03:33,980 --> 00:03:40,650
we want to compare across the different

00:03:36,930 --> 00:03:42,419
languages pro 5 and QP / 06 we want to

00:03:40,650 --> 00:03:44,370
compare against the different compilers

00:03:42,419 --> 00:03:46,290
we want to compare different releases

00:03:44,370 --> 00:03:48,540
the compiler see if we're getting better

00:03:46,290 --> 00:03:50,639
if we're regressing where we're having

00:03:48,540 --> 00:03:53,250
problems so and so forth and certainly

00:03:50,639 --> 00:03:58,799
we want to test against the backends is

00:03:53,250 --> 00:04:03,870
it faster on parrot or JavaScript or or

00:03:58,799 --> 00:04:07,049
JVM or more vm or what so cloning copies

00:04:03,870 --> 00:04:09,349
for all these combinations would take a

00:04:07,049 --> 00:04:11,310
lot of bandwidth and time let alone

00:04:09,349 --> 00:04:13,379
duplicated effort every time you want to

00:04:11,310 --> 00:04:14,940
keep the clones up-to-date so every time

00:04:13,379 --> 00:04:16,139
you decided to fetch and you had all

00:04:14,940 --> 00:04:17,130
these different combinations you'd be

00:04:16,139 --> 00:04:20,549
fetching a whole bunch of duplicates

00:04:17,130 --> 00:04:21,930
stuff and if you just decided okay i

00:04:20,549 --> 00:04:24,450
can't do that i'm going to have one

00:04:21,930 --> 00:04:26,340
clone for each compiler that means it's

00:04:24,450 --> 00:04:29,730
kind of hard to do cross version or

00:04:26,340 --> 00:04:31,230
back in comparison all at once between

00:04:29,730 --> 00:04:33,750
each benchmark run you'd have to clean

00:04:31,230 --> 00:04:36,600
up check out a new version build it from

00:04:33,750 --> 00:04:38,639
scratch then try it again trust me that

00:04:36,600 --> 00:04:40,320
takes a while especially if your

00:04:38,639 --> 00:04:43,020
benchmark suite takes a while by itself

00:04:40,320 --> 00:04:45,270
but a lot of our compilers take a long

00:04:43,020 --> 00:04:49,250
time to compile and so that step is just

00:04:45,270 --> 00:04:52,139
owners so my solution was Perl 6 bench

00:04:49,250 --> 00:04:54,090
it's plumbing the time all and analyze

00:04:52,139 --> 00:04:56,280
scripts are written in perl 5 for speed

00:04:54,090 --> 00:04:59,370
and for consistent data so that when i

00:04:56,280 --> 00:05:01,260
do timings I know that problems with the

00:04:59,370 --> 00:05:04,380
script itself aren't causing the timing

00:05:01,260 --> 00:05:06,210
fluctuations and the porcelain the the

00:05:04,380 --> 00:05:10,020
easy-to-use interface taken from the get

00:05:06,210 --> 00:05:12,360
world is is bench bring in products

00:05:10,020 --> 00:05:17,160
because it's fun I want to write the

00:05:12,360 --> 00:05:19,410
porcelain in Perl 6 so it clones one

00:05:17,160 --> 00:05:21,990
mirror full of each component across the

00:05:19,410 --> 00:05:23,160
network use do bench set up it does a

00:05:21,990 --> 00:05:24,750
whole bunch of cloning this is where

00:05:23,160 --> 00:05:26,940
your major network traffic happens

00:05:24,750 --> 00:05:29,190
clones the heck out of things you do a

00:05:26,940 --> 00:05:31,020
list components and you'll see that you

00:05:29,190 --> 00:05:32,880
end up with each component separately

00:05:31,020 --> 00:05:35,310
cloned by itself Nick and it does a

00:05:32,880 --> 00:05:38,400
mirror clone so it's made now a clone of

00:05:35,310 --> 00:05:39,900
each one of these in a mirror state so

00:05:38,400 --> 00:05:42,389
that it's easy to make local clones and

00:05:39,900 --> 00:05:43,770
in fact that's exactly oh I forgot this

00:05:42,389 --> 00:05:45,360
is a quick digression this is one of the

00:05:43,770 --> 00:05:47,340
added slides because a few people asked

00:05:45,360 --> 00:05:50,490
me this that hadn't gone to other Perl 6

00:05:47,340 --> 00:05:52,200
talks so what's what here of these

00:05:50,490 --> 00:05:55,169
components several of them are in the

00:05:52,200 --> 00:05:57,210
Rikuo stack rokudo is Perl 6 and I'm

00:05:55,169 --> 00:05:58,169
going to say it's Perl 6 on n QP because

00:05:57,210 --> 00:06:01,950
that's kind of where we want to be

00:05:58,169 --> 00:06:03,990
anyway n QP the one that I just listed n

00:06:01,950 --> 00:06:06,180
QP is the original it's not quite pearl

00:06:03,990 --> 00:06:08,430
on parrot and then of course there's the

00:06:06,180 --> 00:06:11,700
JavaScript back end the JVM back end

00:06:08,430 --> 00:06:15,169
there's then underneath the n QP layers

00:06:11,700 --> 00:06:18,360
there's parrot and more vm as as active

00:06:15,169 --> 00:06:22,200
VMs for the JVM i'm actually just using

00:06:18,360 --> 00:06:25,200
the system vm for these tests because it

00:06:22,200 --> 00:06:26,820
pain and then we've got some of the

00:06:25,200 --> 00:06:31,020
other compilers we've got nietzsche

00:06:26,820 --> 00:06:34,530
which is Perl 6 on mono net / leto which

00:06:31,020 --> 00:06:37,110
is both pro 5 and 6 on Perl 5 MJS and

00:06:34,530 --> 00:06:38,780
etc and then of course pro 5 which is

00:06:37,110 --> 00:06:43,100
actually the standard Perl 5

00:06:38,780 --> 00:06:45,410
actually cloned the master repo okay so

00:06:43,100 --> 00:06:48,560
it makes local clones as needed you just

00:06:45,410 --> 00:06:50,990
ask it to extract and you say okay from

00:06:48,560 --> 00:06:53,120
the pearl five I want to pull this tag

00:06:50,990 --> 00:06:55,250
from n QP I want to pull this tag from

00:06:53,120 --> 00:06:57,410
akuto i want to pull this branch it

00:06:55,250 --> 00:07:00,020
extracts the mount if i list my check

00:06:57,410 --> 00:07:01,850
outs i actually get more than just that

00:07:00,020 --> 00:07:03,440
but you'll notice that the extra ones

00:07:01,850 --> 00:07:05,389
are ones that are just named the same

00:07:03,440 --> 00:07:08,540
thing as the component and what this

00:07:05,389 --> 00:07:10,760
basically is is a check out of the head

00:07:08,540 --> 00:07:12,980
of whatever is the default branch so

00:07:10,760 --> 00:07:15,380
you'll notice down here rokudo nam and

00:07:12,980 --> 00:07:17,060
Rikuo Rikuo are listed is the same thing

00:07:15,380 --> 00:07:19,790
because in fact that's the default

00:07:17,060 --> 00:07:22,520
branch on rokudo that way you always can

00:07:19,790 --> 00:07:25,010
see what the current head revision is

00:07:22,520 --> 00:07:26,540
and you can always compare any version

00:07:25,010 --> 00:07:30,410
that you've checked out against what's

00:07:26,540 --> 00:07:32,300
the what's the current head so it knows

00:07:30,410 --> 00:07:34,400
how to keep all this stuff up to date

00:07:32,300 --> 00:07:36,800
and with a single command by updating

00:07:34,400 --> 00:07:38,810
the mirror first then the non tag

00:07:36,800 --> 00:07:40,040
checkouts because there's no point in

00:07:38,810 --> 00:07:41,930
updating the tags unless you've got

00:07:40,040 --> 00:07:46,460
problems with people moving tags around

00:07:41,930 --> 00:07:48,440
the repo which is just that so in here

00:07:46,460 --> 00:07:50,210
you do bench fetch it let's say it

00:07:48,440 --> 00:07:52,760
starts on nietzsche it goes fat she goes

00:07:50,210 --> 00:07:55,010
okay here's the mirror the dot get it

00:07:52,760 --> 00:07:58,970
pulls the fetches data into the mirror

00:07:55,010 --> 00:08:01,039
it does the the nietzsche fetch MV 24

00:07:58,970 --> 00:08:02,990
which is a tag that I'd pulled out on my

00:08:01,039 --> 00:08:05,060
local system and then it does the pull

00:08:02,990 --> 00:08:06,710
it does the actual merge if necessary

00:08:05,060 --> 00:08:09,470
and the only one here that wasn't the

00:08:06,710 --> 00:08:10,669
tag was the the head revision and in

00:08:09,470 --> 00:08:12,080
this case it was already up to date

00:08:10,669 --> 00:08:14,000
because I just done this recently but

00:08:12,080 --> 00:08:15,950
then it goes on and continues with n QP

00:08:14,000 --> 00:08:17,419
and so on so forth this will take a few

00:08:15,950 --> 00:08:20,419
minutes because it's only doing Delta's

00:08:17,419 --> 00:08:22,729
across the network to the clones and

00:08:20,419 --> 00:08:25,520
then it's doing local checkouts and

00:08:22,729 --> 00:08:29,780
those are really fast to even to fetch

00:08:25,520 --> 00:08:31,310
new stuff ok so you can build each of

00:08:29,780 --> 00:08:32,900
these multiple checkouts in sequence so

00:08:31,310 --> 00:08:35,539
you don't have to sit there and manually

00:08:32,900 --> 00:08:36,560
do each one yourself you can say ok I

00:08:35,539 --> 00:08:38,630
want to build I'm going to build

00:08:36,560 --> 00:08:41,900
everything that I've checked out of n QP

00:08:38,630 --> 00:08:44,330
everything out of n QP jbm and 4 / 5 I

00:08:41,900 --> 00:08:47,360
want to do this tag Recodo I want to do

00:08:44,330 --> 00:08:49,850
these two tags in this branch go have a

00:08:47,360 --> 00:08:51,080
fine meal this will take a while because

00:08:49,850 --> 00:08:52,220
it does them in

00:08:51,080 --> 00:08:54,200
once and there's a reason it doesn't

00:08:52,220 --> 00:08:57,410
sequence it's because some of these have

00:08:54,200 --> 00:08:59,780
really large require build requirements

00:08:57,410 --> 00:09:02,060
that the memory that's used to build

00:08:59,780 --> 00:09:04,010
them is very large you would oom

00:09:02,060 --> 00:09:05,720
yourself if you try to do like three

00:09:04,010 --> 00:09:08,540
builds of rokudo at once and you didn't

00:09:05,720 --> 00:09:11,150
have a monster box so it does these in

00:09:08,540 --> 00:09:14,300
sequence make sure that it's using you

00:09:11,150 --> 00:09:16,850
know the the minimum memory requirements

00:09:14,300 --> 00:09:20,120
and then you just wait for a while have

00:09:16,850 --> 00:09:23,720
fun and oh and yes it will prevent

00:09:20,120 --> 00:09:26,030
Recodo n QP and NQ PCC that's the cross

00:09:23,720 --> 00:09:28,070
compiler that's the the current version

00:09:26,030 --> 00:09:30,530
of n QP that we have to use for more vm

00:09:28,070 --> 00:09:32,330
because it's not bootstrap yet each of

00:09:30,530 --> 00:09:33,950
them are kept from cloning their own

00:09:32,330 --> 00:09:37,160
dependencies because in their build

00:09:33,950 --> 00:09:38,990
cycle they want to do like gin parrot or

00:09:37,160 --> 00:09:41,210
something that wants to pull parrot and

00:09:38,990 --> 00:09:44,000
build that as well it wants to make a

00:09:41,210 --> 00:09:45,860
clone but aha during the thing after we

00:09:44,000 --> 00:09:47,720
do our clean up during the to prepare

00:09:45,860 --> 00:09:51,110
for the build we immediately do a local

00:09:47,720 --> 00:09:53,900
clone forcing it to to take local clones

00:09:51,110 --> 00:09:55,100
of our master mirror repose and then

00:09:53,900 --> 00:09:58,370
lets it Jen parrot and so on and so

00:09:55,100 --> 00:10:00,080
forth so once you've done a setup or a

00:09:58,370 --> 00:10:02,870
fetch if it's been a while since the

00:10:00,080 --> 00:10:04,640
last time the thing can stay completely

00:10:02,870 --> 00:10:06,980
off the network it will do all of its

00:10:04,640 --> 00:10:10,820
stuff locally with the one exception of

00:10:06,980 --> 00:10:13,820
nature which which wants to pull down a

00:10:10,820 --> 00:10:15,410
tarball when you do different tags it

00:10:13,820 --> 00:10:17,030
needs an older version of itself to do a

00:10:15,410 --> 00:10:19,430
newer version and we found that there

00:10:17,030 --> 00:10:21,880
were so many differences there that it

00:10:19,430 --> 00:10:24,410
wouldn't have saved us network bandwidth

00:10:21,880 --> 00:10:25,790
okay so now that you've got all this

00:10:24,410 --> 00:10:28,640
stuff built how do you go about

00:10:25,790 --> 00:10:30,740
benchmarking well you gather some

00:10:28,640 --> 00:10:32,390
timings if you just say bench time it

00:10:30,740 --> 00:10:35,900
will time every compiler you've built

00:10:32,390 --> 00:10:37,790
against every test if you say only

00:10:35,900 --> 00:10:39,170
particular ones you can say okay I want

00:10:37,790 --> 00:10:42,620
only these checkouts only particular

00:10:39,170 --> 00:10:45,080
compiler birds or I want these these

00:10:42,620 --> 00:10:47,930
things tested only against these two

00:10:45,080 --> 00:10:49,840
tests or any number of them you just say

00:10:47,930 --> 00:10:51,980
certain tests and you can go on with it

00:10:49,840 --> 00:10:53,660
when you want to analyze the results

00:10:51,980 --> 00:10:56,630
that you've just created from of the

00:10:53,660 --> 00:10:58,730
timing passes you can compare them just

00:10:56,630 --> 00:11:00,950
bench compare and it will ignore startup

00:10:58,730 --> 00:11:02,750
and compile time by default you can turn

00:11:00,950 --> 00:11:03,290
this off if you want to see the effects

00:11:02,750 --> 00:11:06,320
that

00:11:03,290 --> 00:11:09,139
compile-time or startup time has on the

00:11:06,320 --> 00:11:10,699
overall performance comparisons but by

00:11:09,139 --> 00:11:11,949
default it'll ignore them because most

00:11:10,699 --> 00:11:14,540
of the time were actually compared

00:11:11,949 --> 00:11:16,940
worried about the runtime performance of

00:11:14,540 --> 00:11:20,930
these and it'll just output the results

00:11:16,940 --> 00:11:23,120
to screen it's just text so you can say

00:11:20,930 --> 00:11:25,819
okay I want to only compare timings from

00:11:23,120 --> 00:11:28,069
just this compiler for example I want to

00:11:25,819 --> 00:11:29,660
only see the different bill the

00:11:28,069 --> 00:11:31,279
different builds that I've done infra

00:11:29,660 --> 00:11:33,199
Kudo I want to see how it's changing

00:11:31,279 --> 00:11:35,899
over time and if it's regressed or

00:11:33,199 --> 00:11:37,819
anything like that if you don't like the

00:11:35,899 --> 00:11:40,790
colors because by default it's colorized

00:11:37,819 --> 00:11:43,160
you can just turn that off if you want

00:11:40,790 --> 00:11:45,350
to take all the timing data do a

00:11:43,160 --> 00:11:48,139
comparison and then merge that

00:11:45,350 --> 00:11:50,240
information into a single JSON file all

00:11:48,139 --> 00:11:52,069
the timing data is saved as JSON files

00:11:50,240 --> 00:11:53,779
but if you want to have it as a single

00:11:52,069 --> 00:11:56,750
file you can send somebody so you can

00:11:53,779 --> 00:11:58,430
say here's my timings and here's the

00:11:56,750 --> 00:12:00,589
comparison I did here take a look at it

00:11:58,430 --> 00:12:03,170
if you just say that you're going to

00:12:00,589 --> 00:12:04,730
output into a dot JSON file it

00:12:03,170 --> 00:12:06,199
recognizes that and goes instead of

00:12:04,730 --> 00:12:07,550
printing the screen print to the merge

00:12:06,199 --> 00:12:10,850
JSON file and now you've got something

00:12:07,550 --> 00:12:14,209
you can email somebody okay you can also

00:12:10,850 --> 00:12:16,279
output to HTML as a table similar format

00:12:14,209 --> 00:12:18,529
to the screen format but producing HTML

00:12:16,279 --> 00:12:20,630
if you say the outfile HTML there you go

00:12:18,529 --> 00:12:24,850
and here I've said I'm compiling I'm

00:12:20,630 --> 00:12:26,870
comparing only particular timing runs

00:12:24,850 --> 00:12:28,970
now here's where it gets interesting you

00:12:26,870 --> 00:12:31,459
can actually plug them as well if you

00:12:28,970 --> 00:12:34,160
say that the output format is HTML plot

00:12:31,459 --> 00:12:36,470
then it will produce an HTML file that

00:12:34,160 --> 00:12:39,350
uses the JQ plot library to produce a

00:12:36,470 --> 00:12:41,540
whole bunch of plots that tell you how a

00:12:39,350 --> 00:12:43,699
certain benchmarks scale as you pretty

00:12:41,540 --> 00:12:47,920
as you add more load as you say like do

00:12:43,699 --> 00:12:50,329
more iterations of this or do a deeper

00:12:47,920 --> 00:12:52,250
man or boy test or something like that

00:12:50,329 --> 00:12:54,589
it will then produce a plot of the

00:12:52,250 --> 00:12:56,360
scaled output for things that for tests

00:12:54,589 --> 00:12:58,310
that can't scale it will just produce a

00:12:56,360 --> 00:13:01,550
bar chart that shows the comparison

00:12:58,310 --> 00:13:04,970
between each of them so here's a good

00:13:01,550 --> 00:13:06,649
sample this is the while air a set so

00:13:04,970 --> 00:13:08,779
it's doing a while loop and setting

00:13:06,649 --> 00:13:11,389
entries in an array I was just doing

00:13:08,779 --> 00:13:13,990
this and seeing like okay as you asked

00:13:11,389 --> 00:13:16,250
it to produce more iterations

00:13:13,990 --> 00:13:19,340
more iterations the while loop in a

00:13:16,250 --> 00:13:21,530
single test run how does the iterations

00:13:19,340 --> 00:13:23,780
per second that are measured turn out

00:13:21,530 --> 00:13:25,430
and you can see some noise on the left

00:13:23,780 --> 00:13:27,560
hand side as there's little timing

00:13:25,430 --> 00:13:29,780
variations and because i'm subtracting

00:13:27,560 --> 00:13:32,000
out so many different things the startup

00:13:29,780 --> 00:13:33,650
time the compile time sometimes there's

00:13:32,000 --> 00:13:35,720
little glitches where it will end up

00:13:33,650 --> 00:13:37,130
being a little bit off but mostly you

00:13:35,720 --> 00:13:38,960
get some noisy stuff and then it settles

00:13:37,130 --> 00:13:42,160
down and you start to see patterns here

00:13:38,960 --> 00:13:44,390
well what kind of patterns are we seeing

00:13:42,160 --> 00:13:47,810
first of all I should tell you this is a

00:13:44,390 --> 00:13:51,380
log-log plot okay so if you look at this

00:13:47,810 --> 00:13:54,320
thing you've got a log of the the work

00:13:51,380 --> 00:13:57,110
to be done here and the log of the the

00:13:54,320 --> 00:13:58,220
results here so when you get to a happy

00:13:57,110 --> 00:14:01,250
place it's going to be mostly a

00:13:58,220 --> 00:14:06,170
horizontal line across here same a

00:14:01,250 --> 00:14:08,420
throughput for increasing load ok so the

00:14:06,170 --> 00:14:09,980
ascending portion as the lines are going

00:14:08,420 --> 00:14:11,930
up on the left hand side the graph is

00:14:09,980 --> 00:14:14,150
when overhead or warm up that I could

00:14:11,930 --> 00:14:16,820
not subtract out is still dominating the

00:14:14,150 --> 00:14:19,090
jvm is famous for this the JVM has a

00:14:16,820 --> 00:14:22,550
period in which it is warming up it's

00:14:19,090 --> 00:14:25,220
it's jet and so there is a period where

00:14:22,550 --> 00:14:28,220
you'll get a domination of that warm-up

00:14:25,220 --> 00:14:29,450
effect the horizontal portion as I said

00:14:28,220 --> 00:14:30,950
it's about as fast as it's going to get

00:14:29,450 --> 00:14:33,050
hopefully you'll get nice steady

00:14:30,950 --> 00:14:35,660
thorough throughput above a certain load

00:14:33,050 --> 00:14:37,760
and the descending product of a portion

00:14:35,660 --> 00:14:39,920
is when you have some problems scaling

00:14:37,760 --> 00:14:42,650
up so here you see that for this

00:14:39,920 --> 00:14:44,690
particular test something was happening

00:14:42,650 --> 00:14:47,810
up here that eventually it would reach a

00:14:44,690 --> 00:14:49,160
peak and it would start to slow down and

00:14:47,810 --> 00:14:50,690
the rightmost point that you see on

00:14:49,160 --> 00:14:52,970
these graphs each one of these lines has

00:14:50,690 --> 00:14:55,460
a rightmost point that's when it ran

00:14:52,970 --> 00:14:58,190
over the time limit because for scalable

00:14:55,460 --> 00:14:59,960
tests it determines a time limit and

00:14:58,190 --> 00:15:02,060
says I'm going to keep offering more

00:14:59,960 --> 00:15:04,850
load to it until it takes more than say

00:15:02,060 --> 00:15:06,530
five seconds to complete the test by the

00:15:04,850 --> 00:15:08,270
way those five seconds already have the

00:15:06,530 --> 00:15:09,740
startup and compile time subtracted so

00:15:08,270 --> 00:15:12,020
you don't need to worry that something

00:15:09,740 --> 00:15:13,550
that slows up really that starts up

00:15:12,020 --> 00:15:18,140
really slowly is going to affect that

00:15:13,550 --> 00:15:20,660
okay so here's a nearly ideal plot the

00:15:18,140 --> 00:15:23,510
while empty plot so this thing just is

00:15:20,660 --> 00:15:24,529
an empty while loop it's just doing an

00:15:23,510 --> 00:15:26,810
iteration counter

00:15:24,529 --> 00:15:28,310
and here you can see that you know once

00:15:26,810 --> 00:15:29,930
you get past the noise in the ascending

00:15:28,310 --> 00:15:32,749
portion here's what i was talking about

00:15:29,930 --> 00:15:35,089
of the slow warmup of the jvm past this

00:15:32,749 --> 00:15:36,709
point it gets a pretty steady state you

00:15:35,089 --> 00:15:40,370
have steady States on all of them all

00:15:36,709 --> 00:15:41,540
the way across here's the same test with

00:15:40,370 --> 00:15:42,769
native types and I'm going to flip back

00:15:41,540 --> 00:15:45,980
and forth so you can see the difference

00:15:42,769 --> 00:15:47,930
you'll see that one of these jumped up

00:15:45,980 --> 00:15:51,459
and one of them is missing well that's

00:15:47,930 --> 00:15:53,689
because Nietzsche doesn't support the

00:15:51,459 --> 00:15:56,689
referring to the native types here but

00:15:53,689 --> 00:15:58,610
jvm really loves it when loop iteration

00:15:56,689 --> 00:16:02,569
variables are native types it gets fully

00:15:58,610 --> 00:16:05,110
as fast as perl five so here's a case of

00:16:02,569 --> 00:16:09,529
a mild weakness that's in Perl 5 it

00:16:05,110 --> 00:16:12,050
slightly slows down okay so and since

00:16:09,529 --> 00:16:13,670
these are our two a doubling in between

00:16:12,050 --> 00:16:16,100
each of these if you look at this it's

00:16:13,670 --> 00:16:18,860
maybe three or four times slower than

00:16:16,100 --> 00:16:21,470
its peak value most of the other ones

00:16:18,860 --> 00:16:23,899
hit a straight or they get pretty close

00:16:21,470 --> 00:16:34,399
to it but there's a slight slowdown in

00:16:23,899 --> 00:16:37,370
Perl 5 ah yes I believe so okay so so

00:16:34,399 --> 00:16:39,199
here's a case where the tests scale kind

00:16:37,370 --> 00:16:41,750
of gets off kilter because this is a

00:16:39,199 --> 00:16:44,629
nonlinear test you see it says visit 2d

00:16:41,750 --> 00:16:47,059
indices so it's a nested while loop and

00:16:44,629 --> 00:16:49,579
scaling both the ins the inner loop and

00:16:47,059 --> 00:16:51,500
the outer loop and so you end up with

00:16:49,579 --> 00:16:53,569
something where you get diagonal lines

00:16:51,500 --> 00:16:54,920
down from the log log plot effect but

00:16:53,569 --> 00:16:57,019
you can still see the difference between

00:16:54,920 --> 00:16:59,809
them based on where they kind of are in

00:16:57,019 --> 00:17:01,670
the vertical ranking here and so this is

00:16:59,809 --> 00:17:03,920
a particular kind of test that scales

00:17:01,670 --> 00:17:06,140
like this the manor boy test does the

00:17:03,920 --> 00:17:08,030
same thing because as you increase the

00:17:06,140 --> 00:17:11,510
caper ammeter for the man or boy test it

00:17:08,030 --> 00:17:14,510
gets rapidly more work and you see it

00:17:11,510 --> 00:17:15,949
scale down the same way okay so so far

00:17:14,510 --> 00:17:18,860
these have all been my trip micro

00:17:15,949 --> 00:17:21,289
benchmarks the code is kept as close as

00:17:18,860 --> 00:17:23,510
possible to an exact translation between

00:17:21,289 --> 00:17:25,909
the languages that's relatively easy at

00:17:23,510 --> 00:17:28,700
the micro benchmarks scale but what

00:17:25,909 --> 00:17:30,049
about longer or more idiomatic code well

00:17:28,700 --> 00:17:32,059
I only have time to show you one of

00:17:30,049 --> 00:17:35,330
these but we're going to go with this

00:17:32,059 --> 00:17:37,309
one RC forest fire it's a simple to

00:17:35,330 --> 00:17:39,320
cellular automaton it simulates a

00:17:37,309 --> 00:17:40,730
growing forest with occasional forest

00:17:39,320 --> 00:17:42,289
fires I know it's a little hard to see

00:17:40,730 --> 00:17:44,330
on this projectors but there's your

00:17:42,289 --> 00:17:49,429
forest fire and here's another one down

00:17:44,330 --> 00:17:57,320
here so here's the differences and I'll

00:17:49,429 --> 00:17:59,539
answer your concern in a okay so so here

00:17:57,320 --> 00:18:01,760
we go here are the differences for these

00:17:59,539 --> 00:18:04,490
this is pearl the current pro/5 the May

00:18:01,760 --> 00:18:07,190
version and here's n QP g vm doing it

00:18:04,490 --> 00:18:10,909
and the standard n QP and then Nietzsche

00:18:07,190 --> 00:18:13,909
and Rikuo done here and these things

00:18:10,909 --> 00:18:15,440
this one is the frames requested for run

00:18:13,909 --> 00:18:17,149
how many cycles of the cellular

00:18:15,440 --> 00:18:20,000
automaton and this is how many frames

00:18:17,149 --> 00:18:21,470
per second we're getting out of it pearl

00:18:20,000 --> 00:18:23,899
five of course the fastest I actually

00:18:21,470 --> 00:18:25,789
checked on here if you if you do these

00:18:23,899 --> 00:18:27,529
plots live rather than on the projected

00:18:25,789 --> 00:18:30,830
version you can just roll over any data

00:18:27,529 --> 00:18:32,630
point and you can see its measured value

00:18:30,830 --> 00:18:34,970
and the comparison against the fastest

00:18:32,630 --> 00:18:37,100
and you see here that in this test MGP

00:18:34,970 --> 00:18:39,710
JVM is about two and a half times slower

00:18:37,100 --> 00:18:41,870
best this is not with native types i'm

00:18:39,710 --> 00:18:44,389
sorry i did not have time to to make a

00:18:41,870 --> 00:18:46,940
version of this test with native types n

00:18:44,389 --> 00:18:49,130
QP is about eight times slower at its

00:18:46,940 --> 00:18:53,120
best mark nature 45 and Rikuo slower

00:18:49,130 --> 00:18:54,620
than that so I use I want to use perl 6

00:18:53,120 --> 00:18:56,779
I want to use the full Perl 6 I don't

00:18:54,620 --> 00:18:59,029
want to be using n QP all day to do my

00:18:56,779 --> 00:19:00,740
work I want to use the full Ricou toe if

00:18:59,029 --> 00:19:04,730
it's slow if it's the one at the bottom

00:19:00,740 --> 00:19:07,279
of chart why am I so happy ok and it's

00:19:04,730 --> 00:19:09,470
because NQ peach a vm is already

00:19:07,279 --> 00:19:11,480
considerably faster than n QP parrot and

00:19:09,470 --> 00:19:12,830
in some cases that I've tested and that

00:19:11,480 --> 00:19:14,929
was just an example in one of those

00:19:12,830 --> 00:19:16,580
previous slides it's as fast as perl

00:19:14,929 --> 00:19:19,940
five sometimes actually gets a little

00:19:16,580 --> 00:19:23,630
bit faster it hasn't reached the make it

00:19:19,940 --> 00:19:26,179
fast stage ok it's still in the make it

00:19:23,630 --> 00:19:28,010
work make everything you know like fill

00:19:26,179 --> 00:19:30,260
in the gaps that we need for rokudo it

00:19:28,010 --> 00:19:34,429
hasn't been in the Jonathan goes crazy

00:19:30,260 --> 00:19:36,049
mode okay and I think that bodes very

00:19:34,429 --> 00:19:38,450
well for a kudos performance in the

00:19:36,049 --> 00:19:41,570
coming months the fact that Rikuo sits

00:19:38,450 --> 00:19:44,659
on top of n QP and n QP in some cases

00:19:41,570 --> 00:19:45,430
can be as fast as / 05 I see that as

00:19:44,659 --> 00:19:50,920
being

00:19:45,430 --> 00:19:52,600
really good news so you know clearly yes

00:19:50,920 --> 00:19:54,940
there's a long way to go to get

00:19:52,600 --> 00:19:56,410
everything pulled up but now we know

00:19:54,940 --> 00:20:00,460
where to go we can measure our progress

00:19:56,410 --> 00:20:02,470
and pull requests are welcome if you

00:20:00,460 --> 00:20:04,510
want to add more tests if you say hey I

00:20:02,470 --> 00:20:05,620
found this particularly slow operation

00:20:04,510 --> 00:20:09,130
and I would like to add it to the

00:20:05,620 --> 00:20:11,800
benchmark suite please do okay it under

00:20:09,130 --> 00:20:18,630
jeff be pearls expansion github talk to

00:20:11,800 --> 00:20:18,630
me on a hash Perl 6 and any questions

00:20:19,620 --> 00:20:39,820
yes no I don't I I set it up so that we

00:20:37,240 --> 00:20:44,040
could produce those but I haven't

00:20:39,820 --> 00:20:50,710
produced any of those yet partially

00:20:44,040 --> 00:20:52,480
that's a matter of Rikuo that before

00:20:50,710 --> 00:20:53,770
like during the benchmarking cycle over

00:20:52,480 --> 00:20:55,930
the last six months as I was slowly

00:20:53,770 --> 00:20:59,470
building this we discovered some things

00:20:55,930 --> 00:21:01,210
that Rikuo was doing particularly badly

00:20:59,470 --> 00:21:05,110
badly enough that it couldn't finish

00:21:01,210 --> 00:21:07,750
basic tests just from like it would slow

00:21:05,110 --> 00:21:10,390
down too much those were fixed so now

00:21:07,750 --> 00:21:12,430
recent stuff is pretty safe to benchmark

00:21:10,390 --> 00:21:14,050
we have no problems there but we can't

00:21:12,430 --> 00:21:15,910
go very far back before we run into

00:21:14,050 --> 00:21:19,240
there's parts of the test suite we can't

00:21:15,910 --> 00:21:22,630
complete but going forward I definitely

00:21:19,240 --> 00:21:25,270
want to be able to produce plots of a

00:21:22,630 --> 00:21:27,190
single compiler over time and in fact

00:21:25,270 --> 00:21:28,570
you know if you just did multiple check

00:21:27,190 --> 00:21:30,180
outs and built them and compare them

00:21:28,570 --> 00:21:34,170
that's pretty much you what you get

00:21:30,180 --> 00:21:34,170
anybody else yes

00:21:35,610 --> 00:21:43,539
question is would it make sense to add

00:21:37,929 --> 00:21:45,940
Rikuo star uh I suppose it might be

00:21:43,539 --> 00:21:49,960
useful to see at the various tags how r

00:21:45,940 --> 00:21:52,510
akuto is doing but i think at this point

00:21:49,960 --> 00:21:55,919
it's making more sense for us to just

00:21:52,510 --> 00:21:59,470
sear akuto at each at each monthly

00:21:55,919 --> 00:22:01,330
release cycle because really they're not

00:21:59,470 --> 00:22:03,100
changing the compiler when they may crew

00:22:01,330 --> 00:22:05,940
kudos star it's still Rikuo underneath

00:22:03,100 --> 00:22:08,700
and I'm not yet testing stuff in

00:22:05,940 --> 00:22:10,809
standard libraries I'm absolutely

00:22:08,700 --> 00:22:15,090
considering doing that but I haven't yet

00:22:10,809 --> 00:22:15,090
gotten to that stage any other questions

00:22:16,590 --> 00:22:32,130
great thank you guys very much oh sure

00:22:32,880 --> 00:22:39,159
his his concern is that I wasn't showing

00:22:37,210 --> 00:22:43,270
Recodo in its best light on the RC

00:22:39,159 --> 00:22:46,140
forest fire because I had when I did

00:22:43,270 --> 00:22:50,710
idiomatic I did it IAM attic in my mind

00:22:46,140 --> 00:22:52,210
which he said was stressing different

00:22:50,710 --> 00:22:53,950
data structures and different methods of

00:22:52,210 --> 00:22:56,200
doing things than were in Perl 5 and

00:22:53,950 --> 00:22:58,270
that wasn't an entirely fair comparison

00:22:56,200 --> 00:23:01,830
and also that I didn't have time to put

00:22:58,270 --> 00:23:04,510
in the native types into that test and

00:23:01,830 --> 00:23:05,890
when I was thinking about the the final

00:23:04,510 --> 00:23:08,049
thing this morning when I was working on

00:23:05,890 --> 00:23:11,860
the slide deck the the decision that I

00:23:08,049 --> 00:23:14,500
came to is my feeling at the end of this

00:23:11,860 --> 00:23:16,929
is one of hope that things are there's

00:23:14,500 --> 00:23:18,970
so much forward there and it doesn't

00:23:16,929 --> 00:23:21,400
matter that you know maybe Rikuo could

00:23:18,970 --> 00:23:22,900
have been twice as high as it was to me

00:23:21,400 --> 00:23:24,280
that's not the important part the

00:23:22,900 --> 00:23:26,190
important part is that the

00:23:24,280 --> 00:23:30,370
infrastructure underneath rokudo is

00:23:26,190 --> 00:23:32,650
doing quite well and now we just need to

00:23:30,370 --> 00:23:35,460
bring it up to to the level of n QP and

00:23:32,650 --> 00:23:40,200
I think we'll be in a great great place

00:23:35,460 --> 00:23:44,850
it's answer question yeah ok

00:23:40,200 --> 00:23:47,700
sure go for it the forest fire event we

00:23:44,850 --> 00:23:49,950
recruited it badly and I should also

00:23:47,700 --> 00:23:52,440
practice quit I found the benchmarking

00:23:49,950 --> 00:23:55,320
TNA advance copy is good thing it's

00:23:52,440 --> 00:24:00,419
incredible we will make such good use of

00:23:55,320 --> 00:24:02,940
this but the forest fire implementation

00:24:00,419 --> 00:24:05,909
406 is an object or animal and the

00:24:02,940 --> 00:24:07,710
winner profile is done themselves what

00:24:05,909 --> 00:24:10,260
would it look like that in profile oops

00:24:07,710 --> 00:24:13,169
and then we'll go to perform we like

00:24:10,260 --> 00:24:15,480
that it's a somewhat more apt comparison

00:24:13,169 --> 00:24:17,220
for somebody who plans to do object

00:24:15,480 --> 00:24:20,909
oriented programming which is one of the

00:24:17,220 --> 00:24:24,179
reasons why you would go with pro 64 you

00:24:20,909 --> 00:24:27,510
know so in all of the micro benchmarks

00:24:24,179 --> 00:24:30,090
you're testing profile in its best light

00:24:27,510 --> 00:24:32,039
and pro 6 in its were slightly

00:24:30,090 --> 00:24:37,260
compulsive has all the way up overhead

00:24:32,039 --> 00:24:38,580
of doing that but there's no more it's

00:24:37,260 --> 00:24:43,740
really more apt if you're talking about

00:24:38,580 --> 00:24:48,470
application just prepared for a wide

00:24:43,740 --> 00:24:48,470
enough let's see how slow

00:24:52,670 --> 00:25:05,250
but again that will change yeah I mean

00:24:56,760 --> 00:25:08,490
it's so easy it sounds like the ideal

00:25:05,250 --> 00:25:10,770
there would be to have very impolite

00:25:08,490 --> 00:25:28,500
right yes and that's exactly what we

00:25:10,770 --> 00:25:31,160
plan yeah yes sorry I should probably

00:25:28,500 --> 00:25:31,160

YouTube URL: https://www.youtube.com/watch?v=h5sSuL9OueE


