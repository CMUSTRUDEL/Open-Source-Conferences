Title: David Golden - "Real World Optimization"
Publication date: 2017-06-21
Playlist: TPC 2017 in DC
Description: 
	MongoDB is the #1 database that developers want to learn this year, according to the 2017 Stack Overflow developer survey. This full-day workshop mixes lecture and hands-on exercises to teach you how to use MongoDB with Perl, led by the author of the MongoDB Perl driver. We'll cover when to use MongoDB (and when not to!) and you'll leave the workshop knowing CRUD operations, indexing, aggregation pipelines, effective schema design, and more. Strong-beginner or better Perl skills recommended.

This tutorial requires a separate $99 ticket. 100% of workshop fees will be donated to The Perl Conference, courtesy of MongoDB.


David Golden wears many hats in the Perl community. In his day job, he works at MongoDB, where he maintains the MongoDB Perl and C++ drivers.
Captions: 
	00:00:00,000 --> 00:00:05,520
so hello everybody thank you for braving

00:00:02,310 --> 00:00:08,550
the humid outdoor curity my name is

00:00:05,520 --> 00:00:09,380
David Colvin I'm at MongoDB and this is

00:00:08,550 --> 00:00:13,469
to talk about some real-world

00:00:09,380 --> 00:00:15,660
optimization that I did there so I work

00:00:13,469 --> 00:00:17,609
at MongoDB and I'm kind of curious how

00:00:15,660 --> 00:00:21,210
many people have heard of MongoDB it's

00:00:17,609 --> 00:00:22,230
ok I'm ok everyone great fabulous how

00:00:21,210 --> 00:00:24,720
many people have actually worked with

00:00:22,230 --> 00:00:27,990
longer DB at any point in time you're

00:00:24,720 --> 00:00:32,460
more hands ok how many people use

00:00:27,990 --> 00:00:33,350
MongoDB in their day job one hand ok so

00:00:32,460 --> 00:00:35,520
I have some work to do

00:00:33,350 --> 00:00:37,110
fortunately this talk has almost nothing

00:00:35,520 --> 00:00:38,690
to do about MongoDB except that it's

00:00:37,110 --> 00:00:42,180
something that I happen to be working on

00:00:38,690 --> 00:00:45,000
so I'm responsible for a number of

00:00:42,180 --> 00:00:46,620
things at mommy-to-be one of them is the

00:00:45,000 --> 00:00:48,480
perl driver I'm also responsible for a

00:00:46,620 --> 00:00:50,010
couple of other things and with the

00:00:48,480 --> 00:00:51,690
obligatory I'm hiring at this time not

00:00:50,010 --> 00:00:53,399
just as long we D be hiring which I say

00:00:51,690 --> 00:00:56,579
every conference and talk but I'm

00:00:53,399 --> 00:00:58,109
personally hiring from my team it's in

00:00:56,579 --> 00:01:00,000
New York a lot of the work is

00:00:58,109 --> 00:01:01,469
predominantly around go and some of our

00:01:00,000 --> 00:01:03,149
tools that are written go but I would

00:01:01,469 --> 00:01:04,769
really really really love somebody with

00:01:03,149 --> 00:01:07,020
some Perl to help me with the

00:01:04,769 --> 00:01:07,979
programmers so if you're interested or

00:01:07,020 --> 00:01:10,860
you know someone who might be interested

00:01:07,979 --> 00:01:13,290
to come find me at the conference so

00:01:10,860 --> 00:01:14,700
with that out of the way on to the rest

00:01:13,290 --> 00:01:17,340
of the talk so this is the talk about

00:01:14,700 --> 00:01:19,110
the real world and real code based on

00:01:17,340 --> 00:01:21,479
some work that I did a couple years ago

00:01:19,110 --> 00:01:24,330
when I was rewriting a lot of the

00:01:21,479 --> 00:01:25,890
innards of the MongoDB full driver when

00:01:24,330 --> 00:01:28,710
I joined MongoDB about 3 and 1/2 years

00:01:25,890 --> 00:01:30,900
ago the current driver was V zero point

00:01:28,710 --> 00:01:32,850
stuff and this is what I now think about

00:01:30,900 --> 00:01:34,560
the legacy driver and I was writing the

00:01:32,850 --> 00:01:37,200
v1 deck stuff which is kind of the next

00:01:34,560 --> 00:01:39,570
generation that we have today and the

00:01:37,200 --> 00:01:40,799
real problem with the legacy driver was

00:01:39,570 --> 00:01:43,920
that among other things it was

00:01:40,799 --> 00:01:46,020
incredibly incredibly naive it just sort

00:01:43,920 --> 00:01:47,610
of assumed that you didn't have to check

00:01:46,020 --> 00:01:49,170
anything for errors right hey I'm going

00:01:47,610 --> 00:01:51,509
to put something on the on the network

00:01:49,170 --> 00:01:52,920
wire it will always succeed you'll never

00:01:51,509 --> 00:01:55,320
get an error putting anything on the

00:01:52,920 --> 00:01:56,670
wire no problem no error checks at all a

00:01:55,320 --> 00:01:59,670
lot of the networking code is actually

00:01:56,670 --> 00:02:01,890
written in C and soul it was like these

00:01:59,670 --> 00:02:03,540
networking functions no checking to see

00:02:01,890 --> 00:02:05,399
if you actually minus one back done just

00:02:03,540 --> 00:02:06,780
everything always works it also didn't

00:02:05,399 --> 00:02:08,569
have the ability to fail over one of

00:02:06,780 --> 00:02:10,739
 DB strengths they did have

00:02:08,569 --> 00:02:11,360
primaries and secondaries and relatively

00:02:10,739 --> 00:02:12,980
simple fail

00:02:11,360 --> 00:02:14,990
when the driver knew nothing about it so

00:02:12,980 --> 00:02:17,570
for the next generation driver we wanted

00:02:14,990 --> 00:02:19,310
to fix a lot of that and make it a lot

00:02:17,570 --> 00:02:20,660
of smarter the problem is that in

00:02:19,310 --> 00:02:22,090
addition to making it smarter and more

00:02:20,660 --> 00:02:24,950
robust it also got a lot slower

00:02:22,090 --> 00:02:27,560
significantly slower like 50% as fast

00:02:24,950 --> 00:02:29,570
with certain operations and that wasn't

00:02:27,560 --> 00:02:31,400
considered okay even though we were

00:02:29,570 --> 00:02:32,540
being smarter and more robust so we were

00:02:31,400 --> 00:02:34,610
kind of aiming for could we get it to

00:02:32,540 --> 00:02:37,010
like 10 20 percent slower become an

00:02:34,610 --> 00:02:39,440
acceptable degradation for actually like

00:02:37,010 --> 00:02:43,310
having a seatbelt when people are

00:02:39,440 --> 00:02:44,660
driving the car so this talk is all

00:02:43,310 --> 00:02:46,760
about benchmarking and some of the

00:02:44,660 --> 00:02:48,709
benchmarking work that I did to optimize

00:02:46,760 --> 00:02:50,720
the driver and recover some of the speed

00:02:48,709 --> 00:02:53,989
that we had lost moving to a smarter

00:02:50,720 --> 00:02:56,030
driver and so alive a lot of personal

00:02:53,989 --> 00:02:58,510
biases about benchmarking and I'm for

00:02:56,030 --> 00:03:00,380
the sake of our time I'm not going to go

00:02:58,510 --> 00:03:03,920
explicitly into them but I'll try to

00:03:00,380 --> 00:03:04,760
reference them as we go for I think one

00:03:03,920 --> 00:03:06,680
of the most important things about

00:03:04,760 --> 00:03:08,840
benchmarking is to try to isolate one

00:03:06,680 --> 00:03:10,010
thing at a time and not try to testily I

00:03:08,840 --> 00:03:11,570
don't want to run like the entire test

00:03:10,010 --> 00:03:13,760
suite and performance I want to get down

00:03:11,570 --> 00:03:15,739
to like the small chunks of code and

00:03:13,760 --> 00:03:16,970
benchmark small terms of code and all

00:03:15,739 --> 00:03:19,040
the things that they call and kind of

00:03:16,970 --> 00:03:22,340
work my way methodically through the

00:03:19,040 --> 00:03:27,470
codebase to try to find out what's slow

00:03:22,340 --> 00:03:28,940
and how to fix it the other big thing

00:03:27,470 --> 00:03:30,590
that I believe about benchmarking is

00:03:28,940 --> 00:03:31,910
that we shouldn't trust averages or even

00:03:30,590 --> 00:03:34,130
medians or even any of this sort of like

00:03:31,910 --> 00:03:36,049
single point estimates of performance I

00:03:34,130 --> 00:03:38,330
think what we really want is to be

00:03:36,049 --> 00:03:39,590
looking at distributions not average

00:03:38,330 --> 00:03:41,870
that the shape of the distribution

00:03:39,590 --> 00:03:43,820
turned out to be very important you can

00:03:41,870 --> 00:03:45,769
have distributions with very tight bound

00:03:43,820 --> 00:03:48,140
around a metric or you could have a very

00:03:45,769 --> 00:03:49,610
broad distribution around the metric and

00:03:48,140 --> 00:03:50,930
you might care differently about the

00:03:49,610 --> 00:03:53,900
results based on the sheet with a whole

00:03:50,930 --> 00:03:56,030
distribution not just a single point the

00:03:53,900 --> 00:03:57,320
other thing I believe is that when we're

00:03:56,030 --> 00:04:00,230
profiling we should try to profile

00:03:57,320 --> 00:04:02,180
exactly as revenge met so I wanted to be

00:04:00,230 --> 00:04:03,950
able to run a chunk of code as a

00:04:02,180 --> 00:04:07,100
benchmark and then run that same set of

00:04:03,950 --> 00:04:09,920
code through NYT profit profiling and

00:04:07,100 --> 00:04:10,430
how to be the exact same execution both

00:04:09,920 --> 00:04:12,260
times

00:04:10,430 --> 00:04:13,850
none of the existing tools are set up to

00:04:12,260 --> 00:04:17,150
do this so of course I had to write my

00:04:13,850 --> 00:04:18,890
own tools and I'm going to explain kind

00:04:17,150 --> 00:04:20,030
of how what I wanted and it all sort of

00:04:18,890 --> 00:04:23,000
gives you some of the results in how I

00:04:20,030 --> 00:04:23,800
used it so the goal is initially I want

00:04:23,000 --> 00:04:26,229
to load up some tests

00:04:23,800 --> 00:04:29,050
that I'm going to use when a setup for

00:04:26,229 --> 00:04:30,879
all of the all the test runs for any

00:04:29,050 --> 00:04:31,509
individual test run I need to do some

00:04:30,879 --> 00:04:35,050
prep work

00:04:31,509 --> 00:04:36,520
I run the benchmark one time I clean up

00:04:35,050 --> 00:04:40,030
after each run and then I tear

00:04:36,520 --> 00:04:43,389
everything down at the end now here at

00:04:40,030 --> 00:04:45,009
the the first step loading the testator

00:04:43,389 --> 00:04:46,330
this is where I would vary the scale so

00:04:45,009 --> 00:04:47,979
in this case a lot of what I'll show

00:04:46,330 --> 00:04:49,960
today is a lot about insertion single

00:04:47,979 --> 00:04:51,580
document insertion so the scale is how

00:04:49,960 --> 00:04:53,080
many documents am I going to insert I'm

00:04:51,580 --> 00:04:54,940
going to insert one document ten a

00:04:53,080 --> 00:04:56,680
hundred a thousand ten thousand how many

00:04:54,940 --> 00:04:58,289
Dawkins am I going to insert that's

00:04:56,680 --> 00:05:00,340
where I vary the scale of the test

00:04:58,289 --> 00:05:04,539
because performance also changes with

00:05:00,340 --> 00:05:06,039
different scale here where I had sort of

00:05:04,539 --> 00:05:07,630
end on the arrow this is sort of the

00:05:06,039 --> 00:05:08,800
loops I went to a number of loops and

00:05:07,630 --> 00:05:10,090
this is how I'm going to build up the

00:05:08,800 --> 00:05:11,740
distribution of timing I'm going to do

00:05:10,090 --> 00:05:13,419
this a lot until I have enough

00:05:11,740 --> 00:05:15,400
observation that I can get a

00:05:13,419 --> 00:05:17,620
distribution and start to look at what

00:05:15,400 --> 00:05:19,330
that means the only thing I actually a

00:05:17,620 --> 00:05:20,620
lot of time however is this piece of the

00:05:19,330 --> 00:05:22,870
middle running the benchmark that's

00:05:20,620 --> 00:05:24,190
where I may actually want to put a start

00:05:22,870 --> 00:05:25,449
the check of time at the beginning check

00:05:24,190 --> 00:05:28,210
your time at the end and that's the time

00:05:25,449 --> 00:05:29,800
for that people of work that's all for

00:05:28,210 --> 00:05:31,270
the piece but I want a benchmark I only

00:05:29,800 --> 00:05:33,280
want to benchmark that single piece

00:05:31,270 --> 00:05:34,449
there and then I'm going to collect all

00:05:33,280 --> 00:05:38,650
those Tommen's to produce the

00:05:34,449 --> 00:05:39,909
distributions so the tool I wrote sort

00:05:38,650 --> 00:05:41,229
of I'm just going to talk through the

00:05:39,909 --> 00:05:43,630
command-line arguments briefly to get a

00:05:41,229 --> 00:05:45,789
sense of how I used it this was all on

00:05:43,630 --> 00:05:47,199
github and it's very very old but some

00:05:45,789 --> 00:05:51,099
other stuff on cPanel talking about

00:05:47,199 --> 00:05:52,719
later so I was looking at the zero point

00:05:51,099 --> 00:05:55,810
seven oh eight point two point zero

00:05:52,719 --> 00:05:59,259
because you know for placed versions are

00:05:55,810 --> 00:06:00,430
like all the rage those who know me know

00:05:59,259 --> 00:06:03,580
I have lots of rants about version

00:06:00,430 --> 00:06:05,139
numbers I won't do them today I was

00:06:03,580 --> 00:06:06,219
using a data set from Twitter so I had

00:06:05,139 --> 00:06:08,130
like that it's basically like go get

00:06:06,219 --> 00:06:11,500
Twitter JSON and load a bunch of data in

00:06:08,130 --> 00:06:13,990
and this is my scale so I was using a

00:06:11,500 --> 00:06:15,639
hundred documents in this run and I was

00:06:13,990 --> 00:06:16,960
running the metric for insert one so I

00:06:15,639 --> 00:06:19,750
had a piece of code which was doing that

00:06:16,960 --> 00:06:21,159
little bit of insertion as a central ID

00:06:19,750 --> 00:06:24,279
then run that again for the current

00:06:21,159 --> 00:06:26,440
state of the repository so I would use

00:06:24,279 --> 00:06:28,270
get describe to tell me about where I am

00:06:26,440 --> 00:06:30,219
in the commit history and I've use

00:06:28,270 --> 00:06:32,139
whatever I built up into B Lib to run

00:06:30,219 --> 00:06:34,210
this stuff again now I can compare old

00:06:32,139 --> 00:06:36,529
versus new and then I wrote a program

00:06:34,210 --> 00:06:38,899
they would sort of dump it all into

00:06:36,529 --> 00:06:40,489
chuck's the charts look like this the

00:06:38,899 --> 00:06:42,949
two on the top are actually for a fine

00:06:40,489 --> 00:06:45,769
and the bottom two are for an insert for

00:06:42,949 --> 00:06:47,269
those of you who are chart pennants

00:06:45,769 --> 00:06:48,679
you'll notice that this was not started

00:06:47,269 --> 00:06:50,209
here I have some later that do start at

00:06:48,679 --> 00:06:51,889
0 on the y-axis but this is sort of

00:06:50,209 --> 00:06:54,079
showing how the distributions so I was

00:06:51,889 --> 00:06:55,399
using candlestick graphs and this

00:06:54,079 --> 00:06:58,129
candlestick graph represents the

00:06:55,399 --> 00:07:01,579
interquartile range so I can sort of see

00:06:58,129 --> 00:07:03,409
and I think the so the big rectangle is

00:07:01,579 --> 00:07:05,869
the interquartile range 25th percentile

00:07:03,409 --> 00:07:08,689
the 75th percentile and the sticks I

00:07:05,869 --> 00:07:10,099
think word I don't remember 95th and 5

00:07:08,689 --> 00:07:11,509
or something along those lines give me a

00:07:10,099 --> 00:07:13,489
sense of the spread of the distribution

00:07:11,509 --> 00:07:15,019
and what I'm looking for all the

00:07:13,489 --> 00:07:16,099
distributions overlapping or not and the

00:07:15,019 --> 00:07:17,899
more overlapping they are the less

00:07:16,099 --> 00:07:19,519
confidence I have that the changes I've

00:07:17,899 --> 00:07:20,659
made are actually significant this

00:07:19,519 --> 00:07:22,129
however gives you a sense of the

00:07:20,659 --> 00:07:23,569
starting point that there was a

00:07:22,129 --> 00:07:26,509
significant difference between the old

00:07:23,569 --> 00:07:28,099
driver of the new drug so having

00:07:26,509 --> 00:07:30,109
produced charts that I want to move on

00:07:28,099 --> 00:07:34,599
to profile it so profiling looks like

00:07:30,109 --> 00:07:38,269
this this there we go

00:07:34,599 --> 00:07:40,009
it's pretty much exactly the same as

00:07:38,269 --> 00:07:41,509
before for running the benchmarks but

00:07:40,009 --> 00:07:44,149
now I put the profile flag on and this

00:07:41,509 --> 00:07:46,279
invokes my Peepaw and uses NYT

00:07:44,149 --> 00:07:47,569
possibility to turn the profile on or

00:07:46,279 --> 00:07:48,649
off severe enough a very first thing

00:07:47,569 --> 00:07:51,349
that does is trying to profile it off

00:07:48,649 --> 00:07:52,549
and then it runs all the detail do gets

00:07:51,349 --> 00:07:54,739
to that little bit of benchmark for

00:07:52,549 --> 00:07:56,209
insert 1 turns the profiler on runs the

00:07:54,739 --> 00:07:57,829
benchmark turns the profiler back off so

00:07:56,209 --> 00:07:59,059
I'm collecting timings only around that

00:07:57,829 --> 00:08:00,649
little piece that I'm trying to analyze

00:07:59,059 --> 00:08:05,479
and none of the other framework things

00:08:00,649 --> 00:08:08,899
caffeine fit around and then I crank the

00:08:05,479 --> 00:08:11,119
output to NYT profs HTML visualizer and

00:08:08,899 --> 00:08:12,589
look at it and the first thing I saw

00:08:11,119 --> 00:08:14,059
when I start to do this work looks kind

00:08:12,589 --> 00:08:14,989
of like this this is the flame graph how

00:08:14,059 --> 00:08:18,619
many people are familiar with flame

00:08:14,989 --> 00:08:20,269
graphs some but not all ok so as a quick

00:08:18,619 --> 00:08:23,089
refresher flame graphs look really

00:08:20,269 --> 00:08:25,459
pretty but actually only two things are

00:08:23,089 --> 00:08:27,229
still difficult call stack so the

00:08:25,459 --> 00:08:29,179
vertical stack shows subroutines calling

00:08:27,229 --> 00:08:31,549
each other down into a call stack and

00:08:29,179 --> 00:08:33,439
the width of any bars the execution time

00:08:31,549 --> 00:08:34,069
the inclusive execution time of that

00:08:33,439 --> 00:08:35,929
subroutine

00:08:34,069 --> 00:08:38,029
turns out the color is meaningless it's

00:08:35,929 --> 00:08:39,439
color to look like flames I suppose you

00:08:38,029 --> 00:08:41,209
could color to look like mountains or

00:08:39,439 --> 00:08:43,370
something else and the left-to-right

00:08:41,209 --> 00:08:44,839
order is also meaningless all that

00:08:43,370 --> 00:08:46,520
matters is you can see the call stack so

00:08:44,839 --> 00:08:48,320
you can see execution times

00:08:46,520 --> 00:08:50,480
but it does let you sort of see at a

00:08:48,320 --> 00:08:52,150
very large chunks of work that might be

00:08:50,480 --> 00:08:54,950
worth investigating so in this case a

00:08:52,150 --> 00:08:56,750
huge chunk of this work was all loose

00:08:54,950 --> 00:09:00,620
object new and all the things that it

00:08:56,750 --> 00:09:03,830
was calling imagine that and I'd imagine

00:09:00,620 --> 00:09:04,790
that and then there's a lot of chunk

00:09:03,830 --> 00:09:06,710
over here which is a whole bunch of

00:09:04,790 --> 00:09:08,990
stuff that boils down to coercing lots

00:09:06,710 --> 00:09:11,270
of values to type it one of the

00:09:08,990 --> 00:09:13,460
interesting and I will say annoying

00:09:11,270 --> 00:09:14,960
things about MongoDB document

00:09:13,460 --> 00:09:18,610
representation is that the key than

00:09:14,960 --> 00:09:20,540
value have order order matters and

00:09:18,610 --> 00:09:22,700
trying to get pearl to do that

00:09:20,540 --> 00:09:24,170
particularly have to pro 518 randomize

00:09:22,700 --> 00:09:26,330
hashes this gives very noise so the

00:09:24,170 --> 00:09:28,580
answer is slap lots of tight cash around

00:09:26,330 --> 00:09:31,610
things but that turns out to be very

00:09:28,580 --> 00:09:34,340
efficient in certain circumstances

00:09:31,610 --> 00:09:35,810
so this chunk in the middle is the part

00:09:34,340 --> 00:09:37,370
that's actually the insert one and is

00:09:35,810 --> 00:09:38,660
the real work and that's and it'd be

00:09:37,370 --> 00:09:40,910
really nice like a get rid of a lot of

00:09:38,660 --> 00:09:42,140
the rest of it and focus on this the

00:09:40,910 --> 00:09:44,780
next view I like to look at after the

00:09:42,140 --> 00:09:46,190
flame graphs is the profilers listing at

00:09:44,780 --> 00:09:47,660
the top subroutines

00:09:46,190 --> 00:09:49,730
people may be familiar with this view

00:09:47,660 --> 00:09:52,630
and what's interesting about this is if

00:09:49,730 --> 00:09:54,620
this actually adds up all the individual

00:09:52,630 --> 00:09:56,150
occurrences of subroutine so you can

00:09:54,620 --> 00:09:59,630
have subroutines showing up in multiple

00:09:56,150 --> 00:10:00,590
places in your flame graph and this

00:09:59,630 --> 00:10:02,780
brings it all together is you can

00:10:00,590 --> 00:10:05,450
actually sort of see which subroutines

00:10:02,780 --> 00:10:06,800
tend to be heavy not surprising

00:10:05,450 --> 00:10:09,350
there's a lot of stuff which is related

00:10:06,800 --> 00:10:11,390
to MU and those who are very perceptive

00:10:09,350 --> 00:10:12,890
about our site web news a very

00:10:11,390 --> 00:10:16,910
perceptive can see that a lot of this is

00:10:12,890 --> 00:10:18,860
plot mop meta attribute stuff and this

00:10:16,910 --> 00:10:21,710
means that the Moose classes weren't

00:10:18,860 --> 00:10:24,080
immutable that's fixable by package meta

00:10:21,710 --> 00:10:25,970
make immutable so that we're not doing

00:10:24,080 --> 00:10:27,860
any meta object stuff once we're running

00:10:25,970 --> 00:10:29,540
so great freeze those classes down and

00:10:27,860 --> 00:10:31,700
move on

00:10:29,540 --> 00:10:33,470
the other thing we could see from the

00:10:31,700 --> 00:10:35,990
flame graph as expected there's a lot of

00:10:33,470 --> 00:10:38,960
calls to tie it cashed hi Akash type

00:10:35,990 --> 00:10:40,970
ashes and and keeps order but as many of

00:10:38,960 --> 00:10:43,940
us know tying is very very very very

00:10:40,970 --> 00:10:45,440
very inefficient so the answer is stop

00:10:43,940 --> 00:10:47,390
coursing to tie account there were a lot

00:10:45,440 --> 00:10:50,300
of places where documents would get

00:10:47,390 --> 00:10:51,980
coerced to a Nick hash even when they

00:10:50,300 --> 00:10:53,210
didn't need to be and just so that like

00:10:51,980 --> 00:10:55,280
the code could just sort of assume that

00:10:53,210 --> 00:10:57,200
it all worked in Thai exams so I can

00:10:55,280 --> 00:10:58,259
always use the taya cache API to work

00:10:57,200 --> 00:11:00,179
with stuff

00:10:58,259 --> 00:11:02,129
and not have to write a number of way so

00:11:00,179 --> 00:11:03,660
if you stop cursing we have to write

00:11:02,129 --> 00:11:05,759
more code to handle different cases of

00:11:03,660 --> 00:11:07,229
what people might provide because some

00:11:05,759 --> 00:11:08,489
people might not care about order for

00:11:07,229 --> 00:11:11,939
certain types of documents and just

00:11:08,489 --> 00:11:14,040
throw it on in and it works so once we

00:11:11,939 --> 00:11:16,410
make those two changes everything's got

00:11:14,040 --> 00:11:18,419
any better and the answer is yes so at

00:11:16,410 --> 00:11:20,100
this point this is now mostly the insert

00:11:18,419 --> 00:11:21,629
one if most of you will work in the

00:11:20,100 --> 00:11:23,850
plane graph if we can start digging into

00:11:21,629 --> 00:11:28,289
the specifics of what actual real work

00:11:23,850 --> 00:11:30,749
we try to optimize so going back to the

00:11:28,289 --> 00:11:34,009
list of top server teams start to pick

00:11:30,749 --> 00:11:38,160
up some new things so here we have

00:11:34,009 --> 00:11:39,989
constructors and terminal constructors

00:11:38,160 --> 00:11:42,359
are still kind of heavy we make a lot of

00:11:39,989 --> 00:11:47,519
objects and it's a lot of this is was

00:11:42,359 --> 00:11:49,919
because the version one uses objects and

00:11:47,519 --> 00:11:52,619
rolls to on a lot of internal classes to

00:11:49,919 --> 00:11:54,660
be able to do similar things across

00:11:52,619 --> 00:11:56,009
different operations and do and adjust

00:11:54,660 --> 00:11:57,660
for the fact that laundry to be two

00:11:56,009 --> 00:12:00,539
point four has one wire protocol and she

00:11:57,660 --> 00:12:01,919
picks another wire protocol and now 300

00:12:00,539 --> 00:12:03,299
has another n32 has another and all

00:12:01,919 --> 00:12:05,189
these little sort of operating our

00:12:03,299 --> 00:12:06,660
MongoDB version specific changes in

00:12:05,189 --> 00:12:08,789
roles make a lot of that really really

00:12:06,660 --> 00:12:11,220
nice I don't have to write a lot of

00:12:08,789 --> 00:12:13,649
codes you can maintain but then a lot of

00:12:11,220 --> 00:12:15,179
heavy constructors to think about the

00:12:13,649 --> 00:12:17,850
other thing they popped out at me is if

00:12:15,179 --> 00:12:20,429
you look closely right this is a there's

00:12:17,850 --> 00:12:23,459
about in this particular run they're

00:12:20,429 --> 00:12:24,809
about ten thousand operations most of

00:12:23,459 --> 00:12:27,629
the time but for some of them was forty

00:12:24,809 --> 00:12:31,410
thousand twenty thousand thirty fell and

00:12:27,629 --> 00:12:33,660
so we did a scale of one hundred inserts

00:12:31,410 --> 00:12:35,609
across the number of loops over that to

00:12:33,660 --> 00:12:37,919
get about ten thousand you know one

00:12:35,609 --> 00:12:39,899
hundred iterations of a lot of inserts

00:12:37,919 --> 00:12:42,059
we get ten thousand operations why are

00:12:39,899 --> 00:12:43,379
we getting Kings called two three four

00:12:42,059 --> 00:12:45,779
times the number of integers what's

00:12:43,379 --> 00:12:48,329
going on there when I started doing into

00:12:45,779 --> 00:12:50,279
the top function function calls view

00:12:48,329 --> 00:12:52,289
timeout view timeout is a generalized

00:12:50,279 --> 00:12:53,489
sort of like select with timeout either

00:12:52,289 --> 00:12:56,189
four reads or writes essentially this

00:12:53,489 --> 00:12:57,449
consolidates all of the do something

00:12:56,189 --> 00:13:01,289
with the time at wait for the network

00:12:57,449 --> 00:13:03,479
but with a timeout in eats the way and

00:13:01,289 --> 00:13:05,459
it looks kind of girly like this which I

00:13:03,479 --> 00:13:07,710
don't expect you to be able to read but

00:13:05,459 --> 00:13:09,000
the interesting thing is

00:13:07,710 --> 00:13:10,890
not only know how to read these photos

00:13:09,000 --> 00:13:13,800
so I have like left column statements

00:13:10,890 --> 00:13:15,120
and then how much time I spent on the

00:13:13,800 --> 00:13:17,370
line how many calls there are how many

00:13:15,120 --> 00:13:20,010
sub between calls are on the thing those

00:13:17,370 --> 00:13:21,870
that use these things NYP prob how many

00:13:20,010 --> 00:13:23,880
people use that might be problem most

00:13:21,870 --> 00:13:25,200
the room okay so we're you're familiar

00:13:23,880 --> 00:13:27,839
with this it was a little bit

00:13:25,200 --> 00:13:30,750
what's interesting up here is that look

00:13:27,839 --> 00:13:32,160
at this shows me where is where is do

00:13:30,750 --> 00:13:34,110
time out being called and it turns out

00:13:32,160 --> 00:13:36,420
that can read is calling do time out

00:13:34,110 --> 00:13:38,730
thirty thousand times and can write is

00:13:36,420 --> 00:13:40,500
being called ten bells now I expect that

00:13:38,730 --> 00:13:42,029
can't be can write to call it ten

00:13:40,500 --> 00:13:44,370
thousand ounces i'm doing ten thousand

00:13:42,029 --> 00:13:47,010
insertions across the entire run it can

00:13:44,370 --> 00:13:49,140
read has this people so why are there

00:13:47,010 --> 00:13:51,510
three can read calls for every right

00:13:49,140 --> 00:13:53,459
well it turns out that one of them was

00:13:51,510 --> 00:13:55,110
this sort of approach of we're going to

00:13:53,459 --> 00:13:56,700
see if the service detected before I try

00:13:55,110 --> 00:13:57,630
to do anything and send us something to

00:13:56,700 --> 00:13:58,649
the server I'm going to check and see if

00:13:57,630 --> 00:14:01,350
that service still there I'm going to

00:13:58,649 --> 00:14:03,390
try to do a select to read and see if I

00:14:01,350 --> 00:14:06,149
get an EOS which would mean the server's

00:14:03,390 --> 00:14:08,520
have gone away send an RS t QP packet

00:14:06,149 --> 00:14:10,020
and we're dead well comet that is is a

00:14:08,520 --> 00:14:11,370
race condition there's a gap of time

00:14:10,020 --> 00:14:13,200
between the time I check to see if the

00:14:11,370 --> 00:14:14,730
server to send in rst and then I go

00:14:13,200 --> 00:14:16,110
ahead and send the write very possible

00:14:14,730 --> 00:14:18,630
the server will descend on rst if I go

00:14:16,110 --> 00:14:20,010
right after I did the check so since

00:14:18,630 --> 00:14:21,690
this is rate a racy check it does

00:14:20,010 --> 00:14:24,089
actually do a lot of good protecting us

00:14:21,690 --> 00:14:25,290
from network errors we could just delete

00:14:24,089 --> 00:14:29,190
it

00:14:25,290 --> 00:14:30,720
so then the other use is for the timeout

00:14:29,190 --> 00:14:32,010
is what we're reading responses from the

00:14:30,720 --> 00:14:33,390
surface so we send a right to the server

00:14:32,010 --> 00:14:36,000
the server sends back something of yep

00:14:33,390 --> 00:14:39,060
got the right it was applied I was okay

00:14:36,000 --> 00:14:41,250
so why were there two weeks for every

00:14:39,060 --> 00:14:43,800
response and it turned out the read

00:14:41,250 --> 00:14:45,720
algorithm looked like this first read

00:14:43,800 --> 00:14:47,190
four bytes define a network line but

00:14:45,720 --> 00:14:49,650
find the document length so to respond

00:14:47,190 --> 00:14:54,959
and then read length minus four to get

00:14:49,650 --> 00:14:57,420
the rest of the document a horrible

00:14:54,959 --> 00:15:00,060
algorithm here's a better algorithm read

00:14:57,420 --> 00:15:01,890
as many bytes as we can hey network give

00:15:00,060 --> 00:15:03,870
me all the bytes you have if it turns

00:15:01,890 --> 00:15:07,140
out that's not enough we can go back and

00:15:03,870 --> 00:15:08,640
get someone great when I had made that

00:15:07,140 --> 00:15:10,840
change but then there was another

00:15:08,640 --> 00:15:13,900
problem

00:15:10,840 --> 00:15:15,190
I started to test all this stuff so it

00:15:13,900 --> 00:15:16,810
made all the big changes to all the

00:15:15,190 --> 00:15:18,580
reads and the writes almost let me just

00:15:16,810 --> 00:15:20,890
re running all this Tesla to discover

00:15:18,580 --> 00:15:23,740
that actually the tie X has changed I

00:15:20,890 --> 00:15:24,970
had made way back earlier bro bulk

00:15:23,740 --> 00:15:26,200
insertion so if you don't want to insert

00:15:24,970 --> 00:15:27,730
one at a time you want to insert like

00:15:26,200 --> 00:15:29,230
here's 100 documents and sew them all

00:15:27,730 --> 00:15:30,430
insert them all at once it's actually a

00:15:29,230 --> 00:15:32,170
lot more efficient for this one network

00:15:30,430 --> 00:15:34,240
round-trip it turns out that something

00:15:32,170 --> 00:15:36,520
in the X has change broke a whole bunch

00:15:34,240 --> 00:15:37,750
of stuff and I wasn't running all my

00:15:36,520 --> 00:15:39,460
tests after every commit I would do

00:15:37,750 --> 00:15:41,020
almost optimization I'm very excited but

00:15:39,460 --> 00:15:41,890
any degree run the full test suite and

00:15:41,020 --> 00:15:43,690
make sure I hadn't broken

00:15:41,890 --> 00:15:46,900
I ran small parts of the test suite I

00:15:43,690 --> 00:15:48,850
didn't want everything so lesson always

00:15:46,900 --> 00:15:50,560
run tests when you're doing optimization

00:15:48,850 --> 00:15:52,740
make sure that nothing has broken every

00:15:50,560 --> 00:15:55,540
step of the way

00:15:52,740 --> 00:15:57,640
so after eliminating the the RACI check

00:15:55,540 --> 00:16:01,390
and fix $3 the navigate something looks

00:15:57,640 --> 00:16:03,130
like this and the interesting bit is the

00:16:01,390 --> 00:16:05,410
do timeout has fallen down at least a

00:16:03,130 --> 00:16:07,630
little bit still there but it's not all

00:16:05,410 --> 00:16:09,370
the way at the top and when I go back to

00:16:07,630 --> 00:16:13,210
my charts and I look at how what kind of

00:16:09,370 --> 00:16:15,160
progress has I made along the way it

00:16:13,210 --> 00:16:19,210
looks like this so starting from that

00:16:15,160 --> 00:16:24,850
the first all the way on the left is the

00:16:19,210 --> 00:16:26,500
original 0.7 Oh 8 point 2.0 and the rest

00:16:24,850 --> 00:16:28,150
of sort of incremental commits that I

00:16:26,500 --> 00:16:31,030
had made after some rebasing all the

00:16:28,150 --> 00:16:32,740
rest of that wouldn't that get rebasing

00:16:31,030 --> 00:16:34,360
with smoke testing good really useful

00:16:32,740 --> 00:16:36,640
all that we face is yes it wouldn't have

00:16:34,360 --> 00:16:37,990
caught the errors you can see that the

00:16:36,640 --> 00:16:39,160
things are sort of creeping up it's also

00:16:37,990 --> 00:16:40,840
interesting to note that there's a lot

00:16:39,160 --> 00:16:42,310
of variance from runs a lot all right

00:16:40,840 --> 00:16:43,390
some of the some of these interquartile

00:16:42,310 --> 00:16:46,000
ranges are really tight other than

00:16:43,390 --> 00:16:47,440
others of them are really long another

00:16:46,000 --> 00:16:48,730
lesson for optimized is that while your

00:16:47,440 --> 00:16:55,150
tests are running don't go in browse the

00:16:48,730 --> 00:16:58,120
web get up get up go away get a cup of

00:16:55,150 --> 00:16:59,290
coffee if your to start up play ping

00:16:58,120 --> 00:17:01,450
pong or pool or whatever sort of

00:16:59,290 --> 00:17:03,880
diversions they have do sword fighting

00:17:01,450 --> 00:17:05,320
you know on chairs whatever you need to

00:17:03,880 --> 00:17:07,570
do to just leave your computer alone and

00:17:05,320 --> 00:17:09,250
let it run but even still there are some

00:17:07,570 --> 00:17:10,600
fluctuations that happen and you can

00:17:09,250 --> 00:17:13,930
also see that there's actually a fair

00:17:10,600 --> 00:17:15,040
amount of overlap between the ranges but

00:17:13,930 --> 00:17:16,209
they are sort of steadily marching

00:17:15,040 --> 00:17:18,550
upwards and this is kind of what I was

00:17:16,209 --> 00:17:19,990
looking for was not putting my reliance

00:17:18,550 --> 00:17:21,430
on any one metric but looking to see if

00:17:19,990 --> 00:17:23,779
it seemed like the distribution as a

00:17:21,430 --> 00:17:28,279
whole was starting to March

00:17:23,779 --> 00:17:29,989
so what's next I think I can actually

00:17:28,279 --> 00:17:33,739
slow down I'm like blasting to these

00:17:29,989 --> 00:17:36,139
slides though maybe the lightening time

00:17:33,739 --> 00:17:40,039
as a warm-up is not so good for this

00:17:36,139 --> 00:17:43,460
figure so what's next so now we go back

00:17:40,039 --> 00:17:45,349
and look at the top sub routine on the

00:17:43,460 --> 00:17:47,299
heavy with sub routines its encoding

00:17:45,349 --> 00:17:49,729
documents into beasts on which is the

00:17:47,299 --> 00:17:52,269
binary JSON document flow not that

00:17:49,729 --> 00:17:54,529
things get offensive on good idea and

00:17:52,269 --> 00:17:56,779
when I start to dig into that what I

00:17:54,529 --> 00:17:59,149
discovered is that there's a lot of one

00:17:56,779 --> 00:18:00,529
by one option over eyes so the beasts on

00:17:59,149 --> 00:18:02,269
encoder class has a bunch of default

00:18:00,529 --> 00:18:04,309
options set but you can also pass the

00:18:02,269 --> 00:18:05,599
end a set of overrides when you do the

00:18:04,309 --> 00:18:07,129
encode and what was happen is there was

00:18:05,599 --> 00:18:10,599
a loop running that for every single

00:18:07,129 --> 00:18:13,190
option that was possible would say hey

00:18:10,599 --> 00:18:15,019
check to see if this was passed in go

00:18:13,190 --> 00:18:17,899
call the access run self to get the

00:18:15,019 --> 00:18:19,190
default value every single time we're

00:18:17,899 --> 00:18:23,299
doing a whole bunch of method calls at a

00:18:19,190 --> 00:18:25,519
whole bunch of over n roll Gulf is a

00:18:23,299 --> 00:18:28,789
hash so because like Pro merge them so

00:18:25,519 --> 00:18:30,440
take all the defaults themselves if it's

00:18:28,789 --> 00:18:31,969
somebody passing options let pro swap

00:18:30,440 --> 00:18:34,099
the multi up and then pros doing that

00:18:31,969 --> 00:18:37,309
down in you know the interpreter is C

00:18:34,099 --> 00:18:39,440
code and not Theory the Perl op tree and

00:18:37,309 --> 00:18:43,249
this decrease the amount of time in the

00:18:39,440 --> 00:18:48,499
benchmarking from 849 millisecond was

00:18:43,249 --> 00:18:50,269
212 milliseconds so a nice easy win and

00:18:48,499 --> 00:18:51,679
that moved the encode one way way way

00:18:50,269 --> 00:18:54,529
down in the pulse tech it's still doing

00:18:51,679 --> 00:18:58,460
a lot of work but now it's a much much

00:18:54,529 --> 00:18:59,929
less so now let's talk about oh well

00:18:58,460 --> 00:19:02,509
let's go back to that stuff I noticed

00:18:59,929 --> 00:19:04,429
very early on about heavy constructors

00:19:02,509 --> 00:19:06,229
and what we're talking about oh we're

00:19:04,429 --> 00:19:09,080
really talking about booths because

00:19:06,229 --> 00:19:12,469
Luke's is extraordinarily heavy so we

00:19:09,080 --> 00:19:15,559
had at this point with all the

00:19:12,469 --> 00:19:17,089
optimizations to date still call to me

00:19:15,559 --> 00:19:18,919
we're very very heavy well and I started

00:19:17,089 --> 00:19:22,399
to look at what was going on well in a

00:19:18,919 --> 00:19:25,249
lot of cases the Constructors had a lot

00:19:22,399 --> 00:19:27,919
of attributes with this is a string most

00:19:25,249 --> 00:19:30,169
of the attributes were string data and

00:19:27,919 --> 00:19:32,839
the question is do we really need this

00:19:30,169 --> 00:19:35,059
at runtime right a lot of these are also

00:19:32,839 --> 00:19:36,499
internal classes they were things that

00:19:35,059 --> 00:19:37,040
we were putting out in their library for

00:19:36,499 --> 00:19:38,150
end-users

00:19:37,040 --> 00:19:40,280
these were objects that we were

00:19:38,150 --> 00:19:43,190
constructing internally private classes

00:19:40,280 --> 00:19:44,660
for our own use how often are we going

00:19:43,190 --> 00:19:46,850
to mess up putting a string in where

00:19:44,660 --> 00:19:47,780
where we don't really not expecting a

00:19:46,850 --> 00:19:49,130
stranger putting some object that

00:19:47,780 --> 00:19:51,290
doesn't string apply we're expecting a

00:19:49,130 --> 00:19:55,190
spring not very often you have a lot of

00:19:51,290 --> 00:19:57,620
control over it so this is what what I

00:19:55,190 --> 00:19:59,300
did I got rid of the the plain old check

00:19:57,620 --> 00:20:01,820
and replace it with this ternary

00:19:59,300 --> 00:20:03,230
condition with assert so if I set up a

00:20:01,820 --> 00:20:04,670
constant called assert based on

00:20:03,230 --> 00:20:05,960
environment variable whatever then that

00:20:04,670 --> 00:20:07,370
check is going to be there and otherwise

00:20:05,960 --> 00:20:09,170
the check won't be there so when I'm

00:20:07,370 --> 00:20:10,520
running tests I can run tests with

00:20:09,170 --> 00:20:12,020
assertions on and make sure I haven't

00:20:10,520 --> 00:20:13,400
forgotten anything that carl's run with

00:20:12,020 --> 00:20:15,500
it off to make sure that that still

00:20:13,400 --> 00:20:16,970
works but for any users end users don't

00:20:15,500 --> 00:20:18,380
pay the cost of making sure that I know

00:20:16,970 --> 00:20:21,530
how to put strings in the right spot of

00:20:18,380 --> 00:20:22,700
my code easy when and that drops the

00:20:21,530 --> 00:20:24,920
weight of the constructor is way way

00:20:22,700 --> 00:20:26,360
down call center but the problems it's

00:20:24,920 --> 00:20:28,520
not enough we're still generating lots

00:20:26,360 --> 00:20:30,620
and lots of objects some extent if I had

00:20:28,520 --> 00:20:33,080
to go back and rewrite this entirely

00:20:30,620 --> 00:20:34,400
from scratch again I might even just get

00:20:33,080 --> 00:20:36,950
rid of a lot of the oh oh and if you

00:20:34,400 --> 00:20:40,880
just pass around hashes and avoid a lot

00:20:36,950 --> 00:20:42,470
of these overhead as well and so I

00:20:40,880 --> 00:20:45,050
decided it wasn't enough and that made

00:20:42,470 --> 00:20:49,610
me really start to think about these so

00:20:45,050 --> 00:20:51,470
sorry boost you to slow you got to go so

00:20:49,610 --> 00:20:52,880
the next chain was to move to move much

00:20:51,470 --> 00:20:54,350
much lighter and use class access

00:20:52,880 --> 00:20:56,150
accessors to speed up a lot of the

00:20:54,350 --> 00:20:59,030
activists are called to almost as fast

00:20:56,150 --> 00:21:00,920
as air hash active and that helped a lot

00:20:59,030 --> 00:21:02,300
but I found the Constructors we're still

00:21:00,920 --> 00:21:03,890
doing a lot of work because we're still

00:21:02,300 --> 00:21:06,040
generating lots of objects and even move

00:21:03,890 --> 00:21:08,510
has a lot of big document constructors

00:21:06,040 --> 00:21:10,160
and so since these are internal

00:21:08,510 --> 00:21:11,540
pawsnpins I know exactly what we're

00:21:10,160 --> 00:21:13,910
passing to them

00:21:11,540 --> 00:21:15,590
we decided cheat and create private

00:21:13,910 --> 00:21:17,300
constructors for our internal clocks and

00:21:15,590 --> 00:21:20,000
the private constructors were kind of

00:21:17,300 --> 00:21:20,990
like this we created a role private

00:21:20,000 --> 00:21:24,860
constructor that we could add to

00:21:20,990 --> 00:21:26,840
whatever internal clauses we had and it

00:21:24,860 --> 00:21:28,910
used the vomity be constants which is

00:21:26,840 --> 00:21:30,980
where we set the with asserts or not and

00:21:28,910 --> 00:21:32,660
if the asserts are on we create an

00:21:30,980 --> 00:21:33,980
underscore new constructor which was

00:21:32,660 --> 00:21:35,780
passing straight on through to new so if

00:21:33,980 --> 00:21:39,110
it sorts are on we get all lose normal

00:21:35,780 --> 00:21:40,940
checks did you pass me a hash or even

00:21:39,110 --> 00:21:43,130
number of pairs blah blah blah all the

00:21:40,940 --> 00:21:45,290
usual stuff you expect but if the

00:21:43,130 --> 00:21:46,040
assertions are off then we just blessed

00:21:45,290 --> 00:21:47,090
all the are

00:21:46,040 --> 00:21:50,150
give us that are provided straight into

00:21:47,090 --> 00:21:52,160
the class like and and mood definitely

00:21:50,150 --> 00:21:54,980
care moose would have a problem with new

00:21:52,160 --> 00:21:56,150
funds it's a bunch of stuff at worst

00:21:54,980 --> 00:21:57,650
we've left out something that should

00:21:56,150 --> 00:21:59,360
have been required or we've added an

00:21:57,650 --> 00:22:01,820
extra garbage values that aren't really

00:21:59,360 --> 00:22:05,960
attributes but when we run with

00:22:01,820 --> 00:22:07,640
assertions we'd catch that and so this

00:22:05,960 --> 00:22:08,720
needs a lot of the work to the call site

00:22:07,640 --> 00:22:11,110
to make sure we have all these arguments

00:22:08,720 --> 00:22:13,220
we're not using defaults can't use

00:22:11,110 --> 00:22:14,720
subroutines to generate attributes on

00:22:13,220 --> 00:22:18,080
the fly if I need a hash reference I

00:22:14,720 --> 00:22:19,610
can't say oh the default is sub give me

00:22:18,080 --> 00:22:21,680
a hash ref back I have to actually put

00:22:19,610 --> 00:22:24,280
it in the call site but by moving the

00:22:21,680 --> 00:22:27,170
work to the call size I avoid all of the

00:22:24,280 --> 00:22:29,840
constructor overhead and that makes bit

00:22:27,170 --> 00:22:31,070
as much much faster I also meant we just

00:22:29,840 --> 00:22:32,300
put all the is a checks packet I don't

00:22:31,070 --> 00:22:33,650
have to with assert all the is a checks

00:22:32,300 --> 00:22:35,720
because either the constructors running

00:22:33,650 --> 00:22:39,710
or it's not an active streamline code a

00:22:35,720 --> 00:22:45,620
little bit so yeah so some other tidbits

00:22:39,710 --> 00:22:48,410
of things that we found it you say one

00:22:45,620 --> 00:22:50,000
of them is getting rid of try tiny try

00:22:48,410 --> 00:22:51,830
Tanya's heavyweight I think somebody has

00:22:50,000 --> 00:22:53,300
put the modulite on see panda tries to

00:22:51,830 --> 00:22:59,120
reduce some of that overheads let's

00:22:53,300 --> 00:23:02,270
bring a bell for anybody no okay try

00:22:59,120 --> 00:23:04,700
tiny tiny that sound like that the I

00:23:02,270 --> 00:23:07,520
should have written goodbye like tiny

00:23:04,700 --> 00:23:08,900
bothers a lot so tiny one of the try

00:23:07,520 --> 00:23:11,780
tiny is log gives you a lot of great

00:23:08,900 --> 00:23:14,930
sugar it's also using lots and lots and

00:23:11,780 --> 00:23:17,000
lots of quarters and subroutine

00:23:14,930 --> 00:23:18,770
references to do all this magic and

00:23:17,000 --> 00:23:20,330
those are heavy Perl has heavy

00:23:18,770 --> 00:23:23,120
publishing called just the way the line

00:23:20,330 --> 00:23:26,450
gauges and so a simple eval block and

00:23:23,120 --> 00:23:28,850
checking the dollar at is very very very

00:23:26,450 --> 00:23:31,690
fast compared to using try time try tiny

00:23:28,850 --> 00:23:33,650
is protesting and certain problematic

00:23:31,690 --> 00:23:35,000
situations which again if you're careful

00:23:33,650 --> 00:23:36,730
and you know where your code is running

00:23:35,000 --> 00:23:38,390
you're controlling a lot of this

00:23:36,730 --> 00:23:39,650
internally you can actually sort of

00:23:38,390 --> 00:23:42,770
avoid it and you don't wind up needing

00:23:39,650 --> 00:23:46,080
try tiny so some things we used I used

00:23:42,770 --> 00:23:47,760
try tiny for particularly where

00:23:46,080 --> 00:23:50,880
I was getting things from users that I

00:23:47,760 --> 00:23:51,840
wasn't sure I could totally control but

00:23:50,880 --> 00:23:53,250
other places we just got rid of

00:23:51,840 --> 00:23:56,700
Chaitanya and went back to the struggle

00:23:53,250 --> 00:23:58,890
to that simplified things law we also

00:23:56,700 --> 00:24:01,710
within the new code the Moose code and

00:23:58,890 --> 00:24:03,720
the leuco we using type tiny which is

00:24:01,710 --> 00:24:06,450
ironic the type tiny is enormous and not

00:24:03,720 --> 00:24:07,950
tiny at all I'm not even sure what it

00:24:06,450 --> 00:24:10,200
considers itself to be an alternative to

00:24:07,950 --> 00:24:14,070
go to do tiny because it was certainly

00:24:10,200 --> 00:24:15,570
not tiny and forums are expensive so if

00:24:14,070 --> 00:24:16,860
you take some values now I need to

00:24:15,570 --> 00:24:18,269
coerce this to another value it is again

00:24:16,860 --> 00:24:19,590
a lot of subroutine calls is it the

00:24:18,269 --> 00:24:21,029
right type if it's not the right type do

00:24:19,590 --> 00:24:23,070
I have the right time so a lot of logic

00:24:21,029 --> 00:24:24,750
happens do collisions so we tried to

00:24:23,070 --> 00:24:26,250
eliminate a lot of conversions and just

00:24:24,750 --> 00:24:28,490
get things into the right form very

00:24:26,250 --> 00:24:33,269
selectively where we needed it and that

00:24:28,490 --> 00:24:37,040
simplifies things a lot as well but also

00:24:33,269 --> 00:24:38,540
use time high-rez a lot as a Tyner timer

00:24:37,040 --> 00:24:40,190
I'm actually gonna get us back on

00:24:38,540 --> 00:24:43,070
schedule that's how fast I did the first

00:24:40,190 --> 00:24:45,280
half of this my back in the back I got

00:24:43,070 --> 00:24:48,670
the halfway mark side and held up so

00:24:45,280 --> 00:24:52,700
doing even better than that

00:24:48,670 --> 00:24:54,380
so time high-rez use a lot for timings

00:24:52,700 --> 00:24:57,950
you get really good timing so great well

00:24:54,380 --> 00:24:59,690
tbh interval gives you an array that has

00:24:57,950 --> 00:25:01,610
the seconds and the fractional second

00:24:59,690 --> 00:25:03,020
and this functions to manipulate those

00:25:01,610 --> 00:25:06,860
and do those the problem is of course

00:25:03,020 --> 00:25:08,930
that doing math with array component in

00:25:06,860 --> 00:25:12,020
Perl is slow because we're doing array

00:25:08,930 --> 00:25:14,170
indexing we're doing pearls math and

00:25:12,020 --> 00:25:16,850
what we found was that using decimal

00:25:14,170 --> 00:25:19,250
time and just getting time as a float

00:25:16,850 --> 00:25:20,690
meant that now I had a fractional time

00:25:19,250 --> 00:25:23,360
in a fractional time and if I'm doing

00:25:20,690 --> 00:25:25,100
math on those usually subtracting seeing

00:25:23,360 --> 00:25:26,630
like where I am at and time out pearl

00:25:25,100 --> 00:25:28,190
does that very efficiently because oh I

00:25:26,630 --> 00:25:29,330
have internally I have a double

00:25:28,190 --> 00:25:30,710
representing that internal and how the

00:25:29,330 --> 00:25:33,320
double representing that goes from edge

00:25:30,710 --> 00:25:36,170
objective observer mode and then does it

00:25:33,320 --> 00:25:37,610
in one operation and so it takes a whole

00:25:36,170 --> 00:25:39,350
lot of operations out of the pearl top

00:25:37,610 --> 00:25:40,940
tree down to one operation of

00:25:39,350 --> 00:25:43,430
subtraction on a scalar variable so it

00:25:40,940 --> 00:25:45,050
turns out the decimal time may be not as

00:25:43,430 --> 00:25:47,300
ideal in certain circumstances is

00:25:45,050 --> 00:25:51,530
actually a lot faster to do math with

00:25:47,300 --> 00:25:53,240
impulses one of the other things I did

00:25:51,530 --> 00:25:54,710
was to cache boolean true so for those

00:25:53,240 --> 00:25:56,860
of you who are here early and saw me

00:25:54,710 --> 00:25:59,720
give my lightning talk about GUI DM

00:25:56,860 --> 00:26:02,000
boolean dot p.m. gives you true and

00:25:59,720 --> 00:26:04,370
false these are constant functions that

00:26:02,000 --> 00:26:07,190
give you these Singleton's even though

00:26:04,370 --> 00:26:08,660
they're they're functions you're still

00:26:07,190 --> 00:26:10,460
there's still stuff that's happening it

00:26:08,660 --> 00:26:12,620
and Perl is not in all cases smart

00:26:10,460 --> 00:26:14,480
enough to optimize the way those

00:26:12,620 --> 00:26:19,090
operations and so I found that certain

00:26:14,480 --> 00:26:21,200
cases just calling that once and and

00:26:19,090 --> 00:26:23,000
cashing at local wind is dropping it in

00:26:21,200 --> 00:26:24,410
everywhere was helpful I think possibly

00:26:23,000 --> 00:26:26,240
the reason it wasn't optimised away is

00:26:24,410 --> 00:26:28,130
because we were calling them access code

00:26:26,240 --> 00:26:29,450
if you're calling them access code it

00:26:28,130 --> 00:26:32,990
was happy to do the function Paul anyway

00:26:29,450 --> 00:26:34,670
pro can't optimize the top tree so

00:26:32,990 --> 00:26:37,340
caching all these true and false values

00:26:34,670 --> 00:26:38,630
once in a way we could just drop them in

00:26:37,340 --> 00:26:41,420
without a function call turned out to

00:26:38,630 --> 00:26:43,670
speed things up caching the primary

00:26:41,420 --> 00:26:44,780
server between topology scams this

00:26:43,670 --> 00:26:46,130
requires a little bit of experts

00:26:44,780 --> 00:26:47,600
explanation which I was going to skip

00:26:46,130 --> 00:26:50,850
but since I'm ahead of schedule I'll

00:26:47,600 --> 00:26:52,890
explain it so mommy-to-be operates

00:26:50,850 --> 00:26:54,180
in a mode with having we call replica

00:26:52,890 --> 00:26:56,820
set where you have a primary server

00:26:54,180 --> 00:26:59,040
which takes rights and where you should

00:26:56,820 --> 00:27:00,600
do most of your read and secondaries

00:26:59,040 --> 00:27:03,210
which are getting replicated copies of

00:27:00,600 --> 00:27:05,130
all the operations and can step up into

00:27:03,210 --> 00:27:07,320
the primary role of the primary goes

00:27:05,130 --> 00:27:08,760
down and every so often the programmer

00:27:07,320 --> 00:27:10,530
has to sort of stop and check the world

00:27:08,760 --> 00:27:12,030
and say hey make sure I know who all the

00:27:10,530 --> 00:27:13,650
primers and secondaries are if somebody

00:27:12,030 --> 00:27:15,510
has added secondaries I need to know

00:27:13,650 --> 00:27:15,990
about it and kind of gather the view of

00:27:15,510 --> 00:27:18,690
the world

00:27:15,990 --> 00:27:20,460
and there's a lot of logic the whole

00:27:18,690 --> 00:27:22,170
specification for how we choose a server

00:27:20,460 --> 00:27:23,730
says oh I need to do a write to go to my

00:27:22,170 --> 00:27:26,310
set of servers and see which one of the

00:27:23,730 --> 00:27:29,430
primary and and all the stuff well all

00:27:26,310 --> 00:27:31,440
that logic is irrelevant in between

00:27:29,430 --> 00:27:33,000
changes to the checking that's apology

00:27:31,440 --> 00:27:34,440
because if I found the primary one time

00:27:33,000 --> 00:27:36,270
it's going to get a same permanent how

00:27:34,440 --> 00:27:38,040
about a lot of the selection logic by

00:27:36,270 --> 00:27:40,410
caching the choice until the next time I

00:27:38,040 --> 00:27:42,810
update its apology

00:27:40,410 --> 00:27:44,010
so we cache that a lot of invariants are

00:27:42,810 --> 00:27:47,340
cached a lot of these invariants were

00:27:44,010 --> 00:27:50,610
things that had to do with does the

00:27:47,340 --> 00:27:52,530
server support a certain speech is it a

00:27:50,610 --> 00:27:54,480
version 2.6 server is a version of you

00:27:52,530 --> 00:27:56,640
to feature and instead of doing a check

00:27:54,480 --> 00:27:59,640
every time of go get the server version

00:27:56,640 --> 00:28:02,400
and do any you know equals are greater

00:27:59,640 --> 00:28:05,340
than or equals operation against them

00:28:02,400 --> 00:28:06,510
value turn that into a boolean value and

00:28:05,340 --> 00:28:08,790
cache the boolean value so I'm only

00:28:06,510 --> 00:28:10,050
doing the comparisons one time that

00:28:08,790 --> 00:28:12,720
helps a little bit the general message

00:28:10,050 --> 00:28:14,910
is cache stuff anything you can do to

00:28:12,720 --> 00:28:17,130
avoid Perl having to do computations

00:28:14,910 --> 00:28:20,660
will make hot parts of the code fast as

00:28:17,130 --> 00:28:23,400
perl operations are relatively slow

00:28:20,660 --> 00:28:26,160
another thing we stopped doing with stop

00:28:23,400 --> 00:28:27,660
checking for for cryptids long so if you

00:28:26,160 --> 00:28:29,220
have a network connection and you fork

00:28:27,660 --> 00:28:31,110
or you spawn

00:28:29,220 --> 00:28:32,190
generally speaking you get that same

00:28:31,110 --> 00:28:34,920
network connection open on the other

00:28:32,190 --> 00:28:36,890
side I needed to close it and reconnect

00:28:34,920 --> 00:28:39,210
from your on the other side well in

00:28:36,890 --> 00:28:40,710
normal operations you're not working and

00:28:39,210 --> 00:28:42,210
spawning it so I like every time I enter

00:28:40,710 --> 00:28:43,980
your document into the document well

00:28:42,210 --> 00:28:46,110
wait did I sport okay

00:28:43,980 --> 00:28:48,090
let me go into another doc can oh it did

00:28:46,110 --> 00:28:50,550
ice work I like it it's silly to do a

00:28:48,090 --> 00:28:52,710
fork check or a spawn check for every

00:28:50,550 --> 00:28:55,470
single insertion you make people pay a

00:28:52,710 --> 00:28:56,820
cost for that safety on every single

00:28:55,470 --> 00:28:58,560
insertion when it's actually pretty

00:28:56,820 --> 00:29:00,450
weird so instead we move the cost of

00:28:58,560 --> 00:29:02,280
that check to the user and say if you

00:29:00,450 --> 00:29:03,240
fork or if you spa it's on you the user

00:29:02,280 --> 00:29:05,470
to

00:29:03,240 --> 00:29:07,330
reconnect and there's a messaging call

00:29:05,470 --> 00:29:08,740
to say reconnect all the servers and it

00:29:07,330 --> 00:29:11,740
drops all the connections and reconnects

00:29:08,740 --> 00:29:14,710
and it's safe that gets rid of all that

00:29:11,740 --> 00:29:19,990
and I think that's kind of a general

00:29:14,710 --> 00:29:21,820
lesson around if you can don't check for

00:29:19,990 --> 00:29:23,350
rare errors all the time if somehow

00:29:21,820 --> 00:29:25,930
they'll be caught later even if somebody

00:29:23,350 --> 00:29:26,980
does forget to reconnect they're going

00:29:25,930 --> 00:29:30,010
to have problems because going to have

00:29:26,980 --> 00:29:31,210
two sides of a fork trying to talk to a

00:29:30,010 --> 00:29:32,740
server at the same time of the same

00:29:31,210 --> 00:29:35,260
socket and you're going to get errors

00:29:32,740 --> 00:29:37,360
because you'll get gibberish so if

00:29:35,260 --> 00:29:39,190
people make that mistake it will get

00:29:37,360 --> 00:29:41,140
caught in the gibberish so we don't need

00:29:39,190 --> 00:29:42,550
to be checking for rare errors if they

00:29:41,140 --> 00:29:44,530
can be caught later so moving a lot of

00:29:42,550 --> 00:29:46,360
error checks out of the tight loops as

00:29:44,530 --> 00:29:48,310
long as somehow they'll get detected

00:29:46,360 --> 00:29:49,600
later on health and this is generally

00:29:48,310 --> 00:29:51,730
sort of another thing I'll position is

00:29:49,600 --> 00:29:53,800
there's a lot of things we do for safety

00:29:51,730 --> 00:29:56,620
make sure the bargain is value what I

00:29:53,800 --> 00:29:58,240
expected all those checks add up and so

00:29:56,620 --> 00:30:01,000
if you control them and get rid of them

00:29:58,240 --> 00:30:02,320
that's really help so then we get into

00:30:01,000 --> 00:30:05,200
stuff with them so really really

00:30:02,320 --> 00:30:07,000
marginal benefit and I a guy's a little

00:30:05,200 --> 00:30:08,590
bit over whether I should even be doing

00:30:07,000 --> 00:30:11,320
these but this does get really ugly and

00:30:08,590 --> 00:30:12,460
probably controversial and probably half

00:30:11,320 --> 00:30:15,210
the people in this room will probably be

00:30:12,460 --> 00:30:17,500
revolted by what I'm suggesting

00:30:15,210 --> 00:30:18,940
nevertheless like I did try and again

00:30:17,500 --> 00:30:20,770
looking at distributions and looking all

00:30:18,940 --> 00:30:24,220
the times I was still getting some

00:30:20,770 --> 00:30:26,050
marginal benefits in performance by

00:30:24,220 --> 00:30:29,020
doing this so the number one thing is

00:30:26,050 --> 00:30:30,760
avoiding scope right so every time you

00:30:29,020 --> 00:30:32,470
create a new scope and pearl pearl us

00:30:30,760 --> 00:30:34,510
the Perl interpreter does a lot of work

00:30:32,470 --> 00:30:36,220
to set up that scope and get ready to

00:30:34,510 --> 00:30:39,450
clean up that scope at the end so things

00:30:36,220 --> 00:30:42,070
like this if some bad condition happens

00:30:39,450 --> 00:30:43,900
throw ouch throw out just sitting inside

00:30:42,070 --> 00:30:46,050
a scope so before it can do that true

00:30:43,900 --> 00:30:48,970
ouch call the Perl interpreter has to

00:30:46,050 --> 00:30:50,140
set up all the mechanisms it needs so

00:30:48,970 --> 00:30:52,060
that whatever happens in that subroutine

00:30:50,140 --> 00:30:54,100
can be cleaned up at the end of that at

00:30:52,060 --> 00:30:55,300
the end of that block right if you'd

00:30:54,100 --> 00:30:57,250
created variables that have to be

00:30:55,300 --> 00:30:58,960
garbage collected at the end of it so

00:30:57,250 --> 00:31:00,340
all of that machinery gets set up simply

00:30:58,960 --> 00:31:02,500
select them throw a method so the answer

00:31:00,340 --> 00:31:04,150
to that is just use host pick.this

00:31:02,500 --> 00:31:06,250
throw a if condition gets rid of the

00:31:04,150 --> 00:31:07,900
scope same effect in the code but no

00:31:06,250 --> 00:31:10,120
more scope and it turns out if you have

00:31:07,900 --> 00:31:11,980
enough of those in a hot lead if you're

00:31:10,120 --> 00:31:14,310
doing lots of error checking again they

00:31:11,980 --> 00:31:14,310
add up

00:31:14,640 --> 00:31:19,630
similarly here if else if the server

00:31:18,070 --> 00:31:21,910
version is greater than to do something

00:31:19,630 --> 00:31:24,490
otherwise do the legacy version of stuff

00:31:21,910 --> 00:31:26,620
just turn that into a ternary same

00:31:24,490 --> 00:31:28,390
effect in the code no additional scope

00:31:26,620 --> 00:31:35,559
creation no additional cleanup creation

00:31:28,390 --> 00:31:37,750
so what so the idea is you can uglify

00:31:35,559 --> 00:31:39,730
your code make a little harder to read a

00:31:37,750 --> 00:31:40,990
little weird agreed but this is in a

00:31:39,730 --> 00:31:42,309
tight part of the loop but you're really

00:31:40,990 --> 00:31:44,140
really concerned about performance you

00:31:42,309 --> 00:31:46,809
can actually start to see some marginal

00:31:44,140 --> 00:31:47,440
benefit you can avoid intermediate

00:31:46,809 --> 00:31:50,020
variables

00:31:47,440 --> 00:31:52,020
I like intermediate variables for

00:31:50,020 --> 00:31:54,820
readability in certain circumstances

00:31:52,020 --> 00:31:56,380
there's a great book I think it's called

00:31:54,820 --> 00:31:58,510
the art of readable code that has some

00:31:56,380 --> 00:31:59,980
really good stuff on when to use

00:31:58,510 --> 00:32:01,420
intermediate variables and whatnot see

00:31:59,980 --> 00:32:03,460
when does it enhance readability let me

00:32:01,420 --> 00:32:05,200
just retract but interview media

00:32:03,460 --> 00:32:07,120
variables require some sort of memory

00:32:05,200 --> 00:32:09,610
allocations and sort of copy and then

00:32:07,120 --> 00:32:10,900
you use them again you know things that

00:32:09,610 --> 00:32:15,100
copied around a lot so you want to avoid

00:32:10,900 --> 00:32:17,200
those this is really one of the most

00:32:15,100 --> 00:32:20,020
startling things that I discovered

00:32:17,200 --> 00:32:21,690
actually helps avoiding statement and

00:32:20,020 --> 00:32:25,179
what I mean by that is avoiding

00:32:21,690 --> 00:32:27,280
semicolons so here at the top is a bunch

00:32:25,179 --> 00:32:30,010
of assignments assigned this study colon

00:32:27,280 --> 00:32:31,620
a scientist a scientist semicolon I said

00:32:30,010 --> 00:32:34,240
half the people going to be revolted

00:32:31,620 --> 00:32:35,800
Sawyer is over there like with swords in

00:32:34,240 --> 00:32:39,520
the corner like this just so those hands

00:32:35,800 --> 00:32:42,280
in space that I'm saying them when pearl

00:32:39,520 --> 00:32:43,510
sees a semicolon this is a time for the

00:32:42,280 --> 00:32:46,270
Perl interpreter to do several things

00:32:43,510 --> 00:32:47,410
hey have any signal fire hey is there

00:32:46,270 --> 00:32:49,150
anything method is there any memory that

00:32:47,410 --> 00:32:50,830
needs to clean up have any reference

00:32:49,150 --> 00:32:52,450
counts down to zero every single

00:32:50,830 --> 00:32:54,160
semicolon is an opportunity for the Perl

00:32:52,450 --> 00:32:55,480
interpreter to be work if yielding time

00:32:54,160 --> 00:32:57,730
back to the Perl interpreter site

00:32:55,480 --> 00:33:00,220
hey do anything you need to do this is a

00:32:57,730 --> 00:33:01,870
good place to go do that well in this

00:33:00,220 --> 00:33:03,880
case this is just a bunch of assignments

00:33:01,870 --> 00:33:06,070
by wrapping the assignments in

00:33:03,880 --> 00:33:09,220
parentheses and throwing them into comas

00:33:06,070 --> 00:33:11,860
all the same assignments happen in the

00:33:09,220 --> 00:33:14,830
same order but without all the

00:33:11,860 --> 00:33:16,450
intermediate checks and for three maybe

00:33:14,830 --> 00:33:18,790
this is ridiculous but there's a lot of

00:33:16,450 --> 00:33:20,380
places where this you might actually

00:33:18,790 --> 00:33:22,120
have like a whole bunch of things being

00:33:20,380 --> 00:33:24,640
assigned in a row and if you replace all

00:33:22,120 --> 00:33:26,230
those by commas lo and behold you

00:33:24,640 --> 00:33:28,360
actually still see in the pie

00:33:26,230 --> 00:33:30,340
marginal benefits by not letting the

00:33:28,360 --> 00:33:32,890
Perl interpreter check for a bunch of

00:33:30,340 --> 00:33:35,880
stuff that probably haven't happened so

00:33:32,890 --> 00:33:38,200
is all this working and by setting

00:33:35,880 --> 00:33:39,760
really marginal benefits at the end but

00:33:38,200 --> 00:33:41,290
I had a boss who was like this should be

00:33:39,760 --> 00:33:43,330
like you know no more than a 10 or 20

00:33:41,290 --> 00:33:45,700
percent degradation so I would keep

00:33:43,330 --> 00:33:47,080
chipping away and the answers yeah like

00:33:45,700 --> 00:33:49,299
you can actually win by hitting singles

00:33:47,080 --> 00:33:50,799
right enough little bit of increments

00:33:49,299 --> 00:33:52,390
and you can see how many different

00:33:50,799 --> 00:33:55,120
little changes I made right

00:33:52,390 --> 00:33:57,010
bit by bit by bit marching up the

00:33:55,120 --> 00:33:58,169
performance curve to the point where in

00:33:57,010 --> 00:34:00,429
the end yeah I was about a 20%

00:33:58,169 --> 00:34:01,720
performance hit but a 20 percent

00:34:00,429 --> 00:34:03,970
performance hit for a driver there's a

00:34:01,720 --> 00:34:10,000
lot smarter and a lot less night without

00:34:03,970 --> 00:34:11,530
any errors so this is the evolution of

00:34:10,000 --> 00:34:12,879
the flame trim top slim chart was the

00:34:11,530 --> 00:34:14,409
first one I showed where you got a big

00:34:12,879 --> 00:34:16,510
block of loose on right a big block of

00:34:14,409 --> 00:34:17,710
chords in the left the middle one was

00:34:16,510 --> 00:34:20,649
after getting rid of those sort of

00:34:17,710 --> 00:34:22,600
non-work-related sort of hits

00:34:20,649 --> 00:34:25,240
and the final one was after really

00:34:22,600 --> 00:34:26,830
streamlining all the work and while

00:34:25,240 --> 00:34:28,570
getting moving the music's getting rid

00:34:26,830 --> 00:34:30,790
of a lot of nested calls a lot of toy

00:34:28,570 --> 00:34:35,080
room much much flatter and at that point

00:34:30,790 --> 00:34:37,980
when I looked at the top subroutines

00:34:35,080 --> 00:34:42,810
this is what I saw the very top thing is

00:34:37,980 --> 00:34:45,399
core select that means that the biggest

00:34:42,810 --> 00:34:47,169
amount of time in the program in one

00:34:45,399 --> 00:34:49,990
spot is sitting there waiting for the

00:34:47,169 --> 00:34:51,550
metal and this is waiting for the

00:34:49,990 --> 00:34:53,889
network on a benchmark that I'm running

00:34:51,550 --> 00:34:56,109
on my laptop is the best possible

00:34:53,889 --> 00:34:58,570
situation for minimized network latency

00:34:56,109 --> 00:34:59,920
is talking to local hosts well all I'm

00:34:58,570 --> 00:35:01,570
religion is waiting for the server on my

00:34:59,920 --> 00:35:04,960
laptop did you work and give me the

00:35:01,570 --> 00:35:08,020
response back so at that point I said I

00:35:04,960 --> 00:35:09,940
think I'm done right like in a

00:35:08,020 --> 00:35:11,710
real-world application right so like

00:35:09,940 --> 00:35:12,940
this is clearly inserting a whole bunch

00:35:11,710 --> 00:35:14,530
of documents one by one is a very

00:35:12,940 --> 00:35:16,540
artificial benchmark and I went here and

00:35:14,530 --> 00:35:18,490
I did this for insert one and certain

00:35:16,540 --> 00:35:20,320
many update one thing delete one manage

00:35:18,490 --> 00:35:21,490
all you know find one thing find lots of

00:35:20,320 --> 00:35:24,250
them go into all the different major

00:35:21,490 --> 00:35:26,650
parts of the code ran very specific

00:35:24,250 --> 00:35:28,090
benchmarks and because a lot of these

00:35:26,650 --> 00:35:29,590
clients were global by the time I'd done

00:35:28,090 --> 00:35:30,880
insert one a lot of the other stuff got

00:35:29,590 --> 00:35:33,340
faster but there was incremental

00:35:30,880 --> 00:35:34,600
benefits all the way through when I got

00:35:33,340 --> 00:35:36,190
to the point where I said what at this

00:35:34,600 --> 00:35:37,300
point most the time is spent waiting for

00:35:36,190 --> 00:35:38,920
the network in any real-world

00:35:37,300 --> 00:35:39,050
application the network is not going to

00:35:38,920 --> 00:35:40,730
be

00:35:39,050 --> 00:35:42,320
was going to be remote and any

00:35:40,730 --> 00:35:45,230
application is going to be doing actual

00:35:42,320 --> 00:35:48,050
real work on top of this I said we're

00:35:45,230 --> 00:35:52,550
done so that was the point where I

00:35:48,050 --> 00:35:54,100
declared success a lot of the code I had

00:35:52,550 --> 00:35:56,870
written and it was all sitting in like a

00:35:54,100 --> 00:35:59,330
github repo that I used for like scratch

00:35:56,870 --> 00:36:00,770
work I did take a lot of the

00:35:59,330 --> 00:36:03,020
benchmarking code that sort of the you

00:36:00,770 --> 00:36:04,970
know go through all these steps run just

00:36:03,020 --> 00:36:07,460
one piece be able to profile just that

00:36:04,970 --> 00:36:09,500
one piece and I will release that to

00:36:07,460 --> 00:36:11,330
steep and it's called benchmark lab I

00:36:09,500 --> 00:36:13,790
call it a work in progress X if I

00:36:11,330 --> 00:36:15,170
haven't worked on any quite a while it

00:36:13,790 --> 00:36:18,110
doesn't do anything graphing there's

00:36:15,170 --> 00:36:19,790
many charts but it does give you doesn't

00:36:18,110 --> 00:36:21,770
do any analytics on the timing but it

00:36:19,790 --> 00:36:24,250
does give you the facility to do the

00:36:21,770 --> 00:36:26,450
sort of setup run a bunch of stuff

00:36:24,250 --> 00:36:28,310
benchmark appease profile apiece and

00:36:26,450 --> 00:36:29,870
give back the whole bunch of timings

00:36:28,310 --> 00:36:31,370
that makes it very easy to sort of write

00:36:29,870 --> 00:36:32,630
stuff again so if people are interested

00:36:31,370 --> 00:36:35,600
in this technique I encourage you to

00:36:32,630 --> 00:36:36,620
look at benchmark lab contribute do

00:36:35,600 --> 00:36:40,160
other things with it like cool stuff

00:36:36,620 --> 00:36:41,810
give talks and so on so is that I've

00:36:40,160 --> 00:36:44,600
actually almost pretty much got a stack

00:36:41,810 --> 00:36:46,400
on schedule move are there any question

00:36:44,600 --> 00:36:55,970
as I went through things very very good

00:36:46,400 --> 00:36:57,080
yeah I think I might like change my

00:36:55,970 --> 00:36:59,120
routine but instead of hundred questions

00:36:57,080 --> 00:37:00,380
slide I'll have a thank you smarter than

00:36:59,120 --> 00:37:07,340
everyone can applaud and then I'll get a

00:37:00,380 --> 00:37:09,740
question questions yeah remember that

00:37:07,340 --> 00:37:12,140
the G time out call if you timeout is

00:37:09,740 --> 00:37:14,510
trying to give a very bounded time for

00:37:12,140 --> 00:37:16,130
how long we're going to wait and if you

00:37:14,510 --> 00:37:17,420
do this correctly you have to actually

00:37:16,130 --> 00:37:21,380
account for the fact that you could have

00:37:17,420 --> 00:37:23,650
a II interrupted eeeh incr let me know

00:37:21,380 --> 00:37:26,560
that stands for long form

00:37:23,650 --> 00:37:28,420
so it's possible for you honor in a

00:37:26,560 --> 00:37:30,070
select to get an error back and they are

00:37:28,420 --> 00:37:32,500
simply your operating system and

00:37:30,070 --> 00:37:34,630
interrupt this operation and it kind of

00:37:32,500 --> 00:37:36,040
didn't finish and so at that point we

00:37:34,630 --> 00:37:36,970
don't throw an error we want to restart

00:37:36,040 --> 00:37:38,350
but we don't want to restart with the

00:37:36,970 --> 00:37:40,900
same time now we started with we have

00:37:38,350 --> 00:37:42,820
just restart with a smaller time and so

00:37:40,900 --> 00:37:44,320
all the stuff is sitting in a loop and

00:37:42,820 --> 00:37:46,090
we're using time high risk so to figure

00:37:44,320 --> 00:37:47,530
out what time was it and what time is it

00:37:46,090 --> 00:37:49,630
now how much time is left

00:37:47,530 --> 00:37:54,430
tell selectively so that actually we're

00:37:49,630 --> 00:37:55,840
using a lot other questions goal you're

00:37:54,430 --> 00:37:58,410
going to criticize all this stuff I know

00:37:55,840 --> 00:37:58,410
what is it

00:38:03,500 --> 00:38:06,100
yes

00:38:11,340 --> 00:38:14,460
it's true but that's why we have the

00:38:12,810 --> 00:38:15,510
timeout so but the instead of the

00:38:14,460 --> 00:38:17,130
problem is that the read was actually

00:38:15,510 --> 00:38:21,710
saying like please read just four bytes

00:38:17,130 --> 00:38:21,710
instead of instead of instead of saying

00:38:31,770 --> 00:38:34,339
yeah

00:38:37,510 --> 00:38:42,310
yeah and all of this stuff also accounts

00:38:39,940 --> 00:38:44,440
to the fact that if you're using an SSL

00:38:42,310 --> 00:38:46,119
connection you can't actually sort of do

00:38:44,440 --> 00:38:47,440
a select because you'd actually check to

00:38:46,119 --> 00:38:49,660
see if this stuff that the other fella

00:38:47,440 --> 00:38:51,460
frame have already received there's a

00:38:49,660 --> 00:38:54,130
lot of complexity this but the open that

00:38:51,460 --> 00:38:55,630
insight was we wanted to say to the

00:38:54,130 --> 00:38:57,550
network give me everything you've

00:38:55,630 --> 00:38:59,140
already received because maybe that's

00:38:57,550 --> 00:39:00,810
enough maybe the entire document came

00:38:59,140 --> 00:39:03,760
through because the whole document was

00:39:00,810 --> 00:39:06,400
100 bytes instead of just asking for 4

00:39:03,760 --> 00:39:07,890
so now the reads are giving me up to you

00:39:06,400 --> 00:39:09,790
know 8,000 bytes

00:39:07,890 --> 00:39:11,170
whatever the network gives you back then

00:39:09,790 --> 00:39:13,000
check the length on that if it turns out

00:39:11,170 --> 00:39:14,410
that the document needed more than that

00:39:13,000 --> 00:39:15,910
then we just do more ease the idea was

00:39:14,410 --> 00:39:16,900
get as much as we can in one shot

00:39:15,910 --> 00:39:20,010
because the network probably already

00:39:16,900 --> 00:39:20,010
have it yes

00:39:49,269 --> 00:39:54,650
fortunately or unfortunately the case

00:39:51,859 --> 00:39:57,440
maybe the MongoDB wire protocol is

00:39:54,650 --> 00:39:59,059
synchronous so it's send one message get

00:39:57,440 --> 00:40:00,920
one replies much like HTTP and not in

00:39:59,059 --> 00:40:03,230
that sense is like if you imagine like

00:40:00,920 --> 00:40:05,599
I'm going to read an HTTP reply and

00:40:03,230 --> 00:40:07,549
instead of reading the whole reply you

00:40:05,599 --> 00:40:08,660
read like the first few bites do some

00:40:07,549 --> 00:40:10,579
thinking and then read the rest of the

00:40:08,660 --> 00:40:13,390
pipes so we don't have that particular

00:40:10,579 --> 00:40:16,759
problem I did discover a bug which was

00:40:13,390 --> 00:40:18,470
it could didn't actually do this is my

00:40:16,759 --> 00:40:20,450
bug didn't actually count for the fact

00:40:18,470 --> 00:40:23,210
that you might just receive less than 4

00:40:20,450 --> 00:40:28,069
bytes hey give me give me 4 bytes in so

00:40:23,210 --> 00:40:29,599
here's one so actually there now there

00:40:28,069 --> 00:40:31,130
is the stuff to say oh well if you give

00:40:29,599 --> 00:40:33,289
me less than 4 now I have to actually go

00:40:31,130 --> 00:40:36,019
and try to get 4 and figure out the

00:40:33,289 --> 00:40:38,180
length to be 0 any of you it happens

00:40:36,019 --> 00:40:38,779
very rarely but you know networks are

00:40:38,180 --> 00:40:44,140
funny

00:40:38,779 --> 00:40:44,140
it also treat other questions yeah

00:40:47,090 --> 00:40:53,180
I did not I sort of the mind that the

00:40:50,870 --> 00:40:54,350
modern day and age memory is memory and

00:40:53,180 --> 00:40:55,400
if people really care about memory

00:40:54,350 --> 00:40:56,870
that's probably not using Perl in the

00:40:55,400 --> 00:40:58,880
first place

00:40:56,870 --> 00:41:01,190
they're probably writing it in CEO Super

00:40:58,880 --> 00:41:02,840
Plus or something with a little more it

00:41:01,190 --> 00:41:05,360
wasn't a major consideration but mostly

00:41:02,840 --> 00:41:06,800
the Buffs view MongoDB is advertised as

00:41:05,360 --> 00:41:09,230
being fast and that's the thing that

00:41:06,800 --> 00:41:11,450
most people if they see a degradation

00:41:09,230 --> 00:41:12,560
we're going to stir it up I got a sign

00:41:11,450 --> 00:41:13,730
we said one more question but I want

00:41:12,560 --> 00:41:15,080
actually take one more question because

00:41:13,730 --> 00:41:19,070
I did such a great job catching up so

00:41:15,080 --> 00:41:21,340
you had a question dr. benchmark laughs

00:41:19,070 --> 00:41:21,340
yeah

00:41:27,530 --> 00:41:32,070
no because I almost because the timing

00:41:29,910 --> 00:41:33,780
is only around a small bit yeah I think

00:41:32,070 --> 00:41:36,200
like this is not something I would

00:41:33,780 --> 00:41:38,640
recommend in almost any search of stamp

00:41:36,200 --> 00:41:41,760
however how many people have bosses who

00:41:38,640 --> 00:41:43,380
ask for unreasonable thing some people

00:41:41,760 --> 00:41:46,590
in the room okay so one of the bosses

00:41:43,380 --> 00:41:47,700
this has to be as fast as possible you

00:41:46,590 --> 00:41:49,410
know like you start looking for

00:41:47,700 --> 00:41:50,490
everything you can possibly find all

00:41:49,410 --> 00:41:53,670
right thank you all very much

00:41:50,490 --> 00:41:58,340
I think we're roughly close to time and

00:41:53,670 --> 00:41:58,340

YouTube URL: https://www.youtube.com/watch?v=_PJIVVGAZqA


