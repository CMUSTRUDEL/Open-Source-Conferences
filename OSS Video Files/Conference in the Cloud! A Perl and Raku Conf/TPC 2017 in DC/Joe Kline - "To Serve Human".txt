Title: Joe Kline - "To Serve Human"
Publication date: 2017-06-24
Playlist: TPC 2017 in DC
Description: 
	The code we write changes peoples lives, but we often don't think about our impact as IT professionals. The revolution in job automation is a current example of technological impact on society.

Examples of automation, including self-driving cars and other IT choices, will be discussed to illustrate the need to reflect on the consequences of our work.

Sysadmin at Purdue University and member of Purdue Perl Mongers and Hack Lafayette.
Captions: 
	00:00:01,010 --> 00:00:07,710
alright I'm dedicating this talk to a

00:00:03,689 --> 00:00:12,320
Kip Hampton rest in peace and we're here

00:00:07,710 --> 00:00:14,809
to talk about to serve humans a cookbook

00:00:12,320 --> 00:00:18,960
why are we here

00:00:14,809 --> 00:00:21,240
notice an IP the code we write changes

00:00:18,960 --> 00:00:24,720
people's lives but we sometimes don't

00:00:21,240 --> 00:00:26,430
always think about that a great example

00:00:24,720 --> 00:00:34,130
of this I think is the automation of

00:00:26,430 --> 00:00:37,950
jobs self-driving cars cron jobs in

00:00:34,130 --> 00:00:41,870
social media it's nice in the bot is

00:00:37,950 --> 00:00:41,870
kind enough to let you know it's a bot

00:00:41,989 --> 00:00:45,809
sort of a brief history of actually the

00:00:44,520 --> 00:00:49,710
Industrial Revolution

00:00:45,809 --> 00:00:51,239
it started in textiles basically one of

00:00:49,710 --> 00:00:52,680
the first things was automated looms it

00:00:51,239 --> 00:00:55,320
would automatically go back and forth

00:00:52,680 --> 00:00:58,609
loom so a human didn't have to show up

00:00:55,320 --> 00:01:02,090
back and forth speeds could be faster

00:00:58,609 --> 00:01:06,210
that was around 7 to 33 and then in the

00:01:02,090 --> 00:01:11,610
1764 we got a spinning jenny to make the

00:01:06,210 --> 00:01:13,500
threads and yarn bastard and then

00:01:11,610 --> 00:01:14,610
automated the steam power kicked in

00:01:13,500 --> 00:01:18,990
because also this was like you know

00:01:14,610 --> 00:01:22,470
water wheels and then this is a what's

00:01:18,990 --> 00:01:24,270
called a spinning frame to make this not

00:01:22,470 --> 00:01:26,610
the spinny mule to make multiple kinds

00:01:24,270 --> 00:01:30,180
of thread at the same time of different

00:01:26,610 --> 00:01:32,640
varieties and strains and then well this

00:01:30,180 --> 00:01:34,680
is a modern power loom but then the

00:01:32,640 --> 00:01:36,570
whole loom process you know got

00:01:34,680 --> 00:01:38,640
automated too and put a bunch of people

00:01:36,570 --> 00:01:41,310
out of work you know all from you know

00:01:38,640 --> 00:01:43,259
in about a hundred years after got the

00:01:41,310 --> 00:01:45,350
switch off at the power loom and the

00:01:43,259 --> 00:01:49,710
invention of the sewing machine in the

00:01:45,350 --> 00:01:53,850
1830s that drove the demand for prepared

00:01:49,710 --> 00:01:55,259
and industrialized cloth in this so in a

00:01:53,850 --> 00:01:58,640
matter of years we went from something

00:01:55,259 --> 00:02:06,560
like this to something like that

00:01:58,640 --> 00:02:09,509
that's textiles in the 1800's 1870 about

00:02:06,560 --> 00:02:11,970
70 to 80 percent of the people were

00:02:09,509 --> 00:02:13,380
involved in agriculture in some way by

00:02:11,970 --> 00:02:17,010
2008 that number

00:02:13,380 --> 00:02:19,230
up to about 2% and we're still finding

00:02:17,010 --> 00:02:21,420
ways you know this is kind of how it's

00:02:19,230 --> 00:02:23,460
done now even kind of semi-automated to

00:02:21,420 --> 00:02:27,300
finalize to even get the number of

00:02:23,460 --> 00:02:31,250
people involved in agriculture below

00:02:27,300 --> 00:02:34,350
even 2% number itself time marches on

00:02:31,250 --> 00:02:36,270
and even where other parts industrial

00:02:34,350 --> 00:02:39,990
over the industrial revolution like that

00:02:36,270 --> 00:02:42,240
steel in the 1980s that took about ten

00:02:39,990 --> 00:02:47,040
person hours to make one ton of finished

00:02:42,240 --> 00:02:49,410
steel by 2004 that numbers down to three

00:02:47,040 --> 00:02:51,840
person hours per ton and summits in some

00:02:49,410 --> 00:02:55,200
plants are getting one ton of finished

00:02:51,840 --> 00:03:01,640
ale this is like from raw or coke and

00:02:55,200 --> 00:03:03,930
everything to make new steel but um

00:03:01,640 --> 00:03:11,610
moving on to other things in terms of

00:03:03,930 --> 00:03:12,870
automation in 1977 we first started

00:03:11,610 --> 00:03:14,730
doing any kind of research into

00:03:12,870 --> 00:03:17,700
autonomous vehicles but I think the

00:03:14,730 --> 00:03:20,940
seminal moment in software vehicles was

00:03:17,700 --> 00:03:23,220
in 2004 with a Grand Challenge and DARPA

00:03:20,940 --> 00:03:29,310
so hey here's much money and trying to

00:03:23,220 --> 00:03:31,500
make a self-driving car and and in the

00:03:29,310 --> 00:03:34,380
13 years later we got autonomous

00:03:31,500 --> 00:03:36,210
vehicles kind of everywhere nowadays and

00:03:34,380 --> 00:03:39,240
it's going to have a big impact of thing

00:03:36,210 --> 00:03:41,370
because this is a from a couple years

00:03:39,240 --> 00:03:44,250
ago impaired the thing about common jobs

00:03:41,370 --> 00:03:47,100
and the most common job in the u.s. by

00:03:44,250 --> 00:03:50,610
state is truck driver or people involved

00:03:47,100 --> 00:03:52,670
in driving some way there's 1.7 million

00:03:50,610 --> 00:03:55,410
to three and half million people

00:03:52,670 --> 00:03:58,080
involved with that these jobs make about

00:03:55,410 --> 00:04:00,600
forty thousand dollars a year and you

00:03:58,080 --> 00:04:04,680
don't need a anything beyond a high

00:04:00,600 --> 00:04:07,050
school diploma to do this and I say in

00:04:04,680 --> 00:04:09,720
13 years we've gone from it just being

00:04:07,050 --> 00:04:12,840
this really tough technological feat to

00:04:09,720 --> 00:04:16,320
having actual cars in city streets

00:04:12,840 --> 00:04:17,820
driving by themselves the pace of this

00:04:16,320 --> 00:04:19,830
change you take a generation or two I

00:04:17,820 --> 00:04:22,229
mean 100 years to go from kind of

00:04:19,830 --> 00:04:25,050
handlooms to power looms and sewing

00:04:22,229 --> 00:04:26,460
machines now 13 years you know time it

00:04:25,050 --> 00:04:27,150
goes from kindergarten to graduate in

00:04:26,460 --> 00:04:29,669
high school

00:04:27,150 --> 00:04:34,830
this change I mean we're just destroying

00:04:29,669 --> 00:04:38,520
jobs is really fast rate and as a friend

00:04:34,830 --> 00:04:40,889
said we've kind of used to be like in

00:04:38,520 --> 00:04:44,130
the waterfall version of unemployment

00:04:40,889 --> 00:04:49,770
our unemployed people and sprints in an

00:04:44,130 --> 00:04:51,750
iterative manner and this is because we

00:04:49,770 --> 00:04:54,780
found ways to take the tools we've had

00:04:51,750 --> 00:04:57,960
and I'm easy either to either easy to

00:04:54,780 --> 00:04:59,580
use the tools could do the job or

00:04:57,960 --> 00:05:04,050
outright replacing jobs with better

00:04:59,580 --> 00:05:05,910
tools tools themselves I don't think

00:05:04,050 --> 00:05:09,479
have any kind of ethics or morals or

00:05:05,910 --> 00:05:10,770
kind of an amoral entity and the kind of

00:05:09,479 --> 00:05:14,340
dual life that typically they're

00:05:10,770 --> 00:05:17,160
creative or destructive and and what

00:05:14,340 --> 00:05:19,699
they do and I think it's the person that

00:05:17,160 --> 00:05:22,710
wields that tool that determines the

00:05:19,699 --> 00:05:23,820
ethics of the tool and what and then was

00:05:22,710 --> 00:05:27,169
going to be used for creation or

00:05:23,820 --> 00:05:29,970
destruction even open-source is a tool

00:05:27,169 --> 00:05:34,590
the methods and processes of the open

00:05:29,970 --> 00:05:36,900
source method was applied to war I'm

00:05:34,590 --> 00:05:39,810
John Robert this book about ten years

00:05:36,900 --> 00:05:43,409
ago basically described these insurgency

00:05:39,810 --> 00:05:44,940
of the 2003 Iraq war as the the

00:05:43,409 --> 00:05:47,310
insurgent groups used open-source

00:05:44,940 --> 00:05:51,919
methods and processes to exchange

00:05:47,310 --> 00:05:55,050
information and in competing for people

00:05:51,919 --> 00:06:00,300
to fight against the the US and their

00:05:55,050 --> 00:06:02,490
allies so excited D terminals are used

00:06:00,300 --> 00:06:04,590
it's the people using them and their

00:06:02,490 --> 00:06:07,289
decisions

00:06:04,590 --> 00:06:09,449
this is dr. ten Bensel from Notre Dame

00:06:07,289 --> 00:06:13,110
she does research in this is decision

00:06:09,449 --> 00:06:15,030
making negotiations and ethics as well

00:06:13,110 --> 00:06:17,039
so the piece about why people commit

00:06:15,030 --> 00:06:20,699
fraud and the reference to an experiment

00:06:17,039 --> 00:06:23,070
she did where one group is primed to

00:06:20,699 --> 00:06:26,400
think about you know decision in terms

00:06:23,070 --> 00:06:28,620
of a business mindset another group in

00:06:26,400 --> 00:06:32,669
ethical mindset that she distracted with

00:06:28,620 --> 00:06:34,590
the task and then gazing the opportunity

00:06:32,669 --> 00:06:38,240
to do a separate task that they could

00:06:34,590 --> 00:06:38,240
cheat app and

00:06:38,719 --> 00:06:43,309
we're given the opportunity people

00:06:40,249 --> 00:06:45,739
tended to cheat or live ever and this

00:06:43,309 --> 00:06:47,989
kind of self validation it I think

00:06:45,739 --> 00:06:50,269
organizations are less than the sum of

00:06:47,989 --> 00:06:52,519
the ethics and morals of the individuals

00:06:50,269 --> 00:06:54,409
that make up the group and so I think

00:06:52,519 --> 00:06:55,849
it's easy in there I guess the research

00:06:54,409 --> 00:06:57,649
kind of X but it's easy to substitute

00:06:55,849 --> 00:07:01,369
the organization's ethics and morals

00:06:57,649 --> 00:07:02,629
instead of your own and I'm not going to

00:07:01,369 --> 00:07:04,159
go describe what ethical behavior is

00:07:02,629 --> 00:07:07,069
because as son goes said that the

00:07:04,159 --> 00:07:09,110
squishy subject and it could fill up

00:07:07,069 --> 00:07:14,449
even a a semester long course just on

00:07:09,110 --> 00:07:16,909
the intro of ethics but because of IT

00:07:14,449 --> 00:07:19,399
can be part of something that takes your

00:07:16,909 --> 00:07:20,539
work and and does something maybe bad

00:07:19,399 --> 00:07:23,419
with it

00:07:20,539 --> 00:07:26,119
you're writing the software that you

00:07:23,419 --> 00:07:28,129
know it analyzes the emissions of a

00:07:26,119 --> 00:07:30,649
vehicle and someone asks you hey what

00:07:28,129 --> 00:07:33,529
state is the vehicle in and then take

00:07:30,649 --> 00:07:37,549
your data and information and does bad

00:07:33,529 --> 00:07:38,899
things with it not ever I mean but you

00:07:37,549 --> 00:07:40,459
had to be involved and know that here

00:07:38,899 --> 00:07:44,269
what you're doing was made missing with

00:07:40,459 --> 00:07:49,969
an emissions test and then there's the

00:07:44,269 --> 00:07:54,169
current I guess bad boy of a may be

00:07:49,969 --> 00:07:56,300
dubious behavior do things like oh we

00:07:54,169 --> 00:07:58,069
delete you delete the app from your

00:07:56,300 --> 00:08:01,239
phone but it still sends private

00:07:58,069 --> 00:08:04,069
information back to the app owner

00:08:01,239 --> 00:08:06,019
without you knowing it or it does things

00:08:04,069 --> 00:08:07,669
like oh I think you're a cop so I'm not

00:08:06,019 --> 00:08:11,659
going to send any vehicles near by you

00:08:07,669 --> 00:08:13,719
especially in Mena municipalities where

00:08:11,659 --> 00:08:19,429
it's not exactly legal to have a

00:08:13,719 --> 00:08:24,860
something like uber so yes yeah they

00:08:19,429 --> 00:08:26,869
have lots at and anytime we this happens

00:08:24,860 --> 00:08:27,860
and we're it's okay with like if you're

00:08:26,869 --> 00:08:29,719
working the company

00:08:27,860 --> 00:08:31,489
you see these things you let it happen

00:08:29,719 --> 00:08:37,009
is especially if your leader or company

00:08:31,489 --> 00:08:41,240
it ignores us to that behavior and this

00:08:37,009 --> 00:08:45,709
becomes normal but what do we do how do

00:08:41,240 --> 00:08:48,439
we protect ourselves or what do we do

00:08:45,709 --> 00:08:51,490
when we have this bad behavior I think

00:08:48,439 --> 00:08:53,440
traditionally we use bad best practices

00:08:51,490 --> 00:08:55,660
built over time like passwords you know

00:08:53,440 --> 00:08:57,190
way back in the day we didn't have

00:08:55,660 --> 00:08:59,920
passes so that's mostly for non metal

00:08:57,190 --> 00:09:02,760
machines even on network devices we

00:08:59,920 --> 00:09:04,959
would store the password in plain text

00:09:02,760 --> 00:09:07,120
eventually you know we would hey which

00:09:04,959 --> 00:09:08,950
give it a cryptographic function you

00:09:07,120 --> 00:09:11,380
know will store the encrypted password

00:09:08,950 --> 00:09:13,209
we need to we can send back the password

00:09:11,380 --> 00:09:14,920
to the individual but now the most part

00:09:13,209 --> 00:09:16,930
best practices revolve around a hash

00:09:14,920 --> 00:09:21,490
function even I who store in the pass or

00:09:16,930 --> 00:09:22,810
don't know the password is so but what

00:09:21,490 --> 00:09:24,070
do we do when we're I'd say the cutting

00:09:22,810 --> 00:09:25,450
edge of whatever technology you're

00:09:24,070 --> 00:09:29,020
developing your doing and we have no

00:09:25,450 --> 00:09:31,300
best practice because it's so new we

00:09:29,020 --> 00:09:36,490
haven't built up visa the IT wisdom deal

00:09:31,300 --> 00:09:39,940
with these things I think we choose our

00:09:36,490 --> 00:09:41,529
own ethical code to look at or at least

00:09:39,940 --> 00:09:44,709
kind of like we teach kids when when

00:09:41,529 --> 00:09:45,580
they're in peer pressure or how to deal

00:09:44,709 --> 00:09:48,010
with drug because we think about

00:09:45,580 --> 00:09:50,050
situation how would we react kind of

00:09:48,010 --> 00:09:52,930
prepare yourself for that eventualities

00:09:50,050 --> 00:09:57,100
someone does something you don't think

00:09:52,930 --> 00:09:59,050
is a good choice mighty wise turn give

00:09:57,100 --> 00:10:01,630
examples of when we stand up to people

00:09:59,050 --> 00:10:08,020
of it some thought experiments to think

00:10:01,630 --> 00:10:09,610
about is um what do we do and cars no

00:10:08,020 --> 00:10:11,170
one to break the law I mean Thomas

00:10:09,610 --> 00:10:14,230
vehicles nominally will follow the law

00:10:11,170 --> 00:10:17,700
what do we do when we make an AI to do

00:10:14,230 --> 00:10:20,829
predictive policing would we feed our

00:10:17,700 --> 00:10:22,750
personal social political or cultural

00:10:20,829 --> 00:10:24,970
biases into that system

00:10:22,750 --> 00:10:26,620
are we being sure that the system is

00:10:24,970 --> 00:10:29,560
fair or we're making the right choices

00:10:26,620 --> 00:10:33,970
for that especially when the AI like

00:10:29,560 --> 00:10:38,160
this is from Elysium when the AI is the

00:10:33,970 --> 00:10:38,160
judge jury maybe even lawyer for us

00:10:39,570 --> 00:10:44,350
sometimes harm is really accidental I

00:10:41,950 --> 00:10:47,560
mean we just I mean just by the basis of

00:10:44,350 --> 00:10:49,360
you know software itself is difficult

00:10:47,560 --> 00:10:53,100
sometimes to get right even when we're

00:10:49,360 --> 00:10:53,100
intentional about it

00:10:54,700 --> 00:11:03,520
and what most of us don't think we're

00:10:57,400 --> 00:11:05,980
making Skynet but we don't always really

00:11:03,520 --> 00:11:07,990
know what what we're building leads to

00:11:05,980 --> 00:11:09,970
eventually but we still have we still

00:11:07,990 --> 00:11:14,170
have choices to make and there is no

00:11:09,970 --> 00:11:15,430
fate but what we make but how do we how

00:11:14,170 --> 00:11:18,990
do we avoid that you know first another

00:11:15,430 --> 00:11:21,400
tactic you know I think we need to

00:11:18,990 --> 00:11:24,610
examine ourselves examine what we're

00:11:21,400 --> 00:11:26,470
doing and try and maybe make someone

00:11:24,610 --> 00:11:27,790
more or more utopian solution or of a

00:11:26,470 --> 00:11:32,290
better solution you know something

00:11:27,790 --> 00:11:34,720
dystopian Oh another example is um is

00:11:32,290 --> 00:11:37,600
from Herodotus and talking about the

00:11:34,720 --> 00:11:38,980
Persians um we don't maybe have to

00:11:37,600 --> 00:11:40,650
follow this literally in terms of you

00:11:38,980 --> 00:11:45,030
know getting drunk and you know

00:11:40,650 --> 00:11:48,040
considering that but I think if we stop

00:11:45,030 --> 00:11:50,200
change our frame of mind like in 10

00:11:48,040 --> 00:11:51,820
dreadful sin we're in a business mindset

00:11:50,200 --> 00:11:55,000
maybe getting an extra mindset or just

00:11:51,820 --> 00:12:00,490
any other mindset and consider what

00:11:55,000 --> 00:12:05,830
we're doing that's helpful - couple

00:12:00,490 --> 00:12:07,570
thing - or if they can't get our own

00:12:05,830 --> 00:12:08,770
mindset find someone else they're almost

00:12:07,570 --> 00:12:12,640
always people are going to have a

00:12:08,770 --> 00:12:14,260
different viewpoint than we are talk to

00:12:12,640 --> 00:12:19,090
the thought it's kind of a diversity of

00:12:14,260 --> 00:12:21,220
opinion and thought they're not going to

00:12:19,090 --> 00:12:23,140
necessarily suffer from the curse of

00:12:21,220 --> 00:12:25,270
knowledge about us knowing justice I

00:12:23,140 --> 00:12:27,100
mean we know this specific problem we're

00:12:25,270 --> 00:12:29,890
trying to solve for the solution of

00:12:27,100 --> 00:12:33,010
proposing talking through that with

00:12:29,890 --> 00:12:35,710
someone else might allow them to spot

00:12:33,010 --> 00:12:39,760
the holes and weaknesses in the solution

00:12:35,710 --> 00:12:41,950
we're working on and it's to underscore

00:12:39,760 --> 00:12:45,880
that we don't always know where our

00:12:41,950 --> 00:12:46,870
choices are going to lead us but I think

00:12:45,880 --> 00:12:51,610
it doesn't expend some time

00:12:46,870 --> 00:12:54,250
contemplating what we're doing just

00:12:51,610 --> 00:12:55,420
because I've got to reflect sometimes

00:12:54,250 --> 00:12:59,320
the choices we make do we want to

00:12:55,420 --> 00:13:01,060
hopefully make something that's a place

00:12:59,320 --> 00:13:05,230
where we kind of work for the Machine so

00:13:01,060 --> 00:13:07,140
to speak or try and create place where

00:13:05,230 --> 00:13:09,490
the machines work for us and

00:13:07,140 --> 00:13:11,560
the choices you make make a place where

00:13:09,490 --> 00:13:15,340
L we build upon our successes

00:13:11,560 --> 00:13:21,330
technologically and create um better and

00:13:15,340 --> 00:13:21,330
better thing thank you any questions

00:14:04,920 --> 00:14:07,939
I'm done

00:14:12,110 --> 00:14:16,820
that's a difficult question I mean what

00:14:14,840 --> 00:14:28,580
choices are you going to make as a

00:14:16,820 --> 00:14:30,050
worker I mean like if you worked at VW

00:14:28,580 --> 00:14:31,250
or uber it's like okay I want to quit

00:14:30,050 --> 00:14:33,050
over this I mean I don't think most

00:14:31,250 --> 00:14:35,450
people think about what am I willing to

00:14:33,050 --> 00:14:37,100
quit my job over I mean it's I don't

00:14:35,450 --> 00:14:39,200
think about it I mean but I mean I work

00:14:37,100 --> 00:14:45,160
academia and so it's like I consider

00:14:39,200 --> 00:14:45,160
myself so closely but I mean yeah yes

00:14:52,660 --> 00:14:55,260
right

00:15:10,789 --> 00:15:24,019
but I would yes to be completed yeah

00:15:20,459 --> 00:15:24,019
Klaus it's happy

00:15:35,290 --> 00:15:41,380
right plus it's part of it is like part

00:15:38,230 --> 00:15:44,560
of it is like said um the organizational

00:15:41,380 --> 00:15:46,510
ethics take over it's like that's the

00:15:44,560 --> 00:15:48,010
way we do it I mean we don't think about

00:15:46,510 --> 00:15:51,910
your like United right I mean they had

00:15:48,010 --> 00:15:54,400
policies too and this felon or that's

00:15:51,910 --> 00:15:56,500
kind of this evolution that I mean they

00:15:54,400 --> 00:15:58,330
didn't think about because there wasn't

00:15:56,500 --> 00:16:01,360
a good culture like the normalization

00:15:58,330 --> 00:16:03,070
part um the the example you walk by is

00:16:01,360 --> 00:16:04,990
that becomes a standard if you see

00:16:03,070 --> 00:16:08,050
someone you know actually harassing

00:16:04,990 --> 00:16:09,430
somebody and you just that becomes be

00:16:08,050 --> 00:16:12,520
especially for your leader type if you

00:16:09,430 --> 00:16:14,170
walk by someone doing something that is

00:16:12,520 --> 00:16:16,420
normed nominally should be wrong even in

00:16:14,170 --> 00:16:19,930
the company by policy that becomes the

00:16:16,420 --> 00:16:21,760
policy and I said we don't know we don't

00:16:19,930 --> 00:16:23,920
think about it it's like a lot of times

00:16:21,760 --> 00:16:25,240
like in the Delta case it's like there's

00:16:23,920 --> 00:16:28,390
algorithms that we've got to get rid of

00:16:25,240 --> 00:16:30,370
these we've got to get these our

00:16:28,390 --> 00:16:33,340
employees on the plane now we need to

00:16:30,370 --> 00:16:35,200
get X number of people off and the algum

00:16:33,340 --> 00:16:39,400
said you can only offer $800 where ever

00:16:35,200 --> 00:16:44,380
it was when the paper said I got to do

00:16:39,400 --> 00:16:47,830
this it's kind of Raziel yeah I mean

00:16:44,380 --> 00:16:49,600
this is all I mean yeah this is those

00:16:47,830 --> 00:16:51,690
you know I won't call it a quagmire some

00:16:49,600 --> 00:16:53,620
of squishy things we don't think about

00:16:51,690 --> 00:16:54,970
and I'm not supposed to ethics with

00:16:53,620 --> 00:16:57,010
ethics is the shorthand we don't think

00:16:54,970 --> 00:16:58,900
about the consequences of our action

00:16:57,010 --> 00:17:01,990
even some like the poor guy that took

00:16:58,900 --> 00:17:05,140
down s3 last year he thought was just

00:17:01,990 --> 00:17:08,589
taking on a small pod no I took up these

00:17:05,140 --> 00:17:09,760
two data center as three well um we

00:17:08,589 --> 00:17:10,930
don't know what I mean even for those

00:17:09,760 --> 00:17:12,280
things we sometimes you don't think

00:17:10,930 --> 00:17:15,250
about because we think we're doing one

00:17:12,280 --> 00:17:18,030
thing and their actions accidentally

00:17:15,250 --> 00:17:18,030
otherwise doing us

00:17:23,589 --> 00:17:26,589
mostly

00:17:39,720 --> 00:17:51,970
it's very great was also ethics this

00:17:50,020 --> 00:17:53,890
thing what ethics in terms of okay I'm a

00:17:51,970 --> 00:17:56,590
hacker for the NSA I'm the good guy

00:17:53,890 --> 00:18:00,520
but what if you're the hacker for China

00:17:56,590 --> 00:18:02,710
or Russia I mean you're standing up for

00:18:00,520 --> 00:18:05,110
your country's interests in the world I

00:18:02,710 --> 00:18:07,180
mean ethics is not necessarily

00:18:05,110 --> 00:18:10,780
relativity but there is could be just

00:18:07,180 --> 00:18:13,060
the way look at the problem I mean I'm

00:18:10,780 --> 00:18:14,920
kind of moral absolutist but ethics you

00:18:13,060 --> 00:18:20,800
can look at you know Rashomon I can look

00:18:14,920 --> 00:18:22,360
at the same situation and okay from two

00:18:20,800 --> 00:18:25,780
different perspectives and we're both

00:18:22,360 --> 00:18:27,310
kind of right it's you know so it's I

00:18:25,780 --> 00:18:29,380
just want people to think about what

00:18:27,310 --> 00:18:35,860
they do every from time to time it's

00:18:29,380 --> 00:18:37,090
hard to be introspective right and we

00:18:35,860 --> 00:18:41,920
cuz like the effect of talking about the

00:18:37,090 --> 00:18:44,770
AI warm or feeding it's like the the

00:18:41,920 --> 00:18:46,240
drug use rates between ask Americans and

00:18:44,770 --> 00:18:50,580
non-white Hispanics are roughly the same

00:18:46,240 --> 00:18:53,590
in terms of people using drugs however

00:18:50,580 --> 00:18:58,600
more after Americans are arrested for

00:18:53,590 --> 00:19:00,400
drug use so when you make algorithms

00:18:58,600 --> 00:19:02,650
it's going to look more for in act

00:19:00,400 --> 00:19:07,080
American fees or their specific social

00:19:02,650 --> 00:19:10,270
economic areas as opposed to well let's

00:19:07,080 --> 00:19:12,900
we've got to think about that data one

00:19:10,270 --> 00:19:15,900
last question before I get to compensate

00:19:12,900 --> 00:19:15,900
yes

00:19:19,730 --> 00:19:25,220
I don't know again I give a a virgin's

00:19:23,270 --> 00:19:26,930
talk in October 2015 and they're like

00:19:25,220 --> 00:19:29,090
you know it's like when I talk to this

00:19:26,930 --> 00:19:30,680
about friends it's like I'm kind of

00:19:29,090 --> 00:19:32,450
defeated it's going to come off and roll

00:19:30,680 --> 00:19:34,760
over us and you know the people that own

00:19:32,450 --> 00:19:36,620
the machines are going to roll it it's

00:19:34,760 --> 00:19:39,860
hard you just try and be incremental so

00:19:36,620 --> 00:19:41,920
I guess try and do the right thing as

00:19:39,860 --> 00:19:45,140
best you can all the time it's like I

00:19:41,920 --> 00:19:46,940
don't know I mean you just fight you got

00:19:45,140 --> 00:19:50,240
it for you you even a little bit right I

00:19:46,940 --> 00:19:52,910
mean the person that runs and she's not

00:19:50,240 --> 00:19:55,190
there slow is doing more physically than

00:19:52,910 --> 00:19:57,470
you sitting on the couch you're doing

00:19:55,190 --> 00:20:00,710
something react like a stock you don't

00:19:57,470 --> 00:20:01,790
have to be that actors start being a

00:20:00,710 --> 00:20:06,350
little bit more active and if we

00:20:01,790 --> 00:20:08,270
connected trying to understand your area

00:20:06,350 --> 00:20:12,070
and try and make it a little bit better

00:20:08,270 --> 00:20:12,070

YouTube URL: https://www.youtube.com/watch?v=o9V6O8qZfcc


