Title: Andrew Grangaard (‎spazm‎) - ‎Computer science for the self taught hacker‎ (20
Publication date: 2014-06-24
Playlist: YAPC::NA 2014
Description: 
	Description:
Are you a programmer without a Computer Science background? Self-conscious about what you might be missing? Don't have a favorite sorting algorithm? Let's get that chip of your shoulder! I'll introduce you to CS theory: ideas, terminology, math, and nomenclature and then show you how to dig deeper by leveraging Open Courses (and your local library)

Abstract:
What is Computer Science and how is it different than Programming? What did I miss by jumping straight into programming?
This quick tour of topics covered in introductory computer science courses discusses why those topics are considered important. I'll provide links to delve deeper in books and online courses.

After this talk, you'll be able to answer:
Why do we discuss complexity?
How do we reason about programs? What can we prove? What can't we prove?
What is Big-O notation and why should I care?
Why do data structures matter?
Why do we care about sorting?
Captions: 
	00:00:07,650 --> 00:00:14,940
all righty I got my thumbs up can people

00:00:11,410 --> 00:00:18,369
kind of here now you can hear excellent

00:00:14,940 --> 00:00:21,490
here we are on our computer science for

00:00:18,369 --> 00:00:24,279
the self-taught hacker a brief

00:00:21,490 --> 00:00:27,369
introduction to CS with Chipmunks all

00:00:24,279 --> 00:00:30,099
right squirrel squirrel squirrel that

00:00:27,369 --> 00:00:32,680
will be important later it's a really

00:00:30,099 --> 00:00:34,449
pretty rat so yeah

00:00:32,680 --> 00:00:37,809
are you a programmer without a computer

00:00:34,449 --> 00:00:39,339
science background so yeah how many

00:00:37,809 --> 00:00:44,440
people here have a classics yes

00:00:39,339 --> 00:00:48,629
education okay a few a EE like myself

00:00:44,440 --> 00:00:54,150
you know something close physics econ

00:00:48,629 --> 00:00:57,640
liberal arts GED commenced from

00:00:54,150 --> 00:01:00,280
kindergarten at some point all right so

00:00:57,640 --> 00:01:04,210
let's yeah everything's on the computers

00:01:00,280 --> 00:01:05,619
now so I know I spent a while as a sub

00:01:04,210 --> 00:01:06,909
stop guy thinking oh my goodness they

00:01:05,619 --> 00:01:08,350
know all this stuff and what am I

00:01:06,909 --> 00:01:13,899
missing out on and you know get a little

00:01:08,350 --> 00:01:15,909
chip on my shoulder that subscribe to I

00:01:13,899 --> 00:01:18,159
believe that we just saw that yesterday

00:01:15,909 --> 00:01:21,520
in the entire talks so if you were here

00:01:18,159 --> 00:01:23,530
for those circles I'm not going to give

00:01:21,520 --> 00:01:24,850
you a year's worth of just education as

00:01:23,530 --> 00:01:30,070
much as I might try but hopefully I'll

00:01:24,850 --> 00:01:31,899
give you enough to get interested to

00:01:30,070 --> 00:01:34,149
learn more and to feel that it's not

00:01:31,899 --> 00:01:35,859
overwhelming and and maybe you've

00:01:34,149 --> 00:01:38,289
already got number four when you use a

00:01:35,859 --> 00:01:40,509
hash verse doesn't right I'm at which

00:01:38,289 --> 00:01:45,490
point I'm pretty much already done cuz

00:01:40,509 --> 00:01:49,020
you already know that so a typical first

00:01:45,490 --> 00:01:51,249
year intro to CS you need to cover

00:01:49,020 --> 00:01:53,319
algorithms and data structures and some

00:01:51,249 --> 00:01:55,240
computation theory and before you get

00:01:53,319 --> 00:01:59,979
started those you need some complexity

00:01:55,240 --> 00:02:01,960
analysis so that we can rate things so

00:01:59,979 --> 00:02:03,880
that then we can compare them so that we

00:02:01,960 --> 00:02:06,760
can talk about stuff

00:02:03,880 --> 00:02:08,440
and so that applies to the algorithms

00:02:06,760 --> 00:02:10,180
and to the data structures and the data

00:02:08,440 --> 00:02:17,830
structures that are used in the

00:02:10,180 --> 00:02:19,780
algorithms so complexity normally when

00:02:17,830 --> 00:02:22,720
people are talking about it they we've

00:02:19,780 --> 00:02:25,030
got we've got Big O and big Omega and

00:02:22,720 --> 00:02:27,670
big theta but really we only use Big O

00:02:25,030 --> 00:02:31,000
that's and even that we just use a

00:02:27,670 --> 00:02:32,410
little bit but your first year CS you

00:02:31,000 --> 00:02:33,820
pretend that that's the most important

00:02:32,410 --> 00:02:36,280
thing in the world and that's what we

00:02:33,820 --> 00:02:39,550
will be doing today here's your little

00:02:36,280 --> 00:02:43,390
Wikipedia definition may or may not be

00:02:39,550 --> 00:02:44,800
helpful but it gets the idea of it's how

00:02:43,390 --> 00:02:49,690
does something respond as we change the

00:02:44,800 --> 00:02:52,120
input size and so what we need is a

00:02:49,690 --> 00:02:52,570
mathematical formalism because computer

00:02:52,120 --> 00:02:55,390
science

00:02:52,570 --> 00:02:58,209
unlike programming is about math and

00:02:55,390 --> 00:03:00,040
very little about computers what we do

00:02:58,209 --> 00:03:02,110
all day is programming or engineering

00:03:00,040 --> 00:03:04,150
depending on how much we have to deal

00:03:02,110 --> 00:03:05,980
with the real world

00:03:04,150 --> 00:03:11,470
computer science is not so much but it's

00:03:05,980 --> 00:03:14,530
very helpful to teach us to inform our

00:03:11,470 --> 00:03:17,110
decisions so for Big O the big thing is

00:03:14,530 --> 00:03:19,950
how does this scale as we do more of it

00:03:17,110 --> 00:03:24,190
does it does it scale up fast or slow

00:03:19,950 --> 00:03:26,080
and really Big O is you know from a

00:03:24,190 --> 00:03:28,750
mathematical standpoint yeah

00:03:26,080 --> 00:03:32,739
JIT G of n is an asymptotic upper bound

00:03:28,750 --> 00:03:35,110
if you know C some constant times G of n

00:03:32,739 --> 00:03:38,140
is bigger than F of n for all N greater

00:03:35,110 --> 00:03:40,300
than n not a yeah that's when you're

00:03:38,140 --> 00:03:41,950
like that's when you're kind of gloss

00:03:40,300 --> 00:03:45,220
glaze over and glass over if you're

00:03:41,950 --> 00:03:47,370
trying to read someone else's CS stuff a

00:03:45,220 --> 00:03:49,810
nice way to think that is like you're in

00:03:47,370 --> 00:03:53,470
you know it's an adversarial game you

00:03:49,810 --> 00:03:56,830
get to pick G of N and C and some N and

00:03:53,470 --> 00:03:59,380
then your opponent tries to pick the n

00:03:56,830 --> 00:04:04,239
bigger than the N you picked such that

00:03:59,380 --> 00:04:05,860
this isn't true and you know that's what

00:04:04,239 --> 00:04:09,430
you'll be doing when you're trying to

00:04:05,860 --> 00:04:12,159
analyze what things are but

00:04:09,430 --> 00:04:15,099
more usefully let's look at some of the

00:04:12,159 --> 00:04:18,759
things that you will see so the big

00:04:15,099 --> 00:04:23,620
o-notation of something is stated as a

00:04:18,759 --> 00:04:27,789
big a capital o Big O followed by some

00:04:23,620 --> 00:04:30,310
sort of equation function of n an order

00:04:27,789 --> 00:04:32,650
of one means a really just takes one

00:04:30,310 --> 00:04:35,620
operation doesn't matter what else you

00:04:32,650 --> 00:04:37,210
have in there order of n that's the

00:04:35,620 --> 00:04:42,460
baseline just to inspect all of your

00:04:37,210 --> 00:04:44,740
input order of n log n if you're

00:04:42,460 --> 00:04:46,419
designing an algorithm this is this is a

00:04:44,740 --> 00:04:49,990
beautiful spot to be it's basically the

00:04:46,419 --> 00:04:53,669
free position once you're in n log n you

00:04:49,990 --> 00:04:56,020
can sort your input for free ish and

00:04:53,669 --> 00:04:58,030
then if you can do your algorithm

00:04:56,020 --> 00:05:00,430
quickly unsorted input then you can just

00:04:58,030 --> 00:05:03,250
do it that way and it's a quick it's a

00:05:00,430 --> 00:05:05,110
fine line between n log N and N squared

00:05:03,250 --> 00:05:09,370
and at that point you're basically too

00:05:05,110 --> 00:05:12,400
slow yes we have you know lots of

00:05:09,370 --> 00:05:15,880
quadratic equations for things we would

00:05:12,400 --> 00:05:19,539
just like them to be faster then you get

00:05:15,880 --> 00:05:22,750
exponential and factorials and you don't

00:05:19,539 --> 00:05:26,349
want those I may even have a pretty

00:05:22,750 --> 00:05:29,409
graph where they show boom because once

00:05:26,349 --> 00:05:35,949
you have you know 10 things in 2 to the

00:05:29,409 --> 00:05:38,800
10 you're at large you know is

00:05:35,949 --> 00:05:39,430
reasonable but a million things at a

00:05:38,800 --> 00:05:42,099
million squared

00:05:39,430 --> 00:05:46,080
yeah you can do that at a 2 to the

00:05:42,099 --> 00:05:49,840
million not you're not gonna be happy so

00:05:46,080 --> 00:06:00,370
I realize that's a lot of hand waving

00:05:49,840 --> 00:06:02,590
over your big oh yes and that comes in

00:06:00,370 --> 00:06:05,310
handy both in the as you do your

00:06:02,590 --> 00:06:08,320
algorithms this is the lovely slide from

00:06:05,310 --> 00:06:11,080
cs161 at stanford which is an open

00:06:08,320 --> 00:06:17,529
available course from Professor

00:06:11,080 --> 00:06:19,389
roughgarden and it's quite good he did

00:06:17,529 --> 00:06:21,980
it through open open classroom at

00:06:19,389 --> 00:06:24,050
Stanford the video there is pretty bad

00:06:21,980 --> 00:06:27,890
but then he redid it with Coursera I

00:06:24,050 --> 00:06:31,430
took it this fall and I was taking it

00:06:27,890 --> 00:06:33,970
again just now to remind myself and it's

00:06:31,430 --> 00:06:36,920
a wonderful course highly recommend it

00:06:33,970 --> 00:06:41,990
because it's what got me to thank LA I

00:06:36,920 --> 00:06:45,350
should come tell you guys this so that's

00:06:41,990 --> 00:06:48,290
actually that's a lot of words let's try

00:06:45,350 --> 00:06:51,500
and do something specific so one of the

00:06:48,290 --> 00:06:53,810
first things that we analyzed is a

00:06:51,500 --> 00:06:58,730
sorting algorithm we like to start with

00:06:53,810 --> 00:07:02,120
bubble sort because it's conceptually

00:06:58,730 --> 00:07:05,000
very simple for a bubble sort

00:07:02,120 --> 00:07:07,160
you just walk through the array looking

00:07:05,000 --> 00:07:11,780
at two elements at a time if they're out

00:07:07,160 --> 00:07:13,220
of order you swap them if you get to the

00:07:11,780 --> 00:07:19,000
end of the array and you haven't swapped

00:07:13,220 --> 00:07:25,550
any then it's sorted and what we'll see

00:07:19,000 --> 00:07:29,210
see if this actually works oh well maybe

00:07:25,550 --> 00:07:31,880
gifts love it so yeah you know you just

00:07:29,210 --> 00:07:33,980
walk through you sort it the gifts go

00:07:31,880 --> 00:07:36,940
really slow because to remind you that

00:07:33,980 --> 00:07:36,940
it's really slow

00:07:37,450 --> 00:07:44,060
so it's bubble sort ends up being an N

00:07:42,020 --> 00:07:46,280
squared algorithm because you have to

00:07:44,060 --> 00:07:48,980
look each pass through you look at

00:07:46,280 --> 00:07:51,290
everything you look at each pair of

00:07:48,980 --> 00:07:55,760
elements so that that's n operations to

00:07:51,290 --> 00:07:58,640
grab the end things and then you have to

00:07:55,760 --> 00:07:59,930
do that potentially n loops through so

00:07:58,640 --> 00:08:02,950
worst case scenario they're all

00:07:59,930 --> 00:08:07,120
backwards and you have to sort them all

00:08:02,950 --> 00:08:07,120
over and over don't know if I over again

00:08:07,660 --> 00:08:16,070
it's just I'm not watching but it's very

00:08:14,060 --> 00:08:18,050
what's nice about this is you can

00:08:16,070 --> 00:08:20,090
actually write you can sort of just work

00:08:18,050 --> 00:08:24,380
that out on your on your own just

00:08:20,090 --> 00:08:26,680
walking through them and in the little

00:08:24,380 --> 00:08:29,840
person that top has little tiny bubbles

00:08:26,680 --> 00:08:31,450
now if we were to compare that oh maybe

00:08:29,840 --> 00:08:37,610
there's my other graph finally going

00:08:31,450 --> 00:08:39,909
we'll just watch one sort because it's

00:08:37,610 --> 00:08:39,909
pretty

00:08:41,070 --> 00:08:46,060
but so how we even figure out that that

00:08:43,870 --> 00:08:48,010
is too slow I mean it works when you're

00:08:46,060 --> 00:08:51,310
doing things by hand you know I I

00:08:48,010 --> 00:08:54,370
bubblesort my cards when I you know I

00:08:51,310 --> 00:08:58,930
have 10 cards in my hand for a game of

00:08:54,370 --> 00:09:02,200
something well I used to bubble so I

00:08:58,930 --> 00:09:06,760
found I now I do an insert a merged

00:09:02,200 --> 00:09:09,460
insertion sort but um oops

00:09:06,760 --> 00:09:11,350
but yeah and it has time so it's useful

00:09:09,460 --> 00:09:12,550
like if your data is almost totally

00:09:11,350 --> 00:09:14,350
sorted and there's just a couple of

00:09:12,550 --> 00:09:17,170
things it has to do it's probably a good

00:09:14,350 --> 00:09:18,700
way to go if you need to write a sorting

00:09:17,170 --> 00:09:21,100
algorithm right now while someone is

00:09:18,700 --> 00:09:23,620
over your shoulder it's an okay way to

00:09:21,100 --> 00:09:26,950
go should you write your own sorting

00:09:23,620 --> 00:09:30,970
algorithm know there are people smarter

00:09:26,950 --> 00:09:32,710
than me and possibly you who spend their

00:09:30,970 --> 00:09:34,840
time making better starting algorithms

00:09:32,710 --> 00:09:38,590
however it's useful to know what they

00:09:34,840 --> 00:09:42,190
are and how we compare them it's like if

00:09:38,590 --> 00:09:44,350
we were to look at quicksort quicksort

00:09:42,190 --> 00:09:46,720
is a slightly more complex algorithm I

00:09:44,350 --> 00:09:49,090
should actually step back for a second I

00:09:46,720 --> 00:09:51,910
realize I forgot my algorithm slide so

00:09:49,090 --> 00:09:53,860
what is an algorithm it is a mechanical

00:09:51,910 --> 00:09:57,160
process by which you can go from an

00:09:53,860 --> 00:09:59,400
input to an output that's that's the

00:09:57,160 --> 00:10:03,070
extent of the definition of an algorithm

00:09:59,400 --> 00:10:06,900
it's a lot like a function conceptually

00:10:03,070 --> 00:10:10,810
and so it's this a series of steps

00:10:06,900 --> 00:10:13,810
possibly recursively defined that get

00:10:10,810 --> 00:10:15,670
you from your input your output so in

00:10:13,810 --> 00:10:17,950
the quicksort case we have a slightly

00:10:15,670 --> 00:10:22,870
more clever and more interesting

00:10:17,950 --> 00:10:24,180
algorithm it's a the first of what we

00:10:22,870 --> 00:10:26,950
would call a divide and conquer approach

00:10:24,180 --> 00:10:30,190
wherein you take your problem and you

00:10:26,950 --> 00:10:32,620
split it into smaller pieces and you

00:10:30,190 --> 00:10:35,830
keep splitting it until you have some

00:10:32,620 --> 00:10:37,740
sort of you hit a base case and then you

00:10:35,830 --> 00:10:40,270
build it back up

00:10:37,740 --> 00:10:43,630
so for quicksort what one does is you

00:10:40,270 --> 00:10:46,510
pick an element that's your pivot

00:10:43,630 --> 00:10:48,340
and then you walk through all yellow the

00:10:46,510 --> 00:10:50,470
other elements and if it's smaller than

00:10:48,340 --> 00:10:51,850
the pivot make sure it's to the left and

00:10:50,470 --> 00:10:54,040
if it's bigger than the pivot you make

00:10:51,850 --> 00:10:56,680
sure it's to the right then you take

00:10:54,040 --> 00:10:59,380
each of those halves and you do that

00:10:56,680 --> 00:11:01,810
process again and then once you've done

00:10:59,380 --> 00:11:03,550
that for all of them you have a group of

00:11:01,810 --> 00:11:10,690
sorted lists that you just concatenate

00:11:03,550 --> 00:11:12,720
back together so in each case you go you

00:11:10,690 --> 00:11:17,500
look through all the elements once and

00:11:12,720 --> 00:11:19,090
you split it in half so to analyze that

00:11:17,500 --> 00:11:22,630
you see that since you split it in half

00:11:19,090 --> 00:11:27,700
each time you can take a maximum of log

00:11:22,630 --> 00:11:30,130
base 2 of n steps step back and let that

00:11:27,700 --> 00:11:34,210
sink in for a second so each time you

00:11:30,130 --> 00:11:37,210
you cut it in half so you go down by 2

00:11:34,210 --> 00:11:40,810
that's that's all that saying so you do

00:11:37,210 --> 00:11:44,680
log log base 2 number of steps n each

00:11:40,810 --> 00:11:48,880
step you do n operations so it takes n

00:11:44,680 --> 00:11:51,760
times a log log base 2 of n but we don't

00:11:48,880 --> 00:11:53,920
really care about our basis for Big O

00:11:51,760 --> 00:11:56,680
notation you get to play with the

00:11:53,920 --> 00:11:58,360
factors and you drop all of the the

00:11:56,680 --> 00:12:02,920
numbers and you just end up with the

00:11:58,360 --> 00:12:08,280
powers and so we call that a n log n

00:12:02,920 --> 00:12:10,720
solution and a highlight quicksort

00:12:08,280 --> 00:12:14,890
better than merge sort because it's

00:12:10,720 --> 00:12:18,480
easier to explain here on one slide but

00:12:14,890 --> 00:12:18,480
those are two that you would see a lot

00:12:18,510 --> 00:12:25,030
the problem with quicksort

00:12:20,590 --> 00:12:28,420
as seen in this pretty graph is what

00:12:25,030 --> 00:12:32,650
it's worst case scenario is is you have

00:12:28,420 --> 00:12:34,090
to do n work and if you split it into 1

00:12:32,650 --> 00:12:36,960
and n minus 1 you end up splitting it

00:12:34,090 --> 00:12:40,960
into n cases and so you do an N squared

00:12:36,960 --> 00:12:43,030
and so that's bad in of itself and the

00:12:40,960 --> 00:12:46,290
fact that the case where that happens is

00:12:43,030 --> 00:12:50,950
if you're handed a sorted array and so

00:12:46,290 --> 00:12:53,410
that's that's not so good very if you

00:12:50,950 --> 00:12:54,730
pass bubble sort of sorted array it just

00:12:53,410 --> 00:12:56,910
has to walk through and verify that it's

00:12:54,730 --> 00:12:56,910
good

00:12:59,520 --> 00:13:05,680
what I know yeah it's and it's also much

00:13:02,710 --> 00:13:08,920
more complex to imagine what it's doing

00:13:05,680 --> 00:13:10,360
when you're looking at it like I

00:13:08,920 --> 00:13:12,820
couldn't even tell you exactly what this

00:13:10,360 --> 00:13:15,250
picture is doing like the red I believe

00:13:12,820 --> 00:13:17,110
is the pivot that is moving and then

00:13:15,250 --> 00:13:20,770
some of them are being rearranged and

00:13:17,110 --> 00:13:22,090
then magically it's like oh now we go do

00:13:20,770 --> 00:13:25,500
the top half and then we split it and we

00:13:22,090 --> 00:13:25,500
split it and we split it and there we go

00:13:26,070 --> 00:13:36,250
but and this is why we care so you very

00:13:30,700 --> 00:13:39,250
rapidly at 3,000 items to sort at

00:13:36,250 --> 00:13:43,500
whatever units this is in seconds but of

00:13:39,250 --> 00:13:47,170
who knows what CPU for this random graph

00:13:43,500 --> 00:13:49,230
is that it's not really a 2,000

00:13:47,170 --> 00:13:49,230
you

00:13:49,389 --> 00:13:52,570
so I

00:13:50,830 --> 00:13:54,670
she's still approximately zero for a

00:13:52,570 --> 00:13:58,390
quick sort right

00:13:54,670 --> 00:14:00,100
now if you did a chart of various and

00:13:58,390 --> 00:14:04,330
login sorting algorithms you would see

00:14:00,100 --> 00:14:05,950
that they have different slopes but you

00:14:04,330 --> 00:14:10,330
you don't want to be in that upper case

00:14:05,950 --> 00:14:12,340
there I'm in your code and you might

00:14:10,330 --> 00:14:16,240
univer Tinley be doing that now so

00:14:12,340 --> 00:14:18,910
hopefully we will touch on that so for

00:14:16,240 --> 00:14:20,530
instance again what should you be using

00:14:18,910 --> 00:14:23,320
for a sort probably something that's

00:14:20,530 --> 00:14:26,830
built in so sort

00:14:23,320 --> 00:14:29,800
yeah a pro sort actually has some things

00:14:26,830 --> 00:14:31,180
where you can tweak it which how many

00:14:29,800 --> 00:14:32,830
people knew that you could

00:14:31,180 --> 00:14:35,500
there was a used sort pragma where you

00:14:32,830 --> 00:14:37,300
could change how the sort work how many

00:14:35,500 --> 00:14:38,800
of those with your hands up worked on

00:14:37,300 --> 00:14:44,260
that does that because that doesn't

00:14:38,800 --> 00:14:48,280
count if you wrote it so a fun little

00:14:44,260 --> 00:14:51,340
piece of history so Pro sort uses a

00:14:48,280 --> 00:14:53,860
quicksort and mergesort before five six

00:14:51,340 --> 00:14:56,890
it was always quicksort and then a five

00:14:53,860 --> 00:14:59,290
eight we added merge sort and I believe

00:14:56,890 --> 00:15:01,650
it actually does some clever heuristics

00:14:59,290 --> 00:15:03,940
to determine which one it's going to use

00:15:01,650 --> 00:15:06,820
for instance quicksort is going to be

00:15:03,940 --> 00:15:07,810
faster for small lists in general than

00:15:06,820 --> 00:15:10,510
merge sort

00:15:07,810 --> 00:15:13,110
but merge sort is stable which means

00:15:10,510 --> 00:15:16,270
that if you give it a list and things

00:15:13,110 --> 00:15:19,870
have the same sort key especially with

00:15:16,270 --> 00:15:21,040
the sub portion of the key that things

00:15:19,870 --> 00:15:22,570
that have a particular order will

00:15:21,040 --> 00:15:26,950
maintain that order if they were in

00:15:22,570 --> 00:15:28,570
order okay that's I'm going to skip that

00:15:26,950 --> 00:15:30,790
because that's difficult to explain but

00:15:28,570 --> 00:15:32,770
you so one of the things you can say is

00:15:30,790 --> 00:15:35,800
hey I want it to be stable which means

00:15:32,770 --> 00:15:37,630
you're going to get march toward and you

00:15:35,800 --> 00:15:41,080
can explicitly ask for merge sort of

00:15:37,630 --> 00:15:42,970
quicksort you shouldn't but you know

00:15:41,080 --> 00:15:45,460
possibly for your data that's the right

00:15:42,970 --> 00:15:46,900
choice and you know the engineer would

00:15:45,460 --> 00:15:49,450
then say well go benchmark it

00:15:46,900 --> 00:15:53,080
so the CS person says let's analyze it

00:15:49,450 --> 00:15:56,430
and then programmer then has to get some

00:15:53,080 --> 00:15:56,430
data and bench bench market

00:15:56,740 --> 00:16:02,210
and so the other thing we'll look into a

00:15:59,630 --> 00:16:04,400
lot and I know I'm a little behind here

00:16:02,210 --> 00:16:05,540
but data structures and so we're just

00:16:04,400 --> 00:16:07,940
going to kind of fly through these

00:16:05,540 --> 00:16:11,930
there's a lot of data structures that we

00:16:07,940 --> 00:16:16,760
look at first year and stuff

00:16:11,930 --> 00:16:19,160
arrays lists tuples hash tables in Perl

00:16:16,760 --> 00:16:23,180
we have a couple of these built in we

00:16:19,160 --> 00:16:26,839
have arrays essentially so arrays and

00:16:23,180 --> 00:16:28,339
lists are different you know based on

00:16:26,839 --> 00:16:30,830
their implementation you have different

00:16:28,339 --> 00:16:33,230
behaviors is it a linked list in which

00:16:30,830 --> 00:16:35,150
case it's easier to add and remove

00:16:33,230 --> 00:16:38,690
things but it's harder to get to any

00:16:35,150 --> 00:16:40,940
individual one an array allows you to go

00:16:38,690 --> 00:16:43,700
directly to any element so it's order

00:16:40,940 --> 00:16:46,940
one to look up an element however it's

00:16:43,700 --> 00:16:51,220
order n to see if a given element exists

00:16:46,940 --> 00:16:54,890
in the list for a hash table

00:16:51,220 --> 00:16:57,680
both of those are ordered and that's why

00:16:54,890 --> 00:16:59,950
we use hash tables so often because

00:16:57,680 --> 00:17:03,680
they're very useful for random access

00:16:59,950 --> 00:17:05,420
and you know on Sipan we actually do

00:17:03,680 --> 00:17:08,059
have a variety of libraries for trees

00:17:05,420 --> 00:17:09,949
and tries and some graph stuff than some

00:17:08,059 --> 00:17:12,949
sets and when you need those that'll be

00:17:09,949 --> 00:17:16,069
helpful if you're over in Python land

00:17:12,949 --> 00:17:17,959
you've got a built in set and so you see

00:17:16,069 --> 00:17:21,980
it used a lot more because it's it's

00:17:17,959 --> 00:17:26,360
there and right you can very easily use

00:17:21,980 --> 00:17:28,550
a hash as I said but you're just wasting

00:17:26,360 --> 00:17:34,309
some storage space by having it point to

00:17:28,550 --> 00:17:37,100
something but let's actually step back

00:17:34,309 --> 00:17:39,559
into an actual example so a lot of you

00:17:37,100 --> 00:17:42,710
have played with or seen a short scene

00:17:39,559 --> 00:17:45,110
transform anybody at some point actually

00:17:42,710 --> 00:17:49,309
who has never seen or heard of that

00:17:45,110 --> 00:17:53,420
particular transform excellent okay so

00:17:49,309 --> 00:17:54,770
in the short scene transformed the Lisp

00:17:53,420 --> 00:17:57,640
that we still live from would just call

00:17:54,770 --> 00:18:02,720
it a D sua decorates or undecorated

00:17:57,640 --> 00:18:04,700
so the idea here is if you have a sort

00:18:02,720 --> 00:18:06,340
of custom sort comparator that is

00:18:04,700 --> 00:18:11,010
somewhat expensive to

00:18:06,340 --> 00:18:14,080
in this case it's the foo function so

00:18:11,010 --> 00:18:20,919
this is a faster version of just saying

00:18:14,080 --> 00:18:25,659
sort on that's your foo of dollar a

00:18:20,919 --> 00:18:28,960
compare foo of dollar b of unsorted now

00:18:25,659 --> 00:18:31,750
why is this faster is goes back to our

00:18:28,960 --> 00:18:35,020
other issue of when we're doing a sort

00:18:31,750 --> 00:18:37,330
we end up doing n log and comparisons

00:18:35,020 --> 00:18:41,380
and if those comparisons are expensive

00:18:37,330 --> 00:18:43,570
that's a lot of computation and so what

00:18:41,380 --> 00:18:45,330
we do here is we we run that computation

00:18:43,570 --> 00:18:48,880
exactly n times once for each element

00:18:45,330 --> 00:18:52,510
then we do some order 1 lookups to pull

00:18:48,880 --> 00:18:55,690
it out of an array and do the

00:18:52,510 --> 00:18:57,820
comparisons and then we unwrap it to

00:18:55,690 --> 00:19:03,130
remove that decoration now that is

00:18:57,820 --> 00:19:06,399
useful if calling foo is more expensive

00:19:03,130 --> 00:19:10,450
than the base setup time of building and

00:19:06,399 --> 00:19:12,549
carrying down this array and there's

00:19:10,450 --> 00:19:19,919
actually a lovely wiki on this over at

00:19:12,549 --> 00:19:23,740
Wikipedia and this is not my dog but oh

00:19:19,919 --> 00:19:27,159
my god so I hope you guys learned a

00:19:23,740 --> 00:19:29,080
little something from that so uh yes so

00:19:27,159 --> 00:19:30,549
this is actually how knowing some of

00:19:29,080 --> 00:19:32,260
these things will help you in what

00:19:30,549 --> 00:19:34,570
you're actually doing day to day which

00:19:32,260 --> 00:19:37,059
is you should be able to tell if you

00:19:34,570 --> 00:19:39,370
have an algorithm that's going to be

00:19:37,059 --> 00:19:41,350
really slow if you look your code and

00:19:39,370 --> 00:19:43,659
it's saying is this element in this

00:19:41,350 --> 00:19:49,029
array over and over again you're gonna

00:19:43,659 --> 00:19:51,010
be very sad and what I'm not sadly not

00:19:49,029 --> 00:19:54,130
gonna get to is my computation theory

00:19:51,010 --> 00:19:57,490
including my halting stage joke in honor

00:19:54,130 --> 00:20:01,559
of our keynote speaker today Charlie

00:19:57,490 --> 00:20:05,590
Stross an author of a two book trilogy

00:20:01,559 --> 00:20:07,320
called the halting state but computation

00:20:05,590 --> 00:20:10,149
theory is an interesting one which is

00:20:07,320 --> 00:20:14,020
what what can we calculate what does it

00:20:10,149 --> 00:20:16,210
even mean to calculate and you know we

00:20:14,020 --> 00:20:18,030
have the church-turing thesis or church

00:20:16,210 --> 00:20:20,350
or Turing depending on whom you talk to

00:20:18,030 --> 00:20:22,299
which basically defines

00:20:20,350 --> 00:20:23,770
mcclee computable if it's computable by

00:20:22,299 --> 00:20:26,320
a Turing machine which is a very

00:20:23,770 --> 00:20:29,350
simplistic computer and then we also

00:20:26,320 --> 00:20:30,700
proved that a Turing machine anything

00:20:29,350 --> 00:20:32,080
that a Turing machine can do any other

00:20:30,700 --> 00:20:34,059
computer can do because they're all

00:20:32,080 --> 00:20:36,429
equivalent and it's much easier to

00:20:34,059 --> 00:20:40,750
reason about from a writing proofs

00:20:36,429 --> 00:20:43,059
standpoint so when someone asks you

00:20:40,750 --> 00:20:44,740
about that you at least have some idea

00:20:43,059 --> 00:20:47,350
what they're talking about which is that

00:20:44,740 --> 00:20:49,090
just means it's computable yes you can

00:20:47,350 --> 00:20:50,710
do an Atari machine it's terribly

00:20:49,090 --> 00:20:54,610
inefficient but we don't care about

00:20:50,710 --> 00:20:58,600
efficiency and and I'm wrapping it up

00:20:54,610 --> 00:21:01,000
all right so we will not get to P versus

00:20:58,600 --> 00:21:02,559
NP which is a shame because I got a

00:21:01,000 --> 00:21:08,309
little proof it's on the side here it's

00:21:02,559 --> 00:21:11,049
just not quite long enough all right and

00:21:08,309 --> 00:21:12,940
I have a whole bunch of links for you to

00:21:11,049 --> 00:21:16,559
learn more things I totally recommend

00:21:12,940 --> 00:21:19,150
taking this course because it's awesome

00:21:16,559 --> 00:21:22,750
there's some other fine papers to read

00:21:19,150 --> 00:21:25,210
and I would open this up to questions

00:21:22,750 --> 00:21:27,490
possibly one while they get the next

00:21:25,210 --> 00:21:29,760
person up here thank you so much for

00:21:27,490 --> 00:21:29,760
your time

00:21:34,450 --> 00:21:41,530
okay anybody questions just remember

00:21:38,930 --> 00:21:41,530

YouTube URL: https://www.youtube.com/watch?v=UVWIEYga_l4


