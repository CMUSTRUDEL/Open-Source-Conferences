Title: David Bury - ‎Threading and Perl -- avoiding insanity and managing the clones effectively‎
Publication date: 2014-06-24
Playlist: YAPC::NA 2014
Description: 
	Threads in Perl adds a new dimension to program development through the asynchronous nature and multiple stories that are unfolding simultaneously. Parallelism can multiply the speeds of certain applications as well as take advantage of the increasing number of cores in modern CPUs. But nothing is free: beyond the normal bugs, understanding the runtime flow and new, randomized, and sporadic bugs are now new challenges in development and testing.

This talk details tactics to maximize the benefit and address common issues and problems based on the real life experience in developing a highly parallel and distributed software system. It also discusses ideas used to manage the inherent insanity of threads as well as effective use of your clones to handle tasks and utilize a multi-core environment.

If you've ever wondered: When to use a parallel approach? How to use shared variables and related objects effectively? How do I mock objects in Threads? What's a thread pool? Or just want to see an effective example of threads in use. This is the talk for you.
Captions: 
	00:00:29,539 --> 00:00:34,129
mike is first screaming oh hi

00:00:38,080 --> 00:00:42,880
you're right so there's more

00:02:23,069 --> 00:02:26,239
you take up a little

00:02:35,810 --> 00:02:42,380
but earlier they tested by talking

00:02:39,060 --> 00:02:42,380
creepily down and it worked

00:03:12,350 --> 00:03:17,510
you know there's certain jobs you never

00:03:14,700 --> 00:03:17,510
stop doing

00:03:32,850 --> 00:03:48,670
hello alright so a little so a little

00:03:46,900 --> 00:03:53,260
about me I live in Monterey California

00:03:48,670 --> 00:03:55,420
and I'm moving over to San Diego soon so

00:03:53,260 --> 00:03:59,160
if anyone's from San Diego say hello

00:03:55,420 --> 00:04:01,810
maybe we should get lonely talk louder

00:03:59,160 --> 00:04:04,000
so I have about 10 years experience and

00:04:01,810 --> 00:04:06,370
software recently moved back and forth

00:04:04,000 --> 00:04:10,210
between doing paarl and doing some job a

00:04:06,370 --> 00:04:13,180
lot of focus on working on like data

00:04:10,210 --> 00:04:15,360
transformation schemas and code to

00:04:13,180 --> 00:04:15,360
access

00:04:15,600 --> 00:04:20,940
the data and then I've enjoyed working

00:04:18,690 --> 00:04:23,760
on a couple parsers kind of for fun kind

00:04:20,940 --> 00:04:26,550
of for work and then I'm moving to mess

00:04:23,760 --> 00:04:29,550
around with some big data problems and

00:04:26,550 --> 00:04:33,660
this is my first gap see na presentation

00:04:29,550 --> 00:04:36,080
and that's my email for comments or

00:04:33,660 --> 00:04:36,080
questions

00:04:36,190 --> 00:04:42,730
so why do you want to use so before you

00:04:39,940 --> 00:04:46,500
use threads you have to think about why

00:04:42,730 --> 00:04:49,750
you want to use it so the first case is

00:04:46,500 --> 00:04:52,270
simply that you have to do more than one

00:04:49,750 --> 00:04:55,840
thing at once to have a reasonable

00:04:52,270 --> 00:04:59,320
application so for a GUI or client user

00:04:55,840 --> 00:05:01,120
interface you can't do graphics and then

00:04:59,320 --> 00:05:03,100
wait five minutes or something to

00:05:01,120 --> 00:05:06,910
complete you need to do both at the same

00:05:03,100 --> 00:05:09,910
time another area where it matters is

00:05:06,910 --> 00:05:11,350
when you're doing something that CPU

00:05:09,910 --> 00:05:14,560
bound or where performance really

00:05:11,350 --> 00:05:17,290
matters because a normal program is just

00:05:14,560 --> 00:05:20,230
going to use one cpu out of how many

00:05:17,290 --> 00:05:21,730
cords you have so you have four chords

00:05:20,230 --> 00:05:24,450
you're using twenty-five percent of the

00:05:21,730 --> 00:05:29,560
CPU and they gets worse as you go from

00:05:24,450 --> 00:05:32,560
16 to 32 on a lot of big servers and the

00:05:29,560 --> 00:05:35,080
number of cores has been increasing a

00:05:32,560 --> 00:05:39,460
lot one of the clock speed has it in a

00:05:35,080 --> 00:05:41,230
lot of cases and then the last area you

00:05:39,460 --> 00:05:44,620
might want to use threads is where you

00:05:41,230 --> 00:05:47,140
have a lot of high latency so a lot of

00:05:44,620 --> 00:05:50,530
the cost is just in waiting so if you

00:05:47,140 --> 00:05:53,169
wait sequentially it's extremely slow so

00:05:50,530 --> 00:05:56,110
you want to spread it out and do it

00:05:53,169 --> 00:05:59,740
parallel so that shortens your weight so

00:05:56,110 --> 00:06:01,480
threads and summary makes things you can

00:05:59,740 --> 00:06:04,080
go much faster on your computer and

00:06:01,480 --> 00:06:08,440
spend a lot less time waiting but

00:06:04,080 --> 00:06:11,440
there's a cost so there's a catch so

00:06:08,440 --> 00:06:13,210
that the potholes can be really big so

00:06:11,440 --> 00:06:16,030
you should so you have to take all the

00:06:13,210 --> 00:06:18,220
potential code problems that exist

00:06:16,030 --> 00:06:20,850
normally for

00:06:18,220 --> 00:06:23,500
just any code then you need to add and

00:06:20,850 --> 00:06:25,240
non-deterministic behavior of when

00:06:23,500 --> 00:06:28,660
something's going to run if it will run

00:06:25,240 --> 00:06:31,420
and like randomness then you have

00:06:28,660 --> 00:06:34,230
simultaneous story lines of multiple

00:06:31,420 --> 00:06:37,930
things happening at once as well as

00:06:34,230 --> 00:06:41,550
storyline interactions so all these

00:06:37,930 --> 00:06:44,650
things conspire to cause pandemonium and

00:06:41,550 --> 00:06:46,470
so you have linear code problems than

00:06:44,650 --> 00:06:48,730
random list you might have a program

00:06:46,470 --> 00:06:51,990
might have errors that don't always

00:06:48,730 --> 00:06:55,960
occur curr everyone out of ten times or

00:06:51,990 --> 00:06:57,690
one out of a thousand but delete are

00:06:55,960 --> 00:07:00,970
your data or something like that and

00:06:57,690 --> 00:07:02,880
then you have normal you have more run

00:07:00,970 --> 00:07:05,590
time problems to look at like

00:07:02,880 --> 00:07:10,990
deadlocking or resource contention or

00:07:05,590 --> 00:07:13,300
maybe a runaway thread so it can get

00:07:10,990 --> 00:07:15,970
pretty complicated and pretty hairy so

00:07:13,300 --> 00:07:22,240
you have to so we're going to look at a

00:07:15,970 --> 00:07:24,460
couple of ways to mitigate these so to

00:07:22,240 --> 00:07:27,370
help control kind of the runtime

00:07:24,460 --> 00:07:29,860
interactions and what you're doing in

00:07:27,370 --> 00:07:35,530
each thread there are these concurrent

00:07:29,860 --> 00:07:37,330
design patterns that help you think

00:07:35,530 --> 00:07:41,610
through how you want these things occur

00:07:37,330 --> 00:07:45,850
and so here are a couple patterns at

00:07:41,610 --> 00:07:48,460
that you could look at so one is barrier

00:07:45,850 --> 00:07:51,310
which is basically checkpointing and at

00:07:48,460 --> 00:07:54,729
certain points in the code you know

00:07:51,310 --> 00:07:57,460
everything's at the same point you have

00:07:54,729 --> 00:07:59,530
double-checked locking which is

00:07:57,460 --> 00:08:02,410
basically like a simple lock with a

00:07:59,530 --> 00:08:04,249
little pre lock that helps lower the

00:08:02,410 --> 00:08:07,519
costs of the locking

00:08:04,249 --> 00:08:09,829
you have the reactor which is a little

00:08:07,519 --> 00:08:13,069
bit dangerous and it's basically

00:08:09,829 --> 00:08:16,479
event-based threatening so events

00:08:13,069 --> 00:08:19,819
trigger threads and there's also the

00:08:16,479 --> 00:08:23,719
reader writer lock which is alternation

00:08:19,819 --> 00:08:26,539
of some readwrite locking I'm not

00:08:23,719 --> 00:08:29,349
totally sure how that works and then my

00:08:26,539 --> 00:08:32,329
favorite is a thread pool which is a

00:08:29,349 --> 00:08:36,289
thread based distribution of work so

00:08:32,329 --> 00:08:38,479
threads come in and then they so there's

00:08:36,289 --> 00:08:42,339
a queue of work and then the work goes

00:08:38,479 --> 00:08:45,339
down to a pool of a set number of

00:08:42,339 --> 00:08:45,339
processors

00:08:45,450 --> 00:08:59,760
what's that those bad anyway yeah so

00:08:50,640 --> 00:09:01,950
this is pearl pro/5 stuff so uh so

00:08:59,760 --> 00:09:04,620
here's more details on the thread pool

00:09:01,950 --> 00:09:07,650
so you basically have new tasks will go

00:09:04,620 --> 00:09:11,550
into a queue and then the newest things

00:09:07,650 --> 00:09:13,620
I mean whoever came first is going to

00:09:11,550 --> 00:09:16,850
come out of the queue and so the pool is

00:09:13,620 --> 00:09:20,100
going to be reading these tasks yet and

00:09:16,850 --> 00:09:23,250
sending out to a set number of workers

00:09:20,100 --> 00:09:25,860
who will process as as each worker

00:09:23,250 --> 00:09:28,890
finishes the pooler will add more things

00:09:25,860 --> 00:09:32,480
to keep all the the worker threads up

00:09:28,890 --> 00:09:32,480
and running so it's

00:09:33,430 --> 00:09:38,680
that should say bank but um just like in

00:09:37,060 --> 00:09:43,240
a bank you have a bunch of people

00:09:38,680 --> 00:09:44,529
waiting in line your tasks and then as

00:09:43,240 --> 00:09:46,720
they get to the front of the line they

00:09:44,529 --> 00:09:50,740
go to whichever tower is available here

00:09:46,720 --> 00:09:53,310
a worker and then the bank is your pool

00:09:50,740 --> 00:09:53,310
in this case

00:09:55,500 --> 00:10:07,650
so here's one example of how you can run

00:10:03,180 --> 00:10:09,480
it this is what I've used and now go

00:10:07,650 --> 00:10:12,990
into this in more detail but roughly

00:10:09,480 --> 00:10:16,680
this is basically you have a main thread

00:10:12,990 --> 00:10:18,780
figuring out what to do it sends all its

00:10:16,680 --> 00:10:22,020
little things in what to do to a

00:10:18,780 --> 00:10:26,790
distribution thread and then that thread

00:10:22,020 --> 00:10:29,280
will package up the work into good

00:10:26,790 --> 00:10:31,790
chunks and then send it out to a bunch

00:10:29,280 --> 00:10:34,860
of worker threads you have there and

00:10:31,790 --> 00:10:37,440
then the last part is a monitor there

00:10:34,860 --> 00:10:40,830
and that will check to see what's going

00:10:37,440 --> 00:10:44,000
on with your with your tasks and can

00:10:40,830 --> 00:10:50,090
restart them if it needs to

00:10:44,000 --> 00:10:52,870
so let's move on to some pearl Pacific

00:10:50,090 --> 00:10:57,700
thread things

00:10:52,870 --> 00:11:00,010
so the basic use of threads is to use

00:10:57,700 --> 00:11:03,100
the package threads and then you would

00:11:00,010 --> 00:11:06,760
use threads create with the function

00:11:03,100 --> 00:11:11,080
name as a string or or a reference and

00:11:06,760 --> 00:11:13,450
then some arguments and and this will

00:11:11,080 --> 00:11:16,210
end up having the system launched a new

00:11:13,450 --> 00:11:18,420
thread with your function in that

00:11:16,210 --> 00:11:22,540
function name with your arguments and

00:11:18,420 --> 00:11:24,670
then so that's not too bad there are a

00:11:22,540 --> 00:11:27,760
couple of pitfalls you have to look out

00:11:24,670 --> 00:11:30,010
for that's not a completely normal

00:11:27,760 --> 00:11:34,420
function call so you can't do everything

00:11:30,010 --> 00:11:37,380
you would in a normal function one

00:11:34,420 --> 00:11:42,700
example is if you have more than one

00:11:37,380 --> 00:11:46,029
level in your hash or array if you just

00:11:42,700 --> 00:11:49,600
use it nightly you could be missing data

00:11:46,029 --> 00:11:51,810
in your thread so for more complicated

00:11:49,600 --> 00:11:57,180
structures you might want to use a

00:11:51,810 --> 00:11:57,180
thread shared which is our next slide

00:12:01,139 --> 00:12:09,160
so here's how to use thread shared you

00:12:06,610 --> 00:12:12,689
import thread shared but you should do

00:12:09,160 --> 00:12:17,430
it only after the use threads otherwise

00:12:12,689 --> 00:12:17,430
the system will be unhappy and break

00:12:17,590 --> 00:12:22,660
and when you do that you basically get

00:12:19,660 --> 00:12:24,970
the ability to have a shared shared

00:12:22,660 --> 00:12:30,610
memory that can exist between multiple

00:12:24,970 --> 00:12:33,610
threads and the basic use would be using

00:12:30,610 --> 00:12:35,800
the colon shared when you declare

00:12:33,610 --> 00:12:38,100
variable and you should do this before

00:12:35,800 --> 00:12:41,890
you put data in there because for some

00:12:38,100 --> 00:12:46,080
from for some data types when you do

00:12:41,890 --> 00:12:49,750
this year you it empties a the data and

00:12:46,080 --> 00:12:53,200
then anytime you want to read or write

00:12:49,750 --> 00:12:57,100
from the from the shared variable you

00:12:53,200 --> 00:12:59,350
should lock it and and there's a lock

00:12:57,100 --> 00:13:03,130
function here that you would use there

00:12:59,350 --> 00:13:05,980
is no unlock function so it basically

00:13:03,130 --> 00:13:09,790
unlocks whenever it goes out of scope so

00:13:05,980 --> 00:13:12,040
and you want to unlock as soon as

00:13:09,790 --> 00:13:14,860
possible so you don't tie up the system

00:13:12,040 --> 00:13:17,200
so many times you will just put these in

00:13:14,860 --> 00:13:21,310
inbox

00:13:17,200 --> 00:13:24,190
so so there are some limitations you

00:13:21,310 --> 00:13:29,260
can't you can't share globs or code

00:13:24,190 --> 00:13:31,150
references and again you have to be kind

00:13:29,260 --> 00:13:34,360
of careful if you have a raise of a

00:13:31,150 --> 00:13:38,680
raise of or hash or of hashes something

00:13:34,360 --> 00:13:41,170
with a lot of depth to it but a way you

00:13:38,680 --> 00:13:47,470
can handle that is to use the share

00:13:41,170 --> 00:13:49,690
clone function so that can handle most

00:13:47,470 --> 00:13:53,100
of the data but you should be careful

00:13:49,690 --> 00:13:56,590
with them you're just trying to clone

00:13:53,100 --> 00:14:00,790
some random object that object has any

00:13:56,590 --> 00:14:05,260
kind of glove or code reference buried

00:14:00,790 --> 00:14:09,580
in it that will bomb the system and then

00:14:05,260 --> 00:14:12,070
also 4shared clone it looks like it only

00:14:09,580 --> 00:14:16,380
copies values not the references so

00:14:12,070 --> 00:14:18,790
you'll get your clone of data but

00:14:16,380 --> 00:14:21,040
changes in between this big structure

00:14:18,790 --> 00:14:23,370
may not propagate you have to be careful

00:14:21,040 --> 00:14:23,370
with that

00:14:25,080 --> 00:14:29,490
so here's thread cue

00:14:30,579 --> 00:14:37,239
and it's better than the airport q and

00:14:33,759 --> 00:14:39,839
this works very nicely with the third

00:14:37,239 --> 00:14:39,839
cool pattern

00:14:42,060 --> 00:14:51,440
so this one I like to use to have

00:14:45,300 --> 00:14:54,320
multiple threads right to this

00:14:51,440 --> 00:14:56,920
so this could share your state or your

00:14:54,320 --> 00:15:00,279
work like

00:14:56,920 --> 00:15:02,380
or status and messages and then I

00:15:00,279 --> 00:15:05,200
usually have one responsible thread that

00:15:02,380 --> 00:15:08,980
will do the reading and the logic or

00:15:05,200 --> 00:15:12,339
handling the disk you and the basic use

00:15:08,980 --> 00:15:17,889
of the thread Q is just to instantiate

00:15:12,339 --> 00:15:20,380
it with the threat q new and then you'll

00:15:17,889 --> 00:15:24,940
pass the Q object to all threads you

00:15:20,380 --> 00:15:27,040
want to write to that thread and that

00:15:24,940 --> 00:15:33,279
can just come in as the / am and the

00:15:27,040 --> 00:15:36,279
threads create function and then and

00:15:33,279 --> 00:15:40,449
then they would just use the NQ function

00:15:36,279 --> 00:15:43,959
to write all their objects to that Q and

00:15:40,449 --> 00:15:46,209
then you can read off the sku with a

00:15:43,959 --> 00:15:48,910
couple functions but I like the DQ x

00:15:46,209 --> 00:15:51,130
which you can give it how long the wait

00:15:48,910 --> 00:15:56,079
and how many you want and that make sure

00:15:51,130 --> 00:15:57,610
that you don't wait too long for what

00:15:56,079 --> 00:16:00,930
you want to get off the queue or get too

00:15:57,610 --> 00:16:00,930
much data back from the cube

00:16:01,380 --> 00:16:04,770
it Oh

00:16:06,830 --> 00:16:12,950
alright testing with threads so I

00:16:10,040 --> 00:16:17,810
usually like to use walking classes to

00:16:12,950 --> 00:16:22,100
do a lot of my testing but that didn't

00:16:17,810 --> 00:16:24,560
work too well with the marking classes

00:16:22,100 --> 00:16:27,470
I'd tried to test when i was doing

00:16:24,560 --> 00:16:30,800
threads a lot of the problem i had to do

00:16:27,470 --> 00:16:34,030
with the mocking was doing something in

00:16:30,800 --> 00:16:37,370
memory that would kind of override the

00:16:34,030 --> 00:16:39,500
class but as soon as the threat went

00:16:37,370 --> 00:16:42,590
through the thread part the class got

00:16:39,500 --> 00:16:46,760
reset so it just became a normal class

00:16:42,590 --> 00:16:49,610
that was unmarked it might be possible

00:16:46,760 --> 00:16:52,060
to to use it depending on how you

00:16:49,610 --> 00:16:57,410
structure your object or your functions

00:16:52,060 --> 00:17:00,230
but you'd have to test that out so the

00:16:57,410 --> 00:17:02,410
solution I came up with was to mock

00:17:00,230 --> 00:17:06,580
statically which is kind of a

00:17:02,410 --> 00:17:09,680
heavy-handed solution but essentially I

00:17:06,580 --> 00:17:11,449
created fake librarians and how the

00:17:09,680 --> 00:17:13,550
system use that instead of the normal

00:17:11,449 --> 00:17:16,730
and stirring testing

00:17:13,550 --> 00:17:19,340
so I did this by creating a test area

00:17:16,730 --> 00:17:21,740
where you would have the your new

00:17:19,340 --> 00:17:24,320
libraries that you want to mock instead

00:17:21,740 --> 00:17:28,670
of your normal library and then you

00:17:24,320 --> 00:17:31,430
would create your mock mock object and

00:17:28,670 --> 00:17:34,700
some kind of in memory and then write

00:17:31,430 --> 00:17:40,190
that to disk to your kind of fake

00:17:34,700 --> 00:17:43,640
library location then you'd want to make

00:17:40,190 --> 00:17:45,620
sure that your fake library is ahead of

00:17:43,640 --> 00:17:48,500
your is at the very front of your pearl

00:17:45,620 --> 00:17:50,540
path and then reload these libraries and

00:17:48,500 --> 00:17:53,690
then you can go ahead and run your tests

00:17:50,540 --> 00:17:57,080
and it will see all the mocking and then

00:17:53,690 --> 00:18:00,040
another technique used in conjunction

00:17:57,080 --> 00:18:00,040
with that is

00:18:00,640 --> 00:18:12,460
hello is to use a file-based variable so

00:18:08,980 --> 00:18:14,170
basically using files to read and write

00:18:12,460 --> 00:18:18,220
some variables that are just for the

00:18:14,170 --> 00:18:21,700
mocking classes and so this helps in

00:18:18,220 --> 00:18:24,010
cases where the where the test needs to

00:18:21,700 --> 00:18:30,580
maintain some kind of state through

00:18:24,010 --> 00:18:35,230
throughout it and yeah so that allows

00:18:30,580 --> 00:18:38,190
you to do mocking with threads which I

00:18:35,230 --> 00:18:38,190
found very helpful

00:18:38,920 --> 00:18:45,850
especially when you're kind of testing

00:18:43,250 --> 00:18:47,810
like going out over a network you can

00:18:45,850 --> 00:18:51,320
can do it with a bunch of threads

00:18:47,810 --> 00:18:53,450
without worrying if that's network

00:18:51,320 --> 00:18:58,120
connection is there or will get unhappy

00:18:53,450 --> 00:19:01,690
with the number of connections so that's

00:18:58,120 --> 00:19:01,690
that's testing

00:19:02,510 --> 00:19:09,320
so the final final screen least but not

00:19:05,450 --> 00:19:11,900
least as a but not last it's kind of a

00:19:09,320 --> 00:19:15,740
real life example so in this example we

00:19:11,900 --> 00:19:19,010
had a basically had a pearl diamond

00:19:15,740 --> 00:19:23,600
running on a server and it was launching

00:19:19,010 --> 00:19:26,270
a bunch of sub category threads that

00:19:23,600 --> 00:19:30,770
basically would only try to do one type

00:19:26,270 --> 00:19:33,110
of work and then each sub categories is

00:19:30,770 --> 00:19:37,220
basically the second the bottom part of

00:19:33,110 --> 00:19:40,100
this presentation so it was a had a

00:19:37,220 --> 00:19:41,870
master master process that basically

00:19:40,100 --> 00:19:43,930
figured out everything you wanted and

00:19:41,870 --> 00:19:47,810
control what you would do in the system

00:19:43,930 --> 00:19:50,870
so it would say do these end things and

00:19:47,810 --> 00:19:53,390
so those end things would pass through a

00:19:50,870 --> 00:19:55,850
thread Q into another threaded

00:19:53,390 --> 00:19:59,080
distributor and then this would go ahead

00:19:55,850 --> 00:20:04,310
and packaged up there was work units

00:19:59,080 --> 00:20:06,890
into chunks or packages that were a good

00:20:04,310 --> 00:20:09,740
size to send over to the worker threads

00:20:06,890 --> 00:20:13,370
and so that would be sent over by

00:20:09,740 --> 00:20:17,110
another queue down to whatever worker

00:20:13,370 --> 00:20:19,420
thread is available kind of continuously

00:20:17,110 --> 00:20:21,980
so each worker thread would go ahead and

00:20:19,420 --> 00:20:26,169
run its process and then it would also

00:20:21,980 --> 00:20:28,600
share the state of what happened

00:20:26,169 --> 00:20:30,549
on that work down to the monitor and

00:20:28,600 --> 00:20:34,749
that was also done through a thread

00:20:30,549 --> 00:20:37,149
queue and then this monitor could tell

00:20:34,749 --> 00:20:39,369
you know whenever if a package was

00:20:37,149 --> 00:20:41,799
successful and log it and if it wasn't

00:20:39,369 --> 00:20:44,320
successful it can go ahead and send it

00:20:41,799 --> 00:20:46,239
back over to the distributor who would

00:20:44,320 --> 00:20:49,090
eventually send it back to another

00:20:46,239 --> 00:20:52,869
worker thread for some n number of

00:20:49,090 --> 00:20:56,440
configurable times and then the last

00:20:52,869 --> 00:20:59,739
part was the distributor was also

00:20:56,440 --> 00:21:03,609
telling the monitor what it was actually

00:20:59,739 --> 00:21:06,970
sending so the monitor could detect if

00:21:03,609 --> 00:21:08,970
work got lost or had some kind of big

00:21:06,970 --> 00:21:11,720
fatal error

00:21:08,970 --> 00:21:11,720
and so

00:21:11,770 --> 00:21:18,070
and so this would be one Damon don't

00:21:15,340 --> 00:21:21,280
rent and essentially this whole screen

00:21:18,070 --> 00:21:23,350
would work on a cluster of machines and

00:21:21,280 --> 00:21:25,110
each machine would have this Dame and

00:21:23,350 --> 00:21:29,070
running on it and they would be

00:21:25,110 --> 00:21:33,220
coordinated by a database so that's

00:21:29,070 --> 00:21:35,460
that's kind of what inspired this this

00:21:33,220 --> 00:21:42,770
presentation

00:21:35,460 --> 00:21:46,590
so in conclusion working with threads

00:21:42,770 --> 00:21:48,899
can be pretty complicated and will cause

00:21:46,590 --> 00:21:52,490
headaches and you should only use it

00:21:48,899 --> 00:21:56,880
when you really need these features and

00:21:52,490 --> 00:21:59,640
then the runtime logic is very very

00:21:56,880 --> 00:22:02,520
important to understand what your system

00:21:59,640 --> 00:22:06,179
ends up doing and you should pay a lot

00:22:02,520 --> 00:22:10,770
of attention to that design patterns

00:22:06,179 --> 00:22:13,770
help you kind of build out your logic

00:22:10,770 --> 00:22:15,870
and help you figure out what parts you

00:22:13,770 --> 00:22:20,000
really want to distribute and what parts

00:22:15,870 --> 00:22:23,820
you want you don't want to i also found

00:22:20,000 --> 00:22:27,000
for the data sharing in the system

00:22:23,820 --> 00:22:29,970
keeping it simple helps to keep the

00:22:27,000 --> 00:22:32,770
system understandable and helped a lot

00:22:29,970 --> 00:22:34,890
with debugging and

00:22:32,770 --> 00:22:39,010
you have to understand that you're using

00:22:34,890 --> 00:22:40,330
coral threads and there are some special

00:22:39,010 --> 00:22:45,280
cases in there and you should be very

00:22:40,330 --> 00:22:48,820
careful how you use it and the last part

00:22:45,280 --> 00:22:51,250
essentially is you should do a lot of

00:22:48,820 --> 00:22:54,190
testing you know test the parts that

00:22:51,250 --> 00:22:57,400
aren't parallel kind of try to test

00:22:54,190 --> 00:23:00,190
things in one thread and of course do

00:22:57,400 --> 00:23:02,470
thread test and doing a lot of testing

00:23:00,190 --> 00:23:09,520
will help you avoid a lot of the

00:23:02,470 --> 00:23:15,010
pandemonium and and that's it thanks for

00:23:09,520 --> 00:23:18,850
coming and I'm open to any questions any

00:23:15,010 --> 00:23:20,970
questions you start working it's one of

00:23:18,850 --> 00:23:20,970
them

00:23:23,549 --> 00:23:28,429
don't fire multi-level objects on safe

00:23:25,980 --> 00:23:28,429
to use

00:23:31,059 --> 00:23:41,509
I think that's basically just the design

00:23:36,590 --> 00:23:44,869
of the thread shared since just house

00:23:41,509 --> 00:23:47,710
wren sure I believe is an interaction

00:23:44,869 --> 00:23:52,610
because of the locking mechanisms are

00:23:47,710 --> 00:23:56,509
scalar / hashtag or array and their lot

00:23:52,610 --> 00:23:58,489
of block plus an internal second pearl

00:23:56,509 --> 00:24:00,230
engine which is secret which is used to

00:23:58,489 --> 00:24:03,169
actually hold the data and then it's

00:24:00,230 --> 00:24:04,940
pulled out by each hydrant so there's an

00:24:03,169 --> 00:24:07,999
expense of a non-blocking which is done

00:24:04,940 --> 00:24:11,119
and it's never been putting at I decided

00:24:07,999 --> 00:24:13,929
tied yes it gets so complicated with the

00:24:11,119 --> 00:24:16,539
recommended great

00:24:13,929 --> 00:24:18,820
make sense chunky license shared

00:24:16,539 --> 00:24:21,460
variables in ransom are not share and

00:24:18,820 --> 00:24:24,210
hold the local copies that actually

00:24:21,460 --> 00:24:24,210
applies to a

00:24:24,440 --> 00:24:30,919
the confession forest or something it

00:24:27,570 --> 00:24:32,720
just goes to that in threat

00:24:30,919 --> 00:24:35,960
that's something you get back in that

00:24:32,720 --> 00:24:37,850
interim there are locally our little

00:24:35,960 --> 00:24:44,340
puppies there are no shot gardens were

00:24:37,850 --> 00:24:46,909
just big friends there's very sensible

00:24:44,340 --> 00:24:46,909
ok

00:25:00,460 --> 00:25:07,470
all those passages

00:25:04,360 --> 00:25:07,470
database handles

00:25:10,790 --> 00:25:18,520
so for that

00:25:14,140 --> 00:25:22,080
for the database handling to kind of

00:25:18,520 --> 00:25:24,580
deal with the threads issue we had

00:25:22,080 --> 00:25:26,650
basically the one monitor thread would

00:25:24,580 --> 00:25:28,840
talk to that database so we didn't have

00:25:26,650 --> 00:25:32,290
to worry too much about having a lot of

00:25:28,840 --> 00:25:34,060
threads talking so we just kind of

00:25:32,290 --> 00:25:40,440
shuffled that responsibility to one

00:25:34,060 --> 00:25:44,290
thread to keep it single anyone else oh

00:25:40,440 --> 00:25:48,750
yeah I go back the preceding question so

00:25:44,290 --> 00:25:48,750
for using the block three algorithms

00:25:49,620 --> 00:25:59,580
this our objects gonna be a problem that

00:25:52,690 --> 00:25:59,580
put the share little object

00:26:01,370 --> 00:26:08,650
yeah for the wrong

00:26:10,850 --> 00:26:16,340
the data structures in Perl Bernama

00:26:14,210 --> 00:26:18,470
april five were not designed to be

00:26:16,340 --> 00:26:23,510
shared because we were not designed with

00:26:18,470 --> 00:26:30,580
reading invite all good grace so its

00:26:23,510 --> 00:26:30,580
market record than that okay anyone else

00:26:31,059 --> 00:26:35,789
all right thank you for coming

00:26:40,509 --> 00:26:42,570

YouTube URL: https://www.youtube.com/watch?v=IFUTSPeuMZA


