Title: Software Heritage: a status update
Publication date: 2020-02-23
Playlist: MiniDebConf Vaumarcus 2019
Description: 
	by Nicolas Dandrimont

At: MiniDebConf Vaumarcus 2019
https://wiki.debian.org/DebianEvents/ch/2019/Vaumarcus

The Software Heritage project has done great strides since the last time we've talked about it at a Debian conference; this will be a status update ðŸ˜‰

Room: main
Scheduled start: 2019-10-26 14:00:00
Captions: 
	00:00:04,600 --> 00:00:10,629
hi everyone my name is Nicola Don Ramon

00:00:07,660 --> 00:00:15,490
and I'm going to talk to you about the

00:00:10,629 --> 00:00:18,910
software heritage projects so we were

00:00:15,490 --> 00:00:23,009
here we kind of knew that software is

00:00:18,910 --> 00:00:26,919
pretty much everywhere in like

00:00:23,009 --> 00:00:31,270
everything we do everything we use has

00:00:26,919 --> 00:00:34,390
software in it these days and basically

00:00:31,270 --> 00:00:36,370
software is a growing part of our

00:00:34,390 --> 00:00:40,420
scientific technical and cultural

00:00:36,370 --> 00:00:42,970
heritage what so free software people so

00:00:40,420 --> 00:00:46,770
we know that the source code is kind of

00:00:42,970 --> 00:00:49,960
a special object in history

00:00:46,770 --> 00:00:53,490
so the GPL license defines source code

00:00:49,960 --> 00:00:57,370
as the preferred form of modification

00:00:53,490 --> 00:01:01,329
for a given work and basically the

00:00:57,370 --> 00:01:03,610
source code is executable and human

00:01:01,329 --> 00:01:07,750
readable knowledge if you take a binary

00:01:03,610 --> 00:01:10,270
of hello world it's just a bunch of

00:01:07,750 --> 00:01:13,240
bytes that you might be able to decode

00:01:10,270 --> 00:01:15,310
if you're really persistent but it's

00:01:13,240 --> 00:01:19,420
like it's not really understandable

00:01:15,310 --> 00:01:23,580
what's going on in this binary but even

00:01:19,420 --> 00:01:27,100
if you only have basic like

00:01:23,580 --> 00:01:30,570
understanding of English you're also

00:01:27,100 --> 00:01:34,270
able to understand that the source code

00:01:30,570 --> 00:01:36,790
does print so it outputs something and

00:01:34,270 --> 00:01:42,940
probably what it outputs is the string

00:01:36,790 --> 00:01:47,970
hello world so source code is special

00:01:42,940 --> 00:01:51,790
and in the last 50 years there's been an

00:01:47,970 --> 00:01:54,880
exponential growth of software the

00:01:51,790 --> 00:01:57,670
Apollo 11 source code is 11 thousand

00:01:54,880 --> 00:02:00,100
lines of code which is sixty thousand

00:01:57,670 --> 00:02:03,400
nine lines of code which is like tiny

00:02:00,100 --> 00:02:05,170
and there was no such thing as software

00:02:03,400 --> 00:02:09,840
engineering at that point software

00:02:05,170 --> 00:02:12,629
engineering was like this new Wild West

00:02:09,840 --> 00:02:17,469
that we had to that we had to conquer

00:02:12,629 --> 00:02:18,530
today the Linux kernel is I don't know

00:02:17,469 --> 00:02:20,780
20 million line

00:02:18,530 --> 00:02:25,030
of good that's a nude figure I guess

00:02:20,780 --> 00:02:30,890
it's around 25 million lines of code now

00:02:25,030 --> 00:02:33,080
and like this source code is something

00:02:30,890 --> 00:02:35,569
that's like it's an excellent exchange

00:02:33,080 --> 00:02:38,930
medium for developers basically it

00:02:35,569 --> 00:02:40,220
allows developers to understand what's

00:02:38,930 --> 00:02:43,390
going on with the software and

00:02:40,220 --> 00:02:47,540
incidentally computers can execute that

00:02:43,390 --> 00:02:49,580
information basically source code is an

00:02:47,540 --> 00:02:55,100
insight inside the mind of the developer

00:02:49,580 --> 00:02:55,880
of the software source code is data it's

00:02:55,100 --> 00:02:58,820
digital

00:02:55,880 --> 00:03:01,220
it's bytes and like all digital

00:02:58,820 --> 00:03:08,030
information source code is pretty fair

00:03:01,220 --> 00:03:12,019
trade you can have like inconsiderate or

00:03:08,030 --> 00:03:13,459
malicious deletions of code if your

00:03:12,019 --> 00:03:17,690
infrastructure is not maintained

00:03:13,459 --> 00:03:20,239
properly your code hosting platform can

00:03:17,690 --> 00:03:23,900
disappear from one day to the next

00:03:20,239 --> 00:03:28,760
because it's not profitable anymore

00:03:23,900 --> 00:03:30,560
and for obsolete code and for historical

00:03:28,760 --> 00:03:35,630
source code you can even have physical

00:03:30,560 --> 00:03:40,400
decay of the source if you have physical

00:03:35,630 --> 00:03:43,400
media in an attic like magnetic media

00:03:40,400 --> 00:03:48,320
well they can decay and get lost over

00:03:43,400 --> 00:03:50,930
time and we're kind of like where is the

00:03:48,320 --> 00:03:55,670
archive that you can go to when github

00:03:50,930 --> 00:03:59,329
disappears where is the archive like

00:03:55,670 --> 00:04:01,160
where can you find this code and we are

00:03:59,329 --> 00:04:05,000
getting really close to a turning point

00:04:01,160 --> 00:04:07,010
where the people who build computer

00:04:05,000 --> 00:04:11,570
science as we know it are still around

00:04:07,010 --> 00:04:15,260
and can still be used to extract the

00:04:11,570 --> 00:04:20,030
knowledge about the history of software

00:04:15,260 --> 00:04:21,769
and history of technology and so like

00:04:20,030 --> 00:04:24,500
what we want to build is a universal

00:04:21,769 --> 00:04:26,510
platform that can be used for the best

00:04:24,500 --> 00:04:28,520
software source code but also for all

00:04:26,510 --> 00:04:31,220
the future source code that's going to

00:04:28,520 --> 00:04:33,230
be written by humankind

00:04:31,220 --> 00:04:35,120
so this is us this is software heritage

00:04:33,230 --> 00:04:41,360
basically our mission is to collect

00:04:35,120 --> 00:04:43,130
preserve and share the whole source the

00:04:41,360 --> 00:04:46,580
source code of all the software that's

00:04:43,130 --> 00:04:48,590
been written by humankind so we want to

00:04:46,580 --> 00:04:50,270
preserve the past we want to enhance the

00:04:48,590 --> 00:04:50,830
present and we want to prepare for the

00:04:50,270 --> 00:04:53,780
future

00:04:50,830 --> 00:04:57,320
so our core principles basically we want

00:04:53,780 --> 00:05:02,600
to build like a base platform that's

00:04:57,320 --> 00:05:05,390
going to be used by lots of people in

00:05:02,600 --> 00:05:09,760
the industry for research for education

00:05:05,390 --> 00:05:13,130
but also for just the purpose of like

00:05:09,760 --> 00:05:15,430
keeping the data and making sure that it

00:05:13,130 --> 00:05:19,130
doesn't get lost making sure that our

00:05:15,430 --> 00:05:20,780
heritage doesn't get dust we do it with

00:05:19,130 --> 00:05:23,870
an open approach hundred percent free

00:05:20,780 --> 00:05:28,010
software transparent everything that we

00:05:23,870 --> 00:05:30,100
do is done in public on a forge and we

00:05:28,010 --> 00:05:33,500
do it in the wrong hole so we do it

00:05:30,100 --> 00:05:38,140
replicated we have a few agreements with

00:05:33,500 --> 00:05:40,850
mirrors to get copies of the archive

00:05:38,140 --> 00:05:43,760
that are not under our control another

00:05:40,850 --> 00:05:47,419
that I cannot delete by making a mistake

00:05:43,760 --> 00:05:50,450
when I'm tired at nights and we do it as

00:05:47,419 --> 00:05:54,530
a non-profit initiative so basically we

00:05:50,450 --> 00:05:57,350
build a foundation that's not driven by

00:05:54,530 --> 00:06:00,350
business interests so if we do it right

00:05:57,350 --> 00:06:04,340
we should be able to stay live for a

00:06:00,350 --> 00:06:07,070
while so the good of our archive today

00:06:04,340 --> 00:06:10,280
is to target source code repositories

00:06:07,070 --> 00:06:13,730
and source code releases for instance

00:06:10,280 --> 00:06:16,820
taboos that have published so we do

00:06:13,730 --> 00:06:20,240
archive the contents of the files the

00:06:16,820 --> 00:06:22,460
revisions so git commits or as when

00:06:20,240 --> 00:06:25,220
commits we for the metadata the

00:06:22,460 --> 00:06:29,030
authorship data the dates etc etc okay

00:06:25,220 --> 00:06:32,120
the releases and of course we record

00:06:29,030 --> 00:06:34,550
where and when we've found all this data

00:06:32,120 --> 00:06:38,890
and everything is stored in a canonical

00:06:34,550 --> 00:06:41,210
data model that's the same for all the

00:06:38,890 --> 00:06:42,500
version control systems that we use

00:06:41,210 --> 00:06:45,290
report

00:06:42,500 --> 00:06:47,960
we don't have everything that's around

00:06:45,290 --> 00:06:51,740
the source code we don't like I've pages

00:06:47,960 --> 00:06:55,370
or wikis we don't archive issues we

00:06:51,740 --> 00:06:56,930
don't archive mailing lists like we know

00:06:55,370 --> 00:07:02,060
that this is something that's incredibly

00:06:56,930 --> 00:07:05,120
important but this is like we started

00:07:02,060 --> 00:07:08,720
somewhere and we know that there's a lot

00:07:05,120 --> 00:07:10,490
of factors that do this right already so

00:07:08,720 --> 00:07:13,400
our vision is to collaborate with them

00:07:10,490 --> 00:07:16,730
and play our part in like being one cog

00:07:13,400 --> 00:07:21,290
in the machine of something like a

00:07:16,730 --> 00:07:25,930
semantic Wikipedia or like yeah

00:07:21,290 --> 00:07:28,310
basically an encyclopedia of software

00:07:25,930 --> 00:07:30,230
where we could collaborate with the

00:07:28,310 --> 00:07:32,990
Internet Archive for instance to archive

00:07:30,230 --> 00:07:37,690
all the web parts that are around source

00:07:32,990 --> 00:07:42,740
code so the data flow basically we have

00:07:37,690 --> 00:07:46,669
upstream repositories that we list every

00:07:42,740 --> 00:07:52,210
once in a while and all the source all

00:07:46,669 --> 00:07:55,250
those sources that we find we load them

00:07:52,210 --> 00:07:58,190
regularly as well and we make sure that

00:07:55,250 --> 00:08:02,120
all the data is dedicated so we don't

00:07:58,190 --> 00:08:04,820
waste space the idea is that we're going

00:08:02,120 --> 00:08:06,590
to archive redundant sources for

00:08:04,820 --> 00:08:09,380
instance we are going to archive Forks

00:08:06,590 --> 00:08:11,360
of repositories and those Forks will

00:08:09,380 --> 00:08:15,220
share a lot of the data with the parent

00:08:11,360 --> 00:08:19,520
repositories so we don't want to store

00:08:15,220 --> 00:08:21,590
25,000 copies of the gplv3 text file for

00:08:19,520 --> 00:08:24,680
instance because that's there's no point

00:08:21,590 --> 00:08:27,650
in that so what we use to do that is a

00:08:24,680 --> 00:08:29,180
macro tree so basically it's a

00:08:27,650 --> 00:08:36,979
combination of a tree and a hash

00:08:29,180 --> 00:08:40,400
function so every basically every node

00:08:36,979 --> 00:08:44,360
in the tree is identified by your hash

00:08:40,400 --> 00:08:47,690
of the contents and of its children so

00:08:44,360 --> 00:08:50,839
you can quickly check that something

00:08:47,690 --> 00:08:54,830
already exists in your tree so this is

00:08:50,839 --> 00:08:56,150
what git uses this is what like block

00:08:54,830 --> 00:08:58,820
chains use I

00:08:56,150 --> 00:09:01,420
this is that and it gives you the

00:08:58,820 --> 00:09:03,830
duplication for free because you just

00:09:01,420 --> 00:09:06,340
compute the hash of your content you

00:09:03,830 --> 00:09:09,440
check if you already have it or not and

00:09:06,340 --> 00:09:11,390
yeah and it also gives you integrity

00:09:09,440 --> 00:09:14,780
checking so we can make sure that your

00:09:11,390 --> 00:09:20,300
data doesn't rot so our archive

00:09:14,780 --> 00:09:23,330
basically the leaves our contents and

00:09:20,300 --> 00:09:25,430
then you have directories that have sets

00:09:23,330 --> 00:09:31,180
of files with names and then you have

00:09:25,430 --> 00:09:35,690
revisions revisions are simply like

00:09:31,180 --> 00:09:39,280
snapshot in time of a directory with an

00:09:35,690 --> 00:09:43,250
author information and a timestamp and

00:09:39,280 --> 00:09:45,440
basically a set of branches so a set of

00:09:43,250 --> 00:09:47,240
revisions gives us a snapshot of a

00:09:45,440 --> 00:09:51,500
repository so for instance for github

00:09:47,240 --> 00:09:53,390
and for a git repository you'd get the

00:09:51,500 --> 00:09:55,100
list of all the branches pointing at all

00:09:53,390 --> 00:09:58,430
the commits which points to their

00:09:55,100 --> 00:10:01,670
parents etc etcetera recursively and

00:09:58,430 --> 00:10:05,000
this is basically the contents of the

00:10:01,670 --> 00:10:09,700
archive so this is another description

00:10:05,000 --> 00:10:12,230
with like actual file these things and

00:10:09,700 --> 00:10:15,380
contents and the idea of a snapshot with

00:10:12,230 --> 00:10:19,730
a list of branches I guess it's pretty

00:10:15,380 --> 00:10:22,730
small on this screen and basically this

00:10:19,730 --> 00:10:25,880
is incremental so if we visit the same

00:10:22,730 --> 00:10:27,860
repository again and the list of

00:10:25,880 --> 00:10:29,990
branches hasn't changed we only point to

00:10:27,860 --> 00:10:35,330
the same object and if you add a new

00:10:29,990 --> 00:10:38,060
revision then we expand the tree but

00:10:35,330 --> 00:10:42,920
like we still point to the original data

00:10:38,060 --> 00:10:45,290
that we found at the first visit so the

00:10:42,920 --> 00:10:48,230
coverage of the archive you can look at

00:10:45,290 --> 00:10:51,700
archived at software ETH the dog we have

00:10:48,230 --> 00:10:54,470
bit fancier graphs on the home page now

00:10:51,700 --> 00:10:57,350
basically more than 6 billion unique

00:10:54,470 --> 00:11:01,250
source files referenced from all these

00:10:57,350 --> 00:11:03,620
sources or github Debian gitlab and a

00:11:01,250 --> 00:11:06,350
lot of get lab instances basically every

00:11:03,620 --> 00:11:08,670
time we find yoga type instance we try

00:11:06,350 --> 00:11:11,290
to edit tor

00:11:08,670 --> 00:11:14,320
to our infrastructure we've also

00:11:11,290 --> 00:11:16,990
archived some repositories that have

00:11:14,320 --> 00:11:19,990
closed down like Google code and guitar

00:11:16,990 --> 00:11:23,380
use that we've been lucky enough to get

00:11:19,990 --> 00:11:29,290
like food archives off and then we've

00:11:23,380 --> 00:11:30,610
started indexing and archiving like

00:11:29,290 --> 00:11:35,200
programming language package

00:11:30,610 --> 00:11:39,279
repositories like NPM and Piper so we're

00:11:35,200 --> 00:11:43,950
starting to like expand our coverage we

00:11:39,279 --> 00:11:47,470
also allow scientific software

00:11:43,950 --> 00:11:49,570
developers to deposit their software so

00:11:47,470 --> 00:11:53,950
basically if you have a research article

00:11:49,570 --> 00:11:55,870
with attached software if you publish it

00:11:53,950 --> 00:11:58,839
so far now it's on the french open

00:11:55,870 --> 00:12:02,350
science repository the French Open says

00:11:58,839 --> 00:12:04,089
repository will push the source code

00:12:02,350 --> 00:12:06,880
that's been published with the article

00:12:04,089 --> 00:12:10,630
so that it gets archived in software

00:12:06,880 --> 00:12:14,350
heritage of course we want to expand

00:12:10,630 --> 00:12:18,630
this initiative by like opening access

00:12:14,350 --> 00:12:24,640
to more repositories for them to push

00:12:18,630 --> 00:12:27,550
source code to us so in numbers around

00:12:24,640 --> 00:12:30,279
400 terabytes of uncompressed source

00:12:27,550 --> 00:12:34,870
files which is not that big because well

00:12:30,279 --> 00:12:37,330
it's or text files which is small it

00:12:34,870 --> 00:12:43,589
forms a graph that's 20 billion nodes

00:12:37,330 --> 00:12:43,589
and around 300 billion edges which is

00:12:43,800 --> 00:12:51,279
like it's around the scale of some like

00:12:49,180 --> 00:12:56,650
some companies I have graphs of the web

00:12:51,279 --> 00:12:58,750
it's around the same size but the shape

00:12:56,650 --> 00:13:00,850
of our graph is a bit different and what

00:12:58,750 --> 00:13:06,640
the web has because we have long chains

00:13:00,850 --> 00:13:09,040
of revisions in histories so we think

00:13:06,640 --> 00:13:10,990
that we have the richest public source

00:13:09,040 --> 00:13:15,160
code archive and it's still growing

00:13:10,990 --> 00:13:17,440
dady so if you want to look at the web

00:13:15,160 --> 00:13:21,660
interface I gave that software attached

00:13:17,440 --> 00:13:26,320
to the dog so we have a few

00:13:21,660 --> 00:13:30,370
like cool things show so the Apollo 11

00:13:26,320 --> 00:13:33,399
source code has been digitized and put

00:13:30,370 --> 00:13:36,279
on github so basically they took the

00:13:33,399 --> 00:13:38,560
transcripts from the MIT Museum and they

00:13:36,279 --> 00:13:43,450
scanned them page by page and then they

00:13:38,560 --> 00:13:46,390
run OCR and then they reread all the

00:13:43,450 --> 00:13:49,990
source code to make sure that the OCR

00:13:46,390 --> 00:13:56,260
process was okay and so you can browse

00:13:49,990 --> 00:14:12,730
the Apollo software if I move this to a

00:13:56,260 --> 00:14:15,790
new window so basically you have the

00:14:12,730 --> 00:14:20,079
source code that's been used to land on

00:14:15,790 --> 00:14:22,140
the moon for the 50th anniversary of the

00:14:20,079 --> 00:14:24,610
Apollo program some people actually

00:14:22,140 --> 00:14:26,100
restored one of the original computers

00:14:24,610 --> 00:14:29,050
and made sure that they could run

00:14:26,100 --> 00:14:40,060
updated source code on the updated

00:14:29,050 --> 00:14:46,350
binary code on this machine so yeah this

00:14:40,060 --> 00:14:50,560
is this is not too bad I'm gonna

00:14:46,350 --> 00:14:53,470
continue we all know that the quake free

00:14:50,560 --> 00:14:56,290
source code has been published as a GPL

00:14:53,470 --> 00:15:00,279
as well so it's on github and we managed

00:14:56,290 --> 00:15:04,420
to recover it so we get some like

00:15:00,279 --> 00:15:07,510
interesting tidbits of what happened

00:15:04,420 --> 00:15:12,120
during the development of a quake free

00:15:07,510 --> 00:15:16,209
for instance you have this very fancy

00:15:12,120 --> 00:15:21,490
inverse square root computation function

00:15:16,209 --> 00:15:25,360
which does some dark dark magic and yeah

00:15:21,490 --> 00:15:28,360
they the person who came next wasn't

00:15:25,360 --> 00:15:35,470
quite sure what was going on here

00:15:28,360 --> 00:15:38,799
oh yeah so you can search so basically

00:15:35,470 --> 00:15:41,949
the search currently is just in the URL

00:15:38,799 --> 00:15:45,309
of the repository that we've archived or

00:15:41,949 --> 00:15:47,709
the project we are working hard to make

00:15:45,309 --> 00:15:49,509
sure that we can do metadata search so

00:15:47,709 --> 00:15:51,399
basically pull the metadata from the

00:15:49,509 --> 00:15:56,499
repositories and make sure that we can

00:15:51,399 --> 00:16:01,179
search for that we have a calendar view

00:15:56,499 --> 00:16:05,489
of the visits of the repositories and

00:16:01,179 --> 00:16:11,259
then browsing we look at that already so

00:16:05,489 --> 00:16:14,470
in the backend we use a lot of free

00:16:11,259 --> 00:16:16,600
software with debian we just practice

00:16:14,470 --> 00:16:21,459
bugs as a virtualization layer on top of

00:16:16,600 --> 00:16:24,819
debian we've started using ZFS a few few

00:16:21,459 --> 00:16:28,779
months ago we're quite happy with it for

00:16:24,819 --> 00:16:30,179
now and we use puppets to deploy all our

00:16:28,779 --> 00:16:33,129
software

00:16:30,179 --> 00:16:40,569
so the meta data storage is done with

00:16:33,129 --> 00:16:42,579
post recycle which is okay we're kind of

00:16:40,569 --> 00:16:46,119
having some growing pains because the

00:16:42,579 --> 00:16:48,910
database is starting to be around 7 8

00:16:46,119 --> 00:16:52,959
terabytes with indexes which is still

00:16:48,910 --> 00:16:55,269
quite manageable but yeah it's we could

00:16:52,959 --> 00:16:57,790
do better because the data structure

00:16:55,269 --> 00:17:00,699
that we have is like massively parallel

00:16:57,790 --> 00:17:07,089
laser ball so we could do better than

00:17:00,699 --> 00:17:10,720
Postgres the tasks the task scheduling

00:17:07,089 --> 00:17:14,860
is done using Siri we use Python pretty

00:17:10,720 --> 00:17:18,250
much everywhere and we use bootstrap in

00:17:14,860 --> 00:17:21,010
D free for the web stuff what we've

00:17:18,250 --> 00:17:23,620
developed in-house the object storage

00:17:21,010 --> 00:17:28,049
we've written ourselves the idea is that

00:17:23,620 --> 00:17:31,269
we didn't want to force our mirrors to

00:17:28,049 --> 00:17:32,529
deploy on something specific so

00:17:31,269 --> 00:17:37,720
basically we have an abstraction layer

00:17:32,529 --> 00:17:41,470
which is a very simple put get interface

00:17:37,720 --> 00:17:46,210
and then we have implementations for

00:17:41,470 --> 00:17:48,150
Free Asia storage safe and just putting

00:17:46,210 --> 00:17:53,230
the fives on the plane Friday system

00:17:48,150 --> 00:17:55,150
this works pretty well all the data

00:17:53,230 --> 00:17:56,679
model implementation the distance to

00:17:55,150 --> 00:17:59,559
load us the scheduler everything is

00:17:56,679 --> 00:18:05,409
written in Python BIOS

00:17:59,559 --> 00:18:10,409
so this spans 20 Python packages and the

00:18:05,409 --> 00:18:14,289
deployments is around 1440 AD by Jules

00:18:10,409 --> 00:18:16,720
it's not a very big code base we've

00:18:14,289 --> 00:18:20,740
tried to make sure that everything that

00:18:16,720 --> 00:18:22,630
we do now can run also in darker so you

00:18:20,740 --> 00:18:25,690
can actually run your own software

00:18:22,630 --> 00:18:29,190
attach like model thing so you can

00:18:25,690 --> 00:18:34,570
actually get into the code and start

00:18:29,190 --> 00:18:38,049
submitting patches everything we do is

00:18:34,570 --> 00:18:41,559
copy left at least for the back end

00:18:38,049 --> 00:18:43,480
stuff for the puppet stuff we use the

00:18:41,559 --> 00:18:47,530
apache license because that's what most

00:18:43,480 --> 00:18:49,750
of the particular system uses and so we

00:18:47,530 --> 00:18:51,880
try to be friendly to the rest of the

00:18:49,750 --> 00:18:56,789
ecosystems so that we can cross

00:18:51,880 --> 00:19:01,360
pollinate stuff so the deployment

00:18:56,789 --> 00:19:03,520
architecture so at the bottom we have

00:19:01,360 --> 00:19:08,860
our object storage which which only

00:19:03,520 --> 00:19:12,789
stores the source code files and then

00:19:08,860 --> 00:19:16,059
the metadata storage is in possibly a

00:19:12,789 --> 00:19:18,370
sequel database so basically the graph

00:19:16,059 --> 00:19:23,890
storage is split between metadata and

00:19:18,370 --> 00:19:26,500
actual data and then the main components

00:19:23,890 --> 00:19:31,270
are the Lister loader and indexer

00:19:26,500 --> 00:19:38,669
workers which took to a salary broker

00:19:31,270 --> 00:19:41,710
which is basically RabbitMQ and so the

00:19:38,669 --> 00:19:43,780
scheduler components has the list of

00:19:41,710 --> 00:19:47,440
tasks that are recurring and then we

00:19:43,780 --> 00:19:50,460
have two small components that just push

00:19:47,440 --> 00:19:55,149
and pull to rabbitmq from the database

00:19:50,460 --> 00:19:58,139
because we've had some issues with Sarah

00:19:55,149 --> 00:20:00,039
and reliability like if you want

00:19:58,139 --> 00:20:05,169
semantics while you're sure that all

00:20:00,039 --> 00:20:09,159
your tasks have been executed like it's

00:20:05,169 --> 00:20:12,129
not we've had issues when putting

00:20:09,159 --> 00:20:15,940
hundred million tasks in celery itself

00:20:12,129 --> 00:20:19,479
so we've tried to just use the broker as

00:20:15,940 --> 00:20:21,279
a buffer make sure that all the

00:20:19,479 --> 00:20:22,779
information about the tasks are actually

00:20:21,279 --> 00:20:26,249
stored in the database

00:20:22,779 --> 00:20:30,580
maybe we're just doing it wrong it's

00:20:26,249 --> 00:20:35,649
something that we've had to do Hardware

00:20:30,580 --> 00:20:37,929
a few hypervisors one main database

00:20:35,649 --> 00:20:44,190
server and then some replicas as

00:20:37,929 --> 00:20:52,119
containers to dedicated servers using

00:20:44,190 --> 00:20:54,129
blank ZFS these days and we high density

00:20:52,119 --> 00:21:00,339
storage arrays which are basically big

00:20:54,129 --> 00:21:02,289
boxes full of hard drives and we've got

00:21:00,339 --> 00:21:04,539
some sponsorship from Microsoft which

00:21:02,289 --> 00:21:08,979
allows us to run a food mirror of an

00:21:04,539 --> 00:21:12,999
infrastructure on Azure we also put some

00:21:08,979 --> 00:21:16,029
workers there but we only use Linux

00:21:12,999 --> 00:21:20,169
virtual machines so that we can deploy

00:21:16,029 --> 00:21:23,499
them anywhere else that we want by just

00:21:20,169 --> 00:21:26,679
changing the deployment manifests we

00:21:23,499 --> 00:21:30,009
don't want to get locked into a cloud

00:21:26,679 --> 00:21:34,330
provider so we make sure that all the

00:21:30,009 --> 00:21:39,179
data that we generates gets sent back to

00:21:34,330 --> 00:21:43,029
our own infrastructure at least for now

00:21:39,179 --> 00:21:45,159
everything is done through classic force

00:21:43,029 --> 00:21:48,219
development practices we do everything

00:21:45,159 --> 00:21:51,639
in English even though almost all of the

00:21:48,219 --> 00:21:55,109
team is French we have a public

00:21:51,639 --> 00:21:57,519
development mailing lists IRC channel

00:21:55,109 --> 00:22:01,929
source code and code review on a

00:21:57,519 --> 00:22:06,190
fabricator instance and yeah that's it

00:22:01,929 --> 00:22:08,080
for the overview so what happened lately

00:22:06,190 --> 00:22:09,880
in the project

00:22:08,080 --> 00:22:12,460
so last summer we had a very successful

00:22:09,880 --> 00:22:15,340
Google Summer of Code session we had

00:22:12,460 --> 00:22:20,830
three interns who worked on different

00:22:15,340 --> 00:22:23,500
parts of the of the project so one of

00:22:20,830 --> 00:22:25,690
the interns arch it worked on increasing

00:22:23,500 --> 00:22:27,760
the coverage of the archive so basically

00:22:25,690 --> 00:22:31,080
he worked on making sure that we had

00:22:27,760 --> 00:22:35,019
Lister's for new upstream repositories

00:22:31,080 --> 00:22:40,360
so we introduced transistor which is the

00:22:35,019 --> 00:22:42,309
repository for our modules we he has

00:22:40,360 --> 00:22:46,090
rewritten the history for the new

00:22:42,309 --> 00:22:49,029
project so we can I get all the source

00:22:46,090 --> 00:22:51,880
code from the like releases of the new

00:22:49,029 --> 00:22:56,070
project and then his refactored

00:22:51,880 --> 00:23:01,539
the Lister's for the node.js and ruby

00:22:56,070 --> 00:23:04,269
ecosystems as well and i've not finished

00:23:01,539 --> 00:23:05,830
that phrase which city but anyway he's

00:23:04,269 --> 00:23:11,320
also worked on making sure that the

00:23:05,830 --> 00:23:16,179
loaders used the same base basis code

00:23:11,320 --> 00:23:20,010
and so like introducing a loader for a

00:23:16,179 --> 00:23:23,230
new upstream repository is just like

00:23:20,010 --> 00:23:26,169
overriding a few methods to actually do

00:23:23,230 --> 00:23:29,580
get the metadata in the right place and

00:23:26,169 --> 00:23:32,260
everything like entering the turbo

00:23:29,580 --> 00:23:37,929
generating the manifests to load in the

00:23:32,260 --> 00:23:42,669
archive is just hidden under the under

00:23:37,929 --> 00:23:45,360
the hood so loading a new like language

00:23:42,669 --> 00:23:50,789
ecosystem I don't know Perl for instance

00:23:45,360 --> 00:23:50,789
would be just a few dozen lines of code

00:23:51,720 --> 00:23:59,080
calpads another intern worked on a web

00:23:55,630 --> 00:24:00,970
front-end and the major thing that he

00:23:59,080 --> 00:24:05,860
introduced is end-to-end testing of the

00:24:00,970 --> 00:24:07,720
fronton so basically it's a JavaScript

00:24:05,860 --> 00:24:09,789
module that's called Cypress and

00:24:07,720 --> 00:24:12,820
basically what it does it instruments

00:24:09,789 --> 00:24:15,789
web browser it allows you to click and

00:24:12,820 --> 00:24:18,940
to record what happens on the page so

00:24:15,789 --> 00:24:20,020
you have a full test of audio JavaScript

00:24:18,940 --> 00:24:22,590
and

00:24:20,020 --> 00:24:25,540
all your interactions with the server

00:24:22,590 --> 00:24:28,120
without a single click which is quite

00:24:25,540 --> 00:24:30,400
nice because we are starting to have

00:24:28,120 --> 00:24:32,560
like a lot of features and it's hard not

00:24:30,400 --> 00:24:36,000
to break those features by changing

00:24:32,560 --> 00:24:40,000
stuff in the backend so yeah having

00:24:36,000 --> 00:24:44,920
integration of web QA is is very good

00:24:40,000 --> 00:24:47,530
and so it's we are glad that he had the

00:24:44,920 --> 00:24:50,230
opportunity to work on that and the last

00:24:47,530 --> 00:24:53,500
intern tebow worked on graph compression

00:24:50,230 --> 00:24:56,230
so it was more research focused

00:24:53,500 --> 00:24:59,790
internship basically the idea is that we

00:24:56,230 --> 00:25:02,560
have tens of billions of nodes and

00:24:59,790 --> 00:25:08,040
hundreds of billions of edges in our

00:25:02,560 --> 00:25:11,710
graph and so if you store them like

00:25:08,040 --> 00:25:14,560
knavery you can't fit everything in a

00:25:11,710 --> 00:25:18,340
single machine at least not in memory

00:25:14,560 --> 00:25:22,410
and so lookups and recursion is really

00:25:18,340 --> 00:25:25,540
slow but the people who have worked on

00:25:22,410 --> 00:25:27,640
like crawling the web have done a lot of

00:25:25,540 --> 00:25:30,450
work in making sure that you can

00:25:27,640 --> 00:25:35,110
compress graphs of a very large size

00:25:30,450 --> 00:25:37,570
into some manageable memory and so I

00:25:35,110 --> 00:25:42,460
think the results that he's managed to

00:25:37,570 --> 00:25:44,170
achieve are being able to store the

00:25:42,460 --> 00:25:46,900
photograph of the software heritage

00:25:44,170 --> 00:25:50,500
archive in 300 gigabytes of RAM which is

00:25:46,900 --> 00:25:54,670
tiny it's like you can have that on a

00:25:50,500 --> 00:25:58,360
single machine one use over and then you

00:25:54,670 --> 00:26:00,280
can do very fast algorithms to do large

00:25:58,360 --> 00:26:07,120
scale analysis on a single machine which

00:26:00,280 --> 00:26:10,240
is useful when you're only like if your

00:26:07,120 --> 00:26:13,600
research team and you don't have lots of

00:26:10,240 --> 00:26:17,410
resources it's useful to be able to work

00:26:13,600 --> 00:26:20,790
on a smaller scale than having a huge

00:26:17,410 --> 00:26:23,710
Hadoop cluster running in a cloud and

00:26:20,790 --> 00:26:26,230
spending tens and tens of thousands of

00:26:23,710 --> 00:26:29,620
euros to be able to do a join between

00:26:26,230 --> 00:26:31,570
two tables because the algorithms in

00:26:29,620 --> 00:26:33,549
these things are crap and you end up

00:26:31,570 --> 00:26:37,929
scanning all the data to

00:26:33,549 --> 00:26:40,119
just do simple join so so basically yeah

00:26:37,929 --> 00:26:43,389
this is the basis for a new toolkit that

00:26:40,119 --> 00:26:45,549
we are going to put out for helping the

00:26:43,389 --> 00:26:49,269
scientific community analyzed source

00:26:45,549 --> 00:26:53,279
code in large scale which is one of the

00:26:49,269 --> 00:26:56,190
things that we really want to to enable

00:26:53,279 --> 00:27:00,070
so I've talked about replication earlier

00:26:56,190 --> 00:27:03,369
we've signed mirroring agreements with

00:27:00,070 --> 00:27:06,179
two partner organizations so first ID is

00:27:03,369 --> 00:27:08,919
a Swedish company that's focused on

00:27:06,179 --> 00:27:12,480
license compliance in the open source

00:27:08,919 --> 00:27:15,669
world so basically making sure that

00:27:12,480 --> 00:27:19,899
companies know the licenses of those

00:27:15,669 --> 00:27:22,210
software components they use and Aniyah

00:27:19,899 --> 00:27:26,259
is the Italian national agency for new

00:27:22,210 --> 00:27:29,499
technologies basically that the former

00:27:26,259 --> 00:27:33,759
Atomic Energy Commission of Italy so the

00:27:29,499 --> 00:27:37,419
public institution and they want to

00:27:33,759 --> 00:27:40,929
support actually the work on software

00:27:37,419 --> 00:27:44,529
sustainability and so our infrastructure

00:27:40,929 --> 00:27:52,239
will be based on by is based on Kafka so

00:27:44,529 --> 00:27:54,820
kefka is a basically a message bus which

00:27:52,239 --> 00:28:00,190
is like fully distributed you can scale

00:27:54,820 --> 00:28:01,809
it scale it as you wish one of the one

00:28:00,190 --> 00:28:05,159
of the big deployments of CAF car that I

00:28:01,809 --> 00:28:08,649
know is in the Wikimedia Foundation

00:28:05,159 --> 00:28:12,159
every event that happens on the

00:28:08,649 --> 00:28:14,320
Wikimedia projects is pushed to calf

00:28:12,159 --> 00:28:16,659
care cluster and then Lions can

00:28:14,320 --> 00:28:19,859
subscribe to events and get them

00:28:16,659 --> 00:28:23,350
real-time and make sure that they can

00:28:19,859 --> 00:28:26,230
like trigger actions on events that

00:28:23,350 --> 00:28:29,440
happen at the scale of the Wikimedia

00:28:26,230 --> 00:28:31,929
projects which is fairly large so

00:28:29,440 --> 00:28:34,119
basically what we do is we push all the

00:28:31,929 --> 00:28:36,309
types of objects to different topics as

00:28:34,119 --> 00:28:38,529
soon as they're added to the archive and

00:28:36,309 --> 00:28:42,039
they said as I don't build a full

00:28:38,529 --> 00:28:43,629
replica of the archive should just start

00:28:42,039 --> 00:28:45,580
at the beginning and replay all the

00:28:43,629 --> 00:28:47,380
objects then you can get the full graph

00:28:45,580 --> 00:28:48,880
you can just subscribe

00:28:47,380 --> 00:28:52,140
to some objectives for instance if

00:28:48,880 --> 00:28:54,700
you're interested in I don't know

00:28:52,140 --> 00:29:00,160
analyzing the language in get commits

00:28:54,700 --> 00:29:02,020
you can just subscribe to the revision

00:29:00,160 --> 00:29:04,960
topic and read the messages and do

00:29:02,020 --> 00:29:09,220
whatever you want with them so this is a

00:29:04,960 --> 00:29:12,310
work in progress in a sense that we have

00:29:09,220 --> 00:29:14,680
the tools that have been built and our

00:29:12,310 --> 00:29:16,930
partner organizations are building their

00:29:14,680 --> 00:29:20,370
infrastructure on their side and we're

00:29:16,930 --> 00:29:24,120
going to push the data with them soon

00:29:20,370 --> 00:29:27,400
and finally we've worked on improving

00:29:24,120 --> 00:29:31,210
what we do on preservation so in

00:29:27,400 --> 00:29:33,280
February we published the Paris core for

00:29:31,210 --> 00:29:34,930
software source code as heritage for

00:29:33,280 --> 00:29:40,570
sustainable development so it's a

00:29:34,930 --> 00:29:43,840
mouthful but basically it's a simple

00:29:40,570 --> 00:29:46,420
call I think it's like 20 or 30 points

00:29:43,840 --> 00:29:49,030
to raise global awareness of the

00:29:46,420 --> 00:29:51,150
importance of preserving software in

00:29:49,030 --> 00:29:53,530
general and source code in particular

00:29:51,150 --> 00:29:59,980
for sustainable development basically

00:29:53,530 --> 00:30:03,940
it's like I think that was there was a

00:29:59,980 --> 00:30:09,070
meeting with 40 experts on preservation

00:30:03,940 --> 00:30:12,790
on software and they agreed to like cool

00:30:09,070 --> 00:30:16,680
on the global community to make sure

00:30:12,790 --> 00:30:19,330
that software source code was treated as

00:30:16,680 --> 00:30:22,510
the important of leg that he that it is

00:30:19,330 --> 00:30:24,850
because everything that we do in society

00:30:22,510 --> 00:30:27,040
today is mediated by software in one way

00:30:24,850 --> 00:30:30,250
or another and it's very important that

00:30:27,040 --> 00:30:34,570
we make sure that this software isn't

00:30:30,250 --> 00:30:39,490
lost and is understandable by the people

00:30:34,570 --> 00:30:42,790
who use it and lastly what we did in a

00:30:39,490 --> 00:30:45,220
few weeks ago so in collaboration with

00:30:42,790 --> 00:30:47,260
the University of Pisa we have published

00:30:45,220 --> 00:30:51,610
a software heritage acquisition protocol

00:30:47,260 --> 00:30:56,100
so basically what we had done so far was

00:30:51,610 --> 00:31:00,040
trying to do the not the easiest but

00:30:56,100 --> 00:31:01,389
well kind of the easiest thing that we

00:31:00,040 --> 00:31:03,579
can do to archive software

00:31:01,389 --> 00:31:05,440
is just putting every single piece of

00:31:03,579 --> 00:31:08,289
software that's publicly available and

00:31:05,440 --> 00:31:10,379
putting it in one place that's nice but

00:31:08,289 --> 00:31:13,959
there's a lot of software that's just

00:31:10,379 --> 00:31:17,619
not publicly available there's a lot of

00:31:13,959 --> 00:31:20,859
software that's rotting in an attic in a

00:31:17,619 --> 00:31:23,469
university somewhere there's a lot of

00:31:20,859 --> 00:31:27,429
stuff in museums that isn't really

00:31:23,469 --> 00:31:32,039
exploitable by the public and so with

00:31:27,429 --> 00:31:36,399
the University of Pisa who has a lot of

00:31:32,039 --> 00:31:39,129
artifacts from the basically the history

00:31:36,399 --> 00:31:43,209
of Italian computer science they have

00:31:39,129 --> 00:31:45,729
stuff that dates back from the 50s of

00:31:43,209 --> 00:31:50,440
all the computers that have run in Italy

00:31:45,729 --> 00:31:53,889
since the beginning of computers and so

00:31:50,440 --> 00:31:58,299
we have worked with them to put in place

00:31:53,889 --> 00:32:00,219
a process of collection basically making

00:31:58,299 --> 00:32:02,789
sure that people can digitize the

00:32:00,219 --> 00:32:06,759
software and put it in an exploitable

00:32:02,789 --> 00:32:10,239
exploitable format and then collection

00:32:06,759 --> 00:32:14,829
which means allowing software heritage

00:32:10,239 --> 00:32:17,889
to pull the source code and protect it

00:32:14,829 --> 00:32:21,369
and of curation which is making sure

00:32:17,889 --> 00:32:26,139
that the meaningful historical source

00:32:21,369 --> 00:32:29,909
code is like well published and is

00:32:26,139 --> 00:32:33,849
exploitable for everyone so all these

00:32:29,909 --> 00:32:35,320
new things when I publish the slides

00:32:33,849 --> 00:32:37,149
there's going to be links on the slide

00:32:35,320 --> 00:32:41,049
so if you're interested you'd be just

00:32:37,149 --> 00:32:43,119
able to click the links and so that's it

00:32:41,049 --> 00:32:45,779
we have a Wayback Machine for source

00:32:43,119 --> 00:32:49,359
code this is a huge reference catalog

00:32:45,779 --> 00:32:52,959
using intrinsic identifiers for software

00:32:49,359 --> 00:32:57,039
people can deposit their source code and

00:32:52,959 --> 00:33:00,489
with we're building like the universal

00:32:57,039 --> 00:33:02,679
knowledge base about source code much

00:33:00,489 --> 00:33:05,159
more is in store I've talked a lot about

00:33:02,679 --> 00:33:08,440
that thank you

00:33:05,159 --> 00:33:11,709
this is software heritage we're open so

00:33:08,440 --> 00:33:14,299
if you're interested I have 10 minutes

00:33:11,709 --> 00:33:22,549
for questions which you

00:33:14,299 --> 00:33:28,009
want to know more what do I have to do

00:33:22,549 --> 00:33:32,200
if I want to contribute code to it so if

00:33:28,009 --> 00:33:38,149
you want to contribute not right yes I

00:33:32,200 --> 00:33:42,799
understood so right now we have the

00:33:38,149 --> 00:33:47,470
ability well so we have a safe code now

00:33:42,799 --> 00:33:50,389
feature that currently only works on

00:33:47,470 --> 00:33:53,419
repositories so get subversion or

00:33:50,389 --> 00:33:57,279
mercurial I think we should be able to

00:33:53,419 --> 00:34:00,669
actually move it to also Dow tables of

00:33:57,279 --> 00:34:03,320
software so basically you put the URL

00:34:00,669 --> 00:34:05,059
that's a simple review process done by

00:34:03,320 --> 00:34:06,740
administrators to make sure that we can

00:34:05,059 --> 00:34:08,770
download and redistribute the response

00:34:06,740 --> 00:34:11,270
code and then it ends up on the archive

00:34:08,770 --> 00:34:12,980
so if you go to archive that's Australia

00:34:11,270 --> 00:34:20,599
techno talk there's a safeguard Now

00:34:12,980 --> 00:34:22,700
button that you can use so it at the

00:34:20,599 --> 00:34:24,889
moment it only works for version control

00:34:22,700 --> 00:34:27,470
just for now yes okay

00:34:24,889 --> 00:34:30,589
we've been discussing adding the

00:34:27,470 --> 00:34:34,579
possibility of submitting doubles as

00:34:30,589 --> 00:34:37,490
well that's what yeah at some point I

00:34:34,579 --> 00:34:46,299
noticed that some software I was using

00:34:37,490 --> 00:34:46,299
in the past vanished from the net right

00:34:49,329 --> 00:35:02,380
and there's another place which is much

00:34:54,470 --> 00:35:02,380
better suited than my right so yeah we

00:35:03,400 --> 00:35:09,530
actually there's a desert vacation

00:35:06,619 --> 00:35:11,839
period right now in France but just

00:35:09,530 --> 00:35:13,520
after some of my colleagues left for

00:35:11,839 --> 00:35:16,520
vacation they were just completing

00:35:13,520 --> 00:35:19,240
refactoring of all the loading machinery

00:35:16,520 --> 00:35:24,890
and after that we should be able to add

00:35:19,240 --> 00:35:27,680
tables to the safe cut now interface so

00:35:24,890 --> 00:35:28,230
you can just and you can even automate

00:35:27,680 --> 00:35:39,990
it

00:35:28,230 --> 00:35:41,609
but just like it's it's a REST API so

00:35:39,990 --> 00:35:47,839
you can just submit source code for

00:35:41,609 --> 00:35:50,280
instance the French digital agency has

00:35:47,839 --> 00:35:51,990
like registry or for the open source

00:35:50,280 --> 00:35:55,349
projects that have developed that have

00:35:51,990 --> 00:35:58,650
developed by agencies in France and they

00:35:55,349 --> 00:36:00,450
use our sacred now feature to make sure

00:35:58,650 --> 00:36:03,270
that when they detect a new repository

00:36:00,450 --> 00:36:06,390
its archived in software heritage so

00:36:03,270 --> 00:36:10,320
they push safeguard now requests so that

00:36:06,390 --> 00:36:23,730
we trigger download of all these

00:36:10,320 --> 00:36:25,200
repositories creating archive so it is

00:36:23,730 --> 00:36:28,470
it's more about just collecting

00:36:25,200 --> 00:36:30,260
everything or also do you kind of say no

00:36:28,470 --> 00:36:33,869
that's something that's too small too

00:36:30,260 --> 00:36:36,650
unimportant we don't want it right and

00:36:33,869 --> 00:36:40,920
do you kind of support or have

00:36:36,650 --> 00:36:44,339
additional context data about what you

00:36:40,920 --> 00:36:49,319
collect like the Apollo 11 software how

00:36:44,339 --> 00:36:52,079
it was created in which context right so

00:36:49,319 --> 00:36:55,400
we don't currently do any curation

00:36:52,079 --> 00:36:58,560
ourselves on the archive so basically we

00:36:55,400 --> 00:37:04,410
focus on mass correction of the source

00:36:58,560 --> 00:37:07,530
code with the idea that for instance if

00:37:04,410 --> 00:37:10,980
you consider that a JavaScript module

00:37:07,530 --> 00:37:12,780
that just adds spaces to the left of a

00:37:10,980 --> 00:37:15,780
string is not important and you don't

00:37:12,780 --> 00:37:20,609
have it the date disappears have the

00:37:15,780 --> 00:37:23,099
internet stops working so you can't

00:37:20,609 --> 00:37:25,920
really tell from the get-go whether

00:37:23,099 --> 00:37:27,869
something is relevant or not and at

00:37:25,920 --> 00:37:32,400
least that's a responsibility that we

00:37:27,869 --> 00:37:35,550
don't want to take your second question

00:37:32,400 --> 00:37:39,109
was about additional context around the

00:37:35,550 --> 00:37:41,609
source code so we've started working on

00:37:39,109 --> 00:37:42,030
correcting the metadata that we can get

00:37:41,609 --> 00:37:45,450
bottom

00:37:42,030 --> 00:37:48,210
ethically from hosting repositories so

00:37:45,450 --> 00:37:50,760
for instance we would get the so we

00:37:48,210 --> 00:37:53,810
we're not quite there yet but we won't

00:37:50,760 --> 00:37:56,970
record insolence the keywords and the

00:37:53,810 --> 00:38:01,550
description of the repositories in the

00:37:56,970 --> 00:38:06,270
in the upstream absolute hosting

00:38:01,550 --> 00:38:10,320
platform and allow this data to be

00:38:06,270 --> 00:38:13,830
searched as well as just the link that's

00:38:10,320 --> 00:38:16,530
going to that's been used for archiving

00:38:13,830 --> 00:38:19,500
the software however we don't want to

00:38:16,530 --> 00:38:22,890
replace wiki data for instance so what

00:38:19,500 --> 00:38:25,800
we do is we collaborate with people who

00:38:22,890 --> 00:38:28,560
work on wiki data and we make sure that

00:38:25,800 --> 00:38:31,260
so there's a wiki data property

00:38:28,560 --> 00:38:33,240
I think it's software heritage release

00:38:31,260 --> 00:38:36,990
or something like that so basically you

00:38:33,240 --> 00:38:39,900
can cross you can reference artifacts on

00:38:36,990 --> 00:38:42,780
software attached on wiki data so you

00:38:39,900 --> 00:38:45,900
can add link from wiki data to software

00:38:42,780 --> 00:38:48,240
heritage and we also connect the

00:38:45,900 --> 00:38:52,890
backwards link so we make sure that we

00:38:48,240 --> 00:38:55,850
cross-reference this and so once you've

00:38:52,890 --> 00:38:59,310
connected with wiki data you can add

00:38:55,850 --> 00:39:01,830
more contextual information on Wikipedia

00:38:59,310 --> 00:39:04,020
and then cross-reference with wiki data

00:39:01,830 --> 00:39:06,810
so we don't want to do everything but we

00:39:04,020 --> 00:39:12,750
want to actually cross-reference with

00:39:06,810 --> 00:39:14,850
relevant projects because we are only 14

00:39:12,750 --> 00:39:18,570
people in the team which is already

00:39:14,850 --> 00:39:21,240
quite a quite picked him but it's still

00:39:18,570 --> 00:39:22,590
quite small so we don't want to do

00:39:21,240 --> 00:39:27,290
everything ourselves we'd rather

00:39:22,590 --> 00:39:27,290
collaborate with relevant projects

00:39:32,960 --> 00:39:42,080
which has been the biggest difficulties

00:39:38,760 --> 00:39:45,210
or challenges during these years on the

00:39:42,080 --> 00:39:46,680
heritage project so I think the I think

00:39:45,210 --> 00:39:50,190
the biggest challenge that we have is

00:39:46,680 --> 00:39:51,150
that source code is tiny the files that

00:39:50,190 --> 00:39:53,430
we archive

00:39:51,150 --> 00:39:57,120
I think the median size of a file is

00:39:53,430 --> 00:40:00,060
free kilobytes and so it doesn't even

00:39:57,120 --> 00:40:04,890
feel a disk sector these days which

00:40:00,060 --> 00:40:07,560
means that storing several billions of

00:40:04,890 --> 00:40:13,020
those tiny files is a really big

00:40:07,560 --> 00:40:16,560
challenge we like we come to the limits

00:40:13,020 --> 00:40:20,760
of file system performances or even

00:40:16,560 --> 00:40:22,560
object storage facilities right for

00:40:20,760 --> 00:40:27,000
instance we've done some experimentation

00:40:22,560 --> 00:40:30,710
with self self is optimized for 300 kilo

00:40:27,000 --> 00:40:35,520
byte objects basically if you want

00:40:30,710 --> 00:40:38,160
redundancy and erasure coding you end up

00:40:35,520 --> 00:40:40,890
striping your data across multiple disks

00:40:38,160 --> 00:40:42,990
and so you take the size of one sector

00:40:40,890 --> 00:40:45,500
on one disc and you multiply it by the

00:40:42,990 --> 00:40:49,230
stripe width and so for every fied

00:40:45,500 --> 00:40:53,360
that's two kilobytes you store 320

00:40:49,230 --> 00:40:57,270
kilobytes of blanks in your system so

00:40:53,360 --> 00:41:01,110
you get kind of crappy so you get into a

00:40:57,270 --> 00:41:18,860
crappy edge cases with that and we don't

00:41:01,110 --> 00:41:21,510
really have a very good solution yet so

00:41:18,860 --> 00:41:23,520
for the leaves so for the actual

00:41:21,510 --> 00:41:28,560
contents of the files we use sha-1

00:41:23,520 --> 00:41:31,950
chateau five six and blake 2's 2 5 6 as

00:41:28,560 --> 00:41:38,520
well as the get sorted shavon shavon

00:41:31,950 --> 00:41:40,440
with get object header in front for the

00:41:38,520 --> 00:41:41,640
rest of the objects we use git

00:41:40,440 --> 00:41:44,539
compatible identifiers

00:41:41,640 --> 00:41:48,589
so basically Sherwin's we've had

00:41:44,539 --> 00:41:54,079
by winds of a manifest of the object

00:41:48,589 --> 00:41:58,459
with a header in front so we are not too

00:41:54,079 --> 00:42:00,229
worried about collisions because for the

00:41:58,459 --> 00:42:04,880
contents which are the objects that are

00:42:00,229 --> 00:42:10,249
really easy to manipulate we use several

00:42:04,880 --> 00:42:12,979
hashes we've not actually done anything

00:42:10,249 --> 00:42:17,539
regarding performance of hashing objects

00:42:12,979 --> 00:42:21,589
most of the like most of the stuff that

00:42:17,539 --> 00:42:26,959
we hash is really tiny it's like a few

00:42:21,589 --> 00:42:29,809
few kilobytes of metadata so no I don't

00:42:26,959 --> 00:42:39,380
have any anything that we've done around

00:42:29,809 --> 00:42:44,059
this I've looked into using Swift as

00:42:39,380 --> 00:42:46,880
well because I know it's not there yet

00:42:44,059 --> 00:42:51,109
but they are working on storing small

00:42:46,880 --> 00:42:54,709
size files or objects concatenating them

00:42:51,109 --> 00:42:58,759
into a larger blob so that maybe you and

00:42:54,709 --> 00:43:01,359
I know it goes to do scales you have

00:42:58,759 --> 00:43:05,569
like 300 petabyte is not uncommon

00:43:01,359 --> 00:43:08,479
questions yeah I've actually attended a

00:43:05,569 --> 00:43:11,239
session at first dome that's February

00:43:08,479 --> 00:43:18,019
with the people from OVH who work on

00:43:11,239 --> 00:43:23,029
this object packing feature of Swift

00:43:18,019 --> 00:43:24,889
with not actually tested it yet yeah

00:43:23,029 --> 00:43:27,380
it's I think it's one of the avenues

00:43:24,889 --> 00:43:30,589
that we should actually look into

00:43:27,380 --> 00:43:32,689
because it looked promising when we when

00:43:30,589 --> 00:43:37,029
we looked at it the main issue we had

00:43:32,689 --> 00:43:43,219
with it is that it wasn't upstream yet

00:43:37,029 --> 00:43:45,019
I've not checked since yeah that's still

00:43:43,219 --> 00:43:47,209
something that we need to we need to

00:43:45,019 --> 00:43:50,149
look into thank you

00:43:47,209 --> 00:43:51,649
I guess we're so thank you and Nikolas

00:43:50,149 --> 00:43:55,610
before you talk about software heritage

00:43:51,649 --> 00:43:57,670
and I think that's thank you

00:43:55,610 --> 00:43:57,670
you

00:43:57,790 --> 00:44:02,909

YouTube URL: https://www.youtube.com/watch?v=Fye0_DvFWhY


