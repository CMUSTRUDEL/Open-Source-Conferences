Title: Christian Mollekopf - The Road to a Next Iteration of Akonadi - Akademy 2015
Publication date: 2016-04-02
Playlist: Akademy 2015
Description: 
	The next iteration of Akonadi is underway!

This talk will introduce the reasons for and ideas behind the next iteration of Akonadi that is currently being worked on. We will look at concepts that have been kept, new concepts that have been introduced and the reasons behind it. This will be a technical talk primarily aimed at developers in touch with Akonadi. It should contain interesting information for all developers though and hint at potential user visible improvements as well.

Based on the lessons learned from working with and improving current Akonadi, work has started on the next iteration of Akonadi. With that work we want to create a leaner, easier to evolve system that addresses performance problems, but first and foremost the complexity faced by developers. Of course it should also pave the way for features yet to come. The new design will support more advanced queries to compensate for the loss of Nepomuk, introduce an abstraction layer of the storage from applications, and give Akonadi-Resources much more freedom and control to optimize for their specific usecase. This in turn allows applications and resources to be a lot more efficient without increasing complexity.

To reduce complexity while keeping the architecture flexible, the architecture has been overhauled. The new design parts with the central server process and database, shifting work directly into the client process, only sharing a per-resource no-sql database with each resource.

Inspired by various other projects a reactive approach is used to access the data to further reduce complexity in the client applications, which was introduced by the asynchronous nature of data access.

While the talk will come with some code examples we will be mostly looking at the architectural side of things. 

Speaker: Christian Mollekopf
License: Creative Commons Attribution 4.0 International License http://creativecommons.org/licenses/by/4.0/
Akademy 2015: https://akademy.kde.org/2015
KDE: https://www.kde.org/
Donate: https://www.kde.org/donate
Captions: 
	00:00:08,080 --> 00:00:15,500
so I'm having a little problem with the

00:00:11,800 --> 00:00:19,040
projector unfortunately so my slides or

00:00:15,500 --> 00:00:21,260
crop sorry about that but seem like

00:00:19,040 --> 00:00:24,890
there's nothing I can do about it now so

00:00:21,260 --> 00:00:28,669
I'm going to present and the effort for

00:00:24,890 --> 00:00:35,300
ecology next the next iteration of the

00:00:28,669 --> 00:00:37,880
KD p.m. search infrastructure so first

00:00:35,300 --> 00:00:41,629
what's our kannadi the premise of alton

00:00:37,880 --> 00:00:46,219
rd basically is him data as a service so

00:00:41,629 --> 00:00:49,190
if he couples the UI from the data it

00:00:46,219 --> 00:00:51,620
provides offline capability and it

00:00:49,190 --> 00:00:54,070
provides a standardized interface for

00:00:51,620 --> 00:00:56,629
applications so for instance multiple

00:00:54,070 --> 00:00:59,300
calendaring applications can reuse the

00:00:56,629 --> 00:01:01,129
same data and they can share the whole

00:00:59,300 --> 00:01:07,750
synchronization that is headed by a

00:01:01,129 --> 00:01:07,750
finale so to the first cropped picture

00:01:08,020 --> 00:01:17,870
here we see the monolithic application

00:01:12,620 --> 00:01:20,180
that we used to have in there you be

00:01:17,870 --> 00:01:22,400
implemented all the data access of the

00:01:20,180 --> 00:01:25,760
other protocols all different protocols

00:01:22,400 --> 00:01:28,700
nothing was shared so that was

00:01:25,760 --> 00:01:30,680
redesigned to our current model that we

00:01:28,700 --> 00:01:33,770
have in our kannadi which is with a

00:01:30,680 --> 00:01:38,150
central server and the resource backends

00:01:33,770 --> 00:01:40,700
down here so multiple applications can

00:01:38,150 --> 00:01:45,140
share these resource backends they share

00:01:40,700 --> 00:01:50,240
the same data yeah that's what we're

00:01:45,140 --> 00:01:52,600
currently working with this design

00:01:50,240 --> 00:01:57,410
however brought a couple of challenges

00:01:52,600 --> 00:02:01,810
so what we see is high complexity in the

00:01:57,410 --> 00:02:05,530
applications using our kannadi we have

00:02:01,810 --> 00:02:08,679
you to the data agnostic see that

00:02:05,530 --> 00:02:11,180
kannadi has we have performance problems

00:02:08,679 --> 00:02:12,060
because we have to load much more data

00:02:11,180 --> 00:02:16,370
into

00:02:12,060 --> 00:02:19,110
applications than we should have two and

00:02:16,370 --> 00:02:21,300
writing natural resources so the

00:02:19,110 --> 00:02:25,470
backends that access the servers has

00:02:21,300 --> 00:02:28,110
become really really difficult so seeing

00:02:25,470 --> 00:02:31,190
all this we started to look into new

00:02:28,110 --> 00:02:40,880
designs how we can improve upon that

00:02:31,190 --> 00:02:44,940
situation oh sorry I mrs. like so yeah

00:02:40,880 --> 00:02:47,549
we see you to these problems slow

00:02:44,940 --> 00:02:50,430
startup times in applications because it

00:02:47,549 --> 00:02:52,590
has a lot of initial processing we see

00:02:50,430 --> 00:02:54,930
high memory usage because we have for

00:02:52,590 --> 00:02:58,709
instance if you look at an email folder

00:02:54,930 --> 00:03:00,660
that has 200,000 messages inside we need

00:02:58,709 --> 00:03:03,030
to load them all to be able to do the

00:03:00,660 --> 00:03:06,480
threading and the sorting and that just

00:03:03,030 --> 00:03:08,720
takes time and it takes memory due to

00:03:06,480 --> 00:03:12,510
that we also see highly optimized code

00:03:08,720 --> 00:03:14,340
in places that where it shouldn't really

00:03:12,510 --> 00:03:15,989
be necessary we have two highly

00:03:14,340 --> 00:03:18,090
optimized because we have to load so

00:03:15,989 --> 00:03:22,170
much data and because we have to quickly

00:03:18,090 --> 00:03:24,660
process so much data as a result of that

00:03:22,170 --> 00:03:28,140
we have high maintenance costs because

00:03:24,660 --> 00:03:31,079
it'll get very complex and it's become

00:03:28,140 --> 00:03:37,350
very very hard to add new features and

00:03:31,079 --> 00:03:41,010
extended what we have so with economy

00:03:37,350 --> 00:03:43,260
next we have a server less design we

00:03:41,010 --> 00:03:45,989
have applications that share the

00:03:43,260 --> 00:03:48,930
resource separate resource process is

00:03:45,989 --> 00:03:56,030
still with each application has direct

00:03:48,930 --> 00:03:59,720
and process access to the data and each

00:03:56,030 --> 00:04:03,560
each client application connects all

00:03:59,720 --> 00:04:06,600
individual resources that are available

00:04:03,560 --> 00:04:11,519
so let's look at some of the challenges

00:04:06,600 --> 00:04:13,730
that we have incurred a cloudy and how r

00:04:11,519 --> 00:04:17,120
kannadi next tricycle

00:04:13,730 --> 00:04:22,610
and so I set the performance problems we

00:04:17,120 --> 00:04:24,500
have in our kannadi are mostly that we

00:04:22,610 --> 00:04:27,710
have to do more work than we should have

00:04:24,500 --> 00:04:30,800
to it's not that the loading of the data

00:04:27,710 --> 00:04:32,479
is slow it's very efficient but if you

00:04:30,800 --> 00:04:40,550
have to know so much data that just

00:04:32,479 --> 00:04:43,820
makes time so this is the basic design

00:04:40,550 --> 00:04:46,400
of a all units so you have a

00:04:43,820 --> 00:04:51,130
client process is that's the client

00:04:46,400 --> 00:04:51,130
process these are the resource processes

00:04:51,370 --> 00:04:56,750
what we have the client application that

00:04:54,889 --> 00:04:59,180
works against the facade which obstructs

00:04:56,750 --> 00:05:01,490
the whole storage so two clients it

00:04:59,180 --> 00:05:05,570
still looks like it works against the

00:05:01,490 --> 00:05:07,130
unified sort the facade itself loads

00:05:05,570 --> 00:05:10,910
various plugins for the different

00:05:07,130 --> 00:05:12,949
resources it works with the database

00:05:10,910 --> 00:05:15,050
that we have is shared between the

00:05:12,949 --> 00:05:19,460
resource process and the client process

00:05:15,050 --> 00:05:22,490
which allows the client to load the data

00:05:19,460 --> 00:05:26,900
directly from disk it doesn't have to

00:05:22,490 --> 00:05:28,490
access the resource first the part that

00:05:26,900 --> 00:05:31,010
we unfortunately don't see is the

00:05:28,490 --> 00:05:35,660
synchronizer here that is the single

00:05:31,010 --> 00:05:37,849
writer to the database and the client

00:05:35,660 --> 00:05:40,039
then simply writes to the resource if it

00:05:37,849 --> 00:05:44,450
wants to modify something but more on

00:05:40,039 --> 00:05:46,039
that later for storage we are

00:05:44,450 --> 00:05:48,590
recurrently using a key value store

00:05:46,039 --> 00:05:50,330
instead of sequel because we're not

00:05:48,590 --> 00:05:53,270
doing a whole lot of sequel we're

00:05:50,330 --> 00:05:57,620
basically storing objects in the

00:05:53,270 --> 00:05:59,750
database and the key value stores are

00:05:57,620 --> 00:06:04,490
very using which is Alan TV has some

00:05:59,750 --> 00:06:07,669
nice performance properties so just to

00:06:04,490 --> 00:06:12,710
give you a rough idea on on my laptop i

00:06:07,669 --> 00:06:16,760
can write about 150,000 2 k values per

00:06:12,710 --> 00:06:20,120
second and read at about 400,000 which

00:06:16,760 --> 00:06:20,790
are individual kilo cops so even if we

00:06:20,120 --> 00:06:24,900
had

00:06:20,790 --> 00:06:28,020
still had to load all the emails in a

00:06:24,900 --> 00:06:32,670
folder that would be done in half a

00:06:28,020 --> 00:06:35,370
second or so Alan DB also provides

00:06:32,670 --> 00:06:40,260
transactions and it supports multi

00:06:35,370 --> 00:06:44,640
process usage which is precisely what we

00:06:40,260 --> 00:06:47,040
need for such a project and as the other

00:06:44,640 --> 00:06:49,350
significant change we have now one

00:06:47,040 --> 00:06:56,070
database for resource instead of one

00:06:49,350 --> 00:06:59,910
unified database to store the data we

00:06:56,070 --> 00:07:03,300
have the key value store each value is

00:06:59,910 --> 00:07:05,910
split into three parts we have a

00:07:03,300 --> 00:07:09,990
metadata part where we store stuff like

00:07:05,910 --> 00:07:12,600
probation IV access times stuff like

00:07:09,990 --> 00:07:15,690
that and then we have a local and a

00:07:12,600 --> 00:07:17,790
remote part the idea of that is that we

00:07:15,690 --> 00:07:20,190
can provide it default implementation

00:07:17,790 --> 00:07:22,410
for the local part so in here for

00:07:20,190 --> 00:07:25,500
instance if you store any event in in

00:07:22,410 --> 00:07:28,830
there we have the start date the end a

00:07:25,500 --> 00:07:31,950
summary all the standard properties that

00:07:28,830 --> 00:07:33,980
you have that are shared and are most

00:07:31,950 --> 00:07:38,040
likely share across different resources

00:07:33,980 --> 00:07:41,670
implementing events the remote part is

00:07:38,040 --> 00:07:43,800
where resources can customize so for

00:07:41,670 --> 00:07:46,230
instance the column resource stores

00:07:43,800 --> 00:07:48,420
events in Anna so we have I love

00:07:46,230 --> 00:07:51,030
specific synchronization properties that

00:07:48,420 --> 00:07:54,180
we need to store somewhere so that's uid

00:07:51,030 --> 00:07:56,520
next and various other values that we

00:07:54,180 --> 00:08:00,480
need to be able to efficiently

00:07:56,520 --> 00:08:03,960
synchronize the resource can freely

00:08:00,480 --> 00:08:06,440
define that part and add its own

00:08:03,960 --> 00:08:09,090
properties there it can also specialize

00:08:06,440 --> 00:08:11,790
the values that are already available

00:08:09,090 --> 00:08:15,120
here if it would need to somehow be able

00:08:11,790 --> 00:08:16,270
to store it more efficiently but by

00:08:15,120 --> 00:08:22,570
default you know

00:08:16,270 --> 00:08:26,050
do any of that so with that we have a

00:08:22,570 --> 00:08:29,770
fast storage but what's really the aim

00:08:26,050 --> 00:08:32,050
is to only load the data that we really

00:08:29,770 --> 00:08:35,430
have to so to reduce the work that we

00:08:32,050 --> 00:08:38,950
have to do and for that we need indexes

00:08:35,430 --> 00:08:40,990
so what we want to be able to do is to

00:08:38,950 --> 00:08:43,480
for instance if you load the calendar

00:08:40,990 --> 00:08:44,920
look at the specific week we want to be

00:08:43,480 --> 00:08:46,750
able to only load the events that

00:08:44,920 --> 00:08:49,570
actually affect this week because

00:08:46,750 --> 00:08:52,240
currently we have to to load all the

00:08:49,570 --> 00:08:55,630
lenders into memory to figure out what

00:08:52,240 --> 00:08:57,610
we actually want to display so we want

00:08:55,630 --> 00:09:01,180
to index that for that we need various

00:08:57,610 --> 00:09:04,030
indexes like full text indexes for

00:09:01,180 --> 00:09:07,630
searching we need date range indexes for

00:09:04,030 --> 00:09:10,330
events for emails we need threading

00:09:07,630 --> 00:09:12,790
indexes to be able to do the sorting so

00:09:10,330 --> 00:09:15,640
you can only load the top 200 emails

00:09:12,790 --> 00:09:21,730
instead of 200,000 that you're never

00:09:15,640 --> 00:09:24,340
going to look at so if we achieve all

00:09:21,730 --> 00:09:26,110
that what we get is really fast sort of

00:09:24,340 --> 00:09:28,540
times because you basically don't have

00:09:26,110 --> 00:09:32,230
to do any work you're just rendering the

00:09:28,540 --> 00:09:33,910
state from the database and we have no

00:09:32,230 --> 00:09:39,160
memory usage because you don't have to

00:09:33,910 --> 00:09:41,530
load anything into memory and we don't

00:09:39,160 --> 00:09:44,320
do repetitive expensive processing so

00:09:41,530 --> 00:09:46,390
right now if you click on a folder we

00:09:44,320 --> 00:09:48,310
load all the data do the threading for

00:09:46,390 --> 00:09:50,830
all the emails and we do that every time

00:09:48,310 --> 00:09:54,490
you click on the folder which is

00:09:50,830 --> 00:09:56,740
naturally expensive and if we do that in

00:09:54,490 --> 00:10:00,250
indexes we have the opportunity to

00:09:56,740 --> 00:10:03,880
persist that processing and then

00:10:00,250 --> 00:10:12,550
incrementally updated as new items come

00:10:03,880 --> 00:10:14,830
in so the the next problem that we have

00:10:12,550 --> 00:10:18,550
is perhaps in the larger one is

00:10:14,830 --> 00:10:21,250
complexity applications built on top of

00:10:18,550 --> 00:10:22,000
our kannadi sometimes feel a bit like a

00:10:21,250 --> 00:10:24,670
revolt

00:10:22,000 --> 00:10:26,950
machine where you touch one thing and

00:10:24,670 --> 00:10:28,960
then something happens there and

00:10:26,950 --> 00:10:33,250
something happens in the next place it's

00:10:28,960 --> 00:10:36,970
very hard to debug it and to know what's

00:10:33,250 --> 00:10:41,890
actually going on with our kannagi Nets

00:10:36,970 --> 00:10:47,440
trying to attack the problem by using a

00:10:41,890 --> 00:10:49,450
more reactive approach so a large part

00:10:47,440 --> 00:10:52,090
of the problem I think is that we are

00:10:49,450 --> 00:10:55,390
working with multiple mutable states

00:10:52,090 --> 00:10:57,610
that interact with each other and if you

00:10:55,390 --> 00:11:00,340
have multiple such safes you need to

00:10:57,610 --> 00:11:03,370
test basically or you need to consider

00:11:00,340 --> 00:11:05,560
each combination of all these states to

00:11:03,370 --> 00:11:08,650
be able to reason about what the program

00:11:05,560 --> 00:11:11,350
is going to do so in the reactive

00:11:08,650 --> 00:11:14,860
approach you try to confine this mutable

00:11:11,350 --> 00:11:18,520
state as much as possible which would in

00:11:14,860 --> 00:11:22,810
our case we the database in our finale

00:11:18,520 --> 00:11:26,710
so the presentation simply renders that

00:11:22,810 --> 00:11:29,260
state and it sends commands to modify

00:11:26,710 --> 00:11:31,510
that state and once the modification it

00:11:29,260 --> 00:11:34,540
done is done it reacts again to it

00:11:31,510 --> 00:11:41,920
that's a lot easier to test it and it's

00:11:34,540 --> 00:11:46,210
a lot easier to reason about so in the

00:11:41,920 --> 00:11:50,530
resource overview we see this reactive

00:11:46,210 --> 00:11:54,970
loops so here that's the resource

00:11:50,530 --> 00:11:58,000
process I'm so clients sign commands to

00:11:54,970 --> 00:12:00,810
the resource they end up in a few the

00:11:58,000 --> 00:12:04,870
pipeline to which I'll get shortly

00:12:00,810 --> 00:12:10,990
simply processes this q1 message at a

00:12:04,870 --> 00:12:13,810
time and once the processing is done the

00:12:10,990 --> 00:12:16,930
result ends up in the database so it

00:12:13,810 --> 00:12:20,530
modifies the state and then notifies the

00:12:16,930 --> 00:12:24,820
client or respectively the clients about

00:12:20,530 --> 00:12:28,140
the change on the other side we have

00:12:24,820 --> 00:12:30,270
basically the same you for

00:12:28,140 --> 00:12:33,000
for the synchronizer so the

00:12:30,270 --> 00:12:35,940
synchronizers and synchronizer figures

00:12:33,000 --> 00:12:38,100
out the changes that that it has against

00:12:35,940 --> 00:12:41,160
the source sources for instance the imap

00:12:38,100 --> 00:12:44,760
server and it then generates a change

00:12:41,160 --> 00:12:47,550
set that it also sends into the queue

00:12:44,760 --> 00:12:50,430
and again the pipeline simply processes

00:12:47,550 --> 00:12:54,300
those cues picks up the commands and

00:12:50,430 --> 00:12:57,900
once it's done it publishes that stated

00:12:54,300 --> 00:13:00,990
system and also of course it sends to

00:12:57,900 --> 00:13:07,080
change that to the right back to the

00:13:00,990 --> 00:13:09,050
server so everything is in in sync but

00:13:07,080 --> 00:13:16,920
that way you have a basically this

00:13:09,050 --> 00:13:20,160
single flow of information so the

00:13:16,920 --> 00:13:22,650
pipeline is a series of steps that are

00:13:20,160 --> 00:13:25,500
guaranteed to be executed where it can

00:13:22,650 --> 00:13:27,900
do various things the most basic thing

00:13:25,500 --> 00:13:32,880
that we want to do in here is updating a

00:13:27,900 --> 00:13:35,580
nexus by doing this India in there we

00:13:32,880 --> 00:13:38,340
can guarantee that as soon as an entity

00:13:35,580 --> 00:13:41,850
enters the system the relevant indexes

00:13:38,340 --> 00:13:44,370
are already up to date and what we can

00:13:41,850 --> 00:13:46,230
also do stuff like mail filtering in

00:13:44,370 --> 00:13:50,190
there so we can refer instance filter

00:13:46,230 --> 00:13:51,930
males to other places before they enter

00:13:50,190 --> 00:13:53,580
the system so they don't pop up in your

00:13:51,930 --> 00:13:57,350
inbox and then vanish somewhere else

00:13:53,580 --> 00:14:01,740
they will be moved into the right place

00:13:57,350 --> 00:14:03,690
immediately we can do also various other

00:14:01,740 --> 00:14:05,490
things like spam virus infection in

00:14:03,690 --> 00:14:07,410
there we will have to

00:14:05,490 --> 00:14:10,110
conflict resolution in there because

00:14:07,410 --> 00:14:12,360
that's the place where we can where we

00:14:10,110 --> 00:14:18,529
notice if a change actually still

00:14:12,360 --> 00:14:18,529
applies to the current database state

00:14:18,830 --> 00:14:28,620
yeah the last problem that we have is

00:14:25,950 --> 00:14:32,820
the impedance mismatch that we have

00:14:28,620 --> 00:14:35,130
between the source on one side so for

00:14:32,820 --> 00:14:37,830
instance dime observer or your group

00:14:35,130 --> 00:14:40,770
where server the domain model that

00:14:37,830 --> 00:14:44,190
Arkady has which consists of collections

00:14:40,770 --> 00:14:49,260
and items and then the main model of the

00:14:44,190 --> 00:14:52,670
application so if we look at the current

00:14:49,260 --> 00:14:55,709
and the main model slightly simplified

00:14:52,670 --> 00:14:59,130
you basically have collections and

00:14:55,709 --> 00:15:01,680
collections can have entities which are

00:14:59,130 --> 00:15:05,940
collections or items you have to simple

00:15:01,680 --> 00:15:09,870
folder hierarchy additionally we have

00:15:05,940 --> 00:15:15,029
flags and attributes to store stuff

00:15:09,870 --> 00:15:19,490
basically and the pain of you we can

00:15:15,029 --> 00:15:22,950
more or less ignore for for this but

00:15:19,490 --> 00:15:27,959
this is used for a storage model and

00:15:22,950 --> 00:15:30,480
it's used for data access so whatever

00:15:27,959 --> 00:15:33,480
the resource gets from the server it has

00:15:30,480 --> 00:15:36,089
to fit it into this model and if this is

00:15:33,480 --> 00:15:39,600
not a one-to-one mapping which we face

00:15:36,089 --> 00:15:41,250
for instance with tax then the

00:15:39,600 --> 00:15:46,860
synchronization code becomes very very

00:15:41,250 --> 00:15:49,140
complex at the same problem you of

00:15:46,860 --> 00:15:51,750
course also have on the application side

00:15:49,140 --> 00:15:56,430
if the application domain doesn't nap

00:15:51,750 --> 00:16:03,080
one on this model then you run into

00:15:56,430 --> 00:16:05,520
problems so with our kannadi next the

00:16:03,080 --> 00:16:12,420
domain model is supposed to be both

00:16:05,520 --> 00:16:14,280
simpler and more expressive so the main

00:16:12,420 --> 00:16:16,200
part of the model is is you have

00:16:14,280 --> 00:16:19,980
entities and entities have properties

00:16:16,200 --> 00:16:22,050
that's it that's what what is used for

00:16:19,980 --> 00:16:27,330
storage and that's what we cannot really

00:16:22,050 --> 00:16:29,100
change that's by design but that system

00:16:27,330 --> 00:16:34,920
should be flexible enough that I think

00:16:29,100 --> 00:16:39,500
we can map everything internet so but on

00:16:34,920 --> 00:16:42,120
the client API side we need to be more

00:16:39,500 --> 00:16:44,490
expressive we need to allow applications

00:16:42,120 --> 00:16:47,670
that they can query for blenders they

00:16:44,490 --> 00:16:50,040
shouldn't worry for collections and then

00:16:47,670 --> 00:16:51,900
everywhere in the application assume oh

00:16:50,040 --> 00:16:55,100
well that's a collection of this mime

00:16:51,900 --> 00:16:57,480
type therefore it's a glendor so

00:16:55,100 --> 00:17:01,350
currently we're always making implicit

00:16:57,480 --> 00:17:04,939
assumptions about how how for instance a

00:17:01,350 --> 00:17:09,660
calendar is represented in the database

00:17:04,939 --> 00:17:12,449
without gonna be next want to have in a

00:17:09,660 --> 00:17:14,130
cleaner way to define that so different

00:17:12,449 --> 00:17:16,920
since define well we have collections

00:17:14,130 --> 00:17:19,380
and we have various types of collections

00:17:16,920 --> 00:17:21,120
for instance we have calendars and for

00:17:19,380 --> 00:17:24,720
instance a calendar may have additional

00:17:21,120 --> 00:17:27,660
properties like perhaps a perhaps a

00:17:24,720 --> 00:17:31,680
calendar has a collar while a mailbox

00:17:27,660 --> 00:17:36,600
does not or perhaps a calendar has an

00:17:31,680 --> 00:17:39,380
older so that's something that we need

00:17:36,600 --> 00:17:43,020
to define because that that defines

00:17:39,380 --> 00:17:46,350
standardized access to the data that's

00:17:43,020 --> 00:17:50,440
what makes enables various applications

00:17:46,350 --> 00:17:54,159
to use the same data so

00:17:50,440 --> 00:17:57,279
Smart is meant to be evolved over time

00:17:54,159 --> 00:18:01,419
so if we see well we have now a new time

00:17:57,279 --> 00:18:02,769
that we want to deal with so at the

00:18:01,419 --> 00:18:05,320
beginning for instance we have events

00:18:02,769 --> 00:18:08,259
and then we add to deuce at some point

00:18:05,320 --> 00:18:12,879
and the properties we can simply extend

00:18:08,259 --> 00:18:16,539
to what we require because they are not

00:18:12,879 --> 00:18:18,580
implemented in a type-safe way that's

00:18:16,539 --> 00:18:20,259
more by specifications and we for

00:18:18,580 --> 00:18:22,960
instance a anyone has a property called

00:18:20,259 --> 00:18:25,509
start date and started is a cue daytime

00:18:22,960 --> 00:18:33,909
and the interface itself is a queue

00:18:25,509 --> 00:18:36,820
variant based so the client API has a

00:18:33,909 --> 00:18:40,960
minimal set of the necessary operations

00:18:36,820 --> 00:18:45,750
which is you can query for data you can

00:18:40,960 --> 00:18:51,789
create modify or remove entities and

00:18:45,750 --> 00:18:56,529
that's it so for calls basically the

00:18:51,789 --> 00:18:59,620
queries are reactive so you specify what

00:18:56,529 --> 00:19:02,379
you want to what data you're interested

00:18:59,620 --> 00:19:08,799
in use for instance say well give me all

00:19:02,379 --> 00:19:15,159
events from calendar X and the query

00:19:08,799 --> 00:19:17,470
then populates itself that maps and very

00:19:15,159 --> 00:19:21,309
very well for instance on two models

00:19:17,470 --> 00:19:22,779
because you simply define a query we set

00:19:21,309 --> 00:19:32,909
it onto the model and the model will

00:19:22,779 --> 00:19:36,580
simply populate itself and YouTube how

00:19:32,909 --> 00:19:40,059
do to us having now different resources

00:19:36,580 --> 00:19:41,210
the client API or this library is also

00:19:40,059 --> 00:19:43,460
responsible for

00:19:41,210 --> 00:19:46,039
in the data between the different

00:19:43,460 --> 00:19:57,049
resources since we no longer have a

00:19:46,039 --> 00:20:00,799
unified storage so um for the review we

00:19:57,049 --> 00:20:03,919
have the client that works against this

00:20:00,799 --> 00:20:06,679
facade which gives the illusion of

00:20:03,919 --> 00:20:09,020
having a unified storage the facade

00:20:06,679 --> 00:20:14,899
itself figures out to which plugins it

00:20:09,020 --> 00:20:18,350
has to talk the plugins themselves know

00:20:14,899 --> 00:20:21,110
how to access the database and they know

00:20:18,350 --> 00:20:24,409
how to contact the resource so if we

00:20:21,110 --> 00:20:26,870
have a modify current this command it's

00:20:24,409 --> 00:20:29,390
centered resource the resource will

00:20:26,870 --> 00:20:33,080
process it and modified state in the

00:20:29,390 --> 00:20:35,990
database once the processing is done it

00:20:33,080 --> 00:20:37,789
will notify all clients that something

00:20:35,990 --> 00:20:41,539
has changed in Eurovision is available

00:20:37,789 --> 00:20:44,470
and the client can then read the actual

00:20:41,539 --> 00:20:48,470
data directly from the database in

00:20:44,470 --> 00:20:55,460
process which is very cheap at that

00:20:48,470 --> 00:20:59,029
point and so because of this design

00:20:55,460 --> 00:21:02,270
we're also very flexible to customize

00:20:59,029 --> 00:21:05,870
for resource so should we see a need to

00:21:02,270 --> 00:21:08,419
for instance replace database for

00:21:05,870 --> 00:21:11,059
whatever reason because resources do

00:21:08,419 --> 00:21:12,980
have very different requirements some

00:21:11,059 --> 00:21:15,710
resources steel with high volume data

00:21:12,980 --> 00:21:20,720
some resources deal with a bunch of

00:21:15,710 --> 00:21:24,110
events so because that is completely

00:21:20,720 --> 00:21:26,870
encapsulated by the resource you could

00:21:24,110 --> 00:21:29,240
even replace the storage which is

00:21:26,870 --> 00:21:32,179
definitely not what we want to do by

00:21:29,240 --> 00:21:33,140
default oh so the idea is to provide

00:21:32,179 --> 00:21:35,960
defaulting

00:21:33,140 --> 00:21:39,230
patience for everything that writing a

00:21:35,960 --> 00:21:41,330
simple resource takes a couple of lines

00:21:39,230 --> 00:21:43,070
of code and then the code that you

00:21:41,330 --> 00:21:45,080
actually need to contact the server

00:21:43,070 --> 00:21:49,010
because that obviously we can't do for

00:21:45,080 --> 00:21:54,260
the research but if you have to you can

00:21:49,010 --> 00:22:04,540
customize most aspects of how the

00:21:54,260 --> 00:22:04,540
resource itself works so i have a quick

00:22:20,519 --> 00:22:24,709
well of course I can't see anything

00:22:43,640 --> 00:22:46,210
let's try

00:22:50,070 --> 00:22:58,910
so what do you see here is just a simple

00:22:53,880 --> 00:23:01,770
model and that is populated by a query I

00:22:58,910 --> 00:23:04,200
implemented a dummy resource that works

00:23:01,770 --> 00:23:06,870
against an in-memory back-end doesn't

00:23:04,200 --> 00:23:09,030
really do anything useful and if I click

00:23:06,870 --> 00:23:11,160
synchronize it sends a synchronized

00:23:09,030 --> 00:23:14,490
command to the resource it then

00:23:11,160 --> 00:23:18,810
populates the database with a hundred

00:23:14,490 --> 00:23:22,620
events or 100 entities and stay shoot

00:23:18,810 --> 00:23:25,380
and then we get a hundred notifications

00:23:22,620 --> 00:23:30,860
from from the resource that stuff was

00:23:25,380 --> 00:23:30,860
added and the model will update itself

00:23:31,730 --> 00:23:56,010
now that's basically already it so yeah

00:23:50,820 --> 00:23:59,520
it's a fresh and modern home base it

00:23:56,010 --> 00:24:02,910
uses some new techniques to write a

00:23:59,520 --> 00:24:06,110
synchronous C++ code that then is

00:24:02,910 --> 00:24:09,860
developing grocery store tomorrow and

00:24:06,110 --> 00:24:13,680
we're we have a project on fabricator to

00:24:09,860 --> 00:24:16,380
coordinate the development and you can

00:24:13,680 --> 00:24:19,170
of course always contact me by email or

00:24:16,380 --> 00:24:28,580
IRC or whatever and if you'd like to

00:24:19,170 --> 00:24:28,580
join in to develop them questions

00:25:05,150 --> 00:25:17,010
how will this have work with the custom

00:25:12,740 --> 00:25:19,110
business what we are using the can store

00:25:17,010 --> 00:25:21,930
the actual values each value has a

00:25:19,110 --> 00:25:26,760
structure we're using an flatbuffers for

00:25:21,930 --> 00:25:29,310
that which is a system where you can

00:25:26,760 --> 00:25:31,920
basically write a little schema and then

00:25:29,310 --> 00:25:35,400
you generate an excess surfer for that

00:25:31,920 --> 00:25:37,290
value and it's very neat with together

00:25:35,400 --> 00:25:39,630
with Alan B because i'll only be does

00:25:37,290 --> 00:25:41,880
memory mapping of the values and you can

00:25:39,630 --> 00:25:43,760
then basically initialize the structure

00:25:41,880 --> 00:25:47,670
the pointer and then access values

00:25:43,760 --> 00:25:50,670
inside that area but the other thing

00:25:47,670 --> 00:25:53,340
that Alan DB does is it supports

00:25:50,670 --> 00:25:56,640
versioning of these values so you can

00:25:53,340 --> 00:25:59,850
add you can never remove a value but a

00:25:56,640 --> 00:26:02,250
value that is empty that you're not

00:25:59,850 --> 00:26:07,410
using is free it doesn't store anything

00:26:02,250 --> 00:26:11,070
there and if you and if you add new

00:26:07,410 --> 00:26:14,160
values you can still go read the old

00:26:11,070 --> 00:26:16,520
versions so that way we can remove the

00:26:14,160 --> 00:26:16,520
storage

00:26:24,370 --> 00:26:33,790
what kind of issues and the chemistry

00:26:28,370 --> 00:26:36,710
support you would like to switch there's

00:26:33,790 --> 00:26:40,520
so there's currently no real schedule

00:26:36,710 --> 00:26:42,680
for when we want to switch because it's

00:26:40,520 --> 00:26:45,110
in either case going to be quite a large

00:26:42,680 --> 00:26:50,750
undertaking and we have to figure out

00:26:45,110 --> 00:26:53,840
how to swap that exactly and for

00:26:50,750 --> 00:26:56,300
migration we just I mean we cannot

00:26:53,840 --> 00:26:57,680
migrate the data because the data is sit

00:26:56,300 --> 00:27:00,890
in the back ends I don't think that

00:26:57,680 --> 00:27:03,470
makes sense to invest into that so what

00:27:00,890 --> 00:27:06,620
we're interested basically to do is to

00:27:03,470 --> 00:27:10,760
migrate the configuration so to set up

00:27:06,620 --> 00:27:12,740
your resources perhaps again yeah but

00:27:10,760 --> 00:27:16,160
these would just be separate tools i

00:27:12,740 --> 00:27:24,750
guess that's do the migration I'd like

00:27:16,160 --> 00:27:41,970
to avoid yeah that's question

00:27:24,750 --> 00:27:45,850
how much is so important let's go these

00:27:41,970 --> 00:27:49,930
it depends on a lot on the approach we

00:27:45,850 --> 00:27:53,740
take I think we obviously cannot rewrite

00:27:49,930 --> 00:27:56,740
all applications from scratch for the

00:27:53,740 --> 00:27:59,920
resources i think it's it makes sense to

00:27:56,740 --> 00:28:02,440
more or less rewrite them because it

00:27:59,920 --> 00:28:06,760
would just it you wouldn't really gain

00:28:02,440 --> 00:28:10,240
much by trying to maintain backwards

00:28:06,760 --> 00:28:12,810
compatibility that for the client

00:28:10,240 --> 00:28:16,780
applications current plan is to

00:28:12,810 --> 00:28:20,170
re-implement the current api on top of

00:28:16,780 --> 00:28:23,200
Akhenaten next so that the switch is

00:28:20,170 --> 00:28:25,300
transparent to the applications in the

00:28:23,200 --> 00:28:27,250
long run I think the applications can

00:28:25,300 --> 00:28:32,050
lose a lot of codes that we currently

00:28:27,250 --> 00:28:35,350
have by prop reporting it properly and

00:28:32,050 --> 00:28:37,990
removing that API because a lot of

00:28:35,350 --> 00:28:40,600
complexity that we have in the

00:28:37,990 --> 00:28:43,570
applications I believe comes out of game

00:28:40,600 --> 00:28:47,590
tied at reusing currently to access the

00:28:43,570 --> 00:28:51,100
data so thank you maybe stilling is

00:28:47,590 --> 00:28:53,230
between 27 are you both from PDP so

00:28:51,100 --> 00:28:56,040
there's one on Tuesday and if you have

00:28:53,230 --> 00:28:56,040
question just

00:29:01,750 --> 00:29:03,810
you

00:29:12,880 --> 00:29:14,940

YouTube URL: https://www.youtube.com/watch?v=dXK8Zz1QxgI


