Title: What Does AI Know About Me? Mozilla Explains: Your Digital Profile
Publication date: 2021-07-20
Playlist: Mozilla Explains
Description: 
	Artificial intelligence knows way more about you than you may realize. In this episode of Mozilla Explains, Panoptykon Foundationâ€™s Katarzyna Szymielewicz explains the three layers of your digital profile.

Enjoying our Mozilla Explains series? Sign up to our newsletter to learn more about the fight for a healthy interent, and how you can get involved: https://foundation.mozilla.org/newsletter/
Captions: 
	00:00:00,571 --> 00:00:03,154
(upbeat music)

00:00:06,963 --> 00:00:08,600
- I am Katarzyna Szymielewicz.

00:00:08,600 --> 00:00:11,240
I work at Panoptykon Foundation where we investigate

00:00:11,240 --> 00:00:14,440
how data can be used to influence people

00:00:14,440 --> 00:00:17,265
and how we, the people, can fight back.

00:00:17,265 --> 00:00:20,540
I'm here to explain what sort of knowledge about you

00:00:20,540 --> 00:00:24,000
can be generated by machine learning algorithms.

00:00:24,000 --> 00:00:27,410
We are talking about the type of artificial intelligence

00:00:27,410 --> 00:00:30,636
that is designed and controlled by technological companies

00:00:30,636 --> 00:00:33,264
in order to influence human behavior.

00:00:33,264 --> 00:00:35,897
These algorithms make decisions about you,

00:00:35,897 --> 00:00:38,076
and they do it every day.

00:00:38,076 --> 00:00:40,600
Often, without us even knowing.

00:00:40,600 --> 00:00:42,617
It usually happens behind the screen,

00:00:42,617 --> 00:00:47,500
without bothering us, in a very smooth and efficient manner.

00:00:47,500 --> 00:00:50,017
Algorithmic decisions, can seem very trivial,

00:00:50,017 --> 00:00:52,430
but in the age of surveillance capitalism

00:00:52,430 --> 00:00:54,497
they tend to gain gravity.

00:00:54,497 --> 00:00:56,510
Think of traffic lights

00:00:56,510 --> 00:00:58,680
that change when you approach the street,

00:00:58,680 --> 00:01:00,577
or about a personal newsfeed

00:01:00,577 --> 00:01:02,857
that is shown in your social media,

00:01:02,857 --> 00:01:06,540
or equally personalized prices for flights

00:01:06,540 --> 00:01:09,314
that you will be shown the next time you search for one.

00:01:09,314 --> 00:01:13,510
It is also algorithms that assist real people in deciding

00:01:13,510 --> 00:01:15,690
whether you qualify for a mortgage,

00:01:15,690 --> 00:01:18,740
whether you can enroll at a particular university,

00:01:18,740 --> 00:01:21,910
or whether you qualify for insurance.

00:01:21,910 --> 00:01:24,425
But how do they get all that information

00:01:24,425 --> 00:01:26,720
to inform their decisions?

00:01:26,720 --> 00:01:29,730
Well, it's all based on data, your data.

00:01:29,730 --> 00:01:32,603
To be more precise, on your digital profile.

00:01:33,500 --> 00:01:35,510
Everyone has a digital profile

00:01:35,510 --> 00:01:39,460
and it usually has three layers.

00:01:39,460 --> 00:01:42,660
The first layer is the one we control ourselves.

00:01:42,660 --> 00:01:46,210
It is information that we give when we use computers,

00:01:46,210 --> 00:01:48,721
phones, and everything else connected to the internet.

00:01:48,721 --> 00:01:53,210
Your username, your real name, your contacts, friends,

00:01:53,210 --> 00:01:56,320
but also people you have blocked from your contact list,

00:01:56,320 --> 00:01:58,501
your photos, everything you upload

00:01:58,501 --> 00:02:02,420
or consciously share with others.

00:02:02,420 --> 00:02:05,900
In most cases, you can choose not to share it,

00:02:05,900 --> 00:02:08,950
but in reality, even that part gets complicated

00:02:08,950 --> 00:02:12,020
if you just want to live part of your life online

00:02:12,020 --> 00:02:14,850
and be spontaneous in that life.

00:02:14,850 --> 00:02:18,780
Bad news is that even if you manage to control the first

00:02:18,780 --> 00:02:20,570
layer, there are still two more

00:02:20,570 --> 00:02:23,650
that are incredibly difficult to control.

00:02:23,650 --> 00:02:28,120
By the mere fact of being online and doing things online,

00:02:28,120 --> 00:02:31,740
you are sharing a lot more information than you think.

00:02:31,740 --> 00:02:34,570
The second layer in your digital profile

00:02:34,570 --> 00:02:38,601
includes metadata and traces of everything you do online.

00:02:38,601 --> 00:02:42,100
Think of your current location of the sites you visit,

00:02:42,100 --> 00:02:46,130
but even things like how you type and how many mistakes

00:02:46,130 --> 00:02:48,140
you make while typing.

00:02:48,140 --> 00:02:52,000
There is also a record of any connected activity.

00:02:52,000 --> 00:02:53,413
If you've got a smart fridge,

00:02:53,413 --> 00:02:57,930
it remembers that you held the door open for three minutes

00:02:57,930 --> 00:03:01,055
in the middle of the night for that midnight snack.

00:03:01,055 --> 00:03:04,660
It is nearly impossible to prevent that type of data

00:03:04,660 --> 00:03:06,764
being collected about you.

00:03:06,764 --> 00:03:10,390
You cannot opt out from that constant behavioral

00:03:10,390 --> 00:03:13,260
observation. What is the third layer?

00:03:13,260 --> 00:03:16,070
What more algorithms can learn about us

00:03:16,070 --> 00:03:18,070
after they've observed every move,

00:03:18,070 --> 00:03:20,780
every step we make online?

00:03:20,780 --> 00:03:25,428
They can learn more by comparing our behavior with patterns

00:03:25,428 --> 00:03:28,760
they have observed when looking at the behavior

00:03:28,760 --> 00:03:30,420
of all other people.

00:03:30,420 --> 00:03:34,500
Machines make assumptions and predictions about us

00:03:34,500 --> 00:03:37,030
based on statistical data.

00:03:37,030 --> 00:03:39,900
It uses all the prior knowledge collected about you

00:03:39,900 --> 00:03:43,370
from your own data, and observations about people,

00:03:43,370 --> 00:03:45,950
to make predictions about things

00:03:45,950 --> 00:03:47,810
like who you might vote for,

00:03:47,810 --> 00:03:51,562
whether you have any vulnerability like a mental illness,

00:03:51,562 --> 00:03:54,890
or whether you might be expecting a baby.

00:03:54,890 --> 00:03:59,170
It is this third layer of your profile called Inferred Data

00:03:59,170 --> 00:04:02,130
that has most value for companies.

00:04:02,130 --> 00:04:04,431
On that basis, they make their choices

00:04:04,431 --> 00:04:07,979
with regards to what advertising you should be watching

00:04:07,979 --> 00:04:11,440
and how your newsfeed should be shaped.

00:04:11,440 --> 00:04:15,110
It's pretty much impossible for you to control that layer.

00:04:15,110 --> 00:04:17,670
In fact, you cannot even discover

00:04:17,670 --> 00:04:20,160
what these machines think about you.

00:04:20,160 --> 00:04:23,440
So what does AI really know about you?

00:04:23,440 --> 00:04:25,620
Way more than you think.

00:04:25,620 --> 00:04:27,739
Any good news? Well, there are people

00:04:27,739 --> 00:04:29,760
starting to do things about it

00:04:29,760 --> 00:04:33,690
so that you can regain control over your information.

00:04:33,690 --> 00:04:35,780
At Panoptykon, we are making sure

00:04:35,780 --> 00:04:38,539
that there are legal safeguards in place to protect us

00:04:38,539 --> 00:04:42,430
and that legal actions against data-hungry companies

00:04:42,430 --> 00:04:44,430
result in high fines.

00:04:44,430 --> 00:04:48,750
Mozilla is rethinking how our data is collected

00:04:48,750 --> 00:04:50,470
and used altogether.

00:04:50,470 --> 00:04:51,780
It is a long march,

00:04:51,780 --> 00:04:53,983

YouTube URL: https://www.youtube.com/watch?v=dJWGgxIKgZA


