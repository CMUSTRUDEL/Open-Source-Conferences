Title: Why Does YouTube Recommend Conspiracy Theories? Mozilla Explains: Filter Bubbles
Publication date: 2021-05-12
Playlist: Mozilla Explains
Description: 
	YouTube’s recommendation engine, or recommendation algorithm, is intended to keep you on the site watching videos for as long as possible so they can earn advertising revenue. But the content that keeps you on the platform isn’t always factually correct, and videos that are fun to share may not always convey a message worth spreading. 


Guillaume Chaslot explains more about filter bubbles, and why YouTube sometimes recommends conspiracy theories.


Featured in this video, their.tube is a project from Mozilla Creative Media awardee Tomo Kihara. Visit http://www.their.tube to learn more about recommendation algorithms and how they can trap you in a bubble.
Captions: 
	00:00:06,290 --> 00:00:08,630
I'm Guillaume Chaslot

00:00:08,630 --> 00:00:10,370
I have a PhD in AI.

00:00:10,400 --> 00:00:14,150
I worked on the YouTube recommendation algorithm, and I'm going to explain why

00:00:14,150 --> 00:00:15,950
YouTube recommends conspiracies.

00:00:17,630 --> 00:00:22,130
So YouTube earns 2 cents each hour you spend on the site.

00:00:22,340 --> 00:00:26,690
Their objective is to maximize their profit and

00:00:26,690 --> 00:00:29,600
convert your watch time into advertising revenue,

00:00:29,750 --> 00:00:32,090
but your time is not worth 2 cents per hour.

00:00:32,110 --> 00:00:37,070
So the AI is already much better than anyone to decide which video is going

00:00:37,070 --> 00:00:39,020
to keep you online the longest.

00:00:39,450 --> 00:00:41,450
I'm like a junkie for algorithms.

00:00:41,480 --> 00:00:45,410
70% of all the views that come on YouTube as a whole,

00:00:45,650 --> 00:00:50,060
as the entire platform, 70% of those views are coming from YouTube,

00:00:50,060 --> 00:00:50,800
suggesting content.

00:00:50,800 --> 00:00:55,130
Conspiracies, divisiveness, radicalization,

00:00:55,190 --> 00:00:59,180
terrorism, all these things seem pretty terrible, but all,

00:00:59,330 --> 00:01:01,910
for the metric of engagement, they're pretty amazing.

00:01:02,330 --> 00:01:06,920
What I'm here to determine is where YouTube will lead me.

00:01:07,170 --> 00:01:09,850
The new thing that's very dangerous with

00:01:09,850 --> 00:01:12,380
YouTube recommendations is that they push you towards,

00:01:12,710 --> 00:01:16,940
for instance, conspiracy theories or flat earth videos, et cetera,

00:01:17,180 --> 00:01:18,630
because they have a lot of watch time.

00:01:21,260 --> 00:01:25,070
Are your YouTube recommendations Sometimes conspiracy theories?

00:01:25,640 --> 00:01:30,440
I mean the worst case scenario is what we're living right now. A society that

00:01:30,440 --> 00:01:35,060
continues to being more and more divided, where people don't understand

00:01:35,060 --> 00:01:38,660
each other because they live in different filter bubbles and they,

00:01:38,660 --> 00:01:43,370
start to hate each other more and more just because this hatred is useful

00:01:43,400 --> 00:01:47,780
for clickbait. So when you know that YouTube is trying to manipulate you,

00:01:48,020 --> 00:01:49,520
then it doesn't work as well.

00:01:49,550 --> 00:01:54,380
So that's the first step. The second step is to have regulation to be

00:01:54,380 --> 00:01:56,420

YouTube URL: https://www.youtube.com/watch?v=r98HbsaN9nw


