Title: What is Artificial Intelligence? Mozilla Explains.
Publication date: 2021-03-30
Playlist: Mozilla Explains
Description: 
	When you hear artificial intelligence (or AI) you probably assume it’s something difficult to understand and above your comprehension level. But, ultimately, AI is software that’s able to recognize patterns. Mozilla researcher Becca Ricks helps explain AI, algorithms and machine learning models.
Captions: 
	00:00:00,808 --> 00:00:03,391
(upbeat music)

00:00:06,790 --> 00:00:08,060
- My name is Becca Ricks.

00:00:08,060 --> 00:00:10,690
I'm a researcher with Mozilla Foundation

00:00:10,690 --> 00:00:13,311
and I work on issues around trustworthy AI

00:00:13,311 --> 00:00:16,580
and platform and corporate accountability.

00:00:16,580 --> 00:00:19,130
AI is a form of pattern recognition.

00:00:19,130 --> 00:00:21,445
So essentially there are systems

00:00:21,445 --> 00:00:24,850
where they are learning pattern's based on given data.

00:00:24,850 --> 00:00:26,871
And then when you're confronted with new data,

00:00:26,871 --> 00:00:30,240
it is able to classify that data.

00:00:30,240 --> 00:00:32,660
So for example, if you're building a system

00:00:32,660 --> 00:00:35,040
that's trained on data of pictures of cats and dogs,

00:00:37,630 --> 00:00:39,260
when you introduce a picture of a dog

00:00:39,260 --> 00:00:42,083
it will be able to successfully identify it.

00:00:42,980 --> 00:00:44,910
Some of the fundamental pieces to know

00:00:44,910 --> 00:00:48,710
are an algorithm versus a machine learning model.

00:00:48,710 --> 00:00:50,770
A developer might write an algorithm

00:00:50,770 --> 00:00:54,550
that has certain values or certain weights,

00:00:54,550 --> 00:00:57,500
and then essentially the output of the algorithm

00:00:57,500 --> 00:00:59,616
is what's called the machine learning model.

00:00:59,616 --> 00:01:01,790
And the model is the thing that actually

00:01:01,790 --> 00:01:05,140
then takes in new data and is able to make decisions

00:01:05,140 --> 00:01:08,620
based on that pattern about the new piece of data.

00:01:08,620 --> 00:01:10,340
So you can kind of think about the algorithm

00:01:10,340 --> 00:01:13,130
as like the program that works with the data set.

00:01:13,130 --> 00:01:16,930
And then the model is the output that makes the prediction.

00:01:16,930 --> 00:01:18,340
There's a growing awareness

00:01:18,340 --> 00:01:22,500
that a lot of our technologies use AI.

00:01:22,500 --> 00:01:24,370
I don't think people necessarily understand

00:01:24,370 --> 00:01:26,930
why it's making certain decisions.

00:01:26,930 --> 00:01:28,850
On an individual level,

00:01:28,850 --> 00:01:32,600
all of us interact with these technologies every day.

00:01:32,600 --> 00:01:35,700
And for some of us, they might have an adverse impact,

00:01:35,700 --> 00:01:37,850
they might affect whether or not our friends

00:01:37,850 --> 00:01:38,870
are seeing what we post,

00:01:38,870 --> 00:01:40,540
they also might affect whether or not

00:01:40,540 --> 00:01:43,650
we're getting certain resources from our local government.

00:01:43,650 --> 00:01:46,300
And so I think there's a real individual need

00:01:46,300 --> 00:01:48,160
that we all have for understanding

00:01:48,160 --> 00:01:50,390
what's happening to us on a personal level.

00:01:50,390 --> 00:01:52,600
But I think more importantly,

00:01:52,600 --> 00:01:54,670
the way a lot of this technology works

00:01:54,670 --> 00:01:59,670
is there are really collective risks and harms to society.

00:01:59,677 --> 00:02:02,080
And I think it's a little more complicated

00:02:02,080 --> 00:02:04,670
to think about what those harms are

00:02:04,670 --> 00:02:07,110
because they might not be happening to you individually,

00:02:07,110 --> 00:02:09,790
it might be happening to a particular group,

00:02:09,790 --> 00:02:11,120
that's all already vulnerable.

00:02:11,120 --> 00:02:12,390
It might be happening,

00:02:12,390 --> 00:02:16,670
over time to the media ecosystem for example.

00:02:16,670 --> 00:02:17,910
We really need to think about

00:02:17,910 --> 00:02:20,270
what is happening to us collectively

00:02:20,270 --> 00:02:22,201
when we integrate these technologies

00:02:22,201 --> 00:02:25,360
without any kind of transparency or accountability

00:02:25,360 --> 00:02:27,810
into why they're making these decisions.

00:02:27,810 --> 00:02:31,340
The more that we all know about how AI systems work,

00:02:31,340 --> 00:02:34,690
the easier it makes it for us to imagine

00:02:34,690 --> 00:02:36,010
what better looks like.

00:02:36,010 --> 00:02:39,920
And it makes it easier for us to design alternatives

00:02:39,920 --> 00:02:43,460
that benefit society or reflect the values

00:02:43,460 --> 00:02:44,913

YouTube URL: https://www.youtube.com/watch?v=P-iiN0c2uic


