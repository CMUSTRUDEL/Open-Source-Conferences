Title: Mozilla Security Research Summit 2019 - Automated Methods for Fingerprinting Detection
Publication date: 2019-06-24
Playlist: 2019 SF Security Research Summit
Description: 
	Sarah Bird - Automated Methods for Fingerprinting Detection

Talk from the 2019 SF Security Research Summit (https://events.mozilla.org/moz2019securityresearchsummit). This event is part of the Security Engineering University Relationship Framework (SURF) initiative, which aims to increase collaboration between Mozilla and the academic community. We would like to leverage academic talent to help explore security and privacy research problems, and to strengthen Mozilla's ties to the academic community. Mozilla security engineers aim to actively participate in the research community through thesis supervision, collaborations, placements and Mozilla-hosted security summits. For more info see: https://surf.mozilla.org/

Slides: https://drive.google.com/open?id=16py5Lj9Pu9FRZZKXCy0surAMyNSKBYcJ
Captions: 
	00:00:00,030 --> 00:00:06,509
hi I'm Sarah and not so good with

00:00:02,610 --> 00:00:09,599
technology as it turns out and I am a

00:00:06,509 --> 00:00:11,070
senior research engineer at at Mozilla

00:00:09,599 --> 00:00:13,950
and I work on the systems Research Group

00:00:11,070 --> 00:00:15,960
and so a lot of folks here work today

00:00:13,950 --> 00:00:18,060
work on the security engineering team my

00:00:15,960 --> 00:00:20,220
team is a small band of researchers that

00:00:18,060 --> 00:00:22,710
are trying to develop new techniques and

00:00:20,220 --> 00:00:23,880
novel data products we have another

00:00:22,710 --> 00:00:26,910
member of our team in the back row there

00:00:23,880 --> 00:00:27,930
Ilana and so today I'm going to talk to

00:00:26,910 --> 00:00:30,330
you a little bit about the work I've

00:00:27,930 --> 00:00:32,850
been doing on automating methods for

00:00:30,330 --> 00:00:34,110
fingerprinting detection and I'll start

00:00:32,850 --> 00:00:35,969
with the current techniques and this is

00:00:34,110 --> 00:00:37,649
starting where Steve left off and really

00:00:35,969 --> 00:00:40,050
a lot of the work that I do builds on

00:00:37,649 --> 00:00:41,790
his work and work of other researchers

00:00:40,050 --> 00:00:44,550
like Anna poem das who is here in the

00:00:41,790 --> 00:00:46,379
audience too so we'll look at what we're

00:00:44,550 --> 00:00:48,660
currently doing the methods that I have

00:00:46,379 --> 00:00:50,489
in development and and all of the

00:00:48,660 --> 00:00:54,480
opportunities and questions that these

00:00:50,489 --> 00:00:55,530
methods have brought up that I hope some

00:00:54,480 --> 00:00:59,370
of you are interested in collaborating

00:00:55,530 --> 00:01:01,859
with me on and so if I'm ghosts Teves

00:00:59,370 --> 00:01:03,870
the presentation this morning down into

00:01:01,859 --> 00:01:05,369
a slide so if you can just like take

00:01:03,870 --> 00:01:07,580
yourself back in time to when Steve was

00:01:05,369 --> 00:01:10,770
talking about device properties and

00:01:07,580 --> 00:01:12,869
fingerprinting and and this short bit

00:01:10,770 --> 00:01:15,180
that he gave on and the current process

00:01:12,869 --> 00:01:18,390
that we use and so to summarize that

00:01:15,180 --> 00:01:20,610
again we start by doing a crawl using

00:01:18,390 --> 00:01:22,470
open wpm which was a tool he and other

00:01:20,610 --> 00:01:24,420
colleagues at Princeton developed and we

00:01:22,470 --> 00:01:26,400
now continue to maintain at Mozilla and

00:01:24,420 --> 00:01:29,430
open wpm is an instrumented version of

00:01:26,400 --> 00:01:32,070
Firefox that can allows you to go in

00:01:29,430 --> 00:01:35,490
browse websites crawl websites and then

00:01:32,070 --> 00:01:37,409
collect a bunch of things the HTTP

00:01:35,490 --> 00:01:39,210
requests the redirect the resources that

00:01:37,409 --> 00:01:40,799
were loaded all of the headers and of

00:01:39,210 --> 00:01:43,860
particular interest to me all of the

00:01:40,799 --> 00:01:46,049
JavaScript or the instrumented

00:01:43,860 --> 00:01:48,060
JavaScript API s that were hit and a

00:01:46,049 --> 00:01:50,850
bunch of data about that at the moment

00:01:48,060 --> 00:01:52,680
we typically do crawls on the Alexa top

00:01:50,850 --> 00:01:54,720
1 million home pages but we've also my

00:01:52,680 --> 00:01:56,460
teams also done some different sort of

00:01:54,720 --> 00:01:59,159
size and profile of crawl which has

00:01:56,460 --> 00:02:01,469
yielded some interesting things then we

00:01:59,159 --> 00:02:05,250
move into the analyze section and we

00:02:01,469 --> 00:02:07,619
apply a series of heuristics to document

00:02:05,250 --> 00:02:09,660
if a script that was loaded is either

00:02:07,619 --> 00:02:12,670
doing canvas fingerprinting font

00:02:09,660 --> 00:02:15,459
fingerprinting audio or WebRTC

00:02:12,670 --> 00:02:18,459
and then in the validation step those

00:02:15,459 --> 00:02:20,860
scripts that are flagged and present on

00:02:18,459 --> 00:02:23,380
over ten domains are then sent off to

00:02:20,860 --> 00:02:25,540
disconnect for validation and as Steve

00:02:23,380 --> 00:02:28,750
described checked for checked rigorously

00:02:25,540 --> 00:02:30,489
to sort of determine their their status

00:02:28,750 --> 00:02:31,660
and so to dig into this a little bit

00:02:30,489 --> 00:02:34,830
more I'm just curious how many people

00:02:31,660 --> 00:02:35,950
here have used or heard of open wpm

00:02:34,830 --> 00:02:39,160
awesome

00:02:35,950 --> 00:02:42,190
well I will keep this short so the open

00:02:39,160 --> 00:02:43,390
WM visits a page record the resources

00:02:42,190 --> 00:02:46,120
that were loaded and then for the

00:02:43,390 --> 00:02:47,980
instrumented for the instrumented

00:02:46,120 --> 00:02:49,900
JavaScript API so those the ones that

00:02:47,980 --> 00:02:51,220
I've highlighted here in bold we collect

00:02:49,900 --> 00:02:54,780
information about the calls that were

00:02:51,220 --> 00:02:57,010
made so you end up with a table where

00:02:54,780 --> 00:02:58,540
you've got the API you've got the

00:02:57,010 --> 00:03:00,340
arguments the passed of values that

00:02:58,540 --> 00:03:03,670
returned a bunch of other metadata and

00:03:00,340 --> 00:03:08,080
then in the heuristics approach which

00:03:03,670 --> 00:03:11,350
Steve is widely published on you apply a

00:03:08,080 --> 00:03:12,670
rule set to that table and and to try

00:03:11,350 --> 00:03:13,959
and determine whether a script is

00:03:12,670 --> 00:03:15,700
fingerprinting or not and so I'll just

00:03:13,959 --> 00:03:18,040
go through one which is the the canvas

00:03:15,700 --> 00:03:20,079
fingerprinting technique and so there

00:03:18,040 --> 00:03:21,430
are sort of four basic steps first is

00:03:20,079 --> 00:03:22,810
the canvas large enough because it needs

00:03:21,430 --> 00:03:25,480
to be large enough so that when you turn

00:03:22,810 --> 00:03:27,100
it into into an identify that you have

00:03:25,480 --> 00:03:28,420
sufficient entropy to isolate this

00:03:27,100 --> 00:03:31,120
particular user or this particular

00:03:28,420 --> 00:03:33,340
browser again is the text written to the

00:03:31,120 --> 00:03:36,760
canvas big enough to generate that

00:03:33,340 --> 00:03:38,290
entropy then has has the the calls that

00:03:36,760 --> 00:03:39,760
would actually exfiltrate information

00:03:38,290 --> 00:03:41,680
and turn it into an identifier being

00:03:39,760 --> 00:03:43,810
called and then the last step is

00:03:41,680 --> 00:03:45,940
actually a sort of a negative signal

00:03:43,810 --> 00:03:47,140
which is have save restore and event

00:03:45,940 --> 00:03:49,870
lists are being called because if they

00:03:47,140 --> 00:03:52,090
have this is likely going to be a valid

00:03:49,870 --> 00:03:53,890
use of the canvas which is a widely used

00:03:52,090 --> 00:03:55,870
thing it's used in charting libraries

00:03:53,890 --> 00:03:57,280
and lots of other and little games and

00:03:55,870 --> 00:03:58,540
lots of I get other good things and so

00:03:57,280 --> 00:04:00,340
that you have to sort of combine these

00:03:58,540 --> 00:04:03,760
signals to try and see if we actually

00:04:00,340 --> 00:04:06,160
have fingerprinting and there's a other

00:04:03,760 --> 00:04:08,980
the other heuristics are up there and in

00:04:06,160 --> 00:04:12,400
Steve's research and this has been

00:04:08,980 --> 00:04:13,600
really successful and some of the things

00:04:12,400 --> 00:04:15,609
that I think are really important about

00:04:13,600 --> 00:04:17,530
it it works on minified and obfuscated

00:04:15,609 --> 00:04:20,049
code because you are just recording what

00:04:17,530 --> 00:04:22,300
got executed the whole methodology

00:04:20,049 --> 00:04:24,039
already detects fingerprinting with very

00:04:22,300 --> 00:04:25,230
low false positives and with the

00:04:24,039 --> 00:04:27,360
validation step that

00:04:25,230 --> 00:04:28,620
that goes to zero that's our goal we do

00:04:27,360 --> 00:04:29,700
not want to be blocking things that

00:04:28,620 --> 00:04:31,860
shouldn't be blocked

00:04:29,700 --> 00:04:34,580
it's a peer-reviewed methodology you

00:04:31,860 --> 00:04:37,440
know academics and appreciate that step

00:04:34,580 --> 00:04:38,940
it's privacy-preserving we're just using

00:04:37,440 --> 00:04:40,530
crawl data we're not relying on user

00:04:38,940 --> 00:04:42,660
data or anything like that to generate

00:04:40,530 --> 00:04:44,070
this list and as Steve described we're

00:04:42,660 --> 00:04:46,140
already having an impact seeing that

00:04:44,070 --> 00:04:47,340
little case study of tiny MCE choosing

00:04:46,140 --> 00:04:48,930
to remove the fingerprint because they

00:04:47,340 --> 00:04:50,640
didn't want to be a blocked and this is

00:04:48,930 --> 00:04:52,530
this is amazing like we're really this

00:04:50,640 --> 00:04:53,820
these relatively simple and

00:04:52,530 --> 00:04:57,360
straightforward thing to do and it's

00:04:53,820 --> 00:04:59,130
really having an impact and so I want to

00:04:57,360 --> 00:05:01,110
emphasize that before I get onto some of

00:04:59,130 --> 00:05:03,000
the challenges and these are things that

00:05:01,110 --> 00:05:06,420
are sort of informed my direction and so

00:05:03,000 --> 00:05:08,700
the first one is that the ecosystem can

00:05:06,420 --> 00:05:10,890
evolve around these heuristics and in

00:05:08,700 --> 00:05:12,480
particular for simple heuristics that

00:05:10,890 --> 00:05:15,090
are just looking for a few calls of

00:05:12,480 --> 00:05:17,400
certain api's as those API has become

00:05:15,090 --> 00:05:19,020
more widely adopted and become more

00:05:17,400 --> 00:05:20,790
widely used in general for valid use

00:05:19,020 --> 00:05:22,590
cases where those simple heuristics are

00:05:20,790 --> 00:05:24,450
likely generate more false positives and

00:05:22,590 --> 00:05:27,060
so you get in this arms race of creating

00:05:24,450 --> 00:05:28,110
more sophisticated heuristics complex

00:05:27,060 --> 00:05:29,850
heuristics like the canvas

00:05:28,110 --> 00:05:32,580
fingerprinting one that I described

00:05:29,850 --> 00:05:34,110
become easy to evade as people decide

00:05:32,580 --> 00:05:35,880
that they don't want to be good actors

00:05:34,110 --> 00:05:37,860
and just have themselves removed they'll

00:05:35,880 --> 00:05:39,960
just add they can add a save you know a

00:05:37,860 --> 00:05:42,660
save call that doesn't do anything but

00:05:39,960 --> 00:05:45,930
enables them to bypass the heuristic in

00:05:42,660 --> 00:05:47,880
addition to that there are other types

00:05:45,930 --> 00:05:49,410
of browser fingerprinting that we

00:05:47,880 --> 00:05:51,660
already know exist that we don't have

00:05:49,410 --> 00:05:53,610
heuristics for yet and in particular

00:05:51,660 --> 00:05:56,100
there's browser attribute fingerprinting

00:05:53,610 --> 00:05:58,680
so that's when you hit things like the

00:05:56,100 --> 00:06:02,220
user agent the battery API if you're on

00:05:58,680 --> 00:06:03,960
Chrome the the screen size and depth and

00:06:02,220 --> 00:06:05,760
things like that and that was like the

00:06:03,960 --> 00:06:07,620
original panopticon optic like paper

00:06:05,760 --> 00:06:08,640
from AFF was you know the first a sort

00:06:07,620 --> 00:06:10,620
of document that so it's been known

00:06:08,640 --> 00:06:12,750
about for a while others have speculated

00:06:10,620 --> 00:06:14,370
that emoji fingerprinting could be a

00:06:12,750 --> 00:06:16,200
thing although I haven't seen it in the

00:06:14,370 --> 00:06:17,460
world yet there's a form of

00:06:16,200 --> 00:06:18,960
fingerprinting called device class

00:06:17,460 --> 00:06:22,610
fingerprinting which I'll talk about a

00:06:18,960 --> 00:06:25,320
bit more later and then mobile sensor

00:06:22,610 --> 00:06:26,970
using mobile sensors to identify devices

00:06:25,320 --> 00:06:30,480
which I know PEMDAS has done an

00:06:26,970 --> 00:06:32,430
important paper on and so one of the

00:06:30,480 --> 00:06:34,020
nice things about the method the

00:06:32,430 --> 00:06:36,660
heuristic methods is that as I said they

00:06:34,020 --> 00:06:37,980
have very low false positives so we can

00:06:36,660 --> 00:06:38,700
feel very confident that we're getting a

00:06:37,980 --> 00:06:40,200
strong lower

00:06:38,700 --> 00:06:42,420
found on the extent of fingerprinting

00:06:40,200 --> 00:06:44,310
but that doesn't mean that we're

00:06:42,420 --> 00:06:47,970
capturing all of the fingerprinting and

00:06:44,310 --> 00:06:50,280
so we don't necessarily know how big the

00:06:47,970 --> 00:06:51,540
problem is although I will say you know

00:06:50,280 --> 00:06:53,670
our instinct is not that we're missing

00:06:51,540 --> 00:06:55,470
half of it or anything like that but

00:06:53,670 --> 00:06:56,460
that you know there's a difference

00:06:55,470 --> 00:06:58,560
between false positives and false

00:06:56,460 --> 00:07:00,630
negatives and then the last bit is is

00:06:58,560 --> 00:07:03,020
that it only provides a limited window

00:07:00,630 --> 00:07:05,370
into new vectors now Steve discovered

00:07:03,020 --> 00:07:07,290
like audio fingerprinting by look at

00:07:05,370 --> 00:07:08,400
exist looking at existing fingerprinting

00:07:07,290 --> 00:07:09,810
scripts that we're doing say canvas

00:07:08,400 --> 00:07:11,760
fingerprinting and was noticing this odd

00:07:09,810 --> 00:07:13,170
behavior but that's very manual and so

00:07:11,760 --> 00:07:15,030
these techniques don't provide like an

00:07:13,170 --> 00:07:19,500
automated window into new classes of

00:07:15,030 --> 00:07:20,640
fingerprinting and so these are the sort

00:07:19,500 --> 00:07:21,960
of issues that I've been thinking about

00:07:20,640 --> 00:07:24,540
when I'm trying to think of like how can

00:07:21,960 --> 00:07:26,250
we keep the good work and keep our

00:07:24,540 --> 00:07:28,530
competitive advantage and being able to

00:07:26,250 --> 00:07:29,880
you know want to keep stopping the bad

00:07:28,530 --> 00:07:32,730
the behavior that we don't think is

00:07:29,880 --> 00:07:34,440
appropriate to expose users to and so

00:07:32,730 --> 00:07:35,670
there's lots of stuff in the literature

00:07:34,440 --> 00:07:38,010
I wouldn't want to do a literature

00:07:35,670 --> 00:07:39,570
review in front of a whole roomful of

00:07:38,010 --> 00:07:41,460
people who have masses of the literature

00:07:39,570 --> 00:07:44,160
review but the few things that inform my

00:07:41,460 --> 00:07:46,530
work the click see group did some access

00:07:44,160 --> 00:07:49,650
with looking at browser data and instead

00:07:46,530 --> 00:07:51,720
of looking at the JavaScript calls as a

00:07:49,650 --> 00:07:53,880
symptom of fingerprinting looking at the

00:07:51,720 --> 00:07:55,590
generation of unique identifies as the

00:07:53,880 --> 00:07:57,510
other end of the symptom of

00:07:55,590 --> 00:08:00,680
fingerprinting so you fingerprinting is

00:07:57,510 --> 00:08:03,000
turning the JavaScript and browser

00:08:00,680 --> 00:08:04,710
attributes into a unique identifier and

00:08:03,000 --> 00:08:06,690
so there's two pieces to look at there

00:08:04,710 --> 00:08:08,430
there's also been lots of studies that

00:08:06,690 --> 00:08:10,500
are relevant to my work using supervised

00:08:08,430 --> 00:08:12,840
classifiers to identify trackers or

00:08:10,500 --> 00:08:14,850
blocking ads or anti ad blocking and so

00:08:12,840 --> 00:08:18,090
on and they use a variety of sources

00:08:14,850 --> 00:08:20,970
from static analysis HTTP traffic packet

00:08:18,090 --> 00:08:23,370
inspection and so on the fundamental

00:08:20,970 --> 00:08:24,870
challenge that we all face when we're

00:08:23,370 --> 00:08:27,570
doing web measurement is that there's no

00:08:24,870 --> 00:08:29,160
ground truth and the best sources of

00:08:27,570 --> 00:08:31,530
ground truth really are the list that we

00:08:29,160 --> 00:08:34,830
can currently generate from from the

00:08:31,530 --> 00:08:38,660
heuristics or the privacy lists like

00:08:34,830 --> 00:08:41,099
easy lists and easy privacy that are all

00:08:38,660 --> 00:08:43,500
tailor-made for their own things and not

00:08:41,099 --> 00:08:45,420
necessarily what I'm looking for when

00:08:43,500 --> 00:08:47,190
I'm trying to like can I reach beyond

00:08:45,420 --> 00:08:48,660
the lower bound that the heuristics have

00:08:47,190 --> 00:08:51,450
established like how do I know how well

00:08:48,660 --> 00:08:55,470
I'm doing and so I decided to take

00:08:51,450 --> 00:08:58,410
supervised approach to this and so

00:08:55,470 --> 00:09:00,450
starting with cruel data applying a

00:08:58,410 --> 00:09:02,790
minimal label set and then seeing what

00:09:00,450 --> 00:09:05,190
else we label so I'm going to get really

00:09:02,790 --> 00:09:06,870
into the weeds of this for a bit and

00:09:05,190 --> 00:09:08,460
hopefully it'll spark new ideas and

00:09:06,870 --> 00:09:10,560
thoughts and critiques and I look

00:09:08,460 --> 00:09:13,170
forward to having those conversations so

00:09:10,560 --> 00:09:15,420
we're back with the same raw data that

00:09:13,170 --> 00:09:17,190
we use for the heuristics and I am sort

00:09:15,420 --> 00:09:19,350
of focused somewhat religiously on that

00:09:17,190 --> 00:09:22,380
middle column of the api's that were

00:09:19,350 --> 00:09:24,930
accessed so I take this data and I

00:09:22,380 --> 00:09:28,470
transform it into vectors and each of my

00:09:24,930 --> 00:09:31,020
observations I assemble from the script

00:09:28,470 --> 00:09:32,370
domain the script the ends a little bit

00:09:31,020 --> 00:09:34,530
at the end of the script the script path

00:09:32,370 --> 00:09:38,970
and then the function name that was

00:09:34,530 --> 00:09:40,560
called that a series of calls were were

00:09:38,970 --> 00:09:42,540
gathered under and so each observation

00:09:40,560 --> 00:09:44,490
is the relative frequency of calls to a

00:09:42,540 --> 00:09:48,420
set of JavaScript API is over that

00:09:44,490 --> 00:09:50,330
little chunk or snippet of code from

00:09:48,420 --> 00:09:54,390
there we have all our observations and

00:09:50,330 --> 00:09:55,680
we can we can pick a labeling strategy

00:09:54,390 --> 00:09:58,590
and they're a bunch of labeling strategy

00:09:55,680 --> 00:10:00,300
I've been mostly focused on labeling all

00:09:58,590 --> 00:10:01,620
the observations based on the scripts

00:10:00,300 --> 00:10:03,570
that were flagged by the heuristic

00:10:01,620 --> 00:10:06,300
methods but we can also do keyword

00:10:03,570 --> 00:10:09,210
searches and just look for words like

00:10:06,300 --> 00:10:12,000
finger print or pixel or tracker in in

00:10:09,210 --> 00:10:13,980
our observations and then all we can a

00:10:12,000 --> 00:10:16,710
we can I'm trying to I'm also trying to

00:10:13,980 --> 00:10:20,940
think about new ways of labeling at the

00:10:16,710 --> 00:10:24,810
just labeling individual observations so

00:10:20,940 --> 00:10:27,060
this is just semi-supervised learning so

00:10:24,810 --> 00:10:30,480
now we just want to propagate those

00:10:27,060 --> 00:10:32,850
labels and the way I take a fairly a

00:10:30,480 --> 00:10:34,860
very simple approach to this and this

00:10:32,850 --> 00:10:36,780
simplicity of this has allowed me to

00:10:34,860 --> 00:10:39,270
really dig into what's happening at each

00:10:36,780 --> 00:10:40,640
step and try and tease it apart rather

00:10:39,270 --> 00:10:42,600
than using a sort of out the box

00:10:40,640 --> 00:10:46,560
methodology so the first thing as I do

00:10:42,600 --> 00:10:48,780
as I compute the pairwise distances

00:10:46,560 --> 00:10:50,580
reduce pairwise distance matrix from

00:10:48,780 --> 00:10:53,130
every observation to each of the labels

00:10:50,580 --> 00:10:54,660
and then one thing that I found was that

00:10:53,130 --> 00:10:57,870
I needed to remove what I call leaky

00:10:54,660 --> 00:10:58,890
labels and so the thing about a piece of

00:10:57,870 --> 00:11:01,440
JavaScript let's say the whole

00:10:58,890 --> 00:11:02,820
fingerprint 2j s script is there's a

00:11:01,440 --> 00:11:03,610
there's a bit in there that's doing the

00:11:02,820 --> 00:11:05,140
canvas finger

00:11:03,610 --> 00:11:06,250
that I want to isolate but then there's

00:11:05,140 --> 00:11:08,680
a whole bunch of just workhorse

00:11:06,250 --> 00:11:10,090
JavaScript in there that maybe just you

00:11:08,680 --> 00:11:11,710
know just regular JavaScript functions

00:11:10,090 --> 00:11:13,270
that ends up being shared across most of

00:11:11,710 --> 00:11:14,920
the code on most of the web and so if

00:11:13,270 --> 00:11:16,990
you inadvertently label that because

00:11:14,920 --> 00:11:20,050
you've labeled the whole fingerprint 2jf

00:11:16,990 --> 00:11:21,280
script as bad you you just label your

00:11:20,050 --> 00:11:24,130
whole dataset and that doesn't yield any

00:11:21,280 --> 00:11:25,690
information so that label precision is a

00:11:24,130 --> 00:11:27,460
real problem and so I take a very simple

00:11:25,690 --> 00:11:30,070
just threshold based approach to remove

00:11:27,460 --> 00:11:32,170
those leaky labels and from there on out

00:11:30,070 --> 00:11:33,070
it's a simple question of for each of my

00:11:32,170 --> 00:11:35,860
observations

00:11:33,070 --> 00:11:38,170
how many labels is it near I then map

00:11:35,860 --> 00:11:42,390
observations back to scripts and then a

00:11:38,170 --> 00:11:45,190
script gets a score based on how many

00:11:42,390 --> 00:11:47,890
based on the aggregate of all that

00:11:45,190 --> 00:11:50,560
information I have a library that's up

00:11:47,890 --> 00:11:52,270
at Dyea Mozilla dice core it's still in

00:11:50,560 --> 00:11:54,100
alpha I have some known issues that

00:11:52,270 --> 00:11:55,930
you're welcome to collaborate find more

00:11:54,100 --> 00:11:58,000
known issues or currently unknown soon

00:11:55,930 --> 00:12:03,340
to be known issues and I welcome that

00:11:58,000 --> 00:12:04,930
feedback and then at the at the end of

00:12:03,340 --> 00:12:06,970
the day what you end up with is a list

00:12:04,930 --> 00:12:09,310
of scripts and then we're back at the no

00:12:06,970 --> 00:12:11,380
ground truth problem and so whilst I

00:12:09,310 --> 00:12:13,750
might have bypassed the need to create a

00:12:11,380 --> 00:12:15,820
label set up front and then get go and

00:12:13,750 --> 00:12:18,490
work on supervised learning I'm still

00:12:15,820 --> 00:12:19,810
now stuck with a list of say five six

00:12:18,490 --> 00:12:20,950
thousand scripts that I don't know what

00:12:19,810 --> 00:12:23,640
they are and I have to figure out how

00:12:20,950 --> 00:12:26,380
how well like my my labeling has gone

00:12:23,640 --> 00:12:28,330
and so I've been working on some very

00:12:26,380 --> 00:12:29,800
simple tools to just build a website to

00:12:28,330 --> 00:12:31,120
help with script review for people

00:12:29,800 --> 00:12:33,730
who've done measurement studies script

00:12:31,120 --> 00:12:35,650
review is a is a is a big part if

00:12:33,730 --> 00:12:38,050
anybody's interested in this it's a bit

00:12:35,650 --> 00:12:39,910
of a tangent but do reach out and I can

00:12:38,050 --> 00:12:42,970
open-source this this code on script

00:12:39,910 --> 00:12:45,400
review that I've been working on and so

00:12:42,970 --> 00:12:48,400
what I've had some initial successes in

00:12:45,400 --> 00:12:50,980
particular we are detecting instances of

00:12:48,400 --> 00:12:53,500
fingerprinting scripts there are clearly

00:12:50,980 --> 00:12:55,240
just other copies of say fingerprint j/s

00:12:53,500 --> 00:12:56,770
but there had failed to meet the exact

00:12:55,240 --> 00:12:58,180
heuristic criteria which could be for

00:12:56,770 --> 00:13:00,790
all sorts of reasons the page was slow

00:12:58,180 --> 00:13:05,020
to load who knows what what other reason

00:13:00,790 --> 00:13:06,370
in addition we detected scripts that

00:13:05,020 --> 00:13:08,320
were just doing browser attribute

00:13:06,370 --> 00:13:09,580
fingerprinting so this is scripts for

00:13:08,320 --> 00:13:11,440
which we didn't have a label on the way

00:13:09,580 --> 00:13:13,840
in but we were able to identify them on

00:13:11,440 --> 00:13:15,340
the way out and that's because scripts

00:13:13,840 --> 00:13:16,440
that do one kind of fingerprinting often

00:13:15,340 --> 00:13:18,240
do another kind of finger

00:13:16,440 --> 00:13:21,840
printing and so those labels that signal

00:13:18,240 --> 00:13:24,060
is able to spread out we have also

00:13:21,840 --> 00:13:26,940
identified and Steve and I were doing

00:13:24,060 --> 00:13:28,590
review on a on a set on a result set and

00:13:26,940 --> 00:13:29,820
we're seeing some scripts that look like

00:13:28,590 --> 00:13:31,500
finger printing but not quite like

00:13:29,820 --> 00:13:33,060
finger printing and we realized that

00:13:31,500 --> 00:13:35,160
they were device class finger printing

00:13:33,060 --> 00:13:36,780
so I'm gonna go forward and back

00:13:35,160 --> 00:13:39,930
device class finger printing if you're

00:13:36,780 --> 00:13:42,780
not as familiar with it is a type of

00:13:39,930 --> 00:13:44,190
finger printing that was proposed in

00:13:42,780 --> 00:13:45,780
this paper Picasso

00:13:44,190 --> 00:13:47,880
where you're not trying to generate a

00:13:45,780 --> 00:13:50,130
unique identifier for a given browser

00:13:47,880 --> 00:13:53,010
you're trying to die you're trying to

00:13:50,130 --> 00:13:54,780
accurately determine the class of device

00:13:53,010 --> 00:13:57,480
the browser and hardware combination it

00:13:54,780 --> 00:13:59,130
is and so this is often used in the kind

00:13:57,480 --> 00:14:01,470
of fraud or this can be used in the kind

00:13:59,130 --> 00:14:02,850
of fraud and anti fraud cases that Steve

00:14:01,470 --> 00:14:05,400
described earlier and we were seeing

00:14:02,850 --> 00:14:07,590
these canvas images that we captured

00:14:05,400 --> 00:14:11,420
were actually from Facebook's

00:14:07,590 --> 00:14:14,520
implementation of this of this algorithm

00:14:11,420 --> 00:14:16,200
some of the other things that were that

00:14:14,520 --> 00:14:17,280
I have been going well is that keyword

00:14:16,200 --> 00:14:19,200
labeling actually works surprisingly

00:14:17,280 --> 00:14:21,540
well so looking for the word fingerprint

00:14:19,200 --> 00:14:24,960
gave us basically the same results as in

00:14:21,540 --> 00:14:26,460
putting a as in putting the heuristic

00:14:24,960 --> 00:14:28,530
list now obviously this is not a

00:14:26,460 --> 00:14:29,400
sustainable just looking for the word

00:14:28,530 --> 00:14:31,590
fingerprint is not gonna be a

00:14:29,400 --> 00:14:32,820
sustainable path for for doing

00:14:31,590 --> 00:14:34,350
fingerprint detection but it does

00:14:32,820 --> 00:14:35,700
provide interesting opportunities to

00:14:34,350 --> 00:14:37,620
explore this data with a bit more

00:14:35,700 --> 00:14:40,230
granularity and and be able to dig into

00:14:37,620 --> 00:14:41,850
what is otherwise a list of for you know

00:14:40,230 --> 00:14:44,190
two to four million scripts that where

00:14:41,850 --> 00:14:45,900
do you start and then the last piece

00:14:44,190 --> 00:14:48,690
that I think is useful about this

00:14:45,900 --> 00:14:50,130
methodology so far is again let's say

00:14:48,690 --> 00:14:52,710
you start with two million scripts and

00:14:50,130 --> 00:14:54,090
you identify 5,000 as definitively being

00:14:52,710 --> 00:14:55,620
canvass or what or what have you

00:14:54,090 --> 00:14:57,030
fingerprinting based on the heuristics

00:14:55,620 --> 00:14:58,440
but then you you don't have any

00:14:57,030 --> 00:15:00,780
information about what the other one

00:14:58,440 --> 00:15:02,700
point nine nine million are and this the

00:15:00,780 --> 00:15:04,470
the score that the this methodology

00:15:02,700 --> 00:15:06,210
gives the script provides the sort and

00:15:04,470 --> 00:15:07,770
enables you to start looking in some

00:15:06,210 --> 00:15:13,080
kind of prioritized order it like what

00:15:07,770 --> 00:15:14,370
might be there of course this is it's

00:15:13,080 --> 00:15:17,280
there are lots of challenges along the

00:15:14,370 --> 00:15:18,630
way too and in particular I'm getting a

00:15:17,280 --> 00:15:20,960
large number of false positives at the

00:15:18,630 --> 00:15:23,550
moment and these are predominantly

00:15:20,960 --> 00:15:25,770
legitimate uses of the canvas API and so

00:15:23,550 --> 00:15:27,270
something like the canvas API is used on

00:15:25,770 --> 00:15:28,810
an order of magnitude more frequently

00:15:27,270 --> 00:15:33,340
than say the audio context

00:15:28,810 --> 00:15:36,070
PII and these these probabilities these

00:15:33,340 --> 00:15:38,050
uses fall into sort of two classes I

00:15:36,070 --> 00:15:39,100
would say they're things firstly things

00:15:38,050 --> 00:15:41,200
that we've definitely shouldn't be

00:15:39,100 --> 00:15:42,760
flagging like charting libraries or

00:15:41,200 --> 00:15:45,010
little games and things like that which

00:15:42,760 --> 00:15:49,450
I have hope that we can eliminate them

00:15:45,010 --> 00:15:50,980
and then the other class is things that

00:15:49,450 --> 00:15:53,860
are essentially doing the work of a

00:15:50,980 --> 00:15:55,720
canvas fingerprint so in particular the

00:15:53,860 --> 00:15:58,630
WordPress emoji detector and the

00:15:55,720 --> 00:16:01,810
modernizers emoji support detection do

00:15:58,630 --> 00:16:03,100
the exact same set of steps that a that

00:16:01,810 --> 00:16:04,420
canvas fingerprinting does the only

00:16:03,100 --> 00:16:09,640
difference is sort of what's written to

00:16:04,420 --> 00:16:11,620
the canvas and and so in the in the very

00:16:09,640 --> 00:16:13,240
specific domain the very specific

00:16:11,620 --> 00:16:14,380
feature vector that I've set up I don't

00:16:13,240 --> 00:16:16,000
think I'm ever going to be able to tease

00:16:14,380 --> 00:16:18,820
that apart we're gonna need to bring in

00:16:16,000 --> 00:16:20,470
new sources of information more

00:16:18,820 --> 00:16:22,270
challenges again at the moment I'm doing

00:16:20,470 --> 00:16:23,980
manual threshold selection which is very

00:16:22,270 --> 00:16:26,410
common in semi-supervised learning but

00:16:23,980 --> 00:16:27,790
is is not a sustainable way to move

00:16:26,410 --> 00:16:30,820
forward with something that could be

00:16:27,790 --> 00:16:32,350
deployed widely we're also seeing

00:16:30,820 --> 00:16:34,350
interesting variations between call

00:16:32,350 --> 00:16:36,700
strategies so I mentioned before that

00:16:34,350 --> 00:16:40,150
typically steves calls run over like the

00:16:36,700 --> 00:16:43,180
full Alexa top 1 million we've also run

00:16:40,150 --> 00:16:47,230
crawls where we just we do a random walk

00:16:43,180 --> 00:16:49,990
in the top 10,000 and extract a million

00:16:47,230 --> 00:16:51,880
pages but from the top 10,000 sites and

00:16:49,990 --> 00:16:53,440
we found much better sort of signal to

00:16:51,880 --> 00:16:55,330
noise and much better results like

00:16:53,440 --> 00:16:57,490
concentrating our efforts down there and

00:16:55,330 --> 00:16:59,320
that might be because as Steve said

00:16:57,490 --> 00:17:01,060
there's more fingerprinting happening in

00:16:59,320 --> 00:17:02,680
more popular sites or it might be

00:17:01,060 --> 00:17:04,390
because there's just a lot of noise in

00:17:02,680 --> 00:17:06,790
the long tail and we haven't quite time

00:17:04,390 --> 00:17:10,179
to depart all of that yet and then

00:17:06,790 --> 00:17:12,429
lastly you know similar to the critique

00:17:10,179 --> 00:17:14,949
of heuristics as being available the

00:17:12,429 --> 00:17:16,839
current my current strategy for

00:17:14,949 --> 00:17:19,720
generating my features relies on the

00:17:16,839 --> 00:17:23,140
structure of a script and that will also

00:17:19,720 --> 00:17:24,939
be subject to evasion and and is

00:17:23,140 --> 00:17:27,339
inherently noisy like scripts can

00:17:24,939 --> 00:17:28,360
reorganize their code in in a variety of

00:17:27,339 --> 00:17:30,220
different ways and so there's a

00:17:28,360 --> 00:17:32,050
challenge there and I've been thinking

00:17:30,220 --> 00:17:33,820
about things like information flow or I

00:17:32,050 --> 00:17:35,800
was talking earlier about the tenth

00:17:33,820 --> 00:17:38,320
thing that maybe is a new way to sort of

00:17:35,800 --> 00:17:39,510
pull out the right thread of scripts

00:17:38,320 --> 00:17:42,539
that we care about

00:17:39,510 --> 00:17:45,600
seeing and so some of the things that

00:17:42,539 --> 00:17:47,700
I'm looking at at the moment which I

00:17:45,600 --> 00:17:49,470
would love to have a conversation get

00:17:47,700 --> 00:17:53,309
feedback any ideas increasing my

00:17:49,470 --> 00:17:55,639
labeling precision more automatic

00:17:53,309 --> 00:17:59,610
threshold in a metric experimentation

00:17:55,639 --> 00:18:01,980
combining my combining the output of

00:17:59,610 --> 00:18:03,600
this work with other features and one of

00:18:01,980 --> 00:18:05,700
the things that's nice about only taking

00:18:03,600 --> 00:18:07,559
that very one basically one column of

00:18:05,700 --> 00:18:09,059
data is there's lots of other data that

00:18:07,559 --> 00:18:11,250
ends up being independent and so you

00:18:09,059 --> 00:18:13,679
could really combine together different

00:18:11,250 --> 00:18:15,330
pieces of information and to generate a

00:18:13,679 --> 00:18:18,210
better answer and that's something we're

00:18:15,330 --> 00:18:19,889
working on imminently negative labeling

00:18:18,210 --> 00:18:22,080
so marking acceptable scripts say

00:18:19,889 --> 00:18:24,630
charting libraries but that presents its

00:18:22,080 --> 00:18:28,250
whole own other labeling challenge just

00:18:24,630 --> 00:18:31,289
in the opposite direction using results

00:18:28,250 --> 00:18:32,690
and then a sort of separate thing that

00:18:31,289 --> 00:18:35,250
isn't necessarily so much about

00:18:32,690 --> 00:18:36,899
improving the methodology but how can we

00:18:35,250 --> 00:18:38,820
take the results of this methodology and

00:18:36,899 --> 00:18:41,370
use them to help build heuristics for

00:18:38,820 --> 00:18:42,659
the kind of for the tech for the browser

00:18:41,370 --> 00:18:43,769
fingerprinting techniques that we know

00:18:42,659 --> 00:18:46,889
are happening but we don't yet have

00:18:43,769 --> 00:18:49,260
heuristics for and then last but not

00:18:46,889 --> 00:18:51,690
least anything to make the script review

00:18:49,260 --> 00:18:53,940
process or performance assessment less

00:18:51,690 --> 00:18:56,250
painful than the manual process that it

00:18:53,940 --> 00:18:58,260
currently is and if all of that wasn't

00:18:56,250 --> 00:19:01,320
enough questions for you there were also

00:18:58,260 --> 00:19:02,909
questions on the challenges associated

00:19:01,320 --> 00:19:06,419
with doing crawl as your data collection

00:19:02,909 --> 00:19:09,929
methodology the challenges associated

00:19:06,419 --> 00:19:12,090
with evaluating intent and then the

00:19:09,929 --> 00:19:14,399
challenges associated with deployment so

00:19:12,090 --> 00:19:16,019
we have taken this list based approach

00:19:14,399 --> 00:19:18,179
and that has lots of pros as Steve

00:19:16,019 --> 00:19:19,620
articulated earlier but it also has some

00:19:18,179 --> 00:19:21,240
challenges associated with it and

00:19:19,620 --> 00:19:23,399
Christoph started to get into the some

00:19:21,240 --> 00:19:25,620
of the challenges of block lists and

00:19:23,399 --> 00:19:26,850
along with deployment is that's when you

00:19:25,620 --> 00:19:28,260
start thinking about well how do we

00:19:26,850 --> 00:19:29,580
measure how well we've done how much of

00:19:28,260 --> 00:19:31,529
the web are we breaking and so there's a

00:19:29,580 --> 00:19:34,049
whole other separate question about web

00:19:31,529 --> 00:19:35,159
breakage so thank you for your time I

00:19:34,049 --> 00:19:36,690
hope some of these questions have

00:19:35,159 --> 00:19:39,260
sparked interest and I would love to

00:19:36,690 --> 00:19:39,260
talk to you about them

00:19:39,520 --> 00:19:44,619

YouTube URL: https://www.youtube.com/watch?v=qFWPTeDSJn4


