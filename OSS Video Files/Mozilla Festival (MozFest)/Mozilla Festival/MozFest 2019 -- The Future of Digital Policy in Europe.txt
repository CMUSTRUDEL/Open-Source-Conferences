Title: MozFest 2019 -- The Future of Digital Policy in Europe
Publication date: 2020-09-29
Playlist: Mozilla Festival
Description: 
	What comes after the GDPR?

Prabhat Agarwal 
Deputy Head of Platforms Unit at European Commission

Katarzyna Szymielewicz
Co-Founder and President of Panoptykon Foundation

Guillermo Beltrà
Guillermo Beltrà leads Access Now’s policy team globally, providing strategic vision, guiding and coordinating the operations of experts in Latin America, North America, Europe, Middle East and North Africa, and Asia-Pacific.
Captions: 
	00:00:00,060 --> 00:00:06,420
next up is the future of digital private

00:00:03,000 --> 00:00:12,780
put digital policy in Europe panel I'll

00:00:06,420 --> 00:00:15,780
be joined by three panelists soon the

00:00:12,780 --> 00:00:17,850
panelists here not here they are alright

00:00:15,780 --> 00:00:26,779
give a big hand for Casa Jana Guillermo

00:00:17,850 --> 00:00:40,290
and prop hot there they are

00:00:26,779 --> 00:00:41,910
do you guys see help ok Hey all right so

00:00:40,290 --> 00:00:44,489
a little bit of introductions

00:00:41,910 --> 00:00:46,980
I'll start ladies first cartagena show

00:00:44,489 --> 00:00:49,379
miele vich co-founder and president of

00:00:46,980 --> 00:00:50,879
the panopticon foundation lawyer and

00:00:49,379 --> 00:00:53,010
activist specializing in human rights

00:00:50,879 --> 00:00:54,090
and technology and you might recognize

00:00:53,010 --> 00:00:57,270
her from the talk she was part of

00:00:54,090 --> 00:00:58,100
yesterday and kasha for short right ok

00:00:57,270 --> 00:01:01,680
that's cool

00:00:58,100 --> 00:01:03,270
prob hot Aggarwal prophet's been with

00:01:01,680 --> 00:01:06,180
the european commission for the last 12

00:01:03,270 --> 00:01:08,670
years now doing online platforms and

00:01:06,180 --> 00:01:10,740
e-commerce he's a policy maker the EU

00:01:08,670 --> 00:01:13,170
commission dealing with regulating

00:01:10,740 --> 00:01:16,110
platforms and you have a tech background

00:01:13,170 --> 00:01:20,729
he studies physics computer science etc

00:01:16,110 --> 00:01:23,040
etc it's like a long resume and then we

00:01:20,729 --> 00:01:25,009
have Guillermo Beltran Guillermo is a

00:01:23,040 --> 00:01:27,390
global policy director at access now

00:01:25,009 --> 00:01:29,000
global NGO working to defend human

00:01:27,390 --> 00:01:32,100
rights for users at risk

00:01:29,000 --> 00:01:34,110
so thank you for joining me today I want

00:01:32,100 --> 00:01:37,310
to talk about digital policy in Europe

00:01:34,110 --> 00:01:40,079
but just the kind of level set and start

00:01:37,310 --> 00:01:42,390
GDP are went into effect about a year

00:01:40,079 --> 00:01:45,000
and a half ago what do you think we've

00:01:42,390 --> 00:01:46,680
learned since which parts are working in

00:01:45,000 --> 00:01:54,659
which parts are not working anyone can

00:01:46,680 --> 00:01:56,759
start yeah you wanted to so I think like

00:01:54,659 --> 00:01:58,799
I don't want to go into the details of

00:01:56,759 --> 00:02:01,020
kind of which part because there's a

00:01:58,799 --> 00:02:02,790
huge piece of law and let me just zoom

00:02:01,020 --> 00:02:04,560
out on kind of a couple of things what

00:02:02,790 --> 00:02:06,930
would work and what don't work you know

00:02:04,560 --> 00:02:09,539
of course I get annoyed like many people

00:02:06,930 --> 00:02:11,610
clicking away my cookie consent forms

00:02:09,539 --> 00:02:13,740
but I think that that kind of distracts

00:02:11,610 --> 00:02:15,960
from the real issue I think that the

00:02:13,740 --> 00:02:18,600
what's really impressive is that I think

00:02:15,960 --> 00:02:22,770
gdpr has really been a game changer in

00:02:18,600 --> 00:02:25,290
kind of how we see tech policy and tech

00:02:22,770 --> 00:02:26,880
regulation you know taking an issue

00:02:25,290 --> 00:02:28,500
which is a fundamental rights issue you

00:02:26,880 --> 00:02:31,680
know and taking putting a frame around

00:02:28,500 --> 00:02:34,290
it and what I think has been really

00:02:31,680 --> 00:02:36,360
surprising is that I've been kind of

00:02:34,290 --> 00:02:38,520
part of this from the beginning but from

00:02:36,360 --> 00:02:40,440
a slight distance because this is like a

00:02:38,520 --> 00:02:42,450
data protection issue dealt with by

00:02:40,440 --> 00:02:44,130
another team but the way that we've

00:02:42,450 --> 00:02:45,660
turned had at 80 degrees from something

00:02:44,130 --> 00:02:47,670
that was completely crazy completely

00:02:45,660 --> 00:02:50,370
impossible it would never work we'd

00:02:47,670 --> 00:02:51,840
destroy the internet to something where

00:02:50,370 --> 00:02:55,320
a lot of people say wow you know this is

00:02:51,840 --> 00:02:57,180
like a really powerful framework for

00:02:55,320 --> 00:02:59,220
protecting user right and and you know

00:02:57,180 --> 00:03:01,710
lots of people are saying we want to we

00:02:59,220 --> 00:03:03,870
want to now copy this at least in part

00:03:01,710 --> 00:03:06,600
you know around the world and and I

00:03:03,870 --> 00:03:08,700
think that's been really a learning

00:03:06,600 --> 00:03:11,640
experience where that has informed my

00:03:08,700 --> 00:03:13,500
some of my thinking okay so you know

00:03:11,640 --> 00:03:15,360
some of the some of the things that are

00:03:13,500 --> 00:03:17,520
still kind of settling in right now you

00:03:15,360 --> 00:03:19,560
know because it's it's relatively recent

00:03:17,520 --> 00:03:21,330
so it's a lot of emphasis now is

00:03:19,560 --> 00:03:22,830
shifting away from the actual meaning of

00:03:21,330 --> 00:03:25,020
the rules and how they apply not to

00:03:22,830 --> 00:03:26,910
enforcing those you know like so we we

00:03:25,020 --> 00:03:28,770
see cases being geared up by data

00:03:26,910 --> 00:03:31,080
protection authorities in in Member

00:03:28,770 --> 00:03:33,210
States we see the global conversation

00:03:31,080 --> 00:03:35,810
around from data protection and privacy

00:03:33,210 --> 00:03:38,070
changing so those are really the the

00:03:35,810 --> 00:03:40,110
game-changing positive elements I think

00:03:38,070 --> 00:03:42,150
then some of the negative elements that

00:03:40,110 --> 00:03:44,100
I think people are annoyed about is the

00:03:42,150 --> 00:03:45,630
kind of banner clicking but let's not

00:03:44,100 --> 00:03:47,610
forget that there's also a previously

00:03:45,630 --> 00:03:49,410
regulation that was still being

00:03:47,610 --> 00:03:51,660
negotiated I'm still hoping that it'll

00:03:49,410 --> 00:03:53,820
be adopted soon that at least in parts

00:03:51,660 --> 00:03:56,100
of some of the issues you know but more

00:03:53,820 --> 00:03:58,140
by in general people are much more aware

00:03:56,100 --> 00:04:00,030
of privacy issues around the internet

00:03:58,140 --> 00:04:02,160
than just even a couple of years ago

00:04:00,030 --> 00:04:03,780
people are taking much more seriously

00:04:02,160 --> 00:04:06,000
it's conversation in schools it's

00:04:03,780 --> 00:04:07,650
conversation not only in some offices in

00:04:06,000 --> 00:04:09,540
Brussels but it's a conversations

00:04:07,650 --> 00:04:12,600
worldwide I think that's really my take

00:04:09,540 --> 00:04:15,180
away from what has happened right yeah I

00:04:12,600 --> 00:04:17,160
think I agree politically it's a success

00:04:15,180 --> 00:04:18,750
in the sense that it has sparked this

00:04:17,160 --> 00:04:20,280
global conversation about the importance

00:04:18,750 --> 00:04:22,470
of privacy and data protection we've

00:04:20,280 --> 00:04:23,970
seen a 10% increase in countries that

00:04:22,470 --> 00:04:26,570
have actually adopted new data

00:04:23,970 --> 00:04:28,460
protection frameworks that are completed

00:04:26,570 --> 00:04:30,890
and there's like 30 other countries

00:04:28,460 --> 00:04:33,530
around the world that are now working on

00:04:30,890 --> 00:04:36,980
their new data protection frameworks so

00:04:33,530 --> 00:04:41,930
I was thinking so I agree the main

00:04:36,980 --> 00:04:43,670
objective of the gdpr is to put some

00:04:41,930 --> 00:04:45,830
legal structure on the protection of a

00:04:43,670 --> 00:04:46,940
fundamental right in Europe and it's

00:04:45,830 --> 00:04:49,070
important to remember that it's

00:04:46,940 --> 00:04:51,770
everything that's in gdpr is not new

00:04:49,070 --> 00:04:53,780
actually not many things are new it's

00:04:51,770 --> 00:04:56,000
just bringing an old data protection law

00:04:53,780 --> 00:04:57,290
in to kind of more the modern area and

00:04:56,000 --> 00:04:59,660
putting some obligations and some

00:04:57,290 --> 00:05:01,310
enforcement measures on top of it but I

00:04:59,660 --> 00:05:04,100
was thinking earlier in the panel you

00:05:01,310 --> 00:05:06,200
guys had on governing AI about how do

00:05:04,100 --> 00:05:08,000
you regulate the market like how do you

00:05:06,200 --> 00:05:09,980
tell the market where a market in that

00:05:08,000 --> 00:05:12,410
case it was AI but here is like more the

00:05:09,980 --> 00:05:14,180
digital space where do you want it to go

00:05:12,410 --> 00:05:15,950
and that I think is that the GD P R is a

00:05:14,180 --> 00:05:17,360
good public policy tool because in

00:05:15,950 --> 00:05:18,920
addition to protecting a fundamental

00:05:17,360 --> 00:05:20,210
right you're telling the market that's

00:05:18,920 --> 00:05:24,560
the direction I want you guys to

00:05:20,210 --> 00:05:26,540
innovate towards and to sink towards and

00:05:24,560 --> 00:05:29,000
in that sense that is it is being a

00:05:26,540 --> 00:05:31,400
success all that said like privada said

00:05:29,000 --> 00:05:32,900
it's way too soon it was it only entered

00:05:31,400 --> 00:05:34,640
into force about a year and a half ago

00:05:32,900 --> 00:05:37,160
they're still Slovenia and Greece have

00:05:34,640 --> 00:05:39,800
not developed their own implementing

00:05:37,160 --> 00:05:42,650
laws nationally data protection

00:05:39,800 --> 00:05:44,990
authorities don't have are way far from

00:05:42,650 --> 00:05:46,520
having sufficient resources to go police

00:05:44,990 --> 00:05:48,950
everything that they have to go police

00:05:46,520 --> 00:05:50,060
so we're happy where things are going

00:05:48,950 --> 00:05:53,300
but there's a lot of work to be done

00:05:50,060 --> 00:05:54,590
still yeah I fully agree it's a bit too

00:05:53,300 --> 00:05:55,940
early I think we need at least three

00:05:54,590 --> 00:05:58,910
more years to see the enforcement

00:05:55,940 --> 00:06:01,040
measures at full speed what was the

00:05:58,910 --> 00:06:04,820
biggest victory in this beer is that the

00:06:01,040 --> 00:06:06,860
old rules existing for two decades a got

00:06:04,820 --> 00:06:09,350
extended globally because they finally

00:06:06,860 --> 00:06:11,990
are used successfully against global

00:06:09,350 --> 00:06:13,400
companies who target European citizens

00:06:11,990 --> 00:06:16,640
with their services and that was in the

00:06:13,400 --> 00:06:19,220
case before and B we have money is in

00:06:16,640 --> 00:06:20,630
place financial huge financial fines are

00:06:19,220 --> 00:06:23,300
in place and that's the conversation

00:06:20,630 --> 00:06:25,430
starter or dough door opener for the EU

00:06:23,300 --> 00:06:27,560
to start negotiating the standards

00:06:25,430 --> 00:06:29,570
really but where it gets difficult is

00:06:27,560 --> 00:06:32,660
this moment where we realize the GDP R

00:06:29,570 --> 00:06:35,090
is proposing very sound rules for old

00:06:32,660 --> 00:06:37,130
business models that are in fundamental

00:06:35,090 --> 00:06:38,960
conflict with these rules so if you

00:06:37,130 --> 00:06:43,910
think about cookies or

00:06:38,960 --> 00:06:46,580
pop-ups I mean no no we can't imagine

00:06:43,910 --> 00:06:48,620
the amount of popups necessary to to to

00:06:46,580 --> 00:06:49,849
fulfill the they need to inform people

00:06:48,620 --> 00:06:51,710
about what's going on with your data

00:06:49,849 --> 00:06:54,259
behind the screen that's not the

00:06:51,710 --> 00:06:56,389
solution we have to remove the dentists

00:06:54,259 --> 00:06:58,190
we have to end the data transfers

00:06:56,389 --> 00:07:01,460
happening behind the screen rather than

00:06:58,190 --> 00:07:03,590
try to clean them or legalize them with

00:07:01,460 --> 00:07:05,060
pop-ups or any measures of that sort and

00:07:03,590 --> 00:07:07,520
this is what it gets difficult because

00:07:05,060 --> 00:07:10,340
at some at some point enforcement of the

00:07:07,520 --> 00:07:11,990
DPR will have to mean that we cancel

00:07:10,340 --> 00:07:13,910
some of the business models we simply

00:07:11,990 --> 00:07:15,620
delete them like the whole architect

00:07:13,910 --> 00:07:17,570
business model the advertising

00:07:15,620 --> 00:07:19,610
technology developed in a way that can

00:07:17,570 --> 00:07:22,789
not be rocked and reconciled with GDP

00:07:19,610 --> 00:07:24,560
are no pop up we'll clean it so we have

00:07:22,789 --> 00:07:26,419
to face it and that's the difficult part

00:07:24,560 --> 00:07:28,490
because even for the deputation

00:07:26,419 --> 00:07:30,740
authorities today it is a bit hard to

00:07:28,490 --> 00:07:32,750
say okay that branch of the industry has

00:07:30,740 --> 00:07:35,150
to disappear because it's not in line

00:07:32,750 --> 00:07:37,220
with our principles that's the heart the

00:07:35,150 --> 00:07:38,780
heartbeat gosh you guys you and profit

00:07:37,220 --> 00:07:40,220
brought the cookie pop this is a hot

00:07:38,780 --> 00:07:41,449
button issue backstage when we were

00:07:40,220 --> 00:07:43,909
talking about when you go to a website

00:07:41,449 --> 00:07:45,650
it says hey we are asking to save

00:07:43,909 --> 00:07:48,199
cookies on your computer is that okay

00:07:45,650 --> 00:07:48,409
look I get that pop up still 50 times a

00:07:48,199 --> 00:07:50,570
day

00:07:48,409 --> 00:07:53,870
but Guillermo when I mentioned that you

00:07:50,570 --> 00:07:56,150
said don't blame the sites for that pop

00:07:53,870 --> 00:07:58,729
of like who's that blame for that

00:07:56,150 --> 00:08:00,500
annoyance or that no a bad thing or the

00:07:58,729 --> 00:08:02,719
law like what's important to recognize

00:08:00,500 --> 00:08:05,020
is that nobody is forcing those

00:08:02,719 --> 00:08:08,360
advertising networks to do those complex

00:08:05,020 --> 00:08:12,530
cookie-cookie pop-ups or consent notices

00:08:08,360 --> 00:08:14,360
via email that way at all and to cassius

00:08:12,530 --> 00:08:16,580
point nobody's forcing them to have that

00:08:14,360 --> 00:08:18,979
business model where it's all based on

00:08:16,580 --> 00:08:22,400
tracking every single one of us every

00:08:18,979 --> 00:08:26,180
single click we do around the web so the

00:08:22,400 --> 00:08:28,400
whole the whole point is a how do we not

00:08:26,180 --> 00:08:30,440
the market out of that business model

00:08:28,400 --> 00:08:34,490
fully agreed in to one that is much more

00:08:30,440 --> 00:08:36,709
privacy friendly but also remember that

00:08:34,490 --> 00:08:38,240
the gdpr is not the only legislative

00:08:36,709 --> 00:08:39,740
tool that Europe has in any question

00:08:38,240 --> 00:08:41,209
Prabhat has just mentioned the privacy

00:08:39,740 --> 00:08:42,890
regulation this goes hand-in-hand with

00:08:41,209 --> 00:08:46,610
the GDP our and it's not complete yet

00:08:42,890 --> 00:08:48,980
and it's there where the EU is trying to

00:08:46,610 --> 00:08:51,079
give some rules out there to users and

00:08:48,980 --> 00:08:52,970
to and to market actors about how to

00:08:51,079 --> 00:08:55,610
deal with for example browsers

00:08:52,970 --> 00:08:58,310
things and kind of the settings on the

00:08:55,610 --> 00:09:00,560
devices on what on what companies can

00:08:58,310 --> 00:09:02,480
and cannot do with our own personal data

00:09:00,560 --> 00:09:07,879
and with our devices and unfortunately

00:09:02,480 --> 00:09:10,189
that legislative file is stuck yeah just

00:09:07,879 --> 00:09:12,259
maybe just a side comment I think that

00:09:10,189 --> 00:09:13,370
you know one thing is kind of to focus

00:09:12,259 --> 00:09:14,600
on the kind of friction and the

00:09:13,370 --> 00:09:16,759
annoyance you know and the other thing

00:09:14,600 --> 00:09:18,050
is to kind of thumb see it turn it

00:09:16,759 --> 00:09:20,750
around a little bit and say that

00:09:18,050 --> 00:09:23,360
actually you know that bit of friction

00:09:20,750 --> 00:09:26,360
is making a parent it's surfacing

00:09:23,360 --> 00:09:29,029
something that has been kind of been

00:09:26,360 --> 00:09:30,500
hiding you know like a and and so you

00:09:29,029 --> 00:09:33,350
know it feels a little bit like kind of

00:09:30,500 --> 00:09:35,959
you know there's a kind of bump under

00:09:33,350 --> 00:09:37,759
the carpet and before it you couldn't

00:09:35,959 --> 00:09:39,290
really feel the bump right and the and

00:09:37,759 --> 00:09:40,850
now you kind of say hi there's a funny

00:09:39,290 --> 00:09:42,199
bump under the carpet what's going on

00:09:40,850 --> 00:09:43,939
and you kind of look under the carpet

00:09:42,199 --> 00:09:45,680
and you see all these this whole

00:09:43,939 --> 00:09:48,439
tracking business that's going on right

00:09:45,680 --> 00:09:50,149
and and and so of course the bump is

00:09:48,439 --> 00:09:51,620
uncomfortable and you know I'm be much

00:09:50,149 --> 00:09:52,819
nicer if the bumper went there you know

00:09:51,620 --> 00:09:54,259
but actually it's worth looking under

00:09:52,819 --> 00:09:57,019
the carpet and to see what's going on

00:09:54,259 --> 00:09:58,879
there you know and I think that so we

00:09:57,019 --> 00:10:01,100
would you know we have regulated and

00:09:58,879 --> 00:10:02,689
made proposals for making the bump a bit

00:10:01,100 --> 00:10:04,459
more smoother it's just what we mo said

00:10:02,689 --> 00:10:08,059
and let's see what the future of that

00:10:04,459 --> 00:10:08,689
file a holes but I think besides ironing

00:10:08,059 --> 00:10:10,160
out the bump

00:10:08,689 --> 00:10:11,360
let's take a look under the carpet you

00:10:10,160 --> 00:10:13,220
know and let's do let's have a look

00:10:11,360 --> 00:10:14,779
what's actually going on there and and

00:10:13,220 --> 00:10:17,029
there's something that we'll be we'll be

00:10:14,779 --> 00:10:19,100
focusing on in the next in the next

00:10:17,029 --> 00:10:21,259
couple of months and years to come you

00:10:19,100 --> 00:10:24,290
know to take a to shine a light a little

00:10:21,259 --> 00:10:27,139
bit on on on exactly a very complex kind

00:10:24,290 --> 00:10:30,439
of industry and a kind of complex

00:10:27,139 --> 00:10:33,889
service which is you know I think I you

00:10:30,439 --> 00:10:35,029
know it's I'm not really I'm agnostic at

00:10:33,889 --> 00:10:36,680
this particular point where there's

00:10:35,029 --> 00:10:39,139
something that like Kasia said we know

00:10:36,680 --> 00:10:40,519
we need to kind of be tough on on that

00:10:39,139 --> 00:10:42,350
you know I'm also conscious that

00:10:40,519 --> 00:10:44,329
actually some of this is cross financing

00:10:42,350 --> 00:10:46,519
free services and there's the huge

00:10:44,329 --> 00:10:48,470
expectation of cons consumers to kind of

00:10:46,519 --> 00:10:51,079
consume content for free on on the web

00:10:48,470 --> 00:10:53,360
so my offer step is gonna be just to

00:10:51,079 --> 00:10:55,610
take a look you know actually and and

00:10:53,360 --> 00:10:58,519
and take it take a look with open mind

00:10:55,610 --> 00:11:00,319
at a very complex in area what we do

00:10:58,519 --> 00:11:01,579
know though from some behavioral

00:11:00,319 --> 00:11:04,130
research that we've been doing and

00:11:01,579 --> 00:11:05,689
commissioning is that when you talk to

00:11:04,130 --> 00:11:06,180
users the first time you talk to users

00:11:05,689 --> 00:11:07,050
and

00:11:06,180 --> 00:11:08,220
say hey what do you think about

00:11:07,050 --> 00:11:10,170
targeting what do you think about

00:11:08,220 --> 00:11:11,610
recommender systems and so on you know

00:11:10,170 --> 00:11:13,410
first time they say yeah this is really

00:11:11,610 --> 00:11:15,450
good stuff you know like the I get what

00:11:13,410 --> 00:11:16,980
I want you know and then you iterate and

00:11:15,450 --> 00:11:19,320
you explain hey do you know how they get

00:11:16,980 --> 00:11:21,180
to know how to target you and I said I

00:11:19,320 --> 00:11:23,520
didn't know and then the second a second

00:11:21,180 --> 00:11:24,899
iteration they said maybe I'm it's not

00:11:23,520 --> 00:11:26,459
such a great idea you know if you

00:11:24,899 --> 00:11:28,800
iterate once more you know when people

00:11:26,459 --> 00:11:30,779
can swing their views on on on whether

00:11:28,800 --> 00:11:32,339
they like what's going on quite a lot

00:11:30,779 --> 00:11:34,140
you know and I think that process of

00:11:32,339 --> 00:11:36,600
discussion is really something that we

00:11:34,140 --> 00:11:38,130
need to have now again rather than being

00:11:36,600 --> 00:11:39,690
stuck on just the annoyance

00:11:38,130 --> 00:11:43,290
knowing banners that we see you know

00:11:39,690 --> 00:11:44,520
which I find annoying to you just maybe

00:11:43,290 --> 00:11:46,200
did the bottom line in the existing

00:11:44,520 --> 00:11:48,330
system is that people are on one hand

00:11:46,200 --> 00:11:49,740
observed constantly beyond day awareness

00:11:48,330 --> 00:11:52,680
on the other they get constantly

00:11:49,740 --> 00:11:55,860
targeted so that's a deeply unfair

00:11:52,680 --> 00:11:57,870
setting in which our users operate and

00:11:55,860 --> 00:12:00,029
we cannot fix the system by adding more

00:11:57,870 --> 00:12:00,480
trust or more transparency or another

00:12:00,029 --> 00:12:02,910
pop-up

00:12:00,480 --> 00:12:04,529
it's just unfixable that way we have to

00:12:02,910 --> 00:12:06,360
rebuild it and that's why I'm saying

00:12:04,529 --> 00:12:08,959
that some business models will have to

00:12:06,360 --> 00:12:11,490
go away because they're fundamentally

00:12:08,959 --> 00:12:13,860
they cannot be aligned with the

00:12:11,490 --> 00:12:17,160
principles of trust transparency choice

00:12:13,860 --> 00:12:18,600
that we built in the European law it's

00:12:17,160 --> 00:12:20,970
like we've ecology you know we can

00:12:18,600 --> 00:12:22,560
discuss how to deal with waste and how

00:12:20,970 --> 00:12:24,690
to recycle but wouldn't be better to

00:12:22,560 --> 00:12:27,209
produce less waste or you know remove

00:12:24,690 --> 00:12:29,220
from the waste culture which we and we

00:12:27,209 --> 00:12:30,750
are embedded in that's exactly the same

00:12:29,220 --> 00:12:33,330
challenge we face in the digital

00:12:30,750 --> 00:12:35,520
ecosystem just two quick thoughts

00:12:33,330 --> 00:12:36,870
actually on all of this one is first of

00:12:35,520 --> 00:12:38,610
all it's very encouraging to hear that

00:12:36,870 --> 00:12:40,230
an important regulator like the European

00:12:38,610 --> 00:12:42,330
Commission is not willing to lift up the

00:12:40,230 --> 00:12:44,520
carpet and look underneath because many

00:12:42,330 --> 00:12:46,680
groups like ours we've been kind of some

00:12:44,520 --> 00:12:49,040
way that alarm bell for 10 15 years

00:12:46,680 --> 00:12:52,170
there's like this carbon metaphors

00:12:49,040 --> 00:12:54,000
there's that there's been or there was

00:12:52,170 --> 00:12:55,709
an ongoing global conversation about

00:12:54,000 --> 00:12:57,360
this whole do-not-track standard and

00:12:55,709 --> 00:12:59,160
when that failed we at least in Europe

00:12:57,360 --> 00:13:01,440
were saying well then we gotta find at

00:12:59,160 --> 00:13:03,480
least a European solution because try

00:13:01,440 --> 00:13:05,850
tracking online tracking cannot become

00:13:03,480 --> 00:13:07,290
their just a main business model

00:13:05,850 --> 00:13:09,300
everywhere and it has and it's bigger

00:13:07,290 --> 00:13:11,459
and bigger so how to keep that under

00:13:09,300 --> 00:13:13,470
control so it's great that the European

00:13:11,459 --> 00:13:18,930
Commission now has that approach but

00:13:13,470 --> 00:13:19,980
also the gdpr has important principles

00:13:18,930 --> 00:13:21,870
so it I'm coming back to the

00:13:19,980 --> 00:13:24,180
question enforcement as well we have a

00:13:21,870 --> 00:13:27,270
lot of rules but not a lot of resources

00:13:24,180 --> 00:13:29,130
and time yet to actually go enforce them

00:13:27,270 --> 00:13:30,930
so for example privacy by design and by

00:13:29,130 --> 00:13:33,780
default are two very important

00:13:30,930 --> 00:13:35,400
principles that I bet you anything

00:13:33,780 --> 00:13:38,010
all these ad networks are not complying

00:13:35,400 --> 00:13:40,410
with if it came to to a court to have to

00:13:38,010 --> 00:13:43,020
rule on that so there are already tools

00:13:40,410 --> 00:13:45,330
that we have to start using to iron out

00:13:43,020 --> 00:13:47,010
that carpet and get all those business

00:13:45,330 --> 00:13:48,990
models that are not compatible with

00:13:47,010 --> 00:13:50,940
fundamental rights out the door yeah I

00:13:48,990 --> 00:13:54,510
this may be wrong but sometimes it feels

00:13:50,940 --> 00:13:56,370
like the the EU is more concerned with

00:13:54,510 --> 00:13:58,410
lifting up that carpet than the US

00:13:56,370 --> 00:14:01,980
government is that true or is that not

00:13:58,410 --> 00:14:04,320
accurate I mean I take your PIN

00:14:01,980 --> 00:14:06,510
perspective I'm looking at what FTC does

00:14:04,320 --> 00:14:08,160
and what European what US based

00:14:06,510 --> 00:14:09,960
politicians like I said warrants say

00:14:08,160 --> 00:14:12,750
from your perspective so I actually see

00:14:09,960 --> 00:14:13,200
quite radical headlines coming from the

00:14:12,750 --> 00:14:14,870
US

00:14:13,200 --> 00:14:17,550
I also remember from two years ago

00:14:14,870 --> 00:14:19,730
us-based researchers that and advocates

00:14:17,550 --> 00:14:23,040
coming to see PTP our annual

00:14:19,730 --> 00:14:25,920
brussels-based conference on privacy

00:14:23,040 --> 00:14:28,260
with this break them up banner and I

00:14:25,920 --> 00:14:30,480
follow up well welcome guys like finally

00:14:28,260 --> 00:14:33,080
somebody's saying this really forceful

00:14:30,480 --> 00:14:34,350
way really open so from my perspective

00:14:33,080 --> 00:14:37,890
us-based

00:14:34,350 --> 00:14:40,440
entities and and public and he's like

00:14:37,890 --> 00:14:42,750
FTC are actually using forceful measures

00:14:40,440 --> 00:14:44,340
like financial fines for quite a while

00:14:42,750 --> 00:14:46,230
against these companies and I believe

00:14:44,340 --> 00:14:48,600
they already got to the wall to the

00:14:46,230 --> 00:14:50,520
point where they see that structural

00:14:48,600 --> 00:14:52,530
measures like breaking them up are

00:14:50,520 --> 00:14:54,540
necessary because financial fines

00:14:52,530 --> 00:14:56,430
clearly don't work so maybe they haven't

00:14:54,540 --> 00:14:58,350
came up with privacy protective

00:14:56,430 --> 00:15:01,440
regulation yet it's only now happening

00:14:58,350 --> 00:15:03,720
but before us they started using anti

00:15:01,440 --> 00:15:05,340
Pro competition measures against these

00:15:03,720 --> 00:15:07,380
big platforms because they had them at

00:15:05,340 --> 00:15:10,140
home and maybe they were the first to

00:15:07,380 --> 00:15:12,120
see targeting risks or manipulation of

00:15:10,140 --> 00:15:14,610
public debate risks because they had a

00:15:12,120 --> 00:15:17,430
lot of these business going on before we

00:15:14,610 --> 00:15:19,530
saw it at full scale in Europe will say

00:15:17,430 --> 00:15:21,570
brexit campaign so I wouldn't be that

00:15:19,530 --> 00:15:23,160
critical I think a lot of interesting

00:15:21,570 --> 00:15:25,380
ideas are coming from the other side of

00:15:23,160 --> 00:15:26,790
the Atlantic as well what do you guys

00:15:25,380 --> 00:15:28,020
think do you feel like GDP are loosing

00:15:26,790 --> 00:15:30,650
the jar and then the u.s. is kind of

00:15:28,020 --> 00:15:33,860
like oh yeah as to like do you think

00:15:30,650 --> 00:15:35,600
yeah I think that so first of all this

00:15:33,860 --> 00:15:36,710
is what I meant earlier you know in the

00:15:35,600 --> 00:15:38,720
conversation the global conversation

00:15:36,710 --> 00:15:41,390
around regulating tech has of course

00:15:38,720 --> 00:15:43,280
changed you know that's part so part of

00:15:41,390 --> 00:15:45,080
it is that in general the tech lash kind

00:15:43,280 --> 00:15:47,570
of phenomenon and the other one is that

00:15:45,080 --> 00:15:49,400
that that you know people are looking

00:15:47,570 --> 00:15:51,500
all over the world about you know kind

00:15:49,400 --> 00:15:54,740
of similar issues you know whether it's

00:15:51,500 --> 00:15:56,450
data protection or content moderation or

00:15:54,740 --> 00:15:58,280
you know if what happened after the

00:15:56,450 --> 00:16:00,260
Christchurch incident was a kind of

00:15:58,280 --> 00:16:01,460
example where kind of governments saying

00:16:00,260 --> 00:16:03,560
hey what are you gonna do about it kind

00:16:01,460 --> 00:16:07,100
of just watch going watch this happening

00:16:03,560 --> 00:16:08,660
I just warned wanted a warning and maybe

00:16:07,100 --> 00:16:10,190
that's a bit weird from the European

00:16:08,660 --> 00:16:12,290
Commission to say that but you know the

00:16:10,190 --> 00:16:13,970
quantity of of regulation is not

00:16:12,290 --> 00:16:16,370
necessarily a good indicator you know of

00:16:13,970 --> 00:16:18,380
success you know it is it's you know we

00:16:16,370 --> 00:16:19,640
see the Russian internet law is about to

00:16:18,380 --> 00:16:21,350
come in force on the first of November

00:16:19,640 --> 00:16:23,180
you know and we really have quite

00:16:21,350 --> 00:16:24,890
serious concerns about that you know so

00:16:23,180 --> 00:16:27,650
it's not just whether you are a like a

00:16:24,890 --> 00:16:29,210
regulating the net and how many laws

00:16:27,650 --> 00:16:33,170
you've got and got there you know it's

00:16:29,210 --> 00:16:35,810
really about finding you know a good

00:16:33,170 --> 00:16:38,270
operable framework that gives market

00:16:35,810 --> 00:16:39,440
press its participants clarity that

00:16:38,270 --> 00:16:41,210
protects from the mental rights and

00:16:39,440 --> 00:16:43,100
users rights you know and that that

00:16:41,210 --> 00:16:45,590
meets kind of legitimate well specified

00:16:43,100 --> 00:16:47,480
policy aims and and that's that's really

00:16:45,590 --> 00:16:49,340
kind of what we should be looking at you

00:16:47,480 --> 00:16:51,490
know not not really the amount of

00:16:49,340 --> 00:16:54,770
regulation there's no shortage of

00:16:51,490 --> 00:16:56,840
appetite particularly in in less free

00:16:54,770 --> 00:16:58,220
countries to regulate the internet you

00:16:56,840 --> 00:16:59,660
know so let's not forget that you know

00:16:58,220 --> 00:17:02,810
like this should not be the only

00:16:59,660 --> 00:17:04,790
yardstick that we that we apply you know

00:17:02,810 --> 00:17:06,140
whether we what the yardstick we should

00:17:04,790 --> 00:17:06,590
be applying is are we solving a real

00:17:06,140 --> 00:17:08,450
problem

00:17:06,590 --> 00:17:11,660
do we have evidence of the nature the

00:17:08,450 --> 00:17:14,480
scale and and and and the depth of the

00:17:11,660 --> 00:17:16,400
problem do we are we taking the least

00:17:14,480 --> 00:17:19,850
invasive option which is still effective

00:17:16,400 --> 00:17:21,530
you know to address these problems this

00:17:19,850 --> 00:17:24,490
is the this is the standard to which the

00:17:21,530 --> 00:17:27,440
Commission should hold itself and we do

00:17:24,490 --> 00:17:30,350
and then the democratic process should

00:17:27,440 --> 00:17:33,050
should challenge that right and the so

00:17:30,350 --> 00:17:36,140
but it's really important not to just

00:17:33,050 --> 00:17:37,910
say our is there enough regulation or

00:17:36,140 --> 00:17:39,410
not because that puts us in a binary of

00:17:37,910 --> 00:17:41,000
whether we regulate or not it's not

00:17:39,410 --> 00:17:42,740
that's the wrong that's the wrong

00:17:41,000 --> 00:17:44,419
framing the wrong framing is what's the

00:17:42,740 --> 00:17:47,379
problem exactly

00:17:44,419 --> 00:17:50,929
on how we gonna solve it got it yeah and

00:17:47,379 --> 00:17:53,809
well first of all also to say like I

00:17:50,929 --> 00:17:55,249
agree just regulation for the sake of

00:17:53,809 --> 00:17:57,649
regulation is not what we're talking

00:17:55,249 --> 00:17:59,600
about and if I may Europe doesn't do

00:17:57,649 --> 00:18:01,100
everything right either so no we're not

00:17:59,600 --> 00:18:02,929
like a civil society I think we're not

00:18:01,100 --> 00:18:04,609
happy with every internet-related

00:18:02,929 --> 00:18:06,200
regulation that has come out today you

00:18:04,609 --> 00:18:07,309
look at the copyright directive or what

00:18:06,200 --> 00:18:12,139
might happen with it there is content

00:18:07,309 --> 00:18:14,480
director so on the but from either point

00:18:12,139 --> 00:18:17,269
is that the there are many conversations

00:18:14,480 --> 00:18:20,269
around the world in Latin America in the

00:18:17,269 --> 00:18:22,039
u.s. in India in so many different for

00:18:20,269 --> 00:18:23,629
as well about how do we deal with these

00:18:22,039 --> 00:18:25,519
complex multi-dimensional Internet

00:18:23,629 --> 00:18:28,009
problems and the solution will not

00:18:25,519 --> 00:18:29,720
always be through EU style regulation

00:18:28,009 --> 00:18:32,059
and that may be fine

00:18:29,720 --> 00:18:34,820
as long as we are solving problems that

00:18:32,059 --> 00:18:37,279
are that allows work as long as for

00:18:34,820 --> 00:18:41,629
finding solutions to like and societal

00:18:37,279 --> 00:18:43,460
problems in one important precision I

00:18:41,629 --> 00:18:45,289
think that it's always important to

00:18:43,460 --> 00:18:47,779
remember is that the GD P R is not just

00:18:45,289 --> 00:18:50,539
now that we're singling in like zooming

00:18:47,779 --> 00:18:53,600
in to GD P R is not just a protective

00:18:50,539 --> 00:18:55,399
sphere for Europeans or for people in

00:18:53,600 --> 00:18:57,109
Europe it's actually if you read the

00:18:55,399 --> 00:18:59,840
title of the GD P R the second part of

00:18:57,109 --> 00:19:01,070
it is and to enable data flows around

00:18:59,840 --> 00:19:02,989
the world or something like this or

00:19:01,070 --> 00:19:05,419
cross-border data flows the GD P R is

00:19:02,989 --> 00:19:07,369
designed as a tool to actually make the

00:19:05,419 --> 00:19:10,009
internet work in a private like in a

00:19:07,369 --> 00:19:12,259
data protection respective way and and

00:19:10,009 --> 00:19:14,029
that's something that that we need the

00:19:12,259 --> 00:19:17,179
European Commission as well to through

00:19:14,029 --> 00:19:19,519
those negotiations it has with other

00:19:17,179 --> 00:19:22,039
countries so that the data can personal

00:19:19,519 --> 00:19:24,409
data can flow in both directions uphold

00:19:22,039 --> 00:19:26,239
kind of help elevate the level of data

00:19:24,409 --> 00:19:27,649
protection around the world yeah yeah I

00:19:26,239 --> 00:19:29,419
want to go that's a really good point

00:19:27,649 --> 00:19:31,399
but I want to go back to what Prophet

00:19:29,419 --> 00:19:34,129
was saying about but I got from that was

00:19:31,399 --> 00:19:35,480
essentially quantity is not important

00:19:34,129 --> 00:19:37,580
like the quality of the laws being

00:19:35,480 --> 00:19:39,109
passed is more important this is a

00:19:37,580 --> 00:19:41,419
question I asked in the previous panel

00:19:39,109 --> 00:19:43,730
but whenever I see Facebook and Google

00:19:41,419 --> 00:19:45,769
being fined billions and looking at how

00:19:43,730 --> 00:19:47,570
much they make it's just in a quarter

00:19:45,769 --> 00:19:50,749
which is multiple billions like if we're

00:19:47,570 --> 00:19:52,869
talking about future of policy for these

00:19:50,749 --> 00:19:55,330
Internet companies how do you go about

00:19:52,869 --> 00:19:58,070
reprimanding or

00:19:55,330 --> 00:19:59,960
putting ineffective laws when money is

00:19:58,070 --> 00:20:05,870
no object how does that how do you do

00:19:59,960 --> 00:20:08,450
that well it's a it's a good question so

00:20:05,870 --> 00:20:10,820
the the treaty says that that sanctions

00:20:08,450 --> 00:20:14,000
should be this way stiff proportionate

00:20:10,820 --> 00:20:16,220
and effective you know in it and and and

00:20:14,000 --> 00:20:18,110
yeah and we're asking us what does that

00:20:16,220 --> 00:20:20,000
mean now you know if the stock price

00:20:18,110 --> 00:20:22,250
goes up after you hit a company with a

00:20:20,000 --> 00:20:24,350
five billion dollar fine you know what

00:20:22,250 --> 00:20:26,450
is that this weighs if you know is that

00:20:24,350 --> 00:20:29,630
effective and is it proportionate you

00:20:26,450 --> 00:20:30,890
know so that's that's that's a really

00:20:29,630 --> 00:20:34,520
that's a really good question you know

00:20:30,890 --> 00:20:36,320
actually ultimately though the fine is a

00:20:34,520 --> 00:20:39,020
means to an end end is the behavior

00:20:36,320 --> 00:20:42,320
change you know that you and compliance

00:20:39,020 --> 00:20:44,240
to the to the rules you know in theum so

00:20:42,320 --> 00:20:46,700
it's certainly something we're going to

00:20:44,240 --> 00:20:48,950
take into account and and you know

00:20:46,700 --> 00:20:51,799
Commission on antitrust has fine Google

00:20:48,950 --> 00:20:55,190
on numerous occasions you know idea in

00:20:51,799 --> 00:20:56,630
some cases you know they have been

00:20:55,190 --> 00:20:59,000
commitments which you were monitoring

00:20:56,630 --> 00:21:01,220
and to see whether they're really living

00:20:59,000 --> 00:21:04,250
up so it's not just about the define so

00:21:01,220 --> 00:21:06,230
there's also a follow up on that but you

00:21:04,250 --> 00:21:08,870
all right I mean I think we are we are

00:21:06,230 --> 00:21:10,399
entering into into a space where we're

00:21:08,870 --> 00:21:11,779
asking ourselves you know what what does

00:21:10,399 --> 00:21:13,760
this way sit really look like you know

00:21:11,779 --> 00:21:15,289
and and and and that's a really

00:21:13,760 --> 00:21:17,929
important question you know and a lot of

00:21:15,289 --> 00:21:19,610
people are asking that question in terms

00:21:17,929 --> 00:21:21,380
of kind of and they're framing it I'm

00:21:19,610 --> 00:21:23,090
not necessarily framing like this but it

00:21:21,380 --> 00:21:25,520
is being framed as a matter of

00:21:23,090 --> 00:21:27,169
sovereignty rule of law kind of you know

00:21:25,520 --> 00:21:29,630
who who's the boss yeah you know

00:21:27,169 --> 00:21:31,700
actually it's not necessarily how I view

00:21:29,630 --> 00:21:33,620
it but this is a conversation part of

00:21:31,700 --> 00:21:35,990
the conversation out there you know and

00:21:33,620 --> 00:21:38,929
so will I don't have a good answer of

00:21:35,990 --> 00:21:40,130
what the alternative is but it's

00:21:38,929 --> 00:21:42,110
certainly going something we're going to

00:21:40,130 --> 00:21:43,820
look at I have a suggestion I think

00:21:42,110 --> 00:21:46,429
there are these three approaches and two

00:21:43,820 --> 00:21:48,110
of them we already tried first is taxing

00:21:46,429 --> 00:21:50,179
them because that's effectively what the

00:21:48,110 --> 00:21:51,320
fines are it's just another tax imposed

00:21:50,179 --> 00:21:52,970
on these companies and they're clearly

00:21:51,320 --> 00:21:54,710
ready to pay that tax because they

00:21:52,970 --> 00:21:56,659
became wealthy enough to do it and

00:21:54,710 --> 00:21:58,190
that's not going to be effective but

00:21:56,659 --> 00:22:00,500
well I mean transferring money from

00:21:58,190 --> 00:22:02,000
their badges to public badges make sense

00:22:00,500 --> 00:22:04,399
I'm not saying stop finding them is

00:22:02,000 --> 00:22:06,529
please continue but remember that there

00:22:04,399 --> 00:22:09,039
are two other approaches possible second

00:22:06,529 --> 00:22:11,110
is what I call Constitution for digital

00:22:09,039 --> 00:22:12,690
we can approach these digital Emperor's

00:22:11,110 --> 00:22:15,490
and kindly ask them to be more

00:22:12,690 --> 00:22:18,429
protective of our principles our rights

00:22:15,490 --> 00:22:20,259
so and ask Facebook to observe due

00:22:18,429 --> 00:22:22,779
process when it's removing content or

00:22:20,259 --> 00:22:25,779
maybe reveal and more information about

00:22:22,779 --> 00:22:26,889
targeting political ads or other types

00:22:25,779 --> 00:22:28,600
of content you know we've been

00:22:26,889 --> 00:22:31,210
discussing this for a decade they

00:22:28,600 --> 00:22:32,679
believe we had some progress gdpr also

00:22:31,210 --> 00:22:35,110
can be seen as this constitution for the

00:22:32,679 --> 00:22:37,600
emperor to some extent I believe digital

00:22:35,110 --> 00:22:39,429
services Act another initiative coming

00:22:37,600 --> 00:22:41,409
from Brussels which I welcome very much

00:22:39,429 --> 00:22:46,090
could be such a constitution but that's

00:22:41,409 --> 00:22:48,249
still not taking the power away from

00:22:46,090 --> 00:22:50,019
these Emperor's and that we deferred

00:22:48,249 --> 00:22:53,409
approach which is structural measures

00:22:50,019 --> 00:22:55,440
but not case-by-case having FCC or

00:22:53,409 --> 00:22:58,119
European Commission busy investigating

00:22:55,440 --> 00:22:59,710
you know multiple markets different

00:22:58,119 --> 00:23:02,860
markets different companies but maybe

00:22:59,710 --> 00:23:04,869
having some new data ecosystem in mind

00:23:02,860 --> 00:23:07,119
projecting this ecosystem and designing

00:23:04,869 --> 00:23:08,409
it with regulatory measures that's a

00:23:07,119 --> 00:23:11,409
real interesting really interesting

00:23:08,409 --> 00:23:13,149
approach that I advocate for also in my

00:23:11,409 --> 00:23:14,710
previous talk in this space and I think

00:23:13,149 --> 00:23:16,659
that's the biggest challenge of course

00:23:14,710 --> 00:23:18,789
we know we won't come up with it next

00:23:16,659 --> 00:23:21,039
month but maybe next five years is the

00:23:18,789 --> 00:23:22,659
timeframe in which we could redevelop

00:23:21,039 --> 00:23:25,330
our thinking about this data ecosystem

00:23:22,659 --> 00:23:28,539
and propose simply new structure move

00:23:25,330 --> 00:23:30,700
the power a bit around the field yeah I

00:23:28,539 --> 00:23:33,190
that the Emperor Empire metaphor is so

00:23:30,700 --> 00:23:36,190
strong I want to go back to character

00:23:33,190 --> 00:23:38,169
it's just that learning from past

00:23:36,190 --> 00:23:40,659
mistakes is also very important so a

00:23:38,169 --> 00:23:42,580
very recent one is allowing the merger

00:23:40,659 --> 00:23:44,529
between Facebook and whatsapp I think

00:23:42,580 --> 00:23:46,809
that it's now evident that we've just

00:23:44,529 --> 00:23:49,539
allowed that giant to become so big that

00:23:46,809 --> 00:23:51,159
it has created the that it now controls

00:23:49,539 --> 00:23:54,249
effectively the largest communication

00:23:51,159 --> 00:23:55,480
platform in the world and regulating it

00:23:54,249 --> 00:23:57,159
and keeping under control all the

00:23:55,480 --> 00:23:59,200
problems that stem from that has become

00:23:57,159 --> 00:24:01,840
so complex because of that and in

00:23:59,200 --> 00:24:03,340
hindsight at least in from a European

00:24:01,840 --> 00:24:05,799
context the European Commission was in a

00:24:03,340 --> 00:24:08,649
good place to say wait a second

00:24:05,799 --> 00:24:11,289
this is probably gonna create two wave

00:24:08,649 --> 00:24:13,600
more problems than benefits the the

00:24:11,289 --> 00:24:16,059
question is whether competition rules

00:24:13,600 --> 00:24:17,740
and the policies that in that helped the

00:24:16,059 --> 00:24:20,200
Commission make those decisions are up

00:24:17,740 --> 00:24:21,879
and you know kind of ready for the

00:24:20,200 --> 00:24:22,380
digital age and that's another question

00:24:21,879 --> 00:24:25,170
that we need

00:24:22,380 --> 00:24:27,210
be asking how can we rethink all those

00:24:25,170 --> 00:24:29,580
frameworks and all those enforcer

00:24:27,210 --> 00:24:32,970
authorities to be able to deal with such

00:24:29,580 --> 00:24:34,860
new complex phenomenon yeah yeah we know

00:24:32,970 --> 00:24:36,240
well so the panelist told me that they

00:24:34,860 --> 00:24:38,100
want to forfeit some of their time to

00:24:36,240 --> 00:24:39,600
hear some of your questions so I'll only

00:24:38,100 --> 00:24:41,700
keep it at two more questions and then

00:24:39,600 --> 00:24:43,350
you guys can hear from them the audience

00:24:41,700 --> 00:24:46,260
but going back to what you said before

00:24:43,350 --> 00:24:48,240
about how GDP are a big part of it is

00:24:46,260 --> 00:24:50,520
like data flow freely around the world

00:24:48,240 --> 00:24:54,300
and global is the first word in GDP our

00:24:50,520 --> 00:24:57,120
I want to talk to you about global not

00:24:54,300 --> 00:24:58,800
just regional but also being

00:24:57,120 --> 00:25:01,490
all-inclusive like you know it's only

00:24:58,800 --> 00:25:04,830
lawmakers generally who kind of have a

00:25:01,490 --> 00:25:07,860
influence over the laws get passed you

00:25:04,830 --> 00:25:10,670
know how do we bring in everyone or

00:25:07,860 --> 00:25:12,960
other folks to kind of affect these laws

00:25:10,670 --> 00:25:14,400
so that's a yeah that's a good

00:25:12,960 --> 00:25:16,080
interesting conversation we were having

00:25:14,400 --> 00:25:18,510
backstage as well

00:25:16,080 --> 00:25:20,810
in the context of so well first of all

00:25:18,510 --> 00:25:23,760
and we had a very interesting

00:25:20,810 --> 00:25:25,410
conversation about what is our

00:25:23,760 --> 00:25:27,680
understanding of the open Internet

00:25:25,410 --> 00:25:36,060
globally like what does open mean and

00:25:27,680 --> 00:25:38,010
and there is such a multiple fora both

00:25:36,060 --> 00:25:39,750
regulatory and self regulatory and just

00:25:38,010 --> 00:25:41,760
conversations around the world that it's

00:25:39,750 --> 00:25:43,710
not very easy to just pinpoint one place

00:25:41,760 --> 00:25:45,720
where you can say okay there is where

00:25:43,710 --> 00:25:48,570
you have you really need that kind of a

00:25:45,720 --> 00:25:50,850
multi-stakeholder approach because on

00:25:48,570 --> 00:25:53,340
some you have it on some you don't so

00:25:50,850 --> 00:25:54,810
right now the just the complexity of the

00:25:53,340 --> 00:25:57,300
global conversation about all these

00:25:54,810 --> 00:26:00,570
issues is pretty a manageable what we

00:25:57,300 --> 00:26:02,430
were talking about just earlier is that

00:26:00,570 --> 00:26:04,020
when you have conversations about for

00:26:02,430 --> 00:26:05,940
example how do we regulate issues like

00:26:04,020 --> 00:26:09,300
freedom of expression online and what is

00:26:05,940 --> 00:26:12,270
good regulation to to protect that

00:26:09,300 --> 00:26:13,890
fundament that human right it is for us

00:26:12,270 --> 00:26:16,380
it is very important and that's a lot of

00:26:13,890 --> 00:26:19,020
what we do globally to bringing groups

00:26:16,380 --> 00:26:21,120
that are the most affected to the

00:26:19,020 --> 00:26:23,010
conversation the most marginalized and

00:26:21,120 --> 00:26:25,680
vulnerable groups that see themselves

00:26:23,010 --> 00:26:27,570
most affected when there is content

00:26:25,680 --> 00:26:30,360
about issues that they care of being

00:26:27,570 --> 00:26:35,340
taken down or when they are suffering a

00:26:30,360 --> 00:26:36,299
lot of just online attacks to the to who

00:26:35,340 --> 00:26:38,609
they are or to

00:26:36,299 --> 00:26:40,229
what they're doing and so on and having

00:26:38,609 --> 00:26:43,679
those voices in those conversations is

00:26:40,229 --> 00:26:45,089
just key at any level yeah and then the

00:26:43,679 --> 00:26:47,249
last question I want to ask everybody on

00:26:45,089 --> 00:26:50,669
stage before I open up to the audience

00:26:47,249 --> 00:26:56,339
is just so you know what does a win look

00:26:50,669 --> 00:27:00,239
like like what should we for here don't

00:26:56,339 --> 00:27:02,789
all rush along it's a hard one right I I

00:27:00,239 --> 00:27:04,200
don't think we can have final answer

00:27:02,789 --> 00:27:05,940
today because that's a process that's

00:27:04,200 --> 00:27:08,129
something that I believe should be the

00:27:05,940 --> 00:27:10,589
task for the whole movement of people in

00:27:08,129 --> 00:27:12,539
mosfets and Beyond mosfets because it is

00:27:10,589 --> 00:27:14,789
a real task that we have to you know

00:27:12,539 --> 00:27:16,499
work on together nobody should have the

00:27:14,789 --> 00:27:19,079
arrogance to say that's the win for

00:27:16,499 --> 00:27:21,299
everybody but definitely what's not the

00:27:19,079 --> 00:27:23,249
win is the current situation when we

00:27:21,299 --> 00:27:25,950
have big dominant players in the middle

00:27:23,249 --> 00:27:27,690
of the ecosystem controlling data flows

00:27:25,950 --> 00:27:29,700
controlling what is allowed what is not

00:27:27,690 --> 00:27:32,129
allowed guessing the needs of all these

00:27:29,700 --> 00:27:34,679
vulnerable people ruling them basically

00:27:32,129 --> 00:27:37,049
in quite outer Italian way that's what

00:27:34,679 --> 00:27:38,669
we want to depart from some on the other

00:27:37,049 --> 00:27:41,489
on the other side of that spectrum I can

00:27:38,669 --> 00:27:43,589
see open ecosystem in which for example

00:27:41,489 --> 00:27:46,529
run on group groups can organize

00:27:43,589 --> 00:27:48,299
themselves bottom-up and define what it

00:27:46,529 --> 00:27:50,669
means for them to be safe or what it

00:27:48,299 --> 00:27:53,940
means for them to express themselves and

00:27:50,669 --> 00:27:56,489
then the ecosystem basically including

00:27:53,940 --> 00:27:59,700
this allowing for that diversity so a

00:27:56,489 --> 00:28:02,339
diverse federated open ecosystem which

00:27:59,700 --> 00:28:05,519
is not ruled by any benevolent Emperor

00:28:02,339 --> 00:28:08,399
but basically much more bottom-up and

00:28:05,519 --> 00:28:11,700
preserved with rules like GPR like

00:28:08,399 --> 00:28:14,929
hopefully new regulations providing for

00:28:11,700 --> 00:28:17,489
privacy and security how about you guys

00:28:14,929 --> 00:28:19,320
yeah I mean I think I could have said it

00:28:17,489 --> 00:28:20,579
better it's that's the whole concept we

00:28:19,320 --> 00:28:24,589
have to protect the Internet as the

00:28:20,579 --> 00:28:27,179
public resource that it is to enable

00:28:24,589 --> 00:28:29,929
communities individuals and also

00:28:27,179 --> 00:28:33,509
companies to thrive in a way in which it

00:28:29,929 --> 00:28:36,599
empowers and expands fundamental rights

00:28:33,509 --> 00:28:38,129
and and innovation and so on and not the

00:28:36,599 --> 00:28:40,379
contrary and we've been having this come

00:28:38,129 --> 00:28:41,940
up in like multiple circles having

00:28:40,379 --> 00:28:44,489
similar conversations throughout this

00:28:41,940 --> 00:28:46,320
past days and I've heard some ask where

00:28:44,489 --> 00:28:48,839
are we having a nostalgic vision of the

00:28:46,320 --> 00:28:50,070
internet was it is it that what it used

00:28:48,839 --> 00:28:53,310
to be and we just have to chain

00:28:50,070 --> 00:28:56,310
mindset I would say no that still that

00:28:53,310 --> 00:28:57,690
that for me still the idea is just the

00:28:56,310 --> 00:28:59,280
dynamics might be different the

00:28:57,690 --> 00:29:01,500
technology is definitely different now

00:28:59,280 --> 00:29:03,300
the you know things like for example the

00:29:01,500 --> 00:29:05,010
advent of AI and so on complicate the

00:29:03,300 --> 00:29:07,380
whole conversation even much more and so

00:29:05,010 --> 00:29:12,600
on but the idea of having this public

00:29:07,380 --> 00:29:13,950
resource that helps society work better

00:29:12,600 --> 00:29:16,350
and integrate better amongst themselves

00:29:13,950 --> 00:29:19,200
a be more open be more open it's

00:29:16,350 --> 00:29:22,470
definitely what we should try for Prabha

00:29:19,200 --> 00:29:24,570
I think from my perspective I think that

00:29:22,470 --> 00:29:27,900
kind of three elements what offer when

00:29:24,570 --> 00:29:31,590
you know one is the users feel kind of

00:29:27,900 --> 00:29:33,930
safe and empowered online but also free

00:29:31,590 --> 00:29:35,400
you know and where that balance lies is

00:29:33,930 --> 00:29:37,590
going to be our challenge in the next

00:29:35,400 --> 00:29:41,100
kind of couple of of months but I think

00:29:37,590 --> 00:29:43,680
that on those two aspects you know users

00:29:41,100 --> 00:29:45,000
being safe empowered and free I think

00:29:43,680 --> 00:29:46,620
the balance isn't quite right at the

00:29:45,000 --> 00:29:48,900
moment you know it's part of the abuse a

00:29:46,620 --> 00:29:50,520
problem that that we mentioned it's

00:29:48,900 --> 00:29:52,290
maybe the ad tracking problem the cache

00:29:50,520 --> 00:29:53,790
I mentioned you know that's one thing

00:29:52,290 --> 00:29:55,710
there's a there's a third element which

00:29:53,790 --> 00:29:57,930
we didn't really discuss which for the

00:29:55,710 --> 00:29:59,820
four from the EU perspective is super

00:29:57,930 --> 00:30:01,470
important is that to continue to make

00:29:59,820 --> 00:30:02,850
sure that you is a great place to start

00:30:01,470 --> 00:30:04,500
kind of innovative service in your

00:30:02,850 --> 00:30:06,600
interest maybe I'll end on this anecdote

00:30:04,500 --> 00:30:09,300
a couple of weeks ago I was in Riga it's

00:30:06,600 --> 00:30:11,610
a great startup student setting up a

00:30:09,300 --> 00:30:13,770
kind of house sharing platform when they

00:30:11,610 --> 00:30:16,380
move when they move into university you

00:30:13,770 --> 00:30:18,300
know it was great great stuff and they

00:30:16,380 --> 00:30:20,100
wanted to expand to Amsterdam and Berlin

00:30:18,300 --> 00:30:22,350
and the even the guys just look at me

00:30:20,100 --> 00:30:24,660
are there any use EU laws that I should

00:30:22,350 --> 00:30:27,600
be aware of you know and I just said no

00:30:24,660 --> 00:30:30,600
I don't worry you know but so it was a

00:30:27,600 --> 00:30:33,030
it was but you know it needs to be we

00:30:30,600 --> 00:30:34,560
need to make sure that we also keep

00:30:33,030 --> 00:30:36,630
these people in mind we focus on

00:30:34,560 --> 00:30:38,100
Facebook and Google and the big ones you

00:30:36,630 --> 00:30:39,690
know but they're like 10,000 small

00:30:38,100 --> 00:30:41,820
startups in Europe you know all trying

00:30:39,690 --> 00:30:43,740
to kind of grow here at home you know

00:30:41,820 --> 00:30:47,070
and and and they need to make sure we

00:30:43,740 --> 00:30:49,170
need to also make rules that work for

00:30:47,070 --> 00:30:52,110
these people you know so I went for me

00:30:49,170 --> 00:30:54,450
is a situation in which users are safe

00:30:52,110 --> 00:30:56,490
and powered and free online and where

00:30:54,450 --> 00:30:58,590
small startups feel that Europe is a

00:30:56,490 --> 00:31:01,080
good place to start a business I just

00:30:58,590 --> 00:31:02,460
want to add one more on the big ones and

00:31:01,080 --> 00:31:04,029
one for me would also be if then

00:31:02,460 --> 00:31:06,399
knowledge generated about

00:31:04,029 --> 00:31:08,169
humankind all of us by the big ones can

00:31:06,399 --> 00:31:09,879
serve the smaller ones and can serve a

00:31:08,169 --> 00:31:12,009
public purpose let's not forget that

00:31:09,879 --> 00:31:13,779
there is also a lot of knowledge or

00:31:12,009 --> 00:31:15,879
value generated by the existing

00:31:13,779 --> 00:31:17,739
ecosystem the clothes exist existing Co

00:31:15,879 --> 00:31:19,509
system that is not controlled for

00:31:17,739 --> 00:31:21,729
commercial reasons but we don't want to

00:31:19,509 --> 00:31:23,950
destroy it right we want to I hope reuse

00:31:21,729 --> 00:31:24,909
it for a better so that's also target

00:31:23,950 --> 00:31:27,789
yes

00:31:24,909 --> 00:31:29,950
all right now audience question answer

00:31:27,789 --> 00:31:32,830
anybody have any questions I've got a

00:31:29,950 --> 00:31:34,419
few in the middle one in the back

00:31:32,830 --> 00:31:39,729
Kevin's come around the microphone right

00:31:34,419 --> 00:31:42,460
now hi thanks for the panel is really

00:31:39,729 --> 00:31:44,109
interesting um I just wanted to pick up

00:31:42,460 --> 00:31:46,389
on the point about competition law which

00:31:44,109 --> 00:31:48,609
I think Guillermo mentioned and how does

00:31:46,389 --> 00:31:51,849
that need to evolve in the EU and Beyond

00:31:48,609 --> 00:31:53,769
because consumers are giving their data

00:31:51,849 --> 00:31:56,529
away for free they're not exchanging

00:31:53,769 --> 00:31:59,320
money with these companies so how do you

00:31:56,529 --> 00:32:01,239
measure that detriment when it's not

00:31:59,320 --> 00:32:02,889
someone losing money and there might not

00:32:01,239 --> 00:32:07,690
be a choice to switch to a different

00:32:02,889 --> 00:32:09,820
service provider ticket sure you can

00:32:07,690 --> 00:32:13,690
take it so that's a really good question

00:32:09,820 --> 00:32:15,489
so in my team and also a digit

00:32:13,690 --> 00:32:18,839
competition of the European Commission

00:32:15,489 --> 00:32:21,369
like the antitrust team we are in a

00:32:18,839 --> 00:32:24,219
ongoing conversation about exactly that

00:32:21,369 --> 00:32:25,299
what you've just said and I think you

00:32:24,219 --> 00:32:27,669
might have seen that there are a couple

00:32:25,299 --> 00:32:29,259
of reports that have been you know just

00:32:27,669 --> 00:32:32,919
have been published this year around the

00:32:29,259 --> 00:32:36,009
future of competition law and and for in

00:32:32,919 --> 00:32:37,359
in this space and and I think that what

00:32:36,009 --> 00:32:38,859
we're doing right now and it's going to

00:32:37,359 --> 00:32:40,570
take a little bit of time but digesting

00:32:38,859 --> 00:32:43,299
all the recommendations that have been

00:32:40,570 --> 00:32:45,820
made in at EU level in Germany in the UK

00:32:43,299 --> 00:32:47,289
in the u.s. also in Australia and we are

00:32:45,820 --> 00:32:50,429
kind of processing this at the moment to

00:32:47,289 --> 00:32:52,479
see it still which elements of

00:32:50,429 --> 00:32:55,539
recommendations will go through a kind

00:32:52,479 --> 00:32:57,039
of review of competition rules and and

00:32:55,539 --> 00:32:59,469
to what extent are they necessary but

00:32:57,039 --> 00:33:01,389
we're also looking at in this area if

00:32:59,469 --> 00:33:03,999
there is any any need for additional ex

00:33:01,389 --> 00:33:05,259
ante regulations you know to help that

00:33:03,999 --> 00:33:07,299
but the the point that you're making

00:33:05,259 --> 00:33:08,859
that the kind of consumer standard

00:33:07,299 --> 00:33:10,690
consumer welfare standard is something

00:33:08,859 --> 00:33:12,489
to kind of double check is that really

00:33:10,690 --> 00:33:13,839
the right standard that's certainly

00:33:12,489 --> 00:33:15,999
something we're looking at very closely

00:33:13,839 --> 00:33:16,920
so we have a pretty good team of people

00:33:15,999 --> 00:33:19,110
looking at it

00:33:16,920 --> 00:33:21,270
the same team that was responsible for

00:33:19,110 --> 00:33:23,730
the antitrust enforcement for Google and

00:33:21,270 --> 00:33:25,500
I think there's a willingness to kind of

00:33:23,730 --> 00:33:27,720
take a fresh look at this and and

00:33:25,500 --> 00:33:29,250
executive vice president Festa has also

00:33:27,720 --> 00:33:33,000
announced that we would be looking at

00:33:29,250 --> 00:33:34,800
that and as a follow-up how exactly it

00:33:33,000 --> 00:33:36,420
would look like I think there are some

00:33:34,800 --> 00:33:38,250
ideas in the table we're just kind of

00:33:36,420 --> 00:33:40,230
going through exactly when it's been

00:33:38,250 --> 00:33:42,990
proposed and it's not going to be a

00:33:40,230 --> 00:33:44,600
quick quick win but it's certainly

00:33:42,990 --> 00:33:47,640
something we're taking very seriously so

00:33:44,600 --> 00:33:49,980
point fully taken and there's a at least

00:33:47,640 --> 00:33:54,240
two full working teams on this to follow

00:33:49,980 --> 00:33:55,920
it up in the Commission okay any other

00:33:54,240 --> 00:34:00,930
questions out in the audience we had a

00:33:55,920 --> 00:34:02,880
couple over here actually a few I'm just

00:34:00,930 --> 00:34:04,620
McCroskey a data scientist with Mozilla

00:34:02,880 --> 00:34:06,960
and thanks to the thoughtful discussion

00:34:04,620 --> 00:34:10,140
I was curious that given that many

00:34:06,960 --> 00:34:11,730
problematic uses of data on line use the

00:34:10,140 --> 00:34:13,890
example of the ad tech industry which i

00:34:11,730 --> 00:34:16,320
think is great can really constitute

00:34:13,890 --> 00:34:18,540
human experimentation do you think that

00:34:16,320 --> 00:34:20,429
the existing frameworks around ethical

00:34:18,540 --> 00:34:25,740
approval for human experimentation could

00:34:20,429 --> 00:34:28,080
be a useful tool here I believe you

00:34:25,740 --> 00:34:31,560
refer to an framework for research right

00:34:28,080 --> 00:34:33,840
yeah that's that's a brilliant idea and

00:34:31,560 --> 00:34:36,270
I think also coming back we currently in

00:34:33,840 --> 00:34:38,669
terms of horizon 2020 and these types of

00:34:36,270 --> 00:34:40,950
publicly funded programs it's absolutely

00:34:38,669 --> 00:34:43,290
should include this thinking I mean I'm

00:34:40,950 --> 00:34:45,419
saying as external observer I'm not part

00:34:43,290 --> 00:34:45,990
of I'm either researcher here nor a

00:34:45,419 --> 00:34:47,960
regulator

00:34:45,990 --> 00:34:50,580
I wonder what Robert has to say but

00:34:47,960 --> 00:34:53,550
definitely it's it's it's it's something

00:34:50,580 --> 00:34:54,960
that funders of public research should

00:34:53,550 --> 00:34:57,660
have a have in mind I don't know if they

00:34:54,960 --> 00:34:58,950
do but I think that your question was

00:34:57,660 --> 00:35:01,080
probably not so much of a publicly

00:34:58,950 --> 00:35:02,700
funded research in that's going on but

00:35:01,080 --> 00:35:04,560
actually about the tech in industry

00:35:02,700 --> 00:35:06,690
practice itself whether that should be

00:35:04,560 --> 00:35:09,060
subject to prior authorization due to

00:35:06,690 --> 00:35:11,340
kind of in the same way that biotech

00:35:09,060 --> 00:35:13,020
experiments by private companies have to

00:35:11,340 --> 00:35:16,140
be pre-approved is that what you want it

00:35:13,020 --> 00:35:18,270
yeah I think so we're not there yet but

00:35:16,140 --> 00:35:20,310
it's definitely an interesting and

00:35:18,270 --> 00:35:21,900
interesting Avenue of thought for for

00:35:20,310 --> 00:35:24,210
publicly funded research even if it's

00:35:21,900 --> 00:35:26,190
carried out by private companies there

00:35:24,210 --> 00:35:28,410
is an ethical screening and it data

00:35:26,190 --> 00:35:30,660
protection aspects are a mandatory part

00:35:28,410 --> 00:35:32,880
of that debt screening so if you

00:35:30,660 --> 00:35:34,650
if you want to get R&D money from the

00:35:32,880 --> 00:35:36,660
European Commission even as a company as

00:35:34,650 --> 00:35:39,120
Facebook or some other company and that

00:35:36,660 --> 00:35:41,160
involves data protection relevant issues

00:35:39,120 --> 00:35:43,020
you have to do a screening otherwise you

00:35:41,160 --> 00:35:45,330
don't get the money but whether the

00:35:43,020 --> 00:35:47,760
industry itself should be subject and

00:35:45,330 --> 00:35:49,110
subject to such such screening is a good

00:35:47,760 --> 00:35:52,310
question I don't have a good answer but

00:35:49,110 --> 00:35:52,310
it's something that's worth examining

00:35:53,000 --> 00:36:01,350
okay next question let's see what kevin

00:35:55,740 --> 00:36:04,020
has the microphone there hi I was

00:36:01,350 --> 00:36:05,820
wondering caches that the this new

00:36:04,020 --> 00:36:09,480
ecosystem part of it should come

00:36:05,820 --> 00:36:12,750
bottom-up so I was wondering as citizens

00:36:09,480 --> 00:36:14,280
what can we do to try and help push

00:36:12,750 --> 00:36:16,860
things in the right direction should we

00:36:14,280 --> 00:36:20,790
be weaning ourselves off Google and

00:36:16,860 --> 00:36:22,680
Facebook and all these things and in the

00:36:20,790 --> 00:36:24,210
ecosystem I imagine I do not assume

00:36:22,680 --> 00:36:25,500
movement of people outside of these

00:36:24,210 --> 00:36:28,140
networks I think that could be a

00:36:25,500 --> 00:36:30,900
consequence of a new version a federated

00:36:28,140 --> 00:36:32,790
version so once you have a federated one

00:36:30,900 --> 00:36:35,670
then there are places where we can move

00:36:32,790 --> 00:36:39,030
but before we create it it's it's it's

00:36:35,670 --> 00:36:41,220
rather forcing these companies to open

00:36:39,030 --> 00:36:44,100
their API to their level where we can

00:36:41,220 --> 00:36:47,730
experiment and add new layers new

00:36:44,100 --> 00:36:49,260
alternative services on them to start

00:36:47,730 --> 00:36:51,210
with something like for example there is

00:36:49,260 --> 00:36:54,270
a lot of discussion around newsfeed how

00:36:51,210 --> 00:36:56,310
messy how uncomfortable how thank you

00:36:54,270 --> 00:36:58,860
for the human experimentation line of

00:36:56,310 --> 00:37:01,230
thinking I will use it you know how evil

00:36:58,860 --> 00:37:02,940
the the newsfeed for example is for how

00:37:01,230 --> 00:37:05,580
you know it's not to my benefit right

00:37:02,940 --> 00:37:08,040
it's it's it's it's there to stimulate

00:37:05,580 --> 00:37:10,020
me and manipulate me not to help me I

00:37:08,040 --> 00:37:12,420
want a different one can I achieve it

00:37:10,020 --> 00:37:15,960
well technically yes right I can imagine

00:37:12,420 --> 00:37:18,900
API that allows external developer to

00:37:15,960 --> 00:37:21,420
propose a better safer algorithm to

00:37:18,900 --> 00:37:23,910
function on Facebook so the ecosystem I

00:37:21,420 --> 00:37:25,620
imagine has this possibility and then

00:37:23,910 --> 00:37:27,570
eventually we might imagine this as a

00:37:25,620 --> 00:37:29,430
federal structure where yes people could

00:37:27,570 --> 00:37:31,140
also move somewhere else but right now

00:37:29,430 --> 00:37:35,850
they own they have nowhere to move and

00:37:31,140 --> 00:37:37,560
we have to acknowledge this I think it

00:37:35,850 --> 00:37:39,270
would the point you raise I have a

00:37:37,560 --> 00:37:40,800
slightly different perspective but you

00:37:39,270 --> 00:37:42,750
know I don't want to confuse her because

00:37:40,800 --> 00:37:44,640
she's got great ideas but I think that

00:37:42,750 --> 00:37:46,530
the power of you

00:37:44,640 --> 00:37:48,510
to take their business elsewhere is

00:37:46,530 --> 00:37:50,070
really enormous and you shouldn't

00:37:48,510 --> 00:37:52,980
underestimate that you know like the

00:37:50,070 --> 00:37:55,080
it's a it's a really powerful factor in

00:37:52,980 --> 00:37:57,360
in changing company's behavior you know

00:37:55,080 --> 00:37:59,900
much more I think than regulators I

00:37:57,360 --> 00:38:03,090
think you know and and we know this from

00:37:59,900 --> 00:38:05,340
from documents about you know strategy

00:38:03,090 --> 00:38:07,620
documents about how to counter WeChat or

00:38:05,340 --> 00:38:09,810
how to counter snapchat and so on you

00:38:07,620 --> 00:38:12,270
know this is a really important thing so

00:38:09,810 --> 00:38:15,750
countries consuming you know it is

00:38:12,270 --> 00:38:17,820
really a hugely important factor and you

00:38:15,750 --> 00:38:19,950
you do have choice you know likely an

00:38:17,820 --> 00:38:23,130
agency and one of the one of the things

00:38:19,950 --> 00:38:25,680
that that that that we want to also say

00:38:23,130 --> 00:38:27,300
is that you know you're not sometimes

00:38:25,680 --> 00:38:28,740
what I get a little bit frustrated with

00:38:27,300 --> 00:38:31,410
in conversations in Brussels in my

00:38:28,740 --> 00:38:32,850
bubble is that that that users are

00:38:31,410 --> 00:38:34,890
represented as kind of purely passive

00:38:32,850 --> 00:38:36,420
you know like that that there are just

00:38:34,890 --> 00:38:38,370
kind of victims of what is thrown at

00:38:36,420 --> 00:38:41,640
them and they have like zero agencies

00:38:38,370 --> 00:38:43,590
and I think maybe we're simultaneously

00:38:41,640 --> 00:38:45,090
over and under estimating the agency of

00:38:43,590 --> 00:38:46,860
the users you know actually was

00:38:45,090 --> 00:38:48,240
sometimes who in some aspects we think

00:38:46,860 --> 00:38:50,820
that they can do more than they can

00:38:48,240 --> 00:38:52,950
reasonably do an attention economy but

00:38:50,820 --> 00:38:54,270
in other cases I think consumers do have

00:38:52,950 --> 00:38:57,420
a choice you know and they can make a

00:38:54,270 --> 00:38:58,920
they can make a conscious a a choice

00:38:57,420 --> 00:39:00,240
when you know when you pick your food

00:38:58,920 --> 00:39:01,920
and when you pick your clothes you know

00:39:00,240 --> 00:39:04,440
you take conscious choices you know you

00:39:01,920 --> 00:39:05,790
can also do some of that online and

00:39:04,440 --> 00:39:07,470
educate yourself and this is something

00:39:05,790 --> 00:39:08,700
that is really something as part of the

00:39:07,470 --> 00:39:10,680
conversation it's not only about

00:39:08,700 --> 00:39:13,350
regulation it's also about empowering

00:39:10,680 --> 00:39:15,600
people and educating users you know and

00:39:13,350 --> 00:39:17,310
and I'm actually very optimistic I see

00:39:15,600 --> 00:39:18,540
it when we were in a little bit of work

00:39:17,310 --> 00:39:20,670
we do with kids and we should be doing

00:39:18,540 --> 00:39:22,260
much more is that we actually aware of a

00:39:20,670 --> 00:39:24,720
much higher level of awareness than we

00:39:22,260 --> 00:39:26,400
sometimes assume about about the dangers

00:39:24,720 --> 00:39:29,070
and so on and their usage patterns are

00:39:26,400 --> 00:39:31,950
different from from from what kind of

00:39:29,070 --> 00:39:33,540
you know lambda user in the policymakers

00:39:31,950 --> 00:39:35,940
head is and that song that's an

00:39:33,540 --> 00:39:38,220
important part so maybe I'm I'm over

00:39:35,940 --> 00:39:39,570
emphasizing I'm over optimistic but I do

00:39:38,220 --> 00:39:42,510
think this is an important part of the

00:39:39,570 --> 00:39:47,160
conversation I would emphasize robots

00:39:42,510 --> 00:39:48,690
last point about it read about this like

00:39:47,160 --> 00:39:52,050
talk to your friends about these issues

00:39:48,690 --> 00:39:54,120
get more interested look into how these

00:39:52,050 --> 00:39:57,410
platforms are designed to capture your

00:39:54,120 --> 00:39:58,560
attention and keep you there because I

00:39:57,410 --> 00:40:00,510
well

00:39:58,560 --> 00:40:01,860
I for one deleted my facebook account a

00:40:00,510 --> 00:40:06,210
year and a half ago haven't missed it

00:40:01,860 --> 00:40:08,520
for a day we might like there there

00:40:06,210 --> 00:40:09,780
might be some examples where we don't we

00:40:08,520 --> 00:40:11,040
don't really have alternatives and

00:40:09,780 --> 00:40:13,230
you'll ask yourself yeah but then where

00:40:11,040 --> 00:40:13,950
do I go but ask yourself also do I

00:40:13,230 --> 00:40:16,260
really need it

00:40:13,950 --> 00:40:18,360
could I be spending my time somewhere

00:40:16,260 --> 00:40:21,110
else on the internet that is more

00:40:18,360 --> 00:40:25,860
creative for me more participatory more

00:40:21,110 --> 00:40:27,860
and yet just don't like let's have this

00:40:25,860 --> 00:40:31,530
conversation be more more mainstream

00:40:27,860 --> 00:40:33,450
than it actually is just clarify my

00:40:31,530 --> 00:40:35,910
point that nowhere to go does not refer

00:40:33,450 --> 00:40:37,920
to lack of other brands or services I

00:40:35,910 --> 00:40:39,750
mean the business model if the business

00:40:37,920 --> 00:40:41,460
model everywhere is more as the same we

00:40:39,750 --> 00:40:42,990
really have nowhere to go so that's what

00:40:41,460 --> 00:40:45,090
I mean it that's why I think we need to

00:40:42,990 --> 00:40:48,540
rethink ecosystem so it becomes not

00:40:45,090 --> 00:40:51,510
service or even but value driven no time

00:40:48,540 --> 00:40:53,310
for at all time we have okay well that's

00:40:51,510 --> 00:40:56,040
all the time we have for this panel but

00:40:53,310 --> 00:40:59,520
I was late yeah

00:40:56,040 --> 00:41:04,260
do one more we'll do it one more hand up

00:40:59,520 --> 00:41:06,840
back there yeah my question for the

00:41:04,260 --> 00:41:09,870
panel is should be you policy support

00:41:06,840 --> 00:41:13,020
the concept of digital generativity and

00:41:09,870 --> 00:41:15,150
by that I mean the idea if you do things

00:41:13,020 --> 00:41:18,660
like intro for this in decentralization

00:41:15,150 --> 00:41:22,430
you can enable uncoordinated audiences

00:41:18,660 --> 00:41:25,050
to collaborate and generate unplanned

00:41:22,430 --> 00:41:27,690
innovation the classic example is the

00:41:25,050 --> 00:41:30,450
payment services directive to where by

00:41:27,690 --> 00:41:33,390
mandating open API is for banking and

00:41:30,450 --> 00:41:35,550
also allowing users to take their data

00:41:33,390 --> 00:41:37,170
that at least in theories allows you

00:41:35,550 --> 00:41:39,540
know new third parties to come up with

00:41:37,170 --> 00:41:41,370
new services and makes the e much more

00:41:39,540 --> 00:41:42,030
competitive to convince the US where

00:41:41,370 --> 00:41:47,670
banking's

00:41:42,030 --> 00:41:49,020
in the Stone Age simple answer yes

00:41:47,670 --> 00:41:51,770
absolutely

00:41:49,020 --> 00:41:54,000
and it's great that you raise the PSD to

00:41:51,770 --> 00:41:55,560
because that's one example but there's

00:41:54,000 --> 00:41:57,420
another example for example in EU

00:41:55,560 --> 00:41:58,920
telecom slow now there is the power for

00:41:57,420 --> 00:42:01,280
regulatory authorities to force

00:41:58,920 --> 00:42:04,080
interoperability between

00:42:01,280 --> 00:42:05,970
chat apps between say whatsapp and

00:42:04,080 --> 00:42:07,320
signal and telegram and so on is that

00:42:05,970 --> 00:42:09,780
something that they're going to be using

00:42:07,320 --> 00:42:12,569
or not but definitely having that as a

00:42:09,780 --> 00:42:14,459
policy goal to help create that interval

00:42:12,569 --> 00:42:17,699
and that decentralisation were all in

00:42:14,459 --> 00:42:20,640
favor for sure no yeah I mean so and

00:42:17,699 --> 00:42:22,799
we're pretty proud of those the the

00:42:20,640 --> 00:42:25,049
innovations in interoperability space

00:42:22,799 --> 00:42:27,269
that that that you both mentioned and

00:42:25,049 --> 00:42:29,429
and I think that's that's something that

00:42:27,269 --> 00:42:31,410
we want to build on I just have a small

00:42:29,429 --> 00:42:33,209
word of caution in in there is that

00:42:31,410 --> 00:42:34,709
interoperability really works well when

00:42:33,209 --> 00:42:35,880
you have kind of two equivalent things

00:42:34,709 --> 00:42:37,919
that you can really connect to each

00:42:35,880 --> 00:42:40,709
other you know like the and in the

00:42:37,919 --> 00:42:42,630
banking system and or in net neutrality

00:42:40,709 --> 00:42:44,759
regulations you know you did deal with

00:42:42,630 --> 00:42:45,869
you you deal with things that you can

00:42:44,759 --> 00:42:48,569
easily interconnect because they're

00:42:45,869 --> 00:42:52,739
basically the same you know it's not

00:42:48,569 --> 00:42:54,329
super trivial to to take to take that

00:42:52,739 --> 00:42:56,449
concept and to take it to kind of very

00:42:54,329 --> 00:42:58,529
heterogeneous systems you know like

00:42:56,449 --> 00:43:00,269
mastodons and Facebook are kind of very

00:42:58,529 --> 00:43:02,099
different things you know idea and and

00:43:00,269 --> 00:43:03,959
so while the principle of

00:43:02,099 --> 00:43:06,630
interoperability and and decentralized

00:43:03,959 --> 00:43:07,979
kind of thing is really good how to make

00:43:06,630 --> 00:43:09,449
it work in practice I think this is

00:43:07,979 --> 00:43:11,609
something that that requires a little

00:43:09,449 --> 00:43:13,949
bit more conversation I think there's an

00:43:11,609 --> 00:43:16,079
interesting standard which was proposed

00:43:13,949 --> 00:43:16,919
a couple of years ago by w3c about

00:43:16,079 --> 00:43:19,199
social media

00:43:16,919 --> 00:43:21,209
you know news feeds and so on in other

00:43:19,199 --> 00:43:23,069
words that was designed to enable this

00:43:21,209 --> 00:43:24,719
kind of decentralized Federation I think

00:43:23,069 --> 00:43:27,179
we're gonna take a fresh look at that

00:43:24,719 --> 00:43:28,769
and and have a have a you know and to

00:43:27,179 --> 00:43:30,719
have a better understanding of what was

00:43:28,769 --> 00:43:34,380
you know what what what happened to that

00:43:30,719 --> 00:43:35,759
and so on so yes in principle slight

00:43:34,380 --> 00:43:38,069
word of caution on how would this work

00:43:35,759 --> 00:43:39,719
in print in practice you know they

00:43:38,069 --> 00:43:41,519
takeaways from discussions here in this

00:43:39,719 --> 00:43:44,189
space is what's let's let's take step by

00:43:41,519 --> 00:43:47,189
step approach maybe start with the the

00:43:44,189 --> 00:43:49,199
lower hanging fruit like federating the

00:43:47,189 --> 00:43:51,269
the public posts without discussing

00:43:49,199 --> 00:43:53,400
private groups or private messages that

00:43:51,269 --> 00:43:55,949
are more difficult so also that could be

00:43:53,400 --> 00:43:57,599
like the the banking direct if it

00:43:55,949 --> 00:43:59,519
doesn't really open the whole ecosystem

00:43:57,599 --> 00:44:01,559
it opens just one layer but that's

00:43:59,519 --> 00:44:05,249
already a big breakthrough right so we

00:44:01,559 --> 00:44:06,929
could take the similar approach all

00:44:05,249 --> 00:44:08,640
right I think that's all the time we

00:44:06,929 --> 00:44:11,099
have so big round of applause for our

00:44:08,640 --> 00:44:15,839
panelists today on stage right now and

00:44:11,099 --> 00:44:19,319
all day today that is our show this is

00:44:15,839 --> 00:44:22,859
the end of Mozilla Moss fest 2019 xavier

00:44:19,319 --> 00:44:23,580
harding and see you guys soon yeah

00:44:22,859 --> 00:44:25,849
thanks everybody

00:44:23,580 --> 00:44:25,849

YouTube URL: https://www.youtube.com/watch?v=F8ZdgFZOFac


