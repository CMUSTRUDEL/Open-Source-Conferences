Title: Data and Digital Rights in Asia | Amba Kak at MozFest 2018
Publication date: 2018-11-02
Playlist: MozFest 2018 - Dialogues and Debates
Description: 
	Amba Kak, policy advisor at Mozilla, speaks at MozFest 2018. Amba focuses on privacy, net neutrality and free speech in India. 

MozFest is Mozilla's seven-day celebration for, by, and about people who love the internet. Learn more: https://mozillafestival.org/
Captions: 
	00:00:00,020 --> 00:00:07,529
going to be introducing the stalkers the

00:00:04,200 --> 00:00:09,030
dogs and moderating the panels useful we

00:00:07,529 --> 00:00:12,240
know who I am I'm a journalist I work

00:00:09,030 --> 00:00:13,410
for the Economist here in London but as

00:00:12,240 --> 00:00:14,820
I see you even have to put up with me

00:00:13,410 --> 00:00:16,350
quite a bit over the next couple of days

00:00:14,820 --> 00:00:19,080
so I'm going to get out of your hair

00:00:16,350 --> 00:00:23,070
your first speaker is um baka

00:00:19,080 --> 00:00:25,439
she's a policy

00:00:23,070 --> 00:00:27,750
advisor of the policy advisor at Mozilla

00:00:25,439 --> 00:00:31,380
in Delhi she's going to talk to you

00:00:27,750 --> 00:00:32,580
about data protection in India the

00:00:31,380 --> 00:00:34,500
interesting thing about data protection

00:00:32,580 --> 00:00:37,350
in India which is going to tell you a

00:00:34,500 --> 00:00:39,239
greater length than I am is that it's

00:00:37,350 --> 00:00:42,239
not simply a matter of consumer

00:00:39,239 --> 00:00:45,510
protection it's also got to do with the

00:00:42,239 --> 00:00:48,660
tension between government and the tech

00:00:45,510 --> 00:00:52,010
giants and the argument I think that

00:00:48,660 --> 00:00:52,010
she's going to make is that

00:00:52,350 --> 00:00:56,579
most of us can get on board with

00:00:54,149 --> 00:00:59,550
reclaiming certain rights from tech

00:00:56,579 --> 00:01:02,430
giants no we may not necessarily be that

00:00:59,550 --> 00:01:03,780
comfortable with governments taking

00:01:02,430 --> 00:01:05,339
those rights and keeping them for

00:01:03,780 --> 00:01:07,409
themselves rather than distributing them

00:01:05,339 --> 00:01:14,520
to their citizens but I'm going to stop

00:01:07,409 --> 00:01:16,110
there and I am really happy to be here

00:01:14,520 --> 00:01:18,149
and I this is the first time I'm wearing

00:01:16,110 --> 00:01:24,030
a pretty mic as I was told this is

00:01:18,149 --> 00:01:26,100
called so yeah okay I'm gonna okay I'm

00:01:24,030 --> 00:01:28,710
gonna start with just asking the

00:01:26,100 --> 00:01:30,690
audience how many people here have been

00:01:28,710 --> 00:01:33,149
following or somewhat following the

00:01:30,690 --> 00:01:36,119
debate on privacy and data protection in

00:01:33,149 --> 00:01:39,960
India no judgement hey wow that was way

00:01:36,119 --> 00:01:41,460
more than acting but okay so I was

00:01:39,960 --> 00:01:43,380
thinking a little bit about what might

00:01:41,460 --> 00:01:45,210
might be interesting to convey to this

00:01:43,380 --> 00:01:48,240
audience particularly since many of you

00:01:45,210 --> 00:01:49,860
might not have the content and I do this

00:01:48,240 --> 00:01:52,130
quite often I'm often in spaces where

00:01:49,860 --> 00:01:54,750
I'm trying to communicate to people

00:01:52,130 --> 00:01:56,700
mostly in western audiences why what's

00:01:54,750 --> 00:01:59,009
happening in India or elsewhere in the

00:01:56,700 --> 00:02:00,270
world matters I mean it's 2018 and I

00:01:59,009 --> 00:02:02,460
still have to do this which is kind of

00:02:00,270 --> 00:02:04,920
sad but for that reason I was trying to

00:02:02,460 --> 00:02:07,380
figure out how could I explain what was

00:02:04,920 --> 00:02:09,299
going on in India as part of a small

00:02:07,380 --> 00:02:11,039
global narrative this global moment

00:02:09,299 --> 00:02:13,500
about privacy and data protection that

00:02:11,039 --> 00:02:16,109
were experiencing and so the story that

00:02:13,500 --> 00:02:18,480
I had come up with started with Facebook

00:02:16,109 --> 00:02:20,459
Cambridge analytical it was about how in

00:02:18,480 --> 00:02:22,170
March this year we were all almost

00:02:20,459 --> 00:02:24,690
globally it felt like there was this

00:02:22,170 --> 00:02:27,600
outrage his backlash hence the data

00:02:24,690 --> 00:02:29,820
practices of big technology platforms

00:02:27,600 --> 00:02:31,739
and in that outrage was this kind of

00:02:29,820 --> 00:02:33,540
recognition that you know the market the

00:02:31,739 --> 00:02:35,549
personal data wasn't going to fix itself

00:02:33,540 --> 00:02:38,370
and therefore if his governments they

00:02:35,549 --> 00:02:39,810
finally had to act and we saw this we

00:02:38,370 --> 00:02:41,940
saw this in the United States but we

00:02:39,810 --> 00:02:44,430
also saw this in Latin America in Brazil

00:02:41,940 --> 00:02:47,280
we saw it in Africa in Kenya we finally

00:02:44,430 --> 00:02:48,870
saw government's seem less reluctant and

00:02:47,280 --> 00:02:51,840
there was not as much inertia to

00:02:48,870 --> 00:02:54,490
actually act to pass general privacy

00:02:51,840 --> 00:02:57,160
rules that would apply to these company

00:02:54,490 --> 00:03:00,160
so in India the same sort of thing was

00:02:57,160 --> 00:03:02,410
happening in fact you saw in in just a

00:03:00,160 --> 00:03:04,360
period of a year you had the government

00:03:02,410 --> 00:03:06,220
Institute of Committee it was meant to

00:03:04,360 --> 00:03:07,990
draft this law they took feedback from

00:03:06,220 --> 00:03:09,700
the public and in less than a year they

00:03:07,990 --> 00:03:10,510
actually came out with a draft data

00:03:09,700 --> 00:03:13,510
protection law

00:03:10,510 --> 00:03:14,830
I will it's a draft it isn't and people

00:03:13,510 --> 00:03:18,010
are saying that it would go to

00:03:14,830 --> 00:03:20,020
Parliament as soon as this window so if

00:03:18,010 --> 00:03:21,310
you look at it is part of this global

00:03:20,020 --> 00:03:23,650
story it could seem that what's

00:03:21,310 --> 00:03:26,110
happening in India is simply kind of

00:03:23,650 --> 00:03:28,330
being born into and out of this gloom or

00:03:26,110 --> 00:03:30,490
Global moment and that's when you zoom

00:03:28,330 --> 00:03:33,220
out but if you would bear with me for

00:03:30,490 --> 00:03:36,040
the next 10 15 minutes I'm going to urge

00:03:33,220 --> 00:03:37,600
you to zoom in instead because when you

00:03:36,040 --> 00:03:39,760
look closely at what's happening in

00:03:37,600 --> 00:03:42,850
India what you see is a story of

00:03:39,760 --> 00:03:45,550
actually national politics national

00:03:42,850 --> 00:03:47,530
context intersecting and Inter playing

00:03:45,550 --> 00:03:49,240
with this global moon and I'm gonna

00:03:47,530 --> 00:03:50,980
explain what's happening with India's

00:03:49,240 --> 00:03:51,820
privacy law in terms of three

00:03:50,980 --> 00:03:55,000
developments

00:03:51,820 --> 00:03:58,030
the first is Aadhaar the government's

00:03:55,000 --> 00:04:00,550
national ID project the second is the

00:03:58,030 --> 00:04:03,550
gdpr which is your general data

00:04:00,550 --> 00:04:05,890
protection regulation and finally the

00:04:03,550 --> 00:04:08,590
what I call the Indian debt clash which

00:04:05,890 --> 00:04:10,840
is not so much a general angst against

00:04:08,590 --> 00:04:13,540
surveillance capitalism as it is a very

00:04:10,840 --> 00:04:15,970
specific angst about the fact that

00:04:13,540 --> 00:04:18,940
Western companies are exploiting the

00:04:15,970 --> 00:04:21,040
data of Indian citizens to the exclusion

00:04:18,940 --> 00:04:22,400
of Indian companies and the Indian

00:04:21,040 --> 00:04:26,330
government

00:04:22,400 --> 00:04:28,280
- let's start with I've had okay so I

00:04:26,330 --> 00:04:31,669
think again how many people in this room

00:04:28,280 --> 00:04:33,199
have heard something about other okay

00:04:31,669 --> 00:04:35,780
quite a few but for those who don't

00:04:33,199 --> 00:04:37,790
it's odd hi is the name for the

00:04:35,780 --> 00:04:40,729
government's national biometric ID

00:04:37,790 --> 00:04:43,400
project it's a project that assigned a

00:04:40,729 --> 00:04:45,740
12-digit number every Indian resident

00:04:43,400 --> 00:04:47,990
and that number was linked to be

00:04:45,740 --> 00:04:51,410
biometric demographic information which

00:04:47,990 --> 00:04:54,470
included your fingerprints and iris cap

00:04:51,410 --> 00:04:56,570
now the odd high number and and the

00:04:54,470 --> 00:04:58,520
biometric technology is not being used

00:04:56,570 --> 00:05:00,980
just by governments to deliver services

00:04:58,520 --> 00:05:02,840
it was being increasingly used by all

00:05:00,980 --> 00:05:04,970
kinds of private companies and it was

00:05:02,840 --> 00:05:07,130
being inserted into the databases of

00:05:04,970 --> 00:05:08,900
these companies so you had banks asking

00:05:07,130 --> 00:05:11,210
for your telecom companies asking for it

00:05:08,900 --> 00:05:13,070
even Amazon asking for it attack lost

00:05:11,210 --> 00:05:14,900
packages so it was it was kind of the

00:05:13,070 --> 00:05:17,780
Wild West and it did something very

00:05:14,900 --> 00:05:19,760
important in India it took the

00:05:17,780 --> 00:05:21,710
conversation about privacy which was

00:05:19,760 --> 00:05:24,230
considered to be this issue that only

00:05:21,710 --> 00:05:26,930
affected the urban the online the illy

00:05:24,230 --> 00:05:29,300
and it made it clear that this was a

00:05:26,930 --> 00:05:31,460
project this was a technology and this

00:05:29,300 --> 00:05:34,280
was a data driven technology that was

00:05:31,460 --> 00:05:37,460
affecting every Indian resident rich or

00:05:34,280 --> 00:05:39,020
poor urban or rural and it was not just

00:05:37,460 --> 00:05:40,610
a the the fact that they were actually

00:05:39,020 --> 00:05:42,890
interacting with technology for the

00:05:40,610 --> 00:05:44,870
first time it was also the fact that the

00:05:42,890 --> 00:05:47,210
Saffir of surveillance the fear of being

00:05:44,870 --> 00:05:49,070
tracked across your government across

00:05:47,210 --> 00:05:51,170
your interactions with both government

00:05:49,070 --> 00:05:53,620
and private services it really created a

00:05:51,170 --> 00:05:55,930
real fear of surveillance

00:05:53,620 --> 00:05:58,600
it made it clear the data protection was

00:05:55,930 --> 00:06:00,400
not simply about protecting data but

00:05:58,600 --> 00:06:02,020
about protecting people and therefore it

00:06:00,400 --> 00:06:04,780
had to be a conversation that we were

00:06:02,020 --> 00:06:07,030
having and that we were having now it

00:06:04,780 --> 00:06:09,460
also helped that a lot of the legal

00:06:07,030 --> 00:06:10,990
challenges the other project were that

00:06:09,460 --> 00:06:13,720
they were violation of our right to

00:06:10,990 --> 00:06:15,729
privacy so was a single biometric

00:06:13,720 --> 00:06:18,310
identifier that followed me across my

00:06:15,729 --> 00:06:20,169
public and private services simply

00:06:18,310 --> 00:06:23,410
creating a dossier that was available

00:06:20,169 --> 00:06:26,260
for tracking and profiling was the fact

00:06:23,410 --> 00:06:29,620
that the sensitive personal data of 1.2

00:06:26,260 --> 00:06:31,930
billion Indians was in one database was

00:06:29,620 --> 00:06:33,760
that safe was that secure so it kind of

00:06:31,930 --> 00:06:35,680
kicked started this conversation and the

00:06:33,760 --> 00:06:38,350
Government of India in infinite wisdom

00:06:35,680 --> 00:06:40,510
came to the Supreme Court and argued the

00:06:38,350 --> 00:06:42,820
Indians in fact did not have a right to

00:06:40,510 --> 00:06:44,260
privacy because the term privacy didn't

00:06:42,820 --> 00:06:45,729
really figure in the Constitution we

00:06:44,260 --> 00:06:48,100
couldn't find it anywhere and so hence

00:06:45,729 --> 00:06:50,380
through the Supreme Court not only

00:06:48,100 --> 00:06:52,690
disagreed with them but they in really a

00:06:50,380 --> 00:06:54,760
judgment for the ages they said its

00:06:52,690 --> 00:06:57,100
Indians do have a fundamental right to

00:06:54,760 --> 00:06:59,110
privacy in fact this type of privacy is

00:06:57,100 --> 00:07:01,060
kind of fundamental to the exercise of

00:06:59,110 --> 00:07:03,520
any other right but they went even

00:07:01,060 --> 00:07:06,220
further they argued that the government

00:07:03,520 --> 00:07:08,680
had to act to protect Indians from both

00:07:06,220 --> 00:07:10,690
the government and private companies and

00:07:08,680 --> 00:07:13,240
their shares privacy

00:07:10,690 --> 00:07:14,830
so here we are I mean the there was

00:07:13,240 --> 00:07:16,210
clear guidance from the Supreme Court to

00:07:14,830 --> 00:07:17,920
pass a law and now the government is

00:07:16,210 --> 00:07:19,570
moving but what we're seeing is that

00:07:17,920 --> 00:07:21,940
there's a lot of backlash and a

00:07:19,570 --> 00:07:24,400
criticism a main criticism through this

00:07:21,940 --> 00:07:26,410
bill is that it isn't as tough on

00:07:24,400 --> 00:07:28,990
government as it is on private company

00:07:26,410 --> 00:07:30,820
and it's because this bill has really

00:07:28,990 --> 00:07:33,100
been triggered by this context the

00:07:30,820 --> 00:07:35,500
people are really unhappy about so two

00:07:33,100 --> 00:07:37,600
things one the fact that this bill does

00:07:35,500 --> 00:07:39,580
not require the government to ask for

00:07:37,600 --> 00:07:41,620
consent but a large number of services

00:07:39,580 --> 00:07:43,870
and the second that the body that's

00:07:41,620 --> 00:07:45,400
supposed to enforce this law doesn't

00:07:43,870 --> 00:07:48,550
seem like it's sufficiently independent

00:07:45,400 --> 00:07:50,830
from the government is that so so that's

00:07:48,550 --> 00:07:53,260
that's the first piece of this the first

00:07:50,830 --> 00:07:54,820
piece of this but the second is what I

00:07:53,260 --> 00:08:00,460
think many more people might be familiar

00:07:54,820 --> 00:08:03,640
with which is the gdpr

00:08:00,460 --> 00:08:06,070
so on May 25th I'm sure many of us here

00:08:03,640 --> 00:08:08,140
and not just the Europeans many of us

00:08:06,070 --> 00:08:09,970
non Europeans - must have got a lot of

00:08:08,140 --> 00:08:11,500
emails in our inbox they were telling us

00:08:09,970 --> 00:08:13,450
that their privacy companies were

00:08:11,500 --> 00:08:15,760
letting us know their privacy policies

00:08:13,450 --> 00:08:17,620
have changed maybe they were offering

00:08:15,760 --> 00:08:20,860
you the option to opt out or even delete

00:08:17,620 --> 00:08:23,140
your data and that's the cause and

00:08:20,860 --> 00:08:25,210
that's because the law for a lot of

00:08:23,140 --> 00:08:27,340
companies it made sense to kind of apply

00:08:25,210 --> 00:08:29,440
the the chain that changed privacy

00:08:27,340 --> 00:08:31,710
protections globally rather than kind of

00:08:29,440 --> 00:08:33,540
localized mpro

00:08:31,710 --> 00:08:36,210
but that's not the global impact that I

00:08:33,540 --> 00:08:38,670
want to actually stress on today if you

00:08:36,210 --> 00:08:40,470
look at India's data protection bill the

00:08:38,670 --> 00:08:42,390
draft bill that out in the public you

00:08:40,470 --> 00:08:44,370
see that a large chunk of it and

00:08:42,390 --> 00:08:46,500
particularly the strong bill bits that

00:08:44,370 --> 00:08:49,350
put obligations on companies and the

00:08:46,500 --> 00:08:52,590
government almost mirror that of the GDP

00:08:49,350 --> 00:08:55,110
ah and that itself might not be in fact

00:08:52,590 --> 00:08:56,580
government's borrow from each other all

00:08:55,110 --> 00:08:58,530
the time when they're formulating laws

00:08:56,580 --> 00:09:00,720
but the interesting thing about it is

00:08:58,530 --> 00:09:03,480
that the GDP are actually provided a

00:09:00,720 --> 00:09:05,640
reason for Indian companies to advocate

00:09:03,480 --> 00:09:08,220
for strong rule so you heard that right

00:09:05,640 --> 00:09:10,080
often I found unlikely allies in the

00:09:08,220 --> 00:09:12,990
Indian IT industry because they were

00:09:10,080 --> 00:09:14,400
like we also on strong privacy rules and

00:09:12,990 --> 00:09:16,680
if that doesn't make sense to you I'm

00:09:14,400 --> 00:09:18,720
going to kind of explain why one of the

00:09:16,680 --> 00:09:20,840
main reasons is that the European

00:09:18,720 --> 00:09:23,580
Commission was clear that there could be

00:09:20,840 --> 00:09:25,590
transfer of personal data between Europe

00:09:23,580 --> 00:09:27,780
and the rest of the world no problem it

00:09:25,590 --> 00:09:29,790
could be unrestricted the only condition

00:09:27,780 --> 00:09:31,440
was that these countries had to have

00:09:29,790 --> 00:09:34,050
what they called adequate data

00:09:31,440 --> 00:09:36,240
protection and they would decide when

00:09:34,050 --> 00:09:38,520
the particular laws were adequate and so

00:09:36,240 --> 00:09:40,620
for a lot of Indian IT companies this if

00:09:38,520 --> 00:09:42,470
India had strong rules this was an

00:09:40,620 --> 00:09:44,610
opportunity to open up new markets

00:09:42,470 --> 00:09:46,350
currently they were treated often with

00:09:44,610 --> 00:09:48,150
suspicion particularly with with respect

00:09:46,350 --> 00:09:50,100
to their data practices but suddenly

00:09:48,150 --> 00:09:52,200
there was the possibility of opening up

00:09:50,100 --> 00:09:53,370
this Numa

00:09:52,200 --> 00:09:55,620
and for companies that were already

00:09:53,370 --> 00:09:57,480
global like I mentioned it was even more

00:09:55,620 --> 00:09:59,790
of a no-brainer right because you are

00:09:57,480 --> 00:10:01,650
already providing these protections in

00:09:59,790 --> 00:10:03,420
for the European market so it wouldn't

00:10:01,650 --> 00:10:05,010
take a lot to kind of replicate that

00:10:03,420 --> 00:10:07,590
globally as long as the rules were

00:10:05,010 --> 00:10:09,840
similar I think just uh I think just a

00:10:07,590 --> 00:10:11,670
few days ago Tim Cook announced that he

00:10:09,840 --> 00:10:13,290
thought that the GDP I was a great law

00:10:11,670 --> 00:10:13,740
and in fact that laws like this should

00:10:13,290 --> 00:10:16,280
be passed

00:10:13,740 --> 00:10:16,280
everywhere

00:10:20,670 --> 00:10:25,320
and so the final way in which I think

00:10:23,010 --> 00:10:27,630
the gdpr has really been a trigger wa

00:10:25,320 --> 00:10:29,610
it's really been a trigger for the

00:10:27,630 --> 00:10:31,530
indian data protection law is that it's

00:10:29,610 --> 00:10:33,120
been out there in the public domain for

00:10:31,530 --> 00:10:35,580
several years now even though it was

00:10:33,120 --> 00:10:36,930
enforced only in May and so so for not

00:10:35,580 --> 00:10:38,520
just the Indian government but for other

00:10:36,930 --> 00:10:40,080
governments that are currently drafting

00:10:38,520 --> 00:10:42,150
their privacy laws they can look to

00:10:40,080 --> 00:10:45,890
Europe's decades of experience and

00:10:42,150 --> 00:10:45,890
expertise to draft their own

00:10:46,230 --> 00:10:50,910
which brings me to the third part of the

00:10:48,720 --> 00:10:55,110
story which is what I call the Indian

00:10:50,910 --> 00:10:58,170
debt lash now 20% only 20 percent of

00:10:55,110 --> 00:11:01,260
India's pop 1.2 or 1.3 billion plus

00:10:58,170 --> 00:11:03,810
population is online but remember that

00:11:01,260 --> 00:11:06,110
we are already one of if not the largest

00:11:03,810 --> 00:11:09,000
market for many of these tech companies

00:11:06,110 --> 00:11:10,740
nevermind the fact that the financial

00:11:09,000 --> 00:11:13,200
capacity of many of these users is

00:11:10,740 --> 00:11:15,510
severely restricted the important thing

00:11:13,200 --> 00:11:18,150
is if it's the data of the next billion

00:11:15,510 --> 00:11:20,550
that's up for grabs but it isn't just

00:11:18,150 --> 00:11:23,600
big tech companies that have identified

00:11:20,550 --> 00:11:23,600
this potential

00:11:23,880 --> 00:11:28,680
India will be data rich before it's

00:11:26,459 --> 00:11:30,509
economically rich we were told by one of

00:11:28,680 --> 00:11:33,930
India's leading industrialists and the

00:11:30,509 --> 00:11:36,480
chief architect of ad hull he argued as

00:11:33,930 --> 00:11:38,639
several other influential voices did

00:11:36,480 --> 00:11:40,199
why should Western companies get to

00:11:38,639 --> 00:11:41,970
exploit the data of Indian citizens

00:11:40,199 --> 00:11:44,730
without contributing back to the

00:11:41,970 --> 00:11:46,980
domestic economy instead we need to take

00:11:44,730 --> 00:11:48,870
back control of personal data from these

00:11:46,980 --> 00:11:51,660
Western companies and restore that

00:11:48,870 --> 00:11:53,850
control to well actually that's what's

00:11:51,660 --> 00:11:56,130
not clear it's not clear who the control

00:11:53,850 --> 00:11:57,690
is being restored to but there's a lot

00:11:56,130 --> 00:11:59,759
of rhetoric so I'll take you through the

00:11:57,690 --> 00:12:02,899
two big rhetorical devices that are

00:11:59,759 --> 00:12:05,430
being used in this - the first data

00:12:02,899 --> 00:12:07,560
colonization now remember that India is

00:12:05,430 --> 00:12:10,769
still relatively young country we've

00:12:07,560 --> 00:12:12,720
been 70 audio's independent and so the

00:12:10,769 --> 00:12:15,149
rhetoric of colonization is both

00:12:12,720 --> 00:12:17,190
inflammatory as it is provocative and

00:12:15,149 --> 00:12:19,560
what we're hearing is that these Western

00:12:17,190 --> 00:12:21,509
tech companies are obviously treating

00:12:19,560 --> 00:12:22,920
India as a large untapped market but

00:12:21,509 --> 00:12:25,769
they're not investing back into the

00:12:22,920 --> 00:12:29,399
domestic economy so the obvious response

00:12:25,769 --> 00:12:31,710
the argument goes is data sovereignty or

00:12:29,399 --> 00:12:34,500
data nationalism

00:12:31,710 --> 00:12:36,990
which is essentially about putting forth

00:12:34,500 --> 00:12:39,360
the idea the personal data of citizens

00:12:36,990 --> 00:12:41,880
should be a national resource a public

00:12:39,360 --> 00:12:44,220
resource so the one of the officials of

00:12:41,880 --> 00:12:46,860
India's ruling party recently announced

00:12:44,220 --> 00:12:48,600
that if the BJP was elected again in the

00:12:46,860 --> 00:12:51,690
next elections then we would see a

00:12:48,600 --> 00:12:53,550
hundred percent data sovereignity now if

00:12:51,690 --> 00:12:54,810
it isn't clear what any of this actually

00:12:53,550 --> 00:12:57,360
means in terms of policy proposals

00:12:54,810 --> 00:12:59,399
that's kind of by design and in fact it

00:12:57,360 --> 00:13:01,680
is only the data protection bill that

00:12:59,399 --> 00:13:04,200
started to give us some clues about what

00:13:01,680 --> 00:13:05,940
this policy vision really meant so this

00:13:04,200 --> 00:13:07,890
data protection bill includes a

00:13:05,940 --> 00:13:09,959
provision which says that the personal

00:13:07,890 --> 00:13:12,149
data of Indians should be stored

00:13:09,959 --> 00:13:14,970
physically in the country rather than in

00:13:12,149 --> 00:13:16,440
servers elsewhere and so there are many

00:13:14,970 --> 00:13:18,570
reasons that folks from civil society

00:13:16,440 --> 00:13:20,190
and others have spoken up against this

00:13:18,570 --> 00:13:22,020
they've said that this leads to easier

00:13:20,190 --> 00:13:23,640
government surveillance the business

00:13:22,020 --> 00:13:25,770
community thinks it means increased

00:13:23,640 --> 00:13:27,680
costs but I'd urge you to see this as

00:13:25,770 --> 00:13:30,450
part again as part of a bigger story

00:13:27,680 --> 00:13:32,700
which is that and and this was because

00:13:30,450 --> 00:13:34,860
very soon after the Data Protection bill

00:13:32,700 --> 00:13:36,690
there was another draft policy that was

00:13:34,860 --> 00:13:38,459
leaked into the public domain where the

00:13:36,690 --> 00:13:40,980
government argued that not only should

00:13:38,459 --> 00:13:43,589
Lok Data be localized and put in India

00:13:40,980 --> 00:13:45,750
it should be made accessible to both the

00:13:43,589 --> 00:13:48,720
Indian government and select Indian

00:13:45,750 --> 00:13:52,050
companies so now imagine this idea of

00:13:48,720 --> 00:13:54,480
data as a state owned resource available

00:13:52,050 --> 00:13:56,279
to state lest enterprise it might sound

00:13:54,480 --> 00:13:58,529
like a lot like out of the Chinese

00:13:56,279 --> 00:14:01,110
playbook and the very obvious reasons

00:13:58,529 --> 00:14:03,510
China is both an attractive and a very

00:14:01,110 --> 00:14:05,130
deeply uncomfortable example for India

00:14:03,510 --> 00:14:06,780
which is firmly a constitutional

00:14:05,130 --> 00:14:10,050
democracy

00:14:06,780 --> 00:14:11,670
so here we are India's proposed data

00:14:10,050 --> 00:14:12,990
protection law is clearly like I've

00:14:11,670 --> 00:14:14,430
explained being pulled in these

00:14:12,990 --> 00:14:18,150
different directions sometimes

00:14:14,430 --> 00:14:20,490
contradictory directions so will the

00:14:18,150 --> 00:14:22,740
data protection law actually limit the

00:14:20,490 --> 00:14:24,870
type kind of unchecked data extraction

00:14:22,740 --> 00:14:27,600
we've been seeing from companies and the

00:14:24,870 --> 00:14:30,090
government or will it simply become the

00:14:27,600 --> 00:14:32,580
foundation for a state-led vision of the

00:14:30,090 --> 00:14:35,100
digital economy where our personal data

00:14:32,580 --> 00:14:37,950
is once again a resource for the taking

00:14:35,100 --> 00:14:39,390
I think globally as we're looking to

00:14:37,950 --> 00:14:41,820
governments to try and rescue us from

00:14:39,390 --> 00:14:44,160
big day there are important lessons here

00:14:41,820 --> 00:14:47,010
the lesson is that we always run the

00:14:44,160 --> 00:14:48,990
risk of letting collective interest be

00:14:47,010 --> 00:14:51,330
defined simply as government interest

00:14:48,990 --> 00:14:53,430
and I don't and and given that law

00:14:51,330 --> 00:14:55,620
making processes everywhere are becoming

00:14:53,430 --> 00:14:58,290
more and more opaque and unaccountable

00:14:55,620 --> 00:15:00,750
this is a real worry but I don't suggest

00:14:58,290 --> 00:15:02,640
for a moment that we give up either on

00:15:00,750 --> 00:15:04,320
the government or even on law in fact I

00:15:02,640 --> 00:15:06,180
still believe that law is one of the

00:15:04,320 --> 00:15:08,040
most powerful instruments we have for

00:15:06,180 --> 00:15:10,860
collective action

00:15:08,040 --> 00:15:12,810
instead I think the lesson here if any

00:15:10,860 --> 00:15:15,540
is that the citizens voice in this

00:15:12,810 --> 00:15:18,180
debate matters more than ever to show up

00:15:15,540 --> 00:15:20,670
to prevent the co-option of language to

00:15:18,180 --> 00:15:22,980
kind of create a space where the battle

00:15:20,670 --> 00:15:25,529
for personal data is not reduced to a

00:15:22,980 --> 00:15:30,470
battle between and the choice between

00:15:25,529 --> 00:15:30,470
big day and the big date thank you

00:15:33,410 --> 00:15:38,209
you

00:15:35,300 --> 00:15:39,620
um there's also somebody wandering

00:15:38,209 --> 00:15:41,209
around with a mic if you want to ask

00:15:39,620 --> 00:15:43,310
questions just raise your hand somebody

00:15:41,209 --> 00:15:45,290
will come to you I just asked you don't

00:15:43,310 --> 00:15:46,610
start talking until somebody comes to

00:15:45,290 --> 00:15:49,450
you with a mic because then nobody's

00:15:46,610 --> 00:15:49,450
going to be able to hear you

00:15:58,930 --> 00:16:00,990
you

00:16:06,740 --> 00:16:11,630
so if the Indian government is

00:16:09,620 --> 00:16:14,990
advocating for localization of these

00:16:11,630 --> 00:16:17,810
data storage spaces in India it's kind

00:16:14,990 --> 00:16:20,660
of assuming that just by not allowing

00:16:17,810 --> 00:16:23,000
for example us-based their companies to

00:16:20,660 --> 00:16:24,950
exploit this data it doesn't necessarily

00:16:23,000 --> 00:16:28,370
mean that Indian companies won't do that

00:16:24,950 --> 00:16:30,440
in the future right so it may be

00:16:28,370 --> 00:16:33,290
nationalism but how do you guarantee

00:16:30,440 --> 00:16:35,570
that it's not the same Indian entities

00:16:33,290 --> 00:16:37,370
do the same in the like five years ten

00:16:35,570 --> 00:16:38,900
years at the line I mean I mean you I

00:16:37,370 --> 00:16:40,280
couldn't put it better myself so that's

00:16:38,900 --> 00:16:42,500
exactly what I'm trying to say that I

00:16:40,280 --> 00:16:44,360
think we need to prevent like the term

00:16:42,500 --> 00:16:46,070
nationalism from being used to assume

00:16:44,360 --> 00:16:47,540
that it's in the interests of users and

00:16:46,070 --> 00:16:49,010
really argue like what are those

00:16:47,540 --> 00:16:51,110
protections that will protect us from

00:16:49,010 --> 00:16:53,890
all threats to privacy whether private

00:16:51,110 --> 00:16:53,890
or government

00:16:59,920 --> 00:17:01,980
you

00:17:09,880 --> 00:17:14,199
a lot of people in India though of sort

00:17:13,240 --> 00:17:18,130
of national image

00:17:14,199 --> 00:17:21,480
to be practiced at Marting Turman have

00:17:18,130 --> 00:17:26,380
stricter taxes so with only 20%

00:17:21,480 --> 00:17:29,500
access um in India and the government

00:17:26,380 --> 00:17:30,130
not necessarily in investing in tables

00:17:29,500 --> 00:17:33,279
on the ground

00:17:30,130 --> 00:17:34,690
um how do you think that impacts if

00:17:33,279 --> 00:17:37,330
they've protection because in a sense

00:17:34,690 --> 00:17:39,070
comp take the data for completely

00:17:37,330 --> 00:17:41,980
external entities actually providing

00:17:39,070 --> 00:17:46,150
means now actors in first

00:17:41,980 --> 00:17:47,950
so red flag because I'm sure maybe you

00:17:46,150 --> 00:17:49,480
haven't heard but actually when Facebook

00:17:47,950 --> 00:17:52,000
was trying to launch what they called

00:17:49,480 --> 00:17:53,680
free basics or internet.org and be that

00:17:52,000 --> 00:17:54,640
vehicle to provide a certain kind of

00:17:53,680 --> 00:17:56,230
internet access

00:17:54,640 --> 00:17:57,670
the Indian government the telecom

00:17:56,230 --> 00:17:59,680
regulator actually came down very

00:17:57,670 --> 00:18:01,660
strongly they said yes we have a huge

00:17:59,680 --> 00:18:03,940
connectivity problem we have a very far

00:18:01,660 --> 00:18:05,350
way to go but we don't want to make it

00:18:03,940 --> 00:18:07,540
so that we're kind of seeding this

00:18:05,350 --> 00:18:09,430
responsibility necessarily to private

00:18:07,540 --> 00:18:11,020
companies and we want to make sure and

00:18:09,430 --> 00:18:12,940
it's not just connectivity but what

00:18:11,020 --> 00:18:14,140
we're connecting to that matters and I

00:18:12,940 --> 00:18:16,150
think this is a running theme in

00:18:14,140 --> 00:18:17,620
Internet policy in India in some ways

00:18:16,150 --> 00:18:19,600
we've really been at the forefront of

00:18:17,620 --> 00:18:21,550
trying to argue that just because we

00:18:19,600 --> 00:18:23,020
have developmental challenges doesn't

00:18:21,550 --> 00:18:24,670
mean that we can argue for this kind of

00:18:23,020 --> 00:18:26,320
phasing of rights like we'll think of

00:18:24,670 --> 00:18:29,140
connectivity now and we'll think of free

00:18:26,320 --> 00:18:31,000
speech and and you know a net neutrality

00:18:29,140 --> 00:18:32,830
and competition next we've argued that

00:18:31,000 --> 00:18:35,140
we didn't necessarily need to think of

00:18:32,830 --> 00:18:36,640
these issues together and particularly

00:18:35,140 --> 00:18:38,740
on privacy it's interesting we're having

00:18:36,640 --> 00:18:41,050
that same conversation because not just

00:18:38,740 --> 00:18:43,060
is you know a small percentage of the

00:18:41,050 --> 00:18:44,650
population online several of them are

00:18:43,060 --> 00:18:47,080
not literate and not literate in English

00:18:44,650 --> 00:18:49,540
and so we're pushing to argue that we

00:18:47,080 --> 00:18:51,850
need it's not okay to just rely on the

00:18:49,540 --> 00:18:53,830
after effects of GDP our we need a law

00:18:51,850 --> 00:18:55,690
that incentivizes people to speak to

00:18:53,830 --> 00:18:57,940
these new users who have different needs

00:18:55,690 --> 00:18:59,890
and may really make them send meaningful

00:18:57,940 --> 00:19:02,040
for these populations that are coming

00:18:59,890 --> 00:19:02,040
online

00:19:02,320 --> 00:19:07,149
hi

00:19:03,700 --> 00:19:09,429
salat or the talk I wanted to ask a

00:19:07,149 --> 00:19:13,210
little bit about something that you

00:19:09,429 --> 00:19:16,350
didn't mention but a while ago I was

00:19:13,210 --> 00:19:20,590
following at a distance the move towards

00:19:16,350 --> 00:19:23,529
or the push in India towards a digital

00:19:20,590 --> 00:19:25,990
infrastructure for money and I'm

00:19:23,529 --> 00:19:29,279
wondering whether you have any comments

00:19:25,990 --> 00:19:32,860
about how this raft of new legislation

00:19:29,279 --> 00:19:36,490
relates to this kind of strong push

00:19:32,860 --> 00:19:40,659
towards cashless honest in in India and

00:19:36,490 --> 00:19:44,519
and if not that specific situation then

00:19:40,659 --> 00:19:49,409
maybe you could expand a bit on you know

00:19:44,519 --> 00:19:54,220
what kind of initiatives does this

00:19:49,409 --> 00:19:58,850
framework impact on what kinds of data

00:19:54,220 --> 00:20:00,440
is is at stake Thanks

00:19:58,850 --> 00:20:03,320
I'll answer this question in two parts

00:20:00,440 --> 00:20:05,539
so first like as context everybody else

00:20:03,320 --> 00:20:07,279
there has been a very big push in India

00:20:05,539 --> 00:20:09,320
towards the cashless economy and there

00:20:07,279 --> 00:20:11,330
are a lot of FinTech companies that are

00:20:09,320 --> 00:20:12,740
growing in India and the debate there is

00:20:11,330 --> 00:20:14,539
actually very similar to the one that's

00:20:12,740 --> 00:20:16,820
happening on Aadhaar it's a question of

00:20:14,539 --> 00:20:18,830
we won't believe that technology will

00:20:16,820 --> 00:20:21,350
make things better just because you say

00:20:18,830 --> 00:20:23,090
it's so and we have to see eat people

00:20:21,350 --> 00:20:24,889
where they are and actually ask them

00:20:23,090 --> 00:20:26,899
what's convenient to them so yes

00:20:24,889 --> 00:20:28,580
technology is great and moving digital

00:20:26,899 --> 00:20:30,259
is great but to the extent that it's

00:20:28,580 --> 00:20:32,659
empowering to people and it has created

00:20:30,259 --> 00:20:34,580
a debate around that particularly after

00:20:32,659 --> 00:20:36,620
the monetization when many people had

00:20:34,580 --> 00:20:38,450
very few choices and and cash was in

00:20:36,620 --> 00:20:40,039
short supply but I think it's

00:20:38,450 --> 00:20:42,620
interesting on how this conversation

00:20:40,039 --> 00:20:44,090
relates to data protection specifically

00:20:42,620 --> 00:20:46,100
actually payment companies have been

00:20:44,090 --> 00:20:47,809
mandated to store that data in India

00:20:46,100 --> 00:20:49,220
it's been understood that payment

00:20:47,809 --> 00:20:51,200
information is extremely sensitive

00:20:49,220 --> 00:20:53,269
personal information and therefore

00:20:51,200 --> 00:20:55,100
should be put at a higher standard so I

00:20:53,269 --> 00:20:56,629
think in general there's a kind of

00:20:55,100 --> 00:20:58,279
worried that the FinTech market is

00:20:56,629 --> 00:21:00,769
growing and it's another kind of wild

00:20:58,279 --> 00:21:02,539
wild west of applications which we

00:21:00,769 --> 00:21:04,070
aren't sure we can trust and the data

00:21:02,539 --> 00:21:05,779
protection law I think will go a long

00:21:04,070 --> 00:21:07,639
way to making sure that the ground rules

00:21:05,779 --> 00:21:09,289
or that game are set in some way

00:21:07,639 --> 00:21:12,129
especially if we ensure that we have a

00:21:09,289 --> 00:21:12,129
good and strong law

00:21:18,290 --> 00:21:20,350
you

00:21:22,600 --> 00:21:28,140
No

00:21:24,360 --> 00:21:30,270
um you've talked to India

00:21:28,140 --> 00:21:33,950
number of advantages that lots of other

00:21:30,270 --> 00:21:35,840
countries don't but a giant market big

00:21:33,950 --> 00:21:38,659
interested in and therefore will toe the

00:21:35,840 --> 00:21:39,889
line to a certain degree it as as you

00:21:38,659 --> 00:21:41,720
mentioned a robust Constitution

00:21:39,889 --> 00:21:45,409
democracy a strong civil service a

00:21:41,720 --> 00:21:47,640
strong three from civil society also

00:21:45,409 --> 00:21:49,950
strong civil service for that matter

00:21:47,640 --> 00:21:51,480
what about lots of other poor countries

00:21:49,950 --> 00:21:53,640
that don't enjoy all these advantages

00:21:51,480 --> 00:21:55,710
how did they what can they learn from

00:21:53,640 --> 00:21:58,140
India as poor countries but without

00:21:55,710 --> 00:22:00,660
these advantages that's a great point I

00:21:58,140 --> 00:22:02,190
think when India you know ruled against

00:22:00,660 --> 00:22:04,230
Facebook three basics we were kind of

00:22:02,190 --> 00:22:05,610
looking at how similar programs were

00:22:04,230 --> 00:22:07,680
being rolled out in large parts of

00:22:05,610 --> 00:22:09,600
Africa with little to no resistance and

00:22:07,680 --> 00:22:11,310
the question was why and the answer that

00:22:09,600 --> 00:22:13,560
we reached was the fact that we had a

00:22:11,310 --> 00:22:15,810
strong digital rights community and a

00:22:13,560 --> 00:22:17,430
strong civil society but we also found

00:22:15,810 --> 00:22:19,920
that shortly after that in the years

00:22:17,430 --> 00:22:21,720
following we did see after-effects of

00:22:19,920 --> 00:22:23,580
the Indian experience being ported to

00:22:21,720 --> 00:22:25,110
lawmakers elsewhere and maybe giving

00:22:23,580 --> 00:22:26,910
them the kind of affirmation that is

00:22:25,110 --> 00:22:28,590
again like I said it wasn't enough to

00:22:26,910 --> 00:22:30,210
just say these are developing countries

00:22:28,590 --> 00:22:31,710
connectivity is the biggest problem

00:22:30,210 --> 00:22:33,600
because clearly India is one of the

00:22:31,710 --> 00:22:35,760
world's as the world's largest democracy

00:22:33,600 --> 00:22:37,470
was doing was kind of taking a stand on

00:22:35,760 --> 00:22:38,970
internet policy and maybe even

00:22:37,470 --> 00:22:40,980
fashioning themselves as a kind of

00:22:38,970 --> 00:22:42,540
leader in Internet policy so I guess the

00:22:40,980 --> 00:22:44,280
short answer to your question is I think

00:22:42,540 --> 00:22:46,470
both with the data protection law but

00:22:44,280 --> 00:22:48,450
more generally India does enjoy a

00:22:46,470 --> 00:22:50,070
position of leadership and that makes it

00:22:48,450 --> 00:22:52,460
all the more important that we get this

00:22:50,070 --> 00:22:52,460
one right

00:22:58,540 --> 00:23:02,430
you

00:23:00,450 --> 00:23:04,110
they're kind of following up on previous

00:23:02,430 --> 00:23:05,130
question about how these how companies

00:23:04,110 --> 00:23:07,560
are actually providing the

00:23:05,130 --> 00:23:09,510
infrastructure for the rest of the 80%

00:23:07,560 --> 00:23:11,970
of the population that doesn't like have

00:23:09,510 --> 00:23:13,680
the connectivity right and I guess now a

00:23:11,970 --> 00:23:16,670
lot of these tech companies and even

00:23:13,680 --> 00:23:18,780
large banks have huge banker offices and

00:23:16,670 --> 00:23:21,140
because infrastructure is a big problem

00:23:18,780 --> 00:23:22,980
they're not just supporting these

00:23:21,140 --> 00:23:25,730
connectivity infrastructure but also

00:23:22,980 --> 00:23:29,040
growth and trains and everything so for

00:23:25,730 --> 00:23:30,570
for these local citizens who have who

00:23:29,040 --> 00:23:32,760
are benefitting directly from this

00:23:30,570 --> 00:23:35,880
public infrastructure not just internet

00:23:32,760 --> 00:23:38,850
for them they might have not a big

00:23:35,880 --> 00:23:41,550
rationale to vote against these tech

00:23:38,850 --> 00:23:44,280
companies utilizing their data let alone

00:23:41,550 --> 00:23:47,010
say they don't have connectivity from

00:23:44,280 --> 00:23:48,690
like the start so how do you how do you

00:23:47,010 --> 00:23:51,210
think is a good way to educate the

00:23:48,690 --> 00:23:53,760
public that these companies although you

00:23:51,210 --> 00:23:56,460
may be seeing some direct benefits they

00:23:53,760 --> 00:23:59,220
today you also have to fight for your

00:23:56,460 --> 00:24:01,350
privacy and data protection I don't

00:23:59,220 --> 00:24:03,480
think that anyone's trying to kind of

00:24:01,350 --> 00:24:04,800
malign tech companies for the sake of it

00:24:03,480 --> 00:24:05,910
and be like you know get out of the

00:24:04,800 --> 00:24:07,560
country I mean there might be a few

00:24:05,910 --> 00:24:09,090
people like I mentioned who might feel

00:24:07,560 --> 00:24:10,770
that way but I don't think that's where

00:24:09,090 --> 00:24:12,780
the conversation is headed it's like

00:24:10,770 --> 00:24:14,850
elsewhere it's just about ensuring that

00:24:12,780 --> 00:24:16,800
companies are responsible with the use

00:24:14,850 --> 00:24:18,570
of the data of Indian Indian residents

00:24:16,800 --> 00:24:20,580
so yes there might be many external

00:24:18,570 --> 00:24:22,260
benefits that are coming in to your

00:24:20,580 --> 00:24:24,150
point about how do we talk to people I

00:24:22,260 --> 00:24:26,040
think that there's actually you know

00:24:24,150 --> 00:24:27,450
there it might it's the global mood it's

00:24:26,040 --> 00:24:29,460
as high that conversation is actually

00:24:27,450 --> 00:24:31,770
rapidly increasing in India you don't

00:24:29,460 --> 00:24:33,360
even have to explain to people why we

00:24:31,770 --> 00:24:35,040
shouldn't be beholden to tech companies

00:24:33,360 --> 00:24:36,990
but think about them more critically I

00:24:35,040 --> 00:24:40,220
think that inflection point globally and

00:24:36,990 --> 00:24:40,220
in India is already here

00:24:40,920 --> 00:24:43,940
thank you so much

00:24:44,210 --> 00:24:46,270

YouTube URL: https://www.youtube.com/watch?v=jrZD6eK-fRw


