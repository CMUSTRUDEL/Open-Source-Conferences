Title: The Internet's Original Sin | Renee DiResta at MozFest 2018
Publication date: 2018-11-02
Playlist: MozFest 2018 - Dialogues and Debates
Description: 
	Renee DiResta, Mozilla Fellow in Media, Misinformation and Trust, speaks at MozFest 2018. Renee investigates the spread of disinformation and manipulated narratives across social networks.

MozFest is Mozilla's seven-day celebration for, by, and about people who love the internet. Learn more: https://mozillafestival.org/
Captions: 
	00:00:02,659 --> 00:00:08,189
hello everybody these are bright lights

00:00:05,660 --> 00:00:10,019
it's great to be here I'm a 20-18

00:00:08,189 --> 00:00:11,820
mozilla fellow and media misinformation

00:00:10,019 --> 00:00:13,500
and Trust and I'm going to talk about

00:00:11,820 --> 00:00:14,670
the ads based business model I'm happy

00:00:13,500 --> 00:00:16,710
to do kind of questions at the end about

00:00:14,670 --> 00:00:18,859
this information more generally I've

00:00:16,710 --> 00:00:21,000
worked on a number of initiatives

00:00:18,859 --> 00:00:22,710
researching Russia researching Isis

00:00:21,000 --> 00:00:24,840
researching domestic conspiracy

00:00:22,710 --> 00:00:26,130
theorists happy to talk about that but

00:00:24,840 --> 00:00:30,510
one of the things that I try to do is

00:00:26,130 --> 00:00:33,510
route the disinformation problem in this

00:00:30,510 --> 00:00:35,040
structural underpinnings so why we are

00:00:33,510 --> 00:00:37,710
where we are today and that's what I'd

00:00:35,040 --> 00:00:38,899
like to talk to you about I'm going to

00:00:37,710 --> 00:00:40,920
start with something really obvious

00:00:38,899 --> 00:00:43,250
something is wrong on the Internet

00:00:40,920 --> 00:00:45,989
our information ecosystem is broken and

00:00:43,250 --> 00:00:47,309
in fact things have gone so off the

00:00:45,989 --> 00:00:48,539
rails over the last few years that we

00:00:47,309 --> 00:00:50,520
actually have a whole new lexicon for

00:00:48,539 --> 00:00:52,530
describing it so we have misinformation

00:00:50,520 --> 00:00:54,570
and disinformation which is false

00:00:52,530 --> 00:00:56,550
information spread online I really the

00:00:54,570 --> 00:00:59,100
thing that separates them is intent this

00:00:56,550 --> 00:01:01,199
information is very deliberate we talk

00:00:59,100 --> 00:01:04,049
about polarization on Twitter we talked

00:01:01,199 --> 00:01:05,670
about radicalization on YouTube and as

00:01:04,049 --> 00:01:07,350
we have an election coming up in the

00:01:05,670 --> 00:01:08,909
u.s. in ten days the SPECIAL of these

00:01:07,350 --> 00:01:11,490
problems have really reached fever pitch

00:01:08,909 --> 00:01:13,590
I'm sure you all saw the news yesterday

00:01:11,490 --> 00:01:15,990
we have a pipe bomber radicalized

00:01:13,590 --> 00:01:19,860
presumably in Facebook groups we have

00:01:15,990 --> 00:01:21,240
there are so many news cycle actually

00:01:19,860 --> 00:01:23,759
stories that came by yesterday that I

00:01:21,240 --> 00:01:25,500
can pick this one but the root cause of

00:01:23,759 --> 00:01:27,150
the problem is actually sparingly simple

00:01:25,500 --> 00:01:28,710
and it's that our political

00:01:27,150 --> 00:01:30,780
conversations are happening on an

00:01:28,710 --> 00:01:33,150
infrastructure that was built for viral

00:01:30,780 --> 00:01:35,950
advertising and we're only beginning to

00:01:33,150 --> 00:01:37,420
adapt so

00:01:35,950 --> 00:01:40,120
when I first moved to the valley seven

00:01:37,420 --> 00:01:42,190
years ago I was a VC and hundreds of

00:01:40,120 --> 00:01:44,320
startup come in to my office and they

00:01:42,190 --> 00:01:46,360
would this was when social mobile local

00:01:44,320 --> 00:01:48,100
was the big thing so I would hear all of

00:01:46,360 --> 00:01:51,670
these pitches for it's like Facebook but

00:01:48,100 --> 00:01:53,740
for moms and I would say how are you

00:01:51,670 --> 00:01:55,000
going to monetize that and nearly every

00:01:53,740 --> 00:01:57,100
single one of the founders would tell me

00:01:55,000 --> 00:01:58,240
what we're going to run ads sometimes

00:01:57,100 --> 00:01:59,409
they would be even more honest and they

00:01:58,240 --> 00:02:01,000
say we're going to gather the data we're

00:01:59,409 --> 00:02:03,550
gonna repackage it anonymize it sell it

00:02:01,000 --> 00:02:04,780
and this was the norm seven years ago so

00:02:03,550 --> 00:02:06,369
now we hear that and we think that

00:02:04,780 --> 00:02:08,920
sounds a little bit creepy but this was

00:02:06,369 --> 00:02:12,370
really nobody really stopped to question

00:02:08,920 --> 00:02:14,500
that so ads alone aren't a problem

00:02:12,370 --> 00:02:18,220
companies need to sell product people

00:02:14,500 --> 00:02:20,530
want to find things buy ads have powered

00:02:18,220 --> 00:02:22,930
everything from journalism to network

00:02:20,530 --> 00:02:24,910
television over the years but what we

00:02:22,930 --> 00:02:26,650
started to realize is that when ads

00:02:24,910 --> 00:02:27,910
migrated to the internet there was a

00:02:26,650 --> 00:02:31,420
realization that if they were well

00:02:27,910 --> 00:02:33,610
targeted they were very effective and so

00:02:31,420 --> 00:02:34,930
when they're well targeted they in order

00:02:33,610 --> 00:02:36,100
to make them well targeted they have to

00:02:34,930 --> 00:02:37,540
be attention-grabbing and they have to

00:02:36,100 --> 00:02:39,610
be relevant and in order to be

00:02:37,540 --> 00:02:41,769
attention-grabbing and relevant the

00:02:39,610 --> 00:02:43,360
person who is running the ad has to know

00:02:41,769 --> 00:02:45,730
a lot about the user and this is where

00:02:43,360 --> 00:02:48,100
the platforms really come into play so

00:02:45,730 --> 00:02:52,090
the platforms the social platforms were

00:02:48,100 --> 00:02:55,450
designed to facilitate they became

00:02:52,090 --> 00:02:57,220
attention brokers they are designed help

00:02:55,450 --> 00:02:59,320
companies reach users as these sort of

00:02:57,220 --> 00:03:01,420
middlemen where they know what about you

00:02:59,320 --> 00:03:04,510
and that's the service that they're

00:03:01,420 --> 00:03:07,660
offering to advertisers so as the social

00:03:04,510 --> 00:03:09,970
ecosystem grew it really consolidated

00:03:07,660 --> 00:03:12,250
into this handful of platforms that was

00:03:09,970 --> 00:03:14,049
competitive with each other not based on

00:03:12,250 --> 00:03:15,489
differentiated feature sets you know you

00:03:14,049 --> 00:03:17,500
go to youtube and twitter for very

00:03:15,489 --> 00:03:18,880
different things but because their

00:03:17,500 --> 00:03:21,160
business models were all built on

00:03:18,880 --> 00:03:23,110
sustained engagement they had to keep

00:03:21,160 --> 00:03:24,489
you on site so they became competitive

00:03:23,110 --> 00:03:26,739
not because of features but because

00:03:24,489 --> 00:03:28,269
they're competing for your time and so

00:03:26,739 --> 00:03:31,390
the user experience is really designed

00:03:28,269 --> 00:03:34,780
to maximize I'm on-site engagement is

00:03:31,390 --> 00:03:36,760
designed to maximize time on site so we

00:03:34,780 --> 00:03:38,500
find ourselves in an ecosystem where

00:03:36,760 --> 00:03:40,600
more and more people spend time on a

00:03:38,500 --> 00:03:43,480
very very small number of platforms that

00:03:40,600 --> 00:03:46,060
are all designed to be people in one

00:03:43,480 --> 00:03:47,500
place and the political conversations do

00:03:46,060 --> 00:03:49,760
they used to be much more sharing baby

00:03:47,500 --> 00:03:51,110
pictures sharing wedding pictures

00:03:49,760 --> 00:03:53,810
gradually they became the place we had

00:03:51,110 --> 00:03:55,790
conversations as well I think the latest

00:03:53,810 --> 00:03:58,280
statistic is that 60% of people in the

00:03:55,790 --> 00:04:01,400
US get their news from Facebook and if

00:03:58,280 --> 00:04:04,280
you look at ecosystems where Facebook is

00:04:01,400 --> 00:04:07,450
the internet or where whatsapp is the

00:04:04,280 --> 00:04:10,060
internet that is even more

00:04:07,450 --> 00:04:11,890
so people are not just observing on

00:04:10,060 --> 00:04:15,010
these platforms they're creating content

00:04:11,890 --> 00:04:16,840
as well and as you have these these

00:04:15,010 --> 00:04:19,389
platforms where people are producing

00:04:16,840 --> 00:04:21,519
content you have a lot of information so

00:04:19,389 --> 00:04:23,110
for the first time ever we move from a

00:04:21,519 --> 00:04:25,240
period of information scarcity to

00:04:23,110 --> 00:04:27,040
information what and the way that the

00:04:25,240 --> 00:04:29,830
platform's manage this is they design

00:04:27,040 --> 00:04:31,660
territorial algorithms like search like

00:04:29,830 --> 00:04:34,090
friending like recommendation engines

00:04:31,660 --> 00:04:35,740
that help people make sense of all of

00:04:34,090 --> 00:04:37,690
the information that they're seeing on

00:04:35,740 --> 00:04:42,220
those bombs give you the most

00:04:37,690 --> 00:04:44,889
personalized exciting best experience at

00:04:42,220 --> 00:04:45,940
the same time because one of the things

00:04:44,889 --> 00:04:47,680
that they want to do is really

00:04:45,940 --> 00:04:49,780
facilitate sharing again driving

00:04:47,680 --> 00:04:51,430
engagement and seeing what you are what

00:04:49,780 --> 00:04:53,229
you want to share what you care so much

00:04:51,430 --> 00:04:54,610
about that you're willing to share it we

00:04:53,229 --> 00:04:56,470
have virality engines

00:04:54,610 --> 00:04:58,570
so this is where algorithmic

00:04:56,470 --> 00:05:00,400
amplification takes things like

00:04:58,570 --> 00:05:04,169
misinformation and sensationalized

00:05:00,400 --> 00:05:06,360
content and pushes it out and mass

00:05:04,169 --> 00:05:08,909
so to summarize the ecosystem evolution

00:05:06,360 --> 00:05:10,439
I look at three things I see kind of pre

00:05:08,909 --> 00:05:11,749
this sort of intersection of three

00:05:10,439 --> 00:05:14,129
things that happened audience

00:05:11,749 --> 00:05:16,080
consolidation billions of users on a

00:05:14,129 --> 00:05:18,539
handful of platforms personalized

00:05:16,080 --> 00:05:21,150
targeting driven to facilitate ads and

00:05:18,539 --> 00:05:24,060
damnable algorithms and these

00:05:21,150 --> 00:05:25,740
territorial algorithms that are not they

00:05:24,060 --> 00:05:27,990
are remarkably effective but not

00:05:25,740 --> 00:05:29,490
necessarily very sophisticated it will

00:05:27,990 --> 00:05:31,289
show you what you want to see but they

00:05:29,490 --> 00:05:32,879
don't have any kind of value judgment

00:05:31,289 --> 00:05:35,069
and this is where we see things like

00:05:32,879 --> 00:05:36,750
radicalization beginning to be an

00:05:35,069 --> 00:05:38,189
increasing problem because the

00:05:36,750 --> 00:05:40,830
recommendation engine does not actually

00:05:38,189 --> 00:05:42,969
understand what it is suggesting just

00:05:40,830 --> 00:05:45,219
knows that you're likely to like it

00:05:42,969 --> 00:05:46,809
as a result of that kind of intersection

00:05:45,219 --> 00:05:48,759
of three things we have an information

00:05:46,809 --> 00:05:51,339
ecosystem that prioritizes what's

00:05:48,759 --> 00:05:52,719
popular over what's true and it's funny

00:05:51,339 --> 00:05:54,610
because in the work I do we try to never

00:05:52,719 --> 00:05:56,319
say the T word because then you're

00:05:54,610 --> 00:05:57,759
getting into valued judgments so we

00:05:56,319 --> 00:06:00,129
talked about information integrity

00:05:57,759 --> 00:06:02,259
rather than truth but really when we're

00:06:00,129 --> 00:06:03,819
getting down to it so much of the

00:06:02,259 --> 00:06:05,589
problem that we have is actually an

00:06:03,819 --> 00:06:08,049
erosion in this lake is shared

00:06:05,589 --> 00:06:10,479
epistemological framework we see two

00:06:08,049 --> 00:06:12,219
completely different Internet's in the

00:06:10,479 --> 00:06:14,379
US and this is where the polarization

00:06:12,219 --> 00:06:16,599
problem the echo chamber is really are

00:06:14,379 --> 00:06:18,669
reinforced so the unintended

00:06:16,599 --> 00:06:20,139
consequences of this is that we have an

00:06:18,669 --> 00:06:22,329
infrastructure purpose-built for

00:06:20,139 --> 00:06:24,639
advertising coupled with vast amounts of

00:06:22,329 --> 00:06:27,669
personal data infinite reach and little

00:06:24,639 --> 00:06:29,949
and no regulation so this ecosystem that

00:06:27,669 --> 00:06:33,250
was built for advertisers is also

00:06:29,949 --> 00:06:34,630
remarkably effective for propagandists

00:06:33,250 --> 00:06:38,380
and that's because propaganda is a

00:06:34,630 --> 00:06:40,840
marketing campaign or an idea and so

00:06:38,380 --> 00:06:43,120
seven or eight years ago clever people

00:06:40,840 --> 00:06:45,190
with bad intentions realize that a very

00:06:43,120 --> 00:06:47,170
small ad bike could deliver a very long

00:06:45,190 --> 00:06:48,430
term relationship so this is something

00:06:47,170 --> 00:06:50,290
that brand marketers have known for

00:06:48,430 --> 00:06:52,060
years very small ad by engaging content

00:06:50,290 --> 00:06:53,770
well targeted you're going to get people

00:06:52,060 --> 00:06:55,900
they're going to like your page and then

00:06:53,770 --> 00:06:58,120
you're going to continue to push them

00:06:55,900 --> 00:06:59,590
things and so this is the same framework

00:06:58,120 --> 00:07:01,950
the same exact framework that we see

00:06:59,590 --> 00:07:04,020
propagandists using today

00:07:01,950 --> 00:07:08,100
so the work that I do looks at kind of

00:07:04,020 --> 00:07:10,500
five or you know malign actors is the

00:07:08,100 --> 00:07:12,240
term state actors you've got Russia you

00:07:10,500 --> 00:07:14,190
have Iranian of Saudi Arabia you have

00:07:12,240 --> 00:07:16,050
anyone who any any government that is

00:07:14,190 --> 00:07:19,140
willing Institute campaigns both of

00:07:16,050 --> 00:07:21,420
state rolling and also of big news and

00:07:19,140 --> 00:07:22,650
misinformation you have terrorists so a

00:07:21,420 --> 00:07:25,830
lot of the work that I did in 2015

00:07:22,650 --> 00:07:28,440
looked at Isis which built a brand on

00:07:25,830 --> 00:07:31,080
social media overtly the black flag it

00:07:28,440 --> 00:07:33,120
was everywhere we have the domestic

00:07:31,080 --> 00:07:35,700
ideologues I have you know I'm a there

00:07:33,120 --> 00:07:37,650
but there are other there her icons I

00:07:35,700 --> 00:07:40,500
could have used as well the true

00:07:37,650 --> 00:07:42,480
believers the conspiracy theorists the

00:07:40,500 --> 00:07:45,230
spammers who are doing it for financial

00:07:42,480 --> 00:07:48,360
motivation they are all using the same

00:07:45,230 --> 00:07:50,010
framework because this is what we've

00:07:48,360 --> 00:07:51,730
built this is the information ecosystem

00:07:50,010 --> 00:07:54,310
we've designed

00:07:51,730 --> 00:07:55,930
so what are we doing about it so the

00:07:54,310 --> 00:07:56,350
spammers were actually the easiest to

00:07:55,930 --> 00:07:58,980
deal with

00:07:56,350 --> 00:08:01,000
because nobody likes spammers nobody

00:07:58,980 --> 00:08:03,310
thinks about the free speech rates of

00:08:01,000 --> 00:08:04,930
spammers and so Tampines really were

00:08:03,310 --> 00:08:07,060
collaborative ly to solve the spam

00:08:04,930 --> 00:08:08,770
problem they remove financial incentives

00:08:07,060 --> 00:08:12,490
they redesign in terms of service they

00:08:08,770 --> 00:08:14,350
deprecated clickbait with Isis that was

00:08:12,490 --> 00:08:17,980
actually surprisingly difficult some of

00:08:14,350 --> 00:08:19,360
the work that we did 2015 this is when

00:08:17,980 --> 00:08:21,610
the government this is when the US

00:08:19,360 --> 00:08:23,380
government really began to try to engage

00:08:21,610 --> 00:08:25,300
with the tech platforms to say we've got

00:08:23,380 --> 00:08:27,190
to do something about this and it was a

00:08:25,300 --> 00:08:29,350
remarkable series of conversations I

00:08:27,190 --> 00:08:31,150
mean because we would have this was

00:08:29,350 --> 00:08:32,979
shortly after the Snowden revelations so

00:08:31,150 --> 00:08:34,210
the environment was very different so

00:08:32,979 --> 00:08:36,160
the tech companies didn't want to be

00:08:34,210 --> 00:08:37,570
seen as working with her engaging with

00:08:36,160 --> 00:08:39,700
US government meanwhile the government

00:08:37,570 --> 00:08:41,770
is saying Paras are actively recruiting

00:08:39,700 --> 00:08:43,180
on your form what are you doing about it

00:08:41,770 --> 00:08:44,890
and then we would have these surreal

00:08:43,180 --> 00:08:46,540
conversations with civil libertarians

00:08:44,890 --> 00:08:48,640
who would say one man's Paris is another

00:08:46,540 --> 00:08:49,810
man's freedom fighter and then there

00:08:48,640 --> 00:08:51,400
were those of us who were third party

00:08:49,810 --> 00:08:55,110
security researchers in the room like

00:08:51,400 --> 00:08:57,400
these are beheading videos you guys so

00:08:55,110 --> 00:08:59,230
there were these passionate appeals to

00:08:57,400 --> 00:09:00,730
like mill and Brandeis for just gonna

00:08:59,230 --> 00:09:02,590
speak louder than all the bots are gonna

00:09:00,730 --> 00:09:04,750
challenge the bad ideas and freedom of

00:09:02,590 --> 00:09:06,790
speech and win the day and I think that

00:09:04,750 --> 00:09:08,980
now in 2018 we realized that that is not

00:09:06,790 --> 00:09:11,170
what is happening and that we need to do

00:09:08,980 --> 00:09:12,760
something fundamentally different so

00:09:11,170 --> 00:09:14,830
this is Russia these are Russian memes

00:09:12,760 --> 00:09:16,540
from the internet research agency happy

00:09:14,830 --> 00:09:18,160
to talk about that during a hearing her

00:09:16,540 --> 00:09:20,470
name but they achieved worldwide

00:09:18,160 --> 00:09:23,920
notoriety were successfully masquerading

00:09:20,470 --> 00:09:25,870
as Americans period of three years their

00:09:23,920 --> 00:09:28,030
activity their interference in the 2016

00:09:25,870 --> 00:09:29,950
election led to a remarkable shift this

00:09:28,030 --> 00:09:31,510
above all else is why we're having this

00:09:29,950 --> 00:09:33,640
conversation this is why I'm in this

00:09:31,510 --> 00:09:35,380
room because the things that we tried to

00:09:33,640 --> 00:09:37,840
say when it was just domestic conspiracy

00:09:35,380 --> 00:09:39,700
theorists or just artists when we began

00:09:37,840 --> 00:09:41,260
to realize that these are state actors

00:09:39,700 --> 00:09:43,510
using it there is finally an

00:09:41,260 --> 00:09:46,120
acknowledgement that these are dual use

00:09:43,510 --> 00:09:47,650
technologies there are military's using

00:09:46,120 --> 00:09:49,030
them there are intelligence services

00:09:47,650 --> 00:09:50,290
using them and this is a much bigger

00:09:49,030 --> 00:09:52,240
problem this is at this point of

00:09:50,290 --> 00:09:53,950
national security issue an integrity

00:09:52,240 --> 00:09:55,330
issue and that was something that we

00:09:53,950 --> 00:09:57,540
weren't really internalized

00:09:55,330 --> 00:09:59,490
four years ago

00:09:57,540 --> 00:10:01,560
the last are the passionate ideologues

00:09:59,490 --> 00:10:03,060
the true believers who have realized

00:10:01,560 --> 00:10:06,870
that anyone can do this with minimal

00:10:03,060 --> 00:10:09,120
resources so why not try so every day we

00:10:06,870 --> 00:10:11,130
have these power users spammers and

00:10:09,120 --> 00:10:12,870
spies Aricent ideologues they get more

00:10:11,130 --> 00:10:15,269
sophisticated and so we're in an arms

00:10:12,870 --> 00:10:19,300
race now we're wacom all is a trite but

00:10:15,269 --> 00:10:22,420
very apt metaphor and that because

00:10:19,300 --> 00:10:24,700
the ecosystem is such that anyone and do

00:10:22,420 --> 00:10:26,290
this and the challenge that we're having

00:10:24,700 --> 00:10:29,380
as we try to solve it is where are the

00:10:26,290 --> 00:10:33,480
lines where is what is the line between

00:10:29,380 --> 00:10:35,740
clicktivism right you know algorithmic

00:10:33,480 --> 00:10:37,570
political activity and algorithmic

00:10:35,740 --> 00:10:39,430
gaming where is that line when Ted Cruz

00:10:37,570 --> 00:10:41,290
runs ads where you click a button and it

00:10:39,430 --> 00:10:43,480
tweets verbatim the same thing that is

00:10:41,290 --> 00:10:45,480
just like it looked like an army of spam

00:10:43,480 --> 00:10:47,470
bots but is that just political speech

00:10:45,480 --> 00:10:48,820
what's the distinction between a

00:10:47,470 --> 00:10:52,420
guerrilla marketer and an unethical

00:10:48,820 --> 00:10:55,780
spammer how do we atone for and move

00:10:52,420 --> 00:10:57,430
beyond the internet the original sin so

00:10:55,780 --> 00:10:59,410
these are the hard questions that we've

00:10:57,430 --> 00:11:01,860
just begun to ask ourselves there are

00:10:59,410 --> 00:11:05,260
very you know tough days ahead or

00:11:01,860 --> 00:11:06,670
Romanies for regulators for people in

00:11:05,260 --> 00:11:09,130
this room thank yous for building apps

00:11:06,670 --> 00:11:10,990
right and you know to their credit I

00:11:09,130 --> 00:11:12,570
will say over the last two years or so

00:11:10,990 --> 00:11:15,370
the platforms have really come around

00:11:12,570 --> 00:11:16,930
Facebook made some remarkable hires they

00:11:15,370 --> 00:11:18,730
have the war room that you know they did

00:11:16,930 --> 00:11:20,320
a day or push about days ago you

00:11:18,730 --> 00:11:22,240
probably read about it

00:11:20,320 --> 00:11:24,190
Jack Boise showed up and acknowledged

00:11:22,240 --> 00:11:25,660
that he runs a private public where and

00:11:24,190 --> 00:11:28,120
is going to have to actually take

00:11:25,660 --> 00:11:29,290
responsibility for this now so we've had

00:11:28,120 --> 00:11:32,620
congressional hearing after

00:11:29,290 --> 00:11:34,180
congressional hearing and then a lot of

00:11:32,620 --> 00:11:36,730
the leading is actually happening by

00:11:34,180 --> 00:11:38,740
third parties there is initiatives such

00:11:36,730 --> 00:11:40,360
as future Congress there's the Center

00:11:38,740 --> 00:11:42,430
for Humane Technology and they're trying

00:11:40,360 --> 00:11:43,990
to promote transparency and

00:11:42,430 --> 00:11:45,970
accountability they're trying to work

00:11:43,990 --> 00:11:47,920
with regulators to help me at regulators

00:11:45,970 --> 00:11:50,170
of the speed on the things that that we

00:11:47,920 --> 00:11:51,820
look at at Mozilla and like-minded

00:11:50,170 --> 00:11:53,770
information like minded organizations

00:11:51,820 --> 00:11:56,350
like Berkman client and actually the

00:11:53,770 --> 00:11:57,670
ef-2 there's a network of staff and

00:11:56,350 --> 00:11:59,620
fellows who are trying to collaborate on

00:11:57,670 --> 00:12:01,480
solutions the Internet Health Report

00:11:59,620 --> 00:12:03,340
team is here highly recommend haven't

00:12:01,480 --> 00:12:05,320
seen that you take a look at that and

00:12:03,340 --> 00:12:07,720
then there is a really great panel on

00:12:05,320 --> 00:12:10,300
Sunday morning with another mozilla

00:12:07,720 --> 00:12:12,370
fellow of mill Francois called a eyes

00:12:10,300 --> 00:12:14,500
lateral damage there will be some work

00:12:12,370 --> 00:12:16,320
on a discussion of this that I'm out

00:12:14,500 --> 00:12:18,150
there

00:12:16,320 --> 00:12:21,180
I think you know everyday users are

00:12:18,150 --> 00:12:23,700
beginning to realize the disaster that

00:12:21,180 --> 00:12:25,590
is our information ecosystem and so one

00:12:23,700 --> 00:12:27,240
of the reasons why this is a sustained

00:12:25,590 --> 00:12:29,280
topic of conversation is because there

00:12:27,240 --> 00:12:31,260
are people who are agitating there are a

00:12:29,280 --> 00:12:34,260
network of activists and then the

00:12:31,260 --> 00:12:35,220
regulatory conversation it would have to

00:12:34,260 --> 00:12:37,140
engage is quite heavily with the

00:12:35,220 --> 00:12:38,850
activist community now is focused on

00:12:37,140 --> 00:12:40,320
these four things which I don't have

00:12:38,850 --> 00:12:41,700
time to go into great detail on but

00:12:40,320 --> 00:12:44,820
really looking at things like add

00:12:41,700 --> 00:12:46,080
transparency what are the framework that

00:12:44,820 --> 00:12:47,910
we can put in place to help people

00:12:46,080 --> 00:12:50,160
understand political advertising and

00:12:47,910 --> 00:12:52,830
what it looked like online bought

00:12:50,160 --> 00:12:56,130
labeling I have many thoughts about but

00:12:52,830 --> 00:12:57,630
the idea being again helping people

00:12:56,130 --> 00:12:59,940
understand what they're engaging with

00:12:57,630 --> 00:13:02,610
particularly as we enter into an era of

00:12:59,940 --> 00:13:05,280
extremely intelligent AI chatbots

00:13:02,610 --> 00:13:07,140
a number of other things how do we think

00:13:05,280 --> 00:13:12,970
about attaching a provenance or a little

00:13:07,140 --> 00:13:15,639
bit more of a human versus not human

00:13:12,970 --> 00:13:17,949
disclosure for online engagement there's

00:13:15,639 --> 00:13:19,779
antitrust the idea that maybe the

00:13:17,949 --> 00:13:21,009
problem is after that mass consolidation

00:13:19,779 --> 00:13:22,269
that I was describing and maybe the

00:13:21,009 --> 00:13:24,519
solution is a more fragmented

00:13:22,269 --> 00:13:26,199
decentralized kind of return to the

00:13:24,519 --> 00:13:28,569
early days of the internet and then

00:13:26,199 --> 00:13:29,889
privacy which I feel like I can't tell

00:13:28,569 --> 00:13:32,709
an audience of people from Europe about

00:13:29,889 --> 00:13:34,180
because you guys are G R is a way ahead

00:13:32,709 --> 00:13:36,870
of anything that that we've that we've

00:13:34,180 --> 00:13:36,870
tackled in the US

00:13:37,190 --> 00:13:39,740
I'll leave you all with this you know a

00:13:38,660 --> 00:13:42,020
lot of the people in this room are

00:13:39,740 --> 00:13:43,550
founders or creators and I think we're

00:13:42,020 --> 00:13:46,280
at a point where we finally realized

00:13:43,550 --> 00:13:48,620
that fracking users and maximizing

00:13:46,280 --> 00:13:51,020
engagement above all else is not the

00:13:48,620 --> 00:13:53,180
only way we need to be aware of the

00:13:51,020 --> 00:13:55,070
unintended consequences of that model we

00:13:53,180 --> 00:13:57,620
need to be aware of things like the

00:13:55,070 --> 00:13:59,510
design decisions that algorithmic

00:13:57,620 --> 00:14:01,520
recommendation engines are having on

00:13:59,510 --> 00:14:03,530
society we need to be thinking about the

00:14:01,520 --> 00:14:05,120
societal and the downstream impacts of

00:14:03,530 --> 00:14:06,980
the communities that we're facilitating

00:14:05,120 --> 00:14:09,080
online and I think it's time that we

00:14:06,980 --> 00:14:12,200
need to all as a community as is really

00:14:09,080 --> 00:14:14,330
more more responsible choices so you

00:14:12,200 --> 00:14:16,130
know the industry has excelled for years

00:14:14,330 --> 00:14:17,810
at creating innovative technology and

00:14:16,130 --> 00:14:18,950
innovative products and I think it's

00:14:17,810 --> 00:14:21,200
really time that we start to think about

00:14:18,950 --> 00:14:22,910
innovative business models what is the

00:14:21,200 --> 00:14:25,760
future of social on the internet look

00:14:22,910 --> 00:14:27,500
like what is it powered by I think it's

00:14:25,760 --> 00:14:29,090
time to prioritize the creation of a

00:14:27,500 --> 00:14:32,120
digital ecosystem that doesn't

00:14:29,090 --> 00:14:34,520
accommodate camera spies and ideologues

00:14:32,120 --> 00:14:38,650
but is instead really focused on real

00:14:34,520 --> 00:14:38,650
users and genuine conversation and

00:14:46,160 --> 00:14:49,360
[Music]

00:14:49,820 --> 00:14:55,539
I should have no idea how we are on time

00:14:52,320 --> 00:14:55,539
[Music]

00:14:58,750 --> 00:15:06,360
thank you no interest and I work for

00:15:03,030 --> 00:15:09,490
an environmental organization and we

00:15:06,360 --> 00:15:14,269
obviously have to raise funds and

00:15:09,490 --> 00:15:17,769
money at things sometimes that

00:15:14,269 --> 00:15:22,660
using some of the facts and

00:15:17,769 --> 00:15:24,790
sweet and I wonder if there's no hints

00:15:22,660 --> 00:15:27,360
or tips you can provide when you

00:15:24,790 --> 00:15:30,759
mentioned about in the internet health

00:15:27,360 --> 00:15:32,589
foundation of getting involved now for

00:15:30,759 --> 00:15:36,069
NGOs kind of generally you know other

00:15:32,589 --> 00:15:40,360
things that you think doing we not say

00:15:36,069 --> 00:15:42,759
deeply involved in the tech say it's

00:15:40,360 --> 00:15:46,269
okay to use face for advertising for

00:15:42,759 --> 00:15:47,799
example that's highly effective but

00:15:46,269 --> 00:15:50,199
maybe we were actually talking about

00:15:47,799 --> 00:15:51,999
that right before I went on I built an

00:15:50,199 --> 00:15:53,589
advocacy organization myself couple

00:15:51,999 --> 00:15:56,529
years back pro-vaccine

00:15:53,589 --> 00:15:58,629
unity to work on we're gonna get past

00:15:56,529 --> 00:16:00,339
Aleph or Nia and I'm right there with

00:15:58,629 --> 00:16:03,129
you I mean this is this is the way to

00:16:00,339 --> 00:16:06,699
grow this is the way to grow these are

00:16:03,129 --> 00:16:09,449
effective tools I think one of the

00:16:06,699 --> 00:16:09,449
challenges is

00:16:09,880 --> 00:16:15,640
the business community and the large

00:16:11,740 --> 00:16:18,670
NGOs and others have a strong voice and

00:16:15,640 --> 00:16:20,320
and say these are the tools that we want

00:16:18,670 --> 00:16:22,450
to see these are the tools that use but

00:16:20,320 --> 00:16:24,820
also a recognition that I think there is

00:16:22,450 --> 00:16:26,950
going to happen more in the way of of

00:16:24,820 --> 00:16:29,380
checking who's who's running ads who's

00:16:26,950 --> 00:16:32,550
doing this that's where it's a you know

00:16:29,380 --> 00:16:34,180
how do we protect privacy and yet I am

00:16:32,550 --> 00:16:36,400
recognized that there has some

00:16:34,180 --> 00:16:37,660
disclosure Facebook initial steps on

00:16:36,400 --> 00:16:39,940
that we're really interesting they now

00:16:37,660 --> 00:16:42,220
have you registering to run ads you've

00:16:39,940 --> 00:16:43,540
done it I've done it

00:16:42,220 --> 00:16:45,040
but one of the things that we see is

00:16:43,540 --> 00:16:47,350
that there's also these nameless LLC's

00:16:45,040 --> 00:16:50,140
and and it's a great way to launder in

00:16:47,350 --> 00:16:51,460
and so this is where it really comes an

00:16:50,140 --> 00:16:53,080
arms race is really a big challenge and

00:16:51,460 --> 00:16:54,700
so we actually are really relying on

00:16:53,080 --> 00:16:57,480
them to grow teams internally and in the

00:16:54,700 --> 00:17:01,180
same time senator Warner and Senator

00:16:57,480 --> 00:17:02,350
honest adds a disclosure we see it as in

00:17:01,180 --> 00:17:03,670
some ways I can know your customer

00:17:02,350 --> 00:17:06,250
framework the same way the financial

00:17:03,670 --> 00:17:08,320
industry has in the financial industry

00:17:06,250 --> 00:17:09,940
if we're taking money or your bank or

00:17:08,320 --> 00:17:11,710
you're representing a client you have to

00:17:09,940 --> 00:17:13,540
know who they are and this is where we

00:17:11,710 --> 00:17:15,490
start to see like maybe large ad buys

00:17:13,540 --> 00:17:18,930
very targeted as these things are gonna

00:17:15,490 --> 00:17:18,930
happen more process like that

00:17:23,100 --> 00:17:26,429
and I was wondering what commedia

00:17:25,199 --> 00:17:27,900
agencies be doing because they're the

00:17:26,429 --> 00:17:29,549
ones ultimately who are taking the data

00:17:27,900 --> 00:17:30,929
that's available to them and then

00:17:29,549 --> 00:17:33,240
they're seeding it out their entire team

00:17:30,929 --> 00:17:36,630
those users based on you know their

00:17:33,240 --> 00:17:38,730
gender time of day what food they like

00:17:36,630 --> 00:17:41,640
so what can they be doing to ultimately

00:17:38,730 --> 00:17:44,580
help change this I think there's been

00:17:41,640 --> 00:17:47,580
some conversations with the the large

00:17:44,580 --> 00:17:48,960
advertising agencies a lot of that has

00:17:47,580 --> 00:17:51,870
actually been focused on where their ads

00:17:48,960 --> 00:17:55,320
appear and that's particularly on

00:17:51,870 --> 00:17:59,220
YouTube I think as far as what may be

00:17:55,320 --> 00:18:01,169
doing they also have a kind of a loud

00:17:59,220 --> 00:18:03,559
voice here and so you see groups like

00:18:01,169 --> 00:18:09,390
Unilever advocate companies like

00:18:03,559 --> 00:18:11,130
Unilever advocating for more of a maybe

00:18:09,390 --> 00:18:12,539
we don't advertise at night I think was

00:18:11,130 --> 00:18:14,070
one of the things that I saw maybe we

00:18:12,539 --> 00:18:16,620
don't advertise it period than people

00:18:14,070 --> 00:18:18,210
are I deserve an interesting case today

00:18:16,620 --> 00:18:21,780
I think the Unilever thing was related

00:18:18,210 --> 00:18:23,309
to do you want to like push product

00:18:21,780 --> 00:18:25,230
people who are online late at night or

00:18:23,309 --> 00:18:27,059
like loneliness and depression kind of

00:18:25,230 --> 00:18:28,080
come into play and and I think that

00:18:27,059 --> 00:18:30,240
they've been starting to think about

00:18:28,080 --> 00:18:31,980
what are the industry standards that

00:18:30,240 --> 00:18:34,140
they're gonna put in place much like

00:18:31,980 --> 00:18:35,820
things like environmental standards have

00:18:34,140 --> 00:18:38,220
come from big companies really looking

00:18:35,820 --> 00:18:39,419
at it in that in that model and so

00:18:38,220 --> 00:18:41,100
they're they are beginning to take those

00:18:39,419 --> 00:18:42,360
steps I work with them a little bit less

00:18:41,100 --> 00:18:44,970
I I don't engage with the advertising

00:18:42,360 --> 00:18:45,960
kind of bull fires as much but my

00:18:44,970 --> 00:18:48,140
understanding everything's are going

00:18:45,960 --> 00:18:48,140
there

00:18:54,100 --> 00:18:58,130
what surprised you most when you were

00:18:56,630 --> 00:19:01,270
doing your research into the way

00:18:58,130 --> 00:19:01,270
Isis operate online

00:19:01,639 --> 00:19:04,860
very charismatic and they produce

00:19:02,899 --> 00:19:09,290
engaging content

00:19:04,860 --> 00:19:09,290
there's a I have one day

00:19:09,929 --> 00:19:15,899
that they made that was still from it

00:19:11,909 --> 00:19:17,190
actually that mean my put up I'm totally

00:19:15,899 --> 00:19:19,740
blanking on the name of their video now

00:19:17,190 --> 00:19:21,539
it looks like I know how all the people

00:19:19,740 --> 00:19:23,700
in this room are but I remember when I

00:19:21,539 --> 00:19:25,320
was a kid going to the movies and there

00:19:23,700 --> 00:19:26,519
would be this Admiral for joining the

00:19:25,320 --> 00:19:27,480
Marines and it'd be like the Marines

00:19:26,519 --> 00:19:29,249
fighting the fire Beast

00:19:27,480 --> 00:19:31,950
does anybody else in this room remember

00:19:29,249 --> 00:19:34,830
they out of the okay good that's what it

00:19:31,950 --> 00:19:39,119
looks like it's engaging it's I mean

00:19:34,830 --> 00:19:42,520
there's charisma there's it's remarkably

00:19:39,119 --> 00:19:44,590
effective content it's not

00:19:42,520 --> 00:19:46,690
half-baked crappy memes it's good stuff

00:19:44,590 --> 00:19:47,770
and that's a problem it was the same

00:19:46,690 --> 00:19:48,760
thing with Russia I can't tell you how

00:19:47,770 --> 00:19:50,679
many Russian memes I've looked at at

00:19:48,760 --> 00:19:52,240
this point some of them are really funny

00:19:50,679 --> 00:19:54,850
and I think that one of the things we

00:19:52,240 --> 00:19:57,330
try to do is like diminish that and if

00:19:54,850 --> 00:19:59,200
you diminish that you're just not like

00:19:57,330 --> 00:20:01,300
respecting the seriousness of what

00:19:59,200 --> 00:20:03,100
you're up against and and so that's

00:20:01,300 --> 00:20:05,860
where I think sometimes the way that

00:20:03,100 --> 00:20:07,450
there is like we mock it in the media

00:20:05,860 --> 00:20:08,620
but it's actually very well done and it

00:20:07,450 --> 00:20:11,250
resonates with the target audience and

00:20:08,620 --> 00:20:11,250
that's all that matters

00:20:13,590 --> 00:20:19,860
so on that it you obviously have looked

00:20:16,530 --> 00:20:21,690
at a lot of like trolling content and I

00:20:19,860 --> 00:20:24,090
think like the psychology of that is

00:20:21,690 --> 00:20:27,270
fascinating because it is so effective

00:20:24,090 --> 00:20:28,650
and compelling I guess I just want to

00:20:27,270 --> 00:20:31,350
know if you had any other other comments

00:20:28,650 --> 00:20:33,720
or observations on why that might be or

00:20:31,350 --> 00:20:35,700
or what else you sort of observed and

00:20:33,720 --> 00:20:38,940
looking at all of that I think what's

00:20:35,700 --> 00:20:41,280
remarkable about Russia is how effective

00:20:38,940 --> 00:20:42,930
it was I mean they were I don't know how

00:20:41,280 --> 00:20:45,000
many of you read the Mueller indictment

00:20:42,930 --> 00:20:46,650
or it wasn't Mueller as the state of

00:20:45,000 --> 00:20:47,670
Virginia the last indictment that came

00:20:46,650 --> 00:20:51,840
out about a week and a half ago

00:20:47,670 --> 00:20:54,360
um the granularity of not that the ad

00:20:51,840 --> 00:20:55,920
content wasn't what mattered the ads are

00:20:54,360 --> 00:20:57,330
such tiny piece of this I think the

00:20:55,920 --> 00:20:59,190
latest pages that they stole down

00:20:57,330 --> 00:21:00,840
yesterday the Iranian pages hundred

00:20:59,190 --> 00:21:02,610
dollars and spend half a million

00:21:00,840 --> 00:21:04,560
followers on a page right there's no

00:21:02,610 --> 00:21:06,630
that the correlation is not the ads are

00:21:04,560 --> 00:21:08,490
not problem the problem is that they get

00:21:06,630 --> 00:21:09,890
people to like the page through a series

00:21:08,490 --> 00:21:11,820
of late in authentic engagement

00:21:09,890 --> 00:21:13,320
inauthentic dissemination we're really

00:21:11,820 --> 00:21:15,960
always after the platforms to look at

00:21:13,320 --> 00:21:17,970
dissemination for you no evidence of an

00:21:15,960 --> 00:21:21,810
authenticity it's hard to grow a 500

00:21:17,970 --> 00:21:23,520
thousand member page but what they do is

00:21:21,810 --> 00:21:25,590
they create compelling content that

00:21:23,520 --> 00:21:27,330
drives people to reshare it so it's

00:21:25,590 --> 00:21:29,040
really the organic engagement that's the

00:21:27,330 --> 00:21:31,380
problem it's actually the virality it's

00:21:29,040 --> 00:21:32,910
actually the users referring in other

00:21:31,380 --> 00:21:34,770
users I think the other thing that's

00:21:32,910 --> 00:21:36,720
remarkable about it is the extent to

00:21:34,770 --> 00:21:37,740
which they create what we call these

00:21:36,720 --> 00:21:40,170
like media mirages

00:21:37,740 --> 00:21:41,640
in the sense that they they cross link

00:21:40,170 --> 00:21:43,590
all of their pages what we saw with

00:21:41,640 --> 00:21:46,110
Russia was all of the pages targeting

00:21:43,590 --> 00:21:47,520
the black community were incredibly well

00:21:46,110 --> 00:21:49,200
integrated incredibly well networked

00:21:47,520 --> 00:21:51,630
they all had Twitter accounts youtubes

00:21:49,200 --> 00:21:52,950
they're building brands and and there we

00:21:51,630 --> 00:21:54,960
were building specifically like media

00:21:52,950 --> 00:21:56,730
entities and so what they did was they

00:21:54,960 --> 00:21:58,470
created an environment where you like

00:21:56,730 --> 00:21:59,520
one page you sync up with one page and

00:21:58,470 --> 00:22:01,350
then all of a sudden they're cross

00:21:59,520 --> 00:22:02,880
promoting another page so you think

00:22:01,350 --> 00:22:04,410
you're going and liking some independent

00:22:02,880 --> 00:22:06,270
Instagram account that also happens to

00:22:04,410 --> 00:22:08,430
be really into black culture and that's

00:22:06,270 --> 00:22:10,290
also owned by the IRA and so it creates

00:22:08,430 --> 00:22:11,730
this like encapsulation almost where you

00:22:10,290 --> 00:22:14,100
are in a media environment that is

00:22:11,730 --> 00:22:17,940
entirely manufactured that shows you

00:22:14,100 --> 00:22:20,280
like very normal like black culture

00:22:17,940 --> 00:22:23,340
content for very long time and then hits

00:22:20,280 --> 00:22:25,170
you with like a meme that's a little bit

00:22:23,340 --> 00:22:27,389
off a little more radicalizing and so

00:22:25,170 --> 00:22:28,919
it's a very sustained long-term relation

00:22:27,389 --> 00:22:31,339
that is developed over a very long

00:22:28,919 --> 00:22:31,339
period of time

00:22:32,840 --> 00:22:39,849
ranee thank you thank you

00:22:35,920 --> 00:22:39,849

YouTube URL: https://www.youtube.com/watch?v=baPF-sOXP24


