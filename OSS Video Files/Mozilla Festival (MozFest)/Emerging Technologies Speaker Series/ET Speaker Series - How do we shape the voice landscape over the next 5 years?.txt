Title: ET Speaker Series - How do we shape the voice landscape over the next 5 years?
Publication date: 2020-05-12
Playlist: Emerging Technologies Speaker Series
Description: 
	When we investigate the evolution of open source voice technologies, two 'waves' become evident. We sit on the cusp of a "third wave" of open source voice - an inflection point of technologies, communities, business models, drivers, stakeholders and languages. In this presentation, Kathy Reid outlines the three-wave approach to open source voice, highlighting where its come from, a current state of play, and outlines several possible arcs that it could follow. Each of these trajectories has an associated set of conditions - and actions that need to be taken to see the trajectory materialize into reality. 

While this talk focuses on Voice, the research approach, the understandings of the ecosystem and the process of open source project assessment have relevance across Mozilla.

Bio
After two decades bringing emerging technologies into the mainstream, Kathy Reid has gone back to further study and is a Master of Applied Cybernetics student at the 3A Institute at Australian National University. Long an open source advocate, her Master's capstone explores how we can assess open source voice products. Kathy is the former President of Linux Australia Inc. and former Director of Developer Relations at Mycroft AI.
Captions: 
	00:00:00,290 --> 00:00:05,160
hi everybody my name is Joe fish kay I

00:00:03,389 --> 00:00:06,960
am principal research scientist in the

00:00:05,160 --> 00:00:09,269
emerging technologies organization and

00:00:06,960 --> 00:00:14,040
it is my pleasure today to introduce you

00:00:09,269 --> 00:00:16,619
to Cathy Reed this is part of an ongoing

00:00:14,040 --> 00:00:18,960
series that we have within ET in which

00:00:16,619 --> 00:00:23,869
we try and get people from from the

00:00:18,960 --> 00:00:26,039
larger a world to talk to Mozilla about

00:00:23,869 --> 00:00:27,449
issues that are relevant to us and to

00:00:26,039 --> 00:00:30,390
talk about how we can have that

00:00:27,449 --> 00:00:31,590
relationship with with academia right

00:00:30,390 --> 00:00:33,750
and where we're seeing people working on

00:00:31,590 --> 00:00:36,780
things and I'm particularly delighted to

00:00:33,750 --> 00:00:39,620
have Kathy because she's taking this

00:00:36,780 --> 00:00:43,050
analytical approach to thinking about

00:00:39,620 --> 00:00:44,190
open-source and particularly a category

00:00:43,050 --> 00:00:45,239
of open-source that I think I was a

00:00:44,190 --> 00:00:48,390
data-driven

00:00:45,239 --> 00:01:02,250
open-source I have wanted for a long

00:00:48,390 --> 00:01:04,890
time to think about modifying so maybe

00:01:02,250 --> 00:01:06,080
it was talking on hubs which is me I'm

00:01:04,890 --> 00:01:08,729
sorry about that

00:01:06,080 --> 00:01:09,750
I've wonderful a long time to have some

00:01:08,729 --> 00:01:11,939
to come in and talk about our

00:01:09,750 --> 00:01:13,080
relationship to data right because what

00:01:11,939 --> 00:01:14,820
I think is particularly exciting about

00:01:13,080 --> 00:01:19,470
the work that Kathy will be presenting

00:01:14,820 --> 00:01:21,299
today is that she is doing a very dated

00:01:19,470 --> 00:01:25,049
looking at a very data-driven approach

00:01:21,299 --> 00:01:28,560
to open-source work and I think if you

00:01:25,049 --> 00:01:30,329
look at article 6 of the manifesto we

00:01:28,560 --> 00:01:32,670
talked about article 6 basically says

00:01:30,329 --> 00:01:36,689
look Mozilla is a big fan of open source

00:01:32,670 --> 00:01:39,479
code and I would love to see it as you

00:01:36,689 --> 00:01:42,150
know next time we go oh and we revise

00:01:39,479 --> 00:01:43,470
the manifesto I would love to see us say

00:01:42,150 --> 00:01:45,509
look we're a big fan of open source code

00:01:43,470 --> 00:01:48,060
and data because the ways that knowledge

00:01:45,509 --> 00:01:49,530
is created in world are changing and the

00:01:48,060 --> 00:01:51,420
ways that open source is creating

00:01:49,530 --> 00:01:53,159
knowledge in the world are changing and

00:01:51,420 --> 00:01:56,159
they're changing in this data-driven way

00:01:53,159 --> 00:01:58,619
I was really excited to see that email

00:01:56,159 --> 00:02:00,630
that came out the other day that we've

00:01:58,619 --> 00:02:02,880
now got a VP of data coming and joining

00:02:00,630 --> 00:02:05,460
us I think starting next next Monday the

00:02:02,880 --> 00:02:07,710
Monday after that and that's the sort of

00:02:05,460 --> 00:02:09,539
change that I think we at Mozilla need

00:02:07,710 --> 00:02:11,610
to take seriously is understanding the

00:02:09,539 --> 00:02:15,180
role of data in creating open source

00:02:11,610 --> 00:02:19,270
opera indicating open source expiry

00:02:15,180 --> 00:02:21,040
but still taking seriously what it means

00:02:19,270 --> 00:02:23,080
to think about privacy and what it means

00:02:21,040 --> 00:02:24,730
to think about taking these things as

00:02:23,080 --> 00:02:27,130
first-class parts of the open source

00:02:24,730 --> 00:02:29,410
ecosystem so I'm going to stop rattling

00:02:27,130 --> 00:02:30,880
on and I would like to introduce you to

00:02:29,410 --> 00:02:34,140
Cathy Reed from Australian National

00:02:30,880 --> 00:02:37,480
University over to you Kathy thank you

00:02:34,140 --> 00:02:40,060
thanks I need thanks so much Joseph for

00:02:37,480 --> 00:02:41,800
that lovely introduction and almost of

00:02:40,060 --> 00:02:44,260
the opportunity to chat with everyone

00:02:41,800 --> 00:02:46,269
today there are three things that I'd

00:02:44,260 --> 00:02:48,940
like to do before I start the talk

00:02:46,269 --> 00:02:50,709
proper today firstly I'd like to

00:02:48,940 --> 00:02:53,739
acknowledge that I'm presenting today

00:02:50,709 --> 00:02:56,530
from Canberra in Australia this is the

00:02:53,739 --> 00:02:58,750
land is another one and every people the

00:02:56,530 --> 00:03:01,330
indigenous traditional custodians of the

00:02:58,750 --> 00:03:03,580
land and I pay my respects to their

00:03:01,330 --> 00:03:05,230
elders past and present and to their

00:03:03,580 --> 00:03:07,540
leaders emerging and I especially

00:03:05,230 --> 00:03:10,260
welcome any indigenous and First Nations

00:03:07,540 --> 00:03:12,849
people joining us today

00:03:10,260 --> 00:03:15,220
secondly I'd like to acknowledge that

00:03:12,849 --> 00:03:17,260
much of the open source voice ecosystem

00:03:15,220 --> 00:03:19,870
is built on the efforts of those who

00:03:17,260 --> 00:03:22,959
volunteer in the words of Tiffany Faris

00:03:19,870 --> 00:03:24,489
their time talent and treasure and I'd

00:03:22,959 --> 00:03:26,640
like to take the opportunity to

00:03:24,489 --> 00:03:29,769
acknowledge their contributions now

00:03:26,640 --> 00:03:32,500
sadly and I think for many of us most

00:03:29,769 --> 00:03:34,480
importantly at the moment I recognize

00:03:32,500 --> 00:03:36,370
that this is a very time time for people

00:03:34,480 --> 00:03:39,130
all over the world stealing at the

00:03:36,370 --> 00:03:41,560
impacts of covert 19 and I sincerely

00:03:39,130 --> 00:03:47,440
hope you and your loved ones remain safe

00:03:41,560 --> 00:03:49,569
and healthy so Who am I as dovish

00:03:47,440 --> 00:03:51,489
mentioned and can be read and I have a

00:03:49,569 --> 00:03:53,769
strong background in open source and

00:03:51,489 --> 00:03:55,170
some exposure to voice through my time

00:03:53,769 --> 00:03:58,299
at my cross may I

00:03:55,170 --> 00:03:59,980
last year I was one of sixteen students

00:03:58,299 --> 00:04:02,500
from across the world who headed to

00:03:59,980 --> 00:04:04,600
Canberra to undertake an educational

00:04:02,500 --> 00:04:07,380
experiment this distinguished professor

00:04:04,600 --> 00:04:09,850
Genevieve L at the three a Institute

00:04:07,380 --> 00:04:12,150
during that year we were treated for a

00:04:09,850 --> 00:04:14,790
range of incredibly diverse reached

00:04:12,150 --> 00:04:18,729
challenging and immersive educational

00:04:14,790 --> 00:04:20,500
experiences that had a single goal to

00:04:18,729 --> 00:04:24,099
give us the skills to take further

00:04:20,500 --> 00:04:25,890
physical systems data artificial

00:04:24,099 --> 00:04:27,610
intelligence and machine learning

00:04:25,890 --> 00:04:31,090
reliably safe

00:04:27,610 --> 00:04:33,009
and sustainably to scale and as a core

00:04:31,090 --> 00:04:35,080
part of that course we were required to

00:04:33,009 --> 00:04:37,539
undertake a capstone unit that explored

00:04:35,080 --> 00:04:42,069
a key topic and I chose open source

00:04:37,539 --> 00:04:44,680
voice but today's talk isn't just for

00:04:42,069 --> 00:04:47,530
voice people if you have an interest in

00:04:44,680 --> 00:04:49,810
how open source landscape shift or in

00:04:47,530 --> 00:04:52,300
how technology goes to scale or how it

00:04:49,810 --> 00:04:54,129
matures how it evolved and the

00:04:52,300 --> 00:04:56,050
trajectory through which this happens

00:04:54,129 --> 00:04:58,810
then you'll get something out of this

00:04:56,050 --> 00:05:00,789
talk I'm going to do a brief

00:04:58,810 --> 00:05:02,889
introduction to the components of the

00:05:00,789 --> 00:05:04,360
voice deck because I think it's useful

00:05:02,889 --> 00:05:06,069
to have an understanding of the

00:05:04,360 --> 00:05:08,529
different types of functionality than

00:05:06,069 --> 00:05:10,900
existing voice because it helps us to

00:05:08,529 --> 00:05:14,050
see how the landscape might be changing

00:05:10,900 --> 00:05:16,270
in a particular layer I'll cover some

00:05:14,050 --> 00:05:18,099
open source assessment frameworks and

00:05:16,270 --> 00:05:20,379
I'll be talking about why they're no

00:05:18,099 --> 00:05:23,349
longer appropriate as we enter an age of

00:05:20,379 --> 00:05:27,849
data machine learning artificial

00:05:23,349 --> 00:05:29,979
intelligence and systems of systems then

00:05:27,849 --> 00:05:32,139
I'll be painting a picture of three ways

00:05:29,979 --> 00:05:34,930
of open-source voice and some of the

00:05:32,139 --> 00:05:36,879
characteristics of those ways and argued

00:05:34,930 --> 00:05:39,400
that we're on the cusp of the third wave

00:05:36,879 --> 00:05:41,860
of open-source voice and that we have a

00:05:39,400 --> 00:05:45,509
rare moment to help shave the voice

00:05:41,860 --> 00:05:49,629
ecosystem over the next few years

00:05:45,509 --> 00:05:56,050
good let's start with a brief intro to

00:05:49,629 --> 00:05:58,150
the voice deck so those in the audience

00:05:56,050 --> 00:06:00,009
who don't have a background in voice I

00:05:58,150 --> 00:06:02,169
just want to quickly deconstruct what's

00:06:00,009 --> 00:06:04,509
in the voice deck and provide an

00:06:02,169 --> 00:06:06,520
overview of the sorts of functionality

00:06:04,509 --> 00:06:07,240
that you would find the in say of voice

00:06:06,520 --> 00:06:10,539
assistance

00:06:07,240 --> 00:06:12,839
so most voice assistance is some form of

00:06:10,539 --> 00:06:16,300
this stack

00:06:12,839 --> 00:06:18,369
so if you if you used the web stack or

00:06:16,300 --> 00:06:21,069
an application stack with different

00:06:18,369 --> 00:06:24,809
components this is very very similar we

00:06:21,069 --> 00:06:24,809
just use different software in the stack

00:06:24,989 --> 00:06:29,889
usually when we talk about the boy stack

00:06:27,519 --> 00:06:32,349
we don't include transcription as a

00:06:29,889 --> 00:06:35,649
layer but I've chosen to include it here

00:06:32,349 --> 00:06:38,019
for two reasons firstly in order to

00:06:35,649 --> 00:06:40,659
Train speech for text models we need

00:06:38,019 --> 00:06:42,089
recorded audio and a matching written

00:06:40,659 --> 00:06:46,119
transcription and orthographic

00:06:42,089 --> 00:06:47,740
transcription in many languages there

00:06:46,119 --> 00:06:49,809
aren't a lot of transcriptions of

00:06:47,740 --> 00:06:53,669
recorded audio so it makes it more

00:06:49,809 --> 00:06:56,860
difficult to train speech models Disney

00:06:53,669 --> 00:06:59,349
we often call these languages low

00:06:56,860 --> 00:07:01,599
resource languages because there aren't

00:06:59,349 --> 00:07:05,769
a lot of digitized resources available

00:07:01,599 --> 00:07:08,199
in those languages definitely as part of

00:07:05,769 --> 00:07:09,969
this work I've been speaking with

00:07:08,199 --> 00:07:12,189
several linguists at the center of

00:07:09,969 --> 00:07:15,189
excellence for dynamic languages here in

00:07:12,189 --> 00:07:17,229
Australia and for them transcription is

00:07:15,189 --> 00:07:20,409
a teen model Nick that they had in their

00:07:17,229 --> 00:07:24,009
research ops tool team transcription has

00:07:20,409 --> 00:07:26,139
a 40 to 1 ratio that is it takes 40

00:07:24,009 --> 00:07:28,449
minutes of labour to transcribe one

00:07:26,139 --> 00:07:31,029
minute of audio it's slow and it's

00:07:28,449 --> 00:07:35,229
painstaking and we need to consider it

00:07:31,029 --> 00:07:38,050
part of the overall voice deck thinking

00:07:35,229 --> 00:07:39,819
about Wake words most people here will

00:07:38,050 --> 00:07:41,439
have heard of a rake word that's the

00:07:39,819 --> 00:07:45,519
words that you say to wake up an

00:07:41,439 --> 00:07:49,089
assistant like election or ok Google or

00:07:45,519 --> 00:07:51,999
pay Mycroft the wake word software

00:07:49,089 --> 00:07:54,550
called a listener does to set it is

00:07:51,999 --> 00:07:57,959
constantly listening for the wake word

00:07:54,550 --> 00:08:01,209
and it's trained to hear the wake word

00:07:57,959 --> 00:08:03,519
if we go down another layer in speech to

00:08:01,209 --> 00:08:06,789
text this is the layer of the stack that

00:08:03,519 --> 00:08:08,699
takes recorded speech audio and turns it

00:08:06,789 --> 00:08:11,229
into written form called an utterance

00:08:08,699 --> 00:08:13,300
you might have seen videos with

00:08:11,229 --> 00:08:17,529
automatic speech captioning tools and

00:08:13,300 --> 00:08:20,349
devious speech-to-text going down

00:08:17,529 --> 00:08:22,269
another layer the intake parser takes

00:08:20,349 --> 00:08:25,440
the text that's generated by speech

00:08:22,269 --> 00:08:27,550
fatigues and tries to ascribe meaning

00:08:25,440 --> 00:08:29,860
there are different ways of passing

00:08:27,550 --> 00:08:33,070
intense but a common approach is called

00:08:29,860 --> 00:08:35,050
flawed meeting where the head pastor

00:08:33,070 --> 00:08:37,660
expects the outer of a particular

00:08:35,050 --> 00:08:39,670
structure that word slot into like

00:08:37,660 --> 00:08:42,250
please there the tongue with the entry

00:08:39,670 --> 00:08:48,040
for Monday at 5 p.m. where I do a thing

00:08:42,250 --> 00:08:50,410
in Texas feet it's the opposite of

00:08:48,040 --> 00:08:53,200
speech to text the text to speech player

00:08:50,410 --> 00:08:55,240
takes written information and then gives

00:08:53,200 --> 00:08:58,240
us a signifiers voice to play it back

00:08:55,240 --> 00:09:00,220
using audio so if you have a screen

00:08:58,240 --> 00:09:02,590
reader extension on the browser that

00:09:00,220 --> 00:09:07,020
reads continent out to you let's fix the

00:09:02,590 --> 00:09:10,810
speech the voice assistant itself

00:09:07,020 --> 00:09:12,940
gesture or a spy or minecraft is like

00:09:10,810 --> 00:09:14,530
the glue that holds all these components

00:09:12,940 --> 00:09:16,600
of the stack together it's like a

00:09:14,530 --> 00:09:19,450
wrapper or ribbon around all the layers

00:09:16,600 --> 00:09:21,610
in the stack so it's a very brief

00:09:19,450 --> 00:09:23,020
overview of a voice stack and the

00:09:21,610 --> 00:09:27,040
different types of software that you

00:09:23,020 --> 00:09:29,140
might find in one and for turning to

00:09:27,040 --> 00:09:33,010
what's special about as open source

00:09:29,140 --> 00:09:36,880
voice deck many of you who have used

00:09:33,010 --> 00:09:40,090
proprietary voice assistance for context

00:09:36,880 --> 00:09:43,060
is estimated that by 2023 there will be

00:09:40,090 --> 00:09:46,570
eight million voice assistance deployed

00:09:43,060 --> 00:09:48,700
and in 2019 alone nearly a hundred and

00:09:46,570 --> 00:09:52,210
forty seven million voice assistance

00:09:48,700 --> 00:09:54,700
worship worldwide market here in this

00:09:52,210 --> 00:09:57,610
space as you can see here is hotly

00:09:54,700 --> 00:10:00,040
contested by Amazon Google Apple and

00:09:57,610 --> 00:10:04,810
Chinese contender such as they do and

00:10:00,040 --> 00:10:07,780
JAL mean each of these companies has an

00:10:04,810 --> 00:10:09,910
overarching Lee commercial imperative to

00:10:07,780 --> 00:10:13,900
turn voice of systems and the data they

00:10:09,910 --> 00:10:16,810
collect into profit the business models

00:10:13,900 --> 00:10:19,830
used to do this vary but by having an

00:10:16,810 --> 00:10:23,410
always-on microphone in your house

00:10:19,830 --> 00:10:25,540
perhaps your bedroom proprietary base

00:10:23,410 --> 00:10:28,210
companies are able to gather significant

00:10:25,540 --> 00:10:30,940
data about you your family and you have

00:10:28,210 --> 00:10:33,520
it and because its proprietary

00:10:30,940 --> 00:10:36,040
technology consumers and users of the

00:10:33,520 --> 00:10:39,190
technology have very little ability to

00:10:36,040 --> 00:10:40,750
deconstruct inspect and interrogate was

00:10:39,190 --> 00:10:42,370
going on in this assemblage of

00:10:40,750 --> 00:10:46,420
technologies that make up a voice

00:10:42,370 --> 00:10:49,090
assistant ecosystem Commercial Driver's

00:10:46,420 --> 00:10:50,380
also named that some cohorts are not

00:10:49,090 --> 00:10:52,990
serviced at all

00:10:50,380 --> 00:10:56,650
such as those people who don't think a

00:10:52,990 --> 00:10:58,630
mainstream language for example some of

00:10:56,650 --> 00:11:00,520
the big companies only just started to

00:10:58,630 --> 00:11:02,290
support the Hindi language which is

00:11:00,520 --> 00:11:05,770
spoken by millions of people in India

00:11:02,290 --> 00:11:09,130
and some cohorts are not serviced at all

00:11:05,770 --> 00:11:11,770
such as those people who are free and

00:11:09,130 --> 00:11:13,660
some cohorts are under serviced because

00:11:11,770 --> 00:11:16,810
their technology doesn't recognize their

00:11:13,660 --> 00:11:20,940
voice well like women farmers we have

00:11:16,810 --> 00:11:24,940
Australian accents women children people

00:11:20,940 --> 00:11:28,030
and people with speech impediments these

00:11:24,940 --> 00:11:31,210
concerns over privacy openness equity

00:11:28,030 --> 00:11:33,580
equality intelligibility coupled with

00:11:31,210 --> 00:11:35,650
advances in technology that support

00:11:33,580 --> 00:11:37,870
machine learning have seen a growing

00:11:35,650 --> 00:11:42,040
interest in open source alternatives a

00:11:37,870 --> 00:11:44,020
big voice but how do you compare these

00:11:42,040 --> 00:11:46,900
open source products what

00:11:44,020 --> 00:11:49,090
characteristics are important which I

00:11:46,900 --> 00:11:54,310
thought product is when themselves to

00:11:49,090 --> 00:11:55,990
the needs of different cohorts so I said

00:11:54,310 --> 00:11:59,620
about trying to answer some of these

00:11:55,990 --> 00:12:01,900
questions and what I don't regionally

00:11:59,620 --> 00:12:04,630
plan to do with this project was to

00:12:01,900 --> 00:12:07,000
identify or create an assessment

00:12:04,630 --> 00:12:09,550
framework for open source software and

00:12:07,000 --> 00:12:11,530
then apply that to some of the software

00:12:09,550 --> 00:12:13,870
that's available at each level of the

00:12:11,530 --> 00:12:17,380
Boise State to see how it compares give

00:12:13,870 --> 00:12:19,660
it a rating and basically check the box

00:12:17,380 --> 00:12:21,360
that sounds really simple and

00:12:19,660 --> 00:12:26,190
straightforward and logical doesn't it

00:12:21,360 --> 00:12:26,190
so you know how this story goes right

00:12:26,430 --> 00:12:32,140
originally what I had in mind was

00:12:29,170 --> 00:12:34,089
building or using a maturity model you

00:12:32,140 --> 00:12:35,620
may have come across maturity models in

00:12:34,089 --> 00:12:38,010
the work that you do but in case you

00:12:35,620 --> 00:12:40,600
haven't I'll quickly cover them now

00:12:38,010 --> 00:12:43,150
maturity models typically look something

00:12:40,600 --> 00:12:45,160
like this they're sequential and the

00:12:43,150 --> 00:12:47,760
general idea is that you start in an ad

00:12:45,160 --> 00:12:50,650
hoc way and then you improve linearly

00:12:47,760 --> 00:12:52,980
incremental e overtime passing through

00:12:50,650 --> 00:12:58,110
stages of growth like you would from

00:12:52,980 --> 00:13:00,240
adolescence to adulthood many of the

00:12:58,110 --> 00:13:02,279
open source maturity models and

00:13:00,240 --> 00:13:06,120
assessment frameworks have taken exactly

00:13:02,279 --> 00:13:08,730
this approach identifying criteria then

00:13:06,120 --> 00:13:12,000
rating software I love the continuum so

00:13:08,730 --> 00:13:15,209
linear pathway does this software do it

00:13:12,000 --> 00:13:16,550
pick how well does this software do Inc

00:13:15,209 --> 00:13:19,139
titties

00:13:16,550 --> 00:13:22,139
many of the earth informs maturity

00:13:19,139 --> 00:13:26,910
models have the same starting point the

00:13:22,139 --> 00:13:29,820
iso/iec 96 offer standard and this

00:13:26,910 --> 00:13:32,399
having exactly what is expect to find in

00:13:29,820 --> 00:13:35,370
a soft way standard it talks about terms

00:13:32,399 --> 00:13:37,889
like functional suitability performance

00:13:35,370 --> 00:13:40,199
efficiency compatibility usability

00:13:37,889 --> 00:13:43,490
reliability security maintainability

00:13:40,199 --> 00:13:47,209
portability I'll stop there confirmed

00:13:43,490 --> 00:13:47,209
I'll sound like a drone

00:13:47,430 --> 00:13:58,200
what it misses is that all of the open

00:13:54,570 --> 00:14:00,810
source assessment frameworks have not

00:13:58,200 --> 00:14:03,959
been adopted in practice so where as

00:14:00,810 --> 00:14:06,660
iso/iec 9 one to six has been adopted in

00:14:03,959 --> 00:14:08,670
the fourth in industry its adaptation to

00:14:06,660 --> 00:14:11,459
open source hasn't been widely adopted

00:14:08,670 --> 00:14:15,230
at all and there's a couple of reasons

00:14:11,459 --> 00:14:18,300
for this firstly it's really complex

00:14:15,230 --> 00:14:21,120
it's hard to understand and it's hard to

00:14:18,300 --> 00:14:22,709
communicate and there's also very

00:14:21,120 --> 00:14:24,690
limited to lead to support the

00:14:22,709 --> 00:14:27,660
automation of these sorts of things so

00:14:24,690 --> 00:14:29,910
in order to do a maturity assessment you

00:14:27,660 --> 00:14:31,529
have to do a lot of manual work to to

00:14:29,910 --> 00:14:35,220
get to mansions and that's aa

00:14:31,529 --> 00:14:37,589
particularly appealing the other reason

00:14:35,220 --> 00:14:41,040
that they sort of what I call

00:14:37,589 --> 00:14:43,920
traditional approaches haven't taken off

00:14:41,040 --> 00:14:46,050
in open source is that they neglect one

00:14:43,920 --> 00:14:49,020
of the main assets that we have in open

00:14:46,050 --> 00:14:51,360
source which is a community and only

00:14:49,020 --> 00:14:54,060
later attempts that open source maturity

00:14:51,360 --> 00:14:57,930
models I tried to take into account the

00:14:54,060 --> 00:15:00,900
open source community and more

00:14:57,930 --> 00:15:03,870
importantly none of these models taking

00:15:00,900 --> 00:15:08,520
to account considerations necessary for

00:15:03,870 --> 00:15:10,290
an era of data and machine learning such

00:15:08,520 --> 00:15:13,230
as things like the sphere guiding

00:15:10,290 --> 00:15:18,110
principles for data is data findable

00:15:13,230 --> 00:15:18,110
accessible interoperable reusable

00:15:18,330 --> 00:15:24,270
these these frameworks don't take into

00:15:22,140 --> 00:15:27,390
account things like buyers in datasets

00:15:24,270 --> 00:15:30,300
like gender bias or racial bias or

00:15:27,390 --> 00:15:32,010
ethnographic wise and they don't think

00:15:30,300 --> 00:15:35,220
about the needs of under-resourced

00:15:32,010 --> 00:15:37,610
languages or underrepresented group they

00:15:35,220 --> 00:15:40,380
don't think about concepts like equity

00:15:37,610 --> 00:15:41,720
which in a data based world in a

00:15:40,380 --> 00:15:47,190
data-driven world are increasingly

00:15:41,720 --> 00:15:49,080
important so I think they build an

00:15:47,190 --> 00:15:51,330
open-source assessment framework that

00:15:49,080 --> 00:15:54,630
extended some of these existing ones by

00:15:51,330 --> 00:15:56,490
adding on Mississippi requires and how

00:15:54,630 --> 00:15:59,790
well the software supported additional

00:15:56,490 --> 00:16:03,060
languages but I quickly realized though

00:15:59,790 --> 00:16:05,610
is making the problem worse voice

00:16:03,060 --> 00:16:09,810
doesn't fit neatly into linear ways of

00:16:05,610 --> 00:16:12,330
thinking about maturity for example is a

00:16:09,810 --> 00:16:14,030
failure to have on device processing or

00:16:12,330 --> 00:16:17,940
offloaded to a cloud

00:16:14,030 --> 00:16:19,680
well it depends and many a maturity

00:16:17,940 --> 00:16:23,760
models don't deal well with they're full

00:16:19,680 --> 00:16:25,740
of ambiguity instead if I read more

00:16:23,760 --> 00:16:30,080
about Oaks full voice and voice in

00:16:25,740 --> 00:16:30,080
general I started to observe patterns

00:16:30,920 --> 00:16:39,050
and that pattern can best be described

00:16:34,650 --> 00:16:41,970
as three waves each wave has particular

00:16:39,050 --> 00:16:44,520
characteristics just like a maturity

00:16:41,970 --> 00:16:48,090
model does except that it's not as

00:16:44,520 --> 00:16:50,820
finite it's not as clear-cut it's much

00:16:48,090 --> 00:16:55,500
more of a landscape with contours rather

00:16:50,820 --> 00:16:57,450
than creeks up boundaries my argument is

00:16:55,500 --> 00:17:00,450
that open source software open source

00:16:57,450 --> 00:17:03,090
voice software can be categorized into

00:17:00,450 --> 00:17:05,870
one of these three waves based on some

00:17:03,090 --> 00:17:05,870
common characteristics

00:17:06,650 --> 00:17:11,570
further I argue that we are late into

00:17:09,170 --> 00:17:14,930
the second wave of open source boys and

00:17:11,570 --> 00:17:18,320
on the cusp of the third we have a rare

00:17:14,930 --> 00:17:20,990
opportunity an inflection point to shape

00:17:18,320 --> 00:17:23,240
a third wave evolved and what the future

00:17:20,990 --> 00:17:25,600
of open source voice looks like over the

00:17:23,240 --> 00:17:28,780
foreseeable future

00:17:25,600 --> 00:17:31,740
we have deliberate choices to make that

00:17:28,780 --> 00:17:35,179
will affect voice technology

00:17:31,740 --> 00:17:35,179
so let's take a look at this way

00:17:36,299 --> 00:17:42,309
so all those voice technologies like

00:17:39,159 --> 00:17:45,309
speech recognition and speech synthesis

00:17:42,309 --> 00:17:47,350
had their origins decades earlier with

00:17:45,309 --> 00:17:50,259
people like homemade ugly of Bell Labs

00:17:47,350 --> 00:17:52,750
and his proposal in the 1930s for speech

00:17:50,259 --> 00:17:55,330
recognition and physicians for the

00:17:52,750 --> 00:17:58,659
development here happens primarily with

00:17:55,330 --> 00:18:01,870
the emerged companies DARPA Bell Labs

00:17:58,659 --> 00:18:04,240
the Macy conferences of the 1940s and

00:18:01,870 --> 00:18:07,419
1950s held the development of human-like

00:18:04,240 --> 00:18:09,639
speak to the goal but it was eventually

00:18:07,419 --> 00:18:12,519
another technical revolution another

00:18:09,639 --> 00:18:14,259
trajectory intersected with voice but we

00:18:12,519 --> 00:18:17,710
start to see the development of

00:18:14,259 --> 00:18:19,779
open-source voice and of course sets of

00:18:17,710 --> 00:18:24,059
the birth of the free software as open

00:18:19,779 --> 00:18:27,039
source movement in the 1980s and 1990s

00:18:24,059 --> 00:18:29,549
that movement and significant adoption

00:18:27,039 --> 00:18:31,929
in universities and unsurprisingly

00:18:29,549 --> 00:18:33,090
that's where we see the first wave of

00:18:31,929 --> 00:18:37,360
open source

00:18:33,090 --> 00:18:39,820
originated this software was primarily

00:18:37,360 --> 00:18:42,100
used for research purposes and was the

00:18:39,820 --> 00:18:44,649
basis of several publications around

00:18:42,100 --> 00:18:49,029
speech recognition and speech citizens

00:18:44,649 --> 00:18:53,320
and tools such as C mu C and Cowley fit

00:18:49,029 --> 00:18:56,799
into this category very TTS and espeak

00:18:53,320 --> 00:18:59,289
as well these products often use

00:18:56,799 --> 00:19:01,480
rule-based inference for tasks such as

00:18:59,289 --> 00:19:04,960
speech recognition and voice synthesis

00:19:01,480 --> 00:19:07,320
and they tend to use older or less

00:19:04,960 --> 00:19:11,019
popular programming languages for

00:19:07,320 --> 00:19:15,309
example the East beacon T text-to-speech

00:19:11,019 --> 00:19:17,620
engine it's thing is as NCC even though

00:19:15,309 --> 00:19:20,799
it's a very active very active project

00:19:17,620 --> 00:19:26,279
and it's rare to see those languages

00:19:20,799 --> 00:19:26,279
used with dismal modern projects

00:19:28,210 --> 00:19:36,049
so thinking about the markers for the

00:19:31,070 --> 00:19:38,030
end of the first wave as a whole what I

00:19:36,049 --> 00:19:41,720
started to see when I looked at some of

00:19:38,030 --> 00:19:43,610
these these software projects across the

00:19:41,720 --> 00:19:45,140
stack was that several of the

00:19:43,610 --> 00:19:47,240
research-based projects are being

00:19:45,140 --> 00:19:51,020
abandoned then I dug into that a little

00:19:47,240 --> 00:19:53,809
bit deeper and found two causes one is

00:19:51,020 --> 00:19:56,570
it the funding for the project dries up

00:19:53,809 --> 00:20:00,590
and it can no longer sustain the

00:19:56,570 --> 00:20:02,330
researcher is actively working on it but

00:20:00,590 --> 00:20:04,010
the other course that's being observed

00:20:02,330 --> 00:20:06,350
for example in the case of seeing you

00:20:04,010 --> 00:20:07,910
think is that the authors have gone to

00:20:06,350 --> 00:20:10,220
work in the artificial intelligence

00:20:07,910 --> 00:20:12,559
sector where they're machine learning

00:20:10,220 --> 00:20:14,419
skills are highly valued and so they've

00:20:12,559 --> 00:20:18,320
been taken out of the public sector the

00:20:14,419 --> 00:20:20,390
research sector and attracting into into

00:20:18,320 --> 00:20:24,169
the commercial and private sector

00:20:20,390 --> 00:20:26,690
because their skills are so good we also

00:20:24,169 --> 00:20:29,150
see at the end of the first wave that

00:20:26,690 --> 00:20:32,240
the rise of developments in the hardware

00:20:29,150 --> 00:20:35,570
space so we see in the two thousands the

00:20:32,240 --> 00:20:37,520
emergence of powerful GPU hardware and

00:20:35,570 --> 00:20:39,200
instead of rule-based inference we see

00:20:37,520 --> 00:20:42,140
the adoption of neural network based

00:20:39,200 --> 00:20:44,120
approaches to machine learning tasks so

00:20:42,140 --> 00:20:47,150
that means that the first sort of shift

00:20:44,120 --> 00:20:50,950
in evolution near the end of the first

00:20:47,150 --> 00:20:50,950
wave and the start of the second wave

00:20:51,320 --> 00:20:57,600
the second wave is characterized by

00:20:54,600 --> 00:21:00,360
software created for by profit companies

00:20:57,600 --> 00:21:02,790
using an open-source license as part of

00:21:00,360 --> 00:21:04,860
their business strategy usually to

00:21:02,790 --> 00:21:06,300
attract large open-source communities

00:21:04,860 --> 00:21:09,750
who contribute to their product

00:21:06,300 --> 00:21:15,000
offerings and companies like rasa run by

00:21:09,750 --> 00:21:17,670
craft a part of that I if you want to

00:21:15,000 --> 00:21:21,300
talk to me about snips I'm very happy to

00:21:17,670 --> 00:21:23,400
do that but after the talk these

00:21:21,300 --> 00:21:25,980
products tend to use different types of

00:21:23,400 --> 00:21:28,890
neural network for tasks such as speech

00:21:25,980 --> 00:21:32,880
recognition intent passing and voice

00:21:28,890 --> 00:21:36,450
synthesis so there way that they do what

00:21:32,880 --> 00:21:39,230
they do has changed as well where

00:21:36,450 --> 00:21:42,720
research is happening has also shifted

00:21:39,230 --> 00:21:46,320
instead of research being done by public

00:21:42,720 --> 00:21:48,780
universities and then published into

00:21:46,320 --> 00:21:49,260
into a space where people can learn from

00:21:48,780 --> 00:21:51,480
there

00:21:49,260 --> 00:21:54,510
what we're seeing is that research has

00:21:51,480 --> 00:21:56,600
been done by big voice companies rather

00:21:54,510 --> 00:22:00,900
than by publicly funded research

00:21:56,600 --> 00:22:04,380
institutions a lot of that research is

00:22:00,900 --> 00:22:06,780
still published still published but it

00:22:04,380 --> 00:22:08,340
doesn't have the same it doesn't have

00:22:06,780 --> 00:22:09,030
the same driver it doesn't have the same

00:22:08,340 --> 00:22:11,490
origin

00:22:09,030 --> 00:22:13,920
there's the researcher gender is now

00:22:11,490 --> 00:22:17,490
very much commercially driven not

00:22:13,920 --> 00:22:19,380
necessarily publicly driven and my

00:22:17,490 --> 00:22:22,260
argument is that we're well into this

00:22:19,380 --> 00:22:24,830
second wave and we're on the cusp of a

00:22:22,260 --> 00:22:24,830
third wave

00:22:28,880 --> 00:22:33,810
there are several markers that signify

00:22:31,620 --> 00:22:36,150
the end of the second wave and the

00:22:33,810 --> 00:22:39,300
beginning of the third wave of open

00:22:36,150 --> 00:22:41,550
source voice we're seeing the increased

00:22:39,300 --> 00:22:44,130
proliferation of voice datasets across

00:22:41,550 --> 00:22:47,550
the world from which speech models can

00:22:44,130 --> 00:22:49,980
be trained recording and transcription

00:22:47,550 --> 00:22:52,560
are becoming easier they're still not

00:22:49,980 --> 00:22:54,630
easy but they're easier and so it's

00:22:52,560 --> 00:22:57,960
easier to generate speech corporate

00:22:54,630 --> 00:23:01,680
training we're seeing the line between

00:22:57,960 --> 00:23:03,270
human and synthetic voices blurring so

00:23:01,680 --> 00:23:06,300
Google is doing this in a proprietary

00:23:03,270 --> 00:23:08,430
space with duplex but we're also getting

00:23:06,300 --> 00:23:10,680
close in the open floor space with the

00:23:08,430 --> 00:23:14,640
various tacit Ron implementation for

00:23:10,680 --> 00:23:18,000
taking us ever around now but perhaps

00:23:14,640 --> 00:23:20,460
the biggest marker here is that voice is

00:23:18,000 --> 00:23:23,430
going feral in the words of Genevieve

00:23:20,460 --> 00:23:26,850
though it's being embedded in smart

00:23:23,430 --> 00:23:29,750
speakers in mobile devices in cars in

00:23:26,850 --> 00:23:32,610
appliances and in smart home devices

00:23:29,750 --> 00:23:35,310
we're seeing embedded our China contrast

00:23:32,610 --> 00:23:37,200
requires is all sorts of things that we

00:23:35,310 --> 00:23:41,840
couldn't have imagined even five years

00:23:37,200 --> 00:23:45,030
ago voice is going to scale as a

00:23:41,840 --> 00:23:47,870
component in cyber physical systems all

00:23:45,030 --> 00:23:47,870
over the world

00:23:48,630 --> 00:23:55,590
open-source voice is at a tipping point

00:23:50,700 --> 00:23:58,020
an inflection point the third wave of

00:23:55,590 --> 00:24:00,720
open-source voice is almost upon us

00:23:58,020 --> 00:24:02,460
and we have only a short window in which

00:24:00,720 --> 00:24:04,290
to exert some influence on that

00:24:02,460 --> 00:24:08,700
landscape as I think fall under them

00:24:04,290 --> 00:24:12,150
fold what directions can it go in how do

00:24:08,700 --> 00:24:14,250
we shape those directions how do we make

00:24:12,150 --> 00:24:18,600
sure that we're building a world of open

00:24:14,250 --> 00:24:22,020
voice that we want to see let's look at

00:24:18,600 --> 00:24:23,610
some of those possible trajectories and

00:24:22,020 --> 00:24:26,550
let's take a look at gender first

00:24:23,610 --> 00:24:28,530
because well I'm an Australian woman and

00:24:26,550 --> 00:24:33,050
I'm pride of speech recognition not

00:24:28,530 --> 00:24:36,360
recognizing my gender or my accent so

00:24:33,050 --> 00:24:38,220
this is a piece by Medellin Morley that

00:24:36,360 --> 00:24:40,680
came out only last week and she poses

00:24:38,220 --> 00:24:43,500
the question what would a feminist

00:24:40,680 --> 00:24:45,540
Alexis sounds like and I think that's a

00:24:43,500 --> 00:24:49,860
very very interesting question to unpack

00:24:45,540 --> 00:24:52,650
a little bit more collective moment

00:24:49,860 --> 00:24:54,300
women's voices are not recognized very

00:24:52,650 --> 00:24:56,370
well by speech-to-text

00:24:54,300 --> 00:24:58,680
because the training clicks on which

00:24:56,370 --> 00:25:01,200
they're trained the data on which

00:24:58,680 --> 00:25:05,340
they're trained doesn't contain as many

00:25:01,200 --> 00:25:07,920
circles of women women's voices are

00:25:05,340 --> 00:25:10,710
associated with subservient assistant

00:25:07,920 --> 00:25:13,370
based roles and often voice assistants

00:25:10,710 --> 00:25:16,080
that sound like women will be harassed

00:25:13,370 --> 00:25:19,650
but made harassment is left unchecked

00:25:16,080 --> 00:25:22,710
and the personas that these voices use

00:25:19,650 --> 00:25:25,830
will often adopt a very subservient or

00:25:22,710 --> 00:25:27,450
audiophile approach and I don't know

00:25:25,830 --> 00:25:29,670
about you but that's another trajectory

00:25:27,450 --> 00:25:32,550
that I would like to see continued into

00:25:29,670 --> 00:25:35,370
the future I think we can do better and

00:25:32,550 --> 00:25:38,640
so what does breaking yard of this

00:25:35,370 --> 00:25:41,430
trajectory look like I think what we

00:25:38,640 --> 00:25:43,410
need to focus on is dovish pointed out

00:25:41,430 --> 00:25:47,820
very early in this team and very early

00:25:43,410 --> 00:25:49,560
in this talk is about the data voice is

00:25:47,820 --> 00:25:51,360
data-driven and we need to think

00:25:49,560 --> 00:25:53,850
critically about how we use that data

00:25:51,360 --> 00:25:56,340
how it goes through a value chain how it

00:25:53,850 --> 00:25:58,670
transforms into machine learning models

00:25:56,340 --> 00:26:01,170
and into services based on those models

00:25:58,670 --> 00:26:02,130
so we need to be thinking about things

00:26:01,170 --> 00:26:04,169
like equal

00:26:02,130 --> 00:26:06,840
presentation of female voices in

00:26:04,169 --> 00:26:11,490
training data sets and I know for a lot

00:26:06,840 --> 00:26:13,710
of the openness of our resources there

00:26:11,490 --> 00:26:15,990
was a paper done where they looked at

00:26:13,710 --> 00:26:19,020
whether and whether there was

00:26:15,990 --> 00:26:23,390
equivalents in those data sets and in

00:26:19,020 --> 00:26:25,770
the open floor space it's about a

00:26:23,390 --> 00:26:30,150
two-thirds majority at the moment in

00:26:25,770 --> 00:26:33,270
some of those open data set we have that

00:26:30,150 --> 00:26:37,169
means that there are two samples of

00:26:33,270 --> 00:26:40,289
males learning voices two to everyone

00:26:37,169 --> 00:26:42,530
female sounding points so we need to

00:26:40,289 --> 00:26:46,860
think critically about that and how we

00:26:42,530 --> 00:26:49,440
have more equitable representation we

00:26:46,860 --> 00:26:52,289
also need to define design voice user

00:26:49,440 --> 00:26:55,020
interfaces and interaction in a way

00:26:52,289 --> 00:26:57,960
where the voices of women stand up to

00:26:55,020 --> 00:27:00,600
harassment they don't just accept some

00:26:57,960 --> 00:27:02,789
of the some of the utterances that are

00:27:00,600 --> 00:27:06,600
made but they tended in a much more

00:27:02,789 --> 00:27:08,640
nuanced way and one of the other pieces

00:27:06,600 --> 00:27:11,789
that came out as I was looking at the

00:27:08,640 --> 00:27:13,970
Arkansas voice space is that we use

00:27:11,789 --> 00:27:16,950
different voices in different headings

00:27:13,970 --> 00:27:19,980
so women's voices are often used in

00:27:16,950 --> 00:27:21,960
assistance type roles in voice and we

00:27:19,980 --> 00:27:25,650
give women ordens we ask them to do

00:27:21,960 --> 00:27:28,890
tongues for us but men's voices are used

00:27:25,650 --> 00:27:30,900
in more authoritative settings for men

00:27:28,890 --> 00:27:33,419
men's voices they use where they're

00:27:30,900 --> 00:27:35,580
telling us about a product or they're

00:27:33,419 --> 00:27:38,580
instructing us about a particular choice

00:27:35,580 --> 00:27:40,799
that we need to make and I'd like to see

00:27:38,580 --> 00:27:43,830
us think critically about how we use

00:27:40,799 --> 00:27:45,000
voice data and in what settings we use

00:27:43,830 --> 00:27:46,890
that so that we're not

00:27:45,000 --> 00:27:53,669
inculcating some of these stereotypes

00:27:46,890 --> 00:27:57,240
and trajectories there's a three line

00:27:53,669 --> 00:28:00,720
here turned to race lace is another very

00:27:57,240 --> 00:28:04,770
important trajectory this piece came out

00:28:00,720 --> 00:28:06,720
only this week in the New York Times and

00:28:04,770 --> 00:28:12,210
they talked about a paper that came out

00:28:06,720 --> 00:28:15,970
of Stanford where basically what the

00:28:12,210 --> 00:28:18,490
research paper did was assess how well

00:28:15,970 --> 00:28:22,000
from different demographics were

00:28:18,490 --> 00:28:26,020
recognized within the speech this

00:28:22,000 --> 00:28:28,500
recognition which detects player and if

00:28:26,020 --> 00:28:31,390
you come from a predominantly white area

00:28:28,500 --> 00:28:34,570
then your chance of being recognized by

00:28:31,390 --> 00:28:39,760
our voices sisters much higher and again

00:28:34,570 --> 00:28:41,890
this is a data problem minority dialects

00:28:39,760 --> 00:28:46,030
which often intersect along racial lines

00:28:41,890 --> 00:28:47,740
I'm not well recognizing this TP so

00:28:46,030 --> 00:28:49,930
stick to the text and they're less

00:28:47,740 --> 00:28:53,490
represented in text-to-speech data sets

00:28:49,930 --> 00:28:55,890
as well again this is a data problem

00:28:53,490 --> 00:28:58,120
we're not thinking critically about

00:28:55,890 --> 00:29:02,370
equity and data we're not thinking

00:28:58,120 --> 00:29:02,370
critically about representation in data

00:29:03,300 --> 00:29:07,950
so they're also that trajectory to shape

00:29:05,400 --> 00:29:10,590
the course of open-source voice over the

00:29:07,950 --> 00:29:12,090
next few years we need to again be

00:29:10,590 --> 00:29:14,820
thinking about more equitable

00:29:12,090 --> 00:29:18,570
representation we need to be thinking

00:29:14,820 --> 00:29:21,300
about the ability to give people the

00:29:18,570 --> 00:29:24,630
ability to give people a voice that they

00:29:21,300 --> 00:29:27,450
resonate with a voice that sounds like

00:29:24,630 --> 00:29:29,640
them although at the moment with my

00:29:27,450 --> 00:29:31,290
Australian accent and stuff it goes I'm

00:29:29,640 --> 00:29:35,640
not sure you wonderful or not although I

00:29:31,290 --> 00:29:37,250
want a voice themselves like me again we

00:29:35,640 --> 00:29:41,430
also need to be thinking about

00:29:37,250 --> 00:29:43,740
positioning and not using voices in a

00:29:41,430 --> 00:29:45,780
way that is seen as gimmicks and I'm

00:29:43,740 --> 00:29:48,360
sure some of you in the late 90s or

00:29:45,780 --> 00:29:51,810
2000s all have used GPS with voices like

00:29:48,360 --> 00:29:53,640
your own roar and James Earl Jones so

00:29:51,810 --> 00:29:56,520
again we need to be thinking about the

00:29:53,640 --> 00:29:58,850
positioning of voice excuse me just walk

00:29:56,520 --> 00:29:58,850
over

00:30:03,800 --> 00:30:05,860
you

00:30:09,499 --> 00:30:16,580
another very closely related trajectory

00:30:12,629 --> 00:30:20,730
is that as low resource indigenous

00:30:16,580 --> 00:30:23,940
endangered and sleeping languages and as

00:30:20,730 --> 00:30:27,509
a smaller vibe in Australian vision of

00:30:23,940 --> 00:30:29,759
languages we deliberately try to use the

00:30:27,509 --> 00:30:32,999
word sleeping language rather than dead

00:30:29,759 --> 00:30:35,879
language because if we use this if we

00:30:32,999 --> 00:30:38,190
use the word sleeping then it offers us

00:30:35,879 --> 00:30:39,929
a space to think about how that language

00:30:38,190 --> 00:30:42,749
might be woken up again

00:30:39,929 --> 00:30:44,639
how it might be reanimated and brought

00:30:42,749 --> 00:30:47,220
back and there's a lot of work going on

00:30:44,639 --> 00:30:51,389
at the moment to think about and how we

00:30:47,220 --> 00:30:55,499
how we reanimate some about sleeping

00:30:51,389 --> 00:30:57,960
indigenous languages so this is only the

00:30:55,499 --> 00:31:00,299
robot and IP is helping preserve

00:30:57,960 --> 00:31:02,820
languages in the north of Australia at

00:31:00,299 --> 00:31:05,399
the local language centre in the

00:31:02,820 --> 00:31:08,970
Northern Territory and this is just one

00:31:05,399 --> 00:31:13,679
example of how open-source voice and low

00:31:08,970 --> 00:31:17,389
resource languages intersect so the

00:31:13,679 --> 00:31:17,389
trajectory that we're on here

00:31:17,870 --> 00:31:25,580
again is data-driven inform about the

00:31:20,990 --> 00:31:27,920
data encryption is hard so time together

00:31:25,580 --> 00:31:29,930
orthographic material written material

00:31:27,920 --> 00:31:32,990
to support the development of low

00:31:29,930 --> 00:31:35,360
resource language corpora and fewer

00:31:32,990 --> 00:31:39,110
resources needed harder to Train speech

00:31:35,360 --> 00:31:42,470
models there's another trajectory piece

00:31:39,110 --> 00:31:44,000
here as well that makes it harder for

00:31:42,470 --> 00:31:48,140
lower resourcing we're just to get a

00:31:44,000 --> 00:31:50,720
foothold in voice technology and that's

00:31:48,140 --> 00:31:54,470
that often they have very small faces of

00:31:50,720 --> 00:31:56,630
figures so that means they're low

00:31:54,470 --> 00:31:59,780
resource languages tend to be other

00:31:56,630 --> 00:32:02,390
trusted commercially we've only just

00:31:59,780 --> 00:32:04,640
seen Hindi support income of the

00:32:02,390 --> 00:32:06,200
proprietary voice assistance even though

00:32:04,640 --> 00:32:10,490
there are millions of speakers of Hindi

00:32:06,200 --> 00:32:12,590
across the world imagine I imagine that

00:32:10,490 --> 00:32:15,770
the business case for a language like

00:32:12,590 --> 00:32:18,410
all three or younger masa indigenous

00:32:15,770 --> 00:32:23,630
Australian languages is very hard to

00:32:18,410 --> 00:32:25,970
make and I understand that if we think

00:32:23,630 --> 00:32:30,610
about again how we might change or

00:32:25,970 --> 00:32:33,350
Schabel or change the pathway here I

00:32:30,610 --> 00:32:35,150
think what we need here is stronger

00:32:33,350 --> 00:32:37,700
government support for the development

00:32:35,150 --> 00:32:40,550
of these resources the tooling corpora

00:32:37,700 --> 00:32:42,350
and there's an echo here to the corridor

00:32:40,550 --> 00:32:46,100
model in Australia the Center for

00:32:42,350 --> 00:32:49,059
Excellence in dynamic languages the

00:32:46,100 --> 00:32:52,580
investment that they make helps to make

00:32:49,059 --> 00:32:54,290
helps to make voice and investment in

00:32:52,580 --> 00:32:57,320
voice in these one resource languages

00:32:54,290 --> 00:32:58,970
more commercially attractive for example

00:32:57,320 --> 00:33:01,040
the New Zealand government which has

00:32:58,970 --> 00:33:03,860
today our Mallory as an official

00:33:01,040 --> 00:33:06,110
language of New Zealand and New Year's

00:33:03,860 --> 00:33:09,580
million tens of millions of New Zealand

00:33:06,110 --> 00:33:13,250
dollars every year trying to build up

00:33:09,580 --> 00:33:15,740
resources and so now and I think that's

00:33:13,250 --> 00:33:18,590
something as open-source practitioners

00:33:15,740 --> 00:33:21,890
we need to become more involved in

00:33:18,590 --> 00:33:24,710
because it it helps to both support

00:33:21,890 --> 00:33:28,370
those low resource languages but support

00:33:24,710 --> 00:33:30,440
the ecosystem as a whole there's another

00:33:28,370 --> 00:33:33,350
piece here about library fourth language

00:33:30,440 --> 00:33:36,500
ins and that's by having an entire open

00:33:33,350 --> 00:33:37,940
source tool chain the development of

00:33:36,500 --> 00:33:40,250
corpora

00:33:37,940 --> 00:33:42,679
becomes easier the training of corpora

00:33:40,250 --> 00:33:44,750
becomes easier and then certainly we

00:33:42,679 --> 00:33:47,510
have this then suddenly we have speech

00:33:44,750 --> 00:33:50,240
language and speech models available in

00:33:47,510 --> 00:33:52,610
those languages so we also need to think

00:33:50,240 --> 00:33:54,620
about the entire open source tool chain

00:33:52,610 --> 00:33:56,870
the open source voice tool chain is a

00:33:54,620 --> 00:33:59,690
home where are the gaps in that tool

00:33:56,870 --> 00:34:03,560
chain so at the moment we really only

00:33:59,690 --> 00:34:05,750
have alarms for transcription and the

00:34:03,560 --> 00:34:08,030
Center for Excellence in dynamic

00:34:05,750 --> 00:34:11,899
languages is working on tools like Elvis

00:34:08,030 --> 00:34:13,970
and Persephone that help to transcribe

00:34:11,899 --> 00:34:16,159
when resource languages so that you can

00:34:13,970 --> 00:34:19,159
train models to help you transcribe off

00:34:16,159 --> 00:34:26,359
very very small data set again a call

00:34:19,159 --> 00:34:29,050
without the data if I mentioned data so

00:34:26,359 --> 00:34:32,240
we have a continuing trajectory here of

00:34:29,050 --> 00:34:35,120
poor awareness of the nuances of Bayda

00:34:32,240 --> 00:34:36,530
province providence of licensing the

00:34:35,120 --> 00:34:39,860
person behind the day

00:34:36,530 --> 00:34:42,830
often gets lost current approaches the

00:34:39,860 --> 00:34:45,620
data are often n hog the driver is to

00:34:42,830 --> 00:34:48,470
have bigger more data sets not

00:34:45,620 --> 00:34:51,950
necessarily better data set which might

00:34:48,470 --> 00:34:54,740
be smaller and so to break out of this

00:34:51,950 --> 00:34:56,990
trajectory we need some whole life cycle

00:34:54,740 --> 00:35:00,860
thinking about data and where it fits

00:34:56,990 --> 00:35:02,900
into the voice value chain and there's

00:35:00,860 --> 00:35:04,940
also an excellent paper that's come out

00:35:02,900 --> 00:35:06,910
recently from the Bennett Institute at

00:35:04,940 --> 00:35:09,470
Cambridge University

00:35:06,910 --> 00:35:12,830
we've probably heard the mantra that

00:35:09,470 --> 00:35:15,200
data is an asset it's the new oil is the

00:35:12,830 --> 00:35:19,550
fuel with fiber physical systems and

00:35:15,200 --> 00:35:23,840
machine learning this paper reframes

00:35:19,550 --> 00:35:26,960
data and holds that it's that it's a

00:35:23,840 --> 00:35:29,870
shared common good data is a public good

00:35:26,960 --> 00:35:31,940
and just like our parks or just like our

00:35:29,870 --> 00:35:34,360
environment there's a moral obligation

00:35:31,940 --> 00:35:37,780
there to make sure that we're treating

00:35:34,360 --> 00:35:40,580
public data data that is a public good

00:35:37,780 --> 00:35:42,650
in the same way that we might care for

00:35:40,580 --> 00:35:44,390
and have some custodial obligations

00:35:42,650 --> 00:35:48,830
around other public and Commons

00:35:44,390 --> 00:35:50,900
resources so we need to think we need to

00:35:48,830 --> 00:35:56,630
see critically about data as a

00:35:50,900 --> 00:36:00,650
trajectory and metadata is also a part

00:35:56,630 --> 00:36:03,550
of a conversation at the moment metadata

00:36:00,650 --> 00:36:06,650
standards around open voice datasets

00:36:03,550 --> 00:36:09,380
continue to be patchy there isn't an

00:36:06,650 --> 00:36:12,170
emerging industry stone business and to

00:36:09,380 --> 00:36:14,900
break out of that trajectory we need to

00:36:12,170 --> 00:36:18,050
adopt a common metadata standard for

00:36:14,900 --> 00:36:21,320
labeling open voice datasets gender

00:36:18,050 --> 00:36:23,870
provenance other markers that help to

00:36:21,320 --> 00:36:26,810
ensure a representation and help to

00:36:23,870 --> 00:36:31,750
ensure that we have a much more

00:36:26,810 --> 00:36:34,130
equitable open voice landscape I've

00:36:31,750 --> 00:36:37,640
mentioned before the role of government

00:36:34,130 --> 00:36:39,410
in my resource languages but I want to

00:36:37,640 --> 00:36:42,860
draw some other touch points here as

00:36:39,410 --> 00:36:44,600
well if we step back a slide or two and

00:36:42,860 --> 00:36:46,730
remember that the first wave of

00:36:44,600 --> 00:36:48,950
open-source voice came from universities

00:36:46,730 --> 00:36:50,370
from really with research driven and

00:36:48,950 --> 00:36:52,440
that the second

00:36:50,370 --> 00:36:53,970
was driven by companies who had open

00:36:52,440 --> 00:36:56,850
source voice as part of their business

00:36:53,970 --> 00:36:59,330
model then we have to ask the question

00:36:56,850 --> 00:37:01,950
what is the role of government in voice

00:36:59,330 --> 00:37:04,940
right now governments have very little

00:37:01,950 --> 00:37:08,280
involvement and instead of looking at

00:37:04,940 --> 00:37:11,220
open source options they often use

00:37:08,280 --> 00:37:13,470
commercial voice providers for emerging

00:37:11,220 --> 00:37:17,130
technology experiments particularly in

00:37:13,470 --> 00:37:19,200
the health sector so this subscribe here

00:37:17,130 --> 00:37:22,230
for governments to have influence on how

00:37:19,200 --> 00:37:24,690
open-source voice evolved for example by

00:37:22,230 --> 00:37:27,120
partnering with research organizations

00:37:24,690 --> 00:37:28,920
like open source voice companies to

00:37:27,120 --> 00:37:31,800
deliver value in areas that are not

00:37:28,920 --> 00:37:34,110
commercially viable by themselves so

00:37:31,800 --> 00:37:37,620
seek again of indigenous and in dangers

00:37:34,110 --> 00:37:39,410
and by resource linkages but we also

00:37:37,620 --> 00:37:43,470
have to think about privacy

00:37:39,410 --> 00:37:47,790
for example governments are responsible

00:37:43,470 --> 00:37:51,900
for regulation and for data privacy

00:37:47,790 --> 00:37:55,050
legislation so in America the California

00:37:51,900 --> 00:37:56,790
better privacy access is taken off and

00:37:55,050 --> 00:37:59,870
America has been HIPPA regulations

00:37:56,790 --> 00:38:03,270
around health and private information

00:37:59,870 --> 00:38:05,190
Germany and Europe has the GDP are here

00:38:03,270 --> 00:38:07,530
in Australia we have some reasonable

00:38:05,190 --> 00:38:11,010
privacy legislation through our Privacy

00:38:07,530 --> 00:38:13,880
Act one is government doing in the voice

00:38:11,010 --> 00:38:16,350
phase to help ensure privacy

00:38:13,880 --> 00:38:18,630
particularly in areas where personal

00:38:16,350 --> 00:38:22,950
information private information might be

00:38:18,630 --> 00:38:25,320
disclosed like the healthcare setting so

00:38:22,950 --> 00:38:27,630
there's a huge gap here for governments

00:38:25,320 --> 00:38:31,520
to have influence and to be involved in

00:38:27,630 --> 00:38:33,990
how this trajectory shakes out over time

00:38:31,520 --> 00:38:37,200
government also have a role to play and

00:38:33,990 --> 00:38:39,030
standards so in many areas of government

00:38:37,200 --> 00:38:41,220
procurement there are particular

00:38:39,030 --> 00:38:42,930
standards or frameworks that you have to

00:38:41,220 --> 00:38:47,070
adopt in order to be involved in

00:38:42,930 --> 00:38:50,760
government procurement for example in

00:38:47,070 --> 00:38:54,800
the UK a lot of providers have to be

00:38:50,760 --> 00:38:59,850
certified in the the item IT management

00:38:54,800 --> 00:39:01,710
framework in America I think being said

00:38:59,850 --> 00:39:03,640
of having something like coal but is

00:39:01,710 --> 00:39:07,060
much more likely

00:39:03,640 --> 00:39:09,640
in voice and in open soft voice we don't

00:39:07,060 --> 00:39:13,570
yet have standard so it's difficult for

00:39:09,640 --> 00:39:16,750
government to to know how to to go about

00:39:13,570 --> 00:39:18,640
procuring voice because they don't

00:39:16,750 --> 00:39:22,590
necessarily have a framework to assess

00:39:18,640 --> 00:39:22,590
for to to think about in

00:39:25,579 --> 00:39:31,230
that takes me to standards and

00:39:27,930 --> 00:39:33,539
interoperability beside the mind that we

00:39:31,230 --> 00:39:35,880
generally have poor support in the open

00:39:33,539 --> 00:39:38,069
source space for some existing boy

00:39:35,880 --> 00:39:41,279
standards like the speech synthesis

00:39:38,069 --> 00:39:43,200
markup standard and at the moment I

00:39:41,279 --> 00:39:45,960
would say that we have poor progress

00:39:43,200 --> 00:39:48,900
towards standards in voice and standards

00:39:45,960 --> 00:39:51,809
in open source voice and that hasn't

00:39:48,900 --> 00:39:54,450
knock-on effect but it's harder for open

00:39:51,809 --> 00:39:56,339
voice to be adopted by integrators it

00:39:54,450 --> 00:39:59,220
makes it less attractive because you

00:39:56,339 --> 00:40:01,410
have to do things differently for every

00:39:59,220 --> 00:40:03,569
sort of open source piece of software

00:40:01,410 --> 00:40:05,989
that you touch that becomes less

00:40:03,569 --> 00:40:08,039
attractive for integration

00:40:05,989 --> 00:40:12,150
imagine that you're a voice skill

00:40:08,039 --> 00:40:15,839
developer and you're trying to develop a

00:40:12,150 --> 00:40:17,460
skill to do something in your smartphone

00:40:15,839 --> 00:40:21,119
and more to to integrate with the

00:40:17,460 --> 00:40:23,220
particular API just like with the mobile

00:40:21,119 --> 00:40:25,259
space at the moment where you probably

00:40:23,220 --> 00:40:28,499
have to make two versions of a mobile

00:40:25,259 --> 00:40:30,359
app one for Android and one for ions at

00:40:28,499 --> 00:40:32,819
the moment if you wanted to reach most

00:40:30,359 --> 00:40:35,730
of the market you would just have to

00:40:32,819 --> 00:40:38,759
write a skill for the big two boys

00:40:35,730 --> 00:40:40,890
companies if we don't have some

00:40:38,759 --> 00:40:44,039
standards in the open-source space in

00:40:40,890 --> 00:40:45,569
the open-source voice space we're not

00:40:44,039 --> 00:40:47,730
going to be able to attract skill

00:40:45,569 --> 00:40:49,619
development because they're going to be

00:40:47,730 --> 00:40:51,930
developing skills for so many different

00:40:49,619 --> 00:40:53,849
platforms so we need to think more

00:40:51,930 --> 00:40:57,809
critically about how do we make it

00:40:53,849 --> 00:41:02,130
easier for those developments to to add

00:40:57,809 --> 00:41:03,630
value to that ecosystem so I think in

00:41:02,130 --> 00:41:06,420
breaking out of the trajectory that

00:41:03,630 --> 00:41:08,640
we're on here we need to think about how

00:41:06,420 --> 00:41:11,279
we have some standards and

00:41:08,640 --> 00:41:14,160
interoperability and so I know that John

00:41:11,279 --> 00:41:16,920
Stein in the item open voice network is

00:41:14,160 --> 00:41:18,989
doing some work here and I think that

00:41:16,920 --> 00:41:23,609
something that we'll need to to continue

00:41:18,989 --> 00:41:25,619
and have some more momentum we also need

00:41:23,609 --> 00:41:27,930
to think critically about licensing and

00:41:25,619 --> 00:41:30,900
there's a three line here to data as

00:41:27,930 --> 00:41:33,420
well so the licenses that were using

00:41:30,900 --> 00:41:35,940
open source of employment and designed

00:41:33,420 --> 00:41:39,990
around photo projects and products

00:41:35,940 --> 00:41:43,079
but they're not designed around data so

00:41:39,990 --> 00:41:45,930
how does a Pesci 2 or the TPL work for

00:41:43,079 --> 00:41:48,329
data or for models whether the output of

00:41:45,930 --> 00:41:50,250
machine learning where they might be an

00:41:48,329 --> 00:41:54,030
aggregate or a composite of the data

00:41:50,250 --> 00:41:55,710
from tens of thousands of people so we

00:41:54,030 --> 00:41:58,520
need to have some more sophisticated

00:41:55,710 --> 00:42:00,720
thinking about the licensing of data

00:41:58,520 --> 00:42:04,079
particularly where that data is an

00:42:00,720 --> 00:42:08,010
aggregate data things such as a CT

00:42:04,079 --> 00:42:12,119
corpora so again you know we we really

00:42:08,010 --> 00:42:15,599
need to think critically about data we

00:42:12,119 --> 00:42:17,880
also need to think about people so at

00:42:15,599 --> 00:42:20,490
the moment in open-source voice was huge

00:42:17,880 --> 00:42:24,299
competition for ML and AI talent and

00:42:20,490 --> 00:42:28,140
that's often that's making it difficult

00:42:24,299 --> 00:42:32,460
for open-source voice to build and to

00:42:28,140 --> 00:42:34,559
sustain communities companies also treat

00:42:32,460 --> 00:42:36,720
open-source communities differently they

00:42:34,559 --> 00:42:39,299
use open source communities in different

00:42:36,720 --> 00:42:42,210
ways and I'm not sure all of these are

00:42:39,299 --> 00:42:48,029
particularly positive ways so for anyone

00:42:42,210 --> 00:42:49,950
out there who might have used snips you

00:42:48,029 --> 00:42:52,289
invested in a platform that you thought

00:42:49,950 --> 00:42:54,240
with open source and then when the

00:42:52,289 --> 00:42:56,789
company was bought out suddenly

00:42:54,240 --> 00:43:00,299
overnight your investment in there the

00:42:56,789 --> 00:43:03,240
work that you've done is just completely

00:43:00,299 --> 00:43:05,339
devalued so I think we need to think

00:43:03,240 --> 00:43:09,720
about how we approach open source

00:43:05,339 --> 00:43:11,609
communities with voice and to break out

00:43:09,720 --> 00:43:13,920
of this I think we're going to see more

00:43:11,609 --> 00:43:15,150
involvement of open voice the University

00:43:13,920 --> 00:43:18,180
and college level which has

00:43:15,150 --> 00:43:20,960
traditionally been a hotbed for our open

00:43:18,180 --> 00:43:20,960
source project

00:43:21,240 --> 00:43:26,100
but the storyline here that I think we

00:43:23,280 --> 00:43:27,810
we also need to think about is how do we

00:43:26,100 --> 00:43:30,810
grow involved within the community from

00:43:27,810 --> 00:43:33,210
underrepresented groups and if we invest

00:43:30,810 --> 00:43:35,400
in low resource languages I mean tooling

00:43:33,210 --> 00:43:37,680
for low resource languages that open

00:43:35,400 --> 00:43:39,870
voice we're going to be able to grow the

00:43:37,680 --> 00:43:42,180
community from those under represented

00:43:39,870 --> 00:43:48,450
Aryan it would just be Europe and

00:43:42,180 --> 00:43:50,790
America anymore so each of these

00:43:48,450 --> 00:43:54,450
trajectories is not likely to be

00:43:50,790 --> 00:43:58,650
standalone it's likely that the future

00:43:54,450 --> 00:44:00,960
will be a little bit of each for example

00:43:58,650 --> 00:44:02,940
data metadata standards around voice

00:44:00,960 --> 00:44:05,100
data sets are likely to help increase

00:44:02,940 --> 00:44:07,950
the representation of women and minority

00:44:05,100 --> 00:44:09,510
groups but those metadata standards

00:44:07,950 --> 00:44:11,700
won't be adopted unless you answer

00:44:09,510 --> 00:44:14,550
unless there are some incentives for

00:44:11,700 --> 00:44:17,940
doing food such as tie into government

00:44:14,550 --> 00:44:20,070
procurement regulations the involvement

00:44:17,940 --> 00:44:21,660
of governments in open source or likely

00:44:20,070 --> 00:44:23,810
to assist with an increase in the

00:44:21,660 --> 00:44:26,910
availability of one resource language

00:44:23,810 --> 00:44:28,920
resources which in turn helps to attract

00:44:26,910 --> 00:44:31,950
new community members to open source

00:44:28,920 --> 00:44:37,230
projects so there's a lot of causal

00:44:31,950 --> 00:44:39,360
loops happening here but none of these

00:44:37,230 --> 00:44:43,380
trajectories are inevitable or

00:44:39,360 --> 00:44:45,600
incidental we have the power to shape

00:44:43,380 --> 00:44:48,780
the future of open source voice over the

00:44:45,600 --> 00:44:51,300
next five years but we must act soon

00:44:48,780 --> 00:44:54,930
before the trajectories that are already

00:44:51,300 --> 00:45:00,140
in play a lot in place and we cannot

00:44:54,930 --> 00:45:00,140
escape them thank you

00:45:04,520 --> 00:45:11,210
I realized that I was pausing there for

00:45:07,910 --> 00:45:12,350
the applause right because because when

00:45:11,210 --> 00:45:13,490
people say that yeah I go well that was

00:45:12,350 --> 00:45:14,750
a really good talk and then I was like

00:45:13,490 --> 00:45:17,450
wait I'm not gonna hit the applause it

00:45:14,750 --> 00:45:17,990
doesn't work like that Kathy thank you

00:45:17,450 --> 00:45:19,790
very much

00:45:17,990 --> 00:45:22,640
take the applause from me and sort of

00:45:19,790 --> 00:45:25,850
you know filtered through the rest of

00:45:22,640 --> 00:45:29,150
the the internet um I have a couple of

00:45:25,850 --> 00:45:32,120
questions some from me some from other

00:45:29,150 --> 00:45:37,700
people and I would love your thoughts on

00:45:32,120 --> 00:45:39,860
these the first one is about the open

00:45:37,700 --> 00:45:42,080
source voice stack I was not to see your

00:45:39,860 --> 00:45:44,540
diagram the open source voice stack I'm

00:45:42,080 --> 00:45:46,520
delighted because I often find I use a

00:45:44,540 --> 00:45:48,890
diagram of the open source voice tak and

00:45:46,520 --> 00:45:52,940
yours and my diagrams intersect in some

00:45:48,890 --> 00:45:55,460
places and not in some others but but

00:45:52,940 --> 00:45:56,660
the structure is sort of clear and the

00:45:55,460 --> 00:45:59,030
thing that's interesting about that is

00:45:56,660 --> 00:46:00,650
of course there is a stack right there's

00:45:59,030 --> 00:46:03,140
a sequence of things that are depending

00:46:00,650 --> 00:46:05,960
on each other where are you seeing the

00:46:03,140 --> 00:46:07,580
fragility in that stack right and how

00:46:05,960 --> 00:46:09,470
are you measuring that fragility and I

00:46:07,580 --> 00:46:10,850
suppose the question that I have that

00:46:09,470 --> 00:46:12,470
sort of crying out to be a research

00:46:10,850 --> 00:46:13,820
question maybe opera in this list of

00:46:12,470 --> 00:46:15,620
questions we're going to be funding

00:46:13,820 --> 00:46:19,640
through these little research grants is

00:46:15,620 --> 00:46:23,540
how do you measure the fragility of of a

00:46:19,640 --> 00:46:24,500
layer of the voice interface and which

00:46:23,540 --> 00:46:27,110
are the ones that need the most

00:46:24,500 --> 00:46:28,190
intention and most attention and in

00:46:27,110 --> 00:46:30,470
particular which are the ones that

00:46:28,190 --> 00:46:32,990
mozilla has a company that is concerned

00:46:30,470 --> 00:46:36,320
about the health of the the open source

00:46:32,990 --> 00:46:38,180
voice ecosystem where should we be

00:46:36,320 --> 00:46:40,100
investing our effort and time and how do

00:46:38,180 --> 00:46:42,830
you measure that you know now see the

00:46:40,100 --> 00:46:47,360
softball question I think you want to

00:46:42,830 --> 00:46:49,790
start with look I think to answer that

00:46:47,360 --> 00:46:54,040
question I'd like to unpack what

00:46:49,790 --> 00:46:57,850
fragility means a little bit I think

00:46:54,040 --> 00:47:00,110
from an open source perspective

00:46:57,850 --> 00:47:04,070
fertility familiar things like the

00:47:00,110 --> 00:47:06,380
abandonment of projects it's often when

00:47:04,070 --> 00:47:09,170
we talk about space you know the voice I

00:47:06,380 --> 00:47:10,040
talk about decks of cards layered on top

00:47:09,170 --> 00:47:13,130
of each other

00:47:10,040 --> 00:47:15,110
so for example at the moment the CMU

00:47:13,130 --> 00:47:18,289
sinks project which has been a mainstay

00:47:15,110 --> 00:47:20,509
of the STP

00:47:18,289 --> 00:47:23,689
and the wave wave layer within with its

00:47:20,509 --> 00:47:26,419
child project pockets things that's now

00:47:23,689 --> 00:47:29,509
all but abandoned so projects that are

00:47:26,419 --> 00:47:32,359
built around CMU thing are not going to

00:47:29,509 --> 00:47:34,789
get the updates that they need so that's

00:47:32,359 --> 00:47:37,759
one element of fragility how stable how

00:47:34,789 --> 00:47:40,369
sustainable is that fact at the moment

00:47:37,759 --> 00:47:42,529
we're seeing a lot of work in the STT

00:47:40,369 --> 00:47:46,009
layers are seeing a lot of work in the

00:47:42,529 --> 00:47:48,169
TTS layers but for me the issue that I

00:47:46,009 --> 00:47:52,249
that I have is that the intent layer

00:47:48,169 --> 00:47:54,679
isn't very well or is not perhaps as

00:47:52,249 --> 00:48:00,109
robust as it could be at the moment we

00:47:54,679 --> 00:48:03,619
had some second wave open source voice

00:48:00,109 --> 00:48:05,599
pieces in the intent layer so raster for

00:48:03,619 --> 00:48:08,989
example has done a lot of work around

00:48:05,599 --> 00:48:11,269
intent passing but we also have open

00:48:08,989 --> 00:48:13,369
source projects like and ltk the class

00:48:11,269 --> 00:48:16,549
and project they're doing very strong

00:48:13,369 --> 00:48:19,400
intent passing as well the problem that

00:48:16,549 --> 00:48:23,479
we have with intent passing at the

00:48:19,400 --> 00:48:26,059
moment is that we don't have standards

00:48:23,479 --> 00:48:29,449
around how intense are handled for

00:48:26,059 --> 00:48:32,749
example if I ask a proprietary voice

00:48:29,449 --> 00:48:34,969
assistant you know can you please show

00:48:32,749 --> 00:48:38,929
me a price for a particular keyboard

00:48:34,969 --> 00:48:40,339
there are almost all of the threads all

00:48:38,929 --> 00:48:43,549
of the threads that go into that

00:48:40,339 --> 00:48:46,069
response as a function of what is the

00:48:43,549 --> 00:48:49,969
profit motive behind that commercial

00:48:46,069 --> 00:48:51,880
company in an open source space we don't

00:48:49,969 --> 00:48:55,279
have very good ways at the moment of

00:48:51,880 --> 00:48:58,539
disambiguating intent in in the

00:48:55,279 --> 00:49:01,069
smartphone space so for example if I say

00:48:58,539 --> 00:49:04,039
could you could you play something for

00:49:01,069 --> 00:49:06,529
me we don't know for example whether

00:49:04,039 --> 00:49:11,089
that's a music request is it a news

00:49:06,529 --> 00:49:13,369
request is it a media request so again

00:49:11,089 --> 00:49:16,549
we see the through my dear to standards

00:49:13,369 --> 00:49:21,499
and to making sure that when we talk

00:49:16,549 --> 00:49:24,679
about intense were able to were able to

00:49:21,499 --> 00:49:26,839
have some continuity across platforms so

00:49:24,679 --> 00:49:29,900
for me fragility is that their house of

00:49:26,839 --> 00:49:31,970
cards and components being so dependent

00:49:29,900 --> 00:49:34,350
on each other without having

00:49:31,970 --> 00:49:38,130
good standards

00:49:34,350 --> 00:49:40,920
I think that's a really good response

00:49:38,130 --> 00:49:42,420
and and talks to some very important

00:49:40,920 --> 00:49:44,790
issues and I look forward to talking

00:49:42,420 --> 00:49:46,890
about that question with you more I have

00:49:44,790 --> 00:49:49,350
a question from Felix Lawrence who I

00:49:46,890 --> 00:49:51,570
feel is in the wilds of British Columbia

00:49:49,350 --> 00:49:54,720
somewhere but it could be Toronto more I

00:49:51,570 --> 00:49:57,810
forget sorry about that

00:49:54,720 --> 00:49:59,820
an underlying factor that is leading to

00:49:57,810 --> 00:50:01,680
minorities being shortchanged is that

00:49:59,820 --> 00:50:04,020
optimizing a product for each minority

00:50:01,680 --> 00:50:05,370
takes additional investment often out of

00:50:04,020 --> 00:50:07,650
proportion to the number of people in

00:50:05,370 --> 00:50:09,990
that minority and how do we break that

00:50:07,650 --> 00:50:11,790
out do you legally require equal

00:50:09,990 --> 00:50:14,400
investment for each and a whitelisted

00:50:11,790 --> 00:50:15,660
set of minorities do we take a common

00:50:14,400 --> 00:50:17,370
voice approach in which communities

00:50:15,660 --> 00:50:19,050
themselves are empowered to support

00:50:17,370 --> 00:50:20,280
marriages they care about and I will

00:50:19,050 --> 00:50:22,050
point out that the definition of

00:50:20,280 --> 00:50:24,390
minority is of course a locally

00:50:22,050 --> 00:50:26,490
constructed thing right the idea of what

00:50:24,390 --> 00:50:28,980
is a minority in the United States has

00:50:26,490 --> 00:50:30,540
been continues to surprise me after

00:50:28,980 --> 00:50:32,580
living in the States for 20 years I

00:50:30,540 --> 00:50:35,100
still get confused by by what the

00:50:32,580 --> 00:50:38,880
assumptions are around minority and

00:50:35,100 --> 00:50:42,540
majority and it pushes the question of

00:50:38,880 --> 00:50:44,280
like is this worth my effort does that

00:50:42,540 --> 00:50:47,790
process just push the is this worth my

00:50:44,280 --> 00:50:49,410
effort judgment from companies and to

00:50:47,790 --> 00:50:51,110
the community and does that make it okay

00:50:49,410 --> 00:50:54,540
better

00:50:51,110 --> 00:50:56,430
that's a great question Felix and and

00:50:54,540 --> 00:50:57,810
thank you I think it's an excellent

00:50:56,430 --> 00:51:04,040
question and something we should be

00:50:57,810 --> 00:51:06,840
giving more thought to it is difficult

00:51:04,040 --> 00:51:09,810
for me and the way that I'd like to

00:51:06,840 --> 00:51:13,950
answer it is that as an open-source

00:51:09,810 --> 00:51:16,530
person I think we should be giving as

00:51:13,950 --> 00:51:18,330
many opportunities as possible for

00:51:16,530 --> 00:51:20,490
different parts of that sector to

00:51:18,330 --> 00:51:23,910
respond in the way that best meets their

00:51:20,490 --> 00:51:25,500
needs I've spoken a bit about how I

00:51:23,910 --> 00:51:28,110
think governments need to have more

00:51:25,500 --> 00:51:30,810
involvement particularly in programs

00:51:28,110 --> 00:51:33,810
that are designed to provide resources

00:51:30,810 --> 00:51:36,300
for minorities and so in Australia that

00:51:33,810 --> 00:51:38,190
might be resources through indigenous

00:51:36,300 --> 00:51:40,770
languages so we've got several hundred

00:51:38,190 --> 00:51:44,370
of them in New Zealand that might be 40

00:51:40,770 --> 00:51:46,350
reo Maori and in Canada that might be

00:51:44,370 --> 00:51:47,760
fallen and abouts and indigenous

00:51:46,350 --> 00:51:51,540
populations there

00:51:47,760 --> 00:51:53,280
so giving government the ability to have

00:51:51,540 --> 00:51:54,300
some of these tools in one area to

00:51:53,280 --> 00:51:57,300
address that

00:51:54,300 --> 00:52:00,780
the second area to address that I see is

00:51:57,300 --> 00:52:03,870
being able to have end-to-end stacks so

00:52:00,780 --> 00:52:07,110
at the moment the open thought ecosystem

00:52:03,870 --> 00:52:08,820
is quite fragmented we have we have

00:52:07,110 --> 00:52:10,830
software at the different layers of the

00:52:08,820 --> 00:52:12,900
stack but it's very hard to bring all of

00:52:10,830 --> 00:52:15,120
that together and so if you're a

00:52:12,900 --> 00:52:17,520
practitioner in a minority community

00:52:15,120 --> 00:52:20,640
it's very hard for you to work with

00:52:17,520 --> 00:52:23,120
those stacks so if we make it easier if

00:52:20,640 --> 00:52:28,470
we make end-to-end open-source ROIs

00:52:23,120 --> 00:52:30,330
easier for people then we reduce the we

00:52:28,470 --> 00:52:32,190
reduce the labor and we reduce the

00:52:30,330 --> 00:52:33,960
effort that's required to deliver an

00:52:32,190 --> 00:52:35,640
outcome there so I think we need to be

00:52:33,960 --> 00:52:37,740
thinking about how do we reduce the

00:52:35,640 --> 00:52:41,280
effort that's required because then it

00:52:37,740 --> 00:52:44,940
becomes more attractive as well I also

00:52:41,280 --> 00:52:47,340
think that this also comes back to some

00:52:44,940 --> 00:52:49,080
human rights thinking as well and this

00:52:47,340 --> 00:52:53,370
is driving some of the conversation

00:52:49,080 --> 00:52:55,770
around Beijing in data privacy we do

00:52:53,370 --> 00:53:01,310
need to be thinking about what it means

00:52:55,770 --> 00:53:06,810
to treat majority and minority datasets

00:53:01,310 --> 00:53:09,450
in equal and equitable ways if a voice

00:53:06,810 --> 00:53:11,030
assistant can't understand me because

00:53:09,450 --> 00:53:13,860
I'm a woman

00:53:11,030 --> 00:53:16,470
that's a human rights issue it's agenda

00:53:13,860 --> 00:53:18,600
to human rights issue if a voice

00:53:16,470 --> 00:53:22,050
assistant can understand me because I'm

00:53:18,600 --> 00:53:25,620
Australian and I elongate my vows sounds

00:53:22,050 --> 00:53:28,050
like this that becomes a racial question

00:53:25,620 --> 00:53:30,660
and if a voice assistant can't

00:53:28,050 --> 00:53:32,430
understand me because the language

00:53:30,660 --> 00:53:34,470
models there aren't there for the

00:53:32,430 --> 00:53:35,130
indigenous or the endangered language

00:53:34,470 --> 00:53:38,100
that I speak

00:53:35,130 --> 00:53:39,750
it becomes a human rights issue so I

00:53:38,100 --> 00:53:41,340
think it's an incredibly important

00:53:39,750 --> 00:53:46,580
question and I think there are multiple

00:53:41,340 --> 00:53:50,760
ways to to have some influence over that

00:53:46,580 --> 00:53:52,650
Thank You Felix for the question yeah

00:53:50,760 --> 00:53:54,740
that is not an easy question at all and

00:53:52,650 --> 00:53:57,030
I continue to struggle with that

00:53:54,740 --> 00:53:59,700
particularly as someone who's got a very

00:53:57,030 --> 00:54:01,830
strange accent from from not fitting any

00:53:59,700 --> 00:54:05,030
of those categories very well right like

00:54:01,830 --> 00:54:07,800
I grew up in a lot of different

00:54:05,030 --> 00:54:09,960
countries as a kid and I think my accent

00:54:07,800 --> 00:54:11,360
is some strange reflection of that and I

00:54:09,960 --> 00:54:12,980
will say that voice assistance

00:54:11,360 --> 00:54:19,110
understand me

00:54:12,980 --> 00:54:20,369
not very well to be honest to be honest

00:54:19,110 --> 00:54:21,900
people don't understand me very well

00:54:20,369 --> 00:54:24,300
I've developed a technique in the United

00:54:21,900 --> 00:54:26,910
States of when I am in a restaurant and

00:54:24,300 --> 00:54:30,150
I want to have more to drink I'll ask

00:54:26,910 --> 00:54:32,310
for more water because if I say water no

00:54:30,150 --> 00:54:34,440
one understands like a word I say I've

00:54:32,310 --> 00:54:36,750
learned this the hard way I have another

00:54:34,440 --> 00:54:42,060
question which is and this one is sort

00:54:36,750 --> 00:54:43,740
of a kind of a detail or you're defining

00:54:42,060 --> 00:54:47,310
these three waves of open source and if

00:54:43,740 --> 00:54:48,900
I was to read your if I was looking at

00:54:47,310 --> 00:54:50,280
the slides and listening said I think

00:54:48,900 --> 00:54:51,840
you're sort of talking about these three

00:54:50,280 --> 00:54:53,400
waves being approximately sort of open

00:54:51,840 --> 00:54:54,869
source and universities open source in

00:54:53,400 --> 00:54:58,560
business and open source in the world

00:54:54,869 --> 00:55:00,720
and I can see them taking a data-driven

00:54:58,560 --> 00:55:03,240
approach which would frame it a little

00:55:00,720 --> 00:55:05,730
bit more that open source wave one is

00:55:03,240 --> 00:55:09,420
these sort of handcrafted rules today

00:55:05,730 --> 00:55:12,600
open source 2 is this sort of deep

00:55:09,420 --> 00:55:14,490
learning data-driven deep neural

00:55:12,600 --> 00:55:16,680
networks and then what the

00:55:14,490 --> 00:55:19,890
characteristic of the third wave is this

00:55:16,680 --> 00:55:23,390
being deliberate about the data that's

00:55:19,890 --> 00:55:25,740
being used to inform these processes um

00:55:23,390 --> 00:55:27,240
am I getting at the same things are

00:55:25,740 --> 00:55:28,890
these two different approaches on the

00:55:27,240 --> 00:55:30,570
same thing or like like is there an

00:55:28,890 --> 00:55:32,660
underlying sort of deep truth that I

00:55:30,570 --> 00:55:35,670
haven't managed to articulate there no I

00:55:32,660 --> 00:55:38,160
think you've captured that incredibly

00:55:35,670 --> 00:55:40,290
accurately and I think there's a there's

00:55:38,160 --> 00:55:45,240
a continuum here right of how we think

00:55:40,290 --> 00:55:47,760
about data and the critical thinking

00:55:45,240 --> 00:55:50,460
approach that we take to data so if we

00:55:47,760 --> 00:55:52,260
look at the research if we look at the

00:55:50,460 --> 00:55:54,470
first wave of open source that came out

00:55:52,260 --> 00:55:57,210
of universities and was research driven

00:55:54,470 --> 00:56:00,990
the Windows data structures there were

00:55:57,210 --> 00:56:04,109
no ways of handling voice data and so it

00:56:00,990 --> 00:56:06,420
was my necessity ad hoc and then we've

00:56:04,109 --> 00:56:08,210
gone into the method explosion of

00:56:06,420 --> 00:56:10,590
machine learning and neural networks

00:56:08,210 --> 00:56:13,560
where we're starting to think of that

00:56:10,590 --> 00:56:15,180
data at scale but yet we don't have a

00:56:13,560 --> 00:56:17,579
new ones understanding of that

00:56:15,180 --> 00:56:22,530
later we keep thinking they're more data

00:56:17,579 --> 00:56:25,380
is better that bigger data is what we

00:56:22,530 --> 00:56:27,300
want whereas in this third wave I think

00:56:25,380 --> 00:56:29,550
we're going as you said becoming much

00:56:27,300 --> 00:56:31,319
more deliberate about data we're

00:56:29,550 --> 00:56:33,270
thinking about the provenance of data

00:56:31,319 --> 00:56:35,579
we're thinking about the licensing of

00:56:33,270 --> 00:56:37,980
that data we're thinking about the way

00:56:35,579 --> 00:56:40,530
that metadata is applied to those data

00:56:37,980 --> 00:56:42,720
sets so that we can understand the

00:56:40,530 --> 00:56:44,700
limits of consent for using them they

00:56:42,720 --> 00:56:46,020
don't where can their data be used and

00:56:44,700 --> 00:56:48,390
where can it not be used

00:56:46,020 --> 00:56:50,819
so you've captured that very accurately

00:56:48,390 --> 00:56:53,069
I really like this sort of small data

00:56:50,819 --> 00:56:54,569
big data deliberate data as a three

00:56:53,069 --> 00:56:56,160
stage model and that sort of reflects

00:56:54,569 --> 00:56:59,309
things we're seeing outside of voice as

00:56:56,160 --> 00:57:01,440
well okay we're gonna have to stop there

00:56:59,309 --> 00:57:03,119
Kathy thank you very much for this I

00:57:01,440 --> 00:57:05,970
particularly appreciate you getting up

00:57:03,119 --> 00:57:08,190
at like before dawn I think I can sort

00:57:05,970 --> 00:57:10,530
of see something like out of your window

00:57:08,190 --> 00:57:13,710
just starting maybe and we're always

00:57:10,530 --> 00:57:15,329
tiptoeing you know this is the dawn at

00:57:13,710 --> 00:57:17,940
the first wave I voted sauce voice

00:57:15,329 --> 00:57:20,280
here's the metaphor here we'll run with

00:57:17,940 --> 00:57:21,990
the metaphor I really appreciate you

00:57:20,280 --> 00:57:23,609
doing this it made more sense when we

00:57:21,990 --> 00:57:25,710
were like ah let's have a brown bag and

00:57:23,609 --> 00:57:27,660
everyone can sit around over lunch in

00:57:25,710 --> 00:57:30,030
Mountain View and watch this talk and it

00:57:27,660 --> 00:57:31,650
seemed like a good idea at the time

00:57:30,030 --> 00:57:34,109
thank you thank you all for watching

00:57:31,650 --> 00:57:36,839
we'll continue to have this discussion

00:57:34,109 --> 00:57:38,670
in so many ways please feel free to

00:57:36,839 --> 00:57:40,380
reach out to me or to carefully through

00:57:38,670 --> 00:57:42,690
the venues that you see on the screen

00:57:40,380 --> 00:57:43,319
and have a good day everybody thanks

00:57:42,690 --> 00:57:46,549
very much bye bye

00:57:43,319 --> 00:57:46,549
thanks everyone stay well

00:57:52,930 --> 00:57:54,990

YouTube URL: https://www.youtube.com/watch?v=Fwd0-mrHLvU


