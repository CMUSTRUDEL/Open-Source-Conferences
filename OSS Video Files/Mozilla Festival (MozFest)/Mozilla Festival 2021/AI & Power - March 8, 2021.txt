Title: AI & Power - March 8, 2021
Publication date: 2021-02-05
Playlist: Mozilla Festival 2021
Description: 
	The AI in our daily lives reinforces historical power imbalances — across gender, across race, and across class. Is it possible to make more just AI systems mainstream? A panel featuring:

Cierra Robson, Associate Director of the Ida B. Wells JUST Data Lab at Princeton University

Dr. Sarah Roberts, Co-Director, UCLA Center for Critical Internet Inquiry

Nighat Dad, Executive Director, Digital Rights Foundation

Julie Owono, Executive Director, Internet Sans Frontières

And moderator J. Bob Alotta, Mozilla's VP of Global Programs
Captions: 
	00:00:01,880 --> 00:01:04,960
[Music]

00:01:07,560 --> 00:01:26,689
[Music]

00:01:33,130 --> 00:02:42,110
[Music]

00:02:44,730 --> 00:03:03,860
[Music]

00:03:10,260 --> 00:03:58,080
[Music]

00:03:58,840 --> 00:04:01,840
do

00:04:01,860 --> 00:04:19,279
[Music]

00:04:21,910 --> 00:04:41,040
[Music]

00:04:47,480 --> 00:05:56,459
[Music]

00:05:59,070 --> 00:06:18,220
[Music]

00:06:24,660 --> 00:07:33,640
[Music]

00:07:36,260 --> 00:07:55,389
[Music]

00:08:01,840 --> 00:09:10,809
[Music]

00:09:13,440 --> 00:09:32,570
[Music]

00:09:37,380 --> 00:10:47,989
[Music]

00:10:50,620 --> 00:11:09,750
[Music]

00:11:16,190 --> 00:12:25,170
[Music]

00:12:27,790 --> 00:12:46,919
[Music]

00:12:53,320 --> 00:14:02,340
[Music]

00:14:04,970 --> 00:14:24,100
[Music]

00:14:30,540 --> 00:14:58,070
[Music]

00:14:56,839 --> 00:15:39,519
so

00:14:58,070 --> 00:15:39,519
[Music]

00:15:42,150 --> 00:16:01,280
[Music]

00:16:07,670 --> 00:17:16,700
[Music]

00:17:19,319 --> 00:17:38,450
[Music]

00:17:44,850 --> 00:18:25,920
[Music]

00:18:26,320 --> 00:18:30,240
hi everyone um thank you for joining us

00:18:28,640 --> 00:18:32,000
today i'm jay babalota

00:18:30,240 --> 00:18:33,760
i'm the vice president of global

00:18:32,000 --> 00:18:35,679
programs at mozilla and i'm going to be

00:18:33,760 --> 00:18:38,720
your host for today's panel

00:18:35,679 --> 00:18:39,679
um we have a vital discussion planned

00:18:38,720 --> 00:18:42,080
for today

00:18:39,679 --> 00:18:42,960
as part of of mozfest dialogues and

00:18:42,080 --> 00:18:44,400
debates

00:18:42,960 --> 00:18:46,160
we're going to unpack an issue that's

00:18:44,400 --> 00:18:46,880
underpinning so many of the problems

00:18:46,160 --> 00:18:48,640
online

00:18:46,880 --> 00:18:50,080
and offline today the relationship

00:18:48,640 --> 00:18:53,200
between ai

00:18:50,080 --> 00:18:55,520
and power the ai in our lives

00:18:53,200 --> 00:18:57,280
reinforces historical power imbalances

00:18:55,520 --> 00:19:00,960
across gender across race across

00:18:57,280 --> 00:19:02,400
class there are so many examples to list

00:19:00,960 --> 00:19:04,960
but here are a few

00:19:02,400 --> 00:19:07,360
hiring algorithms prior prioritize men

00:19:04,960 --> 00:19:09,679
over women and non-binary candidates

00:19:07,360 --> 00:19:12,000
facial recognition systems misidentified

00:19:09,679 --> 00:19:15,200
black faces and i would argue also that

00:19:12,000 --> 00:19:17,360
zoom backgrounds don't uh allow for

00:19:15,200 --> 00:19:19,120
black folks to use a zoom background

00:19:17,360 --> 00:19:22,640
without becoming part of the background

00:19:19,120 --> 00:19:24,240
as we just discovered 30 seconds ago

00:19:22,640 --> 00:19:25,840
and a year into the pandemic we could

00:19:24,240 --> 00:19:27,520
have gotten that right by now facial

00:19:25,840 --> 00:19:30,480
recognition systems

00:19:27,520 --> 00:19:31,600
uh um and voice assistants like alex and

00:19:30,480 --> 00:19:33,520
siri struggle

00:19:31,600 --> 00:19:34,960
to understand the voices of so many

00:19:33,520 --> 00:19:37,360
diasporas

00:19:34,960 --> 00:19:38,160
ai-powered digital ads can prey on or

00:19:37,360 --> 00:19:40,960
exclude

00:19:38,160 --> 00:19:42,720
those who have the least we're going to

00:19:40,960 --> 00:19:44,320
unpack all of this today but we're also

00:19:42,720 --> 00:19:46,240
going to ask is it possible to

00:19:44,320 --> 00:19:49,919
mainstream ai systems

00:19:46,240 --> 00:19:50,799
which are actually just today i am

00:19:49,919 --> 00:19:52,720
joined by

00:19:50,799 --> 00:19:54,240
a number of fantastic colleagues i'm

00:19:52,720 --> 00:19:57,679
really honored

00:19:54,240 --> 00:19:58,480
to be on screen with y'all dr sarah

00:19:57,679 --> 00:20:00,000
roberts

00:19:58,480 --> 00:20:02,480
is an associate professor at the

00:20:00,000 --> 00:20:04,080
university of california los angeles

00:20:02,480 --> 00:20:06,159
in the department of information studies

00:20:04,080 --> 00:20:08,480
where she serves as the co-director

00:20:06,159 --> 00:20:10,640
of the ucla center for critical uh

00:20:08,480 --> 00:20:13,280
internet inquiry welcome

00:20:10,640 --> 00:20:14,720
sierra robson uh the associate director

00:20:13,280 --> 00:20:16,799
of the idb wells

00:20:14,720 --> 00:20:18,559
just data lab at princeton university

00:20:16,799 --> 00:20:20,159
where she guides research teams

00:20:18,559 --> 00:20:22,400
in partnership with community

00:20:20,159 --> 00:20:24,720
organizations to explore how

00:20:22,400 --> 00:20:26,240
data can be retooled for racial justice

00:20:24,720 --> 00:20:28,000
welcome sierra

00:20:26,240 --> 00:20:29,520
julie omono is a lawyer and the

00:20:28,000 --> 00:20:30,960
executive director of paris-based

00:20:29,520 --> 00:20:34,080
digital rights organization

00:20:30,960 --> 00:20:37,760
international frontiers um

00:20:34,080 --> 00:20:39,360
i made it spanish i'm sorry um julie

00:20:37,760 --> 00:20:41,600
i could have practiced that i actually

00:20:39,360 --> 00:20:43,360
let's go practice your french in the

00:20:41,600 --> 00:20:45,360
bathroom julie's work focuses

00:20:43,360 --> 00:20:46,799
on building bridges and creating

00:20:45,360 --> 00:20:48,080
channels of collaboration between

00:20:46,799 --> 00:20:50,080
various actors

00:20:48,080 --> 00:20:52,000
of the digital space to foster the

00:20:50,080 --> 00:20:53,600
development of an internet that benefits

00:20:52,000 --> 00:20:54,960
everyone all over the world welcome

00:20:53,600 --> 00:20:57,280
julie

00:20:54,960 --> 00:20:59,600
and nigatad is the executive director of

00:20:57,280 --> 00:21:00,159
the digital rights foundation night is

00:20:59,600 --> 00:21:01,679
one of the

00:21:00,159 --> 00:21:04,640
pioneer women's rights activist in

00:21:01,679 --> 00:21:06,880
pakistan and has played a pivotal role

00:21:04,640 --> 00:21:07,840
in defining the cyberspace narrative in

00:21:06,880 --> 00:21:11,360
the country

00:21:07,840 --> 00:21:13,360
welcome and one last thing we're taking

00:21:11,360 --> 00:21:14,480
questions for this panel in real time so

00:21:13,360 --> 00:21:17,120
you can tweet them

00:21:14,480 --> 00:21:17,600
at mozilla with the hashtag dialogues

00:21:17,120 --> 00:21:20,640
and

00:21:17,600 --> 00:21:21,840
debates spelled out so this is a

00:21:20,640 --> 00:21:24,480
conversation

00:21:21,840 --> 00:21:26,159
i'm going to feel the question to to

00:21:24,480 --> 00:21:26,799
each one of our panelists but to the

00:21:26,159 --> 00:21:30,000
other

00:21:26,799 --> 00:21:32,559
panelists uh after our initial uh

00:21:30,000 --> 00:21:33,679
uh panelist takes a stab at an answer

00:21:32,559 --> 00:21:37,039
please feel free

00:21:33,679 --> 00:21:37,679
to chime in um and i'll move us along by

00:21:37,039 --> 00:21:40,240
taking

00:21:37,679 --> 00:21:41,280
facilitated privilege but um i don't

00:21:40,240 --> 00:21:43,520
want to squash any

00:21:41,280 --> 00:21:46,080
any conversation so please do feel free

00:21:43,520 --> 00:21:50,400
to engage one another

00:21:46,080 --> 00:21:54,080
um so let's start with some context

00:21:50,400 --> 00:21:56,960
this panel is entitled ai and power

00:21:54,080 --> 00:21:59,120
right now who wields power in the realm

00:21:56,960 --> 00:22:02,640
of ai and who doesn't

00:21:59,120 --> 00:22:04,880
negot do you want to kick us off

00:22:02,640 --> 00:22:05,840
sure um first of all thank you so much

00:22:04,880 --> 00:22:08,960
for having me

00:22:05,840 --> 00:22:10,840
and having a voice from a place where we

00:22:08,960 --> 00:22:12,000
usually don't have these conversations

00:22:10,840 --> 00:22:15,039
so

00:22:12,000 --> 00:22:18,400
i'm glad that someone from pakistan

00:22:15,039 --> 00:22:20,559
is actually talking about ai and power

00:22:18,400 --> 00:22:21,520
and you asked a question who actually

00:22:20,559 --> 00:22:23,600
has the power

00:22:21,520 --> 00:22:25,360
uh the one group that doesn't yield any

00:22:23,600 --> 00:22:28,559
power in a.i

00:22:25,360 --> 00:22:31,919
is the end user and consumer

00:22:28,559 --> 00:22:35,039
the average internet user and netizen

00:22:31,919 --> 00:22:35,760
um it's the users data that that is

00:22:35,039 --> 00:22:39,120
collected

00:22:35,760 --> 00:22:42,000
and sold and except for the global north

00:22:39,120 --> 00:22:42,720
and a few developing countries most

00:22:42,000 --> 00:22:45,360
users

00:22:42,720 --> 00:22:45,919
do not know what their digital rights

00:22:45,360 --> 00:22:47,440
are and

00:22:45,919 --> 00:22:50,000
you know i'm i'm speaking from the

00:22:47,440 --> 00:22:53,200
perspective and the context of pakistan

00:22:50,000 --> 00:22:56,320
and really are they enshrined and pro

00:22:53,200 --> 00:22:59,360
protected in our laws or constitution

00:22:56,320 --> 00:23:00,640
so this collected data is fed into that

00:22:59,360 --> 00:23:03,360
databases

00:23:00,640 --> 00:23:04,720
that then targets the users through ai

00:23:03,360 --> 00:23:06,960
internet giants

00:23:04,720 --> 00:23:08,480
governments and social media companies

00:23:06,960 --> 00:23:11,039
become more and more powerful

00:23:08,480 --> 00:23:13,440
and the average user is left with fewer

00:23:11,039 --> 00:23:14,880
and fewer avenues and way to exert their

00:23:13,440 --> 00:23:17,360
power

00:23:14,880 --> 00:23:18,880
minus the end user everyone in the

00:23:17,360 --> 00:23:21,679
digital ecosystem

00:23:18,880 --> 00:23:22,320
gains power through ai the only

00:23:21,679 --> 00:23:24,799
difference

00:23:22,320 --> 00:23:27,200
is that each stakeholder you yields

00:23:24,799 --> 00:23:29,280
different amounts of power and control

00:23:27,200 --> 00:23:31,039
uh social media companies and tech

00:23:29,280 --> 00:23:33,360
giants have spun

00:23:31,039 --> 00:23:34,640
a deeply internet connected in

00:23:33,360 --> 00:23:36,640
interconnected web of

00:23:34,640 --> 00:23:38,320
data sharing that gives them immense

00:23:36,640 --> 00:23:40,640
power over the internet

00:23:38,320 --> 00:23:42,320
and internet users and now with

00:23:40,640 --> 00:23:45,360
governments entering

00:23:42,320 --> 00:23:46,799
uh this equation this power and data is

00:23:45,360 --> 00:23:49,039
also being shared with them

00:23:46,799 --> 00:23:50,000
so in usual circumstances governments

00:23:49,039 --> 00:23:53,200
are already

00:23:50,000 --> 00:23:55,840
powerful entities however when we add

00:23:53,200 --> 00:23:56,480
this ai into this equation their power

00:23:55,840 --> 00:24:00,880
increases

00:23:56,480 --> 00:24:02,840
exponentially data and online behavior

00:24:00,880 --> 00:24:05,520
gives the government the ability to

00:24:02,840 --> 00:24:07,760
identify how to target individuals and

00:24:05,520 --> 00:24:09,679
how to control narratives online

00:24:07,760 --> 00:24:11,679
and if we go a little further in this

00:24:09,679 --> 00:24:14,799
debate of power i think it's very

00:24:11,679 --> 00:24:18,080
important for us to examine the bias

00:24:14,799 --> 00:24:21,679
in ai and how these biases mainly stem

00:24:18,080 --> 00:24:24,159
from human humans inherent biases

00:24:21,679 --> 00:24:24,960
the models and systems we create and

00:24:24,159 --> 00:24:26,799
train

00:24:24,960 --> 00:24:29,039
are a reflection of ourselves and

00:24:26,799 --> 00:24:31,039
extremely important for us to see

00:24:29,039 --> 00:24:32,480
who is designing and training ai and

00:24:31,039 --> 00:24:35,039
which part of the world

00:24:32,480 --> 00:24:37,279
you know they are designing ai be it a

00:24:35,039 --> 00:24:40,960
tech giant social media company

00:24:37,279 --> 00:24:40,960
or uh within a government

00:24:43,120 --> 00:24:46,480
thank you nina yeah that anybody else

00:24:45,279 --> 00:24:48,799
want to respond

00:24:46,480 --> 00:24:48,799
um

00:24:50,080 --> 00:24:53,360
i think uh one thing that i want to

00:24:51,760 --> 00:24:55,679
offer up in in

00:24:53,360 --> 00:24:57,120
into the when we're talking about power

00:24:55,679 --> 00:24:58,960
and we're talking about bias

00:24:57,120 --> 00:25:00,240
and then also what it means for just

00:24:58,960 --> 00:25:04,159
this group of folks

00:25:00,240 --> 00:25:05,840
to be um uh having uh

00:25:04,159 --> 00:25:07,440
the opportunity for us all to speak

00:25:05,840 --> 00:25:11,039
together is

00:25:07,440 --> 00:25:12,799
um um oftentimes

00:25:11,039 --> 00:25:14,799
if if we're the voices who have to

00:25:12,799 --> 00:25:17,039
combat the bias what is it actually

00:25:14,799 --> 00:25:18,799
where are where's the original thought

00:25:17,039 --> 00:25:20,320
and where that we'd actually don't have

00:25:18,799 --> 00:25:23,120
the room or the space

00:25:20,320 --> 00:25:23,679
to bring forward in that right so if the

00:25:23,120 --> 00:25:26,320
onus

00:25:23,679 --> 00:25:28,080
is on the folks who are actually bearing

00:25:26,320 --> 00:25:31,279
the brunt of that bias

00:25:28,080 --> 00:25:34,000
to showcase that bias where's the

00:25:31,279 --> 00:25:35,679
invention and the incentive um for that

00:25:34,000 --> 00:25:37,120
to actually come forward and so we're

00:25:35,679 --> 00:25:40,240
losing out twice

00:25:37,120 --> 00:25:43,840
um and and that that that's the impact

00:25:40,240 --> 00:25:43,840
of that bias on everyone

00:25:45,279 --> 00:25:49,360
and we know that the power imbalance

00:25:47,520 --> 00:25:51,679
can't be fixed simply by

00:25:49,360 --> 00:25:53,120
tweaking code or enacting a single new

00:25:51,679 --> 00:25:55,360
law right power and

00:25:53,120 --> 00:25:57,679
inequalities are baked into the systems

00:25:55,360 --> 00:25:59,679
and the data that powers them

00:25:57,679 --> 00:26:00,799
but i'm curious about how deep the

00:25:59,679 --> 00:26:04,000
problem goes

00:26:00,799 --> 00:26:05,840
um sierra do you think you can um

00:26:04,000 --> 00:26:07,200
shine some light on it the subject for

00:26:05,840 --> 00:26:08,880
us yeah

00:26:07,200 --> 00:26:10,240
absolutely first of all thank you so

00:26:08,880 --> 00:26:12,000
much for including me in this

00:26:10,240 --> 00:26:13,520
in this conversation i'm so excited to

00:26:12,000 --> 00:26:15,840
be here with you all

00:26:13,520 --> 00:26:16,640
um to get to the question one of the

00:26:15,840 --> 00:26:18,799
things that

00:26:16,640 --> 00:26:20,400
we have to think about is how even those

00:26:18,799 --> 00:26:22,000
technologies that are

00:26:20,400 --> 00:26:23,520
not meant to reinforce power

00:26:22,000 --> 00:26:26,159
inequalities can still

00:26:23,520 --> 00:26:26,960
end up doing so so the tools that are

00:26:26,159 --> 00:26:29,520
fundamentally

00:26:26,960 --> 00:26:30,720
built to reduce harm can often reinforce

00:26:29,520 --> 00:26:32,559
it and

00:26:30,720 --> 00:26:34,960
one good example of this is pre-trial

00:26:32,559 --> 00:26:37,919
risk assessment tools so

00:26:34,960 --> 00:26:38,880
algorithms judges use to determine a

00:26:37,919 --> 00:26:41,679
defender's

00:26:38,880 --> 00:26:43,600
uh of a defendant's risk of reoffense

00:26:41,679 --> 00:26:46,000
before a sentencing hearing

00:26:43,600 --> 00:26:46,880
in many states this was heralded as a

00:26:46,000 --> 00:26:49,919
solution

00:26:46,880 --> 00:26:52,320
to cash bail which many people know has

00:26:49,919 --> 00:26:54,960
lots of issues and often reinforces

00:26:52,320 --> 00:26:55,760
like income inequality wealth inequality

00:26:54,960 --> 00:26:57,440
um

00:26:55,760 --> 00:26:59,840
but they don't understand the ways in

00:26:57,440 --> 00:27:00,880
which these algorithms can also

00:26:59,840 --> 00:27:03,039
reinforce

00:27:00,880 --> 00:27:04,880
all sorts of different things so

00:27:03,039 --> 00:27:07,039
pre-trial risk assessments were proposed

00:27:04,880 --> 00:27:09,279
as this technological solution

00:27:07,039 --> 00:27:10,640
but those who were deemed most risky

00:27:09,279 --> 00:27:12,480
would be put in prison

00:27:10,640 --> 00:27:14,400
until their hearing and everyone else

00:27:12,480 --> 00:27:16,480
would be allowed to to

00:27:14,400 --> 00:27:18,320
await their child but in the first

00:27:16,480 --> 00:27:20,159
iteration many of these tools included

00:27:18,320 --> 00:27:20,799
race as predictive variables many of

00:27:20,159 --> 00:27:23,039
them included

00:27:20,799 --> 00:27:24,640
zip codes many of them included things

00:27:23,039 --> 00:27:28,000
like do you own a cell phone

00:27:24,640 --> 00:27:29,679
or do you pay rent in their variables

00:27:28,000 --> 00:27:30,320
that they use to predict whether or not

00:27:29,679 --> 00:27:33,440
someone would

00:27:30,320 --> 00:27:34,480
be deemed risky and they people will

00:27:33,440 --> 00:27:35,919
quickly realize

00:27:34,480 --> 00:27:37,679
that this produced discriminatory

00:27:35,919 --> 00:27:40,320
results so

00:27:37,679 --> 00:27:42,480
these categories were then excluded but

00:27:40,320 --> 00:27:43,919
then new categories came up as proxies

00:27:42,480 --> 00:27:46,159
for things like race

00:27:43,919 --> 00:27:47,600
and so what does all of this mean in

00:27:46,159 --> 00:27:48,559
short it means that tweaking code

00:27:47,600 --> 00:27:51,679
doesn't

00:27:48,559 --> 00:27:53,279
rid systems of bias or power instead we

00:27:51,679 --> 00:27:55,520
have to really think about what the

00:27:53,279 --> 00:27:57,120
tools are meant to do at their inception

00:27:55,520 --> 00:27:58,480
and technological tools

00:27:57,120 --> 00:28:00,399
will not be able to solve social

00:27:58,480 --> 00:28:01,919
problems on their own and we really

00:28:00,399 --> 00:28:04,000
should stop asking them to do so and

00:28:01,919 --> 00:28:06,399
instead build tools from the ground up

00:28:04,000 --> 00:28:16,320
that are supposed to help the world in

00:28:06,399 --> 00:28:19,360
the ways that we want them to

00:28:16,320 --> 00:28:22,480
i want all of the um participates

00:28:19,360 --> 00:28:26,720
in the conversation i um to

00:28:22,480 --> 00:28:28,840
to um lean into uh

00:28:26,720 --> 00:28:30,960
being being in conversation with one

00:28:28,840 --> 00:28:33,440
yeah

00:28:30,960 --> 00:28:34,480
i just wanted to uh double down on what

00:28:33,440 --> 00:28:38,240
sierra

00:28:34,480 --> 00:28:39,440
just said um we we tend to focus a lot

00:28:38,240 --> 00:28:42,480
of the conversation

00:28:39,440 --> 00:28:44,880
recently around a.i and its biases

00:28:42,480 --> 00:28:45,760
on technical solutions but we actually

00:28:44,880 --> 00:28:48,320
forget

00:28:45,760 --> 00:28:49,039
what sierra and what we got also said

00:28:48,320 --> 00:28:51,279
previously

00:28:49,039 --> 00:28:52,480
is that the digital world is just a

00:28:51,279 --> 00:28:55,679
mirror of

00:28:52,480 --> 00:28:59,520
whatever already exists uh offline

00:28:55,679 --> 00:29:02,159
so it's um we shouldn't you know

00:28:59,520 --> 00:29:03,760
stop ourselves from having those very

00:29:02,159 --> 00:29:07,279
serious conversations too

00:29:03,760 --> 00:29:08,159
on how racist our societies are on our

00:29:07,279 --> 00:29:10,720
sexes they are

00:29:08,159 --> 00:29:11,360
hi happy international women's day on

00:29:10,720 --> 00:29:14,080
how

00:29:11,360 --> 00:29:14,720
um you know transphobic they are and all

00:29:14,080 --> 00:29:17,200
the the

00:29:14,720 --> 00:29:17,919
the very negative things that we see

00:29:17,200 --> 00:29:20,799
reproduced

00:29:17,919 --> 00:29:21,600
online so i just wanted to to chime in

00:29:20,799 --> 00:29:24,720
and say that

00:29:21,600 --> 00:29:25,360
in this machine in this era in which a

00:29:24,720 --> 00:29:27,919
machine

00:29:25,360 --> 00:29:29,279
is going to basically make decisions and

00:29:27,919 --> 00:29:31,279
is making decisions

00:29:29,279 --> 00:29:33,600
on human interaction and human-produced

00:29:31,279 --> 00:29:36,080
content it's really time for us

00:29:33,600 --> 00:29:37,279
to go beyond the machine and bring back

00:29:36,080 --> 00:29:39,440
the human within

00:29:37,279 --> 00:29:41,279
this this conversation it's absolutely

00:29:39,440 --> 00:29:43,919
important

00:29:41,279 --> 00:29:46,080
sarah i saw your henry's yeah i mean i

00:29:43,919 --> 00:29:48,159
think that's an excellent segue

00:29:46,080 --> 00:29:49,520
and i'd love to just pick that one up

00:29:48,159 --> 00:29:51,279
because um

00:29:49,520 --> 00:29:53,279
you know essentially i think it's what

00:29:51,279 --> 00:29:55,679
i'm uh charged with

00:29:53,279 --> 00:29:56,320
speaking a bit about on today's panel

00:29:55,679 --> 00:29:59,679
and that

00:29:56,320 --> 00:30:02,559
is to actually uh

00:29:59,679 --> 00:30:04,640
on some levels fundamentally ask the

00:30:02,559 --> 00:30:07,039
question what do we mean when we say

00:30:04,640 --> 00:30:08,159
ai anyway right so there are all these

00:30:07,039 --> 00:30:11,279
received notions

00:30:08,159 --> 00:30:12,399
right now within um not only within just

00:30:11,279 --> 00:30:14,799
like the zeitgeist

00:30:12,399 --> 00:30:16,720
you know within our media sphere in

00:30:14,799 --> 00:30:21,200
conversation with each other as

00:30:16,720 --> 00:30:23,919
advocates um and and off times critics

00:30:21,200 --> 00:30:25,279
but that that question of what is ai

00:30:23,919 --> 00:30:28,320
what constitutes ai

00:30:25,279 --> 00:30:31,919
is in fact um a a

00:30:28,320 --> 00:30:35,600
standing problem space uh

00:30:31,919 --> 00:30:37,200
within computer science okay both in

00:30:35,600 --> 00:30:40,080
you know in the theory in the

00:30:37,200 --> 00:30:43,200
theoretical side of of computer science

00:30:40,080 --> 00:30:46,640
and in its application and so um

00:30:43,200 --> 00:30:48,559
this kind of this dilemma about what

00:30:46,640 --> 00:30:51,200
constitutes

00:30:48,559 --> 00:30:53,279
artificial intelligence was present at

00:30:51,200 --> 00:30:54,960
the birth of the field and it was you

00:30:53,279 --> 00:30:58,159
know in some fundamental

00:30:54,960 --> 00:31:02,080
papers by uh

00:30:58,159 --> 00:31:04,559
by the key kinds of uh

00:31:02,080 --> 00:31:06,559
computer scientists of the day you know

00:31:04,559 --> 00:31:09,279
they they actually stated that

00:31:06,559 --> 00:31:11,200
part of the problem with artificial

00:31:09,279 --> 00:31:13,200
intelligence

00:31:11,200 --> 00:31:14,240
precedes artificial intelligence it's

00:31:13,200 --> 00:31:17,039
the question of

00:31:14,240 --> 00:31:19,039
what constitutes intelligence full stop

00:31:17,039 --> 00:31:20,480
what constitutes intelligence within the

00:31:19,039 --> 00:31:22,880
realm of the human

00:31:20,480 --> 00:31:24,799
and then you know if that problem or if

00:31:22,880 --> 00:31:25,760
that if that definition is somewhat

00:31:24,799 --> 00:31:29,519
fuzzy

00:31:25,760 --> 00:31:30,880
unclear contested uh then what does it

00:31:29,519 --> 00:31:33,919
mean therefore that

00:31:30,880 --> 00:31:34,640
this kind of nebulous notion is picked

00:31:33,919 --> 00:31:37,679
up

00:31:34,640 --> 00:31:41,200
and um by by

00:31:37,679 --> 00:31:43,360
a definition abstracted

00:31:41,200 --> 00:31:44,720
and then put into implementation this

00:31:43,360 --> 00:31:47,919
was this was a

00:31:44,720 --> 00:31:50,720
an issue for foreseen uh by the

00:31:47,919 --> 00:31:51,840
uh by some of the uh the the founders of

00:31:50,720 --> 00:31:54,399
this field

00:31:51,840 --> 00:31:54,880
and all the way up till till today we

00:31:54,399 --> 00:31:58,240
have

00:31:54,880 --> 00:32:01,600
um uh you know very important

00:31:58,240 --> 00:32:05,279
uh kind of industry facing

00:32:01,600 --> 00:32:07,919
uh bodies and and uh

00:32:05,279 --> 00:32:09,519
uh thinkers in the form of you know just

00:32:07,919 --> 00:32:10,640
the one that's on my mind is the

00:32:09,519 --> 00:32:13,919
o'reilly group

00:32:10,640 --> 00:32:16,000
um kind of still adequately acknowledge

00:32:13,919 --> 00:32:17,679
you know acknowledging still adequately

00:32:16,000 --> 00:32:21,840
trying to define

00:32:17,679 --> 00:32:25,279
uh what what this is and you know again

00:32:21,840 --> 00:32:28,000
drawing down on this issue of what ai

00:32:25,279 --> 00:32:30,000
is they say not only is it difficult to

00:32:28,000 --> 00:32:31,919
define it's actually impossible to do

00:32:30,000 --> 00:32:34,480
especially without falling into

00:32:31,919 --> 00:32:36,000
you know tautologies and in kind of like

00:32:34,480 --> 00:32:39,120
these self-referential

00:32:36,000 --> 00:32:42,960
um uh intractable uh

00:32:39,120 --> 00:32:43,679
circles so i i i think it's important as

00:32:42,960 --> 00:32:46,320
as some of

00:32:43,679 --> 00:32:47,919
my my colleagues have already said that

00:32:46,320 --> 00:32:48,720
we step you know sierra was just saying

00:32:47,919 --> 00:32:51,840
we can't

00:32:48,720 --> 00:32:54,240
um critique the ai piece if we don't

00:32:51,840 --> 00:32:55,919
really understand what the systems are

00:32:54,240 --> 00:32:58,559
that are in play and what the

00:32:55,919 --> 00:32:59,840
fundamental social issues are that are

00:32:58,559 --> 00:33:03,360
feeding into that

00:32:59,840 --> 00:33:07,039
whether it's uh overtly sometimes

00:33:03,360 --> 00:33:09,279
but more importantly and more worrisome

00:33:07,039 --> 00:33:10,960
in an insidious fashion because we don't

00:33:09,279 --> 00:33:12,559
we don't even know how to adequately

00:33:10,960 --> 00:33:14,960
address these issues

00:33:12,559 --> 00:33:16,480
uh and attend to them as a as a social

00:33:14,960 --> 00:33:17,600
collective there are many of us who do

00:33:16,480 --> 00:33:20,399
work on them right

00:33:17,600 --> 00:33:22,559
but we we're in a in a fight around that

00:33:20,399 --> 00:33:25,200
in a fight to constantly prove

00:33:22,559 --> 00:33:26,320
um that some of these uh social forces

00:33:25,200 --> 00:33:28,399
are at play

00:33:26,320 --> 00:33:30,559
and are causing harm now that gets

00:33:28,399 --> 00:33:32,720
picked up and packaged up into ai

00:33:30,559 --> 00:33:33,600
and pushed out and i guess one of the

00:33:32,720 --> 00:33:36,159
greatest

00:33:33,600 --> 00:33:36,880
concerns there is we take these already

00:33:36,159 --> 00:33:40,399
um

00:33:36,880 --> 00:33:44,399
very hard to uh demonstrate

00:33:40,399 --> 00:33:45,760
systems of power and we create a huge

00:33:44,399 --> 00:33:48,799
layer of opacity

00:33:45,760 --> 00:33:51,120
around them and then we further

00:33:48,799 --> 00:33:52,000
uh automate them and give them

00:33:51,120 --> 00:33:55,120
incredible power

00:33:52,000 --> 00:33:56,000
to be reproduced and so that's where we

00:33:55,120 --> 00:33:58,080
sit with ai

00:33:56,000 --> 00:34:00,399
and the last comment i'll make about my

00:33:58,080 --> 00:34:03,840
own work and my own intervention

00:34:00,399 --> 00:34:05,440
in thinking in the space is simply um

00:34:03,840 --> 00:34:07,840
within the realm of commercial content

00:34:05,440 --> 00:34:10,000
moderation where we have heard for years

00:34:07,840 --> 00:34:11,440
uh from the firms and from others that

00:34:10,000 --> 00:34:15,040
kind of the way out

00:34:11,440 --> 00:34:17,040
of the horror of doing this work and its

00:34:15,040 --> 00:34:18,560
psychological consequence will be

00:34:17,040 --> 00:34:20,879
deliverance via

00:34:18,560 --> 00:34:22,480
ai and other kinds of automated uh

00:34:20,879 --> 00:34:24,480
content moderation tools

00:34:22,480 --> 00:34:25,919
but again i've just you know i hopefully

00:34:24,480 --> 00:34:27,599
convinced everyone that what we're

00:34:25,919 --> 00:34:28,639
dealing with is a very blunt kind of

00:34:27,599 --> 00:34:32,159
instrument

00:34:28,639 --> 00:34:34,960
that is in fact incredibly unintelligent

00:34:32,159 --> 00:34:37,520
in many cases it will do exactly what

00:34:34,960 --> 00:34:38,560
it's programmed to do which is often

00:34:37,520 --> 00:34:40,960
going to create

00:34:38,560 --> 00:34:43,200
more and more and new and different kind

00:34:40,960 --> 00:34:44,720
of errors they might be different

00:34:43,200 --> 00:34:46,960
they might be errors that humans

00:34:44,720 --> 00:34:49,359
wouldn't themselves make in fact

00:34:46,960 --> 00:34:52,000
and so um you know we have a lot of

00:34:49,359 --> 00:34:54,320
false positives coming into play here

00:34:52,000 --> 00:34:55,760
and going back to the claim that humans

00:34:54,320 --> 00:34:57,599
would then be delivered from content

00:34:55,760 --> 00:34:59,599
moderation what i've actually been

00:34:57,599 --> 00:35:00,640
tracking for some time is the ways in

00:34:59,599 --> 00:35:02,640
which um

00:35:00,640 --> 00:35:03,760
ai and other kinds of automated content

00:35:02,640 --> 00:35:06,000
moderation tools

00:35:03,760 --> 00:35:08,079
actually expand the need for human

00:35:06,000 --> 00:35:10,160
intervention because now we need

00:35:08,079 --> 00:35:11,680
not only we need the creation of the

00:35:10,160 --> 00:35:14,079
tools of course

00:35:11,680 --> 00:35:14,960
on the input side but on the output side

00:35:14,079 --> 00:35:18,560
we now need

00:35:14,960 --> 00:35:22,800
more and more humans to vet or even undo

00:35:18,560 --> 00:35:24,880
errors caused by uh by ai moderation

00:35:22,800 --> 00:35:26,800
that's in a best case scenario in the

00:35:24,880 --> 00:35:29,040
worst case scenario the errors aren't

00:35:26,800 --> 00:35:30,720
undone and all kinds of um false

00:35:29,040 --> 00:35:32,800
positives go forward or

00:35:30,720 --> 00:35:34,640
decisions are just simply made that we

00:35:32,800 --> 00:35:38,000
can't understand or even know

00:35:34,640 --> 00:35:41,040
uh are being taken thanks

00:35:38,000 --> 00:35:43,119
i just wanna let me oh sarah go ahead

00:35:41,040 --> 00:35:44,880
oh i just wanted to echo what sarah was

00:35:43,119 --> 00:35:45,680
saying i really appreciate your your

00:35:44,880 --> 00:35:48,000
emphasis on

00:35:45,680 --> 00:35:49,520
the definition of what ai actually is

00:35:48,000 --> 00:35:51,359
and it just brought to mind that the

00:35:49,520 --> 00:35:54,079
definition of what is fair

00:35:51,359 --> 00:35:55,280
is also a contested issue and something

00:35:54,079 --> 00:35:57,520
that we should think

00:35:55,280 --> 00:35:58,880
really critically about i mean computer

00:35:57,520 --> 00:36:00,800
scientists have been thinking about the

00:35:58,880 --> 00:36:02,720
definition of fair for algorithms for

00:36:00,800 --> 00:36:04,560
quite some time and the short answer is

00:36:02,720 --> 00:36:06,640
that there is no answer yet

00:36:04,560 --> 00:36:08,000
but also to remember that what is fair

00:36:06,640 --> 00:36:11,280
is not necessarily

00:36:08,000 --> 00:36:13,599
just so it's not totally clear that

00:36:11,280 --> 00:36:16,160
making facial recognition better at

00:36:13,599 --> 00:36:18,800
identifying black faces is a good thing

00:36:16,160 --> 00:36:19,599
for the world it's not totally clear

00:36:18,800 --> 00:36:22,320
that you want

00:36:19,599 --> 00:36:24,000
police to be able to better identify

00:36:22,320 --> 00:36:25,920
people in black neighborhoods

00:36:24,000 --> 00:36:28,560
it's not totally clear that you want ice

00:36:25,920 --> 00:36:31,280
to um be able to better identify

00:36:28,560 --> 00:36:31,760
undocumented immigrants all of these

00:36:31,280 --> 00:36:33,200
things

00:36:31,760 --> 00:36:34,960
kind of come up in the definition of

00:36:33,200 --> 00:36:36,560
fairness and and so i think it's really

00:36:34,960 --> 00:36:38,400
important that we hone in on what we

00:36:36,560 --> 00:36:39,119
actually need when we are talking about

00:36:38,400 --> 00:36:40,800
fairness

00:36:39,119 --> 00:36:42,960
what we actually want to prioritize in

00:36:40,800 --> 00:36:44,010
our conversations about ai and

00:36:42,960 --> 00:36:46,640
power

00:36:44,010 --> 00:36:48,800
[Music]

00:36:46,640 --> 00:36:50,560
thank you i yeah i really appreciate

00:36:48,800 --> 00:36:52,800
that and that and also the other

00:36:50,560 --> 00:36:55,040
this idea that it's not static right

00:36:52,800 --> 00:36:58,079
that it's um in the in kind of

00:36:55,040 --> 00:36:59,599
in the same way that that um uh the

00:36:58,079 --> 00:37:02,640
shifting of power

00:36:59,599 --> 00:37:03,520
is an ever-evolving possibility the idea

00:37:02,640 --> 00:37:06,400
that even that

00:37:03,520 --> 00:37:07,280
the idea of the intelligence is not

00:37:06,400 --> 00:37:09,520
fixed

00:37:07,280 --> 00:37:10,400
um and that it's that there's a cultural

00:37:09,520 --> 00:37:13,839
context

00:37:10,400 --> 00:37:16,000
uh or multiple cultural contexts around

00:37:13,839 --> 00:37:17,200
what what's getting deemed intelligent

00:37:16,000 --> 00:37:20,240
and and

00:37:17,200 --> 00:37:23,839
um the outputs and the outcomes

00:37:20,240 --> 00:37:24,720
are as uh are leaning into all of those

00:37:23,839 --> 00:37:27,760
systemic

00:37:24,720 --> 00:37:29,280
notions as as anything else i i really

00:37:27,760 --> 00:37:31,839
appreciate that a lot

00:37:29,280 --> 00:37:32,400
um i mean the other the other piece of

00:37:31,839 --> 00:37:34,480
it

00:37:32,400 --> 00:37:36,079
that certainly in in in the context of

00:37:34,480 --> 00:37:38,640
this conversation right is that much of

00:37:36,079 --> 00:37:42,079
the ai technology is actually tested

00:37:38,640 --> 00:37:43,440
and made or made in the western world

00:37:42,079 --> 00:37:46,400
and beta tested elsewhere

00:37:43,440 --> 00:37:48,720
and there are invasive ai systems

00:37:46,400 --> 00:37:50,960
deployed at refugee camps

00:37:48,720 --> 00:37:51,920
uh cambridge analytical medals in

00:37:50,960 --> 00:37:54,640
african elections

00:37:51,920 --> 00:37:55,200
long before the u.s election right and

00:37:54,640 --> 00:37:57,599
so

00:37:55,200 --> 00:37:58,880
um so what can be done are there

00:37:57,599 --> 00:38:04,000
movements pushing back

00:37:58,880 --> 00:38:07,040
against this behavior

00:38:04,000 --> 00:38:10,160
i'm happy i'm happy to jump in

00:38:07,040 --> 00:38:10,880
on this one and uh for that if you allow

00:38:10,160 --> 00:38:13,359
me

00:38:10,880 --> 00:38:14,960
i'm just gonna share uh instead of

00:38:13,359 --> 00:38:17,200
having a beautiful background today

00:38:14,960 --> 00:38:19,599
because zoom doesn't recognize

00:38:17,200 --> 00:38:20,240
the features of my face i'm just going

00:38:19,599 --> 00:38:23,920
to share

00:38:20,240 --> 00:38:25,599
i hope you can see this um this answer

00:38:23,920 --> 00:38:28,720
that i drafted

00:38:25,599 --> 00:38:31,359
um regarding your your your your

00:38:28,720 --> 00:38:35,040
question which is what is being done

00:38:31,359 --> 00:38:38,079
to uh basically prevent

00:38:35,040 --> 00:38:41,119
uh all the bad actors from

00:38:38,079 --> 00:38:43,920
testing all this and also the

00:38:41,119 --> 00:38:44,640
good faith ones are honest on testing to

00:38:43,920 --> 00:38:46,960
test from

00:38:44,640 --> 00:38:47,839
to test all these horrible things on

00:38:46,960 --> 00:38:50,640
users

00:38:47,839 --> 00:38:52,240
and end users and consumers like niga

00:38:50,640 --> 00:38:54,880
said earlier who have

00:38:52,240 --> 00:38:55,920
no absolutely no say into this

00:38:54,880 --> 00:38:58,400
conversation

00:38:55,920 --> 00:38:59,760
and for that i'd like to borrow a term

00:38:58,400 --> 00:39:02,400
that i read

00:38:59,760 --> 00:39:04,960
in a a recent publication called

00:39:02,400 --> 00:39:08,240
philanthropy and digital civil society

00:39:04,960 --> 00:39:09,200
blueprint 2021 it was it's uh it was

00:39:08,240 --> 00:39:12,240
written by

00:39:09,200 --> 00:39:14,720
dr lucy benholtz from the digital civil

00:39:12,240 --> 00:39:18,000
society lab at stanford university

00:39:14,720 --> 00:39:20,079
and it's basically uh i call it a bible

00:39:18,000 --> 00:39:22,079
for all that's related if you want to

00:39:20,079 --> 00:39:23,839
know everything about philanthropy and

00:39:22,079 --> 00:39:25,839
digital civil society

00:39:23,839 --> 00:39:28,320
at this year this is definitely one

00:39:25,839 --> 00:39:32,560
place you should you should go to

00:39:28,320 --> 00:39:34,960
and in that in that bible um

00:39:32,560 --> 00:39:35,760
there was this word that was used global

00:39:34,960 --> 00:39:38,480
majority

00:39:35,760 --> 00:39:40,160
i hate the term honestly global south

00:39:38,480 --> 00:39:43,760
global north they absolutely mean

00:39:40,160 --> 00:39:44,800
nothing um but when we talk about global

00:39:43,760 --> 00:39:47,920
majority

00:39:44,800 --> 00:39:50,640
we uh we we clearly understand

00:39:47,920 --> 00:39:52,079
that a majority of those illegals who

00:39:50,640 --> 00:39:55,599
live on this earth

00:39:52,079 --> 00:39:59,200
are actually um you know

00:39:55,599 --> 00:40:02,800
the well guinea pigs the uh

00:39:59,200 --> 00:40:03,359
they they're just honestly victims of

00:40:02,800 --> 00:40:06,240
whatever

00:40:03,359 --> 00:40:08,640
is being decided elsewhere without ever

00:40:06,240 --> 00:40:11,280
being consulted and ever being

00:40:08,640 --> 00:40:12,240
uh part of the the conversation but at

00:40:11,280 --> 00:40:15,760
the same time

00:40:12,240 --> 00:40:18,240
this global majority is also our future

00:40:15,760 --> 00:40:20,240
they tell us what's gonna happen to us

00:40:18,240 --> 00:40:21,440
here in the global minority i say here

00:40:20,240 --> 00:40:23,839
because i live in

00:40:21,440 --> 00:40:24,800
the so-called global north but i'm i'm

00:40:23,839 --> 00:40:28,160
cameroonian

00:40:24,800 --> 00:40:30,079
um and i i've seen in my work

00:40:28,160 --> 00:40:32,000
at antonette san francisco internet

00:40:30,079 --> 00:40:35,119
without words also in english

00:40:32,000 --> 00:40:38,160
we have seen how how uh

00:40:35,119 --> 00:40:39,280
you know how quick you can understand

00:40:38,160 --> 00:40:41,119
what's going to happen

00:40:39,280 --> 00:40:43,359
when you look at what's happening in

00:40:41,119 --> 00:40:45,440
places where actually nobody usually

00:40:43,359 --> 00:40:47,280
cares and specifically the media

00:40:45,440 --> 00:40:48,480
i'll give you one example when we

00:40:47,280 --> 00:40:51,280
started to talk about

00:40:48,480 --> 00:40:52,480
trolls in uh following in the aftermath

00:40:51,280 --> 00:40:55,280
of the 2016

00:40:52,480 --> 00:40:55,680
u.s presidential election we actually

00:40:55,280 --> 00:40:57,280
knew

00:40:55,680 --> 00:40:59,040
that this was i mean we didn't know

00:40:57,280 --> 00:41:02,960
these were trolls but we

00:40:59,040 --> 00:41:06,400
we knew that we had seen those automated

00:41:02,960 --> 00:41:10,079
automatically um you know generated

00:41:06,400 --> 00:41:12,079
publication tweets uh back in 2010

00:41:10,079 --> 00:41:13,119
when we're looking at what was happening

00:41:12,079 --> 00:41:16,319
in a western

00:41:13,119 --> 00:41:20,720
african country called gabon in which

00:41:16,319 --> 00:41:24,400
they were you know there were repression

00:41:20,720 --> 00:41:26,560
following um uprising of the population

00:41:24,400 --> 00:41:29,440
in the aftermath of the arab spring

00:41:26,560 --> 00:41:30,319
and to counter the narrative around what

00:41:29,440 --> 00:41:31,920
was happening

00:41:30,319 --> 00:41:34,000
and to counter the fact that civil

00:41:31,920 --> 00:41:36,400
society organization citizens have found

00:41:34,000 --> 00:41:37,760
a space on twitter and on facebook

00:41:36,400 --> 00:41:41,040
twitter particularly

00:41:37,760 --> 00:41:42,880
to tell what was really happening in a

00:41:41,040 --> 00:41:44,319
media environment that was completely

00:41:42,880 --> 00:41:48,880
locked for them

00:41:44,319 --> 00:41:51,839
um well the government chose to buy

00:41:48,880 --> 00:41:53,920
people well not people bots obviously i

00:41:51,839 --> 00:41:56,000
mean we started seeing people from india

00:41:53,920 --> 00:41:57,119
or from turkey tweeting about what was

00:41:56,000 --> 00:41:59,920
happening in gabon

00:41:57,119 --> 00:42:02,160
while not being there this was weird but

00:41:59,920 --> 00:42:04,960
at the time honestly we didn't know

00:42:02,160 --> 00:42:05,760
that this was this was a this was a

00:42:04,960 --> 00:42:09,359
troll or

00:42:05,760 --> 00:42:12,480
you know automated uh propaganda

00:42:09,359 --> 00:42:14,880
so why am i saying that global majority

00:42:12,480 --> 00:42:16,720
and global minority more than ever need

00:42:14,880 --> 00:42:19,839
to collaborate it's because

00:42:16,720 --> 00:42:22,800
we have the knowledge in western big

00:42:19,839 --> 00:42:24,480
academic institutions in western big

00:42:22,800 --> 00:42:27,040
human rights organizations

00:42:24,480 --> 00:42:27,680
but in the global majority they have the

00:42:27,040 --> 00:42:30,160
experience

00:42:27,680 --> 00:42:30,960
in their flesh but they cannot name that

00:42:30,160 --> 00:42:32,160
experience

00:42:30,960 --> 00:42:34,800
they cannot name that what they are

00:42:32,160 --> 00:42:36,720
seeing and what they're being victims of

00:42:34,800 --> 00:42:37,839
is wrong we're talking about facial

00:42:36,720 --> 00:42:41,280
recognition

00:42:37,839 --> 00:42:43,920
recently reports surveys that in

00:42:41,280 --> 00:42:46,079
in countries like uganda facial

00:42:43,920 --> 00:42:50,000
recognition is being used to arrest

00:42:46,079 --> 00:42:52,560
um you know uh democrat democratic

00:42:50,000 --> 00:42:53,119
demonstrators that that's absolutely

00:42:52,560 --> 00:42:55,280
worrying

00:42:53,119 --> 00:42:56,640
we're also we're also you talked about

00:42:55,280 --> 00:42:59,119
refugees of course

00:42:56,640 --> 00:43:01,040
refugees this is a big problem in my

00:42:59,119 --> 00:43:03,920
country cameron there's a huge

00:43:01,040 --> 00:43:05,119
refugee well several huge refugee crisis

00:43:03,920 --> 00:43:07,520
at the same time

00:43:05,119 --> 00:43:10,319
and we recently learned that the

00:43:07,520 --> 00:43:13,520
government accepted to sign with them

00:43:10,319 --> 00:43:14,560
i think it was the unhcr at least a big

00:43:13,520 --> 00:43:17,200
u.n

00:43:14,560 --> 00:43:17,680
refugee institution they accepted to

00:43:17,200 --> 00:43:20,480
sign

00:43:17,680 --> 00:43:22,400
a basically a program that would allow

00:43:20,480 --> 00:43:24,960
them to digitally

00:43:22,400 --> 00:43:25,680
trace all the refugees that come into

00:43:24,960 --> 00:43:27,839
cameroon

00:43:25,680 --> 00:43:29,520
it might sound appealing especially for

00:43:27,839 --> 00:43:30,800
a cameroon a country like cameroon

00:43:29,520 --> 00:43:33,200
that's already struggling

00:43:30,800 --> 00:43:34,720
with many other issues and you know

00:43:33,200 --> 00:43:36,960
basically doesn't have the money

00:43:34,720 --> 00:43:38,079
to handle all these new refugees and all

00:43:36,960 --> 00:43:41,119
these new people

00:43:38,079 --> 00:43:43,520
but one are the problems that will come

00:43:41,119 --> 00:43:44,319
after that when you start tracing the

00:43:43,520 --> 00:43:46,400
weakest

00:43:44,319 --> 00:43:48,000
what are you going to do later on to

00:43:46,400 --> 00:43:50,880
those once you have tested when you

00:43:48,000 --> 00:43:51,359
want to have perfected your ability to

00:43:50,880 --> 00:43:53,520
trace

00:43:51,359 --> 00:43:55,359
every single moment of the life of an

00:43:53,520 --> 00:43:58,160
individual what are you gonna do

00:43:55,359 --> 00:43:59,200
uh with those were for now living in a

00:43:58,160 --> 00:44:00,800
more liberal

00:43:59,200 --> 00:44:02,560
in a more liberal world and in a

00:44:00,800 --> 00:44:05,440
peaceful world so

00:44:02,560 --> 00:44:06,000
um this is this has been the core of my

00:44:05,440 --> 00:44:09,920
work

00:44:06,000 --> 00:44:12,240
uh since you know working in this space

00:44:09,920 --> 00:44:12,960
making sure that we collaborate as much

00:44:12,240 --> 00:44:14,640
as possible

00:44:12,960 --> 00:44:16,079
because a lot of things that we can tell

00:44:14,640 --> 00:44:18,720
you and

00:44:16,079 --> 00:44:19,520
i'm not not just africans asians latin

00:44:18,720 --> 00:44:21,839
americans

00:44:19,520 --> 00:44:23,680
but also trans communities lgbt

00:44:21,839 --> 00:44:26,000
communities in general

00:44:23,680 --> 00:44:27,119
they we can tell you things but we need

00:44:26,000 --> 00:44:28,960
to collaborate

00:44:27,119 --> 00:44:30,480
uh with academics and with big

00:44:28,960 --> 00:44:32,720
institutions not in

00:44:30,480 --> 00:44:33,920
an extractive way and i'm insisting on

00:44:32,720 --> 00:44:36,240
that but really

00:44:33,920 --> 00:44:38,000
collaborate respecting you know the

00:44:36,240 --> 00:44:40,000
expertise of each other it's not because

00:44:38,000 --> 00:44:41,520
it's an experience that it's worth less

00:44:40,000 --> 00:44:43,440
that's a false assumption that is

00:44:41,520 --> 00:44:45,839
plaguing the industry um

00:44:43,440 --> 00:44:48,319
but collaborate on an equal level

00:44:45,839 --> 00:44:50,880
because what i'm bringing to the table

00:44:48,319 --> 00:44:52,640
is absolutely necessary for you to make

00:44:50,880 --> 00:44:55,920
the point with your theoretical

00:44:52,640 --> 00:44:58,079
uh you know frame so yeah that's what i

00:44:55,920 --> 00:45:00,800
i wanted to share with you today and i'm

00:44:58,079 --> 00:45:04,640
going to stop sharing

00:45:00,800 --> 00:45:06,640
thank you um sarah i heard i saw your

00:45:04,640 --> 00:45:08,560
um hand raised and i want to also um

00:45:06,640 --> 00:45:09,839
prompt um

00:45:08,560 --> 00:45:12,000
the other folks in the in the

00:45:09,839 --> 00:45:15,119
conversation um

00:45:12,000 --> 00:45:17,440
i i think the

00:45:15,119 --> 00:45:19,200
that presumption of of who has what to

00:45:17,440 --> 00:45:21,839
say and even the terminology

00:45:19,200 --> 00:45:23,680
around majority and minority sierra that

00:45:21,839 --> 00:45:24,480
reminds me too about the distinction

00:45:23,680 --> 00:45:27,839
between

00:45:24,480 --> 00:45:30,640
fair and just and then they got

00:45:27,839 --> 00:45:32,319
the point you uh were making originally

00:45:30,640 --> 00:45:35,839
in terms of who's

00:45:32,319 --> 00:45:37,359
who's articulating um uh their power and

00:45:35,839 --> 00:45:38,960
who has agency

00:45:37,359 --> 00:45:40,720
under the current paradigms i mean i

00:45:38,960 --> 00:45:41,520
think that we could kind of flip the

00:45:40,720 --> 00:45:44,480
script here and

00:45:41,520 --> 00:45:45,040
and break the conversation open a little

00:45:44,480 --> 00:45:48,319
bit about

00:45:45,040 --> 00:45:49,599
around around all of that so so sarah

00:45:48,319 --> 00:45:51,040
you had your hand open but

00:45:49,599 --> 00:45:53,440
but no i'm gonna follow on the rest of

00:45:51,040 --> 00:45:55,920
you uh yeah right afterwards

00:45:53,440 --> 00:45:57,440
yeah i'm gonna toss the mic to my my

00:45:55,920 --> 00:45:59,119
peers in just one second i

00:45:57,440 --> 00:46:01,040
just have such like a short-term memory

00:45:59,119 --> 00:46:04,960
problem that i wanna

00:46:01,040 --> 00:46:06,240
i wanna just raise up uh plus one

00:46:04,960 --> 00:46:08,079
you know i get on these panels and i

00:46:06,240 --> 00:46:10,800
freak out with excitement because

00:46:08,079 --> 00:46:12,000
what people are saying is so on point

00:46:10,800 --> 00:46:14,480
and powerful

00:46:12,000 --> 00:46:16,480
and so julie i think what you just said

00:46:14,480 --> 00:46:19,520
about terminology number one

00:46:16,480 --> 00:46:21,760
and about you know this rel the

00:46:19,520 --> 00:46:23,520
problematic relationship historically

00:46:21,760 --> 00:46:24,880
and in this contemporary moment with

00:46:23,520 --> 00:46:27,680
academia

00:46:24,880 --> 00:46:29,599
and its relationship to industry and its

00:46:27,680 --> 00:46:32,960
extractive relationship

00:46:29,599 --> 00:46:36,079
on communities is also key here to

00:46:32,960 --> 00:46:39,680
kind of where we might break in and

00:46:36,079 --> 00:46:42,880
and do repair work and do new kinds of

00:46:39,680 --> 00:46:43,920
paradigm shifting um to change exactly

00:46:42,880 --> 00:46:45,839
what you were talking about

00:46:43,920 --> 00:46:47,599
so first of all i just wanted to share

00:46:45,839 --> 00:46:50,880
out on the terminology piece

00:46:47,599 --> 00:46:53,599
that i once read a a um

00:46:50,880 --> 00:46:55,280
just within another piece by a civil

00:46:53,599 --> 00:46:58,640
society advocate from

00:46:55,280 --> 00:47:00,640
uh from india who was speaking about

00:46:58,640 --> 00:47:02,000
you know he refused to use those uh

00:47:00,640 --> 00:47:04,240
kinds of um

00:47:02,000 --> 00:47:05,280
received terms as well and he so he was

00:47:04,240 --> 00:47:07,520
talking about the over

00:47:05,280 --> 00:47:08,400
developed world and i've always loved

00:47:07,520 --> 00:47:11,359
that and so

00:47:08,400 --> 00:47:13,280
um i kind of try to use that when i can

00:47:11,359 --> 00:47:15,040
and i also think about uh

00:47:13,280 --> 00:47:16,800
what we're actually talking about is

00:47:15,040 --> 00:47:19,680
resources and and

00:47:16,800 --> 00:47:21,520
economic resources primarily and so i

00:47:19,680 --> 00:47:24,800
think about it in terms of

00:47:21,520 --> 00:47:25,359
um the the economic overly resourced

00:47:24,800 --> 00:47:27,680
world

00:47:25,359 --> 00:47:28,640
you know like like jumping off on that

00:47:27,680 --> 00:47:31,440
point

00:47:28,640 --> 00:47:33,200
versus um the inappropriately

00:47:31,440 --> 00:47:35,599
economically under-resourced

00:47:33,200 --> 00:47:37,040
part parts of the world so i i just

00:47:35,599 --> 00:47:38,640
throwing that out there as a as a

00:47:37,040 --> 00:47:41,599
possibility and is something that

00:47:38,640 --> 00:47:43,040
that i think about um in terms of your

00:47:41,599 --> 00:47:46,319
you know the comments about

00:47:43,040 --> 00:47:48,800
um who get who gets to create

00:47:46,319 --> 00:47:49,599
laboratories on other people and treat

00:47:48,800 --> 00:47:52,880
other

00:47:49,599 --> 00:47:53,440
places and and and uh peoples as guinea

00:47:52,880 --> 00:47:56,240
pigs

00:47:53,440 --> 00:47:57,040
you know we this predates all of this

00:47:56,240 --> 00:47:59,040
this uh

00:47:57,040 --> 00:48:01,200
computational business i always think

00:47:59,040 --> 00:48:03,040
about from my american contacts

00:48:01,200 --> 00:48:04,319
the interference of the american

00:48:03,040 --> 00:48:07,920
government uh

00:48:04,319 --> 00:48:08,559
in in south america and in places like

00:48:07,920 --> 00:48:12,480
chile

00:48:08,559 --> 00:48:14,319
and um you know argentina and brazil and

00:48:12,480 --> 00:48:14,640
all of these countries that were meddled

00:48:14,319 --> 00:48:18,079
with

00:48:14,640 --> 00:48:21,119
to um to murderous ends and

00:48:18,079 --> 00:48:24,640
this is a tradition in place uh

00:48:21,119 --> 00:48:25,359
predating ai but certainly in place

00:48:24,640 --> 00:48:28,480
around

00:48:25,359 --> 00:48:31,440
uh uh picking places in the world

00:48:28,480 --> 00:48:33,520
and then going and doing stuff uh upon

00:48:31,440 --> 00:48:36,319
them that will then come home to roost

00:48:33,520 --> 00:48:37,119
uh in the american context uh and then

00:48:36,319 --> 00:48:39,520
um

00:48:37,119 --> 00:48:42,160
the last thing i wanted to say uh before

00:48:39,520 --> 00:48:45,280
i before i silence myself is uh

00:48:42,160 --> 00:48:48,800
the the piece about uh

00:48:45,280 --> 00:48:51,359
what you said so accurately about

00:48:48,800 --> 00:48:52,640
who actually has special insight into

00:48:51,359 --> 00:48:56,240
these problems

00:48:52,640 --> 00:48:58,000
who is um most harmed

00:48:56,240 --> 00:48:59,680
are the people who have the the

00:48:58,000 --> 00:49:01,440
solutions or at least the

00:48:59,680 --> 00:49:03,920
the knowledge to put it into the

00:49:01,440 --> 00:49:06,160
pipeline to talk about interventions

00:49:03,920 --> 00:49:07,760
and it was with that in mind that my

00:49:06,160 --> 00:49:11,040
colleague and collaborator

00:49:07,760 --> 00:49:13,200
and dear friend dr sofia noble and i

00:49:11,040 --> 00:49:15,520
came up with the ucla center for

00:49:13,200 --> 00:49:18,720
critical internet inquiry where we put

00:49:15,520 --> 00:49:21,599
forth and put forward and put first

00:49:18,720 --> 00:49:23,359
uh these kinds of uh voices with all of

00:49:21,599 --> 00:49:26,640
the expertise they have

00:49:23,359 --> 00:49:27,200
because we ourselves sofia as a black

00:49:26,640 --> 00:49:30,640
woman

00:49:27,200 --> 00:49:33,359
myself as a gay woman we understand

00:49:30,640 --> 00:49:35,119
what it's like to have the knowledge and

00:49:33,359 --> 00:49:36,640
to frankly be the canaries in the coal

00:49:35,119 --> 00:49:38,880
mine we're always trying to

00:49:36,640 --> 00:49:40,400
bang on the window and and tell everyone

00:49:38,880 --> 00:49:41,280
and so that's what we're trying to

00:49:40,400 --> 00:49:43,599
actually

00:49:41,280 --> 00:49:45,359
uh create a beacon for and to create a

00:49:43,599 --> 00:49:47,839
large enough

00:49:45,359 --> 00:49:48,640
critical mass of people to do some of

00:49:47,839 --> 00:49:50,610
that within

00:49:48,640 --> 00:49:52,559
academia specifically

00:49:50,610 --> 00:49:54,720
[Music]

00:49:52,559 --> 00:49:55,920
i just want to acknowledge that um some

00:49:54,720 --> 00:49:59,280
of our internet is

00:49:55,920 --> 00:49:59,760
is um uh more robust than others so

00:49:59,280 --> 00:50:01,760


00:49:59,760 --> 00:50:02,800
is going to go on audio um are you

00:50:01,760 --> 00:50:05,760
able to hear us

00:50:02,800 --> 00:50:05,760
uh pretty well now

00:50:06,240 --> 00:50:12,079
yes i can um i just wanted to add um

00:50:09,760 --> 00:50:14,079
a little bit into this conversation i

00:50:12,079 --> 00:50:15,760
mean i know we are talking about ai and

00:50:14,079 --> 00:50:17,839
power and i think we're very important

00:50:15,760 --> 00:50:21,119
for us to focus on power

00:50:17,839 --> 00:50:24,480
then who gets to uh design

00:50:21,119 --> 00:50:26,559
or train ai uh and i think i have said a

00:50:24,480 --> 00:50:29,359
little bit about this but i

00:50:26,559 --> 00:50:30,240
building what building on what julie

00:50:29,359 --> 00:50:34,240
said

00:50:30,240 --> 00:50:37,280
um it it's whose knowledge is it anyway

00:50:34,240 --> 00:50:40,319
right i mean uh the people who uh

00:50:37,280 --> 00:50:42,319
who are in our context have so much

00:50:40,319 --> 00:50:44,559
knowledge but there is an immense

00:50:42,319 --> 00:50:45,680
inequality of distribution of that

00:50:44,559 --> 00:50:49,839
knowledge

00:50:45,680 --> 00:50:51,920
we are mostly used as you know

00:50:49,839 --> 00:50:52,880
although we have all the knowledge and

00:50:51,920 --> 00:50:56,319
then that

00:50:52,880 --> 00:50:57,440
knowledge sort of transfers or travels

00:50:56,319 --> 00:50:59,440
to the western world

00:50:57,440 --> 00:51:01,200
and then you know that's where we see

00:50:59,440 --> 00:51:03,839
the bias that's where the design you

00:51:01,200 --> 00:51:04,720
know uh the the design of product takes

00:51:03,839 --> 00:51:07,760
place

00:51:04,720 --> 00:51:09,920
uh and instead of distribution or equal

00:51:07,760 --> 00:51:12,559
distribution of resources

00:51:09,920 --> 00:51:13,280
we see that you know the inequalities of

00:51:12,559 --> 00:51:15,760
risk

00:51:13,280 --> 00:51:16,880
inequalities between the global north

00:51:15,760 --> 00:51:19,200
and global south

00:51:16,880 --> 00:51:21,200
organizations working on digital rights

00:51:19,200 --> 00:51:23,920
or working on tech and human rights

00:51:21,200 --> 00:51:24,960
those inequalities become wider and

00:51:23,920 --> 00:51:28,079
wider every

00:51:24,960 --> 00:51:28,960
you know every day so so and it's it's a

00:51:28,079 --> 00:51:31,599
lot of labor

00:51:28,960 --> 00:51:32,480
it's a free labor if like sitting on

00:51:31,599 --> 00:51:34,720
panels and talk

00:51:32,480 --> 00:51:36,000
sharing your knowledge it's a free labor

00:51:34,720 --> 00:51:38,319
uh and i think

00:51:36,000 --> 00:51:39,839
it's it's it's now time when we are

00:51:38,319 --> 00:51:41,359
seeing this these conversations

00:51:39,839 --> 00:51:42,880
happening in the western world around

00:51:41,359 --> 00:51:46,000
content moderation

00:51:42,880 --> 00:51:46,000
how we are still

00:51:47,760 --> 00:51:53,119
absolutely have no idea what's uh

00:51:51,119 --> 00:51:54,319
what are the decisions being taken

00:51:53,119 --> 00:51:55,920
around them

00:51:54,319 --> 00:51:58,160
while people who are sitting in these

00:51:55,920 --> 00:51:58,640
big tech giants social media companies

00:51:58,160 --> 00:52:00,319
or

00:51:58,640 --> 00:52:02,160
you know like running governments so i

00:52:00,319 --> 00:52:04,240
just wanted to acknowledge that there is

00:52:02,160 --> 00:52:08,400
a lot of labor happening in

00:52:04,240 --> 00:52:08,400
global south but there is a very

00:52:10,400 --> 00:52:13,839
that labor and distribution of

00:52:17,040 --> 00:52:24,160
you got you your audio cut out um right

00:52:20,880 --> 00:52:25,920
right at the end there but um but

00:52:24,160 --> 00:52:28,640
i'm gonna i'm gonna try to recap and

00:52:25,920 --> 00:52:31,119
then uh let us know if

00:52:28,640 --> 00:52:31,680
that i've come close but just in terms

00:52:31,119 --> 00:52:34,880
of

00:52:31,680 --> 00:52:36,000
the the wealth of information that is

00:52:34,880 --> 00:52:37,680
extracted

00:52:36,000 --> 00:52:40,160
and i'm paraphrasing obviously that is

00:52:37,680 --> 00:52:43,760
extracted like a resource

00:52:40,160 --> 00:52:47,200
um as resources have long been extracted

00:52:43,760 --> 00:52:49,760
from the location of of that knowledge

00:52:47,200 --> 00:52:50,960
and then there's a huge gap between then

00:52:49,760 --> 00:52:54,160
and and

00:52:50,960 --> 00:52:57,839
and a dearth of information of how that

00:52:54,160 --> 00:53:00,079
information even parlays into

00:52:57,839 --> 00:53:01,119
uh uh invention if you will and i'm

00:53:00,079 --> 00:53:03,680
making air

00:53:01,119 --> 00:53:04,400
air quotes um and how it's being used

00:53:03,680 --> 00:53:07,839
and so

00:53:04,400 --> 00:53:08,800
so it's it's hap so the it's happening

00:53:07,839 --> 00:53:10,720
on two levels

00:53:08,800 --> 00:53:12,480
there's the original extraction of

00:53:10,720 --> 00:53:13,200
knowledge and then there's the ways that

00:53:12,480 --> 00:53:14,960
the

00:53:13,200 --> 00:53:16,800
knowledge is being put to use that's not

00:53:14,960 --> 00:53:19,920
even being made clear

00:53:16,800 --> 00:53:21,200
is that is that correct on the point

00:53:19,920 --> 00:53:24,000
that you're trying to make

00:53:21,200 --> 00:53:24,000
right there at the end

00:53:26,480 --> 00:53:29,520
absolutely great thank you okay

00:53:28,480 --> 00:53:32,319
beautiful

00:53:29,520 --> 00:53:34,079
sierra do you want to hop in there sure

00:53:32,319 --> 00:53:36,160
i was just adding on to

00:53:34,079 --> 00:53:37,920
sarah i mean at the justice data lab we

00:53:36,160 --> 00:53:40,720
do exactly the same thing and

00:53:37,920 --> 00:53:42,160
the way that we are trying to do that is

00:53:40,720 --> 00:53:44,400
literally to put in the hands of

00:53:42,160 --> 00:53:47,119
community organizations

00:53:44,400 --> 00:53:48,000
research resources and so we assign

00:53:47,119 --> 00:53:50,559
teams

00:53:48,000 --> 00:53:52,079
of undergrad researchers with the

00:53:50,559 --> 00:53:54,720
princeton pedigree

00:53:52,079 --> 00:53:56,079
to these community organizations who say

00:53:54,720 --> 00:53:58,559
you know we really would love to know

00:53:56,079 --> 00:53:59,359
this or we really want to advocate for

00:53:58,559 --> 00:54:01,040
this and

00:53:59,359 --> 00:54:02,800
the students work on behalf of the

00:54:01,040 --> 00:54:03,920
organization in partnership with the

00:54:02,800 --> 00:54:07,119
organizations

00:54:03,920 --> 00:54:09,040
the organizations drive all of the

00:54:07,119 --> 00:54:10,240
theorizing drive the data collection

00:54:09,040 --> 00:54:12,160
drive everything

00:54:10,240 --> 00:54:13,359
and i think it's just a really powerful

00:54:12,160 --> 00:54:15,119
way um

00:54:13,359 --> 00:54:17,280
to make sure that the voices who need to

00:54:15,119 --> 00:54:18,640
be included are not only at the table

00:54:17,280 --> 00:54:25,359
but are at the head of the table they're

00:54:18,640 --> 00:54:27,119
controlling the conversation

00:54:25,359 --> 00:54:28,640
let's talk about that the kind of

00:54:27,119 --> 00:54:32,000
opportunities that you're each

00:54:28,640 --> 00:54:34,720
actually um uh creating

00:54:32,000 --> 00:54:35,119
and um what you're excited about and

00:54:34,720 --> 00:54:37,920
what

00:54:35,119 --> 00:54:40,000
like i i really don't want it to be that

00:54:37,920 --> 00:54:43,520
when we're having conversations of power

00:54:40,000 --> 00:54:46,480
and we have a panel of uh

00:54:43,520 --> 00:54:47,119
women queer women queer people of color

00:54:46,480 --> 00:54:49,920
that we're

00:54:47,119 --> 00:54:50,960
only talking about the power that we're

00:54:49,920 --> 00:54:54,400
disallowed

00:54:50,960 --> 00:54:56,799
or um and like i know everybody here

00:54:54,400 --> 00:54:58,480
is doing incredible work and putting

00:54:56,799 --> 00:54:59,200
forward sierra you just gave us a little

00:54:58,480 --> 00:55:01,760
window

00:54:59,200 --> 00:55:02,720
into that as well um what are you

00:55:01,760 --> 00:55:04,640
excited about

00:55:02,720 --> 00:55:06,640
how do you see that shifting you know

00:55:04,640 --> 00:55:10,240
when we're talking about um

00:55:06,640 --> 00:55:12,880
uh the analog disparities of of power

00:55:10,240 --> 00:55:14,079
are often upended when we come to

00:55:12,880 --> 00:55:16,079
collective purpose

00:55:14,079 --> 00:55:17,440
so i'm curious about examples of that

00:55:16,079 --> 00:55:19,200
kind of collectivity

00:55:17,440 --> 00:55:21,040
or anything that's thrilling you in this

00:55:19,200 --> 00:55:24,480
moment um if we could

00:55:21,040 --> 00:55:26,720
if we could go around um and and

00:55:24,480 --> 00:55:28,240
i know i'm i'm uh i didn't give you a

00:55:26,720 --> 00:55:30,160
warning i was gonna ask you that but

00:55:28,240 --> 00:55:32,160
but if we can be thoughtful about that

00:55:30,160 --> 00:55:35,280
of something that you're excited about

00:55:32,160 --> 00:55:35,839
um and what you see as potentially power

00:55:35,280 --> 00:55:38,880
shifting

00:55:35,839 --> 00:55:40,960
in the most micro or macro way um

00:55:38,880 --> 00:55:43,280
i'd love i'd love for that to be in the

00:55:40,960 --> 00:55:45,599
room and it as part of the conversation

00:55:43,280 --> 00:55:46,799
i'm gonna go around so sarah you're the

00:55:45,599 --> 00:55:50,079
first uh

00:55:46,799 --> 00:55:51,200
square in my family feud yeah i feel

00:55:50,079 --> 00:55:53,599
like brady bunch

00:55:51,200 --> 00:55:54,240
a lot of times too with this okay um and

00:55:53,599 --> 00:55:57,280
we're all

00:55:54,240 --> 00:55:59,760
like arranged differently but anyway um

00:55:57,280 --> 00:56:00,640
okay so yeah great question i appreciate

00:55:59,760 --> 00:56:02,880
the

00:56:00,640 --> 00:56:04,160
the context too right because this isn't

00:56:02,880 --> 00:56:07,680
all about

00:56:04,160 --> 00:56:10,880
um those of us on the panel

00:56:07,680 --> 00:56:14,079
and those who who we represent

00:56:10,880 --> 00:56:14,640
um just seating power we're not doing

00:56:14,079 --> 00:56:16,400
that

00:56:14,640 --> 00:56:17,839
you know if we ever did it we're not

00:56:16,400 --> 00:56:20,960
doing it anymore

00:56:17,839 --> 00:56:24,160
and we're actually thinking through

00:56:20,960 --> 00:56:27,040
um new ways of of doing and new ways

00:56:24,160 --> 00:56:29,040
of of creating as sierra was just you

00:56:27,040 --> 00:56:32,000
know articulating and so

00:56:29,040 --> 00:56:33,920
um from my own perspective and from

00:56:32,000 --> 00:56:37,599
speaking for

00:56:33,920 --> 00:56:39,920
uh our our uh our center at ucla

00:56:37,599 --> 00:56:41,920
one of the things that uh sofia noble

00:56:39,920 --> 00:56:45,119
and i are working on right now

00:56:41,920 --> 00:56:46,799
actively is thinking about

00:56:45,119 --> 00:56:48,240
uh you know some of the projects we've

00:56:46,799 --> 00:56:52,559
had in mind for

00:56:48,240 --> 00:56:55,839
for a decade which is um

00:56:52,559 --> 00:56:58,079
pushing back pushing open that public

00:56:55,839 --> 00:57:00,880
space and the public sphere

00:56:58,079 --> 00:57:01,520
that has been inappropriately colonized

00:57:00,880 --> 00:57:05,040
and i do

00:57:01,520 --> 00:57:08,319
use that word very uh

00:57:05,040 --> 00:57:11,599
very um intentionally

00:57:08,319 --> 00:57:15,280
by tech uh

00:57:11,599 --> 00:57:17,839
tech having kind of um

00:57:15,280 --> 00:57:18,640
taken up these notions that we have

00:57:17,839 --> 00:57:20,240
about

00:57:18,640 --> 00:57:22,559
so many of these information

00:57:20,240 --> 00:57:26,240
institutions that have sat in

00:57:22,559 --> 00:57:29,839
uh squarely in uh kind of the public

00:57:26,240 --> 00:57:32,079
good space and then colonized

00:57:29,839 --> 00:57:33,920
their words their identities we have

00:57:32,079 --> 00:57:35,680
susan wojcicki from youtube

00:57:33,920 --> 00:57:37,599
going around the world telling the whole

00:57:35,680 --> 00:57:39,440
world youtube is a library if you want

00:57:37,599 --> 00:57:41,599
to see me go apoplectic

00:57:39,440 --> 00:57:43,200
let me hear her say that one more time i

00:57:41,599 --> 00:57:46,160
lose it every time

00:57:43,200 --> 00:57:47,280
it's not um it's not without harm that

00:57:46,160 --> 00:57:49,680
she does that

00:57:47,280 --> 00:57:51,839
libraries don't collect data and and

00:57:49,680 --> 00:57:52,720
monetize it on their users libraries

00:57:51,839 --> 00:57:54,799
don't

00:57:52,720 --> 00:57:56,480
promote and disseminate uh

00:57:54,799 --> 00:57:58,319
disinformation and misinformation

00:57:56,480 --> 00:58:00,400
material with without any

00:57:58,319 --> 00:58:01,599
sense of responsibility they don't use

00:58:00,400 --> 00:58:04,480
algorithms

00:58:01,599 --> 00:58:06,160
to serve up uh garbage to just keep

00:58:04,480 --> 00:58:08,240
people engaged none of that is not a

00:58:06,160 --> 00:58:10,480
library so youtube is not a library

00:58:08,240 --> 00:58:11,280
but libraries actually have so much to

00:58:10,480 --> 00:58:13,920
offer

00:58:11,280 --> 00:58:15,920
uh and our ways of knowing libraries a

00:58:13,920 --> 00:58:18,160
flawed institution as well with a

00:58:15,920 --> 00:58:19,680
you know with a difficult history but

00:58:18,160 --> 00:58:21,359
how could we reimagine

00:58:19,680 --> 00:58:23,359
some of the principles and values that

00:58:21,359 --> 00:58:25,119
come from libraries and librarianship

00:58:23,359 --> 00:58:26,880
to actually say not only is youtube not

00:58:25,119 --> 00:58:27,760
a library but this is what a library

00:58:26,880 --> 00:58:30,720
looks like

00:58:27,760 --> 00:58:31,200
um when it is in the internet space and

00:58:30,720 --> 00:58:33,200
in

00:58:31,200 --> 00:58:34,880
in practice for the for the public good

00:58:33,200 --> 00:58:37,040
and for the benefit of the public so

00:58:34,880 --> 00:58:38,000
that's just like the slightest preview

00:58:37,040 --> 00:58:40,079
of um

00:58:38,000 --> 00:58:41,280
and a very half-baked explanation of

00:58:40,079 --> 00:58:43,119
what we're coming up with

00:58:41,280 --> 00:58:44,319
but what i'm saying is we're actually

00:58:43,119 --> 00:58:46,960
going to stop

00:58:44,319 --> 00:58:47,920
seeding those spaces and those

00:58:46,960 --> 00:58:50,480
imaginaries

00:58:47,920 --> 00:58:51,520
actually to tech and we're going to

00:58:50,480 --> 00:58:55,280
reintroduce

00:58:51,520 --> 00:58:56,319
very um very directly and with great

00:58:55,280 --> 00:58:59,599
purpose

00:58:56,319 --> 00:59:02,720
uh some of these identifiable

00:58:59,599 --> 00:59:04,319
information curatorial roles to help

00:59:02,720 --> 00:59:06,880
users make sense

00:59:04,319 --> 00:59:08,720
when the the sense making has been

00:59:06,880 --> 00:59:12,000
deliberately removed from them

00:59:08,720 --> 00:59:15,200
uh for the purposes of profit

00:59:12,000 --> 00:59:15,920
so that's kind of where we are um in in

00:59:15,200 --> 00:59:18,640
essence

00:59:15,920 --> 00:59:20,400
um bringing the human back and and and

00:59:18,640 --> 00:59:23,440
foregrounding the human

00:59:20,400 --> 00:59:25,200
in this notion of um artificial

00:59:23,440 --> 00:59:26,400
intelligence like whoever said that was

00:59:25,200 --> 00:59:29,520
better

00:59:26,400 --> 00:59:30,799
you know um we used to think uh uh sweet

00:59:29,520 --> 00:59:32,640
and low was better too

00:59:30,799 --> 00:59:34,160
you know what i mean it's not it caused

00:59:32,640 --> 00:59:36,640
cancer it's not good

00:59:34,160 --> 00:59:37,520
so um you know just we're just thinking

00:59:36,640 --> 00:59:40,640
that way right now

00:59:37,520 --> 00:59:42,160
thanks cool thank you julie what about

00:59:40,640 --> 00:59:45,760
you what are you excited about

00:59:42,160 --> 00:59:47,440
where do you see uh some potential and

00:59:45,760 --> 00:59:50,559
what would make you really happy to see

00:59:47,440 --> 00:59:50,559
some momentum behind

00:59:50,960 --> 00:59:55,599
um i'm honestly very excited about a lot

00:59:53,920 --> 00:59:56,960
of things right now when it comes to

00:59:55,599 --> 01:00:00,000
this conversation

00:59:56,960 --> 01:00:02,799
the first thing of course is that my

01:00:00,000 --> 01:00:04,720
very dear colleague she'll speak

01:00:02,799 --> 01:00:08,079
for herself and myself

01:00:04,720 --> 01:00:11,119
are both part of a a

01:00:08,079 --> 01:00:14,400
new organization powerful organization

01:00:11,119 --> 01:00:15,200
which is making decisions on uh facebook

01:00:14,400 --> 01:00:17,119
and instagram

01:00:15,200 --> 01:00:18,400
content moderation including the

01:00:17,119 --> 01:00:20,319
automated ones

01:00:18,400 --> 01:00:21,760
and i'm talking here about the the

01:00:20,319 --> 01:00:24,880
oversight board which was

01:00:21,760 --> 01:00:28,880
which was created almost a year ago now

01:00:24,880 --> 01:00:31,920
and for me this is exciting because

01:00:28,880 --> 01:00:35,599
it's honestly the first time

01:00:31,920 --> 01:00:38,960
in this industry that we are recognizing

01:00:35,599 --> 01:00:42,079
that the the expertise and knowledge

01:00:38,960 --> 01:00:45,760
from people who we thought before

01:00:42,079 --> 01:00:47,920
uh you know did not matter let's

01:00:45,760 --> 01:00:48,799
talk very frankly i mean i wouldn't i'm

01:00:47,920 --> 01:00:50,880
a black woman

01:00:48,799 --> 01:00:53,040
so how many chances i would have been

01:00:50,880 --> 01:00:53,760
here having this conversation 10 or 15

01:00:53,040 --> 01:00:55,760
years ago

01:00:53,760 --> 01:00:58,000
but that would have been very difficult

01:00:55,760 --> 01:01:01,440
so uh i measure

01:00:58,000 --> 01:01:04,960
and i we we talked about that with night

01:01:01,440 --> 01:01:07,280
um often we measure uh you know

01:01:04,960 --> 01:01:08,880
what what we've been able to to do but

01:01:07,280 --> 01:01:09,680
that's not you know that's not the end

01:01:08,880 --> 01:01:12,799
of it all

01:01:09,680 --> 01:01:15,680
we are here and i'm here particularly uh

01:01:12,799 --> 01:01:18,720
with the purpose of making sure that

01:01:15,680 --> 01:01:19,200
whenever we will have our conversations

01:01:18,720 --> 01:01:22,000
about

01:01:19,200 --> 01:01:22,799
content moderation but others in general

01:01:22,000 --> 01:01:26,079
we will not

01:01:22,799 --> 01:01:28,319
look at people like me or uh

01:01:26,079 --> 01:01:30,559
you know people elsewhere outside of the

01:01:28,319 --> 01:01:31,359
u.s and outside of europe outside of

01:01:30,559 --> 01:01:35,040
canada

01:01:31,359 --> 01:01:37,440
as you know just consumers or users who

01:01:35,040 --> 01:01:38,400
we think about in the afterthought it's

01:01:37,440 --> 01:01:40,960
a priority

01:01:38,400 --> 01:01:42,960
it should be the principle and the other

01:01:40,960 --> 01:01:45,760
thing i'm excited about which is

01:01:42,960 --> 01:01:47,200
closely linked to uh to the one i just

01:01:45,760 --> 01:01:50,160
mentioned is that we're

01:01:47,200 --> 01:01:52,079
i'm doing a research right now at the

01:01:50,160 --> 01:01:53,040
digital civil society lab at stanford

01:01:52,079 --> 01:01:55,280
university

01:01:53,040 --> 01:01:57,119
and also as an affiliate at the berkman

01:01:55,280 --> 01:01:59,839
client center at harvard

01:01:57,119 --> 01:02:00,559
uh when i'm working i mean i'm not even

01:01:59,839 --> 01:02:02,480
studying

01:02:00,559 --> 01:02:03,599
we've developed anthony san franciac

01:02:02,480 --> 01:02:06,160
methodology

01:02:03,599 --> 01:02:08,400
to make sure that in the automated

01:02:06,160 --> 01:02:10,559
moderation systems that

01:02:08,400 --> 01:02:11,599
platforms are rolling out as the

01:02:10,559 --> 01:02:14,480
solution to

01:02:11,599 --> 01:02:15,200
the content problems well we want to

01:02:14,480 --> 01:02:18,559
make sure

01:02:15,200 --> 01:02:19,039
to get you know the human back into the

01:02:18,559 --> 01:02:22,319
loop

01:02:19,039 --> 01:02:23,520
and by human i talk here about the very

01:02:22,319 --> 01:02:26,480
specific

01:02:23,520 --> 01:02:28,960
context that is missing from most of the

01:02:26,480 --> 01:02:31,280
automated content moderation systems

01:02:28,960 --> 01:02:32,000
and by doing that to bring those

01:02:31,280 --> 01:02:34,799
contacts

01:02:32,000 --> 01:02:35,280
to bring this very local knowledge we

01:02:34,799 --> 01:02:39,039
rely

01:02:35,280 --> 01:02:41,440
and we work with and we also

01:02:39,039 --> 01:02:42,400
you know collaborate as i was saying we

01:02:41,440 --> 01:02:44,640
collaborate

01:02:42,400 --> 01:02:45,599
with organizations in the countries

01:02:44,640 --> 01:02:48,079
where we work in

01:02:45,599 --> 01:02:49,440
and once we work with them we have a

01:02:48,079 --> 01:02:51,760
better understanding of

01:02:49,440 --> 01:02:53,599
what hate actually looks like in this

01:02:51,760 --> 01:02:54,400
country what disinformation actually

01:02:53,599 --> 01:02:58,559
looks like

01:02:54,400 --> 01:03:00,720
when you work only with people located

01:02:58,559 --> 01:03:02,799
in global north you're going to feed

01:03:00,720 --> 01:03:03,119
databases that are filled with errors

01:03:02,799 --> 01:03:05,280
and

01:03:03,119 --> 01:03:07,599
honestly most of the times and

01:03:05,280 --> 01:03:10,640
that are even going to silence

01:03:07,599 --> 01:03:12,640
those who are actually using

01:03:10,640 --> 01:03:14,319
those platforms to bring a critical

01:03:12,640 --> 01:03:16,799
debate a critical

01:03:14,319 --> 01:03:18,000
voice that we don't like necessarily but

01:03:16,799 --> 01:03:20,400
that is necessary

01:03:18,000 --> 01:03:21,359
for for many democracies in the world to

01:03:20,400 --> 01:03:23,680
flourish

01:03:21,359 --> 01:03:24,400
and so that's the other part i'm excited

01:03:23,680 --> 01:03:27,280
about

01:03:24,400 --> 01:03:28,480
making sure that whenever we talk about

01:03:27,280 --> 01:03:31,359
those products

01:03:28,480 --> 01:03:33,440
uh we will adopt basically the same

01:03:31,359 --> 01:03:36,480
strategy as the bad actors

01:03:33,440 --> 01:03:39,599
why not test the good things you know

01:03:36,480 --> 01:03:40,400
by collaborating with civil society

01:03:39,599 --> 01:03:43,440
organizations

01:03:40,400 --> 01:03:45,920
in those countries and global majority

01:03:43,440 --> 01:03:46,960
i'm trying to educate myself too it's

01:03:45,920 --> 01:03:50,000
very difficult

01:03:46,960 --> 01:03:50,480
and uh yes that that's yeah that's the

01:03:50,000 --> 01:03:53,359
future

01:03:50,480 --> 01:03:55,359
i'm borrowing you know a word here from

01:03:53,359 --> 01:03:58,960
catherine matar who said that

01:03:55,359 --> 01:04:00,960
to make her work uh so positive

01:03:58,960 --> 01:04:02,960
heading the wikimedia foundation she

01:04:00,960 --> 01:04:05,200
looked at the future and the future was

01:04:02,960 --> 01:04:08,799
africa asia latin america

01:04:05,200 --> 01:04:09,280
thanks so i i think that's so important

01:04:08,799 --> 01:04:12,880
because

01:04:09,280 --> 01:04:14,400
so so many times the conversation is

01:04:12,880 --> 01:04:15,920
how do we have a seat at the table and

01:04:14,400 --> 01:04:17,520
not how do we make a new table or

01:04:15,920 --> 01:04:18,480
whoever said we wanted a table in the

01:04:17,520 --> 01:04:20,480
first place

01:04:18,480 --> 01:04:21,839
right like that's it's really really

01:04:20,480 --> 01:04:24,720
really important to think about

01:04:21,839 --> 01:04:25,359
what what uh how we build the future

01:04:24,720 --> 01:04:28,559
that we're

01:04:25,359 --> 01:04:29,839
intent upon living in sierra what about

01:04:28,559 --> 01:04:32,880
you what are you excited about

01:04:29,839 --> 01:04:34,960
what feels positive to you i'm also so

01:04:32,880 --> 01:04:36,799
excited about so many things and i

01:04:34,960 --> 01:04:38,400
i told you all about the just data lab

01:04:36,799 --> 01:04:39,599
and i'm so excited about the work that's

01:04:38,400 --> 01:04:42,960
going on there

01:04:39,599 --> 01:04:44,400
um but in my own research i'm also i'm

01:04:42,960 --> 01:04:46,240
working on a project that

01:04:44,400 --> 01:04:47,520
that explores how minority political

01:04:46,240 --> 01:04:50,640
candidates in the u.s

01:04:47,520 --> 01:04:51,200
experience misindis information online

01:04:50,640 --> 01:04:53,039
and

01:04:51,200 --> 01:04:55,760
unsurprisingly it often borders on

01:04:53,039 --> 01:04:58,319
harassment one easy example is

01:04:55,760 --> 01:04:59,839
obama's anti-birther rumor that that

01:04:58,319 --> 01:05:00,799
accused him of not being born in the

01:04:59,839 --> 01:05:02,960
united states but that

01:05:00,799 --> 01:05:04,640
specifically hinged on his racial and

01:05:02,960 --> 01:05:06,720
ethnic identity

01:05:04,640 --> 01:05:08,079
but anyway all of that is to say that

01:05:06,720 --> 01:05:10,160
i'm really excited

01:05:08,079 --> 01:05:11,200
about a lot of the new tools that are

01:05:10,160 --> 01:05:13,359
springing up

01:05:11,200 --> 01:05:14,720
created by women created by people of

01:05:13,359 --> 01:05:17,920
color created by other

01:05:14,720 --> 01:05:19,680
other marginalized folks um to

01:05:17,920 --> 01:05:21,599
kind of solve these problems and i

01:05:19,680 --> 01:05:22,079
really appreciate what julie and sarah

01:05:21,599 --> 01:05:23,599
were talking

01:05:22,079 --> 01:05:25,839
about about bringing the human back in

01:05:23,599 --> 01:05:27,440
and one instrumental part of being human

01:05:25,839 --> 01:05:30,640
is the communities

01:05:27,440 --> 01:05:32,880
that that we're a part of so one of my

01:05:30,640 --> 01:05:33,920
favorite examples is amy zhang's squad

01:05:32,880 --> 01:05:36,640
box which

01:05:33,920 --> 01:05:38,640
is a kind of crowd-sourced way for your

01:05:36,640 --> 01:05:41,119
friends and family to filter out

01:05:38,640 --> 01:05:42,799
negative negativity and harassment

01:05:41,119 --> 01:05:45,839
online and it really

01:05:42,799 --> 01:05:48,000
centers community involvement care

01:05:45,839 --> 01:05:50,240
and i love that these things are being

01:05:48,000 --> 01:05:51,200
infused into what we often deemed really

01:05:50,240 --> 01:05:53,440
impersonal

01:05:51,200 --> 01:05:54,480
kind of objective whatever that means

01:05:53,440 --> 01:05:56,799
systems

01:05:54,480 --> 01:05:58,240
and tools so i love that that's kind of

01:05:56,799 --> 01:05:59,839
being infused and

01:05:58,240 --> 01:06:02,160
i think that's the best way to move

01:05:59,839 --> 01:06:02,160
forward

01:06:03,520 --> 01:06:07,680
thank you you got what about you

01:06:08,160 --> 01:06:12,640
yeah i mean um as uh julie already said

01:06:12,240 --> 01:06:15,440
that

01:06:12,640 --> 01:06:16,400
um uh the experience that we both are

01:06:15,440 --> 01:06:19,839
having i think

01:06:16,400 --> 01:06:23,440
it's uh i'm it's i'm very excited and

01:06:19,839 --> 01:06:26,640
also you know like it's a it's unusual

01:06:23,440 --> 01:06:30,559
space for women like me a woman of color

01:06:26,640 --> 01:06:32,799
where you have like a a powerful

01:06:30,559 --> 01:06:34,160
space where you have all the power to

01:06:32,799 --> 01:06:36,079
take decisions

01:06:34,160 --> 01:06:38,079
and it's unusual for us because usually

01:06:36,079 --> 01:06:40,400
we don't have that kind of space

01:06:38,079 --> 01:06:42,559
and i i feel that it's so important to

01:06:40,400 --> 01:06:43,440
normalize these spaces for women of

01:06:42,559 --> 01:06:47,119
color

01:06:43,440 --> 01:06:49,119
who have um immense

01:06:47,119 --> 01:06:50,160
knowledge around human rights and

01:06:49,119 --> 01:06:52,240
technology

01:06:50,160 --> 01:06:54,000
uh and digital rights and we have so

01:06:52,240 --> 01:06:56,079
many women women of color

01:06:54,000 --> 01:06:58,000
and even if they are part of different

01:06:56,079 --> 01:07:00,559
boards or advisory councils

01:06:58,000 --> 01:07:01,680
how much voice they have and i think we

01:07:00,559 --> 01:07:03,760
really need to see that

01:07:01,680 --> 01:07:05,200
you know like how we can give them that

01:07:03,760 --> 01:07:07,599
voice um

01:07:05,200 --> 01:07:09,440
and at the micro level i'm very excited

01:07:07,599 --> 01:07:10,480
uh around the work that we are doing in

01:07:09,440 --> 01:07:13,359
pakistan

01:07:10,480 --> 01:07:14,000
uh i'm very excited to see a lot of

01:07:13,359 --> 01:07:16,880
women

01:07:14,000 --> 01:07:18,640
feminists taking lead around the

01:07:16,880 --> 01:07:20,960
discourse of digital rights

01:07:18,640 --> 01:07:22,160
and the kind of feminist internet we are

01:07:20,960 --> 01:07:26,480
making here

01:07:22,160 --> 01:07:29,440
um also you know looking into the

01:07:26,480 --> 01:07:30,640
issues that no one has ever looked into

01:07:29,440 --> 01:07:32,799
and then holding

01:07:30,640 --> 01:07:34,880
you know tech giants accountable or

01:07:32,799 --> 01:07:36,799
powerful actors accountable within the

01:07:34,880 --> 01:07:40,000
country while living in a country

01:07:36,799 --> 01:07:40,480
where in the patriarchal society talking

01:07:40,000 --> 01:07:42,880
to

01:07:40,480 --> 01:07:45,039
a powerful state is very difficult i'm

01:07:42,880 --> 01:07:45,680
very excited for that future especially

01:07:45,039 --> 01:07:48,559
on this

01:07:45,680 --> 01:07:48,880
international women's day i'm excited to

01:07:48,559 --> 01:07:51,119
see

01:07:48,880 --> 01:07:52,830
the feminist internet you know not just

01:07:51,119 --> 01:07:54,400
in pakistan but across the world

01:07:52,830 --> 01:07:56,799
[Music]

01:07:54,400 --> 01:07:58,640
and and and the other thing i think is

01:07:56,799 --> 01:08:00,480
really important and i'm going to tie it

01:07:58,640 --> 01:08:01,280
to one of the questions we got asked on

01:08:00,480 --> 01:08:04,319
twitter

01:08:01,280 --> 01:08:06,240
is that we're not talking about um uh

01:08:04,319 --> 01:08:07,680
only engaging something theoretically

01:08:06,240 --> 01:08:10,480
right like that these

01:08:07,680 --> 01:08:11,440
ideas of a feminist internet of a

01:08:10,480 --> 01:08:15,200
community

01:08:11,440 --> 01:08:18,239
led internet of of um majority

01:08:15,200 --> 01:08:21,199
uh the global majority right that

01:08:18,239 --> 01:08:22,159
are actually about um being able to

01:08:21,199 --> 01:08:24,480
build

01:08:22,159 --> 01:08:25,600
and having the capacity to build

01:08:24,480 --> 01:08:28,640
autonomy

01:08:25,600 --> 01:08:31,679
and autonomous spaces that are that

01:08:28,640 --> 01:08:35,520
are um untethered from some from

01:08:31,679 --> 01:08:38,080
these systems uh of of inequality

01:08:35,520 --> 01:08:39,279
and and that and that they were designed

01:08:38,080 --> 01:08:40,960
to be

01:08:39,279 --> 01:08:42,799
unjust i mean i think that that's the

01:08:40,960 --> 01:08:44,880
piece is that it's not that

01:08:42,799 --> 01:08:46,239
it's just broken it's actually working

01:08:44,880 --> 01:08:48,799
in the ways that things were

01:08:46,239 --> 01:08:50,000
intended and insofar as we hold

01:08:48,799 --> 01:08:52,080
different intentions

01:08:50,000 --> 01:08:54,239
then we have to build for the for those

01:08:52,080 --> 01:08:57,199
intentions and i think that that's also

01:08:54,239 --> 01:08:59,120
a way that um uh it that's an

01:08:57,199 --> 01:08:59,520
opportunity i'm actually excited about

01:08:59,120 --> 01:09:02,880
so

01:08:59,520 --> 01:09:05,040
um is that um while

01:09:02,880 --> 01:09:06,080
certainly we see when we build

01:09:05,040 --> 01:09:09,520
unintentionally

01:09:06,080 --> 01:09:11,279
or on purpose unjustly what we

01:09:09,520 --> 01:09:13,440
what we get but that we actually do have

01:09:11,279 --> 01:09:16,719
the opportunity to build

01:09:13,440 --> 01:09:17,199
uh really specifically um in new ways

01:09:16,719 --> 01:09:20,799
and that

01:09:17,199 --> 01:09:24,080
and i have and i'm excited about that um

01:09:20,799 --> 01:09:25,520
um i think there are a lot of incredible

01:09:24,080 --> 01:09:27,359
conversations and things being built

01:09:25,520 --> 01:09:31,440
around data around data sovereignty

01:09:27,359 --> 01:09:34,880
around uh um around community access

01:09:31,440 --> 01:09:36,799
around looking at um uh um

01:09:34,880 --> 01:09:38,960
also who's holding who's holding what

01:09:36,799 --> 01:09:40,880
data and and for whom

01:09:38,960 --> 01:09:42,480
there's a lot there that that i feel

01:09:40,880 --> 01:09:46,000
really excited to unpack

01:09:42,480 --> 01:09:48,000
um and uh i told i told

01:09:46,000 --> 01:09:50,400
us that i'd point us to also to the rest

01:09:48,000 --> 01:09:52,239
of mozfest so i'm also excited the fact

01:09:50,400 --> 01:09:56,080
that a lot of what was discussed here

01:09:52,239 --> 01:09:58,480
is getting um uh teased out much more

01:09:56,080 --> 01:10:00,480
uh across so many different panels and

01:09:58,480 --> 01:10:03,360
conversations and workshops

01:10:00,480 --> 01:10:04,719
and in uh in spatial chat around moss

01:10:03,360 --> 01:10:07,520
fest so i really

01:10:04,719 --> 01:10:08,640
urge folks to um to participate in those

01:10:07,520 --> 01:10:11,040
conversations

01:10:08,640 --> 01:10:13,280
if anything that got uplifted here feels

01:10:11,040 --> 01:10:14,719
particularly germane

01:10:13,280 --> 01:10:17,360
one of the questions we got asked on

01:10:14,719 --> 01:10:20,960
twitter um and i think that this is

01:10:17,360 --> 01:10:22,880
um uh i'm gonna bring

01:10:20,960 --> 01:10:24,159
i'm gonna bring them together um i'm

01:10:22,880 --> 01:10:25,520
gonna tell you two questions and then

01:10:24,159 --> 01:10:27,760
anybody who wants to take it

01:10:25,520 --> 01:10:29,679
because i think we've touched on this in

01:10:27,760 --> 01:10:30,880
what ways can we bring an intersectional

01:10:29,679 --> 01:10:33,360
anti-oppression

01:10:30,880 --> 01:10:34,320
anti-cast lens into discussions and

01:10:33,360 --> 01:10:36,880
decisions

01:10:34,320 --> 01:10:38,239
about power inequalities in tech another

01:10:36,880 --> 01:10:41,440
question that came up

01:10:38,239 --> 01:10:43,520
is around indigenous wisdom so community

01:10:41,440 --> 01:10:45,600
and indigenous wisdom how do we

01:10:43,520 --> 01:10:47,600
bring that into tech particularly in

01:10:45,600 --> 01:10:50,880
response to gendered harassment

01:10:47,600 --> 01:10:54,159
racial profiling or misinformation

01:10:50,880 --> 01:10:56,320
um and so i'll just and then

01:10:54,159 --> 01:10:57,679
and then the third question on twitter

01:10:56,320 --> 01:11:01,679
was how do we snap

01:10:57,679 --> 01:11:04,480
out of uh the pre the predetermined

01:11:01,679 --> 01:11:06,400
um identities some of us have been given

01:11:04,480 --> 01:11:09,520
so how do we actually

01:11:06,400 --> 01:11:12,560
um up end or or um

01:11:09,520 --> 01:11:14,880
avoid the algorithm uh versions of

01:11:12,560 --> 01:11:17,920
ourselves that we've been ascribed

01:11:14,880 --> 01:11:20,400
so those are the they're small easy

01:11:17,920 --> 01:11:24,000
questions

01:11:20,400 --> 01:11:25,520
but um if any of them speaks to you um

01:11:24,000 --> 01:11:27,040
i'd love to hear what you have to say

01:11:25,520 --> 01:11:30,080
julia is that

01:11:27,040 --> 01:11:33,040
yeah yes thank you um

01:11:30,080 --> 01:11:34,560
i i will you know take the most

01:11:33,040 --> 01:11:37,760
difficult one

01:11:34,560 --> 01:11:38,239
which is related to how to make sure

01:11:37,760 --> 01:11:41,199
we're

01:11:38,239 --> 01:11:42,080
uh you know bringing in anti-paternity

01:11:41,199 --> 01:11:45,440
uh

01:11:42,080 --> 01:11:47,440
and entire oppression views and

01:11:45,440 --> 01:11:48,960
knowledge and also indigenous knowledge

01:11:47,440 --> 01:11:52,159
i would like to flag

01:11:48,960 --> 01:11:55,199
one a very important uh

01:11:52,159 --> 01:11:57,760
procedure that exists out there so

01:11:55,199 --> 01:11:59,679
the oversight board which i mentioned is

01:11:57,760 --> 01:12:02,800
a new organization which

01:11:59,679 --> 01:12:04,480
makes decision on content decision made

01:12:02,800 --> 01:12:07,520
by facebook and instagram

01:12:04,480 --> 01:12:11,199
on their platforms and one of the ways

01:12:07,520 --> 01:12:14,080
i mean we really want to foster

01:12:11,199 --> 01:12:14,960
interaction with the public i know the

01:12:14,080 --> 01:12:16,719
public is

01:12:14,960 --> 01:12:18,000
potentially two billion people so it's

01:12:16,719 --> 01:12:21,520
not you know

01:12:18,000 --> 01:12:25,040
possible virtually but we do have

01:12:21,520 --> 01:12:28,159
a uh a channel of communication which is

01:12:25,040 --> 01:12:30,239
through the public comment that we open

01:12:28,159 --> 01:12:32,480
uh for each case that we receive for

01:12:30,239 --> 01:12:34,400
instance we had a public comment period

01:12:32,480 --> 01:12:38,159
that was 10 days i think

01:12:34,400 --> 01:12:41,199
for the trump suspension account case

01:12:38,159 --> 01:12:41,920
we received a lot a lot of comments and

01:12:41,199 --> 01:12:44,159
many of them

01:12:41,920 --> 01:12:46,000
from northern institutions and

01:12:44,159 --> 01:12:48,640
particularly in the united states

01:12:46,000 --> 01:12:49,440
we had another case that's related to

01:12:48,640 --> 01:12:53,199
blackface

01:12:49,440 --> 01:12:55,840
on on on facebook uh are we allowed

01:12:53,199 --> 01:12:56,719
to uh and particularly on svartipit who

01:12:55,840 --> 01:13:00,560
is a

01:12:56,719 --> 01:13:03,280
traditional uh christmas character

01:13:00,560 --> 01:13:04,320
in the in the in the netherlands and who

01:13:03,280 --> 01:13:07,520
who has been

01:13:04,320 --> 01:13:08,080
criticized for alleged racism and black

01:13:07,520 --> 01:13:10,960
facing

01:13:08,080 --> 01:13:12,719
and blackface has been you know recently

01:13:10,960 --> 01:13:14,560
facebook rolled out a new policy saying

01:13:12,719 --> 01:13:15,360
blackface is not allowed anymore on its

01:13:14,560 --> 01:13:17,920
platforms

01:13:15,360 --> 01:13:18,560
so uh we invited public comments on that

01:13:17,920 --> 01:13:20,480
as well

01:13:18,560 --> 01:13:22,159
i mean in general in all the cases that

01:13:20,480 --> 01:13:25,280
we have public comments are

01:13:22,159 --> 01:13:26,080
really a great opportunity for us to

01:13:25,280 --> 01:13:28,719
have

01:13:26,080 --> 01:13:30,400
you know access to another point of view

01:13:28,719 --> 01:13:32,719
that's not from the user

01:13:30,400 --> 01:13:33,840
that's not from facebook or instagram

01:13:32,719 --> 01:13:36,320
but that's you know for

01:13:33,840 --> 01:13:37,280
from organization working on this on the

01:13:36,320 --> 01:13:39,760
on this issue

01:13:37,280 --> 01:13:40,560
and it's it's very it's very helpful

01:13:39,760 --> 01:13:43,840
i'll give you

01:13:40,560 --> 01:13:47,600
one example in a case related to

01:13:43,840 --> 01:13:48,000
um uh azerbaijan and and armenia there

01:13:47,600 --> 01:13:50,159
were

01:13:48,000 --> 01:13:52,920
there was a publication published during

01:13:50,159 --> 01:13:55,760
a a conflict that happened in the

01:13:52,920 --> 01:13:56,480
nagorno-karabakh region earlier last

01:13:55,760 --> 01:13:59,280
year

01:13:56,480 --> 01:14:00,239
and uh we received a comment saying

01:13:59,280 --> 01:14:02,000
telling us that

01:14:00,239 --> 01:14:04,000
well you know in a case of conflict

01:14:02,000 --> 01:14:04,719
international human rights usually

01:14:04,000 --> 01:14:07,679
allows

01:14:04,719 --> 01:14:08,640
or is more permissible with regards to

01:14:07,679 --> 01:14:12,239
using

01:14:08,640 --> 01:14:13,440
you know very inflammatory words insults

01:14:12,239 --> 01:14:15,440
and all this we did

01:14:13,440 --> 01:14:17,360
i didn't know that personally and i

01:14:15,440 --> 01:14:20,400
found it very compelling and helpful

01:14:17,360 --> 01:14:22,239
so just to give an example of how we can

01:14:20,400 --> 01:14:23,440
you know deconstruct our preconceived

01:14:22,239 --> 01:14:25,760
ideas too as

01:14:23,440 --> 01:14:27,040
uh oversight board members and look at

01:14:25,760 --> 01:14:29,120
cases differently

01:14:27,040 --> 01:14:30,480
based on contributions and comments that

01:14:29,120 --> 01:14:34,719
we received from

01:14:30,480 --> 01:14:34,719
individuals or or institutions

01:14:36,080 --> 01:14:39,520
thank you um we have three minutes left

01:14:38,960 --> 01:14:43,280
sarah

01:14:39,520 --> 01:14:44,880
um please take us give us your response

01:14:43,280 --> 01:14:46,400
to any of those questions tell us which

01:14:44,880 --> 01:14:50,159
ones you're answering

01:14:46,400 --> 01:14:52,640
um sure just on the blackface uh issue

01:14:50,159 --> 01:14:55,280
uh in in this book in the english or

01:14:52,640 --> 01:14:57,920
french edition whatever is your pleasure

01:14:55,280 --> 01:14:58,960
there is a content moderator working at

01:14:57,920 --> 01:15:02,000
mega tech

01:14:58,960 --> 01:15:04,880
who raises this issue uh

01:15:02,000 --> 01:15:07,360
starting in 2012 and so there's these

01:15:04,880 --> 01:15:10,000
other points of input that we can bring

01:15:07,360 --> 01:15:13,120
to the table about who sees problems

01:15:10,000 --> 01:15:14,800
and who who who has foresight and

01:15:13,120 --> 01:15:17,199
commercial content moderators

01:15:14,800 --> 01:15:19,040
at firms whether they are are located at

01:15:17,199 --> 01:15:20,880
the firms or whether they are

01:15:19,040 --> 01:15:22,159
at geographical and organizational

01:15:20,880 --> 01:15:24,800
remove as uh

01:15:22,159 --> 01:15:26,640
contractors have incredible insight and

01:15:24,800 --> 01:15:27,040
knowledge about these things and yet

01:15:26,640 --> 01:15:28,800
that

01:15:27,040 --> 01:15:30,960
knowledge has gone directly to the

01:15:28,800 --> 01:15:33,679
garbage can in most cases

01:15:30,960 --> 01:15:34,640
so i i i want to acknowledge the work

01:15:33,679 --> 01:15:36,880
that they do

01:15:34,640 --> 01:15:39,040
and the kinds of information they also

01:15:36,880 --> 01:15:41,840
have that has been

01:15:39,040 --> 01:15:42,239
pretty much uh not taken up uh and who

01:15:41,840 --> 01:15:43,760
does

01:15:42,239 --> 01:15:45,760
commercial content moderation well it's

01:15:43,760 --> 01:15:48,400
some of the very people that we are

01:15:45,760 --> 01:15:49,440
concerned with uh in this conversation

01:15:48,400 --> 01:15:52,719
that we've had

01:15:49,440 --> 01:15:55,600
um with apologies to audrey lord

01:15:52,719 --> 01:15:57,120
uh the master's tools will not dismantle

01:15:55,600 --> 01:15:59,520
the master's house

01:15:57,120 --> 01:16:00,640
we are in a paradigm where tech defines

01:15:59,520 --> 01:16:03,920
not only

01:16:00,640 --> 01:16:06,480
the answers but the problems and so what

01:16:03,920 --> 01:16:09,440
i would urge everyone to do is to

01:16:06,480 --> 01:16:11,280
push back on that framing and we we will

01:16:09,440 --> 01:16:14,480
take the power to ask our own

01:16:11,280 --> 01:16:16,480
questions and answer them appropriately

01:16:14,480 --> 01:16:18,239
using the expertise and knowledge we

01:16:16,480 --> 01:16:19,760
have from our lived experience from our

01:16:18,239 --> 01:16:22,320
communities

01:16:19,760 --> 01:16:23,040
from indigenous ways of knowing all the

01:16:22,320 --> 01:16:24,960
places

01:16:23,040 --> 01:16:26,719
that have historically and continue to

01:16:24,960 --> 01:16:30,400
be ignored and denied

01:16:26,719 --> 01:16:32,880
so i i refute um being in a space where

01:16:30,400 --> 01:16:36,320
i respond to the problems that tech

01:16:32,880 --> 01:16:38,400
creates and then asks us to fix

01:16:36,320 --> 01:16:39,840
and that also doesn't take up what we

01:16:38,400 --> 01:16:41,520
have to say by the way

01:16:39,840 --> 01:16:43,120
so i will say we bring we're going to

01:16:41,520 --> 01:16:46,560
bring new

01:16:43,120 --> 01:16:47,199
questions and answers not maybe even not

01:16:46,560 --> 01:16:49,840
to the table

01:16:47,199 --> 01:16:51,440
as you said earlier thank you to another

01:16:49,840 --> 01:16:53,600
place

01:16:51,440 --> 01:16:55,360
right on we're at time so i want to give

01:16:53,600 --> 01:16:57,440
sierra and you got

01:16:55,360 --> 01:17:03,040
a word if you'd like to bring anything

01:16:57,440 --> 01:17:05,040
into the room i just want to plus one

01:17:03,040 --> 01:17:08,640
everything that was already said

01:17:05,040 --> 01:17:09,679
right on my god yeah same here agree to

01:17:08,640 --> 01:17:12,719
everything whatever has

01:17:09,679 --> 01:17:13,679
has been said beautiful thank you so

01:17:12,719 --> 01:17:16,239
much sierra

01:17:13,679 --> 01:17:16,800
julie negat sarah for joining us thank

01:17:16,239 --> 01:17:19,120
you

01:17:16,800 --> 01:17:20,080
all out there for joining us remember

01:17:19,120 --> 01:17:23,199
that um

01:17:20,080 --> 01:17:26,320
power is already ours and this is about

01:17:23,199 --> 01:17:29,120
actually um um stepping up uh

01:17:26,320 --> 01:17:31,679
in in community in collaboration and in

01:17:29,120 --> 01:17:32,640
purpose to exercise that power so thanks

01:17:31,679 --> 01:17:45,840
everyone

01:17:32,640 --> 01:17:45,840
and see you at the rest of mozfest

01:18:39,199 --> 01:18:41,280

YouTube URL: https://www.youtube.com/watch?v=ka6VPT16Oj8


